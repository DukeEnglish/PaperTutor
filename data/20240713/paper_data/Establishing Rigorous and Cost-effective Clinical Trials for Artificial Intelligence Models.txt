Establishing Rigorous and
Cost-effective Clinical Trials for
Artificial Intelligence Models
Edited By
Wanling Gao
Yunyou Huang
Dandan Cui
Zhuoming Yu
Wenjing Liu
Xiaoshuang Liang
Jiahui Zhao
Jiyue Xie
Hao Li
Li Ma
Ning Ye
Yumiao Kang
Dingfeng Luo
Peng Pan
Wei Huang
Zhongmou Liu
Jizhong Hu
Gangyuan Zhao
Chongrong Jiang
Fan Huang
Tianyi Wei
Suqin Tang
Bingjie Xia
Zhifei Zhang
Jianfeng Zhan
BenchCouncil: International Open Benchmark Council
http://www.benchcouncil.org
Technical Report No. BenchCouncil-Medicine-Evaluation-2024
July 11, 2024
4202
luJ
11
]IA.sc[
1v45580.7042:viXraEstablishing Rigorous and Cost-effective Clinical
Trials for Artificial Intelligence Models
Wanling Gao1,3,4, Yunyou Huang2,18,*, Dandan Cui1, Zhuoming
Yu2,18, Wenjing Liu5, Xiaoshuang Liang2,18, Jiahui Zhao2,18, Jiyue
Xie2,18, Hao Li2,18, Li Ma5,7, Ning Ye6, Yumiao Kang6, Dingfeng
Luo8, Peng Pan9, Wei Huang10, Zhongmou Liu11, Jizhong Hu12,
Gangyuan Zhao13, Chongrong Jiang14, Fan Huang15, Tianyi Wei16,
Suqin Tang2, Bingjie Xia15,*, Zhifei Zhang17,*, Jianfeng Zhan1,3,4,*
1Institute of Computing Technology, Chinese Academy of Sciences,
Beijing, 100190, China.
2Guangxi Key Lab of Multi-Source Information Mining and Security,
Guangxi Normal University, Guilin, 541004, China.
3International Open Benchmark Council.
4University of Chinese Academy of Sciences, Beijing, 100086, China.
5Guilin Medical University, Guilin, 541100, China.
6Affiliated Hospital of Guilin Medical University, Guilin, 541000, China.
7XuanJi Technology Co., Ltd., Guilin, 541000, China.
8Xing An County People’s Hospital, Guilin, 541300, China.
9Meng Shan County People’s Hospital, Wuzhou, 543000, China.
10Guilin People’s Hospital, Guilin, 541000, China.
11Yong Fu County People’s Hospital, Guilin, 541000, China.
12Ling Chuan County People’s Hospital, Guilin, 541000, China.
13Quan Zhou County People’s Hospital, Guilin, 541000, China.
14Guan Yang County People’s Hospital, Guilin, 541000, China.
15The Second Affiliated Hospital of Guilin Medical University, Guilin,
541000, China.
16International College, Guangxi University, Nanning, 530004, China.
17Capital Medical University, Beijing, 100069, China.
18Key Lab of Education Blockchain and Intelligent Technology, Ministry
of Education, Guangxi Normal University, Guilin, 541004, China.
2*corresponding authors: Jianfeng Zhan (zhanjianfeng@ict.ac.cn) and
Yunyou Huang (huangyunyou@gxnu.edu.cn) and Zhifei Zhang
(zhifeiz@ccmu.edu.cn) and Bingjie Xia (xbj8879@163.com).
Abstract
A profound gap persists between artificial intelligence (AI) and clinical practice
in medicine, primarily due to the lack of rigorous and cost-effective evaluation
methodologies. State-of-the-art and state-of-the-practice AI model evaluations
are limited to laboratory studies on medical datasets or direct clinical trials
with no or solely patient-centered controls. Moreover, the crucial role of clin-
icians in collaborating with AI, pivotal for determining its impact on clinical
practice, is often overlooked. For the first time, we emphasize the critical neces-
sity for rigorous and cost-effective evaluation methodologies for AI models in
clinicalpractice,featuringpatient/clinician-centered(dual-centered)AIrandom-
ized controlled trials (DC-AI RCTs) and virtual clinician-based in-silico trials
(VC-MedAI) as an effective proxy for DC-AI RCTs. Leveraging 7500 diagnosis
records from two-phase inaugural DC-AI RCTs across 14 medical centers with
125 clinicians, our results demonstrate the necessity of DC-AI RCTs and the
effectivenessofVC-MedAI.Notably,VC-MedAIperformscomparablytohuman
clinicians, replicating insights and conclusions from prospective DC-AI RCTs.
We envision DC-AI RCTs and VC-MedAI as pivotal advancements, presenting
innovativeandtransformativeevaluationmethodologiesforAImodelsinclinical
practice, offering a preclinical-like setting mirroring conventional medicine, and
reshaping development paradigms in a cost-effective and fast-iterative manner.
Chinese Clinical Trial Registration: ChiCTR2400086816.
Keywords:AIinMedicine,ClinicalTrials,VirtualClinician,In-silicoTrials
1 Introduction
Artificial intelligence (AI) holds immense promise in clinical practice [1–4] but falls
intopermissive,time-consuming,andcostlyevaluations.Whilerandomizedcontrolled
trials (RCTs) are considered the gold standard for rigorous evaluation [5, 6], applying
themtoAImodelsinclinicalpracticeposesnewchallenges.Ontheonehand,clinicians
remain the primary decision-makers in medicine, viewing AI as a supportive rather
than a leading force in shaping patient care [7, 8]. However, traditional trial method-
ologies, which typically use controls like no intervention, placebo, or sham solely for
patients, fail to accommodate the dual focus on both patients and clinicians. This
oversight ignores the crucial synergy between AI models and clinicians, hindering the
effective integration of AI into clinical practice [1], as highlighted by criticisms [9, 10]
faced by AI-driven decision support tools, including those officially approved [11, 12].
3Meanwhile, traditional trials are single-blind or double-blind in general, based on fea-
sibility and necessity. However, visible (single-blind) or invisible (double-blind) of AI
modelinformationlikemodelnametoclinicianscaninducevariationsinpsychological
and behavioral responses. Relying on single-blind or double-blind solely is inadequate
for fully exploring the synergy between AI and clinicians and evaluating AI software
or devices comprehensively. Our results also corroborate this view.
Laboratory Preclinical Clinical Experimental group
Control group: no-intervention, placebo or
sham mainly for patients
In vitro Animal models Patients Single or double blind
(a) Patient-centered Trials for Conventional Medicine Evaluation: drug or device
No controls or
OR no-intervention control
for patients only
Laboratory: without RCTs Clinical: RCTs without clinician controls
(b) Patient-centered Trials for Conventional AI Model Evaluation in Clinical Practice
Objective: to evaluate AI’s true impact on clinicians’ behavior and decision-making, and its
subsequent effect on patient outcomes
Subjects: Patients & Clinicians (dual-centered)
Interventions: AI models Controls: no-model and invisible random model
Hybrid Blinding: visible (single-blind) and invisible (double-blind) of model info to clinicians
In-silico trials Clinical trials
Cost-effective
Good
and fast-iterative
Clinical
evaluation
Virtual Clinicians Practices
evaluated on
medical datasets
Laboratory Preclinical-like (VC-MedAI) Dual-centered AI RCTs
A rigorous and cost-effective methodology akin to conventional medicine evaluation
(c) Rigorous and Cost-effective Trials for AI Model Evaluation in Clinical Practice
Fig.1 TransformingClinicalTrialsforAIModelsinClinicialPractice.(a)and(b):patient-
centeredtrialsforconventionalmedicineevaluationandAImodelevaluationinclinicalpractice.(c)
rigorousandcost-effectivetrialsforAImodelevaluationinclinicalpractice:laboratory,preclinical-like
trialsusingin-silicoVC-MedAI,anddual-centeredAIrandomisedcontrolledtrials(DC-AIRCTs).
On the other hand, the lack of preclinical trials mandates a swift transition from
laboratory evaluations to human clinical trials. This transition carries inherent risks,
given the potential for serious clinical outcomes, meanwhile requiring substantial
investments in manpower, resources, finances, and time [1, 13, 14]. Consequently,
conductingRCTsandpublishingreportsexperiencesubstantialdelays[15],oftenren-
dered obsolete by rapid technological advancements [15]. Meanwhile, this prolonged
4
lanoitnevnoC
enicideM
ni
IA
)levoN(
enicideM
ni
IA
enicideM
)
lanoitnevnoC(process impedes AI model development from advancing collaboration with clinicians
and enhancing clinical outcomes, diverging from the fast-iterative approach pivotal
in software development. Moreover, the persistent need for RCTs with each software
iteration perpetuates delays and exacerbates these challenges.
Totackletheabovechallenges,forthefirsttime,weemphasizethecriticalnecessity
forrigorousandcost-effectiveevaluationmethodologiesforAImodelsinclinicalprac-
tice, featuring patient/clinician-centered (dual-centered) AI randomized controlled
trials (DC-AI RCTs) and virtual clinician-based in-silico trials (VC-MedAI), shown
in Fig. 1. Among them, DC-AI RCTs incorporate well-designed interventions, hybrid
single and double blinding, and patient/clinician-centered controls using no-model
and random-model. Experimental groups for each AI model are categorized based on
visibility of AI model information to clinicians: visible and invisible. Control groups
include no-model and invisible random-model (placebo or sham effect) categories, as
visible random-model holds no significance for clinicians. Clinicians and patients are
randomly assigned to receive either model-assisted diagnosis or standard care. Begin-
ning with sepsis, a leading cause of morbidity and mortality [16, 17], we conduct
the first rigorous and comprehensive two-phase DC-AI RCTs prospectively, across 14
medical centers involving 125 clinicians. Phase #1 adopted three AI models and two
controls across 2800 patients in 8 clinical settings. The 6000 diagnosis records from
Phase#1formedthebasisforVC-MedAI.InPhase#2,anewAImodelassistedwith
1500 diagnosis records to prospectively evaluate VC-MedAI.
VC-MedAI not only fills gaps left by traditional approaches like preclinical but
also complements in-silico trials, known for their effectiveness and cost-efficiency in
medicine [18–21]. For specificity and generality, VC-MedAI provides specialized in-
silicotrialsforsepsisandgeneralizedin-silicotrialsforotherdiseases.GivenanewAI
software or device in clinical practice, the workflow and steps of VC-MedAI in-silico
trials are illustrated in Fig. 2.
OurresultsrevealthenecessityofDC-AIRCTsandtheeffectivenessofVC-MedAI:
(1) Even an invisible random model can improve clinicians’ diagnostic accuracy with
3.37% AUC (area under the curve) improvement. However, the values for evaluated
AI models with two blinding types range from 1.95% to 10.9%. This suggests that
an AI model’s influence on clinical outcomes may not surpass that of a random
model. Therefore, DC-AI RCTs are crucial to accurately reflect the clinical signifi-
canceofAImodels.(2)VC-MedAIsupportsgeneratingasetofvirtualclinicianswith
demographicrepresentativeness,modelingthediagnosisbehaviorsofhumanclinicians
encounteringdifferentinterventionsandcontrols,anddiscoveringconsistentoutcomes
and conclusions with prospective clinical trials. DC-AI RCTs and VC-MedAI reshape
the evaluation methodology of AI models in clinical practice in a rigorous and cost-
effective manner. To the best of our knowledge, this is the first attempt to explore
such a study and we anticipate it to be a good starting point.
2 Results
Diagnosis data from DC-AI RCTs. We perform the first rigorous and compre-
hensive DC-AI RCTs on sepsis. We set two-phase trials and a series of comparative
5The First Rigorous and Comprehensive DC-AI RCTs (real-world clinical trials, 7500 diagnosis records)
Experimental
& Control
Hospital diversity Demographic diversity AI model diversity Clinical setting diversity
(14 medical centers) (2800 patients and 125 clinicians) (4 AI models + 1 random) (10 dual-centered settings)
Phase #1 - DC-AI RCTs (3 AI models, 6000 diagnosis records)
6 Experimental Groups (3 AI models * 2 blinding types) 2 Control Groups
low-quality (AUC75) LSTM-based AI model (visible and invisible to clinicians)
No-model
medium-quality (AUC85) LSTM-based AI model (visible and invisible to clinicians)
high-quality (AUC95) LSTM-based (DL) AI model (visible and invisible to clinicians) Random model (invisible)
VC-MedAI
Sex Features Two-stage Preliminary/Final
Diagnosis
Age Generalized
Clinician simulator for
Institution Level medicine Specialized
simulator for
Department sepsis Years of Working Virtual AI Model
Clinicians
Class of Position Time, decision, operations
Area of Expertise Patient
Virtual Clinician Generator Clinician Behavior Simulator
Workflow of VC-MedAI In-silico Trials
(2) (6) Accuracy
Efficiency
AI Inference VC-MedAI Generator VC-MedAI Simulator Diagnosis Reports
(1) (3) (5) (7)
(4)
AI Software or Device
in Medicine
Patient Cohort In-silico Settings Feature Embedding Feedback
Redesign and Redevelopment Suggestions
Prospective Evaluation of VC-MedAI
Phase #2 - DC-AI RCTs (1 new AI model, 1500 records) In-silico Trials using VC-MedAI
2 New Experimental Groups (1 AI models * 2 blinding) 125 virtual clinicians
high-quality (AUC95) CoxPHM-based (ML) AI model 2/10 dual-centered virtual clinical settings
(visible and invisible to clinicians) 1500/7500 virtual diagnosis records
Fig. 2 Workflow of VC-MedAI In-silico Trials. VC-MedAI is constructed and modeled from
Phase#1DC-AIRCTs,containingvirtualcliniciangeneratorandclinicianbehaviorsimulator.We
evaluatetheeffectivenessofVC-MedAIprospectivelycomparedtoPhase#2DC-AIRCTs.
clinical settings, covering a large real-world population [22], for example, eight exper-
imental groups with 4 AI models and 2 blinding types, and two control groups with
no-model and random model. The details are illustrated in Methods section.
6
noitalupoP
sretsulC
itluM
gnilpmaS
deifitartSThe necessity of clinician-centered and DC-AI RCTs. Our Phase #1 DC-
AI RCTs show that (1) when diagnosed with an invisible random model, clinicians
may show improved diagnosis accuracy on average, with 3.37% AUC improvement
from 64.45% to 67.82%, suggesting their cautious approach when dealing with mod-
els, particularly in cases of inconsistent decision-making. (2) when diagnosed with
the assistance of an AI model, clinicians’ diagnosis accuracy achieves AUC improve-
ment varying from 1.95% to 10.9%, indicating that the AI model’s impact on clinical
outcomes might not surpass that of a random model (3.37%). (3) clinicians achieve
optimal diagnosis accuracy, sensitivity, and specificity with a visible medium-quality
AImodel(i.e.,69%.77%,and61%,respectively)ratherthanavisiblehigh-qualityone
(i.e.,66%,73%,and59%)onaverage,underscoringthecriticalimportanceofclinician
interactions over model quality alone. (4) the influence of an AI model on decision-
making can vary significantly among different individual or group clinicians due to
varyingcharacteristicsofclinicians,patients,andtheAImodelitself,aswellaspsycho-
logical factors. For example, the difference even achieves to 2X+ on average in terms
of diagnosis accuracy and model acceptance rate, which is significant given the value
rangeof0to1.Hence,theintricateinteractionsbetweenAImodelsandclinicianswill
incur uncertain and significant implications for patients’ treatment strategies, timeli-
ness, and survival rates [22, 23]. DC-AI RCTs with rigorous experimental and control
groups are essential to ensure fair, standardized, and safe assessment of AI software
and devices. Details are described in a companion paper about the analysis of DC-AI
RCTs on sepsis.
VC-MedAI behaves similar with human clinicians in terms of preliminary
and final diagnosis decision. The preliminary and final diagnosis decisions of VC-
MedAI specialized simulator and human clinicians with the assistance of CoxPHM
are compared in Fig. 3(a) and Fig. 3(b), respectively. The simulator demonstrates
high similarity with human clinicians with an AUC of 0.81 (95% CI: 0.78-0.83) for
preliminary diagnosis and 0.82 (95% CI: 0.8-0.84) for final diagnosis compared to
prospective Phase #2 DC-AI RCTs. Overall, their diagnosis accuracies on average
are quite similar with a deviation of 3% for both preliminary and final diagnosis, as
shown in the “O” sector of Fig. 3(a) and Fig. 3(b). This implies that if a new AI
algorithmperformswellinVC-MedAIspecializedsimulator,itwilllikelyshowsimilar
performance in realistic clinical settings when collaborating with human clinicians.
WefurtherperformdetailedcomparisonsfromtheperspectivesofAImodels(AI),
clinicianpropertieslikeage(A),andpatienttypes(PT),coveringatotalof35dimen-
sions as shown in the legend of Fig. 3. The comparison deviation averages 6.5% for
preliminarydiagnosisand7.4%forfinaldiagnosis.Specifically,wefoundthatin32out
of 35 dimensions for preliminary diagnosis, the comparison deviation is around 10%,
with23dimensionsfallingwithina0%to6%range.Notethattheotherthreedimen-
sions with higher comparison deviations are orthopedics (33%), pediatrics (16%),
medicaluniversity(25%),sincethecliniciansamplesfromthesedimensionsareeither
small in number or have specific peculiarities, e.g., data collection from minors is
restrictedandprotectedbylaw.Thesituationoffinaldiagnosisremainsquitesimilar.
7This implies that at a fine-grained level, VC-MedAI specialized simulator also reflects
the behavior of human clinicians in realistic clinical settings.
Human Clinicians (a new AI model in Phase #2 DC-AI RCTs) VC-MedAI Diagnosis Examples of Ten Clinicians (Human vs. VC-MedAI)
i Fine-grained Diagnosis Accuracy of Ten Clinicians
a b
O: Overall HC1 CoxPHM_AUC95 (All)
VC1 CoxPHM_AUC95 (Visible)
A I C: oA xI P m Ho Md _el vs isible VH CC 22 CoxPHM_AUC95 (Invisible)
CoxPHM_invisible HC3 VC3
S: Sex
Male VH CC 44
Female HC5
VC5
A: Age
Age_<=30 VH CC 66
Age_(30,40] HC7
c d Age_(40,50] VC7 Age_(50,60] HC8
VC8
I: Institution Level
HC9
Grade-A Tertiary VC9
Grade-A Secondary HC10
Medical University VC10
W: Years of Working 0 100% 200% 300%
YoW_(0,5] Cumulative Diagnosis Accuracy
Y Yo oW W_ _( (5 1, 01 ,0 1] 5] j Diagnosis Behavior (click sequence of viewed examination items)
YoW_(15,20]
e f YoW_>20 C_Smear
P: Class of Position C_Culture
None C_Pathogen_Blood 18: C_Smear
Junior C_Medical_Imaging 16: C_Pathogen_Blood
Intermediate C_Haemostatic_Function 11 45 :: CC __ HM ae ed mic oa sl_ taI tm ica _g Fi un ng ction
Senior C_Arterial_Blood_Gas_Analysis 11 23 :: CC __ CA ort mer pia lel_ teB _l Boo lod o_ dG _a Cs o_ uA nn talysis
D: Department C_Complete_Blood_Count 111 0: : C H_ _P Dr ro uc ga _lc Hit io sn toin ry
D_emergency C_Procalcitonin
D_ICU H_Drug_History 78 :: HH __ PC au tl htu or ge en_Blood
D_internal H_Smear 56 :: HH __ HM ae ed mic oa sl_ taI tm ica _g Fi un ng ction
g h D D D_ _ _s o pu r er t dhg io ae pr try e id csics H_PathogH e_ nC _Bul lt ou or de 234 1::: : HHH H___ _MCA Fuor et nme d dr ip ai ca l mael l_ t H eeB n_ il tsBo ato lo l _o rd Eyo_ d xG _ aa mCs o_ inuA an tn t ia ol nysis
D_ophthalmology H_Medical_Imaging 9: H_Smear
D_gynaecology H_Haemostatic_Function
D_ChineseMed H_Arterial_Blood_Gas_Analysis
D_infectious H_Complete_Blood_Count
D_rheumatology H_MedicalHistory
D D_ _g na eust rr oo le on gt yerology H_Fundamental_Examination H: history items
H: history items C: current items
P T S: e P pa st ii se _n pt a T tiy ep ne t C: current items Seq1 S eq2 S eq3 S eq4 S eq5 S eq6 S eq7 S eq8 S eq S9 e q1 S0 e q1 S1 e q1 S2 e q1 S3 e q1 S4 e q1 S5 e q1 S6 e q1 S7 e q1 S8 e q1 S9 e q20 need to tested
Nonsepsis_patient to be tested Human (Left) vs. Virtual (Right) Clinician for each Seq
Fig. 3 VC-MedAI Behaves Similar with Human Clinicians Compared to Prospective
Phase #2 DC-AI RCTs. (a) and (b): the averaged preliminary and final (two-stage) diagnosis
accuracy comparisons between VC-MedAI specialized simulator and clinicians. (c) and (d): two-
stage accuracy comparisons between VC-MedAI generalized simulator and clinicians. (e) and (f):
two-stage time comparisons between VC-MedAI specialized simulator and clinicians. (g) and (h):
two-stagetimecomparisonsbetweenVC-MedAIgeneralizedsimulatorandclinicians.Thebreakdown
comparisonsofO(Overall),AI(AImodels),S(Sex),A(Age),I(Institution),W(YearsofWorking),
P (Class of Position), D (Department), and PT (Patient Type) are arranged from inside to outside
within each corresponding sector as shown in the legend. Generalized simulator has no PT sector
forgeneralsimulation.(i)and(j)arespecificdiagnosisexamplesoftencliniciansandcorresponding
VC-MedAIwiththesamefeatures.(i):diagnosisaccuracy.(j):diagnosisbehavior(clicksequenceof
examinationitems).EachsequencefromSeq1toSeq20containstheoperationsofahumanclinician
(left)andcorrespondingvirtualone(right).Notethathistoryfundamentalexaminationitemsinclude
body temperature, systolic blood pressure, diastolic blood pressure, heart rate, respiratory rate,
consciousnesslevel,andqSOFA(quickSequentialOrganFailureAssessment).
8
IAdeM-CV
dna
snaicinilC
namuH
fo selpmaxE
neTTheVD-MedAIgeneralizedsimulatorachievesanAUCof0.79(95%CI:0.77-0.81)
for preliminary diagnosis and 0.82 (95% CI: 0.79-0.84) for final stage on CoxPHM-
assisted evaluations, compared to real-world Phase #2 trials. Due to the reduction in
patient features, the generalized simulator exhibits a minor decrease in model quality
compared to the specialized one. Nevertheless, it remains within practical usability
and supports the human-AI interaction simulation through in-silico trials for various
diseasesinmedicine.Fig.3(c)andFig.3(d)showsthediagnosisaccuracycomparisons.
Thecomparisondeviationaverages6.6%forpreliminarydiagnosisand10.38%forfinal
diagnosis, from overall dimension and 33 detailed dimensions. This implies that not
onlyforsepsis,butalsoforotherdiseases,ifthecorrespondingAIalgorithmperforms
well in VC-MedAI generalized simulator, it will similarly demonstrate comparable
performance in realistic clinical settings when interacting with human clinicians.
VC-MedAIdemonstratesahighdegreeofsimilaritytohumancliniciansnotonlyon
averagelevelbutalsoattheindividuallevel.Specifically,Fig.3(i)showsacomparison
of fine-grained preliminary or final diagnosis accuracy of ten human clinicians and
VC-MedAI, withtheassistance ofCoxPHM-basedAImodelsunder differentblinding
types. Note that HD represents a human clinician and VD represents corresponding
virtual clinician who has similar features. We find that the model’s impact varies
amongdifferentclinicians;forsome,visiblemodelsprovidemoresignificantassistance
(e.g., Case#1), while for others, invisible models are more effective (e.g., Case#2).
VC-MedAI also reflects similar characteristics. The situation remains the same for all
ten compared clinicians. This implies that even for individual diagnostic case by a
single clinician, VC-MedAI maintains consistency with realistic diagnostic behaviors.
VC-MedAI behaves similar with human clinicians in terms of operation
behaviors. In addition to the diagnosis decision and results, the intermediate data
and behaviors during the diagnosis process are also important features. For example,
the examination data of patients serve as crucial or decisive references for clini-
cian’s decision-making. Hence, the operation behaviors involve a sequence of viewed
or checked examination items. VC-MedAI also supports the operation behavior sim-
ulation of human clinicians, compared to prospective Phase #2 DC-AI RCTs. The
recall-orientedunderstudyforgistingevaluation(ROUGE)scoreis{‘r’:0.80,‘p’:0.69,
‘f’: 0.74} for ROUGE-1 and {‘r’: 0.77, ‘p’: 0.66, ‘f’: 0.71} for ROUGE-L. Fig. 3(j)
shows detailed comparisons of twenty example sequences. We find that their opera-
tionsequencesofhumancliniciansandVC-MedAIspecializedsimulatorachieveshigh
degree of similarity from perspectives of not only specific examination items but also
sequence length. Overall, ten out of twenty sequences are exactly the same and the
remainingonesonlyhaveslightlydeviationwhicheithercheckedoneortwofeweritems
or one or two more items. Meanwhile, the averaged lengths of operation sequence for
human clinicians and VC-MedAI specialized simulator corroborate this point, which
are5.07and6.51,respectively.ThisimpliesthatforagivenAIalgorithmassistingwith
medical diagnosis, the examination items viewed by VC-MedAI will also be similarly
viewed in realistic clinical settings.
Consideringexaminationitemvariationsamongdifferentdiseases,VC-MedAIgen-
eralized simulator simulates the ratio of advanced items need to be further tested,
9e.g., haemostatic function, instead of specific sequence for generality. The AUC of
VC-MedAI generalized simulator for the operation behavior simulation achieves 0.85
(95% CI: 0.83-0.87). The comparison deviation averages 2.27% from 33 dimensions of
AI models and clinician features. Please see Appendix Tables B1-B2 for details. This
impliesforotherdiseasesnotmerelysepsis,theitemratioorderedbyhumanclinicians
in realistic clinical settings will be similar with the output of VC-MedAI.
VC-MedAI behaves similar with human clinicians in terms of preliminary
and final diagnosis time. Diagnosis time is another crucial behavioral character-
istic and key factor, especially in emergency situations where quick diagnosis can
significantly increase survival rates with even a slight time advantage. Fig. 3(e) and
Fig.3(f)showthediagnosistimecomparisonofhumancliniciansandVC-MedAIspe-
cialized simulator in terms of preliminary and final diagnosis, respectively, compared
to Phase #2 DC-AI RCTs using CoxPHM. Note that the diagnosis time only con-
siders the clinician’s diagnostic decision-making based on examination data and does
not account for the waiting time required to obtain these data. Considering the sim-
ilarity of human clinicians and VC-MedAI in operation behaviors illustrated above,
the whole time plus waiting time required by additional examination items likewise
maintains similarity. The time units are in minutes, displayed on a logarithmic scale.
Considering the potential time variability when a person repeats an operation multi-
ple times, we define ±20% of clinician’s diagnosis time as true time range. In terms of
thepreliminarydiagnosisofVC-MedAIspecializedsimulator,themeanabsoluteerror
(MAE)is0.5minutes(95%CI:0.46-0.53),occupying26.6%oftheaveragevalue(1.88
minutes). As for the final diagnosis, the MAE is 0.81 minutes (95% CI: 0.74-0.89),
occupying26.3%oftheaveragevalue(3.08minutes).Fig.3(g)andFig.3(h)showthe
performance of VC-MedAI generalized simulator. The MAE is 0.44 minutes (95% CI:
0.41-0.48) for preliminary diagnosis, occupying 23.4% of the average value, and 0.73
minutes (95% CI: 0.66-0.80) for final diagnosis, occupying 23.8% of the average value.
The experimental data indicates that when using VC-MedAI, the AI model’s impact
ondiagnosistime,whetherpositiveornegative,alignswithrealisticclinicaloutcomes.
VC-MedAI supports the discovery of consistent outcomes with conven-
tional clinical trials. We use VC-MedAI to perform in-silico trials adopting the
same settings with the real-world two-phase DC-AI RCTs, which are detailedly illus-
trated in Methods section. Specifically, VC-MedAI generator first generates the same
number of 125 virtual clinicians with new features through stratified sampling. The
generatingtimeis0.41seconds.Table1illustratesthevirtualclinicianpopulationand
demographics. VC-MedAI simulator then performs two-stage diagnosis on the same
patients using the new generated virtual clinicians, with or without the assistance of
different AI or random models. The diagnosis records are 7500 in total with the time
consumptionof4.83hours,including1.67hoursforpreliminaryand3.16hoursforfinal
diagnosis.Comparedtooneiterationofhumanclinicaltrialswhichmayspanfromsev-
eralmonthstoseveralyears,VC-MedAIachievesatleast150Xspeedup(4.83hoursvs.
1month),nottomentionlongertimeforonetrialandmoretrialiterations.Moreover,
10Table 1 Virtual Clinician Population and Demographics Generated by VC-MedAI.
Category Characteristics No. of Clin- Median Mean±
icians (% by SD
unit)
Male 65(52%)
Sex
Female 60(48%)
age≤30 35(28%) 28 26.2±3.2
30<age≤40 42(33%) 35 35.4±2.8
Age
40<age≤50 36(29%) 43 43.5±2.0
50<age≤60 12(10%) 55 54.8±2.9
(0,5] 39(31%) 4 3.4±1.5
(5,10] 21(17%) 10 9.1±1.5
Years of Working (10,15] 18(14%) 13 13.1±1.1
(15,20] 27(22%) 19 18.5±1.7
>20 20(16%) 30 28.6±5.3
None(Duringresidencytraining) 21(17%)
Junior(Residentphysician) 16(13%)
Class of Position
Intermediate(Attendingphysician) 42(33%)
Senior(Chief/Associatechiefphysician) 46(37%)
Grade-ATertiaryHospital 35(28%)
Institution Level Grade-ASecondaryHospital 88(70%)
MedicalUniversity 2(2%)
Emergency 32(25.6%)
IntensiveCareUnit(ICU) 48(38.4%)
InternalMedicine 14(11.2%)
Surgery 7(5.6%)
Orthopedics 1(0.8%)
Pediatrics 8(6.4%)
Ophthalmology 1(0.8%)
Department
Gynaecology 5(4%)
TraditionalChineseMedicine(TCM) 6(4.8%)
InfectiousDiseases 1(0.8%)
RheumatologyandImmunology 1(0.8%)
Neurology 1(0.8%)
the in-silico trials of 7500 diagnosis records using VC-MedAI reflect similar charac-
teristics with the human clinical trials in terms of diagnosis accuracy and diagnosis
time, as shown from Fig. 4(a) to Fig. 4(h). This implies that VC-MedAI can support
rapidassessment,validation,anditerationofAIsoftwareordevice,whilemaintaining
diagnostic behaviors similar to human clinicians in realistic clinical settings.
In realistic clinical settings, mortality is the most critical clinical outcome and is
closelyrelatedtothetimelyuseofantibiotics.Theearlierantibioticsareadministered,
the higher the patient’s survival chances [24, 25]. Furthermore, studies have shown
thattheuseofantibioticsiscloselylinkedtotheearlydetectionofsepsis[26–28].The
earlier sepsis is detected, the higher the likelihood of timely antibiotic administration
and improved outcomes. We compared the time reduction for early detection of sep-
sis – a primary clinical phenomena related to the first antibiotic order and patients’
outcomes – between human clinical trials and virtual clinician based in-silico trials.
Specifically, we calculated and averaged the time reduction relative to the onset time
of sepsis under different settings, e.g., without model assistance, with the assistance
ofrandom,low-qualityLSTM-based(AUC0.75),medium-qualityLSTM-based(AUC
11Human Clinical Trials In-silico Trials (VC-MedAI) O: Overall Primary Clinical Phenomena related to Clinical Outcome
a b AI: AI models i Time reduction for early detection (crucial for first antibiotic order)
No_model
Random_model Preliminary Diagnosis Clinical Trial In-silico Trial
LSTM_AUC75
LSTM_AUC85 TREWScore (YS)
LSTM_AUC95 TREWScore (EW)
CoxPHM_AUC95 TREWScore (NS)
S: Sex LSTM_AUC95 (YS)
Male LSTM_AUC95 (EW)
Female LSTM_AUC95 (NS)
A: Age LSTM_AUC85 (YS)
Age_<=30 LSTM_AUC85 (EW)
c d Age_(30,40] LSTM_AUC85 (NS)
Age_(40,50] LSTM_AUC75 (YS)
Age_(50,60] LSTM_AUC75 (EW)
I: Institution Level LSTM_AUC75 (NS)
Grade-A Tertiary Random_model (YS)
Grade-A Secondary Random_model (EW)
Medical University Random_model (NS)
W: Years of Working No_model
YoW_(0,5]
YoW_(5,10] -2 -1 0 1 2 3
YoW_(10,15] The time reduction for early detection of sepsis (hours)
e f Y Yo oW W_ _( >1 25 0,20] j Time reduction for early detection (crucial for first antibiotic order)
P: Class of Position Final Diagnosis Clinical Trial In-silico Trial
None
Junior TREWScore (YS)
Intermediate TREWScore (EW)
Senior TREWScore (NS)
D: Department LSTM_AUC95 (YS)
D_emergency LSTM_AUC95 (EW)
D_ICU LSTM_AUC95 (NS)
D_internal LSTM_AUC85 (YS)
g h D D_ _s ou rr thg oe pry edics L LS ST TM M_ _A AU UC C8 85 5 ( (E NW S) )
D_pediatrics
D_ophthalmology LSTM_AUC75 (YS)
D_gynaecology LSTM_AUC75 (EW)
D_ChineseMed LSTM_AUC75 (NS)
D_infectious Random_model (YS)
D_rheumatology Random_model (EW)
D_neurology Random_model (NS)
PT: Patient Type No_model
Sepsis_patient -2 -1 0 1 2 3
Nonsepsis_patient The time reduction for early detection of sepsis (hours)
Fig.4 VC-MedAIsupportsthediscoveryofconsistentoutcomeswithreal-worldclinical
trials. (a) and (b): the averaged preliminary and final diagnosis (two-stage) accuracy comparisons
between human clinical and in-silico trials (specialized). (c) and (d): two-stage diagnosis accuracy
comparisonsbetweenhumanclinicalandin-silicotrials(generalized).(e)and(f):two-stagediagnosis
time comparisons between human clinical and in-silico trials (specialized). (g) and (h): two-stage
diagnosis time comparisons between human clinical and in-silico trials (generalized). Note that the
breakdowncomparisonsofO,AI,S,A,I,W,P,D,andPTarearrangedfrominsidetooutsidewithin
eachcorrespondingsector.(i)and(j)representthetimereductionforearlydetectionrelativetothe
onset time of sepsis patients, which is a primary clinical phenomenon related to clinical outcome.
(i): preliminary and (j): final diagnosis. YS, EW, and NS indicate the model’s prediction as sepsis,
earlywarningofsepsis,andnon-sepsis,respectively.Alargervaluesignifieslargertimereductionand
earlierdetectionofsepsis.
0.85), high-quality LSTM-based (AUC 0.95), and high-quality CoxPHM-based (AUC
0.95)AImodels.Meanwhile,wedifferentiatedtheimpactofmodelpredictionsonclin-
ical phenomena and used YS, EW, NS to represent the model prediction as sepsis,
early warning of sepsis, and non-sepsis, respectively. The time reduction comparisons
of preliminary and final diagnosis are shown in Fig. 4(i) and Fig. 4(j), respectively,
12with the unit in hours. Positive values indicate the sepsis was detected earlier rela-
tive to the onset time, while negative values indicate the disease was detected later.
The larger the value, the greater the time reduction, indicating earlier detection. We
observe that clinical phenomena in both human and in-silico trials exhibit similar
andconsistenttrends.Forinstance,theaveragetimereductionachievedusingahigh-
quality LSTM-based AI model is 0.753 hours in human clinical trials and 0.777 hours
in in-silico trials compared to diagnoses without model assistance. With a prospec-
tivehigh-qualityCoxPHM-basedAImodel,thereductionsare-0.074hoursand-0.077
hours, respectively. From a trend perspective, we find that the model’s performance
in in-silico trials is similarly reflected in human clinical trials. For example, we find
that for patients who have not yet during the sepsis onset, the model’s prediction
as an early warning is more readily accepted by clinicians and achieves higher time
reduction. This situation remains consistent across human clinical and in-silico trials.
As a result, virtual clinician based in-silico trials using VC-MedAI can replicate
conclusions and findings from realistic human clinical trials, implying that the out-
comes of a new AI software or device obtained from in-silico trials would also yield
similar discoveries and conclusions in realistic clinical settings.
3 Discussion
In this study, we innovatively emphasize the critical necessity for rigorous and
cost-effective evaluation methodologies for AI models in clinical practice, featuring
patient/clinician-centered (dual-centered) AI randomized controlled trials (DC-AI
RCTs) and virtual clinician-based in-silico trials (VC-MedAI). We perform the first
rigorous and comprehensive DC-AI RCTs across 14 medical centers involving 125
clinicians. Phase #1 using three models constitutes the basis for VC-MedAI, further
confirming the necessity of a rigorous approach and DC-AI RCTs. Phase #2 using a
newAImodelprovidesprospectivetrialsforevaluatingVC-MedAI,verifyingitseffec-
tiveness as a substitute for DC-AI RCTs and as a preclinical-like process mirroring
conventional medicine.
Conventional clinical trials mainly regard patient as main subjects and adopt
patient-centered trials including experimental or control groups to assess new tech-
niques, device, or drugs [29–32]. In contrast, AI models in clinical practice relies on
clinician-in-the-loop mechanism and the patients are no longer the solely subjects.
DespitenumerousproposalsforAIsoftwareanddevicesinclinicalpractice[24,33,34],
nonehaveconductedDC-AIRCTs.Accordingtoasurvey[9]in2022,only39(0.33%)
outof11,839articleshaveconductedRCTs.Amongthese,92%(36/39)comparedAI-
assistedtoolstocontrolsusingstandardcare,while5%(2/39)usedashamtreatment
without AI assistance as a control [9], all overlooking clinician synergy. In this condi-
tion,itischallengingtodeterminetheextentoftheAIsoftware’simpactandwhether
it has a positive effect, no matter from the accuracy, diagnosis time, or cost perspec-
tive. Our study addresses this deficiency and offers the first rapid and cost-effective
alternative for AI model evaluations in clinical practice.
13The limitation of the study is as follows. VC-MedAI reflects a deviation around
25% considering average length of operation sequences and diagnosis time, compared
to prospective Phase #2 DC-AI RCTs. We will improve its quality through more
clinical trials. Notably, these deviations have little impact on the clinical outcomes
according to our results.
Clinical outcome is of paramount importance in clinical practice. We highlight
DC-AI RCTs – introducing hybrid blinding types and clinician controls – are cru-
cial for shielding confounding factors and uncovering genuine impacts of AI software
or device on clinical outcome. For instance, evaluating an AI model solely against a
no-model control in hospitals might suggest it enhances diagnosis accuracy, sensitiv-
ity,andspecificity.However,comparingitwithaninvisiblerandommodelmayreveal
even a random model can improve clinical outcomes to some extent, whereas the AI
model shows minimal, if any, enhancing effect. Thus, the conclusion shifts, indicating
the AI model has little to no impact on clinical outcomes. Meanwhile, as an effective
proxy of DC-AI RCTs, VC-MedAI remains consistency with real-world clinical trials
in terms of a primary clinical phenomena – time reduction for early detection that
closely linked to the use of antibiotics – related to outcomes [24–28]. From a clinical
perspective, AI software and device assessments need to center on clinicians and be
grounded in DC-AI RCTs, reshaping evaluation methodologies and pioneering inno-
vative directions. In terms of AI development, it’s crucial that AI models not only
enhance the quality and performance but also prioritize interaction with clinicians
to bolster their acceptance. Meanwhile, AI development should account for regional
variations and clinician demographics to enhance clinical applicability and accelerate
progress in clinical practice. We anticipate our evaluation methodology and tool will
accelerate and enhance the assessment of AI effects beneficially.
4 Methods
The design of DC-AI RCTs. We conduct DC-AI RCTs across 14 medical centers
with 125 clinicians. The patient cohort is well chosen from MIMIC [35–38] datasets.
The AI models include state-of-the-art/practice algorithms – the survival analysis
based cox proportional hazards model (CoxPHM) model [24, 39] and deep learning
based long short term memory (LSTM) model [33], specifically, low-quality (AUC
0.75), medium-quality (AUC 0.85), high-quality (AUC 0.95) LSTM-based models, a
high-quality (AUC 0.95) CoxPHM-based model, and a random model (AUC 0.5) as
control. We category the patients into five groups randomly. In Phase #1, the first
group is diagnosed by clinicians without and with the above random or LSTM-based
models, having no idea about the model properties. In total, group #1 contains five
settings. For comparison, patient group #2 to #4 are diagnosed with the assistance
of three LSTM-based AI models and the clinicians are aware of the model properties.
Intotal,Phase#1containseightsettings.InPhase2,anewCoxPHM-basedmodelis
employed to assist the diagnosis of patient group #1 and group #5, with the model’s
propertiesbeinginvisibletocliniciansforgroup#1andvisibleforgroup#5.Tounveil
clinician’sbehaviorsandtheirintricateinteractionswithAI,everyclinicianisassigned
14partial patient cases randomly within each clinical setting. A companion paper about
data descriptors illustrates the collected records [40].
The design and implementation of VC-MedAI Clinician Generator.Givena
user-defined number of virtual clinicians, the generator performs two-stage samplings
according to real-world human clinician populations, as shown in Fig. 5. First, to
ensure the rationality of clinician features, e.g., avoiding mismatches in age, position,
andexperience,thegeneratorsamplestheclassofpositionandmaintainsapopulation
listforeachcategory,namely,none,junior,intermediate,andsenior.Second,thegen-
erator performs stratified sampling and samples the other features like age according
to population lists.
The design and implementation of VC-MedAI behavior simulator. Fig. 5
presents the construction of VC-MedAI, including two-stage (preliminary and final)
diagnosis simulations. This aligns with real-world medical diagnosis, as clinicians
typically rely on the fundamental items and history examination data to make a pre-
liminary diagnose, while also requiring additional advanced examination items for a
final decision. We train VC-MedAI specialized simulators based on Phase #1 DC-AI
RCTsasfollows:(1)featureinputsfromclinician,AImodels,andpatientperspectives.
(2)featureembeddingreferringtotheHAIMframework [41–44].(3)dimensionreduc-
tionadoptingprincipalcomponentsanalysis(PCA)[45]onpatientfeaturestoprevent
the clinician and AI model features from being overshadowed. After that, the number
is 17, equal to the sum of clinician and AI model dimensions. (4) stratified sampling
to divide a training, validating, and testing set with 7:2:1. (5) preliminary and final
decision model training using 5-fold cross-validation. We use XGBClassifier [46] and
XGBRegressor [46] for the simulation of diagnosis decisions and time, respectively.
The hyperparameters are automatically optimized using Optuna [47]. We use trans-
formermodel[48]andXGBClassifierforthebehaviorsimulationofclicksequenceand
item ratio, respectively. The current advanced examination data are excluded for the
preliminary simulation while included for final one. VC-MedAI generalized simulator
follows similar steps but focuses solely on clinician and AI model features, excluding
patient-related steps. Performance on testdata from Phase #1 DC-AI RCTs are in
Appendix Fig. B1 and Tables B7-B12.
Acknowledgements. We acknowledge supports from the Innovation Funding of
ICT, CAS under Grant No. E461070.
Declarations
Competing interests
The authors declare no conflicts of interest and no competing interests.
Ethics statement
15Clinical Human Clinician Behaviors VC-MedAI Generator
Trials Patient case ID and diagnosis order with or without AI model
( DP Ch -a Ase I R#1 CTs) Preliminary Decision Final Decision All operations & timestamp User-defined number of virtual clinicians (N)
institution level model type Demographic: CT scan Class of Position Sampling
sex visibility sex MRI scan None Junior Intermediate Senior
a dg epe artment p 0r he /3d hic t pi ro on b r ae bs iu lil tt y a mg ae rital status Text U X-l rtr aa ysound N1 N2 N3 N4
y ce laa sr ss oo ff pw oo sr itk ii on ng m seo nd se itl i vq iu tyality r Ta imce e-series: Population List 1 Population List 2 Population List 3 Population List 4
area of expertise specificity body temperature
diagnosis order accuracy systolic blood pressure
AUC diastolic blood pressure Stratified Sampling
F Ine pa utu tsre h r c qe oe Ssa n Opr si Ft cr Aiar oa t uote sr ny e r sa st e level ChI em sta Xge -r: a y years os fe wx orking institua tig oe n level ared ae op fa r et xm pe en rtt ise
complete blood count (26)
arterial blood gas analysis (24)
haemostatic function (5) N virtual clinicians (similar with real-world population)
Clinician Features AI Model Features Patient Features
C1 C2 … C8 M1 M2 … M9 P1…P4 P5…P66 P67 P68 VC-MedAI Simulator
8 dimensions 9 dimensions Demographic Time series TextImage Specialized Generalized
Clinician, AI Model, and Patient Features Clinician and AI (current fu hn id sa tom re yn et xa al mex ia nm ati in oa nt i do an t ad )ata and all Model Features
Optuna Optuna Optuna
Transformer &XGB &XGB &XGB
Classifier Regressor Classifier
C1 C2 … C8 M1 M2 … M9 P1…P4 tsfresh BioBertTorch
Feature XRay Click Preliminary Preliminary Item ratio
Embedding Vectorization Vectorization Vectorization Vision Sequence Diagnosis Time to be tested
4D 660D 768D 1042D
2474 Patient Feature Dimensions Clinician, AI Model, and Patient Features Clinician and AI
PCA (All fundam ee xn at mal i, n a ad tiv oa nn dc aed ta, )and history Model Features
D Ri em duen cts ii oo nn Cli dn ii mci ea nn s f ioea nt sure M do imde el n f se ia ot nu sre Patient feature dimensions O &p Xtu Gn Ba O &p Xtu Gn Ba Classifier Regressor
S St ar mat pif lii ned g Training Set Validating Set Testing Set DiF agin na ol s is Final Time
Fig. 5 The Design and Implementation of VC-MedAI. Based on Phase #1 DC-AI RCTs,
VC-MedAIidentifiesaseriesoffeaturesintermsofclinician,AImodel,andpatientproperties.The
VC-MedAIgeneratorgeneratesuser-definednumberofvirtualcliniciansandreflectsimilarfeatures
withreal-worldhumanclinicianpopulation.VC-MedAIsimulatorreceivesfeatureinputandsimulates
theoperationbehaviors,diagnosisdecision,andtimeconsumptionduringpreliminarydiagnosisstage,
andoutputsthefinaldiagnosisandtimeconsumptionduringfinaldiagnosisstage.
This research has been approved by the Ethics Committee of Guilin Medical Uni-
versity (Approval No:GLMC20221101). All the participated clinicians have assigned
the informed consent. The patient data used in this database are sourced from the
publicly available MIMIC dataset, which the authors have received permission to use,
ensuring that no new ethical issues are involved.
Consent for publication
All authors have read and approved the final manuscript.
Data availability
The diagnosis records collected from our two-phase DC-AI RCTs have been orga-
nized into a series of CSV (comma-separated values) files and described in a
companion paper about data descriptors [40]. The database is publicly available
from PhysioNet (waiting for approval) and International Open Benchmark Council
16
noitadilav-ssorc
dlof-5
sisongaiD
yranimilerP
sisongaiD
laniF(https://www.benchcouncil.org/ai.vs.clinician/).
Code availability
The VC-MedAI related code is publicly available from https://github.com/BenchCo
uncil/VC-MedAI/.
Author contribution
W.G. conceptualized this study, formulated the designs, conceived the experiments,
and wrote the manuscript. D.C., Z.Y., W.L., X,L., J.Z., J.X., and H.L. implemented
the algorithms, collected and analyzed the data. L.M., N.Y., Y.K., D.L., P.P., W.H.,
Z.L., J.H., G.Z., C.J., F.H., T.W., and S.T. analyzed the data. B.X., Z.Z., Y.H., and
J.Z. conceptualized this study, directed the project, and revised the manuscript. All
authors have read and approved the final manuscript.
References
[1] Rajpurkar, P., Chen, E., Banerjee, O., Topol, E.J.: Ai in health and medicine.
Nature medicine 28(1), 31–38 (2022)
[2] Briganti, G., Le Moine, O.: Artificial intelligence in medicine: today and tomor-
row. Frontiers in medicine 7, 509744 (2020)
[3] Holmes, J., Sacchi, L., Bellazzi, R., Peek, N.: Artificial intelligence in medicine.
Ann R Coll Surg Engl 86, 334–8 (2004)
[4] Topol, E.J.: High-performance medicine: the convergence of human and artificial
intelligence. Nature medicine 25(1), 44–56 (2019)
[5] Sibbald, B., Roland, M.: Understanding controlled trials. why are randomised
controlledtrialsimportant?BMJ:BritishMedicalJournal 316(7126),201(1998)
[6] Akobeng, A.K.: Understanding randomised controlled trials. Archives of disease
in childhood 90(8), 840–844 (2005)
[7] Ye, T., et al.: Psychosocial factors affecting artificial intelligence adoption in
health care in china: Cross-sectional study. Journal of medical Internet research
21(10), 14316 (2019)
[8] Yun, J.H., Lee, E.-J., Kim, D.H.: Behavioral and neural evidence on consumer
responses to human doctors and medical artificial intelligence. Psychology &
Marketing 38(4), 610–625 (2021)
[9] Lam, T.Y., et al.: Randomized controlled trials of artificial intelligence in clinical
practice: systematic review. Journal of Medical Internet Research 24(8), 37188
(2022)
17[10] Angus, D.C.: Randomized clinical trials of artificial intelligence. Jama 323(11),
1043–1045 (2020)
[11] Abr`amoff, M.D., Lavin, P.T., Birch, M., Shah, N., Folk, J.C.: Pivotal trial of an
autonomous ai-based diagnostic system for detection of diabetic retinopathy in
primary care offices. NPJ digital medicine 1(1), 39 (2018)
[12] US Food and Drug Administration. FDA permits marketing of clinical decision
support software for alerting providers of a potential stroke in patients. https:
//www.fda.gov/news-events/press-announcements/fda-permits-marketing-cli
nical-decision-support-software-alerting-providers-potential-stroke (Published
February 13, 2018. Accessed June 17 2024)
[13] Martin, L., Hutchens, M., Hawkins, C., Radnov, A.: How much do clinical trials
cost. Nature Reviews Drug Discovery 16(6), 381–382 (2017)
[14] Wiens, J., et al.: Do no harm: a roadmap for responsible machine learning for
health care. Nature medicine 25(9), 1337–1340 (2019)
[15] Battelino, T., et al.: Guidelinedevelopmentfor medical device technology: Issues
for consideration. Journal of Diabetes Science and Technology 17(6), 1698–1710
(2023)
[16] Mayr, F.B., Yende, S., Angus, D.C.: Epidemiology of severe sepsis. Virulence
5(1), 4–11 (2014)
[17] Rudd, K.E., et al.: Global, regional, and national sepsis incidence and mor-
tality, 1990–2017: analysis for the global burden of disease study. The Lancet
395(10219), 200–211 (2020)
[18] Sarrami-Foroushani, A., et al.: In-silico trial of intracranial flow diverters repli-
cates and expands insights from conventional clinical trials. Nature communica-
tions 12(1), 3861 (2021)
[19] Viceconti, M., Henney, A., Morley-Fletcher, E.: In silico clinical trials: how com-
putersimulationwilltransformthebiomedicalindustry.International Journal of
Clinical Trials 3(2), 37–46 (2016)
[20] Pappalardo, F., Russo, G., Tshinanu, F.M., Viceconti, M.: In silico clinical tri-
als: concepts and early adoptions. Briefings in bioinformatics 20(5), 1699–1708
(2019)
[21] Clermont, G., et al.: In silico design of clinical trials: a method coming of age.
Critical care medicine 32(10), 2061–2070 (2004)
[22] Zhan, J., et al.: Evaluatology: The science and engineering of evaluation. Bench-
Council Transactions on Benchmarks, Standards and Evaluations 4(1), 100162
18(2024)
[23] Knight,J.C.:Safetycriticalsystems:challengesanddirections.In:Proceedingsof
the 24th International Conference on Software Engineering, pp. 547–550 (2002)
[24] Henry, K.E., et al.: Factors driving provider adoption of the trews machine
learning-based early warning system and its effects on sepsis treatment timing.
Nature medicine 28(7), 1447–1454 (2022)
[25] Liu, V.X., et al.: The timing of early antibiotics and hospital mortality in sep-
sis. American journal of respiratory and critical care medicine 196(7), 856–863
(2017)
[26] Singer, M., et al.: The third international consensus definitions for sepsis and
septic shock (sepsis-3). Jama 315(8), 801–810 (2016)
[27] Dellinger, R.P., et al.: Surviving sepsis campaign: international guidelines for
managementofseveresepsisandsepticshock:2012.Criticalcaremedicine 41(2),
580–637 (2013)
[28] Husabø, G., et al.: Early diagnosis of sepsis in emergency departments, time to
treatment, and association with mortality: an observational study. PLoS One
15(1), 0227652 (2020)
[29] Friedman, L.M., Furberg, C.D., DeMets, D.L., Reboussin, D.M., Granger, C.B.:
Fundamentals of Clinical Trials. Springer, Switzerland (2015)
[30] Piantadosi, S.: Clinical Trials: a Methodologic Perspective. John Wiley & Sons,
New Jersey (2024)
[31] Phillips, K.A., et al.: Why primate models matter. American journal of prima-
tology 76(9), 801–827 (2014)
[32] Pouladi, M.A., Morton, A.J., Hayden, M.R.: Choosing an animal model for the
study of huntington’s disease. Nature Reviews Neuroscience 14(10), 708–721
(2013)
[33] Kaji, D.A., et al.: An attention based deep learning model of clinical events in
the intensive care unit. PloS one 14(2), 0211057 (2019)
[34] FDA permits marketing of artificial intelligence-based device to detect certain
diabetes-related eye problems. Food and Drug Administration (2018)
[35] Johnson,A.E.,etal.:Mimic-iii,afreelyaccessiblecriticalcaredatabase.Scientific
data 3(1), 1–9 (2016)
[36] Johnson,A.E.,etal.:Mimic-iv.PhysioNet.Availableonlineat:https://physionet.
org/content/mimiciv/1.0/(accessed June 17, 2024) (2020)
19[37] Johnson,A.E.,etal.:Mimic-cxr-jpg,alargepubliclyavailabledatabaseoflabeled
chest radiographs. arXiv preprint arXiv:1901.07042 (2019)
[38] Johnson, A.E., Pollard, T., Horng, S., Celi, L.A., Mark, R.: MIMIC-IV-Note:
Deidentified free-text clinical notes. PhysioNet (2023)
[39] Henry, K.E., Hager, D.N., Pronovost, P.J., Saria, S.: A targeted real-time early
warningscore(trewscore)forsepticshock.Sciencetranslationalmedicine 7(299),
299–122299122 (2015)
[40] Gao, W., et al.: Ai. vs. clinician: Unveiling intricate interactions between ai and
clinicians through an open-access database. arXiv e-prints, 2406 (2024)
[41] Soenksen, L.R., et al.: Integrated multimodal artificial intelligence framework for
healthcare applications. NPJ digital medicine 5(1), 149 (2022)
[42] Christ, M., Braun, N., Neuffer, J., Kempa-Liehr, A.W.: Time series feature
extraction on basis of scalable hypothesis tests (tsfresh–a python package).
Neurocomputing 307, 72–77 (2018)
[43] Lee, J., et al.: Biobert: a pre-trained biomedical language representation model
for biomedical text mining. Bioinformatics 36(4), 1234–1240 (2020)
[44] Cohen,J.P.,et al.:Torchxrayvision:Alibraryofchestx-raydatasetsandmodels.
In:InternationalConferenceonMedicalImagingwithDeepLearning,pp.231–249
(2022). PMLR
[45] Ma´ckiewicz, A., Ratajczak, W.: Principal components analysis (pca). Computers
& Geosciences 19(3), 303–342 (1993)
[46] Chen,T.,Guestrin,C.:Xgboost:Ascalabletreeboostingsystem.In:Proceedings
of the 22nd Acm Sigkdd International Conference on Knowledge Discovery and
Data Mining, pp. 785–794 (2016)
[47] Akiba, T., Sano, S., Yanase, T., Ohta, T., Koyama, M.: Optuna: A next-
generation hyperparameter optimization framework. In: Proceedings of the 25th
ACM SIGKDD International Conference on Knowledge Discovery & Data
Mining, pp. 2623–2631 (2019)
[48] Vaswani, A., et al.: Attention is all you need. Advances in neural information
processing systems 30 (2017)
[49] Swift,A.,Heale,R.,Twycross,A.:Whataresensitivityandspecificity?Evidence-
Based Nursing 23(1), 2–4 (2020)
20Appendix A Supplementary Methods
10 patient-centered and clinician-centered (dual-centered) clinical settings.
The DC-AI RCTs are conducted across 14 medical centers collaborated with 125
human clinicians. The patient cases are classified into five groups randomly. The 10
clinical settings are as follows:
• ThepatientcasesofGroup#1arediagnosedbyhumanclinicianswithandwithout
theAImodelassistance.HumanclinicianscanonlyseeinferenceresultsofAImodels
while having no idea about the model characteristics like model name and model
quality on testdata.
– (1) diagnose without AI model assistance.
– (2) diagnose with a random model (control group with AUC 0.5).
– (3) diagnose with a LSTM-based low-quality (AUC 0.75) model.
– (4) diagnose with a LSTM-based medium-quality (AUC 0.85) model.
– (5) diagnose with a LSTM-based high-quality (AUC 0.95) model.
– (6)diagnosewithaCoxPHM-basedhigh-quality(AUC0.95)model.[Phase #2]
• For the other four patient groups, human clinicians make diagnosis decisions while
being aware of the AI model’s name and qualities.
– (7) The patient cases of Group #2 are diagnosed by human clinicians with the
assistance of a LSTM-based low-quality (AUC 0.75) model.
– (8) The patient cases of Group #3 are diagnosed by human clinicians with the
assistance of a LSTM-based medium-quality (AUC 0.85) model.
– (9) The patient cases of Group #4 are diagnosed by human clinicians with the
assistance of a LSTM-based high-quality (AUC 0.95) model.
– (10) The patient cases of Group #5 are diagnosed by human clinicians with the
assistance of a CoxPHM-based high-quality (AUC 0.95) model. [Phase #2]
The patient cases within each experimental and control groups are randomly allo-
cated to clinicians. Each clinician is allocated with six patient cases randomly from
every clinical setting. The total diagnosis records is 7500 (125 clinicians * 6 patient
cases * 10 settings).
The features used in VC-MedAI.
(1) The clinician features contain eight dimensions.
• institution level reflectsthehospitalratingsontheoverallqualityandperformance.
We have three rating categories including A, B, and C.
• sex indicates whether a clinician is male or female.
• age indicates the age of a clinician.
• years of working refers to the number of years a clinician has been employed or
actively working in a hospital.
• department refers to specific divisions or units within a hospital that focus on pro-
viding specialized medical care and services like emergency department. We have
14 department categories.
21• class of position represents the professional title of a clinician including chief
physician, associate chief physician, attending physician, resident physician, junior
physician.
• area of expertise refers to a specific field or subfield where a clinician has acquired
specialized skills and extensive experience.
• diagnosis order indicates the clinician is diagnosing the nth patient in a particular
setting like using or not using an AI model for assistance. We include this feature
consideringtheordermayinfluencepsychologicalfactorssuchastheclinician’strust
in the AI model.
(2) The AI model features include nine dimensions.
• modeltype indicatesthetechniqueofthemodelsuchastraditionalmachinelearning
and deep learning. We also introduce a random-based model type.
• model quality defines the quality range of a model. Specifically, 1 indicates an AUC
rangingfrom0to0.6,while2signifiesanAUCspanning0.6to0.7.Movingforward,
3 represents an AUC falling between 0.7 and 0.8. Next, 4 denotes an AUC between
0.8 and 0.9, and finally, 5 represents an exceptional AUC ranging from 0.9 to 1.
• sensitivity measures how well a model can identify patients with sepsis [49].
• specificity measures how well a model can identify people without sepsis [49].
• accuracy measureshowwellamodel’spredictionsalignwiththeactualorexpected
outcomes.
• AUC (Area Under the Curve) provides a concise measure of the model’s perfor-
mance, with higher values indicating better classification ability.
• visibility indicateswhetherthemodelcharacteristicsarevisibletotheclinician,like
the model type and quality.
• predictionresult indicatesthediagnosisconclusionofamodel.Thepredictionresults
are divided into three categories: sepsis, sepsis alert within 3 hours, and non-sepsis.
Note that the 3-hour window aligns with the recommendations and guidelines on
sepsis [24, 26].
• 0h/3h probability depicts the probability of the sepsis onset at present (0h) and the
sepsisonsetwithinthenextthreehours(3h),respectively.Notethatweuseboth0h
and 3h probability as features for VC-MedAI specialized simulator. For VC-MedAI
generalized simulation, we provide separate simulators for 0h and 3h, considering
that different diseases may involve different recommendations and guidelines on
timewindows.ThedataofgeneralizedsimulatorillustratedinResultssectionderive
from the VC-MedAI generalized simulator for 0h. The data from the VC-MedAI
generalized simulator for 3h is supplemented in Appendix B, with Table B3-B6
showing the performance on a new AI model from Phase #2 DC-AI RCTs, Table
B8-B12 showing the performance on testdata from Phase #1 DC-AI RCTs, and
Table B13-B16 showing the performance on in-silico trials with 125 new virtual
clinicians and 7500 virtual diagnosis records.
(3) The patient features consist of demographic information, time-series data, text,
and images.
• Demographic information includes the sex, age, marital status, and race.
22• Time-seriesexaminationitems includetime-seriesfundamentalitemsandadvanced
items. The included fundamental items are body temperature, systolic blood pres-
sure, diastolic blood pressure, heart rate, respiratory rate, consciousness level, and
qSOFA. The included advanced items are complete blood count (26 dimensions),
arterial blood gas analysis (24 dimensions), haemostatic function (5 dimensions).
• Text data includes the text notes of CT scans, MRI scans, ultrasound, and X-ray
data.
• Image data includes the chest X-ray images.
Feature embedding. For the time-series examination data, we construct a time-
feature matrix and use tsfresh to generate a 660-dimensional embeddings for each
patient.Forthetextdata,weuseBioBerttogeneratea768-dimensionalembeddings.
For the image data, we use TorchXRayVision to generate a 1042-dimensional embed-
dings.Afterthat,theclinicianfeatureshaveeightdimensions.AImodelfeatureshave
nine dimensions. The patient features have 2474 dimensions.
Data validation. Among 6000 diagnosis records from Phase #1 DC-AI RCTs, we
filter the valid data for model training. For example, the records with the incomplete
diagnosisorincompleteclinicianinformationareremoved.Afterthefiltering,thetotal
validrecordsareabout5500.Inaddition,wefilterthediagnosisrecordwithtooshort
or too long diagnosis time, resulting in approximately 4800 records and 4900 records
for preliminary and final diagnosis, respectively.
23