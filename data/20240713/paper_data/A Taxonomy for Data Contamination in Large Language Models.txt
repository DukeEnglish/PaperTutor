A Taxonomy for Data Contamination in Large Language Models
MedhaPalavalli and AmandaBertsch and MatthewR.Gormley
SchoolofComputerScience
CarnegieMellonUniversity
[mpalaval, abertsch, mgormley]@cs.cmu.edu
Abstract (Dodgeetal.,2021;Raffeletal.,2020;Brownetal.,
2020),raisingseriousconcernsaboutthevalidity
Largelanguagemodelspretrainedonextensive
of evaluation scores for many pretrained models
web corpora demonstrate remarkable perfor-
(Leeetal.,2022;Changetal.,2023b).
manceacrossawiderangeofdownstreamtasks.
However,agrowingconcernisdatacontami- The research community lacks consensus on
nation,whereevaluationdatasetsmaybecon- best practices for data contamination, and differ-
tainedinthepretrainingcorpus,inflatingmodel ent works define contamination in subtly differ-
performance. Decontamination,theprocessof ent ways. Without standardization of terminol-
detectingandremovingsuchdata,isapotential
ogy, it is difficult to develop best practices for
solution;yetthesecontaminantsmayoriginate
contamination–oreventocharacterizetheproblem
fromalteredversionsofthetestset,evadingde-
atall. Toaddressthisgap,wesuggestaformaldef-
tectionduringdecontamination. Howdifferent
typesofcontaminationimpacttheperformance initionofcontaminationandtaxonomizesubtypes
oflanguagemodelsondownstreamtasksisnot ofcontamination(§2). Wemappriorworkonboth
fullyunderstood. Wepresentataxonomythat thedetectionandimpactofcontaminationintothis
categorizesthevarioustypesofcontamination taxonomy,revealingseveralunderstudiedformsof
encountered by LLMs during the pretraining
contamination(§2.3). Wealsomeasuretheimpact
phaseandidentifywhichtypesposethehighest
ofdifferenttypesofcontaminationondownstream
risk. Weanalyzetheimpactofcontamination
summarization (§ 4) and QA (§ 5) performance
on two key NLP tasks—summarization and
throughcontinuedpretrainingexperimentsassess-
questionanswering—revealinghowdifferent
types of contamination influence task perfor- ingindirect/approximatetestsetcontaminationef-
manceduringevaluation. fects.
Our findings reveal that for GPT-2 Large mod-
1 Introduction
els,itisoftenthecasethathavingin-domaindata
Advancementsinmachinelearninghavetradition- present during training is as beneficial as having
allyreliedonbenchmarkdatasetstoevaluateand thetestdatapresentduringtraining. Moreover,we
comparemodelperformance(Rajietal.,2021;Gu- observe that certain contamination types exhibit
ruraja et al., 2023). With the surge of large lan- task-dependenteffectsonevaluationperformance,
guagemodels(LLMs)inrecentyears,thesebench- further complicating decontamination best prac-
marksarenowleveragedtoshowcaseremarkable tices. Our findings enable recommendations for
abilitiesacrossdiversetasks. identifyingandmitigatingproblematiccontamina-
However,theshelflifeofbenchmarksisincred- tion during LLM development to ensure reliable
ibly low, with Roberts et al. (2023) demonstrat- evaluations(§7).
ingthatnewermodelswithupdatedtrainingcutoff
datesareiterativelyrenderingexistingbenchmarks 2 Taxonomy
stale. Thepresenceofinternet-sourceddatainboth
pretraining and evaluation datasets increases the ConsideramodelM : X → Y which,givenanin-
riskofdatacontamination(Brownetal.,2020;Ma- putofsometypex ∈ X,outputstexty ∈ Y. While
(cid:98)
garandSchwartz,2022)andchallengesthenotion xcanbeofanyformat,wewillrestrictourselves
offairevaluationformodelspretrainedonmassive tocaseswherey isinthespaceofthenaturallan-
(cid:98)
corpora. BothGPT-3andC4trainingcorporawere guage(Y ⊆ Σ∗ forsomealphabetinΣ). LetD be
foundtocontaintestdataforseveralbenchmarks thetestset,consistingof|D|examples⟨x ,y ⟩.
i (cid:98)i
4202
luJ
11
]LC.sc[
1v61780.7042:viXraAugmenting Karmakaretal.(2022)
InstanceLevel
Contamination Noising Yangetal.(2023)
(§2.1.2)
Masking Karmakaretal.(2022)
DatasetLevel Distribution Jiangetal.(2024)
Contamination
(§2.1.1) Jiangetal.(2024);Zhangetal.(2023);Caoetal.
Selection
(2024);Sainzetal.(2023b);LiandFlanigan(2023)
LanguageUnderstanding
()
(§2.2.1)
PriorTaskUnderstanding
LiandFlanigan(2023);Sainzetal.(2023a)
(§2.2.2)
TransductiveLearning
Jiangetal.(2024);Ouchietal.(2019);Sainzetal.(2023a)
(§2.2.3)
Figure1: TaxonomyofContamination,withsomerepresentativeworksintheliteraturethataddresseachcategory.
2.1 Contamination batim contamination refers to when g is the
identityfunction.
Wedefinecontaminationasanyleakageofinfor-
mationthatprovidesasignalforthecorrectlabel
• Distribution: Afunctionwhichcombinesthe
foratleastoneexampleinthetestsetD. Whencon-
contaminated data D with some additional,
taminationoccurs,somesubsetofthepretraining
non-contaminatingdocuments,suchthatthe
datacanbecharacterizedastheresultofafunction
examplesfromD arenotallsequentialinthe
f(D),whichmaybeacompositionofmultiplecon-
pretrainingdata. Thiscanoccurduringdata
tamination functions f = f(1) ◦f(2) ◦···◦f(n).
shuffling,orifthecontaminationcomesfrom
We characterize types of contamination by their
multiple documents. Practically, this means
dataset-level(§2.1.1)andexample-level(§2.1.2)
thatthecontaminatedregionofthepretraining
properties. Figure 1 provides an overview of our
datag(D)spansmoretokens.
taxonomy.
2.1.2 Instance-levelProperties
2.1.1 Dataset-levelProperties
Ininstance-levelcontamination,thefunctionf ap-
For dataset-level contamination, consider a func- plies some function h to each individual leaked
tiong thatleavestheindividualexamples⟨x i,y (cid:98)i⟩ example f(D) = {h(⟨x ,y ⟩)}|D| .1 A few rep-
i (cid:98)i i=1
intact. Inthesimplestcase,g istheidentityfunc-
resentativeexamplesinthisclassareenumerated
tion;thisistheleakageofafulltestset,e.g. from
below:
scrapingafilecontainingthetestsetinstancesand
labels. Thefollowingaretypesoffunctionsg(D) • Masking: A function that removes some or
cantakeon. all ofthe input(can be donein combination
with the output), e.g. h(⟨x ,y ⟩) = y or re-
i (cid:98)i (cid:98)i
• Selection: Afunctionthatselectssomegroup movingallincorrectanswerchoicesinamul-
ofexamplesD′ ⊂ D,suchthatonlyasubset tiplechoicequestion. Thisprimarilyqualifies
ofthetestsetisleaked. Thisislikelywhenthe ascontaminationforgenerationtasks;fora
testdataisdrawnfromseveralsources,only classificationtask,leakingthelabel-spacein
someofwhichappearinthepretrainingdata; advance may not be a concern if the labels
whensomeofthetestdataismorerecentthan don’thaveinherentcontextualvaluewithout
otherdataandthepretrainingdatacontainsan theinput,suchasbinarylabelslike0sand1s
older snapshot of the contamination source; or positives and negatives. However, if the
orwhenthedataiscontainedinseveraldocu-
1Notethatthisisastrictsubsetofallfunctionsappliedto
mentsandthecleaningofthepretrainingdata
theleakeddataset,f(D);however,wedistinguishthissetof
onlyremovessomeofthesedocuments. Ver- functionsthatoperateonindividualexamples.
noitanimatnoC
noitanimatnoCtoNlabelscarrymeaningfulinformationontheir 2.2.2 PriorTaskUnderstanding
own,theirprematuredisclosurewouldindeed
We define prior task understanding as an ability
constitutecontamination. Notethatmasking
toperformatasklearnedfromnon-contamination
alloftheoutput,leavingonlytheinputsfrom
sources,andsuchpriorknowledgehasbeendemon-
thetestset,isgenerallyconsideredtobeatype
stratedtoboostmodelperformancewhenevaluated
of transductive learning, not contamination;
onunseeninstancesofsaidtask(LiandFlanigan,
see§2.2.3formorediscussion.
2023). Forinstance,fine-tuningamodelonatrain-
ing dataset for the task is clearly not contamina-
• Noising: Afunctionthatmodifiesthesurface
tionofthetestset,althoughitgenerallyimproves
form of the example, e.g. by paraphrasing
performanceonthattestset;likewise,pretraining
the inputs or outputs, by presenting the out-
onotherrelateddatasetsisnotcontaminationfor
putbeforetheinput,orbyusingsilverrather
a given test set. For closed-book QA and tasks
thangoldlabelsforeachexample. Notethat
requiringworldknowledge,priortaskunderstand-
this can also take the form of alternate cor-
ing from training data is essential. Closed-book
rectanswersbeingpresentinthepretraining
QAdemandsansweringwithoutexternalresources,
data: forinstance,inbooksummarization,a
relying solely on the model’s training on similar
differentsummaryofthebookbeingpresent
question-answerpairsorrelateddatasets.
inthepretrainingdataisstillcontamination.
In general, scrutinizing the training data’s
• Augmenting: Afunctionthataddsadditional sources and nature is crucial to maintain model
context,whichmayormaynotberelevantto integrity and generalizability. Prior task under-
the example. For instance, for a task where standingmayviolatetheassumptionof“zero-shot”
themodelmustansweranopen-endedques- performance: thatthemodelhasnotseentraining
tionattesttime,anaugmented contaminated dataforthattask.
example in pretraining would be a multiple-
choice test with the same questions. While 2.2.3 TransductiveLearning
thisprovidesthecorrectanswer,italsointro-
Transductivelearning(Vapnik,1998)incorporates
ducesnew(distractor)informationthatisnot
anunlabeledtestsetintotraining. Duringtraining,
presentattesttime. Anotherexamplewould
therawtextinputsofthetestsetcanbeused,but
beincludingadditionalcontextparagraphsfor
the labels are not seen. The model, once trained,
QA in addition to the necessary context and
is then evaluated on the same test set during the
answer. Notethedifferencebetweenexample-
testphase. TransductiveLMfine-tuninghasshown
level augmenting and dataset-level distribu-
toconsistentlyimproveneuralmodelsinbothin-
tion.
domain and out-of-domain settings (Ouchi et al.,
2019), although concerns have been raised about
2.2 Phenomenathataren’tContamination
blurring the line between training and evaluation
For clarity, we describe several phenomena
(Jiangetal.,2024).
that lead to improved performance on test sets
Wegenerallydonotconsiderpretrainingonthe
downstreambutarenotconsideredcontamination
inputsofthetestsettobecontamination,2although
underourtaxonomy.
wenotethatthiswilllikelyimproveperformance,
in the same manner than pretraining on training
2.2.1 LanguageUnderstanding settextimprovesdownstreamperformancebypro-
Pretrainingenablesmodelstoproduce(generally) viding some domain adaptation to the testing do-
fluent text and encodes some representation main(Gururanganetal.,2020;Krishnaetal.,2023).
of meaning for words commonly used in task Somepriorworkreferstothepresenceofinputs-
definitions; for instance, the model has some only in the pretraining data as contamination for
representationofmeaningforthelabels“positive” classificationtasks(Jiangetal.,2024;Ouchietal.,
and “negative” in sentiment analysis. While this 2019);however,underourtaxonomy,weconsider
representation is likely helpful for performing thisatypeoftransductivelearning.
downstream tasks (Min et al., 2022), this is not
2Akeyexceptionistaskswheretheinput/outputdistinction
inherentlycontamination.
does not apply, such as perplexity evaluation on a dataset
D={x ,...,x }ofsentencesx .
1 |D| i2.3 Mappingpriorworkexploring andmitigatecontamination. Thisiscomputation-
contaminationintothistaxonomy allycostlybutcanidentifynoisycontamination
Methods without access to pretraining data
Theeffectsofselectionhavebeenexploredbyex-
Someapproachesarecapableofdetectingcontam-
periments that compare LLM performance over
ination without direct access to pretraining data,
time (Li and Flanigan, 2023; Cao et al., 2024),
but assume that the test data has not been mod-
promptingthemodeltogeneratesamplesfromspe-
ified or distributed across the pretraining corpus.
cificdatasetsplits(Sainzetal.,2023b),andtrain-
Thesemethodsleveragemetadatafromthedataset
ingLLMsthatselectsomesubsetofanevaluation
todetectcontamination,e.g. byleveragingdataset
dataset(Zhangetal.,2023;Jiangetal.,2024).
ordering(Sainzetal.,2023b)ortheassignmentof
Jiang et al. (2024) also explores the effects of
examplestospecificdatasplits(GolchinandSur-
thefrequencyinwhichcontaminateddataappears
deanu,2023). GolchinandSurdeanu(2024)intro-
distributed throughoutthepretrainingdata.
ducetheDataContaminationQuiz,astreamlined
Through zero-shot experimentation on the
method that efficiently detects and estimates ver-
Codexmodel(Chenetal.,2021),Karmakaretal.
batimcontaminationinLLMsbycraftingmultiple
(2022) investigates the effects of prompts mask-
choicequestionsthatpromptamodeltocorrectly
ingoutinputspecificationsandpromptswithaug-
dataset-specific content among similar but noisy
mented objectives. Additionally,Yangetal.(2023)
alternatives.
showcasesmemorizationofevaluationsamplesby
Chang et al. (2023a) detect contamination of
promptingLLMswithnoisysamples.
books(whichserveasinputsformanylong-context
Apriorpositionpaper(Sainzetal.,2023a)de-
evaluationdatasets)usingdomainspecificfeatures–
finedthreecategoriesofdatacontamination: their
anameclozetestandapublication-yearevaluation.
guidelinecontaminationfallsunderourdefinition
Thisispowerfulfordetectingthepresenceofthe
ofpriortaskunderstanding;theirrawtextcontami-
exacttextofthebook,butitsefficacyondetecting
nationistranductivelearning;andtheirannotation
relatedartifacts(e.g. summariesofthebook,which
contaminationequatestoourdefinitionofdatacon-
mayserveastestsetoutputs)isunknown.
taminationin§2.1. Ourworkfurthercategorizes
Shi et al. (2023) introduces a new detection
andexplorestypesofannotationcontamination.
methodMIN-K%PROB,whichiscapableofde-
tectingwhetherapieceoftextwasinthepretrain-
2.4 DetectingDataContamination
ing corpora by leveraging the variability of the
Methods with access to pretraining data Early
tokens’probabilitiesaccordingtothemodel. This
researchonLLMdatacontaminationprimarilyem-
has the potential to detect distributed or masked
ployed methods akin to high-order n-gram over-
contamination,butisnotrobusttonoisingopera-
lap detection between pretraining and evaluation
tions,whichchangethetokensequence.
data (Radford et al., 2019a; Brown et al., 2020;
Most contemporary data-contamination detec-
Wei et al., 2021; Touvron et al., 2023). Tools for
tiontechniquesaredesignedtoidentifycontamina-
qualitative analysis on large-scale corpora (such
tionoffull,non-distributedtestdatasets,resulting
asDataPortraits(MaroneandDurme,2023)and
in a significant gap in detecting noisy or partial
theROOTSSearchTool(Piktusetal.,2023))have
contamination. The methods most well-adapted
furtherincreasedthepracticalityofthistypeofcon-
todetectnoisycontamination,whilepowerful,re-
taminationdetection. However,theseapproaches
quireaccesstopretrainingdataandexpensiveoper-
haveseverallimitations: theyremainfairlycompu-
ations;moreworkisnecessarytolowerthebarrier
tationallyexpensive,assumeaccesstopretraining
todetection.
data,andgenerallycanonlydetectcontamination
whenaclusterofseveraltestsetexamplesco-occur 3 Methodology
(asmostmethodsleveragedatasketching(Broder,
1997) tools that are only effective for sequences In all our experiments, we employ GPT-2 Large
aboveacertainlength). (Radfordetal.,2019b).3 Thiswillbereferredtoas
theinitialmodel. Sincethepretrainingcorpusfor
Yangetal.(2023)proposesanLLM-basedde-
GPT-2isnotpubliclyaccessible,thereisachance
contaminationmethod,whichleveragesembedding
similarity search followed by evaluation with a
3OurimplementationusesnanoGPT(Karpathy,2023)ini-
strong language model (e.g. GPT-4), to identify tializedwithOpenAI’sgpt2-largeweights.thattheselearned weightsofGPT-2mightbecon- 4 CaseStudy: Summarization
taminated. Consequently,theoutcomesofourex-
Forthiscasestudy,weusethefollowingsumma-
perimentsserveasaconservativeestimateorlower
rization datasets: XSum (Narayan et al., 2018),
boundontheeffectsofdatacontamination.
SAMSum (Gliwa et al., 2019), and CNN/Daily
For each of our datasets, we create
Mail(Nallapatietal.,2016). Weexplore5contam-
train/in-domain/test splits of equal size,
inationsettings:
aiming to establish a fair and comparable evalu-
ation environment. To disentangle the effects of 1. VERBATIM (dataset level, selection): f =
exposure to test data during pretraining from identityfunctionontestsplit
thoseofpriortaskunderstanding,weconstructed 2. DISTRIBUTION (dataset level, distribution):
an in-domain data split, allowing us to train f =shuffletestdatawithWebText
modelsontask-relevantbutuncontaminateddata 3. MASKED(instancelevel,masking): h =mask
for comparison against the various contaminated outinputdocumentsintestsplit
settings. Topartiallymitigatethepotentialrecency 4. NOISED(instancelevel,noising): h =swapin
bias from continued pretraining, we incorporate GPT-3.54 generatedsummariesontestsplit
an additional 10,000 samples of Open AI’s 5. REFORMATTED(instancelevel,noising): h =
WebText(Radfordetal.,2019b)intothecontinued swap format from document-summary to
pretrainingdata. summary-documentfortestdata
Duringcontinuedpretraining,weuseablocksize
Table5providesexamplesofeachsetting.
of1024tokenswithabatchsizeof1. Forfinetun-
ing, the training data is seen sample by sample. 4.1 Results
To obtain deterministic results during our experi-
Inthissection,weconsidertheoverallperformance
ments,wesetthetemperaturetozeroandcapped
ofeachcontaminationmethodacrosssummariza-
themaximumcompletionlengthat200tokens.
tion datasets. Figure 2 shows an example of the
results from one task and one metric (SAMSum,
3.1 TrainingSettings
ROUGE-L).SeeAppendixAforfullresultsonall
Weconsiderseveralsettingsforincorporatingdata: tasks and metrics, specifically Figures 4, 5, 6 or
Table3.
• ZERO-SHOT(notcontamination): promptthe
Consistently,the CHEATINGsettingoutperforms
allothers;thisisexpected,giventhatdeliberately
initialmodelwiththetestsampleandasimple
finetuningonthetestdataisanextremeformof
instructionforthetask.
contamination.
• BASELINE (notcontamination): finetuneini-
Overall,continuedpretrainingwiththeapprox-
tialmodelwithtrainsplit
imate contamination methods improves perfor-
• CHEATING(contaminationatfine-tuningtime,
rather than pre-training): finetune initial
manceabovethe BASELINEsetting,oftensubstan-
tially. Thissuggeststhatexposuretotheseforms
modelwithtestsplit
ofcontaminationduringpretrainingcanimpactthe
• Contamination Setting(s) (standard contam-
reliabilityofevaluationsonthisdatadownstream.
ination during pretraining): continued pre-
trainingwithf(testsplit)andfinetunewith
WhileVERBATIMsettingperformsslightlybet-
terthantheothercontaminationsettings, thisim-
trainsplit;thedetailsofeachcontamination
provementisn’tsignificantformostsettings. Note
settingarespecifictothetask(§4and§5)
that most contaminated settings outperform the
• In-Domain Setting(s) (not contamination):
baseline,andexistwithinastandarddeviationof
continued pretraining with f(in-domain
each other. This suggests that the performance
split)andfinetunewithtrainsplit—foreach
boost may simply be attributed to the increase
contaminationsettingin§4and§5,thereis
in in-domain data seen during the training stage
anassociatedin-domainmodel.
ratherthanencounteringthetestsplitduringcon-
tinuedpretraining.
Foreachsetting+dataset,weaverageresultsover
Notethatforthemostpart,theVERBATIM and
models trained on 3 random shuffles of the data.
INDOMAIN-VERBATIM settings perform on par
Standarddeviationsarecomputedoverthese3runs
anderrorbarsindicate±onestandarddeviation. 4gpt-3.5-turbo-0125withtemperature=0.51
28
2
3 4 5
6 7
26
In-Domain Contamination
24
BASELINE DISTRIBUTION MASKED NOISED REFORMATTED VERBATIM CHEATING
Figure2: BarChartofallSAMSummodelscomparedforRouge-L.
with each other. This trend seems to hold true choice QA with the Children’s Book Test (CBT)
fortheothercontaminationandin-domainmodel (Hill et al., 2016). We explore 6 contamination
pairs. The comparable performance further sug- settings:
geststhatexposuretocontaminateddatamaynot
betheprimaryfactorboostingmodelperformance 1. VERBATIM (dataset level, selection): f =
inthecontaminationsettingsstudied. identityfunctionontestsplit
2. DISTRIBUTION (dataset level, distribution):
Dataset R-1 R-2 R-L R-Lsum f =shuffletest datawithWebText
3. MASKED(instancelevel,masking): h =mask
CNN 38.70 14.14 24.90 32.11
outcontextpassageintestsplit
SAMSum 37.92 13.78 28.73 28.75
4. NOISED (instance level, noising): h = en-
XSum 24.21 4.89 16.60 16.60
counter GPT-3.5 generated answers to test
splitquestions
Table1: Rougescores(R-)forsummariesgeneratedby
GPT-3.5. Thesesummariesareusedassilverlabelsfor
5. REFORMATTED(instancelevel,augmenting/-
ourNOISEDcontaminationsetting. masking)5: h SQuAD = introduce 3 distractor
multiplechoiceansweroptions;h =mask
CBT
Whilethemajorityofthesesettingshavemetrics outincorrectansweroptions
thatfallwithinonestandarddeviationofeachother, 6. AUGMENTED (instance level, augmenting):
thereareexceptions. Forinstance,inthecaseofthe h =promptGPT-3.5toaddadditionalcontent
XSumdataset,theNOISEDsettingfailstosurpass tothecontextpassagesinthetestsplit
the BASELINE. Thisdiscrepancycanbeattributed
totheidiosyncrasiesoftheXSumdataset, where Table6providesexamplesofeachsetting.
groundtruthsummariesmaydeviatesignificantly
from typical summaries, thus posing a challenge 5.1 Results
forthemodelingeneratingaccurateoutputs. Table
Inthissection,weconsidertheoverallperformance
1showsthatthesummariesgeneratedbyGPT-3.5
ofeachcontaminationmethodacrossQuestionAn-
(Brown et al., 2020) for the XSum dataset have
swering datasets. Figure 3 shows an example of
lowerrougescoresthantheothertwodatasets.
theresultsfromonetaskandonemetric(SQuAD,
Additionally,underperformanceofthe MASKED ExactMatch). SeeAppendixBforfullevaluation
contaminationsettingcomparedtothe BASELINE resultsonalltasksandmetrics,specificallyFigures
across all datasets is noteworthy, suggesting that
7,8orTable4.
exposureonlytosummariesduringpretrainingmay
Onceagain,theCHEATINGsettingoutperforms
fail to achieve the benefits of seeing in-domain
all others by a noticeable margin. With the ex-
data.
ception of the MASKED setting for the SQuAD
5 CaseStudy: QuestionAnswering
5ForSQuAD,thisisaformofaugmentedcontamination,
asadditional(distractor)informationisintroduced.ForCBT,
For this case study, we consider open-ended QA
this is a form of masked contamination, as information is
withSQuAD(Rajpurkaretal.,2016)andmultiple- removed.
L-eguoR1
55 2 3
4 5
50
6
45
7
40 8 In-Domain Contamination
BASELINE DISTRIBUTION MASKED NOISED REFORMATTED AUGMENTED VERBATIM CHEATING
Figure3: BarChartofallSQuADmodelscomparedforExactMatch.
dataset,allcontaminatedsettingsexhibitbetterper- Furthermore, we observe variations in the per-
formance compared to the BASELINE setting by formance of AUGMENTED setting across the two
a considerable margin. This indicates that the in- datasets. While this setting perform well for
creaseddatadiversityexperiencedbyboththein- SQuAD, its performance is not as impressive for
domainandcontaminated modelsduringtraining CBT. This discrepancy may be attributed to the
improvedtheirperformanceduringevaluation. natureofdataaugmentation,wheretheadditional
informationprovidedforSQuADismorerelevant
Dataset ExactMatch F1Score and beneficial to the wikipedia paragraphs com-
paredtotheirrelevantintroductions,suchas‘once
SQuAD 74.56 88.15
uponatime’styleintroductionsgeneratedbyGPT-
CBT 77.21 79.78
3.5forthesebookexcerpts,addedtoCBTstories.
It is important to note that since this information
Table2: ExactmatchandF1scoresforanswersgener-
atedbyGPT-3.5. doesn’t significantly contribute to the task, this
form of augmentation falls in a blurry space be-
Note that the NOISED setting performs almost tween distribution and augmentation branches of
as well as the VERBATIM contamination setting. thetaxonomy. Itcouldalsobeviewedasunrelated
Weattributethistothefairlyhighqualityofsilver informationbeingaddedbetweensamplesduring
labelsgeneratedbyGPT-3.5(seeTable2). pretraining,complicatingitscategorization.
Exposuretoin-domaindataduringpretraining
appearstoimprovemodelperformance. However, 6 Analysis
ourresultsshowthatcontaminatedsettingssuchas
NOISED, VERBATIM,and DISTRIBUTION tendto Unsurprisingly,theCHEATINGandVERBATIMcon-
outperformthecorrespondingin-domainsettings tamination settings consistently outperform the
during evaluation. This suggests that seeing data BASELINE across both tasks. The in-domain set-
from the test set positively impacts model per- tings’consistentoutperformanceoftheBASELINE
formanceforquestionansweringtasks. Notethat underscorestheadvantagesofexposuretorelated
forthesethreemodelsetups,theformatofcontext, samplesduringpretraining(Krishnaetal.,2023).
question,andanswerisalmostconsistentwiththe Farmoreconcerningisthatseveralapproximate
formatandcontentseenduringevaluationtime. contaminationsettingsoutperformboththeBASE-
Reformatting(augmenting)free-formquestions LINE andtheirrespectivein-domainsettings,sug-
from SQuAD into multiple-choice answers dur- gestingthatthemodelinthesesettingsbenefitsnot
ing pretraining appears to have a negative effect onlyfromseeingin-domaintextbutfromunfairly
onmodelperformance,thoughitstilloutperforms leveragingpriorknowledgeofthetestexamples. In
the BASELINE setting. Conversely, converting particular,theNOISEDsetting,whichisgenerally
multiple-choicequestionsfromCBTintofree-form notdetectablewithexistingdecontaminationmeth-
questions(masking)duringpretrainingyieldspos- ods,producesscoresinflatedoverBASELINEinall
itiveresults,withthe REFORMATTED settingout- datasets,andscoresmorethanonestandarddevia-
performingmostothercontaminatedsettings. tionaboveitscorrespondingin-domainsettingin
hctaMtcaxEseveraldatasets. creationofourtaxonomy,wehopetopromotestan-
The MASKEDsettinggenerallyperformsaround dardizationregardingthedefinitionandcategories
or worse than the BASELINE, possibly due to the ofcontaminationwithintheresearchcommunity,
more extreme formatting mismatch between this facilitatingclearcommunicationandcollaboration,
dataandthetestdata. WeexpectthattheMASKED while also enabling precise detection and mitiga-
settingmaybeencounteredinthewildifafileof tionofcontaminationinpretrainingdata. Werec-
outputs for the dataset is in the pretraining data; ommendresearchersdecontaminatingpretraining
thelimitedimpactofthiscontaminationondown- corporaforLLMsprioritizedevelopingtechniques
stream performance is thus good news, though that address noisy evaluation data, while also en-
moreinvestigationwouldbenecessarytoconclu- suring rigorous scrutiny to prevent any shuffled
sivelysayMASKEDcontaminationisnotaconcern. or interleaved evaluation data from inadvertently
Formanyofthecontaminated settingsandtheir persistinginthepretrainingdata. Itisnotenough
correspondingin-domainsettings,theeffectofap- tomerelyremoveinstancesofthefulltestdataset
proximatecontaminationisnotgreaterthanaffect inthepretrainingcorpus;fragmentsornoisedver-
of in-domain data seen during pretaining. How- sions of the test set can also inflate performance.
ever, research has shown that memorization in Wehopeourworkinspiresfutureworkondetecting
LLMssignificantlygrowsasthesizeofthemodel andmitigatingspecifictypesofcontamination.
increases (Carlini et al., 2023). The number of
times a sample has been duplicated in the pre-
8 Limitations
trainingcorporahasalsobeenshowntoincreasea
model’s memorization capabilities (Carlini et al.,
2023;GolchinandSurdeanu,2023). Due to resource constraints, we only investigate
theimpactof encounteringcontaminateddatato-
Some behavior is task- or dataset-specific, em-
wards the end of pretraining (i.e. with continued
phasizingthatthereisnoone-size-fits-allapproach
pretraining),ratherthanrandomlythroughoutpre-
todatacuration: theimportanceofremovingeach
training. This may introduce recency bias, influ-
typeofcontaminationfromthepretrainingcorpus
encingourfindings. Additionally, ourfocusona
isatleastpartiallylinkedtothespecifictask’sfor-
singlelanguagemodellimitsthegeneralizabilityof
matting. However,sometypesofapproximatecon-
ourresults. GPT-2pretrainingdataisnotpublicly
taminationdoleadtoinflatedscores,emphasizing
accessiblesoourresultsmayonlyofferanapprox-
thatconsideringamorebroaddefinitionofcontam-
imationofcontaminationeffects. Differentmodel
inationwhende-contaminatingpretrainingcorpora
architectures,trainingprocedures,anddatasetsmay
isaworthwhileendeavor.
yieldvaryingimpactsofcontamination. Conduct-
7 Conclusion ingexperimentsonlargerLLMscouldpotentially
revealmorepronouncedeffectsofcontamination,
Ouranalysishighlightstheimportanceofdatafor- aslargermodelshavebeenshowntoexhibitgreater
mat,withmodelsperformingbetterwhenpretrain- tendenciesofmemorization(Carlinietal.,2023).
ing data matches the evaluation format. We also Further research involving multiple models and
observetask-specificeffects,withcertaincontam- comprehensiveevaluationsisneededtoestablish
ination methods benefiting particular tasks more morerobustconclusionsacrossdiversesettings.
than others. Additionally, we find that some late-
stagepretrainingcontaminationcanactuallybeun-
helpfultodownstreamperformance,ifitoccursina Acknowledgements
substantiallydifferentformatfromthedownstream
task. Our findings underscore gaps in current de- TheauthorswouldliketothankLoriLevinforher
contaminationpractices,whichprimarilyfocuson early guidance and the anonymous reviewers for
full-dataset-levelcontaminationandareoftenun- their thoughtful comments. This work was sup-
abletodetectapproximateornoisycontamination. ported in part by grants from 3M, the Pittsburgh
Wedemonstratethatdifferenttypesofcontam- SupercomputingCenter,andtheNationalScience
inationcanhavevariableeffectsonmodelperfor- FoundationGraduateResearchFellowshipunder
mance, highlighting the need for careful consid- GrantNo. DGE2140739.
eration during training and evaluation. With theReferences 2021ConferenceonEmpiricalMethodsinNatural
LanguageProcessing,pages1286–1305,Onlineand
A.Z. Broder. 1997. On the resemblance and con-
Punta Cana, Dominican Republic. Association for
tainment of documents. In Proceedings. Compres-
ComputationalLinguistics.
sion and Complexity of SEQUENCES 1997 (Cat.
No.97TB100171),pages21–29. BogdanGliwa,IwonaMochol,MaciejBiesek,andAlek-
sanderWawer.2019. SAMSumcorpus: Ahuman-
TomB.Brown,BenjaminMann,NickRyder,Melanie annotated dialogue dataset for abstractive summa-
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind rization. In Proceedings of the 2nd Workshop on
Neelakantan,PranavShyam,GirishSastry,Amanda NewFrontiersinSummarization,pages70–79,Hong
Askell, Sandhini Agarwal, Ariel Herbert-Voss, Kong,China.AssociationforComputationalLinguis-
Gretchen Krueger, Tom Henighan, Rewon Child, tics.
Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,
ClemensWinter,ChristopherHesse,MarkChen,Eric Shahriar Golchin and Mihai Surdeanu. 2023. Time
Sigler,MateuszLitwin,ScottGray,BenjaminChess, travelinllms: Tracingdatacontaminationinlarge
Jack Clark, Christopher Berner, Sam McCandlish, languagemodels.
Alec Radford, Ilya Sutskever, and Dario Amodei.
2020. Languagemodelsarefew-shotlearners. ShahriarGolchinandMihaiSurdeanu.2024. Datacon-
taminationquiz: Atooltodetectandestimatecon-
JialunCao,WuqiZhang,andShing-ChiCheung.2024. taminationinlargelanguagemodels.
Concernedwithdatacontamination? assessingcoun-
termeasuresincodelanguagemodel. Sireesh Gururaja, Amanda Bertsch, Clara Na, David
Widder, and Emma Strubell. 2023. To build our
NicholasCarlini,DaphneIppolito,MatthewJagielski, future, we must know our past: Contextualizing
KatherineLee,FlorianTramer,andChiyuanZhang. paradigmshiftsinnaturallanguageprocessing. In
2023. Quantifyingmemorizationacrossneurallan- Proceedings of the 2023 Conference on Empirical
guagemodels. Methods in Natural Language Processing, pages
13310–13325, Singapore. Association for Compu-
KentK.Chang,MackenzieCramer,SandeepSoni,and tationalLinguistics.
DavidBamman.2023a. Speak,memory: Anarchae-
ologyofbooksknowntochatgpt/gpt-4. Suchin Gururangan, Ana Marasovic´, Swabha
Swayamdipta,KyleLo,IzBeltagy,DougDowney,
Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, and Noah A. Smith. 2020. Don’t stop pretraining:
Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Adapt language models to domains and tasks. In
CunxiangWang,YidongWang,WeiYe,YueZhang, Proceedings of the 58th Annual Meeting of the
YiChang,PhilipS.Yu,QiangYang,andXingXie. Association for Computational Linguistics, pages
2023b. A survey on evaluation of large language 8342–8360,Online.AssociationforComputational
models. Linguistics.
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming FelixHill, AntoineBordes, SumitChopra, andJason
Yuan,HenriquePondedeOliveiraPinto,JaredKa- Weston. 2016. The goldilocks principle: Reading
plan, HarriEdwards, YuriBurda, NicholasJoseph, children’s books with explicit memory representa-
Greg Brockman, Alex Ray, Raul Puri, Gretchen tions.
Krueger,MichaelPetrov,HeidyKhlaaf,GirishSas-
MinhaoJiang,KenZiyuLiu,MingZhong,RylanScha-
try, Pamela Mishkin, Brooke Chan, Scott Gray,
effer,SiruOuyang,JiaweiHan,andSanmiKoyejo.
NickRyder,MikhailPavlov,AletheaPower,Lukasz
2024. Investigating data contamination for pre-
Kaiser, Mohammad Bavarian, Clemens Winter,
traininglanguagemodels.
Philippe Tillet, Felipe Petroski Such, Dave Cum-
mings, Matthias Plappert, Fotios Chantzis, Eliza-
Anjan Karmakar, Julian Aron Prenner, Marco
beth Barnes, Ariel Herbert-Voss, William Hebgen
D’Ambros,andRomainRobbes.2022. Codexhacks
Guss,AlexNichol,AlexPaino,NikolasTezak,Jie
hackerrank: Memorizationissuesandaframework
Tang,IgorBabuschkin,SuchirBalaji,ShantanuJain,
forcodesynthesisevaluation.
William Saunders, Christopher Hesse, Andrew N.
Carr,JanLeike,JoshAchiam,VedantMisra,Evan
AndrejKarpathy.2023. nanogpt.
Morikawa, Alec Radford, Matthew Knight, Miles
Brundage,MiraMurati,KatieMayer,PeterWelinder, KundanKrishna,SaurabhGarg,JeffreyP.Bigham,and
BobMcGrew,DarioAmodei,SamMcCandlish,Ilya ZacharyC.Lipton.2023. Downstreamdatasetsmake
Sutskever,andWojciechZaremba.2021. Evaluating surprisinglygoodpretrainingcorpora.
largelanguagemodelstrainedoncode.
Katherine Lee, Daphne Ippolito, Andrew Nystrom,
Jesse Dodge, Maarten Sap, Ana Marasovic´, William ChiyuanZhang,DouglasEck,ChrisCallison-Burch,
Agnew,GabrielIlharco,DirkGroeneveld,Margaret andNicholasCarlini.2022. Deduplicatingtraining
Mitchell, and Matt Gardner. 2021. Documenting datamakeslanguagemodelsbetter. InProceedings
large webtext corpora: A case study on the colos- of the 60th Annual Meeting of the Association for
sal clean crawled corpus. In Proceedings of the ComputationalLinguistics(Volume1: LongPapers),pages8424–8445,Dublin,Ireland.Associationfor Inioluwa Deborah Raji, Emily M. Bender, Amanda-
ComputationalLinguistics. lynnePaullada,EmilyDenton,andAlexHanna.2021.
Aiandtheeverythinginthewholewideworldbench-
Changmao Li and Jeffrey Flanigan. 2023. Task con- mark.
tamination: Languagemodelsmaynotbefew-shot
anymore. PranavRajpurkar,JianZhang,KonstantinLopyrev,and
PercyLiang.2016. SQuAD:100,000+questionsfor
InbalMagarandRoySchwartz.2022. Datacontamina- machinecomprehensionoftext. InProceedingsof
tion: Frommemorizationtoexploitation. the2016ConferenceonEmpiricalMethodsinNatu-
ralLanguageProcessing,pages2383–2392,Austin,
MarcMaroneandBenjaminVanDurme.2023. Data
Texas.AssociationforComputationalLinguistics.
portraits: Recordingfoundationmodeltrainingdata.
ManleyRoberts,HimanshuThakur,ChristineHerlihy,
SewonMin,XinxiLyu,AriHoltzman,MikelArtetxe, ColinWhite,andSamuelDooley.2023. Datacon-
MikeLewis,HannanehHajishirzi,andLukeZettle- taminationthroughthelensoftime.
moyer.2022. Rethinkingtheroleofdemonstrations:
Whatmakesin-contextlearningwork? InProceed- Oscar Sainz, Jon Campos, Iker García-Ferrero, Julen
ingsofthe2022ConferenceonEmpiricalMethodsin Etxaniz,OierLopezdeLacalle,andEnekoAgirre.
NaturalLanguageProcessing,pages11048–11064, 2023a. NLP evaluation in trouble: On the need to
AbuDhabi,UnitedArabEmirates.Associationfor measure LLM data contamination for each bench-
ComputationalLinguistics. mark. In Findings of the Association for Compu-
tational Linguistics: EMNLP 2023, pages 10776–
Ramesh Nallapati, Bowen Zhou, Cicero dos Santos, 10787, Singapore. Association for Computational
Çag˘lar Gu˙lçehre, and Bing Xiang. 2016. Abstrac- Linguistics.
tivetextsummarizationusingsequence-to-sequence
RNNs and beyond. In Proceedings of the 20th OscarSainz,JonAnderCampos,IkerGarcia-Ferrero,
SIGNLLConferenceonComputationalNaturalLan- JulenEtxaniz,,andEnekoAgirre.2023b. Didchat-
guage Learning, pages 280–290, Berlin, Germany. gptcheatonyourtest?
AssociationforComputationalLinguistics.
Weijia Shi, Anirudh Ajith, Mengzhou Xia, Yangsibo
Shashi Narayan, Shay B. Cohen, and Mirella Lapata. Huang,DaogaoLiu,TerraBlevins,DanqiChen,and
2018. Don’tgivemethedetails,justthesummary! LukeZettlemoyer.2023. Detectingpretrainingdata
topic-aware convolutional neural networks for ex- fromlargelanguagemodels.
treme summarization. In Proceedings of the 2018
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
Conference on Empirical Methods in Natural Lan-
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
guageProcessing,pages1797–1807,Brussels,Bel-
Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti
gium.AssociationforComputationalLinguistics.
Bhosale,DanBikel,LukasBlecher,CristianCanton
Hiroki Ouchi, Jun Suzuki, and Kentaro Inui. 2019. Ferrer,MoyaChen,GuillemCucurull,DavidEsiobu,
Transductivelearningofneurallanguagemodelsfor JudeFernandes,JeremyFu,WenyinFu,BrianFuller,
syntacticandsemanticanalysis. InProceedingsof CynthiaGao,VedanujGoswami,NamanGoyal,An-
the2019ConferenceonEmpiricalMethodsinNatu- thonyHartshorn,SagharHosseini,RuiHou,Hakan
ralLanguageProcessingandthe9thInternational Inan,MarcinKardas,ViktorKerkez,MadianKhabsa,
JointConferenceonNaturalLanguageProcessing IsabelKloumann,ArtemKorenev,PunitSinghKoura,
(EMNLP-IJCNLP),pages3665–3671,HongKong, Marie-AnneLachaux,ThibautLavril,JenyaLee,Di-
China.AssociationforComputationalLinguistics. anaLiskovich,YinghaiLu,YuningMao,XavierMar-
tinet,TodorMihaylov,PushkarMishra,IgorMoly-
AleksandraPiktus,ChristopherAkiki,PauloVillegas, bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-
HugoLaurençon,GérardDupont,AlexandraSasha stein,RashiRungta,KalyanSaladi,AlanSchelten,
Luccioni, Yacine Jernite, and Anna Rogers. 2023. Ruan Silva, Eric Michael Smith, Ranjan Subrama-
Therootssearchtool: Datatransparencyforllms. nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-
lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,
AlecRadford,JeffreyWu,RewonChild,DavidLuan, ZhengYan,IliyanZarov,YuchenZhang,AngelaFan,
DarioAmodei,andIlyaSutskever.2019a. Language Melanie Kambadur, Sharan Narang, Aurelien Ro-
modelsareunsupervisedmultitasklearners. driguez,RobertStojnic,SergeyEdunov,andThomas
Scialom.2023. Llama2: Openfoundationandfine-
AlecRadford,JeffreyWu,RewonChild,DavidLuan,
tunedchatmodels.
Dario Amodei, Ilya Sutskever, et al. 2019b. Lan-
guage models are unsupervised multitask learners. VladimirVapnik.1998. Statisticallearningtheory. John
OpenAIblog,1(8):9. Wiley&Sons.
ColinRaffel,NoamShazeer,AdamRoberts,Katherine JasonWei, MaartenBosma, VincentY.Zhao, Kelvin
Lee,SharanNarang,MichaelMatena,YanqiZhou, Guu, Adams Wei Yu, Brian Lester, Nan Du, An-
WeiLi,andPeterJ.Liu.2020. Exploringthelimits drew M. Dai, and Quoc V. Le. 2021. Finetuned
oftransferlearningwithaunifiedtext-to-texttrans- language models are zero-shot learners. CoRR,
former. CoRR,abs/1910.10683. abs/2109.01652.ShuoYang,Wei-LinChiang,LianminZheng,JosephE.
Gonzalez,andIonStoica.2023. Rethinkingbench-
markandcontaminationforlanguagemodelswith
rephrasedsamples.
Chiyuan Zhang, Daphne Ippolito, Katherine Lee,
MatthewJagielski,FlorianTramèr,andNicholasCar-
lini. 2023. Counterfactual memorization in neural
languagemodels.A FullresultsforSummarizationCaseStudy
Wepresentthefullresultsofthesummarizationcasestudy. Foreachsettinganddataset,wehaveincluded
atableoftheRougemetricsalongwiththeirstandarddeviations. Thedataisalsopresentedthrougha
seriesofbarchartsforeasierinterpretabilityoftheresultsforthereader. Standarddeviationsaremeasured
overtheresultsofthe3modelstrainedonrandomshufflesofthedata.
Contaminated Contaminated
Dataset Model Pretraining Fine-tuning ROUGE-1 ROUGE-2 ROUGE-L ROUGE-LSUM
Data Data
ZERO-SHOT - - 21.98±0.26 5.076±0.01 13.63±0.10 18.51±0.10
BASELINE - × 27.22±0.53 7.436±0.13 18.15±0.43 24.90±0.36
CHEATING - ✓ 33.60±0.58 10.198±0.16 20.52±0.33 29.61±0.32
VERBATIM ✓ × 29.84±0.48 9.488±0.14 19.50±0.38 26.98±0.40
DISTRIBUTION ✓ × 29.73±0.33 9.557±0.13 19.50±0.22 27.12±0.26
MASKED ✓ × 28.34±0.22 8.326±0.13 18.01±0.29 25.96±0.20
CNN NOISED ✓ × 31.31±0.52 8.821±0.15 19.19±0.32 28.85±0.30
REFORMATTED ✓ × 29.21±0.28 8.887±0.13 18.88±0.29 26.27±0.30
INDOMAIN-VERBATIM × × 29.81±0.48 9.277±0.13 18.93±0.25 26.88±0.31
INDOMAIN-DIST. × × 28.86±0.30 8.910±0.13 18.41±0.27 26.10±0.30
INDOMAIN-MASK × × 28.87±0.39 8.493±0.15 18.24±0.30 26.40±0.29
INDOMAIN-NOISE × × 31.16±0.42 8.596±0.10 18.85±0.26 26.53±0.35
INDOMAIN-REFORM. × × 28.80±0.31 8.681±0.12 18.75±0.24 26.07±0.32
ZERO-SHOT - - 11.73±0.14 1.357±0.01 8.377±0.19 9.331±0.16
BASELINE - × 32.95±0.57 10.22±0.15 25.83±0.32 25.59±0.29
CHEATING - ✓ 36.36±0.53 12.31±0.14 28.41±0.33 28.48±0.33
VERBATIM ✓ × 34.34±0.45 10.76±0.16 26.98±0.40 27.04±0.38
DISTRIBUTION ✓ × 33.73±0.51 10.32±0.15 26.48±0.31 26.56±0.33
MASKED ✓ × 33.05±0.46 10.46±0.15 25.77±0.30 25.81±0.28
SAMSum NOISED ✓ × 33.62±0.43 10.27±0.16 26.50±0.37 26.49±0.38
REFORMATTED ✓ × 33.63±0.39 10.25±0.15 26.37±0.31 26.46±0.34
INDOMAIN-VERBATIM × × 33.61±0.46 10.27±0.14 26.39±0.30 26.46±0.35
INDOMAIN-DIST. × × 33.55±0.42 10.26±0.11 26.32±0.33 26.44±0.35
INDOMAIN-MASK × × 32.87±0.41 10.47±0.12 25.74±0.35 25.74±0.31
INDOMAIN-NOISE × × 33.67±0.37 10.33±0.13 26.38±0.29 26.47±0.28
INDOMAIN-REFORM. × × 33.52±0.34 10.24±0.16 26.24±0.28 26.34±0.29
ZERO-SHOT - - 12.52±0.11 2.059±0.00 9.035±0.16 10.27±0.17
BASELINE - × 26.28±0.48 6.424±0.12 19.80±0.32 19.81±0.33
CHEATING - ✓ 29.87±0.41 8.334±0.13 22.97±0.43 22.98±0.42
VERBATIM ✓ × 26.53±0.51 6.820±0.12 20.08±0.33 20.03±0.37
DISTRIBUTION ✓ × 26.61±0.42 6.885±0.13 20.12±0.37 20.11±0.37
MASKED ✓ × 24.50±0.46 5.677±0.12 18.16±0.29 18.39±0.31
XSum NOISED ✓ × 26.16±0.39 6.599±0.12 19.72±0.35 19.72±0.35
REFORMATTED ✓ × 26.27±0.43 6.623±0.12 19.86±0.29 19.86±0.30
INDOMAIN-VERBATIM × × 26.43±0.41 6.745±0.14 19.99±0.27 19.99±0.40
INDOMAIN-DIST. × × 26.34±0.40 6.666±0.12 19.85±0.32 19.85±0.32
INDOMAIN-MASK × × 24.31±0.39 5.521±0.13 18.02±0.29 18.04±0.34
INDOMAIN-NOISE × × 26.31±0.46 6.607±0.11 19.80±0.36 19.81±0.28
INDOMAIN-REFORM. × × 25.29±0.32 6.280±0.12 19.04±0.35 19.06±0.30
Table3: Resultsforall13modelstrainedonXSum,SAMSum,andCNN/DailyMailDatasets. Thetableshowcases
evaluationmetrics,withthebest-performingmodelscoresboldedandthesecondbestitalicized.1
34
32 2
4 3
30 5
6
28 7
In-Domain Contamination
26
BASELINE DISTRIBUTION MASKED NOISED REFORMATTED VERBATIM CHEATING
1
10
2 3
9 5 4
6
8
7
In-Domain Contamination
7
BASELINE DISTRIBUTION MASKED NOISED REFORMATTED VERBATIM CHEATING
21 1
20 2 2
4
5
19
6
7
18 In-Domain Contamination
BASELINE DISTRIBUTION MASKED NOISED REFORMATTED VERBATIM CHEATING
30 1
2
28
3 4
5
6
26
7
In-Domain Contamination
24
BASELINE DISTRIBUTION MASKED NOISED REFORMATTED VERBATIM CHEATING
Figure4: BarChartofallCNN/DailyMailmodelscomparedforeachmetric
1-eguoR
2-eguoR
L-eguoR
musL-eguoR1
36
2
3 5 4
34
7 6
In-Domain Contamination
32
BASELINE DISTRIBUTION MASKED NOISED REFORMATTED VERBATIM CHEATING
1
12
11 2
3
7 4 5 6
10
In-Domain Contamination
BASELINE DISTRIBUTION MASKED NOISED REFORMATTED VERBATIM CHEATING
1
28
2
3 4 5
6 7
26
In-Domain Contamination
BASELINE DISTRIBUTION MASKED NOISED REFORMATTED VERBATIM CHEATING
1
28
2
3 5 4
6
26 7
In-Domain Contamination
BASELINE DISTRIBUTION MASKED NOISED REFORMATTED VERBATIM CHEATING
Figure5: BarChartofallSAMSummodelscomparedforeachmetric
1-eguoR
2-eguoR
L-eguoR
musL-eguoR1
30
28
2 3
4 6 5
26
7
In-Domain Contamination
24
BASELINE DISTRIBUTION MASKED NOISED REFORMATTED VERBATIM CHEATING
9
1
8
7 2 3
5 4
6
6
7
In-Domain Contamination
BASELINE DISTRIBUTION MASKED NOISED REFORMATTED VERBATIM CHEATING
24
1
22
2 3
5 6 4
20
7
In-Domain Contamination
18
BASELINE DISTRIBUTION MASKED NOISED REFORMATTED VERBATIM CHEATING
24
1
22
2 3
5 6 4
20
7
In-Domain Contamination
18
BASELINE DISTRIBUTION MASKED NOISED REFORMATTED VERBATIM CHEATING
Figure6: BarChartofallXSummodelscomparedforeachmetric
1-eguoR
2-eguoR
L-eguoR
musL-eguoRB FullresultsforQuestionAnsweringCaseStudy
WepresentthefullresultsoftheQAcasestudy. Foreachsettinganddataset,wehaveincludedatableof
theexactmatchandf1metricsalongwiththeirstandarddeviations. Thedataisalsopresentedthrougha
seriesofbarchartsforeasierinterpretabilityoftheresultsforthereader. Standarddeviationsaremeasured
overtheresultsofthe3modelstrainedonrandomshufflesofthedata.
Contaminated Contaminated
Dataset Model ExactMatch F1Score
PretrainingData Fine-tuningData
ZERO-SHOT - - 1.178±0.11 4.180±0.22
BASELINE - × 41.76±1.01 55.72±0.85
CHEATING - ✓ 55.73±0.94 66.47±0.80
VERBATIM ✓ × 53.38±0.94 65.07±0.96
DISTRIBUTION ✓ × 52.76±0.89 64.92±0.88
MASKED ✓ × 38.77±0.96 51.93±0.78
NOISED ✓ × 52.72±0.89 64.65±0.89
SQuAD REFORMATTED ✓ × 48.08±0.91 61.85±0.94
AUGMENTED ✓ × 53.58±0.98 65.51±0.90
INDOMAIN-VERBATIM × × 52.44±0.89 64.52±0.92
INDOMAIN-DIST. × × 51.90±0.91 64.43±0.87
INDOMAIN-MASK × × 44.62±0.93 58.95±1.00
INDOMAIN-NOISE × × 50.63±0.85 63.60±0.86
INDOMAIN-REFORM. × × 51.30±0.95 63.72±0.95
INDOMAIN-AUGMENT × × 52.94±0.94 64.24±0.89
ZERO-SHOT - - 1.192±0.12 3.290±0.21
BASELINE - × 19.41±0.99 19.84±0.90
CHEATING - ✓ 54.27±0.85 56.39±0.96
VERBATIM ✓ × 52.06±0.88 53.91±0.89
DISTRIBUTION ✓ × 50.82±0.97 51.21±0.97
MASKED ✓ × 46.51±0.84 47.43±0.93
NOISED ✓ × 49.59±0.86 50.44±0.96
CBT REFORMATTED ✓ × 51.46±0.93 52.96±0.86
AUGMENTED ✓ × 49.09±1.00 50.32±0.89
INDOMAIN-VERBATIM × × 44.19±0.87 45.06±0.96
INDOMAIN-DIST. × × 42.85±0.92 46.06±0.90
INDOMAIN-MASK × × 40.77±0.96 40.18±0.93
INDOMAIN-NOISE × × 49.02±0.97 49.11±0.98
INDOMAIN-REFORM. × × 50.01±0.86 51.12±0.86
INDOMAIN-AUGMENT × × 50.46±0.93 51.62±0.84
Table4: Resultsforall15modelstrainedontheSQuADandCBTdataset. Thetableshowcasesevaluationmetrics,
withthebest-performingmodelscoresboldedandthesecondbestitalicized.1
55 2 3
4 5
50
6
45
7
40 8 In-Domain Contamination
BASELINE DISTRIBUTION MASKED NOISED REFORMATTED AUGMENTED VERBATIM CHEATING
1
4 5 2 3
65
6
60
7
55
8
In-Domain Contamination
50
BASELINE DISTRIBUTION MASKED NOISED REFORMATTED AUGMENTED VERBATIM CHEATING
Figure7: BarChartofallSQuADmodelscomparedforeachmetric
1
4 3 2
5 6
50
7
40
30
In-Domain Contamination
8
20
BASELINE DISTRIBUTION MASKED NOISED REFORMATTED AUGMENTED VERBATIM CHEATING
60
1
3 2
4 5 6
50
7
40
30
In-Domain Contamination
8
20
BASELINE DISTRIBUTION MASKED NOISED REFORMATTED AUGMENTED VERBATIM CHEATING
Figure8: BarChartofallCBTmodelscomparedforeachmetric
hctaMtcaxE
erocS1F
hctaMtcaxE
erocS1FC Examplesforeachcontaminationtype
We provide examples of each of the functions from the different contamination types we are testing,
appliedtoasamplefromeachdatasetfromthecasestudies.
Conversation:
Anita:I’matthestationinBologna
Jenny:Noproblemssofar?
Sample Anita:no,everything’sgoingsmoothly
Tomy:good!
Summary:AnitaisatBolognastation.
⟨someopenwebtext⟩
Conversation:
Anita:I’matthestationinBologna
Jenny:Noproblemssofar?
Distribution Anita:no,everything’sgoingsmoothly
Tomy:good!
Summary:AnitaisatBolognastation.
⟨somemoreopenwebtext⟩
Masking Summary:AnitaisatBolognastation.
Conversation:
Anita:I’matthestationinBologna
Jenny:Noproblemssofar?
Anita:no,everything’sgoingsmoothly
Noising
Tomy:good!
Summary:AnitaconfirmsherlocationattheBolognastationtoJennyandTomy,
reassuringthemthateverythingisrunningsmoothly.
Summary:AnitaisatBolognastation.
Conversation:
Reformatting Anita:I’matthestationinBologna
Jenny:Noproblemssofar?
Anita:no,everything’sgoingsmoothly
Tomy:good!
Table5: ApplyingthedifferentcontaminationtechniquestoasamplefromtheSAMSumdataset.Context:
TheBeyHiveisthenamegiventoBeyoncé’sfanbase.Fanswerepreviouslytitled“TheBeyontourage”,
(aportmanteauofBeyoncéandentourage).ThenameBeyHivederivesfromthewordbeehive,purposelymisspelled
toresembleherfirstname,andwaspennedbyfansafterpetitionsontheonlinesocialnetworkingserviceTwitterandonline
Sample
newsreportsduringcompetitions.
Question:Beyoncehasafanbasethatisreferredtoaswhat?
Answer:TheBeyHive
⟨someopenwebtext⟩
Context:
TheBeyHiveisthenamegiventoBeyoncé’sfanbase.Fanswerepreviouslytitled“TheBeyontourage”,
(aportmanteauofBeyoncéandentourage).ThenameBeyHivederivesfromthewordbeehive,purposelymisspelled
toresembleherfirstname,andwaspennedbyfansafterpetitionsontheonlinesocialnetworkingserviceTwitterandonline
Distribution
newsreportsduringcompetitions.
Question:Beyoncehasafanbasethatisreferredtoaswhat?
Answer:TheBeyHive
⟨somemoreopenwebtext⟩
Question:Beyoncehasafanbasethatisreferredtoaswhat?
Masking
Answer:TheBeyHive
Context:
TheBeyHiveisthenamegiventoBeyoncé’sfanbase.Fanswerepreviouslytitled“TheBeyontourage”,
(aportmanteauofBeyoncéandentourage).ThenameBeyHivederivesfromthewordbeehive,purposelymisspelled
toresembleherfirstname,andwaspennedbyfansafterpetitionsontheonlinesocialnetworkingserviceTwitterandonline
Noising
newsreportsduringcompetitions.
Question:Beyoncehasafanbasethatisreferredtoaswhat?
Answer:BeyHive
Context:
TheBeyHiveisthenamegiventoBeyoncé’sfanbase.Fanswerepreviouslytitled“TheBeyontourage”,
(aportmanteauofBeyoncéandentourage).ThenameBeyHivederivesfromthewordbeehive,purposelymisspelled
toresembleherfirstname,andwaspennedbyfansafterpetitionsontheonlinesocialnetworkingserviceTwitterandonline
newsreportsduringcompetitions.
Question:Beyoncehasafanbasethatisreferredtoaswhat?
Reformatting
Options:
A)TheBeehivers
B)TheBeyHive
C)TheBeyontourage
D)TheBeyFlock
Answer:TheBeyHive
Context:
TheBeyHiveisthenamegiventoBeyoncé’sfanbase.Fanswerepreviouslytitled“TheBeyontourage”,
(aportmanteauofBeyoncéandentourage).ThenameBeyHivederivesfromthewordbeehive,purposelymisspelled
toresembleherfirstname,andwaspennedbyfansafterpetitionsontheonlinesocialnetworkingserviceTwitterandonline
Augmenting
newsreportsduringcompetitions.ThisferventfanbaseactivelyengageswithBeyoncé’smusic,performances,and
philanthropicendeavors.
Question:Beyoncehasafanbasethatisreferredtoaswhat?
Answer:TheBeyHive
Table6: ApplyingthedifferentcontaminationtechniquestoasamplefromtheSQuADdataset.