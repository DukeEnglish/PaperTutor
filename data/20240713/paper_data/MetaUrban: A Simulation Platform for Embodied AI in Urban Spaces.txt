MetaUrban: A Simulation Platform for
Embodied AI in Urban Spaces
WayneWu,HonglinHe,YiranWang,ChendaDuan,
JackHe,ZhizhengLiu,QuanyiLi,BoleiZhou
UniversityofCalifornia,LosAngeles
https://metadriverse.github.io/metaurban
Delivery Bot Electric Wheelchair Robot Dog Humanoid Robot
Sidewalk Crosswalk StreetBlock Plaza
Figure1:(Top)Humansandmobilemachinesstartsharingpublicurbanspaces.(Bottom)MetaUrbansimulator
facilitatesembodiedAIresearchinurbansettingsbycomposinginteractiveurbanenvironmentswithdiverse
streetblocks,objects,andmovementsofpedestrians,vulnerableroadusers,andotheragents.
Abstract
Publicurbanspaceslikestreetscapesandplazasserveresidentsandaccommodate
sociallifeinallitsvibrantvariations. RecentadvancesinRoboticsandEmbodied
AImakepublicurbanspacesnolongerexclusivetohumans. Fooddeliverybots
andelectricwheelchairshavestartedsharingsidewalkswithpedestrians, while
diverserobotdogsandhumanoidshaverecentlyemergedinthestreet. Ensuring
thegeneralizabilityandsafetyoftheseforthcomingmobilemachinesiscrucial
when navigating through the bustling streets in urban spaces. In this work, we
present MetaUrban, a compositional simulation platform for Embodied AI re-
searchinurbanspaces. MetaUrbancanconstructaninfinitenumberofinteractive
urbanscenesfromcompositionalelements,coveringavastarrayofgroundplans,
objectplacements, pedestrians, vulnerableroadusers, andothermobileagents’
appearancesanddynamics. Wedesignpointnavigationandsocialnavigationtasks
asthepilotstudyusingMetaUrbanforembodiedAIresearchandestablishvarious
baselinesofReinforcementLearningandImitationLearning. Experimentsdemon-
stratethatthecompositionalnatureofthesimulatedenvironmentscansubstantially
improvethegeneralizabilityandsafetyofthetrainedmobileagents. MetaUrban
willbemadepubliclyavailabletoprovidemoreresearchopportunitiesandfoster
safeandtrustworthyembodiedAIinurbanspaces.
Preprint.Underreview.
4202
luJ
11
]VC.sc[
1v52780.7042:viXra1 Introduction
Public urban spaces vary widely in type, form, and size, encompassing streetscapes, plazas, and
parks. Theyarecrucialspacesfortransitandtransport,aswellasprovidingopportunitiestostage
varioussocialevents. Sincetheearly20thcentury,thestudyofpublicurbanspaceshaslongbeen
acornerstoneofurbansociology[56,32,29]andplanning[26,78,28]. Forexample,WilliamH.
Whyte,inhisseminalwork,“City-RediscoveringtheCenter”[79],revealedthatthecomplexity
andvibrantinteractioninpublicspacesprofoundlydeterminehumans’sociallife,underscoringthe
criticalroletheseenvironmentsplayinurbansafetyandvitality.
Recent development of Robotics and Embodied AI makes the urban space no longer exclusive
tohumans. Variousmobilemachineshavestartedemerging. Forexample, eldersandphysically
disabledpeoplemaneuverelectronicwheelchairsonthestreet,whilefooddeliverybotsnavigateon
thesidewalktoaccomplishthelast-milefooddeliverytask. Variousmobileleggedrobotslikerobot
dogSpotfromBostonDynamicsandhumanoidrobotOptimusfromTeslaarealsoforthcoming. We
canthusimagineafutureofpublicurbanspacesthatwillbesharedandco-habitatedbyhumansand
mobilemachinesdrivenbyEmbodiedAI.Ensuringthegeneralizabilityandsafetyofthesemobile
machinesbecomesessential.
Simulationplatforms[35,67,70,41,73,13,18,38,44,19]haveplayedacrucialroleinenabling
systematicandscalabletrainingoftheembodiedAIagentsandthesafetyevaluationbeforereal-world
deployment. However,mostoftheexistingsimulatorsfocuseitheronindoorhouseholdenviron-
ments[61,35,67,70,41,24]oroutdoordrivingenvironments[38,44,19]. Forexample,platforms
likeAI2-THOR[35],Habitat[67],andiGibson[70]aredesignedforhouseholdassistantrobotsin
whichtheenvironmentsaremainlyapartmentsorhouseswithfurnitureandappliances;platforms
likeSUMO[38],CARLA[19],andMetaDrive[44]aredesignedforresearchonautonomousdriving
andtransportation. Yet,simulatingurbanspaceswithdiverselayoutsandobjects,complexdynamics
ofpedestrians,ismuchlessexplored.
Distinctfromtheindoorhouseholdanddrivingenvironments,theurbanspacehasuniquecharac-
teristics. Let’sfollowtheadventureofalast-miledeliverybot,whoaimstodeliveralunchorder
fromanearbypizzeriato thecampus. First, itfaces along-horizonjourneyacrossseveralstreet
blocksataone-miledistance,withmultifariousroadhazards,suchasfragmentedcurbsandrugged
groundcausedbytreerootsonsidewalks. Then,itmustsafelynavigatetheclutteredstreetfullof
obstaclesliketrashbins,parkedscooters,andpottedplants. Inaddition,itneedstohandlepedestrians
andcrowdsproperlytoavoidcollisions. Itshouldalsotakespecialcarearounddisabledpeoplein
wheelchairs. Thus,thelayoutdiversity,objectdistribution,anddynamiccomplexitybringunique
challengestothedesignofsimulationenvironmentsandthestudyofthegeneralizabilityandsafety
ofEmbodiedAIagentsoperatinginurbanspaces.
WepresentMetaUrban–acompositionalsimulationplatformforEmbodiedAIresearchinurban
spaces. First,weintroduceHierarchicalLayoutGeneration,aproceduralgenerationapproachthat
cangenerateinfinitelayoutshierarchicallyfromstreetblockstosidewalks,functionalzones,and
objectlocations. Itcangeneratescenesatanarbitraryscalewithvariousconnectionsanddivisionsof
streetblocks,objectlocations,andterrains,whicharecriticalforimprovingthegeneralizabilityof
trainedagents. Then,wedesigntheScalableObjectRetrieval,anautomaticpipelinethatcanobtain
anarbitrarynumberofhigh-qualityobjectswithreal-worlddistribution. Wefirstcomputetheobject
categorydistributionfrombroadreal-worlddatatoformadescriptionpool. Then,withthesampled
descriptionsfromthepool,weeffectivelyretrieveobjectsfromlarge-scale3Dassetrepositorieswith
aVLM-basedopen-vocabularysearchingschema. Finally,weproposetheCohabitantPopulating
methodtogeneratecomplexdynamicsinurbanspaces. Wefirsttailorrecent3Dhumanandmotion
datasetstoget1,100riggedpedestrianmodels,eachwith2,314movements. Then,toformsafety-
criticalscenarios,weintegrateVulnerableRoadUsers(VRUs)likebikers,skateboarders,andscooter
riders. Tobroadenthecategoryofmobilemachinesinurbanscenes,weincludedeliverybots,electric
wheelchairs,robotdogs,andhumanoidrobots. Then,basedonpathplanningalgorithms,wecan
getcomplextrajectoriesamonghundredsofenvironmentalagentssimultaneouslywithcollisionand
deadlockavoidance. Itiscriticalforenhancingthesocialconformityandsafetyofthemobileagents.
Based on MetaUrban, we construct a large-scale dataset, MetaUrban-12K, that includes 12,800
trainingscenesand1,000testscenes.Wefurthercreateanunseentestsetwith100manuallydesigned
scenestoevaluatetrainedmodels’generalizability. Besides,weprovide30,000stepsofhigh-quality
2expertdemonstrationsbyhumansandwell-trainedagentstoenableofflinereinforcementlearning
andimitationlearningresearch. Wedesignpointnavigationandsocialnavigationtasksasapilot
studyusingMetaUrbanforembodiedAIresearchandestablishextensivebaselinesforReinforcement
Learning,SafeReinforcementLearning,OfflineReinforcementLearning,andImitationLearning.
Experimentsdemonstratethatthegeneralizabilityandsafetyofthetrainedmobileagentscanbe
substantiallyimprovedbythecompositionalnatureofthesimulatedenvironments. Wewillmake
thesimulatoravailabletoenablemoreresearchopportunitiesforthecommunityandfostersafeand
trustworthyembodiedAIinurbanspaces.
2 RelatedWork
ManysimulationplatformshavebeendevelopedforEmbodiedAIresearch,dependingonthetarget
environments–suchasindoorhomesandoffices,drivingfreewaysandroadways,andcrowdsin
warehousesandsquares. WecomparerepresentativeoneswiththeproposedMetaUrbansimulator.
Indoor Environments. Platforms for indoor environments are mainly designed for household
assistantrobots,emphasizingtheaffordance,realism,anddiversityofobjects,aswellastheinter-
activityofenvironments. VirtualHome[61]pivotstowardssimulatingroutinehumanactivitiesat
home. AI2-THOR [35] and its extensions, such as ManipulaTHOR [20], RoboTHOR [13], and
ProcTHOR [18], focus on detailed agent-object interactions, dynamic object state changes, and
proceduralscenegeneration,alongsiderobustphysicssimulations. Habitat[67]offersenvironments
reconstructedfrom3Dscansofreal-worldinteriors. Itssubsequentiterations,Habitat2.0[73]and
Habitat3.0[63],introduceinteractableobjectsanddeformablehumanoidagents,respectively. iGib-
son[70]providesphotorealisticenvironments. Itsupgrades,Gibson2.0[40],andOmniGibson[41],
focusonhouseholdtaskswithobjectstatechangesandarealisticphysicssimulationofeveryday
activities, respectively. ThreeDWorld [24] targets real-world physics by integrating high-fidelity
simulationsofliquidsanddeformableobjects. However,unlikeMetaUrban,thesesimulatorsare
focusedonindoorenvironmentswithparticulartaskslikeobjectrearrangementandmanipulation.
DrivingEnvironments. Platformsfordrivingenvironmentsaremainlydesignedforautonomous
vehicle research and development. Simulators like GTA V [50], Sim4CV [51], AIRSIM [69],
CARLA[19],anditsextensionSUMMIT[7]offerrealisticenvironmentsthatmimicthephysical
world’sdetailedvisuals,weatherconditions,andday-to-nighttransitions. Othersimulatorsenhance
efficiencyandextensibilityattheexpenseofvisualrealism,suchasUdacity[75],DeepDrive[74],
Highway-env [39], and DriverGym [37]. MetaDrive [44] trades off between visual quality and
efficiency,offeringalightweightdrivingsimulatorthatcansupporttheresearchofgeneralizableRL
algorithmsforvehicles. Althoughsomeofthesimulators[50,19]involvetrafficparticipantsother
thanvehicles,suchaspedestriansandcyclists,allofthemfocusonvehicle-centricdrivingscenarios
andneglectenvironmentsandthingshappeninginpublicurbanspaceslikesidewalksandplazas.
SocialNavigationEnvironments. Otherthanindooranddrivingenvironments,socialnavigation
platforms emphasize the social compatibility of robots. Simulators like Crowd-Nav [8], Gym-
Collision-Avoidance[22],andSocial-Gym2.0[71],modelscenesandagentsin2Dmaps,focusing
moreonthedevelopmentofpathplanningalgorithms. Othersimulators,suchasHuNavSim[59],
SEAN2.0[76],andSocNavBench[5],upgradetheenvironmentto3Dspaceandintroducehuman
pedestrianstosupportthedevelopmentofmorecomplexalgorithms. However,socialnavigation
platformsfocusoncrowdnavigation,withoversimplifiedobjectsandsurroundingenvironmental
structuresinthescenes. Thisproposedplatformaddressesthegapbetweentheexistingsocialnaviga-
tionplatformsandthereal-worldurbanspacesregardingenvironmentaldiversityandcomplexity.
We will compare MetaUrban with other simulators below, through the scale, sensor, and feature
dimensions. For the scale, MetaUrban can generate infinite scenes with a procedural generation
pipeline. Italsoprovidesthelargestnumberofhumans(1,100)andmovements(2,314)amongall
simulationenvironments. Forthesensor,MetaUrbanprovidesRGBD,semantic,andlidar,while
acousticisournextsteptobettersupportmulti-modeltasks. Forthefeature,differentfromother
simulators,MetaUrbanprovidesreal-worlddistributionoftheobject’scategoriesandusesamore
sophisticatedpathplanalgorithmtogetnaturalhumantrajectories. Italsoprovidesflexibleuser
interfaces–mouse,keyboardandjoystickandracingwheel,whichvastlyeasethecollectionofhuman
expertdemonstrationdata. MetaUrbanusesPyBulletasitsphysicalengine,whichisopen-source
3andhighlyaccurateinphysicssimulation,providingacost-effectiveandflexiblesolutionforfuture
developments. MetaUrbanusesPanda3D[27]forrendering,whichisalightweight,open-source
game engine with seamless Python integration, providing a flexible and accessible development
environment. AdetailedcomparisontableisincludedintheAppendix.
Insummary,noneoftherecentsimulationplatformshavebeenconstructedforurbanspaces,and
theproposedsimulatordiffersfromthemsignificantlyintermsofdiverselayouts,objects,human
dynamics,anddifferenttypesofmobileagentslikedeliveryrobots,electricwheelchairs,robotdogs,
humanoidrobots,andvehicles,andtheirintricateinteractions. WebelieveMetaUrbancanprovidea
lotofnewresearchopportunitiesforEmbodiedAIinurbansettings.
3 MetaUrbanSimulator
MetaUrbanisacompositionalsimulationplatformthatcangenerateinfinitetrainingandevaluation
environmentsforEmbodiedAIinurbanspaces. Figure2depictstheproceduralgenerationpipeline.
MetaUrban uses a structured description script to create urban scenes. Based on the provided
informationaboutstreetblocks,sidewalks,objects,agents,andmore,itstartswiththestreetblock
map,thenplansthegroundlayoutbydividingdifferentfunctionzones,thenplacesstaticobjects,and
finallypopulatesdynamicagents.
Figure 2: Procedural generation. MetaUrban can automatically generate complex urban scenes with its
compositionalnature. Fromthesecondtothefourthcolumn,thetoprowshowsthe2Droadmaps,andthe
bottomrowshowsthebird-eyeviewof3Dscenes.
ThissectionhighlightsthreekeydesignsintheMetaUrbansimulatortosupportexhibitingthree
uniquecharacteristicsofurbanspaces–diverselayouts,particularobjectdistribution,andcomplex
dynamics. Section3.1introducesHierarchicalLayoutGeneration,whichcaninfinitelygenerate
diverse layouts with different functional zone divisions and object locations that are critical for
thegeneralizabilityofagents. Section3.2introducesScalableObjectRetrieval,whichharnesses
worldwideurbanscenedatatoobtainreal-worldobjectdistributionsindifferentplaces,andthen
builds large-scale, high-quality static objects set with VLM-enabled open-vocabulary searching.
It is useful for training agents specialized for urban scenes. Section 3.3 introduces Cohabitant
Populating,inwhichweleveragetheadvancementsindigitalhumanstoenrichtheappearances,
movements,andtrajectoriesofpedestriansandvulnerableroadusers,aswellasincorporateother
agentstoformavividcohabitingenvironment. Itiscriticalforimprovingthesocialconformityand
safetyofthemobileagents.
3.1 HierarchicalLayoutGeneration
Thediversityofscenelayout,i.e.,theconnectionandcategoriesofblocks,thespecificationsofside-
walksandcrosswalks,aswellastheplacementofobjects,iscrucialforenhancingthegeneralizability
oftrainedagentsmaneuveringinpublicspaces. Inthehierarchicallayoutgenerationframework,
westartbysamplingthecategoriesofstreetblocksanddividingsidewalksandcrosswalksandthen
allocatevariousobjects,withwhichwecangetinfiniteurbanscenelayoutswitharbitrarysizesand
specificationsofmaps.
Groundplan. Wedesign5typicalstreetblockcategories,i.e.,straight,intersection,roundabout,
circle,andT-junction. Inthesimulator,toformalargemapwithseveralblocks,wecansamplethe
4category,number,andorderofblocks,aswellasthenumberandwidthoflanesinoneblock,toget
differentmaps. Then,eachblockcansimulateitsownwalkableareas–sidewalksandcrosswalks,
whicharekeyareasforurbanspaceswithplentyofinteractions.
Figure3:Groundplan.(Left)Sidewalkisdividedintofourfunctionalzones–building,frontage,clear,and
furnishingzone.(Right)Seventypicalsidewalktemplates–from(a)to(g).
AsshowninFigure3(left),accordingtotheGlobalStreetDesignGuide[31]providedbytheGlobal
DesigningCitiesInitiative,wedividethesidewalkintofourfunctionalzones–buildingzone,frontage
zone,clearzone,andfurnishingzone. Basedontheirdifferentcombinationsoffunctionalzones,we
furtherconstruct7typicaltemplatesforsidewalks(Figure3(right)). Toformasidewalk,wecanfirst
samplethelayoutfromthetemplatesandthenassignproportionsfordifferentfunctionzones. For
crosswalks,weprovidecandidatesatthestartandtheendofeachroadway,whichsupportspecifying
theneededcrosswalksorsamplingthembyadensityparameter. Finally,roadways,sidewalks,and
crosswalkscantakeaterrainmapassubstratetoformdifferentgroundsituations.
Objectplacement. Afterdeterminingthegroundlayout,wecanplaceobjectsontheground. We
divideobjectsintothreeclasses. 1)Standardinfrastructure,suchaspoles,trees,andsigns,areplaced
periodically along the road. 2) Non-standard infrastructure, such as buildings, bonsai, and trash
bins, are placed randomly in the designated function zones. 3) Clutter, such as drink cans, bags,
andbicycles,areplacedrandomlyacrossallfunctionalzones. Wecangetdifferentstreetstylesby
specifying an object pool while getting different compactness by specifying a density parameter.
Figure4showsdifferentobjectsplacedwithasampledgroundplanandobjects’location.
Figure4:Objectplacement.PlacingDifferentobjects,withthesamegroundplanandobjects’location.
3.2 ScalableObjectRetrieval
Hierarchicallayoutgenerationdecidesthescene’slayoutandwheretoplacetheobjects. However,to
makethetrainedagentsgeneralizablewhennavigatingthroughscenescomposedofvariousobjects
intherealworld,whatobjectstoplaceisanothercrucialquestion. Inthissection,weproposethe
ScalableAssetsRetrievalpipeline,inwhichwefirstgetreal-worldobjectdistributionsfromwebdata,
andthenretrieveobjectsfrom3Dassetrepositoriesthroughanopen-vocabularysearchschemabased
onVLMs. Thispipelineisflexibleandextensible: theretrievedobjectscanbescaledtoarbitrary
sizesaswecontinuetoexploitmorewebdataforscenedescriptionsandincludemore3Dassetsas
thecandidateobjects.
Real-worldobjectdistributionextraction. Urbanspaceshaveuniquestructuresandobjectdis-
tributions,suchastheinfrastructurebuiltbytheurbanplanningadministrationandcluttersplaced
bypeople. Thus, wedesignareal-worlddistributionextractionmethodtogetadescriptionpool
5depicting the frequent objects in urban spaces. As illustrated in Figure 5 (a), we first leverage
off-the-shelfacademicdatasetsforsceneunderstanding,CityScape[10]andMapillaryVistas[52],to
getalistof90objectsthatarewithhighfrequencytobeputintheurbanspace. However,thenumber
ofobjectsislimitedbecauseoftheclosed-setdefinitionsintheimagedatasets. Weintroducetwo
open-setsourcestogetbroaderobjectdistributionfromtherealworld. 1)GoogleStreetdata. We
firstcollect25,000urbanspaceimagesfrom50countriesacrosssixcontinents. Then,weharness
GPT-4o[53]andopen-setsegmentationmodelGrounded-SAM[66]toget1,075descriptionsof
objectsintheurbanpublicspace. 2)Urbanplanningdescriptiondata. Wefurthergetalistof50
essentialobjectsinpublicurbanspacesthroughathoroughsurveyof10urbandesignhandbooks.
Finally,bycombiningthesethreedatasources,wecangetanobjectdescriptionpoolwith1,215
itemsofdescriptionsthatformthereal-worldobjectcategorydistribution.
Figure5:Scalableassetsretrieval.(a)Real-worlddistributionextraction.Wegetobjectdistributionforurban
spacesfromthreesources:academicdatasets,GoogleStreetdata,andtextdescriptiondata.(b)Open-vocabulary
search.WeusetheVLMtogetimageandtextembedding,respectively.Then,basedontherelevantscores,we
cangettheobjectswithhighrankings.
Open-vocabularysearch. Therecentdevelopmentoflarge-scale3Dobjectrepositories[16,14,80]
enablesefficientlyconstructingadatasetforaspecificscene. However,theselargerepositorieshave
threeintrinsicissuestoharnesstheserepositories: 1)mostofthedataisunrelatedtotheurbanscene,
2)thedataqualityinlargerepositoriesisuneven,and3)thedatahasnoreliableattributeannotations.
Tothisend,weintroduceanopen-vocabularysearchmethodtotackletheseissues. Asshownin
Figure5(b), thewholepipelineisbasedonanimage-textretrievalarchitecture. Wefirstsample
objectsfromObjaverse[16]andObjaverse-XL[14]repositoriestogetprojectedmulti-viewimages.
Here,anaiveuniformviewsamplingwillbringlow-qualityharmfulimages. Following[49,48],we
selectandprioritizeinformativeviewpoints,whichsignificantlyenhanceretrievaleffectiveness. Then,
weleveragetheencoderofaVisionLanguageModelBLIP[43]toextractfeaturesfromprojected
imagesandsampleddescriptionsfromtheobjectdescriptionpool,respectively,tocalculaterelevant
scores. Then,wecangettargetobjectswithrelevantscoresuptoathreshold. Thismethodletsusget
anurban-specificdatasetwith10,000high-qualityobjectsinreal-worldcategorydistributions. In
addition,weprovideaninterfaceforcustomizingtrainingobjectsinthescenebyprovidingimages
ortextdescriptions,takingadvantageofrecentadvancesin3Dobjectreconstruction[46,34]and
generation[60,9].
3.3 CohabitantPopulating
Inthissection,wewilldescribehowtopopulatethesestaticurbansceneswithvariedagentsregarding
appearances,movements,andtrajectoriesthroughCohabitantPopulating.
Following BEDLAM [6] and AGORA [57], we represent humans as parametric human model
SMPL-X[58],inwhichthe3Dhumanbodyiscontrolledbyasetofparametersforposeθ,shape
β,andfacialexpressionϕ,respectively. Then,builtuponSynBody[81]’sassetrepository,1,100
3Driggedhumanmodelsareproceduallygeneratedbysamplingfrom68garments, 32hairs, 13
beards,46accessories,and1,038clothandskintextures. Toformsafety-criticalscenarios,wealso
includevulnerableroaduserslikebikers,skateboarders,andscooterriders. Fortheotheragents,we
incorporatethe3DassetsofCOCORoboticsandStarship’sdeliveryrobots,DriveMedical’selectric
wheelchair,BostonDynamic’srobotdog,andAgilityRobotics’humanoidrobot.
Weprovidetwokindsofhumanmovementsinthesimulator–dailymovementsanduniquemove-
ments. Dailymovementsprovidethebasichumandynamicsindailylife, i.e., idle, walking, and
running. Uniquemovementsarethecomplicateddynamicsthatappearrandomlyinpublicspaces,
6suchasdancingandexercising. WeharnesstheBEDLAMdataset[6]toobtain2,311uniquemove-
ments. Forhumansandotheragentswithdailymovements,wesimulatetheirtrajectoriesusingthe
ORCA[77]socialforcesmodelandPushandRotate(P&R)algorithm[11]. ORCA[77]usesajoint
optimizationandacentralizedcontrollerthatguaranteesthatagentswillnotcollidewitheachother
oranyotherobjectsidentifiedasobstacles. PushandRotate(P&R)[11]isamulti-agentpath-finding
algorithmthatcanresolveanypotentialdeadlockbylocalcoordination. Inthefuture,aninteresting
directionistoendowpersonaltraitslikejob,personality,andpurposetohumansandharnessthe
advantagesofLLMs[1]andLVMs[45]toenablesocial[62]andinteractivebehaviors[55]ofhumans
inurbanscenes.
4 MetaUrban-12KDataset
DatasetConstruction. BasedontheMetaUrbansimulator,weconstructtheMetaUrban-12Kdataset,
including12,800interactiveurbanscenesfortraining(MetaUrban-train)and1,000scenesfortesting
(MetaUrban-test). For the train and test sets, we sample randomly from the 6 templates (a-f) of
sidewalksshowninFigure3(right)withthesamedistributionsofobjectsanddynamics. Wefurther
constructanunseentestset(MetaUrban-unseen)with100scenesforzero-shotexperiments,inwhich
wesamplefromtheunseentemplate(g)–WideCommercialSidewalk,unseenobjects,trajectories
ofagentswithfurtherdesigners’manualadjustmentsaccordingtoreal-worldscenes. Inaddition,
to enable the fine-tuning experiments, we construct a training set of 1,000 scenes with the same
distributionofMetaUrban-unseen,termedMetaUrban-finetune. 12Kscenescanbegeneratedin12
hoursonalocalworkstation. Notably,ourMetaUrbanplatformcaneasilyextendthescaleofurban
scenesfromamulti-blockleveltoawholecitylevel. ToenabletheOfflineRLandILtraining,we
collectexpertdemonstrationdatafromawell-trainedRLagentandhumanoperators,forming30,000
stepsofhigh-qualitydemonstrationdata. Thesuccessrateofthedemonstrationdatais60%,which
canbetakenasareferencefortheexperimentsofOfflineRLandIL.TheAppendixprovidesdetailed
visualizationsoftheMetaUrban-12Kdataset.
Figure6:MetaUrban-12Kstatistics.
Statistics. Scenes in this dataset are connected by one to three street blocks covering average
20,000m2areas. Thereareaverage0.03staticobjectsperm2and10dynamicagentsperstreetblock.
Theaveragedistancebetweeneachtwoobjectsis0.7m. Figure6showsdistributionsofthenumber
ofobjects(left),areasofobjectsoccupying(middle),andepisodelength(right). Asshowninthe
distributionofobjectnumbers, therearelotsofobjectsineachscenariowithaminimalvalueof
300. Asshowninthedistributionofobjects’areas,objectsinthedatasetoccupylargeareas,which
complieswithanormaldistributioncenteredat5,250m2. Asshowninthedistributionofepisode
length,theaverageepisodeis410mandmorethan20%ofthemaremorethan800steps–90m.
Fromthesedistributions,wecanobservethatscenesaresignificantlychallenginginMetaUrban-12K
foragentstonavigatethrough,whicharecrowdedandwithlonghorizons.
5 Experiments
Experimentalsettings. Tasks. Wedesigntwocommontasksinurbanscenes: PointNavigation
(PointNav)andSocialNavigation(SocialNav). InPointNav,theagent’sgoalistonavigatetothe
targetcoordinatesinstaticenvironmentswithoutaccesstoapre-builtenvironmentmap. InSocialNav,
theagentisrequiredtoreachapointgoalindynamicenvironmentsthatcontainmovingenvironmental
7agents. Theagentshallavoidcollisionsorproximitytoenvironmentalagentsbeyondthresholdsto
avoidpenalization(distance<0.2meters). Theagent’sactionspaceintheexperimentsconsistsof
acceleration,brake,andsteering. TheobservationscontainavectordenotingtheLiDARsignal,a
vectorsummarizingtheagent’sstate,andthenavigationinformationthatguidestheagenttowardthe
destination. Methods. Weevaluate7typicalbaselinemodelstobuildcomprehensivebenchmarks
on MetaUrban, across Reinforcement Learning (PPO [68]), Safe Reinforcement Learning (PPO-
Lag[64],andPPO-ET[72]),OfflineReinforcementLearning(IQL[36]andTD3+BC[23]),and
ImitationLearning(BC[3]andGAIL[30]). Evaluationmetrics. Theagentisevaluatedusingthe
SuccessRate(SR)andSuccessweightedbyPathLength(SPL)[2,4]metrics,whichmeasurethe
success and efficiency of the path taken by the agent. For SocialNav, except Success Rate (SR),
theSocialNavigationScore(SNS)[12],isalsousedtoevaluatethesocialcomplicityoftheagent.
Forbothtasks,wefurtherreporttheCumulativeCost(CC)[44]toevaluatethesafetypropertiesof
theagent. Itrecordsthecrashfrequencytoobstaclesorenvironmentalagents. Pleaserefertothe
Appendixfordetailsofmodels,rewards,andhyperparameters.
Table1:Benchmarks.ThebenchmarkofPointNavandSocialNavtasksontheMetaUrban-12Kdataset.Seven
representativemethodsofRL,safeRL,offlineRL,andILareevaluatedforeachbenchmark. indicatethe
bestperformanceamongonlinemethods(RLandSafeRL)andofflinemethods(offlineRLandIL),respectively.
PointNav SocialNav
Category Method
Test Zero-shot Test Zero-shot
SR↑ SPL↑ Cost↓ SR↑ SPL↑ Cost↓ SR↑ SNS↑ Cost↓ SR↑ SNS↑ Cost↓
RL PPO[68] 0.66 0.64 0.51 0.49 0.45 0.78 0.34 0.64 0.66 0.24 0.57 0.51
PPO-Lag[64] 0.60 0.58 0.41 0.60 0.57 0.53 0.17 0.51 0.33 0.08 0.47 0.50
SafeRL
PPO-ET[72] 0.57 0.53 0.47 0.53 0.49 0.65 0.05 0.52 0.26 0.02 0.50 0.62
IQL[36] 0.36 0.33 0.49 0.30 0.27 0.63 0.36 0.67 0.39 0.27 0.62 3.05
OfflineRL
TD3+BC[23] 0.29 0.28 0.77 0.20 0.20 1.16 0.26 0.61 0.62 0.32 0.64 1.53
BC[3] 0.36 0.28 0.83 0.32 0.26 1.15 0.28 0.56 1.23 0.18 0.54 0.58
IL
GAIL[30] 0.47 0.36 1.05 0.40 0.32 1.46 0.34 0.63 0.71 0.28 0.61 0.67
5.1 Benchmarks
WebuildtwobenchmarksontheMetaUrban-12KdatasetforPointNavandSocialNavtasks. Wetrain
7typicalbaselinesontheMetaUrban-traindatasetandthenevaluatethemontheMetaUrban-test
set. WeusethedemonstrationdataprovidedinMetaUrban-12KforofflineRLandILtraining. We
furthermakezero-shotevaluationsontheMetaUrban-unseensettodemonstratethegeneralizability
ofmodelstrainedontheMetaUrban-12Kdatasetwhiledirectlytestedonunseenenvironments.
Table1showstheresultsinthePointNavandSocialNavbenchmarks. Fromtheresults,wecandraw
4keyobservations. 1)Thetasksarefarfrombeingsolved. Thehighestsuccessratesareonly66%
and36%forPointNavandSocialNavtasksachievedbythebaselines,indicatingthedifficultyof
thesetasksintheurbanenvironmentscomposedbyMetaUrban. Notethatthesebenchmarksare
builtonamediumlevelofobjectanddynamicdensity;increasingthedensitywillfurtherdegrade
the performances shown in ablation studies. 2) Models trained on MetaUrban-12K have strong
generalizabilityinunseenenvironments. Withzero-shottesting,modelscanstillachieve41%and
26%successratesonaverageforPointNavandSocialNavtasks. Theseresultsarestrongsincethe
modelsgeneralizetonotonlyunseenobjectsandlayoutsbutalsounseendynamicsofenvironmental
agents. It demonstrates that the compositional nature of MetaUrban, supporting the coverage of
alargespectrumofcomplexurbanscenes,cansuccessfullyempowergeneralizationabilitytothe
trained models. 3) SocialNav is much harder than PointNav due to the dynamics of the mobile
environmentalagents. Onaverage,thesuccessratedecreasesby15%fromPointNavtoSocialNav,
indicatingthatdynamicagents,suchaspedestrians,vulnerableroadusers,andotheragentscommon
inurbanscenes,presentsignificantchallengestothetrainedagent. 4)SafeRLremarkablyimproves
thesafetypropertyattheexpenseofeffectiveness. Amongalltasksandsettings,thesafeRLmodels
achievethebestperformanceintheCumulativeCost,indicatingthatthesemodelsaresuccessfulat
avoidingcollisionwithpedestriansandobjects. However,thesuccessrateandSPLorSNSdecrease
accordingly,indicatingfutureeffortstobalancethesafetyandeffectivenessofagentsincomplex
urbanscenes.
85.2 AblationStudy
Inthissection,weevaluatethegeneralizability,scalingability,andeffectsofthedensityofstatic
objectsanddynamicagents. Forunifiedevaluations,weusePPOforallablationstudies. Exceptfor
theresultsondynamicdensity,weusethePointNavtask. Observationsandhyperparametersremain
thesameformodeltrainingacrossdifferentevaluations.
Figure7:Ablationstudy.(a)Evaluationofgeneralizability.(b)Evaluationofscalingability.(c)Evaluationof
thedensityofstaticobjects.(d)Evaluationofthedensityofdynamicagents.
Evaluation of generalizability. To evaluate the generalizable ability of agents trained on data
generated by MetaUrban, we compare the success rate of four settings in Figure 7 (a). Setting-
1 and Setting-2 are the results of training on MetaUrban-train while testing on MetaUrban-test
andMetaUrban-unseen,respectively. WecanobserveaperformancedroponMetaUrban-unseen.
However,thezero-shotresultsstillachieve49%successratefacingvariousout-of-distributionscenes,
demonstratingthestronggeneralizabilityofmodelstrainedonlarge-scaledatacreatedbyMetaUrban.
Setting-3andSetting-4aretheresultsofdirecttrainingonMetaUrban-finetune,andfine-tuningon
MetaUrban-finetunefromthepre-trainedmodelonMetaUrban-train. ComparedbetweenSetting-2
andSetting-3,wecanobserveanobviousperformancedrop,whichiscausedbyanunderfittingof
theinsufficientandcomplexfine-tuningdata. Setting-4outperformsSetting-3byalargemargin,
demonstratingthatthemodeltrainedontheMetaUrban-12Kdatasetcanprovideinformativepriors
asgoodinitializationsforquicktuning.
Evaluationofscalingability. ToevaluatethescalingabilityofMetaUrban’scompositionalarchi-
tecture,wetrainmodelsonadifferentnumberofgeneratedscenes,from5to1,000. Asshownin
Figure7(b),theperformanceimprovesremarkablyfrom12%to46%,asweincludemorescenesfor
training,demonstratingthestrongscalingabilityofMetaUrban. MetaUrban’scompositionalnature
hasthepotentialtoextendmorediversesceneswithalargerelementrepositoryinthefuture,which
couldfurtherboosttheagent’sperformance.
Evaluationofstaticanddynamicdensity. Toevaluatetheinfluenceofstaticobjectdensityand
dynamicenvironmentalagents,weevaluatethedifferentproportionsofthemonthePointNavand
SocialNavtasks,respectively,from1%to100%. Notethatwekeepthenumberoftrainingscenes
unchangedwhensamplingdifferentdensities. AsshowninFigure7(c)and(d),withtheincreasing
densityofbothstaticobjectsanddynamicagents,thesuccessratesofbothtrainandtestexperience
dramatic degradations, demonstrating the challenges for embodied agents when facing crowded
streets in urban scenes. In our experiments, we observe many interesting failure cases that can
indicatepromisingfuturedirectionstoimproveAI’sperformanceinMetaUrbanand,ultimately,in
real-worldurbanscenes. WemakeadetaileddiscussionintheAppendix.
6 Conclusion
We propose a new compositional simulator, MetaUrban, to facilitate embodied AI and robotics
researchinurbanscenes. MetaUrbancangenerateinfiniteurbanenvironmentswithcomplexscene
structuresanddiversemovementsofpedestriansandothermobileagents.Theseenvironmentsusedas
trainingdatacansignificantlyimprovethegeneralizabilityandsafetyoftheembodiedAIunderlying
differentmobilemachinesfromfooddeliverybotstohumanoids. Wecommitourselvestodeveloping
theopen-sourcesimulatorandfosteringthecommunityefforttoturnitintoasustainablecommunity
infrastructure.
9References
[1] JoshAchiam,StevenAdler,SandhiniAgarwal,LamaAhmad,IlgeAkkaya,FlorenciaLeoniAleman,
DiogoAlmeida,JankoAltenschmidt,SamAltman,ShyamalAnadkat,etal. Gpt-4technicalreport. arXiv
preprintarXiv:2303.08774,2023. 7,36
[2] PeterAnderson,AngelX.Chang,DevendraSinghChaplot,AlexeyDosovitskiy,SaurabhGupta,Vladlen
Koltun, Jana Kosecka, Jitendra Malik, Roozbeh Mottaghi, Manolis Savva, and Amir R. Zamir. On
evaluationofembodiednavigationagents. arXivpreprintarXiv:1807.06757,2018. 8,29
[3] MichaelBainandClaudeSammut. Aframeworkforbehaviouralcloning. InKoichiFurukawa,Donald
Michie,andStephenH.Muggleton,editors,MI,1995. 8,30
[4] DhruvBatra,AaronGokaslan,AniruddhaKembhavi,OleksandrMaksymets,RoozbehMottaghi,Manolis
Savva,AlexanderToshev,andErikWijmans. Objectnavrevisited: Onevaluationofembodiedagents
navigatingtoobjects. arXivpreprintarXiv:2006.13171,2020. 8,29
[5] AbhijatBiswas,AllanWang,GustavoSilvera,AaronSteinfeld,andHennyAdmoni. Socnavbench: A
groundedsimulationtestingframeworkforevaluatingsocialnavigation. THRI,2022. 3,28
[6] MichaelJBlack,PriyankaPatel,JoachimTesch,andJinlongYang. Bedlam:Asyntheticdatasetofbodies
exhibitingdetailedlifelikeanimatedmotion. InCVPR,2023. 6,7,27,35
[7] PanpanCai,YiyuanLee,YuanfuLuo,andDavidHsu. Summit:Asimulatorforurbandrivinginmassive
mixedtraffic. InICRA,2020. 3
[8] ChanganChen,YuejiangLiu,SvenKreiss,andAlexandreAlahi. Crowd-robotinteraction:Crowd-aware
robotnavigationwithattention-baseddeepreinforcementlearning. InICRA,2019. 3
[9] Zilong Chen, Feng Wang, and Huaping Liu. Text-to-3d using gaussian splatting. arXiv preprint
arXiv:2309.16585,2023. 6,27
[10] MariusCordts,MohamedOmran,SebastianRamos,TimoRehfeld,MarkusEnzweiler,RodrigoBenenson,
UweFranke,StefanRoth,andBerntSchiele.Thecityscapesdatasetforsemanticurbansceneunderstanding.
InCVPR,2016. 6,24
[11] BorisDeWilde,AdriaanWTerMors,andCeesWitteveen. Pushandrotate: acompletemulti-agent
pathfindingalgorithm. JAIR,2014. 7,27,29,31
[12] MattDeitke,DhruvBatra,YonatanBisk,TommasoCampari,AngelX.Chang,DevendraSinghChaplot,
ChanganChen, ClaudiaPérez-D’Arpino, KianaEhsani, AliFarhadi, LiFei-Fei, AnthonyG.Francis,
ChuangGan,KristenGrauman,DavidHall,WinsonHan,UnnatJain,AniruddhaKembhavi,JacobKrantz,
StefanLee,ChengshuLi,SagnikMajumder,OleksandrMaksymets,RobertoMartín-Martín,Roozbeh
Mottaghi,SoniaRaychaudhuri,MikeRoberts,SilvioSavarese,ManolisSavva,MohitShridhar,Niko
Sünderhauf,AndrewSzot,BenTalbot,JoshuaB.Tenenbaum,JesseThomason,AlexanderToshev,Joanne
Truong, Luca Weihs, and Jiajun Wu. Retrospectives on the embodied ai workshop. arXiv preprint
arXiv:2210.06849,2022. 8,32
[13] MattDeitke,WinsonHan,AlvaroHerrasti,AniruddhaKembhavi,EricKolve,RoozbehMottaghi,Jordi
Salvador,DustinSchwenk,EliVanderBilt,MatthewWallingford,LucaWeihs,MarkYatskar,andAli
Farhadi. Robothor:Anopensimulation-to-realembodiedAIplatform. InCVPR,2020. 2,3
[14] MattDeitke,RuoshiLiu,MatthewWallingford,HuongNgo,OscarMichel,AdityaKusupati,AlanFan,
ChristianLaforte,VikramVoleti,SamirYitzhakGadre,etal. Objaverse-xl:Auniverseof10m+3dobjects.
NeuIPS,2024. 6
[15] Matt Deitke, Ruoshi Liu, Matthew Wallingford, Huong Ngo, Oscar Michel, Aditya Kusupati, Alan
Fan,ChristianLaforte,VikramVoleti,SamirYitzhakGadre,EliVanderBilt,AniruddhaKembhavi,Carl
Vondrick,GeorgiaGkioxari,KianaEhsani,LudwigSchmidt,andAliFarhadi. Objaverse-xl:Auniverseof
10m+3dobjects. arXivpreprintarXiv:2307.05663,2023. 27
[16] MattDeitke,DustinSchwenk,JordiSalvador,LucaWeihs,OscarMichel,EliVanderBilt,LudwigSchmidt,
KianaEhsani,AniruddhaKembhavi,andAliFarhadi. Objaverse:Auniverseofannotated3dobjects. In
CVPR,2023. 6
[17] MattDeitke,DustinSchwenk,JordiSalvador,LucaWeihs,OscarMichel,EliVanderBilt,LudwigSchmidt,
KianaEhsani,AniruddhaKembhavi,andAliFarhadi. Objaverse:Auniverseofannotated3dobjects. In
ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition,pages13142–
13153,2023. 27
[18] MattDeitke,EliVanderBilt,AlvaroHerrasti,LucaWeihs,KianaEhsani,JordiSalvador,WinsonHan,Eric
Kolve,AniruddhaKembhavi,andRoozbehMottaghi. Procthor:Large-scaleembodiedaiusingprocedural
generation. NeuIPS,2022. 2,3,28
[19] AlexeyDosovitskiy,GermanRos,FelipeCodevilla,AntonioLopez,andVladlenKoltun. Carla:Anopen
urbandrivingsimulator. InCoRL,2017. 2,3,28
[20] KianaEhsani,WinsonHan,AlvaroHerrasti,EliVanderBilt,LucaWeihs,EricKolve,AniruddhaKembhavi,
andRoozbehMottaghi. Manipulathor:Aframeworkforvisualobjectmanipulation. InCVPR,2021. 3
[21] MartinEster,Hans-PeterKriegel,JorgSander,XiaoweiXu,etal.Adensity-basedalgorithmfordiscovering
clustersinlargespatialdatabaseswithnoise. Inkdd,volume96,pages226–231,1996. 24
[22] MichaelEverett,YuFanChen,andJonathanP.How. Motionplanningamongdynamic,decision-making
agentswithdeepreinforcementlearning. InIROS,2018. 3
[23] ScottFujimotoandShixiangShaneGu. Aminimalistapproachtoofflinereinforcementlearning. NeuIPS,
2021. 8,30
10[24] ChuangGan,JeremySchwartz,SethAlter,DamianMrowca,MartinSchrimpf,JamesTraer,JulianDe
Freitas, JonasKubilius, AbhishekBhandwaldar, NickHaber, MegumiSano, KunoKim, EliasWang,
MichaelLingelbach,AidanCurtis,KevinT.Feigelis,DanielBear,DanGutfreund,DavidD.Cox,Antonio
Torralba,JamesJ.DiCarlo,JoshTenenbaum,JoshH.McDermott,andDanYamins. Threedworld: A
platformforinteractivemulti-modalphysicalsimulation. InNeurIPSDatasetsandBenchmarks,2021. 2,
3,28
[25] TimnitGebru,JamieH.Morgenstern,BrianaVecchione,JenniferWortmanVaughan,HannaM.Wallach,
HalDaumé,andKateCrawford. Datasheetsfordatasets. Comm.oftheACM,2021. 35
[26] PatrickGeddes. CitiesinEvolution. 1949. 2
[27] MikeGoslinandMarkRMine. Thepanda3dgraphicsengine. Computer,2004. 4,28
[28] PeterHallandMarkTewdwr-Jones. Urbanandregionalplanning. Routledge,2019. 2
[29] GansHerbert. TheUrbanVillagers:GroupandClassintheLifeofItalian-Americans. 1962. 2
[30] JonathanHoandStefanoErmon. Generativeadversarialimitationlearning. NeuIPS,2016. 8,30
[31] GlobalDesigningCitiesInitiativeandNationalAssociationofCityTransportationOfficials. Globalstreet
designguide. IslandPress,2016. 5,23
[32] JaneJacobs. TheDeathandLifeofGreatAmericanCities. 1961. 2
[33] JiamingJi,JiayiZhou,BorongZhang,JuntaoDai,XuehaiPan,RuiyangSun,WeidongHuang,Yiran
Geng,MickelLiu,andYaodongYang. Omnisafe:Aninfrastructureforacceleratingsafereinforcement
learningresearch. arXivpreprintarXiv:2305.09304,2023. 30
[34] BernhardKerbl,GeorgiosKopanas,ThomasLeimkühler,andGeorgeDrettakis. 3dgaussiansplattingfor
real-timeradiancefieldrendering. TOG,2023. 6,27
[35] EricKolve,RoozbehMottaghi,WinsonHan,EliVanderBilt,LucaWeihs,AlvaroHerrasti,MattDeitke,
KianaEhsani,DanielGordon,YukeZhu,KembhaviAniruddha,GuptaAbhinav,andFarhadiAli. Ai2-thor:
Aninteractive3denvironmentforvisualai. arXivpreprintarXiv:1712.05474,2017. 2,3,28
[36] IlyaKostrikov,AshvinNair,andSergeyLevine. Offlinereinforcementlearningwithimplicitq-learning.
arXivpreprintarXiv:2110.06169,2021. 8,30
[37] ParthKothari, ChristianPerone, LucaBergamini, AlexandreAlahi, andPeterOndruska. Drivergym:
Democratisingreinforcementlearningforautonomousdriving. arXivpreprintarXiv:2111.06889,2021. 3
[38] DanielKrajzewicz,GeorgHertkorn,ChristianRössel,andPeterWagner. Sumo(simulationofurban
mobility)-anopen-sourcetrafficsimulation. InMESM,2002. 2,28
[39] EdouardLeurent. Anenvironmentforautonomousdrivingdecision-making. https://github.com/
eleurent/highway-env,2018. 3
[40] ChengshuLi, FeiXia, RobertoMartín-Martín, MichaelLingelbach, SanjanaSrivastava, BokuiShen,
KentElliottVainio,CemGokmen,GokulDharan,TanishJain,AndreyKurenkov,C.KarenLiu,Hyowon
Gweon, JiajunWu, LiFei-Fei, andSilvioSavarese. igibson2.0: Object-centricsimulationforrobot
learningofeverydayhouseholdtasks. InCoRL,2021. 3,28
[41] ChengshuLi,RuohanZhang,JosiahWong,CemGokmen,SanjanaSrivastava,RobertoMartín-Martín,
ChenWang,GabraelLevine,WensiAi,BenjaminMartinez,HangYin,MichaelLingelbach,Minjune
Hwang,AyanoHiranaka,SujayGarlanka,ArmanAydin,SharonLee,JiankaiSun,MonaAnvari,Manasi
Sharma,DhruvaBansal,SamuelHunter,Kyu-YoungKim,AlanLou,CalebR.Matthews,IvanVilla-
Renteria,JerryHuayangTang,ClaireTang,FeiXia,YunzhuLi,SilvioSavarese,HyowonGweon,C.Karen
Liu,JiajunWu,andLiFei-Fei. Behavior-1k: Ahuman-centered,embodiedaibenchmarkwith1,000
everydayactivitiesandrealisticsimulation. CoRL,2024. 2,3,28
[42] JunnanLi,DongxuLi,SilvioSavarese,andStevenHoi.Blip-2:Bootstrappinglanguage-imagepre-training
withfrozenimageencodersandlargelanguagemodels,2023. 27
[43] JunnanLi,DongxuLi,CaimingXiong,andStevenHoi. Blip:Bootstrappinglanguage-imagepre-training
forunifiedvision-languageunderstandingandgeneration. InICML,2022. 6
[44] Quanyi Li, Zhenghao Peng, Lan Feng, Qihang Zhang, Zhenghai Xue, and Bolei Zhou. Metadrive:
Composingdiversedrivingscenariosforgeneralizablereinforcementlearning. TPAMI,2022. 2,3,8,15,
27,28,29,31
[45] HaotianLiu,ChunyuanLi,QingyangWu,andYongJaeLee. Visualinstructiontuning. NeuIPS,2023. 7,
36
[46] RuoshiLiu,RundiWu,BasileVanHoorick,PavelTokmakov,SergeyZakharov,andCarlVondrick. Zero-
1-to-3:Zero-shotoneimageto3dobject. InProceedingsoftheIEEE/CVFInternationalConferenceon
ComputerVision,2023. 6,27
[47] ShilongLiu,ZhaoyangZeng,TianheRen,FengLi,HaoZhang,JieYang,ChunyuanLi,JianweiYang,
HangSu,JunZhu,etal. Groundingdino:Marryingdinowithgroundedpre-trainingforopen-setobject
detection. arXivpreprintarXiv:2303.05499,2023. 24
[48] TiangeLuo,JustinJohnson,andHonglakLee. Viewselectionfor3dcaptioningviadiffusionranking.
arXivpreprintarXiv:2404.07984,2024. 6,27
[49] TiangeLuo,ChrisRockwell,HonglakLee,andJustinJohnson. Scalable3dcaptioningwithpretrained
models. NeuIPS,2023. 6,27
[50] MarkMartinez,ChawinSitawarin,KevinFinch,LennartMeincke,AlexYablonski,andAlainKornhauser.
Beyondgrandtheftautovfortraining,testingandenhancingdeeplearninginselfdrivingcars. arXiv
preprintarXiv:1712.01397,2017. 3
[51] MatthiasMüller,VincentCasser,JeanLahoud,NeilSmith,andBernardGhanem.Sim4cv:Aphoto-realistic
simulatorforcomputervisionapplications. IJCV,2018. 3
11[52] GerhardNeuhold,TobiasOllmann,SamuelRotaBulo,andPeterKontschieder. Themapillaryvistas
datasetforsemanticunderstandingofstreetscenes. InICCV,2017. 6,24
[53] OpenAI. Gpt-4o. https://openai.com/index/hello-gpt-4o/,2024. 6,24
[54] OpenStreetMap contributors. Planet dump retrieved from https://planet.osm.org . https://www.
openstreetmap.org,2017. 24
[55] JoonSungPark,JosephO’Brien,CarrieJunCai,MeredithRingelMorris,PercyLiang,andMichaelS
Bernstein. Generativeagents:Interactivesimulacraofhumanbehavior. InUIST,2023. 7,36
[56] RobertEzraPark,ErnestWatsonBurgess,RoderickDuncanMcKenzie,andLouisWirth. TheCity. 1925.
2
[57] PriyankaPatel,Chun-HaoPHuang,JoachimTesch,DavidTHoffmann,ShashankTripathi,andMichaelJ
Black. Agora:Avatarsingeographyoptimizedforregressionanalysis. InCVPR,2021. 6
[58] GeorgiosPavlakos,VasileiosChoutas,NimaGhorbani,TimoBolkart,AhmedA.A.Osman,Dimitrios
Tzionas,andMichaelJ.Black. Expressivebodycapture:3Dhands,face,andbodyfromasingleimage. In
CVPR,2019. 6
[59] NoéPérez-Higueras,RobertoOtero,FernandoCaballero,andLuisMerino. Hunavsim:Aros2human
navigationsimulatorforbenchmarkinghuman-awarerobotnavigation. arXivpreprintarXiv:2305.01303,
2023. 3,28
[60] BenPoole,AjayJain,JonathanTBarron,andBenMildenhall.Dreamfusion:Text-to-3dusing2ddiffusion.
InICLR,2023. 6,27
[61] XavierPuig, KevinRa, MarkoBoben,JiamanLi, TingwuWang, SanjaFidler, andAntonioTorralba.
Virtualhome:Simulatinghouseholdactivitiesviaprograms. InCVPR,2018. 2,3
[62] XavierPuig,TianminShu,JoshuaBTenenbaum,andAntonioTorralba. Nopa:Neurally-guidedonline
probabilisticassistanceforbuildingsociallyintelligenthomeassistants. InICRA,2023. 7,36
[63] XavierPuig,EricUndersander,AndrewSzot,MikaelDallaireCote,Tsung-YenYang,RuslanPartsey,
RutaDesai,AlexanderWilliamClegg,MichalHlavac,SoYeonMin,VladimirVondrus,ThéophileGervet,
Vincent-PierreBerges,JohnM.Turner,OleksandrMaksymets,ZsoltKira,MrinalKalakrishnan,Jitendra
Malik,DevendraSinghChaplot,UnnatJain,DhruvBatra,AksharaRai,andRoozbehMottaghi. Habitat
3.0:Aco-habitatforhumans,avatars,androbots. InICLR,2023. 3,28
[64] AlexRay,JoshuaAchiam,andDarioAmodei. Benchmarkingsafeexplorationindeepreinforcement
learning. arXivpreprintarXiv:1910.01708,2019. 8,29,30
[65] NilsReimersandIrynaGurevych. Sentence-bert:Sentenceembeddingsusingsiamesebert-networks. In
Proceedingsofthe2019ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.Association
forComputationalLinguistics,112019. 24
[66] TianheRen,ShilongLiu,AilingZeng,JingLin,KunchangLi,HeCao,JiayuChen,XinyuHuang,Yukang
Chen,FengYan,etal. Groundedsam: Assemblingopen-worldmodelsfordiversevisualtasks. arXiv
preprintarXiv:2401.14159,2024. 6,24
[67] ManolisSavva,JitendraMalik,DeviParikh,DhruvBatra,AbhishekKadian,OleksandrMaksymets,Yili
Zhao,ErikWijmans,BhavanaJain,JulianStraub,JiaLiu,andVladlenKoltun. Habitat:Aplatformfor
embodiedAIresearch. InICCV,2019. 2,3
[68] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy
optimizationalgorithms. arXivpreprintarXiv:1707.06347,2017. 8,29
[69] ShitalShah,DebadeeptaDey,ChrisLovett,andAshishKapoor. Airsim:High-fidelityvisualandphysical
simulationforautonomousvehicles. InFSR,2018. 3
[70] BokuiShen,FeiXia,ChengshuLi,RobertoMartín-Martín,LinxiFan,GuanzhiWang,ClaudiaPérez-
D’Arpino,ShyamalBuch,SanjanaSrivastava,LyneTchapmi,TchapmiMicael,VainioKent,WongJosiah,
Fei-FeiLi,andSavareseSilvio.igibson1.0:asimulationenvironmentforinteractivetasksinlargerealistic
scenes. InIROS,2021. 2,3
[71] Zayne Sprague, Rohan Chandra, Jarrett Holtz, and Joydeep Biswas. Socialgym 2.0: Simulator for
multi-agentsocialrobotnavigationinsharedhumanspaces. arXivpreprintarXiv:2303.05584,2023. 3
[72] HaoSun,ZipingXu,MengFang,ZhenghaoPeng,JiadongGuo,BoDai,andBoleiZhou. Safeexploration
bysolvingearlyterminatedmdp. arXivpreprintarXiv:2107.04200,2021. 8,29,30
[73] AndrewSzot,AlexanderClegg,EricUndersander,ErikWijmans,YiliZhao,JohnM.Turner,NoahMaestre,
MustafaMukadam,DevendraSinghChaplot,OleksandrMaksymets,AaronGokaslan,VladimirVondrus,
SameerDharur,FranziskaMeier,WojciechGaluba,AngelX.Chang,ZsoltKira,VladlenKoltun,Jitendra
Malik,ManolisSavva,andDhruvBatra. Habitat2.0:Traininghomeassistantstorearrangetheirhabitat.
InNeuIPS,2021. 2,3
[74] DeepdriveTeam. Deepdrive: asimulatorthatallowsanyonewithapctopushthestate-of-the-artin
self-driving. https://github.com/deepdrive/deepdrive. 3
[75] UdacityTeam. Udacity’sself-drivingcarsimulator:Aself-drivingcarsimulatorbuiltwithunity. https:
//github.com/udacity/self-driving-car-sim. 3
[76] NathanTsoi,AlecXiang,PeterYu,SamuelSSohn,GregSchwartz,SubashriRamesh,MohamedHussein,
AnjaliWGupta,MubbasirKapadia,andMarynelVázquez. Sean2.0:Formalizingandgeneratingsocial
situationsforrobotnavigation. RAL,2022. 3,28
[77] JurVanDenBerg,StephenJGuy,MingLin,andDineshManocha. Reciprocaln-bodycollisionavoidance.
InISRR,2011. 7,27,29,31
[78] StephenVictorWard. Planningthetwentieth-centurycity:theadvancedcapitalistworld. 2002. 2
[79] WilliamHWhyte. City:Rediscoveringthecenter. UniversityofPennsylvaniaPress,2012. 2
12[80] TongWu,JiaruiZhang,XiaoFu,YuxinWang,JiaweiRen,LiangPan,WayneWu,LeiYang,JiaqiWang,
ChenQian,DahuaLin,andZiweiLiu. Omniobject3d:Large-vocabulary3dobjectdatasetforrealistic
perception,reconstructionandgeneration. InCVPR,2023. 6
[81] ZhitaoYang,ZhongangCai,HaiyiMei,ShuaiLiu,ZhaoxiChen,WeiyeXiao,YukunWei,ZhongfeiQing,
ChenWei,BoDai,WayneWu,ChenQian,DahuaLin,ZiweiLiu,andLeiYang. Synbody: Synthetic
datasetwithlayeredhumanmodelsfor3dhumanperceptionandmodeling. InICCV,2023. 6,22,35
13Appendix
A MetaUrbanVisualization 15
A.1 StaticSceneSamples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
A.2 DynamicSceneSamples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
A.3 StaticAssetSamples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
A.4 DynamicAssetSamples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
B MetaUrbanSimulator 22
B.1 LayoutGeneration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
B.2 ObjectRetrieval . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
B.3 CohabitantPopulating . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
B.4 SceneCustomization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
B.5 UserInterface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
B.6 SimulatorComparison . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
C ExperimentDetails 28
C.1 PointNavExperiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
C.2 SocialNavExperiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
D Datasheet 33
E Performance 36
F Discussion 36
14A MetaUrbanVisualization
A.1 StaticSceneSamples
Streetblocks. Wedesignfivetypicalstreetblockcategories–straight,curve,intersection,T-junction,
androundabout.Inthesimulator,toformalargemapwithseveralblocks,wecansamplethecategory,
number,order,lanenumber,andotherrelatedparametersoftheblocks. WeusethealgorithmBlock
IncrementalGeneration(BIG)proposedinMetaDrive[44]togeneratethetargetroadnetworkdefined
byusers. Figure8providesdemonstrationsofgeneratedstreetmapscomposedofdifferentnumbers
ofblocks.
Figure8:Examplesofblockmaps.Generatedblockmapswithadifferentnumberofstreetblocks.
Groundlayouts. Weconstructseventypicaltemplatesforsidewalks,moredetailsaboutthedesign
andthegenerationprocessaregivenintheSectionB.1.
AsshowninFigure9,differenttypesofsidewalkscanbesampledonthesamestreetblock;each
typehasitsuniquedivisionandspecificationoffunctionalzones. Figure10furthershowsseveral
blockmapswithadifferenttypeofsidewalks.
15Figure9:Examplesofsidewalks.Generatedsidewalkswithseventemplates(a)to(g).
Figure10:Examplesofblockmapswithsidewalks.Generatedblockmapswithadifferenttypeofsidewalks.
Staticobjects. Togeneratestaticobjects,webuildtheobjectplacementdistributionconditionedon
geometriczonesofsidewalks,whichwillbediscussedinSectionB.1. Tobetterdistinguishbetween
thedifficultyofscenesonthesameroadnetwork,weusetheobjectdensityρ tocontrolthecrowding
s
levelonthesidewalk.Thisindicatestheratiooftheminimumdistancetothedefaultdistancebetween
objects. Figure11showsblockmapswithdifferentobjectdensities. Wecanobservethatwhenthe
densityincreases,thewalkableregionwillbecomemoreandmorecrowded. Figure12furthergives
ego-viewresultsbyrandomlysamplingviewpointsonblockmaps.
16Figure11:Examplesofblockmapswithdifferentobjectdensities.Eachrowis5randomlysampledblock
mapswithoneobjectdensity,from20%to200%.
Figure12:Examplesofego-viewresultsinstaticscenes.Eachrowisadifferentobjectplacementwiththe
sameobjectdensity(60%).Foreachrow,wesample4viewpointstoshowego-viewresults.
17A.2 DynamicSceneSamples
Dynamicagentssuchaspedestrians,vulnerableroaduserslikebikers(skateboarders,scooterriders),
mobilemachines(deliverybots,electricwheelchairs,robotdogs,andhumanoidrobots),andvehicles
willbepresentintheenvironment. Thedensityofdynamicagentscanbecontrolledwithdynamic
densityratioρ . Figure13showsego-viewresultsbyrandomlysamplingviewpointsonblockmaps.
d
Theurbanspacesarewellpopulatedwithdifferentagents.
Figure13:Examplesofego-viewresultsindynamicscenes.Eachrowisadifferentspecificationofdynamics
(appearances,movements,andtrajectories)withthesamedynamicdensity(100%).Foreachrow,wesample4
viewpointstoshowego-viewresults.
A.3 StaticAssetSamples
Weprovide10,000high-qualitystaticobjectassets. Theroadsideinfrastructureisdividedintothree
categories: 1)Standardinfrastructure,includingpoles,trees,andsigns,isplacedatregularintervals
alongtheroad. 2)Non-standardinfrastructure,suchasbuildings,bonsai,andtrashbins,isplaced
randomlywithindesignatedzones. 3)Clutter,suchasdrinkcans,bags,andbicycles,isscattered
randomlyacrossallfunctionalzones. Figure1415and16showexamplesofthesethreecategories
respectively.
18Figure14:Examplesofstaticobjects–standardinfrastructure.
19Figure15:Examplesofstaticobjects–non-standardinfrastructure.
20Figure16:Examplesofstaticobjects–clutter.
21A.4 DynamicAssetSamples
Humanassets. MetaUrbanprovides1,100rigged3Dhumanmodels,sampledfrom68garments,
32hairs,13beards,46accessories,and1,038clothandskintexturesfromSynBody[81]dataset.
Figure17showsrandomlysampledhumans,whichhavelargevariations.
Figure17:Examplesofdynamics–riggedhumans.
Vulnerableroaduserassets. MetaUrbanprovides5kindsofvulnerableroaduserstoformsafe-
criticalscenarios. Theyarebikers,skateboarders,scooterriders,andelectricwheelchairusers,as
showninthefirstrowofFigure18. Notethatelectricwheelchairs,asahuman-AIsharedcontrol
system,canalsobeseenasmobilemachines,notonlyvulnerableroadusers.
Figure18:Examplesofdynamics–vulnerableroadusers.
Mobilemachineassets. MetaUrbanprovides6kindsofmobilemachines: Starship,YandexRover,
and COCO Robotics’ delivery bots, Boston Dynamic’s robot dog, Agility Robotics’ humanoid
robot,andDriveMedical’selectricwheelchair. Figure19showsthefirst5assets,whiletheelectric
wheelchair, as a cross-category asset (vulnerable road user and mobile machine), is shown in
Figure18.
Figure19:Examplesofdynamics–mobilemachines.
Vehicleassets. MetaUrbanprovides37kindsofvehicles,coveringdifferentbodytypes,sizes,and
appearances. Figure20shows10sampledvehicles.
B MetaUrbanSimulator
B.1 LayoutGeneration
This section gives details about the process we developed to procedurally generate scenes with
sidewalksandcrosswalks,aswellassampleandplacestaticobjectsonthesidewalk.
Groundplan. AsshowninFigure21(Top),wedefine4functionalzones and6geometriczones
forsamplingthetypeofsidewalksandchoosingthedistributionofparametersforeachsidewalk
component. AsshowninFigure21(Bottom),weconstruct7typicaltemplatesforsidewalks;each
typeofthemhasitsuniquedistributionofgeometriczones. Tomatchthedistributionwiththereal
22Figure20:Examplesofdynamics–vehicles.
world,wesetthedistributionofthezonewidthtoauniformdistributionforeachgeometriczone;
themaximumandminimumvaluesoftheuniformdistributionaresetaccordingtotheGlobalStreet
DesignGuide[31]providedbytheGlobalDesigningCitiesInitiative.
Figure21: Architectureofgroundlayouts. (Top)Themappingfromfunctionalzonestogeometriczones.
(Bottom)Specificationsofgeometriczonesfor7sidewalktemplates.
Togenerateascene,wewillfirstsamplethetemplateofthesidewalkz fromitsdistributionz ∼
Z , Z = {z ,z ,...,z }, followed by the sampling of widths of each geometric zone w ∼
T T 1 2 7 i
f (z,i), ∀i∈{1,2,...,7},wheref (z,i)isthewidthdistributionoftheithgeometriczoneunder
w w
thesidewalktemplatez.
Crosswalksarecrucialfortheconnectivityofscenes.MetaUrbanprovidescandidatesatthebeginning
andendofeachroadwayofablock.Then,locationsofthecrosswalkcanbecontrolledbyacrosswalk
densityparameterorbespecifiedbyusersdirectly.
Objectplacement. Figure22illustratestheiterativeprocessofplacingobjectsinthescene. First,
weconvertthepolygonofthegeometriczoneofthesidewalkintorectangles. Wewillplaceobjects
oneachgeometriczoneindependently. Ateachstepofplacingonthespecificzone,wecanobtain
rectanglesthatarenotoccupied. Thenwecheckfromthestartingregiontotheendingregionfor
thecurrentretrievedobjectclass. Weplaceitifpossible,orwestarttoplacethenextclass. Inthe
simulator,weuserectangleboundingboxestorepresentallobjectsphysicallytoadoptthisobject
placementmethod.
B.2 ObjectRetrieval
Distributionextraction. Distinguishedfromtherecentindoorsimulationplatform,thereareno
ready-to-use high-quality asset datasets for urban spaces. Urban spaces have their unique data
23Figure22:Iterativeobjectplacement.Givenagroundplan,wefirstconvertgeometriczonesintorectangles.
Then,weplaceobjectsonzonesonebyone.Intheplacingofeachzone,weattempttoputsampledclassesof
objectsintherectanglesonebyone.
distribution, suchastheinfrastructurebuiltbytheurbanplanningadministration(“firehydrants”
and “bus stops”) and clutters placed by people (“scooters” and “advertising boards”). Thus, we
designareal-worlddistributionextractionmethodtogetadescriptionpooldepictingwhatobjects
arefrequentlyshowninurbanspaces.
We first leverage off-the-shelf scene understanding datasets – Mapillary Vistas [52] and
CityScape[10]. Usingtheprovidedannotationpolygon, wefindtheoverlappingobjectwiththe
sidewalkandgetalistof90objectsthatarewithhighfrequencytobeputintheurbanspace(suchas
“tree”and“bench”). However,thenumberofobjectsislimitedbecauseoftheclosed-setdefinitionsin
theimagedatasets. Togetbroaderobjectdistributionfromtherealworld,weintroducetwoopen-set
sources–worldwideGoogleStreetdataandurbanplanningdescriptiondata.
For the Google Street data, we collect 25,000 urban space images from 50 countries across six
continents. Theselectionofimagelocationswasperformedbyrandomlysamplingpointsalongthe
majorroadsofcitiesusingOpenStreetMap’s[54]roadnetwork. Imageorientationwasdetermined
basedonroadgradienttoenhancetherelevanceofcapturedscenes. Forobjectdetectioninthese
images,weinitiallyemployedGPT-4o[53]togeneratealistofcandidateobjects. Thiswasfollowed
bytheapplicationofGrounded-Dino[47]toobtainboundingboxesfortheseobjects. Werefined
theseboxesusingnon-maximumsuppression(NMS)toensuretheaccuracyofobjectidentification.
FurtherrefinementwasachievedthroughtheuseoftheGrounded-SAMmodel[66], anopen-set
segmentationapproach,whichfilteredtheboundingboxestoidentifyobjectsspecificallylocated
inpublicurbanspaces. Akeypartofourmethodinvolvesdeterminingoverlapsbetweenidentified
objectsandsidewalks. Foreachobjectdetected,wecalculateitsspatialintersectionwithsidewalk
regionsderivedfromthedatasets. Thisoverlapanalysishelpsincuratingalistofobjectsthatare
relevanttourbanpublicspaces.
ToaddressthediversedescriptionsgeneratedbyGPT-4o[53]andensuresemanticuniformity,we
clustertheembeddingsofdescriptionsusingDBSCAN[21],whichresultin1,075distinctobject
clusterswithuniquedescriptors,suchas"agraytrashbin"and"pottedcactus". Weuse“all-mpnet-
base-v2”modelfromSentenceTransformers[65]toembedeachdescription.
Fortheurbanplanningdescriptiondata,wegetalistof50essentialobjectsinpublicurbanspaces
(suchas“drinkingfountains”and“bikeracks”)throughathoroughsurveyofurbandesignhandbooks.
Finally,bycombiningthesethreedatasources,wecangetanobjectdescriptionpoolwith1,215
itemsofdescriptionsthatcanformthereal-worldobjectcategorydistribution.
Figure23illustratesthedistributionofobjectsinurbanspaceextractedfromalloftheworldwidecol-
lecteddata. Houses,gates,andtreesemergeasuniversalelements,dominatingtheurbanlandscapes
acrossalldepictedcountries,reflectingtheirfundamentalroleinbothurbanandruralsettings.
Figure 24 illustrates the object distribution of example countries from 6 continents, showcasing
distinctenvironmentalandculturalcharacteristicsthroughobjectprevalence. Thedataalsohighlights
notableregionaldistinctions: Japan,forinstance,featuresahigherincidenceofpolesandroadcones,
hintingatuniqueaspectsofitsurbaninfrastructure. Incontrast,Brazil’sconsiderablefrequencyof
gatesandmetalgatessuggestsprominentarchitecturalandsecuritypreferences. Suchvariancesnot
onlyrevealthediverseurbanaestheticsandfunctionalprioritiesacrossdifferentregionsbutalso
enhanceourunderstandingofhowspecificobjectscandefinethecharacterandutilityofpublicspaces
24Figure23:Distributionofobjectsinurbanspacesforallcollecteddataworldwide.
globally. Thiscomparativeanalysisofobjectdistributionscontributessignificantlytoconstructing
region-specificsidewalks’simulationenvironments.
25Figure24:Distributionofobjectsinurbanspacesacrossdifferentcountries.Twoexampleimagesareshown
togetherwitheachdistributionfigure,demonstratinglargevariationsamongdifferentcountries.
26Open-vocabularysearch.Toeffectivelyretrievedigitalassetscorrespondingtotheobjectdescription
pool,wedevelopedarobustpipelineutilizingtheObjaverse[17]andObjaverseXL[15]repositories,
known for their extensive digital assets. The process begins with the extraction of digital assets
usingamulti-threadedapproachforfurtherprocessing. Eachdownloadedassetisthenrendered
into20distinctimages,capturingvariousanglestoprovideacomprehensivevisualrepresentation.
Following [49, 48], viewpoints with higher quality are used for the calculation of visual feature
embedding.
For the matching process, we leverage the BLIP2 [42] model, a pre-trained feature extractor, to
alignvisualdatawithourtextualdescriptions. Thisinvolvesprocessingtheimagestoextractvisual
featuresandconcurrentlytransformingtextualdescriptionsintoembeddings. Theseembeddingsare
comparedusingcosinesimilaritytodeterminethesemanticcorrespondencebetweentextandimages,
allowingustoidentifyandcollectthedigitalassetsthatbestmatchthedescriptions.
Oncetheassetsarecollected,ameticulousreviewprocessisinitiatedforeachcategory. Wemanually
inspecteachasset,filteringoutthosethatareoflowresolution,lackrealismordonotmeetourquality
standards. TheselectedassetsarethenuploadedintoMetaUrbantoadjustassetcharacteristicssuch
assize, position, andorientation. Thismeticulouscurationensuresthatonlyhigh-qualitydigital
assetsareincorporatedintoourstaticobjectdataset.
Objectrepositoryextension.MetaDriveprovidesaninterfaceforincludingobjectsenabledbyrecent
advancesin3Dcontentgeneration,suchas3Dobjectreconstruction[46,34]andgeneration[60,9].
Thus,onecaneasilyfurtherextendtheobjectrepositorywithgeneratedcontents. Also,thisfunction
canworktogetherwithscenecustomization(SectionB.4)togetcustomizedsceneswithspecific
objects.
B.3 CohabitantPopulating
Appearances. We include 1,100 3D human models, 5 kinds of vulnerable road users – bikers,
skateboarders, scooter riders, and electric wheelchair users, and 6 kinds of mobile machines as
cohabitantsintheMetaUrbansimulator. Thenumberofdynamicagentsinascenecanbesetbythe
parametersrespectively. TheenvironmentinitializationtimeandRAMusageareonlyproportionalto
thenumberofindividualagents. Forexample,100sameagentswilltakethesameinitializationtime
andRAMusageasone. Thisschemacanbeusedtosignificantlyincreasethemaximumnumberof
spawnedagentsforaspecifichardware.
Movements. Weinclude3dailymovements–idle,walking,andrunning,aswellas2,311unique
movementsfromtheBEDLAM[6]dataset. Allofthemotionsequencesaretrimmedandchecked
bydesignersonebyonetoensuretheirquality. Withthesameskeletalbinding,alloftheunique
movementscanbetransferredtoallofthe3Dhumanmodelsdirectly. Thus,wecanget1,100×
2,311numbersofhuman-motionpairs.
Trajectories.WeharnessORCA[77]andPushandRotate(P&R)algorithm[11]togetthetrajectories
ofalldynamicagents. First, webuildthe0-1maskthatindicateswhetherthegridisawalkable
regionornot. Then,wesamplethestartandendingpointsforeachagentrandomly,followedby
generatingtheir2DtrajectoriesbyusingthemodelofORCA[77]andP&R[11]. Thetrajectoryplan
processisefficient,runningwithin5sfor100agentsonaCorei9CPUprocessor. Vehicleswillalso
beaddedindynamicscenes. AlltrafficvehicleswillfollowIDMpolicies,asMetaDrive[44]does.
B.4 SceneCustomization
MetaUrban supplies various compositional elements, such as street blocks, objects, pedestrians,
vulnerableroadusers,andothermobileagents’appearancesanddynamics. Withjustafewsimple
linesofspecification,itiseasytocreatecustomizedurbanspacesofinterest,suchasstreetcorners,
plazas,andparks.
B.5 UserInterface
MetaUrbanprovidesuserinterfacesfortwopurposes:1)DemonstrationdatacollectionforOfflineRL
andIL.2)Objectlabelingandscenecustomization. Fordemonstrationdatacollection,MetaUrban
providesinterfacesformouse,keyboard,joystick,andracingwheel. Wecaneasilycollecthuman
27expert demonstrations as shown in Figure 25. In addition, MetaUrban provides tools for object
labeling–size,orientation,andattributes,andscenecustomization–assigningthelocationsofthe
selectedobjects.
Figure25:Demonstrationdatacollectionwiththeuserinterface.
B.6 SimulatorComparison
WewillcompareMetaUrbanwithothersimulatorsbelowinTable2,usingthescale,sensor,and
featuredimensions.Forthescale,MetaUrbancangenerateinfinitesceneswithaproceduralgeneration
pipeline. It provides the largest number of humans (1,100) and movements (2,314) among all
simulationenvironments. Forobjects,sofar,wehaveprovided10,000. Comparedtoothersimulators,
alloftheobjectsfromMetaUrbanareurban-specific. Also,weprovideaninterfacetoextendobject
datatoanysizeeasilywithrecentadvancesin3Dcontentgeneration(SectionB.2). Forthesensor,
MetaUrbanprovidesRGBD,semantic,andlidar. Forthefeature,differentfromothersimulators,
MetaUrbanprovidesreal-worlddistributionoftheobject’scategoriesandusesamoresophisticated
pathplanalgorithmtogetthenaturalagent’strajectories. Italsoprovidesflexibleuserinterfaces
–mouse, keyboard, joystick, andracingwheel, whichvastlyeasethecollectionofhumanexpert
demonstrationdata. MetaUrbanusesPyBulletasitsphysicalengineandPanda3D[27]forrendering.
Table2:ComparisonofEmbodiedAIsimulators.WecompareMetaUrbantosimulatorsspecializedforthree
environments–indoor,driving,andsocialnavigationenvironments.
Scale Sensor Feature
Simulator Sc# eo nf es Ob# jo ecf ts Rigged# Hof umans Human# Mof otions RGBD Semantic LiDAR Acoustic Ob Dje isc tt riC ba ut te iog nory E Tn rv a. jeA ctg oe rn yt UserInterface PhysicsEngine Scenario
HuNavSim[59] 5 ✗ 5 6 ✗ ✗ ✗ ✗ ✗ SocialForce ✗ Gazebo Social
SEAN2.0[76] 3 34 <100 1 ✓ ✗ ✗ ✗ Manual SocialForce ✗ Unity Social
SocNavBench[5] 4 ✗ ✗ ✗ ✓ ✗ ✗ ✗ ✗ ✗ ✗ ✗ Social
SUMO[38] ∞ ✗ ✗ ✗ ✗ ✗ ✗ ✗ ✗ ✗ ✗ ✗ Driving
CARLA[19] 15 66,599 49 1 ✓ ✓ ✓ ✓ Manual Rule-based Keyboard,Joystick Unreal4 Driving
MetaDrive[44] ∞ 5 1 1 ✓ ✓ ✓ ✓ Manual Rule-based ✓ PyBullet Driving
AI2-THOR[35] 120 609 ✗ ✗ ✓ ✓ ✗ ✓ Manual ✗ Mouse Unity Indoor
ThreeDWorld[24] 15 200 ✗ ✗ ✓ ✓ ✗ ✓ Manual ✗ VR Flex Indoor
iGibson2.0[40] 15 1,217 ✗ ✗ ✓ ✓ ✗ ✗ Manual ✗ Mouse,VR PyBullet Indoor
ProcTHOR[18] ∞ 1,547 ✗ ✗ ✓ ✓ ✗ ✓ Manual ✗ ✗ Unity Indoor
OmniGibson[41] 306 5,215 ✗ ✗ ✓ ✓ ✓ ✗ Manual ✗ ✗ PhysX Indoor
Habitat3.0[63] 211 18,656 12 3 ✓ ✓ ✗ ✗ Manual Rule-based Mouse,Keyboard,VR Bullet Indoor
MetaUrban ∞ 10,000 1,100 2,314 ✓ ✓ ✓ ✗ Real-world O +PR &C RA JoyM sto icu ks ,e R,K ace iy nb go Ward heel PyBullet Urban
C ExperimentDetails
Thissectiondiscussesthesettingsofenvironments,actionspaces,observationspaces,evaluation
metrics, training details for methods, as well as the reward and cost in the benchmarks of Point
Navigation(PointNav)andSocialNavigation(SocialNav),respectively.
C.1 PointNavExperiments
Environments. ForPointNavexperiments,thereareonlystaticobjectsbesidestheegoagentin
theenvironment. Toevaluatethetrainedpolicy,wesplitseventypesofsidewalksintosixtypesfor
trainingandvalidationwithonefortest. TheoneusedforthetestistheWideCommercialSidewalk,
inwhichthefrontagezonebufferwillbe,aswellassomeunseenobjects.
28Weusedeliveryrobotsastheegoagentinourexperiments. ThetaskofagentsinPointNavexperi-
mentsisfollowingthetrajectoryintheenvironmentthatnavigatesfromstartpointstoendingpoints,
ensuringthatitdoesnotcollidewithotherobjects. Togeneratesuchatask,weharnessORCA[77]
andPushandRotate(P&R)algorithm[11]togetthetrajectoryoftheegoagentafterplacingobjects.
TheprocessisthesameasdiscussedinSectionB.3. Notably,theremaybesometrajectorieswith
smallmovingdistances,wesetathresholdof5mtofilteroutscenarioswithsmallmovingdistances
fortestingtoevaluatedifferentmethodsmoreeffectively.
Action spaces. We use the same continuous action space as MetaDrive [44], which is a 2-
dimensionalvectorthatnormalizedto[−1.0,1.0]indicatingtheaccelerationandsteeringrateofthe
agent. Consideringthatthedynamicsofadeliveryrobotisdifferentfromavehicle,wechangesome
coreparameterslikemaximumvelocity,maximumacceleration,maximumsteeringrateandsoon.
Observationspaces. Multi-modalobservationsareprovidedbyMetaUrban,includingRGB,Depth,
SemanticMap,andLidAR.WeuseLidARinallofourexperimentsforits3Dinformationofthe
surroundingenvironment,whichprovidesdistanceanddirectionofthenearestobjectwithina50m
maximumdetectingdistancecenteringattheego.
Evaluation metrics. For PointNav, an episode is considered successful if the agent issues the
DONEaction,definedascompleting95%ofthesetroutewithin1,000maximumsteps. Theagentis
evaluatedusingtheSuccessRate(SR)andSuccessweightedbyPathLength(SPL)[2,4]metrics,
which measure the effectiveness and efficiency of the path taken by the agent. Additionally, to
measurethesafetyperformanceofthetrainedpolicy,wedefinethecostfunctionbytwoevents,i.e.,
crashingwithobjectsonthesidewalkorbuildingsinthebuildingzone. +1costisgivenoncethose
eventsoccur.
Methods. Inourstudy,weemployadiversesetof7baselinemodelstoestablishcomprehensive
benchmarksonMetaUrban. Thesemodelsspanvariousdomains,includingReinforcementLearning,
SafeReinforcementLearning,OfflineReinforcementLearning,andImitationLearning.
Reinforcement learning. In the realm of Reinforcement Learning, we use the Proximal Policy
Optimization(PPO)[68]forevaluation. PPOisawidelyadoptedandeffectivemethodthatstrikesa
balancebetweensamplecomplexityandeaseoftuning,anditiseasytoscaleasitadoptsparallel
anddistributedtrainingwell. Theagentinthissettingistrainedtomaximizethereward,whichwe
carefullydesigntoencapsulatethedesiredbehavioroftheagentintheMetaUrbanenvironment. The
specificsoftherewardstructurewillbediscussedinthesubsequentparagraph. WetrainthePPO
usingthesamesetofhyperparameterswith128parallelenvironments,whichoccupy128processes.
Thetotaltrainingtimeis12hours,and5MenvironmentstepsforPointNavonasingleNvidiaA5000
GPU.ThedetailedhyperparametersareprovidedinTable3.
Table3:Hyper-parametersofRLandSafeRLforPointNav.
PPO/PPO-Lag/PPO-ETHyper-parameters Value
EnvironmentalhorizonT 1,000
Learningrate 5e-5
Discountfactorγ 0.99
GAEparameterλ 0.95
Clipparameterϵ 0.2
Trainbatchsize 25,600
SGDminibatchsize 256
Valuelosscoefficient 1.0
Entropylosscoefficient 0.0
Costlimit 1
Safereinforcementlearning. Asdrivinginurbanspacesisasafety-criticalapplication,itisimportant
toevaluateSafeReinforcementLearning(SafeRL)algorithms. InthedomainofSafeRL,weutilize
twoapproaches: PPOwithaLagrangianconstraint(PPO-Lag)[64]andPPOwithmodelingofEarly
TerminatedMarkovDecisionProcesses(PPO-ET)[72]. Bothmethodsaimtoensurethatthelearned
29policiesadheretospecificsafetyconstraintswhileoptimizingthereward. PPO-Lagincorporatesa
Lagrangiantermintotheobjectivefunctiontoenforcetheconstraints,whilePPO-ETchangesthe
modelingoftheConstrainedMarkovDecisionProcess(CMDP)toanewunconstrainedMDP,the
optimalpolicythatcoincidenceswiththeoriginalCMDP.
ForPPO-Lag[64],itconsidersthelearningobjectivateasEquation1ratherthanaddingnegativecost
asrewards.
maxminE [R (τ)−λ(C (τ)−d)] (1)
τ θ θ
θ λ≥0
whereR ,C ,θ,anddareepisodicreward,episodiccost,parametersofthepolicy,andgivencost
θ θ
threshold,respectively.
TheruleforPPO-ET[72]istostopwhentheconstraintcostexceedsagivenvalue,whichcanbe
easilyimplementedinpractice.
WeimplementbothoftheseSafeRLmethodsbasedonOmniSafe[33]. Wetrainbothofthemwith
50parallelenvironmentsandthetrainingtakes12hoursforPointNavonasingleNvidiaA5000GPU.
ThedetailedhyperparametersareprovidedinTable3.
Offline reinforcement learning. For Offline Reinforcement Learning, we employ two prominent
methods:ImplicitQ-Learning(IQL)[36]andTwinDelayedDeepDeterministicPolicyGradientwith
BehaviorCloning(TD3+BC)[23]. WecreatethedatasetforPointNavbycombining20%human
demonstrations with 80% demonstrations from a well-trained PPO policy, consisting of 30,000
sampleswithapproximately60%successrate. Thetrainingispurelyofflineandtakesaround2hours
onasingleNvidiaA5000GPUfor100epochs. ThedetailedhyperparametersforIQLandTD3+BC
areprovidedinTable4and5,respectively.
Table4:Hyper-parametersofIQL.
IQLHyper-parameters Value
Learningrate 1e-4
Discountfactorγ 0.99
Targetcriticupdateratio 5e-3
Inversetemperatureβ 3.0
Logstdrange (-5.0,2.0)
Expectile 0.7
Table5:Hyper-parametersofTD3+BC.
TD3+BCHyper-parameters Value
Learningrate 1e-4
Discountfactorγ 0.99
Targetcriticupdateratio 5e-3
Actorupdatedelay 2
BClosscoefficient 2.5
Imitationlearning. ForImitationLearningalgorithms,weusethesamehigh-qualitymixeddemon-
strationusedinOfflineReinforcementLearning. IntheImitationLearningsetting,theagentlearns
tomimicthebehaviorshownintheexpertdemonstration,anditisdifferentiatedfromOfflineRein-
forcementLearninginthesensethattheagentdoesnothaveaccesstotherewards. Weemploytwo
well-establishedmethods: BehaviorCloning(BC)[3]andGenerativeAdversarialImitationLearning
(GAIL)[30]. BCisastraightforwardapproachthattrainstheagenttodirectlymatchtheactions
oftheexpertgiventheobservedstates. GAIL,ontheotherhand,formulatestheimitationlearning
problem as a two-player game between the agent and a discriminator, which tries to distinguish
betweentheagent’sbehaviorandtheexpert’sdemonstrations. ThedetailedhyperparametersforIQL
andTD3+BCareprovidedintable6and7,respectively.
30Table6:Hyper-parametersofBC.
BCHyper-parameters Value
Datasetsize 30,000
Learningrate 1e-4
SGDbatchsize 64
SGDepoch 40
Table7:Hyper-parametersofGAIL.
GAILHyper-parameters Value
Datasetsize 30,000
SGDbatchsize 64
Samplebatchsize 12,800
GeneratorLearningrate 1e-4
DiscriminatorLearningrate 3e-3
Generatoroptimizationepoch 5
Discriminatoroptimizationepoch 2,000
Clipparameterϵ 0.2
Rewardandcost. Therewardfunctioniscomposedasfollows:
R=R +c R +c R +c R +c R (2)
term 1 disp 2 lateral 3 steering 4 crash
Specifically,
• TerminalrewardR : asparserewardsetto+5ifthevehiclereachesthedestination,and
term
−5foroutofroute. IfgivenR ̸=0atanytimestept,theepisodewillbeterminatedat
term
timmediately.
• DisplacementrewardR : adenserewarddefinedasR =d −d ,whereinthed
disp disp t t−1 t
andd denotethelongitudinalpositionoftheegoagentinFrenetcoordinatesofcurrent
1
laneattimetandt−1,respectively. WesettheweightofR asc =0.5.
disp 1
• LateralrewardR :adenserewarddefinedasR =−||l ||,whereinthel denotes
lateral lateral t t
thelateraloffsetoftheegoagentinFrenetcoordinatesofcurrentlaneattimet,whichis
designedtopreventagentdrivingonnonwalkableareas. WesettheweightofR as
lateral
c =1.0.
2
• Steering smoothness reward R : a dense reward defined as R = −||s −
steering steering t
s ||·v ,whereinthes ands denotesthesteeringoftheagentattandt−1,respec-
t−1 t t t−1
tively. Andv denotesthespeedoftheagentattimet. Thisrewardtermisdesignedasa
t
regularizationtopreventtheagentchangingthesteeringtoofrequently. Wesettheweight
ofR asc =0.1.
steering 3
• CrashrewardR : adensenegativerewarddefinedas−1(c ),whereinthec denotesthe
crash t t
collisionbetweenagentsandanyotherobjectsattimetand1(·)istheindicatorfunction.
It’snotablewedonotusetheterminationstrategyforcollisionasinMetaDrive[44]. Weset
theweightofR asc =1.0.
crash 4
AndforbenchmarkingSafeRLalgorithms,collisiontoanyobjectsraisesacost+1ateachtimestep.
C.2 SocialNavExperiments
Environments. ForSocialNavexperiments,mostsettingsarethesameastheonesinPointNav.
Themostimportantdifferenceisthatdynamicagentswillalsobepresentintheenvironment. The
trajectoriesofenvironmentalagentsaregeneratedtogetherbyusingthemodelofORCA[77]with
P&R[11]. SincevehiclesareinheritedfromMetaDrive[44],weusethesameparametertocontrol
itsdensity,i.e.,trafficdensity0.05inourexperiments.
31Evaluationmetrics. ForSocialNav, anepisodeisconsideredsuccessfuliftheagentissuesthe
DONEaction,definedascompleting95%ofthesetroutewithin1,000maximumsteps. Theagentis
evaluatedusingtheSuccessRate(SR)andSocialNavigationScore(SNS)[12],whichistheaverage
ofSuccessweightedbyTimeLength(STL)andPersonalSpaceCompliance(PSC).SNSmeasures
theagentintermsofsafetyandefficiency.
Methods. WebenchmarkthesamemethodsasinPointNavexperimentswiththesamehyperpa-
rameters. However,duetotheinvolvementoflotsofdynamicagents,thetrainingspeedofSocialNav
isaboutapproximately1/3ofPointNavononlinemethods. Thecostschemeisdefinedasraisinga
costof+1ateachtimestepiftheegoagentcrasheswithanyagents,vehicles,orobjects.
32D Datasheet
Motivation
For what purpose was the dataset Thedatasetwascreatedtoenableagentstrainingondiverse
created? scenesandfacilitateEmbodiedAIresearchinurbanspaces.
Who created and funded the ThisworkwascreatedandfundedbytheMetaUrbanteam
dataset? attheUniversityofCalifornia,LosAngeles.
Composition
Whatdotheinstancesthatcomprise EachinstanceisaJSONfileincludingtheconfigurationof
thedatasetrepresent? ourMetaUrbanenvironmentandaspecificseed.
How many instances are there in Thereare12,800urbanscenesreleasedintheMetaUrban-
total(ofeachtype,ifappropriate)? 12K dataset, along with the code to sample substantially
more.
Doesthedatasetcontainallpossi- Weoffer12,800urbanscenes,withtheabilitytogenerate
bleinstancesorisitasample(not moreusingproceduralgenerationscripts.
necessarily random) of instances
fromalargerset?
Whatdatadoeseachinstancecon- EachsceneisspecifiedasaJSONfileincludingtheconfigu-
sistof? rationofourMetaUrbanenvironmentandaspecificseed.
Istherealabelortargetassociated No.
witheachinstance?
Isanyinformationmissingfromin- No.
dividualinstances?
Arerelationshipsbetweenindivid- Eachurbansceneiscreatedindependently,sothereareno
ual instances made explicit (e.g., connectionsbetweenthescenes.
users’ movie ratings, social net-
worklinks)?
Arethererecommendeddatasplits? Yes. SeeSection4inthemainpaper.
Are there any errors, sources No.
of noise, or redundancies in the
dataset?
Is the dataset self-contained, or Thedatasetisself-contained.
doesitlinktoorotherwiserelyon
external resources (e.g., websites,
tweets,otherdatasets)?
Doesthedatasetcontaindatathat No.
mightbeconsideredconfidential?
Doesthedatasetcontaindatathat, No.
if viewed directly, might be of-
fensive, insulting, threatening, or
mightotherwisecauseanxiety?
CollectionProcess
Howwasthedataassociatedwith Eachscenewasprocedurallygenerated.
eachinstanceacquired?
33If the dataset is a sample from a Thedatasetconsistsof12,800scenes,eachbysamplingthe
larger set, what was the sampling parametersofitscomposedelements.
strategy?
Whowasinvolvedinthedatacol- Theauthorswerethesoleindividualsresponsibleforcreating
lectionprocess? thedataset.
Overwhattimeframewasthedata DatawascollectedinMay2024.
collected?
Wereanyethicalreviewprocesses No.
conducted?
Preprocessing/Cleaning/Labeling
Was any preprocess- Welabeleachobject’slocationareaandpivotstomakethem
ing/cleaning/labeling of the spawnintargetfunctionalzonesandfaceanaturaldirection.
datadone?
We use VLMs to automatically label 2D images of cities
worldwide,whichenablestheextractionofreal-worldcate-
gorydistributionofobjectsinurbanspaces.
Was the “raw” data saved Thereisnorawdata.
in addition to the prepro-
cessed/cleaned/labeleddata?
Isthesoftwarethatwasusedtopre- Thecoderelatedtopreprocessing,cleaning,andlabelingthe
process/clean/label the data avail- datawillbemadeavailable.
able?
Uses
Has the dataset been used for any Yes. SeeSection4ofthemainpaper.
tasksalready?
What(other)taskscouldthedataset Thescenescanbeusedinawidevarietyoftasksinembodied
beusedfor? AI,computervision,andurbanplanning.
Is there anything about the com- No.
position of the dataset or the
way it was collected and prepro-
cessed/cleaned/labeled that might
impactfutureuses?
Are there tasks for which the Our dataset can be used for both commercial and non-
datasetshouldnotbeused? commercialpurposes.
Distribution
Will the dataset be distributed to Yes. Weplantomaketheentiretyoftheworkopen-source,
third parties outside of the entity includingthecodeusedtogeneratescenesandtrainagents,
onbehalfofwhichthedatasetwas thescriptstogettheMetaUrban-12Kdataset,andtheasset
created? repositories.
Howwillthedatasetbedistributed? The scene files will be distributed with a custom Python
package.
The code, asset, and repositories will be distributed on
GitHub.
34Will the dataset be distributed un- The scene dataset, 3D asset repository, and code will be
deracopyrightorotherintellectual releasedundertheApache2.0license.
property(IP)license,and/orunder
applicabletermsofuse(ToU)?
HaveanythirdpartiesimposedIP- For 3D human assets, we use Synbody [81]. Its license
based or other restrictions on the is CC BY-NC-SA 4.0. For movement sequences, we use
dataassociatedwiththeinstances? BEDLAM [6]. See https://bedlam.is.tue.mpg.de/
license.htmlforitslicense.
Do any export controls or other No.
regulatoryrestrictionsapplytothe
datasetortoindividualinstances?
Maintenance
Who will be support- Theauthorswillbeprovidingsupport,hosting,andmaintain-
ing/hosting/maintaining the ingthedataset.
dataset?
How can the Forinquiries,email<metaurban_team@gmail.com>.
owner/curator/manager of the
datasetbecontacted?
Isthereanerratum? WewilluseGitHubissuestotrackissueswiththedataset.
Willthedatasetbeupdated? Wewillcontinueaddingsupportfornewfeaturestomake
theurbanscenesmorediverseandrealistic. Wealsointend
tosupportnewtasksinthefuture.
Ifthedatasetrelatestopeople,are Thedatasetdoesnotrelatetopeople.
thereapplicablelimitsonthereten-
tionofthedataassociatedwiththe
instances (e.g., were the individu-
als in question told that their data
wouldberetainedforafixedperiod
oftimeandthendeleted)?
Will older versions of the Yes. Revisionhistorywillbeavailableforolderversionsof
dataset continue to be sup- thedataset.
ported/hosted/maintained?
If others want to ex- Yes. Theworkwillbeopen-sourced,andweintendtooffer
tend/augment/build on/contribute supporttoassistothersinusingandbuildinguponthedataset.
tothedataset,isthereamechanism
forthemtodoso?
Table8:Adatasheet[25]forMetaUrbanandMetaUrban-12K.
35E Performance
WemeasuretheperformanceofMetaUrbanundervaryingstreetblocks,differentdensitiesofstatic
objects,anddynamicagentsinthescene. AllexperimentsareconductedonasingleNvidiaV100
GPUandinasingleprocess. Fortheenvironment,thereareapproximately200objectscovering
1500m2onaverage. Wesample1,000stepsforactionsandrun10timestoreporttheaverageand
standarderrorresultsofFPS.FortheRGBanddepthimage,weusethe128×128resolution. On
average,fortheRGB,Depth,andLiDARobservation,weachieve50±15,60±10,and120±12FPS
intraining,respectively.
F Discussion
Impact. Asthefirsturbanspacesimulator,MetaUrbancouldbenefitbroadareasacrossEmbodied
AI,Economy,andSociety. 1)EmbodiedAI.MetaUrbancontributestoadvancingareassuchasrobot
navigation, socialrobotics, andinteractivesystems. Itcouldfacilitatethedevelopmentofrobust
AI systems capable of understanding and navigating complex urban environments. 2) Economy.
MetaUrbancouldbeusedinbusinessesandservicesoperatinginurbanenvironments,suchaslast-
milefooddelivery,assistivewheelchairs,andtrash-cleaningrobots. Itcouldalsodriveinnovation
inurbanplanningandinfrastructuredevelopmentbyprovidingsimulationtoolsandinsightsinto
how spaces are utilized, thereby enhancing the economic and societal efficiency of public urban
spaceslikesidewalksandparks. 3)Society. ByenablingthesafeintegrationofrobotsandAIsystems
inpublicspaces,MetaUrbancouldsupportthedevelopmentofassistivetechnologiesthatcanaid
in accessibility and public services. Using AI in public spaces might foster new forms of social
interaction and community services, making urban spaces more livable and joyful. 4) Potential
negativesocietalimpacts. TheintegrationofAIandrobotsinurbanenvironments,whilebeneficial,
raises several concerns. Increased surveillance could infringe on privacy, while automation may
leadtojobdisplacementandexacerbateeconomicinequalities. Societaldependencyontechnology
posesrisksofdysfunctionduringfailures,andthepresenceofrobotsmightaltersocialnormsand
interactions. Thus,theenvironmentalimpactofmanufacturingandoperatingurbansimulatorsmust
be carefully managed. Addressing these issues is crucial for ensuring that the benefits of such
technologiesarerealizedwithoutdetrimentalsocietalconsequences.
Limitations. 1)Real-worldscenedistribution. Inthiswork,weextractobjectcategorydistribution
fromreal-worlddataofurbanspaces. Otherthanthereal-worlddistributionofobjectcategories,the
distributionofobjectlocationandscenelayoutisalsoimportantforconstructingspecializedscenes
foragenttraining. Extractionofsuchdistributionreliesonanaccuratereconstructionof3Dscenes
fromreal-worldvideosorevenimages,andthusisextremelychallenging. Aninterestingdirectionis
extractingreal-worldscenedistributionfromin-the-wildvideos,includingobjectcategory,object
location,andscenelayout.Then,wecanbuildadigitaltwinofatargetscenefortheagent’straining.It
couldhelptodevelopscene-specificagents. 2)Interactiveagentbehaviors. Inthiswork,weconstruct
theenvironmentalagents‘dynamicwithdeterministicmethods,determiningtheirmovementsand
trajectorieswithrules. However,intherealworld,allenvironmentalagentsareinteractive; their
behaviors are affected by each other and the surrounding environments. An interesting research
direction is to endow personal traits like job, personality, and purpose to agents and harness the
advancesofLLMs[1]andLVMs[45]toformsocial[62]andinteractivebehaviors[55]ofagents
inurbanscenesspontaneously. 3)Robot-specifictasks. Inthiswork,wedesignpointnavigation
andsocialnavigationtasksasthepilotstudyusingMetaUrbanforembodiedAIresearch. However,
different robots (delivery bots and humanoid robots) have significantly different kinematics and
functions. Thus,moretasks,suchaslocomotionandmanipulation,canbeexplored. Animportant
directionistodesigndifferenttasksbasedondifferentrobots,whichcouldenablevariouscomplexbut
crucialservicesinurbanenvironments. 4)Efficiency. Inthiswork,differentfromindoorscenesand
drivingsimulators,MetaUrbansupportsgeneratingcomplexinteractiveurbansceneswitharbitrary
scales. However,withtheincreaseinscale,thenumberofobjectsanddynamicagentswillsurge
dramatically,whichwillbringthedegradationoftheefficiencyofphysicalsimulationandrendering.
A promising direction is to integrate more sophisticated physical engines and renders, such as
NVIDIAOmniverse.
Future work. 1) Foundation model. MetaUrban can easily generate infinite urban scenes with
alargequantityofsemanticsandcomplexinteractions, whichcouldfacilitatethepre-trainingof
36foundationmodels(likeLLMsandLVMs)thatcanbeusedfordownstreamagentlearningtasks. 2)
Human-robotcohabitate. Mobilemachineshavestartedemergingintheurbanspace,whichmakesit
nolongerexclusivetohumans. Weplantoworkwithurbansociologiststostudytheinfluenceof
robotsonhumanurbanlifethroughbothsimulationandfieldexperiments. 3)Improvelimitations.
Thedirectionsdiscussedinlimitations–real-worldscenedistributionextraction,interactiveagent
behavior simulation, robot-specific task design, and efficiency optimization are also meaningful
directions. Insummary,MetaUrban,asanewurbanenvironmentsimulator,willbringalotofnew
interestingresearchdirections. WearededicatedtomaintainingMetaUrbaninthelongtermand
supportingthecommunity’seffortstodevelopitintoasustainableinfrastructure.
37