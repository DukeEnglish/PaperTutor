A Text-to-Game Engine for UGC-Based Role-Playing Games
Lei Zhang, Xuezheng Peng, Shuyi Yang, Feiyang Wang
RPGGO
{codingtmd.eth, pengxzh, pptbt29, feiyang}@rpggo.ai
Abstract ticulously handcraft these phases, requiring substantial man-
The shift from professionally generated content (PGC) to ual effort and creativity. Asset generation involves profes-
user-generated content (UGC) has revolutionized various sional artists and designers creating high-quality characters,
media formats, from text to video. With the rapid advance- environments, and props. Despite the detailed craftsmanship,
ments in generative AI, a similar shift is set to transform the
the user experience often features an accumulation of artifi-
game industry, particularly in the realm of role-playing
cial elements, limited game paths, and finite experiences, re-
games (RPGs).
This paper introduces a new framework for a text-to-game sulting in a predictable and repetitive set of dialogues, end-
engine that utilizes foundation models to convert simple tex- ings, and player interactions.
tual inputs into complex, interactive RPG experiences. The In contrast, AI-native RPGs represent a significant para-
engine dynamically renders the game story in a multi-modal
digm shift in game development. These games utilize gen-
format and adjusts the game character, environment, and me-
erative AI to evolve, generate, and maintain game content
chanics in real-time in response to player actions. Using this
framework, we developed the ‘Zagii’ game engine, which has from a certain initial condition, thereby eliminating the need
successfully supported hundreds of RPG games across a di- for human intervention. This AI-driven approach allows for
verse range of genres and facilitated tens of thousands of the synthesis of various game elements, such as storylines,
online user gameplay instances. This validates the effective-
characters, and worlds, from simple textual inputs provided
ness of our framework. Our work showcases the potential for
by users. Unlike traditional methods, this approach signifi-
a more open and democratized gaming paradigm, highlight-
ing the transformative impact of generative AI on the game cantly reduces the need for technical skills, enabling indi-
life cycle. vidual creators to produce complex games. Furthermore,
AI-native RPGs are inherently dynamic, with the unique ca-
pability to dynamically generate and adjust game content in
1. Introduction
real-time based on player decisions. This adaptability results
The creation of traditional RPGs, typically undertaken by in a more personalized gaming experience, as the game
professional and large development teams, requires a di- world evolves uniquely for each player, reflecting their ac-
verse set of skills. These include screenwriting, character tions and choices in a narrative that continuously unfolds.
design, game mechanics, coding, and graphical design,
among others. This multidisciplinary requirement makes the
2. Related Works
development process costly, time-consuming, and relatively
inflexible, as changes in one area often trigger cascading There are numerous works at the intersection of LLMs and
changes across the game. This complexity slows the intro- game development, the role of LLMs in games can be cate-
duction of new games to the market, restricts the variety of gorized into several key areas: Player, Non-Player Character
available narrative and gameplay styles, limits player free- (NPC), Game Master (GM), Player Assistant, Commentator
dom and control over narrative paths, and affects content ex- /Reteller, Game Mechanic, Automated Designer, and De-
pansion depth. Traditional RPGs, reliant on rigid game en- sign Assistant (Gallotta et al. 2024). LLMs can play games
gines, often struggle to dynamically adapt to player choices, by converting game states and actions into token sequences,
typically offering a linear or branching path that doesn’t handling both text-based and visual-based game states. They
evolve based on player interaction, or networked narratives have been applied in board games like Chess (Toshniwal et
that aren’t replicable for broader use. al. 2022), Go (Ciolino, Kalin, and Noever 2020), and
Figure 1 illustrates the major life cycle of a game, struc- Othello (Li et al. 2022), as well as in text adventure games
tured into several phases: Concept Planning, Game Design, where they generate character response based on environ-
Game Development, and Game Rendering. Developers me- ment descriptions (Yao et al. 2020, Tsai et al. 2023). LLMs2023), they examine the nuances of role-playing, particu-
larly the conversational agent's capabilities in deception and
self-awareness, providing insights into achieving more hu-
man-like interactions in RPGs. Character-LLM (Shao et al.
2023) introduces a novel approach to enhancing role-play-
ing scenarios through fine-tuning on role-play datasets, em-
phasizing the importance of character consistency and im-
provisation. Role LLM (Wang et al. 2023) presents a sys-
tematic evaluation of LLMs in role-playing, identifying key
areas for improvement and suggesting iterative enhance-
ments based on user feedback.
These studies have significantly advanced the field, al-
lowing us to view the possibilities of AI-native games from
a more transformative perspective, which is this paper going
to present in following chapters.
The text-to-game RPG shares the same life cycle as tradi-
tional game but has brand-new definition of each stage as
figure 2.
• Chapter #3 introduces the details of Game Building Co-
Figure 1: The game life cycle difference between tradi-
pilot, not like the traditional RPG to build a completed
tional RPG and AI-native RPG
game, AI engine only builds the starting point, like world
view, characters, where the game should start from.
also play Atari games by predicting actions from visual in-
• Chapter #4 presents how the Game Rendering happens
puts, as demonstrated by the GATO agent (Reed et al. 2022).
in an AI engine, which is far more powerful and intelli-
In enhancing NPC dialogue and behavior, LLMs create
gent than traditional game engine. It becomes the brain of
immersive interactions by adapting responses to game con-
the game and generates the game from the starting point
texts (Shanahan, McDonell, and Reynolds 2023). They are
and based on the user interaction for a personalized end-
used for both foreground NPCs, which require contextual ing without human intervention.
interactions (Warpefelt and Verhagen 2017, Xu et al. 2023,
And in Chapter #5 introduce the system implementation
Maas, Wheeler, and Billington 2023), and background
and experiment. In the end, this paper introduces the poten-
NPCs, which maintain ambient dialogue (Mehta et al. 2022).
tial key area in the future.
As Game Masters in tabletop role-playing games (TTRPGs),
LLMs generate plots, characters, and narratives. Applica-
tions like AI Dungeon (Hua and Reley 2020) use LLMs for 3. Copilot for Game Building
interactive storytelling. Tools like CALYPSO (Zhu et al.
Envision Copilot as a virtual studio, composed of multiple
2023) assist human GMs with encounter generation, and
AI agents. Each agent specializes in a different aspect of
Shoelace (Acharya et al. 2023) aids in monitoring and re-
game development, collaboratively transforming a user’s
sponding to in-game conversations.
brief description into a comprehensive game. This multi-
Additionally, LLMs can narrate game events for players
agent system can elaborate on the initial input to create a
or spectators, enhancing engagement by summarizing inter-
fully realized game setting, complete with detailed world-
actions and providing automated commentary, which helps
building, character creation, and an engaging initial story-
streamers manage audience interactions effectively (Ranella
line, laying the foundation for a complete game experience.
and Eger 2023).
A UGC creator can incorporate IP-based novels to con-
Focusing on role-playing games (RPGs), the applications
struct worlds they are familiar with, or create a world with a
of LLMs have garnered significant attention in both aca-
brand-new setting that is entirely original. The creator deter-
demic research and industry. Existing studies highlight the
mines the starting point of the world, and the AI engine col-
synergy between LLMs and RPGs. For instance, Generative
laborates with players to shape a personalized world during
Agent (Park et al. 2023) introduced computational agents
the game’s progress.
that simulate human behavior and described an architecture
In this virtual studio, the process commences with the
that utilizes memories and reflections to dynamic plan agent
user’s input, such as “A post-apocalyptic world where ro-
behaviors. LLMGA (Hu et al. 2024) provides a broad per-
bots have taken over, and a lone human survivor fights to
spective on the architecture and functionality of LLM-based
reclaim their home.” The AI agents then collaborate to flesh
game agents, highlighting their application across various
out this concept:
game genres. In study (Shanahan, McDonell, and Reynolds
1. World-Building Agent: Constructs the game's environ-Figure 2: The text-to-game structure Figure 3: Multi-agent Game Building Copilot
ment, detailing the geography, cities, ruins, and ecosystems ¨ Zealous, reflecting the enthusiasm and creativity that
of the post-apocalyptic world, creating a vivid backdrop for the engine brings to game creation.
the narrative. ¨ Adaptability, adjusting and responding to user inputs
2. Character Development Agent: Designs the protagonist, and preferences.
antagonists, and supporting characters, including their back- ¨ Generativity, creating content and assets through AI
stories, personalities, and motivations, ensuring each char- in real-time.
acter is compelling and integral to the story. ¨ Interactivity, employing real-time, multimedia, and
3. Narrative Agent: Expands the initial plot into a detailed realistic world simulation communication methods to
storyline, including key events, conflicts, and resolutions enhance game immersion.
that drive the game's progression. This agent ensures the ¨ Iteration, as AI is not about mechanically executing
narrative is engaging and coherent, providing a strong tasks, but rather driving the evolution of the game
framework for player interactions. from a god-like perspective.
4. Gameplay Mechanics Agent: Develops the rules and Our “ZAGII” Engine serves as the foundational system
systems that govern player interactions, such as combat me- that drives the game-playing experience, integrating multi-
chanics, resource management, and character progression. ple advanced subsystems to create a dynamic and immersive
This ensures that the gameplay is balanced and enjoyable. environment while controlling the game progress, for a
5. Visual and Audio Agents: Generate the visual elements "Multi-Players, Multi-NPCs" scenario.
and soundscapes that bring the game world to life, from As illustrated in Figure 4, all the modules communicate
character models and environment textures to sound effects and share information through a centralized Message Bus,
and music. These agents ensure the game's aesthetic is im- ensuring data consistency and coordination across the entire
mersive and cohesive. system. This integration allows these modules to function
6. Integration Agent: Synthesizes the outputs of all other harmoniously, much like a team of agents working collabo-
agents, creating a seamless and interactive game experience. ratively towards the common goal of delivering a ground-
This agent ensures harmonious collaboration among all ele- breaking gaming experience. By maintaining a unified and
ments, integrating independent settings, and providing guid- consistent flow of information, the Zagii Engine ensures that
ance for game rendering in Chapter #4 to trigger catalysts every aspect of the game works in concert, providing players
for player experience during gameplay. This results in a pol- with a seamless and innovative gaming environment.
ished and engaging game for the player.
The Role-playing System leverages the capabilities of
The multi-agent virtual studio enables anyone, regardless
Large Language Models (LLMs) to endow NPCs with so-
of technical skill, to initiate the development of complex and
phisticated cognitive abilities. These characters can observe
immersive games from simple ideas, thereby expanding the
their surroundings, understand complex scenarios, think
creative potential of individual storytellers and small teams.
critically, plan their actions, make informed decisions, and
interact naturally with their environment. This advanced
4. AI Engine for Game Rendering level of NPC autonomy and intelligence enriches the game-
play experience, making interactions with NPCs more real-
As an engine tasked with revolutionizing the next gener- istic and engaging. By simulating human-like behaviors and
ation game experience, it should embody the following five responses, the role-playing system creates a more believable
key characteristics: and immersive game world.In below chapters, we will elaborate on the design princi-
ples of the various key subsystems of the Zagii Engine and
how we have achieved their implementation with the assis-
tance of AI.
4.1. Role-Playing System
Role-playing Games (RPGs) have emerged as a significant
genre in the gaming industry, offering a unique gaming ex-
perience that hinges on the collaboration of players and
Non-Player Characters (NPCs). These games allow partici-
pants to deeply engage in diverse roles within the game,
crafting a distinctive narrative that is shaped by their collec-
tive actions. Consequently, the need for an intelligent Role-
playing System that can enhance this experience by enabling
Figure 4: The conceptual architecture of Zagii Engine NPCs to authentically embody their roles and collectively
propel the game narrative forward, is paramount.
The Game Status Manager is responsible for real-time However, a significant challenge in the current RPG land-
tracking and updating various game states, including value scape is the predominantly passive nature and limited re-
attributes, objective environment changes and player’s im- sponse capabilities of characters. While substantial work has
pact, which is crucial for advancing the game effectively. It been done to develop systems that enable characters to
monitors the status of game players, NPCs, the environment, freely respond to player interactions (Urbanek et al., 2019;
and the achievement of game objectives. By continuously Shanahan et al., 2023; Shao et al., 2023; Wang et al., 2023),
updating these states, the Game Status Manager ensures that empowering NPCs to take proactive actions based on their
the game progresses smoothly and that all elements of the objectives and the current game scenario remains a chal-
game world remain synchronized. This real-time manage- lenging and open-ended task. This task demands high stand-
ment is essential for creating an immersive and cohesive ards from the Role-playing System, requiring NPCs to au-
gaming experience. tonomously initiate suitable actions that are not pre-de-
The Emergent Narrative System plays a critical role in signed in the game.
crafting emergent storylines that both adapts to and cata- To address this challenge, we draw inspiration from the
lyzes the ongoing game progress and the decisions made by LLM Powered Autonomous Agents (Lilian 2023), a frame-
both players and NPCs as a game designer. Unlike static work that has demonstrated remarkable capabilities in con-
narratives, these dynamic narratives evolve in response to ducting human-like decision-making in complex environ-
in-game actions, providing a fresh and original narrative ments, and Large Language Model Game Agent (LLMGA)
journey for each game session. This adaptability not only (Hu et al. 2024), which is an survey on application of auton-
encourages players to replay the game due to its endless var- omous agent architecture in game NPCs. We propose a
iability but also ensures that each playthrough offers a Role-playing System Architecture that comprises four core
unique and engaging experience to emphasize self-impacted components: Perception, Memory, Thinking, and Action
fate. (referred to as PMTA), as illustrated in Figure 5.
The Multi-modal Rendering System generates sound, The Perception module serves as the character's sensory
music, images, and video based on the current game scenery organ, perceiving all changes in the game world. This in-
and progress. Utilizing Diffusion Models and other founda- cludes the character's external behaviors, alterations in the
tion models, this system creates high-quality game assets game world state, and the progression of the game. These
that enhance the audiovisual experience. The ability to pro- inputs are processed by the Perception module and trans-
duce contextually relevant and aesthetically pleasing media formed into data that can be handled by Large Language
on-the-fly adds to the immersive quality of the game, mak- Models (LLMs) or Multimodal Large Language Models
ing the virtual world more vibrant and lifelike. (MLLMs), serving as input for character decision-making.
In conclusion, the Zagii Engine's integrated subsystems Memory, another pivotal module, stores a series of crucial
collectively contribute to a sophisticated and immersive information for Role-playing. This encompasses the charac-
gaming experience. By leveraging advanced AI techniques ter’s role setting, goals in the game, as well as self-aware-
and real-time data management, the engine ensures dynamic ness and memory fragments generated during role-play in-
gameplay, responsive interactions, and continuously evolv- teractions. In decision-making for Role-Play, Memory dy-
ing narratives, thereby setting a new standard for the next namically retrievals relevant historical memories (present in
generation of interactive entertainment. the form of natural language text) based on the informationsion-making for characters. This not only enhances the over-
all quality of the Role-playing System but also promises to
revolutionize the gaming experience in RPGs by enabling
characters to actively participate and shape the game narra-
tive.
4.2. Player Assistant System
Maximizing player creativity and reducing barriers during
gameplay are critical to the success of any game. Our system
includes a meticulously designed Player Assistant module
to enhance the experience of next-generation AI games.
Figure 5: PMTA framework of Role-playing System This module leverages advanced multimodal large language
models (MllMs) to allow users to customize their characters
perceived by the current character. This provides ample rel- more freely, provide intelligent and effective game guidance,
evant information for character thinking, ensuring the long- and, when necessary, delegate player actions to an AI model.
term consistency of character behavior. Additionally, the re- This delegation is particularly important in multiplayer
sults of character thinking and actions are meticulously an- games. These enhancements significantly improve the con-
alyzed, with essential information requiring retention ex- venience of game interactions and offer increased playabil-
tracted into memory for real-time updates. ity.
The Thinking module processes information from the
Customizing Player Characters
Perception module, along with retrieved memory fragments
Character creation and customization are fundamental as-
from Memory Module. Through a process of reasoning,
pects of many games. Historically, technical constraints
planning, and reflection (Lilian 2023), it generates action
have limited the degree of customization available to users.
decisions and updates its memory. While traditional game
However, the maturation of AI-generated content (AIGC)
AI typically relies on rules, Finite State Machines, Behavior
technology now makes it feasible for players to define their
Trees, Markov Decision Processes (MDP), or Reinforce-
desired characters with unprecedented freedom. With the
ment Learning for behavior decisions (Uludağlı and Oğuz
support of generative AI technology, users can swiftly cus-
2023), our system leverages the robust reasoning capabili-
tomize their character’s appearance, background, skills, and
ties of LLM to accomplish this intricate task. We have
preferred game items. This capability provides a sense of
adopted the widely utilized Retrieval-Augmented Genera-
freedom where players’ imaginations can be directly trans-
tion (RAG) (Lewis et al. 2020, Gao et al. 2023, Zhao et al.
lated into their in-game personas, enhancing their immer-
2024) technology solution to provide ample contextual in-
sion and personal connection to the game world.
formation for the Thinking module. This includes charac-
Gameplay Copilot
ter's role setting information and memory fragments, real-
Numerous studies have demonstrated that providing users
time game progress information, and game world-related
with effective in-game tips is crucial for enhancing the depth
knowledge. Simultaneously, we utilize a dynamic prompt
and enjoyment of their gaming experience. To address this,
generation module to create personalized role-playing
we have integrated a gameplay copilot module for players,
prompt templates for each character to ensure that various
based on sophisticated large model technology. This copilot
character roles across multiple game categories can deliver
can instantly analyze the current game situation, offer ac-
exceptional role-playing performances.
tionable recommendations, and provide natural language
The Action module interprets the action decisions gener-
explanations of the game’s progress. The copilot’s role in
ated by the Thinking module and executes them. These de-
enhancing player experience is a significant research focus
cisions comprise a sequence of action elements, each repre-
within the gaming industry (Gallotta et al. 2024), with nota-
senting speech or an action within the game world. The Ac-
ble contributions from companies such as Microsoft setting
tion module translates each element into executable atomic
benchmarks in this domain.
actions in the game engine. It then executes and renders
them, prompting the next actions of players or other NPCs Autonomous Game Playing
and inducing changes in the state of objects within the game Advancing beyond the copilot mode, AI-based Autonomous
world. Game Playing becomes crucial in certain scenarios. For in-
Through the PMTA framework and the capabilities of stance, in multiplayer games, Autonomous Play can seam-
LLM, we can achieve autonomous thinking and action deci- lessly fill in when there are insufficient players, ensuring aFigure 6: The creator's designed objectives are deconstructed and reasoned through from left to right in the Figure.
continuous and engaging gameplay experience. Leveraging new tasks to players or NPCs, issues new clues or plot
large language models (LLMs), the Autonomous Player can information, or even concludes the current chapter and
make informed decisions and take actions aligned with the transitions to the next one to make the game more playa-
ble.
player’s in-game identity and objectives. This capability
transforms the Autonomous Player into a vital component During the game creation phase, the Game Building Co-
of the game. Additionally, Autonomous Players can take pilot aids creators in identifying critical game statuses for
over minor tasks, allowing human players to concentrate on monitoring. Creators establish game goals and their corre-
more creative and strategic aspects of the game. This dele- sponding achievement criteria. The Copilot identifies key
gation enhances the overall gameplay experience by reduc- performance indicators aligned with these objectives for
ing mundane activities and increasing opportunities for en- continuous tracking during gameplay.
gaging, high-level play. We use numerical values or concise text to record key sta-
In summary, our Player Assistant System, with its cus- tus details. For instance, in emotional companion games, we
tomizable character creation, intelligent game assistance, track player and character emotions using intimacy metrics.
and autonomous gameplay features, represents a significant In Dungeons & Dragons, we monitor the health of player
advancement in game design. By leveraging cutting-edge AI and monsters. In adventure games, we track the player’s cur-
technologies, we aim to create a more immersive, intuitive, rent location in the overall map.
and enjoyable gaming experience that caters to both individ- To manage complex goals, the Copilot decomposes the
ual creativity and collaborative play. goal into multiple sub-goals based on logical judgments or
dependencies, presenting these relationships in a structured
4.3. Game Status Manager format. We provide an example to ensure clear understand-
ing and inference of each sub-goal by the LLM in Figure-6.
In our framework, the Game Status Manager module is re-
The diversity of game goals calls for a flexible goal check
sponsible for tracking the progression of the game and facil-
module capable of adapting its prompt template to each
itating the advancement of new plots. This module is pivotal
unique game scenario. This is vital as the module operates
to gameplay as it determines when to assign new tasks to
continuously throughout game dialogues, necessitating both
players, introduce new plots or clues, and transition to the
speed and accuracy to ensure smooth gameplay. However,
subsequent game chapter.
the limited reasoning capabilities of lightweight LLMs can
The Game Status Manager performs three primary func-
compromise the effectiveness of goal assessments. To ad-
tions:
dress this, we employ two modules leveraging state-of-the-
1. It analyzes the most recent interactions of all game char-
art (SOTA) models:
acters and their impact on the game environment, tracks
• Cold Start: Before gameplay, the SOTA model processes
essential game states, and presents the updated states via
and understands the full scope of the game’s information
the UI for immediate player feedback.
and goals. It generates crucial considerations for goal val-
2. It verifies whether any goals have been accomplished
idation, which are then integrated into the goal check
based on the current game status.
module’s prompt template, guiding the lightweight LLM.
3. Signifies the need for the advancement of new game plots
• Real-Time Assessment: During gameplay, the evalua-
based on achievement detection. The module then assigns
tions of the lightweight LLM are periodically sampledand paralleled with evaluations generated by the SOTA
model based on identical inputs. This allows for a com-
parative analysis, wherein the SOTA model assesses and
highlights discrepancies or deficiencies in the lightweight
LLM’s assessments, informing necessary adjustments.
Game Status Manager is integral to our pursuit of the
open-ended text-to-game rendering, it will continue to be a
key area of our ongoing research.
4.4. Emergent Narrative System
Our goal is to revolutionize gaming narratives by generating
dynamic, real-time narratives that adapt to player actions
and game status. We aim for a "thousand different endings"
effect, providing a unique gaming experience for each
gameplay.
Our approach stands out from traditional methods that use
static scripts or predefined narratives. We ensure the game-
play experience aligns with the unfolding narrative and pro-
gression. The Emergent Narrative Generation System is pri-
marily distinguished by two features: Real-time Narrative
Generation and Interactive Narrative Consumption.
Figure 7: Workflow of Emergent Narrative System
4.4.1. Real-time Narrative Generation
We generate narratives in real-time, aligning narrative de-
4.4.2. Interactive Narrative Consumption
velopment with game progress and the creator's design. This
As players primarily experience the narrative through inter-
dynamic generation keeps the narrative relevant and engag-
actions with NPCs, our system dynamically updates NPC’s
ing.
role-playing prompts to reflect the evolving narrative. This
A key challenge in game narrative design is detailing
approach makes narrative consumption interactive, reflect-
character interactions and stories. While designers excel at
ing player decisions and the dynamic game world, and ad-
creating expansive worlds and frameworks, nuanced narra-
dresses the limitations of static prompts.
tive development often requires additional finesse. This gap
NPC’s role-playing prompts are categorized into static in-
has spurred research in automated story generation.
formation, task-related information, and current narrative
Our system builds on principles established by Yang et al.
context. By dynamically adjusting the narrative context and
(2022), who enhanced long story coherence through struc-
NPC tasks, interactions remain fresh and relevant.
tured prompts and detailed outlines. We adopt a similar ap-
We evaluate this system using metrics including align-
proach, progressing from game world and character design
ment of NPC responses with character traits, accuracy of
to chapter and goal formulation. The system enriches in-
task execution and information provided, consistency with
chapter narratives with multiple goals and twists, ensuring
backgrounds and narratives, and relevance of NPC tasks to
dynamic gameplay. In the future, it will also support dy-
current chapter goals.
namic additions and deletions to accommodate open-world
In conclusion, the system’s capacity to dynamically gen-
games.
erate and render narrative elements, maintain character con-
The system leverages context from the game building co-
sistency, accommodate open-world dynamics, and incorpo-
pilot and incorporates a material recall mechanism, drawing
rate a Game Status Manager significantly enhances game
from large language model knowledge bases and Retrieval-
immersion. This comprehensive approach sustains player
Augmented Generation systems. This enhances the narra-
engagement by delivering continuously evolving narratives
tive's factual and contextual accuracy.
that are responsive to both player actions and the game en-
As showed in Figure 7, our workflow integrates player,
vironment.
environment, and NPC states as factors influencing the nar-
rative. During generation, information from the game build-
4.5. Multi-Modal Rendering System
ing copilot, current states, and incomplete goals are struc-
tured into prompts. Integration with Game Status Manager A complete gaming experience is composed of a combina-
ensures the narrative reflects changes in player stats, envi- tion of multi-modal content including visuals, sound, back-
ronment conditions, and NPC statuses. ground music, and sound effects. Building on the foundation
of the text-based rendering capabilities, however, unfoldingsystem renders a scene involving an entity, it reads the enti-
ty's multi-modal assets; if these assets are absent, initial as-
sets are generated. If multi-modal assets already exist, they
are used as reference information for subsequent generation
to maintain consistency. The lifecycle of an entity is deter-
mined by the game’s progress, while the lifecycle of its
multi-modal assets is determined by that of the entity.
4.5.2. Perception and Retrieval
The perception module is responsible for preprocessing
players’ gaming experiences into concise plot summaries,
generating information to retrieve entity IDs, and assisting
the status manager in updating the status of entity assets.
Based on the current round of dialogue, the perception mod-
ule interprets structured historical dialogue data from the
player’s first-person perspective, understanding player in-
tentions and actions, and outputs plot themes and narratives.
Through the interpretation of player behavior by the per-
ception module, the system can retrieve specific entity IDs
from session memory storage, representing which entities
the user interacted with from their perspective in the current
round, and the depth of these interactions. Game Status
Manager evaluates changes in entities within the dialogue
history based on the current round of dialogue. If there is a
significant change in an entity’s textual metadata, its multi-
modal assets are updated to reflect the latest game progress.
Figure 8: Multi-Modal Rendering System render the The status of entity assets not retrieved remains unchanged;
game by Text-Based Logic Processer and Multi-Modal only the retrieved are used and updated in the current round.
Adaptive generation.
4.5.3. Adaptive Generation
Taking image generation as an example, diffusion models
an evolving multi-modal content expression that dynami-
guided solely by text struggle to maintain consistency of
cally responds to player interactions and narrative progress
specific objects across multiple inference processes. La-
ion throughout the game poses significant challenges on the
beled prompts provide a vast representational space, yet
output consistency and continuous coherent evolution.
they also introduce randomness in the generated content.
The Multi-modal Rendering System utilizes large lan-
This inconsistency induced by text-guided conditions poses
guage models (LLMs) for memory retrieval, status manage-
significant obstacles for rendering real-time RPG games.
ment, and information orchestration. Through various
Yang et al. (2024) proposed a training-free framework that
adapters, it transforms the RPG gaming experience into cor-
uses language models for Recaptioning, Planning, and Gen-
responding multi-modal descriptions to trigger real-time
erating to guide regional conditional diffusion. The Omost
content generation by large multi-modal models. The pro-
method, proposed by Lvmin Zhang’s team (LLlyasviel
duced multi-modal content serves as part of the session
2024), further summarized the approaches for regional con-
memory, ensuring consistency throughout the game's evolu-
ditional combination diffusion using LLMs, achieving prac-
tionary process.
tically significant results through uniquely designed block
4.5.1. Entities image representation symbols that fine-tune LLMs.
Entities are any objects that can act or interact independently, Our multi-modal processor references these studies, im-
each possessing its own description, attributes, and multi- plementing regional conditional control of the image canvas
modal assets, which are part of the session memory and can through attention decomposition. We first arrange prompts
represent NPCs, scenes, key items, or even players. In AI- into global and local sub-prompts. For global prompts, cor-
native games, when users initiate a game, it merely marks responding to the canvas background, we use Plot themes
the beginning of an expandable world, initially featuring a and narratives from the perception module as textual
limited and incomplete number of entities. Entities are cre- prompts to guide the overall image semantics and composi-
ated and updated based on chapter changes and special tion. For local sub-prompts, we employ the Cot method to
events within the game. When the multi-modal rendering guide LLMs in regional partitioning of entity locations and
introduce image prompts through the IP-Adapter, considerYou are participating in a role-playing scenario, taking on the role of DM. Given the background information,
character settings, and lore list in the current scene, your tasks are:
Prompt
compo- - Fully immerse yourself in the role of DM, maintaining this character throughout your interactions with the
nent via user (who is also a player) and other participants.
general - Consistently align your thoughts and actions with DM's personality traits, and strive to achieve their goals
template within the role-play.
- Understand the identity and backstory of the character that the user is playing to enhance and streamline
your interactions with them.
You are engaged in a role-playing game set in the post-apocalyptic world of Fallout, specifically within the
confines of Tibbets Prison in the year 2253. The game is an RPG with a focus on exploration, puzzle-
solving, and combat. Your objective is to fully immerse yourself in the role of the Dungeon Master (DM),
Prompt guiding the player through the narrative and challenges of the game.
compo-
nent via As the DM, you must maintain character throughout, consistently thinking and acting in line with your role.
dynamic Your task is to describe the current situation and challenges the player faces, offering them a range of
genera- actions to choose from. You will also determine the success or failure of the player's actions based on their
tion choices and character sheet.
The player is a prisoner at Tibbets Prison, which has been compromised due to an outside attack. Their cell
door is broken, giving them a chance to escape.
Table 1: Comparison of Prompt Component from different methods, dynamic prompt generation has introduced significant
personalized information and requirements for role-playing based on character settings.
ing the entity's inherent image assets as reference infor- to us, as we leverage LLM across almost all subsystems to
mation to construct image-based regional conditions. By achieve the desired outcomes.
combining multi-modal information and regional conditions
in our prompts, our workflow achieves improved semantic 5.1. Dynamic Prompt Generation
accuracy and feature consistency in image generation. The
The utilization of Large Language Models (LLMs) has be-
newly generated images are post-processed to update any
come increasingly prevalent across a myriad of applications,
missing entity assets, thus completing the full cycle of the
owing to their ability to generate human-like text. The effi-
image generation process.
cacy of these models, however, is contingent upon the qual-
The generation of sound, music, and motion effects dif-
ity of the prompts provided to them. A well-crafted prompt,
fers in detail from image generation, but the methodology is
meticulously tailored to the task at hand, can elicit superior
similar, and will not be elaborated further here.
results from LLMs. This principle holds true across a broad
spectrum of scenarios involving the use of these large mod-
els, underscoring the importance of investing time and effort
5. System Implementation and Experiments
in the creation of effective prompts.
To validate our proposed text-to-game framework, we de- Nevertheless, the task of creating universally effective
veloped an experimental system using Game Building Co- prompts is not without its challenges. Certain applications
pilot and Zagii Engine. Game Building Copilot facilitates present complex scenarios that necessitate a nuanced ap-
game creation, rapidly transforming innovative ideas into proach to prompt design. A prime example of such a sce-
playable RPGs. Conversely, Zagii Engine handles real-time nario is our role-playing system, where the design of role-
game rendering, capable of supporting online gameplay playing prompts for all characters across various game gen-
with significant concurrency. res can be a complex undertaking.
While the design principles and solutions for each subsys- Our role-playing system supports a wide array of Role-
tem have been discussed in previous sections, we will focus Playing Games, encompassing genres such as detective, ad-
here on the aspects related to Large Language Model (LLM) venture, simulator, communication, and more. The diversity
applications. The ability to harness the power of large mod- of these genres introduces a level of complexity in prompt
els effectively and controllably is of paramount importance design, as each genre has unique characteristics and require-
ments. Moreover, within a single game, there exists a mult-Figure 9: Two-layer finetuning for vertical game categories
itude of characters, each with diverse roles and objectives. engineering or dynamic prompt generation. These tech-
These characters range from the intelligent and composed niques guide the model’s responses and improve perfor-
detective unraveling mysteries to the cunning and malevo- mance across tasks. However, fine-tuning, which adjusts a
lent perpetrator concealing the truth, and the meticulous de- pre-trained model’s parameters for a specific task or dataset,
tective assistant strategizing every move. The diversity of can be more effective in certain scenarios. We fine-tune the
these roles further complicates the task of designing univer- LLM on a custom dataset that includes various game sce-
sally effective prompts. narios, dialogues, and narratives. This ensures that the LLM
To address this challenge, we have adopted an approach can generate responses that are not only grammatically cor-
that leverages the capabilities of LLMs to generate person- rect and coherent but also creative and engaging, enhancing
alized role-playing prompts for each character. This ap- the overall gaming experience.
proach involves providing the LLM with a meta-prompt that As an application layer based on Large Language Models
includes the game genre, basic character setup, game objec- (LLMs), it is essential to continually enhance the founda-
tives, and other foundational game information (game meta tional capabilities of LLMs in the gaming domain. Concur-
info). The LLM then generates a personalized role-playing rently, it is also necessary to tailor the approach by incorpo-
prompt based on the provided game and character infor- rating the unique characteristics of different game genres,
mation. This approach allows for the generation of prompts training the models with specific data to endow them with
that are tailored to the unique characteristics and objectives relevant generative abilities. Thus, the structure involves a
of each character, thereby ensuring that each character can two-level training process.
flawlessly embody their roles. Firstly, the base of dialogue and game-related data is con-
Table-1 illustrates the enhancement in role-playing tinuously expanded to fine-tune the foundational models,
prompts brought about by Dynamic Prompt Generation. ensuring they are well-suited for general outputs in the gam-
Compared to prompts based on generic templates, Dynamic ing domain. This involves the collection and integration of
Generation can provide more fitting role-playing instruc- a wide range of dialogue interactions and game scenarios,
tions, considering the unique backgrounds of the game and allowing the models to learn from diverse contexts and im-
characters. prove their adaptability and coherence in generating game-
Our experimental results provide compelling evidence of related content.
the efficacy of this approach. We observed a significant en- Secondly, genre-specific dialogue and game data are con-
hancement in role-playing outcomes, indicating that the use structed, allowing for secondary training of the models for
of LLMs to generate personalized role-playing prompts can distinct game genres. This process involves curating de-
lead to more immersive and engaging role-playing experi- tailed datasets that reflect the unique elements, themes, and
ences. mechanics of various game genres, such as role-playing
games, strategy games, and adventure games. By focusing
5.2 Model Finetuning and Management on genre-specific data, the models can develop a deeper un-
derstanding and more nuanced generative capabilities tai-
Large Language Models (LLMs) can address many applica-
lored to the specific requirements and expectations of each
tion requirements, especially when enhanced with prompt
genre.This dual approach ensures the creation of high-perform- rendering on the front end or players finding the game did
ing models that are not only versatile in general gaming con- not meet their expectations.
texts but also excel in delivering genre-specific outputs,
63
serving as robust foundational models for application in di- 59
verse gaming environments.
5.3. Experiment Results
23
16
For comprehensive experimental validation, we have made
6
our Game Building Copilot and Zagii Engine accessible on
our website. We have also recruited a group of individual
(1-10] (10, 50] (50, 100] (100, 500] (500, +]
game creators to create their own games and conducted
CountofGameplaySessions
game testing on a scale of tens of thousands of players.
5.3.1. Game Creation
During the experiments, game creators used the Game Figure 10: The distribution of gameplay sessions among
Building Copilot to create games. We offered eight different the selected 167 games
templates for game creation, allowing creators to either
build continuously on these templates or create entirely new
8564
games. The games covered six categories: Adventure
(where the game master controls the game), Role-playing, 5825 5528
Mystery, Simulation, Strategy, and Choice-based Adventure.
The game creators successfully published a total of 803 2906
games. Of these, 746 games (approximately 93%) were cre- 1416
ated and published within 24 hours, demonstrating the effi- 437 218
ciency of our framework in enhancing game development
[0, 5] (5, 10](10, 20](20, 30](30, 40](40, 50](50, +]
productivity.
InteractionRounds
5.3.2. Game Playing
From the published 746 games, we selected 168 games
for player testing. During the experiment period, these
Figure 11: The distribution of user-npc interaction rounds
games amassed a total of 60,301 gameplay sessions. A
across all the gameplay sessions.
gameplay session is defined as a scenario where a player
starts a game and continues until the game ends, or they exit
The experimental data validates the effectiveness of our
mid-way. Notably, a meticulously crafted game achieved a
proposed text-to-game framework: games rapidly devel-
total of 35,407 gameplay sessions, indicating significant
oped using our game builder and game renderer demon-
success and validating the potential of the text-to-game con-
strated considerable enjoyment and playability, and it is also
cept to produce engaging games.
feasible to create highly popular RPG games. However, we
For the sake of data analysis consistency, we excluded
also identified several limitations. Many games faced chal-
this exceptional game from subsequent analysis, focusing on
lenges with cold start issues. Reducing user interaction bar-
the 167 games which accumulated 24,894 gameplay ses-
riers and enhancing the engagement of the gameplay expe-
sions.
rience are areas that require further improvement.
Figure 10 shows the distribution of gameplay sessions
among the 167 games. As can be seen, a small number of
games have garnered the majority of gameplay, which is in 6. Conclusion and Future Work
line with the 80/20 rule of traffic distribution. Twenty-nine
games garnered more than 100 gameplay sessions each, This paper presents an innovative text-to-game engine that
with six games receiving over 500 sessions. creates and renders RPG games in real-time. Utilizing gen-
Figure 11 presents the distribution of User-NPC interac- erative AI, our goal is to provide a framework that enables
tion rounds across the 24,894 gameplay sessions. Most anyone to create any game, simplifying game development
game play sessions had interaction rounds ranging between to typing in a text box. The current implementation supports
5 and 30, with over 200 sessions exceeding 50 interaction limited scale ‘Multi-Player Multi-NPCs’ RPG scenarios. As
rounds. A significant portion of gameplay sessions had generative AI continues to evolve, we anticipate the creation
fewer than 5 interaction rounds, which includes instances of large-scale open worlds for UGC-based RPGs, akin to the
where players opened the game but exited quickly. The rea- next generation of Roblox. However, several issues need to
sons for these early exits vary, including unsuccessful game be addressed to achieve this goal.
semaGfostnuoC
snoisseSyalpemaG6.1. 2D & 3D asset generation nlp tasks. *Advances in Neural Information Processing Systems*,
*33*, pp.9459-9474.
Generative AI has led to significant progress in the genera-
Lilian Weng, 2023, "LLM Powered Autonomous Agents":
tion of 2D and 3D game assets. Tools like NVIDIA’s Gau-
https://lilianweng.github.io/posts/2023-06-23-agent/
GAN and Art-breeder are used in the industry to create de-
Li, K., Hopkins, A.K., Bau, D., Viégas, F., Pfister, H. and Watten-
tailed and diverse 2D textures and characters. Innovations in
berg, M., 2022. Emergent world representations: Exploring a se-
3D asset generation have been seen with models like quence model trained on a synthetic task. arXiv preprint
NVIDIA’s DLSS and Unreal Engine’s MetaHuman Creator, arXiv:2210.13382.
enabling the creation of lifelike character models and envi- LLlyasviel. 2024. Omost. GitHub. https://github.com/llly-
ronments. Academic research has also contributed, with asviel/Omost. Accessed: 2024-06-29.
studies showing the potential of Generative AI to produce Maas, C., Wheeler, S. and Billington, S., 2023. To infinity and be-
high-quality assets that integrate seamlessly into game yond: Show-1 and showrunner agents in multi-agent simulations.
To infinity and beyond: Show-1 and showrunner agents in multi-
worlds. However, a major challenge remains: the lack of
agent simulations.
real-time rendering and optimization algorithms to ensure
Mehta, A., Kunjadiya, Y., Kulkarni, A. and Nagar, M., 2022, Feb-
that generated assets are not only of high quality but also
ruary. Exploring the viability of Conversational AI for Non-Playa-
perform well within game environments. ble Characters: A comprehensive survey. In 2021 4th International
Conference on Recent Trends in Computer Science and Technol-
6.2. AB Testing Framework ogy (ICRTCST) (pp. 96-102). IEEE.
Park, J.S., O'Brien, J., Cai, C.J., Morris, M.R., Liang, P. and Bern-
Another crucial area for future work is the development of
stein, M.S., 2023, October. Generative agents: Interactive simula-
a robust A/B testing framework. This framework would as-
cra of human behavior. In Proceedings of the 36th annual acm sym-
sess the impact of different model versions and game fea- posium on user interface software and technology (pp. 1-22).
tures on a large scale and capture a variety of detailed data Ranella, N. and Eger, M., 2023. Towards Automated Video Game
points from player interactions. The process involves creat- Commentary Using Generative AI. in Proceedings of the AIIDE
ing parallel test environments where players are randomly work- shop on Experimental AI in Games.
assigned to different versions of the game engine or specific Reed, S., Zolna, K., Parisotto, E., Colmenarejo, S.G., Novikov, A.,
features. By comparing player responses and performance Barth-Maron, G., Gimenez, M., Sulsky, Y., Kay, J., Springenberg,
J.T. and Eccles, T., 2022. A generalist agent. arXiv preprint
across these environments, we can identify which changes
arXiv:2205.06175.
enhance the game experience. The A/B testing framework
Shanahan, M., McDonell, K. and Reynolds, L., 2023. Role play
should be flexible and scalable, ensuring that model itera-
with large language models. Nature, 623(7987), pp.493-498.
tions are guided by data-driven insights, leading to continu-
Shao, Y., Li, L., Dai, J. and Qiu, X., 2023. Character-llm: A train-
ous improvements.
able agent for role-playing. arXiv preprint arXiv:2310.10158.
Toshniwal, S., Wiseman, S., Livescu, K. and Gimpel, K., 2022,
June. Chess as a testbed for language model state tracking. In Pro-
Reference
ceedings of the AAAI Conference on Artificial Intelligence (Vol.
36, No. 10, pp. 11385-11393).
Acharya, D., Kelly, J., Tate, W., Joslyn, M., Mateas, M. and War-
drip-Fruin, N., 2023, April. Shoelace: A storytelling assistant for Tsai, C.F., Zhou, X., Liu, S.S., Li, J., Yu, M. and Mei, H., 2023.
GUMSHOE One-2-One. In Proceedings of the 18th International Can large language models play text games well? current state-of-
Conference on the Foundations of Digital Games (pp. 1-9). the-art and open questions. arXiv preprint arXiv:2304.02868.
Ciolino, M., Kalin, J. and Noever, D., 2020, September. The go Uludağlı, M.Ç. and Oğuz, K., 2023. Non-player character deci-
transformer: natural language modeling for game play. In 2020 sion-making in computer games. *Artificial Intelligence Review*,
Third International Conference on Artificial Intelligence for Indus- *56*(12), pp.14159-14191.
tries (AI4I) (pp. 23-26). IEEE. Urbanek, J., Fan, A., Karamcheti, S., Jain, S., Humeau, S., Dinan,
Gallotta, R., Todd, G., Zammit, M., Earle, S., Liapis, A., Togelius, E., Rocktäschel, T., Kiela, D., Szlam, A. and Weston, J., 2019.
J. and Yannakakis, G.N., 2024. Large language models and games: Learning to speak and act in a fantasy text adventure game. *arXiv
A survey and roadmap. arXiv preprint arXiv:2402.18659. preprint arXiv:1903.03094*.
Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., Dai, Y., Sun, Wang, Z.M., Peng, Z., Que, H., Liu, J., Zhou, W., Wu, Y., Guo, H.,
J. and Wang, H., 2023. Retrieval-augmented generation for large Gan, R., Ni, Z., Zhang, M. and Zhang, Z., 2023. Rolellm: Bench-
language models: A survey. *arXiv preprint arXiv:2312.10997*. marking, eliciting, and enhancing role-playing abilities of large
language models. arXiv preprint arXiv:2310.
Hua, M. and Raley, R., 2020. Playing With Unicorns: AI Dungeon
and Citizen NLP. DHQ: Digital Humanities Quarterly, 14(4). Warpefelt, H. and Verhagen, H., 2017. A model of non-player
character believability. Journal of Gaming & Virtual Worlds, 9(1),
Hu, S., Huang, T., Ilhan, F., Tekin, S., Liu, G., Kompella, R. and
pp.39-53.
Liu, L., 2024. A survey on large language model-based game
agents. arXiv preprint arXiv:2404.02039. Xu, Y., Wang, S., Li, P., Luo, F., Wang, X., Liu, W. and Liu, Y.,
2023. Exploring large language models for communication games:
Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal,
An empirical study on werewolf. arXiv preprint arXiv:2309.04658.
N., Küttler, H., Lewis, M., Yih, W.T., Rocktäschel, T. and Riedel,
S., 2020. Retrieval-augmented generation for knowledge-intensiveYang, K., Klein, D., Peng, N. and Tian, Y., 2022. Doc: Improving
long story coherence with detailed outline control. arXiv preprint
arXiv:2212.10077.
Yang, L., Yu, Z., Meng, C., Xu, M., Ermon, S. and Bin, C.U.I.,
2024, January. Mastering text-to-image diffusion: Recaptioning,
planning, and generating with multimodal llms. In Forty-first In-
ternational Conference on Machine Learning.
Yao, S., Rao, R., Hausknecht, M. and Narasimhan, K., 2020. Keep
calm and explore: Language models for action generation in text-
based games. arXiv preprint arXiv:2010.02903.
Ye, H., Zhang, J., Liu, S., Han, X. and Yang, W., 2023. Ip-adapter:
Text compatible image prompt adapter for text-to-image diffusion
models. arXiv preprint arXiv:2308.06721.
Zhao, P., Zhang, H., Yu, Q., Wang, Z., Geng, Y., Fu, F., Yang, L.,
Zhang, W. and Cui, B., 2024. Retrieval-augmented generation for
ai-generated content: A survey. *arXiv preprint
arXiv:2402.19473*.
Zhu, A., Martin, L., Head, A. and Callison-Burch, C., 2023, Octo-
ber. CALYPSO: LLMs as Dungeon Master's Assistants. In Pro-
ceedings of the AAAI Conference on Artificial Intelligence and In-
teractive Digital Entertainment (Vol. 19, No. 1, pp. 380-390).