Geometry Image Diffusion: Fast and Data-Efficient Text-to-3D with Image-Based
Surface Representation
SlavaElizarov CiaraRowles SimonDonné
UnityTechnologies UnityTechnologies UnityTechnologies
slava.elizarov@unity3d.com ciara.rowles@unity3d.com simon.donne@unity3d.com
Abstract We propose diffusing geometry images [12], a 2D rep-
resentation of 3D surfaces, with a Collaborative Control
Generatinghigh-quality3Dobjectsfromtextualdescrip- scheme[53]. Thisenables3Dobjectgenerationfromtext
tionsremainsachallengingproblemduetocomputational prompts,asshowninFig.1. Thegeometryimagerepresen-
cost, thescarcityof3Ddata, andcomplex3Drepresenta- tationallowsustorepurposeexistingimage-basedarchitec-
tions. WeintroduceGeometryImageDiffusion(GIMDiffu- tures, while the Collaborative Control scheme enables us
sion),anovelText-to-3Dmodelthatutilizesgeometryimages toleveragepre-trainedText-to-Imagemodels,considerably
toefficientlyrepresent3Dshapesusing2Dimages,thereby reducingtherequiredtrainingdataandcost. Geometryim-
avoidingtheneedforcomplex3D-awarearchitectures. By ages, and more specifically multi-chart geometry images,
integratingaCollaborativeControlmechanism,weexploit offertwogreatadvantagesoverotherrepresentations: they
therich2DpriorsofexistingText-to-Imagemodelssuchas donotimposeconstraintsonthetopologyofthegenerated
Stable Diffusion. This enables strong generalization even object,andtheynaturallyseparatethegeneratedobjectinto
withlimited3Dtrainingdata(allowingustouseonlyhigh- semanticallymeaningfulparts,makingtheresultingobjects
qualitytrainingdata)aswellasretainingcompatibilitywith easiertomanipulateandedit. WebelievethatGIMDiffusion
guidancetechniquessuchasIPAdapter. opensupapromisingnewresearchdirectioninText-to-3D
Inshort,GIMDiffusionenablesthegenerationof3Das- generation,providingapracticalandefficientapproachthat
setsatspeedscomparabletocurrentText-to-Imagemodels. caninspirefutureadvancementsinthefield.
The generated objects consist of semantically meaningful,
Insummary,theadvantagesofGIMDiffusioninclude:
separatepartsandincludeinternalstructures, enhancing
bothusabilityandversatility. • Image-based: By leveraging existing 2D image-based
modelsinsteadofdevelopingnew3Darchitectures, we
simplifybothmodeldesignandtraining.
• FastGeneration: Wegeneratewell-defined3Dmeshes
1.Introduction
in under 10 seconds per object, which could be further
Automatic3Dobjectgenerationpromisessignificantbene- enhancedusingdistillationtechniques.
fitsacrossvideogameproduction,cinema,manufacturing, • Generalization: Throughcollaborativecontrol,wereuse
andarchitecture. Despitenotableprogressinthisarea,par- pre-trainedText-to-Imagepriors,allowingustogeneralize
ticularlywithText-to-3Ddiffusionmodels[4,46,56],gen- wellbeyondourlimited3Dtrainingdata.
eratinghigh-quality3Dobjectsremainsachallengingtask • Separate Parts: GIMDiffusion creates assets that con-
duetocomputationalcosts,datascarcity,andthecomplexity sistofdistinct,semantically-meaningful,separableparts,
oftypical3Drepresentations. Furthermore,itiscrucialthat facilitatingeasiermanipulationandeditingofindividual
thegeneratedobjectscanbere-litwithingraphicspipelines, components.
necessitatingtheuseofphysically-basedrendering(PBR) • AlbedoTextures: The3DassetsgeneratedbyGIMDiffu-
materials. Althoughgraphicspipelinespredominantlyuse siondonothavebaked-inlightingeffects,makingthem
meshesastheirprimary3Drepresentation,processingthese suitableforvariousenvironments.
atscaleisnotoriouslydifficult. Mosttechniquesinsteadgen- • StraightforwardPost-processing: Our3Dassetsdonot
erateanintermediaterepresentation,whichaddsadditional requiretheapplicationofisosurfaceextractionalgorithms
burdentotrainingdatapre-processingandgeneratedobject orUVunwrapping,whichreducespotentialartifactsand
post-processing. simplifiestheoverallworkflow.
1
4202
peS
5
]VC.sc[
1v81730.9042:viXraApalminapot Asneaker
Afantasystylemetalshield Asatchelbag
Aflyagaricmushroom Adeliciousburgerwithlettuce,tomato,andcheese
Aleatherjacketwithspikes Afantasyweapon,battlescythe
Ascooterbike Highlyornategoldinlaidwoodenchestwithrelief
patternsofcelticknots
Figure1.MeshesgeneratedwithourproposedGeometryImageDiffusion(GIMDiffusion)method.Foreachobject,weshowthegenerated
albedotexture,thetexturedmesh,theuntexturedmesh,andtherespectivetextprompt.Theobjectsaregeneratedentirelyusingourmethod:
boththestructure,textureandlayoutoftheUVmaparegeneratedcompletelyfromscratch.
22.Relatedwork However,thelackofcameraconditioningleadstodiscrep-
ancies among different viewing angles (Janus effect [37])
2.1.Text-to-ImageGeneration
andprojectionartifacts, whichrequire3D-awarearchitec-
Diffusionmodels[48,49]andflowmatching[26],alongside tures and retraining on restrictive 3D datasets to mitigate
theriseofversatile,general-purposearchitecturessuchas these issues [13, 19, 27, 43, 44, 67], while weakening the
transformers [54], have brought considerable progress in 2Dprior. Additionally,theoriginalformulationcanleadto
generativemodeling. Inparticular,text-conditionedimage issuessuchassaturatedcolors,oversmoothgeometry,and
generationwasrevolutionizedbyapproachesbasedonLa- limiteddiversity[2,21,24,56,58,69].
tent Diffusion [38] and its further extensions [11, 35, 36]. Feed-forwardmethodsdirectlygenerate3Dshapeswith-
Foundational models like Stable Diffusion, trained on ex- out the need for iterative refinement. However, we must
tensive internet-scale datasets (such as LAION-5B [42]), considercompatibilitywithgraphicspipelines,whichpre-
arecapableofgeneratingcomplexscenesfromtextprompts dominantlyusetexturedmeshesastheirprimaryrepresen-
whileexhibitinganimplicitunderstandingofscenegeometry. tation — an inherently challenging modality for learning-
Duetothehighcostoftrainingsuchmodels,theyareoften basedmodels. WhileseminalworkslikePoint-E[34]and
repurposedforothertasksormodalities[16,53,66]:ourpro- itsfollow-ups[17,65]demonstrateimpressivegeneraliza-
posedGIMDiffusionisaprimeexampleofthis,restricting tion and diversity, the inherent lack of connectivity infor-
thebasemodeltooutputalbedotexturesspecifically. mation limits the expressiveness of point clouds. Instead,
manycurrentmethodsrelyonproxyrepresentations,suchas
2.2.ConditioningDiffusionModels
neuralimplicits[6,18,31–33,60,68]orneuraltriplanes[3–
5,15,51],torepresenttheobjects.
Controlmechanismsmodifypre-trainedfoundationalmod-
els,enablingthemtoacceptadditionalconditionstoguide Because of this, these methods require pre- and post-
thegenerationprocess. Existingpixel-alignedcontroltech- processingtotransformbetweenthemeshdomainandthe
niquesfallintotwocategories: fine-tuningthebasemodel proxyrepresentation,e.g.throughmarchingcubes[28]or
withmodifiedinputandoutputspaces[10,22],oraseparate tetrahedra [9]. This process is costly and far from loss-
model that alters the base model’s internal states [64, 66]. less, introducing issues such as quantization or grid-like
Thelatterapproaches,suchasControlNet[66],havegained artifacts,andresultinginthelossofinformation,including
wide adoption due to their ability to preserve the original partsegmentationandinternalstructures. Whiledirectmesh
model’s performance while adding conditions such as hu- generationtechniquesexist[45],these(aswellastheother
manposesordepthimages. AnimateAnyone[16]leverages feed-forwardmethod)mustbetrainedfromscratchon3D
asimilararchitecturetoinjectthebasemodel’shiddenstates data,whichisscarceandexpensivetogather. Byremaining
intoanewbranchthatalignstothebasemodel’soutput. intheimagedomain,GIMDiffusionleveragesCollaborative
Inourapplication,weneedtobothcontrolthebasemodel Controltoeasethisdataburden[53].
(whichwilloutputUV-spacealbedomaps)andextractsig-
2.4.GeometryImages
nificant features from it (to generate the geometry image
modality). CollaborativeControl[53]achievesexactlythis Geometry images (GIM) [12, 40] have been largely over-
byintroducingbidirectionalcommunicationbetweenboth lookedindeeplearning[47]. XDGAN[1]isapioneering
models,originalforText-to-PBR-Texturegeneration. The effortthatutilizesGIMsastherepresentationofchoicefor
ability to integrate completely new modalities into exist- aStyleGAN-basedarchitecture[20]. However,duetothe
ing models, without retraining and with a reduced risk of architecturalconstraints,thetrainingdatamustbeperfectly
catastrophicforgetting,isinvaluabletoourapplication. alignedwithatemplateatlas,whichlimitsitsapplicabilityto
real-worlddata. Furthermore,thepre-processingalgorithm
2.3.Text-to-3Dgeneration
providedinthepaperisoverlyrestrictedtoshapesofgenus
We identify two main approaches to Text-to-3D gen- zero—Section3.3.2showshowtohandlearbitraryshapes.
eration: optimization-based and feed-forward methods. Recent concurrent work [61] has advocated for low-
Optimization-basedmethodsrelyonpre-trained2Dimage resolution64×64geometryimagesasa3Drepresentation
diffusion models to generate 3D assets [37, 56] and can forclass-conditioneddiffusionmodelsandhighlightsitsef-
produce content of high perceptual quality, at the cost of ficiencyonasmall-scaledatasetof8000objects[7],albeit
impracticallylonggenerationtimes[29,59]. Thesemethods withlimitedgeneralization. Incontrast,GIMDiffusiontack-
adaptexisting2Ddiffusionmodelsto3Dbyapplyingscore les general Text-to-3D: rather than training a model from
distillation sampling [37, 55] to iteratively optimize a 3D scratch,weleverageapre-trainedText-to-Imagediffusion
representation[23,33]. Thekeyadvantageofthisapproach model (using a Collaborative Control scheme trained on
is its ability to utilize the rich 2D prior, allowing for 3D Objaverse[8])toretaingeneralizationanddiversityforthe
objectgenerationwithouttheneedforexpensive3Ddata. shapes,theirappearance,andtheUVatlaslayout.
3(b) Extracted geometry image (b) Extracted geometry image
(b) Extracted geometry image (b) Extracted geometry image
(b)Extractedgeometryimage
(b) Extracted geometry image (b) Extracted geometry image
(a)Inputmesh (c)Extractedalbedotexture (d)Reconstructedmesh
Figure2.(a)Ground-truthgeometry,(b)geometryimageand(c)albedotexturefromourdatapre-processing,and(d)thereconstruction
usingourdedicatedVAE.Wenotethehighlyseparablenatureofthegroundtruthobject,whichissplitintosmallcomponents.Theonly
visibleartifactafterdecodingisthemissingconnectionbetweenthevariouschartsofthegeometryimage,asdiscussedinSecs.3.3and4.3.
3.Method Asthedensityofthegeneratedgeometry’striangulation
isrestrictedbytheresolutionoftheunderlyinggeometryim-
3.1.GeometryImages
age,wefollow[38]anduseaVAEtoincreasetheeffective
resolutionofourproposedmodel. Toaddresstheirregulari-
Geometryimages[12]representa3Dsurfaceinimagefor-
tiesingeometryimagesandbettermatchtheirdistribution—
mat as a function ϕ : [0,1]2 → S ∈ R3, where S is the
particularlytheneedtoaccuratelyreconstructthedisconti-
(a) Input mesh (c) Extracted albedo tex(tau)roeIbjenctspurfauceantd[0m,1]2 reepressenhtstheUVcoo(rdidnate)sinReconstructed mesh (c) Extracted albedo texture (d) Reconstructed mesh
nuitiesattheboundariesofthecharts—weaddachannelto
theunitsquare,typicallysampledonauniformgridofthe
representthemulti-chartmaskandmodifythelossfunction
desiredresolution. Thechoiceofthefunctionϕiscritical
accordingly. Otherwise,wefollowtheVAEtrainingproce-
andisusuallydesignedtominimizespatialdistortion(using
durefromStableDiffusion1.5[38]. AsshowninFig.2,the
conformalmapping)forauniformcoveringofthegeometry.
reconstructionusingthisVAEdoesnotvisuallydifferfrom
Unlike a traditional mesh, which requires explicit data
theinputmesh,exceptforthemissingconnectionsbetween
structurestomaintainconnectivityinformationtoformfaces,
thecharts,whichwedonotcurrentlyhandle.
geometryimagesimplicitlyconnecteachpixeltoitsimmedi-
ateneighbors. WhileGuetal.cuttheinputsurfaceandwarp
3.2.Collaborativecontrol
itontoadisc[12](i.e.restrictedtomanifoldobjects,result-
inginsignificantdistortionsforhigh-genusobjects),Multi- Tomaximallyleveragethepriorknowledgeencodedinex-
(a) Input mesh (c) Extracted albedo tex(tau)reICnhartpGeoumettryImmages[e40]saddhressthislimita (tio dnby )usin Rg eistcingo2DnTexst-tot-Imraugemcodtelse,wdeusetmheColelabsorahtive (c) Extracted albedo texture (d) Reconstructed mesh
atlasconstructiontomapthesurfacepiecewiseontoseveral Controlapproach[53]. AsshowninFig.3,thisapproach
chartsofarbitraryshape(eachchartbeinghomeomorphicto comprisestwoparallelnetworks: apre-trainedRGBmodel
adisc). Thisapproachaddsflexibility(removingtheman- andanewmodelforthegeometryimage. Theformerisre-
ifoldconstraint),andreducesdistortion(providinggreater sponsibleforgeneratingUV-spacealbedotextures,whilethe
geometricfidelity),thoughtheoptimalconstructionofsuch lattergeneratesthegeometryimages. Thesetwomodelsare
multi-chartGIMsremainsanactiveareaofresearch[41,50]. connectedbyasimplelinearcross-networkcommunication
Fortunately,mostavailable3Dmesheshavetexturesap- layer,whichallowsthemtoshareinformationandcollabo-
pliedthroughUVmaps. Weobservethatthesehandcrafted rateingeneratingpixel-alignedoutputsacrossthesedifferent
UVmapscanbeemployedtoconstructadesirablemulti- modalities. Crucially,thisalsoenablesthegeometrymodel
chartϕ. Furthermore,chartsinhandcraftedUVmapsoften to influence the frozen model, guiding it to generate UV-
(a) Input mesh (c) Extracted albedo tex(tau)reInput mesh (d) Reconstructed mesh (c) Extracted albedo texture (d) Reconstructed mesh
carrysemanticmeanings,whichpropagatetotheoutputof spacetexturesthatwouldotherwiselieatthefringesofits
ourmodel. ThisisevidentinFig.2,wherethehands,face, trainingdistribution. Thefrozenbasemodelalsodrastically
andvariouspartofthegunslinger’sappearanceareclearly reducestheamountofdatarequiredtotrainthejointmodel
separatedintheUVatlas. whileretaininggeneralizability,diversity,andquality[53].
4AlbedoTextureDiffusion
(cid:11)
Self-attention HiddenState ! HiddenState Cross-attention
×N
z z
albedo,t+1 Cross-domain albedo,t
communication TextPrompt
×N
‰
Self-attention HiddenState ! HiddenState Cross-attention
‰
GeometryImageDiffusion
z z
gim,t+1 gim,t
Figure3. TheCollaborativeControlScheme[53]appliedinGIMDiffusion,wheretwoseparatediffusionmodelsgeneraterespectively
albedotexturesandgeometryimages.Theformerisafrozenpre-trainedmodel,whilethelatterisanarchitecturalclonetrainedfromscratch.
3.3.DataHandling 2
3.3.1 Dataset 2 1
WetrainourmodelontheObjaversedataset[8]. Wecurate
1
thisdatasettoincludeonlyobjectswithbothhigh-quality 1
structuresandsemanticallymeaningfulUVmapsbyfilter- 2
ing out 3D scans and low-poly models. The final dataset 2
contains approximately 100,000 objects. Each data entry
is accompanied by captions provided by Cap3D [30] and
Figure4. Seamdetectioninourmulti-chartgeometryimagecre-
Hongetal.[14]. Duringtraining,werandomlysamplefrom
ationproceduretoisolatelocallyinvertibleareasoftheUVmap-
thesecaptionsandapplyrandomrotationsof90,180,or270
ping. (Left)Iftwoneighboringmeshregionscorrespondtotwo
degreestotheextractedtextureatlases. Wenowdiscusshow distinctchartsintheUVmap,theverticesontheboundarywillbe
totransformthesemeshesintogeometryimagesandback: duplicatedandhavedifferentUVcoordinates. (Right)IftheUV
theentirepreprocessingwasperformedonconsumer-grade mappingloopsbackontoitself,therewillbealocalminimumin
PChardware(AMDRyzen97950X,GeForceRTX3090, theUVaccessheatmap,andweplacetheseamalongthelinewith
64GBRAM)andtookapproximately20hours. thesmallestUV-degreetoeffectivelyseparatetheseregions.
3.3.2 GeometryImageCreation
To create multi-chart geometry images for the training We begin by identifying the connected components of
shapes, we use their existing UV maps. UV mapping is the mesh, which provides an initial separation into charts.
defined as the mapping ρ : V → [0,1]2, where V is the Withineachcomponent,weidentifytwosituationswhere
setofverticesina3DmeshandρmapseachvertextoUV ρisnotinvertible: duplicatedverticeswithdistinctUVco-
coordinates. Notethatthismappingisnotinjective(multiple ordinates, and a “crease”, i.e. a line where the UV coor-
verticescanbemappedtothesameUVcoordinates),noris dinates change direction (similar to a “mirror” boundary
itasimplefunctionofthevertexpositionsinR3,asmodern constraint). Both situations are visualized in Fig. 4. The
meshformatsallowformultipleverticeswithdistinctUV formerisstraightforwardtodetect,aswecandetectdupli-
coordinates at the same 3D location (to handle sharp tex- catedvertexpositions. Thelatterisdetectedbycreatinga
turetransitions). Theseissuesmeanthatρisnotinvertible, heatmap of the access pattern in UV space and detecting
whichwouldbeasimplewaytocreateageometryimage local minima. We then further split the individual charts
function. However,wearguethatρislocallyinvertibleand alonganydetectedcreases. Finally,inlinewiththedesirable
proposetoconstructamulti-chartgeometryimagebasedon mappingpropertiesdiscussedin[47],weadjustthegeome-
theindividuallyinvertibleareasoftheavailableUVmapping. tryimagemappingtoapproximateanequal-areaprojection
Asmentionedbefore, theislandsinaUVatlastendtobe by rescaling each 2D chart with respect to the area of the
semanticallymeaningful,sothatweaimtopreservethem. correspondingsurface.
5
(cid:244) (cid:244)3.4.Training
For the frozen base model, we used a zero-terminal-
SNR [25] version fine-tuned [52] from StableDiffusion
v2.1 [38] as the base Text-to-Image model, which is kept
frozen and generates the albedo textures. The geometry
modelisanarchitecturalclonethatistrainedfromscratch,
togetherwiththecross-networkcommunicationlayers. Ini-
tially,wetrainthemodelat256×256resolutionfor250,000
steps with a batch size of 48, and then at the final output
Figure5. Theresultingtriangulationofourgeneratedobjectsis
resolutionof768×768foratotalof100,000stepswitha
near-uniformoverthesurface,thankstothearea-preservingnature
batchsizeof8. Allstagesoftrainingwereconductedwitha
ofthegeometryimagesinourtrainingdataset.
learningrateof3e−5on8A100GPUs.
IncaseswhereonlyapartialUVmappingisavailable,we 4.Results
useXatlas[63]toUV-unwrapthemissingregions. However,
Figure 1 shows the results of our method on a set of text
sincetheXatlasparametrizationisoflowerqualityandlacks
prompts, generating objects as they might reasonably be
semantic properties, we exclude meshes where less than
queried, for example, in a gaming workflow. The objects
80%ofthesurfaceareahasbeenunwrappedmanually. This
arewell-definedandcanberelitfromanydirection,asthe
simpleheuristicallowsustoconstructmulti-chartgeometry
generatedalbedotexturesdonotcontainanylighting-related
imagesfornearlyalltrainingexamples.However,itdoesnot
artifacts. Furthermore,Fig.6illustratesthatourproposed
accountforallpossibledegeneratecasesofρ. Therefore,we
methodisabletogeneratenon-trivialvariationsforseedor
verifythattheconstructedρisinjectiveandskipanytraining
promptperturbations,whichiscrucialforthepracticaluse
meshesforwhichthisassumptionisviolated.
ofsuchasystem.
Akeyobservationwemakewithregardtotheconcurrent
3.3.3 Coordinatetransform
work of Yan et al. [61] is that their method exhibits only
verylittlevariationintheUVlayoutofthegeneratedobjects
InObjaverse[8],theobjectsarenotalignedinacanonical
withinagivenclass. Incontrast,GIMDiffusionshowssig-
way. AlthoughalmostallshapesareorientedwiththeYaxis
nificantlydifferentUVlayoutswheneithertheseedorthe
pointing upward, there is no fixed front view. In practice,
promptisvariedslightly,whichincreasesthepracticalvalue
this leads to a rotational ambiguity between the X and Z
ofgeneratedmultipleobjects. Finally,benefitingfromthe
axes. To resolve this ambiguity and isolate it to a single
richnaturalimageprior,ourmodelgeneralizeswellbeyond
coordinate,weleveragecylindricalcoordinates(r,θ,ϕ)so
theinitial3Ddataset. Additionalexamplesdemonstrating
thattheambiguityiscontainedwithintheazimuthθ.
thisgeneralizationareshowninFig.7.
3.3.4 MeshExtraction 4.1.IPAdapterCompatibility
AsmentionedinSec.3.1, geometryimagesimplicitlyen- In practical terms, guiding the style of generated objects
codeconnectivityinformationofthemeshbytreatingneigh- is crucial for many applications. Major efforts have been
boring pixels as connected in 3D space, i.e. a quad mesh. madetoachievestylecontrolindiffusionmodels[62],and
However,toconvertthemintoamorewidelysupportedtri- ourmethodiscompatiblewiththesetechniques,similarto
angularmesh,weneedtospecifyexactlyhowtotriangulate the original Collaborative Control approach [53]. As we
thequads. Forthis, wecloselyfollowthealgorithmfrom areleveragingafrozenbasemodeltogeneratethealbedo
Sanderetal.[40]. Forany2×2blockofpixelsintheGIM, textures,wecanapplyapre-trainedIPAdaptertothatbase
we create up to two triangles depending on how many of model and produce stylized output meshes, as shown in
thepixelsarevalid: ifnecessary,thequadissplitalongits Fig.8. Despitethesignificantmismatchintheapplication
shorterdiagonal. AsshowninFig.5,andinlinewithour domain (natural images compared to albedo atlases), the
goalofarea-preservingmapping[47],theresultingtriangu- style guidance remains successful. We find that this ap-
lationisnearlyuniformoverthesurface,whichmayormay proachstartstobreakdownwhenthetextpromptdeviates
not be desirable for specific applications (as the working toomuch(structurally)fromthecontentoftheconditioning
resolutionofourmodelis768×768,ourGIMscanencode image, which we attribute to the fact that IPAdapter aims
mesheswithupto589,824vertices). Weconsiderthegener- toleverageeveryaspectoftheconditioningimage;bute.g.
ationofarbitrarytopologiesorwithapolygonconstrainta IPAdapterInstruct[39]offersaselectiveextractionofjust
promisingareaoffutureworkforGIMDiffusion. appearancestylebutwithoutentanglingstructure.
6Seed: 906412 Seed:745785 Seed:149311 Seed:454712 Seed:352231 Seed:161715
Prompt:Aflyagaricmushroom Prompt:Aredplasticchair
Figure6.SamplediversityofGIMDiffusionforminorchangestothepromptordifferentrandomseedsfortheinitialgaussiannoise.It
isclearthatthegeneratedvariationsdiffersignificantly,notjustinappearanceandstructurebutalsointhetexture’satlaslayout.Thisis
invaluableinpracticalapplications,whereuserstypicallygeneratemultipleoptionsandpickthebestone.
Anorganicaliengunisstyleof WoodenchestwithVanGogh’s
H.R.Giger StarryNightpaintedonit <Noprompt>
Asteampunkairplane Anavocado-shapedchair Akingsizebed. Asofa.
Figure 7. GIMDiffusion, thanks to the powerful natural image Figure8.Wecanstylisticallyguidethereverseprocessbyapplying
prior of the base model in combination with the Collaborative apre-trainedIPAdaptertothefrozenbasemodelgenerationthe
Controlscheme,generalizeswelloutsidethe“vanilla”natureof albedotextures[62]. Thisisextremelyvaluableinapplications
theObjaversetrainingdata. wheretheassetsneedtomatchanexisting“feel”.
7
erutxeTodeblA
hseMderutxeT
hseMderutxetnU(a)Albedotexture (b)Texturedmesh (c)Explodedviewofthegeometry
Figure9.Thegeneratedimagesretainthesemanticallymeaningfulseparationofchartsinthetextureatlas.Weillustratethisherebyshowing
anexplodedviewofagenerated“Aflyagaricmushroom”.Itisclearthatthevariouspartsofthemushroomwereseparatedasahuman
might,andthatthemethodisevenabletomodelinternalpartsoftheshape.
4.2.SeparabilityandInternalStructure Additionally, we find that the model sometimes dupli-
catespartsoftheobject,whichcanleadtovisualartifacts
Akeyadvantageofourmethodisthatitgeneratesobjects
inthegeneratedmeshesduetoz-fighting. However,thesep-
dividedintodistinctsemantic(ornearlysemantic)partsas
aratednatureofthegeneratedobjectsmakestheseartifacts
shown in Fig. 9, making the generated objects more suit-
relativelyeasytoresolvemanually.
ableforeditingandanimation. Thiscapabilityarisesfrom
themulti-chartrepresentationdesignandthesemanticinfor-
5.Discussionandfuturework
mationembeddedinthetrainingdatathroughhandcrafted
UV-maps,whichlooselycorrespondtothesemanticcompo-
In this work, we present Geometry Image Diffusion
nentsofobjects. Thisapproachalsoallowsuserstoeasily
(GIMDiffusion), a novel Text-to-3D generation paradigm
correctimperfections,suchasmisalignedpartsorextraneous
thatutilizesgeometryimagesasitscore3Drepresentation
geometry,andevencombinedifferentpartsfrommultiple
in combination with powerful natural image priors in the
generations. Additionally, our method generates internal
formofpre-traineddiffusionmodels. Ourresultsshowthat
structures, such as the filament inside a light bulb or the
GIMDiffusion can generate relightable 3D assets as effi-
interiorofafishtank,becausegeometryimagesrepresent
cientlyasexistingText-to-Imagemethodsgeneratenormal
theentireobjectholistically,notjustthevisiblesurfaces.
images,whileavoidingtheneedforcomplex,custom3D-
awarearchitectures. Webelievethatourresearchlaysthe
4.3.Limitations
groundworkforanewdirectioninText-to-3Dgeneration.
Our current method is not without limitations. The most Furtherqualityimprovementsincludeaddressingissues
commonissueistheappearanceofvisiblecracksinthegen- suchasinter-chartalignmentandeliminatingvisiblecracks.
eratedmeshes. Whilewedonotcurrentlystitchthecharts’ Additionally,incorporatingtopologypredictionandcondi-
seamstogether,whichcouldimprovethevisualqualityof tioningonspecificpolygonbudgetswouldenhancecontrol
thegeneratedmeshes, webelievethatthis problemisfur- overthegenerated3Dobjects,makingthemmoresuitable
ther exacerbated by the VAE’s latent compression. Areas for use in gaming and other graphics pipelines. Equally
smallerthan8×8pixelsareessentiallybelowtheVAE’s promisingisthepotentialofGIMDiffusioninrelatedfields
latentresolution,causingvisualproblems. suchasanimationortext-to-videogeneration.
Wealsoencounterconsiderableambiguityinthegeome-
tryimagemapping.Althoughindividualchartsinageometry 6.Acknowledgements
imagecanberotatedarbitrarilyandstillrepresentthesame
3Dobject,thefrozenbasemodelisnotrotationallyequiv- WewouldliketothankShimonVainerfromUnityTechnolo-
ariant[57]. Humanfacesserveasagoodexample—while gies,Dr. LevMelnikovskyfromtheWeizmannInstituteand
typicallyuprightinnaturalimages,theycanappearinran- AlexanderDemidkofortheirvaluablefeedbackandinsight-
domorientationsontexturemaps, whichleadstovarying ful discussions. Konstantin Kutsy has been invaluable in
(andoveralllower)qualityforsuchprompts. helpingusoperateourtraininginfrastructure.
8References etryimages. Proceedingsofthe29thannualconferenceon
Computergraphicsandinteractivetechniques,2002. 1,3,4
[1] HassanAbuAlhaija,AlaraDirik,Andr’eKnorig,SanjaFi-
[13] Lukas Höllein, Aljavz Bovzivc, Norman Muller, David
dler, and Maria Shugrina. Xdgan: Multi-modal 3d shape
Novotny,Hung-YuTseng,ChristianRichardt,MichaelZoll-
generationin2dspace.InBritishMachineVisionConference,
hofer,andMatthiasNießner. Viewdiff:3d-consistentimage
2022. 3
generationwithtext-to-imagemodels.ArXiv,abs/2403.01807,
[2] ThiemoAlldieck,NikosKolotouros,andCristianSminchis-
2024. 3
escu. Scoredistillationsamplingwithlearnedmanifoldcor-
[14] FangzhouHong,JiaxiangTang,ZiangCao,MinShi,Tong
rective. ArXiv,abs/2401.05293,2024. 3
Wu,ZhaoxiChen,TengfeiWang,LiangPan,DahuaLin,and
[3] RaphaelBensadoun,TomMonnier,YanirKleiman,Filippos ZiweiLiu. 3dtopia:Largetext-to-3dgenerationmodelwith
Kokkinos,YawarSiddiqui,MahendraKariya,OmriHarosh, hybriddiffusionpriors. ArXiv,abs/2403.02234,2024. 5
Roman Shapovalov, Benjamin Graham, Emilien Garreau,
[15] YicongHong,KaiZhang,JiuxiangGu,SaiBi,YangZhou,
Animesh Karnewar, Ang Cao, Idan Azuri, Iurii Makarov,
DifanLiu,FengLiu,KalyanSunkavalli,TrungBui,andHao
Eric-TuanLe,AntoineToisoul,DavidNovotny,OranGafni,
Tan. Lrm:Largereconstructionmodelforsingleimageto3d.
NataliaNeverova,andAndreaVedaldi. Meta3dgen,2024. 3
ArXiv,abs/2311.04400,2023. 3
[4] MarkBoss,ZixuanHuang,AaryamanVasishta,andVarun [16] LiuchengHu,XinGao,PengZhang,KeSun,BangZhang,
Jampani. Sf3d:Stablefast3dmeshreconstructionwithuv- andLiefengBo.Animateanyone:Consistentandcontrollable
unwrappingandilluminationdisentanglement. 2024. 1 image-to-video synthesis for character animation. ArXiv,
[5] EricChan,ConnorZ.Lin,MatthewChan,KokiNagano,Box- abs/2311.17117,2023. 3
iaoPan,ShaliniDeMello,OrazioGallo,LeonidasJ.Guibas, [17] ZixuanHuang,JustinJohnson,ShoubhikDebnath,JamesM.
JonathanTremblay,S.Khamis,TeroKarras,andGordonWet- Rehg,andChao-YuanWu.Pointinfinity:Resolution-invariant
zstein. Efficientgeometry-aware3dgenerativeadversarial pointdiffusionmodels. 2024. 3
networks. 2022IEEE/CVFConferenceonComputerVision
[18] HeewooJunandAlexNichol.Shap-e:Generatingconditional
andPatternRecognition(CVPR),pages16102–16112,2021.
3dimplicitfunctions. ArXiv,abs/2305.02463,2023. 3
3
[19] YashKant,ZiyiWu,MichaelVasilkovsky,GuochengQian,
[6] Zhiqin Chen andHao Zhang. Learning implicit fieldsfor Jian Ren, Riza Alp Guler, Bernard Ghanem, S. Tulyakov,
generativeshapemodeling. 2019IEEE/CVFConferenceon IgorGilitschenski,andAliaksandrSiarohin. Spad:Spatially
Computer Vision and Pattern Recognition (CVPR), pages awaremultiviewdiffusers. ArXiv,abs/2402.05235,2024. 3
5932–5941,2018. 3
[20] TeroKarras, SamuliLaine, andTimoAila. Astyle-based
[7] JasmineCollins,ShubhamGoel,AchleshwarLuthra,LeonL. generator architecture for generative adversarial networks.
Xu, Kenan Deng, Xi Zhang, T. F. Y. Vicente, Himanshu 2019IEEE/CVFConferenceonComputerVisionandPattern
Arora,T.L.Dideriksen,MatthieuGuillaumin,andJitendra Recognition(CVPR),pages4396–4405,2018. 3
Malik.Abo:Datasetandbenchmarksforreal-world3dobject [21] Oren Katzir, Or Patashnik, Daniel Cohen-Or, and Dani
understanding. 2022IEEE/CVFConferenceonComputer Lischinski. Noise-free score distillation. ArXiv,
VisionandPatternRecognition(CVPR),pages21094–21104, abs/2310.17590,2023. 3
2021. 3
[22] BingWenKe,AntonObukhov,ShengyuHuang,NandoMet-
[8] MattDeitke,DustinSchwenk,JordiSalvador,LucaWeihs, zger,RodrigoCayeDaudt,andKonradSchindler. Repurpos-
OscarMichel,EliVanderBilt,LudwigSchmidt,KianaEhsani, ingdiffusion-basedimagegeneratorsformonoculardepth
AniruddhaKembhavi,andAliFarhadi.Objaverse:Auniverse estimation. ArXiv,abs/2312.02145,2023. 3
of annotated 3d objects. 2023 IEEE/CVF Conference on [23] BernhardKerbl, GeorgiosKopanas, ThomasLeimkuehler,
Computer Vision and Pattern Recognition (CVPR), pages and George Drettakis. 3d gaussian splatting for real-time
13142–13153,2022. 3,5,6 radiance field rendering. ACM Transactions on Graphics
[9] AkioDoiandAkioKoide. Anefficientmethodoftriangu- (TOG),42:1–14,2023. 3
latingequi-valuedsurfacesbyusingtetrahedralcells. IEICE [24] YixunLiang,XinYang,JiantaoLin,HaodongLi,Xiaogang
TransactionsonInformationandSystems,74:214–224,1991. Xu,andYingcongChen.Luciddreamer:Towardshigh-fidelity
3 text-to-3d generation via interval score matching. ArXiv,
[10] YiqunDuan,XiandaGuo,andZhengbiaoZhu. Diffusion- abs/2311.11284,2023. 3
depth: Diffusion denoising approach for monocular depth [25] ShanchuanLin,BingchenLiu,JiashiLi,andXiaoYang.Com-
estimation. ArXiv,abs/2303.05021,2023. 3 mondiffusionnoiseschedulesandsamplestepsareflawed.
[11] PatrickEsser,SumithKulal,A.Blattmann,RahimEntezari, InProceedingsoftheIEEE/CVFWinterConferenceonAp-
JonasMuller,HarrySaini,YamLevi,DominikLorenz,Axel plicationsofComputerVision,pages5404–5411,2024. 6
Sauer,FredericBoesel,DustinPodell,TimDockhorn,Zion [26] YaronLipman,RickyTQChen,HeliBen-Hamu,Maximilian
English, Kyle Lacey, Alex Goodwin, Yannik Marek, and Nickel,andMattLe. Flowmatchingforgenerativemodeling.
RobinRombach. Scalingrectifiedflowtransformersforhigh- 2022. 3
resolution image synthesis. ArXiv, abs/2403.03206, 2024. [27] RuoshiLiu,RundiWu,BasileVanHoorick,PavelTokmakov,
3 Sergey Zakharov, and Carl Vondrick. Zero-1-to-3: Zero-
[12] XianfengGu,StevenJ.Gortler,andHuguesHoppe. Geom- shotoneimageto3dobject. 2023IEEE/CVFInternational
9ConferenceonComputerVision(ICCV),pages9264–9275, [42] ChristophSchuhmann,RomainBeaumont,RichardVencu,
2023. 3 CadeGordon,RossWightman,MehdiCherti,TheoCoombes,
[28] WilliamE.LorensenandHarveyE.Cline. Marchingcubes: AarushKatta,ClaytonMullis,MitchellWortsman,Patrick
Ahighresolution3dsurfaceconstructionalgorithm.Proceed- Schramowski,SrivatsaKundurthy,KatherineCrowson,Lud-
ingsofthe14thannualconferenceonComputergraphicsand wigSchmidt,RobertKaczmarczyk,andJeniaJitsev. Laion-
interactivetechniques,1987. 3 5b:Anopenlarge-scaledatasetfortrainingnextgeneration
[29] JonathanLorraine,KevinXie,XiaohuiZeng,Chen-Hsuan image-textmodels. ArXiv,abs/2210.08402,2022. 3
Lin,TowakiTakikawa,NicholasSharp,Tsung-YiLin,Ming- [43] RuoxiShi,HanshengChen,ZhuoyangZhang,MinghuaLiu,
YuLiu,SanjaFidler,andJamesLucas. Att3d: Amortized ChaoXu,XinyueWei,LinghaoChen,ChongZeng,andHao
text-to-3dobjectsynthesis. 2023IEEE/CVFInternational Su. Zero123++: a single image to consistent multi-view
ConferenceonComputerVision(ICCV),pages17900–17910, diffusionbasemodel. ArXiv,abs/2310.15110,2023. 3
2023. 3 [44] YichunShi,PengWang,JianglongYe,MaiLong,KejieLi,
[30] TiangeLuo,ChrisRockwell,HonglakLee,andJustinJohn- andX.Yang. Mvdream:Multi-viewdiffusionfor3dgenera-
son. Scalable3dcaptioningwithpretrainedmodels. arXiv tion. ArXiv,abs/2308.16512,2023. 3
preprintarXiv:2306.07279,2023. 5 [45] YawarSiddiqui,AntonioAlliegro,AlexeyArtemov,Tatiana
Tommasi,DanieleSirigatti,VladislavRosov,AngelaDai,and
[31] RaviMalladi,JamesA.Sethian,andBabaC.Vemuri. Shape
MatthiasNießner. Meshgpt:Generatingtrianglemesheswith
modelingwithfrontpropagation:Alevelsetapproach. IEEE
decoder-onlytransformers,2023. 3
Trans.PatternAnal.Mach.Intell.,17:158–175,1995. 3
[46] YawarSiddiqui,TomMonnier,FilipposKokkinos,Mahendra
[32] Lars M. Mescheder, Michael Oechsle, Michael Niemeyer,
Kariya, YanirKleiman, EmilienGarreau, OranGafni, Na-
Sebastian Nowozin, and Andreas Geiger. Occupancy net-
taliaV.Neverova,AndreaVedaldi,RomanShapovalov,and
works: Learning3dreconstructioninfunctionspace. 2019
DavidNovotny. Meta3dassetgen:Text-to-meshgeneration
IEEE/CVF Conference on Computer Vision and Pattern
withhigh-qualitygeometry,texture,andpbrmaterials. ArXiv,
Recognition(CVPR),pages4455–4465,2018.
abs/2407.02445,2024. 1
[33] Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik,
[47] AyanSinha,JingBai,andKarthikRamani. Deeplearning3d
JonathanT.Barron,RaviRamamoorthi,andRenNg. Nerf.
shapesurfacesusinggeometryimages. InEuropeanConfer-
CommunicationsoftheACM,65:99–106,2020. 3
enceonComputerVision,2016. 3,5,6
[34] Alex Nichol, Heewoo Jun, Prafulla Dhariwal, Pamela
[48] JaschaSohl-Dickstein,EricAWeiss,NiruMaheswaranathan,
Mishkin,andMarkChen.Point-e:Asystemforgenerating3d
and Surya Ganguli. Deep unsupervised learning using
pointcloudsfromcomplexprompts. ArXiv,abs/2212.08751,
nonequilibriumthermodynamics. 2015. 3
2022. 3
[49] Yang Song, Jascha Narain Sohl-Dickstein, Diederik P.
[35] PabloPernias,DominicRampas,MatsL.Richter,Christo-
Kingma,AbhishekKumar,StefanoErmon,andBenPoole.
pher Pal, and Marc Aubreville. Würstchen: An efficient
Score-basedgenerativemodelingthroughstochasticdifferen-
architectureforlarge-scaletext-to-imagediffusionmodels.In
tialequations. ArXiv,abs/2011.13456,2020. 3
InternationalConferenceonLearningRepresentations,2024.
[50] Pratul P. Srinivasan, Stephan J. Garbin, Dor Verbin,
3
Jonathan T. Barron, and Ben Mildenhall. Nuvo: Neu-
[36] DustinPodell,ZionEnglish,KyleLacey,A.Blattmann,Tim
ral uv mapping for unruly 3d representations. ArXiv,
Dockhorn, Jonas Muller, Joe Penna, and Robin Rombach.
abs/2312.05283,2023. 4
Sdxl:Improvinglatentdiffusionmodelsforhigh-resolution
[51] Dmitry Tochilkin, David Pankratz, Zexiang Liu, Zixuan
imagesynthesis. ArXiv,abs/2307.01952,2023. 3
Huang, Adam Letts, Yangguang Li, Ding Liang, Chris-
[37] BenPoole,AjayJain,JonathanT.Barron,andBenMilden-
tian Laforte, Varun Jampani, and Yan-Pei Cao. Triposr:
hall. Dreamfusion: Text-to-3d using 2d diffusion. ArXiv, Fast3dobjectreconstructionfromasingleimage. ArXiv,
abs/2209.14988,2022. 3
abs/2403.02151,2024. 3
[38] Robin Rombach, A. Blattmann, Dominik Lorenz, Patrick [52] https://huggingface.co/drhead. Hugging-
Esser,andBjörnOmmer. High-resolutionimagesynthesis face zerodiffusion model weights v0.9. https://
withlatentdiffusionmodels. 2022IEEE/CVFConference huggingface.co/drhead/ZeroDiffusion. Ac-
onComputerVisionandPatternRecognition(CVPR),pages cessed:2024-02-08. 6
10674–10685,2021. 3,4,6 [53] ShimonVainer,MarkBoss,MathiasParger,KonstantinKutsy,
[39] Ciara Rowles, Shimon Vainer, Dante De Nigris, Slava DanteDeNigris,CiaraRowles,NicolasPerony,andSimon
Elizarov, KonstantinKutsy, andSimonDonné. Ipadapter- Donn’e. Collaborativecontrolforgeometry-conditionedpbr
instruct: Resolvingambiguityinimage-basedconditioning imagegeneration. ArXiv,abs/2402.05919,2024. 1,3,4,5,6
usinginstructprompts,2024. 6 [54] Ashish Vaswani, Noam M. Shazeer, Niki Parmar, Jakob
[40] Pedro V. Sander, Zoë J. Wood, Steven J. Gortler, John M. Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser,
Snyder,andHuguesHoppe. Multi-chartgeometryimages. In andIlliaPolosukhin. Attentionisallyouneed. InNeural
EurographicsSymposiumonGeometryProcessing,2003. 3, InformationProcessingSystems,2017. 3
4,6 [55] HaochenWang,XiaodanDu,JiahaoLi,RaymondA.Yeh,
[41] RohanSawhneyandKeenanCrane. Boundaryfirstflattening. andGregoryShakhnarovich. Scorejacobianchaining:Lift-
ACMTransactionsonGraphics(TOG),37:1–14,2017. 4 ingpretrained2ddiffusionmodelsfor3dgeneration. 2023
10IEEE/CVF Conference on Computer Vision and Pattern
Recognition(CVPR),pages12619–12629,2022. 3
[56] ZhengyiWang,ChengLu,YikaiWang,FanBao,Chongxuan
Li,HangSu,andJunZhu. Prolificdreamer:High-fidelityand
diversetext-to-3dgenerationwithvariationalscoredistilla-
tion. ArXiv,abs/2305.16213,2023. 1,3
[57] MauriceWeiler, PatrickForr’e, ErikP.Verlinde, andMax
Welling. Coordinateindependentconvolutionalnetworks-
isometryandgaugeequivariantconvolutionsonriemannian
manifolds. ArXiv,abs/2106.06020,2021. 8
[58] ZikeWu,PanZhou,XuanyuYi,XiaodingYuan,andHan-
wangZhang. Consistent3d:Towardsconsistenthigh-fidelity
text-to-3dgenerationwithdeterministicsamplingprior.ArXiv,
abs/2401.09050,2024. 3
[59] KevinXie,JonathanLorraine,TianshiCao,JunGao,James
Lucas, Antonio Torralba, Sanja Fidler, and Xiaohui Zeng.
Latte3d:Large-scaleamortizedtext-to-enhanced3dsynthesis.
ArXiv,abs/2403.15385,2024. 3
[60] YihengXie,TowakiTakikawa,ShunsukeSaito,OrLitany,
ShiqinYan,NumairKhan,FedericoTombari,JamesTompkin,
VincentSitzmann,andSrinathSridhar.Neuralfieldsinvisual
computingandbeyond. ComputerGraphicsForum,41,2021.
3
[61] Xingguang Yan, Han-Hung Lee, Ziyu Wan, and Angel X.
Chang. An object is worth 64x64 pixels: Generating 3d
objectviaimagediffusion. 2024. 3,6
[62] HuYe,JunZhang,SiboLiu,XiaoHan,andWeiYang. Ip-
adapter: Textcompatibleimagepromptadapterfortext-to-
imagediffusionmodels. arXivpreprintarXiv:2308.06721,
2023. 6,7
[63] JonathanYoung. Xatlas:Meshparameterization/uvunwrap-
pinglibrary. https://github.com/jpcy/xatlas,
2022. 6
[64] DenisZavadski,Johann-FriedrichFeiden,andCarstenRother.
Controlnet-xs:Designinganefficientandeffectivearchitec-
tureforcontrollingtext-to-imagediffusionmodels. ArXiv,
abs/2312.06573,2023. 3
[65] Xiaohui Zeng, Arash Vahdat, Francis Williams, Zan Goj-
cic,OrLitany,SanjaFidler,andKarstenKreis. Lion: La-
tentpointdiffusionmodelsfor3dshapegeneration. ArXiv,
abs/2210.06978,2022. 3
[66] LvminZhang,AnyiRao,andManeeshAgrawala. Adding
conditionalcontroltotext-to-imagediffusionmodels. 2023
IEEE/CVF International Conference on Computer Vision
(ICCV),pages3813–3824,2023. 3
[67] Chuanxia Zheng and Andrea Vedaldi. Free3d: Consis-
tentnovelviewsynthesiswithout3drepresentation. ArXiv,
abs/2312.04551,2023. 3
[68] XinZheng,YangLiu,Peng-ShuaiWang,andXinTong. Sdf-
stylegan:Implicitsdf-basedstyleganfor3dshapegeneration.
ComputerGraphicsForum,41,2022. 3
[69] JunzheZhu,PeiyeZhuang,andOluwasanmiKoyejo. Hifa:
High-fidelitytext-to-3dgenerationwithadvanceddiffusion
guidance. InInternationalConferenceonLearningRepresen-
tations,2023. 3
11