[
    {
        "title": "WildVis: Open Source Visualizer for Million-Scale Chat Logs in the Wild",
        "authors": "Yuntian DengWenting ZhaoJack HesselXiang RenClaire CardieYejin Choi",
        "links": "http://arxiv.org/abs/2409.03753v1",
        "entry_id": "http://arxiv.org/abs/2409.03753v1",
        "pdf_url": "http://arxiv.org/pdf/2409.03753v1",
        "summary": "The increasing availability of real-world conversation data offers exciting\nopportunities for researchers to study user-chatbot interactions. However, the\nsheer volume of this data makes manually examining individual conversations\nimpractical. To overcome this challenge, we introduce WildVis, an interactive\ntool that enables fast, versatile, and large-scale conversation analysis.\nWildVis provides search and visualization capabilities in the text and\nembedding spaces based on a list of criteria. To manage million-scale datasets,\nwe implemented optimizations including search index construction, embedding\nprecomputation and compression, and caching to ensure responsive user\ninteractions within seconds. We demonstrate WildVis's utility through three\ncase studies: facilitating chatbot misuse research, visualizing and comparing\ntopic distributions across datasets, and characterizing user-specific\nconversation patterns. WildVis is open-source and designed to be extendable,\nsupporting additional datasets and customized search and visualization\nfunctionalities.",
        "updated": "2024-09-05 17:59:15 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.03753v1"
    },
    {
        "title": "Limited but consistent gains in adversarial robustness by co-training object recognition models with human EEG",
        "authors": "Manshan GuoBhavin ChoksiSari SadiyaAlessandro T. GiffordMartina G. VilasRadoslaw M. CichyGemma Roig",
        "links": "http://arxiv.org/abs/2409.03646v1",
        "entry_id": "http://arxiv.org/abs/2409.03646v1",
        "pdf_url": "http://arxiv.org/pdf/2409.03646v1",
        "summary": "In contrast to human vision, artificial neural networks (ANNs) remain\nrelatively susceptible to adversarial attacks. To address this vulnerability,\nefforts have been made to transfer inductive bias from human brains to ANNs,\noften by training the ANN representations to match their biological\ncounterparts. Previous works relied on brain data acquired in rodents or\nprimates using invasive techniques, from specific regions of the brain, under\nnon-natural conditions (anesthetized animals), and with stimulus datasets\nlacking diversity and naturalness. In this work, we explored whether aligning\nmodel representations to human EEG responses to a rich set of real-world images\nincreases robustness to ANNs. Specifically, we trained ResNet50-backbone models\non a dual task of classification and EEG prediction; and evaluated their EEG\nprediction accuracy and robustness to adversarial attacks. We observed\nsignificant correlation between the networks' EEG prediction accuracy, often\nhighest around 100 ms post stimulus onset, and their gains in adversarial\nrobustness. Although effect size was limited, effects were consistent across\ndifferent random initializations and robust for architectural variants. We\nfurther teased apart the data from individual EEG channels and observed\nstrongest contribution from electrodes in the parieto-occipital regions. The\ndemonstrated utility of human EEG for such tasks opens up avenues for future\nefforts that scale to larger datasets under diverse stimuli conditions with the\npromise of stronger effects.",
        "updated": "2024-09-05 16:04:57 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.03646v1"
    },
    {
        "title": "Reimagining Data Visualization to Address Sustainability Goals",
        "authors": "Narges Mahyar",
        "links": "http://arxiv.org/abs/2409.03611v1",
        "entry_id": "http://arxiv.org/abs/2409.03611v1",
        "pdf_url": "http://arxiv.org/pdf/2409.03611v1",
        "summary": "Information visualization holds significant potential to support\nsustainability goals such as environmental stewardship, and climate resilience\nby transforming complex data into accessible visual formats that enhance public\nunderstanding of complex climate change data and drive actionable insights.\nWhile the field has predominantly focused on analytical orientation of\nvisualization, challenging traditional visualization techniques and goals,\nthrough critical visualization research expands existing assumptions and\nconventions in the field. In this paper, I explore how reimagining overlooked\naspects of data visualization, such as engagement, emotional resonance,\ncommunication, and community empowerment, can contribute to achieving\nsustainability objectives. I argue that by focusing on inclusive data\nvisualization that promotes clarity, understandability, and public\nparticipation, we can make complex data more relatable and actionable,\nfostering broader connections and mobilizing collective action on critical\nissues like climate change. Moreover, I discuss the role of emotional\nreceptivity in environmental data communication, stressing the need for\nvisualizations that respect diverse cultural perspectives and emotional\nresponses to achieve impactful outcomes. Drawing on insights from a decade of\nresearch in public participation and community engagement, I aim to highlight\nhow data visualization can democratize data access and increase public\ninvolvement in order to contribute to a more sustainable and resilient future.",
        "updated": "2024-09-05 15:16:37 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.03611v1"
    },
    {
        "title": "Improving Uncertainty-Error Correspondence in Deep Bayesian Medical Image Segmentation",
        "authors": "Prerak ModyNicolas F. Chaves-de-PlazaChinmay RaoEleftheria AstrenidouMischa de RidderNienke HoekstraKlaus HildebrandtMarius Staring",
        "links": "http://dx.doi.org/10.59275/j.melba.2024-5gc8",
        "entry_id": "http://arxiv.org/abs/2409.03470v1",
        "pdf_url": "http://arxiv.org/pdf/2409.03470v1",
        "summary": "Increased usage of automated tools like deep learning in medical image\nsegmentation has alleviated the bottleneck of manual contouring. This has\nshifted manual labour to quality assessment (QA) of automated contours which\ninvolves detecting errors and correcting them. A potential solution to\nsemi-automated QA is to use deep Bayesian uncertainty to recommend potentially\nerroneous regions, thus reducing time spent on error detection. Previous work\nhas investigated the correspondence between uncertainty and error, however, no\nwork has been done on improving the \"utility\" of Bayesian uncertainty maps such\nthat it is only present in inaccurate regions and not in the accurate ones. Our\nwork trains the FlipOut model with the Accuracy-vs-Uncertainty (AvU) loss which\npromotes uncertainty to be present only in inaccurate regions. We apply this\nmethod on datasets of two radiotherapy body sites, c.f. head-and-neck CT and\nprostate MR scans. Uncertainty heatmaps (i.e. predictive entropy) are evaluated\nagainst voxel inaccuracies using Receiver Operating Characteristic (ROC) and\nPrecision-Recall (PR) curves. Numerical results show that when compared to the\nBayesian baseline the proposed method successfully suppresses uncertainty for\naccurate voxels, with similar presence of uncertainty for inaccurate voxels.\nCode to reproduce experiments is available at\nhttps://github.com/prerakmody/bayesuncertainty-error-correspondence",
        "updated": "2024-09-05 12:31:51 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.03470v1"
    },
    {
        "title": "Strategic Chain-of-Thought: Guiding Accurate Reasoning in LLMs through Strategy Elicitation",
        "authors": "Yu WangShiwan ZhaoZhihu WangHeyuan HuangMing FanYubo ZhangZhixing WangHaijun WangTing Liu",
        "links": "http://arxiv.org/abs/2409.03271v1",
        "entry_id": "http://arxiv.org/abs/2409.03271v1",
        "pdf_url": "http://arxiv.org/pdf/2409.03271v1",
        "summary": "The Chain-of-Thought (CoT) paradigm has emerged as a critical approach for\nenhancing the reasoning capabilities of large language models (LLMs). However,\ndespite their widespread adoption and success, CoT methods often exhibit\ninstability due to their inability to consistently ensure the quality of\ngenerated reasoning paths, leading to sub-optimal reasoning performance. To\naddress this challenge, we propose the \\textbf{Strategic Chain-of-Thought}\n(SCoT), a novel methodology designed to refine LLM performance by integrating\nstrategic knowledge prior to generating intermediate reasoning steps. SCoT\nemploys a two-stage approach within a single prompt: first eliciting an\neffective problem-solving strategy, which is then used to guide the generation\nof high-quality CoT paths and final answers. Our experiments across eight\nchallenging reasoning datasets demonstrate significant improvements, including\na 21.05\\% increase on the GSM8K dataset and 24.13\\% on the Tracking\\_Objects\ndataset, respectively, using the Llama3-8b model. Additionally, we extend the\nSCoT framework to develop a few-shot method with automatically matched\ndemonstrations, yielding even stronger results. These findings underscore the\nefficacy of SCoT, highlighting its potential to substantially enhance LLM\nperformance in complex reasoning tasks.",
        "updated": "2024-09-05 06:28:05 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.03271v1"
    }
]