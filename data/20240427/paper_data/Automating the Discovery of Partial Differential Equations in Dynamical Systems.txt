AUTOMATICALLY EXTRACTING PARTIAL DIFFERENTIAL
EQUATIONS FROM DATA
APREPRINT
WeizhenLi RuiCarvalho
DepartmentofEngineering DepartmentofEngineering
DurhamUniversity DurhamUniversity
Durham,UK,DH13HN Durham,UK,DH13HN
weizhen.li@dur.ac.uk rui.carvalho@dur.ac.uk
ABSTRACT
Identifyingpartialdifferentialequations(PDEs)fromdataiscrucialforunderstandingthegoverning
mechanismsofnaturalphenomena,yetitremainsachallengingtask. Wepresentanextensiontothe
ARGOSframework,ARGOS-RAL,whichleveragessparseregressionwiththerecurrentadaptive
lassotoidentifyPDEsfromlimitedpriorknowledgeautomatically.Ourmethodautomatescalculating
partialderivatives,constructingacandidatelibrary,andestimatingasparsemodel. Werigorously
evaluatetheperformanceofARGOS-RALinidentifyingcanonicalPDEsundervariousnoiselevels
andsamplesizes,demonstratingitsrobustnessinhandlingnoisyandnon-uniformlydistributeddata.
Wealsotestthealgorithm’sperformanceondatasetsconsistingsolelyofrandomnoisetosimulate
scenarioswithseverelycompromiseddataquality. OurresultsshowthatARGOS-RALeffectively
andreliablyidentifiestheunderlyingPDEsfromdata,outperformingthesequentialthresholdridge
regressionmethodinmostcases.Wehighlightthepotentialofcombiningstatisticalmethods,machine
learning,anddynamicalsystemstheorytoautomaticallydiscovergoverningequationsfromcollected
data,streamliningthescientificmodelingprocess.
Keywords Systemidentification·Machinelearning·Sparseregression·Partialdifferentialequations·Nonlinear
dynamics
1 Introduction
Inrecentyears,scientistshaveincreasinglyemployedstatisticalandmachinelearningmethodstouncoverthegoverning
equationsofdynamicalsystems,particularlydifferentialequations,fromobservationaldata[1–5]. Data-drivenmethods
offerseveraladvantagesovertraditionalapproachesthatrelyonfirstprinciplesandexpertknowledge. Thesemethods
canrevealpatternsandrelationshipsinthedatathatmaynotbeapparentfromfirstprinciples,providingnewinsights
intocomplexsystems[6,7]. Theyarealsoadeptatworkingwithnoisyorincompletedatacommonlyencounteredin
real-worldapplications,employingtechniquesfrommachinelearningtoenhancetherobustnessofdiscoveries[8–11].
Furthermore,byreducingtheneedformanualinterventionanddomainexpertise,data-drivenmethodscansignificantly
streamlinethediscoveryprocess[12].
Data-drivendiscoveryindynamicalsystemshasevolvedfromearlyparameterestimationusingsplineapproximation
and system reconstruction [13, 14], to leveraging statistical methods such as least squares [15–17], mixed-effects
models[18,19],andBayesianapproaches[2,20]forparameterestimationinODEsandPDEs. Theadventofhigh-
performancecomputinghasfurtherpropelledsymbolicregression,enablingthediscoveryofgoverningequationsfrom
datainphysicsandengineering[1,21–23]. AnotabledevelopmentinthisfieldistheSparseIdentificationofNonlinear
Dynamics(SINDy)approach[3,4],whichconstructsanextensivelibraryofpotentialtermsandemploystheSequential
ThresholdRidgeRegression(STRidge)algorithm[4]toselectsignificanttermsiteratively.
SINDyanditsvariousenhancements[24–29]havebeenextensivelyusedtodiscoverabroadspectrumofODEsand
PDEs,describingdiversephenomenasuchasfluidmechanics[30],turbulencemodels[31],aerodynamics[32],and
4202
rpA
52
]GL.sc[
1v44461.4042:viXraarXivTemplate APREPRINT
biologicalandchemicalsystems[33,34]. Recentdevelopmentshavecombinedneuralnetwork-basedtechniquesand
SINDy, leading to innovative approachesthat enhance noisetolerance inidentifying PDEs[5, 23, 35–39]. Neural
networkscanlearncomplexnonlinearrelationshipsandeffectivelyfilteroutnoise,complementingSINDy’sabilityto
identifyparsimoniousmodels. However,bothneuralnetworkandSINDymethodsrequirespecifichyperparameter
tuning,suchassettingregularizationparametersorchoosingnetworkarchitectures. Forexample,STRidgerequires
settingathresholdtoselectactivetermsfromthecandidatelibrary[4,29,36,38]. Additionally,SINDy-basedmethods
typicallyapproximatenumericalderivativesfromnoisydatausingtheSavitzky-Golayfilter,atechniqueforsmoothing
databyfittinglocallow-degreepolynomials[40]. Theparametersofthisfilter,suchasthepolynomialdegreeand
windowsize,mustbecarefullytunedforoptimalperformance[4,12]. Neuralnetworkapproaches,ontheotherhand,
requiredetaileddecisionsregardingtheirarchitectureandfunctioning,suchasthenumberofneurons,thestructureof
hiddenlayers,thetypesofactivationandlossfunctions,andthelearningrate. Inparticular,usingphysics-informed
neural networks [5, 36, 38] requires a prior understanding of the equation terms, as well as initial and boundary
conditions. Consequently,usingneuralnetworksandSINDy-basedmethodspresentsatrade-off: theabsenceoffully
automatedalgorithmsrequiresuserstoengageinmanualtuninganditerativeusageofsemi-automatedalgorithms. This
scenariohighlightsakeychallengeinthefield: developinganautomatedalgorithmtoidentifyPDEswithminimal
manualintervention,streamliningtheprocess,andimprovingitsapplicabilityacrossdiversescientificdomains.
To address the challenge of parameter tuning, Egan et al. [12] proposed the Automatic Regression for Governing
Equations(ARGOS)algorithm,whichidentifiesODEsbyautomatingtheparametertuningprocess. ARGOSassumes
theunderlyingsystemisunknown,automatesthefine-tuningofparametersfornumericaldifferentiation,andleverages
sparseregressionwithbootstrapconfidenceintervalstoselectactivetermsfromthecandidatelibrary. Toautomatically
identifyPDEs,wedevelopARGOSwiththeRecurrentAdaptiveLasso(ARGOS-RAL).ThisextensionoftheARGOS
frameworkemploysonlysparseregressiontoidentifyequationsratherthanengaginginlarge-scalebootstrapping.
WeevaluatetheperformanceoftheARGOS-RALalgorithmthroughaseriesofthreenumericaltests,eachdesigned
toassessitsabilitytoidentifycanonicalPDEsacrossdiversefields,includingbiology,neuroscience,earthscience,
fluidmechanics,andquantummechanics. Thefirsttestexploresthealgorithm’sresilienceagainstvaryingnoiselevels
by altering the signal-to-noise ratio (SNR) in Gaussian random noise integrated into the PDE solutions, which is
crucialforunderstandingtherobustnessofARGOS-RALunderrealisticnoisyconditions. Thesecondtestaddresses
thepracticalchallengesencounteredinreal-worlddatacollection,whichoftenresultsinnon-uniformlydistributed
datapointsinspace andtime, by exploringtheminimumpercentageof datapointsnecessaryforthealgorithmto
accuratelyidentifytheunderlyingequation. Thefinalevaluationassessesthealgorithm’sabilitytoprocessdatasets
characterizedbysignificantnoise,challengingitslimitsandpracticalapplicabilityinscenarioswheredataqualityis
compromised. OurresultsdemonstratethatARGOS-RALcaneffectivelyandreliablyidentifytheunderlyingPDEs
fromdata,outperformingtheSTRidgemethodusedinSINDy.
2 Methods
2.1 OverviewoftheARGOS-RALFramework
ThegeneralformofahomogeneousPDEis
u +F(x,t,u,u ,u ,···)=0 (1)
t x xx
where F(·) governs the behavior of the system, with u = u(x,t) denoting its state. The notation u ,u ,u ,···
t x xx
representsthepartialderivativesofuwithrespecttotimeandspace,respectively. Equation(1)servesasafoundational
representationofthedynamicalsystem,encapsulatingawiderangeofphenomenathroughitsgeneralizedform,which
canbeadaptedtoincludemultiplespatialdimensionsortomodelsystemswithoutexplicittimedependence.
Tofocusondata-drivenmodelingofspatiotemporaldynamicalsystems,weincorporateempiricaldatadirectlyintothe
modelingprocess:
∂U
U = =F(x,U,U ,U ,...), (2)
t ∂t x xx
where U ∈ Rn×m is a matrix representing the solution of the PDE as a function of x and t, and F(·) denotes the
unknownmappinginferredfromthecollecteddata,whichcontainslinearandnonlinearoperators.
We aim to estimate the unknown mapping F(·) with sparse regression by constructing a comprehensive library of
potential terms and assuming that only a few of them are active [3, 4, 12]. To cover a broad spectrum of possible
influencesonthedynamicsofthesystem,thislibraryincludesawidevarietyoffunctions,suchasconstants,monomials,
interactionterms(productsofvariables),possiblytrigonometric,andotherfunctions,dependingonthedynamical
systembeingstudied[4]. InthecaseofBurgers’equation,u =−uu +0.1u ,thetruedynamicsinvolvesonlytwo
t x xx
2arXivTemplate APREPRINT
terms: thenonlinearconvectiontermuu andthelineardiffusiontermu . Whenapplyingsparseregressiontodata
x xx
generatedfromBurgers’equation,themethodshouldideallyselectonlythesetwotermsfromthecandidatelibrary.
AllfeaturesrelatedtoU(x,t)inEq.(2)arematrices. Implementingthismatrixdatainsparseregressionleadstothe
creationofmdistinctregressionmodels. Eachmodelcapturesthespatialdynamicsofthesystemataspecifictime
pointt ,wherej =1,2,...,m. Toconsolidatethemregressionmodelsintoasinglelinearregressionproblem,we
j
reshapethematrixU(x,t)anditsderivativematricesintovectors. Thesevectorsthenserveaspredictorswithinthe
candidatelibraryΘ,whichcanberepresentedinR(n·m)×porC(n·m)×p. Bystackingthevectorizeddataandcandidate
terms,wecanestimateasinglesparsecoefficientvectorβ thatrepresentsthegoverningequationacrossalltimepoints
ratherthanestimatingseparatemodelsforeachtimepoint. Here,U∈Rn×misrepresentedinmatrixformas
 u(x ,t ) u(x ,t ) ··· u(x ,t ) 
1 1 1 2 1 m
u(x ,t ) u(x ,t ) ··· u(x ,t )
 2 1 2 2 2 m 
U(x,t)=  . . . . . . ... . . .  . (3)
u(x ,t ) u(x ,t ) ··· u(x ,t )
n 1 n 2 n m
VectorizingEq.(3)yields:
u=vec(U)=( u(x ,t ) ··· u(x ,t ) ··· u(x ,t ) ··· u(x ,t ) )T . (4)
1 1 n 1 1 m n m
Similarly, u = vec(U ) = vec(∂U/∂t), u = vec(U ) = vec(∂U/∂x), u = vec(U ) = vec(∂2U/∂x2),
t t x x xx xx
u2 =vec(U⊙U),anduu =vec(U⊙U ),where⊙denotestheHadamardproduct. Thedesignmatrixisgivenby
x x
 
Θ(u)= 1 u ··· ud ··· u
x
u
xx
··· uu
x
··· udu
xx
··· , (5)
where ud is a vector where all elements denote a d-th degree monomial. For example, if our data U(x,t) is on
a 200×100 grid (i.e. 200 spatial measurements and 100 time-steps) and the candidate library has 30 terms, then
Θ∈R20000×30.
Aftervectorization,weestimateF(·)bytransformingEq.(2)toalinearregressionmodel
u =Θ(u)β+ϵ, (6)
t
whereβ ∈Rpisasparsecoefficientvectorinwhichonlyafewvaluesarenonzero,andϵisthevectorofresiduals.
2.2 AutomatedNumericalDifferentiationusingtheSavitzky-GolayFilterandtheGaussianBlur
AcrucialstepinconstructingthecandidatelibraryinEq.(5)isthenumericalcalculationofderivatives(seeFig.1A
andB).TheSavitzky-Golayfilter[40]hasbecomeafavoredsolutioninsystemidentificationforsignalsmoothingand
differentiation[4,41]. Thismethodappliesaleastsquarespolynomialfitoveraslidingwindowofdatapoints,thereby
achievingsimultaneoussignalsmoothinganddifferentiation. TheselectionoftheSavitzky-Golayfilterisgroundedin
itsprovenabilitytoaccuratelymaintaintheoriginalcontourofthesignalwhilesignificantlyreducingnoiseandto
approximatehigher-ordernumericalderivativeswithsymbolicdifferentiation[42].
TheSavitzky-Golayfilterischaracterizedbytwointegerhyperparameters:thepolynomialorderoandthewindowlength
l,whichareconstrainedbytheconditionsthatomustbeatleast2,lshouldbeanoddnumber,ando+1+mod(o)≤
l ≤ n−1[42]. Toautomatetheselectionofthesehyperparameters,wefirstapplyaGaussianblurwiththekernel
(1,2,1)tosmooththeobservationaldata(seeA.1). Wethentreatthissmootheddata,denotedasGB(U˜),astheground
truth. Next,wefindtheoptimalsetofhyperparameters{o∗,l∗}byminimizingthemeansquarederror(MSE)between
theSavitzky-GolayfiltereddataSG(U˜,o,l)andthegroundtruthGB(U˜)(seeAlgorithm1inA.2). Afterfindingthe
optimal set {o∗,l∗}, we use the Savitzky-Golay filter with these parameters to compute the smoothed data and its
derivatives.
2.3 SparseRegressionwiththeRecurrentAdaptiveLasso
Theadaptivelassoisatwo-stepmethod[12,43]. Thefirststepusestheordinaryleastsquares(OLS)toobtainunbiased
estimatesandderivetheweightsw:
w =|βˆ |−γ, γ >0 (7)
ols
3arXivTemplate APREPRINT
A
Smoothing and Derivatives
Savitzky-Golay filter
Observed data Filtered points
Savitzky-Golay filter Local polynomial fitted line Boundary points
Two-dimensional Gaussianblur
Vectorize
2 222 8 0 000 11 1 14 66 6 2 2 2 22 8 0 0 00 33 1 3 3 22 2 2 6 2 2 22 8 0 0 00 1 2 1 2 4 2 1 2 1 F1 11 i5 72 lter1 21 e9 25
d
d1 2 2 a8 3 7
ta
Raw data Gaussian kernel
B
Constructing the Candidate Library
C
The Recurrent Adaptive Lasso Algorithm
Figure1: ProcessofidentifyingPDEsfromdatausingARGOSwiththerecurrentadaptivelasso. Theidentification
processconsistsofthreemainsteps: (A)automaticsmoothingandcalculationofderivatives,(B)constructionofthe
candidate library, and (C) implementation of the recurrent adaptive lasso. We begin by collecting the data U˜ and
applyingtheautomaticSavitzky-GolayfilterwithGaussianblurtocalculatethesmoothedUanditspartialderivatives.
Next,wevectorizethesmootheddata,allpartialderivatives,andotherrelatedtermstoconstructthecandidatelibrary.
Finally,weemploytherecurrentadaptivelassotoidentifytheactivefeaturesinthelibrary,andweestimatetheunbiased
coefficientsoftheidentifiedmodelusingordinaryleastsquaresregression.
4arXivTemplate APREPRINT
whereβˆ istheOLSestimate,andγ isanexponenttuningtheshapeofthesoft-thresholdingfunction. Inthesecond
ols
step,weobtaintheestimatedcoefficientsβˆ usingtheglmnetpackage[44]inRbysolvingtheproblem
alasso
p
βˆ =argmin∥u −Θβ∥2+λ(cid:88) w |β |, (8)
alasso t 2 j j
β
j=1
whereλisanonnegativeregularizationparametercontrollingtheamountofshrinkageappliedtothecoefficientsofthe
predictors.Unlikethelasso,wheretheweightvectorisw =1,theadaptivelassovariestheweightsintheregularization
function,resultinginastrongerpenaltyonsmallercoefficients,thusdrivingmoreofthemtozeroandleadingtoa
sparsermodelcomparedtothestandardlasso. Therecurrentadaptivelassoappliestheadaptivelassorepeatedlyuntil
convergence,resultinginasparsemodelwithfewernon-zerocoefficients.
Tobalancethemodel’scomplexityagainstitsaccuracy,wedeterminetheregularizationparameterλbyemployingthe
Paretocurve,whichillustratestheoptimaltrade-offbetweentheregularizationpenaltyandthemodelresiduals[45–47]
(see Fig. 2). Although cross-validation is an alternative method, Cortiella et al. [27] have shown that it finds a λ
optimizedforprediction,potentiallyoverfittingthetrueunderlyingequationwithextrafeatures.
1
0
3.5 4.0 4.5 5.0 5.5
( )
b -
log ||X y||
10 2
Figure2: ParetocurveoftheadaptivelassoforasampleddatasetfromaNavier-StokessystemwithanSNRof36dB.
TheParetocurvebalancesthetrade-offbetweensparsityandgoodness-of-fit. Theredpointonthecurveindicatesthe
optimalvalueoftheregularizationparameterλthatachievesthebestbalancebetweenthesetwocompetingobjectives.
Increasingλleadstosparsersolutionsatthecostofapoorerfittothedata,whiledecreasingλimprovesthefitbut
yieldslesssparsesolutions.
Theadaptivelassoregressionoftendetectsmoretermsthanthoseinthetruesystem. Toimproveparsimony,Eganet
al.[12]suggestedcombiningtheadaptivelassowithbootstraptechniquestoidentifyODEs. Similarly,Cortiellaet
al.[27]adoptedamodifiedversionofthemulti-stepadaptivelasso[48]todevelopasparsermodelthatmoreaccurately
identifiesthetrueequations. Thisisachievedbyiterativelyadjustingtheadaptiveweightsusingpreviousestimatesfrom
theadaptivelasso. AsignificantadvancementmadebyCortiellaetal.[27]istheirmethod’sabilitytomaintainfinite
weightsintheadaptivelassoequationbyensuringthattheestimatedcoefficientsshrinktoasmall,nonzerovaluerather
thandroppingtozero. However,thisapproximationunintentionallyintroducesnumericalinaccuraciesasatrade-offfor
preventingoverflowduringtheequationidentificationprocess.
Therecurrentadaptivelassoisaniterativealgorithmthatestimatesaninitialsparsemodelusingtheadaptivelasso
and subsequently refining it by trimming the candidate library (see Fig. 1 C). At each iteration, it removes terms
whosecoefficientstheadaptivelassopenalizedtozero(seeA.2Algorithm2step9). Itthenemploysleastsquaresto
re-estimatethecoefficientsoftheremainingterms,whichareusedtoupdatetheadaptiveweightsinthenextadaptive
lassoiteration. Thisfocusestheregularizationonthetermsthathadsmallcoefficientsinthepreviousiteration. As
5
)
b
T
(
||
w||
gol
1
01arXivTemplate APREPRINT
thisprocessrepeats,therecurrentadaptivelassoincreasinglyconcentratestheℓ -normshrinkageontermsthatare
1
likely irrelevant, driving their coefficients to zero [43, 49]. Meanwhile, it relaxes the regularization on terms that
consistentlyhavelargercoefficients,allowingthemodeltoretainthem. Thecandidatesetgetssmallerateachiteration
untilthealgorithmconvergesonasparsemodelcontainingonlythekeyterms. Thisiterativere-weightingallowsthe
recurrentadaptivelassotopruneirrelevanttermsmoreaggressivelythanthestandardadaptivelassowhileretaining
goodpredictiveperformance. Theresultisaparsimoniousmodelthatidentifiesthetruegoverningequationmore
reliably,eveninthepresenceofmanyextraneouscandidateterms.
Increasingthenumberofiterationsmaycausetherecurrentadaptivelassotounderestimatethemodel. Thiscanlead
totheomissionofactivetermsthatshouldbeincludedinthetrueunderlyingequation. Therefore,whileiteratingthe
candidatelibraryΘ,werecordallcandidatemodelsandcalculatetheAkaikeinformationcriterion(AIC)foreach
modeltodeterminethefinalgoverningequationcorrespondingtothelowestAIC.Giventheuncertaintythatthetrue
modelfallswithinallcandidates,theAICservestoselectthemodelthatbestapproximatesthetruemodel[50,51].
3 ResultsandDiscussion
3.1 EvaluatingthePerformanceofARGOS-RALunderVaryingNoiseLevelsandSampleSizes
WecomparetheperformanceofARGOS-RALandSTRidge[4]inidentifyingtencanonicalPDEsundervariousSNRs
andsamplesizes(N). Weevaluatetheirperformanceonbothnoisyandnoiselessdata. Figure3demonstratesthe
impactofintroducingincreasinglevelsofGaussianrandomnoiseintothesolutionoftheBurgers’equation,effectively
decreasingtheSNRvalues.
In the evaluation of noise-contaminated data, we express the SNR as SNR = 20log (σ /σ ), where σ is the
10 U Z U
standarddeviationoftheoriginaldata,andσ representsthestandarddeviationoftheaddednoise. Wesystematically
Z
varyσ tospanabroadrangeofnoiselevels,facilitatingacomprehensiveevaluationoftheefficacyofARGOS-RAL
Z
andSTRidgeinidentifyingvariousPDEsunderdifferentnoiseconditions. Forthispurpose, wegeneratedatasets
withSNRssetat{0,2,··· ,58,60,∞}[12],eachcomprisingpairedelements{u ,Θ(u)}. Thisapproachallowsusto
t
examinetherobustnessofeachPDEidentificationmethodasitcopeswithvaryingnoiselevels.
In investigating sample size, N, our objective is to determine the smallest number of samples needed to reliably
identifyPDEswithasuccessrateexceeding80%. Toachievethis,wefirstgenerateafulldatasetforeachPDEby
calculatingpartialderivativesandassemblingacandidatelibraryasdescribedinEq.(5). Thesizeofthefulldataset,
denotedasN,variesdependingonthespecificPDEunderconsideration. Specifically,N = 104 fortheadvection-
diffusion, Burgers, and cable equations, N = 105 for the quantum harmonic oscillator, transport, Navier-Stokes,
and reaction-diffusion equations, and N = 104.8 for the heat and Korteweg-De Vries (KdV) equations. Next, we
randomlysamplesmallersubsetsofsizeN fromthefulldataset,whereN ischosenfromalogarithmicallyspaced
grid: N =102,102.2,102.4,··· ,N[12](seethebluepointsinFig.3A).ByapplyingthePDEidentificationmethods
tothesesubsetsandevaluatingtheirsuccessrates, wecandeterminethesmallestsamplesizerequiredforreliable
identificationofeachPDE.
3.2 QuantifyingSuccessRatesinIdentifyingCanonicalPDEs
ToevaluatetheimpactofdifferentSNRsanddatasizesonthemethod,wemeasuretheuncertaintyofmodelidentification
causedbyrandomsampling.Todoso,wecreate100uniquedatasetsateachpointonthegrid,correspondingtodifferent
SNRsandN values. Foreachdataset,wequantifytheidentificationaccuracywiththesuccessrate,η =#correct/100,
where#correctrepresentsthenumberoftimesthemodelcorrectlyidentifiesallactiveterms. Ouraccuracyassessment
ignoressmalldifferencesbetweentheoreticalandempiricalcoefficients,suchasatheoreticalvalueof0.1compared
to an estimated value of 0.098. Figure 4 illustrates these results for a selection of systems: the Burgers’, Cable,
Navier-Stokes,reaction-diffusion,andquantumharmonicoscillatormodels. Weprovidefurtheranalysisonadditional
PDEs–Transport,Heat,Advection-Diffusion,andKdVequations–inA.3Fig.6.
ARGOS-RALidentifiesBurgers’,cable,Navier-Stokes,reaction-diffusion,andadvection-diffusionequations,achieving
asuccessrateof100%whentheSNRexceeds30dB(seeFig.4and6).However,accuratelydetectingspecificequations
requiresahighSNR,particularlyforthequantumharmonicoscillator,KdV,transport,anddiffusionequations.TheKdV
equation,whichinvolvesthird-orderpartialderivatives,presentschallengesduetothesignificantbiasesinnumerical
approximationsofthesederivatives[39],resultingindatasetsunsuitableforsystemidentificationwithsparseregression.
Toimplementsparseregressionwithintherealnumberdomainforthecomplexnumberquantumharmonicoscillator
PDE,weapplythetransformationshowninA.3Eq.(17). ThistransformationexpandsthedesignmatrixΘfrom
nm×pto2nm×2p,effectivelyquadruplingitssizeandpotentiallyleadingtohighcorrelationsbetweenthevariables
inΘ.Thetransportanddiffusionequations,containingonlytermsu andu respectively,exhibithighcorrelationwith
x xx
6arXivTemplate APREPRINT
A B C
Burgers (SNR = ¥ ) Burgers (SNR = 40 dB) Burgers (SNR = 30 dB)
10.0 10.0 10.0
7.5 7.5 7.5
5.0 5.0 5.0
2.5 2.5 2.5
0.0 0.0 0.0
−5 0 5 −5 0 5 −5 0 5
x x x
D E F
Burgers (SNR = 20 dB) Burgers (SNR = 10 dB) Burgers (SNR = 0 dB)
10.0 10.0 10.0
7.5 7.5 7.5
5.0 5.0 5.0
2.5 2.5 2.5
0.0 0.0 0.0
−5 0 5 −5 0 5 −5 0 5
x x x
0.00 0.25 0.50 0.75 1.00
Figure3: InfluenceofSNRontheBurgers’equationdataset. (A)Noiselessdatapoints(blue)serveasareferencefor
evaluatingtheimpactofsamplesizeonPDEidentificationaccuracy. (B-F)Noisydatasetsaregeneratedbyadding
GaussiannoiseatSNRlevelsof40dB,30dB,20dB,10dBand0dB,respectively,tocomprehensivelycharacterize
thesystem’sbehaviorundervaryingnoiseconditions.
theircorrelatedtermsinthelibrary,suchas{u ,uu }and{u ,uu },whichhinderstheeffectivenessofℓ -norm
x x xx xx 1
shrinkageregressioninidentifyingcorrectterms[43].
Figures4and6illustratethatARGOS-RALachievesahighersuccessratethanSTRidgeinidentifyingPDEswith
limiteddatapoints. ARGOS-RALconsistentlyidentifiesasignificantnumberofPDEsusingasfewas1000datapoints,
maintainingasuccessrateabove80%. However,someequations,suchasthereaction-diffusionandKdVequations,
requirelargersamplesizesofapproximately104and103.8datapoints,respectively,forreliableidentification. Wethus
demonstrateARGOS-RALasaconsistentandefficientmethodforPDEidentificationwithnon-uniformlysampledand
noiselessdatasets.
ARGOS-RALshowsaremarkableabilitytoidentifyPDEsaccuratelyandconsistentlyacrossawiderangeofSNRs
andsamplesizes. ItssuccessrateimprovesastheSNRandsamplesizeincrease,reaching100%whenbothvalues
aresufficientlylarge. ThistrendhighlightstherobustnessofARGOS-RALinhandlingvariousdataconditionsand
underscoresitseffectivenessinidentifyingPDEs,evenwhenfacedwithvaryinglevelsofdataqualityandquantity.
However,incertainscenarios,STRidge[4]withspecificd thresholdsexceedstheperformanceofARGOS-RAL.For
tol
instance,STRidgeachieveshighersuccessratesinidentifyingNavier-Stokesandreaction-diffusionequationsata30
dBSNR,usingd settingsof2and10,respectively(seeFig.4CandD).Moreover,STRidgewithd =2ismore
tol tol
proficientinidentifyingthequantumharmonicoscillatorandthetransportequationwithanSNRlowerthan52dB,see
Fig.4Eand6C,respectively. TheseresultsfromtheSNRandN experimentsrevealthatusingasinglefixedthreshold
inSTRidgecanleadtoperformancevariabilitydependingontheinputdata,highlightingthedifficultyofselecting
anappropriated thresholdwithoutpriorknowledgeofthesystem. Thisvariabilityunderscoresthesensitivityof
tol
STRidgetospecificthresholdsettings,whichcanimpactitsconsistencyacrossdifferentdatasets. Overall,STRidge
surpassesARGOS-RALinidentifyingsimplerPDEs,suchasthetransportanddiffusionequations;seeFig.6CandD.
3.3 RobustnessAnalysisusingWhiteGaussianNoise
Tobetterunderstandthelimitsofidentificationalgorithms,wedesignedanextremetestonasinglespatialdimension.
Thistesteffectivelycreatesasituationwithoutvaliddatacollection(σ =0),equivalenttoanSNRofnegativeinfinity,
U
7
t
t
t
t
t
tarXivTemplate APREPRINT
A Burgers u =−uu +0.1u
t x xx
10.0 u 1.0 1.0
1.00 0.8 0.8
7.5
0.75 0.6 0.6
5.0 0.50 0.4 0.4
2.5 0.2 0.2
0.25
0.0 0.0 0.0
-5 0 5 0.00 0 6 12 18 24 30 36 ∞ 102 102.6 103.2 103.8
x SNR(dB) N
B Cable u =u −u
t xx
5 u 1.0 1.0
4 1.00 0.8 0.8
3 0.75 0.6 0.6
2 0.50 0.4 0.4
1 0.2 0.2
0.25
0 0.0 0.0
-4 -2 0 2 4 10 16 22 28 34 40 ∞ 102 102.6 103.2 103.8 104.4
x SNR(dB) N
C Navier-Stokes ω =0.01ω +0.01ω −uω −vω
t xx yy x y
4 w 1.0 1.0
0.8 0.8
3 3 0.6 0.6
2 0 0.4 0.4
1 0.2 0.2
0 -3 0.0 0.0
0.0 2.5 5.0 7.5 10 16 22 28 34 40 ∞ 102 102.6 103.2 103.8 104.4 105
x SNR(dB) N
D Reaction-diffusion u vt= =0 0. .1 1u vxx+ +0 0. .1 1u vyy ++ vu −− uu vv 22 −− uu 33 −+ vv 33 −+ uu 22 vv
t xx yy
1.0 1.0
u v value 0.8 0.8
10 0.6 0.6
05 0.5 0.4 0.4
-5 0.0 0.2 0.2
-10 -0.5 0.0 0.0
-10-5 0 5 10-10-5 0 5 10 20 24 28 32 36 40 ∞ 102.2 102.8 103.4 104 104.6
x SNR(dB) N
E Quantum harmonic oscillator u =iu 2−x2iu 2
t xx
10.0 |u| 1.0 1.0
0.8 0.8
7.5
5.0 1.0 0.6 0.6 0.4 0.4
2.5 0.5 0.2 0.2
0.0 0.0 0.0
-8 -4 0 4 8 40 44 48 52 56 60 ∞ 102.2 102.8 103.4 104 104.6 105.2
x SNR(dB) N
Methods ARGOS-RAL STRidge (d =0.2) STRidge (d =2) STRidge (d =10)
tol tol tol
Figure4: SuccessratesofARGOS-RALandSTRidgeinidentifying(A)Burgers’,(B)cable,(C)Navier-Stokes,(D)
reaction-diffusion,and(E)quantumharmonicoscillatorequationswithvaryingSNRsandsamplesizes. Weanalyzethe
noisetolerancebyaddingnoiseofdifferentSNRstothePDEsolutions. Forthesamplesizeanalysis,werandomly
samplepointsfromtheset{u ,Θ(u)}basedonnoiselessdata. Inpanel(C),weusetheregionindicatedbythered
t
rectangletoimplementboththeSNRandsamplesizetestsbysamplingpointswithinthisarea. PDEsolutionplots
displaytimesnapshotsatt=306forNavier-Stokesinpanel(C)andt=1forreaction-diffusioninpanel(D).Lines
connectingthepointsareusedforvisualguidanceonlyanddonotrepresentafittothedata. Shadedregionsrepresent
modeldiscoveryaccuracyabove80%.
8
t
t
y
y
t
etar
sseccuS
etar
sseccuS
etar
sseccuS
etar
sseccuS
etar
sseccuSarXivTemplate APREPRINT
representingadatasetentirelycomposedofrandomnoise. Thisscenariosetstheultimateteststageforanalgorithm:
identifyingdynamicalsystemswithoutsignal,whereweexpectsuccessratestodroptozero. Whenfacedwiththis
condition, aneffectivealgorithmshouldidentifyeitheranullmodel(withnocoefficients)oradensemodel(with
manytermsfromthecandidatelibrary). However,ifthealgorithmincorrectlyidentifiescanonicalPDEsfrompure
whitenoisedata,itindicatesthatfurtherimprovementsareneededtopreventsuchmisidentificationsandensurethe
robustnessofthemethod.
Wegenerate100whiteGaussiannoisedatasets,eachconsistingof2000spatial(x)and1000temporal(t)datapoints,
formingamatrixinR2000×1000. Toinvestigatetheinfluenceofnoisevarianceontheidentificationprocess,weusethree
Gaussiandistributionswithvariancesspanningthreeordersofmagnitude: N(0,0.12),N(0,1),andN(0,102). Weaim
todeterminewhetherARGOS-RALandSTRidgecanidentifycanonicalPDEsunderthesenoiseconditions. Table1
showsthepercentagesofdifferentidentifiedmodels. BasedonthePDEstestedbyRudyetal.[4]andourownstudy,
wedefineparsimoniousmodelsasthosehavingthreeorfewernonzerocoefficients,suggestingtheymaycorrespondto
specificphysicalphenomena. Inparticular,wehighlightthreeclassicdifferentialequations: theODEu =c ud,the
t 1
transportequationu =c u ,andtheheatequationu =c u . Incontrast,weclassifymodelswithmorethanthree
t 2 x t 3 xx
nonzerocoefficientsasnon-parsimonious,indicatingthattheircoefficientvectorshaveadensecomposition.
σ
40 Z
0.1 1 10
36
30 σ
Z
0.1 1 10
25
σ
20 Z
0.1 1 10
16
10
4
0
�1�u�u2�…�u3u � �1�u�u2�…�u4u � �1�u�u2�…�u5u �
xxx xxxx xxxxx
Candidate library
ARGOS-RAL STRidge (d tol=2) Non-parsimonious models
Figure 5: Number of nonzero terms identified from 100 random noise datasets using different candidate function
libraries.Foreachcase,wecountthenumberofnonzerocoefficientsinthesparseregression.Wedisplaythedistribution
ofthesecountsusingdotsforeachofthe100trialsandsummarizetheresultsusingboxplots. Eachboxplotshows
themedian(solidhorizontalline),interquartilerange(box),andminimumandmaximumvalues(whiskers)forthe
100trials. Theoptimalalgorithmshouldproduceboxeslocatedeitheratzero,indicatinganullmodel,orabovefour,
representingadensemodel. Theboxmayspanawiderangefromfourtothemaximumnumberoftermsinthelibrary.
Table1andFig.5demonstratethatasthestandarddeviationoftheGaussiannoiseincreases,bothARGOS-RALand
STRidgetendtoidentifymorenon-parsimoniousmodels,asindicatedbytheprobabilitydistributionsofthenumber
of identified terms shifting into the shaded region of Fig. 5. This is the desired behavior when the input signal is
purewhitenoise,aswewanttoensurethatthealgorithmsdonotidentifyparsimoniousmodelsinsuchcases. The
differenceinbehaviorbetweenthetwomethodsismostapparentwhenthenoiselevelislowtomoderate(σ ≤1).
Z
Inthesecases,STRidge’sdistributionsaremorespreadoutandpartiallylocatedintheparsimoniousregion,while
ARGOS-RAL’sdistributionsaremoreconcentratedinthenon-parsimoniousregion. ThissuggeststhatARGOS-RAL
ismoreeffectiveatavoidingtheidentificationofparsimoniousmodelswhentheinputsignalispurewhitenoisewith
lowtomoderatenoiselevels. Asthenoiselevelincreasestoσ =10,bothARGOS-RALandSTRidgeconsistently
Z
9
smret
deifitnedi
fo
rebmuNarXivTemplate APREPRINT
identifynon-parsimoniousmodels,asevidencedbytheconcentrationoftheirdistributionsinthenon-parsimonious
regionofFig.5. Thisindicatesthatbothmethodsareeffectiveatavoidingtheidentificationofparsimoniousmodels
whentheinputsignalispurewhitenoisewithhighnoiselevels.
Parsimoniousmodel(%) Non-
Candidatelibrary ODE Transport Heat parsimonious
Others
u =c ud u =c u u =c u model(%)
t 1 t 2 x t 3 xx
σ =0.1
Z
STRidge(d =2)
tol
(1,u,u2,...,u3u ) 4(1) 3 2(1) 82(11) 9
xxx
(1,u,u2,...,u4u ) 0 0 0 91(10) 9(2)
xxxx
(1,u,u2,...,u5u ) 0 0 0 81(11) 19(1)
xxxxx
ARGOS-RAL
(1,u,u2,...,u3u ) 1(1) 2(1) 4(2) 54(29) 39(23)
xxx
(1,u,u2,...,u4u ) 0 2(1) 3(2) 63(32) 32(23)
xxxx
(1,u,u2,...,u5u ) 0 0 0 34(18) 66(47)
xxxxx
σ =1
Z
STRidge(d =2)
tol
(1,u,u2,...,u3u ) 4(1) 4 4(2) 69(8) 19(1)
xxx
(1,u,u2,...,u4u ) 1 0 2 54(7) 43(10)
xxxx
(1,u,u2,...,u5u ) 0 0 0 0 100(18)
xxxxx
ARGOS-RAL
(1,u,u2,...,u3u ) 0 0 0 0 100(16)
xxx
(1,u,u2,...,u4u ) 0 0 0 0 100(17)
xxxx
(1,u,u2,...,u5u ) 0 0 0 0 100(13)
xxxxx
σ =10
Z
STRidge(d =2)
tol
(1,u,u2,...,u3u ) 0 0 0 0 100(11)
xxx
(1,u,u2,...,u4u ) 0 0 0 0 100(4)
xxxx
(1,u,u2,...,u5u ) 0 0 0 0 100(12)
xxxxx
ARGOS-RAL
(1,u,u2,...,u3u ) 0 0 0 0 100(12)
xxx
(1,u,u2,...,u4u ) 0 0 0 0 100(9)
xxxx
(1,u,u2,...,u5u ) 0 0 0 0 100(6)
xxxxx
Table1: ModelsidentifiedfromrandomnoisebyARGOS-RALandSTRidge. Weconstructthecandidatelibrary
withmonomialsandderivativesofordersrangingfromthreetofive. Wedefineparsimoniousmodelsashavingthree
orfewernonzerocoefficients. WeevaluateeachidentifiedmodelwithanF-testtodeterminestatisticalsignificance,
withthenumberofsignificantmodels(p-value<0.05)notedinparentheses. Numbersoutsideparenthesesindicate
thenumberofmodelsthatdidnotsignificantlydifferfromthenullhypothesisaccordingtotheF-test. c ,c ,c are
1 2 3
constants. Fortheordinarydifferentialequation(ODE)models,themonomialorderdisapositiveinteger,withthe
maximumordercorrespondingtothehighestorderinthecandidatelibrary.
4 Conclusions
WedesignedARGOS-RALtoautomaticallytunealgorithmhyperparameters, enablingtheidentificationofclosed
formsofPDEsdirectlyfromdata. ARGOS-RALoffersseveraladvantagesoverexistingPDEidentificationmethods.
First,itautomatestheprocessofcalculatingpartialderivativesandconstructingthecandidatelibrary,reducingmanual
interventionandstreamliningthemodelingprocess. Second,therecurrentadaptivelassoemployedbyARGOS-RAL
provides a more robust and efficient sparse regression technique compared to the STRidge used in SINDy-based
methods. This enables ARGOS-RAL to handle noisy and limited data more effectively, as demonstrated in our
numericalexperiments.
However,ARGOS-RALalsohassomelimitations. Likeotherlibrary-basedmethods,itseffectivenessdependson
includingthecorrectgoverningtermsinthecandidatelibrary. Ifthetruegoverningtermsareabsent,ARGOS-RALcan
onlyapproximatethePDEusingtheavailableterms,potentiallyleadingtomodelmisspecification. Furthermore,while
ARGOS-RALprovidesamorecomputationallyefficientapproachthanARGOS[12]byfocusingonpointestimates
10arXivTemplate APREPRINT
ratherthanbootstrappingforconfidenceintervals,thiscomesatthecostoflosinguncertaintyquantificationforthe
estimatedcoefficients.
WhenapplyingARGOS-RALtodifferentscientificdomains,severalchallengesarise. Onekeychallengeisdetermining
theappropriaterangeofcandidatetermstoincludeinthelibrary,whichoftenrequiresdomainexpertise. Insomefields,
thegoverningequationsmayinvolvecomplexnonlinearitiesorunconventionaltermsthataredifficulttoanticipate
withoutpriorknowledge. Anotherchallengeisthecomputationalcostofhandlinghigh-dimensionaldata,whichis
commoninmanyscientificapplications. AsthenumberofvariablesandthecomplexityofthePDEincrease,thesizeof
thecandidatelibrarygrowsexponentially,leadingtoincreasedcomputationaldemandsforsparseregression.
Despitethesechallenges,ARGOS-RALoffersapromisingframeworkforautomatingPDEidentificationinvarious
scientific domains. By leveraging sparse regression techniques and automating key steps in the modeling process,
ARGOS-RALhasthepotentialtoacceleratediscoveryandinsightinfieldsrangingfromphysicsandengineeringto
biologyandclimatescience.
Dataavailability
Alldataandcodesareavailableathttps://github.com/Weizhenli/ARGOS-RAL.
References
[1] M.SchmidtandH.Lipson, “DistillingFree-FormNaturalLawsfromExperimentalData,” Science, vol.324,
pp.81–85,Apr.2009.
[2] X.Xun,J.Cao,B.Mallick,A.Maity,andR.J.Carroll,“ParameterEstimationofPartialDifferentialEquation
Models,”JournaloftheAmericanStatisticalAssociation,vol.108,pp.1009–1020,Sept.2013.
[3] S.L.Brunton,J.L.Proctor,andJ.N.Kutz,“Discoveringgoverningequationsfromdatabysparseidentificationof
nonlineardynamicalsystems,”ProceedingsoftheNationalAcademyofSciences,vol.113,no.15,pp.3932–3937,
2016.
[4] S.H.Rudy,S.L.Brunton,J.L.Proctor,andJ.N.Kutz,“Data-drivendiscoveryofpartialdifferentialequations,”
ScienceAdvances,vol.3,p.e1602614,Apr.2017.
[5] M.Raissi,P.Perdikaris,andG.Karniadakis,“Physics-informedneuralnetworks: Adeeplearningframeworkfor
solvingforwardandinverseproblemsinvolvingnonlinearpartialdifferentialequations,”JournalofComputational
Physics,vol.378,pp.686–707,Feb.2019.
[6] P.Y.Lu,J.AriñoBernad,andM.Soljacˇic´,“Discoveringsparseinterpretabledynamicsfrompartialobservations,”
CommunicationsPhysics,vol.5,p.206,Aug.2022.
[7] E.Zhang,M.Dao,G.E.Karniadakis,andS.Suresh,“Analysesofinternalstructuresanddefectsinmaterials
usingphysics-informedneuralnetworks,”ScienceAdvances,vol.8,p.eabk0644,Feb.2022.
[8] Y.-X.Jiang,X.Xiong,S.Zhang,J.-X.Wang,J.-C.Li,andL.Du,“Modelingandpredictionofthetransmission
dynamicsofCOVID-19basedontheSINDy-LMmethod,”NonlinearDynamics,vol.105,pp.2775–2794,Aug.
2021.
[9] S.Maddu,B.L.Cheeseman,I.F.Sbalzarini,andC.L.Müller,“Stabilityselectionenablesrobustlearningof
differentialequationsfromlimitednoisydata,”ProceedingsoftheRoyalSocietyA:Mathematical,Physicaland
EngineeringSciences,vol.478,p.20210916,June2022.
[10] Y.Cai,X.Wang,G.Joós,andI.Kamwa,“AnOnlineData-DrivenMethodtoLocateForcedOscillationSources
FromPowerPlantsBasedonSparseIdentificationofNonlinearDynamics(SINDy),”IEEETransactionsonPower
Systems,vol.38,pp.2085–2099,May2023.
[11] X. Sun, J. Qian, and J. Xu, “Compressive-sensing model reconstruction of nonlinear systems with multiple
attractors,”InternationalJournalofMechanicalSciences,vol.265,p.108905,Mar.2024.
[12] K.Egan,W.Li,andR.Carvalho,“Automaticallydiscoveringordinarydifferentialequationsfromdatawithsparse
regression,”CommunicationsPhysics,vol.7,pp.1–10,Jan.2024.
[13] J.M.Varah,“ASplineLeastSquaresMethodforNumericalParameterEstimationinDifferentialEquations,”
SIAMJournalonScientificandStatisticalComputing,vol.3,pp.28–46,Mar.1982.
[14] J. P. Crutchfield and B. S. Mcnamara, “Equations of motion from a data series,” Complex Systems, vol. 1,
pp.417–452,1987.
11arXivTemplate APREPRINT
[15] M.Bär,R.Hegger,andH.Kantz,“Fittingpartialdifferentialequationstospace-timedynamics,”PhysicalReview
E,vol.59,pp.337–342,Jan.1999.
[16] T.MüllerandJ.Timmer,“Fittingparametersinpartialdifferentialequationsfrompartiallyobservednoisydata,”
PhysicaD:NonlinearPhenomena,vol.171,pp.1–7,Oct.2002.
[17] H.LiangandH.Wu,“ParameterEstimationforDifferentialEquationModelsUsingaFrameworkofMeasurement
ErrorinRegressionModels,”JournaloftheAmericanStatisticalAssociation,vol.103,pp.1570–1583,Dec.2008.
[18] H.Wu,A.A.Ding,andV.DeGruttola,“EstimationofHIVdynamicparameters,”StatisticsinMedicine,vol.17,
pp.2463–2485,Nov.1998.
[19] H. Wu and A. A. Ding, “Population HIV-1 Dynamics In Vivo: Applicable Models and Inferential Tools for
VirologicalDatafromAIDSClinicalTrials,”Biometrics,vol.55,pp.410–418,June1999.
[20] H.Putter,S.H.Heisterkamp,J.M.A.Lange,andF.deWolf,“ABayesianapproachtoparameterestimationin
HIVdynamicalmodels,”StatisticsinMedicine,vol.21,pp.2199–2214,Aug.2002.
[21] J.BongardandH.Lipson,“Automatedreverseengineeringofnonlineardynamicalsystems,”Proceedingsofthe
NationalAcademyofSciences,vol.104,p.9943,June2007.
[22] S.-M.UdrescuandM.Tegmark,“AIFeynman: Aphysics-inspiredmethodforsymbolicregression,”Science
Advances,vol.6,p.eaay2631,Apr.2020.
[23] H.XuandD.Zhang,“Robustdiscoveryofpartialdifferentialequationsincomplexsituations,”PhysicalReview
Research,vol.3,p.033270,Sept.2021.
[24] S.Rudy,A.Alla,S.L.Brunton,andJ.N.Kutz,“Data-DrivenIdentificationofParametricPartialDifferential
Equations,”SIAMJournalonAppliedDynamicalSystems,vol.18,pp.643–660,Jan.2019.
[25] K.Kaheman,J.N.Kutz,andS.L.Brunton,“SINDy-PI:arobustalgorithmforparallelimplicitsparseidentification
ofnonlineardynamics,”ProceedingsoftheRoyalSocietyA:Mathematical,PhysicalandEngineeringSciences,
vol.476,no.2242,p.20200279,2020.
[26] D.A.MessengerandD.M.Bortz,“WeakSINDyforpartialdifferentialequations,”JournalofComputational
Physics,vol.443,p.110525,Oct.2021.
[27] A.Cortiella,K.C.Park,andA.Doostan,“Sparseidentificationofnonlineardynamicalsystemsviareweighted
$\ell_1$-regularizedleastsquares,”ComputerMethodsinAppliedMechanicsandEngineering,vol.376,p.113620,
Apr.2021.
[28] U.Fasel,J.N.Kutz,B.W.Brunton,andS.L.Brunton,“Ensemble-SINDy: Robustsparsemodeldiscoveryinthe
low-data,high-noiselimit,withactivelearningandcontrol,”ProceedingsoftheRoyalSocietyA:Mathematical,
PhysicalandEngineeringSciences,vol.478,p.20210904,Apr.2022.
[29] Y.Li,K.Wu,andJ.Liu,“Discovergoverningdifferentialequationsfromevolvingsystems,”PhysicalReview
Research,vol.5,p.023126,May2023.
[30] J.-C. Loiseau, B. R. Noack, and S. L. Brunton, “Sparse reduced-order modelling: sensor-based dynamics to
full-stateestimation,”JournalofFluidMechanics,vol.844,pp.459–490,June2018.
[31] K.Duraisamy,G.Iaccarino,andH.Xiao,“TurbulenceModelingintheAgeofData,”AnnualReviewofFluid
Mechanics,vol.51,pp.357–377,Jan.2019.
[32] S.Li,E.Kaiser,S.Laima,H.Li,S.L.Brunton,andJ.N.Kutz,“Discoveringtime-varyingaerodynamicsofa
prototypebridgebysparseidentificationofnonlineardynamicalsystems,”PhysicalReviewE,vol.100,p.022220,
Aug.2019.
[33] N.M.Mangan,S.L.Brunton,J.L.Proctor,andJ.N.Kutz,“InferringBiologicalNetworksbySparseIdentification
ofNonlinearDynamics,”IEEETransactionsonMolecular,BiologicalandMulti-ScaleCommunications,vol.2,
no.1,pp.52–63,2016.
[34] M.Hoffmann,C.Fröhner,andF.Noé,“ReactiveSINDy: Discoveringgoverningreactionsfromconcentration
data,”TheJournalofChemicalPhysics,vol.150,p.025101,Jan.2019.
[35] J.H.Lagergren,J.T.Nardini,G.MichaelLavigne,E.M.Rutter,andK.B.Flores,“Learningpartialdifferential
equationsforbiologicaltransportmodelsfromnoisyspatio-temporaldata,”ProceedingsoftheRoyalSocietyA:
Mathematical,PhysicalandEngineeringSciences,vol.476,p.20190800,Feb.2020.
[36] Z. Chen, Y. Liu, and H. Sun, “Physics-informed learning of governing equations from scarce data,” Nature
Communications,vol.12,p.6136,Oct.2021.
[37] Z.ZhangandY.Liu,“ArobustframeworkforidentificationofPDEsfromnoisydata,”JournalofComputational
Physics,vol.446,p.110657,Dec.2021.
12arXivTemplate APREPRINT
[38] P.Thanasutives,T.Morita,M.Numao,andK.-i.Fukui,“Noise-awarephysics-informedmachinelearningfor
robustPDEdiscovery,”MachineLearning: ScienceandTechnology,vol.4,p.015009,Mar.2023.
[39] D.Jia,X.Zhou,S.Li,S.Liu,andH.Shi,“Governingequationdiscoverybasedoncausalgraphfornonlinear
dynamicsystems,”MachineLearning: ScienceandTechnology,vol.4,p.045008,Oct.2023.
[40] A.SavitzkyandM.J.E.Golay,“SmoothingandDifferentiationofDatabySimplifiedLeastSquaresProcedures.,”
AnalyticalChemistry,vol.36,pp.1627–1639,July1964.
[41] F. V. Breugel, J. N. Kutz, and B. W. Brunton, “Numerical Differentiation of Noisy Data: A Unifying Multi-
ObjectiveOptimizationFramework,”IEEEAccess,vol.8,pp.196865–196877,2020.
[42] R.W.Schafer,“WhatIsaSavitzky-GolayFilter? [LectureNotes],”IEEESignalProcessingMagazine,vol.28,
pp.111–117,July2011.
[43] H.Zou,“TheAdaptiveLassoandItsOracleProperties,”JournaloftheAmericanStatisticalAssociation,vol.101,
no.476,pp.1418–1429,2006.
[44] J.H.Friedman,T.Hastie,andR.Tibshirani,“RegularizationPathsforGeneralizedLinearModelsviaCoordinate
Descent,”JournalofStatisticalSoftware,Articles,vol.33,no.1,pp.1–22,2010.
[45] P. C. Hansen, “Analysis of Discrete Ill-Posed Problems by Means of the L-Curve,” SIAM Review, vol. 34,
pp.561–580,Dec.1992.
[46] J.NasehiTehrani,A.McEwan,C.Jin,andA.vanSchaik,“L1regularizationmethodinelectricalimpedance
tomographybyusingtheL1-curve(Paretofrontiercurve),”AppliedMathematicalModelling,vol.36,pp.1095–
1105,Mar.2012.
[47] A.CultreraandL.Callegaro,“AsimplealgorithmtofindtheL-curvecornerintheregularisationofill-posed
inverseproblems,”IOPSciNotes,vol.1,p.025004,Aug.2020.
[48] P.Bühlmann andS.vandeGeer, StatisticsforHigh-Dimensional Data. SpringerSeries inStatistics, Berlin,
Heidelberg: SpringerBerlinHeidelberg,2011.
[49] R.Tibshirani,“RegressionShrinkageandSelectionViatheLasso,”JournaloftheRoyalStatisticalSociety: Series
B(Methodological),vol.58,no.1,pp.267–288,1996.
[50] Y.Yang,“CanthestrengthsofAICandBICbeshared? Aconflictbetweenmodelindentificationandregression
estimation,”Biometrika,vol.92,pp.937–950,Dec.2005.
[51] K. Aho, D. Derryberry, and T. Peterson, “Model selection for ecologists: the worldviews of AIC and BIC,”
Ecology,vol.95,pp.631–636,Mar.2014.
[52] R.C.GonzalezandR.E.Woods,“Smoothing(Lowpass)SpatialFilters,”inDigitalimageprocessing,pp.164–175,
NewYork,NY:Pearson,2018.
[53] M.C.CrossandP.C.Hohenberg,“Patternformationoutsideofequilibrium,”ReviewsofModernPhysics,vol.65,
pp.851–1112,July1993.
[54] S. L. Brunton and J. N. Kutz, “Fourier and Wavelet Transforms,” in Data-Driven Science and Engineering:
MachineLearning,DynamicalSystems,andControl,pp.53–96,Cambridge: CambridgeUniversityPress,2ed.,
2022.
[55] K.TairaandT.Colonius,“Theimmersedboundarymethod: Aprojectionapproach,”JournalofComputational
Physics,vol.225,no.2,pp.2118–2137,2007.
[56] T. Colonius and K. Taira, “A fast immersed boundary method using a nullspace approach and multi-domain
far-fieldboundaryconditions,”ImmersedBoundaryMethodandItsExtensions,vol.197,no.25,pp.2131–2146,
2008.
[57] A. D. Polyanin and V. F. Zaitsev, “Third-Order Equations,” in Handbook of Nonlinear Partial Differential
Equations,pp.857–976,ChapmanandHall/CRC,2ed.,2012.
13arXivTemplate APREPRINT
A Supplementarymaterials
A.1 GaussianBlurKernels
TheGaussianblurconvolvesdatawithaGaussiankerneltosmoothit,regardlessofthedata’sdimensionality. This
convolutionmethodofferssignificantbenefitsforfilteringoutGaussiannoise,acommonnoisedistributionencountered
indataanalysis[52]. Forone-dimensionalspatialPDEs,suchastheBurgers’andcableequations,weemploythe
simplest2-dimensionalGaussiankernel:
(cid:34) 1 (cid:35) (cid:34) 1 2 1 (cid:35)
1 1
2 ⊗[ 1 2 1 ]= 2 4 2 . (9)
16 16
1 1 2 1
In contrast, for two-dimensional spatial PDEs, the Navier-Stokes and reaction-diffusion equations, we use a 3-
dimensionalGaussiankernel:
(cid:34) 1 (cid:35) (cid:34) 1 (cid:35) (cid:34)(cid:34) 1 2 1 (cid:35)(cid:34) 2 4 2 (cid:35)(cid:34) 1 2 1 (cid:35)(cid:35)
1 1
2 ⊗[ 1 2 1 ]⊗ 2 = 2 4 2 4 8 4 2 4 2 . (10)
64 64
1 1 1 2 1 2 4 2 1 2 1
A.2 Algorithms
Here,wedetailtheautomaticSavitzky-GolayFilterandtherecurrentadaptivelassowiththeParetocurveandAIC.
Algorithm1:AutomaticSavitzky-GolayFilter
Input: U∈Rn×morCn×m,dt,dx.
Output: partialderivativesU ,U ,U ,···.
t x xx
1 U GB =Gaussian_Blur(U);// use Gaussian blurred data as the ground truth;
2 (o∗ t,l t∗)=argminMSE(Savitzky-Golay(U˜(t),o,l),U GB);
o,l
3 (o∗ x,l x∗)=argminMSE(Savitzky-Golay(U˜(x),o,l),U GB);
o,l
4 U t =Savitzky-Golay(U GB,o∗ t,l t∗,derivative=1);
5 U x =Savitzky-Golay(U GB,o∗ x,l x∗,derivative=1);
6 U xx =Savitzky-Golay(U GB,o∗ x,l x∗,derivative=2);
.
.
7 .
A.3 AdditionalPDETestCases
Here,wedemonstratehowtosolvethePDEspresentedinthispaper.
A.3.1 Burgers’equation
WecanderiveBurgers’equationfromtheNavier-Stokesequationforthevelocityfieldbydroppingthepressuregradient
term. UnliketheNavier-Stokesequation,Burgers’equationdoesnotexhibitturbulentbehavior,andwecantransformit
tolinearformviatheCole-Hopftransformation[53]:
u =−uu +νu . (11)
t x xx
We solve Burgers’ Eq. (11) using the Fourier spectral method [54] with the ode45 function in MATLAB. We set
ν = 0.1, x ∈ [−8,8]with256points, t ∈ [0,10]with101points, andtheinitialconditionisaGaussianfunction:
exp(cid:0) −(x+2)2(cid:1)
.
A.3.2 Cableequation
The cable equation, shown in Eq. (12), quantitatively describes the electrical behavior of nerve axons and other
cable-likestructuresinbiologicalsystems. Itcapturestheelectricalcircuitofcurrentflowandvoltagechangeboth
within and between neurons. The equation is derived from a circuit model of the membrane and its intracellular
14arXivTemplate APREPRINT
Algorithm2:TherecurrentadaptivelassowithParetocurveandAIC
Input: Θ(u)∈R(n·m)×porC(n·m)×p,u ∈R(n·m)×1orC(n·m)×1.
t
Output: βˆ
1 forγ in1:5do
2 J(γ,0) =NULL;// initialize J;
3 k=1;// iteration counter;
4 J(γ,k) ={1,2,··· ,p};// selected columns from Θ;
5
whileJ(γ,k) ̸=J(γ,k−1)do
(cid:16) (cid:17)−γ
6 w(γ,k) = argmin β J(γ,k) ∥u t−Θ(u) J(γ,k)β J(γ,k)∥2 2 ;// ols weights;
7 βˆ(γ,k) =argmin β J(γ,k) ∥u t−Θ(u) J(γ,k)β J(γ,k)∥2 2+λ∗(cid:80)p j=1w j(γ,k)|β j·J(γ,k)|;
// λ∗ is the optimal point on the Pareto curve;
8
A(γ,k)=AIC(βˆ(γ,k));
(cid:110) (cid:111)
9 J(γ,k) = j :βˆ j(γ,k) ̸=0 ;// select active terms;
10 k =k+1;
end
end
11
J∗ =J(γ∗,k∗)where(γ∗,k∗)istheindexoftheminimumA;
12 βˆ=argmin βJ∗ ∥u t−Θ(u) J∗β J∗∥2 2;
andextracellularspace. ThecableequationplaysacrucialroleasanimportantPDEinbiophysicalstudies,helping
researchers understand how electrical signals change in diseases and disorders. By identifying the cable equation,
researcherscandiagnosethesenegativeconditionsbycheckingforchangesincapacitancesc ,resistancesr ,and
m m
axialresistancer ,r :
a e
∂2V ∂V (cid:114) r
λ2 =τ +V where λ= m and τ =r c . (12)
∂x2 ∂t r +r m m
e a
WesolvethecableequationusingodeintfunctioninPythonwiththeFourierspectralmethod. Wesetλ=1,τ =1,
x∈[−4,4]with∆x=0.1,t∈[0,5]with∆t=0.01,anduseaGaussianfunctionexp(cid:0) −x2(cid:1)
astheinitialcondition.
A.3.3 Navier-Stokes
Wesimulatethetwo-dimensionalNavier-StokesequationforfluidflowaroundacircularcylinderusingtheImmersed
BoundaryProjectionMethod[55,56]. Thetwo-dimensionalvelocitycomponentsaredenotedbyuandv,whileω
representsthevorticityawayfromthecircularcylinderofdiameteroneandmasscentreat(x=1,y =2). Wesetthe
Reynoldsnumberto100andaimtoidentifytheequation
ω =0.01ω +0.01ω −uω −vω . (13)
t xx yy x y
Thespatialdomainspansx ∈ [0,9]with∆x = 0.02, y ∈ [0,4]with∆y = 0.02, andthetemporaldomaincovers
t∈[300,330]with∆t=0.02. Wesavetheflowdataeverytensnapshots. Thissetupgeneratesasimulateddataset
containingapproximately13.5millionpoints(449×199×151). However,constructingthecandidatelibraryΘfor
suchalargedatasetposescomputationalchallenges. Tofacilitatetheevaluation,werandomlysamplepointswithinthe
redrectangularareashowninFig. 4Cateachsnapshot.
A.3.4 Reaction-diffusion
Reaction-diffusionsystemsofferaversatileframeworktomodelpatternformationinvariousnaturalphenomenain
chemistry, biology, geology, physics, and ecology. These systems give rise to a rich tapestry of periodic patterns,
includingspots,zigzags,spiralwaves,androlls. Inouranalysis,wefocusonawidelystudiedclassofreaction-diffusion
systemsknownastheλ−ωsystems,describedbythefollowingcoupledPDEs:
u =0.1u +0.1u +u−uv2−u3+v3+u2v (14)
t xx yy
v =0.1v +0.1v +v−uv2−u3−v3−u2v (15)
t xx yy
15arXivTemplate APREPRINT
Togeneratedataforouranalysis,weemploythesimulationmethoddescribedin[4]. Wediscretizethespatialdomain
x,y ∈[−10,10]usinga512×512gridandevolvethesystemoverthetimeintervalt∈[0,10]using201timesteps.
Thisprocedureyieldsarichdatasetcomprising52,690,944spatiotemporalpointsona512×512×201grid,providing
acomprehensivecharacterizationofthesystem’sdynamics.
A.3.5 Quantumharmonicoscillator
Thequantumharmonicoscillator(QHO)modelstheparabolicpotentialofaharmonicoscillatorinquantummechanics.
Itsimulatesthetimeevolutionofthewavefunctionassociatedwithaparticleintheparabolicpotential,providingthe
probabilitydistributionoftheparticle’spositionatanygiventimebytakingthesquaredmagnitudeofthewavefunction.
Theenergylevelsofaquantumharmonicoscillatorarequantized,meaningtheycanonlyassumespecific,discrete
values. Furthermore,evenifweformastatisticaldistributionfrommultipleexperiments,itwilllackinformationonthe
intricatephaseofthewavefunction. Weusethefollowingequation:
1 1 x2
u = iu −iuV = iu − iu. (16)
t 2 xx 2 xx 2
ToobtaindataontheQHO,weemploytheoperatorsplittingmethodwiththeFouriertransform. Weconsiderthe
timedomaint∈[0,10]with∆t=0.025,andthespacedomainx∈[−7.5,7.5]with∆x=15/512,usingaGaussian
exp(−((x−1)/2)2)astheinitialcondition. Whenperformingasparseregressiononcomplexnumbers,wetransform
theregressionfromcomplextorealnumbers. Foreachy =yR+iyI,wherethenormaliistheimaginarynumber,the
i i i
subscript representstheithobservation,wecanreformitas
i
p
yR+iyI =βR+iβI +(cid:88)(cid:2) (βR+iβI)(xR +ixI )(cid:3) +ϵR+iϵI
i i 0 0 j j ij ij
j=1
=βR+iβI +(βR+iβI)(xR +ixI )+(βR+iβI)(xR +ixI )+···+
0 0 1 1 i1 i1 2 2 i2 i2
(βR+iβI)(xR +ixI )+ϵR+iϵI
p p ip ip
p p
(cid:88) (cid:88)
=βR+iβI + (xRβR−xI βI)+i (xRβI +xI βR)+ϵR+iϵI
0 0 ij j ij j ij j ij j
j=1 j=1
andsplitittoextracttwoequationsforbothrealandimaginaryparts
p p p p
(cid:88) (cid:88) (cid:88) (cid:88)
yR =βR+ xRβR− xI βI +ϵR,yI =βI + xI βR+ xRβI +ϵI. (17)
i 0 ij j ij j i 0 ij j ij j
j=1 j=1 j=1 j=1
BasedonEq.(17),wecanorganizethedatasetas:
 yR   xR −xI xR −xI ··· xR −xI 
1 11 11 12 12 1p 1p
Y =       

yyy y . . . n2 RR1 2I I         , X=        

xx x x
R
nI 1 R 2 I 2 . . .1 1 1
1
−−x x xxR 1 R 2 . . .
I
nI 21 11
1
xx x x
R
nI 1 I 2R 2 . . .2 22
2
−−x x xxR 1 R 2 . . .R
I
nI 2 22
2
· · · ·.· · · ·..· · ·
·
xx x x
R
nI 1 I 2R 2 . . .p 11
1
−−x x xxR 1 R 2 . . .
I
nI 2p 11
1
         .
yI xI xR xI xR ··· xI xR
n n1 n1 n2 n2 n1 n1
Finally,weimplementtherecurrentadaptivelassoandSTRidgeonthere-positedY andX.
A.3.6 Advection-diffusionequation
Theadvection-diffusionequation,whichcombinesadvectionanddiffusionterms,describesthetransportanddispersion
of quantities such as temperature, substance concentration, or fluid velocity in various scientific and engineering
contexts. Wecanexpressthisequationasfollows:
c =Dc −uc (18)
t xx x
Wesolvetheadvection-diffusionequationusingtheFourierspectralmethodandtheodeintfunctioninPython. We
setthediffusioncoefficientD =1,theadvectionvelocityu=1,andconsiderthespatialdomainx∈[−10,10]with
resolution∆x=0.1andthetemporaldomaint∈[0,10]withresolution∆t=0.01. WeuseaGaussianfunctionof
theformexp(cid:0) −(x+2)2(cid:1)
asaninitialcondition.
16arXivTemplate APREPRINT
A.3.7 TheKdVequation
TheKorteweg–DeVries(KdV)equationdescribeswavepropagationonshallowwatersurfaces. TheKdVequation
solutionrevealsthatanisolatedtravelingwaveexhibitslinearbehavior,butnonlinearinteractionsemergewhenmultiple
waves are present. Moreover, the dependence of wave velocity on wave amplitude ensures that any solution with
multipleamplitudeswilldisplaynonlinearbehavior,regardlessoftheinteraction. Eq.(19)presentstheformulaforthe
KdVequation:
u =−6uu −u . (19)
t x xxx
Weemploythetwo-solitonsolution[57]tosolvetheKdVequation:
w(x,t)=−2
∂2
ln(cid:0) 1+B eθ1 +B eθ2 +AB B eθ1+θ2(cid:1) (20)
∂x2 1 2 1 2
(cid:18)
a −a
(cid:19)2
θ =a x−a3t, θ =a x−a3t, A= 1 2
1 1 1 2 2 2 a +a
1 2
wherea ,a ,B ,andB arearbitraryconstants. Wesetthefollowingparameters: 201timesteps(n = 201)with
1 2 1 2
t∈[0,20],512spatialpoints(m=512)withx∈[−30,−30],anda =0.5,a =1,B =1,B =5.
1 2 1 2
A.3.8 Transportequation
Thetransportequation,Eq.(21),playsafundamentalroleinscienceandengineering,describingthespatiotemporal
evolutionofscalarquantitiesorvectorfields. WesolvethisPDEusingtheanalyticalsolution,Eq.(22),withc=3to
generatethedataforourstudy. Thespatialdomainspansx∈[−5,1]withresolution∆x=0.01,whilethetemporal
domaincoverst∈[0,2]withtimestep∆t=0.01.
u =cu , c>0 (21)
t x
u(x,t)=exp(−(x+ct)2) (22)
A.3.9 Diffusionequation
Thediffusion(heat)equation,Eq.(23),playsacrucialroleinmanyscientificandengineeringfields,includingsolid-
statephysics,materialsscience,environmentalscience,andcomputationalfluiddynamics. Thisequationelucidates
the fundamental process of heat diffusion, enabling engineers to gain deep insights into heat conduction, thermal
conductivity,andtemperature-dependentphenomenainsolidsandothermaterials. Here,weusetheanalyticsolution,
Eq.(24),togeneratethedata. Wesetx∈[0,5]with∆x=0.01andt∈[0,1.5]with∆t=0.01,andchoosetheinitial
conditionas6sin(πx/L).
u =10u (23)
t xx
u(x,t)=6sin(cid:16)πx(cid:17) e−k( Lπ)2t,
k =10 (24)
L
Thediffusionequationanditsanalyticsolutionprovideapowerfulframeworkforunderstandingandpredictingheat
transferinvarioussystems. Bycarefullyselectingthespatialandtemporaldomainsandtheinitialcondition,wecan
modelawiderangeofreal-worldscenariosandgainvaluableinsightsintotheunderlyingphysicalprocesses.
17arXivTemplate APREPRINT
A Advection−diffusion c =c - c
t xx x
10.0 1.0 1.0
c
0.8 0.8
7.5 1.00
0.75 0.6 0.6
5.0
0.50 0.4 0.4
2.5 0.25 0.2 0.2
0.0 0.00 0.0 0.0
−10 −5 0 5 10 0 6 12 18 24 30 36 ¥ 102 102.6 103.2 103.8 104.4 105
x SNR(dB) N
B KdV u =6uu - u
t x xxx
20 1.0 1.0
u
0.8 0.8
15
−0.1 0.6 0.6
10 −0.2 0.4 0.4
−0.3
5 −0.4 0.2 0.2
0 0.0 0.0
−10 0 10 20 30 40 44 48 52 56 60 ¥ 102 102.6 103.2 103.8 104.4
x SNR(dB) N
C Transport u =3u
t x
2.0 1.0 1.0
u
0.8 0.8
1.5 1.00
0.75 0.6 0.6
1.0
0.50 0.4 0.4
0.5 0.25 0.2 0.2
0.0 0.0 0.0
−4 −2 0 2024283236404448525660 ¥ 102 102.6 103.2 103.8 104.4 105
x SNR(dB) N
D Diffusion u =10u
t xx
1.5 1.0 1.0
u
0.8
0.8
1.0 5 0.6
4 0.6
3 0.4
0.5
2
1 0.2 0.4
0.0 0.0
0 1 2 3 4 5 40 44 48 52 56 60 ¥ 102 102.6 103.2 103.8 104.4
x SNR(dB) N
Methods ARGOS−RAL STRidge
(
d
tol=0.2)
STRidge
(
d
tol=2)
STRidge
(
d
tol=10)
Figure6: SuccessratesofARGOS-RALandSTRidgeinidentifying(A)advection-diffusion,(B)KdV,(C)transport,
and(D)heatequationswithdifferentSNRsandsamplesizes. Toanalyzethenoisetolerance,weaddednoisetothePDE
solutionsatdifferentSNRlevels. Forthesamplesizeanalysis,werandomlysampledpointsfromtheset{u ,Θ(u)}
t
basedonnoiselessPDEsolutions. Forsamplesizeanalysis,werandomlysamplepointsfrom{u ,Θ(u)}setbasedon
t
noiselessPDEsolutions. Linesareonlyusedtolinkpoints,nottofitpoints. Theplotsdemonstratethatourmethod
maintainshighsuccessratesinidentifyingthecorrectPDEevenundersignificantnoiseandwithlimitedsamplesizes.
18
t
t
t
t
etar
sseccuS
etar
sseccuS
etar
sseccuS
etar
sseccuS