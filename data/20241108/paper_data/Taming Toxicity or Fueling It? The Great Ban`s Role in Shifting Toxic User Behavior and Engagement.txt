Taming Toxicity or Fueling It? The Great Ban’s Role in
Shifting Toxic User Behavior and Engagement
Lorenzo Cimaa,c, Benedetta Tessab,c, Stefano Crescic, Amaury Trujilloc,
Marco Avvenutia
aUniversity of Pisa - Department of Information Engineering, Largo Lazzarino
1, 56122, Pisa, Italy
bUniversity of Pisa - Department of Computer Science, Largo Bruno Pontecorvo
2, 56122, Pisa, Italy
cIIT-CNR, Via Moruzzi 1, 56122, Pisa, Italy
Abstract
In today’s online environments users experience harm and abuse on a daily
basis. Therefore, content moderation is crucial to ensure their safety and
well-being. However, the effectiveness of many moderation interventions is
still uncertain. We evaluate the effectiveness of The Great Ban, one of the
largest deplatforming interventions carried out by Reddit that affected al-
most 2,000 communities. We analyze 53M comments shared by nearly 34K
users, providing in-depth results on both the intended and unintended con-
sequences of this ban. We found that 15.6% of the moderated users aban-
doned the platform while the remaining ones decreased their overall toxicity
by 4.1%. Nonetheless, a subset of those users increased their toxicity by
70% after the intervention. In any case, increases in toxicity did not lead
to marked increases in activity or engagement, meaning that the most toxic
users had overall a limited impact. Our findings bring to light new insights
on the effectiveness of deplatforming. Furthermore, they also contribute to
informing future content moderation strategies.
Keywords: content moderation, online toxicity, deplatforming, Reddit
1. Introduction
Content moderation is essential for online platforms, as it prevents the
spread of harmful content and hateful behavior such as the perpetuation of
hate speech [1]. It is also crucial to promote fairness and safety among users
Preprint submitted to Computer Communications November 8, 2024
4202
voN
7
]YC.sc[
2v73040.1142:viXraby enforcing ethical standards and supporting the health of online commu-
nities [2]. In fact, platforms use content moderation as a means to enforce
their policies [3]. In particular, administrators apply different types of inter-
ventions, which can be more or less severe. For example, they can send short
warning messages and use informative labels [4], or even take the drastic
decision to remove content and/or users [5, 6]. However, despite the in-
creasing reliance on content moderation, there is still little understanding of
the effects of most moderation interventions, which threatens their efficacy.
Recent studies have demonstrated that while some interventions had het-
erogeneous [7, 8] or even ineffectual outcomes [9], others led to undesirable
consequences [10, 11]. This is why it is crucial to assess the effects of recent
moderation interventions as a preliminary step in planning and developing
new ones.
The most popular and widely used intervention is known as deplatform-
ing, which involves the removal of content, users, or even entire communi-
ties [12]. Notorious examples are the ban that Donald Trump received in
2021 from Facebook and X (formerly Twitter) [13] and the deplatforming
of three particularly toxic influencers from X [6]. Additionally, X removed
accounts involved in coordinated inauthentic behavior [14] and Reddit per-
manently shut down different communities because of racism, sexism and
hatefulness [15, 16]. In June 2020, Reddit itself hosted one of the biggest de-
platforming campaigns in the history of social media –The Great Ban– which
resulted in around 2,000 subreddits being banned due to ongoing spread of
toxicity and hate speech.1 Among these are popular communities such as
r/The Donald and r/ChapoTrapHouse. Despite its impact on several commu-
nities and users within and outside Reddit, its effects are still little-explored.
For example, current research on The Great Ban has mainly investigated
the changes in the writing style of the users [17] without assessing the ban’s
effectiveness. Few studies analyzed the changes in toxicity, and those who
did focused only on a small set of subreddits [5]. Moreover, the majority
of the existing works on The Great Ban are focused on community-level
effects, neglecting the individual user-level responses that are instrumental
for understanding how effective the ban was in mitigating problematic be-
haviors [18, 8]. In a previous work, we provided preliminary results on the
1https://www.reddit.com/r/announcements/comments/hi3oht/update_to_our_
content_policy/ (accessed: 10/15/2024)
2effectiveness and unintended consequences of The Great Ban [19]. Here, we
extend our previous analysis by adopting a robust causal method based on
Difference-in-Differences (DiD) to estimate the effects of the intervention.
Furthermore, we address an additional research question investigating the
impact that toxic users had after the intervention, as explained in the fol-
lowing.
Research focus. We address the outstanding knowledge gaps by con-
ducting a comprehensive quantitative causal analysis of the changes in tox-
icity among users active in the 15 most popular subreddits involved in The
Great Ban. We analyze 53M comments posted by nearly 34k users over a
period of 14 months guided by the following research questions.
• RQ1: Did The Great Ban effectively reduce toxicity? Studies have
shown that some interventions led to an increase rather than a decrease in
toxic behavior. Here we assess the effectiveness of The Great Ban in reducing
toxicity, as hate and toxic speech were the main reasons behind the ban.
• RQ2: Did The Great Ban lead to any unintended side effects for cer-
tain users? That is, were there users who became significantly more toxic
after the intervention? The evaluation of the outcomes of a moderation in-
tervention has to take into consideration the possible presence of users who
grew resentful of the platforms and increased –rather than decreased– their
toxicity. Such extreme reactions can arise even amid an overall reduction in
toxicity at platform- or community- level, requiring further analyses at user
level. In this study, we evaluate and estimate the extent of these reactions to
The Great Ban, considering them as potential side effects of the intervention.
• RQ3: What were the behavioral dynamics of toxic users, in terms of
their activity and generated engagement? To deepen our analysis, we ex-
amine further behavioral dimensions of those users who became much more
toxic after The Great Ban. We specifically focus on their degree of activity
on the platform and the engagement they receive from other users. Con-
jointly analyzing the dynamics of toxicity and activity is important as it can
allow to identify users who are both very active and very toxic. Additionally,
investigating the social feedback they receive may reveal the degree to which
highly toxic behaviors are tolerated, and possibly even encouraged, by other
users [20].
Main findings. Based on the insights gained from answering the previ-
ous research questions, our study produces the following main findings:
• The Great Ban led 15.6% of the moderated users to abandon the plat-
3form, while those who stayed reduced their toxicity by an average of
4.1%.
• While the reduction in toxicity was limited, a significant fraction of
users became much more toxic. In particular, 5% of users increased
their toxicity by over 70% compared to their pre-ban levels.
• Resentful users who escalated their toxicity were found across each of
the analyzed subreddits. However, their impact was limited probably
due to their limited activity and the lack of positive feedback from
other users.
• Majorchangesinadimensionofuserbehaviordonotnecessarilyleadto
major changes in other dimensions. For example, the majority of users
who drastically increased their toxicity did not experience significant
changes in activity or engagement.
Our work provides an in-depth analysis of the effects of The Great Ban.
It points out the shortcomings by highlighting the complex challenges of
moderating different communities. Our findings can guide the development
of future moderation interventions aimed at increasing their effectiveness.
2. Related Work
In this section, we review and analyze recent literature on the evaluation
of moderation interventions, beginning with studies most closely related to
our own.
2.1. Deplatforming
The Great Ban was a significant event that had a major impact on Red-
dit. However, only a few studies actually looked into its effects. One of them
is the study conducted by Trujillo et al. [17], that investigated the changes
in activity and use of language among the 15 most popular subreddits in-
volved in the ban. They discovered that the most active users drastically
decreased their level of activity and observed heterogeneous responses to
the ban both intra- and inter- subreddits. Here, we build on this study by
evaluating the impact of The Great Ban in terms of toxicity, rather than
focusing on activity and language. Another body of works focused on assess-
ing the effects of deplatforming in a subset of subreddits affected by the ban
4or in entirely different subreddits. Chandrasekharan et al. [15] and Saleem
and Ruths [21] evaluated how The Great Ban impacted two specific subred-
dits: r/fatpeoplehate and r/coontown. They revealed how a large portion
of users abandoned the platform and the remaining ones notably decreased
their toxicity levels. However, they also observed that several users migrated
to other subreddits and doubled their posting activity [22]. Other studies
focused on deplatforming both within and outside Reddit. Horta Ribeiro
et al. [7] studied the migration of Reddit users from banned subreddits to
other platforms after a deplatforming intervention. They show how migrated
users became drastically less active on the new platforms. This was not the
case for a group of users, who instead became much more toxic and radical-
ized. Mekacher et al. [23] analyzed the consequences of deplatforming from
Twitter to Gettr. They found that politically polarized users exhibit lower
toxicity on fringe platforms, likely due to reduced exposure to interactions
with out-group members. Moreover, Cima et al. [14] examined large-scale
bans implemented by Twitter to combat coordinated inauthentic behaviors.
To conclude, Jhaver et al. [6] studied the impact of the banishment of three
notorious influencers from Twitter. They observed a general decrease in at-
tention towards these influencers and toxicity among their fans. However,
some users became much more active and toxic.
In general, these studies highlight how moderation interventions do not
always yield the desired results and that different communities and different
users can react differently to the same intervention. Our work aims to extend
the existing literature by shedding light on the effects of The Great Ban, one
of the biggest – yet little-explored – moderation interventions. Our study
provides a comprehensive evaluation of the ban’s impact on the 15 most
popular subreddits in terms of toxicity, activity, and engagement.
2.2. Soft moderation
Despite deplatforming being one of the most widely adopted moderation
interventions, it can be perceived by many users as a threat to free speech
since it involves the removal of content and users [24]. This led to the rise
of an alternative category of interventions known as soft interventions. Re-
cently, these have been the focus of several studies. For example, Trujillo and
Cresci [5, 8] investigated the effects of quarantines and restrictions, which
are frequently implemented before community bans on Reddit. In partic-
ular, they analyzed the effects of moderation on r/the donald, revealing a
decrease in overall activity and toxicity. However, this came at the expense
5IN-BEFORE OUT-BEFORE OUT-AFTER
subreddit subscribers coreusers comments users comments users comments
r/chapotraphouse 159,185 9,295 1,368,874 9,205 3,947,894 8,319 3,157,462
r/the donald 792,050 4,262 619,434 4,132 2,578,026 3,145 1,434,008
r/darkhumorandmemes 421,506 1,632 35,561 1,617 1,246,399 1,392 689,079
r/consumeproduct 64,937 1,730 60,073 1,719 1,209,933 1,275 594,349
r/gendercritical 64,772 1,091 94,735 1,039 511,173 706 287,877
r/thenewright 41,230 729 5,792 726 600,057 575 308,584
r/soyboys 17,578 596 5,102 594 454,659 432 190,570
r/shitneoconssay 8,701 559 9,178 555 338,218 384 140,619
r/debatealtright 7,381 488 27,814 476 274,600 328 117,281
r/darkjokecentral 185,399 316 3,214 308 307,876 270 179,067
r/wojak 26,816 244 1,666 240 210,249 170 81,142
r/hatecrimehoaxes 20,111 189 775 188 185,379 143 96,457
r/ccj2 11,834 150 9,785 145 101,165 119 63,393
r/imgoingtohellforthis2 47,363 93 376 92 74,664 72 43,018
r/oandaexclusiveforum 2,389 60 1,313 59 48,774 55 35,853
focusgrouptotal(unique) 16,828 2,243,692 16,540 8,235,086 13,963 5,592,321
r/askreddit 44,279,043 15,863 3,220,750 15,850 17,014,057 15,576 12,372,977
r/worldnews 34,091,866 10,051 577,777 10,050 12,728,027 9,907 9,517,097
r/politics 8,438,064 9,002 1,862,399 8,998 11,059,478 8,862 8,328,241
baselinegrouptotal(unique) 16,955 5,660,926 16,937 18,480,693 16,633 13,378,316
Table 1: Composition of the dataset. Subreddits are sorted by number of core users
before the ban. Data in IN-BEFORE refers to user activity within the specified subreddits
before the ban occurred. OUT-BEFORE and OUT-AFTER represent user activity outside of
the specified subreddits (i.e., in the rest of Reddit), respectively before and after the ban.
of increased political polarization and decreased factual accuracy in shared
news [5, 8]. Chandrasekharan et al. [22] and Shen and Ros´e [25] also stud-
ied the quarantine of r/the donald. They determined that this intervention
was essentially ineffectual and did not produce notable changes in terms of
misogynistic and racist comments or users’ engagement and behavior.
Another common example is flagging disputed posts with warning labels,
whose effectiveness was evaluated in terms of perceived credibility and user
engagement. Pennycook et al. [11] revealed that the use of warning la-
bels can enhance the perceived credibility of unlabeled posts, including those
containing false information that has not yet been addressed. In addition,
Zannettou [24] demonstrated how users tend to reply often to tweets contain-
ing warning labels in order to further debunk the claims. However, this leads
to labeled tweets circulating more than unlabelled ones. To conclude, Kat-
saros et al. [4] assessed the effectiveness of showing warning messages to users
before they post toxic tweets through an A/B test on Twitter. The test con-
6The Great Ban
(29 June 2020)
15 banned IN-BEFORE
subreddits
rest of OUT-BEFORE OUT-AFTER
Reddit
December May July February
2019 2020 2020 2020
Figure 1: Timeline of the data collection and analysis periods. Our study covers two
7-month intervals centered around The Great Ban. The IN-BEFORE dataset contains no
dataafterMay2020,suggestingthatactivityinthebannedsubredditsceasedpriortothe
official date of the ban.
firmed that this strategy is effective at reducing the number of toxic content
on average, although a portion of users actually increased their toxicity.
The findings on soft moderation interventions align with the findings
on deplatforming, showing that each intervention can produce both desired
and undesired effects. Overall, these studies emphasize the necessity for
additional research to assess the impact of less-examined interventions.
3. Dataset
Our dataset2 includes 16M comments shared by 16,828 distinct Reddit
users who have been active in at least one of the 15 most popular public
subreddits that were banned during The Great Ban [17], as detailed in Ta-
ble 1. In this context, the term popular refers to the number of daily active
users. Even though Reddit administrators initially published an obfuscated
list of the most popular banned subreddits,3 [17] were able to decipher this
list for subreddits with over 2,000 daily active users. A total of 15 subreddits
were identified. The composition of our dataset is shown in Figure 1, and
the procedure adopted to build it is described below.
Focus group. We began by collecting all comments posted between
December 2019 and June 2020 in each of the 15 popular banned subreddits,
yielding 8M comments from 194K distinct users. To this end, we used the
Pushshift data archive [26]. The dataset covers 30 weeks (7 months) leading
2https://doi.org/10.5281/zenodo.14034510
3https://www.redditstatic.com/banned-subreddits-june-2020.txt (accessed:
10/15/2024)
7up to The Great Ban, providing a suitable baseline for user activity before
the moderation intervention [8]. Notably, we were unable to collect data
between May and June 2020 due to some subreddits halting their activity or
being banned prior to Reddit’s public announcement of The Great Ban on
June 29, 2020, as shown in Figure 1.
Following recent literature [5, 27], we identified a representative set of
users for the selected subreddits by focusing on core users, that is users who
consistently participated in at least one subreddit. Core users were charac-
terizedasthosewhopostedatleastonecommenteachmonthfromDecember
2019 to March 2020.4 Moreover, we excluded bots (i.e., clearly automated
accounts) by removing all accounts that posted two or more comments at
the exact same timestamp [28]. To this end, we implemented a minimum
time interval of 1 second between comments, ensuring that we did not unin-
tentionally exclude genuine users. We verified the validity of this approach
by manually validating a random sample of 1,000 comments. After these
filtering steps, we ended up with 2.2M comments made by 16,828 core users.
Henceforth, we denote this subset of our dataset as IN-BEFORE, representing
activity within the banned subreddits prior to the ban.
To ensure a fair evaluation of the effects of The Great Ban, we need to
match comparable datasets before and after the intervention. Since no activ-
ityexistsinsidethebannedsubredditsfollowingtheintervention,wecollected
allcommentsmadebythecoreusersoutsidethe15bannedsubredditsduring
the 7 months before and after the ban as shown in Figure 1. We gathered
approximately 13.8M comments from 16,540 distinct users. Data related to
user activities before the ban was labeled as OUT-BEFORE, and data after the
ban as OUT-AFTER, as shown in Table 1. Estimates of the ban’s effects were
derived by comparing the OUT-BEFORE and OUT-AFTER datasets.
Baseline group. We obtain accurate causal estimates of the effects of
The Great Ban by comparing the behavioral changes exhibited by the core
users to possible changes exhibited during the same time by a set of refer-
ence Reddit users who were not affected by the ban. To reach this goal, we
first identify a small set of related, but non-banned, subreddits to act as a
baseline for the banned ones. To obtain this baseline, we first preprocessed
4We excluded April 2020 from this analysis due to the limited number of collected
comments,likelybecausesubredditactivityhadalreadyslowedorhaltedintheearlydays
of that month.
8cluster banned subreddits non-banned subreddits
r/ccj2 r/politics
r/hatecrimehoaxes r/worldnews
cluster 1
r/shitneoconssay r/askreddit
r/soyboys
r/debatealtright r/askreddit
cluster 2 r/gendercritical r/politics
r/thenewright r/worldnews
r/chapotraphouse r/politics
cluster 3 r/the donald r/askreddit
r/worldnews
r/consumeproduct r/askreddit
r/darkhumorandmemes r/politics
cluster 4
r/darkjokecentral r/memes
r/oandaexclusiveforum
r/wojak –
cluster 5
r/imgoingtohellforthis2 –
Table 2: Banned subreddits grouped by the cluster they belong to. For each cluster of
banned subreddits, we report the corresponding most representative non-banned subred-
dits. Frequently occurring non-banned subreddits are used as baselines to compute the
causal effect of the ban on the banned subreddits. Banned subreddits in cluster 5 are
ignored as they are very small compared to the others.
every comment in IN-BEFORE for each banned subreddit by removing URLs,
stopwords, and words less than four characters long. Subsequently, we per-
formed stemming. For r/chapotraphouse we executed these steps only on a
random sample of 1M comments, due to the sheer number of comments in
the subreddit. The preprocessed comments were then fed to BERTopic [29]
to extract up to ten relevant topics, each consisting of ten keywords. We
then used the 100 descriptive keywords for each subreddit to project it with
BERT [30] into a 768-dimensional embedding space. This representation is
suitable to highlight commonalities between the banned subreddits, such as
via clustering, which we leverage to identify the small set of baseline subred-
dits. However, thehighdimensionalityoftheembeddingspaceisnotsuitable
to directly perform clustering [31, 32]. Given the low number of data points
– the 15 banned subreddits – we therefore first greatly reduce the dimension-
9ality with PCA before clustering the banned subreddits with k-means. We
experimented with multiple numbers p of principal components and values
for k, ultimately choosing p = 5 and k = 5 by optimizing the silhouette co-
efficient. Table 2 illustrates the clustering output. We now identify a set of
reference non-banned subreddits for each cluster of banned subreddits, with
the exception of cluster 5 that is formed by particularly small subreddits
(i.e., r/imgoingtohellforthis2 and r/wojak). For clusters one to four, we
computed the cluster centroid and found the most representative keywords
as those having the smallest Euclidean distance to the centroid. We then re-
trieved all comments posted during the pre-ban period that contained those
keywords and identified the non-banned subreddits where such keywords oc-
curred more frequently [33]. These subreddits are related to the non-banned
ones and are therefore suitable candidates for representing a baseline for
our causal analyses. As reported in Table 2, r/politics, r/askreddit, and
r/worldnews are overall the three most representative non-banned subreddits
for our clusters. As reported in Table 1, given the numerosity of the baseline
subreddits, we selected a random stratified sample of 17K users, which is
comparable to the number of core users in the focus group of banned subred-
dits. From this set, we removed 45 users who posted at least one comment
in one of the 15 banned subreddits, so as to avoid any overlap between the
focus and baseline groups.
1011
subreddits
with
those
of
the
baseline
(non-banned)
subreddits.
on
the
remaining
users
was
computed
via
Difference-in-Differences
(DiD),
by
discounting
the
effects
measured
for
the
banned
columns
show
the
effect
sizes
and
the
statistical
significance
of
the
differences
in
toxicity.
The
causal
effect
of
The
Great
Ban
the
latter,
toxicity
scores
were
computed
both
before
(BEF)
and
after
(AFT)
the
ban.
The
ABA
vs
BEF
and
BEF
vs
AFT
Table
3:
Subreddit-wise
mean
toxicity
scores
for
users
who
left
Reddit
after
the
ban
(ABA)
and
for
the
remaining
ones.
For
*:
p<0.1;
**:
p<0.05;
***:
p<0.01
baseline
group
overall
304
0.145
0.096
16,633
0.120
0.067
0.119
0.073
−0.025
***
−0.001
***
r/politics
136
0.146
0.079
8,862
0.125
0.068
0.124
0.072
−0.021
***
−0.001
***
r/worldnews
143
0.146
0.083
9,907
0.125
0.067
0.124
0.072
−0.021
***
−0.001
***
r/askreddit
274
0.146
0.093
15,576
0.121
0.066
0.120
0.072
−0.025
***
−0.001
***
focus
group
overall
2,577
0.167
0.120
13,963
0.147
0.083
0.141
0.101
−0.020
***
−0.006
***
r/oandaexclusiveforum
4
0.129
0.107
55
0.188
0.086
0.182
0.092
+0.059
−0.010
***
r/imgoingtohellforthis2
20
0.202
0.144
72
0.169
0.077
0.187
0.141
−0.033
−0.004
**
r/ccj2
26
0.188
0.093
119
0.133
0.076
0.125
0.106
−0.055
***
−0.008
***
r/hatecrimehoaxes
45
0.175
0.073
143
0.166
0.074
0.158
0.111
−0.009
−0.004
***
r/wojak
70
0.192
0.068
170
0.160
0.065
0.143
0.044
−0.032
***
−0.011
***
r/darkjokecentral
38
0.221
0.154
270
0.155
0.070
0.144
0.092
−0.066
***
−0.005
***
r/debatealtright
148
0.171
0.084
328
0.153
0.070
0.155
0.115
−0.018
**
−0.002
**
r/shitneoconssay
171
0.190
0.084
384
0.165
0.071
0.160
0.098
−0.025
***
−0.007
***
r/soyboys
162
0.200
0.074
432
0.177
0.072
0.163
0.087
−0.023
***
−0.011
***
r/thenewright
151
0.177
0.092
575
0.153
0.076
0.145
0.098
−0.024
***
−0.009
***
r/gendercritical
333
0.184
0.119
706
0.167
0.071
0.141
0.116
−0.017
***
−0.019
***
r/consumeproduct
444
0.190
0.090
1,275
0.158
0.045
0.160
0.099
−0.032
***
−0.009
***
r/darkhumorandmemes
225
0.183
0.108
1,392
0.161
0.073
0.154
0.098
−0.022
***
−0.009
***
r/the
donald
987
0.163
0.122
3,145
0.145
0.081
0.145
0.113
−0.018
***
−0.005
***
r/chapotraphouse
886
0.163
0.123
8,319
0.145
0.084
0.138
0.094
−0.018
***
−0.005
***
subreddit
users
mean
stdev
users
mean
stdev
mean
stdev
ABA
vs
BEF
BEF
vs
AFT
aband.
before
(ABA)
remain.
before
(BEF)
remain.
after
(AFT)
DiD4. Analyses and Results
4.1. RQ1: Effectiveness of The Great Ban
In this section, we analyze how effective The Great Ban was in reducing
toxic behaviors.
Abandoning users. Table 1 underlines a difference of 2,577 users be-
tween the OUT-BEFORE and OUT-AFTER datasets, meaning that (15.6%) of the
users became inactive following The Great Ban. The percentage of users who
have abandoned the baseline subreddits is much smaller, at approximately
2%, corresponding to 304 users. Since there is no sign of activity from these
users during the seven months following the ban, we can presume that they
not only abandoned Reddit but also likely migrated to other platforms. This
is the first clear effect of The Great Ban. To provide more details, for each
subreddit we compare the toxicity of abandoning users to the toxicity of
those who remained on the platform. As shown in Table 3, in 14 out of
15 subreddits, the abandoning users exhibited higher pre-ban toxicity than
the others. This means that toxic users were more inclined to abandon the
platform after the ban, compared to their less toxic fellows. In 12 subreddits,
the difference in toxicity between users who abandoned and those who did
not is statistically significant (p < 0.05) according to a t-test for unpaired
data. Additionally, abandoning users exhibited higher standard deviation,
suggesting greater variability in toxicity.
Remaining users. Besides leading a subset of users to abandon the
platform, the ban may have also contributed to shifts in toxicity among
the remaining users. Table 3 presents, for each subreddit, toxicity scores
for the set of remaining users, both before and after the ban. It shows
how, for the most part, the remaining users reduced their toxicity scores
after the ban. In particular, the scores aggregated by subreddit reveal that
users from all 15 subreddits exhibited a slight decrease in their toxicity. We
performed a Difference-in-Differences (DiD) analysis to compare the changes
with the baseline group, and proved how this decrease is also statistically
significant (p < 0.05). The effect sizes obtained comparing remaining users
before and after the ban are notably smaller than those obtained comparing
the abandoning users to remaining ones. In fact, after The Great Ban, there
was an average reduction in overall toxicity of 4.08% — a relatively modest
decrease. Furthermore, in 14 of the 15 subreddits, the standard deviation
for toxicity values is higher after the ban compared to before. This indicates
12TOXICITY BEFORE TOXICITY AFTER
CHANGE IN TOXICITY
Figure 2: User-level toxicity changes after The Great Ban for each active user. The slope
chart in the central panel highlights a majority of red-colored rising lines, indicating a
substantial number of users who significantly increased their toxicity. The beeswarm plot
in the bottom panel reinforces this observation, showing a higher concentration of users
in the right red-colored tail of the distribution compared to the left blue-colored tail. The
boxplots illustrate the marginal distributions for abandoning and remaining users, before
and after the intervention.
that the ban has increased variability in the behavior of the remaining users,
a phenomenon that we explore more thoroughly with further analyses.
User-level effects. Until now, we presented results at community-level,
showing that after the ban, 15.6% of core users abandoned the platform
and the remaining ones reduced slightly their average toxicity by 4.08%.
To provide a more in-depth analysis, we also examine user-level effects by
analyzingthechangesintoxicityexperiencedbyeachoftheremaining13,963
users. The central panel of Figure 2 shows a slope chart representing user-
level toxicity changes across all users, regardless of the subreddit in which
they were active. A single line is associated with each user and line slopes
represent the amount of increase or decrease in toxicity. Rising lines can be
colored in different shades of red based on their slope, representing users who
became more toxic after the ban. Instead, the decreasing lines are in different
shades of blue and represent users who reduced their toxicity. Figure 2 also
features marginal boxplots displaying the toxicity distributions of remaining
users before (left side of the slope chart) and after (right side) the ban.
In particular, the leftmost boxplot displays the toxicity distribution for users
wholefttheplatform. Finally, thepanelatthebottomshowsthedistribution
13of the changes in user-level toxicity in the form of a beeswarm plot. This
is useful to identify outliers and study both tails of the distribution – those
associated with significant toxicity increases (red dots on the right-hand side
of the beeswarm plot) and decreases (blue dots on the left-hand side).
The three boxplots in Figure 2 align with and support the general toxic-
ity trends detailed in Table 3. Users who abandoned the platforms have the
largest average toxicity with respect to those who stayed. The group display-
ing the lowest average toxicity is the one formed by the remaining users after
the ban. The slope chart in Figure 2 shows that most lines have relatively
small positive or negative slopes. This means that most users manifested
little changes in toxicity, whether it is a change in positive or negative. At
the same time, the slope chart also displays a notable number of steep lines,
representing users who showed significant changes in toxicity. Specifically,
the steep red lines outnumber the blue ones. This means that the majority
of users who drastically changed their toxicity became more toxic. This find-
ing qualitatively illustrates an unintended consequence of The Great Ban: it
led a significant minority of users to become resentful, resulting in markedly
more toxic behavior. The points where the lines intersect the y axis on the
right side of the plot indicate the users’ toxicity levels after the ban. This is
also shown in the boxplot on the right side of the slope chart. As illustrated
in Figure 2 and as suggested by the standard deviation values in Table 3,
there is increased variability in user toxicity following the ban. What led
to this increase in variability is the presence of the aforementioned resentful
users.
Figure 2 presents the aggregated results across all subreddits. Nonethe-
less, the same plots can be used to investigate the effects of The Great Ban
among single subreddits, as done by [19]. This is useful for identifying com-
mon patterns and potential differences among the subreddits. We therefore
conducted the analysis separately for users in each subreddit. The compar-
ison across different subreddits reaffirmed earlier findings that most users
who experienced significant toxicity changes after the ban increased their
toxicity. However, this behavior was more pronounced in some subreddits
and less evident in others. Overall, we observed that the findings for RQ1 in
[19], which utilized the median, are similar to those presented in this section
when using the mean and a causal inference method like DiD.
14chapotraphouse
the_donald
darkhumorandmemes
consumeproduct
gendercritical
thenewright
soyboys
shitneoconssay
debatealtright
darkjokecentral
wojak
hatecrimehoaxes
ccj2
imgoingtohellforthis
oandaexclusiveforum
askreddit
worldnews
politics
15000 10000 5000 0 20 405060 80 100
users %toxicity increment
Figure3: Subreddit-wisepercentagetoxicityincrement(orangebars,right-handside)and
total number of users (purple bars, left-hand side), for the banned and baseline (non-
banned) subreddits. Subreddits where the toxicity increases outweight the decreases are
highlighted in red, while the others in cyan.
4.2. RQ2: Extreme user reactions to The Great Ban
Findings from RQ1 suggest that The Great Ban led to a small decrease
in toxicity, except for a group of particularly resentful users who drastically
increased their toxicity. We now investigate thepresence of these users across
the subreddits.
Let t(i) ,t(i) be the toxicity of the i-th user before and after the
BEF AFT
ban, and ∆t(i) = t(i) −t(i) be their change in toxicity. The beeswarm
AFT BEF
plot of Figure 2 illustrates the distribution of ∆t(i) for all users. We found
that5%ofallusershavea∆t(i) > 0.1. Thisfindingisnoteworthyconsidering
that the mean toxicity pre-ban is 0.141, as reported in Table 3. This means
that 5% of users increased their toxicity by more than 70% after the ban.
To broaden the analysis, we compute the total change in toxicity within a
subreddit with N users as ∆t =
(cid:80)N
∆t(i). To evaluate separately the
i=1
contributions of the two tails of the beeswarm plot, we only consider positive
or negative ∆t(i). We now quantify and focus on the contribution of the
right tail – the one relative to increased toxicity – as follows:
(cid:88)N
∆t+ = ∆t(i) with ∆t(i) > 0
i=1
15chapotraphouse
the_donald
darkhumorandmemes
consumeproduct
gendercritical
thenewright
soyboys
shitneoconssay
debatealtright
darkjokecentral
wojak
hatecrimehoaxes
ccj2
imgoingtohellforthis
oandaexclusiveforum
askreddit
worldnews
politics
6 4 2 0 20 40 50 60 80 100
% users %toxicity increment
Figure 4: Subreddit-wise percentage toxicity increment of the outliers users (orange bars,
right-hand side) and percentage of outlier users out of all subreddit users (purple bars,
left-hand side), for the banned and baseline (non-banned) subreddits. Subreddits where
the toxicity increases of the outlier users outweight the decreases are highlighted in red,
while the others in cyan. The subreddit r/hatecrimehoaxes is black-colored since it
does not contain any outlier.
Figure 3 illustrates the percentage increment toxicity for the banned and
baseline subreddits, along with the number of users in those subreddits. The
corresponding decrease in toxicity, which is relative to the left tail, can be
easily computed as ∆t− = 100−∆t+. By looking at the percentage toxicity
increment for the banned subreddits, we can deduce that the contributions
of the left and right tails are quite balanced across nearly all subreddits.
For example, in the case of r/the donald these contributions are perfectly
balanced. This is also the same for the baseline subreddits. For 13 out of
15 banned subreddits (blue colored), the decrease in toxicity slightly exceeds
the increase, which leads to the overall modest reduction in toxicity observed
in RQ1. However, we can observe the opposite trend in r/debatealtright
and r/imgoingtohellforthis2 (red colored).
To further assess the behavior of outlier users – those who drastically
increased or decreased their toxicity – we recompute ∆t+ and ∆t− by only
considering those users whose |∆t(i)| > 0.25. Figure 4 reiterates the previous
analysisforoutlierusers. Theproportionofoutlierusers(left-handsideofthe
16+1.00
+0.75
+0.50
+0.25
+0.00
-0.25
-0.50
-0.75
-1.00
1 2 3 4 5 6 7 8 9
number of subreddits
Figure5: Relationshipbetweenuserparticipationinthe15bannedsubredditsandchange
in toxicity. The vast majority of users only participated in one or two subreddits. More-
over, participation in more/less subreddits is unrelated to changes in toxicity.
figure) remains relatively small in all subreddits, with r/gendercritical ex-
hibitingthehighestpercentagewithalmost6%ofusers,whiler/hatecrimehoaxes
does not have outliers at all. The results are notably different than those of
Figure 3, as for 11 out of 15 banned subreddits (red colored) the increase in
toxicity (right-hand side of the figure) significantly outweighs the decrease.
Thisdoesnotapplytor/gendercritical,r/soyboys,andr/oandaexlusiveforms,
as for the first two subreddits, the increase in toxicity is less than 50% and no
increase is observed for the latter. For what concerns the baseline subreddits,
the vast majority of outliers exhibited a marked toxicity increment. How-
ever, thenumberofoutlierswithinthebaselinesubredditsismuchlowerwith
respect to the outliers in the banned subreddits, and ranges from 0.13% to
0.22%. In addition to these results, we also repeated the analysis for multiple
values of |∆t(i)|, as described in [19]. We found that the obverved behavior is
independent of the way in which outlier users are defined, which supports the
robusteness of our finding. Overall, our results reveal that the phenomenon
of outlier users who drastically increased their toxicity post-ban is peculiar of
the banned subreddits, and can possibly be explained as a negative reaction
of such users to the ban itself. Moreover, our findings also underscore that
extremely toxic users are spread across almost all banned subreddits, which
is a sign of a systemic reaction to the ban.
17
yticixot
ni
egnahc+8000 +8000
Q4 Q1 Q4 Q14000
+6000 4000 +6000
2000 2000
+4000 +4000 0 0
+2000 Q1Q2Q3Q4 +2000 Q1Q2Q3Q4
+0 +0
-2000 -2000
-4000 -4000
-6000 -6000
Q3 Q2 Q3 Q2
-8000 -8000
-1.0-0.8-0.6-0.4-0.2+0.0+0.2+0.4+0.6+0.8+1.0 -1.0-0.8-0.6-0.4-0.2+0.0+0.2+0.4+0.6+0.8+1.0
change in toxicity change in toxicity
Figure6: Densityscatterplotsoftherelationshipbetweenchangesintoxicityandchanges
in activity (left-hand side) and score (right-hand side), for each user. The insets provide
counts of the number of users in each quadrant of the scatterplots.
4.3. RQ3: Behavioral dynamics of extremely toxic users
Our analyses in RQ2 revealed the widespread presence of extremely toxic
users and quantified the extent of the issue across the subreddits. Here we
move forward by providing additional information on their behavior in order
to draw insights into their possible impact on the platform.
Subreddits participation. Initially, we explore the subreddit partici-
pation habits of these users as a function of their change in toxicity. This
analysis aims to ascertain whether each of the most toxic users engaged in a
few or many of the banned subreddits. Figure 5 suggests that only a small
number of users participated in multiple subreddits. Instead, the vast major-
ity of users participated only in a few subreddits, typically ranging between
one and three, consistently with the echo chamber theory [34]. Moreover,
user toxicity changes do not depend on the number of subreddits in which
the user participated.
Activity. Next, we look into the relationship between changes in toxicity
and activity. We measure user activity as the number of posted comments.
Conjointly studying user activity and toxicity is important since toxic users
pose a meaningful threat only when high toxicity coincides with elevated
activity, which holds the potential to cause a substantial impact on the plat-
form. This joint analysis also enables the identification of those users who
are both highly toxic and remarkably active, allowing to prioritize modera-
tion interventions towards them [35]. The left-most plot of Figure 6 presents
a density scatterplot of the changes in toxicity and activity for each consid-
ered user. The plot area is divided into four quadrants, corresponding to the
combinations of increase/decrease in toxicity/activity. As shown, the bulk
18
ytivitca
ni egnahc
ytisned
erocs
ni egnahc
ytisned+10³
104
+10²
103
+10
102
0
101 -10
-10²
100
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
mean toxicity after mean toxicity after
Figure 7: Density scatterplots of the relationship between toxicity and activity (left-hand
side) and score (right-hand side) after the ban, for each user. The score measures the
difference between the total number of upvotes and downvotes received by a user and is a
proxy for the engagement received.
of the distribution lies close to the plot origin, meaning that the ban caused
minor changes in both toxicity and activity. Moreover, those users who ex-
perienced marked changes in toxicity only had negligible changes in activity,
and vice versa. The insets in Figure 6 show the number of users laying in
each quadrant of the scatterplots. The most frequent reaction to the ban
was a reduction in both toxicity and activity (38% users lay in Q3). This
is also evident in the left-most plot of Figure 7, which pictures the relation-
ship between mean toxicity and user activity, after the ban. It shows how
the vast majority of users who exhibit low levels of toxicity are moderately
active. The opposite behavior is instead the least frequent (16% users are in
Q1). Overall this analysis suggests that the resentful users might have had
a limited impact on the platform due to their low activity.
Engagement. Finally, we examine the relationship between changes in
toxicity and obtained engagement. We measure the engagement obtained by
each comment as its Reddit score, computed as the difference between the
upvotes and downvotes to that comment. Positive scores denote a positive
engagement of the community with a comment, while negative scores gener-
ally denote disagreement. The engagement of a user is the mean engagement
obtained by its comments. This joint analysis of toxicity and engagement is
relevant as it allows an understanding of whether post-ban toxic comments
are tolerated, and possibly even encouraged, on Reddit. The right-most plot
of Figure 6 shows the density scatterplot of this relationship while the right-
most plot of Figure 7 shows the distribution of mean toxicity with respect
to the mean engagement score after the ban. Similarly to what occurred for
19
retfa
ytivitca
naem
ytisned
retfa
erocs
naem
ytisned+10³ *** *** *** *** *** *** ** *
within the 15 banned subreddits
rest of Reddit
+10²
+10
0
-10
-10²
[0.0,0.1) [0.1,0.2) [0.2,0.3) [0.3,0.4) [0.4,0.5) [0.5,0.6) [0.6,0.7) [0.7,0.8) [0.8,0.9) [0.9,1.0]
mean toxicity
Figure8: Thedifferenceinscoresbetweentoxiccommentsmadewithinandoutsidethe15
banned subreddits as a function of comment toxicity. The significance of these differences
is determined using the t-test for unpaired data: *: p<0.1; **: p<0.05; ***: p<0.01.
activity in Figure 6 and Figure 7, we found that the vast majority of users
experienced modest changes in toxicity and engagement, and lower values
of engagement scores correspond to lower levels of toxicity. Again, the most
frequent reaction was a simultaneous reduction of both toxicity and obtained
engagement (31% users are in Q3) and the least frequent one was a simulta-
neous increase of both (21% users are in Q1).
Lastly, we analyze the relationship between toxicity and engagement also
beforetheban, byinvestigatingdifferencesbetweentheengagementobtained
within vs outside of the 15 banned subreddits. Figure 8 provides the results
of this comparison, highlighting that toxic comments received significantly
more engagement within the banned subreddits than outside of them (i.e.,
in the rest of Reddit). This result corroborates that of the right-most plot
of Figure 6 in that it reinforces the idea that toxicity is not encouraged on
Reddit, with the exception of a few toxic subreddits.
5. Discussion
Our study provides insights into the consequences of The Great Ban, a
crucial example of deplatforming that affected over 2,000 subreddits. We
highlight that 15.6% of the users involved abandoned the platform, however
those who remained reduced their average toxicity by 4.1%. At the same
time, however, approximately 5% of all users significantly escalated their
20
erocs
naemtoxicity. The presence of these so-called resentful users was observed across
many of the analyzed subreddits. However, only 16% of users increased both
their toxicity and activity levels, and just 21% of users who became more
toxic also received positive feedback from other users. Our findings provide
new insights regarding the impact of The Great Ban and, in general, on
the heterogeneous and unintended negative reactions to moderation inter-
ventions [8]. Additionally, they shed light on several aspects regarding the
designandimplementationofeffectivemoderationstrategies, underliningthe
inherent challenges in moderating online platforms.
Effectiveness of the moderation. In the current literature, the effec-
tivenessofcontentmoderationhastypicallybeenevaluatedbyexaminingthe
changesintheseinterventionsintermsofactivity andtoxicity [15,6]. Inthis
context, our study showed that a significant portion of toxic users left the
platform, while those who remained exhibited a modest decrease in toxicity
along with a notable decline in activity. Apparently, these results suggest
successful moderation. However, it is crucial to carefully examine these find-
ings by considering potential unintended consequences. For instance, the
deplatforming of toxic users may move the issue somewhere else rather than
solve it. As highlighted by recent studies, moderated users might migrate to
other platforms [7], possibly indicating that their toxic interactions may have
been displaced rather than mitigated. Moreover, migrated users may engage
in much more toxic and aggressive behavior in the new platforms [7]. Finally,
user abandonment and reduced activity after the ban could represent a sig-
nificant issue for Reddit, as user engagement and interactions are the main
sources of revenue for online platforms [5, 36]. As a result, the presumed
effectiveness of The Great Ban in reducing toxicity should be interpreted
carefully as it can negatively impact not only the platform’s revenue because
of abandonment or reduced engagement, but also outside Reddit because of
user migration. Future efforts should focus on finding a balance between
developing strategies that effectively reduce toxicity while minimizing user
abandonment or decline in activity [36]. In fact, effective moderation should
foster healthier online communities while safeguarding platform safety and
economic sustainability. Otherwise, platforms may be discouraged from im-
plementing rigorous moderation measures.
Divergent reactions to moderation. Our study showed that, despite
a slight decrease in toxicity, a significant minority of users exhibited substan-
tial increases in their toxic behavior. This finding has significant implications
for evaluating and designing moderation interventions. First, it underscores
21the complexity of user responses to content moderation, an area that is still
vastly underexplored and warrants further investigation [37]. Additionally,
it brings to light the necessity for personalization in the context of content
moderation. A broad intervention like The Great Ban – which impacted
thousands of subreddits and tens of thousands of users – may not adequately
fit the different motivations and personalities of those affected. Here, this
was shown by the minority of resentful users who significantly escalated their
toxic behavior. Understanding the aspects that lead to these divergent re-
sponses is crucial for developing effective moderation interventions. Future
research and on-field applications should focus on user profiling, by taking
into account individual personal traits, past behavior, and contextual fac-
tors to effectively customize moderation interventions [35]. In addition, user
migration combined to a high percentage of users displaying increased toxi-
city raises concerns about the potential radicalization effects of moderation
and its inadvertent role in amplifying echo chambers [7]. This indicates that
some users may not respond positively to specific moderation interventions,
potentially resulting in more radical behaviors. Our findings emphasize the
careful balance needed in content moderation, which not only should locally
reduce toxicity but also should prevent unintended consequences that may
lead to polarization or radicalization within specific user groups.
Impact of resentful users. The finding that the vast majority of re-
sentful users – who exhibited increased toxicity following the ban – did not
concurrently escalate their activity offers a novel perspective on the little-
studied interplay of toxicity and user activity. Contrary to the suspicion that
highlytoxicusersmightalsobehighlyactive, ourresultsunderscorealimited
overlap between these two dimensions of user behavior. This suggests that a
considerable portion of users expressing heightened toxicity post-ban did not
translate their resentment into increased participation on the platform. In
turn, this result partly mitigates the previous concerns about the divergent
and adverse reactions to The Great Ban. Furthermore, the observation that
users who intensified their toxic behaviors did not receive heightened positive
social feedback from their peers resonates with some recent research on the
drivers of online hateful and toxic speech. The latter posits that online toxic-
ity may be driven by the pursuit of social approval rather than by a desire to
harm [20]. To this end, our results demonstrate that the Reddit community
did not endorse or support the increased toxicity exhibited by these users.
According to the aforementioned theories, toxic users who do not receive the
expectedlevelsofsocialapprovalshoulddecreasetheirtoxicityovertime[20].
22However, we measured overall stationary toxicity trends over the course of
the 7 months after the ban. Our results thus apparently challenge the social
approval theory, in support of competing theories according to which at least
a subset of toxic and hateful users seek amusement by harassing others, as in
trolling behavior [22, 38]. On the one hand, these results call for additional
research to identify the types and characteristics of toxic users. On the other
hand, they reinforce the need for nuanced and diversified moderation strate-
gies that are capable of addressing the complexity and multiplicity of online
user behavior [39].
Limitations and Future works. In this study, we make use of a large
dataset consisting of comments posted by 34K Reddit users during 7 months
before and after The Great Ban took place. This means that our findings
may be limited to Reddit and the effects of The Great Ban itself. Moreover,
online platforms are dynamic and characterized by frequent changes in user
behavior, community norms, and platform policies. Our study takes into
account a specific timeframe and while it covers a relatively extended period,
it limits the generalizability of our findings to different periods of time and
somewhat constrains our ability to fully account for long-term or evolving
trends. In addition, our evaluation of the toxicity scores could be biased
because of the use of Detoxify, a machine learning model. The observational
nature of our work constitutes another limitation, as it limits our ability to
consider external events that might have independently influenced user be-
havior outside of The Great Ban. To conclude, data on user demographics,
motivations, and contextual factors is missing from our dataset. Having this
type of information could have offered a more refined interpretation of our
results. Future research could look more into the unexplored connections be-
tweenusercharacteristicsandmoderationoutcomes, servingasaninitialstep
towards the implementation of more targeted and personalized moderation
interventions [35, 36].
Ethical considerations. This research furthers our understanding of
the effects of content moderation by highlighting the complexities of user
responses to moderation efforts. These new insights can contribute to the
development of more robust and targeted interventions for reducing online
toxicity while minimizing unintended side effects. Our study also discusses
the ethical trade-off between the common good and minority harm. Specifi-
cally, the dilemma faced by moderators who must choose whether to enforce
actions that, while benefitting the broader community, may inadvertently
cause harm to a minority of users by increasing their resentment.
236. Conclusions
The Great Ban was a large-scale deplatforming intervention aimed at
shutting down toxic communities on Reddit. To assess its effectiveness, we
analyzed 53M comments made over 14 months by almost 34K users involved
in the ban. Our findings show that 15.6% of the affected users left Reddit
following the ban, while those who remained reduced their toxicity by an
average of 4.1%. Despite this modest reduction in overall toxicity, 5% of
users increased their toxicity by more than 70% compared to their levels
before the ban. The impact of these resentful users was analyzed across the
subreddits. Wefoundthatonly16%ofusersincreasedboththeirtoxicityand
activityandonly21%alsoreceivedpositiveengagementfromthecommunity.
In general, in this study we provide new and more detailed insights into
the effectiveness of The Great Ban, as well as its unintended consequences,
Our findings can be beneficial to online platforms in the development of new
moderation interventions and policies. For example, in future works we could
investigate the relationship between users’ characteristics and the effects of a
moderation intervention. This could lead to the development of targeted or
personalized approaches that can be more effective in limiting the negative
effects of moderation actions, such as the ones found in our study. More-
over, an encouraging direction for future research is the implementation of
predictive models that forecast the effects of moderation interventions. Such
models would be beneficial to content moderation, as they would allow mod-
erators to plan and assess the effectiveness of certain moderation strategies.
Use of AI
The authors used an LLM to proofread the article prior to submission.
Acknowledgments
This work is partially supported by the European Union – Next Genera-
tion EU within the PRIN 2022 framework project PIANO (Personalized Inter-
ventions Against Online Toxicity), and by the Italian Ministry of Education
and Research (MUR) in the framework of the FoReLab project (Departments
of Excellence).
24References
[1] T. Giorgi, L. Cima, T. Fagni, M. Avvenuti, S. Cresci, Human and LLM
Biases in Hate Speech Annotations: A Socio-Demographic Analysis of
Annotators and Targets, arXiv preprint arXiv:2410.07991 (2024).
[2] T. Gillespie, Custodians of the Internet: Platforms, content moderation,
and the hidden decisions that shape social media, Yale University Press,
2018.
[3] A. Trujillo, T. Fagni, S. Cresci, The DSA Transparency
Database: Auditing self-reported moderation actions by social media,
arXiv:2312.10269 (2023).
[4] M. Katsaros, K. Yang, L. Fratamico, Reconsidering tweets: Intervening
during tweet creation decreases offensive content, in: AAAI ICWSM,
2022.
[5] A. Trujillo, S. Cresci, Make Reddit Great Again: Assessing community
effects of moderation interventions on r/The Donald, in: ACM CSCW,
2022, pp. 1–28.
[6] S. Jhaver, C. Boylston, D. Yang, A. Bruckman, Evaluating the effective-
ness of deplatforming as a moderation strategy on Twitter, in: ACM
CSCW, 2021, pp. 1–30.
[7] M. Horta Ribeiro, S. Jhaver, S. Zannettou, J. Blackburn, G. Stringhini,
E. De Cristofaro, R. West, Do platform migrations compromise con-
tent moderation? Evidence from r/The Donald and r/Incels, in: ACM
CSCW, 2021.
[8] A. Trujillo, S. Cresci, One of many: Assessing user-level effects of mod-
eration interventions on r/The Donald, in: ACM WebSci, 2023, pp.
55–64.
[9] N. Dias, G. Pennycook, D. G. Rand, Emphasizing publishers does not
effectively reduce susceptibility to misinformation on social media, HKS
Misinformation Review 1 (2020).
[10] C. A. Bail, L. P. Argyle, T. W. Brown, J. P. Bumpus, H. Chen, M. F.
Hunzaker, J. Lee, M. Mann, F. Merhout, A. Volfovsky, Exposure to
25opposing views on social media can increase political polarization, Pro-
ceedings of the National Academy of Sciences 115 (2018) 9216–9221.
[11] G. Pennycook, A. Bear, E. T. Collins, D. G. Rand, The implied truth
effect: Attaching warnings to a subset of fake news headlines increases
perceived accuracy of headlines without warnings, Management Science
66 (2020).
[12] M. Horta Ribeiro, S. Jhaver, M. Reignier-Tayar, R. West, et al., De-
platforming norm-violating influencers on social media reduces overall
online attention toward them, arXiv:2401.01253 (2024).
[13] M. Seeliger, M. Baum, When Twitter blocked Trump: The paradox,
ambivalence and dialectic of digitalized publics, Philosophy & Social
Criticism (2023).
[14] L. Cima, L. Mannocci, M. Avvenuti, M. Tesconi, S. Cresci, Coordinated
behavior in information operations on Twitter, IEEE Access (2024).
[15] E. Chandrasekharan, U. Pavalanathan, A. Srinivasan, A. Glynn,
J. Eisenstein, E. Gilbert, You can’t stay here: The efficacy of Red-
dit’s 2015 ban examined through hate speech, in: ACM CSCW, 2017,
pp. 1–22.
[16] H. Habib, M. B. Musa, M. F. Zaffar, R. Nithyanand, Are proactive
interventionsforRedditcommunitiesfeasible?, in: AAAIICWSM,2022,
pp. 264–274.
[17] M. Z. Trujillo, S. F. Rosenblatt, G. D. A. Jauregui, E. Moog, B. P. V.
Samson, L. H´ebert-Dufresne, A. M. Roth, When the echo chamber shat-
ters: Examining the use of community-specific language post-subreddit
ban, in: ACL WOAH, 2021.
[18] R. E. Robertson, Uncommon yet consequential online harms, Journal
of Online Trust and Safety 1 (2022).
[19] L. Cima, A. Trujillo, M. Avvenuti, S. Cresci, The Great Ban: Efficacy
and Unintended Consequences of a Massive Deplatforming Operation
on Reddit, in: DHOW Workshop at ACM WebSci, 2024, pp. 85–93.
26[20] J. Jiang, L. Luceri, J. B. Walther, E. Ferrara, Social approval and
network homophily as motivators of online toxicity, arXiv:2310.07779
(2023).
[21] H. M. Saleem, D. Ruths, The aftermath of disbanding an online hateful
community, arXiv:1804.07354 (2018).
[22] E. Chandrasekharan, S. Jhaver, A. Bruckman, E. Gilbert, Quarantined!
examining the effects of a community-wide moderation intervention on
reddit, ACM Transactions on Computer-Human Interaction (TOCHI)
(2022).
[23] A. Mekacher, M. Falkenberg, A. Baronchelli, The systemic impact of
deplatforming on social media, PNAS Nexus 2 (2023).
[24] S. Zannettou, “I Won the Election!”: An empirical analysis of soft
moderation interventions on Twitter, in: AAAI ICWSM, 2021.
[25] Q. Shen, C. P. Ros´e, A tale of two subreddits: Measuring the impacts
of quarantines on political engagement on reddit, in: AAAI ICWSM,
2022, pp. 932–943.
[26] J. Baumgartner, S. Zannettou, B. Keegan, M. Squire, J. Blackburn, The
pushshift Reddit dataset, in: AAAI ICWSM, 2020, pp. 830–839.
[27] A. Bouleimen, N. Pagan, S. Cresci, A. Urman, S. Giordano, Dynamics
of toxic behavior in the Covid-19 vaccination debate, in: CNA’23, 2023.
[28] S. Hurtado, P. Ray, R. Marculescu, Bot detection in Reddit political
discussion, in: ACM SocialSense, 2019, pp. 30–35.
[29] M. Grootendorst, BERTopic: Neural topic modeling with a class-based
TF-IDF procedure, arXiv preprint arXiv:2203.05794 (2022).
[30] J. Devlin, M.-W. Chang, K. Lee, K. Toutanova, BERT: Pre-training
of deep bidirectional transformers for language understanding, in:
NAACL, 2019, pp. 4171–4186.
[31] P. Domingos, A few useful things to know about machine learning,
Communications of the ACM 55 (2012) 78–87.
27[32] A. Zimek, Clustering high-dimensional data, in: Data Clustering, 2018,
pp. 201–230.
[33] M. Gambini, S. Tardelli, M. Tesconi, The anatomy of conspiracy theo-
rists: Unveiling traits using a comprehensive twitter dataset, Computer
Communications 217 (2024) 25–40.
[34] M. Cinelli, G. De Francisci Morales, A. Galeazzi, W. Quattrociocchi,
M. Starnini, The echo chamber effect on social media, Proceedings of
the National Academy of Sciences 118 (2021).
[35] S. Cresci, A. Trujillo, T. Fagni, Personalized interventions for online
moderation, in: ACM HT, 2022, pp. 248–251.
[36] B.Tessa, L.Cima, A.Trujillo, M.Avvenuti, S.Cresci, Beyondtrial-and-
error: Predicting user abandonment after a moderation intervention,
arXiv preprint arXiv:2404.14846 (2024).
[37] S. Jhaver, A. Q. Zhang, Q. Z. Chen, N. Natarajan, R. Wang, A. X.
Zhang, Personalizing content moderation on social media: User per-
spectives on moderation choices, interface design, and labor, in: ACM
CSCW, 2023, pp. 1–33.
[38] M. Mazza, M. Avvenuti, S. Cresci, M. Tesconi, Investigating the dif-
ference between trolls, social bots, and humans on twitter, Computer
Communications 196 (2022) 23–36.
[39] X. Ma, J. He, T. Wu, N. Zhu, Y. Hua, Interaction behavior enhanced
community detection in online social networks, Computer Communica-
tions 219 (2024) 92–103.
28