Summarization of Opinionated Political Documents with Varied
Perspectives
NicholasDeas,KathleenMcKeown
DepartmentofComputerScience,ColumbiaUniversity
Abstract
Mixed-Perspectiv`e Summarization
Globalpartisanhostilityandpolarizationhas
increased,andthispolarizationisheightened Gig Economy in California The Left argues that Uber
aroundpresidentialelections. Modelscapable 1 2 should be required to treat
Uber's business model is still its drivers as employees.
of generating accurate summaries of diverse
premised on underpaying its
perspectivescanhelpreducesuchpolarization drivers...
by exposing users to alternative perspectives.
2 1
Inthiswork,weintroduceanoveldatasetand
AB5 was a bad idea when it
taskforindependentlysummarizingeachpo- passed last year. It's an The Right argues that
Uber should not be
litical perspective in a set of passages from even worse one in our
required to treat its drivers
current economic climate…
opinionated news articles. For this task, we as employees.
proposeaframeworkforevaluatingdifferentdi-
mensionsofperspectivesummaryperformance.
Figure 1: Example of the Mixed-Perspective Setting
Webenchmark10modelsofvaryingsizesand
of POLISUM. Givenasetofopinionatedpassagesre-
architectures through both automatic and hu-
flectingamixofviews,POLISUMrequiresmodelsto
manevaluation. WhilerecentmodelslikeGPT-
generatebothasummaryoftheleftandright-leaning
4o perform well on this task, we find that all
politicalperspectives.
modelsstruggletogeneratesummariesfaithful
to the intended perspective. Our analysis of
summariesfocusesonhowextractionbehavior
Largelanguagemodels’(LLMs)abilitytosum-
dependsonthefeaturesoftheinputdocuments.
marizeopinionsandnewshasrecentlynearedhu-
1 Introduction man performance (Zhang et al., 2023a; Bhaskar
etal.,2023). Recentwork,however,hasalsoshown
People who hold political ideologies tend to de-
thatLLMscanunfairlyrepresentdiverseopinions
velopmisperceptionsofgroupswithopposingpo-
in review and tweet summarization (Zhang et al.,
litical opinions (Chambers et al., 2006), and po-
2023b;Huangetal.,2023;Tay,2019).
litical events, such as the 2024 US presidential
Toevaluatecurrentmodels’capabilitiesinsum-
election,Frenchlegislativeelection,ortheBrexit
marizingdifferentperspectives,weproposeanovel
referendum, reinforce negative attitudes (Hanna
dataset and task, POLISUM4. Our task involves
etal.,2013;Wellingsetal.,2024). Thesemisper-
generatingindependentabstractivesummariesof
ceptions,reinforcedbynewsconsumptiononsocial
both left and right-leaning political perspectives
media(Levy,2021),contributetoincreasedpolar-
given collections of opinionated news passages
ization and instability (Braley et al., 2023; Lees
withmixedperspectives. POLISUM thusrequires
andCikara,2021). Exposuretoalternativeperspec-
systemstobothdistinguishtheopinionsreflected
tives, however, has been shown to help alleviate
in input texts as well as produce a pair of sum-
polarization (Balietti et al., 2021). To encourage
mariesrepresentingthosedifferingopinions. We
suchexposure,somegroupsfocusonaggregating
summarizeourprimarycontributionsasfollows:
(e.g.,AllSides1)orsummarizingdifferentpolitical
1. We introduce a novel benchmark dataset,
perspectivesondivisiveissues(e.g.,TheFlipSide
2,GroundNews3). POLISUM, for independently summarizing
politicalperspectivesoncontroversialissues,
1https://www.allsides.com/
2https://www.TheFlipSide.io/ 4Wemakeourdatasetavailabletoresearcherswhohave
3https://ground.news/ beengrantedpermissionbyTheFlipSide.
1
4202
voN
6
]LC.sc[
1v39040.1142:viXraprovidedpassagesfromnewsandop-eds. timesmorelabeledexamplesandfocusesonpoliti-
2. We introduce an initial framework for eval- calperspectivesratherthanreviews. Additionally,
uating different components of perspective comparedtoXSum, POLISUMissimilarinlength
summaries,includingbothhumanevaluation butslightlymoreabstractive,measuredbyn-gram
andautomaticmetrics. overlapbetweensourceandreference. Onaverage,
3. Wepresentanddiscussbenchmarkevaluation thereare9.6sourcepassagesforeachpublication
results,findingthatmodelsstrugglewithfaith- (4.8perperspective),withacombinedlengthcom-
fulness to the intended perspective and that parabletoanewsarticle(∼1,300tokens).
improvingautomaticevaluationmetricsisan POLISUMTask. Usingthisdataset,theaimof
importantareaforfuturework. the POLISUM task is to generate a pair of sum-
4. We analyze model extraction behavior (e.g., maries (i.e., Summaries in Table 2) representing
which documents models extract from and the left and right political perspectives on a con-
howmuch)andfindthatgeneratedsummaries troversialtopic(i.e. Headline). Asinput,models
sufferfrombiasesduetoinputdocumentpo- areprovidedwithtwosetsofopinionatededitorial
sition,documentlength,anduseofarousing passages (i.e., Source Passages), each represent-
terms. ing one of the political perspectives. Thus, the
datasetenablesamulti-document,multi-summary
2 POLISUM Dataset
task. Aswithtraditionalnewssummarizationtasks,
thesummaryforeachperspectiveshouldcondense
Data Source. To enable evaluating political per-
the information present in the passages. At the
spective summaries, we collect opinionated texts
andpairedsummariesfromTheFlipSide5. Since sametime,thegeneratedleftandright-perspective
summariesshouldaccuratelyrepresenttheperspec-
September2017,TheFlipSidehascoveredpoliti-
tivesreflectedintheirrespectivepassages.
callycontroversialissues(i.e. overturningofRoev.
Wade,presidentialelections)intheUnitedStates.
3 Experiments
Toward bridging political divides, each publica-
tionincludesaheadlinedetailingtheissue,curated
Traditional opinion summarization typically in-
passagesauthoredbypoliticalcommentatorswith
volvessummarizingacommonperspectiveamong
varyingperspectives,andapairofshortsummaries
all inputs, which we refer to as the Single-
oftheleftandrightperspectives6. Wecollectthis
Perspectivesetting7. Weinsteadintroducethead-
informationfromTheFlipSide,gatheringnearly
ditionalchallengeofidentifyinginputdocuments
1,000 samples. An excerpted example of source
relevant to the intended perspective, referred to
passagesandsummariesisshowninTable2.
astheMixed-Perspectivesetting(illustratedinFig-
Table 1 presents summary statistics of the col-
ure1). Inthissetting,approachesareprovidedwith
lected multi-document, multi-summary dataset
amixedsetofleftandright-leaningtextsasinput
(datastatementincludedinAppendixC). Wealso
andaretaskedwithproducingindependentleftand
showstatisticsfor COCOTRIP(Isoetal.2022;the
right-perspectivesummariesfromthesameinput.
mostcomparablemulti-document,multi-summary
On average, sets of inputs contain ∼10 passages
dataset), XSUM (Narayan et al. 2018; a single-
total,∼5passagesforeachperspective.
document,single-summarycorpuswithsimilarly
Modelinputsareconstructedbyconcatenating
short references), and Multi-News (Fabbri et al.
all passages, ensuring that the left and right per-
2019,amulti-document,single-summarynewscor-
spectivesalternatewhenpossible. Duetoposition
pus). TheaimofCOCOTRIPistogeneratemultiple
biases in summarization (Chhabra et al., 2024),
hotel review summaries for a pair of comparable
the perspective reflected in the first input docu-
hotels: two summaries highlighting each hotel’s
mentmayspuriouslyimpacttheresultingsummary
unique attributes, and one highlighting similari-
quality. To mitigate these effects, we report av-
ties. In contrast, POLISUM contains almost 20
erageperformancebetweentwovariationsofthe
5WethankTheFlipSideforgenerouslyallowingustouse input data. First, models are evaluated on inputs
theirarchiveforthiswork:https://www.TheFlipSide.io/
beginningwithaleft-perspectivepassagefollowed
archives
6Somepublicationslackindividualperspectivesummaries, by alternating perspectives (e.g., left, right, left,
primarily on topics where both parties largely agree or for
meta-articlesthatdonotcoverpoliticaltopics.Thesesamples 7ExperimentaldetailsandresultsoftheSingle-Perspective
arenotincludedinthedataset. taskonPOLISUMareincludedinAppendixE
2Gold %Noveln-grams
Dataset Domain Multi-document Multi-summary #Gold
Length 1 2 3
XSUM News (cid:37) (cid:37) 11,334 23.3 35.8 83.5 95.5
Multi-News News (cid:33) (cid:37) 5,622 263.7 17.8 57.1 75.7
COCOTRIP Reviews (cid:33) (cid:33) 48·3 132.9 22.8 72.4 91.4
POLISUM Op-Eds (cid:33) (cid:33) 907·2 19.2 40.4 86.8 97.5
Table 1: Summary statistics for POLISUM and existing summarization datasets, including data size, reference
length,andpercentageofnoveln-gramsinthesummarycomparedtosourcedocuments. #Goldformulti-summary
datasetsispresentedas#Samples·#References/Sample. CoCoTripstatisticssourcedfromIsoetal.(2022).
Headline HollywoodStrike encourage BART to generate distinct summaries
Perspective Left Right
...Byreplacingtheonce matching the references’ format, the BART de-
...Thisisahugeissue,but
majoritystraightwhite
there’sanotherone— coderisforcedtobegingenerationswith"Theleft"
castwitharidiculously
AI...AlotoftheTV
Source episodesandmovies disproportionate or "The right" respectively. T5 and Flan-T5 are
Passages percentageofminorities,
producedbyHollywood
industryplayersalienated promptedtogeneratesummariesofindividualper-
are,bynature,highly
acommensurateportion
formulaic... oftheaudience... spectives. See Appendix A for other generation
Theleftsupportsthe Therightarguesthat hyperparameterdetails.
strikers,arguingthatAI
Hollywood’stroubles
Summaries willsoonbeathreatto stemfromitsembraceof LLM Baselines. We evaluate 10 LLMs of
workersinmany
leftistpolitics.
industries. varying sizes and architectures to establish base-
linesforcurrentstate-of-the-artmodels8. Mistral-
Table2: Exampleofpartialinputpassagesandpaired
7B(mistralai/Mistral-7B-Instruct-v0.1;Jiangetal.
perspectivesummariesinPOLISUM.
2023), Llama-3-8B and 70B (meta-llama/Meta-
Llama-3-8B-Instructandmeta-llama/Meta-Llama-
etc.), and then on inputs beginning with a right- 3-70B-Instruct; Dubey et al. 2024), Vicuna-7B
perspective passage followed by alternating per- and13B(lmsys/vicuna-7b-v1.5andlmsys/vicuna-
spectives (e.g., right, left, right, etc.). The order 13b-v1.5; Chiang et al. 2023), Mixtral-8x22B
of individual passages that share a perspective is (mistralai/Mixtral-8x22B-Instruct-v0.1;Jiangetal.
randomized. Becausethereferencesummariesare 2024), and GPT-4o (gpt-4o-2024-05-13)9. See
limitedtoasinglesentence,allmodelgenerations
AppendixBforadditionalgenerationhyperparam-
aretruncatedtothefirstsentencebeforeevaluation.
eters,prompts,andreproducibilitydetails.
3.1 Baselines
3.2 Metrics
Avarietyofzero-shotsummarizationbaselinesand
instruction-tunedLLMsareconsidered.
Coverage. Summarycoverageisfirstmeasured
ExtractiveUpperBound. Torepresentpossible
with ROUGE-1and ROUGE-Lbetweenthegener-
extractiveapproaches,wecalculateanupperbound
ated perspective summaries and their references
performance based on similarity to the reference
(Lin, 2004a). To account for the weaknesses of
summaries. Weconsiderallsentencescontainedin
ROUGE, we also employ BERTSCORE (Zhang*
thesourcepassagestobepotentialextractivesum-
et al., 2020) and BLEURT (Sellam et al., 2020)
maries. Wethenselectthesentencewiththehigh-
using the deberta-large-xnli and BLEURT-20-D6
estBERTSCORErelativetothereferencesummary
checkpointsrespectivelyduetohighercorrelations
andcalculatetheremainingperformancemetrics. withhumanjudgmentscomparedtoalternatives10.
Zero-Shot Baselines. As zero-shot summa-
Foreachmetric,wealsouseatwo-samplet-testto
rization baselines, we evaluate the large variants
determinewhetherleftandright-perspectivecover-
of BART (Lewis et al., 2019), T5 (Raffel et al., agescoressignificantlydiffer(p ≤ 0.05).
2019), and Flan-T5 (Chung et al., 2022). As
BARTisnotpretrainedonanysummarizationtask,
8Weuseinstruction-tunedvariantsofallapplicableLLMs,
we use BART finetuned on the CNN/DailyMail
butforsimplicity,omit"Instruct"innamesthroughoutresults.
(CNN/DM; Hermann et al. 2015; Nallapati et al. 9https://openai.com/index/hello-gpt-4o/
2016)dataset. IncontrasttoPOLISUM,CNN/DM 10See human correlations for BERTSCORE linked
in https://github.com/Tiiiger/bert_score and for
andotherpriorsummarizationdatasetslacksum-
BLEURT in https://github.com/google-research/
mariesforindividualperspectives. So,inorderto Bleurt/blob/master/checkpoints.md
3Faithfulness. Wemeasurehowwellthegener- givensummaryaccuratelycaptureseachdimension
ated summaries are consistent and faithful to the asreflectedintheinputs. Intotal, eachof40left
inputs. Because faithfulness metrics for our spe- and40right-leaningsummariesrandomlysampled
cifictaskdonotexist,werelyonexistingfactual- fromthedatasetarejudgedby2annotators.
ity metrics as approximations: SUMMAC (Laban Additionally,weintroduceinitialmetricstoau-
etal.,2022)andALIGNSCORE(Zhaetal.,2023). tomate selected dimensions. To measure Stance,
SUMMAC is a NLI-based metric that measures we employ JointCL, a zero-shot stance classifier
consistency between summaries and source doc- (Liangetal.,2022;AllawayandMcKeown,2023).
uments. Alternatively,ALIGNSCOREusesinforma- Usingtheheadlinesastheobject,wecalculatethe
tionalignmenttomeasurefactualconsistency. All RootMeanSquaredError(RMSE)betweenpredic-
metricsproduceascorebetween0and100where tionsonthegeneratedsummariesandreferences.
highervaluesreflectmoreconsistentandfaithful To capture Object, we use a T5-based keyphrase
summaries. generation model (Li et al., 2023) as a zero-shot
Consensus Stance & Intensity Object stanceobjectclassifier,andcalculateBERTScore
betweenpredictionsongeneratedsummariesand
The right generally praises McConnell,
inputpassages. Finally,similarto(Leeetal.,2022),
arguing that he effectively advanced
conservative priorities. we measure Intensity by calculating the average
arousalscoreofpolarizingtermsaccordingtothe
Reasoning
Figure2:Exampleperspectivesummarywithindicators VADlexicon(Mohammad,2018). Intensityscores
ofdifferentperspectivedimensionshighlighted: Con- areagaincalculatedastheRMSEbetweenarousal
sensus,StanceandIntensity,Object,andReasoning scoresforgeneratedsummariesandinputpassages.
Duetotheircomplexity,weleaveautomatedevalu-
Perspective. Tomeasurehowwellthegenerated ationsofConsensusandReasoningtofuturework.
summariesreflecttheintendedperspective,weop- SeeAppendixFandAppendixDforfurtherdetails
erationalize dimensions of how perspectives are onhumanandautomaticmetricsrespectively.
capturedinsummaries. Stancerepresentswhether
thesummaryaccuratelyportraystheintendedper- 4 Results
spective’s overall attitude toward the object (e.g.,
4.1 SummarizationEvaluation
fororagainst),whileObjectrepresentswhetherthe
summaryidentifiesthesalientstanceobjectamong Table 3 presents coverage and faithfulness met-
inputdocuments. Thesedimensionscorrespondto rics for all models in the mixed-perspective set-
theattitudeandstanceobjectofthestancetriangle ting. All models outperform the extractive base-
theoryrespectively(DuBois,2007). Becauseour lineincoverage,emphasizingthatabstractiveap-
taskrequiresexpressingperspectivesinnaturallan- proachesarevitaltoperformingwellonthistask.
guage as opposed to prior stance detection work, Amongabstractiveapproaches,Llama-3(8B)tends
we include two additional dimensions: Intensity toperformbestonROUGEwhileGPT-4otendsto
reflectswhethertheextenttowhichaperspective perform best on BLEURT and BERTScore. Inter-
is held or the strength of the belief is accurately estingly, while the larger, 13B-parameter Vicuna
capturedbyaperspectivesummary(e.g.,"praises" modelperformsbetterthanits7B-parametervari-
ratherthan"supports"toreflectastrongerbelief); ant,thesameisnottrueforLlama-3. Thissuggests
andReasoningreferstowhethertheelaborationin thatlargermodelsdonotalwaysguaranteebetter
a perspective summary is supported by the input mixed-perspectivesummarizationperformance.
documents. Finally,ourtaskrequiressummarizing Trendsinfaithfulnessmetricsdifferfromthatof
multiple opinions toward a single object, which thecoveragemetrics. Vicunamodelsachievethe
maydisagree. Therefore,weincludeafinaldimen- best performance on SUMMAC for both perspec-
sion to measure whether perspective summaries tivesandAlignScorefortheright-leaningperspec-
appropriatelyexpresstheextenttowhichinputdoc- tive,whereasLlama-3(70B)isbestonAlignScore
umentsagreeordisagree,calledConsensus. fortheleftperspective. Overall,however,allmod-
Weconductahumanevaluationofthereference elsscorefarloweronfaithfulnessmetricsthanthe
textsandsummariesgeneratedbyMistral,Mixtral, extractivebaseline,suggestingimprovementsand
and GPT-4o to capture these dimensions. We re- evaluationoffaithfulnessonthistaskareimportant
cruit6politicalsciencestudentstoratehowwella issuestoaddressinfuturework.
4Left Right
Model
R1 RL BLEURT BERT SUMMAC Align R1 RL BLEURT BERT SUMMAC Align
Extractive 13.14 10.25 22.50 55.37 88.85 97.25 13.21 10.34 22.67 55.01 89.23 97.01
BARTCNN/DM 25.3 22.7 30.5 61.6 24.8 21.0 24.7 22.3 28.9 60.0 25.7 28.9
T5 24.7 22.6 30.9 60.8 23.3 12.0 25.7 23.6 31.2 61.0 24.0 14.7
Flan-T5 24.1 21.2 29.6 58.9 26.2 35.8 24.9 21.8 29.3 58.8 26.9 37.8
Mistral 25.7 21.4 34.5 60.4 25.5 30.1 25.6 21.3 33.2 59.3 26.5 40.5
Mixtral 25.6 21.3 37.2 60.9 24.9 36.9 25.7 21.3 36.3 60.5 25.2 51.7
Vicuna(7B) 24.9 21.6 33.3 59.6 27.9 30.7 25.3 21.8 32.7 58.2 29.4 39.2
Vicuna(13B) 26.4 23.0 37.2 61.4 26.4 37.2 25.3 22.0 35.8 60.3 26.3 54.0
Llama-3(8B) 28.0 23.9 38.1 60.4 25.8 35.2 27.7 23.5 37.3 59.1 26.9 44.8
Llama-3(70B) 23.1 19.0 36.5 59.6 24.0 41.7 23.9 19.6 35.6 59.3 24.4 51.5
GPT-4o 26.1 21.8 41.8 62.3 24.5 41.0 26.5 21.8 40.9 61.6 24.7 51.8
Table3: AveragecoverageandfaithfulnessscoresfortheMixed-Perspectivesetting. Bestperformanceoneach
metricisboldedandsecondbestunderlined. Foreachmodelandmetric,significantlyhigherleftthanrightscores
arehighlightedin blue,andsignificantlyhigherrightthanleftscoresarehighlightedin red. Higherscoresreflect
betterperformanceforallmetrics.
Model Left Right Table4,andhumanperspectivejudgmentsofMis-
S↓ O↑ I↓ S↓ O↑ I↓
BARTCNN/DM 31.0 74.9 15.1 32.6 74.6 14.4 tral, Mixtral, GPT-4o, and reference summaries
T5 31.1 75.6 17.8 33.7 73.3 18.7
are included in Table 5 (breakdown of judgment
Flan-T5 31.0 77.2 7.9 32.1 73.5 8.0
Mistral 28.8 76.4 8.4 30.7 75.6 6.2 scoresandcorrelationsareincludedinAppendixF).
Mixtral 28.2 76.8 10.3 29.4 77.0 5.9
Vicuna(7B) 29.2 76.2 9.0 30.9 75.7 6.6 GPT-4osummariestendtoscorehighestonboth
Vicuna(13B) 29.7 76.7 8.5 31.3 74.9 7.1
Llama-3(8B) 28.9 76.7 8.7 28.9 76.0 6.3 automaticandhumanscores,evenexceedingref-
Llama-3(70B) 28.8 76.1 5.8 30.8 75.2 5.3 erencesummaryjudgments. Whilethereferences
GPT-4o 27.5 77.1 6.8 28.3 77.3 5.3
HumanCorr. 0.05 0.01 0.09 -0.10 -0.10 -0.02 are similar in extractiveness to GPT-4o, the sum-
mariesaredrasticallyshorter,perhapsmakingthe
Table4: Perspectivescoresforallmodelsandaverage
references harder to judge. Compared to human
sample-level Kendall’s Tau correlation between auto-
judgments, theautomaticmetricsforStance, Ob-
maticmetricsandhumanjudgments(bottomrow). Best
performanceoneachmetricisboldedandsecondbest ject, and Intensity largely rank the three models
underlined. S:Stance,O:Object,I:Intensity. in the same order, although there is little sample-
levelcorrelationwithhumanjudgments. Whilethe
metricsmaycapturesystem-leveldifferences(i.e.,
Inexaminingdifferencesbetweenperspectives,
between GPT-4o and Mistral), they often fail to
BLEURT and BERTSCORE are significantly
distinguishindividualsummariesofsimilarquality
higherforleft-leaningsummariesacrossmostmod-
(i.e., summaries by the same model). Improving
els, while SUMMAC and AlignScore are signif-
metricsformeasuringsimilaritybetweenperspec-
icantly higher for most right-leaning summaries.
tivedimensionsandexploringalternativemethods
Notably,allfourmetricsaremodel-based. These
formeasuringperspectivedimensionsarevitalar-
differencessuggestthatinadditiontopoliticalbi-
easforfuturework.
asesstudiedinpriorwork(e.g.,Fengetal.2023),
model-basedmetricsmayalsosufferfrombiases. 5 WhatDrivesModelPerformance?
4.2 PerspectiveEvaluation Inthissection,wenowturntoinvestigatingwhat
factorsmaybedrivingperformanceorpresentob-
Avg. Avg. stacles to highquality summaries. We firstquali-
Model S O I C R
Len Ext tativelyanalyzeexamplesummaries,andthenan-
Ref. 2.9 3.2 2.9 2.9 1.8 17.7 0.68
alyzetherelationshipbetweeninputfeaturesand
Mistral 2.4 3.2 2.5 2.5 1.9 41.6 0.84
Mixtral 3.0 3.4 3.0 3.0 2.6 39.9 0.72 models’ extraction behavior. In analyzing model
GPT-4o 3.2 3.5 3.2 3.2 2.9 33.7 0.66 extraction behavior, we specifically measure the
extent to which models extract from each input
Table5: Averagehumanjudgmentsofeachperspective
document,andwhatqualitiesofinputdocuments
dimensionwithaveragelengthandextractioncoverage
areassociatedwithhigherratesofextraction.
overallinputs. Bestscoresarebolded. Higherscores
reflectbetterperformanceforallmetrics. S:Stance,O:
5.1 QualitativeSummaryEvaluation
Object,I:Intensity,C:Consensus,R:Reasoning.
Examples summaries generated by Mistral, Mix-
Automatic perspective metrics are included in tral, and GPT-4o are shown in Table 6. In these
52020CensusBattle AmyConeyBarretConfirmed
Model Summary Model Summary
TheleftarguesthatthenewevidencemakescleartheGOP’strue Reference TherightapplaudsBarrett’sconfirmation.
Reference motives,andcondemnsthecitizenshipquestionasunderminingthe Theright:Republicansdidnotbreakany
purposeofthecensus. Mistral normsinconfirmingAmyConeyBarrettto
TheleftarguesthattheTrumpadministration’seffortstoincludea theSupremeCourt.
citizenshipquestiononthe2020censusareapartisanpowergrab Theright-leaningpoliticalperspectivewithin
Mistral
thatunderminestheaccuracyandfairnessofthecensus,andthat thesetextsemphasizesthatRepublicanshave
therealgoalistorigaconstitutionalmandate. notbrokenanynormsorrulesinconfirming
Mixtral
TheleftperceivestheTrumpadministration’sattempttoincludea theirnomineestotheSupremeCourt,andthat
citizenshipquestiononthe2020censusasapartisanpowergrab theonlyruleishavingthepowertoactuatea
Mixtral aimedatbenefitingRepublicansandnon-HispanicWhites, party’spoliticalwill.
potentiallyleadingtoanundercountofmillionsofpeopleandan TherightarguesthatRepublicanshave
unfairredistrictingcycle. adheredtohistoricalnormsandconstitutional
TheleftviewstheTrumpadministration’spushtoincludea principlesintheirjudicialnominations,
GPT-4o
citizenshipquestiononthe2020censusasapartisanmaneuver emphasizingjudicialrestraintandoriginalism,
GPT-4o
aimedatdisenfranchisingminorityvotersandskewingpolitical whileDemocratshaveengagedinpoliticizing
powerinfavorofRepublicansandnon-HispanicWhites. theprocessandunderminingthesenorms.
(a)Modelsoftenextractdifferentinformationfromindividualsources (b)Modelstendtoextractfromthesamefewinput
ratherthansynthesizingtheinputsintoasingleperspectivesummary. documents.
Table6: ExampleperspectivesummarygenerationsforMistral,Mixtral,andGPT-4o. Distinctcolorssignifynear
paraphrasesorexactquotesfromaparticulardocumentidentifiedmanuallybytheauthors.
examples, models appear to attend to the correct political slant. Figure 3 presents the extraction
perspective within input documents, suggesting coveragescoresforeachcombinationofsummary
thatmodelsmayhavesufficientknowledgeofleft and source document perspective (e.g., left/right
and right-leaning political beliefs and rhetoric to perspectivesummaryandleft/right-leaningsource
distinguishinputsinsomecases. Insummarizing documents). For both perspectives, performant
theperspectives,however,modelstendtorelyon modelstendtoextractfromsourcedocumentspor-
specific information only present in some of the trayingtheintendedperspective(bluebarsinthe
inputdocumentswithlittleabstractivesynthesisof "LeftSummaries"plot,andredbarsin"RightSum-
the information (Table 6a). Additionally, models maries")significantlymoreoftenthanthealterna-
consistently extract or paraphrase from the same tiveperspective. T5,Flan-T5,andMistral-Instruct,
documents across many examples, such as in Ta- however, present insignificant differences in ex-
ble6b. Suchconsistencysuggeststhatqualitiesof tractioncoverageforbothperspectives. Uniquely,
theinputdocumentsthemselvesmaydrivemodels’ BARTconsistentlyextractssignificantlymorefrom
tendency to extract from them, which we investi- right-leaningdocumentsthanleft-leaning,regard-
gateinsubsection5.2. less of the intended perspective. Therefore, the
largestandbestperformingmodels(e.g.,GPT-
5.2 ExtractionAnalyses 4o,Llama-3-70B,etc.) appeartobesufficiently
Tofurtherunderstandmodelperformanceonthis capableofdistinguishingperspectivesininputs.
task,weanalyzeextractionbehaviorwithrespect Position and lead biases in summarization sys-
todifferentqualitiesoftheinputdocuments: per- tems are well-documented phenomena (Chhabra
spective, position in the input, length, and use of etal.,2024;OlabisiandAgrawal,2024;Jungetal.,
arousal terms. We use extractive fragment cover- 2019). Following these works, Figure 4 presents
agetoquantifythisbehavior,asdefinedbyGrusky theextractioncoveragescoresacrossdocumentpo-
etal.(2018). Intheseanalyses,wehypothesizethat sitionsforeachmodel. Asinpriorworks,wefind
modelswithhighperformancetendtoextractmore a near monotonically decreasing relationship be-
fromtheintendedperspective. Weevaluatethree tweenextractionfromadocumentanditsposition
additionalhypothesesillustratingpotentiallyunde- intheinput,withallmodeldrawingsignificantly
sirablebehaviors: modelsextractmoreinformation more terms from the first document compared to
fromdocumentsthat(1)appearearlierintheinput thosethatfollow. Amongmodels,Llama-3(70B)
(positionbias),(2)arelonger(lengthbias),and(3) andGPT-4oappeartobemostrobusttopositionbi-
thatcontainmorearousinglanguage(arousalbias). ases,indicatedbytheflattercurves,butstillexhibit
AstheMixed-Perspectivesettingrequiresmod- morebiasthanhuman-writtenreferences. Surpris-
els to disentangle perspective among input docu- ingly, however, Mistral appears to be most sus-
ments, we first analyze whether models tend to ceptible to position biases and scores higher on
extract from source documents with the correct extraction coverage than the smaller BART, T5,
6Figure3: Averageextractioncoverageofleftandright-leaningsourcedocumentsforeachmodelshownseparately
forleftandright-leaningsummaries. Onlythetop4sourcedocuments,2foreachperspective,areconsidered. Error
barsreflect95%confidenceintervals.
and Flan-T5 models. Overall, all models suffer perspectiveoutliers,thatis,documentsthatpresent
frompositionbiasesandstruggletoincorporate a perspective that diverges further from the other
documentsthatappearlaterininputs. documentsintheinput. Aswithotheranalyses,the
Inadditiontopositionbiases,weexaminehow largestmodelsappeartobemostrobusttothistrend
extractioncoveragevarieswithlengthoftheinput thoughstillpresentasimilarbehavior. Therefore,
documentsinFigure4. Aslongerdocumentsare contrarytoourinitialhypothesis,weconcludethat
morelikelytocontaincommonterms,inthisset- modelstendtoavoidextractingfromdocuments
ting,wemodifytheextractioncoveragemetricto thatuseextremelymanyorfewarousingterms.
onlyconsidertermsuniquetoanindividualinput
document. In doing so, we more precisely mea- 6 RelatedWork
suretowhatextentmodelsextractfromaparticular
Opinions and Summarization. Mining and
document in relation to document length. In this
summarizingopinionshavelongbeenaninterestto
case, we see a slight positive trend in extraction
theNLPcommunity. Approachestoopinionsum-
of unique terms with document length percentile
marization,typicallyamulti-documenttask,have
amongmodelscomparedtothehuman-writtenref-
includedtwo-stageextraction-abstractionmodels
erences11. We find that models tend to extract
(Suharaetal.,2020;AmplayoandLapata,2019),
from longer documents, but the impact appears
pointer-generatornetworks(Brazinskasetal.,2019;
lesspronouncedthanwithdocumentposition.
Jayakumar and Malaisamy, 2021), and deep con-
Finally,weconsiderhowthelanguageofdocu-
trollable language models (Elsahar et al., 2021).
mentsmayinfluencemodels’contentselection. In
Summarization in other domains, such as news
particular,weconsiderhowthedensityofhighly
summarization,canalsobeinherentlyopinionated.
arousing terms in an input document may lead it
In these cases, prior work has shown that LLMs
tobemorelikelytohaveinformationthatwillap-
canfailtofairlyrepresentthediversityofperspec-
pearinamodel’ssummary,showninFigure5. In
tives among inputs (Zhang et al., 2023b; Huang
contrasttothepositionandlengthanalyses,there-
etal.,2023)oraccountforbiaseswithininputtexts
lationshipbetweenextractioncoverageandarousal
(Tay,2019). Furthermore,recentworkhasfound
of an input document is not monotonic. Instead,
that such behaviors are realized differently when
all models appear to extract less from both non-
multiple dialects are represented (Olabisi et al.,
arousing and highly arousing documents, and to
2022;OlabisiandAgrawal,2024). Incontrastto
a lesser extent, reference summaries exhibit this
theseworks,wefocusonamulti-document,multi-
behavioraswell. Thismaybebecausemodelsand
summarytaskwiththeaimofsummarizingpoliti-
humansstruggletoincorporateunderrepresented
calperspectivesindependently.
11ForallmodelsexcludingFlan-T5,theextractioncoverage
PoliticalIdeologiesandLMs. Recentworkhas
ofthetoppercentileofdocumentlengthsissignificantlylarger
(p≤0.05)thanthatofthebottompercentile increasingly investigated the political biases and
7Figure 4: Average extraction coverage of source documents by position in the input (left) and length of input
document(right)foreachmodel. Forinputdocumentlength,percentilesbucketsareshownratherthanrawvalues.
Extractioncoverageforlengthbiasanalysisonlyconsiderstermsthatappearinasingleinputdocument. Smaller
numbersreflectearlierinputpositions. Shadedregionsreflect95%confidenceintervalsateachdocumentposition.
proaches (Kim and Zhai, 2009), selecting a pair
ofinputsconditionedoneachothertobethemost
contrastiveandrepresentative. Morerecently,work
hasovercomeextractiveapproachlimitationsand
developed abstractive systems (Iso et al., 2022).
These and other abstractive approaches typically
relyonknowledgeoftheperspectivesrepresented
Figure5: Averageextractioncoverageofsourcedocu- by each input. While in our work, we similarly
mentsforeachmodelbydensityofarousingtermsin generate independent summary pairs, we instead
thesourcedocumentaspercentiles.
evaluatehowwellLLMs’cansummarizewithout
priorknowledgeofinputperspectives.
leanings of language models. Santurkar et al.
(2023) identify ideologies that language models
7 Conclusion
best align with, while others such as Feng et al.
(2023)evaluatetheimpactofpartisanpretraining
Inthiswork,weintroduceadataset,POLISUM,for
dataondownstreamstreamtaskperformance. Par-
generatingasummaryoftheleft-perspectiveand
ticularlyinsummarization,evaluatedmodelshave
asummaryoftheright-perspectivegivenasetof
beenfoundtoholdname-nationalitybiases(Lad-
politicallyopinionatedtexts. Forthistask,wealso
haketal.,2023),journalisticframingbiases(Lee
introduceaframeworkforevaluatingperspective
et al., 2022), geopolitical biases (Li et al., 2024),
summariesthroughbothhumanevaluationandau-
as well as biases related to perspectives in input
tomaticmetrics. Webenchmarkcurrentmodelsof
documents (Rajan et al., 2023). While our work
varyingsizesandarchitecturesonthistask,analyz-
similarlyfocusesonapoliticalsummarizationtask,
ingwhatbehaviorsdriveperformancethroughtheir
our work uniquely evaluates models’ abilities to
tendencytoextractfromparticulardocuments.
summarizeindividualpoliticalperspectivesrather
Models that are capable of accurately and
thanasinglebias-freeorcompositesummary.
faithfullysummarizingmultipleperspectivescan
Contrastive,Comparative,andNeutralSumma- helpalleviatepolarizationandmisunderstandings
rization. Tocombattheaforementionedbiases throughexposingotherstoalternativeperspectives
insummarization,somehaveworkedtowardgener- than those they hold. While we find that larger
atingneutralsummariesfreeofjournalisticframing andmorerecentmodelslikeGPT-4ocanperform
bias(Liuetal.,2021;Bangetal.,2023),aswellas well on this task, we also identify problems with
aligningthestanceoftheinputdocumentsandgen- faithfulnesscommonamongallmodelsevaluated.
eratedsummaries(Liuetal.,2024). Ratherthanim- Additionally,biasesduetodocumentposition,doc-
provingthebiasesofasinglesummary,aseparate umentlength,anduseofarousingtermsmayhinder
line of inquiry has aimed to generate contrasting performance. We recommend future work focus
summaries. Contrastive Opinion Summarization onmitigatingtheseissueswhilealsoprogressing
(COS)wasoriginallydominatedbyextractiveap- towardgeneralizationtoarbitraryperspectives.
88 Limitations evate certain perspectives over others can further
contributetotheseimpacts. Weacknowledgethat
We adopt existing coverage and faithfulness met-
the collected data could be misused in order to
ricsfortraditionalsummarizationtaskaspartofour
intentionally induce these behaviors in language
automaticevaluationofsummaries. Thesemetrics,
modelstowardaparticularpoliticalperspective. In
however,maynotbeequallyappropriatetothepro-
thiswork,weavoidconductingexperimentsinvolv-
posedperspectivesummarizationsetting. Through
ingfinetuningmodelsandstrictlyusethecollected
additionalautomaticandhumanevaluation,weaim
data to evaluate summaries in order to highlight
tocaptureaspectsofperformancespecifictosum-
such weaknesses in existing models. All data in
marizingperspectivestocomplementtheseresults.
this work is used with permission from The Flip
Weencouragefutureworktoinvestigatetheexist-
Sideandhumanevaluationsincludedinthiswork
ingcoverageandfaithfulnessmetricsonthistask,
areconductedunderanapprovedIRBprotocol.
aswellasdevelopnovelmetricstoensureaccurate
measuresofperformance.
Additionally, while we focus on capturing var- References
ied political perspectives, we acknowledge that
EmilyAllawayandKathleenMcKeown.2023. Zero-
theleft-rightdichotomymaynotfullycapturethe
shot stance detection: Paradigms and challenges.
broad range of existing political views (Feldman FrontiersinArtificialIntelligence,5.
and Johnston, 2014). We restrict our initial eval-
ReinaldKimAmplayoandMirellaLapata.2019. In-
uation to left and right-leaning perspectives due
formative and controllable opinion summarization.
to data availability, but the task formulation and
arXivpreprint.
proposedevaluationframeworkcanbeappliedto
arbitrarysetsofperspectives. Weencouragefuture StefanoBalietti,LiseGetoor,DanielG.Goldstein,and
DuncanJ.Watts.2021. Reducingopinionpolariza-
worktoevaluateanddevelopapproachesforsum-
tion: Effectsofexposuretosimilarpeoplewithdif-
marizingabroaderrangeofpoints-of-viewinorder
feringpoliticalviews. ProceedingsoftheNational
torepresentsuchperspectivediversity. AcademyofSciences,118(52):e2112552118.
Finally,someofthemodelsevaluatedmaylack
YejinBang,NayeonLee,andPascaleFung.2023. Miti-
appropriate training on recent political issues to
gatingframingbiaswithpolarityminimizationloss.
enabledistinguishingtheperspectivespresentedin
In Findings of the Association for Computational
sourcedocuments. DatainPoliSumcoversatime Linguistics: EMNLP2023,pages11100–11110,Sin-
spanfromSeptember2018toJanuary2024,butthe gapore.AssociationforComputationalLinguistics.
last article of the CNN/DM dataset, for example,
AdithyaBhaskar,AlexFabbri,andGregDurrett.2023.
waswritteninApril2015(Hermannetal.,2015).
PromptedopinionsummarizationwithGPT-3.5. In
Thislackofrecentknowledgemayintroduceaddi- FindingsoftheAssociationforComputationalLin-
tionalchallengestosummarizingsourcepassages guistics: ACL 2023, pages 9282–9300, Toronto,
Canada.AssociationforComputationalLinguistics.
coveringtopicssuchasCOVID-19orrecentelec-
tions. Future work might explore topic-invariant
AliaBraley,GabrielS.Lenz,DhavalAdjodah,Hossein
approaches to summarizing perspectives that are Rahnama,andAlexPentland.2023. Whyvoterswho
abletoadapttocurrentevents. valuedemocracyparticipateindemocraticbackslid-
ing. NatureHumanBehaviour,7(8):1282–1293.
9 EthicsStatement
Arthur Brazinskas, Mirella Lapata, and Ivan Titov.
2019. Unsupervisedmulti-documentopinionsum-
Hallucinations and factual inconsistencies in lan-
marization as copycat-review generation. CoRR,
guagemodelshavereceivedwidespreadattention
abs/1911.02247.
duetotheriskstosafetyandpotentialformisinfor-
mation(Huangetal.,2021;Jietal.,2023). Though JohnR.Chambers, RobertS.Baron, andMaryL.In-
man. 2006. Misperceptions in intergroup conflict:
theintentofourworkistogeneratedistinctsum-
Disagreeingaboutwhatwedisagreeabout. Psycho-
mariesofperspectivesinordertobetterrepresent
logicalScience,17(1):38–45.
each, misrepresentations due to these hallucina-
tionscouldleadtomisunderstandingsofopposing AnshumanChhabra, HadiAskari, andPrasantMoha-
patra. 2024. Revisiting zero-shot abstractive sum-
perspectivesandtheaccompanyingimpactsonpo-
marization in the era of large language models
larization (Braley et al., 2023; Lees and Cikara,
from the perspective of position bias. Preprint,
2021). Additionally,languagemodelsthatmayel- arXiv:2401.01989.
9Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, AlexanderHanna,ChrisWells,PeterMaurer,LewFried-
ZhanghaoWu,HaoZhang,LianminZheng,Siyuan land,DhavanShah,andJörgMatthes.2013. Partisan
Zhuang,YonghaoZhuang,JosephEGonzalez,etal. alignmentsandpoliticalpolarizationonline: acom-
2023. Vicuna: Anopen-sourcechatbotimpressing putationalapproachtounderstandingthefrenchand
gpt-4with90%*chatgptquality. Seehttps://vicuna. uspresidentialelections. InProceedingsofthe2nd
lmsys.org(accessed14April2023),2(3):6. WorkshoponPolitics,ElectionsandData,PLEAD
’13,page15–22,NewYork,NY,USA.Association
HyungWonChung,LeHou,ShayneLongpre,Barret forComputingMachinery.
Zoph,YiTay,WilliamFedus,YunxuanLi,Xuezhi
Wang, Mostafa Dehghani, Siddhartha Brahma, Al- KarlMoritzHermann,TomasKocisky,EdwardGrefen-
bert Webson, Shixiang Shane Gu, Zhuyun Dai, stette,LasseEspeholt,WillKay,MustafaSuleyman,
MiracSuzgun,XinyunChen,AakankshaChowdh- andPhilBlunsom.2015. Teachingmachinestoread
ery,AlexCastro-Ros,MariePellat,KevinRobinson, and comprehend. Advances in neural information
DashaValter,SharanNarang,GauravMishra,Adams processingsystems,28.
Yu, Vincent Zhao, Yanping Huang, Andrew Dai,
NannanHuang,LinTian,HaythamFayek,andXiuzhen
HongkunYu,SlavPetrov,EdH.Chi,JeffDean,Ja-
Zhang.2023. Examiningbiasinopinionsummarisa-
cobDevlin,AdamRoberts,DennyZhou,QuocV.Le,
tionthroughtheperspectiveofopiniondiversity. In
andJasonWei.2022. Scalinginstruction-finetuned
Proceedingsofthe13thWorkshoponComputational
languagemodels. Preprint,arXiv:2210.11416.
ApproachestoSubjectivity,Sentiment,&SocialMe-
JohnWDuBois.2007. Thestancetriangle. Stancetak- diaAnalysis,pages149–161,Toronto,Canada.Asso-
ingindiscourse:Subjectivity,evaluation,interaction, ciationforComputationalLinguistics.
164(3):139–182.
YichongHuang,XiachongFeng,XiaochengFeng,and
BingQin.2021. Thefactualinconsistencyproblem
AbhimanyuDubey,AbhinavJauhri,AbhinavPandey,
inabstractivetextsummarization: Asurvey. arXiv
AbhishekKadian,AhmadAl-Dahle,AieshaLetman,
preprintarXiv:2104.14839.
Akhil Mathur, Alan Schelten, Amy Yang, Angela
Fan,etal.2024. Thellama3herdofmodels. arXiv
Hayate Iso, Xiaolan Wang, Stefanos Angelidis, and
preprintarXiv:2407.21783.
YoshihikoSuhara.2022. Comparativeopinionsum-
marizationviacollaborativedecoding. InFindingsof
Hady Elsahar, Maximin Coavoux, Jos Rozen, and
theAssociationforComputationalLinguistics: ACL
MatthiasGallé.2021. Self-supervisedandcontrolled
2022,pages3307–3324,Dublin,Ireland.Association
multi-documentopinionsummarization. InProceed-
forComputationalLinguistics.
ingsofthe16thConferenceoftheEuropeanChap-
teroftheAssociationforComputationalLinguistics:
ShobanaJayakumarandMuraliMalaisamy.2021. Ab-
MainVolume,pages1646–1662,Online.Association
stractivereviewsummarizationbasedonimproved
forComputationalLinguistics. attentionmechanismwithpointergeneratornetwork
model. Webology,18:77–91.
AlexanderR.Fabbri,IreneLi,TianweiShe,SuyiLi,and
DragomirR.Radev.2019. Multi-news: alarge-scale ZiweiJi,NayeonLee,RitaFrieske,TiezhengYu,Dan
multi-documentsummarizationdatasetandabstrac- Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea
tivehierarchicalmodel. arXivpreprint. Madotto,andPascaleFung.2023. Surveyofhalluci-
nationinnaturallanguagegeneration. ACMComput-
StanleyFeldmanandChristopherJohnston.2014. Un- ingSurveys,55(12):1–38.
derstanding the determinants of political ideology:
Implicationsofstructuralcomplexity. PoliticalPsy- AlbertQ.Jiang,AlexandreSablayrolles,ArthurMen-
chology,35(3):337–358. sch,ChrisBamford,DevendraSinghChaplot,Diego
delasCasas,FlorianBressand,GiannaLengyel,Guil-
ShangbinFeng,ChanYoungPark,YuhanLiu,andYulia laumeLample,LucileSaulnier,LélioRenardLavaud,
Tsvetkov.2023. Frompretrainingdatatolanguage Marie-AnneLachaux,PierreStock,TevenLeScao,
modelstodownstreamtasks: Trackingthetrailsof Thibaut Lavril, Thomas Wang, Timothée Lacroix,
political biases leading to unfair NLP models. In andWilliamElSayed.2023. Mistral7b. Preprint,
Proceedings of the 61st Annual Meeting of the As- arXiv:2310.06825.
sociationforComputationalLinguistics(Volume1:
LongPapers),pages11737–11762,Toronto,Canada. Albert Q. Jiang, Alexandre Sablayrolles, Antoine
AssociationforComputationalLinguistics. Roux, Arthur Mensch, Blanche Savary, Chris
Bamford, Devendra Singh Chaplot, Diego de las
Max Grusky, Mor Naaman, and Yoav Artzi. 2018. Casas, Emma Bou Hanna, Florian Bressand, Gi-
Newsroom: Adatasetof1.3millionsummarieswith anna Lengyel, Guillaume Bour, Guillaume Lam-
diverseextractivestrategies. InProceedingsofthe ple, Lélio Renard Lavaud, Lucile Saulnier, Marie-
2018ConferenceoftheNorthAmericanChapterof AnneLachaux,PierreStock,SandeepSubramanian,
theAssociationforComputationalLinguistics: Hu- Sophia Yang, Szymon Antoniak, Teven Le Scao,
man Language Technologies, Volume 1 (Long Pa- Théophile Gervet, Thibaut Lavril, Thomas Wang,
pers),pages708–719,NewOrleans,Louisiana.As- TimothéeLacroix,andWilliamElSayed.2024. Mix-
sociationforComputationalLinguistics. tralofexperts. Preprint,arXiv:2401.04088.
10TaeheeJung,DongyeopKang,LucasMentch,andEd- BinLiang,QinglinZhu,XiangLi,MinYang,LinGui,
uard Hovy. 2019. Earlier isn’t always better: Sub- YulanHe,andRuifengXu.2022. JointCL:Ajoint
aspectanalysisoncorpusandsystembiasesinsum- contrastivelearningframeworkforzero-shotstance
marization. Preprint,arXiv:1908.11723. detection. InProceedingsofthe60thAnnualMeet-
ingoftheAssociationforComputationalLinguistics
HyunDukKimandChengXiangZhai.2009. Generat- (Volume1: LongPapers),pages81–91,Dublin,Ire-
ingcomparativesummariesofcontradictoryopinions land.AssociationforComputationalLinguistics.
intext. InProceedingsofthe18thACMConference
onInformationandKnowledgeManagement,CIKM Chin-Yew Lin. 2004a. ROUGE: A package for auto-
’09,page385–394,NewYork,NY,USA.Association maticevaluationofsummaries. InTextSummariza-
forComputingMachinery. tionBranchesOut,pages74–81,Barcelona,Spain.
AssociationforComputationalLinguistics.
PhilippeLaban,TobiasSchnabel,PaulN.Bennett,and
MartiA.Hearst.2022. SummaC:Re-visitingNLI- Chin-Yew Lin. 2004b. ROUGE: A package for auto-
basedmodelsforinconsistencydetectioninsumma- maticevaluationofsummaries. InTextSummariza-
rization. TransactionsoftheAssociationforCompu- tionBranchesOut,pages74–81,Barcelona,Spain.
tationalLinguistics,10:163–177. AssociationforComputationalLinguistics.
Faisal Ladhak, Esin Durmus, Mirac Suzgun, Tianyi Ruibo Liu, Chenyan Jia, Jason Wei, Guangxuan Xu,
Zhang,DanJurafsky,KathleenMcKeown,andTat- LiliWang,andSoroushVosoughi.2021. Mitigating
sunoriHashimoto.2023. Whendopre-trainingbi- politicalbiasinlanguagemodelsthroughreinforced
ases propagate to downstream tasks? a case study calibration. arXivpreprint.
in text summarization. In Proceedings of the 17th
Conference of the European Chapter of the Asso- YuhanLiu,ShangbinFeng,XiaochuangHan,Vidhisha
ciationforComputationalLinguistics,pages3206– Balachandran,ChanYoungPark,SachinKumar,and
3219,Dubrovnik,Croatia.AssociationforComputa- YuliaTsvetkov.2024. P3ˆsum: Preservingauthor’s
tionalLinguistics. perspective in news summarization with diffusion
languagemodels. Preprint,arXiv:2311.09741.
NayeonLee,YejinBang,TiezhengYu,AndreaMadotto,
andPascaleFung.2022. NeuS:Neutralmulti-news SaifMohammad.2018. Obtainingreliablehumanrat-
summarizationformitigatingframingbias. InPro- ingsofvalence,arousal,anddominancefor20,000
ceedingsofthe2022ConferenceoftheNorthAmer- Englishwords. InProceedingsofthe56thAnnual
icanChapteroftheAssociationforComputational Meeting of the Association for Computational Lin-
Linguistics: HumanLanguageTechnologies,pages guistics (Volume 1: Long Papers), pages 174–184,
3131–3148, Seattle, UnitedStates.Associationfor Melbourne,Australia.AssociationforComputational
ComputationalLinguistics. Linguistics.
JeffreyLeesandMinaCikara.2021. Understandingand Ramesh Nallapati, Bowen Zhou, Cicero dos Santos,
combatingmisperceivedpolarization. Philosophical Çag˘larGuu.lçehre,andBingXiang.2016. Abstrac-
TransactionsoftheRoyalSocietyB:BiologicalSci- tivetextsummarizationusingsequence-to-sequence
ences,376(1822):20200143. RNNs and beyond. In Proceedings of the 20th
SIGNLLConferenceonComputationalNaturalLan-
Ro’ee Levy. 2021. Social media, news consumption, guage Learning, pages 280–290, Berlin, Germany.
andpolarization: Evidencefromafieldexperiment. AssociationforComputationalLinguistics.
Americaneconomicreview,111(3):831–870.
Shashi Narayan, Shay B. Cohen, and Mirella Lapata.
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan 2018. Don’tgivemethedetails,justthesummary!
Ghazvininejad,AbdelrahmanMohamed,OmerLevy, topic-aware convolutional neural networks for ex-
VesStoyanov,andLukeZettlemoyer.2019. Bart:De- treme summarization. In Proceedings of the 2018
noisingsequence-to-sequencepre-trainingfornatural Conference on Empirical Methods in Natural Lan-
languagegeneration,translation,andcomprehension. guageProcessing,pages1797–1807,Brussels,Bel-
arXivpreprint. gium.AssociationforComputationalLinguistics.
Bryan Li, Samar Haider, and Chris Callison-Burch. Olubusayo Olabisi and Ameeta Agrawal. 2024. Un-
2024. This land is Your, My land: Evaluating derstanding position bias effects on fairness in
geopolitical biases in language models. Preprint, social multi-document summarization. Preprint,
arXiv:2305.14610. arXiv:2405.01790.
YingjieLi,KrishnaGarg,andCorneliaCaragea.2023. OlubusayoOlabisi,AaronHudson,AntonieJetter,and
A new direction in stance detection: Target-stance AmeetaAgrawal.2022. Analyzingthedialectdiver-
extractioninthewild. InProceedingsofthe61stAn- sityinmulti-documentsummaries. InProceedingsof
nualMeetingoftheAssociationforComputational the29thInternationalConferenceonComputational
Linguistics(Volume1: LongPapers),pages10071– Linguistics,pages6208–6221,Gyeongju,Republic
10085,Toronto,Canada.AssociationforComputa- ofKorea.InternationalCommitteeonComputational
tionalLinguistics. Linguistics.
11ColinRaffel,NoamShazeer,AdamRoberts,Katherine A Zero-ShotBaselines
Lee,SharanNarang,MichaelMatena,YanqiZhou,
WeiLi,andPeterJ.Liu.2019. Exploringthelimits
Models Prompt
oftransferlearningwithaunifiedtext-to-texttrans-
“summarizethe
former. arXivpreprint.
T5,Flan-T5 [left,right]-leaningpolitical
perspective:{PASSAGES}”
CharlesRajan,NishitAsnani,andShreyaSingh.2023.
“Produceashort,
Shapingpoliticaldiscourseusingmulti-sourcenews
single-sentencesummaryofthe
summarization. Preprint,arXiv:2312.11703. Mistral, [left,right]-leaningpolitical
Mixtral,Vicuna,
perspectivewithinthefollowing
Shibani Santurkar, Esin Durmus, Faisal Ladhak, Llama-3,
texts.Respondonlywiththe
CinooLee,PercyLiang,andTatsunoriHashimoto. GPT-4o summarybeginningwith"The
2023. Whoseopinionsdolanguagemodelsreflect? [left,right]":{PASSAGES}”
Preprint,arXiv:2303.17548.
Table 7: Summarization prompts provided to each
ThibaultSellam,DipanjanDas,andAnkurParikh.2020.
model. "left" and "right" are included in the prompt
BLEURT: Learning robust metrics for text genera-
dependingontheintendedpoliticalperspective.
tion. InProceedingsofthe58thAnnualMeetingof
theAssociationforComputationalLinguistics,pages
7881–7892,Online.AssociationforComputational BecauseitisfinetunedonCNN/DM,inference
Linguistics. withBARTisdonewithoutaprompt. BARTsum-
maries, however, are forced to begin with either
YoshihikoSuhara,XiaolanWang,StefanosAngelidis,
andWang-ChiewTan.2020. Opiniondigest: Asim- "Theleft"or"Theright"dependingontheintended
ple framework for opinion summarization. arXiv perspective to enforce the task format. Inference
preprint.
with T5 and Flan-T5 is conducted using the first
WenyiTay.2019. Notallreviewsareequal:Towardsad- promptinTable7. Summariesforallthreemodels
dressingreviewerbiasesforopinionsummarization. aregeneratedwiththedefaulttransformerspackage
In Proceedings of the 57th Annual Meeting of the hyperparametersandgreedydecoding.
AssociationforComputationalLinguistics: Student
Research Workshop, pages 34–42, Florence, Italy.
B PromptingBaselines
AssociationforComputationalLinguistics.
ForlargerLLMs,weusethesecondpromptinTa-
ThomasWellings,RegulaHänggliFricker,Evangelos
Pournaras,andWenqingFu.2024. Brexitontwitter: ble7,generatingeachsummaryseparately. Larger
Unravelingthedynamicsofpolarizationovertime. models(GPT-4o,Llama-3-70B,Vicuna-13B,and
InProceedingsofthe25thAnnualInternationalCon-
Mixtral-8x22B)areaccessedviaOpenAIandFire-
ferenceonDigitalGovernmentResearch,dg.o’24,
worksAI12 API’s. Inallcases,weuseatempera-
page855–866,NewYork,NY,USA.Associationfor
ComputingMachinery. tureof0toensuredeterministicoutputsandgreedy
decoding. Smaller model (Mistral-7B, Llama-3-
YuhengZha,YichiYang,RuichenLi,andZhitingHu.
8B,andVicuna-7B)inferenceisrunwithbfloat16
2023. AlignScore: Evaluating factual consistency
precision,alsousinggreedydecoding.
with a unified alignment function. In Proceedings
of the 61st Annual Meeting of the Association for
ComputationalLinguistics(Volume1: LongPapers), C DataStatement
pages11328–11348,Toronto,Canada.Association
forComputationalLinguistics. Details characterizing the collected data are in-
cludedinthefollowingdatastatement.
TianyiZhang*,VarshaKishore*,FelixWu*,KilianQ.
Weinberger,andYoavArtzi.2020. Bertscore: Eval- C.1 CurationRationale
uating text generation with bert. In International
ConferenceonLearningRepresentations. Thedatawascollectedinordertoevaluatemodels
insummarizingpoliticalperspectivesoncontrover-
TianyiZhang,FaisalLadhak,EsinDurmus,PercyLiang,
sial issues provided passages from news articles
Kathleen McKeown, and Tatsunori B. Hashimoto.
2023a. Benchmarking large language models for andop-eds. AlldatacomesfromTheFlipSide,a
newssummarization. Preprint,arXiv:2301.13848. site which publishes summaries of left and right-
leaningperspectivesoncurrentissueswithaccom-
YusenZhang, NanZhang, YixinLiu, AlexanderFab-
panyingpassagesfromothernewssources. Each
bri, Junru Liu, Ryo Kamoi, Xiaoxin Lu, Caim-
ingXiong, JieyuZhao, DragomirRadev, Kathleen sampleincludesaheadlinedescribingthecontro-
McKeown, and Rui Zhang. 2023b. Fair abstrac- versialissue,asetofleftandright-leaningsource
tivesummarizationofdiverseperspectives. Preprint,
arXiv:2311.07884. 12https://fireworks.ai
12passages, and pair of one-sentence left and right theMixed-PerspectiveSetting,modelsarenotex-
perspectivesummaries. pectedtodistinguishinputpassages.
C.2 LanguageVariety E.2 Results
All texts are in English (en-US) and reflect a for-
Automatic coverage and faithfulness metrics for
mal variety of English commonly found in news
theSingle-PerspectiveSettingareshowninTable8,
articles.
whileautomaticperspectivedimensionscoresare
showninTable9.
C.3 SpeechSituation
Allsourcepassagesandsummariesareoriginally
F HumanJudgments
writtentexts. Asthedataisprimarilycomprisedof
passagesfromnewsarticlesandop-eds,thetexts F.1 AnnotatorDemographics
wereintendedforabroadAmericanaudience,writ-
Humanjudgmentsareconductedwith6undergrad-
ten asynchronously, and are likely edited repeat-
uatestudentspursuingaBSorBAinPoliticalSci-
edly before publishing. All data was originally
ence,withself-reportedknowledgeofthecommon
published between September 2018 and January
beliefsofconservativesandliberals. Assuch,they
2024.
have the required expertise to judge perspectives
C.4 TextCharacteristics conveyedinsummaries. Demographicsofthere-
cruitedannotatorsareshowninTable10.
Amajorityofthetextsinthedatasetreflectpolit-
ically controversial issues, including topics such
F.2 HumanJudgmentCorrelationsbyModel
aselections,policy,politicalfigures,andcultural
Correlation with human judgments by model is
phenomena. Asthetaskfocusesonsummarizing
showninTable11. Asintheoverallsample-level
politicalperspectives,thetextsalsoheavilyreflect
results, correlations with human judgments are
opinionsoftheoriginalauthorsinthecaseofthe
largelypoorandnon-significant. ForGPT-4o,how-
sourcepassages,orageneralleftorright-leaning
ever,theautomaticmetricforObjectissignificant
perspectiveinthecaseofthereferencesummaries.
andweaklynegativelycorrelatedwithhumanjudg-
D EvaluationMetricsImplementation ments.
We evaluate models using existing implementa-
F.3 HumanJudgmentsbyPerspective
tionsofcoverage,consistency,andfactualitymet-
Human judgments of perspective dimensions for
rics. ROUGE is calculated using the ROUGE-
both the left and right perspectives are shown in
scorepythonpackage(Lin,2004b). BERTSCORE
Table12. Inbothperspectives,GPT-4osummaries
is calculated using the Torchmetrics implementa-
tion13. All other metrics are calculated using the arescoredhighestforalldimensions. Whilesome
averagescoresappeartobeslightlyhigherforthe
implementationsbytheoriginalauthorsforeach:
left perspective, no differences between perspec-
BLEURT (Sellametal.,2020), SUMMAC (Laban
tivesaresignificant(p > 0.05).
etal.,2022),andALIGNSCORE(Zhaetal.,2023).
Allcoverage,faithfulness,andautomaticmetrics
F.4 HumanEvaluationInterface
for perspective dimensions (Stance, Object, and
Intensity)arescaledtoa0-100range. Screenshotsofthehumanevaluationinterfacepro-
videdtoannotatorsareshowninFigure6,Figure7,
E Single-PerspectiveSetting
Figure 8, and Figure 9. Annotators are first pro-
videdwithinstructionsdescribingeachperspective
E.1 Methods
dimension(Figure6). Annotatorsarethenshown
IntheSingle-PerspectiveSetting,modelsareeval-
examplesummarieswithaccompanyingexplana-
uated similarly to traditional opinion summariza-
tionsdescribinghoweachperspectivedimension
tion. Models are provided with passages from a
couldbeinterpretedintheexamplesummary(Fig-
single perspective only (i.e., left or right-leaning
ure7). Wedonotincludeinputdocumentsorpossi-
passages), and asked to generate a summary for
blejudgmentsfortheexamplesummariestoavoid
the same perspective. Therefore, in contrast to
biasing annotators’ judgments. In the left-hand
13https://github.com/Lightning-AI/torchmetrics column, annotators are given the input passages
13Left Right
Model
R1 RL BLEURT BERT SUMMAC Align R1 RL BLEURT BERT SUMMAC Align
BARTCNN/DM 25.4 22.8 30.7 61.6 25.6 30.3 25.5 22.9 29.9 59.9 27.0 38.4
T5 24.6 22.3 30.1 60.8 23.5 16.3 25.5 23.1 31.2 60.3 23.8 16.8
Flan-T5 23.0 20.2 28.9 59.0 27.3 42.4 23.9 21.2 28.6 58.6 27.3 44.6
Mistral 26.1 22.2 35.9 61.1 26.3 52.1 26.0 22.2 34.7 59.8 27.2 52.7
Mixtral 26.1 22.2 38.6 60.4 26.6 50.7 27.2 23.0 38.0 60.2 26.9 61.4
Vicuna(7B) 24.9 21.5 33.9 59.5 29.6 47.3 26.0 22.4 33.7 58.6 31.7 58.0
Vicuna(13B) 26.0 22.4 38.2 60.3 26.5 51.6 26.3 22.8 37.0 59.4 26.3 60.3
Llama-3(8B) 27.3 23.0 39.2 60.1 25.5 46.0 28.0 23.9 38.9 59.4 25.9 54.3
Llama-3(70B) 23.8 19.6 37.7 60.2 24.2 39.0 25.0 20.5 36.7 59.8 24.4 52.6
GPT-4o 25.6 21.8 41.3 62.1 25.1 44.2 27.0 23.1 40.8 61.5 25.5 54.2
Table8: AveragecoverageandfaithfulnessscoresfortheSingle-Perspectivesetting. Bestperformanceoneach
metricisboldedandsecondbestunderlined. Higherscoresreflectbetterperformanceforallmetrics.
separatedbynewlines,andintheright-handcol-
Left Right
Model
S↓ O↑ I↓ S↓ O↑ I↓ umn,annotatorsareprovidedwithasummaryfol-
BARTCNN/DM 30.3 74.7 15.1 31.7 74.4 14.0
lowed by questions and 4-point Likert scales for
T5 31.3 76.0 17.9 32.5 73.5 19.4
Flan-T5 31.7 77.2 7.9 32.6 73.8 8.0 eachperspectivedimension(Figure8&Figure9).
Mistral 28.5 77.4 8.1 30.0 75.5 6.8
Mixtral 27.4 76.9 9.6 28.9 77.2 5.8 Reference summaries, and summaries generated
Vicuna(7B) 29.5 76.2 9.1 29.1 75.5 6.5
byMistral,Mixtral,andGPT-4oareshownonthe
Vicuna(13B) 27.2 77.0 7.2 31.0 76.3 6.2
Llama-3(8B) 26.7 77.0 7.8 28.5 77.1 6.2 same page in a randomized order for each set of
Llama-3(70B) 29.7 77.1 6.1 30.2 77.0 5.1
GPT-4o 27.6 77.4 6.9 28.6 77.1 5.5 inputpassages. Annotatorsareabletocollapseand
un-collapseallsections.
Table9: PerspectivescoresforallmodelsintheSingle-
Perspectivesetting. S:Stance,O:Object,I:Intensity.
G ExtractionAnalysesbyPerspective
InFigure10,Figure11,andFigure12,wepresent
Demographic
Group % theposition, length, andarousalbiasanalysesby
Variable
Male 66.6% perspective. Allidentifiedtrendsacrosstheleftand
Gender
Female 33.3% rightperspectivesarelargelyconsistentwiththose
ExtremelyLiberal 16.6%
reportedintheresults.
Liberal 33.3%
SlightlyLiberal 33.3%
Political Moderate 16.6% H AdditionalSummaryExamples
Ideology
SlightlyConservative 0%
Conservative 0% Additional summary examples are shown in Ta-
ExtremelyConservative 0%
ble13,Table14,andTable15.
AmericanIndian,Alaskan
16.6%
Native,and/orIndigenous
ArabAmerican,Middle
0%
Eastern,orNorthAfrican
Race/
AsianorAsianAmerican 0%
Ethnicity
BlackorAfricanAmerican 16.6%
Latino/a/xorSpanishOrigin 16.6%
NativeHawaiinorPacific
0%
Islander
SoutheastAsian 0%
White/EuropeanAmerican 66.6%
Other 16.6%
Table10: Demographicstatisticsofthe6annotators.
Model S O I
Mistral 0.04 0.04 0.03
Mixtral -0.03 0.01 -0.08
GPT-4o -0.06 -0.19* 0.02
Table 11: Sample-level correlation with human judg-
mentsforeachperspectivedimensionbymodel. Signif-
icantcorrelationsaremarkedwith*(p≤.05).
14Left Right
Model
S O I C R S O I C R
Ref. 2.9 3.1 2.8 2.9 1.7 2.9 3.4 2.9 2.9 2.0
Mistral 2.4 3.1 2.5 2.6 2.0 2.4 3.2 2.5 2.5 1.8
Mixtral 3.2 3.4 3.1 3.2 2.7 2.8 3.4 2.8 2.8 2.4
GPT-4o 3.3 3.5 3.3 3.3 2.9 3.2 3.6 3.2 3.2 2.8
Table12: Averagehumanjudgmentsofeachperspectivedimensionwithaveragelengthandextractioncoverage
overallinputs. Scoresareshownseparatelyforleftandright-perspectivesummaries.Bestscoresarebolded. Higher
scoresreflectbetterperformanceforallmetrics. S:Stance,O:Object,I:Intensity,C:Consensus,R:Reasoning.
Figure6: Humanevaluationinterfacescreenshot: Instructions.
Figure7: Humanevaluationinterfacescreenshot: Examples.
15Figure8: Humanevaluationinterfacescreenshot: PassagesandQuestionsPart1.
Figure9: Humanevaluationinterfacescreenshot: PassagesandQuestionsPart2.
16Figure10: Averageextractioncoverageofsourcedocumentsforeachmodelbythenumberofhighlyarousing
termsinthesourcedocument(percentilesareshownratherthanrawvalues).
Figure11: Averageextractioncoverageofsourcedocumentsforeachmodelbythedocument’spositionintheinput.
Lowervaluesreflectearlierpositionsintheinput.
Figure 12: Average extraction coverage of source documents for each model by length of the input document
(percentilesareshownratherthanrawvalues).
17RonDeSantis
Model LeftSummary RightSummary
TheleftarguesthatDeSantis’scampaignwas TherightarguesthatRepublicanvoterswere
Reference
doomedbymiscuesandstrategicerrors. justnotreadytomoveonfromTrump.
Theleft:DeSantis’failuretosupportaidfor Theright:DeSantis’s2022re-election
Ukraineandhissigningofasix-weekabortion campaignwassuccessful,buthis2024
baninFloridaalienatedsomemoderatesand presidentialcampaignwasunsuccessfuldueto
Mistral
madehimlookweak,ultimatelyhurtinghis hisfailuretowinovervoterswhowerelooking
chancesofwinningovervotersopentoaTrump forafreshstartaftertheTrump-leddefeatsof
alternative. 2018,2020.
TheleftperceivesDeSantisasaweakcandidate
TherightbelievesthatDeSantis,despitehis
whofailedtoeffectivelydifferentiatehimself
initialpotential,failedtoeffectivelychallenge
fromTrump,ultimatelylosingsupportfrom
Trumpinthe2024GOPpresidentialprimary
Mixtral bothmoderatesandevangelicals,and
duetohisinabilitytouniteabroadcoalition,
strugglingtomanagehiscampaignandimage,
lackofaclearmessage,andTrump’spolitical
leadingtohisdownfallinthe2024GOP
martyrdomfollowingmultipleindictments
presidentialprimary.
TheleftviewsDeSantis’strugglesasindicative TherightviewsDeSantis’strugglesasa
ofthebroaderRepublicanParty’sinabilityto reflectionoftheRepublicanbase’senduring
GPT-4o movebeyondTrumpism,highlightinginternal loyaltytoTrump,despitehisflaws,andthe
conflicts,ineffectivestrategies,andthe challengesofpresentingaviablealternative
alienationofmoderatevoters. withintheparty.
Table13: Additionalright-perspectiveexamplesummariesonthemostrecenttopicinthecollecteddataset(Ron
DeSantis, January 2024). Distinct colors represent quotes or paraphrases from the same document, and italics
denoteinformationfrompassagesreflectingthealternateperspective.
RaceandCoronavirus
Model LeftSummary RightSummary
Theleftarguesthatitisimportanttofocuson Therightrecommendsfocusingonthefactors
racialdisparities,becausetheystemfrom thatunderlieracialdisparities,suchaspoverty
Reference structuralinequalityorganizedalongracial andpre-existinghealthconditions,ratherthan
lines,andemphasizestheimportanceofsocietal raceitself,andemphasizestheimportanceof
solutions. individualresponsibility.
Therightarguesthattheoutsizednumberof
Theleft:Theleftarguesthattheoutsized deathsintheblackcommunityisaseriousissue
numberofdeathsintheblackcommunityisa thatpointstothenation’sfailuresinservingthat
Mistral
seriousissuethathighlightsthenation’s communityfordecades,butitshouldnotbethe
failuresinservingthatcommunityfordecades. focusoftheimmediateresponsetothe
coronavirus.
Theleftarguesthatsystemicracialand
socioeconomicdisparitieshaveledto
disproportionateexposuretoairpollutionand
Therightperspectivesuggeststhatwhileracial
healthimpacts,includingCOVID-19,among
disparitiesinhealthcareareaseriousissue,the
blackandHispaniccommunities,andthat
Mixtral immediateresponsetothecoronavirusshould
immediateactionsuchasexpandingfederal
focusongettingmedicalresourcestowhere
financialcoveragefortestingandtreatment,
theyareneededmost,regardlessofrace.
prioritizinghospitalsinat-riskneighborhoods,
andaddressingunderlyingissueslikeeconomic
andeducationaldisparitiesisnecessary.
Theleftemphasizestheneedtoaddress
Therightemphasizesindividualresponsibility
systemicracialandeconomicinequalitiesthat
andbehavioralfactorsinhealthdisparities,
exacerbatehealthdisparities,advocatingfor
GPT-4o arguingthatimmediatepandemicresponses
immediateandlong-termmeasurestoensure
shouldfocusonactualriskfactorsratherthan
equitableaccesstohealthcareandresourcesfor
racialgeneralizations.
marginalizedcommunities.
Table14: Additionalexamplesummariesforarandomlysampledarticle. Distinctcolorsrepresentquotesorpara-
phrasesfromthesamedocument,anditalicsdenoteinformationfrompassagesreflectingthealternateperspective.
18AndrewMcCabe
Model LeftSummary RightSummary
Theleftpushesbackonthenarrativethat
TherightcondemnsMcCabeandseeshis
exercisingthe25thamendmentwouldconstitute
Reference statementsasevidencethattheinvestigation
acoup,andcriticizesRepublicansforhypocrisy
againstTrumpwaspoliticallymotivated.
regardingtheongoinginvestigations.
Theright:McCabe’srevelationssuggestthat
theongoingFBIinvestigationofTrumpandhis
Theleft:McCabe’srevelationssuggestthat
campaignmayhavemoretodowithpolitics
Trump’sfiringofComeywaspolitically
Mistral thanthemeritsofthecase,andthatsome
motivatedandthatNunes’objectionstotheFBI
politicians,includingNunes,wereawareofthe
investigationmayhavebeendrivenbybias.
investigationandstillworkedwiththeWhite
Housetopushaconspiracytheory.
TherightbelievesthattheFBI,underthe
TheleftperceivesthattopFBIofficials,
leadershipofAndrewMcCabeandJames
includingMcCabe,wereconcernedabout
Comey,oversteppeditsauthoritybyattempting
Trump’spotentialthreattonationalsecuritydue
toactasacheckonPresidentTrump,
Mixtral tohisallegedtieswithRussia,andtheybelieve
potentiallyinfluencedbypoliticalbias,andthat
thatcertainRepublicanleaders,suchasNunes,
theuseofthe25thAmendmenttoremove
McConnell,andRyan,chosetooverlookthis
Trumpfromofficewasaninappropriateand
concernanddefendTrumpinstead.
unrealisticmeasure.
TherightviewstheactionsofMcCabeand
TheleftviewsMcCabe’srevelationsas
otherFBIofficialsasanoverreachoftheir
evidencethattopofficialswerejustifiably
authority,drivenbyanti-Trumpbias,and
GPT-4o concernedaboutTrump’spotentialnational
believesthatanyattempttoremoveTrumpfrom
securityrisksandthattheFBI’sactionswerea
officeshouldfollowconstitutionalprocesses
necessarycheckonpresidentialpower.
ratherthanbedecidedbyunelectedofficials.
Table15: Additionalexamplesummariesforarandomlysampledarticle. Distinctcolorsrepresentquotesorpara-
phrasesfromthesamedocument,anditalicsdenoteinformationfrompassagesreflectingthealternateperspective.
19