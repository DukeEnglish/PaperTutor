Partial Structure Discovery is Sufficient for No-regret
Learning in Causal Bandits
Muhammad Qasim Elahi1, Mahsa Ghasemi1, Murat Kocaoglu1
School of Electrical and Computer Engineering, Purdue University1
elahi0@purdue.edu, mahsa@purdue.edu, mkocaoglu@purdue.edu
November 7, 2024
Abstract
Causal knowledge about the relationships among decision variables and a reward variable in a bandit
setting can accelerate the learning of an optimal decision. Current works often assume the causal graph
is known, which may not always be available a priori. Motivated by this challenge, we focus on the
causal bandit problem in scenarios where the underlying causal graph is unknown and may include latent
confounders. While intervention on the parents of the reward node is optimal in the absence of latent
confounders, this is not necessarily the case in general. Instead, one must consider a set of possibly
optimal arms/interventions, each being a special subset of the ancestors of the reward node, making
causal discovery beyond the parents of the reward node essential. For regret minimization, we identify
that discovering the full causal structure is unnecessary; however, no existing work provides the necessary
andsufficientcomponentsofthecausalgraph. Weformallycharacterizethesetofnecessaryandsufficient
latent confounders one needs to detect or learn to ensure that all possibly optimal arms are identified
correctly. Wealsoproposearandomizedalgorithmforlearningthecausalgraphwithalimitednumberof
samples, providing a sample complexity guarantee for any desired confidence level. In the causal bandit
setup, we propose a two-stage approach. In the first stage, we learn the induced subgraph on ancestors of
the reward, along with a necessary and sufficient subset of latent confounders, to construct the set of
possibly optimal arms. The regret incurred during this phase scales polynomially with respect to the
number of nodes in the causal graph. The second phase involves the application of a standard bandit
algorithm, such as the UCB algorithm. We also establish a regret bound for our two-phase approach,
which is sublinear in the number of rounds.
1 Introduction
Causal bandits have been a topic of interest since their inception and have been studied in various contexts
[Lattimore et al., 2016]. The authors assumed precise knowledge of the causal graph and the impact of
interventions or actions on the parents of the reward node. Subsequently, there has been a flurry of research
on causal bandits [Sen et al., 2017, Lu et al., 2020, Nair et al., 2021]. The primary limitation of the majority
of existing works on causal bandits is their assumption of full knowledge of the causal graph, which is often
impractical for many real-world applications [Lattimore et al., 2016, Lee and Bareinboim, 2018, Wei et al.,
2024]. Recently, efforts have been made to overcome this limitation. In Lu et al. [2021], the authors propose
a sample efficient algorithm for cases where the causal graph can be represented as a directed tree or a causal
forest and later extend the algorithm to encompass a broader class of general chordal graphs. However, the
proposed algorithm is only applicable to scenarios where the Markov equivalence class (MEC) of the causal
graphisknownanddoesnothaveconfounders. InDeKroonetal.[2022], theauthorsproposeacausalbandit
algorithm that does not require any prior knowledge of the causal structure and leverages separating sets.
However, their theoretical result holds only when a true separating set is known. The paper by Konobeev et
al. Konobeev et al. [2023] also deals with causal bandits with an unknown graph and proposes a two-phase
approach. The first phase uses a randomized parent search algorithm to learn the parents of the reward node,
1
4202
voN
6
]LM.tats[
1v45040.1142:viXraPartial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
and the second phase employs UCB to identify the optimal intervention over the parents of the reward node.
However, similar to Lu et al. [2021], they assume causal sufficiency, i.e., no latent confounders are present.
In another related paper, Malek et al. [2023], the authors initially emphasize the challenge of dealing with
exponentially many arms when addressing causal bandits with an unknown graph. To tackle this issue, the
authors assume that the reward is a noisy additive function of its parents. This assumption enables them to
reframe the problem as an additive combinatorial linear bandit problem.
We also focus on the causal bandit setup where the causal graph is unknown, but we allow the presence of
latent confounders and make no parametric assumptions. The optimal intervention in this case is not limited
to parents of the reward node; instead, we have a candidate set of optimal interventions, called possibly
optimal minimum intervention sets (POMISs), each being a special subset of the ancestors of the reward
node [Lee and Bareinboim, 2018]. Thus, learning only the parents of the reward, similar to Konobeev et al.
[2023], is insufficient. This implies that causal discovery beyond parents of the reward is imperative. However,
for regret minimization, discovering the full causal structure is not necessary. Instead, we characterize the set
of necessary and sufficient latent confounders one needs to detect/learn to ensure all the possibly optimal
arms are learned correctly.
Causal discovery is a well-studied problem and can be applied to our setup [Peters et al., 2017, Shen
et al., 2020, Zanga et al., 2022]. However, the majority of the existing causal discovery algorithms rely
on the availability of an infinite amount of interventional data [Kocaoglu et al., 2017, Zhang et al., 2017,
Shanmugam et al., 2015]. Some prior work shows that discovery is possible with limited interventional data,
with theoretical guarantees when the underlying causal graph is a tree and contains no latent confounders
[Greenewald et al., 2019]. Also, the paper Elahi et al. [2024] proposes a sample-efficient active learning
algorithm for causal graphs without latent confounders, given that the MEC for the underlying causal graph
is known. Bayesian causal discovery can also be a valuable tool when interventional data is limited. However,
it faces challenges when tasked with computing posterior probabilities across the combinatorial space of
directed acyclic graphs (DAGs) without specific parametric assumptions [Heckerman et al., 1997, Annadani
etal.,2023,Tothetal.,2022]. Allinall,thesample-efficientlearningofcausalgraphswithlatentconfounders,
without any parametric or graphical assumptions, with theoretical guarantees, remains an open problem.
We propose a randomized algorithm for sample-efficient learning of causal graphs with confounders. We
analyze the algorithm and bound the maximum number of interventional samples required to learn the causal
graph with all the confounders with a given confidence level. For the causal bandit setup, we propose a
two-stage approach where the first step learns a subgraph of the underlying causal graph to construct a set of
POMISs, and the second phase learns the optimal arm among the POMISs. We show that the requirement of
learning only a subgraph leads to significant savings in terms of interventional samples and consequently,
regret. The main contributions of our work are as follows:
• We characterize the necessary and sufficient set of latent confounders in the induced subgraph on
ancestors of the reward node that we need to learn/detect in order to identify all the POMISs for a
causal bandit setup when the underlying causal graph is unknown.
• We propose a randomized algorithm for sample-efficient learning of causal graphs with confounders,
providing theoretical guarantee on the number of interventional samples required to learn the graph
with a given confidence level.
• Weproposeatwo-phasealgorithmforcausalbanditswithunknowncausalgraphscontainingconfounders.
The first phase involves learning the induced subgraph on reward’s ancestors along with a subset of
latent confounders to identify all the POMISs. The next phase involves a standard bandit algorithm,
e.g., upper confidence bound (UCB) algorithm. Our theoretical analysis establishes an upper bound on
the cumulative regret of the overall algorithm.
2 Preliminaries and Problem Setup
We start with an overview of the causal bandit problem and other relevant background needed on causal
models. Structural causal model (SCM) is a tuple M=⟨V,U,F,P(U)⟩ where V ={V }n ∪{Y} is the
i i=1
set of observed variables, U is the set of independent exogenous variables, F is the set of deterministic
2Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
structural equations and P(U) is the distribution for exogenous variables [Pearl, 2009]. The equations f
i
map the parents (Pa(V )) and a subset of exogenous variables U ⊆ U, to the value of variable V , i.e.,
i i i
V =f (Pa(V ),U ). We consider the causal bandit setup where all the observed variables V ∈V are discrete
i i i i i
with the domain Ω(V ) = [K] := {1,2,3,...,K}, and the reward Y is binary, i.e., Ω(Y) = {0,1}. We can
i
associate a DAG G =(V,E) with every SCM, where the vertices V correspond to the observed variables
and edges E consist of directed edges V →V when V ∈Pa(V ) and bi-directed edges between V and V
i j i j i j
(V ←→V ) when they share some common unobserved variable, also called latent confounder. We restrict
i j
ourselves to semi-Markovian causal models in which every unobserved variable has no parents and has exactly
two children, both of which are observed [Malek et al., 2023]. An intervention on a set of variables W⊆V,
denoted by do(W), induces a post-interventional DAG (G ) with incoming edges to vertices W removed. In
W
the context of causal bandits, an arm or action corresponds to hard intervention on a subset of variables
other than the reward. The goal of the agent is to identify the intervention that maximizes the expected
reward. The performance of an agent is measured in terms of cumulative regret R .
T
T
(cid:88)
R :=T max max E[Y|do(W=w)]− E[Y|do(W =w )], (1)
T t t
W⊆Vw∈[K]|W|
t=1
where do(W =w ) represents the intervention selected by the agent in round t. We use the notation ∆
t t do(w)
to define the sub-optimality gap of the corresponding arm do(W=w). We denote the descendants, ancestors
andchildrenofavertexV byDe(V ), An(V )andCh(V )respectively. WeusethenotationBi(V ,G)todenote
i i i i i
the set of vertices having bidirected edges to V except the reward node Y. We refer to the induced graph
i
between observable variables as the observable graph. The transitive closure of a graph, denoted by Gtc,
encodes the ancestral relationship in G. That is, the directed edge V → V is included in Gtc only when
i j
V ∈An(V ). The transitive reduction, denoted by Tr(G)=(V,Er), is a graph with the minimum number
i j
of edges such that the transitive closure is the same as G. The connected component (c-component) of the
DAG G, containing vertex V , is denoted by CC(V ), which is the maximal set of all vertices in G that have
i i
a path to V , consisting only of bi-directed edges [Tian and Pearl, 2002]. For a subset of vertices W ⊆V,
i
we define CC(W) := (cid:83) CC(W ). In a DAG, a subset of nodes W d-separates two nodes V and V
when it effectively
blockW
s
ia∈ llW
paths
bi
etween them, denoted as V ⊥⊥ V |W. Blocking is a
graphicali criterionj
i d j
associated with d-separation [Pearl, 2009]. A probability distribution is said to be faithful to a graph if and
only if every conditional independence (CI) statement can be inferred from d-separation statements in the
graph. Faithfulness is a commonly used assumption in the existing work on causal discovery [Kocaoglu et al.,
2017, Hauser and Bühlmann, 2014]. We assume that the following form of the interventional faithfulness
assumption holds in our setup.
Assumption 1. Consider a set of nodes W⊆V and the stochastic intervention do(W,U) on W and any
set U⊆V\W. The conditional independence (CI) statement (X⊥⊥Y |Z) holds in the induced model
MW,U
if and only if there is a corresponding d-separation statement in post-interventional graph (X⊥⊥ Y |Z) ,
d G
W,U
where X, Y, and Z are disjoint subsets of V\W. The CI statements in the induced model are with respect
to the post-interventional joint probability distribution.
3 Possibly Optimal Arms in Causal Bandits with Unknown Causal
Graph
The optimal intervention in a causal bandit setup is not restricted to the parent set of the reward node when
the reward node Y is confounded with any node in its ancestors An(Y) [Lee and Bareinboim, 2018]. For
instance, consider SCM X = U and X = X ⊕U and reward Y = X ⊕U , where U ∼ Ber(0.5) and
1 1 2 1 2 2 2 1
U ∼Ber(0.5). Note that X and reward Y are confounded in this SCM. The optimal intervention in this
2 2
case is do(X =1) since E[Y|do(X =1)]=1. The intervention on the parent of the reward (Pa(Y)=X )
1 1 2
is suboptimal because E[Y|do(X = 0)] = E[Y|do(X = 1)] = 0.5. The example shows that it is possible
2 2
to construct SCMs where optimal intervention is on ancestors of the reward node instead of parents when
reward node is confounded with one of its ancestors. The authors in Lee and Bareinboim [2018] propose a
graphical criterion to enumerate the set of all possibly optimal arms, which they refer to as POMISs. We
revisit some definitions and results from their work.
3Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
V V V V
3 3 3 3
V V V V V V V V
1 2 1 2 1 2 1 2
Y Y Y Y
(a) G (b) G (c) G (d) G
1 2 3
Figure 1: True Causal Graph G with four other graphs each with one missing bi-directed edge.
Definition 1. (Unobserved Confounder (UC)-Territory [Lee and Bareinboim, 2018]) Consider a
causal graph G(V,E) with a reward node Y and let H be G[An(Y)]. A set of variables T⊆V(H) containing
Y is called an UC-territory on G with respect to Y if De (T)=T and CC (T)=T.
H H
A UC-territory is minimal if none of its subsets are UC-territories. A minimal UC-territory denoted by
MUCT(G,Y), can be constructed by extending a set of variables, starting from the reward {Y}, alternatively
updating the set with the c-component and descendants of the set until there is no change.
Definition 2. (Interventional Border) [Lee and Bareinboim, 2018] Let T be a minimal UC-territory
on G with respect to Y. Then, X =Pa(T)\T is called an interventional border for G w.r.t. Y denoted by
IB(G,Y).
Lemma 1. [Lee and Bareinboim, 2018] For causal graph G with reward Y, IB(G ,Y)is a POMIS, for any
W
W⊆V\{Y}.
Although the graphical characterization in Lemma 1 provides a means to enumerate the complete set of
POMISs, it comes with exponential time complexity. The authors also propose an efficient algorithm for
enumeratingallPOMISsin[LeeandBareinboim,2018]. However,thisrequiresknowingthetruecausalgraph,
and without it, one has to consider interventions on all possible subsets of nodes, which are exponentially
many. One naive approach to tackle the problem is to learn the full causal graph with all confounders to list
all POMISs. However, a question arises: Do we need to learn/detect all possible confounders since the goal is
to find POMISs and not the full graph?
Before answering the above question, we start with an example considering the causal graphs in Figure 1.
Using Lemma 1, the set of POMISs for the true graph G is I ={ϕ,{V },{V },{V },{V ,V }}. However, for
G 1 2 3 1 2
G which has the bidirected edge V ↔Y missing, the set of POMISs is I ={ϕ,{V },{V ,V }}. Also for
1 2 G1 2 1 2
G which has the bidirected edge V ↔V missing, the set of POMISs is I ={ϕ,{V },{V },{V ,V }}. In
2 1 2 G2 1 2 1 2
both cases, we miss at least one POMIS, and since it is possible to construct an SCM compatible with the
true causal graph G where any arm in POMIS is optimal, if this arm is not learned, we can suffer linear regret
Lee and Bareinboim [2018]. Although the graph G has the bidirected edge V ↔V missing, it still has the
3 1 3
same set of POMISs as the true graph, i.e., I ={ϕ,{V },{V },{V },{V ,V }}. This example shows that
G3 1 2 3 1 2
only a subset of latent confounders affect the POMISs learned from the graph. We formally prove that it is
necessary and sufficient to learn/detect all latent variables between the reward and its ancestors because
missing any one of them will cause us to miss at least one of POMISs leading to linear regret for some bandit
instances.
Lemma 2. It is necessary to learn/detect the latent confounders between reward node Y and any node
X ∈An(Y) in causal graph G to learn all the POMISs correctly and hence avoid linear regret.
Theorem 1. Consider a causal graph G(V,E) and another causal graph G′ such that they have the same
vertex set and directed edges but differ in bidirected edges, with the bidirected edges in G′ being a subset of the
bidirected edges in G. The graphs will yield different collections of POMISs if and only if there exists some
Z ∈An(Y) such that either (1) or (2) is true:
1. There is a bi-directed edge between Z and Y in G but not in G′ .
2. Neither of the graphs G′ and G have a bidirected edge between Z and Y, and there exists a bidirected
edge in G between some X ∈MUCT(G′ ,Y) and Z but not in G′.
Pa(Z),Bi(Z,G′)
4Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
We extend Lemma 2 to provide necessary and sufficient conditions in Theorem 1 characterizing all the
latent variables that need to be learned, ensuring that the POMISs learned from a sparser causal graph
match all those in the true causal graph. Suppose we have access to the induced observable subgraph G′ on
ancestors of the reward node. We can start by testing for latent confounders between Y and any node in
An(Y). Then, we need to test for latent confounders between any pair Z ∈An(Y) such that Z and Y don’t
have a bi-directed edge between them, and X ∈ MUCT(G′ ,Y) until there are no new pairs to
Pa(Z),Bi(Z,G′)
test. Theorem 1 can be useful because depending on the underlying causal graph, it saves us the number
of latent confounders we need to test. For instance, consider a causal graph that has the reward Y with n
different parent nodes, i.e., Pa(Y) = {V ,V ,...,V }, with no edges between the parents. In cases where
1 2 n
every parent of Y is confounded with Y, or when none of them is confounded with Y, we only need to test
for |An(Y)| latent variables, as implied by Theorem 1. However, in the worst-case scenario, we would need
to test (cid:0)|An(Y)|+1(cid:1) latent variables when the true graph only has the confounders V ←→ Y and V ←→ V
2 1 i i+1
for all i = 1,..,n−1. The exact number of latents we need to test can range from |An(Y)| to (cid:0)|An(Y)|+1(cid:1)
2
depending on the true graph. One issue still remains: we need a sample-efficient algorithm to learn the
inducedobservablegraphoverAn(Y)andtotestthepresenceofconfounders, whichis addressedinupcoming
sections.
4 Finite Sample Causal Discovery Algorithm
In this section, we propose a sample-efficient algorithm to learn causal graphs with latent confounders. We
propose a two-phase approach. In the first phase, the algorithm learns the observable graph structure, i.e.,
the induced graph between observed variables. In the second phase, it detects the latent confounders. In
the next section, we use the proposed discovery algorithm to construct the algorithm for causal bandits
with an unknown graph. We begin by proposing two Lemmas to learn the ancestrality relations and latent
confounders using interventions.
Lemma 3. Consider a causal graph G(V,E) and W ⊆ V. Furthermore, let X,T ∈ V\W be any two
variables. Under the faithfulness Assumption 1 (X ∈An(T)) if and only if for any w∈[K]|W|, we have
G
W
P(t|do(w))̸=P(t|do(w),do(x)) for some x,t∈[K].
Lemma 4. Consider two variables X and X such that X ∈/ An(X ) and a set of variables (Pa(X )∪
i j j i i
Pa(X )\{X })⊆WandX ,X ∈/ W. UnderthefaithfulnessAssumption1thereislatentconfounderbetween
j i i j
X and X if and only if for any w∈[K]|W|, we have P(x |do(x ),do(W=w))̸=P(x |x ,do(W=w))
i j j i j i
for some realization x ,x ∈[K].
i j
These Lemmas are modified versions of Lemma 1 in Kocaoglu et al. [2017] and Interventional Do-see
test in Kocaoglu et al. [2017], respectively. The difference between Lemma 3 and Lemma 1 in Kocaoglu
et al. [2017] is that we have an inequality test that can be used in the sample-efficient discovery instead of a
statistical independence test. The Interventional Do-see test in Kocaoglu et al. [2017] is valid for adjacent
nodes only; however, our Lemma 4 can be used to test presence of latent confounder between any pair of
nodes. This is because the condition in Lemma 4, X ∈/ An(X ), can always be satisfied for any pair by
j i
flipping the order when one node is an ancestor of the other. In order to provide theoretical guarantees on
sampling complexity, the inequality conditions are not enough; we need to assume certain gaps similar to [Lu
et al., 2021, Konobeev et al., 2023, Greenewald et al., 2019].
Assumption 2. Consider a causal graph G(V,E) and W ⊆ V. Furthermore, let X,T ∈ V\W be any
two variables. Then, we have (X ∈ An(T)) if and only if for any w ∈ [K]|W|, we have |P(t|do(w))−
G
W
P(t|do(w),do(x))|>ϵ for some x,t∈[K], where ϵ>0 is some constant.
Assumption 3. Consider two variables X and X such that X ∈/ An(X ) and a set of variables (Pa(X )∪
i j j i i
Pa(X )\{X })⊆W and X ,X ∈/ W. There is a latent confounder or a bidirected edge between X and X
j i i j i j
(cid:12) (cid:12)
if and only if for any w∈[K]|W|, we have (cid:12)P(x
j
|do(x i),do(W=w))−P(x
j
|x i,do(W=w))(cid:12)>γ for
some realization x ,x ∈[K] and some constant γ >0.
i j
5Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
Algorithm 1: Learn the Transitive Closure of the Causal Graph under any intervention, i.e., Gtc
W
Function LearnTransitiveClosure(V,W,δ ,δ ):
1 2
E=∅ , Fix some w∈[K]|W| and A = max(8, 8 )log2nK2 and B = 8 log2nK2
ϵ2 γ2 δ1 ϵ2 δ2
Get B samples from do(W=w)
Get A samples from every do(X =x ,W=w)∀X ∈V\W and ∀x ∈[K]
i i i i
for every pair X ,X ∈V\W do
i j
Use the Interventional Data to Test if (X ∈An(X ))
i j G
W
if ∃x i,x
j
∈[K]s.t.|P(cid:98)(x j|do(w))−P(cid:98)(x j|do(w),do(x i))|> 2ϵ then
E←−E∪(X ,X )
i j
return The graph’s transitive closure (V,E) and All Interventional data
End Function
Algorithm 2: Learn the Observable Graph
Function LearnObservableGraph(V,α,d ,δ ,δ ):
max 1 2
E=∅ & IData=∅
for i = 1 : 8αd log(n) do
max
W=∅
for V ∈V do
i
W←−W∪V with probability 1− 1
i 2dmax
Gtc,Data =LearnTransitiveClosure(V,W,δ ,δ )
W W 1 2
Compute the transitive reduction Tr(Gtc) & add any missing edges from Tr(Gtc) to E
W W
IData=IData∪Data (Keep Saving Interventional Data)
W
return The observable graph structure (V,E) and interventional data samples in IData
End Function
4.1 Learning the Observable Graph
We propose Algorithm 1 to learn the transitive closure under any arbitrary intervention do(W), denoted by
Gtc. WeusetheAssumption2toboundthenumberofsamplesforancestralitytests. Westartwithanempty
W
graph and add edges by running ancestrality tests for all pairs of nodes in V\W, resulting in the transitive
closure Gtc. We recall that the transitive reduction Tr(G)=(V,Er) of a DAG G =(V,E) is unique, with
W
Er ⊆E, and it can be computed in polynomial time [Aho et al., 1972]. Also, note that Tr(G)=Tr(Gtc). We
propose a randomized Algorithm 2 similar to the one proposed in Kocaoglu et al. [2017] that repeatedly uses
Algorithm 1 to learn the observable graph structure. The motivation behind the randomized Algorithm 2 is
Lemma 5 from Kocaoglu et al. [2017], which states that for any edge (X ,X ), consider a set of variables
i j
W such that {W :π(W )>π(X )&W ∈Pa(X )}⊆W where π is any total order that is consistent with
i i i i j
the partial order implied by the DAG, i.e., π(X)<π(Y) iff X ∈An(Y). In this case, the edge (X ,X ) will
i j
be present in the graph Tr(G ). Algorithm 2 randomly selects W, computes the transitive reduction of
W
the post-interventional graphs, and finally accumulates all edges found in the transitive reduction across
iterations. Algorithm 2 takes a parameter d , which must be greater than or equal to the highest degree
max
for our theoretical guarantees to hold.
Lemma 5. Suppose that the Assumption 2 holds and we have access to max(8, 8 )log2K2 samples from
ϵ2 γ2 δ1
do(X =x ,W=w) ∀x ∈[K] and 8 log2K2 samples from do(W=w) for a fixed w ∈[K]|W| and W⊆V.
i i i ϵ2 δ2
(cid:12)
Then, with probability at least 1−δ 1−δ 2, we have (X
i
∈An(X j))
G
if and only if ∃x i,x
j
∈[K]s.t.(cid:12)P(cid:98)(x
j
|
do(w))−P(cid:98)(x
j
|do(w),do(x i))(cid:12) (cid:12)> 2ϵ. W
Lemma 5 provides the sample complexity for running ancestrality tests. Algorithm 1 selects a realization
w ∈[K]|W|, takes B samples from the intervention do(W=w), and A samples from every do(X =x ,W=
i i
w) for all X ∈V\W and x ∈[K] interventions. Thus, in the worst case, Algorithm 1 requires KAn+B
i i
samples to learn the true transitive closure with high probability. We formally prove this result in the Lemma
6.
6Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
Lemma 6. Algorithm 1 learns the true transitive closure under any intervention, i.e., Gtc, with probability
W
at least 1−nδ −δ with a maximum KAn+B interventional samples. If we set δ = δ and δ = δ, then
1 2 1 2n 2 2
Algorithm 1 learns true transitive closure with probability at least 1−δ.
Algorithm 2 repeatedly calls Algorithm 1 to learn the Tr(G ) for randomly sampled W and updates the
W
edges across interventions to construct the observed graph structure. Using the sampling complexity results
from Lemma 6, we provide the sampling complexity guarantee for Algorithm 2 in Theorem 2.
Theorem2. Algorithm2learnsthetrueobservablegraphwithprobabilityatleast1− 1 −8αd log(n)(nδ +
n2dmα ax−2 max 1
δ 2) with 8αd maxlogn(KAn+B) interventional samples. If we set α = 2dmax lolo gg n( δ2+2) , δ
1
= 32αdmaδ
xnlogn
and δ = δ , then Algorithm 2 learns the true observable graph with probability at least of 1−δ.
2 32αdmaxlog (cid:16)n
(cid:17)
(We have A=max 8, 8 log2nK2 & B = 8 log2nK2 as in line 2 of Algorithm 1.)
ϵ2 γ2 δ1 ϵ2 δ2
4.2 Learning the Latent Confounders
Assumption 3 can be used to test for latents between any pair of observed variables. Note that while using
Algorithm 2, we save and return all the interventional data samples, these samples can be reused to detect
latent confounders in the next phase. For any variables X and X such that X ∈/ An(X ), we need access
i j j i
to interventional samples do(W=w) such that (Pa(X )∪Pa(X )\{X })⊆W and X &X ∈/ W. In the
i j i i j
supplementary material, we demonstrate that randomly selecting the target set W in Algorithm 2 ensures
that we have access to all such datasets for all pairs of observed variables with high probability. In addition
to simple causal effects we need to estimate the conditional causal effect of the form P(x |x ,do(W=w)).
j i
To bound the number of samples required to ensure accurate estimation of the conditional causal effects, we
rely on Assumption 4. Note that Assumption 4 does not restrict the applicability of our algorithm; it simply
assumes that under an intervention do(W=w), either the probability of observing a realization X =x is
i i
zero or is lower-bounded by some constant η >0. The role of this assumption is to bound the number of
interventional samples required for accurate estimation of the conditional causal effects.
Assumption 4. For any variable X ∈V and any intervention do(W=w) where W⊆V and w∈[K]|W|,
i
we assume that either P(x |do(W=w))=0 or P(x |do(W=w))≥η >0.
i i
Algorithm 3: Learn the Causal Graph along-with the Latent Confounders
Function LearnCausalGraph(α,d ,δ ,δ ,δ ,δ ):
max 1 2 3 4
G,IData=LearnObservableGraph(α,d ,δ ,δ )
max 1 2
C = 16 log(2n2K2)+ 1 log(2n2K2), B = 8 log2nK2
ηγ2 δ3 2η2 δ4 ϵ2 δ2
for every pair X ,X ∈V do
i j
If X ∈An(X ), swap them.
j i
Find interventional data sets do(W=w) and do(X =x ,W=w) from IData s.t.
i i
(Pa(X )∪Pa(X )\{X })⊆W and X &X ∈/ W
i j i i j
Get max(0,C−B) new samples for do(W=w)
if ∃x i,x
j
∈[K]s.t.|P(cid:98)(x j|do(x i),do(w))−P(cid:98)(x j|x i,do(w))|> γ
2
then
Add bi-directed edge X ←→X to graph G
i j
return The Causal Graph with Latent Confounders G
End Function
Lemma 7. Consider two nodes X and X s.t. X ∈/ An(X ) and suppose that Assumptions 1 3 hold and
i j j i
we have access to max(8, 8 )log2K2 samples from do(X = x ,W = w) ∀x ∈ [K] and 16 log(2K2)+
ϵ2 γ2 δ1 i i i ηγ2 δ3
1 log(2K2) samples from do(W = w) for a fixed w ∈ [K]|W| and W ⊆ V such that (Pa(X )∪Pa(X )\
2η2 δ4 i j
{X })⊆W and X &X ∈/ W. Then, with probability at least 1−δ −δ −δ , we have a latent confounder
i i j 1 3 4
between X
i
and X
j
iff ∃x i,x
j
∈[K]s.t.(cid:12) (cid:12)P(cid:98)(x j|do(x i),do(w))−P(cid:98)(x j|x i,do(w))(cid:12) (cid:12)> γ 2.
7Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
Theorem 3. Algorithm 3 learns the true causal graph with latents with probability at least 1− 2 −
n2dmα ax−2
8αd log(n)(nδ +(δ +δ +δ )) with a maximum of 8αd logn(KAn+max(B,C)) interventional
max 1 2 3 4 max
samples. If we set α= 2dmax lolo gg n( δ4+2) , δ
1
= 64αdmaδ
xnlogn
and δ
2
=δ
3
=δ
4
= 64αdmδ axlogn, then Algorithm 3
learns the true causal graph with probability at least 1−δ. (A and B are given by line 2 of Algorithm 1 and
C is given by line 3 of Algorithm 3.)
Suppose the constant gaps ϵ and γ in Assumptions 2 and 3 are close; then, we have C > 1A≥ 1B. The
η η
value of the constant 0 < η < 1 is usually small in practical scenarios, so the quantity C is much greater
than both B or A. This implies that the number of samples required to test the presence of latent variables
is greater than that required to learn ancestral relations. This is because we need to accurately estimate
conditional causal effects to detect latent variables, which requires a large number of samples compared to
simple causal effects. Theorem 1 is useful here because it shows that we do not need to test for confounders
between all pairs of nodes among ancestors of the reward node to learn the POMIS set.
5 Algorithm for Causal Bandits with Unknown Graph Structure
Algorithm 4 is the sketch of our algorithm for causal bandits with unknown graph structure. The detailed
algorithm with all steps explained is given in the supplementary material (Algorithm 6). Algorithm 4 first
learns the transitive closure of the graph Gtc to find ancestors of the reward node Y. This is because POMISs
are only subsets of An(Y). The next step is to learn the observed graph structure among the reward Y and
nodes in An(Y). Instead of detecting the presence of confounders between all pairs of nodes in An(Y) as in
Algorithm 3, we focus on identifying the necessary and sufficient ones, as characterized by Theorem 1. This
approach is more sample-efficient since it tests for fewer latent confounders. The exact saving in terms of
samples depends on the underlying causal graph and is hard to characterize in general. The last step of
Algorithm 4 is to run a simple bandit algorithm, e.g., UCB algorithm Lattimore and Szepesvári [2020], to
identify the optimal arm from the POMISs. Given that Assumptions 2, 3, and 4 hold, and the reward is
binary (Y ∈{0,1}), using the results from Lemma 6 and Theorem 3, we provide a worst-case regret bound
for Algorithm 4 in Theorem 4.
Algorithm 4: Sketch of Algorithm for causal bandits with unknown graph structure
Calculate α,δ ,δ ,δ ,δ as in Theorem 4
1 2 3 4
Gtc = LearnTransitiveClosure(W=ϕ, δ , δ)
2n n
G,IData = LearnObservableGraph(An(Y) ,α,d ,δ ,δ )
Gtc max 1 2
# Learn the bi-directed edges between reward Y and all nodes X ∈An(Y) and update G.
i
for every X ∈An(Y) do
i Gtc
G = DetectLatentConfounder(G,X ,X ,δ ,δ ,δ ,IData) (Algorithm 5)
i j 2 3 4
while There is a new pair that is tested do
Find a new pair (Z,X) s.t. Z ∈An(Y) such that Z and Y don’t have a bi-directed edge between them in
G and X ∈MUCT(G ,Y) and test for the latent and update G.
Pa(Z),Bi(Z,G)
G = DetectLatentConfounder(G,Z,X,δ ,δ ,δ ,IData)
2 3 4
Learn the set of POMISs I from the graph G (Using Algorithm 1 from [Lee and Bareinboim, 2018]).
G
Run UCB algorithm over the arm set A={Ω(I)|∀I ∈I }.
G
Theorem 4. Algorithm 4 learns the true set of POMISs with probability at least 1−2δ. Under the event
that it learns POMISs correctly, the cumulative regret is bounded as follows:
(cid:18) 8 8 (cid:19) 4n2K2 8 4nK2
R ≤Knmax , log + log +
T ϵ2 γ2 δ ϵ2 δ
(cid:18) (cid:19) (cid:18) (cid:19)
(cid:12) (cid:12) (cid:0)(cid:12) (cid:12)(cid:1) (cid:88) logT
8αd
max
KA(cid:12)An(Y)(cid:12) + max(B,C) log (cid:12)An(Y)(cid:12) + ∆
do(s)
1+
∆2
,
s∈{Ω(I)|∀I∈IG} do(s)
where A and B are given by line 2 of Algorithm 1, and C is given by line 3 of Algorithm 3 by setting
α= 2dmax(cid:12)log( δ4+ (cid:12)2) , δ 1 = (cid:12) δ (cid:12) (cid:12) (cid:12) and δ 2 =δ 3 =δ 4 = δ (cid:12) (cid:12).
log(cid:12)An(Y)(cid:12) 64αdmax(cid:12)An(Y)(cid:12)log(cid:12)An(Y)(cid:12) 64αdmaxlog(cid:12)An(Y)(cid:12)
8Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
The first three terms in the regret bound correspond to the interventional samples required to learn the
ancestors of the reward node, and then the set of POMISs (I ). The last term corresponds to the regret
G
incurred by running the UCB algorithm. The number of interventional samples used, or the regret incurred
to learn the true set of POMISs with high probability, has polynomial scaling with respect to the number of
nodes (n) in the graph. The number of POMISs, however, in the worst case, can have exponential scaling
with respect to the number of ancestors of the reward node (|An(Y)|). The advantage of sample-efficient
discovery is that it helps us reduce the action space before applying the UCB algorithm. Without discovery,
one would have to run the UCB or a standard MAB solver with exponentially many arms. For instance, if
the causal graph has n nodes, there will be (cid:80)n (cid:0)n(cid:1) Ki =(K+1)n different possible arms/interventions.
i=1 i
Figure 2: Simulations to demonstrate the advantage of Algorithm 4 over full graph discovery (Learning all
possible latents)
6 Experiments
Theorem 4 establishes the worst-case upper bound for cumulative regret when we need to test latent
confounders between all pairs of nodes within An(Y). However, Algorithm 4 selectively examines only a
subset of latent confounders sufficient to infer the true POMIS set, as outlined in Theorem 1. Although the
advantage is hard to quantify in general, we demonstrate it using simulations on randomly generated graphs.
We sample a random ordering σ among the vertices. Then, for each nth node, we determine its in-degree as
X =max(1,Bin(n−1,ρ)), followed by selecting its parents through uniform sampling from the preceding
n
nodes in the ordering. Finally, we chordalize the graph using the elimination algorithm [Koller and Friedman,
2009], employing an elimination ordering that is the reverse of σ. Additionally, we introduce a confounder
between every pair of nodes with a probability of ρ . For all the simulations, we randomly sample 50 causal
L
graphs with different values of densities ρ and ρ and assume that all variables are binary for simplicity,
L
i.e., K =2. We set the value of δ to 0.99, and the gaps γ =ϵ=0.01 and η =0.05. We plot interventional
samples used to learn the induced observable graph on An(Y) with and without latent confounders, as well
as the samples required to learn the POMIS set by Algorithm 4. The width of confidence interval is set to 2
standard deviations.
The simulation results in Figure 2 demonstrate that Algorithm 4 requires fewer samples than learning
the induced graph on An(Y), which includes all confounders. However, as ρ increases for a fixed ρ, this
L
advantage diminishes, as illustrated in Figure 2. The trend remains consistent as the default parameters
ρ and ρ are varied from 0.2,0.4, and 0.6. The plots in Figure 3 compare the exponentially growing arms
L
9Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
in causal bandits with intervention samples used by our algorithm to learn the reduced action set in the
form of POMISs. This demonstrates the major advantage of our algorithm, which, instead of exploring an
exponentially large action set as in naive UCB algorithms, uses interventions to reduce the action space to
the POMIS set before applying the UCB algorithm. Additionally, the regret incurred during the first phase
of finding the true POMIS set grows polynomially with respect to the number of nodes in the graph. The
number of arms in the POMIS set, however, can still have exponential scaling with respect to the number of
ancestors of reward node in the worst case.
(a) ρ=0.4, ρ =0.2 (b) ρ=0.4, ρ =0.4 (c) ρ=0.4, ρ =0.6
L L L
Figure 3: Simulations to demonstrate advantage of discovery for causal bandits.
(a) Nodes n=10 (b) Nodes n=15 (c) Nodes n=20
Figure 4: Cumulative regret for Algorithm 4 versus learning all possible latents (ρ=ρ =0.3).
L
We also run the UCB algorithm on the learned POMIS set and plot the cumulative regret in Figure 4.
Since the number of time steps T is on the order of 108, it is not feasible to store and plot cumulative regret
for every time step over multiple randomly sampled graphs; therefore, we downsample the cumulative regret
to show the overall trend. The downsampling, along with the large scale of the y-axis, makes the regret in the
discovery phase appear linear with a fixed slope, although it is piece-wise linear if we zoom in. Also, the UCB
phase converges very fast compared to the discovery phase because the number of POMISs for randomly
sampled graphs is small. We plot the results for graphs with 10, 15, and 20 nodes, and in all cases, we can
see the advantage of partial discovery compared to full discovery, since Algorithm 4 finds the POMIS set
with fewer samples.
7 Conclusion
Weshowthatpartialdiscoveryissufficienttoachievesublinearregretforcausalbanditswithanunknowncausal
graph containing latent confounders. Without relying on causal discovery, one must consider interventions on
all possible subsets of nodes, which is infeasible. Therefore, we propose a two-phase approach where the first
phase learns the induced subgraph on the ancestors of the reward node, along with a subset of confounders,
to construct a set of possibly optimal arms. The next phase involves applying the Upper Confidence Bound
(UCB) algorithm to the reduced action space to find the optimal arm.
8 Acknowledgment
Murat Kocaoglu acknowledges the support of NSF CAREER 2239375, IIS 2348717, Amazon Research Award
and Adobe Research.
10Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
References
Alfred V. Aho, Michael R Garey, and Jeffrey D. Ullman. The transitive reduction of a directed graph. SIAM
Journal on Computing, 1(2):131–137, 1972.
Yashas Annadani, Nick Pawlowski, Joel Jennings, Stefan Bauer, Cheng Zhang, and Wenbo Gong. Bayesdag:
Gradient-based posterior sampling for causal discovery. arXiv preprint arXiv:2307.13917, 2023.
Arnoud De Kroon, Joris Mooij, and Danielle Belgrave. Causal bandits without prior knowledge using
separating sets. In Conference on Causal Learning and Reasoning, pages 407–427. PMLR, 2022.
Muhammad Qasim Elahi, Lai Wei, Murat Kocaoglu, and Mahsa Ghasemi. Adaptive online experimental
design for causal discovery, 2024.
Kristjan Greenewald, Dmitriy Katz, Karthikeyan Shanmugam, Sara Magliacane, Murat Kocaoglu, Enric
Boix Adsera, and Guy Bresler. Sample efficient active learning of causal trees. Advances in Neural
Information Processing Systems, 32, 2019.
Alain Hauser and Peter Bühlmann. Two optimal strategies for active learning of causal models from
interventional data. International Journal of Approximate Reasoning, 55(4):926–939, 2014.
DavidHeckerman,ChristopherMeek,andGregoryCooper. Abayesianapproachtocausaldiscovery. Technical
report, Technical report msr-tr-97-05, Microsoft Research, 1997.
Murat Kocaoglu, Karthikeyan Shanmugam, and Elias Bareinboim. Experimental design for learning causal
graphs with latent variables. Advances in Neural Information Processing Systems, 30, 2017.
Daphne Koller and Nir Friedman. Probabilistic graphical models: principles and techniques. MIT press, 2009.
MikhailKonobeev,JalalEtesami,andNegarKiyavash. Causalbanditswithoutgraphlearning. arXiv preprint
arXiv:2301.11401, 2023.
Finnian Lattimore, Tor Lattimore, and Mark D Reid. Causal bandits: Learning good interventions via causal
inference. Advances in Neural Information Processing Systems, 29, 2016.
Tor Lattimore and Csaba Szepesvári. Bandit algorithms. Cambridge University Press, 2020.
Sanghack Lee and Elias Bareinboim. Structural causal bandits: Where to intervene? Advances in neural
information processing systems, 31, 2018.
Yangyi Lu, Amirhossein Meisami, Ambuj Tewari, and William Yan. Regret analysis of bandit problems
with causal background knowledge. In Conference on Uncertainty in Artificial Intelligence, pages 141–150.
PMLR, 2020.
YangyiLu,AmirhosseinMeisami,andAmbujTewari. Causalbanditswithunknowngraphstructure. Advances
in Neural Information Processing Systems, 34:24817–24828, 2021.
Alan Malek, Virginia Aglietti, and Silvia Chiappa. Additive causal bandits with unknown graph. arXiv
preprint arXiv:2306.07858, 2023.
Vineet Nair, Vishakha Patil, and Gaurav Sinha. Budgeted and non-budgeted causal bandits. In International
Conference on Artificial Intelligence and Statistics, pages 2017–2025. PMLR, 2021.
Judea Pearl. Causality. Cambridge university press, 2009.
Jonas Peters, Dominik Janzing, and Bernhard Schölkopf. Elements of causal inference: foundations and
learning algorithms. The MIT Press, 2017.
Rajat Sen, Karthikeyan Shanmugam, Alexandros G Dimakis, and Sanjay Shakkottai. Identifying best
interventions through online importance sampling. In International Conference on Machine Learning,
pages 3057–3066. PMLR, 2017.
11Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
Karthikeyan Shanmugam, Murat Kocaoglu, Alexandros G Dimakis, and Sriram Vishwanath. Learning causal
graphs with small interventions. Advances in Neural Information Processing Systems, 28, 2015.
Xinpeng Shen, Sisi Ma, Prashanthi Vemuri, and Gyorgy Simon. Challenges and opportunities with causal
discovery algorithms: application to alzheimer’s pathophysiology. Scientific reports, 10(1):2975, 2020.
Jin Tian and Judea Pearl. A general identification condition for causal effects. In Aaai/iaai, pages 567–573,
2002.
Christian Toth, Lars Lorch, Christian Knoll, Andreas Krause, Franz Pernkopf, Robert Peharz, and Julius
Von Kügelgen. Active bayesian causal inference. Advances in Neural Information Processing Systems, 35:
16261–16275, 2022.
Lai Wei, Muhammad Qasim Elahi, Mahsa Ghasemi, and Murat Kocaoglu. Approximate allocation matching
for structural causal bandits with unobserved confounders. Advances in Neural Information Processing
Systems, 36, 2024.
Alessio Zanga, Elif Ozkirimli, and Fabio Stella. A survey on causal discovery: Theory and practice.
International Journal of Approximate Reasoning, 151:101–129, 2022.
Kun Zhang, Biwei Huang, Jiji Zhang, Clark Glymour, and Bernhard Schölkopf. Causal discovery from non-
stationary/heterogeneous data: Skeleton estimation and orientation determination. In IJCAI: Proceedings
of the Conference, volume 2017, page 1347. NIH Public Access, 2017.
12Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
A Supplemental Material
A.1 Review of d-separation:
Consider three disjoint sets of nodes X, Y, and Z in the causal graph G = (V,E). The sets of nodes X
and Y are d-separated given Z, denoted by (X⊥⊥ Y|Z) , if and only if there exists no path, directed or
d G
undirected, between any node in set X and any node in set Y such that for every collider on the path, either
the collider itself or one of its descendants is included in the set Z, and no other non-collider nodes on the
path are included in the set Z. (A collider on a path is a node with both arrows converging, e.g., B is a
collider on the path ABC in A→B ←C).
A.2 Pearl’s Rules of do-Calculus (Pearl [2009]):
Let G represent the causal DAG, and let P denote the probability distribution induced by the corresponding
causal model. For any disjoint subsets of variables X,Y,Z, and W, the following rules apply:
Rule 1: (Insertion/deletion of observations):
P(y|do(x),z,w)=P(y|do(x),w) if (Y⊥⊥ Z|X,W) . (2)
d G
X
Rule 2: (Action/observation exchange):
P(y|do(x),do(z),w)=P(y|do(x),z,w) if (Y⊥⊥ Z|X,W) . (3)
d G
XZ
Rule 3: (Insertion/deletion of actions):
P(y|do(x),do(z),w)=P(y|do(x),w) if (Y⊥⊥ Z|X,W) , (4)
d G
X,Z(W)
where Z(W) is the set of nodes in Z that are not ancestors of any of the nodes in W in the graph G .
X
A.3 Function to Detect Presence of Latent Confounder:
Algorithm 5: Function to Detect Presence of Latent Confounder
Function DetectLatentConfounder(G,X ,X ,δ ,δ ,δ ,IData):
i j 2 3 4
C = 16 log(2n2K2)+ 1 log(2n2K2), B = 8 log2nK2
ηγ2 δ3 2η2 δ4 ϵ2 δ2
if X ∈An(X ) swap them.
j i
Find interventional data sets do(W=w) and do(X =x ,W=w) from IData s.t.
i i
(Pa(X )∪Pa(X )\{X })⊆W and X &X ∈/ W
i j i i j
Get max(0,B−C) new samples for do(W=w)
if ∃x i,x
j
∈[K]s.t.|P(cid:98)(x j|do(x i),do(w))−P(cid:98)(x j|x i,do(w))|> γ
2
then
Add bi-dirceted edge X ←→X to graph G
i j
return Updated Causal Graph G
End Function
A.4 Proof of Lemma 2:
Lemma. 3.2: It is necessary to learn/detect the latent confounders between reward node Y and any node
X ∈An(Y) in causal graph G to learn all the POMISs correctly and hence avoid linear regret.
Before proceeding to the proof, we recall an important result from Lee and Bareinboim [2018]: For a
causal graph G with reward variable Y, IB(G ,Y) is a POMIS for any W⊆V\Y.
W
Proof: ConsideracausalgraphG(V,E)withanodeX ∈An(Y)suchthatthereexistsalatentconfounder
between X and the reward Y. Suppose we do not detect the presence of the confounder and have access to
another causal graph G′ with everything the same as G except that there is no confounder between X and Y.
We show that there exists one such POMIS that we cannot learn from G′, which actually exists in the true
13Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
causal graph G. To prove this, consider a set of nodes W=Pa(X)∪Ch(Pa(X))∪CC(X)\{X,Y}. For the
graph G′, note that X ∈/ MUCT(G′ ,Y), and also there ∄Z ∈Ch(Pa(X))\{X} s.t. Z ∈MUCT(G′ ,Y).
W W
This implies that ∄Z ∈ Pa(X) s.t. Z ∈ IB(G′ ,Y). However, for the true graph G, we have a different
W
IB(G ,Y) for the same definition of W because it contains the bi-directed edge between X and Y, which
W
implies that X ∈MUCT(G ,Y), and as a result, Pa(X)⊆IB(G ,Y). Also, in the case Pa(X)=∅, we have
W W
a different POMIS. On this side, note that X ∈/ MUCT(G′ ,Y), which implies that along the causal path
W
from X to Y, there must be one node Z such that Z ∈MUCT(G′ ,Y), which implies either X or one of its
W
descendantson the pathfrom X to Y is inIB(G′ ,Y), whichis not thecase forG since X ∈MUCT(G ,Y).
W W
Thus, we have different interventional boundary or POMIS for the two causal graphs G and G′ given the
above choice of W, even if X has no parents.
The next step is to show that the particular POMIS IB(G ,Y) cannot be learned from the DAG
W
G′, i.e., IB(G ,Y) ̸= IB(G′ ,Y) for any W′ ⊆ V. We need to show this because of the graphical
W W′
characterization of POMISs in Lemma 1. Using the definition of W, note that Pa(X)⊆IB(G ,Y) and for
W
all Z ∈ Ch(Pa(X))\{X}, there exists either Z ∈ IB(G ,Y) or De(Z)\{Y} ∈ IB(G ,Y). Also, if there
W W
are such nodes in CC(X)\{X,Y} which do not have a path to X comprised of directed edges only, call
such set of nodes T. If T ̸=ϕ, then for all t∈T, we have either t∈IB(G ,Y) or De(t)\{Y}∈IB(G ,Y).
W W
Also, note that ∄Z ∈ De(X)∪{X} such that Z ∈ IB(G ,Y). Now consider DAG G′ with the bi-directed
W
edge between X and Y missing. Assume by contradiction ∃W′ ⊆ V such that IB(G ,Y) = IB(G′ ,Y).
W W′
This, however, using the aforementioned characterization of IB(G ,Y) implies that ∄Z ∈Ch(Pa(X))\{X}
W
such that Z ∈ MUCT(G′ ,Y) and also ∄t ∈ T such that t ∈ MUCT(G′ ,Y) using the aforementioned
W′ W′
definition of T. However, note that we need Pa(X) ⊆ IB(G′ ,Y), which under the given choice of W is
W′
only possible when X ∈MUCT(G′ ,Y), which would require is a bi-directed edge between X and Y in the
W′
DAG G′, which is a contradiction. Also, for the case when Pa(X)=ϕ, we have a contradiction because we
require the following to be true: ∄Z ∈De(X)∪{X} such that Z ∈IB(G′ ,Y). For the given choice of W,
W′
it implies that there is a bi-directed edge between X and Y in the DAG G′, which is again a contradiction.
Thus, by contradiction, we show that ∄W′ ⊆V such that G′, i.e., IB(G ,Y)̸=IB(G′ ,Y). This implies
W W′
that we will miss at least one POMIS if we do not learn or detect latent confounders between the reward
node Y and any node X ∈An(Y), and may incur linear regret. This completes the proof of Lemma 2.
A.5 Proof of Theorem 1:
Before proving Theorem 1, we state and prove another Lemma. We then extend this Lemma to prove
Theorem 1.
Lemma 8. Consider a causal graph G(V,E) and another graph G′ such that they have the same vertex set
and directed edges but differ in bidirected edges, with the bidirected edges in G′ being a subset of the bidirected
edges in G. The graphs will yield different collections of POMISs if there exists some Z ∈An(Y) such that
either (1) or (2) is true:
1. There is a bi-directed edge between Z and Y in G but not in G′ .
2. Neither of the graphs G′ and G have a bidirected edge between Z and Y, and there exists a bidirected
edge in G between some X ∈MUCT(G′ ,Y) and Z but not in G′.
Pa(Z),Bi(Z,G′)
Proof: The first half of Lemma 8, i.e., "The graphs will yield different collections of POMISs if there
exists some Z ∈ An(Y) such that there is a bi-directed edge between Z and Y in G but not in G′," is the
same as Lemma 2, and the same proof applies here. The reason is that in graph G′, we miss a latent variable
between reward and one of its ancestors, which was actually present in the true graph G. We only need
to proof the second half of Lemma 8 i.e. graphs will yield different collections of POMISs if there exists
some Z ∈ An(Y) such that (2) is true. Consider a causal graph G(V,E) and another DAG G′ such that
they have the same vertex set and directed edges, but differ in bi-directed edges. Consider a causal graph
G(V,E) and another DAG G′ such that they have the same vertex set and directed edges, but differ in
bi-directed edges. We show that if neither of the graphs G′ and G have a bidirected edge between Z and
Y, and there exists a bidirected edge in G between some X ∈MUCT(G′ ,Y) and Z, then there
Pa(Z),Bi(Z,G′)
14Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
exists one such POMIS that we cannot learn from G′, which actually exists in the true causal graph G. To
prove this, consider a set of nodes W=Pa(Z)∪Ch(Pa(Z)\An(X))∪Bi(Z,G′)\{X,Z,Y}. For the graph
G′, note that Z ∈/ MUCT(G′ ,Y), and also there ∄N ∈Ch(Pa(Z)\An(X))\{Z} s.t. N ∈MUCT(G′ ,Y).
W W
This implies that ∄N ∈ Pa(Z)\An(X) s.t. N ∈ IB(G′ ,Y). However, for the true graph G, we have a
W
different IB(G ,Y) for the same definition of W because it contains the bi-directed edge between X and
W
Z, which implies that Z ∈MUCT(G ,Y), and as a result, Pa(Z)\An(X)⊆IB(G ,Y). Also, in the case
W W
Pa(Z)\An(X)=∅, we have different a POMIS. On this side, note that Z ∈/ MUCT(G′ ,Y), which implies
W
that along the causal path from Z to Y, there must be one node N such that N ∈MUCT(G′ ,Y), which
W
implies either Z or one of its descendants on the path from Z to Y is in IB(G′ ,Y), which is not the case for
W
G since Z ∈MUCT(G ,Y). Thus, we have different interventional boundary or POMIS for the two causal
W
graphs G and G′ given the above choice of W.
The next step is to show that the particular POMIS IB(G ,Y) cannot be learned from the DAG G′, i.e.,
W
IB(G ,Y)̸=IB(G′ ,Y) for any W′ ⊆V. We need to show this because of the graphical characterization
W W′
of POMISs in Lemma 1. Using the definition of W, note that Pa(Z)\An(X) ⊆ IB(G ,Y) and for all
W
N ∈Ch(Pa(Z)\An(X))\{Z},thereexistseitherN ∈IB(G ,Y)orDe(N)\{Y}∈IB(G ,Y). Also,ifthere
W W
are such nodes in Bi(Z,G′)\{X,Z,Y} which do not have a path to Z comprising of directed edges only, call
such set of nodes T. If T ̸=ϕ, then for all t∈T, we have either t∈IB(G ,Y) or De(t)\{Y}∈IB(G ,Y).
W W
Also, notethat ∄N ∈De(Z)∪{Z}suchthatN ∈IB(G ,Y). NowconsidertheDAG G′ withthe bi-directed
W′
edgebetweenZ andY missing. Assumebycontradiction∃W′ ⊆VsuchthatIB(G ,Y)=IB(G′ ,Y). This,
W W′
however, usingtheaforementionedcharacterizationofIB(G ,Y)impliesthat∄N ∈Ch(Pa(Z)\An(X))\{Z}
W
such that N ∈ MUCT(G′ ,Y) and also ∄t ∈ T such that t ∈ MUCT(G′ ,Y) for the aforementioned
W′ W′
definition of T. However, note that we need Pa(Z)\An(X) ⊆ IB(G′ ,Y), which under the given choice
W′
of W is only possible when Z ∈ MUCT(G′ ,Y), which would require a bi-directed edge between Z and
W′
X in the DAG G′, which is a contradiction. Also, for the case when Pa(Z) = ϕ, we have a contradiction
because we require the following to be true: ∄N ∈De(Z)∪{Z} such that N ∈IB(G′ ,Y). For the given
W′
choice of W, it implies that there is a bi-directed edge between Z and X in the DAG G′, which is again a
contradiction. Thus, by contradiction, we show that ∄W′ ⊆V such that G′, i.e., IB(G ,Y)̸=IB(G′ ,Y).
W W′
This implies that we miss atleast one POMIS when either of statements (1) and (2) hold. This completes the
proof of Lemma 8.
We now proceed to the formal proof for Theorem 1:
Theorem. 3.1: Consider a causal graph G(V,E) and another DAG G′ such that they have the same vertex
set and directed edges but differ in bidirected edges, with the bidirected edges in G′ being a subset of the
bidirected edges in G. The graphs will yield different collections of POMISs if and only if there exists some
Z ∈An(Y) such that either (1) or (2) is true:
1. There is a bi-directed edge between Z and Y in G but not in G′ .
2. Neither of the graphs G′ and G have a bidirected edge between Z and Y, and there exists a bidirected
edge in G between some X ∈MUCT(G′ ,Y) and Z but not in G′.
Pa(Z),Bi(Z,G′)
Proof: One direction for Theorem 1 is proved already in Lemma 8. We only to need to prove the other
direction which is that two causal graphs G and G′ such that they have the same vertex set and directed
edges, but differ in bi-directed edges will yield same collections POMISs when neither of statements (1)
and (2) is true. Note when neither of (1) or (2) is true the graphs G and G′ might still have a different set
of bi-directed edges. We will have two possible scenarios here. Suppose G has a bi-directed edge between
some Z ∈An(Y) and some X ∈An(Y), such that there is a bi-directed edge between pair of vertices (Z,Y)
and (X,Y) in both the graphs and the bi-directed edge between X and Z is absent in G′. Further, assume
neither of statements (1) and (2) hold. In this case, despite the absence of a bi-directed edge between X
and Z in G′, the graphs will yield the same set of POMISs. This is because Z ∈/ MUCT(G ,Y) for some
W
set of nodes W only when Z ∈ W, and the same is the case for G because they share a bi-directed edge
between Z and Y. By symmetry, we have the argument hold for X as well. So, the presence or absence
of bi-directed edges between X and Z does not change the set of POMISs learned from the graph when
15Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
both X and Z are confounded with reward Y already. Thus, we can delete all such bi-directed edges one by
one from G while the set of POMISs learned from each of the intermediate causal graphs stays the same.
Consider the second scenario, where G has bi-directed edges between a node Z ∈ An(Y), such that there
is no bi-directed edge between Z and Y in both graphs (G and G′) and a node X that has the following
characteristics: X ∈ MUCT(G′ ,Y) for some set W ⊆ V but X ∈/ MUCT(G′ ,Y). However,
W Pa(Z),Bi(Z,G′)
the bi-directed edge between X and Z is absent in G′. Further, assume neither of statements (1) and (2)
hold. TheconditionX ∈MUCT(G′ ,Y)butX ∈/ MUCT(G′ ,Y)impliesthateither∃N ∈Pa(Z)
W Pa(Z),Bi(Z,G′)
such that N ∈ MUCT(G′ ,Y) or ∃N ∈ Bi(Z,G′) such that N ∈ MUCT(G′ ,Y). Since bi-directed edges
W W
in G′ are a subset of bi-directed edges in G, we have: Either ∃N ∈Pa(Z) such that N ∈MUCT(G ,Y) or
W
∃N ∈ Bi(Z,G) such that N ∈ MUCT(G ,Y). Note that any MUCT is closed under the De(.) and CC(.)
W
operations, i.e., for any MUCT, say T, we have De(T) = T and CC(T) = T. if ∃N ∈ Pa(Z) such that
N ∈MUCT(G ,Y) or ∃N ∈Bi(Z,G) such that N ∈MUCT(G ,Y), we already have Z ∈MUCT(G ,Y)
W W W
using the definition of MUCT. The bi-directed edge between X and Z will play a role only when ∄N ∈Pa(Z)
such that N ∈MUCT(G ,Y) and ∄N ∈Bi(Z,G) such that N ∈MUCT(G ,Y) for any choice of W. Recall
W W
that the given condition X ∈MUCT(G′ ,Y) but X ∈/ MUCT(G′ ,Y) already implies that either
W Pa(Z),Bi(Z,G′)
∃N ∈Pa(Z) such that N ∈MUCT(G ,Y) or ∃N ∈Bi(Z,G) such that N ∈MUCT(G ,Y). Thus absence
W W
or presence of bi-directed edge between X and Z will have no effect on POMISs learned from graph G in
this scenario as well. Combining both of the scenarios when neither of the conditions of (1) and (2) hold, all
other bi-directed edges from G, which are absent in G′, can be removed one by one from G while keeping the
POMISs learned from both the intermediate graphs the same. Since G and G′ only differ in bi-directed edges,
with bi-directed edges in G′ being a subset of those in G, eventually both graphs will become identical, which
proves the statement: Two graphs G and G′ will have the same POMISs if neither of the statements (1) or (2)
hold true. This completes the proof of the Theorem 1.
A.6 Proof of Lemma 3:
Consider a causal graph G(V,E) and W ⊆ V. Furthermore, let X,T ∈ V\W be any two variables.
Fix some realization w ∈ [K]|W|. Under post interventional faithfulness Assumption 1 we want to prove:
(X ∈An(T)) ⇐⇒ P(t|do(w))̸=P(t|do(w),do(x)) for some x,t∈[K].
G
ForwardW Direction (=⇒): (X ∈An(T)) =⇒ P(t|do(w))̸=P(t|do(w),do(x)) for some x,t∈[K].
G
By contradiction, assume P(t|do(w))=P(t|do(wW ),do(x)), ∀x,t∈[K]. This implies that P(t|do(w),do(x))=
P(t|do(w))= some function of only t and w. This implies that for the sub-model M the following CI
W,X
statementsholds: (T ⊥⊥X) . However,notethatif(X ∈An(T)) ,thenwestillhave(X ∈An(T)) .
This implies there is a direM ctW ed,X path from X to T in the post-interG vWentional graph G . ThereforeG ,Ww,Xe
W,X
have: (T ̸⊥⊥ X) . Note that under the post interventional faithfulness Assumption 1, the CI statement
d G
W,X
(T ⊥⊥ X) can hold only if the d-separation statement holds (T ⊥⊥ X) , which is clearly a
contradictM ionW .,X This completes the proof for the forward direction. d G W,X
Reverse Direction (⇐=): (X ∈An(T)) ⇐= P(t|do(w))̸=P(t|do(w),do(x)) for some x,t∈[K].
G
We prove the contrapositive statement instead,Wi.e., (X ∈/ An(T)) =⇒ P(t|do(w))=P(t|do(w),do(x)),
G
∀x,t ∈ [K]. Note that (X ∈/ An(T)) clearly implies that (X ∈/W An(T)) which implies that (T ⊥⊥
G G d
W W,X
X) . Thus, using Rule 3 of Pearl’s do calculus, we have: P(t|do(w),do(x)) = P(t|do(w)), ∀x,t ∈ [K].
G
ThisWc,oXmpletes the proof of the reverse direction.
A.7 Proof of Lemma 4:
ConsidertwovariablesX andX suchthatX ∈/ An(X )andasetofvariables(Pa(X )∪Pa(X )\{X })⊆W
i j j i i j i
and X &X ∈/ W. Fix some realization w∈[K]|W|. Under the post-interventional faithfulness Assumption
i j
1 we want to show that: There is latent confounder between X and X ⇐⇒ P(x |do(x ),do(W=w))̸=
i j j i
P(x |x ,do(W=w)) for some realization x ,x ∈[K].
j i i j
Forward Direction ( =⇒ ): There is latent confounder between X and X such that X ∈/ An(X )
i j j i
=⇒ P(x |do(x ),do(W=w))̸=P(x |x ,do(W=w)) for some realization x ,x ∈[K]. By contradiction
j i j i i j
assumeP(x |do(x ),do(W=w))=P(x |x ,do(W=w))∀x ,x ∈[K]. Recallthat: X =f (Pa(X ),U ).
j i j i i j j j j j
16Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
Since there is latent confounder between X and X call it L . Also note that L ∈ U . Define U′ :=
i j ij ij j j
U \{L }
j i,j
P(x |do(x ),do(W))=P(x |do(x ),do(pa(X )),do(pa(X )\{x }))) (5)
j i j i i j i
where the interventions do(Pa(X )) and do(Pa(X ))) are consistent with do(x ) and do(W = w). The
i j i
equation 5 holds by the application of Pearl’s do-calculus Rule 3 because, by definition of the set W, we have
(Pa(X )∪Pa(X )\{X })⊆W and X ,X ∈/ W. All the extra intervention targets can simply be deleted,
i j i i j
and we are left with intervention on X , Pa(X ), and Pa(X ).
i i j
(cid:88)
P(x |do(x ),do(W))= P(x |do(x ),do(pa(X )),do(pa(X )\{x }),U′ =u′ ,L =l )
j i j i i j i j j ij ij
u′ j,li,j
×P(U′ =u′ ,L =l ) (6)
j j ij ij
We have another application of Pearl’s do-calculus Rule 3 because interventions on observed variables
don’taffectunobservedvariables, astherearenocausal/directedpathsfromobservedtounobservedvariables.
Also we have:
P(x |x ,do(W))=P(x |x ,do(pa(X )),do(pa(X )\{x }))) (7)
j i j i i j i
The equation 7 holds by the application of Pearl’s do-calculus Rule 3 because, by definition of the set W,
we have (Pa(X )∪Pa(X )\{X })⊆W and X ,X ∈/ W. All the extra intervention targets can simply be
i j i i j
deleted, and we are left with conditioning on X =x and interventions on Pa(X ) and Pa(X ).
i i i j
(cid:88)
P(x |x ,do(W))= P(x |x ,do(pa(X )),do(pa(X )\{x }),U′ =u′ ,L =l )
j i j i i j i j j ij ij
u′ j,li,j
×P(U′ =u′ ,L =l |x ,do(pa(X )),do(pa(X )\{x })) (8)
j j ij ij i i j i
Using Pearl’s do-calculus Rule 2, we can replace the conditioning X =x with the intervention do(x ) in
i i i
P(x |x ,do(pa(X )),do(pa(X )\{x }),U′ =u′ ,L =l ) because X ∈/ An(X ) and Pa(X ) are already
j i i j i j j ij ij j i i
intervened on. Also, the latent confounder L is conditioned on, so there is no open backdoor path from X
ij i
to X . Thus, we have:
j
(cid:88)
P(x |x ,do(W))= P(x |do(x ),do(pa(X )),do(pa(X )\{x }),U′ =u′ ,L =l )
j i j i i j i j j ij ij
u′ j,li,j
×P(U′ =u′ ,L =l |x ,do(pa(X )),do(pa(X )\{x })) (9)
j j ij ij i i j i
From the Equations 6 and 9 and assumption P(x | do(x ),do(W = w)) = P(x | x ,do(W = w))
j i j i
∀x ,x ∈[K] we have:
i j
(cid:88)
P(x |do(x ),do(pa(X )),do(pa(X )\{x }),U′ =u′ ,L =l )
j i i j i j j ij ij
u′ j,li,j
(cid:18) (cid:19)
× P(U′ =u′ ,L =l |x ,do(pa(X )),do(pa(X )\{x }))−P(U′ =u′ ,L =l ) =0 (10)
j j ij ij i i j i j j ij ij
Since probabilities are non-negative, whenever P(x | do(x ),do(pa(X )),do(pa(X ) \ {x }),U′ =
j i i j i j
u′ ,L =l )>0, we must have:
j ij ij
P(U′ =u′ ,L =l |x ,do(pa(X )),do(pa(X )\{x }))=P(U′ =u′ ,L =l ). (11)
j j ij ij i i j i j j ij ij
However, since we know that L is a confounder between X and X , we have an edge L →X in the
ij i j ij i
causalgraph,whichimpliesthatunderanyinterventiondo(Z)suchthatX ∈/ Z,wemusthave(L ̸⊥⊥X )
i ij i MZ
by interventional faithfulness Assumption 1. This implies that there exists a realization x∗ and l∗ such that:
i ij
17Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
P(U′ =u′ ,L =l∗|x∗,do(pa(X )),do(pa(X )\{x }))̸=P(U′ =u′ ,L =l∗) (12)
j j ij ij i i j i j j ij ij
Now,usingthecombinationdo(W=w)andaspecialchoiceofrealizationsx∗andl∗,wemusthaveatleast
i ij
one special realization x∗ such that: P(x∗ |do(x∗),do(Pa(X )),do(Pa(X )\{x }),U′ =u′ ,L =l∗)>0.
j j i i j i j j ij ij
CombiningthiswithEquations12and10, weconcludeforsomex∗,x∗ ∈[K], wehaveP(x∗ |do(x∗),do(W=
i j j i
w))̸=P(x∗ |x∗,do(W=w)). Thus this leads to contradiction. Thus if there is a latent confounder between
j i
X and X =⇒ P(x |do(x ),do(W=w))̸=P(x |x ,do(W=w)) for some realization x ,x ∈[K]. This
i j j i j i i j
completes the proof of the forward direction.
Reverse Direction ( ⇐= ): For a pair of variables X and X such that X ∈/ An(X ), if P(x |
i j j i j
do(x ),do(W = w)) ̸= P(x | x ,do(W = w)) for some realizations x ,x ∈ [K], then there is a latent
i j i i j
confounder between X and X . We prove the contrapositive statement instead, i.e., if there is no latent
i j
confounder between X and X , then P(x | do(x ),do(W = w)) = P(x | x ,do(W = w)), ∀x ,x ∈ [K].
i j j i j i i j
Note that by construction, we have: (Pa(X )∪Pa(X )\{X })⊆W. For such choice of set W and the fact
i j i
that X ∈/ An(X ) and there is no latent confounder between X and X , we have (X ⊥⊥ X ) . Thus,
j i i j j i G
XiW
from Pearl’s do-calculus Rule 2, we have P(x |do(x ),do(W=w))=P(x |x ,do(W=w)), ∀x ,x ∈[K].
j i j i i j
This completes the proof of the reverse direction.
A.8 Proof of Lemma 5:
SupposethatAssumption2holdsandwehaveaccesstomax(8, 8 )log2K2 samplesfromdo(X =x ,W=w)
ϵ2 γ2 δ1 i i
∀x ∈ [K] and 8 log2K2 samples from do(W = w) for a fixed w ∈ [K]|W| for some W ⊆ V. We want to
shoi w that withϵ p2 robabδ i2lity at least 1−δ −δ , we have the following:
1 2
(X
i
∈An(X j))
G
W
⇐⇒ ∃x i,x
j
∈[K]s.t.(cid:12) (cid:12)P(cid:98)(x j|do(w))−P(cid:98)(x j|do(w),do(x i))(cid:12) (cid:12)> 2ϵ . (13)
Using Hoeffding’s inequality with A samples from intervention do(x ,w),
i
(cid:115)
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)P(cid:98)(x j|do(x i),do(w))−P(x j|do(x i),do(w))(cid:12) (cid:12) (cid:12)≥ 21 Alog2 δK2 w.p.atmost Kδ 1 2. (14)
1
If we choose A=max(8, 8 )log2K2, we have:
ϵ2 γ2 δ1
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)P(cid:98)(x j|do(x i),do(w))−P(x j|do(x i),do(w))(cid:12) (cid:12) (cid:12)≥ 4ϵ w.p.atmost Kδ 1 2. (15)
Similarly, using Hoeffding’s inequality with B samples from intervention do(w),
(cid:115)
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)P(cid:98)(x j|do(w))−P(x j|do(w))(cid:12) (cid:12) (cid:12)≥ 21 Alog2 δK2 w.p.atmost Kδ 2 2. (16)
1
If we choose B = 8 log2K2, we have:
ϵ2 δ2
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)P(cid:98)(x j|do(w))−P(x j|do(w))(cid:12) (cid:12) (cid:12)≥ 4ϵ w.p.atmost Kδ 2 2. (17)
Since the realization w∈[K]|W| is fixed, while x and x are in [K], we have a total of K2 possible bad
i j
events when the estimates are not accurate. Given the choice of samples, A and B, we have:
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)P(cid:98)(x j|do(x i),do(w))−P(x j|do(x i),do(w))(cid:12) (cid:12) (cid:12)≤ 4ϵ ∀x i,x j ∈[K] w.p.atleast1−δ 1, (18)
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)P(cid:98)(x j|do(w))−P(x j|do(w))(cid:12) (cid:12) (cid:12)≤ 4ϵ ∀x j ∈[K] w.p.atleast1−δ 2. (19)
Under the good event, which occurs with a probability of at least 1−δ −δ , the estimates are accurate.
1 2
We now consider the two possible scenarios. Suppose that X ∈/ An(X ) in G . In this case by Pearl’s
i j W
18Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
(cid:12) (cid:12)
do-calculus Rule 3 we have (cid:12) (cid:12)P(x j|do(x i),do(w))−P(x j|do(w))(cid:12) (cid:12)=0,∀x i,x
j
∈[K]. By triangular inequality
(cid:12) (cid:12)
we have the following:
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12)P(cid:98)(x j|do(x i),do(w))−P(cid:98)(x j|do(w))(cid:12)≤(cid:12)P(cid:98)(x j|do(x i),do(w))−P(x j|do(x i),do(w))(cid:12)+
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)P(cid:98)(x j|do(w))−P(x j|do(w))(cid:12) (cid:12) (cid:12)≤ 2ϵ ∀x i,x j ∈[K]. (20)
However,whenX ∈An(X )inG underAssumption2wemusthavesomeconfigurationsayx ,x ∈[K]
i j (cid:12) W (cid:12) i j
for any w ∈ [K]|W| such that (cid:12) (cid:12)P(x j|do(x i),do(w))−P(x j|do(w))(cid:12) (cid:12) > ϵ. By triangular inequality when
(cid:12) (cid:12)
X ∈An(X ) in G , ∃x ,x ∈[K] such that
i j W i j
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12)P(cid:98)(x j|do(x i),do(w))−P(cid:98)(x j|do(w))(cid:12)≥(cid:12)P(x j|do(x i),do(w))−P(x j|do(w))(cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
−(cid:12) (cid:12) (cid:12)P(cid:98)(x j|do(x i),do(w))−P(x j|do(x i),do(w))(cid:12) (cid:12) (cid:12)−(cid:12) (cid:12) (cid:12)P(cid:98)(x j|do(w))−P(x j|do(w))(cid:12) (cid:12) (cid:12)> 2ϵ . (21)
Thus, using Assumption 2 with the given choice of number of samples with probability at least 1−δ −δ ,
1 2
we have the following result:
(X
i
∈An(X j))
G
W
⇐⇒ ∃x i,x
j
∈[K]s.t.(cid:12) (cid:12)P(cid:98)(x j|do(w))−P(cid:98)(x j|do(w),do(x i))(cid:12) (cid:12)> 2ϵ . (22)
This completes the proof for Lemma 5.
A.9 Proof of Lemma 6:
In order to prove that Algorithm 1 learns the true transitive closure under any intervention, i.e., Gtc, we
W
recall from the proof of Lemma 5 that the test for ancestrality works with high probability under the event
that the causal effects of the form P(x |do(x ),do(w)) and P(x |do(w)) are estimated accurately with an
j i j
errorofatmost ϵ forallx ,x ∈[K]andanyfixedw∈[K]W. Now,sinceAlgorithm1takesB = 8 log2nK2
4 i j
(cid:16) (cid:17)
ϵ2 δ2
samples from do(W =w) and A=max 8, 8 log2nK2 samples from every do(X =x ,W =w) for all
ϵ2 γ2 δ1 i i
X ∈ V\W and for all x ∈ [K], the total number of intervention samples collected is clearly at most
i i
KAn+B. In order to show that Algorithm 1 learns the true transitive closure under any intervention, i.e.,
Gtc, with high probability, we must demonstrate that Algorithm 1 can estimate all causal effects with a
W
maximum error of ϵ with high probability, so that all the ancestrality tests work with high probability, as
4
implied by the proof of Lemma 5.
Using Hoeffding’s inequality with B = 8 log2nK2 samples from the intervention do(w), we have for any
X ∈V\W:
ϵ2 δ2
j
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)P(cid:98)(x j|do(w))−P(x j|do(w))(cid:12) (cid:12) (cid:12)≤ 4ϵ ∀x j ∈[K] w.p.atleast1− δ n2. (23)
Using the union bound we have the following:
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)P(cid:98)(X j =x j|do(w))−P(X j =x j|do(w))(cid:12) (cid:12) (cid:12)≤ 4ϵ ∀x j ∈[K], ∀X j ∈V\W w.p.atleast1−δ 2. (24)
(cid:16) (cid:17)
Now, consider a fixed pair X ,X ∈ V\W, and using A = max 8, 8 log2nK2 samples from the
i j ϵ2 γ2 δ1
intervention do(x ,w) for every x ∈[K], we have the following using Hoeffding’s inequality:
i i
19Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)P(cid:98)(x j|do(x i),do(w))−P(x j|do(x i),do(w))(cid:12) (cid:12) (cid:12)≤min( 4ϵ ,γ 4) ∀x i,x j ∈[K] w.p.atleast1− δ n1 (25)
Using the union bound we have the following:
(cid:12) (cid:12)
(cid:12) (cid:12) ϵ γ
(cid:12) (cid:12)P(cid:98)(x j|do(x i),do(w))−P(x j|do(x i),do(w))(cid:12) (cid:12)≤min( 4, 4)
∀x ,x ∈[K], ∀X ∈V\(W∪{X }) w.p.atleast1−δ (26)
i j j i 1
Again using the union bound over all intervention targets X ∈V we have the following:
i
(cid:12) (cid:12)
(cid:12) (cid:12) ϵ γ
(cid:12) (cid:12)P(cid:98)(x j|do(x i),do(w))−P(x j|do(x i),do(w))(cid:12) (cid:12)≤min( 4, 4)
∀x ,x ∈[K], ∀X ∈V\W, ∀X ∈V\(W∪{X }) w.p.atleast1−nδ (27)
i j i j i 1
From Equations 24 and 27, using the union bound with probability at least 1−nδ −δ , all the causal
1 2
effects are estimated within an error of ϵ from the true values, ensuring that all ancestrality tests work
4
perfectly under this good event. Thus, Algorithm 1 learns the true transitive closure under any intervention,
i.e., Gtc, with KAn+B intervention samples with probability of at least 1−nδ −δ . Also, if we set
W 1 2
δ = δ and δ = δ, then Algorithm 1 learns the true transitive closure under any intervention, i.e., Gtc
1 2n 2 2 W
(cid:16) (cid:17)
with a probability of 1−δ, with KAn+B intervention samples, where A = max 8, 8 log4n2K2 and
ϵ2 γ2 δ
B = 8 log4nK2. This completes the proof of Lemma 6.
ϵ2 δ
A.10 Proof of Theorem 2:
We start by revising the statement of Lemma 5: Algorithm 1 learns the true transitive closure under any
intervention, i.e., Gtc, with KAn+B intervention samples with a probability of at least 1−nδ −δ .
W 1 2
Algorithm2randomly samplesatargetset W andcallsAlgorithm 1tolearntheactivetruetransitiveclosure
of the post-interventional graph, i.e., Gtc. For every iteration, Algorithm 2 computes transitive reduction
W
Tr(Gtc) and updates all the edges to construct the observable graph. To prove the results in Theorem 2, we
W
rely on Lemma 5 from Kocaoglu et al. [2017], which is stated below:
Lemma 9. Kocaoglu et al. [2017] Consider a graph G with observed variables V and an intervention set
W ⊆V. Consider post-interventional observable graph G and a variable X ∈V\W. Let X ∈Pa(X )
W j i j
be such that all the parents of X above X in partial order are included in the intervention set W. This
j i
implies that {W :π(W )>π(X )&W ∈Pa(X )}⊆W . Then, the directed edge (X ,X )∈E(Tr(G )).
i i i i j i j W
The properties of transitive reduction yields Tr(G )=Tr(Gtc). Consequently, the transitive reduction of
W W
Gtc , i.e., Tr(Gtc)=Tr(G ) may be used to learn the directed edge (X ,X ).
W W W i j
(Note: E(G) denotes the edges of the graph G and π is any total order that is consistent with the partial order
implied by the DAG, i.e., π(X)<π(Y) iff X is an ancestor of Y).
Assume that the number of the direct parents of X above X is d where d ≤d . Let E (X ) be the
j i ij ij max i j
following event: X ,X ∈/ W & {W :π(W )>π(X )&W ∈Pa(X )}⊆W. The probability of this event
i j i i i i j
for one run of the outer loop in Algorithm 2 with the assumption that 2d >=2 is given by:
max
1 1 1 1 1 1
P[E (X )]= (1− )dij ≥ (1− )2dmax≥ . (28)
i j 4d2 2d 4d2 2d d2 16
max max max max max
The last inequality holds for 2d >=2 because (1− 1)x ≥0.25, ∀x≥2. Based on Lemma 9, the event
max x
E (X ) implies that the directed edge (X ,X ) will be present in Tr(Gtc) and will be learned. The outer loop
i j j j W
runs for 8αd log(n) iterations and elements of the set W are independently sampled. The probability of
max
20Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
failure, i.e., the event under consideration does not happen for all runs of the outer loop in Algorithm 2, is
bounded as follows:
1 1
P[(E i(V))c]≤(1− 16d2 max)8αdmaxlog(n) ≤e− 2dmα ax log(n) = n2dmα
ax
. (29)
For a graph with a total number of variables n, the total number of such bad events will be (cid:0)n(cid:1) since
2
a graph can have at most (cid:0)n(cid:1) edges. Using the union bound, the probability of bad event for any pair of
2
variables is given by:
(cid:18) (cid:19)
n 1 1
P[Failure]≤ × ≤ . (30)
2 n2dmα
ax
n2dmα ax−2
UndertheeventthatAlgorithm1learnsthecorrecttransitiveclosureGtc forallthe8αd lognrandomly
W max
sampled intervention sets W⊆V, the above derivation shows that we will be able to learn all edges in the
true observable graph with a probability of at least 1− 1 . Now recall the result from Lemma 5 that
n2dmα ax−2
Algorithm 1 learns the true transitive closure under any intervention, i.e., Gtc, with KAn+B intervention
W
samples with a probability of at least 1−nδ −δ . Combining the two results above using the union bound,
1 2
we have the following result:
Algorithm2learnsthetrueobservablegraphwithaprobabilityofatleast1− 1 −8αd log(n)(nδ +
n2dmα ax−2 max 1
δ 2) with a maximum 8αd maxlogn(KAn+B) interventional samples. Also, if we set α = 2dmax lolo gg n( δ2+2),
δ = δ ,andδ = δ ,thenAlgorithm2learnsthetrueobservablegraphwithaprobability
1 32αdmaxnlogn 2 32αd (cid:16)maxlogn
(cid:17)
ofatleast1−δ. WhereA=max 8, 8 log2nK2 andB = 8 log2nK2. ThiscompletestheproofofTheorem
ϵ2 γ2 δ1 ϵ2 δ2
2.
A.11 Proof of Lemma 7:
Consider two nodes X and X s.t. X ∈/ An(X ) and suppose that Assumptions 3 4 holds and we have access
i j j i
to max(8, 8 )log2K2 samples from do(X =x ,W=w) ∀x ∈[K] and 16 log(2K2)+ 1 log(2K2) from
ϵ2 γ2 δ1 i i i ηγ2 δ3 2η2 δ4
do(W=w) for a fixed w ∈[K]|W| and W⊆V such that (Pa(X )∪Pa(X )\{X })⊆W and X &X ∈/ W.
i j i i j
We want to show that, with probability at least 1−δ −δ −δ , we have the following:
1 3 4
There exists a latent confounder betweenX andX ⇐⇒
i j
∃x i,x
j
∈[K]s.t.(cid:12) (cid:12)P(cid:98)(x j|do(x i),do(w))−P(cid:98)(x j|x i,do(w))(cid:12) (cid:12)> γ 2. (31)
Using Hoeffding’s inequality with A samples from intervention do(x ,w).
i
(cid:115)
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)P(cid:98)(x j|do(x i),do(w))−P(x j|do(x i),do(w))(cid:12) (cid:12) (cid:12)≥ 21 Alog2 δK2 w.p.atmost Kδ 1 2. (32)
1
If we choose A=max(8, 8 )log2K2, we have:
ϵ2 γ2 δ1
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)P(cid:98)(x j|do(x i),do(w))−P(x j|do(x i),do(w))(cid:12) (cid:12) (cid:12)≥ γ
4
w.p.atmost Kδ 1 2. (33)
Using Hoeffding’s inequality with C samples from intervention do(x ).
i
(cid:115)
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)P(cid:98)(x j|x i,do(w))−P(x j|x i,do(w))(cid:12) (cid:12) (cid:12)≥ 2C1 log2 δK2 w.p.atmost Kδ 3 2. (34)
xi 3
WhereC isthenumberofsampleswhereX =x amongtheC samplesfortheinterventiondo(w). Note
xi i i
the we can’t directly control C and it’s value depends on the true interventions distribution P(x ,do(w))
xi i
along-with the number of samples C. Suppose if we can set C ≥ 8 log2K2, we have:
xi γ2 δ3
21Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)P(cid:98)(x j|x i,do(w))−P(x j|x i,do(w))(cid:12) (cid:12) (cid:12)≥ γ
4
w.p.atmost Kδ 3 2. (35)
We need to find the number of samples C such that C ≥ 8 log2K2. Using the Hoeffding’s bound we
have:
xi γ2 δ3
P(C ≥CP(x |do(w))−η)≥1−2e−2η2/C. (36)
xi i
(cid:113)
Let δ4 =2e−2η2/C, which implies η = C log2K2. Thus we have:
K2 2 δ4
(cid:115)
(cid:18) C 2K2 (cid:19) δ
P C ≥CP(x |do(w))− log ≥1− 4 (37)
xi i 2 δ K2
4
(cid:115)
C 2K2 δ
C ≥CP(x |do(w))− log w.p.atleast1− 4 . (38)
xi i 2 δ K2
4
Using Assumption 4, we have P(x |do(w))=0 or P(x |do(w))≥η. Note that if P(x |do(w))=0, the
i i i
event will never happen, and we don’t care about the accuracy of the estimate P(cid:98)(x j|x i,do(w)) because it is
already initialized to zero. Now the equation above can be rewritten as:
(cid:115)
C 2K2 δ
C ≥Cη− log w.p.atleast1− 4 . (39)
xi 2 δ K2
4
Since we want C ≥ 8 log2K2 with high probability, we have the following relationship:
xi γ2 δ3
(cid:115)
C 2K2 8 2K2
Cη− log ≥ log (40)
2 δ γ2 δ
4 3
Solving the equation for number of samples C we get:
4η8log(cid:16)
2 δK
32(cid:17)
+ln(cid:16) 2K2(cid:17)
+(cid:114) 8η8log(cid:16)
2 δK
32(cid:17)
ln(cid:16) 2K2(cid:17) +ln2(cid:16) 2K2(cid:17)
C ≥
γ2 δ4 γ2 δ4 δ4
(41)
4η2
In order to make the expression simpler we choose the number of samples C as follows:
4η8log(cid:16)
2 δK
32(cid:17)
+ln(cid:16) 2K2(cid:17)
+(cid:114) 8η8log(cid:16)
2 δK
32(cid:17)
ln(cid:16) 2K2(cid:17) +ln2(cid:16) 2K2(cid:17) +(cid:0)
4η8log(cid:16)
2 δK
32(cid:17)
(cid:1)2
C =
γ2 δ4 γ2 δ4 δ4 γ2
(42)
4η2
(cid:115)
4η8log(cid:16) 2 δK 32(cid:17) +ln(cid:16) 2K2(cid:17)
+
(cid:18) 4η8log(cid:16) 2 δK 32(cid:17) +ln(cid:16) 2K2(cid:17)(cid:19)2
γ2 δ4 γ2 δ4
C = (43)
4η2
4η8log(cid:16)
2 δK
32(cid:17)
+ln(cid:16) 2K2(cid:17)
C = γ2 δ4 (44)
2η2
16 2K2 1 2K2
C = log( )+ log( ) (45)
ηγ2 δ 2η2 δ
3 4
Suppose we take C samples for intervention do(w) as given above. Now, from Equations 35, 39, and 40,
using the union bound, we have the following:
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)P(cid:98)(x j|x i,do(w))−P(x j|x i,do(w))(cid:12) (cid:12) (cid:12)≥ γ
4
w.p.atmost δ 3 K+ 2δ 4. (46)
22Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
Since the realization w ∈ [K]|W| is fixed, but x ,x ∈ [K], we have a total of K2 possible bad events
i j
when estimates are not good. With the given choice of number of samples A and C, we have:
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)P(cid:98)(x j|do(x i),do(w))−P(x j|do(x i),do(w))(cid:12) (cid:12) (cid:12)≤ γ 4 ∀x j ∈[K] w.p.atleast1−δ 1. (47)
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)P(cid:98)(x j|x i,do(w))−P(x j|x i,do(w))(cid:12) (cid:12) (cid:12)≤ γ 4 ∀x i,x j ∈[K] w.p.atleast1−δ 3−δ 4. (48)
Under the good event, which has a probability of at least 1−δ −δ −δ , both estimates are accurate.
1 3 4
We now consider the two possible scenarios. Suppose that there is no latent confounder between X and X .
i j
(cid:12) (cid:12)
In this case by Lemma 4 we have (cid:12) (cid:12)P(x j|do(x i),do(w))−P(x j|x i,do(w))(cid:12) (cid:12)=0,∀x ix
j
∈[K]. By triangular
(cid:12) (cid:12)
inequality we have the following:
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12)P(cid:98)(x j|do(x i),do(w))−P(cid:98)(x j|x i,do(w))(cid:12)≤(cid:12)P(cid:98)(x j|do(x i),do(w))−P(x j|do(x i),do(w))(cid:12)+
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)P(cid:98)(x j|x ,do(w))−P(x j|x i,do(w))(cid:12) (cid:12) (cid:12)≤ γ 2 ∀x i,x j ∈[K]. (49)
However, when there is a latent confounder between X and X , in this case, under Assumption 3,
i j
(cid:12)
we must have some configuration, say x i,x
j
∈ [K], for any w ∈ [K]|W|, such that (cid:12) (cid:12)P(x j|do(x i),do(w))−
(cid:12)
(cid:12)
P(x j|x i,do(w))(cid:12) (cid:12) > γ. By triangular inequality when there is a latent confounder between X i and X j,
(cid:12)
∃x ,x ∈[K] such that:
i j
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12)P(cid:98)(x j|do(x i),do(w))−P(cid:98)(x j|x i,do(w))(cid:12)≥(cid:12)P(x j|do(x i),do(w))−P(x j|x i,do(w))(cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
−(cid:12) (cid:12) (cid:12)P(cid:98)(x j|do(x i),do(w))−P(x j|do(x i),do(w))(cid:12) (cid:12) (cid:12)−(cid:12) (cid:12) (cid:12)P(cid:98)(x j|x i,do(w))−P(x j|x i,do(w))(cid:12) (cid:12) (cid:12)> γ
2
(50)
Thus,usingAssumption3withthegivenchoiceofnumberofsampleswithprobabilityatleast1−δ −δ −δ ,
1 3 4
we have the following result:
There exists a latent confounder betweenX andX ⇐⇒
i j
∃x i,x
j
∈[K]s.t.(cid:12) (cid:12)P(cid:98)(x j|do(x i),do(w))−P(cid:98)(x j|x i,do(w))(cid:12) (cid:12)> γ 2. (51)
This completes the proof for Lemma 7.
A.12 Proof of Theorem 3:
The Algorithm 3 first calls Algorithm 2 to learn the observable graph structure. We have already proved in
Theorem 2 that Algorithm 2 learns the true observable graph with a probability of at least 1− 1 −
n2dmα ax−2
8αd log(n)(nδ +δ ) with a maximum of 8αd logn(KAn+B) interventional samples. The next
max 1 2 max
phase in Algorithm 3 is to learn/detect latent confounders between any pair of variables. For all pairs
of nodes X and X such that X ∈/ An(X ), we define a set of nodes W ⊆ V such that X ,X ∈/ S ,
i j j i ij i j i
where W = (Pa(X )∪Pa(X )\{X }). Also, note that |W | ≤ 2d . Let us define the event E =
ij i j i ij max ij
[W ⊆W & X ,X ∈/ W]. The probability of this event for one run of the outer loop in Algorithm 2 with
ij j i
the assumption that 2d ≥2 is given by:
max
23Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
1 1 1 1 1 1
P[E ]= (1− )|Wij| ≥ (1− )2dmax≥ . (52)
ij 4d2 2d 4d2 2d d2 16
max max max max max
The last inequality holds for d ≥ 2. Note that we reuse all the interventional data samples from
max
Algorithm 2 in Algorithm 3. Under Assumption 3, if the event E happens with a large enough number of
ij
samples, we can detect the presence or absence of latent confounders between X and X . The outer loop
i j
runs for 8αd log(n) iterations, and the elements of the set W are independently sampled. The probability
max
of failure, i.e., the event under consideration does not happen for all runs of the outer loop in Algorithm 2, is
bounded as follows:
1 1
P[E ic j]≤(1− 16d2 max)8αdmaxlog(n) ≤e− 2dmα ax log(n) = n2dmα
ax
. (53)
For a graph with a total number of variables n, the total number of such bad events will be (cid:0)n(cid:1). Using
2
the union bound, the probability of bad event for any pair of variables is given by:
(cid:18) (cid:19)
n 1 1
P[Failure]≤ × ≤ . (54)
2 n2dmα
ax
n2dmα ax−2
This implies with a probability of 1− 1 , we will be able to find an appropriate interventional dataset
to test the presence of latent
confoundn e2 rdmsα abxe− t2
ween any pair of variables using Assumption 3 after running
Algorithm 2. We still need to make sure we have enough interventional samples to be able to test the latents.
This is because we need to accurately estimate conditional effects to carry out the test, as in Assumption 3.
We first consider estimation of the causal effect P(cid:98)(x j|do(x i),do(w)) for any randomly sampled set W. Now,
(cid:16) (cid:17)
consider a fixed X ,X ∈V\W. We have access to max 8, 8 log2nK2 samples for every x ∈[K]. We
i j ϵ2 γ2 δ1 i
have already shown that under the good event, we have the following:
(cid:12) (cid:12)
(cid:12) (cid:12) ϵ γ
(cid:12) (cid:12)P(cid:98)(x j|do(x i),do(w))−P(x j|do(x i),do(w))(cid:12) (cid:12)≤min( 4, 4)
∀x ,x ∈[K], ∀X ∈V\W, ∀X ∈V\(W∪{X }) w.p.atleast1−nδ (55)
i j i j i 1
Now,weconsiderestimationoftheconditionalcausaleffects,i.e.,P(cid:98)(x j|x i,do(w)). Notethewhilerunningthe
Algorithm2wehaveaccesstoB = 8 log2nK2 samplesforminterventiondo(w)andinthestep7ofAlgorithm
ϵ2 δ2
3 we add more samples to the data set and have access to at least C = 16 log(2n2K2)+ 1 log(2n2K2)
samples instead. Now, consider a fixed X ,X ∈V\W. With access to C saη mγ2 ples asδ g3iven ab2 oη v2 e, followδ4ing
i j
from Equation 48 in the Proof of Lemma 7, we have the following result:
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)P(cid:98)(x j|x i,do(w))−P(x j|x i,do(w))(cid:12) (cid:12) (cid:12)≤ γ 4 ∀x i,x j ∈[K] w.p.atleast1− nδ 3 2 − nδ 4 2. (56)
Note that in the above equation, we have nδ3
2
and nδ4
2
instead of δ
3
and δ
4
as in Equation 48, because here
in the number of samples C, we also have nδ3
2
and nδ4
2
instead of δ
3
and δ
4
when compared to the number of
samples in Equation 45. Now, using the union bound we have the following:
(cid:12) (cid:12)
(cid:12) (cid:12) γ
(cid:12) (cid:12)P(cid:98)(x j|x i,do(w))−P(x j|x i,do(w))(cid:12) (cid:12)≤
4
δ δ
∀x ,x ∈[K], ∀X ∈V\(W∪{X }) w.p.atleast1− 3 − 4. (57)
i j j i n n
Again using the union bound over all X ∈V\W we have the following:
i
24Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
(cid:12) (cid:12)
(cid:12) (cid:12) γ
(cid:12) (cid:12)P(cid:98)(x j|do(x i),do(w))−P(x j|do(x i),do(w))(cid:12) (cid:12)≤
4
∀x ,x ∈[K], ∀X ∈V\W, ∀X ∈V\(W∪{X }) w.p.atleast1−δ −δ (58)
i j i j i 3 4
This implies that under the good event, for every randomly sampled intervention set W⊆V, the estimate of
the conditional causal effect is accurate within the desired γ threshold. This would imply that the test for
4
detection of latent variables is perfect under this good event. We have already shown that to ensure we have
access to sufficient datasets to detect latent variables between any pair of nodes, the 8αd logn randomly
max
sampled target sets in Algorithm 2 are sufficient. Combining these results with the results from Theorem 2,
we have the following:
The Algorithm 3 learns the true causal graph along with all latents with a probability of at least 1−
1 − 1 −8αd log(n)(nδ +δ )−8αd log(n)(δ +δ )=1− 2 −8αd log(n)(nδ +
n2dmα ax−2 n2dmα ax−2 max 1 2 max 3 4 n2dmα ax−2 max 1
(δ +δ +δ )) with a maximum 8αd logn(KAn+max(B,C)) interventional samples. Also If we set
2 3 4 max
α = 2dmax lolo gg n( δ4+2), δ
1
= 64αdmaδ
xnlogn
and δ
2
= δ
3
= δ
4
= 64αdmδ axlogn, then Algor (cid:16)ithm 2 (cid:17)learns the true
causal graph with latents with a probability at least 1−δ. Note that: A = max 8, 8 log2nK2,B =
ϵ2 γ2 δ1
8 log2nK2,C = 16 log(2K2)+ 1 log(2K2). This completes the proof for Theorem 3.
ϵ2 δ2 ηγ2 δ3 2η2 δ4
A.13 Full Version of Algorithm 4 and Proof of Theorem 4:
Algorithm 6: Full version of Algorithm for causal bandits with unknown graph structure
Set the Parameter δ,d
max
Calculate α,δ ,δ ,δ ,δ as in Theorem 4
1 2 3 4
Gtc = LearnTransitiveClosure(W=ϕ, δ , δ)
2n n
G,IData = LearnObservableGraph(An(Y) ,α,d ,δ ,δ )
Gtc max 1 2
C = 16 log(2n2K2)+ 1 log(2n2K2) , B = 8 log2nK2
#Leaη rγ n2 the bi-δ d3irected2η e2 dges beδ t4ween rewarϵ d2 Y andδ2all nodes X ∈An(Y) and update G.
i
for every X ∈An(Y) do
i Gtc
Set X :=Y
j
Find interventional data sets do(W=w) and do(X =x ,W=w) from IData s.t.
i i
(Pa(X )∪Pa(X )\{X })⊆W and X &X ∈/ W
i j i i j
Get max(0,B−C) new samples for do(W=w)
if ∃ Ax
di
d,x
bj
i-∈ di[ rK ce] ts e. dt. e| dP(cid:98) g( ex Xj|do ←→(x
i
X),do t( ow g) r) a− phP(cid:98) G(x j|x i,do(w))|> γ
2
then
i j
while There is a new pair that is tested do
Find a new pair (Z,X) s.t. Z ∈An(Y) such that Z and Y don’t have a bi-directed edge between
them in G and X ∈MUCT(G ,Y)
Pa(Z),Bi(Z,G)
# Test for the latent between the pair (Z,X) and update G.
Set X :=Z,X :=X
i j
if X ∈An(X ) swap them.
j i
Find interventional data sets do(W=w) and do(X =x ,W=w) from IData s.t.
i i
(Pa(X )∪Pa(X )\{X })⊆W and X &X ∈/ W
i j i i j
Get max(0,B−C) new samples for do(W=w)
if ∃ Ax
di
d,x
bj
i-∈ di[ rK ec] ts e. dt. e| dP(cid:98) g( ex Xj|do ←→(x
i
X),do t( ow g) r) a− phP(cid:98) G(x j|x i,do(w))|> γ
2
then
i j
Learn the set of POMISs I from the graph G Using Algorithm 1 in Lee and Bareinboim [2018].
G
Run UCB algorithm over the arm set A={Ω(I)|∀I ∈I }.
G
Algorithm 4 or its full version (Algorithm 6) starts by learning the transitive closure of the graph, denoted
as Gtc. This is because Gtc can give us An(Y), and every possible POMIS is a subset of An(Y). Thus, we can
25Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits
restrict ourselves to ancestors of the read node. From Lemma 6, we can learn the transitive closure Gtc with
a probability of at least 1−δ with a maximum of KAn+B interventional samples by setting δ = δ and
1 2n
δ = δ. Then, Algorithm 1 learns the true transitive closure with a probability of at least 1−δ. (We have
2 2
(cid:16) (cid:17)
A=max 8, 8 log2nK2 and B = 8 log2nK2 as in line 2 of Algorithm 1). Thus, the total interventional
ϵ2 γ2 δ1 ϵ2 δ2
(cid:16) (cid:17)
samples for this step turn out to be Knmax 8, 8 log4n2K2 + 8 log4nK2.
ϵ2 γ2 δ ϵ2 δ
The next step is to learn the complete observable graph induced on the reward node and its ancestors and
then learn/detect only a subset of latent confounders which are characterized to be necessary and sufficient to
learn the true set of POMISs (Theorem 1). Although this step saves us interventional samples compared to
thefulldiscoveryAlgorithm3,whichlearns/detectslatentsbetweenallpairsofvariables,theexactsavingwill
depend on the structure of the underlying causal graph. For the regret upper bound, we can use the results
from Theorem 3 to bound the number of interventional samples for learning the true POMIS set from the
ancestors of the reward node. This implies that given the true set of ancestors of the reward An(Y), we can
(cid:18) (cid:19)
learn the true POMIS set with a probability of at least 1−δ using 8αd
max
KA(cid:12) (cid:12)An(Y)(cid:12) (cid:12)+B log(cid:0)(cid:12) (cid:12)An(Y)(cid:12) (cid:12)(cid:1)
interventions, where A and B are given by line 2 of Algorithm 1, and C is given by line 3 of Algorithm 3 by
setting α= 2dmax(cid:12)log( δ4+ (cid:12)2), δ 1 = (cid:12) δ (cid:12) (cid:12) (cid:12), and δ 2 =δ 3 =δ 4 = δ (cid:12) (cid:12).
log(cid:12)An(Y)(cid:12) 64αdmax(cid:12)An(Y)(cid:12)log(cid:12)An(Y)(cid:12) 64αdmaxlog(cid:12)An(Y)(cid:12)
The last phase is just running the UCB algorithm over the set of all possibly optimal arms, i.e., A =
(cid:18) (cid:19)
{Ω(I) | ∀I ∈ I }. This phase has a regret bound of (cid:80) ∆ 1+ logT Lattimore and
G s∈{Ω(I)|∀I∈IG} do(s) ∆2
do(s)
Szepesvári [2020]. Now combining all the results we have the following:
Algorithm 4 learns the true set of POMISs I with probability at least 1−δ−δ =1−2δ, and under the
G
good event E that it learns POMISs correctly, the cumulative regret is bounded as follows:
(cid:18) 8 8 (cid:19) 4n2K2 8 4nK2
R ≤Knmax , log + log (59)
t ϵ2 γ2 δ ϵ2 δ
(cid:18) (cid:19) (cid:18) (cid:19)
(cid:12) (cid:12) (cid:0)(cid:12) (cid:12)(cid:1) (cid:88) logT
+8αd
max
KA(cid:12)An(Y)(cid:12)+max(B,C) log (cid:12)An(Y)(cid:12) + ∆
do(s)
1+
∆2
,
s∈{Ω(I)|∀I∈IG} do(s)
where A and B are given by line 2 of Algorithm 1, and C is given by line 3 of Algorithm 3 by setting
α= 2dmax(cid:12)log( δ4+ (cid:12)2), δ 1 = (cid:12) δ (cid:12) (cid:12) (cid:12) and δ 2 =δ 3 =δ 4 = δ (cid:12) (cid:12). This completes the
log(cid:12)An(Y)(cid:12) 64αdmax(cid:12)An(Y)(cid:12)log(cid:12)An(Y)(cid:12) 64αdmaxlog(cid:12)An(Y)(cid:12)
proof of the Theorem 4.
26