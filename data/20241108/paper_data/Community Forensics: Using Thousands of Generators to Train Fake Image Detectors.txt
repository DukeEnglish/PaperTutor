Community Forensics: Using Thousands of Generators to Train
Fake Image Detectors
JeongsooPark AndrewOwens
UniversityofMichigan
Abstract
1.00
OneofthekeychallengesofdetectingAI-generatedim- 0.95
agesisspottingimagesthathavebeencreatedbypreviously
0.90
unseengenerativemodels. Wearguethatthelimiteddiver-
sityofthetrainingdataisamajorobstacletoaddressing 0.85
thisproblem, andweproposeanewdatasetthatissignif-
0.80
icantly larger and more diverse than prior work. As part
ofcreatingthisdataset,wesystematicallydownloadthou- 0.75
sandsoftext-to-imagelatentdiffusionmodelsandsample
imagesfromthem. Wealsocollectimagesfromdozensof 101 102 103
popularopensourceandcommercialmodels. Theresulting Number of Latent Diffusion Models in Training Set
datasetcontains2.7Mimagesthathavebeensampledfrom Latent Diffusion Commercial Other
4803differentmodels. Theseimagescollectivelycapturea Pixel Diffusion GAN
widerangeofscenecontent,generatorarchitectures,and Figure1.Performancevs.modeldiversity.Weuseimagessam-
imageprocessingsettings. Usingthisdataset,westudythe
pledfromdifferentnumbersofopensourcelatentdiffusionmodels
generalizationabilitiesoffakeimagedetectors. Ourexperi- intheCommunityForensicsdatasettotrainfakeimagedetectors
mentssuggestthatdetectionperformanceimprovesasthe (showninFig.2a). Asthenumberofmodelsincreases,sodoes
numberofmodelsinthetrainingsetincreases,evenwhen thedetector’sperformance,eventhoughthesemodelshavesimilar
thesemodelshavesimilararchitectures. Wealsofindthatde- designsandsametotalnumberofimages. Thisimprovementis
tectionperformanceimprovesasthediversityofthemodels largestfortestimagesfromout-of-distributiongenerativemodel
increases,andthatourtraineddetectorsgeneralizebetter classes,suchaspixel-baseddiffusionmodelsorGANs.Foreach
thanthosetrainedonotherdatasets.1 datapoint,wesample10randommodelsubsetswith100Ktraining
imageseachandreportthemeanandstandarderrorvalues.
1.Introduction low-level image processing details, such as the ways that
trainingimagesareresizedorcompressed,canstronglyin-
Our ability to automatically generate realistic images is
fluencedetectionaccuracy[126]. Asaresultofthesemodel-
quickly outpacing our ability to detect them, potentially
specificidiosyncrasies,agenerator’simagesmayevadede-
leading to a state of affairs in which neither humans nor
tection,evenwhenimagesfromarchitecturallysimilarmod-
machines can reliably tell real from fake. While the field
elsexistinthetrainingset. Thisissuehasbeenexacerbated
ofimageforensicshasbeendevelopingmethodstoaddress
bythethousandsofopensourcemodelsthatarenowavail-
this problem, existing fake image detectors still struggle
ableonline,manyofwhichextendpretrainedbasemodels
withgeneralization. Thesemethodsoftenexcelatdetecting
incomplexways.
imagesfromgeneratorsthatwerepresentintheirtraining
We hypothesize that the lack of diversity in training
sets,butfailwhengivenimagessampledfromunseenmod-
datasetsisamajorsourceoftheseshortcomings. Although
els[91,103,105,126].
today’sdatasetsoftencontainmillionsoffakeimages,they
A core challenge is dealing with the large amounts of
come from a relatively small number of generators (e.g.,
variationbetweenmodels. Eachgeneratorhasapotentially
fewerthan20modelsinanygivenpreviousworkthatweare
uniquecombinationofthearchitecture,lossfunction,and
awareof). Asaresult,thisdatafailstocapturemanysources
trainingdistribution. Evenseeminglyminordifferencesin
of variation that one might encounter in the wild. These
1https://jespark.net/projects/2024/community_forensics limitationsalsomakeitchallengingtoaccuratelybenchmark
1
4202
voN
6
]VC.sc[
1v52140.1142:viXra
PAmDreamshaper v6 Fn Samenamemodel5 Ggm LEOSAM s ilmGirl l 91
DeepFloyd VQDiffusion StyleGAN2 DiT
Pony diffusion 87 Attn Maps mist mas Plat diffusion SoteMix First avartar
StyleGANXL GuidedDiffusion Glide CIPS
Ncadg dreamshaper PhotoSomnia vFinal Nitro diffusion Textual inversion Technoalbum AnalogMadness real
(b)Manuallychosenopensourcemodels(19models)
Dalle2 MidjourneyV6 1 MidjourneyV5 2 Dalle3
Uploadmodel Lyrieldiff Vxlnsiya Nightvisionxl 0791 Albedobase xl v21 DucHaitenAnimated
FLUX dev Firefly Image2 Firefly Image3 IdeogramV1
526Mix Textual inversion Cburnett helmet co Enasswhidaly Msart 541 A can thr
(c)Commercialmodels(11models)
(a)Systematicallycollecteddiffusionmodels(4763models)
Figure2. TheCommunityForensicsdataset. Ourdatasetcontainsimagessampledfromthreetypesofgenerativemodels. (a)We
systematicallydownloadopen-sourcelatentdiffusionmodelsfromamodel-sharingcommunity[37,124].(b)Weselectpopularopensource
generatorswithavarietyofarchitecturesandtrainingprocedures.(c)Wesamplefrombothclosedandopenstate-of-the-artcommercial
models.Wepresentexampleimagesandtheircorrespondingmodelnames.
performance,sinceitiseasyforcuesthatworkwellonone Ourdatasetcontains4803distinctmodels,approximately
setofgeneratorstofailonothers. 250×morethanthepreviousforensicsdatasetsthatsample
images from generative models [9, 18, 35, 91, 126, 133],
Toaddresstheseproblems,weproposeCommunityForen-
andcoversavarietyofrecentmodeldesigns(Fig.2).
sics,adatasetthatissignificantlymorediverseandcompre-
hensivethanthoseinpriorworks(Fig.2). Ourdatasetcon- Weusethisdatasettostudygeneralizationinthegener-
tainsimagesgeneratedby: (a)thousandsofsystematically atedimagedetectionproblem. Ourexperimentssupportthe
downloadedopen-sourcelatentdiffusionmodels,(b)hand- hypothesisthatincreasingthediversityofgenerativemodels
selectedopensourcemodelswithvariousarchitectures,and used in training is important for generalization. Through
(c)state-of-the-artcommercialmodels. Weusethisdataset experiments,wefind:
toconductastudyofgeneralizationinimageforensics.
• Classifiers trained on our dataset obtain strong perfor-
Toacquirelargenumbersofmodels,wesampleimages mance, both on our newly proposed evaluations and on
fromthousandsoftext-to-imagediffusionmodelshostedon multiplepreviously-proposedbenchmarks.
apopularmodel-sharingwebsite,HuggingFace[37]. We • Adding more generative models improves performance.
exploitthefactthatthesemodelsuseacommonprogram- Fig.1demonstratestheperformanceoffakeimagedetec-
minglibrary[124]andthuscanbesampledinastandardized tion when trained on samples from varying numbers of
way. AlargefractionofthemareextensionsofStableDif- diffusionmodels. Notably,theperformanceimprovesas
fusion[102],butcollectivelycaptureavarietyofcommon moremodelsareadded,evenacrossdifferentarchitectures.
modelvariations,suchasinthearchitecture,imageprocess- • Includingdiversegenerativemodelarchitecturessignifi-
ing,andimagecontent. Wealsosampleimagesfrommany cantlyimprovesresults,sinceclassifiersdonotfullygen-
otheropensourcemodels,includingGANs[40],autoregres- eralize between generator architectures. Likewise, the
sivemodels[42],andconsistencymodels[81,117]. Tohelp performancegainfromincludinglargenumbersofimages
studyhowimagecontentaffectsclassificationperformance, fromanyparticulararchitectureisrelativelymarginal.
weprovideacorrespondingsetofrealimagesthatarede- • Standardclassifiersperformwell. Incontrasttoobserva-
signedtoresemblethegeneratedimages. Forexample,we tionsfromrecentwork,wefindthatend-to-endtrainingof
conditionthetext-to-imagemodelsusingtextobtainedby classifiersbasedonCNNsorViTsgeneralizeswell,with
captioningourrealimages. qualitativelysimilartothatofotherrecognitionproblems.
22.Relatedwork thedetector. Bammey[9]useshigh-frequencyartifactsto
Datasets for detecting generated images. A number detectgeneratedimages. However,theseapproachesmaybe
of datasets have been proposed for specifically detecting brittlesincetheartifactstheyrelyoncanbeeliminatedby
“deepfake” images containing manipulated faces [28, 64, post-processing[18]. Weinsteadapproachthisproblemina
68, 72, 103, 105, 134]. Rather than focusing on face ma- data-drivenmanner,scalingthenumberofmodels,images,
nipulation, we address of creating general-purpose meth- and architectures. Recent work has created ensembles of
ods that can detect images that have been directly pro- fakeimageclassifiers[51]. Inparallel,researchershavede-
duced by generative models. Wang et al. [126] proposed tectedtextgeneratedbylanguagemodelsusingsupervised
a widely-used dataset of CNN-generated images, mixing learning and heuristics [8, 38, 56, 66, 86, 106, 116, 122],
imagesfromGANs[10,14,59,60,94,132]withothermod- whichcloselyresemblethoseinvisualforensics. However,
els[11,12,21,71,104]. Thisworkshowedthatforensics noexistingtechniquesthatweareawareofaimtocollect
models generalize between generative models, providing comprehensivedatasetsofcommunity-createdgenerators.
motivationfortrainingonlargedatasetsofdiversegenera-
Out-of-distributiongeneralization. Ourworkisrelated
tors. However,theirclassifierwastrainedonimagesfroma
to the out-of-distribution recognition problem as it in-
singleGANandwashighlysensitivetodataaugmentation
volves generalizing to unseen generators and image pro-
parameters, and more recent work shows that it does not
cessing. A variety of approaches have been proposed for
generalizetonewermodels[17,91]. Ojhaetal.[91]intro-
this problem, based on likelihood ratios [73, 101, 128],
ducedadatasetofrecentdiffusionmodelsandfoundthat
self-supervision [48, 87, 112, 125], internal model statis-
trainingalinearclassifieronCLIPfeatures[100]extracted
tics[47,107],temperaturescaling[6,74],andviaenergy-
fromProGAN-generatedimagesperformedwell. Cozzolino basedmodels[31,34,76]. WorkbySchuhmannetal.[111]
etal.[18]extendsthisworkbystudyingtheperformance
andHendrycksetal.[49]showthatdiversetrainingdataand
ofCLIP-baseddetectorsonvariousgenerativemodelsand
dataaugmentationisimportanttoimprovingtherobustness
datasets. Epsteinetal.[35]simulateddetectingfakeimages
toout-of-distributionsamples. Ourresultsareinlinewith
inanonlinewaybytrainingadetectoruptoacertainyear
theseconclusions,aswefindthatadiversesetofgenerative
andtestingitongeneratorsreleasedafterthatyear. Zhuet
modelsandstrongeraugmentationsimprovegeneralization.
al.[133]collected1.4Mgeneratedimagesfrom8different
generators. Thesedatasets,however,onlyconsiderahandful
ofmodels(lessthan20each),limitingthegeneralizationof 3.TheCommunityForensicsDataset
theirdetectors. Weimproveupontheseworksbycollecting
Tosupportourgoalofstudyinggeneralizationingenerated
much more diverse generative models to improve the per-
image detection, we collect a dataset of images sampled
formanceandgeneralizationofthedetector. Inconcurrent
fromawiderangeofmodels(Fig.2). Ourdatasetconsists
work, Hong et al. [50] acquires user-created images from
of: (a) a large and systematically collected set of “in-the-
Midjourney and CivitAI. This strategy is complementary
wild”text-to-imagelatentdiffusionmodelsobtainedfroma
to ours: while it aims to collect in-the-wild fake images,
model-sharingwebsite,(b)hand-selectedmodelsfromother
itsdistributioniscenteredonimagesthatusersshare,and
opensourcearchitectures,and(c)closedandopenstate-of-
themodelsarenotnecessarilyidentifiable,makingitchal-
the-art commercial models. We also pair these generated
lengingtorigorouslyanalyzethedataset’scontentsandto
images with real images from other datasets. For all im-
interpretexperimentsconductedonit.
agesinourdataset,wepreservetheoriginalimageformat
Fingerprint-based image forensics methods. Classic wheneverpossible,withoutanyadditionalcompressionor
workonimageforensicsreliedonmethodsbasedonimage resizing. Thisistomitigatepotentialbiasandperformance
statistics[99]andphysicalconstraints[57],ratherthanlearn- degradationinout-of-domainsettingsduetounwantedarti-
ing. Anumberofdatasetshavebeencreatedfordetecting facts[43]. Ourdatasetcontainssignificantlymoremodels
imagesthathavebeenmanipulatedusingtraditionalmethods, than previous works (Tab. 1) and spans a wider range of
suchaswithphotoeditors[24,29,54,65,88].Recentworks architectures,processingpipelines,andsemanticcontents.
focusondetectingsyntheticimagesbyinspectingthegen-
3.1.Systematicallycollectinggenerativemodels
eratorfingerprints. Zhangetal.[131]andMarraetal.[82]
proposedidentifyingthespatialfingerprintsleftbythegen- Weperformoursystematiccollectionusingpubliclyavail-
eratortodetectsyntheticimages. Othersfocusonspectral able, open source2 models that use the Hugging Face
anomaliestodetectsyntheticimages. Duralletal.[32]and diffusers library [37, 124] because: 1) it is a popular
Dzanicetal.[33]identifiedthatCNN-generatedimagesfail libraryforcreatingtext-to-imagemodelsandiswidelyused
toreproducecertainspectralpropertiesofrealimages.Corvi
2Weusetheterm“opensource”torefertomodelswithpublicweights
etal.[17]studiesthefrequencyfingerprintsofthegenerated
andsourcecode,evenifthemodelsmaybeclosedinsomerespects(e.g.,
imagesandanalyzesthecross-architecturegeneralizationof privatetrainingdata).
3Dataset Models Images Architectures Trainingsetup
Wangetal.[126] 11 362K GAN,Perceptual,Deepfake,... ProGAN[59]vs.LSUN[129]
Ojhaetal.[91] 4∗ 10K∗ GAN,Perceptual,Diffusion,... ProGAN[59]vs.LSUN[129]
Epsteinetal.[35] 14 570K Diffusion Diffusionvs.LAION[111]
Cozzolinoetal.[18] 18 26K Diffusion LDM[102]vs.MS-COCO[75]
Synthbuster[9] 9 10K Diffusion Diffusionvs.Dresden[39]
GenImage[133] 8 1.4M Diffusion,GAN Diffusion,GANvs.Diffusion,GAN
Ours 4803 2.7M Diffusion,GAN,Autoregressive,... Manyvs.Many
Table1.Comparisonwithexistingforensicsdatasets.Wecomparethesizeofthedatasetwithexistingdatasetscontainingidentifiable
generativemodels.Weonlycountthenumberofgeneratedimages.Ourdatasetcontainssignificantlymoregenerativemodelsthanprior
works.∗:OnlycountingtheuniqueevaluationsetbyOjhaetal.[91]astheirdatasetisbasedonWangetal.[126].
byhobbyists,2)thousandsofsuchmodelsarepubliclyin- Weprovidethemodelmetadatawitheachimagetoenable
dexed,and3)itprovidesastandardinterfacebywhichwe otherpossibleforensicsforensicsapplications. Wediscuss
cansampleimages. Weprocessthemintheorderofpopular- theseinAppendixBandprovideinformationaboutimage
ity,asindicatedbythenumberofdownloads. Ourpipeline andmodellicenses.
downloads each model and extracts relevant hyperparam-
3.2.Collectingimagesfromotherarchitectures
eters (e.g., number of diffusion steps), sampling pipeline
Images from manually chosen models. To ensure that
configurations,andmetadatafromthemodel-sharingweb-
ourdatasetcontainsabroaderrangeofmodels,wemanually
page[37,124]. Wesampleimagesusingadistributionof
select19modelsfrompublicrepositoriesandsample40,738
text prompts obtained from real images (Sec. 3.3). Since
imagespermodelonaverage. Wenotethatthisnumberis
experimentssuggestthattherearediminishingreturnsfor
itselfonparwith(ormorethan)priordatasetswithidenti-
samplinglargenumbersofimagesfromanygivenmodel,we
fiable generative models. We include several GANs (e.g.,
sampleafewhundredimagesfromeachone. Imageswith
StyleGANs[61–63,109],BigGAN[10],StyleSwin[130],
NSFWcontentarefilteredoutusingasafetychecker[16].
GigaGAN[58],ProGAN[59],ProjectedGAN[108],GANs-
Weobtain4763modelswithapproximately403imageseach
former[53],SAN[118],andCIPS[7]),pixel-baseddiffusion
fromthisprocess.
models(e.g.,GLIDE[89],ADM[27],andDeepFloyd[25]),
Whilethelackofdocumentationineachmodelandthe
latentdiffusionmodels(e.g.,VQ-Diffusion[44],Diffusion
scaleofdatacollectionmakeitchallengingtoexactlycharac-
Transformers[96],andLatentFlowMatching[23]),andan
terizethemodeldesignsinthisset,theyareeitherentirely(or
autoregressivemodel(TamingTransformers[36])
almostentirely)basedonlatentdiffusion. Morespecifically,
wecategorizemodelsasbeingbasedonlatentdiffusionif Images from commercial models. We sample 15K im-
theyperformadenoisingprocessonalatentrepresentation. agesfrom11commercialmodelsusingLAION-basedcap-
3 Basedonthiscriterionandtheself-reportedtags,allmod- tionstoevaluatethegeneralizationtostate-of-the-artmodels
els in our systematically collected set appear to be based withtypicallyunknownarchitectures: DALL·E2,3[92,93],
on latent diffusion. While pixel-based diffusion models IdeogramV1,V2[5],MidjourneyV5,V6[85],FireflyIm-
alsousethediffuserslibrary(e.g.,DeepFloyd[25]),they age2,3[4],FLUX.1-dev,schnell[69],andImagen3[41].
wereincompatiblewithourautomatedgenerationpipeline.
3.3.Collectingrealimages
Werecordincompatiblemodelssuchastheseandmanually
sampleaportionofthemtoconstructanout-of-distribution Tohelpstudyhowrealimagesinfluenceforensicsmodels,
testset(Sec.3.4),orasmanually-chosenmodelsusedfor we source real images from a variety of existing datasets:
trainingdata(Sec.3.2). LAION [110], ImageNet [26], COCO [75], FFHQ [60],
WeshowexamplesofsampledimagesinFig.2. InAp- CelebA[77],MetFaces[61],AFHQ[15],Forchheim[45],
pendixD,weprovideexamplesofmodelsandinformation
IMD2020[90],LandscapesHQ[115],andVISION[114].4
fromtheirprojectpages. Thesemodelsgenerateavarietyof
3.4.Curatingtheevaluationset
differenttypesofimages,withvarioustypesofpreprocess-
We construct our evaluation set using the incompatible
ing. Forexample,alargefractionofthesemodelsadaptvari-
models from our automated sampling pipeline, commer-
ationsofapopularpretrainedlatentdiffusionmodel,Stable
cialmodels(Sec.3.2),andmanuallycollectedopensource
Diffusion[102],todifferentdownstreamapplications,and
useanumberofadaptationstrategies(e.g.,usingLoRA[52]). 4Followingcommonconventioninvisualforensics,werefertothese
imagesasrealimages,eventhoughtheymaybesynthetic(e.g.,containing
3Wenotethatthisdefinitionincludeslatentconsistencymodels[80,117], graphicdesign).Moreprecisely,ourgoalistodistinguish“AI-generated”
whicharepresentinourdataset. versionsofimagesfromtheoriginals.
4models. The evaluation set comprises 26K images sam- We construct our training set of 5.4M images by pairing
pled from 21 models not included in the training set. 2.7Mgeneratedimageswith2.7Mrealimages.
This includes our commercial models set and an ad-
Training and evaluation setup. We evaluate the mod-
ditional 11K images from 10 models: Deci Diffusion
els trained on our dataset and compare them with prior
V2 [121], GALIP [120], KandinskyV2.2 [113], Kvikon-
works [91, 126, 133]. Following prior works [91, 126],
tent[67],LCM-LoRA-SDv1.5,LCM-LoRA-SDXL,LCM-
weusethethreshold-independentmeanaverageprecision
LoRA-SSD1B[81], StableCascade[97], DF-GAN[119],
(mAP)andaccuracy(Acc.) asourevaluationmetrics. We
andHDiT[19],sampledusingRAISE[22],ImageNet[26],
computethemAPandaccuracybyaveragingtheresultsof
FFHQ[60],andCOCO[75]-basedcaptions.
eachgenerativemodel. Weusefiveevaluationsets: Wanget
The generated images are paired with the source real
al.[126],Ojhaetal.[91],Synthbuster[9],GenImage[133],
datathatareusedtopromptthegenerators. However,since
andourevaluationset. AllevaluationsetsapartfromGen-
someoftherealdatasetsdonothaveappropriatelicenses
Image[133]evaluateout-of-distributionperformanceforall
for redistribution (e.g., LAION [110, 111]), we created a
classifiers. GenImage [133] evaluation set, however, con-
publicversionofourevaluationsetbypairingthegenerated
tains the same set of generators used in training, and is
images with openly licensed COCO [75] and FFHQ [60]
an in-distribution evaluation set for their classifiers. Con-
which allow redistribution for non-commercial purposes.
cretely,theevaluationsetbyWangetal.[126]andOjhaet
The public version of our evaluation set will serve as an
al.[91,126]containsmodelssuchasDALL·E[92],Deep-
easily reproducible and shareable evaluation set that will
Fake [28], CycleGAN [132], StarGAN [14], CRN [12],
complementourdefaultset. Wewillrefertoourdefaultset
IMLE [71], SITD [11], and SAN [21] which are unseen
as the comprehensive evaluation set. We also release the
byboththeirandourclassifiers. Synthbuster[9]evaluation
instructionstoreconstructourcomprehensiveset. However,
setiscomprisedofRAISE[22]-basedsyntheticimagesof
notethatitmaynotbepossibletoexactlyreconstructthis
DALL·E[92,93],Firefly[4],Midjourney[85],Glide[89],
setinthefutureduetolinkrot.
andStableDiffusion[98,102],andismostlyoutofdistri-
3.5.Generatingimages butionforallclassifiers. GenImage[133]evaluationsetis
avalidationsplitoftheirtrainingset;anexactsamesetof
Unconditionalmodelsaresampleduntilwereachthedesired
modelsareusedintrainingtheirclassifier: Midjourney[85],
numberofimages. Forclassconditionalmodels,wesam-
StableDiffusion[102],ADM[27],Glide[89],Wukong[3],
pleanequalnumberofimagesperclass. Tosamplefrom
VQ-Diffusion[44],andBigGAN[10].
text-conditionalmodels,wegatherpromptsfrommultiple
sources to ensure semantic diversity. We obtain captions Model architecture. Building on prior works which
fromrealimages(Sec.3.3). Weeitherusecaptionsthatare mainly used CLIP-ViT [30, 55, 100] and ResNet-50 [46],
alreadypresentinthedataset(whenavailable), orweuse weconsiderViT[30]andConvNeXt[78]pretrainedmodels
BLIP [70] to generate them. The captions are then used forourclassifiers. WeuseaplainViT-Sbackbone[30]pre-
to sample synthetic images. Some models such as Giga- trainedonCLIPobjective[55,100]usingLAION-2B[111],
GAN[58]andHDiT[19]donotprovideapretrainedmodel, ImageNet 21K, and ImageNet 1K datasets [26]. We also
soweinsteadusetheirpre-generatedimages. Generatedim- experimentwithaConvNeXt-Smodel[78]pretrainedonIm-
agesaresavedinPNGformattoavoidcompressionartifacts. ageNet21KandImageNet1Kdatasets[26]. Wereplacethe
However, Firefly[4]generatedimagesare savedin JPEG classificationheadwithalinearlayerwithsigmoidactivation
formatastheirwebUIdoesnotallowdownloadinginPNG. thatoutputstheprobabilityoftheimagebeinggenerated.Un-
likepriorworks[18,91]thatfreezetheCLIP-ViTbackbone,
wetrainthebackboneend-to-end. Themodelsareobtained
4.Experiments throughtimm[13,127]libraryonHuggingFace. Weexper-
imentwithtwoinputresolutions,2242and3842,toevaluate
Weuseourdatasettoconductastudyofgeneralizationin
theimpactoftheinputresolutiononthedetector’sperfor-
visual forensics, asking a number of questions: (1) How
mance. Wedenotethedetectorwith3842 inputresolution
welldoforensicsmodelstrainedonourdatasetgeneralize
asHighres. WeimplementthemodelsusingPyTorch[95].
tounseenmodels? (2)Doesaddingmoremodelsimprove
ThehyperparametersaredetailedinAppendixC.
detectionperformance? (3)Howdoesdiversityofthetrain-
ingdataaffectperformance? (4)Whatarchitecturesanddata Data augmentation. Prior work considered augmenta-
augmentationschemesaremostsuccessful? tionsthatweredesignedtosimulatepostprocessing,suchas
flipping,cropping,Gaussianblur,andJPEGrecompression
4.1.Trainingimageforensicsmodels
totraintheirdetectors[9,18,91,126]. Weproposeanaug-
Wetrainbinaryclassifiersthatdetectgeneratedimagesusing mentationschemethatextendsthisapproachandcompareit
our dataset to study the generalization in image forensics. withpreviouslyproposedaugmentationmethods.Weexpand
5EvaluationSet(mAP) EvaluationSet(Acc)
Model Wangetal.Ojhaetal. SB GenImage Ours Wangetal.Ojhaetal. SB GenImage Ours
[126] [91] [9] [133] Comp. Public [126] [91] [9] [133] Comp. Public
Wangetal.[126] 0.897 0.696 0.516 0.642 0.535 0.600 0.714 0.527 0.508 0.533 0.509 0.517
Ojhaetal.[91] 0.939 0.957 0.620 0.797 0.630 0.656 0.791 0.821 0.532 0.641 0.543 0.548
GenImage[133] 0.929 0.984 0.813 0.999 0.938 0.968 0.795 0.966 0.719 0.990 0.857 0.886
Ours 0.964 0.991 0.904 0.990 0.979 0.977 0.873 0.950 0.818 0.946 0.895 0.888
Ours-Highres. 0.967 0.996 0.974 0.998 0.991 0.994 0.901 0.970 0.908 0.957 0.925 0.912
Table2.GeneralizationofAI-generatedimagedetectorsacrossdatasets.Weevaluatetheclassifierstrainedonourdatasetonseveral
datasets,includingourown.Wealsoevaluateseveralpreviouslyreleasedclassifiers.OurComprehensiveset(abbreviatedasComp.)pairs
thegeneratedimageswithoriginalrealdata;thePublicsetpairsthemwithopenlylicensedCOCO[75]andFFHQ[60]forlicense-compliant
redistributionoftheevaluationset(Sec.3.4). WeuseplainCLIP-ViT-S[30,55,100]architecturewith2242and3842(Highres.) input
resolutions,Wangetal.[126]andGenImage[133]useResNet-50[46]with2242inputresolution,andOjhaetal.[91]usesCLIP-ViT-L
with2242inputresolutionasthebackbone.Ourclassifiersshowrobustperformanceacrossallevaluationsets,outperformingallbaselines
inout-of-distributionevaluations([9,91,126]andOurs)whilenearlymatchingGenImage[133]onitsin-distributionevaluationset.
1.00 mAP Acc
0.75 0.95 0.85
0.50 0.90
0.80
0.25 0.85
0.00 0.80 1000 Random Models 0.75 1000 Random Models
Latent Diff. Pixel Diff. Commercial GAN Other
10 Popular Models 10 Popular Models
Wang et al. Ojha et al. GenImage Ours Ours - High res.
3K 27K 243K 3K 27K 243K
Figure3.Performanceacrossgeneratortypes.Weevaluatethe Number of Images in Training Set Number of Images in Training Set
classifierperformanceacrossfivegeneratortypes–latentdiffusion, Figure4.Performancewithincreasingnumberofimages.We
pixeldiffusion,commercialmodels,GANs,andotherarchitecture trainaclassifierwithvaryingnumbersofimagesfromtwosets:
(StableCascade[97]). Ourclassifiersshowrobustperformance 1000randomlychosenmodelsand10popular(highlydownloaded)
acrossallgeneratortypes,wherepriorworksstruggletogeneralize. modelsinthesystematicallycollectedsubset.Theclassifiertrained
from1000randommodelsoutperforms10popularmodelsinall
thesetofaugmentationstohandleadditionaltransformations cases.Notably,theaccuracygapiswiderthanthatofmAP,which
thatcanoccurinthewild,suchaspadding,resizing,rota- maysuggestthathavingdiversityinthemodelsimprovesaccuracy
tion, and shear, and integrate them into a framework that thresholdcalibration.Wereportthemeanandstandarderrorvalues
canapplycomplexsequencesoftransformations. Weintro- foreachdatapointacross4randomlysampledsubsets.
duceamodifiedversionofRandAugment[20]thatappliesa
randomly-orderedsequenceofaugmentationstotheimages. ourcomprehensiveevaluationsetwithasignificantmargin
Specifically,ourmodifiedRandAugmentsamplesarandom comparedtopriorworks. Thisgapinperformancecanbe
numbernbetween0andn foreachaugmentationtype. tracedtoourtrainingdatawhichincorporatesasubstantially
max
Then,itappliestheaugmentationsinrandomorderuntiln richervarietyofgeneratorscomparedtopriorworks. Conse-
augmentationsareappliedforeachaugmentationtypetothe quently,ourclassifiersdemonstraterobustgeneralizationto
image. Weusevariousaugmentations,includingin-memory out-of-distributiondata,wherepriorworksoftenstruggle.
JPEGcompression,randomresizingwithrandominterpola- Tobetterillustratethegeneralizationoftheclassifiers,we
tionmethods,cropping,flipping,rotation,translation,shear, showtheperformancepereachgeneratortypeinFigure3.
padding,andcutout. Wegroupthemintofivesubsets: latentdiffusion,pixeldiffu-
sion,commercialmodels,GANs,andotherarchitecturetype
4.2.Generalizationtootherdatasets
(StableCascade[97]). Ourclassifiersshowstrongperfor-
Wefirstevaluatehowwellclassifierstrainedonourdataset manceacrossallgeneratortypes,unlikepriorworkswhich
transfertootherbenchmarks. InTable2, weobservethat struggletogeneralizetodiversearchitectures.
ourmodelsoutperformthepriorworks[91,126,133]inall For the following experiments, we use our best-
evaluation sets except GenImage. This is expected since performingmodel(Highres.) unlessstatedotherwise.
the GenImage evaluation set is a validation split of their
4.3.Impactofmodeldiversity
trainingset;allofthegeneratorsarealreadyseenbytheir
classifier. Onallunseenevaluationsets,ourclassifiersout- Next, we examine the impact of the number of models in
perform all prior works. Notably, our classifiers achieve trainingdata. Wetrainclassifierswithimagessampledfrom
veryhighperformance(0.991mAPand92.5%accuracy)on 3to3333generatorsandevaluatethem(Fig.1). Toensure
6
PAm1.00 1.00 1.00 1.00
0.75 0.75 0.75 0.75
0.50 0.50 0.50 0.50
0.25
0.25 0.25 0.25
mAP Acc mAP Acc
mAP Acc mAP Acc
Systematic Manual Full ViT (Ours) ConvNeXt (Ours)
ViT (GenImage) ConvNeXt (GenImage) ViT ConvNeXt R:LAIONF:LAION R:OthersF:LAION
ViT (Wang) ConvNeXt (Wang) ViT (Frozen) ConvNeXt (Frozen) R:LAIONF:Others R:OthersF:Others
(a)Impactofgeneratortypediversity (b)Classifierbackbonecomparison (a)Impactoffrozenbackbones (b)Semanticalignmentanalysis
Figure5.(a)Performanceandmodeldiversity.Wecomparede- Figure 6. (a) Evaluating frozen backbones. Freezing thepre-
tectionperformanceforcommercialmodelsusingclassifierstrained trained backbone, a common practice in prior works ([18, 91]),
on different subsets of the dataset: the systematically collected consistentlydecreasestheperformance.(b)Analyzingsourceand
latentdiffusionmodels,themanuallychosenmodelscontaining generateddataalignment. Weevaluatehowthepairingofthe
diversegeneratortypes,andboth.Asdiversityincreases,sodoes realdatasetsaffectsperformance.Rdenotestherealdatasetusedin
performance.(b)Classifierbackbonecomparison.Wecompare training,andFindicatesthesourcedatasetusedtoobtainthecap-
thearchitecturesacrossdatasets:ours,GenImage[133],andWang tionsforpromptingthegenerators.Theresultssuggestthatpairing
etal.[126].Performanceissimilarbetweenarchitectures. thesourcedata(i.e.,realdatausedtopromptthegenerators)with
thegeneratedimagesisnotessentialforperformance.
thatthegainsarenotduetosimplysamplingqualitatively
differentarchitectures,weonlyuseoursystematicallycol- showsstrongerperformancecomparedtotheonetrainedon
lectedlatentdiffusionmodels. Weuseanextendedevalua- thesystematicset. Additionally,wefindthatthetwosetsare
tionsetthatincludesnon-latentdiffusiongeneratorsfromour complementary;theperformanceisfurtherimprovedwhen
trainingset,whichallowsustocomprehensivelyassessthe wetrainusingbothsets.
generalizationcapabilityoftheclassifierstrainedexclusively
4.4.Analysisofdesignchoices
on latent diffusion models. We find that the performance
Weexaminetheimpactofvariousdesignchoices,including
steadilyincreaseswiththenumberofmodels. However,the
somesuggestedinearlierworks. Inparticular,weinvesti-
performancebeginstoflattenoutbeyond1000models,sug-
gatethechoiceofbackbonemodels,freezingthebackbone,
gestingdiminishingreturns. Interestingly,theperformance
semanticalignmentbetweentherealandgenerateddata,and
improvesevenonout-of-distributionarchitecturessuchas
robustnesstotransformations.
GANsand pixel-based diffusionmodels, eventhough the
classifierisonlytrainedonlatentdiffusionmodels. Classifierbackbonecomparison. Wecomparetheperfor-
InFigure4,wevarythenumberofimagesfromtwosets: manceoftheclassifiertrainedusingCLIP-ViT[30,55,100]
1000randomlychosenmodelsand10popularmodels(as andConvNeXt[78]backbonesfollowingourtrainingpro-
denotedbytheirnumberofdownloads)downloadedfrom cedureinFigure5b. Weexaminethreedatasets: ours,Gen-
oursystematicallycollecteddiffusionmodels. Whilethere- Image [133], and Wang et al. [126]. We observe similar
sultsshowthattheperformanceimproveswithmoretraining performancebetweenarchitecturesacrossalldatasets.
images,itbeginstoplateauatapproximately27Kimages.
Frozenbackbone. Priorworks[18,91]suggestedusing
Moreover,theclassifiertrainedon1000modelsoutperforms
a frozen CLIP-ViT backbone for training the classifiers.
the10modelsinallcases,indicatingthatmodeldiversity
Weinvestigatethispracticebytrainingtheclassifierswith
isimportantforstrongperformance. Wealsonotethatthe
bothfrozenandunfrozenpretrainedbackbones,usingCLIP-
accuracygapisnoticeablywiderthanthatofmAP,which
ViT [30, 55, 100] and ConvNeXt [78]. As shown in Fig-
maysuggestthatmodeldiversityiscrucialincalibratingthe
ure6a,freezingthebackboneconsistentlyleadstopoorer
accuracythresholdsoftheclassifiers.
performance,indicatingthatend-to-endtrainingiscrucialto
Our experiments show that the performance improve-
achievinghighperformance.
mentsfromincreasingthenumberofmodelsmayplateau
whentheyarelimitedtoasinglegeneratortype(Fig.1). In Semanticalignment. Existingworksoftenpairthegener-
Figure5a,weshowthatthediversityofthegeneratortype atedimageswiththesourcedataset(i.e.,therealdatasetused
alsoplaysamajorroleingeneralization. Wetrainclassifiers topromptorgeneratetheimages)arguingthatmisaligned
onthreedifferentsetsoftrainingdata: oursystematically datacanintroducebias[9,18,91,126]. Wetestthispractice
collectedset,manuallychosenset,andafullsetconsisting inFig.6bbyexaminingtheperformancewithbothseman-
ofbothsubsets. Thesystematicsetcomprisesentirelyofla- tically aligned and misaligned real datasets. Specifically,
tentdiffusionmodels,andthemanualsetcontainsnumerous we consider two real datasets: one comprised exclusively
generatortypes,includingGANs,latentandpixel-baseddif- fromLAION[110]andanothercombiningImageNet[26],
fusion,andautoregressivemodels(Sec.3.2). Theclassifier MS-COCO[75],LandscapesHQ[115],Forchheim[45],VI-
trainedonthemanualsetwithmorediversegeneratortypes SION[114],andIMD2020[90]. Wesampleoursystemati-
7Shear Padding Gaussian Blur Whileweonlyfocusongeneratedimagedetectioninour
1.00 1.00 1.00 paper,ourdatasetmayenablefurtherforensicsstudiesthat
0.75 0.75 0.75 cantakeadvantageofourdiversearrayofgenerators. For
0.50 0.50 0.50 example,inAppendixA,weshowapreliminaryresultin
15 30 45 60 75 0.250.500.751.001.25 0.5 0.9 1.3 1.7 2.0 identifyingthegeneratorusedtosynthesizeagivenimage.
fraction
JPEG Rotation Resize Wedonotintendforourdatasettobeusedtotrainclassi-
1.00 1.00 1.00
fiersthataredirectlyusedinthewild. Detectingin-the-wild
0.75 0.75 0.75 syntheticimagesremainsachallengingopenproblem,and
0.50 0.50 0.50 detectionerrorscanhavesevereconsequences(e.g.,falsely
100 84 68 52 36 15 30 45 60 75 0.150.300.450.600.75 accusinganauthorofcreatingfakeimagesorallowingmis-
quality fraction
informationtobecertifiedasreal). Wehopethatourwork
Ours GenImage Wang et al.
Ours - High Res. Ojha et al. willserveasasteppingstoneforfutureresearchinthisarea
byprovidingtoolsandinsightsforstudyinggeneralization
Figure7.Robustnesstovarioustransformations.Ourclassifiers
displayrobustperformanceacrosstransformations. Otherworks anddatacollectionstrategies.
generallyshowmoresensitivitytothesefactors.
Limitations. Whileourdatasetisdiverse,alargeportion
ofthedataisdiffusion-based,especiallymodelsfine-tuned
callycollectedlatentdiffusionmodelsusingthesetwosets
onStableDiffusion[102]. However,wenotethatFigure1
andcategorizethegeneratedimagesbytheirsourcedataset.
showsthatclassifierstrainedonlyondiffusionmodelsstill
Theresultingchangesintheperformanceofallpairswere
generalizereasonablywelltoothergeneratortypesasthey
marginal, suggesting that strict alignment may not be as
representdifferentsemanticcontent. Futureworkmaycon-
criticalaspreviouslybelieved.
sidercollectingmorediversemodels,includingmoreGANs,
Robustnesstotransformations. Figure7illustratesthe VQ-VAEs[123],andautoregressivemodels. Wealsonote
robustnessoftheclassifiersagainstvarioustransformations. thatthegenerativemodelssourcedfromthecommunitymay
Followingpriorworks[91,126],wetestrobustnesstoJPEG containinappropriatecontent. Whileinmanycontextsitis
compressionandGaussianblur. Additionally,weexamine importanttodetectsuchimages(andwehaveremovedim-
robustnesstorotation,resizing,padding,andshear,asthey agesflaggedbyaNSFWdetector),thesemodelsmayrequire
commonlyoccurinreal-worldscenarios. Forpadding,we furtherscrutinybeforebeingusedinotherdownstreamappli-
randomlypadthewidthorheightoftheimagewithagiven cations. Finally,althoughourexperimentssuggestthatour
fractionandscaleitbacktotheoriginalsize. Similarly,in forensicsclassifiersgeneralizetounseenmodelsbetterthan
resize,werandomlyupsampleordownsampletheheightand thoseofpreviouswork,theerrorratesforforensicsmodels
widthoftheimagebyagivenfractionandresizeitbackto arestilltoohightobeusedinmanyimportantapplications.
theoriginalsize(e.g.,iffractionis0.3,resizetheheightand
Acknowledgements. Wethankthecreatorsofthemany
widthto0.7×or1.3×andthenscaleitbacktotheoriginal
opensourcemodelsthatweusedtocollecttheCommunity
size). The results demonstrate that our models are more
Forensicsdataset. WethankChenhaoZheng,CameronJohn-
robusttotransformationsthanexistingmodels. Specifically,
son,MatthiasKirchner,DanielGeng,ZiyangChen,Ayush
GenImage[133]isnotablymoresensitivetoGaussianblur,
Shrivastava, YimingDou, ChaoFeng, ZihaoWei, Zixuan
JPEGcompression,andresizingartifacts;classifierbyOjha
Pan,InbumPark,RohitBanerjee,andAngCaoforthevalu-
etal.[91]displayssensitivitytosheartransforms,andthe
ablediscussionsandfeedback. Thisresearchwasdeveloped
onebyWangetal.[126]performspoorlyoverall.
withfundingfromtheDefenseAdvancedResearchProjects
Agency(DARPA)underContractNo. HR001120C0123.
5.Discussion
References
Inthispaper,westudiedtheproblemofgeneralizingtoun-
seen generative models in synthetic image detection. We [1] Creativemlopenrail-mlicense. https://huggingface.
proposedanewdataset,CommunityForensics,whichcon- co/spaces/CompVis/stable-diffusion-license.14
tains4803modelsand2.7Mimagescollectedfromvarious [2] Huggingface. https://huggingface.co/,2016. 15
publicsources. Westudiedtheimpactofmodeldiversityon [3] Wukong. https://xihe.mindspore.cn/modelzoo/
thegeneralizationperformanceoftheclassifiersanddemon- wukong,2022. 5
stratedthatdiversedataisacrucialfactorintrainingarobust, [4] Adobe. Firefly. https://www.adobe.com/products/
generalizableforensicsmodel. Wetrainedclassifiersonour firefly,2023. 4,5
dataset,demonstratedtheirabilitytogeneralizeonvarious [5] IdeogramAI. Ideogram. https://ideogram.ai,2024. 4
settings,andevaluatedpreviouslyproposedarchitectureand [6] RushilAnirudhandJayaramanJThiagarajan. Outofdis-
trainingpractices. tributiondetectionvianeuralnetworkanchoring. InAsian
8
PAm
PAmConference on Machine Learning, pages 32–47. PMLR, ofthe41stInternationalConferenceonMachineLearning,
2023. 3 pages9550–9575.PMLR,2024. 5,15
[7] IvanAnokhin, KirillDemochkin, TarasKhakhulin, Gleb [20] EkinDogusCubuk,BarretZoph,JonShlens,andQuocLe.
Sterkin,VictorLempitsky,andDenisKorzhenkov. Image Randaugment:Practicalautomateddataaugmentationwith
generatorswithconditionally-independentpixelsynthesis. areducedsearchspace. InAdvancesinNeuralInformation
arXivpreprintarXiv:2011.13775,2020. 4 ProcessingSystems,pages18613–18624.CurranAssociates,
[8] Anton Bakhtin, Sam Gross, Myle Ott, Yuntian Deng, Inc.,2020. 6
Marc’AurelioRanzato, andArthurSzlam. Realorfake? [21] TaoDai,JianruiCai,YongbingZhang,Shu-TaoXia,and
learningtodiscriminatemachinefromhumangeneratedtext. LeiZhang. Second-orderattentionnetworkforsingleimage
arXivpreprintarXiv:1906.03351,2019. 3 super-resolution. InProceedingsoftheIEEE/CVFconfer-
[9] QuentinBammey. Synthbuster:Towardsdetectionofdiffu- ence on computer vision and pattern recognition, pages
sionmodelgeneratedimages. IEEEOpenJournalofSignal 11065–11074,2019. 3,5
Processing,2023. 2,3,4,5,6,7 [22] Duc-TienDang-Nguyen,CeciliaPasquini,ValentinaConot-
[10] AndrewBrock,JeffDonahue,andKarenSimonyan. Large ter,andGiuliaBoato.Raise:Arawimagesdatasetfordigital
scaleGANtrainingforhighfidelitynaturalimagesynthesis. imageforensics. InProceedingsofthe6thACMmultimedia
InInternationalConferenceonLearningRepresentations, systemsconference,pages219–224,2015. 5,14
2019. 3,4,5 [23] QuanDao,HaoPhung,BinhNguyen,andAnhTran. Flow
[11] Chen Chen, Qifeng Chen, Jia Xu, and Vladlen Koltun. matchinginlatentspace. arXivpreprintarXiv:2307.08698,
Learningtoseeinthedark. InProceedingsoftheIEEEcon- 2023. 4
ferenceoncomputervisionandpatternrecognition,pages [24] TiagoJoséDeCarvalho,ChristianRiess,ElliAngelopoulou,
3291–3300,2018. 3,5 HelioPedrini,andAndersondeRezendeRocha. Exposing
[12] QifengChenandVladlenKoltun. Photographicimagesyn- digitalimageforgeriesbyilluminationcolorclassification.
thesiswithcascadedrefinementnetworks. InProceedings IEEETransactionsonInformationForensicsandSecurity,
oftheIEEEinternationalconferenceoncomputervision, 8(7):1182–1194,2013. 3
pages1511–1520,2017. 3,5 [25] DeepFloyd. Deepfloyd. https://huggingface.co/
[13] MehdiCherti,RomainBeaumont,RossWightman,Mitchell DeepFloyd/IF-I-L-v1.0,2024. 4
Wortsman,GabrielIlharco,CadeGordon,ChristophSchuh- [26] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,
mann, Ludwig Schmidt, and Jenia Jitsev. Reproducible andLiFei-Fei. Imagenet:Alarge-scalehierarchicalimage
scalinglawsforcontrastivelanguage-imagelearning. arXiv database. In2009IEEEconferenceoncomputervisionand
preprintarXiv:2212.07143,2022. 5 patternrecognition,pages248–255.Ieee,2009. 4,5,7,14,
[14] YunjeyChoi,MinjeChoi,MunyoungKim,Jung-WooHa, 15
SunghunKim,andJaegulChoo.Stargan:Unifiedgenerative [27] PrafullaDhariwalandAlexanderNichol. Diffusionmodels
adversarialnetworksformulti-domainimage-to-imagetrans- beatgansonimagesynthesis. Advancesinneuralinforma-
lation. InProceedingsoftheIEEEConferenceonComputer tionprocessingsystems,34:8780–8794,2021. 4,5
VisionandPatternRecognition,2018. 3,5 [28] BrianDolhansky,JoannaBitton,BenPflaum,JikuoLu,Russ
[15] YunjeyChoi,YoungjungUh,JaejunYoo,andJung-WooHa. Howes, MenglinWang, andCristianCantonFerrer. The
Starganv2:Diverseimagesynthesisformultipledomains. deepfakedetectionchallenge(dfdc)dataset. arXivpreprint
InProceedingsoftheIEEEConferenceonComputerVision arXiv:2006.07397,2020. 3,5
andPatternRecognition,2020. 4 [29] JingDong,WeiWang,andTieniuTan. Casiaimagetam-
[16] CompVis. Stable diffusion safety checker. https: peringdetectionevaluationdatabase. In2013IEEEChina
//huggingface.co/CompVis/stable-diffusion- summitandinternationalconferenceonsignalandinforma-
safety-checker,2022. 4 tionprocessing,pages422–426.IEEE,2013. 3
[17] RiccardoCorvi,DavideCozzolino,GiadaZingarini,Gio- [30] AlexeyDosovitskiy,LucasBeyer,AlexanderKolesnikov,
vanniPoggi, KokiNagano, andLuisaVerdoliva. Onthe Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,
detectionofsyntheticimagesgeneratedbydiffusionmodels. MostafaDehghani,MatthiasMinderer,GeorgHeigold,Syl-
InICASSP2023-2023IEEEInternationalConferenceon vainGelly,JakobUszkoreit,andNeilHoulsby. Animageis
Acoustics,SpeechandSignalProcessing(ICASSP),pages worth16x16words:Transformersforimagerecognitionat
1–5.IEEE,2023. 3 scale. ICLR,2021. 5,6,7
[18] Davide Cozzolino, Giovanni Poggi, Riccardo Corvi, [31] Yilun Du, Shuang Li, Joshua Tenenbaum, and Igor Mor-
Matthias Nießner, and Luisa Verdoliva. Raising the bar datch. Improvedcontrastivedivergencetrainingofenergy-
ofai-generatedimagedetectionwithclip. InProceedingsof based models. In International Conference on Machine
theIEEE/CVFConferenceonComputerVisionandPattern Learning,pages2837–2848.PMLR,2021. 3
Recognition,pages4356–4366,2024. 2,3,4,5,7 [32] RicardDurall,MargretKeuper,andJanisKeuper. Watch
[19] KatherineCrowson,StefanAndreasBaumann,AlexBirch, yourup-convolution:Cnnbasedgenerativedeepneuralnet-
TanishqMathewAbraham, DanielZKaplan, andEnrico worksarefailingtoreproducespectraldistributions. InPro-
Shippole. Scalablehigh-resolutionpixel-spaceimagesyn- ceedingsoftheIEEE/CVFconferenceoncomputervision
thesiswithhourglassdiffusiontransformers. InProceedings andpatternrecognition,pages7890–7899,2020. 3
9[33] TarikDzanic,KaranShah,andFreddieWitherden. Fourier [48] Dan Hendrycks, Mantas Mazeika, Saurav Kadavath, and
spectrumdiscrepanciesindeepnetworkgeneratedimages. DawnSong. Usingself-supervisedlearningcanimprove
Advancesinneuralinformationprocessingsystems,33:3022– modelrobustnessanduncertainty. InAdvancesinNeural
3032,2020. 3 InformationProcessingSystems.CurranAssociates, Inc.,
[34] Sven Elflein, Bertrand Charpentier, Daniel Zügner, and 2019. 3
StephanGünnemann. Onout-of-distributiondetectionwith [49] Dan Hendrycks, Steven Basart, Norman Mu, Saurav Ka-
energy-basedmodels,2021. 3 davath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler
[35] David C Epstein, Ishan Jain, Oliver Wang, and Richard Zhu,SamyakParajuli,MikeGuo,DawnSong,JacobStein-
Zhang.Onlinedetectionofai-generatedimages.InProceed- hardt, and Justin Gilmer. The many faces of robustness:
ingsoftheIEEE/CVFInternationalConferenceonCom- Acriticalanalysisofout-of-distributiongeneralization. In
puterVision,pages382–392,2023. 2,3,4 ProceedingsoftheIEEE/CVFInternationalConferenceon
[36] PatrickEsser,RobinRombach,andBjornOmmer. Taming ComputerVision(ICCV),pages8340–8349,2021. 3
transformersforhigh-resolutionimagesynthesis. InPro- [50] YanHongandJianfuZhang. Wildfake:Alarge-scalechal-
ceedingsoftheIEEE/CVFconferenceoncomputervision lenging dataset for ai-generated images detection. arXiv
andpatternrecognition,pages12873–12883,2021. 4 preprintarXiv:2402.11843,2024. 3
[37] Hugging Face. Hugging face diffusers library. https: [51] ShuweiHou,YanJu,ChengzheSun,ShanJia,LipengKe,
//huggingface.co/models?library=diffusers, ac- RikyZhou, AnitaNikolich, andSiweiLyu. Deepfake-o-
cessedonJune05,2022,2022. 2,3,4,15 meterv2.0:Anopenplatformfordeepfakedetection.arXiv
[38] SebastianGehrmann,HendrikStrobelt,andAlexanderM preprintarXiv:2404.13146,2024. 3
Rush. Gltr:Statisticaldetectionandvisualizationofgener-
[52] EdwardJHu,YelongShen,PhillipWallis,ZeyuanAllen-
atedtext. arXivpreprintarXiv:1906.04043,2019. 3
Zhu,YuanzhiLi,SheanWang,LuWang,andWeizhuChen.
[39] Thomas Gloe and Rainer Böhme. The’dresden image
Lora:Low-rankadaptationoflargelanguagemodels. arXiv
database’forbenchmarkingdigitalimageforensics. InPro-
preprintarXiv:2106.09685,2021. 4
ceedingsofthe2010ACMsymposiumonappliedcomputing,
[53] DrewAHudsonandLarryZitnick. Generativeadversar-
pages1584–1590,2010. 4
ialtransformers. InInternationalconferenceonmachine
[40] IanGoodfellow,JeanPouget-Abadie,MehdiMirza,Bing
learning,pages4487–4499.PMLR,2021. 4
Xu,DavidWarde-Farley,SherjilOzair,AaronCourville,and
[54] MinyoungHuh,AndrewLiu,AndrewOwens,andAlexeiA
YoshuaBengio. Generativeadversarialnets. Advancesin
Efros. Fighting fake news: Image splice detection via
NeuralInformationProcessingSystems,27,2014. 2
learnedself-consistency. InProceedingsoftheEuropean
[41] Google. Imagen 3. https://deepmind.google/
conferenceoncomputervision(ECCV),2018. 3
technologies/imagen-3,2024. 4
[55] GabrielIlharco,MitchellWortsman,RossWightman,Cade
[42] KarolGregor,IvoDanihelka,AndriyMnih,CharlesBlun-
Gordon, Nicholas Carlini, Rohan Taori, Achal Dave,
dell, and Daan Wierstra. Deep autoregressive networks.
VaishaalShankar,HongseokNamkoong,JohnMiller,Han-
InInternationalConferenceonMachineLearning,pages
nanehHajishirzi,AliFarhadi,andLudwigSchmidt. Open-
1242–1250.PMLR,2014. 2
clip,2021. Ifyouusethissoftware,pleaseciteitasbelow.
[43] PatrickGrommelt,LouisWeiss,Franz-JosefPfreundt,and
5,6,7
Janis Keuper. Fake or jpeg? revealing common biases
[56] GaneshJawahar,MuhammadAbdul-Mageed,andLaksVS
in generated image detection datasets. arXiv preprint
Lakshmanan. Automaticdetectionofmachinegenerated
arXiv:2403.17608,2024. 3
text: Acriticalsurvey. arXivpreprintarXiv:2011.01314,
[44] Shuyang Gu, Dong Chen, Jianmin Bao, Fang Wen, Bo
2020. 3
Zhang,DongdongChen,LuYuan,andBainingGuo. Vector
quantizeddiffusionmodelfortext-to-imagesynthesis. In [57] MicahKJohnsonandHanyFarid.Exposingdigitalforgeries
ProceedingsoftheIEEE/CVFConferenceonComputerVi- incomplexlightingenvironments. IEEETransactionson
sionandPatternRecognition,pages10696–10706,2022. 4, InformationForensicsandSecurity,2(3):450–461,2007. 3
5 [58] MingukKang,Jun-YanZhu,RichardZhang,JaesikPark,
[45] BenjaminHadwigerandChristianRiess. Theforchheimim- EliShechtman,SylvainParis,andTaesungPark. Scalingup
agedatabaseforcameraidentificationinthewild.InPattern gansfortext-to-imagesynthesis.InProceedingsoftheIEEE
Recognition.ICPRInternationalWorkshopsandChallenges: ConferenceonComputerVisionandPatternRecognition
VirtualEvent,January10–15,2021,Proceedings,PartVI, (CVPR),2023. 4,5
pages500–515.Springer,2021. 4,7 [59] TeroKarras,TimoAila,SamuliLaine,andJaakkoLehtinen.
[46] KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun. Progressivegrowingofgansforimprovedquality,stability,
Deepresiduallearningforimagerecognition. InProceed- and variation. In International Conference on Learning
ingsoftheIEEEconferenceoncomputervisionandpattern Representations,2018. 3,4
recognition,pages770–778,2016. 5,6 [60] TeroKarras,SamuliLaine,andTimoAila. Astyle-based
[47] DanHendrycksandKevinGimpel. Abaselinefordetect- generatorarchitectureforgenerativeadversarialnetworks.
ingmisclassifiedandout-of-distributionexamplesinneural InProceedingsoftheIEEE/CVFconferenceoncomputer
networks. InInternationalConferenceonLearningRepre- visionandpatternrecognition,pages4401–4410,2019. 3,
sentations,2016. 3 4,5,6,14,15
10[61] TeroKarras,MiikaAittala,JanneHellsten,SamuliLaine, ComputerVision–ECCV2014:13thEuropeanConference,
JaakkoLehtinen,andTimoAila. Traininggenerativead- Zurich, Switzerland, September6-12, 2014, Proceedings,
versarialnetworkswithlimiteddata. Advancesinneural PartV13,pages740–755.Springer,2014. 4,5,6,7,14
informationprocessingsystems,33:12104–12114,2020. 4 [76] WeitangLiu,XiaoyunWang,JohnOwens,andYixuanLi.
[62] TeroKarras,SamuliLaine,MiikaAittala,JanneHellsten, Energy-based out-of-distribution detection. In Advances
JaakkoLehtinen,andTimoAila. Analyzingandimprov- inNeuralInformationProcessingSystems, pages21464–
ing the image quality of stylegan. In Proceedings of the 21475.CurranAssociates,Inc.,2020. 3
IEEE/CVFconferenceoncomputervisionandpatternrecog- [77] ZiweiLiu, PingLuo, XiaogangWang, andXiaoouTang.
nition,pages8110–8119,2020. Deeplearningfaceattributesinthewild. InProceedingsof
[63] TeroKarras,MiikaAittala,SamuliLaine,ErikHärkönen, InternationalConferenceonComputerVision(ICCV),2015.
Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Alias- 4,14
freegenerativeadversarialnetworks. Advancesinneural [78] ZhuangLiu,HanziMao,Chao-YuanWu,ChristophFeicht-
informationprocessingsystems,34:852–863,2021. 4 enhofer,TrevorDarrell,andSainingXie. Aconvnetforthe
[64] HasamKhalid,ShahrozTariq,MinhaKim,andSimonWoo. 2020s. InProceedingsoftheIEEE/CVFconferenceoncom-
Fakeavceleb: A novel audio-video multimodal deepfake putervisionandpatternrecognition,pages11976–11986,
dataset. InProceedingsoftheNeuralInformationProcess- 2022. 5,7
ingSystemsTrackonDatasetsandBenchmarks,2021. 3 [79] IlyaLoshchilovandFrankHutter. Decoupledweightdecay
regularization. In International Conference on Learning
[65] P.KorusandJ.Huang. Multi-scaleanalysisstrategiesin
prnu-basedtamperinglocalization. IEEETrans.onInforma- Representations,2019. 15
tionForensics&Security,2017. 3 [80] SimianLuo,YiqinTan,LongboHuang,JianLi,andHang
Zhao. Latent consistency models: Synthesizing high-
[66] KalpeshKrishna,YixiaoSong,MarzenaKarpinska,John
resolutionimageswithfew-stepinference. arXivpreprint
Wieting,andMohitIyyer. Paraphrasingevadesdetectors
arXiv:2310.04378,2023. 4
of ai-generated text, but retrieval is an effective defense.
[81] SimianLuo,YiqinTan,SurajPatil,DanielGu,Patrickvon
Advances in Neural Information Processing Systems, 36,
Platen,ApolinárioPassos,LongboHuang,JianLi,andHang
2024. 3
Zhao. Lcm-lora:Auniversalstable-diffusionacceleration
[67] Kvikontent. Kvikontent-midjourney v6.
module. arXivpreprintarXiv:2311.05556,2023. 2,5
https://huggingface.co/Kvikontent/midjourney-v6,2023. 5
[82] FrancescoMarra,DiegoGragnaniello,LuisaVerdoliva,and
[68] Patrick Kwon, Jaeseong You, Gyuhyeon Nam, Sungwoo
GiovanniPoggi. Dogansleaveartificialfingerprints? In
Park, and Gyeongsu Chae. Kodf: A large-scale korean
2019IEEEconferenceonmultimediainformationprocess-
deepfakedetectiondataset.InProceedingsoftheIEEE/CVF
ingandretrieval(MIPR),pages506–511.IEEE,2019. 3
InternationalConferenceonComputerVision,2021. 3
[83] Leland McInnes, John Healy, Nathaniel Saul, and Lukas
[69] BlackForstLabs. Flux. https://blackforestlabs.ai,
Großberger. Umap:Uniformmanifoldapproximationand
2024. 4
projection. JournalofOpenSourceSoftware,3(29),2018.
[70] Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi.
14
Blip:Bootstrappinglanguage-imagepre-trainingforunified
[84] Paulius Micikevicius, Sharan Narang, Jonah Alben, Gre-
vision-languageunderstandingandgeneration. InICML,
goryDiamos,ErichElsen,DavidGarcia,BorisGinsburg,
2022. 5
MichaelHouston,OleksiiKuchaiev,GaneshVenkatesh,etal.
[71] KeLi,TianhaoZhang,andJitendraMalik. Diverseimage Mixedprecisiontraining. InInternationalConferenceon
synthesisfromsemanticlayoutsviaconditionalimle. In LearningRepresentations,2018. 15
ProceedingsoftheIEEE/CVFInternationalConferenceon
[85] Inc.Midjourney.Midjourney.https://www.midjourney.
ComputerVision,pages4220–4229,2019. 3,5
com/home,2022. 4,5
[72] YuezunLi,XinYang,PuSun,HonggangQi,andSiweiLyu. [86] EricMitchell,YoonhoLee,AlexanderKhazatsky,Christo-
Celeb-df: A large-scale challenging dataset for deepfake pherDManning,andChelseaFinn. Detectgpt: Zero-shot
forensics. InProceedingsoftheIEEE/CVFconferenceon machine-generatedtextdetectionusingprobabilitycurva-
computervisionandpatternrecognition,2020. 3 ture. In International Conference on Machine Learning,
[73] YewenLi,ChaojieWang,XiaoboXia,TongliangLiu,Bo pages24950–24962.PMLR,2023. 3
An, et al. Out-of-distribution detection with an adaptive [87] SinaMohseni,MandarPitale,JBSYadawa,andZhangyang
likelihoodratiooninformativehierarchicalvae. Advances Wang. Self-supervised learning for generalizable out-of-
inNeuralInformationProcessingSystems,35:7383–7396, distributiondetection. ProceedingsoftheAAAIConference
2022. 3 onArtificialIntelligence,34(04):5216–5223,2020. 3
[74] Shiyu Liang, Yixuan Li, and R Srikant. Enhancing the [88] Tian-TsongNg,Shih-FuChang,andQSun. Adatasetof
reliabilityofout-of-distributionimagedetectioninneural authenticandsplicedimageblocks. ColumbiaUniversity,
networks. InInternationalConferenceonLearningRepre- ADVENTTechnicalReport,4,2004. 3
sentations,2018. 3 [89] AlexanderQuinnNichol,PrafullaDhariwal,AdityaRamesh,
[75] Tsung-YiLin,MichaelMaire,SergeBelongie,JamesHays, Pranav Shyam, Pamela Mishkin, Bob Mcgrew, Ilya
PietroPerona,DevaRamanan,PiotrDollár,andCLawrence Sutskever, and Mark Chen. Glide: Towards photorealis-
Zitnick. Microsoftcoco: Commonobjectsincontext. In ticimagegenerationandeditingwithtext-guideddiffusion
11models. InInternationalConferenceonMachineLearning, synthesiswithlatentdiffusionmodels. InProceedingsof
pages16784–16804.PMLR,2022. 4,5 theIEEE/CVFConferenceonComputerVisionandPattern
[90] Adam Novozamsky, Babak Mahdian, and Stanislav Saic. Recognition(CVPR),pages10684–10695,2022. 2,4,5,8
Imd2020:Alarge-scaleannotateddatasettailoredfordetect- [103] AndreasRössler,DavideCozzolino,LuisaVerdoliva,Chris-
ingmanipulatedimages. InProceedingsoftheIEEE/CVF tianRiess,JustusThies,andMatthiasNießner. Faceforen-
WinterConferenceonApplicationsofComputerVisionWork- sics: A large-scale video dataset for forgery detection in
shops,pages71–80,2020. 4,7 humanfaces. arXivpreprintarXiv:1803.09179,2018. 1,3
[91] UtkarshOjha,YuhengLi,andYongJaeLee. Towardsuni- [104] AndreasRössler,DavideCozzolino,LuisaVerdoliva,Chris-
versalfakeimagedetectorsthatgeneralizeacrossgenerative tianRiess,JustusThies,andMatthiasNießner. FaceForen-
models. InProceedingsoftheIEEE/CVFConferenceon sics++: Learningtodetectmanipulatedfacialimages. In
ComputerVisionandPatternRecognition(CVPR),pages InternationalConferenceonComputerVision(ICCV),2019.
24480–24489,2023. 1,2,3,4,5,6,7,8,14 3
[92] OpenAI. Dall-e2. https://openai.com/index/dall- [105] AndreasRossler,DavideCozzolino,LuisaVerdoliva,Chris-
e-2,2022. 4,5 tianRiess,JustusThies,andMatthiasNießner. Faceforen-
sics++: Learningtodetectmanipulatedfacialimages. In
[93] OpenAI. Dall-e3. https://openai.com/index/dall-
ProceedingsoftheIEEE/CVFinternationalconferenceon
e-3,2023. 4,5
computervision,2019. 1,3
[94] Taesung Park, Ming-Yu Liu, Ting-Chun Wang, and Jun-
[106] VinuSankarSadasivan,AounonKumar,SriramBalasubra-
YanZhu. Semanticimagesynthesiswithspatially-adaptive
manian,WenxiaoWang,andSoheilFeizi. Canai-generated
normalization. InProceedingsoftheIEEEConferenceon
textbereliablydetected? arXivpreprintarXiv:2303.11156,
ComputerVisionandPatternRecognition,2019. 3
2023. 3
[95] AdamPaszke,SamGross,FranciscoMassa,AdamLerer,
[107] ChandramouliShamaSastryandSageevOore. Detecting
JamesBradbury,GregoryChanan,TrevorKilleen,Zeming
out-of-distributionexampleswithGrammatrices. InPro-
Lin,NataliaGimelshein,LucaAntiga,etal. Pytorch: An
ceedingsofthe37thInternationalConferenceonMachine
imperativestyle,high-performancedeeplearninglibrary.Ad-
Learning,pages8491–8501.PMLR,2020. 3
vancesinneuralinformationprocessingsystems,32,2019.
[108] Axel Sauer, Kashyap Chitta, Jens Müller, and Andreas
5
Geiger. Projected gans converge faster. In Advances in
[96] WilliamPeeblesandSainingXie.Scalablediffusionmodels
NeuralInformationProcessingSystems(NeurIPS),2021. 4
withtransformers. InProceedingsoftheIEEE/CVFInterna-
[109] AxelSauer,KatjaSchwarz,andAndreasGeiger. Stylegan-
tionalConferenceonComputerVision,pages4195–4205,
xl:Scalingstylegantolargediversedatasets. InACMSIG-
2023. 4
GRAPH2022conferenceproceedings,pages1–10,2022.
[97] Pablo Pernias, Dominic Rampas, Mats Leon Richter,
4
ChristopherPal,andMarcAubreville. Würstchen: Anef-
[110] ChristophSchuhmann,RichardVencu,RomainBeaumont,
ficientarchitectureforlarge-scaletext-to-imagediffusion
RobertKaczmarczyk,ClaytonMullis,AarushKatta,Theo
models. InTheTwelfthInternationalConferenceonLearn-
Coombes,JeniaJitsev,andAranKomatsuzaki. Laion-400m:
ingRepresentations,2023. 5,6,14
Opendatasetofclip-filtered400millionimage-textpairs.
[98] Dustin Podell, Zion English, Kyle Lacey, Andreas
arXivpreprintarXiv:2111.02114,2021. 4,5,7,14
Blattmann,TimDockhorn,JonasMüller,JoePenna,and
[111] ChristophSchuhmann,RomainBeaumont,RichardVencu,
RobinRombach. Sdxl:Improvinglatentdiffusionmodels
Cade W Gordon, Ross Wightman, Mehdi Cherti, Theo
forhigh-resolutionimagesynthesis. InTheTwelfthInter-
Coombes,AarushKatta,ClaytonMullis,MitchellWorts-
national Conference on Learning Representations, 2023.
man,PatrickSchramowski,SrivatsaRKundurthy,Katherine
5
Crowson,LudwigSchmidt,RobertKaczmarczyk,andJenia
[99] AlinCPopescuandHanyFarid. Exposingdigitalforgeries Jitsev. LAION-5b:Anopenlarge-scaledatasetfortraining
bydetectingtracesofresampling. IEEETransactionson nextgenerationimage-textmodels. InThirty-sixthConfer-
signalprocessing,2005. 3 enceonNeuralInformationProcessingSystemsDatasets
[100] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya andBenchmarksTrack,2022. 3,4,5
Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, [112] Vikash Sehwag, Mung Chiang, and Prateek Mittal. Ssd:
AmandaAskell,PamelaMishkin,JackClark,etal. Learn- Aunifiedframeworkforself-supervisedoutlierdetection.
ingtransferablevisualmodelsfromnaturallanguagesuper- InInternationalConferenceonLearningRepresentations,
vision. InInternationalconferenceonmachinelearning, 2020. 3
pages8748–8763.PMLR,2021. 3,5,6,7 [113] Arseniy Shakhmatov, Anton Razzhigaev, Aleksandr
[101] Jie Ren, Peter J Liu, Emily Fertig, Jasper Snoek, Ryan Nikolich, Vladimir Arkhipkin, Igor Pavlov, Andrey
Poplin,MarkDepristo,JoshuaDillon,andBalajiLakshmi- Kuznetsov, andDenisDimitrov. Kandinsky2.2. https:
narayanan. Likelihoodratiosforout-of-distributiondetec- //github.com/ai-forever/Kandinsky-2,2023. 5
tion. Advancesinneuralinformationprocessingsystems, [114] DasaraShullani,MarcoFontani,MassimoIuliani,OmarAl
32,2019. 3 Shaya, and Alessandro Piva. Vision: a video and image
[102] Robin Rombach, Andreas Blattmann, Dominik Lorenz, datasetforsourceidentification. EURASIPJournalonIn-
PatrickEsser, andBjörnOmmer. High-resolutionimage formationSecurity,2017:1–16,2017. 4,7
12[115] Ivan Skorokhodov, Grigorii Sotnikov, and Mohamed El- Systems,pages20685–20696.CurranAssociates,Inc.,2020.
hoseiny. Aligninglatentandimagespacestoconnectthe 3
unconnectable. arXivpreprintarXiv:2104.06954,2021. 4, [129] FisherYu,YindaZhang,ShuranSong,AriSeff,andJianx-
7,14 iongXiao.Lsun:Constructionofalarge-scaleimagedataset
[116] Irene Solaiman, Miles Brundage, Jack Clark, Amanda usingdeeplearningwithhumansintheloop. arXivpreprint
Askell,ArielHerbert-Voss,JeffWu,AlecRadford,Gretchen arXiv:1506.03365,2015. 4
Krueger, Jong Wook Kim, Sarah Kreps, et al. Release [130] BowenZhang,ShuyangGu,BoZhang,JianminBao,Dong
strategiesandthesocialimpactsoflanguagemodels. arXiv Chen,FangWen,YongWang,andBainingGuo. Styleswin:
preprintarXiv:1908.09203,2019. 3 Transformer-basedganforhigh-resolutionimagegeneration.
[117] Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya InProceedingsoftheIEEE/CVFconferenceoncomputer
Sutskever. Consistency models. In Proceedings of the visionandpatternrecognition,pages11304–11314,2022.4
40thInternationalConferenceonMachineLearning,pages [131] XuZhang,SveborKaraman,andShih-FuChang. Detect-
32211–32252,2023. 2,4 ingandsimulatingartifactsinganfakeimages. In2019
[118] YuhtaTakida,MasaakiImaizumi,TakashiShibuya,Chieh- IEEEinternationalworkshoponinformationforensicsand
HsinLai,ToshimitsuUesaka,NaokiMurata,andYukiMit- security(WIFS),pages1–6.IEEE,2019. 3
sufuji. SAN:InducingmetrizabilityofGANwithdiscrimi- [132] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A
nativenormalizedlinearlayer. InTheTwelfthInternational Efros. Unpaired image-to-image translation using cycle-
ConferenceonLearningRepresentations,2024. 4 consistentadversarialnetworks.InComputerVision(ICCV),
[119] MingTao,HaoTang,FeiWu,Xiao-YuanJing,Bing-Kun 2017IEEEInternationalConferenceon,2017. 3,5
Bao, and Changsheng Xu. Df-gan: A simple and effec-
[133] Mingjian Zhu, Hanting Chen, Qiangyu YAN, Xudong
tivebaselinefortext-to-imagesynthesis. InProceedingsof
Huang,GuanyuLin,WeiLi,ZhijunTu,HailinHu,JieHu,
theIEEE/CVFconferenceoncomputervisionandpattern
andYunheWang. Genimage: Amillion-scalebenchmark
recognition,pages16515–16525,2022. 5
fordetectingai-generatedimage. InAdvancesinNeural
[120] MingTao,Bing-KunBao,HaoTang,andChangshengXu.
InformationProcessingSystemsDatasetandBenchmarks
Galip:Generativeadversarialclipsfortext-to-imagesynthe-
Track,pages77771–77782,2023. 2,3,4,5,6,7,8
sis. InProceedingsoftheIEEE/CVFConferenceonCom-
[134] BojiaZi,MinghaoChang,JingjingChen,XingjunMa,and
puterVisionandPatternRecognition,pages14214–14223,
Yu-GangJiang. Wilddeepfake: Achallengingreal-world
2023. 5
datasetfordeepfakedetection. InProceedingsofthe28th
[121] DeciAIResearchTeam. Decidiffusion2.0,2024. 5
ACMinternationalconferenceonmultimedia,2020. 3
[122] AdakuUchendu,ThaiLe,KaiShu,andDongwonLee. Au-
thorshipattributionforneuraltextgeneration. InProceed-
ingsofthe2020ConferenceonEmpiricalMethodsinNatu-
ralLanguageProcessing(EMNLP),pages8384–8395,2020.
3
[123] AaronVanDenOord,OriolVinyals,etal. Neuraldiscrete
representation learning. Advances in neural information
processingsystems,30,2017. 8
[124] Patrick von Platen, Suraj Patil, Anton Lozhkov, Pedro
Cuenca,NathanLambert,KashifRasul,MishigDavaadorj,
DhruvNair,SayakPaul,WilliamBerman,YiyiXu,Steven
Liu, and Thomas Wolf. Diffusers: State-of-the-art dif-
fusion models. https://github.com/huggingface/
diffusers,2022. 2,3,4
[125] ApoorvVyas,NatarajJammalamadaka,XiaZhu,Dipankar
Das, Bharat Kaul, and Theodore L. Willke. Out-of-
distributiondetectionusinganensembleofselfsupervised
leave-outclassifiers. InProceedingsoftheEuropeanCon-
ferenceonComputerVision(ECCV),2018. 3
[126] Sheng-Yu Wang, Oliver Wang, Richard Zhang, Andrew
Owens,andAlexeiA.Efros. Cnn-generatedimagesaresur-
prisingly easy to spot... for now. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern
Recognition(CVPR),2020. 1,2,3,4,5,6,7,8
[127] RossWightman.Pytorchimagemodels.https://github.
com/huggingface/pytorch-image-models,2019. 5
[128] ZhishengXiao,QingYan,andYaliAmit. Likelihoodregret:
Anout-of-distributiondetectionscoreforvariationalauto-
encoder. In Advances in Neural Information Processing
13A.Otherapplications Predicted
GAN LatDiffPixDiff Real
GAN 0.93 0.04 0.01 0.01 Predicted
20 20 GAN LatDiff PixDiff Real
15 15 LatDiff 0.02 0.95 0.00 0.03 1 Commercial 0.22 0.40 0.03 0.36 1
10 10
PixDiff 0.20 0.03 0.26 0.52 0 CaS st ca ab dl ee 0.02 0.96 0.00 0.01 0
5 5
Real 0.00 0.00 0.00 0.99
0 0
5 5 (a)Knownarchitectures (b)Unknownarchitectures
10 10
Figure9.Generatortypeclassification.Weclassifythegenerator
5 0 5 10 15 20 5 0 5 10 15 20 type of a given image using k-nearest-neighbor. (a) Confusion
Fake Real Commercial GAN FFHQ
LatDiff LAION CelebA matrixof“known”generatortypes.Weobservehighaccuracyin
PixDiff COCO RAISE
Other ImageNet LandscapesHQ GANs,latentdiffusions,andrealdata.(b)Classificationresultson
(a)Fakevs.realvisualization (b)Generatortypevisualization “unknown”architectures.Commercialmodelsarepredominantly
classifiedaslatentdiffusionandGANs(disregarding‘real’).Stable
Figure 8. Feature space visualization. We visualize a feature
Cascade[97],whichwecategorizedasOthergeneratortype,shows
spaceofourtrainedclassifierusing10%ofourtrainingdataand
similaritytolatentdiffusionmodels.
theevaluationset. Forbettervisibility,onlyasubsetofourreal
datasetsarevisualizedandthelabelsforrealdatasetsareitalicized.
We observe a good separation between fake vs. real data, and
betweendifferentgeneratortypesandrealdatasets. nantlyclassifiedaslatentdiffusionorGANs,whileStable
Cascade[97]displayssimilaritytolatentdiffusionmodels
Otherapplications,beyondthe“real-or-fake”imageforen- despitetheiruniquethree-stagesamplingprocess.
sicstask,couldpotentiallybesupportedbyourdataset. In
particular,adiversearrayofgeneratorsandtheircorrespond- B.Datasetcomposition
ing images in our dataset may be valuable for addressing
thegeneratorattributionproblem,wherethegoalistoiden-
tify the characteristics of the underlying generator that is Model License Counts
responsibleforsynthesizingagivenimage.
Figure8presentsaUMAP[83]visualizationofthefea- 4000
ture space of our trained classifier. We use the activation
of the penultimate layer for visualization following Ojha 3000
et al. [91]. The feature space reveals interesting struc-
ture: GANs form a clearly separated cluster; most com- 2000
mercial models are distributed closely to latent diffusion
models;realdatasetssuchasLAION[110],ImageNet[26], 1000
COCO[75],andRAISE[22]arecloselydistributed,whereas
CelebA[77],FFHQ[60],andLandscapesHQ[115]appear 0
tobemoreisolated. Itisimportanttonotethatthesesepara-
tionsemergenaturallywithoutexplicittraining. Atargeted
learningobjectivemayfurtherenhancetheseseparations.
Buildingonthefeaturespaceobservations,weuseak-
nearest-neighborclassifierwithk=5using10%ofourtrain-
ingdatatoidentifythegeneratortypesinourevaluationset.
Weseparategeneratorsas“known”(i.e.,GANs,latentand Figure10.Histogramofmodellicensesinourdataset.Avastma-
pixeldiffusions,andrealdata)and“unknown”(commercial jorityofthemodelsusetheCreativeML OpenRAIL-Mlicense[1].
modelsandStableCascade[97])generatortypesandcom-
putetheconfusionmatricesasshowninFigure9. Notethat Generator licenses. In Figure 10, we report the gener-
noneofthesegeneratorsareseenduringtraining. Figure9a ator licenses in our dataset. Most of the models use the
demonstratesstrongperformanceinidentifyingGANs,la- CreativeML OpenRAIL-Mlicense[1].
tentdiffusionmodels,andrealdata. However,pixel-based
diffusionmodelsshowlowerperformance,possiblydueto Modelmetadata. Weshowanexamplemodelmetadatain
theirlimitedrepresentation(only3models)inourtraining Tab.3. Itcontainsthenameofthemodels,theircategorized
set. Theclassificationresultforthe“unknown”setisshown architectures,licenses,sourcerealdatasets,andtheHugging
inFigure9b. Interestingly,commercialmodelsarepredomi- Facetagsifavailable.
14
hturT
dnuorG
m-liarnepo-lmevitaerc enoN ++liarnepo tim liarnepo 0.3-lpg 0.2-ehcapa ds-0.1-lpiaf esnecil-yltneulf 0.4-as-cn-yb-cc 0.4-dn-cn-yb-cc 0.4-cn-yb-cc cn-ias 2v-dnuorgyalp 0.1-liar-moolb-ecneicsgib CN-ecruoS-AIDIVN SOT
margoedI
m-liarnepo-ecneicsgib SOT
IAnepO
0.2-citsitra SOT
yenruojdiM
0.3-lpga lpftw SOT
ebodA
esnecil-llarevo 0.3-lpgl cn-edacsac-elbats 0.4-yb-cc 0.4-as-yb-cc FI-dyolFpeeD cc m-liarnepo-edocgib esneciL
hcraeseR
9.0
LXDS
0.2v
esneciL
IAgnipleH
SOT
elgooG
cn-ved-1.XULF esneciL
hcraeseR
LXFF
2v-onyadoyModel Architecture License RealSource HF_pipeline_tag HF_diffusers_tag
danbochman/ coco,forchheim,imagenet,imd2020,laion, StableDiffusionXL- StableDiffusionXL-
LatentDiff None
ccxl landscapesHQ,vision Pipeline Pipeline
livingbox/
creativeml- coco,forchheim,imagenet,imd2020,laion, StableDiffusion-
modern- LatentDiff stable-diffusion
openrail-m landscapesHQ,vision Pipeline
style-v3
...
DeepFloyd PixelDiff DeepFloyd-IF coco N/A N/A
BigGAN GAN MIT imagenet N/A N/A
...
Table3.Examplemodelmetadata.WelogboththeauthorandmodelnamesfortheHuggingFace[37]modelsandonlythemodelnames
forothers.Wealsologthegeneratortype(i.e.,architecture),modellicense,sourcerealdataset,andHuggingFacetagsifavailable.
LatentDiff. GAN PixelDiff. Other 1.000
Models 4766 12 3 1
Percentage 99.67% 0.25% 0.06% 0.02%
0.975
Table4.Modelcountsperarchitectureinthetrainingset.Avast
majorityofthegeneratorsarelatentdiffusionmodels. 0.950
0.8K 3.2K 13K 36K104K
Training Iterations
Figure13.Impactoftrainingiterations.Theperformanceofthe
classifierplateausbeyond3Kiterations.
weightdecaywithawarmupof20%ofthetotaliterations.
22% 73% Wetrainourmodelsfor52Kiterationsusingthissetting. For
themodelsinFigures1and4,weemployshortertraining
iterations(3K)duetothecomputationaloverheadassociated
Latent Diff.
withtrainingasubstantialnumberofmodelsforstatistical
3% GAN
2% Pixel Diff. analysis. Wechosethisnumberofiterationssincewefound
Other thatclassifierperformancebeginstoplateauwithapproxi-
matelythisamountoftraining(Figure13).
Figure11.Numberofimagespergeneratortypeinthetrainingset.
D.Examplemodelprojectpage
Commercial LatentDiff. GAN PixelDiff. Other
Models 11 6 2 1 1
Images 14918 6000 2000 2000 1000
Figure12.Evaluationsetcomposition.
Modelcomposition. Thecompositionofthetrainingset
ofCommunityForensicsisdetailedinTable4andFig.11.
A vast majority of the models and generated images are
latentdiffusion. Figure12illustratesthecompositionofthe
evaluation set, which includes two variants of HDiT [19]:
one trained on FFHQ [60] and another on ImageNet [26].
For computing metrics such as mAP and accuracy, these
HDiT variants are treated as separate entities due to their
distinct training dataand model weights. However, when
reporting the number of models in our dataset, we count
themasasinglemodel.
Figure14.ExamplemodelprojectpagefromHuggingFace[2,37].
C.Trainingsettings
Figure14showsaprojectpagefromHuggingFace[2,37].
For training our classifiers, we use AdamW optimizer [79] Wecanseethetagsassociatedwiththemodel(e.g., Text-
with a learning rate of 2e-5, a weight decay of 1e-2, a to-image,pipelinetype,license),numberofdownloads,and
batchsizeof512,andmixedprecision[84]. Weuseacosine sampleimages.
15
PAm