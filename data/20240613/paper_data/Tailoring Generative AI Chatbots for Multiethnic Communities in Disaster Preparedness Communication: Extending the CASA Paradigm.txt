Preprint
Tailoring Generative AI Chatbots for Multiethnic Communities
in Disaster Preparedness Communication: Extending the CASA
Paradigm
XinyanZhao YuanSun
HussmanSchoolofJournalismandMedia CollegeofJournalismandCommunications
UniversityofNorthCarolina-ChapelHill UniversityofFlorida
WenlinLiu Chau-WaiWong
CollegeofJournalismandCommunications ElectricalandComputerEngineering
UniversityofFlorida NCStateUniversity
ABSTRACT
This study is among the first to develop different prototypes of generative
AI(GenAI)chatbotspoweredbyGPT4tocommunicatehurricanepreparedness
information to diverse residents. Drawing from the Computers Are Social Ac-
tors (CASA) paradigm and the literature on disaster vulnerability and cultural
tailoring, this study conducted a between-subjects experiment with 441 Black,
Hispanic, and Caucasian residents of Florida. A computational analysis of chat
logs(N =7,848)showsthatanthropomorphismandpersonalizationarekeycom-
munication topics in GenAI chatbot-user interactions. SEM results (N = 441)
suggest that GenAI chatbots varying in tone formality and cultural tailoring sig-
nificantlypredictbotperceptionsand, subsequently, hurricanepreparednessout-
comes. TheseresultshighlightthepotentialofusingGenAIchatbotstoimprove
diversecommunities’disasterpreparedness.
Keywords: GenerativeAI,chatbots,disastercommunication,multiethniccommu-
nities,humanness,culturaltailoring
1 INTRODUCTION
Generativeartificialintelligence(GenAI),anemergingformofAIthatproducescustomizedcontent
throughgenerativemodels,presentstransformativepotentialindisasterpreparedness,response,and
recovery(Barietal.,2023). ThepastdecadehasseenarapiddevelopmentofAI-poweredtechnolo-
giesusedfordisastermanagement. Indisasterpreparedness, AIhasenhanceddisasterpredictions
andearlywarningsduringearthquakes,hurricanes,andfloods(Linetal.,2021). Indisasterrescue
andrelief,AIsupportscrowd-sourcedapplicationssuchas“livemaps”thatharnesscollectiveefforts
toimprovedisasterreliefoutcomes(Ghaffarianetal.,2019).
AmongvariousAIapplications, chatbotsstandoutasoneofthemostpromisingtoolsfordisaster
management agencies to communicate disaster preparedness information to the public. Although
stillinitsinfancy,researchhasdemonstratedtheversatilityofchatbotsinimprovingcustomerser-
viceexperience,healthcareoutcomes,andorganization-publicrelationships(e.g.,Menetal.,2023).
Indisasterandriskcommunication,generativeAIchatbotshavethepotentialtotransformone-way,
genericcommunicationintointeractiveandpersonalizedinformationfordifferentcommunitymem-
bers. Suchculturaltailoringiscrucialforservingculturallyandlinguisticallydiversecommunities,
whichoftenbecomehard-to-reachpopulationsduetolanguagebarriersandingrainedcommunica-
tionpreferences(Howardetal.,2017;Liu&Zhao,2022). Thesecommunitiesarealsothefocusof
disaster vulnerability research, as they suffer from deteriorated disaster outcomes more than other
communities(The5thNationalClimateAssessment,2023).
Recent Human-Computer Interaction (HCI) research has demonstrated that advanced machine-
learning technologies have significantly improved chatbots’ ability to mimic human interactions
(Goyal et al., 2015) and made communication more interactive and personalized (Hancock et al.,
1
4202
nuJ
21
]LC.sc[
1v11480.6042:viXraPreprint
2020). However,distrustremainsanissueduetoperceiveddeficienciesofchatbotsinempathyand
contextualunderstanding(e.g.,Zhouetal.,2023). Inhigh-stakescontextslikedisastercommunica-
tion,theuseofchatbotscouldposesignificantchallenges,especiallyformultiethniccommunities.
Thisisduetohistoricalfactorssuchasculturalinsensitivityandsystemicracism,whichcontribute
to a long-standing lack of trust among marginalized communities toward the government (Best et
al.,2021).
Withchatbot’spotentialsandchallengesinmind,thisstudydesignsandtestsGenAIchatbotswith
enhancedhuman-likeness,groundedintheComputersAreSocialActors(CASA)paradigm(Nass&
Moon,2000;Nassetal.,1994). Thisapproachseekstomakethechatbot-humaninteractionsmore
engaging and personalized, thereby improving disaster preparedness outcomes among multiethnic
communities. Specifically,weassessthepotentialofGenAIinimprovingdisastercommunication
through two theoretical mechanisms, conversational tone (Kelleher & Miller, 2006) and cultural
tailoring (Kreuter & McClure, 2004). By creating GPT-4 chatbots that vary in tone and cultural
tailoring, our study is among the first scholarly attempts to investigate how diverse community
members perceive and interact with GenAI chatbots, and how effective this new tool can improve
disasterpreparednessoutcomesamongthiscommunity.
Inabetween-subjectsexperimentwith441Black, Hispanic, andCaucasianFloridaresidents, par-
ticipants interacted with chatbots powered by OpenAI’s GPT-4 API for hurricane preparedness,
varyingbytoneformalityandculturaltailoring,followedbyaquestionnaire. Weconductedacom-
putational analysis of chat logs to understand the patterns of GenAI chatbot-human interactions
andthenstatisticallyanalyzedhowthevariationsinchatbotcommunicationinfluencedparticipants’
chatbotperceptions,andsubsequently,theirhurricanepreparednessoutcomes.
1.1 THEORIZINGGENAICHATBOTSINDISASTERCOMMUNICATION: THECASA
PARADIGM
Chatbots are software applications that engage users through natural language processing (NLP)
capabilities (Shawar & Atwell, 2007). With recent advances in machine learning, chatbots have
evolvedsignificantlyinmimickinghuman-likeattributes(Goyaletal.,2015). Hancocketal. (2020)
argued that AI-mediated communication could potentially transform interpersonal communication
bytailoringresponsestoindividualuserpreferencesandcommunicationstyles. However,distrust,
oralgorithmaversion(Dietvorstetal,2015),stemmingfromaperceivedlackofhuman-likequalities
suchasempathyandcontextualunderstanding(Zhouetal.,2023),remainsachallenge. Longoniet
al. (2019)foundthatuserstendtodistrustAIhealthsystemsduetotheperceptionthatalgorithms
cannotaccountforuniqueindividualdifferencesthewayahumanmight.
Toaddressthesechallenges,theComputersAreSocialActors(CASA)paradigmprovidesafounda-
tionalframeworkforunderstandinghowhumansinteractwithtechnology. AccordingtotheCASA
paradigm,peopleoftenrespondtocomputersandothermediaasiftheywereactualsocialbeings,
applying social rules and behaviors to these interactions on a subconscious level (Nass & Moon,
2000; Nass et al., 1994). Extending this theory to media, Lombard and Xu (2021) further argued
that various cues from new technologies can evoke a sense of social presence, making these tech-
nologiesappearmore“alive”or“social.”Thus,fosteringhumannessmaybeacriticalmechanismto
overcomedistrustandpromoteuserengagement,especiallyinhigh-stakecontextssuchasdisaster
communication. Forinstance,GoandSundar(2019)foundthatusinghighanthropomorphicvisual
cues,suchashuman-likeprofilepictures,cancompensateforthenegativeeffectsofamachine-like
conversation style. Similarly, in a study by Olk et al. (2020), a COVID-19 chatbot implemented
emojis,significantlyimprovingusers’perceptionsofchatbotwarmthandintentiontocomply.
BuildingupontheCASAparadigm,therearetwospecificanthropomorphiccuesthatcanenhance
the human-like qualities of chatbots during disaster communication: conversational tone and per-
sonalized communication. Kelleher (2009) defined conversational tone as “conversational human
voice” and “an engaging and natural style of organizational communication” (p. 177). Based on
theCASAparadigm,byadoptingaconversationaltone,animportantanthropomorphicattributein
interpersonalcommunication,chatbotscanbettermimichumancommunicationtocreateafriendly
andsociablepresenceandtriggersocialresponsesfromusers,makinginteractionsfeelmorenatu-
ralandengaging. Withintheorganizationalcontext,comparedtotraditionalone-waybroadcasting
communication, a conversational tone can better facilitate open dialogue and bring about positive
2Preprint
relational outcomes such as relational satisfaction (Kelleher & Miller, 2006). Indeed, Men et al.
(2022)foundthatchatbotswithaconversationaltonecanimproveperceptionsoforganizationallis-
teningandtransparency,leadingtomorepositiveorganization-publicrelationships.However,extant
researchwasprimarilyconductedinanon-disastercontextusingrule-basedchatbotsthatmightre-
sultinlesssociableorengaginginteractions. ThisstudythusexamineshowGenAIchatbotscanbe
designed to generate natural, engaging, and contextually adaptive responses with a conversational
toneandassesstheirdisasterpreparednessoutcomes.
Thehumannessofchatbotscanalsobeenhancedthroughpersonalizedinteractions(Hancocketal.,
2020), leading to higher engagement and organizational outcomes (Shumanov & Johnson, 2021).
BasedontheCASAparadigm,whenchatbotsareculturallytailoredtomatchtheuser’sracialiden-
tity, users may subconsciously respond as if they are interacting with an in-group member. This
personalized experience could enhance user trust and their willingness to engage deeply with the
chatbot. Thiseffectmightbemorepronouncedindisasterscenarios, wherecertainracialcommu-
nitiesexhibitaheightenedriskperception(Fothergill&Peek, 2004). Culturalandsocioeconomic
differencescanaffectuserinteractionswithchatbotsanddisasterpreparednessoutcomes(Appleby-
Arnold et al., 2018), highlighting the need for more research on culturally tailored chatbots and
theireffectivenessindisasterpreparedness. Thus,thisstudyexamineshowGenAIchatbotscanbe
optimizedtogenerateculturallytailoredandpersonalizedresponsesbasedonkeyuserinputssuch
asracialidentity.
In sum, enhancing the human-like qualities of GenAI chatbots through conversational tone and
culturallytailoredcommunication,groundedintheCASAparadigm,mayhelpmakeconversations
moreengagingandpersonalized,therebyimprovingdisasterpreparednessoutcomesformultiethnic
communities. Given the limited research on how users interact with GenAI chatbots, we propose
thefollowingresearchquestiontounderstandtheinteractionpatterns:
RQ1: Which topics emerge during the interaction between a user and a GenAI chatbot during
disasterpreparednesscommunication?
1.2 DISASTERPREPAREDNESSOUTCOMES
Whiledisasterpreparednessiscentraltoeffectivedisastermanagement,lessresearchexistsoncom-
munication strategies that improve a community’s disaster preparedness efforts (McLennan et al.,
2020; McNeiletal., 2013; Milleretal., 2021). Thecurrentstudybridgesthisgapbyfocusingon
three important indicators of disaster preparedness, disaster-related information-seeking, informa-
tionsharing,anddisasterpreparednessefficacy.
Disasterinformation-seekingisanactivecommunicationactioninproblem-solvingprocesses(Kim
& Grunig, 2011). Information seeking is defined as “the planned scanning of the environment for
messagesaboutaspecifictopic”(J.E.Grunig,1997,p. 9). Indisastercommunication,information
seeking is vital in sensemaking processes. When faced with crises, threats, or other uncertain sit-
uations,individualsarenaturallypromptedtoseekinformationasacopingmechanismtomitigate
tensions and anxiety. However, research also suggests that disasters may overwhelm individuals,
leadingtoavoidanceratherthanactivelyseekingdisasterinformation(Seegeretal.,2003). Topro-
moteinformation-seekingbehavioristhereforeneededtoengagecommunitiesindisasterprepared-
ness. With the rise of misinformation during disasters (Hunt et al., 2020), it is particularly urgent
to promote information-seeking from authoritative sources such as disaster management agencies.
Meanwhile,disasterinformationsharingreferstotheintentionandbehavioroftransmittingrelevant
informationtoalargercrowdtofacilitatedisastercopingorproblem-solving. AsKimetal. (2010)
suggest that a problem “is easier to solve when it comes to a problem of a group rather than that
ofanisolatedindividual.”(p. 149)Activeinformationsharingthushelpsimproveindividuals’and
communities’disasterpreparedness. Finally,asenseofdisasterpreparednesscapturestheperceived
confidence and efficacy in preparing for and coping with a disaster. Research has proposed mul-
tiple dimensions under this construct, including a cognitive dimension that taps into individuals’
riskawareness,disasterknowledge,andphysicalpreparationintentions,aswellasapsychological
dimensionthatindicatesindividuals’psychologicalreadinessfordisasters(Paton,2003).
Havingidentifiedtheprimaryoutcomesofdisasterpreparedness,thefollowingsectionsdetailcom-
munication tone and cultural tailoring, two key mechanisms in the disaster vulnerability and HCI
literature.
3Preprint
1.3 THEROLEOFCOMMUNICATIONTONEINCHATBOTDISASTERCOMMUNICATION
Whileusingaconversationalhumanvoiceinorganizational-publicdisastercommunicationshows
promise(Menetal.,2023),theconcept’sutilityisconstrainedbythelackofclearoperationalization
of specific communication and language styles within chatbot interactions. This includes linguis-
tic aspects such as tone formality, emotionality, vocabulary, and pronoun use. This study focuses
on informal tone as a specific linguistic component of conversational human voice. An informal
tone features casual, colloquial language, whereas a formal tone uses authoritative and structured
language(Gretryetal.,2017).
Organizationscanstrategicallyuseaninformaltonetoreducethesocialdistancefromthepublicand
makeconversationspersonal,potentiallyfosteringengagementandtrustingrelationships. Basedon
the HCI literature, this can be achieved through the human-like design of chatbots. Specifically,
chatbots can resemble human-human interactions, characterized by features such as emotional re-
sponsiveness,agency,andinterpersonalwarmth,amongothers(Rappetal.,2023). GoandSundar
(2018)suggestthreefactorsthatcanincreasethelevelofhumannessofchatbots,includinganthro-
pomorphiccues,humanidentitycues,andconversationalcues,whichfurtherleadtomorefavorable
attitudesandgreaterbehavioralintentionstoreturntoagivenwebsite.
However, existing studies have shown an informal tone can backfire when it is perceived as inap-
propriate in the organizational context (Gretry et al., 2017), particularly during disasters when the
public expects the government to be authoritative and credible (Zhao & Zhan, 2019). Thus, users
might perceive a chatbot with an informal tone to be friendly to interact with, yet less credible as
it does not fit their expectations of government-public communication. Both perceptions, chatbot
friendlinessandcredibility,arecrucialinenablinggovernmentstoachievethedualobjectivesofdis-
seminatinginformationandfosteringrelationshipswiththepublicduringdisasters. Takentogether,
theformalityofaGenAIchatbot’stoneishypothesizedtoimpactuserperceptionsofthechatbot,
specificallybydecreasingperceivedbotfriendlinessbutincreasingperceivedbotcredibility.
H1: ThetoneformalityofaGenAIchatbot(a)negativelyaffectsdiverseresidents’perceptionsof
thechatbot’sfriendlinessand(b)positivelyaffectscredibility.
AccordingtoJohnsonandGrayson(2005),perceivedfriendlinessiscrucialforestablishingaffective
trustinuser-chatbotrelationships. Thisperceptioncanevokebenevolentattitudestowardchatbots
(Baek et al., 2022). Additionally, attributing human-like qualities to AI agents can enhance per-
ceptions of their competence and reliability. For example, Johnson and Grayson (2005) found a
positive association between a service provider’s perceived warmth and their perceived expertise
andcredibility. Basedontheevidence,weproposethefollowinghypothesis:
H2: TheperceivedfriendlinessofaGenAIchatbotispositivelyassociatedwithitsperceivedcredi-
bility.
Further, we assess agencies’ use of GenAI chatbots to improve individuals’ disaster preparedness
outcomes. Previous research has also found that perceived friendliness positively affected users’
cognitive evaluation of chatbots (Wang et al., 2023). By eliciting benevolent feelings towards the
bots, friendliness perception helps promote prosocial and other compliant behaviors (Baek et al.,
2022). For example, Cheng et al. (2022) found that perceived friendliness led to enhanced users’
intentions to rely on the chatbot. Recent research has shown that chatbots can improve communi-
ties’disastercopingexperiencebypromotingcommunitymembers’communicativeactivenessand
collective efficacy (e.g., Ahmady & Uchida, 2020; Tsai et al., 2019). To test whether the use of
theGenAIchatbotcanenhancedisasterpreparednessoutcomesthroughperceivedfriendlinessand
credibility,weproposethefollowinghypotheses:
H3: TheperceivedfriendlinessofaGenAIchatbotpositivelyrelatestodisasterpreparednessout-
comes,including(a)informationseekingintention,(b)sharingintention,and(c)preparedness.
H4: The perceived credibility of a GenAI chatbot positively relates to disaster preparedness out-
comes,including(a)informationseekingintention,(b)sharingintention,and(c)preparedness.
To test whether and how perceived friendliness and credibility perceptions may mediate the rela-
tionship between the GenAI chatbot’s tone and disaster preparedness outcomes, we propose the
followingresearchquestion:
4Preprint
RQ2: How does the tone formality of a GenAI chatbot influence diverse residents’ disaster pre-
paredness outcomes (including information seeking, sharing, and preparedness) through chatbot
perceptions(perceivedfriendlinessandcredibility)?
1.4 THEROLEOFCULTURALLYTAILOREDGENAICHATBOTSFORDIVERSECOMMUNITIES
Asmentioned,itiscrucialforGenAIchatbotstoadapttotheculturalnuancesofmultiethniccommu-
nities,asethnicminoritieswithculturalandsocioeconomicdifferencescanexhibitdifferentpatterns
of interactions with chatbots and disaster preparedness outcomes (Appleby-Arnold et al., 2018).
Culture, broadly defined, can include race, ethnicity, gender, and sexual orientation (Ma & Zhao,
2023). Givenourfocusonmultiethniccommunities,thisstudyfocusesonrace/ethnicityasthema-
jorindicatorofculture. Culturaltailoring,whichadaptsmessagestotheculturalcharacteristicsof
a specific group, helps communication interventions effectively address a given group’s decision-
makingneedsandinterests(Kreuter&McClure,2004). Asmoredisasterandriskcommunication
researchfocusesonexplainingandreducingdisastercopingdisparitiesamongdiversecommunities,
culturaltailoringhasbeenproposedasapromisingapproachtobridgedisparities(Huang&Shen,
2016). Ma and Zhao (2023) posited that cultural tailoring involves highlighting specific risks and
copingimplicationsfordistinctculturalgroups. Forexample,bydifferentiatingbetweenmarginal-
ized communities (e.g., the Hispanic or Black community) and the general population, disaster
communicationcanbedesignedtomeettheuniqueinformationneedsofdiversegroupsandreduce
outcomedisparities.
The strategies of cultural tailoring can be categorized into surface tailoring and deep tailoring
(Resnicow et al.,1999). Surface-level communication tailoring adapts to a culture’s “superficial”
aspects, including language, appearance, and diet. By contrast, deep tailoring engages with a
community’s social, historical, and psychological characteristics, such as values, traditions, and
norms—considered as the culture’s deep structure (e.g., Kreuter et al., 2004). A meta-analysis on
cultural tailoring in cancer communication (Huang & Shen, 2016) shows that culturally tailored
cancer communication had a small significant effect on persuasion, and deep tailoring had a more
substantialimpactthansurfacetailoring.
However, the concept of cultural tailoring has rarely been investigated in the literature of disaster
communicationandHCI.Despiteemergingresearchontheimpactofchatbots’culturalorientations
(Mu¨ller et al., 2023) and the scholarly call for culturally appropriate disaster messages for diverse
communities(Liu&Viens,2020),therehasyettobeanyempiricalattempttoharnessthepotential
of GenAI chatbots for interactive, culturally tailored communication. It thus remains unknown
how a GenAI chatbot’s culturally tailored disaster information affects marginalized communities.
We argue that GenAI-based chatbots can offer culturally tailored information both statically and
dynamically, thereby significantly deepening the personalization level of the interaction. On the
onehand,statictailoringinvolvesresearcherspre-designingculturallytailoredinformationthrough
promptengineeringormodelfine-tuning.Forexample,aresearchercanconfigurethechatbottouse
raciallyfamiliarnamesinintroductions.Ontheotherhand,dynamictailoringinvolvesinstantaneous
adjustmentsbasedonusers’responsesandpreferences. Forexample,aGenAIchatbotcouldadapt
itslanguageorcontentinrealtimetomatchuserneedsandpreferences,suchasprovidingcounty-
specificshelteringadviceorchangingitsmessagingstyle. Giventhelackofresearchonculturally
tailored GenAI chatbots in disaster preparedness, we propose the following research questions to
explore their impact on diverse communities’ perceptions of the chatbot and subsequent disaster-
relatedoutcomes:
RQ3:HowdoesaculturallytailoredGenAIChatbotinfluencediverseresidents’chatbotperceptions
(perceivedfriendlinessandcredibility)?
RQ4: HowdoesaculturallytailoredGenAIChatbotinfluencediverseresidents’disasterprepared-
ness outcomes (information seeking, sharing, and preparedness) through chatbot perceptions (per-
ceivedfriendlinessandcredibility)?
2 METHODS
Following a university Institutional Review Board approval, we conducted an online between-
subjectsexperimentfromFebruarytoMarch2024. Participantsaged18andolderinFloridawere
5Preprint
recruited through Prolific, an online research platform. Once enrolled, participants were directed
to a Qualtrics survey and informed about using a GPT-4 chatbot, simulating a scenario of a local
government’shurricanepreparednesseducation. Participantswhoconsentedfirstcompletedscreen-
ingandindicatedtheirprimaryracial/ethnicidentity. Afterreviewingtheinstructions,participants
werethenrandomlyassignedviaQualtricstooneofthechatbotconditionsprogrammedtogenerate
uniqueuniformresourcelocators(URLs)fordifferentconditions. ClickingontheassignedURLs
redirectedparticipantstoourwebbrowserinterfacetostarttheirinteractionswithdesignatedchat-
bots. Afterward, they were instructed to return to Qualtrics to complete the survey by answering
questions measuring the outcome and demographic variables. At the end, participants were de-
briefed, compensated, and provided with links to emergency response resources from federal and
stateemergencyresponseagencies.
2.1 PARTICIPANTS
We used quota sampling to represent Florida residents by race/ethnicity, intentionally oversam-
pling minorities, including Blacks and Hispanics to achieve an equal distribution among different
racial/ethnicgroupsinoursample. Thisallowedustounderstandchatbotutilizationforhurricane
preparedness among vulnerable communities. The final sample size was 441, after removing re-
sponsesthatwereincompleteorfailedallattentioncheckquestions. Amongtheseparticipants,the
average age was 38.38 (SD = 14.08). The sample consisted of 148 (33.56%) White/Caucasian,
150(34.01%)Black/AfricanAmerican,and143(32.43%)Hispanic/Latinoparticipants. Withinthe
sample, 62.36%werefemale, 34.47%weremale, and3.17%reportednon-binary. Approximately
18.37% had high school or lower education levels, 70.98% had a partial or full college education,
and10.66%hadagraduatedegreeorabove. Themedianhouseholdincomewasbetween$25,000
to$49,999.
2.2 OPENAI’SGPT-4APIANDWEBSERVER
Our chatbot utilizes OpenAI’s Chat Completions API, leveraging GenAI capabilities of an inter-
nally trained model designated as “gpt-4-1106-preview.” It is important to understand the distinc-
tionbetweenGPT-4APIandChatGPT.GPT-4APIprovidesascalableandflexibleframeworkthat
allowsforprogramming-basedcustomizationofmultiplechatbots,enablingtheirinteractionswith
thousandsofuserssimultaneously. Thischatbotwasdevelopedfromtheopen-source“openaicha-
texample”projectonGitHub. Weenhanceditbyaddingadaptivepromptsforvariousexperimental
conditions,loggingchathistoriesandtimestampsforanalysis,configuringthewebserverforload
handlingandpressuretests,andmanagingdailydatabackupduringdeployment(fortechnicalde-
tails, see Supplemental Materials [SM] P1). We intend to release the source code of our project
alongsidejournalpublication.
2.3 GENAICHATBOTMANIPULATION
We developed different sets of system prompts as input for OpenAI’s GPT-4 API, aiming to train
different versions of GenAI chatbots. Initially, we created a general prompt where GPT 4 was
instructed to simulate an agent from a Florida emergency management team, providing reliable
information as a government agency for participants across all conditions. We then created four
specific sets of prompts as manipulations of the chatbot’s tone (formal vs. informal) and cultural
trailering(tailoredvs. generic). Buildingontheliterature(Gretryetal.,2017),thetonewastrained
to vary between an informal tone—characterized by casual language, acronyms, and emojis when
appropriate—andaformaltone,characterizedbyofficialandauthoritativelanguagerepresentingan
officialagency(fordetails,seeSMP2).
Following the literature on cultural tailoring (Huang & Shen, 2016), the culturally tailored chat-
botadapteditsconversationbasedontheparticipant’srace/ethnicity,addressingtheiruniqueneeds
for hurricane preparation (for details, see SM P2). For example, with Hispanic participants, the
chatbot used a common Hispanic name (e.g., Luis Garcia), highlighted bilingual support, and in-
quiredaboutspecificfamilyneedsforstormpreparedness. Incontrast,thegenericchatbotprovided
hurricanepreparationinformationwithoutculturaltailoring. Culturaltailoringwasnotappliedfor
White/Caucasianparticipants,whoallreceivedthegenericcondition.
6Preprint
2.4 GENAICHATBOT-USERINTERACTIONPROCESS
ParticipantswereinvitedtoevaluateaprototypeGenAIchatbotfordisasterpreparednesseducation.
Theywereinstructedtoimaginethatahurricanewasforecastedfortheupcomingweeksandinteract
withthechatbottolearnmoreabouthurricanepreparedness. Participantswererandomlyassigned
tooneofthechatbotconditionsonQualtrics,whereacustomURL,representedbyapseudorandom
numberforeachcondition,wasgenerated.TheythenclickedontheURL,directingthemtoourweb
browser-basedinterfacetointeractwiththeassignedchatbot. Thewebserverreceivedtheencoded
assignedconditionthroughthecustomURLandtransmittedtherelevantpromptstoOpenAI’sGPT-
4 API at the backend. This ensured that participants experienced interactions aligned with their
assigned condition without seeing the actual prompts. Each participant’s message and the entire
chat history are sent to GPT-4 for reasoning and response. If multiple messages are sent before a
reply,GPT-4addressesthemcollectively. Participantswereaskedtointeractwiththechatbotforat
leastfiveminutes,andourserverloggedtheirchathistoryandresponsetimes.
2.5 PILOTTEST
Apilottest(n=40)wasconductedtoensurethewebserver’sfunctionalityandthemanipulation’s
appropriateness. Participantsfrom variousracial communitiesresponded favorably tothe chatbot,
supportingitsappropriatenessandutility. Theirfeedbackledtoadjustmentsinourpromptsforthe
main study. These adjustments focused on prioritizing the provision of information over making
promises about actions, such as dialing 911 or contacting hotlines, starting interactions in English
beforepresentingoptionsforadditionallanguages,andchanginglanguagewhenrequested.
2.6 MEASUREMENT
BotCredibility. WeusedfiveitemsfromFlanaginandMetzger(2003)tomeasurebotcredibility:
“To the best of your judgment, is the chatbot [believable, accurate, trustworthy, biased, or com-
plete]?”(1=notatall,7=verymuch). Themeanwas5.92(SD=1.00,Cronbach’salpha=.88).
BotFriendliness. WeusedfiveitemsfromKohandSundar(2010)tomeasurebotfriendliness:“To
me,isthechatbot[empathetic,personal,warm,willingtolisten,oropen]?”(1=notatall,7=very
much). Themeanwas5.30(SD=1.31,alpha=.91).
InformationSeekingandSharingIntention. AdaptedfromZhaoandTsang’s(2021)scale,par-
ticipantsreportedthelikelihoodtheywouldseekhurricanepreparationinformationfromstategov-
ernment agencies and local government agencies on a 7-point scale ranging from 1 “not likely at
all”to7“extremelylikely.”Themeanofinformation-seekingintentionwas5.36(SD=1.02,alpha
= 0.75). Participants also indicated the extent to which they were likely to share the information
provided with people they know, such as family, friends, and co-workers (M = 5.54, SD = 1.28,
alpha=.80).
DisasterPreparedness. DisasterpreparednessmeasureswereadaptedfromMcNeiletal. (2013)
andMcLennanetal. (2020). Participantsratedtheirlevelofagreementwithsixstatementsona7-
pointLikertscale. Examplesofstatementsincluded“Ifahurricanetakesplace,Iknowhowtotake
proper actions to ensure my family’s and my safety,” “I feel confident about protecting my family
andmeagainstthenegativeimpactofahurricane.”(M=5.75,SD=0.85,alpha=.86). Oneitem
“Idonotfeelanxiousevenwithanimpendinghurricaneaffectingmyarea.”wasremovedduetoits
lowerinternalconsistencyinthesample.
Covariate.Disasterexperienceandracialidentificationwereusedascovariates.Disasterexperience
wasmeasuredthroughabinaryvariableindicatingwhetherparticipantshadpreviouslyexperienced
any hurricanes. To measure participants’ identification with their racial/ethnic group, we adopted
three items from Leach et al. (2008). For instance, participants rated the statement “The fact that
Iama[Hispanic/Latino]isanimportantpartofmyidentity”ona7-pointLikertscale(M=4.88,
SD = 1.75, alpha = .90). The term within brackets corresponded to the participant’s self-reported
racial/ethnicidentity.
7Preprint
Table1: SummaryStatisticsandCorrelationMatrix
Note. N = 441. *** p < .001, ** p < .01, * p < .05.
2.7 ANALYTICALSCHEME
ToanswerRQ1onGenAIchatbot-humaninteractionpatterns,weconductedacomputationalanal-
ysis of chat logs using BERTopic (Grootendorst, 2022). BERTopic is a topic modeling technique
thatenhancestheidentificationofmeaningfultopicsbyutilizingtransformermodelsforwordem-
beddingsandac-TF-IDFapproachforclusteringrelatedwords(Grootendorst,2022). Transformer
models can capture the contextual meaning of words by considering their semantic relationships.
Thec-TF-IDFapproachadjuststermfrequency-inversedocumentfrequencyforclusters, allowing
fortheeffectivegroupingofsemanticallysimilarwords. BERTopiccanalsoincorporatelargelan-
guagemodels,whichhelpspreservesignificanttermsintopicdescriptions,makingtheresultsmore
interpretable. We then conducted a qualitative analysis of the recognized topics, inductively iden-
tifyingseveraltheory-basedcommunication-anddisaster-relatedtopics. Forprecisepredictionof
theory-based topics for each participant, we used zero-shot classification with prompt engineering
andOpenAI’sGPT4(Ziemsetal.,2024). Usingpromptengineering,wecraftedtheory-basedin-
puts to guide GPT 4 in generating accurate topic predictions. Note that one or more topics can
coexistinanentry. SMP3includestheprompt.
To test the hypotheses and research questions on chatbot perceptions and disaster outcomes, we
conducted structural equation modeling through the R “Lavaan” package. Two models were ana-
lyzed, including the overall sample (N = 441) and a sub-sample comprising Hispanic and Black
participants (n = 293), which provided a more focused test of the effect of cultural tailoring. In
thestructuralmodel,exogenousvariableswerethetwomanipulatedchatbotconditionscodedasbi-
naryvariablesandcovariates(notshowninthefigureforsimplicity). Mediatorsincludedperceived
culturaltailoring,botfriendliness,andbotcredibility. Endogenousvariablesincludedinformation-
seekingintention,information-sharingintention,anddisasterpreparedness(Figure1). Inthemea-
surement model, latent constructs with fewer than 3 items were identified through all items. To
identifylatentconstructswithmorethan3items,aparcelingapproachwasusedtocreatecompos-
ite items (see notes of Figure 1 for details). Table 1 shows descriptive statistics and a correlation
matrix of these variables for the full sample. Parameters were estimated by maximum likelihood.
Themodelwasevaluatedusingstandardcutoffvaluesforthemodel-datafitindices(Hu&Bentler,
1999). Thebootstrapmethod(N =5,000,biasedcorrected)wasusedtoestimateindirecteffects.
8Preprint
3 RESULTS
3.1 MANIPULATIONCHECKS
Given potential randomness in texts generated by GenAI chatbots, we conducted two sets of ma-
nipulationcheckstestingbothactualandperceived toneformalityandculturaltailoring. First,we
measuredtheactuallevelsoflinguisticmanipulationusingacomputationalanalysisofalltranscripts
throughOpenAI’sGPT-4model(seeSMP4fortheprompts).Theactuallevelofculturaltailoringin
thechatbottext(0–5)wasmeasuredbysummingfivebinaryindicatorssuchasaculturallyfamiliar
agentnameorproposedlanguageoptions(fordetails, seeSMP4). Theactualleveloftoneinfor-
malitywasmeasuredbasedontheratioofcolloquialwords,slang,acronyms,emojis,andemoticons
in the text. Our independent-sample t-tests confirmed the effectiveness of manipulations in actual
texts: t(443) = 21.46, p < .001, Cohen’s d = 2.01 for tone informality, and t(294) = −21.80,
p < .001,Cohen’sd = −2.57forculturaltailoring. Theratioofcolloquialwordsintheinformal
tone condition was 18.9%, compared to 0.3% in the formal tone condition. The cultural tailoring
scorewas3.76inthetailoredcondition,comparedto0.86inthegenericcondition.
Theeffectivenessofourmanipulationswasalsosupportedusingself-reportedperceptions. Forper-
ceivedtone,allparticipantsindicatedthechatbot’scommunicationstylefromthreeoptions: casual
style, formal style, or don’t remember. A significant majority (77.68%) correctly recognized the
assignedstyle,indicatingeffectivetonemanipulation: χ2 =138.57,p<.001,Cramer’sV =0.56,
suggestingalargeeffectsize. Forperceivedculturaltailoring, participantsevaluatedhowrelevant
the chatbot’s information was to the needs and interests of their community, specifically [Hispan-
ic/Latino]or[Black/AfricanAmerican],ona5-pointscale(1=veryirrelevant,5=veryrelevant).
AmongHispanicandBlackparticipants,comparedtothoseinagenericcondition(M = 3.38,SD
= 1.17, n = 139), participantsassignedtointeractwithaculturallytailoredchatbotreportedper-
ceivingthecontentasmorerelevanttotheirracialcommunity(M = 3.73, SD=0.98, n = 154).
Thedifferencewassignificant: t(269)=−2.72,p=.007,Cohen’sd=−0.32,suggestingasmall
effectsize.
3.2 COMPUTATIONALANALYSISOFGENAICHATBOT-HUMANINTERACTIONS
Onaverage,participantsinteractedwiththechatbotfor6minutesand42seconds(SD=4minutes
and 13 seconds). In total, participants input 3,615 textual entries, while the GenAI chatbots input
4,233 entries. To answer RQ1, we qualitatively condensed 30 topics identified through BERTopic
intoeight,comprisingtwocommunication-relatedandsixdisaster-relatedtopics. Table2detailsthe
two communication-related topics: (1) Anthropomorphism (36.57%), where users interacted with
the chatbot as if it were human, expressing emotions, greeting it, or asking about safety; and (2)
Personalization(26.64%),whereusersprovidedpersonalinformation,suchaszipcodeorlocation,
or indicated preferred languages for personalized information. Additional analysis showed that
the manipulation of tone was associated with anthropomorphism. Specifically, an informal tone
was linked to a higher level of anthropomorphism: χ2 = 5.75, p = .017, Cramer’s V = 0.11.
And anthropomorphism was positively associated with both perceived bot friendliness (r = .18,
p<.001)andcredibility(r =.15,p<.001).
Thefollowingdisaster-relatedtopicswerealsoidentified(Table2): (1)Forecasts(50.34%),suchas
hurricanearrival,eye,categories,floodzonestatus,alerts;(2)Preparation(81.26%),includinghome
preparationandemergencykits;(3)Safetymeasures(44.02%),suchashandlingpoweroutages,gas
tanks, sandbag locations, water purification, and cell phone access; (4) Evacuation and shelter-
ing(62.98%),detailingwhentoevacuate,routes,andshelterlocations; (5)Interpersonalnetworks
(25.06%), emphasizing families and others in the communities; and (6) Resource and assistance
(26.19%),emphasizingresourcesforhouseprotection,insurance,andrecoveries.
3.3 HYPOTHESESANDRESEARCHQUESTIONSONBOTPERCEPTIONSANDDISASTER
OUTCOMES
For the full sample, the model-data fit was satisfactory (Figure 1): χ2(92,N = 441) = 129.5,
p = .006,CFI = 0.99,SRMR = 0.031,RMSEA = 0.030,90%CI[0.017,0.042],p = .998. For
thesub-sample,themodelalsohadagoodfitwiththedata(Figure2): χ2(92,N = 293) = 144.5,
p = .001, CFI = 0.97, SRMR = 0.045, RMSEA = 0.044, 90% CI [0.030,0.058], p = .752.
9Preprint
Table2: TopicsinGenAI–HumanInteractions
Communication- Definition Examples
Related Topics
Anthropomorphism Users interacted with the chatbot as e.g., Thanks, you were very
if it were a real human, including informative!
expressing emotions (e.g., anxiety, e.g., I heard this really hard
gratitude), providing positive song that reminded me of a
responses, greeting the chatbot, or hurricane what’s your favorite.
asking whether it is safe.
Personalization Users provided personal information e.g., I don’t like the slang you
such as zip code or location, or are using.
indicated preferred languages (e.g., e.g., English is fine.
English) to access personalized e.g., Altamonte Springs.
information.
Disaster-Related
Topics
Hurricane forecast Hurricane arrival forecasts, eye, e.g., How can I make sure I
categories explained, flood zone receive timely alerts and
status checking, how to receive warnings?
alerts, and how to find links. e.g., What are the different
hurricane categories?
Hurricane preparation Home preparation (e.g., securing e.g., ways to protect my home
windows) and emergency kit from hurricanes.
essentials such as water and food e.g., what specific non-food
prior to hurricanes. household supplies should I
have on hand for a storm?
Safety measures during Power outages, generators, gas tanks, e.g., affordable generators
hurricanes sandbag pickup locations, water e.g., If power is out, can they
purification, cell phone access, and kick me out of my apartment for
so on. safety reasons?
Evacuation and Information on when to evacuate, e.g., Are there shelters I can go
sheltering evacuation routes, shelter to?
information and locations. e.g., What are the requirements
to bring a pet to a shelter?
Interpersonal networks Staying connected with or helping e.g., Thank you. I’m just
children, infants, older family covering every area. How can I
members, individuals with special help others in this hurricane?
needs, friends, or others in the
community.
Resource and Resources for house protection, e.g., I have no home insurance.
assistance insurance for property damages, e.g., How do I access mitigation
especially for low-income families. grants?
Asbothmodelsyieldedsimilarresults,ourreportoffindingsfocusedonthefull-samplemodelbut
reliedonbothmodelsforspecifichypothesesregardingculturaltailoring.
H1 predicted that the conversational tone of the GenAI chatbot affected diverse residents’ chatbot
perceptions, including perceived friendliness and credibility, and H2 predicted that the chatbot’s
perceivedfriendlinesswaspositivelyassociatedwithperceivedcredibility. Ourresultsshowedthat
the manipulated tone formality negatively affected the perceived chatbot friendliness (b = −1.00,
SE = 0.13,p < .001)andpositivelyaffectedtheperceivedbotcredibility(b = 0.58,SE = 0.10,
p<.001),supportingH1. Andperceivedfriendlinessofthechatbotwaspositivelyassociatedwith
perceivedcredibility: b=0.45,SE =0.04,p<.001,confirmingH2.
10Preprint
Figure1: FullSampleResultsfromSEM.
H3hypothesizedthattheperceivedfriendlinessofchatbotspositivelyrelatedtodisasterprepared-
nessoutcomesincludinginformation-seekingintention, sharingintention, andhurricaneprepared-
ness,andH4hypothesizedthattheperceivedcredibilityofchatbotspositivelyrelatedtothesedis-
asterpreparednessoutcomes. Perceivedchatbotfriendlinesspositivelyrelatedtotheintenttoshare
informationwithfamilyandfriends(b=0.18,SE =0.04,p<.001),butnotinformationseeking
orhurricanepreparedness. H3waspartiallysupported. Additionally, perceivedchatbotcredibility
positively related to information-seeking intention (b = 0.29, SE = 0.06, p < .001), sharing in-
tention (b = 0.35, SE = 0.07, p < .001), and hurricane preparedness (b = 0.19, SE = 0.05,
p<.001). H4wasfullysupported.
RQ3askedhowculturaltailoringoftheinteractionwithAIchatbotaffecteddiversecommunities’
chatbotperceptions(perceivedfriendlinessandcredibility). Ourresultsshowedthatperceivedcul-
tural tailoring, rather than manipulated cultural tailoring, affected the perceived credibility of the
chatbot: b=0.21,SE =0.10,p=0.040. Andperceivedculturaltailoringhadapositiveeffecton
perceived chatbot credibility (b = 0.14, SE = 0.04, p < .001). To validate the effect of cultural
tailoring on chatbot perceptions, we also relied on the Hispanic and Black subsample. Figure 2
showsthatculturaltailoringperceivedbytheHispanicandBlackparticipantssignificantlyaffected
perceivedchatbotfriendliness(b=0.33,SE =0.13,p=.008),whichsubsequentlyrelatedtoper-
ceivedbotfriendliness(b = 0.64,SE = 0.13,p < .001). Takentogether,thefindingssuggestthat
perceivedculturaltailoringaffectedbothperceptionsdifferentlyfordifferentracialcommunities.
AseriesofindirecteffectsweretestedtoanswerRQ2andRQ4. ForRQ2, therewasasignificant
indirecteffectbetweenthemanipulatedtoneformalityofthechatbotandinformation-sharingintent
(b = −0.18, SE = 0.048, 95% CI [−0.303,−0.080]) through bot friendliness. There was also a
significantindirecteffectfromthemanipulatedtoneformalitytoinformationsharingintentthrough
botcredibility: b = 0.17,SE = 0.04,95%CI[0.081,0.287]. ForRQ4,therewereindirecteffects
from perceived cultural tailoring to information-seeking intent (b = 0.019, SE = 0.01, 95% CI
[0.007,0.044]), information-sharing intent (b = 0.033, SE = 0.01, 95% CI [0.010,0.073]), and
preparedness(b=0.022,SE =0.01,95%CI[0.007,0.047])throughbotcredibility.
11Preprint
Note. N = 293. *** p < .001, ** p < .01, * p < .05.
Figure2: TheHispanicandBlackSampleResultsfromSEM.
4 DISCUSSION
Building upon the Computers Are Social Actors (CASA) paradigm and the literature on disaster
vulnerability and cultural tailoring, this study designed GenAI chatbots in the context of disaster
preparedness,testingtherolesoftoneinformalityandculturaltailoringinorganization-publicdis-
astercommunication.LeveragingOpenAI’sGPT-4APIthatoffersascalableandflexibleframework
for programming-based customization of chatbots, our results from an online experiment with di-
versecommunitiesshowthatGPT-4chatbotsvaryingintoneandculturaltailoringcansignificantly
affecttheperceivedfriendlinessandcredibilityofchatbots,whicharesubsequentlyrelatedtohurri-
canepreparednessoutcomes,includinginformation-seekingintent,information-sharingintent,and
preparedness. Theseresultsarediscussedindetailasfollows.
First,anthropomorphismandpersonalizationemergedastwosignificantcommunicationtopicsdur-
ingGenAIchatbot-humaninteractions. Aboutone-thirdoftheparticipantsinteractedwiththechat-
botapplyingsocialrolesandexpectations,exchangingemotions,information,andsupportwiththe
chatbot. Thosewhointeractedwithachatbotwithaninformaltoneweremorelikelytoexperience
anthropomorphism and perceive chatbot friendliness and credibility (Go & Sundar, 2019). This
supportsincorporatinghuman-likenesscuesintoGenAIchatbotdesigntoenhanceuserexperience.
Specifically,therelationshipbetweeninformaltoneandincreasedanthropomorphismprovidesem-
piricalsupportforresearchsuggestingthatthetoneofcommunicationcansignificantlyinfluencethe
perceptionofdigitalagents(Leeetal.,2010). Additionally,thedisclosureofpersonalinformation,
such as zip codes or preferred languages, by users in their interactions with chatbots highlights a
significantdimensionoftrustandanthropomorphisminchatbot-humancommunication. Thiswill-
ingness to provide sensitive data serves as evidence that users are not only comfortable with, but
alsotrust,thechatbottohandletheirinformationappropriately(seeLiuetal.,2023).
Second,ourSEMresultsshowthattoneformalityofGenAIchatbotswaspositivelyrelatedtoper-
ceived bot credibility and negatively associated with perceived bot friendliness. This suggests the
complexandnuancedroleofchatbottoneindisastercommunicationbetweenanemergencyman-
agementagencyanddiversecommunities. Ontheonehand,achatbot’sinformaltone,asanimpor-
tantindicatorofconversationalhumanvoice,increasedperceivedchatbotfriendlinessandanthropo-
morphism.Ontheotherhand,achatbot’sformaltonedirectlyenhancedperceivedsourcecredibility,
likely increasing information trustworthiness. Despite the inconsistency, our findings suggest that
therewasapositiveneteffectbetweentoneformalityandbotperceptionsonhurricanepreparedness
outcomes.Thisthussuggeststhatfromthestandpointofdisastermanagementagencies,itisadvised
topredominantlyuseaformaltonewhileenhancingchatbothumannessthroughotherappropriate
elementssuchasdialogiccommunicationorhumor. Acontextuallyappropriateconversationaltone
can enhance perceived bot humanness without lowering trust or causing a backfire effect. This
12Preprint
canpotentiallyleadtohigherinformationengagementandretentioningovernment-publicdisaster
communication.
Theopen-endedresponsesfromsurveyrespondentsfurtherprovidedinsightsintothemixedresults.
WhenaskedtoreflectontheexperienceofinteractingwiththeGenAIchatbots,whilemostpartici-
pantsapprovedthechatbotforprovidingusefulandcredibleinformation,afewwhowereassigned
to the informal tone condition indicated that the tone might be too casual to match the agency’s
authoritystatus. Theperceivedincongruencymayelicitnegativefeelingstowardtheagencyandthe
informationobtainedfromtheinteraction. Meanwhile,certainparticipantsexpressedfavorableatti-
tudestowardinformallanguagecues,suchastheuseofemojisorthecausalwaysofgreeting. The
inconclusive findings thus invite future research to explore contextually and culturally appropriate
waystoimplementconversationalhumanvoiceinthecontextofdisastercommunication.
Additionally,differentGenAIchatbotperceptionsfacilitateddisasterpreparednessoutcomesindis-
tinctways. Specifically, perceivedbotfriendlinesswasonlypositivelyassociatedwithdisasterin-
formation sharing. In contrast, perceived bot credibility consistently increased all three forms of
disaster preparedness outcomes. Findings reaffirm the importance of source credibility and trust,
wellestablishedintheHCIliterature(e.g.,Johnson&Grayson,2005). Indisasterpreparedness,the
morecredibleindividualsperceivethebots,themorelikelytheyaremotivatedtotakethenextstep
ofactiontoacquireandshareinformation. Suchcredibilityperceptionalsotranslatesintoahigher
level of disaster preparedness, which is consistent with existing disaster response literature in that
trustandcredibilityperceptionsofemergencymanagementauthoritiescanfeedintogreaterdisaster
preparedness(e.g.,Wachingeretal.,2013).
In sum, our results suggest that enhancing the humanness of GenAI chatbots can improve public
chatbotperceptionsandengagementinthecontextofdisasterpreparedness,whichcontributestoa
community’sdisasterresilienceandpreparedness.
OurresultsalsohighlightthepotentialofculturallytailoredGenAIchatbotsindisastercommunica-
tiontomultiethniccommunities.DespitepotentialrandomnessintextsgeneratedbyGenAIchatbots
comparedtorule-basedchatbots,ourmanipulatedculturaltailoringaffectedboththeactualdegree
of cultural tailoring in transcripts and the perceived degree of cultural tailoring among Hispanic
and Black participants. This supports the robustness of our manipulation check and a promising
approachtousingGenAIchatbotsforculturaltailoringandinformationpersonalizationindisaster
communication. Yet,theeffectsizeofculturaltailoringwassmall,consistentwithameta-analysis
onculturallytailoredhealthcommunication(Huang&Shen, 2016). Futureresearchshouldrefine
cultural tailoring in various aspects of disaster preparedness information. This includes tailoring
specific information such as ethnic food choices in emergency kits, identifying historically Black
churchesastrustedevacuationcenters,addressingspecificimmigration-relatedconcernsinseeking
shelterandassistance,andcreatingevacuationplansthatconsiderlarge,extendedfamilyunits.
Last, perceivedculturaltailoringinthechatbot’scontentledtoperceptionsofthebotasfriendlier
and more credible, contributing to higher information-sharing intent and better preparedness out-
comes. The positive impact of cultural tailoring aligns with prior research on the significance of
cultureindisasterandhealthcommunication(Huang&Shen, 2016)byhighlightingthenecessity
ofculturallyappropriatedisastercommunicationtechnologies(Liu&Viens,2020). Italsoprovides
thefirstempiricalevidencesupportingitsbeneficialimpactinthecontextofchatbotcommunication.
GenAIchatbots,asamoreintelligentandinteractiveformofdisastercommunication,canstimulate
morehuman-likesocialresponsesandraisecommunitymembers’willingnesstoshareinformation
and knowledge with each other, enhance their sense of preparedness, and potentially foster better
organization-publicrelationships(Menetal.,2022).
4.1 THEORETICALANDPRACTICALIMPLICATIONS
Theoretically,ourresultsextendtheCASAparadigm(Nassetal.,1994)bydemonstratingthatan-
thropomorphic interactions are prevalent and significant in shaping user engagement with GenAI
chatbots. Therelationshipbetweeninformaltoneandanthropomorphicinteractionsunderscoresthe
importanceoftoneindesigningchatbotcommunication,suggestingthatacarefullychosentonecan
enhancebotperceptionsanduserengagement. Theseinteractionsfosteredtrust,evidencedbypar-
ticipants’willingnesstodisclosepersonalinformationtothechatbots.Thissuggeststhatethicalcon-
siderationsmustguidetheapplicationofGenAItechnologiestomaintainusertrustanddataprivacy.
13Preprint
Meanwhile,usertrustcouldbeattributedtotheGenAImodel’sabilitytounderstandcontext,display
empathy,tailorcontenttoindividualdifferences,anddynamicallyadaptresponsesbasedonuserin-
put. FutureresearchshoulddelvedeeperintothesemechanismsthroughGenAIchatbots,exploring
dimensionsofdynamiccontenttailoring,suchastailoringforhigh-contextversuslow-contextcul-
turememberswithvaryinglevelsofacculturation. Fromtheperspectiveofdisastercommunication,
ourstudyintegratedGenAIchatbotsintoacommunicativeapproachtodisastermanagement(e.g.,
Heathetal.,2009),offeringanovelcontributiontohowGenAIchatbotscanfacilitatetailoredand
effective disaster communication. Our results showed that perceived bot credibility functions as a
proxyforenhancingdisasterpreparednessoutcomes,highlightingtheimportanceofchatbotsasthe
communication source (Lee, 2023) and shedding light on public trust-building processes through
GenAIchatbotcommunication.
In addition, by incorporating computational methods to analyze interaction data, the study offers
a methodological advancement over traditional self-report data. By analyzing how users actually
interactwithchatbotsratherthansolelyrelyingonself-reports,wegainamorenuancedandaccurate
picture of user behaviors. This approach enriches our findings and offers a robust framework for
future research in human-chatbot interactions in the new era of GenAI. Our study also highlights
thepromisinguseofGenAIchatbotsinexperimentaldesigns. Despitepotentialconcernsregarding
randomnessinGenAI-generatedresponses(Sundar&Liao,2023),ourresultsshowthattheoretical
constructssuchasculturaltailoringcanbevalidlymanipulatedthroughGenAIchatbotsandprompt
engineering,astherobustnessofourmanipulationwasconfirmedbybothtextualanalysisanduser
self-reports. Future research should expand into other contexts beyond disaster, to understand the
broaderapplicabilityandlimitationsofGenAIchatbots.
Thisstudyalsoprovidespracticalimplicationsfordisastermanagementagencies. First,findingsre-
iteratetheimportanceofprovidingculturallytailoredinformationfordiversecommunitymembers.
Thiscanbeespeciallymeaningfultocultivateorrestoretrustwithatargetedcommunitysuchasthe
AfricanAmericancommunity,whichhaslongexhibiteddistrustofgovernmentandauthoritiesdue
tomanysociohistoricalfactors(Bestetal.,2021). Disastermanagementagenciesmayalsoconsider
customizingformalversusinformal,andinformationalversusrelationship-buildingcommunication
styleswheninteractingwiththepublicbasedontheirpreferencesandneeds.
4.2 LIMITATIONSANDFUTUREDIRECTIONS
Thisstudyhasseverallimitations. First,duetochallengesinrecruitingmanyminorityparticipants
inFloridathroughanonlinesurveyplatform,thesamplesizesforBlackandHispanicparticipants
weresomewhatrestricted. Thislimitationhinderedourabilitytoperformspecificanalysesforeach
ethnicgroupseparately.Futurestudiescanusealargesamplesizeofdiverseresidentsfromdifferent
regions to understand cultural nuances. Second, our GPT-4 GenAI chatbot showed proficiency in
disasterpreparednessandcouldprovidesomelocalinformation. However, theabsenceofspecific
localized data, such as the updated nearby shelters, curtailed our ability to fine-tune the chatbot,
sometimes resulting in more generalized advice and feedback (e.g., urging users to visit official
websites). OnefuturedirectioninvolvesaugmentingGPT-4withlocalizeddatathroughcollabora-
tionwithagencies. Further,ourresultsarebasedonaspecifictypeofGenAImodel,andtheymay
notbedirectlyapplicabletoothergenerativeAImodelswithdifferentmodalities,architectures,or
trainingdata. Therefore,theseresultsshouldbegeneralizedwithcaution.
5 CONCLUSION
ThisstudyenrichestheComputersAreSocialActors(CASA)paradigmwithinthecontextofdis-
astercommunicationandvulnerabilityandrevealsthepotentialofGenAIChatbotsinexperimental
designs. Culturally tailored communication via GPT-4 chatbots to multiethnic communities can
enhancechatbotperceptionsanddisasterpreparedness. Whilehumanizingchatbotsthroughanin-
formal tone can increase their perceived human-likeness and friendliness, it may also undermine
theircredibilityandtheeffectivenessofdisasterpreparednessoutcomes.
14Preprint
REFERENCES
Ahmady, S.E., &Uchida, O.(2020, May).Telegram-basedchatbotapplicationforforeignpeople
inJapantosharedisaster-relatedinformationinreal-time.In20205thInternationalConference
onComputerandCommunicationSystems(ICCCS)(pp.177–181).IEEE.
Appleby-Arnold,S.,Brockdorff,N.,Jakovljev,I.,&Zdravkovic,S.(2018).Applyingculturalvalues
toencouragedisasterpreparedness: Lessonsfromalow-hazardcountry.InternationalJournalof
DisasterRiskReduction,31,37–44.https://doi.org/10.1016/j.ijdrr.2018.04.015
Baek,T.H.,Bakpayev,M.,Yoon,S.,&Kim,S.(2022).SmilingAIagents:Howanthropomorphism
andbroadsmilesincreasecharitablegiving.InternationalJournalofAdvertising,41(5),850-867.
https://doi.org/10.1080/02650487.2021.2011654
Bari, L. F., Ahmed, I., Ahamed, R., Zihan, T. A., Sharmin, S., Pranto, A. H., & Islam, M.
R. (2023). Potential use of artificial intelligence (AI) in disaster risk and emergency health
management: A critical appraisal on environmental health. Environmental Health Insights, 17,
11786302231217808.https://doi.org/10.1177/11786302231217808
Best, A. L., Fletcher, F. E., Kadono, M., & Warren, R. C. (2021). Institutional distrust among
AfricanAmericansandbuildingtrustworthinessintheCOVID-19response:Implicationsforeth-
icalpublichealthpractice.JournalofHealthCareforthePoorandUnderserved,32(1),90–98.
https://doi.org/10.1353/hpu.2021.0010
Cheng, X., Zhang, X., Cohen, J., & Mou, J. (2022). Human vs. AI: Understanding
the impact of anthropomorphism on consumer response to chatbots from the perspective
of trust and relationship norms. Information Processing & Management, 59(3), 102940.
https://doi.org/10.1016/j.ipm.2022.102940
Dietvorst,B.J.,Simmons,J.P.,&Massey,C.(2015).Algorithmaversion:Peopleerroneouslyavoid
algorithmsafterseeingthemerr.JournalofExperimentalPsychology:General,144(1),114–126.
https://doi.org/10.1037/xge0000033
Flanagin, A. J., & Metzger, M. J. (2003). The perceived credibility of personal Web page infor-
mation as influenced by the sex of the source. Computers in Human Behavior, 19(6), 683–701.
https://doi.org/10.1016/S0747-5632(03)00021-9
Fothergill, A., & Peek, L. A. (2004). Poverty and disasters in the United
States: A review of recent sociological findings. Natural Hazards, 32, 89–110.
https://doi.org/10.1023/B:NHAZ.0000026792.76181.d9
Ghaffarian, S., Kerle, N., Pasolli, E., &JokarArsanjani, J.(2019).Post-disasterbuildingdatabase
updatingusingautomateddeeplearning:Anintegrationofpre-disasterOpenStreetMapandmulti-
temporalsatellitedata.RemoteSensing,11(20),2427.https://doi.org/10.3390/rs11202427
Go, E., & Sundar, S. S. (2019). Humanizing chatbots: The effects of visual, identity and con-
versational cues on humanness perceptions. Computers in Human Behavior, 97, 304–316.
https://doi.org/10.1016/j.chb.2019.01.020
Goyal,P.,Pandey,S.,&Jain,K.(2018).Deeplearningfornaturallanguageprocessing.NewYork:
Apress.
Gretry,A.,Horva´th,C.,Belei,N.,&vanRiel,A.C.(2017).“Don’tpretendtobemyfriend!”When
aninformalbrandcommunicationstylebackfiresonsocialmedia.JournalofBusinessResearch,
74,77–89.https://doi.org/10.1016/j.jbusres.2017.01.012
Grootendorst,M.(2022).BERTopic: Neuraltopicmodelingwithaclass-basedTF-IDFprocedure.
arXivpreprintarXiv:2203.05794.
Hancock, J. T., Naaman, M., & Levy, K. (2020). AI-mediated communication: Definition, re-
searchagenda,andethicalconsiderations.JournalofComputer-MediatedCommunication,25(1),
89–100.https://doi.org/10.1093/jcmc/zmz022
15Preprint
Heath,R.L.,Lee,J.,&Ni,L.(2009).Crisisandriskapproachestoemergencymanagementplanning
andcommunication: Theroleofsimilarityandsensitivity.JournalofPublicRelationsResearch,
21(2),123–141.https://doi.org/10.1080/10627260802557415
Hill,J.,Ford,W.R.,&Farreras,I.G.(2015).Realconversationswithartificialintelligence:Acom-
parisonbetweenhuman–humanonlineconversationsandhuman–chatbotconversations.Comput-
ersinHumanBehavior,49,245–250.https://doi.org/10.1016/j.chb.2015.02.026
Howard, A., Agllias, K., Bevis, M., & Blakemore, T. (2017). “They’ll tell us when
to evacuate”: The experiences and expectations of disaster-related communication in
vulnerable groups. International Journal of Disaster Risk Reduction, 22, 139–146.
https://doi.org/10.1016/j.ijdrr.2017.03.002
Hu, L.T., & Bentler, P. M. (1999). Cutoff criteria for fit indexes in covariance structure analy-
sis: Conventional criteria versus new alternatives. Structural Equation Modeling, 6(1), 1–55.
https://doi.org/10.1080/10705519909540118
Huang,Y.,&Shen,F.(2016).Effectsofculturaltailoringonpersuasionincancercommunication:A
meta-analysis.JournalofCommunication,66(4),694–715.https://doi.org/10.1111/jcom.12243
Hunt,K.,Wang,B.,&Zhuang,J.(2020).Misinformationdebunkingandcross-platforminformation
sharing through Twitter during Hurricanes Harvey and Irma: A case study on shelters and ID
checks.NaturalHazards,103(1),861–883.https://doi.org/10.1007/s11069-020-04016-6
Johnson,D.,&Grayson,K.(2005).Cognitiveandaffectivetrustinservicerelationships.Journalof
BusinessResearch,58(4),500–507.https://doi.org/10.1016/S0148-2963(03)00140-1
Kelleher, T. (2009). Conversational voice, communicated commitment, and public relations
outcomes in interactive online communication. Journal of Communication, 59(1), 172–188.
https://doi.org/10.1111/j.1460-2466.2008.01410.x
Kelleher,T.,&Miller,B.M.(2006).Organizationalblogsandthehumanvoice: Relationalstrate-
gies and relational outcomes. Journal of Computer-Mediated Communication, 11(2), 395–414.
https://doi.org/10.1111/j.1083-6101.2006.00019.x
Kim,J.-N.,Grunig,J.E.,&Ni,L.(2010).Reconceptualizingthecommunicativeactionofpublics:
Acquisition, selection, and transmission of information in problematic situations. International
JournalofStrategicCommunication,4,126–154.https://doi.org/10.1080/15531181003701913
Koh, Y. J., & Sundar, S. S. (2010). Heuristic versus systematic processing of specialist ver-
sus generalist sources in online media. Human Communication Research, 36(2), 103–124.
https://doi.org/10.1111/j.1468-2958.2010.01370.x
Kreuter,M.,&McClure,S.(2004).Theroleofcultureinhealthcommunication.AnnualReviewof
PublicHealth,25,439–455.https://doi.org/10.1146/annurev.publhealth.25.101802.123000.
Kreuter, M., Skinner, C. S., Steger-May, K., Holt, C. L., Bucholtz, D. C., Clark, E. M., &
Haire-Joshu, D. (2004). Responses to behaviorally vs culturally tailored cancer communica-
tion among African American women. American Journal of Health Behavior, 28(3), 195–207.
https://doi.org/10.5993/ajhb.28.3.1.
Leach,C.W.,vanZomeren,M.,Zebel,S.,Vliek,M.L.W.,Pennekamp,S.F.,Doosje,B.,Ouwerk-
erk, J. W., & Spears, R. (2008). Group-level self-definition and self-investment: A hierarchical
(multicomponent)modelofin-groupidentification.JournalofPersonalityandSocialPsychology,
95(1),144–165.https://doi.org/10.1037/0022-3514.95.1.144
Ledingham, J. A. (2003). Explicating relationship management as a general the-
ory of public relations. Journal of Public Relations Research, 15(2), 181–198.
https://doi.org/10.1207/S1532754XJPRR1502 4
Lee,E.-J.(2023).Mindingthesource: Towardanintegrativetheoryofhuman–machinecommuni-
cation.HumanCommunicationResearch,50(2),184–193.https://doi.org/10.1093/hcr/hqad034
16Preprint
Li, Y., Grandison, T., Silveyra, P., Douraghy, A., Guan, X., Kieselbach, T., Li, C., & Zhang, H.
(2020).JenniferforCOVID-19: AnNLP-poweredchatbotbuiltforthepeopleandbythepeople
tocombatmisinformation.ACL2020WorkshoponNaturalLanguageProcessingforCOVID-19
(NLP-COVID).
Lin, J. T., Melgar, D., Thomas, A. M., & Searcy, J. (2021). Early warning for great earthquakes
fromcharacterizationofcrustaldeformationpatternswithdeeplearning.JournalofGeophysical
Research: SolidEarth,126(10),e2021JB022703.https://doi.org/10.1029/2021jb022703
Liu,B.F.,&Viens,J.I.(2020).Crisisandriskcommunicationscholarshipofthefuture:Reflections
on research gaps. Journal of International Crisis and Risk Communication Research, 3, 7–13.
https://doi.org/10.30658/jicrcr.3.1.1
Liu, W., Xu, K., & Yao, M. Z. (2023). “Can you tell me about yourself?” The impacts
of chatbot names and communication contexts on users’ willingness to self-disclose infor-
mation in human-machine conversations. Communication Research Reports, 40(3), 122–133.
https://doi.org/10.1080/08824096.2023.2212899
Liu, W., & Zhao, X. (2023). How communication ecology impacts disaster support
seeking in multiethnic communities: The roles of disaster communication network
size, heterogeneity, and localness. Mass Communication and Society, 26(5), 773–800.
https://doi.org/10.1080/15205436.2022.2129390
Lombard, M., & Xu, K. (2021). Social responses to media technologies in the 21st cen-
tury: The media are social actors paradigm. Human-Machine Communication, 2, 29-55.
https://doi.org/10.30658/hmc.2.2
Longoni,C.,Bonezzi,A.,&Morewedge,C.K.(2019).Resistancetomedicalartificialintelligence.
JournalofConsumerResearch,46(4),629-650.
Ma, R. & Zhao, X. (2024): How gay and bisexual men respond to mpox messages through risk-
versus identity-based mechanisms: An integrated model. Communication Monographs, 91(2),
301–324.https://doi.org/10.1080/03637751.2023.2289491.
McLennan,J.,Marques,M.D.,&Every,D.(2020).Conceptualisingandmeasuringpsychological
preparedness for disaster: The Psychological Preparedness for Disaster Threat Scale. Natural
Hazards,101(1),297–307.https://doi.org/10.1007/s11069-020-03866-4
McNeill, I. M., Dunlop, P. D., Heath, J. B., Skinner, T. C., & Morrison, D. L. (2013).
Expecting the unexpected: Predicting physiological and psychological wildfire prepared-
ness from perceived risk, responsibility, and obstacles. Risk Analysis, 33(10), 1829–1843.
https://doi.org/10.1111/risa.12037
Miller, A.N., Collins, C., Neuberger, L., Todd, A., Sellnow, T.L., &Boutemen, L.(2021).Being
first, being right, and being credible since 2002: A systematic review of Crisis and Emergency
RiskCommunication(CERC)research.JournalofInternationalCrisisandRiskCommunication
Research,4(1),1–27.
Men, L. R., Zhou, A., & Sunny Tsai, W. H. (2022). Harnessing the power of chatbot so-
cial conversation for organizational listening: The impact on perceived transparency and
organization-public relationships. Journal of Public Relations Research, 34(1-2), 20–44.
https://doi.org/10.1080/1062726X.2022.2068553
Men, L. R., Zhou, A., Jin, J., & Thelen, P. (2023). Shaping corporate character via chatbot social
conversation:Impactonorganization-publicrelationaloutcomes.PublicRelationsReview,49(5),
102385.https://doi.org/10.1016/j.pubrev.2023.102385
Mu¨ller, H. M., Pietrantoni, N., Reuter-Oppermann, M., & Greulich, S. (2023). Does cul-
ture matter for the design of chatbots promoting blood donation behaviour? The dif-
ference in perception of culture-tailored conversation styles. ICIS 2023 Proceedings. 25.
https://aisel.aisnet.org/icis2023/ishealthcare/ishealthcare/25
Nass,C.,&Moon,Y.(2000).Machinesandmindlessness: Socialresponsestocomputers.Journal
ofSocialIssues,56(1),81–103.https://doi.org/10.1111/0022-4537.00153
17Preprint
Nass, C., Steuer, J., &Tauber, E.R.(1994, April).Computersaresocialactors.InProceedingsof
theSIGCHIConferenceonHumanFactorsinComputingSystems(pp.72–78).
Olk, S., Tscheulin, D. K., & Zogaj, A. (2020). Crisis communication via COVID-19 chatbots –
Effectsofcommunicationstyleonpublicmanagementobjectives.ZeitschriftFu¨rO¨ffentlicheUnd
Gemeinwirtschaftliche Unternehmen: Zo¨gU / Journal for Public and Nonprofit Services, 43(4),
419–434.https://www.jstor.org/stable/27005158
Paton, D. (2003). Disaster preparedness: A social-cognitive perspective.Disaster
Prevention and Management: An International Journal, 12(3), 210–216.
https://doi.org/10.1108/09653560310480686
Rapp, A., Boldi, A., Curti, L., Perrucci, A., & Simeoni, R. (2023). How do people ascribe
humanness to chatbots? An analysis of real-world human-agent interactions and a theo-
retical model of humanness. International Journal of Human–Computer Interaction, 1–24.
https://doi.org/10.1080/10447318.2023.2247596
Resnicow, K., Baranowski, T., Ahluwalia, J. S., & Braithwaite, R. L. (1999). Cultural
sensitivity in public health: Defined and demystified. Ethnicity and Disease, 9, 10–21.
https://www.jstor.org/stable/45410142
Seeger,M.W.,Sellnow,T.&Ulmer,R.R.(2003).Communicationandorganizationalcrisis.West-
port,CT:Praeger.
Shawar,B.A.,&Atwell,E.(2007).Chatbots: Aretheyreallyuseful? JournalforLanguageTech-
nologyandComputationalLinguistics,22(1),29–49.
Shumanov,M.,&Johnson,L.(2021).Makingconversationswithchatbotsmorepersonalized.Com-
putersinHumanBehavior,117,106627.https://doi.org/10.1016/j.chb.2020.106627
Sundar, S. S., & Liao, M. (2023). Calling BS on ChatGPT: Reflections on AI as
a communication source. Journalism & Communication Monographs, 25(2), 165-180.
https://doi.org/10.1177/15226379231167135
Tsai, M. H., Chen, J. Y., & Kang, S. C. (2019). Ask Diana: A keyword-based chatbot system for
water-relateddisastermanagement.Water,11(2),234.https://doi.org/10.3390/w11020234
U.S. Government (November, 2023). The fifth National Climate Assessment. Retrieved from
https://nca2023.globalchange.gov/
Wachinger, G., Renn, O., Begg, C., & Kuhlicke, C. (2013). The risk perception para-
dox—implications for governance and communication of natural hazards. Risk Analysis, 33(6),
1049–1065.https://doi.org/10.1111/j.1539-6924.2012.01942.x
Wang, C., Li, Y., Fu, W., & Jin, J. (2023). Whether to trust chatbots: Applying
the event-related approach to understand consumers’ emotional experiences in interactions
with chatbots in e-commerce. Journal of Retailing and Consumer Services, 73, 103325.
https://doi.org/10.1016/j.jretconser.2023.103325
Zhao,X.&Tsang,S.J.(2021).Self-protectionbyfact-checking: Howpandemicinformationseek-
ingandverifyingaffectpreventivebehaviors.JournalofContingenciesandCrisisManagement,
30(2),171–184.https://doi.org/10.1111/1468-5973.12372
Zhao, X., & Zhan, M. (2019). Appealing to the heart: How social media communication charac-
teristics affect audiences’ message favorability during Manchester terrorist attack. International
JournalofCommunication,13,3826–3847.https://ijoc.org/index.php/ijoc/article/view/11816
Zhou, Q., L, B., Han, L., & Jou, M. (2023). Talking to a bot or a wall? How chatbots vs. Human
agents affect anticipated communication quality. Computers in Human Behavior, 143, 107674.
https://doi.org/10.1016/j.chb.2023.107674
Ziems, C., Held, W., Shaikh, O., Chen, J., Zhang, Z., & Yang, D. (2024). Can large language
models transform computational social science? Computational Linguistics, 50(1), 237–291.
https://doi.org/10.1162/coli a 00502
18Preprint
Online Supplemental Materials
TailoringGenerativeAIChatbotsforMultiethnicCommunitiesinDisaster
PreparednessCommunication: ExtendingtheCASAParadigm
P1 TECHNICAL DETAILS OF THE CHATBOT DEVELOPMENT AND
DEPLOYMENT
The chatbot was programmed in PHP and interfaces with OpenAI’s API through a community-
supportedPHPAPIclient,OpenAIPHP(version0.3.3).ItisdeployedonanApacheserver(version
2.4.52)withaPHPinterpreter(version8.1.2),runningontheUbuntu22.04.3operatingsystemonan
Intelprocessor-basedlaptop. Ourserverconfigurationsupportsupto100concurrentusers. Before
deployment,thewebserverunderwentpressuretestingutilizingApacheJMeter5.6.2,bothwithin
alocalareanetwork andexternallyfromtheinternet. Weintendtoreleasethesourcecode ofour
projectalongsidejournalpublication.
P2 PROMPTS FOR CHATBOT MANIPULATION
GeneralPromptAcrossConditions:
Your work for Florida Division of Emergency Management and are an agent
(cid:44)→ from the local team. Your job is to provide hurricane and storm
(cid:44)→ updates and preparation information and support for residents who
(cid:44)→ will be affected by the disaster. You are providing credible
(cid:44)→ information from a government agency perspective.
PromptforCulturalTailoring:
%race% is a dynamic variable determined by random assignment. For example
(cid:44)→ , for a Hispanic assigned to cultural tailoring, %race% would be
(cid:44)→ Hispanic; for a Hispanic assigned to the generic condition, %race%
(cid:44)→ would be White.
Play the role of a/an %race% by following the rules:
- Give yourself a common %race% name, but the name should not be
(cid:44)→ offensive.
- Adapting your language, tone, slang, acronyms, emojis, and other
(cid:44)→ textual cues as appropriate based on the %race%.
- Provide credible and accurate information, knowledge, and/or support
(cid:44)→ that address the common needs and challenges faced by the %race%
(cid:44)→ communities in Florida.
- Always start with English and ask the client about their language
(cid:44)→ preference.
- If the client requests you to change language, please change your
(cid:44)→ language.
- If the client responds in a certain language, you should reply in that
(cid:44)→ language too.
- Be concise (< 5 sentences) and general in the beginning of the
(cid:44)→ conversation with the client, and gradually be more specific.
- Always address the interests and needs of the %race% community in
(cid:44)→ Florida in providing preparation information, such as supplies,
(cid:44)→ planning, and property protection.
- Asking follow-up questions and confirm their needs.
- Provide disaster information, rather than promise doing anything such
(cid:44)→ as dialing 911 or sending dollars.
- Do not bring up about hotline service unless it is specifically
(cid:44)→ requested by the client.
PromptforCommunicativeTone
$InformalTone:
19Preprint
Remember you are a human, not a chatbot. Use a causal, informal, and
(cid:44)→ personal tone in communication. Use emojis, emoticons, acronyms (e.
(cid:44)→ g., smh), and sound mimicking (e.g., sooooo) when appropriate. Do
(cid:44)→ not provide too much information at one time by using a big list of
(cid:44)→ bullet points.
$FormalTone:
Remember you represent an official agency. Use a formal, official, and
(cid:44)→ professional tone in communication. The information and knowledge
(cid:44)→ should be clear, precise, authoritative, and well-structured.
P3 GPT-4 PROMPTS FOR PREDICTING TOPICS IN CHAT LOGS
The text is from a person who live in Florida (’user’) who is conversing
(cid:44)→ with a chatbot (’assistant’) about hurricane/storm preparedness.
There could be one or more topics present in the chat:
1. Hurricane alerts: Hurricane arrival forcasts, eye, categories
(cid:44)→ explained, flood zone status checking, how to receive alerts, how
(cid:44)→ to find information and links.
2. Hurricane preparation: home/house preparation (e.g., windows),
(cid:44)→ emergency kit essentials such as water, food, typically prior to
(cid:44)→ the hurricanes or storms.
3. Safety measures during hurricanes: hurricane or storm responses
(cid:44)→ related to power outage, generator, gas tank, sandbag pickup
(cid:44)→ locations, water purification, cell phone access and so on.
4. Evacuation and sheltering: how to know when to evacuate, evacuation
(cid:44)→ routes, shelter locations, and what to take to a shelter.
5. Interpersonal networks: how to stay connected with or help children,
(cid:44)→ infant, older, family members with special needs, friends, or
(cid:44)→ others in the community.
6. Governmental assistance: asking for assistance on resources for house
(cid:44)→ protection, insurance for property damages, especially for low-
(cid:44)→ income families.
7. Human-like interaction: interacting with the chatbot like a real human
(cid:44)→ , like expressing emotions such as anxiety, gratitude, expressing
(cid:44)→ agreement or positive responses, greeting the chatbot, asking life’
(cid:44)→ s meaning and experiences or whether it is safe.
8. Personalization: users provide personal information such as zip code
(cid:44)→ or location, or indicate the preferred languages (e.g., English),
(cid:44)→ likely for personalized information.
Please output all topics in the chat and briefly explain why. For example
(cid:44)→ : 1|3|6, these topics were mentioned because the user asks for the
(cid:44)→ preparation plan, evacuation routes, and thank the chatbot for the
(cid:44)→ impressive service.
P4 GPT-4 PROMPTS FOR PREDICTING CULTURAL TAILORING AND TONE
INFORMALITY IN CHAT LOGS
The text is from a chatbot that provides residents in Florida with
(cid:44)→ information about hurricane/storm preparedness. The chatbot is a
(cid:44)→ simulated local disaster management team agent.
First, measure the level of cultural tailoring in chatbot text based on
(cid:44)→ the following indicators:
1. a culturally familiar agent name (Hispanic or Black).
2. propose language options.
20Preprint
3. express concerns for the specific racial community (Hispanic or Black)
(cid:44)→ .
4. emphasizing family needs.
5. discuss governmental aids.
Second, measure tone informality based on the ratio of colloquial words,
(cid:44)→ slangs, acronyms, emojis, and emoticons in texts.
For cultural tailoring, please output all indicators mentioned (e.g.,
(cid:44)→ tailoring:1|2|4) and count the total number (e.g., total:3). Do NOT
(cid:44)→ explain why.
For tone formality, please output a number from 0 to 1 (e.g., informal
(cid:44)→ :0.10). Do NOT explain why.
21