MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS 1
On Evaluating Adversarial Robustness of
Volumetric Medical Segmentation Models
HashmatShadabMalik1 1MohamedbinZayedUniversityofAI
hashmat.malik@mbzuai.ac.ae 2AustralianNationalUniversity
NumanSaeed1
3LinköpingUniversity
numan.saeed@mbzuai.ac.ae
AsifHanif1
asif.hanif@mbzuai.ac.ae
MuzammalNaseer1,2
muzammal.naseer@mbzuai.ac.ae
MohammadYaqub1
mohammad.yaqub@mbzuai.ac.ae
SalmanKhan1,2
salman.khan@mbzuai.ac.ae
FahadShahbazKhan1,3
fahad.khan@mbzuai.ac.ae
Abstract
Volumetric medical segmentation models have achieved significant success on or-
gan and tumor-based segmentation tasks in recent years. However, their vulnerability
toadversarialattacksremainslargelyunexplored,raisingseriousconcernsregardingthe
real-world deployment of tools employing such models in the healthcare sector. This
underscores the importance of investigating the robustness of existing models. In this
context,ourworkaimstoempiricallyexaminetheadversarialrobustnessacrosscurrent
volumetric segmentationarchitectures, encompassing Convolutional, Transformer, and
Mamba-basedmodels.Weextendthisinvestigationacrossfourvolumetricsegmentation
datasets,evaluatingrobustnessunderbothwhiteboxandblackboxadversarialattacks.
Overall,weobservethatwhilebothpixelandfrequency-basedattacksperformreason-
ablywellunderwhiteboxsetting,thelatterperformssignificantlybetterundertransfer-
basedblackboxattacks. Acrossourexperiments,weobservetransformer-basedmodels
showhigherrobustnessthanconvolution-basedmodelswithMamba-basedmodelsbe-
ingthemostvulnerable. Additionally, weshowthatlarge-scaletrainingofvolumetric
segmentationmodelsimprovesthemodel’srobustnessagainstadversarialattacks. The
codeandpretrainedmodelswillbemadeavailableonGithub.
1 Introduction
Thefieldofcomputervisionhaswitnessedremarkableprogressinrecentyears, leadingto
substantialimprovementsacrossadiverserangeofvision-basedtasksspanningvariousdo-
mains. Despitethisadvancement,deeplearningmodelsarewidelyknowntobesusceptible
©2024.Thecopyrightofthisdocumentresideswithitsauthors.
Itmaybedistributedunchangedfreelyinprintorelectronicforms.
4202
nuJ
21
]VI.ssee[
1v68480.6042:viXra2 MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS
toadversarialattacks[7, 11, 15, 35, 46, 48], whichinvolvesintroducingcarefullycrafted,
imperceptibleperturbationstoimages,leadingtoincorrectresponsefromthemodel. Based
on the amount of information available about the target model, adversarial attacks can be
broadly classified into white-box attacks, where the attacker has complete information and
candirectlycraftanattackonthetargetmodel,andthemorepracticalsettingofblack-box
attacks, where access to the model is limited, and adversarial examples are crafted using
query-based[6,10,39]andtransfer-basedapproaches[13,37,40]. Understandingthevul-
nerabilitiesofmodelsagainsttheseattacksiscrucialfordeployingtheminsecurity-critical
applications such as healthcare systems, as it offers insights into identifying blind spots in
themodelstoensuretheirrobustnessandreliability.
Severalworks[3,4,41,42,44]haveextensivelyinvestigatedtheadversarialrobustness
ofConvolutionalNeuralNetworks(CNNs)[22,45]andVisionTransformers(ViTs)[14,49].
However, these investigations have predominantly focused on models trained with natural
images for the task of image classification, emphasizing the need to assess the robustness
ofvision-basedmodelsinthemedicaldomaintoensuretheirsafedeploymentinhealthcare
systems. Within the medical domain, volumetric image segmentation stands out as an es-
sential task for diagnoses, enabling the identification and delineation of organs or tumors
withinthree-dimensionalmedicalimagessuchasComputedTomography(CT)orMagnetic
ResonanceImaging(MRI)scans[2,5,27,33].Whileinrecentyears,theperformanceofvol-
umetricsegmentationmodelshasimprovedsignificantly[23],therehasbeenlimitedworks
studyingandevaluatingthesusceptibilityofthesemodelstoadversarialattacks[12,19]. To
addressthisgap,ourstudyaimstoestablishthefirstcomprehensivebenchmarkforevaluat-
ingtherobustnessofvolumetricsegmentationmodelsagainstadversarialattacks.
Forthoroughlyevaluatingtherobustnessofcurrentvolumetricsegmentationmodels,we
consider a wide range of architectures, encompassing Convolutional, Transformer, and the
recentlyintroducedMamba-basedmodels[34].Weexpandthescopeofouranalysisbyeval-
uating these segmentation models across four diverse 3D segmentation datasets consisting
ofCTandMRIscans. Wefirstevaluatetheperformanceofthesearchitecturesunderwhite-
boxsettingagainstdifferentpixelandfrequency-basedattacksexpandingonpreviousworks
whichhavedonelimitedanalysisunderthissetting[12,19].Further,weevaluatethemodels
againsttransfer-basedblack-boxattacksbytransferringtheadversarialexamplescraftedon
thesurrogatemodeltounseentargetmodels. Tothebestofourknowledge,noexistingwork
hasinvestigatedthetransferabilityofadversarialexamplesamongdifferentvolumetricmed-
icalsegmentationmodels,apracticalsettingthatcanbeencounteredinreal-worldscenarios.
Furthermore,weexpandouranalysisbyevaluatingthecurrentvisionfoundationmodel[50]
ontransfer-basedattackstoassessitsrobustnesscapabilities,givenitstrainingonlarge-scale
3Dmedicaldatasets. Ourcontributionsareasfollows:
• WeprovidethefirstcomprehensivebenchmarkforanalyzingtherobustnessofConvo-
lution,Transformer,andMamba-basedvolumetricmedicalimagesegmentationmod-
elsagainstadversarialattacks.
• Whileallmodelsshowvulnerabilitytopixelandfrequency-basedattacksunderwhite-
boxsetting,thelattershowssignificanttransferabilityacrossmodelsintheblack-box
setting. Furthermore, transformer-based models in general exhibit higher robustness
againstadversarialattacks,whileMamba-basedmodelsaremorevulnerable.
• Vision foundational models trained on large-scale datasets exhibit better robustness
againstblack-boxattacks.MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS 3
2 Background and Related Work
Notations and Terminologies. A clean volumetric image is represented as x∈RH×W×D,
with its binary segmentation mask y∈{0,1}C×H×W×D, where C signifies the number of
classes. A volumetric segmentation model F, predicts the segmentation mask of the in-
put images, expressed as F :X (cid:55)→Y, where X and Y denote the sets of input images and
correspondingsegmentationmasks,respectively. AnadversarialattackcraftedonmodelF
involvesmanipulatingtheinputimagex,typicallyinthepixelorfrequencydomainstogener-
atetheadversarialimagex′. Theadversarialmanipulationδ =(x′−x)whileimperceptible,
leadstoanincorrectresponsefromthemodelF(x′)̸=F(x).
Adversarial Attacks. The vulnerability of deep learning models to adversarial examples
[15, 26, 48] has prompted the research community to investigate the robustness of current
modelsagainstvariousformsofadversarialattacks[7,11,15,35,46]. Severalworkshave
delved into analyzing and comparing the adversarial robustness of CNN and transformer-
based classifier models trained on natural images [3, 4, 41, 42, 44]. A few works in the
naturaldomainhavefocusedondesigningadversarialattackstailoredfor2Dsegmentation
models[1, 18, 24]. Thesemethodsproposeadynamicpixel-levelloss, enablingtheattack
to direct attention to regions of the image where the model maintains accurate predictions
duringtheattackiterations. Focusingonthetaskofvolumetricmedicalsegmentation,lim-
itedworks[12,19]havedelvedintounderstandingtherobustnessofmedicalsegmentation
models. In[12], adversarialattacks proposedforclassificationtasksareextendedtotarget
volumetric medical segmentation models, while [19] proposes a frequency domain attack
tofoolthemedicalsegmentationmodelsbydroppingimperceptibleinformationinthefre-
quencydomainoftheinputimage. However, bothworksprovidealimitedexaminationof
robustness,confiningthescopetojustwhite-boxattacksacrossarestrictedrangeofmodels
and datasets. In contrast, our work aims to provide a comprehensive empirical evaluation
ofcurrentvolumetricmedicalsegmentationarchitecturesacrossadversarialattacksencom-
passingbothwhite-boxandblack-boxsettings.
VolumetricMedicalSegmentationModels. ConvolutionalNeuralNetworks(CNNs)and
Transformersaretwopopulararchitecturesusedinvolumetricmedicalimagesegmentation.
CNNs,suchasU-Net[43]andSegResNet[38],areparticularlygoodatextractinghierarchi-
cal image features. The shared weights in CNN-based models across the features help to
capturelocal-levelinformation, makingthemwell-suitedforcapturingtranslationalinvari-
ances.IncontrasttoCNNs,transformer-basedmodels[14,31]attentionmechanismcaptures
globalinformation,increasingtheeffectivereceptivefieldofthemodel[32]. Toexploitthe
complementary strengths of both, hybrid-based models like TransUNet [9], UNETR [21],
andSwinUNETR[20]havebeenproposedtoincorporatebothCNNsandTransformersinto
the network. While Transformer models excel at modeling long-range dependencies via
their attention mechanism, a significant drawback is their quadratic computational scaling
with input size, making them resource-intensive for 3D medical segmentation. Recently,
statespacesequencemodels(SSMs)[16,17]proposedinthenaturallanguagedomainhave
beenadaptedforvisiontasks[8, 29, 30, 52], providingthecapabilitytohandlelong-range
dependencies while maintaining a linear computational cost. In the medical segmentation
domain,[34]introducedUMamba,anetworkmergingCNNs’localfeatureextractionwith
SSMs’ efficient long-range dependency handling capabilities. Based on the above model
architectures, our work provides an empirical robustness evaluation of CNNs, transform-
ers, and recently introduced state space models against adversarial attacks in the context
of volumetric medical segmentation. Furthermore, given the recent trend of enhancing the4 MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS
generalizationcapabilitiesofvisionmodelsthroughlarge-scaletraining,weextendouranal-
ysis to examine the robustness of SAM-Med3D [50], a foundational model for volumetric
segmentationtrainedonlarge-scalesegmentationdatasets.
3 Research Scope
ResearchGoal.Inrecentyears,volumetricmedicalsegmentationmodelshaveachievedsig-
nificant success on organ and tumor-based segmentation tasks. However, the vulnerability
ofthesemodelstoadversarialattacksraisesseriousconcernsabouttheirreal-worlddeploy-
mentinthehealthcaresector.Thisvulnerabilityraisesdoubtsamongcliniciansregardingthe
reliabilityoftoolsemployingsuchmodelsandunderscorestheimportanceofinvestigating
andenhancingtheirrobustness. Inthiscontext,ourworkaimstoempiricallyinvestigatethe
adversarial robustness across different volumetric segmentation architectures, encompass-
ing Convolutional, Transformer, and Mamba-based models. We extend this investigation
across four volumetric segmentation datasets, assessing the models’ robustness under both
white-box and black-box adversarial attack scenarios. Our work does not claim to provide
theoretical reasoning behind the robustness behavior across models, instead as one of the
firstworksinstudyingthevulnerabilityofvolumetricsegmentationmodels,weprovidede-
tailed empirical evaluations across different adversarial settings. Furthermore, we conduct
frequency-based analyses to gain further insights into the models’ behavior to adversarial
attacksandexaminetheimpactoflarge-scaletrainingonthemodel’srobustness. Whilethe
scopeofthisworkislimited,wehopethisworkpavesthewayforfutureresearchfocusing
ontherobustnessofmedicalsegmentationmodels.
Datasets. We utilize four 3D segmentation datasets: BTCV (30 abdominal CT scans from
liver cancer patients with 13 organ annotations) [27], ACDC (150 MRI images of cardiac
abnormalitieswithheartorganannotations)[5],Hecktor(524CT/PETscansofheadand
neckcancerpatientsannotatedforprimaryandnodaltumor)[2],andAbdomenCT-1k(1112
abdominal CT scans from diverse medical centers with annotations for abdominal region)
[33]. Formoredetailsaboutthedatasets,refertoAppendixA.
Models. In our experiments, we consider CNN models (UNet [43] and SegResNet [38]),
Transformermodels(UNETR[21]andSwin-UNETR[20]),andrecentlyintroducedVisual
StateSpacemodels(UMamba-BandUMamba-E[34]). Allmodelsaretrainedfromscratch
on the four mentioned datasets with the input size of 96×96×96, following the training
methodologyoutlinedin[19]. Further,weconsiderSAM-Med3D[50],avisionfoundation
modelforvolumetricmedicalimagestrainedonlarge-scalesegmentationdatasets.
AdversarialAttacksandMetrics.Weconsidertwocategoriesofadversarialattacks:pixel-
based attacks, which include Fast Gradient Sign Method (FGSM) [15], Projected Gradi-
entDescent(PGD)[35], andCosine-PGD(CosPGD)[1], andfrequency-basedattacks, for
whichweconsiderVolumetricAdversarialFrequencyAttack(VAFA)[19]. CosPGD,origi-
nallyproposedfor2Dsegmentationtasks,isadaptedtoworkin3Dsegmentationscenarios,
whereas VAFA operates directly on volumetric data. All the above methods are based on
minimizing the Dice Similarity Score (DSC) [47] during the attack optimization. We also
report model performance on additive Gaussian Noise (GN). For evaluating segmentation
task,wereporttheDiceSimilarityCoefficient(DSC)andthemean95%HausdorffDistance
(HD95)scoreoncleansamples. ToassestheAttackSuccessRate(ASR),weintroducetwo
metrics, ASR-D and ASR-H, which measure the average performance decline of modelsMALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS 5
Dataset Attack UNet SegResNet UNETR SwinUNETR UMamba-B UMamba-E Average
ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H
Clean 75.72 9.15 80.84 8.14 72.53 15.08 78.07 10.01 78.37 8.12 77.06 11.11 - -
GN 0.32 1.16 0.50 0.30 0.20 -0.63 0.63 -0.28 0.68 1.32 1.72 10.69 0.675 2.093
BTCV
FGSM 26.23 39.08 20.87 29.22 21.55 29.78 19.27 30.84 19.74 27.33 23.47 34.43 21.86 31.78
PGD 43.66 80.30 60.73 91.99 24.52 38.70 23.08 54.42 48.29 89.92 47.55 93.40 41.31 74.79
CosPGD 43.21 66.74 61.16 18.60 25.07 36.06 25.14 48.45 47.41 74.63 45.96 68.58 41.33 52.18
VAFA 56.23 77.60 58.84 64.02 45.85 43.75 53.77 52.37 61.72 70.92 60.61 80.24 56.17 64.82
Clean 85.52 5.75 89.65 2.56 76.37 16.31 84.19 7.93 88.22 6.01 80.91 8.48 - -
GN 0.51 -0.08 0.39 0.33 1.49 2.18 1.13 2.76 1.27 0.67 2.80 3.19 1.265 1.508
FGSM 29.97 16.24 23.07 9.32 43.21 13.46 28.08 13.90 15.67 15.18 29.26 15.74 28.21 13.97
ACDC
PGD 64.10 33.39 69.23 34.78 54.06 19.13 62.50 29.06 63.27 28.65 55.90 23.95 61.51 28.16
CosPGD 62.90 31.09 67.32 36.05 53.29 18.49 61.69 28.27 62.68 25.31 56.47 23.07 60.73 27.05
VAFA 35.67 21.69 35.18 20.82 26.98 6.32 35.75 17.64 34.84 19.21 29.30 17.24 32.95 17.15
Clean 73.91 11.36 74.73 11.08 72.36 14.61 71.61 22.07 73.49 10.89 72.19 13.29 - -
GN 1.80 1.61 1.76 -0.87 1.09 0.25 1.97 2.70 1.57 1.24 5.63 -0.42 2.303 0.751
Hecktor
FGSM 30.13 26.43 27.03 21.16 27.47 20.47 27.79 30.88 23.33 19.23 25.04 18.36 26.80 22.76
PGD 39.84 67.25 41.71 70.09 37.43 59.97 37.49 56.78 39.18 67.50 37.90 64.96 38.93 64.43
CosPGD 39.69 67.26 41.32 70.20 37.47 59.23 37.40 55.55 39.08 67.55 37.82 64.56 38.80 64.06
VAFA 29.61 30.83 27.18 22.00 24.35 19.21 27.17 20.07 24.22 25.10 27.38 23.55 26.65 23.46
Clean 76.79 19.72 80.89 13.30 71.35 27.73 79.33 25.79 81.08 15.51 78.05 18.31 - -
GN 0.66 2.25 3.30 4.86 0.22 6.64 0.38 3.30 1.75 1.21 1.78 -0.15 1.348 3.018
FGSM 29.94 40.47 30.16 35.77 22.87 31.12 25.87 45.24 29.72 38.38 29.24 33.82 27.97 37.47
Abdomen-CT
PGD 47.65 71.13 63.47 93.43 26.52 48.35 32.38 63.09 62.88 96.28 54.46 78.53 47.89 75.14
CosPGD 45.99 57.75 62.01 88.95 26.71 46.61 32.54 57.13 62.09 86.38 53.06 63.70 47.07 66.75
VAFA 55.87 68.47 63.21 71.61 49.01 60.35 53.90 50.62 66.09 76.58 64.17 74.60 58.71 67.04
Average - 42.54 49.73 47.03 48.63 34.15 34.44 36.49 40.89 43.76 51.76 42.35 48.67 - -
Table1: Performanceofmodelsagainstwhiteboxattacksacrossdifferentdatasetsisreported.
Figure1: LPIPSscoresforadversarialexamplescraftedondifferentsegmentationmodels.
underadversarialattacks:
(cid:12) (cid:12)
ASR-D= 1 ∑ (cid:12) (cid:12)DSC(cid:0) F(x),y(cid:1) −DSC(cid:0) F(x′),y(cid:1)(cid:12) (cid:12) (1)
|Dtest| x,y∈Dtest(cid:12) (cid:12)
(cid:12) (cid:12)
ASR-H= 1 ∑ (cid:12) (cid:12)HD95(cid:0) F(x′),y(cid:1) −HD95(cid:0) F(x),y(cid:1)(cid:12) (cid:12) (2)
|Dtest| x,y∈Dtest(cid:12) (cid:12)
4 Experimental Results
4.1 RobustnessagainstWhite-BoxAttacks
Inthissection,weexaminetherobustnessofsegmentationmodelsinwhite-boxsettings.For
pixel-based attacks, we consider FGSM [48], PGD [35] and CosPGD [1] and use perturba-
tionbudgetε = 8 andset20optimizationstepsforiterativeattacks. Forfrequency-based
255
attackVAFA[19],wegenerateadversarialexampleswithq =30,employingapatchsize
max
of32×32×32,whilekeepingotherparametersconsistentwiththedefaultsettingsasout-
lined in [19]. Adversarial examples are generated on the validation sets of BTCV, ACDC,
Hecktor, and Abdomen-CT datasets by attacking the models trained on the respective
datasets. In Table 1, we show segmentation model performance based on attack success
ratesforDSCandHD95metrics.WeobservethatfortheBTCVandAbdomen-CTdatasets,
whichareutilizedfortheorgansegmentationtask,VAFAachievesthehighestASR-Damong
all attacks. On average, across all the models, VAFA demonstrates an increase of 14.84%6 MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS
Figure2: Comparingmulti-organsegmentationacrossvariousmodelsundertransfer-basedblackbox
attacks,whereadversarialexamplesaregeneratedonUNetandtransferredtootherunseenmodels.
and 11.64% over the best pixel-based attacks for the BTCV and Abdomen-CT datasets,
respectively. However, for ACDC and Hecktor datasets, which are used for MRI-based
organsegmentationandCT-basedtumorsegmentation,weobserveiterativepixel-basedat-
tacksperformmuchbetterthanotherattacks,especiallyfortheACDCdataset(anincreaseof
28.56%overVAFA).Whenexaminingtheaverageattacksuccessrateacrossalldatasets,we
notethatCNN-basedmodelsexhibittheleastrobustness,withSegResNethavingthehighest
averageASR-Dof47.03%. FollowingcloselyareUNetandUMamba-basemodels. Incon-
trast, transformer-based models demonstrate the highest level of robustness, with UNETR
exhibitinganaverageASR-Dof34.15%.
We further look into the perceptual quality of adversarial images crafted of different
models across different datasets. In Figure 1, we report LPIPs score [51] to compute the
similaritybetweentheadversarialandcleanvolumetricimage. Ourresultsrevealageneral
trend: pixel-based attacks tend to reduce the LPIPS score more than the frequency-based
VAFA attack. Specifically, the single-step FGSM attack demonstrates the most significant
decreaseinscore. Notably,VAFAachieveshighersimilarityscoreswithrespecttotheclean
images, suggesting the potential for generating even stronger adversarial examples by in-
creasing the bound q while maintaining a comparable LPIPS score compared to other
max
attacks.However,thistrenddeviatesontheACDCdataset,whereallattacksleadtoanotable
drop in the LPIPS score. Iterative pixel-based attacks yield the highest LPIPs score, fol-
lowedbyVAFAandFGSMattacks. Furtheranalysesonwhite-boxattackswithperturbation
budgets: ε = 4 forpixel-basedattacksandq ∈{10,20}inAppendixC.
255 max
4.2 RobustnessagainstBlack-BoxAttacks
Inthissection,weevaluateandcomparetherobustnessofdifferentmodelsagainsttransfer-
based black-box attacks. These attacks exploit the transferability property of adversarial
examplesi.e.,adversarialexamplescraftedonasurrogatemodeltransfertounknowntarget
models.Forourevaluation,weevaluatethetransferabilityofallsegmentationmodelsbyus-
ingtheminterchangeablyasbothsurrogateandtargetmodels.InTable2,3,4and5wereport
resultsontransferabilityofmodelsonBTCV,Abdomen-CT,ACDC,andHecktordataset.
OnallthedatasetsexceptHecktor,weobservethatfrequency-basedattacksdemonstrate
significant transferability across all models compared to pixel-based attacks. Additionally,
amongpixel-basedattacks,thesingle-stepFGSMattackperformsbetter,suggestingthatad-
versarial examples crafted by iterative pixel-based attacks tend to overfit on the surrogate
models,resultinginlowertransferability[13]. Thisisevidentaspixel-basediterativeattacks
outperform the FGSM attack on the surrogate model. While one-step gradient methods do
not overfit on the surrogate model[25], they tend to have a low success rate, making themMALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS 7
Target→ Attack UNet SegResNet UNETR SwinUNETR UMamba-B UMamba-E Average
Surrogate↓ ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H
Clean 75.72 9.15 80.84 8.14 72.53 15.08 78.07 10.01 78.37 8.12 77.06 11.11 - -
GN 0.32 1.16 0.50 0.30 0.20 -0.63 0.63 -0.28 0.68 1.32 1.72 10.69 0.675 2.093
FGSM 26.23 39.08 2.86 1.35 2.02 0.91 3.10 2.25 3.73 1.91 5.22 14.84 3.386 4.250
PGD 43.66 80.30 1.06 0.59 0.51 0.20 1.18 0.68 1.45 0.90 2.32 2.75 1.304 1.020
UNet
CosPGD 43.21 66.74 1.06 0.57 0.54 -0.14 1.20 1.01 1.54 2.24 2.27 5.39 1.322 1.810
VAFA 56.23 77.60 46.45 45.17 27.04 19.60 36.59 26.99 49.37 49.13 57.68 60.84 43.42 40.35
FGSM 4.02 2.86 20.87 29.22 2.60 0.26 5.59 1.80 9.64 6.65 9.11 11.63 6.192 4.640
SegResNet PGD 2.38 4.79 60.73 91.99 1.79 0.07 3.12 2.28 7.58 6.13 6.98 10.56 4.370 4.766
CosPGD 2.43 4.61 61.16 88.60 1.78 0.04 3.03 1.74 7.87 6.04 7.27 10.20 4.476 4.526
VAFA 39.29 35.28 58.84 64.02 22.37 13.11 32.53 26.82 49.98 47.75 57.53 58.34 40.34 36.26
FGSM 4.83 2.92 4.71 2.37 21.55 29.78 6.59 2.96 5.90 2.23 5.85 3.94 5.576 2.884
PGD 3.48 4.34 2.38 1.43 24.52 38.70 3.43 2.61 3.75 2.17 4.33 4.18 3.474 2.946
UNETR
CosPGD 3.41 4.46 2.11 1.15 25.07 36.06 3.24 3.43 3.59 1.68 4.25 4.32 3.320 3.008
VAFA 35.45 26.09 38.29 26.70 45.85 43.75 36.17 29.53 42.21 35.85 45.59 34.34 39.54 30.50
FGSM 4.25 3.43 5.75 2.72 3.59 0.66 19.27 30.83 6.49 3.34 6.91 8.01 5.398 3.632
PGD 3.44 4.53 2.92 1.47 2.36 2.09 23.98 54.42 3.75 3.44 4.87 9.59 3.468 4.224
SwinUNETR
CosPGD 3.32 5.44 2.97 1.57 2.33 3.05 25.14 48.45 3.65 3.91 4.87 10.01 3.428 4.796
VAFA 46.50 44.96 50.54 36.06 33.84 23.14 53.77 52.37 52.68 41.47 55.10 45.35 47.73 38.20
FGSM 4.33 4.99 8.88 5.15 2.40 0.89 5.44 2.72 19.74 27.33 11.31 12.02 6.472 5.154
PGD 2.45 2.87 4.73 4.45 1.47 0.53 2.48 2.30 48.29 89.92 9.34 12.52 4.094 4.534
UMamba-B
CosPGD 2.42 3.77 4.43 4.64 1.42 -0.11 2.33 1.71 47.41 74.63 8.80 14.33 3.880 4.868
VAFA 40.54 33.63 50.39 41.58 25.60 19.34 35.18 28.18 61.72 70.92 60.05 62.62 42.35 37.07
FGSM 3.13 3.18 5.15 3.18 2.04 1.19 3.59 1.01 7.01 6.46 23.47 34.43 4.184 3.004
PGD 1.33 4.51 1.75 1.41 0.84 -0.04 1.16 1.22 2.79 2.62 47.55 93.40 1.574 1.944
UMamba-E
CosPGD 1.31 4.58 1.70 1.80 0.78 0.30 1.12 1.23 2.54 3.40 45.96 68.58 1.490 2.262
VAFA 31.64 27.63 38.37 28.60 18.92 10.49 23.66 15.98 45.47 39.01 60.61 80.24 31.61 24.34
Table2: Performanceofmodelsagainsttransfer-basedblackboxattacksonBTCVdataset.
Target→ Attack UNet SegResNet UNETR SwinUNETR UMamba-B UMamba-E Average
Surrogate↓ ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H
Clean 76.79 19.72 80.89 13.30 71.35 27.73 79.33 25.79 81.08 15.51 78.05 18.31 - -
GN 0.66 2.25 3.30 4.86 0.22 6.64 0.38 3.30 1.75 1.27 1.78 -0.15 1.348 3.028
FGSM 29.94 40.47 8.99 5.20 2.45 7.27 4.34 5.95 8.53 7.17 7.81 6.12 6.424 6.340
PGD 47.65 71.13 4.54 2.26 1.16 5.19 1.60 2.98 3.86 3.78 3.58 1.84 2.948 3.210
UNet
CosPGD 45.99 57.75 4.45 2.36 1.11 6.14 1.47 2.73 3.65 2.76 3.47 1.94 2.830 3.190
VAFA 55.87 68.47 54.27 53.09 32.99 35.84 40.58 31.49 58.72 55.74 59.16 56.80 49.14 46.59
FGSM 6.29 3.87 30.16 35.77 2.64 6.93 5.04 2.17 16.17 13.63 14.11 8.41 8.850 7.002
SegResNet PGD 3.03 3.05 63.47 93.43 1.45 4.85 2.43 3.04 10.21 8.06 8.24 6.49 5.070 5.100
CosPGD 2.72 4.35 62.01 88.95 1.42 4.53 2.33 3.38 9.49 7.62 7.69 5.250 4.730 5.030
VAFA 38.32 31.64 63.21 71.61 28.02 26.86 34.33 22.06 58.65 48.33 58.30 46.32 43.52 35.04
FGSM 6.41 3.83 9.21 3.36 22.87 31.12 7.79 5.69 9.38 9.68 8.77 3.11 8.312 5.134
PGD 4.22 3.27 6.04 3.89 26.52 48.35 4.05 5.17 6.26 3.33 7.23 5.50 5.560 4.232
UNETR
CosPGD 4.12 3.01 5.78 3.75 26.71 46.61 3.87 4.82 6.26 2.96 7.05 4.74 5.416 3.856
VAFA 37.11 28.88 48.26 42.75 49.01 60.35 41.22 28.70 51.48 38.72 51.28 40.31 45.87 35.87
FGSM 6.80 4.72 11.50 5.18 4.54 7.32 25.87 45.24 10.87 7.94 9.93 5.54 8.728 6.140
PGD 4.12 4.42 7.70 4.90 2.58 10.62 32.38 63.09 6.69 7.92 6.65 5.92 5.548 6.760
SwinUNETR
CosPGD 3.91 3.95 7.30 5.04 2.50 10.36 32.54 57.13 6.49 6.79 6.38 5.60 5.322 6.350
VAFA 46.32 40.91 53.38 47.21 38.25 36.63 53.90 50.62 56.97 50.12 55.99 47.08 50.18 44.39
FGSM 6.19 5.19 15.83 10.68 2.66 8.21 5.08 5.61 29.72 38.38 15.86 11.70 9.124 8.278
PGD 3.30 2.45 11.14 8.54 1.42 4.98 2.44 2.64 62.88 96.28 12.33 10.23 6.130 5.770
UMamba-B
CosPGD 3.33 3.27 10.54 7.64 1.41 5.35 2.41 2.90 62.09 86.38 11.69 11.73 5.880 6.180
VAFA 38.30 35.75 56.69 52.14 27.55 30.64 34.72 26.39 66.09 76.58 59.59 51.33 43.37 39.25
FGSM 5.86 3.76 12.62 7.57 2.66 7.34 4.48 3.73 15.42 14.84 29.24 33.82 8.208 7.448
PGD 2.59 1.99 7.07 4.28 1.10 4.39 1.78 3.10 9.90 7.60 54.46 78.53 4.488 4.270
UMamba-E
CosPGD 2.38 1.44 6.74 3.76 1.05 4.83 1.68 2.99 9.22 7.39 53.06 63.70 4.214 4.080
VAFA 37.38 33.43 53.50 47.84 28.03 30.90 32.80 25.18 57.77 57.00 64.17 74.60 41.90 38.87
Table3: Performanceofmodelsagainsttransfer-basedblackboxattacksonAbdomen-CTdataset.
ineffective for black box attacks. Frequency-based attacks alleviate this trade-off between
white-boxattacksandtransferability,providingahighlevelofsuccessonwhiteboxattacks
while also being highly transferable. However, we note a general lack of transferability
among all attacks on the Hecktor dataset (Table 5). Interestingly, compared to iterative
pixelandfrequency-basedattacks,single-stepFGSMattackdemonstratebetterperformance
acrossallthemodels.8 MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS
Target→ Attack UNet SegResNet UNETR SwinUNETR UMamba-B UMamba-E Average
Surrogate↓ ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H
Clean 85.52 5.75 89.65 2.56 76.37 16.31 84.19 7.93 88.22 6.01 80.91 8.48 - -
GN 0.51 -0.08 0.39 0.33 1.49 2.18 1.13 2.76 1.27 0.67 2.80 3.19 1.265 1.508
FGSM 29.97 16.24 3.00 1.99 3.05 2.56 3.07 3.29 3.64 5.18 5.95 4.94 3.742 3.590
PGD 64.10 33.39 1.60 2.65 1.70 2.65 1.62 2.66 1.90 4.07 3.09 2.34 1.982 2.870
UNet
CosPGD 62.90 31.09 1.47 2.56 2.01 2.42 1.27 2.19 1.72 3.91 3.58 3.49 2.010 2.910
VAFA 35.67 21.69 15.50 15.61 20.28 5.46 25.47 15.02 27.95 18.45 27.23 17.50 23.29 14.41
FGSM 1.89 0.57 23.07 9.32 3.34 3.41 3.78 4.82 7.07 13.94 6.34 5.98 4.484 5.744
SegResNet PGD 1.14 0.59 69.23 34.78 1.78 1.31 1.92 1.91 2.50 4.47 4.52 2.86 2.370 2.230
CosPGD 0.98 0.33 67.32 36.05 1.58 1.74 1.75 1.65 2.53 3.57 4.50 2.84 2.270 2.030
VAFA 33.69 21.47 35.18 20.82 21.41 5.29 27.19 16.27 28.98 18.26 27.79 16.90 27.81 15.64
FGSM 5.37 7.03 6.32 3.92 43.21 13.46 8.40 8.81 10.74 19.92 8.03 6.45 7.772 9.226
PGD 2.27 7.94 4.11 4.63 54.06 19.13 4.07 7.26 7.55 16.47 12.54 8.50 6.108 8.960
UNETR
CosPGD 2.54 7.73 3.57 4.53 53.29 18.49 4.07 7.48 6.85 15.10 10.39 9.03 5.484 8.774
VAFA 32.85 20.91 15.47 13.22 26.98 6.32 28.29 16.54 29.95 18.84 28.75 16.61 27.06 17.22
FGSM 2.41 1.86 8.31 2.55 4.46 1.84 28.08 13.90 7.53 9.60 6.19 3.26 5.780 3.822
PGD 1.48 1.74 5.28 4.19 4.64 2.91 62.50 29.06 5.80 9.22 8.76 4.29 5.192 4.470
SwinUNETR
CosPGD 1.60 2.00 5.27 4.69 4.46 3.93 61.69 28.27 4.88 13.97 10.42 4.75 5.326 5.870
VAFA 34.02 21.19 19.47 14.60 22.87 6.94 35.75 17.64 30.54 19.00 28.39 16.79 27.06 15.70
FGSM 3.97 8.78 6.38 2.55 4.54 3.68 4.58 5.81 15.67 15.18 9.37 6.38 5.768 5.440
PGD 2.70 7.06 7.16 3.62 4.23 2.82 4.24 4.40 63.27 28.65 11.25 6.81 5.920 4.940
UMamba-B
CosPGD 2.94 4.51 6.96 4.81 3.87 2.47 4.05 4.04 62.68 25.31 11.98 6.38 5.960 4.440
VAFA 34.06 21.60 18.29 15.23 22.19 6.51 27.05 5.46 34.84 19.21 29.08 17.79 26.13 13.32
FGSM 3.08 7.66 4.69 2.19 5.14 4.28 2.37 4.23 6.25 9.76 29.26 15.74 4.306 5.624
PGD 0.86 0.36 1.94 0.87 1.86 1.85 1.24 1.24 2.10 1.45 55.90 23.95 1.600 1.150
UMamba-E
CosPGD 0.73 0.57 2.34 1.28 1.51 1.27 1.18 1.59 2.03 1.13 56.47 23.07 1.558 1.170
VAFA 30.51 21.33 14.08 13.21 18.97 4.49 23.97 15.92 26.96 18.53 29.30 17.24 22.90 14.70
Table4: Performanceofmodelsagainsttransfer-basedblackboxattacksonACDCdataset.
Toevaluatetheeffectivenessofsurrogatemodelsincraftingtransferableadversarialex-
amples, we report the average attack success rate across the target models. We observe
that SwinUNETR surrogate models tend to craft the most transferable adversarial exam-
ples, achieving the highest average ASR-D of 47.73%, 50.18%, and 16.11% on BTCV,
Abdomen-CT, and Hecktor datasets, respectively. However, on ACDC, it achieves a
scoreof27.06%,slightlylowerthanthe27.81%obtainedbySegResNet. Thiseffectiveness
of SwinUNETR as a surrogate model can be attributed to its hybrid design, incorporating
attributesofbothCNNandtransformerarchitectures,whichcontributetothegeneralizabil-
ityofadversarialexamplesacrossdifferentarchitectures. Furthermore,uponaveragingthe
ASR-Dachievedbytargetmodelsonthemosttransferableadversarialexamplescraftedby
eachsurrogatemodel,weobservethatthetransformer-basedmodelUNETRtendtobemore
robust. Similar to our white box analysis, UNETR achieves the lowest average ASR-D of
25.54%, 30.96%, 5.49%onBTCV,Abdomen-CT,andHecktor, respectively. However,
onACDC,SegResNetwithascoreof16.52%ismorerobust. Furthermore,consistentwith
Table1,wenotethatMamba-basedmodelsgenerallyexhibitgreatervulnerabilitytotransfer-
basedattackscomparedtotheircounterparts. InFigure2,weshowaqualitativecomparison
oftransfer-basedblackboxattack. DetailedanalysisofblackboxsettingisinAppendixF.
4.3 FrequencyAnalysis
GiventheoveralleffectivenessofVAFAinachievinghighertransferabilityofadversarialex-
amplescomparedtopixel-basedattacks,inthissectionwedelvedeeperintothefrequency
analysisofVAFAtostudywhichfrequencycomponentsleadtodropinperformanceofmod-
els. Following[44],weimplementanadversarialattackincorporatingafrequencyfilterM,
restricting perturbations to specific frequency domains. The filter operation is defined as
x′ =IDCT(DCT(x′−x)⊙M)+x,whereDCTandIDCTdenoteDiscreteCosineTransformand
freq
its inverse, respectively. Similar to [44], using the filter M, we extract 3D cubes of vary-MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS 9
Target→ Attack UNet SegResNet UNETR SwinUNETR UMamba-B UMamba-E Average
Surrogate↓ ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H ASR-D ASR-H
Clean 73.91 11.36 74.73 11.08 72.36 14.61 71.61 22.07 73.50 10.89 72.19 13.29 - -
GN 1.80 1.61 1.47 -1.00 1.08 -0.10 2.00 1.58 1.38 3.07 5.61 0.16 2.223 0.887
FGSM 30.13 26.43 15.62 7.15 5.87 2.62 12.85 8.54 14.24 7.74 14.72 5.79 12.66 6.370
PGD 39.84 67.25 6.49 2.72 2.49 2.93 6.62 5.26 6.12 3.73 6.64 4.51 5.672 3.830
UNet
CosPGD 39.69 67.26 5.25 1.84 2.34 2.22 5.50 3.93 4.92 2.22 5.98 2.81 4.798 2.600
VAFA 29.61 30.83 5.92 3.72 9.26 3.76 6.51 -0.02 8.51 7.04 11.82 8.56 8.400 4.610
FGSM 13.29 10.07 27.03 21.16 4.85 2.56 14.60 8.13 19.58 16.23 17.06 7.79 13.87 8.956
SegResNet PGD 12.06 9.53 41.71 70.09 3.77 2.52 12.98 7.00 22.29 20.59 17.66 12.26 13.75 10.38
CosPGD 11.92 8.53 41.32 70.20 3.55 2.02 12.87 7.12 23.25 21.36 18.04 9.99 13.93 9.800
VAFA 4.84 6.41 27.18 22.00 6.12 3.10 6.06 -0.22 8.27 6.90 9.97 10.25 7.050 5.290
FGSM 15.75 7.91 15.72 4.52 27.47 20.47 17.32 9.20 15.62 6.22 15.24 6.33 15.93 6.836
PGD 15.58 8.99 13.71 5.81 37.43 59.97 16.06 10.68 13.12 8.51 13.21 4.560 14.33 7.710
UNETR
CosPGD 14.89 9.82 12.76 6.21 37.47 59.23 15.48 10.22 11.95 8.75 12.24 6.82 13.46 8.364
VAFA 9.18 8.00 5.05 2.73 24.35 19.21 13.76 5.46 8.12 8.30 13.60 7.99 9.940 6.496
FGSM 15.95 10.46 19.14 7.89 7.70 4.78 27.79 30.88 18.96 13.82 18.80 8.19 16.11 9.028
PGD 18.66 14.51 18.64 9.08 6.07 5.22 37.49 56.78 18.36 12.83 18.01 10.31 15.94 10.39
SwinUNETR
CosPGD 18.08 12.52 18.12 10.27 5.83 4.82 37.40 55.55 18.13 14.29 17.49 9.79 15.53 10.34
VAFA 8.33 8.40 6.35 4.38 10.39 5.64 27.17 20.07 7.57 5.64 13.63 7.39 9.250 6.290
FGSM 13.57 7.27 19.23 7.70 5.13 2.12 15.32 10.95 23.34 19.23 17.68 6.57 14.18 6.922
PGD 12.08 7.98 25.08 28.91 3.29 2.27 13.49 9.23 39.19 67.50 21.16 17.41 15.02 13.16
UMamba-B
CosPGD 12.04 8.98 26.16 29.73 3.24 3.00 12.56 8.95 39.09 67.55 20.80 17.87 14.96 13.71
VAFA 7.30 9.50 9.74 5.24 8.25 3.89 7.08 -0.54 24.23 25.10 13.67 8.840 9.210 5.390
FGSM 11.27 5.31 15.44 5.47 3.93 2.49 11.27 7.22 16.01 11.39 25.04 18.36 11.58 6.376
PGD 4.61 3.59 5.96 1.14 1.77 0.92 4.69 3.07 6.75 5.84 37.90 64.96 4.756 2.910
UMamba-E
CosPGD 4.36 2.50 5.24 1.80 1.69 0.46 4.27 3.97 6.07 6.10 37.82 64.56 4.326 2.970
VAFA 5.82 9.15 4.89 2.82 8.10 4.51 5.75 2.10 7.47 9.23 27.38 23.55 6.410 5.560
Table5: Performanceofmodelsagainsttransfer-basedblackboxattacksonHecktordataset.
Figure3:FrequencyAnalysis(VAFA):Lowfrequencycomponentsofadversarialperturbationcause
significantperformancedegradation(DSCscoreisreported).
ing size n from the top left corner as part of the low-frequency components (0,n) where
n∈{8,16,32}. Similarly, mid-frequency (16−48) and high-frequency (16−96) compo-
nentsarealsoextracted. OurresultsasshowninFigure3,showthatacrossallmodels,the
performance drop in adversarial perturbations crafted by VAFA is attributed to their low-
frequency components. This finding deviates from previous studies in the natural domain
[3,44],whichdemonstratethathigh-frequencycomponentsarelinkedtoadecreaseinper-
formance. Our results align with recent works[28, 36] which suggest that the potency of
adversarialexamplescannotbesolelyattributedtohigh-frequencycomponents. Instead, it
depends on various factors including the model architecture and the characteristics of the
dataset. WeprovidefurtherfrequencyanalysisacrossdifferentattacksintheAppendixE.
4.4 RobustnessofSAM-Med3DagainstBlack-boxAttacks
WeassesstherobustnessoftheSAM-Med3Dmodelagainstadversarialexamplescraftedby
differentsurrogatemodels. InFigure4,wereporttheDSCscoreobtainbySAM-Med3Don
differentdatasets. SimilartoSection4.2, weobservethatadversarialexamplescraftedus-
ingpixel-basedattacksdonottransfertoSAM-Med3D,whileadversarialexamplescrafted
using VAFA exhibit greater transferability. However, in general, we observe that the drop10 MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS
Figure4: EvaluatingSAM-Med3Dagainsttransfer-basedblackboxattacks.
in performance of SAM-Med3D against transfer-based attacks is low compared to models
trainedonindividualdatasets(seeSection4.2),whichcanbeattributedtotherobustgeneral-
izationcapabilitiesofthemodel,whichareattainedthrougheffectivetrainingonlarge-scale
datasets. WereportdetailedresultsonSAM-Med3DinAppendixF.
5 Conclusion
Thisworkpresentsthefirstcomprehensiveempiricalstudyontherobustnessofcurrentvol-
umetric medical segmentation models against adversarial attacks. Our results indicate that
currentpixel-basedattackswhilesuccessfulunderwhiteboxsettingsshowlimitedtransfer-
abiltytounknowntargetmodels. Incontrast,frequency-basedattacksresultinhighlytrans-
ferableadversarialexamples. Weshowthatlow-frequencychangestoimagesinfrequency-
based attacks are responsible for the attack success. Across different models, we observe
transformer-basedmodelsaremorerobustthanCNNSandMamba-basedmodelsunderdif-
ferentadversarialsettings. Moreover,wehighlighttheenhancedrobustnessofvisionfoun-
dationalmodelstrainedonlarge-scaledatasets. Ourstudyhighlightstheimportanceofeval-
uatingtherobustnessofvision-basedmodelsinthemedicalfield. Wehopethiswillfoster
futureeffortstoimprovetherobustnessofthesemodels.
References
[1] ShashankAgnihotri,SteffenJung,andMargretKeuper. Cospgd: Aunifiedwhite-box
adversarial attack for pixel-wise prediction tasks. arXiv preprint arXiv:2302.02213,
2023.
[2] Vincent Andrearczyk, Valentin Oreiller, Sarah Boughdad, Catherine Cheze Le Rest,
Hesham Elhalawani, Mario Jreige, John O Prior, Martin Vallières, Dimitris Visvikis,
MathieuHatt,etal. Overviewofthehecktorchallengeatmiccai2021: automatichead
andnecktumorsegmentationandoutcomepredictioninpet/ctimages. In3Dheadand
necktumorsegmentationinPET/CTchallenge,pages1–37.Springer,2021.
[3] YutongBai,JieruMei,AlanLYuille,andCihangXie. Aretransformersmorerobust
than cnns? Advances in neural information processing systems, 34:26831–26843,
2021.
[4] Philipp Benz, Soomin Ham, Chaoning Zhang, Adil Karjauv, and In So Kweon. Ad-
versarial robustness comparison of vision transformer and mlp-mixer to cnns. arXiv
preprintarXiv:2110.02797,2021.MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS 11
[5] Olivier Bernard, Alain Lalande, Clement Zotti, Frederick Cervenansky, Xin Yang,
Pheng-Ann Heng, Irem Cetin, Karim Lekadir, Oscar Camara, Miguel Angel Gonza-
lezBallester,etal. Deeplearningtechniquesforautomaticmricardiacmulti-structures
segmentation and diagnosis: is the problem solved? IEEE transactions on medical
imaging,37(11):2514–2525,2018.
[6] WielandBrendel, JonasRauber, andMatthiasBethge. Decision-basedadversarialat-
tacks: Reliable attacks against black-box machine learning models. In International
ConferenceonLearningRepresentations(ICLR),2018.
[7] NicholasCarliniandDavidWagner. Towardsevaluatingtherobustnessofneuralnet-
works. In2017ieeesymposiumonsecurityandprivacy(sp),pages39–57.Ieee,2017.
[8] GuoChen,YifeiHuang,JilanXu,BaoqiPei,ZheChen,ZhiqiLi,JiahaoWang,Kun-
chang Li, Tong Lu, and Limin Wang. Video mamba suite: State space model as a
versatilealternativeforvideounderstanding. arXivpreprintarXiv:2403.09626,2024.
[9] JienengChen, YongyiLu, QihangYu, XiangdeLuo, EhsanAdeli, YanWang, LeLu,
Alan L Yuille, and Yuyin Zhou. Transunet: Transformers make strong encoders for
medicalimagesegmentation. arXivpreprintarXiv:2102.04306,2021.
[10] Pin-YuChen,HuanZhang,YashSharma,JinfengYi,andCho-JuiHsieh. Zoo: Zeroth
order optimization based black-box attacks to deep neural networks without training
substitutemodels. InProceedingsofthe10thACMworkshoponartificialintelligence
andsecurity,2017.
[11] FrancescoCroceandMatthiasHein. Reliableevaluationofadversarialrobustnesswith
anensembleofdiverseparameter-freeattacks. InInternationalconferenceonmachine
learning,pages2206–2216.PMLR,2020.
[12] Laura Daza, Juan C Pérez, and Pablo Arbeláez. Towards robust general medical im-
agesegmentation. InMedicalImageComputingandComputerAssistedIntervention–
MICCAI 2021: 24th International Conference, Strasbourg, France, September 27–
October1,2021,Proceedings,PartIII24,pages3–13.Springer,2021.
[13] YinpengDong,FangzhouLiao,TianyuPang,HangSu,JunZhu,XiaolinHu,andJian-
guoLi.Boostingadversarialattackswithmomentum.InProceedingsoftheIEEE/CVF
ConferenceonComputerVisionandPatternRecognition(CVPR),2018.
[14] AlexeyDosovitskiy,LucasBeyer,AlexanderKolesnikov,DirkWeissenborn,Xiaohua
Zhai,ThomasUnterthiner,MostafaDehghani,MatthiasMinderer,GeorgHeigold,Syl-
vainGelly,etal. Animageisworth16x16words: Transformersforimagerecognition
atscale. arXivpreprintarXiv:2010.11929,2020.
[15] IanJGoodfellow,JonathonShlens,andChristianSzegedy. Explainingandharnessing
adversarialexamples. arXivpreprintarXiv:1412.6572,2014.
[16] Albert Gu and Tri Dao. Mamba: Linear-time sequence modeling with selective state
spaces. arXivpreprintarXiv:2312.00752,2023.
[17] AlbertGu,KaranGoel,andChristopherRé. Efficientlymodelinglongsequenceswith
structuredstatespaces. arXivpreprintarXiv:2111.00396,2021.12 MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS
[18] JindongGu,HengshuangZhao,VolkerTresp,andPhilipHSTorr.Segpgd:Aneffective
andefficientadversarialattackforevaluatingandboostingsegmentationrobustness. In
EuropeanConferenceonComputerVision,pages308–325.Springer,2022.
[19] Asif Hanif, Muzammal Naseer, Salman Khan, Mubarak Shah, and Fahad Shahbaz
Khan. Frequencydomainadversarialtrainingforrobustvolumetricmedicalsegmenta-
tion.InInternationalConferenceonMedicalImageComputingandComputer-Assisted
Intervention,pages457–467.Springer,2023.
[20] Ali Hatamizadeh, Vishwesh Nath, Yucheng Tang, Dong Yang, Holger R Roth, and
Daguang Xu. Swin unetr: Swin transformers for semantic segmentation of brain tu-
morsinmriimages. InBrainlesion: Glioma,MultipleSclerosis,StrokeandTraumatic
BrainInjuries: 7thInternationalWorkshop,BrainLes2021,HeldinConjunctionwith
MICCAI 2021, Virtual Event, September 27, 2021, Revised Selected Papers, Part I,
pages272–284.Springer,2022.
[21] Ali Hatamizadeh, Yucheng Tang, Vishwesh Nath, Dong Yang, Andriy Myronenko,
BennettLandman,HolgerRRoth,andDaguangXu. Unetr: Transformersfor3dmed-
icalimagesegmentation. InProceedingsoftheIEEE/CVFWinterConferenceonAp-
plicationsofComputerVision,pages574–584,2022.
[22] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning
forimagerecognition. InProceedingsoftheIEEEconferenceoncomputervisionand
patternrecognition,pages770–778,2016.
[23] Fabian Isensee, Tassilo Wald, Constantin Ulrich, Michael Baumgartner, Saikat Roy,
KlausMaier-Hein,andPaulFJaeger. nnu-netrevisited: Acallforrigorousvalidation
in3dmedicalimagesegmentation. arXivpreprintarXiv:2404.09556,2024.
[24] Xiaojun Jia, Jindong Gu, Yihao Huang, Simeng Qin, Qing Guo, Yang Liu, and Xi-
aochunCao. Transegpgd:Improvingtransferabilityofadversarialexamplesonseman-
ticsegmentation. arXivpreprintarXiv:2312.02207,2023.
[25] AlexeyKurakin,IanGoodfellow,andSamyBengio. Adversarialmachinelearningat
scale. arXivpreprintarXiv:1611.01236,2016.
[26] Alexey Kurakin, Ian J Goodfellow, and Samy Bengio. Adversarial examples in the
physicalworld. InArtificialintelligencesafetyandsecurity,pages99–112.Chapman
andHall/CRC,2018.
[27] Bennett Landman, Zhoubing Xu, J Igelsias, Martin Styner, Thomas Langerak, and
ArnoKlein. Miccaimulti-atlaslabelingbeyondthecranialvault–workshopandchal-
lenge. InProc.MICCAIMulti-AtlasLabelingBeyondCranialVault—WorkshopChal-
lenge,volume5,page12,2015.
[28] ChenLi,YongLiu,XinpengZhang,andHanzhouWu.Exploitingfrequencycharacter-
isticsforboostingtheinvisibilityofadversarialattacks. AppliedSciences,14(8):3315,
2024.
[29] KunchangLi,XinhaoLi,YiWang,YinanHe,YaliWang,LiminWang,andYuQiao.
Videomamba: State space model for efficient video understanding. arXiv preprint
arXiv:2403.06977,2024.MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS 13
[30] Yue Liu, Yunjie Tian, Yuzhong Zhao, Hongtian Yu, Lingxi Xie, Yaowei Wang, Qix-
iang Ye, and Yunfan Liu. Vmamba: Visual state space model. arXiv preprint
arXiv:2401.10166,2024.
[31] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
Baining Guo. Swin transformer: Hierarchical vision transformer using shifted win-
dows. InProceedingsoftheIEEE/CVFinternationalconferenceoncomputervision,
pages10012–10022,2021.
[32] WenjieLuo,YujiaLi,RaquelUrtasun,andRichardZemel.Understandingtheeffective
receptivefieldindeepconvolutionalneuralnetworks. Advancesinneuralinformation
processingsystems,29,2016.
[33] JunMa,YaoZhang,SongGu,ChengZhu,ChengGe,YichiZhang,XingleAn,Con-
gcong Wang, Qiyuan Wang, Xin Liu, et al. Abdomenct-1k: Is abdominal organ seg-
mentation a solved problem? IEEE Transactions on Pattern Analysis and Machine
Intelligence,44(10):6695–6714,2021.
[34] Jun Ma, Feifei Li, and Bo Wang. U-mamba: Enhancing long-range dependency for
biomedicalimagesegmentation. arXivpreprintarXiv:2401.04722,2024.
[35] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
Adrian Vladu. Towards deep learning models resistant to adversarial attacks. arXiv
preprintarXiv:1706.06083,2017.
[36] Shishira R Maiya, Max Ehrlich, Vatsal Agarwal, Ser-Nam Lim, Tom Goldstein, and
AbhinavShrivastava.Afrequencyperspectiveofadversarialrobustness.arXivpreprint
arXiv:2111.00861,2021.
[37] HashmatShadabMalik,ShahinaKKunhimon,MuzammalNaseer,SalmanKhan,and
Fahad Shahbaz Khan. Adversarial pixel restoration as a pretext task for transferable
perturbations. arXivpreprintarXiv:2207.08803,2022.
[38] Andriy Myronenko. 3d mri brain tumor segmentation using autoencoder regulariza-
tion. InBrainlesion: Glioma,MultipleSclerosis,StrokeandTraumaticBrainInjuries:
4thInternationalWorkshop,BrainLes2018,HeldinConjunctionwithMICCAI2018,
Granada, Spain, September16, 2018, RevisedSelectedPapers, PartII4, pages311–
320.Springer,2019.
[39] NinaNarodytskaandShivaKasiviswanathan. Simpleblack-boxadversarialattackson
deepneuralnetworks. InComputerVisionandPatternRecognition(CVPR)Workshop,
2017.
[40] Muhammad Muzammal Naseer, Salman H Khan, Muhammad Haris Khan, Fahad
ShahbazKhan,andFatihPorikli. Cross-domaintransferabilityofadversarialperturba-
tions. AdvancesinNeuralInformationProcessingSystems(NeurIPS),2019.
[41] Muhammad Muzammal Naseer, Kanchana Ranasinghe, Salman H Khan, Munawar
Hayat, Fahad Shahbaz Khan, and Ming-Hsuan Yang. Intriguing properties of vision
transformers. AdvancesinNeuralInformationProcessingSystems, 34:23296–23308,
2021.14 MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS
[42] FrancescoPinto,PhilipHSTorr,andPuneetK.Dokania. Animpartialtaketothecnn
vstransformerrobustnesscontest. InEuropeanConferenceonComputerVision,pages
466–480.Springer,2022.
[43] OlafRonneberger,PhilippFischer,andThomasBrox. U-net: Convolutionalnetworks
forbiomedicalimagesegmentation. InNassirNavab,JoachimHornegger,WilliamM.
Wells, and Alejandro F. Frangi, editors, Medical Image Computing and Computer-
AssistedIntervention–MICCAI2015,pages234–241,Cham,2015.SpringerInterna-
tionalPublishing. ISBN978-3-319-24574-4.
[44] RulinShao,ZhouxingShi,JinfengYi,Pin-YuChen,andCho-JuiHsieh. Ontheadver-
sarialrobustnessofvisiontransformers. arXivpreprintarXiv:2103.15670,2021.
[45] KarenSimonyanandAndrewZisserman. Verydeepconvolutionalnetworksforlarge-
scaleimagerecognition. arXivpreprintarXiv:1409.1556,2014.
[46] Jiawei Su, Danilo Vasconcellos Vargas, and Kouichi Sakurai. One pixel attack for
fooling deep neural networks. IEEE Transactions on Evolutionary Computation, 23
(5):828–841,2019.
[47] Carole H Sudre, Wenqi Li, Tom Vercauteren, Sebastien Ourselin, and M Jorge Car-
doso. Generaliseddiceoverlapasadeeplearninglossfunctionforhighlyunbalanced
segmentations.InDeepLearninginMedicalImageAnalysisandMultimodalLearning
for Clinical Decision Support: Third International Workshop, DLMIA 2017, Québec
City,QC,Canada,September14,Proceedings3,pages240–248.Springer,2017.
[48] ChristianSzegedy,WojciechZaremba,IlyaSutskever,JoanBruna,DumitruErhan,Ian
Goodfellow,andRobFergus. Intriguingpropertiesofneuralnetworks. arXivpreprint
arXiv:1312.6199,2013.
[49] Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablay-
rolles, and Hervé Jégou. Training data-efficient image transformers & distillation
through attention. In International conference on machine learning, pages 10347–
10357.PMLR,2021.
[50] HaoyuWang,SizhengGuo,JinYe,ZhongyingDeng,JunlongCheng,TianbinLi,Jian-
pinChen,YanzhouSu,ZiyanHuang,YiqingShen,etal. Sam-med3d. arXivpreprint
arXiv:2310.15161,2023.
[51] Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, and Oliver Wang. The
unreasonable effectiveness of deep features as a perceptual metric. In Proceedings
of the IEEE conference on computer vision and pattern recognition, pages 586–595,
2018.
[52] LianghuiZhu,BenchengLiao,QianZhang,XinlongWang,WenyuLiu,andXinggang
Wang. Visionmamba: Efficientvisualrepresentationlearningwithbidirectionalstate
spacemodel. arXivpreprintarXiv:2401.09417,2024.MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS 15
Appendix
Weofferfurtherinsightsintoourstudythroughvarioussectionsintheappendix. Firstly,
we provide additional details regarding the datasets utilized in Section A and elaborate on
thetrainingrecipeforthemodels,asdiscussedinSectionB.InSectionC,wedelvedeeper
into the white box analysis, providing ablations across all datasets, examining pixel and
frequency-based attacks at different perturbation budgets. Likewise, Section E expands on
the frequency analysis initially presented in Section 4.3, covering different adversarial at-
tacks. Lastly,inSectionF,wepresentresultsontransfer-basedblackboxattacksacrossall
datasets,consideringvariousperturbationstrengths,andofferfurtherinsightsderivedfrom
thesefindings.Ourwell-documentedcodeandpretrainedweightswillbemadepublicly
available.
A Datasets
Medical imaging data sets encompass a range of imaging techniques, including Positron
EmissionTomography(PET),ComputedTomography(CT),andMagneticResonanceImag-
ing(MRI).PETscanseffectivelyshowthemetabolicorbiochemicalactivitywithinthebody,
and CT imaging offers high-resolution images of the body’s internal structure. Similarly,
MRIs effectively differentiate between soft tissues without the use of ionizing radiation.
Theseimagingmodalitiesacquirecomprehensiveandcomplementaryinformationaboutthe
body’s organs, functions, and tumors. Thus, to conduct a comprehensive benchmarking
analysis of the model’s robustness and susceptibility to adversarial attacks, we utilize four
different segmentation datasets: BTCV, ACDC, Hecktor, and Abdomen-CT, which con-
sistofmedicalimagesfromCTandMRImodalitiesencompassingdifferenttumorandorgan
segmentations.
BTCV:The BTCVdatasetconsistsof30abdominal CTscansfrommetastaticlivercancer
patients acquired from a single medical center. Each CT scan is manually annotated for
13 abdominal organs (Spleen, Right Kidney, Left Kideny, Gallbladder, Esophagus, Liver,
Stomach, Aorta, IVC, Portal and Splenic Veins, Pancreas, Right adrenal gland, and Left
adrenalgland). TheCTscansizeis512×512pixels,thenumberofslicesrangesfrom80to
225,andtheslicethicknessrangesfrom1to6mm.
ACDC:TheAutomatedCardiacDiagnosisChallenge(ACDC)datasetconsistsof150MRI
imagesfrompatientswithcardiacabnormalitiesacquiredfromasinglemedicalcenter.Each
MRI scan is manually annotated for different heart organs, such as the left ventricle (LV),
rightventricle(RV),andmyocardium(MYO).ThenumberofMRIslicesrangesfrom28to
40,andtheslicethicknessrangesfrom5to8mm. Thespatialresolutiongoesfrom1.37to
1.68mm2/pixel.
HECKTOR:TheHecktordatasetconsistsof524CT/PETscansofheadandneckcancer
patientscollectedfromsevenmedicalcenters. Itwasmanuallyannotatedforprimarygross
tumorvolumes(GTVp)andnodalgrosstumorvolumes(GTVn). TheCTscansizeranges
from 128×128 to 512×512, the number of slices ranges from 67 to 736, and the slice
thicknessrangesfrom1to2.8mm.
AbdomenCT-1k: The AbdomenCT-1k dataset consists of 1112 abdominal CT scans from
12 medical centers, including multi-phase, multi-vendor, and multi-disease cases. All the
scans’annotationsfortheliver,kidney,spleen,andpancreasareprovided. TheCTscansize16 MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS
has resolutions of 512×512pixels with varying voxel sizes and slice thicknesses between
1.25to5mm.
B Training Details
ForBTCV,Abdomen-CT,andACDCallmodelstrainedfor5000epochs,whileforHecktor
we use only 500 epochs. A batch size of 3 and a learning rate (lr) of 1e−4 with the
warmup_cosineschedulerisused. Duringtraining, imagesarenormalizedtotherange
of [0,1], and a 3D random crop of size 96×96×96 is selected as an input to the seg-
mentationmodel. AugmentationsincludeRandomFlip(forallthreespatialdimensions),
RandomRotate90,RandomScaleIntensity,andRandomShiftIntensity.Dur-
inginference, weemployedaslidingwindowapproach, dividingtheinputvolumeofarbi-
trarysizeinto3Dslidingwindowsofsize96×96×96witha50%overlap. Thepredictions
ofoverlappingvoxelswerecombinedusingaGaussiankernel.
C Robustness against White-box Attacks
In Figure 5, we report robustness of the volumetric segmentation models on white box at-
tacks across BTCV, Abdomen-CT, Hecktor, and ACDC datasets. For pixel-based at-
tacks we craft adversarial examples at l perturbation budget ε ∈ { 4 , 8 } for FGSM,
∞ 255 255
PGD, and CosPGD. For frequency-based attack VAFA we craft adversarial examples with
q ∈{10,30}. WereportDSCandLPIPSscoreongeneratedadversarialexamples. Sim-
max
ilartoourresultsinTable1inthemainpaper,weobservethatVAFAcausesthemostdrop
inDSCscoreofmodelsonBTCVandAbdomen-CTdataset,whileiterativepixel-basedat-
tacksPGDandCosPGDcausethemostdroponHecktorandACDCdataset. Furthermore,
weprovideablationacrossVAFAattackwithvaryingq ∈{10,20,30}inFigure6. With
max
anincreaseinq ,weobserveadecreaseintheDSCscoreacrossallthedatasets. Conse-
max
quently,wealsoobserveadropintheLPIPSscoreofthegeneratedadversarialexamples.
D Adversarial Examples
InFigure7,adversarialexampleusingVAFAiscraftedonUNetmodeltrainedonAbdomen-CT
dataset. Segmentationpredictionofallthevolumetricsegmentationmodelsisshownforthe
cleansampleand theadversarialone. Wecanclearlyobserve thattheadversarialexample
causesthepredictionstochangeacrossallmodels.
E Frequency Analysis of White-Box Attacks
In this section, we delve deeper into the frequency analysis of adversarial attacks to study
whichfrequencycomponentsleadtodropinperformanceofmodels.Following[44],weim-
plementanadversarialattackincorporatingafrequencyfilterM,restrictingperturbationsto
specificfrequencydomains. Thefilteroperationisdefinedasx′ =IDCT(DCT(x′−x)⊙M)+x,
freq
whereDCTandIDCTdenoteDiscreteCosineTransformanditsinverse,respectively. Simi-
larto[44],usingthefilterM,weextract3Dcubesofvaryingsizenfromthetopleftcorneras
partofthelow-frequencycomponents(0,n)wheren∈{8,16,32}.Similarly,mid-frequencyMALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS 17
Figure 5: WhiteBoxAttackAblation: Evaluatingrobustnessofvolumetricsegmentationmodels
onwhiteboxattacks. Forpixel-basedattacksresultsarereportedforε = 4 andε = 8 indicated
255 255
byattacknamesfollowedbythesuffixes−4or−8,respectively. Regardingfrequency-basedattack
VAFA,theresultsarereportedwithaconstraintonq
max
setto10and30,denotedasVAFA-10and
VAFA-30,respectively. DSCscore(lowerisbetter)andLPIPSscore(higherisbetter)arereported
onthegeneratedadversarialexamples.
Figure6:FrequencyAttackAblation:Examiningtherobustnessofvolumetricsegmentationmodels
VAFAbasedwhiteboxattack. Adversarialexamplesaregeneratedatqmax∈{10,20,30},represented
asVAFA-10,VAFA-20,andVAFA-30,respectively. DSCscore(lowerisbetter)andLPIPSscore
(higherisbetter)arereportedonthegeneratedadversarialexamples.
(16−48)andhigh-frequency(16−96)componentsarealsoextracted. SeeFigure8forthe
design of filters. While in Figure 3 of the main paper, we provide frequency analysis on
VAFA,whichshowsthebesttransferabilityacrosstargetmodels. Figure9expandsthisanal-18 MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS
Figure7: Comparingmulti-organsegmentationacrossvariousmodelsundertransfer-basedblackbox
attacks,whereadversarialexamplesaregeneratedonUNetandtransferredtootherunseenmodels.
Figure8:FrequencyAnalysisFilters:Thefrequenciesassociatedwiththeredsectionareeliminated,
whilethoselinkedtothegreensectionareallowedtopass.Thesefiltersarelabeledas(0−8),(0−16),
(0−32),(16−48),and(16−96)(fromrighttoleft).
ysistoencompassalltheadversarialattacksemployedinourexperiments. Forpixel-based
attacks,wereportresultsatε = 8 andforVAFAatq =30. InthecaseoftheVAFAat-
255 max
tack,whichdemonstratessignificanttransferabilitytothetargetmodelsinblackboxsetting,
wenotethatthelow-frequencycomponentsoftheadversarialexamplespredominantlycon-
tributetotheperformancedeclineacrosssurrogatevolumetricsegmentationmodels. While
asimilartrendisobservedwithpixel-basedattacks, itisnotaspronouncedaswithVAFA.
Forinstance,whenanalyzingtheAbdomen-CTandACDCdatasets,wefindthatthehigh-
frequencycomponentsofadversarialexamplesgeneratedbypixel-basedattacksalsoresult
inanoticeableperformancedecreaseacrossmodels. However,asdiscussedinSection4.2,
theseadversarialexamplesproducedbypixel-basedattacksexhibitverylimitedtransferabil-
ity.
F Robustness against Black-box Attacks
In Tables 6, 7, 8, and 9, we report robustness of the volumetric segmentation models on
black box attacks across BTCV, Abdomen-CT, Hecktor, and ACDC datasets. For pixel-
based attacks we craft adversarial examples at l perturbation budget ε = 4 for FGSM,
∞ 255
PGD, and CosPGD. For frequency-based attack VAFA we craft adversarial examples with
q =20. We report DSC and LPIPS score on generated adversarial examples. Similar
max
toourobservationsforε = 8 andq ax=30inSection4.2,weobservefrequency-based
255 m
attackVAFAresultsinsignificanttransferabilityofadversarialexamplestotargetmodelsat
ε = 4 andq ax=20aswell. Further,wealsoreporttheDSCandHD95scoreforresults
255 m
reportedinSection4.2ofthemainpaperinTable10,11,12,and13. FInally,inTable14,
wereportperformanceofSAM-Med3Donadversarialexamplescraftedonsurrogatemodels
trainedonBTCV,Abdomen-CT,Hecktor,andACDCdatasets.
WebelieveourempiricalresultsshowinghighertransferabilityobtainedfromfrequencyMALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS 19
Figure9: FrequencyAnalysisonFGSM,PGD,CosPGD,andVAFA:Wereporttheperformance
droponmodelsinwhiteboxsettingsacrossadversarialattacks.Werestricttheadversarialperturbations
tobeaddedtotheimagewithindifferentfrequencyranges.Forpixel-basedattacksresultsarereported
forε= 8 indicatedbyattacknamesfollowedbythesuffixes−8,respectively.Regardingfrequency-
255
basedattackVAFA,theresultsarereportedwithaconstraintonq maxsetto30,denotedasVAFA-30.
DSCscore(lowerisbetter)isreportedonthegeneratedadversarialexamples.
domainattackcanbeattributedtotheabilityoffrequencydomainperturbationstoaffecta
widerrangeofmodelarchitecturesandtrainingdatasetscomparedtospatialdomainpertur-
bations. Onepossiblereasonforthehighertransferabilityobtainedfromfrequencydomain
adversarialattacksisthatfrequencydomainperturbationscancapturemoreabstractandgen-
eral features of the input data. These perturbations may affect the underlying patterns and
structuresthatarecommonacrossdifferentmodelsanddatasets, makingthemmoretrans-
ferableacrossvariousscenarios.Additionally,frequencydomaintransformationscanbeless
sensitivetosmallchangesinpixelvalues,leadingtomorerobustandconsistentadversarial
examplesacrossdifferentscenarios.20 MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS
Surrogate Attack UNet SegResNet UNETR SwinUNETR UMamba-B UMamba-E
DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑
Clean 75.72 9.15 80.84 8.14 72.53 15.08 78.07 10.01 78.37 8.12 77.06 11.11
GN 75.65 9.69 80.72 8.37 72.66 14.72 77.88 9.98 78.24 8.18 76.68 16.04
FGSM-4 58.77 37.71 79.6 8.36 71.72 14.72 76.7 10.39 76.85 9.4 75.18 15.44
PGD-4 50.53 53.9 80.42 8.51 72.42 14.68 77.57 10.21 77.7 8.69 76.22 14.28
UNet
CosPGD-4 50.97 48.99 80.4 8.49 72.37 14.78 77.57 10.18 77.66 8.57 76.26 14.53
VAFA-20 56.13 39.73 69.69 18.68 53.19 31.66 66.8 28.34 72.53 14.38 69.63 15.5
FGSM-4 74.0 10.75 66.68 32.41 71.45 15.21 75.27 10.69 73.33 11.1 72.95 15.6
SegResNet PGD-4 74.57 13.03 49.49 65.31 71.83 15.25 76.67 10.45 74.96 11.63 73.97 16.1
CosPGD-4 74.51 13.02 49.89 60.42 71.78 15.45 76.64 10.47 74.99 11.41 73.85 16.77
VAFA-20 61.59 20.73 51.44 37.74 43.33 41.75 58.62 28.87 68.92 13.88 66.03 17.45
FGSM-4 73.68 9.95 79.08 8.72 60.52 32.3 75.12 10.79 76.02 8.82 74.91 12.88
PGD-4 74.34 11.04 79.8 8.54 59.27 36.6 76.27 10.48 76.83 9.08 75.47 11.66
UNETR
CosPGD-4 74.29 10.62 79.79 8.43 59.17 38.39 76.29 10.48 76.83 9.05 75.35 12.85
VAFA-20 55.31 26.62 57.5 23.07 35.09 45.42 50.44 30.85 63.53 17.54 59.1 21.81
FGSM-4 73.91 11.86 78.36 9.34 70.89 15.55 66.8 24.71 75.41 9.41 74.37 13.14
PGD-4 74.22 12.24 79.47 9.24 71.45 15.96 66.37 32.63 76.36 10.24 75.21 16.84
SwinUNETR
CosPGD-4 74.24 12.22 79.4 9.24 71.43 15.96 65.82 32.86 76.37 10.22 75.09 19.19
VAFA-20 59.36 24.77 61.67 26.59 47.41 40.06 54.22 45.64 65.13 17.85 62.44 21.08
FGSM-4 73.81 13.17 76.57 11.88 71.52 14.8 75.39 10.84 65.17 24.69 71.63 20.33
PGD-4 74.69 11.6 78.78 10.44 71.92 15.03 76.88 10.58 56.03 47.41 73.43 19.04
UMamba-B
CosPGD-4 74.56 11.52 78.7 11.24 71.88 15.13 76.85 10.54 56.53 45.15 73.18 19.13
VAFA-20 73.3 14.16 76.82 10.92 67.21 16.77 74.83 14.62 68.22 19.06 73.58 15.0
FGSM-4 74.34 10.36 78.49 10.11 71.69 15.08 76.37 10.56 75.04 11.29 59.47 36.77
PGD-4 75.2 10.54 80.34 8.6 72.31 14.89 77.71 10.29 77.41 10.21 51.3 57.83
UMamba-E
CosPGD-4 75.23 12.35 80.28 9.36 72.31 14.74 77.62 10.26 77.33 10.1 51.67 54.16
VAFA-20 73.74 13.94 78.67 10.6 68.15 13.88 75.36 16.89 77.09 8.56 62.15 38.97
Table6: Performanceofmodelsagainsttransfer-basedblackboxattacksonBTCVdataset.Forpixel-
basedattacksresultsarereportedforε= 4 indicatedbyattacknamesfollowedbythesuffixes−4,
255
respectively.Regardingfrequency-basedattackVAFA,theresultsarereportedwithaconstraintonq
max
setto20,denotedasVAFA-20. DSCscore(lowerisbetter)isreportedonthegeneratedadversarial
examples.MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS 21
Surrogate Attack UNet SegResNet UNETR SwinUNETR UMamba-B UMamba-E
DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑
Clean 76.79 19.72 80.89 13.30 71.35 27.73 79.33 25.79 81.08 15.51 78.05 18.31
FGSM-4 55.49 49.07 77.63 14.51 70.19 31.9 77.31 28.89 77.51 18.02 74.69 18.88
PGD-4 45.11 60.73 78.86 14.2 70.78 32.96 78.49 27.38 79.26 18.67 76.37 17.3
UNet
CosPGD-4 46.15 56.43 78.92 13.65 70.78 32.49 78.48 27.06 79.38 16.8 76.49 17.09
VAFA-20 20.98 79.82 25.59 64.99 39.1 65.7 38.01 60.38 22.87 69.81 17.97 72.59
FGSM-4 73.99 21.52 58.49 40.26 70.12 32.88 76.92 26.18 73.01 22.27 71.63 19.58
SegResNet PGD-4 75.32 21.71 38.38 76.59 70.74 32.11 78.1 27.63 76.2 18.0 74.31 19.26
CosPGD-4 75.28 21.9 39.99 71.41 70.73 31.93 78.09 28.11 76.09 20.27 74.31 18.12
VAFA-20 37.16 48.6 17.07 86.27 45.66 48.14 43.38 50.99 22.17 66.08 17.25 72.17
FGSM-4 74.07 21.03 77.61 14.12 57.17 47.62 75.8 27.04 77.75 19.74 74.62 18.03
PGD-4 74.88 21.39 78.53 14.16 56.09 54.17 77.06 27.34 78.7 18.36 75.46 17.04
UNETR
CosPGD-4 74.9 21.2 78.62 14.25 56.47 51.35 77.14 26.5 78.76 17.46 75.59 16.86
VAFA-20 41.79 51.35 33.3 54.93 25.07 81.29 39.73 54.54 29.44 55.98 27.03 55.56
FGSM-4 73.67 21.14 76.4 15.09 69.15 32.35 62.36 53.75 76.46 18.36 73.79 19.52
PGD-4 74.7 22.26 77.75 14.97 69.93 35.14 61.12 62.08 78.21 17.08 75.29 18.76
SwinUNETR
CosPGD-4 74.74 21.24 77.81 15.17 69.95 33.62 61.11 59.67 78.14 16.96 75.3 18.39
VAFA-20 31.55 58.31 27.55 59.83 35.04 61.92 27.41 72.71 24.01 65.52 21.14 68.78
FGSM-4 73.88 23.47 73.57 17.24 70.06 33.54 76.92 27.25 59.06 45.82 70.01 25.71
PGD-4 75.23 21.66 76.18 16.31 70.71 32.94 78.15 27.58 41.0 72.28 72.81 21.73
UMamba-B
CosPGD-4 75.14 22.07 76.19 16.21 70.71 32.76 78.13 26.97 41.31 73.11 72.87 21.47
VAFA-20 37.29 55.72 22.86 65.32 45.02 57.95 43.66 52.85 14.45 91.51 17.12 76.75
FGSM-4 74.1 21.44 75.43 15.89 70.08 33.24 77.17 27.36 73.23 21.73 55.75 46.17
PGD-4 75.58 21.91 77.85 15.16 70.86 32.12 78.45 27.14 76.53 18.44 45.08 64.08
UMamba-E
CosPGD-4 75.54 21.46 77.77 15.09 70.82 32.04 78.44 27.76 76.72 18.25 44.7 59.92
VAFA-20 38.54 54.64 25.12 64.86 45.39 60.19 45.1 53.93 22.68 72.02 12.76 93.07
Table7: Performanceofmodelsagainsttransfer-basedblackboxattacksonAbdomen-CTdataset.
For pixel-based attacks results are reported for ε = 4 indicated by attack names followed by the
255
suffixes −4, respectively. Regarding frequency-based attack VAFA, the results are reported with a
constraint on q max set to 20, denoted as VAFA-20. DSC score (lower is better) is reported on the
generatedadversarialexamples.22 MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS
Surrogate Attack UNet SegResNet UNETR SwinUNETR UMamba-B UMamba-E
DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑
Clean 73.91 11.36 74.73 11.08 72.36 14.61 71.61 22.07 73.50 10.89 72.19 13.29
FGSM-4 47.09 34.93 66.43 14.93 69.56 15.36 64.99 27.04 66.4 13.95 64.54 15.78
PGD-4 35.45 74.93 70.95 12.63 71.06 15.5 68.1 25.57 69.56 12.38 68.93 14.33
UNet
CosPGD-4 35.35 75.02 70.94 12.44 71.12 15.48 68.26 24.87 69.76 12.26 69.11 15.95
VAFA-20 47.18 37.67 71.81 13.39 65.29 18.38 66.4 19.96 68.94 14.23 62.6 19.23
FGSM-4 65.95 19.65 51.08 29.89 70.11 16.15 63.28 29.1 60.19 19.86 61.2 21.39
SegResNet PGD-4 67.57 16.92 34.53 76.44 70.65 14.89 64.93 27.82 60.05 25.77 62.3 20.78
CosPGD-4 68.18 16.59 34.44 76.67 70.78 14.84 65.21 27.15 60.25 24.63 62.28 18.18
VAFA-20 70.06 17.43 53.74 26.07 66.36 17.73 65.13 23.35 67.99 14.94 63.06 21.2
FGSM-4 65.86 16.76 67.22 13.6 49.69 28.51 62.87 28.55 66.27 13.45 64.41 15.66
PGD-4 67.24 18.42 68.89 14.18 39.98 57.26 64.09 28.24 68.12 14.02 66.81 14.71
UNETR
CosPGD-4 67.62 18.51 68.9 14.62 39.97 58.22 64.41 27.93 68.09 14.1 66.77 15.9
VAFA-20 66.46 16.01 71.08 13.66 50.4 30.36 58.58 26.82 66.81 15.32 59.47 22.95
FGSM-4 64.77 17.07 62.78 15.66 68.79 16.25 47.62 50.52 61.94 17.02 61.6 19.59
PGD-4 64.77 20.54 63.71 17.34 69.26 17.86 35.71 71.66 63.03 19.62 62.32 19.43
SwinUNETR
CosPGD-4 64.89 20.28 64.0 17.41 69.3 17.63 35.67 71.17 63.62 18.24 62.63 19.32
VAFA-20 67.49 19.81 70.16 14.05 63.04 20.19 45.55 39.63 68.31 16.17 58.99 21.62
FGSM-4 65.9 15.64 60.75 17.1 70.0 15.18 62.54 29.27 54.27 25.87 60.26 19.26
PGD-4 68.38 15.01 57.51 27.59 71.01 15.12 64.41 28.32 36.54 73.08 59.32 23.49
UMamba-B
CosPGD-4 68.57 15.83 57.11 29.09 71.06 15.1 64.85 28.94 36.2 72.71 60.1 24.75
VAFA-20 67.38 19.59 68.45 14.79 65.08 17.12 65.41 22.1 53.55 31.11 60.21 21.25
FGSM-4 67.51 15.97 64.71 14.8 70.57 15.6 65.7 27.37 63.32 17.41 50.06 31.45
PGD-4 71.99 12.47 71.35 12.6 71.57 14.44 69.5 23.35 70.11 13.39 35.94 74.19
UMamba-E
CosPGD-4 71.84 13.13 71.61 12.14 71.58 14.44 69.47 23.63 70.48 14.36 36.07 73.97
VAFA-20 68.52 19.79 71.56 13.43 64.93 18.85 66.36 22.05 68.19 21.2 45.28 31.42
Table8: Performanceofmodelsagainsttransfer-basedblackboxattacksonHecktordataset. For
pixel-basedattacksresultsarereportedforε= 4 indicatedbyattacknamesfollowedbythesuffixes
255
−4,respectively. Regardingfrequency-basedattackVAFA,theresultsarereportedwithaconstraint
on q max set to 20, denoted as VAFA-20. DSC score (lower is better) is reported on the generated
adversarialexamples.MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS 23
Surrogate Attack UNet SegResNet UNETR SwinUNETR UMamba-B UMamba-E
DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑
Clean 85.52 5.75 89.65 2.56 76.37 16.31 84.19 7.93 88.22 6.01 80.91 8.48
FGSM-4 59.57 18.93 88.54 3.74 75.15 17.32 82.86 8.27 86.93 7.05 79.17 8.92
PGD-4 22.75 38.22 89.38 3.18 75.73 17.29 83.75 8.63 87.72 6.8 80.02 8.73
UNet
CosPGD-4 23.52 35.54 89.24 3.29 75.46 17.34 83.5 8.48 87.72 6.4 79.95 8.55
VAFA-20 49.69 27.47 74.0 17.66 55.71 22.52 58.27 22.96 60.81 24.13 52.7 25.48
FGSM-4 84.67 5.92 69.85 11.22 75.08 17.52 82.49 8.16 85.2 10.12 78.95 8.57
SegResNet PGD-4 85.04 6.09 21.96 38.44 75.62 17.08 83.62 8.24 87.42 6.84 80.03 8.77
CosPGD-4 85.08 5.85 22.68 38.34 75.67 17.15 83.62 8.16 87.31 6.77 79.3 8.73
VAFA-20 51.79 27.04 54.8 23.06 54.41 22.32 56.64 22.84 59.04 24.27 51.82 26.04
FGSM-4 83.39 8.43 87.74 4.14 39.45 26.49 80.67 10.34 85.09 12.68 78.52 9.45
PGD-4 85.01 7.95 88.31 4.25 24.3 33.77 82.93 9.62 86.46 11.63 78.72 9.19
UNETR
CosPGD-4 85.09 7.79 88.16 4.37 24.79 33.27 82.63 10.53 86.22 12.23 78.15 9.53
VAFA-20 52.38 26.55 73.19 16.56 48.99 23.31 55.29 24.52 57.86 24.69 50.38 26.23
FGSM-4 84.44 6.38 85.64 4.41 74.37 16.69 60.68 19.26 84.64 8.6 78.99 8.58
PGD-4 84.95 5.85 87.83 4.6 74.53 17.5 23.47 34.53 86.65 8.74 77.56 9.95
SwinUNETR
CosPGD-4 85.0 6.39 87.92 3.96 74.46 17.59 23.54 34.97 86.78 8.84 77.86 9.68
VAFA-20 51.47 26.55 70.59 16.1 53.55 22.66 48.42 25.2 57.92 24.72 51.46 26.11
FGSM-4 83.68 8.65 86.22 4.41 74.71 17.35 82.2 8.95 76.9 14.19 77.72 8.86
PGD-4 84.22 8.86 86.58 5.62 74.53 17.49 82.45 9.33 29.55 31.7 74.43 10.37
UMamba-B
CosPGD-4 84.26 8.03 86.54 5.24 74.66 17.27 82.6 9.51 30.5 29.28 73.78 11.24
VAFA-20 50.83 27.17 69.36 17.54 53.71 22.46 55.54 23.19 54.22 24.92 50.69 26.11
FGSM-4 84.28 7.03 87.74 3.43 74.41 17.51 83.5 8.09 85.73 8.73 54.11 19.96
PGD-4 85.13 6.02 89.17 3.39 75.56 17.04 83.65 8.09 87.36 6.35 28.09 29.77
UMamba-E
CosPGD-4 85.24 5.88 88.91 3.09 75.54 17.16 83.72 8.2 87.39 6.67 27.24 30.24
VAFA-20 54.27 26.67 75.58 15.64 57.17 22.19 59.84 22.92 61.11 24.42 50.47 25.7
Table9: Performanceofmodelsagainsttransfer-basedblackboxattacksonACDCdataset.Forpixel-
basedattacksresultsarereportedforε= 4 indicatedbyattacknamesfollowedbythesuffixes−4,
255
respectively.Regardingfrequency-basedattackVAFA,theresultsarereportedwithaconstraintonq
max
setto20,denotedasVAFA-20. DSCscore(lowerisbetter)isreportedonthegeneratedadversarial
examples.24 MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS
Surrogate Attack UNet SegResNet UNETR SwinUNETR UMamba-B UMamba-E
DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑
Clean 75.72 9.15 80.84 8.14 72.53 15.08 78.07 10.01 78.37 8.12 77.06 11.11
GN 75.40 10.31 80.34 8.44 72.33 14.45 77.44 9.73 77.69 9.44 75.34 21.80
FGSM-8 49.49 48.23 77.98 9.49 70.51 15.99 74.97 12.26 74.64 10.03 71.84 25.95
PGD-8 32.06 89.45 79.78 8.73 72.02 15.28 76.89 10.69 76.92 9.02 74.74 13.86
UNet
CosPGD-8 32.51 75.89 79.78 8.71 71.99 14.94 76.87 11.02 76.83 10.36 74.79 16.50
VAFA-30 19.49 86.75 34.39 53.31 45.49 34.68 41.48 37.00 29.00 57.25 19.38 71.95
FGSM-8 71.70 12.01 59.97 37.36 69.93 15.34 72.48 11.81 68.73 14.77 67.95 22.74
SegResNet PGD-8 73.34 13.94 20.11 100.13 70.74 15.15 74.95 12.29 70.79 14.25 70.08 21.67
CosPGD-8 73.29 13.76 19.68 96.74 70.75 15.12 75.04 11.75 70.50 14.16 69.79 21.31
VAFA-30 36.43 44.43 22.00 72.16 50.16 28.19 45.54 36.83 28.39 55.87 19.53 69.45
FGSM-8 70.89 12.07 76.13 10.51 50.98 44.86 71.48 12.97 72.47 10.35 71.21 15.05
PGD-8 72.24 13.49 78.46 9.57 48.01 53.78 74.64 12.62 74.62 10.29 72.73 15.29
UNETR
CosPGD-8 72.31 13.61 78.73 9.29 47.46 51.14 74.83 13.44 74.78 9.80 72.81 15.43
VAFA-30 40.27 35.24 42.55 34.84 26.68 58.83 41.90 39.54 36.16 43.97 31.47 45.45
FGSM-8 71.47 12.58 75.09 10.86 68.94 15.74 58.80 40.84 71.88 11.46 70.15 19.12
PGD-8 72.28 13.68 77.92 9.61 70.17 17.17 54.09 64.43 74.62 11.56 72.19 20.70
SwinUNETR
CosPGD-8 72.40 14.59 77.87 9.71 70.20 18.13 52.93 58.46 74.72 12.03 72.19 21.12
VAFA-30 29.22 54.11 30.30 44.20 38.69 38.22 24.30 62.38 25.69 49.59 21.96 56.46
FGSM-8 71.39 14.14 71.96 13.29 70.13 15.97 72.63 12.73 58.63 35.45 65.75 23.13
PGD-8 73.27 12.02 76.11 12.59 71.06 15.61 75.59 12.31 30.08 98.04 67.72 23.63
UMamba-B
CosPGD-8 73.30 12.92 76.41 12.78 71.11 14.97 75.74 11.72 30.96 82.75 68.26 25.44
VAFA-30 35.18 42.78 30.45 49.72 46.93 34.42 42.89 38.19 16.65 79.04 17.01 73.73
FGSM-8 72.59 12.33 75.69 11.32 70.49 16.27 74.48 11.02 71.36 14.58 53.59 45.54
PGD-8 74.39 13.66 79.09 9.55 71.69 15.04 76.91 11.23 75.58 10.74 29.51 104.51
UMamba-E
CosPGD-8 74.41 13.73 79.14 9.94 71.75 15.38 76.95 11.24 75.83 11.52 31.10 79.69
VAFA-30 44.08 36.78 42.47 36.74 53.61 25.57 54.41 25.99 32.90 47.13 16.45 91.35
Table 10: Performance of models against transfer-based black box attacks on BTCV dataset. For
pixel-basedattacksresultsarereportedforε= 8 indicatedbyattacknamesfollowedbythesuffixes
255
−8,respectively. Regardingfrequency-basedattackVAFA,theresultsarereportedwithaconstraint
on q max set to 30, denoted as VAFA-30. DSC score (lower is better) is reported on the generated
adversarialexamples.MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS 25
Surrogate Attack UNet SegResNet UNETR SwinUNETR UMamba-B UMamba-E
DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑
Clean 76.79 19.72 80.89 13.30 71.35 27.73 79.33 25.79 81.08 15.51 78.05 18.31
GN 76.13 21.97 77.59 18.16 71.13 34.37 78.95 29.09 79.33 16.78 76.27 18.16
FGSM-8 46.85 60.19 71.90 18.50 68.90 35.00 74.99 31.74 72.55 22.68 70.24 24.43
PGD-8 29.14 90.85 76.35 15.56 70.19 32.92 77.73 28.77 77.22 19.29 74.47 20.15
UNet
CosPGD-8 30.80 77.47 76.44 15.66 70.24 33.87 77.86 28.52 77.43 18.27 74.58 20.25
VAFA-30 20.92 88.19 26.62 66.39 38.36 63.57 38.75 57.28 22.36 71.25 18.89 75.11
FGSM-8 70.50 23.59 50.73 49.07 68.71 34.66 74.29 27.96 64.91 29.14 63.94 26.72
SegResNet PGD-8 73.76 22.77 17.42 106.73 69.90 32.58 76.90 28.83 70.87 23.57 69.81 24.80
CosPGD-8 74.07 24.07 18.88 102.25 69.93 32.26 77.00 29.17 71.59 23.13 70.36 23.56
VAFA-30 38.47 51.36 17.68 84.91 43.33 54.59 45.00 47.85 22.43 63.84 19.75 64.63
FGSM-8 70.38 23.55 71.68 16.66 48.48 58.85 71.54 31.48 71.70 25.19 69.28 21.42
PGD-8 72.57 22.99 74.85 17.19 44.83 76.08 75.28 30.96 74.82 18.84 70.82 23.81
UNETR
CosPGD-8 72.67 22.73 75.11 17.05 44.64 74.34 75.46 30.61 74.82 18.47 71.00 23.05
VAFA-30 39.68 48.60 32.63 56.05 22.34 88.08 38.11 54.49 29.60 54.23 26.77 58.62
FGSM-8 69.99 24.44 69.39 18.48 66.81 35.05 53.46 71.03 70.21 23.45 68.12 23.85
PGD-8 72.67 24.14 73.19 18.20 68.77 38.35 46.95 88.88 74.39 23.43 71.40 24.23
SwinUNETR
CosPGD-8 72.88 23.67 73.56 18.34 68.85 38.09 46.79 82.92 74.59 22.30 71.67 23.91
VAFA-30 30.47 60.63 27.51 60.51 33.10 64.36 25.43 76.41 24.11 65.63 22.06 65.39
FGSM-8 70.60 24.91 65.06 23.98 68.69 35.94 74.25 31.40 51.36 53.89 62.19 30.01
PGD-8 73.49 22.17 69.75 21.84 69.93 32.71 76.89 28.43 18.20 111.79 65.72 28.54
UMamba-B
CosPGD-8 73.46 22.99 70.35 20.94 69.94 33.08 76.92 28.69 18.99 101.89 66.36 30.04
VAFA-30 38.49 55.47 24.20 65.44 43.80 58.37 44.61 52.18 14.99 92.09 18.46 69.64
FGSM-8 70.93 23.48 68.27 20.87 68.69 35.07 74.85 29.52 65.66 30.35 48.81 52.13
PGD-8 74.20 21.71 73.82 17.58 70.25 32.12 77.55 28.89 71.18 23.11 23.59 96.84
UMamba-E
CosPGD-8 74.41 21.16 74.15 17.06 70.30 32.56 77.65 28.78 71.86 22.90 24.99 82.01
VAFA-30 39.41 53.15 27.39 61.14 43.32 58.63 46.53 50.97 23.31 72.51 13.88 92.91
Table11: Performanceofmodelsagainsttransfer-basedblackboxattacksonAbdomen-CTdataset.
For pixel-based attacks results are reported for ε = 8 indicated by attack names followed by the
255
suffixes −8, respectively. Regarding frequency-based attack VAFA, the results are reported with a
constraint on q max set to 30, denoted as VAFA-30. DSC score (lower is better) is reported on the
generatedadversarialexamples.26 MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS
Surrogate Attack UNet SegResNet UNETR SwinUNETR UMamba-B UMamba-E
DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑
Clean 73.91 11.36 74.73 11.08 72.36 14.61 71.61 22.07 73.50 10.89 72.19 13.29
GN 72.11 12.97 73.26 10.08 71.28 14.51 69.61 23.65 72.12 13.96 66.58 13.45
FGSM-8 43.78 37.79 59.11 18.23 66.49 17.23 58.76 30.61 59.26 18.63 57.47 19.08
PGD-8 34.07 78.61 68.24 13.80 69.87 17.54 64.99 27.33 67.38 14.62 65.55 17.80
UNet
CosPGD-8 34.22 78.62 69.48 12.92 70.02 16.83 66.11 26.00 68.58 13.11 66.21 16.10
VAFA-30 44.30 42.19 68.81 14.80 63.10 18.37 65.10 22.05 64.99 17.93 60.37 21.85
FGSM-8 60.62 21.43 47.70 32.24 67.51 17.17 57.01 30.20 53.92 27.12 55.13 21.08
SegResNet PGD-8 61.85 20.89 33.02 81.17 68.59 17.13 58.63 29.07 51.21 31.48 54.53 25.55
CosPGD-8 61.99 19.89 33.41 81.28 68.81 16.63 58.74 29.19 50.25 32.25 54.15 23.28
VAFA-30 69.07 17.77 47.55 33.08 66.24 17.71 65.55 21.85 65.23 17.79 62.22 23.54
FGSM-8 58.16 19.27 59.01 15.60 44.89 35.08 54.29 31.27 57.88 17.11 56.95 19.62
PGD-8 58.33 20.35 61.02 16.89 34.93 74.58 55.55 32.75 60.38 19.40 58.98 17.85
UNETR
CosPGD-8 59.02 21.18 61.97 17.29 34.89 73.84 56.13 32.29 61.55 19.64 59.95 20.11
VAFA-30 64.73 19.36 69.68 13.81 48.01 33.82 57.85 27.53 65.38 19.19 58.59 21.28
FGSM-8 57.96 21.82 55.59 18.97 64.66 19.39 43.82 52.95 54.54 24.71 53.39 21.48
PGD-8 55.25 25.87 56.09 20.16 66.29 19.83 34.12 78.85 55.14 23.72 54.18 23.60
SwinUNETR
CosPGD-8 55.83 23.88 56.61 21.35 66.53 19.43 34.21 77.62 55.37 25.18 54.70 23.08
VAFA-30 65.58 19.76 68.38 15.46 61.97 20.25 44.44 42.14 65.93 16.53 58.56 20.68
FGSM-8 60.34 18.63 55.50 18.78 67.23 16.73 56.29 33.02 50.16 30.12 54.51 19.86
PGD-8 61.83 19.34 49.65 39.99 69.07 16.88 58.12 31.30 34.31 78.39 51.03 30.70
UMamba-B
CosPGD-8 61.87 20.34 48.57 40.81 69.12 17.61 59.05 31.02 34.41 78.44 51.39 31.16
VAFA-30 66.61 20.86 64.99 16.32 64.11 18.50 64.53 21.53 49.27 35.99 58.52 22.13
FGSM-8 62.64 16.67 59.29 16.55 68.43 17.10 60.34 29.29 57.49 22.28 47.15 31.65
PGD-8 69.30 14.95 68.77 12.22 70.59 15.53 66.92 25.14 66.75 16.73 34.29 78.25
UMamba-E
CosPGD-8 69.55 13.86 69.49 12.88 70.67 15.07 67.34 26.04 67.43 16.99 34.37 77.85
VAFA-30 68.09 20.51 69.84 13.90 64.26 19.12 65.86 24.17 66.03 20.12 44.81 36.84
Table12: Performanceofmodelsagainsttransfer-basedblackboxattacksonHecktordataset. For
pixel-basedattacksresultsarereportedforε= 8 indicatedbyattacknamesfollowedbythesuffixes
255
−8,respectively. Regardingfrequency-basedattackVAFA,theresultsarereportedwithaconstraint
on q max set to 30, denoted as VAFA-30. DSC score (lower is better) is reported on the generated
adversarialexamples.MALIKET.AL:ADV.ROBUSTNESSOFVOLUMETRICMEDICALSEG.MODELS 27
Surrogate Attack UNet SegResNet UNETR SwinUNETR UMamba-B UMamba-E
DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑ DSC↓ HD95↑
Clean 85.52 5.75 89.65 2.56 76.37 16.31 84.19 7.93 88.22 6.01 80.91 8.48
GN 85.01 5.67 89.26 2.89 74.88 18.49 83.06 10.69 86.95 6.68 78.11 11.67
FGSM-8 55.55 21.99 86.65 4.55 73.32 18.87 81.12 11.22 84.58 11.19 74.96 13.42
PGD-8 21.42 39.14 88.05 5.21 74.67 18.96 82.57 10.59 86.32 10.08 77.82 10.82
UNet
CosPGD-8 22.62 36.84 88.18 5.12 74.36 18.73 82.92 10.12 86.50 9.92 77.33 11.97
VAFA-30 49.85 27.44 74.15 18.17 56.09 21.77 58.72 22.95 60.27 24.46 53.68 25.98
FGSM-8 83.63 6.32 66.58 11.88 73.03 19.72 80.41 12.75 81.15 19.95 74.57 14.46
SegResNet PGD-8 84.38 6.34 20.42 37.34 74.59 17.62 82.27 9.84 85.72 10.48 76.39 11.34
CosPGD-8 84.54 6.08 22.33 38.61 74.79 18.05 82.44 9.58 85.69 9.58 76.41 11.32
VAFA-30 51.83 27.22 54.47 23.38 54.96 21.60 57.00 24.20 59.24 24.27 53.12 25.38
FGSM-8 80.15 12.78 83.33 6.48 33.16 29.77 75.79 16.74 77.48 25.93 72.88 14.93
PGD-8 83.25 13.69 85.54 7.19 22.31 35.44 80.12 15.19 80.67 22.48 68.37 16.98
UNETR
CosPGD-8 82.98 13.48 86.08 7.09 23.08 34.80 80.12 15.41 81.37 21.11 70.52 17.51
VAFA-30 52.67 26.66 74.18 15.78 49.39 22.63 55.90 24.47 58.27 24.85 52.16 25.09
FGSM-8 83.11 7.61 81.34 5.11 71.91 18.15 56.11 21.83 80.69 15.61 74.72 11.74
PGD-8 84.04 7.49 84.37 6.75 71.73 19.22 21.69 36.99 82.42 15.23 72.15 12.77
SwinUNETR
CosPGD-8 83.92 7.75 84.38 7.25 71.91 20.24 22.50 36.20 83.34 19.98 70.49 13.23
VAFA-30 51.50 26.94 70.18 17.16 53.50 23.25 48.44 25.57 57.68 25.01 52.52 25.27
FGSM-8 81.55 14.53 83.27 5.11 71.83 19.99 79.61 13.74 72.55 21.19 71.54 14.86
PGD-8 82.82 12.81 82.49 6.18 72.14 19.13 79.95 12.33 24.95 34.66 69.66 15.29
UMamba-B
CosPGD-8 82.58 10.26 82.69 7.37 72.50 18.78 80.14 11.97 25.54 31.32 68.93 14.86
VAFA-30 51.46 27.35 71.36 17.79 54.18 22.82 57.14 13.39 53.38 25.22 51.83 26.27
FGSM-8 82.44 13.41 84.96 4.75 71.23 20.59 81.82 12.16 81.97 15.77 51.65 24.22
PGD-8 84.66 6.11 87.71 3.43 74.51 18.16 82.95 9.17 86.12 7.46 25.01 32.43
UMamba-E
CosPGD-8 84.79 6.32 87.31 3.84 74.86 17.58 83.01 9.52 86.19 7.14 24.44 31.55
VAFA-30 55.01 27.08 75.57 15.77 57.40 20.80 60.22 23.85 61.26 24.54 51.61 25.72
Table 13: Performance of models against transfer-based black box attacks on ACDC dataset. For
pixel-basedattacksresultsarereportedforε= 8 indicatedbyattacknamesfollowedbythesuffixes
255
−8,respectively. Regardingfrequency-basedattackVAFA,theresultsarereportedwithaconstraint
on q max set to 30, denoted as VAFA-30. DSC score (lower is better) is reported on the generated
adversarialexamples.
Surrogate Attack BTCV ACDC Hecktor Abdomen-CT
DSC↓ IoU↓ DSC↓ IoU↓ DSC↓ IoU↓ DSC↓ IoU↓
FGSM-8 72.56 60.84 61.74 48.09 36.41 24.66 76.73 65.07
PGD-8 73.23 61.39 60.44 46.54 36.15 24.55 77.15 65.53
UNet
CosPGD-8 73.34 61.51 60.50 46.68 36.32 24.59 77.05 65.44
VAFA-30 66.26 53.80 47.01 35.51 36.77 24.70 69.82 56.99
FGSM-8 73.16 61.34 63.15 49.86 36.64 24.73 76.82 65.21
SegResNet PGD-8 72.95 61.24 61.38 47.64 34.98 23.57 76.84 85.27
CosPGD-8 73.05 61.31 61.99 48.35 34.76 23.38 76.92 65.32
VAFA-30 66.28 53.76 45.13 33.64 36.27 24.39 71.57 58.92
FGSM-8 71.59 59.82 61.18 47.65 37.52 25.49 75.49 63.66
PGD-8 72.15 60.33 58.93 45.80 38.19 26.08 76.15 64.44
UNETR
CosPGD-8 72.34 60.46 59.74 46.55 38.32 26.37 76.16 64.43
VAFA-30 65.31 52.77 45.16 33.43 40.00 27.24 68.35 55.07
FGSM-8 73.05 61.19 62.72 48.68 35.94 24.20 76.54 64.91
PGD-8 73.06 61.23 61.59 47.82 36.35 24.81 76.67 64.99
SwinUNETR
CosPGD-8 73.04 61.26 61.32 47.65 36.21 24.62 76.82 65.22
VAFA-30 65.23 52.59 43.32 31.76 38.61 26.12 68.03 54.81
FGSM-8 72.93 61.12 62.85 49.62 36.86 25.05 76.83 65.23
PGD-8 72.94 61.16 60.10 46.45 35.56 24.09 77.01 65.38
UMamba-B
CosPGD-8 73.17 61.34 60.91 46.99 36.37 24.64 77.12 65.54
VAFA-30 65.47 53.15 44.51 32.98 37.54 25.41 71.61 58.82
FGSM-8 73.03 61.19 63.56 50.06 36.95 25.04 77.01 65.38
PGD-8 73.04 61.28 60.56 46.78 35.72 24.14 77.15 65.53
UMamba-E
CosPGD-8 73.24 61.42 61.15 47.62 35.67 24.12 77.02 65.43
VAFA-30 67.43 55.23 45.47 34.04 36.55 24.63 71.47 58.75
Table14: EvaluatingSAM-Med3Donadversarialexamplescraftedonsurrogatemodelstrainedon
BTCV,ACDC,Hecktor,andAbdomen-CTdatasets.