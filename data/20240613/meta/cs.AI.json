[
    {
        "title": "ICE-G: Image Conditional Editing of 3D Gaussian Splats",
        "authors": "Vishnu JaganathanHannah Hanyun HuangMuhammad Zubair IrshadVarun JampaniAmit RajZsolt Kira",
        "links": "http://arxiv.org/abs/2406.08488v1",
        "entry_id": "http://arxiv.org/abs/2406.08488v1",
        "pdf_url": "http://arxiv.org/pdf/2406.08488v1",
        "summary": "Recently many techniques have emerged to create high quality 3D assets and\nscenes. When it comes to editing of these objects, however, existing approaches\nare either slow, compromise on quality, or do not provide enough customization.\nWe introduce a novel approach to quickly edit a 3D model from a single\nreference view. Our technique first segments the edit image, and then matches\nsemantically corresponding regions across chosen segmented dataset views using\nDINO features. A color or texture change from a particular region of the edit\nimage can then be applied to other views automatically in a semantically\nsensible manner. These edited views act as an updated dataset to further train\nand re-style the 3D scene. The end-result is therefore an edited 3D model. Our\nframework enables a wide variety of editing tasks such as manual local edits,\ncorrespondence based style transfer from any example image, and a combination\nof different styles from multiple example images. We use Gaussian Splats as our\nprimary 3D representation due to their speed and ease of local editing, but our\ntechnique works for other methods such as NeRFs as well. We show through\nmultiple examples that our method produces higher quality results while\noffering fine-grained control of editing. Project page: ice-gaussian.github.io",
        "updated": "2024-06-12 17:59:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.08488v1"
    },
    {
        "title": "RMem: Restricted Memory Banks Improve Video Object Segmentation",
        "authors": "Junbao ZhouZiqi PangYu-Xiong Wang",
        "links": "http://arxiv.org/abs/2406.08476v1",
        "entry_id": "http://arxiv.org/abs/2406.08476v1",
        "pdf_url": "http://arxiv.org/pdf/2406.08476v1",
        "summary": "With recent video object segmentation (VOS) benchmarks evolving to\nchallenging scenarios, we revisit a simple but overlooked strategy: restricting\nthe size of memory banks. This diverges from the prevalent practice of\nexpanding memory banks to accommodate extensive historical information. Our\nspecially designed \"memory deciphering\" study offers a pivotal insight\nunderpinning such a strategy: expanding memory banks, while seemingly\nbeneficial, actually increases the difficulty for VOS modules to decode\nrelevant features due to the confusion from redundant information. By\nrestricting memory banks to a limited number of essential frames, we achieve a\nnotable improvement in VOS accuracy. This process balances the importance and\nfreshness of frames to maintain an informative memory bank within a bounded\ncapacity. Additionally, restricted memory banks reduce the training-inference\ndiscrepancy in memory lengths compared with continuous expansion. This fosters\nnew opportunities in temporal reasoning and enables us to introduce the\npreviously overlooked \"temporal positional embedding.\" Finally, our insights\nare embodied in \"RMem\" (\"R\" for restricted), a simple yet effective VOS\nmodification that excels at challenging VOS scenarios and establishes new state\nof the art for object state changes (on the VOST dataset) and long videos (on\nthe Long Videos dataset). Our code and demo are available at\nhttps://restricted-memory.github.io/.",
        "updated": "2024-06-12 17:59:04 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.08476v1"
    },
    {
        "title": "Real2Code: Reconstruct Articulated Objects via Code Generation",
        "authors": "Zhao MandiYijia WengDominik BauerShuran Song",
        "links": "http://arxiv.org/abs/2406.08474v1",
        "entry_id": "http://arxiv.org/abs/2406.08474v1",
        "pdf_url": "http://arxiv.org/pdf/2406.08474v1",
        "summary": "We present Real2Code, a novel approach to reconstructing articulated objects\nvia code generation. Given visual observations of an object, we first\nreconstruct its part geometry using an image segmentation model and a shape\ncompletion model. We then represent the object parts with oriented bounding\nboxes, which are input to a fine-tuned large language model (LLM) to predict\njoint articulation as code. By leveraging pre-trained vision and language\nmodels, our approach scales elegantly with the number of articulated parts, and\ngeneralizes from synthetic training data to real world objects in unstructured\nenvironments. Experimental results demonstrate that Real2Code significantly\noutperforms previous state-of-the-art in reconstruction accuracy, and is the\nfirst approach to extrapolate beyond objects' structural complexity in the\ntraining set, and reconstructs objects with up to 10 articulated parts. When\nincorporated with a stereo reconstruction model, Real2Code also generalizes to\nreal world objects from a handful of multi-view RGB images, without the need\nfor depth or camera information.",
        "updated": "2024-06-12 17:57:06 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.08474v1"
    },
    {
        "title": "RILe: Reinforced Imitation Learning",
        "authors": "Mert AlbabaSammy ChristenChristoph GebhardtThomas LangarekMichael J. BlackOtmar Hilliges",
        "links": "http://arxiv.org/abs/2406.08472v1",
        "entry_id": "http://arxiv.org/abs/2406.08472v1",
        "pdf_url": "http://arxiv.org/pdf/2406.08472v1",
        "summary": "Reinforcement Learning has achieved significant success in generating complex\nbehavior but often requires extensive reward function engineering. Adversarial\nvariants of Imitation Learning and Inverse Reinforcement Learning offer an\nalternative by learning policies from expert demonstrations via a\ndiscriminator. Employing discriminators increases their data- and computational\nefficiency over the standard approaches; however, results in sensitivity to\nimperfections in expert data. We propose RILe, a teacher-student system that\nachieves both robustness to imperfect data and efficiency. In RILe, the student\nlearns an action policy while the teacher dynamically adjusts a reward function\nbased on the student's performance and its alignment with expert\ndemonstrations. By tailoring the reward function to both performance of the\nstudent and expert similarity, our system reduces dependence on the\ndiscriminator and, hence, increases robustness against data imperfections.\nExperiments show that RILe outperforms existing methods by 2x in settings with\nlimited or noisy expert data.",
        "updated": "2024-06-12 17:56:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.08472v1"
    },
    {
        "title": "Surprise! Using Physiological Stress for Allostatic Regulation Under the Active Inference Framework [Pre-Print]",
        "authors": "Imran KhanRobert Lowe",
        "links": "http://arxiv.org/abs/2406.08471v1",
        "entry_id": "http://arxiv.org/abs/2406.08471v1",
        "pdf_url": "http://arxiv.org/pdf/2406.08471v1",
        "summary": "Allostasis proposes that long-term viability of a living system is achieved\nthrough anticipatory adjustments of its physiology and behaviour: emphasising\nphysiological and affective stress as an adaptive state of adaptation that\nminimizes long-term prediction errors. More recently, the active inference\nframework (AIF) has also sought to explain action and long-term adaptation\nthrough the minimization of future errors (free energy), through the learning\nof statistical contingencies of the world, offering a formalism for allostatic\nregulation. We suggest that framing prediction errors through the lens of\nbiological hormonal dynamics proposed by allostasis offers a way to integrate\nthese two models together in a biologically-plausible manner. In this paper, we\ndescribe our initial work in developing a model that grounds prediction errors\n(surprisal) into the secretion of a physiological stress hormone (cortisol)\nacting as an adaptive, allostatic mediator on a homeostatically-controlled\nphysiology. We evaluate this using a computational model in simulations using\nan active inference agent endowed with an artificial physiology, regulated\nthrough homeostatic and allostatic control in a stochastic environment. Our\nresults find that allostatic functions of cortisol (stress), secreted as a\nfunction of prediction errors, provide adaptive advantages to the agent's\nlong-term physiological regulation. We argue that the coupling of\ninformation-theoretic prediction errors to low-level, biological hormonal\ndynamics of stress can provide a computationally efficient model to long-term\nregulation for embodied intelligent systems.",
        "updated": "2024-06-12 17:56:15 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.08471v1"
    }
]