Who Validates the Validators? Aligning LLM-Assisted Evaluation
of LLM Outputs with Human Preferences
ShreyaShankar J.D.Zamfirescu-Pereira BjörnHartmann
UCBerkeley UCBerkeley UCBerkeley
Berkeley,California,USA Berkeley,California,USA Berkeley,California,USA
shreyashankar@berkeley.edu zamfi@berkeley.edu bjoern@eecs.berkeley.edu
AdityaG.Parameswaran IanArawjo
UCBerkeley UniversitédeMontréal
Berkeley,California,USA Montréal,Québec,Canada
adityagp@berkeley.edu ian.arawjo@umontreal.ca
ABSTRACT
systematically[1,16,23,24,27,36,41,52].Suchapproachesrequire
Duetothecumbersomenatureofhumanevaluationandlimitations metrics—a set of functions to automatically score LLM outputs,
ofcode-basedevaluation,LargeLanguageModels(LLMs)arein- eachtypicallyanassertionwithtrueorfalsevalues.Thesemetrics
creasinglybeingusedtoassisthumansinevaluatingLLMoutputs. increasinglyincludecallsto“evaluator”LLMs(e.g.,[1,27,52,58])
YetLLM-generatedevaluatorssimplyinheritalltheproblemsof thatactas“judges,”gradingoutputsonqualitieshardtoarticulate
theLLMstheyevaluate,requiringfurtherhumanvalidation.We incode;forinstance,the“conciseness”ofanoutput.
presentamixed-initiativeapproachto“validatethevalidators”— Theproblemisthat,justliketheLLMstheyevaluate,LLMsthat
aligning LLM-generated evaluation functions (be it prompts or performevaluationscannotbetrusted.These“grader”prompts
code)withhumanrequirements.Ourinterface,EvalGen,provides sufferfromthesameproblemsasanyotherprompt—theyareun-
automatedassistancetousersingeneratingevaluationcriteriaand intuitivelysensitivetoseeminglyminorchangesinwordingor
implementingassertions.Whilegeneratingcandidateimplemen- structure[43].Yetmanyexistingsystemsdonotincludesupport
tations(Pythonfunctions,LLMgraderprompts),EvalGenasks forverifyingthequalityofLLM-generatedevaluations,askingusers
humanstogradeasubsetofLLMoutputs;thisfeedbackisusedto tosimplytrusttheseoutputs.Howcanusersreaptheefficiency
selectimplementationsthatbetteralignwithusergrades.Aqual- benefitsofLLM-assistedevaluationofLLMoutputs,whilemini-
itativestudyfindsoverallsupportforEvalGenbutunderscores mizingoravoidingmisalignment?Howcanwehelpusersvalidate
thesubjectivityanditerativeprocessofalignment.Inparticular, thevalidators?
weidentifyaphenomenonwedubcriteriadrift:usersneedcriteria Inthispaper,weproposeamixed-initiativeapproach,EvalGen,
togradeoutputs,butgradingoutputshelpsusersdefinecriteria. toaddressthisautomated-evaluationalignmentprobleminthecon-
Whatismore,somecriteriaappearsdependentonthespecificLLM textofpromptengineering.Ourapproachstreamlinestheselection
outputsobserved(ratherthanindependentcriteriathatcanbede- ofmetricsunderpracticalconstraintsofusereffortandlatency.
finedapriori),raisingseriousquestionsforapproachesthatassume Specifically,anLLMsuggestscriteriainnaturallanguage,basedon
theindependenceofevaluationfromobservationofmodeloutputs. usercontext(e.g.,thepromptundertest),thattheusercanmodify.
Wepresentourinterfaceandimplementationdetails,acomparison AnLLMthengeneratesapoolofcandidateassertionsforeach
ofouralgorithmwithabaselineapproach,andimplicationsforthe criterion—eithercodeorLLMgraderpromptsthatoutput“true”or
designoffutureLLMevaluationassistants. “false.”WhiletheuserwaitsfortheLLMtogeneratecandidates,they
areaskedtogradeoutputswithasimple“good”(thumbs-up)or
CCSCONCEPTS “bad”(thumbs-down)votingscheme.Thesegradesthenguidethe
automaticselectionofassertionsthatoptimizeforalignmentwith
• Human-centered computing → Interactive systems and
userpreferences(Section4.2).Afterassertionselection,afinalre-
tools;•Computingmethodologies→Naturallanguagepro-
portcardrevealsthealignmentbetweenthechosenassertionsand
cessing.
theuser’sgrades.Ourapproachgeneralizesbeyondtheparticulars
KEYWORDS ofourspecificdesign,andcouldbeextendedto,forinstance,update
metricimplementationswithfeedbackfromhumanpreferences,or
languagemodels,auditing,evaluation,interfaces,promptengineer- querytheuserforfiner-grainedindividualgrades.
ing,activelearning EvalGenisembeddedinsideanexistingopen-sourceinterface
forpromptengineeringandauditing,ChainForge[1].Ouralign-
1 INTRODUCTION mentalgorithmadaptsSPADE[45],afully-automatedalgorithm
forgeneratingPythonassertionsfromtherevisionhistoryofa
LargeLanguageModels(LLMs)makemistakes—theyhallucinate,ig-
prompt.Weperformedanoff-lineverificationofourhuman-guided
noreinstructions,andgenerateoutputsthatrequirevalidation[25].
alignmentalgorithmwithSPADEasabaseline[45],thenrana
ButvalidatingthebehaviorofLLMsischallenging.Inresponse,
qualitativeuserstudywithnine(9)industrypractitionersthatuse
researchersandindustrydevelopershavecreatedtoolsforprompt
engineeringandauditingthathelppeoplewithtestingoutputsmore
4202
rpA
81
]CH.sc[
1v27221.4042:viXraShreyaShankar,J.D.Zamfirescu-Pereira,BjörnHartmann,AdityaG.Parameswaran,andIanArawjo
LLMsinproductioncontexts.Becauseourparticipantswereindus- “Theresponseisnotapologetic.”PrototypessuchasEvalLM[27]
trypractitionersandthuspossiblydealingwithNDA-protected andPromptsRoyale[40]alsosupportLLMevaluators,oftentimes
data,weofferedataskadaptedfromarealLLMpipelineprompt. exclusively,tohelpuserscomparebetweentwoprompts.OfPE
Ourstudydesigndidnotimposerestrictionsonhowparticipants tools,onlyEvalLMoffersawaytohelpuserscalculatethealign-
usedEvalGen,anduserscouldchoosewhethertoaskthetoolto mentofLLMevaluatorswiththeirexpectations,butthisfeatureis
suggestcriteria,entercriteriamanually,orgradeafewLLMoutputs mentionedonlyinauthors’Designsectionandisabsentfromtheir
firstbeforeproceedingontothecriteriaspecificationscreen. userstudy.2Atbest,usersofPEtoolsinspectLLM-generatedeval-
OurfindingsfindoverallsupportforEvalGen,withoneimpor- uatoroutputsmanuallytodouble-check;atworst,thetoolhides
tantcaveat.Weobserveda“catch-22”situation:togradeoutputs, individualscoresentirely.Regardlessofaligningimplementations
peopleneedtoexternalizeanddefinetheirevaluationcriteria;how- ofmetricswithuserpreferences,evenidentifyingwhatmetricsto
ever,theprocessofgradingoutputshelpsthemtodefinethatvery evaluateforcustomtasksremainschallengingforLLMpractition-
criteria.Wedubthisphenomenoncriteriadrift,anditimpliesthat ers,asevidencedbyarecentstudy[37].Whilemanyevaluation
itisimpossibletocompletelydetermineevaluationcriteriapriorto toolsrequireuserstodeclaremetricstheycareabout,someprior
human judging of LLM outputs. Even when participants graded work[45]andEvalGenemployLLMstoproposecustommetrics
first,weobservedthattheystillrefinedtheircriteriauponfurther basedonpromptsintheuser’sLLMpipelines.
grading,evengoingbacktochangepreviousgrades.Thus,ourfind- Over-trustandOver-generalizationofLLMBehavior.That
ingssuggestthatusersneedevaluationassistantstosupportrapid toolsprovidelittleassistancetovalidateevaluatorqualityisalarm-
iterationovercriteriaandimplementationssimultaneously.Since ing,consideringthatotherresearchshowspeopletendtoover-rely
criteriaaredependentuponLLMoutputs(andnotindependentfrom andover-trustAIsystems[3,28,31,50].Forinstance,inonehigh-
them),thisraisesquestionsabouthowtocontendwithcriteriadrift profileincident,researchersfromMITpostedapre-printonarXiv
inthecontextofother“drifts”—e.g.,modeldrift[4],promptedits, claimingthatGPT-4couldacetheMITEECSexam.Withinhours,
orupstreamchangesinachain.Ourfindingsalso(i)underscore workbyChowdhurietal.debunkedthestudy[5],citingproblems
thenecessityofmixed-initiativeapproachestothealignmentof arisingfromover-relianceonGPT-4togradeitself.Otherwork
LLM-assistedevaluationsthatalsoembracemessinessanditeration, hasfoundfurtherreasonstobecautious:LLMsaskedtochoose
and(ii)raisebroaderquestionsaboutwhat“alignmentwithuser thebestresponsefromasetcanbeconsistentlybiasedbysetor-
preferences”meansforevaluationassistants. dering [30, 51]; and LLMs can be highly sensitive to seemingly
Wefirstpositionourwork(Section2)andpresentEvalGen’s innocuousformattingchanges[43].
design(Sec.3)andimplementationdetails(Sec.4).Wethenpresent Arelatedproblemtoover-relianceisover-generalization.Zam-
twoevaluations:anoff-lineevaluationofourapproach(Sec.5),and firescuetal.[57]foundthatusersunfamiliarwithPEtendtoover-
aqualitativestudywithdevelopers(Sec.6&7).Finally,wesuggest generalizefromsinglefailures(causingthemtothrowoutpoten-
implicationsforfuturework(Sec.8). tially good prompts), rather than having a holistic view of the
overallperformanceofapromptorchain.Thiswasdespitethe
2 MOTIVATIONANDRELATEDWORK
factthattheinterfacehadsupportforsystematictesting.Similarly,
Inresponsetothepopularityofblack-boxedLLMslikeChatGPT, Arawjoetal.[1]foundthatevenpeoplefamiliarwithLLMs(de-
promptengineering(PE)hasemergedasanewpracticeandre- velopers,academicsinML)struggledtoscaleuptheirevaluations,
search area. Alongside PE is the auditing of model behavior in appearing to over-generalize from a limited number of outputs
practicessuchas“red-teaming,”usedtoidentifyharmfuloutputsin evenafteranautomatedevaluationpipelinewassetup.Theauthors
internalteamstotweakLLMbehavior,usuallypriortorelease[32, identifiedthreemodesofPEonopen-domaintasks,withthesec-
p.17].Thesetaskshavespurredtheadventofnewtoolsfor“LLM ond,“limitedevaluation,”’characterizedasusers“prototypingan
operations”(hereaftercalledLLMOps)andnewterminologysuch evaluation”[1],andsuggestedthatfutureworkfocusonsupported
as“prompttemplate,”“chainofthought”,“chains,”etc. usersinprototypingevaluationpipelines.Over-generalizationis
AutomatingEvaluationsofPrompts.WhenevaluatingLLM commonintraditionalML,too—Kocielniketal.[29]foundthatAI
systemsthatshowcasesubsetsoferrors,likefalsepositivesorfalse
behavior,userstypicallysendoffhundredsorthousandsofqueries
negatives,thathavethesameaccuracy,canleadtovastlydifferent
tomodels.Asusersreachthelimitsofmanualevaluation,usersset
perceptionsofaccuracy.
upautomatedevaluationpipelines(Figure1a)incodeorwithother
LLMs(hereweusethetermLLM-basedevaluators;otherworkuses
ApproachestoAligningLLMs.TheHCIcommunityhasex-
termssuchas“LLM-as-a-judge”[58]or“co-audit”[18]).1PublicPE tensivelystudiedinteractivemachinelearning(iML).IniML,users
toolslikepromptfoo[52]andChainForge[1]allowuserstowrite iterativelydevelopmodelsbyselectingtrainingexamples,labeling
theirownevaluationmetricstoscoreLLMresponsequality,and data,andevaluatingmodelperformance[10].Interfacesthatfacili-
supportbothcode-basedandLLM-basedevaluators.Forinstance, tateseamlesstransitionsbetweentheseactivitiesresultinfewer
inpromptfoouserscanwritearubricinaconfigfiletospecifyhow errorsandoutputsthatbettermatchusers’expectations[38,46].
anLLMshouldevaluateresponses,andmayusepre-createdgrader SomeiMLinterfacesevenuseMLtoassistusers,forexample,in
prompttemplatesorcustomizethem;anexampleistheassertion scalinguplabeling—reducingoverallusereffortrequired[8].When
usingiMLconceptsfordevelopingLLMpipelines,wemustacknowl-
1Ananalogofthisproblemexistsinsoftwareengineeringaswell:developingasetof edgeakeychallengewithLLMs:theyoftenworkwithlittletono
assertions,oftenintheformofasetofunittestsorregressiontests,thatgivedevelopers
confidencethattheircodeiscorrectandthatcodechangesdonot(re)introducebugs. 2Asofthiswriting,EvalLMisnotpubliclyreleased.WhoValidatestheValidators?AligningLLM-AssistedEvaluationofLLMOutputswithHumanPreferences
Inputs Outputs Metrics Test Results
Prompt Metric (Code)
Under Test
… …
LLM
Metric Prompt
Evaluator LLM
iterate
(a)TypicalEvaluationPipeline
EvalGen
edit criteria
grade
LLM Candidate LLM
Criteria
outputs
LLM
Candidate
Assertions
Inputs Outputs Alignment
Report Card
Prompt
Under Test
Selected
Assertions Test Results
LLM
(b)TheEvalGenEvaluationPipeline
Figure1:EvalGen’sapproachtoassistingusersinaligningevaluations.Usersiteratethroughtheprocessofrefiningcriteria
andgrading.NotethatLLMpipelineinputsandoutputsareprovidedbyourlargersystem,andoutsidethescopeofthispaper.
specifictrainingdata[37].Usersmaysimplyprototypewithinputs EvoPrompt,PromptBreeder,AutoCalibrate[12,20,34]).Itthusre-
theyimaginetheLLMwouldsee,hopingthepromptgeneralizes. mainsunclearhowtosupportdevelopersintheirprototypingof
In the ML and NLP communities, researchers have explored evaluations,withtheproblembecomingevenmorepressingasthe
manywaystoalignLLMs—andtheirevaluations—tospecificuser popularityofpromptoptimizationincreases.
tasks. Many approaches rely on custom model training or fine- Overall,thisworkrevealsthatusersneedmoresupportfor(a)
tuning[6],butallstrategiesheavilyrelyonhumanstoidentify prototypingevaluationsand(b)validatingevaluatorsofLLMout-
examplesofdesirableandundesirableoutputs.Forinstance,Liu puts.ItalsorevealsthatauditingLLMoutputsisfarfromeasy,with
etal.[34]demonstratedusingannotatedLLMoutputs—judgedon humanspronetothedualbiasesofover-generalizationandover-
criterialikeconsistencyandrelevance—as“few-shotexamples”for reliance.OnerecentLLM-assistedapproach,SPADE[45],makes
calibratingLLM-basedevaluators.Beyondclassicalsummarization headwayontheseissues,helpingdevelopersgeneratePythonas-
andNLPtasks,inresponsetothead-hoctediumofPE[56],aca- sertionfunctionsforLLMoutputsfromprompthistory.Herewe
demicsanddevelopersarebuildingautomatedpromptoptimization leverageasimilaralgorithmicapproachtoSPADE,butembedit
tools,maximizingsomeuser-definedmetriconalabeledsetofex- insideanLLM-assisteduserinterfaceforevaluatorprototyping,
amples.Forinstance,givensomemetricsandprompts,Khattab EvalGen,thatalsoassistswithcriteriageneration,measuringalign-
etal.[26]automaticallyrunvariationsofinsertedfew-shotexam- mentwithhumanpreferences,andvisualizingresults.
plesandLLM-generatedrephrasingstooptimizetheprompt.Other
3 EVALGENDESIGN
workurgesuserstowriteassertionstoguideoutputswithamixof
codeandnaturallanguagesuggestions[42,48],butwritingthese
IndesigningEvalGen,ourgoalwas(1)toinvestigatehowtoassist
assertionsisleftuptodevelopers,whichisoftentime-consuming
developersincreatingevaluatorstogradeLLMoutputs,and(2)to
anderror-prone.AbroaderpointisthatresearchinLLMOpsopti-
helpthem“validatethevalidators”throughbothautomatedassis-
mizationtendstocomefromthedomainsofNLPandML,where
tanceandtransparencyaroundhowalignedeachevaluatoriswith
authorsgenerallyvalidatetoolperformanceagainstbenchmark
theirexpectations.AswecoveredinSection2,emergingpractices
datasetswithpre-definedmetrics,leavingopenthequestionof
inpromptengineering,LLMauditing,andpromptoptimization
howwelltheyperforminthewildonidiosyncraticusertasks(e.g.
involvethewritingofevaluationfunctions(metrics)toautomateShreyaShankar,J.D.Zamfirescu-Pereira,BjörnHartmann,AdityaG.Parameswaran,andIanArawjo
Figure2:TheworkflowofourEvalGenprototype,from(a)aPromptNodeattachedtoanemptyMulti-EvalNode,showinga
GenerateCriteriabutton;(b)thepop-upEvalGenWizardwiththreeoptions,Infer,Manual,andGradeFirst;(c)thePickCriteria
screen,allowinguserstodescribecriteriainnaturallanguageandtoggleCodeorLLMimplementations;(d)theGradescreen,
withtheLLMoutput(top),inputvariables(left),andprompt(right),GoodandBadgradebuttons,andan“I’mTired”button
(bottom-right)tofinish;andfinally(e)theReportCardscreen,showingthealignmentofeachcriteriaandacrosscriteria.
Hoveringoverthealignmentshowsaconfusionmatrix.Notethatsomedescriptionsandelementshavebeenclippedforspace.
grading.Thesefunctionsmaybecode-orLLM-based.Basedonthis LLMpipelinesbycreatingnodesofvarioustypestorepresenttheir
context,wesetouttodesignanLLM-poweredevaluationassistant dataflow,suchasan“input”nodefeedingintoa“prompt”node.
thatprovideddeveloperscontrolovermetriccriteria,evaluatortype Wediscusshereonlyourextension,chieflyapop-upscreenthat
(codeorLLM),andimplementation(i.e.,function)generationand helpstheuserdefine,implement,andvalidateevaluationfunctions.
selectionprocesses,withoutaskingthemtocomeupwithcriteria Wealsoimplementedanewnode,Multi-Eval,thatallowsusersto
orwritecodeorgraderpromptsthemselves. includemultipleevaluatorsinasinglenodeandrunallevaluators
ontheoutputsofthepipeline’spreviousnode.Finally,wemade
3.1 EvalGenWorkflow
improvementstoplottingper-criteriascoresintheTableViewof
WeimplementedEvalGeninanexistingopen-sourcesystemfor theLLMoutputinspector,whichcanbeaccessedviatheMulti-Eval
promptengineering,ChainForge[1],whichhandlesqueryingmulti- node.Fig.1bprovidesahigh-leveloverviewoftheEvalGenarchi-
pleLLMswithparametrizedprompts,runningcode-andLLM-based tecturecomparedtothetypicalLLMoutputevaluationpipeline;
evaluators,plottingscores,chaining,etc.InChainForge,userswrite wediscussimplementationdetailsinSec.4.WhoValidatestheValidators?AligningLLM-AssistedEvaluationofLLMOutputswithHumanPreferences
Figure2depictstheworkflowofinthecontextoftheEvalGen LLMevaluatorsistoreducetheeffortrequiredbythedeveloper,
interface,excludingreturningtothemainworkflowwithselected whowouldotherwisehavetogradeoutputsmanually.Theonly
implementationsandusingtheTableViewtoinspectscores.Eval- waytofullyalignanLLMevaluatorwouldbetoasktheuserto
GenassistsadeveloperinengineeringanevaluationofLLMoutputs labelalloutputs;obviously,thisdefeatsthepurpose.Askingthe
forasingleprompttemplate.First,EvalGenisaccessedasabutton developertogradesomeoutputs,usingsometimetheywouldhave
ona“Multi-Eval”nodeweaddedtoChainForge,whichisattached spentwaitinganyway,isthekeyideabehindourdesign.
toaPromptNode(Fig.2a).AWizardopens,depictingthreeoptions
(Fig.2b):Infer,Manual,andGradeFirst.AdescriptionofEvalGen 4 IMPLEMENTATION
(notshown)appearsabovetheoptions.ClickingInferorManual 4.1 SystemArchitecture
leadstothePickCriteriascreen(Fig.2c);clickingGradeFirstleads
totheGradingscreen(Fig.2d)andasksuserstogradeatleastfive Likepriorworkonevaluatorassistants[27,45],oursolutionde-
composesevaluationsintocriteriaandassertions(booleanfunctions
outputs,beforecontinuingtothePickCriteriascreen.
ThePickCriteriainterfaceisdepictedinFig.2c.AnLLMhas thatimplementthecriteria,evaluatingoutputs).WeemployLLMs
ingeneratingcriteria,basedontheprompt[45],andingenerating
generatedcriteriasuggestionsinnaturallanguage(Sections4.1
variouscandidateimplementationsofeachcriterion[27,45].As
and 4.2), along with a toggle to prefer a Python code-based or
usersgrade,werankcandidateassertionsthatimplementeachcri-
LLM-basedevaluator.Theusercaneditallparts—includingthe
teriabasedontheiralignmentwithusergrades(seeAppendixA.3
titlesordescriptionsandtypeofevaluator—oraddnewcriteria
forhowwedefinealignment).Atahighlevel,alignmentisacombi-
notsuggestedbytheLLM.Theycanalsodeletecriteriaordeselect
nationoftheassertion’scoverage,orabilitytofailoutputsthatthe
criteriaasneeded.Pressing“ImplementIt”passesthecriteriatoa
userthinksarebad,andthefalsefailurerate,orabilitytonotfail
secondLLMthatgeneratescandidateimplementations.
outputsthattheuserthinksaregood.Wegiveaformaldefinition
While implementations are generated and executed on LLM
ofassertionalignmentinAppendixA.3.
outputs, users are asked to grade outputs. EvalGen uses these
gradestoimplementationswiththeirpreferences.Fig.2ddepicts EvalGen’sarchitecturediffersfrompriorworkintwomaincom-
ponents:first,EvalGensolicitsgradesfromtheuseronasample
theGradingscreen.AsingleLLMresponseispresentedtotheuser,
ofLLMoutputs—requiringsomepolicytosampleLLMoutputsto
centeredinfocusinthegraderwindow.Thecontextoftheprompt
grade.Second,incontrasttoSPADE[45],whichoperatesofflineand
and any input variables (vars) is also present. The user grades
solvesanintegerlinearprogramtogeneratetheoptimalassertion
outputs with the Good and Bad buttons. Since it may be time-
set,EvalGenemploysanonline(i.e.,streaming)systemarchitec-
consumingtoaskthedevelopertogradeonaper-criterionbasis,
turetoprogressivelyoptimizeforthemostalignedassertionset.
forthegraderinterfacewedecidedonthesimplicityofthumbs-
WhenEvalGengeneratesanewcandidateimplementation,itim-
up/downscoring.Suchscoringisanoisyyetinformativesignalof
mediatelyexecutesthisimplementationonthesetofLLMoutputs,
quality—ifaresponseisgivenathumbs-up,itisassumedtopassall
cullingimplementationsthatareobviouslybad(e.g.,Pythonfunc-
criteria,andsoifacandidateassertionfailsonthatresponse,the
tionswithruntimeerrors).EvalGenmaintainsadynamicestimate
candidateisdown-rankedinthepool(detailsinSection4.1).Users
ofselectivity(i.e.,passrate)foreachcandidateassertion,whichin
mayalsoclickarrowstonavigatethroughoutputs(forinstance,if
theyareunsureaboutagrade,orwanttoreviseapriorgrade).3 turninformshowgradesaresampledintheinterface.Oursystem,
asdepictedinFigure1b,isstructuredintothreecomponents:
Finally,aftertheuserisdonegradingandallcandidateimple-
mentationsaregenerated,executed,andfilteredforalignmentwith
CriteriaSuggestion.WeuseanGPT-4toproposevariousbi-
grades,aReportCardscreenappearswithfeedbackonper-criteria naryevaluationcriteriainnaturallanguage,suchasresponselength
andaggregatemeasuresofalignmentwithusergrades(Fig.2e). ortone.Developerscanselectfromthesesuggestionsoraddtheir
Hoveringoverper-criteriametricsshowsaconfusionmatrixof owncriteria.Foreachcriterion,developerscanselectwhetherit
howalignedthatparticularcriterionistothehumangrades,while shouldbeevaluatedwithapurelycode-basedfunctionorafunction
theaggregatemetricsshowthecoverageandfalsefailurerate(see thatinvolvescallstoanotherLLM.
Section5)oftheselectedsubsetof EvalGen-generatedassertions.
CandidateAssertionSynthesisandExecution.Basedon
TheuserthenreturnstothemainChainForgeinterface(notshown), theselectedcriteria,weuseGPT-4toasynchronouslygenerate
wheretheselectedimplementationsareavailableina“Multi-Eval” oneormorecandidateassertionsascodeoragraderpromptto
node,titledbycriteria.Theusercaneditoraddmorecriteria,in- beevaluatedbyanLLM.Foreachcriterion,weissueonecallto
spectandvisualizeevaluationresults(Fig.3),etc.;however,thisis GPT-4togeneratemultiplecandidateassertionswithinmarkers
outsidethescopeofourdesigndiscussion. inastreamingfashion.Everytimewedetecttheendofmarkerin
Ourdesignreflectstrade-offsbetweendevelopereffortandro- anyGPT-4response,weparsethecandidateassertionandsubmitit
busthumanverificationofLLM-generatedmetrics.Thehuman toEvalGen’sexecutor,whichwillrunitonLLMpipelineoutputs.
cannotcompletelyvalidateanLLM-basedevaluator:thepointof Generatingmultiplecandidateassertionsimprovestheprobability
thatthereisatleastoneimplementationthatalignswithdeveloper
3Initially,wehadaskeduserstogradeapresetnumberofoutputsandabarshowed
expectations.Moreover,forcode-basedassertions,LLMsoccasion-
theirprogress.However,callingLLMsandexecutingassertionsareasynchronous
allysynthesizeerroneousfunctions(e.g.,hallucinatingafunction
operationsthattakeanindeterminateamountoftime:suggestingan“endpoint”touser
gradingmaylosevaluableinformationwhentheuserstillhastowaitforgenerations inaPythonlibrary),requiringseveralcandidateassertions.
toreturn.Theusermayalsofindgradingenjoyableorimportant.Forthesereasons, GradingSampler.ThiscomponentsamplesLLMpipelineout-
wedidnotseektolimitusergrading.However,wekeptthisnumber-leftprogressbar
intheGradeFirstscreen(accessedviaFig.2b). putsfortheusertogivebinaryfeedbackon(thumbsup/down).ShreyaShankar,J.D.Zamfirescu-Pereira,BjörnHartmann,AdityaG.Parameswaran,andIanArawjo
WhentheusergradesanLLMoutput,weupdateinternalestimates arepresentedinAppendixB.Forbothprompts,theplaceholder
ofalignmentforeachcandidateassertion,andwesamplethenext variables(i.e.,transcriptanddocument)representtheinputcon-
outputfortheusertograde. texttoinjectatpipelineruntime.Foreachdataset,weexecuted
OncetheuserdoesnotwanttogradeLLMoutputsanymore, thecorrespondingpipelineonceforeachinputusingOpenAI’s
orisfinishedgradingalloutputs,foreachcriterion,weselectthe GPT-3.5-Turbotogenerateoutputs—resultingin84medicalLLM
candidate assertion with the highest alignment with the user’s outputsand100productLLMoutputs.
grades.Theusercanprovideathresholdforthefalsefailurerate TwoofthepaperauthorsmanuallygradedallLLMoutputsto
(asdefinedinSection5)suchthatEvalGenonlyselectsassertions establishground-truthlabels.Overall,68%and51%oftheoutputs
thatdonotexceedthisthreshold. weregoodforthemedicalandproductLLMpipelines,respectively.
Commonissuesincludedthepresenceofpersonalinformationin
4.2 SelectingAssertions&ElicitingGrades
themedicalpipelineoutputsandbadreviewsorlengthycontentin
Oncetheuserselectscriteria,EvalGen’sexecutorbeginsgenerat- theproductpipelineoutputs.
ingcandidateassertionsandexecutingthemonallLLMoutputs.
5.2 ImpactofHumanInputintheCriteria
EvalGenmaintainsdynamicestimatesforthefollowing:
SelectivityofCandidateAssertions.Theselectivityisthe GenerationStep
probabilitythatanassertionwillclassifyanLLMoutputaspass- Here,wereportquantitativeandqualitativedifferencesinSPADE’s
ing.ThisprobabilityisadjustedeachtimeEvalGenprocessesthe andEvalGen’sassertionsets.Therearetwodifferencesbetween
outcomeofexecutingacandidateassertiononanLLMoutput. SPADEandEvalGeninhowtheygenerateassertionsets.Thefirst
Confidence Scores for Potentially Poor Outputs. These differenceisthatEvalGenaskstheusertoadd,edit,orremove
scoresestimatethelikelihoodthatanLLMoutputisoflowquality, criteriabeforegeneratingdifferentcandidateassertions,whereas
withouthavingbeenexplicitlyevaluatedbytheuser.Thescores SPADEdoesnotsolicitanyinputfromtheuseraboutthecriteria.
aredependentonassertionselectivityandarerevisedwhenever Theseconddifferenceisintheselectionoftheassertionsthemselves:
EvalGenevaluatesanewassertionagainstanLLMoutput,orwhen givenuser-confirmedcriteriaandasampleofgradesprovidedin
ausergradesanLLMoutputdirectly. aUI,EvalGenpicksthemostalignedassertionpercriterionthat
AssertionAlignment.Alignment,ortheharmonicmeanof meetssomefalsefailureratethreshold.Meanwhile,SPADEsolves
coverageandfalsefailurerate(AppendixA.3),isrecalculatedfor anoptimizationproblemtoselectaminimalassertionsetthatmeet
eachassertioneverytimetheusergradesanLLMpipelineoutput. afalsefailureratethresholdandcoverallSPADE-generatedcriteria.
SeeAppendixAforacompletedescriptionofassertionselectivity
andhowitimpactsconfidencescores;howEvalGenusesthese 5.2.1 EvaluationProcedure. WefirstranSPADEend-to-endfor
confidencescorestosamplegradesfromtheuser;formaldefinitions both LLM pipelines, supplying all labeled LLM outputs to see
ofalignment;andhowEvalGendeterminestheresultingassertion theresultingassertionsets.Weinitiallysetbothfalsefailurerate
setbasedonalignmentwithgrades. thresholdsto10%.WhileSPADEmetthisthresholdforthemedical
pipeline,theproductpipelinerequiredadjustingthefalsefailure
5 ALGORITHMEVALUATION rateto40%tofindaviableassertionset.Thisillustratesthechal-
lengeofbalancingcoveragewithfalsefailures,underscoringthe
Herewepresentresultsontheeffectivenessof EvalGen’sselec-
needforevaluatorsystemstoeffectivelynavigatethesetrade-offs.
tionalgorithm.Ourexperimentaimedtounderstandhowsoliciting
Subsequently,weranEvalGenforbothpipelineswiththesame
humaninputatthecriteriasuggestionstageimpactsthesize(num-
falsefailureratethresholds.Forthemedicalpipeline,wedefined
berofassertions)andalignmentoftheresultingassertionset.We
threeevaluationcriteria:wordcount,presenceofthesixtargeted
comparedtoabaseline,SPADE[45],afullyautomatedsystemthat
keys,andabsenceofPII,withthefirsttwoimplementedviacode-
generatescriteriaandcandidateassertionsandchoosestheminimal
basedassertionsandthelastviaanLLMevaluator.Theproduct
assertionsetthatmeetcoverageandfalsefailurerateconstraints.
pipelinecriteriaincludedabsenceofnegativereviews,absenceof
5.1 EvaluationSetup links,adherencetomarkdownformat,andwordcountlimitation,
with only the first criterion requiring LLM implementation. To
WedevelopedtwoLLMpipelinesbasedonreal-worlddatasets.The
createthealignedassertionsets,weprovidedEvalGenwith16
medicalpipelineoperatesonadatasetof84unstructuredtexttran-
gradedoutputsperpipelineinsteadofall80-100gradedoutputs—
scriptsfromdoctor-patientcalls[54],aimingtoextractspecific
giventheimpracticalityofexpectinguserstoextensivelygradein
information(e.g.,symptoms,medication)withoutrevealingany
asinglesession.
personallyidentifiableinformation(PII).Thistaskrequiresasser-
tionstoensurecompliancewithprivacylaws.Theproductpipeline 5.2.2 Results. OurresultsinTable1showthatEvalGen,byincor-
involvedcraftingSEO-friendlydescriptionsfor100Amazonprod- poratinghumanjudgmentduringcriteriaselection,achievedequal
uctsandtheirreviews[21].Weselectedthistaskbecauseitmirrors orbetteralignmentthanSPADEwithfewerassertionsforboth
actualLLMapplications(thereareanumberofstartupsusingAI pipelines.Specifically,intheproductpipeline,EvalGenproduced
towriteSEO-optimizedproductdescriptions),anditbenefitsfrom anassertionsetlessthanhalfthesizeofSPADE’sandincreased
assertions:forexample,eveniftherearenegativereviews,thede- coveragefrom49%to73%.Thisunderscoresthebenefitofinvolv-
scriptionsshouldnotsaynegativethingsabouttheproducts,which inghumansinselectingcriteria,asafullyautomatedtoolmay
wouldadverselyaffecttheproducts’salespotential.Ourprompts generateassertionsforcriteriathathumansmaynotactuallycareWhoValidatestheValidators?AligningLLM-AssistedEvaluationofLLMOutputswithHumanPreferences
aboutwritingassertionsfor.Inthemedicalpipeline,SPADEadded Next,wespentafewminutesdescribingEvalGen’sfunctionality.
unnecessaryassertions,suchasoneforaneutraltone,notchosen WeshowedparticipantshowtoviewLLMoutputs,triggerEvalGen,
forEvalGen,andsplitchecksforspecifickeysintomorecrite- write an assertion from scratch and add it to their set, run the
riathanneeded.Fortheproductpipeline,SPADEgeneratedtwice assertionsetonalltheLLMoutputs,andinspecttheTableView
thenumberofassertionscomparedtoEvalGen,someofwhich plottingresultsofeachassertiononeachLLMoutput.Wethengave
wereunrealistic,likeaPythonfunctiondesignedtoflagspecific theparticipantremotecontrolaccesstoourscreen,instructingthem
negativephrasessuchas“neverorder”and“disappointed”inthe tocomeupwithanassertionsetforthepipeline.Participantswere
output.Incontrast,EvalGenreturnedamorepragmaticassertion allowedupto40minutestoexplorethetoolwhilethinkingaloud.
forthiscriterion—anLLM-basedvalidatortoensuretheproduct Wecommunicatedthatweweremainlyinterestedinobservingtheir
descriptionsremainedentirelypositive. processofcreatingassertions,notinteractingwithotherfeaturesof
ChainForgesuchascomparingdifferentLLMAPIs.Iftheparticipant
MedicalPipeline ProductPipeline hadanyquestionsabouttheinterface,weansweredthem.
Aftertheparticipanthadanassertionsettheyliked,orranout
Metric EvalGen SPADE EvalGen SPADE
oftime,weaskedthemopen-endedquestions.Wefirstaskedthem
DatasetSize 84 84 100 100 tocommentonEvalGen’sapproachtogeneratingassertions,and
#BadOutputs 27 27 49 49 whether they felt that the assertions aligned with their grades.
#Assertions 3 5 4 9 Wethenaskedfollow-upquestionstolearnmoreaboutwhythey
Coverage 0.33 0.33 0.73 0.49 feltaparticularwayorfoundsomeaspectofassertionalignment
FFR 0.10 0.10 0.39 0.39 challenging.Welimitedthepost-interviewto10minutes.Attheend,
Alignment(%) 48.29 48.29 66.46 54.35 weaskedparticipantstoratehowtheyfeltabouttheassertions’
Table 1: Comparison of EvalGen and SPADE Across alignment on a 7-point Likert scale (1 = strongly disagree, 7 =
Pipelines. With user input at the criteria stage, EvalGen stronglyagree).Overall,thestudyrangedfrom45minto1h15min.
achievesthesameorgreateralignmentwithfewerfunctions. Ourstudywasapprovedbyourinstitutionalreviewboard(IRB),
andparticipantsgenerouslyvolunteeredtheirtime.
6 USERSTUDY Analysis. We asked participants to think aloud while using
thetool,whilewetooknotesontheirthoughtsandanyvisible
TounderstandhowdevelopersmightuseEvalGentobuildevalua-
emotions(e.g.,delightwhenEvalGensuggestedacriterionthey
torsforLLMpipelines,weaskednineindustrypractitionerswho
struggledtoexternalize,orfrustrationwhentheycouldnotfind
hadpriorexperiencewithLLMstouseEvalGenandthinkaloud.
RecruitmentandParticipants.Werecruitednineindustry agoodassertionforacriterion).Wealsorecordedthetranscripts
foreachvideocall.Weemployedopenandaxialcoding[13]to
practitionersviaaTwitterpost,callingforanyoneinterestedinsolv-
identifycommonthemesacrossthetranscriptsandnotesforeach
ingtheproblemof“whovalidatesthevalidators.”Weselectedthe
participant.Initially,wecodedindividualsentencesofinterestfor
firstninewhohadexperiencecodingandbuildingLLMpipelines
eachparticipant,thengroupedtheseintobroaderthemesonaper-
forsomecompanyorproduct.Participantsincludedsoftwareen-
participantbasisinasecondpassofcoding.Finally,weconsolidated
gineers,MLscientists,startupexecutives,andindependentcon-
thesethemesacrossallparticipants,reorganizingthemasneeded.
sultants.WefocusedondeveloperswithexperiencewithLLMs
becausetheycanbestintuitwhatfeaturesofanassertionassistant
7 USERSTUDYFINDINGS
theywouldfinduseful,comparedtotheirexistingworkflows.
Procedure. All studies were conducted over Zoom. We first Overall,wefoundthat:
spent5minutesestablishingrapportandaskingparticipantsabout
• ParticipantsfeltthatEvalGenwasagreatstartingpoint
theirbackgroundsandexperience.Wethenintroducedthepartici-
forassertions,andwantedto—andcould—exercisecontrol
pantstoourLLMpipelineinChainForge,wherethepipeline’stask
overEvalGen’sassistance.
wastodonamedentityrecognition(NER)onadatasetoftweets.
• Participantsstruggledtoalignassertionswiththeirpref-
TheLLMusedinourpipelinewasGPT-3.5-TurbofromOpenAI.
erencesduetotwomainchallengesingrading:(i)some
ThepromptforourLLMpipelinewasasfollows:Youwillbedoing
criteriaaredifficultforhumanstograde(e.g.,underatar-
namedentityrecognition(NER).Extractupto3well-knownentities
getwordcount),and(ii)astheygrademoreLLMoutputs,
fromthefollowingtweet:{tweet_full_text}Foreachentity,writeone
weobserveacriteriadriftphenomenon,inwhichcriteria
sentencedescribingthepersonorentity.Alltheentitiesyouextract
changeasparticipantsgrademoreLLMoutputs(bothdefi-
shouldbefoundinaknowledgebaselikeWikipedia,sodon’tmakeup
nitionsofexistingcriteria,andchangestotheoverallset
entities.ReturnyouranswerasabulletedMarkdownlist,whereeach
ofcriteria).
bulletisformattedas‘-entity:description‘.Donotextracthashtagsas
• Participants’perceptionsofalignmentandneedsvaried
entities.Wechosethistaskandsetofinputsforthreereasons:first,
basedontheevaluatortype(i.e.,code-basedvs.LLM-based).
NERisacommon,real-worldtaskthatlanguagemodelsexcelat;
second,tweetsareshortandcanbedisplayedinaUIwithoutany Weunpackthesefindingsbelow.Wefirstdescribethetypical
scrolling;third,“NERfortweets”isaproblemthatmanypeople participantworkflowandhighlightwhereparticipantswantedto
havestudied[15,33,49].Weallowedparticipantstochangethe exercisecontrolintheprocess.Then,wediscussthechallenges
taskorpromptiftheywanted. participantsfacedinaligningassertionswiththeirpreferences.ShreyaShankar,J.D.Zamfirescu-Pereira,BjörnHartmann,AdityaG.Parameswaran,andIanArawjo
7.1 TypicalParticipantWorkflow
ThisishowIwouldwantaworkflowtoassistmein
Allparticipants(𝑛=9)usedtheprovidedtask(aprompttemplate evals—basicallyIwanttheAItodo80%ofit,and
forNERofadatasetof100tweets,describedin6).Three(3)partici- therecanbeescapehatchesiftheAIfails.
pantschangedtheprompt:ofthesethree,one(1)personchanged Here,wediscusswhatparticipantslikedanddislikedindifferent
thetaskfromNERtosentimentanalysis.Afterparticipantshad componentsof EvalGen’sUI.
settledontheirownprompt(ordecidedtheywantedtouseour
7.2.1 LLM-generatedcriteriaalleviateswriter’sblock. Eight(out
prompt),eachengagedinroughlythefollowingactivities:
of9)participantswerepleasantlysurprisedthatsuggestedcriteria
(1) EyeballingLLMoutputs:Participantsviewedthetable reflectedthecriteriatheywanted(allexceptP3).P4said,“Iget
writer’sblockwhenthinkingaboutwhatassertionstowrite,so
of100LLMoutputs,makingsuretheoutputsseemedrea-
this is great.” P6 said, “I feel that if I gave my prompt [for my
sonableataglance.
(2) StartingEvalGen:Participantsclickedthebuttontostart ownpipeline],thiswouldcreatereallygoodcriteriaautomatically.”
Someparticipantshadnegativeinitialreactions:forexample,P7
EvalGen.Thiswizardpresentsthreeoptions(Fig.2b):auto-
initiallyexpresseddissatisfactionthat7criteriaweregenerated,
generatecriteria,writecriteria,andgradeoutputsfirst(be-
astheyhadexpectedless.Butafterdeletingsomecriteria,they
foregeneratingcriteria).6participantsclickedtheauto-
realizedthatthesuggestionscoveredallthecriteriatheywanted
generatebutton;1participantwroteacriterionthemselves
(i.e.,theydidnothavetoaddcriteriathemselves),andstated,“this
andthenclickedtheauto-generatebutton.Theremaining
auto-generationissweet”.P3foundthatsomeEvalGen-suggested
2participantswantedtogradefirst(P4,P9).
(3) Gradingoutputs:ParticipantswhogradedLLMoutputs criteriadidnotmakesensegiventhatassertionsonlyoperateon
LLMpipelineinput-outputpairs,likeresponselatencyandresponse
firstgradedbetween5and10outputs,with2to4“thumbs-
stabilityovertime.P3didnotfeelthatthiswasafailureofEvalGen,
down”grades.Aftergrading,bothparticipantsclickedthe
butratherexpressedthatLLMsarenotperfectandstressedthe
buttontoauto-generatecriteria.
(4) Refiningcriteria:Afterreceivingcriteriasuggestionsfrom importanceofhavingcontroloverselectedcriteria.
EvalGen,participantsremovedsomesuggestionsandadded 7.2.2 Gradingoutputsfirsthelpsrefineinitialcriteria. Participants
1-2criteriaoftheirown.Theyusuallyleftevaluationtype whogradedbeforeselectingcriteria(P4andP9)expressedthat
(code-basedorLLM-based)unchangedfromwhatEvalGen theyfoundthegradingprocessveryuseful.Bothparticipantswere
suggested,evenifEvalGensuggestedatypethatdidnot happythatEvalGenpromptedthemtogivefeedbackonwhyan
makesense(e.g.,checkingwordcountwithanLLMAPI LLMoutputwasbad.WhileP9selectedthegradingoptioninitially
call,ratherthancode),whichhappenedrarely. becauseitseemedlikethe“optionthatrequiredtheleastthinking,”
(5) Gradingmoreoutputs:Participantsgradedoutputswhile theylaterrealizedthatitwasthecorrectthingtodo:
EvalGengeneratedandevaluateddifferentcandidateas-
Ofthe3options,[selectingcriteria]probablywasn’t
sertions.Someparticipantsgradedcontinuouslyforupto
thebesttostartwithbecauseIcouldn’thaveextracted
10minutes;othersstoppedafter10grades.
[allthe]rulesdirectlyfromtheprompt.[Whilegrad-
(6) Understandingalignmentongradedoutputs:Partici-
ing,Ifound]somerulesthataren’tincludedinthe
pantsviewedthe“ReportCard”screen,wheretheyallspent
prompt.
afewminutesinspectingtheresultingassertionset.Only
oneparticipantdidnotunderstandwhattheoverallset’s Otherparticipantswhodidnotgradebeforeselectingcriteria
coverage and false failure rate meant (P9), but did once regrettedthisdecision:forexample,P2said,“youshouldenforce
theresearcherexplainedit.Participantschosetoviewthe thatwealllookatatleast20examplesfirst.”Wediscusscriteria
differentassertionimplementationsEvalGenevaluated, refinementmorein7.3.1.
includingtheonesthatdidnotalignwiththeirgrades.
7.2.3 Userswerehappytogradewhilewaiting. Overall,allpartic-
(7) Eyeballingalignmentonungradedoutputs:Returning
ipantsbutone(P7)foundgradingwhilewaitingforEvalGento
tothemainscreen,participantsclickedtheRunbuttonof
finishgeneratingandexecutingcandidateassertionstobeagood
theMulti-Evalnodetorunallassertionsonall100LLM
useoftheirtime.Theparticipantwhodidnotagreesaidthatthey
outputsandinspectedthetableofresults(Fig.3).
wouldfinditusefulif,onthegradingscreen,EvalGenshowed
(8) Iteratingoncriteria:3outof9participantsagainopened
whatitwasdoingwiththegrades.However,threeparticipants
theEvalGenwizardtoiterateontheircriteriaandasser-
founditdifficulttoenumerateallcriteriaintheirheadandgrade
tions(backtostep2),orstoppedbecausetheyweresatisfied
againstallcriteria,wantingEvalGentopromptthemtogradeper
ortired.Morethanhalfoftheparticipantsexpressedinter-
eachcriteria(P6,P7,P8).Severalparticipantsrealizedtheyneeded
estiniteratingontheirassertionsiftheyhadmoretime.
togobackandchangetheirgradesinEvalGenandwerehappy
theycoulddothis.
7.2 EvalGenasaStartingPoint
7.2.4 Usersneedmorecontrolwhenreviewingalignmentongraded
WefoundthatparticipantslikedEvalGenasastartingpointtogen- results. IntheReportCardscreen,participantslikedthatEvalGen
eratingassertions.Theyfeltthatexertingcontrolwasnecessary— generatedmultipleassertionimplementationsforeachcriterion
sinceEvalGensometimesmademistakes—andtheydidnotmind andpickedthemostalignedone(i.e.,highestcoveragewithinafalse
doingso.P8said: failureratethresholdof20%).However,forsomecriteria,EvalGenWhoValidatestheValidators?AligningLLM-AssistedEvaluationofLLMOutputswithHumanPreferences
P1 P2 P3 P4 P5 P6 P7 P8 P9
6 5 3 4 5 3 1 2 5
Table2:Ratings(1-7,7best)forthestatement,“Ifeltlikethe
assertionsalignedwithmygrades.”Responsesweremixed.
thetable,oneatatime—andeveryoneelseassessedalignmentvia
falsefailurerate:foreachcolumn(assertion),theytypicallylooked
forrows(LLMoutputs)thattheassertionreturnedFalse.Some
participantswantedthistabletoautomaticallyrecompute,withan
accompanyingvisualization,whenevertherewerechangestothe
LLMpipeline;forexample,P6said:
OnethingIwouldfindcoolisifthereisawayto
easily see how changes to my prompt impact the
overall[coverageandfalsefailurerate]scores.Just
veryquicklybeingabletovisualizehow[myprompt
edit]changestheclassificationsonabunchof[LLM
outputs.]
Figure3:TheTableView,showinginputs,LLMoutputs,and
Thissuggestsuserswantdatavisualizationplotsbetweenthe
evaluationresultspercriteriafortheNERtask(Sec.6).
original prompt and its revision, akin to LLM Comparator and
EvalLM[24,27].NotethatChainForge[1]alsohasvisualization
plots,butwedidnotintroduceparticipantstothisfeature.
generatednogoodassertions,andparticipantsdeletedthecriteria
withoutcomplaints.P8said,“Ilikethatittries,becausemaybethere 7.3 AlignmentisIterative,Criteria-and
willbeagoodimplementation!”Thissuggeststhat,comparedto Implementation-specific
anopaqueapproacheswediscussedinRelatedWork,seeingalign-
Perceptionsofthetools’supportofalignmentwerepolarizedacross
mentscoreshelpedparticipantscullassertionsthatwereunaligned
participants,asshowninTable2.Themainreasonwhypeople
ratherthanblindlytrustingthem.ForcriteriawhereEvalGendid
hadlowconfidenceintheassertionreportcard’salignmentwith
notfindanygoodassertionimplementations,participantsalsoex-
theirgradeswasbecausetheywerestilluncertainoftheirown
pressedinterestinwritingassertions.Someparticipantssaidthat
criteriawhilegrading.Participantswouldsayutteranceswitha
theyhadnotgradedenoughresponsestogettheiridealalignment
questioningtone,like“Iguess”and“sure,”whengrading,indicat-
numbers,sotheywantedtogobackandgrademore(P1,P7).Par-
ingtheiruncertainty(P2,P5,P7,P8,P9).Lookingmorecloselyat
ticipantsalsolikedseeingthecoverageandfalsefailurerateofthe
theirinteractions,weobservedacatch-22situation:participants
set,andhoweachassertioncontributedtotheseoverallstatistics.
neededtoexternalizecriteriainordertogradeoutputs,butthey
However,inthisscreen,someparticipantsexpressedinterestin
alsoneededtogradeoutputs—providingfeedbackonwhybadout-
seeingper-criterionalignmentandaskedtoprovidegradesforeach
putswerebad—inordertoexternalizecriteria.Here,weexplore
criterion(P5,P6,P7,P8).Anotherplacewhereparticipantswanted
theirchallenges.
toexercisecontrolbutwerelimitedbyEvalGen’sinterfacewas
intheselectedassertions:P2andP5wantedtochangeaselected 7.3.1 Criteriadrift. Gradingoutputsspurredchangesorrefine-
assertiontoanothercandidateassertion.BothP2andP5wantedto mentsinparticipants’criteria,whichwerefertoascriteriadrift.
changecode-basedassertions:forexample,P5said,“thisisaweird Weobservedtwotypesofdrift.
implementationofentitycount”andpreferredanotherassertion First,participantswantedtoaddnewcriteriawhentheyobserved
withasmallmodification.4
new“types”ofbadLLMoutputs(P2,P5,P6,P8,P9).IntheEvalGen
interface,theycouldnotgobackandaddnewcriteria;theyhadto
7.2.5 Usersdifferinhowtheyassessalignmentforungradedresults.
waitforallcandidateassertionstofinishexecuting,movepastthe
Participantsreallylikedviewingthetableofassertionresultson
reportcardscreen,andstartanewEvalGenprocess.
allLLMoutputs,withallparticipantsexpressinginterestuponfirst
Second,asparticipantsgradedmoreoutputs,wefoundthatthey
viewingit(Figure3)—buttheyverifiedtheresultsdifferently.Inthis
reinterpretexistingcriteriatobetterfittheLLM’sbehavior(P2,P5,
table,rowsrepresentLLMoutputs,andcolumnsrepresentasser-
P6,P8,P9).Forexample,P2andP8hada“propernoun”criterion,
tions.P2saidthatthistable“earnstrust”;P5saidthatitwas“cool
which was supposed to assess that “the entities extracted were
toseealltheresultsonexamples[they]didn’tgrade.”P5initially
propernouns.”Atfirst,theyratedasbadanyLLMoutputsthatcon-
didnotlikeusingaGUItocomeupwithassertions,andthensaid
tainedanyentitythatwasnotapropernoun.But,afterobserving
thatthey“preferlookingatthistableto[their]currentworkflow
thatresponseshadvaryingnumbersofpropernouns,bothwanted
inJupyternotebooks.”Interestingly,onlyoneparticipantassessed
tochangetheircriteriasuchthatmostoftheentitieswereproper
alignmentinthistableviacoverage—byinspectingeachrowin
nouns,ratherthanall.P9appreciatedtheabilitytoprovidefeed-
4NotethatassertionscanbeeditedintheMultiEvalnodeafterreturningtothemain backonunsatisfactoryoutputsbeforefinalizingtheinitialcriteria
window,butnotinEvalGen’sreportcardscreen. set,asthisprocesshelpedthemarticulatetheircriteria.Twice,P8ShreyaShankar,J.D.Zamfirescu-Pereira,BjörnHartmann,AdityaG.Parameswaran,andIanArawjo
mentionedthattheygaveabadgradenotbecausetheybelieved P5feltthatEvalGencouldnotfindagoodassertionthataligned
theoutputwasbad,butbecausetheywantedtobeconsistentwith withtheirgrades,butalsosaidthattheywere“lostatwhatwould
previousgrades—goodlabelingpractice,perhaps,butnotgoodfor beagoodimplementation.”
alignment.P7noticedthatinsomeoutputsincludedhashtagsfrom Overall,alignmentisnotmerelyamatterofperformance(i.e.,
theoriginaltweetinputs(e.g.,#justdoit),whileinothercases,the theideathat“abetterLLMwoulddobetter”):weobservedthatmis-
outputsdidnotusethehashtagsymbolbutstillmentionedtheenti- alignmentsometimesoccurredduetotacitcriteriathatparticipants
tiesreferredtobythehashtags(e.g.,“Nike”insteadof#Nike).This heldwhichwasnotexplicitlyexplainedinnaturallanguage.Like
inconsistencyledP7torethinkthecriteriadefinitionforincluding priorworkhasfoundforcross-LLMcomparison[1],thistacitun-
hashtags;specifically,whetheritwasacceptablefortheLLMto derstandingofcriteriacouldbehighlysubjectiveandcontradictory
replicateentitiesfromhashtags,providedthehashtagwasremoved. acrossparticipants.
P5expressedthesameuncertainty.“Ithinkit’shardtoknowuntil
youseeit,”P7said. 7.4 AlignmentNeedsandPreferencesDifferfor
Codevs.LLMEvaluators
7.3.2 Usersprefertoadjusttheirgradingapproachbasedonthe
difficultyofevaluatingacriterion. Overall,participantsgenerally All participants liked EvalGen’s ability to assist in generating
likedtheprocessofgradingLLMresponsesandfeelinglikethe bothcode-basedandLLM-basedassertions,expressingtheneedfor
gradeswereuseful,buttheywantedtoprioritizegradingcriteria bothtypesofassertions.BothP4andP6mentionedthattheyliked
theyfeltneededtheiralignment—especiallyforLLM-basedasser- theabilitytocorrectEvalGen’ssuggestedtype.Yetparticipants
tions(P3,P5,P7,P8).Forexample,P3expressedthattheywould reasonedaboutcode-basedassertionsandLLM-basedassertions
trusttheassertionsmoreiftheEvalGenprocessallowedthemto differently:whiletheylikedhavingassertionsofbothtypes,they
setdifferentfalsefailureratespercriteria(sinceLLMsmightbe wantedtoconstructanditerateonthemdifferentlyinordertofeel
badatevaluatingsomecriteria),insteadofoneglobalfalsefailure liketheresultingsetofassertionsalignedwiththeirpreferences.
rateconstraintfortheentireassertionset:
7.4.1 Userslikehavingcontrolovertheevaluationtypeandthought
Therearecriteriawhereyoucanbeokaywithfailing,
eachevaluationtypehadadifferentaffordance. Participantsseemed
andthenthereareothercriteriawhereyouarelike,
tohaveaclearideaofwhenacriterionshouldbeevaluatedbycode,
‘thismustabsolutelypass’...[T]here’sa[spectrum]of
andwhenitshouldbeevaluatedbyanLLM.Generally,forformat-
failureasopposedto:itjustpassesorfails.
tingchecks(e.g.,assertingthatanoutputisinMarkdown),count-
Relatedly,someparticipantsexpressedthattheydidn’ttrusttheir basedchecks,andcheckstoincludeorexcludespecificphrases,
gradesbecausetheythemselvescouldn’tevaluatesomecriteriaas participantspreferredcode-basedassertions.P6andP8expressed
wellasanautomatedsolution(P2,P5,P6,P7,P8;wediscussfurther thattheywantedtouseLLM-basedassertionsfortheirownLLM
inSection7.4).Acriterionlikewordcountishardforhumansto pipelinesbecause“mostoftheircriteriawasfuzzy.”P2selectedcri-
assessbuteasyforagoodPythonfunctiontoevaluate.P8desired teriatobeevaluatedviaLLMwhenevertheycouldnotimmediately
to grade for only one criteria, reasoning that it might improve thinkofaPythonfunctionthatcouldimplementthatcriteria.We
efficiency(“Igenerallywanttobeintheloopforthesetests...butI alsoobservedaparticipant(P8)preferringLLM-basedtocode-based
wanttoputmyselfintheloopinawaythatisefficient.”). assertions:LLMsarerelativelyforgivingwhenencounteringout-
putswithanunexpectedqualityorformat,whereascodeassertions
7.3.3 Whatconstitutes“alignment”issubjective,especiallywhen
checkexactconstraints.
convertingnaturallanguagecriteriatocode-basedassertions. For
code-basedassertions,EvalGen’sinterpretationofthecriterion 7.4.2 Userscan—andwantto—directlyverifycode-basedimplemen-
(i.e.,GPT-4’sinterpretation)didnotmatchwhattheparticipants tations. Regardlessofthetypeofassertion(codeorLLM),EvalGen
expected.Assuch,nomatterhowmanygradestheparticipantgave, followsthesameprocessofexploringmultiplecandidateassertions
all candidate assertions were similarly misaligned. Participants percriterionand,foreachcriterion,selectingtheassertionthat
whoobservedthiswereconfusedwhytheirgradesseeminglyhad alignsmostwiththeuser’sgrades.Whileparticipantsgenerally
littleimpactonsomeofthechosenassertions(P3,P5,P7,P9).For likedthisapproachforLLM-basedassertions,theydidnotlikethis
example,whileallparticipantshadacriteriontoenforcethatthere forcode-basedassertions.Thisobservationmaybespecifictousers
werenoentitieswithhashtagsintheoutput,someparticipants whoareexpertsincoding(asallofourparticipantsare).Some
interpretedthisasanyhashtagsrepresentingentitiesshouldnotbe participantswantedtoseethecodeforeachcandidateassertion
extractedasentities:e.g.,iftheoutputincludedthehashtag#Nike, andselectthebestPythonfunctionforeachcriterionthemselves
P5didnotwantNiketobeextractedatall.Ontheotherhand,P9 (P2,P5,P7).P5said:
wantedNiketobeextractedasanentity,buttheydidnotwantthe
WhensomethingcanbesolvedusingPythoncode,
LLMoutputtoincludethehashtag.BothP5andP9gotthesame
Idohaveanenvisioned[implementation]inmind
code-basedassertionforthecriterion,whichsimplycheckedfor
thatIcaneasilyverify.Justshowing[me]the[code]
thepresenceofthehashtagcharacterintheoutput—thisassertion
willbequicker.
didnotalignwithP5’sgrades,butdidwithP9’s.Thisparticular
misalignmentcanalsobeviewedasaninstanceofcriteriadrift, P7wantedtoiterateoncode-basedassertionssimplybypro-
asdescribedinSection7.3.1,sinceP5wasonlyabletorefinethe vidingfeedbacktomaketheassertionmoreorless“fancy”—for
criterionaftergradingseveralLLMoutputs.Foranothercriterion, example,incheckingforapatternintheLLMoutput,theymightWhoValidatestheValidators?AligningLLM-AssistedEvaluationofLLMOutputswithHumanPreferences
wanttheregextobemoreorlesscomplicateddependingonthesam- LLMoutputs.Forinstance,AutoCalibrateisamethodtocali-
pleofLLMoutputsthey’veseen.However,P7thenacknowledged brateLLMevaluatorswithhumanpreferencesthatrequireslarge
thattheirabilitytoeditdependsoncodelengthandcomplexity: expert-labelleddatasetswithsettled(i.e.,establishedupfront)cri-
teria[34].However,inpractice,wefoundthatdevelopersrapidly
Forsomethingthat’slike10linesofcodeorless,I’ll
iterateovercriteria,andfurthermorethatcognitivelyengaging
lookat[thecode].Butfor[longerfunctions,]Iprob-
withLLMoutputshelpsthemtorefinetheircriteria.Thissuggests
ablywanttoeyeball[thefunctionresults].Thisis
criteriarefinementandgradingshouldhappenintandemininter-
whereitgetsabitunclear.
activesettings,andposeschallengestoalignmentmethodsthat
Whileparticipantshadlotsofideasforimprovement,partici-
presumesettled,expertlabels.Inparticular,thedependenceofcri-
pantsoverallfeltthatEvalGenprovidedagoodstarttocode-based
teriaonaspecificpromptandLLM’soutputsmeansthatanychange
assertions,anditwaseasyforthemtoeditthecodeiftheywanted:
totheLLMpipelinecancausecriteriadrift:forexample,LLMAPIs
twoparticipantsevenaskedfortheabilitytoexportcode-based
canbereplacedwithnewmodels,resultinginpromptdrift[4].
assertionsasunittestsorinaPythonfile(P4,P6).
Futuresystemdesignsshouldsupporttheserequirements.For
instance,anevaluatorassistantmightadjustcriteriadynamically
7.4.3 Userswanttheirgradestoaidautomatedcriteriageneration.
astheusergradesandgivesfeedback.Wemightalsoconsiderper-
WhileparticipantslikedthatEvalGentriedmultiplecandidateas-
criteriagrading(whilekeepingthesimplicityofthumbsup/down
sertionsforeachcriterion,theywantedEvalGentousetheirgrades,
voting).Elicitinggradesatthecriterialevelmightallowevaluation
aswellasnaturallanguagefeedbackonthumbs-downgrades,in
assistantstomorepreciselyadjustboththecriteriaforevaluation,
promptingLLMsforcandidateassertions(P3,P4,P5,P7).Forexam-
aswellasthewaythesecriteriaareimplemented.Finally,including
ple,anytimeausergivesagrade,EvalGencouldqueryanLLMfor
examplesofbothgoodandbadLLMoutputswithintheLLM-based
anewcandidateassertion,includingthenewgradeintheprompt
evaluatorpromptscouldalsobebeneficial(amethodakintorecent
sothatthecandidateassertionmaybemorealignedwiththeuser’s
work[26,35]).However,wheneveroutputschange,wemayneed
grades.Thisstrategycan,ofcourse,beusedtogeneratenewcode-
toaskuserstore-gradeorre-thinktheircriteria.
basedassertionstoo.Notonlydidparticipantswantgradestobe
Ourcriteriadriftfindingechoespriorworkineducationalset-
includedintheprocessofgeneratingnewcandidateassertions,
tings,whereinstructorsoftenupdatetheirgradingrubricstoreflect
butsomewantedtheirlabeledLLMoutputstobeincludedinthe
commonerrorsastheygrademoreassignments[47].Similarto
LLM-basedassertions’promptsthemselves(P3,P5).P3excitedly
howteachersadjustrubricsandregradeastheyseemorestudent
realizedthiswhenlookingatthetableofresults(“Icantakethese
submissions,makingusersreassessLLMoutputsafterupdatingcri-
goodandbadexamplesandusethemasfew-shotexemplarsinthe
teriacouldenhancetheaccuracyandconsistencyofgrades.Given
promptfortheLLMevaluators...”).Thissuggestsanoptimization
theobservedinconsistencyinparticipants’grading,evaluationas-
loopakintoConstitutionMakerandDSPy[26,39],butforassertion
sistantsmightalsopursuecrowdsourcingmethodslikemajority
generationandvalidation,ratherthanpromptoptimization.
votingandselforexternalassessmentstodetermineaccurategrades
7.4.4 LLM-basedassertionsarehardertotrust. Whileparticipants forLLMoutputs[7,9].Anotherchallengeforevaluationassistants
foundEvalGen’ssuggestedcode-basedassertionstobemoreob- isextendingadaptedcriteriatogradebothungradedandfuture
viouslymisalignedthantheLLM-basedassertions(Section7.3.3), unseenLLMoutputs.Howdoevaluationassistantsconsistently
theyalsoacknowledgedthatLLM-basedassertionsareharderfor samplegradesforoutputsthatreflecttheoveralldistributionof
themtotrust—sincetheycaneditthecode-basedassertionsmore LLMpipelinesuccessesandfailures?
easilythantheLLM-basedassertions(P2,P5,P6,P8,P9).Some Thereadermightwonderwhencriteria“settle.”Perhapsthere
participantswereskepticalofhowLLM-basedassertionsmight wassimplynotenoughtimeinourstudy,andhadparticipants
transfertomonitoringLLMoutputsinaproductionpipeline(P3, gradedforanhourortwo,theymighthavesolidifiedtheircriteria,
P6,P8).P8said,“IcannotbegintothinkabouthowLLMsasvalida- andcriteriadriftgoesaway.Thereisreasontobelievethatthis
tors[inproduction]canwork,I’mveryskeptical.”P9asked,“How situationdoesnotchangewithmoretime—aswesaw,thecriteria
doImaintainmyevalsovertime;doIhavetorerunthisentire participantsrefinedchangedtoadapttothebehavioroftheLLM
process?”Onesuggestionisaninterfacethatsolicitsgradesfrom outputsbeingevaluated—adependent,ratherthanindependentas-
otherpeople—possiblytheend-usersoftheuser’sLLMpipeline—to sessmentofquality.Intherealworld,similarsituationsexistwhere
continuallyrealignLLM-basedassertions. criteriaarenever“fullysettled”asmoreinputscomein—consider
the court of law. One of our participants remarked that people
8 DISCUSSION “knowabadoutputwhentheyseeit.”TheiradagereflectsaU.S.
SupremeCourtJustice’sfamousopinionina1964courtcaseabout
Here,weunpackcriteriadriftandhowitaffectsalignment,discuss
obscenecontent[17].Asinthatremark,thedecisionsofhuman
the implications of our findings for future LLMOps evaluation
validatorsseematfirstglance“tobebasedonanon-rational,in-
assistants,andoutlinesomeopenquestions.
tuitivegutreaction,insteadofreasonedanalysis;itseemstobe
8.1 ImplicationsofCriteriaDriftforLLM utterlysubjectiveandpersonal”[17,p.1025].However,perhaps,as
thelawscholarGewirtzargues,subjectivityisnot necessarilya
EvaluationAssistants
signofirrationality(contrastingwithsomeimaginedfutureAIthat
ThepracticeofbenchmarksinMLandNLPpresumeaworldof isentirelyobjectiveandrational,entirely“aligned”or“better”than
well-defined criteria (and well-labeled data) on which to judge humans).Onthecontrary:“TherearegoodreasonstoaccepttheShreyaShankar,J.D.Zamfirescu-Pereira,BjörnHartmann,AdityaG.Parameswaran,andIanArawjo
imperfectinajudge.Weshouldencouragejudgestobelieveand newassertionandsolicitingreviewfromateammember,anda
say:ThisisthebestIcandonow;itdoesn’tsolvealltheproblems, workflowsimilartocontinuousintegration/continuousdeployment
butit’sastart,andI’llkeepthinking”[17,p.1027].Thisraisesa (CI/CD)thatseamlesslypushesnewassertionstoproduction.
deeperepistemicquestionforevaluationassistants—is“alignment”
anactualizablegoal?Towhatextentdoesourcommonterminology 8.3 FutureWorkandLimitations
andassumptions—e.g.,thatthereisa“groundtruth”setoflabels
Assertionsserveasastraightforwardmechanismforevaluating
wemerelyneedtoelicit—failus?Isvalidatingthevalidatorsonly
LLM outputs, yet the potential of evaluation assistants extends
everawork-in-progress?
beyondEvalGen’ssupportedbinaryjudgments.Considertheex-
ampleofwordcount:ratherthansettingrigidthresholds,onemight
8.2 OperationalizingAssertions finditmoreusefultomonitorvariationsinwordcountacrossdif-
ferentLLMoutputs.LikeintraditionalMLmonitoring[44],there
Participantsexpressedthedesiretodeploytheirassertionsinpro-
is,ofcourse,stillimprecisioninwhatwordcountcountsas“bad,”
duction.Somewantedtodeployassertionsinthecriticalpathof
givenitsdistribution.DoestheAIassistant’sdefinitionofbadalign
theLLMpipeline,tocatchbadoutputsbeforetheyareshownto
withtheuser’s?Trackingfiner-grainedinformationinevaluations,
end-users.Otherswantedamorepassivedeployment—onepartici-
beyondsimpletrue/falseconditions,canaidindebuggingissues
pantrequestedforsomeformofreportsenttotheiremailinbox
withinLLMpipelines,onceauserknowstheoutputisbad.Sec-
daily,containingresultsoftheassertionsetexecutedonasample
ond,manyuserswritetheirLLMpipelinesaschainsofmultiple
ofLLMoutputsfromthatday.Inpractice,assertionshavedifferent
LLMcalls[1,11,14,53].Evaluationassistantscanfacilitateend-to-
operationalrequirements.Forexample,ifanassertionrunsinthe
endalignment,whichcanbecomplicatednotonlywithchainsof
criticalpath,itshouldnotresultinmanyfalsefailures,otherwise
LLMcalls,butalsoincompoundAIsystemsthatleverageother
theLLMmaygetunnecessarilyreprompted(i.e.,rerun)andthe
componentslikeretrieval-augmentedgeneration[55].
overalllatencymightincreaseforourLLMpipeline.Moreover,as
Increasingly,userwanttheirpromptstoautomaticallyimprove
criteriachangesovertime,evaluationassistantsshouldaskusersto
basedonassertionresults.Forinstance,ifanassertionfailsfora
gradenewLLMoutputsobservedinproductionandautomatically
groupofLLMoutputs,onemightwanttoaddaninstructiontothe
adaptassertionsets.
prompttosolvethisfailuremode.Someframeworksalreadyexper-
Our study confirmed the dual necessity for both code-based
imentwithusingfeedbackfromassertionsorusergradestorefine
andLLM-basedassertionsamongparticipants,butfurthershowed
prompts[35,39,48].However,incorporatingthisintoanevaluation
thatparticipantsfelteachtyperequireddistincttreatment,both
assistantisnotasstraightforward:theremaybeacyclicalprocess
inimplementationselectionandinhowtheyperceivealignment.
whereevaluationassistantsnotonlyhelpinadjustingassertions
Oftenusefulforsanitycheckslikeoutputstructure,code-based
basedonpromptperformancebutalsousetheseinsightstosuggest
assertions can be used in the critical path of the LLM pipeline.
furtherpromptmodifications.Thisiterativecycleofevaluation
Infact,anumberofLLMOpstoolsexistforuserstoimplement
andadjustmentcouldfosteraco-evolutionaryenvironmentwhere
suchcode-basedguardrails[19,22,42].However,ourparticipants
prompts,assertions,andevenevaluativemechanismsthemselves
highlightedthechallengeoffindingtherightimplementationfor
arecontinuouslyrefinedinaunifiedinterface.
agivenassertion—adecisionthatcandependintricatelyonthe
Finally,therearetwolimitationsofourstudythatareworth
characteristicsofLLMoutputs.Forexample,determiningtheac-
pointing out. First, our off-line evaluation only focused on two
ceptablelengthofaresponsemightvarysignificantlybasedon
pipelines.Differentapplicationsmaywarrantdifferentmethodsof
theobservedoutputdistribution.Infact,specificallyforanoutput
samplinggradesandaligningassertions.Second,ourqualitative
lengthcriterion,P3mentionedthattheywouldlookatahistogram
studyfocusedonasmallsampleofdevelopers,allofwhomhave
ofwordlengthsforabatchofoutputsandseeifthereweresome
significantexperiencedeployingLLMs.Moreover,participantsdid
bucketsofanomalouswordlengthsthatexhibitedotherfailure
nothaveenoughtimetoiteratemanytimesinEvalGen,andour
modes(e.g.,a“rambling”responsefromtheLLM).
setupdidnotcoverthedeploymentphaseofLLMworkflows.Future
Someparticipantsmentioned thattheywantedtheir collabo-
workmightexplorebestpracticesandpitfallsofevaluationsinthe
rators,suchasproductmanagers,togradeoutputsinEvalGen.
broaderLLMOpslifecycle.
Importantly,whenallowingmultipleuserstocollaborateongrad-
ing,evaluationassistantshavetoconsiderinter-raterreliabilityand
9 CONCLUSION
handledisagreements,ifany.Again,wecandrawinspirationfrom
techniquesfromthecrowdsourcingliterature:forexample,evalua- ThisworkpresentedEvalGen,amixed-initativeapproachtoalign-
tionassistantscouldmodeleachindividualgrader’saccuracyand ingLLM-generatedevaluationfunctionswithhumanpreferences.
applycorrectionsifnecessary[59].Moreover,collaboratorsmay EvalGenassistsusersindevelopingbothcriteriaacceptableLLM
havedifferentexperiencelevelswithcoding:thosewithlessexpe- outputs and developing functions to check these standards, en-
riencemaychooseLLM-basedassertionsforcriteriathatmightbe suringevaluationsreflecttheusers’owngradingstandards.Ina
betterevaluatedwithcode.WhileEvalGenprovidesinitialsugges- qualitativestudywith9expertusers,weobservedapatternwecall
tionsforwhethercriteriashouldbeevaluatedwithcodeoranother criteriadrift,whereusersrefinetheirevaluationstandardsasthey
LLM,evaluationassistantsmaywanttomakesurethatallusers grademoreLLMoutputs.Recognizingthedependencyofcriteria
fromthesameteam“agree”ontherightimplementations.One on LLM outputs highlights new directions for designing future
couldimagineinterfacessimilartocreatinga“pullrequest”fora evaluationassistants.WhoValidatestheValidators?AligningLLM-AssistedEvaluationofLLMOutputswithHumanPreferences
REFERENCES
intoself-improvingpipelines.arXivpreprintarXiv:2310.03714(2023).
[1] IanArawjo,ChelseSwoopes,PriyanVaithilingam,MartinWattenberg,andElena [27] TaeSooKim,YoonjooLee,JaminShin,Young-HoKim,andJuhoKim.2023.
Glassman.2023.ChainForge:AVisualToolkitforPromptEngineeringandLLM Evallm:Interactiveevaluationoflargelanguagemodelpromptsonuser-defined
HypothesisTesting.arXivpreprintarXiv:2309.09128(2023). criteria.arXivpreprintarXiv:2309.13633(2023).
[2] PierreBoyeau,AnastasiosNAngelopoulos,NirYosef,JitendraMalik,and [28] AgnesMKloft,RobinWelsch,ThomasKosch,andSteevenVilla.2023."AIen-
MichaelIJordan.2024.AutoEvalDoneRight:UsingSyntheticDataforModel hancesourperformance,Ihavenodoubtthisonewilldothesame":ThePlacebo
Evaluation.arXivpreprintarXiv:2403.07008(2024). effectisrobusttonegativedescriptionsofAI.arXivpreprintarXiv:2309.16606
[3] ZanaBuçinca,MajaBarbaraMalaya,andKrzysztofZGajos.2021.Totrustorto (2023).
think:cognitiveforcingfunctionscanreduceoverrelianceonAIinAI-assisted [29] RafalKocielnik,SaleemaAmershi,andPaulN.Bennett.2019.WillYouAccept
decision-making. ProceedingsoftheACMonHuman-ComputerInteraction5, anImperfectAI?ExploringDesignsforAdjustingEnd-userExpectationsof
CSCW1(2021),1–21. AISystems.InProceedingsofthe2019CHIConferenceonHumanFactorsin
[4] LingjiaoChen,MateiZaharia,andJamesZou.2023.HowisChatGPT’sbehavior ComputingSystems(Glasgow,ScotlandUk)(CHI’19).AssociationforComputing
changingovertime?arXivpreprintarXiv:2307.09009(2023). Machinery,NewYork,NY,USA,1–14. https://doi.org/10.1145/3290605.3300641
[5] RaunakChowdhuri,NeilDeshmukh,andDavidKoplow.2023. No,GPT4 [30] ZongjieLi,ChaozhengWang,PingchuanMa,DaoyuanWu,ShuaiWang,Cuiyun
can’taceMIT. https://flower-nutria-41d.notion.site/No-GPT4-can-t-ace-MIT- Gao,andYangLiu.2023. Splitandmerge:Aligningpositionbiasesinlarge
b27e6796ab5a48368127a98216c76864 languagemodelbasedevaluators.arXivpreprintarXiv:2310.01432(2023).
[6] PaulFChristiano,JanLeike,TomBrown,MiljanMartic,ShaneLegg,andDario [31] Q.VeraLiaoandS.ShyamSundar.2022. DesigningforResponsibleTrustin
Amodei.2017.Deepreinforcementlearningfromhumanpreferences.Advances AISystems:ACommunicationPerspective.InProceedingsofthe2022ACM
inneuralinformationprocessingsystems30(2017). ConferenceonFairness,Accountability,andTransparency(Seoul,Republicof
[7] AidaMostafazadehDavani,MarkDíaz,andVinodkumarPrabhakaran.2022. Korea)(FAccT’22).AssociationforComputingMachinery,NewYork,NY,USA,
Dealingwithdisagreements:Lookingbeyondthemajorityvoteinsubjective 1257–1268. https://doi.org/10.1145/3531146.3533182
annotations. TransactionsoftheAssociationforComputationalLinguistics10 [32] QVeraLiaoandJenniferWortmanVaughan.2023.AItransparencyintheage
(2022),92–110. ofLLMs:Ahuman-centeredresearchroadmap.arXivpreprintarXiv:2306.01941
[8] MichaelDesmond,MichelleBrachman,EvelynDuesterwald,CaseyDugan, (2023).
NarendraNathJoshi,QianPan,andCarolinaSpina.2022. AIAssistedData [33] XiaohuaLiu,FuruWei,ShaodianZhang,andMingZhou.2013.Namedentity
LabelingwithInteractiveAutoLabel.InProceedingsoftheAAAIConferenceon recognitionfortweets.ACMTransactionsonIntelligentSystemsandTechnology
ArtificialIntelligence,Vol.36.13161–13163. (TIST)4,1(2013),1–15.
[9] StevenDow,AnandKulkarni,ScottKlemmer,andBjörnHartmann.2012.Shep- [34] YuxuanLiu,TianchiYang,ShaohanHuang,ZihanZhang,HaizhenHuang,Furu
herdingthecrowdyieldsbetterwork.InProceedingsoftheACM2012conference Wei,WeiweiDeng,FengSun,andQiZhang.2023. CalibratingLLM-based
oncomputersupportedcooperativework.1013–1022. evaluator.arXivpreprintarXiv:2309.13308(2023).
[10] JohnJDudleyandPerOlaKristensson.2018.Areviewofuserinterfacedesign [35] AmanMadaan,NiketTandon,PrakharGupta,SkylerHallinan,LuyuGao,Sarah
forinteractivemachinelearning. ACMTransactionsonInteractiveIntelligent Wiegreffe,UriAlon,NouhaDziri,ShrimaiPrabhumoye,YimingYang,etal.
Systems(TiiS)8,2(2018),1–37. 2024.Self-refine:Iterativerefinementwithself-feedback.AdvancesinNeural
[11] HarrisonChaseetal.2023.LangChain.https://pypi.org/project/langchain/. InformationProcessingSystems36(2024).
[12] ChrisanthaFernando,DylanBanarse,HenrykMichalewski,SimonOsindero, [36] AditiMishra,UtkarshSoni,AnjanaArunkumar,JinbinHuang,BumChulKwon,
andTimRocktäschel.2023.Promptbreeder:Self-referentialself-improvement andChrisBryan.2023.PromptAid:PromptExploration,Perturbation,Testing
viapromptevolution.arXivpreprintarXiv:2309.16797(2023). andIterationusingVisualAnalyticsforLargeLanguageModels.arXivpreprint
[13] UweFlick.2013.TheSAGEhandbookofqualitativedataanalysis.Sage. arXiv:2304.01964(2023).
[14] FlowiseAI,Inc.2023.FlowiseAIBuildLLMsAppsEasily.flowiseai.com. [37] ChrisParnin,GustavoSoares,RahulPandita,SumitGulwani,JessicaRich,and
[15] MichelNaimGerguis,CherifSalama,andMWatheqEl-Kharashi.2016.ASU: AustinZHenley.2023.BuildingYourOwnProductCopilot:Challenges,Oppor-
AnExperimentalStudyonApplyingDeepLearninginTwitterNamedEntity tunities,andNeeds.arXivpreprintarXiv:2312.14231(2023).
Recognition..InProceedingsofthe2ndWorkshoponNoisyUser-generatedText [38] KayurPatel,NaomiBancroft,StevenM.Drucker,JamesFogarty,AmyJ.Ko,
(WNUT).188–196. andJamesLanday.2010. Gestalt:integratedsupportforimplementationand
[16] KatyIlonkaGero,ChelseSwoopes,ZiweiGu,JonathanKKummerfeld,and analysisinmachinelearning.InProceedingsofthe23ndAnnualACMSymposium
ElenaLGlassman.2024. SupportingSensemakingofLargeLanguageModel onUserInterfaceSoftwareandTechnology(NewYork,NewYork,USA)(UIST
OutputsatScale.arXivpreprintarXiv:2401.13726(2024). ’10).AssociationforComputingMachinery,NewYork,NY,USA,37–46. https:
[17] PaulGewirtz.1996.On"IknowitwhenIseeit".TheYaleLawJournal105,4 //doi.org/10.1145/1866029.1866038
(1996),1023. [39] SavvasPetridis,BenWedin,JamesWexler,AaronDonsbach,MahimaPushkarna,
[18] AndrewD.Gordon,CarinaNegreanu,JoséCambronero,RasikaChakravarthy, NiteshGoyal,CarrieJ.Cai,andMichaelTerry.2023.ConstitutionMaker:Interac-
Ian Drosos, Hao Fang, Bhaskar Mitra, Hannah Richardson, Advait Sarkar, tivelyCritiquingLargeLanguageModelsbyConvertingFeedbackintoPrinciples.
StephanieSimmons,JackWilliams,andBenZorn.2023. Co-audit:toolsto arXiv:2310.15428[cs.HC]
helphumansdouble-checkAI-generatedcontent. arXiv:2310.01297[cs.HC] [40] PromptsRoyale.2023.PromptsRoyale.https://www.promptsroyale.com.
[19] Guardrails2023.GuardrailsAI. https://github.com/guardrails-ai/guardrails. [41] CharviRastogi,MarcoTulioRibeiro,NicholasKing,andSaleemaAmershi.2023.
[20] QingyanGuo,RuiWang,JunliangGuo,BeiLi,KaitaoSong,XuTan,Guoqing SupportingHuman-AICollaborationinAuditingLLMswithLLMs.arXivpreprint
Liu,JiangBian,andYujiuYang.2023.Connectinglargelanguagemodelswith arXiv:2304.09991(2023).
evolutionaryalgorithmsyieldspowerfulpromptoptimizers. arXivpreprint [42] TraianRebedea,RazvanDinu,MakeshSreedhar,ChristopherParisien,and
arXiv:2309.08532(2023). JonathanCohen.2023.Nemoguardrails:Atoolkitforcontrollableandsafellm
[21] YupengHou,JiachengLi,ZhankuiHe,AnYan,XiusiChen,andJulianMcAuley. applicationswithprogrammablerails.arXivpreprintarXiv:2310.10501(2023).
2024.BridgingLanguageandItemsforRetrievalandRecommendation.arXiv [43] MelanieSclar,YejinChoi,YuliaTsvetkov,andAlaneSuhr.2023. Quantify-
preprintarXiv:2403.03952(2024). ingLanguageModels’SensitivitytoSpuriousFeaturesinPromptDesignor:
[22] Instructor 2023. Instructor, Generating Structure from LLMs. HowIlearnedtostartworryingaboutpromptformatting. arXivpreprint
https://jxnl.github.io/instructor/. arXiv:2310.11324(2023).
[23] EllenJiang,KristenOlson,EdwinToh,AlejandraMolina,AaronDonsbach, [44] ShreyaShankar,LabibFawaz,KarlGyllstrom,andAdityaParameswaran.2023.
MichaelTerry,andCarrieJCai.2022.PromptMaker:Prompt-basedPrototyping AutomaticandPreciseDataValidationforMachineLearning.InProceedingsofthe
withLargeLanguageModels.InExtendedAbstractsofthe2022CHIConference 32ndACMInternationalConferenceonInformationandKnowledgeManagement.
onHumanFactorsinComputingSystems(NewOrleans,LA,USA)(CHIEA’22). 2198–2207.
AssociationforComputingMachinery,NewYork,NY,USA,Article35,8pages. [45] ShreyaShankar,HaotianLi,ParthAsawa,MadelonHulsebos,YimingLin,JD
https://doi.org/10.1145/3491101.3503564 Zamfirescu-Pereira,HarrisonChase,WillFu-Hinthorn,AdityaGParameswaran,
[24] MinsukKahng,IanTenney,MahimaPushkarna,MichaelXieyangLiu,James andEugeneWu.2024. SPADE:SynthesizingAssertionsforLargeLanguage
Wexler,EmilyReif,KrystalKallarackal,MinsukChang,MichaelTerry,andLucas ModelPipelines.arXivpreprintarXiv:2401.03038(2024).
Dixon.2024.LLMComparator:VisualAnalyticsforSide-by-SideEvaluationof [46] PatriceSimard,DavidChickering,AparnaLakshmiratan,DenisCharles,Léon
LargeLanguageModels. arXiv:2402.10524[cs.HC] Bottou,CarlosGarciaJuradoSuarez,DavidGrangier,SaleemaAmershi,Johan
[25] AdamTaumanKalaiandSantoshSVempala.2023.Calibratedlanguagemodels Verwey,andJinaSuh.2014.Ice:enablingnon-expertstobuildmodelsinterac-
musthallucinate.arXivpreprintarXiv:2311.14648(2023). tivelyforlarge-scalelopsidedproblems.arXivpreprintarXiv:1409.4814(2014).
[26] OmarKhattab,ArnavSinghvi,ParidhiMaheshwari,ZhiyuanZhang,Keshav [47] ArjunSingh,SergeyKarayev,KevinGutowski,andPieterAbbeel.2017.Grade-
Santhanam,SriVardhamanan,SaifulHaq,AshutoshSharma,ThomasTJoshi, scope:afast,flexible,andfairsystemforscalableassessmentofhandwritten
HannaMoazam,etal.2023.Dspy:Compilingdeclarativelanguagemodelcalls work.InProceedingsofthefourth(2017)acmconferenceonlearning@scale.81–88.ShreyaShankar,J.D.Zamfirescu-Pereira,BjörnHartmann,AdityaG.Parameswaran,andIanArawjo
[48] Arnav Singhvi, Manish Shetty, Shangyin Tan, Christopher Potts, Koushik
Sen,MateiZaharia,andOmarKhattab.2023. DSPyAssertions:Computa-
tionalConstraintsforSelf-RefiningLanguageModelPipelines.arXivpreprint
arXiv:2312.13382(2023).
[49] ChanchalSuman,SaichethanMiriyalaReddy,SriparnaSaha,andPushpakBhat-
tacharyya.2021.Whypaymore?Asimpleandefficientnamedentityrecognition
systemfortweets.ExpertSystemswithApplications167(2021),114101.
[50] HelenaVasconcelos,MatthewJörke,MadeleineGrunde-McLaughlin,Tobias
Gerstenberg,MichaelSBernstein,andRanjayKrishna.2023.Explanationscan
reduceoverrelianceonaisystemsduringdecision-making.Proceedingsofthe
ACMonHuman-ComputerInteraction7,CSCW1(2023),1–38.
[51] PeiyiWang,LeiLi,LiangChen,ZefanCai,DaweiZhu,BinghuaiLin,YunboCao,
QiLiu,TianyuLiu,andZhifangSui.2023.LargeLanguageModelsarenotFair
Evaluators. arXiv:2305.17926[cs.CL]
[52] IanWebster.2023.promptfoo:Testyourprompts.https://www.promptfoo.dev/.
[53] TongshuangWu,EllenJiang,AaronDonsbach,JeffGray,AlejandraMolina,
MichaelTerry,andCarrieJCai.2022.PromptChainer:ChainingLargeLanguage
ModelPromptsthroughVisualProgramming.InExtendedAbstractsofthe2022
CHIConferenceonHumanFactorsinComputingSystems(NewOrleans,LA,USA)
(CHIEA’22).AssociationforComputingMachinery,NewYork,NY,USA,Article
359,10pages. https://doi.org/10.1145/3491101.3519729
[54] Wen-waiYim,YujuanFu,AsmaBenAbacha,NealSnider,ThomasLin,and
MelihaYetisgen.2023.Aci-bench:anovelambientclinicalintelligencedataset
forbenchmarkingautomaticvisitnotegeneration.ScientificData10,1(2023),
586.
[55] MateiZaharia,OmarKhattab,LingjiaoChen,JaredQuincyDavis,HeatherMiller,
ChrisPotts,JamesZou,MichaelCarbin,JonathanFrankle,NaveenRao,and
AliGhodsi.2024. TheShiftfromModelstoCompoundAISystems. https:
//bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/.
[56] JDZamfirescu-Pereira,HeatherWei,AmyXiao,KittyGu,GraceJung,MatthewG
Lee,BjoernHartmann,andQianYang.2023.HerdingAIcats:Lessonsfromde-
signingachatbotbypromptingGPT-3.InProceedingsofthe2023ACMDesigning
InteractiveSystemsConference.2206–2220.
[57] J.D.Zamfirescu-Pereira,RichmondY.Wong,BjoernHartmann,andQianYang.
2023.WhyJohnnyCan’tPrompt:HowNon-AIExpertsTry(andFail)toDesign
LLMPrompts.InProceedingsofthe2023CHIConferenceonHumanFactorsin
ComputingSystems(Hamburg,Germany)(CHI’23).AssociationforComputing
Machinery,NewYork,NY,USA,Article437,21pages. https://doi.org/10.1145/
3544548.3581388
[58] LianminZheng,Wei-LinChiang,YingSheng,SiyuanZhuang,ZhanghaoWu,
YonghaoZhuang,ZiLin,ZhuohanLi,DachengLi,EricXing,etal.2024.Judging
llm-as-a-judgewithmt-benchandchatbotarena.AdvancesinNeuralInformation
ProcessingSystems36(2024).
[59] HongleiZhuang,AdityaParameswaran,DanRoth,andJiaweiHan.2015.Debias-
ingcrowdsourcedbatches.InProceedingsofthe21thACMSIGKDDInternational
ConferenceonKnowledgeDiscoveryandDataMining.1593–1602.WhoValidatestheValidators?AligningLLM-AssistedEvaluationofLLMOutputswithHumanPreferences
A ALGORITHMSFORSELECTING
Therefore,outputswithlowscoresmaystillvarywidelyinquality,
ASSERTIONS&ELICITINGGRADES reflectingoursystem’suncertainty.
A.1 AssertionSelectivityandImpactonLLM
A.3 ChoosingAlignedAssertions
OutputQualityConfidence
OncetheuserstopsgradingandwantstoseethealignmentReport
One way to establish confidence in whether an LLM output is
Card, as depicted in Figure 2e, for each criterion, we select the
problematicistoassesstheselectivity,orpassrate,ofassertions
candidateassertionwiththehighestalignmentscore.Weadopt
thatfailit.Intuitively,assertionsthatfrequentlyfailoutputs(low
notationfromShankaretal.[45]indefiningalignment.Formally,
selectivity)providelimitedinsightintooutputquality.Forexample, let𝐸beasetofLLMpipelineinput-outputpairsand𝑓 :𝐸→{0,1}
anassertionthattriviallyfailseveryoutputoffersnodiscernment representanassertion.Let𝑦beabinaryvector,where𝑦
𝑖
∈{0,1}
andhasaselectivityof0. representswhethertheuserthinksanLLMoutput𝑒 𝑖isbad.Suppose
EvalGenleveragesselectivityestimatesofassertionstoassign 𝐹 ={𝑓 1,𝑓 2,...,𝑓 𝑗}isasetof𝑗 assertions.Concretely,thecoverage
aconfidencescoretoeachLLMoutput,indicatingthelikelihood andfalsefailurerate(FFR)of𝐹 isrepresentedbythefollowing
itisofpoorquality.Therationaleisstraightforward:anoutputis
equations:
morelikelytobeproblematiciffailedbyassertionsknownfortheir
highselectivity.Concretely,forasetofassertions𝐹 whereeach
assertion𝑓 ∈𝐹 returns1forapassand0forafail,wecalculatethe Coverage(𝐹)= (cid:205) 𝑖I[𝑦 𝑖 =0∧(∃𝑓 ∈𝐹,𝑓 (𝑒 𝑖)=0)]
confidencescoreforanLLMoutput𝑒asfollows: (cid:205) 𝑖I[𝑦 𝑖 =0]
FFR(𝐹)=
(cid:205) 𝑖I[𝑦 𝑖 =1∧(∃𝑓 ∈𝐹,𝑓 (𝑒 𝑖)=0)]
𝜎(𝑒)= ∑︁ selectivity(𝑓)×𝑓 (𝑒) (cid:205) 𝑖I[𝑦 𝑖 =1]
𝑓∈𝐹 Inbothdefinitions,Iistheindicatorfunction.Intuitively,cover-
agerepresentstheset’struenegativerate,whilefalsefailurerate
The score 𝜎 is always non-negative. A score of 0 means no
representstheset’sfalsenegativerate.Analignedsetofassertions
assertionshavefailedtheoutput,indicatingahigherlikelihoodof
wouldhaveahighcoverageandlowfalsefailurerate.Wedefinethe
quality,whilelowerscores,resultingfromfailuresbynon-selective
alignmentof𝐹 astheharmonicmeanofcoverageandtheinverse
assertions,pointtouncertaintyorpotentialissueswiththeoutput.
ofFFR:
A.2 SamplingGrades
Coverage(𝐹)×(1−FFR(𝐹))
Giventhatusersmaynotwanttogradesomanyoutputsinthe Alignment(𝐹)=2×
Coverage(𝐹)+(1−FFR(𝐹))
EvalGeninterface,choosingwhichoutputsforuserstogradeis
crucialforaligningthesystem’sevaluationswithuserexpectations. NotethatalignmentisverysimilartoF1score;however,weare
Randomlyselectingoutputswithoutconsideringtheirpredicted concernedwiththeprecisionandrecalloffailures(i.e.,when𝑓 =0,
qualitycanleadtomisalignment,especiallyiftheselectedsamples notwhen𝑓 =1),andweareconcernedwithaset(i.e.,whenany
aren’trepresentativeoftheentiredataset.Priorworkalsounder- assertionreturns0).
scorestheimportanceofsolicitingarepresentativegradedsample
ofLLMoutputs[2,45]. A.4 EvaluationofSamplingPolicy
Given𝜎scoresaspreviouslydefined,weconsideranumberof
WedescribedinAppendixA.2fouroptionsweconsideredtosample
strategiestosampleoutputsforgrading:
LLMoutputs:random,highest,lowest,andalternating.Here,we
• Random:Sampleoutputsatrandom(uniformly)
compareEvalGen’ssamplingpolicy,alternating,totheseother
• Highest:Sampletheoutputswiththehighest𝜎.Thisap-
three baselines. For this experiment, we sampled 16 outputs to
proachfocusesonpotentiallyproblematiccontent.
grade,butinpracticetheusercangrademoreorfewer.Usingthe
• Lowest:Sampletheoutputswiththelowest𝜎,prioritizing
sameLLMpipelinesasdescribedinSection5.1,toassesssampling
outputsthatdon’tfailanyassertionsorfaillow-selectivity
variance, we conducted 10 trials for each of the four sampling
assertions.
policies—where,foreachtrial,wekeptthesamesetofcandidate
• Alternating:Alternatebetweenhighandlow𝜎,aiming
assertionfunctions.
foradiversesamplewithbothbadandgoodoutputs.
Thefindings,showninFigure4,revealthattherandomsampling
InSection5,wetestthesestrategiesagainstarandombaseline policyexhibitsalargevarianceinalignment.Thisinconsistency
ontwodifferentLLMpipelines.Weemployanalternatingsampling could lead to user frustration, particularly if the effort spent in
policyfortheEvalGenuserstudies.Wedonotclaimtohavethe gradingoutputsresultsinassertionsetswithunpredictablerele-
bestsamplingpolicy;wechoseanalternatingpolicywiththehope vancetotheirspecifiedcriteria.Thealternativesamplingstrategies,
thatitwouldsolicitabalancedsampleofgoodandbadgrades. whichweighttheprobabilityforanLLMoutputtobegradedby
Onemaywonderwhywedonotlistapolicythatranksthe theselectivity(i.e.,passrate)ofassertionsthatfailit,consistently
outputsbyscoreandsamplesthemiddleforgrading.Whilethis yieldedhigheralignmentscoresacrosstheentiredatasetsthanthe
mightseemakintoseekingoutuncertaincases—asiscommon randompolicy.Notably,whilethealternatingpolicydidn’tconsis-
inactivelearning—ourscoresrepresentthelikelihoodofoutputs tentlyoutperform,ourresultssuggestthatanynon-randompolicy
beingpoor.Theydonotdifferentiatebetweengoodandbadperse. implementedinEvalGenmayachievesatisfactoryoutcomes.ShreyaShankar,J.D.Zamfirescu-Pereira,BjörnHartmann,AdityaG.Parameswaran,andIanArawjo
Andtheproductpipelinepromptisasfollows:
0.6
You are an expert copywriter. You need to write an e-
commerce product description based on the product
0.5
details and customer reviews. Your description
should be SEO-optimized. It should use an active
0.4 voice and include the product's features,
benefits, unique selling points without
0.3 overpromising, and a call to action for the buyer
. Benefits describe how product features will
work for the buyer, addressing exactly how the
0.2
product will improve their lives. Clearly
distinguish between features (e.g., lightweight,
0.1 USB-chargeable) and benefits (e.g., convenience,
Dataset nutritious drinks on-the-go). Don't mention
0.0 product medical weaknesses of the product or use generic or
repetitive language. Don't make up review text or
random highest lowest alternating
quotes. Don't include any links. Don't cite the
SamplingPolicy reviews too heavily. Divide your description into
readable chunks divided by relevant subheadings.
Keep your description around 200 words, no more
Figure4:Alignmentsforassertionsetsthatresultfromdif-
than 300, in Markdown format.
ferentpoliciestosamplegradesfromtheuser.Eachpolicy
wastestedacross10trials,witheachinvolvingasampleof16 {document}
LLMoutputs.RandomlysamplingLLMoutputsforgrading
introducessignificantvarianceinalignmentacrosstheentire
dataset. Received03April2024
Inthisofflinestudy,asshowninFigure4,there’snovariationin
theoutcomesofthenon-randompoliciesbecausetheyaredetermin-
istic.However,inreal-worlduse,EvalGenupdatesitspredictions
asitreceivesnewinformation,sotherecouldbesomedifferences
inresultsovertime.Initially,whenusersstartgradingoutputsin
EvalGen,theymighteffectivelybegradingrandomoutputsfor
thefirstoneortwooutputs,asthe𝜎scoresupdateandstabilize.
B TASKPROMPTS
Wepreparedtwopromptsandcorrespondingdatasetsfortasksto
presentusers(5.1).Bothpipelineswereadaptedfrompriorwork[21,
54]andcorrespondtomedicalrecordprocessingandaproduct
descriptionwriting,respectively.Themedicalpipelinepromptis
asfollows:
You are extracting insights from some medical records.
The records contain a medical note and a
dialogue between a doctor and a patient. You need
to extract values for the following: Chief
complaint, History of present illness, Physical
examination, Symptoms experienced by the patient,
New medications prescribed or changed, including
dosages (N/A if not provided), and Follow-up
instructions (N/A if not provided). Your answer
should not include any personal identifiable
information (PII) such as name, age, gender, or
ID. Use "the patient" instead of their name, for
example. Return your answer as a bullet list,
where each bullet is formatted like `chief
complaint: xx.` If there is no value for the key,
the value should be `N/A`. Keep your response
around 150 words (you may have to summarize some
extracted values to stay within the word limit).
{transcript}
tnemngilA