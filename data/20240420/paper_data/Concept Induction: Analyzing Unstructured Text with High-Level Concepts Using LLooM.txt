Concept Induction: Analyzing Unstructured Text with High-Level
Concepts Using LLooM
MichelleS.Lam JaniceTeoh JamesA.Landay
StanfordUniversity StanfordUniversity StanfordUniversity
Stanford,CA,USA Stanford,CA,USA Stanford,CA,USA
mlam4@cs.stanford.edu jteoh2@stanford.edu landay@stanford.edu
JeffreyHeer MichaelS.Bernstein
UniversityofWashington StanfordUniversity
Seattle,WA,USA Stanford,CA,USA
jheer@uw.edu msb@cs.stanford.edu
Figure1:AsummaryoftheLLooMconceptinductionalgorithm.Statusquotopicmodelstendtoproducetopicsalignedwith
low-levelkeywords(e.g.,‚Äúfeminist,feminism‚Äù).WeintroduceLLooM,aconceptinductionalgorithmthattakesinunstructured
textandproduceshigh-levelconcepts(e.g.,‚ÄúCriticismofFeminism‚Äù)definedbyexplicitinclusioncriteria.Weinstantiatethis
algorithmintheLLooMWorkbench,amixed-initiativetextanalysistoolthatcanamplifytheworkofanalystsbyautomatically
visualizingdatasetsintermsofinterpretable,high-levelconcepts.
ABSTRACT toxiconlinecomments,whereastate-of-the-artBERTopicmodel
Dataanalystshavelongsoughttoturnunstructuredtextdatainto outputs‚Äúwomen,power,female,‚Äùconceptinductionproduceshigh-
meaningfulconcepts.Thoughcommon,topicmodelingandclus- levelconceptssuchas‚ÄúCriticismoftraditionalgenderroles‚Äùand
teringfocusonlower-levelkeywordsandrequiresignificantinter- ‚ÄúDismissalofwomen‚Äôsconcerns.‚ÄùWepresentLLooM,aconcept
pretativework.Weintroduceconceptinduction,acomputational inductionalgorithmthatleverageslargelanguagemodelstoitera-
processthatinsteadproduceshigh-levelconcepts,definedbyex- tivelysynthesizesampledtextandproposehuman-interpretable
plicitinclusioncriteria,fromunstructuredtext.Foradatasetof conceptsofincreasinggenerality.WetheninstantiateLLooMina
mixed-initiativetextanalysistool,enablinganalyststoshifttheir
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalor attentionfrominterpretingtopicstoengagingintheory-driven
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed analysis.Throughtechnicalevaluationsandfouranalysisscenarios
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
rangingfromliteraturereviewtocontentmoderation,wefindthat
onthefirstpage.Copyrightsforcomponentsofthisworkownedbyothersthanthe
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or LLooM‚Äôsconceptsimproveuponthepriorartoftopicmodelsin
republish,topostonserversortoredistributetolists,requirespriorspecificpermission termsofqualityanddatacoverage.Inexpertcasestudies,LLooM
and/orafee.Requestpermissionsfrompermissions@acm.org.
helped researchers to uncover new insights even from familiar
CHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA
¬©2024Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM. datasets,forexamplebysuggestingapreviouslyunnoticedconcept
ACMISBN979-8-4007-0330-0/24/05...$15.00 ofattacksonout-partystancesinapoliticalsocialmediadataset.
https://doi.org/10.1145/3613904.3642830
4202
rpA
81
]CH.sc[
1v95221.4042:viXraCHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA M.S.Lam,J.Teoh,J.A.Landay,J.Heer,M.S.Bernstein
CCSCONCEPTS ‚ÄúCriticismoftraditionalgenderroles‚Äùand‚ÄúDismissalofwomen‚Äôs
‚Ä¢ Human-centered computing ‚Üí Human computer inter- concerns.‚ÄùEachconceptisdefinedbydetailedcriteriainnatural
action(HCI);Interactivesystemsandtools;Visualizationsystems language:e.g.,‚ÄúDoestheexamplecritiqueorchallengetraditional
andtools;‚Ä¢Computingmethodologies‚ÜíArtificialintelligence; genderrolesorexpectations?‚Äù,or‚ÄúDoestheexampledismissor
Naturallanguageprocessing. invalidatewomen‚Äôsfears,concerns,orexperiences?‚Äù.Thesedefin-
ingcriteriaaresupportedbyasetofrepresentativetextexamples
KEYWORDS thatbestdemonstratetheideaoftheconcept,alongwithconcept
scoresrangingfrom0to1thatindicatetheextenttowhichevery
unstructuredtextanalysis,topicmodeling,human-AIinteraction,
exampleinthedatasetalignswiththatconcept(Figure1).
largelanguagemodels,datavisualization
Toenabletheseresults,wedevelopaconceptinductionalgo-
ACMReferenceFormat: rithmcalledLLooM,whichdrawsontheabilityoflargelanguage
MichelleS.Lam,JaniceTeoh,JamesA.Landay,JeffreyHeer,andMichaelS. models (LLMs) like GPT-3.5 and GPT-4 [46] to generalize from
Bernstein.2024.ConceptInduction:AnalyzingUnstructuredTextwithHigh- examples:LLooMsamplesextractedtextanditerativelysynthe-
LevelConceptsUsingLLooM.InProceedingsoftheCHIConferenceonHuman sizesproposedconceptsofincreasinggenerality(Figure2).Once
FactorsinComputingSystems(CHI‚Äô24),May11‚Äì16,2024,Honolulu,HI,USA.
datahasbeensynthesizedintoaconcept,wecanmoveuptothe
ACM,NewYork,NY,USA,28pages.https://doi.org/10.1145/3613904.3642830
nextabstractionlevel;wecangeneralizefromsmaller,lower-level
conceptstobroader,higher-levelconceptsbyrepeatingtheprocess
1 INTRODUCTION
withconceptsastheinput.Sinceconceptsincludeexplicitinclu-
Muchoftheworld‚Äôsinformationisboundupinunstructuredtext, sioncriteria,wecanexpandthereachofanygeneratedconcept
butitischallengingtomakesenseofthisdata.Topicmodeling toconsistentlyclassifynewdatathroughthatsamelensanddis-
algorithms‚ÄîsuchasLatentDirichletAllocation(LDA)andunsu- covergapsinourcurrentconceptset.Thesecorecapabilitiesof
pervised clustering based on language model embeddings such synthesis,classification,andabstractionarewhatallowLLooMto
asBERTopic‚Äîhavebecomeubiquitoustoolsforwadingthrough iterativelygenerateconcepts,applythembacktodata,andbubble
large-scale,unstructureddata[3,51].Spreadingtodomainslike uptohigher-levelconcepts.
socialscienceandmedicine,topicmodelshavehadfar-reaching Instantiatedinamixed-initiativetextanalysistoolthatwecall
impact:researchershaveusedthesemodelstoanalyzescientific theLLooMWorkbench,ouralgorithmamplifiestheworkofana-
abstracts,socialmediafeedcontent,andhistoricalnewspapercov- lystsbyautomaticallyvisualizingdatasetsintermsofinterpretable,
erageinordertoinvestigatephenomenalikescientificresearch high-levelconcepts.TheLLooMWorkbenchadditionallyoffersan-
trends,politicalpolarization,publichealthmeasures,andmedia alystsatraceableandmalleableprocess.Eachextractedconceptis
framing[16,18,24,47,49,57]. notjustafinallabel,butcanbeunrolledintoanauditabletraceof
However,thetopicsproducedbythesemodelsaredefinedrel- thelower-levelsubconceptsthatledtotheconcept(e.g.,‚ÄúWomen‚Äôs
ative to low-level text signals such as keywords, requiring sub- responsibilities,‚Äù ‚ÄúTraditional gender roles,‚Äù and ‚ÄúPower dynam-
stantialeffortfromtheanalystwhomustinterpret,validate,and icsandwomen‚Äùledtothe‚ÄúCriticismoftraditionalgenderroles‚Äù
reasonaboutthosetopics.Forexample,whenappliedtoadatasetof concept),whereeachsubconceptisagainpairedwithreviewable
misogynisticsocialmediaposts,astate-of-the-artBERTopicmodel criteriaandrepresentativeexamples.Further,analystscanusethe
producescompetentbutlow-leveltopicssuchas‚Äúwomen,power, LLooMWorkbenchtoseedthealgorithm,steeringitsattention
female‚Äùand‚Äúfeminists,feminism,feminist,‚Äùwhichareon-topicbut towardparticularconcepts.
toogenerictohelpananalystanswerquestionssuchas‚Äúhoware Withaseriesoffouranalysisscenarios,wefirstillustratehow
womeninpowerdescribed?‚Äùand‚Äúwhatkindsofargumentsare LLooM works in practice by comparing it to a state-of-the-art
leviedagainstfeminists?‚ÄùThisgaparisesbecausetopicmodelsrely BERTopicmodel.Thesescenariosspanavarietyofdomainsand
onmeasuresoftermco-occurrenceorembeddingdistances,which analysisgoals:acontentmoderationtaskwithadatasetoftoxicon-
arehighlycorrelatedwithlow-leveltextualsimilarityandareof- linecontent[35],ananalysisofpartisananimosityonsocialmedia
tenunreliableproxiesforhumanjudgement[26,37,63].Moreover, feedswithapoliticalsocialmediacontentdataset[30],aliterature
topicmodelsoftenproducetopicsthataretoogeneral,toospe- reviewanalyzingtheindustryimpactofthefieldofHCIwithpaper
cific,orthataregenerallyincoherent(‚Äújunk‚Äùtopics,e.g.,‚Äúmorning, abstractsfromthepast30years[6],andananalysisofanticipated
snoring,sir‚Äù)[1,11].Analystslackrecoursewheninputtextsare consequencesofAIresearchwithadatasetofbroaderimpactstate-
categorizedintouninformativegroups.Thetasksthatanalystsmust mentsfromNeurIPS2020[45].Inthesescenarios,LLooMnotonly
perform‚Äîgeneratingresearchquestions,formulatinghypotheses, covers most topics surfaced by BERTopic, but also provides on
andproducinginsights‚Äîaredependentonthecreationofhigh- average2.0timesthenumberofhigh-qualitytopics.Additionally,
levelconcepts,whichwedefineashuman-interpretabledescriptions cluster-basedtopicmodelsstrugglewithlargesetsofuncategorized
definedbyexplicitinclusioncriteria. examples(averaging77.7%coverage),butLLooMconceptscover
Inthispaper,weintroduceconceptinduction,thetaskofextract- onaverage93%ofexamples.
inghigh-levelconceptsfromunstructuredtexttoamplifytheory- Then,inasetoftechnicalevaluations,webenchmarkLLooM
drivendataanalysis.Forexample,giventhesamedatasetofpo- againstzero-shotGPT-4variantsandBERTopicforreal-worldand
tentiallymisogynisticsocialmediapoststhattheBERTopicmodel syntheticdatasets;wefindthatLLooMprovidesperformancegains
labeled with ‚Äúwomen, power, female‚Äù and ‚Äúfeminists, feminism, overbaselinemethods.Thesebenefitsareespeciallystrongforun-
feminist,‚Äù concept induction seeks to identify concepts such as seendatasets(ùëù < .02)andnuancedconcepts(ùëù < .0001)whereConceptInduction:AnalyzingUnstructuredTextwithHigh-LevelConceptsUsingLLooM CHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA
Figure2:AprocessoverviewoftheLLooMconceptinductionalgorithm.Startingfrom(1)unstructuredtextdata,LLooM
performs(2)conceptgenerationaidedbyanLLMtoproduce(3)high-levelconcepts,whichconsistofgeneratednaturallanguage
descriptionsandexplicitcriteriaintheformofzero-shotLLMprompts.LLooMperforms(4)conceptscoringbasedonconcept
criteriapromptsandvisualizesdataintermsofconceptsinthe(5)LLooMWorkbench,amixed-initiativetextanalysistool.
baselinemethodsstruggle;LLooMimprovesgroundtruthconcept scenarios and a technical evaluation demonstrating how
coveragebyatleast17.9%and16.0%inthosecases,respectively. LLooMenablesanalyststoderiveinsightsfromdatathat
WhilebothLLooMandGPT-4canproduceoverarching,summary- extendbeyondstatusquotools.LLooMimprovesuponthe
style concepts, LLooM is capable of additionally producing the qualityandcoverageoftopicmodelsandhelpsexpertana-
nuancedandgroundedconceptsthatanalystsseektomorerichly lyststouncovernovelinsightsevenonfamiliardatasets.
characterizepatternsindata.Inexpertcasestudies,wealsogave
original researchers for two of the analysis scenarios access to 2 RELATEDWORK
LLooMtore-analyzetheirdata.TheresearchersusedLLooMWork-
Toinstantiateaconcept-centeredapproachforunderstandingand
benchtointeractivelysteerconceptsandinitiatetheory-driven
interactingwithdata,LLooMdrawsonpriorliteratureintopic
explorations(e.g.,refiningaconceptof‚ÄúPolicy-related‚Äùsocialme-
modelingandunsupervisedclustering,qualitativeanalysis,and
diapoststothosewherepolicywasblamedforacrisis,ordrawing
mixed-initiativedataanalysistools.
ondomainknowledgetoaddanewconceptfor‚ÄúSocialdistrust‚Äù
definedby‚Äúdistrustofotherpeopleorsociety‚Äù).
2.1 TopicModelingandClustering:Automated
LLooMinstantiatesanovelapproachtodataanalysisthatallows
analyststoseeandexploredataintermsofconceptsratherthan ConceptDevelopment
siftingthroughmodelparameters.Bytransformingunstructured Avastamountofimportantinformationexistsaslargeandun-
dataintohigh-levelconceptsthatanalystscanunderstandandcon- structuredtextdatasets‚Äîglobalsocialmediaposts,corporaofhis-
trol,LLooMcanaugmentanalyststodrawoutnewinsights,weave toricaldocuments,massivelogsofmodel-generatedoutput‚Äîbut
togetherconnections,andformanarrativetapestrysupportedby itischallengingtomakesenseofthiskindofdata.Today,many
inputdata.Thispaperintroducesthefollowingcontributions: data analysts rely on topic modeling and unsupervised cluster-
‚Ä¢ TheLLooMalgorithm.WeintroduceLLooM,aconceptin- ingtoautomaticallysummarizeorexploredata.LatentDirichlet
ductionalgorithmthatextractsandappliesconceptstomake Allocation(LDA),aclassictopicmodelingapproach,represents
senseofunstructuredtextdatasets.LLooMleverageslarge documentsasdistributionsovertopicsandrepresentstopicsas
languagemodelstosynthesizesampledtextspans,generate distributionsoverwords,andgenerateslatenttopicsbasedonthe
conceptsdefinedbyexplicitcriteria,applyconceptsbackto co-occurrenceofwordsindocuments[3].Whileeasytoapply,a
data,anditerativelygeneralizetohigher-levelconcepts. persistentissuewithLDAisthatitstopicsmaybeincoherentor
‚Ä¢ TheLLooMWorkbench.WeinstantiatetheLLooMalgo- irrelevanttotheanalyst[1,7,11].Furthermore,itsbag-of-words
rithmintheLLooMWorkbench,atextanalysistoolthat (orlow-dimensionaln-gram)assumptionslimittopicstosimpler
amplifiestheory-drivendataanalysisbyallowingusersto ideasthatcanbecapturedwithkeywords.
visualizeandinteractwithtextdataintermsofhigh-level Morerecentapproachesperformunsupervisedclusteringon
concepts.Thetoolisavailableincomputationalnotebooks high-dimensionalvectorembeddingstouncoverlatenttopicswith-
orastandalonePythonpackage.1 outrelyingdirectlyonkeywords.PopularpackageslikeBERTopic[25]
‚Ä¢ Evaluationwithanalysisscenarios,atechnicalevalu- streamlinethecommonpipelineofembeddingtextdata(e.g.,using
ation,andexpertcasestudies.Wepresentfouranalysis apre-trainedmodellikeBERT[17,51]),performingdimensional-
ityreduction,andapplyingaclusteringalgorithm(e.g.,k-means,
1Codeavailableathttps://github.com/michelle123lam/lloom agglomerativeclustering,HDBSCAN[40])torecovergroupsofCHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA M.S.Lam,J.Teoh,J.A.Landay,J.Heer,M.S.Bernstein
similar examples based on distance metrics. Unsupervised clus- technicalbarriers,interpretability,andtrust‚Äîthatsocialscientists
teringloosensthemappingfromtopicstokeywords,butbecause anddataanalystsencounterwhenusingtopicmodels[2,13,50].In
embeddingdistancesarestillhighlycorrelatedwithlow-leveltext thefaceofuninterpretabletopics,researchersfoundthatinteractive
similarityratherthanhumanjudgmentofsemanticsimilarity,re- visualanalysissystemssuchasTermite,LDAvis,andSemanticCon-
sultingtopicsfrequentlyalignwithsurfacelevelfeatures[26,37]. ceptSpacescouldenableanalyststoidentifycoherentthemesand
Whiletoday‚Äôstopicmodelsappearhighlyperformantbasedon buildtrustintopicmodels[12,15,20,55].LLooManalogouslyen-
automatedmetrics,recentworkhashighlightedthatthesemetrics ablesanalyststovisualizeanditerateonmodeloutputstofacilitate
maybestronglymisalignedwithtruehumanevaluationsoftopic interpretabilityandtrust.
quality[28,29]‚Äîthereisstillacriticalgapbetweenautomatically Beyond topicmodeling, work atthe intersectionof HCIand
generatedtopicsandmeaningfulinterpretations.LLooMaddresses AIhasassisteddatasensemakingbyaligningtechnicalabstrac-
this gap by supporting a workflow for data analysts to extract tionstouser-understandableconcepts.Interactivemachinelearning
interpretable,high-levelconceptsfromunstructuredtext. toolssuchasFeatureInsight[4]andAnchorViz[10]helpusersto
builddictionary-orexample-basedconceptstoexploredataand
2.2 QualitativeAnalysis:ManualConcept improveclassifierperformance.ModelSketchingleveragesLLMsto
Development allowMLpractitionerstocreatesketch-likemodelsbycomposing
human-understandableconcepts[36].SystemslikeGANzilla[21]
Incontrasttocommonmachinelearningapproaches,qualitative
andSensecape[56]supportsensemakingwithgenerativemodels
analysismethodshavelongacknowledgedthatdatainterpreta-
byorganizingoutputsintoconceptualgroupingsthataremeaning-
tionsarevaried,subjective,andhighlydependentonone‚Äôsanalysis
fultotheuser,suchassystem-providedimage-editingdirectionsor
goals[2,44].Qualitativecodingprocesses,suchasgroundedtheory
user-curatedhierarchicalcanvases.Instatisticaldataanalysis,sys-
methods,havetheresearcherengageinmanuallyreviewingand
temslikeTisane[33]aidanoften-overlookedprocessofhypothesis
interpretingthedata,typicallystartingfromline-by-line,lower-
formalization[32]byallowinganalyststoiteratebackandforth
levelsummariesandproceedingtoroundsofthematicgrouping
betweenconceptualhypothesesandmodelimplementations.
andsynthesisintocodes[8,43].Oncecodeshavebeensynthesized,
Meanwhile,recentworkinNLPhasexploredhowLLMsmight
theyareappliedbacktothedatainaprocessof‚Äúconstantcompari-
aidtextanalysisbyproposingnaturallanguageexplanationsfor
son,‚Äùwhichbothelucidatesthedataandteststherobustnessand
clusters[60],augmentingexpertdemonstrationsforsemi-supervised
richnessofthecurrentcodes.Thesesynthesizedcodesalsoserve
textclustering[58],orgeneratingandassigninginterpretabletop-
astheinputforeachsuccessiveroundofcodingtoderivebroader,
ics[48].LLooMbuildsonthegoaloforientingdataanalysisaround
moreabstractiveinsights.TheLLooMalgorithmdrawsinspiration
human-understandableconcepts,buttakesastrongerstanceabout
fromqualitativecodingprocesses,seekingtobringthebenefits
therequirements,scope,andapplicationofextractedconcepts.Tobe
ofiterativeinterpretation,codedevelopment,andrefinementto
mostusefulforthedataanalysistasksofforminghypothesesand
automateddataanalysistools.
answeringresearchquestions,werequireconceptstobedefinedby
Giventhesubstantiallaborinvolvedinconductingqualitative
ahuman-understandabledescriptionandexplicitinclusioncriteria.
analysis,researchershaveexploredalgorithmicsystemsthatuseAI
Tosupportarichunderstandingoftext,theLLooMalgorithmpro-
toaidqualitativeanalystswithbothinductivecoding(generating
ducesconceptsatthescopeofnotjustbroadtopic-levelpatterns,
codesfromdata)anddeductivecoding(applyingcodesbackto
butalsonuancedandspecifictextattributes.Finally,whilethetasks
data)[9,19,52].Mostrecently,researchattheintersectionofLLMs
oftextclusteringandtopicmodelingfocusonproducingoutputs
andqualitativeanalysishasfocusedonamplifyingdeductivecoding
toaiddatainterpretation,theLLooMWorkbenchinstantiatescon-
processesandfoundthatLLMsperformfairlywellincodingdata
ceptsasbidirectionalrepresentationsthatbothserveasanoutput
withexistingcodebooks,thoughnotenoughforfullreliance[62,64].
modalitytointerpretdataandaninput modalitytoproactively
Meanwhile,novelsystemsdesignedtoaidinductivecoding,such
authorconceptsandinvestigatenewresearchquestions.
asPaTAT[22]andScholastic[27],haveexploredopportunitiesfor
human-AIcollaborationthatkeeptheinductivecodegeneration
workinthehandsofhumananalystsandleverageAItosample
andre-organizedataortoformalizethemesintodecisionrules.
Webuildonthisworktoaugmentanalystswhoseektoextract
meaningfulhigh-levelconceptsfromtheirdata.However,LLooM
investigateswhetheroptionsforAI-initiatedconceptgeneration 3 LLOOM:CONCEPTINDUCTIONUSING
canfurtherextendtheworkofanalystsasatoolforthoughtto LARGELANGUAGEMODELS
reflectonawiderrangeofpotentialdataanalysisdirections.
Wedefineconceptinductionasaprocessthattakesanunstructured
textdatasetasinputandproducesasetofemergent,high-level
2.3 AI-AssistedDataAnalysis:Mixed-Initiative
conceptsasoutput,eachofwhicharedefinedbyexplicitcriteria.We
ConceptDevelopment
firstdescribeLLooM,aconceptinductionalgorithmthatleverages
Ourworkbuildsonasubstantialbodyofmixed-initiativeapproaches largelanguagemodelstoiterativelyextractandsynthesizeconcepts
toaiddataanalysis,andweespeciallydrawattentiontopriorwork fromrawdata.Then,wepresenttheLLooMWorkbench,atext
thatsimilarlyseekstoextracthuman-interpretableconceptsfrom analysistoolthatusestheLLooMalgorithmtoenableanalyststo
data.Workintopicmodelinginvestigatedthechallenges‚Äîsuchas generate,visualize,andrefinehigh-levelconceptsfromtextdata.ConceptInduction:AnalyzingUnstructuredTextwithHigh-LevelConceptsUsingLLooM CHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA
3.1 TheLLooMAlgorithm toidentifyunifyingconceptsandcarrythemforwardtonewexam-
TheLLooMalgorithmperformsconceptinductionbyexecuting ples.Thiscapability,alsoreferredtoasfew-shotreasoning,isoften
iterativeroundsofconceptgenerationandscoringusingalargelan- leveragedincaseswheretheuseralreadyknowstheunderlying
guagemodel(LLM).WespecificallyuseGPT-3.5andGPT-4inour patternandwantsthemodeltoapplyitrepeatedly(e.g.,totranslate
implementation.SummarizedinFigure3,theprimarygoalofour texttodifferentformats,ortotransferawritingstyle)[5].However,
algorithmistoexecutethecriticalsynthesisstepofbridgingfrom wecanalsoleveragethiscapabilityinsituationswheretheuser
low-leveltextsignalstohigh-levelconcepts,whichwedefineas doesnotknowaheadoftimewhatconceptsexistintheirdatato
human-interpretabledescriptionsdefinedbyexplicitinclusioncri- aiddiscovery.WhileLLMscanhallucinateandproduceunreliable
teria,specificallyanatural-languagedescriptionofdecisionrule(s) outputs,byconstructingourtasktonotjustproduceconcepts,but
forwhetheraninputmatchestheconcept.Withpriormethods,an- thecriteriatoevaluatethoseconcepts,wecanverifyLLMoutputs
alystsmustcarryoutthiscriticalbridgingworkfromlow-leveltext byreviewingthecriteriaandre-evaluatingtheoriginaldatatotest
signalstohigh-levelconceptsthemselves;LLMsprovideassistance ifconceptshold.
withthisstep.
Buildingonthisinsight,LLooMimplementstheSynthesize
First, for the concept generation step, LLooM implements the
operatorasazero-shotpromptthatinstructsanLLM(gpt-4)to
Synthesize operatorthatpromptstheLLMtogeneralizefrom identifyunifyinghigh-levelconceptsfromaprovidedclusterof
providedexamplestogenerateconceptdescriptionsandcriteriain examples.Theinstructionsaskthemodeltogenerateanamethat
naturallanguage.Aswedemonstrateempiricallyinourtechnical describestheconcept,provideIDsoftherepresentativeexamples
evaluations(¬ß5),directlypromptinganLLMlikeGPT-4toperform thatbestmatchthisconcept,andgenerateitsownpromptthatcan
thiskindofsynthesisproducesbroad,genericconceptsratherthan evaluateanoveltextexampleanddeterminewhethertheconcept
nuanced and specific conceptual connections (e.g., that a set of applies.Eachofthesecomponentsisusefuloutputforunderstand-
postsarefeminist-related,ratherthanthattheyallconstitutemen‚Äôs ingthemeaningofaconcept.Thesecomponentsalsoleveragea
critiquesoffeminism).Whilegenericconceptsmaybehelpfulforan chain-of-thought(CoT)promptingstrategy[34,61]thatinstructs
overarchingsummaryofdata,analystsseekricher,morespecific themodeltoprovideatraceofitsworkandimprovethelikelihood
conceptsthatcharacterizenuancedpatternsinthedata,assupported ofinternalconsistency.
byourexpertcasestudies(¬ß6).Additionally,suchsynthesisisnot
Weincludeourprompttemplatebelow.2Userscanvarythecon-
possiblefortextdatasetsthatexceedLLMcontextwindows. ceptnamelength,thenumberofrepresentativeconceptexamples,
Toaddresstheseissues,theLLooMalgorithmincludestwoop- andthenumberofconceptstosuggest;weuse2-4wordconcept
eratorsthataidbothdatasizeandconceptquality:(1)a Distill namesandrequest1-2representativeexamplesbydefault.
operator,whichshardsoutandscalesdowndatatothecontextwin- I have this set of bullet point summaries of text
dowwhilepreservingsalientdetails,and(2)a Cluster operator, examples:
{bullets_json}
whichrecombinestheseshardsintogroupingsthatshareenough
meaningfuloverlaptoinducemeaningfulratherthansurface-level
Please write a summary of {n_concepts} unifying
conceptsfromtheLLM. patterns for these examples {seed_phrase}.
Finally,fortheconceptscoringstep,weleveragethezero-shot For each high-level pattern,write a {n_name_words}
reasoningabilitiesofLLMstoimplementa Score operatorthat word NAME for the pattern and an associated one-
sentence ChatGPT PROMPT that could take in a new text
labelsdataexamplesbyapplyingconceptcriteriaexpressedaszero-
example and determine whether the relevant pattern
shotprompts.Withtheselabels,wecanvisualizethefulldataset applies.
intermsofthegeneratedconceptsorfurtheriterateonconcepts Please also include {n_example_ids} example_ids for
byloopingbacktoconceptgeneration.Wenowwalkthroughthe items that BEST exemplify the pattern. Please respond
ONLY with a valid JSON in the following format:
LLooMalgorithmindetail.
{{
"patterns": [
3.1.1 ConceptGeneration. Thekeytoourconceptinductionalgo- {{
rithmistheSynthesizeoperator,whichleveragesthecapability "name": "<PATTERN_NAME_1>"
"prompt": "<PATTERN_PROMPT_1>"
ofLLMstosynthesizehigh-level,conceptualsimilaritiesshared "example_ids": ["<EXAMPLE_ID_1>","<
amongsetsofexamples.Whenchainedtogetherwithotherauxil- EXAMPLE_ID_2>"]
iaryoperatorstoformaDistill‚ÄìCluster‚ÄìSynthesizepipeline, }}
theSynthesizeoperatorallowstheLLooMalgorithmtogenerate {{
"name": "<PATTERN_NAME_2>"
high-levelconcepts(Figure3).
"prompt": "<PATTERN_PROMPT_2>"
"example_ids": ["<EXAMPLE_ID_1>","<
Synthesize. Thisoperatortakesasinputagroupoftextex- EXAMPLE_ID_2>"]
}}
amplesandistaskedwithproducingoneormoreunifying,high- ]
levelconceptsthatconnecttheexamples.Byourdefinition,these }}
high-levelconceptsmustconsistofbothahuman-understandable
descriptionandinclusioncriteria.LLMshavecapabilitiesthatare 2Withintheprompt,weusetheterm‚Äúpattern‚Äùasasynonymfor‚Äúconcept‚Äù;through
experimentation,wefoundthatthistermwasmoreeffectiveforconciselyconveying
well-suitedtoaidthistask.Forexample,GPT-3.5TurboandGPT-4
thattheconceptsneededtobesharedamongmultipleitems,while‚Äúconcept‚Äùisamore
cansuccessfullygeneralizefromasmallnumberofexamples;i.e., generictermthatresultedinlessreliableinstruction-following.CHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA M.S.Lam,J.Teoh,J.A.Landay,J.Heer,M.S.Bernstein
Figure3:ConceptgenerationintheLLooMalgorithm,demonstratedwithsampletextinputs.Theprocessstartswithunstruc-
turedtextdataandanoptionalSeedfromtheanalyst.Then,theDistilloperatorcondensestheinputdatawithanLLMby
filteringtoexcerptsandsummarizingtobulletpoints(gpt-3.5-turbo).TheClusteroperatorpoolsandgroupsthedistilled
bulletpointsusingaclusteringalgorithm.Finally,theSynthesizeoperatorproposeshigh-levelconceptsusinganLLMprompt
(gpt-4).TheLoopoperatorcanoptionallyrepeatthisprocessmultipletimestoproducehigher-levelconcepts.
Notably,thisoperatorstartswheretopicmodelingtypicallyends: I have the following TEXT EXAMPLE:
withdatagroupingsthatarelikelytosharesimilarities.However, {text_example_json}
incontrasttoapproachesthatseektoassignalabeltoclusters,a
Please extract {n_quotes} QUOTES exactly copied from
keydifferentiatorofourSynthesisoperatoristhatitisnotbound
this EXAMPLE {seed_phrase}.
tolabelinganentiregroupofexamples,butframesthetaskaround Please respond ONLY with a valid JSON in the
selectivelyproposingsalientconnectionsamongitemsinagroup. following format:
{{
Ourpromptinstantiatesthisbyaskingthemodeltoidentifysubsets
"relevant_quotes": [ "<QUOTE_1>","<QUOTE_2>",...
ofexamplesthatbestexemplifyconceptsratherthanrequiringthat
]
allexamplesmatchtheconceptandphrasingthetaskaspattern }}
identificationratherthanholisticlabelassignment.Sinceclusters
Then,weperformaSummarizestep,whichpromptsanLLM
areoftennoisy,insteadofattemptingtoholisticallysummarizethe
(gpt-3.5-turbo)togenerateanabstractivesummarizationinthe
cluster,whichcouldleadtoavagueconnection,ourapproachisto
formofbulletpointtextsummaries.Userscanadjustthenumber
identifypocketsofexamplesthathaveunifyingconnections.
ofbulletpointstogenerateandthelengthofthebulletpointsif
Auxiliary operators. The remaining operators of the concept necessary,butweuseadefaultof‚Äú2-4‚Äùbulletpointswithlengths
generationphasearedesignedtoimprovetheperformanceofour of‚Äú5-8‚Äùwords.Weincludeanexamplepromptbelow:
coreSynthesizeoperatorbymitigatingseveralchallengesoflarge
I have the following TEXT EXAMPLE:
languagemodels,suchastokenlimitsandunevenoutputquality. {text_example_json}
Distill.TheDistilloperatorcondensesinputdataintoa
morecompactrepresentationwhilepreservingimportantordistinc- Please summarize the main point of this EXAMPLE {
seed_phrase} into {n_bullets} bullet points,where
tiveattributes,whichbothaddressesLLMcontextwindowlimits
each bullet point is a {n_words} word phrase.
andgrantstheabilityto‚Äúzoom‚Äùintoareasofinteresttoimprove Please respond ONLY with a valid JSON in the
conceptgeneration.InLLooM,wetakeamulti-stepapproachto following format:
implement our Distill operator in natural language. First, we {{
"bullets": [ "<BULLET_1>","<BULLET_2>",... ]
performaFilterstepofzero-shotsummarizationbyprovidingthe
}}
inputtextexampleandpromptinganLLM(gpt-3.5-turbo)to
generateanextractivesummarizationthatselectsexactquotesfrom TheDistilloperatorallowsustoparedowneachexampleto
theoriginaltext;thisstepcanbeomittedifthetextisnotvery itssalientattributesandisinspiredbyinitialline-by-linecodingor
long.Userscanadjustthenumberofquotestoselect,butbydefault opencodinginqualitativeanalysis[8,43].
theparameterisleftemptysuchthatthemodelmayextractany Cluster.Next,theClusteroperatorgroupstogetherrelated
numberofquotes.BelowisanexampleoftheFilterprompt: itemsbasedonpatternsintheirrepresentationsfromtheDistillConceptInduction:AnalyzingUnstructuredTextwithHigh-LevelConceptsUsingLLooM CHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA
step.FortheClusteroperatortogeneratecross-cuttingconcepts, GPT-3.5,multiplechoiceprompting[53,54]canprovideapproxi-
allofthedistilledbulletpointsaredetachedfromtheiroriginal mateanswerprobabilities.Weusemultiplechoicepromptingto
examplesandpooledtogether.Thus,theinputoftheClusteroper- instructthemodeltogenerateamultiple-choiceanswer4foreach
atoristhesetofcondensedbulletpointsfromtheDistilloperator, providedexamplealongwitharationale.Theseanswersareparsed
andtheoutputisasetofgroupassignments,suchthateachisolated andconvertedtobucketednumericalscoreswith‚ÄúStronglyagree‚Äù
bulletpointisassignedtoagroupofrelateditems.TheLLooMal- mappingto1.0and‚ÄúStronglydisagree‚Äùmappingto0.0.Thescores
gorithmtransformsbulletpointsintoembeddingsusingaspecified arethenthresholdedtoabinarylabel;userscanadjustthethresh-
pre-trainedembeddingmodelandthenclusterstheitemsusinga oldatwhichanexampleshouldbeconsideredaconceptmatch.
providedclusteringalgorithm.OurimplementationusesOpenAI‚Äôs Givenùëõexamplesandùëêhigh-levelconcepts,thisphaseresultsina
text-embedding-ada-002modelduetoitsrelativelylongcontext ùëõ√óùëêmatrixwithabinaryconceptlabelforeachexample.
andfastgenerationtime.Forclustering,weselectHDBSCAN,ahi- Thisconceptscoringphaseisdesignedtobringsomeoftheben-
erarchicalclusteringalgorithm,becauseitsdensity-basedapproach efitsofthedeductivecodingprocessinqualitativeanalysis,which
does not require heavy parameter tuning and does not require appliescodesbacktothedata.Thisdeductivecodingprocessboth
allpointstobeplacedinacluster.Thesepropertiesincreasethe allows an analyst to make sense of their data and also exposes
likelihood that our dynamically-generated clusters will contain potentialgaps,biases,orlimitationsintheircodebook,whichcan
salientexampleswithoutmanualintervention.TheClusteroper- beaddressedinfurtheriterationsofinductivecoding.
atorresemblestheinitialphasesofprocesseslikeaffinitygrouping
Loop. Finally,basedontheconceptscoringresults,LLooMcan
andaxialcodinginthatitcoalescesexamplesintopossiblegroup-
ings,whichisacriticalstepbeforetheSynthesizeoperatorcan
useaLoopoperatortoexecutemultipleiterationsofthealgorithm.
Thisoperatorexecutesthelogictorevisetheinputs tothenext
completetheprocesstoidentifysimilaritiesandconceptualthemes.
Seed.WhatiftheanalystwantstosteerLLooM‚Äôsattention iterationofthepipeline.Weusedatacoveragetodeterminewhich
exampleswillbeprocessedineachsubsequentiteration.Afterthe
towardparticularaspectsofthedata?LLooMallowstheanalystto
conceptscoringphasecompletes,theLoopoperatoridentifiestwo
guidethesystemtoattendto‚Äúsocialissues‚Äùforapoliticaldataset,
classesofoutliers:1)not-coveredexamples,whichdidnotmatchany
‚Äúevaluationmethods‚Äùforanacademicpapersdataset,or‚Äúdisplays
ofemotion‚Äùforatextconversationsdataset.TheoptionalSeedop- ofthecurrenthigh-levelconceptsand2)covered-by-genericexam-
eratoracceptsauser-providedseedtermtoconditiontheDistill ples,whichonlymatched‚Äúgeneric‚Äùconcepts,thosethatmatcheda
orSynthesizeoperators,whichcanimprovethequalityandalign- majorityofexamples(atleast50%).Allsuchexamplesareprovided
asinputtothenextiterationofthealgorithm,andtheconcepts
mentoftheoutputconcepts.Thisseedtermprovidesadditional
generatedbysubsequentrunsareaddedtothefullsetofconcepts.
instructionsintheLLMprompttoaskthemodeltoattendtoa
particularaspectofthedata.3FortheDistilloperator,thiswill
3.1.3 ImplementationDetails. TheLLooMalgorithmisimplemented
instructthemodeltogeneratesummariesthatfocusonpartsof asaPythonlibrarythatcanbeimportedintocomputationalnote-
thedatarelatedtotheseedterm.Similarly,fortheSynthesize bookslikeJupyterorwebapplicationframeworkslikeFlask.We
operator,thiswillinstructthemodeltoproposeunifyingconcepts primarilyuseGPT-3.5(gpt-3.5-turbo)foralloperatorsexceptfor
amongtheexamplesthatarerelatedtotheseedterm.Takingin- theSynthesizeoperator,whichbenefitsfromtheimprovedreason-
spirationfromqualitativeanalysis,whichacknowledgesthatthere ingcapabilitiesofGPT-4.FortheDistilloperator,boththeFilter
aremultiplevalidinterpretationsofdata,theSeedoperatorgrants
andSummarizestepsareexecutedwithzero-shotpromptstothe
theanalystcontroltosteertheconceptgenerationprocessbased gpt-3.5-turbomodelusingtheOpenAIAPIwithatemperature
ontheiranalysisgoalsanddesiredinterpretivelens. of0toprovidemoreconsistentresults.FortheClusteroperator,
weuseOpenAIembeddingsfromthetext-embedding-ada-002
3.1.2 ConceptScoring. TheconceptgenerationphasesoftheLLooM
model,andweusetheHDBSCANclusteringalgorithm.Forthe
algorithmarefollowedbyaconceptscoringphasethatappliesthe Synthesizeoperator,weusetheOpenAIAPIwithoptionsforei-
generatedconceptsbacktothefulldataset. thergpt-3.5-turboorgpt-4,againusingatemperatureof0.The
Score. Armedwiththeconcepts,LLooMnextappliesascore
ScoreoperatorprovidesoptionstouseeithertheOpenAIAPIwith
gpt-3.5-turboortheGooglePaLMAPIwiththechat-bison-001
(e.g.,0-1)thatdescribestheassociationbetweeneachinputand
model,bothwithatemperatureof0forconsistency.Asapoint
theconcept.Foreachhigh-levelconcept,thesystemappliesthe
Scoreoperatortoallexamples(inputtexts)togenerateaconcept ofreference,acrossthescenariosthatwedescribein¬ß4,thetotal
costofonerunoftheLLooMalgorithmaveraged$1.44intotalcost,
scorethatestimateshowwelleachexamplematchesthegenerated
used848,323tokens(combininginputandoutput),andtookon
conceptprompt.Thisisimplementedusingabatchedzero-shot
average13.7minutestocomplete.Notably,theconceptscoringstep
promptthatincludesasetofexamplesinJSONformat,theconcept
issubstantiallymorecostlyandtime-intensivethantheconcept
prompt,andinstructionstogenerateananswerinmultiple-choice
generationstep,onaverageconsuming79.9%ofthetotalcostand
format.PriorworkhasfoundthatLLMsdonotprovidecalibrated
58.4%ofthetotaltime.FullpromptsareprovidedinAppendixA.
0-1confidencescoresinzero-shotsettings[38].However,recent
workhasfoundthatforinstruction-tunedOpenAImodelssuchas 3.1.4 AlgorithmLimitations. Wenoteseverallimitationsofthe
currentLLooMalgorithmthatmaybefruitfulareasforfuturework.
3Theseedtermisinsertedastheseed_phraseshownintheexamplepromptsabove 4Ourmultiplechoiceoptionsare:A:Stronglyagree,B:Agree,C:Neitheragreenor
intheformat‚Äúrelatedto{seed_term}.‚Äù disagree,D:Disagree,E:StronglydisagreeCHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA M.S.Lam,J.Teoh,J.A.Landay,J.Heer,M.S.Bernstein
Figure4:TheLLooMWorkbench,aninteractivetextanalysistoolthatleveragesLLooM‚Äôsconceptinductioncapabilities.The
toolconsistsofthe(A)Matrixviewwithanoverviewoftheprevalenceofconceptsamonguser-defineddataslices.Selectinga
conceptrowdisplaystheassociated(B)Conceptdetailview,whichdisplaystheconceptcriteria,subconcepts,andmatching
examples.Selectingaslicecolumndisplaysthecorresponding(C)Slicedetailview,whichdisplaysasimilaroverviewofthe
exampleswithintheslice.
First,theLLooMalgorithmhasanumberofavailableparameters, 3.2 TheLLooMWorkbench
suchasthenumberofquotestoextractandthenumberofbullet WeinstantiatetheLLooMconceptinductionalgorithminanin-
pointstogenerateintheDistillphase.Whiletheseparameters
teractive text analysis tool called the LLooM Workbench. With
areinterpretabletoauser,theyarenotstraightforwardforauser this tool, an analyst can upload their unstructured text dataset,
tosetinadvance,soitwouldbebestforthesystemtodynamically andLLooMwillautomaticallyextractanddisplayconceptsinan
setthesevalueswhenpossible.Oursystemhasdefaultvaluesand interactivevisualization(Figure4).
formulastocalculateparametervalues,butthesehavenotbeen
robustlytestedforappropriatenessonawidevarietyofdatasets. 3.2.1 WorkbenchComponents. TheLLooMWorkbenchallowsan-
Additionally, the current implementation does not make use alyststoseeandinteractwithdataintermsofhigh-levelconcepts.
ofverificationsteps,forexampletoensurethatquotesareexact MatrixView.Conceptthreadsarethefocalpointofthework-
matches,thatbulletpointsareaccuratetoquotes,andthatconcept bench‚Äôsmatrixvisualization(Figure4A).Inthisview,thegenerated
scoresandrationaleappearcorrect.Whilereliableverificationis conceptsaredisplayedasrows,anduser-specifieddataslicesare
anongoingchallengeforLLMs,futureextensionsofLLooMcould displayedascolumns.Bydefault,an‚ÄúAll‚Äùsliceisinitiallyshown
benefitfromprogrammaticchecksandLLMoperatorsexplicitlyde- foralldatasets,butuserscanspecifytheirowncustomslicesby
signedtoverifyoutputsateachphase.OuruseofLLMsalsomeans authoringfiltersonanymetadatacolumnfromtheoriginaldataset
thatthereisvariabilityintheresultsuponre-run.Whilethiscan oranygeneratedconcept.Then,eachcellinthematrixattheinter-
beausefulfeaturetoexploreparallelanalysispathsandsimulate sectionofconceptùëêandsliceùë†displaysacirclewhosesizeindicates
variations,itmaybeundesirableincaseswhereanalysesmustbe theprevalenceofconceptùëê insliceùë†,andcanbenormalizedby
replicableorwhererobust,consistentalignmentisnecessary[14]. thetotalsizeoftheconceptorthetotalsizeoftheslice.Thisvi-
sualizationallowsuserstoperformconsistentcomparisonsofaConceptInduction:AnalyzingUnstructuredTextwithHigh-LevelConceptsUsingLLooM CHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA
particularconcept‚Äôsprevalenceacrossdataslices(withinarow) 4 LLOOMSCENARIOS
orofallconcepts‚Äôprevalencewithinaparticularslice(withina Bysurfacingconceptualthreadsasaninterpretableandmalleable
column).TheusercanselectanyrowtodiveintoaConceptDetail materialwithwhichtoworkwithdata,LLooMopensupnewways
VieworacolumntodiveintoaSliceDetailView. tounderstandandinteractwithtextdata.Inthenextthreesections,
ConceptDetailView.Inthispanel,ausercanbothinspectthe wewalkthroughamulti-partevaluationto:demonstratethecon-
meaningofaselectedconceptandreviewthesubsetofthedataset ceptsthatLLooMsurfacesfromavarietyofreal-worlddatasets(¬ß4:
thatmatchedthisconcept(Figure4B).Theupperleftportionof LLooMScenarios),understandthetechnicalperformanceofthe
thepaneldisplaysaconceptsummarythatincludesthegenerated LLooMalgorithmcomparedtoexistingapproaches(¬ß5:Technical
conceptname,thegeneratedcriteria(whichisexecutedtoeval- Evaluations),andexplorehowexpertanalystsmakesenseofdata
uatewhetherunseenexamplesmatchtheconcept),subconcepts withconceptsintheLLooMWorkbench(¬ß6:ExpertCaseStudies).
thatledtothisconcept,andrepresentativetextexamplesforeach First,todemonstrateLLooM‚Äôsoutputsonreal-worlddatasets
subconcept.Theupperrightsideofthepaneldisplaysahistogram inavarietyofdomains,wepresentfourdataanalysisscenarios:
foramoredetailedviewofconceptprevalenceacrossslices.Fi- developingcontentmoderationpoliciesfortoxiccontent(¬ß4.2),
nally,thebottomsectionofthepaneldisplaysaconceptmatch mitigating partisan animosity on social media (¬ß4.3), analyzing
table,whichdisplaysexamplesthatpotentiallymatchtheconcept academicpaperabstracts(¬ß4.4),andinvestigatinganticipatedcon-
basedonLLooMconceptscores.Theprimarydatasettextcolumn sequencesofAIresearch(¬ßC.1).Thesecaseswereselectedtospan
andconceptscorecolumnaredisplayedbydefault,butuserscan avarietyoftextformatsandlengths(fromshortsocialmediaposts
specifytoincludeanyadditionalcolumnfromtheoriginaldataset. topaperabstracts)andanalysisgoals(fromsurveyingliteratureto
ForcaseswherethealgorithmperformedtheFiltersteptoextract developingadecision-makingpolicyorMLmodel).
relevantquotes,thefilteredtextishighlightedinthetable.
SliceDetailView.Similarly,thispaneldisplaysdetailsofauser- 4.1 Method
defined slice. The upper portion of the panel displays the user-
ThegoalofthescenariosistoqualitativelyillustratehowLLooM
providedslicename(e.g.,‚ÄúLowtoxicity‚Äù)andfilteringcriteria(e.g.,
toxicity < 0.25),alongwithahistogramforamorecompre- worksinpractice.Thus,wecompareagainsttopicmodelsbecause
theyarethedefactostandardinunstructuredtextanalysistoday.
hensiveviewofconceptprevalencefortheslice(Figure4C).The
bottomofthepaneldisplaysaslicesummarytable,whichincludes
4.1.1 Baselineresultgeneration. Weuseastate-of-the-artBERTopic
allexamplesthatmetthefilteringcriteria.Eachrowinthetablerep-
modelasarepresentativebaselinetopicmodel.Foreachscenario,
resentsanexample,andthetabledisplaystheprimarytextcolumn weranBERTopicusingOpenAItext-embedding-ada-002embed-
andallconceptscorecolumnsbydefault;userscanagainspecify dingsandHDBSCANwithaminimumclustersizesetto2‚àí3%
toincludeanyadditionalmetadatacolumnfromthedataset.
ofthefulldatasetsize.Then,wegatheredallresultingtopicsand
theirassociatedkeywords(generatedbyBERTopicusingc-TF-IDF)
3.2.2 WorkbenchActions. Inadditiontothecorevisualizations,
alongwiththedocumentsassignedtoeachtopic.TorunLLooM,
theLLooMWorkbenchsupportsarangeofactionsforanalyststo
weinitiatedanewsessionthatexecutedoneiterationoftheLLooM
buildontheinitialsetofLLooMconcepts.
process. Within LLooM, we randomly sampled up to 200 items
AddingandEditing.Userscanmanuallyaddcustomconceptsby
torunthisprocessandsetalimitofatmost20finalconceptsto
specifyingaconceptnameandanassociatedcriteriapromptthat
generate.Wefocusedondatasamplesofthesesizestoprioritize
definestheconcept.Theconceptwillbeappliedtothedatawith
theScoreoperator,anditwillbeaddedtothematrixvisualization interactiveconceptinductioncompletiontimesrangingfrom5-15
minutesandconceptscoringtimesunder20secondstosupport
asanadditionalrow.Usersmayalsoeditanexistingconceptby
manualconceptauthoring.Fortheseruns,weusedgpt-3.5-turbo
modifyingitsnameand/orcriteriaprompt,andtheycansimilarly
toperformalldistillingandsynthesizingoperations,andweused
initiateconceptrescoringaftermakingthesemodifications.
OpenAItext-embedding-ada-002embeddingsfortheclustering
Merging and Splitting. Users can also merge multiple related
phase.Toassignitemstoconcepts,wegatheredallitemsthatre-
concepts,whichpromptsthesystemtogenerateanewconcept
ceivedapositivelabelforeachconcept,usingathresholdsetatthe
nameandcriteriathatcombinetheselectedconcepts.Conversely,
highestscoreoption(1.0:Stronglyagree).
userscansplitconceptswhentheyaretoogeneral,whichprompts
thesystemtoauthornewsubconceptsfortheselectedconcept. 4.1.2 Baselinequalitativeanalysis. Foreachdataset,amemberof
theresearchteammanuallyreviewedallresults.ForBERTopic,they
3.2.3 ImplementationDetails. TheLLooMWorkbenchisimple-
reviewedeachtopicbyinspectingthegeneratedkeywords(e.g.,‚Äúoil,
mentedasJupyterwidgetforuseincomputationalnotebooks.The
gas,energy,‚Äù‚Äúhouse,republicans,democrats‚Äù)andalldocuments
widgetdrawsontheLLooMalgorithmPythonlibrarydescribed
assignedtothetopic,andtheywrotetheirownmanuallabelto
in¬ß3.1andimplementsalibraryofSvelteUIcomponents.Weuse
synthesize the unifying theme of the topic (e.g., Environmental
theanywidgetPythonlibrary5torendertheSveltecomponentsas
policy,Politicalparties).
notebookwidgets.TheinteractiveLLooMmatrixvisualizationis
Bydesign,LLooMhastheadvantageofgeneratinghighlyspe-
implementedusingtheD3JavaScriptlibrary.6
cificconceptsdescribedinnaturallanguage(e.g.,Userinterfaceen-
hancementandUserexperienceenhancement).However,BERTopic
5https://anywidget.dev outputsareunlikelytocommunicatesuchnuancewithkeywords
6https://d3js.org alone(e.g.,‚Äúuser,users,interaction‚Äù),soitwouldseemunfairtoCHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA M.S.Lam,J.Teoh,J.A.Landay,J.Heer,M.S.Bernstein
Figure5:Forthetoxiccontentdataset,LLooMgeneratescontent-relatedconceptssuchasEmpowermentofwomenandGender
inequality,butalsosurfacesstyle-andtone-relatedconceptssuchasExpressingfrustrationandReflectionandintrospection.
penalizethemethodlargelybecauseitlackssuchexpressivity.Thus, 4.2.1 Results. LLooMgenerated10uniquesetsofconcepts,such
tofacilitateadirectcomparisonwithBERTopicoutputs,wetakea as‚ÄúDevaluationofmen,‚Äù‚ÄúEmpowermentofwomen,‚Äùand‚ÄúGender
conservativeapproachtoestimateoverlapbygroupingtogether inequality anddiscrimination,‚Äù as summarized in Figures 5 and
setsofLLooMconceptsthatwouldbeunreasonableforBERTopicto 6.Meanwhile,BERTopicgenerated8topicswithkeywordssuch
produce.TheresearchteammemberreviewedallLLooMconcepts as‚Äúfeminists,feminism,feminist‚Äùand‚Äúwomen,men,like.‚ÄùBased
andgroupedtogetheranyconceptsthatoverlappedinmeaning: onmanualinspectionoftheBERTopicresults,thesewerefairly
eitherifoneconceptwasasubsetofanotherconcept(e.g.,Advo- high-levelgroupingsalignedwithparticularkeywordssuchasfem-
cacyforPoliciesandAdvocacy),oriftwoconceptsappearedtobe inism,power,andmen/women.Meanwhile,LLooMresultswere
synonymous(e.g.,UserinterfaceenhancementandUserexperience not bound to keywords, but often captured attitudes (e.g., ‚ÄúDe-
enhancement).Usingthissimplifiedsetofresults,BERTopictop- valuationofmen‚Äù)andinterpretations(e.g.,‚ÄúMen‚Äôsperceptionof
icsandLLooMconceptsdeemedashavingsharedmeaningwere unfairtreatment,‚Äù‚ÄúReflectionandintrospection‚Äù)thatwentbeyond
consideredoverlappingresults. surface-levelfeaturesoftext.Weobservedthat50%ofBERTopic
resultswerecoveredbyLLooMwhile40%ofLLooMresultswere
coveredbyBERTopic,sotherewassomedivergencebetweenthe
4.2 Scenario1:DevelopingModerationPolicies twomethods.Inaddition,44.4%ofexampleswereuncategorized
forToxicContent byBERTopic,while9.5%wereuncategorizedbyLLooM,soLLooM
First,weinvestigateacontentmoderationtaskwhereasocialme- achievedhigherdatacoverage.
diaplatformisdevelopingamodeltoperformautomatedcontent
moderationoftextposts.Priorresearchhasfoundsubstantialdis-
agreementamongthepopulationonwhatconstitutestoxiccon-
4.3 Scenario2:MitigatingPartisanAnimosity
tent[23,35],sounstructuredtextanalysismightgrantmoderators
onSocialMedia
greaternuanceinunderstandingandtriagingemergentuserbe-
havior.Weuseadatasetofsocialmediaposts(fromTwitter,Reddit, PoliticalpolarizationisadominantconcernintheUnitedStates,
and4chan)thatgathersadiversesetofannotators‚Äôperspectiveson anditposespotentialexistentialriskstodemocracy.Ifsocialmedia
contenttoxicitywithratingsfrom17,280U.S.surveyparticipants algorithmsplayaroleinamplifyingpartisananimosity[30,42],
onover100,000examples[35].WeappliedBERTopictothefull howmightweredesignsocialmediaalgorithmstomitigatethis
dataset,filteredtothelargestclusters,andselectedthefeminism- effect?Ournextscenarioinvestigatespoliticalsocialmediapoststo
relatedcluster(ùëõ = 496) becauseitalignedwithadistinctuser explorewhetherwecandetectanddownrankcontentthatampli-
communityandpotentiallycontroversialtopics. fiespartisananimosity.WeuseadatasetofpublicFacebookpostsConceptInduction:AnalyzingUnstructuredTextwithHigh-LevelConceptsUsingLLooM CHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA
1.0 1.0
0.9 0.9
0.8 0.8
0.7 0.7
0.6 0.6
0.5 0.5
0.4 0.4
0.3 0.3
0.2 0.2
0.1 0.1
0.0 0.0
fw eo mm ie nin s, t s,m fe en, miw nio sm ma w, n ofe m wemi on,ni ms et wm n oe , n mr, i el gi nk h ,t e s a, t te eq n Bt mu i ea o El nn ,, Rpk sen Tr eo c x o,w e n pt w, r o ieb cm sui a pl t n e T, c t, oa r rg pppeu aaa tl ie y, r, ci ap p re a cr ii hdo , y ,d s eal ca ori ne os my, time Se Ge eki nn d Gg e er-E nbx dap el rs a ie Nn nd
e
a et s gi qt ao ue tirn a vle i Nt eo t y
e
py ga op arn tte irds v a ed y i as al t c tir oi tf uf‚Ä¶ de esmi E t xni o ps rt w es a sr sd is n gw fr G‚Ä¶ u est nr da Cet ri r i to i in cn ie sq mu a o Gl fi t efy ne dm ei r n Si tsts ee rrm ee Foto et yy p mi ip Dn ne e igs v s ta lw e Muo g eatm ai nl 'ie o t sn n a r pio ef a r n c Rm ep ee pe t fln ir es o cp n ti e ooc ft n u a‚Ä¶ n nf dai ir nt tr ro‚Ä¶ Esp m Pe p erc ot ci w eo e pn r tim oO e n u nt Ftl oi f e e o ffr m e inw m iio snim ms e amn na Gd
R
s e
e
nm cpr de oen g' r‚Ä¶ n-s i tbi is a os s n u e oe d f S s fv oi e ciol am lie nn ic mste e i dint a e ill ni vo‚Ä¶ lvement
LLooM Concept
Figure6:Scenario1:Toxiccontentdataset‚ÄîBERTopicplacesalargeproportionofexamples(44.3%)inanuncategorizedcluster
(ingrey)whilemostotherclusterscontainbetween2‚àí10%ofexamples.LLooMconceptsdisplayarangeofprevalencevalues
from1‚àí50%,andtheoutliercategorycontains9.5%ofexamples.
fromJiaetal.[30].Thisdatasetwasgeneratedbyfilteringforpolit- withthesamedatasetofHCIpaperabstracts.Wefiltertothosefrom
icalpostsonCrowdTangleusingpolitics-relatedpagecategories UIST(ùëõ=1733)becausetheCaoetal.[6]paperidentifiedthatUIST
suchas‚Äúpolitics,‚Äù‚Äúpolitician,‚Äù‚Äúpoliticalorganization,‚Äùand‚Äúpolit- papershadanextremelyoutsizedproportionofpatentcitations,
icalparty.‚ÄùThedatasetconsistsof405poststhatwererandomly andwesoughttobetterunderstandthenatureofUISTresearch
sampledandmanuallycodedforpartisananimosity.7 overtimeandpotentialfactorsunderlyingitshighindustryimpact.
Toenablecomparisonsacrosstimeperiods,wegatheredastratified
4.3.1 Results. LLooMgenerated14distinctconcepts,suchas‚ÄúCon-
randomsampleacrosseachdecadefrom1989-1998,1999-2008,and
cernsaboutNationalSecurity,‚Äù‚ÄúPoliticalAffiliationMentioned,‚Äù
2009-2018with70papersfromeachdecadeforatotalsampleof
and‚ÄúAdvocacyforPolicies,‚ÄùsummarizedinFigure7.Meanwhile, ùëõ=210papersforthisexploratoryanalysis.
BERTopicgenerated8topicswithkeywordssuchas‚Äúhouse,repub-
licans,democrats,‚Äù‚Äúcare,vaccine,mandate,‚Äùand‚Äúoil,gas,energy.‚Äù
4.4.1 Results. LLooMgenerated16distinctconcepts,suchas‚ÄúGes-
BERTopicproduceddatagroupingsthatalignedwithmajorentities
tureRecognition,‚Äù‚ÄúVisualizationTechniques,‚Äùand‚ÄúSensorIntegra-
(e.g.,manuallabelsof‚ÄúPoliticalParties‚Äùand‚ÄúCommunity‚Äù)and
tion,‚ÄùshowninFigure8.Meanwhile,BERTopicgenerated12distinct
politicalissues(e.g.,manuallabelsof‚ÄúBorderPolicy‚Äùand‚ÄúEnviron-
topicswithkeywordssuchas‚Äúcontrol,user,haptic,‚Äù‚Äúreality,vr,vir-
mentalPolicy‚Äù).LLooMconceptssimilarlycoveredmanyofthese
tual,‚Äùand‚Äúspeech,audio,multimodal.‚ÄùForthisdataset,BERTopic
sameentitiesandpoliticalissues,butalsocapturedcertainuserbe-
outputsweremorecoherentthanfortheotherscenarios,perhaps
haviorssuchasexpressionsofcondolencesandspecificmentionsof
inpartbecauseacademicabstractsarewrittentoclearlysignaltheir
individuals(suchaspoliticalfigures)intheFacebookposts.LLooM
subjectmatter.Additionally,forthiskindofanalysis,low-levelkey-
alsocapturedseveraladditionalpoliticalissuessuchassocialjustice
andaccesstoaffordableservices.While87.5%ofBERTopicresults wordsaremoreusefulthanistypicalsincemanykeywordsare
precisetechnicalterms(e.g.,‚ÄúVR,‚Äù‚Äúhaptics,‚Äùand‚ÄúmultimodalUIs.‚Äù)
werecoveredbyLLooM,50%ofLLooMresultswerecoveredby
thataregenerallyusedinastandard,narrowsense.Meanwhile,the
BERTopic,sotherewasasizeableportionofLLooMconceptsthat
werenoveladditions.Here,26.2%ofexampleswereuncategorized LLooMconceptsalignedquitestronglywiththeBERTopictopics,
byBERTopicwhile2.5%wereuncategorizedbyLLooM. butareasofnon-overlapappearedtosurfaceseveraluniquecon-
cepts.Whilemostoutputswerealignedwithrecognizableresearch
4.4 Scenario3:AnalyzingUISTPaperAbstracts topics,theconceptsof‚ÄúPerformanceimprovement,‚Äù‚ÄúPrototypeSys-
tems,‚Äùand‚ÄúMathematicalFrameworks‚Äùappearedtocharacterize
Arecentlarge-scaleliteraturereviewinvestigatedtheimpactof
aspectsoftheworklikethehigher-levelmethodsandevaluation
HCIresearchonindustrybyanalyzingpatentcitations[6].This
strategiesandallraisedinterestingquestionsaboutthecommon
priorworkusedLDAtopicstodescribetrendsamongresearch
evaluationmetricsandimplementationapproachesusedatUIST
thatinfluencedpatents.WeexplorewhetherLLooMcouldhelpto
comparedtootherHCIvenues.Bycontrast,thenon-overlapping
characterizeresearchfromthepast30yearsatmajorHCIvenues
BERTopictopicsappearedtobeadditionalresearchtopicareas,but
notnewkindsoftopics.While83.3%ofBERTopicresultswerecov-
7Thescoresconsistof8sub-scoresthataresummedtogether.Eachsub-scorecan
eredbyLLooM,62.5%ofLLooMresultswerecoveredbyBERTopic,
rangefrom1-3,sothescorerangeisfrom8to24,where8correspondstothelowest
partisananimosityand24correspondstothehighestpartisananimosity. so LLooM achieved somewhat higher coverage. Here, 18.6% of
ecnelaverP ecnelaverPCHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA M.S.Lam,J.Teoh,J.A.Landay,J.Heer,M.S.Bernstein
1.0 1.0
0.9 0.9
0.8 0.8
0.7 0.7
0.6 0.6
0.5 0.5
0.4 0.4
0.3 0.3
0.2 0.2
0.1 0.1
0.0 0.0
house,
n re epw, u blw io cr ak b, n os rc , dar d ere e , m bio d dc er ana y,t , s s p ro o elu i pt ,c h e c,e r ohn no gl ro ec sa su mst an o, i l c,g or g ne a ga rt s,
a
te uln ae k ti ir n og gy n, s, cg l ao e rd a, e ,d d e vr r as ch ci ip n, e, ‚Ä¶ mandate Policy-re Pl oa lt ite iA cd d alv o Cc oac Smy pm ee cin fit ca ry Men Ati Gdo v ovn os c era ncE y m v f ee o nrn t t - PrP oeo lll ii ta itci cee ald Cs t oPh mae rt mm y u e nPs it Go y os i vt Ei eSno rogn ncs a i mg a ele j Pntm u
o
lise a tt iin nt cc d ae l
A
c f co Ao cfc em filu sims sa tu tin ooi t n y A ffM o‚Ä¶ e rn d Pti a uo b bl ln Giee c
o
d vS H ee rer nv ai ltc mhe e s nC t o An cc ce or Iun nn Cst ti oa t nb ui ctl ii et o ry n na sl O I aut nl bi v oe or ul t ve Nam tie on Et n Cna ol e nr EgS g xrye
p
e rsS‚Ä¶ eso i sl sou it ni oao nl n s s M ofe et Ci on ng ds olences
BERTopic Topic LLooM Concept
Figure7:Scenario2:Partisananimositydataset‚ÄîThelargesttopicfromBERTopicisagainanuncategorizedtopicwith26.2%
ofexamples.AsetofsevenLLooMconceptscapturedmoregeneric,high-prevalencepoliticaltopics,butthereisarangeof
conceptprevalencevalues,andonly2.5%ofexampleswereoutliers.
1.0 1.0
0.9 0.9
0.8 0.8
0.7 0.7
0.6 0.6
0.5 0.5
0.4 0.4
0.3 0.3
0.2 0.2
0.1 0.1
0.0 0.0
web, uu ss ere ,r , ui snt erer sf , a ic nte te or ioa l nc st p,i uo t3 ,n d, p op i ca n st op i pne n tr erg, eo l c,fi d h in ,u s g s pa le e ur ar, d y i , h o, sa ppt m hi iu ec l nrt fii c orm alo , m d r ata e il s oo nl , u v bit s ri dp ao i iern no ,a ,l , r bc o oo u dl t yo ,e r , como mti mo bru ln ieni nac l di ,ta t yi , p o evn r o, plvi er ,t u a ul ial g sto ,r it arh t, m ps anelists User Exper Ui se en rc Ie ntE ern fh aa c Vin e s c Aue pE a pn l lm i ihe z can a at tn ti ic o oe n n m T oe fe n ct prh Gon ri t Paq o et pu ny -he lip is c ke a els iy V nis Pt ps euu rt‚Ä¶ f al oi a rz na mdt i i ao n ntn ce er Iac mti p So r en o nv se orm Ie nn tt eg Vra Rt i PEo v hn yal siu ca Gt ai el o stn WM u ero bed el BRi ren ocg wo sg i Cn ni ot gi mo P pn r oot no et ny t-p Vbe i Aa d ds e ve o a d nN cU aI evi Mmg aea tt ni hto s e n i mn aIO tiu Hcmtl ai aa l p e g tfir irn ca g FmT eee ew d‚Ä¶ o br ak cf ko r Te W‚Ä¶ c e Mh b a ni cAq hc iu c A ne e u e s dis Li o e bi al Pi rrt noy ic ne g s Asi pn plg ications
BERTopic Topic
LLooM Concept
Figure8:Scenario3:HCIUISTpapersdataset‚ÄîBERTopicagainplacesasizeableportionofexamplesintoanuncategorizedset
with18.6%ofexamples.LLooMconceptsdisplayalongtaildistributionwithafewhigh-frequencyuserinterfaceconceptsand
alongersetofmorenuancedconcepts;6.7%ofexampleswereoutliers.
exampleswereuncategorizedbyBERTopicwhile6.7%wereuncat- However,wenotethatabenefitofLLooM‚Äôsgeneratedconcept
egorizedbyLLooM. criteriaisthatevenifconceptsareinducedfromasmallerdata
sample,theycanbeappliedtoamuchlargersettoassessconcept
generalizabilityandcoverage.
4.5 ScenarioLimitations
Wedonothavemanualannotationsforthescenariodatasets
Wenoteseverallimitationsoftheseanalysisscenarios.First,to on‚Äúgroundtruth‚Äùconcepts,sowecannotreportonglobalcover-
provideafairercomparisonbetweenLLooMandBERTopic,weonly ageofLLooMconceptsnortheiralignmentwithmanualanalysts‚Äô
conductedoneiterationoftheLLooMalgorithm.Then,because generatedconcepts.Weperformagroundtruthconceptcoverage
weprioritizedinteractivecompletiontimesforourscenarios,we analysisinthenextsection,¬ß5,withannotateddatasets.Finally,
sampledapproximately200examplestousewithinLLooMforeach whilethescenarioswereselectedtospanavarietyoftopicareas,
scenario,butsomeofthedatasetsweremuchlarger.Thus,there datasetsizes,andanalysisgoals,LLooMresultsmaydifferwhen
arerisksthatLLooMwasnotfullyrepresentativeofthedataand appliedtootherkindsofdatasets.
thatitsconceptscoulddifferifrunonasignificantlylargerdataset.
ecnelaverP
ecnelaverP ecnelaverP
ecnelaverPConceptInduction:AnalyzingUnstructuredTextwithHigh-LevelConceptsUsingLLooM CHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA
5 TECHNICALEVALUATIONS Benchmark Dataset Results
Next,weperformtechnicalevaluationstocompareLLooMcon- Bills Wiki
ceptgenerationagainsthumanannotationsandstate-of-the-art 1.0
methodsforunstructuredtextanalysis.Weinvestigatehowwell
0.8
LLooMcangenerateconceptsthatrecovergroundtruthconcepts
intwoevaluationsusing(1)real-worldbenchmarkdatasetsdrawn
0.6
fromWikipediaarticlesandU.S.Congressionalbills(¬ß5.1)and(2)a
syntheticdatasetforgreaterexperimentalcontrol(¬ß5.2).Asinthe
0.4
LLooMscenarios,weincludeaBERTopicbaselineasastate-of-the-
arttopicmodelingmethod.Sincethisevaluationisperformance- 0.2
oriented,weaddGPT-4andGPT-4Turbobaselinestounderstand
howLLooMperformsrelativetobaseLLMs. 0.0
5.1 ConceptGeneration:BenchmarkDataset
BERTopic GP PT T- -4 4-turbo LLooM BERTopic GP PT T- -4 4-turbo LLooM
G G
First,weevaluateLLooMconceptgenerationonreal-worlddatasets
drawnfrompriorworkintopicmodeling[48]thathaveunstruc-
Figure 9: On the real-world benchmark datasets, LLooM
turedtextdocumentsandhumantopicannotations:aWikipedia
exceeds baseline performance for the likely-unseen Bills
articles dataset [41] and a U.S. Congressional bills dataset [29].
dataset and matches GPT-4 baseline performance for the
Theseannotationsareexplicitlydefinedastopics,whichtendto possibly-seenWikidataset,achievingcoverageratesof0.74
alignwithmoregenericconceptsandmaynotfullycapturethe and0.81ontherespectivedatasets.
setofconceptsthatLLooMcangenerate.However,thetopicanno-
tationsprovideahelpfulpointofcomparisonwithexistingtopic
modelingmethods. LLooMClusterandSynthesizeoperatorstoaccommodatethe
longerdocumentsofourbenchmarkdatasets.Weaddbaselinesthat
5.1.1 Metric. The goal of concept induction with LLooM is to
directlyqueryGPT-4andGPT-4Turbowithzero-shotprompts.For
reliablysurfaceinformative,validconceptsfromunstructuredtext.
thesebaselines,weusethesamepromptthatunderliestheLLooM
Thus,weassessthevalidityandcomprehensivenessofLLooM‚Äôs
Synthesizeoperator,butinsteadprovidethefulldocumenttext
conceptsbymeasuringhowwelltheyrecovergroundtruthtopics,
insteadofthedistilledandclusteredtextexcerpts.SinceGPT-4has
whicharegeneratedbyhumanannotatorsandknowntooccurin
alimitedcontextwindow,werandomlysampledocumentstofill
agivendataset.Weuseametricofconceptcoveragetoassesshow
thecontextwindow;alldocumentsfitintothelargerGPT-4Turbo
wellLLooMandbaselinemethodsrecovergroundtruthconcepts
contextwindow.
fromahuman-annotateddataset,whetherthatbeabenchmark
datasetorthesyntheticdatasetwedescribein¬ß5.2. 5.1.3 Datasets. TheWikipediaarticlesdataset(Wiki)consistsof
Foreachmethodanddataset,werun10independenttrialsofcon- 14,290articlesandhumanannotationsfor15Generictopics,such
ceptgenerationforatotalof80trials.Eachtrialrandomlyshuffles as‚ÄúArtandarchitecture‚Äùand‚ÄúLanguageandliterature‚Äù.TheCon-
thedatasetdocuments,usesnewsessionsforcallstotheOpenAI gressionalBillsdataset(Bills)consistsof32,661billsummaries
API for LLooM and the GPT-4 variants, and trains a new topic andhumanannotationsfor28Generictopics,suchas‚ÄúEducation,‚Äù
modelforBERTopic.Foreverytrial,wedeterminecoverage,the ‚ÄúEnvironment,‚Äùand‚ÄúHealth‚Äù.Weuserandomsamplesofdataset
proportionofgroundtruthtopicsthatarecoveredbythegenerated documents(n=205andn=213,respectively)stratifiedacrosstop-
concepts.WecalculateautomatedcoveragemetricsusingGPT-3.5 ics,toaccommodatecontextwindowlimitsfortheGPT-4baseline.
(gpt-3.5-turbo).Ourfew-shotpromptprovidesthegroundtruth
Adownsideofusingpublicly-availableannotateddatasetsisthat
andgeneratedconceptsandasksmodeltomatcheachgroundtruth theymayhaveappearedintheGPTpre-trainingcorpus,which
conceptwithatmostonegeneratedconceptifitsmeaningmatches inpartmotivatesoursyntheticdatasetevaluation.Aspriorwork
thegroundtruthconcept(AppendixA.5).Toverifythisautomated hasnoted,text-to-labelmappingsfortheWikidatasetmayhave
coveragemetric,werandomlysampletheresultsof16trials(4from appearedinthepre-trainingdata[48],sothisdatasetmaypresent
eachconceptgenerationmethod)andmanuallymatchallground inflatedestimatesfortheGPT-4baselines.Meanwhile,theBills
truthandgeneratedconceptsforeachtrial.Treatingthemanual datasetmayprovideamorerealisticperformanceestimate:thedata
coverageasgroundtruth,weobserveameanabsoluteerror(MAE) islesslikelytohaveappearedintheGPT-4trainingdatasincethe
of0.07(i.e.,anaveragecasemayhaveamanualcoverageof40% billsummarytextsandlabelsarestoredseparately.TheLLooM
andanautomatedcoverageof33%). algorithmsubstantiallytransformstextspansbeforeperforming
conceptgeneration,soitlikelydoesnot‚Äúbenefit‚Äùasgreatlyfrom
5.1.2 Method. We evaluated four concept generation methods:
GPT-4‚ÄôspotentialknowledgeoftheWikidataset.
LLooM, BERTopic, GPT-4, and GPT-4 Turbo. We use the same
LLooMprocessandBERTopicsetupdescribedin¬ß4,butforparity 5.1.4 Results. LLooMexceedsbaselinecoverageby17.9%onthe
withourGPT-4baselines,weuseGPT-4fortheSynthesizeoper- Bills dataset (LLooM: ùëÄ = 0.74, GPT-4 Turbo: ùëÄ = 0.56) and
ator;wecontinuetouseGPT-3.5fortheDistilloperatorsteps. matchesGPT-4baselinesontheWikidataset(LLooM:ùëÄ =0.81,
Additionally,weincreasetheinputandoutputbatchsizesofthe GPT-4:ùëÄ = 0.83,GPT-4Turbo:ùëÄ = 0.82),asshowninFigure9.
egarevoCCHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA M.S.Lam,J.Teoh,J.A.Landay,J.Heer,M.S.Bernstein
SupportingournoteontheWikidataset‚Äôspossibleinclusioninthe datasets grant us experimental control to independently study
GPTpre-trainingdata,GPT-4andGPT-4Turbodisplaysubstantially howperformanceisimpactedbyfactorslikedocumentlengthand
higher coverage on the Wiki dataset than the Bills dataset; the within-documentconceptprevalence,whileholdingconstantthe
Wikiperformancemetricsmaybeinflatedduetomemorization setofgroundtruthconceptsandtheiracross-documentprevalence.
oftext-to-labelmappings.Thus,itispromisingthatontheBills Additionally,sinceweconstructthesedatasets,wecanguarantee
dataset,LLooMmaintainsrelativelyconsistenthighcoverage(only thatthesemappingsoftextstogroundtruthlabelsdonotoccurin
dropping8.7%),whileGPT-4Turbocoveragedrops25.6%.Inline theGPT-4pre-trainingdata.
withourLLooMscenarios,BERTopicdisplayssubstantiallylower
conceptcoverageforbothdatasets(Bills:ùëÄ =0.29,Wiki:ùëÄ =0.63) 5.2.1 Datasetgeneration. Oursyntheticdatasetisgeneratedfroma
seedsetofgroundtruthGenericandSpecificconceptsthatareheld
comparedtotheGPT-4baselinesandLLooM.
consistent,whilewevarydocumentlengthandwithin-document
Wefurtherinvestigatethesefindingsusingalinearmodelwith
afixedeffectofmethod:coverage ~ 1 + method.Weuseasep- conceptprevalence.
Parameters.First,wevarydocumentlengthsinceunstructured
aratemodelforeachdataset.FortheBillsdataset,weobservea
significantmaineffectofmethod(ùêπ(3,36) = 22.36,ùëù < .001).A textcanvarysignificantlyinlengthdependingonthedomain(e.g.,
socialmediapostsversusacademicpapers).Additionally,largelan-
posthocpairwiseTukeytestfindsstatisticallysignificantdiffer-
guagemodelslikeGPT-4havelimitedcontextwindowsanddisplay
encesincoveragebetweenallpairsofmethodsexceptforGPT-4
vs.GPT-4Turbo(ùëù = 0.997forGPT-4vs.GPT-4Turbo,ùëù < .02 unevenperformanceacrossthecontextwindow[39].Wetestdocu-
forGPT-4Turbovs.LLooM,ùëù < .01forallotherpairs).Forthe mentlengthsof5or10sentences;thisapproximatelymatchesthe
rangeofdocumentlengthsinourLLooMscenarios(meanlengths
Wikidataset,wealsoobserveasignificantmaineffectofmethod
(ùêπ(3,36)=3.568,ùëù <.05).AposthocpairwiseTukeytestonlyfinds of2to8sentences).Then,whetherconceptscompriseasmallor
astatisticallysignificant(ùëù <.05)differenceincoveragebetween largeportionofadocument,westillwantLLooMtorecoverthem
sinceanalystsareinterestedinbothsubtleandobviousconcepts.
BERTopicandGPT-4;therewasnosignificantdifferencebetween
Thus,wevarywithin-documentconceptprevalence,operationalized
anyotherpairsofmethods.
asthepercentageofsentencesinthedocumentrelatedtoapro-
Wequalitativelycomparedthegeneratedtopicsbyinspectingall
videdseedconcept.Wetestconceptprevalencevaluesof20%or
outputsforeachmethodthatmatchedagivengroundtruthtopic
40%.Finally,conceptsarenotmonolithic:someconceptsarelower-
(Tables17and18).BERTopictopicsweregenerallymorevague
level,specificideasexplicitlydiscussedinadocument,whileothers
(e.g.,‚Äúalbum,band,music‚ÄùforagroundtruthWikimusictopicor
arehigher-level,moregenericthemesthatemergefrommultiple
‚Äúgame,series,fantasy‚ÄùforaWikivideogamestopic).GPT-4and
lower-levelconcepts,andwewantourmethodtocaptureboth.
GPT-4Turbotopicsoftencloselymatchedgroundtruthtopics(e.g.,
WhileGenericconceptsareusefulincontextsliketextclustering
‚ÄúVideoGames‚ÄùforaWikivideogamestopicand‚ÄúTransportation
tosurfaceoverarchingpatterns,Specificconceptsareusefulincon-
Policy‚ÄùforaBillstransportationtopic),butGPT-4displayedfailure
textslikediscourseanalysisandcancharacterizenuancedpatterns
modesofcombiningmultiplegroundtruthtopicsinasingletopic
thatinformtheory-drivenanalysis.Thus,ourdatasetinstantiates
(e.g.,‚ÄúArtisticWorks,‚ÄùwhichhadadefinitionthatmappedtoWiki
bothGenericandSpecificgroundtruthconcepts.
music orartandarchitecturetopics)whileGPT-4Turbodidnot
Generationprocedure.Foroursyntheticdataset,wechoseanover-
displaythisfailuremode.LLooMproducedtopicsthatmatched
all‚Äúpolitics‚Äùtopictoalignwithpolitics-relateddatasetsfromour
closelywithgroundtruthtopics(e.g.,‚ÄúEducationalPolicies‚Äùfora
benchmarkdatasetevaluation(Billsdataset)andanalysisscenarios
Billseducationtopic),butitalsogeneratedtopicsthathighlighted
(PartisanAnimositydataset).Wemanuallycreatedahierarchyof
othernotableaspectsofcontentwithinatopicarea(e.g.,‚ÄúCommu-
tenGenericconcepts(e.g.,‚ÄúHealthcare‚Äù),eachofwhichhasfour
nityDevelopment:Doesthetextdiscusspromotingeducationfor
constituentSpecificconcepts(e.g.,‚ÄúMentalhealth,‚Äù‚ÄúHealthinsur-
communitydevelopment?‚ÄùforthesameBillseducationtopic).For
ance‚Äù),alllistedinAppendixC.4.
example,inagroundtruthWikivideogamestopic,LLooMgener-
Foreachuniquecombinationofdocumentlengthandconcept
atedconceptslike‚ÄúVideoGameDiscussion,‚Äù‚ÄúGameSetting,‚Äùand
prevalence,wegenerated40documentsusingGPT-4.Eachdocu-
‚ÄúCharacterDesign,‚ÄùandinaWikimusictopic,LLooMgenerated
mentwasgeneratedbyselectingoneofthe40Specificconcepts,
conceptslike‚ÄúBandFormation‚Äùand‚ÄúMusician‚ÄôsCareer.‚Äù
promptingthemodeltogenerateadocumentof doc_lengthsen-
Overall,LLooMmaintainshighconceptcoverageonbothdatasets
tences about the overall ‚Äúpolitics‚Äù topic, and requesting a fixed
andprovidessubstantialcoveragebenefitsoverbaselinesonthe
Billsdataset(ùëù <0.02).GPT-4Turboisthenearestcompetitoron numberofsentencesrelatedtotheselectedSpecificconceptbased
onconcept_prevalence(seesamplegenerationsinFigure10).
coveragemetrics,butLLooMprovidestheaddedbenefitofcon-
ceptsthatextendbeyondmatchinggroundtruthlabelstodescribe Write a {doc_length}-sentence paragraph about
'politics'.
uniquecharacteristicsofdatawithinagroundtruthtopic.
In {concept_prevalence * doc_length} sentences of the
paragraph,include content related to a SEED TOPIC '{
low_level_concept}'.
5.2 ConceptGeneration:SyntheticDataset
Please only return a JSON with this format:
{{
AfterdemonstratingLLooM‚Äôsperformanceonreal-worlddatasets,
"paragraph": "<PARAGRAPH>"
wefurtherprobeitsperformanceinacontrolledsetting.Oursyn-
"seed_topic_sentences": "<The sentences from
theticdatasetevaluationassesseshowLLooMperformswhenwe PARAGRAPH related to SEED TOPIC>"
varythedocumentsandconceptscontainedinacorpus.Synthetic }}ConceptInduction:AnalyzingUnstructuredTextwithHigh-LevelConceptsUsingLLooM CHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA
Figure10:Samplesyntheticdatasetdocuments.Wegenerateddocumentsforcombinationsofdocumentlength,concept
prevalence,andseedtopic.Theboldedportionindicatestheseedconceptsentences.
Synthetic Dataset Results 5.2.3 Results. Overall, we observe that LLooM achieves 16.0%
Generic concepts Specific concepts highercoveragethanthenearestbaselinesonSpecificconcepts
1.0 (LLooM:ùëÄ =0.71,GPT-4Turbo:ùëÄ =0.55)andmatchesorexceeds
baselinesonGenericconcepts(LLooM:ùëÄ = 0.98,GPT-4Turbo:
0.8 ùëÄ = 0.98,GPT-4:ùëÄ = 0.69,BERTopic:ùëÄ = 0.46),asshownin
Figure11.Thesetrendsarestableacrossdocumentlengthsand
0.6
conceptprevalencelevels(Figure12)andareconsistentwithour
benchmarkdatasetfindings,whichhavegroundtruthtopicssimilar
0.4
informtoGenericconcepts.Notably,LLooMespeciallyappearsto
0.2 providebenefitforSpecificconceptsandmaintainshighcoverage
whilebaselinemethodssubstantiallydeclineincoverage.
0.0 Weanalyzetheseresultsusingalinearmodelwithfixedeffectsof
BERTopic GP PT T- -4 4-turbo LLooM BERTopic GP PT T- -4 4-turbo LLooM m mee tt hh oo dd,d +oc du om c_e ln et nle gn tg hth +,a cn od nc co en pc te _p pt rp er vev aa ll ee nn cc ee: .c Wo eve ur sa eg se ep~ ar1 ate+
G G modelsforGenericconceptcoverageandSpecificconceptcoverage.
ForSpecificconcepts,weobserveasignificantmaineffectofmethod
Figure11:Onthesyntheticdatasets,LLooMexceedsbaselines (ùêπ(3,154) = 227.4,ùëù < .0001), concept prevalence (ùêπ(1,154) =
onSpecificconceptcoverage(0.71)andexceedsormatches 22.0,ùëù <.0001),anddocumentlength(ùêπ(1,154)=5.8,ùëù <.05).A
baselinesonGenericconceptcoverage(0.98).
posthocpairwiseTukeytestfindsstatisticallysignificantdifferences
incoveragebetweenallpairsofmethods(ùëù <.0001),statistically
significant differences between concept prevalence levels (ùëù <
ThisapproachallowedustoexplicitlyincludeSpecificconcepts 0.0001),andstatisticallysignificantdifferencesbetweendocument
inthetextwhileimplicitlyinvokingGenericconceptsasthemes lengths(ùëù < 0.05).Inotherwords,Specificconceptcoverageis
thatunifymultipleSpecificconcepts. highestforLLooM,thenGPT-4Turbo,thenGPT-4,thenBERTopic,
Verification.Duringthegenerationprocess,weprogrammati- andSpecificconceptcoverageishigherforlongerdocumentsand
callyverifiedthatthetotalnumberofsentencesinthedocuments thosewithhigherconceptprevalence.ForGenericconcepts,we
matchedtherequestedlengthandthatthenumberofseedconcept observeasignificantmaineffectofmethod(ùêπ(3,154)=115.03,ùëù <
sentencesalignedwiththerequestedconceptprevalence.Were- .0001).AposthocpairwiseTukeytestfindsastatisticallysignificant
viewedalldocumentsandmanuallyverifiedthattheseedconcept (ùëù < .0001)differenceincoveragebetweenallpairsofmethods
sentencessufficientlyconveyedthespecifiedconcept. exceptforGPT-4Turbovs.LLooM.Genericconceptcoverageis
significantlyhigherforLLooMcomparedtoGPT-4andBERTopic,
5.2.2 Method. Weexperimentedwiththesamefourmethods‚Äî
butnotsignificantlydifferentfromGPT-4Turbo.
LLooM,BERTopic,GPT-4,andGPT-4Turbo‚Äîusingthesamepro-
Weagaincomparetheconceptsgeneratedbyeachmethodthat
cedureasthebenchmarkdatasetevaluation(Section5.1).Foreach
successfully matched ground truth concepts (Table 19). Again,
combinationofdocumentlengthandconceptprevalence,weevalu-
BERTopicproducesthemostvagueoutputs(e.g.,‚Äúfiscal,economic,
atedeachmethodonthecorrespondingsetofsyntheticdocuments
withùëõ = 10independenttrials.Weagaincalculatedautomated hoping‚Äùforaneconomyconcept)thataresupersetsofSpecificcon-
cepts.Consistentwiththebenchmarkdatasets,GPT-4andGPT-4
coveragemetricsusingGPT-3.5.Wecomputedcoverageforboth
TurboproduceconceptsthattendtoaligncloselywithGeneric
GenericandSpecificgroundtruthconcepts.
egarevoCCHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA M.S.Lam,J.Teoh,J.A.Landay,J.Heer,M.S.Bernstein
Generic concepts Specific concepts
5 sentences 10 sentences 5 sentences 10 sentences
1.0 1.0
0.8 0.8
0.6 0.6
0.4 0.4
0.2 0.2
0.0 0.0
1.0 1.0
0.8 0.8
0.6 0.6
0.4 0.4
0.2 0.2
0.0 0.0
BERTopic G GP PT T- -4 4-turbo LLooM BERTopic G GP PT T- -4 4-turbo LLooM BERTopic G GP PT T- -4 4-turbo LLooM BERTopic G GP PT T- -4 4-turbo LLooM
Figure12:Syntheticdatasetresultsbydocumentparameters.Acrossdocumentlengthsandconceptprevalencelevels,LLooM
achievessubstantiallyhigherSpecificconceptcoverageandmatchesorexceedsGenericconceptcoveragecomparedtobaselines.
concepts(e.g.‚ÄúHealthcarePolicy‚Äùforahealthcareconcept).GPT-4 6 EXPERTCASESTUDIES
againdisplaysanoccasionalfailuremodeofcombiningmultiple BuildingonouranalysisscenariosthatshowcaseLLooM‚Äôsconcepts
groundtruthconcepts(e.g.,‚ÄúPoliticalInfluence,‚Äùwhichwasde- andourtechnicalevaluationthatsupportsthevalidityandcoverage
finedinsuchawaythatcouldmaptoeconomyorforeignpolicy), oftheseconcepts,weexplorehowLLooMmightaidrealisticdata
butGPT-4Turbodoesnotappeartofacethisissue.Meanwhile, analysistasksthatgobeyondthestandalonetaskofconceptgen-
LLooMproducesconceptsthatmatchbothGenericaswellasSpe- eration.Wecarryoutfirst-usesessionswithexpertdataanalysts
cificgroundtruthconcepts,aswesawforthebenchmarkdataset. whohaveauthoredpublicationsontwoofourscenariodatasets:
Forexample,LLooMproduces‚ÄúEconomicPolicies‚Äùforaneconomy (1)MitigatingPartisanAnimosityonSocialMediaand(2)Ana-
concept,butitalsoproducesconceptslike‚ÄúFiscalMeasures‚Äùand lyzingtheIndustryImpactofHCI.Thesesessionsareintendedas
‚ÄúEconomicStability‚Äùthataremorespecificandnuancedportrayals exploratoryprobestodemonstratehowdataanalystsinteractwith
ofdatawithintheeconomyconcept. LLooMconceptstomakesenseoftheirowndata.Whilethegoal
Insummary,LLooMperformsstronglyacrossalldatasets,andit oftheLLooMscenariosandtechnicalevaluationwastovalidate
particularlyexcelsrelativetobaselinemethodsforSpecificconcepts LLooMoutputs,thegoaloftheexpertcasestudieswastosurface
(ùëù < .0001),wherebaselineperformancesuffers.LLooM,GPT-4,
designopportunitiesfortheLLooManalysisexperiencebyhigh-
andGPT-4TurboproducecompetentGenericconcepts,butLLooM lightingpreliminarydifferencesfromstatusquodataanalysistools.
isadditionallyabletorecoverSpecificconceptsinthedataset. Wefocusedonasmallnumberofexperiencedanalystsbecausethey
areadiscerningandcriticalaudiencewhomayalreadyholdstrong
understandingofadataset,sotheycanprovideexpertfeedbackon
theutilityofLLooMoutputsfordataanalysis.
Detailsonparticipantrecruitmentandsessionformatarein-
5.3 ConceptClassification cludedinAppendixB.1.Asabriefsummary,eachstudyconsisted
ofa1-hoursessionthatincludedaBERTopicanalysistask,aLLooM
WethenevaluateLLooM‚ÄôsScoreoperatoragainsthumanannota-
Workbenchanalysistask,andaconcludinginterview.Duringthe
tors(AppendixC.2).LLooMattainsinter-raterreliability(ùúÖ =0.63,
session,participantsengagedinathink-aloudprotocolastheycon-
ùúÖ = 0.645)verysimilartothatofhumanannotators(ùúÖ = 0.64)
ductedexploratorydataanalysisofthesamedatasetthattheyhad
andachievesmoderatetohighperformancelevels(Accuracy:0.91,
analyzedforapriorpublication.
Precision:0.70)onsubjectiveconceptsgeneratedfromourLLooM
scenariodatasets.
ecnelaverp
tpecnoc
%02
ecnelaverp
tpecnoc
%04
egarevoC
egarevoC
ecnelaverp
tpecnoc
%02
ecnelaverp
tpecnoc
%04
egarevoC
egarevoCConceptInduction:AnalyzingUnstructuredTextwithHigh-LevelConceptsUsingLLooM CHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA
Dataset: Partisan Animosity Dataset: UIST Abstracts
Helpful Interpretable Unique Helpful Interpretable Unique
100% 100%
80% 80%
60% 60%
40% 40%
20% 20%
0% 0%
ERTopic LLooM ERTopic LLooM ERTopic LLooM ERTopic LLooM ERTopic LLooM ERTopic LLooM
B B B B B B
Figure13:ExpertAnalystAssessmentsofConceptQuality.Expertsfamiliarwiththesedatasetsconsistentlyratedahigher
proportionofLLooMconceptsashelpful,interpretable,andunique(non-overlapping).
6.1 Expert1:MitigatingPartisanAnimosityon theoriginalconcept named‚ÄúCrisis‚Äùwiththecriteria,‚ÄúDoesthis
SocialMedia examplementioncrisisduetoapolicy?‚ÄùInafewseconds,they
werepleasedtoseethattheyhadsuccessfullyidentifiedasalient
Inthefirstsession,theLLooMWorkbenchhelpedtheexpertan-
clusterofpoststhatcarriedhighpartisananimosityscores.
alysttoidentifypreviously-unnoticedtrendsandactivatedrele-
Activatingrelevantdomainknowledge.Promptedbythisexplo-
vantdomainknowledgetoinspiretheory-drivenanalyses.Forthe
BERTopictopics,theanalystlabeled5ashelpful(62.5%),oneas ration,theanalystwasremindedoftheirdomainknowledgeon
uninterpretable(12.5%),andoneasoverlappingwithanothertopic anti-democraticattitudesinpoliticalscienceliterature[59],which
(12.5%),asshowninFigure13.ForLLooMconcepts,theanalyst includedsocialdistrust.Theycreatedanewconceptnamed‚ÄúSocial
Distrust‚Äùwiththecriteria,‚ÄúDoesthisexampledisplaydistrustof
labeled18ashelpful(90%),noneasuninterpretable(0%),andone
otherpeopleorsociety?‚ÄùTheanalystfoundthattheseexamples
asoverlappingwithanotherconcept(5%).
receivedmid-to-highpartisananimosityscores,butdidnotfallin
6.1.1 BERTopicAnalysisProcess‚ÄîMakingsenseofvagueandover- thehighestbucketofscores,soperhapsthatfactorwaslesspredic-
lappingtopics. Theanalystreviewedtopickeywords(e.g.,‚Äúoil,gas, tiveofthemostseverecasesofpartisananimosity.Whileitwould
energy,strategic‚Äù)andattemptedtoexplaineachtopic(e.g.,Natural ordinarilybechallengingtoextractexamplesthatdisplaysocial
resourcesandenergy)basedonpriorknowledgeofthedataset.They distrust,whichmanifestsimplicitlyratherthanexplicitly,LLooM
spenttimeexploringexamplesprimarilytocomparetwohighly allowedtheanalysttosuccessfullycapturetheconcept.
similartopics(‚Äúhouse,republicans,democrats‚Äùand‚Äúrep,congress-
man,great‚Äù),butcouldnotidentifyameaningfuldifference. 6.1.3 InterviewTakeaways. Overall,whileBERTopicallowedthe
analysttoseedataintermsofloosegroupings,LLooMallowedthem
6.1.2 LLooMAnalysisprocess‚ÄîExploringdatathroughthelensof tonavigateandunderstanddataintermsofmeaningfulconcepts.
concepts. Bycontrast,withtheLLooMWorkbench,theanalystdid BERTopicisamap,LLooMisavehicle.BERTopictopicshelped
notneedtospendtimeinterpretingeachconceptandprimarily theanalystto‚Äúvisualizethemainpatterns.‚ÄùTheyfeltthatforfu-
spenttimeinspectingthedatathroughthelensoftheconcept. turequalitativecoding,topicslikethesecouldsimplifytheirwork
Exploringconceptsthatmatchorviolateexpectations.Theana- becauseexampleswithineachclusterwouldlikelyhavesimilar
lystselectivelyexploredconceptsthatdifferentiatedlowandhigh ratingsforconstructslikepartisananimosity.WithLLooMWork-
partisananimosityexamplesbasedontheconceptprevalencehis- bench,theanalystfeltthatthesystem‚Äú[did]amuchbetterjobin
tograms.Severalconceptsmatchedtheanalyst‚Äôsexpectationsas termsofvisualizingandhelpingmenavigateconceptsaswellas
associatedwithhighpartisananimosity(e.g.,‚ÄúGovernment-Related examplesunderthoseconcepts.‚Äù
Themes‚Äùand‚ÄúPoliticalCommentary‚Äù)orlowpartisananimosity LLooMmayaidpreliminaryphasesofqualitativeanalysis.Thean-
(e.g.,‚ÄúGovernmentAccountability‚Äùand‚ÄúPublicHealthConcern‚Äù). alystexpressedthattheLLooMWorkbenchwould‚Äúhelp[them]alot
However,LLooMhelpedtheanalysttodiscoveranunanticipated inprovidingguidanceondifferentcategorizationsofthedata‚Äùfor
and particularly helpful ‚ÄúPolitical Party Positions‚Äù concept that qualitativeanalysis.TheyraisedapotentialconcernthatLLooM‚Äôs
wasprevalentamonghighpartisananimositypostsandsurfaceda outputscouldimpacttheirjudgmentincategorizingdata:since
patternofattacksonout-partystances. it‚Äúalreadygivesmeaninitialcategorization,itmightaffectmy
Investigatingnascentpatterns.Startingfromanexisting‚ÄúPolicy- judgement.‚ÄùHowever,‚Äúgivenhowprecisetheconceptsare,‚Äùthey
related‚Äùconcept,theanalystnoticedapatternofpostsdramatizing feltthatasafirststepofcoding,LLooMwouldbeextremelyhelpful
theimpactofparticularpolicies(e.g.,immigrationandborderpoli- tosavetimeandgrantabetterunderstandingofthewholedataset,
cies).Theyexploredthispatternfurtherbycreatingavariantof especiallyforlargedatasets.
stpecnoC
fo
tnecreP
stpecnoC
fo
tnecrePCHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA M.S.Lam,J.Teoh,J.A.Landay,J.Heer,M.S.Bernstein
6.2 Expert2:AnalyzingUISTPaperAbstracts mentioned‚Äúobjectrecognition,‚Äùandtheanalystcommentedthat
LLooMWorkbenchhelpedthesecondanalysttoactivelyexplore evenresearchersinthefieldwouldlikelystruggletocomeupwith
hypothesesandcarryoutanalysisideasthatwerepreviouslychal- termslikethisbeforedivingintothedata.
lengingtoenact.FortheBERTopictopics,theylabeled8ashelpful
6.2.3 InterviewTakeaways. Insummary,theanalystfoundLLooM
(66.7%),3asuninterpretable(25%),andnoneasoverlappingwith
helpfulinnotonlyprovidinga‚Äústraightforward,high-levelidea‚Äù
anothertopic(0%),asshowninFigure13.ForLLooMconcepts,the
ofdata,butalsofosteringproactiveanalyst-leddataexplorations.
analystlabeledall16ashelpful(100%),noneasuninterpretable
LLooMshouldhelpanalystscalibratetheirtrust.Onelimitation
(0%),andnonethatwereoverlappingwitheachother(0%).
thattheyraisedwasthatdatascientistsandcomputationalsocial
scientistswouldlikelywanttohavequantitativemetricstoindicate
6.2.1 BERTopicAnalysisProcess‚ÄîDealingwithincoherentandoverly-
therobustnessandreliabilityofthetooltoincreasetheirconfidence
generictopics. Thesecondanalystspentmostoftheirtimereview-
inbuildingontheoutputconcepts.Additionally,usersinthese
ingtheBERTopickeywordsandonlyinspectedexamplestomake
domainswouldlikelywanttobetterunderstandLLooM‚Äôsinternal
sense of topics with uninterpretable keywords. They primarily
processtocalibratetheirtrustinthetool.
lookedforcoherentgroupsoftermswithinthekeywordsets,such
LLooM can facilitate theory-driven analysis. The analyst was
as‚Äúreality,vr,virtual,‚Äùbutstruggledtoauthormanuallabelsfor3
mostenthusiasticaboutthepossibilityforthetooltosupportmore
ofthetopics(25%).
theory-drivenanalysesinresponsetoLLooM‚Äôsautomaticallyex-
Difficultiesiteratingonuninformativetopics.Severalclusterscon-
tractedconcepts.Whiletheyhadwantedtoanalyzedatainthis
sistedoftermslike‚Äúuser‚Äùand‚Äúinterface‚Äùthatmightbeinformative
wayinpriorresearchprojects,itwaschallengingtoexecutethis
inageneralsense,butwereuninformativeinthisanalysiscontext.
kindofanalysiswithexistingtools.
GiventheubiquityofusersandinteractioninHCIresearch,such
clustersdidn‚Äôthelptheanalysttounderstandthepatternshappen- 7 DISCUSSION
ingwithinaconferencelikeUIST.Thiswasamajorpainpointwhen
Inthispaper,wepresentLLooM,aconceptinductionalgorithm
theyhadpreviouslyusedLDAfortopicmodelingonthisdataset,
thatextractshigh-level,interpretableconceptsfromunstructured
astheyhadtoperformmultipleroundsofiterationtocatchstop-
textdatasets.LLooMnotonlyimprovestopicqualityandcoverage,
wordsandoptimizeoutputclusters,whichwastime-consuming
butalsoprovidesbenefitstosteerabilityandinterpretability.Here,
andcausedthemtodoubtwhethertheirresultswererobust.
wediscussdesignimplications,limitations,andopportunitiesfor
6.2.2 LLooMAnalysisProcess‚ÄîLeveragingconceptstoexplorehy- futurework.
potheses. WhenusingtheLLooMWorkbench,theanalystnoted
7.1 DesignImplications
thatitcontrastedsharplywiththeirpriorexperiencewithtradi-
tionaltopicmodels. LLooMpointstowardseveraldesignopportunitiesintherealmsof
Lesstimevalidating,moretimeexploring.WithLLooM,theywere topicmodelingandinteractivedataanalysis.
abletoimmediatelyunderstandtheextractedconceptsandverify
7.1.1 Redesigning data analysis abstractions to support theory-
howtheymappedtospecificdocuments.Theanalystdeemedall
drivenanalysis. WithLLooM,weaskwhetheritispossibletore-
oftheLLooMconceptsasbothinterpretableandhelpfulfortheir
designthecoreabstractionsofourdataanalysissystemstocenter
analysistaskofunderstandingresearchatUIST,andtheyfound
aroundthewayanalystswouldliketothinkabouttheirdata.Based
thecriteriapromptespeciallyhelpfulinclarifyingthemeaningof
onourevaluationsandpreliminaryfindings,itappearsthatitis
concepts.Mostoftheanalyst‚Äôstimewasspentusingtheconcepts
indeedpossibletoorientatopicmodelingprocessentirelyaround
tocomparechangesinpapertopicsormethodsoverthedecades.
human-understandable concepts expressed in natural language,
Exploringtheirownhunchesandanalysisideas.Theanalystwas
andenableanalyststosteerthemodel‚Äôsattentiontowardspecific
particularlyexcitedaboutauthoringnewconceptswithLLooM,as
analyticgoals.Bylinkingdata-drivenresultswithhuman-readable
thiswasabarrierwithtraditionaltopicmodelingtoolswhereana-
ideas,wecanenactaverydifferentdataanalysisexperiencewhere
lystscannotproactivelyspecifytheirowntopicsthattheywishtoex-
ananalystcan‚Äúread‚Äùemergentpatternsfromdataand,inresponse,
plore.TheanalystwascuriousaboutwhethermoreHCIresearchers
‚Äúwrite‚Äùtheirtheorytoapplyitbackontothedata.
wereincorporatingAIintotheirsystems,sincethisappearedto
bethecasefromtheiranecdotalexperience.Theyauthoredanew 7.1.2 Introducingautomationtoaidreflectiononanalysisprocesses.
conceptcalled‚ÄúAI‚Äùwiththecriteria‚ÄúDoesthisexampleinclude Byautomatingelementsofthedataanalysisprocess,wecanfree
conceptsofartificialintelligence?‚Äùandindeedfoundthattherewas analyststostepbackonelevelandnotjustenacttheiranalysis
asteadyriseinAI-relatedpapersacrossthedecades. process,butreflectandidentifypotentialgapstherein.Moreover,
Investigating concepts that are challenging to describe. In past incontextssuchascomputationalsocialscience,analystsmayneed
analyseswheretheanalysthadahypothesisandwantedto‚Äúzoom tomakecrediblecommitmentsforreplicabilityandgeneralizability
in‚Äùonthatphenomenon,theyhadtorelyonkeywordsearch,which purposes that they have not overly biased the analysis process.
wastime-intensive,requireddomainknowledge,andcouldresult Inthesecases,LLooMcanautomaticallycarryoutkeyaspectsof
incoveragegaps.TheyfeltthatLLooMwouldbehighlyuseful manualdataanalysis,suchasdistillingdata,groupingtogether
fortheseanalysistasksnotonlytolowereffort,buttoincrease relevantitems,synthesizingtrendsintoconcepts,andapplying
coverage.LLooMsuccessfullysurfacedexamplesintheAIconcept those concepts to categorize data. LLooM can aid reflection by
thatdidn‚ÄôtexplicitlyusetheAIterm,suchasapaperthatonly guidinguserstoclarifythemeaningofconcepts,catchblindspotsConceptInduction:AnalyzingUnstructuredTextwithHigh-LevelConceptsUsingLLooM CHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA
intheiranalysisthataren‚Äôtcoveredbyconcepts,andinitiateparallel modelcapabilitiesimprove,futureworkshouldexplorestrategies
re-runstoexploreavarietyofdatainterpretations.Incontrast,if forusingopen-sourcemodelsforconceptinduction.
theanalystdoeswishtoinjecttheirinsightandperspectivesinto Anotherlimitationofclosed-sourceLLMsisthatitiscostlytorun
theanalysis,asismorecommoninethnomethodologicaltraditions, ourprocessatextremelylargescalessinceourmethoddependson
LLooMcanoperateinaclosedloopwiththeanalyst. callstoexternalAPIsthatchargebytokenusageandthatenforce
tokenlimits.IntheyearssincetheoriginalreleasesofAPIsfor
7.1.3 Innovatingonourcorealgorithmicoperators. Toimplement
LLMs,costshavealreadydramaticallydecreased,soweanticipate
LLooM,wecombinedthecoreoperatorsintroducedinthiswork
thatcostandefficiencyissueswillbecomelessofabarrierinthe
(e.g.,Distill,Cluster,andSynthesize)intoanarchitecturethatdrew
future.Giventhatconceptscoringisanespeciallycostlypartof
inspirationfromthequalitativeanalysisprocess.However,thereis
thepipeline,ifanalystsneedtoscaleupclassification,theycould
amuchbroaderdesignspaceofoperatorsandimplementations.We
exploretrainingdistilledmodelsusingasmallersetofLLM-labeled
seeexcitingopportunitiestodynamicallyrearrangeandrestruc-
examplestoreducethecostandspeedofinference,ordrawingon
turetheseoperatorsasbuildingblocksfordifferentanalysistasks
open-sourceLLMs.
dependingonananalyst‚Äôsgoals.Goingfurther,wecouldinnovate
newoperatorsthatalignwiththecognitiveprocessesofnotjust 7.2.3 Potentialtobiasanalysts. Lastly,assurfacedbyourexpert
dataanalysts,butotherhumandomainexpertsfortasksbeyond casestudiesandinpriorliteratureonAI-assisteddataanalysis[27,
dataanalysis. 31],AI-basedanalysistoolslikeLLooMmayriskbiasinganalysts
orlimitingtheiragencytoleadanalyses.Ifanalyststooheavily
7.2 LimitationsandFutureWork dependonLLooMoutputs‚Äîbynotinspectingtheconcepts,not
LLooMalsopresentscriticaldesignchallenges,especiallygivenits exploringpotentialgapsoutsideofthesetofgeneratedconcepts,
useoflargelanguagemodeloutputsanditsspecificuseofOpenAI‚Äôs oroverrelyingontheautomatedconceptscores‚Äîtheymaymiss
GPTmodels.Thesepointtoimportantfutureworkdirections. importantpatternsinthedataormayinadvertentlybuildonlow-
qualityorfaultymodeloutputs.Thus,futureworkshouldhelp
7.2.1 UncertainLLMbehaviors:risksofunevencross-domainperfor- userstocalibratetheirtrustinLLooMwithindicatorsofreliability
mance. Onecorelimitationofthiswork,andanyworkthatbuilds andpotentialknowledgegaps.Thisworkshouldfurtheraidusersin
uponlargelanguagemodels,isthatwecurrentlylackreliability verifyingsystemoutputs,manuallyinspectingresults,andleading
andperformanceguarantees.LLMperformancecanvarywidely follow-upanalysestoaugmentexploratoryLLooManalyses.Along
acrossdomainsandgreatlydependsonthetrainingdata,whichis thisline,animportantlimitationofLLMtoolsisthatthevaluesand
oftenwithheldfrompublicknowledge.WhilewecanexpectLLMs biasesencodedinLLMsareunclear,buttheycertainlycanshape
likeGPT-4toperformstronglyontextsimilartothedistributionof theconceptsthatoursystemgenerates.Futuretoolsneedtodesign
large-scaleInternettextdataonwhichtheyweretrained,perfor- aroundthischallengeandprovidegreatertransparencyandcontrol
mancemaydeclineinspecializeddomainssuchaslaw,medicine, aboutthevaluesembeddedinLLM-leddataanalysis.
andfieldsrequiringtechnicalexpertise.Noveltechniquesmaybe
neededtoenableconceptinductioninareasunderrepresentedin 8 CONCLUSION
LLMtrainingdata.LLMsoftenerrinfollowinginstructions,strug-
Unstructuredtextholdsavastamountofinformation,butitremains
glewithlogicalstatements,orproduceoutputswithhallucinations
difficulttoderivemeaningfulinsightsfromdatainthisform.Itises-
thatarenotfaithfultotheoriginaldata.Wecannotentirelyre-
peciallychallengingtoenacttheory-drivenanalysesofunstructured
movethepossibilityofsuchfoundationalerrors,butoursystem
text.Currenttoolsliketopicmodelingandclusteringarehelpful,
additionallymitigatestheriskofdownstreamharmbyheavilyin-
buttendtooutputsurfacefeatureslike‚Äúrep,congressman,great‚Äù
corporatinghumanreview:analystscantraceconceptsbackto
thatrequiresubstantialefforttointerpretandvalidate.Weintroduce
lower-levelconceptsandoriginaldataexamples,andtheycanre-
thetaskofconceptinduction,acomputationalprocessthattakes
viewconceptscoresandrationalestocatchwhenmodelsfail.
in unstructured text and produces high-level concepts‚Äîhuman-
7.2.2 Drawbacks of closed-source LLMs: cost and lack of trans- interpretabledescriptionsdefinedbyexplicitinclusioncriteria(e.g.,
parency. Compoundedontheuncertaintiesoflargelanguagemod- a‚ÄúGovernmentandcommunitycollaboration‚Äùconceptdefinedby
elsingeneral,thereareadditionaldownsidesofclosed-sourcemod- criterialike‚ÄúDoesthetextexamplementionagovernmentprogram
elslikeOpenAI‚ÄôsGPTmodels,whichweuseinourLLooMimple- orinitiativeandcommunityengagementorparticipation?‚Äù).High-
mentation.Sincewelacktransparencyonboththedataonwhich levelconceptsprovidetheaffordancesto‚Äúread‚Äùoutdatapatterns
thesemodelsweretrainedandthedesignofthemodelsthemselves, inaninterpretableformandto‚Äúwrite‚Äùoutactionabletheoriesthat
wehavelimitedabilitytoanticipateblindspotsthatwouldimpact canbeappliedbacktodata.WepresentLLooM,aconceptinduc-
LLooM‚Äôs functionality. Additionally, the use of OpenAI models tionalgorithmthatimplementsanovelLLM-poweredSynthesize
presentsbarrierstoreproducibility:themodelversionsunderlying operatortoiterativelysampleunstructuredtextandproposehigh-
theAPIsmaychangeatanytimewithoutourknowledge,andwe levelconceptsofincreasinggenerality.ByinstantiatingLLooMin
lackthecontroltoinvokethesamemodelversionwemayhave amixed-initiativetextanalysistoolcalledtheLLooMWorkbench,
used in the past. We opt to use the closed-source OpenAI GPT wedemonstratethatitsconceptsareabletoexceedthequalityof
modelsbecausetheyrepresentthestate-of-the-art;ourpreliminary topicmodels.WithLLooM,analystscanseeandinteractwithdata
testingwithothermodelscouldnotreliablyexecutethesynthe- intermsofinterpretable,actionableconceptstoleadtheory-driven
sisoperationscentraltoourapproach.However,asopen-source analysesofunstructuredtext.CHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA M.S.Lam,J.Teoh,J.A.Landay,J.Heer,M.S.Bernstein
ACKNOWLEDGMENTS
[15] JasonChuang,JohnD.Wilkerson,RebeccaWeiss,DustinTingley,andBrandonM
Stewart.2014.Computer-AssistedContentAnalysis:TopicModelsforExploring
WethankouranonymousreviewersinadditiontoOmarShaikh,
MultipleSubjectiveInterpretations.InAdvancesinNeuralInformationProcessing
JordanTroutman,andFarnazJahanbakhshfortheirvaluablefeed- Systemsworkshoponhuman-propelledmachinelearning.1‚Äì9.
backonourpaper.WethankZacharyXiforcontributionstoour [16] DorottyaDemszky,NikhilGarg,RobVoigt,JamesZou,JesseShapiro,Matthew
Gentzkow,andDanJurafsky.2019. AnalyzingPolarizationinSocialMedia:
evaluations.ThisworkwassupportedinpartbyIBMasafounding MethodandApplicationtoTweetson21MassShootings.InProceedingsofthe
memberoftheStanfordInstituteforHuman-centeredArtificial 2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-
tionalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers).
Intelligence(HAI)andbyNSFawardIIS-1901386.MichelleS.Lam
AssociationforComputationalLinguistics,Minneapolis,Minnesota,2970‚Äì3005.
wassupportedbyaStanfordInterdisciplinaryGraduateFellowship. https://doi.org/10.18653/v1/N19-1304
[17] JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova.2018.Bert:
REFERENCES Pre-trainingofdeepbidirectionaltransformersforlanguageunderstanding.arXiv
preprintarXiv:1810.04805(2018).
[1] LoulwahAlSumait,DanielBarbar√°,JamesGentle,andCarlottaDomeniconi. [18] PaulDiMaggio,ManishNag,andDavidBlei.2013.ExploitingAffinitiesbetween
2009.TopicSignificanceRankingofLDAGenerativeModels.InProceedingsof TopicModelingandtheSociologicalPerspectiveonCulture:Applicationto
the2009thEuropeanConferenceonMachineLearningandKnowledgeDiscovery NewspaperCoverageofUSGovernmentArtsFunding. Poetics41,6(2013),
inDatabases-VolumePartI(Bled,Slovenia)(ECMLPKDD‚Äô09).Springer-Verlag, 570‚Äì606.
Berlin,Heidelberg,67‚Äì82. [19] MargaretDrouhard,Nan-ChenChen,JinaSuh,RafalKocielnik,VanessaPe√±a-
[2] EricP.S.Baumer,DavidMimno,ShionGuha,EmilyQuan,andGeriK.Gay. Araya,KetingCen,XiangyiZheng,andCeciliaR.Aragon.2017.Aeonium:Visual
2017. Comparinggroundedtheoryandtopicmodeling:Extremedivergence analyticstosupportcollaborativequalitativecoding.In2017IEEEPacificVisu-
orunlikelyconvergence? JournaloftheAssociationforInformationScience alizationSymposium(PacificVis).220‚Äì229. https://doi.org/10.1109/PACIFICVIS.
and Technology 68, 6 (2017), 1397‚Äì1410. https://doi.org/10.1002/asi.23786 2017.8031598
arXiv:https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/asi.23786 [20] MennatallahEl-Assady,RebeccaKehlbeck,ChristopherCollins,DanielKeim,and
[3] DavidMBlei,AndrewYNg,andMichaelIJordan.2003.LatentDirichletAlloca- OliverDeussen.2019.SemanticConceptSpaces:GuidedTopicModelRefinement
tion.JournalofMachineLearningResearch3,Jan(2003),993‚Äì1022. usingWord-EmbeddingProjections. IEEETransactionsonVisualizationand
[4] MichaelBrooks,SaleemaAmershi,BongshinLee,StevenMDrucker,Ashish ComputerGraphics26,1(2019),1001‚Äì1011.
Kapoor,andPatriceSimard.2015.FeatureInsight:Visualsupportforerror-driven [21] NoyanEvirgenandXiang‚ÄôAnthony‚ÄôChen.2022.GANzilla:User-DrivenDirection
featureideationintextclassification.In2015IEEEConferenceonVisualAnalytics DiscoveryinGenerativeAdversarialNetworks.InProceedingsofthe35thAnnual
ScienceandTechnology(VAST).IEEE,105‚Äì112. ACMSymposiumonUserInterfaceSoftwareandTechnology(Bend,OR,USA)
[5] TomBrown,BenjaminMann,NickRyder,MelanieSubbiah,JaredDKaplan, (UIST‚Äô22).AssociationforComputingMachinery,NewYork,NY,USA,Article
PrafullaDhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,Amanda 75,10pages. https://doi.org/10.1145/3526113.3545638
Askell,etal.2020.Languagemodelsarefew-shotlearners.Advancesinneural [22] SimretArayaGebreegziabher,ZhengZhang,XiaohangTang,YihaoMeng,ElenaL.
informationprocessingsystems33(2020),1877‚Äì1901. Glassman,andTobyJia-JunLi.2023.PaTAT:Human-AICollaborativeQualitative
[6] HanchengCao,YujieLu,YutingDeng,DanielMcfarland,andMichaelS.Bernstein. CodingwithExplainableInteractiveRuleSynthesis.InProceedingsofthe2023
2023.BreakingOutoftheIvoryTower:ALarge-ScaleAnalysisofPatentCitations CHIConferenceonHumanFactorsinComputingSystems(Hamburg,Germany)
toHCIResearch.InProceedingsofthe2023CHIConferenceonHumanFactorsin (CHI‚Äô23).AssociationforComputingMachinery,NewYork,NY,USA,Article
ComputingSystems(Hamburg,Germany)(CHI‚Äô23).AssociationforComputing 362,19pages. https://doi.org/10.1145/3544548.3581352
Machinery,NewYork,NY,USA,Article760,24pages. https://doi.org/10.1145/ [23] Mitchell L. Gordon, Kaitlyn Zhou, Kayur Patel, Tatsunori Hashimoto, and
3544548.3581108 MichaelS.Bernstein.2021. TheDisagreementDeconvolution:BringingMa-
[7] JonathanChang,SeanGerrish,ChongWang,JordanBoyd-Graber,andDavid chineLearningPerformanceMetricsInLineWithReality.InProceedingsofthe
Blei. 2009. Reading Tea Leaves: How Humans Interpret Topic Models. 2021CHIConferenceonHumanFactorsinComputingSystems(Yokohama,Japan)
In Advances in Neural Information Processing Systems, Y. Bengio, D. Schu- (CHI‚Äô21).AssociationforComputingMachinery,NewYork,NY,USA,Article
urmans, J. Lafferty, C. Williams, and A. Culotta (Eds.), Vol. 22. Curran 388,14pages. https://doi.org/10.1145/3411764.3445423
Associates, Inc. https://proceedings.neurips.cc/paper_files/paper/2009/file/ [24] ThomasLGriffithsandMarkSteyvers.2004.FindingScientificTopics.Proceedings
f92586a25bb3145facd64ab20fd554ff-Paper.pdf oftheNationalAcademyofSciences101,suppl_1(2004),5228‚Äì5235.
[8] KathyCharmaz.2006.ConstructingGroundedTheory:APracticalGuidethrough [25] MaartenGrootendorst.2020.BERTopic:LeveragingBERTandc-TF-IDFtocreate
QualitativeAnalysis.Sage. easilyinterpretabletopics. https://doi.org/10.5281/zenodo.4381785
[9] Nan-ChenChen,MargaretDrouhard,RafalKocielnik,JinaSuh,andCeciliaR. [26] JohannesHellrichandUdoHahn.2016. BadCompany‚ÄîNeighborhoodsin
Aragon.2018.UsingMachineLearningtoSupportQualitativeCodinginSocial Neural Embedding Spaces Considered Harmful. In Proceedings of COLING
Science:ShiftingtheFocustoAmbiguity.ACMTrans.Interact.Intell.Syst.8,2, 2016,the26thInternationalConferenceonComputationalLinguistics:Techni-
Article9(jun2018),20pages. https://doi.org/10.1145/3185515 calPapers.TheCOLING2016OrganizingCommittee,Osaka,Japan,2785‚Äì2796.
[10] Nan-ChenChen,JinaSuh,JohanVerwey,GonzaloRamos,StevenDrucker,and https://aclanthology.org/C16-1262
PatriceSimard.2018.AnchorViz:Facilitatingclassifiererrordiscoverythroughin- [27] Matt-HeunHong,LaurenA.Marsh,JessicaL.Feuston,JanetRuppert,JedR.
teractivesemanticdataexploration.In23rdInternationalConferenceonIntelligent Brubaker,andDanielleAlbersSzafir.2022. Scholastic:GraphicalHuman-AI
UserInterfaces.269‚Äì280. CollaborationforInductiveandInterpretiveTextAnalysis.InProceedingsofthe
[11] JasonChuang,SonalGupta,ChristopherManning,andJeffreyHeer.2013.Topic 35thAnnualACMSymposiumonUserInterfaceSoftwareandTechnology(Bend,
ModelDiagnostics:AssessingDomainRelevanceviaTopicalAlignment.InPro- OR,USA)(UIST‚Äô22).AssociationforComputingMachinery,NewYork,NY,USA,
ceedingsofthe30thInternationalConferenceonMachineLearning(Proceedings Article30,12pages. https://doi.org/10.1145/3526113.3545681
ofMachineLearningResearch,Vol.28),SanjoyDasguptaandDavidMcAllester [28] AlexanderHoyle,PranavGoel,AndrewHian-Cheong,DenisPeskov,Jordan
(Eds.).PMLR,Atlanta,Georgia,USA,612‚Äì620. https://proceedings.mlr.press/ Boyd-Graber,andPhilipResnik.2021. IsAutomatedTopicModelEvaluation
v28/chuang13.html Broken?:TheIncoherenceofCoherence.NeuralInformationProcessingSystems
[12] JasonChuang,ChristopherD.Manning,andJeffreyHeer.2012.Termite:Visu- 34(2021),2018‚Äì2033.
alizationTechniquesforAssessingTextualTopicModels.InProceedingsofthe [29] AlexanderMiserlisHoyle,PranavGoel,RupakSarkar,andPhilipResnik.2022.
InternationalWorkingConferenceonAdvancedVisualInterfaces(CapriIsland, AreNeuralTopicModelsBroken?.InFindingsoftheAssociationforComputational
Italy)(AVI‚Äô12).AssociationforComputingMachinery,NewYork,NY,USA,74‚Äì77. Linguistics:EMNLP2022.AssociationforComputationalLinguistics,AbuDhabi,
https://doi.org/10.1145/2254556.2254572 UnitedArabEmirates,5321‚Äì5344. https://doi.org/10.18653/v1/2022.findings-
[13] JasonChuang,DanielRamage,ChristopherManning,andJeffreyHeer.2012.In- emnlp.390
terpretationandTrust:DesigningModel-DrivenVisualizationsforTextAnalysis. [30] ChenyanJia,MichelleS.Lam,MinhChauMai,JeffreyT.Hancock,andMichaelS.
InProceedingsoftheSIGCHIConferenceonHumanFactorsinComputingSystems Bernstein.2024.EmbeddingDemocraticValuesintoSocialMediaAIsviaSocietal
(Austin,Texas,USA)(CHI‚Äô12).AssociationforComputingMachinery,NewYork, ObjectiveFunctions.Proc.ACMHum.-Comput.Interact.8,CSCW1,Article163
NY,USA,443‚Äì452. https://doi.org/10.1145/2207676.2207738 (Apr2024),36pages. https://doi.org/10.1145/3641002
[14] JasonChuang,MargaretE.Roberts,BrandonM.Stewart,RebeccaWeiss,Dustin [31] JialunAaronJiang,KandreaWade,CaseyFiesler,andJedR.Brubaker.2021.Sup-
Tingley,JustinGrimmer,andJeffreyHeer.2015.TopicCheck:InteractiveAlign- portingSerendipity:OpportunitiesandChallengesforHuman-AICollaboration
mentforAssessingTopicModelStability.InProceedingsofthe2015Conferenceof inQualitativeAnalysis.Proc.ACMHum.-Comput.Interact.5,CSCW1,Article94
theNorthAmericanChapteroftheAssociationforComputationalLinguistics:Hu- (apr2021),23pages. https://doi.org/10.1145/3449168
manLanguageTechnologies.AssociationforComputationalLinguistics,Denver, [32] EuniceJun,MelissaBirchfield,NicoleDeMoura,JeffreyHeer,andRen√©Just.
Colorado,175‚Äì184. https://doi.org/10.3115/v1/N15-1018 2022.HypothesisFormalization:EmpiricalFindings,SoftwareLimitations,andConceptInduction:AnalyzingUnstructuredTextwithHigh-LevelConceptsUsingLLooM CHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA
DesignImplications. ACMTrans.Comput.-Hum.Interact.29,1,Article6(Jan [53] JoshuaRobinson,ChristopherMichaelRytting,andDavidWingate.2022.Lever-
2022),28pages. https://doi.org/10.1145/3476980 aginglargelanguagemodelsformultiplechoicequestionanswering. arXiv
[33] EuniceJun,AudreySeo,JeffreyHeer,andRen√©Just.2022. Tisane:Authoring preprintarXiv:2210.12353(2022).
StatisticalModelsviaFormalReasoningfromConceptualandDataRelationships. [54] ShibaniSanturkar,EsinDurmus,FaisalLadhak,CinooLee,PercyLiang,and
InProceedingsofthe2022CHIConferenceonHumanFactorsinComputingSystems TatsunoriHashimoto.2023. WhoseOpinionsDoLanguageModelsReflect?
(NewOrleans,LA,USA)(CHI‚Äô22).AssociationforComputingMachinery,New arXiv:2303.17548[cs.CL]
York,NY,USA,Article490,16pages. https://doi.org/10.1145/3491102.3501888 [55] CarsonSievertandKennethShirley.2014. LDAvis:Amethodforvisualizing
[34] TakeshiKojima,ShixiangShaneGu,MachelReid,YutakaMatsuo,andYusuke andinterpretingtopics.InProceedingsoftheWorkshoponInteractiveLanguage
Iwasawa.2022. Largelanguagemodelsarezero-shotreasoners. Advancesin Learning,Visualization,andInterfaces.AssociationforComputationalLinguistics,
neuralinformationprocessingsystems35(2022),22199‚Äì22213. Baltimore,Maryland,USA,63‚Äì70. https://doi.org/10.3115/v1/W14-3110
[35] Deepak Kumar, Patrick Gage Kelley, Sunny Consolvo, Joshua Mason, Elie [56] SanghoSuh,BryanMin,SrishtiPalani,andHaijunXia.2023.Sensecape:Enabling
Bursztein,ZakirDurumeric,KurtThomas,andMichaelBailey.2021. Design- MultilevelExplorationandSensemakingwithLargeLanguageModels.InProceed-
ingToxicContentClassificationforaDiversityofPerspectives.InSeventeenth ingsofthe36thAnnualACMSymposiumonUserInterfaceSoftwareandTechnology
SymposiumonUsablePrivacyandSecurity(SOUPS2021).USENIXAssociation, (SanFrancisco,CA,USA)(UIST‚Äô23).AssociationforComputingMachinery,New
299‚Äì318. https://www.usenix.org/conference/soups2021/presentation/kumar York,NY,USA,Article1,18pages. https://doi.org/10.1145/3586183.3606756
[36] MichelleS.Lam,ZixianMa,AnneLi,IzequielFreitas,DakuoWang,JamesA. [57] OrenTsur,DanCalacci,andDavidLazer.2015.AFrameofMind:UsingStatistical
Landay,andMichaelS.Bernstein.2023.ModelSketching:CenteringConcepts ModelsforDetectionofFramingandAgendaSettingCampaigns.InProceedings
inEarly-StageMachineLearningModelDesign.InProceedingsofthe2023CHI ofthe53rdAnnualMeetingoftheAssociationforComputationalLinguisticsandthe
ConferenceonHumanFactorsinComputingSystems(Hamburg,Germany)(CHI 7thInternationalJointConferenceonNaturalLanguageProcessing(Volume1:Long
‚Äô23).AssociationforComputingMachinery,NewYork,NY,USA,Article741, Papers).AssociationforComputationalLinguistics,Beijing,China,1629‚Äì1638.
24pages. https://doi.org/10.1145/3544548.3581290 https://doi.org/10.3115/v1/P15-1157
[37] BohanLi,HaoZhou,JunxianHe,MingxuanWang,YimingYang,andLeiLi.2020. [58] VijayViswanathan,KirilGashteovski,CarolinLawrence,TongshuangWu,and
OntheSentenceEmbeddingsfromPre-trainedLanguageModels.InProceedings GrahamNeubig.2023. LargeLanguageModelsEnableFew-ShotClustering.
ofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing arXiv:2307.00524[cs.CL]
(EMNLP).AssociationforComputationalLinguistics,Online,9119‚Äì9130. https: [59] JanGVoelkel,MichaelStagnaro,JamesChu,SophiaPink,JosephMernyk,Chrys-
//doi.org/10.18653/v1/2020.emnlp-main.733 talRedekopp,IsaiasGhezae,MatthewCashman,DhavalAdjodah,LeviAllen,etal.
[38] StephanieLin,JacobHilton,andOwainEvans.2022.TeachingModelstoExpress 2023.MegastudyidentifyingeffectiveinterventionstostrengthenAmericans‚Äô
TheirUncertaintyinWords. arXiv:2205.14334[cs.CL] democraticattitudes.(2023).
[39] NelsonF.Liu,KevinLin,JohnHewitt,AshwinParanjape,MicheleBevilacqua, [60] ZihanWang,JingboShang,andRuiqiZhong.2023. Goal-DrivenExplainable
FabioPetroni,andPercyLiang.2023.LostintheMiddle:HowLanguageModels ClusteringviaLanguageDescriptions. arXiv:2305.13749[cs.CL]
UseLongContexts. arXiv:2307.03172. [61] JasonWei,XuezhiWang,DaleSchuurmans,MaartenBosma,FeiXia,EdChi,
[40] LelandMcInnesandJohnHealy.2017.AcceleratedHierarchicalDensityBased QuocVLe,DennyZhou,etal.2022.Chain-of-thoughtpromptingelicitsreasoning
Clustering.InDataMiningWorkshops(ICDMW),2017IEEEInternationalConfer- inlargelanguagemodels.AdvancesinNeuralInformationProcessingSystems35
enceon.IEEE,33‚Äì42. (2022),24824‚Äì24837.
[41] StephenMerity,NitishShirishKeskar,andRichardSocher.2018.Regularizing [62] ZiangXiao,XingdiYuan,Q.VeraLiao,RaniaAbdelghani,andPierre-Yves
andOptimizingLSTMLanguageModels.In6thInternationalConferenceon Oudeyer.2023.SupportingQualitativeAnalysiswithLargeLanguageModels:
LearningRepresentations,ICLR2018,Vancouver,BC,Canada,April30-May3, CombiningCodebookwithGPT-3forDeductiveCoding.InCompanionProceed-
2018,ConferenceTrackProceedings.OpenReview.net. https://openreview.net/ ingsofthe28thInternationalConferenceonIntelligentUserInterfaces(Sydney,
forum?id=SyyGPP0TZ NSW,Australia)(IUI‚Äô23Companion).AssociationforComputingMachinery,
[42] SmithaMilli,MicahCarroll,SashrikaPandey,YikeWang,andAncaDDragan. NewYork,NY,USA,75‚Äì78. https://doi.org/10.1145/3581754.3584136
2023.Twitter‚ÄôsAlgorithm:AmplifyingAnger,Animosity,andAffectivePolariza- [63] KaitlynZhou,KawinEthayarajh,DallasCard,andDanJurafsky.2022.Problems
tion.arXivpreprintarXiv:2305.16941(2023). withCosineasaMeasureofEmbeddingSimilarityforHighFrequencyWords.
[43] MichaelMuller.2014. Curiosity,Creativity,andSurpriseasAnalyticTools: InProceedingsofthe60thAnnualMeetingoftheAssociationforComputational
GroundedTheoryMethod.InWaysofKnowinginHCI.Springer,25‚Äì48. Linguistics(Volume2:ShortPapers).AssociationforComputationalLinguistics,
[44] MichaelMuller,ShionGuha,EricP.S.Baumer,DavidMimno,andN.Sadat Dublin,Ireland,401‚Äì423. https://doi.org/10.18653/v1/2022.acl-short.45
Shami.2016.MachineLearningandGroundedTheoryMethod:Convergence, [64] Caleb Ziems, William Held, Omar Shaikh, Jiaao Chen, Zhehao Zhang,
Divergence,andCombination.InProceedingsofthe2016ACMInternational and Diyi Yang. 2024. Can Large Language Models Transform Com-
ConferenceonSupportingGroupWork(SanibelIsland,Florida,USA)(GROUP putational Social Science? Computational Linguistics (02 2024), 1‚Äì
‚Äô16).AssociationforComputingMachinery,NewYork,NY,USA,3‚Äì8. https: 55. https://doi.org/10.1162/coli_a_00502arXiv:https://direct.mit.edu/coli/article-
//doi.org/10.1145/2957276.2957280 pdf/doi/10.1162/coli_a_00502/2332904/coli_a_00502.pdf
[45] PriyankaNanayakkara,JessicaHullman,andNicholasDiakopoulos.2021.Un-
packingtheExpressedConsequencesofAIResearchinBroaderImpactState-
A PROMPTS
ments.InProceedingsofthe2021AAAI/ACMConferenceonAI,Ethics,andSociety
(VirtualEvent,USA)(AIES‚Äô21).AssociationforComputingMachinery,NewYork,
A.1 Distilloperator:Filterstepprompt
NY,USA,795‚Äì806. https://doi.org/10.1145/3461702.3462608
[46] OpenAI.2023.GPT-4TechnicalReport. arXiv:2303.08774[cs.CL]
[47] MichaelPaulandMarkDredze.2011. YouAreWhatYouTweet:Analyzing I have the following TEXT EXAMPLE:
TwitterforPublicHealth.InProceedingsoftheinternationalAAAIconferenceon {text_example_json}
webandsocialmedia,Vol.5.265‚Äì272.
[48] ChauMinhPham,AlexanderHoyle,SimengSun,andMohitIyyer.2023.Top- Please extract {n_quotes} QUOTES exactly copied from
icGPT:APrompt-basedTopicModelingFramework. arXiv:2311.01449[cs.CL] this EXAMPLE {seed_phrase}.
[49] DanielRamage,SusanT.Dumais,andDanielJ.Liebling.2010.Characterizing
Please respond ONLY with a valid JSON in the
MicroblogswithTopicModels.ProceedingsoftheInternationalAAAIConference
following format:
onWebandSocialMedia(2010). https://api.semanticscholar.org/CorpusID:
11745061 {{
[50] DanielRamage,EvanRosen,JasonChuang,ChristopherDManning,andDanielA "relevant_quotes": [ "<QUOTE_1>","<QUOTE_2>",...
McFarland.2009.Topicmodelingforthesocialsciences.InNIPS2009workshop ]
onapplicationsfortopicmodels:textandbeyond,Vol.5.1‚Äì4. }}
[51] NilsReimersandIrynaGurevych.2019.Sentence-BERT:SentenceEmbeddings
usingSiameseBERT-Networks.InProceedingsofthe2019ConferenceonEm-
piricalMethodsinNaturalLanguageProcessing.AssociationforComputational A.2 Distilloperator:Summarizestepprompt
Linguistics. https://arxiv.org/abs/1908.10084
[52] TimRietzandAlexanderMaedche.2021.Cody:AnAI-BasedSystemtoSemi- I have the following TEXT EXAMPLE:
AutomateCodingforQualitativeResearch.InProceedingsofthe2021CHICon-
{text_example_json}
ferenceonHumanFactorsinComputingSystems(Yokohama,Japan)(CHI‚Äô21).
AssociationforComputingMachinery,NewYork,NY,USA,Article394,14pages.
https://doi.org/10.1145/3411764.3445591 Please summarize the main point of this EXAMPLE {
seed_phrase} intoCHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA M.S.Lam,J.Teoh,J.A.Landay,J.Heer,M.S.Bernstein
{n_bullets} bullet points,where each bullet point is {{
a {n_words} word phrase. "example_id": "<example_id>"
Please respond ONLY with a valid JSON in the "rationale": "<rationale>"
following format: "answer": "<answer>"
{{ }}
"bullets": [ "<BULLET_1>","<BULLET_2>",... ] ]
}} }}
A.3 Synthesizeoperatorprompt A.5 Automatedcoverageprompt
I have this set of bullet point summaries of text I have this set of CONCEPTS:
examples: {ground_truth_concepts}
{bullets_json}
I have this set of TEXTS:
Please write a summary of {n_concepts} unifying {generated_concepts}
patterns for these examples {seed_phrase}.
For each high-level pattern,write a {n_name_words} Please match at most ONE TEXT to each CONCEPT. To
word NAME for the pattern perform a match,the text must
and an associated 1-sentence ChatGPT PROMPT that EXACTLY match the meaning of the concept.
could take in a new text example Do NOT match the same TEXT to multiple CONCEPTS.
and determine whether the relevant pattern applies.
Please also include {n_example_ids} example_ids for Here are examples of VALID matches:
items that BEST exemplify the pattern. - Global Diplomacy,International Relations;
Please respond ONLY with a valid JSON in the rationale: "The text is about diplomacy between
following format: countries."
{{ - Statistical Data,Quantitative Evidence;
"patterns": [ rationale: "The text is about data and quantitative
{{ measures."
"name": "<PATTERN_NAME_1>" - Policy and Regulation,Policy issues and legislation
"prompt": "<PATTERN_PROMPT_1>" ;
"example_ids": ["<EXAMPLE_ID_1>","< rationale: "The text is about policy,laws,and
EXAMPLE_ID_2>"] legislation."
}}
{{ Here are examples of INVALID matches:
"name": "<PATTERN_NAME_2>" - Reputation Impact,Immigration
"prompt": "<PATTERN_PROMPT_2>" - Environment,Politics and Law
"example_ids": ["<EXAMPLE_ID_1>","< - Interdisciplinary Politics,Economy
EXAMPLE_ID_2>"]
}} If there are no valid matches,please EXCLUDE the
] concept from the list.
}} Please provide a 1-sentence RATIONALE for your
decision for any matches.
Please respond with a list of each concept and either
A.4 Scoreoperatorprompt
the item it matches or NONE
if no item matches in this format:
CONTEXT: {{
I have the following text examples in a JSON: "concept_matches": [
{examples_json} {{
"concept_id": "<concept_id_number>"
I also have a pattern named {concept_name} with "item_id": "<item_id_number or NONE>"
the following PROMPT: "rationale": "<rationale for match>"
{concept_prompt} }}
]
TASK: }}
For each example,please evaluate the PROMPT by
generating RATIONALE of your thought process
and providing a resulting ANSWER of ONE of the B ADDITIONALMETHODS
following multiple-choice options,including just
the letter: B.1 ExpertCaseStudy:StudyDesign
- A: Strongly agree
TheExpertCaseStudyrequiredparticipantswhohaveexpertisein
- B: Agree
- C: Neither agree nor disagree dataanalysis:specifically,thosewhohaveconductedananalysisof
- D: Disagree unstructuredtextdocuments.Itwasimportantthattheyhadalready
- E: Strongly disagree conductedthisanalysis(sothattheyhadenoughpriorknowledgeof
Respond with ONLY a JSON with the following
thedatatodistinguishhelpfulandunhelpfulconcepts)andthatthe
format,escaping any quotes within strings with a
datasetcouldbesharedpublicly(sincetheanalysisscenariosand
backslash:
{{ expertcasestudieswouldbepublished).Thus,oureligibilitycriteria
"pattern_results": [ were (1) that the analyst had previously authored an academicConceptInduction:AnalyzingUnstructuredTextwithHigh-LevelConceptsUsingLLooM CHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA
1.0 1.0
0.9 0.9
0.8 0.8
0.7 0.7
0.6 0.6
0.5 0.5
0.4 0.4
0.3 0.3
0.2 0.2
0.1 0.1
0.0 0.0
sol ce ia er tn ai l,n g c, onw sor ek q, ud ea nt ca e, fores‚Ä¶ Imp Pa otct e no tf i al Me Bt eh no ed fio tl so A lg a gy n ord i tR his Im k ms Pr pSo oo rp c t Aio a des t n va a cl al e nI co im f np gVa ec rt C Ti o hfic ema opt ri u eo t t Nin e c e Dr a ewl V ci f irs C si iaoo on mn t nr -eib w M Gu o at r ei kik no n en p g rr
E
fao lu fiip n cz io d a es te i nra tl o nU MIn ac m ce p hr i N‚Ä¶ o n ev e ue rLm ae l e arn Nt ni e IWt in mdwg peo
r
rA oAk vp‚Ä¶ A epln di a cl Ta ry tis ai ios nn i
T
rnS ag
i
p nTa iec nce g h An Fi r dq a vu em re e ss aw rioO r au lkt l i I Ate n tr t aer ckpr s e a Prn‚Ä¶ i Id v a mED c ane y gf er eC ‚Ä¶ go Sy n ec C ge o Qr mn un es as ne t nr tav t uiat o mi no mn C ah ca hl il ne e ‚Ä¶ learning
BERTopic Topic LLooM Concept
Figure14:NeurIPSBroaderImpactStatements,TopicPrevalence.BERTopicstruggleswithonlytwocategories,oneofwhich
appearstobeavaguecatch-alltopicwith93.3%ofexamples.LLooMsurfacesconceptsthatrangefromcharacterizingthe
majorityofdatatosmallsubsets,andonlyfailstocategorize9.3%ofexamples.
publicationbasedonadatasetand(2)thatthedataconsistedof 15minutesforanalysisusingLLooMWorkbench,and10minutes
unstructuredtextdocuments.Forourexploratoryanalysisgoals, forafinalinterviewonLLooMandtheiroverallexperiencewith
werecruitedùëÅ =2participantsthroughcontactsintheuniversity bothtools.Eachsessionwasconductedremotelyoveravideocall,
setting.Expert1wasapostdoctoralscholarinCommunicationand andparticipantswerecompensatedwitha$45Amazongiftcard.
Human-ComputerInteractionwithresearchinterestsinemerging
mediatechnologiesandhuman-centeredAI.Expert2wasaPh.D. C ADDITIONALRESULTS
studentinHuman-ComputerInteractionandNaturalLanguage
C.1 Scenario4:InvestigatingAnticipated
Processingwithresearchinterestsincomputationalsocialscience
ConsequencesofAIResearch
andlarge-scaledatamining.Theparticipantshadnoknowledge
oftheLLooMWorkbenchanditsfunctionalitypriortothestudy In2020,NeurIPS,apremiermachinelearningresearchconference,
session. requiredauthorstoincludeabroaderimpactstatementintheirsub-
For the BERTopic analysis task, the participant was given a missioninanefforttoencourageresearcherstoconsidernegative
spreadsheetviewpopulatedwithBERTopicoutputsfortheirdataset. consequencesoftheirwork.Thesestatementsprovideawindow
Asummarytabdisplayedthekeywordsandsizeofeachtopic;a intotheethicalthoughtprocessesofabroadswathofAIresearchers,
detailtabdisplayedafilterableviewwithalldocumentsandtheir andpriorworkhasperformedaqualitativethematicanalysisona
assignedtopic.Tounderstandhowtheexpertinterpretedthetopics, sampleof300statements[45].Usingthisdataset,weexplorehow
wefirsthadthemcompleteanaming taskofprovidingamean- LLooMmighthelpustounderstandhowAIresearchersdiscuss
ingful name for each topic. Then, the participant was asked to downstreamconsequences,ethicalissues,andpotentialmitigations.
freelyexplorethedataandtopics.Finally,wehadthemcomplete
C.1.1 Results. LLooMgenerated14uniqueconcepts,including
anannotationtaskonwhethereachtopicwashelpful(aidstheir
exampleslike‚ÄúAdversarialAttacksandDefenses,‚Äù‚ÄúPrivacyCon-
understandingofthedataset),interpretable(hasadiscerniblemean-
cerns,‚Äùand‚ÄúEnergyConservation,‚ÄùasshowninFigure14.Incon-
ing),andunique(doesnotsharethesamemeaningasanothertopic).
trast,BERTopicgeneratedonly2topicswithkeywordssuchas
FortheLLooManalysistask,theparticipantaccessedtheLLooM
‚Äúsocietal,consequences,foreseeable‚Äùand‚Äúlearning,work,data.‚ÄùThe
Workbenchviaacomputationalnotebookalreadypopulatedwith
BERTopictopicswereallquitegeneric(ourmanualanalysismapped
theLLooM-generatedconceptsfortheirdataset.Theparticipant
thetopicstolabelsof‚ÄúMachineLearningTechniques‚Äùand‚ÄúEthics
wasaskedtoreviewthegeneratedconcepts,andthentofreely
andSocietalImpacts‚Äù).Sincethesetopicscouldlikelyapplyasa
explorethedatabasedontheirinterests.Towardstheendofthis
categorylabelforallimpactstatements,theydonothelpanalysts
section,weaskedtheparticipanttocompleteaconceptmodification
tobreakdownthedataintoemergenttrends.TheLLooMresults
tasktoeithereditoraddonenewconcept.Toconclude,wehad
alsoincludedsomemoregenericconcepts(e.g.,‚Äú‚ÄôSocietalImpact‚Äô),
themcompletethesameannotationtaskonLLooMconcepts.
butitalsoidentifiedspecifickindsofimpact mentionedinstate-
Thesessionwasroughlysplitinto5minutesforconsentand
ments,includingbothpositiveimpacts(e.g.,‚ÄúEnergyConservation,‚Äù
setup,15minutesforanalysisusingBERTopic,5minutesforapost-
‚ÄúGeneralizationImprovement,‚Äù‚ÄúImprovedTrainingTechniques,‚Äù
interviewonBERTopic,5minutesforaLLooMWorkbenchtutorial,
and‚ÄúEfficientMLAlgorithms‚Äù)andnegativeimpacts(e.g.,‚ÄúPrivacy
ecnelaverP ecnelaverPCHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA M.S.Lam,J.Teoh,J.A.Landay,J.Heer,M.S.Bernstein
Concerns,‚Äù‚ÄúAdversarialAttacks‚Äù).Furthermore,theconceptsen- Table1:Per-DatasetClassificationMetrics.Wereportmeans
capsulatedproposedsolutionstodownstreamimpactsofAIresearch andstandarddeviationsforclassificationmetricsoneach
(e.g.,‚ÄúAdversarialDefenses,‚Äù‚ÄúImportanceofVerification‚Äù). LLooMscenariodataset.Weobserveconsiderablevariance
While100%ofBERTopicresultsoverlappedwithLLooM,only inclassificationperformanceacrossconceptsanddatasets.
14.3%ofLLooMresultsoverlappedwithBERTopic,sotherewas
asubstantialportionofLLooMconceptsthatwerenovelcontri- Dataset Accuracy Precision F1Score
butions.Here,noneofexampleswereuncategorizedbyBERTopic
while9.3%wereuncategorizedbyLLooM.However,oneofthetwo NeurIPSStatements 0.90(0.02) 0.61(0.05) 0.55(0.14)
PartisanAnimosity 0.90(0.02) 0.95(0.01) 0.68(0.10)
BERTopicresults(‚Äúlearning,work,data‚Äù)appearstobeavague
catch-alltopic;BERTopicassigned93.3%ofexamplestothisgroup. ToxicContent 0.91(0.02) 0.65(0.27) 0.61(0.18)
UISTAbstracts 0.92(0.04) 0.59(0.25) 0.53(0.12)
C.2 ConceptClassificationEvaluation
WeperformanadditionalevaluationonthereliabilityofLLooM‚Äôs
automatedconceptclassificationwiththeScoreoperator.Toassess ‚Ä¢ NeurIPSStatementsdataset:
‚Äì ImportanceofVerification:Doesthetextexampleemphasizethe
howwellLLooMalignswithhumanjudgment,wesampleLLooM-
importanceofverifyingdataorsystems?
generatedconcepts,gatherhumanannotationsondocumentsfor
‚Äì NewFrameworkProposal:Doesthetextexampleproposeanew
eachconcept,andcomparetheresultswithLLooMscores.
framework?
‚Äì PotentialBenefitsandRisks:Doestheexamplediscusspotential
C.2.1 Method. Forthisevaluation,wesampleconceptsfromthe
benefitsandrisks?
fourLLooMscenariodatasets.Tocapturethesystem‚Äôsperformance
‚Äì WideApplicationSpace:Doestheexamplementionwideappli-
onbothrareandcommonconcepts,weperformastratifiedrandom
cationspaceforgenericobjects?
samplebasedonconceptprevalence,theproportionofdocuments
thatLLooMclassifiedasmatchingaconcept.8 Foreachdataset, Toassessinter-raterreliability,twomembersoftheresearch
teamindependentlyannotatedthefoursampledconceptsforone
wesampledoneconceptfromeachquartileofconceptprevalence
dataset(thePartisanAnimositydataset),eachannotating400docu-
foratotaloffourconcepts.Then,foreachselectedconcept,we
constructedbalanceddatasetswithùëõ=100documentsbytakinga mentsintotal.Oneraterannotatedthedocumentsfortheremaining
threedatasets.Foreachdocument,basedontheconceptnameand
stratifiedrandomsampleof50positivedocuments(thosethatwere
inclusioncriteria,eachannotatorselectedfromthesamemultiple-
classifiedasmatchingtheconcept)and50negativedocuments.For
choiceoptionsprovidedtoGPT-4intheLLooMSynthesizeopera-
rareconceptswithfewerthan50positivedocuments,theremainder
torprompt,rangingfromwhetherthey‚Äústronglyagree‚Äùto‚Äústrongly
wasdrawnfromarandomsampleofnegativedocuments.
disagree‚Äùthatthedocumentmatchestheconcept.Then,wecom-
Includedbelowarethesampledconceptsforeachdataset:
parethesemanualscoreswiththosegeneratedbyLLooMinthe
‚Ä¢ PartisanAnimositydataset: conceptscoringstep.Forinter-raterreliability,weuseCohen‚ÄôsùúÖ
‚Äì Advocacy:Doesthetextexampleadvocateforacauseorissue?
becauseweonlyconsiderpairsofraters,ourscaleiscategorical
‚Äì Event:Isthistextexamplerelatedtoanevent?
(binarylabels),andourdataisapproximatelybalanced.
‚Äì PoliticalPartyPositions:Doesthetextexamplementiontheposi-
tionsoractionsofpoliticalparties?
C.2.2 Results. Forclassificationmetricsacrossdatasets,weob-
‚Äì SocialJusticeFocus:Doesthetextexampleemphasizeworking serveameanaccuracyof0.91,precisionof0.70,recallof0.59,and
towardsajustfuture?
F1scoreof0.59;per-datasetmetricresultsareshowninFigure15
‚Ä¢ ToxicContentdataset:
andTable1.Giventhattheconceptsinthissetarequitecomplex,
‚Äì ExpressingFrustration:Doesthetextexampleinvolveexpressing
andgiventhatthedocumentsarerelativelylongtextexamples,the
frustrationordisbelief?
‚Äì Men‚ÄôsPerceptionofUnfairTreatment:Doesthetextexample scoringprocedureachievesrelativelystrongperformanceresults.
discussmenfeelingtreatedunfairlyinsociety? However,thisperformancevariesquitewidelybothacrossdatasets
‚Äì SeekingExplanation:Doesthetextexampleseekanexplanation andacrossconceptswithinadataset.
foracertainbehavior? To provide a point of comparison on this variability, we cal-
‚Äì StereotypingWomen:Doesthetextexampleinvolvestereotyping culated inter-rater reliability between LLooM and each human
women? annotatoraswellasbetweenthetwohumanannotators(A1and
‚Ä¢ UISTAbstractsdataset: A2).Acrossthefourconcepts,Cohen‚ÄôsùúÖbetweenthetwohuman
‚Äì ApplicationofPrototypeSystem:Doesthetextexamplediscuss
annotatorswas0.64;meanwhile,theIRRbetweenLLooMandA1
theapplicationofaprototypesystemtovariousinterfaces?
was0.63,andtheIRRbetweenLLooMandA2was0.645.Thus,
‚Äì Pen-likeInputandInteraction:Doesthetextexampleinvolve
LLooM‚Äôsannotationsperformquitecomparablytothatofother
precisepen-likeinputandhandleinteraction?
humanannotators.Per-conceptIRRvaluesarereportedinTable2.
‚Äì UserExperienceEnhancement:Doestheexampledescribeaprod-
uctortechnologythatenrichestheuser‚Äôsexperience? QualitativelyanalyzingerrorcaseswhereLLooMdisagreedwith
‚Äì VREvaluation:Doesthetextexampleinvolveevaluatingand humanannotators,wefindthattheLLooMannotationsgenerally
improvingimmersioninVR? appearedreasonable;theytendedtobeplausible,butdiffering,in-
terpretationsofthetext.ForfalsepositiveswhereLLooMmarked
8Weonlyconservativelyclassifyexamplesaspositiveonlyiftheyreceiveanannota-
documentsasmatchingaconceptwhilethehumanannotator(A1)
tionof‚Äústronglyagree,‚Äùthemostconfidentlabeloption.Allotherlabeloptionsare
considerednegative. didnot,differencesseemedtostemfromdifferingthresholds ofConceptInduction:AnalyzingUnstructuredTextwithHigh-LevelConceptsUsingLLooM CHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA
Classification Metrics Batch Size 1
Accuracy Recall Precision F1-Score
1.0 Dataset
NeurIPS Statements
0.8 Partisan Animosity
Toxic Content
0.6 UIST Abstracts
0.4
0.2
0.0
NeurIPS
PS at rta it se am n e Ant nis Tom xo is ci t Uy ICo Sn Tt e An bt Nst er ua rc It Ps
S
PS at rta it se am n e Ant nis Tom xo is ci t Uy ICo Sn Tt e An bt Nst er ua rc It Ps
S
PS at rta it se am n e Ant nis Tom xo is ci t Uy ICo Sn Tt e An bt Nst er ua rc It Ps
S
PS at rta it se am n e Ant nis Tom xo is ci t Uy ICo Sn Tt e An bt stracts
Figure15:ConceptClassificationMetrics.AcrossthefourLLooMscenariodatasets,weobservehighaccuracy.Thereissubstantial
varianceinclassificationpIeRrRf oMremtricasn bcye Cboontchepatcrossdatasetsandacrossconceptswithinadataset.
Concept
Advocacy Event Political Party Positions Social Justice Focus Table2:WeobservethatLLooMachievesinter-raterreliabil-
1.0 IRR Paiitrylevels(Cohen‚ÄôsùúÖ)comparabletothatofhumanannotators
LLo(oAM 1vs.a An1dA2).Agreementismoderatetohigh.
0.8 LLooM vs. A2
A1 vs A2
0.6 Concept A1-A2 LLooM- LLooM-
A1 A2
0.4
Advocacy:Doesthetextexample 0.60 0.74 0.78
0.2 advocateforacauseorissue?
0.0 Event: Is this text example re- 0.57 0.69 0.57
A1 v Ls
LA o2
oM vs L.
LA o1
oM vs.
A2
A1 v Ls
LA o2
oM vs L.
LA o1
oM vs.
A2
A1 v Ls
LA o2
oM vs L.
LA o1
oM vs.
A2
A1 v Ls
LA o2
oM vs L.
LA o1
oM vs.
A2 l Pa ote lid tit co alan Pae rv te ynt P?
ositions: Does 0.67 0.63 0.70
thetextexamplementionthepo-
sitionsoractionsofpoliticalpar-
Figure 16: Per-Concept Inter-rater Reliability. Across the
ties?
fourconcepts,wefindsimilar,moderate-to-highCohen‚ÄôsùúÖ
Social Justice Focus: Does the 0.64 0.46 0.53
valuesforthepairofhumanannotators(A1andA2)andfor
textexampleemphasizeworking
LLooMwhenpairedwitheachhumanannotator.
towardsajustfuture?
conceptmatching.Ingeneral,LLooMwasmorelikelytolabelex-
amplesaspositiveforaconcept,especiallyforborderlinecases.
However,itsdecisionsseemtofallwithinaagreyareaofreason-
abilitygiventhesubjectivenatureofmanyoftheseconcepts.For
example,thefollowingexamplewaslabeledbyLLooMaspositive
fortheAdvocacyconceptwhilethehumanannotatormarkedthe LLooMlabeledtheexampleasnegative:‚Äú[...]Iwillbeworking
example as negative: ‚ÄúToday was made possible because of the tomakesureHeadStart&EarlyHeadStarthastheresourcesit
PennsylvaniaDemocratswhoorganized,knockeddoors,donated, needstoservethousandsofchildreninMiddleGA.‚ÄùThetextdid
andvoted.‚ÄùInthiscase,thetextimplicitlyreferencescausesor notexplicitlyadvocateforacauseoraskotherstojoinwiththe
issuesthataresupported,butdoesnotexplicitlyadvocatefora typicallanguageofadvocacy,butitmentionedaparticulargov-
cause.Thissubjectivitycouldreasonablyleadtodifferinglabels. ernmentprogram(HeadStart)thatpromotesschoolreadinessfor
Meanwhile,forfalsenegativeswherethehumanannotatormarked pre-school-agechildrenfromlow-incomefamilies.Theannotator
documentsasmatchingaconceptwhileLLooMdidnot,acommon hadthisknowledgeandinterpretedthetextasadvocatingforthis
trendwasthattheexamplesrequiredadeeperlevelofexpertise cause,whiletheLLMmaynothavehadthiscontext.
orappreciationofnuance.ThismaybeafailuremodeforLLMs Overall,thisevaluationanderroranalysissupportsearlierevi-
likeGPT-3.5,whichunderliestheLLooMScoreoperator.Forexam- dencethatLLooMperformsannotationatalevelcomparabletothat
ple,withthesameAdvocacyconceptabove,thefollowingexample ofanotherhumanannotator,butthatitcannotavoidtheinherent
(excerpted)waslabeledbythehumanannotatoraspositivewhile disagreementthatwillarisefromsubjectiveannotationtasks[23].
appaK
s'nehoC
erocSCHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA M.S.Lam,J.Teoh,J.A.Landay,J.Heer,M.S.Bernstein
Figure17:SampleofWikiDatasetresultsforLLooMandbaselinemethods.
C.3 TechnicalEvaluation:ConceptGeneration (1) Generic:ElectionCampaigns,Specific:Fundraising,Candidate
Outputs Profiles,PoliticalRallies,CampaignPromises
(2) Generic:GovernmentPolicies,Specific:HealthcarePolicies,Edu-
WeincludesampleoutputsforLLooM,BERTopic,GPT-4,andGPT-4-
cationPolicies,InternationalRelationsPolicies,EconomicPolicies
Turboonthebenchmarkdatasets(WikiandBills)andthesynthetic (3) Generic:PoliticalParties,Specific:PartyPlatforms,PartyLeader-
datasetfromthetechnicalevaluationinSection5.Foreachdataset, ship,PartyHistory,PartyFactionalism
wesampledthreegroundtruthtopics.Then,foreachofthefour (4) Generic:HumanRights,Specific:LGBTQ+Rights,Women‚ÄôsRights,
methods,wesampleduptothreegeneratedconceptsthatmatched RacialEquality,Children‚ÄôsRights
thegroundtruthtopicfromacrossalltrials.Wedisplaytheresults (5) Generic:Immigration,Specific:BorderControlPolicies,Refugee
fortheWikidatasetinFigure17forthe‚ÄúVideogames,‚Äù‚ÄúEngineer- Policies,ImmigrationReform,IllegalImmigration
ingandtechnology,‚Äùand‚ÄúMusic‚Äùconcepts.Wedisplaytheresults (6) Generic:Economy,Specific:Taxes,Unemployment,FiscalPolicy,
GovernmentSpending
fortheBillsdatasetinFigure18forthe‚ÄúTransportation,‚Äù‚ÄúEnvi-
(7) Generic:Healthcare,Specific:UniversalHealthcare,MentalHealth,
ronment,‚Äùand‚ÄúEducation‚Äùconcepts.Wedisplaytheresultsforthe
DrugPolicy,HealthInsurance
syntheticdatasetinFigure19forthe‚ÄúHealthcare,‚Äù‚ÄúImmigration,‚Äù
(8) Generic:Environment,Specific:ClimateChange,RenewableEn-
and‚ÄúEconomy‚Äùconcepts.
ergy,NatureConservation,AirPollution
(9) Generic:ForeignPolicy,Specific:TradeAgreements,Warand
Peace,DiplomaticRelations,InternationalAid
C.4 TechnicalEvaluation:SyntheticDataset
(10) Generic:GunControl,Specific:BackgroundChecks,AssaultWeapons
Concepts Ban,GunControlLegislation,SecondAmendmentRights
Togeneratethesyntheticdata,weusedthefollowingsetof10
Genericconceptsand40Specificconcepts:ConceptInduction:AnalyzingUnstructuredTextwithHigh-LevelConceptsUsingLLooM CHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA
Figure18:SampleofBillsDatasetresultsforLLooMandbaselinemethods.CHI‚Äô24,May11‚Äì16,2024,Honolulu,HI,USA M.S.Lam,J.Teoh,J.A.Landay,J.Heer,M.S.Bernstein
Figure19:SampleofSyntheticDatasetresultsforLLooMandbaselinemethods.