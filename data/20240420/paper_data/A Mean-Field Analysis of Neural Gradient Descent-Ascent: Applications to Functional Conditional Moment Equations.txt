A Mean-Field Analysis of Neural Gradient Descent-Ascent:
Applications to Functional Conditional Moment Equations
Yuchen Zhu∗ Yufeng Zhang † Zhaoran Wang ‡ Zhuoran Yang§
Xiaohong Chen¶
Abstract
We study minimax optimization problems defined over infinite-dimensional function classes. In
particular, we restrict the functions to the class of overparameterized two-layer neural networks
andstudy (i) the convergenceof the gradientdescent-ascentalgorithmand(ii) the representation
learning of the neuralnetwork. As an initial step, we consider the minimax optimization problem
stemmingfromestimatingafunctionalequationdefinedbyconditionalexpectationsviaadversarial
estimation,wheretheobjectivefunctionisquadraticinthefunctionalspace. Forthisproblem,we
establishconvergenceunderthemean-fieldregimebyconsideringthecontinuous-timeandinfinite-
widthlimit ofthe optimizationdynamics. Under this regime,gradientdescent-ascentcorresponds
to a Wasserstein gradient flow over the space of probability measures defined over the space of
neural network parameters. We prove that the Wasserstein gradient flow converges globally to a
−1 −1
stationarypointoftheminimaxobjectiveata (T +α )sublinearrate,andadditionallyfinds
O
the solution to the functional equation when the regularizer of the minimax objective is strongly
convex. Here T denotes the time and α is a scaling parameter of the neural network. In terms
of representationlearning, our results show that the feature representationinduced by the neural
−1
networksisallowedtodeviatefromtheinitialonebythemagnitudeof (α ),measuredinterms
O
of the Wasserstein distance. Finally, we apply our general results to concrete examples including
policy evaluation, nonparametric instrumental variable regression,and asset pricing.
∗Georgia Instituteof Technology. Email: yzhu738@gatech.edu.
†Northwestern University. Email: yufengzhang2023@u.northwestern.edu.
‡Northwestern University. Email: zhaoranwang@gmail.com.
§Yale University. Email: zhuoran.yang@yale.edu.
¶Yale University. Email: xiaohong.chen@yale.edu.
1
4202
rpA
81
]GL.sc[
1v21321.4042:viXra1 Introduction
Minimax optimization problems are ubiquitous in machine learning, statistics, economics, and
other fields. Examples include generative adversarial networks (GANs) (Goodfellow et al., 2020;
Salimans et al., 2016), adversarial training (Ganin et al., 2016; Madry et al., 2017), robust opti-
mization(Ben-Tal et al.,2009;Levy et al.,2020),andzero-sumgames(Xie et al.,2020;Zhao et al.,
2022). Thegoalinminimaxoptimizationistofindasolution(f∗,g∗)totheproblemmin max (f,g),
f∈F g∈G
L
where isabivariateobjectivefunction and and arethefeasiblesetsofthedecisionvariables
L L F G
f and g. In modern machine learning applications, and are often function classes parameter-
F G
ized by neural networks, the objective (f,g) can be approximated using data, and the minimax
L
optimization problem is solved using first-order optimization algorithms.
While minimax optimization problems are well-studied in the literature, most of the existing
works focus on the case where and are subsets of finite-dimensional Euclidean spaces, and the
F G
objective (f,g) enjoys certain convexity and concavity properties. However, when and are
L F G
parametric function classes such as neural networks, the objective (f,g) is nonconvex-nonconcave
L
with respect to the network parameters, and it seems unclear whether first-order optimization
algorithms converge.
In this work, we study the convergence of first-order optimization algorithms for solving min-
imax optimization problems with neural networks. In particular, as an initial step, we focus on
arguably the simplest minimax objective function, which is a linear function of f and quadratic
function of g, up to regularization. Such an objective function arises in solving functional condi-
tional moment equations, which finds ample applications such as policy evaluation, nonparamet-
ric instrumental variable regression, and asset pricing (Ai and Chen, 2003; Blundell et al., 2007;
Chen and Pouzo, 2009, 2012; Chen and Christensen, 2018; Cai et al., 2019; Chernozhukov et al.,
2020; Duan et al., 2020; Xu et al., 2020a; Jin et al., 2021; Chen and Qi, 2022; Ramprasad et al.,
2022; Chernozhukov et al., 2022; Xu et al., 2020a).
Inparticular,afunctionalconditionalmomentequationreferstoanequationininfinite-dimensional
function space whosesolution is a function, and the coefficients of theequation aregiven by (condi-
tional) expectations involving observed random variables. As a simple example, in nonparametric
regression, the goal is to find a function f∗ that solves the equation E[X Z = ] = f∗(), where
| · ·
X is the response and Z is the covariate. This equation is defined in terms of the conditional
2expectation of X given Z. As another important example in economics and causal inference, in
nonparametric instrumental variable regression, the goal is to find a function f∗ that solves the
equation E[X f∗(X )Z = ] = 0, where X is the response, X is the endogenous covariate,
r e r e
− | ·
and Z is exogenous covariate (i.e., conditioning instrumental variables). This equation is defined
in terms of the conditional expectation of X = (X ,X ) given Z. In general, a functional condi-
r e
tional moment equation can be written as E[Φ(X,Z;f)Z = ] = 0, where X denotes the set of all
| ·
endogenous variables, Z denotes the set of all exogenous variables, f is a unknown function, and
Φ(x,z;f) is a scalar-valued mapping that takes x, z, and f as inputs and outputs a scalar. For
simplicity, we focus on linear equations where Φ is a linear function of f.
Given i.i.d. observations of (X,Z), our goal is to design an optimization algorithm that ef-
ficiently finds the solution f∗ to equation E[Φ(X,Z;f)Z = ] = 0 from data using overparam-
| ·
eterized two-layer neural networks. Specifically, a neural network is represented by f(;θ) =
·
α/N N φ(;θi), where N is the number of neurons, φ(;θi) denotes the i-th neuron, θi
i=1 · · { }i∈[N]
are thPe network parameters, and α is a scaling parameter. To formulate this problem as a mini-
max optimization problem, we adopt the adversarial estimation approach (Chernozhukov et al.,
2020; Liao et al., 2020; Wai et al., 2020), which introduces a dual function g that is a func-
tion of z, and considers a minimax optimization problem with the objective function (f,g) =
L
E g(Z) Φ(X,Z;f) 1/2 g(Z)2 +Reg(f) , where Reg(f) is a regularizer that penalizes the com-
· − ·
pl(cid:2)exityoff. Forsuchanobjective, weconsi(cid:3)derthearguablysimplestfirst-orderalgorithm, gradient
descent-ascent (GDA), where both f and g are represented by over-parameterized two-layer neural
networks.
Specifically, we aim to address the following two questions:
• Does GDA with over-parameterized neural networks converge to some solution?
• Does GDA learn data-dependent features that yield a statistically accurate solution?
Answering these two challenges involves two intricate challenges in terms of optimization and
representationlearningusingneuralnetworks. Second,theminimaxobjectiveisnonconvex-nonconcave
with respect to the network parameters of f and g, it is unclear whether first-order algorithms
converge. Second, the representation of the neural network evolves during the course of optimiza-
tion, and it is unclear how to track and assess the data-dependent features learned by the neural
networks. While some of the existing works on neural network optimization use the technique
3of neural tangent kernel (NTK) (Jacot et al., 2018; Du et al., 2018; Cai et al., 2019; Xu and Gu,
2020; Wang et al., 2022), which suggests that the feature representation of the neural networks is
fixed throughout training and is only determined by the initialization of the network parameters.
Despite an elegant theoretical framework, the NTK approach is limited in its ability to capture the
representation learningaspectofneuralnetwork optimization. Toshowthattheneuralnetwork op-
timization algorithms learn usefuldata-dependentfeatures, in addition toestablishingconvergence,
more importantly, we need to show that (i) the algorithm approximately finds a proper solution
concept, e.g., a stationary point or a local or global optimizer of the minimax objective function,
and (ii) the representation of the neural networks moves from the initialization by a considerable
amount.
As we will show in the sequel, we tackle both challenges leveraging the framework of mean-field
analysis of over-parameterized neural networks (Chizat and Bach, 2018; Mei et al., 2018, 2019;
Zhang et al., 2020; Lu et al., 2020b; Zhang et al., 2021). In particular, we focus on the continuous-
time and infinite width limit of the GDA algorithm, where the stepsize goes to zero and the
width N goes to infinity. From the mean-field lens, a neural network f(;θ) can be identified
·
with a probability measure µ by writing f(;θ) = α φ(;θ) µ(dθ), where µ is the empirical
· · θ ·
distribution of θi and α is the scaling parameterRof the neural network. Thus, parameter
i∈[N]
{ }
updates of GDA can be regarded as updates of the probability measure µ. From this perspective,
we prove that in the continuous-time and infinite width limit, GDA corresponds to a gradient flow
of the minimax objective in the Wasserstein space, i.e., the space of probability measures over
L
the parameter space equipped with the second-order Wasserstein distance. Besides, by defining
a proper potential function that characterizes the stationary point of the minimax objective, we
prove that the Wasserstein gradient flow converges to a stationary point at a sublinear rate of
(1/T + 1/α), where T is the time horizon. Moreover, we prove that the Wasserstein distance
O
betweentheparameterdistributionfoundbyGDAanditsinitialization is (α−1),whichshowsthat
O
therepresentationoftheneuralnetworksisallowedtomovefromtheinitialization byaconsiderable
amount and such behavior is not captured by the NTK analysis, where the representation is shown
to be fixed at the initialization. Furthermore, when the regularization on f satisfies a version of
strong convexity, we prove that the Wasserstein gradient flow converges to the global optimizer f∗
at a sublinear (1/T +1/α) rate.
O
4To our best knowledge, our work provides the first theoretical analysis of an optimization algo-
rithm solving functional conditional moment equations using neural networks with representation
learning. We apply our general theory to four important examples: policy evaluation, instrumental
variables regression, asset pricing, and adversarial Riesz representer estimation. In these examples,
weprovethattheGDAalgorithmfindstheglobally optimalvaluefunction,linkfunctions,nonpara-
metric structural demand function, and Riesz representer, respectively, with over-parameterized
neural networks. Moreover, GDA learns data-dependent features that enable these statistically
accurate estimators.
1.1 Closely Related Literature
Minimax Optimization. Minimax optimization has emerged as a cornerstone in the field of
machine learning, particularly in the context of adversarial training, game theory, and robust
optimization. The seminal work of von Neumann laid the foundational theory of the minimax
theorem, which has since been extended and applied to various machine learning paradigms. No-
tably, Goodfellow et al. revolutionized the field with the introduction of Generative Adversarial
Networks (GANs), which employ a minimax optimization framework to train generative models
(Goodfellow et al., 2020; Salimans et al., 2016). This has spurred a plethora of research explor-
ing the theoretical and practical aspects of minimax optimization in machine learning. Recent
advancements have focused on improving the algorithmic stability and convergence properties of
minimax optimization algorithms. A sequence of works has provided insights into the gradient
complexity and efficiency of first-order algorithms in finding ε-saddle points or stationary points
(Jin et al., 2020; Lin et al., 2020b; Daskalakis and Panageas, 2018; Lu et al., 2020a; Zhao, 2023;
Ouyang and Xu, 2021; Ostrovskii et al., 2021). Derivative-free optimization methods have also
gained significant attention in the community of minimax optimization to tackle scenarios where
gradient information is unavailable or impractical to compute. Extensive and active research has
been conducted to analyze the convergence rate and practicality of these zero-order algorithms
(Liu et al., 2019; Wang et al., 2020; Xu et al., 2020b; Huang et al., 2022). The ongoing research
continues to unravel the multifaceted nature of minimax optimization, highlighting its significance
and potential in shaping the future of machine learning.
5Adversarial Estimation/learning. Theincorporationofadversarialcomponentsintoalgorithms
has exhibited substantial potential in machine learning. This potential is exemplified by the emer-
gence of generative adversarial networks (GAN) (Goodfellow et al., 2020; Salimans et al., 2016),
adversarial training (Ganin et al., 2016; Madry et al., 2017), and its extension into reinforcement
learning (Omidshafiei et al., 2017; Silver et al., 2017). Notably, this paradigm shift has also found
meaningfulapplicationsintherealmofnon-parametricstatisticsandcausalinference. Withinthese
domains, the task of estimating models defined by conditional moment equations can be reformu-
lated into more manageable unconditional formulations (Dikkala et al., 2020; Chernozhukov et al.,
2020;Wai et al.,2020). Inthiscontext, theestimationproblemassumesthecharacter ofazero-sum
game involving a player engaged in optimizing over the hypothesis space and an adversary respon-
sible for identifying violations of moment equations within a test function space. This perspective
also establishes a connection with the extensive literature on minimax optimization, which is of-
ten amenable to solution through primal-dual type algorithms (Luo et al., 2020; Lin et al., 2020a;
Ding et al., 2023).
Mean-field Analysis in Deep Learning. This study intersects with the burgeoning field of
over-parameterized neural networks. Recent findings underscore the efficacy of gradient-based al-
gorithmsintrainingover-parameterizedneuralnetworks(Jacot et al.,2018;Chizat and Bach,2018;
Allen-Zhu et al., 2019a,b; Lu et al., 2020b). This analytical perspective is colloquially termed as
“lazy training” for neural networks. Another prominent line of inquiry employs the mean-field
approach. Such an analysis delves into the dynamism inherent in infinite-dimensional function
spaces, a phenomenon that can be rigorously captured using non-linear partial differential equa-
tions (PDEs). By elevating these dynamics to an infinite dimensional realm, the problem not only
becomes more tractable but also assumes a convex nature, which yields more favorable mathemat-
ical attributes for nuanced analysis. This methodology finds profound resonance in contemporary
machine learning and optimization literature, particularly for establishing the global convergence
of algorithms (Mei et al., 2018, 2019; Zhang et al., 2020, 2021; Fang et al., 2021). To the best of
our knowledge, our paper is the first to apply the mean-field limit to study the convergence of
algorithms in solving functional conditional moment equations using neural networks.
62 Preliminaries
Thefunctionalconditionalmomentequationscover manyimportantexamplesinstatistics, machine
learning, economics, and causal inference. In this section, we first introduce the general formula-
tion of the functional conditional moment equations and then reformulate them into a minimax
optimization problem. Then, we present a few concrete examples of function conditional moment
equations such as policy evaluation, nonparametric instrumental variables regression, asset pricing,
and Riesz representers estimation.
Finally, we introduce the background of mean-field neural networks and Wasserstein space,
which are essential for the convergence analysis of the GDA algorithm.
2.1 Functional Conditional Moment Equations
In this section, we introduce the general formulation of functional conditional moment equations.
Let X be a vector that includes all the endogenous variables, let Z denote all the
∈ X ∈ Z
exogenous variables, andlet P( )denotethejointdistributionof(X,Z). Let
D ∈ X×Z W ⊆ X×Z
be a subset of variables that may contain both the endogenous and exogenous variables, and let
L2(W) denote a Hilbert space of measurable functions of W with finite second moment. Let
:= f : R L2( ) denote a class of functions defined on . In a functional conditional
F { W → }⊂ W W
moment equation problem, we aim to find a function f that solves the following functional
0
∈ F
equation involving the conditional distribution of X given Z over :
F
E Φ(X,Z;f ) Z = z = 0, z , (2.1)
X|Z 0
∀ ∈ Z
(cid:2) (cid:12) (cid:12) i
whereΦ: R is a known function(cid:12)al. Here we useE to indicate that theexpectation
X|Z
X×Z×F →
in (2.1) is taken with respect to the conditional distribution of X given Z.
For any function f and any z , we define a functional δ¯: R as
∈F ∈ Z Z ×F →
δ¯(z;f) := E Φ(X,Z;f) Z = z , f ,z . (2.2)
X|Z
∀ ∈ F ∈ Z
(cid:2) (cid:12) (cid:3)
(cid:12)
In other words, the conditional moment equation problem in (2.1) boils down to finding a function
f such that δ¯(;f ) is a zero function on . Therefore an equivalent way to solve f in
0 0 0
∈ F · Z ∈ F
(2.1) is by solving
inf E[(δ¯(Z;f))2]
f∈F
7(Ai and Chen, 2003; Chen and Pouzo, 2012). To control the complexity of the function class ,
F
Ai and Chen (2003) proposed to use flexible sieve spaces that becomes dense in as the
k(n)
F F
sieve dimension k(n) grows to infinity with data sample size n, and proposed the so-called sieve
minimum distance criterion
min E δ¯(Z;f)2 /2,
f∈Fk(n)
(cid:2) (cid:3)
In particular, Ai and Chen (2003) allows for two-layer NNs, splines, wavelets, Fourier series, and
all kinds of polynomial sieves to approximate functions in L2( ). Alternatively
k(n)
F F ⊂ W
(Chen and Pouzo, 2012) proposes the following penalized (or regularized) minimum distance crite-
rion:
minE δ¯(Z;f)2 /2+λ (f), (2.3)
f∈F ·R
(cid:2) (cid:3)
where λ 0 is a regularization parameter, (f) is a regularizer on function f . They allow
≥ R ∈ F
that (f) to be any convex or lower-semicompact regularizer. In the minimum distance approach,
R
for any fixed f, the authors first estimate δ¯(z;f) by the following least squares criterion:
1 1
argminE Φ(X,Z;f) δ(Z) 2 = argmaxE Φ(X,Z;f)δ(Z) δ(Z)2
2 − − 2
δ∈L2(Z) δ∈L2(Z)
h (cid:0) (cid:1) i h i
Furthermore, we assume that the functional Φ is affine in f, which captures several important
applications in machine learning and causal inference listed in Section 2.2. Specifically, we define
Φ(x,z,f) = Φ(x,z,f) Φ(x,z,0), where 0 stands for the zero function on . Then for any two
− W
functions f ,f and any a,b R, we have
e 1 2
∈ F ∈
Φ(x,z;af +bf ) = a Φ(x,z;f )+b Φ(x,z;f ), (x,z) . (2.4)
1 2 1 2
· · ∀ ∈ X ×Z
e e e
Solving (2.1) with Over-parameterized Neural Networks. In the sequel, we aim to solve
the problem in (2.1) based on i.i.d. data points sampled from , with being a class of over-
D F
parameterized neural networks. In this case, it is possible that (2.1) does not have a solution
within .
F
For the choice of regularizer, we consider the following specific form of (f):
R
(f)= E [Ψ(X,Z;f)] (2.5)
D
R
8where for any given (x,z) , Ψ(x,z;f) : R is a convex functional of f that satisfies
∈ X ×Z F →
Ψ(x,z;0) = 0, Ψ(x,z;f) 0, f , (2.6)
≥ ∀ ∈ F
δΨ(x,z;af +bf ) δΨ(x,z;f ) δΨ(x,z;f )
1 2 = a 1 +b 2 , f ,f , a,b R. (2.7)
1 2
δf · δf · δf ∀ ∈ F ∈
HereweuseE todenotethattheexpectation in(2.5)istakenwithrespecttothedatadistribution
D
, which is the joint distribution of X and Z. Equation (2.6) requires that Ψ(X,Z;f) is a non-
D
negative functional of f that is equal to 0 if and only f = 0. Equation (2.7) requires that the
functional derivative of Φ(X,Z;f) with respect to f, is again a linear mapping of f. One example
of Ψ is the L -regularizer of the following type, Ψ(x,z;f) = f(w)2. Here w is a subset of
2
∈ W
variables that contain values from both the endogenous variables x and exogenous variables z.
Minimax Estimation. To solve the optimization problem in (2.3), we first move to an uncondi-
tional moment formulation by introducing test functions inthe instruments. To simplify notations,
in the sequel, we use E to denote the expectation taken with respect to X, Z solely as well as the
D
expectation with respect to the joint distribution of (X,Z) without distinguishing their differences.
By Fenchel duality, we rewrite the objective function J(f) as follows,
J(f) = E 1/2 δ¯(z;f)2+λΨ(X,Z;f) (2.8)
D
·
h i
= E max g(z) E Φ(X,z;f) z 1/2 g(z)2 +λΨ(X,Z;f)
D
g:Z→R · − ·
h (cid:2) (cid:12) (cid:3) i
= max E g(Z) Φ(X,Z;f) (cid:12)1/2 g(Z)2 +λΨ(X,Z;f) .
D
g:Z→R · − ·
h i
The formulation in (2.8) motivates us to consider the following minimax optimization problem,
minmax (f,g) = E g(Z) Φ(X,Z;f) 1/2 g(Z)2 +λΨ(X,Z;f) . (2.9)
D
f g L · − ·
h i
We note that is a convex-concave functional with respect to function f and g. We denote by
L
(f∗,g∗) the unique saddle point of (2.9). Without the regularization, i.e., λ = 0, the saddle point
of (2.9) is f∗ = f and g∗ = 0.
0
2.2 Examples of Functional Conditional Moment Equation
In this section, we discuss several important examples of the functional conditional moment equa-
tion to further motivate the significance of such generalization and introduction of this concept.
9Policy Evaluation. We consider a Markov decision process given by ( , , ,r,γ), where
S A P
Rd is the state space, is the action space, : P( ) is the transition kernel,
S ⊆ A P S × A → S
r : [0,1] is the reward function, γ (0,1) is the discount factor. Given a policy
S × A → ∈
π : P( ), an agent interacts with the environment in the following manner. At a state
S → A
x , the agent takes an action a π( s ) and receives a reward r = r(s ,a ). Then, the agent
t t t t t t
∼ ·|
transits to the next state s ( s ,a ). We denote the transition kernel induced by policy π
t+1 t t
∼ P ·|
by π(s′ s)= (s′ s,a)π(a s)da for any s,s′
P | AP | | ∈ S
In policy evRaluation, we aim to estimate the value function Vπ : R defined as follows,
S →
∞
Vπ(s)= E γir(s ,a ) s = s ,
π i i 0
hXi=0 (cid:12) i
(cid:12)
where the expectation E is taken with respect to a π((cid:12) s ) and s ( s ,a ) for t 0.
π t t t+1 t t
∼ ·| ∼ P ·| ≥
By the Bellman equation (Sutton and Barto, 2018), it holds for any s that
∈ S
Vπ(s) πVπ(s)= 0, πf(s)= E a∼π(·|s) r(s,a) +γE s′∼Pπ(·|s) f(s′) . (2.10)
−T T
(cid:2) (cid:3) (cid:2) (cid:3)
Corresponding to the Bellman equation in (2.10), let denotes the joint distribution of the state-
D
action tuple (s,a,s′) under policy π, the value function Vπ satisfies the following functional condi-
tional moment equation,
E s′|s r(s,a) Vπ(s)+γ Vπ(s′) s = 0. (2.11)
− ·
h (cid:12) i
(cid:12)
We notice that (2.11) is a special case of the functional cond(cid:12)itional moment equation in (2.1) by
setting the exogenous variable Z to be the current state s, the endogenous variable X to be the
next state s′ and the function to be estimated f : R to be defined on the state space . In
S → S
this case, the functional is Φ(X,Z;f) = r+γ f(X) f(Z), where r is the reward function. We
· −
remark that the reason function f can be evaluated simultaneously on X and Z is that both X
and Z are variables defined on . Following the same derivation of (2.8), the problem of policy
S
evaluation is equivalent to the following minimax optimization problem,
minmax (f,g) = E g(Z) r+γ f(X) f(Z) 1/2 g(Z)2+λΨ(X,Z;f) .
D
f g L · · − − ·
h i
(cid:0) (cid:1)
Nonparametric Instrumental Variables Regression. The nonparametric instrumental vari-
ables model is common and useful in statistics and economics, which is also the starting point of
10the generalization discussed in this work. The model can be described simply by a line of equation
Y = f (X)+ε, E ε Z = 0.
0
(cid:2) (cid:12) (cid:3)
(cid:12)
where Y in an observed outcome, X is the endogenous variable, Z is the exogenous variable, f is
0
thetruemodelthatcharacterize therelationshipbetween Y andX andis alsothefunctionwewant
to estimate. In this model, ε is a noise possibly correlated with the endogenous X but uncorrelated
with the exogenous Z. It’s straightforward to see that NPIV model fits into the framework of the
functional conditional moment equation by plugging the model equation into the equation about
ε,
E Y f (X) Z = 0. (2.12)
D 0
−
h (cid:12) i
(cid:12)
We notice that (2.12) is a special case of functional conditional moment equation in (2.4) by
identifyingX,Z withtheendogenousandexogenousvariablerespectivelyandsettingthefunctional
asΦ(X,Z;f) = Y f(X). Followingthesamederivationof (2.8),theproblemofNPIVisequivalent
−
to the following minimax optimization problem,
minmax (f,g) = E g(Z) Y f(X) 1/2 g(Z)2 +λΨ(X,Z;f) .
D
f g L · − − ·
h i
(cid:0) (cid:1)
Asset Pricing. Asset pricing refers to the process of determining the fair value of financial
assets. This field is fundamental in finance and underpins much of the work in investment, portfo-
lio management, and risk assessment. Semiparametric Consumption Captial Asset Pricing Model
(CCAPM) is a foundational model in asset pricing that describes the relationship between sys-
tematic risk and expected asset returns, which also incorporates the influence of the consumption
preferenceofinvestorsovertime. Moreover, CCAPMcanbecharacterizedthroughafunctionalcon-
ditional moment equation (Chen et al., 2014; Chen and Ludvigson, 2009). To describe the model,
let C denotetheconsumption level at timet, c C /C theconsumptiongrowth. Themarginal
t t t t−1
≡
utility of consumption at time t is given by
MU =
C−γ0f
(c ),
t t 0 t
where γ > 0 is the discount factor, f : R is the nonparametric structural demand function,
0 0
C →
which is an unknown positive function of our interest and is defined on , the space of consumption
C
11growth. The unknown function f can be understood as a taste shifter that describes how the
0
marginal utility of consumption changes with the state of the economy in terms of consumption
growth.
Now, consider the growth-return tuple (c ,r ,c ) for t N+ with joint distribution ,
t t+1 t+1
∈ D
where c is the consumption growth at the current time t, and c is the consumption growth at
t t+1
e
the next time t+1. r is a modified return observed in this period, which is a known function
t+1
of the actual return r and the consumption growth c at time t+1. We consider the scenario
t+1 t+1
e
wherethe timeseries of consumptiongrowth c follows a time-homogenous Markov chain with
t t≥0
{ }
a smooth transition kernel. That being said, both conditional transition probabilities c c and
t+1 t
|
c c admit a smooth density function. The CCAPM model captures the behavior of f through
t t+1 0
|
the following functional conditional moment equation,
E r f (c ) f (c ) c = 0, (2.13)
ct+1|ct t+1
·
0 t+1
−
0 t t
(cid:2) (cid:12) (cid:3)
where the modified return can be
furthe
er expressed as r
=(cid:12)
δ r
c−γ0,
δ (0,1] is the rate of
t+1 0 · t+1 · t+1 0 ∈
time preference. We focus on a setting where R is a compact set, and the modified return r
t+1
C ⊆ e
isboundedforallt 0. Wenoticethat(2.13)isaspecialcaseofthefunctionalconditionalmoment
≥ e
equation in (2.4). We can identify theexogenous variable Z withc , theconsumptiongrowth at the
t
current time t, and the endogenous variable X with c , the consumption growth at the next time
t+1
t+1. In this scenario, we identify the space with , the space of consumption growth and the
W C
functiontobeestimatedf : Risdefinedon . ThefunctionalisΦ(X,Z;f) = r f(X) f(Z),
t+1
C → C · −
where r again denotes the modified return. Similar to the scenario of policy evaluation, the
t+1
e
reason function f can be evaluated simultaneously on X and Z is that both X and Z are variables
e
defined on . Following the same derivation of (2.8), the problem of asset pricing through CCAPM
C
is equivalent to the following minimax optimization problem,
minmax (f,g) = E g(Z) (r f(X) f(Z)) 1/2 g(Z)2+λΨ(X,Z;f)
D t+1
f g L · · − − ·
h i
e
Adversarial Riesz representer Estimation. Many problems in statistics, causal inference,
and finance involve learning a continuous linear functional of the following form,
(g) = E m(V;g) . (2.14)
V
(cid:2) (cid:3)
12where function g : R, is defined on a function space , and V is a random vector of
∈ G X → F G
which we have access to observations and represents the source of randomness in the functional.
Moreover, suppose such continuous linear functional () is also mean-square continuous with
F ·
respect to L2 norm. In that case, it can be written in a more benign and useful manner, which is
also often the case. Formally speaking, this means that, for such linear functional , there exists
V
function f such that for any g ,
0
∈ G
(g) = E f (X)g(X) . (2.15)
0
V
(cid:2) (cid:3)
The function f here is called the Riesz representer of the linear functional , and the equation
0
V
(2.15) is known as the Riesz representation theorem. Information aboutthe Riesz representation of
such linear functional is crucial to lots of applications and learning problems. Therefore, we want
to estimate f by exploiting the relationship characterized by the equation. We have the following
0
trivial observation that the true Riesz representer f can be recovered by solving the following
0
conditional moment equation.
E f (X) f(X) X = 0. (2.16)
0
−
h (cid:12) i
(cid:12)
Ofcourse, f = f willsolve theequationabove, andthereforethetrueRieszrepresenterisachieved.
0
We remark that this is indeed a special case since the expectation taken in (2.16) is unconditioned.
In the equation, we only involve the endogenous variable X, which also indicates that the exoge-
nous variable Z coincides with X. While special, the problem still fits in the framework discussed
here. By setting Φ(X,Z;f) = f(X) f (X), we recovered the intractable formulation of Riesz
0
−
representer estimation.
However, unlike the previous examples where have access to observations of each term in the
functional conditional moment equations, here we have no direct access to values of f , making the
0
problem seemingly intractable. Fortunately, the alternative formulation of the original problem as
a minimax optimization problem solves this difficulty. When written in the minimax formulation,
we will again see the linear functional show up in the equation in the form of (2.14), which
V
can be approximated using empirical values calculated from accessible observations of the random
vector V. Following the same derivation of (2.8) and the definition of Riesz representer in (2.15),
the problem of adversarial Riesz representer estimation is equivalent to the following minimax
13optimization problem,
minmax (f,g) = E m(V;g) f(X) g(X) 1/2 g(X)2 +λΨ(X,X;f) . (2.17)
D
f g L − · − ·
h i
Again, we stress that in (2.17), the absence of Z is due to the fact both the endogenous and
exogenous variables are described by X and the objective is computationally tractable since we
have access to both observations of X and V.
2.3 Mean-Field Neural Network and Wasserstein Space
In the sequel, we will consider functions in the neural network function class. Consider a neural
function defined on a given state space Ω, σ : Ω RD R that takes an input x Ω and
× → ∈
parameter θ RD and outputs a value in R. For θ = (θ ,...,θ ) where θ RD, we can define an
1 N i
∈ ∈
over-parameterized two-layered neural network function h using neuron function σ,
N
1
h(x,θ) = σ(x;θ ), x Ω.
i
N ∀ ∈
i=1
X
For suchaform,wecanfurtherconsidertheinfinitewidthlimitwhenN . Whentaking sucha
→ ∞
limit, theneuralnetworkfunctionhbecomesamean-fieldneuralnetwork andcanbeparameterized
with probability measure over the parameter space, µ P(RD).
∈
h(x;µ) = σ(x;θ)dµ(θ), x Ω.
RD ∀ ∈
Z
When considering such a limit, the optimization problem over the neural network function class
is turned from a finite-dimensional problem over the parameter space into an infinite-dimensional
problem over the space of probability measures. Therefore, we will need to track the convergence
of probability measures over the Wasserstein space when analyzing the convergence of algorithms.
In the sequel, we introduce the background knowledge of the Wasserstein space for the reader’s
information. Let P (RD) be the space of all the probability measures over the D-dimensional
p
Euclidean space RD with finite p-th order moments. The Wasserstein-p distance between two
probability measures µ,ν P (RD) is defined as follows,
p
∈
1/p
(µ,ν) = inf x y pdγ(x,y) γ P (RD RD),x γ = µ,y γ = ν , (2.18)
p p ♯ ♯
W k − k ∈ ×
(cid:26)(cid:16)Z (cid:17) (cid:12) (cid:27)
(cid:12)
where the infimum is taken over all the couplin(cid:12)g of µ and ν. Here we denote by x γ and y γ the
♯ ♯
marginal distributions of γ with respect to x and y, respectively. We call = (P (RD), ) the
p p p
M W
14Wasserstein-p space. For any 1 p q, due to the relation that E[X p]1/p E[X q]1/q, we have
≤ ≤ | | ≤ | |
that W (µ,ν) W (µ,ν) for two measures µ,ν. In this paper, we focus on the cases when p = 1,2.
p q
≤
Without further clarification, we refer to the distance with p = 2 as the Wasserstein distance in
the sequel.
The Wasserstein-2 space = (P (RD), ) can be viewed as an infinite-dimensional Rie-
2 2 2
M W
mannian manifold (Villani, 2008). Formally, the tangent space at point ρ P (RD) is defined
2
∈
as
Tan P (RD) = v L2(ρ) v,u dρ = 0, u L2(ρ) s.t. div(uρ) = 0 .
ρ 2
∈ h i ∀ ∈
(cid:0) (cid:1) n (cid:12) (cid:12) Z o
Then, for any absolutely continuous curv(cid:12) e ρ : [0,1] P (RD) on the Wasserstein-2 space, there
2
→
exists a family of vector fields v Tan (P (RD)) such that the continuity equation
t
∈
ρt 2
∂ ρ +div(v ρ )= 0 (2.19)
t t t t
holdsinthesenseofdistributions. For anytwo absolutely continuous curves ρ,ρ :[0,1] P (RD),
2
→
we define the inner product between ∂ ρ ,∂ ρ for any t [0,1] as follows,
t t t t
∈ e
e
∂ ρ ,∂ ρ = v ,v dρ , (2.20)
h
t t t t iρt
h
t t
i
t
Z
where v ,v is the inner product over
RDe
, (ρ ,v )
ande
(ρ ,v ) satisfy the continuity equation in
0 0 t t t t
h i
(2.19). Notethat(2.20)yieldsaRiemannianmetricover . Furthermore,theRiemannianmetric
2
e Me e
1/2
induces a norm ∂ ρ = ∂ρ ,∂ ρ .
k
t t kρt
h
t t t iρt
3 Algorithms
In this section, we introduce the gradient descent-ascent algorithm (GDA) and its mean-field limit,
which is characterized by continuity equations.
Gradient Descent-Ascent Algorithm. We solve the minimax optimization problem in (2.9)
via Gradient Descent-Ascent algorithm (GDA). Recall that in the minimax objective, we have
two functions simultaneously involved, where function f represents the true model of interest and
function g represents an adversarial player. Specifically, we parameterize both f and g with neural
15networks with width N and parameters θ = (θ1,θ2,...,θN) RD×N and ω = (ω1,ω2,...,ωN)
∈ ∈
RD×N
N N
α α
f(;θ) = φ(;θi), g(;ω) = ψ(;ωi). (3.1)
· N · · N ·
i=1 i=1
X X
where we use bold symbols θ and ω to denote the whole parameter used by each neural net and
unboldsymbolsθ and ω to denote theparameter used by each neuron. Here, φ(;θ) : RD R,
· W× →
ψ(;ω) : RD Rarethefunctionsforneurons. Inparticular, wecanrecover thegeneralsetting
· Z× →
of two-layer neural networks parameterization for f and g when we choose φ,ψ to be the following
specific form,
φ(w;β,W) = β σ (w;W), ψ(z;β,W) = β σ (z;W),
f g
· ·
whereσ : RD R, σ : RD R are activation functions with inputw and z respectively
f g
W× → Z× →
and parameters W. We note that it’s not necessary to choose the same width N for f and g, and
activation functions σ ,σ need not have the same parameter dimension D. Here we use the same
f g
width N and parameter dimension D to keep notations simple as these won’t affect the validity of
the results presented in this paper.
Besides, we introduce a scaling factor α > 0 in (3.1). Setting the scaling parameter α = √N
in (3.1) recovers the neural tangent kernel regime (Jacot et al., 2018). Setting the parameter
α = 1 recovers the mean-field regime (Mei et al., 2018, 2019). In a discrete-time finite-width (DF)
scenario, at thekth iteration, the primalfunction f andadversarial player g areupdatedas follows,
DF-GD: θ
k+1
= θ
k
η g(z k;ω k) θΦ(x k,z k;f(;θ k)) ηλ θΨ(x k,z k;f(;θ k)),
− · ·∇ · − ·∇ ·
DF-GA: ω
k+1
= ω
k
+η Φ(x k,z k;f(;θ k)) ωg(z k;ω k)) η g(z k;ω k) ωg(z k;ω k), (3.2)
· · ·∇ − · ·∇
where θ ,ω denotes the state of the parameters at iteration k, η > 0 is the step-size, and the data
k k
samples (x ,z ) ∞ are collected by independently samplingfrom the data distribution . When
{ k k }k=0 D
f,g are two-layered neural networks with width N, we can plug in the form for f,g as is described
in (3.1). The update for the parameter of i-th neuron at k-th iteration can be further specified to
the following,
δΨ(x ,z ;f(,θ ))
θi = θi ηαǫ g(z ;ω ) Φ(x ,z ;φ(,θi)) ηλǫ k k · k φ(x ;θi),
k+1 k − · k k ·∇θ k k · k − · δf ·∇θ k k
ωi = ωi +ηαǫ Φ(x ,z ;f(,θ )) ψ(z ;ωi) ηαǫ g(z ;ω ) ψ(z ;ωi), (3.3)
k+1 k · k k · k ·∇ω k k − · k k ·∇ω k k
16where θ = (θ1,θ2,...,θN) and ω = (ω1,ω2,...,ωN), δΨ/δf denotes the variation of Ψ with
k k k k k k k k
respect to f. Here, α is the neural network scaling parameter and ǫ = 1/N is the stepsize scale.
Both α and ǫ show up in (3.3) due to the finite width parameterization of two-layered neural
networks described in (3.1).
For a given space , let define a set of functions defined on R. For a functional defined
S H S →
over the function class , F : R, its variation at f is a function δF : R, such that
H H → ∈ H δf S →
for any test function h ,
∈ H
d δF
F(f +εh) = (s) h(s) ds. (3.4)
hdε iε=0 ZS δf ·
We initialize the parameters with θi µ and wi ν , with µ ,ν = (0,I ) be standard Gaus-
0 ∼ 0 0 ∼ 0 0 0 N D
sian distribution in RD. In addition, to keep track of the evolution of the parameter distribution,
we denote the empirical distribution of θ and ω at the kth iteration by,
N N
1 1
µ (θ) = δ (θ), ν (ω) = δ (ω),
k N θ ki k N ω ki
i=1 i=1
X X
b b
where δ is the Dirac mass function.
Mean-Field (MF) Limit. Toanalyze theconvergence of theGradientDescent-Ascent Algorithm
for solving functional conditional moment equations with neural networks, we employ an analysis
that studies the mean-field limit regime (Mei et al., 2018, 2019) of the discrete-time dynamics
described in (3.2). Here, by the mean-field limit, we are referring to an infinite-width limit, i.e.,
when N for the neural network width and a continuous time, i.e., t = kǫ where the step
→ ∞
scale ǫ 0 in (3.3). In what follows, we introduce the mean-field limit of the GDA dynamics,
→
which refers to the infinite-width and continuous limit of (3.3). For θ = θi N and ω = ωi N
{ }i=1 { }i=1
independently sampled respectively from µ,ν P(RD) probability distribution on the parameter
∈
space RD, we can write the infinite width limit of neural networks used in (3.1) as
f(;µ) = α φ(;θ)µ(dθ), g(;ν) = α ψ(;ω)ν(dω). (3.5)
· · · ·
Z Z
In the sequel, we denote by µ the distribution of θi and ν the distribution of ωi for the infinite-
t t t t
width and continuous limit of the neural networks at time t. For notational simplicity, we overload
the notation of the objective function in (2.9) via (µ,ν) = (f(;µ),g(;ν)). This is to further
L L · ·
emphasize the dependence of objective on (µ,ν) when we parameterize the function pair (f,g)
L
17using distributions on the parameter space. By Otto’s calculus (Villani, 2008), the mean-field limit
of the update direction takes the following form,
δ (µ,ν)
vf(θ;µ,ν) = L (θ)
θ
−∇ δµ
δΦ(X,Z;f(;µ)) δΨ(X,Z;f(;µ))
=αE g(Z;ν) · , φ(;θ) λ · , φ(;θ) ,
D − · δf ∇θ · L2 − · δf ∇θ · L2
(cid:21)
h (cid:10) (cid:11) D E
δ (µ,ν)
vg(ω;µ,ν) = L (ω)
ω
∇ δν
=αE Φ(X,Z;f(,µ)) ψ(Z;ω) g(Z;ν) ψ(Z;ω) . (3.6)
D ω ω
· ·∇ − ·∇
h i
Here , is the inner product on L2( ) with respect to the Lebesgue measure. Recall that
h·
·iL2
X ×Z
is the data distribution of random variables (X,Z) , we denote by ρ the density of
X,Z
D ∈ X ×Z D
with respect to the Lebesgue measure on and we use , to represent the inner product
D
X ×Z h· ·i
on L2( ) with respect to the probability distribution . That is to say, for any two function
X ×Z D
h ,h L2( ),
1 2
∈ X ×Z
h ,h = h h dρ .
1 2 D 1 2 X,Z
h i
ZX×Z
In the sequel, we will also slightly abuse this notation and use , to denote the inner product
D
h· ·i
on sub-spaces of L2( ), with the measure being the marginals of on these sub-spaces. In
X ×Z D
(3.6), δΦ/δf and δΨ/δf is the variation of Φ and Ψ over f under , , where the test functions
L2
h· ·i
are chosen over the function class . In the same way, δ /δµ and δ /δν respectively denote the
F L L
variation of the objective with respect to distributions µ and ν under , , following definition
L2
L h· ·i
in (3.4) with the test function chosen over P( ). We also remark that we can also define the
X ×Z
variation under , , which will only differ from the variation under , by a constant function
D L2
h· ·i h· ·i
factor that corresponds to the density of the marginals of .
D
Then,themean-fieldlimitoftheGDupdatein(3.2)ischaracterized bythecontinuity equation,
which is a system of PDEs given by,
∂ µ (θ)= η div µ (θ)vf(θ;µ ,ν ) ,
t t θ t t t
− ·
∂ ν (ω) = η div (cid:0) ν (ω)vg(ω;µ ,ν )(cid:1) , (3.7)
t t ω t t t
− ·
(cid:0) (cid:1)
where div , div Note that the initialization µ and ν are the same as the initialization of the
θ ω 0 0
discrete-time dynamics in (3.3), i.e. µ = (0,I ), ν = (0,I ) are taken to be the distribution
0 D 0 D
N N
of standard Gaussian random variables in RD.
184 Main Results
In this section, we introduce the main theoretical results of the gradient descent-ascent (GDA)
dynamics. We firstpresent the assumptions in §4.1. Then in §4.2 we show that the GDA dynamics
converge to a mean-field limit when the network with N goes to infinity and the stepsize scale ǫ
goes to zero. Finally, in §4.3 we prove that the mean-field limiting dynamics converge to a globally
optimal solution of the primal objective J under proper assumptions. Moreover, we will show that
the mean-field dynamics learns a data-dependent representation that is (α−1) away from the
O
initial representation.
4.1 Assumptions
We consider two types of assumptions in this work. The first type of assumption is about the func-
tion class in which we search for solutions to the minimax optimization problem. In this category,
Assumption 4.1 and Assumption 4.2 discuss the richness and regularity of the two-layered neural
network function class. The second type of assumption is about the feasible class of problems to
apply our framework. In this category, Assumption 4.3 discusses several technical assumptions on
the data space and the regularity/smoothness of the functionals.
We start with the discussion of the two-layered neural network function class. Consider the
neuron function φ and ψ with the following form,
φ(w;θ) = b(β) σ(θ⊤(w,1)), ψ(z;ω) = b(β) σ(ω⊤(z,1)), (4.1)
· ·
whereθ = (β,θ) R R1+dim(W),ω =e (β,ω) R R1+dim(Z) containse theparametersintheoutput
∈ × ∈ ×
layer and the hidden layer, b :R R is an odd re-scaling function and σ :R R is the activation
e
→ e →
function. Note that such a form of activation function satisfies the condition of universal function
approximation theorem (Theorem 3.1 in Pinkus (1999)) if σ is not a polynomial. For notational
simplicity, we write σ(w;θ) = σ(θ⊤(w,1)). The re-scaling function b : R R is introduced to
→
ensure that the value of the neural network is upper bounded. When b(R) = ( B ,B ), the
e e 0 0
−
function class induced by the neural network in (3.5) is equivalent to the following class,
= f : R f(w) = β′ σ(w;θ) dµ(β′,θ),µ P ( B ,B ) Rd+1 , (4.2)
2 0 0
F W → · ∈ − ×
n (cid:12)(cid:12) Z
e e
(cid:0) (cid:1)o
(cid:12)
19whered = dim( ). Thiscapturesarich function class dueto theuniversalfunctionapproximation
W
theorem (Barron, 1993; Pinkus, 1999). We remark that we introduce the re-scaling function b(β)
in (4.1) to avoid the study of the space of probability measures over ( B ,B ) Rd+1, which has
0 0
− ×
a boundary and thus lacks regularity in the study of optimal transport. Moreover, note that a
scaling hyperparameter α > 0 is introduced in the definition of the mean-field neural nets in (3.5).
When α > 1, this causes an effect of over-parameterization. In brief, α controls the error between
the (f(;µ ),g(;µ )) and optimizer (f∗,g∗) according to Theorem 4.7. Furthermore, the over-
t t
· ·
parameterization scale α has an influence through Lemma 4.6, which shows that the Wasserstein
distance between the Gaussian initialization (µ ,ν ) and the optimal distribution (µ∗,ν∗) is upper-
0 0
bounded by (α−1). Next, we impose the following regularity assumptions on the neural network
O
functions φ and ψ,
Assumption 4.1 (Regularity of Neural Networks). We assumethat thereexist absolute constants
B > 0, B > 0 and B > 0 such that
0 1 2
φ(w;θ) B , φ(w;θ) B , 2 φ(w;θ) B , w , θ RD,
| | ≤ 0 ∇θ ≤ 1 ∇θθ F ≤ 2 ∀ ∈ W ∈
|ψ(z;ω)
| ≤
B 0, (cid:13) (cid:13) ∇ωψ(z;ω)(cid:13) (cid:13)
≤
B 1, (cid:13) (cid:13) ∇2 ωωφ(z;ω)(cid:13) (cid:13)
F
≤B 2, ∀z
∈
Z, ω
∈
RD,
(cid:13) (cid:13) (cid:13) (cid:13)
where 2 , 2 denotes t(cid:13)he hessian(cid:13)with respe(cid:13)ct to θ and(cid:13)ω respectively, denotes the vector
∇θθ ∇ωω k·k
2 norm, and denotes the matrix Frobenius norm. Moreover, we assume that the rescaling
F
− k·k
function b : R R is odd and its range satisfies that b(R)= ( B ,B ).
0 0
→ −
Assumption 4.1 is satisfied by a broad class of neuron functions. For example, it is satisfied
when we set the activation function σ(x) = sigmoid(x) and rescaling function b(β) = tanh(β).
We also make the following assumption regarding the realizability of the saddle point solution
(f∗,g∗) to (2.9).
Assumption4.2(Realizability). Weassumethatthesaddlepointsolution(f∗,g∗)of (2.9)belongs
to the function class defined in (4.2), i.e., f∗,g∗ .
∈ F
Ingeneral, problem (2.9)may notadmita saddlepointwithin thegiven neuralnetwork. There-
fore, Assumption 4.2 is introduced to guarantee that the discussion in this paper is meaningful. By
universal function approximation theorem(Barron, 1993; Pinkus, 1999), the function class defined
in (4.2) captures a rich class of functions. Therefore, such an assumption is quite general and does
not restrict the influence of the applications of our results.
20We impose the following assumptions on the integrability of the functional Φ and Ψ and their
variations, as well as the compactness of the data space and .
X Z
Assumption 4.3 (Data regularity and Functional Integrability).
(i) For the data space , , we assume that is compact, in the sense that there exists a
X Z X ×Z
positive constant C > 0 such that for any data tuple (x,z) , it satisfies that (x,z) C .
1 1
∈ X ×Z k k ≤
Moreover,thedatadistribution admitsapositive,smoothdensityρ withrespecttotheLebesgue
D
D
measure on .
X ×Z
(ii) For the functionals Φ(x,z;f) and Ψ(x,z;f), there exists a positive constant C > 0 such that
2
δΦ(x,z;f) δΨ(x,z;f)
(w′) dw′ C , (w′) dw′ C , (x,z) .
2 2
δf ≤ δf ≤ ∀ ∈ X ×Z
ZW
(cid:12) (cid:12)
ZW
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
(iii) We
ass(cid:12)
ume that
δΨ(cid:12)(x,z;f)
(w′)dw′
as(cid:12)
a linear
function(cid:12)
al of f is upper-bounded by constant
W δf
times of values of f. RThat is to say, there exists w as a part of the data tuple (x,z) and a
∈ W
positive constant C > 0 such that
Ψ
δΨ(x,z;f)
(w′) dw′ C f(w) .
Ψ
δf ≤ ·
ZW
(cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12)
(iv) We assume that the variation of minimax objective (f,g) with respective to f and g are
L
continuous functions defined on and . That is to say,
W Z
δ (f,g) δ (f,g)
L C( ), L C( ).
δf ∈ W δg ∈ Z
Item (i) of Assumption 4.3 restricts our scenarios to data spaces with bounded values and smooth
densitiesfortechnicalreasons. Item(ii)and(iii)ofAssumption4.3isanintegrability conditionthat
weadditionallyrequiretoavoiddiscussionofimproperfunctionalsthatpotentiallyhavesingularities
with exploding values. Item (iv) is a smoothness condition that requires the variation of the
minimax objective averaged over data to be continuous on respective space. We also remark that
a sufficient condition for item (iv) to hold is the variation of Φ and Ψ with respect to f averaged
under the marginal of on is continuous. We will also use this condition to verify item (iv) in
D W
practice. These are general and reasonable assumptions widely satisfied by various applications in
machine learning, causal inference, and statistics.
214.2 Convergence of GDA dynamics to the Mean-Field Limit
In the following proposition, we show that the empirical distribution of the parameters µ and ν
k k
weakly converges to the mean-field limit in (3.7) as the width N goes to infinity and the stepsize
b b
scale ǫ goes to zero. Let ρ (θ,ω) = µ (θ) ν (ω), where (µ ,ν ) is the PDE solution to the con-
t t t t t
⊗
tinuous deterministic dynamics in (3.7) and ρ = N−1 N δ δ corresponds to the empirical
k · i=1 θ ki · ω ki
distribution of (θ ,ω ), which is k-th iterate of the discrPete stochastic dynamics in (3.3) with step-
k k b
size scale ǫ. The following proposition proves that the PDE solution ρ in (3.7) well approximates
t
the discrete gradient descent-ascent dynamics in (3.3).
Proposition 4.4 (Convergence of GDA to Mean-Field Limit). Let ρ be solution to (3.7)
t t≥0
{ }
with ρ = (0,I ) (0,I ), ρ be solution to (3.3) with ρ = (0,I ) (0,I ). Under
0 D D k k≥0 0 D D
N ⊗N { } N ⊗N
Assumption 4.1 and 4.3, ρ converges weakly to ρ as ǫ 0+ and N . It holds for any
⌊t/ǫ⌋ b t → b → ∞
Lipschitz continuous, bounded function F : RD RD R that
b × →
lim F(θ,ω)dρ (θ,ω)= F(θ,ω)dρ (θ,ω).
⌊t/ǫ⌋ t
ǫ→0+,N→∞
Z Z
Proof. See §B for a detailed proof. b
The proof of Proposition 4.4 is based on the propagation of chaos (Mei et al., 2018, 2019;
Araújo et al., 2019; Zhang et al., 2020; Sznitman, 1991). We deferred the detailed proof of Propo-
sition 4.4 to Appendix B. Proposition 4.4 allows us to convert the discrete gradient descent-ascent
dynamics over finite dimensional parameter space to its continuous, infinite-dimensional counter-
part in Wasserstein space, in which the training is amenable to analysis since our infinitely wide
neural network f(;µ) and g(;ν)) in (3.5) is linear in µ and ν respectively.
· ·
4.3 Global Optimality and Convergence of the Mean-Field Limit
In this section, we will introduce our main results that characterize the global optimality and
convergence of the mean-field neural networks, parameterized by the parameter distribution ρ =
t
(µ ,ν ). Theproofcontains two steps. We firstshowthatit issufficientto findastationary pointof
t t
the Wasserstein gradient flow defined in (3.7) in order to solve the minimax optimization problem
in (2.9), then we characterize the convergence of ρ to the stationary point. Before presenting the
t
two stages of the proof, we would need to further clarify the notions of stationarity regarding the
Wasserstein gradient flow. We introduce the following definition,
22Definition 4.5 (Stationary point of Wasserstein Gradient Flow). A distribution pair (µ,ν) is
called a stationary point of the Wasserstein gradient flow (3.7) if it satisfies
vf(θ;µ,ν)= vg(ω;µ,ν) = 0, θ,ω RD.
∀ ∈
From Definition 4.5, thestationary pointofWasserstein gradientflow (3.7)isadistributionpair
(µ,ν), atwhichtheassociated vector field(vf(;µ,ν),vg(;µ,ν))isazerofunctionontheparameter
· ·
spaceRD RD. Moreover, fortheWassersteingradientflowfollowingvectorfield(vf,vg)andinitial
×
condition (µ,ν), the solution to its associated continuity equation (µ ,ν ) is a constant flow such
t t
that for all t 0, µ = µ,ν = ν. Now, we have the following important supporting lemma that
t t
≥
characterizes the relation between stationary points of Wasserstein gradient flow (3.7) and saddle
points of (2.9).
Lemma 4.6. Under Assumptions 4.1 and 4.2, the following two properties hold.
(i) Suppose that (µ∗,ν∗) is a stationary point of the Wasserstein gradient flow as is defined in
Definition 4.5. Then, the corresponding function (f(;µ∗),g(;ν∗)) is the saddle point of the
· ·
objective function (f,g) defined in (2.9).
L
(ii) There exists a stationary distribution pair (µ∗,ν∗) and constant D¯ > 0 such that
W (µ ,µ∗) α−1D¯, W (ν ,ν∗) α−1D¯.
2 0 2 0
≤ ≤
Lemma 4.6 demonstrates that the stationary point of the Wasserstein gradient flow in (3.7)
achieves global optimality as a solution to the minimax objective (2.9). Lemma 4.6 allows us to
bypass the hardness of solving the nonconvex-nonconcave optimization problem (2.9) of finding
saddle points in the space of neural network parameters (θ,ω) by searching for a stationary point
of the Wasserstein gradient flow instead. Moreover, there exist good pairs of stationary points that
are close to the Gaussian initialization (µ ,ν ), with Wasserstein distance upper bounded by order
0 0
(α−1).
O
Proof. See §A.1 for a detailed proof.
We are now ready to show our main results. The following theorem characterizes the global
optimality and convergence of the Wasserstein gradient flow ρ .
t
23Theorem4.7(GlobalConvergencetoSaddlePoint). Let(µ ,ν )bethesolutiontotheWasserstein
t t
gradient flow (3.7) at time t with η = α−2 and initial condition µ = ν = (0,I ), (f∗,g∗) the
0 0 D
N
saddle point of the minimax objective (f,g) in (2.9). Under Assumptions 4.1, 4.2, and 4.3, it
L
holds that
inf E λΨ X,Z;f(;µ ) f∗() + g(Z;ν ) g∗(Z) 2 (T−1+α−1). (4.3)
D t t
t∈[0,T] · − · − ≤ O
h (cid:0) (cid:1) (cid:0) (cid:1) i
Proof. See §A.2 for a detailed proof.
Theorem 4.7 says that the optimality gap between (f(;µ ),g(;ν )) and (f∗,g∗), quantified by
t t
· ·
the Ψ-induced distance and L2 distance respectively, decays to zero at a sublinear rate in terms
of time T up to the error of (α−1), where α > 0 is the scaling parameter in (3.1) and (3.5). In
O
order to prove the convergence, we construct a potential V(µ,ν) = E λΨ X,Z;f(;µ) f∗() +
D
· − ·
g(Z;ν) g∗(Z) 2 , with V(µ,ν)= 0 if and only if (µ,ν) = (µ∗,ν∗). Suh ch a(cid:0)potential characteri(cid:1)zes
−
t(cid:0)he saddle point(cid:1)oi f the minimax objective. We show that the Wasserstein gradient flow decreases
the potential at a sublinear rate, thus suggesting the convergence of the gradient flow to the saddle
point. Moreover, varying α allows a trade-off between the error of order (α−1) in the optimality
O
gap andthemaximum deviation between ρ andtheGaussian initialization ρ forall t. Intheproof
t 0
of item (ii) of Lemma 4.6, we proved that the deviation of ρ from ρ quantified by the Wasserstein
t 0
distance is of order (α−1). Regarding representation learning, this suggests that GDA induces
O
a data-dependent representation that is significantly different from the initialization. Choosing a
small α of order (1) will correspond to the mean-field regime (Mei et al., 2018, 2019) that allows
O
ρ to move further away from the initialization, with the potential drawback of yielding a large
t
error of order (α−1). On the other hand, choosing a large α of order (√N) will correspond to
O O
the NTK regime (Jacot et al., 2018), and this causes the Wasserstein flow ρ to stay close to the
t
initial distribution ρ along the trajectory, inducing a data-independent representation.
0
Aswehavecommentedbefore,animportantclassofregularizerΨ(X,Z;f)istheL2 regularizer.
In this scenario, the left-hand side of (4.3) shouldbeunderstoodas a weighted L2 distance between
the gradient flow iterate at time t to the optimal solution (f∗,g∗). As we let T and α go to
infinity, such a distance will shrink to 0, thus the gradient flow converges globally in the minimal
distance sense to the optimal solution. Due to this observation, in the sequel we will discuss several
additional results in the case where the regularizer Ψ(X,Z;f) is strongly convex, in the sense that
24it’s bounded below by a quadratic function. We formalize the additional constraint in this case
with the following assumption,
Assumption 4.8 (Strong Convexity). We assume that the regularizer Ψ(X,Z;f) is c -strongly
Ψ
convex, in the sense that there exists a constant c > 0 such that for any f ,
Ψ
∈ F
Ψ(x,z;f) c f(w)2, (x,z) ,
Ψ
≥ ·| | ∀ ∈ X ×Z
where w is part of the data tuple (x,z).
∈ W
Assumption 4.8 implies that regularizer Ψ(X,Z;f) is equivalent to a quadratic regularizer
because Ψ is simultaneously bounded above and below by quadratic functionals. We have the
following strengthened version of Theorem 4.7 in such case,
inf E λc f(;µ ) f∗() 2 + g(Z;ν ) g∗(Z) 2 (T−1+α−1). (4.4)
D Ψ t t
t∈[0,T] · · − · − ≤ O
h (cid:0) (cid:1) (cid:0) (cid:1) i
Equation (4.4) shows that the iterates (f(;µ ),g(;ν )) converges to the saddle point solution
t t
· ·
(f∗,g∗) under a weighted L2 distance decays to zero at a sublinear rate up to an error of (α−1).
O
With Assumption 4.2, the saddle point f∗ is the global optimizer of the primal functional J(f)
defined in (2.3). Therefore, as a direct consequence of Theorem 4.7, when the regularizer Ψ is
strongly convex, f(;µ ) converges globally to f∗ at a sublinear rate in terms of T up to an error
t
·
of (α−1).
O
Under Assumption 4.8, we can also quantify the optimality gap between J(f ) and J(f∗), in
t
termsoftheminimaldistanceinf J(f ) J(f∗). Thefollowingtheoremcharacterize theglobal
t∈[0,T] t
−
convergence of J(f ) to J(f∗),
t
Theorem 4.9 (Global Convergence toPrimalSolution). Let(µ ,ν )bethesolutiontotheWasser-
t t
stein gradient flow (3.7) at time t with η = α−2 and initial condition µ = ν = (0,I ). Under
0 0 D
N
Assumptions 4.1, 4.2, 4.3 and 4.8, let f = f(;µ ), it holds that
t t
·
inf J(f ) J(f∗) (T−1/2+α−1/2),
t
t∈[0,T] − ≤ O
where f∗ is the global minimizer of the objective function defined in (2.3).
Proof. See §A.3 for a detailed proof.
25Theorem 4.9 proves that under the additional strong convexity assumption on the regularizer
Ψ(X,Z;f), the primal objective J(f ) as is defined in (2.3) decays to zero at rate of T−1/2 in terms
t
of time horizon T, up to an error of (α−1/2). Here we use f∗ to denote the global minimizer
O
instead of the saddle point. However, this will not create any confusion since for each f∗ global
minimizer of the primal objective (2.3), we can find g∗ such that (f∗,g∗) is a saddle point of
∈ F
(2.9).
5 Applications
In this section, we presentthe applications of Theorem 4.7 and Theorem 4.9 to several special cases
of functional conditional moment equation, such as the problem of policy evaluation, instrumental
variables regression, asset pricing, and adversarial Riesz representer estimation. In Section 2.2, we
already discussedwhy these problems are special cases of functional conditional moment equations,
thus Theorem 4.7 and Theorem 4.9 are potentially feasible to apply. We will recall the problem
settings and examine the technical assumptions for these cases.
5.1 Application 1: Policy Evaluation
Let denote the joint distribution of the state-action tuple (S,A,S′) under policy π. In this
D
scenario, the endogenous variable X = S′ is the next state while the exogenous variable Z = S
is the current state. Therefore, = , = and = . We attempt to estimate the value
X S Z S W S
function V, which is defined on = R. The functional Φ and regularizer Ψ adopted in this
W S →
case are,
Φ(s′,s;f)= r+γ f(s′) f(s), Ψ(s′,s;f) = f(s′)2.
· −
Here, the regularizer we adopt is a L2 regularizer that penalizes the squared value of the estimator
evaluated at the next state s′. With these specific choices of functional Φ and regularizer Ψ,
the GDA algorithm identifies with the Gradient Temporal Difference Learning (GTD) algorithm
(Wai et al., 2020). Therefore, the application of our general framework to the problem of policy
evaluationcontributestothereinforcementlearningliteraturebyprovidingananalysisoftheneural
GTD algorithm in the mean-field regime. Before presenting the theoretical results, we first verify
that Assumption 4.3 and Assumption 4.8 hold.
26Verify item (i) of Assumption 4.3. For item (i) of Assumption 4.3, we can always assume
that (x,z) 1 since we can always re-scale the state space without changing the nature of the
k k ≤
problem, therefore the compactness assumption is inherently satisfied.
Verify item (ii) of Assumption 4.3. For item (ii) of Assumption 4.3, we first compute the
variation of the functional Φ and Ψ,
δΦ(s′,s;f) δΨ(s′,s;f)
(w′) = γδ s′(w′) δ s(w′), (w′) = 2f(s′)δ s′(w′).
δf − δf
Therefore, the desired integrability conditions hold since
δΦ(s′,s;f) δΨ(s′,s;f)
(w′) dw′ γ+1, (w′) dw′ 2 f(s′). (5.1)
δf ≤ δf ≤ ·| |
ZW
(cid:12) (cid:12)
ZW
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
Verify item (ii(cid:12)i) of Assumpt(cid:12)ion 4.3. For item(cid:12) (iii) of Assum(cid:12)ption 4.3, we choose w = s′,
C = 2. The desired condition holds due to (5.1).
Ψ
Verify item (iv) of Assumption 4.3. For item (iv) of Assumption 4.3, we first compute the
variations of (f,g) in explicit forms,
L
δ (f,g)
L
δf
(w′) = E S|S′ γ ·g(S) S′ = w′ −g(w′)ρ s(w′)+2λ ·f(w′)ρ S′(w′), ∀w′ ∈S,
δ (f,g) h (cid:12) i
L (z′)= E S′|S r+γ f((cid:12) s′) S = z′ f(z′) g(z′)ρ S(z′), z′ ,
δg · − − ∀ ∈ S
h (cid:12) i
(cid:12)
where ρ S, ρ S′ denotes the density of the marginal distribution of with respect to the current
D
state S and next state S′ respectively. Due to the item (i) of Assumption 4.3, the variations of
L
with respect to f and g are both continuous since the density of the conditional transition S′ S
and S S′ are both smooth and the functions f,g are also continuous by construction. Therefo(cid:12)re,
(cid:12)
item (i(cid:12)v) is satisfied.
(cid:12)
Verify Assumption 4.8. For Assumption 4.8, we choose c = 1 and w = s′. The desired condi-
Ψ
tion holds by definition of our choice of regularizer Ψ(s′,s;f) = f(s′)2.
We have checked that the technical Assumption 4.3 and Assumption 4.8 hold for the case
of policy evaluation. Assumption 4.3 allows us to apply Theorem 4.7. This implies the global
convergence of the estimated value function to the minimizer of the primal objective (2.3) applied
in this case. Theconvergence is quantified in a weighted L2 distance. Additionally, Assumption 4.8
enablesustoapplyTheorem4.9andfurthercharacterize suchconvergence usingtheoptimality gap
between the value of primal objectives. We summarize the conclusions in the following corollary.
27Corollary 5.1 (Global Convergence of Mean-field Neural Nets in Policy Evaluation). Let f∗ be
the minimizer of primal objective J(f) defined in (2.8) with Φ(S′,S;f) = r + γ f(S′) f(S),
· −
(f) = E [f(S′)2]. Let (µ ,ν ) be the solution to the Wasserstein gradient flow (3.7) at time t
D t t
R
with η = α−2 and initial condition µ = ν = (0,I ). Under Assumption 4.1, 4.2, 4.3, and 4.8,
0 0 D
N
it holds that
inf E (f(S′;µ ) f∗(S′))2 (T−1+α−1),
D t
t∈[0,T] − ≤ O
h i
inf J(f(;µ )) J(f∗()) (T−1/2+α−1/2).
t
t∈[0,T] · − · ≤ O
Proof. Apply Theorem 4.7 and Theorem 4.9 to the setting of policy evaluation.
Corollary 5.1 proves that in the setting of policy evaluation, the L2 distance between the mean-
field neural network f(;µ ) at time t and the global minimizer f∗ decays to zero at a sub-linear
t
·
rate, up to an error of order (α−1). Moreover, the optimality gap inf J(f(;µ )) J(f∗())
t∈[0,T] t
O · − ·
in terms of primal objective values decays to zero at the rate of (T−1/2), up to an error (α−1/2)
O O
caused by over-parameterization. Corollary 5.1 allows us to efficiently and globally solve the policy
evaluation problem using over-parameterized two-layer neural networks. We also remark that in
such a scenario, the primal objective J(f) is also known as the regularized mean-squared Bellman
error (MSBE) in the literature of reinforcement learning. As we have commented before, in the
setting of policy evaluation, applying the GDA algorithm within neural network function classes
is equivalent to applying the neural GTD algorithm. Therefore, Corollary 5.1 states that, in the
mean-field regime, the neural GTD algorithm converges globally to the minimizer at a sublinear
rate up to an additional over-parameterization error (α−1). The neural GTD algorithm also
O
reduces regularized MSBE at the rate of (T−1/2) up to an additional over-parameterization error
O
(α−1/2). Moreover, The global convergence of mean-field neural networks also implies the global
O
convergence of the discrete dynamics in (3.3) due to the proximity between the discrete dynamics
and continuous dynamics, which is proved in Proposition 4.4.
5.2 Application 2: Nonparametric Instrumental Variables Regression
Let denotethejointdistributionoftheendogenousvariableX, theexogenous variableZ,andthe
D
observed outcome Y. Inthis scenario, theendogenous variable is definedin space , theexogenous
X
28variable is defined in space , and = . We attempt to estimate the model function f , which
0
Z W X
is defined on = R. The functional Φ and regularizer Ψ adopted in this case are,
W X →
Φ(x,z;f) = y f(x), Ψ(x,z;f) = f(x)2.
−
Here,theregularizerweadoptisaL2 regularizerthatpenalizesthesquaredvalueoftheestimatorof
themodelfunctionevaluated at theendogenous variable x. Thisisalso thesamesetting considered
in (Dikkala et al.,2020). We examine Assumption4.3 and Assumption4.8 inorder to applyresults
from Section 4.3.
Item (i) of Assumption 4.3. For item (i) of Assumption 4.3, the conditional moment model
estimation problems with compact data space still capture a large class of important applications,
therefore the scenarios considered are still quite general while imposing this assumption.
Item (ii) of Assumption 4.3. For item (ii) of Assumption 4.3, we first compute the variation of
the functional Φ and Ψ,
δΦ(x,z;f) δΨ(x,z;f)
(w′) = δ (w′), (w′) = 2f(x)δ (w′).
x x
δf − δf
Therefore, the desired integrability conditions hold since
δΦ(x,z;f) δΨ(x,z;f)
(w′) dw′ 1, (w′) dw′ 2 f(x). (5.2)
δf ≤ δf ≤ ·| |
ZW
(cid:12) (cid:12)
ZW
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
Item (iii) of Assumption 4.3. For item (iii) of Assumption 4.3, we choose w = x, C = 2. The
Ψ
desired condition holds due to (5.2).
Item (iv) of Assumption 4.3. For item (iv) of Assumption 4.3, we first compute the variations
of (f,g) in explicit forms,
L
δ (f,g)
L (w′) = E g(Z) X = w′ +2λ f(w′)ρ (w′), w′ ,
Z|X X
δf − · ∀ ∈ X
δ (f,g) h (cid:12) i
L (z′) = E Y f(X(cid:12) ) Z = z′ g(z′)ρ (z′), z′ ,
X|Z Z
δg − − ∀ ∈ Z
h (cid:12) i
(cid:12)
where ρ , ρ denotes the density of the marginal distribution of with respect to the endogenous
X Z
D
variable X and the exogenous variable Z respectively. Due to the item (i) of Assumption 4.3, the
variations of withrespecttof andg arebothcontinuoussincethedensityoftheconditionaltran-
L
sition Z X and X Z are both smooth and the functions f,g are also continuous by construction.
Therefor(cid:12)e, item (iv)(cid:12) is satisfied.
(cid:12) (cid:12)
29Assumption 4.8. For Assumption 4.8, we choose c = 1 and w = s′. The desired condition holds
Ψ
by definition of our choice of regularizer Ψ(x,z;f) = f(x)2.
We have checked that the technical Assumption 4.3 and Assumption 4.8 hold for the case of
nonparametric instrumental variables regression. Theorem 4.7 can be applied in this case due to
the establishment of Assumption 4.3. This implies the global convergence of the estimated model
function to the minimizer of the primal objective. The convergence is quantified in a weighted
L2 distance. The choice of quadratic regularizer implies the establishment of Assumption 4.8,
which further enables us to apply Theorem 4.9 and characterize the convergence in terms of primal
objective value. We summarize the conclusions in the following corollary.
Corollary 5.2 (Global Convergence of Mean-field Neural Nets in NPIV). Let f∗ bethe minimizer
of primal objective J(f) defined in (2.8) with Φ(X,Z;f) = Y f(X), (f) = E [f(X)2]. Let
D
− R
(µ ,ν ) be the solution to the Wasserstein gradient flow (3.7) at time t with η = α−2 and initial
t t
condition µ = ν = (0,I ). Under Assumption 4.1, 4.2, 4.3, and 4.8, it holds that
0 0 D
N
inf E (f(X;µ ) f∗(X))2 (T−1+α−1),
D t
t∈[0,T] − ≤ O
h i
inf J(f(;µ )) J(f∗()) (T−1/2+α−1/2).
t
t∈[0,T] · − · ≤ O
Corollary 5.2 proves that in the setting of NPIV, the L2 distance between the mean-field neural
network f(;µ ) at time t and the global minimizer f∗ decays to zero at a sub-linear rate, up to an
t
·
erroroforder (α−1). Moreover, theoptimality gapinf J(f(;µ )) J(f∗())decaystozeroat
t∈[0,T] t
O · − ·
the rate of (T−1/2), up to an error (α−1/2). Corollary 5.2 allows us to solve the NPIV problem
O O
globallyusingover-parameterized two-layer neuralnetworks. Wealsowanttoremarkthatwhenthe
truemodelfunctionislinearintheinput,werecover thesettingofinstrumentalvariables regression
as an important special instance of NPIV. Therefore, Corollary 5.2 also implies IV regression can
be globally solved efficiently by using over-parameterized two-layer neural networks.
5.3 Application 3: Asset Pricing
Let denote the joint distribution of the growth-return tuple (c ,r ,c ). In this scenario, the
t t+1 t+1
D
exogenous variable Z = c is the consumption growth at the current time t, and the endogenous
t
e
variable X = c is the consumption growth at the next time t+1. Therefore, = = , =
t+1
X Z C W C
30where is the space of consumption growth and is also a compact subset of R. Here, we consider
C
the scenario where the modified return r is also bounded for all t 0, i.e., r R for some
t+1 t+1
≥ k k ≤
R > 0. We attempt to estimate the function f , which is defined on = R. The functional
0
e W S →e
Φ and regularizer Ψ adopted in this case are,
Φ(c ,c ;f) = r f(c ) f(c ), Ψ(c ,c ;f)= f(c )2.
t+1 t t+1 t+1 t t+1 t t+1
· −
Here, the regularizer we adopt ise a L2 regularizer that penalizes the squared value of the estimator
evaluated at the consumption growth of the next time c . Before presenting the theoretical
t+1
results, we first verify that Assumption 4.3 and Assumption 4.8 hold.
Verify item (i) of Assumption 4.3. For item (i) of Assumption 4.3, since we assume that the
space of consumption growth is a compact subset of R, therefore there exists C > 0 such that
1
C
for all t 0, (c ,c ) C . Moreover, it is reasonable to assume that the consumption growth
t+1 t 1
≥ k k ≤
is bounded since the data often fluctuates within certain regimes in practice.
Verify item (ii) of Assumption 4.3. For item (ii) of Assumption 4.3, we first compute the
variation of the functional Φ and Ψ,
δΦ(c ,c ;f) δΨ(c ,c ;f)
t+1 t (w′) = r δ (w′) δ (w′), t+1 t (w′)= 2f(c ) δ (w′).
δf
t+1
·
ct+1
−
ct
δf
t+1
·
ct+1
e
Therefore, the desired integrability condition holds since,
δΦ(c ,c ;f) δΨ(c ,c ;f)
t+1 t (w′) dw′ R+1, t+1 t (w′) dw′ 2 f(c ). (5.3)
t+1
δf ≤ δf ≤ ·| |
ZW
(cid:12) (cid:12)
ZW
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
Verify item (iii) of Assumption 4.3. Foritem(iii)ofAssumption4.3,wechoosew = c,C = 2.
Ψ
The desired property holds due to (5.3).
e
Verify item (iv) of Assumption 4.3. For item (iv) of Assumption (4.3), we first compute the
variations of (f,g) in explicit forms,
L
δ (f,g)
L (w′) = E r g(c ) c = w′ g(w′)ρ (w′)+2λ f(w′)ρ (w′), w′ ,
δf
ct|ct+1 t+1
·
t t
−
ct
·
ct+1
∀ ∈S
δ (f,g) h (cid:12) i
L (z′)= E re f(c (cid:12) )e c = z′ f(z′) g(z′)ρ (z′), z′ ,
δg
ct+1|ct t+1
·
t+1 t
− −
ct
∀ ∈S
h (cid:12) i
e (cid:12)
whereρ ,ρ denotesthedensityofthemarginaldistributionof withrespecttothecurrenttime
ct ct+1
D
consumption growth c and the next time consumption growth c respectively. The variations
t t+1
of with respect to f and g are both continuous since the density of the conditional transition
L
31c c and c c are both smooth, and the function f,g are also continuous by construction.
t+1 t t t+1
Ther(cid:12)efore, item(cid:12) (iv) is satisfied.
(cid:12) (cid:12)
Verify Assumption 4.8. For Assumption 4.8, we choose c = 1 and w = c . The desired
Ψ t+1
condition holds by definition of our choice of regularizer Ψ(c ,c ;f)= f(c )2.
t+1 t t+1
We have checked that the technical Assumption 4.3 and Assumption 4.8 hold for the case of
assetpricingwithCCAPMmodel. Theorem4.7canbeappliedinthiscaseduetotheestablishment
of Assumption 4.3. This implies the global convergence of the estimated function to the minimizer
of the primalobjective. Theconvergence is quantified in a weighted L2 distance. SinceAssumption
4.8 holds, we can apply Theorem 4.9 and characterize the convergence in terms of primal objective
value. We summarize the conclusions in the following corollary.
Corollary 5.3 (Global Convergence of Mean-field Neural Nets in Asset Pricing). Let f∗ be the
minimizer of primal objective J(f) defined in (2.8) with Φ(c ,c ;f) = r f(c ) f(c ),
t+1 t t+1 t+1 t
· −
(f) = E [f(c )2]. Let (µ ,ν ) be the solution to the Wasserstein gradient flow (3.7) at time t
D t+1 t t
R e
with η = α−2 and initial condition µ = ν = (0,I ). Under Assumption 4.1, 4.2, 4.3, and 4.8,
0 0 D
N
it holds that
inf E (f(c ;µ ) f∗(c ))2 (T−1+α−1),
D t+1 t t+1
t∈[0,T] − ≤ O
h i
inf J(f(;µ )) J(f∗()) (T−1/2+α−1/2).
t
t∈[0,T] · − · ≤ O
Proof. Apply Theorem 4.7 and Theorem 4.9 to the setting of asset pricing.
Corollary 5.3 proves that in the setting of conditional moment model estimation, the L2 dis-
tance between the mean-field neural network f(;µ ) at time t and the global minimizer f∗ de-
t
·
cays to zero at a sub-linear rate, up to an error of order (α−1). Moreover, the optimality gap
O
inf J(f(;µ )) J(f∗()) decays to zero at the rate of (T−1/2), up to an error (α−1/2).
t∈[0,T] t
· − · O O
Corollary 5.3 allows us to solve the CCAPM model globally by estimating the nonparametric
structural demand function with over-parameterized two-layer neural networks. Since the return
on investment is linked to the marginal utility of consumption through the CCAPM equation,
we can price fairly the assets by considering consumption risk and utilizing the marginal utility
information.
325.4 Application 4: Adversarial Riesz Representer Estimation
Let denote the joint distribution of the endogenous variable X and the random vector V. In
D
this scenario, the exogenous variable Z coincides with the endogenous variable X, therefore the
problem is essentially unconditional. The endogenous variable is defined in space , the exogenous
X
variable is defined on = , and = . We attempt to estimate the Riesz representer f , which
0
Z X W X
is defined on = R. The functional Φ and regularizer Ψ adopted in this case are,
W X →
Φ(x,x;f) = f (x) f(x), Ψ(x,x;f)= f(x)2.
0
−
Here, the regularizer we adopt is a L2 regularizer that penalizes the squared value of estimator
of the Riez representer evaluated at the variable x. This is also the same setting considered in
(Chernozhukov et al., 2020). We examine Assumption 4.3 and Assumption 4.8 in order to apply
results from Section 4.3.
Item (i) of Assumption 4.3. For item (i) of Assumption 4.3, we restrict our attention to
estimating Riesz represented of functionals defined on a compact space. In practice, such an
assumption is very general since we often treat data distribution on an unbounded space with
exponential decay as a distribution defined on a compact space.
Item (ii) of Assumption 4.3. For item (ii) of Assumption 4.3, we first compute the variation of
the functional Φ and Ψ,
δΦ(x,x;f) δΨ(x,x;f)
(w′) = δ (w′), (w′) = 2f(x)δ (w′).
x x
δf − δf
Therefore, the desired integrability conditions hold since
δΦ(x,x;f) δΨ(x,x;f)
(w′) dw′ 1, (w′) dw′ 2 f(x). (5.4)
δf ≤ δf ≤ ·| |
ZW
(cid:12) (cid:12)
ZW
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
Item (iii) of Assu(cid:12)mption 4.3. F(cid:12)or item (iii) of (cid:12)Assumption 4.3,(cid:12)we choose w = x, C = 2. The
Ψ
desired condition holds due to (5.4).
Item (iv) of Assumption 4.3. For item (iv) of Assumption 4.3, we first compute the variations
of (f,g) in explicit forms,
L
δ (f,g)
L (w′) = E g(Z) X = w′ +2λ f(w′)ρ (w′), w′ ,
Z|X X
δf − · ∀ ∈ X
δ (f,g) h (cid:12) i
L (z′) = E f (X) (cid:12) f(X) Z = z′ g(z′)ρ (z′), z′ ,
X|Z 0 Z
δg − − ∀ ∈ Z
h (cid:12) i
(cid:12)
33where ρ , ρ denotes the density of the marginal distribution of with respect to the endogenous
X Z
D
variable X and the exogenous variable Z respectively. Due to the item (i) of Assumption 4.3, the
variations of withrespecttof andg arebothcontinuoussincethedensityoftheconditionaltran-
L
sition Z X and X Z are both smooth and the functions f,g are also continuous by construction.
Therefor(cid:12)e, item (iv)(cid:12) is satisfied.
(cid:12) (cid:12)
Assumption 4.8. For Assumption 4.8, we choose c = 1 and w = s′. The desired condition holds
Ψ
by definition of our choice of regularizer Ψ(x,x;f)= f(x)2.
We have checked that the technical Assumption 4.3 and Assumption 4.8 hold for the case
of adversarial Riesz representer estimation. Theorem 4.7 can be applied in this case due to the
establishment of Assumption 4.3. This implies the global convergence of the estimated Riesz
representer to the minimizer of the primal objective. The convergence is quantified in a weighted
L2 distance. The choice of quadratic regularizer implies the establishment of Assumption 4.8,
which further enables us to apply Theorem 4.9 and characterize the convergence in terms of primal
objective value. We summarize the conclusions in the following corollary.
Corollary 5.4 (Global Convergence of Mean-field Neural Nets in Adversarial Riesz Representer
Estimation). Let f∗ be the minimizer of primal objective J(f) defined in (2.8) with Φ(x,x;f) =
f (x) f(x), (f)= E [f(x)2]. Let (µ ,ν ) be the solution to the Wasserstein gradient flow (3.7)
0 D t t
− R
at time t with η = α−2 and initial condition µ = ν = (0,I ). Under Assumption 4.1, 4.2, 4.3,
0 0 D
N
and 4.8, it holds that
inf E (f(X;µ ) f∗(X))2 (T−1+α−1),
D t
t∈[0,T] − ≤ O
h i
inf J(f(;µ )) J(f∗()) (T−1/2+α−1/2).
t
t∈[0,T] · − · ≤ O
Corollary 5.4 proves that in the setting of adversarial Riesz represented estimation, the L2
distance between the mean-field neural network f(;µ ) at time t and the global minimizer f∗ de-
t
·
cays to zero at a sub-linear rate, up to an error of order (α−1). Moreover, the optimality gap
O
inf J(f(;µ )) J(f∗())decaystozeroattherateof (T−1/2),uptoanerror (α−1/2). Corol-
t∈[0,T] t
· − · O O
lary 5.4 allows us to estimate the Riesz representer of a given functional using over-parameterized
two-layer neural networks.
346 Conclusion
In this paper, we focus on the minimax optimization problem derived from solving functional con-
ditionalmomentequations usingoverparameterized two-layer neuralnetworks. For suchaproblem,
wefirstprovethatthegradientdescent-ascent algorithm converges toamean-fieldlimitasthestep-
size goes to zero and the network width goes to infinity. In this mean-field limit, the optimization
dynamics is characterized by a Wasserstein gradient flow in the space of probability distributions.
We further establish the global convergence of the Wasserstein gradient flow, and prove that the
feature representation induced by the neural networks is allowed to move by a considerable dis-
tance from the initial value. We further apply our general results to W policy evaluation with
high dimensional state space, nonparametric instrumental variables with high dimensional X and
Z, asset pricing with a nonparametric structural demand function, and general Riesz representer
estimation. Our analysis opens avenues for studying functional minimax optimization problems
with more complicated objectives, such as nonlinear functional conditional moment equations. We
leave thestudy of theconvergence properties of thealgorithm in such a general setting to futurere-
search. This setting includes nonparametric quantile instrumental variables regression as a leading
and important application.
35References
Ai, C. and Chen, X. (2003). Efficient estimation of models with conditional moment restrictions
containing unknown functions. Econometrica, 71 1795–1843.
Allen-Zhu, Z., Li, Y. and Liang, Y. (2019a). Learning and generalization in overparameterized
neural networks, going beyond two layers. Advances in neural information processing systems,
32.
Allen-Zhu, Z., Li, Y. and Song, Z. (2019b). A convergence theory for deep learning via over-
parameterization. In International Conference on Machine Learning. PMLR.
Ambrosio, L. and Gigli, N. (2013). A user’s guide to optimal transport. In Modelling and Optimi-
sation of Flows on Networks. Springer, 1–155.
Ambrosio, L., Gigli, N. and Savaré, G. (2008). Gradient flows: In metric spaces and in the space
of probability measures. Springer.
Araújo, D., Oliveira, R. I. and Yukimura, D. (2019). A mean-field limit for certain deep neural
networks. arXiv preprint arXiv:1906.00193.
Barron, A. R. (1993). Universal approximation bounds for superpositions of a sigmoidal function.
IEEE Transactions on Information Theory, 39 930–945.
Ben-Tal, A., El Ghaoui, L. and Nemirovski, A. (2009). Robust optimization, vol. 28. Princeton
university press.
Blundell, R., Chen, X. and Kristensen, D. (2007). Semi-nonparametric iv estimation of shape-
invariant engel curves. Econometrica, 75 1613–1669.
Cai, Q., Yang, Z., Lee, J. D. and Wang, Z. (2019). Neural temporal-difference learning converges
to global optima. In Advances in Neural Information Processing Systems.
Chen, X., Chernozhukov, V., Lee, S. and Newey, W. K. (2014). Local identification of nonpara-
metric and semiparametric models. Econometrica, 82 785–809.
Chen, X. and Christensen, T. M. (2018). Optimal sup-norm rates and uniform inference on non-
linear functionals of nonparametric iv regression. Quantitative Economics, 9 39–84.
36Chen, X. and Ludvigson, S. C. (2009). Land of addicts? an empirical investigation of habit-based
asset pricing models. Journal of Applied Econometrics, 24 1057–1093.
Chen, X. and Pouzo, D. (2009). Efficient estimation of semiparametric conditional moment models
with possibly nonsmooth residuals. Journal of Econometrics, 152 46–60.
Chen, X. and Pouzo, D. (2012). Estimation of nonparametric conditional moment models with
possibly nonsmooth generalized residuals. Econometrica, 80 277–321.
Chen, X. and Qi, Z. (2022). On well-posedness and minimax optimal rates of nonparametric q-
function estimation in off-policy evaluation. In International Conference on Machine Learning.
PMLR.
Chernozhukov, V., Newey, W., Singh, R. and Syrgkanis, V. (2020). Adversarial estimation of riesz
representers. arXiv preprint arXiv:2101.00009.
Chernozhukov, V., Newey, W. K. and Singh, R. (2022). Debiased machine learning of global and
local parameters using regularized riesz representers. The Econometrics Journal, 25 576–601.
Chizat, L. and Bach, F. (2018). On the global convergence of gradient descent for over-
parameterized models using optimal transport. In Advances in Neural Information Processing
Systems.
Daskalakis, C. and Panageas, I. (2018). The limit points of (optimistic) gradient descent in min-
max optimization. Advances in neural information processing systems, 31.
Dikkala, N., Lewis, G., Mackey, L. and Syrgkanis, V. (2020). Minimax estimation of conditional
moment models. Advances in Neural Information Processing Systems, 33 12248–12262.
Ding, S., Dong, H., Fang, C., Lin, Z. and Zhang, T. (2023). Provable particle-based primal-dual
algorithm for mixed nash equilibrium. arXiv preprint arXiv:2303.00970.
Du, S. S., Zhai, X., Poczos, B. and Singh, A. (2018). Gradient descent provably optimizes over-
parameterized neural networks. arXiv preprint arXiv:1810.02054.
Duan, Y., Jia, Z.andWang, M.(2020). Minimax-optimal off-policy evaluation with linear function
approximation. In International Conference on Machine Learning. PMLR.
37Fang, C., Lee, J., Yang, P. and Zhang, T. (2021). Modeling from features: a mean-field framework
for over-parameterized deep neural networks. In Conference on learning theory. PMLR.
Ganin, Y.,Ustinova, E.,Ajakan, H.,Germain, P.,Larochelle, H.,Laviolette, F.,Marchand, M.and
Lempitsky, V. (2016). Domain-adversarial training of neural networks. The journal of machine
learning research, 17 2096–2030.
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A.
and Bengio, Y. (2020). Generative adversarial networks. Communications of the ACM, 63 139–
144.
Holte, J. M. (2009). Discrete Gronwall lemma and applications. In MAA-NCS meeting at the
University of North Dakota, vol. 24.
Huang, F., Gao, S., Pei, J.and Huang, H. (2022). Accelerated zeroth-order and first-order momen-
tum methods from mini to minimax optimization. Journal of Machine Learning Research, 23
1–70.
Jacot, A., Gabriel, F. and Hongler, C. (2018). Neural tangent kernel: Convergence and generaliza-
tion in neural networks. In Advances in Neural Information Processing Systems, vol. 31.
Jin, C., Netrapalli, P. and Jordan, M. (2020). What is local optimality in nonconvex-nonconcave
minimax optimization? In International conference on machine learning. PMLR.
Jin, Y.,Yang, Z.andWang, Z.(2021). Ispessimismprovablyefficientforofflinerl? InInternational
Conference on Machine Learning. PMLR.
Levy, D.,Carmon, Y.,Duchi, J. C.andSidford, A.(2020). Large-scalemethodsfordistributionally
robust optimization. Advances in Neural Information Processing Systems, 33 8847–8860.
Liao, L., Chen, Y.-L., Yang, Z., Dai, B., Kolar, M. and Wang, Z. (2020). Provably efficient neural
estimation of structural equation models: An adversarial approach. Advances in Neural Infor-
mation Processing Systems, 33 8947–8958.
Lin, T.,Jin, C.andJordan, M.(2020a). Ongradientdescentascentfornonconvex-concaveminimax
problems. In International Conference on Machine Learning. PMLR.
38Lin, T., Jin, C. and Jordan, M. I. (2020b). Near-optimal algorithms for minimax optimization. In
Conference on Learning Theory. PMLR.
Liu, S., Lu, S., Chen, X., Feng, Y., Xu, K., Al-Dujaili, A., Hong, M. and O’Reilly, U.-M. (2019).
Min-max optimization without gradients: Convergence and applications to adversarial ml. arXiv
preprint arXiv:1909.13806.
Lu, S., Tsaknakis, I., Hong, M. and Chen, Y. (2020a). Hybrid block successive approximation for
one-sided non-convex min-max problems: algorithms and applications. IEEE Transactions on
Signal Processing, 68 3676–3691.
Lu, Y., Ma, C., Lu, Y., Lu, J. and Ying, L. (2020b). A mean-field analysis of deep resnet and
beyond: Towards provable optimization via overparameterization from depth.
Luo, L., Ye, H., Huang, Z. and Zhang, T. (2020). Stochastic recursive gradient descent ascent
for stochastic nonconvex-strongly-concave minimax problems. Advances in Neural Information
Processing Systems, 33 20566–20577.
Madry, A., Makelov, A., Schmidt, L., Tsipras, D. and Vladu, A. (2017). Towards deep learning
models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083.
Mei, S., Misiakiewicz, T. and Montanari, A. (2019). Mean-field theory of two-layers neural net-
works: Dimension-free bounds and kernel limit. arXiv preprint arXiv:1902.06015.
Mei, S., Montanari, A. and Nguyen, P.-M. (2018). A mean field view of the landscape of two-layer
neural networks. Proceedings of the National Academy of Sciences, 115 E7665–E7671.
Omidshafiei, S., Pazis, J., Amato, C., How, J. P. and Vian, J. (2017). Deep decentralized multi-
task multi-agent reinforcement learning under partial observability. In International Conference
on Machine Learning. PMLR.
Ostrovskii, D. M., Lowy, A. and Razaviyayn, M. (2021). Efficient search of first-order nash equi-
libria in nonconvex-concave smooth min-max problems. SIAM Journal on Optimization, 31
2508–2538.
Otto, F. and Villani, C. (2000). Generalization of an inequality by Talagrand and links with the
logarithmic Sobolev inequality. Journal of Functional Analysis, 173 361–400.
39Ouyang, Y.andXu, Y.(2021). Lower complexity boundsof first-ordermethodsforconvex-concave
bilinear saddle-point problems. Mathematical Programming, 185 1–35.
Pinkus, A. (1999). Approximation theory of the MLP model in neural networks. Acta Numerica,
8 143–195.
Ramprasad, P., Li, Y., Yang, Z., Wang, Z., Sun, W. W. and Cheng, G. (2022). Online bootstrap
inference for policy evaluation in reinforcement learning. Journal of the American Statistical
Association 1–14.
Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A. and Chen, X. (2016). Im-
proved techniques for training gans. Advances in neural information processing systems, 29.
Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., Hubert, T.,
Baker, L.,Lai, M.,Bolton, A.et al.(2017). Masteringthegameofgowithouthumanknowledge.
nature, 550 354–359.
Sutton, R. S. and Barto, A. G. (2018). Reinforcement learning: An introduction. MIT press.
Sznitman, A.-S. (1991). Topics in propagation of chaos. In Ecole d’Été de Probabilités de Saint-
Flour XIX—1989. Springer, 165–251.
Villani, C. (2003). Topics in optimal transportation. American Mathematical Society.
Villani, C. (2008). Optimal transport: Old and new. Springer.
Wai, H.-T., Yang, Z., Wang, Z. and Hong, M. (2020). Provably efficient neural GTD for off-policy
learning. Advances in Neural Information Processing Systems, 33.
Wainwright, M. J. (2019). High-dimensional statistics: A non-asymptotic viewpoint. Cambridge
University Press.
Wang, S., Yu, X. and Perdikaris, P. (2022). When and why pinns fail to train: A neural tangent
kernel perspective. Journal of Computational Physics, 449 110768.
Wang, Z., Balasubramanian, K., Ma, S. and Razaviyayn, M. (2020). Zeroth-order algorithms for
nonconvex minimax problems with improved complexities. arXiv preprint arXiv:2001.07819.
40Xie, Q., Chen, Y., Wang, Z. and Yang, Z. (2020). Learning zero-sum simultaneous-move markov
games using function approximation and correlated equilibrium. In Conference on learning the-
ory. PMLR.
Xu, L.,Chen, Y.,Srinivasan, S.,de Freitas, N.,Doucet, A.andGretton, A.(2020a). Learningdeep
features in instrumental variable regression. arXiv preprint arXiv:2010.07154.
Xu, P. and Gu, Q. (2020). A finite-time analysis of q-learning with neural network function ap-
proximation. In International Conference on Machine Learning. PMLR.
Xu, T., Wang, Z., Liang, Y. and Poor, H. V. (2020b). Enhanced first and zeroth order variance
reduced algorithms for min-max optimization.
Zhang, Y., Cai, Q., Yang, Z., Chen, Y. and Wang, Z. (2020). Can temporal-difference and q-
learning learn representation? A mean-field theory. arXiv preprint arXiv:2006.04761.
Zhang, Y., Chen, S., Yang, Z., Jordan, M. and Wang, Z. (2021). Wasserstein flow meets replicator
dynamics: A mean-field analysis of representation learning in actor-critic. Advances in Neural
Information Processing Systems, 34 15993–16006.
Zhao, R.(2023). Aprimal-dualsmoothing framework for max-structurednon-convex optimization.
Mathematics of operations research.
Zhao, Y., Tian, Y., Lee, J. and Du, S. (2022). Provably efficient policy optimization for two-player
zero-sum markov games. In International Conference on Artificial Intelligence and Statistics.
PMLR.
41A Proof of Main Results
A.1 Proof of Lemma 4.6
Proof of (i). The proof for Claim (i) will be two-stage. First, we will show that if function pair
(f∗,g∗) is a stationary point for (f,g) with respect to (f,g), then it’s a saddle point for the same
L
objective as well. Then we will show that the distribution pair (µ∗,ν∗) being a stationary point
of (µ,ν) implies that the corresponding (f∗,g∗) is a stationary point for (f,g), which concludes
L L
the claim. We will start with the first part. We define the following functional and ,
1 2
L L
(f,g) = E g(Z) Φ(X,Z;f) , (f,g) = E 1/2 g(Z)2+λΨ(X,Z;f) .
1 D 2 D
L · L − ·
h i h i
We see that the minimax objective in (2.9) is indeed the sum of such two functionals,
(f,g) = (f,g)+ (f,g).
1 2
L L L
For any function pair (f,g), we can verify that the following chain of equalities holds,
max (f,g′) min (f′,g) = max (f,g′) (f,g) +max (f,g) (f′,g) . (A.1)
g′ L − f′ L g′ L −L f′ L −L
(cid:0) (cid:1) (cid:0) (cid:1)
We considered the function space L2( ) and L2( ) equipped with inner product , , which
L2
W Z h· ·i
are also Hilbert spaces. Since are compact, continuous function f and g parameterized in
X ×Z
the form of (3.5) are square-integrable, thus naturally belong to L2( ) and L2( ).
W Z
For afixedf, (f,g)is acontinuous linear functionaling definedon L2( ). Thus,thereexists
1
L Z
functionh inL ( )suchthat (f,g) = h ,g . Similarly, forafixedg, (f,g)is acontinuous
f 2 Z L1 f L2 L1
linear functional in f, thus there exists fu(cid:10)nctio(cid:11)n h in L ( ) such that (f,g) = h ,f . In
g 2 W L1 g L2
fact, h and h matches the variation of with respect to g and f. (cid:10) (cid:11)
f g 1
L
δ (f,g) δ (f,g)
1 2
h = L , h = L .
f f
δg δf
Since is a concave functional with respect to g, we apply Jensen’s inequality and it holds
2
L
that,
(f,g′) (f,g) = f,g′ f,g + f,g′ f,g
1 1 2 2
L −L L −L L −L
δ(cid:0) L1(f,(cid:1)g) ,g′(cid:0)
g
(cid:1)
+
(cid:0)δ L2((cid:1)f,g) ,g(cid:0)
′
g(cid:1)
≤ δg − L2 g − L2
D E D E
δ (f,g)
= L ,g′ g . (A.2)
δg − L2
D E
42Follow a similar reasoning, using the fact that is a linear functional with respect to f and is
1 2
L L
a convex functional with respect to f, it holds that
δ (f,g)
(f,g) (f′,g) L ,f f′ . (A.3)
L −L ≤ δf − L2
D E
Plugging(A.2)and(A.3)into(A.1),were-writetheminimaxexpressionin(A.1)usingthevariation
of (f,g), the following inequality holds,
L
δ (f,g) δ (f,g)
max (f,g′) min (f′,g) max L ,g′ g + L ,f f′ . (A.4)
g′ L − f′ L ≤ f′,g′ δg − L2 δf − L2
D E D E
Thus, if (f∗,g∗) is the stationary point, i.e.,
δ (f∗,g∗) δ (f∗,g∗)
L = L = 0, a.s., (A.5)
δf δg
then(A.4)suggeststhatforsuchstationarypoint(f∗,g∗),foranyfunctionpair(f′,g′),thefollowing
inequality holds,
max (f∗,g′) min (f′,g∗) 0. (A.6)
g′ L − f′ L ≤
Equation (A.6) proves that (f∗,g∗) is a saddle point for the minimx objective (f,g). Therefore,
L
the stationarity of (f∗,g∗) implies that it’s a saddle point for objective (f,g).
L
Now, we proceed to show the second stage of the proof. We now show that if (µ∗,ν∗) is
the stationary point of , i.e., vf(;µ∗,ν∗) = vg(;µ∗,ν∗) = 0, the corresponding function pair
L · ·
(f(;µ∗),g(;ν∗)) is the stationary point of (f,g) with respect to (f,g). We recall that the corre-
· · L
spondence between (µ∗,ν∗) and (f(;µ∗),g(;ν∗)) is through (3.5).
· ·
Let (µ∗,ν∗) be a stationary point of (2.9), that is
δ (µ∗,ν∗) δ (µ∗,ν∗)
L (θ)= L (ω) = 0, θ,ω RD (A.7)
θ ω
∇ δµ ∇ δν ∀ ∈
We can also compute the variation of (µ,ν) explicitly.
L
δ (µ∗,ν∗) δΦ(X,Z;f(;µ∗)) δΨ(X,Z;f(;µ∗))
L (θ)= E α g(Z;ν∗) · +λ · ,φ(;θ) ,
D
δµ · δf · δf · L2
h D E i
δ (µ∗,ν∗)
L (ω) = E α Φ(X,Z;f(,µ∗)) g(Z;ν∗) ψ(Z;ω) .
D
δν · − ·
h i
(cid:0) (cid:1)
43By the oddness of b in Assumption 4.1, we have that φ(;0) = 0, This implies that the variation of
·
(µ∗,ν∗) with respect to µ and ν are 0 when θ = ω = 0, i.e.,
L
δ (µ∗,ν∗) δ (µ∗,ν∗)
L (0) = L (0) = 0.
δµ δν
Combined with (A.7), we deduced that
δ (µ∗,ν∗) δ (µ∗,ν∗)
L (θ)= L (w) = 0 θ,ω RD.
δµ δν ∀ ∈
Note that
δ (f(;µ∗),g(;ν∗)) δ (µ∗,ν∗)
α L · · ,φ(;θ) = L (θ)= 0. (A.8)
δf · L2 δµ
D E
L(f(·;µ∗),g(·;ν∗))
By the universal function approximation theorem (Lemma D.1), since is in
δf
C( ) as is assumed in item (iv) of Assumption 4.3, there exists φ ∞ (φ) such that
W { n }n=1 ∈ G
L(f(·;µ∗),g(·;ν∗))
φ uniformly. Here, (φ) denotes the space of functions that are linearly spanned
n → δf G
by φ(,θ) By (A.8), it holds that
·
(f(;µ∗),g(;ν∗))
L · · (),φ () = 0. (A.9)
n
δf · · L2
D E
Following a similar strategy, we can show that there exists ψ ∞ (ψ) such that ψ
{ n }n=1 ∈ G n →
L(f(·;µ∗),g(·;ν∗))
, where for each ψ , it holds that
δg n
(f(;µ∗),g(;ν∗))
L · · (),ψ () =0. (A.10)
n
δg · · L2
D E
We take the limit of (A.9) and (A.10) by passing n and conclude,
→ ∞
δ (f(;µ∗),g(;ν∗)) (f(;µ∗),g(;ν∗))
L · · = 0, L · · () = 0. a.s. (A.11)
δf δg ·
Equation(A.11)provesthatif(µ∗,ν∗)isastationarypointoftheWassersteingradientflow,then
theassociated functionpair(f(;µ∗,g(;ν∗)))isastationary pointoftheminimaxobjective (f,g),
· · L
which matches the conditions we conclude in (A.5). Therefore, we prove that (f(;µ∗),g(;ν∗)) is
· ·
a saddle point of the minimax objective (f,g). We complete the proof of item (i) of Lemma 4.6.
L
Proof of (ii). We now show that there exists good solution pair (µ∗,ν∗) that is both optimal as
well as close to initialization (µ ,ν ) in Wasserstein distance.
0 0
44By Assumption 4.2, there exists distribution µ†,ν† P (RD) such that the optimal solution to
2
∈
the optimization problem (2.9)(f∗,g∗) satisfies the following,
f∗(w) = φ(w;θ)dµ†(θ),g∗(z) = ψ(z;ω)dν†(ω), w ,z
∀ ∈ W ∈ Z
Z Z
Recall that α > 0 is the scaling parameter in neural network parameterization. We can construct
(µ∗,ν∗) using a convex combination of (µ†,ν†) and the initialization (µ ,ν ),
0 0
µ∗(θ)= α−1µ†(θ)+(1 α−1)µ (θ), ν∗(w) = α−1ν†(ω)+(1 α−1)ν (ω). (A.12)
0 0
− −
We claim that (µ∗,ν∗) constructed in (A.12) satisfies all the desired requirements. Since µ ,ν
0 0
are standard Gaussian distribution, the integration of φ(;θ) with respect to µ and ψ(;ω) with
0
· ·
respect to ν are identically 0 due to oddness of neuron functions,
0
φ(w;θ)dµ (θ)= 0, ψ(z;ω)dν (ω) = 0. w ,z
0 0
∀ ∈ W ∈ Z
ZW ZZ
Thus, the expressions for (f∗,g∗) are simplified to
f∗(w) = α φ(w;θ)dµ∗(θ), g∗(z) = α ψ(z;ω)dν∗(ω).
Z Z
By Talagrand’s inequality (Lemma D.5), the following chain of inequalities holds,
(µ ,µ∗)2 2D (µ∗ µ ) D (µ∗ µ )
2 0 KL 0 χ2 0
W ≤ k ≤ k
µ∗(θ) 2 (1 α−1) µ (θ)+α−1 µ†(θ) 2
0
= 1 dµ (θ) = − · · 1 dµ (θ)
0 0
µ (θ) − µ (θ) −
Z (cid:18) 0 (cid:19) Z (cid:18) 0 (cid:19)
= α−2D (µ† µ ). (A.13)
χ2 0
k
A similar bound on (ν ,ν∗) also applies,
2 0
W
(ν ,ν∗)2 α−2D (ν† ν ). (A.14)
2 0 χ2 0
W ≤ k
Let D¯ = max D (µ† µ )1/2,D (ν† ν )1/2 , we conclude the proof of item (ii) in Lemma 4.6.
χ2 0 χ2 0
{ k k }
A.2 Proof of Theorem 4.7
By Lemma 4.6, there exists distribution (µ∗,ν∗) that is a stationary point of Wasserstein gradient
flow (3.7) and simultaneously satisfying the distance bound in item (ii) of Lemma 4.6. For such
(µ∗,ν∗), we denote ρ∗(θ,ω)= µ∗(θ)ν∗(ω) as their product measure. Moreover, for any distribution
45pair (µ,ν), we use ρ(θ,ω) = µ(θ)ν(ω) as their product measure for simplicity. To rewrite the
Wasserstein gradient flow for (µ,ν) into the flow for ρ, we define vector the stacked vector field v
as,
v(θ,ω;µ,ν) = vf(θ;µ,ν),vg(ω;µ,ν) . (A.15)
(cid:0) (cid:1)
Following from Lemma C.5, (A.13), and (A.14), it holds that
(ρ∗,ρ ) α−1D¯,
2 0
W ≤
where D¯ is defined in Lemma 4.6.
Note that
f(w;µ) = α φ(w;θ)µ(θ)dθ = α φ(w;θ)ρ(θ,ω)d(θ,ω), w ,
∀ ∈ W
Z Z
g(z;ν) = α ψ(z;ω)ν(ω)dω = α ψ(z;ω)ρ(θ,ω)d(θ,ω), z .
∀ ∈ Z
Z Z
Thus, we overload the notation to write f(;ρ) = f(;µ) and g(;ρ) = g(;ν) for ρ P (RD RD).
2
· · · · ∈ ×
By writing ρ = (µ ,ν ), the update in (3.7) takes the following form
t t t
∂ ρ (θ,ω) = div ρ (θ,ω)v(θ,ω;ρ ) , ρ = (µ ,ν ).
t t t t 0 0 0
−
(cid:0) (cid:1)
Before we prove Theorem 4.7, we first show the following lemma.
Lemma A.1. We assume (ρ ,ρ∗) 2 (ρ ,ρ∗). UnderAssumptions4.1, 4.3, 4.2, it holdsthat
2 t 2 0
W ≤ W
1d (ρ ,ρ∗)2
W2 t η E λΨ X,Z;f(;µ ) f∗() + g(Z;ν ) g∗(Z) 2 +C ηα−1. (A.16)
D t t ∗
2 dt ≤ − · · − · − ·
h (cid:0) (cid:1) (cid:0) (cid:1) i
where C >0 is a constant depending on B ,B ,B , λ, and D¯
∗ 0 1 2
Proof. Let β be the geodesic connecting ρ and ρ∗ with β = ρ and β = ρ∗. Let u be
s s∈[0,1] t 0 t 1
{ }
the corresponding veclocity field such that ∂ β = div(β u ). By the first variation formula of
s s s s
−
Wasserstein distance in Lemma D.3, it holds that
1d (ρ ,ρ∗)2
2 t
W = η v(;ρ ),u
2 dt − · t 0 ρt
(cid:10) (cid:11) 1
= η v(;ρ∗),u +η ∂ v(;β ),u ds
− · 1 ρ∗
Z0
s · s s βs
(cid:10)1 (cid:11) (cid:10) 1 (cid:11)
= η ∂ v(;β ),u ds+η v(θ,ω;β ),∂ (u (θ,w)β (θ,ω)) d(θ,ω)ds.
Z0
s · s s βs
Z0 Z
s s s s
(cid:10) (cid:11) (cid:10) (cid:11)
(i) (ii)
| {z } | {z }
(A.17)
46where the notation h ,h = h h dρ for any distribution ρ and functions h ,h . We will
1 2 ρ 1 · 2 1 2
provide bounds for t(cid:10)erm (i)(cid:11)and (Rii) separately in the sequel.
Upper bounding term (i). For term (i) of (A.17), by the definitions of v, vf, and vg in (A.15)
and (3.6), we have that
δΦ(X,Z;f(;β )) δΨ(X,Z;f(;β ))
∂ vf(θ,ω;β ) = α∂ E g(Z;β ) · s , φ(;θ) λ · s , φ(;θ)
s s s D s θ θ
− · δf ∇ · L2 − · δf ∇ · L2
h D E D E i
δΦ(X,Z;f(;β )) δΨ(X,Z;f(;∂ β ))
= α E g(Z;∂ β ) · s ,φ(;θ) λ · s s ,φ(;θ) .
θ D s s
∇ − · δf · L2 − · δf · L2
h D E D E i
δΦ(X,Z;f) δΨ(X,Z;f)
where the second inequality holds since a constant, s independent function, is
δf − δf
linear in f, and ∂ f(;β ),∂ g(;β ) satisfies
s s s s
· ·
∂ f(w;β )= ∂ φ(w;θ)β (θ,ω) d(θ,ω)= φ(w;θ)∂ β d(θ,ω)= f(w;∂ β ), w
s s s s s s s s
∀ ∈ W
Z Z
(cid:0) (cid:1)
∂ g(z;β )= ∂ ψ(z;ω)β (θ,ω) d(θ,ω)= ψ(z;ω)∂ β d(θ,ω)= g(z;∂ β ), z
s s s s s s s s
∀ ∈ Z
Z Z
(cid:0) (cid:1)
A similar computation for ∂ vg(θ,ω;β ) gives
s s
∂ vg(θ,ω;β ) = α E Φ(X,Z;f(,∂ β )) φ(Z;ω) g(Z;∂ β ) φ(Z;ω)
s s ω D s s s s
∇ · · − ·
h i
We recall that Φ(x,z;f) = Φ(x,z;f)e Φ(x,z;0) is the linear component in Φ. We note that the
−
δΦ(X,Z;f) δΦ(X,Z;f)
variation of Φ is the same as the variation of Φ with respect to f, =
e δf δf
We define the potential (θ,ω;∂ β ) as e
e s s
V
δΦ(X,Z;f(;β )) δΨ(X,Z;f(;∂ β ))
(θ,ω;∂ β )= E g(Z;∂ β ) · s ,φ(;θ) +λ · s s ,φ(;θ)
s s D s s
V · δf · L2 · δf · L2
h D E D E i
E Φ(X,Z;f(,∂ β )) ψ(Z;ω) g(Z;∂ β ) ψ(Z;ω)
D s s s s
− · · − ·
h i
Then, the vector fieeld ∂ v(θ,ω;β ) is the gradient of such potential (θ,ω;∂ β )
s s s s
V
∂ vf(θ;β )
s s
∂ v(θ,ω;β )= = α (θ,w;∂ β ),
s s   s s
∂ vg(ω;β ) − ∇V
s s
 
 
where the gradient operator = ( , ).
θ ω
∇ ∇ ∇
Then, by Stoke’s formula and integration by parts, we have
∂ v(;β ),u = α (θ,ω;∂ β )u (θ,w)β (θ,w)d(θ,w)
s · s s βs − ∇V s s s s
Z
(cid:10) (cid:11)
= α (θ,w;∂ β )div(u β )d(θ,w)
s s s s
V
Z
= α (θ,w;∂ β )∂ β d(θ,w)
s s s s
− V
Z
47Integrating potential with respect to ∂ β simplied the expression to
s s
V
α (θ,ω;∂ β )∂ β d(θ,ω)
s s s s
V
Z
δΦ(X,Z;f(;β ))
= E g(Z;∂ β ) · s , αφ(;θ)∂ β (dθ)
D s s s s
· δf · L2
h D Z E i
δΨ(X,Z;f(;∂ β ))
+E λ · s s , αφ(;θ)∂ β (dθ)
D · δf · s s L2
h (cid:10) Z (cid:11) i
E Φ(X,Z;f(,∂ β )) αψ(Z;ω)∂ β (dω) g(Z;∂ β ) αψ(Z;ω)∂ β (dω)
D s s s s s s s s
− · · − ·
h Z Z i
δΨ(X,Z;f(;∂ β ))
= E λ e · s s ,f(;∂ β ) +g(Z;∂ β )2 . (A.18)
D s s s s
· δf · L2
h D E i
By convexity of Ψ(x,z;f) and the fact that Ψ(x,z;0) = 0 for all (x,z) , it holds that
∈X ×Z
δΨ(x,z;f(;∂ β ))
s s
Ψ(x,z;f(;∂ β )) · ,f(;∂ β ) , (x,z) . (A.19)
s s s s
· ≤ δf · L2 ∀ ∈ X ×Z
D E
Integrating (A.18) with respect to s [0,1], we have that
∈
1 1 δΨ(X,Z;f(;∂ β ))
∂ v(;β ),u ds= E λ · s s ,f(;∂ β ) +g(Z;∂ β )2 ds
Z0
(cid:10)
s · s s (cid:11)βs −
Z0
D
h
·
(cid:10)
δf · s s (cid:11)L2 s s
i
E λ Ψ(X,Z;f(;∂ β ))+g(Z;∂ β )2 ds
D s s s s
≤ − · ·
h i 2
E λ Ψ(X,Z;f(;ρ ) f(;ρ∗))+ g(Z;ρ ) g(Z;ρ∗) ds
D t t
≤ − · · − · −
h (cid:16) (cid:17) i
= E λ Ψ(X,Z;f(;ρ ) f∗())+ g(Z;ρ ) g∗(Z) 2 . (A.20)
D t t
− · · − · −
h (cid:0) (cid:1) i
where the first inequality holds due to (A.19), and the second inequality holds due to Jensen’s
inequality.
Upper bounding term (ii). By Lemma D.6, for term (ii) in (A.17), it holds that
v(θ,ω;β ),∂ (u (θ,ω)β (θ,ω)) d(θ,ω)
s s s s
Z
(cid:10) (cid:11)
= v(θ,ω;β ),u (θ,ω) u (θ,ω)β (θ,ω) d(θ,ω)
s s s s
∇ ⊗
Z
(cid:10) (cid:11)
sup v(θ,ω;β ) u 2 . (A.21)
≤ k∇ s kF ·k s kβs
θ,ω
where denotes the Frobenius norm. Since u is the velocity field corresponding to the geodesic
F s
k·k
connecting ρ∗, by assumptions, it holds that
u 2 = (ρ ,ρ∗)2 4 (ρ ,ρ∗)2 = 4α−2D¯2 = (α−2) (A.22)
k s kβs W2 t ≤ W2 0 O
48On the other hand, by the definition of v in (A.15), we have that
v(θ,ω;β ) 2 = vf(θ;β ) 2 + vg(ω;β ) 2 (A.23)
k∇ s kF k∇θ s kF k∇ω s kF
By the definition of vf in (3.6), we have that
δΦ(X,Z;f(;β ))
vf(θ;β ) α E g(Z;β ) · s (w′)dw′ sup 2 φ(w;θ) 2
∇θ s F ≤ · D s · δf · ∇θ,θ F
(cid:13) (cid:13) (cid:13) (cid:13) +αh(cid:12) (cid:12) (cid:12)E λ
ZW
δΨ(X,Z;f( ·;β s)) (w′)dw′ (cid:12) (cid:12) (cid:12)i
suw p∈W
(cid:13) (cid:13)2 φ(w;θ) 2(cid:13) (cid:13)
· D · δf · ∇θ,θ F
h
(cid:12)ZW
(cid:12)i
w∈W
(cid:13) (cid:13)
αB E λC (cid:12) (cid:12)f(W;β ) +C g(Z;β ) . (cid:12) (cid:12) (cid:13) (cid:13) (A.24)
2 D Ψ s 2 s
≤ ·
h (cid:12) (cid:12) (cid:12) (cid:12)i
(cid:12) (cid:12) (cid:12) (cid:12)
where the first inequality follows from Assumption 4.1, and second inequality comes from the
integrability conditions in Assumption 4.3.
Thus, it suffices to upper bound f(w;β ) and g(z;β ) for all (w,z) . For f(w;β ), we
s s s
∈ W ×Z
have that
f(w;β ) = α φ(wθ)dβ (θ,ω) = α φ(w;θ) d(β ρ )(θ,ω)
s s s 0
· · −
(cid:12) (cid:12) (cid:12)Z (cid:12) (cid:12)Z (cid:12)
(cid:12) (cid:12) αB(cid:12) (cid:12)1 1(β s,ρ 0) αB(cid:12) (cid:12) 1 2(cid:12) (cid:12)(β s,ρ 0). (cid:12) (cid:12) (A.25)
≤ ·W ≤ ·W
Moreover, it holds that
(β ,ρ ) (β ,ρ∗)+ (ρ∗,ρ ) (ρ ,ρ∗)+ (ρ ,ρ∗) 3α−1D¯, (A.26)
2 s 0 2 s 2 0 2 t 2 0
W ≤ W W ≤ W W ≤
where the second inequality follows from the fact that β ,s [0,1] is the geodesic connecting ρ
s t
∈
and ρ∗ and the last inequality follows from (ii) in Lemma 4.6. Plugging (A.26) into (A.25), we have
that
f(w;β ) (1), w . (A.27)
s
≤ O ∀ ∈ W
(cid:12) (cid:12)
(cid:12) (cid:12)
Througha similar argument, such an upperboundcan also beestablished for g(z;β ) for all z ,
s
∈ Z
g(z;β ) (1), z . (A.28)
s
≤ O ∈ Z
(cid:12) (cid:12)
(cid:12) (cid:12)
Plugging (A.27) and (A.28) into (A.24), we establish an upper bound for vf(θ;β ) ,
∇θ s F
(cid:13) (cid:13)
(cid:13) (cid:13)
vf(θ;β ) (α). (A.29)
∇θ s F ≤ O
(cid:13) (cid:13)
(cid:13) (cid:13)
49Similarly, by the definition of vg in (3.6) we have that
vg(ω;β ) α E Φ(X,Z;f(;β )) + g(Z;β ) sup 2 ψ(z;ω) 2
∇ω s F ≤ · D · s s · ∇ω,ω F
z∈Z
(cid:13) (cid:13) h(cid:12) (cid:12) (cid:12) (cid:12)i (cid:13) (cid:13)
(cid:13) (cid:13) αB E(cid:12) Φ(X,Z;0) +(cid:12) C(cid:12) f(W;β(cid:12) ) + g(cid:13) (Z;β ) = (cid:13) (α). (A.30)
2 D 2 s s
≤ · O
(cid:16) h(cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12)(cid:17)
(cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12)
Combining the bound from (A.29) and (A.30) and plugging into(A.23), it holds that
2 2 2
v(θ,ω;β ) = vf(θ;β ) + vg(ω;β ) (α2). (A.31)
s θ s ω s
∇ F ∇ F ∇ F ≤ O
(cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13)
(cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13)
Equation (A.22) a(cid:13)nd (A.31) pr(cid:13)ovide(cid:13)upper bound(cid:13)s on (cid:13)the two term(cid:13)s involved in (A.21). Plugging
the upper bounds that we have achieved, it holds that
v(θ,w;β ),∂ (u (θ,ω)β (θ,ω)) d(θ,ω) (α−1). (A.32)
s s s s
≤ O
Z D E
Now combining (A.20) and (A.32), we have that
1d (ρ ,ρ∗)2
W2 t η E λΨ(X,Z;f(,ρ ) f(;ρ∗))+ g(Z;ρ ) g(Z;ρ∗) 2 +C η α−1.
D t t ∗
2 dt ≤ − · · − · − · ·
h (cid:0) (cid:1) i
where C = C B ,B ,B ,C,λ,D¯ > 0 is a constant. This completes the proof of Lemma A.1.
∗ ∗ 0 1 2
(cid:0) (cid:1)
We are now ready to present the proof of Theorem 4.7 with the help of Lemma A.1.
Proof of Theorem 4.7. We define
t∗ = inf τ R E λΨ(X,Z;f(,ρ ) f(;ρ∗))+ g(Z;ρ ) g(Z;ρ∗) 2 <C α−1 (A.33)
+ D τ τ ∗
∈ · − · − ·
(cid:12)
n (cid:12) (cid:2) (cid:0) (cid:1) (cid:3) o
(cid:12)
Also, we define (cid:12)
t = inf τ R (ρ ,ρ∗) > 2 (ρ ,ρ∗) (A.34)
∗ + 2 τ 2 0
∈ W W
(cid:12)
n (cid:12) o
In other words, (A.16) of Lemma A.1 holds(cid:12) (cid:12)for t t ∗, and for 0 t min t ∗,t∗ , we have
≤ ≤ ≤ { }
1d (ρ ,ρ∗)2
W2 t η E λΨ(X,Z;f(,ρ ) f(;ρ∗))+ g(Z;ρ ) g(Z;ρ∗) 2 +C ηα−1 0
D t t ∗
2 dt ≤ − · · − · − · ≤
h (cid:0) (cid:1) i
We now show that t > t∗ by contradiction. By the continuity of (ρ ,ρ∗)2 with respect to t
∗ 2 t
W
Ambrosio et al. (2008), since (ρ ,ρ∗) < 2 (ρ ,ρ∗), it holds that t > 0. Let’s assume t t∗,
2 0 2 0 ∗ ∗
W W ≤
then t = min t ,t∗ . Thus, by (A.16), (A.33), (A.34), it holds that for 0 t t that
∗ ∗ ∗
{ } ≤ ≤
1d (ρ ,ρ∗)2
2 t
W 0
2 dt ≤
50which further implies that (ρ ,ρ∗) (ρ ,ρ∗). This contradicts the definition of t in (A.34).
W2 t∗
≤
W2 0 ∗
Thus, it holds that t t∗, which implies that (A.16) of Lemma A.1 holds for any 0 t t∗. We
∗
≥ ≤ ≤
now discuss two different situations.
Scenario (i) If t T, then it holds that
∗
≤
inf E λΨ(X,Z;f(,µ ) f∗)+ g(Z;ν ) g∗ 2
D t t
t∈[0,T] · − −
h (cid:0) (cid:1) i
E λΨ(X,Z;f(,µ ) f∗)+ g(Z;ν ) g∗ 2
≤
D
·
t∗
−
t∗
−
h (cid:0) (cid:1) i
< C α−1 = (T−1+α−1). (A.35)
∗
O
Therefore, (A.35) implies Theorem 4.7 in this scenario.
Scenario (ii) If t > T, then (A.16) in Lemma A.1 holds for 0 t T. Re-arranging the terms,
∗
≤ ≤
we have the following inequality for all 0 t T,
≤ ≤
1d (ρ ,ρ∗)2
E λΨ(X,Z;f(,µ ) f∗)+ g(Z;ν ) g∗ 2 η−1 W2 t +C α−1 (A.36)
D t t ∗
· − − ≤ − · 2 dt ·
h (cid:0) (cid:1) i
This further suggests the following upper bound,
inf E λΨ(X,Z;f(,µ ) f∗)+ g(Z;ν ) g∗ 2
D t t
t∈[0,T] · − −
h T (cid:0) (cid:1) i
T−1 E λΨ(X,Z;f(,µ ) f∗)+ g(Z;ν ) g∗ 2 dt
D t t
≤ · · − −
Z0
h (cid:0) (cid:1) i
1/2 η−1 T−1 (ρ ,ρ∗)2+C α−1
2 0 ∗
≤ · · ·W ·
1/2 α−2 D¯2 η−1 T−1+C α−1 = (T−1+α−1), (A.37)
∗
≤ · · · · · O
where the second inequality comes from integrating (A.36) in for t [0,T], the third inequality
∈
comes from (ii) in Lemma 4.6 and last equality comes from setting η to α−2. Therefore, (A.37)
implies Theorem 4.7 in this scenario.
Based on the discussion of scenarios (i) and (ii) above, we finish the proof of Theorem 4.7.
A.3 Proof of Theorem 4.9
Proof. We nowproveTheorem 4.9. For notation simplicity, wedenotef = f(;µ )as theestimator
t t
·
at time t. Recall the definition of J(f) from (2.3) and δ¯(z;f) from (2.2).
J(f) = E 1/2 δ¯(Z;f)2+λ Ψ(X,Z;f) , δ¯(z;f) = E Φ(X,Z;f) Z = z .
D X|Z
· ·
(cid:2) (cid:3) (cid:2) (cid:12) (cid:3)
(cid:12)
51Plugging the definition of J(f), it holds that
inf J(f ) J(f∗)
t
t∈[0,T] −
= inf E 1/2 δ¯(Z,f )2 δ¯(Z,f∗)2 +λ Ψ(X,Z;f ) Ψ(X,Z;f∗) . (A.38)
D t t
t∈[0,T] · − −
h (cid:16) (cid:17) (cid:16) (cid:17)i
Similar to the proof of Theorem 4.7, we define t as,
∗
t = inf τ R (ρ ,ρ∗)> 2 (ρ ,ρ∗) .
∗ + 2 τ 2 0
∈ W W
(cid:12)
n (cid:12) o
(cid:12)
We attempt to upper-bound (A.38) in(cid:12)two different scenarios, depending on the value of t
∗
compared with T.
Scenario (i) If t T, then we have that
∗
≤
inf J(f ) J(f∗) J(f ) J(f∗). (A.39)
t∈[0,T]
t
− ≤
t∗
−
In order to upper-bound right-hand side of (A.39), we need to uniformly upper-bound f (w) and
t∗
f∗(w) for all w . For f (w) = f(w;µ ), we have that
∈ W
t∗ t∗
sup f(w;µ ) = α sup φ(w;θ)dµ (θ) = α sup φ(w;θ)d(µ µ )(θ)
|
t∗
| ·
t∗
·
t∗
−
0
w∈W w∈W (cid:12)Z (cid:12) w∈W (cid:12)Z (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
αB (cid:12) (µ ,µ ) αB (cid:12) (µ ,µ(cid:12)) αB (ρ ,ρ∗)+(cid:12) (ρ ,ρ∗)
≤
1 ·W1 t∗ 0
≤
1 ·W2 t∗ 0
≤
1
·
W2 t∗ W2 0
(cid:16) (cid:17)
3B D¯ = (1). (A.40)
1
≤ · O
where the first inequality follows from Lemma D.7, the second inequality follows from Lemma C.5.
The last inequality follows from (ii) in Lemma (4.6) and definition of t . For f∗, a similar chain of
∗
inequalities would apply,
sup f(w;µ∗) = α sup φ(w;θ)dµ∗(θ) = α sup φ(w;θ)d(µ∗ µ )(θ)
0
| | · · −
w∈W w∈W (cid:12)Z (cid:12) w∈W (cid:12)Z (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
αB (cid:12) (µ∗,µ ) αB (cid:12) (µ∗,µ )(cid:12) αB (ρ∗,ρ ) (cid:12)
1 1 0 1 2 0 1 2 0
≤ ·W ≤ ·W ≤ ·W
B D¯ = (1). (A.41)
1
≤ · O
With uniform bounds on f and f∗, we are now ready to upper-bound inf J(f ) J(f∗)
t∗ t∈[0,T] t
−
52through upper-bounding J(f ) J(f∗),
t∗
−
δΨ(X,Z;f )
J(f ) J(f ) E δ¯(Z;f ) E Φ(X,Z;f f∗)Z +λ t∗ ,f f∗
t∗
−
∗
≤
D t∗
·
X|Z t∗
− | · δf
t∗
− L2
h (cid:2) (cid:3) D E i
supΦ(x,z;0) +C e sup f(w;µ ) E C f(W;µ ) f(W;µ∗)
≤ x,z| |
Φ
· w∈W|
t∗
| ·
D Φ
·|
t∗
− |
(cid:16) (cid:17) h i
+λC E f(W;µ ) f(W;µ∗)
Ψ
·
D
|
t∗
− |
h i 1/2
B E f(W;µ ) f(W;µ∗) B E λ f(W;µ ) f(W;µ∗)2
≤
∗
·
D
|
t∗
− | ≤
∗
·
D
|
t∗
− |
h 1/2i (cid:16) h i(cid:17)
B E Ψ(X,Z;f f∗) B α−1/2, (A.42)
≤
∗
·
D t∗
− ≤
∗
·
(cid:16) h i(cid:17)
where B = B (Φ,c ,C ,C ,λ,C,B ,D¯,C ) >0 is a constant and its values changes from line to
∗ ∗ φ Φ Ψ 1 ∗
line. Thesecond inequality follows from (A.40) and (A.41). The last inequality follows from (A.35)
in the proof of Theorem (4.7). Therefore, in this scenario, we have that
inf J(f ) J(f ) J(f ) J(f ) (T−1/2+α−1/2). (A.43)
t∈[0,T]
t
−
∗
≤
t∗
−
∗
≤ O
Equation (A.43) concludes the proof of Theorem 4.9 in the scenario of t T.
∗
≤
Scenario (ii) If t > T, by definition of t , we have that
∗ ∗
(µ ,µ∗) (ρ ,ρ∗) 2 (ρ ,ρ∗)= 2α D¯, t [0,T].
2 t 2 t 2 0
W ≤ W ≤ W · ∀ ∈
Following the same arguments in (A.40) and (A.41), we have a uniform upper-bound for f for all
t
t [0,T] and f∗ that writes,
∈
sup f(w;µ ) + f(w;µ∗) 4B D¯ = (1), t [0,T].
t 1
≤ · O ∀ ∈
w∈W
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
Following the same derivation of (A.42), we have that
1/2
inf J(f ) J(f ) B inf B E Ψ(X,Z;f f∗)
t ∗ ∗ ∗ D t
t∈[0,T] − ≤ ·t∈[0,T] · −
(cid:16) h i(cid:17)
1/2
B inf E Ψ(X,Z;f f∗)
∗ D t
≤ · t∈[0,T] −
(cid:16) h i(cid:17)
T 1/2
B T−1 E Ψ(X,Z;f f∗) dt
∗ D t
≤ · · −
(cid:16)
Z0
h i (cid:17)
B 1/2 D¯2 T−1+C α−1 = (T−1/2+α−1/2), (A.44)
∗ ∗
≤ · · · · O
q
where the last inequality follows from (A.36) and (A.37) in the proof of Theorem 4.7. Equation
(A.44) concludes the proof of Theorem (4.9) in the scenario of t >T.
∗
53Based on the discussion of scenarios (i) and (ii) above, we finish the proof of Theorem 4.9.
B Mean Field Limit of Neural Networks
In this section, we prove Proposition 4.4. The formal version is presented as follows. Let ρ (θ,ω)=
t
µ (θ) ν (ω), where (µ ,ν ) is the PDE solution in (3.7) and ρ (θ,ω) = N−1 N δ (θ) δ (ω)
t ⊗ t t t k · i=1 θ ki · ω ki
is the empirical distribution of (θ ,ω ). Here we omit the dependence of the emPpirical distribution
k k
b
ρ on N and stepsize scale ǫ for notational simplicity.
k
Pbroposition B.1 (Formal Version of Proposition 4.4). Let h : RD RD R by any continuous
× →
function such that h 1 and Lip(h) 1. Under Assumption 4.1, 4.3, with probability at least
∞
k k ≤ ≤
1 5δ, it holds that
−
sup h(θ,w)dρ (θ,w) h(θ,w)dρ (θ,w)
kǫ k
−
k≤T/ǫ(cid:12)Z Z (cid:12)
(k∈N)(cid:12) (cid:12)
(cid:12) b (cid:12)
(cid:12) (cid:12)
B eBT log(N/δ)/N + ǫ (D+log(N/δ)) .
≤ · · ·
(cid:16)q q (cid:17)
Here B is a constant that depends on α,η,λ,B ,B and B .
0 1 2
The proof of Proposition B.1 based heavily on Mei et al. (2018, 2019); Araújo et al. (2019);
Zhang et al. (2020), which make use of the propagation of chaos arguments in Sznitman (1991).
Recall that (vf(;ρ),vg(;ρ)) is the a vector field defined as,
· ·
δΦ(X,Z;f(;ρ)) δΨ(X,Z;f(;ρ))
vf(θ;ρ) =αE g(Z;ρ) · , φ(;θ) λ · , φ(;θ) ,
D θ θ
− · δf ∇ · L2 − · δf ∇ · L2
h D E D E i
vg(w;ρ) =αE Φ(X,Z;f(,ρ)) ψ(Z;ω) g(Z;ρ) ψ(Z;ω) . (B.1)
D ω ω
· ·∇ − ·∇
h i
From now on, we equivalently write θi = θ (k), ωi = ω (k) to emphasize the dependence on
k i k i
iterations. For abbreviation, we denote θ(N)(k) = θ (k) N and ω(N)(k) = ω (k) N . We recall
{ i }i=1 { i }i=1
the finite-width representation of f(;θ(N)) and g(;ω(N)) are,
· ·
N N
α α
f(,θ(N)) = φ(;θ ), g(,ω(N)) = ψ(;ω ).
i i
· N · · · N · ·
i=1 i=1
X X
54Correspondingly, we defined the finite-width counter-part of vf and vg as following,
δΦ(X,Z;f(;θ(N)))
vf(θ;θ(N),ω(N))= αE g(Z;ω(N)) · , φ(;θ)
D − · δf ∇θ · L2
(cid:20)
(cid:10) (cid:11)
b
δΨ(X,Z;f(;θ(N)))
λ · , φ(;θ) ,
− · δf ∇θ · L2
(cid:21)
(cid:10) (cid:11)
vg(w;θ(N),ω(N))= αE Φ(X,Z;f(,θ(N))) ψ(Z;ω) g(Z;ω(N)) ψ(Z;ω) . (B.2)
D ω ω
· ·∇ − ·∇
(cid:20) (cid:21)
And wbe also defined the stochastic counter-part,
δΦ(x ,z ;f(;θ(N)))
Vf (θ;θ(N),w(N)) = α g(z ;ω(N)) k k · , φ(;θ)
k − k · δf ∇θ · L2
(cid:20) D E
b δΨ(x ,z ;f(;θ(N)))
k k
λ · , φ(;θ) ,
θ
− · δf ∇ · L2
D E (cid:21)
Vg (ω;θ(N),w(N)) = α Φ(x ,z ;f(;θ(N))) ψ(z ;ω) g(z ;ω(N)) ψ(z ;ω) . (B.3)
k k k · ·∇ω k − k ·∇ω k
(cid:16) (cid:17)
whereb(x ,z ) . FollowingfromMei et al.(2019);Araújo et al.(2019),weconsiderthefollowing
k k
∼ D
four dynamics.
• Stochastic Gradient Descent (SGD). We consider the following SGD dynamics for
θ(N)(k) and ω(N)(k), where k N, with θ (0) i.i.d. µ ,w (0) i.i.d. ν (i [N]) as its ini-
i 0 i 0
∈ ∼ ∼ ∈
tialization,
θ (k+1) = θ (k)+ηǫ Vf (θ (k);θ(N)(k),ω(N)(k)),
i i · k i
ω i(k+1) = ω i(k)+ηǫ ·bV kg (ω i(k);θ(N)(k),ω(N)(k)). (B.4)
Note that this dynamics is equivalent to (3.3b).
• Population Gradient Descent (PGD). We consider the following population gradient
descent dynamics for θ˘(N)(k) and ω˘(N)(k), wherek N, with θ˘(0) = θ (0), ω˘ (0) = ω (0) (i
i i i i
∈ ∈
[N]) as its initialization,
θ˘(k+1) = θ˘(k)+ηǫ vf(θ˘(k);θ˘(N)(k),ω˘(N)(k)),
i i i
·
ω˘ (k+1) = w (k)+ηǫ vg(ω˘ (k);θ˘(N)(k),ω˘(N)(k)). (B.5)
i i b i
·
• Continuous-time Population Gradient Dbescent (CTPGD). We consider the following
continuous time population gradient descent dynamics for θ(N)(t) and ω(N)(t), where t R ,
+
∈
with θ (0) = θ (0), ω (0) = ω (0) (i [N]) as initialization,
i i i i e
∈ e
d d
θe i(t) = η vf(θei(t);θ(N)(t),ω(N)(t)), ω i(t) = η vg(ω i(t);θ(N)(t),ω(N)(t)). (B.6)
dt · dt ·
e b e e e e b e e e
55• Ideal particle (IP). We consider the following ideal particle dynamics for θ¯(N)(t) and
w¯(N)(t), where t R , with θ¯(0) = θ (0), w¯ (0) = w (0) (i [N]) as initialization,
+ i i i i
∈ ∈
d d
θ¯(t) = η vf(θ¯(t);ρ ), ω¯ (t) = η vg(ω¯ (t);ρ ). (B.7)
i i t i i t
dt · dt ·
We aim to prove that ρ = N−1 N δ δ weakly converges to ρ . For any continuous
k · i=1 θi(k) · wi(k) kǫ
function h that satisfies the assumPptions of Proposition B.1, using the IP, CTPGD and PGD
b
dynamics as interpolating dynamics, we have,
PDE−SGD
h(θ,ω)dρ (θ,ω) h(θ,ω)dρ (θ,ω)
kǫ k
z }−| {
(cid:12)Z Z (cid:12)
(cid:12) N (cid:12)
(cid:12) h(θ,ω)dρ (θ) N−1 b h θ¯((cid:12) kǫ),ω¯ (kǫ)
kǫ i i
≤ (cid:12) − (cid:12)
(cid:12)Z Xi=1 (cid:16) (cid:17)(cid:12)
(cid:12) (cid:12)
(cid:12) N N (cid:12)
+N(cid:12) −1 h θ¯(kǫ),ω¯ (kǫ) h θ (kǫ),ω (k(cid:12)ǫ)
i i i i
(cid:12) − (cid:12)
(cid:12)Xi=1 (cid:16) (cid:17) Xi=1 (cid:16) (cid:17)(cid:12)
(cid:12) (cid:12) N N e e (cid:12) (cid:12)
+N−1(cid:12) h θ (kǫ),ω (kǫ) h θ˘(k),ω˘ (k) (cid:12)
i i i i
(cid:12) − (cid:12)
(cid:12)Xi=1 (cid:16) (cid:17) Xi=1 (cid:16) (cid:17)(cid:12)
(cid:12) (cid:12) N e e N (cid:12) (cid:12)
+N−1(cid:12) h θ˘(k),ω˘ (k) h(θ (k),ω (k)) (cid:12)
i i i i
(cid:12) − (cid:12)
(cid:12)Xi=1 (cid:16) (cid:17) Xi=1 (cid:12)
(cid:12) (cid:12)
(cid:12) N (cid:12)
h((cid:12)θ,ω)dρ (θ) N−1 h θ¯(kǫ),ω¯ (kǫ)(cid:12) + (θ¯,ω¯)(N)(kǫ) (θ,ω)(N)(kǫ)
kǫ i i
≤ (cid:12) − · (cid:12) − (N)
(cid:12)Z Xi=1 (cid:16) (cid:17)(cid:12) (cid:13) (cid:13)
(cid:12)
(cid:12) PDE−IP
(cid:12)
(cid:12)
(cid:13)
(cid:13)
IP−CTPeGeD (cid:13)
(cid:13)
(cid:12) (cid:12)
| {z }
+ |(θ,ω)(N)(kǫ) (θ˘,ω˘)(N{z)(k) + (θ˘,ω˘)(N)(k}) (θ,ω)(N)(k) . (B.8)
− (N) − (N)
(cid:13) (cid:13) (cid:13) (cid:13)
(cid:13) (cid:13) e e CTPGD−PGD (cid:13) (cid:13) (cid:13) (cid:13) PGD−SGD (cid:13) (cid:13)
The last in|equality follows{zfrom the fact }tha|t Lip(h) 1.{zHere the norm} denotes the
(N)
≤ k · k
supremum norm over the sequence of vectors (θ,w)(N) = (θ ,w ) N ,
{ i i }i=1
(θ,ω)(N) = sup (θ ,ω ) . (B.9)
i i
(N) i∈[N]
(cid:13) (cid:13) (cid:13) (cid:13)
(cid:13) (cid:13) (cid:13) (cid:13)
In whatfollows, we defineB > 0 a(cid:13)s a consta(cid:13)nt with its v(cid:13)alue var(cid:13)yingfrom line to line. We establish
the following lemmas as upper-bound of the four terms on the right-hand side of (B.8).
Lemma B.2 (Upper Bound of PDE IP). Under Assumption 4.1 and 4.3, with probability at
−
least 1 δ, it holds that
−
N
sup h(θ,ω)dρ (θ,ω) N−1 h θ¯(t),ω¯ (t) B log(NT/δ)/N. (B.10)
t i i
− ≤ ·
t∈[0,T] (cid:12) (cid:12)Z Xi=1
(cid:0)
(cid:1)(cid:12)
(cid:12)
q
(cid:12) (cid:12)
56Proof. See §B.1.1 for a detailed proof.
Lemma B.3 (Upper Bound of IP CTPGD). Under Assumption 4.1 and 4.3, with probability at
−
least 1 2δ, it holds that
−
sup (θ¯,ω¯)(N)(t) (θ,ω)(N)(t) B eBT log(N/δ)/N. (B.11)
t∈[0,T] − (N) ≤ · ·
(cid:13) (cid:13) q
Proof. See §B.1.2 for a(cid:13) (cid:13) detailed proof. e e (cid:13) (cid:13)
Lemma B.4 (Upper Bound of CTPGD PGD). Under Assumption 4.1 and 4.3, it holds that
−
sup (θ,ω)(N)(kǫ) (θ˘,ω˘)(N)(k)) B eBT ǫ. (B.12)
k≤T/ǫ − (N) ≤ · ·
(cid:13) (cid:13)
Proof. See §B.1.3 for a detai(cid:13) (cid:13) lede pe roof. (cid:13) (cid:13)
Lemma B.5 (Upper Bound of PGD SGD). Under Assumption 4.1 and 4.3, with probability at
−
least 1 2δ, it holds that
−
sup (θ˘,ω˘)(N)(k)) (θ,w)(N)(k) B eBT ǫ (D+log(N/δ). (B.13)
k≤T/ǫ − (N) ≤ · · ·
(cid:13) (cid:13) q
(cid:13) (cid:13)
Proof. See §B.1.4 fo(cid:13) r a detailed proof. (cid:13)
With these lemmas, we are now ready to present the proof of Proposition B.1.
Proof. Plugin(B.10),(B.12),(B.12)and(B.13)to(B.8)andconditionontheintersection ofevents
in Lemma B.2, B.3, B.4 and B.5, we have that
h(θ,ω)dρ (θ,ω) h(θ,ω)dρ (θ,ω) B eBT log(N/δ)/N + ǫ (D+log(N/δ)) ,
kǫ k
− ≤ · · ·
(cid:12)Z Z (cid:12) (cid:16)q q (cid:17)
(cid:12) (cid:12)
(cid:12) b (cid:12)
with probability at least 1 5δ. Thus, we complete the proof of Proposition B.1.
−
B.1 Proofs of Lemmas B.2-B.5
In this section, we present the proofs of Lemmas B.2-B.5, which based heavily on Mei et al. (2018,
2019); Araújo et al. (2019); Zhang et al. (2020). The required supporting technical lemmas are in
§C. The constant B presented in the proof is a positive constant whose values varies from line to
line for notational simplicity.
57B.1.1 Proof of Lemma B.2
Proof. We first consider the ideal particle dynamics in (B.7). It holds that θ¯(t) µ ,ω¯ (t)
i t i
∼ ∼
ν , (i [N]) (Proposition 8.1.8 in Ambrosio et al. (2008)). Since the randomness of θ¯(t) and ω¯ (t)
t i i
∈
comesfromθ (0)andω (0)respectivelywhileθ (0)andω (0) (i [N])areindependent,θ¯(t) i.i.d. µ ,
i i i i i t
∈ ∼
ω¯ (t) i.i.d. ν (i [N]). Due to independence of θ¯(t) and ω¯ (t), we also have (θ¯(t),ω¯ (t)) i.i.d. ρ (i
i t i i i i t
∼ ∈ ∼ ∈
[N]). This implies the following,
N
E N−1 h(θ¯(t),w¯ (t)) = h(θ,ω)dρ (θ,ω).
ρt
·
i i t
h Xi=1 i Z
For notational simplicity, we denote γ = (θ ,ω ), similar notations also generalize to γ¯ ,γ ,γ˘ . Let
i i i i i i
γ1,(N) = γ ,...,γ1....,γ and γ2,(N) = γ ,...,γ2,...,γ be two sets of variables that only
{ 1 i N } { 1 i N } e
differ in the i-th element. Then, by the assumption that f 1, we have the following bounded
∞
k k ≤
difference property,
N N
N−1 h(γ1) N−1 h(γ2) = N−1 h(γ1) h(γ2) 2/N.
j − j ·| i − i | ≤
(cid:12) j X=1 j X=1 (cid:12)
(cid:12) (cid:12)
Applying McDiar(cid:12)mid’s inequality (Wainwright, 2(cid:12)019), we have for a fixed t [0,T] that
∈
N
P N−1 h(γ¯ (t)) h(γ)dρ (γ) p exp Np2/4 . (B.14)
i t
(cid:12) − (cid:12) ≥ ! ≤ −
(cid:12) Xi=1 Z (cid:12) (cid:16) (cid:17)
(cid:12) (cid:12)
Moreover, we have for(cid:12)any s,t [0,T] that, (cid:12)
(cid:12) ∈ (cid:12)
N N
N−1 h(γ¯ (t)) h(γ)dρ (γ) N−1 h(γ¯ (s)) h(γ)dρ (γ)
i t i s
(cid:12) − − − (cid:12)
(cid:12)(cid:12) Xi=1 Z (cid:12) (cid:12) Xi=1 Z (cid:12)(cid:12)
(cid:12)(cid:12) (cid:12) (cid:12) (cid:12)(cid:12)
(cid:12)(cid:12) N N(cid:12) (cid:12) (cid:12)(cid:12)
(cid:12) N−1 h(γ¯ (t)) N−1 h(γ¯ (s)) + h(γ)dρ (γ) h(γ)(cid:12)dρ (γ)
i i t s
≤ − −
(cid:12) Xi=1 Xi=1 (cid:12) (cid:12)Z Z (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) γ¯(N)(t) γ¯(N)(s) + (ρ ,ρ ) (cid:12) (cid:12) (cid:12)
1 t s
≤ − (N) W
(cid:13) (cid:13)
(cid:13) (cid:13)γ¯(N)(t) γ¯(N)(s)(cid:13) (cid:13) + 2(ρ t,ρ s)
≤ − (N) W
(cid:13) (cid:13)
(cid:13) (cid:13)θ¯(N)(t) θ¯(N)(s)(cid:13) (cid:13) + w¯(N)(t) w¯(N)(s) + 2(µ t,µ s)+ 2(ν t,ν s).
≤ − (N) − (N) W W
(cid:13) (cid:13) (cid:13) (cid:13)
(cid:13) (cid:13) (cid:13) (cid:13)
where the seco(cid:13)nd inequality foll(cid:13)ows fro(cid:13)m the fact that L(cid:13)ip(h) 1 and Lemma D.7. The last
≤
inequality follows from the definition of γ(N), (B.9) and Lemma C.5. Applying (C.12), (C.14) of
Lemma C.2, we have for any s,t [0,T] that
∈
N N
N−1 h(γ¯ (t)) h(γ)dρ N−1 h(γ¯ (s)) h(γ)dρ B t s .
i t i s
(cid:12) − − · − (cid:12) ≤ · −
(cid:12)(cid:12) Xi=1 Z (cid:12) (cid:12) Xi=1 Z (cid:12)(cid:12) (cid:12) (cid:12)
(cid:12)(cid:12) (cid:12) (cid:12) (cid:12)(cid:12) (cid:12) (cid:12)
(cid:12)(cid:12) (cid:12) (cid:12) (cid:12)(cid:12) (cid:12) (cid:12)
(cid:12) (cid:12)
58Apply the union bound to (B.14) for t ι 0,1,..., T/ι , we have that
∈ ·{ ⌊ ⌋}
N
P sup N−1 h(γ¯ (t)) h(γ)dρ (γ) p+B ι (T/ι+1) exp Np2/4 .
i t
t∈[0,T](cid:12)
(cid:12) Xi=1
−
Z
(cid:12)
(cid:12)
≥ · ! ≤ · (cid:16)−
(cid:17)
(cid:12) (cid:12)
Setting ι = N−1(cid:12) (cid:12)/2 and p = B log(NT/δ)/N, w(cid:12) (cid:12)e have that
·
N p
sup N−1 h θ¯(t),ω¯ (t) h(θ,ω)dρ B log(NT/δ)/N.
i i t
t∈[0,T](cid:12)
(cid:12) Xi=1 (cid:16)
(cid:17)−
Z
(cid:12)
(cid:12)
≤ ·
q
(cid:12) (cid:12)
with probability at le(cid:12)ast 1 δ. Thus, we complete the proo(cid:12)f of Lemma B.2.
(cid:12) (cid:12)
−
B.1.2 Proof of Lemma B.3
Following from the definition of θ (t), w (t) and θ¯(t), w¯ (t) in (B.6) and (B.7). We have for any
i i i i
i [N] and t [0,T] that
e
∈ ∈ e
t dθ (s) dθ¯(s)
θ¯(t) θ (t) i i ds
i i
− ≤ ds − ds
(cid:13) (cid:13) e (cid:13) (cid:13) = Z η0 (cid:13) (cid:13) (cid:13) te vf(θ (s);θ(N)(cid:13) (cid:13) (cid:13)(s),ω(N)(s)) vf(θ¯(s);ρ ) ds
i i s
· −
Z0
(cid:13) (cid:13)
η t(cid:13) (cid:13)vbf(θe (s);θe(N)(s),ωe(N)(s)) vf(θ¯(s);θ¯(N(cid:13) (cid:13))(s),ω¯(N)(s)) ds
i i
≤ · −
Z0
(cid:13) (cid:13)
+η (cid:13) (cid:13)bt e vf(θ¯(e s);θ¯(N)(es),ω¯(N)(s))b vf(θ¯(s);ρ ) ds (cid:13) (cid:13)
i i s
· −
Z0
(cid:13) (cid:13)
t (cid:13) (cid:13)
B θ¯(N(cid:13)b)(s) θ(N)(s) + ω¯(N)(s) ω(N)(s)(cid:13) ds
≤ · Z0
(cid:13)
− (cid:13)(N)
(cid:13)
− (cid:13)(N)
+η (cid:13) (cid:13) t vf(θ¯(s)e ;θ¯(N)((cid:13) (cid:13)s),ω¯(N)(cid:13) (cid:13)(s)) vf(θ¯e(s);ρ )(cid:13) (cid:13), ds (B.15)
i i s
· −
Z0
(cid:13) (cid:13)
(cid:13) (cid:13)
where the last inequality follows fro(cid:13)mb (C.8) of Lemma C.1. Similarly, we have(cid:13)that
t
ω¯ (t) ω (t) η vg(ω (s);θ(N)(s),ω(N)(s)) vg(ω¯ (s);ρ ) ds
i i i i s
− ≤ · −
Z0
(cid:13) (cid:13)
(cid:13) (cid:13) e (cid:13) (cid:13) B t(cid:13) (cid:13)bθ¯(Ne)(s) e θ(N)(s)e + ω¯(N)(s) ω(N)(cid:13) (cid:13)(s) ds
≤ · Z0
(cid:13)
− (cid:13)(N)
(cid:13)
− (cid:13)(N)
+η (cid:13) (cid:13) t vg(ω¯ (se );θ¯(N)((cid:13) (cid:13)s),ω¯(N(cid:13) (cid:13))(s)) vg(ω¯e(s);ρ )(cid:13) (cid:13) ds, (B.16)
i i s
· −
Z0
(cid:13) (cid:13)
(cid:13) (cid:13)
where the last inequality follows from ((cid:13)Cb.9) (cid:13)
We now upper-bound the second term of (B.15) and (B.16). We start with (B.15). Following
from the definition of vf and vf in (B.1) and (B.2), we have for any s [0,T] and i [N] that
∈ ∈
N
vf(θ¯(s);θ¯(N)(b s),w¯(N)(s)) vf(θ¯(s);ρ ) = α2 N−1 Zj (s) , (B.17)
i − i s · · i
(cid:13) (cid:13) (cid:13) j X=1 (cid:13)
(cid:13) (cid:13) (cid:13) (cid:13)
(cid:13)b (cid:13) (cid:13) (cid:13)
59where
δΦ(X,Z;f)
Zj (s) = E ψ(Z;ω)dν (ω) ψ(Z;ω¯ (s)) , φ(;θ¯(s))
i D s − j · δf ∇θ · i L2
(cid:20)D(cid:16)Z (cid:17) E
δΨ(X,Z; φ(;θ)dµ (θ)) δΨ(X,Z;φ(;θ¯ (s)))
+λ · s · j , φ(;θ¯(s)) .
θ i
·
D
Rδf − δf ∇ · EL2
(cid:21)
Following from Assumption 4.1 and 4.3, we have that Zj (s) B. When j = i, since θ¯ (s) i.i.d.
k i k ≤ 6 j ∼
µ ,ω¯ (s) i.i.d. ν (j [N]), it holds that E[Zj (s) θ¯(s)] = 0. Following from Lemma C.3, we have
s j ∼ s ∈ i i
for fixed s [0,T] and i [N] that (cid:12)
(cid:12)
∈ ∈
P N−1 Zj (s) B N−1/2+p = E P N−1 Zj (s) B N−1/2+p θ¯(s)
· i ≥ · · i ≥ · i
(cid:18)(cid:13) Xj6=i (cid:13) (cid:16) (cid:17)(cid:19) h (cid:16)(cid:13) Xj6=i (cid:13) (cid:16) (cid:17)(cid:12) (cid:17)i
(cid:13) (cid:13) (cid:13) (cid:13) (cid:12)
(cid:13) (cid:13) exp (cid:13) Np2 . (cid:13) (cid:12) (B.18)
≤ −
(cid:16) (cid:17)
From Lemma D.7 and (C.14) of Lemma C.2, we have that
sup φ(w;θ)dµ (θ) φ(w;θ)dµ (θ) B (µ ,µ ) B (µ ,µ ) B s t .
s t 1 s t 2 s t
− ≤ ·W ≤ ·W ≤ · −
w∈W (cid:12)Z Z (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
Following(cid:12)from Assumption 4.1 and 4.3, Lem(cid:12)ma C.2, we have for any s,t [0,T] that,(cid:12) (cid:12)
∈
N−1 Zj (s) N−1 Zj (t) B t s .
(cid:12) · i − · i (cid:12)≤ · −
(cid:12) (cid:12) (cid:12) (cid:12)(cid:13) (cid:13) (cid:13) Xj6=i (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) Xj6=i (cid:13) (cid:13) (cid:13)(cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12)
Applying the union bou(cid:12)nd to (B.18) for i [N] and t ι 0(cid:12),1,..., T/ι , we have that
∈ ∈ ·{ ⌊ ⌋}
P sup N−1 Zj (s) B N−1/2+p +Bι N (T/ι+1) exp Np2 .
· i ≥ · ≤ · · −
(cid:16) si ∈∈ [[ 0N ,T] ](cid:13) Xj6=i (cid:13) (cid:16) (cid:17) (cid:17) (cid:16) (cid:17)
(cid:13) (cid:13)
Setting ι = N−1/2 and p = B log(NT/δ)/N, we have that
·
p
sup N−1 Zj (s) B log(NT/δ)/N. (B.19)
· i ≤ ·
i∈[N] (cid:13) Xj6=i (cid:13) q
s∈[0,T](cid:13) (cid:13)
(cid:13) (cid:13)
with probability at least 1 δ. Following from Assumption 4.1, when i = j, N−1Zi(s) B/N
− k i k ≤
in (B.17). Plugging (B.19) into (B.17), with probability at least 1 δ, we have that
−
N
sup vf(θ¯(s);θ¯(N)(s),ω¯(N)(s)) vf(θ¯(s);ρ ) sup α2 N−1 Zj (s)
i − i s ≤ · i
i∈[N] (cid:13) (cid:13) i∈[N],s∈[0,T] (cid:13) j X=1 (cid:13)
s∈[0,T](cid:13) (cid:13) (cid:13) (cid:13)
(cid:13)b (cid:13) (cid:13) (cid:13)
B log(NT/δ)/N. (B.20)
≤ ·
q
60Through similar arguments, with probability at least 1 δ, we have for the second term of (B.16)
−
sup vg(w¯ (s);θ¯(N)(s),ω¯(N)(s)) vg(ω¯ (s);ρ ) B log(NT/δ)/N. (B.21)
i i s
− ≤ ·
i∈[N]
(cid:13) (cid:13) q
s∈[0,T](cid:13) (cid:13)
(cid:13)b (cid:13)
Now, conditioning on the intersection of event in (B.20) and event in (B.21), the following holds
simultaneously for any t [0,T]
∈
t
θ(N)(t) θ¯(N)(t) B θ(N)(s) θ¯(m)(s) ds+BT log(NT/δ)/N (B.22)
(cid:13)
− (cid:13)(N) ≤ · Z0
(cid:13)
− (cid:13)(N) ·
q
(cid:13) (cid:13)ωe(N)(t) ω¯(N)(t)(cid:13) (cid:13) B t(cid:13) (cid:13)e ω(N)(s) ω¯(N)(s(cid:13) (cid:13)) ds+BT log(NT/δ)/N (B.23)
(cid:13)
− (cid:13)(N) ≤ · Z0
(cid:13)
− (cid:13)(N) ·
q
(cid:13) (cid:13) (cid:13) (cid:13)
Summ(cid:13)ieng (B.22) and (B(cid:13).23) and app(cid:13)lyeing Gronwall’s L(cid:13)emma (Holte, 2009), with probability at
least 1 2δ, for any t [0,T], it holds that
− ∈
θ(N)(t) θ¯(N)(t) + ω(N)(t) ω¯(N)(t) B eBt 2BT log(NT/δ)/N
− (N) − (N) ≤ · · ·
(cid:13) (cid:13) (cid:13) (cid:13) q
(cid:13) (cid:13)e (cid:13) (cid:13) (cid:13) (cid:13)e (cid:13) (cid:13) B eBT log(N/δ)/N. (B.24)
≤ · ·
q
. The last inequality holds since B as a constant represents values changing from line to line. Note
that
(θ¯,ω¯)(N)(t) (θ,ω)(N)(t) θ(N)(t) θ¯(N)(t) + ω(N)(t) ω¯(N)(t) .
− (N) ≤ − (N) − (N)
(cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13)
Therefor(cid:13) (cid:13)e, equation (B.2e 4)eimplies(cid:13) (cid:13)(B.11).(cid:13) (cid:13)e Thus, we comple(cid:13) (cid:13)te the(cid:13) (cid:13)peroof of Lemma B(cid:13) (cid:13).3.
B.1.3 Proof of Lemma B.4
Bythedefinitionofvf,vg in(B.2),θ˘(t),ω˘ (t)in(B.5),θ (t),ω (t)in(B.6),itholdsthatthedistance
i i i i
between θ (kǫ) θ˘(k) satisfies
i i e
− b b e
(cid:13) (cid:13)
θ (k(cid:13) (cid:13)ǫe ) θ˘(k) (cid:13) (cid:13)
i i
−
(cid:13) kǫ(cid:13)
(cid:13) (cid:13)e η (cid:13) (cid:13)vf θ i(s);θ(N)(s),ω(N)(s) vf θ˘ i( s/ǫ );θ˘(N)( s/ǫ ),ω˘(N)( s/ǫ ) ds
≤ · − ⌊ ⌋ ⌊ ⌋ ⌊ ⌋
Z0
(cid:13) (cid:16) (cid:17) (cid:16) (cid:17)(cid:13)
η kǫ(cid:13) (cid:13)vbf θe (s);θe(N)(s),ωe(N)(s) vbf θ ( s/ǫ ǫ);θ(N)( s/ǫ ǫ),ω(N)( s/ǫ ǫ(cid:13) (cid:13)) ds
i i
≤ · − ⌊ ⌋ ⌊ ⌋ ⌊ ⌋
Z0
(cid:13) (cid:16) (cid:17) (cid:16) (cid:17)(cid:13)
(cid:13)k−1 e e e e (cid:13)
+η (cid:13)b vf θ (ℓǫ);θ(N)e (ℓǫ),ω(N)(ℓb ǫ) vf θ˘(ℓ);θ˘(N)(ℓ),ω˘(N)e (ℓ) (cid:13)
i i
· −
Xℓ=0(cid:13) (cid:16) (cid:17) (cid:16) (cid:17)(cid:13)
(cid:13)
(cid:13)b
k−e1 e
e b
(cid:13)
(cid:13)
B k ǫ2+B θ(N)(ℓǫ) θ˘(N)(ℓ) + ω(N)(ℓǫ) ω˘(N)(ℓ) . (B.25)
≤ · · · − (N) − (N)
Xℓ=0(cid:16)(cid:13) (cid:13) (cid:13) (cid:13) (cid:17)
(cid:13) (cid:13)e (cid:13) (cid:13) (cid:13) (cid:13)e (cid:13) (cid:13)
61Similarly, the distance between ω (kǫ) ω˘ (k) satisfies
i i
k − k
e
ω (kǫ) ω˘ (k)
i i
k − k
kǫ
e η vg ω i(s);θ(N)(s),ω(N)(s) vg ω˘ i( s/ǫ );θ˘(N)( s/ǫ ),ω˘(N)( s/ǫ ) ds
≤ · − ⌊ ⌋ ⌊ ⌋ ⌊ ⌋
Z0
(cid:13) (cid:16) (cid:17) (cid:16) (cid:17)(cid:13)
η kǫ(cid:13) (cid:13)vbg ωe (s);θe(N)(s),ωe(N)(s) vbg ω ( s/ǫ ǫ);θ(N)( s/ǫ ǫ),ω(N)( s/ǫ ǫ(cid:13) (cid:13)) ds
i i
≤ · − ⌊ ⌋ ⌊ ⌋ ⌊ ⌋
Z0
(cid:13) (cid:16) (cid:17) (cid:16) (cid:17)(cid:13)
+η (cid:13) (cid:13)k− b1 veg w (e ℓǫ);θ(N)e (ℓǫ),ω(N)(ℓb ǫ) e vg ω˘ (ℓ);e θ˘(N)(ℓ),ω˘(N)e (ℓ) (cid:13) (cid:13)
i i
· −
Xℓ=0(cid:13) (cid:16) (cid:17) (cid:16) (cid:17)(cid:13)
(cid:13) (cid:13)b k−e1 e e b (cid:13) (cid:13)
B k ǫ2+B θ(N)(ℓǫ) θ˘(N)(ℓ) + ω(N)(ℓǫ) ω˘(N)(ℓ) . (B.26)
≤ · · · − (N) − (N)
Xℓ=0(cid:16)(cid:13) (cid:13) (cid:13) (cid:13) (cid:17)
(cid:13) (cid:13)e (cid:13) (cid:13) (cid:13) (cid:13)e (cid:13) (cid:13)
where (B.25) follows from (C.8) of Lemma C.1 and (C.13) of Lemma C.2, (B.26) follows from
(C.9) of Lemma C.1 and (C.13) of Lemma C.2. Combining the inequalities in (B.25) and (B.26),
it holds for any k T/ǫ (k N) that
≤ ∈
θ(N)(kǫ) θ˘(N)(k) + ω(N)(kǫ) ω˘(N)(k)
− (N) − (N)
(cid:13) (cid:13) (cid:13) (cid:13)
(cid:13) (cid:13)e 2B T ǫ+B(cid:13) (cid:13) k−1 (cid:13) (cid:13) θe(m)(ℓǫ) θ˘(N)(ℓ) (cid:13) (cid:13) +B k−1 ω(N)(ℓǫ) ω˘(N)(ℓ) . (B.27)
≤ · · · − (N) · − (N)
Xℓ=0(cid:13) (cid:13) Xℓ=0(cid:13) (cid:13)
(cid:13) (cid:13)e (cid:13) (cid:13) (cid:13) (cid:13)e (cid:13) (cid:13)
Applying the discrete Gronwall’s lemma (Holte, 2009) to (B.27) , we have that
sup θ(N)(kǫ) θ˘(N)(k) + ω(N)(kǫ) ω˘(N)(k) 2B2 T ǫ eBT B eBT ǫ,
− (N) − (N) ≤ · · · ≤ · ·
k≤T/ǫ
(cid:13) (cid:13) (cid:13) (cid:13)
(k∈N)(cid:13) (cid:13)e (cid:13) (cid:13) (cid:13) (cid:13)e (cid:13) (cid:13)
where the inequalities hold since we allow the value of B to vary from line to line. Thus, we
complete the proof of Lemma B.4.
B.1.4 Proof of Lemma B.5
Proof. Let = σ(θ(N)(0),w(N)(0),u ,...,u )betheσ algebragenerated byθ(N)(0),w(N)(0)and
k 0 k
G −
u = (x ,z ) (ℓ k). Following from the definition of Vf ,Vg and vf,vg in (B.2) and (B.3), we
ℓ ℓ ℓ ≤ k k
have for any i [N] and k N that
∈ ∈ + b b b b
E Vf (θ (k);θ(N)(k),ω(N)(k)) = vf(θ (k);θ(N)(k),ω(N)(k)),
k i Gk−1 i
h (cid:12) i
E Vb kg (ω i(k);θ(N)(k),ω(N)(k))(cid:12)
Gk−1
=bvg(ω i(k);θ(N)(k),ω(N)(k)).
h (cid:12) i
b (cid:12) b
62Recall the definition of θ(N),ω(N) and θ˘(N),ω˘(N) as the SGD and PGD dynamics defined in (B.4)
and (B.5). We have for any i [N], k N that
+
∈ ∈
θ˘(k) θ (k)
i i
−
(cid:13) k−(cid:13)1 k−1
(cid:13) (cid:13)
(cid:13) = ηǫ (cid:13) Vf θ (ℓ);θ(N)(ℓ),ω(N)(ℓ) vf θ˘(ℓ);θ˘(N)(ℓ),ω˘(N)(ℓ)
·(cid:13) ℓ i − i (cid:13)
(cid:13)Xℓ=0 (cid:16) (cid:17) Xℓ=0 (cid:16) (cid:17)(cid:13)
(cid:13) (cid:13)k−1 b k−1 b (cid:13) (cid:13)
ηǫ (cid:13) X (ℓ) +ηǫ vf θ˘(ℓ);θ˘(N)(ℓ),ω˘(N)(ℓ) vf θ (ℓ);θ(N(cid:13))(ℓ),ω(N)(ℓ)
i i i
≤ ·(cid:13) (cid:13) · −
(cid:13)Xℓ=0 (cid:13) Xℓ=0(cid:13) (cid:16) (cid:17) (cid:16) (cid:17)(cid:13)
(cid:13) (cid:13) (cid:13) (cid:13)
(cid:13) (cid:13) k−1 (cid:13)b b (cid:13)
ηǫ (cid:13)A (k) +(cid:13)Bǫ θ˘(m)(ℓ) θ(m)(ℓ) + ω˘(N)(ℓ) ω(N)(ℓ) , (B.28)
i
≤ ·k k · − (N) − (N)
Xℓ=0(cid:13) (cid:13) (cid:13) (cid:13)
(cid:13) (cid:13) (cid:13) (cid:13)
(cid:13) (cid:13) (cid:13) (cid:13)
where the last inequality follows from (C.8) of Lemma C.1. X (ℓ) and A (k) are defined as,
i i
X (ℓ) = Vf θ (ℓ);θ(N)(ℓ),ω(N)(ℓ) E Vf θ (ℓ);θ(N)(ℓ),ω(N)(ℓ) ℓ 1,
i ℓ i − ℓ i Gℓ−1 ∀ ≥
(cid:16) k−1 (cid:17) h (cid:16) (cid:17) (cid:12) i
b b (cid:12)
X (0) = 0, A (k) = X (ℓ).
i i i
ℓ=0
X
Following from (C.7) of Lemma C.1, it holds that X (ℓ) B, thus the stochastic process
i
k k ≤
{A i(k) }k∈N
+
is a martingale with kA i(k) −A i(k −1)
k ≤
B. Applying the Azuma-Hoeffding bound
in Lemma C.4, we have that
P max A (k) B T/ǫ (√D+p) exp p2 . (B.29)
i
k≤T/ǫ k k ≥ · · ≤ −
(cid:16)(k∈N +) q (cid:17) (cid:16) (cid:17)
Apply the union bound to (B.29) for i [N], we have that
∈
P max A (k) B T/ǫ (√D+p) N exp p2 .
i
i∈[N] k k ≥ · · ≤ · −
(cid:16)k≤T/ǫ,(k∈N +) q (cid:17) (cid:16) (cid:17)
Setting p = log(N/δ), with probability at least 1 δ, it holds that
−
p
A (k) B T/ǫ (√D+ log(N/δ)), i [N],k T/ǫ(k N ). (B.30)
i +
k k ≤ · · ∀ ∈ ≤ ∈
q q
Plug (B.30) into (B.28) and taking supremum norm over i [N], we have that
∈
θ˘(N)(k) θ(N)(k)
− (N)
(cid:13) (cid:13)
(cid:13) k−1 (cid:13)
(cid:13) Bǫ (cid:13) θ˘(m)(ℓ) θ(m)(ℓ) + ω˘(N)(ℓ) ω(N)(ℓ) +B √Tǫ (√D+ log(N/δ)).
≤ · − (N) − (N) · ·
Xℓ=0(cid:18)(cid:13) (cid:13) (cid:13) (cid:13) (cid:19) q
(cid:13) (cid:13) (cid:13) (cid:13)
(cid:13) (cid:13) (cid:13) (cid:13) (B.31)
63Through similar arguments, for w˘ (k) and w (k), with probability at least 1 δ, it holds that,
i i
−
ω˘(N)(k) ω(N)(k)
− (N)
(cid:13) (cid:13)
(cid:13) k−1 (cid:13)
(cid:13) Bǫ θ˘(cid:13)(m)(ℓ) θ(m)(ℓ) + ω˘(N)(ℓ) ω(N)(ℓ) +B √Tǫ (√D+ log(N/δ)).
≤ · − (N) − (N) · ·
Xℓ=0(cid:18)(cid:13) (cid:13) (cid:13) (cid:13) (cid:19) q
(cid:13) (cid:13) (cid:13) (cid:13)
(cid:13) (cid:13) (cid:13) (cid:13) (B.32)
Conditioning on the intersection of event in (B.31) and event in (B.32), summing (B.31), (B.32),
and applying the discrete Gronwall’s lemma (Holte, 2009), for any k T/ǫ,k N , the following
+
≤ ∈
inequality holds with probability at least 1 2δ,
−
θ˘(N)(k) θ(N)(k) + ω˘(N)(k) ω(N)(k) B eBkǫ B √Tǫ (√D+ log(N/δ))
− (N) − (N) ≤ · · · ·
(cid:13) (cid:13) (cid:13) (cid:13) q
(cid:13) (cid:13) (cid:13) (cid:13)
(cid:13) (cid:13) (cid:13) (cid:13) B eBT ǫ (D+log(N/δ)).
≤ · · ·
q
Here the last inequality holds since we allow the value of B to vary from line to line. Thus, we
complete the proof of Lemma B.5.
64C Supporting Lemmas
C.1 Supporting Lemmas for §B
In what follows, we presented the technical lemmas heavily used in B. We recall the definition
§
of vf,vg, vf,vg and Vf ,Vg as in (B.1), (B.2), and (B.3) respectively. Let B > 0 be a constant
k k
depending on α,η,B ,B ,B ,C, whose value varies from line to line. Recall that f(;θ(N)) and
b b
0b 1b 2
·
g(;ω(N))arethefinitewidthrepresentation withparametersθ(N),ω(N),whosedefinitionsaregiven
·
by
N N
α α
f(;θ(N))= φ(;θ ), g(;ω(N)) = ψ(;ω ).
i i
· N · · · N · ·
i=1 i=1
X X
Lemma C.1. Under Assumption 4.1 and 4.3, it holds that for any θ(N) = θ N , θ(N) = θ N ,
{ i }i=1 { i }i=1
w(N) = w N ,w(N) = w N ,that,f(;θ(N))andg(;ω(N))areuniformlyboundedandLipschitz
{ i }i=1 { i }i=1 · ·
in θ,ω respectively, which is given by the following,
sup f(w;θ(N)) +sup g(z;ω(N)) B, (C.1)
≤
w∈W z∈Z
(cid:12) (cid:12) (cid:12) (cid:12)
sup(cid:12) f(w;θ(N))(cid:12) f(w;(cid:12) θ(N)) B(cid:12) θ(N) θ(N) , (C.2)
− ≤ · − (N)
w∈W
(cid:12) (cid:12) (cid:13) (cid:13)
sup g(cid:12) (z;ω(N)) g(z;ω(N)) (cid:12) B ω(cid:13)(N) ω(N) (cid:13) . (C.3)
− ≤ · − (N)
z∈Z
(cid:12) (cid:12) (cid:13) (cid:13)
(cid:12) (cid:12) (cid:13) (cid:13)
Recall the definition of vf,vg and Vf ,Vg in (B.2), (B.3), the finite width representation of the
k k
velocity field and its stochastic counter-part, when evaluated at arbitrary θ ,ω , are also uniformly
b b b b i i
f g
bounded and lipschitz in θ,ω respectively. This means for V ,V , the following inequalities hold,
k k
b b
Vf (θ ;θ(N),ω(N)) + Vg (ω ;θ(N),w(N)) B, (C.4)
k i k i ≤
(cid:13) (cid:13)Vb kf (θ i;θ(N),ω(N))(cid:13) (cid:13) −V(cid:13) (cid:13) kf b(θ i;θ(N),ω(N)) ≤(cid:13) (cid:13)B
·
θ(N) −θ(N) (N)+ ω(N) −ω(N)
(N)
, (C.5)
(cid:13) (cid:13) (cid:16)(cid:13) (cid:13) (cid:13) (cid:13) (cid:17)
(cid:13)Vbg (ω ;θ(N),w(N)) bVg (ω ;θ(N),ω(N))(cid:13) B (cid:13) θ(N) θ(N)(cid:13) +(cid:13) ω(N) ω(N)(cid:13) . (C.6)
k i − k i ≤ · − (N) − (N)
(cid:13) (cid:13) (cid:16)(cid:13) (cid:13) (cid:13) (cid:13) (cid:17)
(cid:13)b b (cid:13) (cid:13) (cid:13) (cid:13) (cid:13)
A similar series of inequalities also hold for vf,vg,
vf(θ ;θ(N),ω(N)) + vg(ω ;θ(N),ω(N))b b B, (C.7)
i i
≤
(cid:13) (cid:13)v bf(θ i;θ(N),ω(N))(cid:13) (cid:13) −v k(cid:13) (cid:13)f ( bθ i;θ(N),ω(N)) ≤(cid:13) (cid:13)B
·
θ(N) −θ(N) (N)+ ω(N) −ω(N)
(N)
, (C.8)
(cid:13) (cid:13) (cid:16)(cid:13) (cid:13) (cid:13) (cid:13) (cid:17)
(cid:13)vbg(ω i;θ(N),ω(N)) −bvg(ω i;θ(N),ω(N))(cid:13)
≤
B
·
(cid:13)θ(N) −θ(N)(cid:13) (N)+(cid:13)ω(N) −ω(N)(cid:13)
(N)
. (C.9)
(cid:13) (cid:13) (cid:16)(cid:13) (cid:13) (cid:13) (cid:13) (cid:17)
(cid:13)b b (cid:13) (cid:13) (cid:13) (cid:13) (cid:13)
65As a corollary of the inequalities stated above, the uniform bounds in fact hold for any f,g ,
∈ F
which says,
sup f(w) +sup g(z) B. (C.10)
≤
w∈W z∈Z
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
Similarly, the uniform boundsalso hold for the velocity field vf,vg, such that for any ρ P (RD
2
∈ ×
RD), it holds that
vf(θ;ρ) + vg(ω;ρ) B. (C.11)
≤
(cid:13) (cid:13) (cid:13) (cid:13)
(cid:13) (cid:13) (cid:13) (cid:13)
Proof. We will prove these results separately.
(i) Proof of (C.1), (C.2), and (C.3)
For (C.1) of Lemma C.1, since φ, ψ are bounded as is assumed in Assumption 4.1, we have for
any w ,z , any θ(N) and ω(N) that
∈ W ∈Z
N
f(w;θ(N)) + g(z;ω(N)) α N−1 φ(w;θ ) + ψ(z;ω ) B.
i i
≤ · ≤
i=1
(cid:12) (cid:12) (cid:12) (cid:12) X(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12)
For (C.2), and(C.3)ofLemmaC.1, sinceforanyw , z , φ(w;θ)hasaboundedgradient
∈ W ∈ Z
in θ, ψ(z;ω) has a bounded gradient in ω. The uniform upper bound of the gradient controls the
Lipschitzconstantofthefunction,thusitholdsforanyw ,z ,anyθ(N),θ(N) andω(N),ω(N)
∈ W ∈ Z
that
N
f(w;θ(N)) f(w;θ(N)) αN−1 B θ θ B θ(N) θ(N) ,
− ≤ · 1 i − i ≤ · − (N)
i=1
(cid:12) (cid:12) X(cid:12) (cid:12) (cid:13) (cid:13)
(cid:12) (cid:12) N (cid:12) (cid:12) (cid:13) (cid:13)
g(z;ω(N)) g(z;ω(N)) αN−1 B ω ω B ω(N) ω(N) .
− ≤ · 1 i − i ≤ · − (N)
i=1
(cid:12) (cid:12) X(cid:12) (cid:12) (cid:13) (cid:13)
(cid:12) (cid:12) (cid:12) (cid:12) (cid:13) (cid:13)
(ii) Proof of (C.4), (C.5) and (C.6)
For (C.4) of Lemma C.1, recall the definition of Vf , Vg in (B.3), for any θ(N) and ω(N), it holds
k k
b b
66that,
δΦ(x ,z ,f(;θ(N)))
Vf (θ ;θ(N),ω(N)) α sup φ(w;θ ) sup g(z;ω(N)) k k · (w′) dw′
k i ≤ · ∇θ i · · δf
(cid:13) (cid:13) (cid:13)b (cid:13) (cid:13) (cid:13) +w α∈W s(cid:13) (cid:13) up φ(w;(cid:13) (cid:13) θ )z∈Z λ(cid:12) (cid:12) δΨ((cid:12) (cid:12)x kZ ,W z k(cid:12) (cid:12) (cid:12),f( ·;θ(N))) (w′) dw′ (cid:12) (cid:12) (cid:12)
θ i
· ∇ · · δf
w∈W
(cid:13) (cid:13)
ZW
(cid:12) (cid:12)
(cid:13) (cid:13) (cid:12) (cid:12)
B, (cid:12) (cid:12)
≤
Vg (ω ;θ(N),ω(N)) α Φ(x ,z ;f(;θ(N))) +sup g(z;ω(N)) sup ψ(z;ω )
k i ≤ · k k · · ∇ω i
z∈Z z∈Z
(cid:13) (cid:13) (cid:16)(cid:12) (cid:12) (cid:12) (cid:12)(cid:17) (cid:13) (cid:13)
(cid:13)b (cid:13) (cid:12) (cid:12) (cid:12) (cid:12) (cid:13) (cid:13)
(cid:13) (cid:13) B.
≤
For notational simplicity, we further define
δΦ(x ,z ;f(;θ(N))) δΨ(x ,z ;f(;θ(N)))
uf(θ(N),w(N)) = αg(z ;ω(N)) k k · αλ k k · ,
k
− · δf − · δf
ug(θ(N),w(N)) = αΦ(x ,z ;f(;θ(N))) αg(z ;ω(N)).
k k k
· −
f
For (C.5) of Lemma C.1, following from Assumption 4.3 and the definition of V in (B.3), we
k
have for any θ(N),θ(N) and ω(N),ω(N) that
b
Vf (θ ;θ(N),ω(N)) Vf (θ ;θ(N),ω(N))
k i − k i
(cid:13) (cid:13)
(cid:13) (cid:13)b
≤
V kf (θ i;θ(N),ωb(N)) −V kf (θ i;θ(N(cid:13) (cid:13)),ω(N)) + V kf (θ i;θ(N),ω(N)) −V kf (θ i;θ(N),ω(N))
(cid:13) (cid:13) (cid:13) (cid:13)
(cid:13) (cid:13)ubf(θ(N),ω(N)) uf(θb(N),ω(N)) sup (cid:13) (cid:13) θφ(cid:13) (cid:13)(bw;θ i) + uf(θ(N),bω(N)), θφ(;θ i)(cid:13) (cid:13) θφ(;θ i) .
≤ | − |· w∈Wk∇ k ∇ · −∇ · L2
(cid:13)D E (cid:13)
(cid:13) (cid:13)
Moreover, uf(θ(N),ω(N)) is also Lipschitz in (θ(N),ω(N)) since(cid:13) (cid:13)
uf(θ(N),ω(N)) uf(θ(N),ω(N)) B f(w ;θ(N)) f(w ;θ(N)) +B g(z ;ω(N)) g(z ;ω(N))
k k k k
| − | ≤ ·| − | ·| − |
B θ(N) θ(N) + ω(N) ω(N) ,
≤ · − (N) − (N)
(cid:16)(cid:13) (cid:13) (cid:13) (cid:13) (cid:17)
wherethesecondinequalityisachievedby(cid:13) applying(C.(cid:13) 2),(C.3(cid:13) ). Therefore,(cid:13) thefactthatVf (θ ;θ(N),ω(N))
k i
isLipschitzin(θ(N),ω(N))isdueto φ(w;θ ) and uf(θ(N),ω(N))(w′)dw′ isuniformlybounded.
θ i b
k∇ k
For (C.6) of Lemma C.1, following from Assumption(cid:12)4R.3 and the definition of(cid:12)Vg in (B.3), through
(cid:12) (cid:12) k
a similar argument as is in the proof of (C.5), we have for any θ(N),θ(N) and ω(N),ω(N) that
b
Vg (ω ;θ(N),ω(N)) Vg (ω ;θ(N),ω(N))
k i − k i
(cid:13) (cid:13)
(cid:13) (cid:13)b
≤
V kg (ω i;θ(N),ωb(N)) −V kg (ω i;θ(N(cid:13) (cid:13)),ω(N)) + V kg (ω i;θ(N),ω(N)) −V kg (ω i;θ(N),ω(N))
(cid:13) (cid:13) (cid:13) (cid:13)
(cid:13) (cid:13)ubg(θ(N),ω(N)) uf(θ(bN),ω(N)) sup (cid:13) (cid:13)ωψ(cid:13) (cid:13)(zb;ω i) + ug(θ(N),ωb(N)), ωψ(;ω i) (cid:13) (cid:13) ωψ(;ω i) .
≤ | − |· z∈Zk∇ k ∇ · −∇ · L2
(cid:13)D E (cid:13)
(cid:13) (cid:13)
(cid:13) (cid:13)
67Again, ug(θ(N),ω(N)) is Lipschitz in (θ(N),ω(N)) since
ug(θ(N),ω(N)) ug(θ(N),ω(N)) B f(w ;θ(N)) f(w ;θ(N)) +B g(z ;ω(N)) g(z ;ω(N))
k k k k
| − | ≤ ·| − | ·| − |
B θ(N) θ(N) + ω(N) ω(N) .
≤ · − (N) − (N)
(cid:16)(cid:13) (cid:13) (cid:13) (cid:13) (cid:17)
Therefore, the Lipschtizness of Vg (ω ;θ(cid:13) (N),ω(N)) in(cid:13) (θ(N),(cid:13) ω(N)) comes(cid:13) from ψ(z;ω ) and
k i k∇ω i k
ug(θ(N),ω(N))(z′)dz′ is uniformly bounded.
b
(cid:12)R (cid:12)
(cid:12) (cid:12)
(iii) Proof of (C.7), (C.8), and (C.9)
Equations (C.7), (C.8), (C.9) of Lemma C.1 for vf and vg follow from the fact that
vf(θ ;θ(N),ω(N))= E Vf (θ ;θ(N),ω(N)) , vgb(ω ;θ(Nb),w(N))= E Vg (ω ;θ(N),ω(N)) .
i D k i i D k i
h i h i
Therbefore, (C.7) follows fromb (C.4) and triangle inbequality, b
vf(θ ;θ(N),ω(N)) + vg(ω ;θ(N),ω(N)) E Vf (θ ;θ(N),ω(N)) +E Vg (ω ;θ(N),ω(N))
i i ≤ D k i D k i
(cid:13) (cid:13) (cid:13) (cid:13) h(cid:13) (cid:13)i h(cid:13) (cid:13)i
(cid:13)b (cid:13) (cid:13)b (cid:13) B. (cid:13)b (cid:13) (cid:13)b (cid:13)
≤
Equations (C.8) and (C.9) follows from (C.5), (C.6) and triangle inequality,
vf(θ ;θ(N),ω(N)) vf (θ ;θ(N),ω(N)) E Vf (θ ;θ(N),ω(N)) Vf (θ ;θ(N),ω(N))
i − k i ≤ D k i − k i
(cid:13) (cid:13) h(cid:13) (cid:13)i
(cid:13)b b (cid:13) B (cid:13)bθ(N) θ(N) + ωb(N) ω(N) ,(cid:13)
≤ · − (N) − (N)
(cid:16)(cid:13) (cid:13) (cid:13) (cid:13) (cid:17)
vg(ω ;θ(N),ω(N)) vg (ω ;θ(N),ω(N)) E (cid:13)Vg (ω ;θ(N),(cid:13)ω(N)) (cid:13)Vg (ω ;θ(N),(cid:13)ω(N))
i − k i ≤ D k i − k i
(cid:13) (cid:13) h(cid:13) (cid:13)i
(cid:13)b b (cid:13) B (cid:13)bθ(N) θ(N) + ωb(N) ω(N) .(cid:13)
≤ · − (N) − (N)
(cid:16)(cid:13) (cid:13) (cid:13) (cid:13) (cid:17)
(cid:13) (cid:13) (cid:13) (cid:13)
(iv) Proof of (C.10), and (C.11)
Equation(C.10)followsfromthedefinitionof in(4.2)andtheuniformboundsofneuronfunctions
F
φ and ψ. For any f,g , there exists probability measures µ,ν over the parameter space such
∈ F
that
b b
f(w)= φ(w;θ)µ(dθ), g(z) = ψ(z;ω)ν(dω), w ,z .
∀ ∈ W ∈ Z
Z Z
We apply the triangle inequalityband achieve, b
sup f(w) +sup g(z) sup φ(w;θ)µ(dθ)+ sup g(z) ψ(z;ω)ν(dω) B.
| | | | ≤ | | | || | ≤
w∈W z∈Z Z w∈W Z z∈Z
b b
68Equation (C.11) follows from the definition of vf,vg in (B.1) and the proof of (C.4) and (C.7).
Proof of (C.11) is essentially the same as the proof for (C.4) and (C.7), except for the fact that
auniformboundisneededfortheinfinitewidthrepresentationoff andg,whichisprovedin(C.10).
Based on the separate proofs for items (i), (ii), (iii), and (iv) above, we finish the proof of Lemma
(C.1).
Now, recall ρ is the PDE solution to (3.7), θ¯(N)(t),w¯(N)(t) is the IP dynamics defined in (B.7),
t
θ(N)(t),w(N)(t) is the CTPGD dynamics defined in (B.6). We have the following lemma that also
bound the difference of iterates for IP, CTPGD dynamics between time s and t.
e e
Lemma C.2. Under Assumption 4.1 and 4.3, it holds for any s,t [0,T] that,
∈
θ¯(N)(t) θ¯(N)(s) + ω¯(N)(t) ω¯(N)(s) B t s , (C.12)
− (N) − (N) ≤ · −
(cid:13) (cid:13) (cid:13) (cid:13) (cid:12) (cid:12)
(cid:13)θ(N)(t) θ(N)(s)(cid:13) +(cid:13)ω(N)(t) ω(N)(s)(cid:13) B (cid:12)t s(cid:12), (C.13)
− (N) − (N) ≤ · −
(cid:13) (cid:13) (cid:13) (cid:13) (cid:12) (cid:12)
(cid:13)e 2(µ t,µ s))e+ 2((cid:13)ν t,ν s))(cid:13)e B t se. (cid:13) (cid:12) (cid:12) (C.14)
W W ≤ · −
(cid:12) (cid:12)
Proof. For (C.12) of Lemma C.2, by the
definition(cid:12)
of
θ¯((cid:12)
t) and ω¯ (t) in (B.7) and (C.11) of Lemma
i i
C.1, we have for any s,t [0,T] and i [N] that
∈ ∈
t
θ¯(t) θ¯(s) η vf(θ¯(τ);ρ ) dτ B t s
i i i τ
− ≤ · ≤ · −
Zs
(cid:13) (cid:13) t(cid:13) (cid:13) (cid:12) (cid:12)
(cid:13) ω¯ (t) ω¯ (s)(cid:13) η (cid:13) vg(ω¯ (τ);ρ (cid:13) ) dτ B (cid:12) t s(cid:12)
i i i τ
− ≤ · ≤ · −
Zs
(cid:13) (cid:13) (cid:13) (cid:13) (cid:12) (cid:12)
(cid:13) (cid:13) (cid:13) (cid:13) (cid:12) (cid:12)
Similarly, for(C.13)ofLemmaC.2, bythedefinitionofθ (t)andω (t)in(B.6),and(C.7)ofLemma
i i
C.1, we have for any s,t [0,T] and i [N],
e
∈ ∈ e
θ (t) θ (s) B t s , ω (t) ω (s) B t s .
i i i i
− ≤ · − − ≤ · −
(cid:13) (cid:13) (cid:12) (cid:12) (cid:13) (cid:13) (cid:12) (cid:12)
For (C.14) of Lemm(cid:13) ae C.2, foe llowi(cid:13) ng from(cid:12) the f(cid:12) act(cid:13) theat θ¯(te) i.i.d.(cid:13) µ , ω¯ (t(cid:12) ) i.i.d.(cid:12) ν and the definition
i t i t
∼ ∼
of in (2.18), it holds that for any s,t [0,T] that
2
W ∈
1/2
(µ ,µ ) E θ¯(t) θ¯(s) 2 B t s
2 t s i i
W ≤ − ≤ ·| − |
h(cid:13) (cid:13) i1/2
(ν ,ν ) E (cid:13)ω¯ (t) ω¯ (s)(cid:13)2 B t s
2 t s i i
W ≤ − ≤ ·| − |
h(cid:13) (cid:13) i
(cid:13) (cid:13)
Therefore, we complete the proof of Lemma C.2.
69Lemma C.3. Let X N be i.i.d. random variables with X ξ and E[X ]= 0. Then it holds
{ i }i=1 k i k ≤ i
for any p > 0 that
N
P N−1 X Cξ N−1/2+p exp Np2 ,
i
(cid:13) · (cid:13) ≥ · ! ≤ −
(cid:13) Xi=1 (cid:13) (cid:16) (cid:17) (cid:16) (cid:17)
(cid:13) (cid:13)
(cid:13) (cid:13)
where C > 0 is an absolu(cid:13)te constant. (cid:13)
Proof. See Lemma 30 in Mei et al. (2019)
Lemma C.4(Azuma-Hoeffdingbound). LetX RD beamartingalewithrespecttothefiltration
k
∈
(k 0) with X = 0. We assume for ξ > 0 and any λ RD that,
k 0
G ≥ ∈
E[exp( λ,X X ) ] exp ξ2 λ 2/2
k k−1 k−1
h − i | G ≤ ·k k
(cid:16) (cid:17)
Then it holds that
P max X Cξ √n (√D+p) exp p2
 k 
k≤n k k ≥ · · ≤ −
(k∈N) (cid:16) (cid:17)
 
 
where C > 0 is an absolute constant.
Proof. See Lemma 31 in Mei et al. (2019) and Lemma A.3 in Araújo et al. (2019).
C.2 Other Supporting Lemmas
Lemma C.5. For any probability measures µ,ν,µ′,ν′ P (RD), it holds that
2
∈
(µ ν,µ′ ν′)2 (µ,µ′)2+ (ν,ν′)2.
2 2 2
W ⊗ ⊗ ≤ W W
Proof. By the connection between optimal transport and the Wasserstein distance (Villani, 2008),
for any two probability measures ρ,ρ′ P (RD) the Wasserstein distance satisfies that
2
∈
2(ρ,ρ′)= inf w T(w) dρ(w). (C.15)
W2 T:X→X,T♯ρ=ρ′
Z
k − k
Thus, there exists mappings T and T such that (T ) µ = µ′, (T ) ν = ν′, and
µ ν µ ♯ ν ♯
2(µ,µ′) = θ T (θ) 2dν(θ),
W2 k − µ k
Z
2(ν,ν′) = ω T (ω) 2dν(ω),
W2 k − ν k
Z
70and that (T ) µ = µ′ and (T ) ν = ν′. Note that we have (T T ) (µ ν) = µ′ ν′. Thus, by
µ ♯ ν ♯ µ ν ♯
× × ×
(C.15), it holds that
2(µ ν,µ′ ν′) (θ,ω) T (θ),T (ω) 2 dµ(θ)dν(ω)
W2 × × ≤ − µ ν
Z
(cid:13) (cid:0) (cid:1)(cid:13)
= (cid:13) θ T (θ) 2+ ω T(cid:13)(ω) 2 dµ(θ)dν(ω)
µ ν
k − k k − k
Z (cid:16) (cid:17)
= 2(µ,µ′)+ 2(ν,ν′).
W2 W2
Thus, we complete the proof of Lemma C.5.
D Technical Results
D.1 Universal Function Approximation Theorem
In what follows, we introduce the universal function approximation theorem (Pinkus, 1999). For
any given activation function σ : R R, we consider the following function class,
→
r
(σ) = c σ(x⊤wi+θ ) c ,θ R,wi Rd .
i i i i
G ∈ ∈
nXi=1 (cid:12) o
(cid:12)
We denote by C(Rd) the class of continuous function(cid:12) s over Rd. Then, the following theorem holds.
Lemma D.1 (Universal Function Approximation Theorem, Theorem 3.1 in Pinkus (1999)). If the
activation function σ C(R) is not a polynomial, the function class (σ) is dense in C(Rd) in the
∈ G
topology of uniform convergence on a compact set.
D.2 Wasserstein Space
We use the definition of absolutely continuous curves in P (RD) in Ambrosio et al. (2008).
2
Definition D.2 (Absolutely Continuous Curve). Let β : [a,b] P (RD) be a curve. Then, we
2
→
say β is an absolutely continuous curve if there exists a square-integrable function f : [a,b] R
→
such that
t
(β ,β ) f(τ)dτ
2 s t
W ≤
Zs
for any a s < t b.
≤ ≤
Then, we have the following first variation formula.
71Lemma D.3 (First Variation Formula, Theorem 8.4.7 in Ambrosio et al. (2008)). Given ν
∈
P (RD) and an absolutely continuous curve µ : [0,T] P (RD), let β : [0,1] P (RD) be the
2 2 2
→ →
geodesic connecting µ and ν. It holds that
t
d (µ ,ν)2
W2 t = µ˙ ,β˙ .
dt 2 −h
t 0 iµt
where µ˙ = ∂ µ , β˙ = ∂ β .
t t t 0 s s s=0
|
Lemma D.4 (Benamou-Brenier formula, Proposition 2.30 in Ambrosio and Gigli (2013)). Let
µ0,µ1 P (RD). Then, it holds that
2
∈
1
(µ0,µ1)= inf µ˙ dt µ : [0,1] P (RD),µ = µ0,µ = µ1 .
W2
k
t kµt
→
2 0 1
(cid:26)Z0 (cid:12) (cid:27)
(cid:12)
(cid:12)
Lemma D.5 (Talagrand’s Inequality, Corol(cid:12)lary 2.1 in Otto and Villani (2000)). Let ν be N(0,κ
·
I ). It holds for any µ P (RD) that
D 2
∈
(µ,ν)2 2D (µ ν)/κ.
2 KL
W ≤ k
Lemma D.6 (Eulerian Representation of Geodesics, Proposition 5.38 in Villani (2003)). Let β :
[0,1] P (RD)beageodesicandubethecorrespondingvectorfieldsuchthat∂ β = div(β u ).
2 t t t t
→ − ·
It holds that
∂ (β u ) = div(β u u ).
t t t t t t
· − · ⊗
where is the outer product of two vectors.
⊗
Lemma D.7 (Dual Representation of the first order Wasserstein Distance, Villani (2008)). The
first order Wasserstein distance has the following dual representation form
(µ,ν) = sup f(x)d(µ ν)(x) f : RD R that is 1-Lipschitz continuous
1
W − →
(cid:26)Z (cid:12) (cid:27)
(cid:12)
(cid:12)
for any two probability measures µ,ν P (R(cid:12) D).
1
∈
72