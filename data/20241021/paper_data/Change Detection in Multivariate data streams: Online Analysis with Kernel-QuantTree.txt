Change Detection in Multivariate data streams:
Online Analysis with Kernel-QuantTree
Michelangelo Olmo Nogara Notarianni1((cid:0)) , Filippo Leveni1 , Diego
Stucchi2 , Luca Frittoli1 , and Giacomo Boracchi1
1 Politecnico di Milano (DEIB), Milan, Italy
{michelangeloolmo.nogara, filippo.leveni, luca.frittoli,
giacomo.boracchi}@polimi.it
2 STMicroelectronics, Agrate Brianza, Italy
diego.stucchi@st.com
Abstract. WepresentKernel-QuantTreeExponentiallyWeightedMov-
ing Average (KQT-EWMA), a non-parametric change-detection algo-
rithm that combines the Kernel-QuantTree (KQT) histogram and the
EWMA statistic to monitor multivariate data streams online. The re-
sulting monitoring scheme is very flexible, since histograms can be used
tomodelanystationarydistribution,andpractical,sincethedistribution
of test statistics does not depend on the distribution of datastream in
stationary conditions (non-parametric monitoring). KQT-EWMA en-
ables controlling false alarms by operating at a pre-determined Average
Run Length (ARL ), which measures the expected number of station-
0
ary samples to be monitored before triggering a false alarm. The lat-
terpeculiarityisincontrastwithmostnon-parametricchange-detection
tests, which rarely can control the ARL a priori. Our experiments on
0
synthetic and real-world datasets demonstrate that KQT-EWMA can
control ARL while achieving detection delays comparable to or lower
0
than state-of-the-art methods designed to work in the same conditions.
Keywords: Online Change Detection · Non-parametric Monitoring ·
Multivariate Data Streams
1 Introduction
Change detection is a frequently faced challenge in data stream analysis, where
thepropertiesofsomemonitoredprocess,e.g.ameasurementacquiredbyasen-
sor,maychangeovertime.Inmachinelearning,changesindatadistributionare
known as concept drifts and pose challenges for classifiers and learning systems
in general, requiring continuous adaptation.
In many application domains such as industrial monitoring, communication
networks, and computer security, data come in virtually unlimited streams and
need to be monitored online. In particular, each new observation needs to be
processed immediately after being acquired, and must be evaluated consider-
ing the whole data stream seen so far, while using a limited amount of mem-
ory and performing a fixed number of operations. In this study, we focus on
4202
tcO
71
]GL.sc[
1v87731.0142:viXra2 O. Nogara Notarianni et al.
online change-detection methods for multivariate data streams, which require
algorithms capable of handling multidimensional vectors within these compu-
tational requirements and storage limitations. Another important challenge is
posed by monitoring in a non-parametric manner, i.e., without any assumption
on the initial data distribution. Non-parametric methods are particularly use-
ful in real-world scenarios where the distribution of data is typically unknown.
Unfortunately, most non-parametric change-detection algorithms are designed
to monitor univariate data streams [15]. On top of that, controlling false alarms
is a significant concern when each detected change can trigger costly interven-
tions. Unfortunately, most online change-detection algorithms for multivariate
data streams, particularly the non-parametric ones, struggle to effectively con-
trol false alarms. This paper addresses these challenges by proposing a method
that is online, non-parametric, and capable of maintaining a target false alarm
rate.
Online change detection monitoring techniques can be grouped into two cat-
egories: one-shot methods, which evaluate fixed-size batches of data points, and
sequential methods, which do not require a fixed sample size and take into ac-
count the whole data stream. QuantTree (QT) is a one-shot non-parametric so-
lutionwhich,supportedbytheoreticalresults,guaranteesapre-setconstantfalse
positive rate (FPR). First presented in [2], QT algorithm defines a histogram,
partitioning the d-dimensional input space. Non-parametric statistics can be
computedoverit,enablingchangedetectioninmultivariatedatastreamsbatch-
wise. A fundamental limitation of QT is discussed in [12]: its splits are defined
along the space axis, resulting in a hyper-rectangular partitioning that does not
alwaysadheretotheinputdistribution.Toaddressthisproblem,apreprocessing
stageistypicallyintroducedtoalignthesplitdirectionstotheprincipalcompo-
nents of the training set. However, it was observed [12] that this preprocessing
can also worsen the control over false alarms. Hence, Kernel-QuantTree (KQT)
was introduced, a generalized version of QT which partitions the space using
kernel functions. The increased flexibility of the histogram in modeling the data
distribution results in a one-shot monitoring of multivariate data streams with
increased detection power. However, KQT is a batch-wise monitoring scheme
usingfixed-sizewindowsanditfailstoleveragetheknowledgeoftheentiredata
streamdistribution,therebyhinderingfastdetectionofchangesinanonlinesce-
nario.Asequential versionof QTalgorithm,QT-EWMA,waspresentedin[4].
QT-EWMA computes the Exponentially Weighted Moving Average (EWMA)
statistic on a QT histogram, thus considering the entire data stream acquired
uptothecurrenttimeinstantttomonitorthedatadistribution.Moreover,QT-
EWMA can control the average time elapsed before a false alarm is triggered
(ARL ).Althoughbeingatrulysequential extensionof QT,QT-EWMAinher-
0
its the same weaknesses of its one-shot counterpart, i.e the axis-parallel splits.
WeproposeKernel-QuantTreeExponentiallyWeightedMovingAverage(KQT-
EWMA),anovelsequential non-parametricchange-detectionalgorithmformul-
tivariate data streams that extends KQT to the online scenario, following the
approach of QT-EWMA. The theoretical properties of KQT guarantee thatOnline Analysis with Kernel-QuantTree 3
KQT-EWMAiscompletelynon-parametricsincethedistributionofourstatis-
tic does not depend on the data distribution, hence the thresholds controlling
the ARL can be set a priori, as in QT-EWMA. These thresholds guarantee
0
by design a constant false alarm probability over time, thus a fixed false alarm
rate at any time instant during monitoring.
Our extensive experimental analysis on both synthetic and real datasets
shows that KQT-EWMA outperforms state-of-the-art existing methods, suc-
cessfully extending KQT properties to the online scenario. Specifically, KQT-
EWMAachievescontrolovertheARL atalowerdetectiondelaycomparedto
0
competitors. We will show that, by relying on a precise partition of the space,
KQT-EWMA outperforms QT-EWMA in complex scenarios, e.g., when ana-
lyzing data from multimodal distributions.
2 Problem formulation
Weconsideravirtuallyunlimitedmultivariatedatastreamx ,x ,...inRdwhere
1 2
data samples x are i.i.d. realizations of a random variable with unknown distri-
t
bution ϕ . We define the change-point t=τ as the unknown time instant when
0
the distribution ϕ experiences a change to ϕ , i.e.:
0 1
(cid:40)
ϕ ift<τ
x ∼ 0 (1)
t
ϕ ift≥τ.
1
We further assume we are provided with a training set TR of N stationary
realizations from ϕ , which is used to fit a model ϕˆ .
0 0
After estimating ϕˆ , online change-detection algorithms typically compute a
0
statisticT ateachobservationx ,toassesswhetherthenewsequence{x ,...,x }
t t 1 t
contains a change point or not. The decision rule usually involves checking
whether T > h , where h is a given threshold. The detection time t∗ is iden-
t t t
tified as the earliest time instant when sufficient statistical evidence indicates a
change in the distribution, i.e.:
t∗ =min{t:T >h }. (2)
t t
A desirable property of change-detection algorithms is that the sequence of
thresholds {h } can be set a priori to guarantee a predefined ARL =E [t∗],
t t 0 ϕ0
where the expectation is taken assuming that the whole data stream is drawn
from ϕ . In practice, ARL , represents the expected time before a false alarm
0 0
occurs,and plays arole similarto TypeI errorprobabilitycontrol in hypothesis
testing. The change-detection goal is to detect a distribution change as soon
as possible, thereby minimizing the detection delay t∗−τ, while aiming for an
empirical ARL to approximate the predefined target value set beforehand.
0
3 Related work
Change-detection algorithms are often parametric since they underpin hypothe-
ses about the data distribution ϕ . As an example, the Change Point Model
04 O. Nogara Notarianni et al.
(CPM)[15]basedontheHotellingtestreliesontheassumptionthatϕ conforms
0
toGaussiandistribution.CPMperformsonlinemonitoringofdatastreamswith
theoretical guarantees regarding ARL control. The CPM formulation can be
0
extended to detect changes given an unknown non-Gaussian distribution when
implemented with the Lepage statistic [10], always controlling false alarms. Un-
fortunately, the test statistics based on ranks are not suitable for multivariate
scenarios. A semi-parametric change-detection strategy, Semi-Parametric Log-
Likelihood (SPLL), was presented in [8]. SPLL models the initial data distri-
butionϕ byfittingaGaussianMixtureModel(GMM)ϕˆ onatrainingsetand
0 0
then compares new incoming batches with batches from the training set using a
likelihoodtest.SinceSPLLdoesnotprovideawaytosetthedetectionthreshold
aprioritocontroltheARL ,itwascombinedwithCPM[4].InSPLL-CPM[4],
0
SPLL reduces the dimensionality of incoming samples by computing their log-
likelihood with respect to a GMM ϕˆ fit on TR, thus the resulting univariate
0
sequencecanbeconvenientlymonitoredbyanon-parametricextensionof CPM
leveragingtheLepageteststatistic[10].Again,themainlimitationofbothSPLL
andSPLL-CPMistheassumptionthatϕ canbewellapproximatedbyaprob-
0
abilitydistributionofaknownfamily(aGMM),whichdoesnotholdingeneral.
There are only a few other multivariate methods that perform non-parametric
change-detection. Scan-B [9] employs a Maximum Mean Discrepancy (MMD)
statistic and can be configured to achieve a target ARL . However, the thresh-
0
olds for this method are defined by analyzing the asymptotic behavior of ARL
0
whenthesizeB oftheslidingwindowislarge[9].Therefore,itfailsataccurately
controlling ARL . The NEWMA algorithm [7], also based on MMD, examines
0
the relationship between two EWMA statistics with distinct forgetting factors.
A limitation of this approach is that setting the ARL thresholds requires the
0
knownanalyticalexpressionofϕ .TheKernel-CUSUM[14]algorithmavoidsas-
0
sumptions about data distribution ϕ , but relies on a truncated approximation
0
for ARL , which results in the underestimation of the thresholds [14]. QT [2]
0
and QT-EWMA [4,5] are histogram-based change-detection methods featuring
the desirable property that the distribution of test statistics, defined over bin
probabilities,doesnotdependontheinitialdistributionϕ .Thisallowstosetde-
0
tectionthresholdsaprioriviaMonteCarloprocedures,allowingforefficientfalse
alarm control. KQT [12] defines histogram bins via nonlinear partition of the
input space, resulting in a powerful change-detection algorithm in multivariate
datastreams.However,beingaone-shot method,itcannotbedirectlyemployed
for online change detection. Our proposal, namely KQT-EWMA, aims to ex-
tendKQTtothesequential scenariowhileretainingthecapabilityofcontrolling
false alarms given a target ARL defined beforehand.
0
4 Kernel-QuantTree EWMA
We present KQT-EWMA, a novel change-detection algorithm which combines
a KQT histogram [12], used as a model ϕˆ of the stationary distribution ϕ ,
0 0
and the online statistic T based on an Exponential Weighted Moving Aver-
tOnline Analysis with Kernel-QuantTree 5
age [4]. In Section 4.1, we illustrate the KQT-EWMA algorithm, describing
the histogram construction, the threshold computation to control ARL , and
0
theonlinemonitoringprocess.InSection4.2,wecomparethecomputationcom-
plexityof KQT-EWMAagainstthealternativesconsideredintheexperimental
section. Finally, in Section 4.3 we discuss the limitations of KQT-EWMA.
4.1 The KQT-EWMA algorithm
Algorithm 1 illustrates the training and inference phases of the KQT-EWMA
algorithm. First, the KQT histogram h={(S ,π )}K is constructed over the
k k k=1
training set TR ⊂ Rd to match a set of target probabilities {π }K (line 1),
j j=1
as described in [12]. The histogram construction process consists in iteratively
splitting the input space into K bins defined as sub-level sets of a measurable
function {f : Rd → R}K , which measures distances between training points
k k=1
andselectedcentroidsusingakernelfunction.WeremarkthatK−1binsdefined
byKQTarecompactsubsetsofRd.Asamplethatdoesnotfallintoanyofthese
is assigned to the residual bin, which covers the unbounded remaining part of
the space. We consider the Mahalanobis and the Weighted Mahalanobis (WM)
distancesaskernelfunctions,(asin[12]),butthepropertiesof KQTholdforany
measurablefunctionprojectingamultivariatevectorinRdonasingledimension.
As in [4], KQT-EWMA computes the weighted averages {Z } (line 7),
j,t
which keep track of the percentage of data stream samples {x ,...,x } falling
1 t
in each bin S ; to this purpose, we define K binary statistics {y } as:
j j,t j
y =1(x ∈S ), (3)
j,t t j
foreachj ∈{1,...,K}andt≥1(line6).Asdiscussedin[4],undertheassump-
tion that the monitored samples x ∼ ϕ are stationary, the expected values of
t 0
the binary statistics in (3) can be approximated (line 2) as:
N π N π +1
E[y ]≈πˆ := j , j <K and E[y ]≈πˆ := K . (4)
j,t j N +1 K,t K N +1
During monitoring, each incoming sample x is used to update the weighted
t
averages{Z }andtocomputetheteststatisticT .First,thesampleisprocessed
j,t t
by the histogram h to obtain the binary statistics {y } (line 6), which in turn
j,t
are used to update the weighted averages {Z } (line 7) as
j,t
Z =(1−λ)Z +λy where Z =πˆ . (5)
j,t j,t−1 j,t j,0 j
Thepastsamplesareweightedbyanexponentialcurvewhichdecreaseswithtime
constant λ. The expected value of the Z statistic under ϕ approximates πˆ ,
j,t 0 j
i.e. E[Z ]≈πˆ for j =1,...,K, thus the change-detection statistic is computed
j,t j
(line 8) as follows:
T
=(cid:88)K (Z j,t−πˆ j)2
. (6)
t πˆ
j
j=16 O. Nogara Notarianni et al.
Algorithm 1: KQT-EWMA
Input: training set TR⊂Rd, target probabilities {π }K , thresholds {h } ,
j j=1 t t
data stream to be monitored x ,x ,...,x ,···⊂Rd
1 2 t
Output: detection flag CD, detection time t∗
1 Construct the KQT histogram {S j,π j}K j=1 over TR as in [12]
2 Calculate the expected probabilities {πˆ j}K j=1 as in (4)
3 Initialize the weighted averages Z j,0 ←πˆ j for each bin j ∈{1,...,K}
4 Initialize the detection flag CD← False and the detection time t∗ ←∞
5 for t=1... do
6 Compute the binary mask y j,t ←1(x t ∈S j)
7 Update the random variables Z j,t ←(1−λ)Z j,t−1+λy j,t, ∀j =1...,K
8 Compute the test statistic T t ←(cid:80)K j=1(Z j,t−πˆ j)2/πˆ j
9 if T t >h t then
10 CD← True, t∗ ←t
11 break
12 return CD, t∗
The test statistic T measures the overall difference between the proportion of
t
pointsineachbinS ,representedbyZ ,andtheirapproximatedexpectedval-
j j,t
uesπˆ underϕ ,thuscorrespondstothePearsonstatistic.Thestatisticnaturally
j 0
increases as a consequence of a change ϕ →ϕ that modifies the probability of
0 1
at least one bin. Finally, the statistic T is compared against the corresponding
t
threshold h to detect a change (line 10).
t
False Alarms and Threshold computation strategy. KQT-EWMAalgo-
rithm inherits from Kernel-QuantTree the fundamental property that the dis-
tribution of the statistics in (6) does not depend on the data distribution ϕ .
0
The true bin probabilities p = P (S ), i.e. the set of probabilities of a point
j ϕ0 j
sampled from ϕ to belong to the bin S , are drawn from the Dirichlet distri-
0 j
bution (p ,...,p ) ∼ D(π N,π N,...,π N +1) where {π }K is the set of
1 K 1 2 K j j=1
target probabilities, as demonstrated in [12]. It follows that the distribution of
any statistic based on KQT, including T , does not depend on ϕ [2,4]. Thus,
t 0
thethresholds{h } canbedefinedaprioritocontrolARL onanydatastream,
t t 0
which is defined as:
1
ARL =E [t∗]= . (7)
0 ϕ0 α
Asexplainedin[5],detectionthresholdsh guaranteetheconstantfalsealarm
t
probability, i.e. thresholds are such that the following equation is satisfied:
P(T >h |T ≤h ∀k <t)=α ∀t≥1. (8)
t t k k
Since detection time t∗ is a Geometric random variable with parameter α,
the probability of encountering a false alarm before time t can be determinedOnline Analysis with Kernel-QuantTree 7
through the geometric sum:
(cid:88)t 1−(1−α)t
P(t∗ ≤t)= α(1−α)k−1 =α· =1−(1−α)t. (9)
α
k=1
Thus, we can monitor the control over false alarms in data streams containing
a change point τ by computing the proportion of streams in which t∗ ≤τ.
We leverage the results in [5] which proves that, to estimate the thresholds
h ,onecandirectlysimulatetheconstructionof QThistogramsonatrainingset
t
TR ∼ ϕ of size N by drawing its bin probabilities from the Dirichlet distribu-
0
tion,(p ,...,p )∼D(π N,π N,...,π N+1).ThisapproachholdswithKQT
1 K 1 2 K
givenanykernelfunction,i.e.wecanusethesamethresholdsequencesgivenany
measurablefunction,includinglinearsplitfunctionsalongtheaxis,whichwould
resultinaQThistogram.Therefore,thesamethresholds,computedinaMonte
Carlo scheme, can be used for QT-EWMA and KQT-EWMA to guarantee a
constantfalsealarmprobabilityovertime.Thethresholdsdonotdependonthe
data distribution ϕ nor the data dimension d. The entire simulation procedure
0
must be repeated when changing the λ parameter of the EWMA statistic, the
target bin probabilities {π }K , or the training set size N.
j j=1
4.2 Computational complexity
Since efficiency is key in online monitoring, we analyze the computational com-
plexity of KQT-EWMA in comparison with QT, QT-EWMA, KQT, and
SPLL, SPLL-CPM, and Scan-B. The results are summarized in Table 1. Fur-
ther explanations can be found in [5,12]
The training of a KQT given a training set TR of N points comprises i)
the projection of TR by f , whose cost depends on the specific kernel function,
k
ii) the computation of the split value, which costs O(N), and iii) the centroid
selection. The cost of computing the Euclidean distance - or other distances
basedonl norms-isO(d),whiletheMahalanobisdistancecostsO(d2)andthe
p
Weighted Mahalanobis (WM) distance costs O(M d2), where M is the number
of Gaussian components fitted to TR and d is the data dimension. The centroid
selection criteria is based on the information gain, which estimate is dominated
by the computation of the determinant of the sample covariance matrix, which
costs O(d3). Overall, the cost of the index computation is multiplied by the
numberofcentroidsV testedduringtheselectionprocedure;therefore,anupper
bound for the cost of KQT construction is O(K V (N +M N d2 +d3)) when
using the WM distance and the information gain criteria. During monitoring,
theonlyoperationperformedistheprojectionbyf ofthesamples,resultingin
k
a cost of O(KM d2) in case of the WM distance.
4.3 Discussion and limitations
The main limitation of KQT-EWMA is that it is based on measures requiring
the computation of the sample covariance matrix, which can be challenging in8 O. Nogara Notarianni et al.
Table 1: Training and inference costs of KQT-EWMA with Weighted Mahalanobis
(WM) distance and distances derived from l norms (e.g. Euclidean distance when
p
p=2), compared against the other considered methods. V is the number of centroids
tested to build each bin, M is the number of Gaussian components fit on the dataset,
K is the number of bins, and N is the training set size. As for the other methods, m
is the number of Gaussian components and w is the window length used by SPLL; n
is the number of windows of B samples employed by Scan-B.
Method Training Cost Inference Cost (per sample)
KQT-EWMA (WM) O(KV(N +M N d2+d3)) O(KM d2)
KQT-EWMA (l ) O(KV(N +N d+d3)) O(Kd)
p
QT-EWMA O(KN logN) O(K)
SPLL (online) O(mN d2) O(md+w logw)
Scan-B N.A. O(nBd)
high-dimensionaldatastreams.InKQT,givenanykernelfunction,thecentroid
selectioncriteriaisthemaximuminformationgain:thebestsplitlowersthedata
entropy[12],whichiscomputedasH(B)=(1/2)log(cid:0) (2πe)ddet(cov[B])(cid:1)
,where
cov[B] is the sample covariance matrix computed over a set of points B. More-
over, the sample covariance matrix estimated from the training set TR is used
to define the Mahalanobis and the WM distances. The problem of determining
the minimal sample size N that guarantees that the sample covariance matrix
approximates the actual covariance matrix depends on the data distribution,
as well explained in [13]. Our experiments shows that KQT-EWMA can lose
control over ARL when few training points are provided.
0
QT-EWMA-update Algorithm [5] is an effective monitoring scheme when N
is relatively small, i.e. when there are a few training samples, as this estimates
the bin probabilities incrementally as new observations are available, as long as
no changes are detected. While an incremental variant of KQT-EWMA can
be implemented, this would be impractical due to computational and memory
requirements,asitwouldrequirere-computingcovariancematricesandcentroids
(possibly in a high dimensional space) at each update.
5 Experiments
The goal of our experiments is to show that KQT-EWMA controls the false
alarmswhileachievingstate-of-the-artdetectiondelays.Todothis,wewillshow
empirical results obtained on both synthetic and real-world data streams. In
KQT-EWMA,asinQT-EWMA[4],wesetthenumberofbinstoK =32and
uniform target probabilities π = 1/K. The exponential decay of the EWMA
j
statistic is given by a time constant λ = 0.05. To monitor with QT and SPLL
wesetthebatchsizeν =32asin[4],andweemploytheoriginalconfigurationof
the Scan-B algorithm [9] (n=5 windows of B =100 samples), if not specified
otherwise. We set window length w = 1000 for SPLL-CPM. The number of
centroids tested to build each bin of KQT-EWMA is V =250.Online Analysis with Kernel-QuantTree 9
5.1 Datasets
Synthetic: As in [5], we generate synthetic data streams in spaces of increas-
ing dimension d ∈ {2,4,8,16,32,64}. We use Gaussian distributions ϕ with
0
a random covariance matrix, and then we define the post-change distribution
ϕ =ϕ (Q+v) as a random roto-translation of ϕ . The roto-translation param-
1 0 0
eters Q and v are generated using the CCM framework [3] to guarantee a fixed
distance between the two distributions computed as the symmetric Kullback-
Leibler divergence sKL(ϕ ,ϕ ) ∈ {0.5,1,1.5,2,2.5,3}. We expand our analysis
0 1
todatasetssampledfrombi-modalandtri-modalGaussianstoshowthebenefits
of the distribution estimation with a KQT histogram for change detection.
Real-world:Asin[4],wetestsevenmultivariateclassificationdatasetsofvary-
ing dimensionality: El Niño Southern Oscillation (“niño”, d=5), Physicochemi-
cal Properties of Protein Ternary Structure (“protein”, d=9), two of the Forest
Covertype datasets (“spruce” and “lodgepole”, d = 10), Credit Card Fraud De-
tection (“credit”, d = 28), Sensorless Drive Diagnosis (“sensorless”, d = 48),
and MiniBooNE particle identification (“particle”, d=50). We preprocess these
datasetsfromtheUCIMachineLearningRepository[6]asin[4]:"particle","pro-
tein", "credit", and "sensorless" datasets are standardized with respect to the
standardscore,andwesumtoeachcomponentof“sensorless”,“particle”,“spruce”
and “lodgepole” imperceptible Gaussian noise to avoid repeated values, which
harm the construction of QT histograms. The distributions of these datasets
are considered to be stationary [4]. We randomly sample the data streams and
introducechangesϕ →ϕ byshiftingtheeachdistributionbyarandomvector
0 1
drawnfromad-dimensionalGaussianscaledbythetotalvarianceofthedataset.
We show the analysis of UCI datasets as the average results obtained over all
the datasets.
Our experiments also include the INSECTS dataset[11], whichcontains d=
33 attributes derived from the wing-beat frequency of various insects, captured
viaan opticalsensor.This dataset,tailor-madefor change-detectiontechniques,
contains records under diverse environmental conditions impacting insect flight
behaviors.Wefocusontheabrupt-changevariantofthisdataset,whichincludes
five distinct distribution changes ϕ → ϕ → ··· → ϕ . We sample data points
0 1 5
from these distributions to build our training set TR and test data streams.
Results obtained over the five changes present in the INSECTS datasets are
averaged and shown all together.
5.2 Figures of merit
Empirical ARL . To assess whether KQT-EWMA and the other considered
0
methods control the target ARL (see (7)), we compute its empirical value as
0
theaveragetimebeforeraisingafalsealarmondatastreamswesamplefromϕ .
0
EmpiricalARL valuesaremeasuredon4000datastreamsdrawnfromϕ ,given
0 0
a target ARL taking values in {500, 1000, 2000, 5000}. We generate stationary
0
data streams of length L=6·ARL - the corresponding probability to detect a
0
false alarm in each sequence is thus P(t∗ ≤L)≈0.9975, as in [4].10 O. Nogara Notarianni et al.
Monomodal Bimodal Trimodal
5000
2000
1000
500
500 1000 2000 5000 500 1000 2000 5000 500 1000 2000 5000
TargetARL0 TargetARL0 TargetARL0
1000
100
0.06 0.14 0.26 0.45 0.06 0.14 0.26 0.45 0.06 0.14 0.26 0.45
FARate FARate FARate
QT-EWMA KQT-EWMA-maha SPLL
Scan-B KQT-EWMA-weight SPLL-CPM
Fig.1:EmpiricalARL anddetectiondelayachievedbytheconsideredmethodsmoni-
0
toringdatastreamsgeneratedbyGaussianmixtureswithincreasingnumberofcompo-
nents (1, 2, 3). We show that as the number of components increases, KQT-EWMA
with Weighted Mahalanobis (WM) distance advantage in terms of detection delay in-
creases,achievingingeneralthelowestdelayswhilecontrollingfalsealarms.Inallthe
experiments, the GMM used to compute the WM distance fits M =4 components.
Detection Delay. We evaluate the detection power of KQT-EWMA and the
otherconsideredmethodsbytheirdetectiondelay,i.e.,ARL =E[t∗−τ],where
1
theexpectationistakenassumingthatachangepointτ ispresent.Again,weset
the target ARL a priori, ARL ∈{500,1000,2000,5000}. Results are averaged
0 0
over 4000 data streams of length 6·ARL , each containing a change point at
0
τ =300.Thisisadifferencecomparedtotheanalysisin[4,5],wheretheaverage
detection delay is computed at any given target ARL on sequences of fixed
0
length. We use sequences of the same length to estimate detection delay and
ARL to achieve a fair comparison between these two quantities.
0
False Alarm rate. The False Alarms (FA) rate is computed as the number of
alarms raised at some t < τ, averaged over 4000 experiments. By setting the
targetARL to{500,1000,2000,5000},weexpectthepercentageoffalsealarms
0
to be {45%,26%,14%,6%}, respectively, as stated by (9). The target FA rates
are indicated in the plots by vertical dotted lines.
5.3 Results and Discussion
False alarms control. To show the control over false alarms, we plot the em-
pirical ARL obtained in our experiments against the target ARL set a pri-
0 0
ori. We compare results obtained over data sampled from monomodal Gaus-
0LRAlaciripmE
yaleDnoitceteDOnline Analysis with Kernel-QuantTree 11
Results averaged over UCI+Credit datasets
5000
1000
2000 100
1000
500
500 1000 2000 5000 0.06 0.14 0.26 0.45
TargetARL0 FARate
QT-EWMA KQT-EWMA-maha SPLL
Scan-B KQT-EWMA-weight SPLL-CPM
Fig.2:AverageempiricalARL anddetectiondelayondatastreamssampledfromthe
0
UCIdatasets,excludingthehighest-dimensionalones(i.e.,"particle"and"sensorless").
Inthesetwocases,N =4096trainingsamplesarenotenoughforKQT-EWMAbased
on Mahalanobis and WM distances to properly control ARL . In this setting, KQT-
0
EWMAwithWMdistanceachievesbyfarthebestperformance,halvingthedetection
delay of QT-EWMA while controlling the target ARL .
0
Results averaged over INSECTS dataset (d=33)
5000
1000
2000
100
1000
500
500 1000 2000 5000 0.06 0.14 0.26 0.45
TargetARL0 FArate
Fig.3:AverageempiricalARL anddetectiondelayondatastreamsfromtheINSECTS
0
dataset [11], with different combinations of ϕ and post-change distribution ϕ . QT-
0 1
EWMA and KQT-EWMA achieve similar detection delays, while KQT-EWMA
with WM distance struggles in controlling higher values of ARL .
0
sianswiththesameperformancemeasurescomputedovermultimodalGaussian
datasets (bimodal and trimodal, in Figure 1, first row). In all the experiments,
the number of components used to fit the GMM and compute the WM distance
isM =4.QT-EWMAandSPLL-CPMcancontrolallthetargetvalueschosen
for ARL , while ingeneral SPLL and Scan-B struggle in achieving hightarget
0
ARL ∈ {2000,5000}. This is true also considering the results obtained with
0
others real-world data sets (see Figures 2 and 3).
KQT-EWMAeffectivelycontrolstargetvaluesofARL ,whileachievingthe
0
lowest detection delays in these scenarios(see Figure 1, second row). Figure 2
(first row) shows experimental results averaged over data streams sampled from
5 UCI datasets having d ≤ 28, for which we used N = 4096 training points.
We show two high-dimensional datasets (“particle” and “sensorless”, d=50 and
d = 48 respectively, see Figure 6) separately, since 4096 training points are not
enoughtoestimatethesamplecovariancematrixinhighdimensions,andKQT-
0LRAlaciripmE
0LRAlaciripmE
yaleDnoitceteD
yaleDnoitceteD12 O. Nogara Notarianni et al.
Monomodal Gaussian (d=4)
N=128 N=256 N=1024 N=4096
5000
2000
1000
500
TargetARL0 TargetARL0 TargetARL0 TargetARL0
1000
100
FArate FArate FArate FArate
QT-EWMA KQT-EWMA-maha SPLL
Scan-B KQT-EWMA-weight SPLL-CPM
Fig.4: Empirical ARL and detection delay on Gaussian data streams in d = 4 di-
0
mensions, for varying training set sizes N ∈ {128,256,1024,4096}. The empirical
ARL (firstrow)ofQT-EWMAandSPLL-CPMalwaysapproachesthetargetvalues
0
(500,1000,2000,5000), while the other methods cannot control the ARL . When the
0
training set size N is sufficiently large (N ∈{1024,4096}), KQT-EWMA can control
the FA rate, and achieves the lowest detection delay when using the Mahalanobis or
the WM distance.
EWMA based on Mahalanobis and WM distances do not properly control the
ARL . In particular, KQT-EWMA with WM distance achieves low empirical
0
ARL values due to the difficulty in fitting a GMM here.
0
Figure7plotsthechangemagnitudesKL(ϕ ,ϕ )againstthedetectiondelay
0 1
achieved by the considered methods monitoring Gaussian data sequences with
a target ARL =1000. While all methods successfully control the false alarms,
0
KQT-EWMAachievesthelowestdetectiondelay,eveninthissettingwherethe
parametric assumptions of SPLL are met (number of Gaussian components is
settom=1).Theadvantageof KQT-EWMAoverthealternativesisespecially
noticeable when the divergence between the pre- and post-change distributions
is low (sKL = 0.5). As expected, the detection delay of all methods decreases
when the change magnitude increases.
Detection Delay vs False Alarms. To assess the detection power of these
models, we plot the average detection delay against the percentage of false
alarms. Figure 1 (second row) shows that KQT-EWMA with Mahalanobis and
WM distances achieves the lowest detection delay regardless of the number of
modalities,alongsideScan-B.However,Scan-Bisunabletocontrolhigherval-
ues of ARL . Similarly, SPLL cannot control ARL , and the distance from the
0 0
0LRAlaciripmE
yaleDnoitceteD
005
60.0
0001
41.0 62.0
0002
54.0
0005 005
60.0
0001
41.0
0002
62.0 54.0
0005 005
60.0
0001
41.0
0002
62.0 54.0
0005 005
60.0
0001
41.0
0002
62.0 54.0
0005Online Analysis with Kernel-QuantTree 13
Monomodal Gaussian (N =4096)
d=2 d=4 d=16 d=64
5000
2000
1000
500
TargetARL0 TargetARL0 TargetARL0 TargetARL0
1000
100
FArate FArate FArate FArate
QT-EWMA KQT-EWMA-maha SPLL
Scan-B KQT-EWMA-weight SPLL-CPM
Fig.5:EmpiricalARL anddetectiondelayondatastreamsdrawnfromaGaussiandis-
0
tribution with dimension d∈{2,4,16,64}, trained over N =4096 stationary samples.
TheempiricalARL (firstrow)of KQT-EWMA,QT-EWMA,andSPLL-CPMal-
0
ways match the target, while Scan-B and SPLL fail. However, KQT-EWMA using
the Mahalanobis distance cannot control the ARL well when d = 64, as N = 4096
0
training points are not sufficient to estimate such a high-dimensional covariance ma-
trix.Whend≤16,thedetectiondelay(secondrow)achievedwithKQT-EWMAwith
MahalanobisdistanceisthelowestachievedamongthemethodscontrollingtheARL .
0
targetvaluesisevenmorepronounced.Thisisalsoevidentintheresultsonreal
data (Figures 2 and 3). If we compare KQT-EWMA to QT-EWMA, which
has the second-best detection delay values in the Gaussian scenario (Figure 1,
secondrow),wecanobservethatKQT-EWMAmorethanhalvesthedetection
delay of QT-EWMA. Moreover, this difference increases as the complexity of
theunderlyingdistributionrises.Thisresultisconfirmedbyalltheexperiments
onbothreal(Figures2and3)andsynthetic(Figures4and5)datasets,showing
that the histogram construction strategy of KQT-EWMA, coupled with the
Mahalanobis andWM distances,improvesthe detectionperformance, achieving
lower detection delays. Figure 5 shows the effects of detectability loss [1]: the
abilitytoperceiveadistributionchangediminishesasthedatadimensionalityd
increases while the distance between pre- and post-change distribution is fixed
(sKL=1), thus detection delays increase.
Figure 7 illustrates the relation between the detection delay and the change
magnitude between pre- and post-change Gaussian sequences. We set target
ARL =1000forallmethods.Allmethodssuccessfullycontrolthefalsealarms,
0
and KQT-EWMA achieves the lowest detection delay, even when the para-
0LRAlaciripmE
yaleDnoitceteD
005
60.0
0001
41.0
0002
62.0 54.0
0005 005
60.0
0001
41.0
0002
62.0 54.0
0005 005
60.0
0001
41.0
0002
62.0 54.0
0005 005
60.0
0001
41.0
0002
62.0 54.0
000514 O. Nogara Notarianni et al.
UCI "Sensorless" dataset (d=48)
5000
100
2000
10
1000
500
500 1000 2000 5000 0.06 0.14 0.26 0.45
TargetARL0 FARate
UCI "Particle" dataset (d=50)
5000
1000
2000
100
1000
500
500 1000 2000 5000 0.06 0.14 0.26 0.45
TargetARL0 FARate
QT-EWMA KQT-EWMA-maha SPLL
Scan-B KQT-EWMA-weight SPLL-CPM
Fig.6:EmpiricalARL anddetectiondelayachievedbytheconsideredmethodsmoni-
0
toringthetwohigh-dimensionalUCIdatasets"particle"(d=48,above)and"sensor-
less" (d = 50, below). The N = 4096 training samples used in these experiments are
not enough for KQT-EWMA based on Mahalanobis and WM distances to properly
control ARL . Results are averaged over 4000 experiments.
0
metric assumptions of SPLL are met (number of Gaussian components is set
to m = 1). The advantage of KQT-EWMA over the alternatives is especially
noticeable when the divergence between the pre- and post-change distributions
is low (sKL = 0.5). As expected, the detection delay of all methods decreases
when the change magnitude increases.
Our extensive analysis shows that KQT-EWMA consistently achieves the
lowest detection delays across different scenarios. Overall, KQT-EWMA based
on Mahalanobis and WM distances can detect distribution changes more effec-
tively, especially when the complexity of the underlying distribution rises.
6 Conclusion and Future Works
We introduce KQT-EWMA, a non-parametric online change-detection algo-
rithm for multivariate data streams based on Kernel-QuantTree [12]. The theo-
retical results underpinning KQT-EWMA [5,12] guarantee the control of false
alarms independently on the initial data distribution. Our experiments on syn-
thetic and real-world data streams show that KQT-EWMA achieves state-of-
the-art detection delay while effectively controlling false alarms.
0LRAlaciripmE
0LRAlaciripmE
yaleDnoitceteD
yaleDnoitceteDOnline Analysis with Kernel-QuantTree 15
Monomodal Gaussian (d=4, N =4096, Target ARL =1000)
0
QT-EWMA KQT-EWMA-maha SPLL
Scan-B KQT-EWMA-weight SPLL-CPM
Fig.7: Detection delay as a function of the magnitude of the change ϕ →ϕ between
0 1
pre- and post-change Gaussian sequences. We set the target ARL = 1000. KQT-
0
EWMA achieves the lowest detection delay, even in the challenging scenario when
the change magnitude is low (sKL = 0.5). As expected, all methods decrease their
detection delays when the change magnitude increases. We remark that the empirical
ARL achieved by SPLL and Scan-B is lower than the target.
0
Inparticular,thealgorithmcanleverageanymeasurablekernelfunctionand
it is able to fit complex distributions, resulting in high detection power. The
sequences of thresholds can be computed independently on the data distribu-
tion ϕ , the data dimension d, and the selected kernel function. Moreover, the
0
monitoring scheme is invariant to roto-translation of the input data (when em-
ploying Mahalanobis and Weighted Mahalanobis distances, as shown in [12]),
thus KQT-EWMA does not require any preprocessing step such as PCA.
Ourexperimentalevaluationalsodelineatessomelimitations:whilethecom-
putational complexity of QT-EWMA scales well with the data dimension d
during both training and testing phases, KQT-EWMA’s computational com-
plexity does not, potentially impacting its practical utility in high-dimensional
scenarios. Additionally, KQT-EWMA relies on the sample covariance matrix,
whose estimation can be poor in high-dimensional scenarios where the train-
ing set TR is not sufficiently large. Nevertheless, our experiments show that
KQT-EWMA achieves excellent performance compared to the other methods
designed for online monitoring, including QT-EWMA, while effectively con-
trollingthefalsealarms,especiallywhenconsideringcomplexdatadistributions
such as multi-modal Gaussians or real-world datasets.
Futureworkconcernsaddressingthelimitationsof KQT-EWMAwithhigh-
dimensional datasets. Specifically, we plan to design kernels that do not rely on
covariance matrix computation and are specifically tailored for the sequential
high-throughput scenario.16 O. Nogara Notarianni et al.
References
1. Alippi,C.,Boracchi,G.,Carrera,D.,Roveri,M.:Changedetectioninmultivariate
datastreams: Likelihood and detectability loss. International Joint Conference on
Artificial Intelligence (IJCAI) 2, 1368–1374 (2016)
2. Boracchi, G., Carrera, D., Cervellera, C., Macciò, D.: QuantTree: Histograms for
change detection in multivariate data streams. In: Proceedings of the 35th Inter-
national Conference on Machine Learning. vol. 80, pp. 639–648. PMLR (2018)
3. Carrera, D., Boracchi, G.: Generating high-dimensional datastreams for change
detection. Big Data Research 11, 11–21 (2018)
4. Frittoli, L., Carrera, D., Boracchi, G.: Change detection in multivariate datas-
treamscontrollingfalsealarms.In:MachineLearningandKnowledgeDiscoveryin
Databases. Research Track. pp. 421–436. Springer (2021)
5. Frittoli,L.,Carrera,D.,Boracchi,G.:Nonparametricandonlinechangedetection
in multivariate datastreams using QuantTree. IEEE Transactions on Knowledge
and Data Engineering 25(8), 8328–8342 (2022)
6. Kelly, M., Longjohn, R., Nottingham, K.: The uci machine learning repository,
https://archive.ics.uci.edu
7. Keriven, N., Garreau, D., Poli, I.: Newma: A new method for scalable model-free
online change-point detection. IEEE Transactions on Signal Processing 68, 3515–
3528 (2020). https://doi.org/10.1109/TSP.2020.2990597
8. Kuncheva, L.I.: Change detection in streaming multivariate data using likelihood
detectors. IEEE Transactions on Knowledge and Data Engineering 25(5), 1175–
1180 (2013)
9. Li,S.,Xie,Y.,Dai,H.,Song,L.:ScanB-statisticforkernelchange-pointdetection.
Sequential Analysis 38(4), 503–544 (2019)
10. Ross, G.J., Tasoulis, D.K., Adams, N.M.: Nonparametric monitoring of data
streams for changes in location and scale. Technometrics 53(4), 379–389 (2011)
11. Souza, V.M.A., dos Reis, D.M., Maletzke, A.G., Batista, G.E.A.P.A.: Challenges
in benchmarking stream learning algorithms with real-world data. Data Mining
and Knowledge Discovery 34, 1805 – 1858 (2020)
12. Stucchi,D.,Rizzo,P.,Folloni,N.,Boracchi,G.:KernelQuantTree.In:Proceedings
of the 40th International Conference on Machine Learning (2023)
13. Vershynin,R.:Howcloseisthesamplecovariancematrixtotheactualcovariance
matrix?JournalofTheoreticalProbability25(042010).https://doi.org/10.1007/
s10959-010-0338-z
14. Wei, S., Xie, Y.: Online kernel cusum for change-point detection (11 2022). https:
//doi.org/10.48550/arXiv.2211.15070
15. Zamba, K.D., Hawkins, D.M.: A multivariate change-point model for statistical
process control. Technometrics 48(4), 539–549 (2006)