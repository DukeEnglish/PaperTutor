Preprint
CAN MLLMS UNDERSTAND THE DEEP IMPLICATION
BEHIND CHINESE IMAGES?
ChenhaoZhang1,2∗ XiFeng2,3∗ YuelinBai2∗ XinrunDu4,5∗
JinchangHou2,3 KaixinDeng6 GuangzengHan7 QinruiLi8 BingliWang9 JiahengLiu4
XingweiQu10 YifeiZhang11 QixuanZhao2,3 YimingLiang12 ZiqiangLiu2 FeitengFang2,3
MinYang2 WenhaoHuang5 ChenghuaLin11 GeZhang4,5† ShiwenNi2†
1HuazhongUniversityofScienceandTechnology 2ShenzhenInstituteofAdvancedTechnology,CAS
3UniversityofScienceandTechnologyofChina 4M-A-P 501.ai 6CDUT 7UniversityofMemphis
8UniversityofCalifornia,SantaBarbara 9SICAU 10UniversityofManchester 12SWU 12UCAS
ABSTRACT
As the capabilities of Multimodal Large Language Models (MLLMs) continue
to improve, the need for higher-order capability evaluation of MLLMs is in-
creasing. However, there is a lack of work evaluating MLLM for higher-order
perception and understanding of Chinese visual content. To fill the gap, we in-
troduce the Chinese Image Implication understanding Benchmark, CII-Bench,
which aims to assess the higher-order perception and understanding capabilities
ofMLLMsforChineseimages. CII-Benchstandsoutinseveralwayscompared
to existing benchmarks. Firstly, to ensure the authenticity of the Chinese con-
text, images in CII-Bench are sourced from the Chinese Internet and manually
reviewed, with corresponding answers also manually crafted. Additionally, CII-
BenchincorporatesimagesthatrepresentChinesetraditionalculture, suchasfa-
mous Chinese traditional paintings, which can deeply reflect the model’s under-
standing of Chinese traditional culture. Through extensive experiments on CII-
Bench across multiple MLLMs, we have made significant findings. Initially, a
substantialgapisobservedbetweentheperformanceofMLLMsandhumanson
CII-Bench. ThehighestaccuracyofMLLMsattains64.4%,whereashumanac-
curacyaverages78.2%,peakingatanimpressive81.0%. Subsequently,MLLMs
perform worse on Chinese traditional culture images, suggesting limitations in
their ability to understand high-level semantics and lack a deep knowledge base
of Chinese traditional culture. Finally, it is observed that most models exhibit
enhancedaccuracywhenimageemotionhintsareincorporatedintotheprompts.
WebelievethatCII-BenchwillenableMLLMstogainabetterunderstandingof
Chinese semantics and Chinese-specific images, advancing the journey towards
expert artificial general intelligence (AGI). Our project is publicly available at
https://cii-bench.github.io/.
(a) Chinese image (b) English image
Figure1: ComparisionofChineseandEnglishimageimplications. Chineseimagesoftenembody
richerscenesanddeeperimplicationswithChinesetraditionalculturecomparedwiththestraight-
forwardandexplicitsymbolisminEnglishimages.
∗EqualContribution.(cid:66)ch zhang@hust.edu.cn;fengxi@ustc.edu
†Correspondingauthors.(cid:66)gezhang@umich.edu;sw.ni@siat.ac.cn
1
4202
tcO
71
]LC.sc[
1v45831.0142:viXraPreprint
1 INTRODUCTION
Withtherapidadvancementofartificialintelligence,MultimodalLargeLanguageModels(MLLMs)
(Liuetal.,2023b;Lietal.,2023c;Yeetal.,2023;Tongetal.,2024)havedemonstratedexceptional
performanceacrossvariousdomains,includingnaturallanguageprocessing(Chowdhary&Chowd-
hary, 2020; Luo et al., 2024; Zhang et al., 2024a) and computer vision (Lu et al., 2022; Li et al.,
2023b;a;Xuetal.,2023;Fuetal.,2023;Caietal.,2023;Zhangetal.,2023;Chenetal.,2024b;Jin
etal.,2024).Thesemodelsarenotonlycapableofprocessingandgeneratingtextbutalsoexcelatin-
tegratingandinterpretinginformationacrossmultiplemodalities,suchasimages,sound,andvideo.
However, despite the significant progress made in tasks like image recognition and generation, a
crucialresearchquestionremains:Canthesemodelstrulyunderstandandinterpretimagesthathave
deepimplications?(Liuetal.,2024b)constructanEnglishimageimplicationunderstandingdataset,
II-Bench,andtheexperimentsonMLLMsandhumansubjectsrevealasubstantialgapinthemod-
els’higher-orderperceptionabilities,particularlyinnuancedemotionalunderstandingandprofound
meaningextraction,whencomparedtohumans. Unfortunately,therapidadvancementofMLLMs
hasledtosignificantperformanceimprovements. Forinstance,Claude-3.5-Sonnethasachievedan
impressiveaccuracyof80.9%onII-Bench,approachingtheaveragehumanaccuracyof90.3%.This
progressunderscorestheneedformorechallengingbenchmarksthatincorporatericherscenesand
deeperimplicationstocontinuepushingtheboundaryofimageimplicationunderstandingtask.
In contrast to English images, Chinese images often embody richer scenes (Xu, 2023) and deeper
implicationsasFigure1shows.Forinstance,Chinesetraditionallandscapepaintingsnotonlydepict
natural scenery but also convey profound philosophical concepts, such as the harmony between
humansandnature,throughartistictechniquesliketheinterplayofvoidandsolid,theuseofnegative
space, and the brushwork. As the famous Chinese poet Su Shi noted, “Poetry and painting share
the same essence, embodying both craftsmanship and purity”. The depth of Chinese images lies
not only in their aesthetic appeal but also in the underlying spirit and philosophy they express.
Similarly, New Year paintings, as a significant carrier of Chinese traditional culture, typically use
symbolism and implication to convey wishes for good fortune, prosperity, and peace. Unlike the
directness often found in English imagery, Chinese images emphasize the creation of atmosphere
and subtle expression, requiring viewers to possess certain cultural knowledge to accurately grasp
theirmeanings.Thisculturaldisparityleadstosignificantdifferencesinthemodesofexpressionand
meaningconveyedbetweenChineseandEnglishimages,highlightingtheneedtoconsidercultural
contextwhenevaluatingthecapabilityofMLLMstounderstandthedeepimplicationsofimages.
To address this gap, we develop CII-Bench, a benchmark designed to comprehensively test the
higher-orderperception,reasoning,andunderstandingabilitiesofmodelswithinaChinesecontext.
Thisbenchmarkallowsustogainaclearerunderstandingofthesemodels’interpretivecapacities,
offering new insights into their application in cross-cultural environments, and thus advancing the
researchanddevelopmentofMLLMs.
As illustrated in Figure 2, CII-Bench comprises
698 images and 800 multiple-choice questions
spanning six domains: Life, Art, Society, Poli-
tics, Environment, and Chinese Traditional Cul-
ture. Moreover, to ensure diversity, CII-Bench
includessixtypesofimages: Illustration,Meme,
Poster, Single-panel Comic, Multi-panel Comic,
and Painting. By employing images of various
typesandfromdifferentdomains,thebenchmark
provides a more robust evaluation of models’
comprehensionandreasoningabilities.
Figure2: CompositionofCII-Bench.
We conduct extensive experiments to evaluate
CII-Bench on MLLMs that support Chinese and
deeplyevaluatethemodel’sgraspofChinesetraditionalculture. Ourkeycontributionsareasfol-
lows:
• WeintroduceCII-Bench,thefirstbenchmarkdesignedtoassesstheunderstandingofimplica-
tionsinChineseimages,whichposesasignificantchallengetocurrentMLLMs.
2Preprint
• WedesignacomprehensiveevaluationmetricbasedonGPT-4otoevaluateChinesetraditional
culture. Thismetricalignsmorecloselywithhumanannotationsandisbettersuitedforevalu-
atingChinesetraditionalpainting.
• Our experimental findings are as follows: (1) There is a notable performance gap between
MLLMs and humans. Models demonstrate the highest accuracy of 64.4%, while human ac-
curacy average at 78.2% and best at 81.0%. (2) Closed-source models generally outperform
open-source models, but the best-performing open-source model surpasses the top closed-
source model, with a difference of more than 3%. (3) Models perform significantly worse
in Chinese traditional culture compared to other domains, indicating that current models still
lacksufficientunderstandingofChineseculture. FurtheranalysisshowsthatGPT-4ocanonly
observethesurface-levelinformation, it’sdifficulttodeeplyinterpretthecomplexculturalel-
ements contained in Chinese traditional painting. (4) Incorporating image emotion hints into
promptsgenerallyimprovesmodelscores, indicatingthatmodelsstrugglewithemotionalun-
derstanding,leadingtomisinterpretationoftheimplicitmeaningsintheimages.
2 RELATED WORK
2.1 MULTIMODALLARGELANGUAGEMODELS
Withtherapiddevelopmentoflargelanguagemodels(LLMs)(Aakankshaetal.,2022;Wonetal.,
2022; Chiang et al., 2023; Touvron et al., 2023; OpenAI, 2023a;b; Team, 2024; Cai et al., 2024),
MultimodalLargeLanguageModels(MLLMs)havemadesignificantimprovements. Manyworks
incorporateadditionalmoduleinputsonLLMs,effectivelybridgingthegapbetweenvisualandlan-
guage. BLIP-2(Lietal.,2023c)encodesimagesusingViT(Dosovitskiyetal.,2020)andemploys
a Q-Former to map visual features into the language space. LLaVA (Liu et al., 2023b;a; 2024a;
Li et al., 2024a) utilizes an MLP as the connector between the visual encoder and the LLM back-
bone. Similarly, mPLUG-Owl2(Yeetal.,2023)employsamodality-adaptivemoduletofacilitate
thecollaborationbetweenvisualandlanguagemodalitiesbymappingthemintoaunifiedrepresen-
tationspace. Subsequentworks(Wangetal.,2023;Luetal.,2024;Chenetal.,2024c;Youngetal.,
2024; Laurenc¸on et al., 2024; GLM et al., 2024; Yao et al., 2024; Anthropic, 2024; Wang et al.,
2024)furtherenhanceMLLMsbydesigningnovelmodulesformoresufficientmodalityalignment.
2.2 MLLMBENCHMARKS
TherapidadvancementofMLLMshasemphasizedthecriticalneedforcomprehensiveevaluation
frameworkswithintheresearchcommunity. Initialbenchmarksprimarilyfocusedonspecifictasks,
such as visual question answering (VQA) (Antol et al., 2015; Goyal et al., 2017; Kafle & Kanan,
2017;Singhetal.,2019;Hudson&Manning,2019)andimagecaptioning(Linetal.,2014;Agrawal
etal.,2019;Plummeretal.,2015). Whilethesebenchmarkshaveyieldedsignificantinsights,they
fallshortinprovidingaholisticassessmentofMLLMsacrossthebroaderspectrumofmultimodal
perception and reasoning capabilities. To address this limitation, recent studies have developed
more comprehensive evaluation approaches (Xu et al., 2023; Fu et al., 2023; Lu et al., 2022; Cai
et al., 2023; Zhang et al., 2023; He et al., 2024; Chen et al., 2024b). For instance, MMBench
(Liu et al., 2023c) and SEED (Li et al., 2023b;a) assess models’ capabilities through common-
sense questions, employing multiple-choice formats to evaluate various dimensions of ability. To
assessspecializedexpertise,MMMU(Yueetal.,2023)andCMMMU(Zhangetal.,2024b)utilize
contentderivedfromexamsandtextbooks,enhancingtheevaluationofdomain-specificknowledge.
Furthermore, Cambrian-1 (Tong et al., 2024) introduces a novel vision-centric benchmark (CV-
Bench)torepurposestandardvisiontasksformultimodalevaluation.
2.3 IMAGEIMPLICATIONUNDERSTANDING
Imageimplicationunderstandingrepresentsamorecomplexandchallengingtaskthanconventional
imageunderstanding. Thisadvancedcognitiveprocessnecessitatesmulti-hopreasoningabilityand
sophisticatedtheoryofmind(ToM),capabilitiesthatareintrinsictohumancognition(Desaietal.,
2022;Hesseletal.,2023;Yangetal.,2024;Zhongetal.,2024;Strachanetal.,2024;Streetetal.,
2024;Horvitzetal.,2024). II-Bench(Liuetal.,2024b)isthefirstbenchmarkspecificallydesigned
toevaluateMLLMsinbothimageunderstandingandreasoningthroughEnglishimageimplication.
3Preprint
生活Life 艺术Art 社会Society
Question:这张图片有什么隐喻？ Question:远处的小岛暗示了什么？ Question:这张图片有什么隐喻？
Option: Option: Option:
( 就A 盲)有 目的 的人 去不 追充 求分 某考 些虑 事自 物身 。的情况 ( 代A 表)远 了处 人的 们小 在岛 现被 实描 世绘 界为 中精 寻神 找寄 精托 神的 慰象 藉征， (A)坚持不懈是一种重要的美德。
( 的B) 想羽 法毛 ，熄 讽灭 刺蜡 了烛 不是 切一 实种 际天 的马 胡行 乱空
尝试。
和 ( 出B寄 一)远托 种处的 与的地 自小方 然岛。 和与 谐远 共处 处的 的棕 氛榈 围树 ，共 暗同 示营 着造 ( 来B 。)父母的行为习惯决定了孩子的未
(C)每个人都有追求时尚的权利。 人与自然之间的和谐关系。 (C)教育的失败是因为家长没有起到
(D)羽毛熄灭蜡烛是一种天马行空的想法，虽然失败了，但这种 (C)远处的小岛象征着希望和目标，虽然 足够的监督作用。
距离遥远，但依旧可以到达。
创新值得赞扬。 (D)远处的小岛上有着特定的文化景观或历史遗迹，象征着特 (D)钢琴的学习应该从小做起并坚持下来，这才能够走向成功。
(E)图中人物多次用羽毛熄灭蜡烛，赞扬了坚持不懈、百折不挠 定的文化背景或历史时期，提醒人们关注和尊重历史与文化的 (E)有的家长把教育失败的原因归咎于孩子，却忽略了自身的原
的 (F)精 用神 羽。 毛熄灭蜡烛这种不合理的行为，讽刺了有的人做事不考 重 ( 索E)要 方远性 向处。 ，的 鼓小 励岛 人作 们为 勇远 敢方 地的 去地 探标 索， 未象 知征 。着未知的领域或新的探 因 (F)。 如果父母不以身作则成为榜样，那么将来孩子的教育一定失
虑周到，盲目的尝试。 (F)远处的小岛象征着个人内心深处的平静之地，是人们在面对 败。
外界压力和挑战时寻求内心平静和恢复的地方。
Image Type:多格漫画(Multi-panel Comic) Image Type:插画(Illustration) Image Type:单格漫画(Single-panel Comic)
Rhetoric:隐喻 Rhetoric:象征 Rhetoric:对比
Emotion:消极 Emotion: 积极 Emotion:消极
Difficulty Level: 简单 Difficulty Level:简单 Difficulty Level:简单
中华传统文化Chinese Traditional Culture 环境Environment 政治Politics
Question:这张图片有什么隐喻？ Question:这张图片有什么隐喻？ Question:这张图片有什么隐喻？
Option: Option: Option:
(A)象征着自然界的生物受到人类 (A)个体在面对群体或更高权威时，所面临
(A)萧瑟的冬景暗示了人物对于 活动的严重影响，甚至面临灭绝 的道德困境和选择。
春天到来、万物复苏的渴望。 的威胁。 (B)天使和士兵形象之间的冲突暗示了信仰
(B)这张图片表现了工业技术的飞速
(B)孤身赏雪景暗示了图片中 发展，暗示着未来生活将更加便利和富裕。 与现实之间的张力，以及个体在面对残酷
(C)这张图片旨在宣传新型环保技术的应用，表现工业与自然和 现实时，如何坚持自己的信仰。
人物淡然、超脱世俗的心境。
谐共处的美好愿景。 (C)图片象征了人类对宗教信仰的追求，表达了对精神世界的渴望。
(C)独自一人欣赏雪景暗示了人物内心的孤独和知己难求的悲伤。 (D)暗示了人们有能力通过改变行为模式、采用新技术、实施环 (D)图片可能讽刺了那些以战争干预其他国家或地区的行为，表
保政策等方式，来减轻对自然环境的破坏，实现可持续发展和
(D)抬头的动作暗示了人物的思考。 生态平衡的可能。 达了对和平的渴望与对战争后果的担忧。
(E)独身一人暗示了人物对于亲人和家乡的怀念。 (E)表达了人类对自然界的彻底征服，通过技术改变地表环境。 (E)个人的命运既受到外力的影响，也取决于个人的选择。
(F)表达了对环境污染和生态破坏的深刻忧虑，它提醒观者在追 (F)即使在和平时期，战争的威胁也可能随时存在；而即使在战争
(F)萧瑟的冬景暗示了人物内心的悲伤。 求工业发展的同时，不应忽视对自然环境的保护和珍惜。 中，人们也可能怀抱着对和平的渴望。
Image Type:绘画(Painting) Image Type:海报(Poster) Image Type:插画(Illustration)
Rhetoric:隐喻 Rhetoric:象征 Rhetoric:隐喻、对比
Emotion:积极 Emotion:消极 Emotion:消极
Difficulty Level:困难 Difficulty Level:中等 Difficulty Level:困难
Figure3: CII-Benchexamplessampledfromeachdomain. TheEnglishversioninAppendixB.
3 THE CII-BENCH
3.1 OVERVIEWOFCII-BENCH
WepresenttheChineseImageImplicationUnderstandingBenchmark(CII-Bench),anovelbench-
mark designed to assess the perceptual, reasoning, and comprehension abilities of MLLMs in the
context of Chinese imagery. This benchmark includes a diverse range of visual content such as
traditional Chinese traditional artworks, comics, posters, and Chinese Internet memes, all rich in
visual information and cultural significance. The main goal of CII-Bench is to evaluate if current
MLLMscanleveragetheirunderstandingandknowledgeofChineseculturetoaccuratelyinterpret
thedeeperimplicationsandabstractinformationwithintheseimages.
CII-Benchcomprises698imagesacrossvariouscategories,withdetailedclassificationanddomain
statisticsprovidedinAppendixA.Theseimagesaremanuallycollectedandannotatedby30under-
graduatestudentsfromdifferentdisciplinesandinstitutions,sourcedfromseveralwell-knownimage
websites. Eachimageispairedwith1to3multiple-choicequestions,eachofferingsixoptionswith
only one correct answer. One fixed question asks, “What is the implication in this image?” Ad-
ditionalquestionsforthesameimageprobedifferentlevelsofunderstanding, suchasoverarching
interpretationandnuanceddetails.Thebenchmarkincludes800multiple-choicequestions,with765
forthetestsetand35fordevelopingandvalidatingfew-shottasks. Figure3providesrepresentative
examplesfromCII-Bench.
3.2 DATACURATIONPROCESS
3.2.1 DATACOLLECTION
Wecollect17,695rawimagesfromvariousrenownedillustrationwebsites, ensuringasufficiently
extensiverawdataset. Ourcollectorsarewellinstructedtoadheretocopyrightandlicenseregula-
tions,avoidingdatafromsitesprohibitingcopyandredistribution. Fordetailedinformationonthe
specificwebsitesfromwhichwecollectimages,pleaserefertoAppendixC.
4Preprint
3.2.2 DATAFILTRATION
Aftercollectingtherawimages,wemeticulouslydesignathree-stagedatafilteringprocess: Inthe
firststage,wefocusonimagededuplication. Weutilizeimagesimilarityalgorithmsforpixel-level
comparisontoeliminateduplicatesandpreservedatasetuniqueness;Inthesecondstage,weregulate
textprevalenceinimages. OpticalCharacterRecognition(OCR)technologyidentifiestextualareas
and disqualifies images exceeding set text-area ratios, maintaining a visual-centric dataset; In the
thirdstage,imagesundergorigorousvisualinspection,discardingthosewithoutmetaphoricaldepth
based on strict criteria. This process refines the dataset, rejecting over 95% of initial images and
securingunder1,000high-qualityones.
3.2.3 DATAANNOTATION
Theannotationprocessforthebenchmarkwasmeticulouslydesignedthroughseveralstepstoensure
rigorandprecisionasfollowing. ThedetailedannotationprotocolcanbefoundinAppendixC.
Preparation and Consistency Check: Before formal annotation, annotators first acquaint them-
selves with standard templates and guidelines. A pre-annotation round on a shared image batch
ensuresuniformstandardunderstanding,withdiscrepanciesresolvedthroughdiscussion.
MultipleRoundsofAnnotationandCross-Validation: Toreducebias, eachimagereceivesan-
notations from two different annotators. Cross-validation follows, with a third-party review for
significantdiscrepancies,guaranteeingaccuracy.
RefinementofAnnotationContent: Annotatorsannotateeachimage’sdifficulty,type,emotional
label,domain,andrhetoricaldevicesbasedonspecificcriteria,ensuringconsistencyandcompara-
bility. Theyalsocraft1to3refinedquestionsperimage,eachwithonecorrectansweramongfive
distractoroptions,includingthedefaultquestion,“Whatistheimplicationinthisimage?”
ContextAnalysis: Duringtheannotationprocess,annotatorsassesstheimage’sculturalandback-
groundsignificance,especiallyforimplicationsandrhetoricaldevices,consultingrelevantmaterials
foraccuracy.
Post-Annotation Review: Upon completion, annotations undergo a thorough quality review for
anyoversight,errors,orinconsistencies.Basedontheevaluationresults,feedbackisprovidedtothe
annotators,withre-annotationsasnecessarytomaintaindataquality.
3.3 DATASETSTATISTICS
CII-Benchcomprises 698images, each accompaniedby 1to 3multiple-choicequestions, totaling
800 questions. We randomly select 35 of these questions to construct a few-shot development set
andvalidationset.Onaverage,eachquestionisapproximately11characterslong,whileeachoption
hasanaveragelengthof28characters. Additionally,eachimageissupplementedwithamanually
writtendescriptionbytheannotators,whichprovidesadetailedexplanationoftheimage’scontent,
nuances,andthehumaninterpretationofitsdeepimplication.
CII-Bench covers images across six distinct domains: Life, Art, Society, Politics, Environment,
and Chinese Traditional Culture. The types of images are diverse, including Illustration, Meme,
Poster, Single-panel Comic, Multi-panel Comic, and Painting. Based on human understanding,
these images are categorized into three levels of difficulty: Easy, Medium, and Hard. Moreover,
theimagesareclassifiedaccordingtotheemotionalinformationtheyconvey: Positive,Neutral,or
Negative. Each image is also manually annotated with the rhetorical devices employed, including
Metaphor,Exaggeration,Symbolism,VisualDislocation,Antithesis,Analogy,Personification,and
Contrast. DetailedstatisticalinformationisprovidedinAppendixA.
4 EXPERIMENT
We conduct systematic experiments on both open-source and closed-source MLLMs using CII-
Bench. Foreachmodel,weemployeightdifferentconfigurations: None(zero-shot),1-shot,2-shot,
3-shot, CoT, Domain, Emotion, and Rhetoric. “None” represents the use of a standard prompt
withoutanyadditionalinformation. “Emotion”indicatestheinclusionofinformationrelatedtothe
5Preprint
emotionalpolarityoftheimage(e.g.,positive,negative)intheprompt,“Domain”involvesadding
information about the image’s domain (e.g., life, art), and “Rhetoric” refers to including details
abouttherhetoricaldevicesusedintheimage(e.g.,metaphor,contrast)intheprompt. Additionally,
toverifythenecessityofimagesinproblem-solving,weselectaportionofLLMstocompletetasks
withoutimageinput. ForconsistencyacrossallMLLMsandLLMs,weuseidenticalpromptsand
experimentsetup,withspecificdetailsavailableinAppendixD.
4.1 BASELINES
MLLMs. TocomprehensivelyevaluateCII-Bench,wecarefullyselectadiverserangeofMLLMs,
encompassing both open-source and closed-source models, with the aim of covering a wide spec-
trum of model characteristics and scales. These models span parameter sizes from 7B to 100B,
ensuringthatmodelsofvaryingcomplexityandcapabilityarethoroughlyassessed. Inselectingthe
models, we focus on the following key aspects: 1) model diversity, 2) Open-Source vs. Closed-
Sourcemodels,and3)modelparameterscalinglaw.
LLMs. To verify the critical role of images in answering questions, we specifically design an ex-
perimentinwhichsomeLLMsparticipateinthetaskwithoutanyimageinput. Thepurposeofthis
experiment is to assess whether these models can accurately understand the questions and make
correctchoicesintheabsenceofimageinformation,therebyfurtherdemonstratingtheimportance
ofimagesinthecomprehensionandproblem-solvingprocess. WeselectDeepSeek-67B,LLaMA-
3-8B,andQwen2-7bastheLLMsusedinthisexperiment.
Evaluation. We use accuracy as the primary evaluation metric, multi-choice format questions
and answer extraction method, which are widely used in previous benchmarks such as Helleswag
(Zellersetal.,2019),MMMU(Yueetal.,2023),CMMMU(Zhangetal.,2024b),MMLU(Lietal.,
2024b)andsoon. SinceCII-Benchisentirelycomposedofmultiple-choicequestions,theevalua-
tionprocessonlyrequiresextractingtheselectedoptionfromthemodel’sresponse,whichsimplifies
thecomplexityofruledesign. Itisimportanttonotethatwhenmodelsusechain-of-thought(CoT)
prompts,theresponsesmayincludeintermediatesteps. Therefore,theevaluationrulesmustbesuf-
ficientlyrobust, orthemodel’soutputmustfollowafixedformat. Iftheselectedoptioncannotbe
extractedfromthemodel’sresponse,themodelisconsideredtohaveansweredthequestionincor-
rectly. Forthedetailedstatisticsofthemodeloutput,pleaseseeAppendixF.Forreference,wealso
selectthreeChinesePhDstudentstoevaluatehumanperformanceonCII-Bench.
4.2 MAINRESULTS
In this section, we conduct a comprehensive comparison of the performance of various MLLMs,
LLMs,andhumansonCII-Bench. Detailedresultsacrossdifferentdomainsandemotionaldimen-
sions are presented in Table 1, while different image types, difficulty levels, and rhetoric can be
foundinAppendixE.Themainexperimentalresultsandfindingsaresummarizedasfollows:
4.2.1 NATURALCHALLENGESOFCII-BENCH
This benchmark presents a significant challenge for current models. Notably, despite GPT-4o be-
ing an advanced model, its accuracy is only 54.1%, indicating substantial room for improvement.
This reflects the rigorous and demanding nature of the benchmark. Further analysis reveals that
mostmodelsperformworstinthedomainofChinesetraditionalculture,highlightingasignificant
deficiencyintheirunderstandingofChineseculturalnuances. Itisalsonoteworthythathumanper-
formanceinthisdomainisnotideal,asquestionsrelatedtoChinesetraditionalcultureoftenrequire
deep cultural knowledge. The lack of this knowledge base poses difficulties for both models and
humanswhendealingwithChineseculturalcontent. Inaddition,text-onlymodelslikeDeepSeek-
67B-Chat only get 27.1% accuracy, which shows that most of the questions in CII-Bench require
imageinformationtobeansweredcorrectly, provingthatCII-Benchishighlydependentonvisual
content(Chenetal.,2024a).
4.2.2 GAPBETWEENHUMANSANDMLLMS
The results indicate a significant gap between human performance and multimodal large models
(MLLMs) on CII-Bench. Human participants achieved an average accuracy of 78.2%, with the
6Preprint
Model Overall Life Art Society Politics Env. CTC Positive Negative Neutral
(800) (216) (123) (157) (21) (51) (130) (220) (247) (231)
Open-sourceModels
Qwen-VL-Chat 34.3 27.9 34.7 32.5 45.8 55.2 36.5 34.0 35.1 33.6
idefics2-8b 36.3 25.0 46.3 38.1 41.7 56.9 32.9 32.8 39.1 36.4
MiniCPM-Llama3-2.5 40.4 36.3 45.6 37.1 50.0 51.7 40.2 43.2 37.0 41.3
CogVLM2-Llama3-Chinese-Chat 43.4 37.1 48.3 42.3 54.2 63.8 40.2 40.3 45.7 43.8
MiniCPM-v2.6 45.0 37.5 47.6 49.5 58.3 55.2 42.3 45.6 44.6 44.9
LLaVA-1.6-34B 46.0 40.8 55.1 42.8 45.8 62.1 43.1 44.4 48.2 45.2
LLaVA-1.6-72B 48.0 43.8 48.3 49.5 70.8 60.3 43.8 41.5 52.5 49.2
Qwen2-VL-7B 49.6 42.5 51.7 54.1 62.5 65.5 44.5 50.2 47.5 51.2
GLM-4V-9b 50.3 46.7 48.3 53.6 54.2 62.1 48.2 51.9 52.9 46.3
InternVL2-Llama3-76B 52.9 50.8 53.7 51.0 58.3 67.2 51.1 54.8 51.8 52.3
InternVL2-8B 53.1 49.2 53.1 55.7 62.5 63.8 50.4 50.6 53.3 55.1
InternVL2-40B 57.9 55.8 55.1 61.9 62.5 70.7 52.6 54.4 58.0 60.8
Qwen2-VL-72B 64.4 61.7 61.2 68.0 79.2 75.9 59.9 62.7 63.8 66.4
Closed-sourceModels
GPT-4o 54.1 54.1 55.8 52.1 50.0 63.8 51.8 51.9 56.2 54.1
Claude-3.5-Sonnet 54.1 52.1 61.9 52.6 62.5 46.6 53.3 52.7 56.5 53.0
Qwen-VL-MAX 56.9 53.3 59.2 58.8 62.5 67.2 52.6 53.9 58.3 58.0
Gemini-1.5Pro 60.1 60.0 63.3 62.4 70.8 62.1 51.1 54.8 65.6 59.4
GLM-4V 60.9 55.0 59.9 66.5 66.7 79.3 55.5 58.5 64.5 59.4
Text-OnlyModels
Llama-3-8B-Instruct 21.7 22.2 26.9 18.6 25.0 27.8 20.4 21.2 24.4 19.5
DeepSeek-67B-Chat 27.1 26.6 32.7 30.9 20.0 35.2 18.2 25.7 22.2 33.2
Qwen2-7B-Instruct 32.5 33.2 34.6 30.9 35.0 40.7 28.5 33.6 30.4 33.6
Humans
Humanavg 78.2 81.0 67.7 82.7 87.7 84.0 65.9 77.9 75.2 81.6
Humanbest 81.0 83.2 73.6 87.2 89.5 86.0 66.7 78.2 78.8 83.3
Table1:OverallresultsofdifferentMLLMs,LLMsandhumansondifferentdomainsandemotions.
Thebest-performingmodelineachcategoryisin-bold,andthesecondbestisunderlined.
highestaccuracyreaching81.0%. Incontrast,thebest-performingclosed-sourcemodel,GLM-4V,
achievedanaccuracyof60.9%,whilethetopopen-sourcemodel,Qwen2-VL-72B,scored64.4%.
These findings highlight the substantial disparity between human abilities and even the most ad-
vancedmodelsinunderstandingimageimplications. Thehighestaccuracyachievedbythemodels
is considerably lower than the average human score, indicating that multimodal large models still
facesignificantchallengesinthisdomain.
4.2.3 MODELPERFORMANCEACROSSDIFFERENTDOMAINSANDEMOTIONS
Intermsofdomainperformance, ourresultsinTable1indicatethatthemodelsgenerallyperform
betterintheEnvironmentandPoliticsdomains,achievinghigheraccuracy.Conversely,theaccuracy
islowerintheLifeandSocietydomains,provingthateverydaymetaphorsaregenerallymorediffi-
cultintheChinesecontext. ThelowestscorefortheChineseTraditionalCultureandArtdomains,
whichshowsthatwhilethemodelsgeneralizewellincommondomains,theystrugglewiththemore
abstractandlogicallydemandinginformationfoundinChineseTraditionalCultureandArt.
Fromanemotionalperspective, themodelstendtoexhibithigheraccuracywhentheimageimpli-
cationsconveynegativeemotions,whileaccuracyisthelowestforimageswithpositiveemotions.
Thisdiscrepancyhighlightsthatthemodels’preferencesdonotalignwiththoseofhumans,ashu-
mans are significantly more sensitive to positive implications. The performance of the model is
oppositetotheconclusionshowninII-Bench(Liuetal.,2024b), reflectingtheobviousdifference
inemotionalexpressionintheChineseandEnglishcontexts.
4.2.4 ANALYSISONDIFFERENTPROMPTSKILLS
Analysis of Chain-of-Thought (CoT). In Table 2, we evaluate the impact of Chain-of-Thought
(CoT) prompting on model performance. The results indicate that CoT does not significantly im-
provetheaccuracyofthemodels. Insomecases,particularlywithsmalleropen-sourcemodels,the
accuracy even declined when CoT was used. For example, MiniCPM-v2.6 scores 45.0% without
CoT,butthisdropsto38.9%withCoT;similarly, LLaVA-1.6-72Bscoresdecreasefrom48.0%to
45.3%.
7Preprint
Model None CoT Domain Emotion Rhetoric
Open-sourceModels
Qwen-VL-Chat 34.3 34.0 32.1 35.0 33.4
idefics2-8b 36.3 33.3 37.5 38.6 37.4
MiniCPM-Llama3-2.5 40.4 35.8 41.1 39.0 34.8
CogVLM2-Llama3-Chinese-Chat 43.4 42.6 43.5 44.0 43.4
MiniCPM-v2.6 45.0 38.9 44.4 45.4 45.4
LLaVA-1.6-34B 46.0 44.5 46.4 47.1 45.4
LLaVA-1.6-72B 48.0 45.3 47.3 48.6 45.4
Qwen2-VL-7B 49.6 50.0 51.0 50.8 49.3
GLM-4V-9b 50.3 49.1 49.9 51.1 49.5
InternVL2-Llama3-76B 52.9 52.6 54.1 52.8 53.5
InternVL2-8B 53.1 47.9 53.5 56.3 53.8
InternVL2-40B 57.9 57.6 57.1 60.0 57.9
Qwen2-VL-72B 64.4 62.1 66.0 64.3 63.0
Closed-sourceModels
GPT-4o 54.1 54.9 55.4 54.9 51.9
Claude-3.5-Sonnet 54.1 51.6 56.4 53.5 54.9
Qwen-VL-MAX 56.9 54.0 59.1 59.9 54.8
Gemini-1.5Pro 60.1 54.1 59.0 57.9 55.6
GLM-4V 60.9 48.8 60.4 60.6 58.8
Table2: OverallresultsofdifferentpromptsonCII-Bench. Thelabel(Emotion,Domain,Rhetoric)
means providing corresponding information for the images in the prompt. The best-performing
modelineachcategoryisin-bold,andthesecondbestisunderlined.
Upon analyzing the models’ responses, we find that those models showing a decrease in accuracy
withCoToftensufferfromoverinterpretation,wherequestionsthatwereinitiallyansweredcorrectly
are misinterpreted after CoT is applied. Additionally, for questions that were originally answered
incorrectly, CoT does not lead to significant improvements and sometimes even causes confusion,
suchasselectingmultipleoptions. However,formostmodels,theprobabilityoffailingtoextractan
answeroptionfromtheresponsedecreasesafterusingCoT,whichexplainswhysomemodelsshow
improvedaccuracywithCoT.
AnalysisofDifferentTypesandDomains. Toevaluatetheimpactofdifferentlabelinformation
on model accuracy, we conduct an ablation study by providing relevant label information (such
asemotion, domain, andrhetoric)intheprompts. TheresultsinTable2showthatemotionlabels
significantlyimprovemodelaccuracy,followedbydomainandrhetoriclabels,bothofwhichexhibit
similareffectiveness.
Thisresultalignswithhumanintuition. Theansweroptionstypicallyincludenegative,positive,and
neutral choices. When the model receives emotional information, it can eliminate some irrelevant
options, naturally leading to higher accuracy. In contrast, domain and rhetoric information gener-
ally do not effectively help the model eliminate options, resulting in more limited improvements.
Additionally,fromamodeltrainingperspective,modelstendtohaveamorematureunderstanding
of emotions, while specific nouns in rhetoric and domain labels are often custom-defined. During
pre-training, themodelmaynothaveencounteredalargenumberofdescriptionsforsuchspecific
nouns,makingtheselabelslesshelpfulinimprovingaccuracy.
Analysis of Few-shot Examples. The results in Table 3 indicate that few-shot examples do not
improve the models’ accuracy. Specifically, performance declines as the number of examples in-
creases. This decline can be attributed to the models’ inferior capabilities in handling multiple
imagescomparedtosingleimages,leadingtoadecreaseinaccuracywithahighernumberofshots.
Furthermore,asthenumberofshotsincreases,theinputlengthalsoextends,andthemodels’ability
toprocesslongtextsisinadequate,resultinginsuboptimalperformancewithlongcontexts.
4.3 EVALUATIONOFCHINESETRADITIONALCULTURE
The Chinese traditional culture category is a distinctive feature of the CII-Bench dataset, where
MLLMsconsistentlyscorethelowest.Therefore,weneedadeeperevaluationofthisfieldtoanalyze
8Preprint
Model None 1-shot 2-shot 3-shot
Qwen2-VL-7B 49.6 44.1 39.3 37.5
GPT-4o 54.1 51.8 49.5 49.1
Claude-3.5-Sonnet 54.1 55.4 55.3 55.4
InternVL2-40B 57.9 53.0 47.1 41.9
Gemini-1.5Pro 60.1 57.4 55.8 55.4
Table3: Few-shotresultsofdifferentmodelsontheCII-Bench.
the extent to which MLLM understands Chinese traditional culture. We chose to deeply analyze
MLLM’sunderstandingofChinesetraditionalculturebyevaluatingChinesetraditionalpaintings.
4.3.1 EVALUATIONMETRIC
Chinese traditional painting, a cornerstone of Chinese traditional culture, encompasses a rich
tapestry of styles and techniques developed over millennia. These paintings are typically cate-
gorized based on their subject matter (e.g., landscape paintings, flower-and-bird paintings, figure
paintings,andNewYearpaintings)ortheirstylisticandskill(e.g.,courtpaintings,meticulousbrush
paintings, freehandbrushpaintings, andcolor-and-inkpaintings). Eachcategoryembodiesunique
characteristicsthatreflectChina’sartisticevolutionandphilosophicalunderpinnings.
TocomprehensivelyassessMLLMs’understandingofChinesetraditionalpaintings, wedevelopa
multifacetedevaluationmetric. Thismetricisdesignedtoprobeboththesurface-levelinformation
readilyapparentintheartworkandthedeepercultureandhistorythatinformsitscreationandin-
terpretation. Ourevaluationmetricencompassesfivekeyperspectives: Surface-levelInformation,
AestheticCharacteristics,BrushandInkSkills,CultureandHistory,andDeepImplications. For
eachperspective,wegiveitsdetaileddescriptioninFigure4.
Evaluation Metric Evaluation Standard
[1point]:
Thedescriptionofthepictureisincompleteanddoesnotincludeanybackground
1. Surface-level Information:
information.Itonlymentionsthemostobviouselementsinthepicture,lacking
• Identification of primary entities within the painting
recognitionandunderstandingoftraditionalculturalelements.
• Analysis of color composition and application
• Recognition of intricate details and their significance
[2points]:
The description of the image is relatively complete, but the background
2.Aesthetic Characteristics:
informationislimited.Sometraditionalculturalelementscanbeidentified,but
• Comprehension of compositional techniques
theirmeaningisnotexplainedindepth.Thereisalackofinsightintotheaesthetic
• Recognition of the painting’s artistic school or
movement characteristicsorskillsoftheimage.
• Interpretation of emotional expression through visual
[3points]:
elements
Thedescriptionoftheimageiscomprehensiveandincludessomebackground
information.Thetraditionalculturalelementscanbeaccuratelyidentifiedand
3. Brush and Ink Skills:
• Identification of specific painting skills briefly explained. There is a preliminary understanding of the aesthetic
characteristicsorskillsofthepicture,butthereisalackofin-depthanalysis.Some
• Analysis of expressive methods employed by the artist
historicalorculturalbackgroundismentioned,butitisnotfullyexpanded.
4. Culture and History:
[4points]:
• Understanding of the painting’s historical background
• Interpretation of the artist’s intended message or Thedescriptionoftheimageisdetailedandcontainsrichbackgroundinformation.
Itisabletoexplainthesignificanceoftraditionalculturalelementsindepth.It
philosophy
providesarelativelyin-depthanalysisoftheaestheticcharacteristicsandskillsof
• Placement of the artwork within its appropriate
theimage.Itprovidesrelevanthistoricalandculturalbackgroundandattemptsto
historical period
exploretheimplicationoftheimage,buttheimplicationismisunderstood.
5. Deep Implications:
[5points]:
• Recognition of traditional cultural elements embedded
Thedescriptionoftheimageiscomprehensiveandaccurate,andthebackground
in the painting
informationisin-depthandcomprehensive.Itcannotonlyaccuratelyinterpret
• Interpretation of philosophical concepts, humanistic
traditionalculturalelements,butalsorevealtheirdeepmeaning.Ithasunique
spirit, or social values conveyed
• Demonstration of a deep understanding of Chinese insights into the aesthetic characteristics and skills of the image. It deeply
expoundsontherelevanthistoricalandculturalbackground,andcanseethrough
traditional culture as reflected in the artwork
thephilosophicalthoughts,humanisticspiritorsocialvaluescontainedinthe
image,showingadeepunderstandingofChinesetraditionalculture.
Figure4: EvaluationmetricandevaluationstandardofChinesetraditionalpainting.
4.3.2 LLM-BASEDCHINESETRADITIONALPAINTINGAUTOMATICEVALUATION
To evaluate Chinese traditional painting comprehension in MLLMs, we develop an LLM-based
evaluation standard based on evaluation metrics, as illustrated in Figure 4. Our experiment utilize
the CTC domain data from CII-Bench, comprising 130 Chinese traditional paintings. We employ
human-writtendescriptionsandimplicationinterpretationsasgroundtruth. WechooseGPT-4oto
9Preprint
generatedescriptionsfortheseimages,whicharesubsequentlyscoredusingGPT-4oandoureval-
uationstandard. PleaseseetheevaluationpromptinAppendixD.Tovalidatethemodel’sscoring
efficacy,weenlistthreePhDstudentswell-versedinChinesemetaphoricalimagerytoindependently
scorethe130paintings.
The model-human scoring consistency reached 98%, affirming the method’s validity for assessing
Chinesetraditionalpaintingcomprehension.Table4presentsthedetailedmodelscores. Analysisof
theseresults,inconjunctionwithourevaluationstandard,revealsinsightsacrossthreedimensions:
overallperformance,difficultylevels,andemotions. Theoverallscoreof2.71indicatesthatwhile
MLLMisabletoobservethesurface-levelinformationofpaintings,ithasalargegapwithhumans
indeeplyinterpretingthecomplexculturalelementscontainedinChinesetraditionalart. Interms
of difficulty evaluation, the model is consistent with human cognition, while in terms of emotion,
themodelhasahighernegativescore,indicatingthatthemodelcanidentifynegativeimplications
inpaintings,suchasusingthepasttosatirizethepresent,andnotappreciatingtalents.
Model Overall Easy Middle Difficult Positive Negative Neutral
GPT-4o 2.71 3.0 3.2 2.35 2.63 3.0 2.82
Table4: OverallresultofChinesetraditionalpainting.
4.4 ERRORANALYSIS
To conduct a comprehensive error analysis of GPT-4o’s performance (under CoT setting) on CII-
Bench, we randomly select a total of 100 erroneous samples from various domains, distributed
according to their proportions in the dataset. These samples are subjected to in-depth analysis by
expertannotators. AsillustratedinFigure5,GPT-4o’serrorscanbecategorizedintothefollowing
types: Information Neglect, Misunderstanding of Visual Information, Over-Inference, Superficial
Reasoning,andLackofCulturalBackgroundKnowledge. Fordetailedanalysisofcases,pleasesee
theAppendixG.
InformationNeglect(36%):
Complex images contain both visual and textual
elements. Sole reliance on visual information
makes accurate interpretation challenging due to
diversity in meaning. Incorporating textual infor-
mationclarifiestheauthor’semotionalintent,aid-
ingaccurateinterpretation.Unfortunately,GPT-4o
frequentlyoverlookskeyvisual(13%)andtextual
(23%) information. When directly asked about
theseelements,wefindthatGPT-4ocanoftenan-
swer correctly, indicating two main issues: 1) In-
sufficient image recognition abilities, and 2) Sig-
nificant shortcomings in multimodal fusion, lead- Figure5: GPT-4oerrorresponsesdistribution.
ingtounderutilizationofacquiredinformation.
Over-Inference(25%):
Duringanswerconstruction,distractorsareincludedatsurfaceanddeeplevels.GPT-4ooftenselects
more exaggerated, deep-level incorrect options, ignoring narrower but correct ones, especially in
Chinesememes. ThissuggeststhatGPT-4ohasapreferenceforselectingabstractoptions.
LackofCulturalBackgroundKnowledge(16%):
CII-Benchrequiresamodel’sdeepunderstandingofChinesetraditionalculture.Lackingknowledge
oftraditionalsymbols,historicalfigures,andclassicalallusions,GPT-4ostruggleswithinterpreting
deeper implications within images. Despite reasonable Chinese language handling, the model’s
culturaldeficiencyaffectsitsreasoningandperformance.
SuperficialReasoning(12%):
Understandingextendedmeaningswithinimagesiscrucial. However,GPT-4ooftenonlyfocuson
surface-level elements, neglecting the deep implications and deeper cultural connotations behind
10Preprint
them. Thissuperficialreasoninghindersthemodelfromfullygraspingprofoundmessagesthatthe
artistordesignerintendstoconvey.
MisunderstandingofVisualInformation(11%):
Accurateidentificationofvisualinformationisvital. WefindthatGPT-4osometimesmisidentifies
visualelementswithinimages,particularlywhendealingwithabstractimages. Theabstractnature
ofsuchimagesoftenstemsfromtheinclusionofexaggeratedimaginativeelements,sometimeseven
defying physical laws. Therefore, correctly identifying these abstract elements requires the model
tohaveadeepunderstandingoftheessenceofobjects, acapabilitythatcurrentmodelsclearlydo
notyetpossess.
5 DISCUSSION
5.1 INTERPRETABILITYANALYSISOFCHINESEIMAGEIMPLICATIONS
TheessenceofChineseimageimplicationsisdeeplyrootedindeepculturalheritageandcomplex
contextualassociations,whichenablesthemtoconveyprofoundmessagesthroughnuancedexpres-
sions. Forexample,intraditionalChineseartformssuchaslandscapeandNewYearpaintings,the
imagery transcends mere depiction of nature or daily occurrences. Instead, it embodies emotions,
philosophical insights, and societal norms through metaphorical and highly symbolic expressions.
These symbols, like the pine tree, plum blossom, and crane, are not superficial meaning but are
steepedincenturiesofculturaltradition,representingresilience,purity,andlongevity.
However,decipheringthesecomplexmessagescanbechallenging,particularlyforthoseunfamiliar
withtheculturalandhistoricalnarrativestiedtothesesymbols. ThiscontrastswithEnglishimage
implications, which often convey messages through more straightforward and explicit symbolism.
As a result, the interpretability of Chinese image implications depends to some extent on recon-
structingandresonatingwiththeculturalcontext,whichiswhatmakesthemunique: theirmeaning
isnotonlyvisualbutalsoculturallyresonant,bridgingacrosstimeandspace.
Moreover, the interpretability of Chinese image implications has new changed in the modern era.
Globalization and the surge of internet culture have intertwined foreign elements with traditional
Chinese culture, birthing new symbols and implications. This intersection introduces additional
layersofmeaning,complicatingtheinterpretationoftraditionalsymbols.
5.2 WHYCHOOSECHINESETRADITIONALPAINTINGSTOEVALUATECHINESE
TRADITIONALCULTURE?
TheimageryassociatedwithChinesetraditionalcultureoftenembodiescompleximplications,en-
compassingcustoms,historicalanecdotes,andlegendarytales,makingdirectevaluationparticularly
challenging. Chinesetraditionalpainting,intrinsicallyintertwinedwithChinesetraditionalculture,
offersaviableproxyforthisassessment. TheuniquevalueofChinesetraditionalpaintingliesinits
embodimentofChineseculturalconnotations,aestheticimplications,anddistinctiveartisticexpres-
sion. The core philosophical concepts of Confucianism, Taoism, and Buddhism, along with their
humanistic essence, have consistently permeated the entire trajectory of Chinese painting history.
Consequently, we have chosen to evaluate MLLMs’ comprehension of Chinese traditional culture
throughanin-depthanalysisoftheirunderstandingofChinesetraditionalpaintings.
6 CONCLUSION
The development of CII-Bench marks a significant step forward in evaluating the capabilities of
multimodallargemodels(MLLMs)andbringsusclosertoachievingexpertartificialgeneralintel-
ligence(AGI).Thisbenchmarkpromotesadeeperexplorationofthehigher-ordertheoryofmindin
MLLMs. ExperimentalresultsindicatethatcurrentMLLMsstillexhibitasignificantgapcompared
to humans in understanding the implications of images within a Chinese context. We found that
most MLLMs lack a deep knowledge base of Chinese traditional culture, leading to a superficial
understanding of this cultural content. Finally, the experiments showed that incorporating image
emotionhintsintopromptsoftenimprovesmodelperformance,suggestingthatmodelsstillstruggle
11Preprint
withemotionalunderstanding,whichinturnleadstomisinterpretationofimplications. Webelieve
thatCII-Benchwillinspiretheacademiccommunitytofurtherdevelopthenextgenerationofmul-
timodalfoundationalmodelsthatmovetowardexpertAGI.
LIMITATIONS
Weacknowledgeseverallimitationsinourstudy. AlthoughCII-Benchiscomprehensive,subjective
elements can result in varying interpretations, impacting result consistency. In addition, in order
to ensure high quality and practicability, our benchmark is not particularly large. The evaluation
metricsmaynotfullycapturetheadvancedunderstandingandreasoningcapabilitiesofAIsystems.
Theselimitationsunderscorethenecessityforcontinuousrefinementandexpansionofourbench-
marks. Future work will focus on developing and incorporating more stringent and objective test
setstoenhancethereliabilityandvalidityofourbenchmark.
ETHICS STATEMENT
In developing CII-Bench, we strictly adhere to ethical guidelines and legal regulations, ensuring
fairness, transparency, inclusivity and respect for all stakeholders. We stress the importance of
safeguardingprivacyandintellectualpropertyrights,underscoringourcommitmenttoresponsible
andlawfuldatamanagement.Wehavetakenstepstoanonymizeanypersonaldatatoprotectprivacy
andandhavemadeeveryefforttominimizeharmfulorbiasedcontent. However,werecognizethat
biasescaninadvertentlyariseandsomeinformationmaybepotentiallyoffensive.Wearecommitted
to continuous monitoring and improvement to mitigate such biases. Furthermore, we encourage
usersofourdatasettoemployitresponsiblyandtoconsidertheethicalimplicationsoftheirwork,
particularlyinapplicationsthatmayimpactindividualsorcommunities.
REFERENCES
SharanAakanksha, MaartenJacob, AdamGaurav, ChungPaul, SebastianCharles, KensenParker,
JoshuaSasha,etal. Palm: Scalinglanguagemodelingwithpathways,2022.
HarshAgrawal,KaranDesai,YufeiWang,XinleiChen,RishabhJain,MarkJohnson,DhruvBatra,
DeviParikh,StefanLee,andPeterAnderson. Nocaps: Novelobjectcaptioningatscale. 2019.
Anthropic. Claude3.5sonnetmodelcardaddendum. 2024.
Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C. Lawrence
Zitnick,andDeviParikh. Vqa: Visualquestionanswering. 2015.
Rizhao Cai, Zirui Song, Dayan Guan, Zhenhao Chen, Xing Luo, Chenyu Yi, and Alex Kot.
Benchlmm: Benchmarking cross-style visual capability of large multimodal models. arXiv
preprintarXiv:2312.02896,2023.
Zheng Cai, Maosong Cao, Haojiong Chen, Kai Chen, Keyu Chen, Xin Chen, Xun Chen, Zehui
Chen,etal. Internlm2technicalreport,2024.
LinChen, JinsongLi, XiaoyiDong, PanZhang, YuhangZang, ZehuiChen, HaodongDuan, Jiaqi
Wang,YuQiao,DahuaLin,andFengZhao. Areweontherightwayforevaluatinglargevision-
languagemodels?,2024a.
LinChen, JinsongLi, XiaoyiDong, PanZhang, YuhangZang, etal. Areweontherightwayfor
evaluatinglargevision-languagemodels?,2024b.
Zhe Chen, Weiyun Wang, Hao Tian, Shenglong Ye, Zhangwei Gao, Erfei Cui, Wenwen Tong,
KongzhiHu,JiapengLuo,ZhengMa,etal. Howfararewetogpt-4v? closingthegaptocom-
mercialmultimodalmodelswithopen-sourcesuites. arXivpreprintarXiv:2404.16821,2024c.
Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng,
Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez, et al. Vicuna: An open-source chatbot
impressing gpt-4 with 90%* chatgpt quality. See https://vicuna. lmsys. org (accessed 14 April
2023),2023.
12Preprint
KR1442ChowdharyandKRChowdhary. Naturallanguageprocessing. Fundamentalsofartificial
intelligence,pp.603–649,2020.
PooravDesai,TanmoyChakraborty,andMdShadAkhtar.Niceperfume.howlongdidyoumarinate
init? multimodalsarcasmexplanation. AAAI,2022.
AlexeyDosovitskiy,LucasBeyer,AlexanderKolesnikov,DirkWeissenborn,XiaohuaZhai,Thomas
Unterthiner,etal. Animageisworth16x16words: Transformersforimagerecognitionatscale.
ICLR,2020.
ChaoyouFu,PeixianChen,YunhangShen,YuleiQin,MengdanZhang,XuLin,JinruiYang,Xiawu
Zheng, Ke Li, Xing Sun, et al. Mme: A comprehensive evaluation benchmark for multimodal
largelanguagemodels. arXivpreprintarXiv:2306.13394,2023.
TeamGLM,AohanZeng,BinXu,BowenWang,ChenhuiZhang,DaYin,etal. Chatglm: Afamily
oflargelanguagemodelsfromglm-130btoglm-4alltools,2024.
Yash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv Batra, and Devi Parikh. Making the v in
vqamatter: Elevatingtheroleofimageunderstandinginvisualquestionanswering. 2017.
Zheqi He, Xinya Wu, Pengfei Zhou, Richeng Xuan, Guang Liu, Xi Yang, Qiannan Zhu, and Hua
Huang. Cmmu: A benchmark for chinese multi-modal multi-type question understanding and
reasoning,2024.
JackHessel,AnaMarasovic,JenaD.Hwang,LillianLee,JeffDa,RowanZellers,RobertMankoff,
andYejinChoi. Doandroidslaughatelectricsheep? humor“understanding”benchmarksfrom
thenewyorkercaptioncontest. 2023.
ZacharyHorvitz,JingruChen,RahulAditya,HarshvardhanSrivastava,RobertWest,ZhouYu,and
KathleenMcKeown. Gettingseriousabouthumor: Craftinghumordatasetswithunfunnylarge
languagemodels. 2024.
DrewAHudsonandChristopherDManning. Gqa: Anewdatasetforreal-worldvisualreasoning
andcompositionalquestionanswering. 2019.
ChuanyangJin, YutongWu, JingCao, JiannanXiang, Yen-LingKuo, ZhitingHu, TomerUllman,
Antonio Torralba, Joshua Tenenbaum, and Tianmin Shu. MMToM-QA: Multimodal theory of
mindquestionanswering. 2024.
KushalKafleandChristopherKanan. Ananalysisofvisualquestionansweringalgorithms. 2017.
Hugo Laurenc¸on, Le´o Tronchon, Matthieu Cord, and Victor Sanh. What matters when building
vision-languagemodels? arXivpreprintarXiv:2405.02246,2024.
BoLi,YuanhanZhang,DongGuo,RenruiZhang,FengLi,etal. Llava-onevision: Easyvisualtask
transfer,2024a.
BohaoLi,YuyingGe,YixiaoGe,GuangzhiWang,RuiWang,RuimaoZhang,andYingShan.Seed-
bench-2: Benchmarking multimodal large language models. arXiv preprint arXiv:2311.17092,
2023a.
BohaoLi,RuiWang,GuangzhiWang,YuyingGe,YixiaoGe,andYingShan. Seed-bench: Bench-
marking multimodal llms with generative comprehension. arXiv preprint arXiv:2307.16125,
2023b.
Haonan Li, Yixuan Zhang, Fajri Koto, Yifei Yang, Hai Zhao, et al. Cmmlu: Measuring massive
multitasklanguageunderstandinginchinese,2024b.
Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. Blip-2: Bootstrapping language-
image pre-training with frozen image encoders and large language models. arXiv preprint
arXiv:2301.12597,2023c.
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr
Dolla´r,andCLawrenceZitnick. Microsoftcoco: Commonobjectsincontext. 2014.
13Preprint
HaotianLiu,ChunyuanLi,YuhengLi,andYongJaeLee.Improvedbaselineswithvisualinstruction
tuning. arXivpreprintarXiv:2310.03744,2023a.
HaotianLiu,ChunyuanLi,QingyangWu,andYongJaeLee. Visualinstructiontuning,2023b.
Haotian Liu, Chunyuan Li, Yuheng Li, Bo Li, Yuanhan Zhang, Sheng Shen, and Yong Jae Lee.
Llava-next: Improvedreasoning,ocr,andworldknowledge. https://llava-vl.github.
io/blog/2024-01-30-llava-next/,2024a.
Yuan Liu, Haodong Duan, Yuanhan Zhang, Bo Li, Songyang Zhang, Wangbo Zhao, Yike Yuan,
JiaqiWang,ConghuiHe,ZiweiLiu,etal. Mmbench: Isyourmulti-modalmodelanall-around
player? arXivpreprintarXiv:2307.06281,2023c.
ZiqiangLiu,FeitengFang,XiFeng,XinrunDu,ChenhaoZhang,etal. Ii-bench: Animageimpli-
cationunderstandingbenchmarkformultimodallargelanguagemodels,2024b.
Haoyu Lu, Wen Liu, Bo Zhang, Bingxuan Wang, Kai Dong, Bo Liu, Jingxiang Sun, Tongzheng
Ren,etal. Deepseek-vl: Towardsreal-worldvision-languageunderstanding,2024.
PanLu,SwaroopMishra,TonyXia,LiangQiu,Kai-WeiChang,Song-ChunZhu,OyvindTafjord,
PeterClark,andAshwinKalyan. Learntoexplain: Multimodalreasoningviathoughtchainsfor
sciencequestionanswering. 2022.
Zihan Luo, Xiran Song, Hong Huang, Jianxun Lian, Chenhao Zhang, Jinqi Jiang, and Xing Xie.
Graphinstruct: Empoweringlargelanguagemodelswithgraphunderstandingandreasoningca-
pability,2024.
OpenAI. Chatgpt. https://chat.openai.com/,2023a.
OpenAI. Gpt-4technicalreport. arXivpreprintarXiv:2303.08774,2023b.
BryanAPlummer,LiweiWang,ChrisMCervantes,JuanCCaicedo,JuliaHockenmaier,andSvet-
lanaLazebnik. Flickr30kentities: Collectingregion-to-phrasecorrespondencesforricherimage-
to-sentencemodels. 2015.
Amanpreet Singh, Vivek Natarjan, Meet Shah, Yu Jiang, Xinlei Chen, Devi Parikh, and Marcus
Rohrbach. Towardsvqamodelsthatcanread. 2019.
James WA Strachan, Dalila Albergo, Giulia Borghini, Oriana Pansardi, Eugenio Scaliti, Saurabh
Gupta, Krati Saxena, Alessandro Rufo, et al. Testing theory of mind in large language models
andhumans. NatureHumanBehaviour,2024.
WinnieStreet, JohnOliverSiy, GeoffKeeling, AdrienBaranes, BenjaminBarnett, MichaelMcK-
ibben, TatendaKanyere, AlisonLentz, RobinIMDunbar, etal. Llmsachieveadulthumanper-
formanceonhigher-ordertheoryofmindtasks. arXivpreprintarXiv:2405.18870,2024.
GeminiTeam. Gemini: Afamilyofhighlycapablemultimodalmodels,2024.
Shengbang Tong, Ellis Brown, Penghao Wu, Sanghyun Woo, et al. Cambrian-1: A fully open,
vision-centricexplorationofmultimodalllms,2024.
HugoTouvron,LouisMartin,KevinStone,PeterAlbert,AmjadAlmahairi,YasmineBabaei,Niko-
layBashlykov,SoumyaBatra,PrajjwalBhargava,ShrutiBhosale,etal. Llama2: Openfounda-
tionandfine-tunedchatmodels. arXivpreprintarXiv:2307.09288,2023.
PengWang, ShuaiBai, SinanTan, ShijieWang, ZhihaoFan, JinzeBai, KeqinChen, XuejingLiu,
Jialin Wang, Wenbin Ge, Yang Fan, Kai Dang, , et al. Qwen2-vl: Enhancing vision-language
model’sperceptionoftheworldatanyresolution. arXivpreprintarXiv:2409.12191,2024.
WeihanWang,QingsongLv,WenmengYu,WenyiHong,JiQi,YanWang,JunhuiJi,ZhuoyiYang,
Lei Zhao, Xixuan Song, et al. Cogvlm: Visual expert for pretrained language models. arXiv
preprintarXiv:2311.03079,2023.
Chung Won, Hou Le, Longpre Shayne, Zoph Barret, Tay Yi, Fedus William, Li Yunxuan, et al.
Scalinginstruction-finetunedlanguagemodels,2022.
14Preprint
Peng Xu, Wenqi Shao, Kaipeng Zhang, Peng Gao, Shuo Liu, Meng Lei, Fanqing Meng, Siyuan
Huang, Yu Qiao, and Ping Luo. Lvlm-ehub: A comprehensive evaluation benchmark for large
vision-languagemodels. arXivpreprintarXiv:2306.09265,2023.
Qingshu Xu. Comparing covid-19 metaphors in chinese and english social media with critical
metaphoranalysis. FrontiersinPsychology,2023.
YixinYang,ZhengLi,QingxiuDong,HemingXia,andZhifangSui. Canlargemultimodalmodels
uncoverdeepsemanticsbehindimages?,2024.
YuanYao, TianyuYu, AoZhang, ChongyiWang, JunboCui, HongjiZhu, TianchiCai, HaoyuLi,
WeilinZhao, ZhihuiHe, etal. Minicpm-v: Agpt-4vlevelmllmonyourphone. arXivpreprint
arXiv:2408.01800,2024.
Qinghao Ye, Haiyang Xu, Jiabo Ye, Ming Yan, Haowei Liu, Qi Qian, Ji Zhang, Fei Huang, and
Jingren Zhou. mplug-owl2: Revolutionizing multi-modal large language model with modality
collaboration. arXivpreprintarXiv:2311.04257,2023.
AlexYoung,BeiChen,ChaoLi,ChengenHuang,GeZhang,GuanweiZhang,HengLi,Jiangcheng
Zhu, Jianqun Chen, Jing Chang, et al. Yi: Open foundation models by 01. ai. arXiv preprint
arXiv:2403.04652,2024.
XiangYue,YuanshengNi,KaiZhang,TianyuZheng,RuoqiLiu,GeZhang,SamuelStevens,etal.
Mmmu: Amassivemulti-disciplinemultimodalunderstandingandreasoningbenchmarkforex-
pertagi. arXivpreprintarXiv:2311.16502,2023.
RowanZellers, AriHoltzman, YonatanBisk, Ali Farhadi, and YejinChoi. Hellaswag: Cana ma-
chinereallyfinishyoursentence?,2019.
Chenhao Zhang, Renhao Li, Minghuan Tan, Min Yang, Jingwei Zhu, Di Yang, Jiahao Zhao,
GuanchengYe, ChengmingLi, andXipingHu. CPsyCoun: Areport-basedmulti-turndialogue
reconstructionandevaluationframeworkforChinesepsychologicalcounseling. 2024a.
Ge Zhang, Xinrun Du, Bei Chen, Yiming Liang, Tongxu Luo, Tianyu Zheng, Kang Zhu, Yuyang
Cheng,etal.Cmmmu:Achinesemassivemulti-disciplinemultimodalunderstandingbenchmark,
2024b.
WenxuanZhang,SharifahMahaniAljunied,ChangGao,YewKenChia,andLidongBing.M3exam:
Amultilingual, multimodal, multilevelbenchmarkforexamininglargelanguagemodels. arXiv
preprintarXiv:2306.05179,2023.
ShanshanZhong,ZhongzhanHuang,ShanghuaGao,WushaoWen,LiangLin,MarinkaZitnik,and
PanZhou. Let’sthinkoutsidethebox: Exploringleap-of-thoughtinlargelanguagemodelswith
creativehumorgeneration,2024.
15Preprint
A STATISTICS OF CII-BENCH
Statistics Statistics
TotalQuestions 800 Life 216(30.95%)
TotalImages 698 Art 123(17.62%)
Dev:Validation:Test 15:20:765 Society 157(22.49%)
Easy:Medium:Hard 305:282:111 Environment 51(7.31%)
Politics 21(3.01%)
AverageQuestionLength 10.54
ChineseTraditionalCulture 130(18.62%)
AverageOptionLength 28.31
AverageExplanationLength 121.06 Positive 220(31.52%)
Neutral 247(35.39%)
Metaphor 562
Negative 231(33.09%)
Exaggerate 121
Symbolism 236 Illustration 178(25.50%)
VisualDislocation 42 Meme 145(20.77%)
Antithesis 13 Poster 87(12.46%)
Analogy 19 Multi-panelComic 34(4.87%)
Personification 73 Single-panelComic 143(20.49%)
Contrast 87 Painting 119(17.05%)
Table5: GeneralstatisticsofCII-Bench.
Figure6: CII-Benchspecificimagetypeanddomainstatistics.
16Preprint
B CII-BENCH EXAMPLES OF ENGLISH VERSION
Life Art Society
Question:Whatmetaphordoesthis Question: What does the distant island Question:Whatmetaphordoesthis
imagecontain? suggest? imagecontain?
O ( cA op n) t sSi io don m er: e in p ge to hp el ie r p ou wr nsu ce i rc ce ur mta si tn a t nh ci en sg .s blindly without fully O ( s sA p eep i) r k it T t i suo h oaen ll a : d s cui es s t ata e nn n dt a i n rs ecl fa e un , g d r ee i ps inr d e te s hep eni c t rit ene ad g l a was p o a l ra ls dcy .em wb ho el ro ef p eople O ( (A Bp )) t PPio ae rrn es: e nv tse ’r ban ehce a vi is o a rn a nim d p ho ar bt ia tn s t virtue.
( f u (B e Cna) r )t e hE Eaex vlr it e si i rtn s i y cg a o u n a ni n es i d h m h i r an a e sgg c i tkna hl a eec t sa i rv sn ig ed a h l tie t td e tew m oa i , p pt h s t usa r.a t si uri ez i fn ag sh ion. ( d h r (B Cei as lr) )at m a tT Tin o oh ht n n e ep y s d a h dwli i ims p sit tta bh atn r e net n t twei a s s it el su,a e lrc an ner nd ,e h , da s ut ut o e smg ysg g a me a e nt n sh bs t e oa i anr t ln m igw zd eo a i tt ss hh h p he aht orh ne m pe are eto u no ari af no l d u w s ao grl od a. l, d ( pCe at r)e e Tr nm h tsei n nfe oa tit lh pue rr oef vu o it f du ier ne d g uo c ef a nt th oioe ui n gr h ic sh dil ud er e tn o.
( a ( thD Elt e)h) co TE au hx ng et dhi n r l eeig t pu wf ei a a is i th tl heei dn d a g , a f t eta h t a eic ts m ha k en p rid tn sl pde rb aw o y if si t et hih n e t n ha po e f ev e sraa pst ot iih ro n ie n t r i on ii s f s t hc pa o e en m r p sim i em c vta e eug n rri ad en n aa t cb ot ei l v e e ae . x n ti did n e ga u; i sh w ( s t (hD Eyh em )) i i Tc T b mh hoh p, ele i oa z dd rl it itni sah s g tnto aa cau nn e tg t p o ih i a ss f r llf t aa pa i ncn ar dud y a ,l i ac nw aro g s a n c aay ut a t, l lt i t aei n us nns r dts a ist ml oi p l nb ael a rc ta kc oit f k t ii aga nc nri cn tdo hu ua r el nb et du d sle p ir soa. e tl r c a l t nha i ci nn s egd t ,o s h src ii ya sc mtp a oe l br s p y o eo la irr zni o eh d sdi s c, ut uro ne lr ktmi u nc ria oenl w. ds i ni nt e tg es r, p re ito op rl ie e so f s ( aDu s p ) the Pr isv ia i ins si o o t hn le e. a pr an ti hn g to s h suo cu cld e ss st .art at an early age and be persisted with,
r ( f be F e ls a i) ni tl T h di ee lh yrn e c s tu re a yn. ti r r te hia z is e no s g n stha .b ol se e a wc ht oo f a t cr ty win ig th t oo u e t x ct ain reg fu ui ls h co a n c sia dn ed rl ae t iw onit h a na d o u ( im nFr n d )k on iTn d ve o ew ih drw e n ud n d ai t. lr ie ,se c t ac ah t nn pio to l an il csos l e g af io n wcr da h e l s e x e y rp el me l po m b er oea olnt i pi zto ls e en . s , s c ee h en a kc l o l ceu anr la mgg e i s an . ng a d p p re l eao ccp oel ve o e t rfo y i nb wnr ha ev er ne pl ey faa e ccx ie np d glo e eer xe p t et wh rne it ah li n an ( c (E Fh )i) l IdS fr o pem an re , e w np ta h sr i dle e on nt ns e o gb t ll lea ecm at die n bgt yh t e eh xefa air mil u o pwr le en o a r nf e de s d p bu o ec cna ost i mbio ein l i r t oo y ln . e t mh oei dr e ls, their
pressure andchallenges. children’s education will inevitably fail.
Image Type:Multi-panel Comic Image Type: Illustration Image Type:Single-panel Comic
Rhetoric:Metaphor Rhetoric: Symbolism Rhetoric:Contrast
Emotion:Negative Emotion: Positive Emotion:Negative
Difficulty Level: Easy Difficulty Level: Easy Difficulty Level:Easy
Chinese Traditional Culture Environment Politics
Question:Whatmetaphordoesthis Question:Whatmetaphordoesthis Question:Whatmetaphordoesthis
imagecontain? imagecontain? imagecontain?
O (Ap ) t Tio hn e : desolate winter scene hints O (Ap )t Si yo mn b: olizes that creatures in the O (Ap ) t Tio hn e : individual faces a moral dilemma and
a a o ( a
t ( l ( to
hB
o C
Dt r f l r o
n o
wt )
)
)aih n
e u
v l aV
E
Tle gl ea
ir n
hi hnl tc de s h
j e
teoh uw
os
.i sfa n
a
g
y
swi r cgs gn
i
a
n a
tp os eg c ng.r ors t i
d
t t
l
fe n th s
d
hr lg
t
e’
l
oht
e
s yh a
o e
s sl n e
m
kn no
s
d io oc on
na
w h rwg t
gt
rh ai
t o
y n e
e
uar
w
g
r
pl lar a
os
e cf
o.
sn nvo t ufeedir gv r
f
s it
i
ga ’c mh
n
el ae
d p
ssp
i tl n
se s
i e g
e
ts h
r
i
e
att
hn
th
ee
ta h
rca edhn
ca
td
o hr a
ad
mc
re
t
aeet ca
er t’
tc
e
h
ra s
e
ik
sd
i i n in
a
nn
dt
e r
dt
r
ei
e
t
d
eu psd pe
irit.
n h o ( i (
t n ( e t
sm
e
eB C
D
una u f
ac c
svt tm ) )p )e
h
hu
u t
ix l aT T
Sn
nrr ra y it oa
eo
ouh hn ni il
.
nn n
l
li i
g a o
os saw mc g
g b
c
g
gt i i
e
lo i ett m m
i i
eo hi
se
er nv tnl aa a
s s
dtsd i
,
,t. g g et
t
ti
d
ahfe ea vhe u
n
er
r
es ar ae ot
p
d, le tu i
ou i
me ps pr
tc
pge v her ets mhev ie
eo
l ns e tn i
ep
co ie gfr
m
nhe lne f ep aa tal t pw y s r c
n ahh
lo i i
e
ngt ai n amlhm
m
devl rg e
m s
eobp
e e
t tr e
i
na h ctoea
nh
c ote
n
mp aett
b
lihie tt
o
ood
e
ih aed gour
h
br d e inae sb
ai c
e lp a vy c
c ai
ovt p to
io
lfye
o
ln
e
bil erc to v
x a, no
ap e
i lt v s
at hnm mi
t i
no ei
e
ree
i co
n
n t
ann
eni c
dgo tt
me p
oafao
o ptb
en nf
e st ne
d e sii
t d
ton w
iw
ap
ba
nd lr
m le
u eo epoes n .s
a
ofnt vp gr
l n
ii ie
i e
ca r
n
er o il wto
d e
ont u
u s
e m ,s tsc h.
t
meh
r
eynn
an
to kaa al inlo
t n
udg
gr
y a,
l
c h ( a f
m ( e (
oB a
C
Dh n xi tg i
a
ho d p)
)
)t ih h ei rnT
T
Ttc e
e r
h tae h hr
s
hae cn
s
e eia ew oind su
n
c
i u i
oh mt
t
gr mo nh hle e n d
a
aon
e
ta af i
g r
ilr e gl lrc i ii ei or t eet co y
b
y
n ss
stn , me.
y
gu b of a
l m
igr
i
ae rn neo g t yd
b gf
rn w e
s o
et ss h
f
ee
l gw
aot o ied s
itz
rw
h
n
o i
etw
rte
nh
s
ht inaeh si zeht n
,
e eh
f
t
u s e
ae i i tpma xn cnm
hi
peds rg
a
oa di ii rnr o stvg eo
u
eiwn ie
t
su ad
y
swibp lo u
t i’
e
h n
wf hao t l got sw hr
o
h c
a r ap
ue e a
lr u
de sn
s
da en
r .h
n
es w
sug
r ie
ie ratal
er ol i ff tt o i ore r es i l n. pig t eei ao r cvu ees n af nea i dit nh ,
( h (E Fo )) m TB e he la ein n bg d l . ea alo kn we ih ni tn et rs s a ct e t nh ee h c ih na tsr a ac tt te hr e’ cs h l ao rn acg ti en rg ’ fo s r i nfa nm eri l sy a da nn ed s s. ( E ( e a dE F c n ea o) ) vdr t l eE E h o c lx ’ gx oasp ip pr csr r e mae u e ls or es s f d fs nae e e t tcs s hs . e h t ed rtu h e u nm er c ao pa t tu in uocgi rnot h ay n , l’ t rc s e eee c nc mrho vnnm i i no rap ol dbol nioe g n mt uy ge t. e c v neo in ten v w wq iu r e ho re is ls n e t m n o poef ut n n rtta soa ut u l n i r np ee go g b l l il ey nu c dt ta i l uo tt he sn tr e ri a n p in ag rd l o t h tee c tion c ( t ( ehE Fo ve )n ) e i nEAc r e vo inr new n i n wn n a d i ancb i rv h ,o t i o i pu d mi et u c oeeat psh sl ’ . le o e f c s m po f e an a a ys te c e s eq i t,s iu l t lie h nn hef o c l tue lh des r n e oo ac nf te t w d oo fa b t hr wo. et a ih rr b dcy a e n se i x rb et ee fr e on v ra e pl r - ef po ar cr ec ese .es n a tn ; d an b dy
Image Type:Painting Image Type:Poster Image Type:Illustration
Rhetoric:Metaphor Rhetoric: Symbolism Rhetoric:Metaphor, Contrast
Emotion:Positive Emotion:Negative Emotion:Negative
Difficulty Level:Hard Difficulty Level:Medium Difficulty Level:Hard
Figure 7: CII-Bench examples sampled from each domain. The pictures include life, art, society,
Chinesetraditionalculture,environmentandpolitics. Understandingtheseimagesandcompleting
thecorrespondingquestionsrequireacertainlevelofcomprehension.
17Preprint
C DATA ANNOTATION PROTOCOL
This document outlines a comprehensive protocol for annotating a dataset consisting of questions
thatexplorethemetaphoricalimplicationsofimages.
C.1 DATACOLLECTION
Somewebsitesfromwhichwecollectdataareasfollows:
• https://fabiaoqing.com/biaoqing/lists/page.html
• https://www.sohu.com/a/282205200_439969
• https://www.sohu.com/a/300233985_616741
• https://www.zcool.com.cn/u/746800
• https://www.shencaitang.com/news/1940
• https://www.dpm.org.cn/collection/paints.html
• https://www.zuomeme.com/wangyou/all
C.2 GENERALGUIDELINES
GeneralPrinciples:
• Annotationsshouldbeaccurateandconsistent.
• Allquestions,optionsandexplanationsshouldbewritteninChinese.
• Anyimageswithoutmetaphoricalimplicationsshouldbediscarded.
SpecificInstructions:
• Each image needs to be categorized as one of the following image types: single-panel comic,
multi-panelcomic,poster,meme,illustrationorpainting.
• Eachimageneedstobecategorizedasoneofthefollowingdifficultylevelsfromahumanun-
derstandingperspective: easy,middle,orhard.
• Eachimageneedstobecategorizedasoneofthefollowingdomains: life,art,society,politics,
environmentorChinesetraditionalculture.
• Eachimageneedstobecategorizedasoneofthefollowingemotions: positive,neutralornega-
tive.
• Each image needs to be categorized as one or more of the following rhetoric: metaphor, exag-
gerate,symbolism,contrast,visualdislocation,antithesis,analogy,personificationorothers.
• Eachimageneedsahumanexplanationandimplicationdescription.
• Eachimageneeds1-3questionsaboutthefine-grainedmetaphoricalimplicationsoftheimage,
eachwithonecorrectanswerandfivedistractoroptions.
C.3 DATAQUALITYASSURANCE
Tofurtherensurethequalityandreliabilityofthedata,theannotateddatasetsweredouble-checked
and cross-validated. Each question was manually validated by at least five annotators. Any in-
consistenciesormisinterpretationsfoundwerethoroughlyexaminedandresolvedbyconsensusof
theannotationteam,thusimprovingthereliabilityofthedatasetwhileensuringconsistencyofthe
annotations. In total, we conducted five rounds of data quality checks to ensure data quality and
ultimatelyobtainCII-Bench.
18Preprint
C.4 ETHICALCONSIDERATIONS
CopyrightandLicensing. Itisessentialtostrictlyfollowallcopyrightandlicensingregulations.
Datafromsourcesthatdonotpermitcopyingorredistributionwillbeexplicitlyexcluded.
DataPrivacy. Adherencetoprivacylawsandethicalstandardsindatahandlingiscrucial. Annota-
torsmustavoidcollectingquestionsthatcontainanypersonalinformation.
19Preprint
D EXPERIMENT SETUP
In experiments, we set the model temperature as 0, and all experiments are conducted on Nvidia
A800GPUs. ThepromptsofdifferentsettingsareasfollowsFigure8toFigure11. Particularly,the
evaluationpromptofChinesetraditionalpaintingisFigure12.
Evaluation Prompt: Direct
请根据提供的图片尝试回答下面的单选题。直接回答正确选项，不要包
含额外的解释。请使用以下格式：“答案： ”，其中
$LETTER
是你认为正确答案的字母。
$LETTER
{question}
{options}
答案：
Figure8: Thepromptusedindirectoutputsetting.
Evaluation Prompt: Keywords
请根据提供的图片尝试回答下面的单选题。请使用以下格式：“答案：
”，其中 是你认为正确答案的字母。
$LETTER $LETTER
关键词：
{key_words}
{question}
{options}
答案：
Figure9: Thepromptusedinkeywordsetting.
Evaluation Prompt: CoT
请尝试根据提供的图片回答以下单选题。让我们逐一思考每个选项，逐
步分析。你回答的最后一行应该用以下格式：“答案： ”，
$LETTER
其中 是你认为正确答案的字母。
$LETTER
{question}
{options}
Figure10: ThepromptusedinCoTsetting.
20Preprint
Evaluation Prompt: Few-Shot
请根据提供的图片尝试回答下面的单选题。直接回答正确选项，不要包
含额外的解释。请使用以下格式：“答案： ”，其中
$LETTER
是你认为正确答案的字母。
$LETTER
{question 1}
{options 1}
答案：
{answer 1}
(one or two more examples)
请根据提供的图片尝试回答下面的单选题。直接回答正确选项，不要包
含额外的解释。请使用以下格式：“答案： ”，其中
$LETTER
是你认为正确答案的字母。
$LETTER
{question}
{options}
答案：
Figure11: ThepromptusedinFew-Shotsetting.
#Role
Youareanimpartialjudge,familiarwithChinesetraditionalcultureandtraditionalpaintings.
##Attention
YouareresponsibleforevaluatingthequalityofthedescriptionsprovidedbythemodelfortraditionalChinesepaintings.Yourevaluation
shouldrefertothehumananswerandscorebasedontheEvaluationStandard.
##EvaluationStandard
-[1point]:
Thedescriptionofthepictureisincompleteanddoesnotincludeanybackgroundinformation.Itonlymentionsthemostobviouselementsin
thepicture,lackingrecognitionandunderstandingoftraditionalculturalelements.
-[2points]:
Thedescriptionoftheimageisrelativelycomplete,butthebackgroundinformationislimited.Sometraditionalculturalelementscanbe
identified,buttheirmeaningisnotexplainedindepth.Thereisalackofinsightintotheaestheticcharacteristicsorskillsoftheimage.
-[3points]:
Thedescriptionoftheimageiscomprehensiveandincludessomebackgroundinformation.Thetraditionalculturalelementscanbeaccurately
identifiedandbrieflyexplained.Thereisapreliminaryunderstandingoftheaestheticcharacteristicsorskillsofthepicture,butthereisalack
ofin-depthanalysis.Somehistoricalorculturalbackgroundismentioned,butitisnotfullyexpanded.
-[4points]:
Thedescriptionoftheimageisdetailedandcontainsrichbackgroundinformation.Itisabletoexplainthesignificanceoftraditionalcultural
elementsindepth.Itprovidesarelativelyin-depthanalysisof theaestheticcharacteristicsand skillsofthe image.Itprovidesrelevant
historicalandculturalbackgroundandattemptstoexploretheimplicationoftheimage,buttheimplicationismisunderstood.
-[5points]:
Thedescriptionoftheimageiscomprehensiveandaccurate,andthebackgroundinformationisin-depthandcomprehensive.Itcannotonly
accuratelyinterprettraditionalculturalelements,butalsorevealtheirdeepmeaning.Ithasuniqueinsightsintotheaestheticcharacteristicsand
skillsoftheimage.Itdeeplyexpoundsontherelevanthistoricalandculturalbackground,andcanseethroughthephilosophicalthoughts,
humanisticspiritorsocialvaluescontainedintheimage,showingadeepunderstandingofChinesetraditionalculture.
##Constraints
-Avoidanypositionbiasesandbeasobjectiveaspossible
-Donotallowthelengthofthedescriptionstoinfluenceyourevaluation
##Workflow
Outputyourfinalverdictbystrictlyfollowingthisformat:"[ratings]".
Figure12: ThepromptofChinesetraditionalpaintingevaluation.
21Preprint
E RESULTS ON DIFFERENT TYPES, DIFFICULTIES AND RHETORIC
In this section, we report the performance of different MLLMs and humans on different types of
images,levelsofdifficulty,andrhetorictypes.
Model Overall Illus. Paint. Poster Single-C. Multi-C. Meme
Open-sourceModels
Qwen-VL-Chat 34.3 33.5 36.8 45.1 35.2 23.7 27.5
idefics2-8b 36.3 44.0 32.8 45.1 35.2 23.7 24.8
MiniCPM-Llama3-2.5 40.4 39.5 38.4 49.0 42.6 34.2 37.3
CogVLM2-Llama3-Chinese-Chat 43.4 45.0 39.2 52.9 45.5 23.7 39.2
MiniCPM-v2.6 45.0 44.0 40.8 53.9 51.1 36.8 39.2
LLaVA-1.6-34B 46.0 50.0 44.0 48.0 47.7 29.0 42.5
LLaVA-1.6-72B 48.0 50.9 44.0 43.1 56.8 39.5 43.1
Qwen2-VL-7B 49.6 47.7 43.2 0.8 58.0 31.6 46.4
GLM-4V-9b 50.3 46.8 47.2 55.9 59.7 42.1 47.1
InternVL2-Llama3-76B 52.9 48.2 50.4 59.8 62.5 39.5 49.7
InternVL2-8B 53.1 48.2 48.0 56.9 64.8 52.6 51.0
InternVL2-40B 57.9 53.7 51.2 56.9 68.2 50.0 59.5
Qwen2-VL-72B 64.4 61.5 59.2 68.6 70.5 47.4 67.3
Closed-sourceModels
GPT-4o 54.1 54.1 50.4 56.9 54.6 47.4 57.5
Claude-3.5-Sonnet 54.1 55.1 54.4 47.1 55.1 50.0 57.5
Qwen-VL-MAX 56.9 57.3 51.2 60.8 62.5 39.5 56.2
Gemini-1.5Pro 60.1 64.7 50.4 52.0 66.5 52.6 62.1
GLM-4V 60.9 59.6 54.4 67.7 70.5 44.7 57.5
Humans
Humanavg 78.2 71.5 65.6 75.2 79.8 74.5 83.6
Humanbest 81.0 76.9 66.1 78.6 81.7 78.4 85.0
Table6:OverallresultsofdifferentMLLMsondifferentimagetypes.Thebest-performingmodelin
eachcategoryisin-bold,andthesecondbestisunderlined. Forbrevity,Illus. referstoIllustration,
Paint. refers to Painting, Single-C. refers to Single-panel Comic, Multi-C. refers to Multi-panel
Comic.
Model Overall Easy Medium Hard
Open-sourceModels
Qwen-VL-Chat 34.3 36.3 33.5 30.3
idefics2-8b 36.3 35.4 39.3 30.3
MiniCPM-Llama3-2.5 40.4 43.1 39.3 35.3
CogVLM2-Llama3-Chinese-Chat 43.4 46.3 39.9 44.3
MiniCPM-v2.6 45.0 47.1 44.2 41.0
LLaVA-1.6-34B 46.0 44.9 47.0 46.7
LLaVA-1.6-72B 48.0 50.0 47.0 45.1
Qwen2-VL-7B 49.6 52.6 47.9 45.9
GLM-4V-9b 50.3 52.6 49.1 46.7
InternVL2-Llama3-76B 52.9 57.4 49.7 48.4
InternVL2-8B 53.1 57.7 49.4 50.0
InternVL2-40B 57.9 62.3 55.5 51.6
Qwen2-VL-72B 64.4 68.9 63.1 54.9
Closed-sourceModels
GPT-4o 54.1 56.0 54.9 46.7
Claude-3.5-Sonnet 54.1 55.1 52.4 55.7
Qwen-VL-MAX 56.9 57.4 56.7 55.7
Gemini-1.5Pro 60.1 61.1 61.3 54.1
GLM-4V 60.9 62.9 59.2 59.8
Humans
Humanavg 78.2 82.5 76.1 70.9
Humanbest 81.0 84.0 78.9 71.8
Table7:OverallresultsofdifferentMLLMsonvariousdifficultylevels.Thebest-performingmodel
ineachcategoryisin-bold,andthesecondbestisunderlined. Thenumbersinparenthesesindicate
thenumberofsamplesineachcategory.
22Preprint
Model Overall Meta. Exag. Symb. Contrast VisD. Pers. Anal. Anti.
Open-sourceModels
Qwen-VL-Chat 34.3 31.8 38.9 38.4 41.0 37.0 34.2 28.6 30.8
idefics2-8b 36.3 35.2 32.6 35.6 41.9 30.4 26.6 23.8 38.5
MiniCPM-Llama3-2.5 40.4 38.5 42.4 40.2 38.1 34.8 44.3 33.3 38.5
CogVLM2-Llama3-Chinese-Chat 43.4 42.2 46.5 42.7 44.8 50.0 44.3 52.4 38.5
MiniCPM-v2.6 45.0 41.7 48.6 43.4 41.0 45.7 45.6 38.1 53.9
LLaVA-1.6-34B 46.0 45.1 47.9 45.9 41.0 45.7 44.3 42.9 30.8
LLaVA-1.6-72B 48.0 46.1 54.2 48.0 49.5 47.8 46.8 47.6 38.5
Qwen2-VL-7B 49.6 47.6 52.1 48.4 49.5 56.5 51.9 47.6 53.9
GLM-4V-9b 50.3 48.7 56.3 51.3 52.4 50.0 50.6 57.1 30.8
InternVL2-Llama3-76B 52.9 51.5 59.7 51.3 51.4 52.2 55.7 52.4 46.2
InternVL2-8B 53.1 51.0 54.9 55.2 47.6 54.4 57.0 47.6 46.2
InternVL2-40B 57.9 55.8 63.2 56.6 55.2 54.4 69.6 71.4 46.2
Qwen2-VL-72B 64.4 62.5 70.1 65.8 63.8 73.9 67.1 66.7 53.9
Closed-sourceModels
GPT-4o 54.1 52.6 54.9 51.6 51.4 60.9 55.7 52.4 38.5
Claude-3.5-Sonnet 54.1 52.1 54.9 56.6 47.6 50.0 54.4 57.1 38.5
Qwen-VL-MAX 56.9 54.7 60.4 58.7 52.4 58.7 55.7 57.1 46.2
Gemini-1.5Pro 60.1 59.5 64.6 60.1 61.9 47.8 55.7 81.0 53.9
GLM-4V 60.9 60.2 65.3 63.4 57.1 65.2 60.8 66.7 46.2
Humans
Humanavg 78.2 76.0 82.8 74.1 70.4 73.9 72.9 90.0 52.8
Humanbest 81.0 77.0 85.2 76.5 75.7 75.6 74.7 95.0 66.7
Table8: OverallresultsofdifferentMLLMsandhumansondifferentrhetoric. Thebest-performing
model in each category is in-bold, and the second best is underlined. For brevity, Meta. refers to
Metaphor,Exag. referstoExaggerate,Symb. referstoSymbolism,VisD.referstoVisualDisloca-
tion,Anti. referstoAntithesis,Anal. referstoAnalogy,Pers. referstoPersonification
23Preprint
F ADDITIONAL DETAILS OF RESULTS
We do detailed statistics of the model output. The results are shown in Table 9 to 12. Miss is
mainlycausedbytwosituations,oneisthatthemodeldoesnotgiveananswer,andtheotheristhe
regexisnotmatched. TheMissrateofmostmodelsiscontrolledbelowanacceptableratio. Inthe
CoT setting,somemodelsdonotfollowinstructionswellanddonotprovidetheexpectedlettersas
answer,whichcannotbematchedandwillbeconsideredaMiss.
Mode Metric InternVL2-40B InternVL2-8B InternVL2-Llama3-76B MiniCPM-Llama3-2.5 MiniCPM-v2.6
Acc 57.6 47.9 52.6 35.8 39.3
CoT Error 0.0 0.0 0.0 0.0 0.0
Miss 0.0 0.0 0.0 8.1 0.0
Acc 57.1 53.5 54.1 41.1 44.4
Domain Error 0.0 0.0 0.0 0.0 0.0
Miss 0.0 0.0 0.0 5.9 0.0
Acc 60.0 56.3 52.8 39.0 45.4
Emotion Error 0.0 0.0 0.0 0.0 0.0
Miss 0.0 0.0 0.0 8.4 0.0
Acc 57.9 53.1 52.9 40.4 45.0
None Error 0.0 0.0 0.0 0.0 0.0
Miss 0.0 0.0 0.0 0.4 0.0
Acc 57.9 53.8 53.5 34.8 45.4
Rhetoric Error 0.0 0.0 0.0 0.0 0.0
Miss 0.0 0.0 0.0 10.4 0.0
Table9: Accuracy,ErrorandMissrateofdifferentmodelsunderdifferentsettings.(1/4)
Mode Metric Qwen-VL-Chat Qwen2-VL-72B Qwen2-VL-7B CogVLM2-Llama3-Chinese-Chat
Acc 34.0 62.1 50.0 43.0
CoT Error 0.3 0.0 0.0 0.0
Miss 0.0 0.0 0.3 0.0
Acc 32.1 66.0 51.0 43.5
Domain Error 0.3 0.0 0.0 0.0
Miss 0.1 0.0 0.0 0.0
Acc 35.0 64.3 50.8 44.0
Emotion Error 0.1 0.0 0.0 0.0
Miss 0.5 0.0 0.0 0.0
Acc 34.3 64.4 49.6 43.4
None Error 0.5 0.0 0.0 0.0
Miss 0.4 0.0 0.0 0.0
Acc 33.4 63.0 49.3 43.4
Rhetoric Error 0.3 0.0 0.0 0.0
Miss 0.3 0.0 0.0 0.0
Table10: Accuracy,ErrorandMissrateofdifferentmodelsunderdifferentsettings.(2/4)
24Preprint
Mode Metric GLM-4V-9b LLaVA-1.6-72B LLaVA-1.6-34B idefics2-8b
Acc 49.1 45.3 44.5 33.3
CoT Error 0.0 0.0 0.0 0.0
Miss 0.0 0.0 0.0 0.0
Acc 49.9 47.3 46.4 37.5
Domain Error 0.0 0.0 0.0 0.0
Miss 0.0 0.0 0.0 0.0
Acc 51.1 48.6 47.1 38.6
Emotion Error 0.0 0.0 0.0 0.0
Miss 0.0 0.0 0.0 0.1
Acc 50.3 48.0 46.0 36.3
None Error 0.0 0.0 0.0 0.0
Miss 0.0 0.0 0.0 0.0
Acc 49.5 45.4 45.4 37.4
Rhetoric Error 0.0 0.0 0.0 0.0
Miss 0.0 0.0 0.0 0.0
Table11: Accuracy,ErrorandMissrateofdifferentmodelsunderdifferentsettings.(3/4)
Mode Metric Gemini-1.5Pro GLM-4V GPT-4o Claude-3-5-Sonnet Qwen-VL-MAX
Acc 54.1 49.9 54.9 51.6 54.8
CoT Error 0.3 3.4 0.0 1.8 1.1
Miss 1.8 2.4 0.1 0.0 0.0
Acc 59.0 60.4 55.4 56.4 59.1
Domain Error 0.3 1.6 0.0 2.5 1.5
Miss 1.4 0.0 0.0 0.0 0.1
Acc 58.0 60.6 54.9 53.5 59.9
Emotion Error 0.3 3.4 0.0 2.5 1.1
Miss 1.8 0.0 0.1 0.0 0.0
Acc 60.1 60.9 54.1 54.1 56.9
None Error 0.3 0.0 0.0 3.3 1.9
Miss 0.1 0.0 0.0 0.9 0.0
Acc 55.6 58.8 51.9 54.9 54.8
Rhetoric Error 0.3 2.1 0.0 1.9 0.9
Miss 0.9 0.0 0.1 0.0 0.0
Table12: Accuracy,ErrorandMissrateofdifferentmodelsunderdifferentsettings.(4/4)
25G CASE STUDY
TheappendixisoursampleanalysisofGPT-4o,includingananalysisofsixerrorexamples.
ListofCaseStudyFigures
1 Error1: TextualInformationNeglect . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
2 Error2: VisualInformationNeglect . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
3 Error3: Over-Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
4 Error4: LackofCulturalBackgroundKnowledge . . . . . . . . . . . . . . . . . . . . . 30
5 Error5: SuperficialReasoning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
6 Error6: MisunderstandingofVisualInformation . . . . . . . . . . . . . . . . . . . . . 32
26Preprint
Textual Information Neglect
Question: 这张图片有什么隐喻？<image1>
Option:
(A) 禁止饲养宠物
(B) 禁止拍摄鸟类
(C) 禁止飞行
(D) 禁止发出大的声音
(E) 禁止饲养珍惜动物
(F) 禁止传播色情内容
<image 1>
GPT-4o: 让我们逐一分析每个选项：
(A) 禁止饲养宠物 -该图片显示一个被禁止符号（红色圆圈和斜线）覆盖在一只鸟的图像上，并且无
标识任何宠物特定的信息。
(B) 禁止拍摄鸟类 -图片并没有显示任何与拍摄相关的符号或装置。
(C) 禁止飞行 -虽然鸟可以飞，但图片没有特别强调飞行的元素。
(D) 禁止发出大的声音 -图片没有显示与声音相关的符号。
(E) 禁止饲养珍惜动物 -该选项与禁止饲养宠物类似，但没有特别标识珍惜动物的信息。
(F) 禁止传播色情内容-这完全与图像无关。
综合来看，这张图片最直接的解释是禁止养鸟。
答案：A
Error Reason: 图片中展示了一只鸟，一个禁止符号，以及非常显眼的四个大字“禁止色禽”。这里
的色禽谐音了色情，也指图片中颜色花哨的鸟，因此图片想要传达的是禁止色情。而GPT-4o却因为
忽略了图片中“禁止色禽”，导致其对图片的深意理解错误。
GroundTruth:(F)禁止传播色情内容
FigureG1: AsampleerrorcaseofInformationNeglect.
BacktoListoffigures
27Preprint
Visual Information Neglect
Question: 这张图片有什么隐喻？<image1>
Option:
(A) 这张图片反映了家庭内部女性受到了男性的欺凌，呼吁社会关注家庭暴力和男女平等。
(B) 红色领带可以被视为外界对个人身份的期望或定义，而女性手中散落的文件则象征着她内在的真
实自我。
(C) 这张图片批判职场中女性受到权力的不平等的待遇。
(D) 这张图片展示了女性与巨大红色领带的互动，象征着个人在面对社会传统习俗时的挣扎。红色领
带代表传统的束缚，而女性散落的文件则表现出她试图突破这些束缚的努力。
(E) 这张图片批判了职场中男性表现出的虚伪，因为蛇往往象征着虚伪。
(F) 在这张图片中，一个身穿黑白衣服的女性站在巨大的红色领带前，领带如同一条巨蛇，暗示着人
类与未知力量的斗争。
<image 1>
GPT-4o:为了逐一分析每个选项：
(A) 这张图片反映了家庭内部女性受到男性的欺凌，呼吁社会关注家庭暴力和男女平等。
-这个选项略显偏颇，因为图片似乎并没有直接传达家庭暴力或家庭内部性别不平等的具体细节。
(B) 红色领带可以被视为外界对个人身份的期望或定义，而女性手中散落的文件则象征着她内在的真
实自我。
-确实可能与图片的一部分思想契合，即红色领带作为一种外界期望的象征，而散落的文件可能暗示
女性内心的挣扎和真实自我。
(C) 这张图片批判职场中女性受到权力的不平等的待遇。
-虽然这确实可能是一部分涵义，但图片中的元素（红色领带、散落的文件）更多地暗示社会期望和
传统束缚的紧张关系。
(D) 这张图片展示了女性与巨大红色领带的互动，象征着个人在面对社会传统习俗时的挣扎。红色领
带代表传统的束缚，而女性散落的文件则表现出她试图突破这些束缚的努力。
-这个选项很切题，领带代表着传统和期望，而散落的文件体现了突破束缚的努力，符合图片的整体
氛围和隐喻。
(E) 这张图片批判了职场中男性表现出的虚伪，因为蛇往往象征着虚伪。
-把领带比作蛇或虚伪有些勉强，图片中的领带更多的是象征某种外界期望或传统束缚。
(F) 在这张图片中，一个身穿黑白衣服的女性站在巨大的红色领带前，领带如同一条巨蛇，暗示着人
类与未知力量的斗争。
-提到“巨蛇”和“未知力量”有些离题，更多的是在描绘传统束缚的隐喻。
答案：D
Error Reason: 图片中红色领带呈现出了蛇的形象，暗示了职场中女性受到来自男性的权利威压，批
判职场中女性受到权力的不平等的待遇。GPT-4o没有认出领带的形状，认为领带代表传统的束缚，
这显然不合理，散落的文件也并非代表着努力。总之，GPT-4o由于忽略了视觉信息，导致了对图片
的主题理解错误。
GroundTruth:(C)这张图片批判职场中女性受到权力的不平等的待遇。
FigureG2: AsampleerrorcaseofInformationNeglect.
BacktoListoffigures
28Preprint
Over-Inference
Question: 这张图片有什么隐喻？<image1>
Option:
(A) 这张图片表达了对纯真和好奇心的赞美。
(B) 这张图片表达了对艺术创作的热爱。
(C) 该作品反映了环境保护的主题，绿色的地毯代表自然，提醒我们要保护地球。
(D) 这张图片强调了环保的重要性。
(E) 图片中的情节暗示了一种教育方法，即通过体验学习来教授孩子纪律和规矩的重要性。
(F) 图画强调了年龄和经验之间的代沟，以及两代人之间沟通的挑战。
<image 1>
GPT-4o:让我们逐一分析每个选项：
(A) 这张图片表达了对纯真和好奇心的赞美。
这与图片内容没有直接的联系。图片演示了某些行为，但并没有特别强调纯真和好奇心。
(B) 这张图片表达了对艺术创作的热爱。
虽然图片中的小孩在绘画，但整体情节似乎更多围绕反应及处理孩子的行为，这也不太符合。
(C) 该作品反映了环境保护的主题，绿色的地毯代表自然，提醒我们要保护地球。
图片中的绿色地毯并未显著成为环保的象征，情节更聚焦在对孩子行为的反应上。
(D) 这张图片强调了环保的重要性。
同样，图片重点不在于环保，地毯色彩也非显著性的环保标志。
(E) 图片中的情节暗示了一种教育方法，即通过体验学习来教授孩子纪律和规矩的重要性。
通过图片中老人对孩子绘画的接收、模仿及重新影响这一过程，确实可以看出一种通过体验进行教育
的意图。
(F) 图画强调了年龄和经验之间的代沟，以及两代人之间沟通的挑战。
这图片没有过多出现沟通和代沟的明显象征，而是更专注于行为与反应教育。
答案：E
Error Reason: 图片是经典漫画《父与子》的一小节，这幅漫画主要描写了父亲与儿子之间的有趣互
动，充满乐趣。图片中儿子打翻了墨水弄脏了地毯，却巧妙地利用墨水作画掩盖瑕疵，甚至最终父亲
也参与作画，乐在其中。作者可能想要表达孩子的纯真、好奇，也可能想要表达错误也能通过努力不
断弥补。GPT-4o选择的选项E，提到了纪律和规矩，显然不符合主题，推理过度。
GroundTruth:(A)这张图片表达了对纯真和好奇心的赞美。
FigureG3: AsampleerrorcaseofOver-Inference.
BacktoListoffigures
29Preprint
Lack of Cultural Background Knowledge
Question: 这张图片有什么隐喻？<image1>
Option:
(A) 老人可能代表着即将放手的母亲，年轻的女性则是即将成为家庭一部分的新成员。中间的男性正
处在人生的重要转折点上，需要学会独立。
(B) 这张图片描绘了一个普通的购物场景。
(C) 这张图片展示了家庭外出旅游的场景。
(D) 老人手中的篮子象征着她对年轻一代的教导和支持；年轻女性的时尚装扮则代表了新思想的引入。
中间的男性则体现了作为桥梁的作用，连接着过去与未来。
(E) 这张图片形象展示了对婆媳之间关系的调侃，表面和平而实际很分裂。
(F) 这张图片生动地展现了婆媳之间的和谐共处与相互支持的主题。画面中的三人手牵手，象征着家
庭成员间的团结与和睦。
<image 1>
GPT-4o:让我们逐一思考每个选项。
(A) 老人可能代表着即将放手的母亲，年轻的女性则是即将成为家庭一部分的新成员。中间的男性正
处在人生的重要转折点上，需要学会独立。
-梳理选项中的描述，老人可能代表一代人，年轻女性代表新一代，男性则是连接两代人的桥梁，中
间的男性正处于转折点，这与图片中的人物关系和手牵手的方式似乎匹配。
(B) 这张图片描绘了一个普通的购物场景。
-从图片来看，没有明显的购物元素。
(C) 这张图片展示了家庭外出旅游的场景。
-图片中没有明示旅游的细节或装饰，没有明显的展现旅游场景。
(D) 老人手中的篮子象征着她对年轻一代的教导和支持；年轻女性的时尚装扮则代表了新思想的引入。
中间的男性则体现了作为桥梁的作用，连接着过去与未来。
-分享了明确的分析和隐喻，老人手中的篮子象征支持，年轻女性代表新思想，桥梁则表示连接。这
与图像所传达的有较好的一致性。
(E) 这张图片形象展示了对婆媳之间关系的调侃，表面和平而实际很分裂。
-图片没有表现出明显的分裂和矛盾。
(F) 这张图片生动地展现了婆媳之间的和谐共处与相互支持的主题。画面中的三人手牵手，象征着家
庭成员间的团结与和睦。
-表述与图像中的人物关系较为吻合，表达了团结与和睦。
根据以上分析，更合适的选项为 (D)，较为全面地解释了图片中的隐喻。
答案：D
Error Reason: 图片中展示了3个人物手拉手，居中的人是丈夫，右边是妻子，左边则是婆婆。婆婆呈
现红色，妻子呈现绿色，而丈夫则是红绿相间。婆婆和妻子两种截然不同的颜色，暗示了她们之间的
冲突，讽刺了当代社会中婆媳之间的冲突。丈夫被冲突所波及，左右为难。GPT-4o缺乏对中国文化
的理解，因此无法选出正确的答案。
GroundTruth:(E)这张图片形象展示了对婆媳之间关系的调侃，表面和平而实际很分裂。
FigureG4: AsampleerrorcaseofLackofCulturalBackgroundKnowledge.
BacktoListoffigures
30Preprint
Superficial Reasoning
Question: 这张图片有什么隐喻？<image1>
Option:
(A) 两者共同拉起横幅，意味着传统与现代技术在对抗浪费方面的合作。人群象征着团结的力量。
(B) 在这张图片中，直升机和起重机代表着不同形式的力量汇聚在一起，共同为反对浪费的目标努力。
人群展示了大众对于这一事业的热情和支持。
(C) 图片反映了现代社会信息传播的困境：信息爆炸的同时，有效信息的获取和理解却变得越来越困
难。
(D) 直升机代表着政府的支持，而起重机则象征着社会基层的努力。横幅上的“反铺张浪费万人大签
名”表明人们希望通过大型活动来提高对节约资源意识的关注。
(E) 这张图片对讽刺了目前因为反对铺张浪费现象而产生的不合理行为。
(F) 图片赞扬了广大人民群众为了共同的目标而努力的合作精神。
<image 1>
GPT-4o:从这张图片中，可以看到直升机和起重机共同举起了一个标有“反铺张浪费万人大签名”的
横幅，同时下面有大量的人群集结。各个选项的分析如下：
(A) 两者共同拉起横幅，意味着传统与现代技术在对抗浪费方面的合作。人群象征着团结的力量。
-图片中直升机和起重机确实共同举起了横幅，人群也显示了团结的力量。这种描述贴近图片内容。
(B) 在这张图片中，直升机和起重机代表着不同形式的力量汇聚在一起，共同为反对浪费的目标努力。
人群展示了大众对于这一事业的热情和支持。
-这种说法也与图片内容相符，但没有明确现代与传统技术分别指代什么形式的力量。
(C) 图片反映了现代社会信息传播的困境：信息爆炸的同时，有效信息的获取和理解却变得越来越困
难。
-此选项与图片所展示的内容不符，主要不涉及信息传播的困境。
(D) 直升机代表着政府的支持，而起重机则象征着社会基层的努力。横幅上的“反铺张浪费万人大签
名”表明人们希望通过大型活动来提高对节约资源意识的关注。
-图片中的直升机和起重机虽然显示了支持，但没有明显证据表明直升机代表政府、起重机代表基层。
(E) 这张图片讽刺了目前因为反对铺张浪费现象而产生的不合理行为。
-从图片来看，没有表现出对不合理行为的讽刺倾向，主要是为了展示反对铺张浪费的行动。
(F) 图片赞扬了广大人民群众为了共同的目标而努力的合作精神。
-人群众多，似乎确实展示了为了共同目标而合作的精神。
答案分析：综合来看，选项 (A) 和 (B) 都比较贴合图片内容，但 (A) 更为具体地说明了技术与团结的
隐喻。因此选 (A)。
答案：A
Error Reason: 图片夸张的展示了反对浪费的万人签名活动。密密麻麻的人群、拉起签名纸的直升机
和起重机，的确体现了人民的团结精神，但是这并非作者想要传达的思想。如此浮夸、耗费资源和人
力的签名活动，正是一种浪费的体现，可笑的是活动本身却是反对浪费的。GPT-4o只意识到了最肤
浅的图片含义，没有充分结合图片信息，挖掘出深意。
GroundTruth:(E)这张图片对讽刺了目前因为反对铺张浪费现象而产生的不合理行为。
FigureG5: AsampleerrorcaseofSuperficialReasoning.
BacktoListoffigures
31Preprint
Misunderstanding of Visual Information
Question: 这张图片有什么隐喻？<image1>
Option:
(A) 爱情让人们失去了理性判断。
(B) 爱让我们变得更加聪明和睿智。
(C) 爱是一种需要持续投入的投资。
(D) 爱情会导致人们的孤立和疏远。
(E) 过于充盈的爱，会让我们失去独处的思考。
(F) 爱情会让人更加关注自己的内心世界。
<image 1>
GPT-4o:这幅图片展示了一对年轻人亲吻的场景，其中一个人的头脑中有一个操作杆的人，这个细节
表明隐喻的含义。逐个选项分析：
(A) 爱情让人们失去了理性判断。
-操作杆的人可能暗示爱情在操控一个人的理智，显示出理性被放在一个小角落来观察，可以一定程
度上支持这个观点。
(B) 爱让我们变得更加聪明和睿智。
-从图片来看，这种解释不太符合，因为图中的操控体现了某种控制，而不是增强智慧。
(C) 爱是一种需要持续投入的投资。
-没有直接暗示投入或投资的行为，所以这个选项不太符合。
(D) 爱情会导致人们的孤立和疏远。
-图片中两个人紧密接触，并没有表现出孤立和疏远的感觉。
(E) 过于充盈的爱，会让我们失去独处的思考。
-这也不符合图片中的暗示，图中没有表现出爱太多导致失去独处思考的情境。
(F) 爱情会让人更加关注自己的内心世界。
-操作杆的人是在脑中，可能象征着对内心世界的观察和控制，但更接近的是对于理性判断的控制，
而不是单纯的内心世界关注。
综上所述:
答案：(A)
Error Reason: 图片展示了一对男女接吻，奇怪的是男子的后脑有一个小阳台，阳台上有个小人正在
抽烟。抽烟往往暗示着思考，图片可能想要暗示充斥着的爱让我们没有独立思考的时间与空间。
GPT-4o认为图中男子后脑有一个操纵杆，这显然是错误的。正是由于错误的识别为操纵杆，才导致
它的分析全部错误。
GroundTruth:(E)过于充盈的爱，会让我们失去独处的思考。
FigureG6: AsampleerrorcaseofMisunderstandingofVisualInformation.
BacktoListoffigures
32