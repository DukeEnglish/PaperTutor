[
    {
        "title": "Fluid: Scaling Autoregressive Text-to-image Generative Models with Continuous Tokens",
        "authors": "Lijie FanTianhong LiSiyang QinYuanzhen LiChen SunMichael RubinsteinDeqing SunKaiming HeYonglong Tian",
        "links": "http://arxiv.org/abs/2410.13863v1",
        "entry_id": "http://arxiv.org/abs/2410.13863v1",
        "pdf_url": "http://arxiv.org/pdf/2410.13863v1",
        "summary": "Scaling up autoregressive models in vision has not proven as beneficial as in\nlarge language models. In this work, we investigate this scaling problem in the\ncontext of text-to-image generation, focusing on two critical factors: whether\nmodels use discrete or continuous tokens, and whether tokens are generated in a\nrandom or fixed raster order using BERT- or GPT-like transformer architectures.\nOur empirical results show that, while all models scale effectively in terms of\nvalidation loss, their evaluation performance -- measured by FID, GenEval\nscore, and visual quality -- follows different trends. Models based on\ncontinuous tokens achieve significantly better visual quality than those using\ndiscrete tokens. Furthermore, the generation order and attention mechanisms\nsignificantly affect the GenEval score: random-order models achieve notably\nbetter GenEval scores compared to raster-order models. Inspired by these\nfindings, we train Fluid, a random-order autoregressive model on continuous\ntokens. Fluid 10.5B model achieves a new state-of-the-art zero-shot FID of 6.16\non MS-COCO 30K, and 0.69 overall score on the GenEval benchmark. We hope our\nfindings and results will encourage future efforts to further bridge the\nscaling gap between vision and language models.",
        "updated": "2024-10-17 17:59:59 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.13863v1"
    },
    {
        "title": "How Numerical Precision Affects Mathematical Reasoning Capabilities of LLMs",
        "authors": "Guhao FengKai YangYuntian GuXinyue AiShengjie LuoJiacheng SunDi HeZhenguo LiLiwei Wang",
        "links": "http://arxiv.org/abs/2410.13857v1",
        "entry_id": "http://arxiv.org/abs/2410.13857v1",
        "pdf_url": "http://arxiv.org/pdf/2410.13857v1",
        "summary": "Despite the remarkable success of Transformer-based Large Language Models\n(LLMs) across various domains, understanding and enhancing their mathematical\ncapabilities remains a significant challenge. In this paper, we conduct a\nrigorous theoretical analysis of LLMs' mathematical abilities, with a specific\nfocus on their arithmetic performances. We identify numerical precision as a\nkey factor that influences their effectiveness in mathematical tasks. Our\nresults show that Transformers operating with low numerical precision fail to\naddress arithmetic tasks, such as iterated addition and integer multiplication,\nunless the model size grows super-polynomially with respect to the input\nlength. In contrast, Transformers with standard numerical precision can\nefficiently handle these tasks with significantly smaller model sizes. We\nfurther support our theoretical findings through empirical experiments that\nexplore the impact of varying numerical precision on arithmetic tasks,\nproviding valuable insights for improving the mathematical reasoning\ncapabilities of LLMs.",
        "updated": "2024-10-17 17:59:35 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.13857v1"
    },
    {
        "title": "Diffusing States and Matching Scores: A New Framework for Imitation Learning",
        "authors": "Runzhe WuYiding ChenGokul SwamyKianté BrantleyWen Sun",
        "links": "http://arxiv.org/abs/2410.13855v1",
        "entry_id": "http://arxiv.org/abs/2410.13855v1",
        "pdf_url": "http://arxiv.org/pdf/2410.13855v1",
        "summary": "Adversarial Imitation Learning is traditionally framed as a two-player\nzero-sum game between a learner and an adversarially chosen cost function, and\ncan therefore be thought of as the sequential generalization of a Generative\nAdversarial Network (GAN). A prominent example of this framework is Generative\nAdversarial Imitation Learning (GAIL). However, in recent years, diffusion\nmodels have emerged as a non-adversarial alternative to GANs that merely\nrequire training a score function via regression, yet produce generations of a\nhigher quality. In response, we investigate how to lift insights from diffusion\nmodeling to the sequential setting. We propose diffusing states and performing\nscore-matching along diffused states to measure the discrepancy between the\nexpert's and learner's states. Thus, our approach only requires training score\nfunctions to predict noises via standard regression, making it significantly\neasier and more stable to train than adversarial methods. Theoretically, we\nprove first- and second-order instance-dependent bounds with linear scaling in\nthe horizon, proving that our approach avoids the compounding errors that\nstymie offline approaches to imitation learning. Empirically, we show our\napproach outperforms GAN-style imitation learning baselines across various\ncontinuous control problems, including complex tasks like controlling humanoids\nto walk, sit, and crawl.",
        "updated": "2024-10-17 17:59:25 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.13855v1"
    },
    {
        "title": "AutoAL: Automated Active Learning with Differentiable Query Strategy Search",
        "authors": "Yifeng WangXueying ZhanSiyu Huang",
        "links": "http://arxiv.org/abs/2410.13853v1",
        "entry_id": "http://arxiv.org/abs/2410.13853v1",
        "pdf_url": "http://arxiv.org/pdf/2410.13853v1",
        "summary": "As deep learning continues to evolve, the need for data efficiency becomes\nincreasingly important. Considering labeling large datasets is both\ntime-consuming and expensive, active learning (AL) provides a promising\nsolution to this challenge by iteratively selecting the most informative\nsubsets of examples to train deep neural networks, thereby reducing the\nlabeling cost. However, the effectiveness of different AL algorithms can vary\nsignificantly across data scenarios, and determining which AL algorithm best\nfits a given task remains a challenging problem. This work presents the first\ndifferentiable AL strategy search method, named AutoAL, which is designed on\ntop of existing AL sampling strategies. AutoAL consists of two neural nets,\nnamed SearchNet and FitNet, which are optimized concurrently under a\ndifferentiable bi-level optimization framework. For any given task, SearchNet\nand FitNet are iteratively co-optimized using the labeled data, learning how\nwell a set of candidate AL algorithms perform on that task. With the optimal AL\nstrategies identified, SearchNet selects a small subset from the unlabeled pool\nfor querying their annotations, enabling efficient training of the task model.\nExperimental results demonstrate that AutoAL consistently achieves superior\naccuracy compared to all candidate AL algorithms and other selective AL\napproaches, showcasing its potential for adapting and integrating multiple\nexisting AL methods across diverse tasks and domains. Code will be available\nat: https://github.com/haizailache999/AutoAL.",
        "updated": "2024-10-17 17:59:09 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.13853v1"
    },
    {
        "title": "Retrospective Learning from Interactions",
        "authors": "Zizhao ChenMustafa Omer GulYiwei ChenGloria GengAnne WuYoav Artzi",
        "links": "http://arxiv.org/abs/2410.13852v1",
        "entry_id": "http://arxiv.org/abs/2410.13852v1",
        "pdf_url": "http://arxiv.org/pdf/2410.13852v1",
        "summary": "Multi-turn interactions between large language models (LLMs) and users\nnaturally include implicit feedback signals. If an LLM responds in an\nunexpected way to an instruction, the user is likely to signal it by rephrasing\nthe request, expressing frustration, or pivoting to an alternative task. Such\nsignals are task-independent and occupy a relatively constrained subspace of\nlanguage, allowing the LLM to identify them even if it fails on the actual\ntask. This creates an avenue for continually learning from interactions without\nadditional annotations. We introduce ReSpect, a method to learn from such\nsignals in past interactions via retrospection. We deploy ReSpect in a new\nmultimodal interaction scenario, where humans instruct an LLM to solve an\nabstract reasoning task with a combinatorial solution space. Through thousands\nof interactions with humans, we show how ReSpect gradually improves task\ncompletion rate from 31% to 82%, all without any external annotation.",
        "updated": "2024-10-17 17:59:03 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.13852v1"
    }
]