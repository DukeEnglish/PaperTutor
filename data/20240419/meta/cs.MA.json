[
    {
        "title": "Large Language Models for Synthetic Participatory Planning of Shared Automated Electric Mobility Systems",
        "authors": "Jiangbo Yu",
        "links": "http://arxiv.org/abs/2404.12317v1",
        "entry_id": "http://arxiv.org/abs/2404.12317v1",
        "pdf_url": "http://arxiv.org/pdf/2404.12317v1",
        "summary": "Unleashing the synergies of rapidly evolving mobility technologies in a\nmulti-stakeholder landscape presents unique challenges and opportunities for\naddressing urban transportation problems. This paper introduces a novel\nsynthetic participatory method, critically leveraging large language models\n(LLMs) to create digital avatars representing diverse stakeholders to plan\nshared automated electric mobility systems (SAEMS). These calibratable agents\ncollaboratively identify objectives, envision and evaluate SAEMS alternatives,\nand strategize implementation under risks and constraints. The results of a\nMontreal case study indicate that a structured and parameterized workflow\nprovides outputs with high controllability and comprehensiveness on an SAEMS\nplan than generated using a single LLM-enabled expert agent. Consequently, the\napproach provides a promising avenue for cost-efficiently improving the\ninclusivity and interpretability of multi-objective transportation planning,\nsuggesting a paradigm shift in how we envision and strategize for sustainable\nand equitable transportation systems.",
        "updated": "2024-04-18 16:51:23 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.12317v1"
    },
    {
        "title": "mABC: multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture",
        "authors": "Wei ZhangHongcheng GuoJian YangYi ZhangChaoran YanZhoujin TianHangyuan JiZhoujun LiTongliang LiTieqiao ZhengChao ChenYi LiangXu ShiLiangfan ZhengBo Zhang",
        "links": "http://arxiv.org/abs/2404.12135v1",
        "entry_id": "http://arxiv.org/abs/2404.12135v1",
        "pdf_url": "http://arxiv.org/pdf/2404.12135v1",
        "summary": "The escalating complexity of micro-services architecture in cloud-native\ntechnologies poses significant challenges for maintaining system stability and\nefficiency. To conduct root cause analysis (RCA) and resolution of alert\nevents, we propose a pioneering framework, multi-Agent Blockchain-inspired\nCollaboration for root cause analysis in micro-services architecture (mABC), to\nrevolutionize the AI for IT operations (AIOps) domain, where multiple agents\nbased on the powerful large language models (LLMs) perform blockchain-inspired\nvoting to reach a final agreement following a standardized process for\nprocessing tasks and queries provided by Agent Workflow. Specifically, seven\nspecialized agents derived from Agent Workflow each provide valuable insights\ntowards root cause analysis based on their expertise and the intrinsic software\nknowledge of LLMs collaborating within a decentralized chain. To avoid\npotential instability issues in LLMs and fully leverage the transparent and\negalitarian advantages inherent in a decentralized structure, mABC adopts a\ndecision-making process inspired by blockchain governance principles while\nconsidering the contribution index and expertise index of each agent.\nExperimental results on the public benchmark AIOps challenge dataset and our\ncreated train-ticket dataset demonstrate superior performance in accurately\nidentifying root causes and formulating effective solutions, compared to\nprevious strong baselines. The ablation study further highlights the\nsignificance of each component within mABC, with Agent Workflow, multi-agent,\nand blockchain-inspired voting being crucial for achieving optimal performance.\nmABC offers a comprehensive automated root cause analysis and resolution in\nmicro-services architecture and achieves a significant improvement in the AIOps\ndomain compared to existing baselines",
        "updated": "2024-04-18 12:35:39 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.12135v1"
    },
    {
        "title": "RAGAR, Your Falsehood RADAR: RAG-Augmented Reasoning for Political Fact-Checking using Multimodal Large Language Models",
        "authors": "M. Abdul KhaliqP. ChangM. MaB. PflugfelderF. Miletić",
        "links": "http://arxiv.org/abs/2404.12065v1",
        "entry_id": "http://arxiv.org/abs/2404.12065v1",
        "pdf_url": "http://arxiv.org/pdf/2404.12065v1",
        "summary": "The escalating challenge of misinformation, particularly in the context of\npolitical discourse, necessitates advanced solutions for fact-checking. We\nintroduce innovative approaches to enhance the reliability and efficiency of\nmultimodal fact-checking through the integration of Large Language Models\n(LLMs) with Retrieval-augmented Generation (RAG)- based advanced reasoning\ntechniques. This work proposes two novel methodologies, Chain of RAG (CoRAG)\nand Tree of RAG (ToRAG). The approaches are designed to handle multimodal\nclaims by reasoning the next questions that need to be answered based on\nprevious evidence. Our approaches improve the accuracy of veracity predictions\nand the generation of explanations over the traditional fact-checking approach\nof sub-question generation with chain of thought veracity prediction. By\nemploying multimodal LLMs adept at analyzing both text and images, this\nresearch advances the capability of automated systems in identifying and\ncountering misinformation.",
        "updated": "2024-04-18 10:25:42 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.12065v1"
    },
    {
        "title": "JointPPO: Diving Deeper into the Effectiveness of PPO in Multi-Agent Reinforcement Learning",
        "authors": "Chenxing LiuGuizhong Liu",
        "links": "http://arxiv.org/abs/2404.11831v1",
        "entry_id": "http://arxiv.org/abs/2404.11831v1",
        "pdf_url": "http://arxiv.org/pdf/2404.11831v1",
        "summary": "While Centralized Training with Decentralized Execution (CTDE) has become the\nprevailing paradigm in Multi-Agent Reinforcement Learning (MARL), it may not be\nsuitable for scenarios in which agents can fully communicate and share\nobservations with each other. Fully centralized methods, also know as\nCentralized Training with Centralized Execution (CTCE) methods, can fully\nutilize observations of all the agents by treating the entire system as a\nsingle agent. However, traditional CTCE methods suffer from scalability issues\ndue to the exponential growth of the joint action space. To address these\nchallenges, in this paper we propose JointPPO, a CTCE method that uses Proximal\nPolicy Optimization (PPO) to directly optimize the joint policy of the\nmulti-agent system. JointPPO decomposes the joint policy into conditional\nprobabilities, transforming the decision-making process into a sequence\ngeneration task. A Transformer-based joint policy network is constructed,\ntrained with a PPO loss tailored for the joint policy. JointPPO effectively\nhandles a large joint action space and extends PPO to multi-agent setting with\ntheoretical clarity and conciseness. Extensive experiments on the StarCraft\nMulti-Agent Challenge (SMAC) testbed demonstrate the superiority of JointPPO\nover the strong baselines. Ablation experiments and analyses are conducted to\nexplores the factors influencing JointPPO's performance.",
        "updated": "2024-04-18 01:27:02 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.11831v1"
    },
    {
        "title": "Distributed Fractional Bayesian Learning for Adaptive Optimization",
        "authors": "Yaqun YangJinlong LeiGuanghui WenYiguang Hong",
        "links": "http://arxiv.org/abs/2404.11354v1",
        "entry_id": "http://arxiv.org/abs/2404.11354v1",
        "pdf_url": "http://arxiv.org/pdf/2404.11354v1",
        "summary": "This paper considers a distributed adaptive optimization problem, where all\nagents only have access to their local cost functions with a common unknown\nparameter, whereas they mean to collaboratively estimate the true parameter and\nfind the optimal solution over a connected network. A general mathematical\nframework for such a problem has not been studied yet. We aim to provide\nvaluable insights for addressing parameter uncertainty in distributed\noptimization problems and simultaneously find the optimal solution. Thus, we\npropose a novel Prediction while Optimization scheme, which utilizes\ndistributed fractional Bayesian learning through weighted averaging on the\nlog-beliefs to update the beliefs of unknown parameters, and distributed\ngradient descent for renewing the estimation of the optimal solution. Then\nunder suitable assumptions, we prove that all agents' beliefs and decision\nvariables converge almost surely to the true parameter and the optimal solution\nunder the true parameter, respectively. We further establish a sublinear\nconvergence rate for the belief sequence. Finally, numerical experiments are\nimplemented to corroborate the theoretical analysis.",
        "updated": "2024-04-17 13:09:33 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.11354v1"
    }
]