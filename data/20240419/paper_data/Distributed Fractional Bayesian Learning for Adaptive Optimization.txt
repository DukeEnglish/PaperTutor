Distributed Fractional Bayesian Learning for
Adaptive Optimization
Yaqun Yang, Jinlong Lei (Member, IEEE), Guanghui Wen (Senior Member, IEEE), and Yiguang Hong (Fellow,
IEEE)
Abstract— This paper considers a distributed adaptive interpret the intentions of others and make trajectory planning
optimization problem, where all agents only have access for itself [4]. In Economics of Markowitz profile problem,
to their local cost functions with a common unknown
one should learn the uncertain parameters of expectation or
parameter, whereas they mean to collaboratively estimate
covariance matrices associated with the stocks model, and
the true parameter and find the optimal solution over a
connectednetwork.Ageneralmathematicalframeworkfor then find the best solution to the optimal portfolio [5]. These
suchaproblemhasnotbeenstudiedyet.Weaimtoprovide together motivate us to investigate the distributed decision-
valuable insights for addressing parameter uncertainty in making problems with model uncertainty.
distributedoptimizationproblemsandsimultaneouslyfind
Generallyspeaking,theresolutionofdecision-makingprob-
the optimal solution. Thus, we propose a novel Prediction
lems with model uncertainty consists of two processes: model
while Optimization scheme, which utilizes distributed frac-
tionalBayesianlearningthroughweightedaveragingonthe construction and decision making [6], i.e., agents need to
log-beliefstoupdatethebeliefsofunknownparameter,and estimate the unknown model function (the classical setting
distributed gradient descent for renewing the estimation is characterized by known function structure while with un-
of the optimal solution. Then under suitable assumptions,
known parameters) and find the optimal solution to it. The
we prove that all agents’ beliefs and decision variables
commonly used approaches include the sequential and simul-
converge almost surely to the true parameter and the op-
timal solution under the true parameter, respectively. We taneousmethods.However,asequentialmethodthatconsiders
furtherestablishasublinearconvergencerateforthebelief optimization after prediction may not be applicable to com-
sequence.Finally,numericalexperimentsareimplemented plex decision-making scenarios, since large-scale parameter
tocorroboratethetheoreticalanalysis. learning problems lead to a long time waiting for solving the
IndexTerms—FractionalBayesianLearning,Distributed original problem. Besides, as has been analyzed in [7], this
GradientDescent,ConsensusProtocol,MultiagentSystem. scheme provides an approximate solution to model param-
eters, which propagates the corrupt error into the objective
I. INTRODUCTION
optimization. In some practical scenarios, optimization after
A. BackgroundsandMotivations prediction may lead to a “frozen robot" problem as pointed
out in [8]. Therefore, developing dynamic learning coupled
Distributedoptimizationhasbeenwidelyusedformodeling
algorithmthatconsiderpredictionwhileoptimizationiscrucial
and resolving cooperative decision-making problems in large-
and has gained increasing popularity in recent years, see e.g.,
scale multi-agent systems including economic dispatch, smart
[7]–[9].
grids, automatic controls, and machine learning (see e.g., [1],
It is noticed that the aforementioned works [3]–[5], [8], [9]
[2]). However, in many complex situations, agents need to
investigate the coupled phenomenon between model construc-
make decisions with uncertainty. For example, in Robotics,
tion and decision making in specific scenarios and develop
planning the task for a robot requires predicting other agents’
corresponding methods. However, the general mathematical
reactive behaviors which might be unknown at the very
framework and its resolution along with convergence anal-
beginning [3]. In Autonomous Driving, vehicles need to
ysis in large-scale distributed problems are rarely studied.
The paper is sponsored by the National Key Research and Devel- The previous theoretical works in this field mostly focus
opment Program of China under No 2022YFA1004701, the National on the centralized problem with parameter uncertainty, and
Natural Science Foundation of China under No. 72271187 and No.
merely consider the unidirectional coupling of optimization
62373283,andpartiallybyShanghaiMunicipalScienceandTechnology
Major Project No. 2021SHZDZX0100, and National Natural Science andpredictionwheretheestimationofthemodelparameteris
FoundationofChina(GrantNo.62088101). independent of decision making [10]–[13]. Moreover, few of
Yaqun Yang is with the Department of Control Science and
them have investigated the large-scale distributed scenarios.
Engineering, Tongji University, Shanghai, 201804, China. (email:
yangyaqun@tongji.edu.cn) Weconsiderthebidirectionalcouplingofparameterlearning
Jinlong Lei and Yiguang Hong are with the Department of Control and objective optimization, which brings more difficulties to
ScienceandEngineering,TongjiUniversity,Shanghai,201804,China;
the resolutions along with theoretical analysis. Though there
andtheShanghaiInstituteofIntelligentScienceandTechnology,Tongji
University, Shanghai, 200092, China. (email: leijinlong@tongji.edu.cn, exist some related works, most of them assume that the
yghong@iss.ac.cn) unknown parameter influences the objective function in a
GuanghuiWeniswiththeDepartmentofSystemsScience,School
specific structure. For example, [14] considers a distributed
ofMathematics,SoutheastUniversity,Nanjing,211189,China.(email:
ghwen@seu.edu.cn) quadratic optimization problem with the unknown model
4202
rpA
71
]CO.htam[
1v45311.4042:viXra2
parameter being the objective coefficients, and adopts the in the objective optimization problem, since the sequential
recursive least square to estimate the parameter and gradient method cannot attain an exact solution, we need to design a
tracking to solve the objective optimization. While the work scheme that simultaneously estimates the parameter and find
[14] imposes some assumptions on the intermediate process, the optimal solution. Thirdly, the process of simultaneously
which however is lack of strict theoretical verification. As a learning and optimizing the objective function is coupled in
result, bidirectional coupling optimization problem has not both directions, and the existence of stochastic noises will
been fully resolved here. In addition, [15] uses weighted bring about difficulties in the rigorous theoretic analysis of
least square to solve the unknown coefficient matrices in the designed scheme. All in all, these challenges highlight the
linear-quadratic stochastic differential games. Different from complex and dynamic nature of addressing such problems.
objective functions of such particular structures, we consider This paper addresses all the aforementioned challenges asso-
amoregeneraldistributedbidirectionalcouplingmathematical ciated with the problem (1), and will summarize the main
formulation and give rigorous convergence analysis. contributions in section I-D.
B. ProblemFormulationandChallenges
C. RelatedWorks
We characterize the uncertainty of the distributed optimiza-
Distributed optimization has been developed for nearly
tion problem in a parametric sense. Our primary objective is
40 years. In the first 20 years of the 21st century, various
to establish the model parameters in a way that the action
scholars aimed to broaden the theory of distributed optimiza-
generatedfromthisestimatedmodelbestmatchestheobserved
tion for convex or non-convex objective functions, smooth
action, meanwhile, find this best-estimated model’s optimal
or non-smooth conditions, static or time-varying networks
solution.Tobespecific,weconsideradistributedoptimization
(see e.g., [16], [17]). By 2020, survey papers related to this
problem with unknown model parameter θ as follows.
field have appeared one after another like [18]. Most of the
1 (cid:88)N distributed optimization works considered precisely known
min J (x,θ ),θ ∈Θ, (1)
x∈R N i ∗ ∗ objective functions, while seldom of them have investigated
i=1 the model uncertainty.
where J (x,θ ) represents the private cost function of agent Inrecentyears,theproblemswithbothunknownparameter
i ∗
i ∈ N := {1,2,··· ,N}. The unknown true parameter θ learning and objective optimization have gradually attracted
∗
is taken from a finite set Θ := {θ ,θ ,··· ,θ }. This type research attention. For example, [19] presented a coupled
1 2 M
of problem setting is frequently encountered in specific real- stochastic optimization scheme to solve problems with imper-
world scenarios. For example, the unknown intention of vehi- fectinformation.[7]introducedamethodtooptimizedecisions
cles in autonomous driving can be lane-merging, maintaining in a dynamic environment, where the model parameter is
drivingalongtherightlane,andmaintainingalongtheleftlane unavailable but may be learned by a separate process called
[4],whichmeansthattheunknownparametersetiscomposed Joint estimation-optimization. In addition, [10]–[12] consid-
of three elements. ered centralized mis-specific convex optimization problems
Each agent i ∈ N has a prior belief q (θ ),m = f(x,θ), where the unknown parameter θ of objective is a
i m
1,2,··· ,M of the M possible parameters. Given an input solution to some learning problem l(θ). To be specific, [10]
strategy x, the feedback is realized randomly from a proba- and [12] both used the gradient descent method to solve
bility distribution depending on the system’s true parameter the parameter learning problem and objective optimization
θ , i.e. the noisy feedback y =J (x,θ )+ϵ (x,θ ) for every problem under deterministic optimization and stochastic op-
∗ i i ∗ i ∗
agent i. Let f (y |x,θ ) denote the likelihood function (also timization scenarios respectively, whereas [11] investigated
i i m
called probability density function here) of observation y for an inexact parametric augmented Lagrangian method to solve
i
any strategy x∈R under parameter θ ∈Θ. such problem. However, the aforementioned prediction while
m
Though each agent only knows its local information, it can optimizationworksarecentralizedschemesandunidirectional
interact with other agents over a fixed connected network coupling,i.e.theobjectiveoptimizationdependsonparameter
G = {N,E,W} in which N = {1,2,··· ,N} is the set of learning while the parameter learning problem is indepen-
agents. Herein, E ⊆N ×N represents the edges of network, dent of objective optimization. Although distributed coupled
where (i,j) ∈ E if and only if agents i and j are connected. optimization has also been investigated, for example, [13]
Each agent i has a set of neighbors N = {j|(i,j) ∈ E}. proposed a distributed stochastic optimization with imperfect
i
W =[w ] denotestheweightedadjacencymatrix,where information and [14] presented a distributed problem with a
ij N×N
w >0 if j ∈N and w =0 otherwise. The agents want to compositestructureconsistingofanexactengineeringpartand
ij i ij
collaboratively solve the problem (1), namely, simultaneously an unknown personalized part. However, [13] still focused on
find the true parameter θ ∈Θ and the optimal solution x to unidirectionalcoupling,while[14]imposedsomeassumptions
∗ ∗
the global objective function. on the the intermediate process.
Thereareseveralchallengestosolvingthisproblem.Firstly, It is worth noting that the coupling between parameter
we need to develop a fully distributed strategy based on local learningandequilibriumsearchinghavebeenlittleinvestigated
informationandlocalcommunication.Thisapproachissignifi- in the field of game theory. For example, [20] considered
cantly more challenging compared to dealing with centralized parameter learning and decision-making in game theory and
issues [10]–[12]. Secondly, given the parameter uncertainty developed a non-Bayesian method for parameter estimating.3
Moreover,[21]examinedthelearningdynamicsinfluencedby with the true parameter, and that the decision variable
strategic agents engaging in multiple rounds of a game with of every agent converges to the optimal result under
an unknown parameter that affects the payoff, although this this common true belief. Besides, we also give the
paper operates under the centralized scheme. convergence rate analysis of belief.
Inspiredby[21],weconsiderusingaBayesiantypescheme
to learn the model parameter. Bayesian inference is widely II. ALGORITHM AND ASSUMPTIONS
used in belief updating of uncertainty parameters [21], [22].
Inthissection,weproposeadistributedfractionalBayesian
The standard Bayesian method fully generates past obser-
learning method to solve the problem (1) with some basic
vations to update the parameter estimation. Non-Bayesian
assumptions.
inference advocates placing excessive weights on prior beliefs
andunderreacingttonewobservations.However,thisapproach
hasbeenproventobemorepractical,especiallywhendealing A. AlgorithmDesign
with uncertainty in the real world [23], [24]. In addition, [25]
To solve the problem (1), we need to update the belief of
considered a different type of non-Bayesian learning, called
the unknown parameter set Θ, and get the adaptive decision
Bayesian fractional posterior or power prior. The authors of
based on the current belief. At each step t, every agent i∈N
[26] have shown that in distributed learning, the fractional maintainsitsprivatebeliefq(t) andlocaldecisionx(t).Firstly,
Bayesian inference with distributed log-belief consensus can i i
each agent updates its belief by Bayesian fractional posterior
getafastconvergencerate.Assuch,weconsiderthisvariation
(2) based on its current observation, exchanges information
of Bayesian inference to estimate the unknown parameter of
with its neighbors N = {j|(i,j) ∈ E} over the distributed
i
our problem. As for the adaptive optimization method with
network G and performs a non-Bayesian consensus using log-
the objective function computing, we consider the classical beliefs (3) to renew the belief q(t+1). Secondly, we obtain
distributed gradient descent (DGD) [27], which also has good i
an adaptive decision based on the updated belief. Each agent
performance in convex optimization. i∈N calculates a local function (cid:80) J (cid:16) x(t),θ(cid:17) q(t+1)(θ)
θ∈Θ i i i
by averaging its private cost function J (x,θ) across its belief
i
D. MainContribution q(t+1),andthenperformsagradientdescentmethodbasedon
i
To solve the distributed optimization problem (1) with this local function and shares the intermediate result with its
unknown parameter θ , we design an efficient algorithm and neighbors. After receiving its neighbors’ temporary decision
∗
give its convergence analysis. Below are our contributions. information over the static connected network, agent i ∈ N
1) We propose a general mathematical formulation for renews the decision x(t+1) by a distributed linear consensus
i
distributed optimization problem with parameter uncer- protocol. Finally, we feed the results of the current iteration
tainty. The formulation models the bidirectional cou- into the unknown system to obtain the corresponding output
pling between parameter learning and objective opti- datawithnoiseandproceedtothenextloop.Thepseudo-code
mization.Thoughtherehasbeenafewresearchonsome for the algorithm is outlined in Algorithm 1.
practical applications, the general mathematical model Remark1. ComparedtothestandardBayesianposteriorin
has not been abstracted and studied yet. Thus, our for- multi-agentBayesianlearning[21],weuseBayesianfractional
mulated model can expand upon prior theoretical works posterior distribution in (2). It has been demonstrated to be
with known objective functions, and the type with fixed valuable in Bayesian inference because of its flexibility in
modelstructureinfluencedbyunknownparameterwhich incorporatinghistoricalinformation.Thismethodmodifiesthe
however is independent of the objective computation. likelihoodofhistoricaldatausingafractionalpowerα(t) [28].
2) We design a novel distributed fractional Bayesian The parameter α controls the relative weight of loss-to-data
learning dynamics and adaptive optimization algo- to loss-to-prior. If 0<α <1, the loss-to-prior is given more
rithm,whichconsidersmodelconstructionanddecision- prominencethannewlygenerateddataintheBayesianupdate;
making simultaneously in the Prediction while Op- α = 1 is the standard Bayesian; α > 1 that means we pay
timization scheme. To be specific, we use fractional more attention to data, and in the extreme case with large α,
Bayesian learning for updating beliefs of the unknown the Bayesian estimator degenerates into maximum likelihood
parameter, which adopts a distributed consensus pro- estimatorasinfrequentistinference[22].Ithasbeenshownin
tocol that averages on a reweighting of the log-belief [29]thatforsmallα,fractionalBayesianinferenceoutperform
for the belief consensus. This is more reasonable and standard Bayesian for the underlying unknown distribution in
robust than standard Bayesian learning, and the belief several settings.
consensusprotocolisshowntobefasterthanthenormal Remark 2. Different from the standard linear consensus
distributed linear consensus protocol by experiment. in distributed scenarios [30], we adopt (3) that implements
We then utilize the distributed gradient descent method distributed consensus averaging on a reweighting of the log-
to update the optimal solution, whereas each agent’s beliefs. It is worth noting that the standard linear consensus
gradient is computed based on the expectation of its protocolsimplifiedintoavectorformx(t+1)=Wx(t)[31]
local objective function over its private belief. has a convergence rate of O(ρt w), where ρ w is the spectral
3) Finally, we rigorously prove that all agents’ belief con- radius of W − 11T . Log-belief consensus logx(t + 1) =
N
vergealmostsurelytoacommonbeliefthatisconsistent W logx(t) can be recast as y(t+1) = Wy(t) with y(t) ≜4
Algorithm 1 Distributed Fractional Bayesian Learning in true parameter [32]. In this case, the information of agent i
Optimization is enough for revealing the true paper, and hence it is unnec-
Initialization: For each i ∈ N: (x(0),y(0)) ; stepsize essary to use the observation of multiple agents. Therefore,
i i
sequency {α(t) ≥ 0} ; weigh matrix W = [w ] ; Assumption 1 is imposed to preclude the degraded case and
t≥0 ij N×N
prior distribution q(0) = 1 1 make the multi-agent setting meaningful.
i M M
Belief update: for each agent i∈N, and m=1,··· ,M Assumption 2 (Graph and Weighted Matrix) ThegraphG
Update local fractional Bayesian posterior belief is static, undirected and connected. The weighted adjacency
f (y(t)|x(t),θ )α(t)q(t)(θ ) matrix W is nonnegative and doubly stochastic, i.e.,
b(t)(θ )= i i i m i m , (2)
i m (cid:80) f (y(t)|x(t),θ)α(t)q(t)(θ) W1=1,1TW =1T. (8)
θ∈Θ i i i i
Receive information b(t)(θ ) from j ∈ N and perform Thisassumptioniscrucialinthedevelopmentofdistributed
j m i algorithms, based on which every agent’s information can
a non-bayesian rule to update the private belief
be merged after multiple rounds of communication. Then
exp((cid:80) w log(b(t)(θ ))) consensus will be obtained. With Assumption 2, we can get
q(t+1)(θ )= j∈Ni ij j m (3)
i m (cid:80) exp((cid:80) w log(b(t)(θ))) the following lemma from [31].
θ∈Θ j∈Ni ij j
Lemma 1 [31, Theorem 1] Let Assumption 2 hold. Then
Decision update: Given the current private belief q(t+1),
i 11T
each agent i∈N evaluates its local expected cost by lim Wt =
t→∞ N
J˜(x(t),θ)= (cid:88) J (x(t),θ)q(t+1)(θ). (4)
i i i i i holds with exponential rate O(ρt ), where ρ ∈ [0,1) is the
w w
θ∈Θ the spectral radius of W − 11T.
N
Then every agent i utilizes a distributed gradient de- Assumption 3 (Stepsize Policy) The stepsize sequence
scent method to optimize the decision variable, {α(t)} with 0<α(t) <1 satisfies
t≥0
(cid:20) (cid:21)
x( it+1) = (cid:88) w
ij
x( jt)−α(t) ∂∂ xJ˜ j(x( jt),θ) . (5) (cid:88)∞
α(t) =∞ and
(cid:88)∞
(α(t))2 ≤∞.
j∈Ni
t=0 t=0
Obtain the new data: Every agent i ∈ N gets new data This assumption indicates that lim α(t) =0.
t→∞
based on the renewed decision under true parameter θ ∗. Inthefollowing,weimposesomeassumptionsregardingthe
y(t+1) =J (x(t+1),θ )+ϵ (x(t+1),θ ). (6) strong convexity and Lipschitz smooth on the cost functions.
i i i ∗ i i ∗
Assumption 4 (Function Properties) For every i ∈ N,
J (x,θ) is strongly convex and Lipschitz smooth in x with
i
constant µ and L for any fixed θ ∈Θ, i.e., for any x,x′ ∈R,
logx(t), where y(t) converges at rate O(ρt ), hence x(t)
w we have
displays a exponential faster rate than y(t). Thus, the utilized
method (3) is likely to bring a faster rate of consensus. (∇ J (x′,θ)−∇ J (x,θ))T (x′−x)≥µ∥x′−x∥2 ,
x i x i
∥∇ J (x′,θ)−∇ J (x,θ)∥≤L∥x′−x∥.
x i x i
B. Assumptions
Finally,weimposethefollowingconditiononthelikelihood
To prove the convergence of sequences {x(t)} and
i t≥0 functionf (y |x,θ)(viz.ProbabilityDensityFunction),which
{q i(t)} t≥0 generated by Algorithm 1 for all agents i ∈ N, can guarani teei the uniqueness of true parameter θ ∗.
we give some assumptions as follows.
Assumption 5 (Uniqueness of true parameter θ ) For
∗
Assumption 1 (Bounded Belief) Every realized cost has
every θ ̸= θ , there exists at least one agent i ∈ N with the
∗
bounded information content, i.e., there exists a positive con- KL divergence D (f (y |x,θ∗)||f (y |x,θ)) > 0 for all
KL i i i i
stant B such that x ∈ R. Here, the KL divergence between the distribution of
(cid:12) (cid:12)
max max
maxsup(cid:12)
(cid:12)log
f i(y i|x,θ′)(cid:12)
(cid:12)<B (7)
observed y with decision x under parameter θ ∗ and θ ∈Θ is
i θ′,θ′′∈Θ x yi (cid:12) (cid:12) f i(y i|x,θ′′)(cid:12) (cid:12) given by
(cid:90) (cid:18) f(y|x,θ∗)(cid:19)
In addition, for each i∈N, f (y |x,θ) is continuous in x for D (f(y|x,θ∗)||f(y|x,θ))= f(y|x,θ∗)log dy.
i i KL f(y|x,θ)
all θ ∈Θ. y
Bounded private beliefs suggest that an agent i ∈ N
III. CONVERGENCE ANALYSIS
can only reveal a limited amount of information about
In this section, we give the convergence analysis of Al-
the unknown parameter. Conversely, the unbounded belief
(cid:12) (cid:12) gorithm 1. We not only show the convergence of the belief
sup yi(cid:12) (cid:12) (cid:12)log ff ii (( yy ii || xx ,, θθ ′′ ′) )(cid:12) (cid:12)
(cid:12)
= ∞ corresponds to a situation where q i(t)(·) about the unknown parameters, but also present the
an agent may receive arbitrarily strong signals favoring the convergence analysis of the decision variable x(t).
i5
A. BeliefConvergence Therefore, combining (10) and (11) yields
Inthissubsection,wedemonstratethatallagents’beliefsof
Θconvergetoasharedbeliefandpresentitsformula.Though
(cid:12) (cid:12)
the proof is motivated by [20], observations are different in (cid:12) (cid:12)logq i(t+1)(θm) − 1 (cid:88)N logq i(t+1)(θm)(cid:12) (cid:12)
optimization versus game settings. So, we include it here for (cid:12) (cid:12) q i(t+1)(θ∗) N
i=1
q i(t+1)(θ∗)(cid:12) (cid:12)
completeness.
N t (cid:12) (cid:12)
≤(cid:88)(cid:88) α(t−τ+1)(cid:12) (cid:12)Wτ(i,j)− 1(cid:12) (cid:12)(cid:12) (cid:12)logfj(y j(t−τ+1)|x j(t−τ+1),θm)(cid:12)
(cid:12)
Lemma 2 Let Assumptions 1, 2 and 3 hold. Then the agents’
j=1τ=1
N (cid:12) fj(y j(t−τ+1)|x j(t−τ+1),θ∗)(cid:12)
log-belief ratios will finally reach consensus, i.e.
t
≤NB(cid:88) α(t−τ+1)(cid:12) (cid:12)Wτ(i,j)− 1(cid:12) (cid:12), (12)
(cid:12) (cid:12) (cid:12)
(cid:12)
(cid:12)logq qi( i(t t+ +1 1) )( (θ θm ∗)) − N1 (cid:88) i=N 1logq qi( i(t t+ +1 1) )( (θ θm ∗))(cid:12) (cid:12) (cid:12)
(cid:12)
(cid:12)→0,∀θ
m
∈Θ. (9) τ=1 N
where the last inequality follows from Assumption 1. Denote
Furthermore, for all θ ∈ Θ, the sequence 1 (cid:80)N q i(t)(θm) sequence γ =|Wτ(i,j)− 1|. In light of Lemma 1, we can
convergesalmostsurelytosomenon-negativeN randoi= m1 vq ai( rt i) a(θ b∗ l)
e obtain
limτ
γ = 0
withN
exponential rate. This together
τ→∞ τ
ν . with Assumption 3 brings the asymptotic convergence of
m (cid:12) (cid:12)
Proof: According to the belief update rules (2) and (3), (cid:12) (cid:12) (cid:12)logq qi( i(t t+ +1 1) )( (θ θm ∗)) − N1 (cid:80)N i=1logq qi( i(t t+ +1 1) )( (θ θm ∗))(cid:12) (cid:12) (cid:12). 1
we have
As for the convergence of sequence 1 (cid:80)N q i(t)(θm) , re-
logq i(t+1)(θ m) =logexp((cid:80)N j=1w ijlogb( jt)(θ m)) calling the third equality of (10), we
havN
e
i=1 q i(t)(θ∗)
q(t+1)(θ ) exp((cid:80)N w logb(t)(θ ))
i ∗ j=1 ij j ∗
N N
=(cid:88) j=1w ijlogb( jt)(θ m)−(cid:88) j=1w ijlogb j(t)(θ ∗) q qi( (t t+ +1 1) )( (θ θm )) =exp (cid:88)N w ijlogb b( j (t t) )( (θ θm )) 
= =(cid:88) (cid:88)j jN N= =1 1w wi ij jl lo og gb qb q( j j(( j j(t tt t) )) )( (( (θ θθ θm m∗ ∗) ))
) +α(t)(cid:88) jN =1w ijlogf fj j(cid:16) (cid:16)y yj( j(t t) )| |x x( j ( jt t) ), ,θ θm ∗(cid:17)(cid:17)
i ∗ ≤
(
=2)(cid:88)
j
(cid:88)N
=
N1w wij j= b
b
f( j1
( j
jt t)
)
(cid:16)(
(
yθ
θ
jm
(∗ t)
))
|x(
jtj
),θ
m∗
(cid:17)α(t) q j(t)(θ m)
, (13)
(cid:88)N (cid:88)t f j(cid:16) y j(t−τ+1)|x( jt−τ+1),θ m(cid:17) j=1 ij f j(cid:16) y j(t)|x( jt),θ ∗(cid:17)α(t) q j(t)(θ ∗)
= Wτ(i,j)α(t−τ+1)log
(cid:16) (cid:17)
f y(t−τ+1)|x(t−τ+1),θ
j=1τ=1 j j j ∗
+(cid:88)N Wt+1(i,j)logq j(0)(θ m) where the first inequality is followed by eλa+(1−λ)b ≤λea+
j=1
q j(0)(θ ∗)
(cid:16) (cid:17)
( F1 ur− thλ er) meb o, resi ,n bc ae see dx ois na (cid:80)c Nonve wx fu =nc 1t ,io wn ea dn ed ri(cid:80) veN j=1w ij = 1.
N t f y(t−τ+1)|x(t−τ+1),θ i=1 ij
(cid:88)(cid:88) j j j m
= Wτ(i,j)α(t−τ+1)log ,
(cid:16) (cid:17)
f y(t−τ+1)|x(t−τ+1),θ
j=1τ=1 j j j ∗
(10)
1
(cid:88)N q i(t+1)(θ m)
≤ 1
(cid:88)N fi(cid:16) y i(t)|x i(t),θm(cid:17)α(t) q i(t)(θm)
. (14)
where Wt(i,j) means the (i,j)-element of matrix Wt, and N i=1 q i(t+1)(θ ∗) N i=1 fi(cid:16) y i(t)|x( it),θ∗(cid:17)α(t) q i(t)(θ∗)
the last equality follows from q(0) = 1 1 .
i M M
With Assumption 2, we achieve the double stochasticity of
Wt. Then based on (10), we have By taking conditional expectation on both sides
of the above equation and noting that q(t) is F -
i t
1 (cid:88)N logq i(t+1)(θ m)
=
measurable, where F t denote the σ-algebra generated
N q(t+1)(θ )
i=1 i ∗
(cid:16) (cid:17)
N t f y(t−τ+1)|x(t−τ+1),θ
1 (cid:88)(cid:88) i i i m
α(t−τ+1)log
(cid:16)
(cid:17). (11) 1[33,Lemma7]Stepsizesequence0<α(t)<1satisfieslimt→∞α(t)=
N i=1τ=1 f i y i(t−τ+1)|x( jt−τ+1),θ ∗ l0 imun t→de ∞r A γs tsu =m 0pt wio in th3 e. xB pe os ni ed ne ts i, al0 ra< te,γ tt he< nl1 imis t→a ∞sca (cid:80)la t τr =se 0q αue (tn −ce τ)s γa τti =sfi 0e .s6
by {(x(0),y(0)),(x(1),y(1)),··· ,(x(t),y(t))|i∈N}. Then On the other hand, by the belief update rules in (3),
i i i i i i
E(cid:104) N1 (cid:88)N q qi( (t t+ +1 1) )( (θ θm )) |F t(cid:105) q i(t+1)(θ ∗)= (cid:80) θe ∈x Θp( e(cid:80) xpj (∈ (cid:80)Ni j∈w Nij il wog ij(b lo( jt g) (( bθ ( j∗ t)) () θ) )))
i=1 i ∗  −1
≤ N1 (cid:88) i=N
1
q qi( i(t t) )( (θ θm ∗)) E(cid:34) f fi i(cid:16) (cid:16)y yi( i(t t) )| |x xi(
(
it t) ), ,θ θm ∗(cid:17)(cid:17) α(t) |F t(cid:35) = 1+ θ(cid:88) ̸=θ∗exp(cid:18) (cid:80)(cid:80) N jN j == 11 ww ii jj ll oo gg bb ( j( j tt )) (( θθ ∗) )(cid:19) 
−1
N
≤ = N N1 1 (cid:88) (cid:88)i i= =N N1
1
q q qq i(i( i(i( t tt )t )) ) ( (θ( θ( mθ ∗θm ))∗ (cid:34))) E (cid:90) y(cid:34) itf f fi i i(cid:16) ((cid:16) yy y i(i( i( tt )t) ) || x|x x ( i( i ( i tt )t) ) ,, , θθ θ ∗m ∗ )(cid:17)(cid:17) f fi i| (cid:16) (cid:16)F y yi(t i(t(cid:35) t) )|α |x x( ( i
(
it t t) ) ), ,θ θm ∗(cid:17)(cid:17) dy i(t)(cid:35)α(t) = ( =2) (cid:32)1 (cid:88)1 N+ +θ θ(cid:88) (cid:88)̸= ̸=θ θ∗ ∗e ex xp p q( (cid:16) t)((cid:88) j (cid:88) j θ= N = )1 1 (cid:17)w w (cid:33)i ij j −αl 1o (g t)b lb ( j o( j tt g)) (( θ fθ f∗ j) j) (cid:16)(cid:16) yy j(j( t t )) || xx ( j( j tt )) ,, θθ ∗(cid:17) (cid:17)
+ w log j , ∀i∈N, (19)
= 1
(cid:88)N q i(t)(θ m)
, (15) j=1
ij q j(t)(θ∗)
N q(t)(θ )
i=1 i ∗ where the third equality in the above equation is achieved
where the second inequality holds since xα, 0 < α < 1 similarly to the third equality of (10).
is a concave function. Therefore, 1 (cid:80)N q i(t)(θm) is a non- By recalling from Assumptions 1 and 3 that
nenagtivesupermartingale.HencebN ythei= su1 peq i( rt m)( aθ∗ rt)
ingalecon- log
fj(cid:16) y j(t)|x j(t),θ(cid:17)
is bounded and lim α(t) =0. Thus,
vergence theorem, we conclude its almost sure convergence,
fj(cid:16) y j(t)|x j(t),θ∗(cid:17) t→∞
denoted as ν m.
N f
(cid:16) y(t)|x(t),θ(cid:17)
Inthefollowing,weshowthateveryagent’sestimatedbelief lim (cid:88) w α(t)log j j j =0. (20)
ij (cid:16) (cid:17)
of M possible parameters converges to a common belief q˜ ≜ t→∞ f y(t)|x(t),θ
j=1 j j j ∗
(q˜(θ ),q˜(θ ),··· ,q˜(θ ))T ∈RM.
1 2 M
Take θ =θ without loss of generality. Then by substituting
∗ 1
Theorem 1 Let Assumptions 1, 2, and 3 hold. Then for every
(18) and (20) into (19), we have
agent i ∈ N, its belief sequence {q(t)} generated by
i t≥0 M
Algorithm 1 converges to a common belief with the form lim q(t+1)(θ )=(1+ (cid:88) ν )−1, a.s. (21)
q˜(θ )= ν m for each m=1,··· ,M, (16) t→∞ i ∗ m=2 m
m (cid:80)M
ν
m=1 m Further, applying (17) into above relation yields
where ν m = tl →im ∞N1 (cid:80)N i=1 q qi( i(t t) )( (θ θm ∗)) is given in Lemma 2. tl →im ∞q i(t+1)(θ m)= 1+(cid:80)ν M mm =2ν m, a.s. ∀i∈N (22)
Proof: Performinganexponentialoperationonbothside
Therefore, Theorem 1 can be proved by noting that ν = 1
1
of (9), we have
with the notation θ =θ .
∗ 1
lim q i(t+1)(θm) · 1 =1 Though the above result shows that every agent’s belief
t→∞ q i(t+1)(θ∗) exp(cid:32) 1 (cid:80)N logq i(t+1)(θm)(cid:33) converges to a common belief, which does not mean that
N i=1 q i(t+1)(θ∗) the belief vector is 1 for the element with true parameter θ ∗.
⇒ tl →im ∞N1 (cid:88) i=N
1
q qi( i(t t+ +1 1) )( (θ θm ∗)) · exp(cid:32) N1 (cid:80)N i=1l1 ogq qi( i(t t+ +1 1) )( (θ θm ∗))(cid:33) =1 wT pah hre ia lr m eef e oo t tr e he r e, , riw . qee (. θq˜n me → )e |d θmqto ∗ ̸=, θf w ∗ur h =th ere 0er .ip Tnr ho v iv e se c rt eoit srs uq lc t∗o a(n lθv o)e nr o gg ne wln y ic te q h(t iθo t∗ s)a p= rt oru o1e f,
(cid:34) N (cid:32) N (cid:33)(cid:35) will be given in Theorem 3.
⇒ lim 1 (cid:88)q i(t+1)(θm) −exp 1 (cid:88) logq i(t+1)(θm) =0.
t→∞ N
i=1
q i(t+1)(θ∗) N
i=1
q i(t+1)(θ∗)
B. DecisionConvergence
This together with Lemma 2 implies that For each i∈N, define
tl →im ∞N1 (cid:88) i=N 1logq qi( i(t t+ +1 1) )( (θ θm ∗)) =logν m. Jq i(( it x) ,(θ θ) )≜ ≜( (q Ji( it () x( ,θ θ1 1), ),q Ji(t i) (( xθ ,2 θ), 2· ),· ·· ·, ·q ,i(t J) i( (θ xM ,θ)) MT )∈ )TR ∈M R, M( .23)
Then by Lemma 2, we derive (24)
tl →im ∞logq qi( i(t t+ +1 1) )( (θ θm ∗)) ==logν m. (17) T beh le ien f t qh i(e t)e ex qp ue ac lt sed toc qos ( itt )(f θu )n Tct Jio in (x( i( t4 )) ,θa )v ,e ir .a eg .,in Jg ˜ i(a xc ( ir t)o ,s θs )th =e
Therefore, by using Assumption 2, we obtain that q( it)(θ)TJ i(x( it),θ) . We redenote J˜ i(x( it),θ) as F i(x( it),q( it))
  to clearly show its dependence on the decision x(t) and the
N i
tl →im ∞exp(cid:88) j=1w ijlogq qj( j(t t+ +1 1) )( (θ θm ∗)) =ν m. (18) belief qt i, i.e. F,
(x(t),q(t))≜q(t)(θ)TJ (x(t),θ). (25)
i i i i i i7
Therefore, each agent’s local cost function can be reformu- Proof: By using the optimality condition of the
late as q∗(θ)TJ (x,θ), and the original distributed objective unconstrained optimization problem (26), we have
i
function (1) can be rewritten as 1 (cid:80)N ∇ F (x∗(q˜),q˜) = ∇ F¯(1x∗(q˜),1 ⊗ q˜T) = 0.
N i=1 x i x
min
1 (cid:88)N
q∗(θ)TJ (x,θ)≜min
1 (cid:88)N
F (x,q∗). (26)
T x¯(h te )n anb dy Fu ¯si in ng (3it 0e )ra at nio dn (3o 2f )x ,( i wt) ein ha( v2 e8), and the definition of
x∈R N i x∈R N i
i=1 i=1
We denote by x∗(q) the optimal solution to the optimization
problem min x N1 (cid:80)N i=1F i(x,q), namely, ∥x¯(t+1)−x∗(q˜)∥=(cid:13) (cid:13) 1 (cid:88)N (cid:88)N w (cid:2) x(t)−α(t)∇ F (x(t),q(t))(cid:3)
(cid:13)N ij j x j j j
N
1 (cid:88) i=1j=1
x∗(q)=argmin x∈R N F i(x,q). (27) −(cid:2) x∗(q˜)−α(t)∇ F¯(1x∗(q˜),1⊗q˜T)(cid:3)(cid:13) (cid:13)
i=1 x (cid:13)
(cid:13)
Then x∗(q∗)=x ∗, which is the optimal solution to the prob- =(cid:13)
(cid:13)
x¯(t)−α(t)∇ xF¯(x(t),Q(t))
lem (1). Besides, step (5) in Algorithm 1 can be reformulated
(cid:13)
as −x∗(q˜)+α(t)∇ xF¯(1x∗(q˜),1⊗q˜T)(cid:13)
(cid:13)
x(t+1)
=(cid:88)N
w
(cid:104)
x(t)−α(t)∇ F
(x(t),q(t))(cid:105)
. (28)
≤(cid:13) (cid:13)x¯(t)−x∗(q˜)
i ij j x j j j (cid:16) (cid:17)
−α(t) ∇ F¯(x(t),Q(t))−∇ F¯(1x∗(q˜),Q(t))
j=1 x x
{xI (n t)}the fo foll row evin eg ry, w age enw til il cs oh no vw ert gh ea st tt ohe ad ce oc mis mio on nse soq lu ue tn ioc ne −α(t)(cid:16) ∇ xF¯(1x∗(q˜),Q(t))−∇ xF¯(1x∗(q˜),1⊗q˜T)(cid:17)(cid:13) (cid:13)
x∗(i q˜)t (≥ c0 onvergence to the true optimal solution x∗(q∗) will ≤(cid:13) (cid:13)x¯(t)−x∗(q˜) (35)
be presented in later part), where q˜ is given in Theorem 1 . −α(t)(cid:16) ∇ xF¯(x(t),Q(t))−∇ xF¯(1x∗(q˜),Q(t))(cid:17)(cid:13) (cid:13)
First of all, the properties of the newly shaped function
F i(x,q i) defined by (25) are shown below. For completeness, +α(t)(cid:13) (cid:13)∇ xF¯(1x∗(q˜),Q(t))∇ xF¯(1x∗(q˜),1⊗q˜T)(cid:13) (cid:13),
we give its proof in Appendix I.
Lemma 3 Let Assumption 4 hold. Then for all i ∈ N and
for all q ∈ RM, F (x,q ) is strongly convex and Lipstchiz where the second equality holds by using 1(cid:80)N w = 1,
i i i N i=1 ij
smooth in x with constant µ and L. and the last equality utilizes the triangle inequality.
In the following, we will show the recursions on the The first term in the right-hand side of (35) can be further
optimization error ∥x¯(t+1) −x∗(q˜)∥ in Lemma 4, and con- bounded by first writing the following expansion:
sensus error ∥x(t+1)−1x¯(t+1)∥ in Lemma 5. For the sake of
simplicity, we give some more notations below.
x(t) ≜(x(t),x(t),··· ,x(t))T ∈RN, (29)
(cid:13) (cid:13)x¯(t)−x∗(q˜)
x¯(t) ≜
11
(cid:88)N
x2
(t)
∈R,N
(30)
−α(t)(cid:16)
∇ xF¯(x(t),Q(t))−∇
xF¯(1x∗(q˜),Q(t))(cid:17)(cid:13)
(cid:13)2
N i =∥x¯(t)−x∗(q˜)∥2
i=1
(cid:16) (cid:17)
Q(t) ≜(q(t),q(t),··· ,q(t))T ∈RN×M, (31) −2α(t)(x¯(t)−x∗(q˜))T ∇ F¯(x(t),Q(t))−∇ F¯(1x∗(q˜),Q(t))
1 2 N x x
1 (cid:88)N F (x(t),q(t))≜F¯(x(t),Q(t))∈R, (32) +[α(t)]2(cid:13) (cid:13)∇ xF¯(x(t),Q(t))−∇ xF¯(1x∗(q˜),Q(t))(cid:13) (cid:13)2
N i i i ≤∥x¯(t)−x∗(q˜)∥2 (36)
i=1
(cid:16) (cid:16) (cid:17) (cid:16) (cid:17)
F(x(t),Q(t))≜ F x(t),q(t) ,F x(t),q(t) , −2α(t)(x¯(t)−x∗(q˜))T(∇ F¯(x(t),Q(t))−∇ F¯(1x¯(t),Q(t)))
1 1 1 2 2 2 x x
(cid:124) (cid:123)(cid:122) (cid:125)
··· ,F
(cid:16) x(t),q(t)(cid:17)(cid:17)T
∈RN (33)
Term 1
N N N +2[α(t)]2∥∇ F¯(x(t),Q(t))−∇ F¯(1x¯(t),Q(t))∥2
x x
(cid:124) (cid:123)(cid:122) (cid:125)
Lemma 4 LetAssumptions2,3,and4hold.UnderAlgorithm
Term 2
1, supposing stepsize α(t) < 21 L, we can bound the gap +2[α(t)]2∥∇ xF¯(1x¯(t),Q(t))−∇ xF¯(1x∗(q˜),Q(t))∥2
between x¯(t+1) and x∗(q˜) as follows,
−2α(t)(x¯(t)−x∗(q˜))T(∇ F¯(1x¯(t),Q(t))−∇ F¯(1x∗(q˜),Q(t)))
x x
∥x¯(t+1)−x∗(q˜)∥ (cid:124) (cid:123)(cid:122) (cid:125)
(cid:113) Term 3
≤ 1−α(t)µ(1−2Lα(t))∥x¯(t)−x∗(q˜)∥
√
[α(t)]0.5L 2Lα(t)
+ √ ∥x(t)−1x¯(t)∥+ √ ∥x(t)−1x¯(t)∥ (Plus Term 3 contains two terms) where the last equality
µN N is obtained by adding and subtracting the same terms and
+α(t)
1 (cid:88)N
∥q(t)−q˜∥∥∇ J (x∗(q˜),θ)∥ (34)
together with (a+b)2 ≤2a2+2b2.
N i x i RecallingfromthedefinitionofF¯ in(32)andtogetherwith
i=18
the triangle equality ∥(cid:80)N z ∥≤(cid:80)N ∥z ∥, we have By recalling the definition of F¯ in (32) and using (40), we
i=1 i i=1 i
can further bound Term 3 as follows
∥∇ F¯(x(t),Q(t))−∇ F¯(1x¯(t),Q(t))∥
x x
N Term 3≤
=(cid:13) (cid:13) N1 (cid:88) i=1(cid:16) F i(x( it),q( it))−F i(x¯(t),q( it))(cid:17)(cid:13) (cid:13)
2[α(
Nt)]2L(cid:88)N
(x¯(t)−x∗(q˜))T(∇ xF i(x¯(t),q( it))−∇ xF i(x∗(q˜),q( it)))
N
≤ N1 (cid:88) i=1∥F i(x( it),q( it))−F i(x¯(t),q( it))∥
−2α
N(t)(xi ¯= (t1 )−x∗(q˜))T(cid:88)N
(∇ xF i(x¯(t),q( it))−∇ xF i(x∗(q˜),q( it)))
N
≤ N1 (cid:88) L∥x( it)−x¯(t)∥, (37) =−2α(t)(1−α(t)L)i=1
N
i=1
N
where the last inequality uses the Lipschitz smoothness of ×(cid:88) (x¯(t)−x∗(q˜))T(∇ F (x¯(t),q(t))−∇ F (x∗(q˜),q(t)))
x i i x i i
F (x,q ) to x in Lemma 3. Therefore, based on the Cauchy-
i i i=1
Schwartz inequality, we can bound Term 1 as follows N
≤−2α(t)(1−α(t)L)(cid:88)
µ∥x¯(t)−x∗(q˜)∥2
Term 1≤2α(t)∥x¯(t)−x∗(q˜)∥ N
i=1
×∥∇ xF¯(x(t),Q(t))−∇ xF¯(1x¯(t),Q(t))∥ =−2α(t)(1−α(t)L)µ∥x¯(t)−x∗(q˜)∥2, (42)
N
=2(cid:16) [α(t)]0.5µ0.5∥x¯(t)−x∗(q˜)∥(cid:17)(cid:16) [α(t)]0.5L(cid:88) ∥x(t)−x¯(t)∥(cid:17)
where the last inequality holds by using (41) and
−2α(t)(1−
µ0.5N i N
i=1 α(t)L)<0 since α(t) < 1 .
2L
≤α(t)µ∥x¯(t)−x∗(q˜)∥2+
α(t)L2 ×N(cid:88)N
∥x(t)−x¯(t)∥2
Then by substituting (38), (39), and (42) into (36), we get
µN2 i=1 i (cid:13) (cid:13)x¯(t)−x∗(q˜)
=α(t)µ∥x¯(t)−x∗(q˜)∥2+
α(t)L2
∥x(t)−1x¯(t)∥2, (38)
−α(t)(cid:16)
∇ xF¯(x(t),Q(t))−∇
xF¯(1x∗(q˜),Q(t))(cid:17)(cid:13)
(cid:13)2
µN
≤(1−α(t)µ+2[α(t)]2µL)∥x¯(t)−x∗(q˜)∥2
wherethepenultimateinequalityisfollowedby2ab≤a2+b2
for all a,b>0 and ((cid:80)N i=1∥z i∥)2 ≤N(cid:80)N i=1∥z i∥2. + α(t)L2 ∥x(t)−1x¯(t)∥2+ 2L2[α(t)]2 ∥x(t)−1x¯(t)∥2.
As for Term 2, by using (37), we achieve µN N
√ √ √
(cid:32) N (cid:33)2 Since a+b≤ a+ b for all a,b≥0, the first term on
Term 2≤2[α(t)]2 L (cid:88) ∥x(t)−x¯(t)∥ the right hand side of (35) can be bounded by
N i
i=1
≤2[α(t)]2L N2 (cid:88)N
∥x( it)−x¯(t)∥2
(cid:13) (cid:13)x¯(t) −− αx (∗ t( )q˜ (cid:16))
∇ xF¯(x(t),Q(t))−∇
xF¯(1x∗(q˜),Q(t))(cid:17)(cid:13)
(cid:13)
i=1
2L2[α(t)]2 (cid:113)
= ∥x(t)−1x¯(t)∥2. (39) ≤ 1−α(t)µ+2[α(t)]2µL∥x¯(t)−x∗(q˜)∥ (43)
N √
[α(t)]0.5L 2Lα(t)
Recalling the definition of F¯ in (32) and the Lipschitz + √ ∥x(t)−1x¯(t)∥+ √ ∥x(t)−1x¯(t)∥
µN N
smooth property of F in Lemma 3, we have
i
Consider the second term on the right-hand side of (35).
∥∇ F¯(1x¯(t),Q(t))−∇ F¯(1x∗(q˜),Q(t))∥2
x x Recalling the definition of newly shaped function in (26) and
=∥
1 (cid:88)N (cid:16)
∇ F (x¯(t),q(t))−∇ F
(x∗(q˜),q(t))(cid:17)
∥2
(32), we have
N i=1 x i i x i i α(t)(cid:13) (cid:13)∇ xF¯(1x∗(q˜),Q(t))−∇ xF¯(1x∗(q˜),1⊗q˜T)(cid:13) (cid:13)
N
≤ N1 (cid:88) i=1∥∇ xF i(x¯(t),q( it))−∇ xF i(x∗(q˜),q( it))∥2 (40) =α(t)(cid:13) (cid:13) N1 (cid:88)N (cid:16) ∇ xF i(x∗(q˜),q( it))−∇ xF i(x∗(q˜),q˜)(cid:17)(cid:13) (cid:13)
i=1
N
≤ NL(cid:88) i=1(x¯(t)−x∗(q˜))T(∇ xF i(x¯(t),q( it))−∇ xF i(x∗(q˜),q( it))) =α(t)(cid:13) (cid:13) N1 (cid:88)N (cid:16) q( it)−q˜(cid:17)T ∇ xJ i(x∗(q˜),θ)(cid:13) (cid:13)
i=1
where the last inequality is followed by the Lipschitz smooth N
properties [34, Equation (2.1.8)]. ≤α(t) 1 (cid:88) ∥q(t)−q˜∥∥∇ J (x∗(q˜),θ)∥. (44)
N i x i
In addition, based on the strong convexity of F i in Lemma i=1
3, we have
Substituting (43) and (44) into (35) yields the lemma.
(x¯(t)−x∗(q˜))T(∇ F (x¯(t),q(t))−∇ F (x∗(q˜),q(t))) In the following lemma, we establish the recursion for the
≥µ∥x¯(t)−x xi ∗(q˜)∥2i x i i
(41)
consensus error
(cid:13) (cid:13)x(t+1)−1x¯(t+1)(cid:13) (cid:13)2
.9
Lemma 5 Let Assumptions 2 and 4 hold. We then have By using (25) and (33), we can obtain that
(cid:13) (cid:13) (cid:13)x(t+1)− 1x¯(t+1)(cid:13) (cid:13) (cid:13)2 ⩽ 3+ 4ρ2 w (cid:13) (cid:13) (cid:13)x(t)−1x¯(t)(cid:13) (cid:13) (cid:13)2 (45) (cid:13)
(cid:13)∇
F(cid:16) x(t),Q(t)(cid:17)(cid:13) (cid:13)2 =(cid:88)N
∥q(t)(θ)T∇ J (x(t),θ)∥2
(cid:34) (cid:13) x (cid:13) i x i i
+
3ρ2 w[α(t)]2
2M2L2∥x(t)−1x∗(q˜)∥2
i=1
1−ρ2
w
≤(cid:88)N
∥q(t)(θ)∥2∥∇ J (x(t),θ)∥2
N (cid:35) i x i i
(cid:88) i=1
+2M ∥∇ J (x∗(q˜),θ)∥2 ,
x i N
i=1 ( ≤48) M(cid:88) ∥∇ J (x(t),θ)∥2. (49)
x i i
where ρ is the spectral radius of W − 11⊤. i=1
w N
In addition, recalling the Lipschitz smooth property in As-
Proof: By recalling the definitions of x¯(t) and
F¯(x(t),Q(t)) in (30) and (32), together with the double sumption 4, and the definition of J i(x,θ) in (24), we obtain
stochasticity of W in Assumption 2, we have ∥∇ J (x(t),θ)∥
x i i
x(t+1)−x¯(t+1) ( =28)(cid:88)N w (x(t)−α(t)∇ F (x(t),q(t))) =∥∇ xJ i(cid:16) x( it),θ(cid:17) −∇ xJ i(x∗(q˜),θ)+∇ xJ i(x∗(q˜),θ)∥
i ij j x i i i
j=1 ≤∥∇ xJ i(x∗(q˜),θ)∥
(cid:16) (cid:17)
− x¯(t)−α(t)∇ xF¯(x(t),Q(t)) . (46) +(cid:118) (cid:117)
(cid:117)
(cid:116)(cid:88)M
∥∇ J (cid:16) x(t),θ (cid:17) −∇ J (x∗(q˜),θ )∥2
As a result, consider the vector form. By recalling the defini- x i i m x i m
tions of
F(cid:16) x(t),Q(t)(cid:17)
in (33), we have
m=1
√
=∥∇ J (x∗(q˜),θ)∥+ ML∥x(t)−x∗(q˜)∥ (50)
(cid:13) (cid:16) (cid:16) (cid:17)(cid:17) x i i
∥x(t+1)−1x¯(t+1)∥≤(cid:13)W x(t)−α(t)∇ F x(t),Q(t)
(cid:13) x Whereas by using (a+b)2 ≤2(a2+b2), we have
(cid:16) (cid:16) (cid:17)(cid:17)(cid:13)
−1 x¯(t)−α(t)∇ xF¯ x(t),Q(t) (cid:13) (cid:13) ∥∇ J (x(t),θ)∥2 ≤
x i i
(cid:13) (cid:13)(cid:18) 11⊤(cid:19)(cid:34) (cid:16) (cid:17) 2∥∇ J (x∗(q˜),θ)∥2+2ML2∥x(t)−x∗(q˜)∥2.
=(cid:13) W − x(t)−1x¯(t) x i i
(cid:13) N
(cid:13)
This together with (49) produces
(cid:35)(cid:13)
(cid:16) (cid:16) (cid:17) (cid:16) (cid:17)(cid:17) (cid:13)
−α(t) F x(t),Q(t) −1∇ xF¯ x(t),Q(t) (cid:13) (cid:13) (cid:13) (cid:13)∇ F(cid:16) x(t),Q(t)(cid:17)(cid:13) (cid:13)2 (51)
(cid:13) (cid:13) x (cid:13)
=(cid:13) (cid:13) (cid:13) (cid:13)(cid:18) W − 1 N1⊤(cid:19)(cid:16) x(t)−1x¯(t)(cid:17) ≤M(cid:88)N (2∥∇ xJ i(x∗(q˜),θ)∥2+2ML2∥x( it)−x∗(q˜)∥2).
(cid:13) i=1
(cid:13)
−α(t)(cid:18) W − 1 N1⊤(cid:19)(cid:18) I− 1 N1⊤(cid:19) F(cid:16) x(t),Q(t)(cid:17)(cid:13) (cid:13) (cid:13), By combining (47) with (51), and letting c 1 = 1− 2ρ2 w, we
(cid:13) have
w 1x¯h (e tr )e −the 1x¯s (e tc )on =d e 0q ,ua wli hty ereh ao sld ts hesin lc ae st1 eN1 qT u( ax li( tt y) − fol1 lox¯ w(t s)) b=
y
ρ1
2
w
(cid:13) (cid:13) (cid:13)x(t+1)−1x¯(t+1)(cid:13) (cid:13) (cid:13)2 ⩽ 3− 2ρ2 w (cid:13) (cid:13) (cid:13)x(t)−1x¯(t)(cid:13) (cid:13) (cid:13)2 + 3 1[α −( ρt)
2
w]2
(cid:16) (cid:17) (cid:16) (cid:17)
∇ xF¯ x(t),Q(t) = 1 N⊤F x(t),Q(t) . ×(cid:104) 2M2L2∥x(t)−1x∗(q˜)∥2+2M(cid:88)N
∥∇ J
(x∗(q˜),θ)∥2(cid:105)
.
Noticing that ∥I − 11⊤∥ ≤ 1 and ρ is the spectral norm x i
N w i=1
o ∥f x(∥ tW +1)− −11 xN1 ¯⊤ (t+∥, 1)b ∥ased on above relation we derive Note that ρ2 w(cid:16) 3− 2ρ2 w(cid:17) ≤ 3+ 4ρ2 w by ρ w ∈ (0,1). Then multi-
plying ρ on both side of above relation leads to (45).
(cid:13) (cid:13) (cid:13) (cid:16) (cid:17)(cid:13) w
≤ρ (cid:13)x(t)−1x¯(t)(cid:13)+α(t)ρ (cid:13)∇ F x(t),Q(t) (cid:13). From now on, we consider the stepsize α(t) of order O(1),
w(cid:13) (cid:13) w(cid:13) x (cid:13) t
which also satisfy the Assumption 3. In the following, we
Hencebyusing(a+b)2 ≤a2+b2+2ab≤a2+b2+a2/c+b2c present a uniform bound on the iterates {x(t)} generated
t≥0
for any c>0, we obtain that for any c 1 >0, by Algorithm 1. The proof is presented in Appendix II.
(cid:13) (cid:13)2
(cid:13)x(t+1)−1x¯(t+1)(cid:13) Lemma 6 Let Assumptions 2 and 4 hold. Considering Algo-
(cid:13) (cid:13)
rithm 1 with stepsize α(t) of order O(1), for all t ≥ 0 we
(cid:13) (cid:13)2 t
≤ρ2 w(1+c 1)(cid:13) (cid:13)x(t)−1x¯(t)(cid:13)
(cid:13)
have the gap between the iteration vector x(t) which defined
(cid:104) (cid:105)2 (cid:13) (cid:16) (cid:17)(cid:13)2 in (29) and the optimal solution under belief q˜ which defined
+ α(t) ρ2 w(1+ c1 1)(cid:13) (cid:13)∇ xF x(t),Q(t) (cid:13) (cid:13) . (47) in (16) is bounded by some constant Xˆ, i.e.
Note that for any probability vector q ∈ RM, since every ∥x(t)−1x∗(q˜)∥2 ≤Xˆ. (52)
element of q is nonnegative and less than 1, we have
√ Next, we derive the convergence rate of consensus error
∥q∥≤ M. (48)
based on the recursive form of Lemma 5, while present it in10
a more general way. For completeness, its proof is given in Consider
Appendix III.
β(t) L [α(t)]0.5∥x(t)−1x¯(t)∥
lim = √ lim
Lemma 7 Let {e(t)} t≥0 and {α(t)} t≥0 be nonnegative se- t→∞1−p(t) µN t→∞ 0.5α(t)µ−µL[α(t)]2
quences, where α(t) of order O(1). If the recursion √ α(t)L∥x(t)−1x¯(t)∥
t
+ 2L lim
e(t+1) ≤δe(t)+c[α(t)]2 (53) t→∞0.5α(t)µ−µL[α(t)]2
α(t) 1 (cid:80)N ∥q(t)−q˜∥∥∇ J (x∗(q˜),θ)∥
holds for δ ∈ (0,1) and c > 0. Then the sequence {e(t)} + lim N i=1 i x i . (57)
diminishes to 0 with rate O(1). t≥0 t→∞ 0.5α(t)µ−µL[α(t)]2
t2
Since α(t) =O(1) and ∥x(t)−1x¯(t)∥=O(1) when t→∞,
Now we will make full use of previous results to derive the t t
we can conclude that the limit of the first two terms of (57) is
convergence of decision variable. We need to introduce the
0. As for the last term of (57), recalling Theorem 1, we have
following lemma from [19, lemma 1].
lim ∥q(t)−q˜∥ = 0. Together with ∥∇ J (x∗(q˜),θ)∥ is
t→∞ i x i
Lemma 8 Let the sequence recursion boundedwithafixedpoint,wecanobtainthatthelimitofthe
last term of (57) also comes to 0. As a result,
u(t+1) ≤p(t)u(t)+β(t) (54)
β(t)
hold for 0 ≤ p(t) < 1,β(t) ≥ 0,(cid:80)∞ (1−p(t)) = ∞ and lim =0. (58)
lim β(t) =0. If u(t) ≥0,
wet= ha1
ve lim u(t) =0.
t→∞1−p(t)
t→∞ (1−p(t)) t→∞
Combining 0 ≤ p(t) < 1 and β(t) ≥ 0, together with
Theorem 2 Let Assumptions 1, 2, 3, and 4 hold. Consider
(56) and (58), we see that the conditions of Lemma 8 hold.
Algorithm 1 with the stepsize α(t) of order O(1). Then for
t Therefore, by applying Lemma 8, we conclude that u(t) →0
every agent i ∈ N, the decision sequence x( it) converges to as t→0, i.e. ∥x¯(t)−x∗(q˜)∥→0.
anoptimalsolutionof (26)underq˜,i.e.lim t→∞x( it) =x∗(q˜). Therefore, by recalling that ∥x(t)−1x¯∥2 →0 and ∥x¯(t)−
Proof: By Lemma 5 and Lemma 6, we define e(t) = x∗(q˜)∥2 →0 with t→∞, we achieve
∥x(t)−1x¯(t)∥2, δ = 3+ρ2 w, and ∥x(t)−1x∗(q˜)∥2 =∥x(t)−1x¯(t)+1x¯(t)−1x∗(q˜)∥2
4
c=
3ρ2
w
(cid:34)
2M2L2Xˆ
+2M(cid:88)N
∥∇ J
(x∗(q˜),θ)∥2(cid:35)
.
≤2∥x(t)−1x¯∥2+2∥1x¯−1x∗(q˜)∥2
1−ρ2 x i =2∥x(t)−1x¯∥2+2N∥x¯(t)−x∗(q˜)∥2 →0,
w i=1
Then we can recast Lemma 5 as the recursion of Lemma Hence for all i∈N, lim x(t) =x∗(q˜).
t→∞ i
7. Since ρ ∈ [0,1), we have δ ∈ [3/4,1). Then by using
w
Lemma7,weconcludethattheconsensuserror∥x(t)−1x¯(t)∥2
C. ConvergencetotheTrueSolution
diminishes to 0 at rate O(1).
t2 Though the algorithm can converge to x∗(q˜) based on
Besides, in light of Lemma 8 and Lemma 4, we set
subsection A and B, whether it can converge to the true
u(t) :=∥x¯(t)−x∗(q˜)∥, solution x∗(q∗) remains unknown. In the following, we will
(cid:113) validate that q˜ = q∗. First of all, we introduce Toeplitz’s
p(t) := 1−α(t)µ+2µL[α(t)]2,
lemma [35] to help develop the convergence result.
√
[α(t)]0.5L 2Lα(t)
β(t) := √ ∥x(t)−1x¯(t)∥+ √ ∥x(t)−1x¯(t)∥ Lemma 9 Let {A ,1 ≤ k ≤ k } be a double array of
nk n n≥1
µN N
positivenumberssuchthatforfixedk,A →0whenn→∞.
nk
N
+α(t) N1 (cid:88) i=1∥q( it)−q˜∥∥∇ xJ i(x∗(q˜),θ)∥. L (cid:80)et
k kn
={ 1Y An} nn k≥ →1 b 1e wa hs ee nqu nen →ce ∞of
,
r the ea nl n nlu →im
m
∞be (cid:80)rs.
k kn
=If 1Y An nk→
Y
ky =an yd
.
Since α(t) < 1 , 0 ≤ 1−α(t)µ(1−2α(t)L) < 1, therefore Based on which, we obtain the following Theorem.
2L
0 ≤ p(t) < 1. Besides, β(t) ≥ 0 because of the nonnegativity Theorem 3 Let Assumptions 1, 2, 3, 4, and 5 hold with the
property of the norm. stepsize α(t) of order O(1). Consider the belief sequence
t
Note that {q(t)} generated by Algorithm 1. Then, every agent’s
√ i t≥0
lim
1− 1−y =z == =1 =− =√ =1 =− =y
= lim
z
=1. (55)
estimate almost surely converges to the true parameter θ ∗.
y→0 0.5y y=2z−z2 z→0z−0.5z2 In addition , for all agents i∈N and θ m ̸=θ ∗,
Thus, getting limit with substitution of equivalence infinitesi- (cid:32) T (cid:33)
mal,wehave(cid:0) 1−p(t)(cid:1) ∼(cid:0) 0.5α(t)µ−µL[α(t)]2(cid:1) .Therefore, q i(T+1)(θ m)≤exp −Z(θ ∗,θ m)(cid:88) α(t) a.s. (59)
by recalling
(cid:80)∞
α(t) =∞ from Assumption 3, we have
t=1
t=1 where
(cid:88)∞ (1−p(t))=(cid:88)∞ (cid:16) 0.5α(t)µ−µL[α(t)]2(cid:17)
=∞. (56) Z(θ∗,θm)=
N1 (cid:88)N
D
KL(cid:0)
f
j(cid:0)
y
j|x∗(q˜),θ∗(cid:1)
∥f
j(cid:0)
y
j|x∗(q˜),θm(cid:1)(cid:1)
.
t=1 t=1 j=111
Proof: Based on the belief update rules (2) and (3), and ∆(t) ≜ G(t)(z(t)(θ ,θ )). Then ∆(t) ∈ [0,1], and for any
j j j ∗ m j
similarly to the derivation of (10), we derive β ∈[0,1],
(cid:16) (cid:17)
log
q i(T+1)(θ ∗) Pr(∆( jt) ≤β)=Pr G( jt)(z j(t)(θ ∗,θ m))≤β
q(T+1)(θ ) (cid:16) (cid:17)
i m =Pr z(t)(θ ,θ )≤(G(t))−1(β)
N T j ∗ m j
=(cid:88)(cid:88) Wt(i,j)α(T−t+1)z j(T−t+1)(θ ∗,θ m), (60) =G( jt)(G( jt))−1(β)=β.
j=1t=1
Thatis,∆(t)isindependentanduniformlydistributedon[0,1].
w 2,h wer ee az cj( ht i) e( vθ e∗, tθ hm e) do= ubll eog stff ojj c(cid:16)(cid:16) hyy aj(j( t st )) t|| ixx c( j( j itt t)) y,, θθ
m
o∗(cid:17) f(cid:17). WW t.it Th hA enss bu ym up st ii no gn whC ero ens ηi jd (te )j r ≜an (o Gth
∗
je )r −s 1e (q ∆u
(
je tn ))c .e So inf cr ean ∆do
(
jtm
)
iv sa ir .i ia .dbl wes it{ hη uj(t n) i} f∞ t o= rm1,
(60), we have distribution, η(t) is also i.i.d with the same distribution as
j
log fj(yj|x∗(q˜),θ∗). Additionally, since each ∆(t) is generated
1 (cid:88)N q(T+1)(θ∗) fj(yj|x∗(q˜),θm) j
log i fromtherealizedoutcome(x(t),y(t)),(η(t))∞ isinthesame
N q(T+1)(θ ) j j j t=1
i=1 i m probability space as z(t)(θ ,θ ). From (64), G(t) converge to
j ∗ m j
=
1 (cid:88)N (cid:88)N (cid:88)T
Wt(i,j)α(T−t+1)z(T−t+1)(θ ,θ )
G∗
j
as t→∞. Therefore, with probability 1,
N j ∗ m
(cid:12) (cid:12)
i=1j=1t=1 lim (cid:12)z(t)(θ ,θ )−η(t)(cid:12)
= N1 (cid:88)N (cid:88)T α(T−t+1)z j(T−t+1)(θ ∗,θ m) =t l→ im∞ (cid:12) (cid:12) (cid:12)(cid:12) z jj (t)(θ∗ ∗,θm m)−(Gj ∗ j(cid:12) )−1(cid:16) G( jt)(cid:16) z j(t)(θ ∗,θ m)(cid:17)(cid:17)(cid:12) (cid:12)
(cid:12)
j=1t=1 t→∞
=0
N T
= 1 (cid:88)(cid:88) α(t)z(t)(θ ,θ ). (61)
N j ∗ m Consequently, w.p.1
j=1t=1
(cid:12) (cid:12)
By utilizing Lemma 2 and Assumption 3, lim (cid:12) (cid:12)1 (cid:88)T (cid:16) z(t)(θ ,θ )−η(t)(cid:17)(cid:12) (cid:12)
(cid:32) N (cid:33)
T→∞(cid:12) (cid:12)T
t=1
j ∗ m j (cid:12)
(cid:12)
Tl →im ∞(cid:80)T t=1 1α(t) log qq i(i( TT ++ 11 )) (( θθ m∗) ) − N1 (cid:88) i=1log qq i(i( TT ++ 11 )) (( θθ m∗) ) ≤ Tl →im ∞T1 (cid:88)T (cid:12) (cid:12) (cid:12)z j(t)(θ ∗,θ m)−η j(t)(cid:12) (cid:12) (cid:12)=0. (65)
=0. (62) t=1
This together with (η(t))∞ is i.i.d with the distribution of
Therefore, j t=1
log
fj(yj|x∗(q˜),θ∗),
by the strong Large Number Theorem
1 q(T+1)(θ∗) fj(yj|x∗(q˜),θm)
lim log i
T→∞(cid:80)T t=1α(t) q i(T+1)(θ m)
lim
1 (cid:88)T
z(t)(θ∗,θ )=
1 (cid:88)T
η(t)
N T→∞T j m T j
= Tl →im ∞(cid:80)T t=1 1α(t)N1 (cid:88) i=1log qq i(i( TT ++ 11 )) (( θθ m∗) ) =E(cid:20) lot= g1 f j(y j |x∗(q˜),θ∗)(cid:21)t=1 a.s. (66)
f (y |x∗(q˜),θ )
N T j j m
( =61) 1 (cid:88) lim 1 (cid:88) α(t)z(t)(θ∗,θ ). (63)
N T→∞(cid:80)T α(t) j m Note that Tα(T) +(cid:80)T−1t(cid:0) α(t)−α(t+1)(cid:1) = (cid:80)T α(t).
j=1 t=1 t=1 t=1 t=1
Define Y = 1(cid:80)t z(τ)(θ∗,θ ), and the sequence
t t τ=1 j m
To consider the convergence of the above equation, we first t(α(t)−α(t+1))
study the convergence of T1 (cid:80)T t=1z j(t)(θ ∗,θ m). {A Tt,1 ≤ t ≤ T} T≥1 with A Tt = (cid:80)T t=1α(t) (t =
Denote the cumulative distribution function as follow 1,...,T −1),A = Tα(T) . Then from (63) we derive
TT (cid:80)T α(t)
t=1
(cid:16) (cid:17)
G( jt)(z)≜Pr z j(t)(θ ∗,θ m)≤z 1 q(T+1)(θ∗)
G∗ j(z)≜Pr(cid:18) log ff jj (( yy jj || xx ∗∗ (( q˜q˜ )) ,, θθ m∗)
)
≤z(cid:19) . Tl →im ∞
N
(cid:80)T t=1α(t) log q i(i T (cid:32)+1)(θ m)
T
= 1 (cid:88) lim 1 Tα(T)· 1 (cid:88) z(t)(θ∗,θ )
Then, since x(t) →x∗(q˜) as t→∞ and by the continuity of N T→∞(cid:80)T α(t) T j k
j j=1 t=1 t=1
the likelihood function (Assumption 1), we have T−1 t (cid:33)
+(cid:88) t(cid:16) α(t)−α(t+1)(cid:17) · 1(cid:88) z(τ)(θ∗,θ )
lim G(t)(z)=G∗(z), ∀z ∈R. (64) t j m
t→∞ j j t=1 τ=1
N T
For any sequence of realized outcomes {(x(t),y(t))}∞ , = 1 (cid:88) lim (cid:88) A Y .
we define a sequnece of random variable
{∆(tj )}∞j
,
wht= er1
e
N j=1T→∞
t=1
Tt t
j t=112
By noticing that
(cid:80)T
A =1, and the almost sure conver- Theorem 4 Let Assumptions 1-5 hold. Consider Algorithm 1
t=1 Tt
genceof{Y }from(66),weconcludefromLemma9thatthe holdwiththestepsizeα(t) oforderO(1).Thenforeveryagent
t t
following holds almost surely. i∈N,
lim x(t) =x , a.s.
1 q(T+1)(θ∗) t→∞ i ∗
lim log i
T→∞(cid:80)T t=1α(t) q i(T+1)(θ m) IV. EXPERIMENTS
N T
= 1 (cid:88) lim 1 (cid:88) z(t)(θ∗,θ ) In this section, we provide numerical examples to demon-
N T→∞T j m strate our theoretical analysis. One is the near-sharp quadratic
j=1 t=1 problem, and the other is a more realistic scenario of source
 
( =66)E 
1 (cid:88)N
log
f j(y
j
|x∗(q˜),θ∗)
 (67)
searching.
N f (y |x∗(q˜),θ )
j j m
j=1
A. Near-sharpQuadraticProblem
N
= 1 (cid:88) D (f (y |x∗(q˜),θ∗)∥f (y |x∗(q˜),θ )). Consider the following near-sharp quadratic problem:
N KL j j j j m
j=1 1 (cid:88)N
min ∥θ x−d ∥2, (70)
By recalling Assumption 5, we obtain Z(θ ,θ ) ≜ x∈Rp N ∗ i
∗ m i=1
1 (cid:80)N D (f (y |x∗(q˜),θ∗)∥f (y |x∗(q˜),θ )) > 0.
N j=1 KL j j j j m where d = e 1 and e is the i-th smallest eigenvalue of the
Therefore, (67) indicates that for all ϵ>0, there exists T′(ϵ) i i i
W. Set Θ = {1,2.5,4} and θ = 2.5. For all agent i, the
such that for all T >T′, ∗
realized date is obtained from (6), where ϵ ∼N(0,1).
i
(cid:12) (cid:12)
(cid:12) 1 q(T+1)(θ∗) (cid:12) Considering five agents communicate under path topology,
(cid:12) (cid:12) (cid:12)(cid:80)T t=1α(t) log q i(i T+1)(θ m) −Z j(θ ∗,θ m)(cid:12) (cid:12) (cid:12)≤ϵ a.s. w che ou ses neA aslg αo (r ti )th =m1 1t 0o .so Sl ev te tt hh ee wpr eo ib gl he tm ed( a7 d0 j) aw cei nth cyth me ast te rip xsi bz ye
t+80
As a result, Metropolis-Hastings rules [31]. We show the average beliefs
q¯(t) = 1(cid:80)5 q(t) of five agents for the three possible pa-
q i(T+1)(θ m) ≤exp(cid:32) −(cid:88)T α(t)(cid:0)
Z(θ ,θ
)−ϵ(cid:1)(cid:33)
a.s.
rameters5 in Fi= ig1 uri e 1, and the gap between each agent’s belief
q i(T+1)(θ∗)
t=1
∗ m q i(t)(θ ∗)andaveragebeliefq¯(t)(θ ∗),i.e.q i(t)(θ ∗)−q¯(t)(θ ∗)for
(68) all i ∈ N in Figure 2. From Figure 1, we can see that the
posterior probability of true parameter converge to 1 and the
Using the fact that (cid:80)M m=1q iT+1(θ m)=1, we obtain probability of fake parameter decrease to 0, which means the
(cid:32) T (cid:33) averagebeliefsequencegeneratedbyourAlgorithmconverges
1 −1≤ (cid:88) exp −(cid:88) α(t)(Z(θ ,θ )−ϵ) , a.s. tothetrueparameter.Figure2showsthatthegapbetweeneach
q(T+1)(θ∗) ∗ m agent’sbeliefofthetrueparameterandtheaveragebeliefis0
i θm̸=θ∗ t=1
at the very beginning, which is because we set q(0) = 1 1
Furthermore, we derive i M M
for all i ∈ N in the algorithm initialization. As the iteration
1+(cid:80) θm̸=θ∗exp(cid:16) −(cid:80)T t1 =1α(t)(cid:0) Z(θ∗,θm)−ϵ(cid:1)(cid:17) ≤q i(T+1)(θ∗)≤1, a.s.o fuf llt yhe coa mlg mor ui nth icm atep dro wce ie thds, itsin nit eia igll hy boe ua rc sh ta oge inn tt egh ra as teno gt loy be at l
(69) information, and thus cannot reach consensus. Gradually, all
agents beliefs get consensus to the true parameter.
Because of (cid:80)T α(t) → ∞, then qt(θ ) → 1 a.s. We then
t=1 i ∗
concludefromTheorem1thatq˜ =q∗,whereinvectorq∗(θ)
1 0.2
only q(θ )=1, while other q(θ )| =0. 0.9
FTFa arkukeee PPPaaarrraaammmeeettteeerrr 1
2 0.15
∗ m θm̸=θ∗ 0.8
Besides, since in (68) ϵ is arbitrary and q(T+1)(θ∗) ≤ 1, 0.7 0.1
we ca qn (To +b 1t )ai (n θth )a ≤t fo exr pan (cid:32)y −i Z∈ (θN ,, θθ
m
)̸= (cid:88)Tθ
∗
α, (ti
)(cid:33)
a.s.
ytilibaborP
tsoP
00000 ..... 23456 eulaV
paG
-0
0
-. 0.0
0
.5
10
5
i m ∗ m 0.1 -0.15
t=1 00 0.2 0.4 0.6 0.8 Itera1 tions1.2 1.4 1.6 1.8 1042 -0.2 100 101 102
Iterations
103 104
This completes the assertion of the theorem.
Fig. 1. The average belief of Fig. 2. The gap between av-
Remark 3. Since the stepsize α(t) is of order O(1),
t five agents for three candidate erage belief and each agent’s
we conclude (cid:80)T α(t) = O(ln(t)). As a result, based on parameters beliefoftrueparameter
t=1
Theorem3,wecanobtainthatforeachagenti∈N andθ ̸=
m
θ ,thebeliefsequencecanreachasublinearconvergencerate, Furthermore, the adaptive decision sequences of all agents
∗
i.e. q(T+1)(θ )=O(1/T). arepresentedinFigure3.Wecanseethatfiveagents’decision
i m
Overall, recalling that x∗(q∗) = x , Theorem 2 together reach consensus to the true optimal decision.
∗
Theimpactofstepsizes.Besides,weimplementAlgorithm
withTheorem3impliesthatthealgorithmconvergestoitstrue
1 with different stepsizes to explore their impact on the
optimal solution x . We formalize it in the following result.
∗
algorithm convergence. The beliefs of the true parameter with13
1 Let x=(x 1,x 2) denote the localization of sampling water
Agent 1
0.9 A Ag ge en nt t 2 3 and θ = (β 1,β 2) be the pollution source localization. Under
Agent 4 stablesourcestrengthandstaticwaterconditions,thepollution
0.8 Agent 5
True Decision
source forms a stable field which is the Gauss model of
0.7
continuous point source diffusion in unbounded space [36]
noisiceD00 .. 56
that can be formulated as
stnegA0.4 c(x=(x 1, (cid:18)x 2); (θ x= −(β β1, )β 22))
(x −β
)2(cid:19)
0.3 =c exp − 1 1 − 2 2 , (71)
0 2σ2 2σ2
0.2 1 2
where c is the initial constant concentration of pollution
0.1 0
source; σ and σ denote the lateral diffusion parameter and
1 2
0
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5 the longitudinal diffusion parameter, respectively.
Iterations 104
Five WSAs try to find the source by optimizing the aggre-
Fig.3. DecisionconvergenceofallagentsunderAlgorithm1 gation function collaboratively
5
1(cid:88)
min −c (x;θ ). (72)
stepsizes α(t) = 1 , 1 , 10 are shown in Figure 4. Since x 5 i ∗
t+3 t+5 t+80 i=1
10 > 1 > 1 for any t ≥ 6, and (cid:80)T 10 >
(cid:80)t+8 T t=0
1
t+1 3t+ >3 (cid:80)T t=t+ 15 t+1
5
for any T ≥ 15. Bat s= e1 dt+ o8 n0 the w loh ce ar lie zac ti ioi ns od fe dfi in ffe ed renin ta( g7 e1 n) tsw .Tith hed ii nf if te ir ae ln lt ocx ai l, izw ath ioic nh sois ffith vee
convergence rate (59) of beliefs, we can obtain that as T → WSAs are (−2,0),(−0.5,3),(2,4),(4,−1),(1,−3), respec-
∞, algorithm implement with stepsize 10 converge faster tively. Three possible pollution source is θ = (0,0),θ =
t+80 1 2
than others. Whereas at the beginning when T is small, due (4,3),θ =(2,−2), where θ =θ . Set c =100,σ =σ =
to (cid:80)T t=1 t+1 3 > (cid:80)T t=1 t+10 80, algorithm with stepsize t+1 3 2, and ϵ3 i ∼N(0,1). ∗ 1 0 1 2
performs better. The theoretical results match the numerical The five WSAs use Algorithms 1 to identify the true
results in Figure 4. Generally speaking, algorithm with bigger location of the target and adaptively move towards the center
stepsize leads to faster convergence rate as data information of the pollution source by sampling the water quality at their
used is much more efficient than prior information due to currentlocation.Themotiontrajectoriesofthefiveparticipants
Equation (2). are shown in Figure 6. It can be observed that all sensing and
Different distributed consensus protocol comparison. actuation devices first achieve consensus and then coopera-
We further carry out simulations to compare the classical tivelylocatetherealpollutionsource.Theexperimentalresults
distributed linear consensus protocol [31] with (3) which alignwiththeoreticalanalysis,indicatingafasterconvergence
implements distributed consensus averaging on a reweighting speedforconsensuscomparedtotheoptimizationconvergence
of the log-belief. The result demonstrated in Figure 5 shows speed.
that the log-belief is faster than linear consensus, which is
consistent with the theoretical discussions in Remark 2.
1
1
retemaraP
eurT
eht
fo ytilibaborP
tsoP00000000 ........ 23456789
retemaraP
eurT
eht fo ytiltibaborP
tsoP00000000 ........ 23456789
LLoinge Caro nCsoennsseunssus
R the ea oc ph
t
c imon as
l
e sn os lu us
ti
ofi nrs tt o, gth ee thn
e
f ri
.
nd
0.1
0.1
00 0.5 1 1.5 2 Iter2 a. t5 ions 3 3.5 4 4.5 1045 00 0.5 1 1.5 2 2.5 3
Iterations 104
Fig.4. Theimpactofstepsizes
Fig. 5. Comparison between
on the convergence rate of the
log-beliefandlinearconsensus
trueparameter’sbelief
B. SourceResearch
In addition, we conduct experiments on the problem of Fig.6. Motiontrajectoriesofagentsinsensorpollutioncleanproblem
an ideal source localization and cleanup for a pollution
source. Consider distributed wireless sensor and actor net-
works(WSANs)withfivedevicesthatarecapableofsampling V. CONCLUSION
waterquality,processingthedata,andmakingdecisionsofthe This work has provided valuable insights for addressing
source localization based on the observations. parameteric uncertainty in distributed optimization problems14
and simultaneously found the optimal solution. To be more [16] AngeliaNedic´ andAsumanOzdaglar. Distributedsubgradientmethods
specific, a general mathematical framework which considers formulti-agentoptimization. IEEETransactionsonAutomaticControl,
54(1):48–61,2009.
learning the unknown parameter of model whereas adaptive
[17] Minghui Zhu and Sonia Martínez. On distributed convex optimization
distributed optimization has been considered, different from underinequalityandequalityconstraints. IEEETransactionsonAuto-
prior work with exact parametric structure. We have designed maticControl,57(1):151–164,2011.
[18] Giuseppe Notarstefano, Ivano Notarnicola, and Andrea Camisa. Dis-
a novel distributed fractional Bayesian learning algorithm
tributed optimization for smart cyber-physical networks. Foundations
to resolve the bidirectional coupled problem. We then have andTrendsinSystemsandControl,7(3):253–383,2020.
proved that agents’ beliefs about the unknown parameter [19] HesamAhmadiandUdayVShanbhag.Ontheresolutionofmisspecified
convex optimization and monotone variational inequality problems.
converge to a common belief, and that the decision variables
ComputationalOptimizationandApplications,77(1):125–161,2020.
alsoconvergetotheoptimalsolutionalmostsurely.Itisworth [20] Shijie Huang, Jinlong Lei, and Yiguang Hong. Distributed non-
noting from the numerical experiments that by utilizing the bayesianlearningforgameswithincompleteinformation.arXivpreprint
arXiv:2303.07212,2023.
consensus protocol which averages on a reweighting of the
[21] ManxiWu,SaurabhAmin,andAsumanOzdaglar.Multi-agentbayesian
log-belief, we have attained faster than normal distributed learning with adaptive strategies: Convergence and stability. arXiv
linear consensus protocol. In future, it is of interests to adapt preprintarXiv:2010.09128,2020.
[22] Pier Giovanni Bissiri, Chris C Holmes, and Stephen G Walker. A
the proposed method into real-world situations, and further
generalframeworkforupdatingbeliefdistributions.JournaloftheRoyal
investigate the bidirectional coupled distributed optimization StatisticalSocietySeriesB:StatisticalMethodology,78(5):1103–1130,
problems with continuous unknown model parameters. 2016.
[23] Pooya Molavi, Alireza Tahbaz-Salehi, and Ali Jadbabaie. Foundations
of non-bayesian social learning. Columbia Business School Research
Paper,2017.
REFERENCES
[24] Larry G Epstein, Jawwad Noor, and Alvaro Sandroni. Non-
bayesian learning. The BE Journal of Theoretical Economics,
10(1):0000102202193517041623,2010.
[25] AnirbanBhattacharya,DebdeepPati,andYunYang.Bayesianfractional
[1] Angelia Nedic´. Distributed gradient methods for convex machine
posteriors. TheAnnalsofStatistics,1(2):209–230,2019.
learning problems in networks: Distributed optimization. IEEE Signal
[26] Anusha Lalitha, Tara Javidi, and Anand D Sarwate. Social learning
ProcessingMagazine,37(3):92–101,2020.
and distributed hypothesis testing. IEEE Transactions on Information
[2] SulaimanA.AlghunaimandAliH.Sayed. Distributedcoupledmultia-
Theory,64(9):6161–6179,2018.
gentstochasticoptimization. IEEETransactionsonAutomaticControl,
[27] ShiPu,AlexOlshevsky,andIoannisChPaschalidis. Asharpestimate
65(1):175–190,2020.
on the transient time of distributed stochastic gradient descent. IEEE
[3] PeterTrautmanandAndreasKrause.Unfreezingtherobot:Navigationin TransactionsonAutomaticControl,67(11):5900–5915,2021.
dense,interactingcrowds. In2010IEEE/RSJInternationalConference
[28] ZifeiHan,KeyingYe,andMinWang. Astudyonthepowerparameter
onIntelligentRobotsandSystems,pages797–803.IEEE,2010.
inpowerpriorbayesiananalysis. TheAmericanStatistician,77(1):12–
[4] MakramChahine,RoyaFiroozi,WeiXiao,MacSchwager,andDaniela 19,2023.
Rus. Intention communication and hypothesis likelihood in game- [29] Peter Grünwald. The safe bayesian: learning the learning rate via
theoretic motion planning. IEEE Robotics and Automation Letters, the mixability gap. International Conference on Algorithmic Learning
8(3):1223–1230,2023. Theory,pages169–183,2012.
[5] GerardCornuejolsandRehaTütüncü. Optimizationmethodsinfinance, [30] Angelia Nedic´, Alex Olshevsky, and César A Uribe. A tutorial on
volume5. CambridgeUniversityPress,2006. distributed (non-bayesian) learning: Problem, algorithms and results.
[6] Craig Wilson, Venugopal V Veeravalli, and Angelia Nedic´. Adaptive 2016 IEEE 55th Conference on Decision and Control (CDC), pages
sequential stochastic optimization. IEEE Transactions on Automatic 6795–6801,2016.
Control,64(2):496–509,2018. [31] Lin Xiao and Stephen Boyd. Fast linear iterations for distributed
[7] Nam Ho-Nguyen and Fatma Kılınç-Karzan. Exploiting problem struc- averaging. Systems&ControlLetters,53(1):65–78,2004.
ture in optimization under uncertainty via online convex optimization. [32] DaronAcemoglu,MuntherADahleh,IlanLobel,andAsumanOzdaglar.
MathematicalProgramming,177(1-2):113–147,March2018. Bayesianlearninginsocialnetworks. TheReviewofEconomicStudies,
[8] Simon Le Cleac’h, Mac Schwager, and Zachary Manchester. Lu- 78(4):1201–1236,2011.
cidgames:Onlineunscentedinversedynamicgamesforadaptivetrajec- [33] Angelia Nedic´, Asuman Ozdaglar, and Pablo A Parrilo. Constrained
tory prediction and planning. IEEE Robotics and Automation Letters, consensusandoptimizationinmulti-agentnetworks.IEEETransactions
6(3):5485–5492,2021. onAutomaticControl,55(4):922–938,2010.
[9] GraemeBestandRobertFitch. Bayesianintentioninferencefortrajec- [34] Yurii Nesterov. Introductory lectures on convex optimization: A basic
tory prediction with an unknown goal destination. In 2015 IEEE/RSJ course,volume87. SpringerScience&BusinessMedia,2013.
International Conference on Intelligent Robots and Systems (IROS), [35] Konrad Knopp. Theory and Application of infinite series. Courier
pages5817–5823.IEEE,2015. Corporation,1990.
[10] Hao Jiang and Uday V Shanbhag. On the solution of stochastic [36] Yngvar Gotaas. A model of diffusion in a valley from a continuous
optimizationandvariationalproblemsinimperfectinformationregimes. pointsource. ArchivfürMeteorologie,GeophysikundBioklimatologie,
SIAMJournalonOptimization,26(4):2394–2429,2016. SerieA,21(1):13–26,1972.
[11] Necdet Serhat Aybat, Hesam Ahmadi, and Uday V Shanbhag. On the [37] LéonBottou,FrankECurtis,andJorgeNocedal.Optimizationmethods
analysisofinexactaugmentedlagrangianschemesformisspecifiedconic forlarge-scalemachinelearning. SIAMreview,60(2):223–311,2018.
convexprograms.IEEETransactionsonAutomaticControl,67(8):3981–
3996,2021.
APPENDIX I
[12] HesamAhmadiandUdayVShanbhag.Ontheresolutionofmisspecified
convex optimization and monotone variational inequality problems. PROOF OF LEMMA 3
ComputationalOptimizationandApplications,77(1):125–161,2020. Proof: With the definition (25), we obtain that
[13] Aswin Kannan, Angelia Nedic´, and Uday V Shanbhag. Distributed
stochastic optimization under imperfect information. 2015 54th IEEE F (x,q )=q (θ )J (x,θ )+···+q (θ )J (x,θ ). (73)
ConferenceonDecisionandControl(CDC),pages400–405,2015. i i i 1 i 1 i M i M
[14] IvanoNotarnicola,AndreaSimonetto,FrancescoFarina,andGiuseppe Then by recalling from Assumption 4 that for every θ ,
m
Notarstefano. Distributed personalized gradient tracking with con-
vex parametric models. IEEE Transactions on Automatic Control, J (λx+(1−λ)y,θ )≤λJ (x,θ )+(1−λ)J (y,θ )
i m i m i m
68(1):588–595,2023. µ
[15] NianLiuandLeiGuo. Stochasticadaptivelinearquadraticdifferential − λ(1−λ)∥x−y∥2. (74)
games. arXivpreprintarXiv:2204.08869,2022. 215
Hence, for all x,y ∈R and λ∈(0,1). Since {α(t)} is a decreasing stepsize to zero, then there
t≥0
(cid:2) existsaconstantT >0suchthatforallt≥T,α(t) ≤ µ .
F (λx+(1−λ)y,q )≤q (θ ) λJ (x,θ )+(1−λ)J (y,θ ) 2M2L2
i i i 1 i 1 i 1 Hence, for any t≥T,
−
µ λ(1−λ)∥x−y∥2(cid:3)
+···+q (θ
)(cid:2)
λJ (x,θ )
2 i M i 1 ∥x(t)−α(t)∇ F (x(t),q(t))−x∗(q˜)∥2
+(1−λ)J i(y,θ 1)−
µ 2λ(1−λ)∥x−y∥2(cid:3) i ≤(1−x αi (t)i µ)∥xi
(t)−x∗(q˜)∥2
(cid:104) (cid:105) i √
=λ q (θ )J (x,θ )+···+q (θ )J (x,θ ) +2α(t)∥∇ J (x∗(q˜),θ)∥ M∥x(t)−x∗(q˜)∥
i 1 i 1 i m i m x i i
+(1−λ)(cid:104) q i(θ 1)J i(y,θ 1)+···+q i(θ m)J i(y,θ m)(cid:105) +α(t) Mµ L2∥∇ xJ i(x∗(q˜),θ)∥2
−(cid:0) q (θ )+···+q (θ )(cid:1)µ λ(1−λ)∥x−y∥2 ≤∥x(t)−x∗(q˜)∥2−α(t)(cid:104) µ∥x(t)−x∗(q˜)∥2
i 1 i m 2 √i i
=λF i(x,q i)+(1−λ)F i(y,q i)− µ 2λ(1−λ)∥x−y∥2. −2 µM∥∇ xJ i(x∗(q˜),θ)∥∥ (cid:105)x( it)−x∗(q˜)∥
− ∥∇ J (x∗(q˜),θ)∥2 . (80)
It indicates that F i(x,q i) is strongly convex in x with a ML2 x i
constant µ.
Let us define
As for the properties of Lipschitz continuous gradients, by √
using Assumption 4, we derive from [37] that X ≜{p≥0:µp2−2 M∥∇ J (x∗(q˜),θ)∥p
i x i
µ
∇2J (x,θ )≤L,∀θ ∈Θ, (75) − ∥∇ J (x∗(q˜),θ)∥2 ≤0}, (81)
x i m m ML2 x i
Then
which is non-empty and compact. If ∥x(t)−x∗(q˜)∥∈/ X, we
∇2 xF i(x,q i)=q i(θ 1)∇2 xJ i(x,θ 1)+···+q i(θ M)∇2 xJ i(x,θ M) conclude from (80) that i
≤q (θ )L+···+q (θ )L=L (76)
i 1 i M ∥x(t)−α(t)∇ F (x(t),q(t))−x∗(q˜)∥2 ≤∥x(t)−x∗(q˜)∥2.
i x i i i i
where the last equality holds since the sum of belief is 1. (82)
APPENDIX II Otherwise,
PROOF OF LEMMA 6 ∥x(t)−α(t)∇ F (x(t),q(t))−x∗(q˜)∥2 ≤
xw ∗e (q˜fi )P r ∥sr 2to lyo ff o: c roF ano ls lr id ia en ∈ry Nbt o≥ .un0 d, ii nn go ∥rd xe ( ir t)to −bo αu (tn )d ∇∥ xx F( it () x− ( i1 t)x ,q∗( ( iq˜ t)) )∥ −2, i m p −∈a Xx i µ(cid:110) p2 ∥x − ∇i 2 JMi µ (2 xL ∗2 (i q˜(cid:2) µ ),p θ2 )− ∥22 (cid:3)√ (cid:111)M∥∇ xJ i(x∗(q˜),θ)∥p
∥x(t)−α(t)∇ F (x(t),q(t))−x∗(q˜)∥2 ML2 x i
i x i i i (cid:110) µ∥∇ J (x∗(q˜),θ)∥
=∥x( it)−x∗(q˜)∥2+[α(t)]2∥∇ xF i(x( it),q( it))∥2 =m p∈a Xx
i
(1− 2Mµ2 L2)p2+ x Mi
1.5L2
p
−2α(t)∇ F (x(t),q(t))T(x(t)−x∗(q˜)) µ2∥∇ J (x∗(q˜),θ)∥2(cid:111)
x i i i i + x i . (83)
≤∥x(t)−x∗(q˜)∥2+[α(t)]2∥∇ F (x(t),q(t))∥2 2M3L4
i x i i i
From the definition of X , the right zero point of the upward
−2α(t)(cid:0) ∇ F (x(t),q(t))−∇ F (x∗(q˜),q(t))(cid:1)T (x(t)−x∗(q˜)) i
x i i i x i i i opening parabola in (81) is
+2α(t)∥∇ xF i(x∗(q˜),q( it))∥∥x( it)−x∗(q˜)∥
1
(cid:32)
√
≤(1−2α(t)µ)∥x i(t)−x∗(q˜)∥2+[α(t)]2∥∇ xF i(x( it),q( it))∥2 p( ir) =
2µ
2 M∥∇ xJ i(x∗(q˜),θ)∥
+2α(t)∥∇ F (x∗(q˜),q(t))∥∥x(t)−x∗(q˜)∥ (77) (cid:114) (cid:33)
x i i i 4µ2
+ 4M∥∇ J (x∗(q˜),θ)∥2+ ∥∇ J (x∗(q˜),θ)∥2
where the last inequality follows by the strong convexity of x i ML2 x i
F i(x,q) with x in Lemma 3. (cid:32)√ (cid:114) (cid:33)
Then similarly to the derivation of (49) and (51), we have M 2 M2L2+1
= + ∥∇ J (x∗(q˜),θ)∥, (84)
∥∇ F (x(t),q(t))∥2 ≤ µ L M x i
x i i i
2M∥∇ J (x∗(q˜),θ)∥2+2M2L2∥x(t)−x∗(q˜)∥2 (78) which means X = [0,p(r)]. Since the values of quadratic
x i i i i
function is bounded in a bounded closed set, we define
and
∥∇ xF i(x∗(q˜),q( it))∥2 ≤M∥∇ xJ i(x∗(q˜),θ)∥2. (79) m p∈a Xx i(cid:110) (1− Mµ L2 2)p2+ µ∥∇ xJ Mi( 1x .5∗ L( 2q˜),θ)∥ p
Substituting (78) and (79) into (77), we can obtain µ2∥∇ J (x∗(q˜),θ)∥2(cid:111)
+ x i ≜R . (85)
∥x(t)−α(t)∇ F (x(t),q(t))−x∗(q˜)∥2 2M3L4 i
i x i i i
≤(1−2α(t)µ+2M2L2[α(t)]2)∥x(t)−x∗(q˜)∥2 Combining (82) and (83), together with (85), we have
√ i
+2α(t)∥∇ xJ i(x∗(q˜),θ)∥ M∥x( it)−x∗(q˜)∥ ∥x( it)−α(t)∇ xF i(x( it),q( it))−x∗(q˜)∥2
+2M[α(t)]2∥∇ J (x∗(q˜),θ)∥2. ≤max{∥x(t)−x∗(q˜)∥2,R }, ∀t≥T. (86)
x i i i16
Recallingfromthedefinitionofx(t) andF(x(t),Q(t))in(29) Since δ ∈(0,1), we derive
and (33) respectively, in light of relation (28) we have
t
(cid:88) 1
lim δτ = , (91)
∥x(t+1)−1x∗(q˜)∥2 t→∞ 1−δ
τ=0
=∥W∥2∥x(t)−α(t)F(x(t),Q(t))−1x∗(q˜)∥2 t ∞ (cid:32) ∞ (cid:33)′
(cid:88) (cid:88) (cid:88) δ
≤∥x(t)−α(t)F(x(t),Q(t))−1x∗(q˜)∥2 tl →im
∞
τδτ =δ τδτ−1 =δ δτ = (1−δ)2.
τ=1 τ=1 τ=0
(86) (cid:88)N (92)
≤ max{∥x(t)−1x∗(q˜)∥2, R }, ∀t≥T,
i
Moreover, due to
i=1
where thefirst inequalityholds bythe 2-norm ofW is 1 from (cid:32) (cid:88)t (cid:33)′′ (cid:88)t (cid:88)t (cid:88)t
δτ = τ(τ −1)δτ−2 = τ2δτ−2− τδτ−2,
Assumption 2. As a result,
τ=1 τ=2 τ=2 τ=2
(cid:110) (cid:88)N (cid:111) we can obtain that
∥x(t)−1x∗(q˜)∥2≤max ∥x(T)−1x∗(q˜)∥2, R i . (87) t (cid:32) t (cid:33)′′ t 
i=1 (cid:88) τ2δτ =δ2  (cid:88) δτ + 1(cid:88) τδτ−1−1+δ,
(cid:16) (cid:16) (cid:17)(cid:17) δ
Note that x(t+1) = W x(t)−α(t)∇ F x(t),Q(t) τ=1 τ=1 τ=1
x
from (28) based on the vector form of x and F in (29) and and therefore
(33). Since each belief value q( it)(θ) is bounded by 1 for all (cid:88)t (cid:20)
2 1
(cid:21)
t ≥ 0 and i ∈ N, Q(t) defined in (31) is bounded. This lim τ2δτ =δ2 + −1 +δ
together with the continuity of ∇ xF under Assumption 4, we t→∞ τ=1 (1−δ)3 δ(1−δ)2
conclude that for a fixed constant T, x(T) is bounded. This δ(1+δ)
= +δ(1−δ). (93)
together with (87) proves the lemma. (1−δ)2
Substituting (91), (92), and (93) into (90), we can get the
APPENDIX III upper bound of Term 5. Together with (89) of Term 4 and
PROOF OF LEMMA 7 recalling (88), we acheive
Proof: According to the recursion (53), we have e(t+1) (cid:20) δ2(δ+3) 2δ (cid:21)
0≤ lim ≤c 1+ + .
t
t→∞[α(t)]2 T2(1−δ)2 T2(1−δ)
(cid:88)
e(t+1) ≤δt+1e(0)+c δt−τ[α(τ)]2.
Thus, e(t+1) =O([α(t)]2)=O(1), which yields the conclu-
t2
τ=0 sion.
Since α(t) is of order O(1), without loss of generality we set
t
α(t) = γ with a constant γ >0 and T >0. Dividing both
t+T
side of above inequality by [α(t)]2, we have
e(t+1) δt+1 (cid:88)t (cid:20) α(τ)(cid:21)2
≤ e(0)+c δt−τ
[α(t)]2 [α(t)]2 α(t)
τ=0
e(0) δt+1 (cid:88)t (cid:18) t+T (cid:19)2
= · +c δt−τ . (88)
γ2 1 τ +T
(t+T)2 τ=0
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Term 4 Term 5
As for Term 4, since 1 > 1 by δ ∈ (0,1), we can obtain
that δ
δt+1 (t+T)2
lim = lim =0. (89)
t→∞ 1 t→∞ (1)t
(t+T)2 δ
As for Term 5, we have
(cid:88)t (cid:18)
t−τ
(cid:19)2
Term 5=c δt−τ 1+
τ +T
τ=0
(cid:88)t (cid:18) 2(t−τ) (t−τ)2 (cid:19)
=c δt−τ 1+ +
τ +T (τ +T)2
τ=0
t t t
(cid:88) 2c(cid:88) c (cid:88)
≤c δτ + τδτ + τ2δτ. (90)
T T2
τ=0 τ=1 τ=1