Reuse Your Rewards:
Reward Model Transfer for Zero-Shot Cross-Lingual Alignment
ZhaofengWu(cid:227) AnanthBalashankar(cid:229) YoonKim(cid:227) JacobEisenstein AhmadBeirami(cid:229)
(cid:227)MIT (cid:229)GoogleResearch GoogleDeepMind
zfw@csail.mit.edu
Abstract
Aligning language models (LMs) based on
human-annotatedpreferencedataisacrucial
stepinobtainingpracticalandperformantLM-
basedsystems. However,multilingualhuman
preferencedataaredifficulttoobtainatscale,
making it challenging to extend this frame-
work to diverse languages. In this work, we
evaluateasimpleapproachforzero-shotcross-
lingual alignment, where a reward model is
trained on preference data in one source lan-
Figure 1: Cross-lingual reward model (RM) transfer.
guageanddirectlyappliedtoothertargetlan-
Toaligninatargetlanguage(inthisexample,Spanish),
guages. On summarization and open-ended
common monolingual alignment uses a RM for that
dialoggeneration,weshowthatthismethodis
target language. Instead, we re-purpose a RM for a
consistently successful under comprehensive
differentsourcelanguage(inthisexample,English).
evaluation settings, including human evalua-
tion: cross-lingually aligned models are pre-
ferredbyhumansoverunalignedmodelsonup
to>70%ofevaluationinstances. Wemoreover
find that a different-language reward model
sometimes yields better aligned models than
asame-languagerewardmodel. Wealsoiden-
tifybestpracticeswhenthereisnolanguage-
specific data for even supervised finetuning,
anothercomponentinalignment.
1 Introduction
Alignmenthasbecomeanindispensablestagefor
buildingpracticallanguagemodels(LMs)adjusted
to human preferences. This additional step, how-
ever,makesitchallengingtodevelopLMsformany
languages: unlikeforautoregressivelanguagemod-
eling where multilingual unlabeled data may be
easytoobtain(Joshietal.,2020),suchasreligious
Figure2: Performingtarget-languagealignmentus-
texts(ChristodouloupoulosandSteedman,2015),
ingaRMforadifferentsourcelanguageimproves
labeledpreferencedatacanbeexpensivetogather. performance,whenevaluatedexclusivelyinthetar-
HowdowealignaLMinatargetlanguagewithout getlanguage. Thisimprovementissometimeseven
anypreferencedatainthatlanguage? largerthanusingthetarget-languageRM(monolin-
gualalignment). Herewemeasurethewinrateagainst
We propose a novel reward model (RM) trans-
thetarget-language(unaligned)SFTmodeljudgedby
fer setup, where we re-purpose a trained RM for
humans,andthe95%confidenceintervalacrossvalida-
some source language to align a LM in a target
tioninstances. “source→target“denotesusingasource-
languageRMtodrivealignmentinthetargetlanguage.
WorkdonewhileZWwasapart-timeinternatGoogle.
4202
rpA
81
]LC.sc[
1v81321.4042:viXra
(cid:229)
(cid:229)language(Figure1). Acrosstwotasks(summariza- classifiertrainedusingthecross-entropyloss,
tionandopen-endeddialoggeneration),tworeward
−E [zlogσ(r(x,y))+
optimizationmethods(reinforcementlearningand (x,y,z)∼DRM
best-of-n reranking), and various evaluation set- (1−z)log(1−σ(1−r(x,y)))].
tings, we demonstrate substantial and consistent
2. Pairwisefeedbackchoosesabettergeneration
zero-shotcross-lingualutilityofRMs. Surprisingly,
out of two. We denote the chosen one as y
w
alignment using a different-language RM some-
and the other as y . To train a pointwise RM
l
timesoutperformsusingasame-languageRM,both
onsuchdata,theBradley-Terrymodel(Bradley
whenjudgedbyhumansandLMs. Wealsodemon-
andTerry,1952)isoftenused,maximizing
stratethatourRMtransferframeworkisstilluseful
evenwhentarget-languagedataforsupervisedfine- E (x,yw,y l)∼DRM[logσ(r(x,y w)−r(x,y l))].
tuning(SFT),anothercomponentinalignment,is
Itisalsogeneralizabletomorethantwooutputs.
inaccessible.
OurresultsshowthatRMsignalsaregeneraliz- Therewardoptimizationstage alsoinitializes
ableandrobusttoinputdistributionchanges,which from π SFT and further adjusts the model outputs
could be leveraged for more future applications. using human feedback (as captured by the RM).
Practically,ourfindingspavethepathtowardslow- Twocommonmethodsarereinforcementlearning
eringthecostsfortraininganddeployingLMsthat (RL)andbest-of-n. Best-of-nisaninference-time
moreequitablyserveusersaroundtheworld. procedure that does not change the underlying
model, where multiple generations are sampled
from π and then reranked using the RM; the
2 Background: AlignmentFromHuman SFT
highest-scoringgenerationisreturnedastheoutput.
Feedback
InRL,themodelitselfischangedsuchthatitssam-
InadditiontotraditionalunsupervisedLMpretrain- plesarescoredhighlybytheRM,withtheobjective
ing, many recent LMs also include an alignment E [r(x,y˜)−
x∼DRO,y˜∼πθ(x)
phase to improve helpfulness, harmlessness, etc.,
β(logπ (y˜|x)−logπ (y˜|x))].
θ SFT
supervisedbyhumanfeedback(Baietal.,2022a;
DRO isadatasetofinputsandβ isaregularization
Ouyang et al., 2022; i.a.). A common recipe in-
hyperparameter. Theaboveistypicallyoptimized
cludes three stages: supervised finetuning (SFT),
with PPO (Schulman et al., 2017). While we
rewardmodeling(RM),andrewardoptimization.
generallyexperimentwithbothmethods,insome
Wegiveanoverviewofeachandreferreadersto
ofouranalyseswefocusonbest-of-nforaclean
Ouyangetal.(2022)andBaietal.(2022a)forde-
testbedwithoutconfoundersfromRLtraining.
tails. Weassumeabasemodelalreadypretrained
usingausuallynext-tokenpredictionobjective.
3 RewardModelTransferfor
Cross-LingualAlignment
The SFT stage initializes from the base model
andtakestaskinputsx ∈ X totrainthemodelto Thepipelinein§2isusuallyperformedmonolin-
simulate example outputs y ∈ Y. Specifically, it gually,commonlyinEnglish. Aligningforanew
optimizestheconditionallog-likelihoodofy given language requires both SFT data and RM data in
someinputx,similartoregularlanguagemodeling. thatlanguage. Whiletheformermayberelatively
WedenotethetrainedSFTmodelusingπ SFT. easiertoobtainduetoautomaticconstructionmeth-
ods,suchasbyre-purposingexistingmultilingual
TheRMstage trainsamodelr : X ×Y → Ras
datasets(Muennighoffetal.,2023)orbyeliciting
aproxyforhuman-judgedqualityofy underx. It from LMs (Wang et al., 2023c), RM data for a
initializesfromπ SFT andistrainedusingadataset newlanguagecanbemoreexpensivetogather,as
ofhumanjudgmentsofgenerations. Weconsider it in principle requires human judgments. Addi-
twotypesoffeedbacktotraintheRM: tionally, RM data should ideally be periodically
1. Pointwisefeedbackjudgesthequalityofasin- re-collectedtoavoidover-optimization(Baietal.,
gle generation; in particular we only consider 2022a),furtherincreasingdatademand. Thus,we
binary(goodorbad)pointwisejudgments. De- aremainlyinterestedinalignmentwithouttarget-
noting it as z ∈ {0,1} and letting DRM be a languageRMdata,though,in§5.3,weinvestigate
datasetofjudgments,theRMcanbeastandard dispensingwithtarget-languageSFTdatatoo.Weproposetoperformrewardoptimizationus- whichweconfirmedinourexperiments(Figure4).
ing a RM trained for a different language (Fig- Wethereforefocusonbest-of-nforthistask.
ure1). Intuitively,assumingmodelgenerationqual-
itytransferscross-lingually(e.g.,goodEnglishgen- Evaluation. Weassessmodelqualityacrosssev-
erations are still good when translated into Span- eral settings. First, we use the target-language
ish1),amodelthatcanjudgetheoutputqualityin RM,whichisbydesignfinetunedtojudgetarget-
onelanguageshouldgeneralizetoothers,aslong languagegenerationquality. Butbecauseofpoten-
astheRMunderstandsthelanguages,whichisen- tialRMbiases(Gaoetal.,2023;Costeetal.,2023;
abled by multilingual base model training. This Eisensteinetal.,2023),wealsoincludetwozero-
generalizabilityisoftenobservedforothertasksin shot-promptedevaluationmodelswithmuchlarger
thezero-shotcross-lingualtransferliterature(Wu backbones—GPT-4(OpenAI,2023)andPaLM-2-
andDredze,2019;Piresetal.,2019;Conneauetal., L(Aniletal.,2023). Thislatterevaluationsetupis
2020b; Hu et al., 2020; i.a.), and we expect it to commoninpriorworkandhasbeendemonstrated
work for RMs too. A simple baseline would be tocorrelatewellwithhumanjudgments(Leeetal.,
touseautomaticallytranslatedRMdata,towhich 2023; Rafailov et al., 2023; An et al., 2023; Mu
wecomparein§5.1. Inthispaper,weusesource et al., 2023; i.a.). We also confirm its validity in
languagetodenotetheRMlanguage,andtarget §5.1and§C.Finally,wealsoperformhumanevalu-
languageforthelanguageofthealignedmodel. ationsbyself-reportednativeoradvancedspeakers,
though only for a subset of language pairs and
4 ExperimentalSetup 250(RL)/100(best-of-n)instancesperpairdue
to its cost. For both human and LM evaluation,
Weconsidertwotasks: summarization,commonin
weelicitpairwisejudgmentstocompareresponses
alignmentresearch(Stiennonetal.,2020;Ziegler
from the aligned model and the SFT model (Bai
etal.,2020;Leeetal.,2023;i.a.),andopen-ended
et al., 2022b; Lee et al., 2023; i.a.). We measure
dialoggeneration,withsubstantialreal-worldrele-
thewinrate, i.e., howoften thejudgeprefers the
vance. §Adescribesdatasetdetailsand§Btraining
former. A50%winrateindicatesnoimprovement
details. §G.1containsourtaskinstructions.
fromalignment. §G.2includesmoredetailssuchas
Summarization. The Seahorse dataset (Clark theevaluationpromptsandpositionalbiascontrol.
etal.,2023)containsdocumentsandsummariesin
sixlanguages(German,English,Spanish,Russian, 5 Results
Turkish, and Vietnamese) with pointwise human
Here we report the results of cross-lingual align-
ratingswhichweuse. ForSFT,wegatherthedata
ment. See§Hfornumericalresultsthatcorrespond
sourcesofSeahorse: XSum(Narayanetal.,2018),
totheplotsinthissection.
XL-Sum (Hasan et al., 2021), MLSum (Scialom
etal.,2020),andWikiLingua(Ladhaketal.,2020).
5.1 Cross-LingualAlignmentIsEffective
WeusemT5-XL(Xueetal.,2021)asourmultilin-
gualbasemodel,with3.7Bparameters. Whenevaluatedbythefinetunedtarget-language
RM, Figure 3 shows that monolingual best-of-
Open-Ended Dialog Generation. We use the
n or RL always improves model quality, as ex-
OpenAssistantdataset(Köpfetal.,2023)withmul-
pected. Encouragingly,cross-lingualrewardopti-
tilingual, pairwise human-rated chat transcripts.
mizationimprovesovertheSFTmodelinallcases
FortheSFTdata,weusethehuman-preferredre-
too. Similarly,whenjudgedbyageneral-purpose
sponse in each pair to finetune the model. Many
LM, PaLM-2-L in Figure 4 and GPT-4 in §D, in-
languagesinOpenAssistanthaveonlylimiteddata,
language and cross-lingual reward optimization
soweonlyconsiderthreelanguageswiththemost
bothgenerallyimprovemodelquality. Importantly,
amounts of data: English, Spanish, and Russian.
weobservehighagreementbetweenthetwoLMs:
WeusePaLM-2-XXSasthebasemodel(Aniletal.,
onaninstancelevel,theyagree>70%acrosssetups
2023). TheauthorsofOpenAssistantfoundRLto
(see §D); if we consider how often they agree in
be ineffective for this dataset (Köpf et al., 2023),
therelativerankingoftwosourcelanguages,they
1Webelievethisisaweakassumption,thoughfortasksand agree78%forsummarization(bothbest-of-nand
instancesmoresubjecttoculture-specificfactors,generations
RL) and 100% for dialog generation (best-of-n).
maybejudgedmoredifferentlyacrosslanguages(Costaetal.,
2014;Hershcovichetal.,2022;Shwartz,2022). ThisindicatesthereliabilityofaLMjudge.Human evaluation (Figure 2) reveals the same Summarization Dialog
trend,thoughwithlargerconfidenceintervalsdue 5
to the cost. It also justifies LM-based evaluation. 4
For summarization, PaLM-2-L (GPT-4) agrees
3
with humans 65% (69%) of the time in English
2
and 66% (62%) in Spanish, matching the 63%
1 human-human agreement for English reference
summariesand67%forSpanishinSeahorse(Clark, 0
de en es ru tr vi en es ru
personalcommunication,April15,2024). Fordia-
Same-language RM Different-language RM
log,PaLM-2-L(GPT-4)agreeswithhumans69%
(a) Best-of-n
(59%) of the time in English and 62% (60%) in
Spanish, again similar to the 63% human-human Summarization
agreementinBaietal.(2022a)and66%inDubois German English
1 1
et al. (2024). With further evidence in §C, we
believe our LM judges reasonably reflect output 0 0
0 1000 2000 3000 0 1000 2000 3000
quality. Spanish Russian
1 1
We also compare our cross-lingual transfer
setuptoanalternativestrategy,sometimesdubbed 0 0
0 1000 2000 3000 0 1000 2000 3000
“translate-train” (Conneau et al., 2018; i.a.), that
Turkish Vietnamese
firsttrainsasilvertarget-languageRMbyautomat- 1 1
icallytranslatingthesource-languagedataandthen
0 0
usingthesilverRMfortarget-languagealignment. 0 1000 2000 3000 0 1000 2000 3000
Averagedacrossall30(= 62−6)cross-linguallan- Same-language RM Different-language RM
guagepairs,underbest-of-nandjudgedbyPaLM- (b) RL
2-L,ourRMtransferstrategyoutperformstranslate- Figure3: Cross-lingualalignmenteffectivenessjudged
train2 (averagewinrate58.8vs. 57.5;seeTable6 byafinetunedtarget-languageRMevaluator,measured
initsscoreincreasebetweenthealignedmodelandthe
and17forrawnumbers). RMtransferalsohasan
target-languageSFTmodel. Eachgroupin(a)andsub-
efficiencyadvantage: toaligninmultipletargetlan-
plotin(b)representsonetargetlanguage,anddifferent
guages,itsufficestotrainonesource-languageRM,
dots/lines within each represent different source lan-
ratherthandifferentonesforeachtargetlanguage.
guages. RLisdifficulttotrainforOpenAssistant(§4),
In §F, we also explore alignment using bilingual soweomitithere. Inmostcases,theRMevaluator
RMs with two source languages (Mulcaire et al., scoreimprovesforcross-linguallyalignedmodels.
2019),thoughwithoutnoticeableimprovements.
language words (due to bias in the RM training
5.2 Cross-LingualAlignmentSometimes data). A different-language policy model is un-
OutperformsMonolingualAlignment likely to exploit this, as it rarely generates these
words,butasame-languagepolicymodelmay.
Remarkably,cross-lingualrewardoptimizationof-
Thishypothesisisconsistentwithourobserved
ten yields an even better model than using the
patterns. First, there are many fewer cases of
target-language RM. This is validated by (1) the
cross-lingual reward optimization outperforming
consistent trend when evaluated by PaLM-2-L,
the monolingual setting when measured by the
GPT-4, and humans, (2) their instance-level and
finetuned target-language RM evaluator than the
ranking-levelagreement(§5.1),and(3)thesmall
promptedLMevaluators(Figure3): underthishy-
confidenceintervals. Thismaybeduetoaregular-
pothesis, the finetuned evaluator RMs would be
izationeffect: thetarget-languageRMmaypossess
moresusceptibletosuchartifactsand(incorrectly)
language-specificspuriousartifacts,towhichthe
assign higher scores in the monolingual settings.
target-languagepolicymodelcanoverfit(Gaoetal.,
Theunderperformanceofthetranslate-trainbase-
2023) more than artifacts in a different language
line(§5.1)alsoprovidesweakevidence: inprinci-
in the source-language RM. Suppose, for exam-
ple,asource-languageRMandasource-translated-
ple,thatthetarget-languageRMassignshigherre-
into-target-languageRMshouldcapturethesame
wardswhenthegenerationcontainscertaintarget-
reward signal, as they are derived from the same
2WhichweimplementusingGoogleTranslate. datasource,andwouldleadtosimilardownstream
esaercnI
erocS
MR
.gL-tegraT
esaercnI
erocS
MR
.gL-tegraTFigure4: Alignmenteffectiveness,comparedtothetarget-languageSFTmodeljudgedbyPaLM-2-L,andthe95%
confidenceintervalacrossvalidationinstances. “source→target“denotesasource-languageRMdrivingalignment
inthetargetlanguage. Cross-lingualalignmentisgenerallyeffective,sometimesoutperformingmonolingual
alignment. RLishardtotrainforOpenAssistant,inlinewithwhatitsauthorsfound(Köpfetal.,2023).
performance. However,theformerislesssuscepti- Translate. Weinvestigateifit,combinedwithRM
bletorewardover-optimizationduetothelanguage transfer,stillenablescross-lingualalignment. As
mismatch, leading to better performance, though acasestudy,weonlyconsidersummarizationand
thisisadmittedlyconfoundedbytranslationqual- whenEnglishisthesourceortargetlanguage.
ity. UsingtranslatedSFTdatasubstantiallydegrades
Corroboratingthishypothesis,wealsofindthat thequalityoftheSFTmodel(Figure5(a))andthe
whenusedmonolingually, theRMsbehavemore best-of-n-alignedLM(Figure5(b)). Therearehow-
likeabag-of-word(BoW)model. Wetakeeachof evertwofactors: (1)qualitylossduetotranslation,
the6summarizationRMsandinferonthevalida- and (2) domain/style mismatch. For (2), we note
tionsetofeachdatasetineachlanguage(Table1). thatdifferentlanguageshaveSFTdatacomposedof
Ineverysetting, wefitaBoWlinearregressorto differentdatasets,followingSeahorse(Table1).3
predict the RM-assigned score for each instance Andthesedatasetsdifferstylistically: forexample,
andcomputetheR2 acrossinstancesasaproxyfor while XSum includes news articles, WikiLingua
theRM’ssimilaritytoaBoWmodelinthatsetting. consistsofhow-toarticlesandwithmoreformulaic
For each dataset, and for every source language summaries. Therewouldthusbeadomaindiffer-
thatdiffersfromthedataset’slanguage,wecheck ence between using organic target-language SFT
whether inferring using the source-language RM datavs. datatranslatedfromadifferentlanguage.
orthedataset-languageRMresultsinalargerR2.
Toaccountforthis,weemployround-tripback-
ThelattermonolingualusagehasahigherR2(0.65
translation,firsttranslatingthetarget-languageSFT
vs. 0.63),soitismorelikelythattheRMsoverfit dataintothesourcelanguageandthenbacktothe
tolexicalpatternswhenusedin-language. targetlanguage. Thissetupisnotpracticallyuseful
butitupper-boundstheeffectoftranslationerrors
5.3 Cross-LingualAlignmentWithout alone. InFigure5(a),weseethatthisbridgesmost
Target-LanguageSFTData of the gap, in some cases leading to models that
win over the SFT model >50% of the time. Al-
Sofarweassumedaccesstotarget-languageSFT
ternatively, we artificially control for domain by
datasince,as§3argues,SFTdatacouldbemore
easilyobtainedthanRMdata. Wenowrelaxthisas-
3SFTdataquantitymayalsobeaconfounder,butwecon-
sumptionandinsteadtranslatethesource-language
siderdirectionsbothfromandtoEnglish,andthedegradation
SFT data into the target language using Google issubstantialinboth.Soquantityisnotthebiggestfactor.60
Target-Language SFT Data Back-Translated SFT Data
Translated Source-Language SFT Data
40
20
0
en de en es en ru en tr en vi de en es en ru en tr en vi en
(a) Summarization, unaligned SFT model
75
50
25
0
en de en es en ru en tr en vi de en es en ru en tr en vi en
(b) Summarization, best-of-n-aligned
75
50
25
0
en de en es en ru en tr en vi de en es en ru en tr en vi en
(c) Summarization, best-of-n-aligned, WikiLingua only
75
50
25
0
en de en es en ru en tr en vi de en es en ru en tr en vi en
(d) Summarization, RL-aligned
Figure5: Cross-lingualalignmentresultswithouttarget-languageSFTdatausingvariousstrategiesandondifferent
data. TrainingtheSFTmodelusingdatatranslatedfromanotherlanguagecanbehelpfulwhenaligning
usingRL((d)),butdomainmatchisimportantforbest-of-n((c)andtheback-translationresults).
repeatingourexperimentssolelyusingWikiLingua back-translationisnothelpful.
for both SFT and RM as it is present for all lan- To summarize,5 cross-lingual alignment could
guages. FromFigure5(c),thegapindeedreduces, stillbehelpfulevenwithouttarget-languageSFT
with the translated SFT models sometimes even data,thoughcareneedstobetakenwhentraining
outperformingtheoriginal,andback-translationis the surrogate SFT model. While we only experi-
nolongerconsistentlybeneficial. mented on summarization, we believe there will
Other than genre control, we also hypothesize belargertextdiversityfordialoggenerationinthe
that the gap would be smaller for RL than best- wild,forwhichthisissuewarrantsgreaterattention.
of-n because the RM, whose transferability we
5.4 PracticalRecommendations
verified(§5),intuitivelyplaysabiggerroleinthe
RLpipeline. Best-of-n,ontheotherhand,ismore Our findings suggest that, for SFT, it is always
reliant on the SFT model quality, as reflected by beneficialtouseorganictarget-languagedata,but
thehighresemblancebetweenthetransferperfor- wheninaccessible,automatictranslationmaybea
mancepatternsinFigure5(b)andtheSFTmodel remedy,thoughoneshouldbemindfulofthedata
quality in Figure 5(a). Figure 5(d) indeed shows distributionmatchbetweenthedatasourceandthe
thatthetranslatedmodelshavelittleperformance application,orrelyingmoreonRL.
drop, except for cases where the former degen- ForRM,cross-lingualtransferisoftensuccess-
erates.4 Again, apart from the degenerate cases, ful, but how does one select the source RM lan-
4Whichwebelieveisduetoalackofcarefulcase-by-case beveryexpensivetotuneforeachtransferpair.
hyperparametertuning,whichwedidnotperformasitwould 5Nopunintended.
L-EGUOR
)%(
TFS
tsniagA
etaR
niW
)%(
TFS
tsniagA
etaR
niW
)%(
TFS
tsniagA
etaR
niWSummarization, Best-of-n Summarization, RL the original reward modeling task, but the latter
de 3 4 2 2 3 2 de 2 2 2 6 6 1
is not sufficient for the former. So how much
en 1 1 1 1 1 1 en 3 3 3 4 3 2
es 4 3 4 4 2 5 es 6 4 5 3 2 6 doesthisgeneralizabilityexplainthealignmentsuc-
ru 5 6 6 6 6 6 ru 4 5 4 5 5 5
tr 2 2 3 3 5 3 tr 5 6 6 2 4 3 cess? We analyze this generalizability following
vi 6 5 5 5 4 4 vi 1 1 1 1 1 4 thecross-lingualtransfertradition,zero-shotapply-
deenesrutrvi deenesrutrvi
ingasource-languageRMtothetarget-language
Target Target
Dialog, Best-of-n Dialog, RL validationdataandcomputingaccuracy(Wuand
en 1 1 1 en 1 1 1 Dredze, 2019, 2020; Pires et al., 2019; i.a.). We
alsoconsideramajoritybaselineandalengthbase-
es 2 2 2 es 3 3 3
linetocheckiftheRMsareonlysuperficiallycap-
ru 3 3 3 ru 2 2 2
turinggenerationlength(Wangetal.,2023b;Sing-
en es ru en es ru
haletal.,2023). Tocomputethislengthbaseline:
Target Target
fordialoggeneration,apairwisetask,alllonger,or
Figure 6: PaLM-2-L-judged rankings of source lan-
guageeffectivenesswhendrivingalignmentindifferent shorter,responsesineachpairarechosen,depend-
targetlanguages. Englishisgenerallyagoodsource. ingonwhich(longorshort)yieldshighertraining
setaccuracy. Forsummarization,apointwisetask,
guage to align in a new target language? In Fig- all responses longer (or shorter) than a threshold
ure 6, we show the source languages ranked by are chosen. The direction (long or short) and the
transfereffectivenessforeachtargetlanguage. The thresholdarealsoselectedusingthetrainingset.
rankingsacrosstargetlanguagesaregenerallysta-
Figure 7 confirms cross-lingual RM generaliz-
ble,especiallyforbest-of-n: ifasourcelanguage
ability: cross-lingual RMs often perform above
is effective for one target language, it is usually
the majority baseline for summarization and ran-
effectiveforotherstoo. Therefore,onemayselect
domperformance(50%)fordialog. §Everifiesthis
thesourcelanguagebyextrapolatingfromitsper-
cross-lingualgeneralizabilitywithanothersetup.
formanceonothertargetlanguages. Inparticular,
Nevertheless,theimprovementsoverthemajori-
English RMs are usually the most accessible in
ty/randombaselinesaremodest. Thedialogmodels
practice. Ourresultsshowthatitisadecentstrat-
evensometimesunderperformthelengthbaseline
egy to use them as the source: English is often a
(thoughthisdoesnotmeantheRMsonlyrelyon
highly-rankedsourcelanguage,mostfrequentlythe length6). Partofthisisduetothehighsubjectivity
best,perhapsduetotherelativelyhigherannotator
of the reward modeling task: the RM accuracies
quantity and quality (Yu et al., 2022) or implicit
here are nearthe human agreement levelfor Sea-
modelingassumptions(Dyeretal.,2019). Beyond
horse(Clarketal.,2023),plottedinFigure7,and
thisempiricalobservation,wetrytocausallypre-
generallymatchthehumanagreementnumbersin
dict the pairwise transferability from various fea-
dialoggenerationwork(Baietal.,2022a;Dubois
turesin§6,butwithoutsuccess.
etal.,2024). Butitisstillinterestingthatseemingly
weak RMs, like the Vietnamese RM which per-
6 Analysis
formssimilarlytothemajoritybaselinewhenused
The effectiveness of cross-lingual alignment mo- monolinguallyorthedialogRMswhichareoften
tivates us to better understand how it relates to surpassedbythelengthbaseline,canachievehigh
variousfactors. WeshowthatwhileRMgeneral- cross-lingualalignmenteffectiveness(Figure4).
izabilitywithintheoriginalrewardmodelingtask Furthermore,theresultsheredonotmatchtheir
is a prerequisite, it does not uniquely explain the downstreamutility,regardlessofwhetherwecon-
downstreamsuccess. Similarly,wealsoshowthat siderthequalityoftheRMsasmeasuredbytheirin-
thepairwisewinrates(judgedbyPaLM-2-Lunless languagevalidationaccuracy(Turkish,forexample,
otherwisementioned)cannotbefullyexplainedby, isthebestinFigure7,butnotsoinFigure6),the
andtherebynotpredictablefrom,languagefeatures generalizabilityoftheRMswhichweoperational-
ortheKL-divergencefromtheSFTmodel. izeasthedifferencebetweenin-languagetraining
and validation loss (or accuracy—they yield the
6.1 ImpactofRMGeneralizabilityWithin
RewardModeling 6TheRMsagreewiththelengthbaselineon72.6%ofthe
validationinstances,higherthanthebaselineagreementlevel
TheRMs’cross-lingualutilityindownstreamalign-
of56.6%(howoftentworandommodelsattheiraccuracy
mentispredicatedontheirgeneralizabilitywithin levelsagreeonaverage),butfarfromfullagreement.
ecruoS
ecruoS
ecruoS
ecruoSFigure7: Source-languageRMgeneralizabilitywithintheoriginalrewardmodelingtaskandthe95%confidence
intervalacrossvalidationinstances. “source→target“denotestrainingasource-languageRMandmeasuringits
accuracyonthetargetlanguagevalidationdata. Thebaselinesareexplainedin§6.1. Dialoggeneration,apairwise
task,doesnothaveamajoritybaseline;thedatasetauthorsalsodidnotreporthumanagreement. RMsgenerally
exhibitcross-lingualgeneralizability,exceedingthemajoritybaselineandoftenthelengthbaseline.
sameranking: Russian,German,English,Turkish, trendisnotclear. Systematically,wecomputethe
Vietnamese, and Spanish, from the least amount correlation between alignment utility and WALS
ofoverfittingtothemost,againdifferentfromFig- featuresoflinguistictypology(DryerandHaspel-
ure 6), or the specific pairwise transfer effective- math,2013). ForeachWALSfeaturepresentforall
ness (for each target language, we compare the 6summarizationlanguages,wedivideallwinrates
effectiveness of source languages ranked by the intotwogroups: thosebetweenlanguagepairsthat
rewardmodelingtaskgeneralizabilityherevs. by havethesame,ordifferent,featurevalues. Under
downstreamalignmentwinrate;onsummarization, a one-sided unpaired t-test, no feature shows sta-
averagedacrosstargetlanguages,Kendall’sτ=0.1 tistical significance at α = 0.05 with Bonferroni
(samewhenusingbest-of-norRL),indicatinglow correction (Dunn, 1961).7 Therefore, alignment
rankingagreement). Overall, while cross-lingual utility does not strongly correlate with such lan-
alignmentdependsonRMgeneralizabilityonthe guagefeatures.
originaltask,thereareotherfactorsatplaytoo.
6.2 ImpactofLanguageFeatures 6.3 ImpactofPolicyDivergence
Can the cross-lingual alignment performance be
Fromalearningangle,ithasbeenshownthatthe
predictedfromsimplelanguagefeatures, suchas
reward that a learned policy can obtain strongly
their frequency in the pretraining corpus or typo-
correlates with its KL-divergence from the base
logicalsimilarity? Thesummarizationlanguages
(SFT) policy (Bai et al., 2022a). This could be
rankedbyfrequencyinthemT5corpus,thebase
concerning, if the model deviates from the base
modelforthistask,are: English,Russian,Spanish,
policyto“hack”thereward(Gaoetal.,2023;Coste
German, Turkish, Vietnamese (Xue et al., 2021).
etal.,2023;Eisensteinetal.,2023),butnotifthe
Thisdoesnotmatchthetransferutilityrankingin
evaluationmetricisrobust. Asweperformhuman
Figure6. Similarly,neitherdoestherankingmatch
evaluation and also verified that our LM judges
theSFTdataquantityorRMdataquantity(in§A).
correlate with human judgments, this is less of a
Linguistic typology and orthography are also
problemforus. Nevertheless,inFigure8,weplot
common predictors of cross-lingual transferabil-
thecorrelationbetweenthewinratesandtheKL-
ity(Gerzetal.,2018;Ketal.,2020;Mulleretal.,
divergence of the aligned models. There is not
2021;i.a.). This,however,isnotthecaseforusei-
a clear correlation, and hence we do not observe
ther: forsummarizationRL,forexample,English
rewardover-optimization.
benefits from Vietnamese the most, but they be-
longtodisparatelanguagefamilies. Orthography
may be playing a role: Russian overall does not 7Evenwithoutcorrection,only4showstatisticalsignifi-
canceatα = 0.05outof123: 1A,3A,37A,and54A.The
transferwelltootherlanguages,anditistheonly
firsttwoarephonologicalfeatures,andtheothertwominor
languagethatdoesnotusetheLatinscript,butthis syntacticfeatures,thuslikelybeingspuriouscorrelations.alsousetranslationforSFT,butshowedthatcross-
70 RL
lingualtransferoutperformstranslationforRM.
Best-of-n
65
8 Conclusion
60 Weshowedthroughtwodifferenttasksthatwecan
performalignmentusingadifferent-languageRM.
55 Surprisingly, we find this to be sometimes more
effectivethanusingasame-languageRM.Wealso
50
identified issuesand remedies when we dispense
withtarget-languageSFTdata. Wehopeourfind-
0 1 2 3 4 ingscanmotivatefutureworktobuildbetterLMs
KL Divergence
for more languages. Adapting our RM transfer
Figure 8: Win rate (PaLM-2-L-judged) vs. KL- setuptoothersettingssuchasdomaingeneraliza-
divergenceforsummarizationacrossdifferent(source,
tionwouldalsobeexcitingfuturedirections.
target)languagepairs. Forbest-of-n,weusetheupper
boundformulainStiennonetal.(2020),Beiramietal.
Limitations
(2024),i.a.,whichisafunctionofnandthusappearsas
averticalline. KL-divergencedoesnotfullyexplain
Free-formgenerationischallengingtoevaluate,es-
thefinalalignmentperformance.
peciallyinacross-lingualsetup. Aswementioned,
neither the finetuned target-language RM evalua-
7 RelatedWork
torscoresnorpairwiseevaluationfromhumansor
LMsareperfect(Wangetal.,2023b;Zhengetal.,
Zero-shotcross-lingualtransfer. Thereisalong
2023;Hoskingetal.,2024;i.a.). Nevertheless,we
line of research on cross-lingual representation
believetheconsistentcross-lingualtransferability
generalizability, such as with sentence embed-
observedacrossourmanyevaluationsettingssug-
dings (Conneau et al., 2018) or more recently,
geststhatitwouldholdmoregenerally. Similarly,
LMs (Wu and Dredze, 2019, 2020; Pires et al.,
itisnotpossibletocomprehensivelystudythemyr-
2019; Siddhant et al., 2020). Commonly, a mul-
iadofrewardoptimizationmethods(Rafailovetal.,
tilingual LM (Devlin et al., 2019; Conneau and
2023;Azaretal.,2023;i.a.),someofwhichmay
Lample,2019;Conneauetal.,2020a;i.a.) isfine-
notenjoythesamecross-lingualRMtransferbene-
tunedonataskinasourcelanguageandevaluated
fit(infact,thenotionofaRMdonotevenexistin
onthetask’stestsetinadifferentlanguage. This
some,thoughanalogousideasmaybeapplicable).
isgenerallyeffective. OurRMtransfersetupcan
However,thetwothatwestudy,best-of-nandPPO,
be viewed under this framework, but we go fur-
arerepresentativeofcurrentcommonpractices,es-
therandshowthatthisgeneralizabilityisusefulfor
peciallygiventhestrongempiricalperformanceof
downstreamtasks,inourcasealignment. Shaham
best-of-n (Gao et al., 2023; Mudgal et al., 2023;
et al. (2024) and Chirkova and Nikoulina (2024)
Rafailov et al., 2023; i.a.). Somewhat orthogo-
areclosetousinstudyingcross-lingualgeneraliz-
nally, past work has argued that it is limiting to
abilityinalignment,butonlyfocusingonSFTand
useonesinglescalartorepresentgenerationqual-
onlyusingtranslateddata.
ity(Xuetal.,2023a;Krishnaetal.,2023;Hosking
MultilingualAlignment. ForSFT,itiscommon et al., 2024) and that more fine-grained rewards
toassembleexistingmultilingualtaskdatasetsinto could be beneficial (Wu et al., 2023). We follow
instructiondatasets(Muennighoffetal.,2023;Asai theconventiontouseonesinglescoretomoreeas-
etal.,2023;Ahujaetal.,2023). Somehavedirectly ilymeasureandcomparecross-lingualtransferin
collectedSFTdatafornon-Englishlanguages,ei- many setups, but a similar but more fine-grained
ther on a per-language basis (Zhang et al., 2023; study would be valuable future work. It has also
Xu et al., 2023b; Ni et al., 2023; i.a.) or multi- beenshownthatitismorechallengingtotrainre-
lingually (Zhao et al., 2024; Singh et al., 2024), ward models for low-resourced languages (Shen
thoughthiscanbeexpensive. Pastworkhasalso etal.,2024). Weonlyconsideredrelativelyhigh-
usedautomatictranslationforSFT(Lietal.,2023a; resourcedlanguagesinthiswork,anditispossible
Lai et al., 2023; Shaham et al., 2024; i.a.) and that the pattern would differ when using lower-
RMdata(Laietal.,2023;Shenetal.,2024). We resourced source languages for transfer. Finally,
etaR
niWourmotivatingassumptionthatgenerationquality JianLi,HyeontaekLim,HanzhaoLin,ZhongtaoLiu,
beinglanguage-agnosticdoesnotalwayshold,es- FrederickLiu,MarcelloMaggioni,AromaMahendru,
JoshuaMaynez,VedantMisra,MaysamMoussalem,
peciallywhenfacingculture-specifictasksortask
Zachary Nado, John Nham, Eric Ni, Andrew Nys-
instances. Inthosecases,webelievewewouldsee
trom, Alicia Parrish, Marie Pellat, Martin Polacek,
reducedcross-lingualgeneralizability. AlexPolozov,ReinerPope,SiyuanQiao,EmilyReif,
Bryan Richter, Parker Riley, Alex Castro Ros, Au-
Acknowledgments rkoRoy,BrennanSaeta,RajkumarSamuel, Renee
Shelby, Ambrose Slone, Daniel Smilkov, David R.
WewouldliketothankJonathanBerant,JilinChen, So, Daniel Sohn, Simon Tokumine, Dasha Valter,
Elizabeth Clark, Daphne Domansi, Jie Fan, Han Vijay Vasudevan, Kiran Vodrahalli, Xuezhi Wang,
Pidong Wang, Zirui Wang, Tao Wang, John Wiet-
Guo,HenryHand,HarrisonLee,JongLee,Alisa
ing, Yuhuai Wu, Kelvin Xu, Yunhan Xu, Linting
Liu, Ana Marasovic´, Usha Rani Markuk, Kathy
Xue,PengchengYin,JiahuiYu,QiaoZhang,Steven
Meier-Hellstern, Chirag Nagpal, Flavien Prost, Zheng,CeZheng,WeikangZhou,DennyZhou,Slav
Linlu Qiu, Kevin Robinson, Alexis Ross, Shan- Petrov, andYonghuiWu.2023. PaLM2 technical
report.
nonZejiangShen,BailinWang,XinyanVelocity
Yu, and the T5X team Google for their valuable
Akari Asai, Sneha Kudugunta, Xinyan Velocity Yu,
feedbackandsupport. TheMITresearcherswere Terra Blevins, Hila Gonen, Machel Reid, Yulia
partially supported by funds from an MIT-IBM Tsvetkov,SebastianRuder,andHannanehHajishirzi.
2023. BUFFET:Benchmarkinglargelanguagemod-
WatsonAILabgrant.
elsforfew-shotcross-lingualtransfer.
Mohammad Gheshlaghi Azar, Mark Rowland, Bilal
References
Piot, Daniel Guo, Daniele Calandriello, Michal
Valko, and Rémi Munos. 2023. A general theoret-
Kabir Ahuja, Harshita Diddee, Rishav Hada, Milli-
ical paradigm to understand learning from human
cent Ochieng, Krithika Ramesh, Prachi Jain, Ak-
preferences.
shayNambi,TanujaGanu,SameerSegal,Mohamed
Ahmed, Kalika Bali, and Sunayana Sitaram. 2023.
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda
MEGA: Multilingual evaluation of generative AI.
Askell, AnnaChen, NovaDasSarma, DawnDrain,
In Proceedings of the 2023 Conference on Empir-
Stanislav Fort, Deep Ganguli, Tom Henighan,
icalMethodsinNaturalLanguageProcessing,pages
NicholasJoseph,SauravKadavath,JacksonKernion,
4232–4267, Singapore. Association for Computa-
TomConerly,SheerEl-Showk,NelsonElhage,Zac
tionalLinguistics.
Hatfield-Dodds, Danny Hernandez, Tristan Hume,
Chenxin An, Shansan Gong, Ming Zhong, Xingjian ScottJohnston,ShaunaKravec,LianeLovitt,Neel
Zhao, Mukai Li, Jun Zhang, Lingpeng Kong, and Nanda, Catherine Olsson, Dario Amodei, Tom
XipengQiu.2023. L-Eval: Institutingstandardized Brown, Jack Clark, Sam McCandlish, Chris Olah,
evaluationforlongcontextlanguagemodels. Ben Mann, and Jared Kaplan. 2022a. Training a
helpful and harmless assistant with reinforcement
RohanAnil,AndrewM.Dai,OrhanFirat,MelvinJohn- learningfromhumanfeedback.
son, Dmitry Lepikhin, Alexandre Passos, Siamak
Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Yuntao Bai, Saurav Kadavath, Sandipan Kundu,
Chen, Eric Chu, Jonathan H. Clark, Laurent El AmandaAskell,JacksonKernion,AndyJones,Anna
Shafey,YanpingHuang,KathyMeier-Hellstern,Gau- Chen, Anna Goldie, Azalia Mirhoseini, Cameron
ravMishra,EricaMoreira,MarkOmernick,Kevin McKinnon,CarolChen,CatherineOlsson,Christo-
Robinson, Sebastian Ruder, Yi Tay, Kefan Xiao, pher Olah, Danny Hernandez, Dawn Drain, Deep
YuanzhongXu,YujingZhang,GustavoHernandez Ganguli,DustinLi,EliTran-Johnson,EthanPerez,
Abrego,JunwhanAhn,JacobAustin,PaulBarham, Jamie Kerr, Jared Mueller, Jeffrey Ladish, Joshua
Jan Botha, James Bradbury, Siddhartha Brahma, Landau,KamalNdousse,KamileLukosuite,Liane
KevinBrooks,MicheleCatasta,YongCheng,Colin Lovitt, Michael Sellitto, Nelson Elhage, Nicholas
Cherry,ChristopherA.Choquette-Choo,Aakanksha Schiefer,NoemiMercado,NovaDasSarma,Robert
Chowdhery,ClémentCrepy,ShachiDave,Mostafa Lasenby, Robin Larson, Sam Ringer, Scott John-
Dehghani, Sunipa Dev, Jacob Devlin, Mark Díaz, ston,ShaunaKravec,SheerElShowk,StanislavFort,
Nan Du, Ethan Dyer, Vlad Feinberg, Fangxiaoyu TameraLanham,TimothyTelleen-Lawton,TomCon-
Feng, Vlad Fienber, Markus Freitag, Xavier Gar- erly,TomHenighan,TristanHume,SamuelR.Bow-
cia,SebastianGehrmann,LucasGonzalez,GuyGur- man,ZacHatfield-Dodds,BenMann,DarioAmodei,
Ari, Steven Hand, Hadi Hashemi, Le Hou, Joshua NicholasJoseph,SamMcCandlish,TomBrown,and
Howland, Andrea Hu, Jeffrey Hui, Jeremy Hur- JaredKaplan.2022b. ConstitutionalAI:Harmless-
witz,MichaelIsard,AbeIttycheriah,MatthewJagiel- nessfromAIfeedback.
ski,WenhaoJia,KathleenKenealy,MaximKrikun,
SnehaKudugunta,ChangLan,KatherineLee,Ben- Ahmad Beirami, Alekh Agarwal, Jonathan Berant,
jaminLee,EricLi,MusicLi,WeiLi,YaGuangLi, AlexanderD’Amour,JacobEisenstein,ChiragNag-pal,andAnandaTheerthaSuresh.2024. Theoretical Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
guaranteesonthebest-of-nalignmentpolicy. Kristina Toutanova. 2019. BERT: Pre-training of
deepbidirectionaltransformersforlanguageunder-
RalphAllanBradleyandMiltonE.Terry.1952. Rank standing. InProceedingsofthe2019Conferenceof
analysisofincompleteblockdesigns: I.themethod theNorthAmericanChapteroftheAssociationfor
of paired comparisons. Biometrika, 39(3/4):324– ComputationalLinguistics: HumanLanguageTech-
345. nologies,Volume1(LongandShortPapers),pages
4171–4186,Minneapolis,Minnesota.Associationfor
Nadezhda Chirkova and Vassilina Nikoulina. 2024.
ComputationalLinguistics.
Zero-shotcross-lingualtransferininstructiontuning
oflargelanguagemodel.
MatthewS.DryerandMartinHaspelmath,editors.2013.
Christos Christodouloupoulos and Mark Steedman. WALSOnline(v2020.3). Zenodo.
2015. A massively parallel corpus: the Bible in
YannDubois,XuechenLi,RohanTaori,TianyiZhang,
100languages. LanguageResourcesandEvaluation,
IshaanGulrajani,JimmyBa,CarlosGuestrin,Percy
49(2):375–395.
Liang,andTatsunoriB.Hashimoto.2024. Alpaca-
ElizabethClark,ShrutiRijhwani,SebastianGehrmann, farm:Asimulationframeworkformethodsthatlearn
Joshua Maynez, Roee Aharoni, Vitaly Nikolaev, fromhumanfeedback.
ThibaultSellam,AdityaSiddhant,DipanjanDas,and
AnkurParikh.2023. SEAHORSE:Amultilingual, OliveJeanDunn.1961. Multiplecomparisonsamong
multifaceted dataset for summarization evaluation. means. JournaloftheAmericanStatisticalAssocia-
In Proceedings of the 2023 Conference on Empiri- tion,56(293):52–64.
calMethodsinNaturalLanguageProcessing,pages
ChrisDyer,GáborMelis,andPhilBlunsom.2019. A
9397–9413, Singapore. Association for Computa-
critical analysis of biased parsers in unsupervised
tionalLinguistics.
parsing.
AlexisConneau,KartikayKhandelwal,NamanGoyal,
Vishrav Chaudhary, Guillaume Wenzek, Francisco JacobEisenstein,ChiragNagpal,AlekhAgarwal,Ah-
Guzmán, Edouard Grave, Myle Ott, Luke Zettle- madBeirami,AlexD’Amour,DJDvijotham,Adam
moyer,andVeselinStoyanov.2020a. Unsupervised Fisch,KatherineHeller,StephenPfohl,DeepakRa-
cross-lingualrepresentationlearningatscale. InPro- machandran,PeterShaw,andJonathanBerant.2023.
ceedings of the 58th Annual Meeting of the Asso- Helpingorherding? Rewardmodelensemblesmiti-
ciationforComputationalLinguistics,pages8440– gatebutdonoteliminaterewardhacking.
8451, Online. Association for Computational Lin-
LeoGao,JohnSchulman,andJacobHilton.2023. Scal-
guistics.
inglawsforrewardmodeloveroptimization. InPro-
AlexisConneauandGuillaumeLample.2019. Cross- ceedings of the 40th International Conference on
linguallanguagemodelpretraining. InAdvancesin Machine Learning, volume 202 of Proceedings of
NeuralInformationProcessingSystems,volume32. Machine Learning Research, pages 10835–10866.
CurranAssociates,Inc. PMLR.
AlexisConneau,RutyRinott,GuillaumeLample,Adina Sebastian Gehrmann, Tosin Adewumi, Karmanya
Williams, Samuel Bowman, Holger Schwenk, and Aggarwal, Pawan Sasanka Ammanamanchi,
Veselin Stoyanov. 2018. XNLI: Evaluating cross- Anuoluwapo Aremu, Antoine Bosselut, Khy-
lingualsentencerepresentations. InProceedingsof athi Raghavi Chandu, Miruna-Adriana Clinciu,
the2018ConferenceonEmpiricalMethodsinNat- Dipanjan Das, Kaustubh Dhole, Wanyu Du, Esin
uralLanguageProcessing,pages2475–2485,Brus- Durmus, Ondˇrej Dušek, Chris Chinenye Emezue,
sels, Belgium. Association for Computational Lin- Varun Gangal, Cristina Garbacea, Tatsunori
guistics. Hashimoto,YufangHou,YacineJernite,HarshJham-
tani,YangfengJi,ShailzaJolly,MihirKale,Dhruv
Alexis Conneau, Shijie Wu, Haoran Li, Luke Zettle-
Kumar, Faisal Ladhak, Aman Madaan, Mounica
moyer, and Veselin Stoyanov. 2020b. Emerging
Maddela, Khyati Mahajan, Saad Mahamood, Bod-
cross-lingualstructureinpretrainedlanguagemod-
hisattwaPrasadMajumder,PedroHenriqueMartins,
els. InProceedingsofthe58thAnnualMeetingof
AngelinaMcMillan-Major,SimonMille,Emielvan
theAssociationforComputationalLinguistics,pages
Miltenburg,MoinNadeem,ShashiNarayan,Vitaly
6022–6034,Online.AssociationforComputational
Nikolaev, Andre Niyongabo Rubungo, Salomey
Linguistics.
Osei, Ankur Parikh, Laura Perez-Beltrachini,
Niranjan Ramesh Rao, Vikas Raunak, Juan Diego
AlbertCosta,AliceFoucart,SayuriHayakawa,Melina
Rodriguez, Sashank Santhanam, João Sedoc,
Aparici, Jose Apesteguia, Joy Heafner, and Boaz
ThibaultSellam, SamiraShaikh, AnastasiaShimo-
Keysar. 2014. Your morals depend on language.
PLOSONE,9(4):1–7. rina,MarcoAntonioSobrevillaCabezudo,Hendrik
Strobelt, Nishant Subramani, Wei Xu, Diyi Yang,
ThomasCoste,UsmanAnwar,RobertKirk,andDavid Akhila Yerukola, and Jiawei Zhou. 2021. The
Krueger.2023. Rewardmodelensembleshelpmiti- GEM benchmark: Natural language generation,
gateoveroptimization. its evaluation and metrics. In Proceedings of the1st Workshop on Natural Language Generation, Andreas Köpf, Yannic Kilcher, Dimitri von Rütte,
Evaluation,andMetrics(GEM2021),pages96–120, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens,
Online.AssociationforComputationalLinguistics. Abdullah Barhoum, Nguyen Minh Duc, Oliver
Stanley, Richárd Nagyfi, Shahul ES, Sameer Suri,
Daniela Gerz, Ivan Vulic´, Edoardo Maria Ponti, Roi DavidGlushkov,ArnavDantuluri,AndrewMaguire,
Reichart, and Anna Korhonen. 2018. On the rela- Christoph Schuhmann, Huu Nguyen, and Alexan-
tionbetweenlinguistictypologyand(limitationsof) der Mattick. 2023. OpenAssistant conversations –
multilinguallanguagemodeling. InProceedingsof democratizinglargelanguagemodelalignment.
the2018ConferenceonEmpiricalMethodsinNatu-
ralLanguageProcessing,pages316–327,Brussels, FaisalLadhak,EsinDurmus,ClaireCardie,andKath-
Belgium.AssociationforComputationalLinguistics. leenMcKeown.2020. WikiLingua: Anewbench-
markdatasetforcross-lingualabstractivesummariza-
Tahmid Hasan, Abhik Bhattacharjee, Md. Saiful Is-
tion. In Findings of the Association for Computa-
lam,KaziMubasshir,Yuan-FangLi,Yong-BinKang,
tionalLinguistics: EMNLP2020,pages4034–4048,
M.SohelRahman,andRifatShahriyar.2021. XL-
Online.AssociationforComputationalLinguistics.
sum:Large-scalemultilingualabstractivesummariza-
tionfor44languages. InFindingsoftheAssociation
Viet Lai, Chien Nguyen, Nghia Ngo, Thuat Nguyen,
forComputationalLinguistics: ACL-IJCNLP2021,
FranckDernoncourt,RyanRossi,andThienNguyen.
pages4693–4703,Online.AssociationforComputa-
2023. Okapi: Instruction-tunedlargelanguagemod-
tionalLinguistics.
elsinmultiplelanguageswithreinforcementlearning
fromhumanfeedback. InProceedingsofthe2023
Daniel Hershcovich, Stella Frank, Heather Lent,
Conference on Empirical Methods in Natural Lan-
Miryam de Lhoneux, Mostafa Abdou, Stephanie
guage Processing: System Demonstrations, pages
Brandl, Emanuele Bugliarello, Laura Cabello Pi-
318–327,Singapore.AssociationforComputational
queras, Ilias Chalkidis, Ruixiang Cui, Constanza
Linguistics.
Fierro,KaterinaMargatina,PhillipRust,andAnders
Søgaard.2022. Challengesandstrategiesincross-
HarrisonLee,SamratPhatale,HassanMansoor,Thomas
cultural NLP. In Proceedings of the 60th Annual
Mesnard, Johan Ferret, Kellie Lu, Colton Bishop,
Meeting of the Association for Computational Lin-
Ethan Hall, Victor Carbune, AbhinavRastogi, and
guistics(Volume1: LongPapers),pages6997–7013,
SushantPrakash.2023. RLAIF:Scalingreinforce-
Dublin,Ireland.AssociationforComputationalLin-
ment learning from human feedback with ai feed-
guistics.
back.
TomHosking,PhilBlunsom,andMaxBartolo.2024.
HaonanLi,FajriKoto,MinghaoWu,AlhamFikriAji,
Humanfeedbackisnotgoldstandard.
and Timothy Baldwin. 2023a. Bactrian-X: Multi-
Junjie Hu, Sebastian Ruder, Aditya Siddhant, Gra- lingualreplicableinstruction-followingmodelswith
ham Neubig, Orhan Firat, and Melvin Johnson. low-rankadaptation.
2020. XTREME: A massively multilingual multi-
XuechenLi,TianyiZhang,YannDubois,RohanTaori,
task benchmark for evaluating cross-lingual gener-
IshaanGulrajani,CarlosGuestrin,PercyLiang,and
alisation. InProceedingsofthe37thInternational
Tatsunori B. Hashimoto. 2023b. AlpacaEval: An
Conference on Machine Learning, volume 119 of
automaticevaluatorofinstruction-followingmodels.
ProceedingsofMachineLearningResearch,pages
https://github.com/tatsu-lab/alpaca_eval.
4411–4421.PMLR.
PratikJoshi, SebastinSanty, AmarBudhiraja, Kalika Chin-Yew Lin. 2004. ROUGE: A package for auto-
Bali,andMonojitChoudhury.2020. Thestateand maticevaluationofsummaries. InTextSummariza-
fateoflinguisticdiversityandinclusionintheNLP tionBranchesOut,pages74–81,Barcelona,Spain.
world. InProceedingsofthe58thAnnualMeetingof AssociationforComputationalLinguistics.
theAssociationforComputationalLinguistics,pages
Jesse Mu, Xiang Lisa Li, and Noah Goodman. 2023.
6282–6293,Online.AssociationforComputational
Learningtocompresspromptswithgisttokens.
Linguistics.
Karthikeyan K, Zihan Wang, Stephen Mayhew, and Sidharth Mudgal, Jong Lee, Harish Ganapathy,
Dan Roth. 2020. Cross-lingual ability of multilin- YaGuang Li, Tao Wang, Yanping Huang, Zhifeng
gual BERT: An empirical study. In International Chen, Heng-Tze Cheng, Michael Collins, Trevor
ConferenceonLearningRepresentations. Strohman, Jilin Chen, Alex Beutel, and Ahmad
Beirami.2023. Controlleddecodingfromlanguage
KalpeshKrishna,ErinBransom,BaileyKuehl,Mohit models.
Iyyer,PradeepDasigi,ArmanCohan,andKyleLo.
2023. LongEval:Guidelinesforhumanevaluationof NiklasMuennighoff,ThomasWang,LintangSutawika,
faithfulnessinlong-formsummarization. InProceed- Adam Roberts, Stella Biderman, Teven Le Scao,
ingsofthe17thConferenceoftheEuropeanChap- MSaifulBari, ShengShen, ZhengXinYong, Hai-
teroftheAssociationforComputationalLinguistics, ley Schoelkopf, Xiangru Tang, Dragomir Radev,
pages1650–1669,Dubrovnik,Croatia.Association Alham Fikri Aji, Khalid Almubarak, Samuel Al-
forComputationalLinguistics. banie,ZaidAlyafeai,AlbertWebson,EdwardRaff,and Colin Raffel. 2023. Crosslingual generaliza- 2023. Directpreferenceoptimization:Yourlanguage
tion through multitask finetuning. In Proceedings modelissecretlyarewardmodel. InThirty-seventh
of the 61st Annual Meeting of the Association for ConferenceonNeuralInformationProcessingSys-
ComputationalLinguistics(Volume1: LongPapers), tems.
pages15991–16111,Toronto,Canada.Association
forComputationalLinguistics. JohnSchulman,FilipWolski,PrafullaDhariwal,Alec
Radford,andOlegKlimov.2017. Proximalpolicy
Phoebe Mulcaire, Jungo Kasai, and Noah A. Smith. optimizationalgorithms.
2019. Polyglotcontextualrepresentationsimprove
crosslingual transfer. In Proceedings of the 2019 ThomasScialom,Paul-AlexisDray,SylvainLamprier,
Conference of the North American Chapter of the Benjamin Piwowarski, and Jacopo Staiano. 2020.
AssociationforComputationalLinguistics: Human MLSUM: The multilingual summarization corpus.
LanguageTechnologies,Volume1(LongandShort InProceedingsofthe2020ConferenceonEmpirical
Papers),pages3912–3918,Minneapolis,Minnesota. MethodsinNaturalLanguageProcessing(EMNLP),
AssociationforComputationalLinguistics. pages8051–8067,Online.AssociationforComputa-
tionalLinguistics.
Benjamin Muller, Antonios Anastasopoulos, Benoît
Sagot, and Djamé Seddah. 2021. When being un- Uri Shaham, Jonathan Herzig, Roee Aharoni, Idan
seenfrommBERTisjustthebeginning: Handling Szpektor,ReutTsarfaty,andMatanEyal.2024. Mul-
new languages with multilingual language models. tilingualinstructiontuningwithjustapinchofmulti-
InProceedingsofthe2021ConferenceoftheNorth linguality.
AmericanChapteroftheAssociationforComputa-
Noam Shazeer and Mitchell Stern. 2018. Adafactor:
tionalLinguistics: HumanLanguageTechnologies,
Adaptivelearningrateswithsublinearmemorycost.
pages 448–462, Online. Association for Computa-
InProceedingsofthe35thInternationalConference
tionalLinguistics.
on Machine Learning, volume 80 of Proceedings
Shashi Narayan, Shay B. Cohen, and Mirella Lapata. of Machine Learning Research, pages 4596–4604.
2018. Don’tgivemethedetails,justthesummary! PMLR.
Topic-aware convolutional neural networks for ex-
LingfengShen,WeitingTan,SihaoChen,YunmoChen,
treme summarization. In Proceedings of the 2018
JingyuZhang,HaoranXu, BoyuanZheng,Philipp
Conference on Empirical Methods in Natural Lan-
Koehn, andDanielKhashabi.2024. Thelanguage
guageProcessing,pages1797–1807,Brussels,Bel-
barrier: Dissectingsafetychallengesofllmsinmulti-
gium.AssociationforComputationalLinguistics.
lingualcontexts.
Jinjie Ni, Fuzhao Xue, Yuntian Deng, Jason Phang,
VeredShwartz.2022. Goodnightat4pm?! Timeex-
KabirJain,MahirHiteshShah,ZangweiZheng,and
pressionsindifferentcultures. InFindingsoftheAs-
Yang You. 2023. Instruction in the wild: A user-
based instruction dataset. https://github.com/ sociationforComputationalLinguistics: ACL2022,
XueFuzhao/InstructionWild. pages2842–2853,Dublin,Ireland.Associationfor
ComputationalLinguistics.
OpenAI.2023. GPT-4technicalreport.
AdityaSiddhant,MelvinJohnson,HenryTsai,Naveen
LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida, Ari, Jason Riesa, Ankur Bapna, Orhan Firat, and
CarrollWainwright,PamelaMishkin,ChongZhang, KarthikRaman.2020. Evaluatingthecross-lingual
SandhiniAgarwal,KatarinaSlama,AlexRay,John effectiveness of massively multilingual neural ma-
Schulman,JacobHilton,FraserKelton,LukeMiller, chinetranslation. ProceedingsoftheAAAIConfer-
Maddie Simens, Amanda Askell, Peter Welinder, enceonArtificialIntelligence,34(05):8854–8861.
PaulFChristiano,JanLeike,andRyanLowe.2022.
Shivalika Singh, Freddie Vargus, Daniel Dsouza,
Traininglanguagemodelstofollowinstructionswith
Börje F. Karlsson, Abinaya Mahendiran, Wei-Yin
humanfeedback. InAdvancesinNeuralInformation
Ko, Herumb Shandilya, Jay Patel, Deividas Mat-
ProcessingSystems,volume35,pages27730–27744.
aciunas, Laura OMahony, Mike Zhang, Ramith
CurranAssociates,Inc.
Hettiarachchi, Joseph Wilson, Marina Machado,
Pouya Pezeshkpour and Estevam Hruschka. 2023. LuisaSouzaMoura,DominikKrzemin´ski,Hakimeh
Large language models sensitivity to the order of Fadaei, Irem Ergün, Ifeoma Okoh, Aisha Alaagib,
optionsinmultiple-choicequestions. OshanMudannayake,ZaidAlyafeai,VuMinhChien,
Sebastian Ruder, Surya Guthikonda, Emad A. Al-
Telmo Pires, Eva Schlinger, and Dan Garrette. 2019. ghamdi,SebastianGehrmann,NiklasMuennighoff,
HowmultilingualismultilingualBERT? InProceed- MaxBartolo,JuliaKreutzer,AhmetÜstün,Marzieh
ingsofthe57thAnnualMeetingoftheAssociationfor Fadaee, and Sara Hooker. 2024. Aya dataset: An
Computational Linguistics, pages 4996–5001, Flo- open-access collection for multilingual instruction
rence,Italy.AssociationforComputationalLinguis- tuning.
tics.
PrasannSinghal,TanyaGoyal,JiachengXu,andGreg
RafaelRafailov,ArchitSharma,EricMitchell,Christo- Durrett.2023. Alongwaytogo:Investigatinglength
pherDManning,StefanoErmon,andChelseaFinn. correlationsinRLHF.Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel JingrenZhou.2023b. CValues: Measuringtheval-
Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, uesofchineselargelanguagemodelsfromsafetyto
DarioAmodei,andPaulFChristiano.2020. Learn- responsibility.
ing to summarize with human feedback. In Ad-
vances in Neural Information Processing Systems, LintingXue,NoahConstant,AdamRoberts,MihirKale,
volume 33, pages 3008–3021. Curran Associates, RamiAl-Rfou,AdityaSiddhant,AdityaBarua,and
Inc. ColinRaffel.2021. mT5: Amassivelymultilingual
pre-trainedtext-to-texttransformer. InProceedings
PeiyiWang,LeiLi,LiangChen,ZefanCai,DaweiZhu, ofthe2021ConferenceoftheNorthAmericanChap-
BinghuaiLin,YunboCao,QiLiu,TianyuLiu,and teroftheAssociationforComputationalLinguistics:
ZhifangSui.2023a. Largelanguagemodelsarenot HumanLanguageTechnologies,pages483–498,On-
fairevaluators. line.AssociationforComputationalLinguistics.
Xinyan Yu, Trina Chatterjee, Akari Asai, Junjie Hu,
Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack
andEunsolChoi.2022. Beyondcountingdatasets:
Hessel,TusharKhot,KhyathiChandu,DavidWad-
A survey of multilingual dataset construction and
den,KelseyMacMillan,NoahA.Smith,IzBeltagy,
necessaryresources. InFindingsoftheAssociation
andHannanehHajishirzi.2023b. Howfarcancamels
forComputationalLinguistics: EMNLP2022,pages
go? Exploringthestateofinstructiontuningonopen
3725–3743,AbuDhabi,UnitedArabEmirates.As-
resources. InThirty-seventhConferenceonNeural
sociationforComputationalLinguistics.
InformationProcessingSystemsDatasetsandBench-
marksTrack.
GeZhang,YeminShi,RuiboLiu,RuibinYuan,Yizhi
Li,SiweiDong,YuShu,ZhaoqunLi,ZekunWang,
YizhongWang,YeganehKordi,SwaroopMishra,Alisa
Chenghua Lin, Wenhao Huang, and Jie Fu. 2023.
Liu,NoahA.Smith,DanielKhashabi,andHannaneh
Chineseopeninstructiongeneralist: Apreliminary
Hajishirzi.2023c. Self-instruct: Aligninglanguage
release.
modelswithself-generatedinstructions. InProceed-
ingsofthe61stAnnualMeetingoftheAssociationfor Wenting Zhao, Xiang Ren, Jack Hessel, Claire
ComputationalLinguistics(Volume1: LongPapers), Cardie, Yejin Choi, and Yuntian Deng. 2024.
pages13484–13508,Toronto,Canada.Association (InThe)WildChat: 570k ChatGPT interaction logs
forComputationalLinguistics. inthewild. InTheTwelfthInternationalConference
onLearningRepresentations.
ShijieWuandMarkDredze.2019. Beto,bentz,becas:
Thesurprisingcross-lingualeffectivenessofBERT. ChujieZheng,HaoZhou,FandongMeng,JieZhou,and
InProceedingsofthe2019ConferenceonEmpirical MinlieHuang.2023. Largelanguagemodelsarenot
MethodsinNaturalLanguageProcessingandthe9th robustmultiplechoiceselectors.
InternationalJointConferenceonNaturalLanguage
Processing(EMNLP-IJCNLP),pages833–844,Hong DanielM.Ziegler,NisanStiennon,JeffreyWu,TomB.
Kong,China.AssociationforComputationalLinguis- Brown, Alec Radford, Dario Amodei, Paul Chris-
tics. tiano, and Geoffrey Irving. 2020. Fine-tuning lan-
guagemodelsfromhumanpreferences.
ShijieWuandMarkDredze.2020. Arealllanguages
createdequalinmultilingualBERT? InProceedings
ofthe5thWorkshoponRepresentationLearningfor
NLP,pages120–130,Online.AssociationforCom-
putationalLinguistics.
ZeqiuWu,YushiHu,WeijiaShi,NouhaDziri,Alane
Suhr,PrithvirajAmmanabrolu,NoahA.Smith,Mari
Ostendorf, and Hannaneh Hajishirzi. 2023. Fine-
grainedhumanfeedbackgivesbetterrewardsforlan-
guagemodeltraining. InThirty-seventhConference
onNeuralInformationProcessingSystems.
Fangyuan Xu, Yixiao Song, Mohit Iyyer, and Eunsol
Choi. 2023a. A critical evaluation of evaluations
forlong-formquestionanswering. InProceedings
of the 61st Annual Meeting of the Association for
ComputationalLinguistics(Volume1: LongPapers),
pages3225–3245,Toronto,Canada.Associationfor
ComputationalLinguistics.
GuohaiXu,JiayiLiu,MingYan,HaotianXu,Jinghui
Si, Zhuoran Zhou, Peng Yi, Xing Gao, Jitao Sang,
RongZhang,JiZhang,ChaoPeng,FeiHuang,andA DatasetDetailsandStatistics
Train Validation
WereportdatasetstatisticsinTable1,2,3,and4. MLSum 220748 8932
German
WereusetheSFTdataforrewardoptimization(for WikiLingua 40839 3699
bothtrainingandevaluationforRL,andforonly
XSum 23206 642
evaluation for best-of-n since it does not have a
English XL-Sum 306522 9690
trainingstage),butonlytheinputx,withoutrefer-
WikiLingua 99020 12021
encegenerationsy.
XL-Sum 38110 3170
ThesummarizationSFTdatasets,reportedinTa-
Spanish MLSum 259888 8374
ble 1, are the original data sources of Seahorse,
WikiLingua 79212 9730
whichwetakefromtheGEMrelease(Gehrmann
et al., 2021). They are evenly mixed at the in- XL-Sum 62243 5492
Russian
stancelevelforbothSFTtrainingandRLtraining. WikiLingua 37028 3209
For evaluation of the aligned model, we macro-
XL-Sum 27176 1953
averagetheper-datasetmetrics(e.g.,winrate)fora Turkish
WikiLingua 3148 194
language-levelscore. BecausetheSeahorsedataset
wascreatedusingthevalidationandtestinstances XL-Sum 32111 2341
Vietnamese
oftheoriginalsummarizationdatasets,tobeclean, WikiLingua 13707 679
we exclude the Seahorse training instances from
Table1: Numberofsummarizationinstancesforthe
thesesplitswhenperformingSFTandrewardopti-
SFTandrewardoptimizationstages. Thedatasetsare
mization. OpenAssistantdoesnothavethisissue taken from the GEM release (Gehrmann et al., 2021)
andhascleansplitseparations. TheSeahorsesum- andwithcertainvalidationinstancesremoved(§A).
mariesarehuman-ratedalongsixaxes,andweonly
usethesixthaxisforourpointwiserewardasiten-
Train Validation
capsulatespreviousaxes(Clarketal.,2023). We
limitthemaximumlengthofmodelinputsto1,024 German 8389 1250
tokens and outputs to 512 tokens. See also §G.1 English 14031 2071
forinstructionsweattachtothedatasetinstances Spanish 8741 1310
duringtrainingandinference. Russian 7679 1112
Turkish 7855 1096
B TrainingDetails Vietnamese 7844 1166
SFT. The model is trained using Adafac- Table 2: Number of summarization instances for re-
wardmodeling.
tor(ShazeerandStern,2018)withaconstantlearn-
ing rate at 10−3 for summarization and 10−5 for
dialoggeneration,batchsize32,anddropout0.1. Train Validation
Weperformcheckpointselectionusingvalidation
English 8898 472
ROUGE-Lscore(Lin,2004).
Spanish 5681 311
RM. ThemodelistrainedusingAdafactorwith Russian 1884 99
aconstantlearningrateat10−4 after1,000linear
Table3: Numberofdialoggenerationinstancesforthe
warm-upsteps,batchsize32,anddropout0.1. We SFTandrewardoptimizationstages.
performcheckpointselectionusingvalidationloss.
RL. WeusePPOforRLtrainingwithaconstant Train Validation
learningrateat10−4,batchsize32,for3,000steps
English 22076 1026
forsummarizationand2,500stepsfordialoggen-
Spanish 13714 699
eration. Thevaluemodelhas1,000linearwarm-up
Russian 2627 135
steps and we only start training the policy model
after2,000stepselapse. Wesettheregularization Table 4: Number of dialog generation instances for
rewardmodeling.
coefficientatβ = 0.01.
Best-of-n. Weusen = 64.De En Es Ru Tr Vi
Acc. 73.5% 73.0% 73.2% 73.7% 73.6% 78.2%
Summarization
N 306 1672 295 255 720 349
Acc. – 72.0% 70.8% 73.3% – –
Dialog
N – 472 311 99 – –
Table5: TheaccuracyofevaluatingthePaLM-2-LjudgeontheRMvalidationdata. Wealsoreportthenumberof
comparisonsbasedonwhichtheaccuracyiscalculated.
Figure9: Alignmenteffectiveness,comparedtothetarget-languageSFTmodeljudgedbyGPT-4,andthe95%
confidenceintervalacrossvalidationinstances. “source→target“denotesasource-languageRMdrivingalignment
inthetargetlanguage. Cross-lingualalignmentisgenerallyeffective,sometimesoutperformingmonolingual
alignment. RLishardtotrainforOpenAssistant,inlinewithwhatitsauthorsfound(Köpfetal.,2023).
C LMJudgeAccuracyonGround-truth man agreement numbers). Taken together with
RewardModelingData the LM judges’ agreement with human evalua-
tion (§5.1), we believe it is valid to use a LM to
WeverifythevalidityofusingLMasajudgefor
assessthegenerationqualityinoursetup.
ourtasksbycomputingitsaccuracyonthevalida-
tion splits of the RM datasets we used. We only
D GPT-4asaJudgeResults
considerPaLM-2-Lasacasestudy. ForOpenAssis-
tant,apairwisedataset,wesimplycheckiftheRM In this section, we present the alignment evalua-
ranks the candidate generations correctly accord- tion results as judged by GPT-4, specifically the
ing to human preference. For Seahorse, a point- gpt-4-0125-previewmodel. Duetoitshighcost,
wise dataset, we group summaries for the same wecapthenumberofevaluationinstancesforeach
source document, and for each summary pair in datasetat1,000(i.e.,foreachrowofTable1and
suchgroups,wecomputetherankingcorrectness. 3). TheresultsareshowninFigure9. Weobserve
We show the results in Table 5. The accura- thesametrendsasin§5.1,wherecross-lingualre-
ciesgenerallymatchthehumanagreementinSea- wardoptimizationisgenerallyeffective,sometimes
horse(Clarketal.,2023),andwhilehumanagree- evenmoresothanwhendonemonolingually. Com-
mentwasnotreportedinOpenAssistant,theygen- pared to PaLM-2-L, the two LMs agree on 72%
erally match the human agreement numbers in of the instances in English and 71% in Spanish
pastworkondialoggeneration(Baietal.,2022a; for summarization, and 75% and 73% for these
Duboisetal.,2024)too(see§5.1forreferencehu- languages for dialog. These are higher than theSummarization cross-lingual alignment. There, we showed that
thesource-languageRMsassignhigherscoresto
bettertarget-languagegenerationsthanworseones.
Here,weconsideranalternativesetuptostudythe
sameproblem: insteadofrelyingonexistingRM
datasets for the better and worse generations, we
takegenerationsfrommonolingually-alignedmod-
0.0 0.5 1.0 1.5 2.0
els as better ones than those fromunaligned (i.e.,
Source-Lg. RM Score Increase
SFT)models. Theassumptionhereisthatmono-
Dialog lingualalignmentimprovesmodelquality,which
is indeed the case as illustrated in Figure 4 and
9. Like in §6.1, we indeed see from Figure 10
thatsource-languageRMsassignhigherscoresto
monolingually-alignedmodelsthanunalignedSFT
models. Under RL, this score difference also in-
creasesthroughouttraining. Theseresultsconfirm
0.0 0.5 1.0 1.5 2.0
theRMs’cross-lingualgeneralizabilitywithinthe
Source-Lg. RM Score Increase
rewardmodelingtask.
(a) Best-of-n
F AlignmentUsingBilingualRMs
Summarization
0.8
Seeing the benefit of cross-lingual RM transfer-
0.7
ability in §5, we hypothesize that bilingual RMs
0.6
couldbringfurtherimprovementssincetheresult- 0.5
ing reward could be encouraged to be more lan-
0.4
guageagnostic(Mulcaireetal.,2019). Itwouldbe
0.3
0.2 computationallyexpensivetoexperimentwithall
0.1 possiblelanguageconfigurations(therewouldbea
0.0 cubicnumberofthemwithpairwisesources),so,
0 500 1000 1500 2000 2500 3000 forsimplicity,wetakethebest-performingsource
RL Training Steps
languagesunderthesummarizationbest-of-nsetup
(b) RL
asjudgedbyPaLM-2-L,EnglishandGerman(Fig-
Figure10: Source-languageRMgeneralizabilityevalu-
ure 6), and see if a bilingual RM based on them
atedbyincreasesinscorestheyassigntotarget-language
would lead to further performance improvement.
generations after monolingual target-language align-
ment (best-of-n or RL). We show all (source, target) Specifically, we first train a bilingual SFT model
languagepairswherethetwolanguagesdifferasden- by pooling the SFT data for both languages, and
sity in (a) and lines in (b). RL is difficult to train for similarly for the RM, which initializes from this
OpenAssistant (§4), so we omit it here, since the as- bilingualSFTmodel.
sumptionthattheRL’edmodelisbetterwouldnothold.
Figure11doesnotshowanimprovementfrom
In most cases, the source-language RM assigns a
the bilingual RM, which always achieves similar
higherscore(>0increase)toalignedmodels,demon-
performancetotheEnglishRM,thebetterofthe
stratingcross-lingualRMgeneralizability.
twomonolingualRMs. Nevertheless,ifthistrend
holdsconsistently,thatthebilingualRMmatches
baselinehuman-humanagreementnumbersin§5.1.
the performance of the better monolingual RM,
This shows a sign of homogeneity between LM
thiscouldbeusefulasanalternativetohavingto
judges,butalsoconfirmstheirreliability.
perform source language selection. We leave a
moresystematicvalidationofthisphenomenonto
E VerifyingRMTransferforReward
futurework.
Modeling
In §6.1, we observed RM generalizability on the G Prompts
original reward modeling task, which would be
a necessary condition for successful downstream Inthissection,welistallthepromptsweused.
ytisneD
ytisneD
esaercnI
erocS
MR
.gL-ecruoSSummarization
100
German RM
English RM
75
German + English RM
50
25
0
de en es ru tr vi
Target Language
Figure11: Alignmentperformance,measuredinthewinrateagainstthemonolingualtarget-languageSFTmodel,
whenalignmentisdrivenbyaGermanRM,anEnglishRM,orabilingualGerman+EnglishRM.Thebilingual
RMdoesnotyieldanoticeableimprovement.
G.1 TaskInstructions conveys the key information from the
original post. Below we define four
Weprependthefollowingtask-specificinstructions
evaluation axes for summary quality:
to inputs for SFT and reward optimization. All
coherence, accuracy, coverage, and overall
occurrences of [LANGUAGE] are substituted with
quality.
thetargetlanguage. TheRMstagedoesnotinclude
such prompts, where we simply concatenate the
Coherence: This axis answers the question
textswithdelimiters.
“how coherent is the summary on its own?”
Summarization: Summarize the following
A summary is coherent if it's easy to
text in [LANGUAGE]:
understand when read on its own and free of
Dialoggeneration: You are given a dialog
English errors. A summary is not coherent
between a human and an assistant in
if it's difficult to understand what the
[LANGUAGE]. Please write one turn of the
summary is trying to say. Generally, it's
assistant side in [LANGUAGE].\n\n”
more important that the summary is
G.2 EvaluationPrompts understandable than it being free of
grammar errors.
We use the following prompts to elicit pairwise
generation judgments for both human and LM
judgeevaluation. Alloccurrencesof[LANGUAGE], Accuracy: This axis answers the question
[INPUT], [GENERATION1], and [GENERATION2] “does the factual information in the
summary accurately match the post?” A
are substituted with the respective content. For
summary is accurate if it doesn't say
both tasks, we compare the probability of the to-
kens“1”and“2”. Tocontrolforthepositionalbias things that aren't in the article, it
doesn't mix up people, and generally is
ofLMs(Wangetal.,2023a;PezeshkpourandHr-
not misleading.
uschka,2023;Zhengetal.,2023)andpotentiallyof
ourhumanannotators,werandomlyshufflethetwo
Coverage: This axis answers the question
generations for human evaluation and the GPT-4
“how well does the summary cover the
judge. For the PaLM-2 judge for which we have
important information in the post?” A
probabilityaccess,weprompttheLMjudgetwice
summary has good coverage if it mentions
withbothorderingsofthegenerationsandcompute
the main information from the post that's
theaccuracybyaveragingtheprobabilitiesofthe
“1”and“2”tokens. important to understand the situation
described in the post. A summary has poor
Summarization. This prompt is adapted from coverage if someone reading only the
theoneinLeeetal.(2023). summary would be missing several important
A good summary is a shorter piece of text pieces of information about the situation
that has the essence of the original. It in the post. A summary with good coverage
tries to accomplish the same purpose and should also match the purpose of the
)%(
TFS
tsniagA
etaR
niWoriginal post (e.g. to ask for advice).
Src\Tgt De En Es Ru Tr Vi
Overall quality: This axis answers the De 52.3 50.8 63.0 66.7 63.0 60.4
question “how good is the summary overall En 56.4 55.5 66.1 70.7 67.2 63.1
at representing the post?” This can Es 51.9 51.2 62.4 66.0 64.4 57.5
encompass all of the above axes of quality, Ru 48.1 46.5 59.2 63.6 59.0 56.3
as well as others you feel are important. Tr 53.3 52.9 62.6 66.6 60.4 59.0
If it's hard to find ways to make the Vi 46.5 48.2 60.0 65.6 62.1 58.0
summary better, the overall quality is
Table6: Cross-lingualalignmentresultsusingbest-of-
good. If there are lots of different ways nwithn=64,forthesummarizationtask,measured
the summary can be made better, the overall inwinrate(%)againstthetarget-languageSFTmodel
quality is bad. asjudgedbyPaLM-2-L(Figure4).
You are an expert summary rater and are Src\Tgt En Es Ru
knowledgeable in [LANGUAGE]. Given a
En 62.9 65.0 59.6
piece of text in [LANGUAGE] and two of its
Es 59.1 62.4 57.6
possible summaries, also in [LANGUAGE],
Ru 53.4 54.3 52.5
output 1 or 2 to indicate which summary
best adheres to coherence, accuracy, Table 7: Cross-lingual alignment results using best-
coverage, and overall quality as defined of-nwithn=64,forthedialoggenerationtask,mea-
above. suredinwinrate(%)againstthetarget-languageSFT
modelasjudgedbyPaLM-2-L(Figure4).
Text - [INPUT]
Summary 1 - [GENERATION1] "model": "model_1",
Summary 2 - [GENERATION2] "answer": """[GENERATION1]"""
}},
Preferred Summary= {{
"model": "model_2",
DialogGeneration Thispromptisadaptedfrom
"answer": """[GENERATION2]"""
theoneinLietal.(2023b).
}}
You are a helpful assistant, that ranks ]
models by the quality of their answers.
You are also knowledgeable in [LANGUAGE]. Respond 1 or 2 to indicate the better
output. Please provide the ranking that
I want you to create a leaderboard of the majority of humans would give.
different large-language models. To do
so, I will give you the instructions Better output=
(prompts) given to the models, and the
responses of two models. Please rank the H RawResults
models based on which response would be
Weshowtherawnumericalresultsthatcorrespond
preferred by humans. All inputs are
toourplotsinTable6to25.
python dictionaries.
Here is the prompt, in [LANGUAGE]:
{{
"instruction": """[INPUT]""",
}}
Here are the outputs of the models, also
in [LANGUAGE]:
[
{{Src\Tgt De En Es Ru Tr Vi
Src\Tgt De En Es Ru Tr Vi
De 59.8 59.9 58.4 50.0 55.8 62.4
De 59.4 61.0 59.4 49.6 52.5 59.3
En 59.4 61.8 59.7 52.1 59.6 61.2
En 55.9 59.9 58.5 52.6 54.8 56.6
Es 57.6 59.7 58.8 52.0 60.4 60.1
Es 52.0 56.1 56.8 53.0 55.0 49.9
Ru 56.9 56.5 56.4 52.0 57.4 58.0
Ru 54.8 55.2 56.8 51.8 53.3 52.2
Tr 59.9 60.7 59.0 52.2 60.1 62.8
Tr 53.1 54.6 55.7 53.1 53.4 56.3
Vi 60.5 64.1 63.1 52.5 64.4 61.6
Vi 63.9 61.8 65.2 54.6 55.1 53.6
Table12: Cross-lingualalignmentresultsusingRL,
Table 8: Cross-lingual alignment results using RL,
forthesummarizationtask,measuredinwinrate(%)
forthesummarizationtask,measuredinwinrate(%)
against the target-language SFT model as judged by
against the target-language SFT model as judged by
GPT-4(Figure9).
PaLM-2-L(Figure4).
Src\Tgt En Es Ru
Src\Tgt En Es Ru
En 51.7 51.9 51.5
En 53.1 54.5 53.5 Es 49.9 51.5 52.5
Es 49.9 51.1 47.5 Ru 48.5 51.6 51.5
Ru 51.2 52.7 52.5
Table13: Cross-lingualalignmentresultsusingRL,
for the dialog generation task, measured in win rate
Table9: Cross-lingualalignmentresultsusingRL,for
(%)againstthetarget-languageSFTmodelasjudged
thedialoggenerationtask,measuredinwinrate(%)
byGPT-4(Figure9).
against the target-language SFT model as judged by
PaLM-2-L(Figure4).
Src\Tgt En Es
De 61.0 64.0
Src\Tgt De En Es Ru Tr Vi
En 60.9 67.4
De 49.0 50.2 58.2 63.6 57.6 56.6 Es 62.6 69.0
En 52.6 56.6 62.7 70.2 67.0 62.1 Ru 51.9 63.4
Es 51.7 54.1 59.8 65.9 63.6 59.2 Tr 61.8 66.3
Ru 48.7 51.2 56.0 63.0 59.0 56.8 Vi 52.3 61.2
Tr 56.7 57.8 62.3 69.5 66.6 61.5
Table14: Cross-lingualalignmentresultsusingbest-
Vi 45.2 52.1 56.6 62.8 60.5 56.5
of-n,forthesummarizationtask,measuredinwinrate
Table10: Cross-lingualalignmentresultsusingbest-of- (%)againstthetarget-languageSFTmodelasjudged
nwithn=64,forthesummarizationtask,measured byhumanevaluators(Figure2).
inwinrate(%)againstthetarget-languageSFTmodel
asjudgedbyGPT-4(Figure9).
Src\Tgt En Es
De 64.4 64.2
Src\Tgt En Es Ru En 61.4 65.9
Es 58.7 62.7
En 53.7 58.0 60.6
Ru 61.9 60.6
Es 50.7 56.6 56.6
Tr 63.3 64.9
Ru 50.4 48.6 48.5
Vi 66.2 64.7
Table11: Cross-lingualalignmentresultsusingbest-
Table15: Cross-lingualalignmentresultsusingRL,
of-nwithn=64,forthedialoggenerationtask,mea-
forthesummarizationtask,measuredinwinrate(%)
suredinwinrate(%)againstthetarget-languageSFT
against the target-language SFT model as judged by
modelasjudgedbyGPT-4(Figure9).
humanevaluators(Figure2).Src\Tgt En Es
Src\Tgt De En Es Ru Tr Vi
En 67.6 52.0
Es 71.4 56.4 De 0.92 0.78 0.83 0.01 0.37 1.92
En 1.50 1.32 1.01 0.02 0.83 3.30
Table16: Cross-lingualalignmentresultsusingbest-
Es 1.78 1.63 1.51 0.10 1.39 3.92
of-nwithn=64,forthedialoggenerationtask,mea-
suredinwinrate(%)againstthetarget-languageSFT Ru 0.79 0.45 0.46 0.02 0.36 1.26
modelasjudgedbyhumanevaluators(Figure2). Tr 2.20 1.91 1.83 0.15 1.34 4.28
Vi 1.78 2.52 1.74 0.02 1.47 4.37
Table20: KL-divergenceoftheRLmodelsfromthe
Src\Tgt De En Es Ru Tr Vi
correspondingtarget-languageSFTmodelforthesum-
De – 50.0 61.9 66.1 66.1 54.6 marizationtask(Figure8).
En 47.9 – 63.3 64.9 64.5 53.1
Es 50.6 52.9 – 64.1 64.5 59.0
Ru 47.4 51.2 60.3 – 63.3 57.7
Tr 50.6 52.5 61.8 65.6 – 50.8
Vi 42.0 50.8 59.1 64.4 63.6 –
Lg. De En Es Ru Tr Vi
Table17: AlignmentqualityusingRMtrainedbytrans- Mono. 36.2 38.9 32.9 16.9 35.2 41.8
latingthesourcelanguagedataintothetargetlanguage
Lg→En 27.8 – 27.1 22.4 28.2 26.7
usingbest-of-nwithn=64,forthesummarizationtask,
En→Lg 16.1 – 24.6 13.6 29.9 40.3
measured in win rate (%) against the target-language
En→Lg→En 36.5 – 36.1 35.4 36.5 35.8
SFTmodelasjudgedbyPaLM-2-L(§5.1).
Lg→En→Lg 32.5 – 26.6 12.2 32.1 34.9
Table 21: ROUGE-L score when the SFT model is
Src\Tgt De En Es Ru Tr Vi trainedusingdifferentstrategies,eithermonolingually,
translated from a source language, or back-translated
De 71.0 64.8 68.0 67.9 67.5 67.7
intoasourcelanguageandthenback(Figure5(a)).
En 62.2 67.4 67.9 66.3 66.5 70.8
Es 67.4 62.7 72.3 69.7 71.4 65.2
Ru 66.5 61.3 65.4 65.7 66.5 63.6
Tr 66.8 64.6 68.5 69.1 73.2 68.7
Vi 63.0 66.7 68.6 66.5 67.8 71.3
Lg. De Es Ru Tr Vi
Majority 52.9 59.5 63.1 55.1 56.2 67.9
Target-languageSFT;RMtransferonly
Length 56.6 59.5 63.1 55.1 55.2 67.9
Lg→En 50.8 51.2 46.5 52.9 48.2
Table18: RMgeneralizabilitywithintherewardmodel-
En→Lg 56.4 66.1 70.7 67.2 63.1
ingtaskevaluatedbyaccuracy(%)onin-taskvalidation
dataforthesummarizationtask,onthesixSeahorselan-
(Back-)TranslatedSFT
guages,aswellasthemajoritybaselineandthelength
baseline(§6.1)(Figure7). Lg→En 36.6 26.6 29.8 37.5 31.8
En→Lg 14.4 43.5 43.9 47.1 41.6
En→Lg→En 42.7 43.2 40.1 41.4 37.1
Src\Tgt En Es Ru Lg→En→Lg 45.3 54.0 60.1 61.7 51.1
En 68.4 68.4 76.3
Table 22: Alignment performance using best-of-n,
Es 65.4 67.8 77.0 measuredinthewinrateagainstthemonolingualtarget
Ru 56.6 63.5 64.4 languageSFTmodelasjudgedbyPaLM-2-L,whenthe
SFT model is trained using different strategies. The
Length 66.1 68.1 71.1
firstsectionusesaSFTmodelthatistrainedontarget-
language datasets (same as Table 6), while the sec-
Table19: RMgeneralizabilitywithintherewardmodel-
ond uses translated or back-translated SFT data (Fig-
ingtaskevaluatedbyaccuracy(%)onin-taskvalidation
ure5(b)).
dataforthedialoggenerationtask,inthreelanguages,
aswellasthelengthbaseline(§6.1)(Figure7).Lg. De Es Ru Tr Vi
Target-languageSFT;RMtransferonly
Lg→En 38.3 32.4 38.6 32.9 29.2
En→Lg 62.8 59.4 53.7 47.4 66.4
(Back-)TranslatedSFT
Lg→En 40.5 29.1 33.2 26.0 19.4
En→Lg 45.7 50.3 60.3 37.1 67.6
En→Lg→En 31.4 33.9 34.0 40.8 31.7
Lg→En→Lg 40.3 31.2 40.1 45.9 61.4
Table 23: Alignment performance using best-of-n,
measuredinthewinrateagainstthemonolingualtarget
languageSFTmodelasjudgedbyPaLM-2-L,whenthe
SFT model is trained using different strategies. The
firstsectionusesaSFTmodelthatistrainedontarget-
languagedatasets,whilethesecondusestranslatedor
back-translatedSFTdata. Here,weonlyconsiderthe
WikiLinguadatasetforbothSFTandRM(Figure5(c)).
Lg. De Es Ru Tr Vi
Target-languageSFT;RMtransferonly
Lg→En 61.0 56.1 55.2 54.6 61.8
En→Lg 55.9 58.5 52.6 54.8 56.6
(Back-)TranslatedSFT
Lg→En 60.2 37.5 22.7 54.9 19.2
En→Lg 28.8 57.0 56.5 59.6 51.9
En→Lg→En 47.5 46.7 42.1 42.4 48.3
Lg→En→Lg 44.7 45.1 46.6 49.5 30.7
Table 24: Alignment performance using RL, mea-
sured in the win rate against the monolingual target
languageSFTmodelasjudgedbyPaLM-2-L,whenthe
SFT model is trained using different strategies. The
firstsectionusesaSFTmodelthatistrainedontarget-
languagedatasets,whilethesecondusestranslatedor
back-translatedSFTdata(Figure5(d)).
Src\Tgt De En Es Ru Tr Vi
De 52.3 50.8 63.0 66.7 63.0 60.4
En 56.4 55.5 66.1 70.7 67.2 63.1
De+En 56.6 55.7 66.6 70.6 66.7 64.1
Table 25: Alignment performance using best-of-n,
measuredinthewinrateagainstthemonolingualtarget
language SFT model as judged by PaLM-2-L, when
usingeitheramonolingualRM(sameasTable6)ora
bilingualRM(Figure11).