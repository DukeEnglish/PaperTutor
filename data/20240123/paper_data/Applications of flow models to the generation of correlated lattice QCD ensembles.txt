MIT-CTP/5658,FERMILAB-PUB-24-0014-T
Applications of flow models to the generation of correlated lattice QCD ensembles
RyanAbbott,1,2 AleksandarBotev,3 DenisBoyda,1,2 DanielC.Hackett,4,1,2 GurtejKanwar,5 S´ebastienRacani`ere,3
Danilo J. Rezende,3 Fernando Romero-L´opez,1,2 Phiala E. Shanahan,1,2 and Julian M. Urban1,2
1Center for Theoretical Physics, Massachusetts Institute of Technology, Cambridge, MA 02139, USA
2The NSF AI Institute for Artificial Intelligence and Fundamental Interactions
3Google DeepMind, London, UK
4Fermi National Accelerator Laboratory, Batavia, IL 60510, U.S.A.
5Albert Einstein Center, Institute for Theoretical Physics, University of Bern, 3012 Bern, Switzerland
Machine-learned normalizing flows can be used in the context of lattice quantum field theory to
generatestatisticallycorrelatedensemblesoflatticegaugefieldsatdifferentactionparameters. This
workdemonstrateshowthesecorrelationscanbeexploitedforvariancereductioninthecomputation
ofobservables. Threedifferentproof-of-conceptapplicationsaredemonstratedusinganovelresidual
flow architecture: continuum limits of gauge theories, the mass dependence of QCD observables,
and hadronic matrix elements based on the Feynman-Hellmann approach. In all three cases, it
is shown that statistical uncertainties are significantly reduced when machine-learned flows are
incorporated as compared with the same calculations performed with uncorrelated ensembles or
direct reweighting.
I. INTRODUCTION defined by different Euclidean lattice action parameters.
Such flows can be used to generate multiple statistically
correlated ensembles at different parameters. As we ex-
Understanding the strongly interacting sector of the
ploreinthiswork,thismaybeparticularlyvaluablewhen
StandardModelofparticlephysics,describedbythethe-
the variation of some quantity with respect to the action
ory of quantum chromodynamics (QCD), is essential for
parameter is of physical or computational interest—see
advancing particle and nuclear physics. The numerical
alsoRefs.[46,47]. Theadvantageofflowsinthiscontext
framework of lattice QCD is a systematically improv-
originates from correlated cancellations of uncertainties
able tool to explore the dynamics of the strong nuclear
between expectation values evaluated at different action
force. This approach has enabled precise calculations
parameters, which leads to reductions in the number of
across applications spanning from hadron structure to
configurations needed to achieve a fixed statistical error.
high-temperature QCD and nuclear physics [1, 2]. Nev-
Examples of physically relevant applications of deriva-
ertheless, there is great potential to extend the reach
tives with respect to action parameters include contin-
of lattice QCD beyond the current state of the art if
uum and chiral extrapolations as well as the compu-
computational challenges such as critical slowing down,
tation of matrix elements such as the chiral conden-
topological freezing, and signal-to-noise problems can be
sate, the nucleon sigma term, or other observables, us-
overcome. In this context, emerging machine learning
ing Feynman-Hellmann techniques. Another is deriva-
techniques offer a promising avenue towards mitigating
tives with respect to the electromagnetic coupling for
these computational obstacles [3, 4].
scalesettingortocomputeisospinbreakingcorrectionsin
A growing community effort is developing at the in- QCD+QED[48,49]. Onemayalsoconsiderapplications
tersectionofmachinelearningandlatticeQCD—seee.g. in theories with a sign problem, e.g., to derivatives with
Refs. [5–9] for a selection of applications. In particu- respect to the baryon chemical potential or the QCD θ-
lar, generative flow models [10–12] are one of several term. Inallofthesecases,thedistributionstoberelated
promising pathways which show potential to accelerate by a flow transformation are much more similar than in
the sampling of lattice field configurations. This line of applicationsintendedtoacceleratesampling,andcurrent
investigation is developing, with demonstrations in 2D flow methods can already be applied at the scale of typi-
theories [9, 13–40] and first applications to 4D gauge callatticeQCDcalculations. Threeselectedapplications
theories with and without fermions [41–43]. While the are investigated, namely the continuum extrapolation of
field is progressing rapidly, achieving high-quality mod- gradient flow scales, the computation of the gluon mo-
els that can be applied at the scale of state-of-the-art mentum fraction of the pion in quenched lattice QCD
calculations still requires further engineering [44]. In using the Feynman-Hellmann approach, and the mass
addition to their promise in the context of sampling, dependence of observables in N =2 QCD.
f
flow models—functioning as approximate maps between
This paper is organized as follows. In Section II, we
distributions—canbeusedtoacceleratelatticeQCDcal-
discuss preliminaries on flows, their applicability in the
culations in qualitatively different ways. For example,
context of correlated ensembles, and the residual flow
flow models provide a promising new approach to deter-
architectures used in this work. The three numerical
mining thermodynamic observables [9, 30, 39, 45].
demonstrationsarepresentedinSectionIII.Weconclude
Inthiswork,weexploreapplicationswhichutilizeflows inSectionIV.AppendixAprovidesfurtherdetailsofthe
to map gauge field configurations between distributions flow models used in this work.
4202
naJ
91
]tal-peh[
1v47801.1042:viXra2
II. FLOWS FOR THE GENERATION OF In practice, a learned flow is not perfect, but may
CORRELATED ENSEMBLES function as an approximate map between distributions.
Toensurecorrectnessofexpectationvaluescomputedon
A. Flows for lattice QCD theflowed configurations, onemayusetheindependence
Metropolisalgorithm[53–55]orsimplyreweighting,with
the weight of each configuration given by w(U). Expec-
This section presents an introduction to normalizing
tation values of observables such as plaquettes, hadronic
flows [10–12], reviewing the key ideas relevant for the
correlation functions, or the topological charge can be
present work.
directly reweighted as
A “flow” is defined as a diffeomorphism f between
probability distributions that maps samples from a base
= w , (4)
(orprior)distribution,r(U),toamodeldistributionwith ⟨O⟩p ⟨ O⟩q
density
wherethenotation isusedtorefertoexpectationval-
q
⟨⟩
−1 ueswithrespecttotheprobabilitydistributionq,andwe
∂f(U)
q(V)=r(U) det , (1) assume the reweighting factors have been properly nor-
∂U
(cid:12) (cid:12) malized such that w q = 1. Derived quantities, such as
(cid:12) (cid:12) ⟨ ⟩
where V = f(U). Flows c(cid:12)an be cons(cid:12)tructed such that gradient flow scales or hadron masses, can be computed
(cid:12) (cid:12)
from reweighted correlation functions.
they have many free, trainable parameters. These pa-
rameters may be optimized such that the model dis-
tribution approximates some target distribution p, i.e.,
B. Correlated ensembles and flows
q(V) p(V).
≃
For the applications explored in this work, flow mod-
Whileapplicationsofflowstoacceleratethegeneration
els are constructed in which the samples U are lat-
of field configurations continue to advance, here we de-
tice gauge-field configurations, and the probability dis-
scribe another avenue for flow models to improve lattice
tributions p(U) and r(U) are defined in terms of Eu-
QCDcalculationsbyreducingthevarianceofobservables
clidean lattice actions such that r(U) exp( S (U)),
0
∝ − that can be computed from differences between quanti-
and p(V) exp( S (V)). In most cases, it is not neces-
1
∝ − ties at different action parameters. The key idea is the
sary to know the normalization of p or r (the exception
following. Consideragenericparameteroftheaction, α.
being thermodynamic observables [9]).
The goal is to compute some observable as a function
Expressive flow transformations can be constructed in
O
of α, and in particular the derivative
a variety of ways, for example as the composition of n
invertible layers
d
⟨O⟩
⟨O⟩α1 −⟨O⟩α2
, (5)
f =g g ... g . (2) dα ≃ ∆α
1 2 n
◦ ◦ ◦
where the right-hand side is a finite-difference approxi-
Architectures for invertible layers g which act on lat-
i
mation of the derivative using ∆α = α α , with
tice gauge fields have been discussed in Ref. [43]. The 1 2 α
− ⟨⟩
denoting the expectation under the distribution defined
particular constructions used in this work are detailed
by the action parameter α, i.e., p . Higher order deriva-
in Section IIC. Given a model, its trainable parameters α
tives, or derivatives of one observable with respect to
may be optimized in various ways. One choice is to min-
another, may be computed in a similar way.
imize the Kullback-Leibler (KL) divergence [50] between
In this work, we consider three qualitatively different
the model and target distributions. Approaches such as
approachestothecomputationofthequantityinEq.(5).
path gradients [51], related control variate methods [43],
The first two are standard tools in common use:
as well as the “REINFORCE” algorithm [52], may be
be used to improve and accelerate training dynamics by
1. Use a very small step ∆α = ϵ, and compute the
reducing the variance associated with stochastic gradi-
numerator in Eq. (5) with ϵ reweighting:
ent estimates. After optimization, model quality can be
characterized using the Effective Sample Size per config- = w , (6)
uration (ESS),
⟨O⟩α1 −⟨O⟩α1+ϵ
⟨O−
ϵ O⟩α1
where w = p /p . The separation ϵ may be
2
ϵ α1+ϵ α1
N w(V ) made small without compromising signal-to-noise
1 i=1 i
ESS = , (3) due to correlated noise cancellations between the
N (cid:104) (cid:80)N
i=1
w(V i)(cid:105)2 twoexpectationvalues. Asϵ 0itbecomesexact,
→
recoveringanestimatestatisticallyidenticaltothat
estimated using N gaug(cid:80)e fiel(cid:2)d con(cid:3)figurations gener-
obtained by applying the derivative analytically.
ated from q(V), and where w(V ) = p(V )/q(V ) is the
i i i
reweightingfactoroftheithconfiguration. Thevaluesof 2. Generate independent ensembles to separately
theESSlieintheintervalESS [1/N, 1], withESS=1 computeexpectationvaluesatα andα inEq.(5).
1 2
∈
corresponding to a perfect model. Thisenablesuseofmuchmorewidelyseparatedα
13
and α than accessible with reweighting, thereby that is, g for any givenactivelink dependson all frozen
2 x
allowing exploitation of the bias-variance trade- links but only the same active link. This separation of
off to reduce statistical uncertainties while ac- variables allows efficient computation of the Jacobian of
cepting additional discretization artifacts from the thetransformationusingautomaticdifferentiationasde-
finite-difference approximation in order to improve scribed in Eq. (26) of Ref. [43]. In the present work, we
signal-to-noise. However, this effect must be suf- use two partitioning schemes for the site index:
ficiently large to compensate for the lack of corre-
1. Acheckerboardor“mod2”maskingpattern,where
lated noise cancellations.
theactivelinksarethosewithdirectionµinthepo-
These two methods each have different capabilities, with sitionsthatsatisfy(p+ x )=0(mod2)forfor
µ µ
eachusefulfordifferentapplications. Incorporatingflows p 0,1. A stack of 8 layers is needed to trans-
provides an additional approach that combines some of for∈ m all links, i.e., 2 com(cid:80) plementary checkerboards
the advantages of both: in each of the 4 directions µ.
3. Use a trained flow model to map configurations 2. A “mod 4” masking pattern, where the positions
between the distributions given by α 1 and α 2. In- of active links satisfy (p+ µx µ)=0(mod4), for
cluding flow reweighting factors, correlated differ- p 0,1,2,3. 16layersarethusneededtotransform
ences can be calculated as: ev∈ ery link on the lattice. (cid:80)
(U) w(f(U)) (f(U)) , (7) The function g (U ,U (x )) must be constructed in a
⟨O − O ⟩α1 x f µ a
waythatisexpressivebutsimpletoevaluate. Onesimple
where w(f(U)) = p (f(U))/q(f(U)), such that a
α2 construction utilizes 1 1 staples,
perfect flow would remove the reweighting factors ×
entirely. This approach benefits from the same SR (U)=U (x+µ)U†(x+ν)U†(x) and
x,µν ν µ ν
correlated cancellation of uncertainties as does ϵ (10)
SL (U)=U†(x+µ ν)U†(x ν)U (x ν) ,
reweighting, while allowing for larger steps in ∆α x,µν ν − µ − ν −
toexploitthebias-variancetradeoffasdoestheap-
such that the 1 1 loops,
proach using independent ensembles. ×
In Section III below, we provide numerical demonstra- W xR ,µν(U)=U µ(x)S xR ,µν(U f) and
(11)
tions of the advantages of this flow-based approach. WL (U)=U (x)SL (U ) ,
x,µν µ x,µν f
havethesamegaugetransformationasg . Onecanthen
x
C. Architecture based on residual flows define a covariant algebra-valued object as, e.g.,
Theflowarchitectureusedinthisworkisbasedonthat G x,µ = α µ(1 ν) P(W x,µν(U))
introduced in Ref. [43], with a series of improvements ν̸=µ
(cid:88) (12)
that are detailed below. The flow transformation is de-
+ α(2) (W (U)W (U)) ,
fined as the composition of trainable gauge-equivariant µνρP x,µν x,µρ
ν,ρ̸=µ
layers that act directly on the gauge links. The trans- (cid:88)
formation of a gauge field U U′ through an SU(N)- whereW =WR +WL ,and (W)isthetraceless
residual layer can be expressed→ as x,µν x,µν x,µν P
(1) (2)
anti-HermitianprojectionofW. Moreover,α andα
µν µνρ
U′(x)=egx(U)U (x) , (8) are d 1 and (d 1)2 trainable parameters in d space-
µ µ − −
time dimensions for fixed µ, respectively. Any polyno-
where g x(U) is an algebra-valued matrix which can in mial function of G
x,µ
with coefficients that are arbitrary
principle have an arbitrary dependence on the entire function of Tr[G G† ] is thus gauge covariant and can
x,µ x,µ
gauge-field configuration, as long as it transforms locally be used to construct g (U). One choice of such a con-
x
undergaugetransformations, g x(U) →Ω† xg x(U)Ω x; here struction is:
Ω denotes a gauge transformation and the subscript la-
x
bels the spacetime dependence. This transformation can g (U ,U (x ))=G f Tr[G G† ] , (13)
x f µ a x,µ × x,µ x,µ
be inverted by fixed point iteration, with a unique solu-
tion guaranteed if the Lipschitz continuity condition is where f(x) is e.g., a ratio o(cid:0)f polynomials(cid:1)—see Ap-
satisfied [43]. pendix A for an example.
For numerical tractability, each layer partitions the A useful modification to this construction is to con-
gauge field and transforms only the active links, defined sider Wilson loops that are larger than 1 1. Sums of
×
asthosewithfixeddirectionµonasubsetoflatticesites such loops can be constructed iteratively, by repeatedly
x , conditioned on the values of the remaining frozen adding together links and staples which transform in the
a
l{ ink} s U . Each layer acts as same way, and finally computing a 1 1 loop. This is
f ×
inspired by similar transformations used in Refs. [41, 56]
U µ′(x a)=egx(Uf,Uµ(xa))U µ(x a) , (9) and resembles the learned smearing of Ref. [57]. This4
The flow models used in these applications are sum-
marized in Table I. All flow models have been optimized
usingpathgradients[51]asdescribedinRef.[43]. Gauge
field samples for both training and evaluation are ob-
tainedusingstandardMarkovChainMonteCarlometh-
ods, specifically the (pseudo-)heatbath algorithm with
overrelaxation[58–62]forYang-MillstheoryandtheHy-
FIG. 1. Sketch of the recursive transformation, Eq. (14), to brid/HamiltonianMonteCarlo[63](HMC)algorithmfor
build generic Wilson loops in the residual layers. QCD.
gauge-equivariant “convolution” can be written explic- A. Continuum limit of gauge theories
itly as the recursion
One application in lattice QCD for flow-correlated en-
V(i+1) =V(i)+ ηℓ (Rℓ (V(i))+Lℓ (V(i))) , (14)
µ µ i,ρ µρ µρ semblesisintakingthecontinuumlimit. Foranumerical
ρ (cid:88)̸=µ, demonstration, we consider gradient flow scales.
ℓ
We use the pure-gauge SU(3) theory, with action
where
β
V(0)(x)=
U µ(x) U µ(x) is frozen,
(15)
S g(U)=
−N
cTr Re U µν , (16)
µ (cid:40)0 U µ(x) is active, µ (cid:88)>ν
where β is the inverse squared bare gauge coupling and
ηℓ aretrainablecoefficients,andLℓ andRℓ labelgeneric
i,ρ U µν istheplaquette. Thecontinuumlimitoflatticespac-
staple-likeobjectsthattransforminthesamewayasthe
ing a 0 corresponds to β .
gauge links. Here we use two explicit choices, R1 = → →∞
µν Oneclassofobservablesisobtainedbyusingthegradi-
(S xR ,µν)† in Eq. (10) and R µ2 ν = W xR ,µνU µ, and similarly entflow;inparticular,ascalet c canbedefinedimplicitly
forLℓ ;seeFigure1. NotethatinEq.(14),theseobjects from
µν
are computed using the variables V(i). After iterating,
V(i) isnotanelementofthegaugegroup, butthisisnot ⟨t2E(t) ⟩|t=tc =c , (17)
important since ultimately there is a projection to the
where c is a numerical constant, and E(t) is the energy
algebra to construct G in Eq. (12).
µ density at flow time t, for which we use the plaquette
The iterative procedure in Eq. (14) can be used to
definition; see Ref. [64]. The choice c = 0.3 defines the
construct expressive residual layers. After applying n
pt scale t , often referred to as “t ”. One can compute
iterations of Eq. (14) to Eq. (15), the resulting val- 0.3 0
the ratio of two gradient flow scales t /t , which can
ues of V(npt) can be used to construct the quantity 0.3 0.35
be related to the ratio of the the strong coupling at two
g x(V(npt),U µ(x a)) that enters in the transformation of
different energy scales [64]. The continuum limit of this
the residual layer defined in Eq. (9). Specifically, the
quantity takes the form
convolutedfrozenlinks, V(npt), areusedtoconstructthe
staples in Eq. (11) in spite of U f. t t a2
0.3 0.3
= +k + , (18)
1
t t t ···
0.35(cid:12)lat 0.35(cid:12)cont 0.3
(cid:12) (cid:12)
III. EXAMPLE APPLICATIONS (cid:12) (cid:12)
where k
1
is a (cid:12)dimensionle(cid:12)ss constant, the ellipsis indi-
cateshigherordersina2,thesubscripts“lat”and“cont”
Physics contexts in which derivatives of the form of
refertofinite-aandcontinuumvalues,anddiscretization
Eq. (5) arise are ubiquitous; here we discuss three ex- effects are parameterized by powers of a2/t .
0.3
amples. First, derivatives with respect to the gauge
The standard approach for performing a continuum
coupling β can be used to constrain continuum extrap-
extrapolationinlatticeQCDreliesoncomputingthede-
olations. Second, matrix elements may be computed
sired quantity at several different lattice spacings using
using Feynman-Hellmann techniques, where derivatives
independent ensembles and extrapolating. This method
with respect to action parameters correspond to single
can be improved by additional constraints on such an
insertions of the corresponding operator. Second-order
extrapolation in the form of derivatives
derivatives using Feynman-Hellmann also access physi-
callyrelevantprocesses,e.g.,Comptonscattering. Third, d(t /t )
k(a2)= 0.3 0.35 =k +O(a2) . (19)
derivatives with respect to the quark mass can be em- d(a2/t ) 1
0.3
ployed to constrain chiral extrapolations or in calcula-
tions of e.g., sigma terms. This section presents numer- Without generating more ensembles, this derivative can
ical demonstrations using flows to improve estimates of be computed using finite differences combined with ϵ
these three kinds of derivatives. reweighting or with flows to nearby values of the lattice5
spacing,orequivalently,valuesofthebaregaugecoupling 0.860
β: flowedensemble
0.858 ensembleatβ=6.02
withflowedensemble
k(a2)
tt 00 .. 33
5 β+∆β −
tt 00 .. 33
5 β . (20)
0.856 (cid:15)reweighting
≃ a2 (cid:12) a2 (cid:12) 0.854
t0.3(cid:12)β+∆β − t0.3 β(cid:12)
(cid:12) (cid:12) 0.852
Note that the gradient flo(cid:12)w scales t
c
a(cid:12)re derived quan-
tities, so we use the notation “ ” to indicate that they 0.850
β
|
have been computed in a theory with the given β.
0.848
To demonstrate the advantage gained by using flows,
wecomputeEq.(20)usingϵreweighting(Eq.(6))andthe 0.846
flowedapproach(Eq.(7))andcompare. Forthistest,we 0.00 0.05 0.10 0.15 0.20 0.25 0.30
use 96k configurations at β = 6.02 on volume L4 = 164.
a2/t
Forϵreweighting,weuseastepof∆β =0.001,leadingto 0.3
anESSof96%onthisensemble. Fortheflowedapproach,
we use Model A of Table I, which maps from β = 6.02 FIG.2. Continuumextrapolationoftheratiooftwogradient
to β = 6.03, that is ∆β = 0.01. This model achieves flow scales t 0.3/t 0.35, using the quantity in the numerator to
setthescale. Twomethodsareshown: ϵreweighting(dotted
an ESS of 67%, which is significantly higher than direct
grey line), and using a flowed ensemble (solid orange band).
reweighting, which has an ESS of 2% at the same target
Statistical uncertainties are displayed as bands.
parameters. Using these approaches, we find
Flow: k(a2)= 0.0167(41) , the matrix element can be obtained as
− (21)
ϵ reweighting: k(a2)= 0.0208(63) , 1 dM
− T = h , (25)
h
2M dλ
that is, the statistical uncertainly using ϵ reweighting h (cid:12)λ→0
(cid:12)
is 50% larger than that obtained with flows. In other where M
h
is the hadron mass. I(cid:12) (cid:12)n practice, this can be
words, one needs about 2.4 fewer samples using the estimated using a finite-difference approximation of the
×
flow method as compared with ϵ reweighting to achieve derivative, e.g.,
the same statistical uncertainty.
1 M (+λ) M ( λ)
Assuming that cutoff effects are already in the linear T = h − h − +O(λ2) . (26)
h
2M (0) 2λ
regimeatthisvalueofthelatticespacing,onecanusethis h
procedure to perform a simple continuum extrapolation As a numerical demonstration, we consider a Feynman-
of the ratio of flow scales. The continuum-extrapolated Hellman calculation of the gluon momentum fraction of
results show the same hierarchy of uncertainties as in the pion in the quenched approximation of lattice QCD,
Eq. (21): similar to Ref. [65]. In this case the operator may be
O
defined as
Flow: t /t =0.8539(13) ,
0.3 0.35 cont
| (22)
β
ϵ reweighting: t /t =0.8552(20) .
0.3 0.35 cont = Tr Re U U , (27)
| i0 ij
O −N  − 
c
i i<j
TheseresultsareshowninFigure2forthetwomethods. (cid:88) (cid:88)
 
where i,j (1,2,3), which is a discretization of the
∈
Energy-Momentum-Tensor (EMT). The matrix element
B. Hadron structure with Feynman-Hellman can then be related to the gluon momentum fraction of
techniques the hadron x by
g
⟨ ⟩
dM 3M
Another promising application of machine-learned h = h x latt , (28)
dλ − 2 ⟨ ⟩g
flows is in the calculation of matrix elements via the (cid:12)λ→0
(cid:12)
Feynman-Hellman (FH) approach—see Refs. [65–68] for where the superscrip(cid:12)t “latt” emphasizes that it is a bare
(cid:12)
recent applications. In this framework, a matrix element matrixelement. Whenaddingthisoperatortothegauge
action with a small parameter λ, the full action can be
T = h h , (23)
h seen as an anisotropic action with different couplings for
⟨ |O| ⟩
the temporal and spatial plaquettes:
where h is a stable hadron at rest and is the opera-
torofinterestprojectedtozeromomentuO m,iscomputed β
S = (1+λ)ReTr U
λ i0
by taking derivatives with respect to a parameter in the − N c
i
action. Specifically, adding the operator to the action as (cid:88) (29)
β
(1 λ)ReTr U .
ij
− N −
S S =S+λ , (24) c
λ i<j
→ O (cid:88)
t/
t
53.0
03.06
Model Prior type Parameters Target type Parameters Train ESS Eval. vol. ESS
A Pure Gauge SU(3) β =6.02 Pure Gauge SU(3) β =6.03 99.72% 164 67%
B1 Pure Gauge SU(3) β =6.00 Feynman-Hellman β =6.00,λ=+0.01 99.4% 16×83 84%
B2 Pure Gauge SU(3) β =6.00 Feynman-Hellman β =6.00,λ=−0.01 99.4% 16×83 84%
C N =2 QCD β =5.60,κ=0.153 N =2 QCD β =5.60,κ=0.1545 99.2% 84 48%
f f
TABLEI.Summaryofflowmodelsusedinthiswork. Allflowmodelshavebeentrainedonahypercubiclatticevolumeofsize
44, while the evaluation lattice volume at which the flows are used (Eval. vol.) is given explicitly in the table.
Itisthereforepossibletouseflowtransformationstomap tion of more than 20 in the number of configurations
×
from the standard pure gauge action at λ = 0 to non- necessary to achieve the same statistical error.
zero values of λ. This target is referred to as “Feynman- It is also possible to compute the second derivative of
Hellman” in Table I. M with respect to λ, which can be approximated as
π
We test the flowed approach by computing the differ-
d2M M (+λ)+M ( λ) 2M (0)
ence in Eq. (26) using an ensemble generated at λ = 0 π h h h
− − . (31)
andflowedtonon-zero λvalues. Wetraintwoflows,B1 dλ2 ≃ λ2
±
(cid:12)λ=0
andB2inTableI.Thetargetparametersarematchedto (cid:12)
While for(cid:12) the particular case of the gluon energy-
Ref. [65], albeit at a smaller volume. The value of β =6 (cid:12)
momentum tensor this derivative is not physically rel-
corresponds to a lattice spacing of a 0.09 fm, and the
≃ evant, second derivatives are related to matrix elements
hopping parameter κ in the quenched Dirac operator—
oftwo-currentinsertions—seeforinstanceComptonscat-
related to the bare quark mass as κ = 1/(2m +4)—is
0
tering applications [70, 71]. Using the same three meth-
taken to be κ=0.132. The lattice spatial and temporal
ods as for the first derivative, we find:
extent are L = 8 and T = 16, such that M L > 4. For
π
the purpose of this demonstration, we approximate the d2M
π
pion masses using the effective mass at the center of the Flow: = 6(15) ,
dλ2 −
lattice, (cid:12)λ=0
d2M π(cid:12)
(cid:12)
C π(T/2+1)+C π(T/2 1) ϵ reweighting: dλ2 (cid:12) = −140(110) . (32)
coshaM π = − , (30) (cid:12)λ=0
2C π(T/2) d2M π(cid:12)
(cid:12)
Indep. ens.: (cid:12) = 120(150) .
dλ2 −
where C π(t) is the pion correlator. (cid:12)λ=0
(cid:12)
For evaluation, 14k gauge-field configurations are gen- Allthedeterminationsyield(cid:12)numbersthatarezerowithin
(cid:12)
erated using 1 heatbath step with 5 overrelaxation
two standard deviations, but the relative magnitude of
steps between measurements for each independent en-
the uncertainties can nevertheless be used to assess the
semble. Correlation functions are measured with four
advantage of the flowed approach. In particular, for the
smeared sources per configuration with point sinks, us-
secondderivative,theerrorreductionwhenusingflowsis
ing Chroma [69]. The pion mass as a function of λ is
larger than for the case of the first derivative, a factor of
shown in Figure 3a, as determined using ϵ reweighting,
7 10 smaller than that obtained using ϵ reweighting or
independent ensembles, and flowed ensembles. Since the −
independent ensembles. This, in turn, leads to requiring
flow model quality at the volume of interest is very high,
one to two orders of magnitude fewer configurations to
uncertainties in the observables computed on flowed en-
achieve some target statistical precision.
semblesareverysimilartothosecomputedusingensem-
bles generated with heatbath.
The physical quantity of interest, ⟨x ⟩l gatt, depends on C. Mass dependence of QCD observables
the difference between the pion mass determined at dif-
ferent values of λ. When this difference is computed us-
As a third example, we compute derivatives with re-
ing independent ensembles, statistical uncertainties add
spect to the quark mass in QCD with N = 2 unim-
f
in the usual way, and the error in the correlated dif-
proved Wilson fermions. As a simple demonstration, we
ference is larger than that of each M (λ) estimate. In
π workdirectlywiththeactionincludingtheexactfermion
contrast, for flowed ensembles or ϵ reweighting, cancel-
determinant,
lations of correlated fluctuations significantly reduce the
variances. This can be seen in Figure 3b, which shows S(U)=S (U) logdetD [U]D†[U] , (33)
x latt computedfollowingthedifferentmethodsoutlined g − w w
⟨ ⟩g
inSectionII.Theuseofflowedensemblesreducestheun- where S (U) is the plaquette gauge action and D is
g w
certainty by a factor of 7 with respect to independent the discrete standard Wilson operator. The quark mass
≃
ensembles, and 5 with respect to ϵ reweighting. Thus, enters in the action via the hopping parameter κ. This
≃
incorporatingflowsintothiscalculationleadstoareduc- target is referred to as “N =2 QCD” in Table I.
f7
1.4
indepensembles
0.585
(cid:15)reweighting
1.2
flowedensembles
0.580
1.0
0.575 0.8
0.570 0.6
0.565 0.4
heatbathensembles
(cid:15)reweighting
0.560 flowedensembles 0.2
-0.01 0(cid:15) 0.01
λ method
(a) (b)
FIG. 3. (a) Pion mass in lattice units as a function of the coupling to the gluonic energy-momentum tensor λ. Marker shapes
denotehowtheensembleswereobtained: orangecirclesforheatbathensemblesatfixedvaluesofλ,bluesquaresforensembles
flowed from λ = 0, and red circles when using configurations generated at λ = 0 and reweighted to λ=ϵ=10−4. The pion
massisevaluatedinquenchedlatticeQCDatβ =6.0,κ=0.132,L=8andT =16. (b)Baregluonmomentumfractionofthe
pion from Eq. (28) using a finite-difference approximation computed using the three different methods: independent heatbath
ensembles, ϵ reweighting, and correlated flowed ensembles.
Depending on the observable, such derivatives can be
1.20 (cid:15)reweighting useful, e.g., to extract sigma terms or to constrain chi-
flowedensembles
ral extrapolations. Here we specifically consider average
1.15 Wilson loops, the squared topological charge at gradient
flow time t/a2 =2, and gradient flow scales t .
c
1.10
Wetrainaflowtomapconfigurationsfromκ=0.1530
1.05 to κ = 0.1545 at β = 5.6 (Model C in Table I). Such
parameters are close to those in Ref. [72]. 9k configura-
1.00 tions are generated using standard HMC with pseudo-
fermions. Note, however, the reweighting factor and
0.95 KL divergence for each configuration are computed with
Eq.(33);thisisstatisticallyconsistentandintroducesno
0.90
dW1 1 dW2 2 dW4 4 dQ2 dt0.10 approximations. Attheevaluationvolumeof84,theflow
dκ× dκ× dκ× dκ dκ achievesESS=48%,whichshouldbecomparedwiththe
ESS=28%obtainedusingdirectreweightingtothesame
observable
target parameters.
FIG. 4. Illustration of the error reduction in derivatives of The results are given in Figure 4, which compares the
observables with respect to the action parameter κ. W is (normalized) values of several observables computed us-
n×n
the average square Wilson loop of size n, Q2 is the squared ing the two methods, i.e., correlated flowed ensembles
topologicalchargedefinedviathegradientflow,andt labels and ϵ reweighting (with ∆κ = 1.5 10−4). At these
c
·
gradient flow scales, as in Eq. (17). The y-axis shows the statistics and for these choices of κ, independent ensem-
values of the observables and their statistical errors normal- bles result in statistical errors ≳ 2 larger than those
ized to the value obtained with flows. Results that incorpo- ×
attained with flows, and we do not display them. In all
rate flows are shown as blue squares, while the errors with ϵ
cases, thecentralvaluesareconsistentwithinastandard
reweighting are denoted by red triangles.
deviation and flows provide a variance reduction. The
error reduction varies between observables in the range
20% 40%. In particular, the largest reduction is
Forthistest,wecomputethederivativeofsomesimple ∼ −
seen for the 1 1 plaquette loop, while the smallest is
observables(genericallylabelledasX)withrespecttoκ, ×
seen for the topological charge. Thus, depending on the
approximated via finite differences:
observable of interest, one requires a factor of 1.5 2
− ×
dX X(κ ) X(κ ) fewer configurations to obtain a comparable statistical
2 1
− . (34)
dκ ≃ κ κ error when using flows.
2 1
−
Ma
eulav
dezilamron
π ttal
x
gi
h8
102
N =2QCD
f
PureGauge
Feyman-Hellmann
101
100
dW dκ1 ×1 dW dκ2 ×2 dW dκ4 ×4 d dQ κ2 dt d0 κ.10 tt 00 .. 33
5 cont
hx il gatt d d2M λ2π
(cid:12)
observable
(cid:12)
FIG. 5. Summary of the variance reduction in observables computed from derivatives with respect to the action parameters
when using flows compared with ϵ reweighting. The improvement factor is defined as the ratio of variances of the observables
computed with ϵ reweighting over flows. The label “N = 2 QCD” denotes derivatives of observables with respect to κ in
f
two-flavorQCD,thelabel“PureGauge”correspondstotheresultforthecontinuumlimitextrapolationofgradientflowscales
in the pure gauge theory, and the label “Feynman-Helmann” indicates observables computed using the Feynman-Hellmann
approach in quenched QCD.
IV. CONCLUSION the results for the computation of matrix elements in
the Feynman-Hellmann approach. In this application,
the cost of applying the flow is comparable to the cost
In this work, we present the application of machine-
of measuring correlation functions, while the cost of a
learnedflowstothecomputationofobservablesinvolving
heatbath update is less by an order of magnitude. This
derivatives. Specifically, we use flows to map ensembles
amounts to a factor of ≲ 3 increase in computational
between distributions defined by different parameters in
cost to achieve a variance reduction by a factor of more
the lattice action. By exploiting correlated cancellations
than20. Thisconstitutesarealcomputationaladvantage
ofuncertaintiesbetweentheseensembles,thisapplication
of approximately one order of magnitude, neglecting the
has the potential to provide a computational advantage
costs of training. Given expected further improvements
in the evaluation of finite-difference approximations of
throughthecontinueddevelopmentofflowarchitectures,
derivatives.
these results are promising.
To illustrate this idea, we showcase three numerical
This work focuses on target actions that only depend
demonstrationsinthecontextoflatticeQCD:continuum
on the gauge fields, e.g., pure gauge SU(3), quenched
limitextrapolations,matrixelementsusingtheFeynman-
QCD, and exact-determinant QCD. To generalize these
Hellman approach, and the mass dependence of observ-
results to state-of-the-art lattice QCD scales, where the
ables. In all cases, flows provide a reduction of vari-
fermion determinant cannot be explicitly evaluated, one
ance, which implies that fewer configurations are needed
must combine these flows with pseudofermion flows for
to achieve the same statistical error. The improvement
QCD, as explored in Refs. [18, 41, 42].
factor for all demonstrations of this work, defined as the
AsflowmodeltechnologyforlatticeQCDcontinuesto
variance reduction in observables computed using flows
advance, applications of correlated ensembles could be
withrespecttoϵreweighting, issummarizedinFigure5.
extended to compute other interesting quantities, such
These values are in the range of 1.5 for observables in
× assigmatermsofhadronsorobservablesinQED+QCD.
QCD to more than 20 for quantities in the Feynman-
× If the success seen in the proof-of-principle applications
Hellmann approach. With higher-quality flow models,
of this work can be achieved in such contexts, it holds
these factors can be improved.
the potential to drive substantial advances in the field.
This comparison does not account for the differing
costs of the different steps in each method, namely gen-
erating the initial ensemble with heatbath, applying the
flow(intheflowedcase),andmeasuringcorrelationfunc- ACKNOWLEDGEMENTS
tions. Of course, the potential advantages of this ap-
proach depend sensitively on not only the model used, We thank Michael Albergo, Kyle Cranmer, and Ross
but on the particular application, the cost of evaluat- Young for useful discussions. RA, DCH, FRL, PES, and
ing observables, how autocorrelations are treated, and JMU are supported in part by the U.S. Department of
the precision goal. For a ballpark comparison, consider Energy, Office of Science, Office of Nuclear Physics, un-
rotcaf
tnemevorpmi9
dergrantContractNumberDE-SC0011090. PESisaddi- itycanbeincreasedwithfurthertrainingorsimplemod-
tionallysupportedbytheU.S.DOEEarlyCareerAward ifications of the hyperparameters.
DE-SC0021006, by a NEC research award, and by the The layers considered in this work use a ratio of poly-
Carl G and Shirley Sontheimer Research Fund. FRL ac- nomials
knowledgessupportbytheMauricioandCarlotaBotton
Fellowship. GK was supported by the Swiss National 1 a 0+a 1x
f(x)= (A1)
Science Foundation (SNSF) under grant 200020 200424. 1+2x b 0+b 1x
This manuscript has been authored by the Fermi Re-
search Alliance, LLC under Contract No. DE-AC02- toconstructg x inEq.(13), wherea i andb i aretrainable
07CH11359 with the U.S. Department of Energy, Office parameters.
of Science, Office of High Energy Physics. This work All models have n pt = 6, where n pt is the number of
is supported by the U.S. National Science Foundation iterations of Eq. (14) in each layer. This choice has been
under Cooperative Agreement PHY-2019786 (The NSF foundtobeempiricallybetterthanlowervaluesofn pt. In
AI Institute for Artificial Intelligence and Fundamental models A, B1, and B2 we alternate the masking pattern
Interactions, http://iaifi.org/) and is associated betweenmod2ormod4,sinceempiricallythisresultsin
with an ALCF Aurora Early Science Program project, slight improvements compared to just using the mod 2
and used resources of the Argonne Leadership Comput- masking at the same computational cost (a mod 4 stack
ing Facility which is a DOE Office of Science User Fa- is computationally equivalent to two mod 2 stacks). The
cility supported under Contract DEAC02-06CH11357. model architectures are shown in Table II.
The authors acknowledge the MIT SuperCloud and Lin- The models are optimized by minimizing the reverse
coln Laboratory Supercomputing Center [73] for provid- KL divergence, where samples from the prior distribu-
ing HPC resources that have contributed to the research tion are generated using heatbath/overrelaxation (pure
results reported within this paper. Numerical experi- gauge) or HMC (QCD). The training scheme consists of
ments and data analysis used PyTorch [74], JAX [75], a constant learning rate for a fixed number of gradient
Haiku [76], Horovod [77], NumPy [78], and SciPy [79]. stepswithaconstantbatchsize,summarisedinTableII.
Figures were produced using matplotlib [80]. In all cases, we use path gradients.
A sufficient condition to guarantee invertibility of the
residual layers (Lipschitz condition) is
Appendix A: Details of models
g (V ) g (V ) < V V , (A2)
x 1 x 2 1 2
|| − || || − ||
In this appendix, we provide some additional details
of the models of this work and the scheme used to train where denotesthematrixnorm. Thisisnotexplicitly
||·||
them. It is important to stress that the hyperparame- enforcedinthetransformationsusedinthiswork,butwe
ters and training schemes of these models have not been have not detected any violations in trained models. See
fine-tuned to be optimal, but they suffice for the present Appendix B of Ref. [81] for a discussion on the Lipschitz
demonstration. Itisthereforelikelythatthemodelqual- condition.
[1] P. Boyle et al. in Snowmass 2021. 3, 2022. K. Jansen, P. Kessel, S. Nakajima, and P. Stornati
arXiv:2204.00039 [hep-lat]. arXiv:2007.07115 [hep-lat].
[2] USQCD Collaboration, A. S. Kronfeld et al. [10] D. J. Rezende and S. Mohamed arXiv:1505.05770
arXiv:2207.07641 [hep-lat]. [stat.ML].
[3] D. Boyda et al. in 2022 Snowmass Summer Study. 2, [11] L. Dinh, J. Sohl-Dickstein, and S. Bengio
2022. arXiv:2202.05838 [hep-lat]. arXiv:1605.08803 [cs.LG].
[4] K. Cranmer, G. Kanwar, S. Racani`ere, D. J. Rezende, [12] G. Papamakarios, E. Nalisnick, D. J. Rezende,
and P. E. Shanahan Nature Rev. Phys. 5 no. 9, (2023) S. Mohamed, and B. Lakshminarayanan Journal of
526–535, arXiv:2309.01156 [hep-lat]. Machine Learning Research 22 no. 57, (2021) 1–64.
[5] D. Bachtis, G. Aarts, and B. Lucini Phys. Rev. D 103 [13] S.-H. Li and L. Wang Phys. Rev. Lett. 121 (Dec, 2018)
no. 7, (2021) 074510, arXiv:2102.09449 260601. https://link.aps.org/doi/10.1103/
[hep-lat]. PhysRevLett.121.260601.
[6] S. Cal`ı, D. C. Hackett, Y. Lin, P. E. Shanahan, and [14] M. S. Albergo, G. Kanwar, and P. E. Shanahan Phys.
B. Xiao Phys. Rev. D 107 no. 3, (2023) 034508, Rev. D 100 no. 3, (2019) 034515, arXiv:1904.12072
arXiv:2208.02728 [hep-lat]. [hep-lat].
[7] C. Lehner and T. Wettig arXiv:2304.10438 [15] G. Kanwar, M. S. Albergo, D. Boyda, K. Cranmer,
[hep-lat]. D. C. Hackett, S. Racani`ere, D. J. Rezende, and P. E.
[8] L. Wang, G. Aarts, and K. Zhou arXiv:2309.17082 Shanahan Phys. Rev. Lett. 125 no. 12, (2020) 121601,
[hep-lat]. arXiv:2003.06413 [hep-lat].
[9] K. A. Nicoli, C. J. Anders, L. Funcke, T. Hartung, [16] D. Boyda, G. Kanwar, S. Racani`ere, D. J. Rezende,10
Model Number of layers Masking patterns Number of params. Gradient steps Learning rate Training batch size
A 96 (M2 + M4) × 4 16k 12000 10−4 2048
B1 72 (M2 + M4) × 3 12k 2100 10−3 512
B2 72 (M2 + M4) × 3 12k 2100 10−3 512
C 88 M2 × 11 15k 900 1.5·10−3 960
TABLEII.Additionaldetailsoftheflowmodelsofthiswork. “M2”and“M4”refertoamaskingpatternmodulo2ormodulo
4, respectively, as described in Section IIC.
M. S. Albergo, K. Cranmer, D. C. Hackett, and P. E. [35] M. Caselle, E. Cellini, A. Nada, and M. Panero JHEP
Shanahan Phys. Rev. D 103 no. 7, (2021) 074504, 07 (2022) 015, arXiv:2201.08862 [hep-lat].
arXiv:2008.05456 [hep-lat]. [36] D. Albandea, L. Del Debbio, P. Herna´ndez, R. Kenway,
[17] D. C. Hackett, C.-C. Hsieh, M. S. Albergo, D. Boyda, J. Marsh Rossney, and A. Ramos Eur. Phys. J. C 83
J.-W. Chen, K.-F. Chen, K. Cranmer, G. Kanwar, and no. 7, (2023) 676, arXiv:2302.08408 [hep-lat].
P. E. Shanahan arXiv:2107.00734 [hep-lat]. [37] D. Albandea, L. Del Debbio, P. Herna´ndez, R. Kenway,
[18] M. S. Albergo, G. Kanwar, S. Racani`ere, D. J. Rezende, J. M. Rossney, and A. Ramos in 40th International
J. M. Urban, D. Boyda, K. Cranmer, D. C. Hackett, Symposium on Lattice Field Theory. 10, 2023.
and P. E. Shanahan Phys. Rev. D 104 no. 11, (2021) arXiv:2310.03381 [hep-lat].
114507, arXiv:2106.05934 [hep-lat]. [38] S. Bacchio, P. Kessel, S. Schaefer, and L. Vaitl Phys.
[19] M. S. Albergo, D. Boyda, D. C. Hackett, G. Kanwar, Rev. D 107 no. 5, (2023) L051504,
K. Cranmer, S. Racani`ere, D. J. Rezende, and P. E. arXiv:2212.08469 [hep-lat].
Shanahan arXiv:2101.08176 [hep-lat]. [39] K. A. Nicoli, C. J. Anders, T. Hartung, K. Jansen,
[20] M. S. Albergo, D. Boyda, K. Cranmer, D. C. Hackett, P. Kessel, and S. Nakajima (2, 2023) ,
G. Kanwar, S. Racani`ere, D. J. Rezende, arXiv:2302.14082 [hep-lat].
F. Romero-L´opez, P. E. Shanahan, and J. M. Urban [40] A. Singha, D. Chakrabarti, and V. Arora
arXiv:2202.11712 [hep-lat]. arXiv:2306.00581 [hep-lat].
[21] K. A. Nicoli, S. Nakajima, N. Strodthoff, W. Samek, [41] R. Abbott, M. S. Albergo, D. Boyda, K. Cranmer,
K.-R. Mu¨ller, and P. Kessel Phys. Rev. E 101 no. 2, D. C. Hackett, G. Kanwar, S. Racani`ere, D. J. Rezende,
(2020) 023304, arXiv:1910.13496 F. Romero-L´opez, P. E. Shanahan, B. Tian, and J. M.
[cond-mat.stat-mech]. Urban Phys. Rev. D 106 no. 7, (2022) 074506,
[22] S. Foreman, X.-Y. Jin, and J. C. Osborn in 9th arXiv:2207.08945 [hep-lat].
International Conference on Learning Representations. [42] R. Abbott, M. S. Albergo, A. Botev, D. Boyda,
May, 2021. arXiv:2105.03418 [hep-lat]. K. Cranmer, D. C. Hackett, G. Kanwar, A. G. D. G.
[23] S. Foreman, T. Izubuchi, L. Jin, X.-Y. Jin, J. C. Matthews, S. Racani`ere, A. Razavi, D. J. Rezende,
Osborn, and A. Tomiya in 38th International F. Romero-L´opez, P. E. Shanahan, and J. M. Urban in
Symposium on Lattice Field Theory. Dec, 2021. 39th International Symposium on Lattice Field Theory.
arXiv:2112.01586 [cs.LG]. 8, 2022. arXiv:2208.03832 [hep-lat].
[24] S. Foreman, X.-Y. Jin, and J. C. Osborn in 38th [43] R. Abbott, M. S. Albergo, A. Botev, D. Boyda,
International Symposium on Lattice Field Theory. 12, K. Cranmer, D. C. Hackett, G. Kanwar, A. G. D. G.
2021. arXiv:2112.01582 [hep-lat]. Matthews, S. Racani`ere, A. Razavi, D. J. Rezende,
[25] L. Del Debbio, J. M. Rossney, and M. Wilson F. Romero-L´opez, P. E. Shanahan, and J. M. Urban
arXiv:2105.12481 [hep-lat]. arXiv:2305.02402 [hep-lat].
[26] M. Gabri´e, G. M. Rotskoff, and E. Vanden-Eijnden [44] R. Abbott, M. S. Albergo, A. Botev, D. Boyda,
arXiv:2105.12603 [physics.data-an]. K. Cranmer, D. C. Hackett, A. G. D. G. Matthews,
[27] P. de Haan, C. Rainone, M. C. N. Cheng, and S. Racani`ere, A. Razavi, D. J. Rezende,
R. Bondesan arXiv:2110.02673 [cs.LG]. F. Romero-L´opez, P. E. Shanahan, and J. M. Urban
[28] S. Lawrence and Y. Yamauchi Phys. Rev. D 103 no. 11, Eur. Phys. J. A 59 no. 11, (2023) 257,
(2021) 114509, arXiv:2101.05755 [hep-lat]. arXiv:2211.07541 [hep-lat].
[29] X.-Y. Jin in 38th International Symposium on Lattice [45] K. A. Nicoli, C. J. Anders, L. Funcke, T. Hartung,
Field Theory. 1, 2022. arXiv:2201.01862 K. Jansen, P. Kessel, S. Nakajima, and P. Stornati PoS
[hep-lat]. LATTICE2021 (2022) 338, arXiv:2111.11303
[30] J. M. Pawlowski and J. M. Urban Phys. Rev. D 108 [hep-lat].
no. 5, (2023) 054511, arXiv:2203.01243 [46] S. Bacchio arXiv:2305.07932 [hep-lat].
[hep-lat]. [47] G. Catumba, A. Ramos, and B. Zaldivar
[31] J. Finkenrath arXiv:2201.02216 [hep-lat]. arXiv:2307.15406 [hep-lat].
[32] M. Gerdes, P. de Haan, C. Rainone, R. Bondesan, and [48] RM123 Collaboration, G. M. de Divitiis, R. Frezzotti,
M. C. N. Cheng arXiv:2207.00283 [hep-lat]. V. Lubicz, G. Martinelli, R. Petronzio, G. C. Rossi,
[33] A. Singha, D. Chakrabarti, and V. Arora F. Sanfilippo, S. Simula, and N. Tantalo Phys. Rev. D
arXiv:2207.00980 [hep-lat]. 87 no. 11, (2013) 114505, arXiv:1303.4896
[34] A. G. D. G. Matthews, M. Arbel, D. J. Rezende, and [hep-lat].
A. Doucet arXiv:2201.13117 [stat.ML]. [49] N. Tantalo PoS LATTICE2022 (2023) 249,11
arXiv:2301.02097 [hep-lat]. A. Hannaford-Gunn, R. Horsley, H. Perlt, P. Rakow,
[50] S. Kullback and R. A. Leibler The Annals of G. Schierholz, H. Stu¨ben, R. Young, J. Zanotti, and
Mathematical Statistics 22 no. 1, (1951) 79 – 86. K. U. Can PoS LATTICE2021 (2022) 088,
[51] L. Vaitl, K. A. Nicoli, S. Nakajima, and P. Kessel, 2022. arXiv:2202.03662 [hep-lat].
[52] P. Bialas, P. Korcyl, and T. Stebel [69] SciDAC,LHPC,UKQCDCollaboration, R.G.Edwards
arXiv:2308.13294 [cs.LG]. and B. Joo Nucl. Phys. B Proc. Suppl. 140 (2005) 832,
[53] N. Metropolis, A. W. Rosenbluth, M. N. Rosenbluth, arXiv:hep-lat/0409003.
A. H. Teller, and E. Teller J. Chem. Phys. 21 (1953) [70] K. U. Can et al. Phys. Rev. D 102 (2020) 114505,
1087–1092. arXiv:2007.01523 [hep-lat].
[54] W. K. Hastings Biometrika 57 (1970) 97–109. [71] CSSM/QCDSF/UKQCD Collaboration,
[55] L. Tierney the Annals of Statistics (1994) 1701–1728. A. Hannaford-Gunn et al. PoS LATTICE2021 (2022)
[56] M. Favoni, A. Ipp, D. I. Mu¨ller, and D. Schuh 028, arXiv:2207.03040 [hep-lat].
arXiv:2012.12901 [hep-lat]. [72] R. Gupta, C. F. Baillie, R. G. Brickner, G. W. Kilcup,
[57] A. Tomiya and Y. Nagai arXiv:2103.11965 A. Patel, and S. R. Sharpe Phys. Rev. D 44 (1991)
[hep-lat]. 3272–3292.
[58] M. Creutz Phys. Rev. D 21 (1980) 2308–2315. [73] A. Reuther, J. Kepner, C. Byun, S. Samsi, W. Arcand,
[59] N. Cabibbo and E. Marinari Phys. Lett. B 119 (1982) D. Bestor, B. Bergeron, V. Gadepally, M. Houle,
387–390. M. Hubbell, et al. 2018 IEEE High Performance
[60] A. D. Kennedy and B. J. Pendleton Phys. Lett. B 156 extreme Computing Conference (HPEC) (Sep, 2018)
(1985) 393–399. 1–6, arXiv:1807.07814 [cs.DC].
[61] F. R. Brown and T. J. Woch Phys. Rev. Lett. 58 (1987) [74] A. Paszke et al. arXiv e-prints (Dec., 2019)
2394. arXiv:1912.01703, arXiv:1912.01703 [cs.LG].
[62] S. L. Adler Phys. Rev. D 37 (1988) 458. [75] J. Bradbury, R. Frostig, P. Hawkins, M. J. Johnson,
[63] S. Duane, A. Kennedy, B. J. Pendleton, and D. Roweth C. Leary, D. Maclaurin, G. Necula, A. Paszke,
Physics Letters B 195 no. 2, (1987) 216–222. J. VanderPlas, S. Wanderman-Milne, and Q. Zhang,
[64] M. Lu¨scher JHEP 08 (2010) 071, arXiv:1006.4518 2018. http://github.com/google/jax.
[hep-lat]. [Erratum: JHEP 03, 092 (2014)]. [76] T. Hennigan, T. Cai, T. Norman, and I. Babuschkin,
[65] QCDSF, UKQCD Collaboration, R. Horsley, R. Millo, 2020. http://github.com/deepmind/dm-haiku.
Y. Nakamura, H. Perlt, D. Pleiter, P. E. L. Rakow, [77] A. Sergeev and M. Del Balso arXiv:1802.05799
G. Schierholz, A. Schiller, F. Winter, and J. M. Zanotti [cs.LG].
Phys. Lett. B 714 (2012) 312–316, arXiv:1205.6410 [78] C. R. Harris, K. J. Millman, S. J. Van Der Walt,
[hep-lat]. R. Gommers, P. Virtanen, D. Cournapeau, E. Wieser,
[66] QCDSF-UKQCD-CSSM Collaboration, M. Batelaan, J. Taylor, S. Berg, N. J. Smith, et al. Nature 585
K. U. Can, R. Horsley, Y. Nakamura, P. E. L. Rakow, no. 7825, (2020) 357–362.
G. Schierholz, H. Stu¨ben, R. D. Young, and J. M. [79] P. Virtanen, R. Gommers, T. E. Oliphant,
Zanotti Phys. Rev. D 108 no. 3, (2023) 034507, M. Haberland, T. Reddy, D. Cournapeau, E. Burovski,
arXiv:2305.05491 [hep-lat]. P. Peterson, W. Weckesser, J. Bright, et al. Nature
[67] QCDSF/UKQCD/CSSM, CSSM, UKQCD, QCDSF methods 17 no. 3, (2020) 261–272.
Collaboration, M. Batelaan et al. Phys. Rev. D 107 [80] J. D. Hunter Computing in Science & Engineering 9
no. 5, (2023) 054503, arXiv:2209.04141 no. 3, (2007) 90–95.
[hep-lat]. [81] M. Lu¨scher Commun. Math. Phys. 293 (2010) 899–919,
[68] CSSM/QCDSF/UKQCD Collaboration, arXiv:0907.5491 [hep-lat].