Using LLMs to discover emerging coded antisemitic
hate-speech emergence in extremist social media
Dhanush Kikkisetti, Raza Ul Mustafa, Wendy Melillo, Roberto Corizzo, Zois Boukouvalas, Jeff Gill, Nathalie Japkowicz
American University, 4400 Massachusetts Ave NW, Washington, DC 20016, USA
{vk4372a,rmustafa,melillo,rcorizzo,boukouva,jgill,japkowic}@american.edu
Abstract—Onlinehatespeechproliferationhascreatedadiffi-
cult problem for social media platforms. A particular challenge
relatestotheuseofcodedlanguagebygroupsinterestedinboth
creatingasenseofbelongingforitsusersandevadingdetection.
Coded language evolves quickly and its use varies over time.
Thispaperproposesamethodologyfordetectingemergingcoded
hate-ladenterminology.Themethodologyistestedinthecontext
of online antisemitic discourse. The approach considers posts
scraped from social media platforms, often used by extremist
users. The posts are scraped using seed expressions related
to previously known discourse of hatred towards Jews. The
methodbeginsbyidentifyingtheexpressionsmostrepresentative
of each post and calculating their frequency in the whole
corpus. It filters out grammatically incoherent expressions as
well as previously encountered ones so as to focus on emergent
well-formed terminology. This is followed by an assessment of Fig.1. Nonantisemiticuseoftheterm”globalist”
semantic similarity to known antisemitic terminology using a
fine-tuned large language model, and subsequent filtering out
of the expressions that are too distant from known expressions
globalist refers to someone “who gets it!” and should feel
of hatred. Emergent antisemitic expressions containing terms
good about it! The term does not, in any way, refer to Jews. clearlyrelatingtoJewishtopicsarethenremovedtoreturnonly
coded expressions of hatred. Yet, the AJC Translate Hate Glossary argues that the term
Index Terms—hate speech, coded antisemitic terminology has an antisemitic connotation when it “is used to promote
the antisemitic conspiracy that Jewish people do not have
I. INTRODUCTION
allegiance to their countries of origin, like the United States,
Online hate speech detection1 is a complex problem for but to some worldwide order—like a global economy or
social media platforms. A particular challenge, not much international political system—that will enhance their control
discussedintheliterature,relatestotheuseofcodedlanguage. overtheworld’sbanks,governments,andmedia”.Intheabove
The following post illustrates the issue in the context of post, it is clear that the antisemitic connotation is implied.
antisemitic hate speech: From this post, we surmise that
“Nope Globalist want us intertwined and run by the
1) The globalists (a.k.a., the Jews) are distinct from “us”,
elites,Globalistdon’tlaytariffsontheirfriendsyou
presumably, the good American citizens;
stupid fu****”. [posted on Dec. 31, 2022, on the
2) They control “our” fate to be run by the elites (a subset
Disqus platform ] of these Jews)4;
AccordingtotheAmericanJewishCommittee(AJC)Translate 3) They help each other by not imposing the same tariffs
Hate Glossary2, a globalist, in its unbiased definition, is on each other as those they impose on “us”.
“a person who advocates the interpretation or planning of
The above post, thus has a double meaning. To a recipient
economic and foreign policy in relation to events and devel-
who is unaware of its antisemitic connotation, some category
opments throughout the world”. According to this definition,
of people, the globalists, do not seem to behave very nicely.
the term is rather flattering. Indeed, that is the way it is
Yet, to an informed audience, it is a very pointed post that
intended in the Hyatt hotel’s welcoming message to its club
reiterates old Nazi and Soviet anitisemitic propaganda5 and
members seen in Figure 13. In that commercial context a
propagates it further. Furthermore, on social media platforms,
ResearchsupportedbyAmericanUniversity’sSignatureResearchInitiative
program.WethankJacobLevineforhisinspirationintheinitialstepsofthis 4“Elite”appearsintheAJCGlossaryinthecontextof“CosmpolitanElite”:
project. ““Cosmopolitan”and“elite”aretermsthathaveseparatelyincitedantisemites
1Warning:Someofthepaper’scontentmaybedisturbingtothereader. across the political spectrum. Based on stereotypes of Jewish wealth and
2https://www.ajc.org/translatehate/globalist insularity,Jewshavebeenaccusedofbeingpartofaneliteclassforcenturies.”
3Photobyoneoftheauthorson11/3/23ataHyattTexasproperty. 5c.f.“Globalist”and“CosmopolitanElite”intheAJCGlossary.
4202
naJ
91
]LC.sc[
1v14801.1042:viXrait does so without setting off any serious alerts since, except II. BACKGROUNDANDRELATEDWORK
for the “stupid fu****” mention, which could raise a flag, no
Withtheadventoftheinternetandsocialmedia,technology
offensive terms are used.
hasincreasedthespeedatwhichlanguageevolves.Propaganda
Though the usefulness and importance of catching such intheformofhatespeechnowtravelstheworldatsuchafast
subtle posts and their impact on society beyond the small pacethatitisbeyondhumancapacitytokeepupwith.Harmful
extremistgroupstheyareprimarilyintendedforareimportant words take on new meanings in both direct and coded ways,
subjectsthatwedebateelsewhere,thispaperisconcernedwith incitinghatredinthemindsofthoseonlytoowillingtobelieve
theautomaticdiscoveryof“coded”termssimilartoglobalists them as they reinforce and justify preexisting prejudices.
and cosmopolitan elite which carry both a “regular” and an
antisemiticconnotationdependingonthecontextinwhichthey A. Machine Learning Methods for Hate Speech Detection
are used. Such an automated process is necessary due to the In recent times, there has been a notable rise in hate
fact that coded terminology evolves rapidly online and fixed crimes across the United States.6 While establishing a clear
glossaries such as the AJC glossary become quickly outdated. relationship between hate crimes and online content is not
In addition, due to the large volume of posts appearing on straightforward, a report by the US Department of Justice
social media, human monitoring cannot be performed without pointstothesimultaneouspurchasesofFacebookadscontain-
the assistance of automated tools pointing them in the right ing dividing content and hate crime. These two reports7 thus
direction.Thepurposeofourapproachisjustthat:tocreatean suggest that hate speech should not be considered harmless,
automated monitoring tool to assist human monitors by sug- and coming up with methods to curb it is an important goal.
gesting emerging, potentially coded, antisemitic terminology,
Previousworkaimstodetecthatespeechfromsocialmedia
along with the posts that use that terminology.
usingvariousMachineLearning(ML)methodsasdocumented
Thoughthetopicofhatespeechis,unfortunately,quitevast, by a number of surveys written in the last six years [1]–[4].
this study focuses on antisemitism. The choice of a particular One of the most recent surveys shows that while up to 2016,
category of hate speech comes from our belief that we can fewer than 10 papers were published on the topic each year,
performamorethoroughanalysisoftheproblembyremaining since then, there has been a huge increase in interest in the
focused. Antisemitism was selected because of the reported topic with over 150 papers published in 2020, the last year
increase in antisemitic incidents in the months preceding the for which their survey had complete information [4]. Hate
beginning of this study, in 2022. The lessons learned from speech detection has been attempted using a wide variety of
this particular study will apply to other categories of hatred techniques and applied to many different problems. Founta et
including hatred against Black, Muslim, Asian, and LGPTQ+ al.[5],forexample,usedRecurrentNeuralNetworks(RNN)to
populations amongst others. classifyracismandsexism.Serra` etal.[6]showedthatcharac-
The main contribution of this paper is a methodology ter level based Long Short-Term Memory networks (LSTMs)
for the novel problem of extracting emerging coded hate- for abusive language detection could be useful. Similarly,
ladenterminology(antisemitism,inthispaper)fromextremist ConvolutionalNeuralNetworks(CNNs)havealsobeenshown
social posts, along with a practical pipeline to demonstrate to be successful in hate speech detection and classification
its effectiveness. The methodology is based on the hypothesis [7]. More recently, large language models have been used for
thatcodedantisemiticterminologybegetscodedantisemitic these tasks like in the work of [8] who propose different fine-
terminology. In other words, those who use coded termi- tuned and non-fined-tuned variations of pre-trained models
nology to remain under the radar of social media monitors suchasBERT,RoBERTa,ALBERT,etc.onoffensivelanguage
will, when not able to express new ideas with existing coded detection.Mostofthesestudies,however,considerhatespeech
terms,deriveorinventnewones.Basedonthishypothesis,we as a whole and, typically, do not distinguish the community
harvest terminology used in similar contexts as known coded towards which it is directed. We feel that this generalized
antisemitic terminology and propose it as potential emerging approach is too broad and decided, instead, to use a divide-
antisemitic coded terminology to human monitors, along with and-conquer approach by focusing on particular communities
the context in which that terminology occurs. We propose separately.OurfirstattemptfocusedontheJewishcommunity
fourdifferentversionsofourpipelineandvalidatethemusing and the problem of antisemitic speech in social media.
a quantitative approach. The most advanced version is also
B. Antisemitism in Social Media and its Detection
evaluated qualitatively. We conclude with a discussion of our
approach’s practical utility. Antisemitism specifically targets Jewish individuals or the
Jewish community [9]. In [10], authors use the outcomes of
Theremainderofthepaperisstructuredasfollows:Section
two surveys from EU and ADL to assess how the level of
II presents background and related work. In Section III, we
antisemitism relates to the perception of antisemitism by the
discuss data preparation matters. Next, the methodology and
Jewish community in eight different EU countries. A recent
pipeline for extracting coded terminology is introduced in
detail in Section IV. This is followed by a presentation and
6https://bjs.ojp.gov/library/publications/hate-crime-recorded-law-enforcement-2010-2019
discussion of the results in Section V. Finally, Section VI
7(1) https://bit.ly/2xeeF5h; (2) https://www.ojp.gov/pdffiles1/nij/grants/
concludes the paper and discusses future work. 304532.pdfsurvey finds that 20% of American Jewish adults have expe-
rienced an act of antisemitism, such as an attack either online
or on social media.8 In another study, the authors address the Extremist Social Media Platforms Important Terms
Extraction
challenges of quantifying and measuring online antisemitism. Extract raw data
It raises the question of whether the number of antisemitic
messagesisincreasingproportionallytoothercontentorifthe
Generate Fine-Tuned
share of antisemitic content is rising. Additionally, the paper LLM Embeddigs for the
context in which the
aimstodeterminetheextentofonlineJew-hatredbeyondwell-
Data scrapping Weighted term is used
knownwebsites,forums,andclosedsocialmediagroups[11].9 Context
Similarity
Afewstudieshaveattemptedtocombatonlineantisemitism Score
in a way similar to the way in which generalized hate speech Known Antisemitic Extract Trending
Terms Antisemitic Terminology
has been countered in the works discussed in the previous
section. In [12], for example, the authors prepared a data
set that includes both social posts and associated images,
Fig.2. EmergentCodedAntisemiticTerminologyExtractionPipeline
when available. They labeled the entries as antisemitic or
not, and if antisemitic, indicated the kind of antisemitism:
political, economic, religious or racial. They used a bimodal approachforthedetectionofemergingantisemitic,sometimes
deep learning approach for classifying the data into these coded, terminology used on extremist social media platforms.
categories. [13] considers a subset of the text-only part of
this datasetin an attempt to classify antisemitic posts using a III. DATAPREPARATION
lesscomputationally-intensiveapproach.Focusingontheclass This study is part of a large multi-disciplinary project
imbalanceprobleminthedatawhiletakingadvantageofOpe- sponsored by our institution which, simultaneously, collects
nAI’s GPT technology, they compared GPT-based resampling and analyzes the use of coded language to express antisemitic
techniques against other traditional kinds. Very recently, [14] sentiment in lightly moderated social media platforms typi-
proposed a new data set for antisemitism detection in social cally preferred by individuals with extremist tendencies and
media posts that uses a strict annotating process. The data studies the migration of this language from these extremist
set is so recent, however, that it has not yet been used for platforms to the general population. The overall project in-
classification or the results obtained on such efforts have not cludes a data team, a population team, and a software team
yet been published. There are other projects that consider the which collaborate closely and work in parallel. The pipeline
detection of online antisemitism using AI approaches as well. illustrating our proposed methodology is shown in Figure 2.
In particular, the project entitled “Decoding Antisemitism”10
A. Dataset
calls itself an “AI-driven Study on Hate Speech and Imagery
Online”, and already produced five published reports on the The project is constantly evolving, though for this study,
subject. The project specifically aims at linking national or we considered the first delivery of the data curated by the
international events reported in the traditional media to anti- datateaminJune2023.Thedatateam’sobjectivesconcerning
semitic online social media discussions. this study was to analyze the usage of antisemitic terms.
We describe the data gathering and cleanup methodologies
C. Alternatives to automated hate speech detection
summarized by the 3 leftmost components in Figure 2.
In[15],theauthorsquestionwhetherthewayinwhichhate 1) Data Scraping and Labeling: To build the corpus, the
speech detection has been handled by the machine learning datateamanalyzedantisemiticsocialmediapostsfromvarious
community is the way forward, or whether hate speech detec- extremistsocialmediaplatformsincludingDiscuss,Telegram,
tion is a lot more complex than previously assumed by the Minds, and GETTR. It used antisemitic expressions obtained
researchers who labeled data sets and applied classifiers to from the previously mentioned American Jewish Commit-
them. Furthermore, the authors note that some hateful content tee (AJC) Translate Hate Glossary as well as the Southern
may occur without the use of well-known slurs and that on Poverty Law Center (SPLC) to collect social media posts.
top of it all, the nature of hate speech is constantly evolving. This collection effort was facilitated by Pyrra11, a private
Incontrasttopreviousstudies,ourworktakestheseobserva- software company that allows its users to scrape posts from
tions into consideration and focuses on identifying emerging, alt-social media platforms according to a list of seed terms.
potentially coded terms related to antisemitism using NLP The data team considered the 46 seed expressions available
methods.Therehasbeenalackofrigorousresearchinfinding fromtheAJCGlossaryatthetimeaswellastheterm“Cultural
emergingantisemiticcodedtermsthatcanleadtothedetection Marxism”,discussedinaSPLCarticle12 andchose16ofthem
ofhatespeechand,perhaps,subsequently,tothepreventionof to make the process tractable. It analyzed the 659 retrieved
hatecrimes.Thispaperaimstobridgethisgapandprovidean posts related to these seed expressions to determine whether
8https://bit.ly/41FV6ei 11https://www.pyrratech.com/
9Thesestudiespreceded10/7/23whenthesituationworseneddrastically. 12https://www.splcenter.org/fighting-hate/intelligence-report/2003/
10https://decoding-antisemitism.eu/ cultural-marxism-catchingthe post was antisemitic or not.13 The 16 terms used in the • Antisemitic: the candidate expressions have to be se-
subset were selected based on their potential to reveal posts mantically related to antisemitic discourse.
that had emerging new antisemitic terms in them. The list • Coded: antisemitic expressions that contain terms relat-
of seed words used is: Cabal, Cosmopolitan Elite, Cultural ing to obvious Jewish concepts are removed.
Marxism,Deicide,TheGoyimKnow,Holocough,JewishCap- • Emerging: alreadyknowncodedantisemiticexpressions
italist, Jewish Communist, Jew Down, Jewish Lobby, New are removed in order to concentrate on new terminology.
World Order, Not the Real Jews, Rothschild, Soros, Zionist, These operations are divided into two phases. In Phase 1, we
and Zionist Occupied Government. Since the distribution of addresstheextractionofemergingcodedterminologywithout
postswithrespecttoeachseedexpressionisnotideal,though worrying about its semantic relation to antisemitism. In Phase
the software team used all the posts retrieved from the 16 2,weaddresssemanticsusinglargelanguagemodels.Phase1
seed expressions, it used only the seed expressions with at isrepresentedbythe“ImportantTermsExtraction”component
least5postsrelatedtothemtoconductitsanalysis.Theterms in Figure 2. Phase 2 is represented by the combination of the
droppedfromthelistaccordingtothiscriterionareJewDown LLMGeneration,SimilarityScoring,AntisemiticTerminology
andCosmopolitanelite,leavinguswith14seedwordsforthe Extraction, and Monitoring components in Figure 2. Both
remainder of the study. phasesofthepipelineareimplementedusingtwoapproaches:
2) Preprocessing: Text preprocessing is a critical step in a standard solution and an advanced solution. We subse-
Natural Language Processing (NLP). It involves transforming quentlytestallfourcombinations,yieldingabaselineapproach
raw text data into a format that can be easily analyzed by composed of two standard solutions, two hybrid approaches
machine learning algorithms. The preprocessing steps usually composed of one standard and one advanced solution, and
used involve several techniques, such as tokenization, stop one advanced approach composed of two advanced solutions.
word removal, stemming, and lemmatization [16]. During the
A. Phase 1: Emerging Coded Trending Terms Extraction
first phase of cleaning the corpus, we removed the urls
and lower-cased all the posts to normalize them. This initial ForthefirstpartofPhase1,theextractionoftrendingterms,
procedure was followed by stop words removal. Then we weexploretheuseofoff-the-shelfNLPtoolsforourstandard
lemmatized the text to get a single root form for each word solutionandthenproposeouradvancedsolutionthatcombines
priortopassingitontothecodedantisemitictermsextraction tf-idfandfrequency.Oncethetrendingtermsareextracted,we
process, which will be discussed in the next section. Bigrams propose a strategy to remove non-emerging and non-coded
and trigrams were formed by running two- and three- word terms from the list of extracted terms. This strategy is applied
windows through all the posts.14 It was important to filter to both the standard and advanced solutions.
out badly-formed expressions obtained through that approach. 1) Standard Solution: Trending Terms Extraction using
In particular, we decided to include bigrams and trigrams Concordance and Collocation tools: In this first attempt at
that only contain nouns, proper nouns, adjectives, and verbs, trendingtermsextraction,weusetraditionalNLPtechniquesto
since others were judged less relevant to our quest.Since the extractbi-gramsandtri-gramsusingconcordanceandcolloca-
emphasis of this study is on the novel proposed extraction tionalgorithmsfromtheNLTKToolkit[18].Concordanceisa
processdiscussednext,wedidnotexperimentwiththevarious technique that provides a comprehensive view of how a given
pre-processing techniques suggested in the literature on hate term appears in a corpus. Using this approach, we use the
speechforsocialmediaposts[17].Itwasleftforfuturework. 14 seed terms from Section III-A1 for analyzing patterns and
gaininginsightsintolanguageusage.Foreachoccurrenceofa
IV. CODEDANTISEMITICTERMSEXTRACTIONAPPROACH seed term, this approach provides the surrounding words con-
text.Weusedefaultsettingsfortheextractionofcontext.Next,
As previously mentioned, the purpose of this study is the
using collocation, we find the most frequent bi-grams and tri-
extraction of emerging coded antisemitic terms. In order to
gramsinthecollectedcontexts.Collocationisatechniquethat
carryoutthisgoal,wedesignedamethodforoperationalizing
finds a meaningful combination of words from a corpus that
each term of that expression. That operationalization and the
are semantically coherent. Different statistical measures can
linking of its resulting components into a functional system
be used to detect collocations including frequency, pointwise
constitute the main contribution of this work. The purpose
mutual information (PMI), and log-likelihood ratio (LLR)
of this section is to discuss the process. To begin with, we
amongothers.Weusefrequency,heresincethatisthemeasure
consider each word in the emerging coded antisemitic terms
also used in the advanced approach In the future, we plan to
expression and give it the specific meaning shown below.
experimentwithotherstatisticalmeasuresforbothapproaches.
• Terms:theextractedexpressionsarelimitedtogrammat- The standard approach yielded 126 trending terms.
ically consistent bigrams and trigrams; they have to be
2) Advanced Solution: Trending Terms Extraction using
relevant enough to the documents in which they appear
TF-IDF and Frequency: Our proposed advanced approach
and appear frequently enough in the corpus.
is presented in Algorithm 1 which uses TF-IDF feature-
weighting [19] and frequency to extract trending terms. In a
13Acopyofthecodingstatementisavailableuponrequest.
nutshell,thiswasdonebyselectingallthetermsthatobtained
14Wealsoconsideredunigramsbutwerenotabletofilterthemeffectively
usingourcurrentmethodology.Theirtreatmentwasleftforfuturework. a TF-IDF value greater than a self-set threshold, listing theseterms in decreasing order of frequency, and selecting the top On lines 7-11, we take each term in matrix W and find the
200 terms from the list.15 When the same term appeared in highest score across all the rows (documents) of the matrix
several documents, the highest TF-IDF value it received was and store it in D . To remove the less relevant terms, we
s
retained Algorithms 1 shows the approach that was followed computetheaverageofallthevaluesinD andusethisvalue,
s
in detail. The algorithm is explained line by line next. δ, as a threshold. This allows us to consider only the terms
with TF-IDF values greater than the average value of all the
Algorithm 1 Trending terms extraction scores in D . δ is calculated on line 12. On lines 13-19, we
s
1: Initialize Trending terms ▷ Stores top 200 trending terms check if the terms’ TF-IDF value is greater than δ. If so, we
2: Initialize D s ▷ Stores terms’ highest TF-IDF scores (s) savetheterms’valuesandtheirfrequenciesinD f.Finally,on
3: Initialize D f ▷ Stores terms’ values and frequencies line 20, we sort the terms in D f in descending order of their
4: Set T ▷ Stores all the vocabulary terms (value). frequency values and select the top 200 terms, storing them
5: Set F ▷ Stores the frequency of each term in the corpus. in Trending_terms.
6: Calculate the TF-IDF scores for each term in each doc- 3) Removal Strategy: Redundant, Non-Emergent and Non-
ument and store them in matrix W ∈ Rd×v, where Coded terms Removal: Once the list of most trending terms
d denotes the number of documents and v denotes the
have been extracted using either the standard or advanced
vocabulary size.
solution, three categories of terms are removed from it. First,
7: for each term t in T do as we consider expressions that are both bigrams and tri-
8: for each row in W do ▷ Each row is a document grams, there is a possibility of encountering bigrams within
9: D s[t]←max(D s[t],W[row,t]) ▷ Finds t’s trigrams. Such redundant bigrams are removed from the list
highest TF-IDF score, s, across all documents
of expressions. Next, we remove the terms that have occurred
10: end for earlier. For now, this corresponds to the original list of 16
11: end for seed words used to retrieve the posts. In the future, this list
12: δ ←Average(D s) ▷ δ is the average of all s’s will grow as we intend to use the system continuously, using
13: i = 1 newly discovered terms of interest as new seed terms. Lastly,
14: for each t in D s do the terms that are considered non-coded are removed. These
15: if D s[t]≥δ then correspond to terms that contain words that obviously pertain
16: D f[i]←(T[t],F[t]) ▷ If t’s to Jewish themes. The list of words currently used includes
highest TF-IDF score is larger than threshold δ, store t’s
jew, jewish, kike, and zionist. Expressions that include these
value and frequency in D
f words either as stand-alone words or embedded within other
17: i = i + 1 words are removed. After the removal phase is applied, we
18: end if are left with 52 and 94 trending terms for the standard and
19: end for advanced trending term extraction solutions, respectively.
20: Sort D f in descending order of frequency
21: for i=1,2,...,200 do
B. Phase 2: Embeddings and Comparisons
22: Trending terms←D f[i][T] ▷ Store the most
frequent terms in Trending terms (drop the frequencies) Though the bigrams and trigrams extracted in the previous
23: end for sectionareknowntobetrending,theirsemanticsareunknown
and, in particular, there is no information as to whether or
The algorithm begins by initializing the not these terms are antisemitic. To find out which of these
Trending_terms list which is the list that will return the trending expressions are antisemitic, we compare the context
200 bigrams and trigrams (terms) that received the highest in which they are used to the context in which the known
combination of TF-IDF and Frequency scores. Next, D s antisemitic expressions are used. If a trending term appears
and D f are also initialized. D s will be used to store all the in contexts similar to those in which seed expressions occur,
terms’ highest TF-IDF scores, whereas D f will store all it will be deemed antisemitic. Otherwise, it will be discarded
the terms and their associated frequencies. Since terms are as non-antisemitic. To compute embeddings for the trending
subsequently referred to according to their indices, T, which and seed terms, we begin by fine-tuning BERT. Since BERT
is set next, serves as the reference vector that associates was not specifically trained on instances of hate speech or
an index with the actual value of the term (i.e., the actual antisemitism, we fined-tuned it with additional data collected
bigram or trigram). Next, the frequency of each term in using the same seed expressions as before (since time elapsed
the corpus is calculated and saved in vector F. The TF-IDF between the original collection and the new collection, more
values obtained for each unique term and each document are posts were available for this exercise). This fine-tuned version
then calculated and placed in the matrix W of size d x v of BERT is then used to generate contextual embeddings for
where d represents the number of documents whereas, v is both the trending terms discovered in the last section and the
the number of terms. seed terms used to extract posts. We present the details of
BERT’s fine-tuning followed by the standard and advanced
15We assume that at least 200 terms had a TF-IDF value larger than the
self-setthreshold. embedding solutions we implemented.Similarityasdescribedonlines6-8.Online9,the14resulting
Context words in window of size 5 measurements are averaged and assigned to S[tt] The process
isrepeatedforeachtrendingterm(lines5-10)andthemedian
W-5 W-4 W-3 W-2 W-1 W+1 W+2 W+3 W+4 W+5
of all the S[tt]’s, γ, is calculated on line 11. γ is then used
Word Word Word Word Word Term Word Word Word Word Word
as our threshold for potential antisemitism on lines 12-18: if
Surronding context W Surronding context
S[tt] for trending term tt is greater than γ, tt will be given
the partial label “potentially antisemitic” (TT PL w[tt] =
1). Otherwise, it will be given the partial label “probably
Fig.3. Pre-truncateembeddingapproachforawindowofsize5. not antisemitic” (TT PL w[tt] = 0). (We used the median
as it offered more flexibility than the mean.) Algorithm 2 is
repeated 10 times, once for each window size w considered.
1) Fine-tuning the BERT model: The generalized BERT
This yields 10 partial labels TT PL w[tt], w = 1...10 for
model does not possess domain-specific vocabulary, thus it
each term tt, and the final labeling for tt is “antisemitic” if
is not capable of handling coded hate speech such as anti-
m out of the 10 partial labels are “potentially antisemitic”. It
semitism. Indeed, when such out-of-vocabulary terms occur,
is “not antisemitic”, otherwise. The optimal value of m was
they get broken down into smaller tokens for which embed-
7 for the pre-truncate case.
dings are generated. These are treated as rare tokens, yielding
unsatisfactory results. To avoid this issue, we fine-tune the
Algorithm 2 Comparing semantic similarity–window size w
BERT model using an additional 56K posts extracted using
1: Embeddings tt←{et 1,et 2...,et n} ▷ n pre- or
the same seed words as before on Pyrra. We, thus, extend
post- truncate trending terms embeddings at window size
BERT’s vocabulary from 30k to 55k tokens, and fine-tune
w
it using the Masked Language Modeling (MLM) approach.
2: Embeddings st←{es 1,es 2...,es 14} ▷ 14 pre- or
MLMisapre-trainingapproachthatmasksafewtokens.The
post- truncate seed words embeddings at window size w
model is subsequently trained to predict the masked tokens
3: Initialize TT PL w. TT PL w will store the n trending
from the words that surround them.16
terms & predicted antisemitic label for window size w.
2) Comparing Trending Terms to Seed Terms: To differ-
4: Initialize S. S will store the average semantic score for
entiate between antisemitic and non-antisemitic terms during
each trending term at window size w.
Phase 2, we compare the trending terms’ embeddings to the
5: for each tt in Embeddings tt do
seed terms’ embeddings using Cosine Similarity. We generate
6: for each st in Embeddings st do
twotypesofembeddingsfollowingi)thestandardpre-truncate
7: tt scores[tt]←Sim(et tt,es st) ▷ Cosine Sim
embedding method and ii) the advanced post-truncate embed-
8: end for
ding method. In pre-truncate embedding, we truncate the post
9: S[tt]←Average(tt scores[tt]) ▷ Average all the 14
containing the term to be embedded prior to embedding it. In
semantic scores between tt and all the st’s
post-truncateembedding,weembedtheentirepostcontaining
10: end for
the term of interest, and truncate the resulting embedding
11: γ ←Median(S) ▷ γ is the median of all the scores
afterwards.17
12: for each tt in S do
a) Standard Solution: Pre-truncate embeddings: In this
13: if S[tt]>γ then ▷ check if score greater than γ
approach, we consider context windows of 5 to 14 words,
14: TT PL w[tt]←1 ▷ if score greater than γ
where the size of the windows refers to the twin windows
15: else
locatedbeforeandafterthetermbeingembedded,respectively.
16: TT PL w[tt]←0 ▷ if score less than γ
We show an example of windows of size 5 in Figure 3.
17: end if
Since the same term may be found in more than one post,
18: end for
we concatenate all the embeddings extracted from fine-tuned
BERT using the same window size and take their average.
b) Advanced Solution: Post-truncate embeddings: In
Embedding, here, refers to the pooled layer obtained
this approach, we begin by embedding each complete post
from the 12 layers of the BERT architecture. We follow the
using fine-tuned BERT. The approach is illustrated in Figure
same procedure for all the trending terms we extracted and
4 for the 18-word post AND THE EVIL LYING DEEP
the 14 seed words retained in Section III-A1.
STATE CABAL SATANIC SCUM BAGS ALL NEED TO
Next, we determine the trending terms antisemitic nature
BE ROUNDED UP AND EXECUTED. This yields an 18
using Algorithm 2. After some initialisations on lines 1-4,
x 12 x 768 tensor representing the total number of words
S[tt], the “similarity to antisemitism” value for trending term
in the post, the total number of encoding layers, and their
tt, is computed as follows: tt’s embedding is compared to
dimension. This embedding can be thought of as a word
eachofthe14seedterms(thest’s)’sembeddingsusingCosine
embeddings lookup table that provides complete context for
each post.18 Once this embedding is constructed, we follow
16https://huggingface.co/learn/nlp-course/chapter7/3
17Sincewecannotembedpostsexceeding512tokens,weturnedlargeposts
intomultipleones. 18WeassumethateachwordintheposthasatokenidinBert’svocabulary.terms unknown or not yet catalogued by that community.19
Post
AND THE EVIL LYING DEEP STATE CABAL SATANIC SCUM BAGS ALL NEED TO BE Known Terms For the first category, we simply compiled
ROUNDED UP AND EXECUTED.
a general glossary from three existing sources: the Institute
Encoder EmbeddingsTensors: 18X12X768 Encoder
for Curriculum Services’ Glossary spanning the history of
Word embedding lookup table
European Antisemitism, which we took in its entirety; the
W-5 (Deep State - W) W+5
American Jewish Committee “Translate Hate” glossary which
Context words in a window of size 5
W-5 W-4 W-3 W-2 W-1 W+1 W+2 W+3 W+4 W+5 we also used in its entirety (prior to its recent expansion from
Word Word Word Word Word Deep Word Word Word Word Word 46 to 70 terms) and portions of the Glossary of Terms and
State
Surronding context W Surronding context AcronymsconstructedbytheR2PrisprojectonRadicalization
andviolentextremism.Sincethislastsourceencompassedha-
tredofdifferenttypes,forthisspecificstudy,werestrictedour-
Fig.4. Post-truncateembeddingapproachforawindowofsize5.
selves to the terms whose composition or definition included
a known antisemitic term (e.g., nazi, Aryan, anti-semitic, Ku
KluxKlan,SS,Swastika,Fascism,WhiteSupremacist,etc.).20
thesameproceduredescribedinSectionIV-B2aexceptforthe New Terms The new terms are the terms that do not appear in
fact that we now extract word-level contextual embeddings
the glossaries just mentioned and that need to be manually
from the lookup table (see Figure 4). The advantage of
verified through an internet search. We used the following
this approach over the previous one is that it builds more
systematic procedure to assign ground labels to new terms:
informed embeddings given its use of a complete rather than
• Eachextractedtermnotfoundintheglossarycompilation
partial context. Please note that there are three additional
was searched for on Google in two ways: the term alone
differences between the standard and the advanced approach:
or together with “+ antisemitism” added to the search.
in the standard approach, we used context window sizes
• The documents retrieved on the first page of the Google
between 5 and 14 while in the advanced approach, we used
browser for both searches were examined for references
context window sizes between 1 and 10. That is because a
to antisemitism.
window of 1 word does not convey much information in the
• If, based on this analysis, the term was found to be
standard approach whereas it does in the advanced approach.
associatedwithantisemitism(e.g.,“deepstate”wasfound
As a result, we started at size 5 in the standard approach and
to be associated with a conspiracy theory against the
1 in the advanced approach and used 10 different window
Jews), it was coded as antisemitic in our gold standard
sizes in each case. Furthermore, in the advanced approach,
database.If,ontheotherhand,thetermdidnotcarryany
the embeddings are generated by averaging the final encoder
clear meaning (e.g., “late 20th”) or was not associated
layer of BERT rather than using the pooled layer since that
with antisemitism (e.g., “new york city”), it was coded
yielded better results. Finally, the optimal value for m in the
as not antisemitic in our gold standard database.
advanced approach was 9 rather than 7.
Qualitative evaluation We conducted two types of qualitative
evaluation. The first one simply consisted of observing the
terms extracted by the approach to assess whether they made
V. RESULTSANDDISCUSSION sense when taken out of context. The second one can be
thought of as a sanity check. For terms extracted and labeled
as either antisemitic or not, we went back to the the posts
The purpose of our study was to design a methodology
from which the term was extracted to assess whether, within
for extracting emerging coded antisemitic terminology from
the context of the post, it was used in an antisemitic way or
online posts appearing on social media platforms often used
not. Though we do not use these qualitative assessments in
byextremistgroups.Weproposedapipelinetoimplementthis
ourquantitativeevaluation,weshowexamplesofthedifferent
methodology and instantiated this pipeline with standard and
situations that arose in terms of agreement or disagreement
advanced components. The difficult part of our evaluation is
between our system and our gold standard.
the assessment of whether the approach yields a significant
numberoftermsandwhetherthesetermscan,indeedinsome B. Results
contexts, have an antisemitic connotation. In order to answer Quantitative Results: We tested four different versions of
these questions, we created a gold standard and tested our our proposed pipeline, by combining the standard and ad-
results according to it.
19In this paper, we created a prototype system based on the seed words
providedtousbythedatateam.Theseseedwordsareonlyasmallsubsetof
thealreadyknowncodedantisemiticterms.Asaresult,someoftheemergent
termsdiscoveredbyoursystemareemergentvis-a-visthesystem’sknowledge
A. Construction of a gold standard:
but not vis-a-vis the broader current knowledge. Discovering terms known
to the community but not known by the system constitutes a useful proof
The gold standard we created uses two complementary of concept. The discovery of terms not currently known by the community
constitutesanaddeddemonstrationoftheworthoftheapproach.
methodologies. One for the terms already familiar to the
20Thesourcesweusedcanbefoundatthefollowingwebsites:https://bit.
community that fights antisemitism, and the other, for the ly/45kEtYB;https://bit.ly/3MIjKpt;andhttp://www.r2pris.org/glossary.htmlTABLEI
ACCURACY,PRECISION,RECALLANDF-SCOREUSINGTHEFOURVERSIONSOFOURPIPELINE.
Model+Embedding ApproachType Accuracy Precision Recall F-score
colloc-pretrunc standard 0.74 0.34 1 0.51
colloc-posttrunc hybrid 0.76 0.36 1 0.53
tfidf-pretrunc hybrid 0.67 0.47 0.55 0.51
tfidf-posttrunc advanced 0.80 0.63 0.83 0.72
vanced solutions proposed for trending term extraction with etc. Table III also shows an instance of a new term —
the standard and advanced solutions proposed for term em- FEMA camps.Thiscorrespondstoaconspiracytheorywhere
bedding. These combinations resulted in one standard, two FEMA is believed to plan the incarceration and possible
hybrid, and one advanced implementation. Table I lists the execution of US citizens in favor of the establishment of a
results obtained by concordance + collocation followed by New World Order, one of our seed words which often refers
pre-truncation embedding (colloc-pretrunc) or post-truncation to the establishment of a new form of government controlled
embedding (colloc-posttrunc); and those obtained by tfidf by a Jewish elite.On the other hand, during the process of
+ frequency followed by pre-truncation embedding (tfidf- extracting coded antisemitic terms, some terms were labeled
pretrunc) or post-truncation embedding (tfidf-posttrunc). The as antisemitic despite the fact that they do not appear in our
results were obtained using our gold standard labels. The gold standard. In certain cases, that represents an outright
approach using the two advanced components stands out as mistake like in the case of Big Part in Table III where
the absolute winner: tfidf-posttrunc, although the results for the context is certainly racist, but not specifically antisemitic,
allfourmethods,includingtfidf-posttrunc,showahigherlevel thoughantisemitismispartofthepost,butinothersituations,
of recall than precision. Future work will attempt to improve a case could be made for the antisemitic label. For example,
all these metrics scores, with a focus on precision so as ourapproachpredictsEnd gameasacodedantisemiticterm,
not to unduly label terms as antisemitic when they are, in eventhoughwedidnotfindanyreasonforitinourglossaryor
fact, benign. When comparing the numbers in Table I, it is internet search. A look at the post in which the term appeared
important to note that the number and type of terms retrieved (Table III) helps us understand how the antisemitic context of
differ between the two term extraction processes, colloc and the post that includes the terms “concentration camps” and
tfidf. While colloc extracted 52 terms of which only 7 were ”new world order” led the system to mislabel it. We conclude
truly antisemitic, tfidf extracted 94 of which 29 were truly that, in such cases, our approach is extracting the right term
antisemitic. The recall of 1 obtained by the two colloc-based according to the context, but the term should be considered
methods, thus means that both pretrunc and posttrunc were Neutral (in an antisemitic context) rather than antisemitic.
able to identify these 7 antisemitic terms. Their low level of
C. Discussion
precision, however, suggests that they are too liberal in their
labeling of terms as antisemitic. Though we assume that our approach could still be refined,
wenotethattheresultsobtainedbythemostsuccessfulversion
Qualitative Results: Our qualitative evaluation was applied
of our system are encouraging, suggesting the viability of our
to the version of our pipeline that obtained the best results:
hypothesis that emergent coded terms could be discovered
tfidf-posttrunc,i.e.,theadvancedversion.TableIIshowssome
automatically using distance measures in embedding spaces.
of the terms extracted by that version. The terms in red
The sanity checks suggest that the terms identified by our
correspond to terms incorrectly classified as antisemitic with
approach are, usually, warranted as the context shown in the
no good explanation; those in black are correctly classified as
posts attests to the antisemitic nature of the way in which
antisemitic as they correspond to our Known Terms; those in
the identified terms are used. These checks also point to
blue were verified to be antisemitic as they correspond to our
the errors made by the system and will help us improve
New Terms; and those in purple were incorrectly classified as
our results. We also believe that our approach could have
antisemitic,althoughthecontextinwhichtheyariseisclearly
important practical uses. After being vetted by a human team,
antisemitic. As discussed below, we call these terms Neutral
the emergent coded terminology it discovers could be input
(in an antisemitic context).
to the moderating algorithms used by social media platforms
Sanity Check:InTableIII,weshowafewsamplepostscon- to discover problematic discourse or users currently avoiding
tainingthefollowingtrendingantisemitictermsdiscoveredby discovery.
tfifd-posttrunc: Interest groups, White Genocide,
Deep state. Each of these terms had an entry in the VI. CONCLUSION
antisemitic glossary compilation described earlier. For in- This paper proposes an approach for detecting the emer-
stance, White Genocide, refers to a conspiracy theory gence of new antisemitic coded terminology which offers
rooted in white supremacist ideology, claiming that there is a valuable resource in combating online antisemitism and
anintentionaleffortbyJewstodestroythewhiteracethrough contributes to the ongoing efforts to create safer and more
immigration, mixed-racial marriage, LGBTQ+ identification, inclusive online spaces. We achieve an accuracy of 80% andTABLEII
LISTOFTRENDINGTERMSTHATAREPREDICTEDANTISEMITICBYTHEMOSTADVANCEDVERSIONOFTHEPIPELINE.
FalsePositives KnownTerms NewTerms Neutral
plainsight germanpeople whitegenocide interestgroups FEMAcamps colorrevolution endgame worldwar
newyorkcity bigpart nostraaetate federalreserve centralbank criticalracetheory westerncivilization democratparty
TABLEIII
POSTSONSOCIALMEDIAWITHAUTOMATICALLYLABELEDANTISEMITICCODEDTERMSASPERTHEMOSTADVANCEDVERSIONOFTHEPIPELINE.
CodedTerm Status Website Post
Interestgroups KnownTerm Minds the united states government is controlled by interest groups that are only seeking to enlarge their
own power. the us government does not represent the will of the citizenry, and condemning it is not a
condemnation on the principles of freedom, democracy, etc.the usa is being set up to fail.the rootless
cosmopolitanelitehavebeenconstructingelaboratesafehousesfordecadesinpreparationforthis.
DeepState KnownTerm 4chan US deepstateMIGApededetected.TherealdeepstateistheJewishlobby.
WhiteGenocide KnownTerm TruthSocial Rotten Eggs - Dr. Reiner Fuellmich and Whitney Webb! Vatican Pro-Abortion- False Prophet Francis
Owned By New World Order! Jacob’s Trouble = White Genocide! Pandemic Of The Double
Dosed.InflationSpiking,MoreLockdowns,TheWorstIsYetToCome!
EndGame/FEMAcamps Neutral/NewTerm TruthSocial FEMAisnotagoodthing!FEMA campsareconcentrationcamps.FEMA campsaretheend game
oftheNewWorldOrder
BigPart FalsePositive 4chan allturdsneedtobedeportedfromtheWest.turdsarebrownMENAsunnimuslimgarbage.theyarea
big part of the non-white invasion. many of the turkish Iraqi and syrian immigrants who rape women
andgirlsareactuallyethnicturds.turdsarealsozionistsandturdistanisabaseforisraeliops.imagine
sympathizingwiththesezio-musliminvaders.
F-Score of 72% in extracting antisemitic terms using this [7] B.Gamba¨ckandU.K.Sikdar,“Usingconvolutionalneuralnetworks
approach which relies on NLP techniques including POS to classify hate-speech,” in Proceedings of the first workshop on
abusivelanguageonline,pp.85–90,2017.
tagging,TF-IDF,andFined-tunedlargelanguagemodelssuch
[8] G. Wiedemann, S. M. Yimam, and C. Biemann, “Uhh-lt & lt2 at
as BERT. In the future, we intend to refine our semantic semeval-2020 task 12: Fine-tuning of pre-trained transformer net-
similarity technique by exploring other deep learning and worksforoffensivelanguagedetection,”ArXiv,vol.abs/2004.11493,
2020.
large language model approaches and their various parameter
[9] M. Schwarz-Friesel and J. Reinharz, Inside the antisemitic mind:
combinations. Similarly, we will experiment with different the language of Jew-Hatred in contemporary Germany. Brandeis
types of text pre-processing approaches to deal specifically UniversityPress,2017.
[10] S. Zannettou, J. Finkelstein, B. Bradlyn, and J. Blackburn, “A
with hate-speech and social media text. This will be done in
quantitative approach to understanding online antisemitism,” in
the context of a lifelong-learning setting where the trending ProceedingsoftheInternationalAAAIconferenceonWebandSocial
terms discovered will be used as input to the data scraping Media,vol.14,pp.786–797,2020.
[11] G.Jikeli,D.Cavar,andD.Miehling,“Annotatingantisemiticonline
component in the following iteration. We also intend to create
content. towards an applicable definition of antisemitism,” arXiv
amoreuser-friendlyversionthatwillbeconvenientforpeople preprintarXiv:1910.01214,2019.
working in this space. Finally, our goal is to extend this study [12] M.Chandra,D.R.Pailla,H.Bhatia,A.J.Sanchawala,M.Gupta,
M.Shrivastava,andP.Kumaraguru,““subvertingthejewtocracy”:
to hateful terminology against other minority groups.
Online antisemitism detection using multimodal deep learning,”
Proceedingsofthe13thACMWebScienceConference2021,2021.
[13] N. A. Cloutier and N. Japkowicz, “Fine-tuned generative llm
oversamplingcanimproveperformanceovertraditionaltechniques
REFERENCES on multiclass imbalanced text classification,” IEEE COnfernece on
BigData,2023.
[14] G. Jikeli, S. Karali, D. Miehling, and K. Soemer, “Antisemitic
[1] A. Schmidt and M. Wiegand, “A survey on hate speech detection
messages?aguidetohigh-qualityannotationandalabeleddataset
usingnaturallanguageprocessing,”inSocialNLP@EACL,2017.
oftweets,”ArXiv,vol.abs/2304.14599,2023.
[2] P.FortunaandS.Nunes,“Asurveyonautomaticdetectionofhate
[15] S. Parker and D. Ruths, “Is hate speech detection the solution the
speech in text,” ACM Computing Surveys (CSUR), vol. 51, pp. 1 –
worldwants?,”ProceedingsoftheNationalAcademyofSciencesof
30,2018.
theUnitedStatesofAmerica,vol.120,2023.
[3] F. Poletto, V. Basile, M. Sanguinetti, C. Bosco, and V. Patti,
[16] R.U.Mustafa,M.S.Nawaz,J.Farzund,M.Lali,B.Shahzad,and
“Resources and benchmark corpora for hate speech detection: a
P.Viger,“Earlydetectionofcontroversialurduspeechesfromsocial
systematic review,” Language Resources and Evaluation, vol. 55,
media,”DataSci.PatternRecognit.,vol.1,no.2,pp.26–42,2017.
pp.477–523,2020.
[17] A. Glazkova, “A comparison of text preprocessing techniques for
[4] M. S. Jahan and M. Oussalah, “A systematic review of hate
hate and offensive speech detection in twitter,” Social Network
speech automatic detection using natural language processing,”
AnalysisandMining,vol.13,pp.1–28,2023.
Neurocomputing,vol.546,p.126232,2021.
[18] E. Loper and S. Bird, “Nltk: The natural language toolkit,” arXiv
[5] A.M.Founta,D.Chatzakou,N.Kourtellis,J.Blackburn,A.Vakali,
preprintcs/0205028,2002.
and I. Leontiadis, “A unified deep learning architecture for abuse
[19] J. Ramos et al., “Using tf-idf to determine word relevance in doc-
detection,” in Proceedings of the 10th ACM conference on web
ument queries,” in Proceedings of the first instructional conference
science,pp.105–114,2019.
onmachinelearning,vol.242:1,pp.29–48,Citeseer,2003.
[6] J.Serra,I.Leontiadis,D.Spathis,G.Stringhini,J.Blackburn,and
A.Vakali,“Class-basedpredictionerrorstodetecthatespeechwith
out-of-vocabulary words,” in Proceedings of the first workshop on
abusivelanguageonline,pp.36–40,2017.