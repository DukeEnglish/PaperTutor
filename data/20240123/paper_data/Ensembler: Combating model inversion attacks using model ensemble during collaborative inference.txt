ENSEMBLER: COMBATING MODEL INVERSION AT-
TACKS USING MODEL ENSEMBLE DURING COLLABO-
RATIVE INFERENCE
DanchengLiu&JinjunXiong∗
DepartmentofComputerScience
StateUniversityofNewYorkatBuffalo
Buffalo,NewYork,14260
{dliu37, Jinjun}@buffalo.edu
ABSTRACT
Deeplearningmodelshaveexhibitedremarkableperformanceacrossvariousdo-
mains.Nevertheless,theburgeoningmodelsizescompeledgedevicestooffloada
significantportionoftheinferenceprocesstothecloud. Whilethispracticeoffers
numerousadvantages,italsoraisescriticalconcernsregardinguserdataprivacy.
Inscenarioswherethecloudserver’strustworthinessisinquestion,theneedfora
practicalandadaptablemethodtosafeguarddataprivacybecomesimperative. In
thispaper,weintroduceEnsembler,anextensibleframeworkdesignedtosubstan-
tiallyincreasethedifficultyofconductingmodelinversionattacksforadversarial
parties. Ensembler leverages model ensembling on the adversarial server, run-
ninginparallelwithexistingapproachesthatintroduceperturbationstosensitive
dataduringcolloborativeinference.Ourexperimentsdemonstratethatwhencom-
bined with even basic Gaussian noise, Ensembler can effectively shield images
from reconstruction attacks, achieving recognition levels that fall below human
performanceinsomestrictsettings,significantlyoutperformingbaselinemethods
lackingtheEnsemblerframework.
1 INTRODUCTION
In numerous critical domains, deep learning (DL) models have demonstrated exceptional perfor-
mance when compared to traditional methods, including image classification Deng et al. (2009);
Dosovitskiy et al. (2021), natural language processing Brown et al. (2020), protein predictions
Jumper et al. (2021), and more. One noteworthy trend accompanying these impressive advances
is the escalating size of DL models employed for these tasks (Hu et al., 2021), with the famous
GPT-3modelcontaining175billionparameters(Brownetal.,2020). Asaresult,whentasksneces-
sitatetheinvolvementofedgedevicessuchasmobilephones,reducingthecomputationalworkload
on these devices becomes imperative. A prevalent approach involves offloading a substantial por-
tionoftheworkloadtoacloudservercapableofexecutingextensivecomputations. Thisframework
canbeconceptualizedascollaborativecomputing,whereaclientcollaborateswithaserveroffering
computation-as-a-service(CaaS).
Recently,someattentionintheresearchcommunityhasbeenshiftedtoanemphasisontheprivacy
ofclient’ssensitivedatainsuchaframework.Whiletheclientinherentlytrustsitself,theservermay
poseasanadversarialentityseekingtocompromisetheuser’sprivacyduringtheinferenceprocess.
ThisriskbecomesparticularlypronouncedwhenDLmodelsaretaskedwithhandlingsensitivedata,
suchasdiseaseclassificationorfacialauthentication,whichrequireaccesstomedicalorfacialuser
information.Inotherscenarios,aclientcouldbeasmallcompanythatholdsprivatemodelsanduses
theserversolelyforthepurposeofprovidingservice. Italsodoesnotwanttheservertoaccessthe
dataofitscustomers,whichsometimescontainssensitiveinformation. Withtheprevalenceofedge
computing,thereisanincreasingneedforresearcherstodevelopamachinelearningframeworkthat
∗Usefootnoteforprovidingfurtherinformationaboutauthor(webpage, alternativeaddress)—not forac-
knowledgingfundingagencies.Fundingacknowledgementsgoattheendofthepaper.
1
4202
naJ
91
]RC.sc[
1v95801.1042:viXrasupports secure, accurate, and efficient machine learning service, and works in this area are often
categorizedunderthetermprivacy-preservingmachinelearning(PPML).
There have been multiple works addressing this formidable challenge of safeguarding the client’s
sensitive information in collaborative inference scenarios, an important part of the entire PPML
framework. Foranextensivediscussionondifferentalgorithmicandarchitecturalchoicesandtheir
impactsonprivacyprotection,wereferreaderstoSection5andTable2ofthecomprehensivesurvey
by (Xu et al., 2021). In this paper, we will simply group existing approaches into two categories:
encryption-based algorithms that guarantee privacy at the cost of thousands of times of time effi-
ciency(Mishraetal.,2020;Knottetal.,2021;Tanetal.,2021;Reagenetal.,2021;Ratheeetal.,
2020;Lametal.,2023;Watsonetal.,2022),andperturbation-basedalgorithmsthatoperateonthe
intermediate layers of a DL architecture, introducing noise to thwart the adversary’s ability to re-
coverclientinput(Mireshghallahetal.,2020;Osiaetal.,2018;Luetal.,2022;Sirichotedumrong
& Kiya, 2021). Since perturbation-based algorithms directly operate on the intermediate outputs
from the client, they incur minimal additional complexity during the inference process. However,
asopposedtoguaranteedprivacyprovidedbyencryption-basedalgorithms, perturbation-basedal-
gorithmssufferfromthepossibilityofprivacyleakage,meaningsensitiveprivateinformationmay
stillberecoverablebytheadversarialserverdespitetheintroducedperturbations.
Heetal.(2019)presentedoneofthefirstsystematicstudiesonmodelinversionattacks(MIA)on
collaborative inference (CI). Their research shows that a shadow network can effectively emulate
theclient’ssecretnetwork,enablingtherecoveryofrawimages,especiallywhentheclientretains
onlyonesingleconvolutionallayer. Whiletheclientisabletokeepmoreprivacyasitkeepsmore
layers,suchamethodislesspracticalintherealworldduetothelimitationsofthecomputational
powerofedgedevices. Mireshghallahetal.(2020)proposedShredder,whichusesanoiseinjection
layerbeforetheclientsendingoutcomputedresultstoreducemutualinformationbetweenclientand
serverwhilemaintaininggoodclassificationaccuracy. Nevertheless,Luetal.(2022)demonstrated
thatShredderfallsshortinsafeguardingfacialimagesfromrecovery. Inourownexperimentation
withthenoiseinjectionlayerproposedbyShredder,appliedtoaResNet-18architectureonCIFAR-
10,weobservedsignificantaccuracydropswithcombinedmultiplicativeandadditivenoise. Onthe
otherhand, simpleadditivenoiseresultinginapproximatelya5percentdropinaccuracyfailedto
protectimagesfromrecovery,asdepictedinFigure. 1. Luproposedtouseapolicy-basedprocessor
betweenclientandservertoprotectprivateinformation, butfiguresintheirworkseemtoindicate
thattheeffectivenessoftheirpolicyshouldbeattributedtoremovingsomeregionsfromtheoriginal
imagethatcontainsensitivedata. Whilesuchanapproachiseffectiveinsomecases,itfallsshortin
scenarioswheresensitiveinformationisembeddedwithintheimage,suchasinfacialauthentication
tasks.
Inthispaper,weaimtobringforththesecontributionstotheresearchcommunity.Firstly,weexpand
uponthesystematicanalysisofvariousmodelsplitstrategiesbetweentheclientandserver,focusing
onmorecomplexarchitecturescommonlyusedinpractice. Second, wetakeadifferentpathfrom
thoseapproachesthatproposedifferentmodificationstothedataandintroduceEnsembler,asecure
collaborative inference framework designed to substantially increase the effort required to recover
clientinput. Ensembler isnotonlyastand-aloneframeworkthatsignificantlyincreasestheadver-
sary server’s reconstruction difficulty but can also be seamlessly integrated with existing complex
algorithmstoconstructpracticalandsecureinferencearchitecturestailoredtospecificneeds.
Theremainderofthispaperisorganizedasfollows: Section2introducesthebackgroundofcollab-
orativeinferenceandrelatedworks,aswellasformallydefiningthethreatmodel. Section3offers
a systematic analysis of the impact of different model split strategies on server-side reconstruc-
tiondifficulty. Section4introducesEnsembleranddetailsitsdesignforbettersecurecollaborative
inference. Section 5 presents the empirical experiments related to Ensembler and showcases its
effectivenessinprotectingtheclient’sprivatedata,andSection6concludesthepaper.
2 BACKGROUND
2.1 COLLABORATIVEMACHINELEARNING
The development of mobile graphic processing units (GPUs) has ushered in a new era where ma-
chinelearningtasksareincreasinglydeployedwithaportionofthecomputationbeinghandledby
2edge devices. Related areas include federated learning, where multiple edge devices jointly train
a deep learning model (McMahan et al., 2017; Yu et al., 2023; Yaldiz et al., 2023); split learning,
where a DL model is split into two or more parts, and the client and server jointly train it (Poirot
etal.,2019); andcollaborativeinference,whereaDLmodelissplit,withonlyaportiondeployed
ontheservertoprovideservices(Heetal.,2019;Osiaetal.,2018). Inthispaper,wewillfocuson
theinferencepartandassumethatthetrainingphaseofDLmodelsissecure. Thoughthetraining
phase is sometimes also susceptible to adversarial attacks aimed at stealing sensitive information
(Inan et al., 2021; Li et al., 2022; Zhang et al., 2021), private inference is still more prevalent in
mostpracticalscenarios.
2.2 THREATMODEL
Inthispaper, weconsiderthecollaborativein-
ference task between the client and the server,
who acts as a semi-honest adversarial attacker
thataimstostealtherawinputfromtheclient.
Formally, we define the system as a collabo-
rative inference on a pre-trained DNN model,
M(x,θ), where the client holds the first and
thelastafewlayers(i.e. the“head”and“tail”
ofaneuralnetwork),denotedasM (x,θ )
c,h c,h
and M (x,θ ). The rest of the layers of
c,t c,t
DNN are deployed on the server, denoted as Figure1: SampleimagefromCIFAR-10. Leftis
M s(x,θ s). θ is the trained weights of M, theoriginalimageandrightisrecoveredimage.
where θ = {θ ,θ ,θ }. The complete col-
c,h s c,t
laborativepipelineisthustomakeaprediction
ofincomingimagexwithM [M [M (x)]].
c,t s c,h
Duringtheprocess,theserverhasaccesstoθ andtheintermediateoutputM (x). Inaddition,we
s c,h
assumethatithasagoodestimateoftheDNNusedforinference.Thatis,ithasauxiliaryinformation
on the architecture of the entire DNN, as well as a dataset in the same distribution as the private
trainingdatasetusedtotraintheDNN.However,itdoesnotnecessarilyknowthehyper-parameters,
aswellasengineeringtricksusedtotrainthemodel. Sincetheserverisacomputation-as-a-service
(CaaS)provider,itisassumedtohavereasonablylargecomputationresources. Whileitispowerful
incomputing,theserverisrestrictedfromqueryingtheclienttoreceiveadirectrelationshipbetween
rawinputxandintermediateoutputM (x).
c,h
InordertoreconstructrawinputxfromtheintermediateoutputM (x),theserveradoptsacom-
c,h
mon model inversion attack (He et al., 2019; Lu et al., 2022; Dosovitskiy & Brox, 2016). It con-
structsashadownetworkM˜(x,θ˜ ,θ ,θ˜ ) : {M˜ ,M ,M˜ }suchthatM˜ simulatesthe
c,h s c,t c,h server c,t
behaviorofM.AftertrainingM˜,theadversarialserverisabletoobtainarepresentationM˜ such
c,h
thatM˜ (x)∼M (x). Asthenextstep,withthehelpadecoderofM˜ toreconstructtheraw
c,h c,h c,h
imagefromintermediaterepresentation,itisabletoreconstructtherawinputfromM (x).
c,h
2.3 ASSUMPTIONSOFOTHERRELATEDWORKS
In this section, we provide an overview of various attack models and the assumptions adopted
in other works related to collaborative inference (CI) under privacy-preserving machine learning
(PPML).Sincedifferentworkspotentiallyusedifferentcollaborationstrategiesbetweentheclient
andtheserver,wewillusethegenericnotation,whereM isheldbytheclient,andM isheldby
c s
theserver. Generally,theattacksfromtheserverwillfallintothreecategories:
• TrainingDatasetReconstructionAttacksthattrytopredictifcertainattributes,including
butnotlimitedtoindividualsamples,distributions,orcertainproperties,areamemberof
the private training set used to train M(x,θ). If successful, the privacy of the training
datasetwillbecompromised. WereferreaderstothesurveybyHuetal.(2022)andSalem
etal.(2023)formoredetails.
• Model Inversion Attacks that try to recover a particular input during inference when its
rawformisnotsharedbytheclient. Forexample,inanimageclassificationtask,theclient
3maywanttosplitMsuchthatitonlyshareslatentfeaturescomputedlocallytotheserver.
However, uponsuccessfulmodelinversionattacks, theserverwillbeabletogeneratethe
rawimageforclassificationtasksbasedonthelatentfeatures.Itisimportanttonotethat,in
thispaper,weadoptthesamedefinitionofmodelinversionattacksasof(Heetal.,2019).
Thistermalsoreferstoattacksthatreconstructtheprivatetrainingdatasetinotherworks.
Wewillfocusonreconstructingprivaterawinputfortherestofthepaper.
• Model Extraction Attacks that try to steal the parameters and even hyper-parameters of
M. Thistypeofattackscompromisetheintellectualpropertyoftheprivatemodelandare
often employed as sub-routines for model inversion attacks when the server lacks direct
accesstoM’sparameters.
Differentworksalsomakedifferentassumptionsonthecapabilityoftheserver. First,itiswidely-
acceptedthattheserverhassufficientlyyetreasonablylargecomputingpowerandresources,asits
roleisoftenprovidingMLservice. RegardingtheauxiliaryinformationonM, theygenerallyfall
intothreelevels:
• WhiteBoxassumesthattheserverhasfullaccessofarchitecturedetailsofMsuchasthe
structureandparameters(Liuetal.,2021).Differentdefinitionsalsoadddifferentauxiliary
informationavailabletotheserver,suchastrainingdatasetLiuetal.(2021),corruptedraw
inputZhangetal.(2020),oradifferentdatasetWang&Kurz(2022). Thissettingisoften
associatedwithattacksthattrytoreconstructprivatetrainingdataset(Wang&Kurz,2022;
Zhangetal.,2020;Haimetal.,2022).
• BlackBoxassumesthattheserverdoesnothaveanyinformationofneitherMnortraining
dataset. However, it is allowed to send unlimited queries to the client to get M (x) (Xu
c
etal.,2023;Kahlaetal.,2022).
• Query-Free restricts the server from querying M . While such an assumption greatly
c
limitsthereconstructionabilityoftheadversarialparty,therearenolimitationsonauxiliary
informationavailabletotheserverbesidestheactualweightsofM . (Heetal.,2019;Ding
c
et al., 2023) have both shown that M is still vulnerable of leaking private information
c
of the raw input when the server has information of the model architecture and training
dataset. Ourworkwilladoptthissetting.
3 ANALYSIS ON SPLITTING BETWEEN CLIENT AND SERVER
Previous work from He et al. (2019) provided a systematic analysis on the recovery difficulty and
qualityoftheabovementionedmodel-inversionattack. Theirworkanalyzedeffectsonreconstruc-
tion quality from loosening assumptions of auxiliary information available to the server (DNN ar-
chitectureandtrainingdataset),aswellaschoosingdifferentsplitpoints(h)betweentheclientand
theserver.However,theirworkwasbasedonasimple6-layerconvolutionalneuralnetwork(CNN),
whichisseldomusedintoday’sservice.Inthissection,wefurthertheiranalysisuponmorepractical
architectures,namelyResNet-18andVGG-16.
One of the important findings from He et al. (2019); Ding et al. (2023)’s study is that increasing
thedepth(h)ofM willleadtoworseimagereconstructionqualityoftheadversarialattackerin
c,h
MIA.Atthesametime,partofZhouetal.(2022)’salgorithmletstheclient,insteadoftheserver,
computetheSoftmaxfunctionofM(x,θ)atthelastlayer. Thesuccessoftheiralgorithmraisesthe
possibilityofutilizingasecondsplitpointtoenhancingprivacyprotection. Underthethreatmodel
defined by Section 2.2, we provide visual evaluations of the quality of reconstructed images from
MIA,asshownbyFig.2and3.Theverticalaxisisthepositionoffirstsplitpoint,andthehorizontal
axisisthepositionofsecondsplitpointcountingbackwards. ForVGG-16architecture,thefirsth
layers of M belongs to the client. For the ResNet-18 architecture with 4 blocks, h represents the
numberofresidualblockscomputedbytheclient,withh=1beingtheclientonlycomputingthefirst
convolutionallayer.
As shown in the figures, our experiments align with the results from He et al. (2019) and Ding
etal.(2023). Thedeeperthefirstsplitpointis,theworsethereconstructedimageis. However,
the experiments do not support the idea from Zhou et al. (2022). The second split point does not
increase the difficulty of reconstruction under MIA. It is also noteworthy to point out that while
4r
Figure2: EffectoffirstandsecondsplitpointsonVGG16. Theverticalaxisisthefirstsplitpointin
termsoflayers,andthehorizontalaxisisthesecondsplitpointcountingbackwardsonlayers.
r
Figure3:EffectoffirstandsecondsplitpointsonResNet-18with4blocksintheshapeof[2,2,2,2].
The vertical axis is the first split point, and the horizontal axis is the second counting backwards.
Whenh=1,onlythefirstconvolutionallayerbelongstotheclient;whenh=2,splitpointisattheend
ofthefirstblock;whenh=3,thesplitpointisatthesecondblock.
5our experiments indicate that image reconstruction quality is below human-level recognition after
h=6 for VGG-16 and h=2 for ResNet-18, this should not be treated as a privacy-guarantee. This
is because we are using a standard decoder for M˜ (x,θ˜ ), whereas there exist more powerful
c,h c,h
generativedecodersthatcoulddopotentiallybetteratreconstructingimages(Khosravyetal.,2022).
Atthesametime,thisreconstructiondependsonthetask. Forexample,Luetal.(2022)isableto
reconstructhigh-qualityfacialimageswithlargerh,andDingetal.(2023)ismoresuccessfulwith
vehicle reconstruction. We also provide a brief experiment of MIA on NLP task in the Appendix
A.1.
4 Ensembler ARCHITECTURE
Whileitis possibletoprotectsensitivedata viaincreasingthedepth (h)asshownbythe previous
section,suchdepthisoftenimpracticalforedgedevicesduetothecomputationaldemandsinvolved.
Inthissection,wepresentEnsembler,aframeworkthataugmentstheprivacyofintermediateinfor-
mationsentbytheclientwithoutrequiringextracomputationeffortsoftheclientduringinference.
Ensemblerishighlyextensible,anditiscompatiblewithexistingworksthatapplynoisesandpertur-
bationduringbothDNNtrainingandinference. WewillgooverthedetailedarchitectureinSection
4.1,aswellasthetrainingstageofthisnewframeworkinSection4.2.
4.1 ARCHITECTUREOVERVIEW
AsillustratedinFig. 4,Ensemblerleveragesmodelensemblingontheservertogeneratearegular-
ized secret M that is hard to be reconstructed by the server. It consists of three parts: standard
c,h
clientlayers,Ndifferentservernets,andaselector. Duringthecollaborativeinferencepipeline,the
clientcomputesM (x)andtransmitstheintermediateoutputtotheserver. Theserverthenfeeds
c,h
theintermediateoutputthrougheachoftheMi,andreportingtheoutputofeachMi totheclient.
s s
The client then employs a selector to perform a selection of the feedback from the server, which
activatesresultsofPoutofNnetsandcombinesthem. Asafinalstep,itperformsthecomputation
ofthelasttlayerstoclassifytheinput. Wewillintroducetheseseparatelyinthissection.
4.1.1 CLIENTLAYERS
Duringcollaborativeinference,apartoftheDNNisrunbytheclient. Undertheproposedframe-
work,theclientisresponsibleforrunningthefirsthlayersM andthelasttlayersM . These
c,h c,t
layersarethesameastheclientpartofatypicalcollaborativeinferenceframework. M takesthe
c,h
rawinput(oftenanimage)andoutputstheintermediateresult,whereasM takestheoutputfrom
c,t
theserverasinputandoutputsthelikelihoodofeachclass.
4.1.2 SERVERNETS
On the server side, the network is consisted of N copies of DNN, with each Mi corresponding
s
to what the server would normally process in a typical collaborative inference pipeline. That is,
each Mi : {M ,Mi,M } is a valid pipeline for the inference task. Upon receiving M (x),
c,h s c,t c,h
whichistheinputfromtheclient,theservershallfeedthisinputintoeachofMi,anditoutputsN
s
representationsofhiddenfeaturesusedforclassification.
4.1.3 SELECTOR
To increase the difficulty of the server reconstructing the model and recovering the raw input, a
selectorisappliedbeforethelastlayerrunbytheclient. Theselectorservesasasecretactivation
function,whichactivatesPoftheNnetsaccordingtoEquation. 1,whereS istheactivationfrom
i
selector,and⊙istheelement-wisemultiplication. Forsimplicity,weconsiderS = 1/P ifMi is
i s
selectedbytheclient,anS =0otherwise.
i
Selector[M (x)]=Concat[S ⊙M1(x),S ⊙M2(x),...,S ⊙MN(x)] (1)
s 1 s 2 s N s
6Figure 4: Illustration of the proposed architecture, Ensembler. Different from the traditional CI
pipelines,itdeploysNneuralnetworksontheserver,andusesaselectortoactivatePoftheNnets.
4.2 TRAININGSTAGE
Asmentionedabove,thedesignchoicesofEnsembler aimtoachievearegularizedM suchthat
c,h
ashadownetworkbasedonM wouldbeanincorrectestimateofM . Toachievethisgoal, the
s c,h
proposed architecture uses a two-staged training pipeline. For the first stage, it needs to obtain
N distinct Mi(x,θi) : {Mi ,Mi,Mi } such that a shadow network that accurately simulates
c,h s c,t
Mi could not simulate Mj . In our approach, we choose to simply introduce a Gaussian noise
c,h c,h
layer after the intermediate output Mi (x). The objective function in this stage is to minimize
c,h
thecross-entropylossintheformofEquation. 2, whereN(0,σ)i isafixedGaussiannoiseadded
to the intermediate output. The choice of σ is dependent on the quality of training, and given the
inherentredundancyintheparametersofDNNs,addingsomenoiseswillnotaffecttheclassification
accuracy.Forexample,addingnoiseofN(0,0.1)afterthefirstlayerofaResNet-18architecturefor
CIFAR-10imageclassificationtaskresultsinlessthan1%accuracyloss.WechooseGaussiannoise
becauseofsimplicityinimplementation,andwe’darguethatanymethodthatwillleadtodistinctive
M will be sufficient for this step. However, this step is nonetheless needed to ensure that each
c,h
model has different parameter weights. Otherwise, all N models would be identical to each other,
andtheframeworkfailsitspurposeinprotectingprivacy.
(cid:88)
Li =− y ∗logMi (Mi[Mi (x)+N(0,σ)i]) (2)
θ j c,t s c,h j
j
After the first training stage, N different DNNs are obtained. The proposed framework selects P
of the N nets, and retrains an “ensembled” network, Ensembler, which has been outlined in the
previoussection. Duringthetraining,parametersofM arefrozen. Thisstepisusedtoensurethe
s
performanceofthemodelduringinference. Whilethetrainingprocessisjustlikeanytypicalneural
network,itisnoteworthytopointoutthatweaddaregularizationtermtothestandardcross-entroy
losstoenforceM tolearnajointM andM representationfromallofthePservernets. The
c,h c,t
custom loss function, as shown in Equation. 3, adds a high penalty to the model if the gradient
descends only to the direction of some single server net Mi. In the equation, CS is the cosine
s
similarity, andλisahyper-parametercontrollingtheregularizationstrength. Sincethisisanend-
to-endtrainingprocess,anyperturbation-basedalgorithmscouldbeseamlesslycombinedwiththe
proposedframeworkduringthissteptoprovidefurtherprivacyprotection. Forourexperiment,we
justchoosesimpleGaussiannoisestobeconsistentwiththefirststep.
i∈N
(cid:88)(cid:88)
L =− [y ∗logM (Selector[Mi[M (x)+N(0,σ)]]) ]
θ j c,t s c,h j
(3)
i j
+λmax [CS(M (x),Mi (x))]
i∈P c,h c,h
74.3 INTUITIONBEHINDEnsembler
In this section, we discuss the intuition behind the proposed architecture. Since the attacker will
constructshadownetworkstosimulatethebehaviorofclient’sprivatenetworks,theexactpurposeof
thetwo-stagedtrainingalgorithmistoensurethattheattackerisnotabletolearntheselectorwithits
shadownetwork.Throughthefirststageoftraining,Ndifferentmodelsthathavedistinctiveweights
areobtained,yetallofthemareabletomakecomparativepredictionsonthedataset. Anarbitrary
ensembleofPoutoftheNnetworkswillformanewnetwork,whoseM willbedistinctivefrom
c,h
networksunderadifferentcombination. Thatis,sinceMi+j wouldbedifferentfromMi+k,Mi+j
s s c,h
obtainedfromMi+j wouldbedifferentfromMi+k obtainedfromMi+k,where+isensembleof
s c,h s
server nets. Thus, with N networks in the first stage of the algorithm, we will have 2N different
possible M that could be the valid answer to the shadow network. When the attacker tries to
c,h
train an adaptive attacker, the shadow network will learn an arbitrary representation M˜ and an
c,h
arbitraryS˜. Suchcombinationisavalidchoiceintermsofclassificationaccuracybutisnonetheless
incorrectcomparedtotheactualM .
c,h
4.4 TIMECOMPLEXITYOFEnsembler
From previous section, it is clear that the time complexity of the proposed framework is N times
of the individual network on a single-core GPU, and there is negligible extra communication cost
between the client and the server. However, it is worthy to emphasize that since each Mi is inde-
s
pendenttoeachother,theproposedframeworkisfriendlytoparallelexecutionandevenmultiparty
(multi-server) inference. Under those settings, the theoretical time complexity of N would be re-
placedwithlowerpracticaltimecostsorevencausestheframeworktobeuninvertible. Ontheother
hand, since the server is not able to adaptively learn the client’s representation, the only option is
toexhaustivelytryallcombinations,whichtakes2N timescomparedtoreconstructingasinglenet-
work. Here, we provide a semi-formal argument on exponential complexity of reconstructing the
bestqualityimageunderEnsemblerprotection.
Lemma1ReconstructingimagefromsingleneuralnetworkMi isnotviable.
s
For any shadow network obtained through single Mi , it needs to first simulate the behavior of
s
Mi . In this case, if there exists some Mi that simulates M , the training loss of the second
c,h c,h c,h
trainingphraseisnotoptimized(Equation. 3)duetotheregularizationterm.
Lemma2ReconstructingimagefromincorrectchoiceofM ˜ =[Mi,...,Mj]isnotviable.
activated s s
Since g ∈ N(0,σ) are independent of each other, the N different Mi(x,θi) obtained in the first
i
trainingstagearealsodistinctive. IncludingincorrectMj intheshadownetworkconstructionwill
s
leadtothemodelregularizinginanincorrectdirection.
ConclusionThetimecomplexityofreconstructingbestqualityinputfromNservernetsistheoreti-
cally2N −1.
5 EXPERIMENTS AND EVALUATIONS
5.1 ARCHITECTUREDETAILS
During the experiment, we consider the most strict setting, where h=1 and t=1 on a ResNet-18
architectureforthreeimageclassificationtasks,CIFAR-10,CIFAR-100,andasubsetofCelebA-HQ
Zhuetal.(2022). Thatis,theclientonlyholdsthefirstconvolutionallayeraswellasthelastfully-
connected layer, which is also the minimum requirement for our framework. For CIFAR-10, the
intermediateoutput’sfeaturesizeis[64x16x16],forCIFAR-100,weremovetheMaxPoolinglayer
andtheintermediateoutput’sfeaturesizeis[64x32x32],andforCelebA,theintermediateoutput’s
feature size is [64x64x64]. We consider the ensembled network to contain 10 neural networks
(N=10),eachbeingaResNet-18.Theselectorsecretlyselects{4,3,5}outofthe10nets(P={4,3,5}),
respectively.Theadversarialserverisawareofthearchitectureandthetrainingdataset.Itconstructs
ashadownetworkM˜ consistedofthreeconvolutionallayerswith64channelseach,withthefirst
c,h
one simulating the unknown M , and the other two simulating the Gaussian noise added to the
c,h
8intermediateoutput. ItalsohasM˜ withthesameshapeasM . Foradaptiveshadownetwork,it
c,t c,t
learnsfromall10servernetswithanadditionalactivationlayerthatisidenticaltotheselector. For
anynoisesaddedtotheintermediateoutputsduringthetrainingandinferencestage,weconsidera
fixedGaussiannoiseg∼N(0,0.1).
5.2 EXPERIMENTSETUP
To evaluate the effectiveness of our approach, we employ three key metrics: Structural Similarity
(SSIM), Peak Signal to Noise Ratio (PSNR), and visual assessment. The first two metrics offer
quantitative evaluations of the reconstruction quality of MIA, with higher SSIM and PSNR val-
uesindicatingbetterreconstructionquality. Asourproposedarchitectureoperatesinparallelwith
existing perturbation methods, we consider the following baseline approaches for comparison on
CIFAR-10: no protection (NONE), adding small noise in a single network that does not require
retraining (Shredder Mireshghallah et al. (2020)), adding large noise and retrain a single network
(Single), andaddingdropoutlayerinthesinglenetworkorensemblednetwork, butwithonlyone
roundoftraining(DR-singleandDR-ensemble). Thedropoutisincludedtodifferentiateourarchi-
tecturewithdropoutlayers,astheselectorcomponentdoeslookverysimilartoadropoutlayer. For
theothertwo datasets, weselectsomeoftheimportant benchmarskforcomparison. For CelebA-
HQ, since the intermediate output’s feature size is too large for the simple Gaussian filter to be
visuallyeffective,weaddanuntrainedrandomM (Random)toillustratethemaximumcapacity
c,h
ofGaussianfilteratthecostofaccuracy.Fortheproposedarchitecture,weevaluatetheperformance
ofbothreconstructionofasingleneuralnetwork(N=1), aswellasreconstructionusingtheentire
network(Adaptive). Forreconstructionofensemblednetsusingasingleneuralnetwork,wereport
thebestreconstructionresultoftheNnets.ForSection3,weimplementtheexperimentsonaserver
withfourA-6000GPUsusingPythonandPyTorch. ForSection4,weusedamixtureoftheserver
andGoogleColab,whichusesoneT4GPU.
5.3 COMPARISONOFRESULTS
We provide the quantitative evaluations for CIFAR-10 in Table. 1, and the visual assessments in
Figure. 5inAppendixA.2.1. Itcouldbeseenthattheproposedframeworksignificantlyincreases
thereconstructiondifficultyoftheadversarialparty. Ensemblerincurs2.13%dropinclassification
accuracycomparedtothemodelwithoutanyprotection,whichismarginalcomparedtoitsadvan-
tageinprotectingprivacyoftheclient’srawinput. Fromthefigure,itisclearthatthereconstructed
imagesarehardlyrecognizablebyhuman-levelinterpretations.
In addition, we provide the quantitative evaluations for CIFAR-100 and CelebA-HQ in Table. 2
and3,andthevisualassessmentsinAppendixA.2.2andA.2.3. Theproposedframeworkremains
effectivewhenthefeaturesizeincreases. Inparticular, theframeworksafegaurdsthemodel’spre-
diction ability while protecting the input images on par with the random head network. Although
thevisualassessmentsshowthatincreasingfeaturesizeleadstobettervisualrecognition,weargue
thatitisinevitablewithsimpleGaussiannoises. Inparticular, theshadownetworkisabletoraise
thereconstructionqualityofatotallymismatchedrandomM tobeyondhuman-recognitionlevel
c,h
fromtheshadownetworkwithbestPSNR.
Table 1: Quantitative evaluations of the different defense mechanisms with CIFAR-10. Last three
aretheproposedframework. ForSSIMandPSNR,lowervaluesmeanworsereconstructionquality.
Name Changeinaccuracy SSIM PSNR
NONE 0.00% 0.4363 12.2678
Shredder -5.68% 0.5359 10.4033
Single 2.15% 0.3921 7.5266
Dr-single 2.70% 0.3453 6.6674
Dr-ensemble(bestSSIM) 1.42% 0.373 7.3493
Dr-ensemble(bestPSNR) 1.42% 0.3232 7.9598
Adaptive -2.13% 0.0555 5.981
N=1(bestSSIM) -2.13% 0.2889 4.865
N=1(bestPSNR) -2.13% 0.2221 5.5348
9Table 2: Quantitative evaluations of the different defense mechanisms with CIFAR-100. Last two
aretheproposedframework. ForSSIMandPSNR,lowervaluesmeanworsereconstructionquality.
Name Changeinaccuracy SSIM PSNR
Single -0.97% 0.4558 8.5225
Adaptive 0.31% 0.0864 4.7715
N=1(bestSSIM&bestPSNR) 0.31% 0.2636 5.0741
Table3: QuantitativeevaluationsofthedifferentdefensemechanismswithCelebA-HQZhuetal.
(2022). Last two are the proposed framework. For SSIM and PSNR, lower values mean worse
reconstructionquality.
Name Changeinaccuracy SSIM PSNR
Single -1.24% 0.2650 14.3126
Random(bestSSIM&bestPSNR) -65.19% 0.1387 12.8150
Adaptive 2.39% 0.0897 13.3698
N=1(bestSSIM&bestPSNR) 2.39% 0.1791 12.0645
6 CONCLUSION
In this paper, we present two contributions to the research community of PPML and collaborative
inference. First,weextendthediscussiononchoosingthesplitpointsbetweenclientandserverun-
dercollaborativeinference. Ourexperimentsilluminatethatdeepersplitpointsyieldlower-quality
reconstructions,whiletheintroductionofasecondsplitpointofferslittletonoimprovement. Fur-
thermore,weintroduceanovelframework,Ensembler,designedtosignificantlyincreasethecom-
plexityofreconstructionforadversarialparties. Ensemblerseamlesslyalignswithexistingmethods
thatintroducediverseformsofnoisetointermediateoutputs,potentiallyyieldingrobustandadapt-
able architectures if combined with them. Our experiments highlight the substantial deterioration
inreconstructionqualityforimagessafeguardedbyEnsemblerwhencomparedtothosewithoutits
protection.
REFERENCES
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel
Herbert-Voss,GretchenKrueger,TomHenighan,RewonChild,AdityaRamesh,DanielZiegler,
JeffreyWu,ClemensWinter,ChrisHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,
BenjaminChess,JackClark,ChristopherBerner,SamMcCandlish,AlecRadford,IlyaSutskever,
and Dario Amodei. Language models are few-shot learners. In H. Larochelle, M. Ranzato,
R.Hadsell,M.F.Balcan,andH.Lin(eds.),AdvancesinNeuralInformationProcessingSystems,
volume33,pp.1877–1901.CurranAssociates,Inc.,2020.
JiaDeng,WeiDong,RichardSocher,Li-JiaLi,KaiLi,andLiFei-Fei.Imagenet:Alarge-scalehier-
archicalimagedatabase. In2009IEEEConferenceonComputerVisionandPatternRecognition,
pp.248–255,2009. doi: 10.1109/CVPR.2009.5206848.
Shiwei Ding, Lan Zhang, Miao Pan, and Xiaoyong Yuan. Patrol: Privacy-oriented pruning for
collaborativeinferenceagainstmodelinversionattacks,2023.
AlexeyDosovitskiyandThomasBrox.Invertingvisualrepresentationswithconvolutionalnetworks.
In2016IEEEConferenceonComputerVisionandPatternRecognition(CVPR),pp.4829–4837,
2016. doi: 10.1109/CVPR.2016.522.
AlexeyDosovitskiy,LucasBeyer,AlexanderKolesnikov,DirkWeissenborn,XiaohuaZhai,Thomas
Unterthiner,MostafaDehghani,MatthiasMinderer,GeorgHeigold,SylvainGelly,JakobUszko-
reit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recogni-
tion at scale. In International Conference on Learning Representations, 2021. URL https:
//openreview.net/forum?id=YicbFdNTTy.
10Niv Haim, Gal Vardi, Gilad Yehudai, michal Irani, and Ohad Shamir. Reconstructing train-
ing data from trained neural networks. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave,
and Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022. URL
https://openreview.net/forum?id=Sxk8Bse3RKO.
Zecheng He, Tianwei Zhang, and Ruby B. Lee. Model inversion attacks against collaborative in-
ference. InProceedingsofthe35thAnnualComputerSecurityApplicationsConference,ACSAC
’19, pp. 148–162, New York, NY, USA, 2019. Association for Computing Machinery. ISBN
9781450376280. doi: 10.1145/3359789.3359824. URL https://doi.org/10.1145/
3359789.3359824.
HongshengHu,ZoranSalcic,LichaoSun,GillianDobbie,PhilipS.Yu,andXuyunZhang. Mem-
bershipinferenceattacksonmachinelearning:Asurvey. ACMComput.Surv.,54(11s),sep2022.
ISSN0360-0300. doi: 10.1145/3523273. URLhttps://doi.org/10.1145/3523273.
XiaHu,LingyangChu,JianPei,WeiqingLiu,andJiangBian. Modelcomplexityofdeeplearning:
A survey. Knowl. Inf. Syst., 63(10):2585–2619, oct 2021. ISSN 0219-1377. doi: 10.1007/
s10115-021-01605-0. URLhttps://doi.org/10.1007/s10115-021-01605-0.
Huseyin A. Inan, Osman Ramadan, Lukas Wutschitz, Daniel Jones, Victor Ru¨hle, James Withers,
and Robert Sim. Privacy analysis in language models via training data leakage report. CoRR,
abs/2101.05405,2021. URLhttps://arxiv.org/abs/2101.05405.
John M. Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ron-
neberger,KathrynTunyasuvunakool,RussBates,AugustinZ´ıdek,AnnaPotapenko,AlexBridg-
land, Clemens Meyer, Simon A A Kohl, Andy Ballard, Andrew Cowie, Bernardino Romera-
Paredes, Stanislav Nikolov, Rishub Jain, Jonas Adler, Trevor Back, Stig Petersen, David A.
Reiman, Ellen Clancy, Michal Zielinski, Martin Steinegger, Michalina Pacholska, Tamas
Berghammer, Sebastian Bodenstein, David Silver, Oriol Vinyals, Andrew W. Senior, Koray
Kavukcuoglu,PushmeetKohli,andDemisHassabis. Highlyaccurateproteinstructureprediction
with alphafold. Nature, 596:583 – 589, 2021. URL https://api.semanticscholar.
org/CorpusID:235959867.
M. Kahla, S. Chen, H. Just, and R. Jia. Label-only model inversion attacks via boundary repul-
sion. In 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),
pp. 15025–15033, Los Alamitos, CA, USA, jun 2022. IEEE Computer Society. doi: 10.
1109/CVPR52688.2022.01462. URLhttps://doi.ieeecomputersociety.org/10.
1109/CVPR52688.2022.01462.
Mahdi Khosravy, Kazuaki Nakamura, Yuki Hirose, Naoko Nitta, and Noboru Babaguchi. Model
inversionattackbyintegrationofdeepgenerativemodels: Privacy-sensitivefacegenerationfrom
a face recognition system. IEEE Transactions on Information Forensics and Security, 17:357–
372,2022. doi: 10.1109/TIFS.2022.3140687.
B. Knott, S. Venkataraman, A.Y. Hannun, S. Sengupta, M. Ibrahim, and L.J.P. van der Maaten.
Crypten: Securemulti-partycomputationmeetsmachinelearning. InarXiv2109.00984,2021.
Kwok-Yan Lam, Xianhui Lu, Linru Zhang, Xiangning Wang, Huaxiong Wang, and Si Qi Goh.
Efficient fhe-based privacy-enhanced neural network for ai-as-a-service. Cryptology ePrint
Archive,Paper2023/647,2023. URLhttps://eprint.iacr.org/2023/647. https:
//eprint.iacr.org/2023/647.
HaoranLi,MingshiXu,andYangqiuSong. Sentenceembeddingleaksmoreinformationthanyou
expect: Generativeembeddinginversionattacktorecoverthewholesentence. InFindingsofthe
AssociationforComputationalLinguistics: ACL2023,pp.14022–14040,Toronto,Canada,July
2023.AssociationforComputationalLinguistics. doi: 10.18653/v1/2023.findings-acl.881. URL
https://aclanthology.org/2023.findings-acl.881.
JingtaoLi,AdnanSirajRakin,XingChen,ZhezhiHe,DeliangFan,andChaitaliChakrabarti.Ressfl:
A resistance transfer framework for defending model inversion attack in split federated learn-
ing. InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition
(CVPR),pp.10194–10202,June2022.
11Ximeng Liu, Lehui Xie, Yaopeng Wang, Jian Zou, Jinbo Xiong, Zuobin Ying, and Athanasios V.
Vasilakos. Privacy and security issues in deep learning: A survey. IEEE Access, 9:4566–4593,
2021. doi: 10.1109/ACCESS.2020.3045078.
RuiLu,SipingShi,DanWang,ChuangHu,andBihaiZhang. Preva: Protectinginferenceprivacy
through policy-based video-frame transformation. In 2022 IEEE/ACM 7th Symposium on Edge
Computing(SEC),pp.175–188,2022. doi: 10.1109/SEC54971.2022.00021.
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Ar-
cas. Communication-Efficient Learning of Deep Networks from Decentralized Data. In
Aarti Singh and Jerry Zhu (eds.), Proceedings of the 20th International Conference on Artifi-
cial Intelligence and Statistics, volume 54 of Proceedings of Machine Learning Research, pp.
1273–1282. PMLR, 20–22 Apr 2017. URL https://proceedings.mlr.press/v54/
mcmahan17a.html.
Fatemehsadat Mireshghallah, Mohammadkazem Taram, Prakash Ramrakhyani, Ali Jalali, Dean
Tullsen, and Hadi Esmaeilzadeh. Shredder: Learning noise distributions to protect infer-
ence privacy. In Proceedings of the Twenty-Fifth International Conference on Architectural
Support for Programming Languages and Operating Systems, ASPLOS ’20, pp. 3–18, New
York, NY, USA, 2020. Association for Computing Machinery. ISBN 9781450371025. doi:
10.1145/3373376.3378522. URLhttps://doi.org/10.1145/3373376.3378522.
PratyushMishra,RyanLehmkuhl,AkshayaramSrinivasan,WentingZheng,andRalucaAdaPopa.
Delphi: Acryptographicinferenceserviceforneuralnetworks. In29thUSENIXSecuritySympo-
sium(USENIXSecurity20), pp.2505–2522.USENIXAssociation, August2020. ISBN978-1-
939133-17-5. URLhttps://www.usenix.org/conference/usenixsecurity20/
presentation/mishra.
SeyedOsia, AliTaheri, AliShahinShamsabadi, KleomenisKatevas, HamedHaddadi, andHamid
Rabiee.Deepprivate-featureextraction.IEEETransactionsonKnowledgeandDataEngineering,
PP,022018. doi: 10.1109/TKDE.2018.2878698.
Maarten G. Poirot, Praneeth Vepakomma, Ken Chang, Jayashree Kalpathy-Cramer, Rajiv Gupta,
and Ramesh Raskar. Split learning for collaborative deep learning in healthcare. CoRR,
abs/1912.12115,2019. URLhttp://arxiv.org/abs/1912.12115.
Deevashwer Rathee, Mayank Rathee, Nishant Kumar, Nishanth Chandran, Divya Gupta, Aseem
Rastogi, and Rahul Sharma. Cryptflow2: Practical 2-party secure inference. Cryptology
ePrintArchive,Paper2020/1002,2020. URLhttps://eprint.iacr.org/2020/1002.
https://eprint.iacr.org/2020/1002.
BrandonReagen, Woo-SeokChoi, YeongilKo, VincentT.Lee, Hsien-HsinS.Lee, Gu-YeonWei,
and David Brooks. Cheetah: Optimizing and accelerating homomorphic encryption for private
inference. In2021IEEEInternationalSymposiumonHigh-PerformanceComputerArchitecture
(HPCA),pp.26–39,2021. doi: 10.1109/HPCA51647.2021.00013.
A.Salem,G.Cherubin,D.Evans,B.Kopf,A.Paverd,A.Suri,S.Tople,andS.Zanella-Beguelin.
Sok: Let the privacy games begin! a unified treatment of data inference privacy in machine
learning. In2023IEEESymposiumonSecurityandPrivacy(SP),LosAlamitos,CA,USA,may
2023.IEEEComputerSociety. doi: 10.1109/SP46215.2023.10179281. URLhttps://doi.
ieeecomputersociety.org/10.1109/SP46215.2023.10179281.
WaritSirichotedumrongandHitoshiKiya. Agan-basedimagetransformationschemeforprivacy-
preserving deep neural networks. In 2020 28th European Signal Processing Conference (EU-
SIPCO),pp.745–749,2021. doi: 10.23919/Eusipco47968.2020.9287532.
CongzhengSongandAnanthRaghunathan.Informationleakageinembeddingmodels.InProceed-
ings of the 2020 ACM SIGSAC Conference on Computer and Communications Security, CCS
’20, pp. 377–390, New York, NY, USA, 2020. Association for Computing Machinery. ISBN
9781450370899. doi: 10.1145/3372297.3417270. URL https://doi.org/10.1145/
3372297.3417270.
12SijunTan,BrianKnott,YuanTian,andDavidJ.Wu. CRYPTGPU:Fastprivacy-preservingmachine
learningonthegpu. InIEEES&P,2021.
Q. Wang and D. Kurz. Reconstructing training data from diverse ml models by ensemble in-
version. In 2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV),
pp. 3870–3878, Los Alamitos, CA, USA, jan 2022. IEEE Computer Society. doi: 10.
1109/WACV51458.2022.00392.URLhttps://doi.ieeecomputersociety.org/10.
1109/WACV51458.2022.00392.
Jean-LucWatson,SameerWagh,andRalucaAdaPopa. Piranha: Agpuplatformforsecurecom-
putation. CryptologyePrintArchive,Paper2022/892,2022. URLhttps://eprint.iacr.
org/2022/892. https://eprint.iacr.org/2022/892.
RunhuaXu,NathalieBaracaldo,andJamesJoshi. Privacy-preservingmachinelearning: Methods,
challengesanddirections. CoRR,abs/2108.04417,2021. URLhttps://arxiv.org/abs/
2108.04417.
YixiaoXu,XiaoleiLiu,TengHu,BangzhouXin,andRunYang. Sparseblack-boxinversionattack
with limited information. In ICASSP 2023 - 2023 IEEE International Conference on Acous-
tics,SpeechandSignalProcessing(ICASSP),pp.1–5,2023. doi: 10.1109/ICASSP49357.2023.
10095514.
Duygu Yaldiz, Tuo Zhang, and Salman Avestimehr. Secure federated learning against model poi-
soningattacksviaclientfiltering. InICLR2023WorkshoponBackdoorAttacksandDefensesin
MachineLearning,032023.
XiaofanYu,LucyCherkasova,HarshVardhan,QuanlingZhao,EmilyEkaireb,XiyuanZhang,Arya
Mazumdar,andTajanaRosing. Async-hfl: Efficientandrobustasynchronousfederatedlearning
in hierarchical iot networks. In Proceedings of the 8th ACM/IEEE Conference on Internet of
ThingsDesignandImplementation,IoTDI’23,pp.236–248,NewYork,NY,USA,2023.Asso-
ciationforComputingMachinery. ISBN9798400700378. doi: 10.1145/3576842.3582377. URL
https://doi.org/10.1145/3576842.3582377.
Wanrong Zhang, Shruti Tople, and Olga Ohrimenko. Leakage of dataset proper-
ties in Multi-Party machine learning. In 30th USENIX Security Symposium (USENIX
Security 21), pp. 2687–2704. USENIX Association, August 2021. ISBN 978-1-
939133-24-3. URLhttps://www.usenix.org/conference/usenixsecurity21/
presentation/zhang-wanrong.
Y. Zhang, R. Jia, H. Pei, W. Wang, B. Li, and D. Song. The secret revealer: Generative
model-inversion attacks against deep neural networks. In 2020 IEEE/CVF Conference on
Computer Vision and Pattern Recognition (CVPR), pp. 250–258, Los Alamitos, CA, USA,
jun 2020. IEEE Computer Society. doi: 10.1109/CVPR42600.2020.00033. URL https:
//doi.ieeecomputersociety.org/10.1109/CVPR42600.2020.00033.
Jun Zhou, Longfei Zheng, Chaochao Chen, Yan Wang, Xiaolin Zheng, Bingzhe Wu, Cen Chen,
Li Wang, and Jianwei Yin. Toward scalable and privacy-preserving deep neural network via
algorithmic-cryptographicco-design. ACMTrans.Intell.Syst.Technol.,13(4),may2022. ISSN
2157-6904. doi: 10.1145/3501809. URLhttps://doi.org/10.1145/3501809.
Hao Zhu, Wayne Wu, Wentao Zhu, Liming Jiang, Siwei Tang, Li Zhang, Ziwei Liu, and
ChenChangeLoy. CelebV-HQ:Alarge-scalevideofacialattributesdataset. InECCV,2022.
A APPENDIX
A.1 MIAONTEXTDATA
Aslargelanguagemodels(LLM)developinrecentyears,privacyoftextdatahasalsobroughtforth
muchattention. TherehavebeenseveralworksapplyingMIAonLLMs,buttheyallatleastrequire
black-box query-access to M (Song & Raghunathan, 2020; Li et al., 2023). To the best of our
c,h
knowledge,MIAfortextdataunderaquery-freethreatmodelhasnotbeenstudied.
13Table4: ExampleofEnglishtoGermanTranslation. Fromlefttoright,thecolumnsare: 1. ground
truthofrawinputinEnglish. 2. translatedtextinGermanduringcollaborativeinference. 3. trans-
latedtextinGermanusingshadownetworkasthemodel. 4. decodedinputfromtheintermediate
outputofshadownetwork(toensurethedecoderisworkingproperly). 5. decodedinputfromthe
intermediateoutputproducedbyM
c,h
Ground Standard Trans- ShadowTransla- Decoder On DecoderOnClient
Truth lation tion Shadow
There is a Ein junges Ein junges There is a Dark swinging com-
young girl Ma¨dchen fa¨hrt Ma¨dchen fa¨hrt young girl plete wait for no
on her cell- mit ihrem aufihremHandy skating while complete complete
phone while Handy wa¨hrend und telefoniert skating on her complete wearing
skating. sieskatet. dabei , wa¨hrend cellphone. completewaitwait
sie auf ihrem
Handyfa¨hrt
Trendy girl Ein Ma¨dchen Ein Ma¨dchen gliding girl Here picture waves
talking on mit Glatze spricht auf der talking on balding wait for a
her cell- spricht auf Straße,wa¨hrend her cellphone picture complete
phone while ihrem Handy sie die Straße while gliding wearing picture wait
gliding , wa¨hrend sie spricht. slowly down mixing wait mixing
slowly down die Straße ent- thestreet waitmixingwait
thestreet langfa¨hrt.
In the experiments, we tried to use the same MIA pipeline from the image reconstruction to text
reconstructionbyconsideringanexamplemodelfromPyTorch1. Thisisatransformermodelfor
English to German translation tasks, and for collaborative inference, the client privately holds the
embeddinglayerforthetwolanguages. ThetextresultsforreconstructionaresummarizedinTable.
4,whichisastandardMIApipelinefromlefttoright. Thesecondcolumnshowcasesthetranslated
text under normal inference. The adversarial server trains a shadow network, whose translation
is shown in the third column. From the shadow network, a decoder is trained to reconstruct the
input from intermediate output. Finally, the decoder is applied to the intermediate output from
the client, with the results illustrated in the last column. As it suggests on the last two columns,
while the decoder is able to reconstruct text on the shadow network M˜ , due to the moderate
c,h
difference between M˜ and M , the decoded result from M could not be understood. It is
c,h c,h c,h
alsonoteworthytomentionthattheshadowmodelismuchhardertoconvergecomparedtotraining
theentireM,possiblybecausemajorityofparametersarefrozeninthenetwork.
A.2 IMAGES
A.2.1 VISUALILLUSTRATIONSFORCIFAR-10
A.2.2 VISUALILLUSTRATIONSFORCIFAR-100
1https://pytorch.org/tutorials/beginner/translation_transformer.html
14(a)GroundTruth (b)NONE
(c)ShredderMireshghallahetal.(2020) (d)Single
(e)DR-single (f)DR-ensemble(BestSSIM)
(g)DR-ensemble(BestPSNR) (h)N=1(BestSSIM)
(i)N=1(BestPSNR) (j)Adaptive
Figure5:VisualAssessmentoftheimagereconstructionqualityunderdifferentdefensemechanisms
forCIFAR10. Itisclearthatourproposedframework(h,i,j)iseffective. Theeffectismoreobvious
onthefourthimage.
(a)Single (b)Adaptive
(c)N=1(BestSSIM) (d)N=1(BestPSNR)
Figure6:VisualAssessmentoftheimagereconstructionqualityunderdifferentdefensemechanisms
forCIFAR-100.
A.2.3 VISUALILLUSTRATIONSFORCELEBA-HQ
15(b)Adaptive
(a)Single
(c)N=1(BestSSIM) (d)N=1(BestPSNR)
(e)Random(BestSSIM) (f)Random(BestPSNR)
Figure 7: Visual Assessment of the image reconstruction quality under different defense mecha-
nismsforCelebA-HQ.Whenconstructingshadownetworksanddecodersusingsinglepipeline,the
decoderthatresultsinbestPSNRandSSIMisthesameone.
16