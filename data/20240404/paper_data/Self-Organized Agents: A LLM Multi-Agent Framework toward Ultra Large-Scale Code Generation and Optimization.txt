Self-Organized Agents: A LLM Multi-Agent Framework toward
Ultra Large-Scale Code Generation and Optimization
YoichiIshibashi YoshimasaNishimura
TsukushiAI TsukushiAI
ishibashi.tsukushiai@gmail.com nishimura.tsukushiai@gmail.com
Abstract Single agent Self-organized Agents (SoA)
✗Limited scalability ✔Scalable code generation/improvement
Recentadvancementsinautomaticcodegener-
ationusinglargelanguagemodel(LLM)agent
have brought us closer to the future of auto-
matedsoftwaredevelopment. However,exist-
ing single-agent approaches face limitations Code Size
per agent Max context
ingeneratingandimprovinglarge-scale,com- length
Max context
plex codebases due to constraints in context Code Size " length
! per agent
length. To tackle this challenge, we propose
Self-Organizedmulti-Agentframework(SoA), Total Code Size Total Code Size
anovelmulti-agentframeworkthatenablesthe
Figure1: Left(singleagent): Asingleagentissolely
scalableandefficientgenerationandoptimiza-
responsiblefortheentireimplementation. Asthecode-
tionoflarge-scalecode. InSoA,self-organized
basegrowslarger,theloadincreasesforcodegenera-
agentsoperateindependentlytogenerateand
tion,modification,andmemorymanagement,making
modifycodecomponentswhileseamlesslycol-
it difficult to manage and develop. The larger the en-
laboratingtoconstructtheoverallcodebase. A
tire codebase becomes, the more it puts pressure on
keyfeatureofourframeworkistheautomatic
thecontextlengthduringself-debugging,limitingthe
multiplicationofagentsbasedonproblemcom-
amountofcodethatcanbemanaged. Right(SoA):The
plexity,allowingfordynamicscalability. This
implementation is distributed among multiple agents.
enablestheoverallcodevolumetobeincreased
The agents are independent; code generation, modifi-
indefinitelyaccordingtothenumberofagents,
cation, and memory management are separated from
while the amount of code managed by each
other agents. Each agent manages only its own part,
agentremainsconstant. WeevaluateSoAon
allowingittofocusontheimplementationregardless
the HumanEval benchmark and demonstrate
ofthecomplexityoftheentirecodebase. Furthermore,
that,comparedtoasingle-agentsystem,each
agents automatically multiply according to the com-
agent in SoA handles significantly less code,
plexityoftheproblem. Thisallowsforthegeneration
yettheoverallgeneratedcodeissubstantially
andmodificationofcomplexandlarge-scalecodewhile
greater. Moreover,SoAsurpassesthepowerful
maintainingaconstantamountofcodemanagement/-
single-agentbaselineby5%intermsofPass@1
generation/modificationperagent.
accuracy. 1
1 Introduction
of automatic code generation techniques in the
In recent years, research on agents using Large field of automated application and tool develop-
Language Models (LLMs) (Brown et al., 2020; ment(Hongetal.,2023;Dongetal.,2023;Huang
OpenAI,2023;Touvronetal.,2023),suchasRe- etal.,2023). Comparedtonon-agent-basedmeth-
Act (Yao et al., 2023b), Reflexion (Shinn et al., ods (Muennighoff et al., 2023; Li et al., 2023b),
2023),Toolformer(Schicketal.,2023),andAuto- these research achievements have led to remark-
GPT2,hasbeenexpandingthepossibilitiesofau- ableperformanceimprovementsinautomaticcode
tomatinghumantasks. Theseadvancementshave generation(Zhongetal.,2024;Zhouetal.,2023).
particularlycontributedtotherapiddevelopment Mostrecentresearchhasfocusedonsingle-agent
approachesforcodegeneration. Thesesingle-agent
1Our code will be available at https://github.com/
code generation methods face limitations, espe-
tsukushiAI/self-organized-agent.
2https://github.com/Significant-Gravitas/ ciallyintermsofscalability,whentheimplemen-
4202
rpA
2
]ES.sc[
1v38120.4042:viXratationbecomescomplexandrequiresalargecode- talresults,werevealedhowagentsautomatically
base. Themainreasonforthistechnicaldifficultyis multiplyaccordingtothecomplexityoftheprob-
thatasingleagentmustmanagetheentirecodegen- lem, effectively scaling up the overall code vol-
erationprocessalone. Forinstance,implementinga umewhilekeepingthecodegenerationperagent
machinelearningalgorithminvolvesseveralstages, constant (§4.2). These experimental results sup-
suchasdatapreprocessing,algorithmtraining,and portthecontributionofourframework,whichover-
result evaluation, which include many functions comesthescalabilityissuesfacedbysingle-agent
andclasses. Whenthesecomplexcomponentsare approachesandprovidesasolutioncapableofhan-
combined, thecodebaseinevitablybecomesvery dlinglargerprojects.
large. However, there are limitations to the con-
text length of LLMs, and as the number of input 2 CodeGenerationTask
tokens increases, the inference performance de-
The code generation task involves generating
creases (Levy et al., 2024; Shaham et al., 2023;
Python functions from docstrings (Chen et al.,
Lietal.,2023a). Consistentlyunderstandingand
2021). In this task, an agent is given a docstring
generatingormodifyingappropriatecodeforsuch
thatdefinesthetypesofthefunction’sinputsand
anextensivecodebaseposesasignificantchallenge
expected outputs, as well as the specific require-
forasingleagentintermsofcomprehendingand
mentsthatthefunctionshouldmeet. Theagentis
managing the context. Consequently, the single-
then required to generate the code for a function
agentapproachstrugglestoefficientlygenerateand
thatfulfillsthespecifiedfunctionality. Thegener-
modifycodeasitscomplexityandsizeincrease.
atedcodeisverifiedforaccuracyusingunittests,
To tackle these challenges, we propose a self-
and the quality of the code is evaluated based on
organized multi agent framework that can auto-
its ability to pass the test cases. As with previ-
matically generate and modify large-scale code
ousstudies(Shinnetal.,2023;Zhongetal.,2024;
(Figure 1). Self-organization (Ashby, 1947) is a
Zhou et al., 2023), we use the evaluation metric
phenomenoninwhichlivingorganismsormatter
Pass@1 (Chen et al., 2021), where a problem is
createanorderly,largestructureasaresultoftheir
considered solved if any of the k code samples
individualautonomousbehaviors,despitelacking
passalltestcases.
the ability to oversee the entire system. In our
framework,self-organizedagents,eachresponsible
3 Self-organizedAgentFramework
fordifferentcodepartsortasks,independentlygen-
erateandmodifycode. Withtheself-organization Our Self-organized Agents (SoA) framework en-
of agents, a single agent no longer needs to com- ables efficient implementation of large-scale and
prehendtheentirecodebase,makingitpossibleto complexcodebyhavingself-organizedagentsin-
scaleuplarge-scalecodesimplybyincreasingthe dependentlygenerateandmodifysmall-scaleand
number of agents. Another feature of our frame- simplecode. Inthissection,weintroducetheim-
workisthatagentsautomaticallymultiplyaccord- portantcomponentsofSoA,namelytheagentsand
ing to the complexity of the problem, allowing the layers responsible for more abstract process-
theoverallcodebasetoexpandwhilekeepingthe ingthantheagents,andfinallyintroducethecode
amount of code handled by each agent constant. generationandmodificationprotocolsintheSoA
Thesefeaturesenablethedynamicandflexiblegen- framework.
erationandmodificationoflarge-scalecode,which
3.1 ChildAgent
was impossible with the traditional single-agent
approach. Childagentsimplementagivenfunctionbasedon
In our experiments, we evaluated the perfor- itsdocstrings. AsshowninFigure2,thisagenthas
manceofthisframeworkusingHumanEval(Chen asimplestructureconsistingoftwoelements: an
etal.,2021),abenchmarkforcodegeneration. The LLMandmemory. TheLLMgeneratescodefrom
results show that our self-organized multi-agent thegivendocstringsandmodifiesthecodebased
framework outperformed Reflexion (Shinn et al., ontheresultsofunittests. Thememorystoresthe
2023),anexistingpowerfulcodegenerationagent codegeneratedbytheagentitselfandretrievesthe
(§4.1),demonstratingtheeffectivenessofourap- latestcodetobeinputtotheLLMalongwiththe
proachingeneratingandmodifyingcode. Further- unittestfeedbackduringcodemodification. Ifan
more,throughadetailedanalysisoftheexperimen- agenthastheseminimalspecifications,itispossi-bletouseanoff-the-shelfagents(e.g.,Reflexion) theirMotheragent,theycontributetothecreation
as a Child agent. We deliberately use a simple ofamoreoptimizedandlargecodebase.
agenttoverifytheeffectivenessofSoAinasimple
3.2 MotherAgent
setup.
TheMotherisanagentthatgeneratesnewagents
CodeGeneration ThemainroleofChildagents
(Mother or Child). Similar to Child agents, the
istogeneratefunctionsthatmeetthespecifications
Mother agent independently implements the spe-
basedonthegivenfunction’sdocstrings. Asshown
cificPythonfunctionbasedonitsgivendocstrings.
in Figure 2, the agent follows the instructions to
The Mother has memory, code generation capa-
generate the rest of the function and complete it.
bilities,andself-debuggingfunctions,assameas
Thecompletedfunctionimplementationisstored
Child agents. The unique feature of the Mother
inmemory,andtheunittestsforthefunctionare
agentisitsabilitytogeneratemultipleChildagents
alsostoredastheyformthebasisforfuturecode
accordingtothecomplexityoftheproblemanddel-
modifications.
egatepartsoftheimplementationtotheseagents.
CodeModification: EmpoweringChildAgents ThisstructureallowstheMotheragenttofocuson
withSelf-OrganizationandAdaptability One implementingabstractprocesses,whiletheChild
of the most remarkable aspects of agents in the agentsgeneratedbytheMotheragentconcentrate
SoA framework is their ability to autonomously on implementing concrete processes. This divi-
improve their code based on the state of nearby sion of labor enhances the overall efficiency and
agents . This process sets SoA apart from tradi- flexibilityoftheSoAframework.
tionalagentapproachesandshowcasesthepower
Code Generation We explain the code genera-
of self-organization in code modification. While
tionprocessbytheMotheragentusingtheimple-
existingagentslikeReflexion(Shinnetal.,2023)
mentation example of the is_sum_of_odds_ten
relysolelyontheresultsofunittests,Childagents
function shown in Figure 2. The starting point is
inSoAgobeyondthislimitationbyindependently
thefunction’sdocstringsandunittests,whichare
observingthestateoftheirmotheragent,suchas
memorizedforreferenceinthelaterself-debugging
differencesinmodificationsandfeedback. Bygath-
phase. The first task of the Mother agent is to
ering this invaluable information from their sur-
generate a skeleton of the implementation from
roundingenvironment,Childagentscanadapttheir
thegivendocstrings,includingsubfunctionssuch
behaviorandmakemoreinformeddecisionsabout
asget_odd_numberstoextractoddnumbersand
code modification, even without explicit instruc-
sum_of_numberstocalculatetheirsum. Thenum-
tions. The modifications and feedback generated
ber and types of these subfunctions are automati-
bytheMotheragentserveasanimportantsource
cally determined by the LLM based on the com-
of information for the Child agents. Armed with
plexityoftheproblem.
these insights, Child agents can more effectively
It is important to note that these subfunctions
modify their own code, contributing to the over-
areunimplemented,andtheMotheragentdoesnot
all improvement of the codebase in a way that is
directlyimplementthem. Instead,itdelegatesthe
bothefficientandadaptive. Figure3illustratesthis
implementationofthesubfunctionstootheragents,
process, which begins with the execution of unit
allowingtheMotheragenttofocusongenerating
testsandtheretrievalofthelatestimplementation
theskeletonandstreamlineitsowncodegeneration
frommemory. TheChildagentthenharnessesthe
process. Afterthedocstringsandunittestsforthe
power of the LLM to create a code modification
subfunctions are generated, they are assigned to
proposal,seamlesslycombiningtheinformationob-
newlyinitializedagentsforimplementation. These
servedfromtheMotheragentwiththetestresults
agents proceed with the implementation of their
and the latest implementation details. By storing
respective functions without looking at the inter-
the modified code in memory, Child agents cre-
nalsoftheis_sum_of_odds_tenfunctionimple-
ateafeedbackloopthatcontinuouslyrefinesand
mentedbytheMotheragent. Sinceagentswithin
improvesthecodebaseovertime. Thisiterativepro-
the same Mother can work asynchronously, the
cess,drivenbytheprinciplesofself-organization
overallcodegenerationprocessisstreamlined.
and adaptability, enables SoA to tackle complex
codemodificationtaskswithefficiencyandeffec- CodeModification TheMother’scodemodifica-
tiveness. As Child agents work in harmony with tionisalmostthesameastheChild’scodemodifi-Child Mother
Docstrings Unit test Docstrings Unit test
def get_odd_numbers(lst): def is_sum_of_odds_ten(lst):
''' ‘’’
E fx rt or ma c at s g it vh ee n o ld id s tn u om fb e nr us m b ers. assert get_odd_numbers([1,2,3]) == [1, 3] C oh de dc k ns u mi bf e rs su m i so f 1 0 assert is_sum_of_odds_ten([1,9]) == True
‘’' ’’’
pass pass
Memory Memory
LLM LLM
Unit test Unit test
STEP1: STEP1:
Generate the code Generate the skeleton
Code Code
def get_odd_numbers(lst): def is_sum_of_odds_ten(lst):
''' ‘’'Checks if sum of odd numbers is 10
Extracts the odd numbers from a given ’’’
list of numbers. odd_numbers = get_odd_numbers(lst)
‘''
o d d _ n u m b e r s = [ n i ff o nr %n 2i n ! =l s 0t ] STEP2: Update memory sum_odds = sum_numbers(odd_numbers) STEP2: Update memory
return odd_numbers return “Yes” if sum_odds == 10 else “No”
LLM
STEP3: Generate signature and unit tests
def get_odd_numbers(lst): def sum_numbers(lst):
''' '''
Extracts the odd numbers. Calculates the sum of numbers.
‘’' ‘’’
pass pass
assert get_odd_numbers([1,2,3]) == [1, 3] assert sum_numbers([1,3]) == 4
child or mother child or mother
Figure2: Overviewofcodegeneration. ChildagentsgenerateexecutablePythonfunctionfromagivendocstring.
TheMotheragentgeneratestheskeletonofthefunction. TheMotherspawnsanewinitializedagent(Childor
Mother)anddelegatesunimplementedfunctions.
cation(Figure3). Itobservesinformationfromthe Algorithm1intheappendix.
upperMotherandusesittomodifythefunctions
CodeGeneration Thecodegenerationprocess
itisresponsiblefor. Theonlydifferenceisthatthe
in theSoA frameworkbeginswith the function’s
feedbackitgeneratesandthecodebeforeandafter
docstringsandunittests. Intheinitialstage,there
modificationareusedbylower-levelagents(Child
isonlyoneinitializedMotheragent,whichisthe
orMother).
rootofthetreestructure. Basedontheinputdoc-
3.3 Self-organizedAgentProcess strings and unit tests, it generates docstrings and
unit tests for subtasks and passes them to other
The Self-organized Agent (SoA) framework is a
agentsitgenerates(see§3.2). Ifthetreestructure
distributedframeworkinwhichmultipleagents(in-
reachesapredetermineddepth,thetasksarepassed
cludingMotheragentsandChildagents)repeatedly
toChildagents;otherwise,theyarepassedtonewly
generate and modify functions. The core of this
generated Mother agents. By repeatedly prolifer-
frameworkliesintheprincipleofself-organization,
ating and increasing the number of agents until
whereeachagentfunctionsindependentlywithout
thelastagent,itispossibletogeneratelarge-scale
the need to directly observe the entire codebase.
codewhilekeepingtheamountofcodemanaged
The hierarchical combination of Mother agents
byindividualagentsconstant.
and Child agents forms an agent network that ef-
fectivelyconstructsasinglelarge-scalecodebase. Code Modification Once code generation is
In this hierarchical structure, Mother agents de- complete,theprocesstransitionstothecodemod-
composecomplexproblemsintomoremanageable ification phase. First, the implementations of all
smallerproblemsbydividingtasksanddelegating agentsarecombinedtocreatethefinalimplementa-
themtotheagentstheyhavegenerated. Although tion. Thisfinalimplementationisevaluatedusing
each agent is independent, the agents as a whole theunittestsprovidedtotherootMother,andfeed-
canworkefficientlytowardstheimplementationof backisgeneratedfromtheresults. Sincethereare
asinglefunction. Despitethefactthattheamount noagentshigherthanthisrootMother,information
ofcodeeachagentgenerates,modifies,andman- from higher-level agents as shown in Figure 3 is
agesisalwayssmall,thenumberofagentsscales, notused. Themodificationprocessstartsbasedon
allowing the amount of code generated to be in- thisfeedbackandpropagatesinformationfromthe
creased indefinitely according to the difficulty of rootMotheragenttotheChildagents. Eachagent
theproblem. Detailedalgorithmsarepresentedin updatesitsimplementationbasedonthereceivedUpper Mother Baselines WecompareSoAwithseveralstate-of-
Agent state the-artcodegenerationmethodsincludingAlpha-
(Self-feedbacks, New code, Old code)
Code(Lietal.,2022),Incoder(Friedetal.,2023),
Mother Codex(Chenetal.,2021),CoT(Weietal.,2022),
and Gemini Pro (Anil et al., 2023). Additionally,
S uT pE pP e1 r: aO gb es ne trve rT ee ss ut
l t
Memo Ur ny
it test
we evaluate the performance of various GPT-3.5-
LLM basedagents,suchasChatGPT,Self-Edit(Zhang
STEP2:
Code et al., 2023), and Reflexion (Shinn et al., 2023).
Generate self-feedbacks
(1) Return a Boolean value. Thesebaselinesarechosentorepresentadiverse
(2) In 'get_odd_numbers', Old code
ignore negative numbers. range of approaches, including single-agent and
STEP3: LLM multi-agentsystems,aswellasthosewithandwith-
Fix code
outself-debuggingcapabilities.
def is_sum_of_odds_ten(lst):
‘’'Checks if sum of odd numbers is 10 STEP4:
’ o’ d’ d _numbers = get_odd_numbers(lst) Update
sum_odds = sum_numbers(odd_numbers) memory AgentConfiguration Toevaluatetheeffective-
return True if sum_odds == 10 else False ness of the SoA framework, we selected the Re-
flexion agent as a baseline. Reflexion iteratively
Agent state
modifies code based on the given docstrings and
Child To other children/mothers
automaticallygeneratedunittestsuntilitreaches
the maximum number of iterations or passes the
STEP1: Test Memory
Observe mother agent result Unit test unittests. ThemaindifferencebetweenReflexion
LLM
STEP2: andSoAisthatReflexioniscomposedofasingle
Code
Generate self-feedbacks
agent, while SoA is composed of self-organized
(1) Ignore numbers that are
negative. Old code STEP4: multipleagents. IntheSoAconfiguration,weset
STEP3: Update
Fix code LLM memory the maximum number of iterations for the learn-
def get_odd_numbers(lst): ing loop to 8 and the maximum tree depth to 2.
'''
Extracts the odd numbers from a given list of numbers. Additionally, following (Shinn et al., 2023), we
‘''
odd_numbers = [n for n in lst if n % 2 != 0 and n > 0]
return odd_numbers providedafew-shottrajectorytotheLLM.
Data and Tasks To evaluate the performance
Figure 3: Overview of code modification. Agents
(Mother/Child)observethestateofMother(feedback, of automatic code generation, we used the Hu-
oldcode,andupdatedcode)andusethisinformation manEval (Chen et al., 2021) benchmark. Hu-
to improve the functions for which they are responsi- manEvalisasetthatincludesdiverseprogramming
ble. Thestateoftheupperagentisusedtomodifycode
problemsdesignedtomeasurethefunctionalcor-
byloweragentswithinthehierarchy. Thisstatepropa-
rectness of generated code. We used the Python
gationpromotescollaborationandinformationsharing
languagesetforevaluationandfollowedtheevalua-
throughoutthehierarchy,enablingefficientcodemodi-
tionmethodologyofReflexion(Shinnetal.,2023).
fication.
Inthisprocess,multipletestcasesarecreatedfor
eachgeneratedcode,andntestcasesarerandomly
feedback,generatesnewfeedback,andtransmitsit selectedtoconstructatestsuite. Thistestsuiteis
tolower-levelagents(see§3.2). Finally,theChild usedtoverifywhetherthegeneratedcodefunctions
agentsupdatetheirownimplementations,andthe correctly. We set 6 unit tests for Reflexion and 1
process terminates (see §3.1). This series of pro- unittestforSoA.
cessesisrepeateduntilapredeterminedmaximum
numberofiterationsisreached. 4.1 MainResults
Table1comparesthePass@1accuracyofthepro-
4 Experiments
posed method and the baseline. Comparing SoA
withReflexion,astrongbaseline,SoAoutperforms
LLMSelection WeusedGPT3.5-turbo3forcode
Reflexionby5%inPass@1. Consideringthateach
generationandfeedbackgeneration.4
agent in SoA does not see the entire code, this is
a surprising result. This result suggests that self-
3gpt3.5-turbo-1106
organizedagentscangeneratecodethatfunctions
4GPT-4wasnotselectedduetothehighexperimentalcost
required. well as a whole without needing to oversee theDocstrings
def func2 def func5
def function1(x) Agent Skeleton of Code Unit test
Unit test
“””
Docstrings def function1(x) def func5
“”” 1. Generate Unit test
LLM ……
# Generate here
y = function2(x) def func5
Memory def func3 Unit test
def function1(x) 2. Memorize ……
Unit test
z = function3(y) def func5
Unit test
……
3. Self-debugging
Unit test return function4(z) def func5
Unit test def func4 Unit test
assert function(1) == 2
Unit test def func5
Unit test
Figure4: OverviewoftheSoAframework. MotheragentsandChildagentshierarchicallyconstructanetworkand
performfunctiongenerationandmodification. MotheragentsdelegatetaskstootherMotheragentsorChildagents,
andeachagentindependentlyexecutestaskswhileeffectivelyimplementingasinglefunctionasawhole.
Method SD SO Pass@1 allfunctions. InthecontextofHumanEval,which
AlphaCode (Lietal.,2022) ✘ ✘ 17.1 requires the implementation of a single function,
Incoder (Friedetal.,2023) ✘ ✘ 15.2 SoA’scodeamountiscalculatedbysummingthe
Codex (Chenetal.,2021) ✘ ✘ 47.0
code generated by each agent, while Reflexion’s
GeminiPro (Aniletal.,2023) ✘ ✘ 67.7
code amount is based on a single function. The
CoT(Weietal.,2022) ✘ ✘ 44.6
codeamountperfunctioninSoAreferstothecode
ChatGPT ✘ ✘ 57.3
GPT-3.5 Self-Edit(Zhangetal.,2023) ✔ ✘ 62.2 generatedbyeachindividualagent,whereasinRe-
Reflexion(Shinnetal.,2023) ✔ ✘ 66.5 flexion, it is equivalent to the code amount of a
SoA(ours) ✔ ✔ 71.4
singlefunction. Theresultsunequivocallydemon-
strateSoA’ssuperiorityoverReflexionintermsof
Table1: ResultsofSoAandbaselinesonHumanEval.
ThescoreofChatGPTistakenfromDongetal.(2023). the number of tokens per final code and the av-
SDindicateswhethertheagentusesself-debuggingwith erage number of characters per function. What
unittests,whileSOdenoteswhethertheagentemploys is remarkable is that despite each agent in SoA
self-organizedmulti-agentcollaboration. handlingsignificantlyfewertokens/characterscom-
paredtothesingleagentinReflexion,theoverall
output generated by SoA is substantially greater.
entire code, by independently implementing the
Thisfindingunderscorestheexceptionalscalabil-
functionsassignedtothem.
ityofSoA,indicatingitsabilitytohandleincreas-
ingly complex tasks by seamlessly adding more
4.2 Analysis
agents to the system. Our results suggest that by
One of the most critical aspects of our study is
increasingthedepthoftheagenthierarchyandin-
theefficiencyoftheself-organizedmulti-agentap-
troducingmoreMotheragents,SoAcangenerate
proachinlarge-scalecodegeneration. Toshowcase
even larger-scale code by efficiently distributing
thesuperiorperformanceofSoA,weconducteda
theworkloadamongmultipleagents. Asthetree
comprehensivecomparativeanalysisbetweenRe-
structure becomes deeper, the system exhibits an
flexion,astate-of-the-artsingle-agentsystem,and
infinitescalingpotential,enablingthegeneration
our proposed multi-agent system. Using the Hu-
ofincreasinglycomplexandextensivecodebases
manEval benchmark, we meticulously examined
whileensuringthateachagenthandlesamanage-
the overall scale of the code generated by both
ableportionofthecode. Eachagentcanmaintain
systems and the amount of code each agent inde-
amanageableamountofcodewhiletheoretically
pendentlygeneratedandmemorized. Toensurea
allowing for an indefinite increase in the overall
faircomparison,weremovedcommentsanddoc-
codegenerationcapacity.
stringsfromtheHumanEvalresultsandfocusedon
thenumberofcharactersandtokensofpurecode. ThisdistributedapproachempowersSoAtosig-
Figure5presentsavisualizationoftheaverage nificantlyscaleupitsabilitytotacklelarge-scale
amount of code generated by SoA and Reflexion and complex coding tasks with remarkable effi-
from the perspective of individual functions and ciency and high quality, far surpassing the limi-Single agent (Reflexion) Multi agent (SoA) Multi-Agent Collaboration for Software De-
Single agent (Reflexion) Single agent (Reflexion) velopment Inrecentyears,severalmulti-agent-
Multi agents (SoA) Multi agents (SoA)
based approaches have emerged as promising
100 60
solutions for software development, such as
75 40
MetaGPT(Hongetal.,2023),ChatDev(Qianetal.,
50
20 2023),Self-collaboration(Dongetal.,2023),and
25
AgentCoder(Huangetal.,2023). Thesemethods
0 0
PEenrt irae fcinoadle cboadsee PerF aun fcutniocntion
typicallypersonifyagentsandassignthemspecific
(all agents) (agent)
Single agent (Reflexion) Single agent (Reflexion) namesoroccupationalroles,suchasprogrammers,
Multi agents (SoA) Multi agents (SoA)
project managers, or QA engineers, to allocate
400 200
tasks. While this approach has shown promise,
300 150
ourmethodtakesadifferentandmoreflexibleap-
200 100
proach. Instead of assigning fixed occupational
100 50
roles, we subdivide agent capabilities based on
0 0
PEenrt irae fcinoadle cboadsee PerF uan fcutniocntion
codefunctionality,allowingeachagenttodemon-
(all agents) (agent)
strateitsexpertisewithoutbeingconstrainedbypre-
Figure5: Comparisonofcodegenerationamountbe-
definedroles. Thisfine-grainedtaskallocationen-
tweenSoA(mulit-agent)andReflexion(singleagent).
ablesmoreflexibleproblem-solvingandadaptation
tothecomplexityofthesoftwaredevelopmentpro-
cess. Moreover,byincorporatingtheconceptsof
tations encountered by single-agent systems like
self-organizationandself-proliferation,ouragents
Reflexion, where a sole agent is responsible for
candynamicallyscaleuptheoverallcodevolume
managingandgeneratingtheentirecodebase.
basedonthedifficultyoftheproblemathand,pro-
vidingahighlyadaptableandefficientframework
5 RelatedWork forlarge-scalecodegenerationandmodification.
Macrovs. MicroPerspectives Whilebothmulti-
LLM Agents Recent advancements in LLM
agent-basedmethods(Hongetal.,2023;Qianetal.,
agents, such as ReAct (Yao et al., 2023b), Re-
2023;Dongetal.,2023;Huangetal.,2023)andour
flexion (Shinn et al., 2023), Toolformer (Schick
proposedSoAframeworksharethecommongoal
etal.,2023),andSelf-Refine(Madaanetal.,2023),
ofautomatingsoftwaredevelopment,theyaddress
haveprimarilyfocusedonsingle-agentapproaches,
differenttechnicalaspectsoftheprocess. Existing
where one agent is responsible for both genera-
multi-agent methods primarily focus on optimiz-
tion and modification tasks. Among these, Re-
ingthemacrostructureofsoftwaredevelopment,
flexion(Shinnetal.,2023)hasgainedsignificant
such as project management and task allocation.
attentioninthefieldofcodegenerationduetoits
In contrast, our method takes a more micro-level
outstandingperformance. However, despitetheir
perspective, focusing on the elemental technolo-
strengths, these single-agent approaches face in-
gies of code generation and modification. These
herentlimitationswhenitcomestogeneratingand
approaches are not mutually exclusive but rather
modifyinglarge-scalecodebases. Toaddressthese
complementary,offeringamorecomprehensiveso-
limitationsandpushtheboundariesofwhatispos-
lutiontothechallengesfacedinautomaticsoftware
siblewithLLMagents,weproposeSoA,anovel
development. Bycombiningthestrengthsofboth
multi-agent framework that harnesses the power
macroandmicro-levelapproaches,wecancreate
ofself-organizationandcollaboration. Whilewe
apowerfulandholisticframeworkthatefficiently
intentionally adopted simple agents for SoA in
handlesthecomplexitiesoflarge-scalecodegener-
thiswork,ourframeworkisflexibleenoughtoin-
ationandmodification.
corporate more sophisticated and powerful meth-
ods (Zhong et al., 2024; Zhou et al., 2023) and Prompt Engineering Tree-of-Thought
other state-of-the-art LLMs 5, further enhancing (ToT) (Yao et al., 2023a) and Skeleton of
its potential for large-scale code generation and Thought (SoT) (Ning et al., 2023) are prompt
modification. engineering techniques that utilize tree-like
structures. ToTrepresentsreasoningstepsasnodes
5https://claude.ai/ to explore correct reasoning paths, while SoT
snektonTu
odce
rteatrceanraehGc
#e
g.garveAvA
tnusorce
rtectacraarahhCc
.eggvaArevA
tnuoc
retcarahc
egarevA
tnuoc
retcarahc
egarevA
snekoT
detareneG
#
.gvA
sretcarahC
.gvAgeneratesaskeletonoftheanswerandcompletes researchanddevelopmentinthefieldofautomatic
the contents in parallel to decrease generation softwaredevelopment.
latency. Incontrast,SoAusesatreestructurewith
agents as nodes, focusing on their collaboration
References
andself-organizationtogenerateandmodifycode
efficiently. Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-
Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan
6 Conclusion Schalkwyk,AndrewM.Dai,AnjaHauth,KatieMil-
lican, David Silver, Slav Petrov, Melvin Johnson,
Ioannis Antonoglou, Julian Schrittwieser, Amelia
Inthiswork,weintroducedSelf-organizedAgents
Glaese, Jilin Chen, Emily Pitler, Timothy P. Lilli-
(SoA),anovelmulti-agentframeworkforefficient
crap,AngelikiLazaridou,OrhanFirat,JamesMolloy,
and scalable automatic code generation and op- Michael Isard, Paul Ronald Barham, Tom Henni-
timization using large language models (LLMs). gan,BenjaminLee,FabioViola,MalcolmReynolds,
YuanzhongXu,RyanDoherty,EliCollins,Clemens
SoA addresses the limitations of single-agent ap-
Meyer, Eliza Rutherford, Erica Moreira, Kareem
proaches in handling large-scale, complex code-
Ayoub, Megha Goel, George Tucker, Enrique Pi-
basesbyleveragingthepowerofself-organization queras,MaximKrikun,IainBarr,NikolaySavinov,
and distributed code generation. In SoA, self- IvoDanihelka,BeccaRoelofs,AnaïsWhite,Anders
Andreassen, Tamara von Glehn, Lakshman Yagati,
organizedagentsoperateindependentlytogenerate
MehranKazemi,LucasGonzalez,MishaKhalman,
andmodifycodecomponentswhileseamlesslycol-
JakubSygnowski,andetal.2023. Gemini: Afam-
laboratingtoconstructtheoverallcodebase. Akey ily of highly capable multimodal models. CoRR,
feature of our framework is the automatic multi- abs/2312.11805.
plicationofagentsbasedonproblemcomplexity,
WRossAshby.1947. Principlesoftheself-organizing
allowingfordynamicscalabilityandenablingthe
dynamicsystem. TheJournalofgeneralpsychology,
overallcodevolumetobeincreasedindefinitelyac- 37(2):125–128.
cordingtothenumberofagents,whiletheamount
TomB.Brown,BenjaminMann,NickRyder,Melanie
ofcodemanagedbyeachagentremainsconstant.
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
We evaluated SoA on the HumanEval bench- Neelakantan,PranavShyam,GirishSastry,Amanda
mark and demonstrated its superior performance Askell, Sandhini Agarwal, Ariel Herbert-Voss,
compared to Reflexion, a state-of-the-art single- Gretchen Krueger, Tom Henighan, Rewon Child,
Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,
agentsystem,withSoAachievinga5%improve-
ClemensWinter,ChristopherHesse,MarkChen,Eric
ment in terms of Pass@1 accuracy. Furthermore,
Sigler,MateuszLitwin,ScottGray,BenjaminChess,
our in-depth analysis revealed SoA’s remarkable Jack Clark, Christopher Berner, Sam McCandlish,
scalability, as each agent in SoA handles signifi- Alec Radford, Ilya Sutskever, and Dario Amodei.
2020. Languagemodelsarefew-shotlearners. InAd-
cantlylesscodecomparedtothesingle-agentbase-
vancesinNeuralInformationProcessingSystems33:
line,yettheoverallgeneratedcodeissubstantially
AnnualConferenceonNeuralInformationProcess-
greater. Theseresultshighlighttheeffectivenessof ing Systems 2020, NeurIPS 2020, December 6-12,
SoAingeneratingandoptimizinglarge-scalecode 2020,virtual.
efficientlyandwithhighquality.
MarkChen,JerryTworek,HeewooJun,QimingYuan,
However,itisessentialtoacknowledgethelimi- Henrique Pondé de Oliveira Pinto, Jared Kaplan,
tationsofthecurrentimplementationofSoA.The Harrison Edwards, Yuri Burda, Nicholas Joseph,
framework’sperformancemaybeaffectedbythe Greg Brockman, Alex Ray, Raul Puri, Gretchen
Krueger,MichaelPetrov,HeidyKhlaaf,GirishSas-
choice of LLM and the quality of the generated
try, Pamela Mishkin, Brooke Chan, Scott Gray,
unit tests. Additionally, SoA has been evaluated
NickRyder,MikhailPavlov,AletheaPower,Lukasz
onalimitedsetofprogrammingtasks,anditsef- Kaiser, Mohammad Bavarian, Clemens Winter,
fectivenessinhandlingmorecomplex,real-world Philippe Tillet, Felipe Petroski Such, Dave Cum-
mings, Matthias Plappert, Fotios Chantzis, Eliza-
software development projects remains to be in-
beth Barnes, Ariel Herbert-Voss, William Hebgen
vestigated. Furthermore, the communication and
Guss,AlexNichol,AlexPaino,NikolasTezak,Jie
collaboration mechanisms among agents in SoA Tang,IgorBabuschkin,SuchirBalaji,ShantanuJain,
canbefurtheroptimizedtoimproveefficiencyand William Saunders, Christopher Hesse, Andrew N.
Carr,JanLeike,JoshuaAchiam,VedantMisra,Evan
faulttolerance.
Morikawa, Alec Radford, Matthew Knight, Miles
Despite these limitations, we believe that the
Brundage,MiraMurati,KatieMayer,PeterWelinder,
SoAframeworkhassignificantpotentialforfuture BobMcGrew,DarioAmodei,SamMcCandlish,IlyaSutskever, and Wojciech Zaremba. 2021. Evaluat- Lago,ThomasHubert,PeterChoy,CypriendeMas-
inglargelanguagemodelstrainedoncode. CoRR, sond’Autume,IgorBabuschkin,XinyunChen,Po-
abs/2107.03374. Sen Huang, Johannes Welbl, Sven Gowal, Alexey
Cherepanov, James Molloy, Daniel J. Mankowitz,
YihongDong,XueJiang,ZhiJin,andGeLi.2023. Self- EsmeSutherlandRobson, PushmeetKohli, Nando
collaboration code generation via chatgpt. CoRR, deFreitas, KorayKavukcuoglu, andOriolVinyals.
abs/2304.07590. 2022. Competition-levelcodegenerationwithalpha-
code. CoRR,abs/2203.07814.
DanielFried,ArmenAghajanyan,JessyLin,SidaWang,
Eric Wallace, Freda Shi, Ruiqi Zhong, Scott Yih,
AmanMadaan, NiketTandon,PrakharGupta,Skyler
LukeZettlemoyer,andMikeLewis.2023. Incoder:
Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon,
Agenerativemodelforcodeinfillingandsynthesis.
Nouha Dziri, Shrimai Prabhumoye, Yiming Yang,
InTheEleventhInternationalConferenceonLearn-
Shashank Gupta, Bodhisattwa Prasad Majumder,
ing Representations, ICLR 2023, Kigali, Rwanda,
Katherine Hermann, Sean Welleck, Amir Yazdan-
May1-5,2023.OpenReview.net.
bakhsh, and Peter Clark. 2023. Self-refine: Itera-
Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng tiverefinementwithself-feedback. InAdvancesin
NeuralInformationProcessingSystems36: Annual
Cheng,JinlinWang,CeyaoZhang,ZiliWang,Steven
ConferenceonNeuralInformationProcessingSys-
KaShingYau,ZijuanLin,LiyangZhou,ChenyuRan,
tems2023, NeurIPS2023, NewOrleans, LA,USA,
Lingfeng Xiao, and Chenglin Wu. 2023. Metagpt:
Meta programming for multi-agent collaborative
December10-16,2023.
framework. CoRR,abs/2308.00352.
NiklasMuennighoff,QianLiu,ArmelZebaze,Qinkai
DongHuang,QingwenBu,JieM.Zhang,MichaelLuck, Zheng, Binyuan Hui, Terry Yue Zhuo, Swayam
and Heming Cui. 2023. Agentcoder: Multi-agent- Singh, Xiangru Tang, Leandro von Werra, and
basedcodegenerationwithiterativetestingandopti- ShayneLongpre.2023. Octopack: Instructiontuning
misation. CoRR,abs/2312.13010. codelargelanguagemodels. CoRR,abs/2308.07124.
Mosh Levy, Alon Jacoby, and Yoav Goldberg. 2024. XuefeiNing,ZinanLin,ZixuanZhou,HuazhongYang,
Sametask,moretokens:theimpactofinputlengthon and Yu Wang. 2023. Skeleton-of-thought: Large
thereasoningperformanceoflargelanguagemodels. language models can do parallel decoding. CoRR,
CoRR,abs/2402.14848. abs/2307.15337.
JiaqiLi,MengmengWang,ZilongZheng,andMuhan
OpenAI. 2023. GPT-4 technical report. CoRR,
Zhang. 2023a. Loogle: Can long-context lan-
abs/2303.08774.
guage models understand long contexts? CoRR,
abs/2311.04939.
Chen Qian, Xin Cong, Cheng Yang, Weize Chen,
Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas YushengSu,JuyuanXu,ZhiyuanLiu,andMaosong
Muennighoff, Denis Kocetkov, Chenghao Mou, Sun.2023. Communicativeagentsforsoftwarede-
Marc Marone, Christopher Akiki, Jia Li, Jenny velopment. CoRR,abs/2307.07924.
Chim,QianLiu,EvgeniiZheltonozhskii,TerryYue
Zhuo, Thomas Wang, Olivier Dehaene, Mishig TimoSchick,JaneDwivedi-Yu,RobertoDessì,Roberta
Davaadorj,JoelLamy-Poirier,JoãoMonteiro,Oleh Raileanu,MariaLomeli,EricHambro,LukeZettle-
Shliazhko,NicolasGontier,NicholasMeade,Armel moyer,NicolaCancedda,andThomasScialom.2023.
Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Toolformer: Languagemodelscanteachthemselves
JianZhu,BenjaminLipkin,MuhtashamOblokulov, tousetools. InAdvancesinNeuralInformationPro-
cessingSystems36: AnnualConferenceonNeural
Zhiruo Wang, Rudra Murthy V, Jason Stillerman,
InformationProcessingSystems2023,NeurIPS2023,
Siva Sankalp Patel, Dmitry Abulkhanov, Marco
Zocca,MananDey,ZhihanZhang,NourMoustafa-
NewOrleans,LA,USA,December10-16,2023.
Fahmy,UrvashiBhattacharyya,WenhaoYu,Swayam
Singh,SashaLuccioni,PauloVillegas,MaximKu- Uri Shaham, Maor Ivgi, Avia Efrat, Jonathan Berant,
nakov,FedorZhdanov,ManuelRomero,TonyLee, and Omer Levy. 2023. Zeroscrolls: A zero-shot
NadavTimor,JenniferDing,ClaireSchlesinger,Hai- benchmark for long text understanding. In Find-
leySchoelkopf,JanEbert,TriDao,MayankMishra, ingsoftheAssociationforComputationalLinguis-
Alex Gu, Jennifer Robinson, Carolyn Jane Ander- tics:EMNLP2023,Singapore,December6-10,2023,
son,BrendanDolan-Gavitt,DanishContractor,Siva pages 7977–7989. Association for Computational
Reddy,DanielFried,DzmitryBahdanau,YacineJer- Linguistics.
nite,CarlosMuñozFerrandis,SeanHughes,Thomas
Wolf, Arjun Guha, Leandro von Werra, and Harm Noah Shinn, Federico Cassano, Ashwin Gopinath,
deVries.2023b. Starcoder: maythesourcebewith Karthik Narasimhan, and Shunyu Yao. 2023. Re-
you! CoRR,abs/2305.06161. flexion: languageagentswithverbalreinforcement
learning. In Advances in Neural Information Pro-
YujiaLi,DavidH.Choi,JunyoungChung,NateKush- cessingSystems36: AnnualConferenceonNeural
man, JulianSchrittwieser, RémiLeblond, TomEc- InformationProcessingSystems2023,NeurIPS2023,
cles, James Keeling, Felix Gimeno, Agustin Dal NewOrleans,LA,USA,December10-16,2023.Hugo Touvron, Louis Martin, Kevin Stone, Peter Al- A Pseudocode
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti
Bhosale,DanBikel,LukasBlecher,CristianCanton-
Ferrer,MoyaChen,GuillemCucurull,DavidEsiobu,
JudeFernandes,JeremyFu,WenyinFu,BrianFuller,
CynthiaGao,VedanujGoswami,NamanGoyal,An-
thonyHartshorn,SagharHosseini,RuiHou,Hakan
Inan,MarcinKardas,ViktorKerkez,MadianKhabsa,
IsabelKloumann,ArtemKorenev,PunitSinghKoura,
Marie-AnneLachaux,ThibautLavril,JenyaLee,Di-
anaLiskovich,YinghaiLu,YuningMao,XavierMar-
tinet,TodorMihaylov,PushkarMishra,IgorMoly-
bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-
stein,RashiRungta,KalyanSaladi,AlanSchelten,
Ruan Silva, Eric Michael Smith, Ranjan Subrama-
nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-
lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,
ZhengYan,IliyanZarov,YuchenZhang,AngelaFan,
Melanie Kambadur, Sharan Narang, Aurélien Ro-
driguez,RobertStojnic,SergeyEdunov,andThomas
Scialom.2023. Llama2: Openfoundationandfine-
tunedchatmodels. CoRR,abs/2307.09288.
JasonWei,XuezhiWang,DaleSchuurmans,Maarten
Bosma,BrianIchter,FeiXia,EdH.Chi,QuocV.Le,
andDennyZhou.2022. Chain-of-thoughtprompting
elicits reasoning in large language models. In Ad-
vancesinNeuralInformationProcessingSystems35:
AnnualConferenceonNeuralInformationProcess-
ingSystems2022,NeurIPS2022,NewOrleans,LA,
USA,November28-December9,2022.
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran,
TomGriffiths,YuanCao,andKarthikNarasimhan.
2023a. Treeofthoughts: Deliberateproblemsolving
withlargelanguagemodels. InAdvancesinNeural
InformationProcessingSystems36: AnnualConfer-
enceonNeuralInformationProcessingSystems2023,
NeurIPS2023,NewOrleans,LA,USA,December10
-16,2023.
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak
Shafran, Karthik R. Narasimhan, and Yuan Cao.
2023b. React: Synergizing reasoning and acting
inlanguagemodels. InTheEleventhInternational
ConferenceonLearningRepresentations,ICLR2023,
Kigali,Rwanda,May1-5,2023.OpenReview.net.
KechiZhang,ZhuoLi,JiaLi,GeLi,andZhiJin.2023.
Self-edit: Fault-awarecodeeditorforcodegenera-
tion. InProceedingsofthe61stAnnualMeetingof
theAssociationforComputationalLinguistics(Vol-
ume1: LongPapers),ACL2023,Toronto,Canada,
July 9-14, 2023, pages 769–787. Association for
ComputationalLinguistics.
Lily Zhong, Zilong Wang, and Jingbo Shang. 2024.
LDB: A large language model debugger via ver-
ifying runtime execution step-by-step. CoRR,
abs/2402.16906.
Andy Zhou, Kai Yan, Michal Shlapentokh-Rothman,
HaohanWang,andYu-XiongWang.2023. Language
agenttreesearchunifiesreasoningactingandplan-
ninginlanguagemodels. CoRR,abs/2310.04406.Algorithm1GenerateCodewithSelf-organizedAgentFramework
Input: docstrings: Docstringsforthefunction,unit_tests: Listofunittests,max_depth: Maximumdepthoftheagent
hierarchy,max_iterations:Maximumnumberofcodemodificationiterations
Output: Thefinalgeneratedcode
1:
2: InitializetherootMotheragentwithdocstringsandunit_tests
3:
4: functionGENERATEAGENT(agent,depth,subtask_docstrings,subtask_unit_tests)
5: ifdepth−1=max_depththen
6: next_agent←newChildAgent
7: else
8: next_agent←newMotherAgent
9: endif
10: Assignsubtask_docstringsandunit_teststonext_agent
11: GENERATE(next_agent,depth+1)
12: endfunction
13:
14: functionGENERATE(agent,depth)
15: ifdepth=1then ▷RootMother
16: skeleton←Generateskeletonfromagent.docstringsandagent.unit ests
t
17: agent.code←skeleton
18: foreachsubtask_docstrings,subtask_unit_testsinsubtasksdo
19: GENERATEAGENT(agent,depth,subtask_docstrings,subtask_unit_tests)
20: endfor
21: elseifdepth=max_depththen ▷Child
22: Generatecodeforagent.subtask_docstringsandagent.subtask_unit_tests
23: agent.code←generatedcode
24: else ▷Mother
25: Generatecodeforagent.subtask_docstringsandagent.subtask_unit_tests
26: agent.code←generatedcode
27: foreachsubtask_docstrings,subtask_unit_testsinsubtasksdo
28: GENERATEAGENT(agent,depth,subtask_docstrings,subtask_unit_tests)
29: endfor
30: endif
31: endfunction
32:
33: functionMODIFY(agent,test_result,upper_agent_observation)
34: Generatefeedbackforagentbasedontest_resultandupper_agent_observation
35: Updateagent’scodebasedonfeedback
36: foreachsubagentinagent.subagentsdo
37: Evaluatesubagent.codeusingsubagent.unit_teststogetsubagent_test_result
38: MODIFY(subagent,subagent_test_result,feedbackandcodechanges)
39: endfor
40: endfunction
41:
42: StartcodegenerationwithGENERATE(root_mother,1)
43:
44: foreachiterationinmax_iterationsdo
45: Combineimplementationsfromallagentstocreatefinal_implementation
46: Evaluatefinal_implementationusingunit_teststogettest_result
47: Modifythecodestartingfromroot_motherwithMODIFY(root_mother,test_result,None)
48: endfor
49:
50: returnThefinalimplementationcombinedfromallagents