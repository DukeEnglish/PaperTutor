Guarantees of confidentiality via
Hammersley-Chapman-Robbins bounds
Kamalika Chaudhuri1, Chuan Guo1, Laurens van der Maaten1, Saeed Mahloujifar1,
Mark Tygert1
1Fundamental Artificial Intelligence Research at Meta
Protecting privacy during inference with deep neural networks is possible by adding noise to the ac-
tivationsinthelastlayerspriortothefinalclassifiersorothertask-specificlayers. Theactivationsin
such layers are known as “features” (or, less commonly, as “embeddings” or “feature embeddings”).
Theaddednoisehelpspreventreconstructionoftheinputsfromthenoisyfeatures. Lowerbounding
the variance of every possible unbiased estimator of the inputs quantifies the confidentiality arising
from such added noise. Convenient, computationally tractable bounds are available from classic in-
equalitiesofHammersleyandofChapmanandRobbins—theHCRbounds. Numericalexperiments
indicate that the HCR bounds are on the precipice of being effectual for small neural nets with the
data sets, “MNIST” and “CIFAR-10,” which contain 10 classes each for image classification. The
HCR bounds appear to be insufficient on their own to guarantee confidentiality of the inputs to
inference with standard deep neural nets, “ResNet-18” and “Swin-T,” pre-trained on the data set,
“ImageNet-1000,” which contains 1000 classes. Supplementing the addition of noise to features with
other methods for providing confidentiality may be warranted in the case of ImageNet. In all cases,
theresultsreportedherelimitconsiderationtoamountsofaddednoisethatincurlittledegradationin
theaccuracyofclassificationfromthenoisyfeatures. Thus,theaddednoiseenhancesconfidentiality
without much reduction in the accuracy on the task of image classification.
Date: April 4, 2024
Correspondence: Mark Tygert at mark@tygert.com
1 Introduction
The Hammersley-Chapman-Robbins(HCR) bounds of Hammersley(1950) andChapman &Robbins (1951)
provide easily interpretable, tight data-driven guarantees on confidentiality. The interpretation is especially
simple and direct, lower bounding the variance of any estimator for reconstructing inputs to inference with
neural networks. Moreover, computing the bounds is efficient and straightforward. Confidentiality stems
from suitable addition of noise; the HCR bounds quantify the effect of the added noise on the minimum
possible variance of any estimator.
Thispaperstudiestheprivacypreservationarisingfromaddingnoisetotheactivationsinthefinallayers
of deep neural networks, that is, to the layers immediately preceding the classifiers used during supervised
training of the nets and used for classification during inference. The most common terminology for these
activations is “features” (or vectors of features). Less common synonyms are “feature embeddings” or
simply “embeddings.” Adding noise is also known as “dithering.” Dithering features is a canonical method
for limiting the quality of possible reconstructions of the inputs that generated the noiseless features.
The present paper omits consideration of adding noise directly to the data or for proxies to that process,
such as DP-SGD of Abadi et al. (2016), since quantifying their privacy preservation in terms of the variance
minimized over all possible estimators is trivial, given directly by the amount of noise added.
A method for quantifying privacy that is closely related to the HCR bounds is to use Fisher information
and the Cram´er-Rao bound, as advanced by Hannun et al. (2021) and others. The Cram´er-Rao bound is
most useful when a quadratic form specified by the Fisher information matrix is a good approximation to
the expected loss (the risk function) near the parameters at which the Fisher information is evaluated. In
contrast,theHCRboundsusedbelowaretypicallytightwhetherornotaquadraticformspecifiedbyFisher
1
4202
rpA
3
]GL.sc[
1v66820.4042:viXrainformationevaluatedatasinglesettingofparametersisagoodapproximation. Furthermore,evaluatingthe
Fisher information forcomplicated models in machine learning such as deep neural networks can be difficult
or costly at scale. The approach proposed below avoids most of the difficulties and is computationally
tractable. In fact, the HCR bounds always exist, whereas the Cram´er-Rao bounds exist only when the loss
is sufficiently smooth.
The present paper could be viewed as providing an alternative to the Cram´er-Rao bounds that is more
practical. Indeed, the Cram´er-Rao bound is a certain limit of an HCR bound. Subsection 2.4 below details
the connection, a connection first made in the original works of Hammersley (1950) and of Chapman &
Robbins (1951).
Unfortunately, the experimental results reported below indicate that the HCR bounds are weak for one
of the data sets tested, at least with some standard neural nets for image classification (image classification
is also known as “image recognition”). Section 4 below concludes that dithering features and leveraging the
associatedHCRboundswouldbemostusefulinconjunctionwithcruder,brute-forcemethodsforenhancing
confidentialityoftheinputstoinference(suchaslimitingthesizesofthevectorsoffeaturesbeingrevealed).
Earlierwork,notablythethesisofAlisic(2021),alsoappliesHCRboundstoquantifyprivacy,comparing
favorably with the differential privacy of Dwork & Roth (2014). The focus of Alisic (2021) and the subset
of the thesis reported by Alisic et al. (2020) is on confidentiality in the measurement of dynamical systems
— quite different from the setting considered in the present paper — yet the results are complementary and
consonant with those of the present paper.
Theremainderofthepresentpaperhasthefollowingstructure: Section2developstheoryandalgorithms
basedonHCRbounds. Section3reportsnumericalexperimentswiththepopulardatasetsMNIST,CIFAR-
10,andImageNet-1000forimageclassification,whenprocessedwithstandardarchitecturessuchasResNets
and Swin Transformers as well as with some especially simple, illustrative neural nets.1 Section 4 draws
several conclusions and suggests coupling the methods presented in the present paper with cruder, brute-
force techniques for enhancing confidentiality.
2 Methods
This section details the methodology of the present paper. Subsection 2.1 briefly reviews the general for-
mulation of Hammersley-Chapman-Robbins (HCR) bounds. Subsection 2.2 specifies the HCR bounds for
dithering vectors of features specifically and develops algorithms for computing the bounds. Subsection 2.3
specializestheHCRboundstotheaddition(tothefeatures)ofindependentandidenticallydistributednoise.
Subsection 2.4 considers a limit in which the HCR bounds become the classical Cram´er-Rao bounds (under
suitable assumptions of regularity in the parametric model, so that the relevant derivatives exist).
2.1 Hammersley-Chapman-Robbins bounds
This subsection reviews a classic bound introduced independently by Hammersley (1950) and Chapman &
Robbins (1951). Specifically, we use the multivariate generalization detailed, for example, by Wikipedia
contributors (2024).
Weconsiderafamilyofprobabilitydensityfunctions(pdfs)f (x)ofavectorx,parameterizedbyavector
θ
θ, with x coming from an n-dimensional real vector space Rn and θ coming from a p-dimensional real vector
space Rp. We consider any estimator θˆ(X) of θ; the estimator is a function of the vector X of observations.
We define g(θ) to be the expected value of θˆwith respect to the pdf f , that is,
θ
(cid:90)
g(θ)= E [θˆ]= θˆ(x)f (x)dx. (1)
θ θ
Rn
The Hammersley-Chapman-Robbins (HCR) bound is
(g (θ+ε)−g (θ))2
Var (θˆ )≥ k k (2)
θ k (cid:20)(cid:16) (cid:17)2(cid:21)
E fθ+ε(X) −1
θ fθ(X)
1Permissively licensed open-source codes that can automatically reproduce all results of the present paper are available at
https://github.com/facebookresearch/hcrbounds
2for k =1, 2, ..., p and for any vector ε in the same p-dimensional real vector space Rp to which θ belongs.
In (2), θˆ is the kth entry of the vector-valued θˆ, similarly g is the kth entry of the vector-valued g, and
k k
(cid:104) (cid:105) (cid:90) (cid:18) (cid:90) (cid:19)2
Var (θˆ )= E (θˆ −g (θ))2 = θˆ (x)− θˆ (y)f (y)dy f (x)dx (3)
θ k θ k k k k θ θ
Rn Rn
and
(cid:34)(cid:18) f (X) (cid:19)2(cid:35) (cid:90) (cid:18) f (x) (cid:19)2
E θ+ε −1 = θ+ε −1 f (x)dx. (4)
θ f (X) f (x) θ
θ Rn θ
If θˆis an unbiased estimator of θ, then g(θ)=θ and (2) simplifies to
(ε )2
Var (θˆ )≥ k (5)
θ k (cid:20)(cid:16) (cid:17)2(cid:21)
E fθ+ε(X) −1
θ fθ(X)
for k =1, 2, ..., p and for any vector ε in the same p-dimensional real vector space Rp to which θ belongs.
Requiring the estimator to be unbiased is tantamount to forbidding the use of extra, outside information
such as a Bayesian prior. Unbiasedness is a reasonable yet significant restriction. If, for example, the actual
values of the data are known from sources other than the observations X, then clearly the estimator can be
better than unbiased — the estimator could simply ignore the observations X and report the correct values
known a-priori from another source.
A bound on the mean-square error of any unbiased estimator θˆof θ follows immediately from (5):
E
(cid:34) 1(cid:88)p
(θˆ −θ
)2(cid:35)
≥
p1(cid:80)p k=1(ε k)2
(6)
θ p k k (cid:20)(cid:16) (cid:17)2(cid:21)
k=1 E θ fθ f+ θ(ε X(X )) −1
for any vector ε in the same p-dimensional real vector space Rp to which θ belongs.
2.2 Dithering the features of a machine-learned model
Thissubsectiondiscusseshowtoenhanceprivacy(specifically, confidentiality)oftheinputdatausedduring
inference with an already trained machine-learned model, by adding noise to the features that the inference
calculates. The formal term for adding noise is “dithering.” The present subsection specializes the HCR
bounds of (2) and (5) to this setting and details algorithms for computing the bounds.
Tosetnotation,weletthevectorθ ofparametersdenotetheinputdataandthevectorX ofobservations
denote the resulting features, with noise added to the features. We let the vector a of activations denote
θ
thefeatureswithoutnoiseadded. Notethattheinputdataneednotbetheentiretestset,butcouldbeonly
one or more of the individual examples input during inference.
Obtaining a tight HCR bound hinges on selecting a suitable vector ε of perturbations, perhaps taking
the maximum bound realized over several choices of ε. The ideal ε maximizes the ratio in the HCR bound
of (5). When the noise added to the features is Gaussian, with the entries of the noise being independent
and identically distributed centered normal variates, the denominator in (5) becomes the expression in (12)
given below. Maximizing (5) thus amounts to making the perturbation ε to the input θ as large as possible
while making the corresponding perturbation z to the features a as small as possible, for z of (10) below;
ε θ ε
thatis,thegoalistomaximizetheratioofEuclideannorms∥ε∥/∥z ∥,or,equivalently,tominimizetheratio
ε
∥z ∥/∥ε∥. If the perturbation ε is small, then linearization yields that z ≈(∂a /∂θ)ε, which is the product
ε ε θ
of the Jacobian (∂a /∂θ) and the perturbation ε to θ. Under this linear approximation, the minimum of
θ
the ratio ∥z ∥/∥ε∥ is therefore equal to reciprocal of the spectral norm of the pseudoinverse of the Jacobian
ε
(∂a /∂θ); afterall, thespectralnormofthepseudoinverseissimplythereciprocaloftheleastsingular-value
θ
of the Jacobian itself, and the least singular-value of the Jacobian (∂a /∂θ) is by definition the minimum of
θ
the ratio ∥(∂a /∂θ)ε∥/∥ε∥≈∥z ∥/∥ε∥.
θ ε
SomesimpleiterationscanapproximatethespectralnormofthepseudoinverseoftheJacobian(∂a /∂θ)
θ
while simultaneously calculating a perturbation ε for which the ratio ∥(∂a /∂θ)ε∥/∥ε∥≈∥z ∥/∥ε∥ is nearly
θ ε
3Algorithm 1: Calculation of a perturbation ε to the vector of parameters θ
Input: Positive integers i, n, and p, a vector z whose n entries are real numbers, a vector θ whose
p entries are real numbers, and functions t and u that apply the transpose of the Jacobian
(∂a /∂θ) and the Jacobian itself (without transposition) to arbitrary vectors, respectively,
θ
where a is the vector of features introduced in Subsection 2.2; here, i is the number of
θ
repetitions of the LSQR algorithm of Paige & Saunders (1982) that the present Algorithm 1
will execute, z is the starting vector for the iterations of LSQR (so t(z) is the starting vector
with regard to the normal equations), and θ is the unperturbed input data.
Output: A vector ε whose p entries are real-valued and a vector z whose n entries are real-valued;
ε
ε is the perturbation to θ such that z =a −a .
ε θ+ε θ
1 Set z(0) =z.
2 Calculate the vector of features a θ corresponding to the input θ.
3 for j = 1, 2, ..., i do
4 Set z˜(j) =∥z∥·z(j)/∥z(j)∥, so that the Euclidean norms of z and z˜(j) are equal.
5 Solve the least-squares problem of minimizing the Euclidean norm ∥(∂a θ/∂θ)ε(j)−z˜(j−1)∥,
obtaining the minimizing ε(j) using LSQR of Paige & Saunders (1982). LSQR should invoke
the functions t and u to perform the matrix-vector multiplications that LSQR requires. This
step 5 amounts to applying the pseudoinverse of the Jacobian (∂a /∂θ) to z˜(j−1), yielding ε(j).
θ
6 Calculate the vector of features a θ+ε(j) corresponding to the perturbed input (θ+ε(j)).
7 Set z(j) =a θ+ε(j) −a θ.
8 end
9 return ε=ε(i) and z ε =z(i).
minimal. Indeed, iterations of LSQR of Paige & Saunders (1982) with the Jacobian (∂a /∂θ) applied to
θ
vectorsgeneratedduringtheiterationsofLSQRandwiththetranspose(∂a /∂θ)⊤ oftheJacobianappliedto
θ
othervectorsgeneratedduringtheiterationscanapproximatetheactionofthepseudoinverseoftheJacobian
(∂a /∂θ). SuchiterationsofLSQRproduceaperturbationε, fromwhichthecorrespondingperturbationz
θ ε
to the features is straightforward to calculate. Then the newly calculated z can serve as the starting point
ε
(∂a /∂θ)⊤z in the normal equations for further iterations of LSQR. The further iterations of LSQR yield
θ ε
an updated perturbation ε, from which the corresponding perturbation z to the features is straightforward
ε
tocompute. Repeatingthisprocessseveral(say, i=10)times, iterativelyupdatingεandz everytime, will
ε
approximately minimize the ratio ∥z ∥/∥ε∥. Algorithm 1 provides pseudocode summarizing the procedure.
ε
Note that automatic differentiation can apply to arbitrary vectors both the Jacobian and its transpose,
efficiently and matrix-free (never actually having to form the full Jacobian). Furthermore, there is no need
to compute ε especially precisely, as any approximation whatsoever to the ideal for ε yields a perfectly
rigorous guarantee via the HCR bounds. Indeed, given the perturbation ε to the input θ, calculating the
correspondingperturbationz tothefeaturesexactly(withoutanyapproximations)requiresjustoneforward
ε
run of inference with the machine-learned model.
2.3 Additive noise
This subsection specializes the HCR bounds of the previous subsections to the case in which the dithered
features are simply the features plus independent and identically distributed noise. In particular, this
subsection derives an explicit expression for the right-hand side of (5). In accordance with the notation
of the preceding subsection, Subsection 2.2, we denote by a the features generated by inference with the
θ
already trained model using the original data θ (or just a single test example) as inputs, and we denote by
a the features generated by inference using the perturbed data (θ+ε) as inputs.
θ+ε
Dithering yields the observed noisy vector of features
X =a +Z, (7)
θ
where Z is the noise added. Denoting by f the probability density function of the noise, we see that
f (X)=f (a +Z)=f(Z) (8)
θ θ θ
4and
f (X)=f (X−(a −a ))=f (a +Z−(a −a ))=f(Z−(a −a ))=f(Z−z ), (9)
θ+ε θ θ+ε θ θ θ θ+ε θ θ+ε θ ε
where
z =a −a ; (10)
ε θ+ε ε
thatis,z istheperturbationaddedtothefeaturesduringdeterminationofε(withz updatedtocorrespond
ε ε
exactly to the ε actually used, as discussed at the end of Subsection 2.2). Combining (8) and (9) yields that
the denominator in (5) is
(cid:34)(cid:18)
f (X)
(cid:19)2(cid:35) (cid:34)(cid:18)
f(Z−z )
(cid:19)2(cid:35)
E θ+ε −1 = E ε −1 , (11)
θ f (X) f(Z)
θ
where z from (10) is viewed as a fixed constant during evaluation of the expectation.
ε
For some distributions of Z — including the multivariate normal distribution N(0,σ2·Id) corresponding
to a standard deviation σ — we can evaluate (11) via analytic integration, aligning one of the axes of
integration in the integral corresponding to the right-hand side of (11) with the fixed direction given by z .
ε
Appendix A performs the calculation for this normal case, yielding that the denominator in (5) is
(cid:34)(cid:18)
f (X)
(cid:19)2(cid:35) (cid:18)
∥z
∥2(cid:19)
E θ+ε −1 =exp ε −1, (12)
θ f (X) σ2
θ
where ∥z ∥ is the Euclidean norm of z from (10). For more complicated distributions, we can estimate the
ε ε
right-hand side of (11) via Monte-Carlo methods. For isotropic (that is, rotation-invariant) distributions
of the added noise Z, such as the multivariate normal distribution N(0,σ2·Id), the value of (11) depends
only on the Euclidean norm of z and not on the entries of z individually. In all cases, the value of (11) is
ε ε
independent of the machine-learned model used.
2.4 Cram´er-Rao bounds
ThissubsectionconnectstheearliersubsectionswiththefamousapproachofCram´erandRao—aconnection
that the original works of Hammersley (1950) and of Chapman & Robbins (1951) note as motivation for
developing their own bounds. (The remainder of this subsection will be assuming tacitly, without further
elaboration, that all derivatives required for this subsection’s derivations actually exist and are continuous.
UnliketheHCRbounds,theCram´er-Raoboundspertainonlytoscenariosinwhichthederivativesdoexist.)
If the perturbation ε is very small, then z =a −a will also be very small, with z =0, so
ε θ+ε θ 0
p
(z )
=(cid:88)∂(z ε)
j ε +o(∥ε∥) (13)
ε j ∂ε k
k
k=1
for j =1, 2, ..., n, while the right-hand side of (12) becomes
exp(cid:18) ∥z ε∥2(cid:19)
−1=
∥z ε∥2
+o(∥ε∥2)=
1 (cid:88)n
((z ) )2+o(∥ε∥2), (14)
σ2 σ2 σ2 ε j
j=1
where (z ) denotes the jth entry of the vector z . Combining (13) and (14) yields
ε j ε
exp(cid:18)
∥z
ε∥2(cid:19)
−1=
1
(cid:88)n (cid:32) (cid:88)p
∂(z ε)
j ε
(cid:33)2
+o(∥ε∥2). (15)
σ2 σ2 ∂ε k
k
j=1 k=1
Evaluating (15) for a perturbation ε in which all entries but one — say the kth — are zero yields
exp(cid:18) ∥z ε∥2(cid:19)
−1=
(ε k)2 (cid:88)n (cid:18) ∂(z ε) j(cid:19)2
+o(∥ε∥2), (16)
σ2 σ2 ∂ε
k
j=1
5where k is one of the positive integers 1, 2, ..., p. Naturally,
∂(z ) 1
ε j = (17)
∂ε ∂ε /∂(z )
k k ε j
for j =1, 2, ..., n. Combining (5), (12), and (16) and taking the limit ε→0 then yields
σ2 σ2
Var (θˆ )≥ = (18)
θ k (cid:80)n (∂(z ) /∂ε )2 (cid:80)n 1/(∂ε /∂(z ) )2
j=1 ε j k j=1 k ε j
for k = 1, 2, ..., p, where the latter equality in (18) follows from (17). Please note that (18) is exact, not
approximate — the higher-order terms vanish in the limit ε→0. Evaluating the bound (18) for all p values
of k requires thecomputation ofeither p or n gradients, where p is thedimension ofthe space ofparameters
and n is the dimension of the space of observations. (Taking the Jacobian of z with respect to ε requires n
ε
gradients; taking the Jacobian of ε with respect to z requires p gradients.) The inequality in (18) is known
ε
as the “Cram´er-Rao bound,” as elucidated by Hannun et al. (2021), for example.
3 Results
This section applies the methods of the previous section, Section 2, to several standard data sets and neural
architecturesforclassifyingtheinputimages.2 Allboundsreportedinthepresentsectionareforthestandard
deviationscorrespondingto(5); ofcourse,thestandarddeviationisthesquarerootofthevariancefrom(5).
Subsection 3.1 considers MNIST, a classic data set of 28×28 pixel grayscale scans of handwritten digits,
first training a simple neural net on the standard training set and then conducting inference and computing
the associated HCR bounds on the test set. Subsection 3.2 does similarly for CIFAR-10, a classic data
set of 32×32 pixel color images of 10 classes, namely airplanes, birds, boats, cars, cats, deer, dogs, frogs,
horses, and trucks. Subsection 3.3 considers ImageNet, a standard data set with 1000 classes, processing
imagesfromthevalidationsetviatheconventionalpre-trainedneuralnets,“ResNet18”and“Swin-T,”from
TorchVision of TorchVision maintainers & contributors (2024).
In the coming subsections, “Affine ” refers to a layer which multiplies the input row vector from the
m×n
right by an m×n matrix whose entries are learned and adds a vector which is independent of the input
(that is, a “bias”) that is also learned; the dimension of the input is m and the dimension of the output
is n. “ReLU” refers to a layer which preserves unchanged every non-negative entry of the input and zeros
every negative entry; the dimensions of the input and of the output are the same. “Flatten” refers to a
layer which reshapesthe inputinto a single, longervector. “Convolution2D ” refersto
m×n(channels);k×ℓ(kernel)
a layer which convolves each of the m channels of the input with n convolutional kernels, each of size k×ℓ
pixels whose values are learned, and adds to the result an image which is independent of the input (that is,
a “bias”) that is also learned. “MaximumPooling2D ” refers to a layer which partitions
m×n(stride);k×ℓ(kernel)
the input into m×n blocks of pixels and replaces each block with the maximum value in the block (in this
paper, the stride and size of the kernel are always the same, that is, m=k and n=ℓ); the first dimension
of the output is 1/m times the first dimension of the input, while the second dimension of the output is 1/n
times the second dimension of the input. “Softmax” refers to a layer which calculates the softmax of the
inputvector(thesoftmaxisalsoknownasthe“Gibbsdistribution”); thedimensionsoftheinputandofthe
output are the same.
The weights and biases in the neural networks are the learned values; the values of the inputs, features,
and class-confidences are activations (that is, values at nodes) in the neural nets. All results reported are
HCR bounds maximized over 25 independent and identically distributed pseudorandom realizations of z
ε
in(12), obtainedbyrunningthealgorithm(Algorithm1)ofSubsection2.2withthenentriesofthestarting
√
vector z being proportional to the noise added to the features. The constant of proportionality is 1/ n
times the size s of perturbation specified in the captions to the subfigures (these sizes are 1/200, 1/500, and
1/1000 for the different subfigures, as indicated in the captions). This constant of proportionality results in
theright-handsideof(12)beingroughlyexp(s2)−1≈s2,wheresisthesizeoftheperturbation(s=1/200,
s=1/500, or s=1/1000, as specified in the subfigures’ captions).
2Permissively licensed open-source software that can automatically reproduce all the results reported here is available at
https://github.com/facebookresearch/hcrbounds
63.1 MNIST
This subsection reports the results of numerical experiments with the standard data set, “MNIST,” a data
set presented by LeCun et al. (1998). MNIST contains images of handwritten digits (0, 1, 2, ..., 9).
To calculate features for a given input, we use the activations in the last layer of the following neural
network: inputs → Flatten → Affine → ReLU → Affine → ReLU → features
784×784 784×784
There are 784 entries both in the input vector for each image and in the corresponding features. The
input images are 28×28 pixels, with only a single color channel (the inputs are grayscale).
Giventhefeatures,theclassifiertakestheargmaxoftheactivations(valuesatthenodes)inthelastlayer
ofthefollowingneuralnetwork,passingthegivenfeaturesasinputstothenetwork: features→Affine
784×10
→ Softmax → class-confidences
In all processing, we first normalize the pixels’ potential values to range from 0 to 1, then subtract the
overallmean0.1037,andfinallydividebythestandarddeviation0.3081. Whendisplayingimages,wereverse
all these normalizations.
For training, we use random minibatches of 32 examples each, over 6 epochs of optimization (thus
sweeping 6 times through all 60,000 examples from the training set of MNIST). We minimize the empirical
average cross-entropy loss using AdamW of Loshchilov & Hutter (2019), with a learning rate of 0.001.
On the test set of MNIST, the average accuracy for classification without dithering is 97.9% and with
dithering is 95.1%.
In Figures 1 and 2, the size of the perturbation (either 1/200 or 1/1000) pertains to the Euclidean norm
of z in (12). In the limit that the size is 0, the HCR bounds would become Cram´er-Rao bounds (if the
ε
parameterizations of the neural networks were differentiable), as in (18). The results for the different sizes
turn out to be reasonably similar.
Figure 1 histograms (over all examples in the test set) the magnitudes of the HCR lower bounds on the
standard deviations of unbiased estimators for the original images’ values. The estimates are for the Fourier
modes in a discrete cosine transform (DCT) of type II, with the DCT normalized to be an orthogonal linear
transformation (meaning real and unitary or isometric). The modes of the DCT form an orthonormal basis
suitableasasystemofcoordinates; notethatthesemodesareforthenormalizedinputimages,standardized
such that the standard deviation of the normalized pixel values is 1 and the mean is 0. The histograms in
the rightmost column of Figure 1 consider only the 8×8 lowest-frequency modes, whereas the histograms
in the leftmost column consider all 28×28.
Figure1showsthattheboundswouldhavebeenreasonablyeffectivehadthepixelsoftheoriginalimages
not been mostly almost pure black or pure white (so that rounding away the obtained bounds denoises the
estimates very effectively).
Figure 2 visualizes the HCR bounds on three examples from the test set. The visualization involves
(1) inverting the DCT to move the bounds on the DCT modes back into the original domain, (2) adding
to the values of the pixels in the normalized original image the product of independent and identically
distributed Rademacher variates (which are −1 with probability 1/2 and +1 with probability 1/2) times
the corresponding HCR bounds, and (3) reversing the per-pixel normalization back into the conventional
perceptual space in which the values of pixels can range from 0 to 1 (while clipping negative values to 0 and
clippingvaluesexceeding1to1). Figure2illustratesthattheobtainedboundsaresignificantyetineffective
(mostly since thresholding the grayscale images to purely black-and-white would denoise away much of the
displayed perturbations).
3.2 CIFAR-10
This subsection presents the results of numerical experiments with the standard benchmark data set,
“CIFAR-10,” ofKrizhevsky(2009). CIFAR-10containsimagesrepresentingtenlabeledclasses—airplanes,
birds, boats, cars, cats, deer, dogs, frogs, horses, and trucks.
To calculate features for a given input, we use the activations in the last layer of the following neural
network, adapted from the net of Shahrestani (2021): inputs → Convolution2D →
3×32(channels);3×3(kernel)
ReLU → MaximumPooling2D → Convolution2D → ReLU →
2×2(stride);2×2(kernel) 32×1024(channels);5×5(kernel)
MaximumPooling2D → Convolution2D → ReLU → Flatten
3×3(stride);3×3(kernel) 1024×3072(channels);3×3(kernel)
→ Affine → ReLU → features (“Flatten” simply removes dimensions that are 1 in the shape of the
3072×3072
tensor, in this particular case.)
7(a)10iterationswithaperturbationof1/200 (b)10iterationswithaperturbationof1/200
(c)10iterationswithaperturbationof1/1000 (d)10iterationswithaperturbationof1/1000
Figure1: HistogramsoftheHCRboundsoverthe10,000examplesofMNIST’stestset, bothunfilteredand
filteredtothe8×8lowest-frequencymodesofthetype-2discretecosinetransform;thenumbersofiterations
are the numbers of repetitions of LSQR in Subsection 2.2, which is the input i in Algorithm 1
8(a)one,perturbedby1/1000 (b)one,perturbedby1/200 (c)one,unperturbed
(d)four,perturbedby1/1000 (e)four,perturbedby1/200 (f)four,unperturbed
(g)nine,perturbedby1/1000 (h)nine,perturbedby1/200 (i)nine,unperturbed
Figure 2: Reconstructions of examples from MNIST’s test set
9There are 3,072 entries both in the input vector for each image and in the corresponding features. The
input images are 32×32 pixels, with three color channels (red, green, and blue).
Giventhefeatures,theclassifiertakestheargmaxoftheactivations(valuesatthenodes)inthelastlayer
ofthefollowingneuralnetwork,passingthegivenfeaturesasinputstothenetwork: features→Affine
3072×10
→ Softmax → class-confidences
In all processing, we first normalize the pixels’ potential values to range from 0 to 2 and then subtract
1, so that the resulting pixel values can range from −1 to 1. When displaying images, we reverse all these
normalizations.
For training, we use random minibatches of 32 examples each, over 7 epochs of optimization (thus
sweeping 7 times through all 50,000 examples from the training set of CIFAR-10). We use the AdamW
optimizer of Loshchilov & Hutter (2019) with a learning rate of 0.001, minimizing the empirical average
cross-entropy loss.
On 2,500 examples drawn at random without replacement from the test set of CIFAR-10, the average
accuracy for classification without dithering is 70% and with dithering is 50%.
In Figures 3 and 4, the size of the perturbation (either 1/500 or 1/1000) pertains to the Euclidean norm
of z in (12). The size 1/1000 is close to the limit in which HCR bounds would become Cram´er-Rao bounds
ε
(if the parameterizations of the neural networks were differentiable), as in (18). The results for the different
sizes are quite similar.
Figure 3 histograms (over 2,500 examples from the test set) the magnitudes of the HCR lower bounds
on the standard deviations of unbiased estimators for the original images’ values. The estimates are for the
Fourier modes in a discrete cosine transform (DCT) of type II, with the DCT normalized to be orthogonal
(meaningrealandunitaryorisometric). ThemodesoftheDCTformanorthonormalsystemofcoordinates;
note that these modes are for the normalized input images, standardized such that the normalized pixel
values range from −1 to 1. The histograms in the rightmost column of Figure 3 consider only the 8×8
lowest-frequency modes, while the histograms in the leftmost column consider all 32×32.
Figure4visualizestheHCRboundsonthreeexamplesfromthetestset. AswithFigure2,thevisualiza-
tion involves (1) inverting the DCT, (2) adding to the values of the pixels in the normalized original image
the product of independent and identically distributed Rademacher variates with the corresponding HCR
bounds on the standard deviations, and (3) reversing the per-pixel normalization back to where the values
of pixels in each color channel can range from 0 to 1 (while clipping negative values to 0 and clipping values
exceeding 1 to 1).
Both Figure 3 and Figure 4 show that the bounds are on the precipice of guaranteeing that decent
reconstructions of the original images are impossible from the dithered features.
3.3 ImageNet-1000
This subsection presents the results of numerical experiments with the popular data set, “ImageNet-1000,”
of Russakovsky et al. (2015). ImageNet-1000 contains a thousand labeled classes, each consisting of images
representing a particular noun (such as a species or a dog breed).
All examples of the present subsection consider 128 examples from the validation set of ImageNet-1000,
drawingtheexamplesuniformlyatrandomwithoutreplacement. These128examplesaremorethansufficient
to find that the HCR bounds for ImageNet are ineffective, allowing the dithered features to lead to full
reconstructions that are imperceptibly different from the input images. All models of the present subsection
aretrainedonthetrainingsetofImageNet;wedownloadedthepre-trainednetworksfromPyTorch’s“model
zoo” of TorchVision maintainers & contributors (2024). The input images get resized to be 91×91 pixels
(withthreecolorchannels—red,green,andblue)andthenupsampledtobe224×224pixels(withthesame
RGB color channels) for input to the pre-trained neural nets. There are slightly fewer degrees of freedom
in an image that has 91×91 pixels for each of three color channels than in the features of either of the
pre-trained networks (“ResNet-18” and “Swin-T”) considered here. For pre-processing, we applied to the
inputimagestheusualnormalizationsfromthemodelzooofTorchVisionmaintainers&contributors(2024).
In Figures 5 and 6, the size (either 1/500 or 1/1000) of the perturbation pertains to the Euclidean norm
ofz in(12). Thesize1/1000iscloseto0—closetothelimitinwhichHCRboundswouldbecomeCram´er-
ε
Rao bounds (if the parameterizations of the neural networks were differentiable), as in (18). The results of
the different sizes are similar.
10(a)6iterationswithaperturbationof1/500 (b)6iterationswithaperturbationof1/500
(c)4iterationswithaperturbationof1/1000 (d)4iterationswithaperturbationof1/1000
Figure3: HistogramsoftheHCRboundsover2,500examplesfromCIFAR-10’stestset,bothunfilteredand
filteredtothe8×8lowest-frequencymodesofthetype-2discretecosinetransform;thenumbersofiterations
are the numbers of repetitions of LSQR in Subsection 2.2, which is the input i in Algorithm 1
11(a)airplane,perturbedby1/1000 (b)airplane,perturbedby1/500 (c)airplane,unperturbed
(d)bird,perturbedby1/1000 (e)bird,perturbedby1/500 (f)bird,unperturbed
(g)boat,perturbedby1/1000 (h)boat,perturbedby1/500 (i)boat,unperturbed
Figure 4: Reconstructions of examples from CIFAR-10’s test set
12ThefollowingtwosubsubsectionsrefrainfromdisplayinganaloguesofFigures2and4,sincevisualizations
of which reconstructions are possible (analogous to those of Figures 2 and 4) turn out to be perceptually
indistinguishable from the original images.
3.3.1 ResNet-18
This subsubsection uses the ResNet-18 of He et al. (2016). There are 24,843 entries in the input vector for
each image and 25,088 entries in the corresponding features. The average (top-1) accuracy of classification
without dithering is 57% and with dithering is 54%.
Figure5histograms(over128examplesfromthevalidationset)themagnitudesoftheHCRlowerbounds
on the standard deviations of unbiased estimators for the original images’ values. The estimates are for the
Fourier modes in an orthogonal discrete cosine transform (DCT) of type II. The modes of the DCT form an
orthonormalsystemofcoordinates;notethatthesemodesareforthenormalizedinputimages,standardized
such that the standard deviation of the normalized pixel values is about 1 and the mean is roughly 0. The
rightmost histograms in Figure 5 consider only the 32×32 lowest-frequency DCT modes.
The bounds reported in Figure 5 are useless for all practical purposes, providing next to no guarantee of
any protection against reconstruction attacks.
3.3.2 Swin-T
This subsubsection uses the Swin-T of Liu et al. (2021). There are 24,843 entries in the input vector for
each image and 37,632 entries in the corresponding features. The average (top-1) accuracy of classification
without dithering is 64% and with dithering is 54%.
Figure6histograms(over128examples)themagnitudesoftheHCRlowerboundsonthestandarddevia-
tionsofunbiasedestimatorsfortheoriginalimages’values. Theestimatesareforthemodesinanorthogonal
discrete cosine transform of type II. The modes of the DCT constitute an orthonormal basis appropriate for
a system of coordinates; note that these modes are for the normalized input images, standardized such that
the standard deviation of the normalized pixel values is around 1 and the mean is approximately 0. The
rightmost histograms in Figure 6 filter down to the 32×32 lowest-frequency modes.
As with Figure 5, the bounds reported in Figure 6 provide effectively no guarantee of protection against
reconstructing the input images.
4 Conclusion
The guarantees provided by the Hammersley-Chapman-Robbins (HCR) bounds in the results presented
abovearesometimesontheprecipiceofbeingveryuseful, butarefarfromideal. Theresultsaboveconsider
only examples in which the neural networks are at least somewhat deep. The HCR bounds might be more
usefula-prioriforshallowneural-networkssuchasthosecorrespondingtopopulargeneralizedlinearmodels.
However, for such models Cram´er-Rao bounds are easy to calculate and simpler than the HCR analogues;
none of the computational sophistication developed in the present paper is necessary to compute ideal
Cram´er-Rao bounds in such cases. Hannun et al. (2021) took this approach.
Thus, the HCR approach appears to be ineffectual on its own. Perhaps the best use of the HCR bounds
would be to supplement other, cruder techniques for enhancing privacy. An obvious such cruder technique
wouldbetolimitthesizesofthevectorsoffeatures. Intheexamplesconsideredabove,thesizesofthevectors
of features are never less than the corresponding numbers of pixels in the images times the numbers of color
channels. In the complete absence of noise, reconstructing the whole original images from the calculated
features can be possible only when the number of features is no less than the number of pixel values being
reconstructed (though, even then, computational cost might limit the feasibility of full reconstruction in
practice). In the presence of noise, the HCR bounds rigorously limit the quality of the reconstruction. Yet
the above results indicate that the bounds are fairly ineffectual for large models. A more effective strategy
than relying exclusively on the HCR bounds could be to limit the sizes of the vectors of features. After
all, the numbers of degrees of freedom in the original images that any scheme whatsoever can reconstruct
from the corresponding features obviously cannot ever be greater than the sizes of the vectors of features.
Dithering and the HCR bounds can nicely complement the limiting of the sizes of the vectors of features.
13(a)10iterationswithaperturbationof1/500 (b)10iterationswithaperturbationof1/500
(c)10iterationswithaperturbationof1/1000 (d)10iterationswithaperturbationof1/1000
Figure5: HistogramsoftheHCRboundsover128examplesfromImageNet’svalidationset,usingaResNet-
18,bothunfilteredandfilteredtothe32×32lowest-frequencymodesofthetype-2discretecosinetransform;
the numbers of iterations are the numbers of repetitions of LSQR in Subsection 2.2, which is the input i in
Algorithm 1
14(a)10iterationswithaperturbationof1/500 (b)10iterationswithaperturbationof1/500
(c)10iterationswithaperturbationof1/1000 (d)10iterationswithaperturbationof1/1000
Figure6: HistogramsoftheHCRboundsover128examplesfromImageNet’svalidationset,usingaSwin-T,
both unfiltered and filtered to the 32×32 lowest-frequency modes of the type-2 discrete cosine transform;
the numbers of iterations are the numbers of repetitions of LSQR in Subsection 2.2, which is the input i in
Algorithm 1
15Acknowledgements
We would like to thank Awni Hannun and Edward Suh.
A Normally distributed noise
This appendix considers the multivariate normal distribution in which all n entries of a vector Z are inde-
pendent and identically distributed as N(0,σ2), so that the probability density function (pdf) of Z is
1
(cid:18) ∥z∥2(cid:19)
f(z)= exp − , (19)
(2πσ2)n/2 2σ2
where ∥z∥ is the Euclidean norm of z. With this pdf, the right-hand side of (11) is
(cid:34)(cid:18) f(Z−z ) (cid:19)2(cid:35) (cid:90) (cid:18) f(z−v) (cid:19)2
E ε −1 = −1 f(z)dz, (20)
f(Z) f(z)
Rn
where v’s first entry v = ∥z ∥ is the Euclidean norm of z and v’s other entries v = 0 for k > 1; the
1 ε ε k
invariance of (19) to rotations of the coordinate system yields (20) — the right-hand side of (20) aligns the
first coordinate axis with the direction of z . The remainder of this appendix simplifies (20) further.
ε
Substituting (19) into the right-hand side of (20) yields
(cid:90) (cid:18) f(z−v) (cid:19)2
−1 f(z)dz
f(z)
Rn
1 (cid:90) ∞ (cid:90) ∞ (cid:18) (cid:18) (z )2−(z −v )2(cid:19) (cid:19)2 (cid:18) (z )2+···+(z )2(cid:19)
= ··· exp 1 1 1 −1 exp − 1 n dz dz ···dz
(2πσ2)n/2 2σ2 2σ2 1 2 n
−∞ −∞
1 (cid:90) ∞ (cid:90) ∞ (cid:18) (cid:18) (z )2−(z −c)2(cid:19) (cid:19)2 (cid:18) (z )2+···+(z )2(cid:19)
= ··· exp 1 1 −1 exp − 1 n dz dz ···dz , (21)
(2π)n/2 2 2 1 2 n
−∞ −∞
where
v ∥z ∥
c= 1 = ε . (22)
σ σ
Expanding the square yields three terms
(cid:18) exp(cid:18) (z 1)2−(z 1−c)2(cid:19) −1(cid:19)2 =exp(cid:0) (z )2−(z −c)2(cid:1) −2exp(cid:18) (z 1)2−(z 1−c)2(cid:19) +1. (23)
2 1 1 2
The last term in (23) corresponds in (21) to
1 (cid:90) ∞ (cid:90) ∞ (cid:18) (z )2+···+(z )2(cid:19)
··· exp − 1 n dz dz ···dz =1. (24)
(2π)n/2 2 1 2 n
−∞ −∞
The penultimate term in (23) corresponds in (21) to
2 (cid:90) ∞ (cid:90) ∞ (cid:18) (z −c)2+(z )2+···+(z )2(cid:19)
− ··· exp − 1 2 n dz dz ···dz
(2π)n/2 2 1 2 n
−∞ −∞
2 (cid:90) ∞ (cid:90) ∞ (cid:18) (z )2+(z )2+···+(z )2(cid:19)
=− ··· exp − 1 2 n dz dz ···dz =−2. (25)
(2π)n/2 2 1 2 n
−∞ −∞
The first term in the right-hand side of (23) corresponds in (21) to
1 (cid:90) ∞ (cid:90) ∞ (cid:18) 2(z −c)2−(z )2+(z )2+···+(z )2(cid:19)
··· exp − 1 1 2 n dz dz ···dz
(2π)n/2 2 1 2 n
−∞ −∞
1 (cid:90) ∞ (cid:18) 2(z −c)2−(z )2(cid:19) 1 (cid:90) ∞ (cid:18) (z )2−4cz +2c2(cid:19)
= √ exp − 1 1 dz = √ exp − 1 1 dz . (26)
2π 2 1 2π 2 1
−∞ −∞
16Further simplification yields
1 (cid:90) ∞ (cid:18) (z )2−4cz +2c2(cid:19) exp(c2)(cid:90) ∞ (cid:18) (z −2c)2(cid:19)
√ exp − 1 1 dz = √ exp − 1 dz =exp(c2). (27)
2π 2 1 2π 2 1
−∞ −∞
Combining all formulas in this appendix yields that the right-hand side of (11) is
(cid:34)(cid:18)
f(Z−z )
(cid:19)2(cid:35) (cid:18)
∥z
∥2(cid:19)
E ε −1 =exp ε −1. (28)
f(Z) σ2
References
Abadi, Martin, Chu, Andy, Goodfellow, Ian, McMahan, H. Brendan, Miranov, Ilya, Talwar, Kunal, &
Zhang,Li.2016. Deeplearningwithdifferentialprivacy. Pages 308–318 of: Weippl,Edgar,Katzenbeisser,
Stefan,Kruegel,Christopher,Myers,Andrew,&Halevi,Shai(eds),Proceedingsofthe2016ACMSIGSAC
Conference on Computer and Communications Security (CCS). Association for Computing Machinery.
Alisic,Rijad.2021. Privacy of Sudden Events in Cyber-Physical Systems. Ph.D.thesis,KTHRoyalInstitute
of Technology. This is actually a “licentiate thesis” — part of a Ph.D.
Alisic, Rijad, Molinari, Marco, Par´e, Philip E., & Sandberg, Henrik. 2020. Maximizing privacy in MIMO
cyber-physical systems using the Chapman-Robbins bound. Pages 6272–6277 of: Braatz, Richard D.,
Chung,ChungChoo,Lee,JayH.,&Zaccarian,Luca(eds),Proceedings of the 2020 59th IEEE Conference
on Decision and Control (CDC). IEEE.
Chapman,DouglasG.,&Robbins,Herbert.1951. Minimumvarianceestimationwithoutregularityassump-
tions. Ann. Math. Stat., 22(4), 581–586.
Dwork, Cynthia, & Roth, Aaron. 2014. The algorithmic foundations of differential privacy. Found. Trends
Theor. Comput. Sci., 9(3–4), 211–407.
Hammersley, John M. 1950. On estimating restricted parameters. J. R. Stat. Soc. Ser. B, 12(2), 192–240.
Hannun, Awni,Guo, Chuan, &vanderMaaten,Laurens.2021. Measuringdataleakageinmachine-learning
models with Fisher information. Pages 760–770 of: de Campos, Cassio, & Maathuis, Marloes H. (eds),
Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial Intelligence. Proceedings of
Machine Learning Research, vol. 161. Microtome Press.
He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, & Sun, Jian. 2016. Deep residual learning for image recog-
nition. Pages 770–778 of: Proceedings of the 29th IEEE Conference on Computer Vision and Pattern
Recognition (CVPR). IEEE Computer Society.
Krizhevsky, Alex. 2009. Learning multiple layers of features from tiny images. Tech. rept. Master’s Thesis.
University of Toronto Department of Computer Science.
LeCun, Yann, Bottou, L´eon, Bengio, Yoshua, & Haffner, Patrick. 1998. Gradient-based learning applied to
document recognition. Proc. IEEE, 86(11), 2278–2324.
Liu, Ze, Lin, Yutong, Cao, Yue, Hu, Han, Wei, Yixuan, Zhang, Zheng, Lin, Stephen, & Guo, Baining.
2021. Swin Transformer: hierarchical vision Transformer using shifted windows. Pages 9992–10002
of: Proceedings of the 2021 IEEE/CVF International Conference on Computer Vision (ICCV). IEEE
Computer Society.
Loshchilov,Ilya,&Hutter,Frank.2019.Decoupledweightdecayregularization.Tech.rept.1711.05101.arXiv.
Also published as a poster and paper at the 2019 International Conference on Learned Representations
(ICLR).
Paige, Christopher C., & Saunders, Michael A. 1982. LSQR: an algorithm for sparse linear equations and
sparse least squares. ACM Trans. Math. Softw., 8(1), 43–71.
17Russakovsky, Olga, Deng, Jia, Su, Hao, Krause, Jonathan, Satheesh, Sanjeev, Ma, Sean, Huang, Zhiheng,
Karpathy, Andrej, Khosla, Aditya, Bernstein, Michael, Berg, AlexanderC., &Fei-Fei, Li.2015. ImageNet
large scale visual recognition challenge. Int. J. Comput. Vis., 115(3), 211–252.
Shahrestani, Afshin. 2021 (August). Classifying CIFAR-10 using a simple CNN. https://medium.
com/analytics-vidhya/classifying-cifar-10-using-a-simple-cnn-4e9a6dd7600b. Blog post on
Medium’s series, Analytics Vidhya.
TorchVision maintainers, & contributors. 2024. TorchVision: PyTorch’s computer vision library. https:
//github.com/pytorch/vision. Repository on GitHub.
Wikipedia contributors. 2024. Chapman–Robbins bound. Accessed online via the Web in March 2024 at
https://en.wikipedia.org/wiki/Chapman-Robbins_bound.
18