Federated Multi-Agent Mapping for Planetary Exploration
Tiberiu-Ioan Szatmari1 and Abhishek Cauligi2
Abstract—In multi-agent robotic exploration, managing and
effectivelyutilizingthevast,heterogeneousdatageneratedfrom
dynamic environments poses a significant challenge. Feder-
ated learning (FL) is a promising approach for distributed
mapping, addressing the challenges of decentralized data in Local model Joint model Local dataset P sa hra am rinet ger Base station Rover
collaborative learning. FL enables joint model training across
multipleagentswithoutrequiringthecentralizationorsharing
of raw data, overcoming bandwidth and storage constraints.
Our approach leverages implicit neural mapping, representing
maps as continuous functions learned by neural networks, for
compact and adaptable representations. We further enhance
this approach with meta-initialization on Earth datasets, pre-
training the network to quickly learn new map structures.
Thiscombinationdemonstratesstronggeneralizationtodiverse
domains like Martian terrain and glaciers. We rigorously
evaluatethisapproach,demonstratingitseffectivenessforreal-
world deployment in multi-agent exploration scenarios.
I. INTRODUCTION
Multi-agentsystems,wherecollaborativegroupsofrovers
or drones work together, hold a large potential for space
operations. These systems offer advantages like autonomous
Fig. 1: In future multi-agent space exploration, balancing communication
mapping of unexplored terrains, conducting scientific ex-
efficiencywitheffectivecollaborationisparamount.Traditionalapproaches
periments, setting up communication networks, and sample that rely on sharing all raw data back to a base station quickly become
collection. The inherent communication delays in space infeasible due to bandwidth constraints. Federated learning addresses this
by allowing rovers to learn maps and adapt their skills locally. They then
necessitate autonomy, optimal resource management, and
share only the trained models with a base station, minimizing communi-
adaptability in the face of unforeseen circumstances. cation overhead. This enables efficient creation of a shared, global map
To address these limitations and open new possibilities representationwhileempoweringindividualroverautonomy.
in space exploration, next-generation multi-agent systems contexts,robotsmustachieveproficiencyinself-localization,
promise significant advancements. By deploying teams of mapping, and information sharing. This will enable coordi-
mobile robots on planetary bodies, missions can benefit nated action, thereby enhancing mission efficiency.
fromincreasedefficiencythroughtaskparallelizationanden- The NASA Jet Propulsion Laboratory (JPL) mission
hanced robustness through redundancy [1]. The exploration Cooperative Autonomous Distributed Robotic Exploration
of Venus with its extreme conditions is one such appli- (CADRE) mission [3] exemplifies these principles and
cation. Teams of autonomous, altitude-controlled balloons demonstrates the potential of autonomous multi-robot net-
[2] present a compelling multi-agent solution by navigating worksinLunarexploration.TheCADREroverswillleverage
theatmosphere,collaborativelycollectingscientificdata,and meshnetworkradios,stereocameras,andground-penetrating
adapting to changing conditions. Such missions demonstrate radars for collaborative 3D mapping. Importantly, the mis-
thepracticaladvantagesandpotentialofmulti-agentsystems sion highlights the unique capacity of multi-robot missions
in addressing the unique demands of space exploration. to gather distributed measurements unattainable by a single
Diverse capabilities within these teams allow for a wide robot. CADRE will explore the Moon’s Reiner Gamma
range of tasks. However, missions such as infrastructure region for a 14 day mission (one Lunar day). To start their
installationandscientificsamplingfacechallengesinGlobal mission, the three rovers will carry out distributed mapping
Navigation Satellite System (GNSS)-denied environments. of their surrounding environment and transmit the raw data
The impracticality of remote operation due to communica- collected on-board each rover to a central base station.
tion delays requires real-time autonomy onboard. In such
A. Contributions
1Tiberiu-Ioan Szatmari, Department of Applied Mathematics and Com-
puter Science, Technical University of Denmark & Eriksholm Research In this work, we propose a learning-based approach for
Centre(email:tibs@dtu.dk).
distributed implicit mapping in multi-agent systems. Robots
2Abhishek Cauligi is with the Jet Propulsion Lab-
independentlyexploretheirsurroundingsusingonboardsen-
oratory, California Institute of Technology (email:
abhishek.s.cauligi@jpl.nasa.gov). sors and their existing real-time mapping systems to create
4202
rpA
2
]OR.sc[
1v98220.4042:viXralocal maps. We represent these maps using a specialized 2D II. TECHNICALBACKGROUND
version of Neural Radiance Fields (NeRFs), meta-initialized
on similar mapping data to accelerate the learning process. A. Related Work
Importantly, our approach supports heterogeneous multi-
Existingmappingimplementationsrelyprimarilyonmaps
agent systems where robots may have different sensor con-
generated using on-board sensors through Simultaneous Lo-
figurations and capabilities. Federated learning is employed
calization and Mapping (SLAM) [14], [15] or real-time
to merge the trained NeRF parameters from each robot,
approaches[16].Thesemapsinformplanningsystemsabout
creatingaunifiedglobalmaprepresentationatacentralbase
terrain traversability and provide elevation data, playing
station. This global model is distributed back to the robots
a crucial role in path planning and navigation. However,
forcontinuousrefinement,enablingeffectivemapgeneration
in cooperative multi-agent scenarios, a single agent’s map
with few-shot or even one-shot communication rounds [4],
offers limited situational awareness. Constructing a global
[5], particularly when combined with local post-processing.
map by merging individual local maps could significantly
To evaluate our approach, we leverage the availability
improvemissionexecution.Thisapproachprovidesenhanced
of Earth-based mapping datasets for meta-training. These
situational awareness by offering a broader perspective of
datasets often originate from sources such as autonomous
the environment, expanding the knowledge of each agent
driving platforms [6], [7], [8], aerial surveys [9], and
beyond its immediate surroundings. Additionally, it supports
robotics research [10], providing a wide variety of terrain
optimized path planning, allowing agents to make more
and environmental conditions. This process establishes
informed and efficient decisions.
a robust prior for representing map-like data. We then
However, generating and sharing a global map from local
rigorously test our method’s ability to adapt to out-of-
maps presents unique challenges for multi-agent systems,
distribution maps simulating diverse planetary surfaces.
such as ensuring accurate map alignment in dynamic en-
Crucially, this demonstrates the efficacy of our proposed
vironments, addressing communication constraints, and han-
approach in generalizing to unforeseen and extreme
dling the heterogeneity of sensors and mapping techniques
environments. For validation, we employ datasets from the
among agents.
Athabasca Glacier in Canada [11], with its challenging icy
Learning-based techniques hold significant potential for
terrain, and the DoMars16k dataset [12], which includes
addressing such challenges. Recent works, such as DiNNO
simulated Martian geomorphological features from locations
[17], propose distributed deep neural network training al-
such as Jezero Crater (the Mars 2020 landing site [13]) and
gorithms for multi-robot collaboration. DiNNO builds upon
Oxia Planum (the prospective ExoMars landing site).
the alternating direction method of multipliers (ADMM)
[18] and leverages familiar deep learning tools for efficient
The main contributions of this paper are as follows:
optimization. DiNNO also achieves strong performance in
1) We introduce a method enabling rapid neural network non-convex deep learning tasks within multi-robot systems.
adaptationinextreme,unstructuredenvironments.This However, challenges remain when it comes to representing
approach leverages a 2D NeRF for map learning, with complex scenes with high fidelity and frequent synchroniza-
parameters pre-trained on the KITTI dataset [6] for tion among agents.
swift deployment adaptation.
2) We propose a federated learning approach to train
B. Neural Radiance Fields
multiple agents on local area maps. This approach
facilitates efficient compression of learned network
Neural Radiance Fields (NeRFs) [19] offer a novel ap-
parameters, enabling optimized data transfer back to
proachtocreatingphotorealistic3Drepresentationsfrom2D
ground station operators for future flight missions.
images. At their core, NeRFs rely on deep neural networks
3) Wedemonstratetheefficacyofourproposedapproach
to model a scene’s volumetric density and color distribution.
for multi-agent mapping by evaluating it on both
This enables the simulation of novel viewpoints, even those
image quality metrics (PSNR and SSIM) and a path-
not directly observed during training. Mathematically, a
planning simulation to assess the real-world utility of
NeRF function F : (x,d)− > (c,σ) takes a 3D location
θ
the generated maps.
(x,y,z) and viewing direction d as input and outputs the
To address our contributions, we establish the necessary emitted radiance (color c and intensity σ) at that point.
technical foundation in Section II, discussing concepts such While the original NeRF formulation focuses on rep-
as NeRFs and federated learning. Section III (“Approach”) resenting and rendering 3D scenes, the concept can also
dives into the core of our methodology, providing a high- be elegantly used for 2D images. 2D NeRFs (also known
level overview, a detailed examination of components, the as Coordinate-based multi-layer perceptrons (MLPs) [20])
design of our network architecture, and the implementation leverage similar principles, but instead of modeling volu-
of our federated mapping process. We then rigorously eval- metric density, they represent a 2D image as a continuous
uate our approach in Section IV, presenting key results and function. This function takes image coordinates (x,y) as
theirimplications.Weconclude(SectionV)withasummary input and outputs the corresponding color c (RGB) at that
of our findings and potential avenues for future research. location.C. Mapping with NeRFs leverages a central hypernetwork [26] to generate person-
alized models for each client. These personalized models
Inthefieldofscenerepresentation,neuralmappingutilizes
benefit from shared patterns across the network without
neuralnetworkstolearnintricaterepresentationsofcomplex
directly exposing sensitive data, and the approach decouples
data. This approach is particularly powerful for tasks like
communication costs from model size.
modeling physical spaces or generating images. However,
previous work [21] has shown that neural networks are E. Distributed Mapping
biased to learn lower-frequency features. This spectral bias
A recent paper by Holden et. al. [27] introduces a method
means that directly using (x,y,z,θ,ϕ) as input limits a
for collaboratively training NeRFs across distributed devices
network’s ability to represent high-frequency variations in
without centralizing data. This federated learning approach
colorandgeometryinrenderedsenses.Thesehigh-frequency
buildsasharedNeRFmodelwithoutsharinglocallycaptured
details are crucial for realism, encompassing elements like
images. It also employs low-rank decomposition to further
sharp textures and complex reflections. Further research has
compressmodelupdates,optimizingbandwidthusage.How-
demonstrated that mapping inputs to a higher-dimensional
ever, the performance of such techniques on highly non-
space using high-frequency functions significantly improves
IIDdata,typicalinmulti-agentexploration,remainsanopen
the network’s ability to model data with high-frequency
question.Additionally,integratingagentswithdiversesensor
variations [22], [19]. We refer to Section III-B for imple-
configurations is another potential challenge.
mentation and further details.
Similar results are also shown in [28], demonstrating the
Whilethefieldofneuralmappingisrelativelyunexplored,
potentialoffederatedlearningforlarge-scalescenemodeling
a recently proposed approach called RNR-Map [23] lever-
with NeRFs. This approach offers reduced communication
agesNeRFstoembeda3Denvironmentintoagrid,enabling
costs, training time, and memory requirements compared
imagerenderingforlocalizationandnavigation.Thismapis
to centralized methods. However, some limitations persist,
visually descriptive and generalizes well to changes in the
particularly concerning the performance of local models due
environment.Whileitexcelsatimage-basedlocalizationand
to limited viewpoints and the challenges of dynamic scenes.
navigation tasks, its rendering is limited to observed areas,
Thus, existing research in federated learning for large-
and it may struggle when visual information is ambiguous.
scale scene modeling demonstrates promising results but
D. Federated Learning faces limitations that hinder their direct application to multi-
agent planetary exploration. The ability to handle highly
Federated learning (FL) is a machine learning frame-
non-IID data, where agents may observe drastically differ-
work that allows models to be trained collaboratively across
ent environments, remains a challenge. Additionally, these
decentralized devices, without requiring raw data to leave
methodsoftenlackafocusonaccommodatingdiversesensor
thosedevices[24].Thisprotectsdataprivacywhileenabling
types. Finally, federated learning frameworks can struggle
models to learn new skills from the combined data pool.
with maintaining local model performance when each agent
Instead of transmitting data to a central server, each device
has limited viewpoints.
trains a local model. Only the model parameters are shared,
significantly reducing communication overhead. III. APPROACH
Federated averaging (FedAvg) [24] is a core algorithm in
A. Overview
FL,anditisdefinedtoaggregatelocallytrainedmodelsfrom
To address the challenges outlined in Section II-E, we
participating clients to create a globally optimal model.
introduce a federated learning framework tailored for multi-
We begin with a model initialized with parameters θ. In
agent planetary exploration. Our approach centers on indi-
FedAvg, there are K clients each with a local dataset of n
k
vidualagentsgeneratinglocalmapsusingon-boardmapping,
samples,wherethetotaldatasetsizeisn.Theaveragelossof
the model is represented by θt. During each communication thenlearninglocalmapsusing2DNeRFs.Weemployoffline
meta-trainingusingEarth-based2Dmappingdatatoenhance
round t, local models are trained for a given number of
adaptabilitytonovelplanetaryenvironments.Thisestablishes
epochs (Eq. 1),
a robust prior that enables NeRFs to rapidly learn from
∀k,θ kt+1 =θ t−η∇F k(θ t). (1) limitedlocaldataandviewpoints.Thisstrategyaddressesthe
challengesofbothhighlynon-IIDdataandmaintaininglocal
Afterlocaltraining,theglobalmodelisiterativelyoptimized
model performance. Additionally, by learning underlying
until a convergence criterion is met (Eq. 2). Each model
map representations, our approach allows agents to integrate
contributioncanalsobeweightedwithagivenscalar(default
data from heterogeneous sensor configurations.
is the number of samples present with that client nk.),
n 1) Offline Meta-training : We accelerate 2D NeRF
θt+1
=(cid:88)K n
nkθ k(t+1). (2)
a od ffla ip nt eab mili et ty a-tt ro ainn ie nw
g
po hu at- so ef- ud si is ntr gib aut ti ro an vem rsaa bp is litv yia ma an
p
k=1 dataset.
Other FL approaches are exemplified by Personalized fed- 2) Collaborative Map Building : Agents collaborate to
erated learning (pFL), which offers ways to tailor models actively build a global map within a shared reference
for individual clients. One such approach, pFedHN [25], frame. By exchanging only learned NeRF parameters,Meta Initialization Federated Mapping
Robot 1 PE PP
PE Robot 2 PE Model PP
aggregation
Generated maps MLP/CNN Robot 3 PE PP
Local maps Local networks Local networks Global map
PE : Positional PP :Post processing
encoding
Fig.2:Ourproposedfederatedmappingapproachbeginswithanofflinepreparationstagewhereaneuralnetworkistrainedonanempty(unknown)grid
map and then meta-trained with Reptile on a map dataset for quick adaptation (this is done only once, offline). Next, multiple agents explore within a
global reference frame, generating local area maps. Each agent utilizes a neural network to learn its local map. These learned network parameters are
thensharedwithacentralserverwheremodelaggregationoccurs.Finally,theupdatedjointmodelparameters,nowcontainingglobalmapknowledge,are
distributedbacktoeachrobot.Locally,robotscanfurtherrefine(e.g.removenoise)theglobalmap.
agents protect raw sensor data privacy and minimize Importantly, this pre-training step is distinct from meta-
communication overhead. initialization techniques focused on rapid adaptation; here,
3) Map Refinement: Generated maps undergo an image thegoalistomitigateartifactsinducedbythelargereference
processing step to remove artifacts and fill gaps, en- frame.
hancing their quality and coherence. The network itself takes positionally encoded coordinates
Our map refinement process focuses on two key aspects. asinputandproducesamapimageasoutput.Pixelvaluesin
First, it uses morphological image processing techniques this image represent learned map traversability information.
(e.g. connected elements) to address gaps in the map rep- We train the network by minimizing a Mean Squared Error
resentation by analyzing surrounding geometry. Second, it (MSE) loss between its output map image and ground truth
removes small, isolated objects that likely represent noise images generated onboard the robots:
or artifacts. This improves map clarity and reduces poten- (cid:20) (cid:21)
cos(2πBv)
tial misinterpretations during agent task execution. Fig. 2 γ(v)= , (3)
sin(2πBv)
illustrates the overall approach, while Alg. 1 provides a
pseudocode definition.
wherevrepresentstheinputcoordinates(x,y),B isamatrix
B. Mapping the Unknown ofrandomfrequenciessampledfromaGaussiandistribution
withmean0andvarianceσ2.Varianceσ2controlsthespread
In multi-agent mapping scenarios with a large 2D global
of frequencies, and it is considered a hyperparameter which
reference frame, several challenges arise. Individual robots,
can be changed depending on the task.
withtheirlimitedsensoryrange,gatherdataonlywithintheir
Weutilizetwoinputchannelsforthe2Dcoordinatesanda
local field of view. This leads to incomplete knowledge of
mappingsizeof128toenrichthefeaturespace.Furthermore,
the global map. Additionally, when a neural network learns
the scale parameter set to 10 adjusts the frequency matrix
a map directly from this partial map information, significant
B, influencing the capacity of the network to discern finer
inaccuraciescanarise,especiallyinareastherobotshaveyet
spatial details.
toexplore.Finally,rawcoordinates(x,y)provideinsufficient
information for networks to learn fine-grained details and
C. Meta Initialization
spatial variations within maps.
To address these challenges, we employ a combination To accelerate map learning and improve generalization,
of strategies. First, inspired by Fourier Feature Networks particularly for the diverse terrains expected in space ap-
[22], we transform input coordinates (x,y) into a richer, plications, we employ a meta-initialization strategy. First,
higher-dimensionalrepresentationusingaGaussianencoding we train a 2D NeRF on the previously described empty
scheme(Eq.3).Thisencodingenablesthenetworktocapture map, where the input is the encoded grid. Subsequently,
the intricate spatial details crucial for map representation. we utilize the Reptile meta-learning framework [29] to train
Next, we address the issue of artifacts caused by learning this NeRF on a large dataset of Earth-based traversability
smaller maps within a large reference frame. We pre-train and elevation maps (e.g., from the KITTI dataset [6]). This
the network on an image representing a fully unexplored meta-learning process aims to establish a strong prior for
map (e.g., a white image). This pre-training establishes a representing diverse map-like data, anticipating the variety
baseline for areas the robots have yet to see, preventing the of terrains encountered in space missions. Inspired by prior
network from misinterpreting them and ensuring the map work demonstrating the benefits of meta-initialization for
accurately reflects observed data as it becomes available. image representation [30], we anticipate that this learnedAlgorithm 1 Federated Mapping with Meta-Initialization
Require: M an empty map, M the federated global
0 global
map,D traversabilitymapdataset,F globalreference
trav
frame
Offline Meta-Training
1: Train a 2D NeRF on the empty map
2: θ 0 ←Train(Net,M 0)
3: θ ←MetaTrain(Net,θ 0,D trav)
(b)Corresponding2Dtraversability
(a)AthabascaGlacierlandscape. map. Federated Map Learning
Fig.3:AthabascaGlacier:fromlandscapepictureto2Dmaprepresentation. 4: Initialize: Distribute meta-trained network parameters θ
5: for each agent i in parallel do
initialization enables significantly faster convergence when 6: Explore local area, generating map M i
adapting to new, out-of-distribution maps. 7: θ i ←argmin θL(M i,Net(θ)) ▷ Local network
training
Reptile is an effective first-order meta-learning algorithm.
Itfocusesonfindingmodelinitializationparametersthaten- 8: Send θ i to the central server
able rapid adaptation to new tasks using only a few gradient 9: end for
updates.Thealgorithmworksbyrepeatedlysamplingabatch 10: θ global ← N1 (cid:80)N i=1 n nkθ i ▷ Federated Aggregation
of tasks. For each task, it performs one or more gradient 11: Distribute θ global to each agent
descentstepstoupdatethemodelparameters.Finally,Reptile 12: M global ←Net(θ global) ▷ Generate global map
updatesthemodelinitializationbycalculatingthedifference 13: M global ←RefineMap(M global) ▷ Filter and remove
noise
between the initial parameters and the parameters obtained
aftertheinner-looptaskupdates.Mathematically,theupdate 14: Repeat exploration, training, and aggregation as needed
rule can expressed as:
(cid:88)
θ ←θ−ϵ (θ−∇ L (ϕ )), (4)
θ T T E. Federated Mapping
T
Using the network described in III-D, our federated map-
whereθ representsmodelparameters,T asampledtask,and
ping process begins with learning an unexplored grid (Line
L the loss for task T. ϵ is a step-size akin to a learning
T 2) and meta-training (Line 3). This establishes a robust
rate and ϕ represents the parameters obtained after one (or
T foundation for swift map adaptation. we then initialize each
more) gradient updates on task T.
agent with the meta-trained network parameters (Line 4).
Agentsindependentlyexploretheirenvironmentsandgen-
D. Network Definition
eratelocalmaps(Line6).Theinitializednetworkisusedfor
The network is defined as a basic convolutional archi- map learning through standard training procedures (ADAM
tecture, tailored for 2D implicit mapping. While this can optimizer, MSE loss) as seen in Line 7. Locally trained net-
change, our default configuration consists of four convo- work parameters are then sent to the central server (Line 8),
lutional layers (with kernel size 1, padding 0, input shape wherefederatedaggregation(e.g.FedAvg)combinesthemto
of 400 × 400 and an output dimension of 3) interspersed create an updated global model (Line 10). This new global
with ReLU activations [31] and batch normalization. Each model, encompassing shared map knowledge, is distributed
oftheseconvolutionalblockslearnsspatialfeaturesfromthe backtoallagents(Line11).Then,theupdatedglobalmodel
input, finally producing a 3-dimensional output representing isusedtogenerateaglobalmaprepresentationateachagent
color (RGB). While the convolutional structure is tailored (Line12).Wethenperformatwo-stepprocesstofillingaps
for spatial data, the specific configuration with kernel size 1 and remove artifacts for the global map (Line 13).
andnopaddingmakeseachlayerfunctionallyequivalenttoa Importantly, we focus on few-shot federated learning,
fully-connected(dense)layer.Therefore,inthisspecificcase, aiming for significant map information exchange with min-
the network closely resembles a multi-layer perceptron with imal communication rounds. This process iterates as agents
non-linearities and batch normalization in between layers. continue exploring, leading to continuous refinement of the
This setup offers scalability: the network can range from map representation.
simplelinearlayers(MLP-like)tolargerconvolutionallayers
if a more complex model is needed. The network employs IV. EXPERIMENTS
256 channels, aligning with the dimensionality in positional
A. Datasets
encoding mentioned in the previous section. As we are
aiming to learn implicit representations (image regression), Our evaluation strategy combines real-world Earth-based
the ADAM optimizer [32] and a Mean Squared Error loss datasets for meta-initialization with simulated planetary en-
(MSE) are used for training. vironments for testing out-of-distribution adaptation.Fig.4:Meta-initializationwithReptileenablesfaster2DNeRFconvergenceformapreconstructionfromKITTIdata(farright).Thisisdemonstratedby
comparingarandomlyinitializedmodel(top)anditsmeta-initializedcounterpart(bottom)fromsteps0-4.Eachsteprepresentstwooptimizationiterations.
TABLEI:Comparativeanalysisofinitializationmethodsformaplearning.
Formeta-initialization,weleveragetheKITTIdataset[6].
WedetailthePSNRaftertwoiterationsoftestoptimization,showingthatthe
This extensive dataset was collected in and around the mid- meta-learned initialization (Meta) outclasses other methods. Additionally,
sizecityofKarlsruhe,Germany,aswellasinruralareasand wepresenttheavg.numberofiterationsrequiredfortheothermethodsto
reachtheMeta’sperformancelevelaftertwoiterations.
on highways. It was recorded using an autonomous driv-
ing platform equipped with high-resolution cameras (color Initialization PSNR↑ #itertomatch↓
and grayscale), a Velodyne laser scanner, and a GPS lo-
Random 8.16 68.68±1.06
calization system. KITTI provides rich traversability and Emptymap 9.37 26.98±1.84
elevation maps, along with ground truth information. We Meta 13.30
leveragethisreadilyavailableEarth-baseddataforourmeta-
learning process, aiming to establish a strong prior for
representingmap-likedata.Forourexperiments,wedefinea B. Metrics
train/test/validationsplitof2385,282,and141mapsamples,
We employ two primary image quality metrics to quanti-
respectively.
tatively evaluate our federated mapping approach.
The first, Peak Signal-to-Noise Ratio (PSNR), measures
Totestforadaptability,weuseout-of-distributiondatasets. the raw difference between a reconstructed image (in our
The Athabasca glacier in Canada, with data collected dur- case, a generated map) and a ground truth image. Higher
ing the Exobiology Extant Life Surveyor (EELS) project PSNR values indicate closer similarity, and it is commonly
at JPL [11], provides a unique testbed for our system’s usedtoquantifyreconstructionqualityforimages.However,
ability to handle the complexities of frozen, unexplored it can be less reliable for assessing perceptual image quality.
terrains. EELS is a technology development project aimed Mathematically, PSNR is defined as:
atcreating“snake-like”autonomousroboticsystemscapable
MAX2
of exploring icy planetary bodies. The dataset consists of a PSNR=10∗log I, (5)
large-scalepointcloud,whichweconvertinto2Dtraversabil- 10 MSE
ity/elevation maps. The vast glacier ice fields and crevasses whereMAX isthemaximumpixelvalue,andMSE isthe
I
serve as an Earth analog to simulate the challenges antici- mean squared error between the images.
pated on Europa, an icy moon of Jupiter. Figure 3 illustrates Thesecond,StructuredSimilarityIndex(SSIM)addresses
such a map. Additionally, the DoMars16k dataset [12] of- some limitations of PSNR by considering structural in-
fers a diverse range of simulated Martian geomorphological formation within the image. It measures similarity based
features, including craters, rocks, and dunes. This dataset on luminance, contrast, and structure. SSIM values range
provides a valuable testbed for evaluating our approach’s between -1 and 1, with 1 indicating perfect similarity. It is
generalizationcapabilitiestothedistinctvisualandstructural defined as:
characteristics of the Martian environment.
(2µ µ +c )(2σ +c )
SSIM(x,y)= x y 1 xy 2 , (6)
(µ2 +µ2 +c )(σ2+σ2+c )
This dataset strategy offers two major advantages. First, x y 1 x y 2
we leverage the abundance of Earth-based data for robust wherexandy areimagepatchestobecompared,µ ,µ are
x y
initialization. Second, we rigorously test the federated sys- the mean values of x and y, σ2,σ2 are the variances of x
x y
tem’sabilitytoquicklyadapttonewandpotentiallydifferent and y, σ the covariance between x and y, and c ,c are
xy 1 2
environments to be encountered in future space exploration. constants.(a)FederatedmappingontheAthabascaGlacier(black=passable).SeeFig.5fordetailedprogression.
(b)FederatedmappingonaMartiansurface(brown=passable).SeeFig.5fordetailedprogression.
Fig. 5: Federated map learning results for both the Athabasca Glacier (top row) and a Martian surface (bottom row). For both, the figure progresses as
follows:thefirstfoursubfiguresdisplaythelocalmapslearnedbyindividualagents.Subfigure5showsthegroundtruthglobalmap.Subfigure6presents
therawglobalmapobtainedbycombiningtheagentmapsthroughfederatedlearning.Finally,subfigure7showcasestherefinedglobalmap,highlighting
theimprovementachievedthroughpost-processing.
TABLE II: Federated mapping results on out-of-distribution datasets
Moreover, we evaluate using a path planning metric,
(AthabascaGlacierandMarsSurface),withperformanceassessedthrough
comparing A* paths on true versus learned maps, with PSNR, SSIM, and the F1 score, which is directly tied to path planning
validatedstart/endpoints.Weassesspathviabilityusingtrue efficacyacrossdifferentalgorithms.
positives (TP), false positives (FP), true negatives (TN), and
AthabascaGlacier MarsSurface
false negatives (FN). Precision in this context measures the
Algorithm PSNR↑ SSIM↑ F1↑ PSNR↑ SSIM↑ F1↑
accuracy of valid path predictions, while recall evaluates
how well the model identifies all safe paths. The F1 score, FedAdam 5.27 0.31 0.1 4.4 0.25 0.03
FedYogi 10.73 0.44 0.42 9.19 0.39 0.87
combiningprecisionandrecall,providesabalancedmeasure
FedAvg 10.85 0.47 0.95 9.26 0.42 0.94
of the learned map’s utility for autonomous navigation,
focusing on differentiating feasible from infeasible paths.
C. Meta Initialization Results trained parameters using federated optimization, as outlined
In Fig. 4, we provide a qualitative comparison highlight- in Section II-D. This aggregated knowledge is distributed
ing meta-init’s advantages based on 1000 iterations and a backtotheagents.Crucially,thisone-shotscenarioillustrates
learning rate (LR) of 1e−4, across 200 test samples per run. that FedAvg can capture the essential map structure from
The meta-initialized network rapidly captures fine-grained each local agent to a high degree. Furthermore, by applying
map details from the very start of the learning process, relatively simple and efficient map refinement techniques
whiletherandomlyinitializedcounterparttakessignificantly (such as finding and filling gaps, and removing noise),
longer to achieve comparable fidelity. In Table I, the meta- the global map is further enhanced. This refined global
learned network, initiated from an empty map, attains a top map becomes viable for critical downstream tasks like path
averagePSNRof13.30afteronelearningstep,equivalentto planning and exploration.
two forward passes with gradients, on novel test maps. This Table II offers a comprehensive evaluation of federated
performance surpasses that of networks initialized randomly learning algorithms applied to one-shot mapping perfor-
(8.16 PSNR) and with an empty map (9.37 PSNR) under mance. We maintain consistent variables across the board,
identical conditions. Specifically, to reach the meta-trained such as the number of agents (4) and local training epochs
network’sPSNR,randominitializationrequires68.68±1.06 set at 100. While PSNR and SSIM metrics suggest decent
forward passes, while empty map initialization needs 26.98 map reconstruction quality, the standout metric here, given
± 1.84, showcasing the meta-learned network’s superior downstreamtaskssuchaspathplanning,istheF1score.We
efficiency and quick adaptation on new maps. conducted A* simulations on 75 routes, randomly selected
from real terrain, to assess the navigational accuracy of
D. Federated Mapping Results
the learned global maps. This evaluation underscores the
Fig. 5 demonstrates the successful outcome of our fed- practical benefits of our approach, demonstrating significant
erated mapping process with a map from the Athabasca enhancements in path planning capabilities beyond con-
Glacier and of the Martian surface. Here, four agents in- ventional image quality measures. FedAdam [33] applies
dependently explore distinct areas, generating local maps. adaptive learning from Adam to federated settings but did
Their local networks learn these maps (LR = 1e−4), and not produce a quality map (low F1). FedYogi [33], adapting
in a single communication round (R = 1), they share their Yogi’s method for better rate stabilization in FL, showsimproved navigation, notably on Mars data. However, Fe- [12] T. Wilhelm, M. Geis, J. Pu¨ttschneider, T. Sievernich, T. Weber,
dAvg excels in path planning across scenarios as well as in K. Wohlfarth, and C. Wo¨hler, “DoMars16k: A diverse dataset for
weakly supervised geomorphologic analysis on Mars,” Remote Sens-
reconstructed map quality.
ing,vol.12,no.23,p.3981,2020.
[13] V. Verma, M. W. Maimone, D. M. Gaines, R. Francis, T. A. Estlin,
V. CONCLUSION S.R.Kuhn,G.R.Rabideau,S.A.Chien,M.McHenry,E.J.Graser,
A. L. Rankin, and E. R. Thiel, “Autonomous robotics is driving
In this paper, we introduce a federated multi-agent map-
Perseverance rover’s progress on Mars,” Science Robotics, vol. 8,
ping strategy for space exploration robotics, utilizing 2D no.80,pp.1–12,2023.
NeRF for efficient and detailed map creation. This method [14] A.R.Khairuddin,M.S.Talib,andH.Haron,“Reviewonsimultaneous
localizationandmapping(SLAM),”inInt.Conf.onControlSystem,
supports rapid adaptation and skill acquisition in diverse
ComputingandEngineering,2015.
environments through meta-initialization and collaborative [15] S.Thrun,W.Burgard,andD.Fox,ProbabilisticRobotics.MITPress,
learning. Validation on mission-like datasets confirms its ef- 2005.
[16] T. Miki, L. Wellhausen, R. Grandia, F. Jenelten, T. Homberger, and
fectiveness. Future work includes expanding to 3D mapping
M. Hutter, “Elevation mapping for locomotion and navigation using
for enhanced detail, personalizing learning for specific rover GPU,”inIEEE/RSJInt.Conf.onIntelligentRobots&Systems,2022.
needs, and integrating inpainting and occupancy prediction [17] J. Yu, J. A. Vincent, and M. Schwager, “DiNNO: Distributed neural
network optimization for multi-robot collaborative learning,” IEEE
to improve map quality and range.
RoboticsandAutomationLetters,vol.7,no.2,pp.1896–1903,2022.
[18] S.Boyd,N.Parikh,E.Chu,B.Peleato,andJ.Eckstein,“Distributed
ACKNOWLEDGMENT optimization and statistical learning via the alternating direction
methodofmultipliers,”FoundationsandTrendsinMachineLearning,
The research was carried out in part at the Jet Propulsion
vol.3,no.1,pp.1–122,2011.
Laboratory, California Institute of Technology, under a con- [19] B.Mildenhall,P.P.Srinivasan,M.Tancik,J.T.Barron,R.Ramamoor-
tractwiththeNationalAeronauticsandSpaceAdministration thi,andR.Ng,“NeRF:representingscenesasneuralradiancefieldsfor
viewsynthesis,”CommunicationsoftheACM,vol.65,no.1,pp.99–
(80NM0018D0004). The authors thank Preston Culbertson,
106,2021.
Jean-PierredelaCroix,GeorgiosGeorgakis,ShehryarKhat- [20] V. Sitzmann, J. N. P. Martel, A. W. Bergman, D. B. Lindell, and
tak, Mike Paton, Jakob Eg Larsen and Niels H. Pontoppidan G.Wetzstein,“Implicitneuralrepresentationswithperiodicactivation
functions,”inConf.onNeuralInformationProcessingSystems,2020.
for their discussions during the development of this work.
[21] N.Rahaman,A.Baratin,D.Arpit,F.Draxler,M.Lin,F.Hamprecht,
Y.Bengio,andA.Courville,“Onthespectralbiasofneuralnetworks,”
REFERENCES inInt.Conf.onMachineLearning,2019.
[22] M. Tancik, P. P. Srinivasan, B. Mildenhall, S. Fridovich-Keil,
[1] M. J. Schuster, M. G. Mu¨ller, S. G. Brunner, H. Lehner, and oth-
N. Raghavan, U. Singhal, R. Ramamoorthi, J. Barron, and R. Ng,
ers, “The ARCHES space-analogue demonstration mission: Towards
“Fourier features let networks learn high frequency functions in low
heterogeneousteamsofautonomousrobotsforcollaborativescientific
dimensional domains,” in Conf. on Neural Information Processing
sampling in planetary exploration,” IEEE Robotics and Automation
Systems,2020.
Letters,vol.5,no.4,pp.5315–5322,2020.
[23] O. Kwon, J. Park, and S. Oh, “Renderable neural radiance map for
[2] F.Rossi,M.Saboia,andJ.Krishnamoorthy,VanderHook,“Proximal
visual navigation,” in IEEE Conf. on Computer Vision and Pattern
explorationofVenusvolcanismwithteamsofautonomousbuoyancy-
Recognition,2023.
controlledballoons,”ActaAstronautica,vol.208,no.2,pp.389–406,
[24] H.B.McMahan,E.Moore,D.Ramage,S.Hampson,andB.Aguera
2023.
y Arcas, “Communication-efficient learning of deep networks from
[3] J.-P. de la Croix, F. Rossi, R. Brockers, D. Aguilar, K. Albee,
decentralizeddata,”inAI&Statistics,2017.
E.Boroson,A.Cauligi,J.Delaune,andothers,“Multi-agentautonomy
[25] A. Shamsian, A. Navon, E. Fetaya, and G. Chechik, “Personalized
forspaceexplorationontheCADRELunartechnologydemonstration
federated learning using hypernetworks,” in Int. Conf. on Machine
mission,”inIEEEAerospaceConference,2024.
Learning,2021.
[4] Y. Park, D.-J. Han, D.-Y. Kim, J. Seo, and J. Moon, “Few-round
[26] V.Chauhan,S.Molaei,D.Clifton,P.Lu,andJ.Zhou,“Abriefreview
learning for federated learning,” in Conf. on Neural Information
ofhypernetworksindeeplearning,”2023.
ProcessingSystems,2021.
[27] L.Holden,F.Dayoub,D.Harvey,andT.-J.Chin,“FederatedNeural
[5] Y.Zhou,G.Pu,X.Ma,X.Li,andD.Wu,“Distilledone-shotfederated RadianceFields,”2023. Availableathttps://arxiv.org/pdf/
learning,”2021. Availableathttps://arxiv.org/pdf/2009. 2305.01163.pdf.
07999.pdf.
[28] T. Suzuki, “Federated learning for large-scale scene modeling with
[6] A.Geiger,P.Lenz,C.Stiller,andR.Urtasun,“Visionmeetsrobotics: Neural Radiance Fields,” 2023. Available at https://arxiv.
TheKITTIdataset,”Int.JournalofRoboticsResearch,vol.32,no.11, org/pdf/2309.06030.pdf.
pp.1231–1237,2013.
[29] A. Nichol and J. Schulman, “Reptile: a scalable metalearning algo-
[7] J. Geyer, Y. Kassahun, M. Mahmudi, X. Ricou, R. Durgesh, A. S. rithm,” 2018. Available at https://arxiv.org/pdf/1803.
Chung,L.Hauswald,V.H.Pham,M.Mu¨hlegg,S.Dorn,etal.,“A2d2: 02999.pdf.
Audi autonomous driving dataset,” 2020. Available at https://
[30] M.Tancik,B.Mildenhall,T.Wang,D.Schmidt,P.P.Srinivasan,J.T.
arxiv.org/pdf/2004.06320.pdf.
Barron,andR.Ng,“Learnedinitializationsforoptimizingcoordinate-
[8] P.Sun,H.Kretzschmar,X.Dotiwalla,A.Chouard,V.Patnaik,P.Tsui,
basedneuralrepresentations,”inIEEEConf.onComputerVisionand
J.Guo,Y.Zhou,Y.Chai,B.Caine,etal.,“Scalabilityinperception
PatternRecognition,2021.
for autonomous driving: Waymo Open Dataset,” in IEEE Conf. on
[31] A. B. Agarap, “Deep learning using rectified linear units (ReLU),”
ComputerVisionandPatternRecognition,2020. 2018. Available at https://arxiv.org/pdf/1803.08375.
[9] G.-S. Xia, J. Hu, F. Hu, B. Shi, X. Bai, Y. Zhong, L. Zhang, and pdf.
X. Lu, “AID: A benchmark data set for performance evaluation of
[32] D.P.KingmaandJ.L.Ba,“Adam:Amethodforstochasticoptimiza-
aerial scene classification,” IEEE Transactions on Geosciences and tion,”inInt.Conf.onLearningRepresentations,2015.
RemoteSensing,vol.55,no.7,pp.3965–3981,2011.
[33] S. Reddi, Z. Charles, M. Zaheer, Z. Garrett, K. Rush, J. Konecˇny`,
[10] Y.Tian,Y.Chang,L.Quang,A.Schang,C.Nieto-Granda,J.P.How,
S. Kumar, and H. B. McMahan, “Adaptive federated optimization,”
and L. Carlone, “Resilient and distributed multi-robot visual slam: 2021. Available at https://arxiv.org/pdf/2003.00295.
Datasets,experiments,andlessonslearned,”2023. pdf.
[11] R. Thakker, M. Paton, B. Jones, G. Daddi, R. Royce, M. R. Swan,
M.Swan,andothers,“Toboldlygowherenorobotshavegonebefore
- part 4: NEO autonomy for robustly exploring unknown, extreme
environmentswithversatilerobots,”inAIAAScitechForum,2024.