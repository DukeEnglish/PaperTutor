[
    {
        "title": "ALOHa: A New Measure for Hallucination in Captioning Models",
        "authors": "Suzanne PetrykDavid M. ChanAnish KachinthayaHaodi ZouJohn CannyJoseph E. GonzalezTrevor Darrell",
        "links": "http://arxiv.org/abs/2404.02904v1",
        "entry_id": "http://arxiv.org/abs/2404.02904v1",
        "pdf_url": "http://arxiv.org/pdf/2404.02904v1",
        "summary": "Despite recent advances in multimodal pre-training for visual description,\nstate-of-the-art models still produce captions containing errors, such as\nhallucinating objects not present in a scene. The existing prominent metric for\nobject hallucination, CHAIR, is limited to a fixed set of MS COCO objects and\nsynonyms. In this work, we propose a modernized open-vocabulary metric, ALOHa,\nwhich leverages large language models (LLMs) to measure object hallucinations.\nSpecifically, we use an LLM to extract groundable objects from a candidate\ncaption, measure their semantic similarity to reference objects from captions\nand object detections, and use Hungarian matching to produce a final\nhallucination score. We show that ALOHa correctly identifies 13.6% more\nhallucinated objects than CHAIR on HAT, a new gold-standard subset of MS COCO\nCaptions annotated for hallucinations, and 30.8% more on nocaps, where objects\nextend beyond MS COCO categories. Our code is available at\nhttps://davidmchan.github.io/aloha/.",
        "updated": "2024-04-03 17:59:36 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.02904v1"
    },
    {
        "title": "ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline",
        "authors": "Yifan XuXiao LiuXinghan LiuZhenyu HouYueyan LiXiaohan ZhangZihan WangAohan ZengZhengxiao DuWenyi ZhaoJie TangYuxiao Dong",
        "links": "http://arxiv.org/abs/2404.02893v1",
        "entry_id": "http://arxiv.org/abs/2404.02893v1",
        "pdf_url": "http://arxiv.org/pdf/2404.02893v1",
        "summary": "Large language models (LLMs) have shown excellent mastering of human\nlanguage, but still struggle in real-world applications that require\nmathematical problem-solving. While many strategies and datasets to enhance\nLLMs' mathematics are developed, it remains a challenge to simultaneously\nmaintain and improve both language and mathematical capabilities in deployed\nLLM systems.In this work, we tailor the Self-Critique pipeline, which addresses\nthe challenge in the feedback learning stage of LLM alignment. We first train a\ngeneral Math-Critique model from the LLM itself to provide feedback signals.\nThen, we sequentially employ rejective fine-tuning and direct preference\noptimization over the LLM's own generations for data collection. Based on\nChatGLM3-32B, we conduct a series of experiments on both academic and our newly\ncreated challenging dataset, MathUserEval. Results show that our pipeline\nsignificantly enhances the LLM's mathematical problem-solving while still\nimproving its language ability, outperforming LLMs that could be two times\nlarger. Related techniques have been deployed to\nChatGLM\\footnote{\\url{https://chatglm.cn}}, an online serving LLM. Related\nevaluation dataset and scripts are released at\n\\url{https://github.com/THUDM/ChatGLM-Math}.",
        "updated": "2024-04-03 17:51:18 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.02893v1"
    },
    {
        "title": "Linear Attention Sequence Parallelism",
        "authors": "Weigao SunZhen QinDong LiXuyang ShenYu QiaoYiran Zhong",
        "links": "http://arxiv.org/abs/2404.02882v1",
        "entry_id": "http://arxiv.org/abs/2404.02882v1",
        "pdf_url": "http://arxiv.org/pdf/2404.02882v1",
        "summary": "Sequence Parallel (SP) serves as a prevalent strategy to handle long\nsequences that exceed the memory limit of a single GPU. However, existing SP\nmethods do not take advantage of linear attention features, resulting in\nsub-optimal parallelism efficiency and usability for linear attention-based\nlanguage models. In this paper, we introduce Linear Attention Sequence Parallel\n(LASP), an efficient SP method tailored to linear attention-based language\nmodels. Specifically, we design an efficient point-to-point communication\nmechanism to leverage the right-product kernel trick of linear attention, which\nsharply decreases the communication overhead of SP. We also enhance the\npractical efficiency of LASP by performing kernel fusion and intermediate state\ncaching, making the implementation of LASP hardware-friendly on GPU clusters.\nFurthermore, we meticulously ensure the compatibility of sequence-level LASP\nwith all types of batch-level data parallel methods, which is vital for\ndistributed training on large clusters with long sequences and large batches.\nWe conduct extensive experiments on two linear attention-based models with\nvarying sequence lengths and GPU cluster sizes. LASP scales sequence length up\nto 4096K using 128 A100 80G GPUs on 1B models, which is 8 times longer than\nexisting SP methods while being significantly faster. The code is available at\nhttps://github.com/OpenNLPLab/LASP.",
        "updated": "2024-04-03 17:33:21 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.02882v1"
    },
    {
        "title": "Cherry on Top: Parameter Heterogeneity and Quantization in Large Language Models",
        "authors": "Wanyun CuiQianle Wang",
        "links": "http://arxiv.org/abs/2404.02837v1",
        "entry_id": "http://arxiv.org/abs/2404.02837v1",
        "pdf_url": "http://arxiv.org/pdf/2404.02837v1",
        "summary": "This paper reveals the phenomenon of parameter heterogeneity in large\nlanguage models (LLMs). We find that a small subset of ``cherry'' parameters\nexhibit a disproportionately large influence on model performance, while the\nvast majority of parameters have minimal impact. This heterogeneity is found to\nbe prevalent across different model families, scales, and types. Motivated by\nthis observation, we propose CherryQ, a novel quantization method that unifies\nthe optimization of mixed-precision parameters. CherryQ identifies and\npreserves the critical cherry parameters in high precision while aggressively\nquantizing the remaining parameters to low precision. Extensive experiments\ndemonstrate the effectiveness of CherryQ. CherryQ outperforms existing\nquantization approaches in terms of perplexity and downstream task performance.\nNotably, our 3-bit quantized Vicuna-1.5 exhibits competitive performance\ncompared to their 16-bit counterparts. These findings highlight the potential\nof CherryQ for enabling efficient deployment of LLMs by taking advantage of\nparameter heterogeneity.",
        "updated": "2024-04-03 16:16:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.02837v1"
    },
    {
        "title": "Retrieving Examples from Memory for Retrieval Augmented Neural Machine Translation: A Systematic Comparison",
        "authors": "Maxime BouthorsJosep CregoFrancois Yvon",
        "links": "http://arxiv.org/abs/2404.02835v1",
        "entry_id": "http://arxiv.org/abs/2404.02835v1",
        "pdf_url": "http://arxiv.org/pdf/2404.02835v1",
        "summary": "Retrieval-Augmented Neural Machine Translation (RAMT) architectures retrieve\nexamples from memory to guide the generation process. While most works in this\ntrend explore new ways to exploit the retrieved examples, the upstream\nretrieval step is mostly unexplored. In this paper, we study the effect of\nvarying retrieval methods for several translation architectures, to better\nunderstand the interplay between these two processes. We conduct experiments in\ntwo language pairs in a multi-domain setting and consider several downstream\narchitectures based on a standard autoregressive model, an edit-based model,\nand a large language model with in-context learning. Our experiments show that\nthe choice of the retrieval technique impacts the translation scores, with\nvariance across architectures. We also discuss the effects of increasing the\nnumber and diversity of examples, which are mostly positive across the board.",
        "updated": "2024-04-03 16:13:29 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.02835v1"
    }
]