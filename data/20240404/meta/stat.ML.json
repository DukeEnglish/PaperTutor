[
    {
        "title": "Gaussian Process Regression with Soft Inequality and Monotonicity Constraints",
        "authors": "Didem KochanXiu Yang",
        "links": "http://arxiv.org/abs/2404.02873v1",
        "entry_id": "http://arxiv.org/abs/2404.02873v1",
        "pdf_url": "http://arxiv.org/pdf/2404.02873v1",
        "summary": "Gaussian process (GP) regression is a non-parametric, Bayesian framework to\napproximate complex models. Standard GP regression can lead to an unbounded\nmodel in which some points can take infeasible values. We introduce a new GP\nmethod that enforces the physical constraints in a probabilistic manner. This\nGP model is trained by the quantum-inspired Hamiltonian Monte Carlo (QHMC).\nQHMC is an efficient way to sample from a broad class of distributions. Unlike\nthe standard Hamiltonian Monte Carlo algorithm in which a particle has a fixed\nmass, QHMC allows a particle to have a random mass matrix with a probability\ndistribution. Introducing the QHMC method to the inequality and monotonicity\nconstrained GP regression in the probabilistic sense, our approach improves the\naccuracy and reduces the variance in the resulting GP model. According to our\nexperiments on several datasets, the proposed approach serves as an efficient\nmethod as it accelerates the sampling process while maintaining the accuracy,\nand it is applicable to high dimensional problems.",
        "updated": "2024-04-03 17:09:25 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.02873v1"
    },
    {
        "title": "Guarantees of confidentiality via Hammersley-Chapman-Robbins bounds",
        "authors": "Kamalika ChaudhuriChuan GuoLaurens van der MaatenSaeed MahloujifarMark Tygert",
        "links": "http://arxiv.org/abs/2404.02866v1",
        "entry_id": "http://arxiv.org/abs/2404.02866v1",
        "pdf_url": "http://arxiv.org/pdf/2404.02866v1",
        "summary": "Protecting privacy during inference with deep neural networks is possible by\nadding noise to the activations in the last layers prior to the final\nclassifiers or other task-specific layers. The activations in such layers are\nknown as \"features\" (or, less commonly, as \"embeddings\" or \"feature\nembeddings\"). The added noise helps prevent reconstruction of the inputs from\nthe noisy features. Lower bounding the variance of every possible unbiased\nestimator of the inputs quantifies the confidentiality arising from such added\nnoise. Convenient, computationally tractable bounds are available from classic\ninequalities of Hammersley and of Chapman and Robbins -- the HCR bounds.\nNumerical experiments indicate that the HCR bounds are on the precipice of\nbeing effectual for small neural nets with the data sets, \"MNIST\" and\n\"CIFAR-10,\" which contain 10 classes each for image classification. The HCR\nbounds appear to be insufficient on their own to guarantee confidentiality of\nthe inputs to inference with standard deep neural nets, \"ResNet-18\" and\n\"Swin-T,\" pre-trained on the data set, \"ImageNet-1000,\" which contains 1000\nclasses. Supplementing the addition of noise to features with other methods for\nproviding confidentiality may be warranted in the case of ImageNet. In all\ncases, the results reported here limit consideration to amounts of added noise\nthat incur little degradation in the accuracy of classification from the noisy\nfeatures. Thus, the added noise enhances confidentiality without much reduction\nin the accuracy on the task of image classification.",
        "updated": "2024-04-03 16:58:03 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.02866v1"
    },
    {
        "title": "Adaptive Sampling Policies Imply Biased Beliefs: A Generalization of the Hot Stove Effect",
        "authors": "Jerker Denrell",
        "links": "http://arxiv.org/abs/2404.02591v1",
        "entry_id": "http://arxiv.org/abs/2404.02591v1",
        "pdf_url": "http://arxiv.org/pdf/2404.02591v1",
        "summary": "The Hot Stove Effect is a negativity bias resulting from the adaptive\ncharacter of learning. The mechanism is that learning algorithms that pursue\nalternatives with positive estimated values, but avoid alternatives with\nnegative estimated values, will correct errors of overestimation but fail to\ncorrect errors of underestimation. Here, we generalize the theory behind the\nHot Stove Effect to settings in which negative estimates do not necessarily\nlead to avoidance but to a smaller sample size (i.e., a learner selects fewer\nof alternative B if B is believed to be inferior but does not entirely avoid\nB). We formally demonstrate that the negativity bias remains in this set-up. We\nalso show there is a negativity bias for Bayesian learners in the sense that\nmost such learners underestimate the expected value of an alternative.",
        "updated": "2024-04-03 09:15:38 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.02591v1"
    },
    {
        "title": "Convergence Analysis of Flow Matching in Latent Space with Transformers",
        "authors": "Yuling JiaoYanming LaiYang WangBokai Yan",
        "links": "http://arxiv.org/abs/2404.02538v1",
        "entry_id": "http://arxiv.org/abs/2404.02538v1",
        "pdf_url": "http://arxiv.org/pdf/2404.02538v1",
        "summary": "We present theoretical convergence guarantees for ODE-based generative\nmodels, specifically flow matching. We use a pre-trained autoencoder network to\nmap high-dimensional original inputs to a low-dimensional latent space, where a\ntransformer network is trained to predict the velocity field of the\ntransformation from a standard normal distribution to the target latent\ndistribution. Our error analysis demonstrates the effectiveness of this\napproach, showing that the distribution of samples generated via estimated ODE\nflow converges to the target distribution in the Wasserstein-2 distance under\nmild and practical assumptions. Furthermore, we show that arbitrary smooth\nfunctions can be effectively approximated by transformer networks with\nLipschitz continuity, which may be of independent interest.",
        "updated": "2024-04-03 07:50:53 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.02538v1"
    },
    {
        "title": "Masked Completion via Structured Diffusion with White-Box Transformers",
        "authors": "Druv PaiZiyang WuSam BuchananYaodong YuYi Ma",
        "links": "http://arxiv.org/abs/2404.02446v1",
        "entry_id": "http://arxiv.org/abs/2404.02446v1",
        "pdf_url": "http://arxiv.org/pdf/2404.02446v1",
        "summary": "Modern learning frameworks often train deep neural networks with massive\namounts of unlabeled data to learn representations by solving simple pretext\ntasks, then use the representations as foundations for downstream tasks. These\nnetworks are empirically designed; as such, they are usually not interpretable,\ntheir representations are not structured, and their designs are potentially\nredundant. White-box deep networks, in which each layer explicitly identifies\nand transforms structures in the data, present a promising alternative.\nHowever, existing white-box architectures have only been shown to work at scale\nin supervised settings with labeled data, such as classification. In this work,\nwe provide the first instantiation of the white-box design paradigm that can be\napplied to large-scale unsupervised representation learning. We do this by\nexploiting a fundamental connection between diffusion, compression, and\n(masked) completion, deriving a deep transformer-like masked autoencoder\narchitecture, called CRATE-MAE, in which the role of each layer is\nmathematically fully interpretable: they transform the data distribution to and\nfrom a structured representation. Extensive empirical evaluations confirm our\nanalytical insights. CRATE-MAE demonstrates highly promising performance on\nlarge-scale imagery datasets while using only ~30% of the parameters compared\nto the standard masked autoencoder with the same model configuration. The\nrepresentations learned by CRATE-MAE have explicit structure and also contain\nsemantic meaning. Code is available at https://github.com/Ma-Lab-Berkeley/CRATE .",
        "updated": "2024-04-03 04:23:01 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.02446v1"
    }
]