All You Need is Resistance: On the Equivalence of Effective Resistance
and Certain Optimal Transport Problems on Graphs
Sawyer Robertson∗, Zhengchao Wan†, and Alexander Cloninger˚†
April 24, 2024
Abstract
The fields of effective resistance and optimal transport on graphs are filled with rich connections to
combinatorics, geometry, machinelearning, andbeyond. Inthisarticleweputforthaboldclaim: thatthe
two fields should be understood as one and the same, up to a choice of p. We make this claim precise
by introducing the parameterized family of p-Beckmann distances for probability measures on graphs and
relate them sharply to certain Wasserstein distances. Then, we break open a suite of results including
explicit connections to optimal stopping times and random walks on graphs, graph Sobolev spaces, and
a Benamou-Brenier type formula for 2-Beckmann distance. We further explore empirical implications in
the world of unsupervised learning for graph data and propose further study of the usage of these metrics
where Wasserstein distance may produce computational bottlenecks.
Keywords: effective resistance, optimal transport, graph Laplacians, convex optimization, random walks
MSC: 65K10, 05C21, 90C25, 68R10, 05C50
Contents
1 Introduction and notation 2
1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
1.2 Outline of this paper . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
1.3 Related work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
1.4 Mathematical background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
2 General properties of the Beckmann problem 8
2.1 Duality theory for the p-Beckmann problem . . . . . . . . . . . . . . . . . . . . . . . . . . 8
2.2 Comparing p-Beckmann and p-Wasserstein distances . . . . . . . . . . . . . . . . . . . . . 9
2.3 Worked examples: Paths and trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
3 The 2-Beckmann problem: Three perspectives 13
3.1 Effective resistance between measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
3.2 Sobolev norms and a graph Benamou-Brenier formula . . . . . . . . . . . . . . . . . . . . . 18
3.3 A linearized optimal transportation distance . . . . . . . . . . . . . . . . . . . . . . . . . . 20
4 Acknowledgements 24
A Proofs 29
A.1 Proofs from section 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
A.2 Proofs from section 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
∗Department of Mathematics, University of California, San Diego
†Halıcıo˘glu Data Science Institute, University of California, San Diego
1
4202
rpA
32
]CO.htam[
1v16251.4042:viXra1 Introduction and notation
1.1 Introduction
Thetheory ofoptimal transportation (OT),which tracesits rootsto the Mongeformulation asearlyas 1781
[56] as well as the Kantorovich relaxation articulated in 1942 [41], is typically framed as an optimization
problem for some convex or affine function which measures the cost of mass transportation over all feasible
plans which provide recipes for transporting some mass distribution to another. OT has received significant
attention due to its connections to geometry [85, 33], partial differential equations [7, 30, 29], applied
mathematics [63, 71, 72, 32, 69], and many other fields. For discrete measures and domains in particular,
OT and Wasserstein distance have been used and studied for a variety of purposes including document
retrieval[44],statistics[81,61,11],imageregistration[38],distanceapproximation[75],politicalredistricting
[55, 15, 1], graph neural networks [16, 17, 92], and graph Ollivier-Ricci curvature [83, 4, 70, 59].
When the underlying metric space of the transportation process is a graph, much attention has been
focused on the 1-Wasserstein metric, which can be informally set up as a linear program of the following
form:
# +
ÿ
(1) W pα,βq “ inf π dpi,jq : π P Πpα,βq ,
1 ij
ij
where Πpα,βq consists of the couplings of two generic probability distributions α,β on the nodes of a graph
anddpi,jqistheshortestpathmetriconthevertexsetV (seeDefinition1.3foracompletedescription). Itso
happens on graphs that this metric can also be written in a fashion often termed the Beckmann formulation:
# +
ÿ
(2) W pα,βq “ inf |Jpeq|w : J : E Ñ R, BJ “ α´β
1 e
e
where B is the graph incidence matrix, J is any map on the edges of the graph and which is identified
as a vector in R|E|, and w is the nonnegative weight for edge e P E (see Definition 1.4 for a complete
e
description). This formulation is named after Martin Beckmann who studied dynamic formulations of OT
beginning in the 1950s [5], and whose models for OT in the continuous setting Eq. (2) closely mirrors in a
discrete sense. The variable J is sometimes called a feasbile flow between α and β (see Fig. 1), and as such
Eq. (2) is also sometimes deemed a flow-based formulation for OT on graphs.
Seemingly separately, effective resistance (ER) on graphs has long been studied for its metric properties
between nodes and its connections to many other problems in graph theory. Recall that for two nodes
i,j P V, and corresponding standard basis vectors δ ,δ P R|V|, the ER between them is given by r “
i j ij
pδ ´δ qTL:pδ ´δ q where L: is the Moore-Penrose psuedo inverse of the graph Laplacian. Applications and
i j i j
research on ER include foundational work by Spielman and Srivastava on spectral graph sparsifcation using
ER [76], as well as spectral clustering models leveraging computational advantages of ER solvers [42]. ER
has also been used for computing and studying statistics associated to random walks on graphs [25, 82, 50].
Interestingly, inthecaseofdirectedandconnectiongraphs, theoppositeisthecaseasrandomwalkstatistics
have been used to obtain versions of ER [78, 19]. Moreover, there exist geometric applications involving ER
as an ingredient for defining discrete Ricci curvature [22, 23]. For other references which study and utilize
effective resistance in various contexts, see, e.g., [25, 40, 34, 91, 36, 12, 18, 10].
This paper is built on an observation which seems to have not yet appeared in the field: that effective
resistance, when extended to probability measures on a graph G, can be realized as an OT distance obtained
from a Beckmann-type problem with a 2-norm penalty. The resulting metric, while removed from a conven-
tional coupling-based formulation of OT, is intricately connected to the theory of random walks on graphs,
the graph Laplacian matrix, and graph Sobolev spaces.
2Theorem 1.1 (Informal statement of Theorem 3.4). Let G “ pV,E,wq be a weighted connected graph with
Laplacian matrix L and psuedoinverse L:. Denote the oriented vertex-edge incidence matrix of G by B, and
let α,β be fixed probability measures on V regarded as vectors in R|V|. For 1 ď p ă 8, define B pα,βq by
p
the following convex optimization problem:
# +
ÿ
(3) B pα,βqp “ inf |Jpeq|pw : J : E Ñ R, BJ “ α´β .
p e
ePE
Then it holds:
(a) When p “ 1, B pα,βq “ W pα,βq.
1 1
(b) When p “ 2, B pα,βq “ pα´βqTL:pα´βq.
2
The metric introduced in Theorem 1.1 for p “ 2 is a (squared) norm distance, so its properties and
structures are fundamentally different from the (nonlinear) Wasserstein metric in general. However, this
metric seems to posses a rich array of properties and characterizations which demonstrate strong homophily
with the classical results in OT. This metric also shows promise for use in kernel-based learning methods
for data defined on graphs, and in terms of complexity, is significantly less expensive to compute at scale
compared to the Wasserstein metric.
Our main contributions are summarized as follows.
1. We introduce the notion of p-Beckmann distance between probability measures, and derive various
bounds between p-Beckmann distances and p-Wasserstein distances for measures on general graphs
(e.g., Corollary 2.11).
2. We provide an explicit formula for B on trees (Proposition 2.15).
p
3. We obtain a generalized commute time formula for 2-Beckmann distance, or measure effective resis-
tance, in terms of optimal access times of the simple random walk on a graph (Theorem 3.13).
4. We realize 2-Beckmann distance as a negative Sobolev-type semi-norm distance and use this property
to obtain a Benamou-Brenier type formula for 2-Beckmann distance (Theorem 3.22).
5. We apply 2-Beckmann distance to an unsupervised kernel-based clustering method involving handwrit-
ten digit data, and compare the results with the 2-Wasserstein kernel; and thereby establish empirical
evidence for the usage of a 2-Beckmann kernel on a drop-in basis in place of a 2-Wasserstein kernel
for datasets defined on graphs (Fig. 6).
1.2 Outline of this paper
In Section 1.4, we provide relevant mathematical background and notation.
In Section 2, we delve into the general properties of the p-Beckmann problem, including duality theory
in Section 2.1 and estimates between Beckmann and Wasserstein distances Section 2.2. In Section 2.3, we
highlight some specialized results in the cases of paths and trees.
In Section 3 we focus exclusively in the properties and theory of the 2-Beckmann distance. In Section 3.1
we frame the metric as effective resistance between measures and relate it to optimal stopping times and
access times between probability measures on G. In Section 3.2 we frame the metric as a negative Sobolev-
type seminorm and obtain a graph Bemaou-Brenier-type formula. Finally, in Section 3.3 we apply the
2-Beckmann distance to an unsupervised learning problem and explore various empirical observations and
implications.
Lastly, in Appendix A we provide proofs of the results mentioned in the main component of the paper.
31.3 Related work
In this section we wish to highlight some particularly relevant works on which this paper is based in parts,
and in doing so, better situate the novelty of our contributions in a broader context.
The most relevant investigation of OT on graphs, including regularization and convex duality, appears in
work by Essid and Solomon [28] and further studies in the field can be found in [75, 74, 62, 57, 67, 49, 65].
The introduction of p-Beckmann distances in Section 2 and its study as an effective resistance metric
in Section 3.1 should be understood as extensions of the notion of p-resistances from work of Alamgir
and Luxburg [2] to general probability measures (from the case of nodes, i.e., Dirac measures). Such
generalizations of resistances and their implications in unsupervised models were also considered by Nguyen
and Hamitsuka [60], and Saito and Herbster [68] but only between nodes. The notions of measure access
times and optimal stopping times have been studied at length by Lov´asz, Winkler and Beveridge across
several papers [50, 51, 52, 9, 8].
Separately, the notion of using negative Sobolev distance as a linearization of quadratic Wasserstein
distance was studied by Greengard, Hoskins, Marshall, and Singer in [37] and is a homophilous framework
appearing in the continuous setting. The proof of the Benamou-Brenier-type formula for 2-Beckmann
distance is a direct discretization of the proof appearing in [35]. It is also notable that our model of 2-
Beckmann distance as a negative Sobolev distance on graphs is parallel to the works by Le, T. Nguyen,
Phung, V. A. Nguyen, and Fukumizo and appearing in [46, 47, 48]; but our definitions differ slightly from
theirs. Linearized OT and its usage in the unsupervised setting is also explored by Moosm¨uller and AC [58],
and results therein form a basis for our Theorem 3.25 on linear separation of measures in the 2-Beckmann
metric space.
1.4 Mathematical background
` ˘
Let G “ pV,E,wq be a graph, where V “ t1,2,...,nu is the set of vertices, E Ă V is a set of undirected
2
edges of cardinality m ě 0, and w “ pw q is a choice of real edge weights satisfying w ě 0, w “ w ,
ij i,jPV ij ij ji
and w ą 0 if and only if ti,ju P E. In order to ensure the feasibility of optimal transportation problems and
ij
simplify the expositionin places, we assume thatG is finite, has no multiple edges or loops, and is connected.
For our purposes, a path in G is an ordered sequence of nodes P “ pi ,i ,...,i q such that i „ i for
0 1 k ℓ ℓ`1
0 ď ℓ ď k´1. If P is a path, |P| is the (integral) length of the path, i.e., |P ř| “ k, and |P|
w
is the weighted
length of P, or the sum of the weights of edges it contains; i.e. |P| “ k´1w . For any two nodes
w ℓ“0 i ℓi ℓ`1
i,j P V, Ppi,jq is the set of all paths which begin at i and end at j.
In this paper, we will consider several different metrics on V. A metric on V is a map κ : V ˆV Ñ R
such that
(i) (Nonnegativity) κpi,jq ě 0 for each i,j P V,
(ii) (Definiteness) κpi,jq “ 0 if and only if i “ j,
(iii) (Symmetry) κpi,jq “ κpj,iq for each i,j P V,
(iv) (Triangle inequality) κpi,kq ď κpi,jq`κpj,kq for each i,j,k P V.
WewillprimarilyusevariantsoftheshortestpathmetriconV andthemetricsinducedbyeffectiveresistance.
Definition 1.2. Let 1 ď p ă 8. Define the weighted p-shortest path metric on V by the formula
$ ,
˜ ¸
& kÿ´1 1{p .
(4) d pi,jq “ inf wp : P “ pi “ i ,i ,...,i “ jq P Ppi,jq
p % i i 0 1 k -
ℓℓ`1
ℓ“0
4It is relatively straightforward to verify that d satisfies the properties necessary for a metric on V for
p
each p,w.
We define the Adjacency matrix A P Rnˆn entrywise by
#
w if i „ j
ij
(5) A “ .
ij
0 otherwise
ř
where the notation i „ j means ti,ju P E. For each i P V we define its degree d “ w . We will
i j„i ij
also use the diagonal degree matrix D “ diagpd ,...,d q P Rnˆn and the diagonal edge weight matrix
1 n
W “ diagpw ,...,w q P Rmˆm.
e1 em
For technical purposes, we may ocassionally refer to the index-oriented and bi-oriented edge sets E1 and
E2, respectively, defined below:
(6) E1 “ tpi,jq : i,j P V,i „ j,i ă ju
(7) E2 “ tpi,jq,pj,iq : i,j P V,i „ ju.
We define the incidence matrix B P Rnˆm, with rows indexed by V and columns indexed by E1, by the
formula:
$
’ &1 if e
j
“ pi,¨q
(8) B i,e j “ ’ %´1 if e j “ p¨,iq .
0 otherwise
We also occasionally use the matrix Br P Rnˆ2m, with rows indexed by V and columns indexed by E2, defined
by an identical formula as in Eq. (8). We define the Laplacian matrix L by the formula L “ D ´ A, or
L “ BWBT. Note that Br WĂ Br T “ 2L, where WĂ P R2mˆ2m is the diagonal matrix of edge weights of E2.
We recall that L is symmetric, positive semi-definite, and has a set of nonnegative eigenvalues
(9) 0 “ λ ď λ ď ... ď λ .
0 1 n
“ ‰
We use Λ “ diagpλ ,λ ,...,λ q P Rnˆn for the diagonal matrix of eigenvalues, and U “ u u ¨¨¨ u
0 1 n 1 2 n
for the respective orthonormal eigenvectors of L. The spectral decomposition of L is given by the equation
L “ UΛUT.
For any matrix X P Rℓˆk, we will use the notation X: P Rkˆℓ for its Moore-Penrose psuedoinverse. We
recall that X: is the unique matrix satisfying the following four properties [6]:
(i) XX:X “ X
(ii) X:XX: “ X:
(iii) pXX:qT “ XX:
(iv) pX:XqT “ X:X
where p¨qT indicates matrix transpose.
In the case of the Laplacian matrix L, we have
L: “ UΛ´1UT
where, with an abuse of notation, we write
(10) Λ´1 “ diagpλ “ 0,λ´1,...,λ´1q P Rnˆn.
0 1 n
5Similarly, we write L´1{2 “ UΛ´1{2UT.
For a finite set S, we define ℓ pSq to be the linear space of functions f : S Ñ R with the standard
2
Euclidean inner product xf,gy “ gTf. We identify ℓ pVq with Rn and ℓ pE1q with Rm, respectively.
ℓ2pSq 2 2
For a vector x P Rn and 1 ď p ă 8, we define the vector p-norm by
˜ ¸
ÿn 1{p
}x} “ |x |p .
p i
i“1
For any finite set S, in a similar manner as before, we can define ℓ pSq to be the linear linear space of
p
functions f : S Ñ R with the norm }¨} . If in some cases we wish to refer simply to the linear space of
p
functions on S, such as when we employ multiple norms at once, we use the notation ℓpSq and specify the
norm or inner product in context.
If J P ℓpE1q, then we can weight the norm }¨} by the edge weights as follows:
p
˜ ¸
ÿ 1{p
(11) }J} “ |Jpeq|pw ,
w,p e
ePE1
and similarly for ℓpE2q. We will use the subscript of w to indicate the presence of edge weights.
As a matter of notation, functions in ℓpVq will be denoted with lowercase Latin and Greek letters (in the
case of measures), and functions in ℓpE1q and ℓpE2q will be denoted with uppercase Latin letters.
Note that the matrices B, BT, and L act on their respective function spaces by matrix multiplication.
We summarize their pointwise formulas below.
ÿ ÿ
(12) pBJqpiq “ Jpeq´ Jpeq, i P V,J P ℓpE1q
ePE1:e“pi,¨q ePE1:e“p¨,iq
(13) pBTfqpe “ pi,jqq “ fpiq´fpjq, e P E1,f P ℓpVq
ÿ
(14) pLfqpiq “ pfpiq´fpjqqw , i P V,f P ℓpVq
ij
j„i
It is worth noting that in some contexts (e.g., [27, 26]), Bp¨q and BTp¨q are considered the graph equivalents
of the divergence and gradient operators, respectively. We will also occasionally use the Dirichlet energy
functional for f P ℓpVq, defined by the quadratic form of the Laplacian matrix:
ÿ
(15) fTLf “ w pfpiq´fpjqq2 “ }BTf}2
ij w,2
pi,jqPE1
We define the probability measure simplex PpVq by the set
# +
ÿ
(16) PpVq :“ α P ℓpVq : α ě 0, αpiq “ 1 .
iPV
For i P V, δ is the Dirac or unit measure at node i, identified with the i-th standard basis vector in Rn.
i
The primary objects of study for this paper are two different optimal transportation distances between
probability measures on V. The first, which is classical and extensively studied on graphs, is p-Wasserstein
distance.
Definition 1.3. Let α,β P PpVq, 1 ď p ă 8, and k any metric on V. Define the set of transportation
couplings between α and β, denoted Πpα,βq, by the following set
␣ (
(17) Πpα,βq “ π P Rnˆn : π ě 0,π1 “ α,1Tπ “ βT ,
6α α
β β
(a) p “1, B pα,βq“W pα,βq«9.3. (b) p “2, W pα,βq«1.225,
1 1 2
B pα,βq«1.499
2
Figure 1: A side-by-side comparison of optimal flows for the 1-Beckmann and 2-Beckmann problems on a
4ˆ4 hexagonal lattice graph. The masses of α,β at each node are rendered proportionally to opacity; and
similarly the optimal flow values at each edge are rendered proportionally to opacity. The arrows indicate
orientationoftheflowvalue; i.e., ˝ Ñ ˝1 iftheoptimalflowJ satisfiesJp˝,˝1q ą 0and˝ Ð ˝1 ifJp˝,˝1q ă 0.
where 1 P Rn is the vector containing all ones. We define the pk,pq-Wasserstein distance between two
probability measures , denoted W pα,βq by the following optimization problem:
k,p
$ ,
˜ ¸
& ÿ 1{p .
(18) W pα,βq “ inf π kpi,jqp : π P Πpα,βq .
k,p % ij -
i,jPV
As a matter of convention, when k “ d , that is, the weighted 1-shortest-path metric, we write W “
1 d1,p
W . The second optimal mass transportation distance is much less studied in its own right except in the
p
cases of p “ 1 and to a seemingly much lesser extent, p “ 2.
Definition 1.4. Let 1 ď p ă 8 and α,β P PpVq. Define the set of feasible edge flows between α and β,
denoted Jpα,βq, by the affine region
␣ (
(19) Jpα,βq “ J P ℓ pE1q : BJ “ α´β .
2
Then thep-Beckmann distancebetween α,β, denoted B pα,βqis given by the following constraintednorm
p
optimization problem:
(20) B pα,βq “ inft}J} : J P Jpα,βqu
p w,p
Note that Jpα,βq ‰ ∅ for any α,β since the column space of B is exactly the mean zero functions
on V. The p-Wasserstein and p-Beckmann problems are essentially two different perspectives on optimal
transportation for measures on graphs. The “Wasserstein philosophy” being that mass transportation is
tracked between all pairs of nodes, and is accounted according to dp. We can also think of this philosophy
ij
as one of mass teleportation- the primal variable, or coupling, does not reveal how mass π moves from i to
ij
j, only that it did so along a shortest path somewhere, or a combination of shortest paths. The “Beckmann
philosophy” is the viewpoint that mass must move along edges and the transportation should be accounted
7intermsofedgeflows,whicharereallyjustsignedmassvaluesoneachorientededge. Inthisformulation,the
penaltylieson|Jpeq|p,sotransportationflowscanoftenbenon-sparse,oroccuralongweightedcombinations
of shortest and non-shortest paths. Comparisons of optimal flows for values p “ 1,2 in an example setting
are shown in Fig. 1.
Remark 1.5. A slightly different way to formulate Definition 1.4 would be through E2 with a nonnegativity
constraint. That is, let
! )
r
(21) J2pα,βq “ J P ℓ pE2q : J ě 0,BJ “ α´β, .
2
and then,
␣ (
(22) B pα,βq “ inf }J} : J P J2pα,βq .
p w,p
It is not hard to show that these two formulations arrive at the same value. Definition 1.4 simply allows
for signed flows; for example, a flow value of ´1 along the oriented edge p1,2q represents one unit of mass
transported from node 2 to node 1. We opt to drop the nonnegativity constraint for this paper and focus
on the former formulation as it simplifies the calculations slightly, but we may have occassion to use this
formulation instead.
In the Proposition below, we summarize two relevant properties of W and B .
p p
Proposition 1.6. Let α,β P PpVq.
(i) The objective functions for both W pα,βq and B pα,βq are convex for all 1 ď p ă 8, and the infima
p p
are always achieved.
(ii) The objective for B pα,βq is strictly convex for p ą 1. The infimum is always achieved and is unique
p
in the case p ą 1.
(iii) W and B pα,βq define metrics on PpVq.
p p
Proofs of items (i) and (ii) are straightforward since the objectives are defined either by affine functions
or common norms whose convexity properties are well-understood. For (iii), a proof for W can be found in
p
[62, Ch. 2], and the case of B is relatively straightforward.
p
2 General properties of the Beckmann problem
In this section, we look at a few interesting properties of the Beckman problem B pα,βq for general 1 ď
p
p ă 8. In Section 2.1 we derive the Lagrangian dual to the p-Beckmann problem, in Section 2.2 we obtain
bounds that relate certain Beckmann and Wasserstein distances, and finally, in Section 2.3, we work through
some example results on paths and trees to highlight examples of Wasserstein and Beckmann distances.
2.1 Duality theory for the p-Beckmann problem
In this subsection we study the convex duality of the p-Beckmann problem. In [2] Alamgir and Luxburg intro-
ducedformulationsofp-resistances,thatis,generalizationsofeffectiveresistanceobtainedbyBeckmann-type
min cost flow problems penalized by a p-norm. They studied the primal and dual forms of these problems,
and thereby obtained so-called potential-based formulations of the resistance problems. As described in
Section 1.3, the results presented in this section may be considered extensions of the results concerning
p-resistances to the case of general probability measures; namely, we understand the p-resistance between
generic nodes i,j to be p-Beckmann distance between Dirac measures at i,j. In Theorem 2.1 we obtain the
dual formulation of the p-Beckmann optimization problem, and thus generalize the Kantorovich-Rubenstein
duality on graphs to all 1 ď p ă 8 (see Remark 2.3).
8Theorem 2.1. Let α,β P PpVq and 1 ă p ă 8 be fixed. Let q be the conjugate of p so that 1 ` 1 “ 1.
p q
Then the dual to the p-Beckmann problem, given by
␣ (
(23) B pα,βq “ inf }J} : J P ℓpE1q,BJ “ α´β ,
p w,p
is given by the maximization problem
! › › )
(24) B pα,βq “ sup φTpα´βq : φ P ℓpVq,› BTφ› ď 1 ,
p w1´q,q
and strong duality holds. In the special case of p “ 1 and q “ 8, we have
␣ ( ! › › )
(25) B pα,βq “ inf }J} : J P ℓpE1q,BJ “ α´β “ sup φTpα´βq : φ P ℓpVq,› BTφ› ď 1
1 w,1 w´1,8
We defer the proof to Appendix A.1.
Remark 2.2. If we specialize to the case where the edge weights are all unit value; i.e., G is unweighted,
then the weights can be dropped from the preceding results. In particular, the dual norm to }¨} is simply
p
}¨} and
q
␣ ( ! › › )
(26) B pα,βq “ inf }J} : J P ℓpE1q,BJ “ α´β “ sup φTpα´βq : φ P ℓpVq,› BTφ› ď 1
p p q
Remark 2.3. The case p “ 1 and q “ 8 is the conventional Kantorovich-Rubenstein duality on graphs [89],
which can be more conventionally written as
# +
ÿ ␣ (
(27) inf |Jpeq|w : J P ℓpE1q,BJ “ α´β “ sup φTpα´βq : φ P ℓpVq,}φ} ď 1
e Lip
ePE1
where the Lipschitz seminorm }φ} “ }BTφ} on ℓpVq is defined by
Lip w´1,8
|φpiq´φpjq| |φpiq´φpjq|
(28) }φ} “ max “ max .
Lip
dpi,jq i„j w ij
Note also that this duality occurs in a homophilous manner for Beckmann’s minimal flow problem in the
continuous setting [71, Sec 4.2], which is the namesake for the minimal flow formulations on graphs.
2.2 Comparing p-Beckmann and p-Wasserstein distances
In this section, we establish some bounds between B and W in certain situations. Section 2.2.1 introduces
p p
a technique for obtaining an edge flow from a given coupling with some control on the cost, and uses it to
derive elementary bounds for general p; and in Section 2.2.2 we focus on the case of W and obtain sharp
1
estimates related to B , the latter of which is of particular interest in the ensuing sections.
2
2.2.1 From coupling to flow
An essential ingredient in comparing the optimal values of transportation metrics is having the ability to
convert a coupling π to a feasible edge flow J, and vice-versa. In this subsection we will make use of the
bi-oriented edge flow formulation of B , which was discussed in Remark 1.5.
p
Definition 2.4. Let i,j P V. Let P P Ppi,jq be a path between i,j. Write P “ pi “ i ,i ,...,i “ jq.
0 1 k
Define
kÿ´1
(29) I “ δ P ℓpE2q.
P pi ℓ,i ℓ`1q
ℓ“0
9Proposition 2.5. Let α,β P PpVq, 1 ď p ă 8, and suppose π P Πpα,βq. For each pair of nodes i,j P V
with i ‰ j, let P
ij
P Ppi,jq be a fixed path between i,j. Define the edge flow Jπ “ Jπ,pP ijq P ℓpE2q by the
expression
ÿ
(30) Jπ “ π I
ij P
ij
i‰jPV
Then Jπ is a feasible flow for B pα,βq, i.e., Jπ ě 0 and BJπ “ α´β, and the following estimate holds:
p
ÿ
(31) }Jπ} ď π }I } .
w,p ij P w,p
ij
i,jPV
We include a proof in Appendix A.1. We can use Proposition 1.6 to derive at least two estimates which
relate B to W for different choices of k. The first is somewhat brutal, but is informative for p small.
p k,p
Theorem 2.6. Let α,β P PpVq, 1 ď p ă 8, and assume that w ě 1 for each i,j P V such that i „ j.
ij
Then
(32) B pα,βq ď W pα,βqp
p p
Proof. Let π P Πpα,βq be an optimal coupling for W pα,βq. For each i,j, let P P Ppi,jq be a choice of
p ij
path which is minimal in the sense of d 1, and let Jπ “ Jπ,pP ijq be the feasible flow as in Proposition 2.5.
Then
ÿ ÿ
(33) B pα,βq ď }Jπ} ď π }I } ď π d pi,jqp “ W pα,βqp
p w,p ij P w,p ij 1 p
ij
i,jPV i,jPV
since }¨} ď }¨}p provided w ě 1.
w,p w,1 ij
Ifweallowforsomeflexibilitywhenpickingtheunderlyingmetrick ofW , thenwecanprovideatighter
k,p
estimate when W is large.
Theorem 2.7. Let α,β P PpVq, 1 ă p ă 8 and let q be the conjugate of p such that 1 ` 1 “ 1. Then
p q
(34) B pα,βq ď n2{qW pα,βq.
p dp,p
The proof of Theorem 2.7 follows mainly from H¨older’s inequality and Proposition 2.5; we provide the
proof in Appendix A.1. Note in particular that when p “ 2, we have q “ 2 and thus it holds B pα,βq ď
2
nW pα,βq.
d2,2
2.2.2 Estimating from the p “ 1 case
When p “ 1 and the choice of metric is k “ d there is a direct overlap between B and W [62, 28].
1 1 1
Theorem 2.8. Let α,β P PpVq. Then
B pα,βq “ W pα,βq.
1 1
Foraproofofthisresult, werecommendtheexpositionin[62, Ch. 6]. Notethatforp ě 1andJ P ℓpE1q,
we have that since }¨} ď }¨} in general,
p 1
ˆ ˙
}J} “ }W1{pJ} ď }W1{pJ} ď }J} maxw1{p´1 .
w,p p 1 w,1 e
ePE1
Thus if C “ max w1{p´1 we have }J} ď C }J} . If J˚ is an optimal flow for B pα,βq, we have
w,p ePE1 e w,p w,p w,1 1
(35) B pα,βq ď }J˚} ď C }J˚} “ C B pα,βq
p w,p w,p w,1 w,p 1
Therefore, we have the following two estimates for any choice of α,β and p ě 1.
10Corollary 2.9. Let α,β P PpVq and 1 ď p ă 8. Then the following estimates hold:
(36) B pα,βq ď C B pα,βq
p w,p 1
(37) B pα,βq ď C W pα,βq
p w,p 1
Moreover, via similar logic as before, since }¨} ď m1´1{p}¨} on ℓpE1q, where we recall m “ |E|, we
1 p
have for J P ℓpE1q,
p´1
(38) }J} “ }WJ} ď m1´1{p}WJ} ď m1´1{p}W1 } p }J}
w,1 1 p E1 8 w,p
p´1
ThereforeifwesetC “ m1´1{p}W1 } p ,wehave}J} ď C }J} andusingasimilarargument
w,m,p E1 8 w,1 w,m,p w,p
as before, the following corollary holds.
Corollary 2.10. Let α,β P PpVq and 1 ď p ă 8. Then the following estimates hold:
(39) B pα,βq ď C B pα,βq
1 w,m,p p
(40) W pα,βq ď C B pα,βq
1 w,m,p p
An application of this allows us to relate 2-Beckmann distance to W , which we state as a corollary
1
below.
Corollary 2.11. Let α,β P PpVq. Then
(41) B pα,βq ď C W pα,βq ď C C B pα,βq.
2 w,2 1 w,2 w,m,2 2
If in particular the graph is unweighted, then we have that C “ 1 and C “ m1{2, so that
w,2 w,m,2
(42) B pα,βq ď W pα,βq ď m1{2B pα,βq.
2 1 2
Remark 2.12. Note that the bound in Corollary 2.11 is sharp without making additional assumptions on the
structure of G or α,β. Suppose G is a path on n vertices with m “ n´1, then the upper and lower bounds
are achieved, respectively, when we have:
?
(i) α “ δ , β “ δ , so that B pδ ,δ q “ n´1 and W pδ ,δ q “ n´1 so W “ m1{2B .
1 n 2 1 n 1 1 n 1 2
(ii) α “ δ and β “ δ , so that B “ W “ 1.
1 2 2 1
Proofs of these statements could be obtained directly or by way of Proposition 2.13 and Proposition 2.14,
whichwediscussinthenextsubsection. Thisleadstoanas-yetopenquestion: Ifoneconstrainsthestructure
of G or α,β, can the bound in Corollary 2.11 be improved?
2.3 Worked examples: Paths and trees
In this subsection, we specialize to the case of the path graph P and derive explicit formulas for W and B
n p p
so as to illustrate their connections to optimal transportation in the setting of the real line and to elucidate
their differences when p ą 1. We also take a look at B on tree graphs, and obtain a closed-form solution
p
for all 1 ď p ă 8 which generalizes the known formula for 1-Wasserstein distance on trees. Proofs of
Proposition 2.13, Proposition 2.14, and Proposition 2.15 are all included in Appendix A.1.
Let P be the unweighted path graph with n nodes ordered from 1 to n, and oriented edges E1 of the
n ř
form pi,i ` 1q for 1 ď i ď n ´ 1. For α P PpVpP qq, let αp “ n αpiqδ be the empirical measure on
n i“1 i
R induced by α where, with a slight abuse of notation, δ i is the Dirac measure on R at x “ i. Let F αp
be the cumulative distribution function of αp, and let F´1 be its psuedo-inverse or quantile function, i.e.,
αp
F αp´1 ptq “ inftx : F αppxq ě tu for t P r0,1s. The proposition below is an adaptation of the classical inverse
cdf result for W on R to the case of path graphs; for more detail, see, e.g., [64, 71].
p
11αpiq 1 1 0 K peq 1 1
2 2 α 2
i 1 2 3 e p1,2q p2,3q
βpiq 0 1 3 K peq 0 1
4 4 β 4
(a) Illustration of two copies of P with arrows indi- (b)IllustrationoftwocopiesofP witharrowsindicat-
3 3
cating orientation of the edges. Example probability ing orientation of the edges. The edge cdfs K and
α
measuresα,β areshownwithnodecoloropacitypro- K are shown with edge color opacity proportional to
β
portional to mass. value.
3
1
F αppxq
F´1ptq
βp
0.75
2
F´1ptq
αp
0.5
1
0.25
F βppxq
0 0
0 1 2 3 0 0.25 0.5 0.75 1
x t
(c) Plots of the cdfs F αp,F βp of the empirical mea- (d) Plots of the inverse cdfs F αp´1 and F βp´1 of the
sures αp,βp on R. From Proposition 2.14 we have empirical measure αp,βp on R. From Proposition 2.13
B ppα,βqp “0.5p`0.75p. we have W ppα,βqp “1pp0.25q`2pp0.25q`1pp0.5q.
Figure 2: (a)-(b) Illustrations of two measures α,β and their edge cdfs K ,K for the fixed path graph
α β
P . (c)-(d) Plots of the empirical cdfs F and F , as well as their inverses. Note that the shaded regions
3 αp βp
are reflections of each other; and that for p “ 1 their common area is B pα,βq “ W pα,βq. This also
1 1
demonstrates the divergence of the metrics for p ą 1.
Proposition 2.13. Let α,β P PpVpP qq and 1 ď p ă 8. Then the p-Wasserstein distance W pα,βq on P
n p n
is given by
ż ˇ ˇ
1ˇ ˇp
(43) W pα,βqp “ ˇF´1 ptq´F´1 ptqˇ dt.
p αp βp
0
To characterize p-Beckmann distance on P , we introduce a bit more notation. For α P PpVq and an
n
oriented edge e “ pi,i `1q P E1, let K P ℓpE1q be the “edge cdf,” i.e.,
α
ÿ
(44) K pi,i `1q “ αpjq.
α
jďi
Note that, naturally, K αpi,i `1q “ F αppiq.
Proposition 2.14. Let α,β P PpVpP qq and 1 ď p ă 8. Then the p-Beckmann distance B pα,βq on P is
n p n
given by
ż
(45) B ppα,βqp “ }K α´K β}p
p
“ |F αpptq´F βpptq|pdt.
R
12Proposition 2.13 and Proposition 2.14 provide an alternate, albeit circuitous, proof of Theorem 2.8 on
paths by applying a change of variables. This also demonstrates why we do not expect the two families
of metrics to overlap for p ą 1. A worked example of Proposition 2.13 and Proposition 2.14 in action is
illustrated in Fig. 2.
It is also intriguing to note that much in the same way that W , and hence B , is determined explicitly
1 1
on trees (a result which itself has been leveraged in other applications such as computer vision and natural
language processing [79, 53, 90, 80, 31, 45]), B can be determined in an similar manner for general p on
p
trees.
Proposition 2.15. Let T “ pV,E,wq be a weighted tree, α,β P PpVq, and fix 1 ď p ă 8. For an oriented
edge e “ pi,jq P E1, define a generalized version of Eq. (44) by
ÿ
K pe “ pi,jqq “ αpkq,
α
kPV˚pi;eq
where V˚pi;eq Ă V is the set of nodes belonging to the subtree with root i obtained from T by removing
the edge e (and similarly for K ). Then it holds
β
(46) B pα,βq “ }K ´K } .
p α β w,p
3 The 2-Beckmann problem: Three perspectives
This section is focused entirely on B . The foundational premise of this section is that B , while ostensibly
2 2
a simple least squares optimization problem, actually posesses a rich supply of connections and contexts
to other notions that already exist in graph theory. In Section 3.1 we view B as an effective resistance
2
metric between measures, and connect it to the simple random walk on G and optimal stopping times for
measures. InSection3.2, weviewB asanegativeSobolevnormforfunctionsongraphs, andtherebyobtain
2
a Benamou-Brenier type formula for B . Lastly, in Section 3.3, we view B as a linearized variant of W ,
2 2 2
prove a convex separation result, and showcase its potential application in unsupervised learning problems
for graph data.
3.1 Effective resistance between measures
In this subsection we consider B from the perspective of effective resistance. We begin with some sup-
2
plemental background on effective resistance which will be needed, and then proceed with discussion of the
main results.
3.1.1 Background on effective resistance
Definition 3.1. Let i,j P V be any two nodes. The effective resistance between i,j, denoted r , is given
ij
by the formula
(47) r “ pδ ´δ qTL:pδ ´δ q.
ij i j i j
The effective resistance between the nodes of a graph has many different properties and representations,
many of which intersect with the simple random walk on G. We give its definition and some of its properties
below.
Definition 3.2. The simple random walk on G is the Markov chain pX q on the state space of nodes V
t tě0
with transition probability matrix D´1A; that is,
#
w
ij if i „ j
PrX t`1 “ j|X t “ is “ d i .
0 otherwise
13Recall that X will admit a stationary distribution whenever G is connected and will be ergodic whenever
t
G is also non-bipartite. The stationary distribution, which we denote ρ, is always proportional to the degree
at each node. A useful tool is the vertex hitting time
(48) Ts “ inftt ě s : X “ ju, s ě 0,j P V.
j t
ř
Also, let volpGq “ d denote the volume of the graph G.
iPV i
Proposition 3.3. Let i,j P V be any two nodes. Then the following observations hold
(i) pi,jq ÞÑ r is a metric on V,
ij
(ii) pi,jq ÞÑ
r1{2
is a metric on V,
ij
(iii) r “ inftfTLf : Lf “ δ ´δ u,
ij i j
(iv) r “ }L´1{2pu ´u q}2, where u is the i-th orthonormal eigenvector of the graph Laplacian L.
ij i j 2 i
´ ¯
(v) r “ 1 ErT0 : X “ js`ErT0 : X “ is , i.e., r is proportional to the commute time between
ij volpGq i 0 j 0 ij
i,j.
For proofs of these results, see, e.g., [40, 50, 25].
3.1.2 2-Beckmann as measure effective resistance
We begin with the observation that B pα,βq2 can be realized as a type of effective resistance for measures.
2
We make this precise in the theorem below.
Theorem 3.4. Let α,β P PpVq. Then
(49) B pα,βq2 “ pα´βqTL:pα´βq.
2
Proof. We can write
(50) B pα,βq2 “ inft}J}2 : BJ “ α´βu
2 w,2
(51) “ inft}W1{2J}2 : BJ “ α´βu
2
(52) “ inft}S}2 : pBW´1{2qS “ α´βu
2
with S “ W1{2J. Recall that for matrices X,x it holds that X:x “ argmint}y} : Xy “ xu when x belongs
2
to the column space of X [6], and thus we have
(53) B pα,βq2 “ }pBW´1{2q:pα´βq}2
2 2
(54) “ pα´βqTppBW´1{2q:qTpBW´1{2q:pα´βq
(55) “ pα´βqTL:pα´βq
since L “ BWBT.
One immediate consequence of Theorem 3.4 is a Brenier-type theorem for graphs, which we state as
a corollary below. Based on the discussion following Eq. (12), in this theorem we opt to use the notation
BT “ ∇ to achieve homophily with the continuous setting.
Corollary3.5. Letα,β P PpVq. TheuniqueoptimaledgeflowJ˚ forB pα,βqcanbewrittenJ˚ “ ∇f where
2
f is a mean-zero potential function of minimal ℓ norm satisfying the Poisson-type equation Lf “ α´β.
2
The optimal cost is }∇f} .
w,2
14Proof. It is enough to write pα´βqTL:pα´βq “ pα´βqTL:LL:pα´βq and L “ BWBT. The claim then
follows from the proof of Theorem 3.4.
Based on the Theorem 3.4, we introduce the following definition and notation of effective resistance for
measures.
Definition 3.6. Let α,β P PpVq. Then we define the measure effective resistance by
(56) r “ pα´βqTL:pα´βq.
αβ
In the subsequent sections, we will explore the properties of r in its own right, with particular focus on
αβ
its relationship to optimal stopping rules of the simple random walk.
3.1.3 Measure effective resistance and optimal stopping rules
We have already argued in Theorem 3.4 that measure effective resistance can be understood as a type of
flow-basedoptimaltransportationdistancebetweenthemeasures. Thegoalofthissectionistoessentiallyset
thatasideandthinkaboutr initsownright. AnaturalapproachalongtheselinesistotakeProposition3.3
αβ
as a starting point. Immediately, r has several analagous properties, which we state below without proof.
αβ
Proposition 3.7. Let α,β P PpVq. Then the following statements hold:
(i) pα,βq ÞÑ
r1{2
is a metric on PpVq,
αβ
␣ (
(ii) r “ inf fTLf : Lf “ α´β ,
αβ
(iii) r “ }L´1{2pα´βq}2.
αβ 2
To go deeper, we pose the following question along the lines of Proposition 3.3(v): To what extent can
r be understood as a generalized commute time between the measures α,β? To answer this question, we
αβ
need to use results that concern stopping rules for the simple random walk.
Definition 3.8. A stopping rule is a map Γ that associates to each finite path ω “ pX ,X ,...,X q on
0 1 k
G a number Γpωq in r0,1s. We can think of Γpωq as the probability that we continue a random walk given
that ω is the walk so far observed. Alternatively, Γ can be considered a random variable taking values in
t0,1,2,...u whose distribution depends only on the steps pX ,X ,...,X q.
0 1 Γ
The mean length ErΓs is the expected duration of the walk. If ErΓs ă 8 then the walk stops almost
surely in finite time, so we define X to be the position of the random walk at the stopping time. Having
Γ
defined stopping rules, we can define the generalized hitting time between α,β.
Definition 3.9. Let α,β P PpVq. The access time Hpα,βq is defined as
(57) Hpα,βq “ inftErΓ|X „ αs : ErΓs ă 8, and X „ βu.
0 Γ
where for any random variable Y on V, we say Y „ α if PrY “ is “ αpiq for i P V. In other words, Hpα,βq is
the minimum mean length of walks that originate with distribution α and terminate according to a stopping
rule that achieves distribution β at stopping time. If Γ achieves the inf in Hpα,βq, then Γ is said to be an
optimal stopping rule.
Remark 3.10. It is not hard to see that the set of feasible stopping rules in Definition 3.9 is nonempty. The
so-called “na¨ıve” stopping rule Γ can be obtained from the following construction: at the beginning of the
n
random walk, sample j „ β, and stop the walk when X “ j. It is readily verified that X „ β, and that
ÿ
Γn Γn
ErΓ s “ α β Hpi,jq
n i j
i,jPV
where for i,j P V, the hitting time Hpi,jq is defined by Hpi,jq “ Hpδ ,δ q (or, the mean number of steps to
i j
reach j from i).
15α α
β β
(a) Initial distribution α, stopping (b) Initial distribution β, stopping
distribution β. distribution α.
Figure 3: Two illustrations of 1000 simulated simple random walks on the dodecahedral graph with given
initial distribution, illustrated with node opacity proportional to density; and na¨ıve stopping rule according to
the given stopping distribution, illustrated with opposite node color and opacity proportional to density. The
edges are dashed only to indicate depth, and edge opacity is proportional to the total number of times the
simulated random walks landed on each edge. The mean lengths of paths in (a) (resp. (b)) correspond to
H pα,βq (resp. H pβ,αqq.
n n
Several examples of optimal stopping rules for general distributions are given in [52], and in particular, it
is shown thereby that any such α,β admit an optimal stopping rule provided G is connected.
The access time Hpα,βq has several notable properties, which we summarize in the Proposition below.
The proofs of these results can be found in [52].
Proposition 3.11. Let α,β P PpVq. Then the following facts hold for Hpα,βq:
ř
(i) When β is concentrated at a node j P V, it holds Hpα,jq “ α Hpi,jq,
iPV i
ř
(ii) Hpα,βq “ max pα ´β qHpi,jq,
j iPV i i
(iii) Hpα,βq is convex in both of its arguments; namely if α,α1,β,β1 P PpVq and c P r0,1s, we have
(58) Hpcα`p1´cqα1,βq ď cHpα,βq`p1´cqHpα1,βq
(59) Hpα,cβ`p1´cqβ1q ď cHpα,βq`p1´cqHpα,β1q
Beveridge [8] also established a connection between the entries of the psuedoinverse of the graph Lapla-
cian(treatedasadiscreteGreen’sfunction)andtheaccesstimebetweennodesandthestationarydistribution
of the random walk. We reproduce that formula here as a proposition, in a modified form to match our
conventional choice of Laplacian matrix.
Theorem 3.12 (Access Time Formula for the Discrete Green’s Function, Beveridge [8]). Let ρ be the
stationary distribution of the simple random walk on V. Then the i,j-th entry of L: can be expressed as
1
(60) pL:q “ pHpρ,jq´Hpi,jqq,
ij
volpGq
ř
where volpGq “ d .
iPV i
For α P PpVq, define H P ℓpVq by H piq “ Hpα,iq. We are ready to state our main result connecting
α α
r to the access time.
αβ
16Theorem 3.13 (Generalized Commute Time Formula). Let α,β P PpVq. Then
1
(61) r “ ´ pα´βqTpH ´H q.
αβ α β
volpGq
Or, in alternative expanded forms,
ÿ
1
(62) r “ ´ pα ´β qpHpα,iq´Hpβ,iqq
αβ i i
volpGq
iPV
ÿ
1
(63) “ ´ pα ´β qpα ´β qHpi,kq.
i i k k
volpGq
i,kPV
We provide the proof in Appendix A.2. The reason we term Theorem 3.13 a generalized commute time
formula is that in the case where α,β are Dirac measures, this recovers the result that r 9pHpi,jq`Hpj,iqq,
ij
since we have
1
(64) r j “ ´ pδ ´δ qTpH ´H q
i i j δ δ
volpGq i j
1
(65) “ ´ pHpi,iq´Hpi,jq`Hpj,jq´Hpj,iq
volpGq
1
(66) “ pHpi,jq`Hpj,iqq.
volpGq
Theorem 3.13 shows, however, that in the more general case of measures r is not exactly the same as a
αβ
measure commute time Hpα,βq`Hpβ,αq. Theorem 3.13 can be used to establish a relationship between
the measure commute time and the measure resistance, as we show below.
Corollary 3.14 (Measure Commute Time Inequalities). Let α,β P PpVq. Then r satisfies the following
αβ
two inequalities:
2
(67) r ď maxtHpα,βq,Hpβ,αqu
αβ
volpGq
1
(68) r ď pH pα,βq`H pβ,αqq
αβ n n
volpGq
where H pα,βq “ ErΓ s (resp. H pβ,αq) is the expected duration of the na¨ıve stopping rule described in
n n n
Remark 3.10 with initial distribution α (resp. β) and stopping node sampled from β (resp. α).
The proof of Corollary 3.14 is located in Appendix A.2. Note that the second half of the proof of
Corollary 3.14 actually contains a related observation regarding B and W , which we state as another
2 r,1
corollary below, without proof.
Corollary 3.15. Let α,β P PpVq, and let r be the effective resistance metric on V. Then we have
B pα,βq ď W pα,βq1{2.
2 r,1
A final observation that one can glean from the random walk and access time setting is an interpretation
of the transportation potential f “ L:pα´βq mentioned in Corollary 3.5.
Proposition 3.16. Let α,β P PpVq, and let Γ be any stopping rule such that ErΓs ă 8 and X „ β. Let f
Γ Γ
be the degree-weighted exit frequencies
« ff
Γÿ´1
1
f piq “ E δ piq : X „ α .
Γ d tXt“iu 0
i
t“0
Then Lf “ α´β. In particular, the transportation potential L:pα´βq is given by the mean normalized
Γ
function f ´ 1fT1 for any suitable stopping rule Γ.
Γ n Γ n
17Thispropositionfollowsfromapplyingtheso-calledconservationequationforexitfrequencies, mentioned
in, e.g., [52, 51]. Another way of putting it is that the unique optimal flow for B pα,βq can be realized
2
as the gradient of the degree-normalized exit frequencies of any finite-mean stopping rule which achieves
a stopping distribution of β, having been intialized at α (since, moreover, as discussed in [51], any two
degree-normalized exit frequencies for different stopping times differ by a constant, and thus have the same
gradient).
3.2 Sobolev norms and a graph Benamou-Brenier formula
The relationship between Sobolev spaces and optimal transportation have been explored at length in the
continuous setting [84, 63, 37, 77]. The goal of this subsection is to present the 2-Beckmann problem as an
optimization problem on a negative Sobolev space for functions defined on graphs. In this section we follow
the exposition laid out in [63] in the continuous setting by analogy to the discrete setting. As it turns out,
there are at least two results that achieve strong homophily between the graph and continuous setting.
3.2.1 Background from the continuous setting
Recall that if f : Rn Ñ R is a function with a square integrable derivative ∇f in the weak sense and µ is a
Borel probability measure which is absolutely continuous with respect to the Lebesgue measure dx; i.e. so
that dµ “ gdx for a density function g, we can define the Sobolev-type seminorm }¨}2 by
H91pµq
ż
(69) }f}2 “ }∇f}2dµ.
H91pµq
Rn
2
The dot H91pµq serves to distinguish }¨}2 from a true Sobolev norm, which include a contribution from
H91pµq
}¨} . We can then define the possibly infinite dual norm to }f}2 , denoted }¨} by the following,
L2 H91pµq H9´1pµq
for any dx- absolutely continuous signed measure ν “ hdx:
"ż *
(70) }hdx} “ sup fhdµ : }f} ď 1 .
H9´1pµq H91pµq
Rn
This setup leads to two results (among others) in the continuous setting, which are of interest in the graph
setting as well.
Theorem 3.17 (H9´1 - Linearization of W [63]). If µ is a Borel probability measure on Rn and dµ is an
2
infintesimally small perturbation of µ, then
W pµ,µ`dµq “ }dµ} `opdµq.
2 H9´1pµq
The second result which interests us is the Sobolev form of the Benamou-Brenier formula, which we
state below.
Theorem 3.18 (Benamou-Brenier formula, H9´1 form [63]). Let µ,ν be Borel probability measures on Rn.
Then it holds:
"ż *
1
(71) W pµ,νq “ inf }dµ } : µ “ µ,µ “ ν .
2 t H9´1pµtq 0 1
0
3.2.2 Graph sobolev norms
Next we transition to defining the appropriate discrete analogues of }¨} and }¨} on the graph G.
H91pµq H9´1pµq
18Definition 3.19. Let f,g P ℓpVq. We define the graph Sobolev seminorm }¨} by the equation
H91pVq
ÿ ÿ
(72) }f}2 “ w |∇fpi,jq|2 “ w |fpiq´fpjq|2.
H91pVq ij 2 ij 2
pi,jqPE1 pi,jqPE1
We define the (possibly infinite) dual graph Sobolev norm }¨} by the supremum
H9´1pVq
! )
(73) }g}2 “ sup fTg : }f} ď 1 .
H9´1pVq H91pVq
It is useful to note that for mean zero functions, }¨} and }¨} will be true norms (in particular,
H91pVq H9´1pVq
the former will be definite and the latter will be finite). The first proposition in the section elucidates the
relationship between graph Sobolev norms and the graph Laplacian matrix.
Proposition 3.20. Let f,g P ℓpVq. Then the following hold:
(i) }f}2 “ fTLf.
H91pVq
(ii) If 1Tg “ 0, then }g}2 “ gTL:g.
H9´1pVq
Proof. The first claim is straightforward. The second requires a closer look. We can work backwards and
use the proof of Theorem 2.1 to obtain
(74) pgTL:gq1{2 “ }L´1{2g}
2
(75) “ inft}f} : L1{2f “ gu
! 2 )
(76) “ sup fTg : }L1{2f} ď 1 ,
2
where Lt´1{2,1{2u “ UΛt´1{2,1{2uUT as in Eq. (10). But }L1{2f}2 “ fTLf “ }f}2 , so the claim follows.
2 H91pVq
3.2.3 2-Beckmann as a negative Sobolev distance
Sinceourdefinitionshavebeensetupandexplainedproperly,wecanderivethefollowingresult, whichfollows
directly from Proposition 3.20 and Theorem 3.4. We consider this a graph analogue of Theorem 3.17 for
2-Beckmann distance.
Theorem 3.21. Let α,β P PpVq. Then
B pα,βq “ }α´β} .
2 H9´1pVq
Thus in particular if β “ α`dα for a small perturbation dα, then B pα,α`dαq “ }dα} .
2 H9´1pVq
Note that since the H9´1 norm depends on the operator L´1{2, the Beckmann řdistance B 2pα,α`dαq
can be articulated in terms of the spectral coefficients of dα; to wit, if dα “ n c u is the spectral
ℓ“2 ℓ ℓ
decomposition of a mean-zero perturbation dα P ℓpVq in terms of the eigenvectors u of L, then
ℓ
ÿn
c2
(77) B pα,α`dαq2 “ }L´1{2dα}2 “ ℓ .
2 2 λ
ℓ
ℓ“2
Therefore in general, one has B pα,α`dαq ď
λ´1{2
}dα} ; but if the spectral properties of dα are known,
2 2 2
this estimate may be sharpened.
The next result which leverages the Sobolev norm perspective on graph optimal transport can be con-
sidered a graph analogue of the Benamou-Brenier formula. Let µ P ℓpVq for each t P r0,1s. We say
t
µ
t
P C1pr0,1sq if the map t ÞÑ µ
t
: r0,1s Ñ ℓpVq is continuoˇusly differentiable as a map from r0,1s to Rn.
Moreover, when µ admits a derivative, we write dµ “ d µ ˇ .
t t ds s s“t
19Theorem 3.22 (Graph Benamou-Brenier Formula). Let α,β P PpVq. Then we have
"ż *
1
(78) B pα,βq2 “ inf }dµ }2 dt : µ P C1pr0,1sq,µ “ α,µ “ β .
2 t H9´1pVq t 0 1
0
See Appendix A.2 for a proof, which is based on the proof appearing in the lecture notes [35]. Note
that the infimum is achieved by a linear line segment connecting α to β, which underlines the idea that B
2
should be treated as a linearized variant of Wasserstein distance. We explore the linearization angle and its
implications on graph learning tasks in the next section.
3.3 A linearized optimal transportation distance
A third and final perspective on 2-Beckmann distance is from the world of clustering and classification of
graph data. We begin with a background discussion from the continuous setting, and then explore convex
separation properties for graph data as well as an application involving a handwritten digit dataset.
3.3.1 Background from the continuous setting
A typical classification scenario usually consists of some data tx u Ă Rn which one wishes to separate into
i
classes or clusters either without prior knowledge of the data labels (unsupervised) or with some information
about the class labels of the dataset (semi-supervised or supervised). In many applications, e.g., [20, 93, 13],
the data x can often occur not as vectors in Rn but as distributions µ on Rn.
i i
In such scenarios, Wasserstein distance, formulated in the Monge sense as
ż
(79) W pµ,νq2 “ inf }Tpxq´x}2dµpxq,
2 2
T:T 7µ“ν Rn
whereT µisthepush-forwardofµunderthemapT andtheinf isoverallsuchT exhibitingdesiredregularity,
7
arises as a natural distance metric between probabilitiy measures on Rn. However, this metric can be slow
to compute at scale, and in the discrete setting can even suffer from being undefined.
One approach to resolving this issue involves the usage and study of Linearized Optimal Transport
embeddings [58, 88, 54, 43, 21], which can be summarişzed as follows. Given data measures tµ iu, fix
a reference measure µ, and define T “ argmin }Tpxq ´ x}2dµpxq. Then the measures are
i T:T 7µ“µ i Rn 2
featurized in the form of the maps T : Rn Ñ Rn and 2-Wasserstein distance between the data measures is
i
then approximated by }T ´T } .
i j L2
Theoretically, the ability of Linearized Optimal Transport in approximating 2-Wasserstein distance can
be captured by the following two results, the informal statements of which we restate from [58].
Theorem 3.23 (Informal Statement of Theorem 4.4 from [58]). If P “ tµ u are ϵ-perturbations of shifts
i
and scalings of µ, and Q “ tν u are ϵ-perturbations of shifts and scalings of ν, and P and Q have small
i
minimal distance depending on ϵ and satisfy a few technical assumptions, P and Q are linearly separable in
LOT embedding space.
Theorem 3.24 (Informal Statement of Theorem 4.1 from [58]). If µ,ν are ϵ-perturbations of shifts and
scalings of one another, then
(80) W pµ,νq ď WLOTpµ,νq ď W pµ,νq`C ϵ`C1ϵ1{2.
2 2 2 σ σ
In particular, when ϵ “ 0 and µ,ν are shifts and scalings of each other, LOT is an isometry.
It is also worth noting that in the situation where µ is some shift or scaling of µ, i.e., µ “ T µ for an
i i 7
affine combination of scaling and translation T on Rn, then the LOT embedding of µ will be the map T
i
itself; i.e., T is optimal in the Wasserstein cost.
203.3.2 Linear separtation for 2-Beckmann distance
To set up the problem, suppose we have data sampled from C classes, and each class is associated to a
canonical distribution α P PpVq so that our data may be represented in the form D “ tTα u .
i i i“1,...,C;TPT
That is, each data point is of the form Tα where α is the underlying distribution of the class and the map
i i
T : PpVq Ñ PpVq represents a perturbation of the class distribution among valid perturbations T (to be
determined).
For example, consider a hypothetical dataset of images with resolution k ˆℓ. In this setting, G is the
kˆℓ lattice graph, and after normalization each image can be understood as a distribution on G. In our data
model, we assume that each image may be expressed as a perturbation of a canonical distribution associated
to the corresponding image class.
In the unsupervised setting, we simply have D and we wish to use some clustering technique, e.g., k-
means or principal geodesic analysis, associated to a metric on PpVq. In the supervised setting, we have data
equipped with labels D1 “ tpTα ,y qu so that each label depends only on the class distribution
i i i“1,...,C;TPT
and we seek to build some classifier, ideally linear, which facilitates predictive analysis.
We treat B as a linearization of W on graphs. In this setting, the featurization of each canonical class
2 2
distribution is given by α ÞÑ L´1{2α and similarly for the individual samples Tα .
i i i
For a set of measures A “ tα ,...,α u Ă PpVq, define the mutual support by
1 k
čk
MSpAq “ supppα q Ă V,
i
i“1
where supppα q is the subset of nodes in V on which α ą 0.
i
Theorem 3.25. Let α ‰ α P PpVq be the canonical class distributions for a binary distributional dataset
1 2
D “ tTα u . Assume MSptα ,α uq ‰ ∅ and let T be the set of affine perturbation maps defined
i i“1,2;TPT 1 2
by
Tα “ α`dT
where dT P ℓpVq is vector which satisfies the three conditions:
(i) dT is mean zero, or 1TdT “ 0;
n
(ii) supppdTq Ă MSptα ,α uq; and
1 2
(iii) }dT} ă δ, where
1
$ ,
& .
1
(81) δ “ min }α ´α } , min α pkq ą 0.
%3 1 2 2
i“1,2
i -
kPMSptα1,α2uq
Then the sets A “ tTα u and A “ tTα u , which belong to the metric space pPpVq,B q, can be
1 1 TPT 2 2 TPT 2
isometrically embedded into ℓ pVq under L´1{2 so that their images are linearly separable as convex sets in
2
Rn.
See Appendix A.2 for the proof. Note that it is not hard to extend Theorem 3.23 to the case of
C ą 2 classes, by simply requiring that the perturbations be smaller than the mutual distances between
the canonical class distributions, up to an appropriate constant, so that in the data model there are no
overlapping perturbations. The main point of this result is that L´1{2 as an embedding of measures, is
well-behaved; in the sense that as long as the original collections of measures were separable, L´1{2 will not
imbue any pathology.
21R64 PpVq ℓ pVq
2
x ÞÑ x{p1Txq α ÞÑ L´1{2α
0 7.5 15 ´0.05 0 0.05
Figure 4: An illustration of the preprocessing pipeline for the digits data, with an example from the class
of handwritten zeros. The first step is a mass normalization to convert the pixel values into a fixed-sum
distribution viewed on the nodes V of the 8ˆ8 lattice graph. The second step is an embedding α ÞÑ L´1{2α,
such that ℓ distance in the target corresponds to 2-Beckmann distance in PpVq. When computing W , we
2 2
omit the final step.
Figure 5: Using the digits dataset, and for each pair of digit classes, we computed the pairwise 2-Beckmann
and2-Wassersteindistancesforeachpairofsamplesoriginatingfromtherespectivedigitclasses(witharound
30,000 pairs of distances per pair of digit classes). Within each tile of the grid, we render a scatterplot of the
distances over the overall linear regression between B and W for the experiment given by W « 8.446B .
2 2 2 2
22(a) Similarity kernel between each image is given by expt´B p¨,¨q2u
2
(b) Similarity kernel between each image is given by expt´W p¨,¨q2u
2
RI ARI MI AMI Hom Com
B 0.940 0.685 1.782 0.783 0.774 0.797
2
W 0.935 0.656 1.719 0.755 0.747 0.775
2
(c) Performance metrics
Figure6: (a)-(b)Usingthedigitsdataset,wedemonstratetheresultsofanunsupervisedclusteringalgorithm
with different choices of similarity kernel. Each node corresponds to an image of a digit, which we featurize
as a distribution on the 8ˆ8 square lattice graph. We built a k “ 42 nearest neighbor graph on the nodes
(shown), and then apply spectral clustering [87] to create predicted classes. The text labels of the nodes
correspond to the ground truth classes, i.e., digit values. The colors of the nodes on the left (resp. right)
are given by the ground truth classes (resp. predicted classes). (c) We evaluate the performance of the
unsupervised clustering alogrithm for each kernel. We compare across several metrics, including Rand index
(RI) and adjusted Rand index (ARI) [39]; mutual information (MI) and adjusted mutual information (AMI)
[86]; and homogeneity (Hom) and completeness (Com) [66]. In all such cases other than MI, a value of
1.0 corresponds to perfect clustering as compared to the ground truth. Since the predictions depend on
a random initialization in the k-means step, we simulated 100 runs of the algorithm and reported the best
result for each kernel across the six metrics.
233.3.3 Experimental results
To further explore the implications of our results on learning with graph data, we conducted two experiments
which illuminate some of the potential applications and underlying properties of 2-Beckmann distance be-
tween measures. Both examples make use of the “Pen-Based Recognition of Handwritten Digits” dataset
[3], accessed and processed via the Sklearn Python package [14]. The dataset contains 1797 grayscale hand-
written digits of resolution 8ˆ8 and pixel values ranging from 0´15. The reason for choosing this dataset
is that the 2-Wasserstein kernel is computationally prohibitive at scale without approximation, so rather than
regularize the Wasserstein metric, we opt for a lighter-weight image dataset. Specifically, if W is obtained
2
via, e.g., a Hungarian algorithm or a linear program, the time complexity to obtain a kernel matrix for N
samples, each defined on a graph of n nodes, is roughly Opn3N2q. A Beckmann kernel matrix, on the other
hand, runs Opn3 `pn2 `nqN2q since only a single SVD calculation of L: is required at the beginning, and
then subsequent entries of the kernel matrix are obtained through matrix-vector multiplication and pairwise
comparison. The Wasserstein metric W pα,βq was directly evaluated for each pair of examples α,β by using
2
the CVXPY convex optimization Python package [24] with initialization determined by the trivial coupling
βαT. Fig. 4 illustrates the pre-processing pipeline for an example image of a handwritten zero.
The first experiment, described in detail in Fig. 5, is a comparative study of B and W in which we show
2 2
that the two metrics are well-correlated for the dataset in question. The second experiment, described in
Fig. 6, is a comparative study of B and W within the context of unsupervised learning on the digit dataset.
2 2
In this setup, we show that the two kernels perform almost identically on the dataset with respect to several
metrics (with a slight edge toward B ), and thus there is some empirical evidence for drop-in usage of B
2 2
where W , or perhaps W more generally, may present a computational bottleneck.
2 p
4 Acknowledgements
The authors would like to acknowledge Yusu Wang for her inspirational discussions early on in this project,
Stefan Steinerberger for his help placing the preliminary results within the context of the broader OT space,
Zachary Lubberts for his helpful discussions on applications of graph OT to discrete geometry, and Caroline
Moosm¨uller for her helpful feedback on linearized Wasserstein distance and Sobolev transport in the con-
tinuous setting. SR wishes to acknowledge Evangelos Nikitopoulos, as well as financial support from the
Halıcıo˘glu Data Science Institute through their Graduate Prize Fellowship. AC was funded by NSF DMS
2012266 and a gift from Intel. ZW was supported by NSF CCF 2217058.
References
[1] Tara Abrishami, Nestor Guillen, Parker Rule, Zachary Schutzman, Justin Solomon, Thomas Weighill,
and Si Wu. Geometry of graph partitions via optimal transport. SIAM Journal on Scientific Computing,
42(5), 2020.
[2] Morteza Alamgir and Ulrike Luxburg. Phase transition in the family of p-resistances. Advances in neural
information processing systems, 24, 2011.
[3] E. Alpaydin and Fevzi. Alimoglu. Pen-Based Recognition of Handwritten Digits. UCI Machine Learning
Repository, 1998.
[4] Frank Bauer, J¨urgen Jost, and Shiping Liu. Ollivier-ricci curvature and the spectrum of the normalized
graph laplace operator. arXiv preprint arXiv:1105.3803, 2011.
[5] Martin Beckmann. A continuous model of transportation. Econometrica: Journal of the Econometric
Society, 1952.
24[6] Adi Ben-Israel and A Charnes. Contributions to the theory of generalized inverses. Journal of the
Society for Industrial and Applied Mathematics, 11(3), 1963.
[7] Jean-David Benamou and Yann Brenier. A computational fluid mechanics solution to the monge-
kantorovich mass transfer problem. Numerische Mathematik, 84(3):375–393, 2000.
[8] Andrew Beveridge. A hitting time formula for the discrete green’s function. Combinatorics, Probability
and Computing, 25(3), 2016.
[9] Andrew Beveridge and L´aszl´o Lov´asz. Exit frequency matrices for finite markov chains. Combinatorics,
Probability and Computing, 19(4), 2010.
[10] Robi Bhattacharjee, Alexander Cloninger, Yoav Freund, and Andreas Oslandsbotn. Effective resistance
in metric spaces. arXiv preprint arXiv:2306.15649, 2023.
[11] J´er´emie Bigot. Statistical data analysis in the wasserstein space. ESAIM: Proceedings and Surveys, 68,
2020.
[12] Mitchell Black, Zhengchao Wan, Amir Nayyeri, and Yusu Wang. Understanding oversquashing in gnns
through the lens of effective resistance. In International Conference on Machine Learning, pages 2528–
2547. PMLR, 2023.
[13] Robert V Bruggner, Bernd Bodenmiller, David L Dill, Robert J Tibshirani, and Garry P Nolan. Au-
tomated identification of stratifying signatures in cellular subpopulations. Proceedings of the National
Academy of Sciences, 111(26), 2014.
[14] Lars Buitinck, Gilles Louppe, Mathieu Blondel, Fabian Pedregosa, Andreas Mueller, Olivier Grisel, Vlad
Niculae, Peter Prettenhofer, Alexandre Gramfort, Jaques Grobler, Robert Layton, Jake VanderPlas,
Arnaud Joly, Brian Holt, and Ga¨el Varoquaux. API design for machine learning software: experiences
from the scikit-learn project. In ECML PKDD Workshop: Languages for Data Mining and Machine
Learning, 2013.
[15] Sarah Cannon, Moon Duchin, Dana Randall, and Parker Rule. Spanning tree methods for sampling
graph partitions. arXiv preprint arXiv:2210.01401, 2022.
[16] Benson Chen, Gary B´ecigneul, Octavian-Eugen Ganea, Regina Barzilay, and Tommi Jaakkola. Optimal
transport graph neural networks. arXiv preprint arXiv:2006.04804, 2020.
[17] Samantha Chen, Sunhyuk Lim, Facundo M´emoli, Zhengchao Wan, and Yusu Wang. Weisfeiler-lehman
meetsgromov-wasserstein. InInternationalConferenceonMachineLearning,pages3371–3416.PMLR,
2022.
[18] Fan Chung, Wenbo Zhao, and Mark Kempton. Ranking and sparsifying a connection graph. Internet
Mathematics, 10(1-2), 2014.
[19] Alex Cloninger, Gal Mishne, Andreas Oslandsbotn, Sawyer Jack Robertson, Zhengchao Wan, and Yusu
Wang. Random walks, conductance, and resistance for the connection graph laplacian. arXiv preprint
arXiv:2308.09690, 2023.
[20] Alexander Cloninger, Brita Roy, Carley Riley, and Harlan M Krumholz. People mover’s distance: Class
level geometry using fast pairwise data adaptive transportation costs. Applied and Computational
Harmonic Analysis, 47(1), 2019.
[21] Alexander Cloninger, Keaton Hamm, Varun Khurana, and Caroline Moosm¨uller. Linearized wasserstein
dimensionality reduction with approximation guarantees. arXiv preprint arXiv:2302.07373, 2023.
25[22] Karel Devriendt and Renaud Lambiotte. Discrete curvature on graphs from the effective resistance.
Journal of Physics: Complexity, 3(2), 2022.
[23] Karel Devriendt, Andrea Ottolini, and Stefan Steinerberger. Graph curvature via resistance distance.
Discrete Applied Mathematics, 348, 2024.
[24] Steven Diamond and Stephen Boyd. CVXPY: A Python-embedded modeling language for convex
optimization. Journal of Machine Learning Research, 2016.
[25] Peter G Doyle and J Laurie Snell. Random walks and electric networks, volume 22. American Mathe-
matical Soc., 1984.
[26] Abderrahim Elmoataz, Olivier Lezoray, and S´ebastien Bougleux. Nonlocal discrete regularization on
weighted graphs: a framework for image and manifold processing. IEEE transactions on Image Pro-
cessing, 17(7), 2008.
[27] AbderrahimElmoataz,MatthieuToutain,andDanielTenbrinck. Onthep-laplacianandinfinity-laplacian
on graphs with applications in image and data processing. SIAM Journal on Imaging Sciences, 8(4),
2015.
[28] Montacer Essid and Justin Solomon. Quadratically regularized optimal transport on graphs. SIAM
Journal on Scientific Computing, 40(4), 2018.
[29] Lawrence C Evans. Partial differential equations and monge-kantorovich mass transfer. Current devel-
opments in mathematics, 1997(1), 1997.
[30] Lawrence C Evans and Wilfrid Gangbo. Differential equations methods for the Monge-Kantorovich
mass transfer problem. American Mathematical Soc., 1999.
[31] Zhongxi Fang, Jianming Huang, Xun Su, and Hiroyuki Kasai. Wasserstein graph distance based on
l1–approximated tree edit distance between weisfeiler–lehman subtrees. In Proceedings of the AAAI
Conference on Artificial Intelligence, volume 37, 2023.
[32] Alfred Galichon. Optimal transport methods in economics. Princeton University Press, 2018.
[33] Wilfrid Gangbo and Robert J McCann. The geometry of optimal transportation. Acta Mathematica,
177, 1996.
[34] Jun Ge and Fengming Dong. Spanning trees in complete bipartite graphs and resistance distance in
nearly complete bipartite graphs. Discrete Applied Mathematics, 283, 2020.
[35] Augusto Gerolin. Benamou-brenier’s approach for ott. In Optimal Transport and Applications. Summer
School, Lake Arrowhead, 2013.
[36] Severino V Gervacio. Resistance distance in complete n-partite graphs. Discrete Applied Mathematics,
203, 2016.
[37] Philip Greengard, Jeremy G Hoskins, Nicholas F Marshall, and Amit Singer. On a linearization of
quadratic wasserstein distance. arXiv preprint arXiv:2201.13386, 2022.
[38] Steven Haker, Lei Zhu, Allen Tannenbaum, and Sigurd Angenent. Optimal mass transport for registra-
tion and warping. International Journal of computer vision, 60, 2004.
[39] Lawrence Hubert and Phipps Arabie. Comparing partitions. Journal of classification, 2, 1985.
[40] Palle Jorgensen and Erin PJ Pearse. Operator theory and analysis of infinite networks, volume 7. World
Scientific, 2023.
26[41] Leonid V Kantorovich. On the translocation of masses. In Dokl. Akad. Nauk. USSR (NS), volume 37,
1942.
[42] Nguyen Lu Dang Khoa and Sanjay Chawla. Large scale spectral clustering using resistance distance and
spielman-teng solvers. In Discovery Science: 15th International Conference, DS 2012, Lyon, France,
October 29-31, 2012. Proceedings 15. Springer, 2012.
[43] Varun Khurana, Harish Kannan, Alexander Cloninger, and Caroline Moosm¨uller. Supervised learning of
sheared distributions using linearized optimal transport. Sampling Theory, Signal Processing, and Data
Analysis, 21(1), 2023.
[44] Matt Kusner, Yu Sun, Nicholas Kolkin, and Kilian Weinberger. From word embeddings to document
distances. In International conference on machine learning. PMLR, 2015.
[45] Tam Le, Makoto Yamada, Kenji Fukumizu, and Marco Cuturi. Tree-sliced variants of wasserstein
distances. Advances in neural information processing systems, 32, 2019.
[46] Tam Le, Truyen Nguyen, Dinh Phung, and Viet Anh Nguyen. Sobolev transport: A scalable metric
for probability measures with graph metrics. In International Conference on Artificial Intelligence and
Statistics, pages 9844–9868. PMLR, 2022.
[47] Tam Le, Truyen Nguyen, and Kenji Fukumizu. Scalable unbalanced sobolev transport for measures on
a graph. In International Conference on Artificial Intelligence and Statistics. PMLR, 2023.
[48] Tam Le, Truyen Nguyen, and Kenji Fukumizu. Generalized sobolev transport for probability measures
on a graph. arXiv preprint arXiv:2402.04516, 2024.
[49] Haibin Ling and Kazunori Okada. An efficient earth mover’s distance algorithm for robust histogram
comparison. IEEE transactions on pattern analysis and machine intelligence, 29(5), 2007.
[50] L´aszl´o Lov´asz. Random walks on graphs. Combinatorics, Paul erdos is eighty, 2(1-46), 1993.
[51] L´aszl´o Lov´asz and Peter Winkler. Efficient stopping rules for markov chains. In Proceedings of the
twenty-seventh annual ACM symposium on Theory of computing, 1995.
[52] L´aszl´o Lov´asz and Peter Winkler. Mixing of random walks and other diffusions on a graph. London
Mathematical Society Lecture Note Series, 1995.
[53] Maxime Mathey-Prevot and Alain Valette. Wasserstein distance and metric trees. L’Enseignement
Math´ematique, 69(3), 2023.
[54] Quentin M´erigot, Alex Delalande, and Frederic Chazal. Quantitative stability of optimal transport maps
and linearization of the 2-wasserstein space. In International Conference on Artificial Intelligence and
Statistics. PMLR, 2020.
[55] Stacy Miller. The problem of redistricting: the use of centroidal voronoi diagrams to build unbiased
congressional districts. Senior project, Whitman College, 2007.
[56] Gaspard Monge. M´emoire sur la th´eorie des d´eblais et des remblais. Mem. Math. Phys. Acad. Royale
Sci., 1781.
[57] LUIGI Montrucchio and Giovanni Pistone. Kantorovich distance on a weighted graph. arXiv preprint
arXiv:1905.07547, 1420, 2019.
[58] Caroline Moosm¨uller and Alexander Cloninger. Linear optimal transport embedding: Provable wasser-
stein classification for certain rigid transformations and perturbations. arXiv preprint arXiv:2008.09165,
2020.
27[59] Florentin M¨unch and Rados(cid:32)law K Wojciechowski. Ollivier ricci curvature for general graph laplacians:
heat equation, laplacian comparison, non-explosion and diameter bounds. Advances in Mathematics,
356, 2019.
[60] Canh Hao Nguyen and Hiroshi Mamitsuka. New resistance distances with global information on large
graphs. In Artificial intelligence and statistics. PMLR, 2016.
[61] Victor M Panaretos and Yoav Zemel. Statistical aspects of wasserstein distances. Annual review of
statistics and its application, 6, 2019.
[62] Gabriel Peyr´e, Marco Cuturi, et al. Computational optimal transport. Center for Research in Economics
and Statistics Working Papers, 1(2017-86), 2017.
[63] R´emi Peyre. Comparison between w2 distance and h- 1 norm, and localization of wasserstein distance.
ESAIM: Control, Optimisation and Calculus of Variations, 24(4), 2018.
[64] Aaditya Ramdas, Nicol´as Garc´ıa Trillos, and Marco Cuturi. On wasserstein two-sample testing and
related families of nonparametric tests. Entropy, 19(2), 2017.
[65] Sawyer Robertson, Dhruv Kohli, Gal Mishne, and Alexander Cloninger. On a generalization of wasser-
stein distance and the beckmann problem to connection graphs. arXiv preprint arXiv:2312.10295, 2023.
[66] Andrew Rosenberg and Julia Hirschberg. V-measure: A conditional entropy-based external cluster
evaluation measure. In Proceedings of the 2007 joint conference on empirical methods in natural
language processing and computational natural language learning (EMNLP-CoNLL), 2007.
[67] ErnestKRyu,YongxinChen,WuchenLi,andStanleyOsher. Vectorandmatrixoptimalmasstransport:
theory, algorithm, and applications. SIAM Journal on Scientific Computing, 40(5), 2018.
[68] Shota Saito and Mark Herbster. Multi-class graph clustering via approximated effective p-resistance.
In International Conference on Machine Learning. PMLR, 2023.
[69] TimSalimans,HanZhang,AlecRadford,andDimitrisMetaxas. Improvinggansusingoptimaltransport.
arXiv preprint arXiv:1803.05573, 2018.
[70] Areejit Samal, RP Sreejith, Jiao Gu, Shiping Liu, Emil Saucan, and J¨urgen Jost. Comparative analysis
of two discretizations of ricci curvature for complex networks. Scientific reports, 8(1), 2018.
[71] Filippo Santambrogio. Optimal transport for applied mathematicians. Birk¨auser, NY, 55(58-63), 2015.
[72] Geoffrey Schiebinger, Jian Shu, Marcin Tabaka, Brian Cleary, Vidya Subramanian, Aryeh Solomon,
Joshua Gould, Siyan Liu, Stacie Lin, Peter Berube, et al. Optimal-transport analysis of single-cell gene
expression identifies developmental trajectories in reprogramming. Cell, 176(4), 2019.
[73] Maurice Sion. On general minimax theorems. Pacific J. Math., 8(4), 1958.
[74] Justin Solomon. Optimal transport on discrete domains. AMS Short Course on Discrete Differential
Geometry, 2018.
[75] Justin Solomon, Raif Rustamov, Leonidas Guibas, and Adrian Butscher. Earth mover’s distances on
discrete surfaces. ACM Transactions on Graphics (ToG), 33(4), 2014.
[76] Daniel A Spielman and Nikhil Srivastava. Graph sparsification by effective resistances. In Proceedings
of the fortieth annual ACM symposium on Theory of computing, 2008.
[77] StefanSteinerberger. Awassersteininequalityandminimalgreenenergyoncompactmanifolds. Journal
of Functional Analysis, 281(5), 2021.
28[78] Tomohiro Sugiyama and Kazuhiro Sato. Kron reduction and effective resistance of directed graphs.
SIAM Journal on Matrix Analysis and Applications, 44(1), 2023.
[79] Yuki Takezawa, Ryoma Sato, and Makoto Yamada. Supervised tree-wasserstein distance. In Interna-
tional Conference on Machine Learning. PMLR, 2021.
[80] Yuki Takezawa, Ryoma Sato, Zornitsa Kozareva, Sujith Ravi, and Makoto Yamada. Fixed support
tree-sliced wasserstein barycenter. IEICE Technical Report; IEICE Tech. Rep., 122(325), 2022.
[81] MINH TANG, AVANTI ATHREYA, DANIEL L SUSSMAN, VINCE LYZINSKI, and CAREY E PRIEBE.
A nonparametric two-sample hypothesis testing problem for random graphs. Bernoulli, 2017.
[82] PrasadTetali. Randomwalksandtheeffectiveresistanceofnetworks. JournalofTheoreticalProbability,
4, 1991.
[83] Yu Tian, Zachary Lubberts, and Melanie Weber. Curvature-based clustering on graphs. arXiv preprint
arXiv:2307.10155, 2023.
[84] C´edric Villani. Topics in optimal transportation, volume 58. American Mathematical Soc., 2021.
[85] C´edric Villani et al. Optimal transport: old and new, volume 338. Springer, 2009.
[86] NX Vinh, J Epps, and J Bailey. Information theoretic measures for clusterings comparison: Variants.
Properties, Normalization and Correction for Chance, 18, 2009.
[87] Ulrike Von Luxburg. A tutorial on spectral clustering. Statistics and computing, 17, 2007.
[88] Wei Wang, Dejan Slepˇcev, Saurav Basu, John A Ozolek, and Gustavo K Rohde. A linear optimal
transportation framework for quantifying and visualizing variations in sets of images. International
journal of computer vision, 101, 2013.
[89] Nik Weaver. Lipschitz algebras. World Scientific, 2018.
[90] Makoto Yamada, Yuki Takezawa, Ryoma Sato, Han Bao, Zornitsa Kozareva, and Sujith Ravi. Approx-
imating 1-wasserstein distance with trees. Transactions on Machine Learning Research, 2022.
[91] LuzhYeandWeigenYan. Resistancebetweentwoverticesofalmostcompletebipartitegraphs. Discrete
Applied Mathematics, 257, 2019.
[92] Ze Ye, Tengfei Ma, Chien-Chun Ni, Kin Sum Liu, Jie Gao, and Chao Chen. Ricci-{gnn}: Defending
against structural attacks through a geometric approach, 2021. URL https://openreview.net/
forum?id=˙qoQkWNEhS.
[93] Yin Zhang, Rong Jin, and Zhi-Hua Zhou. Understanding bag-of-words model: a statistical framework.
International journal of machine learning and cybernetics, 1, 2010.
A Proofs
This appendix contains deferred proofs from the remainder of the paper.
29A.1 Proofs from section 2
Proof of Theorem 2.1. We can derive the Lagrangian dual in a fairly straightforward manner. We rewrite
the constraint BJ “ α´β using the expresion
#
0 if BJ “ α´β
(82) sup φTpα´βq´φTpBJq “
φPℓpVq `8 otherwise.
Thus the Beckmann problem may be rewritten as the following
" *
(83) inf }J} “ inf }J} `supφTpα´βq´φTpBJq
w,p w,p
BJ“α´β J " φ *
(84) “ sup φTpα´βq`inf}J} ´φTpBJq ,
w,p
φ J
where we exchange the sup and inf using, e.g., Sion’s minimax theorem [73] or Slater’s condition. Now we
have that, using the Legendre transform of }¨} ,
p
(85) inf}Jpeq} ´φTpBJq “ inf}J} ´JTpBTφq
w,p w,p
J #J
0 if }BTφ} ď 1
(86) “
w1´q,q
´8 otherwise
since the dual norm to }¨} is }¨} . Therefore, the Lagrangian dual becomes
w,p w1´q,q
! › › )
(87) sup φTpα´βq : φ P ℓpVq,› BTφ› ď 1
w1´q,q
The special case of p “ 1 and q “ 8 follows from the same proof, with the only change being that the dual
norm to }¨} is }¨} , which can be shown directly or through a limiting argument.
w,1 w´1,8
Proof of Proposition 2.5. Let i,j P V be fixed distinct vertices. We begin by noting simply that by inspec-
tion,
r
Bpπ I q “ π pδ ´δ q
ij P ij i j
ij
and thus that
˜ ¸
ÿ ÿ
r
(88) B π I “ π pδ ´δ q
ij P ij i j
ij
i,jPV iÿ,jPV ÿ
(89) “ δ pπ1q ´ δ p1Tπq
i i j j
iPV jPV
(90) “ α´β.
Since Jπ ě 0 by construction, Jπ is a feasible edge flow for B pα,βq. The estimate on }Jπ} follows
p w,p
immediately from the triangle inequality.
Proof of Theorem 2.7. Suppose π P Πpα,βq is an optimal coupling for W pα,βq. For each i,j, let
dp,p
P
ij
P Ppi,jq be a choice of path which is minimal in the sense of d p, and let Jπ “ Jπ,pP ijq be the feasible
30flow as in Proposition 2.5. Then by H¨older’s inequality,
(91) B pα,βq ď }Jπ}
p ÿ w,p
(92) ď π }I }
ij P w,p
ij
i,ÿjPV
(93) ď π d pi,jq
ij p
i,jPV
˜ ¸
ÿ 1{p
(94) ď }1 } πpd pi,jqp
VˆV q ij p
i,jPV
˜ ¸
ÿ 1{p
(95) ď }1 } π d pi,jqp “ n2{qW pα,βq
VˆV q ij p dp,p
i,jPV
since π ď 1 and p ą 1.
ij
Proof of Proposition 2.13. The proof of this result is straightforward and comes in two parts. First, we
observe that W pα,βq “ W
pαp,βp
q where
p p
"ż *
(96) W pαp,βp qp “ inf |x ´y|pdπpx,yq : π P Πpαp,βp q .
p
RˆR
In this case, Πpαp,βp q is the set of all Borel probability measures on RˆR with respective marginals α,β.
Equality here holds because any such π P
Πpαp,βp
q, since it has discrete marginals, must itself be discrete and
supported on the Cartesian product t1,...,nuˆt1,...,nu; i.e., it can be written as a matrix. Thus, there
is a one-to-one correspondence between the feasible couplings on V ˆV and RˆR, and the cost of any
such pair of corresponding couplings is identical since shortest path distance on VpP q is |i ´j|.
n
The second part of the proof is classical, and it suffices to observe that the p-Wasserstein distance
between probability measures on R is simply the p-norm distance between their inverse cdfs. For a proof we
recommend, e.g., [64].
Proof of Proposition 2.14. We note that the signed incidence matrix B, which is of shape nˆn´1, must
have no kernel- for the rank of B agrees with the rank of BBT “ L, which is n ´ 1 for any connected
graph on n nodes. Therefore, for any 1 ď p ă 8, B pα,βq is the p-norm of the unique flow J such that
p
BJ “ α´β and which does not depend on p. We therefore need only show that BpK ´K q “ α´β. To
α β
wit, if i “ 1, note that
BK p1q “ K p1,2q “ αp1q,
α α
and if 1 ă i ă n,
BK piq “ K pi,i `1q´K pi ´1,iq “ αpiq,
α α α
and lastly if i “ n,
BK pnq “ ´K pn´1,nq “ αpnq´1.
α α
Therefore, with a simple cancellation, it holds BpK ´K q “ α´β for all i P V. The first equality in the
α β
proposition therefore follows, and the second follows immediately upon inspection.
Proof of Proposition 2.15. Once again the proof of this result is a matter of rigid feasibility: there can only
really be one feasible flow J P ℓpE1q satisfying BJ “ α´β owing to, e.g., rank considerations for Laplacians
on trees. Thus it is enough only to establish that BpK ´K q “ α´β. Let i P V be fixed, and suppose i
α β
has N incoming oriented edges, and M outgoing oriented edges. At the root of each incoming oriented edge
is a subtree I , and at the head of each outgoing oriented edge is a subtree O . This setup is illustrated in
ℓ ℓ
31I O
1 1
I i O
2 2
. .
. .
. .
I O
N M
Figure 7: A sketch of a vertex neighborhood in an oriented tree.
Fig. 7. For each 1 ď ℓ ď N, let αpI q be the total mass of α on that component, and similarly for αpO q. We
ℓ ℓ
split up the argument into a few cases depending on M,N. Assume for a moment that M ě 2 and N ě 1;
then by inspection we have
(97) pBK qpiq “ ´pαpI q`αpI q`...`αpI qq
α ˜ 1 2 N¸ ˜ ¸
ÿN ÿ ÿN ÿ
(98) ` αpiq` αpI q` αpO q `¨¨¨` αpiq` αpI q` αpO q
ℓ ℓ ℓ ℓ
ℓ“1 ℓ‰1 ℓ“1 ℓ‰M
ÿN ÿM
(99) “ Mαpiq`pM ´1q αpI q`pM ´1q αpO q
ℓ ℓ
ℓ“1 ℓ“1
(100) “ αpiq`M ´1.
If M “ 1 and N ě 1, then pBK qpiq “ αpiq. If M “ 0 and N ě 1, then pBK qpiq “ αpiq´1. If N “ 0,
α α
then pBK qpiq “ αpiq`M ´1, as before, since the only difference is the lack of contribution of the I ’s.
α ℓ
Therefore, BK “ α`c where c P Rn is a vector which does not depend on α, and thus it holds that
α
BpK ´K q “ α´β. The claim follows.
α β
A.2 Proofs from section 3
Proof of Theorem 3.13. We start by considering the pointwise value of the vector L:pα´βq. To this end,
a useful observation is that for any coupling π P Πpα,βq, we have
ÿ
α´β “ π pδ ´δ q.
ij i j
i,jPV
32With this in hand alongside Theorem 3.12, we can calculate
˜ ¸
ÿ ÿ
(101) L:pα´βq “ pL:q π pδ pjq´δ pjqq
i ij kℓ k ℓ
jPV k,ℓPV
ÿ
1
(102) “ pHpρ,jq´Hpi,jqqπ pδ pjq´δ pjqq
kℓ k ℓ
volpGq
j,k,ℓPV
ÿ
1
(103) “ π pHpρ,kq´Hpi,kq´Hpρ,ℓq`Hpi,ℓqq
kℓ
volpGq
k,ℓPV
ÿ ÿ
1
(104) “ α pHpρ,kq´Hpi,kqq´ β pHpρ,ℓq´Hpi,ℓqq
k ℓ
volpGq
k ℓ
ÿ
1
(105) “ pα ´β qpHpρ,kq´Hpi,kqq
k k
volpGq
k
ÿ
1
(106) “ c ´ pα ´β qHpi,kq
k k
volpGq
k
where by introducing the placeholder c for some c P R, we are separating the first piece of the summand
which does not depend on i and which will be eliminated in the subsequent calculation. Then, multiplying by
pα´βqT, and using the fact that pα´βqT1 “ 0, we get
n
ÿ
1
(107) pα´βqTL:pα´βq “ ´ pα ´β qpα ´β qHpi,kq
i i k k
volpGq
i,kPV
ÿ ÿ
1
(108) “ ´ pα ´β q pα Hpi,kq´β Hpi,kqq
k k i i
volpGq
kPV iPV
ÿ
1
(109) “ ´ pα ´β qpHpα,kq´Hpβ,kqq
k k
volpGq
kPV
using Proposition 3.11(i) in the final line. The claim follows.
Proof of Corollary 3.14. From the proof of Theorem 3.13 and H¨older’s inequality, we have
ÿ
1
(110) r “ ´ pα ´β qpα ´β qHpi,kq
αβ i i k k
volpGq
i,kPV
ÿ ÿ
1
(111) “ pβ ´α q pα ´β qHpi,kq
k k i i
volpGq
k › i ›
›ÿ ›
1 › ›
(112) ď }α´β} › pα ´β qHpi,kq›
volpGq 1› i i ›
i 8
2
(113) ď maxtHpα,βq,Hpβ,αqu.
volpGq
whereinthefinallinewemakeuseofProposition3.11(ii). ThesecondinequalityintheCorollaryfollowsfrom
ř
the observation in the proof of Theorem 3.13 that if π P Πpα,βq is any coupling, α´β “ π pδ ´δ q.
i,jPV ij i j
Then since x ÞÑ }L´1{2x}2 is convex in x,
2
› ›
› ›2
(114) pα´βqTL:pα´βq “ ›L´1{2pα´βq›
› 2 ›
›ÿ ›2
› ›
(115) “ › π L´1{2pδ ´δ q›
› ij i j ›
ÿi,j 2
(116) ď π r .
ij ij
i,j
33Thus in the special case where π “ αβT,
ÿ
1
(117) r ď α β pHpi,jq`Hpj,iqq
αβ i j
volpGq
i,jPV
1
(118) “ pH pα,βq`H pβ,αqq.
n n
volpGq
Proof of Theorem 3.22. Let µ P C1pr0,1sq such that µ “ α and µ “ β. Then we estimate, using
t 0 1
Proposition 3.20 and the fact that L: “ L:LL:,
ż ż
1 1
(119) }dµ }2 dt “ pdµ qTL:dµ dt
t H9´1pVq t t
0 ż0
1
(120) “ pL:dµ qTLpL:dµ qdt
t t
ż0
1 ÿ ˇ ˇ
ˇ ˇ2
(121) “ w L:dµ piq´L:dµ pjq dt
ij t t
0
pi,jqPE1
ż
ÿ 1ˇ ˇ
ˇ ˇ2
(122) “ w L:dµ piq´L:dµ pjq dt
ij t t
0
pi,jqPE1
ˇż ˇ
ÿ ˇ 1 ˇ2
ˇ ˇ
(123) ě w ij ˇ pL:dµ tpiq´L:dµ tpjqqdtˇ
0
pi,jqPE1
where the final inequality follows from Jensen’s inequality. Then, focusing on the inner term and letting
e “ pi,jq P E1 we evaluate
ż ˆż ˙
1 1
(124) pL:dµ piq´L:dµ pjqqdt “ BT L:dµ dt peq
t t t
0 ˆ0ż ˙
1
(125) “ BTL: dµ dt peq
t
0
(126) “ BTL:pβ´αqpeq.
(127)
Hence,
ˇż ˇ
ÿ ˇ 1 ˇ2 ÿ ˇ ˇ
(128) w ij
ˇ
ˇ pL:dµ tpiq´L:dµ
tpjqqdtˇ
ˇ “ w ij
ˇ BTL:pβ´αqpi,jqˇ2
0
pi,jqPE1 pi,jqPE1
(129) “ pL:pβ´αqqTLpL:pβ´αqq
(130) “ pα´βqTL:pα´βq,
and therefore,
"ż *
1
(131) inf }dµ }2 dt : µ P C1pr0,1sq,µ “ α,µ “ β ě pα´βqTL:pα´βq “ B pα,βq2.
t H9´1pVq t 0 1 2
0
For the reverse inequality, it is sufficient to consider the special curve µ “ p1´tqα´tβ, which satisfies
ş t
1 }dµ }2 dt “ pα´βqTL:pα´βq “ B pα,βq2.
0 t H9´1pVq 2
34Proof of Theorem 3.25. We observe first that the collection of vectors tdTu Ă ℓpVq is convex; for the
TPT
first two conditions (i) and (ii) are equivalent to the intersection of a finite number of linear constraints; and
(iii) is stable under convex combinations. Since L´1{2 is a linear map, the image L´1{2A will be convex for
i
i “ 1,2. Separately, we have for S,T P T:
(132) }Tα ´Sα } “ }pα ´α q`pdT ´dSq}
1 2 2 1 2 2
(133) ě |}α ´α } ´}dT ´dS} |
1 2 2 2
(134) ě }α ´α } ´2δ ą 0.
1 2 2
Thus,
(135) min }Tα ´Sα } ą 0
1 2 2
S,TPT
andhenceA XA “ ∅. NotemoreoverthatL´1{2 (andmoregenerally,anypowerofL)willactnonsingularly
1 2
on mean zero vectors since its kernel is exactly the constant functions. Therefore, since Tα ´Sα is mean
1 2
zero for any T,S, and since A and A are disjoint, the sets L´1{2A and L´1{2A are disjoint as well; and
1 2 1 2
thus they are linearly separable.
35