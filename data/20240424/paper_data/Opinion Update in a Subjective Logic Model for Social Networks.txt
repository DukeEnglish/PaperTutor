Opinion Update in a Subjective Logic Model for
Social Networks
M´ario S. Alvim1, Sophia Knight2, and Jos´e C. Oliveira2
1 Department of Computer Science, UFMG, Brazil
msalvim@dcc.ufmg.br
2 Department of Computer Science, University of Minnesota Duluth, USA
sophia.knight@gmail.com, josecarlosdeoliveirajr@gmail.com
Abstract. SubjectiveLogic(SL)isalogicincorporatinguncertaintyand
opinionsforagentsindynamicsystems.Inthiswork,weinvestigatethe
use of subjective logic to model opinions and belief change in social
networks. In particular, we work toward the development of a subjec-
tivelogicbelief/opinionupdatefunctionappropriateformodelingbelief
change as communication occurs in social networks. We found through
experimentsthatanupdatefunctionwithbelieffusionfromSLdoesnot
haveidealpropertiestorepresentarationalupdate.Evenwithoutthese
properties, we found that an update function with cumulative belief fu-
sion can describe behaviors not explored by the social network model
defined by Alvim, Knight, and Valencia [3].
Keywords: Socialnetworks·SubjectiveLogic·Beliefchange·Dynamic
opinions · Multi-agent systems
1 Introduction
Recently, social networks have begun to influence every aspect of our lives,
with unprecedented, unanticipated consequences, especially in politics and pub-
lic opinion. Research on social networks has studied opinions and their change
overtime,buttoaccuratelymodelrealpeopleandtheiropinionsandbeliefs,we
mustincluderepresentationsofuncertainty informalmodelsofsocialnetworks.
Toachievethisgoal,weusesubjective logic (SL),whichincludesinformation
about agents’ uncertainty, to develop a more nuanced model of social networks
and their changes over time. This work builds upon the model developed by
Alvim,Knight,andValencia(AKV)[3].Theirsocialnetworkmodelincorporates
quantitative opinions and influence on each agent but only addresses binary
opinions and uncertainty is not represented.
The contributions of this paper are the following:
– We propose a model for social networks using elements of the subjective
logic model such as multinomial opinions, trust opinions, and belief fusion
operators.
4202
rpA
32
]AM.sc[
1v98741.4042:viXra2 M. S. Alvim et al.
– We propose a belief/opinion update function using SL’s trust discount and
belief fusion. We use examples to show that our update function, with cu-
mulative, averaging, and weighted belief fusions, does not satisfy proprieties
that are useful to model a basic social network with rational update.
– We analyze the update function using trust discount and cumulative belief
fusionfromsubjectivelogicandhowitcanrepresentadifferentscenarionot
described in the model proposed by Alvim, Knight, and Valencia [3].
2 Related Work
There is a great deal of work concerned with logical models of social networks
and formalizing belief change in social networks, but we are unaware of other
work modeling quantitative uncertainty in social networks. More specifically,
other work allows uncertainty only in the sense of multiple states or worlds
that an agent considers possible, whereas in this work we use subjective logic,
considering uncertainty as a total lack of information, on top of the multiple
states an agent may consider possible. Much of the literature treats opinions
as binary, non-quantitative phenomena, whereas we investigate opinions that
take on a spectrum of values between 0 and 1, and which also include possible
uncertainty.
Before the advent of online social networks, Degroot et al. [7] proposed a
model of learning and consensus in multi-agent systems, in which quantitative
beliefs are updated by a constant stochastic matrix at each time step. The De-
groot model does not include uncertainty but otherwise is close to our work in
spirit. The models in [4] are also similar to the models we use, but the focus
of that work is on payoffs and optimal decision-making, whereas our focus is
purely on the changes in information and uncertainty over time. Incorporating
goals and decisions into our models provides an interesting problem for future
work, particularly in the context of our focus on uncertainty. In [8], Holliday
develops a logic with ordered but non-quantitative trust and certainty about
propositions: agent a may trust agent b more than they trust agent c, leading
them to believe certain propositions more strongly than others. Liu et al. [12]
use ideas from doxastic and dynamic epistemic logics to qualitatively model in-
fluence and belief changes in social networks. Christoff [6] has developed several
non-quantitativelogicsforsocialnetworks,andYoungPedersen[13,15]develops
a non-quantitative logic concerned specifically with polarization. In [14], Xiong
and ˚Agotnes develop a logic to analyze signed social networks where agents can
have“friends”and“enemies,”adifferentapproachtosomeofthesamequestions
that concern us, such as polarization and influence.
Hunter[9]introducesalogicofbeliefupdatesoversocialnetworkswithvary-
ing levels of influence and trust. Using dynamic epistemic logic, Baltag et al. [5]
created a threshold model where agents’ behavior changes when the proportion
of supporters changes, but with binary belief and no uncertainty.
ThisworkisacontinuationofAlvimetal.’swork[1,2,3].Alvimetal.develop
a formal model for social networks where agents have quantitative opinions andOpinion Update in a Subjective Logic Model for Social Networks 3
quantitative influence on each other, with a function for agents’ belief update
over time. The goal of the current paper is to extend this model by adding the
possibility of uncertainty to the agents’ quantitative opinions.
3 Background: Subjective Logic
This section provides background on the elements of subjective logic that we
use in our model. Subjective Logic is a logic developed by Jøsang [10] that ex-
tends probabilistic logic by adding uncertainty and subjectivity. In probabilistic
logic, a uniform distribution does not express “we don’t know” because a uni-
form distribution says that we know that the distribution over the domain is
uniform. Subjective logic can distinguish between the situation where the dis-
tribution over outcomes is unknown and the situation where the distribution is
known and, for example, uniform. In subjective logic, it is also possible to have
a situation where some information about the distribution is known and there
is some uncertainty. The subjectivity comes from the fact that we can assign an
opinion, or information, about a proposition to an agent.
Opinion representation The main object of subjective logic is the opinion.
We represent an opinion by ωA, where A is an agent, X a random variable,
X
and ωA is A’s opinion about X. An opinion expresses support for none, one,
X
or many states of a domain. This section presents the elementary definitions
that compose an opinion. A domain is a state space consisting of a finite set of
values called states, events, outcomes, hypotheses, or propositions. The values
are assumed to be exclusive and exhaustive.
Belief mass is a distribution over a domain X representing an agent’s confi-
dence in each value in the domain. The belief mass assigned to a value x ∈ X
(cid:80)
expressessupportforxbeingTRUE.Beliefmassissub-additive,i.e. b (x)≤
X
x∈X
1.Thesub-additivityiscomplementedbyuncertaintymass u anditrepresents
X
the lack of support or evidence for the variable X having any specific value.
Definition 1. (Belief Mass Distribution) Let X be a domain of size k ≥ 2,
and let X be a variable over that domain. A belief mass distribution denoted
b : X → [0,1] assigns belief mass to possible values of the variable X. Belief
X
(cid:80)
mass and uncertainty mass sum to one, i.e., u + b (x)=1.
X X
x∈X
Opinionscanbesemanticallydifferent,dependingonthesituationtheyapply
to.Analeatory opinionappliestoavariablegovernedbyarandomorfrequentist
process, and represents the likelihood of values of the variable in any unknown
past or future instance of the process. “The (biased) coin will land heads with
p=0.6”isanaleatoryopinion.Anepistemic opinionappliestoavariablethatis
assumedtobenon-frequentist,andthatrepresentsthelikelihoodofthevariables
inaspecificunknowninstance.“Beatriz killed Evandro”isanepistemicopinion.
Inanepistemicopinion,opposite/differentpiecesofevidenceshouldcanceleach
other out. Therefore, it must be uncertainty-maximized.4 M. S. Alvim et al.
Base rate distribution represents a prior probability distribution over a do-
main:theprobabilitydistributionbeforeconsideringevidenceaboutthedomain.
Definition 2. (Opinion) Let X be a domain of size k ≥ 2, and X a random
variable in X. An opinion over the random variable X is the ordered triple ω =
X
(b ,u ,a ) where
X X X
– b is a belief mass distribution over X,
X
– u is the uncertainty mass which represents a lack of evidence,
X
– a is a base rate distribution (a probability distribution) over X.
X
The projected probability distribution of an opinion is the posterior probabil-
ity distribution after updating the base rate distribution with the belief mass
distribution. The more an opinion depends on the belief mass, the less it de-
pends on the base rate. The projected probability distribution is defined by
P (x)=b (x)+a (x)u , ∀x∈X
X X X X
ThisrepresentationisequivalenttorepresentinganopinionasaBetaPDF(or
DirichletPDFifk >2),wheretheposteriorprobabilityisobtainedbyupdating
theparametersαandβ(oravectorofparametersαfortheDirichletPDF)given
the observations. The equivalence is defined as the projected probability from
SL’sopinionbeingequivalenttotheexpectedprobabilityoftheBetaPDF.More
details about the equivalence between opinions and Beta PDFs are presented in
Appendix A.
The definition of opinion is useful for our model since it is more expressive
thanthebeliefstate ofanagentaboutapropositionin[3],whichissimilarlyan
opinion with domain X = {true,false}, with no uncertainty mass. The agent
must commit all of their mass to the values of the domain with no uncertainty.
Example 1. Let X={x,x} be a domain where x is “global warming is happen-
ing”andxis“globalwarmingisnot happening”.LetX bearandomvariablein
X.AnopinionaboutX mustbeepistemicbecauseitisaboutafactinthepresent
instance that is true or false. Let the base rate be uniform. With no evidence,
an agent A will hold the opinion ωA = ((0,0),1,(0.5,0.5)) with PA(x) = 0.5,
X X
meaning that A is 50% sure that the global warming is happening, but their
opinion is relying only on the base rate, with no evidence supporting either of
the values.
After gathering evidence from newspapers, scientific studies, and other peo-
ple,Aassignsabeliefmasstox.IfagentAholdstheopinionωA =((0.6,0),0.4,
X
(0.5,0.5)), then PA(x) = 0.8. In this case, A is 80% sure that global warm-
X
ing is happening, and has evidence that corresponds to 60% of their mass. The
uncertainty mass means that A is relying 40% on the base rate.
Trust discount To model the influence that one agent has on another, subjec-
tive logic has trust opinion, an opinion an agent has about another agent as a
source of information.Opinion Update in a Subjective Logic Model for Social Networks 5
Definition 3. (Trust opinion) Let T = {t ,t } be a trust domain, where t
B B B B
means“B isagoodsourceofinformation”andt means“B isnotagoodsource
B
of information”. Then ωA , or ωA for short, is the (trust) opinion that A has
tB B
about the trustworthiness of B as a source of information.
Weusetrustopinionstomodelanagent’supdatedopinionaftercommunica-
tion:ω[A;B] isanewopiniongeneratedbytakingbeliefmassωB proportionalto
X X
thebeliefmassofthetrustopinionωA.Andω[A;B] representsA’sopinionabout
B X
X after communicating with B, ωA represents A’s opinion about B’s trust-
B
worthiness, and ωB represents B’s opinion about X. The operation is denoted
X
ω[A;B] =ωA⊗ωB.
X B X
Thereareseveraloptionsforcomputingthisvalue,dependingonthesituation
being modeled. Developing an accurate function for opinion updates in social
networks is a focus of the current paper.
Example 2. Let ωA = ((1,0),0,aA) with PA(t ) = 1 and ωB = ((0.6,0),0.4,
B B B B X
(0.5,0.5)) with PB(x) = 0.8. Here, A completely trusts B and B is 80% sure
X
that x is true with 60% of their mass assigned to x.
PA(t ) = 1, i.e. A completely trusts B. Then, A by trusting B (in short
B B
[A;B]) will hold the same opinion as B about X. Therefore, ω[A;B] = ωB. By
X X
theopinionthatAhasaboutX bytrustingB,Ais60%surethatxistruewith
80% of their mass assigned to x.
Example 3. Let ωA = ((0.5,0.5),0,aA) with PA(t ) = 0.5 and ωB = ((0.8,0),
B B B B X
0.2,(0.5,0.5)) with PA(x) = 0.9. Here, A trusts B by 50% and B is 80% sure
X
that x is true with 60% of their mass assigned to x.
PA(t ) = 0.5. Then, [A;B] will hold 50% of the belief mass of each value
B B
fromB.Therefore,ω[A;B] =((0.4,0),0.6,(0.5,0.5))withP[A;B](x)=0.7.Bythe
X X
opinion that A has about X by trusting B, A is 70% sure that x is true with
40% of their mass assigned to x.
Belief fusion TomodelA’sconcurrentinteractionswithmultipleotheragents,
we use belief fusion [10,11]. Belief fusion combines a set of opinions into a single
opinion which then represents the opinion of the collection of sources. There is
more than one possible definition for the belief fusion operator. The possible
definitionsdifferintheirpropertiesandapplications.Below,weomitthedetails
of the calculation of the fusion operators and instead, explain the intuition. For
more details, see [10]. For our model, we consider the following operators from
[10,11]:
– Cumulative belief fusion (denoted ω(A⋄B) = ωA ⊕ ωB): Used when it is
X X X
assumed that the amount of independent evidence increases by including
more sources. The idea is to sum the amount of evidence of the opinions. It
isnon-idempotent.E.g.asetofagentsflipsacoinseveraltimesandproduces
an opinion about the bias of the coin. An opinion produced by cumulative
belief fusion represents all the experiments made by the agents.6 M. S. Alvim et al.
– Averaging belief fusion (denoted ω(A⋄B) =ωA⊕ωB): It is used when includ-
X X X
ingmoresourcesdoesnotmeanthatmoreevidencesupportstheconclusion.
The idea is to take the average of the amount of evidence of the opinions. It
is idempotent, but it has no neutral element. E.g. After observing the court
proceedings, each member of a jury produces an opinion about the same
evidence. The verdict is the fusion between those opinions.
– Weighted belief fusion (denoted ω(A⋄ˆB) =ωA⊕ˆωB): It is used when we take
X X X
theaverageoftheamountofevidenceoftheopinionsweightedbytheirlack
of uncertainty. In particular, opinions with no belief mass are rejected. It is
idempotent and it has a neutral element u = 1. E.g. a group of medical
X
doctors needs to decide on a diagnosis. Each of them has an opinion, but
some of them are more certain (assigned more belief mass) than others.
Those opinions must have more weight than the others upon fusion.
Each of these operators is defined in the Appendix B.
4 A Subjective Logic model for social networks
We describe how to use subjective logic to model a social network. Existing no-
tionsfromsubjectivelogicworkwellformodelingtherelevantaspectsofagents’
opinions about an issue in a social network, except for the update function. Our
goal is to expand subjective logic with an appropriate update function.
4.1 Static elements of the model
The static elements represent a snapshot of a social network at a given point in
time. They include the following components:
– A (finite) set A={A ,A ,...,A } of n≥1 agents. An agent is a user in
0 1 n−1
a social network
– Adomain ofk disjointeventsX={x ,x ,...,x }andarandomvariable
0 1 k−1
X over X. A domain is a generalization of a proposition from binary logic
byhavingmultipletruthvaluesforaproposition.Apropositionfrombinary
logic would have a domain of size 2. It can represent topics that cannot
be answered with just a YES or NO. In the examples in this work, we use
a domain of size two for simplicity, and the random variable X represents
opinions about a single issue.
– A set of opinions {ωAj} , one for each agent, about a single random
X Ai∈A
variable X.
4.2 Dynamic elements of the model
The dynamic elements of the model formalize the evolution of agents’ beliefs as
they interact and communicate about their opinions over time. They include:Opinion Update in a Subjective Logic Model for Social Networks 7
– Asetoftrustopinions {ωAi} overthedomainT ={t ,t }where
Aj Ai,Aj∈A Aj Aj aj
A ,A ∈A and i̸=j. Each trust opinion represents how much A trusts A
i j i j
asasourceofevidence.Weconsidertrustopinionasdogmatic,i.e.theuncer-
taintymassisi =0foralltrustopinions.Therefore,PAi(t )=bAi(t ).
Tj Aj Aj Aj Aj
Throughout this paper, we represent a trust opinion only by PAi(t ).
Aj Aj
– A time frame T = {0,1,2,...,t } representing the discrete passage of
max
time.
– An update function f such that
ωAi[t+1] =f(ωAi[t],{ωAi} ,{ωAj[t]} ). (1)
X X Aj Aj∈A X Aj∈A
An update function f takes A ’s opinions at time t and updates it using all
i
other agents’ opinions and trust opinions to them. Here we consider that
agents have complete trust in themselves. Otherwise, we can define this
function with A ’s opinion included in the set of opinions {ωAi} .
i Aj Aj∈A
5 Applying trust discount and belief fusion
The intuition behind our planned update function is to fuse agent A’s current
opinion with all the opinions that A can gather by trusting other agents. Define
a dogmatic opinion as an opinion with no uncertainty, i.e. u = 0. For this
X
update function, we are not considering situations with dogmatic opinions, be-
causeitmeanstheagenthasaninfiniteamountofevidenceandthebelieffusion
operators remove non-dogmatic opinions when at least one is present.
Definition 4. (Update function with Belief Fusion and Trust) Let ωA0[t],··· ,
X
ωAn−1[t] be non-dogmatic opinions. Let ⊕ be a belief fusion operator. Define the
X
update function for ωAn[t+1] as
X
ωAn[t+1] =ωA[t]⊕ (cid:77) (ωAn ⊗ωAn[t]). (2)
X X Am X
Am∈A
m̸=n
Our goal in this section is to understand the effects and properties of the
proposed update function applied to only two agents. Doing so will properly
set a foundation to understand the same effects and properties on a large-scale
model. Now we define the update function for two agents with examples and
experiments.
Definition 5. (Update function for two agents with Belief Fusion and Trust)
Let ωA[t] and ωB[t] be non-dogmatic opinions. Let ⊕ be a belief fusion operator.
X X
Define the update function for ωA[t+1] as
X
ωA[t+1] =ωA[t]⊕(ωA⊗ωB[t]). (3)
X X B X8 M. S. Alvim et al.
We call (ωA ⊗ωB[t]) the opinion that A will learn by interacting with B.
B X
ωA[t+1] is the opinion that A holds after merging their previous opinion (ωA[t])
X X
with the opinion that A learned (ωA⊗ωB[t]).
B X
Example 4. For brevity, we write the value of PA(t ) where it should be ωA. If
B B B
ωA[t] =((0,0),1,(0.5,0.5)), PA[t](x) =0.5
X X
ωA =((0.5,0.5),0,aA), PA(t ) =0.5 (4)
B B B B
ωB[t] =((0.8,0),0.2,(0.5,0.5))) PB[t](x)=0.9,
X X
then
ωA[t+1] =((0,0),1,(0.5,0.5))⊕(0.5⊗((0.8,0),0.2,(0.5,0.5)))
X (5)
=((0,0),1,(0.5,0.5))⊕((0.4,0),0.6,(0.5,0.5)).
Agent A is 50% sure about x and B is 90% about x. Both trust each other
by50%.Asweshowbelow,therearedifferentoutcomesdependingonthechoice
of fusion operator.
Example 5. Now consider these two agents iteratively updating their opinion
over time.
ωA[0] =((0.2,0),0.8,(0.5,0.5)) PA[0](x)=0.6 PA(t )=0.5
X X B B (6)
ωB[0] =((0.8,0),0.2,(0.5,0.5)) PB[0](x)=0.9 PB(t )=0.5
X X A A
Here,initiallyagentAis60%sureaboutxandB is90%aboutx.Bothtrust
each other by 50%. The iterated evolution of PA(x) and PB(x) over 20 time
X X
steps is shown in Fig. 1.
Fig.1. PA(x) (blue) and PB(x) (orange) updated 20 times as in Example 5.
X X
Say that weak convergence means that A cannot move further from B upon
update, i.e. PA[t] ≤ PA[t+1] ≤ PB[t] or PA[t] ≥ PA[t+1] ≥ PB[t]. We expected
X X X X X X
thattheupdatefunctionwouldweaklyconvergebyPA(x)andPB(x)converging
X X
to some value between PA[0](x)=0.6 and PB[0](x)=0.9. But because evidence
X XOpinion Update in a Subjective Logic Model for Social Networks 9
keeps accumulating over time, with cumulative belief fusion, PA(x) and PB(x)
X X
converge to 1. Therefore, the update function with cumulative fusion does not
weakly converge.
For averaging and weighted belief fusion, PA(x) and PB(x) converge to 0.5,
X X
violatingweakconvergence.Withepistemicopinions,increasinguncertaintyover
timeisexpected,butthesamehappenswithaleatoryopinionsbecausethetrust
discount removes an amount of evidence from each agent at every step.
Example 6. In this case, A and B have the same opinion and the same trust.
ωA[0] =((0.6,0),0.4,(0.5,0.5)) PA[0](x)=0.8 PA(t )=0.5
X X B B (7)
ωB[0] =((0.6,0),0.4,(0.5,0.5)) PB[0](x)=0.8 PB(t )=0.5
X X A A
Here, A and B have the same opinion. They are 80% sure about x. Both
trust each other by 50%. The evolution of PA(x) and PB(x) is shown in Fig. 2.
X X
Fig.2. PA(x) and PB(x) (both orange) updated 20 times as in Example 6.
X X
Even starting with the same opinion, agents A and B do not keep the same
opinion over time. With cumulative belief fusion, A and B keep accumulating
evidence and PA(x) and PB(x) converge to 1. With averaging or weighted
X X
belief fusion, uncertainty keeps increasing, and PA(x) and PB(x) converge to
X X
0.5. The example shows none of the belief fusion operators make the update
idempotent with respect to the agents’ opinions. None of these operators can
represent the case where agents with the same opinion, when interacting, keep
the same opinion over time.
In this section, we showed that an update function when belief fusion and
trustdiscountdonothaveidealpropertiesthatcanbeusefultomodelarational
update in a social network. Even without these properties, in the next section,
we show that an update function with cumulative belief fusion can represent a
differentkindofbiasnotexploredinAlvim,Knight,andValencia’swork[1,2,3].
6 Analysis of the update function with cumulative belief
Inthissection,weanalyzethecumulativebelieffusionoperator,whichwebelieve
in practice provides some interesting outcomes in simple simulations of social10 M. S. Alvim et al.
networks, even though it does not always weakly converge, as seen above. We
will show that the cumulative belief function is promising for modeling belief
updates in social networks.
Recalling the definition of cumulative belief fusion, it is assumed that the
amountofevidenceincreasesbyincludingmoresources.Anopinioninsubjective
logiccanbetranslatedtoaBetaPDFusingtheamountofevidenceforeachstate
in the domain as parameters. Say that rA(x) are rA(x) the amount of evidence
X X
supporting the state x for agents A and B respectively. The cumulative fusion
operatorgetsthesumrA(x)+rA(x)tobetheamountofevidenceofthemerged
X X
opinion and translates it back to a subjective logic opinion. More details are
presentedintheappendix.Forrepeatedinteractionsusingthecumulativebelief
fusion, we interpret repeated evidence contained in an opinion as reinforcement
of the belief in the state.
We did many simulations using the two-agent update function with cumu-
lative fusion and we found three cases for initial epistemic opinions with the
projected probability PA(x) ranging from 0 to 1.
X
Suppose that X = {x,x} and all opinions are epistemic. Recall that the
update function for two agents with trust discount and belief fusion is
ωA[t+1] =ωA[t]⊕(ωA⊗ωB[t]) (8)
X X B X
whereAandB areagents,ωA[t] andωB[t] arenon-dogmaticepistemicopinions,
X X
and ωA is a trust opinion. Also, recall that ωA ⊗ωB[t] is the opinion that A
B B X
learns after trusting B about X. The update function behaves like these three
cases:
1. Consensus:Thiscase happenswhen bothagentsareagreeingordisagreeing
at the same time, not necessarily with the same projected probability, i.e.
PA[0](x)<0.5 and PA(t )⊗PB[0](x)<0.5 or
X B b X (9)
PA[0](x)>0.5 and PA(t )⊗PB[0](x)>0.5
X B b X
When these agents interact, they will accumulate evidence about the same
outcome in each interaction. The fusion leads bA(x) and bB(x) to converge
X X
to 0 or 1, depending on what they are agreeing upon, and both with un-
certainty mass to 0. Increasing the trust discount or the uncertainty will
increase the speed of convergence.
This represents a situation when two agents agree that x is TRUE, with
different levels of projected probabilities. That leads them to be completely
certain about the proposition.
Example 7. Let A and B be initially in consensus agreeing that x is TRUE
as follows.
ωA[0] =((0.2,0.0),0.8,(0.5,0.5)) PA[0]x=0.6 PA(t )=0.5
X X B b (10)
ωB[0] =((0.4,0.0),0.6,(0.5,0.5)) PB[0]x=0.7 PB(t )=0.5
X X A bOpinion Update in a Subjective Logic Model for Social Networks 11
A is 60% sure about x and B is 70% sure about x. Both trust each other by
50%.OnthelimitoftheinteractionsbetweenAandB,bothwillbesureby
100% that x is true.
PA[t](x)=PB[t](x)−t −→ −∞
→1 (11)
X X
SimilarlyifbothdisagreethatxisTRUE,i.e.thatxisTRUE,PA[t](x)and
X
PB[t](x) will converge to 0.
X
Fig.3. On the left, the evolution of PA[t](x) and PA[t](x) for the Example 7. On the
X X
right, the similar case for when both agents disagree that x is TRUE.
2. Balanced opposite: This case happens when both agents are learning the
exact opposite opinion that A already had, i.e.
PA[0](x)=1−PA(t )⊗PB[0](x), ∀x∈X (12)
X B b X
Becausecontrarypiecesofevidencecanceleachother,thefusionleadsbA[0](x)
X
to be a vacuous opinion. The speed of convergence is defined by the trust
opinion. The more an agent trusts another, the faster the convergence.
Thisrepresentsasituationwhentwoagentssupportoppositeviewsbutwith
the same projected probability. That leads them to be completely indecisive
about the proposition.
Example 8. Let A and B have balanced opposite opinions.
ωA[0] =((0,0.4),0.6,(0.5,0.5)) PA[0](x)=0.3 PA(t )=1
X X B B (13)
ωB[0] =((0.4,0),0.6,(0.5,0.5)) PB[0](x)=0.7 PB(t )=1
X X A A
A is 30% sure about x and B is 70% sure about x. Both trust each other by
100%. On the limit of interactions between A and B, both will be sure by
50% that x is true.
PA[t](x)=PB[t](x)−t −→ −∞
→0.5 (14)
X X12 M. S. Alvim et al.
Fig.4. Evolution of PA[t](x) and PA[t](x) for the Example 8.
X X
3. Unbalanced opposite:Thishappenswhenthereareoppositebeliefs,butthey
don’thavethesameprojectedprobabilityintheirrespectiveviews.Inother
words, both are in conflict but one agent is more radical than the other.
(PA[0](x)<0.5 and PA(t )⊕PB >0.5
X B b X
or PA[0](x)>0.5 and PA(t )⊕PB <0.5) (15)
X B b X
and PA[0] ̸=1−PA(t ) PB[0](x)
X B b X
Inthiscase,contrarypiecesofevidencewillcanceleachother,butoneagent
will transmit more evidence than the other upon interaction. The agents
that transmit more evidence will win in the limit. Increasing the trust or
becoming more radical will increase the speed of convergence.
– If A is sure that x is TRUE more than B is sure that x is FALSE
discounted by the trust, i.e.
PA[t](x)>1−PA(t )⊗PB[t](x) (16)
X B b X
then,AandB willeventuallybothagreethatxisTRUEinsomedegree,
i.e.
PA[t](x)=PB[t](x)−t −→ −∞
→p∈(0.5,1] (17)
X X
– If A is sure that x is FALSE more than B is sure that x is TRUE
discounted by the trust, i.e.
PA[t](x)<1−PA(t )⊗PB[t](x) (18)
X B b X
then,AandBwilleventuallybothagreethatxisFALSEinsomedegree,
i.e.
PA[t](x)=PB[t](x)−t −→ −∞
→p∈[0,0.5) (19)
X X
The unbalanced opposite is the most interesting case. It can represent some
bias when conflicting agents are interacting. The behavior is different from any
update function described by [3]. After experiments, we found thatOpinion Update in a Subjective Logic Model for Social Networks 13
– If the agents are too far, they will radicalize, i.e.
PA[t](x)−t −→ −∞
→0 or
X
PA[t](x)−t −→ −∞
→1
X
– Otherwise,theywillconvergetosomevalueatthewinningoutcome.[0,0.5)
ifAissurethatxisFALSEmorethanB issurethatxisTRUEdiscounted
bythetrust,or(0.5,1]ifAissurethatxisTRUEmorethanB issurethat
x is FALSE discounted by the trust.
Thisbehaviorshowsthatwehaveafixed-pointforPA[0](x)foreachPB[t](x)
X X
such that PB[0](x) = PB[t](x) when t goes to infinity, in other words, for every
X X
initial A’s opinion there is an initial B’s opinion such that A’s and B’s opinions
willbotheventuallyconvergetoB’sinitialopinion,whenAandB communicate
repeatedly. Fig. 5 shows the results from the experiments. We found the fixed-
points by a binary search for each PA[0](x).
X
Fig.5. Fixed point for PA[0](x) for each PB[t](x)
X X
The experiments show that the fixed-point function has a curve similar to
the logistic function. Each fixed-point represents the boundary between the re-
gion where two agents will radicalize and the region where they will eventually
agreeonsomelessradicalpoint.Webelievethattheradicalizationphenomenon
happens because the agents are transmitting evidence in an unstable way, when
the proportion of evidence x vs. x increases over time. They do not radicalize
when the agents are transmitting evidence in a stable way, when the proportion
of evidence x vs. x is the same over time.
7 Future Work and Conclusions
In this work, we described a subjective logic model for social networks. It is
defined by a set of agents representing users in a social network, a domain of14 M. S. Alvim et al.
disjoint events that can be used to represent a topic that cannot be answered
with simply YES or NO, a set of multinomial opinions to represent the opinion
of each user, trust opinions to represent the relationship between users and an
update function to represent the interaction between users.
The main focus of this work is to define an update function. Many update
functions can be used depending on what kind of interaction is represented.
We did experiments with three update functions using cumulative belief fusion,
averaging belief fusion, and weighted belief fusion, with trust discount. The ex-
periments showed that none of these functions have useful properties to model
the rational update function described in [3] such as idempotency, weak conver-
gence, and non-increasing uncertainty.
Through experiments, we showed that our update function with cumulative
belief fusion has the potential to represent a kind of interaction not described
in [3], even though it does not meet our initial desired properties for an update
function.Wealsoshowedthatiftheagentsdisagreeaboutaproposition,i.e.they
haveoppositeopinions,thereisacloseenoughdistancebetweenthemwherethe
update is stable, and they converge to a non-radical point. But if they are far
enough, they will still converge, but also radicalize, converging to completely
agree or completely disagree about the proposition. This is different from the
update function describing confirmation bias from [3], where . The next step for
the update function with cumulative fusion is to have a clear definition of this
behavior by calculating the convergence of the update function for each case.
References
1. Alvim, M.S., Amorim, B., Knight, S., Quintero, S., Valencia, F.: A multi-agent
model for polarization under confirmation bias in social networks. In: Peters,
K., Willemse, T.A.C. (eds.) Formal Techniques for Distributed Objects, Compo-
nents, and Systems - 41st IFIP WG 6.1 International Conference, FORTE 2021,
HeldasPartofthe16thInternationalFederatedConferenceonDistributedCom-
puting Techniques, DisCoTec 2021, Valletta, Malta, June 14-18, 2021, Proceed-
ings. Lecture Notes in Computer Science, vol. 12719, pp. 22–41. Springer (2021).
https://doi.org/10.1007/978-3-030-78089-0 2
2. Alvim, M.S., Amorim, B., Knight, S., Quintero, S., Valencia, F.: A formal model
forpolarizationunderconfirmationbiasinsocialnetworks.Log.MethodsComput.
Sci. 19(1) (2023). https://doi.org/10.46298/lmcs-19(1:18)2023
3. Alvim,M.S.,Knight,S.,Valencia,F.:Towardaformalmodelforgrouppolarization
in social networks. In: The Art of Modelling Computational Systems. LNCS, vol.
11760, pp. 419–441. Springer (2019)
4. Bala, V., Goyal, S.: Learning from Neighbours. The Review of Economic Studies
65(3),595–621(1998).https://doi.org/10.1111/1467-937X.00059,https://doi.org/
10.1111/1467-937X.00059
5. Baltag, A., Christoff, Z., Rendsvig, R.K., Smets, S.: Dynamic epistemic logics of
diffusion and prediction in social networks. Studia Logica 107(3), 489–531 (2019)
6. Christoff, Z.L.: Dynamic logics of networks: information flow and the spread of
opinion. Ph.D. thesis, Universiteit van Amsterdam (2016)
7. DeGroot, M.H.: Reaching a consensus. Journal of the American Statistical Asso-
ciation 69(345), 118–121 (1974). https://doi.org/10.2307/2285509Opinion Update in a Subjective Logic Model for Social Networks 15
8. Holliday, W.H.: Trust and the dynamics of testimony. In: Logic and Interactive
RAtionality. Seminar’s yearbook. pp. 118–142 (2009), https://events.illc.uva.nl/
dg/wp-content/uploads/2012/07/yearbook.2009.pdf
9. Hunter,A.:Reasoningabouttrustandbeliefchangeonasocialnetwork:Aformal
approach. In: Liu, J.K., Samarati, P. (eds.) Information Security Practice and
Experience 2017. Lecture Notes in Computer Science, vol. 10701, pp. 783–801.
Springer (2017)
10. Jøsang, A.: Subjective Logic - A Formalism for Reasoning Under Uncertainty.
Artificial Intelligence: Foundations, Theory, and Algorithms, Springer (2016)
11. Jøsang,A.:Categoriesofbelieffusion.JournalofAdvancesinInformationFusion
13(2), 235–254 (2018)
12. Liu,F.,Seligman,J.,Girard,P.:Logicaldynamicsofbeliefchangeinthecommu-
nity. Synthese 191(11), 2403–2431 (2014)
13. Pedersen, M.Y., Smets, S., ˚Agotnes, T.: Modal logics and group polarization. J.
Log. Comput. 31(8), 2240–2269 (2021). https://doi.org/10.1093/logcom/exab062
14. Xiong, Z., ˚Agotnes, T.: On the logic of balance in social networks. J. Log. Lang.
Inf. 29(1), 53–75 (2020). https://doi.org/10.1007/s10849-019-09297-0
15. YoungPedersen,M.:PolarizationandEchoChambers:ALogicalAnalysisofBal-
ance and Triadic Closure in Social Networks. Master’s thesis, Universiteit van
Amsterdam (2019)
A Appendix: Mapping an opinion to a Beta PDF
ThisappendixshowsthemappingofanopiniontoaBetaPDFdefinedbyJøsang
[10] We show the evidence notation of the multivariate Beta PDF (or Dirichlet
PDF) and show its equivalence with the opinion representation defined at Def.
2.
Multinomial probability density over a domain of cardinality k is expressed
by the k-dimensional Beta PDF. Assume a domain X of cardinality k, and a
random variable X over X with probability distribution p . The Beta PDF can
X
be used to represent probability density over p .
X
The multivariate Beta PDF takes as variable the k-dimensional probabil-
ity distribution p . The strength parameters for the k possible outcomes are
X
represented as k positive real numbers α x, each corresponding to one of the
X
possiblevalues x∈X.Thestrengthparametersrepresentevidence/observations
of X =x where x∈X.
Definition 6. (Multivariate Beta Probability Density Function). Let X be a
domain consisting of k mutually disjoint values. Let α represent the strength
X
vector over the values of X, and let p denote the probability distribution over
X
X. With p as a k-dimensional variable, the multivariate Beta PDF denoted
X
Beta(p ,α ) is expressed as:
X X
(cid:18) (cid:19)
(cid:80)
Γ α (x)
X
Beta(p X,α X)= (cid:81)x Γ∈X
(α (x))
(cid:89) p X(x)(αX(x)−1), where α X(x)≥0, (20)
x∈X
X x∈X
with the restrictions that p (x)̸=0 if α (x)<1.
X X16 M. S. Alvim et al.
Now assume that x∈X represents a frequentist event. Let r (x) denote the
X
number of observations for x. The strength vector α can be expressed as a
X
function of the observations r (x) and the base rate a :
X X
α (x)=r (x)+a (x)W, where r (x)≥0 ∀x∈X. (21)
X X X X
By expressing the strength vector α in terms of the evidence observation
X
r , the base rate a , and the non-informative prior weight W, we get the rep-
X X
resentation of the Beta PDF denoted Betae (p ,r ,a ). The exact definition
X X X X
of Betae (p ,r ,a ) is described at [10].
X X X X
GivenaBetaPDFBetae (p ,r ,a ),theexpecteddistributionoverXcan
X X X X
be written as
r (x)+a (x)W
E (x)= X X , ∀x∈X. (22)
X W + (cid:80) r (x )
X j
xj∈X
The Beta model translates observation evidence directly into a PDF over a
k-component probability variable. The representation evidence, together with
the base rate, can be used to determine subjective opinions. In other words, it
is possible to define a bijective mapping between Beta PDFs and opinions.
The bijective mapping between ω and Betae (p ,r ,a ) is based on the
X X X X X
requirement for equality between the projected probability distribution P de-
X
rived from ω and the expected probability distribution E derived from
X X
Betae (p ,r ,a ). This means that the more evidence in favor of a partic-
X X X X
ular outcome x, the greater the belief mass on the outcome. Furthermore, the
more total evidence available, the less uncertainty mass.
Definition 7. (Mapping: Opinion ↔ Beta PDF) Let ω =(b ,u ,a ) be an
X X X X
opinion and let Betae (p ,r ,a ) be a Beta PDF, both over the same variable
X X X X
X ∈X. These are equivalent through the following mapping,
∀x∈X
 Wb (x)
 b X(x) = W + xr (cid:80) iX W∈( Xx r) X(x i) ⇔  1r X =(x u) X=
+
x(cid:80) i∈u XX X
b X(x i)
if u X ̸=0
u
X
=
W + x(cid:80) i∈Xr X(x i)
 r
1X
=(x) (cid:80)= bb
XX
(( xx i) )·∞
if u
X
=0
xi∈X
(23)
This equivalence between opinions and Beta PDFs is very powerful because
it makes it possible to determine opinions from statistical observations.
B Appendix: Belief fusion operators
This appendix shows a more detailed definition of the belief fusion operators
intuitively described at Sec. 3. Here, we will define the belief fusions in termsOpinion Update in a Subjective Logic Model for Social Networks 17
of Beta PDFs. Since there is a mapping between opinions and Beta PDFs, the
directdefinitionforeachoperatorwillbeomitted.Thesedefinitionscanbefound
at [10,11].
Cumulative belief fusion The cumulative belief fusion is used when it is
assumed that the amount of independent evidence increases by including more
sources. The idea is to sum the amount of evidence of the opinions.
Let X be a domain, and X be a random variable over X. W.l.o.g., let A and
B be agents, and ωA and ωB be opinions. The cumulative belief fusion between
X X
A and B is denoted ω(A⋄B) and it can be represented as a Beta PDF.
X
Definition 8. (Cumulative Belief Fusion) Let X be a domain, and X be a ran-
dom variable over X. Let A and B be agents, and ωA and ωB be opinions. The
X X
cumulative belief fusion between ωA and ωB is denoted:
X X
ω(A⋄B) =ωA ⊕ωB (24)
X X X
Let Betae (p ,rA,aA) and Betae (p ,rB,aB) be the Beta PDFs equivalent
X X X X X X X X
to ωA and ωB, respectively.
X X
The opinion ω(A⋄B) is the opinion equivalent to Betae (p ,r(A⋄B),a(A⋄B))
X X X X X
defined as:
Betae (p ,r(A⋄B),a(A⋄B))=Betae (p ,rA,aA)⊕Betae (p ,rB,aB)
X X X X X X X X X X X X (25)
=Betae (p ,(rA +rB),a(A⋄B)).
X X X X X
More specifically, for each values x ∈ X the accumulated source evidence
r(A⋄B) is computed as:
r(A⋄B)(x)=rA(x)+rB(x), ∀x∈X. (26)
X X
Thefusionofthreeormoreopinionsisdefinedat[11].Itcanbeverifiedthat
thecumulativefusionoperatoriscommutative,associative,andnon-idempotent.
Averaging Belief Fusion The averaging belief fusion is used when including
more sources does not mean that more evidence supports the conclusion. The
idea is to take the average of the amount of evidence of the opinions.
Let X be a domain, and X be a random variable over X. W.l.o.g., let A and
B be agents, and ωA and ωB be opinions. The averaging belief fusion between
X X
A and B is denoted ω(A⋄B) =ωA and it can be represented as a Beta PDF.
X X
Definition 9. (AveragingBeliefFusion)LetXbeadomain,andX bearandom
variable over X. Let A and B be agents, and ωA and ωB be opinions. The
X X
averaging belief fusion between ωA and ωB is denoted:
X X
ω(A⋄B) =ωA⊕ωB (27)
X X X18 M. S. Alvim et al.
Let Betae (p ,rA,aA) and Betae (p ,rB,aB) be the Beta PDFs equivalent
X X X X X X X X
to ωA and ωB, respectively.
X X
The opinion ω(A⋄B) is the opinion equivalent to Betae (p ,r(A⋄B),a(A⋄B))
X X X X X
defined as:
Betae (p ,r(A⋄B),a(A⋄B))=Betae (p ,rA,aA)⊕Betae (p ,rB,aB)
X X X X X X X X X X X X (28)
=Betae (p ,(rA +rB)/2,a(A⋄B)).
X X X X X
More specifically, for each values x ∈ X the accumulated source evidence
r(A⋄B) is computed as:
rA(x)+rB(x)
r(A⋄B)(x)= X X , ∀x∈X. (29)
2
Thefusionofthreeormoreopinionsisdefinedat[11].Itcanbeverifiedthat
thecumulativefusionoperatoriscommutative,idempotent,butnon-associative.
Weighted Belief Fusion The weighted belief fusion is used when including
more sources does not mean that more evidence supports the conclusion. The
idea is used when we take the average of the amount of evidence of the opinions
weightedbytheirlackofuncertainty.Inparticular,opinionswithnobeliefmass
are rejected.
Let X be a domain, and X be a random variable over X. W.l.o.g., let A and
B be agents, and ωA and ωB be opinions. The averaging belief fusion between
X X
A and B is denoted ω(A⋄ˆB) =ωA and it can be represented as a Beta PDF.
X X
Definition 10. (WeightedBeliefFusion)LetXbeadomain,andX bearandom
variable over X. Let A and B be agents, and ωA and ωB be opinions. The
X X
averaging belief fusion between ωA and ωB is denoted:
X X
ω(A⋄ˆB) =ωA⊕ˆωB (30)
X X X
Let Betae (p ,rA,aA) and Betae (p ,rB,aB) be the Beta PDFs equivalent
X X X X X X X X
to ωA and ωB, respectively. Also, let cA be the confidence that A has in their
X X X
opinion. Formally:
i
(cid:88)
cA =1− bA(x) (31)
X X
x∈X
The opinion ω(A⋄ˆB) is the opinion equivalent to Betae (p ,r(A⋄ˆB),a(A⋄ˆB))
X X X X X
defined as:
Betae (p ,r(A⋄ˆB),a(A⋄ˆB))=Betae (p ,rA,aA)⊕ˆBetae (p ,rB,aB)
X X X X X X X X X X X X (32)
=Betae (p ,(cArA +cBrB)/2,a(A⋄ˆB)).
X X X X X X X
More specifically, for each values x ∈ X the accumulated source evidence
r(A⋄B) is computed as:
cArA(x)+cBrB(x)
r(A⋄ˆB)(x)= X X X X , ∀x∈X. (33)
cA +cB
X XOpinion Update in a Subjective Logic Model for Social Networks 19
Thefusionofthreeormoreopinionsisdefinedat[11].Itcanbeverifiedthat
thecumulativefusionoperatoriscommutative,idempotent,butnon-associative.