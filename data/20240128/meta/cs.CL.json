[
    {
        "title": "Modular Adaptation of Multilingual Encoders to Written Swiss German Dialect",
        "authors": "Jannis VamvasNoëmi AepliRico Sennrich",
        "links": "http://arxiv.org/abs/2401.14400v1",
        "entry_id": "http://arxiv.org/abs/2401.14400v1",
        "pdf_url": "http://arxiv.org/pdf/2401.14400v1",
        "summary": "Creating neural text encoders for written Swiss German is challenging due to\na dearth of training data combined with dialectal variation. In this paper, we\nbuild on several existing multilingual encoders and adapt them to Swiss German\nusing continued pre-training. Evaluation on three diverse downstream tasks\nshows that simply adding a Swiss German adapter to a modular encoder achieves\n97.5% of fully monolithic adaptation performance. We further find that for the\ntask of retrieving Swiss German sentences given Standard German queries,\nadapting a character-level model is more effective than the other adaptation\nstrategies. We release our code and the models trained for our experiments at\nhttps://github.com/ZurichNLP/swiss-german-text-encoders",
        "updated": "2024-01-25 18:59:32 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.14400v1"
    },
    {
        "title": "TURNA: A Turkish Encoder-Decoder Language Model for Enhanced Understanding and Generation",
        "authors": "Gökçe UludoğanZeynep Yirmibeşoğlu BalalFurkan AkkurtMelikşah TürkerOnur GüngörSusan Üsküdarlı",
        "links": "http://arxiv.org/abs/2401.14373v1",
        "entry_id": "http://arxiv.org/abs/2401.14373v1",
        "pdf_url": "http://arxiv.org/pdf/2401.14373v1",
        "summary": "The recent advances in natural language processing have predominantly favored\nwell-resourced English-centric models, resulting in a significant gap with\nlow-resource languages. In this work, we introduce the language model TURNA,\nwhich is developed for the low-resource language Turkish and is capable of both\nnatural language understanding and generation tasks. TURNA is pretrained with\nan encoder-decoder architecture based on the unified framework UL2 with a\ndiverse corpus that we specifically curated for this purpose. We evaluated\nTURNA with three generation tasks and five understanding tasks for Turkish. The\nresults show that TURNA outperforms several multilingual models in both\nunderstanding and generation tasks, and competes with monolingual Turkish\nmodels in understanding tasks. TURNA is made available at\nhttps://huggingface.co/boun-tabi-LMG/TURNA .",
        "updated": "2024-01-25 18:24:13 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.14373v1"
    },
    {
        "title": "Genie: Achieving Human Parity in Content-Grounded Datasets Generation",
        "authors": "Asaf YehudaiBoaz CarmeliYosi MassOfir ArvivNathaniel MillsAssaf ToledoEyal ShnarchLeshem Choshen",
        "links": "http://arxiv.org/abs/2401.14367v1",
        "entry_id": "http://arxiv.org/abs/2401.14367v1",
        "pdf_url": "http://arxiv.org/pdf/2401.14367v1",
        "summary": "The lack of high-quality data for content-grounded generation tasks has been\nidentified as a major obstacle to advancing these tasks. To address this gap,\nwe propose Genie, a novel method for automatically generating high-quality\ncontent-grounded data. It consists of three stages: (a) Content Preparation,\n(b) Generation: creating task-specific examples from the content (e.g.,\nquestion-answer pairs or summaries). (c) Filtering mechanism aiming to ensure\nthe quality and faithfulness of the generated data. We showcase this\nmethodology by generating three large-scale synthetic data, making wishes, for\nLong-Form Question-Answering (LFQA), summarization, and information extraction.\nIn a human evaluation, our generated data was found to be natural and of high\nquality. Furthermore, we compare models trained on our data with models trained\non human-written data -- ELI5 and ASQA for LFQA and CNN-DailyMail for\nSummarization. We show that our models are on par with or outperforming models\ntrained on human-generated data and consistently outperforming them in\nfaithfulness. Finally, we applied our method to create LFQA data within the\nmedical domain and compared a model trained on it with models trained on other\ndomains.",
        "updated": "2024-01-25 18:14:57 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.14367v1"
    },
    {
        "title": "A Comparative Analysis of Noise Reduction Methods in Sentiment Analysis on Noisy Bengali Texts",
        "authors": "Kazi Toufique ElahiTasnuva Binte RahmanShakil ShahriarSamir SarkerMd. Tanvir Rouf ShawonG. M. Shahariar",
        "links": "http://arxiv.org/abs/2401.14360v1",
        "entry_id": "http://arxiv.org/abs/2401.14360v1",
        "pdf_url": "http://arxiv.org/pdf/2401.14360v1",
        "summary": "While Bengali is considered a language with limited resources, sentiment\nanalysis has been a subject of extensive research in the literature.\nNevertheless, there is a scarcity of exploration into sentiment analysis\nspecifically in the realm of noisy Bengali texts. In this paper, we introduce a\ndataset (NC-SentNoB) that we annotated manually to identify ten different types\nof noise found in a pre-existing sentiment analysis dataset comprising of\naround 15K noisy Bengali texts. At first, given an input noisy text, we\nidentify the noise type, addressing this as a multi-label classification task.\nThen, we introduce baseline noise reduction methods to alleviate noise prior to\nconducting sentiment analysis. Finally, we assess the performance of fine-tuned\nsentiment analysis models with both noisy and noise-reduced texts to make\ncomparisons. The experimental findings indicate that the noise reduction\nmethods utilized are not satisfactory, highlighting the need for more suitable\nnoise reduction methods in future research endeavors. We have made the\nimplementation and dataset presented in this paper publicly available at\nhttps://github.com/ktoufiquee/A-Comparative-Analysis-of-Noise-Reduction-Methods-in-Sentiment-Analysis-on-Noisy-Bengali-Texts",
        "updated": "2024-01-25 18:06:19 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.14360v1"
    },
    {
        "title": "Topologies of Reasoning: Demystifying Chains, Trees, and Graphs of Thoughts",
        "authors": "Maciej BestaFlorim MemediZhenyu ZhangRobert GerstenbergerNils BlachPiotr NyczykMarcin CopikGrzegorz KwaśniewskiJürgen MüllerLukas GianinazziAles KubicekHubert NiewiadomskiOnur MutluTorsten Hoefler",
        "links": "http://arxiv.org/abs/2401.14295v1",
        "entry_id": "http://arxiv.org/abs/2401.14295v1",
        "pdf_url": "http://arxiv.org/pdf/2401.14295v1",
        "summary": "The field of natural language processing (NLP) has witnessed significant\nprogress in recent years, with a notable focus on improving large language\nmodels' (LLM) performance through innovative prompting techniques. Among these,\nprompt engineering coupled with structures has emerged as a promising paradigm,\nwith designs such as Chain-of-Thought, Tree of Thoughts, or Graph of Thoughts,\nin which the overall LLM reasoning is guided by a structure such as a graph. As\nillustrated with numerous examples, this paradigm significantly enhances the\nLLM's capability to solve numerous tasks, ranging from logical or mathematical\nreasoning to planning or creative writing. To facilitate the understanding of\nthis growing field and pave the way for future developments, we devise a\ngeneral blueprint for effective and efficient LLM reasoning schemes. For this,\nwe conduct an in-depth analysis of the prompt execution pipeline, clarifying\nand clearly defining different concepts. We then build the first taxonomy of\nstructure-enhanced LLM reasoning schemes. We focus on identifying fundamental\nclasses of harnessed structures, and we analyze the representations of these\nstructures, algorithms executed with these structures, and many others. We\nrefer to these structures as reasoning topologies, because their representation\nbecomes to a degree spatial, as they are contained within the LLM context. Our\nstudy compares existing prompting schemes using the proposed taxonomy,\ndiscussing how certain design choices lead to different patterns in performance\nand cost. We also outline theoretical underpinnings, relationships between\nprompting and others parts of the LLM ecosystem such as knowledge bases, and\nthe associated research challenges. Our work will help to advance future prompt\nengineering techniques.",
        "updated": "2024-01-25 16:34:00 UTC",
        "interpretation": "解释内容未找到",
        "id": "2401.14295v1"
    }
]