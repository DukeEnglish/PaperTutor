Information Leakage Detection through Approximate
Bayes-optimal Prediction
Pritha Gupta prithag@mail.uni-paderborn.de
Department of Computer Science, Paderborn University
Paderborn, Germany
Marcel Wever marcel.wever@ifi.lmu.de
MCML, LMU Munich
Munich, Germany
Eyke Hu¨llermeier eyke@lmu.de
MCML, LMU Munich
Munich, Germany
Editor: Leslie Pack Kaelbling
Abstract
Intoday’sdata-drivenworld,theproliferationofpubliclyavailableinformationintensifiesthe
challenge of information leakage (IL), raising security concerns. IL involves unintentionally
exposing secret (sensitive) information to unauthorized parties via systems observable
information. Conventionalstatisticalapproachesrelyonestimatingmutualinformation(MI)
between observable and secret information for detecting IL, facing challenges such as the
curse of dimensionality, convergence, computational complexity, and MI misestimation.
Furthermore, though proven effective, emerging supervised machine learning (ML) methods
are limited to binary system sensitive information and lack a comprehensive theoretical
framework. To address these limitations, we establish a theoretical framework using
statistical learning theory and information theory to quantify and detect IL accurately. We
demonstratethatMIcanbeaccuratelyestimatedbyapproximatingthelog-lossandaccuracy
of the Bayes predictor. As in practice, the Bayes predictor is typically unknown, and we
propose to approximate it with the help of automated machine learning (AutoML). First,
we compare our MI estimation approaches against current baselines, using synthetic data
sets generated using the multivariate normal (MVN) distribution with known MI. Second,
we introduce a cut-off technique using one-sided statistical tests to detect IL and employ
the Holm-Bonferroni correction to increase confidence in detection decisions. Our study
evaluates IL detection performance on real-world data sets, highlighting the effectiveness
of Bayes predictor’s log-loss’s estimation, and finds our proposed method to effectively
estimate MI on synthetic data sets and thus detect ILs accurately.
Keywords: InformationLeakageDetection, MutualInformation, Bayes-optimalPredictor,
AutoML, Statistical Tests, Holm-Bonferroni, Privacy
1 Introduction
Information leakage (IL) has become a significant and complex challenge in today’s data-
driven world (Shabtai et al., 2012). The rapid proliferation of publicly available data,
coupled with the increasing use of Internet of Things (IoT) technologies, has magnified the
1
4202
naJ
52
]LM.tats[
1v38241.1042:viXraGupta, Wever and Hu¨llermeier
threat of IL, posing a substantial risk to the security and confidentiality of systems (Shabtai
et al., 2012; Kelsey, 2002). This heightened threat of IL is amplified by the increasing
use of Internet of Things (IoT) technologies, posing substantial risks to the security and
confidentiality of systems.
IL occurs when sensitive or confidential information is inadvertently exposed to unau-
thorized individuals through observable information of a system (Hettwer et al., 2019).
This unintended disclosure of sensitive data can lead to severe consequences, ranging from
potential electrical blackouts to the theft of critical information such as medical records
and military secrets (Hettwer et al., 2019; Shabtai et al., 2012). Consequently, the efficient
detection and quantification of IL are of paramount importance. The theoretical foundations
of quantifying IL in systems stem from the field of information theory, proposes to estimate
the mutual information (MI) between observable and secret information (Chatzikokolakis
et al., 2010). MI is shown to be difficult to compute specifically for high-dimensional data,
despite being a pivotal measure (Gao et al., 2015; Eirola et al., 2014). Traditional solutions
often resort to using statistical estimation to calculate MI, but often encounter challenges
when dealing with high-dimensional data, a problem known as the curse of dimensionality
(Gao et al., 2015; Kraskov et al., 2004). Recent works offer more robust non-parametric
approaches with improved convergence rates for MI estimation in complex datasets (Singh
and Po´czos, 2016; Kandasamy et al., 2015; Moon et al., 2021). However, their implementa-
tion in high-dimensional scenarios remains challenging due to the sophisticated statistical
techniques involved (Kandasamy et al., 2015).
In recent years, machine learning (ML) techniques have become very popular in the
field of information leakage detection (ILD), particularly in the sub-field of performing
side-channel attacks (SCAs) on cryptographic systems (Picek et al., 2023). These systems
unintentionallyreleasetheobservable information viamanymodes,suchasnetworkmessages,
CPUcaches, powerconsumption, orelectromagneticradiationcalledtheside-channels(Picek
et al., 2023). These modes are exploited by the SCAs to reveal the secret inputs (secret
keys, plaintexts) to the adversaries, potentially rendering all implemented cryptographic
protections irrelevant (Moos et al., 2021; Hettwer et al., 2019). A system is considered to
contain a side-channel if it is susceptible to SCAs, thereby making it vulnerable. Therefore,
detecting the existence of a side-channel in a cybersecurity system is equivalent to uncovering
IL (Hettwer et al., 2019).
In this field, the most relevant literature uses ML to perform SCAs, not preventing side-
channels through early detection of ILs (Hettwer et al., 2019). Notably, current ML-based
methods in this realm detect side-channels, preventing SCAs and protecting the system
on both algorithmic and hardware levels (Mushtaq et al., 2018; Moos et al., 2021). These
approaches leverage the observable information of a system to classify it as vulnerable (with
IL) or non-vulnerable (without IL) (Perianin et al., 2020; Mushtaq et al., 2018). These
techniques extract observable information from secure systems used as input, categorizing
the systems as non-vulnerable (labeled as 0). Subsequently, they intentionally introduce
known ILs in these systems, categorizing them as vulnerable (labeled as 1). Finally, the
extracted observable information with corresponding class labels is used to produce the
binary classification data set for the learning model. However, this approach confines these
techniques to domain-specific scenarios and cannot be easily transferred to detect other
unknown leakage patterns (Perianin et al., 2020).
2ML-based techniques have shown promising potential in estimating MI within classifi-
cation system data sets (Belghazi et al., 2018; Qin and Kim, 2019; Cristiani et al., 2020).
Despite their promise, these methods grapple with challenges related to convergence issues
andhighcomputationalcomplexity(Belghazietal.,2018;Cristianietal.,2020). Forinstance,
the approach proposed by Qin and Kim (2019) introduces a lower bound on MI using the
Kullback-Leibler (KL) divergence. However, this method tends to underestimate MI and
might not capture certain subclasses of IL. Recent advancements have demonstrated the
effectiveness of ML-based techniques in directly detecting IL by analyzing the accuracy of
the supervised learning models on extracted system data (Moos et al., 2021; Drees et al.,
2021). Yet, these methods exhibit limitations in handling imbalanced and noisy real-world
data sets, commonly encountered in practical scenarios, and tend to miss ILs by producing
false negatives (Zhang et al., 2020; Picek et al., 2018).
To address these limitations, in our prior work, we propose utilizing weighted binary
classifiersintegratedwithstatisticaltestsasFisher’sexacttest(FET)andpairedt-test(PTT)
to account for imbalance (Gupta et al., 2022). To mitigate noise, an ensemble of binary
classifiers, including a deep multi-layer perceptron, along with their derived results (p-values)
from the statistical tests, are aggregated using Holm-Bonferroni correction to enhance ILD
accuracy and increase confidence in systems. Despite its merits, this approach remains
confined to binary classification tasks and lacks a comprehensive theoretical framework.
1.1 Our Contributions
We offer the following contributions in this work to address the existing literature’s short-
comings.
• In Section 2, we introduce a novel theoretical framework for addressing the ILD
problem in systems that generate classification data. In this context, we draw upon the
core concepts from the information theory and statistical learning theory to leverage
the connection between MI and the performance of Bayes predictor, as explained
in Sections 2.2.1 and 2.2.2, respectively. We also quantify the IL and formalize the
conditions under which it exists in a system from both the statistical learning theory
and information theory perspectives in Section 2.3.
• In Section 3, we propose two distinct approaches for quantifying IL using MI within a
given system based on approximating the Bayes predictor’s accuracy and the log-loss.
We employ probability calibration techniques to enhance the precision of Log-Loss
estimation, described in Section 3.2.4. We describe the three state-of-the-art baselines
in Section 3.3 (Eirola et al., 2014; Belghazi et al., 2018; Qin and Kim, 2019). We
propose to approximate the Bayes predictor’s accuracy and the log-loss using the
competitive automated machine learning (AutoML) tools, described in Section 4.
Section 5 describes the rigorous empirical evaluation of our methods against three
state-of-the-art approaches, which involves applying them to synthetic data sets with
known MI and utilizing the normalized mean absolute error (NMAE) performance
metric for assessment.
• In Section 6.2, we formalize a technique for ILD using a cut-off on estimated MI
through the one-sample t-test (OTT) statistical test. We discuss classification-based
3Gupta, Wever and Hu¨llermeier
ILD approaches using FET and PTT statistical tests in Section 6.3. Our prior work
demonstrates the competence of these approaches in accurately detecting padding
side-channel leaks within OpenSSL TLS servers (Gupta et al., 2022). To enhance
the confidence of IL detection decisions, we propose employing the Holm-Bonferroni
correction on multiple models’ (pipelines’) estimates, as described in Section 6.4. This
approach enhances robustness against noise in estimating MI (e.g., accuracy, confusion
matrix) and variations in the quality of AutoML pipelines.
• Finally, in Section 7, we conduct an extensive benchmarking study, comparing our ILD
methods against state-of-the-art approaches, including FET and PTT, for detecting
timing side-channels (ILs) to counter Bleichenbacher attacks.
2 Information Leakage Problem
This section will briefly explain the task of information leakage detection (ILD) using a
mapping that categorizes a given system as vulnerable and non-vulnerable. Additionally,
we will define a measure to quantify information leakage (IL) and formalize the conditions
under which IL occurs in a system using the foundational concepts of information theory
and statistical learning theory described in Section 2.2. The notations used throughout the
paper are listed in Appendix A.
2.1 Information Leakage Detection
ILD stands as a pivotal task in modern cybersecurity, aiming to identify any unintended
disclosure of confidential data or sensitive information through a system’s emitted observable
information. The ILD process involves a leakage detector (ILD algorithm) analyzing the
extracted system data set, denoted as = (x ,y ) N (size N N), where
D { i i }i=1 ⊂ X × Y ∈
= Rd denotes the space of observable information and = [M] = 1,2,...,M represents
X Y { }
the secret information in terms of categorical class labels. The goal of ILD boils down to
associating this data set with a binary label, where 0 indicates an absence of leakage (no
D
IL) and 1 suggests the presence of leakage (IL) in the system. This objective is represented
by the mapping L as
(cid:91)
L : ( )N 0,1 ,
X ×Y → { }
N∈N
which takes a data set (extracted from the system) of any size as input and provides an
D
assessment of potential IL in the system as an output. This process is encapsulated in the
predicted IL mapping Lˆ produced by an ILD approach.
Let = ( ,z ) NL be an IL-Dataset, such that N N,z 0,1 . Further, let
L { Di i }i=1 L ∈ i ∈ { }
z = (z ,...,z )betheground-truthvector,generatedbyL,suchthatz = L( ), i [N ].
1 NL i Di
∀ ∈
L
Letzˆ= (zˆ ,...,zˆ )bethecorrespondingpredictionvector,suchthatzˆ = Lˆ( ), i [N ].
1 NL i Di
∀ ∈
L
Since the ILD task produces binary decisions, the performance of predicted IL mapping Lˆ
is measured using metrics commonly used in binary classification, e.g., accuracy. To avoid
confusion, we will refer to as IL-Dataset and each as the data set.
L D
42.2 Fundamentals of Information and Statistical Learning Theory
This section recalls some fundamental concepts from information theory and statistical
learning theory required to formalize the conditions that signify a system’s occurrence of IL.
We provide a formal description of mutual information (MI) rooted in information theory
and how it is estimated for a given system data set. Additionally, we formally describe the
classification problem with the relevant evaluation metrics from statistical learning theory.
Building upon this, we define the concept of Bayes predictor and the classification problem
handled by estimating class (conditional) class probabilities.
2.2.1 Mutual Information
Mutual information (MI), a fundamental concept in information theory, measures the extent
to which knowledge of one random variable informs about another, thereby quantifying their
degree of dependence (Cover and Thomas, 2005). Consider any pair of random variables
X and Y with joint distribution P ( ) on . Although these random variables can
(X,Y)
· X ×Y
be of any type, we subsequently assume that X is a continuous d-dimensional real-valued
random variable ( = Rd) and Y is a discrete random variable with M possible values
X
( = 1,...,M )— in the information leakage scenario, this will be the relevant case for us.
Y { }
In the following, for the sake of simplicity, we will use the same notation for a probability
measure and its probability mass or density function. Often, the symbol for the former
is capitalized, whereas small letters are used for the latter. Assuming that the meaning
is always clear from the context, we will use capital letters throughout. In particular, we
will denote the marginals of the joint distribution P ( ) by P ( ) and P ( ), and the
(X,Y) X Y
· · ·
conditional distributions by P ( ) and P ( ), respectively.
Y|X X|Y
· ·
Recall that the entropy of a discrete random variable Y is defined as
(cid:88)
H(Y) = P (Y = y) lg(P (Y = y)), (1)
Y Y
− ·
y∈Y
where 0 lg(0) = 0 by definition; the continuous version—differential entropy—is essentially
·
obtained by replacing summation with integration. The maximum entropy is lg(M) and
occurs when all outcomes are equally likely, indicating complete uncertainty about the
outcome of Y, i.e., P (y) = 1/M, y [M]. The minimum entropy is 0, indicating complete
Y
∀ ∈
certainty about Y, and occurs for the case of a Dirac measure (one outcome y = m has
a probability P (m) = 1, while all others have a probability of 0, i.e., P (i) = 0, i
Y Y
∀ ∈
[M] m ). The conditional entropy of Y given X is defined as
\{ }
(cid:90)
(cid:88)
H(Y X) = P (x) P (Y = y X = x) lg(P (Y = y X = x))dx.
X Y|X Y|X
| − | · |
y∈Y
x∈X
According to this definition, conditional entropy measures the residual uncertainty in one
random variable given knowledge of the other— more specifically, it measures the expected
residual uncertainty, with the expectation taken with respect to the marginal distribution of
Y. H(Y X) is bounded by H(Y), reaching its upper bound when H(Y X = x) follows the
| |
marginaldistributionP ( )forallx , signifyingthatX doesnotprovideanyinformation
Y
· ∈ X
about Y. The minimum entropy is 0, indicating that X completely determines Y, and again
occurs in the case where all conditionals P ( x) are Dirac distributions.
Y|X
·|
5Gupta, Wever and Hu¨llermeier
Now,MIbetweenapairofrandomvariables(X,Y)measuresthereductionofuncertainty
about variable Y by observing variable X:
I(X;Y) = H(Y) H(Y X). (2)
− |
Thus defined, MI is a symmetric measure:
I(X;Y) = H(Y) H(Y X)
− |
= H(Y)+H(X) H(X,Y)
−
= H(X)+H(Y) H(Y,X)
−
= H(X) H(X Y) = I(Y;X).
− |
Consequently, its value ranges between 0 and min( H(X),H(Y) ). A value of 0 indicates
{ }
that X and Y are completely independent, while the maximal value min( H(X),H(Y) )
{ }
signifies full dependence (Cover and Thomas, 2005). By plugging in the expressions for
(conditional) entropy and rearranging terms, one easily shows that MI equals the Kullback-
Leibler (KL) divergence of the joint distribution P ( ) from the product of the marginals
(X,Y)
·
(i.e., the joint distribution under the assumption of independence):
I(X;Y) = H(Y) H(Y X)
− |
(cid:90) (cid:88) (cid:18) P (X,Y)(X = x,Y = y) (cid:19)
= P (X = x,Y = y) lg dx. (3)
(X,Y) · P (X = x) P (Y = y)
X Y
y∈Y ·
x∈X
The unit of MI varies based on the base of the logarithm: natural logarithm ln uses nats,
decimal logarithm log employs Hartleys, and binary logarithm lg corresponds to bits. We
calculate MI using the binary logarithm lg, thus using bits as the unit of information.
2.2.2 Classification Problem
In the realm of classification, the learning algorithm (learner) is provided with a training
data set = (x ,y ) N of size N N, where = Rd is the input (instance)
D { i i }i=1 ⊂ X ×Y ∈ X
space and = 1,2,...,M = [M], M N the output (categorical class labels) space
Y { } ∈
(Vapnik, 1991), and the (x ,y ) are assumed to be independent and identically distributed
i i
(i.i.d.) according to P ( ). According to statistical learning theory, the primary goal of
(X,Y)
·
the learner in standard classification is to induce a hypothesis h: , h , with low
X → Y ∈ H
generalization error (risk)
(cid:90)
R(h) = E[ℓ(y,h(x))] = ℓ(y,h(x))dP (X = x,Y = y), (4)
(X,Y)
X×Y
where is the underlying hypothesis space (set of candidate functions the learner can
H
choose from), ℓ: R a loss function, and P ( ) is the joint probability measure
(X,Y)
Y ×Y → ·
modelingtheunderlyingdata-generatingprocess. Alossfunctioncommonlyusedinstandard
classification is the 0-1 loss ℓ (y,yˆ):= yˆ = y , where yˆ = h(x) and is the indicator
01
functionasdefinedinAppendixA.Theris(cid:74) km̸ inim(cid:75) izer(denotedbyh∗)ach(cid:74) i· e(cid:75)
vestheminimum
expectedlossE[ℓ( )]intermsofthelossfunctionℓacrosstheentirejointdistributionP ( )
(X,Y)
· ·
6and is defined as h∗ = arg min R(h). The measure P ( ) in (4) induces marginal
h∈H (X,Y)
·
probability (density or mass) functions on and as well as a conditional probability of
X Y
the class Y given an input instance x, i.e., P (x,y) = P (y x) P (x). In practice,
(X,Y) Y|X X
| ×
these probabilities are not observed by the learner, so directly minimizing the risk (4) is not
feasible. Instead, learning in a standard classification setting is commonly accomplished by
minimizing (a regularized version of) empirical risk for h:
N
1 (cid:88)
R (h) = ℓ(y ,h(x )). (5)
emp i i
N
i=1
Inthesubsequentdiscussions,wedenotebyg = arg min R (h)the(learned)hypothesis
h∈H emp
that minimizes (5), i.e., the empirical risk minimizer (Vapnik, 1991). In practice, for the
availablefinitesampleddataset ,g isthebestpossibleapproximation(empiricalestimation)
D
of the true risk minimizer h∗ and serves as an appropriation thereof.
2.2.2.1 Bayes-optimal Predictor In statistical learning theory, the Bayes predictor is
the optimal (pointwise) classification function gb: producing a minimum expected
X → Y
risk, i.e., minimizing (4) for a given loss function ℓ( ):
·
(cid:88)
gb(x) = arg min ℓ(y,yˆ) P (Y = y X = x) = arg minE [ℓ(y,yˆ) x],
Y|X y
· | |
yˆ∈Y yˆ∈Y
y∈Y
where E [ℓ] is the expected loss of the prediction yˆ with respect to y , and P (y x) is
y Y|X
∈ Y |
the conditional probability of the class y given an input instance x (Devroye et al., 1996).
In the case where the loss is 0-1, the Bayes predictor simplifies to
gbc(x) = arg maxP (Y = y X = x). (6)
Y|X
|
y∈Y
The expected loss of this predictor is known as the Bayes error-rate m (Bc). To determine
Err
the Bayes predictor, the conditional probability distribution P ( ) must be known for
Y|X
·
the underlying data set . In the case where and are independent of each other, i.e.,
D X Y
P (y x) corresponds to the marginal distribution P (y) as input features are completely
Y|X Y
|
uninformative, we have
gbc(x) gmc(x) arg maxP (Y = y). (7)
Y
≡ ≡
y∈Y
We refer to this predictor as the marginal Bayes predictor on . The marginal Bayes
X
predictor assigns to each input x a class label from the set of labels with the highest
marginal probability. Strictly speaking, as the maximum in (7) is not necessarily unique,
the marginal Bayes predictor may pick any label with the highest probability— in that
case, we nevertheless assume that it picks the same label for every x, so that it is a constant
function.
2.2.2.2 Probabilistic Classification Distinct from standard classifiers, probabilistic
classifiers focus on estimating the (conditional) class probabilities P (y x) for each class
Y|X
|
y in , given an input instance x . We denote predictions of that kind by Pˆ (y x).
Y|X
Y ∈ X |
As before, training data comes in the form = (x ,y ) N , where the (x ,y )
D { i i }i=1 ⊂ X ×Y i i
7Gupta, Wever and Hu¨llermeier
are i.i.d. according to P ( ), and the goal to induce a hypothesis h : P( ) with low
(X,Y) p
· X → Y
generalization error (risk)
(cid:90)
R (h ) = E[ℓ (y,h (x))] = ℓ (y,h (x))dP (X = x,Y = y).
p p p p p p (X,Y)
X×Y
Now, however, instead of comparing a predicted class yˆ with a true class y, the loss
ℓ compares a predicted probability distribution with y—thus, the loss is a mapping
p
ℓ : P( ) R, where P( ) denotes the set of probability mass functions (PMFs) on .
p
Y × Y → Y Y
Since is finite and consists of M classes, P( ) can be represented by the (M 1)-
Y Y −
simplex, i.e., predictions can be represented as probability vectors h (x) = pˆ= (pˆ ,...,pˆ ),
p 1 M
where pˆ = pˆ[m] = Pˆ (m x) is the probability assigned to class m. Typically, learning
m Y|X
|
predictors of that kind involve minimizing the empirical risk
N
1 (cid:88)
R (h ) = ℓ (y ,h (x )). (8)
emp|p p p i p i
N
i=1
Subsequently, we denote the empirical risk minimizer by g = arg min R (h )
p hp∈Hp emp|p p
(Vapnik, 1991; Bishop, 2006, chap. 4). In the case where Y is independent of X, the marginal
Bayes predictor or marginal classifier (denoted by gmc) is again the best constant probability
p
predictor, i.e., the one with the lowest risk (8) among all constant predictors.
Proper Scoring Rules So-called (strictly) proper scoring rules constitute an important
class of loss functions is probabilistic classification (Gneiting and Raftery, 2007). Roughly
speaking, such losses incentivice the learner to predict accurate probabilities. Formally, a
loss ℓ ( ) is a proper scoring rule if
p
·
E ℓ (Y,p) E ℓ (Y,pˆ)
Y∼p p Y∼p p
≤
for all distributions p,pˆ, and a strictly proper scoring rule is the above inequality is strict
whenever p = pˆ. Thus, by predicting the true distribution p of the (categorical) random
̸
variable Y, the learner minimizes its loss in expectation. Important examples of strictly
proper scoring rules include the Brier score and the categorical cross-entropy (CCE). The
latter is defined as ℓ (y,pˆ):= ln(pˆ ) (Bishop, 2006, chap. 4). The CCE loss (logarithmic
CCE y
−
scoring rule) is widely recognized for its information-theoretic interpretations and practical
effectiveness (Good, 1992; Roulston and Smith, 2002; Daley and Vere-Jones, 2004). It can
also be motivated in the realm of Neyman–Pearson theory (Feuerverger and Rahman, 1992).
Probability Calibration Despite its sound theoretical grounding, the (empirical)
minimization of a proper scoring rule is not guaranteed to produce accurate probability
estimates in practice. Instead, predictions are often noisy or systematically biased— neural
networks, for instance, tend to be over-confident and predict probabilities that are biased
toward the extremes (Szegedy et al., 2016). So-called calibration methods seek to improve
probabilityestimatesthroughsuitablepost-hocadjustments. Broadlyspeaking,suchmethods
leverage validation data to learn calibration functions in the form of (monotone) mappings
from predicted probabilities to improved probabilities (Silva Filho et al., 2023). In this study,
five prevalent techniques for calibrating multi-class probabilities will be used and briefly
described in Section 3.2.4.
8Deterministic Prediction Obviously, a probabilistic prediction may also serve as a
basis for a deterministic prediction, if needed. Typically, the class label with the highest
(predicted) probability is adopted in that case, i.e., yˆ= arg max Pˆ (y x). As readily
y∈Y Y|X
|
seen, this prediction minimizes the standard 0-1 loss in expectation. The other way around,
this also shows that to perform well in terms of standard 0-1 loss, the learner merely needs
to identify the most probable class, or, stated differently, strong performance can even be
achieved with relatively inaccurate estimates, provided the highest predicted probability is
still assigned to the truly most probable class label (Domingos and Pazzani, 1997; Cheng
and Hu¨llermeier, 2012).
2.2.2.3 Performance Evaluation Metrics Koyejo et al. (2015) and Powers (2011) define
evaluationmeasuresusedforevaluatingtheperformanceofclassifiers, usingtheground-truth
labels denoted by y = (y ,...,y ) for a given = (x ,y ) N and the predictions denoted
1 N D { i i }i=1
by the vector yˆ = (yˆ ,...,yˆ ). The predictions could be obtained by the empirical risk
1 N
minimizer g derived using (5) for a standard classification, such that yˆ = g(x ), i [N] or
i i
∀ ∈
by the deterministic predictions produced by a probabilistic classifier g derived using (8),
p
such that yˆ = arg max g (x )[m], i [N].
i m∈M p i
∀ ∈
Accuracy is defined as the proportion of correct predictions
N
1 (cid:88)
m (y,yˆ):= y = yˆ .
Acc i i
N (cid:74) (cid:75)
i=1
Error-rate is defined as the proportion of incorrect predictions
N
1 (cid:88)
m (y,yˆ):= y = yˆ .
Err i i
N (cid:74) ̸ (cid:75)
i=1
Confusion matrix (CM) Many evaluation metrics are based on the concepts, true
positive (m ), true negative (m ), false positive (m ), and false negative (m ), which are
tp tn fp fn
defined as
N N
(cid:88) (cid:88)
m (y,yˆ) = y = 0,yˆ = 0 , m (y,yˆ) = y = 1,yˆ = 1 ,
tn i i tp i i
(cid:74) (cid:75) (cid:74) (cid:75)
i=1 i=1
N N
(cid:88) (cid:88)
m (y,yˆ) = y = 0,yˆ = 1 , m (y,yˆ) = y = 1,yˆ = 0 .
fp i i fn i i
(cid:74) (cid:75) (cid:74) (cid:75)
i=1 i=1
The confusion matrix is defined using these metrics as
(cid:16) (cid:17)
m (y,yˆ) =
mtn(y,yˆ) mfp(y,yˆ)
.
CM mfn(y,yˆ) mtp(y,yˆ)
False negative rate (FNR) is defined as the ratio of false negatives to the number of
positive instances
m (y,yˆ)
m (y,yˆ) = fn .
FNR
m (y,yˆ)+m (y,yˆ)
fn tp
False positive rate (FPR) is defined as the ratio of false positives to the number of
negative instances
m (y,yˆ)
m (y,yˆ) = fp .
FPR
m (y,yˆ)+m (y,yˆ)
fp tn
9Gupta, Wever and Hu¨llermeier
Mathews correlation coefficient (MCC) is another balanced measure that considers
true and false positives, including true and false negatives. It produces a value between
1 and +1, where +1 represents a perfect prediction, 0 is random, and 1 indicates total
− −
disagreement between the predictions and ground truths. It is formally defined as
(cid:32) (cid:33)
(m (y,yˆ) m (y,yˆ) m (y,yˆ) m (y,yˆ))
m (y,yˆ) = tp × tn − fp × fn
MCC (cid:112)
(m (y,yˆ)+m (y,yˆ))(m (y,yˆ)+m (y,yˆ))
tp fp tp fn
(cid:18) (cid:19)
1
.
× (m (y,yˆ)+m (y,yˆ))(m (y,yˆ)+m (y,yˆ))
tn fp tn fn
Balanced error-rate (BER) is the average of both FPR and FNR, offering a balanced
evaluation metric for a given classification model as
(cid:18) (cid:19)
1 m (y,yˆ) m (y,yˆ) m (y,yˆ)+m (y,yˆ)
m (y,yˆ) = fp + fn = fnr fpr .
BER
2 m (y,yˆ)+m (y,yˆ) m (y,yˆ)+m (y,yˆ) 2
tn fp tp fn
2.3 Quantifying and Detecting Information Leakage
This section describes a measure for quantifying IL in systems by approximating the Bayes
predictor, enabling IL detection. IL occurs in a system when observable information (x ,
∈ X
represented by X) is directly or indirectly correlated with its secret information (e.g.,
secret keys, plaintexts) (y , represented by Y), i.e., some information in x can
∈ Y ∈ X
be exploited to infer the secret y (Kelsey, 2002; Chatzikokolakis et al., 2010). The
∈ Y
presence of IL in a system is determined by analyzing the system’s classification data set
= (x ,y ) N if the Bayes predictor (or a suitable proxy g or g) significantly
D { i i }i=1 ⊂ X ×Y p
outperforms the marginal Bayes predictor (or a suitable proxy gmc). The performance
p
difference quantifies IL within a system and serves as a foundational condition for its
detection. Thus, the ILD involves analyzing the learnability of g minimizing (8) (proxy of
p
Bayes predictor) on the given system data set .
D
IL Quantification IL measures the extent of information in the inputs or observable
information x that can be exploited to deduce the outputs or secret class labels
∈ X
y , quantified directly through MI (Chatzikokolakis et al., 2010). Another method for
∈ Y
quantifying IL in a system uses Bayes predictor gbc to explore dependencies (correlation)
between and . As shown in (7), for cases where and are independent, the Bayes
X Y X Y
predictor reduces to the marginal Bayes predictor. IL is quantified as the difference in
average penalties between the marginal Bayes predictor gmc and the Bayes predictor gbc
using loss functions or metrics like 0-1, CCE, log-loss etc as δ = m (Mc) m (Bc).
Err Err Err
−
In practice, since the ground-truth joint probability density function (PDF) P (.)
(X,Y)
are seldom observed, we approximate the Bayes predictor and the marginal Bayes predictor,
using the empirical risk minimizers, g (or g) and gmc respectively as suitable proxies. When
p p
penalty or loss is evaluated solely based on the classification decisions of the learners, we
may use the empirical risk minimizer g or the decision rule arg max g (x)[y] of g as a
y∈Y p p
proxy for Bayes predictor. However, when using error-rate as the loss function, g serves as a
better proxy as it directly targets and minimizes the average 0-1 loss. In scenarios requiring
assessment based on (conditional) class probabilities, the empirical risk minimizer g should
p
be employed.
10IL is then approximately quantified as the difference in the penalty for the give loss
function between gmc and the empirical risk minimizers, i.e., δ ≊ m (gmc) m (g) ≊
p Err Err p Err
−
m (g) m (gmc) using error-rate (average 0-1 loss). Notably, using log-loss as the loss
Acc Acc p
−
function estimates MI between X and Y to quantify IL, i.e., δ = I(X;Y) = E[ℓ (Mc)]
ll ll
−
E[ℓ (Bc)] ≊ E[ℓ (gmc)] E[ℓ (g )] as per (11). We also propose estimating MI by calculating
ll ll p ll p
−
the midpoint between its upper and lower bounds, defined through Bayes error-rate (proxy
m (g )), asdetailedinSection3.1. OurLog-LossandMid-Pointapproachesoutperform
Err p
state-of-the-art techniques in accurately estimating MI on synthetic data set with known
MI, as detailed in Section 5.
IL Detection The presence of IL in a system generating data set is indicated if
D
the approximated MI or δ is significantly greater than 0. Our prior work (Gupta et al.,
(·)
2022) proposes classification-based ILD approaches that are built on using average 0-1 loss
function or error-rate to quantify and detect IL through δ , serving as baselines for this
Err
study. We propose MI-based ILD approaches which employ the one-sample t-test (OTT)
on multiple MI estimates to determine the presence of IL, as explained in Section 6.2. Our
ILD approach, using log-loss for MI estimation, effectively detects leakage in OpenSSL TLS
server implementations as discussed in Section 7.
3 Mutual Information Estimation Techniques
In this section, we will introduce the two techniques for estimating the mutual information
(MI) in a system generating classification data set using statistical learning theory rather
than relying solely on standard statistical techniques. We briefly describe Mid-Point and
Log-Loss in Sections 3.1 and 3.2, respectively. Additionally, Section 3.3 outlines three
competitive state-of-the-art MI estimation approaches (Eirola et al., 2014; Belghazi et al.,
2018; Qin and Kim, 2019). All these techniques are eventually used to perform information
leakage detection (ILD) using one-sample t-test (OTT) in a given system, as explained
in Section 6.2.
3.1 Mid-point Estimation
We propose the Mid-Point approach, which leverages the relationship between Bayes
error-rate and MI for a given classification task to estimate the MI and eventually perform
ILD in the given system. To estimate the MI, we use the empirical risk minimizer g of (5)
to approximate Bayes error-rate of the given system data set. This approach uses lower and
upper bounds on the conditional entropy H(Y X) which are derived based on the Bayes
|
error-rate m (Bc) and number of class labels M (Tebbe and Dwyer, 1968).
Err
Derived by Hellman and Raviv (1970) and Tebbe and Dwyer (1968), the lower bound on
the conditional entropy of Y given X is expressed as
(cid:18) (cid:18) (cid:19)(cid:19)(cid:18) (cid:19)
m+1 m 1
H (m (Bc),M) = lg(m)+m(m+1) lg m (Bc) − ,
l Err Err
m − m
where H is valid for 1 1 m (Bc) 1 ,m = 1,...,M 1.
l m+1 ≤ − Err ≤ m −
Derived by Fano (1961) and Tebbe and Dwyer (1968), the upper bound on the conditional
entropy of Y given X is expressed as
H (m (Bc),M) = H (m (Bc))+m (Bc)lg(M 1),
u Err 2 Err Err
−
11Gupta, Wever and Hu¨llermeier
where H (a) = alg(a) (1 a)lg(1 a) is the binary cross-entropy function.
2
− − − −
Using H ( ) and H ( ), the conditional entropy H(Y X) is bounded as
u l
· · |
H (m (Bc),M) H(Y X) H (m (Bc),M)
l Err u Err
≤ | ≤
2m (Bc) H(Y X) H (m (Bc)), M = 2.
Err 2 Err
≤ | ≤
These bounds are substituted in (2) to derive the upper F ( ) and lower F ( ) bounds on MI,
u l
· ·
in terms of the Bayes error-rate m (Bc) and number of classes M
Err
H(Y) H (m (Bc),M) I(X;Y) H(Y) H (m (Bc),M)
u Err l Err
− ≤ ≤ −
F (m (Bc),M) I(X;Y) F (m (Bc),M)
l Err u Err
≤ ≤
H(Y) H (m (Bc)) I(X;Y) H(Y) 2m (Bc), M = 2.
2 Err Err
− ≤ ≤ −
We propose employing the mid-point of the upper F ( ) and the lower F ( ) bound to
u l
· ·
estimate the MI, by replacing m (Bc) with the error-rate of g as
Err
F (m (g),M)+F (m (g),M)
I(cid:98)(X;Y) ≊ u Err l Err . (9)
2
Here g is the empirical risk minimizer of (5) and serves as an appropriate approximation
(proxy) of the Bayes predictor, as m (Bc) ≊ m (g).
Err Err
Overestimated MI in Imbalanced Data Sets AsperFigure1, wecanseethatinthe
case of balanced binary classification, when the mid-point MI is 0, the Bayes error-rate is 0.5,
i.e., m (Bc) = m (Mc) = 0.5 which implies that there exists no information leakage (IL)
Err Err
in the system. But for the imbalanced case r = 0.3, when the m (Bc) = m (Mc) = 0.3,
Err Err
the mid-point MI is greater than 0, while in this case there exists no IL in the system
according the statistical learning theory condition illustrated in Section 2.3. This highlights
the problem of overestimation associated with the Mid-Point approach because the ground-
truth MI might indeed be equivalent to the lower bound (F (m (Bc),M)).
l Err
To illustrate this issue, let us consider an example where the class imbalanced joint
distribution P ( ), along with the calculated marginals P ( ), P ( ), and the conditional
(X,Y) Y X
· · ·
P ( ), is defined as
Y|X
·
Joint Distribution Conditionals on Y given X
P (x,y) y = 0 y = 1 P (x) P (y x) y = 0 y = 1 P (x)
(X,Y) X Y|X X
|
x = 0 0.5 0 0.5 x = 0 1 0 0.5 (10)
x = 1 0.45 0.05 0.5 x = 1 0.9 0.1 0.5
P (y) 0.95 0.05 P (y) 0.95 0.05
Y Y
− −
Inthegivenscenario,wecalculatetheground-truthMIbysubstitutingthejointandmarginal
(cid:80) (cid:80)
probabilitymassfunctions(PMFs)from(2)in(3)asI(X;Y) = P (x,y)
(cid:16) (cid:17) x∈{0,1} y∈{0,1} (X,Y) ·
lg
P (X,Y)(x,y)
= 0.0519bits. The Bayes predictor producing optimal decisions is defined
PX(x)·PY(y)
using(6)asgbc(x) = 0withBayeserror-rateof0.05,asm (Bc) = (cid:80) P (y = 1 x)
Err x∈{0,1} Y|X | ·
P (x) = 0.05. Consequently, the binary entropy of Bayes error-rate and Y are calculated
X
using (1) as H(Y) = H (m (Bc)) ≊ 0.286bits. Inserting them into (9), the Mid-Point
2 Err
MI estimation is 0.0932bits approximately.
12Balanced Imbalanced r = 0.3
1.0
m (Bc)=m (Mc) m (Bc)=m (Mc)
Err Err Err Err
0.8
0.6
0.4
0.2
0.0
0.0 0.1 0.2 0.3 0.4 0.5 0.0 0.1 0.2 0.3
Bayes Error-Rate m (Bc)
Err
Fano’s: F l(m Err(Bc),M = 2)
Mid-Point MI: (F u(m Err(Bc),M = 2)+F l(m Err(Bc),M = 2)) ×0.5
Hellman-Raviv: F u(m Err(Bc),M = 2)
Figure 1: Bayes error-rate versus MI estimated using Mid-Point approach
In this example, the ground-truth MI is equal to 0.0519bits, while the Mid-Point
MI estimation is 0.0932bits, indicating the problem of overestimation. This arises due
to the deterministic nature of error-rates in capturing (quantifying) the probabilistic re-
lationship (MI) between two random variables. Furthermore, error-rates might not serve
as an appropriate metric for assessing the performance of imbalanced data sets, leading
to detecting non-existent ILs in the system and resulting in false positives. To enhance
estimation accuracy using these bounds, it becomes crucial to define a Bayes predictor
that minimizes metrics as balanced error-rate (BER) or maximizes mathews correlation
coefficient (MCC), F1-score, etc., as defined in Section 2.2.2.3. Zhao et al. (2013) derives a
relationship between BER and MI for the binary classification setting. Unfortunately, such
a relationship doesn’t extend seamlessly to handling multiple classes.
Baseline ILDs Oversights One common approach to identifying IL is the PTT-
Majority baseline, which relies on uncovering significant differences in error-rates between
the Bayes predictor (or a suitable approximation g or g ) and the marginal Bayes predictor
p
(Gupta et al., 2022). However, considering the example in (10), the Bayes predictor
(gbc(x) = 0) coincides with marginal Bayes predictor and always predicts class 0 for any
given input x. This alignment between Bayes predictor and marginal Bayes predictor
leads to a situation where the IL present in a system goes undetected by PTT-Majority.
Furthermore, the Fisher’s exact test (FET) based ILD approaches, including FET-Mean
and FET-Median, also fall short in identifying this IL. The failure to identify the IL
stems from the Bayes predictor’s confusion matrix, which in this case is evaluated as (95 00),
05 00
yielding an exact p-value of 1 when tested using the FET (Gupta et al., 2022). Consequently,
in cases when Bayes error-rate is very close to marginal Bayes predictor’s error-rate, these
13
)Y;X(I
noitamrofnI
lautuMGupta, Wever and Hu¨llermeier
baseline ILD approaches fail to detect the IL in the system and produce false negatives
(Gupta et al., 2022).
3.2 Log-Loss Estimation
To address the challenges posed by the Mid-Point approach’s overestimation, false positives,
and the false negatives produced by baseline ILD approaches, we propose the Log-Loss
approach for MI estimation. This approach utilizes the empirical risk minimizer g defined
p
in (8) to approximate the log-loss of the Bayes predictor to estimate MI. The MI between
X and Y can be calculated by substituting the log-loss of Bayes predictor and marginal
Bayes predictor in (2) as
I(X;Y) = H(Y X)+H(Y)
− |
(cid:90)
(cid:88) (cid:0) (cid:1)
= P (X = x) P (Y = y X = x) lg P (Y = y X = x) dx
X Y|X Y|X
| · |
y∈Y
x∈X
(cid:88)
P (Y = y) lg(P (Y = y))
Y Y
− ·
y∈Y
= E[ℓ (Bayes predictor)]+E[ℓ (marginal Bayes predictor)]
ll ll
−
= E[ℓ (Bc)]+E[ℓ (Mc)],
ll ll
−
whereE[ℓ ( )]representtheexpectedlog-loss. Note,thattheconditionalentropy(H(Y X))
ll
· |
is equal to the expected log-loss of Bayes predictor, i.e H(Y X) = E[ℓ (Bc)]), while the
ll
|
entropy of Y is the expected log-loss of marginal Bayes predictor, i.e, H(Y) = E[ℓ (Mc)]).
ll
3.2.1 Log-Loss
As discussed in Section 2.2.2.2, the most common loss function, categorical cross-entropy
(CCE), is used to obtain a probabilistic classifier g for a given classification task ( ). This
p
D
classifier provides the estimated conditional class probabilities for an instance x, forming
a vector g (x) = pˆ= (pˆ ,...,pˆ ), where pˆ is the probability assigned to class m, and
p 1 M m
(cid:80)M
pˆ = 1. (Bishop, 2006, chap. 4) defines the log-loss for a probabilistic classifier g as
m=1 m p
M M
(cid:88) (cid:88)
ℓ (y,pˆ) = pˆ lg(pˆ ) = g (x)[m] lg(g (x)[m]).
ll m m p p
− · − ·
m=1 m=1
Thelog-lossreachesitsminimumvalueof0iftheprobabilityishigh,i.e.,pˆ ≊ 1,m [M]for
m
∈
onespecificclassmandlowprobabilitiesforallotherclasses,i.e.,pˆ ≊ 0, j [M] m . It’s
j
∀ ∈ \{ }
akin to conditional entropy, where uncertainty in the classification increases log-loss, i.e., if
g produces uniformly distributed (conditional) class probabilities results in a higher penalty,
p
1
i.e.,pˆ = , m [M] = ℓ (y,pˆ) = lg(M)(Bishop,2006,chap.4). Therefore,expected
m ll
M ∀ ∈ ⇒
log-loss of Bayes predictor and marginal Bayes predictor serves as a direct substitution
estimateforconditionalentropyandentropyofY,receptively,i.e.,H(Y X) ≊ ℓ (y,pˆ). Note
ll
|
that CCE also behaves similarly, but it is only minimized when the estimated probability
of the ground-truth class label y is high ≊ 1 for a given input x and therefore makes
∈ X
it an appropriate loss function to estimate conditional class-probabilities by learning g
p
(approximation of Bayes predictor) for a given data set using (8).
D
143.2.2 Marginal Bayes Predictor Estimation
TheestimationofmarginalBayespredictorisreferredtoasmarginalclassifieranddenotedby
gmc, relies on estimating the class-distribution from the provided data set = (x ,y ) N
p D { i i }i=1
to make predictions using the (8) and only the class labels y of the given data set . For
D
each input x from the data set , the estimated class probabilities gmc(x) = pˆ =
p mc
∈ X D
(x ,y ) y = m
i i i
(pˆ ,...,pˆ ) are determined, where pˆ = |{ ∈ D | }| represents the estimated
1 M m
|D|
prior probability for class M. The log-loss of marginal Bayes predictor is used to estimate
the entropy of Y, i.e., H(Y) ≊ ℓ (y,pˆ ) The maximum value of ℓ (Mc) being lg(M) for a
ll mc ll
balanced data set and any value between 0 and lg(M), indicates an imbalance in the data
set. It takes a minimum of 0 for a highly imbalanced data set where one class dominates the
other classes.
3.2.3 MI Estimation
In the Log-Loss approach, we propose to induce the Bayes predictor using g and marginal
p
Bayes predictor using gmc. The expected log-loss of Bayes predictor is approximated by
p
evaluating the log-loss of g (empirical risk minimizer of (8)) for the given data set , i.e.,
p
D
E[ℓ (Bayes predictor) ≊ E[ℓ (g )]
ll ll p
N N M
1 (cid:88) 1 (cid:88) (cid:88)
E[ℓ (g )] = ℓ (y,g (x )) = g (x )[m] lg(g (x )[m]).
ll p ll p i p i p i
N −N ·
i=1 i=1m=1
Similarly, the expected log-loss of marginal Bayes predictor is approximated by evaluating
the log-loss of gmc, i.e., E[ℓ (marginal Bayes predictor) ≊ E[ℓ (gmc)]
p ll ll p
N M
1 (cid:88) (cid:88)
E[ℓ (gmc)] = ℓ (y,gmc(x )) = pˆ [m] lg(pˆ [m]).
ll p ll p i mc mc
N − ·
i=1 m=1
The MI is then estimated using approximations for the Log-Loss approach as
I(cid:98)(X;Y) ≊ E[ℓ ll(g pmc)] E[ℓ ll(g p)]
−
M (cid:32) N (cid:33)
(cid:88) 1 (cid:88)
≊ g (x )[m] lg(g (x )[m]) pˆ [m] lg(pˆ [m]) . (11)
p i p i mc mc
N · − ·
m=1 i=1
Precision Consider the example in (10), to illustrate the MI estimation precision of the
Log-Lossapproach. Whilethisexampledoesn’tconclusivelydemonstratesuitability, itdoes
highlight the potential precision of the Log-Loss approach in estimating MI and detecting
ILs. Since we propose to employ the consistent learners using the automated machine
learning (AutoML) tools to induce Bayes predictor, the learned predictors g and gmc closely
p p
approximate the conditional and true marginal probabilities, respectively. Therefore, the
predicted marginal probabilities by marginal Bayes predictor (gmc) are approximately equal
p
to pˆ ≊ (0.95,0.05), (conditional) class probabilities by g are approximately equal to
mc p
g (x = 0) ≊ (P (y = 0 x = 0),P (y = 1 x = 0)) = (1.0,0.0) for x = 0 and g (x =
p Y|X Y|X p
| |
1) ≊ (P (y = 0 x = 1),P (y = 1 x = 1)) = (0.9,0.1) for x = 1. The MI estimated via
Y|X Y|X
| |
15Gupta, Wever and Hu¨llermeier
(11) as I(X;Y) ≊ 0.286 0.234 ≊ 0.052bits, will be close to the actual MI. This underlines
−
how the accurate approximation of learned predictors contributes to the close estimation of
MI and reinforces the Log-Loss approach’s potential for precision in detecting ILs within a
system.
3.2.4 Classifier Calibration
Ensuring the precision of probability estimates from the probabilistic risk minimizer g is
p
crucial for the effectiveness of the Log-Loss approach. However, even with the CCE loss
function, these probabilities might not accurately reflect the ground-truth conditionals P ,
Y|X
especiallyinimbalancedclassscenarios(PakdamanNaeinietal.,2015;DomingosandPazzani,
1997). Famous classification methods like Naive Bayes, random forest classifier (RF) produce
inaccurate probability estimates despite their success in accurate classification (Cheng and
Hu¨llermeier, 2012; Domingos and Pazzani, 1997). Consequently, the utilization of classifier
calibration techniques becomes essential to produce predicted probabilities close to actual
frequencies, thereby enhancing the predictive value of probabilistic models (Silva Filho et al.,
2023). In the realm of classifier calibration, post-processing methods are employed to map
predicted class probabilities to more reliable and calibrated probabilities, often achieved
through distinct models or transformation methods (Silva Filho et al., 2023). This study
focuses on five prevalent multi-class calibration approaches to enhance the accuracy of MI
estimation using the Log-Loss approach:
• Isotonic Regression: This approach calibrates predicted probabilities by fitting
a monotonic function that transforms the original scores by minimizing the mean
squared error (MSE), ensuring improved calibration without overfitting the training
data (Barlow and Brunk, 1972; Zadrozny and Elkan, 2002). When combining this
method with log-loss to estimate MI, we refer to it IR Cal Log-Loss.
• Platt’s Scaling: It involves training a logistic regression model on the original
classifier’s outputs and true labels to act as a calibrated version of the original classifier
to produce calibrated class probabilities (Platt, 1999, 2000). When combining this
method with log-loss to estimate MI, we refer to it PS Cal Log-Loss.
• Beta Calibration: This approach employs a parametric transformation using a beta
distribution with adjustable hyperparameters to flexibly calibrate probabilities for
different data sets (Kull et al., 2017). When combining this method with log-loss to
estimate MI, we refer to it Beta Cal Log-Loss.
• Temperature Scaling: By scaling the logits (log-odds) of predicted probabilities
using a “temperature” parameter, this method calibrates the entire distribution
while maintaining the rank order of class labels according to original predicted class
probabilities (Guo et al., 2017). When combining this method with log-loss to estimate
MI, we refer to it TS Cal Log-Loss.
• Histogram Binning: Predicted probabilities are discretized into bins, and the true
class frequency in each bin is estimated to adjust predicted class probabilities and
achieve calibration (Zadrozny and Elkan, 2001). When combining this method with
log-loss to estimate MI, we refer to it HB Cal Log-Loss.
16These calibration techniques are pivotal in refining the predicted class probabilities and
ensuring accurate MI estimation through the Log-Loss approach. When using these
techniques to estimate MI and perform ILD using Log-Loss, we refer to them collectively
as Cal Log-Loss.
3.3 Baselines
In this section, we will briefly describe three baseline approaches, namely Gaussian mixture
model (GMM), mutual information neural estimation (MINE) and PC-Softmax, recently
introduced to estimate the MI (Eirola et al., 2014; Belghazi et al., 2018; Qin and Kim, 2019).
3.3.1 Gaussian Mixture Model
GMM provide a robust solution to approximating unknown probability density functions
(PDFs) (P , P , P ) required to estimate MI via (3) effectively for classification data
(X,Y) X Y
sets (Maia Polo and Vicente, 2022). The process begins by fitting a GMM to the joint
D
space , to estimate the joint PDF Pˆ ( ) between X and Y. To deduce the marginal
(X,Y)
X ×Y ·
PDFs on X (Pˆ ( )) and Y (Pˆ ( )), fitted GMM is used with appropriate variables. The MI
X Y
· ·
is approximated using the estimated PDFs (pˆ( )) and the provided data set = x ,y N
· D { i i }i=1
as
N
1 (cid:88)(cid:16) (cid:17)
I(cid:98)(X;Y) = lg(Pˆ (X,Y)(X = x i,Y = y i)) lg(Pˆ X(x i)) lg(Pˆ Y(y i)) .
N − −
i=1
While GMMs are robust, they face challenges of overfitting with high-dimensional data sets,
where model parameters grow quadratically with data set dimensionality (d) (Maia Polo and
Vicente, 2022; Eirola et al., 2014). The high-dimensional data clustering (HDDC) variant
restricts covariance matrices (spherical, diagonal) to reduce parameters, allowing for efficient
estimation and compatibility with the expectation-maximization (EM) algorithm to address
the problem of curse of dimensionality (Eirola et al., 2014). GMM performs poorly on
high-dimensional data sets and is particularly suited for data that follows a multivariate
normal (MVN) distribution.
Estimation Process Considering a GMM with K components for the space ,
X ×Y
each component k is associated with its unique parameters: mixing coefficients (π ), means
k
(µ ), and covariance matrices (Σ ) (Eirola et al., 2014). These mixing coefficients must be
k k
0 < π < 1 for each component, and the sum of all coefficients over the components equals
k
(cid:80)K
one, i.e., π = 1, which are written as
k=1 k
(cid:20) (cid:21) (cid:20) (cid:21)
µ Σ Σ
X XX XY
µ = k , Σ = k k .
k k
µ Σ Σ
Y YX YY
k k k
The marginal model for X (Pˆ ( )) is a GMM of K components with the same mixing coeffi-
X
·
cients (π ), but only consider the means (µ ) and covariance matrices (Σ ) associated
k X k XX k
with X (Eirola et al., 2014). The marginals GMM for Y (Pˆ ( )) is determined in a similar
Y
·
way. EM algorithm is employed to fit a GMM and determine K (number of components).
The value of K is essential since an insufficient number of components can overlook data
properties, while too many may lead to overfitting. The Akaike information criterion (AIC)
assists in this decision, considering both the log-likelihood ℓ(θ) of the fitted model and the
17Gupta, Wever and Hu¨llermeier
number of free parameters F, defined as AIC = 2logℓ(θ)+2F (Eirola et al., 2014). In
−
order to make the approach robust and comparison fair with our approaches, we perform
the hyperparameter optimization (HPO) using Akaike information criterion (AIC) as the
objective function.
3.3.2 Mutual Information Neural Estimation
MINE aims to estimate the MI between two variables (X, Y) by training a neural network
to optimize a specific objective function for a given data set = x ,y N
D { i }i=1
(cid:16) (cid:17)
ℓ (x,y) = sup E [T (x,y)] log(E [e(T θ(x,y))]) ,
MINE (x,y)∼P (X,Y)(x,y) θ
−
(x,y)∼PX(x)·PY(y)
θ
where T (x,y) : Rd+M R represents the neural network (learnable parameters θ) function,
θ
→
with input layer of size d+M (units) (Belghazi et al., 2018). The d-dimensional input
x concatenated with one-hot-encoded M length ground-truth class label y serves as an
input to the network. The network’s architecture encompasses an input layer (Linear units)
and hidden layers using ReLU activation, evaluating a real-valued output (Linear unit)
quantifying the dependency between x and y. MINE maximizes the discrepancy between the
network’s expectations over the joint (P ( )) and marginal (P ( ),P ( )) distributions.
(X,Y) X Y
· · ·
Essentially, MINE serves as an upper-bound estimator for MI by capturing the variable’s
statistical dependency without having to explicitly determine their unobserved (underlying)
probability distributions (Belghazi et al., 2018). Through iterative training, the process
outlined in Algorithm 1, MINE efficiently estimates MI, especially when data dimensionality
is high with unobserved PDFs.
Algorithm 1 Training algorithm: MINE
Require: Dataset = (x ,y ) N , Neural Network T
D { i i }i=1 θ
Ensure: Estimated MI: Iˆ
θ
1: Initialize network parameters θ and hyperparameters
2: Set N epochs = 10000, Set B such that N mod B = 0
3: for n [N epochs] do
∈
4: Define a random permutation π on set of indices [N]
5: for b [B] do
∈
6: Define batch start and end: b s = (b −1)N B +1, b e = b · N B
7: Evaluate the lower-bound:
(cid:16) (cid:17)
8: V(θ)
←
B1 (cid:80)b i=e bsT θ(x i,y i) −log B1 (cid:80)b i=e bs(cid:0) exp(cid:0) T θ(x i,y π(i))(cid:1)(cid:1)
9: Evaluate bias-corrected gradients (using exponential moving average) as:
10: G b(θ) θV(θ)
← ∇
11: Update the statistics network parameters: θ θ+G b(θ)
←
12: end for
13: end for
(cid:18) (cid:19)
14: Compute Iˆ θ = N1 (cid:80)N i=1T θ(x i,y i) −log N1 (cid:80)N i=1(cid:0) exp(cid:0) T θ(x i,y π(i))(cid:1)(cid:1)
15: return Estimated MI: lg(e) Iˆ θ
·
18Overfitting Solution The main challenge for MINE lies in determining the suitable
neural network architecture for estimating MI. The HPO approach is not straightforward
due to the absence of a suitable objective function. Discrepancy-based methods like MINE
and Kullback-Leibler (KL) divergence, which compare network outputs between shuffled and
original data sets, can potentially lead to architectures that overfit and produce biased MI
estimates. To tackle these challenges, we propose an innovative solution that combines HPO
with ensemble methods. Instead of relying on a single architecture, we leverage the power of
diversity by aggregating the outputs of top-5 performing architectures identified through
HPO, with MSE as the objective function. This enhances MI estimation precision and yields
more reliable and robust MI estimates. Moreover, it demonstrates strong generalization
across diverse data sets, making it a promising solution.
3.3.3 PC-Softmax
PC-Softmax offers an alternative approach to estimating MI in classification data sets
D
using a modified version of softmax function, referred to as probabilitiy-corrected softmax
(PC-softmax) (Qin and Kim, 2019). This approach combines PC-softmax with the CCE
loss function to acquire an empirical risk minimizer g for classification data sets , using
p
D
(8). The (conditional) class probabilities predicted by g are then used to estimate MI using
p
the PC-softmax function (Qin and Kim, 2019).
This approach provides several advantages over MINE— it’s straightforward and easy
to implement, and the network architecture can be easily optimized using classification
evaluation metrics or loss functions as objective functions. It approximates the lower bound
of KL divergence between the joint (P ( )) and the product of marginals (P ( ),P ( ))
(X,Y) X Y
· · ·
for variables X and Y to estimate a lower bound on the MI (Qin and Kim, 2019).
Estimation Process The accurate estimation of (conditional) class probabilities
by the empirical risk minimizer g is quite challenging, particularly compared to stan-
p
dard classification. In practice, typically g is obtained by learning a scoring function
p
h (x): RM, h , which assigns an un-normalized real-valued score to each class
s|θ s|θ s
X → ∈ H
label, parameterized by θ Rn, where n is the number of trainable parameters (Bishop,
∈
2006, chap. 4). Neural networks or multi-layer perceptron (MLP) with M linear nodes in
the second last layer are commonly used to estimate these parameters θ of the scoring
function h ( ). MLP outputs un-normalized scores h (x) = s = (s ,...,s ) for a given
s|θ s|θ 1 M
·
instance x, where s = h (x)[m] = s[m] is the score assigned to class m. The softmax
m s|θ
function S(x):RM [0,1]M is then commonly used to convert these scores into probabilities
→
pˆ = (pˆ ,...,pˆ ), typically implemented in the output layer with M nodes of the MLP.
1 M
For a given ground-truth class y [M], the score s[y] is transformed to the corresponding
∈
(conditional) class probability pˆ[y] by the softmax function
exp(s[y])
S(x)[y] = pˆ[y] = .
(cid:80)M
exp(s[m])
m=1
Theempiricalriskminimizerg isthenobtainedusingtheCCEloss,computedforreal-valued
p
scores using the softmax function, defined as ℓ (x,y):= ln(S(x)[y]).
CCE
−
Qin and Kim (2019) shows that the expected CCE is equivalent to the MI between input
and output Y random variable up to a constant lg(M) under a uniform label distribution,
X
19Gupta, Wever and Hu¨llermeier
i.e., I(X;Y) I(cid:98)(X;Y) ≊ (cid:80) log(S(x)[y]). The authors introduce PC-softmax as
≥ − (x,y)∈D
an extension of traditional softmax to enhance MI estimation, providing mathematical
justifications for its effectiveness as an estimator
exp(s[y])
S (x)[y] = .
pc (cid:80)M
exp(P (m) s[m])
m=1 Y ·
The PC-softmax function reduces to the traditional softmax when P (y) = 1 , y
Y M ∀ ∈
[M]. The corresponding CCE loss is defined as ℓ (x,y):= ln(S (x)[y]), which is
Pcce pc
−
especially effective for enhancing MI estimation accuracy in unbalanced data sets. The
loss is evaluated by estimating the marginal using the data set, such that Pˆ (y = m) =
Y
(x ,y ) y = m
i i i
|{ ∈ D | }|, since P ( ) is seldom observed. This loss function maximizes the
Y
·
|D|
lower bound on the MI, making it a simple yet effective technique for estimating MI in
classification tasks. The MI for a given data set = x ,y N is estimated as
D { i }i=1
1 (cid:88) 1 (cid:88)
I(X;Y) I(cid:98)(X;Y) ≊ ℓ Pcce(x,y) lg(e) = lg(S pc(x)[y]).
≥ N × −N
(x,y)∈D (x,y)∈D
This approach provides a lower bound on MI, similar to Log-Loss, but Log-Loss offers
a simpler and potentially more accurate method for estimating MI in classification tasks.
Contrary to MINE, the MLP architecture for this approach can be optimized for any given
data set using standard objective functions used for optimizing MLP architectures in
D
classification tasks, like accuracy, validation CCE loss, etc.
4 AutoML tools
In the last decade, the field of automated machine learning (AutoML) has emerged as a
responsetothehighandunmetdemandforengineeringmachinelearningapplicationsexperts.
While AutoML envisions the automation of the entire data science process, the arguably
most studied problem is that of the combined algorithm selection and hyperparameter
optimization (CASH), which was first formally specified by Thornton et al. (2013).
Since then, various systems have been devised (Thornton et al., 2013; Feurer et al., 2019;
Olson et al., 2016; Mohr et al., 2018), demonstrating promising performances for tailoring
the choice of machine learning (ML) algorithms and the setting of their hyperparameters to a
given task, typically comprising a data set and a loss function. A more thorough overview of
AutoML methods can be found in (Zo¨ller and Huber, 2021). While various AutoML systems
with complementary strengths have been proposed in the literature, a recent benchmark
study (Gijsbers et al., 2022) suggests AutoGluon (Erickson et al., 2020, 2022) as the AutoML
system with the best performance across data sets and different tasks.
In (Hollmann et al., 2023), instead of tackling the CASH problem, a general predictor
called TabPFN is fitted across various different data sets and is able to immediately return
highly accurate predictions. Yielding competitive performance to AutoGluon, TabPFN
suggests itself as a state-of-the-art AutoML tool that returns results substantially faster
than other AutoML systems.
20Due to their strong performance, we selected AutoGluon and TabPFN to approximate
the Bayes predictor in our method. In Sections 4.1 and 4.2, we briefly describe the concepts
AutoGluon and TabPFN are based on, respectively.
4.1 AutoGluon
In contrast to other AutoML systems that aim to select feature preprocessing algorithms
and a learning algorithm and tune their respective hyperparameters, AutoGluon (Erickson
et al., 2020, 2022) follows a different approach. More specifically, AutoGluon focuses on
building a stacking ensemble, greedily adding more models as long as they are beneficial
for the overall performance of the ensemble. To this end, AutoGluon searches over a wide
range of different ML algorithms and pre-fitted models, including deep learning, gradient
boosting, and linear models. Simultaneously, AutoGluon tunes hyperparameters for each
model to optimize their performance. For performing hyperparameter optimization (HPO),
different standard techniques can be used such as ASHA (Li et al., 2020), Hyperband (HB)
(Li et al., 2017), Bayesian optimization (BO) (Frazier, 2012), or Bayesian optimization and
Hyperband (BOHB) (Falkner et al., 2018).
A recent benchmark study found AutoGluon to perform superior to other AutoML
systems in terms of predictive performance and robustness. The only drawback noted by
Gijsbers et al. (2022) is the prediction time, as it will grow with the number of models
included in the returned stacking ensemble.
Moreover, AutoGluon allows the customization of the set of considered ML algorithms
and models, including gradient boosting machine (GBM) tree-based models and deep neural
networks (NNs). For our study, we limited the search space of AutoGluon to consistent
classifiers (Mielniczuk and Tyrcha, 1993; Biau et al., 2008). In Table 4, we present the
models and learning algorithms with corresponding hyperparameters, including their range
values available to AutoGluon in our experimental evaluation in Sections 5 and 7.
4.2 TabPFN
TabPFN (Hollmann et al., 2023) is an approach to AutoML that solves classification tasks
in a transductive way. Instead of fitting a model specifically to a data set and returning this
model to the user, TabPFN is a transformer-based neural network architecture trained on
vast number of different probability distributions of tabular data. Instead of searching for a
proper learning algorithm and its hyperparameter setting in the first place, TabPFN can be
used to instantaneously make predictions as it is already fitted on prior data.
Due to this, predictions can be obtained faster by orders of magnitude compared to
classical AutoML estimation baseline tools. Moreover, the predictions have proven to be
highly accurate and excel, particularly on small tabular data sets. However, TabPFN was
only considered for data sets consisting of up to 1000 training data points, 100 numeric
features, and 10 classes. Hence, in practical applications with more data points, TabPFN is
currently not reliably applicable.
Due to its highly accurate predictions, which furthermore appear to come along with
well-calibrated probability estimates for the classes, TabPFN is an interesting pick for our
approach to approximate the Bayes predictor. Since TabPFN is limited to handling data sets
with up to 100 numeric features, our real IL-Datasets obtained from OpenSSL TLS server
21Gupta, Wever and Hu¨llermeier
implementations contain more than 100 features. To address this, we recommend applying
dimensionality reduction techniques, specifically random forest classifier (RF) and extra
trees classifier (XT) (only when d > 100). We perform fine-tuning on TabPFN, adjusting
parameters such as the number of reduced features, the reduction model, and the number
of prior-fitted models using HPO. Table 4 lists the specific parameter ranges used for
conducting our experiments detailed in Sections 5 and 7.
5 Mutual Information Estimation: Empirical Evaluation
This section extensively evaluates our methods and compares them to baseline approaches
for estimating mutual information (MI) using data sets generated by synthetic systems,
subsequently referred to as synthetic data sets. We begin by outlining the procedure
for generating these synthetic data sets via multivariate normal (MVN) distribution, as
detailed in Section 5.1. Section 5.2 provides a comprehensive overview of the empirical setup,
utilizingthenormalizedmeanabsoluteerror(NMAE)metricforperformanceassessment. To
summarize the results, we assess the overall performance of MI estimation techniques across
various systems in Section 5.3.1. Our evaluation also explores generalization capabilities
across factors, including the number of classes (M), input dimensions (d), class imbalance
(r), and noise level (ϵ) present within the given synthetic data set. Concise results on
generalization capabilities for selected approaches are discussed in Section 5.3.2, with
analysis detailed in Appendix C.2. Our results highlight our proposed approaches’ superior
performance and better generalization capabilities compared to state-of-the-art methods.
5.1 Simulating Synthetic Systems
We employ the MVN distribution to simulate a real-world scenario involving systems
containing information leakages (ILs) and generating synthetic classification data set. MVN
is a natural choice due to its ability to mimic real-world data patterns (Amancio et al., 2014;
Bishop, 2006, chap. 2). Some illustrations of two-dimensional data points generated using
the two noise introduction procedures are shown in Figure 3.
5.1.1 Introducing Class Imbalance (r)
In order to generate the synthetic data sets using the MVN distribution, we define the
vector n = (n ,...,n ), where n = (x ,y ) y = m denotes the sample
M 1 M m i i i
|{ ∈ D | }|
counts for each class label m in the data set . The parameter r indicates the minimum
D
proportion of instances associated with a particular class label in , offering insights into
D
frequency disparities in the class distribution of the data set. Mathematically, it is defined
1 1
as: r = min nm, i.e., r (0, ]. So, when the underlying data set is balanced, r = ,
m∈[M] |D| ∈ M M
1
whereas in the case of imbalanced one, r < .
M
In order to generate a multi-class imbalanced data set (M > 2), we introduce two
generation methods termed Minority and Majority. With the Minority approach, we
create data sets with a singular minority class, and the other classes have an equal but
larger number of data points (> N) in comparison to the minority class (g = Minority).
M r
Conversely, with the Majority method, we create data sets with just one majority class,
22Multi-class Multi-class
Binary-class Imbalance r=0.1 Imbalance r=0.1
Imbalance r=0.1 (Majority) (Minority)
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
1 2 1 2 3 4 5 1 2 3 4 5
Class Label Class Label Class Label
Figure 2: Class frequencies in the imbalanced synthetic data sets
while the other classes have an equal but smaller number of data points (< N) relative
M
to the majority class (g = Majority). The resulting sample counts vector ngr for both
r M
generation methods g Minority,Majority is defined as
r
∈ { }
nMajority
= ( N r ,..., N r ,N (M 1) N r )
M ⌈ · ⌉ ⌈ · ⌉ − − ⌈ · ⌉
N(1 r) N(1 r) N(1 r)
nMinority
= ( − ,..., − ,N (M 1) − ), (12)
M ⌈(M 1)⌉ ⌈(M 1)⌉ − − ·⌈(M 1)⌉
− − −
where = N = 1000 M is the number of instances or the data set size, M is the number
|D| ·
of classes and r is the class imbalance parameter. The class frequencies for each generation
method are depicted in Figure 2.
5.1.2 Data Generation using MVN Distribution
We use the MVN distribution to generate the realistic synthetic classification data sets,
widely employed for benchmarking classifiers (Amancio et al., 2014). The MVN distribution
is a natural choice due to its simplicity, well-established statistical properties, and ability to
effectivelymodelcomplexinter-variablecorrelationsinreal-worlddata(Bishop,2006,chap.2).
Moreover, the central limit theorem provides additional justification for preferring the MVN
distribution over other multi-variate distributions, as it states that the cumulative sum of
a large number of independent random variables often conforms to a normal distribution
(Bishop, 2006, chap. 4).
Formal Model In order to generate the synthetic system’s data set while maintaining
a clear means of obtaining the ground-truth MI, we define the conditional probability on X
given Y as
P (X = x Y = m) = MVN(µ ,Σ), (13)
X|Y m
|
where µ denotes the d-dimensional mean vector associated with class label m and Σ is the
m
covariance matrix of size d d, expressing correlations among input features x. The marginal
× 1
on Y is estimated using the n as P (Y = m) = nm, which boils down to P (Y = m) =
M Y M Y M
for balanced data sets, for which the entropy of Y is maximal, i.e. H(Y) = lg(M). The
23
ycneuqerFGupta, Wever and Hu¨llermeier
marginal on Y for data sets generated using either the “Minority” or “Majority” generation
method are
 (cid:40)

 Majority
P Y(Y = m) = r, if m
∈
[M] \M

 P (Y = m) = 1 r (M 1), if m = M
Y
g r = (cid:40) − · − (14)

 Minority
P Y(Y = m) = M1− −r 1, if m
∈
[M] \M

 P (Y = m) = r, if m = M
Y
The joint distribution between X and Y is P (x,m) = P (m) P (x m) and the
(X,Y) Y X|Y
× |
marginal on X is calculated as
M M
(cid:88) (cid:88)
P (x) = P (m) P (X = x Y = m) = P (m) MVN(µ ,Σ). (15)
X Y X|Y Y m
· | ·
m=1 m=1
Using this, we can compute the exact class probabilities for a given instance x, with the
conditional on Y given X is calculated as
P (Y = m) P (X = x Y = m)
Y X|Y
P (Y = m X = x) = · |
Y|X | (cid:80)M P (Y = m) P (X = x Y = m)
m=1 Y · X|Y |
P (X = x,Y = m)
(X,Y)
= . (16)
P (X = x)
X
5.1.3 Introducing Noise (ϵ) in the System
To simulate systems generating classification data sets, we sample the instances (x ,y )
i i
∼
P (x y ), i [N] (using Equation (13)) and the class-distribution follows P (y) (using
Y|X i i Y
| ∀ ∈
Equation (14)). However, we need to introduce noise into the data set to simulate real-world
IL scenarios in cryptographic systems. Specifically, we aim to replicate situations where the
certainty about the true output y diminishes as we observe more inputs x , i.e,
i i
∈ Y ∈ X
H(Y X) > 0, I(X;Y) < H(Y).
|
We propose two methods: the MVN perturbation and proximity techniques. The
perturbation technique introduces noise by flipping a certain percentage of outputs or
class labels (y , i [N]) in the generated synthetic data set. On the other hand, the
i
∀ ∈
proximity technique introduces noise by reducing the distance between the mean vectors
(µ ) associated with each class. As a result, this leads to a higher degree of overlap
m
between the Gaussians MVN(µ ,Σ) across all classes m. These methods enable us to
m
simulate scenarios where cryptographic systems leak no information (non-vulnerable), i.e.,
the case when H(Y X) = H(Y) and I(X;Y) = 0. Figure 3 illustrates an example of
|
two-dimensional data points generated by both vulnerable systems with noise levels of 0
and 0.5 and non-vulnerable systems with noise level of 1.0, simulated using the outlined
techniques to introduce noise.
5.1.3.1 MVN Perturbation Technique Our initial approach involves introducing noise
by flipping a certain percentage of class labels in the simulated system’s data set. The
procedure for simulating perturbed systems to generate classification data sets, for a unique
configuration of the generation method (g ), number of classes (M), input dimensions (d),
r
noise (ϵ), and class imbalance (r), is outlined in Algorithm 2.
24MVN Perturbation Dataset
Vulnerable †=0.0 Vulnerable †=0.5 Non-vulnerable †=1.0
MVN Proximity Dataset
Figure 3: Generated synthetic data sets using MVN perturbation and proximity techniques
Modified probability density functions (PDFs): The introduction of noise by
flipping ϵ percentage of class labels (y ) modifies the conditional probability measures
∼ Y
P ( ) and P ( ) defined in Section 5.1.2. For fixed ϵ, let random variables B
Y|X X|Y
· · ∼
Bernoulli(p = ϵ,q = 1 ϵ), Y˜ Categorical(P (1),...,P (M)) such that B,Y˜ are
Y Y
− ∼ { }
independent of X,Y . The modified output random variable Y is defined as
ϵ
{ }
Y = Y B = 0 + B = 1 Y˜ .
ϵ
·(cid:74) (cid:75) (cid:74) (cid:75)·
The conditional on the modified output variable Y given X (P ( )) is derived as
ϵ Yϵ|X
·
P (Y = m X = x) = P (B = 0) P (m x)+P (B = 1) P (Y˜ = m)
Yϵ|X ϵ
|
B
·
Y|X
|
B
·
Y˜
= (1 ϵ) P (Y = m X = x)+ϵ P (Y = m).
Y|X Y
− · | ·
The marginal distributions on X remain unchanged because only the class labels are
flipped. Accordingly, the modified marginal Y is derived as: P (Y = y) = ϵ P (Y =
ϵ Yϵ ϵ
·
Y
y)+(1 ϵ) P (Y = y) = P (Y = y). So, the marginal on Y is the same as that of Y.
Y Y ϵ
− ·
Consequently, we can evaluate the ground-truth MI using the marginal P (Y = m) and
Y
modified conditional PDFs, i.e., P (Y = m X = x) using (17). The conditional on X
Yϵ|X ϵ
|
given Y (P ( )) is derived as
ϵ X|Yϵ
·
P (Y = m X = x) P (X = x)
P (X = x Y = m) =
Yϵ|X ϵ
| ·
X
.
X|Yϵ
|
ϵ
P (Y = m)
Y
The altered conditional distribution P (X = x Y = m) appears to be a combination of
X|Yϵ
|
ϵ
multiple MVN distributions, which introduces complexity into the data set. This increased
complexityposesagreaterchallengeformodelstolearnfromthedata, makingtheestimation
of MI more challenging.
25Gupta, Wever and Hu¨llermeier
Algorithm 2 Generate Perturbation MVN for given g , M, d, ϵ and r
r
D
1: Define = , N = 1000 M
2:
CalculaD
te
ng M{ r}
= (n
1,...,n·
M) using (12)
3: Sample positive semi-definite matrix for the MVN distribution
Q OrthogonalMatrix =
(cid:16)q .1 ., .1 .. ...
.
q .1., .d(cid:17)
, q [ 1,1), (i,j) [d] [d]
∼ d×d q d,1 ... q d,d i,j ∈ − ∀ ∈ ×
(cid:18) (cid:19)
s 1,1 ... 0
S Diagonal(RandomMatrix d×d) = 0 ... 0 , s i,i [0,1), i [d]
∼ 0 ... s d,d ∈ ∀ ∈
Σ = (Q S) QT
· ·
4: for m [M] do
∈
5: Define µ m = (1.5m,...,1.5m) Rd
∈
6: for i [n m] do
∈
7: Sample x i MVN(µ m,Σ)
∼
8: Assign label y i using B Bernoulli(p = ϵ,q = 1 ϵ) ▷ Flip ϵ % labels
(cid:40) ∼ −
y = m, B = 0
i
9:
y Categorical(P (1),...,P (M)), B = 1
i Y Y
∼
10:
11: = (x i,y i) ▷ Add instances
D D∪{ }
12: end for
13: end for
14: return
D
Algorithm 3 Generate Proximity MVN for given g , M, d, ϵ and r
r
D
1: Define = , N = 1000 M
2:
CalculaD
te
ng M{ r}
= (n
1,...,n·
M) using (12)
3: Sample positive semi-definite matrix for the MVN distribution
Q OrthogonalMatrix =
(cid:16)q .1 ., .1 .. ...
.
q .1., .d(cid:17)
, q [ 1,1), (i,j) [d] [d]
∼ d×d q d,1 ... q d,d i,j ∈ − ∀ ∈ ×
(cid:18) (cid:19)
s 1,1 ... 0
S Diagonal(RandomMatrix d×d) = 0 ... 0 , s i,i [0,1), i [d]
∼ 0 ... s d,d ∈ ∀ ∈
Σ = (Q S) QT
· ·
4: for m [M] do
∈
5: Define µ m = (1.5 m(1 ϵ),...,1.5 m(1 ϵ)) Rd ▷ Distance 1.5(1 ϵ)
· − · − ∈ −
6: for i [n m] do
∈
7: Sample x i MVN(µ m,Σ)
∼
8: = (x i,m) ▷ Add instances
D D∪{ }
9: end for
10: end for
11: return
D
265.1.3.2 MVN Proximity Technique Our second approach introduces noise in the
simulated systems by reducing the distance between the Gaussians generated by MVN
distributions. This is achieved by moving the mean vectors µ′ , m [M] corresponding
m 0
∀ ∈
to MVN distribution representing each class closer to each other. The updated MVNs for
each class m is defined by MVN(µ′ ,Σ), which in turn represents the conditional PDF
m
P ( ) for the underlying generated system data set. The process for simulating systems
X|Y
·
using the proximity technique to generate classification data sets, for a unique configuration
of the generation method (g ), number of classes (M), input dimensions (d), noise (ϵ),
r
and class imbalance (r), is outlined in Algorithm 3. Notably, when introducing proximity,
only the original MVN is modified, which only modifies the conditional on X given Y, i.e.,
P (X = x Y = m) = MVN(µ′ ,Σ). Consequently, the conditional probability P ( )
X|Y m Y|X
| ·
and the marginal on X can be computed using Equations (15) and (16). Importantly,
this process does not impact the marginal distributions of Y (as shown in Equation (14)),
allowing for the evaluation of ground-truth MI using (17).
5.1.4 Ground-truth MI
It is imperative to have the ground truths or true MI values to evaluate and compare
MI estimation approaches. The synthetic classification data sets are generated using the
conditional P ( ) with the class distribution (marginal on Y) defined by P ( ) in (13) and
X|Y Y
· ·
(14), respectively. The maximum possible MI, i.e., the entropy of Y (H(Y)), is evaluated
1
by substituting P ( ) into (1). If the underlying data set is imbalanced, then r (0, )
Y
· ∈ M
indicating that the entropy of Y is less than lg(M). Conversely, when the underlying data
1
set is balanced with r = , the entropy of Y equals lg(M). With this information, we
M
derive the conditional P ( ) and the marginal on Y (P ( )), as derived in (16) and (15),
Y|X Y
· ·
respectively. Thus, we can estimate the ground-truth MI by substituting them in (2) as
(cid:90)
(cid:88) (cid:0) (cid:1)
I(X;Y) = P (x) P (Y = y X = x) lg P (Y = y X = x) dx
X Y|X Y|X
| · |
y∈Y
x∈X
(cid:88)
P (Y = y) lg(P (Y = y))
Y Y
− ·
y∈Y
(cid:88) (cid:88) (cid:0) (cid:1)
= P (Y = y X = x) lg P (Y = y X = x) dx
Y|X Y|X
| · |
x∈Xy∈Y
(cid:88)
P (Y = y) lg(P (Y = y)) .
Y Y
− ·
y∈Y
Using the above formula, we can get an estimate on the actual ground-truth MI for the
generated synthetic data set = (x ,y ) N as
D { i i }i=1
N
GI( ) ≊ 1 (cid:88) P (Y = y X = x ) lg(cid:0) P (Y = y X = x )(cid:1)
Y|X i i Y|X i i
D N | · |
i=1
M
(cid:88)
P (Y = m) lg(P (Y = m)) . (17)
Y Y
− ·
m=1
27Gupta, Wever and Hu¨llermeier
5.2 Experimental Setup
In this section, we outline the empirical evaluation process for our proposed MI estimation
approachescomparedtothebaselinesonvarioussyntheticdatasets,asillustratedinFigure4.
Our primary goal is to assess the generalization capabilities of our approaches compared to
For Each Dataset
N1S-3SCV
BASELINE
MI Estimators
Classification MID-POINT
Accuracy MI Estimator
Synthetic
AutoGluon LOG-LOSS
Dataset Class Probabilities
TabPFN MI Estimator
Generator
Class Probabilities LOG-LOSS
Calibrated MI Estimator
Class Probabilities
Calibration
Techniques
Normalized Mean
Ground-Truth MIs Estimated MIs
Squared Error
Figure 4: Experimental setup for evaluating MI estimation approaches
the baselines. The evaluation criteria encompass various factors, including the number of
classes (M), input dimensions (d), class imbalance (r), and noise level (ϵ) within synthetic
data sets with known MI. To achieve this, we simulate the systems generating data set using
perturbation and proximity techniques for different unique configurations of g ,d,M,r,ϵ, as
r
outlined in Table 1.
5.2.1 Evaluation Process
To conduct our experiments, we employ each MI estimation approach (detailed in Section 3)
on synthetic data sets outlined in Table 1. For each unique configuration (g ,M,d,r,ϵ),
r
we generate 10 synthetic data sets denoted as using different seeds j [10]. We apply
j
D ∈
each approach to these 10 data sets and evaluate their performance using NMAE, as shown
in Figure 4.
For accurate MI estimation on each data set , we utilize nested cross-validation with
j
D
HPO. The objective functions employed for HPO include balanced error-rate (BER) for
PC-Softmax, AutoGluon, and TabPFN, Akaike information criterion (AIC) for Gaussian
mixture model (GMM), and mean squared error (MSE) for mutual information neural
estimation (MINE) with specific parameter ranges provided in Table 4. We split into a
j
D
trainingdatasetwith70%ofinstancesandatestdatasetwiththeremaining30%. Wethen
perform HPO with 100 function evaluations using Monte Carlo cross-validation (MCCV)
28employing 3 splits on the training data set, reserving 30% of the instances for validation.
This process is denoted as “N1S-3SCV” indicating 1 split for test evaluation and 3 MCCV
splits for HPO using nested cross-validation (denoted by N), as depicted in Figure 4. For
AutoGluon, we let it run for 1800 seconds with BER as an objective using the training data
set. The best-performing model or pipeline is chosen based on the objective function with
minimum validation loss (or maximize validation accuracy).
We use the best model or pipeline to estimate MI (Iˆ) using the complete data set
j j
D
and compare it to the corresponding ground-truth MI (I ) evaluated using (17). We evaluate
j
our approach using the NMAE metric, comparing the actual MIs (I) with the estimated
MIs (Iˆ), defined in (18).
Table 1: Overview of the synthetic data sets for MI estimation experiments
MVNPerturbation&MVNProximitySyntheticDataSets
DatasetType GenerationMethod(gr) InputDimensions(d) Classes(M) NoiseLevel/FlipPercentage(ϵ) ClassImbalance(r)
Balanced NA 2,4,...,20 2,4,...,10 0.0,0.1,...,1.0 NA
{ } { } { }
Binary-classImbalanced Minority 5 2 0.0,0.1,...,1.0 0.05,0.1,...,0.5
{ } { }
Multi-classImbalanced Minority,Majority 5 5 0.0,0.1,...,1.0 0.02,0.04,...,0.2
{ } { }
Evaluation Metric To access the generalization performance of our approaches fairly,
especially concerning the number of classes M, we propose using a normalized version of
mean absolute error (MAE). Since the MI values range between 0 and lg(M), the MAE will
likewise fall within this same range. The normalizing factor, which is the entropy on Y, is
computed using P ( ) defined in (14) as H (g ,M,r) =
(cid:80)M
P (m) lg(P (m)). For
Y · Y r − m=1 Y · Y
each approach and unique data set configuration (g ,d,M,r,ϵ), we obtain 10 ground truths
r
and estimated MI values, as shown in Figure 4. The ground-truth MI values are represented
as a vector I = (I ,...,I ), and the estimated one as Iˆ = (Iˆ,...,Iˆ ). We use the NMAE
1 10 1 10
metric to evaluate the performance as
 
m NMAE(I,Iˆ ) =
1

1 (cid:88)10
I[j] Iˆ [j]  =
(cid:88)10 |I
j
−Iˆ
j | . (18)
H (g ,M,r) 10 | − | 10 H (g ,M,r)
Y r Y r
j=1 j=1 ·
Implementation Details To generate synthetic data sets using the MVN distribution,
including the ground-truth MI calculation, we implemented a script using the multivar
iate normal and ortho group functions provided by scipy (Virtanen et al., 2020). For
HPO, we used BO implemented by the BayesSearchCV implemented by scikit-optimize
(Head et al., 2021). The detailed and documented code, including the implementation of all
MI estimation approaches and the synthetic data set generation processes, along with the
Python scripts used for experiments, can be found on our GitHub1.
For MI estimation approaches, we utilized two leading AutoML tools, TabPFN and
AutoGluondetailedinSection4toinducetheBayespredictor. Additionally, weincorporated
theimplementationsoffivecalibrationtechniquesfortheCalLog-Lossapproachesprovided
by netcal(Ku¨ppersetal.,2020;Ku¨ppersetal.,2023). WeimplementedtheGMMapproach
using the InfoSelect implementation, which we extended to incorporate diagonal, spherical,
and tied covariance matrices2 (Polo and Da Silva, 2020). Considering the estimation
1. https://github.com/LeakDetectAI/automl_quant_il_detect
2. https://github.com/felipemaiapolo/infoselect/issues/5
29Gupta, Wever and Hu¨llermeier
challenges faced by both the GMM and the provided InfoSelect implementation with
high-dimensional data sets, the dimensionality reduction technique is implemented when the
data set dimensionality exceeds 100 (d > 100). The architectures and objective function for
MINE approach was implemented using PyTorch (Paszke et al., 2019), while the multi-layer
perceptron (MLP) architectures including the categorical cross-entropy (CCE) loss for the
PC-Softmax approach was implemented using Keras (Chollet et al., 2015).
5.3 Results
In this section, we provide a comprehensive analysis of our results on MI estimation
approaches using MVN synthetic data sets, as detailed in Table 1. We discuss the overall
performance of various approaches on system data sets generated with perturbation and
proximity techniques in Section 5.3.1. We assess the generalization of top-performing
approaches using AutoGluon and TabPFN including the baselines across various factors,
including the number of classes (M), input dimensions (d), class imbalance (r), and noise
levels (ϵ) in Section 5.3.2. For a complete overview of generalization capabilities across all
techniques, please refer to Appendix C.2.
5.3.1 Overall Results
InFigure5, wepresentacomprehensiveanalysisofvariousMIestimationapproachesapplied
to data sets generated using the MVN distribution to simulate synthetic systems. We use
bar charts to illustrate the mean and standard error (SE) of the NMAE on both MVN
perturbation and proximity synthetic data sets. Our analysis covers different data set types
generated by synthetic systems, including balanced, binary-imbalanced, and multi-class
imbalanced data sets, as detailed in Table 1. For systems generating a balanced data
set, we examine two scenarios involving vulnerable synthetic systems: one with no noise
and another with a 50% noise level. Additionally, considering the critical importance of
accurate MI estimation on non-vulnerable systems (ϵ = 1.0) for the precise prediction of
the existence of IL by the respective information leakage detection (ILD) approaches, we
include non-vulnerable systems in our analysis.
5.3.1.1 MVN Perturbation Data Sets In Figure 5a, we delve into the performance
insights of MI estimation approaches applied to synthetic data sets generated using the
MVN perturbation technique. In cases where systems generate balanced classification data
sets, we observe that the Log-Loss estimation method, using TabPFN in combination with
suitable calibration techniques (Cal Log-Loss), stands out as a top performer. Especially,
TabPFN IR Cal Log-Loss exhibits exceptional performance, with an impressively low
mean NMAE (approximately 0.0026 for ϵ = 0.0, 0.0056 for ϵ = 1.0) with low variation,
with SE being approximately 0.0008 for ϵ = 0.0 and 0.0006 for ϵ = 1.0. While in the case
of a vulnerable system with noise ϵ = 5.0, TabPFN IR Cal Log-Loss performs worse
with NMAE approximately 0.2115 and SE being 0.0124. In this case, TabPFN PS Cal
Log-Loss and Beta Cal Log-Loss perform very well with NMAE at approximately
0.0666 and SE being 0.0032. However, it is worth noting that, overall, the use of the HB
Cal Log-Loss method with both AutoML approaches does not yield substantial benefits,
except in cases where it is paired with AutoGluon for estimating MI in non-vulnerable
systems generating balanced data set.
30Vulnerable (cid:15)=0.0 Vulnerable (cid:15)=0.5 Non-vulnerable (cid:15)=1.0
1.0
0.8
0.6
0.4
0.2
0.0
Binary-class Imbalanced Multi-class Imbalanced
1.0
0.8
0.6
0.4
0.2
0.0
(a) Performance on MVN perturbation synthetic data sets
MI Estimation Technique
Vulnerable (cid:15)=0.0 Vulnerable (cid:15)=0.5 Non-vulnerable (cid:15)=1.0
Auto1G.0luon Mid-Point AutoGluon HB Cal Log-Loss TabPFN TS Cal Log-Loss
AutoGluon Log-Loss TabPFN Mid-Point TabPFN HB Cal Log-Loss
0.8
AutoGluon PS Cal Log-Loss TabPFN Log-Loss GMM Baseline
Auto0G.6luon IR Cal Log-Loss TabPFN PS Cal Log-Loss MINE Baseline
AutoGluon Beta Cal Log-Loss TabPFN IR Cal Log-Loss PC-Softmax Baseline
Auto0G.4luon TS Cal Log-Loss TabPFN Beta Cal Log-Loss
0.2
0.0
Binary-class Imbalanced Multi-class Imbalanced
1.0
0.8
0.6
0.4
0.2
0.0
MI Estimation Technique
AutoGluon Mid-Point AutoGluon HB Cal Log-Loss TabPFN TS Cal Log-Loss
AutoGluon Log-Loss TabPFN Mid-Point TabPFN HB Cal Log-Loss
AutoGluon PS Cal Log-Loss TabPFN Log-Loss GMM Baseline
AutoGluon IR Cal Log-Loss TabPFN PS Cal Log-Loss MINE Baseline
AutoGluon Beta Cal Log-Loss TabPFN IR Cal Log-Loss PC-Softmax Baseline
AutoGluon TS Cal Log-Loss TabPFN Beta Cal Log-Loss
(b) Performance on MVN proximity synthetic data sets
Figure 5: Overall NMAE of MI estimation approaches on synthetic data set
31
rorrE
etulosbA
naeM
dezilamroN
rorrE
etulosbA
naeM
dezilamroNGupta, Wever and Hu¨llermeier
In the context of systems generating binary-class classification imbalanced data sets,
the GMM baseline emerges as a standout performer, achieving the lowest mean NMAE
(approximately 0.019) and maintaining a low SE (approximately 0.0017). Furthermore,
the Log-Loss and IR Cal Log-Loss approaches using TabPFN also exhibit strong
performance in terms of NMAE, with very low SEs. Conversely, when confronted with
multi-class imbalanced data sets, the IR Cal Log-Loss approach using TabPFN takes the
lead by achieving the lowest mean NMAE (approximately 0.0293) and maintains a low SE
(approximately 0.0013). The GMM baseline also performs well in this context, highlighting
its adaptability in estimating MI within systems generating imbalanced data sets. Overall,
TabPFN models combined with the Cal Log-Loss approach, especially IR Cal Log-Loss,
consistently demonstrate strong performance in estimating MI in the MVN perturbation
system data sets.
5.3.1.2 MVN Proximity Data Sets In Figure 5b, we delve into the performance
insights of MI estimation approaches applied to synthetic data sets generated using the
MVN proximity technique. Notably, we find similar trends in the performance of MI
estimation approaches compared to the baselines as on the MVN perturbation system data
sets. Once again, the Log-Loss estimation method, coupled with TabPFN and appropriate
calibration techniques (Cal Log-Loss), excels in scenarios involving systems generating
balanced classification data sets. Specifically, the TabPFN IR Cal Log-Loss method
exhibits exceptional performance for vulnerable systems with a mean NMAE of 0.0027 for
ϵ = 0.0, 0.0104 for ϵ = 0.5 and a remarkably low SE of 0.0008 for ϵ = 0.0 and 0.0011 for
ϵ = 0.5. In contrast, for non-vulnerable systems, the TabPFN PS Cal Log-Loss and
TabPFN TS Cal Log-Loss approaches deliver the best performance, both recording mean
NMAE of 0.0163. The TabPFN Log-Loss also exhibits strong performance in this context.
Like before, AutoGluon models display larger NMAE values, signifying the superiority
of TabPFN for this scenario. Similar to the perturbation data set, in the case of binary-
class imbalanced data sets, the GMM baseline emerges as the top performer, achieving the
lowest mean NMAE of 0.017. TabPFN IR Cal Log-Loss also showcases commendable
performance with very low SE. In multi-class imbalanced data sets, TabPFN IR Cal Log-
Loss again maintains its superior performance with the lowest mean NMAE of 0.01625. The
GMMbaselinealsodemonstratesstrongperformance, highlightingitsversatilityindelivering
accurate MI estimates across imbalanced synthetic data sets. Overall, TabPFN with Cal
Log-Loss, especially IR Cal Log-Loss, consistently demonstrates strong performance
in estimating MI for MVN perturbation system data sets. In general, AutoGluon models
display higher NMAE values, signifying the superiority of TabPFN models for this scenario.
As mentioned in Section 5.1.3, introducing noise using perturbation techniques makes the
generated data sets more complex. Thus, the overall performance of all the models in
estimating MI within the synthetic data sets generated using the proximity technique is
slightly better than that by using the perturbation technique.
5.3.1.3 Summary In summary, TabPFN, particularly IR Cal Log-Loss, consistently
demonstrates remarkable MI estimation capabilities across a range of scenarios for both
synthetic systems simulated using MVN perturbation and proximity techniques. The GMM
baseline consistently stands out as an outlier, excelling in accurately estimating MI for
imbalanced synthetic data set. Nevertheless, it is worth noting that while AutoGluon
models deliver respectable results, they do not reach the same level of prominence as
32TabPFN within these data sets. In general, we observe that using calibration techniques
(Cal Log-Loss) does not significantly impact the performance for TabPFN Log-Loss,
especially for the balanced synthetic data sets, which suggests that TabPFN produces
well-calibrated class probabilities, which is also observed in Appendix C.2. In contrast,
using appropriate calibration techniques (Cal Log-Loss) mostly significantly improves the
performance of AutoGluon Log-Loss for estimating MI in vulnerable synthetic data sets,
thus hinting at miscalibrated class probabilities returned by the resulting models, which
is also observed in Appendix C.2. The usage of calibration techniques (Cal Log-Loss)
significantly deteriorates the performance of AutoGluon Log-Loss by overestimating the
MI due to overfitting in non-vulnerable systems, which could hamper the ILD performance
of this approach by detecting non-existent ILs and producing false positives.
5.3.2 Generalization Capability Analysis
In this section, we delve into the generalization capabilities of different MI estimation
approaches, focusing on their performance relative to baseline methods. We identify the
best-performing MI estimation approaches using both AutoGluon and TabPFN to assess
their generalization capability. Our selection process is based on a comprehensive analysis
of the overall results presented in Section 5.3.1. Specifically, we calculate mean NMAE
for each data set type, including balanced, binary-class, and multi-class imbalance. For
instance, to select the best performing TabPFN model (out of Mid-Point, Log-Loss, IR
Cal Log-Loss, PS Cal Log-Loss, Beta Cal Log-Loss, TS Cal Log-Loss, and HB
Cal Log-Loss) on balanced data sets, we evaluate the mean NMAE across all experiments
as outlined in Table 1 and then choose the best-performing approach.
We gauge the generalization capability with respect to the number of classes (M) and
input dimensions (d) for a non-vulnerable system and two types of vulnerable synthetic
systems (ϵ = 0.0 and ϵ = 0.5) generating balanced data sets. To assess generalization
with respect to the number of classes, we aggregate the NMAE across all input dimensions
(d 2,4,...,20 ) for each possible number of classes (M 2,4,...,10 ) Similarly, we
∈ { } ∈ { }
assess generalization with respect to the input dimensions by aggregating NMAE across the
number of classes. To assess generalization with respect to class imbalances, we aggregate
the NMAE across different noise levels (ϵ 0.0,0.1,...,1.0 ) for each class imbalance
∈ { }
parameter (r) value, such that r 0.05,0.1,...,0.5 for binary-class imbalanced data
∈ { }
sets and r 0.02,0.04,...,0.2 for multi-class imbalanced data sets. Similarly, we assess
∈ { }
generalization with respect to the noise levels by aggregating NMAE across the class
imbalances.
For a visual representation of our filtered generalization results using a series of line plots,
we refer to Figures 6 and 7 for results on MVN perturbation and MVN proximity data sets
respectively. The best models are selected based on the overall results shown in Figures 5a
and 5b, respectively. In these figures, the Y-axis displays the mean NMAE for MI estimates
obtained by the selected approaches with respect to various factors of system data sets. This
comprehensive analysis allows us to assess the generalization capabilities of our proposed
MI estimation approaches compared to baselines under diverse scenarios of the number of
classes (M), input dimensions (d), class imbalance (r), and noise level (ϵ) (referred to as flip
percentage (ϵ) in case of MVN perturbation data set).
33Gupta, Wever and Hu¨llermeier
Vulnerable (cid:15)=0.0 Vulnerable (cid:15)=0.5 Non-vulnerable (cid:15)=1.0
1.0
0.8
0.6
0.4
0.2
0.0
2 4 6 8 10 2 4 6 8 10 2 4 6 8 10
Classes (M) Classes (M) Classes (M)
1.0
0.8
0.6
0.4
0.2
0.0
4 8 12 16 20 4 8 12 16 20 4 8 12 16 20
Input Dimensions (d) Input Dimensions (d) Input Dimensions (d)
1.0 Binary-class Imbalanced Multi-class Imbalanced
0.8
0.6
0.4
0.2
0.0
0.1 0.2 0.3 0.4 0.5 0.04 0.08 0.12 0.16 0.20
Class Imbalance (r) Class Imbalance (r)
1.0
0.8
0.6
0.4
0.2
0.0
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
Flip Percentage ((cid:15)) Flip Percentage ((cid:15))
MI Estimation Technique
AutoGluon TabPFN GMM Baseline MINE Baseline PC-Softmax Baseline
Figure 6: Generalizability of MI estimation approaches on MVN perturbation synthetic data
sets
5.3.2.1 Number of Classes (M) In the top row of Figures 6 and 7, we analyze the
generalization capability of MI estimation methods across data sets with varying numbers
of classes (M). These figures pertain to results on MVN perturbation and MVN proximity
data sets, respectively, with the X-axis ranging from 2 to 10, representing the number of
classes.
Vulnerable Systems In vulnerable systems, AutoGluon and TabPFN consistently
exhibit high MI estimation accuracy (lower mean NMAE), with increasing the number of
classes. Overall TabPFN consistently outperforms AutoGluon with AutoGluon showing
notableimprovements,especiallyinsyntheticsystemssimulatedusingperturbationtechnique
34
rorrE
etulosbA
naeM
dezilamroNwith a 50% noise level (ϵ = 0.5). In the case of the GMM baseline, the MI estimation
accuracy sometimes improves (mean NMAE decreases) for vulnerable systems, especially
for multi-class balanced synthetic data sets (classes more than 2). This observation can be
attributed to the loss of information due to aggregation. Since the number of classes (M) in
vulnerable synthetic data sets increases, the precision of the MI estimation by GMM baseline
tends to degrade, as illustrated in Figures 12 and 13. In contrast, the performance of MINE
and PC-Softmax baselines declines as the number of classes increases, with MINE being
the least accurate, also illustrated in Figures 12 and 13.
Non-vulnerable Systems Similar to vulnerable systems, both AutoGluon and TabPFN
consistently demonstrate improved MI estimation (lower mean NMAE) with increasing the
number of classes. AutoGluon shows more significant improvements, especially for multi-
class balanced synthetic data sets (classes more than 2). TabPFN consistently outperforms
AutoGluonfornon-vulnerablesystems. Incontrast, theperformanceofbaselinesdeteriorates
asthenumberofclassesincreases,especiallyfortheGMMbaselineinthecaseofperturbation
non-vulnerable system data sets. As an exception to estimating MI in vulnerable systems,
MINE and PC-Softmax baselines perform better than GMM, particularly for perturbation
system data sets.
5.3.2.2 Input Dimensions (d) In the second row of Figures 6 and 7, we analyze the
generalization capability of MI estimation methods across data sets with varying input
dimensions (d). These figures pertain to results on MVN perturbation and MVN proxim-
ity data sets, respectively, with the X-axis ranging from 2 to 20, representing the input
dimensions.
Vulnerable Systems Notably, both AutoGluon and TabPFN consistently exhibit high
MI estimation accuracy (lower mean NMAE) as input dimensions increase from 2 to 20.
Overall TabPFN outperforms AutoGluon with AutoGluon showing notable improvements,
especiallyinsyntheticsystemssimulatedusingperturbationtechniquewitha50%noiselevel
(ϵ = 0.5). The GMM baseline shows significant deterioration in performance with increasing
input dimensions (especially from 10 to 20), specifically for MVN proximity system data
sets. While MINE and PC-Softmax baselines also show deterioration in performance most
of the time with increasing input dimensions, this becomes significant, especially beyond 10,
also illustrated in Figures 12 and 13. These findings conclude that even using deep MLPs for
MI estimation approaches sometimes does not work for high-dimensional system data sets.
Non-vulnerable Systems Similar to vulnerable systems, both AutoGluon and TabPFN
exhibit improved MI estimation accuracy (lower mean NMAE) as input dimensions increase
from 2 to 20, with TabPFN outperforming AutoGluon and AutoGluon exhibiting more
significant improvements. Again, the GMM baseline shows significant deterioration in
performance with increasing input dimensions (especially from 10 to 20), specifically for
MVNperturbationdatasets. WhileMINEandPC-Softmaxbaselinesconsistentlyperform
well with increasing input dimensions for MVN perturbation data sets, their performance
deteriorates in the case of MVN proximity data sets.
5.3.2.3 Class Imbalance (r) In the third row of Figures 6 and 7, we analyze the
generalization capability of MI estimation methods across data sets with different levels
of class imbalance (r). These figures pertain to results on MVN perturbation and MVN
proximity data sets, respectively, with the X-axis ranging from 0.05 to 0.5 for binary-class
35Gupta, Wever and Hu¨llermeier
Vulnerable (cid:15)=0.0 Vulnerable (cid:15)=0.5 Non-vulnerable (cid:15)=1.0
1.0
0.8
0.6
0.4
0.2
0.0
2 4 6 8 10 2 4 6 8 10 2 4 6 8 10
Classes (M) Classes (M) Classes (M)
1.0
0.8
0.6
0.4
0.2
0.0
4 8 12 16 20 4 8 12 16 20 4 8 12 16 20
Input Dimensions (d) Input Dimensions (d) Input Dimensions (d)
1.0 Binary-class Imbalanced Multi-class Imbalanced
0.8
0.6
0.4
0.2
0.0
0.1 0.2 0.3 0.4 0.5 0.04 0.08 0.12 0.16 0.20
Class Imbalance (r) Class Imbalance (r)
1.0
0.8
0.6
0.4
0.2
0.0
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
Noise Level ((cid:15)) Noise Level ((cid:15))
MI Estimation Technique
AutoGluon TabPFN GMM Baseline MINE Baseline PC-Softmax Baseline
Figure 7: Generalizability of MI estimation approaches on MVN proximity synthetic data
sets
imbalanced data sets and from 0.02 to 0.2 for multi-class imbalanced data sets, representing
the degree of class imbalance.
Binary-class Imbalanced In the systems generating imbalanced binary-class data set,
TabPFNandGMMconsistentlyexhibithighMIestimationaccuracyastheclassimbalancein
thesyntheticdatasetsdecreasesfrom0.0to0.5. Notably, theGMMbaselineexhibitsaslight
advantage over TabPFN, particularly in MVN perturbation synthetic data set. In contrast,
theperformanceofAutoGluontendstodeteriorateasclassimbalancedecreasesinmostcases.
Moreover, MINE and PC-Softmax baselines also exhibit performance deterioration, with
the decline becoming particularly significant beyond a class imbalance of 0.25, especially in
36
rorrE
etulosbA
naeM
dezilamroNMVNperturbationsyntheticdataset. TheseintriguingobservationssuggestthatAutoGluon,
MINE, and PC-Softmax surprisingly perform better on imbalanced binary-class synthetic
data sets. However, it’s essential to note that they still underperform compared to TabPFN
and GMM.
Multi-class Imbalanced TabPFN and GMM continue to display high MI estimation
accuracy as the class imbalance in the synthetic data sets decreases (0.0 to 0.2). In this
scenario, TabPFN shows a slight advantage over the GMM baseline, especially in MVN
perturbation synthetic data set. Surprisingly, the performance of AutoGluon also improves
inmostcasesasclassimbalancedecreases. Ontheotherhand, theperformanceofMINEand
PC-Softmax baselines remains relatively consistent, with only a noticeable performance
dropoccurringataclassimbalanceof0.04. Theseintriguingfindingscontrasttheobservations
for systems generating imbalanced binary-class synthetic data sets, highlighting the different
behavior of AutoGluon, MINE, and PC-Softmax in handling imbalanced multi-class
synthetic data sets.
5.3.2.4 Noise Level (ϵ) In the last row of Figures 6 and 7, we analyze the generalization
capability of MI estimation methods across data sets with varying noise level (ϵ) in both
binary-class and multi-class imbalanced scenarios. These figures pertain to results on MVN
perturbation and MVN proximity data sets, respectively, with the X-axis ranging from 0.0
to 1.0, representing the noise level.
Binary-class Imbalanced In the systems generating imbalanced binary-class data
set, TabPFN and GMM baseline demonstrated high MI estimation accuracy consistently as
the noise level in the synthetic data sets increased (0.0 to 1.0). The GMM baseline shows
a slight advantage over the TabPFN, especially in MVN perturbation synthetic data set.
In contrast, the performance of AutoGluon tends to deteriorate as the noise level in the
synthetic data sets increases. On the other hand, both MINE and PC-Softmax baselines
exhibited significant improvements in performance with increasing noise levels in the system
data sets. The findings suggest that TabPFN and GMM baseline are reliable options for
estimating MI for systems generating noisy imbalanced binary-class synthetic data sets.
Multi-class Imbalanced TabPFN and GMM continue to maintain high MI estimation
accuracy as the noise level in the synthetic data sets increases (0.0 to 1.0). In this scenario,
TabPFN showed a slight advantage over the GMM baseline, especially in MVN perturbation
synthetic data set. The performance of AutoGluon continued deteriorating with increasing
noiselevelsinthesyntheticdataset. MINEandPC-Softmaxbaselinescontinuedtoexhibit
significant improvements with increasing noise levels in the synthetic data set. These findings
highlight the robustness of TabPFN and GMM in estimating MI for systems generating
noisy imbalanced multi-class synthetic data sets.
5.3.2.5 Summary In this section, we summarize the key takeaways regarding the
generalization capabilities of the chosen approaches for balanced and imbalanced synthetic
data sets. These findings consistently apply to the MVN perturbation and proximity
synthetic data set.
Influence of Number of Classes (M) and Input Dimensions (d)Ourperformance
analysis using NMAE, across various numbers of classes (M) and input dimensions (d),
consistently demonstrates strong generalization capabilities for TabPFN and AutoGluon.
In contrast, the baselines display diminished generalization capability, as the performance
consistentlydeteriorateswhenthenumberofclassesandinputdimensionsincreases. Notably,
37Gupta, Wever and Hu¨llermeier
GMM encounters significant challenges when dealing with high-dimensional synthetic data
sets, resulting in substantial performance degradation beyond 10 input dimensions, aligning
with the well-known limitations of GMM in high-dimensional spaces. Furthermore, MINE
demonstrates the lowest generalization capability concerning the number of classes and
input dimensions, which suggests that it may not be well-suited for estimating MI between
multi-dimensional inputs and one-dimensional outputs in classification synthetic data sets.
A comprehensive analysis of the generalization capabilities of all approaches, considering
both the number of classes (M) and input dimensions (d), without aggregating results across
either dimension, is provided in Appendix C.2.1.
Influence of Class Imbalance (r) and Noise (ϵ) Our performance analysis across
various class imbalances (r) and noise levels (ϵ) in imbalanced synthetic data sets highlights
the robust generalization capabilities of TabPFN and GMM. Notably, the strong gener-
alization capability of GMM can be attributed to the low dimensionality (d = 5) of the
imbalanced synthetic data set. This characteristic suggests that GMM primarily struggles
with estimating MI in high-dimensional synthetic data sets, remaining largely unaffected
by noise and class imbalance. In contrast, AutoGluon, MINE, and PC-Softmax baselines
did not exhibit strong generalization capabilities concerning variations in class imbalance
(r) and noise levels (ϵ) within the imbalanced synthetic data set. A comprehensive analysis
of the generalization capabilities of all approaches, considering both the class imbalance
(r) and noise levels (ϵ), without aggregating results across either dimension, is provided
in Appendix C.2.2.
Conclusion TabPFN based approaches consistently demonstrates remarkable general-
ization capabilities in estimating MI across various factors for both MVN perturbation and
proximity data sets.
6 Information Leakage Detection Approaches
In this section, we outline the information leakage detection (ILD) process in a given system,
as depicted in Figure 8b, and present various approaches, including baseline methods, shown
in Figure 8a. As discussed in Section 2, detecting information leakage (IL) in a system
involves leveraging mutual information (MI) and approximating the predictive performance
of Bayes predictor on the system data set . Consequently, we partition our ILD approaches
D
into two parts: one based on MI, and the other centered on classification, explained
inSections6.2and6.3respectively. TheMI-basedapproachemploysone-samplet-test(OTT)
on MI estimates, obtained through various techniques, including Log-Loss, Mid-Point,
and baseline approaches, detailed in Section 3. For the classification-based approach, we
introduce two methodologies from our prior work (Gupta et al., 2022), employing Fisher’s
exact test (FET) and paired t-test (PTT) to assess classifier performance in detecting ILs.
We recommend using automated machine learning (AutoML) tools, specifically AutoGluon
and TabPFN, for ILD, as outlined in Section 4. To enhance IL detection confidence, we
propose applying Holm-Bonferroni correction on p-values acquired from top-10 performing
AutoML pipelines or models obtained through hyperparameter optimization (HPO), as
described in Section 6.4.
386.1 IL Detection Process
The IL detection process begins with the acquisition of accurate MI or Bayes predictor
performance estimates obtained from the models. This is achieved using nested K-fold cross-
validation (KFCV) coupled with HPO. The objective functions employed for HPO include
balanced error-rate (BER) for PC-Softmax, AutoGluon, and TabPFN, Akaike information
criterion (AIC) for Gaussian mixture model (GMM), and mean squared error (MSE) for
mutual information neural estimation (MINE) with specific parameter ranges provided
in Table 4. The process begins by partitioning the data set generated by the system
D
into a training data set (90% of instances) and a test data set (10% of instances). We
conduct HPO for 100 function evaluations using Monte Carlo cross-validation (MCCV)
employing 3 splits on the training data set. Each split reserves 30% of the training data
for validation, enabling an effective performance assessment of current parameter values.
Refer to Table 4 for the hyperparameters and their corresponding ranges for the approaches.
This process is annotated as “N10F-3SCV” signifying the use of KFCV with K = 10 (10F)
for evaluation and 3S MCCV splits for HPO using nested cross-validation, as depicted
in Figure 8a. Subsequently, we identify the top-performing models using HPO. In the
case of AutoGluon, the tool is executed for a fixed duration of 1800 seconds on to select
D
the best-performing pipelines. KFCV is then applied to the top-10 performing models or
pipelines (J = 10), generating K = 10 estimates from each, using the complete system data
set , as depicted in Figure 8b.
D
The next crucial step involves assessing p-values, derived from appropriate statistical
testsappliedtotheK = 10estimatesforeachofthetop-10performingmodelsorpipelinesto
determine the presence of IL within the system, as depicted in Figure 8b. To compute these
p-values,theOTTisutilizedonthe10MIestimatesofj-thbest-performingmodelorpipeline
(denoted as
Iˆ
), as elaborated in Section 6.2. Additionally, the PTT is employed to compare
j
theaccuraciesofthej-thbest-performingAutoMLpipeline(denotedasa )withthoseofthe
j
marginal Bayes predictor accuracies (denoted by a ), as detailed in Section 6.3.1. We also
mc
apply FET on the confusion matrices of AutoML pipelines (denoted as = Mk K ),
Mj { j }k=1
and the results are then aggregated using both the mean and median operators, as detailed
in Section 6.3.2.
To enhance the confidence in the IL detection decision, multiple p-values obtained
from top-10 performing AutoML pipelines or models through HPO using Holm-Bonferroni
correction, as described in Section 6.4. Based on our prior work (Gupta et al., 2022), we
J
concluded that setting the rejection threshold equal to , on the cut-off parameter τ
⌊2⌋
provides a robust and accurate IL detection in a system. In this context, we aggregate
J = 10 p-values using the Holm-Bonferroni correction by using the condition τ 5 to
≥
deduce the occurrence of IL in the system. In summary, the ILD process involves rigorous
estimation, statistical assessment, and the use of correction techniques to confidently detect
the presence of IL within a given system.
6.2 MI-based Approach
In this section, we will describe the process of applying OTT on the MI estimates obtained
through Log-Loss and Mid-Point, including the state-of-the-art techniques to perform
39Gupta, Wever and Hu¨llermeier
N10F-3SCV
BASELINE One-Sample
Estimated MIs BASELINE
MI Estimator t-test
One-Sample
Mid-Point MIs MID-POINT
t-test
System
Data
One-Sample
Log-Loss MIs LOG-LOSS
t-test
One-Sample
AutoGluon Calibrated Log- CAL LOG-LOSS
t-test
TabPFN Loss MI
Accuracies
Paired t-test PTT-MAJORITY
&
Mean FET-MEAN
Confusion Fisher's Exact
Matrices Test
Median FET-MEDIAN
(a) Calculation of p-value by different ILD approaches
System Base Leakage Hyperparameter Top 10 Best p-value
Data Detector Optimization Models Calculation
10 p-values
Holm-
Check if
Bonferroni Leakage Decision
Correction
(b) Information leakage (IL) detection process
Figure 8: Procedure of using ILD approaches to detect ILs in a system generating
D
ILD in a given system. These approaches are built upon the condition for the existence of
IL in a system, as discussed in Section 2.3. According to information theory, IL occurs in a
system if the MI between system input and output is significantly greater than 0. To ensure
precise estimation of MI using Log-Loss and Mid-Point techniques, we suggest utilizing
AutoML tools, specifically AutoGluon and TabPFN, described in Section 4.
One-Sample T-Test Based Approach The one-sample t-test (OTT) is a statistical
test used to determine if the mean of a sample differs significantly from a known or
40hypothesized population mean (Demˇsar, 2006). In the context of detecting IL in the system
using MI estimates, we apply this test to evaluate whether the MI values obtained from the
system significantly deviate from the expected or null hypothesis values, in this case being
0. To deduce the presence of IL in a system, using the OTT, we start by considering the
null hypothesis (H
(Iˆ
0)) and the alternative hypothesis (H
(Iˆ
0)). In this case, the
0 j 0 j
∼ ≫
null hypothesis (H ) would state that the MI for the system is approximately equal to the
0
expected mean (≊ 0), indicating no IL. Conversely, the alternative hypothesis (H ) suggests
1
that there is a significant deviation from the expected mean ( 0), implying the presence of
≫
IL. We collect 10 MI estimates from the system using KFCV for K = 10, which are treated
as sample data points and denote them by the vector Iˆ = (Iˆ,...,Iˆ ). Next, we collect the
j 1 10
samplemean(µ )andthestandarddeviation(σ )oftheseMIestimates. Thesamplemean
Iˆ
j
Iˆ
j
is an estimate of the population mean, while the sample standard deviation measures the
variability within our sample. The t-statistic quantifying the amount of standard error (SE)
the sample mean is away from the expected population mean under the null hypothesis
µ Iˆ −µ 0
is calculated as t = σ Iˆjj /√ K, where µ 0 = 0.0 is the expected population mean under the
null hypothesis and K is the number of MI estimates in the sample (in this case, 10). We
then consult the t-distribution with K 1 degrees of freedom and calculate the p-value
−
associated with our calculated t-statistic. The p-value represents the probability of observing
a sample mean as extreme as the 0, we obtained if the null hypothesis is true. If the p-value
is sufficiently small (typically below a predefined significance level, e.g., α = 0.01), we reject
the null hypothesis (H ), indicating that there is evidence of IL in the system. Conversely,
0
if the p-value is not sufficiently small, we fail to reject the null hypothesis, suggesting no
significant evidence of IL. In summary, the OTT is applied to the MI estimates to assess
whethertheydeviatesignificantlyfromtheexpectedpopulationmeanof0todetectpotential
IL in the system.
6.3 Classification-based Approach
In this section, we will describe two ILD methodologies introduced in our prior work (Gupta
et al., 2022). These approaches are built upon the condition for the occurrence of IL in a
system, as discussed in Section 2.3. According to statistical learning theory, IL occurs in a
system if the accuracy of Bayes predictor significantly surpasses that of a marginal Bayes
predictor. For accurate Bayes predictor estimation, we propose using advanced AutoML
tools, specifically AutoGluon and TabPFN discussed in Section 4 to estimate the empirical
risk minimizer g in (5). This marks a departure from our prior work (Gupta et al., 2022),
where an arbitrary, predefined set of classifiers are proposed for estimating Bayes predictor.
6.3.1 Paired T-Test Based Approach
Our first approach is based on using PTT between the accuracy estimates of marginal Bayes
predictor and AutoML pipelines, approximating the performance of Bayes predictor, and
we refer to this approach as PTT-Majority (Gupta et al., 2022). The performance of the
marginal Bayes predictor gmc in (7) is estimated using the gmc described in Section 3.2.2
p
and Bayes predictor in (6) by empirical risk minimizer g defined in (5). We propose using
the PTT between the K = 10 accuracy estimates obtained through KFCV for the j-th best-
41Gupta, Wever and Hu¨llermeier
performing AutoML pipeline estimating g and of gmc denoted by a and a , respectively.
p j mc
These paired tests assess the probability (or p-value) of observing a statistically significant
difference between the paired samples, i.e., accuracies of gmc and g (or (Demˇsar, 2006).
p p
The p-value represents the probability of obtaining test results (mean of the accuracy
differences) as extreme as the observation, assuming the null hypothesis H ( ) holds (Demˇsar,
0
·
2006). The null hypothesis defined as H (a ≊ a ) suggests that the accuracies are drawn
0 mc j
from the same distribution or that the average difference between paired samples from
the two populations is nearly zero (≊ 0), implying there is no difference in performance
(Demˇsar,2006). Outofcommonlyusedpairedstatisticaltests, wechoosetousethecorrected
version of PTT proposed by Nadeau (2003), which accounts for the dependency between
the accuracy estimates due to conducting a KFCV. However, PTT has limitations as it
assumes asymptotic behavior and that the samples (differences in accuracy) follow a normal
distribution, which can lead to overly optimistic p-values. Moreover, this approach relies
on accuracy, which can be misleading for imbalanced classification data sets (Powers, 2011;
Picek et al., 2018).
6.3.2 Fisher’s Exact Test Based Approach
To address the class imbalance in system data sets and inaccurate p-value estimation, we
suggest using FET on the evaluated K confusion matrices (using KFCV) to detect IL. IL is
likely to occur if a sufficiently strong correlation exists between inputs x and outputs y in
the given system data set . The prediction produced by the AutoML pipeline, yˆ= g(x) is
D
viewed as a single point, encapsulating all the information in input x. If a correlation exists,
yˆ will contain input information relevant for predicting the correct outputs (m ,m ). We
tp tn
can identify IL by assessing the dependency between predictions yˆ and ground truths y by
applying the FET on the confusion matrix.
FET is a non-parametric test used to determine the probability of independence (or
non-dependence) between two classification methods, in this case, classifying instances based
on ground truths y and classifying them based on AutoML predictions yˆ (Fisher, 1922).
The null hypothesis H (P(y,yˆ M) = P(y M) P(yˆ M)) posits that model predictions
0
| | · |
yˆ and ground-truth class labels y are independent, indicating the potential absence of
IL. Conversely, the alternative hypothesis H (P(y,yˆ M) = P(y M) P(yˆ M)) suggests
1
| ̸ | · |
that model predictions yˆare significantly dependent on ground-truth class labels y, implying
thepresenceofIL. FETofferstheadvantageofcalculatingp-valuesusingthehypergeometric
distribution exactly rather than relying on approximations that only become exact as the
sample size approaches infinity, as is the case with many other statistical tests. Additionally,
thisapproachdirectlyteststhelearnabilityoflearnedclassifiergwithoutconsideringmarginal
Bayespredictorandisindirectlyrelatedtothemathewscorrelationcoefficient(MCC),defined
in Section 2.2.2.3, which accounts for class imbalance (Camilli, 1995; Chicco et al., 2021).
Using KFCV, we obtain K = 10 confusion matrices = Mk K from the j-th best-
Mj { j }k=1
performing pipeline, yielding 10 p-values after applying FET. Bhattacharya and Habtzghi
(2002) showed that the median of multiple p-values provides the best estimation of the true
p-value. Therefore, to obtain the final p-value, we aggregate them using the median operator
and the arithmetic mean, referring to the approaches by FET-Median and FET-Mean,
receptively.
426.4 Reliability and Robustness: Holm-Bonferroni Correction
To enhance the robustness of our ILD, we use the Holm-Bonferroni correction, which is a
valuable statistical technique that ensures the accuracy and reliability of our ILD framework,
as shown in Figure 8b (Holm, 1979). The motivation behind employing multiple pipeline
(model) estimates, rather than relying on a single one, is twofold. Firstly, it helps to mitigate
the influence of overfitting and noisy estimates that can arise when using just one pipeline
(model). Secondly, the statistical tests we employ are inherently asymmetric, allowing us
only to reject the null hypothesis, effectively demonstrating the presence of IL but not its
absence. To address these challenges and enhance the trustworthiness of our ILD results, we
introduce a set of multiple estimates, fostering greater confidence not to miss present IL and
asserting confidence in the absence of IL if all models (pipelines) fail to detect it.
The Holm-Bonferroni correction serves as our safeguard, effectively controlling the family-
wise error-rate, quantifying the probability of false positives or type-1 errors (Holm, 1979).
By adjusting the rejection criteria α for each hypothesis within our family of null-hypotheses,
denoted as = H ,...,H , where J = 10, we ensure that the significance level for
1 J
F { }
this family does not exceed our predefined threshold by α = 0.01. Our process begins by
independently testing each of the J models (pipelines), which results in J p-values, i.e.,
p ,...,p . These p-values are then sorted in ascending order to make an aggregated decision.
1 J
α
For each hypothesis H , if its associated p-value p is less than , we confidently
j j
∈ F J +1 j
reject that particular null hypothesis. We continue this process until we id−entify the first one,
α
H , for which the p-value no longer justifies rejection, i.e., p > . At this point,
τ+1 τ+1
J τ
the rejected set of hypotheses is represented by = H ,...,H , whi−le the non-rejected
r 1 τ
F { }
set of hypotheses by = H ,...,H .
a τ+1 J
F { }
To determine the condition for the presence of IL in a system, we can set a rejection
threshold on the cut-off parameter of the process (denoted as τ), which corresponds to the
number of rejected hypotheses, denoted as . A higher rejection threshold would help
r
|F |
avoid false positives and prevent the detection of non-existent IL while decreasing it would
avoid missing ILs occurrences and reduce false negatives. Additionally, the cut-off parameter
denoted by τ quantifies the level of confidence in the IL detection within a system. This
systematic and rigorous approach empowers us to detect and characterize IL with a high
degree of confidence, ensuring the robustness of our ILD framework. This rejection threshold
J
was set in our prior work (Gupta et al., 2022), where we concluded that setting it to = 5
⌊2⌋
on the cut-off parameter τ results in robust and accurate detection of IL in a system, and
we continue to use it for this study.
7 ILD Approaches: Empirical Evaluation
In this section, we provide a comprehensive evaluation of information leakage detection
approaches aimed at detecting side-channel leaks (information leakages (ILs)) through
time delays to counter Bleichenbacher attacks on OpenSSL TLS servers. The empirical
setup, along with a description of the IL-Datasets used in our experiments, is detailed
in Section 7.1. Our results, discussed in Section 7.2, conclude that our proposed information
43Gupta, Wever and Hu¨llermeier
leakage detection (ILD) approaches outperform the state-of-the-art in terms of detection
accuracy.
7.1 Experimental Setup
This section outlines our empirical process for all ILD approaches, including the baselines
for detecting timing side-channel leaks in OpenSSL TLS servers, as depicted in Figure 8.
Our main objective is to assess the generalization capability of various ILD approaches, as
discussed in Section 6, across different class imbalances (r 0.1,0.3,0.5 ) in the system
∈ { }
data set using detection accuracy. Additionally, we also asses the generalization capability
of these approaches with respect to the complexity of IL in the system, quantified by the
time delay of the OpenSSL TLS server, please refer to Appendix C.1 for details. To achieve
this, we use multiple IL-Datasets generated by Funke (2022) time delay values ranging from
1 to 256 and class imbalances r 0.1,0.3,0.5 , as described in Table 2.
∈ { }
7.1.1 OpenSSL Timing Data Sets
To validate our approaches in a real-world scenario, we aim to identify critical side-channel
vulnerabilities in cryptographic software. Specifically, we focus on identifying potential
security weaknesses in the information generated via network traffic when using a modified
OpenSSL TLS server. A secure OpenSSL TLS server processing secret cryptographic
messages should not reveal any information about the content of encrypted messages
to external observers. However, Bleichenbacher’s attack exploits inadvertently disclosed
information by the server, particularly whether the decrypted message is correctly formatted
or not (Bleichenbacher, 1998). A secured or non-vulnerable OpenSSL TLS server must
behave identically regardless of whether the incoming message is correctly formatted or
not, releasing the same information in the network traffic. This naturally translates into
the problem of information leakage (IL), where the content of a secret message is exposed
through observable information released via the side-channel of network traffic.
Our prior work explored the use of machine learning (ML) techniques for this application,
while Funke (2022) delved into the possibility of applying their approach to timing side-
channels (Gupta et al., 2022). In a timing side-channel, the observable difference is in
the server’s computation time when processing a message with correct and manipulated
(incorrect) padding. This corresponds to real-life vulnerabilities where error handling
takes significantly longer than processing correctly formatted input, as observed in the
Java TLS implementation with vulnerability CVE-2014-04113 (Meyer et al., 2014). For
our experiments, Funke (2022) provided data sets generated by both vulnerable and non-
vulnerable OpenSSL TLS server implementations, allowing us to simulate systems with
and without IL. The non-vulnerable TLS server implementation (built upon OpenSSL
version 1.0.2l4) lacks detectable timing IL, meaning there is no observable difference in server
processing times between correctly and incorrectly formatted messages (with manipulated
padding) (Funke, 2022). In contrast, the vulnerable TLS server implementation (built upon
3. https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-0411
4. https://www.openssl.org/source/old/1.0.2/
44the DamnVulnerableOpenSSL5) intentionally introduces an artificial delay for processing
incorrectly formatted messages with manipulated padding (Funke, 2022).
There are a total of 10 padding manipulations (with incorrect format), with five of them
resulting in a time delay simulating systems with IL, i.e. z = 1, while the remaining five
exhibit no time delay simulating systems with no IL, i.e., z = 0. The time delay measures
the observable difference in computation time taken by the OpenSSL TLS server for verifying
the messages with correct and incorrect (manipulated) padding. The time delay quantifying
the complexity of the IL in the given system is varied from 1 to 256 µ-seconds to generate
the IL-Datasets. The five padding manipulations for which the time delay is introduced are:
0X00InPkcs#1Padding(First8BytesAfter0X000X02), CorrectlyFormattedPkcs#1PmsMe
ssageBut1ByteShorter, No0X00InMessage, WrongFirstByte(0X00SetTo0X17), and Wron
gSecondByte(0X02SetTo0X17). The five incorrect padding manipulations with no delay
are: 0X00InSomePaddingByte, 0X00OnTheLastPosition(|Pms|=0), 0X00OnTheNextToLas
tPosition(|Pms|=1), CorrectlyFormattedPkcs#1Message(|Pms|=47), and InvalidTls
VersionInPms. Each IL-Dataset , contains 10 binary-class synthetic data sets , each
L D
consisting of negative (class label y = 0) instances corresponding to the correctly formatted
message (CorrectlyformattedPKCS#1PMSmessage) versus the positive (class label y = 1)
instances corresponding to the incorrectly formatted message (with manipulated padding).
Using this, several IL-Datasets were generated for each possible time delay value (3 for
t 1,2,4,8,...,256 and 10 for t 5,10,...,35 in µ-seconds) and class imbalance
∈ { } ∈ { }
r 0.1,0.3,0.5 , as detailed Table 2.
∈ { }
7.1.2 Evaluation Process
To conduct our experiments, we employ each ILD approach depicted in Figure 8a on a set
of IL-Datasets detailed in Table 2. Each ILD approach uses the detection process with a
J
rejection threshold of = 5 on the cut-off parameter τ, as described in Section 6.1. Each
⌊2⌋
IL-Dataset ( = ( ,z ) 10 ) consists of 10 different system data sets, each corresponding
L { Di i }i=1
to a distinct incorrect padding manipulation, as discussed in Section 7.1.1 Specifically, within
an IL-Dataset, five systems contain IL (i.e., z = 1), and five systems do not contain IL
(i.e., z = 0). For each ILD approach, we apply it to individual IL-Datasets, generating
predicted IL decisions denoted by a vector zˆ = (zˆ ,...,zˆ ). These predictions are then
1 10
compared to the corresponding ground-truth vector z = (z ,...,z ) using standard binary
1 10
classification metrics, as defined in Section 2.2.2.3. Specifically, we assess the performance of
ILD approaches using Accuracy (m (zˆ,z)), FPR (m (zˆ,z)) and FNR (m (zˆ,z)).
Acc fpr fnr
Implementation Details The details for implementing the mutual information (MI)
estimation approaches, including the hyperparameter optimization (HPO), are detailed
in Section 5.2. MI-based ILD approaches employ one-sample t-test (OTT) statistical
test on estimated MIs, as discussed in Section 6.2. To implement the state-of-the-art
classification-based ILD approaches, namely PTT-Majority, FET-Mean, and FET-
Median, the Bayes predictor is induced using the TabPFN and AutoGluon automated
machinelearning(AutoML)tools, asdetailedinSection4. Subsequently, thestatisticaltests,
i.e., Fisher’s exact test (FET), paired t-test (PTT), OTT, and Holm-Bonferroni correction,
5. https://github.com/tls-attacker/DamnVulnerableOpenSSL
45Gupta, Wever and Hu¨llermeier
Table 2: Overview of the OpenSSL timing IL-Datasets used for the ILD experiments
TimeDelay
# Folds Imbalancer IL-DatasetLconfiguration DatasetDconfiguration
(inµseconds)
# Systems|L| # z=0 #z=1 |D| # y=0 #y=1 # Features
1 3 0.1 10 5 5 [1916,2090] [1726,1882] [190,208] 124
1 3 0.3 10 5 5 [1232,1344] [863,941] [369,403] 124
1 3 0.5 10 5 5 [1725,1889] [863,941] [850,978] 124
2 3 0.1 10 5 5 [1936,2128] [1744,1916] [192,212] 124
2 3 0.3 10 5 5 [1245,1368] [872,958] [373,410] 124
2 3 0.5 10 5 5 [1727,1929] [872,958] [855,971] 124
4 3 0.1 10 5 5 [2008,2052] [1808,1848] [200,204] 124
4 3 0.3 10 5 5 [1291,1320] [904,924] [387,396] 124
4 3 0.5 10 5 5 [1740,1908] [904,924] [829,984] 124
8 3 0.1 10 5 5 [1886,2044] [1698,1840] [188,204] 124
8 3 0.3 10 5 5 [1212,1314] [849,920] [363,394] 124
8 3 0.5 10 5 5 [1725,1860] [849,920] [842,966] 124
16 3 0.1 10 5 5 [1980,2042] [1782,1838] [198,204] 124
16 3 0.3 10 5 5 [1272,1312] [891,919] [381,393] 124
16 3 0.5 10 5 5 [1734,1872] [891,919] [843,959] 124
32 3 0.1 10 5 5 [2072,2108] [1866,1898] [206,210] 124
32 3 0.3 10 5 5 [1332,1355] [933,949] [399,406] 124
32 3 0.5 10 5 5 [1770,1906] [933,949] [837,973] 124
64 3 0.1 10 5 5 [1986,2128] [1788,1916] [198,212] 124
64 3 0.3 10 5 5 [1277,1368] [894,958] [383,410] 124
64 3 0.5 10 5 5 [1750,1922] [894,958] [832,972] 124
128 3 0.1 10 5 5 [2030,2084] [1828,1876] [202,208] 124
128 3 0.3 10 5 5 [1305,1340] [914,938] [391,402] 124
128 3 0.5 10 5 5 [1782,1904] [914,938] [852,967] 124
256 3 0.1 10 5 5 [1964,1992] [1768,1794] [196,198] 124
256 3 0.3 10 5 5 [1262,1281] [884,897] [378,384] 124
256 3 0.5 10 5 5 [1739,1885] [884,897] [850,989] 124
10 10 0.1 10 5 5 [1962,3942] [1766,3548] [196,394] 124
10 10 0.3 10 5 5 [1261,2910] [883,2037] [378,873] 124
10 10 0.5 10 5 5 [1750,4084] [883,2037] [855,2104] 124
15 10 0.1 10 5 5 [1936,3992] [1744,3594] [192,398] 124
15 10 0.3 10 5 5 [1245,2592] [872,1815] [373,777] 124
15 10 0.5 10 5 5 [1743,3746] [872,1815] [859,1976] 124
20 10 0.1 10 5 5 [2004,3904] [1804,3514] [200,390] [124,154]
20 10 0.3 10 5 5 [1288,2857] [902,2000] [386,857] [124,154]
20 10 0.5 10 5 5 [1746,4065] [902,2000] [826,2065] [124,154]
25 10 0.1 10 5 5 [1924,3900] [1732,3510] [192,390] 124
25 10 0.3 10 5 5 [1237,2705] [866,1894] [371,811] 124
25 10 0.5 10 5 5 [1721,3794] [866,1894] [855,1928] 124
30 10 0.1 10 5 5 [1982,3990] [1784,3592] [198,398] 124
30 10 0.3 10 5 5 [1274,2574] [892,1802] [382,772] 124
30 10 0.5 10 5 5 [1750,3673] [892,1802] [841,1877] 124
35 10 0.1 10 5 5 [1992,3990] [1794,3592] [198,398] 124
35 10 0.3 10 5 5 [1281,2611] [897,1828] [384,783] 124
35 10 0.5 10 5 5 [1755,3718] [897,1828] [858,1923] 124
are implemented using the scipy (Virtanen et al., 2020). The generated 10 IL-Datasets
corresponding to each time delay is converted into a multi-class classification data set
containing 11 padding classes, including messages with the correct padding (labeled as 0)
with network traffic input information, are uploaded on OpenML6 designed by Vanschoren
etal.(2014)usingtheopenml(Feureretal.,2021). Thedetaileddocumentedcodecontaining
the implementation of all ILD approaches, the parser for OpenML real IL-Datasets with the
scripts used for running the experiments is accessible on our GitHub1.
6. https://www.openml.org/s/383
467.2 Detection Accuracy on OpenSSL Timing Data Sets
In this section, we comprehensively analyze various ILD approaches’ performance under
different conditions. These conditions include varying levels of data set imbalance and time
delay. We focus on OpenSSL systems with short time delays ( 25 µ-seconds), which are
≤
associatedwithcomplexILsthatarechallengingtodetect. Additionally, weconsidersystems
with large time delays ( 25 µ-seconds), where detection is relatively simple. Furthermore,
≥
we examine IL-Datasets with imbalanced binary classification data sets, featuring class
imbalances (r 0.1,0.3), as well as balanced data sets (r = 0.5). These factors are crucial
∈
in understanding how different approaches perform based on class imbalance in the system
data set and the complexity of the IL patterns.
To evaluate the performance of ILD approaches, we present the mean detection accuracy
with standard error (SE) for each method across different IL-Datasets, employing a rejection
threshold of 5 on the cut-off parameter τ, as depicted in Figure 9. For a more detailed
analysis of ILD approaches’ generalization capability in terms of Accuracy, FPR, and FNR
concerning IL complexity, we refer to Appendix C.1.
Selected ILD Approaches To identify the best-performing calibration approach for
both TabPFN and AutoGluon using Log-Loss estimation, we assessed their normalized
mean absolute error (NMAE) obtained from all experiments detailed in Section 5.2. This
evaluation involved analyzing the performance of all binary-class synthetic data sets to
determine the optimal calibration approach for each AutoML tool. This selection process
was conducted separately for balanced (r = 0.5) and imbalanced (r 0.1,0.3 ) binary-
∈ { }
class IL-Datasets, utilizing the respective results obtained from balanced and imbalanced
binary-class synthetic systems.
Based on this evaluation, we found that AutoGluon TS Cal Log-Loss is the most
effective technique for both balanced and imbalanced binary-class data sets. In contrast, for
imbalanced data sets, TabPFN IR Cal Log-Loss performed the best, while TabPFN PS
Cal Log-Loss showed top performance in handling balanced data sets. It is worth noting
that the choice of the calibration approach depends on the specific characteristics of the
system data set. In previous research, we observed that FET-Median and FET-Mean
J
yield similar detection accuracies when a rejection threshold of = 5 is applied to the
⌊2⌋
cut-off parameter τ. Additionally, the study by Bhattacharya and Habtzghi (2002) has
highlighted the robustness of the median aggregation operator in estimating the true p-value.
As a result, we have opted to present the detection accuracy achieved with FET-Median
in this section.
7.2.1 Imbalanced Data Sets
Our initial experiments focus on systems generating imbalanced data sets (r = 0.1 and
r = 0.3) with short time delay ( 25 µ-seconds) and long time delay ( 25 µ-seconds).
≤ ≥
Short Time Delay Detecting ILs in this context proves to be especially challenging, as
most ILD approaches struggle to identify ILs efficiently. Notably, TabPFN Cal Log-Loss
approach consistently exhibits high detection accuracy, with AutoGluon FET-Median also
performing competently. For instance, TabPFN Cal Log-Loss achieves a mean accuracy
of approximately 69% for r = 0.1 and 58% for r = 0.3, while AutoGluon FET-Median
47Gupta, Wever and Hu¨llermeier
detects around 54% and 58% of ILs, respectively. This underscores the fact that TabPFN
is capable of more accurateMI estimation than AutoGluon, and highlights the inaccuracies
in MI estimation via the Mid-Point approach, as discussed in Section 5.3.1. However,
detecting ILs in imbalanced data sets with short time delay remained challenging due to
missed IL and a high false positive rate, as detailed in Appendix C.1.
ILD with Rejection Threshold = 5, τ 5
≥
Time Delay 25 µ-seconds
≤
Class Imbalance Class Imbalance
r =0.1 r =0.3 Balanced
1.0
0.9
0.8
0.7
0.6
0.5
Time Delay 25 µ-seconds
1.0 ≥
0.9
0.8
0.7
0.6
0.5
Detection Technique
AutoGluon Mid-Point AutoGluon FET-Median TabPFN FET-Mean
AutoGluon Log-Loss TabPFN Mid-Point TabPFN FET-Median
AutoGluon Cal Log-Loss TabPFN Log-Loss GMM Baseline
AutoGluon PTT-Majority TabPFN Cal Log-Loss MINE Baseline
AutoGluon FET-Mean TabPFN PTT-Majority PC-Softmax Baseline
Figure9: DetectionaccuracyofILDapproachesindetectingtimingside-channelsinOpenSSL
TLS servers
Long Time Delay Detecting ILs in systems with imbalanced data sets and longer
time delay ( 25 µ-seconds) becomes more manageable. Across both imbalance levels
≥
(r = 0.1 and r = 0.3), it is evident that several approaches consistently perform well with
detection accuracy scores significantly above 50%. In particular, the TabPFN Cal Log-
Loss approach stood out as one of the top-performing methods, detecting approximately
94% of the ILs. Additionally, AutoGluon FET-Median excelled, detecting over 92% of the
ILs for r = 0.3 and approximately 72% for r = 0.1. Interestingly, FET based approaches
perform better than PTT-Majority in detecting ILs in imbalanced synthetic data sets,
confirming our prior work findings (Gupta et al., 2022).
48
ycaruccA
noitceteD7.2.2 Balanced Data Sets
Our second set of experiments focuses on systems generating balanced data sets (r = 0.1
and r = 0.3) with short time delay ( 25 µ-seconds) and long time delay ( 25 µ-seconds).
≤ ≥
Short Time Delay Detecting ILs in systems generating balanced data sets (r = 0.5)
with short time delay ( 25 µ-seconds) remains challenging, though somewhat easier than
≤
in imbalanced data sets. AutoGluon Log-Loss and Cal Log-Loss approaches outperform
other ILD methods, detecting a significant proportion of the ILs (approximately 68%).
Surprisingly, the usage of PS Cal Log-Loss does not improve the detection performance
of TabPFN, while we observed that IR Cal Log-Loss enhances the detection accuracy
of Log-Loss to 67%, making it a competent approach in this context. It is worth noting
that, in contrast to imbalanced data sets, AutoGluon Mid-Point demonstrates improved
performance (approximately 64% accuracy) for balanced data sets with a short time delay.
The ILD approaches using AutoGluon perform better than TabPFN. PTT-Majority
approach outperform FET based ones by detecting more than 61% of ILs using both
AutoML tools.
Long Time Delay In systems with balanced data sets (r = 0.5) and longer time delay
( 25 µ-seconds), detecting ILs becomes straightforward. Out of the MI-based approaches,
≥
AutoGluon Mid-Point and TabPFN IR Cal Log-Loss consistently outperforms other
methods, detecting the majority (around 99%) of the ILs. This confirms that IR Cal
Log-Loss offers an alternative calibration technique for TabPFN Log-Loss that signifi-
cantly improves the detection accuracy. In turn, TabPFN using PS Cal Log-Loss and
Log-Loss approaches only detects 97% of the ILs, implying no improvement using the
selected calibration technique. Also, TabPFN Mid-Point only detects 85% of ILs. Out of
classification-based approaches, PTT-Majority consistently outperforms other methods,
detecting around 99% of the ILs. Conversely, FET-Median detects 96% of ILs using
AutoGluon and only 90% using TabPFN.
7.2.3 Summary
In summary, TabPFN Cal Log-Loss consistently emerges as the top-performing approach
across various conditions, highlighting the importance of calibrating TabPFN Log-Loss for
precise MI estimation, thus improving its detection accuracy for all OpenSSL TLS server
data sets. For balanced data sets, we observed a significant improvement in detection
accuracy by using IR Cal Log-Loss for TabPFN calibration, in contrast to PS Cal
Log-Loss, which was chosen based on results from balanced binary-class system synthetic
data sets. This could be attributed to the fact that calibration has a limited effect in
accurately estimating MI for balanced synthetic data sets, making it challenging to choose
the appropriate calibration technique for ILD, please refer to Appendix C.2.1 for details.
Interestingly, IR Cal Log-Loss also showed a notable enhancement in estimating MI
for imbalanced binary-class system synthetic data sets, making it a suitable calibration
technique for ILD as well, please refer to Figures 15 and 16 for details.
The observed behavior could be attributed to several factors, including feature reduction
techniques due to the large dimensionality of the system data sets (d > 100) and the
scarcity of positive instances due to data set imbalance. Feature reduction techniques were
unnecessary for our MI estimation experiments, as we limited data set dimensionality to
49Gupta, Wever and Hu¨llermeier
less than 20 features. Reducing a significantly large number of input dimensions using
reduction techniques (from 150 to [20,50] features) can introduce noise and uncertainty into
the model, making it more challenging to calibrate probabilities effectively. Additionally,
the limited number of positive test instances (around 20 for r = 0.1 and 37 for r = 0.3 using
K-fold cross-validation (KFCV) (with K = 10) could result in unreliable class probability
estimates. The calibration technique did not significantly improve detection accuracy for
the AutoGluon Log-Loss approach. Our observation in Section 5.3.1 and appendix C.2.1
back the reason behind this behavior, where the usage of calibration techniques mostly leads
to overfitting and overestimating MI in non-vulnerable synthetic data sets, resulting in the
detection of non-existent ILs (false positives). These observations suggest that the choice
and requirement of calibration techniques depends on the underlying system data sets.
Intriguingly, the PTT-Majority approach performs slightly better than FET based
approaches in detecting IL in balanced synthetic data sets, contradicting our prior findings
(Gupta et al., 2022). This suggests that the performance of ILD approaches may vary with
the type of IL pattern in the system data set. All baseline methods are ineffective and
detect only 50% of the ILs, suggesting that they produce random detection decisions; please
refer to Appendix C.1 for details. Our observations indicate that detecting IL is notably
more manageable in systems generating balanced data sets. In these scenarios, TabPFN IR
Cal Log-Loss, and the Mid-Point and PTT-Majority approaches using AutoGluon
consistently demonstrate robust performance.
8 Conclusion
This paper introduced a comprehensive theoretical framework for addressing the information
leakagedetection(ILD)problem, drawingupontheconceptsdescribedbyinformationtheory
and statistical learning theory. Through this systematic framework, we establish potent
methodologies for identifying vulnerabilities and enhancing cybersecurity.
We introduced two techniques to quantify and detect information leakage (IL) by esti-
mating mutual information (MI) between a given system’s observable and secret information,
leveraging the approximation of Bayes predictor’s Log-Loss and accuracy. Our proposed
approaches employ two powerful automated machine learning (AutoML) tools, TabPFN and
AutoGluon, to estimate MI, offering an automated and more efficient alternative to direct
estimation using statistical techniques or deep multi-layer perceptrons (MLPs). To perform
ILD in a given system, we propose to apply one-sample t-test (OTT) on the estimated MIs
obtained from these approaches. Additionally, we apply the Holm-Bonferroni correction to
multiple models’ (pipelines’) estimates, enhancing the robustness of our approaches against
noise and boosting confidence in IL decisions, as proposed in our prior work (Gupta et al.,
2022). Our empirical findings demonstrate that our approach, which approximates calibrated
Log-Loss using TabPFN, is highly effective and robust in precisely estimating MI in syn-
thetic data sets and detecting timing side-channel leaks in OpenSSL TLS servers compared
to state-of-the-art methods, as detailed in Sections 5.3 and 7.2. The key contributions of
our work include (a) providing a comprehensive theoretical framework for ILD problem,
(b) addressing imbalance issues with minimal false positives, (c) demonstrating robustness
to noise in generated data sets, and (d) offering an automated, adaptable, and scalable IL
detection solution for real-world cybersecurity scenarios.
50Furthermore,ourworkconcludesthatthechoiceandrequirementofcalibrationtechniques
for Log-Loss estimation depend on the characteristics of the system data sets. In future
work, we would like to provide a complete automated solution on the high dimensional
data set with numerous classes, mitigating the limitations of our approaches using TabPFN
(Hollmann et al., 2023). Specifically, we intend to develop an end-to-end AutoML tool
that selects appropriate dimensionality reduction techniques in conjunction with calibration
methodstoaccuratelyestimateMIanddetectIL. ConsideringthattheMid-Pointapproach
does not account for system data set imbalance, it is crucial to determine a Bayes predictor
that reduces metrics likes balanced error-rate (BER) or maximizes mathews correlation
coefficient (MCC), F1-score, and so on, as defined in Section 2.2.2.3. To improve the
estimation using the Mid-Point approach, we intend to expand upon the relationship
between BER and MI for binary classification provided by Zhao et al. (2013) and adapt it to
accommodate multiple classes. Additionally, our future work includes the detection of leaks
through other side-channels like via CPU caches, power consumption, and electromagnetic
radiations (Mushtaq et al., 2018; Picek et al., 2023). We intend to explore adaptive
techniques that dynamically adjust and fine-tune the IL detection process based on changing
environments or evolving attack strategies, utilizing reinforcement learning, online learning,
and other adaptive methods (Faezi et al., 2021).
Acknowledgments and Disclosure of Funding
We extend our gratitude to Karlson Pfannschmidt, Arunselvan Ramaswamy, Bj¨orn Had-
denhorst, and Jan Peter Drees for their valuable and helpful suggestions. Special thanks
go to Dennis Funke for his contribution to the simulation of the real-world OpenSSL TLS
servers to generate real data sets as part of his bachelor’s thesis under the supervision of Jan
Peter Drees. Experiments were performed on resources provided by the Paderborn Center
for Parallel Computing. This work is supported by the Bundesministerium fu¨r Bildung
und Forschung (BMBF) under the project 16KIS1190 (AutoSCA) and funded by European
Research Council (ERC)-802823.
51Gupta, Wever and Hu¨llermeier
Appendix A. Notations
In this paper, we maintain a consistent set of notations as detailed in Table 3. To ensure
clarity and ease of reference, we use full forms when representing probability density
functions (PDFs) and probability mass functions (PMFs) in the equations, while in the
text, we employ shorter forms for conciseness and readability. Occasionally, we may opt for
shorter forms in equations as well, particularly when it helps streamline derivations and
reduce equation width.
Table 3: Notation used throughout the paper
Symbol Meaning
[n] Setofintegers{1,2,...,n},n∈N
A Indicatorfunctionwhichis1ifstatementAistrueand0otherwise
(cid:74) (cid:75)
StatisticalLearningTheory
X Input(x∈Rd)randomvariable(d-dimensionalcontinuous)
Y Output(y∈[M])randomvariable(discrete)
X ∈Rd InputSpace,setofxsampledfromX
Y∈[M] OutputSpace,setofysampledfromY
D={(xi,yi)}N
i=1
Classificationdataset
r ImbalanceinadatasetD
ϵ NoiseinadatasetD
mErr(Bc),mErr(Mc) TheBayeserror-rateanderror-rateofmarginalBayespredictor
δloss=mloss(Mc)−mloss(Bc) DifferencebetweentheaveragepenaltyofBayespredictorandmarginal
Bayespredictorregardingaspecifiedlossfunction(loss)quantifyingIL
ProbabilityDistributionFunctions
P (X,Y)(·),Pˆ (X,Y)(·) ActualandpredictedjointPDFbetween(X,Y)
P (X,Y)(x,y)=P (X,Y)(X=x,Y =y) JointPDFofX andY,atpoint(x,y)
PX(·),Pˆ X(·) ActualandpredictedmarginalPDFofX
PX(x)=PX(X=x) Probabilitymassofinputx
PY(·),Pˆ Y(·) ActualandpredictedmarginalPMFofY
PY(y)=PY(Y =y) Probabilityofclasslabely
P Y|X(·),Pˆ Y|X(·) ActualandpredictedconditionalPDFofY givenX
P Y|X(y|x)=P Y|X(Y =y|X=x) Probabilityofygivenx
P X|Y(·),Pˆ X|Y(·) ActualandpredictedconditionalPDFofY givenX
P X|Y(x|y)=P X|Y(X=x|Y =y) Probabilityofxgiveny
InformationTheory
I(X;Y) MIbetweenX andY
H(Y |X) ConditionalentropyforY givenX
H(X),H(Y) EntropyforrandomvariableX andY
H2(a)=−(a)×lg(a)−(1−a)×lg(1−a) Binarycross-entropyfunctionfora∈(0,1)
lg(a),a∈R+ Binarylogarithm(base2)ofpositiverationalnumbera
log(a),a∈R+ Decimallogarithm(base10)ofpositiverationalnumbera
Informationleakagedetection(ILD)process
L,L ILDfunctionandIL-Dataset
H0(condition),H1(condition) NullandAlternatehypothesisforstatisticaltests
J∈N TotalhypothesesforHolm-Bonferronicorrection
τ ∈[J] Cut-offparameterforHolm-Bonferronicorrection
α RejectionthresholdonH0 (acceptH1)forstatisticaltests
5253
−
−
{
}
−
{
}
{
}
PC-Softmax
[1e−5,1e−1]
{RMSProp,SGD,Adam}
[1,50]
[2,256]
[1e−10,0.2]
{True,False}
{True,False}
NA
MINE
[1e
5,1e
1]
RMSProp,SGD,Adam
[1,50]
[2,256]
[1e
10,0.2]
True,False
True,False
NA
LearningRate
OptimizerType
#Layers
#Units
RegularizationStrength
EarlyStopping
BatchNormalization
OtherParameters
{
}
−
−
GMM
RF,XT
[10,50]
Full,Diagonal,Tied,Spherical
[1e
10,1e
1]
NA
NA
NA
NA
Learner
ReductionTechnique
#ReducedFeatures
CovarianceMatrixType
RegularizationStrength
OtherParameters
Baselines
TabPFN
RF,XT
[10,50]
[32,200]
NA
NA
NA
NA
NA
Learner
ReductionTechnique
#ReducedFeatures
#Ensembles
OtherParameters
TabPFN
−
−
NNTORCH
[1e−5,1e−1]
[0.0,0.5]
[2,20]
[8,256]
NA
NA
NA
NA
FASTAI
[1e
5,1e
1]
[0.0,0.5]
NA
NA
NA
NA
NA
NA
LearningRate
DropoutProb
#Layers
#Units
OtherParameters
NeuralNetworks(MLPs)
Extratreesclassifier(XT)
NA
[20,300]
[6,20]
NA
NA
NA
NA
NA
Randomforestclassifier(RF)
NA
[20,300]
[6,20]
NA
NA
NA
NA
NA
EXtremegradientboostingmachine(XGBoost)
[0.01,0.5]
[20,300]
[3,10]
NA
NA
NA
NA
NA
Categoricalboostingmachine(CatBoost)
[0.01,0.5]
NA
[4,10]
NA
NA
NA
NA
[−0.1,10−]
Lightgradientboostingmachine(LightGBM)
[0.01,0.5]
[20,300]
[3,20]
[20,300]
[0.2,0.95]
[0.2,0.95]
[20,5000]
[1e
6,1e
2]
Learner
LearningRate
#Estimators
MaxDepth
#Leaves
FeatureFraction
BaggingFraction
MinDatainLeaf
LambdaL1/LambdaL2
Tree-basedEnsembleModels
AutoGluon
approaches
(Gaussian
mixture
model
(GMM),
Mutual
information
neural
estimation
(MINE),
and
PC-Softmax)
Table
4:
Hyperparameter
ranges
for
AutoML
tools:
AutoGluon
models
and
TabPFN
including
the
MI
estimation
baselineGupta, Wever and Hu¨llermeier
Appendix B. Implementation Details for HPO
In this section, we outline various models and learning algorithms along with their respective
hyperparameters and range values, which are available within the AutoGluon tool in Table 4.
The objective functions employed for hyperparameter optimization (HPO) include BER for
PC-Softmax, AutoGluon, and TabPFN, Akaike information criterion (AIC) for GMM, and
meansquarederror(MSE)forMINE. ThesearchspaceinAutoGluonencompassesconsistent
classifiers, notably tree-based ensemble models such as RF and XT, as well as gradient
boosting machine (GBM) algorithms like LightGBM, CatBoost, and XGBoost (Biau et al.,
2008)Additionally,itincludesaMLPimplementedusingPyTorchandtrainedMLPprovided
by fastai (Mielniczuk and Tyrcha, 1993; Howard and Gugger, 2020). Furthermore, the
hyperparameters and their respective range values for both TabPFN and the baseline MI
estimators (including GMM, MINE, and PC-Softmax) are detailed in Table 4.
Appendix C. Generalization Capability
In this section, we explore the generalization capabilities of our ILD and MI estimation
approaches, comparing them to state-of-the-art methods. We employ heatmapsdepicting key
performance metrics, such as Accuracy, FPR, and FNR with respect to the time delay, which
is further detailed in Appendix C.1. The time delay signifies the difference in computation
time between correctly padded messages and manipulated (incorrect) padded messages sent
to the OpenSSL TLS server.
Furthermore, we present detailed heatmaps illustrating the normalized mean absolute
error(NMAE)performanceresultsofMIestimationmethodsonsyntheticdatasetsproduced
using the multivariate normal (MVN) distribution. We carefully select the best-performing
calibrated Log-Loss approach for both AutoGluon and TabPFN. These heatmaps provide
insights into the generalization capabilities across various scenarios, taking into account
multiple factors such as the number of classes (M), input dimensions (d), class imbalance
(r), and noise level (ϵ) (referred to as flip percentage (ϵ) in case of MVN perturbation data
set), as elaborated in Appendix C.2.
C.1 ILD Approaches
We assessed the generalization capability of various ILD approaches to detect timing side-
channels aimed at mitigating the Bleichenbacher attack, focusing on key performance metrics
like detection accuracy, FPR, and FNR. Our analysis incorporated heatmaps with a fixed
rejection threshold of 5 (τ = 5) to illustrate the generalization performance of these ILD
approaches. In particular, Figure 10 demonstrates the performance relative to time delays in
increments (linear step) of 5µs, whereas Figure 11 showcases the performance versus time
delays in the logarithmic step of 2µs.
C.1.1 TabPFN
This section delves into a comprehensive analysis of MI and classification-based ILD ap-
proaches using TabPFN. Typically, ILD approaches employing TabPFN show reduced
effectiveness in detecting ILs in systems generating imbalanced data set compared to those
producing balanced ones. Remarkably, TabPFN IR Cal Log-Loss stands out in terms of
54ILD with Rejection Threshold = 5, τ 5
≥
Class Imbalance r =0.1
Detection Accuracy False Positive Rate False Negative Rate
1.0
AutoGluonMid-Point .50 .50 .49 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .02 .00 .00 .00
AutoGluonLog-Loss .49 .50 .50 .53 .48 .52 .04 .08 .10 .04 .10 .04 .98 .92 .90 .90 .94 .92
AutoGluonIRCalLog-Loss .50 .50 .49 .50 .50 .50 1.0 1.0 .98 .98 1.0 1.0 .00 .00 .04 .02 .00 .00
AutoGluonPSCalLog-Loss .49 .50 .50 .53 .48 .52 .04 .08 .10 .04 .10 .04 .98 .92 .90 .90 .94 .92
AutoGluonBetaCalLog-Loss .49 .50 .50 .52 .47 .51 .04 .08 .10 .04 .10 .04 .98 .92 .90 .92 .96 .94
AutoGluonTSCalLog-Loss .49 .50 .50 .53 .48 .52 .04 .08 .10 .04 .10 .04 .98 .92 .90 .90 .94 .92
Au Ato uG tolu Go ln uoH nB PC Ta Tl -MLo ag jo-L ro its ys . .5 40
7
. .5 50
3
. .4 49
8
. .5 40
8
. .5 40
7
. .5 40
8
1 .1.0
0
1 .0.0
6
. .9 28
2
. .9 18
6
1 .0.0
6
1 .1.0
8
. .0 90
6
. .0 80
8
. .0 84
2
. .0 82
8
. 10 .0
0
. .0 80
6
0.9
AutoGluonFET-Mean .52 .52 .48 .50 .61 .60 .10 .02 .04 .06 .14 .02 .86 .94 1.0 .94 .64 .78
AutoGluonFET-Median .51 .54 .58 .55 .58 .62 .32 .20 .12 .18 .48 .22 .66 .72 .72 .72 .36 .54
TabPFNMid-Point .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00
TabPFNLog-Loss .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00
TabPFNIRCalLog-Loss .52 .55 .56 .74 .95 .97 .04 .04 .04 .02 .00 .02 .92 .86 .84 .50 .10 .04
TabPFNPSCalLog-Loss .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00
TabPFNBetaCalLog-Loss .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 0.8
TabPFNTSCalLog-Loss .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00
TabPFNHBCalLog-Loss .50 .50 .51 .48 .49 .52 .00 .00 .00 .04 .02 .02 1.0 1.0 .98 1.0 1.0 .94
TabPFNPTT-Majority .50 .50 .50 .50 .50 .50 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 1.0 1.0
TabPFNFET-Mean .50 .50 .50 .50 .50 .50 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 1.0 1.0
TabPFNFET-Median .50 .50 .50 .50 .50 .50 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 1.0 1.0
GMMBaseline .50 .50 .53 .50 .50 .50 1.0 1.0 .94 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00
MINEBaseline .49 .47 .51 .49 .51 .47 .06 .16 .12 .04 .06 .10 .96 .90 .86 .98 .92 .96 0.7
PC-SoftmaxBaseline .49 .49 .51 .53 .48 .52 .04 .08 .06 .04 .10 .04 .98 .94 .92 .90 .94 .92
Class Imbalance r =0.3
AutoGluonMid-Point .50 .50 .50 .50 .50 .51 1.0 1.0 1.0 1.0 1.0 .98 .00 .00 .00 .00 .00 .00
AutoGluonLog-Loss .48 .50 .47 .54 .72 .89 .04 .04 .06 .04 .06 .02 1.0 .96 1.0 .88 .50 .20
AutoGluonIRCalLog-Loss .50 .50 .50 .50 .50 .51 1.0 1.0 1.0 1.0 1.0 .98 .00 .00 .00 .00 .00 .00
AutoGluonPSCalLog-Loss .48 .51 .48 .54 .73 .88 .04 .02 .04 .02 .02 .02 1.0 .96 1.0 .90 .52 .22
AutoGluonBetaCalLog-Loss .48 .49 .48 .53 .72 .87 .04 .02 .04 .04 .06 .02 1.0 1.0 1.0 .90 .50 .24 0.6
AutoGluonTSCalLog-Loss .48 .50 .47 .54 .72 .89 .04 .04 .06 .04 .06 .02 1.0 .96 1.0 .88 .50 .20
AutoGluonHBCalLog-Loss .50 .50 .50 .50 .50 .51 1.0 1.0 1.0 1.0 1.0 .98 .00 .00 .00 .00 .00 .00
AutoGluonPTT-Majority .50 .50 .49 .49 .47 .48 .00 .04 .02 .02 .06 .04 1.0 .96 1.0 1.0 1.0 1.0
AutoGluonFET-Mean .55 .56 .68 .76 .78 .83 .12 .02 .06 .00 .00 .02 .78 .86 .58 .48 .44 .32
AutoGluonFET-Median .58 .66 .67 .72 .86 .87 .40 .24 .30 .34 .12 .26 .44 .44 .36 .22 .16 .00
TabPFNMid-Point .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00
TabPFNLog-Loss .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 0.5
TabPFNIRCalLog-Loss .69 .87 .92 .98 .96 .98 .00 .04 .06 .04 .08 .04 .62 .22 .10 .00 .00 .00
TabPFNPSCalLog-Loss .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00
TabPFNBetaCalLog-Loss .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00
TabPFNTSCalLog-Loss .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00
TabPFNHBCalLog-Loss .50 .49 .54 .92 .99 1.0 .00 .02 .00 .00 .00 .00 1.0 1.0 .92 .16 .02 .00
TabPFNPTT-Majority .50 .50 .50 .50 .50 .50 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 1.0 1.0
TabPFNFET-Mean .50 .50 .50 .50 .50 .50 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 1.0 1.0 0.4
TabPFNFET-Median .50 .50 .50 .50 .50 .50 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 1.0 1.0
GMMBaseline .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00
MINEBaseline .52 .48 .51 .49 .49 .50 .06 .12 .04 .06 .08 .10 .90 .92 .94 .96 .94 .90
PC-SoftmaxBaseline .49 .50 .50 .52 .48 .52 .04 .08 .10 .04 .10 .04 .98 .92 .90 .92 .94 .92
Balanced
AutoGluonMid-Point .59 .74 .90 .95 1.0 1.0 .10 .00 .00 .00 .00 .00 .72 .52 .20 .10 .00 .00
AutoGluonLog-Loss .74 .79 .79 .82 .85 .84 .52 .42 .42 .36 .30 .32 .00 .00 .00 .00 .00 .00 0.3
AutoGluonIRCalLog-Loss .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00
AutoGluonPSCalLog-Loss .74 .79 .79 .82 .85 .84 .52 .42 .42 .36 .30 .32 .00 .00 .00 .00 .00 .00
AutoGluonBetaCalLog-Loss .74 .79 .79 .82 .85 .84 .52 .42 .42 .36 .30 .32 .00 .00 .00 .00 .00 .00
AutoGluonTSCalLog-Loss .74 .79 .79 .82 .85 .84 .52 .42 .42 .36 .30 .32 .00 .00 .00 .00 .00 .00
AutoGluonHBCalLog-Loss .52 .54 .51 .54 .51 .55 .96 .92 .98 .92 .98 .90 .00 .00 .00 .00 .00 .00
AutoGluonPTT-Majority .57 .78 .91 .95 .99 1.0 .12 .00 .00 .00 .00 .00 .74 .44 .18 .10 .02 .00
AutoGluonFET-Mean .50 .50 .59 .80 .83 .96 .00 .00 .00 .00 .00 .00 1.0 1.0 .82 .40 .34 .08 0.2
AutoGluonFET-Median .53 .53 .78 .87 .98 1.0 .00 .00 .00 .00 .00 .00 .94 .94 .44 .26 .04 .00
TabPFNMid-Point .48 .62 .67 .79 .88 .98 .34 .14 .22 .36 .18 .04 .70 .62 .44 .06 .06 .00
TabPFNLog-Loss .50 .50 .47 .91 .95 .98 .00 .06 .08 .04 .08 .04 1.0 .94 .98 .14 .02 .00
TabPFNIRCalLog-Loss .49 .82 .97 .99 .95 .98 .02 .04 .04 .02 .04 .04 1.0 .32 .02 .00 .06 .00
TabPFNPSCalLog-Loss .50 .50 .47 .91 .96 .98 .00 .06 .08 .04 .08 .04 1.0 .94 .98 .14 .00 .00
TabPFNBetaCalLog-Loss .50 .50 .47 .91 .96 .98 .00 .06 .08 .04 .08 .04 1.0 .94 .98 .14 .00 .00
TabPFNTSCalLog-Loss .50 .50 .47 .91 .96 .98 .00 .06 .08 .04 .08 .04 1.0 .94 .98 .14 .00 .00 0.1
TabPFNHBCalLog-Loss .48 .68 .95 .97 .95 .99 .04 .04 .02 .06 .10 .02 1.0 .60 .08 .00 .00 .00
TabPFNPTT-Majority .50 .64 .78 .96 .97 1.0 .00 .00 .00 .00 .00 .00 1.0 .72 .44 .08 .06 .00
TabPFNFET-Mean .50 .50 .52 .61 .75 .82 .00 .00 .00 .00 .00 .00 1.0 1.0 .96 .78 .50 .36
TabPFNFET-Median .50 .50 .63 .73 .87 .93 .00 .00 .00 .00 .00 .00 1.0 1.0 .74 .54 .26 .14
GMMBaseline .50 .50 .49 .50 .49 .49 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .02 .00 .02 .02
MINEBaseline .49 .50 .51 .53 .50 .48 .08 .08 .12 .00 .04 .16 .94 .92 .86 .94 .96 .88
PC-SoftmaxBaseline .49 .50 .50 .53 .50 .53 .04 .08 .10 .04 .06 .02 .98 .92 .90 .90 .94 .92 0.0
10 15 20 25 30 35 10 15 20 25 30 35 10 15 20 25 30 35
Delay in µ-seconds Delay in µ-seconds Delay in µ-seconds
Figure 10: Performance of ILD approaches versus time delay with 5µs steps
generalization performance, detecting over 60% of the ILs in systems with a minimal time
delay less than 20µs.
55Gupta, Wever and Hu¨llermeier
ILD with Rejection Threshold = 5, τ 5
≥
Class Imbalance r =0.1
Detection Accuracy False Positive Rate False Negative Rate
1.0
AutoGluonMid-Point .50 .50 .50 .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00
AutoGluonLog-Loss .43 .43 .57 .47 .53 .50 .50 .83 .93 .13 .13 .00 .07 .00 .07 .07 .00 .13 1.0 1.0 .87 1.0 .93 .93 .93 .33 .00
AutoGluonIRCalLog-Loss .53 .50 .50 .50 .50 .50 .50 .50 .50 .87 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 .07 .00 .00 .00 .00 .00 .00 .00 .00
AutoGluonPSCalLog-Loss .47 .43 .57 .47 .53 .50 .50 .83 .93 .07 .13 .00 .07 .00 .07 .07 .00 .13 1.0 1.0 .87 1.0 .93 .93 .93 .33 .00
AutoGluonBetaCalLog-Loss .43 .43 .57 .47 .53 .50 .50 .80 .93 .13 .13 .00 .07 .00 .07 .07 .00 .13 1.0 1.0 .87 1.0 .93 .93 .93 .40 .00
AutoGluonTSCalLog-Loss .43 .43 .57 .47 .53 .50 .50 .83 .93 .13 .13 .00 .07 .00 .07 .07 .00 .13 1.0 1.0 .87 1.0 .93 .93 .93 .33 .00
Au Ato uG tolu Go ln uoH nB PC Ta Tl -MLo ag jo-L ro its ys . .5 53
0
. .5 50
0
. .5 50
0
. .5 50
0
. .5 50
3
. .5 50
0
. .5 50
0
. .5 60
3
. 15 .0
0
. .8 07
7
1 .0.0
0
1 .0.0
0
1 .0.0
0
1 .0.0
7
1 .0.0
0
1 .0.0
0
1 .0.0
0
1 .0.0
0
. .0 97
3
. 10 .0
0
. 10 .0
0
. 10 .0
0
. .0 80
7
. 10 .0
0
. 10 .0
0
. .0 70
3
. .0 00
0
0.9
AutoGluonFET-Mean .50 .50 .53 .50 .47 .53 .80 1.0 1.0 .00 .00 .00 .00 .07 .00 .00 .00 .00 1.0 1.0 .93 1.0 1.0 .93 .40 .00 .00
AutoGluonFET-Median .50 .47 .57 .60 .50 .60 .87 .87 .93 .13 .33 .00 .07 .13 .40 .27 .27 .13 .87 .73 .87 .73 .87 .40 .00 .00 .00
TabPFNMid-Point .50 .50 .50 .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00
TabPFNLog-Loss .50 .50 .50 .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00
TabPFNIRCalLog-Loss .53 .57 .53 .57 .60 .90 1.0 1.0 1.0 .00 .13 .00 .07 .07 .07 .00 .00 .00 .93 .73 .93 .80 .73 .13 .00 .00 .00
TabPFNPSCalLog-Loss .50 .50 .50 .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00
TabPFNBetaCalLog-Loss .50 .50 .50 .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00 0.8
TabPFNTSCalLog-Loss .50 .50 .50 .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00
TabPFNHBCalLog-Loss .50 .50 .53 .50 .50 .60 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00 1.0 1.0 .93 1.0 1.0 .80 .00 .00 .00
TabPFNPTT-Majority .50 .50 .50 .50 .50 .50 .50 .77 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 1.0 1.0 1.0 .47 .00
TabPFNFET-Mean .50 .50 .50 .50 .50 .50 .50 .97 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 1.0 1.0 1.0 .07 .00
TabPFNFET-Median .50 .50 .50 .50 .50 .50 .50 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00
GMMBaseline .50 .50 .50 .50 .50 .47 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .07 .00 .00 .00
MINEBaseline .53 .50 .57 .50 .50 .43 .47 .50 .50 .00 .20 .00 .07 .07 .27 .07 .07 .00 .93 .80 .87 .93 .93 .87 1.0 .93 1.0 0.7
PC-SoftmaxBaseline .43 .47 .57 .47 .53 .53 .53 .50 .47 .13 .07 .00 .07 .00 .00 .07 .00 .07 1.0 1.0 .87 1.0 .93 .93 .87 1.0 1.0
Class Imbalance r =0.3
AutoGluonMid-Point .50 .50 .53 .50 .50 .50 .50 .50 .50 1.0 1.0 .93 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00
AutoGluonLog-Loss .47 .50 .57 .47 .50 .87 1.0 1.0 .93 .07 .00 .00 .07 .00 .00 .00 .00 .13 1.0 1.0 .87 1.0 1.0 .27 .00 .00 .00
AutoGluonIRCalLog-Loss .50 .50 .53 .50 .50 .50 .50 .50 .50 1.0 1.0 .93 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00
AutoGluonPSCalLog-Loss .50 .50 .57 .47 .50 .83 1.0 1.0 .93 .00 .00 .00 .07 .00 .00 .00 .00 .13 1.0 1.0 .87 1.0 1.0 .33 .00 .00 .00
AutoGluonBetaCalLog-Loss .50 .50 .57 .50 .50 .87 1.0 1.0 .97 .00 .00 .00 .00 .00 .00 .00 .00 .07 1.0 1.0 .87 1.0 1.0 .27 .00 .00 .00 0.6
AutoGluonTSCalLog-Loss .47 .50 .57 .47 .50 .87 1.0 1.0 .93 .07 .00 .00 .07 .00 .00 .00 .00 .13 1.0 1.0 .87 1.0 1.0 .27 .00 .00 .00
AutoGluonHBCalLog-Loss .50 .50 .53 .50 .50 .50 .50 .50 .50 1.0 1.0 .93 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00
AutoGluonPTT-Majority .47 .50 .50 .47 .50 .50 .77 1.0 1.0 .07 .00 .00 .07 .00 .00 .07 .00 .00 1.0 1.0 1.0 1.0 1.0 1.0 .40 .00 .00
AutoGluonFET-Mean .50 .50 .50 .50 .50 .57 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 1.0 .87 .00 .00 .00
AutoGluonFET-Median .50 .53 .50 .53 .53 .97 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00 1.0 .93 1.0 .93 .93 .07 .00 .00 .00
TabPFNMid-Point .50 .50 .50 .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00
TabPFNLog-Loss .50 .50 .50 .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00 0.5
TabPFNIRCalLog-Loss .47 .60 .53 .50 .67 .83 .97 .97 .90 .33 .13 .13 .13 .33 .33 .07 .07 .20 .73 .67 .80 .87 .33 .00 .00 .00 .00
TabPFNPSCalLog-Loss .50 .50 .50 .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00
TabPFNBetaCalLog-Loss .50 .50 .50 .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00
TabPFNTSCalLog-Loss .50 .50 .50 .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00
TabPFNHBCalLog-Loss .50 .50 .50 .50 .53 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 .93 .00 .00 .00 .00
TabPFNPTT-Majority .50 .50 .50 .50 .50 .50 .73 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 1.0 1.0 .53 .00 .00
TabPFNFET-Mean .50 .50 .50 .50 .50 .50 .83 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 1.0 1.0 .33 .00 .00 0.4
TabPFNFET-Median .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00
GMMBaseline .50 .50 .50 .50 .50 .50 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00
MINEBaseline .47 .47 .43 .47 .47 .50 .43 .53 .47 .07 .13 .13 .07 .07 .07 .13 .00 .13 1.0 .93 1.0 1.0 1.0 .93 1.0 .93 .93
PC-SoftmaxBaseline .43 .47 .57 .47 .50 .50 .53 .50 .43 .13 .07 .00 .07 .00 .07 .07 .00 .13 1.0 1.0 .87 1.0 1.0 .93 .87 1.0 1.0
Balanced
AutoGluonMid-Point .50 .50 .50 .50 .57 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 .87 .00 .00 .00 .00
AutoGluonLog-Loss .50 .50 .63 .57 .77 .80 .83 .80 .87 .53 .53 .33 .53 .47 .40 .33 .40 .27 .47 .47 .40 .33 .00 .00 .00 .00 .00 0.3
AutoGluonIRCalLog-Loss .50 .50 .50 .50 .53 .50 .50 .50 .50 1.0 1.0 1.0 1.0 .93 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00
AutoGluonPSCalLog-Loss .50 .50 .63 .57 .77 .80 .83 .80 .87 .53 .53 .33 .53 .47 .40 .33 .40 .27 .47 .47 .40 .33 .00 .00 .00 .00 .00
AutoGluonBetaCalLog-Loss .50 .50 .63 .57 .77 .80 .83 .80 .87 .53 .53 .33 .53 .47 .40 .33 .40 .27 .47 .47 .40 .33 .00 .00 .00 .00 .00
AutoGluonTSCalLog-Loss .50 .50 .63 .57 .77 .80 .83 .80 .87 .53 .53 .33 .53 .47 .40 .33 .40 .27 .47 .47 .40 .33 .00 .00 .00 .00 .00
AutoGluonHBCalLog-Loss .47 .53 .57 .50 .53 .53 .53 .57 .53 1.0 .93 .80 1.0 .93 .93 .93 .87 .93 .07 .00 .07 .00 .00 .00 .00 .00 .00
AutoGluonPTT-Majority .50 .50 .50 .50 .60 1.0 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 .80 .00 .00 .00 .00
AutoGluonFET-Mean .50 .50 .50 .50 .50 .70 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 1.0 .60 .00 .00 .00 0.2
AutoGluonFET-Median .50 .50 .50 .50 .50 .93 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 1.0 .13 .00 .00 .00
TabPFNMid-Point .50 .40 .40 .57 .47 .83 .77 .90 .77 .40 .53 .40 .33 .20 .27 .47 .20 .47 .60 .67 .80 .53 .87 .07 .00 .00 .00
TabPFNLog-Loss .47 .47 .53 .50 .50 1.0 1.0 1.0 .97 .07 .07 .00 .00 .00 .00 .00 .00 .07 1.0 1.0 .93 1.0 1.0 .00 .00 .00 .00
TabPFNIRCalLog-Loss .50 .47 .53 .50 .80 1.0 1.0 1.0 1.0 .00 .07 .00 .00 .00 .00 .00 .00 .00 1.0 1.0 .93 1.0 .40 .00 .00 .00 .00
TabPFNPSCalLog-Loss .47 .47 .53 .50 .50 1.0 1.0 1.0 .97 .07 .07 .00 .00 .00 .00 .00 .00 .07 1.0 1.0 .93 1.0 1.0 .00 .00 .00 .00
TabPFNBetaCalLog-Loss .47 .47 .53 .50 .50 1.0 1.0 1.0 .97 .07 .07 .00 .00 .00 .00 .00 .00 .07 1.0 1.0 .93 1.0 1.0 .00 .00 .00 .00
TabPFNTSCalLog-Loss .47 .47 .53 .50 .50 1.0 1.0 1.0 .97 .07 .07 .00 .00 .00 .00 .00 .00 .07 1.0 1.0 .93 1.0 1.0 .00 .00 .00 .00 0.1
TabPFNHBCalLog-Loss .50 .47 .57 .50 .60 .97 .97 1.0 .97 .00 .07 .00 .00 .00 .07 .07 .00 .07 1.0 1.0 .87 1.0 .80 .00 .00 .00 .00
TabPFNPTT-Majority .50 .50 .50 .50 .60 .97 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 .80 .07 .00 .00 .00
TabPFNFET-Mean .50 .50 .50 .50 .50 .57 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 1.0 .87 .00 .00 .00
TabPFNFET-Median .50 .50 .50 .50 .50 .80 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00 1.0 1.0 1.0 1.0 1.0 .40 .00 .00 .00
GMMBaseline .50 .50 .50 .50 .50 .53 .50 .50 .50 1.0 1.0 1.0 1.0 1.0 .93 1.0 1.0 1.0 .00 .00 .00 .00 .00 .00 .00 .00 .00
MINEBaseline .47 .53 .60 .50 .53 .47 .53 .53 .47 .13 .07 .07 .07 .07 .07 .07 .00 .20 .93 .87 .73 .93 .87 1.0 .87 .93 .87
PC-SoftmaxBaseline .43 .47 .57 .47 .53 .50 .57 .50 .43 .13 .07 .00 .07 .00 .07 .07 .00 .13 1.0 1.0 .87 1.0 .93 .93 .80 1.0 1.0 0.0
Delay in µ-seconds Delay in µ-seconds Delay in µ-seconds
Figure 11: Performance of ILD approaches versus time delay with logarithmic step of 2µs
Classification-based Approaches When focusing on the balanced data sets, TabPFN
PTT-Majority stands out in detecting ILs. On the other hand, TabPFN FET-Median
proves to be more adept in detecting ILs for imbalanced data sets. In the context of
56
1 2 4 8 61 23 46 821 652 1 2 4 8 61 23 46 821 652 1 2 4 8 61 23 46 821 652imbalanced data sets, the classification-based ILD approaches using TabPFN can detect ILs
only when the time delay of the systems exceeds 35µs. For delays shorter than 35µs, these
methodologies fall short in detecting in any ILs, resulting in a 100% FNR. Amongst all,
TabPFN FET-Median showcases the best detection performance for imbalanced synthetic
data set. Detecting ILs in systems generating balanced data sets is comparatively easier. In
this context, the classification-based ILD approaches using TabPFN In systems producing
balanced data sets, the classification-based ILD approaches using TabPFN can detect ILs in
systems even with a slight time delay of at least 15µs. For systems with minimal time delay
below 15µs, all these approaches fail in detecting ILs, yielding a 100% FNR. Particularly,
TabPFN PTT-Majority displays superior detection Accuracy, occasionally detecting over
60% of the ILs in systems with time delay beyond 15µs.
MI-based Approaches Overall, TabPFN IR Cal Log-Loss is the most proficient
in detecting ILs for balanced and imbalanced synthetic data sets. In the context of the
imbalanced synthetic data sets, most MI-based approaches using TabPFN, except for IR Cal
Log-Loss and HB Cal Log-Loss, face challenges in detecting 50% of the ILs, leading to
random detection decisions. This behavior arises because these methods tend to overfit by
overestimating MI, leading to the detection of non-existent ILs and yielding a 100% FPR.
Both TabPFN IR Cal Log-Loss and HB Cal Log-Loss approach detect over 80% of
the ILs in systems with time delay above 32µs. Impressively, TabPFN IR Cal Log-Loss
approach occasionally detects over 55% of the ILs in systems with very minimal time delay
under 20µs. This highlights the remarkable enhancement IR Cal Log-Loss brings to the
Log-Loss approach, with HB Cal Log-Loss also contributing positively. For systems
producing balanced synthetic data sets, MI-based ILD approaches using TabPFN display
significantly improved performance. They can reliably detect ILs even in systems with short
delays of 15µs, with TabPFN IR Cal Log-Loss occasionally detecting more than 80%
of the ILs. Yet, for systems with time delay below 15µs, they falter in detecting any IL,
producing a 100% FNR.
C.1.2 AutoGluon
This section delves into a comprehensive analysis of classification and MI-based ILD ap-
proaches using AutoGluon. Generally, ILD approaches using AutoGluon face greater
challenges with imbalanced synthetic data sets, especially with shorter time delays. Notably,
the generalization capability of ILD approaches using AutoGluon is commendable, detecting
occasionally over 65% of ILs in systems, even with time delays under 20µs.
Classification-based Approaches The Fisher’s exact test (FET) based classification
ILD approaches using AutoGluon reveal comparable performances for both balanced and
imbalanced synthetic data sets, albeit with minor differences. However, the AutoGluon
PTT-Majority approach demonstrates superior detection performance on balanced syn-
thetic data sets compared to the imbalanced ones. For imbalanced synthetic data sets,
the classification-based ILD approaches using AutoGluon start reliably detecting ILs in
systems with time delays exceeding 30µs. Below this threshold, their detection performance
plummets significantly, often missing the majority of ILs, resulting in an elevated FNR
(typically around 100%). The AutoGluon FET-Median approach appears to have a slight
edge over the other approaches. When considering balanced synthetic data sets, AutoGluon’s
57Gupta, Wever and Hu¨llermeier
classification-based ILD approaches excel, reliably detecting ILs even in systems with a brief
time delay of 15µs, occasionally achieving over 60% detection Accuracy. Mirroring the
findings from TabPFN, the PTT-Majority approach using AutoGluon consistently stands
out as the top performer for balanced synthetic data sets.
MI-based Approaches Upon a deeper performance inspection of MI-based ILD ap-
proaches using AutoGluon, it is evident that AutoGluon Mid-Point notably thrives in
detecting ILs in balanced synthetic data sets, whereas AutoGluon Log-Loss is particularly
proficient for imbalanced ones. Intriguingly, the calibration techniques (Cal Log-Loss)
fail to enhance the performance of AutoGluon Log-Loss approach and, in some instances,
even deteriorate its effectiveness. Within imbalanced synthetic data sets, AutoGluon’s
MI-based approaches generally struggle, especially for shorter time delays. Their perfor-
mance consistency improves for time delays beyond 25µs, with Log-Loss variant emerging
as the front runner. Most calibration techniques (Cal Log-Loss) do not augment the
Log-Loss approach’s performance. In fact, employing the IR Cal Log-Loss and HB
Cal Log-Loss methods negatively impact its performance, leading to the detection of
non-existent ILs, potentially stemming from overfitting or overestimating MI, leading to a
100% FPR, which is consistent with our findings in Sections 5.3.1 and 7.2. As expected,
the AutoGluon Mid-Point approach also mistakenly detects non-existent ILs, leading to
a 100% FPR. For balanced synthetic data sets, the MI-based approaches exhibit enhanced
performance, with most methods detecting approximately 74% ILs in systems with time
delay over 10µs, AutoGluon Mid-Point approach emerging as the front runner. However,
like the imbalanced counterparts, calibration techniques (Cal Log-Loss) do not improve
the Log-Loss approach’s performance. In fact, employing the IR Cal Log-Loss and HB
Cal Log-Loss methods diminish its efficacy, leading to the detection of non-existent ILs,
potentially stemming from overfitting or overestimating MI, leading to a 100% FPR, which
is consistent with our findings in Sections 5.3.1 and 7.2.
C.1.3 ILD Baselines
FortheILDbaselines,theperformanceanalysispredominantlyindicatesaconsistentbehavior,
regardless of the system data sets being balanced or imbalanced. Generally, all baselines
consistently achieve a detection accuracy approximately equal to 50%. Interestingly, while
MINE and PC-Softmax often miss most of the ILs and produces false negatives, GMM
leans towards the opposite end of the spectrum, generating false positives and overestimating
MI. ThistendencyofGMMtooverestimateMIismorepronouncedinhigh-dimensionaldata
sets, where it’s traditionally known to be susceptible to mis-estimation due to overfitting.
However, it’s worth noting that occasionally, both MINE and PC-Softmax demonstrate
better performance, detecting 60% of ILs. Despite these occasional spikes in detection
accuracy, the overall performance of baselines emphasizes the necessity and superiority of
more specialized approaches in the realm of ILD.
C.1.4 Summary
Summarizing our observations, while calibration techniques (Cal Log-Loss) tend to
improve the detection capabilities of TabPFN Log-Loss, they sometimes either diminish
the performance of AutoGluon Log-Loss or leave it unaffected. In contrast, calibration
58techniques (Cal Log-Loss) didn’t significantly impact TabPFN Log-Loss’s performance,
as discussed in Section 5.3.1, which indicate that the application and necessity of calibration
techniques are contingent upon the underlying system data sets, as discussed in Section 7.2.3.
For systems yielding balanced data sets, except IR Cal Log-Loss and HB Cal Log-Loss
methods using AutoGluon when detecting nearly 50% of ILs, often errs by overlooking most
ILs, resulting in an elevated FNR (typically around 100%). When AutoGluon employs the
IR Cal Log-Loss and HB Cal Log-Loss techniques detecting about 50% of ILs, tends
to make arbitrary detection decisions due to the identification of non-existent ILs, yielding
a 100% FPR, possibly because of overfitting or overestimation of MI. Our observation
in Section 5.3.1 and appendix C.2 back the reason behind this behavior, where the usage
of calibration techniques for AutoGluon Log-Loss approach mostly leads to overfitting
and overestimating MI in non-vulnerable synthetic data sets, resulting in the detection of
non-existent ILs.
For systems with time delays between 1 to 256 µ-seconds that generate imbalanced
data sets, the majority of MI-based approaches are prone to arbitrary detection decisions,
producing approximately 50% Accuracy. These approaches often misidentify non-existent
ILs, incurring around a 100% FPR, likely stemming from overfitting or MI overestimations.
The remaining MI-based approaches, which detect over 50% of the ILs in systems with
longer time delays, generally falter due to missing new ILs and yielding high FNR. Similarly,
classification-basedapproachesalsounderperformbyfailingtodetectnovelILsandproducing
high FNR. The baseline ILD approaches remain subpar, merely detecting 50% of the ILs
across all systems, making random decisions due to elevated FPR or FNR (typically around
100%).
In summary, overall TabPFN IR Cal Log-Loss consistently demonstrate robust
performance across systems, be it those producing balanced or imbalanced data sets. When
using AutoGluon, the FET-Median method stands out for imbalanced synthetic data
sets, whereas the Mid-Point and PTT-Majority strategies excel at detecting ILs in the
systems producing balanced data sets.
C.2 MI Estimation Approaches
We assessed the generalization capability of our MI estimation approaches employing both
AutoGluon and TabPFN relative to baseline methods, using the NMAE performance metric
defined in (18). For each data set type, namely balanced, binary-class, and multi-class
imbalance, we determine the NMAE for every unique configuration of the number of classes
(M), input dimensions (d), class imbalance (r), and noise level (ϵ). Note that we select the
top-performing calibration technique (from among IR Cal Log-Loss, PS Cal Log-Loss,
Beta Cal Log-Loss, TS Cal Log-Loss, and HB Cal Log-Loss), which is used to make
the Log-Loss approach for MI estimation more efficient due to spatial constraints. Our
comprehensive assessment incorporated the usage of heatmaps to illustrate the generalization
capabilities of these approaches. In particular, we discuss the generalization capabilities with
respect to the number of classes (M) and input dimensions (d) in the balanced synthetic
data sets in Appendix C.2.1. Conversely, Appendix C.2.2 includes our discussion on the
generalization capabilities with respect to the class imbalance (r) and noise level (ϵ) within
binary-class and multi-class imbalance synthetic data set.
59Gupta, Wever and Hu¨llermeier
Vulnerable (cid:15)=0.0
AutoGluonMid-Point AutoGluonLog-Loss AutoGluonIRCalLog-Loss
1.0
10 .02.01.00.00.00.00.00.00.00.00 .38.49.22.13.12.22.19.22.34.31 .01.00.00.00.00.00.00.00.00.00
8 .01.01.00.00.00.00.00.00.00.00 .35.09.24.15.20.31.23.42.20.41 .02.01.00.00.00.00.00.00.00.20 0.9
6 .02.01.00.00.00.00.00.00.00.00 .35.20.12.21.32.45.46.59.49.70 .01.01.00.00.00.00.00.00.00.00
4 .01.01.00.00.00.00.00.00.00.00 .39.30.36.15.18.49.62.34.54.32 .01.01.01.20.00.00.00.00.00.00 0.8
2 .02.01.01.01.00.00.00.00.00.00 .42.47.36.47.50.82.48.58.51.46 .02.01.00.01.00.01.00.00.01.01
0.7
TabPFNMid-Point TabPFNLog-Loss TabPFNPSCalLog-Loss
10 .03.01.01.00.00.00.00.00.00.00 .01.01.00.00.00.00.00.00.00.00 .01.01.00.00.00.00.00.00.00.00 0.6
8 .02.00.00.00.00.00.00.00.00.00 .02.01.00.00.00.00.00.00.00.00 .02.01.00.00.00.00.00.00.00.00
6 .02.01.01.00.00.00.00.00.00.00 .01.00.00.00.00.00.00.00.00.00 .01.01.00.00.00.00.00.00.00.00 0.5
4 .02.01.00.00.00.00.00.00.00.00 .01.00.00.00.00.00.00.00.00.00 .01.00.00.00.00.00.00.00.00.00
2 .02.02.01.00.00.00.00.00.00.00 .03.02.00.00.00.00.00.00.00.00 .03.02.00.00.00.00.00.00.00.00 0.4
GMMBaseline MINEBaseline PC-SoftmaxBaseline
0.3
10 .00.00.00.01.07.26.26.42.961.00.90.97.97.98.99.94.99.96.901.00.82.81.88.76.75.90.83.80.83.82
8 .00.00.00.01.09.29.26.50.971.00.72.95.981.00.991.00.971.001.00.99 .85.77.83.84.76.85.75.63.67.89 0.2
6 .01.00.00.01.07.27.26.44.98.39 .91.98.96.79.98.881.001.00.90.99 .68.84.78.73.76.78.75.77.90.76
4 .01.00.00.01.07.25.28.491.00.80 .69.77.78.83.80.99.82.99.82.89 .62.87.70.70.66.71.72.76.66.79 0.1
2 .01.01.01.02.11.53.40.701.001.00.82.57.95.801.00.22.70.62.911.00.58.68.47.48.49.46.57.46.46.56
0.0
2 4 6 8 101214161820 2 4 6 8 101214161820 2 4 6 8 101214161820
InputDimensions(d) InputDimensions(d) InputDimensions(d)
(a) Balanced MVN perturbation synthetic data set with 0% noise level
Vulnerable (cid:15)=0.0
AutoGluonMid-Point AutoGluonLog-Loss AutoGluonIRCalLog-Loss
1.0
10 .02.01.00.00.00.00.00.00.00.00 .44.24.17.13.08.33.23.28.37.30 .01.01.20.00.00.00.00.00.00.00
8 .02.01.00.00.00.00.00.00.00.00 .48.13.18.17.20.37.21.43.39.41 .01.01.00.00.00.00.00.00.00.00 0.9
6 .02.01.00.00.00.00.00.00.00.00 .49.15.16.20.26.35.29.37.39.38 .01.01.00.20.00.00.00.00.00.00
4 .02.01.00.00.00.00.00.00.00.00 .50.18.35.21.13.53.52.48.37.39 .01.01.01.00.00.00.00.00.00.00 0.8
2 .02.01.01.01.00.00.00.00.00.00 .49.55.40.38.34.51.44.58.53.44 .02.00.01.01.00.00.00.00.00.00
0.7
TabPFNMid-Point TabPFNLog-Loss TabPFNTSCalLog-Loss
10 .03.01.01.00.00.00.00.00.00.00 .01.01.00.00.00.00.00.00.00.00 .01.01.00.00.00.00.00.00.00.00 0.6
8 .02.00.00.00.00.00.00.00.00.00 .02.01.00.00.00.00.00.00.00.00 .02.01.00.00.00.00.00.00.00.00
6 .02.01.01.00.00.00.00.00.00.00 .01.00.00.00.00.00.00.00.00.00 .01.00.00.00.00.00.00.00.00.00 0.5
4 .02.01.00.00.00.00.00.00.00.00 .01.00.00.00.00.00.00.00.00.00 .01.00.00.00.00.00.00.00.00.00
2 .02.02.01.00.00.00.00.00.00.00 .03.02.00.00.00.00.00.00.00.00 .03.02.00.01.00.00.00.00.00.00 0.4
GMMBaseline MINEBaseline PC-SoftmaxBaseline
0.3
10 .00.00.00.01.07.26.26.42.961.00.90.97.97.98.99.94.99.96.901.00.82.81.88.76.75.90.83.80.83.82
8 .00.00.00.01.09.29.26.50.971.00.66.95.961.00.991.00.971.001.00.99 .85.77.83.84.76.85.75.63.67.89 0.2
6 .01.00.00.01.07.27.26.44.98.39 .91.98.96.79.98.881.001.00.90.99 .68.84.78.73.76.78.75.77.90.76
4 .01.00.00.01.07.25.28.491.00.80 .71.79.78.83.80.99.82.99.82.89 .62.87.70.70.66.71.72.76.66.79 0.1
2 .01.01.01.02.11.53.40.701.001.00.82.60.95.611.00.41.70.76.91.98 .58.68.47.48.49.46.57.46.46.56
0.0
2 4 6 8 101214161820 2 4 6 8 101214161820 2 4 6 8 101214161820
InputDimensions(d) InputDimensions(d) InputDimensions(d)
(b) Balanced MVN proximity synthetic data set with 0% noise level
Figure 12: Generalizability of MI estimation approaches on noise-free vulnerable systems
C.2.1 Number of Classes (M) and Input Dimensions (d)
To delve into a deeper understanding of the generalization capabilities of MI estimation
approaches with respect to the number of classes (M) and input dimensions (d), we analyze
theNMAEofdifferentapproachesbalancedsyntheticdatasets. Weexploretheirperformance
onvulnerablesyntheticsystemsatnoiselevelsof0%and50%, depictedinFigures12and13,
respectively. Similarly, we assess the performance on non-vulnerable synthetic systems at a
noise level of 100%, as showcased in Figure 14. The Y-axis ranges from 2 to 10, representing
60
)M(sessalC
)M(sessalC
)M(sessalC
)M(sessalC
)M(sessalC
)M(sessalCVulnerable (cid:15)=0.5
AutoGluonMid-Point AutoGluonLog-Loss AutoGluonIRCalLog-Loss
1.0
10 .22.22.25.22.30.22.22.22.22.22 .12.08.06.09.10.13.13.13.12.18 .15.22.31.24.16.17.13.09.15.06
8 .21.22.21.24.21.22.21.21.21.21 .20.12.16.13.11.07.11.13.15.12 .04.20.08.17.14.29.16.08.10.05 0.9
6 .21.21.24.21.21.21.21.21.21.24 .12.11.14.09.13.13.17.17.14.25 .05.11.18.16.17.11.09.10.11.10
4 .19.23.19.20.19.22.20.20.19.20 .18.15.19.15.22.16.10.10.10.08 .04.16.05.17.11.11.21.13.07.22 0.8
2 .16.17.20.20.24.21.22.19.21.20 .12.09.12.09.12.20.09.08.17.16 .08.13.22.22.35.22.28.27.26.20
0.7
TabPFNMid-Point TabPFNLog-Loss TabPFNPSCalLog-Loss
10 .21.21.22.22.22.22.22.22.22.23 .02.02.02.04.04.05.05.07.07.08 .02.02.03.04.05.07.06.08.09.10 0.6
8 .20.21.21.21.21.21.22.22.23.23 .07.06.06.04.04.03.03.03.03.03 .07.06.05.03.03.03.03.03.04.05
6 .20.21.21.21.21.21.21.21.22.23 .08.08.08.07.07.07.07.06.06.05 .07.08.07.07.06.05.04.03.03.03 0.5
4 .19.20.20.20.20.20.20.20.21.22 .07.07.08.09.10.11.12.12.12.13 .07.07.07.09.09.09.10.09.08.07
2 .15.16.15.15.16.16.16.15.18.19 .08.07.08.09.10.11.13.12.13.13 .08.07.08.09.09.10.12.12.11.12 0.4
GMMBaseline MINEBaseline PC-SoftmaxBaseline
0.3
10 .20.21.23.24.30.35.31.39.53.64 .24.26.28.31.30.32.31.30.31.30 .25.28.29.31.29.30.29.30.31.30
8 .11.09.14.19.27.27.28.33.53.57 .20.25.23.27.23.24.30.29.28.30 .25.28.28.29.28.26.29.30.28.27 0.2
6 .08.11.27.28.29.27.27.30.42.39 .23.19.28.23.26.23.29.26.25.22 .24.27.26.24.26.27.26.27.28.27
4 .02.05.16.22.25.28.27.31.34.39 .21.12.19.23.22.20.27.22.22.20 .22.26.22.24.25.23.22.22.23.25 0.1
2 .02.03.02.04.09.18.22.22.23.27 .15.20.21.22.26.24.30.22.26.21 .17.12.15.15.11.13.12.11.13.16
0.0
2 4 6 8 101214161820 2 4 6 8 101214161820 2 4 6 8 101214161820
InputDimensions(d) InputDimensions(d) InputDimensions(d)
(a) Balanced MVN perturbation synthetic data set with 50% noise level
Vulnerable (cid:15)=0.5
AutoGluonMid-Point AutoGluonLog-Loss AutoGluonIRCalLog-Loss
1.0
10 .04.03.02.02.02.00.00.00.00.00 .35.19.34.30.25.18.26.19.30.26 .02.03.02.12.02.20.11.00.20.10
8 .03.02.02.02.02.01.01.00.00.00 .23.43.32.15.25.27.34.32.26.24 .03.14.13.12.11.11.01.01.01.01 0.9
6 .02.03.02.02.02.01.01.01.01.00 .28.23.30.19.33.30.28.19.29.28 .03.05.03.02.02.12.01.01.11.01
4 .03.03.03.03.02.01.01.00.01.01 .28.26.42.32.29.39.19.15.26.17 .02.08.05.03.02.11.12.00.01.01 0.8
2 .06.04.04.04.02.02.02.01.01.01 .28.39.35.45.41.19.42.52.51.26 .07.07.06.05.03.02.02.01.01.03
0.7
TabPFNMid-Point TabPFNLog-Loss TabPFNTSCalLog-Loss
10 .05.05.03.01.01.01.00.00.01.00 .03.03.02.01.01.01.01.01.01.01 .03.03.02.01.01.01.01.01.01.01 0.6
8 .04.03.03.01.01.00.00.00.00.00 .04.04.03.02.01.00.00.00.00.00 .04.04.03.01.01.00.00.00.00.00
6 .04.03.02.01.00.00.00.00.00.00 .03.02.01.01.01.00.00.00.00.00 .03.02.01.01.01.00.00.00.00.00 0.5
4 .03.03.01.01.01.01.00.00.00.00 .03.03.03.01.01.00.00.00.00.00 .03.03.03.01.00.00.00.00.00.00
2 .06.04.02.02.01.01.00.00.01.00 .06.05.03.01.01.01.01.01.01.00 .05.04.03.01.01.01.01.01.01.00 0.4
GMMBaseline MINEBaseline PC-SoftmaxBaseline
0.3
10 .00.00.01.01.06.26.26.42.951.00.71.84.85.94.92.92.98.96.97.95 .69.71.81.84.89.89.81.83.85.90
8 .01.01.01.02.10.29.36.50.961.00.74.58.72.96.95.99.981.00.961.00.65.75.84.81.77.88.79.86.76.88 0.2
6 .01.08.00.01.06.27.26.44.971.00.63.68.84.85.98.82.75.99.92.84 .58.74.78.71.85.80.84.76.84.81
4 .01.01.01.01.05.29.27.49.89.80 .42.78.87.77.72.80.84.91.94.85 .52.69.72.75.79.78.67.81.78.83 0.1
2 .03.04.02.03.11.53.40.70.991.00.52.45.85.75.69.61.99.88.70.81 .37.54.55.49.54.64.66.51.73.71
0.0
2 4 6 8 101214161820 2 4 6 8 101214161820 2 4 6 8 101214161820
InputDimensions(d) InputDimensions(d) InputDimensions(d)
(b) Balanced MVN proximity synthetic data set with 50% noise level
Figure 13: Generalizability of MI estimation approaches on noisy vulnerable systems
the number of the classes in the synthetic data sets, while the X-axis ranges from 2 to 20,
representing the input dimensions (d).
TabPFN Overall, we observe that Mid-Point, Log-Loss, and Cal Log-Loss ap-
proaches employing TabPFN demonstrate remarkable generalization capabilities with regard
to the number of classes (M) and input dimensions (d), barring few exceptional cases
where the Mid-Point method falls short. For vulnerable synthetic data sets with higher
dimensionality (d 14), the TabPFN Mid-Point doesn’t perform as well, recording a
≥
maximum NMAE of 0.20, particularly for systems simulated using the MVN perturba-
tion technique. The performance of TabPFN Log-Loss and TabPFN Cal Log-Loss
61
)M(sessalC
)M(sessalC
)M(sessalC
)M(sessalC
)M(sessalC
)M(sessalCGupta, Wever and Hu¨llermeier
Non-vulnerable (cid:15)=1.0
AutoGluonMid-Point AutoGluonLog-Loss AutoGluonIRCalLog-Loss
1.0
10 .13.13.11.10.11.11.11.10.11.12 .01.01.00.01.00.00.00.00.00.06 .07.08.08.09.11.08.16.16.08.18
8 .11.11.12.15.20.14.07.10.08.15 .01.01.01.01.02.01.01.01.00.01 .06.07.09.12.21.12.06.09.06.19 0.9
6 .08.08.15.14.07.13.08.08.22.09 .01.01.01.01.01.00.01.01.01.01 .05.05.12.14.05.11.07.08.19.09
4 .08.07.05.06.26.17.20.10.13.16 .02.01.01.01.01.01.01.01.01.00 .04.04.04.05.31.10.26.10.14.12 0.8
2 .21.28.26.24.44.41.41.39.38.29 .05.02.02.01.07.04.01.03.02.01 .25.36.33.30.51.52.56.56.51.36
0.7
TabPFNMid-Point TabPFNLog-Loss TabPFNPSCalLog-Loss
10 .06.07.07.08.08.07.07.06.06.07 .01.01.01.01.01.01.01.01.01.01 .01.01.01.01.01.01.01.01.01.01 0.6
8 .06.05.04.02.01.01.01.01.00.00 .01.01.01.01.01.01.01.01.01.01 .01.01.01.01.01.01.01.01.01.01
6 .06.07.07.07.07.11.13.16.21.28 .01.01.01.01.01.01.01.01.01.01 .01.01.01.01.01.01.01.01.01.01 0.5
4 .06.08.09.09.12.15.20.21.29.36 .00.00.01.01.01.01.01.01.01.01 .00.00.01.01.01.01.01.01.01.01
2 .05.05.05.05.02.04.05.04.11.17 .00.00.00.00.00.00.00.00.00.00 .00.00.00.00.00.00.00.00.00.00 0.4
GMMBaseline MINEBaseline PC-SoftmaxBaseline
0.3
10 .01.01.03.06.19.42.41.53.87.96 .01.01.01.01.01.01.01.01.01.01 .01.01.01.01.01.01.01.01.01.01
8 .01.01.03.06.16.38.37.49.85.95 .01.01.01.00.01.01.01.01.01.01 .01.01.01.01.01.01.01.01.01.01 0.2
6 .01.01.02.05.14.34.34.45.81.94 .00.01.01.01.01.01.01.01.01.01 .00.01.01.01.01.01.01.01.01.01
4 .00.00.01.01.07.22.28.39.76.92 .01.01.03.02.03.02.02.03.01.00 .00.01.01.01.01.01.01.01.01.01 0.1
2 .01.02.02.03.02.11.10.25.38.53 .00.04.05.03.08.06.04.18.15.07 .00.01.01.01.02.00.00.01.02.00
0.0
2 4 6 8 101214161820 2 4 6 8 101214161820 2 4 6 8 101214161820
InputDimensions(d) InputDimensions(d) InputDimensions(d)
(a) Balanced MVN perturbation synthetic data set with 100% noise level
Non-vulnerable (cid:15)=1.0
AutoGluonMid-Point AutoGluonLog-Loss AutoGluonIRCalLog-Loss
1.0
10 .09.06.07.09.07.09.19.26.19.11 .03.10.08.13.07.10.22.24.13.20 .07.05.08.08.05.06.08.17.18.03
8 .07.05.11.11.11.08.22.28.22.13 .02.10.07.14.10.15.17.09.11.09 .05.04.04.13.12.07.21.18.15.06 0.9
6 .07.08.07.18.16.14.22.26.18.20 .04.03.06.10.13.14.14.19.17.09 .05.06.05.09.12.14.14.15.17.15
4 .05.10.12.12.21.10.30.17.17.12 .01.02.06.08.10.12.15.13.08.08 .03.07.12.11.13.09.25.16.23.06 0.8
2 .16.23.23.30.37.32.26.33.29.28 .01.03.03.08.09.17.20.20.10.15 .22.25.26.42.47.35.30.40.32.29
0.7
TabPFNMid-Point TabPFNLog-Loss TabPFNTSCalLog-Loss
10 .03.01.01.01.01.02.02.02.02.01 .01.01.01.02.01.01.01.02.01.01 .01.01.01.02.01.01.01.01.01.01 0.6
8 .04.02.02.01.02.02.02.02.03.02 .01.02.01.02.01.01.01.03.01.02 .01.02.01.02.01.01.01.02.01.01
6 .04.05.02.02.03.04.04.03.07.07 .02.02.01.02.02.02.02.02.02.02 .02.02.01.02.01.02.01.02.02.02 0.5
4 .05.07.08.06.07.06.07.06.09.13 .01.02.03.03.02.02.03.02.03.04 .01.02.03.03.02.02.02.01.02.02
2 .04.06.05.07.04.04.05.07.07.09 .01.01.02.03.02.02.02.03.02.02 .01.01.02.03.02.02.02.03.02.02 0.4
GMMBaseline MINEBaseline PC-SoftmaxBaseline
0.3
10 .01.01.01.01.03.06.14.29.55.48 .09.07.11.20.18.28.33.22.28.22 .11.13.14.22.21.24.32.31.23.24
8 .00.01.01.03.04.08.15.16.37.50 .07.08.10.18.13.18.16.29.24.21 .08.10.14.20.19.21.27.28.19.22 0.2
6 .01.01.01.02.02.08.06.18.37.45 .07.07.08.20.19.14.30.31.17.20 .06.07.11.17.16.18.30.23.19.22
4 .01.01.01.02.08.12.15.21.35.27 .02.04.07.20.15.17.20.21.15.24 .04.04.06.14.12.17.22.23.17.15 0.1
2 .01.01.01.05.05.13.23.19.21.33 .03.05.14.13.11.22.28.38.18.11 .01.02.03.06.07.11.20.13.08.08
0.0
2 4 6 8 101214161820 2 4 6 8 101214161820 2 4 6 8 101214161820
InputDimensions(d) InputDimensions(d) InputDimensions(d)
(b) Balanced MVN proximity synthetic data set with 100% noise level
Figure 14: Generalizability of MI estimation approaches on non-vulnerable systems
approaches on both the vulnerable systems (depicted in Figures 12 and 13) and the
non-vulnerable systems (shown in Figure 14) suggests that the overall precision of MI
estimation is largely independent of the underlying system’s data set’s number of classes (M)
and input dimensions (d). These approaches also consistently outperform the remaining,
achieving an NMAE nearly 0.01 in most cases, with the exception being the vulnerable
systems with a 50% noise, simulated using the MVN perturbation approach. Additionally,
it’s noteworthy that leveraging the calibration technique (Cal Log-Loss) doesn’t improve
the precision of MI estimation for the TabPFN Log-Loss approach, aligning with our
62
)M(sessalC
)M(sessalC
)M(sessalC
)M(sessalC
)M(sessalC
)M(sessalCprevious observations in Section 5.3.1. All these observations regarding the generalization
capability of the approaches using TabPFN align with our findings in Section 5.3.2.
Binary-class Imbalanced
AutoGluonMid-Point AutoGluonLog-Loss AutoGluonTSCalLog-Loss
1.0
1.0 .44 .26 .40 .29 .38 .28 .46 .32 .35 .25 .00 .00 .00 .00 .01 .02 .09 .03 .19 .01 .03 .00 .09 .09 .28 .19 .57 .39 .37 .34
0.9 .43 .33 .27 .27 .21 .16 .13 .18 .08 .12 .00 .01 .01 .01 .01 .01 .01 .01 .01 .00 .00 .01 .01 .01 .02 .02 .03 .19 .03 .10
0.8 .66 .51 .42 .31 .22 .18 .15 .12 .11 .17 .02 .02 .03 .03 .03 .03 .03 .02 .02 .01 .02 .02 .03 .03 .03 .02 .02 .05 .10 .14
0.7 .61 .52 .42 .32 .26 .21 .17 .17 .13 .13 .03 .04 .05 .05 .06 .06 .06 .05 .05 .04 .03 .04 .05 .05 .06 .03 .02 .08 .04 .06 0.9
0.6 .68 .53 .44 .33 .27 .22 .19 .15 .16 .18 .05 .07 .09 .10 .11 .11 .10 .10 .07 .07 .05 .07 .06 .10 .08 .04 .05 .06 .14 .13
0.5 .72 .54 .44 .35 .29 .23 .20 .18 .18 .16 .07 .12 .14 .14 .17 .15 .14 .10 .10 .13 .06 .09 .11 .11 .07 .06 .06 .09 .09 .10
0.4 .71 .56 .45 .37 .30 .24 .20 .17 .16 .18 .10 .16 .19 .20 .19 .21 .15 .15 .21 .18 .08 .07 .07 .11 .05 .07 .10 .03 .06 .09
0.3 .72 .55 .44 .36 .28 .22 .18 .18 .15 .17 .14 .22 .26 .25 .21 .25 .27 .16 .27 .19 .07 .06 .08 .11 .05 .07 .07 .14 .07 .15 0.8
0.2 .71 .56 .45 .36 .29 .23 .18 .17 .17 .13 .16 .26 .28 .33 .32 .35 .25 .21 .21 .29 .07 .04 .05 .05 .05 .03 .10 .10 .13 .08
0.1 .71 .54 .44 .34 .25 .21 .15 .14 .10 .11 .21 .31 .33 .37 .48 .22 .30 .19 .26 .44 .02 .06 .02 .02 .02 .09 .06 .09 .05 .04
0.0 .69 .51 .37 .26 .18 .11 .07 .03 .01 .01 .19 .41 .37 .52 .39 .40 .24 .29 .53 .46 .02 .02 .01 .01 .01 .01 .01 .02 .01 .01 0.7
TabPFNMid-Point TabPFNLog-Loss TabPFNIRCalLog-Loss
1.0 .81 .67 .55 .44 .33 .25 .18 .12 .05 .03 .11 .14 .15 .13 .09 .07 .04 .02 .00 .00 .02 .01 .01 .01 .02 .01 .02 .03 .05 .02
0.9 .80 .67 .54 .43 .33 .25 .17 .11 .06 .07 .11 .14 .14 .12 .09 .06 .03 .02 .00 .00 .02 .02 .04 .02 .04 .02 .02 .03 .03 .05 0.6
0.8 .79 .65 .52 .41 .31 .23 .15 .11 .09 .10 .10 .13 .13 .12 .09 .06 .03 .01 .01 .01 .03 .04 .05 .04 .03 .04 .04 .03 .04 .04
0.7 .77 .63 .49 .40 .31 .24 .19 .14 .12 .13 .09 .13 .13 .13 .11 .07 .04 .02 .02 .02 .04 .06 .05 .06 .06 .05 .05 .05 .05 .05
0.6 .76 .62 .49 .38 .31 .24 .20 .16 .14 .16 .09 .13 .13 .13 .12 .08 .05 .04 .05 .05 .05 .07 .08 .07 .09 .05 .05 .06 .07 .07
0.5 .76 .60 .47 .38 .30 .23 .19 .17 .15 .17 .08 .11 .11 .12 .11 .08 .06 .07 .07 .07 .07 .07 .07 .08 .06 .05 .04 .09 .07 .07 0.5
0.4 .75 .59 .48 .37 .29 .24 .19 .17 .16 .16 .07 .09 .11 .11 .11 .09 .07 .08 .08 .09 .07 .08 .08 .08 .07 .04 .03 .07 .07 .08
0.3 .73 .60 .47 .37 .30 .25 .19 .16 .14 .15 .05 .08 .09 .11 .12 .10 .09 .09 .09 .10 .05 .07 .05 .08 .10 .08 .05 .08 .08 .10
0.2 .74 .57 .46 .37 .30 .23 .19 .15 .14 .14 .04 .05 .09 .11 .11 .09 .09 .10 .11 .11 .04 .04 .08 .08 .07 .04 .04 .07 .08 .07
0.1 .73 .57 .43 .34 .26 .20 .15 .11 .11 .10 .02 .03 .06 .07 .08 .08 .07 .08 .11 .09 .03 .04 .07 .06 .07 .06 .05 .06 .09 .07 0.4
0.0 .71 .52 .39 .28 .18 .10 .05 .03 .01 .01 .00 .00 .00 .01 .00 .01 .01 .01 .00 .01 .00 .00 .01 .01 .00 .00 .01 .01 .00 .01
GMMBaseline MINEBaseline PC-SoftmaxBaseline
1.0 .00 .01 .00 .02 .00 .01 .00 .01 .01 .01 .00 .00 .00 .00 .00 .00 .03 .02 .01 .01 .00 .00 .00 .00 .00 .02 .00 .03 .01 .00 0.3
0.9 .01 .01 .01 .02 .01 .01 .01 .01 .01 .01 .02 .01 .04 .01 .01 .01 .03 .02 .02 .01 .00 .01 .01 .01 .01 .01 .00 .01 .00 .01
0.8 .00 .01 .01 .01 .02 .02 .02 .02 .03 .00 .02 .02 .02 .02 .03 .03 .02 .05 .04 .04 .01 .02 .02 .02 .02 .01 .01 .03 .02 .01
0.7 .02 .01 .01 .02 .02 .04 .03 .02 .01 .02 .04 .04 .05 .05 .06 .09 .04 .06 .07 .05 .03 .04 .05 .04 .05 .04 .05 .04 .06 .04 0.2
0.6 .01 .02 .02 .02 .02 .01 .01 .03 .01 .02 .05 .06 .07 .08 .06 .06 .09 .13 .09 .09 .03 .06 .06 .07 .07 .08 .09 .07 .12 .05
0.5 .02 .03 .03 .01 .03 .02 .02 .04 .02 .03 .05 .10 .13 .13 .13 .13 .13 .11 .12 .13 .06 .07 .10 .12 .11 .12 .10 .13 .13 .13
0.4 .01 .02 .02 .03 .04 .01 .03 .02 .03 .03 .09 .14 .15 .20 .13 .16 .20 .18 .19 .26 .08 .14 .12 .17 .15 .15 .18 .13 .15 .20
0.3 .02 .02 .02 .04 .04 .03 .02 .02 .05 .02 .10 .14 .21 .27 .25 .18 .30 .31 .31 .24 .08 .14 .17 .22 .25 .29 .18 .27 .31 .30 0.1
0.2 .03 .02 .01 .01 .02 .02 .02 .02 .02 .02 .12 .09 .23 .28 .22 .38 .49 .41 .23 .41 .12 .19 .22 .29 .25 .28 .29 .27 .27 .36
0.1 .01 .02 .03 .03 .03 .03 .02 .02 .02 .01 .17 .22 .36 .17 .29 .30 .54 .41 .68 .17 .14 .24 .30 .34 .42 .35 .58 .37 .54 .48
0.0 .00 .01 .01 .00 .00 .18 .01 .01 .01 .00 .23 .36 .49 .42 .43 .71 .56 .76 .74 .42 .20 .33 .37 .36 .43 .47 .59 .63 .73 .66 0.0
ClassImbalance(r) ClassImbalance(r) ClassImbalance(r)
Figure 15: Generalizability of MI estimation approaches on MVN perturbation synthetic
binary-class imbalanced data sets
AutoGluon Overall, we observe that Mid-Point, Log-Loss and Cal Log-Loss
approaches using AutoGluon mostly generalize well with respect to the number of classes
(M) and input dimensions (d), with a few exceptional cases, which are missed in the analysis
in Section 5.3.2. Notably, the Mid-Point and Cal Log-Loss employing AutoGluon
overestimates MI due to overfitting within a non-vulnerable system produces a binary-class
data set (M = 2), which backs up the observation that the corresponding ILD approaches
detects non-existent ILs and produces false positives. The performance of AutoGluon
Cal Log-Loss sometimes deteriorates with the increasing number of classes and input
dimensions of the vulnerable synthetic data set. As observed in Section 5.3.1, the usage of
calibration techniques by AutoGluon Log-Loss approach mostly leads to overfitting and
overestimating MI in non-vulnerable systems, while in case of vulnerable systems it
mostly improves the precision of estimated MI as depicted in Figure 14 and Figures 12
and 13, respectively. All these observations regarding the generalization capability of the
approaches using AutoGluon align with our findings in Section 5.3.2.
Baselines All baseline approaches display diminished generalization capability for both
the vulnerable systems and the non-vulnerable systems, as performance consistently
63
)(cid:15)(egatnecrePpilF
)(cid:15)(egatnecrePpilF
)(cid:15)(egatnecrePpilF
50.0 1.0 51.0 2.0 52.0 3.0 53.0 4.0 54.0 5.0 50.0 1.0 51.0 2.0 52.0 3.0 53.0 4.0 54.0 5.0 50.0 1.0 51.0 2.0 52.0 3.0 53.0 4.0 54.0 5.0Gupta, Wever and Hu¨llermeier
Binary-class Imbalanced
AutoGluonMid-Point AutoGluonLog-Loss AutoGluonTSCalLog-Loss
1.0
1.0 .83 .82 .68 .60 .48 .47 .44 .46 .26 .39 .08 .13 .19 .07 .15 .08 .13 .05 .00 .17 .07 .35 .31 .43 .21 .51 .56 .63 .30 .37
0.9 .82 .62 .62 .52 .46 .38 .28 .22 .18 .12 .11 .15 .13 .14 .26 .13 .14 .14 .11 .14 .14 .25 .37 .38 .38 .35 .27 .19 .13 .05
0.8 .79 .71 .57 .51 .42 .34 .22 .18 .20 .12 .10 .19 .15 .18 .20 .11 .10 .08 .06 .15 .10 .22 .25 .36 .22 .31 .18 .17 .21 .06
0.7 .77 .65 .56 .47 .40 .33 .26 .28 .15 .12 .09 .17 .19 .07 .10 .13 .03 .02 .10 .11 .12 .15 .19 .30 .27 .25 .28 .35 .16 .10 0.9
0.6 .75 .56 .55 .44 .28 .24 .19 .15 .11 .09 .05 .10 .07 .06 .03 .05 .07 .09 .14 .18 .08 .11 .24 .24 .14 .14 .15 .16 .16 .09
0.5 .75 .61 .49 .37 .28 .19 .16 .08 .07 .07 .09 .08 .08 .10 .05 .12 .19 .14 .29 .31 .06 .09 .15 .13 .16 .11 .12 .08 .09 .10
0.4 .73 .56 .44 .31 .22 .17 .14 .06 .03 .04 .14 .20 .25 .24 .31 .36 .29 .20 .38 .24 .03 .05 .07 .07 .06 .07 .12 .06 .03 .06
0.3 .71 .54 .42 .27 .21 .14 .08 .03 .02 .04 .17 .28 .17 .39 .33 .23 .36 .26 .40 .46 .02 .02 .06 .02 .05 .03 .05 .02 .01 .05 0.8
0.2 .72 .54 .40 .28 .18 .12 .08 .04 .02 .02 .17 .23 .29 .45 .35 .34 .52 .32 .43 .41 .02 .02 .03 .03 .03 .04 .04 .03 .03 .03
0.1 .71 .53 .39 .28 .19 .12 .07 .03 .01 .02 .17 .21 .31 .50 .36 .45 .42 .45 .59 .39 .01 .01 .02 .02 .03 .02 .02 .02 .02 .02
0.0 .71 .53 .39 .28 .19 .13 .07 .03 .02 .01 .04 .36 .33 .48 .52 .39 .48 .43 .42 .50 .00 .01 .01 .01 .01 .02 .02 .02 .02 .01 0.7
TabPFNMid-Point TabPFNLog-Loss TabPFNIRCalLog-Loss
1.0 .81 .67 .55 .44 .34 .26 .18 .11 .05 .01 .12 .15 .14 .12 .09 .07 .04 .02 .00 .00 .00 .00 .01 .01 .00 .00 .01 .01 .01 .00
0.9 .78 .62 .49 .39 .29 .21 .15 .11 .08 .08 .09 .11 .10 .09 .08 .05 .05 .04 .02 .02 .02 .02 .04 .04 .03 .02 .03 .04 .03 .03 0.6
0.8 .76 .59 .46 .36 .27 .20 .15 .12 .09 .09 .08 .08 .09 .09 .09 .07 .07 .07 .06 .06 .02 .03 .03 .04 .04 .03 .04 .05 .04 .04
0.7 .74 .57 .43 .33 .25 .18 .14 .11 .08 .08 .06 .07 .07 .08 .09 .07 .08 .08 .07 .07 .02 .03 .04 .04 .04 .03 .04 .05 .05 .05
0.6 .73 .55 .42 .31 .23 .16 .11 .08 .05 .05 .04 .05 .06 .06 .08 .06 .07 .07 .07 .07 .02 .02 .03 .04 .04 .02 .03 .05 .05 .05
0.5 .72 .54 .40 .29 .21 .15 .09 .05 .02 .02 .03 .04 .05 .05 .06 .05 .05 .06 .05 .06 .02 .03 .03 .03 .04 .02 .03 .04 .03 .03 0.5
0.4 .72 .54 .40 .28 .20 .13 .07 .03 .02 .02 .02 .02 .03 .03 .04 .03 .04 .04 .04 .04 .02 .02 .02 .03 .04 .03 .02 .02 .03 .02
0.3 .71 .53 .39 .27 .19 .12 .06 .03 .01 .01 .01 .01 .02 .02 .03 .02 .02 .03 .03 .02 .01 .02 .02 .02 .03 .02 .02 .02 .01 .01
0.2 .71 .52 .38 .27 .18 .11 .05 .02 .01 .02 .01 .01 .01 .02 .02 .02 .02 .02 .02 .02 .01 .01 .02 .02 .02 .02 .02 .02 .01 .01
0.1 .71 .52 .38 .27 .18 .11 .06 .02 .01 .01 .01 .00 .01 .01 .01 .01 .01 .01 .01 .01 .01 .00 .01 .01 .01 .02 .01 .02 .01 .01 0.4
0.0 .71 .52 .39 .27 .18 .11 .06 .02 .01 .01 .01 .00 .01 .01 .01 .01 .01 .01 .01 .01 .00 .00 .01 .01 .01 .01 .01 .01 .01 .01
GMMBaseline MINEBaseline PC-SoftmaxBaseline
1.0 .00 .00 .00 .00 .00 .01 .01 .01 .01 .01 .01 .00 .03 .00 .04 .00 .00 .02 .03 .01 .00 .01 .00 .00 .00 .01 .00 .00 .00 .01 0.3
0.9 .01 .01 .01 .01 .01 .02 .01 .01 .01 .01 .07 .11 .12 .14 .17 .19 .23 .20 .22 .08 .05 .09 .08 .13 .15 .10 .16 .16 .19 .17
0.8 .01 .01 .02 .02 .02 .02 .02 .02 .01 .02 .09 .13 .21 .20 .09 .24 .30 .29 .32 .32 .07 .11 .14 .18 .22 .22 .22 .21 .21 .28
0.7 .02 .01 .02 .03 .03 .02 .01 .02 .02 .01 .12 .14 .21 .15 .29 .31 .42 .32 .39 .34 .09 .12 .18 .20 .26 .26 .23 .30 .22 .38 0.2
0.6 .02 .02 .03 .03 .03 .02 .03 .03 .02 .02 .11 .25 .26 .35 .33 .51 .46 .51 .37 .46 .11 .20 .27 .31 .28 .35 .30 .34 .34 .38
0.5 .01 .01 .02 .01 .02 .02 .03 .04 .01 .01 .19 .24 .19 .29 .42 .44 .57 .65 .48 .69 .14 .22 .30 .43 .30 .42 .38 .31 .32 .33
0.4 .01 .01 .01 .01 .01 .01 .02 .03 .02 .02 .14 .35 .28 .39 .37 .59 .46 .43 .49 .49 .16 .28 .33 .35 .46 .40 .49 .53 .58 .56
0.3 .01 .01 .01 .01 .02 .17 .02 .02 .02 .01 .20 .24 .40 .47 .60 .77 .68 .46 .71 .69 .17 .26 .42 .39 .51 .54 .62 .53 .62 .52 0.1
0.2 .01 .01 .00 .01 .01 .01 .01 .01 .01 .01 .15 .33 .44 .63 .44 .64 .68 .83 .40 .71 .18 .33 .42 .45 .47 .52 .67 .67 .58 .71
0.1 .01 .10 .00 .00 .01 .01 .01 .01 .01 .01 .23 .44 .41 .41 .47 .81 .69 .41 .59 .76 .20 .34 .37 .40 .59 .43 .59 .53 .65 .55
0.0 .00 .09 .00 .00 .00 .00 .01 .01 .01 .00 .27 .44 .48 .68 .63 .81 .70 .80 .40 .61 .23 .29 .32 .54 .58 .42 .54 .64 .58 .56 0.0
ClassImbalance(r) ClassImbalance(r) ClassImbalance(r)
Figure 16: Generalizability of MI estimation approaches on MVN proximity synthetic binary-
class imbalanced data sets
deteriorates when the number of classes (M) and input dimensions (d) increases. Specifically,
the GMM baseline encounters significant challenges when dealing with high-dimensional
data sets, resulting in substantial performance degradation beyond 10 input dimensions,
aligning with the well-known limitations of GMM in high-dimensional spaces. Overall, GMM
baseline performs better than the PC-Softmax and MINE baselines, except in the case
of non-vulnerable synthetic systems simulated using MVN perturbation technique, as also
observed in Section 5.3.1. All these observations regarding the generalization capability of
the baselines align with our findings in Section 5.3.2.
C.2.2 Class Imbalance (r) And Noise Level (ϵ)
To delve into a deeper understanding of the generalization capabilities of MI estimation
approaches with respect to the class imbalance (r) and noise level (ϵ) (referred to as flip
percentage (ϵ) in case of MVN perturbation data set), we analyze the NMAE of different
approaches within binary-class and multi-class imbalance synthetic data set. We explore
their performance on binary-class synthetic data sets simulated using the MVN perturbation
and the MVN proximity technique, employing the heatmaps illustrated in Figures 15 and 16,
respectively. Similarly, the performance assessment using multi-class synthetic data sets
64
)(cid:15)(leveLesioN
)(cid:15)(leveLesioN
)(cid:15)(leveLesioN
50.0 1.0 51.0 2.0 52.0 3.0 53.0 4.0 54.0 5.0 50.0 1.0 51.0 2.0 52.0 3.0 53.0 4.0 54.0 5.0 50.0 1.0 51.0 2.0 52.0 3.0 53.0 4.0 54.0 5.0Multi-class Imbalanced
AutoGluonMid-Point AutoGluonLog-Loss AutoGluonBetaCalLog-Loss
1.0
1.0 .09 .34 .15 .07 .11 .18 .08 .05 .03 .13 .00 .00 .00 .00 .00 .01 .00 .00 .00 .00 .00 .00 .00 .00 .00 .01 .00 .00 .00 .00
0.9 .37 .55 .44 .30 .24 .19 .15 .11 .10 .09 .01 .02 .01 .01 .01 .01 .01 .01 .01 .01 .01 .02 .01 .01 .01 .01 .01 .01 .01 .01
0.8 .45 .38 .52 .38 .30 .24 .20 .20 .16 .15 .04 .04 .04 .04 .04 .03 .03 .03 .02 .03 .04 .04 .03 .04 .03 .04 .03 .03 .02 .02
0.7 .49 .44 .57 .42 .33 .28 .24 .21 .20 .20 .07 .09 .08 .07 .06 .07 .06 .06 .05 .05 .07 .09 .08 .09 .08 .06 .06 .03 .02 .06 0.9
0.6 .54 .45 .59 .45 .35 .29 .25 .23 .22 .22 .12 .14 .14 .12 .12 .11 .09 .09 .06 .06 .09 .13 .11 .11 .09 .08 .04 .05 .06 .06
0.5 .52 .44 .61 .44 .35 .29 .25 .23 .21 .21 .13 .16 .18 .17 .17 .15 .12 .06 .05 .10 .13 .21 .16 .16 .12 .10 .09 .12 .12 .12
0.4 .53 .44 .59 .44 .34 .28 .24 .21 .20 .19 .18 .25 .23 .25 .20 .17 .12 .16 .12 .15 .18 .21 .22 .15 .12 .10 .13 .05 .07 .19
0.3 .51 .43 .57 .42 .33 .26 .22 .19 .18 .17 .26 .31 .31 .26 .21 .25 .11 .14 .16 .11 .22 .27 .25 .15 .12 .10 .16 .14 .14 .20 0.8
0.2 .50 .41 .55 .39 .31 .24 .19 .16 .14 .14 .32 .40 .35 .33 .22 .21 .16 .16 .21 .13 .23 .27 .12 .14 .12 .09 .16 .13 .17 .14
0.1 .48 .38 .52 .34 .25 .18 .14 .12 .10 .09 .36 .30 .27 .28 .34 .27 .22 .19 .22 .35 .18 .20 .10 .14 .14 .11 .14 .12 .11 .33
0.0 .42 .32 .43 .26 .16 .10 .05 .02 .01 .00 .19 .33 .17 .13 .23 .14 .10 .27 .21 .15 .09 .14 .07 .04 .09 .04 .03 .16 .13 .06 0.7
TabPFNMid-Point TabPFNLog-Loss TabPFNIRCalLog-Loss
1.0 .47 .40 .28 .43 .32 .25 .17 .12 .07 .03 .13 .17 .14 .11 .08 .05 .03 .01 .00 .00 .02 .02 .02 .02 .02 .01 .02 .01 .01 .01
0.9 .49 .42 .30 .44 .33 .25 .18 .12 .07 .09 .12 .16 .13 .10 .07 .05 .03 .01 .01 .01 .03 .02 .02 .02 .02 .01 .01 .01 .01 .01 0.6
0.8 .52 .45 .32 .46 .35 .27 .21 .16 .13 .15 .11 .15 .13 .10 .07 .05 .03 .02 .03 .03 .03 .04 .03 .03 .02 .02 .01 .02 .01 .01
0.7 .53 .46 .33 .46 .35 .27 .23 .20 .20 .19 .10 .14 .12 .09 .06 .04 .02 .02 .02 .03 .04 .05 .04 .05 .04 .02 .03 .02 .02 .02
0.6 .54 .45 .61 .45 .35 .29 .25 .23 .21 .21 .10 .14 .13 .10 .08 .05 .04 .03 .02 .02 .05 .07 .05 .05 .04 .03 .03 .03 .03 .03
0.5 .53 .45 .60 .45 .35 .29 .24 .22 .21 .21 .11 .15 .14 .12 .11 .08 .08 .07 .06 .07 .05 .08 .05 .05 .05 .03 .03 .03 .03 .04 0.5
0.4 .53 .45 .59 .44 .34 .28 .23 .21 .19 .19 .11 .14 .13 .13 .13 .12 .12 .11 .10 .11 .05 .06 .04 .05 .05 .04 .04 .03 .03 .04
0.3 .51 .43 .57 .42 .32 .25 .21 .18 .17 .17 .11 .14 .13 .14 .13 .12 .14 .13 .13 .14 .05 .05 .04 .05 .04 .02 .03 .02 .03 .03
0.2 .50 .41 .54 .39 .30 .23 .19 .16 .14 .14 .10 .12 .12 .13 .13 .13 .14 .13 .14 .14 .05 .04 .04 .04 .04 .03 .04 .02 .03 .04
0.1 .48 .39 .51 .35 .25 .18 .14 .11 .10 .08 .07 .08 .09 .10 .10 .09 .10 .10 .11 .10 .03 .03 .04 .03 .03 .02 .03 .03 .03 .03 0.4
0.0 .43 .33 .43 .26 .16 .09 .05 .02 .01 .01 .00 .00 .00 .01 .00 .00 .00 .00 .00 .00 .01 .01 .01 .01 .00 .00 .00 .01 .00 .01
GMMBaseline MINEBaseline PC-SoftmaxBaseline
1.0 .00 .00 .00 .00 .00 .00 .00 .00 .01 .00 .00 .00 .00 .00 .00 .01 .00 .00 .00 .00 .00 .00 .00 .00 .00 .00 .00 .00 .01 .00 0.3
0.9 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .02 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01
0.8 .03 .05 .04 .04 .04 .03 .03 .03 .03 .03 .04 .05 .04 .04 .04 .02 .04 .03 .04 .03 .04 .04 .04 .04 .04 .04 .04 .04 .04 .04
0.7 .06 .08 .07 .08 .07 .06 .05 .05 .07 .07 .06 .09 .09 .07 .06 .08 .07 .07 .07 .07 .07 .08 .08 .08 .08 .08 .08 .07 .08 .08 0.2
0.6 .10 .11 .15 .12 .07 .09 .09 .11 .11 .10 .10 .12 .13 .10 .09 .14 .16 .14 .12 .13 .11 .15 .15 .13 .12 .13 .13 .12 .12 .11
0.5 .14 .14 .16 .08 .12 .12 .11 .15 .16 .16 .18 .20 .22 .24 .16 .17 .19 .21 .20 .15 .15 .22 .20 .21 .19 .21 .20 .19 .18 .19
0.4 .16 .20 .19 .17 .13 .14 .13 .11 .17 .10 .23 .33 .27 .21 .24 .25 .27 .23 .33 .09 .24 .26 .28 .30 .26 .26 .26 .29 .28 .30
0.3 .17 .30 .29 .21 .19 .16 .18 .17 .15 .12 .26 .40 .42 .41 .36 .38 .36 .40 .36 .21 .30 .38 .36 .39 .28 .38 .34 .38 .34 .33 0.1
0.2 .16 .18 .24 .24 .22 .15 .23 .16 .18 .20 .43 .55 .50 .55 .51 .49 .48 .36 .42 .35 .37 .48 .49 .41 .42 .42 .43 .48 .44 .41
0.1 .14 .16 .14 .23 .25 .30 .20 .22 .15 .27 .49 .64 .50 .68 .59 .69 .62 .61 .70 .66 .50 .61 .54 .63 .55 .52 .56 .59 .51 .60
0.0 .00 .00 .00 .00 .00 .00 .00 .00 .10 .00 .70 .93 .95 .84 .84 .98 .89 .81 .77 .55 .56 .76 .79 .90 .72 .74 .76 .64 .74 .79 0.0
ClassImbalance(r) ClassImbalance(r) ClassImbalance(r)
Figure 17: Generalizability of MI estimation approaches on MVN perturbation synthetic
multi-class imbalanced data sets
simulated using the MVN perturbation and the MVN proximity technique, employing the
heatmaps, is illustrated in Figures 17 and 18, respectively. The Y-axis ranges from 0.0 to
1.0, representing the noise level (ϵ) in the synthetic data set. In contrast, the X-axis ranges
from 0.05 to 0.5 for the binary-class imbalanced synthetic data sets and from 0.02 to 0.2 for
the multi-class imbalanced synthetic data sets, representing the degree of class imbalance.
TabPFN Overall, we observe that Log-Loss and Cal Log-Loss approaches employ-
ing TabPFN demonstrate remarkable generalization capabilities with regard to the class
imbalance and noise level, indicating their resilience to variations in class imbalance and
noise level in binary-class and multi-class imbalance synthetic data sets. The TabPFN
Mid-Point demonstrates remarkable generalization capabilities with regard to the noise
level, while it underperforms on the synthetic data sets with a high degree of class imbalance.
As elaborated in Section 3.1, the Mid-Point strategy tends to overestimate MI in synthetic
data sets pronounced class imbalance. The use of calibration techniques (Cal Log-Loss)
with TabPFN Log-Loss approach, results in an appreciable improvement in MI estimation
precision, specially in case of multi-class systems simulated using the perturbation tech-
nique. All these observations regarding the generalization capability of the approaches using
TabPFN align with our findings in Section 5.3.2.
65
)(cid:15)(egatnecrePpilF
)(cid:15)(egatnecrePpilF
)(cid:15)(egatnecrePpilF
20.0 40.0 60.0 80.0 1.0 21.0 41.0 61.0 81.0 2.0 20.0 40.0 60.0 80.0 1.0 21.0 41.0 61.0 81.0 2.0 20.0 40.0 60.0 80.0 1.0 21.0 41.0 61.0 81.0 2.0Gupta, Wever and Hu¨llermeier
Multi-class Imbalanced
AutoGluonMid-Point AutoGluonLog-Loss AutoGluonIRCalLog-Loss
1.0
1.0 .61 .58 .49 .38 .55 .47 .36 .24 .13 .14 .29 .49 .48 .46 .46 .31 .31 .15 .04 .10 .23 .35 .34 .26 .37 .18 .18 .16 .11 .14
0.9 .53 .50 .60 .42 .35 .31 .21 .22 .22 .22 .22 .35 .19 .26 .38 .22 .13 .20 .19 .24 .18 .33 .28 .23 .24 .22 .17 .11 .19 .13
0.8 .46 .36 .49 .35 .25 .17 .10 .10 .09 .09 .08 .09 .15 .11 .11 .10 .10 .10 .11 .15 .08 .13 .13 .14 .10 .08 .08 .19 .09 .09
0.7 .52 .35 .50 .28 .21 .17 .13 .07 .04 .04 .13 .10 .09 .05 .11 .12 .10 .11 .13 .30 .11 .09 .12 .10 .06 .07 .06 .07 .08 .07 0.9
0.6 .46 .34 .46 .27 .17 .13 .07 .04 .02 .02 .04 .02 .06 .06 .06 .06 .10 .09 .16 .27 .18 .08 .07 .08 .08 .09 .08 .07 .07 .07
0.5 .43 .32 .43 .27 .18 .11 .07 .02 .03 .01 .06 .03 .04 .03 .10 .14 .15 .19 .20 .16 .06 .05 .06 .16 .07 .03 .03 .04 .07 .05
0.4 .44 .33 .45 .27 .17 .12 .07 .03 .03 .02 .05 .02 .08 .03 .09 .06 .10 .17 .19 .27 .04 .04 .03 .04 .05 .03 .05 .04 .04 .03
0.3 .45 .33 .43 .27 .16 .10 .06 .05 .02 .01 .04 .08 .04 .07 .14 .06 .17 .13 .18 .29 .03 .02 .03 .03 .03 .02 .13 .04 .02 .02 0.8
0.2 .43 .33 .44 .27 .16 .10 .05 .03 .01 .01 .03 .04 .05 .09 .05 .09 .07 .16 .19 .29 .02 .02 .03 .03 .02 .02 .02 .02 .03 .03
0.1 .43 .33 .43 .27 .17 .09 .05 .02 .01 .01 .02 .03 .05 .03 .12 .11 .12 .06 .15 .35 .02 .01 .01 .01 .02 .01 .01 .01 .02 .01
0.0 .43 .33 .43 .26 .17 .10 .06 .03 .01 .00 .03 .04 .09 .07 .05 .06 .07 .19 .21 .21 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 0.7
TabPFNMid-Point TabPFNLog-Loss TabPFNIRCalLog-Loss
1.0 .46 .40 .28 .43 .32 .25 .18 .12 .07 .03 .13 .17 .14 .11 .08 .05 .03 .01 .00 .00 .02 .02 .01 .01 .01 .01 .01 .01 .01 .01
0.9 .48 .39 .54 .37 .26 .19 .14 .11 .08 .07 .09 .11 .10 .08 .07 .06 .05 .04 .03 .03 .04 .03 .03 .03 .03 .03 .03 .03 .02 .03 0.6
0.8 .45 .35 .47 .30 .20 .13 .08 .05 .03 .03 .07 .08 .07 .06 .05 .05 .04 .04 .04 .04 .03 .03 .03 .03 .03 .02 .02 .02 .02 .02
0.7 .43 .33 .43 .26 .16 .09 .05 .03 .02 .01 .05 .05 .05 .05 .05 .04 .04 .04 .04 .04 .03 .03 .03 .03 .02 .02 .02 .02 .02 .02
0.6 .42 .32 .41 .24 .15 .09 .04 .02 .02 .02 .04 .04 .04 .04 .04 .03 .03 .04 .03 .04 .02 .02 .02 .02 .02 .02 .02 .02 .02 .02
0.5 .42 .31 .41 .24 .14 .08 .04 .02 .02 .02 .03 .03 .03 .03 .03 .03 .03 .03 .03 .03 .02 .02 .02 .02 .02 .01 .01 .02 .02 .02 0.5
0.4 .42 .31 .41 .24 .15 .08 .05 .02 .02 .02 .02 .02 .02 .02 .02 .02 .02 .02 .02 .02 .02 .02 .02 .02 .02 .01 .01 .01 .01 .02
0.3 .42 .32 .42 .25 .15 .09 .05 .02 .01 .01 .01 .02 .02 .02 .02 .01 .01 .01 .01 .02 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01
0.2 .42 .32 .42 .26 .16 .09 .05 .02 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01
0.1 .42 .32 .42 .26 .16 .09 .05 .02 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 .01 0.4
0.0 .43 .32 .43 .26 .16 .09 .05 .02 .01 .01 .00 .00 .00 .01 .00 .00 .00 .01 .00 .00 .01 .00 .01 .01 .01 .00 .01 .01 .01 .01
GMMBaseline MINEBaseline PC-SoftmaxBaseline
1.0 .03 .00 .00 .00 .00 .00 .00 .00 .00 .00 .02 .00 .00 .00 .01 .01 .01 .01 .02 .01 .00 .00 .01 .01 .00 .00 .01 .00 .00 .00 0.3
0.9 .01 .07 .07 .06 .01 .01 .01 .02 .01 .01 .21 .16 .25 .27 .26 .28 .24 .26 .23 .29 .20 .22 .28 .27 .28 .25 .20 .28 .23 .20
0.8 .02 .06 .02 .03 .01 .01 .04 .04 .01 .01 .33 .43 .39 .46 .23 .43 .37 .39 .44 .25 .31 .40 .39 .44 .38 .38 .35 .39 .40 .39
0.7 .02 .02 .02 .02 .01 .02 .03 .01 .02 .01 .44 .46 .40 .49 .55 .56 .45 .56 .42 .41 .37 .50 .52 .48 .49 .49 .48 .49 .51 .50 0.2
0.6 .01 .13 .03 .01 .00 .07 .01 .01 .02 .01 .45 .59 .47 .68 .37 .45 .55 .63 .56 .61 .42 .55 .60 .53 .56 .56 .52 .58 .58 .55
0.5 .01 .03 .02 .09 .11 .00 .01 .01 .01 .01 .42 .66 .67 .80 .74 .67 .69 .66 .64 .67 .53 .63 .63 .69 .59 .61 .64 .65 .61 .59
0.4 .01 .10 .02 .00 .00 .01 .00 .09 .01 .01 .59 .80 .76 .56 .69 .65 .64 .72 .71 .86 .51 .77 .62 .71 .65 .70 .71 .63 .67 .71
0.3 .01 .01 .01 .01 .00 .00 .01 .01 .01 .01 .55 .77 .85 .81 .77 .77 .63 .64 .83 .90 .54 .70 .66 .71 .76 .65 .69 .74 .67 .80 0.1
0.2 .09 .01 .01 .01 .00 .01 .01 .01 .01 .01 .60 .86 .87 .87 .78 .67 .67 .58 .80 .69 .57 .76 .79 .72 .62 .70 .73 .76 .77 .65
0.1 .01 .01 .01 .00 .00 .01 .01 .01 .00 .00 .63 .86 .87 .76 .72 .72 .84 .61 .75 .70 .51 .74 .82 .75 .75 .76 .69 .84 .69 .83
0.0 .00 .01 .01 .02 .00 .02 .00 .00 .00 .00 .55 .75 .86 .82 .87 .85 .79 .87 .89 .84 .54 .65 .74 .75 .70 .69 .69 .70 .70 .73 0.0
ClassImbalance(r) ClassImbalance(r) ClassImbalance(r)
Figure 18: Generalizability of MI estimation approaches on MVN proximity synthetic multi-
class imbalanced data sets
AutoGluon The generalization capabilities of Mid-Point, Log-Loss, and Cal Log-
Loss approach employing AutoGluon concerning class imbalances and noise levels within
imbalanced synthetic data sets display a mixed bag of outcomes. Among the methods, the
AutoGluon Mid-Point approach demonstrates worse generalization, especially when faced
with synthetic data sets showcasing a high degree of class imbalance (r 0.2 for binary-class
≤
systems and r 0.08 for multi-class systems) and increased noise levels. As elaborated
≤
in Section 3.1, the Mid-Point strategy tends to overestimate MI in synthetic data sets
pronounced class imbalance. It is evident that AutoGluon Log-Loss and AutoGluon Cal
Log-Loss approaches overestimate MI, indicating their tendency to overfit for certain
degrees of class imbalances and low values of noise levels in synthetic data sets, notably
those created using the MVN proximity technique. These observations are less pronounced
in multi-class scenarios but still evident in specific configurations.
A distinctive observation with AutoGluon pertains to its response to changing noise
levels. With increasing noise, Cal Log-Loss’s performance fluctuates, indicating potential
sensitivity to noise in the context of imbalanced synthetic data set. The AutoGluon Log-
Loss using calibration technique (Cal Log-Loss) often excels, especially with average noise
levels, emphasizing the benefits of using the calibration technique, especially for multi-class
synthetic data set. Yet, the calibration technique deteriorates the MI estimation precision
66
)(cid:15)(leveLesioN
)(cid:15)(leveLesioN
)(cid:15)(leveLesioN
20.0 40.0 60.0 80.0 1.0 21.0 41.0 61.0 81.0 2.0 20.0 40.0 60.0 80.0 1.0 21.0 41.0 61.0 81.0 2.0 20.0 40.0 60.0 80.0 1.0 21.0 41.0 61.0 81.0 2.0in non-vulnerable, imbalanced data sets. All these observations regarding the generalization
capability of the approaches using AutoGluon align with our findings in Section 5.3.2.
Baselines The MINE and PC-Softmax baseline approaches continue to face hurdles
when dealing with imbalanced synthetic data sets, be it binary or multi-class, with their
generalization capability deteriorating with the decreasing degree of class imbalance and
noise level. Interesting, MINE and PC-Softmax baselines estimate MI precisely in both
binary-class and multi-class imbalance non-vulnerable synthetic data sets, as observed
in Appendix C.2.1 and section 5.3. The GMM baselines generally adapt well to class
imbalanceandnoiselevels,withanexceptionalcaseofmulti-classsyntheticsystemssimulated
using MVN perturbation technique. The GMM baseline tends to slightly outperform the
TabPFN approaches, especially in MVN perturbation imbalanced binary-class synthetic
data set. Notably, the strong generalization capability of GMM can be attributed to the
low dimensionality (d = 5) of the imbalanced synthetic data sets, implying that its primary
challenges lie in estimating MI for high-dimensional synthetic data sets, with minor influence
(largely unaffected) from noise and class imbalance. All these observations regarding the
generalization capability of the baselines align with our findings in Section 5.3.2.
C.2.3 Summary
In conclusion, TabPFN Cal Log-Loss consistently demonstrates remarkable generalization
capabilitiesinestimatingMIacrossvariousfactorsforbothMVNperturbationandproximity
synthetic data set. Notably, the usage of calibration techniques (Cal Log-Loss) for
TabPFN Log-Loss approach leads to significant enhancements in MI estimation precision
for vulnerable synthetic data sets, while leading to substantial deterioration in precision for
non-vulnerable synthetic data set. This explains why the AutoGluon Cal Log-Loss ILD
technique often detects non-existing ILs, leading to false positives, whereas the TabPFN
Cal Log-Loss ILD method surpasses other ILD techniques utilizing TabPFN, as seen
in Section 7.2.3 and appendix C.1.4. Overall, the baselines reiterate the inherent challenges
they face in high-dimensional, imbalanced noisy synthetic data sets, with these limitations
becoming even clearer when compared against the Cal Log-Loss approach using TabPFN
and AutoGluon. All these observations align with our findings in Section 5.3.
References
Diego Raphael Amancio, Cesar Henrique Comin, Dalcimar Casanova, Gonzalo Travieso,
Odemir Martinez Bruno, Francisco Aparecido Rodrigues, and Luciano da Fontoura Costa.
A systematic comparison of supervised classifiers. PLoS ONE, 9(4):e94137, April 2014.
ISSN 1932-6203. doi: 10.1371/journal.pone.0094137. URL https://doi.org/10.1371/
journal.pone.0094137.
R. E. Barlow and H. D. Brunk. The isotonic regression problem and its dual. Journal of
the American Statistical Association, 67(337):140–147, 2023/11/20/ 1972. ISSN 01621459.
doi: 10.2307/2284712. URL http://www.jstor.org/stable/2284712.
Mohamed Ishmael Belghazi, Aristide Baratin, Sai Rajeshwar, Sherjil Ozair, Yoshua Bengio,
Aaron Courville, and Devon Hjelm. Mutual information neural estimation. In Jennifer
Dy and Andreas Krause, editors, Proceedings of the 35th International Conference on
67Gupta, Wever and Hu¨llermeier
Machine Learning, volume 80 of Proceedings of Machine Learning Research, pages 531–
540, Stockholmsma¨ssan, Stockholm, Sweden, Jul 2018. Proceedings of Machine Learning
Research. URL https://proceedings.mlr.press/v80/belghazi18a.html.
Bhaskar Bhattacharya and Desale Habtzghi. Median of the<i>p</i>Value under the
alternativehypothesis. TheAmericanStatistician,56(3):202–206,112002. ISSN0003-1305,
1537-2731. doi: 10.1198/000313002146. URL https://doi.org/10.1198/000313002146.
G´erard Biau, Luc Devroye, and G´abor Lugosi. Consistency of random forests and other
averaging classifiers. Journal of Machine Learning Research, 9(66):2015–2033, June 2008.
ISSN 1532-4435. URL http://jmlr.org/papers/v9/biau08a.html.
Christopher M. Bishop. Probability Distributions. Springer New York, NY, Springer
New York, NY, 2006. ISBN 978-0387310732. doi: 10.5555/1162264. URL https:
//link.springer.com/book/9780387310732.
Daniel Bleichenbacher. Chosen ciphertext attacks against protocols based on the rsa
encryption standard pkcs #1. In Hugo Krawczyk, editor, Advances in Cryptology —
CRYPTO ’98, pages 1–12, Berlin, Heidelberg, 1998. Springer Berlin Heidelberg. ISBN
978-3-540-68462-6.
Gregory Camilli. The relationship between fisher’s exact test and Pearson’s chi-square
test: A bayesian perspective. Psychometrika, 60(2):305–312, June 1995. ISSN 0033-3123,
1860-0980. doi: 10.1007/bf02301418. URL https://doi.org/10.1007/bf02301418.
Konstantinos Chatzikokolakis, Tom Chothia, and Apratim Guha. Statistical measurement of
informationleakage.InJavierEsparzaandRupakMajumdar,editors,ToolsandAlgorithms
for the Construction and Analysis of Systems, pages 390–404, Berlin, Heidelberg, 2010.
Springer Berlin Heidelberg. ISBN 978-3-642-12002-2.
Weiwei Cheng and Eyke Hu¨llermeier. Probability estimation for multi-class classification
based on label ranking. In Peter A. Flach, Tijl De Bie, and Nello Cristianini, editors,
Machine Learning and Knowledge Discovery in Databases, pages 83–98, Berlin, Heidelberg,
2012. Springer Berlin Heidelberg. ISBN 978-3-642-33486-3.
Davide Chicco, Niklas T¨otsch, and Giuseppe Jurman. The matthews correlation coef-
ficient (mcc) is more reliable than balanced accuracy, bookmaker informedness, and
markedness in two-class confusion matrix evaluation. BioData Mining, 14(1):13, Feb 2021.
ISSN 1756-0381. doi: 10.1186/s13040-021-00244-z. URL https://doi.org/10.1186/
s13040-021-00244-z.
Francois Chollet et al. Keras, 2015. URL https://github.com/fchollet/keras.
Thomas M. Cover and Joy A. Thomas. Elements of information theory, Apr 2005. URL
https://doi.org/10.1002/047174882x.ch2.
Valence Cristiani, Maxime Lecomte, and Philippe Maurine. Leakage assessment through
neural estimation of the mutual information. In Lecture Notes in Computer Science, pages
144–162.SpringerInternationalPublishing, Berlin, Heidelberg, 2020. ISBN9783030616373,
689783030616380. doi: 10.1007/978-3-030-61638-0 9. URL https://doi.org/10.1007/
978-3-030-61638-0_9.
Daryl J. Daley and David Vere-Jones. Scoring probability forecasts for point processes:
the entropy score and information gain. Journal of Applied Probability, 41(A):297–312,
Dec. 2004. ISSN 0021-9002. doi: 10.1239/jap/1082552206. URL http://www.jstor.org/
stable/3215984. Full publication date: 2004.
Janez Demˇsar. Statistical comparisons of classifiers over multiple data sets. Journal of
Machine Learning Research, 7(1):1–30, 2006. ISSN 1532-4435. URL http://jmlr.org/
papers/v7/demsar06a.html.
Luc Devroye, L´aszl´o Gy¨orfi, and G´abor Lugosi. The Bayes Error, volume 31, chapter 2.
Springer New York, Springer New York, NY, 1996. ISBN 9781461268772, 9781461207115.
doi: 10.1007/978-1-4612-0711-5. URL https://doi.org/10.1007/978-1-4612-0711-5.
Pedro Domingos and Michael Pazzani. On the optimality of the simple Bayesian classifier
under zero-one loss. Machine Learning, 29(2/3):103–130, November 1997. ISSN 0885-6125.
doi: 10.1023/a:1007413511361. URL https://doi.org/10.1023/a:1007413511361.
Jan Peter Drees, Pritha Gupta, Eyke Hu¨llermeier, Tibor Jager, Alexander Konze, Claudia
Priesterjahn, Arunselvan Ramaswamy, and Juraj Somorovsky. Automated detection of
side channels in cryptographic protocols. In Proceedings of the 14th ACM Workshop on
Artificial Intelligence and Security, AISec ’21, pages 169–180, New York, NY, USA, Nov.
2021. Association for Computing Machinery. ISBN 9781450386579. doi: 10.1145/3474369.
3486868. URL https://doi.org/10.1145/3474369.3486868.
Emil Eirola, Amaury Lendasse, and Juha Karhunen. Variable selection for regression
problems using Gaussian mixture models to estimate mutual information. In 2014
International Joint Conference on Neural Networks (IJCNN), 2014 International Joint
Conference on Neural Networks (IJCNN), pages 1606–1613, Beijing, China, July 2014.
IEEE. doi: 10.1109/ijcnn.2014.6889561. URL https://doi.org/10.1109/ijcnn.2014.
6889561.
Nick Erickson, Jonas Mueller, Alexander Shirkov, Hang Zhang, Pedro Larroy, Mu Li, and
Alexander Smola. AutoGluon-tabular: Robust and accurate AutoML for structured data.
arXiv preprint arXiv:2003.06505, 2020.
Nick Erickson, Xingjian Shi, James Sharpnack, and Alexander Smola. Multimodal AutoML
for image, text and tabular data. In Proceedings of the 28th ACM SIGKDD Conference
on Knowledge Discovery and Data Mining, KDD ’22, pages 4786–4787, New York, NY,
USA, August 2022. Association for Computing Machinery. ISBN 9781450393850. doi:
10.1145/3534678.3542616. URL https://doi.org/10.1145/3534678.3542616.
SinaFaezi,RozhinYasaei,AnomadarshiBarua,andMohammadAbdullahAlFaruque. Brain-
inspired golden chip free hardware trojan detection. IEEE Transactions on Information
Forensics and Security, 16:2697–2708, 2021. doi: 10.1109/TIFS.2021.3062989.
69Gupta, Wever and Hu¨llermeier
Stefan Falkner, Aaron Klein, and Frank Hutter. BOHB: robust and efficient hyperparameter
optimization at scale. In Jennifer G. Dy and Andreas Krause, editors, Proceedings of the
35th International Conference on Machine Learning, (ICML), volume 80 of Proceedings
of Machine Learning Research, pages 1436–1445, Stockholmsma¨ssan, Stockholm, Sweden,
2018.ProceedingsofMachineLearningResearch. URLhttp://proceedings.mlr.press/
v80/falkner18a.html.
Robert M Fano. Transmission of Information: A Statistical Theory of Communications.
The MIT Press, Cambridge, MA, 1961. URL https://books.google.de/books?id=
2PMbtQEACAAJ.
Andrey Feuerverger and Sheikh Rahman. Some aspects of probability forecasting. Communi-
cationsinStatistics-TheoryandMethods,21(6):1615–1632,Jan1992. ISSN0361-0926. doi:
10.1080/03610929208830868. URL https://doi.org/10.1080/03610929208830868.
Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost Tobias Springenberg, Manuel
Blum, and Frank Hutter. Auto-sklearn: Efficient and robust automated machine learning.
In Frank Hutter, Lars Kotthoff, and Joaquin Vanschoren, editors, Automated Machine
Learning, The Springer Series on Challenges in Machine Learning, pages 113–134. Springer
International Publishing, Cham, 2019. ISBN 9783030053178, 9783030053185. doi: 10.
1007/978-3-030-05318-5 6. URL https://doi.org/10.1007/978-3-030-05318-5_6.
MatthiasFeurer, JanN.VanRijn, ArlindKadra, PieterGijsbers, NeeratyoyMallik, Sahithya
Ravi, Andreas Mu¨ller, Joaquin Vanschoren, and Frank Hutter. Openml-python: An
extensible python api for openml. J. Mach. Learn. Res., 22(1), jan 2021. ISSN 1532-4435.
R. A. Fisher. On the interpretation of χ 2 from contingency tables, and the calculation of
p. Journal of the Royal Statistical Society, 85(1):87, January 1922. ISSN 0952-8385. doi:
10.2307/2340521. URL https://doi.org/10.2307/2340521.
Peter I. Frazier. Optimization via simulation with bayesian statistics and dynamic program-
ming. In Oliver Rose and Adelinde M. Uhrmacher, editors, Proceedings of the 2012 Winter
Simulation Conference (WSC), pages 1–16, Berlin, Germany, December 2012. IEEE, WSC.
doi: 10.1109/WSC.2012.6465237. URL https://doi.org/10.1109/WSC.2012.6465237.
Dennis Funke. Pushing the AutoSCA tool to picosecond precision: Improving timing side
channel detection, 09 2022.
ShuyangGao,GregVerSteeg,andAramGalstyan. Efficientestimationofmutualinformation
forstronglydependentvariables, Feb2015. URLhttps://proceedings.mlr.press/v38/
gao15.html.
Pieter Gijsbers, Marcos L. P. Bueno, Stefan Coors, Erin LeDell, S´ebastien Poirier, Janek
Thomas, Bernd Bischl, and Joaquin Vanschoren. AMLB: an automl benchmark. CoRR,
abs/2207.12560, 2022. doi: 10.48550/arXiv.2207.12560. URL https://doi.org/10.
48550/arXiv.2207.12560.
Tilmann Gneiting and Adrian E. Raftery. Strictly proper scoring rules, prediction, and
estimation. Journal of the American Statistical Association, 102(477):359–378, Mar. 2007.
70ISSN 0162-1459. doi: 10.1198/016214506000001437. URL https://doi.org/10.1198/
016214506000001437.
I. J. Good. Rational Decisions, pages 365–377. Springer New York, New York, NY, 1992.
ISBN 978-1-4612-0919-5. doi: 10.1007/978-1-4612-0919-5 24. URL https://doi.org/10.
1007/978-1-4612-0919-5_24.
Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. On calibration of modern
neural networks. In Proceedings of the 34th International Conference on Machine Learning
, (ICML), ICML’17, page 1321–1330. JMLR.org, 2017.
Pritha Gupta, Arunselvan Ramaswamy, Jan Drees, Eyke Hu¨llermeier, Claudia Priesterjahn,
and Tibor Jager. Automated information leakage detection: A new method combining
machine learning and hypothesis testing with an application to side-channel detection
in cryptographic protocols. In Ana Paula Rocha, Luc Steels, and H. Jaap van den
Herik, editors, Proceedings of the 14th International Conference on Agents and Artificial
Intelligence, pages 152–163, Virtual Event, 2022. INSTICC, SCITEPRESS - Science and
Technology Publications. ISBN 978-989-758-547-0. doi: 10.5220/0010793000003116. URL
https://doi.org/10.5220/0010793000003116.
Tim Head, Manoj Kumar, Holger Nahrstaedt, Gilles Louppe, and Iaroslav Shcherbatyi.
scikit-optimize/scikit-optimize, October 2021. URL https://doi.org/10.5281/zenodo.
5565057.
M. Hellman and J. Raviv. Probability of error, equivocation, and the chernoff bound. IEEE
Transactions on Information Theory, 16(4):368–372, July 1970. ISSN 0018-9448. doi:
10.1109/tit.1970.1054466. URL https://doi.org/10.1109/tit.1970.1054466.
Benjamin Hettwer, Stefan Gehrer, and Tim Gu¨neysu. Applications of machine learning
techniques in side-channel attacks: A survey. Journal of Cryptographic Engineering, 10
(2):135–162, April 2019. ISSN 2190-8508, 2190-8516. doi: 10.1007/s13389-019-00212-8.
URL https://doi.org/10.1007/s13389-019-00212-8.
Noah Hollmann, Samuel Mu¨ller, Katharina Eggensperger, and Frank Hutter. TabPFN:
A transformer that solves small tabular classification problems in a second. In The
Eleventh International Conference on Learning Representations, 2023. URL https:
//openreview.net/forum?id=cp5PvcI6w8_.
Sture Holm. A simple sequentially rejective multiple test procedure. Scandinavian Journal
of Statistics, 6(2):65–70, 1979. URL http://www.jstor.org/stable/4615733.
Jeremy Howard and Sylvain Gugger. Fastai: A layered api for deep learning. Information,
11(2), 2020. ISSN 2078-2489. doi: 10.3390/info11020108. URL https://www.mdpi.com/
2078-2489/11/2/108.
Kirthevasan Kandasamy, Akshay Krishnamurthy, Barnaby´s Po´czos, Larry Wasserman, and
James M. Robins. Nonparametric von mises estimators for entropies, divergences and
mutual informations. In Proceedings of the 28th International Conference on Neural
71Gupta, Wever and Hu¨llermeier
Information Processing Systems - Volume 1, NIPS’15, pages 397–405, Cambridge, MA,
USA, 2015. Neural Information Processing Systems Foundation, Inc.
John Kelsey. Compression and information leakage of plaintext. In Joan Daemen and
Vincent Rijmen, editors, Fast Software Encryption, pages 263–276, Berlin, Heidelberg,
2002. Springer Berlin Heidelberg. ISBN 978-3-540-45661-2.
Oluwasanmi Koyejo, Pradeep Ravikumar, Nagarajan Natarajan, and Inderjit S. Dhillon.
Consistent multilabel classification. In Proceedings of the 28th International Conference on
Neural Information Processing Systems - Volume 2, NIPS’15, pages3321–3329, Cambridge,
MA, USA, 2015. MIT Press. doi: 10.5555/2969442.2969610.
Alexander Kraskov, Harald Sto¨gbauer, and Peter Grassberger. Estimating mutual informa-
tion. Physics Review E, 69:066138, Jun 2004. doi: 10.1103/PhysRevE.69.066138. URL
https://link.aps.org/doi/10.1103/PhysRevE.69.066138.
Meelis Kull, Telmo Silva Filho, and Peter Flach. Beta calibration: a well-founded and easily
implemented improvement on logistic calibration for binary classifiers. In Aarti Singh
and Jerry Zhu, editors, Proceedings of the 20th International Conference on Artificial
Intelligence and Statistics, volume 54 of Proceedings of Machine Learning Research, pages
623–631. Proceedings of Machine Learning Research, 20–22 Apr 2017. URL https:
//proceedings.mlr.press/v54/kull17a.html.
Fabian Ku¨ppers, Jonas Schneider, and Anselm Haselhoff. Parametric and multivariate
uncertainty calibration for regression and object detection. In Computer Vision – ECCV
2022 Workshops, pages 426–442, Cham, 2023. Springer Nature Switzerland. ISBN 978-3-
031-25072-9.
FabianKu¨ppers,JanKronenberger,AmirhosseinShantia,andAnselmHaselhoff.Multivariate
confidence calibration for object detection. In The IEEE/CVF Conference on Computer
Vision and Pattern Recognition (CVPR) Workshops, pages 1322–1330, Los Alamitos, CA,
USA, June 2020. IEEE. doi: 10.1109/cvprw50498.2020.00171. URL https://doi.org/
10.1109/cvprw50498.2020.00171.
Liam Li, Kevin G. Jamieson, Afshin Rostamizadeh, Ekaterina Gonina, Jonathan Ben-tzur,
Moritz Hardt, Benjamin Recht, and Ameet Talwalkar. A system for massively parallel
hyperparameter tuning. In Inderjit S. Dhillon, Dimitris S. Papailiopoulos, and Vivienne
Sze, editors, Proceedings of Machine Learning and Systems 2020, MLSys 2020, March
2-4, 2020, Austin, TX, USA, 2020. mlsys.org. URL https://proceedings.mlsys.org/
book/303.pdf.
Lisha Li, Kevin G. Jamieson, Giulia DeSalvo, Afshin Rostamizadeh, and Ameet Talwalkar.
Hyperband: A novel bandit-based approach to hyperparameter optimization. J. Mach.
Learn. Res., 18:185:1–185:52, 2017. URL http://jmlr.org/papers/v18/16-558.html.
FelipeMaiaPoloandRenatoVicente.Effectivesamplesize,dimensionality,andgeneralization
in covariate shift adaptation. Neural Computing and Applications, 35(25):18187–18199,
January 2022. ISSN 0941-0643, 1433-3058. doi: 10.1007/s00521-021-06615-1. URL
https://doi.org/10.1007/s00521-021-06615-1.
72Christopher Meyer, Juraj Somorovsky, Eugen Weiss, J¨org Schwenk, Sebastian Schinzel,
and Erik Tews. Revisiting SSL/TLS implementations: New bleichenbacher side
channels and attacks. In 23rd USENIX Security Symposium (USENIX Security
14), pages 733–748, San Diego, CA, August 2014. USENIX Association. ISBN
978-1-931971-15-7. URL https://www.usenix.org/conference/usenixsecurity14/
technical-sessions/presentation/meyer.
Jan Mielniczuk and Joanna Tyrcha. Consistency of multilayer perceptron regression esti-
mators. Neural Networks, 6(7):1019–1022, January 1993. ISSN 0893-6080. doi: 10.1016/
s0893-6080(09)80011-7. URL https://doi.org/10.1016/s0893-6080(09)80011-7.
Felix Mohr, Marcel Wever, and Eyke Hu¨llermeier. ML-plan: Automated machine learning
via hierarchical planning. Machine Learning, 107(8-10):1495–1515, July 2018. ISSN 0885-
6125, 1573-0565. doi: 10.1007/s10994-018-5735-z. URL https://doi.org/10.1007/
s10994-018-5735-z.
Kevin R. Moon, Kumar Sricharan, and Alfred O. Hero. Ensemble estimation of generalized
mutual information with applications to genomics. IEEE Transactions on Information
Theory, 67(9):5963–5996, 2021. doi: 10.1109/TIT.2021.3100108.
Thorben Moos, Felix Wegener, and Amir Moradi. DL-LA: Deep learning leakage assessment.
IACR Transactions on Cryptographic Hardware and Embedded Systems, 2021(3):552–
598, July 2021. ISSN 2569-2925. doi: 10.46586/tches.v2021.i3.552-598. URL https:
//doi.org/10.46586/tches.v2021.i3.552-598.
Maria Mushtaq, Ayaz Akram, Muhammad Khurram Bhatti, Maham Chaudhry, Vianney
Lapotre, and Guy Gogniat. NIGHTs-WATCH: A cache-based side-channel intrusion
detector using hardware performance counters. In Proceedings of the 7th International
Workshop on Hardware and Architectural Support for Security and Privacy,HASP’18,New
York, NY, USA, June 2018. Association for Computing Machinery. ISBN 9781450365000.
doi: 10.1145/3214292.3214293. URL https://doi.org/10.1145/3214292.3214293.
Claude Nadeau. Inference for the generalization error. Machine Learning, 52(3):239–
281, September 2003. ISSN 0885-6125. doi: 10.1023/a:1024068626366. URL https:
//doi.org/10.1023/a:1024068626366.
Randal S. Olson, Nathan Bartley, Ryan J. Urbanowicz, and Jason H. Moore. Evalua-
tion of a tree-based pipeline optimization tool for automating data science. In Tobias
Friedrich, Frank Neumann, and Andrew M. Sutton, editors, Proceedings of the Genetic
and Evolutionary Computation Conference 2016, GECCO ’16, pages 485–492, New York,
NY, USA, July 2016. Association for Computing Machinery. ISBN 9781450342063. doi:
10.1145/2908812.2908918. URL https://doi.org/10.1145/2908812.2908918.
Mahdi Pakdaman Naeini, Gregory Cooper, and Milos Hauskrecht. Obtaining well calibrated
probabilities using Bayesian binning. Proceedings of the AAAI Conference on Artificial
Intelligence, 29(1), February 2015. ISSN 2374-3468, 2159-5399. doi: 10.1609/aaai.v29i1.
9602. URL https://doi.org/10.1609/aaai.v29i1.9602.
73Gupta, Wever and Hu¨llermeier
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan,
Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas
Ko¨pf, Edward Yang, Zach DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy,
Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An Imperative
Style, High-Performance Deep Learning Library. Curran Associates Inc., Red Hook, NY,
USA, 2019. URL https://dl.acm.org/doi/10.5555/3454287.3455008.
Thomas Perianin, Sebastien Carr´e, Victor Dyseryn, Adrien Facon, and Sylvain Guilley.
End-to-end automated cache-timing attack driven by machine learning. Journal of
Cryptographic Engineering, 11(2):135–146, June 2020. ISSN 2190-8508, 2190-8516. doi:
10.1007/s13389-020-00228-5. URL https://doi.org/10.1007/s13389-020-00228-5.
Stjepan Picek, Annelie Heuser, Alan Jovic, Shivam Bhasin, and Francesco Regazzoni.
The curse of class imbalance and conflicting metrics with machine learning for side-
channel evaluations. IACR Transactions on Cryptographic Hardware and Embedded
Systems, 2019:209–237, November 2018. doi: 10.13154/tches.v2019.i1.209-237. URL
https://tches.iacr.org/index.php/TCHES/article/view/7339.
Stjepan Picek, Guilherme Perin, Luca Mariot, Lichao Wu, and Lejla Batina. Sok: Deep
learning-based physical side-channel analysis. ACM Computing Surveys, 55(11), feb 2023.
ISSN 0360-0300. doi: 10.1145/3569577. URL https://doi.org/10.1145/3569577.
John C. Platt. Probabilistic outputs for support vector machines and comparisons to
regularized likelihood methods. Advances in large margin classifiers, 10(3):61–74, 1999.
John C. Platt. Probabilities for SV Machines, pages 61–73. Cambridge: MIT Press, 2000.
ISBN 9780262283977. doi: 10.7551/mitpress/1113.001.0001. URL https://doi.org/10.
7551/mitpress/1113.001.0001.
Felipe Maia Polo and Felipe Leno Da Silva. InfoSelect - mutual information based feature
selection in python, 2020.
DavidMartinPowers. Evaluation: Fromprecision, recallandf-measuretoroc., informedness,
markedness & correlation. Journal of Machine Learning Technologies, 2(1):37–63, 2011.
Zhenyue Qin and Dongwoo Kim. Rethinking softmax with cross-entropy: Neural network
classifier as mutual information estimator. CoRR, abs/1911.10688, 2019. URL http:
//arxiv.org/abs/1911.10688.
Mark S. Roulston and Leonard A. Smith. Evaluating probabilistic forecasts us-
ing information theory. Monthly Weather Review, 130(6):1653–1660, Jun. 2002.
URLhttps://journals.ametsoc.org/view/journals/mwre/130/6/1520-0493_2002_
130_1653_epfuit_2.0.co_2.xml.
Asaf Shabtai, Yuval Elovici, and Lior Rokach. A Survey of Data Leakage Detection and
Prevention Solutions. SpringerBriefs in Computer Science. Springer US, New York, NY,
1 edition, 2012. ISBN 9781461420521, 9781461420538. doi: 10.1007/978-1-4614-2053-8.
URL https://doi.org/10.1007/978-1-4614-2053-8.
74Telmo Silva Filho, Hao Song, Miquel Perello-Nieto, Raul Santos-Rodriguez, Meelis Kull,
and Peter Flach. Classifier calibration: A survey on how to assess and improve pre-
dicted class probabilities. Machine Learning, 112(9):3211–3260, May 2023. ISSN 0885-
6125, 1573-0565. doi: 10.1007/s10994-023-06336-7. URL https://doi.org/10.1007/
s10994-023-06336-7.
Shashank Singh and Barnab´as P´oczos. Finite-sample analysis of fixed-k nearest neigh-
bor density functional estimators. In Daniel D. Lee, Masashi Sugiyama, Ulrike von
Luxburg, Isabelle Guyon, and Roman Garnett, editors, Advances in Neural Information
Processing Systems 29, NIPS’16, pages 1217–1225. Neural Information Processing Systems
Foundation, Inc., 2016. URL https://proceedings.neurips.cc/paper/2016/hash/
2dea61eed4bceec564a00115c4d21334-Abstract.html.
Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.
Rethinking the Inception architecture for computer vision. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition, CVPR, Las Vegas, NV, USA,
June 27-30, pages 2818–2826. IEEE Computer Society, 2016.
D. Tebbe and S. Dwyer. Uncertainty and the probability of error (Corresp.). IEEE
Transactions on Information Theory, 14(3):516–518, May 1968. ISSN 0018-9448. doi:
10.1109/tit.1968.1054135. URL https://doi.org/10.1109/tit.1968.1054135.
Chris Thornton, Frank Hutter, Holger H. Hoos, and Kevin Leyton-Brown. Auto-weka:
Combined selection and hyperparameter optimization of classification algorithms. In
Inderjit S. Dhillon, Yehuda Koren, Rayid Ghani, Ted E. Senator, Paul Bradley, Rajesh
Parekh, Jingrui He, Robert L. Grossman, and Ramasamy Uthurusamy, editors, The
19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,
KDD 2013, Chicago, IL, USA, August 11-14, 2013, KDD ’13, pages 847–855, New York,
NY, USA, 2013. Association for Computing Machinery. ISBN 9781450321747. doi:
10.1145/2487575.2487629. URL https://doi.org/10.1145/2487575.2487629.
Joaquin Vanschoren, Jan N. van Rijn, Bernd Bischl, and Luis Torgo. Openml: Networked
scienceinmachinelearning. SIGKDD explorations newsletter, 15(2):49–60, Jun2014. ISSN
1931-0145. doi: 10.1145/2641190.2641198. URL https://doi.org/10.1145/2641190.
2641198.
V. Vapnik. Principles of risk minimization for learning theory. In Proceedings of the 4th
International Conference on Neural Information Processing Systems, NIPS’91, pages 831–
838, San Francisco, CA, USA, 1991. Morgan Kaufmann Publishers Inc. ISBN 1558602224.
Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David
Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright,
St´efan J. van der Walt, Matthew Brett, Joshua Wilson, K. Jarrod Millman, Nikolay
Mayorov, Andrew R. J. Nelson, Eric Jones, Robert Kern, Eric Larson, C J Carey, I˙lhan
Polat, Yu Feng, Eric W. Moore, Jake VanderPlas, Denis Laxalde, Josef Perktold, Robert
Cimrman,IanHenriksen,E.A.Quintero,CharlesR.Harris,AnneM.Archibald,AntoˆnioH.
Ribeiro, Fabian Pedregosa, Paul van Mulbregt, and SciPy 1.0 Contributors. Scipy 1.0:
75Gupta, Wever and Hu¨llermeier
fundamentalalgorithmsforscientificcomputinginpython. Nature Methods, 17(3):261–272,
Mar 2020. ISSN 1548-7105. doi: 10.1038/s41592-019-0686-2.
BiancaZadroznyandCharlesElkan. Obtainingcalibratedprobabilityestimatesfromdecision
trees and naive bayesian classifiers. In Proceedings of the 18th International Conference
on Machine Learning , (ICML), ICML ’01, page 609–616, San Francisco, CA, USA, 2001.
Morgan Kaufmann Publishers Inc. ISBN 1558607781.
Bianca Zadrozny and Charles Elkan. Transforming classifier scores into accurate multiclass
probability estimates. KDD ’02, page 694–699, New York, NY, USA, 2002. Association
for Computing Machinery. ISBN 158113567X. doi: 10.1145/775047.775151. URL https:
//doi.org/10.1145/775047.775151.
Jiajia Zhang, Mengce Zheng, Jiehui Nan, Honggang Hu, and Nenghai Yu. A novel evaluation
metric for deep learning-based side channel analysis and its extended application to
imbalanced data. IACR Transactions on Cryptographic Hardware and Embedded Systems,
2020(3):73–96, June 2020. ISSN 2569-2925. doi: 10.46586/tches.v2020.i3.73-96. URL
https://doi.org/10.46586/tches.v2020.i3.73-96.
Ming-Jie Zhao, Narayanan Edakunni, Adam Pocock, and Gavin Brown. Beyond fano’s
inequality: Boundsontheoptimalf-score,ber,andcost-sensitiveriskandtheirimplications.
Journal of Machine Learning Research, 14(32):1033–1090, 2013. URL http://jmlr.org/
papers/v14/zhao13a.html.
Marc-Andr´e Z¨oller and Marco F. Huber. Benchmark and survey of automated machine
learning frameworks. Journal of Artificial Intelligence Research, 70:409–472, 2021. doi:
10.1613/jair.1.11854. URL https://doi.org/10.1613/jair.1.11854.
76