In-and-Out: Algorithmic Diffusion for Sampling Convex Bodies
Yunbum Kook∗ Santosh S. Vempala† Matthew S. Zhang‡
May 3, 2024
Abstract
We present a new random walk for uniformly sampling high-dimensional convex bodies.
It achieves state-of-the-art runtime complexity with stronger guarantees on the output than
previously known, namely in Rényi divergence (which implies TV, W , KL, χ2). The proof
2
departsfromknownapproachesforpolytimealgorithmsfortheproblem—weutilizeastochastic
diffusion perspective to show contraction to the target distribution with the rate of convergence
determined by functional isoperimetric constants of the stationary density.
1 Introduction
Generating random samples from a high-dimensional convex body is a basic algorithmic problem
with myriad connections and applications. The core of the celebrated result of [DFK91], giving a
randomized polynomial-time algorithm for computing the volume of a convex body, was the first
polynomial-time algorithm for uniformly sampling convex bodies. In the decades since, the study
of sampling has led to a long series of improvements in its algorithmic complexity [LS90; LS93;
KLS97; LV06; CV18], oftenbasedonuncoveringnewmathematical/geometricstructure, establishing
connections to other fields (e.g., functional analysis, matrix concentration) and developing new tools
for proving isoperimetric inequalities and analyzing Markov chains. With the proliferation of data
andtheincreasingimportanceofmachinelearning,samplinghasalsobecomeanessentialalgorithmic
tool, with applications needing samplers in very high dimension, e.g., scientific computing [CV16;
Har+17; Koo+22], systems biology [LNP12; Thi+13], differential privacy [MT07; Mir17] and
machine learning [Bin+19; Sta20].
Samplers for convex bodies are based on Markov chains (see Appendix A for a summary). Their
analysis is based on bounding the conductance of the associated Markov chain, which in turn bounds
the mixing rate. Analyzing the conductance requires combining delicate geometric arguments with
(Cheeger) isoperimetric inequalities for convex bodies. An archetypal example of the latter is the
following: for any measurable partition S ,S ,S of a convex body K ⊂ Rd, we have
1 2 3
d(S ,S )
vol(S ) ≥ 1 2 min{vol(S ),vol(S )},
3 1 2
C
K
where d(·,·) is the (minimum) Euclidean distance, and C is an isoperimetric constant of the
K
uniform distribution over K. (The KLS conjecture posits that C = O(1) for any convex body K in
K
isotropic position, i.e., under the normalization that a random point from K has identity covariance).
∗School of Computer Science, Georgia Institute of Technology, yb.kook@gatech.edu
†School of Computer Science, Georgia Institute of Technology, vempala@gatech.edu
‡DepartmentofComputerScience,UniversityofToronto,andVectorInstitute,matthew.zhang@mail.utoronto.ca
1
4202
yaM
2
]SD.sc[
1v52410.5042:viXraThe coefficient C2 is bounded by the Poincaré constant of the uniform distribution over K (and
K
they are in fact asymptotically equal). The classical proof of conductance uses geometric properties
of the random walk at hand to reduce the analysis to a suitable isoperimetric inequality (see e.g.,
[LS93; Vem05]). The end result is a guarantee on the number of steps after which the total variation
distance (TV distance) between the current distribution and the target is bounded by a desired error
parameter. This framework has been widely used and effective in analyzing an array of candidate
samplers, e.g., Ball walk [KLS97], Hit-and-Run [Lov99; LV06], Riemannian Hamiltonian Monte Carlo
[LV18] etc.
One successful approach, studied intensively over the past decade, is based on diffusion. The
basic idea is to first analyze a continuous-time diffusion process, typically modeled by a stochastic
differential equation (SDE), and then show that a suitable time-discretization of the process,
sometimes together with a Metropolis filter, converges to the desired distribution efficiently. A
major success along this line is the Unadjusted Langevin Algorithm and its variants [Bes+95; DT12;
Dal17; DMM19; VW19]. These algorithms have strong guarantees for sampling “nice” distributions,
such as ones that are strongly log-concave, or more generally distributions satisfying isoperimetric
inequalities, while also obeying some smoothness conditions. The analysis of these algorithms is
markedly different from the conductance approach, and typically yields guarantees in stronger
metrics such as the KL-divergence.
Our starting point is the following question:
Can diffusion-based approaches be used for the problem of sampling convex bodies?
Despite remarkable progress, thus far, constrained sampling problems have evaded the diffusion
approach, except as a high-level analogy (e.g., the Ball walk can be viewed as a discretization of
Brownian motion, but this alone does not suggest a route for analysis) or with significantly worse
convergence rates (e.g., [Bro+17; BEL18]).
Our main finding is a simple diffusion-based algorithm that can be mapped to a stochastic
process (and, importantly, to a pair of forward and backward processes), such that the rate of
convergence is bounded directly by an appropriate functional inequality for the target distribution.
As a consequence, for the first time, we obtain clean end-to-end guarantees in the Rényi divergence
(which implies guarantees in other well known quantities such as W ,TV,KL,χ2 etc.), while giving
2
state-of-the-art runtime complexity for sampling convex bodies (e.g., Ball walk or Speedy walk [LS93;
KLS97]). Besides being a stronger guarantee on the output, Rényi divergence is of particular interest
for differential privacy [Mir17]. Perhaps most interesting is that our proof approach is completely
different from prior work on convex body sampling. In summary,
• The guarantees hold for the q-Rényi divergences while matching the rates of previous work
(prior work only had guarantees in the TV distance).
• The analysis is simple, modular, and easily extendable to several other settings.
1.1 Diffusion for uniform sampling
WeproposethefollowingIn-and-Out1 samplerforuniformlysamplingfromK. Eachiterationconsists
of two steps, one that might leave the body and the second accepted only if it is (back) in the body.
1This name reflects the “geometry” of how the iterates are moving. As we elaborate in Remark 1, the name
‘proximal sampler’ may be more familiar to those from an optimization background.
2𝑦
𝑧(reject) "
𝑥
!
𝑥 !,𝑥 " 𝑥 ! 𝑥 "
𝑥 𝑥
# "
Ball walk Speedy walk In-and-Out
Figure 1.1: Description of uniform samplers: (i) Ball walk: proposes a uniform random point z from
B (x ), but z ∈/ K so it stays at x = x . (ii) Speedy walk: moves to x drawn uniformly at random
δ 1 1 2 2
from K∩B (x ). (iii) In-and-Out: first moves to y obtained by taking a Gaussian step from x ,
δ 1 2 1
and then to x obtained by sampling the truncated Gaussian N(y ,hI )| .
2 2 d K
Algorithm 1 In-and-Out
Input: initial point x ∼ π , convex body K ⊂ Rd, iterations T, threshold N, and h > 0.
0 0
Output: x .
T+1
1: for i = 0,...,T do
2: Sample y i+1 ∼ N(x i,hI d).
3: Repeat: Sample x i+1 ∼ N(y i+1,hI d) until x i+1 ∈ K or #attempts i ≥ N (declare Failure).
4: end for
It might be illuminating for the reader to compare this algorithm to the well-studied Ball walk
(Algorithm 2); each proposed step is a uniform random point in a fixed-radius ball around the
current point, and is accepted only if the proposed point is in the body K. In contrast, each iteration
of In-and-Out is a two-step process, where the first step (Line 2) ignores the boundary of the body,
and the second step (Line 3) is accepted only if a proposal x is a feasible point in K. We will
i+1
presently elaborate on the benefits of this variation.
Each successful iteration of the algorithm, i.e., one that is not declared “Failure”, can be called
a proper step. We will see that the number of proper steps is directly bounded by isoperimetric
constants (such as Poincaré and log-Sobolev) of the target distribution. In fact, this holds quite
generally without assuming the convexity of K. The implementation of an iteration is based on
rejection sampling (Line 3), and our analysis of the efficiency of this step relies crucially on the
convexity of K. This is reminiscent of the Speedy walk in the literature on convex body sampling
(Algorithm 3), which is used as a tool to analyze proper steps of the Ball walk. We refer the reader
to Appendix B for a brief survey on these and related walks.
This simple algorithm can be interpreted as a composition of “flows” in the space of measures.
This view will allow us to use tools from stochastic analysis. In particular, we shall demonstrate
how to interpret the two steps of one iteration of In-and-Out as alternating forward and backward
heat flows.
We begin by defining an augmented probability measure on Rd×Rd by
1
π(x,y) ∝ exp(cid:0) − ∥x−y∥2(cid:1)1 (x).
2h K
3Forward flow Backward flow
SDE dZ = dB dZ← = ∇log(πXP )(Z←)dt+dB
t t t h−t t t
Fokker-Planck ∂ µ = 1∆µ ∂ µ← = −div(cid:0) µ←∇log(πXP )(cid:1)+ 1∆µ←
t t 2 t t t t h−t 2 t
Table 1: The Fokker-Planck equations for the forward and backward heat flow describe how the
laws of Z and Z← in (FH) and (BH) evolve over time. See Section 3.2 for details.
t t
We denote by πX,πX|Y(·|y) the marginal distribution of its first component (resp. conditional
distribution given the second component), and similarly denote by πY,πY|X(·|x) for the second
component. In particular, the marginal in the first component πX is the uniform distribution over
K. Sampling from such a joint distribution to obtain the marginal on X (say), can be more efficient
than directly working only with πX. This idea was utilized in Gaussian Cooling [CV18] and later as
the restricted Gaussian Oracle (RGO) [LST21; Che+22].
Underthisnotation,Algorithm1correspondstoaGibbssamplingschemefromthetwomarginals
of π(x,y). To be precise, Line 2 and Line 3 correspond to sampling from
y ∼ πY|X(·|x ) = N(x ,hI ) and x ∼ πX|Y(·|y ) = N(y ,hI )| .
i+1 i i d i+1 i+1 i+1 d K
We implement the latter step through rejection sampling; if the number of trials in Line 3 hits the
threshold N, then we halt and declare failure of the algorithm. It is well known that such a Gibbs
sampling procedure will ensure the desired stationarity of π(x,y).
Stochastic perspective: forward and backward heat flows. Our algorithm can be viewed
through the lens of stochastic analysis, due to an improved analysis for the proximal sampling
[Che+22]. This view provides an interpolation in continuous-time, which is simple and powerful. To
make this concrete, we borrow an exposition from [Che24, Chapter 8.3]. Let us denote the successive
laws of x and y by µX and µY, respectively. Recall that the first step of sampling from πY|X(·|x )
i i i i i
(Line 2) yields µY = R πY|X=xdµX(x). This is the result of evolving a probability measure under
i+1 i
(forward) heat flow of µX for some time h, given precisely by the following stochastic differential
i
equation: for Z ∼ µX,
0 i
dZ = dB (FH)
t t
where B is the standard Brownian process. We write law(Z ) = µXP . In particular, Z = Z +ζ ∼
t t i t h 0
µX ∗N(0,hI ) = µY for ζ ∼ N(0,hI ). When µX = πX, the first step of Algorithm 1 gives
i d i+1 d i
1 Z 1
πY(y) = [πX ∗N(0,hI )](y) = exp(cid:0) − ∥y−x∥2(cid:1)dx. (1.1)
d vol(K)(2πh)d/2 2h
K
The second step of sampling from πX|Y(·|y ) can be represented by µX = R πX|Y=ydµY (y)
i+1 i+1 i+1
(Line 3). The continuous-time process corresponding to this step might not be obvious. However,
let us consider (FH) with Z ∼ πX. Then, Z ∼ πY, so the joint distribution of (Z ,Z ) is simply π.
0 h 0 h
This implies that (Z |Z = y) ∼ πX|Y=y. Imagine there is an SDE reversing the forward heat flow
0 h
in a sense that if we are initialized deterministically at Z ∼ δ at time 0, then the law of the SDE
h y
at time h would be law(Z |Z = y) = πX|Y=y. Then, this SDE would serve as a continuous-time
0 h
interpolation of the second step.
Such a time reversal SDE is indeed possible! The following SDE on (Z←) initialized at
t t∈[0,h]
Z← ∼ πY = πXP ensures Z ∼ law(Z←) = πXP :
0 h h−t t h−t
dZ← = ∇log(πXP )(Z←)dt+dB for t ∈ [0,h]. (BH)
t h−t t t
4Although this is designed to reverse (FH) initialized by Z ∼ πX (so Z = Z← ∼ πY), its
0 h 0
constructionalsoensuresthatifZ← ∼ δ ,apointmass,thenZ← ∼ law(Z |Z = y) = πX|Y=y. Thus,
0 y h 0 h
if we initialize (BH) with Z← ∼ µY , then the law of Z← corresponds to R πX|Y=ydµY (y) = µX .
0 i+1 h i+1 i+1
Remark 1. We note that In-and-Out is exactly the proximal sampling scheme [LST21; Che+22;
FYC23] for uniform distributions. The proximal sampler with a target density proportional to
exp(−V(x)) considers an augmented distribution π(x,y) ∝ exp(−V(x)− 1 ∥x−y∥2) and then
2h
repeats the following two steps: (1) y
i+1
∼ πY|X=xi = N(x i,hI d) and then (2) x
i+1
∼ πX|Y=yi+1.
1.2 Results
Our model of computation is the classical general model for convex bodies [GLS88]. We assume
vol(K) > 0 throughout this paper. Below, B (x) denotes the d-dimensional ball of radius r centered
r
at x.
Definition 1 (Convex body oracle). A well-defined membership oracle for a convex body K ⊂ Rd
is given by a point x ∈ K, a number D > 0, with the guarantee that B (x ) ⊆ K ⊆ B (x ), and
0 1 0 D 0
an oracle that correctly answers YES or NO to any query of the form “x ∈ K?”
Definition 2 (Warmness). A distribution µ is M-warm with respect to another distribution π, i.e.,
for every x in the support of π, we have dµ(x) ≤ M dπ(x).
We now summarize our main result which is further elaborated in Section 3.4 (Theorem 27).
Below, πK is the uniform distribution over K, and R is the Rényi-divergence of order q (see
q
Definition 6).
Theorem 3. For any given η,ε ∈ (0,1), q ≥ 1, and any convex body K given by a well-defined
membership oracle, there exist choices of parameters h,N such that In-and-Out, starting from an
M-warm distribution, with probability at least 1−η, returns X ∼ µ such that R (µ∥πK) ≤ ε. The
q
number of proper steps is Oe(qd2Λlog M), and the expected total number of membership queries is
ηε
Oe(qMd2Λlog5(1/ηε)), where Λ is the largest eigenvalue of the covariance of πK.
We note that for X ∼ πK,
∥Cov(πK)∥ ≤ tr(Cov(πK)) = E(cid:2) ∥X −E[X]∥2(cid:3) ≤ D2.
op
TheaboveguaranteeintheRényidivergenceimmediatelyprovidesW ,TV,KL,andχ2guarantees
2
as special cases. Previous guarantees for uniformly sampling convex bodies were only in the TV-
distance. For two distributions µ and π, we have
1. KL(µ∥π) = lim R (µ∥π) ≤ R (µ∥π) ≤ R (µ∥π) ≤ R (µ∥π) = logsup dµ for 1 < q ≤ q′.
q→1 q q q′ ∞ dπ
2. 2∥µ−π∥2 ≤ KL(µ∥π) ≤ log(χ2(µ∥π)+1) = R (µ∥π).
TV 2
3. W2(µ,π) ≤ 2C (π)KL(µ∥π) (Talagrand’s T -inequality) and C (πK) ≲ D2.
2 LSI 2 LSI
4. W2(µ,π) ≤ 2C (π)χ2(µ∥π) [Liu20] and C (πK) ≲ ∥Cov(πK)∥ logd.
2 PI PI op
Thequerycomplexityisbetteriftheconvexbodyis(near-)isotropic,i.e.,theuniformdistribution
over the body has (near-)identity covariance. This relies on recent estimates of the worst-case
Poincaré constant for isotropic log-concave distributions [KLS95; Kla23].
5Corollary 4. Assume that πK is isotropic. Under the same setting as above, In-and-Out succeeds
with probability 1−η, returning X ∼ µ such that R (µ∥πK) ≤ ε. The number of proper steps is
q
Oe(qd2log M), and the expected total number of membership queries is Oe(qMd2log5(1/ηε)).
ηε
Ouranalysiswillinfactshowthattheboundonthenumberofproperstepsholdsforgeneralnon-
convex bodies and any feasible start in K. This is deduced under an M-warm start in Corollaries 28
and 29. We remark that such a bound for non-convex uniform sampling is not known for the
Ball walk or the Speedy walk.
Theorem 5. For any given ε ∈ (0,1) and set K ⊂ B (0) with vol(K) > 0, In-and-Out with variance
D
h and M-warm initial distribution achieves R (µX∥πX) ≤ ε after the following number of iterations:
q m
( O(cid:0) qh−1C (πX)log M(cid:1) for q ≥ 2,
m = min PI ε
O(cid:0) qh−1C (πX)log logM(cid:1) for q ≥ 1.
LSI ε
We have two different convergence results above under (LSI-I) and (PI). Under (LSI-I) we have
a doubly-logarithmic dependence on the warmness parameter M. On the other hand, using (PI),
which is weaker than (LSI-I) (in general, C ≤ C ), the dependence on M is logarithmic. We
PI LSI
discuss our results further in Section 1.3.
Outline of analysis. We summarize our proof strategy below, which consists of two steps: (i)
The current distribution should converge to the uniform distribution, (ii) within each iteration of
the algorithm, the failure probability and the expected number of rejections should be small enough.
• We need to demonstrate that the corresponding Markov chain is rapidly mixing. Here, we
use the heat flow perspective to derive mixing rates under any suitable divergence measure
(such as KL, χ2, or R ), extending known results for the unconstrained setting [Che+22]. As a
q
result, the mixing analysis reduces to a suitable functional inequality of the target distribution
alone.
• We show that the number of rejections in Line 3 over the entire execution of the algorithm
is bounded with high probability. To do this, we apply a detailed argument involving local
conductance and the convexity of K, which relies on techniques from [BNN06]. For this step,
we show that with the appropriate choice of variance h = Θ e(d−2) and threshold N = Θ e(Tη−1),
the entire algorithm succeeds with probability 1−η. The expected number of rejections is
polylogarithmic.
While each individual component resembles pre-existing work in the literature, in their synthesis
we will demonstrate how to interleave past developments in theoretical computer science, optimal
transport, and functional analysis. The combination of these in this domain yields elegant and
surprisingly simple proofs, as well as stronger results.
1.3 Discussion
Here we make a few remarks, contrasting our results with known ones.
No need to be lazy. Previous uniform samplers like the Ball walk are made lazy (i.e., with
probability 1/2, the Markov chain does nothing), to ensure convergence to the target stationary
distribution. However, our algorithm does not need this, since we directly show that our sampler
contracts towards a uniform distribution.
6Unified framework. We remark that these two different bounds also place the previously known
mixing guarantees for Ball walk,Speedy walk in a unified framework. Existing tight guarantees for
Speedy walk are in TV distance and based on the log-Sobolev constant, assuming an oracle for
implementing each step [LV17]. The known convergence guarantees of Ball walk (see Appendix B
for details), namely the mixing time of Oe(Md2D2log 1) for TV distance, are for the composite
ε
algorithm [Speedy walk+rejection sampling]. Here Speedy walk records only the accepted steps of
Ball walk, so its stationary distribution differs slightly from the uniform distribution (and can be
corrected with a post-processing step). On the other hand, In-and-Out actually converges to πK
without any adjustments and achieves stronger Rényi divergence bounds in the same asymptotic
complexity. Our analysis shows that the mixing guarantee is determined by isoperimetric constants
of the target (Poincaré or log-Sobolev).
√
Effective step size. The Ball walk’s largest possible step size is of order 1/ d (see Appendix B)
to keep the rejection probability bounded by a constant. This bound could also be viewed as an
“effective” step size of In-and-Out. This follows from the fact that the ℓ -norm of the Gaussian
√ 2
N(0,hI) √is concen √trated around hd, and we will set the variance h of In-and-Out to Oe(1/d2), so
we have hd ≈ 1/ d.
What has really changed? In-and-Out has clear similarities to both Ball walk and Speedy walk.
What then are the changes that allow us to use continuous-time interpolation? One step of Ball walk
is [random step (y ∈ B (x)) + Metropolis-filter (accept if y ∈ K)]. This filtering is an abrupt discrete
δ
step, and it is unclear how to control contraction. It could be replaced by a step of Speedy walk
(x ∼ Unif(B (y)∩K)). Then, each iteration of In-and-Out can be viewed as a Gaussian version of a
δ
Ball walk′s proposal+Speedy walk algorithm.
How can we compare In-and-Out with Speedy walk? Iterating speedy steps leads to a biased
distribution (one that is proportional to the local conductance). As clarified in Remark 2, one step of
(a Gaussian version of) Speedy walk can be understood as a step of backward heat flow. Therefore,
if one can control the isoperimetric constants of the biased distribution along the trajectory of the
backward flow, then contraction of Speedy walk toward the biased distribution will follow from the
simultaneous backward analysis.
2 Preliminaries
Unless otherwise specified, we will use ∥·∥ for the 2-norm on Rd, and operator norm on Rd×d.
We write a = O(b), a ≲ b to mean that a ≤ cb for some universal constant c > 0. Similarly,
a ≳ b,a = Ω(b) for a ≥ cb, while a = Θ(b) means that a ≲ b,b ≲ a simultaneously. We will also use
a = Oe(b) to denote a = O(bpolylog(b)). Lastly, we will use measure and density interchangeably
when there is no confusion.
To quantify the convergence rate, we introduce some common divergences between distributions.
Definition 6 (Distance and divergence). For two measures µ,ν on Rd, the total variation distance
between them is defined by
∥µ−ν∥ := sup|µ(B)−ν(B)|,
TV
B∈F
where F is the collection of all measurable subsets of Rd. The 2-Wasserstein distance is given by
W2(µ,ν) := inf E [∥X −Y∥2],
2 (X,Y)∼γ
γ∈Γ(µ,ν)
7where Γ is the set of all couplings between µ,ν. Next, we define the f-divergence of µ towards ν with
µ ≪ ν (i.e., µ is absolutely continuous with respect to ν) as, for some convex function f : R → R
+
with f(1) = 0 and f′(∞) = ∞,
Z (cid:16)dµ(cid:17)
D (µ∥ν) := f dν.
f dν
The KL-divergence arises when taking f(x) = xlogx, the χq-divergence when taking f(x) = xq −1,
and the q-Rényi divergence is given by
1
R (µ∥ν) := log(cid:0) χq(µ∥ν)+1(cid:1) .
q q−1
Werecalltwoimportantfunctionalinequalitiesofadistribution. Weuseν todenoteaprobability
measure over Rd.
Definition 7. We say that ν satisfies a Poincaré inequality (PI) with parameter C (ν) if for all
PI
smooth functions f : Rd → R,
Var f ≤ C (ν)E [∥∇f∥2], (PI)
ν PI ν
where Var f := E |f −E f|2.
ν ν ν
The Poincaré inequality is implied by the log-Sobolev inequality.
Definition 8. We say that ν satisfies a log-Sobolev inequality (LSI) with parameter C (ν) if for
LSI
all smooth functions f : Rd → R,
Ent (f2) ≤ 2C (ν)E [∥∇f∥2], (LSI-I)
ν LSI ν
where Ent (f2) := E [f2logf2]−E [f2]log(E [f2]). Equivalently, for any probability measure µ
ν ν ν ν
over Rd with µ ≪ ν,
C (ν)
KL(µ∥ν) ≤ LSI FI(µ∥ν), (LSI-II)
2
where FI(µ∥ν) := E [∥∇log dµ∥2] is the Fisher information of µ with respect to ν.
µ dν
We recall the data-processing inequality for Rényi divergence and f-divergence.
Lemma 9 (Data-processing inequality). For measures µ,ν, Markov kernel P, f-divergence D ,
f
and q ≥ 1, it holds that
D (µP ∥νP) ≤ D (µ∥ν), and R (µP ∥νP) ≤ R (µ∥ν).
f f q q
The aforementioned functional inequalities allow us to show exponential contraction of various
divergences, through the following helpful inequality.
Lemma 10 (Grönwall). Suppose that u,g : [0,T] → R are two continuous functions, with u being
differentiable on [0,T] and satisfying
u′(t) ≤ g(t)u(t) for all t ∈ [0,T].
Then,
(cid:16)Z t (cid:17)
u(t) ≤ exp g(s)ds u(0) for all t ∈ [0,T].
0
83 Analysis
We begin this section by proving some introductory lemmas, which will streamline our later
exposition.
We first record two fundamental lemmas, which introduce the mathematical formalism for our
analysis. The first is the existence of forward and backward heat flows (Lemma 22), which will
interpolate each line in Algorithm 1. These flow equations describe how the laws of Z and Z← in
t t
(FH) and (BH) evolve respectively over time.
Lemma 11. The forward heat flow equation with initial distribution µ is given by
0
1
∂ µ = ∆µ ,
t t 2 t
and its backward heat flow equation is given by
1
∂ µ← = −div(cid:0) µ←∇log(πXP )(cid:1)+ ∆µ← with µ← = µ .
t t t h−t 2 t 0 h
These admit (weak) solutions on [0,h] for any initial distribution µ with dµ0 ≤ M < ∞.
0 dπX
One successful iteration of In-and-Out is exactly the same as the composition of running the
forwardheatflowandthenbackwardheatflow, bothfortimeh. ItsvalidityisjustifiedinSection1.1,
and we give its proof below.
Lemma 12. Let µX be the law of the k-th iterate x of In-and-Out. If (FH) is initialized with
k k
law(Z ) = µX, then law(Z ) = µY . If (BH) is initialized with law(Z←) = µY , then law(Z←) =
0 k h k+1 0 k+1 h
µX .
k+1
Proof. We explicitly show that the forward and backward heat flows indeed interpolate the two
discrete steps given in Algorithm 1. For the forward part, we have Z = Z +ζ for ζ ∼ N(0,hI ), so
h 0 d
law(Z ) = law(Z )∗N(0,hI ) = µX ∗N(0,hI ) = µY .
h 0 d k d k+1
Regarding the backward part, it is known from [Che+22, Lemma 14] that the construction of the
time-reversal SDE ensures that (Z←,Z←) and (Z ,Z ) have the same joint distribution, when
h 0 0 h
Z ∼ πX (and so Z ∼ πY). Hence, law(Z←|Z← = y) = law(Z |Z = y) = πX|Y=y, where the last
0 h h 0 0 h
equality follows from (Z ,Z ) ∼ π. Since we initialize (BH) with Z← = y ∼ µY , we have
0 h 0 k+1
Z Z
law(Z←) = law(Z←|Z← = y)µY (dy) = πX|Y(·|y)µY (dy) = µX ,
h h 0 k+1 k+1 k+1
where the last follows from the definition of Line 3.
Our analysis of these objects consists of two parts: (1) demonstrating the mixing of In-and-Out,
i.e., how many outer iterations are needed to be sufficiently close to the uniform distribution, and
(2) quantifying the failure probability and wasted steps in Line 3.
For (1), we collect in Section 3.1 some important implications of functional inequalities, e.g. the
Poincaré and log-Sobolev inequalities, for the uniform distribution. Then in Section 3.2, we exploit
the flow perspective of the algorithm to obtain the mixing guarantees. To this end, we revisit the
proofs for the contraction results of forward and backward heat flows, and then extend them to our
constrained setting:
9Theorem 13 (Adapted for uniform distributions, [Che+22]). Let µX be the law of the k-th output of
k
In-and-Out with initial distribution µX. Let C be the (LSI-I) constant of the uniform distribution
0 LSI
πX over K. Then, for any q ≥ 1,
R (µX ∥πX)
R (µX ∥πX) ≤ q 0 .
q k (1+h/C )2k/q
LSI
For C the (PI) constant of πX and any q ≥ 2,
PI

R (µX ∥πX) ≤
R q(µX
0
∥πX)− 2klog(1 q+h/C PI) if k ≤ 2log(1+q
h/C PI)
(cid:0)R q(µX
0
∥πX)−1(cid:1) ,
q k (1+h/C PI)−2(k−k0)/q if k ≥ k
0
:= ⌈ 2log(1+q
h/C )
(cid:0)R q(µX
0
∥πX)−1(cid:1) ⌉.
PI
This reduces the problem of obtaining a mixing guarantee to that of demonstrating a functional
inequality on the target distribution. For this, it is not strictly necessary that K be convex.
On the other hand, convexity of K is crucial for the proof of (2). We show in Section 3.3 that
the failure probability remains under control by taking a suitable variance h and threshold N. We
then show that the expected number of trials per iteration is of order logN, not N:
Lemma 14 (Per-iteration guarantees). Let K be any convex body in Rd presented by a well-defined
membership oracle, πX the uniform distribution over K, and µ an M-warm initial distribution
with respect to πX. For any given m ∈ N and η ∈ (0,1), set Z = 9mM(≥ 9), h = loglogZ and
η 2d2logZ
N = Z(logZ)4 = Oe(mM). Then, the failure probability of one iteration of In-and-Out is at most
η
η/m. Moreover, the expected number of membership queries needed per iteration is O(cid:0) M(log mM)4(cid:1) .
η
3.1 Functional inequalities
The contraction of an outer loop of our algorithm is controlled by isoperimetry of the uniform
distribution πX, which is described precisely by a functional inequality. The most natural ones
to consider in this setting are the Poincaré inequality (PI) and log-Sobolev inequality (LSI-I). In
Appendix C, we provide a more detailed discussion of how these are related to other important
notions of isoperimetry, such as the Cheeger and log-Cheeger inequalities.
Below, we use µ,ν to denote two arbitrary probability measures over Rd. The relationship
between a Poincaré inequality and the χ2-divergence is derived by substituting f = dν into (PI).
dµ
Lemma 15. Assume that ν satisfies (PI) with parameter C (ν). For any probability measure µ
PI
over Rd with µ ≪ ν, it holds that
C (ν) dµ
χ2(µ∥ν) ≤ P 2I E ν(cid:2)(cid:13) (cid:13)∇ dν(cid:13) (cid:13)2(cid:3) .
The Poincaré inequality implies functional inequalities for the Rényi divergence.
Lemma 16 ([VW19, Lemma 9]). Assume that ν satisfies (PI) with parameter C (ν). For any
PI
q ≥ 2 and probability measure µ over Rd, it holds that
qC (ν)
1−exp(−R (µ∥ν)) ≤ PI RF (µ∥ν),
q 4 q
where RF (µ∥ν) := qE (cid:2)(cid:0)dµ(cid:1)q ∥∇log dµ∥2(cid:3) /E (cid:2)(cid:0)dµ(cid:1)q(cid:3) is the Rényi Fisher information of order q
q ν dν dν ν dν
of µ with respect to ν.
10The log-Sobolev inequality paired with the KL-divergence (LSI-II) can be understood as a special
case of the following inequality2 paired with the q-Rényi divergence for q ≥ 1.
Lemma 17 ([VW19, Lemma 5]). Assume that ν satisfies (LSI-II) with parameter C (ν). For any
LSI
q ≥ 1 and probability measure µ over Rd, it holds that
qC (ν)
R (µ∥ν) ≤ LSI RF (µ∥ν).
q 2 q
Note that lim R = KL and RF = FI.
q→1 q 1
We have collected below the functional inequalities used to establish the mixing of our algorithm
(see Appendix C for a detailed presentation).
Lemma 18. Let K ⊂ Rd be a convex body with diameter D, and π be the uniform distribution over
K. Then, C (π) ≲ ∥Cov(π)∥ logd and C (π) ≲ D2. If π is isotropic, then C (π) ≲ logd and
PI op LSI PI
C (π) ≲ D.
LSI
3.2 Contraction and mixing
We start by analyzing how many outer iterations of In-and-Out are required to be ε-close to πX,
the uniform distribution over K. The contraction of Algorithm 1 comes from analyzing Lines 2
and 3 through the perspective of heat flows (see Section 1.1). To exploit this view, we first revisit
the previous contraction analysis in [Che+22], which is carried out for distributions with smooth
densities. Although the uniform distribution is not even continuous, we prove a technical lemma
(Lemma 22) that enables us to extend previously known results to the uniform distribution. Lastly,
combining the previous results with our technical lemma, we obtain clean contraction results of
Algorithm 1 toward the uniform distribution πX in Theorem 23.
Part I: Contraction analysis for smooth distributions. Inthispart,wereviewthecontraction
results for heat flow and its time-reversal [Che+22], which are intimately connected with our
algorithm. We also provide key technical ingredients needed for its proof, such as the computations
for measures evolving under simultaneous forward/backward heat flows. We refer interested readers
to Appendix D for additional details. Only in Part I, we assume that ν denotes a probability
measure with smooth density.
Forward heat flow. We begin by introducing the “heat flow” equation (or also known as the
Fokker-Planck equation), which describes the evolution of the law of Z under (FH),
t
1 1
∂ µ = ∆µ = div(µ ∇logµ ). (FP-FH)
t t 2 t 2 t t
It is well known that one can realize this equation in discrete time through a Gaussian transition
density, in the sense that, for µ (the solution at time h > 0 to (FP-FH) with initial condition µ ),
h 0
and for any smooth function f : Rd → R,
E [f(x)] = E [P f(x)],
µ h µ0 h
where P f(x) = E [f].3 By this we can formally identify µ = µ P , and also write µ for
h N(x,hI ) h 0 h h
d
the law of Z , where {Z } solves (FH).
h h h≥0
2Such inequalities are often called Polyak-Łojasiewicz inequalities, which say for f :Rd →R, and all y∈Rd that
f(y)≤c∥∇f(y)∥2 for some constant c, if minf(x)=0.
3{P } is often called the heat semigroup.
h h≥0
11Backward heat flow. Although there are many ways to define a “reversal” of P , we will use
h
the notion of adjoint introduced by [KP21], which is the most immediately useful.
Given some initial measure ν and some time horizon h, the adjoint corresponds to reversing (FH)
for times in [0,h] when the initial distribution under consideration is Z ∼ ν. For other measures,
0
it must be interpreted more carefully, and is given by the following partial differential equation
starting from some measure µ← (see (D.1) and its derivation):
0
1
∂ µ← = −div(cid:0) µ←∇log(νP )(cid:1)+ ∆µ← for t ∈ [0,h]. (FP-BH)
t t t h−t 2 t
Write µ← = µ←Qν,h, where {Qν,h} is a family of transition densities. Write P for the
t 0 t t t∈[0,h] 0,h
joint distribution of the (Z ,Z )-marginals of (FH), when Z ∼ ν, and P for the conditional.
0 h 0 0|h
Note that P (·|x) = N(x,hI ). It is also known that (FP-BH) gives a time-reversal of the heat
h|0 d
equation at the SDE level, in the sense that we can interpret δ Qν,h = P (·|Z = x). Thus
x h 0|h h
µ←Qν,h = R P (·|Z = x)µ←(dx), and νP Qν,h = νP for all t ∈ [0,h].
0 h 0|h h 0 h t h−t
The ultimate purpose of this machinery is to affirm our earlier description of the Gibbs sampling
procedure as alternating forward and backward heat flows. Indeed, notice that, if µX is the law of
i
the iterate at some iteration i, then µXP is precisely µY under our scheme, while (µXP )QπX,h
i h i+1 i h h
is µX , assuming QπX,h is well defined for non-smooth measures πX. Thus, while Algorithm 1 is
i+1 h
implemented via discrete steps, it can be exactly analyzed through arguments in continuous time.
We shall see the benefits of this shortly.
Instead of considering the change in metrics along the evolution of µP with respect to “fixed”
t
ν, it will be useful to consider the simultaneous evolution of µP ,νP (and similarly µQ ,(νP )Q ).
t t t h t
This type of computation was carried out for specific metrics in earlier work [VW19; Che+22]. The
following is a more generalized form of one appearing in [Yua+23, Lemma 2]. In the lemma below,
we consider an arbitrary diffusion equation with corresponding Fokker-Planck equation:
1
dX = b (X )dt+ dB and ∂ µ = −∇·(b µ )+ ∆µ (3.1)
t t t t t t t t 2 t
where b : Rd → Rd is smooth, X ∈ Rd, and µ = Law(X ) if X ∼ µ .
t t t t 0 0
Lemma 19 (Decay along forward/backward heat flows). Let (µ ) ,(ν ) denote the laws of the
t t≥0 t t≥0
solutions to (3.1) starting at µ ,ν respectively. Then, for any differentiable function g,
0 0
∂ g(cid:0) D (µ ∥ν )(cid:1) = −1 g′(cid:0) D (µ ∥ν )(cid:1) ×E D ∇(cid:0) f′◦ µ t(cid:1) ,∇log µ tE .
t f t t 2 f t t µt ν ν
t t
Proof. The case where g ≠ id is an application of the chain rule, so it suffices to take g = id and
simply differentiate an f-divergence.
For brevity, we drop the variable x of functions involved, and proceed as follows:
∂ D (µ ∥ν ) = Z n(cid:0) f ◦ µ t(cid:1) ∂ ν +(cid:0) f′◦ µ t(cid:1)(cid:0)µ t(cid:1)′ ν o dx
t f t t t t t
ν ν ν
t t t
= Z n ∂ ν (cid:16)(cid:0) f ◦ µ t(cid:1) −(cid:0) f′◦ µ t(cid:1)µ t(cid:17) +(cid:0) f′◦ µ t(cid:1) ∂ µ o dx
t t t t
ν ν ν ν
t t t t
= Z (cid:2) −∇·(b ν )+ 1 ∆ν (cid:3)(cid:16)(cid:0) f ◦ µ t(cid:1) −(cid:0) f′◦ µ t(cid:1)µ t(cid:17) dx
(i) t t 2 t ν t ν t ν t
Z 1 µ
+ (cid:2) −∇·(b µ )+ ∆µ (cid:3)(cid:0) f′◦ t(cid:1)dx,
t t 2 t ν
t
12where in (i) we substitute the F-P equation from (3.1). Integrating by parts (i.e., R fdiv(G) =
−R ⟨∇f,G⟩ for a real-valued function f and vector-valued function G), we have that
Z (cid:2) −∇·(b ν )(cid:3)(cid:0) f ◦ µ t(cid:1)dx = Z D b ν ,(cid:0) f′◦ µ t(cid:1) ∇µ tE dx. (3.2)
t t t t
ν ν ν
t t t
On the other hand, we have that
−Z (cid:2) −∇·(b ν )(cid:3)(cid:0) f′◦ µ t(cid:1)µ t dx = −Z D b ν , µ t ∇(cid:0) f′◦ µ t(cid:1)+(cid:0) f′◦ µ t(cid:1) ∇µ tE dx.
t t t t
ν ν ν ν ν ν
t t t t t t
The second term cancels with the RHS of (3.2). We have a similar cancellation for the 1∆ν term:
2 t
Z 1 ∆ν (cid:0) f ◦ µ t(cid:1)dx = −Z 1 D ∇ν ,(cid:0) f′◦ µ t(cid:1) ∇µ tE dx,
2 t ν 2 t ν ν
t t t
and
−Z 1 ∆ν (cid:0) f′◦ µ t(cid:1)µ t dx = Z 1 D ∇ν , µ t ∇(cid:0) f′◦ µ t(cid:1)+(cid:0) f′◦ µ t(cid:1) ∇µ tE dx.
2 t ν ν 2 t ν ν ν ν
t t t t t t
Combining these, we are left with
Z (cid:2) −∇·(b ν )+ 1 ∆ν (cid:3)(cid:16)(cid:0) f ◦ µ t(cid:1) −(cid:0) f′◦ µ t(cid:1)µ t(cid:17) dx = −Z D b ν − 1 ∇ν ,∇(cid:0) f′◦ µ t(cid:1)µ tE dx
t t 2 t ν ν ν t t 2 t ν ν
t t t t t
= −Z D b µ − 1 µ ∇logν ,∇(cid:0) f′◦ µ t(cid:1)E dx.
t t 2 t t ν
t
Finally, we note that
Z (cid:2) −∇·(b µ )+ 1 ∆µ (cid:3)(cid:0) f′◦ µ t(cid:1)dx = Z D b µ − 1 ∇µ ,∇(cid:0) f′◦ µ t(cid:1)E dx
t t 2 t ν t t 2 t ν
t t
= Z D b µ − 1 µ ∇logµ ,∇(cid:0) f′◦ µ t(cid:1)E dx.
t t 2 t t ν
t
Putting it all together, noticing that the drift terms cancel, we are left with
∂ D (µ ∥ν ) = −Z 1 D µ ∇log µ t ,∇(cid:0) f′◦ µ t(cid:1)E dx = −1 E D ∇log µ t ,∇(cid:0) f′◦ µ t(cid:1)E ,
t f t t 2 t ν ν 2 µt ν ν
t t t t
which completes the proof.
To recover the decay result for the q-Rényi divergence, one can substitute g(x) = 1 logx and
q−1
f(x) = xq −1. For the χ2-divergence, instead substitute g(x) = x and f(x) = x2−1. From this,
we can obtain a single step of decay for the Rényi and χ2-divergences under different functional
inequalities.
Before proceeding, we need a standard lemma on functional inequalities under (FH).
Lemma 20 (Functional inequalities under Gaussian convolutions, [Cha04, Corollary 13]). The
following inequality holds for any π with finite log-Sobolev and Poincaré constants,
C (πP ) ≤ C (π)+t, and C (πP ) ≤ C (π)+t.
PI t PI LSI t LSI
Combining the previous two lemmas, we can establish contraction between µP Q and ν after
h h
one forward/backward iteration.
13Theorem 21 ([Che+22, Theorem 3 and 4]). Assume ν, a measure with smooth density, satisfies
(LSI-I) with constant C . For any q ≥ 1 and initial distribution µ with a smooth density, denoting
LSI
again Q := Qν,h,
h h
R (µ∥ν)
R (µP Q ∥ν) ≤ q .
q h h (1+h/C )2/q
LSI
If ν satisfies (PI) with constant C , then it follows that
PI
χ2(µ∥ν)
χ2(µP Q ∥ν) ≤ .
h h (1+h/C )2
PI
Moreover, for all q ≥ 2,

R (µP Q ∥ν) ≤
R q(µ∥ν)− 2log(1+ qh/C PI) if R q(µ∥ν) ≥ 1,
q h h  (1R +q h( /µ C∥ν)
)2
if R q(µ∥ν) ≤ 1.
PI
Proof. Since the SDE in (3.1) captures the forward heat flow (FH), we set µ and ν in Lemma 19
0 0
to µ and ν, respectively, obtaining contraction along the forward heat flow as follows: Substituting
the q-Rényi into Lemma 19, we have, from the definition of the Rényi divergence as R (µ∥ν) :=
q
1 log(D (µ∥ν)+1), with f(x) = xq −1 and g(x) = 1 log(x+1),
q−1 f q−1
hD (cid:16) (cid:17)q−1 Ei h(cid:16) (cid:17)q−2 i
E ∇ µPt ,∇log µPt E µPt ⟨∇µPt,∇log µPt⟩
∂ R (µP ∥νP ) = −q µPt νPt νPt = −q µPt νPt νPt νPt
t q t t 2 h(cid:16) (cid:17)qi 2 h(cid:16) (cid:17)qi
(q−1)E µPt (i) E µPt
νPt νPt νPt νPt
h(cid:16) (cid:17)q i
=
−q E νPt µ νPP tt ∥∇log µ νPP tt∥2
=
−1
RF (µP ∥νP ),
(ii)
2
E
h(cid:16) µPt(cid:17)qi 2 q t t
νPt νPt
where in (i), we use again that ∇(cid:2) f′(cid:0)µt(cid:1)µt(cid:3) = ∇(cid:0) f′ ◦ µt(cid:1) · µt + f′(cid:0)µt(cid:1) ∇µt, and (ii) uses that
νt νt νt νt νt νt
∇µPt = µPt∇log µPt, and the last equality recalls the definition of the Rényi Fisher information.
Thν iP styieldνP st νPt
1 1R (µP ∥νP ) 1R (µP ∥νP )
∂ R (µP ∥νP ) = − RF (µP ∥νP ) ≤ − q t t ≤ − q t t ,
t q t t 2 q t t q C (νP ) q C +t
(i) LSI t (ii) LSI
where we used Lemma 17 in (i) and Lemma 20 in (ii). Applying Grönwall’s inequality (Lemma 10),
(cid:16) 1 Z h 1 (cid:17) R (µ∥ν)
R (µP ∥νP ) ≤ exp − dt R (µ∥ν) ≤ q .
q h h q C +t q (1+h/C )1/q
0 LSI LSI
Since the SDE (3.1) also captures the backward equation (BH), we set µ and ν in Lemma 19
0 0
to µP and ν˜ := νP respectively, obtaining contraction along the backward heat flow:
h h
1 1 R (µP Q ∥ν˜Q ) 1 R (µP Q ∥ν˜Q )
∂ R (µP Q ∥ν˜Q ) = − RF (µP Q ∥ν˜Q ) ≤ − q h t t ≤ − q h t t ,
t q h t t 2 q h t t q C (ν˜Q ) q C +h−t
LSI t (i) LSI
where (i) follows from that ν˜Q = νP Q = νP and C (ν˜Q ) ≤ C +h−t due to Lemma 20.
t h t h−t LSI t LSI
Applying Lemma 10 again yields
R (µP ∥ν˜)
R (µP Q ∥ν) ≤ q h .
q h h (1+h/C )1/q
LSI
14Composing these two inequalities leads to the decay rate claimed in the theorem.
The result in the χ2-divergence can be derived entirely analogously. For instance, the decay
from the forward part can be shown as follows:
1 h(cid:13) µP (cid:13)2i χ2(µP ∥νP ) χ2(µP ∥νP )
∂ χ2(µP ∥νP ) = − E (cid:13)∇ t(cid:13) ≤ − t t ≤ − t t ,
t t t 2 νPt (cid:13) νP (cid:13) C (νP ) C +t
t (i) PI t PI
where (i) follows from Lemma 15. Applying Grönwall’s inequality then gives
(cid:16) Z h 1 (cid:17) χ2(µ∥ν)
χ2(µP ∥νP ) ≤ exp − dt χ2(µ∥ν) ≤ .
h h C +t 1+h/C
0 PI PI
The decay along the backward heat flow in χ2 is entirely analogous to the Rényi case. Then we
combine two contraction results from the forward and backward flows, completing the proof.
The result in the R under (PI) can be shown in a similar manner. Only difference is that in
q
forward and backward computations, one should use the functional inequality in Lemma 16 and the
following standard inequalities:
(1 if R (µ∥ν) ≥ 1,
1−exp(cid:0) −R (µ∥ν)(cid:1) ≥ 2 q
q 1R (µ∥ν) if R (µ∥ν) ≤ 1.
2 q q
Part II: Extension to constrained distributions. We now prove a technical lemma that
extends the contraction results to constrained distributions. This lemma guarantees the existence of
weak solutions to two stochastic processes that describe the evolution of distributions involved in
Line 2 and 3 in In-and-Out, in addition to lower-semicontinuity of f-divergence. We shall prove it
for any measure that is absolutely continuous with respect to πX, since this imposes no additional
technical hurdles.
Lemma 22. Let ν be a measure, absolutely continuous with respect to the uniform measure πX.
The forward and backward heat flow equations given by
1
∂ µ = ∆µ ,
t t 2 t
1
∂ µ← = −div(cid:0) µ←∇log(νP )(cid:1)+ ∆µ← with µ← = µ ,
t t t h−t 2 t 0 h
admit solutions on (0,h], and the weak limit lim µ← = µ← exists for any initial measure µ with
t→h t h 0
bounded support. Moreover, for any f-divergence with f lower semi-continuous,
D (µ←∥ν) ≤ limD (µ← ∥ν ).
f h f h−t t
t↓0
Proof. The existence of weak solutions for the forward equation is well-known, since µ can be
0
weakly approximated by measures with continuous density, for which the heat equation admits a
unique solution for all time. In particular, the weak solution is C∞ for t > 0.
The reverse SDE is more subtle, since ∇logνP will in general cease to be Lipschitz as t → 0.
t
On the other hand, for any h > 0, we can write explicitly
1 Z ∥x−y∥2
µ (x) = exp(cid:0) − (cid:1)dµ (y).
h (2πh)d/2 2h 0
15If one considers the system started at µ˜ = µ = νP and solve the forward-backward Fokker-Planck
0 ϵ ϵ
equations on times [0,h−ϵ], then µ˜ = µ = µ← = µ˜← and
h−ϵ h 0 0
Z exp(cid:0) −∥x−y∥2(cid:1) νP (x)
µ← (x) = µ˜← (x) = 2(h−ϵ) ϵ dµ (y).
h−ϵ h−ϵ R exp(cid:0) −∥z−y∥2(cid:1) νP (z)dz h
2(h−ϵ) ϵ
This follows from that if we consider system started at time ϵ > 0, with initial distribution µ , then
ϵ
we obtain the above through the Bayesian perspective on the forward and reverse heat semigroups,
elaborated in Appendix D.
We now show that the following integral is indeed integrable, so µ˜← is well-defined:
h
Z exp(cid:0) −∥x−y∥2(cid:1) ν(x)
µ˜←(x) := 2h dµ (y).
h R exp(cid:0) −∥z−y∥2(cid:1) ν(z)dz h
2h
For fixed x and ϵ < h/2,
Z ∥z−y∥2 (∥y−x ∥+D)2
exp(cid:0) − (cid:1) ν(z)dz ≳ exp(cid:0) − 0 (cid:1) ,
2(h−ϵ) 2(h−ϵ)
asthesupportofν isconstrainedtoK ⊂ B (x ). Sinceµ hasboundedsupport,µ (y) ≲ exp(−∥y∥2)
D 0 0 h a
for some constant a > 0. Thus,
exp(cid:0) −∥ 2x (h− −y∥ ϵ)2(cid:1) µ h(y)
≲
exp(cid:0) −∥ 2x (h− −y∥ ϵ)2(cid:1) µ h(y)
≲
exp(cid:16)⟨2(x−x 0),y⟩+2D∥y−x 0∥
−
∥y∥2(cid:17)
,
R exp(cid:0) −∥z−y∥2(cid:1) νP (z)dz exp(−(∥y−x0∥+D)2) h a
2(h−ϵ) ϵ 2(h−ϵ)
and the last bound is integrable in y.
We then show the pointwise convergence of µ˜← to µ˜← as ϵ → 0. Note that νP → ν, as ν has
h−ϵ h ϵ
a bounded support. Also, the denominator is independent of ϵ due to
1 Z ∥z−y∥2
exp(cid:0) − (cid:1) νP (z)dz = N(0,(h−ϵ)I)∗νP = ν ∗N(0,hI).
(2π(h−ϵ))d/2 2(h−ϵ) ϵ ϵ
Hence, for ϵ ≤ d−1,
exp(cid:0) −∥ 2x (h− −y∥ ϵ)2(cid:1)
≤
(cid:16) h (cid:17)d/2
exp(cid:0) −∥x− 2hy∥2(cid:1)
≲
exp(cid:0) −∥x− 2hy∥2(cid:1)
.
R exp(cid:0) −∥z−y∥2(cid:1) νP (z)dz h−ϵ R exp(cid:0) −∥z−y∥2(cid:1) ν(z)dz R exp(cid:0) −∥z−y∥2(cid:1) ν(z)dz
2(h−ϵ) ϵ 2h 2h
As shown above, the last bound is integrable with respect to µ , so the dominated convergence
h
theorem implies
Z exp(cid:0) −∥x−y∥2(cid:1) Z exp(cid:0) −∥x−y∥2(cid:1)
lim 2(h−ϵ) dµ (y) = 2h dµ (y),
ϵ→0 R exp(cid:0) −∥z−y∥2(cid:1) νP (z)dz h R exp(cid:0) −∥z−y∥2(cid:1) ν(z)dz h
2(h−ϵ) ϵ 2h
Thus, the pointwise convergence follows. Note that if we take ν(x) = πX(x) = 1 K(x), then µ˜← is
vol(K) h
the distribution of the backwards step of our algorithm. In particular, this corresponds to first
sampling x ∼ µ , then y ∼ Qν,h(·|x), which is precisely the law of µ← given by (FP-BH).
h h h
As for the second statement, it follows from Scheffé’s lemma [Bil95, Theorem 16.12] that the
pointwise convergence of µ← → µ← leads to its TV-convergence, which in turn implies the weak
h−ε h
convergence. It follows from lower semicontinuity of D [AFP00, Theorem 2.34] that the weak
f
convergence ensures D (µ←∥ν) ≤ lim D (µ← ∥ν← ).
f h t↓0 f h−t h−t
16In the sequel, we will only consider ν = πX. Since the Rényi divergence is a continuous
function of the χq divergence (see Definition 6), which itself is an f-divergence, it enjoys the same
lower-semicontinuity properties. Using this lower-semicontinuity together with the decay results in
Theorem 21, we can easily derive the contraction results of In-and-Out in R and χq for any q ≥ 1.
q
We remark that this result does not require convexity of K.
Theorem 23. Let µX be the law of the k-th output of In-and-Out with initial distribution µX. Let
k 0
C be the (LSI-I) constant of the uniform distribution πX over K. Then, for any q ≥ 1,
LSI
R (µX ∥πX)
R (µX ∥πX) ≤ q 0 .
q k (1+h/C )2k/q
LSI
For C the (PI) constant of πX,
PI
χ2(µX ∥πX)
χ2(µX ∥πX) ≤ 0 .
k (1+h/C )2k
PI
Furthermore, for any q ≥ 2,

R (µX ∥πX) ≤
R q(µX
0
∥πX)− 2klog(1 q+h/C PI) if k ≤ 2log(1+q
h/C PI)
(cid:0)R q(µX
0
∥πX)−1(cid:1) ,
q k (1+h/C PI)−2(k−k0)/q if k ≥ k
0
:= ⌈ 2log(1+q
h/C )
(cid:0)R q(µX
0
∥πX)−1(cid:1) ⌉.
PI
Proof. Let us set µ = µX and π = πX. Then, µ = µ← = µY, π = π← = πY, and µ← = µX,
0 0 0 h 0 1 h 0 h 1
π← = πX. For small ϵ > 0, as µ = (µX) = µX ∗N(0,ϵI ) is C∞-smooth, we can now invoke the
h ϵ 0 ϵ 0 d
decayresultswithstepsizeh−ϵinTheorem21. Thus,forcontractionconstantsC = (1+ h−ϵ )−2/q
ϵ C +ϵ
LSI
and C = (1+ h−ϵ )−2 respectively when Φ = R and Φ = χ2,
ϵ C +ϵ q
PI
Φ(µ← ∥π ) ≤ C ·Φ(µ ∥π ) ≤ C ·Φ(µ ∥π ),
h−ϵ ϵ ϵ ϵ ϵ ϵ 0 0
where we used the data-processing inequality for the last inequality. By the second result of
Lemma 22, sending ϵ → 0 leads to
Φ(µX ∥πX) = Φ(µ←∥π ) ≤ C ·Φ(µ ∥π ) = C ·Φ(µX ∥πX).
1 h 0 0 0 0
Repeating this argument k times completes the proof.
3.3 Failure probability and wasted steps
We begin by defining a suitable version of local conductance [KLS97].
Definition 24 (Local conductance). The local conductance ℓ on Rd is defined by
R exp(− 1 ∥x−y∥2)dy R exp(− 1 ∥x−y∥2)dy
ℓ(x) d=ef K 2h = K 2h .
R exp(− 1 ∥x−y∥2)dy (2πh)d/2
Rd 2h
The local conductance at y quantifies the success probability of the proposal at y in Line 3.
Then the expected number of trials until the first success of Line 3 is 1/ℓ(y). Revisiting (1.1), we
can notice πY(y) = ℓ(y)/vol(K).
17Naïve analysis for expected number of trials. Starting from πX, when we just naïvely sample
from πY|X(·|x) for all x without imposing any failure condition, the expected number of trials for
one iteration is that for the probability density p of N(x,hI ),
x d
Z Z 1 Z 1 Z 1 ℓ(y)
p (dy)πX(dx) = πY(dy) = dy = ∞.
K Rd
ℓ(y) x
Rd
ℓ(y)
Rd
ℓ(y) vol(K)
This suggests that one should consider the algorithm as having “failed” if the number of trials
exceeds some threshold.
Refined analysis under a failure condition. Going forward, we assume an M-warm start as
in previous work for uniform sampling algorithms. By induction we have dµX i ≤ M for all i.
dπX
Lemma 25 (Propagation of warm-start). From an M-warm start, we have dµX
i
/dπX ≤ M for all i.
Proof. Assume that µX satisfies the M-warm start. Then, for any measurable S and the transition
i
kernel T of Algorithm 1 at x,
x
Z Z
µX (S) = T (S)dµX(x) ≤ M T (S)dπX(x) = MπX(S),
i+1 x i x
K K
where the last equality follows from the stationarity of π. Hence, dµX /dπX ≤ M.
i+1
We now establish a lemma that comes in handy when analyzing the failure probability of the
algorithm. In essence, this lemma bounds the probability that taking a Gaussian step from πX in
Line2getsδ-distanceawayfromK. Letusdenotetheδ-blowupofKbyK := {x ∈ Rd : d(x,K) ≤ δ}.
δ
Lemma 26. πY(K δc) ≤ ec2 1exp(−t2/8c2 1) for δ = t/d and variance h = c2 1/d2, where c
1
is some
constant and t ≥ 2c (c +1).
1 1
Proof. For y ∈ ∂K , we can take the supporting half-space H at proj (y) containing K, due to
δ K
convexity of K. Then,
1 Z Z exp(cid:0) − 1 ∥y−x∥2(cid:1) 1 Z Z exp(cid:0) − 1 ∥y−x∥2(cid:1)
πY(Kc) = 2h dxdy ≤ 2h dxdy
δ vol(K)
Kc K
(2πh)d/2 vol(K)
Kc H
(2πh)d/2
δ δ
1 Z Z ∞ exp(cid:0) − 1 z2(cid:1)
= √ 2h dzdy. (3.3)
vol(K)
Kc d(y,K)
2πh
δ
Let us denote the tail probability of the 1-dimensional Gaussian with variance h by
1 Z ∞ 1
T(s) := P (Z ≥ s) = √ exp(cid:0) − z2(cid:1)dz.
Z∼N(0,h) 2πh
s
2h
By the co-area formula and integration by parts,
Z Z ∞ exp(cid:0) − 1 z2(cid:1) Z ∞
√ 2h dzdy = T(s)vol(∂K )ds
Kc d(y,K)
2πh
δ
s
δ
= h T(s)Z s vol(∂K )dzi∞ +Z ∞ √1 exp(cid:0) −s2 (cid:1)Z s vol(∂K )dzds. (3.4)
0
z
δ δ
2πh 2h
0
z
| {z }
=:F
18Recall that T(s) ≤ 1 exp(−1(sh−1/2)2) for s ≥ δ = t/d due to a standard tail bound on a Gaussian
2 2
distribution. This tail bound, combined with
Z s
vol(∂K )dz = vol(K )−vol(K) ≤ vol(cid:0)(1+s)K(cid:1) −vol(K) = (cid:0)(1+s)d−1(cid:1)vol(K),
z s
0
ensures that F vanishes at s = ∞. Hence, bounding the first term in (3.4) by 0 results in
Z Z ∞ exp(cid:0) − 1 z2(cid:1) 1 Z ∞ s2
√ 2h dzdy ≤ √ exp(cid:0) − (cid:1)(cid:0)(1+s)d−1(cid:1)vol(K)ds
Kc d(y,K)
2πh 2πh
δ
2h
| {z }
δ
≤exp(sd)
vol(K) Z ∞ (cid:16) 1 (cid:17)
≤ √ exp(hd2/2) exp − (s−hd)2 ds
2πh
δ
2h
1
≤
vol(K)exp(hd2/2)exp(cid:0)
−
(δh−1/2−dh1/2)2(cid:1)
2
(i)
t2
≤
vol(K)exp(c2/2)exp(cid:0)
−
(cid:1)
,
1 8c2
(ii) 1
where in (i) we used the tail bound of a Gaussian, and (ii) follows from that in the regime of
h = c2 1d−2, we have δh−1/2−dh1/2−1 ≥ t/c 1−(c 1+1) ≥ t/2c1 for t ≥ 2c 1(c 1+1). Putting the last
bound into (3.3) completes the proof of the claim.
Now we choose a suitable threshold N for bounding the failure probability. Following (3.3) in
the proof, one can notice that for y ∈ Kc, δ = Ω(1/d), and h = Θ(d−2),
δ
Z ∞ exp(cid:0) − 1 z2(cid:1)
ℓ(y) ≤ √ 2h dz = P (Z ≥ δ) ≤ exp(−Ω(t2)).
d(y,K)
2πh Z∼N(0,h)
Thus, the expected number of trials from Kc for the rejection sampling in Line 3 is ℓ(y)−1 ≥
δ
exp(Ω(t2)). Intuitively, one can ignore whatever happens in Kc, since K takes up most of measure
δ δ
ofπY. AsthenumberoftrialsfromKc isatleastexp(Ω(t2))inexpectation,themoststraightforward
δ
way to ignore algorithmic behaviors from Kc is simply to set the threshold to N = Oe(exp(t2)). Even
δ
though the threshold is N, the expected number of trials is much lower.
Lemma 14 bounds the failure probability and expected number of trials per iteration.
Proof of Lemma 14. Forµ := µ∗N(0,hI ),thefailureprobabilityisE [(1−ℓ)N]. Sincedµ/dπX ≤
h d µ h
M implies dµ /d(πX) = dµ /dπY ≤ M, it follows that
h h h
E [(1−ℓ)N] ≤ M E [(1−ℓ)N].
µ h πY
Then,
Z Z Z Z
(1−ℓ)N dπY = A+ A+ A
Rd| {z } K δc K δ∩[ℓ≥N−1log(3mM/η)] K δ∩[ℓ<N−1log(3mM/η)]
=:A
Z Z ℓ(y)
≤ πY(Kc)+ exp(−ℓN)dπY + dy
δ vol(K)
[ℓ≥N−1log(3mM/η)] K ∩[ℓ<N−1log(3mM/η)]
δ
t2 η log(3mM/η) vol(K )
≤ ec2 1exp(− )+ + δ
8c2 3mM N vol(K)
1
t2 η et 3mM
≤ ec2 1exp(− )+ + log ,
8c2 3mM N η
1
19where we used vol(K ) ⊂ vol(cid:0)(1 + δ)K(cid:1) = (1 + δ)dvol(K) ≤ etvol(K). Taking c2 = loglogZ,
√ δ 1 2logZ
t = 8loglogZ, and N = Z(logZ)4, we can bound the last line by η . Therefore,
mM
η
E [(1−ℓ(·))N] ≤ M E [(1−ℓ(·))N] ≤ .
µ h πY m
We now bound the expected number of trials per iteration. Let X be the minimum of the
threshold N and the number of trials until the first success. Then the expected number of trials per
step is bounded by ME [X] due to dµ /dπY ≤ M. Thus,
πY h
Z (cid:16)1 (cid:17) Z 1 vol(K )
∧N dπY ≤ dπY +NπY(Kc) = δ +NπY(Kc)
Rd ℓ K ℓ δ vol(K) δ
δ
≤ et+N exp(−Ω(t2)) ≤ (logZ)3+3(logZ)4 =
O(cid:16)(cid:0)log mM (cid:1)4(cid:17)
.
η
Therefore, the expected number of trials per step is O(cid:0) M(log mM)4(cid:1), and the claim follows since
η
each trial uses one query to the membership oracle of K.
3.4 Putting it together
WecannowshowthatIn-and-Outsubsumespreviousresultsonuniformsamplingfromconvexbodies
(such as Ball walk and Speedy walk), providing detailed versions of the main results in Section 1.2.
We first establish that the query complexity of In-and-Out matches that of the Ball walk under
stronger divergences. Recall that 2∥·∥2 ≤ KL ≤ log(1+χ2) ≤ χ2.
TV
Theorem 27. For any given η,ε ∈ (0,1), q ≥ 1, m ∈ N defined below and any convex body K given
by a well-defined membership oracle, consider In-and-Out (Algorithm 1) with an M-warm initial
distribution µX, h = (2d2log 9mM)−1, and N = Oe(mM). For πX the uniform distribution over K,
0 η η
• It achieves R q(µX m∥πX) ≤ ε after m = Oe(qd2∥Cov(πX)∥ oplog M ηε) iterations. With probability
1−η, thealgorithmiteratesthismanytimeswithoutfailure, usingOe(qMd2∥Cov(πX)∥ op(log η1 ε)5)
expected number of membership queries in total.
• For isotropic πX, with probability 1 − η, the algorithm achieves R (µX ∥ πX) ≤ ε with
q m
m = Oe(qd2log M) iterations, using Oe(qMd2(log 1 )5) membership queries in expectation.
ηε ηε
Proof. We just put together Lemma 14 and Theorem 23. For target accuracy ε > 0, we use
the R -decay under (PI) for q ≥ 2 in Theorem 23. The M-warm start assumption guarantees
q
R (µX ∥ πX) ≲ logM. Due to C (πX) = O(∥Cov(πX)∥ logd) (Lemma 18), In-and-Out can
q 0 PI op
achieve R q(µX
m
∥πX) ≤ ε after m = Oe(qd2∥Cov(πX)∥ oplog M ηε) iterations. Since each iteration has
η/m-failure probability by Lemma 14, the union bound ensures that the total failure probability is at
most η throughout m iterations. Lastly, each iteration requires Oe(M(log 1 )4) membership queries
ηε
in expectation by Lemma 14. Therefore, In-and-Out uses Oe(qMd2min(D2,∥Cov(πX)∥ op)(log η1 ε)5)
expected number of membership queries over m iterations. Since R is non-decreasing in q, we can
q
obtain the desired bound on R for q ∈ [1,2).
q
For isotropic πX, we have Cov(πX) = I , so the claim immediately follows from C (πX) =
d PI
O(logd) (see Lemma 18).
We now show that the number of proper steps is bounded as claimed for general non-convex
bodies and any feasible start in K. We first establish this result under an M-warm start (Theorem 5).
20Proof of Theorem 5. By the Rényi-decay under (LSI-I) in Theorem 23, In-and-Out can achieve
ε-distance to πX after O(cid:0) qh−1C (πX)log R q(µX 1 ∥πX)(cid:1) iterations for q ≥ 1.
LSI ε
For q ≥ 2, we use the decay result under (PI). In this case, In-and-Out decays under two different
rates depending on the value of R (·∥πX). It first needs O(qh−1C (πX)R (µX ∥πX)) iterations
q PI q 0
until R (·∥πX) reaches 1. Then, In-and-Out additionally needs O(qh−1C (πX)log 1) iterations,
q PI ε
and thus it needs O(qh−1C (πX)(cid:0)R (µX ∥ πX) + log 1(cid:1)) iterations in total. By substituting
PI q 0 ε
R (µX ∥πX) ≲ logM, we complete the proof.
q 0
Next, we show that In-and-Out mixes from any start.
Corollary 28. For any given ε ∈ (0,1) and set K ⊂ B (0), In-and-Out with variance h and any
D
feasible start x
0
∈ K achieves R q(µX
m
∥πX) ≤ ε after m = Oe(qh−1C LSI(πX)log d+D ε2/h) iterations.
Proof. We first bound the warmness of µX w.r.t. πX when µX = δ . One can readily check that
1 0 x0
Z exp(cid:0) − 1 ∥y−x∥2(cid:1)exp(cid:0) − 1 ∥y−x ∥2(cid:1)
µX(x) = 1 (x)· 2h 2h 0 dy.
1 K (2πh)d/2R exp(cid:0) − 1 ∥y−x∥2(cid:1)dx
K 2h
By Young’s inequality, ∥y−x∥2 ≤ (∥y∥+D)2 ≤ 3∥y∥2+3D2 for x ∈ K. Hence,
2
Z exp(cid:0) − 1 ∥y−x∥2(cid:1)exp(cid:0) − 1 ∥y−x ∥2(cid:1)
2h 2h 0 dy
R exp(cid:0) − 1 ∥y−x∥2(cid:1)dx
K 2h
≤exp(2h−1D2) Z exp(cid:16) − 1 (cid:0) ∥y−x∥2+∥y−x ∥2− 3 ∥y∥2(cid:1)(cid:17) dy
vol(K) 2h 0 2
=exp(2h−1D2) Z exp(cid:16)
−
1 (cid:0)1
∥y−2(x+x )∥2+(∥x∥2+∥x ∥2−2∥x+x
∥2)(cid:1)(cid:17)
dy
vol(K) 2h 2 0 0 0
exp(5h−1D2) Z (cid:16) 1 (cid:17)
≤ exp − ∥y−2(x+x )∥2 dy
vol(K) 4h 0
exp(5h−1D2)
= (4πh)d/2.
vol(K)
Therefore, M = esssup µX 1 ≤ 2d/2exp(5h−1D2). By Theorem 5 under (LSI-I), In-and-Out needs
πX
Oe(qh−1C LSI(πX)log d+D ε2/h) iterations.
We then obtain the following corollary for a convex body K.
Corollary 29. For any given ε ∈ (0,1) and convex body K ⊂ B (0), In-and-Out with variance h
D
and an M-warm initial distribution achieves R q(µX m∥πX) ≤ ε after m = Oe(qh−1D2log 1 ε) iterations.
If πX is isotropic, then In-and-Out only needs Oe(qh−1Dlog d+d2/h) iterations.
ε
Proof. For convex K, it follows from Lemma 18 that C (πX) = O(D2) and C (πX) = O(D) for
LSI LSI
isotropic K. The rest of the proof can be completed in a similar way.
For h = Θ˜(d−2), In-and-Out requires Oe(qd2D2) iterations and in particular Oe(qd2D) iteration
for isotropic uniform distributions. These results match those of Speedy walk [KLM06; LV17] (see
Theorem 31).
Acknowledgements. We are deeply grateful to Andre Wibisono and Sinho Chewi for helpful
comments and pointers to the literature for Lemma 19. This work was supported in part by NSF
award 210644, NSERC through the CGS-D award, and a Simons Investigator award.
21References
[AC21] K.AhnandS.Chewi.“Efficientconstrainedsamplingviathemirror-Langevinalgorithm”.
In: Advances in Neural Information Processing Systems (NeurIPS) 34 (2021), pp. 28405–
28418.
[AFP00] L. Ambrosio, N. Fusco, and D. Pallara. Functions of bounded variation and free discon-
tinuity problems. Oxford University Press, 2000.
[AGS05] L. Ambrosio, N. Gigli, and G. Savaré. Gradient flows: in metric spaces and in the space
of probability measures. Springer Science & Business Media, 2005.
[BNN06] M. Belkin, H. Narayanan, and P. Niyogi. “Heat flow and a faster algorithm to compute
the surface area of a convex body”. In: Foundations of Computer Science (FOCS). IEEE.
2006, pp. 47–56.
[Bes+95] J.Besag,P.Green,D.Higdon,andK.Mengersen.“Bayesiancomputationandstochastic
systems”. In: Statistical Science (1995), pp. 3–41.
[Bil95] P. Billingsley. Probability and measure. John Wiley & Sons, 1995.
[Bin+19] E. Bingham, J. P. Chen, M. Jankowiak, F. Obermeyer, N. Pradhan, T. Karaletsos, R.
Singh,P.A.Szerlip,P.Horsfall,andN.D.Goodman.“Pyro:Deepuniversalprobabilistic
programming”. In: The Journal of Machine Learning Research (JMLR) 20 (2019), 28:1–
28:6.
[Bro+17] N. Brosse, A. Durmus, Ã. Moulines, and M. Pereyra. “Sampling from a log-concave
distributionwithcompactsupportwithproximalLangevinMonteCarlo”.In:Conference
on Learning Theory (COLT). Vol. 65. PMLR, 2017, pp. 319–342.
[BEL15] S. Bubeck, R. Eldan, and J. Lehec. “Finite-time analysis of projected Langevin Monte
Carlo”. In: Advances in Neural Information Processing Systems (NeurIPS). Vol. 28.
2015.
[BEL18] S. Bubeck, R. Eldan, and J. Lehec. “Sampling from a log-concave distribution with
projected Langevin Monte Carlo”. In: Discrete & Computational Geometry (DCG) 59
(2018), pp. 757–783.
[Cha04] D. Chafaï. “Entropies, convexity, and functional inequalities, On Phi-entropies and
Phi-Sobolev inequalities”. In: Journal of Mathematics of Kyoto University 44.2 (2004),
pp. 325–363.
[Che70] J. Cheeger. “A lower bound for the smallest eigenvalue of the Laplacian”. In: Problems
in analysis 625.195-199 (1970), p. 110.
[Che+22] Y. Chen, S. Chewi, A. Salim, and A. Wibisono. “Improved analysis for a proximal
algorithm for sampling”. In: Conference on Learning Theory (COLT). PMLR. 2022,
pp. 2984–3014.
[Che21] Y. Chen. “An almost constant lower bound of the isoperimetric coefficient in the KLS
conjecture”. In: Geometric and Functional Analysis (GAFA) 31 (2021), pp. 34–61.
[Che24] S. Chewi. Log-concave sampling. Book draft available at https://chewisinho.github.
io, 2024.
[CV16] B. Cousins and S. S. Vempala. “A practical volume algorithm”. In: Mathematical
Programming Computation 8.2 (2016), pp. 133–160.
22[CV18] B. Cousins and S. S. Vempala. “Gaussian Cooling and O∗(n3) algorithms for volume and
Gaussian volume”. In: SIAM Journal on Computing (SICOMP) 47.3 (2018), pp. 1237–
1273.
[Dal17] A.Dalalyan.“Furtherandstrongeranalogybetweensamplingandoptimization:Langevin
Monte Carlo and gradient descent”. In: Conference on Learning Theory (COLT). PMLR.
2017, pp. 678–689.
[DT12] A. S. Dalalyan and A. B. Tsybakov. “Sparse regression learning by aggregation and
Langevin Monte-Carlo”. In: Journal of Computer and System Sciences 78.5 (2012),
pp. 1423–1443.
[DMM19] A. Durmus, S. Majewski, and B. Miasojedow. “Analysis of Langevin Monte Carlo via
convex optimization”. In: The Journal of Machine Learning Research (JMLR) 20.1
(2019), pp. 2666–2711.
[DFK91] M. Dyer, A. Frieze, and R. Kannan. “A random polynomial-time algorithm for approx-
imating the volume of convex bodies”. In: Journal of the ACM (JACM) 38.1 (1991),
pp. 1–17.
[Eld13] R. Eldan. “Thin shell implies spectral gap up to polylog via a stochastic localization
scheme”. In: Geometric and Functional Analysis (GAFA) 23.2 (2013), pp. 532–569.
[FYC23] J. Fan, B. Yuan, and Y. Chen. “Improved dimension dependence of a proximal algorithm
for sampling”. In: Conference on Learning Theory (COLT). PMLR. 2023, pp. 1473–1521.
[GKV23] K. Gatmiry, J. Kelner, and S. S. Vempala. “Sampling with barriers: Faster mixing via
Lewis weights”. In: arXiv preprint arXiv:2303.00480 (2023).
[GC11] M. Girolami and B. Calderhead. “Riemann manifold Langevin and Hamiltonian Monte
Carlo methods”. In: Journal of the Royal Statistical Society: Series B (Statistical
Methodology) 73.2 (2011), pp. 123–214.
[Gop+23] S. Gopi, Y. T. Lee, D. Liu, R. Shen, and K. Tian. “Algorithmic aspects of the Log-
Laplace transform and a non-Euclidean proximal sampler”. In: Conference on Learning
Theory (COLT). Vol. 195. PMLR, 2023, pp. 2399–2439.
[GLS88] M. Grötschel, L. Lovász, and A. Schrijver. Geometric algorithms and combinatorial
optimization. Vol. 2. Springer, 1988.
[GHZ22] M. Gürbüzbalaban, Y. Hu, and L. Zhu. “Penalized Langevin and Hamiltonian Monte
Carlo algorithms for constrained sampling”. In: arXiv preprint arXiv:2212.00570 (2022).
[Har+17] H. S. Haraldsdóttir, B. Cousins, I. Thiele, R. M. Fleming, and S. S. Vempala. “CHRR:
coordinate hit-and-run with rounding for uniform sampling of constraint-based models”.
In: Bioinformatics 33.11 (2017), pp. 1741–1743.
[Jia+21] H. Jia, A. Laddha, Y. T. Lee, and S. S. Vempala. “Reducing isotropy and volume to
KLS: an O∗(n3ψ2) volume algorithm”. In: Symposium on Theory of Computing (STOC).
2021, pp. 961–974.
[Jia21] Q. Jiang. “Mirror Langevin Monte Carlo: the case under isoperimetry”. In: Advances in
Neural Information Processing Systems (NeurIPS) 34 (2021), pp. 715–725.
[KLM06] R.Kannan,L.Lovász,andR.Montenegro.“Blockingconductanceandmixinginrandom
walks”. In: Combinatorics, Probability and Computing 15.4 (2006), pp. 541–570.
[KLS95] R.Kannan,L.Lovász,andM.Simonovits.“Isoperimetricproblemsforconvexbodiesand
a localization lemma”. In: Discrete & Computational Geometry 13.3 (1995), pp. 541–559.
23[KLS97] R. Kannan, L. Lovász, and M. Simonovits. “Random walks and an O∗(n5) volume
algorithm for convex bodies”. In: Random Structures & Algorithms (RS&A) 11.1 (1997),
pp. 1–50.
[KN12] R. Kannan and H. Narayanan. “Random walks on polytopes and an affine interior point
method for linear programming”. In: Mathematics of Operations Research 37.1 (2012),
pp. 1–20.
[KP21] B. Klartag and E. Putterman. “Spectral monotonicity under Gaussian convolution”. In:
arXiv preprint arXiv:2107.09496 (2021).
[Kla23] B. Klartag. “Logarithmic bounds for isoperimetry and slices of convex sets”. In: Ars
Inveniendi Analytica (2023).
[KL22] B. Klartag and J. Lehec. “Bourgain’s slicing problem and KLS isoperimetry up to
polylog”. In: Geometric and Functional Analysis (GAFA) 32.5 (2022), pp. 1134–1159.
[Koo+22] Y.Kook,Y.T.Lee,R.Shen,andS.S.Vempala.“SamplingwithRiemannianHamiltonian
Monte Carlo in a constrained space”. In: vol. 35. 2022, pp. 31684–31696.
[Koo+23] Y. Kook, Y. T. Lee, R. Shen, and S. S. Vempala. “Condition-number-independent
convergence rate of Riemannian Hamiltonian Monte Carlo with numerical integrators”.
In: Conference on Learning Theory (COLT). Vol. 195. PMLR, 2023, pp. 4504–4569.
[KV23] Y. Kook and S. S. Vempala. “Gaussian Cooling and Dikin walks: The Interior-Point
Method for logconcave sampling”. In: arXiv preprint arXiv:2307.12943 (2023).
[Led94] M. Ledoux. “A simple analytic proof of an inequality by P. Buser”. In: Proceedings of
the American Mathematical Society 121.3 (1994), pp. 951–959.
[LST21] Y. T. Lee, R. Shen, and K. Tian. “Structured logconcave sampling with a restricted
Gaussian oracle”. In: Conference on Learning Theory (COLT). PMLR. 2021, pp. 2993–
3050.
[LV18] Y. T. Lee and S. S. Vempala. “Convergence rate of Riemannian Hamiltonian Monte
Carloandfasterpolytopevolumecomputation”.In:Symposium on Theory of Computing
(STOC). 2018, pp. 1115–1121.
[LV17] Y. T. Lee and S. S. Vempala. “Eldan’s stochastic localization and the KLS hyperplane
conjecture: An improved lower bound for expansion”. In: Foundations of Computer
Science (FOCS). IEEE. 2017, pp. 998–1007.
[Leh23] J. Lehec. “The Langevin Monte Carlo algorithm in the non-smooth log-concave case”.
In: The Annals of Applied Probability 33.6A (2023), pp. 4858–4874.
[LNP12] N. E. Lewis, H. Nagarajan, and B. O. Palsson. “Constraining the metabolic genotype–
phenotype relationship using a phylogeny of in silico methods”. In: Nature Reviews
Microbiology 10.4 (2012), pp. 291–305.
[Li+22] R. Li, M. Tao, S. S. Vempala, and A. Wibisono. “The mirror Langevin algorithm
converges with vanishing bias”. In: International Conference on Algorithmic Learning
Theory (ALT). PMLR. 2022, pp. 718–742.
[Liu20] Y. Liu. “The Poincaré inequality and quadratic transportation-variance inequalities”.
In: Electronic Journal of Probability 25.1 (2020), pp. 1–16.
[Lov99] L. Lovász. “Hit-and-run mixes fast”. In: Mathematical Programming 86 (1999), pp. 443–
461.
24[LS90] L. Lovász and M. Simonovits. “The mixing rate of Markov chains, an isoperimetric
inequality, and computing the volume”. In: Foundations of Computer Science (FOCS).
IEEE. 1990, pp. 346–354.
[LS93] L. Lovász and M. Simonovits. “Random walks in a convex body and an improved volume
algorithm”. In: Random Structures & Algorithms (RS&A) 4.4 (1993), pp. 359–412.
[LV03] L. Lovász and S. S. Vempala. “Hit-and-run is fast and fun”. In: preprint, Microsoft
Research (2003).
[LV06] L. Lovász and S. S. Vempala. “Hit-and-run from a corner”. In: SIAM Journal on
Computing (SICOMP) 35.4 (2006), pp. 985–1005.
[MT07] F.McSherryandK.Talwar.“Mechanismdesignviadifferentialprivacy”.In:Foundations
of Computer Science (FOCS). IEEE. 2007, pp. 94–103.
[Mil09] E. Milman. “On the role of convexity in isoperimetry, spectral gap and concentration”.
In: Inventiones Mathematicae 177.1 (2009), pp. 1–43.
[Mir17] I. Mironov. “Rényi differential privacy”. In: Computer Security Foundations Symposium
(CSF). IEEE. 2017, pp. 263–275.
[Smi84] R. L. Smith. “Efficient Monte Carlo procedures for generating points uniformly dis-
tributed over bounded regions”. In: Operations Research 32.6 (1984), pp. 1296–1308.
[SWW23] V.Srinivasan,A.Wibisono,andA.Wilson.“Fastsamplingfromconstrainedspacesusing
theMetropolis-adjustedmirrorLangevinalgorithm”.In:arXivpreprintarXiv:2312.08823
(2023).
[Sta20] Stan Development Team. RStan: the R interface to Stan. R package version 2.21.2. 2020.
url: http://mc-stan.org/.
[Thi+13] I. Thiele, N. Swainston, R. M. Fleming, A. Hoppe, S. Sahoo, M. K. Aurich, H. Har-
aldsdottir, M. L. Mo, O. Rolfsson, M. D. Stobbe, et al. “A community-driven global
reconstruction of human metabolism”. In: Nature Biotechnology 31.5 (2013), pp. 419–
425.
[Vem05] S. S. Vempala. “Geometric random walks: a survey”. In: Combinatorial and Computa-
tional Geometry 52.573-612 (2005), p. 2.
[VW19] S. S. Vempala and A. Wibisono. “Rapid convergence of the unadjusted Langevin
algorithm:Isoperimetrysuffices”.In:Advances in Neural Information Processing Systems
(NeurIPS) 32 (2019).
[Vil09] C. Villani. Optimal transport: old and new. Vol. 338. Springer, 2009.
[Yua+23] B. Yuan, J. Fan, J. Liang, A. Wibisono, and Y. Chen. “On a classof Gibbs sampling over
networks”. In: Conference on Learning Theory (COLT). PMLR. 2023, pp. 5754–5780.
[Zha+20] K.S.Zhang,G.Peyré,J.Fadili,andM.Pereyra.“WassersteincontrolofmirrorLangevin
Monte Carlo”. In: Conference on Learning Theory (COLT). PMLR. 2020, pp. 3814–3841.
25A Related work
Sampling from constrained log-concave distributions is a fundamental task arising in many fields.
Uniform sampling with convex constraints is its simplest manifestation, which was first studied
as a core subroutine for a randomized volume-computation algorithm [DFK91]. Since then, this
fundamental problem has been studied for over three decades [LS90; LS93; KLS97; LV03; LV06;
BEL18; Bro+17]. We review these algorithms, grouping them under three categories — geometric
random walks, structured samplers, and diffusion-type samplers. Below, K is convex.
Geometric random walk. We discuss two geometric random walks – Ball walk [LS93; KLS97]
and Hit-and-Run [Smi84; Lov99].
Ball walk is a simple metropolized random walk; it draws y uniformly at random from a ball of
radius δ centered at a current point x, and moves to y if y ∈ K and stays at x otherwise. In the
literature, Ball walk actually refers to a composite algorithm consisting of [Speedy walk+ rejection
sampling], where Speedy walk records only the accepted steps of Ball walk (see Appendix B for
details). The step size δ should be set to O(d−1/2) to avoid stepping outside of K. [KLS97] showed
that Ball walk needs Oe(Md2D2log 1) membership queries to be ε-close to πK in TV, where D is
ε
the diameter of K, and the warmness parameter M measures the closeness of the initial distribution
to the target uniform distribution πK.
Hit-and-Run is another zeroth-order algorithm that needs no step size; it picks a uniform random
lineℓpassinga current point, andmovetoauniform randompointonℓ∩K. [LV06]showsthat, ifwe
define the second moment as R2 := E [∥X−E[X]∥2], then Hit-and-Run requires O(d2R2log M)
X∼πK ε
queries. Notably, this algorithm has a poly-logarithmic dependence on M as opposed to Ball walk.
Both algorithm are affected by skewed shape of K (i.e., large D or R), so these samplers are
combined with pre-processing step called rounding. This procedure finds a linear transformation that
makes the geometry of K less skewed and so more amenable to sampling. In literature, there exists
a randomized algorithm [Jia+21] that rounds K and generates a good warm start (i.e., M = O(1)),
with Ball walk used as a core subroutine. This algorithm takes up Oe(d3) queries in total, and in
such position with the good warm start, Ball walk only needs Oe(d2log 1) queries to sample from πK.
ε
Structured samplers. The aforementioned samplers based on geometric random walks require
only access to the membership oracle of the convex body without any additional structural assump-
tions. The alternate paradigm of geometry-aware sampling attempts to exploit the structure of
convex constraints, with the aim of expediting the convergence of the resultant sampling schemes.
One common assumption is to make available a self-concordant barrier function ϕ which has regu-
larity on its high-order derivatives and blows up when approaching the boundary ∂K. The Hessian
of ϕ encodes the local geometry of the constraint, and the samplers often work directly with ∇2ϕ.
The first canonical example of such a zeroth-order sampler is Dikin walk used when K is given
by m linear constraints [KN12]; it draws a uniform sample from an ellipsoid (characterized by ∇2ϕ)
of fixed radius around a current point, and is often combined with a Metropolis adjustment. [KN12]
shows that Dikin walk mixes in O(mdlog M) steps, although each iteration is slightly more expensive
ε
than one membership query. This algorithm requires no rounding, but still needs a good warm-start,
which can be achieved by an annealing-type algorithm using Oe(md) iterations of Dikin walk [KV23].
Riemannian Hamiltonian Monte Carloisastructuredsamplerthatexploitsthefirst-orderinforma-
tion of the potential (i.e., ∇log(1/π)) [GC11]; its proposal is given as the solution to the Hamilton’s
ODE equation, followed by the Metropolis-filter. In the linear-constraint setting above, this sampler
requires O(md2/3log M) many iterations to achieve ε-close distance to πK [LV18]. This sampler is
ε
further analyzed for practical ODE solvers [Koo+23] and for more sophisticated self-concordant
barriers [GKV23].
26Similarly, Mirror Langevin [Zha+20; Jia21; AC21; Li+22] is a class of algorithms which converts
the constrained problem into an unconstrained one obtained by considering the pushforward of the
constrained space by ∇ϕ. The algorithm can also be metropolized [SWW23]. The best known rates
for this algorithm are Oe(dlog 1) under some strong assumptions on ϕ.
ε
Diffusion-type samplers. Samplers based on discretizations of Itô diffusions, stochastic pro-
cesses which rapidly mix to π in continuous time, have long been used for sampling without
constraints [Bes+95; DT12; Dal17; Che24]. While the underlying stochastic processes generalize
easily to constrained settings, the discretization analysis relies crucially on the smoothness of the
target distribution. This is clearly impossible to achieve in the constrained setting, and so some
techniques are required to circumvent this difficulty. These algorithms, however, generalize easily to
the more general problem of sampling from distributions of the form π˜X ∝ e−f1 , by naturally
K
incorporating first order information from f.
The first approach for adapting diffusion-based samplers [BEL15; BEL18; Leh23] iterates a
two-stepprocedure. First, arandomstepistaken, withx ∼ N(x ,2hI )forsomeappropriately
k+1/2 k d
chosen step h,4 and then project it to K, i.e., x = proj (x ). The complexity is given in
k+1 K k+1/2
terms of queries to a projection oracle, each call to which can be implemented with a polynomial
number of membership oracle queries; a total of O˜(d2D3) queries are needed to be ε-close in W to
ε4 2
πX. Another approach, which uses an algorithmically designed “soft” penalty instead of a projection,
was proposed in [GHZ22], and achieves a rate estimate of O˜(d/ε10).
Asecondapproach,suggestedby[Bro+17],considersadifferentproximalscheme,whichperforms
a “soft projection” onto K, by taking steps like N((1−hλ−1)x +hproj (x ),2hI ). It is called
k K k d
Moreau-YosidaregularizedLangevin,namedafterananalogousregularizationschemeforconstrained
optimization. This scheme also relies on access to a projection oracle for K, and quantifies their
query complexity accordingly. Their final rate estimate is O˜(d5) to be ε-close in TV distance to πX.
ε6
Observing the prior work integrating diffusion-based sampling with convex constraints, the
dependence on the key parameters d,ε, while polynomial, are many orders worse than the rates for
zeroth-order samplers such as Ball walk,Hit-and-Run. In contrast, our analysis not only recovers but
in some sense surpasses the known rates for Ball walk,Hit-and-Run, while harmonizing well with the
continuous-time perspective of diffusions.
Proximal schemes for sampling. TheGibbssamplingschemeusedinthispaperwasinspiredby
the restricted Gaussian oracle introduced in [LST21] (in turn inspired by Gaussian Cooling [CV18]),
which alternately iterates between a pure Gaussian step, and a “proximal” step (which we elaborate
in our exposition). This scheme was given novel interpretations by [Che+22], which showed that it
interpolates the forward and backward heat flows, in the sense defined by [KP21]. The backward
heat flow itself is intimately related to stochastic localization schemes, invented and popularized
in [Eld13; Che21].
This formulation proved surprisingly powerful, allowing many existing rates in unconstrained
sampling to be recovered from a relatively simple analysis. This was further extended by [FYC23] to
achieve the current state-of-the-art rate in unconstrained sampling. Finally, [Gop+23] suggest that
this could be applied to tackle some constrained problems. However, the assumptions in this final
mentioned work are not compatible with the uniform sampling problem on general convex bodies.
4A gradient step can be added in the more general case, for sampling from π˜X
27B Ball walk and Speedy walk
We restate the previously known guarantees for uniform sampling by Ball walk and Speedy walk.
Below, let B (x) denote the d-dimensional ball of radius r centered at x.
r
Algorithm 2 Ball walk
Input: initial distribution π , convex body K ⊂ Rd, iterations T, step size δ > 0.
0
1: Sample x 0 ∼ π 0.
2: for i = 1,...,T do
3: Sample y ∼ Unif(B δ(x i−1)).
4: If y ∈ K, then x i ← y. Else, x i ← x i−1.
5: end for
Ball walk is particularly simple; draw a uniform random point from B around the current point,
δ
and go there if the drawn point is inside of K and stay at the current point otherwise. Its stationary
distribution can be easily seen to be π ∝ 1 , the uniform distribution over K.
K
In the literature, there are two approaches to analyzing the convergence rate of this sampler: (i)
a direct analysis via the s-conductance of Ball walk and (ii) an indirect approach which first passes
through Speedy walk.
Direct analysis. The following TV-guarantee is obtained by lower bounding the s-conductance
of Ball walk, which requires a one-step coupling argument and the Cheeger inequality for π. We
refer interested readers to [Vem05, Section 5].
Theorem 30 (Convergence of Ball walk). For any ε ∈ (0,1) and convex body K ⊂ Rd presented by a
well-defined membership oracle, let π be the distribution after t steps of Ball walk with an M-warm
t
initial distribution π . Then, Ball walk with step size δ = Θ( ε√ ) achieves ∥π −π∥ ≤ ε for
0 t TV
M d
t ≳ d2D2M2 log M. If π is isotropic, then Ball walk only needs O(d2logdM2 log M) iterations.
ε2 ε ε2 ε
The mixing time of Ball walk under this approach has a polynomial dependence on 1/ε, rather
than a polylogarithmic dependence.
Indirect analysis through Speedy walk. [KLS97]introducedSpeedy walk, whichcouldbeviewed
as a version of Ball walk and converges to a speedy distribution (see Proposition 1), which is slightly
biased from π. Then, Speedy walk is used together with another algorithmic component (rejection
sampling) [KLS97, Algorithm 4.15] that converts the speedy distribution to the uniform distribution.
In the literature, Ball walk often refers to ‘Speedy walk combined with the conversion step’, rather
than a direct implementation of Algorithm 2. Strictly speaking, a mixing guarantee of this combined
algorithm should not be referred to as a provable guarantee of Ball walk.
Algorithm 3 Speedy walk
Input: initial distribution π , convex body K ⊂ Rd, iterations T, step size δ > 0.
0
1: Sample x 0 ∼ π 0.
2: for i = 1,...,T do
3: Sample x i ∼ Unif(K∩B δ(x i−1)).
4: end for
As opposed to Ball walk, Speedy walk always takes some step at each iteration. However, the
problem of sampling from x ∼ Unif(K∩B (x )) in Line 3 is not straightforward. This step
i δ i−1
admits the following implementation based on rejection sampling, via a procedure denoted by (∗):
28• Propose y ∼ Unif(B (x )).
δ i−1
• Set x ← y if y ∈ K. Otherwise, repeat the proposal.
i+1
Each actual step (indexed by i) in Speedy walk is called a proper step, and rejected steps during
(∗) are called improper steps. For example, if x ,x ,x ,x ,x ,x ,x ,... are the positions produced
1 1 2 3 3 3 4
by Ball walk, then only proper steps x ,x ,x ,x ,... are recorded by Speedy walk.
1 2 3 4
To describe the theoretical guarantees of Speedy walk, we define the local conductance ℓ(x) at
x ∈ K, which measures the success probability of the rejection sampling scheme in (∗):
vol(K∩B (x))
ℓ(x) := δ ,
vol(B (x))
δ
and define the average conductance:
1 Z
λ := E [ℓ] = ℓ(x)dx.
π vol(K)
K
Proposition 1 ([KLS97]). The stationary distribution ν of Speedy walk has density
ℓ(x)1 (x)
ν(x) = K .
R ℓ(x)dx
K
Thespeedydistributionν isindeeddifferentfromtheuniformdistributionπ,andthisdiscrepancy
is quantified in terms of the average conductance.
Proposition 2 ([KLS97, Page 22]). ∥ν −π∥ ≤ 1−λ.
TV λ
One can relate the step size δ to the average conductance.
√
Proposition 3 (Bound on average conductance, [KLS97, Corollary 4.5]). λ ≥ 1− δ d.
2
The best known result for Speedy walk’s mixing is due to [KLM06] devising the blocking conduc-
tance and using the log-Cheeger inequality. When ν is isotropic (i.e., it has covariance proportional
to the identity matrix), [LV17] improves the mixing bound via the log-Cheeger constant.
Theorem 31 (Mixing of Speedy walk). For any ε ∈ (0,1) and convex body K ⊂ Rd presented by a
well-defined membership oracle, let ν be the distribution after t proper steps of Speedy walk started
t
at any feasible point x ∈ K. Then, Speedy walk with step size δ = Θ(d−1/2) achieves ∥ν −ν∥ ≤ ε
√0 t TV
for t ≳ (D2+log(D d))d2log 1. From an M-warm start, the expected number of improper steps
ε
during t iterations is Oe(tM). When ν is isotropic, Speedy walk needs O(d2Dlog 1 loglogD) proper
ε
steps to achieve ε-TV distance to ν.
Then, [KLS97] uses the following post-processing step to obtain an approximately uniform
distribution on K, with a provable guarantee.
A: Call Speedy walk to obtain a sample X ∼ ν until 2d X ∈ K. If so, return X¯ = 2d X.
t 2d−1 2d−1
Proposition 4 ([KLS97, Theorem 4.16]). Under the same setting above, assume ∥ν −ν∥ ≤ ε for
t TV
step size δ ≤ (8dlog d)−1/2 and fixed t ∈ N. For ν¯ = law(X¯) given by A, it holds that ∥ν¯−π∥ ≤ ε,
ε TV
and the expected number of calls on the conversion algorithm is at most 2.
Combining the previous two results, we conclude that the total expected number of membership
queries to obtain a sample ε-close to π in TV is Oe(Md2D2log 1), which now has a poly-logarithmic
ε
dependence on 1/ε.
29Remark2(BackwardheatflowanalysisofSpeedy walk). ConsideraGaussianversionofSpeedy walk,
whose one-step corresponds to x ∼ N(x ,hI )| , and this transition kernel exactly matches
i+1 i d K
integrating (BH) for time h. Thus, νQπX,h = ν due to the stationarity of ν under Speedy walk,
h
where QπX,h is the transition kernel defined by the backward heat flow for time h that reverses
h
πX ∗N(0,hI ) to πX. Hence, if we can control the LSI/PI constants of ν along the backward
d
heat-flow’s trajectory, then we could directly analyze Speedy walk by emulating computations in
Lemma 21.
C Functional inequalities
We provide full details on functional inequalities omitted in Section 3.1. We use µ and µ to denote
LC
a probability measure and log-concave probability measure over Rd, respectively.
Cheeger and PI constants. The Cheeger isoperimetric constant C (µ) measures how large
Ch
surface area a measurable subset with larger volume has, defined by
µ+(S)
C (µ) := inf ,
Ch
S⊂Rd
min(µ(S),µ(Sc))
where the infimum is taken over all measurable subsets S, and µ+(S) is the Minkowski content of S
under µ defined as, for Sε := {x ∈ X : d(x,S) < ε},
µ(Sε)−µ(S)
µ+(S) := liminf .
ε→0 ε
[Che70] established C (µ) ≲ C−2(µ)5, and then [KLS95] showed that for covariance matrix
PI Ch
Σ := E [(·−E X)(·−E X)T],
µ µ µ µ
1 1
C (µ ) ≳ = . (C.1)
Ch LC (E [∥X −E X∥2])1/2 (tr(Σ ))1/2
µ µ µ
LC LC LC
This immediately leads to C (π) ≲ (E [∥X −E X∥2])1/2 ≤ D2 for the uniform distribution π over
PI π π
a convex body K with diameter D > 0.
Kannan et al. proposed the KLS conjecture in the same paper, which says that for the spectral
norm ∥·∥ ,
2
1
C (µ ) ≳ .
Ch LS ∥Σ ∥1/2
µ LS 2
While the original result in [KLS95] ensures C ≳ d−1/2 for an isotropic log-concave distribution
Ch
(due to Σ = I ), this conjecture indeed claims C ≳ 1 for such case. Following a line of work [LV17;
d Ch
Che21; KL22; Kla23], the current bound is
(logd)−1/2
C (µ ) ≳ ,
Ch LS ∥Σ ∥1/2
µ LS 2
which implies that C (π) ≲ logd when π is isotropic for convex K.
PI
5The opposite direction C (µ ) ≳ C−2(µ ) also holds for log-concave distributions due to [Mil09], while
PI LC Ch LC
C (µ)≳C−2(µ)/d for general distributions due to [Led94].
PI Ch
30Log-Cheeger and LSI constants. Just as the Cheeger and PI constants are related above, there
are known connections between LSI and log-Cheeger constants. The log-Cheeger constant C (µ)
logCh
of a distribution µ ∈ P(Rd) is defined as
µ+(S)
C (µ) := inf .
logCh q
S⊂Rd:µ(S)≤1 µ(S) log 1
2 µ(S)
[Led94] established that C (µ) ≲ C−2 (µ)6, and [KLM06] showed that any log-concave
LSI logCh
distributions with support of diameter D > 0 satisfy C (µ ) ≳ D−1. Later in 2016, [LV17]
logCh LS
improved this to C (µ ) ≳ D−1/2 under isotropy. Therefore, for convex K, it follows that
logCh LS
C (π) ≲ D2 and that C (π) ≲ D if π is isotropic.
LSI LSI
D The Wasserstein geometry
We present additional technical background on the Wasserstein geometry and Markov semigroup
theory. Interested readers can refer to [Vil09; AGS05; Che24] for standard references on Wasserstein
spaces and applications to sampling.
Wasserstein gradient. Let P (Rd) be the space of probability measures admitting densities on
2,ac
Rd with finite second moment. Although there are many ways to metrize P (Rd), the geometry
2,ac
induced by the Wasserstein-2 distance W is a particularly useful structure for analysis.
2
Under the W -geometry, one can define a “gradient” of a functional defined over P (Rd).
2 2,ac
Specifically,forafunctionalF : P (Rd) → R∪{∞},theWasserstein gradient ofF atµ ∈ P (Rd)
2,ac 2,ac
is defined as ∇ F(µ) = ∇(δF)(µ) ∈ L2(µ), where ∇ is the standard gradient and δF is the first
W2
variation of F7. Equipped with this W -gradient, one can define the Wasserstein gradient flow of F
2
that describes the evolution of a measure {µ } , from some initial measure µ , as follows:
t t≥0 0
∂ µ = div(cid:0) µ ∇ F(µ )(cid:1) .
t t t W2 t
More generally, we can identify the Wasserstein “velocity” for some measure µ as v if the time
t t
derivative of µ can be written in the form
t
∂ µ = −div(µ v ).
t t t t
Under this identification, the time derivative of a functional F on P (Rd) with smooth Wasserstein
2,ac
gradient under these dynamics can be written as
∂ F(µ ) = E ⟨∇ F(µ ),v ⟩,
t t µt W2 t t
when v ∈ {∇ψ : ψ ∈
C∞(Rd)}L2(µt)
, where
{·}L2(µt)
denotes the closure of a set with respect to
t c
L2(µ ). This is the appropriate notion of tangent space in this geometry.
t
For instance, when we take the functional to be the entropy of the measure, H(µ) := 1 R µlogµ,
2
one can verify ∇ H(µ) = 1∇logµ. The heat flow equation can be written as ∂ µ = 1∆µ =
W2 2 t t 2 t
1 div(∇µ ) = 1 div(µ ∇logµ ), which indicates that the velocity of measures µ under the heat flow
2 t 2 t t t
is v = −1∇logµ . Hence, we can notice that ∇ H(µ ) = −v , and thus recover the heat flow as
t 2 t W2 t t
the Wasserstein gradient flow of the entropy of the measure.
6The opposite direction holds under dimension-scaling due to [Led94]: C (µ)≳C−2 (µ)/d.
LSI logCh
7The first variation can be defined, for any measures ν ,ν ∈ P (Rd), as lim F((1−t)ν0+tν1)−F(ν0) =
0 1 2,ac t↓0 t
⟨δF(ν ),ν −ν ⟩. This definition is unique up to an additive constant, which is irrelevant as we are only con-
0 1 0
cerned with its gradient.
31Fokker-Planckequationandtime-reversalofSDE. Considerastochasticdifferentialequation
(X ) given by
t
dX = −a (X )dt+ dB with X ∼ µ . (D.1)
t t t t 0 0
It is well known that measures µ described by
t
1
∂ µ = div(µ a )+ ∆µ , (D.2)
t t t t 2 t
correspond to law(X ). In this context, (D.2) is referred to as the Fokker-Planck equation corre-
t
sponding to (D.1).
From this equation, one can deduce the Fokker-Planck equation of the time reversal µ← := µ :
t T−t
1 1
∂ µ← = −div(µ←a )− ∆µ← = −div(cid:0) µ←(a +∇logµ )(cid:1)+ ∆µ←
t t t T−t 2 t t T−t T−t 2 t
In particular, this describes the evolution of law(X ) of the stochastic differential equation:
t
dX = (cid:0) a (X )+∇logµ (X )(cid:1)dt+ dB with X ∼ µ← = µ . (D.3)
t T−t t T−t t t 0 0 T
While the law of this process will give µ← = µ at time T, it is also true that it will give µ (·|z) if
T 0 0|T
one starts (D.3) at X = z. This is a subtle fact, whose justification requires the introduction of a
0
tool called Doob’s h-transform. The presentation of this subject is beyond the scope of this paper,
and we refer interested readers to [KP21] as a reference to its application in this context.
32