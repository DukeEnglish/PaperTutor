[
    {
        "title": "Exploiting Priors from 3D Diffusion Models for RGB-Based One-Shot View Planning",
        "authors": "Sicong PanLiren JinXuying HuangCyrill StachnissMarija PopovićMaren Bennewitz",
        "links": "http://arxiv.org/abs/2403.16803v1",
        "entry_id": "http://arxiv.org/abs/2403.16803v1",
        "pdf_url": "http://arxiv.org/pdf/2403.16803v1",
        "summary": "Object reconstruction is relevant for many autonomous robotic tasks that\nrequire interaction with the environment. A key challenge in such scenarios is\nplanning view configurations to collect informative measurements for\nreconstructing an initially unknown object. One-shot view planning enables\nefficient data collection by predicting view configurations and planning the\nglobally shortest path connecting all views at once. However, geometric priors\nabout the object are required to conduct one-shot view planning. In this work,\nwe propose a novel one-shot view planning approach that utilizes the powerful\n3D generation capabilities of diffusion models as priors. By incorporating such\ngeometric priors into our pipeline, we achieve effective one-shot view planning\nstarting with only a single RGB image of the object to be reconstructed. Our\nplanning experiments in simulation and real-world setups indicate that our\napproach balances well between object reconstruction quality and movement cost.",
        "updated": "2024-03-25 14:21:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.16803v1"
    },
    {
        "title": "CurbNet: Curb Detection Framework Based on LiDAR Point Cloud Segmentation",
        "authors": "Guoyang ZhaoFulong MaYuxuan LiuWeiqing QiMing Liu",
        "links": "http://arxiv.org/abs/2403.16794v1",
        "entry_id": "http://arxiv.org/abs/2403.16794v1",
        "pdf_url": "http://arxiv.org/pdf/2403.16794v1",
        "summary": "Curb detection is an important function in intelligent driving and can be\nused to determine drivable areas of the road. However, curbs are difficult to\ndetect due to the complex road environment. This paper introduces CurbNet, a\nnovel framework for curb detection, leveraging point cloud segmentation.\nAddressing the dearth of comprehensive curb datasets and the absence of 3D\nannotations, we have developed the 3D-Curb dataset, encompassing 7,100 frames,\nwhich represents the largest and most categorically diverse collection of curb\npoint clouds currently available. Recognizing that curbs are primarily\ncharacterized by height variations, our approach harnesses spatially-rich 3D\npoint clouds for training. To tackle the challenges presented by the uneven\ndistribution of curb features on the xy-plane and their reliance on z-axis\nhigh-frequency features, we introduce the multi-scale and channel attention\n(MSCA) module, a bespoke solution designed to optimize detection performance.\nMoreover, we propose an adaptive weighted loss function group, specifically\nformulated to counteract the imbalance in the distribution of curb point clouds\nrelative to other categories. Our extensive experimentation on 2 major datasets\nhas yielded results that surpass existing benchmarks set by leading curb\ndetection and point cloud segmentation models. By integrating multi-clustering\nand curve fitting techniques in our post-processing stage, we have\nsubstantially reduced noise in curb detection, thereby enhancing precision to\n0.8744. Notably, CurbNet has achieved an exceptional average metrics of over\n0.95 at a tolerance of just 0.15m, thereby establishing a new benchmark.\nFurthermore, corroborative real-world experiments and dataset analyzes mutually\nvalidate each other, solidifying CurbNet's superior detection proficiency and\nits robust generalizability.",
        "updated": "2024-03-25 14:13:09 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.16794v1"
    },
    {
        "title": "HPL-ESS: Hybrid Pseudo-Labeling for Unsupervised Event-based Semantic Segmentation",
        "authors": "Linglin JingYiming DingYunpeng GaoZhigang WangXu YanDong WangGerald SchaeferHui FangBin ZhaoXuelong Li",
        "links": "http://arxiv.org/abs/2403.16788v1",
        "entry_id": "http://arxiv.org/abs/2403.16788v1",
        "pdf_url": "http://arxiv.org/pdf/2403.16788v1",
        "summary": "Event-based semantic segmentation has gained popularity due to its capability\nto deal with scenarios under high-speed motion and extreme lighting conditions,\nwhich cannot be addressed by conventional RGB cameras. Since it is hard to\nannotate event data, previous approaches rely on event-to-image reconstruction\nto obtain pseudo labels for training. However, this will inevitably introduce\nnoise, and learning from noisy pseudo labels, especially when generated from a\nsingle source, may reinforce the errors. This drawback is also called\nconfirmation bias in pseudo-labeling. In this paper, we propose a novel hybrid\npseudo-labeling framework for unsupervised event-based semantic segmentation,\nHPL-ESS, to alleviate the influence of noisy pseudo labels. In particular, we\nfirst employ a plain unsupervised domain adaptation framework as our baseline,\nwhich can generate a set of pseudo labels through self-training. Then, we\nincorporate offline event-to-image reconstruction into the framework, and\nobtain another set of pseudo labels by predicting segmentation maps on the\nreconstructed images. A noisy label learning strategy is designed to mix the\ntwo sets of pseudo labels and enhance the quality. Moreover, we propose a soft\nprototypical alignment module to further improve the consistency of target\ndomain features. Extensive experiments show that our proposed method\noutperforms existing state-of-the-art methods by a large margin on the\nDSEC-Semantic dataset (+5.88% accuracy, +10.32% mIoU), which even surpasses\nseveral supervised methods.",
        "updated": "2024-03-25 14:02:33 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.16788v1"
    },
    {
        "title": "The Anatomy of Adversarial Attacks: Concept-based XAI Dissection",
        "authors": "Georgii MikriukovGesina SchwalbeFranz MotzkusKorinna Bade",
        "links": "http://arxiv.org/abs/2403.16782v1",
        "entry_id": "http://arxiv.org/abs/2403.16782v1",
        "pdf_url": "http://arxiv.org/pdf/2403.16782v1",
        "summary": "Adversarial attacks (AAs) pose a significant threat to the reliability and\nrobustness of deep neural networks. While the impact of these attacks on model\npredictions has been extensively studied, their effect on the learned\nrepresentations and concepts within these models remains largely unexplored. In\nthis work, we perform an in-depth analysis of the influence of AAs on the\nconcepts learned by convolutional neural networks (CNNs) using eXplainable\nartificial intelligence (XAI) techniques. Through an extensive set of\nexperiments across various network architectures and targeted AA techniques, we\nunveil several key findings. First, AAs induce substantial alterations in the\nconcept composition within the feature space, introducing new concepts or\nmodifying existing ones. Second, the adversarial perturbation itself can be\nlinearly decomposed into a set of latent vector components, with a subset of\nthese being responsible for the attack's success. Notably, we discover that\nthese components are target-specific, i.e., are similar for a given target\nclass throughout different AA techniques and starting classes. Our findings\nprovide valuable insights into the nature of AAs and their impact on learned\nrepresentations, paving the way for the development of more robust and\ninterpretable deep learning models, as well as effective defenses against\nadversarial threats.",
        "updated": "2024-03-25 13:57:45 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.16782v1"
    },
    {
        "title": "Diff-Def: Diffusion-Generated Deformation Fields for Conditional Atlases",
        "authors": "Sophie StarckVasiliki Sideri-LampretsaBernhard KainzMartin MentenTamara MuellerDaniel Rueckert",
        "links": "http://arxiv.org/abs/2403.16776v1",
        "entry_id": "http://arxiv.org/abs/2403.16776v1",
        "pdf_url": "http://arxiv.org/pdf/2403.16776v1",
        "summary": "Anatomical atlases are widely used for population analysis. Conditional\natlases target a particular sub-population defined via certain conditions (e.g.\ndemographics or pathologies) and allow for the investigation of fine-grained\nanatomical differences - such as morphological changes correlated with age.\nExisting approaches use either registration-based methods that are unable to\nhandle large anatomical variations or generative models, which can suffer from\ntraining instabilities and hallucinations. To overcome these limitations, we\nuse latent diffusion models to generate deformation fields, which transform a\ngeneral population atlas into one representing a specific sub-population. By\ngenerating a deformation field and registering the conditional atlas to a\nneighbourhood of images, we ensure structural plausibility and avoid\nhallucinations, which can occur during direct image synthesis. We compare our\nmethod to several state-of-the-art atlas generation methods in experiments\nusing 5000 brain as well as whole-body MR images from UK Biobank. Our method\ngenerates highly realistic atlases with smooth transformations and high\nanatomical fidelity, outperforming the baselines.",
        "updated": "2024-03-25 13:52:48 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.16776v1"
    }
]