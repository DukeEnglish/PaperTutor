[
    {
        "title": "Optimal convex $M$-estimation via score matching",
        "authors": "Oliver Y. FengYu-Chun KaoMin XuRichard J. Samworth",
        "links": "http://arxiv.org/abs/2403.16688v1",
        "entry_id": "http://arxiv.org/abs/2403.16688v1",
        "pdf_url": "http://arxiv.org/pdf/2403.16688v1",
        "summary": "In the context of linear regression, we construct a data-driven convex loss\nfunction with respect to which empirical risk minimisation yields optimal\nasymptotic variance in the downstream estimation of the regression\ncoefficients. Our semiparametric approach targets the best decreasing\napproximation of the derivative of the log-density of the noise distribution.\nAt the population level, this fitting process is a nonparametric extension of\nscore matching, corresponding to a log-concave projection of the noise\ndistribution with respect to the Fisher divergence. The procedure is\ncomputationally efficient, and we prove that our procedure attains the minimal\nasymptotic covariance among all convex $M$-estimators. As an example of a\nnon-log-concave setting, for Cauchy errors, the optimal convex loss function is\nHuber-like, and our procedure yields an asymptotic efficiency greater than 0.87\nrelative to the oracle maximum likelihood estimator of the regression\ncoefficients that uses knowledge of this error distribution; in this sense, we\nobtain robustness without sacrificing much efficiency. Numerical experiments\nconfirm the practical merits of our proposal.",
        "updated": "2024-03-25 12:23:19 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.16688v1"
    },
    {
        "title": "A note on generalization bounds for losses with finite moments",
        "authors": "Borja Rodríguez-GálvezOmar RivasplataRagnar ThobabenMikael Skoglund",
        "links": "http://arxiv.org/abs/2403.16681v1",
        "entry_id": "http://arxiv.org/abs/2403.16681v1",
        "pdf_url": "http://arxiv.org/pdf/2403.16681v1",
        "summary": "This paper studies the truncation method from Alquier [1] to derive\nhigh-probability PAC-Bayes bounds for unbounded losses with heavy tails.\nAssuming that the $p$-th moment is bounded, the resulting bounds interpolate\nbetween a slow rate $1 / \\sqrt{n}$ when $p=2$, and a fast rate $1 / n$ when $p\n\\to \\infty$ and the loss is essentially bounded. Moreover, the paper derives a\nhigh-probability PAC-Bayes bound for losses with a bounded variance. This bound\nhas an exponentially better dependence on the confidence parameter and the\ndependency measure than previous bounds in the literature. Finally, the paper\nextends all results to guarantees in expectation and single-draw PAC-Bayes. In\norder to so, it obtains analogues of the PAC-Bayes fast rate bound for bounded\nlosses from [2] in these settings.",
        "updated": "2024-03-25 12:15:55 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.16681v1"
    },
    {
        "title": "Causal Discovery from Poisson Branching Structural Causal Model Using High-Order Cumulant with Path Analysis",
        "authors": "Jie QiaoYu XiangZhengming ChenRuichu CaiZhifeng Hao",
        "links": "http://arxiv.org/abs/2403.16523v1",
        "entry_id": "http://arxiv.org/abs/2403.16523v1",
        "pdf_url": "http://arxiv.org/pdf/2403.16523v1",
        "summary": "Count data naturally arise in many fields, such as finance, neuroscience, and\nepidemiology, and discovering causal structure among count data is a crucial\ntask in various scientific and industrial scenarios. One of the most common\ncharacteristics of count data is the inherent branching structure described by\na binomial thinning operator and an independent Poisson distribution that\ncaptures both branching and noise. For instance, in a population count\nscenario, mortality and immigration contribute to the count, where survival\nfollows a Bernoulli distribution, and immigration follows a Poisson\ndistribution. However, causal discovery from such data is challenging due to\nthe non-identifiability issue: a single causal pair is Markov equivalent, i.e.,\n$X\\rightarrow Y$ and $Y\\rightarrow X$ are distributed equivalent. Fortunately,\nin this work, we found that the causal order from $X$ to its child $Y$ is\nidentifiable if $X$ is a root vertex and has at least two directed paths to\n$Y$, or the ancestor of $X$ with the most directed path to $X$ has a directed\npath to $Y$ without passing $X$. Specifically, we propose a Poisson Branching\nStructure Causal Model (PB-SCM) and perform a path analysis on PB-SCM using\nhigh-order cumulants. Theoretical results establish the connection between the\npath and cumulant and demonstrate that the path information can be obtained\nfrom the cumulant. With the path information, causal order is identifiable\nunder some graphical conditions. A practical algorithm for learning causal\nstructure under PB-SCM is proposed and the experiments demonstrate and verify\nthe effectiveness of the proposed method.",
        "updated": "2024-03-25 08:06:08 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.16523v1"
    },
    {
        "title": "On the rates of convergence for learning with convolutional neural networks",
        "authors": "Yunfei YangHan FengDing-Xuan Zhou",
        "links": "http://arxiv.org/abs/2403.16459v1",
        "entry_id": "http://arxiv.org/abs/2403.16459v1",
        "pdf_url": "http://arxiv.org/pdf/2403.16459v1",
        "summary": "We study the approximation and learning capacities of convolutional neural\nnetworks (CNNs). Our first result proves a new approximation bound for CNNs\nwith certain constraint on the weights. Our second result gives a new analysis\non the covering number of feed-forward neural networks, which include CNNs as\nspecial cases. The analysis carefully takes into account the size of the\nweights and hence gives better bounds than existing literature in some\nsituations. Using these two results, we are able to derive rates of convergence\nfor estimators based on CNNs in many learning problems. In particular, we\nestablish minimax optimal convergence rates of the least squares based on CNNs\nfor learning smooth functions in the nonparametric regression setting. For\nbinary classification, we derive convergence rates for CNN classifiers with\nhinge loss and logistic loss. It is also shown that the obtained rates are\nminimax optimal in several settings.",
        "updated": "2024-03-25 06:42:02 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.16459v1"
    },
    {
        "title": "Real-time Adaptation for Condition Monitoring Signal Prediction using Label-aware Neural Processes",
        "authors": "Seokhyun ChungRaed Al Kontar",
        "links": "http://arxiv.org/abs/2403.16377v1",
        "entry_id": "http://arxiv.org/abs/2403.16377v1",
        "pdf_url": "http://arxiv.org/pdf/2403.16377v1",
        "summary": "Building a predictive model that rapidly adapts to real-time condition\nmonitoring (CM) signals is critical for engineering systems/units.\nUnfortunately, many current methods suffer from a trade-off between\nrepresentation power and agility in online settings. For instance, parametric\nmethods that assume an underlying functional form for CM signals facilitate\nefficient online prediction updates. However, this simplification leads to\nvulnerability to model specifications and an inability to capture complex\nsignals. On the other hand, approaches based on over-parameterized or\nnon-parametric models can excel at explaining complex nonlinear signals, but\nreal-time updates for such models pose a challenging task. In this paper, we\npropose a neural process-based approach that addresses this trade-off. It\nencodes available observations within a CM signal into a representation space\nand then reconstructs the signal's history and evolution for prediction. Once\ntrained, the model can encode an arbitrary number of observations without\nrequiring retraining, enabling on-the-spot real-time predictions along with\nquantified uncertainty and can be readily updated as more online data is\ngathered. Furthermore, our model is designed to incorporate qualitative\ninformation (i.e., labels) from individual units. This integration not only\nenhances individualized predictions for each unit but also enables joint\ninference for both signals and their associated labels. Numerical studies on\nboth synthetic and real-world data in reliability engineering highlight the\nadvantageous features of our model in real-time adaptation, enhanced signal\nprediction with uncertainty quantification, and joint prediction for labels and\nsignals.",
        "updated": "2024-03-25 02:47:29 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.16377v1"
    }
]