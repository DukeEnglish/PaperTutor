[
    {
        "title": "An LLM-Based Digital Twin for Optimizing Human-in-the Loop Systems",
        "authors": "Hanqing YangMarie SiewCarlee Joe-Wong",
        "links": "http://arxiv.org/abs/2403.16809v1",
        "entry_id": "http://arxiv.org/abs/2403.16809v1",
        "pdf_url": "http://arxiv.org/pdf/2403.16809v1",
        "summary": "The increasing prevalence of Cyber-Physical Systems and the Internet of\nThings (CPS-IoT) applications and Foundation Models are enabling new\napplications that leverage real-time control of the environment. For example,\nreal-time control of Heating, Ventilation and Air-Conditioning (HVAC) systems\ncan reduce its usage when not needed for the comfort of human occupants, hence\nreducing energy consumption. Collecting real-time feedback on human preferences\nin such human-in-the-loop (HITL) systems, however, is difficult in practice. We\npropose the use of large language models (LLMs) to deal with the challenges of\ndynamic environments and difficult-to-obtain data in CPS optimization. In this\npaper, we present a case study that employs LLM agents to mimic the behaviors\nand thermal preferences of various population groups (e.g. young families, the\nelderly) in a shopping mall. The aggregated thermal preferences are integrated\ninto an agent-in-the-loop based reinforcement learning algorithm AitL-RL, which\nemploys the LLM as a dynamic simulation of the physical environment to learn\nhow to balance between energy savings and occupant comfort. Our results show\nthat LLMs are capable of simulating complex population movements within large\nopen spaces. Besides, AitL-RL demonstrates superior performance compared to the\npopular existing policy of set point control, suggesting that adaptive and\npersonalized decision-making is critical for efficient optimization in CPS-IoT\napplications. Through this case study, we demonstrate the potential of\nintegrating advanced Foundation Models like LLMs into CPS-IoT to enhance system\nadaptability and efficiency. The project's code can be found on our GitHub\nrepository.",
        "updated": "2024-03-25 14:32:28 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.16809v1"
    },
    {
        "title": "Cluster-Based Normalization Layer for Neural Networks",
        "authors": "Bilal FayeHanane AzzagMustapha Lebbah",
        "links": "http://arxiv.org/abs/2403.16798v1",
        "entry_id": "http://arxiv.org/abs/2403.16798v1",
        "pdf_url": "http://arxiv.org/pdf/2403.16798v1",
        "summary": "Deep learning faces significant challenges during the training of neural\nnetworks, including internal covariate shift, label shift, vanishing/exploding\ngradients, overfitting, and computational complexity. While conventional\nnormalization methods, such as Batch Normalization, aim to tackle some of these\nissues, they often depend on assumptions that constrain their adaptability.\nMixture Normalization faces computational hurdles in its pursuit of handling\nmultiple Gaussian distributions.\n  This paper introduces Cluster-Based Normalization (CB-Norm) in two variants -\nSupervised Cluster-Based Normalization (SCB-Norm) and Unsupervised\nCluster-Based Normalization (UCB-Norm) - proposing a groundbreaking one-step\nnormalization approach. CB-Norm leverages a Gaussian mixture model to\nspecifically address challenges related to gradient stability and learning\nacceleration.\n  For SCB-Norm, a supervised variant, the novel mechanism involves introducing\npredefined data partitioning, termed clusters, to normalize activations based\non the assigned cluster. This cluster-driven approach creates a space that\nconforms to a Gaussian mixture model. On the other hand, UCB-Norm, an\nunsupervised counterpart, dynamically clusters neuron activations during\ntraining, adapting to task-specific challenges without relying on predefined\ndata partitions (clusters). This dual approach ensures flexibility in\naddressing diverse learning scenarios.\n  CB-Norm innovatively uses a one-step normalization approach, where parameters\nof each mixture component (cluster in activation space) serve as weights for\ndeep neural networks. This adaptive clustering process tackles both clustering\nand resolution of deep neural network tasks concurrently during training,\nsignifying a notable advancement in the field.",
        "updated": "2024-03-25 14:17:38 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.16798v1"
    },
    {
        "title": "Iso-Diffusion: Improving Diffusion Probabilistic Models Using the Isotropy of the Additive Gaussian Noise",
        "authors": "Dilum FernandoDhananjaya jayasundaraRoshan GodaliyaddaChaminda BandaraParakrama EkanayakeVijitha Herath",
        "links": "http://arxiv.org/abs/2403.16790v1",
        "entry_id": "http://arxiv.org/abs/2403.16790v1",
        "pdf_url": "http://arxiv.org/pdf/2403.16790v1",
        "summary": "Denoising Diffusion Probabilistic Models (DDPMs) have accomplished much in\nthe realm of generative AI. Despite their high performance, there is room for\nimprovement, especially in terms of sample fidelity by utilizing statistical\nproperties that impose structural integrity, such as isotropy. Minimizing the\nmean squared error between the additive and predicted noise alone does not\nimpose constraints on the predicted noise to be isotropic. Thus, we were\nmotivated to utilize the isotropy of the additive noise as a constraint on the\nobjective function to enhance the fidelity of DDPMs. Our approach is simple and\ncan be applied to any DDPM variant. We validate our approach by presenting\nexperiments conducted on four synthetic 2D datasets as well as on unconditional\nimage generation. As demonstrated by the results, the incorporation of this\nconstraint improves the fidelity metrics, Precision and Density for the 2D\ndatasets as well as for the unconditional image generation.",
        "updated": "2024-03-25 14:05:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.16790v1"
    },
    {
        "title": "The Anatomy of Adversarial Attacks: Concept-based XAI Dissection",
        "authors": "Georgii MikriukovGesina SchwalbeFranz MotzkusKorinna Bade",
        "links": "http://arxiv.org/abs/2403.16782v1",
        "entry_id": "http://arxiv.org/abs/2403.16782v1",
        "pdf_url": "http://arxiv.org/pdf/2403.16782v1",
        "summary": "Adversarial attacks (AAs) pose a significant threat to the reliability and\nrobustness of deep neural networks. While the impact of these attacks on model\npredictions has been extensively studied, their effect on the learned\nrepresentations and concepts within these models remains largely unexplored. In\nthis work, we perform an in-depth analysis of the influence of AAs on the\nconcepts learned by convolutional neural networks (CNNs) using eXplainable\nartificial intelligence (XAI) techniques. Through an extensive set of\nexperiments across various network architectures and targeted AA techniques, we\nunveil several key findings. First, AAs induce substantial alterations in the\nconcept composition within the feature space, introducing new concepts or\nmodifying existing ones. Second, the adversarial perturbation itself can be\nlinearly decomposed into a set of latent vector components, with a subset of\nthese being responsible for the attack's success. Notably, we discover that\nthese components are target-specific, i.e., are similar for a given target\nclass throughout different AA techniques and starting classes. Our findings\nprovide valuable insights into the nature of AAs and their impact on learned\nrepresentations, paving the way for the development of more robust and\ninterpretable deep learning models, as well as effective defenses against\nadversarial threats.",
        "updated": "2024-03-25 13:57:45 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.16782v1"
    },
    {
        "title": "Diff-Def: Diffusion-Generated Deformation Fields for Conditional Atlases",
        "authors": "Sophie StarckVasiliki Sideri-LampretsaBernhard KainzMartin MentenTamara MuellerDaniel Rueckert",
        "links": "http://arxiv.org/abs/2403.16776v1",
        "entry_id": "http://arxiv.org/abs/2403.16776v1",
        "pdf_url": "http://arxiv.org/pdf/2403.16776v1",
        "summary": "Anatomical atlases are widely used for population analysis. Conditional\natlases target a particular sub-population defined via certain conditions (e.g.\ndemographics or pathologies) and allow for the investigation of fine-grained\nanatomical differences - such as morphological changes correlated with age.\nExisting approaches use either registration-based methods that are unable to\nhandle large anatomical variations or generative models, which can suffer from\ntraining instabilities and hallucinations. To overcome these limitations, we\nuse latent diffusion models to generate deformation fields, which transform a\ngeneral population atlas into one representing a specific sub-population. By\ngenerating a deformation field and registering the conditional atlas to a\nneighbourhood of images, we ensure structural plausibility and avoid\nhallucinations, which can occur during direct image synthesis. We compare our\nmethod to several state-of-the-art atlas generation methods in experiments\nusing 5000 brain as well as whole-body MR images from UK Biobank. Our method\ngenerates highly realistic atlases with smooth transformations and high\nanatomical fidelity, outperforming the baselines.",
        "updated": "2024-03-25 13:52:48 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.16776v1"
    }
]