Virtual Co-Pilot: Multimodal Large Language
Model-enabled Quick-access Procedures for Single
Pilot Operations
Fan Li1, Shanshan Feng2, Yuqi Yan1, Ching-Hung Lee3, Yew Soon Ong4
1Department of Aeronautical and Aviation Engineering, The Hong Kong Polytechnic University, HKSAR
2Centre for Frontier AI Research, A*STAR
3School of Public Policy and Administration, Xi'an Jiaotong University, Xi’an, China
4 School of Computer Science and Engineering, Nanyang Technological University, Singapore
Abstract— Advancements in technology, pilot shortages, and Single-pilot operations draw increasing attention in the
cost pressures are driving a trend towards single-pilot and aviation fields, particularly in general aviation and business jet
even remote operations in aviation. Considering the extensive sectors. However, single-pilot operations require a high level
workload and huge risks associated with single-pilot of skill and proficiency, as the pilot must be able to manage
operations, the development of a Virtual Co-Pilot (V-CoP) is all aspects of the flight without a co-pilot. The absence of a
co-pilot can increase the risk of human error due to the high
expected to be a potential way to ensure aviation safety. This
workload and complex tasks involved in flying an aircraft.
study proposes a V-CoP concept and explores how humans
Hence, many studies attempted to develop advanced avionics
and virtual assistants can effectively collaborate. A
systems that can automate many tasks, reducing the workload
preliminary case study is conducted to explore a critical role
of the pilot [4].
of V-CoP, namely automated quick procedures searching,
using the multimodal large language model (LLM). The This study attempts to introduce a potential virtual co-pilot
LLM-enabled V-CoP integrates the pilot’s instruction and (V-CoP), which replaces the role of human co-pilot, assists the
real-time cockpit instrumental data to prompt applicable captain, and communicates with other stakeholders. The V-
aviation manuals and operation procedures. The results CoP is expected to be achieved by using the multimodal large
language model (LLM). The multimodal LLM can process
showed that the LLM-enabled V-CoP achieved high accuracy
and generate responses based on multiple input types,
in situational analysis (90.5%) and effective retrieval of
including but not limited to text [5]. This means it can
procedure information (86.5%). The proposed V-CoP is
understand and respond to various forms of data, such as
expected to provide a foundation for future virtual intelligent
images, audio, and video, in addition to text . In other words,
assistant development, improve the performance of single
it is possible to take the role of human co-pilot in
pilots, and reduce the risk of human errors in aviation.
communication and monitoring. However, cockpit teamwork
Keywords—Aviation, large language model, virtual assistant,
will face novel challenges, such as new task allocation and
human-AI collaboration
new interaction ways between the captain and the virtual co-
pilot. This study aims to explore a possible way to achieve a
I. INTRODUCTION
V-CoP for advanced single pilot operations. The following
Most of the current commercial aircraft cockpits are
research questions are addressed:
designed for two pilots, namely the captain and the co-pilot
1. What are the main functions and responsibilities of the V-
[1]. The captain on the flight deck is responsible for major
CoP?
strategic and tactical decisions and has ultimate responsibility
2. What requirements should be met to achieve a good V-
for decision-making and the overall safety of the flight. The
CoP? How to evaluate the team performance between
co-pilot helps the captain operate the airplane and maintain
human pilot and V-CoP?
navigation [2], [3]. The following accident scenario describes
3. Is it possible to use the LLM to partially achieve V-CoP?
teamwork between the pilot and co-pilot:
To address these questions, the traditional teamwork
“On January 15, 2009, an Airbus took off from LaGuardia between pilot and co-pilot is analyzed, classical theories and
Airport. Shortly after takeoff, the plane struck a flock of geese, related research studies are incorporated. Accordingly, the
causing both engines to fail. After the bird strike, the captain definition and scope of the V-CoP are discussed in Section II.
took control of the aircraft while the co-pilot immediately Extensive studies are needed to achieve a whole V-CoP, this
began going through the dual engine failure checklist in the study conducts a case study to partially achieve it.
Quick Reference Handbook. Finally, the Captain made the Specifically, a multimodal large language model (LLM)-
decision and achieved to ditch the plane in the Hudson River.” enabled intelligent teammate for quick-access procedures is
developed to achieve one key function of the V-CoP, namely
This aviation accidents, with no loss of life, underscores searching the quick reference handbook. Section III and
the importance of quick-access standard procedures and Section IV describe the methods and results of developing the
effective dual-pilot operation. Nevertheless, as a result of LLM-enabled quick-access procedures. Section V concludes
technological progress, a deficit of experienced pilots, and the this study by pointing out the future directions and limitations.
drive for cost-effectiveness, a growing number of nations are
turning their focus towards single-pilot and even remote II. DEFINITION OF VIRTUAL CO-PILOT AND TEAMWORK
operations in the field of aviation [2]. Single-pilot operation
A. A Virtual Co-pilot
refers to the operation of an aircraft by one pilot, who is solely
responsible for safely controlling the aircraft, navigating, The V-CoP is expected to replace the position of human
communicating with air traffic control, and managing all other co-pilots to mitigate the risks and challenges of pure single-
flight-related tasks. pilot operation. It should achieve two types of functions, the
XXX-X-XXXX-XXXX-X/XX/$XX.00 ©20XX IEEEbasic function of co-pilots and novel functions enabled by AI. • The V-CoP doesn't have a specific personality, so it
The basic functions of co-pilots include: can play any type of team role in the teamwork.
• Emergency handling: during an emergency, the V- • The V-CoP doesn't have personal emotions and
CoP can receive and respond to the pilot’s instruction, consciousness, so its attitudinal aspect of teamwork
identify the non-normal situations, figure out Quick can be stable. It is willing to undertake coordinative/
Actions, send instructions to the aircraft system to adaptive behavior.
accomplish Quick Actions, provide accurate standard • The V-CoP doesn't understand context in the same
operating procedures, and accomplish applicable way a human does and it can't form genuine
procedures. relationships. Hence, the overlap among mental
• Communication: the V-CoP can accomplish basic models of P-V-CoP would be relatively small.
communication with the captain, crew, and air traffic Overall, these significant differences can greatly mediate
control. the influencing factors, as shown in Fig.1. The new mediate
• Monitoring: the V-CoP continuously monitors factors that are introduced by the V-CoP are highlighted in
aircraft instruments via image processing, promptly Fig.1. For example, the great adaptability of V-CoP can well
responds to system alerts and abnormal conditions, remove the effects of culture and lead to dynamic
monitors fuel consumption and ensures efficient compositions. In addition, the acceptance of V-CoP would be
usage, and ensures the completion of checklists, an additional condition factor. All the influencing factors of
verifying the proper functioning of critical systems teamwork would be mediated by the usability of the V-CoP,
before and during flights. including ease of use, intelligence level, transparency and so
For the novel functions enabled by AI, the V-CoP is on. For example, the calmness of the V-CoP can enhance
available 24/7 and does not require rest or breaks, unlike cooperations. The V-CoP would introduce a new interaction
humans. In addition, the study proposes the adaptive team role mode between human-machine collaboration. In the
based on the task requirements and leadership style of pilots. cooperation between a single pilot and V-CoP, the primary
According to the teamwork theory, the team roles can be interaction way between pilots and virtual co-pilots is natural
classified into nine types, namely shaper, plant, coordinator,
language, as the virtual co-pilot is developed based on LLM.
monitor evaluator, resource investigator, implementor, team
In addition, the future V-CoP may introduce the possible
worker, completer-finisher, and specialist [6]. The human co-
“body language” to deliver efficient information.
pilot can hardly perform all these team roles, as personality is
hard to change and also a determining factor of team role. For
the LLM-enabled V-CoP, adaptively changing the team role
to collaborate with different pilots and meet the dynamic task
requirements is possible.
B. Sustainable Teamwork between Single Pilot and V-CoP
The V-CoP introduces new interaction and collaboration
challenges within teamwork. Hence, the teamwork dynamics
in pilot-V-CoP (P-V-CoP) are significantly different from the
traditional teamwork between human pilots. The traditional
human-machine teamwork concept mainly focuses on
developing a machine assistant from human needs, ignoring
the dynamic needs of the machine teammate [7]. Compared
with traditional machines, the current intelligent virtual
teammate is developed based on advanced artificial
intelligence, which means that it can learn, evolve, and be
Fig. 1. The influencing factors of sustainable teamwork
tutored [8], [9]. In other words, human pilots can enhance and
between pilot and V-CoP.
assist the perception, decision-making, and action of the V-
CoP.
Hence, we propose the concept of sustainable teamwork
Social
between the pilot and V-CoP. Sustainable teamwork means
that all the teammates work together to seek long-term
collaborations and help each other to evolve to ensure Usability
harmonious teamwork. To achieve sustainable teamwork, we
can start from the influencing factors of teamwork
performance. According to the traditional teamwork theory, Function quality
the main influencing factors of human teamwork are
cooperation, communication, schema, coordination, and
situation awareness [10]. Besides these factors, three Functional needs
conditions including context, composition, and culture can
influence teamwork, too [10]. Most of these factors may have
Fig.2. The needs of a good V-CoP and sustainable
similar effects on the teamwork of P-V-CoP. Nevertheless,
teamwork.
the advanced LLM-based V-CoP would be significantly
different from human co-pilot in the following aspects:C. The V-CoP Evaluation and emergency conditions is critical for aviation safety.
What constitutes an effective V-CoP, and how can it be Hence, in this study, a case study is conducted to achieve and
evaluated? Based on the main concept of human-centered demonstrate one of the primary functions of V-CoP, namely
design and Maslow's hierarchy of needs, we believe that the automatically searching and providing the procedures
virtual co-pilot should meet the following requirements: applicable for normal, non-normal, and emergency
conditions.
• Functional needs: the V-CoP should facilitate basic
collaborations with pilots in flying, namely monitoring
A. The teamwork of P-V-CoP for quick-access procedures
the aircraft's instruments, double-checking
Fig.3. illustrates its main concept and the teamwork
information such as the programmed flight path, and
between P-V-CoP in searching quick-access procedures.
handling basic communications with air traffic control
[11]. Both the human pilot and the V-CoP can perceive the real-
• Function quality needs: the V-CoP should provide time information from the cockpit instruments, such as the
accurate, efficient, and precise information for safe and airspeed indicator, attitude indicator, altimeter, turn
reliable collaboration, as aviation is a safety-critical coordinator, heading indicator, and vertical speed indicator
domain with strict regulations. Following the basic on the primary flight display. Humans can sense motion
quality characteristics of software, we propose that the movement, and spatial orientation easily with the vestibular
function quality needs can be analyzed from accuracy, and proprioception systems. Human pilots can understand
reliability, maintainability, and efficiency [12]. real-time problems and call for procedures using the standard
• Usability needs: traditionally, the usability dimensions communication phraseology, such as “ECAM Actions” and
include ease of use, learnability, accessibility, and “Clear Status”. The V-CoP mainly processes images, videos,
understandability [12]. Besides these factors, since the and audio information with the embedded multimodal LLM.
intelligent V-CoP would facilitate adaptive Specifically, the cockpit and instrument images are processed
collaboration, adaptability, predictability, to understand the context. The pilot’s voice instructions are
dependability, and transparency should be considered,
encoded and integrated with the context as prompts to search
LLM-based VirtualCo-pilot
(a) Images of cockpit
instruments displays
(b) External knowledge Display
base (e.g.aircraft applicable
manual) procedures
(c) Pilot’s instructions
LLM
The A320simulator for data collection An example of quick-
access reference
HumanCaptain
provided by V-CoP
Understand the Call for
problem Procedures
Perceive the problem
Fig.3. The teamwork of P-V-CoP for quick-access procedures.
for accurate applicable procedures. The LLM is combined
too [13].
with a large dataset of aviation manuals, checklists, and
• Social needs: a consensus of pilots on long flights is
communication transcripts to respond to the prompts.
the isolated feeling [1]. Compared with the first three
requirements, the social interaction requirements place B. Training Data Collection
more attention on the soft skills of the V-CoP. The V-
Our collected dataset has 200 samples, and each sample
CoP plays the role of a teammate instead of a cold
includes three parts: high-resolution images of the flight
machine. Hence, the V-CoP should be capable of
simulator's instrument panels, pilots’ instructions, and the
understanding the pilot’s states and actively
corresponding procedures. The establishment of the database
responding to the pilot.
includes two phases, data collection and labelling. During the
Overall, a good V-CoP should meet the Functional,
data collection, a qualified pilot controlled the A320
Function Quality, Usability, and Social needs (FQUS), as
simulator to go through numerous scenarios, including
shown in Fig.2.
normal, non-normal and emergencies, as shown in Fig.4.
III. DESIGN FRAMEWORK FOR LLM-ENABLED V-COP WITH High-resolution images of the flight simulator's
QUICK-ACCESS PROCEDURES instrument panels were captured during the normal. non-
normal and emergency scenarios. In this study, each sample
As mentioned in the Introduction, quickly accessing
contains one image from one display. There are numerous
standard and applicable procedures for normal, non-normal,displays in the cockpit. To accelerate the situation analysis of “My primary role is to meticulously analyze aircraft
the V-CoP, only the display which shows the problematic dashboard images from the Airbus A320 series for any
parameters or information was processed by the V-CoP. anomalies. (1) Upon receiving an image or information from
These images represent the visual data a pilot would typically you, I will diligently check for errors or emergencies. (2) If I
analyze during the specific flight condition. Fig.5. shows identify an anomaly, I will seek your permission to delve into
several examples of high-resolution images of the flight the Airbus A320 series documents you have provided to
simulator's instrument panels. The data were collected during search for a solution. (3) Once found, I will provide you with
the simulated flight operations, and the pilot was encouraged the exact original text from these documents that addresses
to verbalize his thoughts. The thoughts were translated into the anomaly, along with precise indexing such as page
the pilot’s instructions in the dataset. The experienced pilot number or section. My goal is to ensure the information I
reviewed the 200 samples after data collection to figure out offer is not only accurate and relevant but also the best
and confirm the suitable procedures for the simulated possible solution based on the source material.”
situations. The performance of the V-CoP for quick-access reference
in each trial is evaluated from the following three aspects:
C. Develop V-CoP with Aviation-Specific Knowledge Base
accuracy in interpreting the flight condition (IFC), accuracy
The core model of V-CoP is OpenAI’s GPT-4, which is in the generated procedures (GP), and index correction (IC).
renowned for its advanced natural language processing A panel of aviation experts evaluated the V-CoP performance
capabilities. It's capable of understanding, processing, and together, using the standardized scoring system to assess each
generating human-like text. To customize it for aviation and trial, as shown in Table I. If IFC is correct, then its value is 1,
for establishing V-CoP, the model is augmented with a otherwise its value is 0. If IFC is incorrect, then the value of
comprehensive aviation knowledge base. Specifically, a wide both GP and IC is 0.
range of manuals [14], such as the flight crew operating To accelerate the process of optimizing the V-CoP
manual, A320 standard operating procedures, and quick configuration, two experiments were conducted. In the
reference handbook for A320 [15] are utilized. This preliminary experiment, we randomly selected 50 samples.
enhancement enables the model to possess a deep and The preliminary experiment was conducted to evaluate the
practical understanding of aviation operations, adhering to performance of the V-CoP in generating quick-access
established standards and protocols in the aviation field. reference across three settings: single-dimensional input of
instrument images, hybrid input of instrument images and
pilots’ instructions, and hybrid input of preprocessed images
and pilots’ instructions. We adopted the OCR (Optical
Character Recognition) technology to preprocess instrument
images and convert text displayed on instrument panels into
a digital format that GPT-4 can process. The best setting is
selected for refining the V-CoP.
Image of flight error
Pilot’s instruction
Fig. 4. The A320 simulator for training data collection.
Generated procedures
Fig. 6. An example of quick-access reference provided by
V-CoP.
(a) (b) (c) IV. RESULTS AND DISCUSSION
Fig. 5. Examples of the flight simulator's instrument. (a) This section analyzes the performance of the V-CoP in
The engine and warning display; (b) The primary generating quick-access references across three settings and
flight display; (c) The systems display. discusses the potential direction for enhancing its performance.
For flight operations, the V-CoP should provide real and A. V-CoP Performance Across Three Settings in
strict procedures instead of a made-up procedure, as pilots Preliminary Experiment
must comply with strict procedures. Hence, the V-CoP is The preliminary experiment revealed notable differences
instructed to search the results from the aviation-related in performance across the three settings, as shown in Table
knowledge base provided. The instruction for configuring the II. The “Image + Instruction” group outperformed the other
V-CoP is displayed below: groups in all three evaluators, indicating that the combination
of visual and textual data significantly enhances the model'sability to interpret the situation, retrieve relevant checklist of 200), suggesting that the model was generally adept at
information, and accurately find manual sections. In referencing the correct sections of the manuals. However, its
particular, the "Image + Instruction" group demonstrates performance is suboptimal, necessitating further enhancement
in future studies.
significantly superior performance compared to the
For usability evaluation, a formal user experiment was
"Image" group. This suggests a synergistic effect where
conducted. In this study, the expert panel with aviation
instructions provide contextual grounding for the visual
experience evaluated the easy-to-use and readability of the
information, leading to a more comprehensive understanding
generated procedures with a five-Likert scale. The panel
of the V-CoP model.
agreed that the V-CoP can only achieve 3.5 in usability, as the
Conversely, the “OCR + Instruction” group, despite the
LLM provides too much long information, and the efficiency
additional processing to convert image text into a machine- is not good.
readable format, did not result in the highest performance. For the social needs of human pilots, the expert panel
This might be due to the complexities involved in accurately agreed that the developed V-CoP cannot meet the
interpreting OCR data or the added step of data processing requirements of being a companion and more efforts are
that may introduce errors or misunderstandings. needed to enhance its soft skills.
Overall, the “Image + Instruction” group appears to be the
most effective when it comes to interpreting flight-related data TABLE III. V-COP PERFORMANCE IN FORMAL EXPERIMENT
and assisting pilots in simulated emergencies. This finding can
Accuracy
serve as the basis for refining the V-CoP and designing the Settings
IFCa GPb ICc
formal experiment.
Image + Pilot’s Instruction 90.5% 85.5% 70.5%
TABLE I. THE STANDARDIZED SCORING SYSTEM FOR V-COP a. IFC: Interpreting the flight condition. b. GP: Generated procedures; c. IC: Index correction
EVALUATION
C. Error Analysis of the V-CoP
Scores
Aspects To gain further insights into the nature of the errors and
Accurate Inaccurate
enhance the V-CoP's performance in the future, we performed
IFCa 1 0
an in-depth analysis of the error types as follows:
GPb 1 * IFCa 0
ICc 1 * IFCa * GPb 0 (a) Interperating the Flight Situation
a. IFC: Interpreting the flight condition. b. GP: Generated procedures; c. IC: Index correction 0.11 0.05 0.11
B. V-CoP FQUS Evaluation in the Formal Experiment
The preliminary experiment suggested that the potential
0.42 0.32
way to improve V-CoP performance is by combining image
data with the pilot’s instructions. Hence, in the formal
experiment, we refined the V-CoP with inputs from cockpit
Image Clarity Issue Insufficient Context
instrumental images and the pilot’s instructions. The refined Instruction Mislead/Conflict Instruction Caused Incomplete Analysis
V-CoP for quick-access reference was tested with 200 GPT-4 Model Recognition Error
samples.
According to the sustainable teamwork proposed in (b) Generated Procedures
Section II, we should evaluate the V-CoP from four aspects,
0.19 0.15
namely functions, function quality, usability, and social needs.
For the first aspect, we can evaluate the V-CoP’s capability to
provide quick-access references. Both the preliminary and
formal experiments demonstrated the V-CoP’s capability in 0.30 0.37
generating flight operating procedures. Hence, the function of
quick-access references is achieved.
Situation Analysis Error Insufficient Context
Model Search Error Content Nonexistent
TABLE II. V-COP PERFORMANCE ACROSS THREE SETTINGS IN
PRELIMINARY EXPERIMENT WITH 50 SAMPLES (c) Index Correction
Accuracy 0.07
Settings
IFCa GPb ICc 0.12
0.34
Image 82% 60% 60%
0.08
Image + Pilot’s Instruction 94% 86% 72%
0.07
OCR + Pilot’s Instruction 74% 60% 46%
a. IFC: Interpreting the flight condition. b. GP: Generated procedures; c. IC: Index correction 0.32
For the second one, function quality, we evaluated the V-
Unnumbered Source File Indexed to Broad Title Only
CoP from three aspects. As shown in Table III, the proposed
Error Due to Situation Analysis Insufficient Context
V-CoP exhibited strong performance in understanding the Error Due to Checklist other
flight situations presented in the images with an average score
of 90.5% (181 out of 200). It achieved an average score of Fig.7. The error analysis of the V-CoP.
86.5% (173 out of 200) in retrieving relevant checklist
information from the knowledge base. Nevertheless, the For understanding the flight situation, the V-CoP mainly
average score in indexing the original text was 70.5% (141 out made errors due to the following reasons, includingincomplete image analysis, misleading instruction, even historical data patterns that could enhance the V-CoP’s
insufficient context, image clarity, and GPT-4 model context understanding.
recognition error. Specifically, the most significant error type
is incomplete image analysis (42.11%), where the V-CoP V. CONCLUSION
model did not fully analyze the image content, as shown in
This research introduces and delineates the concept of V-
Fig.7(a). For the generated procedures, four types of errors
CoP, a system that employs a multimodal LLM to interpret
were made by the V-CoP, including model search error,
and generate human-like text from cockpit images and pilot
insufficient context, nonexistent content, and situation
inputs, thereby offering real-time support during flight
analysis error, as shown in Fig.7(b). Among them, insufficient
operations. To the best of our knowledge, this is the first work
context, which indicates the provided information was too
to study the virtual co-pilot with pretrained LLMs for
vague or general for a specific checklist item, made up most
aviation. A case study was undertaken to partially explore the
errors (37%). For the last aspect, there are many reasons that
feasibility of an LLM-enabled V-CoP in identifying
the V-CoP cannot provide a correct index, such as
unnumbered source file, indexed to broad title only, situation comprehensive, dynamic, and interactive procedures
analysis error, and insufficient context, as shown in Fig.7(c). adaptable to various flight scenarios. The case study revealed
The formal experiment results provide valuable insights that GPT-4, when provided with instrument images and pilot
into the LLM-based V-CoP's current capabilities and instructions, can effectively retrieve quick-access references
limitations as a pilot assistance system. The performance for flight operations. The findings affirmed that the V-CoP can
across different performance evaluators indicates that while harness the capabilities of LLM to comprehend dynamic
the model is proficient in interpreting aviation-related images, aviation scenarios and pilot instructions.
certain areas require improvements to enhance accuracy and However, the V-CoP's performance is yet to meet the
reliability. The investigation of errors sheds light on the stringent aviation safety standards. The error analysis
specific challenges faced by the V-CoP: indicates the need for improvements in context
• Model search errors and content nonexistence imply comprehension, knowledge base refinement, and image
limitations within the knowledge base and retrieval analysis capabilities.
processes.
• Situation analysis errors and incomplete image REFERENCES
analysis suggest issues with image processing and
[1] P. L. Myers III and A. W. Starr Jr, “Single pilot operations IN
contextual understanding. commercial cockpits: background, challenges, and options,” J Intell
• Insufficient context across all categories underscores a Robot Syst, vol. 102, no. 1, p. 19, 2021.
need for better integration of the data provided with the [2] D. Harris, “Single-pilot airline operations: Designing the aircraft may
be the easy part,” The Aeronautical Journal, pp. 1–21, 2023.
model's existing knowledge.
[3] A. K. Faulhaber, M. Friedrich, and T. Kapol, “Absence of pilot
D. Recommendations for Potential Improvements monitoring affects scanning behavior of pilot flying: implications for
the design of single-pilot cockpits,” Hum Factors, vol. 64, no. 2, pp.
During the experiments, we found that a structured and 278–290, 2022.
streamlined knowledge base can reduce search errors and [4] M. L. Cummings, A. Stimpson, and M. Clamann, “Functional
requirements for onboard intelligent automation in single pilot
content nonexistence issues. By organizing the data in a more
operations,” in AIAA Infotech@ Aerospace, 2016, p. 1652.
accessible and hierarchical manner, the retrieval process can
[5] E. Kasneci et al., “ChatGPT for good? On opportunities and challenges
become more efficient and accurate. In this study, the raw and of large language models for education,” Learn Individ Differ, vol. 103,
long manuals from Airbus were adopted, which hinders the p. 102274, 2023.
[6] R. M. Belbin and V. Brown, Team roles at work. Routledge, 2022.
indexing and retrieval processes. We may potentially employ
[7] T. Inagaki, “Smart collaboration between humans and machines based
database management techniques to improve indexing and
on mutual understanding,” Annu Rev Control, vol. 32, no. 2, pp. 253–
retrieval processes in the next step. 261, 2008.
In addition to the challenges associated with the [8] R. Mallick, C. Flathmann, C. Lancaster, A. Hauptman, N. McNeese,
and G. Freeman, “The pursuit of happiness: the power and influence of
knowledge base, the V-CoP's performance is significantly
AI teammate emotion in human-AI teamwork,” Behaviour &
influenced by the formulation of instructions, as evidenced
Information Technology, pp. 1–25, 2023.
by errors arising from misleading directives and inadequate [9] X. Cheng, and S. Zhang, Tool, Teammate, Superintelligence:
context. Enhanced clarity and precision in instructions could Identification of ChatGPT-Enabled Collaboration Patterns and their
potentially improve situational analysis and indexing. In this
Benefits and Risks in Mutual Learning, 2024.
[10] J. V Dinh and E. Salas, “Factors that influence teamwork,” The Wiley
research, we utilized basic instructions such as "check the
Blackwell handbook of the psychology of team working and
error" and "focus on the yellow part." As a subsequent step, collaborative processes, pp. 13–41, 2017.
we propose referencing aviation standard phrases to devise a [11] F. Dehais, J. Behrend, V. Peysakhovich, M. Causse, and C. D. Wickens,
“Pilot flying and pilot monitoring’s aircraft state awareness during go-
method for generating appropriate prompts for the V-CoP.
around execution in aviation: A behavioral and eye tracking study,” Int.
The development of a standardized protocol for instruction
J. Aerosp. Psychol., vol. 27, no. 1–2, pp. 15–28, 2017.
formulation could mitigate ambiguity. This may necessitate [12] F. Li, C.-H. Chen, C.-H. Lee, and L.-P. Khoo, “A user requirement-
the establishment of a guideline set for instruction driven approach incorporating TRIZ and QFD for designing a smart
vessel alarm system to reduce alarm fatigue,” The Journal of
composition, with an emphasis on clarity and specificity.
Navigation, vol. 73, no. 1, pp. 212–232, 2020.
Last, providing additional context could mitigate a
[13] M. Clamann and D. B. Kaber, “Applicability of usability evaluation
significant number of errors, particularly those related to techniques to aviation systems,” Int J Aviat Psychol, vol. 14, no. 4, pp.
insufficient context and incomplete image analysis. The 395–420, 2004.
[14] A. AIRBUS, “Aircraft characteristics airport and maintenance
question is how to collect supplementing inputs with
planning.” AIRBUS SAS, 2017.
background information relevant to the scenario. This might
[15] Airbus, “Flight Crew Operating Manual A318/A319/A320/A321
include data about the phase of flight, weather conditions, or FMGS Pilot’s Guide Vol 4,” https://www.avialogs.com/aircraft-a/airbus/item/1004-flight-crew-operating-manual-a318-a319-a320-
a321-fmgs-pilot-s-guide-vol-4.