Towards Human-AI Deliberation: Design and Evaluation of
LLM-Empowered Deliberative AI for AI-Assisted
Decision-Making
ShuaiMa QiaoyiChen XinruWang
TheHongKongUniversityofScience SunYat-senUniversity PurdueUniversity
andTechnology Zhuhai,Guangdong,China WestLafayette,Indiana,USA
HongKong,China chenqy99@mail2.sysu.edu.cn xinruw@purdue.edu
shuai.ma@connect.ust.hk
ChengboZheng ZhenhuiPeng MingYin
TheHongKongUniversityofScience SunYat-senUniversity PurdueUniversity
andTechnology Zhuhai,Guangdong,China WestLafayette,Indiana,USA
HongKong,China pengzhh29@mail.sysu.edu.cn mingyin@purdue.edu
cb.zheng@connect.ust.hk
XiaojuanMa
TheHongKongUniversityofScience
andTechnology
HongKong,China
mxj@cse.ust.hk
ABSTRACT CCSCONCEPTS
InAI-assisteddecision-making,humansoftenpassivelyreviewAI’s •Human-centeredcomputing→EmpiricalstudiesinHCI.
suggestionanddecidewhethertoacceptorrejectitasawhole.
Insuchaparadigm,humansarefoundtorarelytriggeranalyti-
KEYWORDS
calthinkingandfacedifficultiesincommunicatingthenuances
ofconflictingopinionstotheAIwhendisagreementsoccur.To AI-AssistedDecision-making,Human-AICollaboration,Appropri-
tacklethischallenge,weproposeHuman-AIDeliberation,anovel ateReliance
frameworktopromotehumanreflectionanddiscussiononcon-
flictinghuman-AIopinionsindecision-making.Basedontheories
ACMReferenceFormat:
inhumandeliberation,thisframeworkengageshumansandAI
ShuaiMa,QiaoyiChen,XinruWang,ChengboZheng,ZhenhuiPeng,Ming
indimension-levelopinionelicitation,deliberativediscussion,and
Yin,andXiaojuanMa.2024.TowardsHuman-AIDeliberation:Designand
decisionupdates.ToempowerAIwithdeliberativecapabilities,we
EvaluationofLLM-EmpoweredDeliberativeAIforAI-AssistedDecision-
designedDeliberativeAI,whichleverageslargelanguagemodels Making.InProceedingsofACMConference(Conference’17).ACM,NewYork,
(LLMs)asabridgebetweenhumansanddomain-specificmodelsto NY,USA,26pages.https://doi.org/10.1145/nnnnnnn.nnnnnnn
enableflexibleconversationalinteractionsandfaithfulinformation
provision.Anexploratoryevaluationonagraduateadmissionstask
showsthatDeliberativeAI outperformsconventionalexplainable
AI(XAI)assistantsinimprovinghumans’appropriaterelianceand
1 INTRODUCTION
taskperformance.Basedonamixed-methodsanalysisofparticipant
behavior,perception,userexperience,andopen-endedfeedback, Withremarkabletechnologicaladvancements,AIhasbeenincreas-
wedrawimplicationsforfutureAI-assisteddecisiontooldesign. inglyusedtosupportpeopleinmakingdecisionsinvariousdo-
mains, including criminal justice [32, 35], admissions [25, 140],
financialinvestment[53],andmedicaldiagnosis[21,79],among
others.ConcernssurroundingAI’saccuracy,safety,ethics,andac-
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalor
countability[12,21,79]haveledtothewidespreadadoptionofthe
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation AI-assisteddecision-making paradigminreal-worldapplications
onthefirstpage.CopyrightsforcomponentsofthisworkownedbyothersthanACM [8,17,131,141].Inthisparadigm,AIperformsanassistiveroleby
mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,
providingarecommendation,whilehumandecision-makerscan
topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee.Requestpermissionsfrompermissions@acm.org. choosetoacceptorrejectAI’ssuggestionintheirfinaldecision
Conference’17,July2017,Washington,DC,USA [72].
©2024AssociationforComputingMachinery.
Research in recent years, however, identified two challenges
ACMISBN978-x-xxxx-xxxx-x/YY/MM...$15.00
https://doi.org/10.1145/nnnnnnn.nnnnnnn withintheexistingAI-assisteddecision-makingparadigm.First,
4202
raM
52
]CH.sc[
1v21861.3042:viXraConference’17,July2017,Washington,DC,USA ShuaiMa,etal.
abatteryofempiricalstudiesfoundthatpeoplerarelytriggeran- conversationcapability).WeelaborateonthedesignofHuman-AI
alyticalthinking(i.e.,System2thinking[65])whendirectlypre- DeliberationframeworkandDeliberativeAIinSection3anddemon-
sentedwithAI’ssuggestions[11,16,109].Asaresult,peoplefre- stratehowtoinstantiatetheframeworkinanillustrativetaskin
quentlyover-relyontheAI’sincorrectrecommendations(over- Section4.
reliance) or mistakenly ignore AI’s correct suggestions (under- WerealizethatHuman-AIDeliberationmightbeespeciallysuit-
reliance) [17, 90, 131]. Although some solutions have been pro- ableforhandlingtaskcasesthatarechallengingforboth
posed,suchasdisplayingAIexplanations[8]andforcingpeopleto humansandAI.Ifbothpartiesareverygoodatthetaskcases
think(e.g.,applyingcognitiveforcingfunctions[17]),theresultsare (bothhavehighdecisionaccuracy)oronepartyisveryproficient
mixedatbest[71,107](Challenge1).Second,insteadoffullconsen- inthetaskcases,deliberationmaynotbenecessary.Therefore,
susorcompletedivergence,humanandAIdecisionrationalesoften westudytheimpactofHuman-AIDeliberationwhenthetaskcase
exhibitpartialalignment[117,132].Whiletheymayconcuron ischallengingforbothparties.Specifically,usingourproposed
certainaspects,differencesmaypersistonothers[100].However, Human-AIDeliberationasaresearchprobe,weaimtoexplorethe
incurrentAI-assisteddecision-makingsystems,AIconsistently followingresearchquestions.
providesafixedrecommendationregardlessofhumanthoughts Whendealingwithtaskcasesthatarechallengingforbothhu-
andhumanscanonlyacceptorrejectAI’srecommendationasa mansandAI:
whole[72],withlimitedsupportforresolvingconflictsorengaging
• RQ1:HowwillHuman-AIDeliberationaffecttaskperformance
inameaningfulexchangeofideaswiththeAIsystem[100].Forex-
andhumans’reliance(anditsappropriateness)onAIsugges-
ample,asshowninFigure1(a),whenthehumandecision-maker’s
tions?
predictionisinconsistentwiththeAImodel’srecommendation
• RQ2:HowwillHuman-AIDeliberationaffecthumans’percep-
andthehumanonlypartiallyagreeswiththeAI’sreasoning(e.g.,
tionsoftheAIanduserexperience?
explanation),existingAI-assisteddecision-makinginterfacesdo
• RQ3:Howwillhumansengageinthedeliberationprocesswhen
notsupportanycommunicationbetweenhumansandAIregarding
workingwithDeliberativeAI?
conflictingopinions.Thislimitationmayimpedetheeffectiveuti-
• RQ4:Howwillhumansperceivetheeffectivenessoftheproposed
lizationofbothhumanandAIknowledge,hinderingcollaborative
Human-AI Deliberation and what can be improved for future
andcomplementaryhuman-AIteamperformance(Challenge2).
Human-AIDeliberationdesign?
Deliberation,characterizedbythoughtfulandreasoneddiscus-
sion,playsapivotalroleinfacilitatingconstructivediscourseand
Toanswerthesequestions,weconductedanexploratorystudy
consensus-buildingacrossvariouscontexts[3,119].Deliberation
inthecontextofanillustrativetask(collegegraduateadmission).
proves effective in facilitating various human decision-making
Werecruitedparticipantswithgraduateadmissionsexperience(at
tasks,includingdeliberativepolitics[13,54,123],clinicaldiagnosis
leastonceadmittedtoagraduateprogram)onProlificandasked
[62,108,111],criminaljustice[29,126],andmore.Itoffersindivid-
themtopredictanapplicant’schanceofgettinganofferbasedon
ualsanopportunitytorigorouslyevaluatedifferentperspectives,
theapplicant’sprofile.Basedonapilotstudy,weselectedsome
includingtheirown,whichcanpotentiallyaddressChallenge1
taskcasesthatwereedgecasesandthereforechallengingforboth
inAI-assisteddecision-making.Moreover,deliberationallowspar-
humansandAI(e.g.,theiraccuracyonthesetaskcaseswasaround
ticipantstorefinetheirviewpointsthroughinformeddiscussions
50-55%).WecomparedtheproposedDeliberativeAIwithtraditional
aboutopiniondiscrepancies[50,51,106].Suchastructuredprocess
explainableAI(XAI)andhumanalonebaselines.Ourexperimental
mayalsoenablehumansandAItoengageindetaileddiscussions,
resultsrevealedthatHuman-AIDeliberationhasthepotentialto
potentiallymitigatingChallenge2.Despitethepotentialbenefits
enhancedecisionaccuracyandpromoteappropriaterelianceon
ofdeliberation,howtodesignmechanismstofacilitatedelibera-
AIrecommendationscomparedtotraditionalXAIassistants.We
tiveconversationbetweenhumansandAIandhowdeliberations
thenderivedvaluableinsightsbyanalyzingparticipants’question-
influenceAI-assisteddecision-makingremaintobeexplored.
naireratings,humanbehaviors,conversationlogs,andopen-ended
Inthispaper,basedonguidelinesandtheoriesinhumandeliber-
feedback.
ation[3,4,119]anddecision-making[2,10,134],weintroducea
Insummary,wemakethreecontributions:
novelframework,Human-AIDeliberationforAI-assisteddecision-
making(Figure1(b)).InsteadofpresentingafixedAIsuggestionfor • Weproposeanovelconceptualframework,Human-AIDelibera-
humanstoacceptorreject,ourframeworkencourageshumansto tion,groundedindecision-makinganddeliberationtheories,for
externalizetheirthoughts,enablesaninteractivedeliberationpro- humansandAItodeliberatetheirconflictingthoughtsinadeci-
cessbetweenhumansandAIaroundtheconflictingpointsoftheir siontask.Accordingly,wedesignthearchitectureofDeliberative
opinionsandrationales,andfostersdynamic,fine-grainedupdates AI thatiscapableofdeliberationwithhumansthroughanovel
ofhumansandAI’sdecisions.Thekeycomponentofthisframe- integrationofdomain-specificmodelsandLLMs.
workisDeliberativeAI,whichhastheabilitytolocateviewpoint • WedemonstratetheinstantiationoftheframeworkandDelib-
dissimilarities,stimulatecomprehensivedeliberationwithhuman erativeAI inanillustrativetask(collegegraduateadmission),
decision-makers,andmakenecessarychanges,evencompromises, includingtheimplementationofdifferentcomponentsandinter-
initsownsuggestionastheconstructivediscussionunfolds.To facedesign.
designsuchanAIassistant,weproposetointegratethestrength • Weconductanexploratorystudytogainaninitialunderstanding
ofdomain-specificmodels(forreliableassistantinformationgen- ofhowHuman-AIDeliberationmightimpactthedecision-making
eration)andLargeLanguageModels(LLMs,forinteractivityand processandhowhumanswouldperceivethisnovelAIassistance.TowardsHuman-AIDeliberation:DesignandEvaluationofLLM-EmpoweredDeliberativeAIforAI-AssistedDecision-Making Conference’17,July2017,Washington,DC,USA
sugg iM se Ay s tion A At tt tr ri ib bu ut te e 1 2 sugg iM se Ay s tion A At tt tr ri ib bu ut te e 1 2 arguments arguments I fs ru u op g md g a Aet se t t i om o Bny AA tt tt rr ii bb uu tt ee 13
Attribute 3 Attribute 3 Attribute 2
Deliberation
Attribute 4 Attribute 4 Attribute 4
AI’s reasons (detailed opinions) AI’s reasons (detailed opinions) AI’s reasons (detailed opinions)
I think it is B. I agree Attribute 1 Attribute 3 Attribute 3
A dw it sti at rh i gb rA u
e
AtI e’ es ow2o
r
p
i
a
t
Bi hnn
?
di 1o a4n n,s b
d
o u 3f t
.
Pr Bed: A Attt tr rii bbu ut te
e
2
3 A
AA
t
tt
t
tt
r
rr
i
ii
b
bb
u
uu
t
tt
e
ee
2
41 pF rein da : l B A At tt tr ri ib bu ut te
e
1
2
A B Attribute 4 Attribute 4
Human’s reasons (detailed opinions) Human’s reasons (detailed opinions)
Figure1:AnillustrationofHuman-AIDeliberation.(A)IntraditionalAI-assisteddecision-making,whenhumansdisagreewith
AI’ssuggestions(andonlyfindpartsofAI’sreasonsapplaudable),itisdifficultforhumanstodecidewhetherandhowmuchto
adoptAI’ssuggestion.(B)InourproposedHuman-AIDeliberation,weprovideopportunitiesforthehumanandtheAImodel
todeliberateonconflictingopinionsbydiscussingrelatedevidenceandarguments.Then,AIandhumanscanupdatetheir
thoughts(whenfinditnecessary)andreachfinalpredictions.
Additionally,wedemonstrateitspotentialtoimprovedecision and AI knowledge[83]. Toaddressthis, we propose Human-AI
accuracyandpromoteappropriatehumanrelianceonAI. Deliberationtoresolveconflictsthroughnaturaldiscussions.
ThesecondchallengeconcernshumanrelianceonAIsugges-
tions[8,90,92,94,141].Achievingcomplementaryperformance
2 RELATEDWORK
reliesonhumandecision-makers’abilitytojudiciouslydetermine
2.1 AI-AssistedDecision-Making:Inadequacies whentoconsiderAIrecommendationsandwhentobeskeptical
andChallenges [17,109,141].Bothover-reliance,whereindividualstrustAIexces-
sively[78,104],andunder-trust,whereindividualsfailtoutilize
ArtificialIntelligence(AI)isincreasinglyusedindecision-making
AIwhennecessary[78],canleadtoadverseoutcomes.Successful
acrossvariousdomains[28,31,68,93,95,144].However,AI’sreal-
decision-makingrequiresindividualstodecidewhetherandhowto
worldapplicationsarenotinfallible,stillfarfrom100%accuracy
relyonAIrecommendationsonacase-by-casebasis[6–8,124,141].
[45,91,113].Thisisespeciallyconcerninginhigh-stakesdomains
CurrentapproachespresentAIperformanceindicators,explana-
likemedicineandcriminaljustice,leadingtoethicalandlegalcom-
tions,outputs,andconfidencelevelstoassisthumansinmaking
plexities[12,21,79].Toaddressthis,theprevalentparadigmof
informeddecisions.However,existingresearchhasfoundthatwhen
AI-assisteddecision-makinghasemerged,drawingsubstantialatten-
peopleareprovidedwitharecommendationandpassivelylookat
tionintheHuman-ComputerInteraction(HCI)andAIcommunities
it,theyoftenlackanalyticalthinking,leadingtoover-relianceor
[8,17,131,141].Inthisparadigm,AItakesonasupportiverole,
under-relianceonAIsystems[16,43,67,83].Human-AIDelibera-
offeringrecommendationsforhumandecision-makerstoacceptor
tion,asproposedinthispaper,encouragesacarefulevaluationof
rejectintheirfinaldecisions[72].
AIrationalesthroughdiscussionsofconflictsinhumanandAIopin-
ResearchinAI-assisteddecision-makingencompassesvarious
ions.Byengaginghumansinthedeliberationprocess,itpromotes
objectives,suchasteamperformance,decisionfairness,efficacy,
amorecomprehensiveunderstandingofAIinsights,reducingthe
efficiency,understandingofAI,trust,relianceonAI,andsubjective
potentialforbothunder-relianceandover-reliance.
experience[6,16,17,25,26,35,43,57,67,83,90,90,91,112,130,131,
138,141].OneofthekeychallengesinAI-assisteddecision-making
2.2 TheRoleofDeliberationinHuman
isachievingcomplementaryperformance,wherethecollaborative
DecisionMaking
decisionoutcomesurpasseswhateitherhumanorAIcanachieve
alone[8,73,112,141].However,empiricalstudiesrevealdifficulties Themeaningofdeliberationis“theactofthinkingaboutordis-
inachievingthis,primarilyduetotwoissues. cussingsomethinganddecidingcarefully” [96].Itinvolvesconsider-
OnechallengeistheunderutilizationofhumanandAIdomain ingallrelevantindividualsasmoralagentswhomustjustifytheir
knowledge[5].Someresearchersaimtoleveragethecomplemen- viewpointsandlistentoothers’reasons[52].Ratherthanseeking
taryaspectsofhumanandAIintelligencebytrainingAItocomple- consensus,theprocessaimstoenhanceindividualperspectives
menthumanknowledge[7,135].Moreover,existingAI-assistant byincorporatingothers’viewpoints,thusincreasingdecisionma-
interfacesdonotefficientlyharnesstheknowledgeofbothparties turityandwisdom[52].Theoriginofgroupdeliberationcanbe
[121].AIcontributesitsknowledgetohumansbyprovidingrecom- tracedbacktopublicdeliberationordeliberativedemocracy,where
mendationswithAIexplanationsservingasameansofrepresent- citizens convene to discuss policies with potential implications
ingitsdetailedreasoning[72].Theseexplanationscouldfacilitate fortheirlives[116].Recentstudiesononlinedeliberationhave
thecollaborativesynthesisofhumanandAIintelligence,allowing showcaseditsabilitytoenhancetheaccuracyofcrowd-working
themtocombineinsightsintodifferentfeaturesforfinaldecisions. tasks[24,34],improveperceptionsofproceduraljustice[40],and
However,whenconflictingviewsarise,currentinterfacesprovide facilitateconsensus-buildingamongparticipants[80,111,126,137].
limitedsupportforthecommunicationandexchangeofhuman Furthermore,deliberationproveseffectiveinfacilitatingvariousConference’17,July2017,Washington,DC,USA ShuaiMa,etal.
decision-makingtasks,includingclinicaldiagnosis[62,108,111], Regardingdiscussion,someresearchhasexploreddialoguesbe-
criminaljustice[29,126],andmore. tween humans and AI in cooperative games [39, 69], but these
Effectivedecision-makingisofparamountimportanceacross discussionshavenotbeenspecificallytailoredtodecision-making
diversedomains,anddeliberationemergesasavaluableprocess tasks.RecenteffortshavestartedtointegratediscussionsintoAI-
repletewithmanifoldadvantages.First,itenhancesdecisionquality assisteddecision-making,suchasZhengetal.’s[143]inclusionof
andproblem-solving[9,75].Deliberationinvolvescomprehensive AIingroupdecision-makingtoassessstudentessays.However,
analysisandcarefulevaluationofoptions,fosteringaholisticun- theseeffortsoftenrelyonWizardofOz(WoZ)setupsandlackgen-
derstandingofissuesbyconsideringvariousfactorsandpotential uinelydesignedAIsystemsforhumaninteraction.Chiangetal.[26]
outcomes[63].Researchunderscoresthatdeliberativedecisions examinedhuman-AIcollaborativedecision-makingforrecidivism
tendtobewiserandmoreeffectiveowingtotheirfoundationin riskassessment,butintheirwork,AIonlyofferssuggestionsand
thorough information and thoughtful analysis [30, 74]. Second, doesnotparticipateinthediscussionwithhumans.Additionally,
deliberationpromotesparticipationandcollaboration[102].Iten- Zhangetal.[140]utilizeAImodelsasboundaryobjectstofoster
couragesengagementfrommultiplestakeholders,therebyfacilitat- deliberationamongorganizations,buttheydonotencompassde-
ingcooperationandcommunicationamongdecision-makers[136]. liberationbetweenhumansandAI.Perhapsthemostsimilarwork
Thiscollaborativeprocessaidsinresolvingcomplexissues,provid- tooursisthatofSlacketal.[118].TheyfocusedonAIexplanation
ingdecision-makerswithampletimefordialogueandnegotiations, andproposedusingdialoguetoimprovetheflexibilitytosupport
ultimatelyensuringthewidespreadacceptanceofdecisions[42]. arbitraryfollow-upquestionsthatusersmighthaveandenhance
Third,deliberationhasthepotentialtomitigatedecisionbiasesand people’sunderstandingofAI.Inthispaper,wealsousetheformof
enhancefairness[59,70].Itassistsdecision-makersinobjectively dialoguetoallowpeopletointeractwiththeAI,andalsoinclude
analyzingissues,mitigatingpersonalbiasesandemotionalinflu- thepartwheretheAIgivesexplanationsthroughdialogue(such
ences,andidentifyingflawedperceptionsandknowledge[122]. astheAIanswersusers’questions).Butthekeydifferenceisthat
Despitethesignificanceofdeliberationindecision-making,there wefocusondeliberationdesignandproposeDeliberativeAI which
isadearthofresearchonitsintegrationintoAI-assisteddecision- cannotonly“explaintousers”butalsoactivelyengageusersin
makingprocesses.Toaddressthisgap,drawingupontheoriesand thedeliberativediscussionsby“askingorchallenging”theusers,
practicesindeliberation[13,54,86,120,123],weproposeaframe- aimingtopromotepeople’scriticalthinking.
workcalledHuman-AIDeliberationtofacilitatehumanreflection Drawinginspirationfromtheprinciplesofdeliberation,wein-
anddiscussiononconflictinghuman-AIopinions.Basedonthis troduceanovelparadigmofHuman-AIDeliberation.Additionally,
framework,weaimtomoveafirststeptowardsdesigningaDelib- wedesignDeliberativeAI whichcombinestheconversationalcapa-
erativeAI andinvestigatingitseffectsondecisionprocessesand bilitiesoflargelanguagemodels(LLMs)withthepredictiveabilities
outcomesthroughanexploratoryempiricalstudy. ofdomain-specificmodels(DS-Model).DeliberativeAI encourages
meticuloushumanthinkingandfacilitatesdiscussionsconcern-
ing disparities between human and AI viewpoints. Through an
2.3 ExistingStudiesonDeliberationin
exploratoryassessment,weinvestigatethepotentialimpactsof
AI-AssistedDecisionMaking
deliberationonAI-assisteddecision-making.Ourworktakesan
Deliberationencompassestwoessentialfacets:theanalyticaland initialsteptowarddesigningandevaluatinghuman-AIdelibera-
contemplativeconsiderationofissuesandactivediscussion[52]. tionindecision-makingcontexts,offeringvaluableinsightsinto
Theseaspectshavegarneredsomeattentioninpreviousresearch theintegrationofdeliberationintoAI-assisteddecision-making
onAI-assisteddecision-making. processes.
Concerningthestimulationofanalyticalthinkinginhumans,
oneapproachinvolvesinterventionsaimedatencouragingdeeper 3 FRAMEWORK:HUMAN-AIDELIBERATION
engagement in System 2 thinking [65] by controlling when AI
Inthissection,wefirstintroducethegeneralprocessofdecision-
informationispresented.Forinstance,theconceptof"cognitive
makingwithanemphasisonthestepthatweighstheevidence
forcing"hasexploredstrategiestocompelhumandecision-makers
foranalternative.Then,groundedinthetheoreticalconstructof
tospendmoretimedeliberatingonproblems[17,105,109].Meth-
WeightofEvidence(WoE),weproposetheHuman-AIDeliberation
odsincludeaskingindividualstomakeindependentpredictions
framework.Finally,basedontheoriesandpracticesinhumande-
beforereceivingAIsuggestions[17,90]orimplementinga"slowal-
liberation,weintroducethedesignconsiderationsandstructureof
gorithm"[17,105].Thesecognitiveforcingtechniqueshavedemon-
DeliberativeAI,thecoreAIcomponentofourframework.
stratedtheabilitytoreducehumanrelianceonAI.Additionally,
researchershaveinvestigatedhowandwhatinformationshould
3.1 UnpackingDecision-Making
bepresented.Forinstance,Garhosetal.[43]foundthatpeople
engagedinmoreanalyticalthinkingwhenAIexplanationswere Decision-makingisaprocessofmakingachoicefromanumber
providedwithoutconcreterecommendations.Furthermore,Danry ofalternativestoachieveadesiredresult[37].Existingliterature
etal.[27]introducedAI-framedQuestioningtoenhancecritical summarizesthegeneraldecision-makingprocessintosevensteps
thinkingandhumandiscernmentofflawedstatements.Whilethese [88,125]–Step1:Identifytheproblem,Step2:Collectinformation,
approachesyieldpositiveresults,theycomewithlimitations,such Step3:Identifythealternatives,Step4:Weightheevidence,Step5:
aspotentiallyleadingtounder-relianceandnotaddressingdiffer- Choosefromthealternatives,Step6:Implementaction,andStep7:
encesbetweenhumanandAIperspectives. Evaluatetheresults.TowardsHuman-AIDeliberation:DesignandEvaluationofLLM-EmpoweredDeliberativeAIforAI-AssistedDecision-Making Conference’17,July2017,Washington,DC,USA
Inthiswork,wedissectadecision-makingproblemandhuman- to opinion discrepancy and even decision errors. Hence, foster-
AI thoughts into four structured components (Figure 2 (a)). (1) inghumans’deliberationonconflictingevidenceweightscouldbe
Decisionmeanstheoveralldecisiontomakeforaspecificprob- advantageous.
lem.(2)Dimensionreferstoanaspectthatpeopleconsiderwhen
reachinganoveralldecision.Forinstance,inagraduateadmis- 3.2 Human-AIDeliberation:AFramework
sion task, dimensions could be applicants’ academic excellence,
Deliberationisbeneficialforenhancingdecision-makingbyinte-
researchability,etc.Takingtabulartaskdata(commonlyusedin
gratingdiverseperspectives,improvingthequalityofsolutions
decision-making[46,131])asanexample,adimensionmaybean
byconsideringvariousviewpoints,fosteringcriticalthinking,and
attributeorasetofrelatedattributes.(3)Opiniononadimension
increasingthelikelihoodofreachinginformedandwell-thought-
denotesone’sviewsontheimpactofadimensionontheoverall
outconclusions[52].Althoughdeliberationiscommonlyusedin
decision(e.g.,anapplicant’sacademicexcellencecontributes+50%
democracyandpoliticalsettings[13,54,123],itsideacanbeap-
totheoverallchanceofbeingadmitted).(4)Evidenceisthebasisof
plied to other decision-making tasks such as clinical diagnosis
anopinion.Forhumans,evidencecanencompassfacts,heuristics,
[62,108,111],criminaljustice[29,126],etc.BuildingupontheWoE
pastexperiences,personalbeliefs,interpretations,andevencreative
decision-makingapproach,weproposeHuman-AIDeliberation,a
thoughts[114,115].Incontrast,AI’sevidenceprimarilyoriginates
frameworktostimulatedeliberativeprocessesinvolvingbothhu-
frominformationandknowledgeembeddedinthetrainingdata.
mansandAI(Figure2).Thisframeworkcomprisesthefollowing
essentialactivities:
3.1.1 WhenandWheretoDeliberate? Inthescopeofthispaper,
weproposetoconductHuman-AIDeliberationin“WeightheEvi- • ElicitationofThoughts:HumanandAIstartwitharticulat-
dence”(Step4inthesevendecision-makingsteps).Foronething, ingtheirdimension-levelperspectivesonthedecisionproblem.
disagreementsbetweenhuman’sthoughtsandAI’ssuggestions WhileAIpresentingits“thoughts”(e.g.,intheformoffeatureim-
oftensurfacewhentheyassessalternativesinthisstep.Diverse portanceexplanation)israthercommoninAI-assisteddecision-
interpretationsofevidenceinStep4arelikelytoleadtoconflicting making[83],thisactivityalsoencouragesindividualstoclarify
opinionsanddisparateoutcomesinsteps5-7[72].Foranother,in theirideasandexaminetheirreasoning,whichpromptsanalyti-
existingAI-assisteddecision-makingtasks[8,72,73],steps1-3are calthinkinginhuman[17,97].Twoaspectsofthisactivityre-
usuallysettledinadvanceandthereisnoneedformuchdelibera- quirecarefuldesign.First,AIthoughtelicitationdemandsagood
tion.WeproposetohavehumansandAIdeliberatetheiropinions balancebetweenhumaninformationneedsandinterpretability
atthedetailedDimensionlevel(i.e.,towhatextentadimension [1,101].PriorresearchsuggestedthatcertainmechanismsAI
supportsoropposesthefinaldecision)ratherthanmerelytalking appliestomakeinferencesandpredictions,althoughinformative,
aboutaccepting/rejectingone’soveralldecision.Inthisprocess, arenotcomprehensibletohumans[99].Hence,thedesignofAI’s
bothhumanandAIneedtosupporttheirargumentswithevidence “thought”explanationsshouldbecriticalforthisactivity.Second,
andweighthepresentedevidenceaccordingtocredibilityandpro- humanthoughtelicitation,whileencouragingthoughtfulreason-
bativevalue[10]. ing[17,97],canimposeapotentialworkload.Itthusdemands
suitable,friendlyinterfacedesigns.
3.1.2 WhattoDeliberateon? Inreal-worldpractices,adeliberation • Alignment of Human-AI Thoughts: As human’s and AI’s
processinStep4isofteninformedbytheimportanceofevidence viewpoints and the process they form those viewpoints may
interpretedinaparticularcontext[22].Ininformationtheory,such diverge[60,66,99],thisactivityistaskedwithestablishinga
“importance”isquantifiedasthe(probabilistic)weightofevidence commonlanguageforthetwopartiestocomparetheirWoEand
(WoE)foragivenhypothesis(andagainstalternativehypotheses) determinetheextentofdiscrepancy,ifany.Properassessment
[50,51,106].WoEiswellstudiedandwidelyadoptedinvarious andpresentationofhuman-AIWoEdifferencescanhelpeffec-
decision-makingdomains[2].Thisisbecauseitsliteralmeaningis tivelynavigatehumans’attentionandeffortsinthesubsequent
easytounderstandbylayusersanditsprobabilisticcalculationis activities[14].
simpletoimplementinpracticalapplications[51,110]. • Discussion:Thisactivityfeaturesconstructivediscussionsthat
WoEisthecorecontentofdeliberationinourproposedframe- enablehumansandAItosubstantiatetheiropinionsviacom-
work.Itcorrespondsto“opinion”–theimportanceofadimension munication,clarifyingchoicesofevidence,andthebasisforas-
toafinaldecisiongivenone’sinterpretationofevidence.Inthe signedweights.Ithasthepotentialbenefitsofcultivatingcritical
remainderofthispaper,weusethetermopinion(aswellasits thinking,mitigatingbiases,andraisingawarenessofdifferences
synonymse.g.,viewpoint)andWoEinterchangeably. betweenmultipleparties[58,76,97].Thisactivityhasahuge
Itiscrucialtonotethatduringevidenceweighing,bothhumans designspaceandusuallyneedstobetailoredtospecificdecision
andAIpossessstrengthsandlimitations.Forinstance,humansmay tasks.Itentailsconsideringvariousdiscussion-relatedfactors,
offernovelinsightsnotpresentinAItrainingdata,yettheycan includingcontent,style,leadership(whoinitiatesandleadsthe
beconstrainedbytimeandcognitivebiases,asperthe“Bounded conversation),duration,andsoon.Atypicalsolutionistrans-
RationalityModel”[114,115].AIexcelsindata-drivenknowledge ferringhuman-humandiscussionpractices[58,76,97]tothe
andcomputation,butisknowntobesusceptibletobiasesintrain- human-AIdiscussioncontexts.
ingdataandfaltersinthefaceofout-of-distributioncases[84]. • UpdateofThoughts:In-depthdiscussionsmayexposepotential
TheseinherenthumanandAIshortcomingscanresultinpoten- flawsandconflictsintheoriginaldecisionsashumansandAI
tiallyincorrect,incomplete,orbiasedevidenceweighting,leading are both imperfect [8]. This activity provides an opportunityConference’17,July2017,Washington,DC,USA ShuaiMa,etal.
B
A AI Thought Human Thought
Decision Elicitation Elicitation
Elicitation of Elicitation of
“Thoughts” Thoughts
Dimension 1 Dimension 2 Dimension N
Update
Opinion Opinion Opinion Interface
Update of Update of
“Thoughts” Alignment of Human-AI Thoughts
Thoughts
… Update
Evidence Evidence Evidence Mechanism A Ps rs ee ss es nm tae tn iot n a on fd
Difference
Discussion
Key activity Discussion
Approach
Design space Final Decision
Figure2:TheframeworkforHuman-AIDeliberation.(A)IllustratestheWeightofEvidence(WoE)conceptindecision-making,
showcasinghowdecision-makersassessevidenceacrossdimensionstoshapeopinionsandarriveatafinaldecision.(B)Presents
theArchitectureforHuman-AIDeliberation,withkeyactivities(showningreyboxes)andpotentialdesignspace(shownin
dashed-lineboxes).
forthemtoreflectonthegapsinthinking[97]andrevisetheir - DC2.Justificationrationality:DeliberativeAI shouldadeptly
thoughtsaccordingly.ForAI,thismeansdesigningappropriate providerationaljustificationsforitsstancesduringinteractions
mechanismstointeractivelyupdateitsrecommendations.For andencouragehumanstodothesame.
humans,theinterfaceshouldpossesstheflexibilityforthemto - DC3.Constructiveupdates:Ratherthanrigidlyadheringtoits
changetheirWoE. initialopinionsorblindlyleaningtowardsothers,DeliberativeAI
shouldaimtofacilitatecompromise,reconciliation,orconsensus
Insummary,theproposedHuman-AIDeliberationframework asdeliberationevolves.Itshouldhelpbothsidestothinkcarefully
consistsoffourinterlinkedactivitiesandrequiresproperdesigns andrationallyandupdatetheirWoEinatimelymanner.
(thepotentialdesignspaceisillustratedinthedashedboxinFigure - DC4.Interactivity:DeliberativeAI shouldbeabletounder-
2(b))ofadecision-makinginterfaceandanAIwiththeabilitytode- standhumanintentionsanddynamicallygenerateappropriate
liberatewithhumans.Sincetheinterfacedesignistask-dependent, responsesbasedonhuman’squestions,arguments,andstate-
weonlyintroducethedesignofDeliberativeAI inthenextsubsec- ments.
tion.Notably,notallactivitiesinthisframeworkarenecessarily - DC5.Respectandagreement:DeliberativeAI mustensure
requiredforHuman-AIDeliberation.Furthermore,wedonotintend polite discourse and respect for other participants, especially
toexhaustallpossibleformsofHuman-AIDeliberation.Researchers duringdiscussions.Evenifitdisagreeswithhumansonsome
areencouragedtoextendthisframeworkorproposeplausibleal- aspects,DeliberativeAI shouldshowrespectandunderstanding,
ternatives. creatingapositiveenvironmentforcontinuedengagement.
To fulfill these considerations, we integrate Large Language
3.3 DeliberativeAI:DesignConsiderationsand Models(LLMs)anddomain-specificmodels(DSmodels)tobuild
OverallStructure DeliberativeAI.DSmodelsareresponsiblefortheinitialgeneration
and subsequent refinement of AI’s WoE. DS models’ predictive
Inspired by human-human deliberation practices and measure-
poweranddomainknowledgeofferreliable(insteadofpotential
ments,wederiveasetofdesignconsiderationsforaDeliberativeAI.
hallucination) information for deliberation activities. LLMs, on
Then,weintroduceitsoverallarchitectureproposedinaccordance
theotherhand,bridgetheinteractionsbetweenhumansandDS
withtheseconsiderations.
modelswiththeirconversationabilities.Overall,thearchitecture
Accordingtodeliberativetheories[13,54,123]andpractices
ofDeliberativeAI (illustratedinFigure3)comprisesthreelayers:
[86,120],DiscourseQualityIndex(DQI)[119]anditsimprovedver-
Communicationlayer,Controllayer,andKnowledgelayer.
sions[4,18]arethemostcomprehensiveandwidelyusedguideline
forassessinghumandeliberation.WeadaptDQItoourAI-assisted • TheCommunicationlayer,empoweredbyLLMs,incorporates
decision-makingcontextandsummarizethefollowingdesigncon- threecomponents:
siderations(DCs): - IntentionAnalyzer(forDC4)understandshumanintentand
argument evidence, facilitating cross-referencing with the
- DC1.Participationequality:DeliberativeAI shouldensure KnowledgelayerthroughtheControllayer.
thatbothpartiespossessequalvoice[23]andsharesimilarop- - DeliberationFacilitator(forDC2&5)encouragescarefulthink-
portunitiestoofferopinionsandreasonsaswellastoparticipate ingandrationaljustificationswhilemaintainingrespectful
indiscussions. deliberation.TowardsHuman-AIDeliberation:DesignandEvaluationofLLM-EmpoweredDeliberativeAIforAI-AssistedDecision-Making Conference’17,July2017,Washington,DC,USA
Conversational Interaction
(e.g., question, response, (dis-)agreement)
Large Langue Model (as a bridge)
Intention Deliberation Argument
Communication Layer
Analyzer Facilitator Evaluator
Data-related Constrain LLM’s
Dialogue
Information Type Output
Controller
Control Layer Knowledge Regulator
Extractor
Opinion Update
Real-time AI Opinion & Controller
Query Knowledge
Knowledge Layer Domain Specific
Training Data
Model
Figure3:TheArchitectureofDeliberativeAI.Ourdesignintegratesbothadomain-specificmodelandaLargeLanguageModel,
enablingtheAItoengageinnaturalcommunicationwithhumanswhilealsoharnessingdomainknowledgederivedfromthe
specializedmodel.
- ArgumentEvaluator (forDC2&3)assesseshumanjustifica- andworkloadreduction[103,133].Second,graduateadmissionof-
tionrationality,whichcanbeusedtofurtherprompthumans’ teninvolvesdeliberationamongcommitteemembers[140],making
reasoningandupdateAIopinions. itidealforstudyingtheeffectsofourproposedHuman-AIDeliber-
• TheControllayer,encompassingfourcomponents,oversees: ation.
- DialogueController (forDC1)managesthedeliberativedis- Thetaskutilizesasynthesizeddataset[25]thatsimulatesprofiles
cussionprocess(e.g.,whentoelicitthoughts,whentoupdate ofapplicantsataU.S.publicuniversitybasedonpubliclyavailable
opinions,whentomoveontothenextdimension,etc.) aggregatestatisticsanddistributions1.Thedatasetcomprises100
- Regulator(forDC2)guidesandconstrainsLLMoutputwith studentapplications’profiles,featuringattributesconsideredby
domain-specificmodelinsightsandtrainingdata. admissioncommitteesinactualscenarios,e.g.,GREVerbal,GRE
- KnowledgeExtractor (forDC2)extractsdatainsightsfrom Quant,GREWriting,GPA,StatementofPurposeStrength,Diversity
domain-specificmodelsandtraining databasedonhuman StatementStrength,Country,Major,Applicant’sUndergraduateInsti-
intentanalysis. tutionRank,andRecommendationLetterStrength.Thedatasetalso
- OpinionUpdateController (forDC3)adjustsAIviewpoints includesadecisionlabelforeachcase:strongreject,weakreject,
basedonhuman-AIdynamics(e.g.,thestrengthofjustifica- weakaccept,orstrongaccept.
tions,uncertaintybehindAI’sopinions,etc.). Tobuildadomain-specificmodel(DS-model)thatcangener-
• TheKnowledgelayercomprisesadomain-specificmodeland atesuggestions,wetrainedamulti-categorylinearmodelusinga
trainingdata,providingbothdomain-specificknowledgeand 70%randomsplitofthedatasetasin[25].Weemployedalinear
data-derivedinsights. regressionmodelasadecisionclassifier,discretizingthepredicted
responses into one of the four decision labels. Consistent with
InSec.4,wewillempiricallyexploreasubsetofthesedimensions
commonpractices[36],wefurtherbinarizedtheoriginallabels,
withaspecificinstantiationoftheproposedHuman-AIDeliberation
mappingstrong/weakrejectto“reject”andstrong/weakacceptto
frameworkandDeliberativeAI inagraduateadmissiontask.
“accept”asthegroundtruthforassessingAImodel’sandpartic-
ipants’predictionaccuracy.Thetrainedmodelachievedan80%
4 INSTANTIATINGTHEFRAMEWORK:
accuracy on the remaining 30% test set. The task samples used
GRADUATEADMISSIONPREDICTION inthestudywereselectedfromthetestset.Itshouldbenoted
4.1 Task,DatasetandAIModel thatinordertoexploretheeffectofHuman-AIDeliberation,we
speciallyselectedcasesfromthetestdatathatarechallengingfor
We choose to use graduate admission as an illustrative task to
bothhumansandAI,sothattheperformanceofAIisaround50%.
demonstratehowtoinstantiatetheproposedHuman-AIDelibera-
ButthisdoesnotmeanthattheAImodelusedinourstudyisan
tionframework.Inthistask,participantsdecideonadmittingor
unrealisticallylow-performanceAI,justthatwefocusondifficult
rejectingapplicantstoaU.S.universitybasedontheirprofiles.We
taskcases.
chosethistaskfortwokeyreasons.First,thistaskiswidelyusedin
AI-assisteddecision-makingresearch[25,36,140,142],withreal- 1Duetoprivacyissues,publicgraduateadmissiondatasetsareallsynthesized.We
worlduniversitiesemployingAIalgorithmsfordecisionconsistency acknowledgedthatitmaydeviatefromthereal-worldsetting.Conference’17,July2017,Washington,DC,USA ShuaiMa,etal.
4.2 ImplementationofHuman-AIDeliberation Prolific4.Eachparticipantexpressedtheiropinionsonvariousdi-
4.2.1 Human-AI Thought Representation and Alignment. In our mensionsofapplicantprofilesandengagedindiscussionswith
Human-AIDeliberationframework,theinitialstepinvolvesboth theAI,particularlyfocusingonconflictingopinions.Thisyielded
humansandAIexternalizingtheirthoughts.Weemployfeature 226humandeliberativestatements.Toextractdiverseintentions
contribution[82,83]torepresenttheirweightofevidence(WoE) fromthesestatements,twoauthorsconductedqualitativecoding
alongeachdecisiondimension[2].Featurecontributionisrepre- usingthematicanalysis[61],andtheresultsaresummarizedin
sentedbycontributionscoresindicatingthepositiveornegative Table2.WetheniterativelyrefinedLLMpromptsbasedonthecol-
influenceofeachfeature𝑥
𝑖
onthefinalprediction𝑦.Ingraduate lecteddataandbuiltan"IntentionAnalyzer"witha96%accuracy
admissiontasks,wetreateachattributeinanapplicant’sprofile inidentifyingthemesofparticipantstatements.Specificprompts
asadimension,andfeaturecontributionrequireshumansandAI areavailableinthesupplementarymaterials.
toassesstheinfluenceofeachdimensiononthefinaldecision.It I-2.DeliberationFacilitator.ThiscomponentaddressesDC2(Justi-
providesacommongroundforAIandhumanstoexpress,compare, ficationRationality)andDC5(RespectandAgreement),asdiscussed
andinitiatediscussionsabouttheirthoughtsatthefeaturelevel inSec3.3,bydesigningcorrespondingLLMprompts.Inparticular,
(seeTable1). weinstructLLMto(1)Demonstrateanuancedunderstandingofthe
Forthehumanside,WoEcanbeinterpretedastheinfluenceof human’sstatement;(2)analyzethespecificcontentoftheperson’s
anattributeonthetotalchanceofanapplicantbeingadmitted.For statement;and(3)provideathoughtfulandcriticalresponse.For
theAIside,weusedSHAP(SHapleyAdditiveexPlanations)[87],a detailedprompts,pleaserefertothesupplementarymaterials.
widely-usedexplainableAIalgorithm,togenerateAIfeaturecon- I-3.ArgumentEvaluator.Themainfunctionofthiscomponentis
tributions.SHAPvaluesindicateboththedirectionandstrengthof toassessthestrengthofaperson’sstatement,whichinformsup-
afeature’simpactonpredictions.SHAPofferstwokeyadvantages: datestoAIopinions.Drawingfromestablishedtheoriesinhuman
itcapturesfeatureinteractions,mirroringhumandecision-making, argumentationevaluation[55,127,128],wedevisedacomprehen-
anditsadditivenatureresembleshowhumanscombineevidence sivescoringmechanismwithninekeyitems:Clarity,Relevance,
weightsfororagainstoptions[10].However,whenappliedinthe Evidence,Logic,Consistency,Counterarguments,Depth,Credibil-
contextofHuman-AIDeliberation,twolimitationsarise:(1)Raw ity,andAlignment.Thesecriteriaareintegratedintoaprompt,
SHAPvaluescanbechallengingtointerpretdirectly.Tobettercon- guidingtheLLMtoevaluatehumanstatements.Wethenaverage
veyfeatureinfluencetonon-experthumans,weconvertedSHAP andscalethescorestoobtaintheoverallhumanargumentstrength
valuesintoprobabilitiesbyadoptingaregressionmodelandtrans- 𝑆 𝐻𝑢𝑚𝑎𝑛 (from0to1;0:weakest,1:strongest).Additionaldetails,
formingthefour-categorylabelrangeintoa0-100%range(inthis includingscoringschemasandprompts,canbefoundinthesup-
way,thegeneratedSHAPvaluecanbedirectlymappedto0-100%) plementarymaterials.
2(2)SHAPvaluesonlytellusershowimportantafeatureis,but Insummary,thecommunicationlayercanengageingeneral
notwhyitisimportant.Tobridgethisgap,weproposegenerat- interactionswithhumans.Toimbueitwithspecificmodelopinions
ing“meta-explanations”thatuseKnowledgeExtractor(Sec.3.3)to andknowledge,werequireacontrollayertomediatebetweenthe
extractevidence(e.g.,datapatterns)fromtrainingdataforeach LLMandtheDS-model.
dimension,enhancingAI’stransparencyduringdeliberation. II.ControlLayer.Thislayermanagesthequeryingandextrac-
tionofspecificDS-modelopinionsandknowledgewhilecontrolling
4.2.2 ImplementationofDeliberativeAI. Next,wedescribehow theentireconversationflow.
weimplementedeachcomponentofDeliberativeAI. II-1.Dialogue/DiscussionController.Thiscomponentservesas
I.CommunicationLayer.Thislayerservesasavitalbridge thecontrolcenterforthediscussionprocess,orchestratingastruc-
betweenhumansandtheDS-model,facilitatingeffectivecommu- tureddeliberationflowasshowninFigure4.Itunfoldsasfollows:
nicationbycomprehendinghumaninputsandcraftingrelevant [ThoughtElicitation]ParticipantsexpresstheirWoEoneachdimen-
responses. sion;AIrespondswithitsperspectives.[Discussion]AIhighlights
I-1.IntentionAnalyzer.Weharnessedthelanguagecapabilities commonalitiesanddiscrepancies,invitingparticipantstoprovide
ofLLMs3todiscernhumanintentionsandtargeteddimensionsin justificationsorquestiondifferingviewpoints.AIrespondswith
discussion.Toformulateeffectivepromptsforintentionanalysis, criticalinsights.AllthreecomponentsoftheCommunicationlayer
weconductedapilotstudytogathercommondialoguesaround (IntentionAnalyzer,DeliberationFacilitator,andArgumentEvalu-
graduateadmissiondecisions,includingquestions,arguments,cri- ator)playvitalrolesinthisphase.Afteroneroundofdiscussion,
tiques,andchallenges.Inthepilotstudy,wedevelopedaprelimi- AIoffersinputoptionsforparticipantstoupdate,maintain,orcon-
naryversionDeliberativeAI(withimperfectdeliberativediscussion tinuethediscussion.AIproceedsbasedonparticipants’choices.If
capability)tocarryoutconversationswith30participantsfrom theywishtomovetothenextdimension,AIsummarizesanypend-
ingdimensions,highlightingdifferences.Participantscanchooseto
exploreuntoucheddimensions,revisitpreviousdiscussions,orskip
thisround.Participantshavetheflexibilitytoinitiatedialogueson
2OtherconversionmethodsincludeusingtheTreeExplainerfromtheSHAPlibrary
anydimensionatanytime,usingquickinputoptionsorfreetext.
(andsettingmodel_output=“probability”)togeneratetheprobabilisticSHAPvalue.
Becausetheadmissionpredictionusedinthispapercanbenaturallyconvertedintoa Theycanrefinetheirviewsonthedecisioninterfaceindependently
probabilityproblem,weadoptedmoredirectcategorylabel-probabilitymapping. ofAIopinionupdates.
3Inthisstudy,weuseGPT-3.5-turboasthelanguagemodel,whichhassufficient
conversationalpowerandisfreelyaccessible(relativetoGPT-4).Wewilluse“LLM”
throughoutthispaperforconsistency. 4www.prolific.coTowardsHuman-AIDeliberation:DesignandEvaluationofLLM-EmpoweredDeliberativeAIforAI-AssistedDecision-Making Conference’17,July2017,Washington,DC,USA
Table1:ThemappingbetweenAI“thoughts”andhumanthoughtsintheWeightofEvidenceframework.
Component AI“thoughts” Humanthoughts
Decision Acceptorrejectoneapplicant Acceptorrejectoneapplicant
Dimension Feature/Attribute(e.g.,GPA) Feature/Attribute(e.g.,GPA)
Opinion Afeature’scontribution(e.g.,GPA:+13%) Weightofevidence(e.g.,GPA:-5%)
Evidence Trainingdata Dataorotherknowledgeheldbypeople
Table2:Qualitativeanalysisofthesentiment/intentioncategoryofparticipants’statements(arguments,justifications,questions,
critiques,etc.)inthedeliberativediscussion.
Themes DefinitionsandExamples #Participants
Participantsevaluatehowattributevaluesaredistributedamongthepoolof
Distribution/Levelof
applicants. 35(15%)
anattribute’svalues
“3.16isn’tabadGPA-it’sonlyslightlybelowaverage,sure,butit’sstillfairlygood”(P2)
Participantsconsiderorchallengetheoverallimportanceofanattributeonthe
Overallimportance admissiondecision.
24(10%)
ofanattribute “Diversityisextremelyimportanttotheinstitutionasawholesothestudentshighlyrated
diversitystatementwouldhighlyinfluencetheiradmittance.”(P33)
Participantsdirectlyexpresstheiropiniononanattribute’scontributionor
Contributionof challengethecontributiongivenbytheAIbutwithoutevidence.
47(20%)
anattribute “IknowApplicantUndergraduateSchoolRankinghasasignificantimpactonthechanceof
admission.Butwhyismediumranknotgood?”(P1)
Participantscompareanattribute’scurrentvaluewithothervalues(oftenusing
Contrastive theaverage)tojudgeanattribute’simpact.
41(18%)
evaluation “Iamsurprisedyourankedtheapplicant’sGPAonanegativescale.3.26isnotthatmuch
lowerthanthe3.5ofthelastapplicant.”(P10)
Participantsevaluatehowdifferentattributesinteract,takingintoaccountthe
influenceofcertainattributevaluesonthestrengthofothers.
Holisticreview “TheengineeringmajorisincrediblydifficultandanyGPAabovea3.5isconsideredsuccess-
ofmultipleattributes ful.”(P3) 23(10%)
“Isaid2%positiveinfluencebecausethisindividualwenttoatoprankschool,whichIassume
isharderacademicallythansomelowerrankedschools.”(P22)
Participantsgivedata-irrelevantstatementsbasedontheirheuristics,pastexpe-
Data-irrelevant riences,personalbeliefs,etc.
77(34%)
questions/arguments “Statementofpurposeistheonlypartoftheapplicationprocesswheretheapplicantgets
toshowuswhotheyreallyareintheirownwords-notjustascoreorsomedatavalue.I
rankedthesehigherforthisreason.”(P5)
II-2.Knowledgeextractor.Basedontheattributes/dimensionsand • Overallattributeimportance:Functionget_global_feature_importance
intenttypesidentifiedbythe“IntentionAnalyzer”(seeTable2), (attribute)returnsglobalimportance.Functionget_correlation
wedevelopedaseriesofqueryfunctionstoextractrelevantdata (attribute)providesPearsoncorrelation.Functionget_influence_on_admission_chance
knowledgefromtheDS-Model.Thesefunctionshelppullevidence (attribute)calculatesadmissionchancechangesforvaryingat-
fortheLLMtogenerateresponsesindeliberativediscussionsappro- tributevalues.
priately.Weestablishedamappingbetweentherecognizedintent • Contributionofanattribute:Functionget_current_value_influence
typeandthequeryfunctionandcalleddifferentqueryfunctions (attribute)calculatesadmissionchancedifferenceswhenanat-
basedontherecognizedintenttype.Belowisabriefoverviewofthe tributeisrandomized.
designedfunctionscorrespondingtodifferenthumanintenttypes. • ContrastiveEvaluation:Functionget_contrastive_admission_chance
Pleaserefertothesupplementarymaterialsfordetailedcodesand (attribute,contrastive)computesadmissionchancedifferences
examples. withacontrastivevalue.
• Holisticreviewofmultipleattributes:Functionget_holistic_analysis
(attributes,fixed_attributes)evaluatesattributeimpactsinspecific
• Distribution/Levelofanattribute’svalue:Functionget_distribution scenarios,e.g.,GPApercentileintop-rankedschools.
(attribute)calculatesattributevaluepercentileswithintheappli-
cantpool,alongwithcontextualcomparisons(withminimum,
maximum,quartiles,mean,andmedian).Conference’17,July2017,Washington,DC,USA ShuaiMa,etal.
II-3.Regulator.Theprimaryobjectiveofthiscomponentisto 4.3 InterfaceDesign
harnesstheexpertiseoftheDS-Modeltoregulatetheresponsesgen- Theinterfaceforthegraduateadmissiontaskisstructuredinto
eratedbyLLM.ThisapproachmakescertainthatLLM’sresponses threemainregions:
alwaysalignwiththeDS-Model’sknowledgeanddecisions.To
• ProfileRegion(Figure6(A))displaystheapplicant’sprofile,
achievethisgoal,wecreatedconsistency-ensuringpromptsbased
providingatablewiththecurrentvalueandpossiblerangeof
onthreekeyelements:(1)thefindingsextractedbytheKnowledge
eachattribute.Userscanaccessattributedefinitionsandbasic
Extractor, (2) the overarching decisions made by the DS-Model,
datadistributionstatistics(minimum,maximum,average,and
and(3)theDS-Model’sviewpointonthecurrentattributeunder
medianvalues)byhoveringoverpinkcircularmarkers.
discussion.
• OpinionandPredictionRegion(Figure6(B))isdedicatedto
II-4.OpinionUpdateController:WeupdatedtheAI’sopinions
thoughtelicitationbybothusersandtheAI.
bytakingintoconsideration:(1)thecurrentopinionsofboththe
human(𝑂 𝐻𝑢𝑚𝑎𝑛)andtheAI(𝑂 𝐴𝐼)onthediscussedattribute,(2) - Theupperpartdisplaysaggregatepredictionsfrombothhu-
thestrengthofthehuman’sargument(𝑆 𝐻𝑢𝑚𝑎𝑛,seeArgumentEval- mansandAI.Thisincludesalegend(Figure6-1)andtwoslide
uator),and(3)theAI’suncertainty(𝑈 𝐴𝐼)measuredandcalibrated bars(Figure6-2and-3)representingAI’sandtheuser’sover-
allpredictions,respectively.Eachslidebarshowsthreeline
viaUncertaintyQuantification360toolbox[48](theuncertainty
indicators:awhitelinerepresentingtheaverageadmission
rangesfrom0to1:thecloserto1,themoreuncertainAI’spre-
probabilityofallapplicants,agreenlineshowingtheinitial
dictionis).WeproposethefollowingformulatoupdatetheAI’s
opinions(𝑂ˆ 𝐴𝐼)onanattributebasedonthesefactors,inspiredby predictionsmadebyhumans/AI,andayellowlinedenoting
theupdatedpredictionbyhumans/AI(onlyshownafteran
resultaggregationincrowdintelligence[44,89]:
updateismade).
- ThebottompartofthisregionallowsbothhumansandAI
𝑂ˆ 𝐴𝐼 = 1−𝑈 𝐴1 𝐼− +𝑈 𝑆𝐴 𝐻𝐼
𝑢𝑚𝑎𝑛
·𝑂 𝐴𝐼 + 1−𝑈𝑆 𝐴𝐻 𝐼𝑢 +𝑚 𝑆𝑎 𝐻𝑛
𝑢𝑚𝑎𝑛
·𝑂 𝐻𝑢𝑚𝑎𝑛, (1) t ao ppe lx ip care ns ts as tp tre ic bi ufi tc eo ).p Aini so imns po lin fiee dac ph rod fiec leis ii son did si pm lae yn es dio in n( ti h.e e.,
middle(Figure6-5)tominimizeusers’needtoswitchatten-
III.KnowledgeLayer
tion. Each dimension is accompanied by a status indicator,
ThislayerprimarilyconsistsoftheDS-Modelandthetraining
denotingwhetherithasbeendiscussed(green),iscurrently
dataset.TheDS-Modelofferscomprehensiveperspectivesandfa-
beingdiscussed(orange),orisyettobediscussed(gray).Sepa-
cilitatesreal-timedecisionpredictions.Thetrainingdatasetoffers
rate“concreteopinion”slidebarsarepresentednexttoeach
necessaryinformation(e.g.,datadistributionsandpatterns)forthe
attribute(Figure 6-4andFigure6-6)for AIandhumansto
KnowledgeExtractortoperformreal-timecalculationsandqueries.
indicatetheirdimension-levelopinions.
- Each dimension’s slide bar starts in a central position (0%
4.2.3 AnExample. Figure5providesthedetailsofaconversation
contribution).Userscandragtheslideranytimetotherightto
between a human and a Deliberative AI discussing how an ap-
increasetheweightonanattributetowardapositive“admit”
plicant’sGPAaffectsadmissionschances.Here’sastep-by-step
decisionortothelefttoreduceitscontribution.Alternatively,
breakdown:
userscandirectlyinputcontributionvaluesinaboxbelowthe
(1) TheuserinputsGPA-relatedargumentsinthedialoguein- slider.
terface. SlidebarsinFigure6-2andFigure6-4areinterconnected,soas
(2) Thesystempackagestheuser’sinputasapromptforthe thoseinFigure6-3andFigure6-6.Valueswithinthe“overall
IntentionAnalyzerintheCommunicationLayer. predictionbar”reflectthecumulativevaluesfromthe“concrete
(3) TheIntentionAnalyzerrecognizesattributesandintentions opinionbars.”Anychangesinthedimension-levelbarsimmedi-
andsavesinJSONformat,thenforwardsittotheKnowledge atelyupdatetheoverallprediction.AI’sandtheuser’sopinions
ExtractorintheControlLayer. aredisplayedsidebysideforeasycomparison.Notethatatthe
(4) TheKnowledgeExtractor generatesaqueryfunctionand beginningofeachcase,usershavetocompletetheiropinion
fetchesstatisticalresultsfromtheDS-Modelandtraining inputsandclickthe[SubmitOpinion]buttontoseeAI’sinitial
data. (overallandconcrete)suggestions.
(5) ThestatisticalresultsaretransmittedtotheRegulator. • DiscussionRegion(Figure6(C))iswherealldeliberativedia-
(6) Regulatorcraftsaconstraintpromptensuringconsistency loguestakeplace.Userscantypeouttheiropinionarguments,
betweentheLLM’soutputandtheDS-Model’sprediction, questions,disagreementswithAI,responsestoAIqueries,and
feedingittotheLLM-basedDeliberationFacilitator. more.Importantly,changesmadeintheOpinionRegionareseam-
(7) TheDeliberationFacilitatorgeneratesresponsestotheuser’s lesslyintegratedbyAIandreflectedinongoingdiscussions,and
initialarguments. conversely,anyviewpointchangesmentionedinthedialogue
areinstantlyupdatedintheOpinionRegion.
Overall,inthisframework,LLMisusedforlanguageunderstand-
ingandgeneration.TheopinionsandevidenceusedbyLLMare
5 EXPLORATORYUSERSTUDY
retrievedinrealtimefromtheDS-Modelandtrainingdatathrough
ourlogiccode(likeretrievalaugmentedgeneration[81]).Inthis To get an initial understanding of the impact of the Human-AI
way,theLLMisusedinacontrollableandresponsiblemanner, DeliberationmechanismonAI-assisteddecision-making,wecon-
minimizingthepotentialhallucination. ductedamixed-methodsstudyinthecontextofgraduateadmissionTowardsHuman-AIDeliberation:DesignandEvaluationofLLM-EmpoweredDeliberativeAIforAI-AssistedDecision-Making Conference’17,July2017,Washington,DC,USA
Quick Response
Options for Human
Summarize Similarities
and Differences
n AI summarizes
oe agreements, and ranks
is
s
un
ile
disagreements.
cm
s iDit A AIs sk
e
f lo ecr tJ su ts ht eif i dc ia mti eo nn
sion
with the largest
difference and asks
people “why”.
Give Justification
Human gives
justification or
questions/challenges
Respond Critically the AI.
AI responds with respect
and critical thoughts (if
the justification is data-
related, reply with DS-
model’s knowledge).
Update Opinions?
-Update Tell/Ask AI more
-Keep
-Tell/Ask AI more
Keep Update
AI Opinion Update Update Opinion
AI briefly summarizes Human updates opinions.
what has been
discussed and makes
updates on the
discussed dimensions.
Move on to Next
Dimension? No
-Yes
-No
Summarize Differences
for remaining
dimensions Yes
AI reminds humans
what have not been
discussed yet
Continue Discussion?
-Yes
-No
Yes
Ask for Final Check
AI asks for the human to No
finally check their
prediction. Then the
human can proceed to Check and Proceed
the next. Human checks the
prediction and make
necessary updates. Then
proceed to the next
applicant.
Figure4:Theconversationflowforthedeliberativediscussion.
decisions.Wecallthisstudyexploratorybecausewedidnotseek andtheothertworepresentedAsianapplicants(Asiacases).To
tospecificallyprovewhetherHuman-AIDeliberationiseffective keeptheDeliberativeAI discussionsengagingandavoidrepetition,
foractualgraduateadmissions.Inotherwords,graduateadmis- wecarefullychosetaskswithdiverseattributes.It’sworthnoting
sionisNOTourfocus.Instead,wejustusegraduateadmissionas thattheAImodelisbiasedtowardUSapplicantsduetotraining
anillustrativetasktoexplorethepotentialeffectsofHuman-AI databiases.Thisbiasresultsina“+11%”featurecontributionfor
DeliberationonAI-assisteddecision-making. “CountrybelongstotheUS“anda“-4%”featurecontributionfor
“CountrybelongstoAsia”.Soitcanbeinterestingtotestwhether
5.1 TaskSetup participantswilldiscoversuchbiaseswhencollaboratingwiththe
Weusedthegraduateadmissiontaskasourtestbed.Toensure AI.
manageablestudydurationsandpreventparticipantfatigue,we
5.2 Conditions
selectedfivetaskcasesbasedonthelengthofthepilotstudy.These
cases included one for the tutorial and four for the main tasks. WecomparedtheproposedDeliberativeAI withthetraditional
Amongthemaintasks,tworepresentedUSapplicants(UScases), explainableAIassistant(XAI)andHumanAlone.Conference’17,July2017,Washington,DC,USA ShuaiMa,etal.
User input sentences: “Although the GPA is good, it is not outstanding 1
and just a little bit above the average. I don’t think that’s going to have a
particularly positive impact on the admission.”
Dialogue Interface
LLM output sentences: “I understand your concern about the applicant’s GPA not
Prompt: [Please identify the attribute and intention 2 7 being outstanding. However, it is important to note that the applicant’s GPA of 3.63
category from User input sentences] falls within the 80% percentile among the applicant pool. This means that 80% of
the applicants have a lower GPA than this applicant.”
Communication Layer (LLM) Intention Deliberation
Analyzer Facilitator
LLM output json: {Attribute: GPA, 3 6 Prompt: [Use the Statistical results to support your response and
Category: Distribution of an attribute's values} promote the user to critically think of her/his statement]
Knowledge
Control Layer (code) Regulator
Extractor
Query function: get_distribution (GPA) 4 5 Statistical results: the GPA falls within the 80% percentile
Domain Specific
Knowledge Layer Model Training Data
Figure5:AnillustrationofhowDeliberativeAI processeshumans’inputsandhowitgeneratesoutputs.Thepromptsusedare
simplifiedinthisfigureforillustrationpurposes.(forthecompleteprompts,pleasecheckoursupplementarymaterials)
• DeliberativeAI(DAI):Participantssharetheirthoughtsonvari- criteria:(1)residingintheUnitedStates;(2)havingbeenadmitted
ousdimensionsbeforeviewingAIrecommendations.Wepresent toaUSgraduateprogrambefore(asthetaskinvolvedpredicting
AI’s“thoughts”oneachdimensionafterward.Aftercomparing graduateadmissioninaUSuniversity);(3)havingatleasta99%
conflictingviewpoints,weofferadialogueinterfaceforpartic- approvalratewithatleast1000previoussubmissions;(4)using
ipantsandAItodiscussanyoftheperspectives,asshownin Englishastheirfirstlanguage;and(5)usingadesktopcomputer
Figure6. fortheexperiment.Afterfilteringbasedonattention-checkques-
• ExplainableAI(XAI):Afterindividualsprovidetheirpredic- tions,weobtained153validresponses(DeliberativeAI:48,XAI:51,
tions,theyreceiveAIrecommendations(alongwithfeaturecontribution-HumanAlone:54).Amongthefinalparticipants,84self-reportedas
basedexplanations)andthenmaketheirfinaljudgments(see male,67asfemale,and2asother.Therewere23participantsaged
Figure15inAppendix). 24-29,42aged30-39,33aged40-49,30aged50-59,and25agedover
• HumanAlone:Participantsneedtomakepredictionsindepen- 59.Participantsalsoratedtheirknowledgeofartificialintelligence:
dentlywithoutanyAIassistance. 9hadnoknowledge,86knewbasicAIconcepts,50hadexperi-
enceusingAIalgorithms,and8wereAIexperts.Participantsin
5.3 ProcedureandParticipants theDeliberativeAI conditionreceivedbonusesbasedontheactual
studylength.Tomotivatehigh-qualitywork,participantsreceived
5.3.1 Procedure. Weconductedabetween-subjectsstudy.After
a$0.50bonusiftheiroverallaccuracyexceeded75%.Onaverage,
obtainingconsent,participantscompletedabackgroundquestion-
participantsearnedabout$12perhour.
nairegatheringdemographicdataandassessingtheirAIexper-
tise. Participants then went to an interactive tutorial, practiced
5.4 Measurement
withoneexampletask,andreceiveddistributionandsummary
statisticsforeachattributeoftheapplicant’sprofile.Followingthe Tocomprehensivelyassesstheimpactofhuman-AIdeliberation,we
tutorial,qualificationquestionswereaskedtocheckparticipants’ evaluatedthefollowingaspects.Detailedmeaningsandquestions
understandingofthetask,withonlythoseansweringallquestions foreachmetricscanbeseeninTable3.
correctly proceeding to the main task. The main task involved • TaskPerformance.WeevaluateddecisionaccuracyusingDeci-
tacklingfourgraduateadmissiontaskcases,includingproviding sionAccuracy[8,90,141].
predictions/opinions,receivingAIsuggestions/opinions,engaging • Reliance.Weassessedparticipants’relianceonAIsuggestions
indiscussionswithAI,andconfirmingfinalpredictions.Finally,we usingAgreementFraction[57,90,141]andSwitchFraction[57,
collectedparticipants’perceptions,experiences,andfeedbackon 141].Also,wemeasuredtheappropriatenessofhumanreliance
theAIsystemandthediscussionprocessintheexitsurvey. byOver-relianceRatio[104,129,131]andUnder-relianceRatio
[104,129,131].
5.3.2 Participants. Beforeparticipantrecruitment,weconducted
• Behaviors.Weexaminedparticipants’OpinionChanges[15,49,
apoweranalysistodeterminetherequiredsamplesizeforusing
107],FrequencyofOpinionChanges[139],ConflictingDimensions,
G*Power[41].Wespecifiedadefaulteffectsize𝑓=0.25(indicating
DimensionsDiscussed,andTimeSpent[1,138].Specifically,for
amoderateeffect),asignificancethreshold𝛼=0.05,andastatistical
OpinionChanges,weuseweightofadvice(WOA)[49]tomeasure
power1−𝛽=0.8.Thisresultedinarequiredtotalsamplesizeof159
howhumans’overallopinionsareinfluencedbyAI’sopinions5.
participantsforthethreeconditions.Afterobtaininginstitutional
IRBapproval,werecruitedatotalof174participantsfromProlific4.
5WOAis0whenahuman’sfinalpredictionmatchestheirinitialone,1whenitmatches
Toensurehigh-qualityresponses,participantshadtomeetspecific theAI’sprediction,and0.5whentheindividualaveragestheirestimatewithAIadvice.TowardsHuman-AIDeliberation:DesignandEvaluationofLLM-EmpoweredDeliberativeAIforAI-AssistedDecision-Making Conference’17,July2017,Washington,DC,USA
A
B C
1
2 3
4 5 6
Figure6:TheinterfaceofDeliberativeAI.Theinterfacecontainsthreeparts.Thetoppart(A)istheapplicant’sprofile.The
bottomleftpart(B)istheregionforhumansandAItoindicate(andupdate)theiropinions.Thebottomrightpart(C)isthe
discussionregionwherehumansandAIcandiscussconflictingopinions.(Allthedashedlinesareonlyforillustration)Conference’17,July2017,Washington,DC,USA ShuaiMa,etal.
Table3:Measurementsusedinouruserstudy.Wecollectedparticipants’objectivedecisionandbehaviordata,subjective
questionnairedata,andqualitativeopen-endedfeedback.
Aspect Metrics DetailedMeaningandQuestions
ObjectiveMeasures
Performance DecisionAccuracy Accuracyofparticipants’finalpredictions.
Percentageoftaskswhereparticipants’finalpredictionagreedwithAI’spredic-
AgreementFraction tion. NumberoffinaldecisionssameastheAIsuggestion
Totalnumberofdecisions
PercentageoftaskswhereAI’spredictionwasusedwheninitialdisagreement
SwitchFraction existed. NumberofdecisionsuserswitchedtoagreewiththeAImodel
Reliance Totalnumberofdecisionswithinitialdisagreement
Fraction of tasks where participants used an incorrect AI prediction.
Over-relianceRatio NumberofincorrecthumanfinaldecisionswithincorrectAIsuggestions
TotalnumberofincorrectAIsuggestions
Fraction of tasks where participants did not use a correct AI prediction.
Under-relianceRatio NumberofincorrecthumanfinaldecisionswithcorrectAIsuggestions
TotalnumberofcorrectAIsuggestions
OpinionChanges WOA=
humanfinallypredictedadmissionchance−humaninitiallypredictedadmissionchance
AIinitiallypredictedadmissionchance−humaninitiallypredictedadmissionchance
FrequencyofOpinionChanges Countofopinionchangesperprediction.
DialogueRounds Numberofconversationroundsinadecision-makingtask.
Behaviors
ConflictingDimensions Countofdimensionswithconflictinginformation.
DimensionsDiscussed Countofdimensionsconsideredinaprediction.
TimeSpent Averagetimespentperdecision.
SubjectiveMeasures
Helpfulness “IthinktheAImodel’sassistanceishelpful/usefulformetomakegooddecisions.”
Perceptions Trustworthiness “TheAImodelcanbetrustedtoprovidereliabledecisionsupport.”
ofAI “IunderstandhowtheAImodelworkstopredictanapplicant’schanceofbeing
Understanding
admitted.”
DecisionConfidence “IfeelconfidentinthedecisionsImade.”
MentalDemand “Thedecision-makingprocessismentallydemanding.”
User “Ihavetoworkhard(mentallyandphysically)toaccomplishmylevelofperfor-
Effort
Experience mance.”
Complexity “Thedecision-makingprocessandtheinteractionwithAImodelsarecomplex.”
Satisfaction “IamsatisfiedwiththeAImodel’sassistanceandthedecision-makingprocess.”
“DoyouthinkthediscussionwithAIis(ornot)helpful?Couldyoutellusthe
Perceptionofhelpfulness
reasonswhyyouthinkthediscussionishelpful(ornothelpful)?”
Open-ended
PerceptionofAIupdate “WhatdoyouthinkoftheAIupdatingitsownviewsduringthediscussion?”
Feedback
“Tomakeabetterdiscussion,whichpartsdoyouthinkthecurrentAIneedstobe
PotentialImprovement
improved,andhowshoulditbeimproved?”
• PerceptionsofAI.Wemeasuredparticipants’perceivedHelpful- 5.4.1 AnalysisMethods. Weconductedmixed-methodsanalyses
ness[16,20,77],Trustworthiness[17,46],andUnderstanding[131] toexaminetheaforementionedmetrics.Forthequantitativeanaly-
through7-pointLikertscale(1:Stronglydisagree;7:Strongly sis,wefirstperformednormalitytests(Shapiro-Wilk)andfound
agree.Thesamebelow). thatthedatadidnotfitthenormalityassumption.Thereforewe
• UserExperience.Wemeasuredparticipants’DecisionConfi- ranthenon-parametertests.Specifically,tocompareDeliberative
dence[98].Meanwhile,asdeliberationrequiresextraefforts,we AI and XAI (such as humans’ reliance on AI, and their percep-
evaluatedparticipants’self-reportedMentalDemand[17,46,56, tionsofAI),werunMann-WhitneyUtest.Tocompareallthree
71],Effort[56],Complexity[17],andSatisfaction[17,46]via7- conditions(suchastaskperformance,anduserexperience),we
pointLikertscale. employedKruskal–WallistestswithBonferronipost-hoccorrec-
• Open-endedFeedback.Asweaimtogainanin-depthunder- tion.Forqualitativeanalysis,twoauthorsindependentlycoded
standingofparticipants’perceptionsoftheDeliberativeAI and participants’ open-ended feedback and conversation logs using
thedeliberativedecision-makingprocess,weaddedthreeopen- an inductive thematic analysis approach [61]. The final themes
endedquestionsintheexitsurvey. emergedthroughdiscussionsandharmonizationoverseveralitera-
tions.Wealsoidentifiedrepresentativeexamplesfromthesource
textsfordemonstrationinthispaper.
ApositiveWOAmeanshumanopinionsalignmorewithAI(withvaluesabove1
indicatingover-adjustment),whileanegativeWOAsignifiesadivergencefromAI
opinions.TowardsHuman-AIDeliberation:DesignandEvaluationofLLM-EmpoweredDeliberativeAIforAI-AssistedDecision-Making Conference’17,July2017,Washington,DC,USA
6 RESULTS nosignificantdifferencebetweenDeliberativeAI(𝑀=0.32,𝑆𝐷=0.28)
Inthissection,wereportourexploratoryfindingsregardingthefour
andXAI(𝑀=0.29,𝑆𝐷=0.30)intermsofunder-reliance.Whilesignif-
researchquestions:(RQ1)howHuman-AIDeliberationaffectstask icantlylessover-reliancewasobservedinDeliberativeAI (𝑀=0.47,
performanceandhumanreliance(andrelianceappropriateness)on
𝑆𝐷=0.31)thaninXAI (𝑀=0.65,𝑆𝐷=0.33,𝑝<0.001),whichmeans
AI,(RQ2)howHuman-AIDeliberationaffectshumanperceptions thatparticipantshadmoreappropriaterelianceonAIwhencollab-
andtaskexperience,(RQ3)howhumansengageinthedelibera- oratingwithourproposedDeliberativeAI.
tionprocess,and(RQ4)howhumansperceivetheeffectivenessof 6.1.4 Anexploratoryanalysisoflearningeffects. Inadditiontothe
Human-AIDeliberationandwhatshouldbeimproved. accuracyandreliance,weobservedlearningeffectswhenhumans
workedwithDeliberativeAI tomakedecisions(Figure9).Toquan-
6.1 RQ1:HowwillHuman-AIDeliberationaffect
tifytheeffect,following[19]wefittedalinearmodelofaverage
taskperformanceandhumans’reliance participantaccuracyforeachdecisionround.Wefoundalearning
(anditsappropriateness)onAIsuggestions? effecttrendforDeliberativeAI (althoughonlymarginallysignifi-
cant,𝑝=0.051).However,nosignificantlearningeffectswerefound
6.1.1 DecisionAccuracy. AsshowninFigure7,wefindthatpar-
inXAI.Thisresultrevealsparticipantsmaygainbetterknowledge
ticipantsintheDeliberativeAI conditionexhibitedsignificantly
higherdecisionaccuracy(𝑀=0.598,𝑆𝐷=0.169)comparedtothose aboutthetaskandhowtocollaboratewiththeAIpartnertodeal
intheXAIcondition(𝑀=0.524,𝑆𝐷=0.16,𝑝<0.05).Althoughthereis withthetaskasthedeliberationprogresses.
Insummary,DeliberativeAI hasapositiveeffectinimproving
nostatisticallysignificantdifference,atrendemergeswhereDelib-
decisionaccuracy.Besides,sincetheAImodel’saccuracyisonly
erativeAI tendstosurpassHumanAloneperformance,whileXAI
50%,participantsinDeliberativeAI reliedlessonAI’sincorrect
generallyunderperformscomparedtoHumanAlone.Thisfinding
suggestionswhichinturnleadstomoreappropriatereliance(less
indicatesthatinscenarioswheretasksaredifficultforbothhumans
over-reliance).However,ourcurrentresultsdonotmeanthatDe-
andAI,traditionalExplainableAI(XAI)mightnotenhanceper-
liberativeAI willalsoleadtobetterdecisionperformanceandmore
formanceandcouldevenleadtodetrimentaleffects.Conversely,
appropriatehumanreliancethanXAIwhentheAIperformanceis
Human-AIDeliberationhasthepotentialtoprovidepositivebene-
high.Futureworkisneededtofurtherexploretheeffectswhenthe
fits,eventhoughtheperformanceofunderlyingAImodelsinthese
AIperformancevaries.
challengingtaskcasesisnotgoodenough.
6.2 RQ2:HowwillHuman-AIDeliberation
 ' H F L V L R Q  $ F F X U D F \ affecthumans’perceptionsoftheAIand
      userexperience?
WemeasuredtheeffectsofdifferentAIconditionsonparticipants’
     $ ,  $ F F X U D F \ perceptionsanduserexperienceviaa7-pointLikertscale(1:strongly
 ' H O L E H U D W L Y H  $ , disagree,7:stronglyagree).
 ; $ ,
     + X P D Q  $ O R Q H 6.2.1 PerceptionsofAI. Figure10showsparticipants’perceptions
oftheAImodel.Therewerenosignificantdifferencesinperceived
helpfulness andunderstanding betweenDeliberativeAI andXAI.
    However,participantsreportedsignificantlylesstrustinDeliber-
ativeAI (𝑀=4.47,𝑆𝐷=1.68)comparedtoXAI (𝑀=5.52,𝑆𝐷=1.27,
Figure7:Taskperformanceindifferentconditions.Theerror 𝑝<0.01),aligningwiththeirreliancebehaviors(Sec.6.1.2).Thisdif-
barsrepresent95%confidenceinterval.(*:𝑝<0.05,**:𝑝<0.01, ferencemaybeattributedtoparticipantsidentifyingmoreAIflaws
***:𝑝<0.001) throughdeliberationthanbysolelyobservingAI’sexplanations,
supportedbyconversationlogsanalysis(seeSec.6.4fordetails).
6.2.2 Userexperience. First,wewanttoseeparticipants’decision
6.1.2 Reliance. Wemeasuredparticipants’objectiverelianceby
confidence.AsindicatedinFigure11,participantsinXAI reported
agreementfractionandswitchfraction.AsshowninFigure8(a),
significantlyhigherconfidence(𝑀=6,𝑆𝐷=1.10)intheirpredictions
participantsagreedsignificantlylesswithAI’ssuggestionsinDelib-
erativeAI(𝑀=0.57,𝑆𝐷=0.24)thaninXAI(𝑀=0.68,𝑆𝐷=0.27,𝑝<0.05),
thanthoseinHumanAlone(𝑀=5.59,𝑆𝐷=1.12,𝑝<0.05).However,
fromFigure7(a)wefoundthatthefinalaccuracyofparticipants
andswitchedsignificantlylesstoAI’spredictionsinDeliberativeAI
(𝑀=0.23,𝑆𝐷=0.35)thaninXAI (𝑀=0.51,𝑆𝐷=0.41,𝑝<0.001).Com- inXAI isevenlowerthanthoseinHumanAlone (althoughnot
significant).ThisindicatesthatthetraditionalXAI mightleadto
binedwithparticipants’open-endedfeedback(Sec.6.4),thismaybe
humans’illusionaryconfidence,whichcouldpreventhumans
becausepeopleinvestmoreinindependentthinkingintheprocess
frommakingoptimaldecisions.
ofdeliberationwithAIandrealizetheproblematicaspectsofAI’s
GiventhattheDeliberativeAIrequiresparticipantstoexternalize
perspective.
thoughtsatadimensionlevelandengageindeliberativediscussions
6.1.3 AppropriatenessofReliance. Wefurthermeasuredtheappro- onconflictingopinions,it’scrucialtoexplorehowtheseactivities
priatenessofparticipants’relianceonAI’ssuggestionbyunder- influencetheuserexperience.Resultsshowednosignificantdif-
relianceandover-reliance(Figure8(b)).Resultsshowthatthereis ferenceamongthethreeconditionsconcerningMentalDemand,Conference’17,July2017,Washington,DC,USA ShuaiMa,etal.
 5 H O L D Q F H  $ S S U R S U L D W H Q H V V  R I  5 H O L D Q F H
             
   
   
 ' H O L E H U D W L Y H  $ ,
     ; $ ,
   
   
   
     
 $ J U H H P H Q W  ) U D F W L R Q  6 Z L W F K  ) U D F W L R Q  8 Q G H U  5 H O L D Q F H  2 Y H U  5 H O L D Q F H
(a) (b)
Figure8:Participants’relianceandtheappropriatenessoftheirreliance.(A)Participants’relianceonAI’ssuggestionswas
measuredbyagreementfractionandswitchfraction.(B)Theappropriatenessofparticipants’relianceonAI’ssuggestions,
includingunder-reliance(theratiowhereparticipantsdidnotuseacorrectAIsuggestion)andover-reliance(theratiowhere
participantsusedanincorrectAIsuggestion).Theerrorbarsrepresent95%confidenceinterval.(*:𝑝<0.05,**:𝑝<0.01,***:𝑝<0.001)
 / H D U Q L Q J  & X U Y H V 6.3 RQ3:Howwillhumansengageinthe
   
deliberationprocesswhenworkingwith
   
 ' H O L E H U D W L Y H  $ , DeliberativeAI?
 ; $ ,
   
TogaindeeperinsightsintotheimpactofourDeliberativeAI,we
    analyzedhowparticipantsengagedwiththistechnologyduring
thedecision-makingprocess.
  
 5 R X Q G    5 R X Q G    5 R X Q G    5 R X Q G  
AsshowninFigure12(a),eachdecision-makinginstancetyp-
icallyinvolvedamedianof2.0roundsofconversationbetween
Figure9:Learningcurvemeasuredbydecisionaccuracyin
participantsandtheDeliberativeAI.Duringthesediscussions,par-
eachtaskround.Theerrorbarsrepresent95%confidence
ticipants’ viewpoints changed a median of 1.0 times, and they
interval.
encountered a median of 1.0 conflicting dimension with the AI
model(basedonourpilotstudy,wedefined“conflicting”bya15%
 3 H U F H S W L R Q V  R I  $ , opiniondifferencethreshold).It’sinterestingtonotethatalthough
  DeliberativeAI onlyhighlightedamedianof1conflictingdimen-
    ' H O L E H U D W L Y H  $ , sion,participantsdiscussedamedianof2.0dimensionswiththe
   ; $ ,
AIduringtheseinteractions,indicatingproactiveengagementin
  conversations,evenwhennotexplicitlyprompted.
Regarding the time spent in making a decision, as shown in
 
Figure12(b),participantstookthemosttimetomakeadecision
  inDeliberativeAI (amedianof236seconds),followedbyamedian
 3 H U F H L Y H G  3 H U F H L Y H G  3 H U F H L Y H G
of33secondsinXAI,andamedianof23secondsinHumanAlone,
 + H O S I X O Q H V V  7 U X V W Z R U W K L Q H V V  8 Q G H U V W D Q G L Q J
allpair-wisecomparisonsaresignificant(𝑝<0.001).Thesestatistics
indicatethathumansmake“quick”decisionswithtraditionalXAI.
Figure10:Participants’perceptionsoftheAIassistant.The
ComparedtowithoutAIassistance,participantsonlyspentanaver-
errorbarsrepresent95%confidenceinterval.(*:𝑝<0.05,**:
ageof10secondslongeroneachdecisionintheXAIcondition.This
𝑝<0.01,***:𝑝<0.001)
alsoechoespreviousfindingsthatpeoplewillmistakenlyregard
explanationsasamanifestationofAIcapabilities[11],resultingin
over-reliance.SinceinDeliberativeAI humansneedtospendmore
Effort,andPerceivedSystemComplexity.However,wefindpartic-
timeinthedeliberativediscussionprocess,itmightforcehumans
ipantsreportedsignificantlylowerSatisfactioninDeliberativeAI
tomake“slow”decisions(i.e.,invokemoreSystem2thinking[65]),
thaninHumanAlone.Combinedwiththequalitativeresults(Sec.
whichismoreappropriateforhigh-stakesdecision-making.
6.4),wespeculatethatthismaybebecauseDeliberativeAI exposes
Wealsoassessedhowparticipants’opinionswereinfluencedby
moreconflictsbetweenhumansandAIandtheyneedtocarryout
AI’sopinionsinboththeDeliberativeAI andXAI conditionsby
deliberationaroundtheseconflicts.Thiscaneasilyreducepeople’s
calculatingtheWeightofAdvice(WOA).Figure13showsaclear
satisfactioncomparedtosimplymakingadecision.Wealsoob-
contrast:theWOAintheDeliberativeAI conditionhadanotably
servedatrendthatDeliberativeAI ismorecomplexthanthetwo
lowermedian(0.085)comparedtoXAI (median:0.538,𝑝<0.001).
baselines.Thesefindingssuggestthatthereisatrade-offbetween
ThisindicatesthatparticipantsintheDeliberativeAI condition
encouragingusers’deliberativethinkingandoptimizingtheiruser
tendedtorelymoreontheirownpredictions.It’snoteworthythat
experience,inlinewithfindingsinpreviousstudies[17].
 \ F D U X F F $TowardsHuman-AIDeliberation:DesignandEvaluationofLLM-EmpoweredDeliberativeAIforAI-AssistedDecision-Making Conference’17,July2017,Washington,DC,USA
 8 V H U  ( [ S H U L H Q F H
 
   
 ' H O L E H U D W L Y H  $ ,
   ; $ ,
 + X P D Q  $ O R Q H
 
 
 
 ' H F L V L R Q  0 H Q W D O  ( I I R U W  & R P S O H [ L W \  6 D W L V I D F W L R Q
 & R Q I L G H Q F H  ' H P D Q G
Figure11:Effectsonuserexperience.Theerrorbarsrepresent95%confidenceinterval.(*:𝑝<0.05,**:𝑝<0.01,***:𝑝<0.001)
 ' H V F U L S W L Y H  6 W D W L V W L F V  R I  & R Q Y H U V D W L R Q V  L Q  ' H O L E H U D W L Y H  $ ,  7 L P H  6 S H Q W  3 H U  ' H F L V L R Q
  
       
   
      
   
 
       
 
 
 & R Q Y H U V D W L R Q  2 S L Q L R Q  ' L P H Q V L R Q  ' L P H Q V L R Q  ' H O L E H U D W L Y H  ; $ ,  + X P D Q
 5 R X Q G  & K D Q J H  7 L P H V  Z L W K  & R Q I O L F W V  ' L V F X V V H G  $ ,  $ O R Q H
(a) (b)
Figure12:Descriptivestatisticsofparticipants’decision-makingprocess.(a)DescriptivestatisticsofconversationsinDeliberative
AI.(b)Timespentperdecisioninthethreeconditions.
 2 S L Q L R Q  & K D Q J H V   : 2 $  (especiallyfortheopinionupdatingfeature).Wealsoseekvaluable
  insightstoenhancethefuturedesignofHuman-AIDeliberation.We
analyzedparticipants’open-endedfeedbackusingtheirconversa-
   
tionlogsassupport.WesummarizeourkeyfindingsinFigure14.
 
  6.4.1 PerceptionsoftheDeliberativeAIandthediscussion
process. Overall,participantsprovidedbothpositiveandnegative
feedbackonDeliberativeAI andthedeliberativediscussionpro-
 
 ' H O L E H U D W L Y H  $ ,  ; $ , cess.43outof48participantsthoughtthedeliberativediscussion
helpedthemmakemoreinformeddecisions.Specifically,discus-
Figure13:Thechangesinparticipants’opinionsmeasured sionwithAIhelphumans“identifyAI’sproblems”(21/48),“consider
byWeightofAdvice.(*:𝑝<0.05,**:𝑝<0.01,***:𝑝<0.001) differentaspects”(10/48),“reflectandrealizetheirmistakes”(15/48).
Forinstance,Participant1(Male,32)pointedoutissueswithAI’s
knowledge:
thelowerquartileforDeliberativeAI is0,implyingthatatleast
25% of participants did not alter their opinions after seeing AI "TheAIrelieswaytoomuchonGPAscoresbutunder-
suggestions.Thesefindingsalignwithparticipants’lowerreliance estimatestheroleofrecommendationletters.Itdid
onAIobservedinFigure8. notgivemeconvincingjustifications.Icannotrelytoo
muchontheAI’sopiniononthesetwodimensions."
6.4 RQ4:Howwillhumansperceivethe (P1,Male,32)
effectivenessoftheproposedHuman-AI
Participant19(Male,42)appreciatedhowthediscussionsinspired
Deliberationandwhatcanbeimprovedfor
self-reflection:
futureHuman-AIDeliberationdesign?
Inadditiontoquantitativemeasures,weaimtocomprehendpar- "TheAIcancauseyoutodoubtwhatyoubelieveto
ticipants’in-depthperceptionsregardingthehelpfulnessofthe besufficientforanopinion,especiallyaccordingto
proposedHuman-AIDeliberationandthefeatureofDeliberativeAI theinformation/datagiven."(P19,Male,42)
 U H E P X 1   V  G Q R F H 6Conference’17,July2017,Washington,DC,USA ShuaiMa,etal.
How do humans perceive the Deliberative AI and the How do humans perceive the AI updating its own Which parts and how should the current AI and
deliberative discussion process? views during the discussion? discussion process be improved?
Pros AI’s Update leads to better UX Improvements for AI
More informed decisions • Make humans feel like actually interacting with • AI needs a better understanding of what humans
• Help humans identify AI’s problems another person think and say
• Help humans consider different aspects • Make humans feel listened to and respected • AI needs to remember what humans said before
• Help humans reflect and realize their mistakes • Make the discussion engaging • AI should consider the problem / provide arguments
• Offer new knowledge, insights, and fresh perspectives • Make the decision process more collaborative and beyond statistics
• Help with fact-checking adaptive • AI should provide more in-depth probing and
• Help identify biases analyze each attribute’s implications
• Promote a balance between AI’s objective knowledge and People have mixed perception of how AI updates • AI should explain why its opinions get changed
human’s subjective opinions • The adjustment of AI opinions makes sense
• People are not sure how and why AI updated Improvements for the discussion process
Better interaction with AI • A little “pushover” / AI did not update much
• More conversational and human-like
• • E Hn eg lpa g hue mAI a i nn s h uu nm da en rs’s ta p ne dr s Ap Ie ac nti dv e its decisions Affect people’s perceptions of AI • • M Pro or ge r eco ssn ivc eis e disclosure of opinions and arguments
• Feel AI can take qualitative information into • Give humans more agency (e.g., AI justifies first or
Cons consideration asks humans what they want to discuss)
Limitations of the Deliberative AI • Feel AI is capable of learning • Improve the conversation generation speed
• Increase decision quality • Use charts to show statistical data
• AI relies too much on data instead of logic • Doubt the quality of AI’s original opinions
• AI considers little about humans’ reasoning
• AI cannot remember the historical discussion
• AI does not look at the big picture
• AI is still not transparent enough
Limitations of the discussion process
• Human agency
• Cognitive burden
• Conversation is not as deep as with humans
• Too long AI conversation
Figure14:Themainresultsofourthematicanalysisoftheopen-endedquestions.
Thesefindingsalignwiththecontentofthehuman-AIconversa- What’smore,15participantsthoughtthediscussion“promoted
tionswecollected.In32%oftheconversations,participantsex- abalancebetweenAI’sobjectiveknowledgeandhuman’ssubjective
pressed doubts or questions to AI, in 17% of the conversations, opinions”.Forexample,
participantsacknowledgedAI’sarguments,andin15%ofthecon-
"Itprovidesanopportunitytoconsidermultipleper-
versations,participantsengagedinreflectionandself-correction.
spectivesandstatisticaldata,whichcanleadtoamore
Besides,18participantsacknowledgedthatdiscussingwithAI
informedandbalanceddecision-makingprocess."(P2,
can“offernewknowledge,insights,andfreshperspectives”.Forex-
Male,42)
ample,P5(Male,45)said
"Ithinkthatreceivingthefeedbackwiththedatabe-
"ItprovidedsomeinformationthatIactuallydidnot hindtheAIisahelpfulvisualreminderofhowmuch
know(suchasthepercentile,howsimilarstatsim- above/below the average the applicant was. Being
pactedotherdecisionsinthepast,etc.),whichIthought abletorelyontheAIforthisandfocusingonmy
wereextremelyhelpful." ownopinionsthataremoresubjectivehelpedmeto
balance."(P48,Male,28)
Moreover,nineparticipantsexplicitlyacknowledgedthatdiscus-
sion“helpsthemidentifybiases”.Forexample, However,wealsoidentifiedlimitationsinthecurrentdiscussion
processbasedonparticipants’feedback.Regardingthediscussion’s
"ThereweretimeswhereitmademerealizetheAI
limitations,fiveparticipantsfelttheir“agencygetsreduced”asthe
probablyhadaninherentbiassoallinallIthinkit
AIpromptedthemtothinkotherthanpassivelywaitingfortheir
helpedtoactuallymakemepauseandreflect."(P35,
questions.Additionally,fourparticipantsfoundthedeliberative
Female,29)
discussion“mentallydemanding”andbelievedtheAI’sresponses
Thisobservationissubstantiatedbyanexaminationofparticipants’ wereoverlyverbose.Thesefindingsalignwiththeresultsofthe
conversationhistoriesduringthediscussionprocess.Remember effectsonparticipants’userexperience(seeSec.6.2.2).
thattheAImodelassignsapositivefeatureimportanceto[Country RegardingtheDeliberativeAI’slimitations,twocommoncon-
belongstotheUS]whileanegativefeatureimportancetofeature cernswerethatit“reliestooheavilyondataoverlogic”(mentioned
[CountrybelongstoAsia].Wearegratifiedtonotethatasubstan- by15participants)and“failstoconsiderhumanreasoning”(men-
tialportionofparticipants(15outof48)identifiedbiasesinAI’s tionedby10participants).Thisfeedbackalignswithouranalysis
opinions.Forinstance,P3(Male,42)questioned,“Whydoestheir ofparticipants’conversations,wherehumansintegratedpersonal
countrymatter?Theyarebeingpenalizedforbeingfromacertain experiencesandlogicintotheirdecision-making.Forinstance,they
country,whichcouldbeinterpretedasbeingracist.”Similarly,P17 consideredfactorssuchas“Businessapplicationsarehighlycompet-
(Female,60)inquired,“Couldyouexplainwhyyouseeanengineering itive,soahigherGPAisrequired.”(P17,Female,60),“AgoodSOP
majorandAsianoriginasnegatives?”Theseinsightfulconversa- representsthattheapplicanthasanin-depthunderstandingofthe
tionsindicatethatwithDeliberativeAI,participantscouldidentify projectandastrongwillingness.”(P32,Male,28),“Middle-ranking
theAImodel’sbiasesinthedecision-makingprocess. schoolsmaygivestudentshigherGPA,soaGPAof3.6maynothaveTowardsHuman-AIDeliberation:DesignandEvaluationofLLM-EmpoweredDeliberativeAIforAI-AssistedDecision-Making Conference’17,July2017,Washington,DC,USA
aparticularlypositiveimpact.”(P29,Male,50).Incontrast,theAI’s changedduringconversations”.Thistransparencywasseenas
responseslackedin-depthanalysisofthesehumanjustifications. essentialforbuildingtrustandunderstanding.
Furthermore,someparticipantsexpressedconcernsabouttheAI’s
Regarding the design of the human-AI discussion process, 8
inability to remember historical discussions (five), its failure to
participantssuggestedmakingtheconversation“moreconversa-
considerthebiggerpicture(three),anditslackoftransparency
tionalandhuman-like”,with11participantsfavoring“conciseAI
(three).
responses”.Additionally,2participantsrecommended“progressively
6.4.2 Perceptionsof DeliberativeAI’supdating. Participants disclosingAI’sarguments”,while3participantsdesiredmoreuser
generallyappreciatedthefeatureofdynamicalupdating.25outof agencyinleadingthediscussionprocess.Inaddition,3participants
48participantsfoundthattheAIupdates“improvedtheuserexperi- alsosuggestedimprovingthedialoguegenerationspeedandvisual
ence.”Theydescribedtheexperienceasmoreinteractive,akinto informationdisplay.
“interactingwitharealperson”(6participants),wheretheiropin- ThingstoNoteaboutInterpretingtheResults.Weexplored
ionswere“listenedtoandrespected”(19participants).Furthermore, thepossibleimpactofHuman-AIDeliberationondecision-making
thesedynamicupdatesmadethediscussionprocess“moreengag- fromdifferentaspects.However,wecautionreaderstoconsider
ing”(8participants)andtheoveralldecision-makingprocess“more theseresultsasexploratoryfindings.Sincewedidnotrecruitreal
collaborative”(5participants). membersofthegraduateadmissionscommitteetoparticipatein
However,perceptionsofhowAIupdateditsopinionsvaried. ourstudy,wedonotknowwhetherDeliberativeAI canhelpwith
While11participantsfeltthemagnitudeofAIupdateswastoo realgraduateadmissionsdecisions.Inaddition,thegeneralizability
sensible(e.g.,“theAIupdatedtoomuch”),13participantsexpressed oftheseresultshasyettobeverified.Inourstudy,DeliberativeAI
uncertaintyabout“whyandhowtheAIupdated.”Forinstance,one onlyhad50%accuracyontheselected“challenging”taskcases,so
participantmentioned, itisuncertainwhethersimilarfindingscanappearon“easy”cases
whereAIhashighperformance.Inaddition,duetothelengthof
"I’m not sure if the AI really changed its opinions
discussion,weonlyaskedparticipantstosolvefourtaskcaseswith
becauseofwhatIsaidorbecauseitwasprogrammed
DeliberativeAI,whichalsolimitsthegeneralizabilityoftheresults.
todosoinresponsetomyjudgments".(P2,Male,42)
Nonetheless,webelievetheseexploratoryfindingsarevaluable
Interestingly,someparticipantsbelievedthatAIchangeditsviews
inprovidinganinitialunderstandingofthepotentialofDelibera-
tooeasily,whileothersfeltitdidn’tcompromiseenough.Addition-
tiveAI andtheimpactitmayhaveondecision-making.Common
ally,AI’sopinionupdatesinfluencedparticipants’perceptionsof
issuesidentifiedinthisstudycanshedlightonfuturedesignsof
AI.Eightparticipantsbelievedthat“AIcouldtakequalitativeinfor-
DeliberativeAI.
mationintoaccount”,andfiveparticipantsthought“AIislearning
humanknowledgefromthediscussionprocess”,whichcould“improve
7 DISCUSSION
thequalityofdecision-making”(3participants).Threeparticipants
reportedthatthelackoftransparencyintheAIupdateprocess Inthispaper,weintroduceHuman-AIDeliberation,whichaimsto
madethem“doubtthequalityoftheopinionsgivenbytheAIatthe addresstwocommonchallengesinAI-assisteddecision-making.
beginning”.Therefore,althoughAIupdatesimitatethebehaviorof First,wetackletheissueofhumans’insufficientanalyticalthinking
deliberationbetweenhumans,inordertomakeAIupdatesmore whenarecommendationisdirectlypresented.Second,weaddress
meaningful,itisnecessarytoconsidertheperceptionsofdifferent theproblemoflimitedinteractionsupportforresolvinghuman-AI
usersandconductamoretargeteddesign. disagreements.Existinginterfacesonlyallowindividualstoaccept
orrejectAIsuggestionsasawhole,hinderingtheutilizationof
6.4.3 Opportunitiesforfutureimprovementsof Delibera-
human-AInuancedknowledgeandcollaborativeproblem-solving.
tiveAI. Participantsofferedinsightfulsuggestionsforenhancing
Ourexploratoryassessmentinthecontextofanillustrativetask
DeliberativeAI inthefuture.
revealsthatHuman-AIDeliberationhasthepotentialtoenhance
• DeeperUnderstandingofHumans:15participantsstressedthe decisionaccuracyandpromoteappropriaterelianceonAIrecom-
needforAIto“bettercomprehendhumans’thoughtsandargu- mendationscomparedtotraditionalexplainableAIassistants.Anal-
ments”,desiringmorenuancedandcontext-awarecommunica- ysisofquestionnaireratings,humanbehaviors,andopen-ended
tion. feedbackprovidesvaluableinsights.Wenowdelveintoourkey
• EnhancedMemory:8participantsemphasizedtheimportanceof findingsanddiscussdesignimplicationsandcriticallimitations.
AI“rememberingpreviousinteractionsformorepersonalizedand
coherentconversations”.
7.1 DeliberationasaNewParadigm
• HolisticProblemSolving:12participantsrecommendedthatAI
ComplementingExisting(X)AIAssistance
“thinkbeyondstatistics”and“provideargumentswithbroadercon-
siderations”,offeringmorecomprehensivesuggestions. TheproposedHuman-AIDeliberationaimsatengaginghumansin
• DeeperAnalysis:10participantsadvocatedforAItodelvedeeper thedeliberationprocessthroughconflict-orienteddiscussions.It
intodiscussions,“conductingmorethoroughprobingand“analyz- canserveasapowerfulsupplementtoexistingAIassistance.On
ingtheimplicationsbeyondthesuperficialmeaningofanattribute theonehand,DeliberativeAI stillplaystheroleofanassistantand
withinagivencontext”. itsunderlyingcomponentisbasedonexistingXAI.Althoughit
• MoreTransparency:8participantsexpressedthedesireformore willrefute,italwaysrespectshumanopinions.Peoplehavethe
transparencyfromAI,seekingexplanationsfor“whyAI’sopinions fullagencyasthefinaldecision-maker.Additionally,DeliberativeConference’17,July2017,Washington,DC,USA ShuaiMa,etal.
AI canbeseenasanenhancedversionofanAIassistantthaten- 7.3 Human-AIConflictResolvingIsTheKeyto
gagespeopleinanalyticalthinking.Someinteractiondesignof ImprovingCollaboration
DeliberativeAI alignswithpriorwork,suchasencouragingpartici-
Wecontendthatresolvingconflictsisinherentlymorebeneficialfor
pantstoformindependentopinionsbeforeseeingAIsuggestions
enhancingdecision-makingprocessesthanmerelyseekingconsen-
(e.g.,CognitiveForcingFunction[17])andutilizingAI-generated
sus.Ourmethodology,Human-AIDeliberation,emphasizestheres-
questionstostimulatecriticalthinking(e.g.,employingAI-framed
olutionofdisputesbetweenhumansandAI,adimensionpresently
questioning[27]).
overlookedinAI-assisteddecision-makingframeworks.Weargue
Ontheotherhand,Human-AIDeliberationmakesimportantcon-
thatconflictservesasacrucialelementinhuman-AIcollaboration,
tributionstosteppingoutsidetheboundariesoftraditionalAI/XAI
unveilinginherentflawsandbiases.Thisconflict-centricapproach
forAI-assisteddecision-making.Peoplearenolongerjustrecipients
yieldsmultipleadvantages:itenhancestheaccuracyofdecision-
ofAIsuggestionsandexplanations,butneedtoactivelyparticipate
makingbymitigatingover-relianceonAI,fostersintrospection,
indiscussionsandexplaintheirownideas,whichcontributesto
andfacilitatesthereconciliationofdifferingopinionswithAIrec-
mutualcommunicationandtransparencybetweenhumansand
ommendations.Furthermore,byprioritizingconflict,humanscan
AI.Thiscommunicationcanleadtomoreinformedandmature
betterrecognizebiasesinAIinterpretations,therebyadvancing
decisionsasdeliberationsprogress.
fairnessindecision-makingprocesses[59,70].
WesuggestthatthedesignoffutureAIassistantsshouldnot
Nevertheless, an emphasis on conflict resolution—despite its
only focus on the design of the AI side (such as improving the
apparent benefits—may diminish user satisfaction. Engaging in
performanceofAIorimprovingthepresentationofAIauxiliary
deliberation with AI, particularly around divergent viewpoints,
information),butalsodrawonhuman-to-humandecision-making
necessitatesthatindividualscriticallyevaluatetheirownperspec-
methodsandtheoriestoexploredesignopportunities,especially
tives and articulate their arguments. This process amplifies the
fromtheperspectiveofcommunicationbetweenhumansandAI.
perception of "dissenting voices," potentially compromising the
userexperience.Hence,weadvocateforabalancedapproachinfu-
turedesignparadigms:onethatcentersonconflictresolutionwhile
7.2 ReducingHumanOver-Relianceby simultaneouslyconsideringstrategiestoenhanceuserengagement
ExposingAIMistakes withconflictswithoutdetractingfromtheoverallexperience.
Human-AIDeliberationsignificantlydiminishesparticipants’ten-
dencytoover-relyonincorrectAIsuggestions.Apivotalelementis
7.4 ObstaclestoDiscussion:HumansandAI
theadoptionofcognitiveforcingtheory,asproposedbyBuccincaet
ThinkDifferently
al.[17],whichmotivatesindividualstoformulatetheiropinionsbe-
forebeingexposedtoAIrecommendations.Thismethodeffectively HumansUseHeuristicsandLogic,whileAIReliesonData:
counterstheanchoringbias—theinitialinfluenceofAI’serroneous CombiningLLMandDS-ModelempowersDeliberativeAI indy-
predictionsonjudgment—therebyencouragingmoreanalytical, namicdiscussionswithhumans.However,AI’sdata-centricap-
System2thinking[65].Notably,ourExplainableAI(XAI)baseline proachclasheswithhumandecision-making,whichintegratesper-
alsorequiresparticipantstoarticulatetheirperspectivesindepen- sonalunderstandingandexperiences[47],logic[38],heuristics[33],
dentlybeforereceivingAIcounselandexplanations.Despitethis andcreativity[114,115].Toaddressthis,weproposeDS-Model
stringentbaseline,ourDeliberativeAI approachshowsenhanced guidingLLMsfordata-relateddiscussionsandLLMsautonomously
effectivenessinreducingover-reliance.Thus,theobserveddecrease handlingdata-irrelevantmattersbasedonDS-Model’spredictions.
inover-reliancewithinourDeliberativeAI extendsbeyondmere Whileeffective,thisapproachfaceslimitationsinengagingusers
cognitiveforcing,attributedalsotothepromotionofthoughtful withstrongsubjectiveperspectivesandreasoning[85].
deliberationbetweenindividualsandAIamidstcontrastingview- ExistingExplanationMethodsAreInsufficienttoEnable
points. Discussion:CurrentXAImethods,likelocalfeatureimportance
WithintheDeliberativeAI,asparticipantsnavigatethroughcon- [83],inadequatelyclarifyspecificfeaturecontributions.Oursolu-
flictingopinionswithAI,theybecomeincreasinglycognizantofAI tion,basedontrainingdata,providesdata-relatedinsights,suchas
limitations,furthermitigatingover-reliance.Furthermore,31%of datadistributionandvaluecomparisons,toempowerAIinfeature-
conversationsinvolveparticipantsexpressingskepticismtowards leveldiscussions.However,challengesarise.First,patternsinferred
theAI’sopinionsandlogic.However,thedeclineinover-reliance fromdatamaynotpreciselyalignwithAI’sexplanations.Second,
is not due to people blindly doubting AI. Notably, our strategy usersoftenrelyonvariousformsofreasoningbeyonddata,in-
significantlyreducesover-relianceonAIwithoutincreasingunder- cludingsubjectiveexperiences[33,47].Thisfindingisalignedwith
reliance.Thisindicatesthatthroughdeliberativediscourse,par- Milleretal.’swork[99],"probabilitiesarenotasimportantascausal
ticipants critically assess AI’s opinions on a case-by-case basis, links."Hence,offeringdata-driveninsightsasmeta-explanations
integratingaccurateAIinsightswhileamendingtheirownassess- maynotfullyalignwithusers’thinkingstylesorreplicatehuman-
mentsasnecessaryandidentifyinginstanceswhereAIjudgments likeconversations.
maybeerroneous.Consequently,werecommendthatdesignersof Therefore,futurehuman-AIdeliberationdesignsshouldtryto
AI-assisteddecision-makingsystemsprioritizetransparencyand copewithhumans’intuitionandcognitiveprocessesanddesign
explicitlyhighlightAI’spotentialerrors,ratherthanmerelyhint- human-compatible AI explanations to empower more effective
ingthat“AImaymakeerrors”. human-AIdiscussions.TowardsHuman-AIDeliberation:DesignandEvaluationofLLM-EmpoweredDeliberativeAIforAI-AssistedDecision-Making Conference’17,July2017,Washington,DC,USA
7.5 EthicalConcernsinDeliberativeAIDesign canrangefromasimplemachinelearningclassifiertoacomplex
ResponsiblyUtilizingLLMsforAssistingHumanDecision- neuralnetworkmodelorevenanotherspecificlargemodel.
Making.LLMsareadvancingrapidlybutfaceacriticalissueknown
as“hallucination”,wheretheygenerateseeminglycrediblebutfalse
7.7 LimitationsandFutureWork
information[64].Engagingindiscussionswithuserssolelybased
onLLM-generatedopinions,withoutproperfine-tuningoftask Thestudydesignofthispaperhasseverallimitations.First,the
data,ishighlyirresponsible.Evenwithfine-tuning,unpredictable illustrativetask(collegeadmissiondecision)wechosedisconnects
responsescanoccur.Toaddressthis,weadvocateforaresponsible withrealcollegeadmission.Ontheonehand,limitedbytheavail-
approachthatcombinesLLMsandDS-Model.DS-Model’soutput ablepublicdataset,thedatasetweuseddoesnotcontaintheraw
tightlycontrolsLLMs’responses,withLLMsprimarilyactingas textsofsomeimportantdimensions,suchaspurposestatements,di-
acommunicationbridgebetweenusersandDS-Model.Whilethis versitystatements,recommendationletters,etc.Thus,inourstudy,
approach restricts LLMs’ flexibility to some extent, it enhances participantscouldonlydiscusstheratingsonthemratherthanwhat
security and controllability. However, it’s essential to note that informationisincludedinthem.Furthermore,theparticipantswe
evenwithDS-ModelandtrainingdataguidingLLMs’responses, recruitedwerenotmembersoftheactualadmissionscommittee.
thepotentialforerrorinformationremains.Therefore,researchers Althoughwerequireparticipantstohaveatleastamaster’sdegree
planningtoemployLLMsindecision-makingshouldexercisecau- andgraduateapplicationexperience,thereisstillaconsiderable
tionandtransparency.It’scrucialtoinformusersaboutthepos- gap in expertise. Therefore, the graduate admission task is just
sibilityofinaccurateinformationandpotentialpitfallsassociated anillustrativetasktoexploretheinstantiationandpotentialof
withLLM-generatedresponses. theproposedHuman-AIDeliberationframework.Weneedfuture
ConcernsRegardingAIUpdating.Researchonhuman-AIdis- studiestotrulyexplorewhetherandwhyDeliberativeAI yields
cussionshighlightsadesireforAItoactivelyengagewithhuman improvementinreal-worldcollegeadmissiondecision-making.
opinions[143].Toaddressthis,we’veimplementedanAIopin- Second,thenumberofdecisiontasksamplesusedinourstudyis
ionupdatemechanism,allowingAItoadaptitsstancebasedon relativelylimited.Wetriedtoinclude8or10decisiontasksamples
userarguments’rationalityandpredictionuncertainty.Although inourpilotstudy,whichresultedinparticipantstakingmorethan
usersgenerallyappreciatetheAI’sresponsivenessandthefeel- one hour to complete all decision tasks. In addition, the users’
ingofbeingheardandrespected,ethicalconcernshaveemerged, engagementdroppedsubstantiallyaftercompletingthreeorfour
particularlyregardingaccountability.Onepivotalquestionarises: tasks,andtheysimplydraggedthesliderontheinterfacetogive
WhoshouldbeheldaccountableiftheAIinitiallyhadthecorrect theiropinionswithoutdiscussingtheconflictingpointswithAI.
predictionbutupdatedtoanincorrectoneafterengagingindis- We infer that long tasks lead to user fatigue, which will affect
cussionswiththehuman?Furthermore,theAI’sabilitytoadapt the validity of the study. Therefore, due to concerns about the
itsviewpointsmaygivehumanstheimpressionoflearningand lengthofthestudy,weonlyselectedfourtasksamples,whichto
progress,despitetheunderlyingAImodelremainingunchanged. someextentlimitsthegeneralizabilityandsignificancereliability
Thiscanimpactuserexpectationsandpotentiallyleadtoanoveres- oftheexperimentalresults.Futureworkneedstotesttheeffects
timationofAIcapability.WhiletheAI’scapacitytoupdateopinions ofHuman-AIDeliberationthroughalong-termstudysothatmore
ispromising,it’scrucialtoremainvigilantaboutpotentialadverse deliberativedecisiondatacanbecollected.
outcomesduringthedesignphase.Mostimportantly,futuredesigns Third,theAIinourstudyisoflowperformance(50%accuracy),
shouldprioritizetransparencyintheAIupdatingmechanismto notaconventionalAIthatperformsbetterthanhumans.Wemade
helpusersfullycomprehendtheprinciplesgoverningAIupdates thisdesignchoicebecauseHuman-AIDeliberationismoresuitable
andeffectivelymanagetheirexpectations. fordealingwithtaskcasesthatarechallengingforbothhumansand
AI.However,weacknowledgethatthedecision-makingdynamics
assistedbyAIwithdifferentperformancescanbedifferent.Thus,
all our results are based on the premise that AI’s performance
7.6 ApplicabilityandGeneralizability
isrelativelylowandonparwithhumans’independentdecision-
Althoughthehuman-AIdeliberationframeworkweintroducedis makingperformance.Therefore,wecannotsaywhethersomeof
potentiallyapplicableandcantheoreticallybeadaptedtovarious thepositiveoutcomesofDeliberativeAI (suchasareductionin
decision-makingscenarios,deliberationmaynotbesuitablefor people’soverdependence)willpersistwhentheAIperformsvery
alltasks.First,thedeliberativeprocessrequiresadditionaltime well.Futureworkcanfurtherconsiderthevariationofhumanand
andcognitiveresources,makingitlesssuitableforrepetitive,low- AIdecisionperformance.
stakesdecisionssuchascontentmoderation[71].Instead,itmaybe Finally,ourstudyshowsthepotentialofDeliberativeAI com-
morebeneficialinhigh-stakesdecision-makingenvironments,such paredtoXAI,butitisstillunclearwhichcomponentsofDeliberative
ashealthcare[79],financialinvestments[53],andcriminaljustice AI contributetothebenefits.WeacknowledgethatDeliberative
[26], especially when dealing with complex or edge cases. Sec- AI hasmorefeaturesthantheXAI condition.Forexample,De-
ondly,Human-AIDeliberationisbettersuitedtohandlechallenging liberativeAI canpresentdistributioninformationofthetraining
taskcasesthataredifficultforbothhumansandAI.Furthermore, data(e.g.,percentiles)intheconversation(asevidenceofAIinthe
ourproposedmethodofcombininglargelanguagemodels(LLMs) Human-AIDeliberationframework),whichXAIdoesnothave.This
withdomain-specific(DS)modelscanbeadaptedtootherdecision- isbecausewechosetoapplythemostcommonlyusedXAIdisplay
makingscenarios.ItdoesnotlimittheformoftheDSmodel,which methodasthebaseline.TheseXAIsystemstypicallyonlyprovideConference’17,July2017,Washington,DC,USA ShuaiMa,etal.
suggestionsandexplanationswithoutprovidingdatadistribution [13] LauraWBlack,StephanieBurkhalter,etal.2010.Methodsforanalyzingand
information.Inaddition,DeliberativeAIconsistsofmultiplecritical measuringgroupdeliberation.InSourcebookforpoliticalcommunicationresearch.
Routledge,345–367.
components.Afutureablationstudycouldhelpinvestigatetherole
[14] AngieBoggust,BenjaminHoover,ArvindSatyanarayan,andHendrikStrobelt.
andimportanceofeachcomponentforasystematiccomparison. 2022. Sharedinterest:Measuringhuman-aialignmenttoidentifyrecurring
patternsinmodelbehavior.InProceedingsofthe2022CHIConferenceonHuman
FactorsinComputingSystems.1–17.
8 CONCLUSION
[15] SilviaBonaccioandReeshadSDalal.2006.Advicetakinganddecision-making:
In this paper, we introduce the framework of Human-AI Delib- Anintegrativeliteraturereview,andimplicationsfortheorganizationalsciences.
Organizationalbehaviorandhumandecisionprocesses101,2(2006),127–151.
eration,asanewparadigmofAIassistancefordecision-making. [16] ZanaBuçinca,PhoebeLin,KrzysztofZGajos,andElenaLGlassman.2020.Proxy
Human-AIDeliberationencouragestheexternalizationofthoughts, tasksandsubjectivemeasurescanbemisleadinginevaluatingexplainableAI
systems.InProceedingsofthe25thinternationalconferenceonintelligentuser
facilitatesinteractivedeliberationbetweenhumansandAI,and
interfaces.454–464.
allowsfordynamicupdatesofdecisions.Toenablethedeliberation, [17] ZanaBuçinca,MajaBarbaraMalaya,andKrzysztofZGajos.2021.Totrustorto
wepresentanovelAIassistantcalledDeliberativeAI,whichcan think:cognitiveforcingfunctionscanreduceoverrelianceonAIinAI-assisted
decision-making. ProceedingsoftheACMonHuman-ComputerInteraction5,
identifydifferencesinviewpoints,engageincomprehensivedelib-
CSCW1(2021),1–21.
eration,andadaptitssuggestionsduringdiscussions.Weapplythis [18] André Bächtiger, Marlène Gerber, and Eléonore Fournier-Tombs. 2022.
frameworktoanillustrativetask(graduateadmissionsdecisions) 83Discourse Quality Index. In Research Methods in Deliberative Democ-
racy.OxfordUniversityPress. https://doi.org/10.1093/oso/9780192848925.
andconductanexploratorystudytoassessitspotentialimpacton 003.0006arXiv:https://academic.oup.com/book/0/chapter/378695331/chapter-
decision-makingprocesses,outcomes,userperceptions,andexpe- pdf/49943298/oso-9780192848925-chapter-6.pdf
[19] ÁngelAlexanderCabrera,AdamPerer,andJasonI.Hong.2023. Improving
riences.ResultsindicatethepotentialofDeliberativeAI toimprove
Human-AICollaborationWithDescriptionsofAIBehavior.Proc.ACMHum.-
decisionaccuracyandpromotemoreappropriatehumanreliance Comput.Interact.7,CSCW1,Article136(apr2023),21pages. https://doi.org/10.
onAI.Additionally,weanalyzeparticipants’behaviorsandopen- 1145/3579612
[20] CarrieJCai,EmilyReif,NarayanHegde,JasonHipp,BeenKim,DanielSmilkov,
endedfeedbacktogaindeeperinsightsintohowusersuseand
MartinWattenberg,FernandaViegas,GregSCorrado,MartinCStumpe,etal.
perceiveDeliberativeAI,uncoveringareasforimprovement.Lastly, 2019. Human-centeredtoolsforcopingwithimperfectalgorithmsduring
weofferdesignimplicationsbasedonourfindings,highlighting medicaldecision-making.InProceedingsofthe2019chiconferenceonhuman
factorsincomputingsystems.1–14.
thepotentialofHuman-AIDeliberationasavaluablesupplementto [21] CarrieJCai,SamanthaWinter,DavidSteiner,LaurenWilcox,andMichaelTerry.
currentAI-assisteddecision-making. 2019."HelloAI":uncoveringtheonboardingneedsofmedicalpractitionersfor
human-AIcollaborativedecision-making.ProceedingsoftheACMonHuman-
computerInteraction3,CSCW(2019),1–24.
REFERENCES
[22] NancyCartwrightandJacobStegenga.2011.Atheoryofevidenceforevidence-
[1] AshrafAbdul,ChristianvonderWeth,MohanKankanhalli,andBrianYLim. basedpolicy.(2011).
2020.COGAM:measuringandmoderatingcognitiveloadinmachinelearning [23] SimoneChambers.2005.Measuringpublicity’seffect:Reconcilingempirical
modelexplanations.InProceedingsofthe2020CHIConferenceonHumanFactors researchandnormativetheory.ActaPolitica40(2005),255–266.
inComputingSystems.1–14. [24] QuanzeChen,JonathanBragg,LydiaBChilton,andDanSWeld.2019.Cicero:
[2] DavidAlvarez-Melis,HarmanpreetKaur,HDIII,HannaMWallach,andJen- Multi-turn,contextualargumentationforaccuratecrowdsourcing.InProceed-
niferWortmanVaughan.2021.AHuman-CenteredInterpretabilityFramework ingsofthe2019chiconferenceonhumanfactorsincomputingsystems.1–14.
BasedonWeightofEvidence.arXiv(2021). [25] Hao-FeiCheng,RuotongWang,ZhengZhang,FionaO’Connell,TerranceGray,
[3] AndréBächtigerandJohnParkinson.2019.Mappingandmeasuringdeliberation: FMaxwellHarper,andHaiyiZhu.2019.Explainingdecision-makingalgorithms
Towardsanewdeliberativequality.OxfordUniversityPress. throughUI:Strategiestohelpnon-expertstakeholders.InProceedingsofthe
[4] AndréBächtiger,SusumuShikano,SerainaPedrini,andMirjamRyser.2009. 2019chiconferenceonhumanfactorsincomputingsystems.1–12.
Measuringdeliberation2.0:standards,discoursetypes,andsequenzialization. [26] Chun-WeiChiang,ZhuoranLu,ZhuoyanLi,andMingYin.2023.AreTwoHeads
InECPRGeneralConference.Potsdam,5–12. BetterThanOneinAI-AssistedDecisionMaking?ComparingtheBehaviorand
[5] GaganBansal,BesmiraNushi,EceKamar,EricHorvitz,andDanielSWeld.2020. PerformanceofGroupsandIndividualsinHuman-AICollaborativeRecidivism
Optimizingaiforteamwork.arXivpreprintarXiv:2004.13102(2020). RiskAssessment.InProceedingsofthe2023CHIConferenceonHumanFactorsin
[6] GaganBansal,BesmiraNushi,EceKamar,WalterSLasecki,DanielSWeld,and ComputingSystems.1–18.
EricHorvitz.2019.Beyondaccuracy:Theroleofmentalmodelsinhuman-AI [27] ValdemarDanry,PatPataranutaporn,YaoliMao,andPattieMaes.2023.Don’t
teamperformance.InProceedingsoftheAAAIConferenceonHumanComputation JustTellMe,AskMe:AISystemsthatIntelligentlyFrameExplanationsasQues-
andCrowdsourcing,Vol.7.2–11. tionsImproveHumanLogicalDiscernmentAccuracyoverCausalAIexplana-
[7] GaganBansal,BesmiraNushi,EceKamar,DanielSWeld,WalterSLasecki,and tions.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputing
EricHorvitz.2019.Updatesinhuman-aiteams:Understandingandaddressing Systems.1–13.
theperformance/compatibilitytradeoff.InProceedingsoftheAAAIConference [28] JeffreyDastin.2018.AmazonscrapssecretAIrecruitingtoolthatshowedbias
onArtificialIntelligence,Vol.33.2429–2437. againstwomen.InEthicsofDataandAnalytics.AuerbachPublications,296–299.
[8] GaganBansal,TongshuangWu,JoyceZhou,RaymondFok,BesmiraNushi,Ece [29] DennisJDevine,LauraDClayton,BenjaminBDunford,RasmySeying,and
Kamar,MarcoTulioRibeiro,andDanielWeld.2021.Doesthewholeexceedits JenniferPryce.2001.Jurydecisionmaking:45yearsofempiricalresearchon
parts?theeffectofaiexplanationsoncomplementaryteamperformance.In deliberatinggroups.Psychology,publicpolicy,andlaw7,3(2001),622.
Proceedingsofthe2021CHIConferenceonHumanFactorsinComputingSystems. [30] ApDijksterhuis,MaartenWBos,LoranFNordgren,andRickBVanBaaren.
1–16. 2006.Onmakingtherightchoice:Thedeliberation-without-attentioneffect.
[9] JasonBarabas.2004.Howdeliberationaffectspolicyopinions.Americanpolitical Science311,5763(2006),1005–1007.
sciencereview98,4(2004),687–701. [31] StevenEDilsizianandEliotLSiegel.2014.Artificialintelligenceinmedicine
[10] DonaldJBaumann,JohnDFluke,LenDalgleish,andHomerKern.2014.The andcardiacimaging:harnessingbigdataandadvancedcomputingtoprovide
decision-makingecology.Fromevidencetooutcomesinchildwelfare:Aninter- personalizedmedicaldiagnosisandtreatment.Currentcardiologyreports16,1
nationalreader(2014),24–40. (2014),1–8.
[11] AstridBertrand,RafikBelloum,JamesREagan,andWinstonMaxwell.2022. [32] JonathanDodge,QVeraLiao,YunfengZhang,RachelKEBellamy,andCasey
HowCognitiveBiasesAffectXAI-assistedDecision-making:ASystematicRe- Dugan.2019. Explainingmodels:anempiricalstudyofhowexplanations
view.InProceedingsofthe2022AAAI/ACMConferenceonAI,Ethics,andSociety. impactfairnessjudgment.InProceedingsofthe24thinternationalconferenceon
78–91. intelligentuserinterfaces.275–285.
[12] ReubenBinns,MaxVanKleek,MichaelVeale,UlrikLyngs,JunZhao,andNigel [33] CharlesADoswell.2004. Weatherforecastingbyhumans—Heuristicsand
Shadbolt.2018.’It’sReducingaHumanBeingtoaPercentage’Perceptionsof decisionmaking.WeatherandForecasting19,6(2004),1115–1126.
JusticeinAlgorithmicDecisions.InProceedingsofthe2018Chiconferenceon [34] RyanDrapeau,LydiaChilton,JonathanBragg,andDanielWeld.2016.Microtalk:
humanfactorsincomputingsystems.1–14. Usingargumentationtoimprovecrowdsourcingaccuracy.InProceedingsofthe
AAAIConferenceonHumanComputationandCrowdsourcing,Vol.4.32–41.TowardsHuman-AIDeliberation:DesignandEvaluationofLLM-EmpoweredDeliberativeAIforAI-AssistedDecision-Making Conference’17,July2017,Washington,DC,USA
[35] JuliaDresselandHanyFarid.2018.Theaccuracy,fairness,andlimitsofpredict- AMAjournalofethics21,10(2019),913–919.
ingrecidivism.Scienceadvances4,1(2018),eaao5580. [63] LawrenceRJacobs,FayLomaxCook,andMichaelXDelliCarpini.2009.Talking
[36] JessicaMariaEchterhoff,MatinYarmand,andJulianMcAuley.2022. AI- together:PublicdeliberationandpoliticalparticipationinAmerica.Universityof
ModeratedDecision-Making:CapturingandBalancingAnchoringBiasinSe- ChicagoPress.
quentialDecisionTasks.InCHIConferenceonHumanFactorsinComputing [64] ZiweiJi,NayeonLee,RitaFrieske,TiezhengYu,DanSu,YanXu,EtsukoIshii,
Systems.1–9. YeJinBang,AndreaMadotto,andPascaleFung.2023.Surveyofhallucination
[37] FranzEisenfuhr.2011.Decisionmaking. innaturallanguagegeneration.Comput.Surveys55,12(2023),1–38.
[38] JonathanStBTEvans.2002.Logicandhumanreasoning:anassessmentofthe [65] DanielKahneman.2011.Thinking,fastandslow.Macmillan.
deductionparadigm.Psychologicalbulletin128,6(2002),978. [66] RobertAKaufmanandDavidKirsh.2022.CognitiveDifferencesinHumanand
[39] MetaFundamentalAIResearchDiplomacyTeam(FAIR)†,AntonBakhtin,Noam AIExplanation.InProceedingsoftheAnnualMeetingoftheCognitiveScience
Brown,EmilyDinan,GabrieleFarina,ColinFlaherty,DanielFried,AndrewGoff, Society,Vol.44.
JonathanGray,HengyuanHu,etal.2022. Human-levelplayinthegameof [67] HarmanpreetKaur,HarshaNori,SamuelJenkins,RichCaruana,HannaWallach,
Diplomacybycombininglanguagemodelswithstrategicreasoning. Science andJenniferWortmanVaughan.2020. Interpretinginterpretability:under-
378,6624(2022),1067–1074. standingdatascientists’useofinterpretabilitytoolsformachinelearning.In
[40] JennyFanandAmyXZhang.2020.Digitaljuries:Acivics-orientedapproachto Proceedingsofthe2020CHIconferenceonhumanfactorsincomputingsystems.
platformgovernance.InProceedingsofthe2020CHIconferenceonhumanfactors 1–14.
incomputingsystems.1–14. [68] AmirEKhandani,AdlarJKim,andAndrewWLo.2010.Consumercredit-risk
[41] FranzFaul,EdgarErdfelder,AxelBuchner,andAlbert-GeorgLang.2009.Statis- modelsviamachine-learningalgorithms.JournalofBanking&Finance34,11
ticalpoweranalysesusingG*Power3.1:Testsforcorrelationandregression (2010),2767–2787.
analyses.Behaviorresearchmethods41,4(2009),1149–1160. [69] JánosKramár,TomEccles,IanGemp,AndreaTacchetti,KevinRMcKee,Mateusz
[42] JamesSFishkin.2018.Democracywhenthepeoplearethinking:Revitalizingour Malinowski,ThoreGraepel,andYoramBachrach.2022.Negotiationandhonesty
politicsthroughpublicdeliberation.OxfordUniversityPress. inartificialintelligencemethodsfortheboardgameofDiplomacy. Nature
[43] KrzysztofZGajosandLenaMamykina.2022.DoPeopleEngageCognitively Communications13,1(2022),7214.
withAI?ImpactofAIAssistanceonIncidentalLearning.In27thInternational [70] GeoffreyPKramer,NorbertLKerr,andJohnSCarroll.1990.Pretrialpublicity,
ConferenceonIntelligentUserInterfaces.794–806. judicialremedies,andjurybias.Lawandhumanbehavior14,5(1990),409–438.
[44] FrancisGalton.1907.Voxpopuli.Nature75,1949(1907),450–451. [71] VivianLai,SamuelCarton,RajatBhatnagar,QVeraLiao,YunfengZhang,and
[45] JingGao,FengTian,JunjunFan,DakuoWang,XiangminFan,YichengZhu, ChenhaoTan.2022. Human-AICollaborationviaConditionalDelegation:A
ShuaiMa,JinHuang,andHonganWang.2018. Implicitdetectionofmotor CaseStudyofContentModeration.InCHIConferenceonHumanFactorsin
impairmentinParkinson’sdiseasefromeverydaysmartphoneinteractions.In ComputingSystems.1–18.
ExtendedAbstractsofthe2018CHIConferenceonHumanFactorsinComputing [72] VivianLai,ChachaChen,QVeraLiao,AlisonSmith-Renner,andChenhaoTan.
Systems.1–6. 2021.TowardsaScienceofHuman-AIDecisionMaking:ASurveyofEmpirical
[46] BhavyaGhai,QVeraLiao,YunfengZhang,RachelBellamy,andKlausMueller. Studies.arXivpreprintarXiv:2112.11471(2021).
2021.Explainableactivelearning(xal)towardaiexplanationsasinterfacesfor [73] VivianLaiandChenhaoTan.2019.Onhumanpredictionswithexplanationsand
machineteachers.ProceedingsoftheACMonHuman-ComputerInteraction4, predictionsofmachinelearningmodels:Acasestudyondeceptiondetection.In
CSCW3(2021),1–28. Proceedingsoftheconferenceonfairness,accountability,andtransparency.29–38.
[47] JohnyGhattas,PninaSoffer,andMorPeleg.2014.Improvingbusinessprocess [74] HélèneLandemore.2012.Democraticreason:Politics,collectiveintelligence,and
decisionmakingbasedonpastexperience.DecisionSupportSystems59(2014), theruleofthemany.PrincetonUniversityPress.
93–107. [75] HélèneLandemoreandScottEPage.2015. Deliberationanddisagreement:
[48] SoumyaGhosh,QVeraLiao,KarthikeyanNatesanRamamurthy,JiriNavratil, Problemsolving,prediction,andpositivedissensus. Politics,philosophy&
PrasannaSattigeri,KushRVarshney,andYunfengZhang.2021.Uncertainty economics14,3(2015),229–254.
Quantification360:AHolisticToolkitforQuantifyingandCommunicatingthe [76] JamesRLarson,PennieGFoster-Fishman,andChristopherBKeys.1994.Dis-
UncertaintyofAI.arXivpreprintarXiv:2106.01410(2021). cussionofsharedandunsharedinformationindecision-makinggroups.Journal
[49] FrancescaGinoandDonAMoore.2007. Effectsoftaskdifficultyonuseof ofpersonalityandsocialpsychology67,3(1994),446.
advice.JournalofBehavioralDecisionMaking20,1(2007),21–35. [77] BettinaLaugwitz,TheoHeld,andMartinSchrepp.2008. Constructionand
[50] IsidoreJacobGood.1950.ProbabilityandtheWeighingofEvidence.(1950). evaluationofauserexperiencequestionnaire.InSymposiumoftheAustrian
[51] DavidGough.2007.Weightofevidence:aframeworkfortheappraisalofthe HCIandusabilityengineeringgroup.Springer,63–76.
qualityandrelevanceofevidence. Researchpapersineducation22,2(2007), [78] JohnDLeeandKatrinaASee.2004.Trustinautomation:Designingforappro-
213–228. priatereliance.Humanfactors46,1(2004),50–80.
[52] DiegoGracia.2003.Ethicalcasedeliberationanddecisionmaking.Medicine, [79] MinHunLee,DanielPSiewiorek,AsimSmailagic,AlexandreBernardino,and
HealthCareandPhilosophy6(2003),227–233. SergiBermúdeziBadia.2021.AHuman-AICollaborativeApproachforClinical
[53] BenGreenandYilingChen.2019.Theprinciplesandlimitsofalgorithm-in-the- DecisionMakingonRehabilitationAssessment.InProceedingsofthe2021CHI
loopdecisionmaking.ProceedingsoftheACMonHuman-ComputerInteraction ConferenceonHumanFactorsinComputingSystems.1–14.
3,CSCW(2019),1–24. [80] Sung-ChulLee,JaeyoonSong,Eun-YoungKo,SeonghoPark,JiheeKim,and
[54] JürgenHabermas.2005. Concludingcommentsonempiricalapproachesto JuhoKim.2020. Solutionchat:Real-timemoderatorsupportforchat-based
deliberativepolitics.Actapolitica40(2005),384–392. structureddiscussion.InProceedingsofthe2020CHIConferenceonHuman
[55] RobertHarris.1997. EvaluatingInternetresearchsources. Virtualsalt17,1 FactorsinComputingSystems.1–12.
(1997),1–17. [81] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
[56] SandraGHart.2006. NASA-taskloadindex(NASA-TLX);20yearslater.In Karpukhin,NamanGoyal,HeinrichKüttler,MikeLewis,Wen-tauYih,TimRock-
Proceedingsofthehumanfactorsandergonomicssocietyannualmeeting,Vol.50. täschel,etal.2020.Retrieval-augmentedgenerationforknowledge-intensivenlp
SagepublicationsSageCA:LosAngeles,CA,904–908. tasks.AdvancesinNeuralInformationProcessingSystems33(2020),9459–9474.
[57] GaoleHe,LucieKuiper,andUjwalGadiraju.2023.KnowingAboutKnowing:An [82] QVeraLiao,DanielGruen,andSarahMiller.2020.QuestioningtheAI:informing
IllusionofHumanCompetenceCanHinderAppropriateRelianceonAISystems. designpracticesforexplainableAIuserexperiences.InProceedingsofthe2020
InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems. CHIConferenceonHumanFactorsinComputingSystems.1–15.
1–18. [83] QVeraLiaoandKushRVarshney.2021.Human-CenteredExplainableAI(XAI):
[58] RandyYHirokawa.1985.Discussionproceduresanddecision-makingperfor- FromAlgorithmstoUserExperiences.arXivpreprintarXiv:2110.10790(2021).
mance:Atestofafunctionalperspective.HumanCommunicationResearch12, [84] HanLiu,VivianLai,andChenhaoTan.2021.Understandingtheeffectofout-
2(1985),203–224. of-distributionexamplesandinteractiveexplanationsonhuman-aidecision
[59] GuyHochman,ShaharAyal,andDanAriely.2015.Fairnessrequiresdeliberation: making. ProceedingsoftheACMonHuman-ComputerInteraction5,CSCW2
Theprimacyofeconomicoversocialconsiderations.Frontiersinpsychology6 (2021),1–45.
(2015),747. [85] HanmengLiu,RuoxiNing,ZhiyangTeng,JianLiu,QijiZhou,andYueZhang.
[60] AndreasHolzinger,GeorgLangs,HelmutDenk,KurtZatloukal,andHeimo 2023.Evaluatingthelogicalreasoningabilityofchatgptandgpt-4.arXivpreprint
Müller.2019.Causabilityandexplainabilityofartificialintelligenceinmedicine. arXiv:2304.03439(2023).
WileyInterdisciplinaryReviews:DataMiningandKnowledgeDiscovery9,4(2019), [86] ChristopherLordandDionysiaTamvaki.2013. Thepoliticsofjustification?
e1312. Applyingthe‘DiscourseQualityIndex’tothestudyoftheEuropeanParliament.
[61] Hsiu-FangHsiehandSarahEShannon.2005.Threeapproachestoqualitative EuropeanPoliticalScienceReview5,1(2013),27–54.
contentanalysis.Qualitativehealthresearch15,9(2005),1277–1288. [87] ScottMLundbergandSu-InLee.2017.Aunifiedapproachtointerpretingmodel
[62] GiuliaInguaggiato,SuzanneMetselaar,BertMolewijk,andGuyWiddershoven. predictions.Advancesinneuralinformationprocessingsystems30(2017).
2019. Howmoralcasedeliberationsupportsgoodclinicaldecisionmaking.Conference’17,July2017,Washington,DC,USA ShuaiMa,etal.
[88] FredCLunenburg.2010.Thedecisionmakingprocess..InNationalForumof [114] HerbertASimon.1990. Boundedrationality. Utilityandprobability(1990),
EducationalAdministration&SupervisionJournal,Vol.27. 15–18.
[89] AidanLyonandEricPacuit.2013.Thewisdomofcrowds:Methodsofhuman [115] HerbertAlexanderSimon.1997. Modelsofboundedrationality:Empirically
judgementaggregation.InHandbookofhumancomputation.Springer,599–614. groundedeconomicreason.Vol.3.MITpress.
[90] ShuaiMa,YingLei,XinruWang,ChengboZheng,ChuhanShi,MingYin,and [116] RobertLSimon.2008. TheBlackwellguidetosocialandpoliticalphilosophy.
XiaojuanMa.2023. WhoShouldITrust:AIorMyself?LeveragingHuman JohnWiley&Sons.
andAICorrectnessLikelihoodtoPromoteAppropriateTrustinAI-Assisted [117] VenkateshSivaraman,LeighABukowski,JoelLevin,JeremyMKahn,andAdam
Decision-Making.InProceedingsofthe2023CHIConferenceonHumanFactors Perer.2023.Ignore,trust,ornegotiate:understandingclinicianacceptanceof
inComputingSystems.1–19. AI-basedtreatmentrecommendationsinhealthcare.InProceedingsofthe2023
[91] ShuaiMa,MingfeiSun,andXiaojuanMa.2022.ModelingAdaptiveExpression CHIConferenceonHumanFactorsinComputingSystems.1–18.
ofRobotLearningEngagementandExploringitsEffectsonHumanTeachers. [118] DylanSlack,SatyapriyaKrishna,HimabinduLakkaraju,andSameerSingh.2022.
ACMTransactionsonComputer-HumanInteraction(2022). TalkToModel:ExplainingMachineLearningModelswithInteractiveNatural
[92] ShuaiMa,XinruWang,YingLei,ChuhanShi,MingYin,andXiaojuanMa.2024. LanguageConversations.(2022).
"AreYouReallySure?"UnderstandingtheEffectsofHumanSelf-Confidence [119] MarcoRSteenbergen,AndréBächtiger,MarkusSpörndli,andJürgSteiner.
CalibrationinAI-AssistedDecisionMaking. arXivpreprintarXiv:2403.09552 2003.Measuringpoliticaldeliberation:Adiscoursequalityindex.Comparative
(2024). EuropeanPolitics1(2003),21–48.
[93] ShuaiMa,ZijunWei,FengTian,XiangminFan,JianmingZhang,XiaohuiShen, [120] JürgSteiner,AndréBächtiger,MarkusSpörndli,andMarcoRSteenbergen.2005.
ZheLin,JinHuang,RadomírMěch,DimitrisSamaras,etal.2019. SmartEye: Deliberativepoliticsinaction.Analysingparliamentarydiscourse.(2005).
assistinginstantphototakingviaintegratinguserpreferencewithdeepview [121] MarkSteyversandAakritiKumar.2022. ThreeChallengesforAI-Assisted
proposalnetwork.InProceedingsofthe2019CHIconferenceonhumanfactorsin Decision-Making.(2022).
computingsystems.1–12. [122] PhilipETetlock.2017.Expertpoliticaljudgment.InExpertPoliticalJudgment.
[94] ShuaiMa,ChenyiZhang,XinruWang,XiaojuanMa,andMingYin.2024.Beyond PrincetonUniversityPress.
Recommender:AnExploratoryStudyoftheEffectsofDifferentAIRolesin [123] DennisFThompson.2008.Deliberativedemocratictheoryandempiricalpoliti-
AI-AssistedDecisionMaking.arXivpreprintarXiv:2403.01791(2024). calscience.Annu.Rev.Polit.Sci.11(2008),497–520.
[95] ShuaiMa,TaichangZhou,FeiNie,andXiaojuanMa.2022.Glancee:AnAdapt- [124] AmyTurner,MeenaKaushik,Mu-TiHuang,andSrikarVaranasi.2022.Cali-
ableSystemforInstructorstoGraspStudentLearningStatusinSynchronous bratingtrustinAI-assisteddecisionmaking.
OnlineClasses.InCHIConferenceonHumanFactorsinComputingSystems. [125] DartmouthUMass.[n.d.]. 7STEPSTOEFFECTIVEDECISIONMAKING.
1–25. https://www.umassd.edu/fycm/decision-making/process/.
[96] Merriam-Webster.[n.d.]. DeliberationDefinition. https://www.merriam- [126] NielsVanBerkel,JorgeGoncalves,DanulaHettiachchi,SenuriWijenayake,
webster.com/dictionary/deliberation. RyanMKelly,andVassilisKostakos.2019.Crowdsourcingperceptionsoffair
[97] KatherineLMilkman,DollyChugh,andMaxHBazerman.2009. Howcan predictorsformachinelearning:Arecidivismcasestudy. Proceedingsofthe
decisionmakingbeimproved?Perspectivesonpsychologicalscience4,4(2009), ACMonHuman-ComputerInteraction3,CSCW(2019),1–21.
379–383. [127] FransHVanEemerenandAFranciscaSnHenkemans.2016.Argumentation:
[98] DeborahJMiller,ElliotSSpengler,andPaulMSpengler.2015.Ameta-analysis Analysisandevaluation.Taylor&Francis.
ofconfidenceandjudgmentaccuracyinclinicaldecisionmaking.Journalof [128] FransHVanEemeren,AFranciscaSnHenkemans,andRobGrootendorst.2002.
CounselingPsychology62,4(2015),553. Argumentation:Analysis,evaluation,presentation.Routledge.
[99] TimMiller.2019.Explanationinartificialintelligence:Insightsfromthesocial [129] EwartJdeVisser,MarvinCohen,AmosFreedy,andRajaParasuraman.2014.A
sciences.Artificialintelligence267(2019),1–38. designmethodologyfortrustcuecalibrationincognitiveagents.InInternational
[100] TimMiller.2023.ExplainableAIisDead,LongLiveExplainableAI!Hypothesis- conferenceonvirtual,augmentedandmixedreality.Springer,251–262.
drivenDecisionSupportusingEvaluativeAI.InProceedingsofthe2023ACM [130] XinruWang,ChenLiang,andMingYin.[n.d.]. TheEffectsofAIBiasesand
ConferenceonFairness,Accountability,andTransparency.333–342. ExplanationsonHumanDecisionFairness:ACaseStudyofBiddinginRental
[101] SwatiMishraandJeffreyMRzeszotarski.2021.CrowdsourcingandEvaluating HousingMarkets.([n.d.]).
Concept-drivenExplanationsofMachineLearningModels.Proceedingsofthe [131] XinruWangandMingYin.2021.Areexplanationshelpful?acomparativestudy
ACMonHuman-ComputerInteraction5,CSCW1(2021),1–26. oftheeffectsofexplanationsinai-assisteddecision-making.In26thInternational
[102] TinaNabatchiandMattLeighninger.2015.Publicparticipationfor21stcentury ConferenceonIntelligentUserInterfaces.318–328.
democracy.JohnWiley&Sons. [132] XinruWangandMingYin.2023. WatchOutforUpdates:Understanding
[103] DJPangburn.2019.Schoolsareusingsoftwaretohelppickwhogetsin.What theEffectsofModelExplanationUpdatesinAI-AssistedDecisionMaking.In
couldgowrong.FastCompany17(2019). Proceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.
[104] RajaParasuramanandVictorRiley.1997.Humansandautomation:Use,misuse, 1–19.
disuse,abuse.Humanfactors39,2(1997),230–253. [133] AustinWatersandRistoMiikkulainen.2014.Grade:Machinelearningsupport
[105] JoonSungPark,RickBarber,AlexKirlik,andKarrieKarahalios.2019.ASlowAl- forgraduateadmissions.AiMagazine35,1(2014),64–64.
gorithmImprovesUsers’AssessmentsoftheAlgorithm’sAccuracy.Proceedings [134] DouglasLWeed.2005.Weightofevidence:areviewofconceptandmethods.
oftheACMonHuman-ComputerInteraction3,CSCW(2019),1–15. RiskAnalysis:AnInternationalJournal25,6(2005),1545–1557.
[106] CharlesSandersPeirce.2014.IllustrationsoftheLogicofScience.OpenCourt. [135] BryanWilder,EricHorvitz,andEceKamar.2020. Learningtocomplement
[107] ForoughPoursabzi-Sangdeh,DanielGGoldstein,JakeMHofman,JenniferWort- humans.arXivpreprintarXiv:2005.00582(2020).
manWortmanVaughan,andHannaWallach.2021.Manipulatingandmeasuring [136] MagdalenaEWojcieszak,YoungMinBaek,andMichaelXDelliCarpini.2010.
modelinterpretability.InProceedingsofthe2021CHIconferenceonhumanfactors Deliberativeandparticipatorydemocracy?Ideologicalstrengthandthepro-
incomputingsystems.1–52. cessesleadingfromdeliberationtopoliticalengagement.InternationalJournal
[108] AnnePreisz.2019. Fastandslowthinking;andtheproblemofconflating ofPublicOpinionResearch22,2(2010),154–180.
clinicalreasoningandethicaldeliberationinacutedecision-making.Journalof [137] YaoXie,MelodyChen,DavidKao,GeGao,andXiang’Anthony’Chen.2020.
paediatricsandchildhealth55,6(2019),621–624. CheXplain:enablingphysicianstoexploreandunderstanddata-driven,AI-
[109] CharviRastogi,YunfengZhang,DennisWei,KushRVarshney,AmitDhurand- enabledmedicalimaginganalysis.InProceedingsofthe2020CHIConferenceon
har,andRichardTomsett.2022.Decidingfastandslow:Theroleofcognitivebi- HumanFactorsinComputingSystems.1–13.
asesinai-assisteddecision-making.ProceedingsoftheACMonHuman-Computer [138] FumengYang,ZhuanyiHuang,JeanScholtz,andDustinLArendt.2020.How
Interaction6,CSCW1(2022),1–22. dovisualexplanationsfosterendusers’appropriatetrustinmachinelearning?.
[110] ThomasLSaaty.2008.Decisionmakingwiththeanalytichierarchyprocess. InProceedingsofthe25thInternationalConferenceonIntelligentUserInterfaces.
Internationaljournalofservicessciences1,1(2008),83–98. 189–201.
[111] MikeSchaekermann,GraemeBeaton,MinahzHabib,AndrewLim,KateLarson, [139] IlanYaniv.2004.Receivingotherpeople’sadvice:Influenceandbenefit.Organi-
andEdithLaw.2019. Understandingexpertdisagreementinmedicaldata zationalbehaviorandhumandecisionprocesses93,1(2004),1–13.
analysisthroughstructuredadjudication.ProceedingsoftheACMonHuman- [140] AngieZhang,OlympiaWalker,KaciNguyen,JiajunDai,AnqingChen,and
ComputerInteraction3,CSCW(2019),1–23. MinKyungLee.2023.DeliberatingwithAI:ImprovingDecision-Makingfor
[112] MaxSchemmer,NiklasKuehl,CarinaBenz,AndreaBartos,andGerhardSatzger. theFuturethroughParticipatoryAIDesignandStakeholderDeliberation.Pro-
2023.AppropriaterelianceonAIadvice:Conceptualizationandtheeffectof ceedingsoftheACMonHuman-ComputerInteraction7,CSCW1(2023),1–32.
explanations.InProceedingsofthe28thInternationalConferenceonIntelligent [141] YunfengZhang,QVeraLiao,andRachelKEBellamy.2020. Effectofconfi-
UserInterfaces.410–422. denceandexplanationonaccuracyandtrustcalibrationinAI-assisteddecision
[113] ChuhanShi,YichengHu,ShenanWang,ShuaiMa,ChengboZheng,Xiaojuan making.InProceedingsofthe2020ConferenceonFairness,Accountability,and
Ma,andQiongLuo.2023.RetroLens:AHuman-AICollaborativeSystemfor Transparency.295–305.
Multi-stepRetrosyntheticRoutePlanning.InProceedingsofthe2023CHICon-
ferenceonHumanFactorsinComputingSystems.1–20.TowardsHuman-AIDeliberation:DesignandEvaluationofLLM-EmpoweredDeliberativeAIforAI-AssistedDecision-Making Conference’17,July2017,Washington,DC,USA
[142] JieqiongZhao,YixuanWang,MichelleVMancenido,ErinKChiou,andRoss [144] QianZhuandShuaiMa.2019.WhatDidIMiss?.InAdjunctProceedingsofthe
Maciejewski.2023.Evaluatingtheimpactofuncertaintyvisualizationonmodel 32ndAnnualACMSymposiumonUserInterfaceSoftwareandTechnology.53–55.
reliance.IEEETransactionsonVisualizationandComputerGraphics(2023).
[143] ChengboZheng,YuhengWu,ChuhanShi,ShuaiMa,JiehuiLuo,andXiaojuan
APPENDICES
Ma.2023. CompetentbutRigid:IdentifyingtheGapinEmpoweringAIto
ParticipateEquallyinGroupDecision-Making.InProceedingsofthe2023CHI
A BASEINTERFACE
ConferenceonHumanFactorsinComputingSystems.1–19.Conference’17,July2017,Washington,DC,USA ShuaiMa,etal.
A
C
B 1
2
3
Figure15:Thebaseline(traditionalexplainableAI)interfaceinouruserstudy.Theinterfacecontainsthreeparts.Thetop(A)
istheapplicant’sprofile.Thebottomleftpart(B)showsAI’sfeaturecontributionexplanation.Thebottomrightpart(C)isfor
humansto(1)indicatetheirinitialpredictions,(2)seeAI’ssuggestions,and(3)indicatetheirfinaldecisions.NotethatAI’s
suggestionsandexplanationsareonlyshownafterhumansmaketheirinitialpredictions.(Allthedashedlinesareonlyfor
illustration)