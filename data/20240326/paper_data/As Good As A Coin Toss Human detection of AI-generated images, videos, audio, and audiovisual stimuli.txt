As Good As A Coin Toss
Human detection of AI-generated images, videos, audio, and audiovisual stimuli
Di Cooke*, Abigail Edwards, Sophia Barkoff, and Kathryn Kelly
International Security Program, Center for Strategic and International Studies, Washington D.C., USA
ABSTRACT 1 INTRODUCTION
As synthetic media becomes progressively more realistic Advancements in generative AI technology have made it
and barriers to using it continue to lower, the technology easier for any person to manufacture increasingly realistic
has been increasingly utilized for malicious purposes, from synthetic media (colloquially known as ‘deepfakes’) at faster
financial fraud to non-consensual pornography. Today’s speeds, larger scales, and with more personalisation than
principal defense against being misled by synthetic media ever before. [14] In turn, this has led to synthetic media
relies on the ability of the human observer to visually and being increasingly employed for harmful purposes,
auditorily discern between real and fake. However, it inclusion for disinformation campaigns, non-consensual
remains unclear just how vulnerable people actually are to pornography, financial fraud, child sexual abuse and
deceptive synthetic media in the course of their day to day exploitation activities, espionage, and more. [24] As of
lives. We conducted a perceptual survey series with 1276 today, the principal defense to combat deceptive synthetic
participants to assess how accurate people were at media depends nearly entirely on the human observer’s
distinguishing synthetic images, audio-only, video-only, perceptual detection capabilities to visually or auditorily
and audiovisual stimuli from authentic. To reflect the identify AI-generated content. [14] The increasing realism
circumstances under which people would likely encounter of synthetic media impedes this ability, increasing people’s
synthetic media ‘in the wild’, testing conditions and stimuli vulnerability to being misled by synthetic content. Yet it has
emulated a typical online platform, while all synthetic been found that people overestimate how capable they are
media used in the survey was sourced from publicly at identifying synthetic media. [12]
accessible generative AI technology. While there are growing efforts to develop alternative
We find that participants were able to overall correctly countermeasures, such as the creation of technical
identify the authenticity of digital content 51.2% of the time. solutions including machine detection, watermarking, or
We also find that detection performance worsens when the content provenance, these methods either currently lack
stimuli contain synthetic content as compared to authentic robustness or are not yet sufficiently widespread enough to
content, images featuring human faces as compared to non- be effective. [11, 14, 33] Similarly, despite widespread calls
human face objects, a single modality as compared to to deploy educational interventions such as digital media
multimodal stimuli, mixed-authenticity as compared to literacy campaigns, formalized efforts have been relatively
being fully synthetic for audiovisual stimuli, and features limited in practice. As a result, an accurate measure of
foreign languages as compared to languages the observer is people’s perceptual ability to differentiate between the real
fluent in. Finally, we also find that participants’ prior and fake is critical to effectively combat the potential and
knowledge of synthetic media does not meaningfully impact realised harms arising from social media.
their detection performance. Collectively, these results We conducted a study to assess human perceptual
indicate that people are highly susceptible to being tricked detection capabilities in distinguishing between human-
by synthetic media in their daily lives and that human authored and AI-generated digital content, requiring
perceptual capabilities can no longer be relied upon as a participants to classify synthetic and authentic images,
useful defense. This highlights the critical need for audio-only, video-only, and audiovisual media items. Our
alternative robust countermeasures to mitigate the study analyzed the overall detection performance under
potential and realised harms arising from synthetic media. these environmental conditions, as well as the individual
impacts of specific stimuli characteristics on human
ACKNOWLEDGEMENTS perceptual detection capabilities, examining the effects of
media type, authenticity, image subject matter, modality,
We would like to thank Gamin Kim, Ike Barrash, and
and language familiarity on detection accuracy rates. In
Daniel Pycock for their contributions in data analysis and
addition, it assessed how prior knowledgeability of
formatting, as well as Alexis Day for her contributions to
synthetic media, as self-reported by participants, impacts
the survey’s design and development.
detection performance.
In order to ensure that study results are reflective of
human detection performance as it would be ‘in the wild’,
or as it would be if they encountered synthetic media in the
*to whom correspondence should be addressed at dcooke@csis.org
1course of their day to day lives, our survey design sought to speech, and language recognition, providing potentially
emulate typical online platform environmental conditions. novel observations to not only synthetic media detection
Discussed in greater detail in our ‘Methods’ section, this research but the human perception field as well. Finally, we
included structuring the survey format to mimic typical find that people’s prior knowledge of synthetic media does
online platform features such as sequentially shown not impact detection performance, with people who
content and vertical scrolling, as well as providing pacing reported being unfamiliar, semi-familiar or highly familiar
signposts for participants to progress through the survey with synthetic media prior to taking the survey all
within average web browsing speeds. The stimuli content performing similarly. This suggests either that current
was also selected to be representative of the most commonly public knowledge of synthetic media even at higher degrees
digital content featured on online platforms. Participants is insufficient for meaningfully improving detection
were not provided with any feedback, nor were they advised performance, or that synthetic media has become
what the proportion of synthetic to authentic content there convincingly realistic enough that perceptual-based
would be. Finally, synthetic stimuli were solely sourced educational interventions are insufficient.
from generative AI tools and services accessible to members Collectively, these results demonstrate that depending on
of the public, either commercially or via open source people’s perceptual detection capabilities to discern the real
software, so as to accurately reflect the quality of synthetic from the take is no longer a viable bulwark against the
content that people are already encountering online today. threats posed by synthetic media. While our findings
To the best of the authors’ knowledge, this is the first provide useful insights on how to reduce people’s
study to test human detection performance of most of these susceptibility to certain digital content characteristics
synthetic media types under such conditions. While which people have been found to be more vulnerable to
Josephs et al’s 2023 study examined the impact of real being deceived by, it is expected any benefits will be short
world web browsing conditions on human detection term. Rather, it is expected that continued advancements in
performance on video-only stimuli, [7] the majority of generative AI technology will eventually lead to any
current research has assessed detection performance under detection performance differences resulting from these
conditions not necessarily reflective of the circumstances of characteristics to become negligible, and that human
how people would encounter and determine the presence of detection performance overall will plateau.
synthetic media in their regular lives, such as requiring two- As a consequence, it is more critical than ever that robust
alternative forced choice methods, providing instant alternative countermeasures be developed and deployed in
feedback or unlimited testing time, as well as informing order to combat the potential and realised harms arising
participants what the percentage of synthetic versus from synthetic media, whether this be technical,
authentic media will be. [5, 6, 13, 15, 19] As far as we are educational, or otherwise.
aware, this is also the first study to test human detection
capabilities on images which didn’t feature human faces, 2 RESULTS
examine the role of language in detecting synthetic video- We conducted a pre-registered perceptual survey series,
only and audiovisual stimuli, as well as compare detection requiring 1276 participants to classify authentic and
performance between mixed-synthetic and fully synthetic synthetic media stimuli presented to them under typical
audiovisual stimuli. online platform environmental conditions. To assess the
Our results find that participants' overall accuracy rates impact of individual stimuli characteristics and prior
for identifying synthetic content are close to a chance level knowledgeability of synthetic media on detection
performance of 50% with minimal variation between media performance, we conducted a binomial logistic regression
types, suggesting that people’s visual and auditory along with a series of pre-registered and post hoc ANOVA
perceptual capabilities are inadequate for reliably and t-tests. To reduce the risks of a type 1 error, the p-value
identifying synthetic media encountered in online was adjusted to p=0.0033 (α/15) using Bonferroni
platforms today. Our results also find that detection correction.
accuracy rates worsen when people are presented with
stimuli featuring synthetic content as compared to
authentic content, images of human faces as compared to
non-human face objects, stimuli containing a single
modality as compared to multimodal stimuli, mixed-
authenticity stimuli as compared to fully synthetic
audiovisual stimuli, and stimuli featuring foreign languages
as compared to featuring languages participants are fluent
speakers in. This indicates that individual content
characteristics present within the stimuli affect certain
visual and auditory perceptual processes such as object,
22.2 Human Face vs. Non-Human Face Images
Participants were also found to be significantly less
accurate (see Table 1) when classifying images featuring
human faces (M=46.6%) as compared to images featuring
animals (M=51.7%), food (M=49.9%), and landscapes
(M=54.7%). Post hoc analysis confirmed this difference in
detection performance remained present even when
controlling for model type [t(12201)=-13.83, p<0.001;
d=0.21].
Table 1. Logistic Regression Analysis of Synthetic Media
Detection Performance
2.1 Media Type & Authenticity
Mean detection performance across all stimuli was found
to be 51.2%, close to a random chance performance of 50%.
As shown in Figure 1, participants were the least accurate at
classifying image stimuli with a 49.4% accuracy rate.
Comparatively, mean detection accuracy was higher for
video-only stimuli at 50.7% and audio-only stimuli at Figure 2. The top row are synthetic images from each category
which were most often misclassified as authentic, while the
53.7%, with participants being the most accurate at
bottom row are synthetic images often correctly identified as
correctly classifying audiovisual stimuli at a 54.5% accuracy synthetic. Beneath each image is its corresponding mean accuracy
rate. It was also found that stimuli’s authenticity was found rate.
to be a meaningful predictor for detection performance, as
shown in Table 1. Participants were significantly better at 2.3 Single Versus Multimodal Stimuli
correctly identifying fully authentic stimuli (M=64.6%) as
Detection accuracy was found to be significantly higher
compared to stimuli which contained synthetic media
[t(49004)=5.18, p<0.001; d=0.4] for participants
(M=38.8%). Participants were also significantly more
classifying multimodal audiovisual stimuli in comparison
accurate [t(9861)=6.3, p<0.001; d=0.11] in classifying
their single modality counterparts, or audio-only and video-
audiovisual stimuli containing both synthetic audio and
only stimuli (M=52.2%). Post hoc analysis of the 30 video
video (M=49%) as compared to audiovisual stimuli
stimuli which were presented in an audiovisual format,
containing synthetic video and authentic audio (M=43.4%).
either fully authentic or mixed synthetic (synthetic video
and authentic audio), in one of the surveys and in a video-
only format in the other survey found that participants were
significantly more accurate in identifying the stimuli
[t(37517)=10.15, p<0.001; d=0.1] when the audio was
included (M=55.9%) than when the stimuli was presented
in a video-only format (M=50.7%).
2.4 Language Familiarity
Participants were found to be significantly more accurate
(see Table 1) in classifying stimuli when presented with
visual and auditory content featuring a language they
reported being fluent speakers (M=54.5%) of as opposed to
those featuring foreign languages (M=51.3%), as shown in
Figure 1. Average detection accuracy by media type, with error Figure 3. Regarding audio-only stimuli, post hoc analysis
bars representing 95% confidence intervals.
found that participants were significantly more accurate
[t(17696)=3.947, p<0.001; d=0.06] discerning between
synthetic and authentic audio-only stimuli featuring a
known language (M=55.3%) as opposed to a foreign
3language (M=52.3%). Further analysis also revealed that 2.5 Self-Reported Prior Knowledgeability
participants were significantly better at respectively No significant difference in detection performance was
identifying audiovisual stimuli [t(22640)=6.864, p<0.001; found (see Table 1) between participants who reported
d=0.09] featuring known languages (M=56.5%) compared being previously unfamiliar with synthetic media
to those featuring foreign languages (M=52%). This was (M=51.1%) and those who reported having prior knowledge
also found to be the case for video-only stimuli, with of synthetic media, either semi-familiar (M=51%) or highly
participants being significantly more accurate familiar (M=51.9%). A post hoc one-way ANOVA also did
[t(19278)=2.83, p<0.001; d=0.04] at detecting known not find any significant difference in detection performance
language video-only stimuli (M=52%) versus foreign between the three groups [F(2,124185)=1.4, p=0.25;
language stimuli (M=49.5%). η2<0.01], with Tukey's HSD test confirming no significant
difference between their means.
3 LIMITATIONS
This study is not without limitations. Firstly, as all
synthetic media items used in this survey were collected or
produced prior to 2023, current human detection
performance of synthetic media produced today by publicly
available generative AI tools may be lower than reported
here, as further advancements in generative AI technology
has since further improved the realism of synthetic content.
Furthermore while this study’s design sought to mimic
online platform environmental conditions to replicate the
manner in which individuals would probably encounter
synthetic media in their day to day lives, it is unlikely that
Figure 3. Mean detection accuracy by language familiarity and
individuals will solely encounter synthetic media in an
media type, with error bars representing 95% confidence
intervals. online platform without any accompanying contextual
information such as added text, comments, or source
information, which may further inhibit or facilitate the their
When examining the 30 video stimuli presented in both a ability to determine the legitimacy of the digital content.
video-only and audiovisual format, post hoc analysis found Another limitation to be considered is that participants self-
that the inclusion of audio featuring known languages reported their degree of pre-existing synthetic media
significantly improved detection performance knowledge and fluency in languages, wherein participants
[t(23035)=9.17, p<0.001; d=0.12] by 5.5 percentage points may have over or underestimated their capabilities in
(see Figure 4). For videos featuring foreign languages, comparison with other participants.
detection performance also significantly improved
[t(16966)=5.63, p<0.001; d=0.09] to a lesser degree by 4.3 4 DISCUSSION AND OUTLOOK
percentage points. 4.1 ‘In The Wild’ Detection Performance
Multiple implications can be drawn from the results of
this study. First, people struggled to meaningfully
distinguish synthetic images, audio, video, and audiovisual
stimuli from their authentic counterparts, with overall
detection accuracy being close to a chance level
performance. This is congruent with existing research to
some degree, as some prior studies have recorded similar
detection accuracy rates for synthetic images, [19, 28] yet
studies on video, audio, and audiovisual stimuli have
typically found higher detection accuracy rates. [3, 5, 6, 13,
15, 20, 23] Although study differences bar detailed
comparison, it is hypothesized that the overall divergence
in detection performance is due to the differing
environmental testing conditions - suggesting that people’s
detection performance is constrained when they encounter
Figure 4. Mean detection accuracy by language familiarity
between video-only clips and their audiovisual counterparts, with synthetic media under online platform environmental
error bars representing 95% confidence intervals. conditions. This is consistent with Josephs et al 2023’s
4study, which found that online platform environmental consistent with existing research such as Groh et al 2023’s
factors, including divided attention, exposure length, study, which found the addition of audio to videos of real
amongst others, also had inhibitory effects on people’s and fake political speeches improved detection
detection capabilities. [7] Further research might be performance. [6] This may be due to the multimodal nature
conducted on how these and other environmental factors of speech perception, as speech perception research has
may also impact detection performance, both individually found that people rely on both visual and auditory
and cumulatively. Having a better understanding of what perceptual cues to comprehend spoken words. [22]
these environmental factors are and their effects on Therefore, synthetic audiovisual stimuli is less difficult to
detection performance will provide a clearer picture of how detect than its monomodal counterparts because people are
vulnerable people may be to deceptively employed synthetic able to leverage both the auditory and visual information
media ‘in the wild’. For instance, despite the smartphone's available to better identify observable AI-generated
growing popularity as people’s primary device to access artifacts present in the stimuli. In addition, detection
online information, it has been found that people employ accuracy is found to be higher when identifying fully
lower amounts of cognitive resources when consuming synthetic audiovisual stimuli, as compared to mixed
digital content via smartphones. [4, 30] As a consequence, synthetic audiovisual stimuli where the video contains
smartphone use may further hinder people’s abilities to synthetic content while the audio is fully authentic. This
detect synthetic media when encountering it in their day to suggests that people may be better at identifying fully
day lives. synthetic audiovisual stimuli than mixed synthetic due to
the higher potential presence of observable artifacts in both
4.2 Stimuli Content Characteristics the audio and visual modalities which they can leverage to
Detection performance is also found to be sensitive to determine authenticity, as opposed to potential observable
stimuli content characteristics, which suggests that these artifacts only being present in only one modality as would
individual characteristics may affect people’s perceptual be the case with mixed synthetic audiovisual stimuli.
capabilities when distinguishing between the real and the Language: People are also more accurate in detecting
fake. synthetic audio-only, video-only, and audiovisual stimuli
Authenticity: People are found to be more accurate at featuring languages the observer is a fluent speaker of
identifying authentic as compared to synthetic content, also compared to stimuli featuring foreign languages,
revealing a bias towards classifying stimuli as authentic, suggesting that language familiarity plays a significant role
indicating that people are inclined towards categorizing in people’s visual and auditory perceptual detection
digital content as real. This bias is consistent with previous capabilities. This is consistent with existing synthetic audio
research which also found people had a similar inclination detection research such as Müller et al’s 2023 study, which
to classify video-only stimuli as being authentic. [7, 12]. found native English speakers to be better at detecting
Image Content: Meanwhile, people are worse at English synthetic audio clips than non-native speakers. [15]
detecting synthetic images featuring human faces as Therefore, detection performance may be higher when
compared to synthetic images featuring non-face objects, known languages are present in visual and auditory digital
indicating they found synthetic images featuring human content due to the observer being more familiar with the
faces to be more convincing than similarly realistic looking visual and auditory language information available, making
images featuring non-face objects. This may be due to the them more sensitive to observable artifacts. [17] In
specialized human visual perceptual process which occurs addition, when comparing detection performance of video-
when people observe faces as opposed to non-face objects. only stimuli as compared to their audiovisual counterparts
Visual perception research has established that whereas (the same video clips but with the audio included) it was
humans recognize faces as a perceptual whole, non-face found that people’s detection accuracy improved to a
objects are conversely identified by their distinct individual greater degree between video-only and audiovisual stimuli
components. [10, 27] Therefore, the more gestalt face featuring known languages versus those featuring foreign
recognition process which takes place once an image is languages. This suggests that people are more sensitive to
recognised to feature a face may lead people to be less auditory perceptual cues in audiovisual stimuli featuring
sensitive towards identifying observable AI-generated familiar language as opposed to foreign ones. This is
artifacts than they would if employing the more fragmented congruent with established language perception research,
object recognition process which occurs when observing which has found that people weigh auditory information
non-face objects. highly when observing known languages being spoken,
Modality: People are also less accurate at detecting while they rely more on visual perceptual cues when
synthetic audio-only and video-only stimuli as compared to observing foreign languages. [25, 31] Therefore, it may be
audiovisual, which suggests the inclusion of additional that the inclusion of audio facilitated people’s sensitivity to
modalities to a stimuli improves the perceptual ability to synthetic visual content to a greater degree for stimuli
distinguish between authentic and synthetic media. This is featuring familiar languages than foreign languages
5because of the greater weight given to auditory perceptual to clarify in what contexts perceptual-based interventions
cues when observing familiar languages in the language are able to improve detection performance and when they
perceptual process. are not will be beneficial in order to develop more effective
Understanding how individual stimuli characteristics educational interventions to reduce people’s vulnerability
such as the ones examined in this study may inhibit or to deceptive synthetic content.
facilitate people’s perceptual detection capabilities is
valuable as it enables more accurate predictions of how 5 CONCLUSION
susceptible people may be to different types of synthetic The results of our study demonstrate that people’s
content they may be exposed to. It also highlights which perceptual detection capabilities cannot no longer be relied
demographics may be more vulnerable to being duped by upon as reliable defense against being deceived by synthetic
synthetic media than others, such as monolingual speakers media. With advancements in generative AI technology,
potentially being less sensitive to visual and auditory AI- the ability to create synthetic content that is sufficiently
generated artifacts presented in foreign languages than realistic has become available for any member of the public
multilingual speakers. In turn, these insights can inform to use, including those with harmful intent. This underlines
the development of more effective countermeasures to the critical importance to develop and deploy robust
better mitigate people's susceptibility to synthetic media. countermeasures not reliant on human perceptual
For instance, although the default for many social media detection capabilities. This includes increasing investment
platforms is to have audiovisual stimuli muted when being and research for technical solutions such as machine
played, detection performance of synthetic media is likely detection, watermarking or cryptographic signatures, as
to be improved if the audio is not muted when the video well as the wider adoption of other techniques like content
automatically plays. Therefore a useful content moderation provenance or hashing databases. It also highlights the
policy to adopt may be to not mute videos deemed to be at need to pursue widespread educational interventions such
higher risk of containing deceptive synthetic content, such as digital media literacy campaigns to better equip people
those featuring political content in the run up to with the skills and knowledge to identify false content, such
government elections. as critical analysis techniques like cross-referencing and
Future research would be useful to further explore the source analysis. While not discussed here, policymakers
effects of these and other stimuli characteristics on and industry leaders also need to consider what kind of
detection performance, such as determining whether the regulations need to be enacted to constrain synthetic media
difference in detection performance between faces and non- being used for malicious purposes.
face objects is also found in identifying synthetic video and Our study also identifies several stimuli content
audiovisual stimuli. As generative AI technology continues characteristics that have inhibitory or facilitatory effects on
to improve, periodic reassessment of these content peoples’ perceptual detection capabilities. These findings
characteristics would be beneficial to determine whether provide useful insights for informing immediate steps
they continue to have the same effect. which could be taken in the short term to reduce people’s
vulnerability to more convincingly deceptive content, such
4.3 Prior Knowledgeability as specific content moderation policies for online platforms.
People’s prior knowledgeability of synthetic media did not However, as synthetic media outputs continue to progress
affect detection performance, with people who reported realism, it is anticipated that perceptual-based
being highly familiar with synthetic media performing countermeasures will eventually plateau, requiring
similarly to those who reported being less familiar or alternative solutions over the long term. Regardless, further
unfamiliar. As this study did not test participants on their work in this space is vital to improve our understanding of
synthetic media knowledge, rather asked them to self- and monitor the limitations of human perceptual deception
report, this suggests one of two possible causes. The first is capabilities in order to better identify and account for the
that synthetic media has become convincingly realistic to potential and realised harms arising from deceptive
the degree where increased familiarity with synthetic media synthetic media.
does not meaningfully improve people’s perceptual
detection capabilities. Alternatively, current public 6 METHODS
knowledge of synthetic media, even at comparatively higher
6.1 Design
levels, does not sufficiently educate people on effective
Our pre-registered mixed design study was divided across
perception-based detection methods. Existing research
two online surveys, with participants only able to take one
suggests the truth is somewhere in the middle, as some
of the two surveys. This was done to reduce the risk of
studies have found that increased exposure to synthetic
participant exhaustion and to eliminate carryover effects.
content and providing immediate feedback or prior training
All participants were required to use a computer to take the
has improved detection performance, while others have
survey, and were provided with an introduction to the
found that not to be the case. [5, 6, 13, 15, 19] Further work
6study’s purpose and explanation of synthetic media. same visual content as the audiovisual stimuli from Survey
Participants were then asked to report on their fluency of 1 but with the audio content removed, with the reverse for
non-English languages, and to select their level of the Survey 1 video-only and Survey 2 audiovisual stimuli.
preexisting knowledge of synthetic media as being either: 1)
Highly Familiar (“I have a comprehensive understanding 6.2 Participants
what kind of deepfakes can be made, and have encountered A total of 124187 observations were collected and retained
many examples before”), 2) Semi-Familiar (“I have a from 1276 participants for this pre-registered study. All
general understanding of deepfakes, and have encountered participants were fluent English speakers and were North
a couple of examples before”), or 3) Unfamiliar (“I’ve never American residents. The sex and age demographic
heard of deepfakes before, or I recognise the term but don’t distribution was representative of US demographics:
know much about them, and have not encountered Survey 1 being 45% Female, 8% Unreported; 19% 18-29
examples yet that I can recall.”) years old, 62% 30-64 years old, 19% 65+ years old and
Participants were asked to classify the stimuli as either Survey 2 being 49% Female, 2% Unreported; 19% 18-29
being authentic or as containing synthetic media. The years old, 61% 30-64 years old, 20% 65+ years old.
stimuli were presented sequentially in randomized order Participants were recruited from the research survey
and participants progressed through the survey by scrolling platform Prolific, and paid a pro rata rate of $11.4 per hour.
vertically, emulating the experience of browsing through an
online platform news feed. Audio, video, and audiovisual 6.3 Stimuli
clips were all replayable. Participants were asked to A total of 194 stimuli were presented to participants
progress through the survey at pace reflective of how they across both surveys, consisting of authentic and synthetic
would browse through an online platform’s newsfeed. images, audio-only, video-only, and audiovisual clips.
While there was no hard time restraint and participants had Image, audio-only, and video-only stimuli were each 50%
the freedom to decide how much time they spent on each synthetic and 50% authentic. Of the audiovisual stimuli, 15
question, signposts reminding them to take the survey at clips were fully authentic, 15 contained synthetic video and
their typical browsing speed appeared when participants authentic audio, and 8 were fully synthetic. The stimuli
completed 25%, 50%, and 75% of the survey. A self- content and subject matter was representative of popular
regulated approach to pacing was decided to be appropriate digital content found on online platforms, containing
for this study, as imposing hard time limits would risk predominantly human-featured content including images,
insufficiently accounting for the variety of factors which user generated social media videos, film scenes, news
existing research has shown to affect browsing speed, segments, music videos, vlogs, podcasts and audiobooks
including media type, subject matter, emotional valence, clips, and radio segments. [2] Image stimuli also contained
and personality. [16, 29, 32] other subject matters commonly featured on online
Two attention checks each were presented at random platforms, including food, landscapes, and animals. In all
within Survey 1 subsections 1 and 2, while two attention synthetic stimuli, AI-generated content was prominently
checks were presented at random in Survey 2. Participants featured. Audio content included many of the most widely
who failed to pass both attention checks within each Survey spoken languages online, including English, Mandarin,
1 subsection or within Survey 2 had their results removed Spanish, Hindi, Turkish, Russian, Portuguese, French,
from that section respectively. Participants who dropped German, Hebrew, Swedish, Japanese, and Korean. [21]
out part way through a section or reported having issues To ensure participants relied predominantly on their
with playing the audio, video, or audiovisual clips, had their perceptual detection capabilities, extraneous cues within
results removed from those sections as well. the content were minimized or excluded, such as unique
In subsection 1 of Survey 1, 663 participants classified 96 backgrounds or memorable contextual information.
image stimuli and passed both attention checks. Image However, as contextual content could not be fully removed
stimuli were presented in a separate subsection from the from all stimuli, diverse subject matters were ensured so as
other media types so that if participants had difficulties to further reduce possible participant reliance on
playing the audio, video, and audiovisual clips, requiring contextual cues for detection.
their results being removed, this would not also require So that the synthetic stimuli in the study reflected the
removing their image stimuli results as well. In subsection quality of the majority of synthetic content being published
2 of Survey 1, 604 participants from the same group of on online platforms, all synthetic content sourced from
participants classified 48 stimuli including 14 audio-only, commercially available generative AI products and services
16 video-only, and 18 audiovisual clips, passing both or open-source software and was generated prior to 2023.
attention checks. In Survey 2, 614 novel participants Synthetic stimuli were either produced for the purposes of
classified a different set of 16 audio-only, 14 video-only, and this study, or were collected from previously published
18 audiovisual stimuli, passing both attention checks. The digital content. Authentic stimuli were collected from
video-only stimuli presented in Survey 2 contained the commensurate publicly digital content on multiple online
7platforms and manually curated to match the synthetic from the UK Research and Innovation’s Economic and
stimuli in terms of subject matter, content types, and Social Research Council Ethics framework. We declare no
quality. Synthetic stimuli collected from pre-existing digital competing interests.
content was verified by confirming the source content
contained observable AI-generated artifacts. The legitimacy 8 DATA & PRE-REGISTRATION
of authentic stimuli was verified by being published as This study was pre-registered at OSF Registries
human-created content by a credible source. (https://osf.io/fnhr3). Study datasets are not yet publicly
Images: 96 images each containing single subject matter available, but can be made available upon request in
were used, with of them prominently and separately support of reviewing this submission.
featuring 48 human faces, 26 animals, 12 landscapes, and
10 of food. Synthetic images of human faces were sourced REFERENCES
from multiple publicly available general adversarial
[1] David Beniaguev. 2022. Synthetic Faces High
network (GAN) datasets and were manually curated to be
Quality (SFHQ) part 3 Dataset. Kaggle.
diverse across sex, race, and age (Male-presenting, Female- https://doi.org/10.34740/KAGGLE/DSV/4741518
presenting; Caucasian, Black, East Asian, Southeast Asian; [2] Laura Ceci. Top video content type by global reach
Child, Young Adult, Middle Aged Adult, Elderly Adult).1 [1, Q2 2023. Statista.
8, 9] Authentic human faces were sourced from the FFHQ https://www.statista.com/statistics/1254810/top-
video-content-type-by-global-reach/
dataset and were matched against the synthetic dataset in
[3] Christopher Doss, Jared Mondschein, Dule Shu, Tal
terms of race, sex, and age. [9] Synthetic non-face images
Wolfson, Denise Kopecky, Valerie A. Fitton-Kane,
were sourced from open source or publicly available GAN
Lance Bush, and Conrad Tucker. 2023. Deepfakes
and latent diffusion (LD) datasets or directly from models.2 and scientific knowledge dissemination. Sci. Rep. 13,
[8, 9, 27] 1 (August 2023), 13429.
Audio-Only: 30 audio stimuli consisting of 5 to 6 second- https://doi.org/10.1038/s41598-023-39944-3
long clips were used, each featuring a human voice speaking [4] Johanna Dunaway and Stuart Soroka. 2021.
Smartphone-size screens constrain cognitive access
clearly in a single language. Synthetic audio clips were
to video news stories. Inf. Commun. Soc. 24, 1
specifically generated for this study or collected from pre-
(January 2021), 69–84.
existing outputs.3 While exact model information was not https://doi.org/10.1080/1369118X.2019.1631367
available for all stimuli, audio manipulation techniques [5] Matthew Groh, Ziv Epstein, Chaz Firestone, and
employed to produce the clips included text-to-voice (TTV), Rosalind Picard. 2022. Deepfake detection by
voice cloning, and voice masking. [11] human crowds, machines, and machine-informed
crowds. Proc. Natl. Acad. Sci. 119, 1 (January 2022),
Audiovisual & Video-Only: 38 audiovisual and 30
e2110013119.
video stimuli in both vertical and horizontal formats were
https://doi.org/10.1073/pnas.2110013119
used. Each clip was between 5 to 6 seconds long and
[6] Matthew Groh, Aruna Sankaranarayanan, Nikhil
featured a human speaking clearly in a single language. In Singh, Dong Young Kim, Andrew Lippman, and
all the stimuli the human speaking features prominently Rosalind Picard. 2023. Human Detection of Political
and their face is fully visible the entire clip. Synthetic Speech Deepfakes across Transcripts, Audio, and
stimuli were sourced from published outputs produced Video. https://doi.org/10.48550/arXiv.2202.12883
[7] Emilie Josephs, Camilo Fosco, and Aude Oliva.
from open-source4 and commercially available5 generative
2023. Artifact magnification on deepfake videos
AI software and services. While exact model information
increases human detection and subjective
was not available for all stimuli, video manipulation
confidence. http://arxiv.org/abs/2304.04733
techniques employed to produce the clips included face [8] Tero Karras, Miika Aittala, Samuli Laine, Erik
swapping, head generation, and lip syncing, as well as audio Härkönen, Janne Hellsten, Jaakko Lehtinen, and
manipulation techniques such as voice cloning, TTV, and Timo Aila. 2021. Alias-Free Generative Adversarial
voice masking. [18] Networks. http://arxiv.org/abs/2106.12423
[9] Tero Karras, Samuli Laine, and Timo Aila. 2019. A
Style-Based Generator Architecture for Generative
7 ETHICS Adversarial Networks.
All participants gave fully informed consent prior to taking https://doi.org/10.48550/arXiv.1812.04948
[10] Robert T. Keys, Jessica Taubert, and Susan G.
part in the study. The study was designed with guidance
1 3
Sources which requested biography citation specifically have Synthesia, Yepic, Respeecher, Play.ht, Well Said Labs, Google
been listed as such. Additional sources include: Generated Media, Aloud
Inc., This Person Does Not Exist 4 DeepfaceLab, DeepfaceLive, FaceSwap, SimSwap
2
Sources which requested biography citation specifically have 5
Synthesia, Yepic, Canny AI, Flawless, Mac Guff, DOB Studies,
been listed as such. Additional sources include: Nyx.AI, Stability
Pulse9, Metaphysic.ai, Adapt Entertainment, DeepBrain AI
AI 2.1, DALL-E 2
8Wardle. 2021. A visual search advantage for illusory https://w3techs.com/technologies/overview/conten
faces in objects. Atten. Percept. Psychophys. 83, 5 t_language
(2021), 1942–1953. [22] Lawrence Rosenblum. 2019. Oxford Research
https://doi.org/10.3758/s13414-021-02267-4 Encyclopedia, Linguistics. In Audiovisual speech
[11] Zahra Khanjani, Gabrielle Watson, and Vandana P. perception and the McGurk effect. ) Oxford
Janeja. 2023. Audio deepfakes: A survey. Front. Big University Press USA.
Data 5, (2023). [23] Andreas Rossler, Davide Cozzolino, Luisa Verdoliva,
https://www.frontiersin.org/articles/10.3389/fdata. Christian Riess, Justus Thies, and Matthias
2022.1001063 Niessner. 2019. FaceForensics++: Learning to
[12] Nils C. Köbis, Barbora Doležalová, and Ivan Detect Manipulated Facial Images. In 2019
Soraperra. 2021. Fooled twice: People cannot detect IEEE/CVF International Conference on Computer
deepfakes but think they can. iScience 24, 11 Vision (ICCV), October 2019. IEEE, Seoul, Korea
(November 2021), 103364. (South), 1–11.
https://doi.org/10.1016/j.isci.2021.103364 https://doi.org/10.1109/ICCV.2019.00009
[13] Kimberly T. Mai, Sergi D. Bray, Toby Davies, and [24] Kelley Sayler and Laurie Harris. 2023. Deepfakes
Lewis D. Griffin. 2023. Warning: Humans Cannot and National Security. Congresssional Research
Reliably Detect Speech Deepfakes. PLOS ONE 18, 8 Service.
(August 2023), e0285333. https://crsreports.congress.gov/product/details?pr
https://doi.org/10.1371/journal.pone.0285333 odcode=IF11333
[14] Yisroel Mirsky and Wenke Lee. 2022. The Creation [25] Kaoru Sekiyama. 1997. Cultural and linguistic
and Detection of Deepfakes: A Survey. ACM factors in audiovisual speech processing: The
Comput. Surv. 54, 1 (January 2022), 1–41. McGurk effect in Chinese subjects. Percept.
https://doi.org/10.1145/3425780 Psychophys. 59, 1 (January 1997), 73–80.
[15] Nicolas M. Müller, Karla Pizzi, and Jennifer https://doi.org/10.3758/BF03206849
Williams. 2022. Human Perception of Audio [26] Vojtech Semecky. 2022. This Beach Does Not Exist.
Deepfakes. In Proceedings of the 1st International https://thisbeachdoesnotexist.com/
Workshop on Deepfake Detection for Audio [27] Jessica Taubert, Deborah Apthorp, David Aagten-
Multimedia, October 14, 2022. ACM, Lisboa Murphy, and David Alais. 2011. The role of holistic
Portugal, 85–91. processing in face perception: Evidence from the
https://doi.org/10.1145/3552466.3556531 face inversion effect. Vision Res. 51, 11 (June 2011),
[16] Ana Cristina Munaro, Renato Hübner Barcelos, 1273–1278.
Eliane Cristine Francisco Maffezzolli, João Pedro https://doi.org/10.1016/j.visres.2011.04.002
Santos Rodrigues, and Emerson Cabrera Paraiso. [28] Raffaele Tucciarelli, Neza Vehar, Shamil Chandaria,
2021. To engage or not engage? The features of and Manos Tsakiris. 2022. On the realness of people
video content on YouTube affecting digital who do not exist: The social processing of artificial
consumer engagement. J. Consum. Behav. 20, 5 faces. iScience 25, 12 (December 2022), 105441.
(2021), 1336–1352. https://doi.org/10.1016/j.isci.2022.105441
https://doi.org/10.1002/cb.1939 [29] Emily Vraga, Leticia Bode, and Sonya Troller-
[17] Jordi Navarra and Salvador Soto-Faraco. 2007. Renfree. 2016. Beyond Self-Reports: Using Eye
Hearing lips in a second language: visual Tracking to Measure Topic and Style Differences in
articulatory information enables the perception of Attention to Social Media Content. Commun.
second language sounds. Psychol. Res. 71, 1 Methods Meas. 10, 2–3 (April 2016), 149–164.
(January 2007), 4–12. https://doi.org/10.1080/19312458.2016.1150443
https://doi.org/10.1007/s00426-005-0031-5 [30] Mason Walker. 2019. Americans favor mobile
[18] Fatemeh Nazarieh, Zhenhua Feng, Muhammad devices over desktops and laptops for getting news.
Awais, Wenwu Wang, and Josef Kittler. 2024. A Pew Research Center.
Survey of Cross-Modal Visual Content Generation. https://www.pewresearch.org/short-
IEEE Trans. Circuits Syst. Video Technol. (2024), reads/2019/11/19/americans-favor-mobile-devices-
1–1. https://doi.org/10.1109/TCSVT.2024.3351601 over-desktops-and-laptops-for-getting-news/
[19] Sophie J. Nightingale and Hany Farid. 2022. AI- [31] Yue Wang, Dawn M. Behne, and Haisheng Jiang.
synthesized faces are indistinguishable from real 2009. Influence of native language phonetic system
faces and more trustworthy. Proc. Natl. Acad. Sci. on audio-visual speech perception. J. Phon. 37, 3
119, 8 (February 2022), e2120481119. (July 2009), 344–356.
https://doi.org/10.1073/pnas.2120481119 https://doi.org/10.1016/j.wocn.2009.04.002
[20] Swaroop Shankar Prasad, Ofer Hadar, Thang Vu, [32] Callum Woods, Zhiyuan Luo, Dawn Watling, and
and Ilia Polian. 2022. Human vs. Automatic Szonya Durant. 2022. Twenty seconds of visual
Detection of Deepfake Videos Over Noisy Channels. behaviour on social media gives insight into
2022 IEEE Int. Conf. Multimed. Expo ICME (July personality. Sci. Rep. 12, 1 (January 2022), 1178.
2022), 1–6. https://doi.org/10.1038/s41598-022-05095-0
https://doi.org/10.1109/ICME52920.2022.9859954 [33] Peipeng Yu, Zhihua Xia, Jianwei Fei, and Yujiang
[21] Q Success. 2023. Usage Statistics and Market Share Lu. 2021. A Survey on Deepfake Video Detection.
of Content Languages for Websites, November IET Biom. 10, 6 (November 2021), 607–624.
2023. W3Techs. https://doi.org/10.1049/bme2.12031
9