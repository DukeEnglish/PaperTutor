HPL-ESS: Hybrid Pseudo-Labeling for Unsupervised
Event-based Semantic Segmentation
LinglinJing1,2*,YimingDing1∗,YunpengGao1,4,ZhigangWang1†,XuYan3,
DongWang1,GeraldSchaefer2,HuiFang2†,BinZhao1,4,XuelongLi1,5
1ShanghaiAILaboratory,2LoughboroughUniversity,3SSE&FNII,CUHK-Shenzhen,
4NorthwesternPolytechnicalUniversity,5InstituteofArtificialIntelligence(TeleAI)
l.jing@lboro.ac.uk, wangzhigang@pjlab.org.cn
Abstract
Ours
Event-basedsemanticsegmentationhasgainedpopular-
ity due to its capability to deal with scenarios under high-
ESS [25]
speed motion and extreme lighting conditions, which can- HALISE [4]
not be addressed by conventional RGB cameras. Since it
is hard to annotate event data, previous approaches rely EV-SegNet [1]
on event-to-image reconstruction to obtain pseudo labels
ESS [25]
for training. However, this will inevitably introduce noise,
and learning from noisy pseudo labels, especially when
E2VID [23]
generated from a single source, may reinforce the errors.
This drawback is also called confirmation bias in pseudo-
labeling. Inthispaper,weproposeanovelhybridpseudo-
Accuracy (%)
labelingframeworkforunsupervisedevent-basedsemantic
segmentation, HPL-ESS, to alleviate the influence of noisy
pseudo labels. Specifically, we first employ a plain un-
Figure 1. Comparison on the DSEC-Semantic dataset. Our
supervised domain adaptation framework as our baseline, methodoutperformsotherUDAworksbyalargemarginandeven
which can generate a set of pseudo labels through self- surpassesfullysupervisedmethods.
training. Then, we incorporate offline event-to-image re-
constructionintotheframework,andobtainanothersetof
pseudo labels by predicting segmentation maps on the re- chronous events characterized by exceptionally high tem-
constructed images. A noisy label learning strategy is de- poral resolution. This technology enables the capture of
signedtomixthetwosetsofpseudolabelsandenhancethe dynamicscenes, providingfeaturesofhighdynamicrange
quality.Moreover,weproposeasoftprototypicalalignment (HDR)andreducedmotionblur. Eventcamerashavebeen
(SPA) module to further improve the consistency of target extensivelyappliedinvariousapplications,includingobject
domainfeatures. Extensiveexperimentsshowthatthepro- recognition [15, 23], SLAM [8], and autonomous driving
posedmethodoutperformsexistingstate-of-the-artmethods systems[19],effectivelyaddressingchallengessuchasmo-
byalargemarginonbenchmarks(e.g., +5.88%accuracy, tionblurandoverexposure.
+10.32%mIoUonDSEC-Semanticdataset),andevensur- However, event data significantly differ from images,
passesseveralsupervisedmethods. makingitdifficulttoannotateindensepixelpredictiontasks
suchassemanticsegmentation. Previousworks[1,31,32]
requireper-pixelpairedeventsandimages,andthenlever-
1.Introduction age pre-trained networks on images to generate labels for
event data. Although a more precisely paired and sharper
Eventcamerasarebio-inspiredvisionsensorsthatrespond
image would naturally yield improved results, these meth-
to changes in pixel intensity, generating a stream of asyn-
odsincreasethedemandsoncapturedevices. Othermeth-
odsrelyonevent-to-imageconversiontogetridoftheneed
*Equalcontribution.
†Correspondingauthor. for ground-truth labels. E2VID [25] is an event-to-image
1
4202
raM
52
]VC.sc[
1v88761.3042:viXra
)%(
UoIm(ETI) reconstruction method to transform events into im- • Extensive experiments on two benchmark datasets
ages, while VID2E [10] employs image-to-event (ITE) in demonstratethatourmethodoutperformspreviousstate-
reverse. Basedontheabovemethods,afeasiblestrategyis of-the-artmethodsbyalargemargin.
to generate pseudo labels from converted images for event
data. ESS[27]furtheremploysunsuperviseddomainadap- 2.RelatedWork
tation (UDA) to transfer knowledge from labeled image
2.1.Event-basedSemanticSegmentation
data (source domain) to unlabeled event data (target do-
main)throughthebridgeofevent-to-imagereconstruction.
Using deep learning, [1] first introduces event cameras to
Despite improvements, reconstruction-based methods thesemanticsegmentationtask,withanarchitecturebased
suffer from the limitation that, due to the lack of texture onanencoder-decoderCNN,pre-trainedonthewell-known
informationineventdata,thereconstructedimagesusually urbanenvironmentCityscapesdataset[6]. Anopendataset,
have large fuzzy regions, inevitably introducing noise into DDD17, containing annotated DAVIS driving records for
the generated pseudo labels. Training on noisy pseudo la- this task is released in [3]. [10] enables the use of ex-
bels has the risk of reinforcing the errors, especially when isting video datasets by transforming them into synthetic
they are obtained from a single source, a problem that is eventdata,facilitatingthetrainingofnetworksdesignedfor
knownasconfirmationbias[2]inpseudo-labeling. real event data. Despite its capacity to leverage an unlim-
To alleviate the bias of single-source pseudo labels, in itednumberofvideodatasets,challengespersistduetothe
thispaper,weproposeHPL-ESS,ahybridpseudo-labeling sim-to-realgapinmanysimulatedscenarios. [32]employs
frameworkforunsupervisedevent-basedsemanticsegmen- two student networks for knowledge distillation from the
tation. Our method is built upon a modified UDA frame- image to the event domain. However, the method heavily
work, which executes self-training on the mixture of un- depends on per-pixel paired events and active pixel sen-
pairedimagesandeventdata. Theframeworkhastheabil- sor (APS) frames. Consequently, in scenarios where APS
itytogenerateasetofpseudolabelsbydirectlypredicting framesareunavailable,theapplicationofsuchaknowledge
theeventdata. Simultaneously,weintroduceofflineevent- distillation approach becomes significantly restricted. [31]
to-image reconstruction into the framework, which gener- substitutes the active pixel sensor modality with grayscale
ates another set of pseudo labels by predicting the recon- imagesgeneratedbyE2VID[25],transferringthesegmen-
structed images. Through training on these hybrid pseudo tationtaskfromtheeventdomaintotheimagedomain. Re-
labels,thenetworkcanprogressivelyimproveitsabilityto cently,ESS[27]addressesevent-basedsemanticsegmenta-
directlypredictmoreaccuratelabelsforeventdata.Tograd- tion by introducing the DSEC-Semantic dataset, which re-
ually mitigate the impact of low-quality reconstructed im- liesonpairedhigh-resolutionimagesandevents, thuspro-
agesduringtraining,weapproachthischallengeasanoisy vidinghigh-qualitysemanticlabelsforeventstreams. ESS
label learning (NLL) problem. In this context, we distin- also introduces an event-to-image-based UDA method to
guishbetweennoisydata(reconstructedimages)andclean transfer knowledge from the source image domain to the
data (original events). Then, we introduce a noisy-label targeteventdomain.
adaptation process to further refine pseudo labels at each
2.2.UnsupervisedDomainAdaptation
iteration. Inaddition,duetothelargedomaingapbetween
imageandevent,thenetworkispronetoproducedispersed
Unsuperviseddomainadaptation(UDA)approachescanbe
featuresinthetargetdomain[10]. Tocounteractthisissue,
divided into two key methodologies: domain adversarial
wealsodesignasoftprototypicalalignment(SPA)module
learningandself-training. Domainadversariallearningfo-
tolearntheintrinsicstructureofthetargetdomainandad-
cuses on aligning feature distributions across domains [9]
dressthedispersionoftargetfeatures. AsillustratedinFig-
but does not inherently ensure the discriminative power of
ure 1, the proposed method is very effective, outperform-
targetfeatures[18]. Incontrast,self-trainingcapitalizeson
ingotherstate-of-the-artUDAapproachesbyalargemargin
a model’s high-confidence predictions to bolster the per-
andevensurpassingseveralfullysupervisedmethods.
formance within the target domain. This approach signif-
Insummary,ourcontributionsinthispaperare: icantlyalleviatesthedomainshiftissuebyiterativelyalign-
• Weproposeahybridpseudo-labelingframeworkforun- ing the feature distribution of the target domain to match
supervised event-based semantic segmentation. This that of the source domain, which proves to be particularly
frameworkgetsridofevent-to-imagepairsandisrobust effective in scenarios where obtaining labels for the target
tonoisypseudolabels. domain is challenging. In this context, strategies such as
• Wedesignasoftprototypicalalignment(SPA)moduleto leveraging domain-invariant features [5, 12, 17], pseudo-
enforcethenetworktogenerateconsistenteventfeatures labeling [36, 38], intermediate domains [16, 21, 30], and
under the same class, forming a more compact feature consistency regularisation [13] have been used. We con-
spaceinthetargetdomain. siderthatunderasimilartaskandscenario, eventdatacan
2Source Train Only
Image Hybrid Pseudo
Labeling
Student Train and
Network Inference
Recon.
Image
Weighted
Aggregation
OffLine E2VID EMA
Soft Prototypical
Alignment (SPA)
Cross-Entropy
Target Loss
Events JS Divergence
Teacher
Logits
Network
Target
Stop Gradient
Events Pseudo-
Labels
Figure 2. Overview of the HPL-ESS architecture. During training, we introduce offline event-to-image reconstruction as input to our
framework. To avoid overfitting noise, we use only a small proportion (5%) of the reconstructions. The network is trained by hybrid
pseudolabelsfromreconstructionandself-prediction.Additionally,asoftprototypicalalignment(SPA)moduleisdesignedtoenhancethe
consistencyoftargetdomainfeatures.Intheinferencephase,onlyeventsareusedasinput.
also be drawn close to RGB images semantically through tamp,andpindicatesthebinarypolarity(positiveornega-
theapplicationofUDAmethods. tive) of brightness changes occurring between two times-
tamps. Due to the high temporal resolution of E , we sub-
i
3.Method sampleE intoasequenceofvoxelgridrepresentations[37],
i
whereeachvoxelgridisconstructedfromnon-overlapping
As illustrated in Figure 2, the proposed HPL-ESS frame-
temporalwindowswithafixednumberofevents.Theseare
workincorporatesself-trainingUDAtechniques,described
theneffectivelysuperimposedtoformastaticframe.
in Section 3.2, and employs offline event-to-image recon-
structiontogeneratehybridpseudolabels,coveredinSec- 3.2.UDAFrameworkOverview
tion 3.3. To gradually mitigate the impact of low-quality
We modify DaFormer [14] as the backbone and baseline
andblurredareasinoffline-reconstructedimages,weintro-
for our event-based semantic segmentation UDA method.
duceanoisylabellearning(NLL)methodtorefinepseudo
The framework is composed of two networks: a teacher
labels. We further propose a soft prototypical alignment
network F and a student network F . Other modules in
(SPA) module to explore the intrinsic structure of event ϕ ψ
DaFormer are eliminated to ensure the simplicity and effi-
data,alleviatingtheimpactoffeaturedivergenceasdetailed
ciencyofourmethod.Tofacilitateknowledgetransferfrom
inSection3.4.
thesourcedomaintothetargetdomain,themodifiedbase-
3.1.DefinitionsandProblemFormulation line is trained using the mixed data of labeled images and
unlabeled events. To be specific, in our work, the student
In a UDA framework for event-based semantic segmenta-
network F first conducts warm-up by being trained with
ψ
tion, a neural network F is usually trained from labeled
thesupervisedlossonthesourceimagedomain
source dataset S = {I ,Y }M to transfer to an unlabeled
i i i=1
t mar ag inet Sda cta os ne st isT
ts
o=
f
i{ mE ai g} eN i= s1 I.
i
S ∈pe Rci Hfic ×a Wlly, anth de thso eu irrc ce ord ro e-
-
L s(F
ψ
|S)= |S1 |(cid:88)|S| H(F ψ(I i),Y i), (1)
spondinglabelsY ∈RH×W.Incontrast,thetargetdomain i=1
i
T consistsofnumerouscontinuousandasynchronousevent where H denotes the cross entropy function. Correspond-
streamsE andwithouthavingaccesstothetargetlabelsV . ingly, the parameters of the teacher network are updated
i i
Each event stream E can be represented as a series of tu- using the exponential moving average (EMA) [29] from
i
ples{(x ,y ,t ,p )},wherejdenotesthesampleindex,x, the student model to maintain stability. After warm-up,
j j j j
andydenotethespatialco-ordinates,trepresentsthetimes- the framework follows a self-training strategy, where the
3teachernetworkdirectlypredictstheeventdatatogenerate Source Images
pseudo labels for the training of the student model. This
processisrepeateduntilthenetworkshaveconverged.
In addition, augmentation methods, such as jitter and
ClassMix [22], are used on both events and images to im-
prove the method’s availability across domains. Although
self-training UDA is usually an effective technique, it is Distance: Distance:
challenging to obtain satisfactory results due to the large
domain gap between images and events. Furthermore, it
All Class Prototypes
suffersfromtheaforementionedsingle-sourcenoisypseudo
labels. JS( | )
3.3.HybridPseudo-Labeling
To address the above issues, we consider the E2VID [26] Target Events Reconstructed Image
method to reconstruct the event streams into simulated
images, which are then incorporated into our framework
Figure3. TheconceptofourSPAmoduleonsourcedomain,re-
as an intermediate domain to narrow down the gap be- constructedimages,andevents.
tween the source image domain and the target event do-
main. Thereconstructedimagesalsoprovideanothersetof
pseudo labels to alleviate the bias of single-source pseudo problemandexplicitlyregardF ψ(I il)asanoisylabelofthe
labels. Inparticular,werandomlysampletheeventdataset events E il. Inspired by [35], we employ a label correction
T = {E }N to create two groups, T = (cid:8) El(cid:9)a and strategybasedonself-predictiontomitigatethenoiseissue.
i i=1 l i i=1
T = {Eu}b , where a+b = N. Event streams El are Thisstrategyadaptsthenoisydistributionfromthepseudo-
u i i=1 i ground-truth F (Il) to the view of the event distribution.
reconstructedintosimulatedimagesIl as ψ i
i Specifically,foreachEl,wereconstructtherefinedpseudo
i
I il =E2VID(cid:0) E il(cid:1) . (2) labelVˆ il bycombiningF ψ(I il)andtheF ϕ(E il)as
Now, the inputs to the student network encompass source Vˆl =(1−α)F (Il)+αF (El), (4)
imagesI ,unlabeledeventsEu,unlabeledeventsElandthe i ψ i ϕ i
i i i
correspondingreconstructedimagesI il. Notably,wedonot withratioα. Then,themodifiedlossL
l
forE il is
reconstructalleventstreamsintosimulatedimagestoavoid
the An set iw llo ur sk trao tv ee drfi intti Fn ig guth rees 2e ,n tho eisy stud dat ea n. tnetworkF ψ takes L l(F ψ |T l)= |T1 |(cid:88)|Tl| H(cid:16) F ψ(cid:0) E il(cid:1) ,Vˆ il(cid:17) . (5)
the reconstructed image Il as input and generates the pre- l i=1
i
dictedprobabilitymap.ThismapisthenutilizedasF ψ(I il), During training, the teacher network progressively gener-
thepseudo-ground-truthforEl. Simultaneously, similarto atesmoreaccurateF (El),graduallyweakeningtheimpact
i ϕ i
the self-training backbone, event data Eu and El are input ofF (Il).
i i ψ i
to the teacher network F to obtain the direct pseudo la-
ϕ
belsF (Eu)andF (El). ForEu,thestudentnetworkF is 3.4.SoftPrototypicalAlignment
ϕ i ϕ i i ψ
trainedwiththesupervisedlossL ucalculatedas Byemployingman-madepairedElandIltobridgetheim-
i i
agedomainandeventdomain,weaimtoenhancethealign-
L u(F
ψ
|T u)= |T1
u|(cid:88)|Tu|
H(F ψ(E iu),F ϕ(E iu)). (3) m ase ant pb see utw doee -ln abth ee lmso au yrc se tia lln nd ot tar bg ee at. bH leo tw oe sv oe lvr, eu ts hi eng diF sψ tr( ibI uil)
-
i=1
tionmisalignmentbecauseoftheobviousdifferencesinthe
For E il, F ϕ(E il) together with the event pseudo-ground- distributions of I il and E il. Inspired by [36], we propose a
truthF ψ(I il)constitutesthehybridpseudolabels. softprototypicalalignment(SPA)moduletoexplicitlyalign
The event-to-image reconstruction process suffers from thedistributionsforourproblem. AsillustratedinFigure3,
limited interpretability and a lack of control, leading to weemploythe meanvalueF (I ) ofeachclass onsource
ψ i
low-quality reconstructed images I il, e.g., incorrect con- images asprototypes η and aimto align theprototype dis-
tent and blurred areas. Predicting semantic segmentation tance between F (Il) and F (El). The distance between
ψ i ψ i
maps on these images and viewing them as pseudo labels F (Il)andηiscalculatedas
ψ i
will inevitably introduce significant noise. Directly us-
i mng ant ch ee .m Td hu er ri en fg ort era ,i wni eng trm eaa ty thr ie ssu al st ain ns ou ib sy-op lat bim elal lep ae rr nf io nr g- Z i(I) = (cid:80)ex ep xp(cid:0) − (cid:0) −(cid:13) (cid:13)F (cid:13) (cid:13)Fψ ψ(cid:0) I (cid:0)il I(cid:1) il(cid:1)− −η(cid:13) (cid:13) η(cid:13) (cid:13)/τ /(cid:1) τ(cid:1), (6)
4where τ is the coefficient temperature. Similarly, the dis- DSEC dataset [11]. It includes 53 driving sequences
tancebetweenF (El)andηiscalculatedas captured by an event camera at a resolution of 640 ×
ψ i
480. [27] used a state-of-the-art image-based segmenta-
Z i(E) = (cid:80)ex ep
xp(cid:0)
− (cid:0)
−(cid:13)
(cid:13)F (cid:13) (cid:13)Fψ
ψ(cid:0)
E (cid:0)i
El(cid:1)
il(cid:1)−
−η(cid:13)
(cid:13) η(cid:13) (cid:13)/τ
/(cid:1)
τ(cid:1). (7) t ci eo sn sm yie et lh do sd 8,[ 02 88 2]t lo abg ee ln eder ta rt ae ins ie ng gm se an mta pt li eo sn al na dbe 2l ,s 8. 0T 9h ti es sp tir no g-
samples,distributedacross11classes: sky,building,fence,
We use the Jensen-Shannon (JS) divergence [7] instead of
person, road, pole, sidewalk, vegetation, vehicle, wall, and
KLdivergenceusedin [24]fordistributionalignmentdue
trafficsign.
to the symmetry of JS divergence. This ensures an equal
As source data, we use the CityScapes street scene
pulling effect on the distributions of F (Il) and F (El).
ψ i ψ i dataset [6], which includes 2,975 training and 500 valida-
TheJSdivergencelossiscalculatedas
tion images with a resolution of 2048×1024. Following
LS =JS(cid:16) Z(I)∥Z(E)(cid:17) , (8) commonpracticeinUDAmethods,weresizetheCityScape
JS i i imagesto1024×512pixels.
and compels the network to generate consistent event fea-
4.2.ImplementationDetails
turesandimagefeaturesforElandIlunderthesameclass.
i i
Additionally,ElandEuarenottrainedwiththesameset In our experiments, we employ DaFormer [14] as our
i i
of pseudo labels, making the target distributions of El and UDA backbone. The encoder in Daformer uses an MiT-
i
Eu morelikelytobedispersed. Insuchascenario,thenet- B5model[34]andispre-trainedonImageNet-1K.Across
i
workfailstorectifythelabelsoftargetdatalocatedatthefar all experiments, the batch size is consistently set to 4. We
end of the class cluster. Considering that the distributions usetheAdamWoptimizerwithaweightdecayof1×10−4.
ofF (El)andF (Eu)belongtothesamescene,theirdis- Thelearningrateissetto6×10−5 andweusealearning
ψ i ψ i
tributionsareexpectedtoexhibitsimilarrelativedistances. ratewarm-upfor1,500iterations, withalinearincreasein
Toachievethis,wefurtheremploythemeanvalueofeach thelearningrateduringthisperiod. Weadditionallywarm-
classinF (Il)asaprototype. Wethenbringintherelative up for 5,000 iterations on the source dataset to make the
ψ i
distances of F (El) and F (Eu) to F (Il), respectively. networkgaintheinitialsemanticsegmentationability. αin
ψ i ψ i ψ i
Employing a methodology akin to Eqns. (6), (7), and (8), Eq.4andωinEq.9arebothsetto0.5. Fordataaugmenta-
weobtainLI thatformsamorecompactfeaturespacein tioninbothsourceandtargetdomains, wefollow[14,33]
JS
thetargetdomain. and employ techniques such as color jitter, Gaussian blur,
Theoveralllossinourframeworkisdefinedas and ClassMix [22]. These augmentations are instrumental
in training the model to learn more robust features across
L=L +L +L +ω(LS +LI ), (9)
s u l JS JS differentdomains.
whereωdenotesahyper-parameter. In the event-to-image simulation process, Spade
E2VID[25]isemployedasouremulatorforreconstruction.
4.Experiments Thisstepoccurssolelyintheofflinephase,ensuringthatit
does not impact the efficiency of our online training and
4.1.Dataset
testingprocess. ItisworthnotingthatE2VIDwillprogres-
sivelyproduceexpandingblackartifactsiffedwithdiscon-
As target data, we evaluate the proposed framework on
tinuouseventinputs. Tomitigatethisproblem,wereinitial-
two event-based semantic segmentation datasets, namely
izetheE2VIDnetworkeachtimeanimageisreconstructed,
DSEC-Semantic [11] and DDD17 [3]. These driving-
preventing the occurrence of such artifacts. Regarding the
focussed datasets were captured using automotive-grade
eventpre-processingontheDDD17dataset,eventsarecon-
eventcameras,encompassingadiverserangeofurbanand
vertedinto20voxelgrids,witheachgridcontaining32,000
ruralsettings.
events. For the DSEC-Semantic dataset, due to its higher
The DDD17 dataset comprises per-pixel paired events
resolution,thenumberofvoxelgridsisincreasedto40,and
andframescapturedbyDAVISeventcameraswithareso-
eachgridcomprises100,000events.
lutionof346×260. In[1],semanticlabelsweregenerated
using pre-trained segmentation networks based on DAVIS
4.3.ComparisonwithState-of-the-Art
images, resultingin15,950samplesfortrainingand3,890
fortesting. Duetothelowresolution,severalcategoriesin Wecompareourmethodwithpreviousrelevantapproaches,
DDD17havebeenmergedintosixclasses,namelyflat(road and use the top-1 accuracy and the mean intersection over
andpavement),background(constructionandsky),object, union(mIoU)asthecommonsemanticsegmentationeval-
vegetation,human,andvehicle. uationmetrics. BeyondUDAmethods, certainapproaches
DSEC-Semantic,arecentlyintroduceddatasetforevent- haveembracedafullysupervisedsettingtotacklethechal-
based semantic segmentation, extends the comprehensive lenges. EV-SegNet[1]presentsthefirstbaselineforevent-
5Table1.PerformanceandnecessarynumberofeventsonDSEC-SemanticdatasetinbothUDAandfullysupervisedlearningsettings.
Type Method No. ofEvents Accuracy[%] mIoU[%]
Supervised EV-SegNet[1] - 88.61 51.76
HALISE[4] - 89.01 52.43
ESS[27] 2E6 89.37 53.29
UDA EV-Transfer[20] 2E6 60.50 23.20
E2VID[25] 2E6 76.67 40.70
ESS[27] 2E6 84.04 44.87
Ours 1.8E5(↓91.0%) 89.92(+5.88%) 55.19(+10.32%)
based semantic segmentation, which employs an encoder- significantimprovement,outperformingthepreviousstate-
decoder architecture and takes only events for fully su- of-the-artUDAworkESSby5.87%and9.65%intermsof
pervised learning. HALISE [4] encodes event frames and accuracyandmIoU,respectively. Notably,ourUDA-based
source images into a spike stream, representing informa- methodevensurpassestheperformanceoffullysupervised
tion in a binarised manner, and aligns the feature distribu- approaches by 0.55% in terms of accuracy and 1.9% in
tioninthesespikestreams. EV-Transfer[20]fabricatesthe terms of mIoU. Since this is a highly imbalanced dataset,
motionofastillimagetogenerateeventstreams,andthen the gain in mIoU is more representative in the segmenta-
usessourcelabelsandthecorrespondingsyntheticeventsto tiontask. Inaddition,bysolelyutilizingtheE2VIDrecon-
conducttraining. E2VID[25]convertseventsintheDSEC- struction method offline, our approach avoids dependency
Semantic dataset to reconstruct images, and then predicts on recurrent networks in E2VID during both training and
semantic segmentation maps using other pre-trained mod- inference, significantly reducing the required input events
els. E2VID can only perform direct transfer as there is from 2E6 to 1E5 (a 95% reduction). These enhancements
no event label for training. VID2E [10] converts source remarkablyprovetheeffectivenessandcomputationaleffi-
video frames to synthetic events and trains on the source ciencyofourproposedmethod.
labels. ESS [27] employs the above E2VID-based process Some example results are visualized in Figure 5. The
to generate pseudo-labels and attempts to transfer knowl- background of the reconstructed image exhibits fuzzy re-
edgefromthesourceimagedomaintothetargeteventdo- gions and low resolution, which inevitably poses signifi-
main by the UDA technique. While methods employing cant challenges to semantic segmentation Networks. For
supervisedlearningmayachievesuperiorresultscompared instance, due to the lack of texture information in events,
totraditionalUDAapproaches,theirrelianceonlabelssig- the reconstructed sky category appears very similar to the
nificantlyelevatesthedemandsfordatasetcollection. buildingcategoryintermsofcontrastandedgeinformation,
DSEC-Semantic dataset. We employ the CityScape leadingtopotentialmisinterpretationofthemodel’spredic-
dataset as the labeled source dataset and the DSEC- tions(asindicatedbytheredarrow). Theproposedhybrid
Semantic dataset as the unlabeled target dataset. This pseudo-labelingmethodeffectivelymitigatestheseinterfer-
dataset poses additional challenges due to its more fine- encefactorsinreconstructedimages,resultinginimproved
grained categories compared to the DDD17 dataset. We performance.
reporttheobtainedresultsforallmethodsinTable1. DDD17 dataset. Table 2 reports the UDA results on
As we can see from there, our method demonstrates a theDDD17datasetforevent-basedsemanticsegmentation.
Similar to the DSEC-Semantic dataset, only labeled im-
agesfromCityScapeandunlabeledeventsfromDDD17are
Event Frame Ours Ground Truth
available in this task. Table 2 showcases that our method
achievesconsistentoptimalresults, outperformingthepre-
vious state-of-the-art work by 1.05% (mIoU) and 0.79%
(accuracy),respectively.
SincetheeventgroundtruthinDDD17isderivedfrom
the low-quality paired images, this significantly impacts
thereliability,especiallyconcerningtexturedetails,asalso
mentioned in [27]. As Figure 4 illustrates, our predictions
even surpass the ground truth in object details. Taking the
firstlineinFigure4asanexample, intheyellowbox, our
Figure4.ExampleresultsonDDD17dataset.TheDDD17ground network better separates the details of the trees and street-
truthlacksdetailsforsomeobjects. lights,whicharemissingintheDDD17groundtruth. Sim-
6Figure 5. Visualization results on DESC-Semantic dataset. From left to right: event frame, event-to-image reconstruction, the maps
predictedbyE2VID,ESS,andourproposedHPL-ESS,groundtruth.
Table2. PerformancecomparisonofHPL-ESSwithstate-of-the- Designanalysisofourframework.Weconductseveral
artmethodsonDDD17datasetinUDAsetting.Onlysourcelabels ablationstudiestoassesstheeffectivenessoftheproposed
areavailable.
framework. As depicted in Table 3, (a) directly applying
theUDAbaselinealonedoesnotyieldsatisfactoryresults,
Method Accuracy[%] mIoU[%]
likely due to the substantial domain gap between the im-
EV-Transfer[20] 47.37 14.91
age and event domains. Similarly, (b) training directly on
E2VID[25] 83.24 44.77
theevent-to-image(ETI)reconstructedimagesfromE2VID
VID2E[10] 85.93 45.48
alsoresultsinunsatisfactoryperformance. Thisresultveri-
ESS[27] 87.86 52.46
fiestheaforementioneddiscussion,namelyevent-to-image-
Ours 88.65(+0.79%) 53.51+(1.05%)
based methods will suffer from the noise brought by the
reconstructedimage. Both(a)and(b)highlighttheunreli-
abilityofsolelyrelyingonthesingle-sourcepseudolabels
ilarly, in the second line, our method segments more cor-
and emphasize the necessity for hybrid label learning. An
recttrees,whiletheDDD17groundtruthmisclassifiestrees
intriguingobservationisthat(c)employingthesourcedata
withsky. Thisdiscrepancycouldpotentiallylowerourper-
to pre-train the network for a certain number of iterations,
formance during evaluation. Due to the higher resolution
i.e., usingawarmupphase, significantlyenhancestheper-
andqualityoftheDSEC-Semanticdataset,weoptedforthis
formance. In (d), our method is based on source domain
datasettoevaluateourmethodandcomparisonworks.
warm-up,andasdescribedinSection3,theE2VIDrecon-
structedimagesareintroducedontopoftheUDAbackbone
4.4.ComprehensiveAnalysis
to provide the hybrid pseudo labels for events, leading to
considerableperformancegains.
SinceDSEC-Semanticisahigher-qualitydataset, allabla-
tionexperimentsareconductedonDSEC-Semantic. We further validate the effectiveness of the proposed
7Table3.AblationsstudyonDSEC-Semanticdataset. Table 5. Ablation study for online and offline reconstruction
pseudolabels.
Method Baseline ETI Warmup NLL SPA mIoU[%]
(a) ✓ 36.76 Method Accuracy[%] mIoU[%]
(b) ✓ 40.70
OffLine 83.25 48.45
(c) ✓ ✓ 44.87
(d) ✓ ✓ ✓ 51.08 OnLine 89.92 55.19
(e) ✓ ✓ ✓ ✓ 52.23
(f) ✓ ✓ ✓ ✓ 52.69
HPL-ESS ✓ ✓ ✓ ✓ ✓ 55.19 erativelyrepredictingthembyournetworkduringtraining.
As shown in Table 5, the online reprediction strategy re-
Table4.Ablationstudyfortheproportionofeventsamplespartic- markably surpasses the offline fixing strategy, demonstrat-
ipatingintheevent-to-imagereconstruction. ingthatourmethodbecomesmorepowerfulduringtraining
andcanpredictmoreaccuratereconstructionpseudolabels
Proportion Accuracy[%] mIoU[%]
foreventdata.
0% 82.71 44.87
1% 86.54 46.84
5.DiscussionandLimitation
5% 89.91 55.19
10% 89.89 55.15
Due to the imbalance issue presented in the benchmark
50% 89.81 54.96
datasets, the accuracy performance of classes with insuf-
80% 89.75 54.82
ficient samples, e.g., ’rider’ and ’traffic light,’ is compara-
100% 89.63 54.51
tively lower than the accuracy of some other classes, e.g.,
skyandroad. Theseresultsareillustratedinthevisualiza-
tion examples in Supplementary Materials. Despite that
NLLstrategyandSPAmodule. AsshowninTable3,NLL
ourapproachyieldssignificantimprovementfortheclasses
reducesthenoiseofpseudo-labelsonreconstructedimages
withasmallnumberofsampleswhencomparedtoprevious
throughiterativelabelrefinement,makingitmoreadaptive
methods, we will further consider more strategies to deal
to the event domain and resulting in a performance gain.
withthedataimbalanceissueinthefuturework.
SPA prioritizes the divergence of various features on the
target domain and aligns the labeled and unlabeled events
6.Conclusion
withthesourcedomainprototype,contributingtoenhanced
evaluation performance. Ultimately, the simultaneous in-
In this paper, we have proposed a novel hybrid pseudo-
troductionofthesetwomodulesinourframeworkleadsto
labelingframeworkHPL-ESSforunsupervisedevent-based
optimalperformance.
semanticsegmentation. HPL-ESSeffectivelyalleviatesthe
Proportion of reconstructed event samples. In our challenges posed by noisy pseudo labels, a common is-
framework, we do not transform all event data into re- sue in this field. The proposed method uniquely incorpo-
constructed images to avoid overfitting the reconstruction rates self-training unsupervised domain adaptation and of-
noise. Infact,asdemonstratedinTable4,theoptimalresult flineevent-to-imagereconstructiontogeneratehigh-quality
isachievedwhenusingonly5%oftheeventdatatogener- hybrid pseudo labels. The introduction of a noisy label
ate the reconstructed images as the pseudo labels. Perfor- learningstrategyfurtherrefinesthepseudolabelsgradually.
mance experiences a slight decline as more reconstructed Moreover,asoftprototypicalalignment(SPA)modulesig-
images are introduced. Particularly, when using 100% of nificantlyenhancestheconsistencyandreliabilityofthetar-
the data, it results in an mIoU drop to 54.51%. The lower getfeatures. TheeffectivenessofHPL-ESSisevidencedby
dependenceonthenumberofreconstructedimagesalsoun- itssuperiorperformanceinextensiveexperiments,whereit
derscores the remarkable computational efficiency of our not only surpasses existing state-of-the-art UDA methods
method during training. Further reduction of the ratio, be- butalsoexceedsseveralsupervisedmethods.
low 5%, leads to progressively worse performance, reach-
ingitslowest pointata0% ratioandrevertingbackto the
7.Acknowledgments
UDAbackbone.
Online/Offline reconstruction pseudo label. Offline ThisworkissupportedbytheShanghaiAILaboratory,Na-
event-to-imagereconstructionenablesustodirectlypredict tionalKeyR&DProgramofChina(2022ZD0160101),the
thereconstructedimageusingapre-trainednetworkandget NationalNaturalScienceFoundationofChina(62376222),
pseudo labels for event data, which are named reconstruc- andYoungEliteScientistsSponsorshipProgrambyCAST
tion pseudo labels here. In this section, we compare the (2023QNRC001). This work is supported by 111 Project
effects of fixing these reconstruction pseudo labels and it- (No. D23006).
8References [13] Cheng-An Hou, Yao-Hung Hubert Tsai, Yi-Ren Yeh, and
Yu-Chiang Frank Wang. Unsupervised domain adaptation
[1] Inigo Alonso and Ana C Murillo. Ev-segnet: Semantic
withlabelandstructuralconsistency. IEEETransactionson
segmentation for event-based cameras. In Proceedings of
ImageProcessing,25(12):5552–5562,2016. 2
theIEEE/CVFConferenceonComputerVisionandPattern
[14] LukasHoyer, DengxinDai, andLucVanGool. Daformer:
RecognitionWorkshops,pages0–0,2019. 1,2,5,6
Improving network architectures and training strategies for
[2] EricArazo, DiegoOrtego, PaulAlbert, NoelE.O’Connor,
domain-adaptivesemanticsegmentation. InProceedingsof
and Kevin McGuinness. Pseudo-labeling and confirmation
theIEEE/CVFConferenceonComputerVisionandPattern
biasindeepsemi-supervisedlearning.In2020International
Recognition,pages9924–9935,2022. 3,5
Joint Conference on Neural Networks, IJCNN 2020, Glas-
[15] LinglinJing,YifanWang,TailinChen,ShirinDora,Zhigang
gow, United Kingdom, July 19-24, 2020, pages 1–8, 2020.
Ji,andHuiFang.Towardsamoreefficientfew-shotlearning-
2
basedhumangesturerecognitionviadynamicvisionsensors.
[3] Jonathan Binas, Daniel Neil, Shih-Chii Liu, and Tobi Del-
InBMVC,page938,2022. 1
bruck. Ddd17: End-to-end davis driving dataset. arXiv
[16] Linglin Jing, Ying Xue, Xu Yan, Chaoda Zheng, Dong
preprintarXiv:1711.01458,2017. 2,5
Wang,RuimaoZhang,ZhigangWang,HuiFang,BinZhao,
[4] Shristi Das Biswas, Adarsh Kosta, Chamika Liyanaged-
andZhenLi.X4d-sceneformer:Enhancedsceneunderstand-
era, Marco Apolinario, and Kaushik Roy. Halsie–hybrid
ingon4dpointcloudvideosthroughcross-modalknowledge
approach to learning segmentation by simultaneously ex-
transfer. arXivpreprintarXiv:2312.07378,2023. 2
ploiting image and event modalities. arXiv preprint
[17] Huafeng Li, Yiwen Chen, Dapeng Tao, Zhengtao Yu, and
arXiv:2211.10754,2022. 6
Guanqiu Qi. Attribute-aligned domain-invariant feature
[5] Manh-HaBui,ToanTran,AnhTran,andDinhPhung. Ex-
learning for unsupervised domain adaptation person re-
ploitingdomain-specificfeaturestoenhancedomaingener-
identification. IEEETransactionsonInformationForensics
alization. AdvancesinNeuralInformationProcessingSys-
andSecurity,16:1480–1494,2020. 2
tems,34:21189–21201,2021. 2
[18] FengmaoLv,JunZhu,GuowuYang,andLixinDuan. Tar-
[6] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo
gan: Generating target data with class labels for unsuper-
Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe
vised domain adaptation. Knowledge-Based Systems, 172:
Franke, Stefan Roth, and Bernt Schiele. The cityscapes
123–129,2019. 2
datasetforsemanticurbansceneunderstanding.InProceed-
ingsoftheIEEEconferenceoncomputervisionandpattern [19] Ana I Maqueda, Antonio Loquercio, Guillermo Gallego,
recognition,pages3213–3223,2016. 2,5 NarcisoGarc´ıa,andDavideScaramuzza.Event-basedvision
meets deep learning on steering prediction for self-driving
[7] ErikEnglessonandHosseinAzizpour. Generalizedjensen-
cars. In Proceedings of the IEEE conference on computer
shannon divergence loss for learning with noisy labels.
Advances in Neural Information Processing Systems, 34: visionandpatternrecognition,pages5419–5427,2018. 1
30284–30297,2021. 5 [20] Nico Messikommer, Daniel Gehrig, Mathias Gehrig, and
[8] GuillermoGallego,JonEALund,EliasMueggler,HenriRe- Davide Scaramuzza. Bridging the gap between events and
becq,TobiDelbruck,andDavideScaramuzza. Event-based, frames through unsupervised domain adaptation. IEEE
6-dofcameratrackingfromphotometricdepthmaps. IEEE RoboticsandAutomationLetters,7(2):3515–3522,2022. 6,
transactions on pattern analysis and machine intelligence, 7
40(10):2402–2412,2017. 1 [21] Jaemin Na, Heechul Jung, Hyung Jin Chang, and Wonjun
[9] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pas- Hwang. Fixbi: Bridging domain spaces for unsupervised
cal Germain, Hugo Larochelle, Franc¸ois Laviolette, Mario domain adaptation. In Proceedings of the IEEE/CVF con-
Marchand,andVictorLempitsky. Domain-adversarialtrain- ference on computer vision and pattern recognition, pages
ing of neural networks. The journal of machine learning 1094–1103,2021. 2
research,17(1):2096–2030,2016. 2 [22] Viktor Olsson, Wilhelm Tranheden, Juliano Pinto, and
[10] DanielGehrig, MathiasGehrig, JavierHidalgo-Carrio´, and LennartSvensson. Classmix:Segmentation-baseddataaug-
Davide Scaramuzza. Video to events: Recycling video mentation for semi-supervised learning. In Proceedings of
datasetsforeventcameras. InProceedingsoftheIEEE/CVF theIEEE/CVFWinterConferenceonApplicationsofCom-
Conference on Computer Vision and Pattern Recognition, puterVision,pages1369–1378,2021. 4,5
pages3586–3595,2020. 2,6,7 [23] GarrickOrchard, CedricMeyer, RalphEtienne-Cummings,
[11] MathiasGehrig,WillemAarents,DanielGehrig,andDavide ChristophPosch,NitishThakor,andRyadBenosman.Hfirst:
Scaramuzza. Dsec: Astereoeventcameradatasetfordriv- A temporal approach to object recognition. IEEE transac-
ingscenarios. IEEERoboticsandAutomationLetters,6(3): tionsonpatternanalysisandmachineintelligence, 37(10):
4947–4954,2021. 5 2028–2040,2015. 1
[12] Boqing Gong, Kristen Grauman, and Fei Sha. Connecting [24] Yingwei Pan, Ting Yao, Yehao Li, Yu Wang, Chong-Wah
thedotswithlandmarks: Discriminativelylearningdomain- Ngo, and Tao Mei. Transferrable prototypical networks
invariant features for unsupervised domain adaptation. In for unsupervised domain adaptation. In Proceedings of
International conference on machine learning, pages 222– the IEEE/CVF conference on computer vision and pattern
230.PMLR,2013. 2 recognition,pages2239–2247,2019. 5
9[25] Henri Rebecq, Rene´ Ranftl, Vladlen Koltun, and Davide optical flow, depth, and egomotion. In Proceedings of
Scaramuzza.Highspeedandhighdynamicrangevideowith theIEEE/CVFConferenceonComputerVisionandPattern
aneventcamera. IEEEtransactionsonpatternanalysisand Recognition,pages989–997,2019. 3
machineintelligence,43(6):1964–1980,2019. 1,2,5,6,7 [38] Yang Zou, Zhiding Yu, BVK Kumar, and Jinsong Wang.
[26] Henri Rebecq, Rene Ranftl, Vladlen Koltun, and Davide Unsuperviseddomainadaptationforsemanticsegmentation
Scaramuzza.Highspeedandhighdynamicrangevideowith via class-balanced self-training. In Proceedings of the Eu-
aneventcamera.IEEETransactionsonPatternAnalysisand ropeanconferenceoncomputervision(ECCV),pages289–
MachineIntelligence,page1964–1980,2021. 4 305,2018. 2
[27] ZhaoningSun,NicoMessikommer,DanielGehrig,andDa-
videScaramuzza. Ess: Learningevent-basedsemanticseg-
mentation from still images. In European Conference on
Computer Vision, pages 341–357. Springer, 2022. 2, 5, 6,
7
[28] AndrewTao,KaranSapra,andBryanCatanzaro. Hierarchi-
cal multi-scale attention for semantic segmentation. arXiv
preprintarXiv:2005.10821,2020. 5
[29] AnttiTarvainenandHarriValpola. Meanteachersarebetter
role models: Weight-averaged consistency targets improve
semi-supervised deep learning results. Advances in neural
informationprocessingsystems,30,2017. 3
[30] HaoxiangWang,BoLi,andHanZhao.Understandinggrad-
ualdomainadaptation:Improvedanalysis,optimalpathand
beyond. InInternationalConferenceonMachineLearning,
pages22784–22801.PMLR,2022. 2
[31] LinWang,YujeongChae,andKuk-JinYoon. Dualtransfer
learning for event-based end-task prediction via pluggable
eventtoimagetranslation. InProceedingsoftheIEEE/CVF
InternationalConferenceonComputerVision,pages2135–
2145,2021. 1,2
[32] Lin Wang, Yujeong Chae, Sung-Hoon Yoon, Tae-Kyun
Kim, and Kuk-Jin Yoon. Evdistill: Asynchronous events
toend-tasklearningviabidirectionalreconstruction-guided
cross-modal knowledge distillation. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern
Recognition,pages608–619,2021. 1,2
[33] Binhui Xie, Shuang Li, Mingjia Li, Chi Harold Liu, Gao
Huang, andGuorenWang. Sepico: Semantic-guidedpixel
contrastfordomainadaptivesemanticsegmentation. IEEE
Trans.PatternAnal.Mach.Intell., 45(7):9004–9021, 2023.
5
[34] EnzeXie,WenhaiWang,ZhidingYu,AnimaAnandkumar,
Jose M Alvarez, and Ping Luo. Segformer: Simple and
efficient design for semantic segmentation with transform-
ers. Advances in Neural Information Processing Systems,
34:12077–12090,2021. 5
[35] Yu-Chu Yu and Hsuan-Tien Lin. Semi-supervised domain
adaptation with source label adaptation. In Proceedings of
theIEEE/CVFConferenceonComputerVisionandPattern
Recognition,pages24100–24109,2023. 4
[36] PanZhang,BoZhang,TingZhang,DongChen,YongWang,
andFangWen. Prototypicalpseudolabeldenoisingandtar-
getstructurelearningfordomainadaptivesemanticsegmen-
tation. InProceedingsoftheIEEE/CVFconferenceoncom-
puter vision and pattern recognition, pages 12414–12424,
2021. 2,4
[37] Alex Zihao Zhu, Liangzhe Yuan, Kenneth Chaney, and
Kostas Daniilidis. Unsupervised event-based learning of
10