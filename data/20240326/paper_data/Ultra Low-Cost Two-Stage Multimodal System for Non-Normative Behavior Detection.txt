Ultra Low-Cost Two-Stage Multimodal System
for Non-Normative Behavior Detection
Albert Lu and Stephen Cranefield
1 University of Cincinnati, USA
lu2y4@mail.uc.edu
2 University of Otago, New Zealand
stephen.cranefield@otago.ac.nz
Abstract. Theonlinecommunityhasincreasinglybeeninundatedbya
toxic wave of harmful comments. In response to this growing challenge,
we introduce a two-stage ultra-low-cost multimodal harmful behavior
detection method designed to identify harmful comments and images
withhighprecisionandrecallrates.WefirstutilizetheCLIP-ViTmodel
to transform tweets and images into embeddings, effectively capturing
the intricate interplay of semantic meaning and subtle contextual clues
within both texts and images. Then in the second stage, the system
feeds these embeddings into a conventional machine learning classifier
likeSVMorlogisticregression,enablingthesystemtobetrainedrapidly
andtoperforminferenceatanultra-lowcost.Byconvertingtweetsinto
richmultimodalembeddingsthroughtheCLIP-ViTmodelandutilizing
themtotrainconventionalmachinelearningclassifiers,oursystemisnot
only capable of detecting harmful textual information with near-perfect
performance, achieving precision and recall rates above 99% but also
demonstratestheabilitytozero-shotharmfulimageswithoutadditional
training,thankstoitsmultimodalembeddinginput.Thiscapabilityem-
powers our system to identify unseen harmful images without the need
forextensiveandcostlyimagedatasets.Additionally,oursystemquickly
adaptstonewharmfulcontent;ifanewharmfulcontentpatternisiden-
tified, we can fine-tune the classifier with the corresponding tweets’ em-
beddings to promptly update the system. This makes it well suited to
addressingtheever-evolvingnatureofonlineharmfulness,providingon-
line communities with a robust, generalizable, and cost-effective tool to
safeguard their communities.
Keywords: MultimodalNon-NormativeBehaviorDetection·Zero-shot
Learning · Low-Cost Machine Learning System
1 Introduction
Withtheincreasingprevalenceofonlinesocialcommunities,addressingharmful
ornon-normativebehaviorhasbecomeacriticalconcern.Harmfulcommentsand
imagesnotonlycontributetoatoxiconlineenvironmentbutcanalsoperpetuate
harm and discrimination [33,23]. Detecting and mitigating harmful behavior is
4202
raM
42
]AM.sc[
1v15161.3042:viXra2 A. Lu and S. Cranefield
crucial for fostering a safer and more inclusive online space. Previous studies on
harmful behavior detection systems have not addressed the issue of multimodal
representation learning for harmful behavior [8,7].
We introduce a two-staged multimodal harmful behavior detection method
to combat harmful content online. This solution leverages advanced language
models and established machine learning techniques to analyze both text and
images, effectively detecting harmful content. It achieves this feat with minimal
resource requirements, both for training and inference. Moreover, it has the
ability to identify harmful images solely through a model trained on harmful
text, eliminating the need for vast and costly image datasets.
BuildingupontheCLIP-ViTmodel[29],wegeneratemultimodalembeddings
forourcollectedharmfultweets,capturingboththeirsemanticmeaningandsub-
tle contextual nuances. By further augmenting the dataset through rephrased
tweets generated by the Mistral-7B-Instruct model [17], our system gains the
ability to detect harmful content and the ability to detect it with greater pre-
cision. Subsequently, utilizing these rich representations, machine learning algo-
rithmsclassifyharmfulcommentsandimageswithhighaccuracy,recallrate,and
F1-score, as demonstrated in our experiments. These experimental results high-
light the promise of our system in effectively addressing the pervasive challenge
of harmful content within online communities.
Firstly,webeganwithgeneratingtweetembeddings.Wepreprocessed19,190
harmful tweets from the dataset created by [11]. This data formed our train-
ing and testing set for harmful comments. For the non-harmful tweets, we ob-
tained 10,000 normal and positive tweets from 80 topics using Twitter’s API.
Out of these, 6,252 tweets were in English. To expand our dataset, we utilized
the Mistral-7B-Instruct model to generate an additional 10,825 rephrased non-
harmful tweets. In total, our dataset contained 17,077 non-harmful tweets. All
textual data was transformed into multimodal embeddings using the CLIP-ViT
model. We performed dimensionality reduction with UMAP [24] to facilitate
visual analysis and exploration. The findings of this study demonstrate that in-
tegrating multimodal embeddings with traditional machine learning classifiers
provides a cost-effective approach for identifying harmful content across text
and images. This method is significantly more economical compared to alterna-
tive solutions that depend on fine-tuning resource-intensive models. Finally, we
collected a dataset of regular and harmful images to assess the system’s ability
to generalize across modalities. Our experiments demonstrated that the harm-
fultweetembeddingsandmachinelearningmodelstrainedonthemcannotonly
identifytextualharmfulcommentsbutalsodetectharmfulimageswithzero-shot
learning.
2 Related Work
Sentence Embedding. Despite notable advancements, popular sentence em-
bedding models like InferSent [9] face limitations. Their treatment of each sen-
tence as an isolated entity hinders their ability to capture crucial contextualLow-Cost Multimodal Non-Normative Behavior Detection 3
information, ultimately impacting their ability to detect specific contexts. Uni-
versal Sentence Encoder [6], while offering significant progress, still suffers from
limited contextual understanding and static embeddings. Although LASER [35]
and Sentence-BERT [31] achieve state-of-the-art performance, they are both
limited to textual data, rendering their embeddings inapplicable to multimodal
data.
Dimensionality Reduction. Autoencoders [38], including Variational Au-
toencoders (VAE) [41][16] and Generative Adversarial Networks (GAN) [14],
excel at learning interpretable latent representations and dimensionality reduc-
tion, but their computational complexity hinders their applicationin large-scale
frameworks. In contrast, Principal Component Analysis (PCA) [18] is compu-
tationally efficient and effective with data exhibiting linear relationships. The
CLIP-ViT embeddings are known to be able to handle complex patterns and
non-linear relationships, rendering PCA variants like Robust PCA [4], Kernel
PCA [34], Sparse PCA [45], and Incremental PCA [32] less suitable for captur-
ing these intricate features.
Rephrased Comment Generation with Large Language Models.
Large language models have been widely used for generating rephrased com-
ments. These models leverage their vast amount of memory and language un-
derstanding to generate alternative versions of given text [20,39]. LLMs like
GPT-4 [27], Palm 2 [1], and BARD [26] can generate rephrased comments that
maintaintheoriginalmeaningwhileofferingvariationsinwordingandstructure.
However, their models are not open-sourced for research purposes.
Llama2[36]ontheotherhandisopen-sourced,cost-efficient,andhasstrong
performance compared to previous open-source LLMs, but is not as efficient as
the newer LLMs such as the Mistral model we are using in this paper. Falcon
180B [28] is the current king of the jungle of LLMs with 180 billion parameters,
trained on 3.5 trillion tokens. It requires a large amount of computing power for
fine-tuning and inference, with 64 A100s needed for full fine-tuning, and around
16 for LoRa fine-tuning.
Multimodal Large Language Models (MM-LLMs) MM-LLMs aim
to learn joint representations from multiple modalities (text, image, audio and
video) and have gained significant attention [19,37,25,13] in recent years.
The unprecedented ability of GPT-4V [43] in processing arbitrarily inter-
leaved multimodal inputs and the genericity of its capabilities together make
GPT-4V a powerful multimodal generalist system. Nevertheless, it is not open-
sourced for research purposes, so we did not use it in our work. The recently
released open-source MM-LLM LLaVA [22], LLaVA-v1.5 [21], and Fuyu-8B [3]
are fast and incredibly powerful. However, their primary training objective is
to function as a digital assistant that can answer questions based on the user’s
prompt and understand the images provided by the user, whereas our work fo-4 A. Lu and S. Cranefield
cusesonmultimodalembeddingsthatcouldpreciselyrepresentbothtextualand
visual information.
harmful Comments Dataset From Online Social Community. The
Rudditdataset[15]containscommentsfromRedditassociatedwithfine-grained,
real-valued scores ranging from -1 (totally normal comment) to 1 (indicating
maximum harmfulness). However, it only provided post IDs and not the text of
a post and while Reddit’s API allows retrieval of a comments given its post ID,
we were only able to extract a few of them that still exist on Reddit, as most of
the harmful comments have been deleted by the platform.
We tried gathering normal comments through Reddit’s API, focusing on
those with a positive score of at least 3 (indicating community-perceived posi-
tivity), but we encountered limitations. Reddit’s 1,000 comment crawl limit is
insufficient for constructing an adequate amount of training data. Additionally,
maintaining consistency in social norms would be optimal by using comments
from a single community. Therefore, collecting both normal and harmful tweets
from Twitter emerged as a better solution.
3 Multimodal harmful Behavior Detection System
Fig.1: Multimodal harmful behavior detection
3.1 Generating Multimodal Embeddings We obtained 19,190 harmful
tweets from a hate speech detection dataset containing 24,784 Twitter tweets
[11] by selecting those with class labels equal to 1. To supplement this data, we
retrieved 6,252 normal English tweets using Twitter’s API. We employed the
Mistral-7B-Instruct model to generate additional rephrased tweets as shown in
Figures 2 and Figures 3 (warning: these and other figures contain harmful lan-
guage). These tweets then underwent preprocessing via our custom regex-basedLow-Cost Multimodal Non-Normative Behavior Detection 5
processor, removing unwanted elements such as usernames, external links, and
timestamps. Subsequently, we leveraged the CLIP-ViT-L-14 model to convert
these processed tweets into vector representations. We selected the CLIP-ViT
model for three key reasons:
– Cross-modal detectionn expertise: Trained on a vast collection of image-
text pairs, CLIP-ViT-L-14 possesses superior capabilities in bridging the
gap between visual and textual information. This enables us to exploit its
strengths in constructing a harmful behavior hyperspace based on harmful
community comments, which also bolsters our ability to identify harmful
images.
– Comprehensiveness and robustness: The extensive training data utilized by
CLIP-ViT-L-14 ensures the generation of comprehensive and robust tweet
representations.
– Exceptional relationship capture: Employing a vision transformer architec-
ture,CLIP-ViT-L-14capturesintricaterelationshipswithinthedata,further
enhancing its effectiveness in our application.
Fig.3: Mistral-7B-Instruct generated
Fig.2: Prompt to rephrase tweet rephrased tweets
3.2 Similar harmful behaviours form a cluster in the vector space and
its visualization The key to demonstrating the effectiveness of the CLIP-ViT
model’sembeddingforcommentsliesinmeasuringthesimilarityofembeddings
forsimilartweets.WeusetheMistral-7b-Instructmodeltogenerate10rephrased
commentsfromtheoriginalcomment.Wethengaveitinstructionstoconvertthe
outputintoJSONformat.Wechosetogenerate10rephrasedcommentsbasedon
empirical evidence, as this quantity has been found to strike a balance between
avoiding excessive repetition and ensuring a sufficient variety of outputs. We
selected the Mistral-7B-Instruct model because it has the potential to deliver
both efficiency and high performance. While other large language models are
either so large that they require several GPUs for inference or are less accurate,
the Mistral-7B-Instruct offers a compelling balance between these factors.
Next,wegeneratedembeddingsforthese10rephrasedtweetsusingtheCLIP-
ViT model, which we will reduce to three-dimensional in Figure 6 for better6 A. Lu and S. Cranefield
visualization.Wealsovisualizeddifferenttweetsandtheirrephrasedtweets,and
the resultis similarharmful behaviors (original tweetand itsrephrased version)
are located close together. The subsequent subsection will delve into further
details regarding the aforementioned information.
To visualize the effectiveness of harmful embeddings, we used UMAP to re-
ducethemto3D.Thisallowedustoanalyzeinteractionsbetweencommentsand
their rephrased versions. As shown in Figure 4–6, UMAP effectively preserves
both local and global structures, enabling accurate representation of complex
relationships. Similar comments form clusters in 3D, highlighting semantic sim-
ilarities. UMAP’s computational efficiency made it ideal for our large dataset.
Fig.4: Comment example 1 (Red) Fig.5:Commentexample2(Blue)and
and its LLM rephrased comments its LLM rephrased commentsLow-Cost Multimodal Non-Normative Behavior Detection 7
Fig.6:VisualizationoftwodifferentcommentsandtheirLLMrephrasedversions
in 3D with UMAP
3.4 Creating the harmful Visual Testing Dataset Building a robust and
reliabledatasetiscrucialforevaluatetheeffectivenessofanyharmfulcontentde-
tection model.For this purpose, we constructed a comprehensive harmfulvisual
testing dataset utilizing two distinct approaches:
1. Keyword-based Image Retrieval: We first extracted relevant key-
words from the harmful comments within our textual dataset using the Mistral-
7B-Instruct model as shown in Figure 7. These keywords, capturing the core
semantic meaning of the harmful language, were then used as search queries us-
ing Google’s API. This strategy leverages the inherent link between textual and
visual content, allowing us to retrieve images that visually depict the harmful
concepts expressed in the comments.
Fig.7: Keywords extraction with the Mistral-7B-Instruct model8 A. Lu and S. Cranefield
2. Original Comment-Based Image Retrieval: In a few cases, we ob-
served that utilizing the original harmful comments as search queries yielded a
more accurate retrieval of visually harmful images than using keywords. This
phenomenoncanbeattributedtothefactthattheoriginalcommentsretainthe
fullcontextandnuancesoftheharmfulmeaning,oftenexceedingtheexpressive-
nessoftheextractedkeywords.Bydirectlyusingtheoriginalcommentsassearch
queries, we minimize the risk of information loss and ensure that the retrieved
imagesaccuratelyreflecttheintendedharmfulcontent.However,therearecases
whereusingtheentireoriginaltweetdoesnotyieldtheresultwewanted.So,we
use both keyword and original comments in a search query and manually pick
the more accurate one. Note that we can not rule out the possibility that bias
may have been introduced due to that.
Non-harmful Visual Data: To complement the harmful visual data, we
incorporatedadiverseselectionofnon-harmfulimagesfromtheestablishedRed-
Capsdataset[12].Thiswidelyuseddatasetoffersarepresentativeandbalanced
collection of images, ensuring a fair and generalizable evaluation of our model’s
performance.
ManualVerification:Toguaranteethequalityandreliabilityofthedataset,
wereviewedeachimage,manuallyverifyingitsaccuratelabelingaseitherharm-
ful or non-harmful. We added manual checks of images found only because they
appeared on the same web pages as harmful words.
Visual Representations:
To illustrate the process, we present examples of images retrieved using dif-
ferent methods as shown in Figures 8 and Figures 9:
Fig.8: Example images retrieved
using keywords and original harmful Fig.9: Example images from the Red-
comment as the search query Capsdatasetusedasnon-harmfuldata
By combining these strategies and employing manual verification, we con-
structedacomprehensiveandreliableharmfulvisualtestingdataset.Thisdataset
plays a crucial role in evaluating the effectiveness of our model in detecting vi-Low-Cost Multimodal Non-Normative Behavior Detection 9
sually harmful content and ultimately contributes to the development of robust
and responsible technologies for mitigating online harm.
4 Experimental Results
We conducted experiments to evaluate the multimodal harmful behavior detec-
tion system’s effectiveness in online social communities. The experiments in-
volved testing it on both harmful comments and harmful images.
4.1 harmful Comment Detection To evaluate the system’s ability to detect
harmfulcomments,wecollectedatotalof19,190harmfultweetsfromhatespeech
detection [11]. To ensure the quality of the input data, we preprocessed these
tweetsusingcustom-maderegularexpressionstoremoveanydistractingfeatures.
For non-harmful tweets, we retrieved 10,000 normal and positive tweets from 80
topicsusingTwitter’sAPI.Outofthese,6,252tweetswereinEnglish.Toaddress
classimbalance,wegeneratedanadditional10,825rephrasednon-harmfultweets
with the Mistral-7B-Instruct model. In total, we now have 17,077 non-harmful
tweets. These tweets were labeled as harmful (1) or non-harmful (0) as shown
in Figures 10.
Fig.10: Composition of our harmful and non-harmful tweet dataset with class
labels and quantity
ByusingtheembeddingoftheCLIP-ViTmodel,wecanleverageitscompre-
hensiveandrobustrepresentationstoidentifyandencodecomplexrelationships
within the data. These representations enable the model to perform well even
withalimitedamountofdata.Ourexperimentsdemonstratethatcombiningthe
CLIP-ViT embedding with various traditional machine learning algorithms can
achieve excellent results in classifying harmful tweet detection. Unlike language
models (LLMs), which typically require hours or days to train and incur high
inference costs with GPUs, our approach is cost-efficient while still achieving
outstanding experimental results.10 A. Lu and S. Cranefield
Intheexperiment,wetooktheclassificationresultfromthePerspectiveAPI
(PAPI), a textual offense detection API from Google as a baseline method and
fine-tuned the BERT model for comparison. The results presented in Figure 11
demonstrate that our multimodal harmful behavior detection system achieves
an accuracy, recall rate, and F1-score of approximately 1.0 in detecting harmful
tweets. This emphasizes the effectiveness of combining cutting-edge embeddings
such as CLIP-ViT with conventional machine learning algorithms to identify
harmful behavior in tweets. It achieved similar performance to the fine-tuned
BERT model at a much lower cost of development.
Fig.11: Textual testing results: CLIP-ViT embedding + Conventional ML algo-
rithms
4.2 Testing Classifier’s Ability to Zero-Shot harmful Image Posts To
evaluate our zero-shot harmful image detection, we compiled 200 normal and
200harmfulimages.ThenormalimagescovereddiversetopicsfromtheRedCaps
dataset[12],whiletheharmfulimageswereretrievedusingkeywordsandoriginal
tweets. We employed various conventional machine learning algorithms, most of
thesealgorithmsshowsourtwo-stagemultimodalclassifierachievedcompetitive
results, demonstrating its effectiveness in detecting harmful behavior in visualLow-Cost Multimodal Non-Normative Behavior Detection 11
content. This highlights our contribution in enabling the model to generalize
to unseen harmful visual content without the need for additional labeled image
data. Unlike resource-intensive transformer models like DETR [5], professionals
in the trust and safety industry used to collect gigabytes of data to improve
performance and cover a wider range of sensitive content, our approach offers
efficient and versatile harmful image detection with zero-shot learning, making
it ideal for real-world applications.
Fig.12: Testing Image Data: Fig.13:TestingImageData:Precision,
Precision, Recall, and F1 Score Recall, and F1 Score12 A. Lu and S. Cranefield
Fig.14: Testing Image Data: AUC and ROC
5 Conclusion and Future Work
Inthispaper,wepresentedatwo-stagedmultimodalharmfulbehaviordetection
system for online social communities. We utilized the state-of-the-art language
models CLIP-ViT to generate embeddings and the Mistral-7B-Instruct for gen-
erating rephrased tweets. We then applied several machine learning algorithms
to classify harmful comments and harmful images based on embeddings from
the CLIP-ViT model. Experimental results showed that our system achieved
highaccuracy,recallrate,andF1-scoreindetectingharmfultweets,demonstrat-
ing the effectiveness of combining SOTA embeddings and conventional machine
learning algorithms. This approach offers the potential to achieve exceptional
performance at a minimal cost, making it particularly advantageous to deploy
in the industry. We also demonstrated that the system, constructed using tex-
tualpostsandlargelanguagemodelmultimodalembeddings,cangeneralizewith
zero-shot learning for harmful image posts.
In the future, there are several directions for further research and improve-
ment:
– Enabling Video Analysis Ability: Exploring the integration of other
Multimodal Large Language Models like NExT-GPT [40] which could also
handlevideoinputs.Thiswouldenrichthesystem’sfunctionalityandprovide
a more comprehensive detection of harmful behavior.Low-Cost Multimodal Non-Normative Behavior Detection 13
– Enabling audio data analysis with ASR: Connecting the system with
an Automatic Speech Recognition (ASR) model [30,2] or API would enable
classification of audio content based on harmfulness.
References
1. Anil,R.,Dai,A.M.,Firat,O.,Johnson,M.,Lepikhin,D.,Passos,A.T.,Shakeri,S.,
Taropa,E.,Bailey,P.,Chen,Z.,Chu,E.,Clark,J.,Shafey,L.E.,Huang,Y.,Meier-
Hellstern, K.S., Mishra, G., Moreira, E., Omernick, M., Robinson, K., Ruder, S.,
Tay, Y., Xiao, K., Xu, Y., Zhang, Y., Abrego, G.H., Ahn, J., Austin, J., Barham,
P.,Botha,J.A.,Bradbury,J.,Brahma,S.,Brooks,K.M.,Catasta,M.,Cheng,Y.,
Cherry,C.,Choquette-Choo,C.A.,Chowdhery,A.,Cr´epy,C.,Dave,S.,Dehghani,
M., Dev, S., Devlin, J., D’iaz, M.C., Du, N., Dyer, E., Feinberg, V., Feng, F.,
Fienber, V., Freitag, M., Garc´ıa, X., Gehrmann, S., Gonza´lez, L., Gur-Ari, G.,
Hand,S.,Hashemi,H.,Hou,L.,Howland,J.,Hu,A.R.,Hui,J.,Hurwitz,J.,Isard,
M.,Ittycheriah,A.,Jagielski,M.,Jia,W.H.,Kenealy,K.,Krikun,M.,Kudugunta,
S., Lan, C., Lee, K., Lee, B., Li, E., Li, M.L., Li, W., Li, Y., Li, J.Y., Lim, H.,
Lin, H., Liu, Z.Z., Liu, F., Maggioni, M., Mahendru, A., Maynez, J., Misra, V.,
Moussalem, M., Nado, Z., Nham, J., Ni, E., Nystrom, A., Parrish, A., Pellat,
M., Polacek, M., Polozov, O., Pope, R., Qiao, S., Reif, E., Richter, B., Riley,
P., Ros, A., Roy, A., Saeta, B., Samuel, R., Shelby, R.M., Slone, A., Smilkov,
D., So, D.R., Sohn, D., Tokumine, S., Valter, D., Vasudevan, V., Vodrahalli, K.,
Wang, X., Wang, P., Wang, Z., Wang, T., Wieting, J., Wu, Y., Xu, K., Xu, Y.,
Xue, L.W., Yin, P., Yu, J., Zhang, Q., Zheng, S., Zheng, C., Zhou, W., Zhou, D.,
Petrov,S.,Wu,Y.:Palm2technicalreport. ArXivabs/2305.10403(2023). URL
https://api.semanticscholar.org/CorpusID:258740735
2. Baevski, A., Zhou, H., Mohamed, A.r., Auli, M.: wav2vec 2.0: A framework for
self-supervisedlearningofspeechrepresentations.ArXivabs/2006.11477(2020).
https://api.semanticscholar.org/CorpusID:219966759
3. Bavishi,R.,Elsen,E.,Hawthorne,C.,Nye,M.,Odena,A.,Somani,A.,Ta¸sırlar,S.:
Introducingourmultimodalmodels(2023).https://www.adept.ai/blog/fuyu-8b
4. Cand`es, E.J., Li, X., Ma, Y., Wright, J.: Robust principal component analysis?
ArXiv abs/0912.3599 (2009)
5. Carion,N.,Massa,F.,Synnaeve,G.,Usunier,N.,Kirillov,A.,Zagoruyko,S.:End-
to-endobjectdetectionwithtransformers. In:EuropeanConferenceonComputer
Vision. Springer (2020). https://arxiv.org/abs/2005.12872
6. Cer, D.M., Yang, Y., yi Kong, S., Hua, N., Limtiaco, N., John, R.S., Constant,
N., Guajardo-Cespedes, M., Yuan, S., Tar, C., Sung, Y.H., Strope, B., Kurzweil,
R.: Universal sentence encoder. ArXiv abs/1803.11175 (2018). URL https:
//api.semanticscholar.org/CorpusID:4494896
7. Cheriyan, J., Savarimuthu, B.T.R., Cranefield, S.: Norm violation in online com-
munities - a study of stack overflow comments. In: COIN@AAMAS (2020). URL
https://api.semanticscholar.org/CorpusID:215745091
8. Cheriyan, J., Savarimuthu, B.T.R., Cranefield, S.: Towards offensive language de-
tection and reduction in four software engineering communities. Proceedings of
the 25th International Conference on Evaluation and Assessment in Software En-
gineering(2021). URLhttps://api.semanticscholar.org/CorpusID:235352820
9. Conneau,A.,Kiela,D.,Schwenk,H.,Barrault,L.,Bordes,A.:Supervisedlearning
ofuniversalsentencerepresentationsfromnaturallanguageinferencedata. ArXiv14 A. Lu and S. Cranefield
abs/1705.02364 (2017). URL https://api.semanticscholar.org/CorpusID:
28971531
10. Davidson,T.,Warmsley,D.,Macy,M.,Weber,I.:Automatedhatespeechdetection
and the problem of offensive language. In: Proceedings of the 11th International
AAAI Conference on Web and Social Media, ICWSM ’17, pp. 512–515 (2017).
https://arxiv.org/abs/1703.04009
11. Davidson,T.,Warmsley,D.,Macy,M.W.,Weber,I.:Automatedhatespeechdetec-
tion and the problem of offensive language. In: International Conference on Web
and Social Media (2017). URL https://api.semanticscholar.org/CorpusID:
1733167
12. Desai, K., Kaul, G., Aysola, Z., Johnson, J.: RedCaps: Web-curated image-text
datacreatedbythepeople,forthepeople. In:NeurIPSDatasetsandBenchmarks
(2021). Https://arxiv.org/abs/2111.11431
13. Faghri,F.,Fleet,D.J.,Kiros,J.R.,Fidler,S.:VSE++:Improvingvisual-semantic
embeddings with hard negatives. In: British Machine Vision Conference (2017).
https://api.semanticscholar.org/CorpusID:6095318
14. Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
S.,Courville,A.C.,Bengio,Y.:Generativeadversarialnetworks. Communications
of the ACM 63, 139–144 (2014). https://api.semanticscholar.org/CorpusID:
1033682
15. Hada, R., Sudhir, S., Mishra, P., Yannakoudakis, H., Mohammad, S.M., Shutova,
E.: Ruddit: Norms of offensiveness for English Reddit comments. In: Proceedings
of the 59th Annual Meeting of the Association for Computational Linguistics and
the11thInternationalJointConferenceonNaturalLanguageProcessing(Volume
1:LongPapers),pp.2700–2717.AssociationforComputationalLinguistics,Online
(2021). https://aclanthology.org/2021.acl-long.210
16. Higgins, I., Matthey, L., Pal, A., Burgess, C.P., Glorot, X., Botvinick, M.M., Mo-
hamed, S., Lerchner, A.: Beta-VAE: Learning basic visual concepts with a con-
strained variational framework. In: International Conference on Learning Repre-
sentations (2016). URL https://api.semanticscholar.org/CorpusID:46798026
17. Jiang, A.Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D.S., Casas,
D.d.L.,Bressand,F.,Lengyel,G.,Lample,G.,Saulnier,L.,Lavaud,L.R.,Lachaux,
M.A.,Stock,P.,LeScao,T.,Lavril,T.,Wang,T.,Lacroix,T.,ElSayed,W.:Mis-
tral 7b. ArXiv abs/2310.06825 (2023)
18. Jolliffe,I.T.:Principalcomponentanalysis. WileyInterdisciplinaryReviews:Com-
putational Statistics 2(4), 433–459 (2010). https://doi.org/10.1002/wics.101
19. Kiros, R., Salakhutdinov, R., Zemel, R.S.: Unifying visual-semantic embeddings
with multimodal neural language models. ArXiv abs/1411.2539 (2014)
20. Li,Y.,Xu,M.,Miao,X.,Zhou,S.,Qian,T.:Largelanguagemodelsascounterfac-
tual generator: Strengths and weaknesses (2023). URL https://arxiv.org/abs/
2305.14791
21. Liu,H.,Li,C.,Li,Y.,Lee,Y.J.:Improvedbaselineswithvisualinstructiontuning.
ArXiv abs/2310.03744 (2023)
22. Liu, H., Li, C., Wu, Q., Lee, Y.J.: Visual instruction tuning. ArXiv
abs/2304.08485 (2023)
23. Lupu, Y., Sear, R., Vela´squez, N., Leahy, R., Johnson Restrepo, N., Gold-
berg, B., Johnson, N.F.: Offline events and online hate. PLOS ONE (2023).
https://doi.org/10.1371/journal.pone.0278511
24. McInnes, L., Healy, J., Saul, N., Großberger, L.: UMAP: Uniform manifold ap-
proximation and projection. J. Open Source Softw. 3, 861 (2018). URL https:
//api.semanticscholar.org/CorpusID:53244226Low-Cost Multimodal Non-Normative Behavior Detection 15
25. Nam,H.,Ha,J.W.,Kim,J.:Dualattentionnetworksformultimodalreasoningand
matching. 2017 IEEE Conference on Computer Vision and Pattern Recognition
(CVPR) pp. 2156–2164 (2016). https://api.semanticscholar.org/CorpusID:
945386
26. Nicholson, A.E., Korb, K.B., Nyberg, E.P., Wybrow, M., Zukerman, I., Mascaro,
S., Thakur, S., Alvandi, A.O., Riley, J., Pearson, R., Morris, S., Herrmann, M.,
Azad,A.K.M.,Bolger,F.,Hahn,U.,Lagnado,D.A.:Bard:Astructuredtechnique
forgroupelicitationofbayesiannetworkstosupportanalyticreasoning.RiskAnal-
ysis42,1155–1178(2020). URLhttps://api.semanticscholar.org/CorpusID:
211817846
27. OpenAI: Gpt-4 technical report. ArXiv abs/2303.08774 (2023)
28. Penedo, G., Malartic, Q., Hesslow, D., Cojocaru, R.A., Cappelli, A., Alobeidli,
H., Pannier, B., Almazrouei, E., Launay, J.: The refinedweb dataset for falcon
llm: Outperforming curated corpora with web data, and web data only. ArXiv
abs/2306.01116 (2023)
29. Radford,A.,Kim,J.W.,Hallacy,C.,Ramesh,A.,Goh,G.,Agarwal,S.,Sastry,G.,
Askell,A.,Mishkin,P.,Clark,J.,Krueger,G.,Sutskever,I.:Learningtransferable
visual models from natural language supervision. In: M. Meila, T. Zhang (eds.)
Machine Learning, Proceedings of the 38th International Conference on, Proceed-
ingsofMachineLearningResearch,vol.139,pp.8748–8763.PMLR,VirtualEvent
(2021). URL https://proceedings.mlr.press/v139/radford21a.html
30. Radford, A., Kim, J.W., Xu, T., Brockman, G., McLeavey, C., Sutskever, I.: Ro-
bustspeechrecognitionvialarge-scaleweaksupervision. ArXivabs/2212.04356
(2022)
31. Reimers, N., Gurevych, I.: Sentence-BERT: Sentence embeddings using siamese
bert-networks. In: Conference on Empirical Methods in Natural Language Pro-
cessing (2019). https://api.semanticscholar.org/CorpusID:201646309
32. Ross, D.A., Lim, J., Lin, R.S., Yang, M.H.: Incremental learning for robust visual
tracking. International Journal of Computer Vision 77, 125–141 (2008). https:
//api.semanticscholar.org/CorpusID:1089627
33. Saha, K., Chandrasekharan, E., De Choudhury, M.: Prevalence and psychological
effects of hateful speech in online college communities. In: Proceedings of the
10th ACM Conference on Web Science, pp. 255–264 (2019). https://doi.org/
10.1145/3292522.3326032
34. Scholkopf, B., Smola, A., Mu¨ller, K.R.: Kernel principal component analysis. In:
International Conference on Artificial Neural Networks (1997). https://api.
semanticscholar.org/CorpusID:7831590
35. Schwenk,H.,Douze,M.:LASER:Language-agnosticsentencerepresentations. In:
Proceedings of the 2018 Conference on Empirical Methods in Natural Language
Processing,pp.3519–3524(2018).https://github.com/facebookresearch/LASER
36. Touvron,H.,Martin,L.,Stone,K.R.,Albert,P.,Almahairi,A.,Babaei,Y.,Bash-
lykov,N.,Batra,S.,Bhargava,P.,Bhosale,S.,Bikel,D.M.,Blecher,L.,Canto´nFer-
rer, C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W., Fuller,
B.,Gao,C.,Goswami,V.,Goyal,N.,Hartshorn,A.S.,Hosseini,S.,Hou,R.,Inan,
H., Kardas, M., Kerkez, V., Khabsa, M., Kloumann, I.M., Korenev, A.V., Koura,
P.S.,Lachaux,M.A.,Lavril,T.,Lee,J.,Liskovich, D.,Lu,Y.,Mao,Y.,Martinet,
X., Mihaylov, T., Mishra, P., Molybog, I., Nie, Y., Poulton, A., Reizenstein, J.,
Rungta, R., Saladi, K., Schelten, A., Silva, R., Smith, E.M., Subramanian, R.,
Tan, X., Tang, B., Taylor, R., Williams, A., Kuan, J.X., Xu, P., Yan, Z., Zarov,
I., Zhang, Y., Fan, A., Kambadur, M., Narang, S., Rodriguez, A., Stojnic, R.,16 A. Lu and S. Cranefield
Edunov, S., Scialom, T.: Llama 2: Open foundation and fine-tuned chat models.
ArXiv abs/2307.09288 (2023)
37. Wang, H., Sahoo, D., Liu, C., Lim, E.P., Hoi, S.C.H.: Learning cross-modal em-
beddings with adversarial networks for cooking recipes and food images. 2019
IEEE/CVFConferenceonComputerVisionandPatternRecognition(CVPR)pp.
11,564–11,573 (2019). https://api.semanticscholar.org/CorpusID:145047863
38. Wang,Y.,Yao,H.,Zhao,S.:Auto-encoderbaseddimensionalityreduction. Neuro-
computing 184, 232–242 (2016). https://api.semanticscholar.org/CorpusID:
207111259
39. Witteveen, S., Andrews, M.: Paraphrasing with large language models. In:
A. Birch, A. Finch, H. Hayashi, I. Konstas, T. Luong, G. Neubig, Y. Oda,
K. Sudoh (eds.) Proceedings of the 3rd Workshop on Neural Generation and
Translation, pp. 215–220. Association for Computational Linguistics, Hong Kong
(2019). https://doi.org/10.18653/v1/D19-5623. URL https://aclanthology.
org/D19-5623
40. Wu,S.,Fei,H.,Qu,L.,Ji,W.,Chua,T.S.:Next-gpt:Any-to-anymultimodalllm.
CoRR abs/2309.05519 (2023). URL https://arxiv.org/abs/2309.05519
41. Xu, W., Sun, H., Deng, C., Tan, Y.: Variational autoencoder for semi-supervised
text classification. In: AAAI Conference on Artificial Intelligence (2017). URL
https://api.semanticscholar.org/CorpusID:2060721
42. Xu, W., Sun, H., Deng, C., Tan, Y.: Variational autoencoder for semi-supervised
text classification. In: AAAI Conference on Artificial Intelligence (2017). https:
//api.semanticscholar.org/CorpusID:2060721
43. Yang,Z.,Li,L.,Lin,K.,Wang,J.,Lin,C.C.,Liu,Z.,Wang,L.:Thedawnoflmms:
Preliminary explorations with gpt-4v(ision) (2023)
44. Zhang,P.,Xiao,S.,Liu,Z.,Dou,Z.,Nie,J.Y.:Retrieveanythingtoaugmentlarge
language models. ArXiv abs/2310.07554 (2023)
45. Zou,H.,Hastie,T.J.,Tibshirani,R.:Sparseprincipalcomponentanalysis. Journal
of Computational and Graphical Statistics 15, 265–286 (2006). https://api.
semanticscholar.org/CorpusID:5730904