Navigating the EU AI Act: A Methodological
Approach to Compliance for Safety-critical Products
Jessica Kelly, Shanza Zafar, Lena Heidemann, Joao Vitor-Zacchi, Delfina Espinoza, Nu´ria Mata
Fraunhofer IKS
Munich, Germany
jessica.kelly@iks.fraunhofer.de
safety standards, such as ISO 26262 [1] for automotive or
Abstract—In December 2023, the European Parliament provi- ARP 4761 [2], DO-178C [3], and DO-254 [4] for aerospace,
sionallyagreedontheEUAIAct.Thisunprecedentedregulatory cover some aspects of the Act requirements for high-risk AI
frameworkforAIsystemslaysoutguidelinestoensurethesafety,
systems.However,thesestandardsdonot,intheircurrentstate,
legality,andtrustworthinessofAIproducts.Thispaperpresents
addressAIspecificconsiderationsforsafety,transparency,and
a methodology for interpreting the EU AI Act requirements
for high-risk AI systems by leveraging product quality models. human oversight. Although efforts are being made to develop
We first propose an extended product quality model for AI new safety standards for AI systems, their development and
systems,incorporatingattributesrelevanttotheActnotcovered adherence are a time-intensive process. Quality models for AI
by current quality models. We map the Act requirements to
products, such as ISO/IEC 25059:2023 [5], can help address
relevant quality attributes with the goal of refining them into
the requirements set out in the Act early in the development
measurable characteristics. We then propose a contract-based
approach to derive technical requirements at the stakeholder cycle. Additionally, they provide the flexibility to include the
level.ThisfacilitatesthedevelopmentandassessmentofArtificial attributes that may not be safety relevant, but ensure better
Intelligence(AI)systemsthatnotonlyadheretoestablishedqual- quality.
ity standards, but also comply with the regulatory requirements
In addition to the effect on the AI regulatory landscape,
outlined in the Act for high-risk (including safety-critical) AI
the Act introduces additional challenges to compliance when
systems. We demonstrate the applicability of this methodology
onanexemplaryautomotivesupplychainusecase,whereseveral several stakeholders are involved. Safety-critical AI products
stakeholders interact to achieve EU AI Act compliance. are typically part of complex global supply chains, where
Index Terms—EU AI Act, Quality Attributes, AI Systems, many suppliers interact to produce the final product. In the
Regulations.
automotive industry, for example, it is uncommon for a single
entity to be responsible for the development and integration
I. INTRODUCTION
of all vehicle components. In such scenarios, demonstrating
With the growing number of AI systems being deployed in compliance to the Act becomes an increasingly challenging
safety-criticalapplications,thereisapressingneedtoestablish and intricate task. It is clear that organizations will need tools
regulations that govern the safe and responsible use of AI. In and methodologies to address the requirements laid out by
December2023,theEUAIAct(Act)wasprovisionallyagreed the regulation. Specifically, a systematic methodology that
upon by the European Parliament, setting the precedent for aids organizations in verifying compliance is required. To
the regulation of AI applications. It is the first comprehensive facilitate this, our work leverages product quality models to
regulatoryframeworkgoverningthedevelopment,deployment, break down the Act requirements into verifiable properties.
and use of AI systems. The Act introduces a risk-based clas- In the first phase, an extended quality model for AI systems
sification of AI products. Applications whose risk is deemed is derived using attributes that are relevant to the Act. Next,
“Unacceptable”, such as social-scoring systems, are banned using this quality model, an approach to map the articles
within the framework of the Act. Applications with a risk of the Act to quality attributes for AI Systems is presented.
rated “High” (high-risk) must demonstrate compliance with Finally, to address the complexities arising from supply chain
stringent requirements ensuring that, among others, safety, relationships, a contract-based approach for the derivation of
transparency, and human rights needs are met. The outlined technical requirements from quality attributes is proposed.
requirementsaffectnotonlyAIproducts,butanystakeholders This methodology is, to the best of our knowledge, the first
involved in the AI value chain. Organizations will need to systematicapproachforderivingtechnicalrequirementsatthe
adapt to the evolving landscape of the Act, balancing inno- stakeholder level from high-level Act requirements.
vation and regulatory adherence. While entities across the AI The contributions are as follows:
value chain will need to align with the framework of the Act, • Anextendedqualitymodelforsafety-criticalAIsystems,
future standards and regulations will also be affected. which covers relevant attributes for the EU AI Act;
Safety-criticalsystems,whosefailurecouldresultinsignifi- • AsystematicapproachformappingtheActrequirements
cantharmtopeopleorevenlossoflife,fitunderthedefinition to relevant quality attributes in the extended quality
of high risk as defined by the Act. Existing domain-specific model;
©2024IEEE.Personaluseofthismaterialispermitted.PermissionfromIEEEmustbeobtainedforallotheruses,inanycurrentorfuturemedia,including
reprinting/republishingthismaterialforadvertisingorpromotionalpurposes,creatingnewcollectiveworks,forresaleorredistributiontoserversorlists,or
reuseofanycopyrightedcomponentofthisworkinotherworks.
4202
raM
52
]IA.sc[
1v80861.3042:viXra• A contract-based approach for deriving verifiable techni- Act, this work focuses only on the risk classification and
cal requirements for the quality attributes; and finally, does not delve into the requirements for AI systems that are
• Anexemplaryusecaseforanautomotivesupplychainis deemed high risk. A different perspective is taken in [11],
presentedtodemonstratetheapplicabilityoftheproposed which provides an overview of explainability requirements in
methodology. the Act, proposing metrics for assessing AI Act compliance.
The authors highlight the need for metrics that are risk-
II. BACKGROUND
focused, model-agnostic, goal-aware, intelligible, and acces-
There is currently little work surrounding how the require- sible, and assess current metrics against these criteria. The
ments laid out for high-risk AI systems should be addressed. paperprovidesathoroughcoverageofexplainability,butdoes
Many organizations seek to understand whether compliance not address the broader spectrum of requirements outlined in
with current regulations can assist in addressing the EU AI the EU AI Act. It also lacks a comprehensive methodology
Act.Existingstandardsdonotfullycoverthestringentrequire- for addressing these requirements from the perspective of
mentslaidoutintheAct,suchastransparency,lawfulness,and different stakeholders, leaving a gap in practical guidance for
fairness.Productqualitymodelsmayhelpfillthisgap,andcan entities seeking compliance. A more pragmatic approach to
be more easily adapted to include properties that may not be compliance is suggested in [12], where the authors propose
safety relevant but which do contribute to quality. Existing a methodology for organizations to measure their compliance
quality standards, such as ISO/IEC 25010 Product Quality to the Act using a comprehensive questionnaire. However, the
Standard [6] and ISO/IEC FCD 25012 Data Quality Model approach focuses on measuring compliance to the Act, and
[7] do not address AI specific attributes such as transparency, does not provide guidance to organizations who may seek
controllability, and intervenability. The Quality Model for AI further compliance.
Products/Systems in ISO 25059:2023 [5] introduces some AI
specific attributes like functional adaptability, and robustness,
III. PROPOSEDMETHODOLOGY:ELICITINGHIGH-LEVEL
however, it is still lacking in its coverage of attributes like
REQUIREMENTSFROMTHEACT
transparency, monitorability, and data quality, among others. This section presents the systematic methodology for elic-
ISO/IEC 24028 - overview of trustworthiness in artificial iting high-level requirements from the EU AI Act. First, an
intelligence highlights the need for new standards which overview of the extended quality model for AI Products is
incorporateAIspecificqualityattributes[8].Giventhis,recent presented, followed by the approach for mapping Act require-
contributions have addressed the need for extended quality ments to quality attributes. Finally, a contract-based approach
models for AI systems. for deriving technical requirements for quality attributes is
Theauthorsof[9]defineasystematicprocessforderivinga proposed.
quality model for ML systems. They formalize the derivation
A. Deriving an Extended Quality Model for safety-critical AI
of quality attributes using a quality meta-model, enabling
Systems
the modelling of different hierarchies of quality. From this
meta-model, relevant entities are defined and categorized into To derive relevant quality attributes for safety-critical AI
corresponding views of an ML product, namely the model, systems, ISO/IEC 25059 [5] is used as a baseline. ISO/IEC
data, infrastructure, environment, and system views. Relevant 25059 provides the quality model serving as an extension to
properties are then described for a selected use case, and the ISO 25010:2011 series - Systems and Software Quality
a list of corresponding metrics is proposed. This systematic Requirements and Evaluation (SQuaRE) [6]. ISO/IEC 25059
approach ensures a comprehensive coverage of ML-related defines quality attributes and sub-attributes that establish con-
quality properties, however, it may not be well suited for sistent terminology for specifying, measuring, and evaluating
addressing the Act. Given the high-level nature of the Act, the quality of AI systems. It considers the quality model from
it is beneficial to address high-level properties of AI prod- two perspectives, product quality and quality in use. In this
ucts, which may apply to several levels of abstraction and report, we will only focus on the product quality model. The
stakeholder perspectives. In addition, alignment with existing product quality model from ISO/IEC 25059 is highlighted in
standards is relevant for organizations wishing to understand Figure 1.
theircurrentcoverageintheirdevelopmentpractices.Assuch, We extend the product quality model presented in ISO/IEC
the extended quality model proposed in this paper is based on 25059, with a specific focus on the following points:
analignmenttohigh-levelproductqualitystandards,andother • Covering relevant topics from the Act to increase trust-
existing safety standards. worthiness.ISO/IEC25059hassomegapswhenitcomes
Aside from quality models, recent literature has emerged tothecoverageofActrequirements,forexample,thereis
proposingdifferentapproachesforaddressingtheAct.Novelli alackofconsiderationforhumanoversight,transparency
etal.[10]highlighttheimportanceofaccuratelyassessingthe for different stakeholders, and ethical integrity. We have
risk of AI systems in the context of the Act. The authors added them as attributes in the extended quality model.
introduce a risk-assessment model to improve the accuracy • Integrating safety and data quality attributes in the
of this risk estimation for ethical and safe AI practices in ISO/IEC 25059 product quality model. The safety at-
accordance with the Act. While relevant to addressing the tribute, present in ISO/IEC 25010:2011 upon whichISO/IEC 25059 is based, is notably absent in ISO/IEC TABLEI
25059.Similarly,thedataqualitymodelisextendedfrom NEWORMODIFIEDDEFINITIONSOFQUALITY(SUB-)ATTRIBUTESINTHE
EXTENDEDQUALITYMODEL(SEEFIGURE1).
ISO/IEC 25012:2008 [7]. We have included it in our
extended quality model due to the high dependence of Term Definition
the quality (including safety) of the AI systems on the Ethical Theextenttowhichanentity’sactions,beliefs,meth-
quality of data. Integrity ods,measures,andprinciplesallderivefromasingle
coregroupofvalues.
• Incorporating AI-related safety properties and data qual- Human The ability for humans to understand, supervise, and
ity from other sources, such as work from [13], or the Oversight controlthedesignandoperationofAI-basedsystems.
upcomingsafetystandardforAIsystemsinroadvehicles, [16]
Fairness The extent to which a system prevents unjust pre-
ISO PAS 8800 [14].
dictions towards protected attributes (race, gender,
• Aligning ISO/IEC 25059:2023 with the updated version income, etc). Ability of the model to output fair
ofISO/IEC25010:2023.ItiscurrentlybasedonISO/IEC decisions.[9]
Privacy Theextenttowhichtheproductorsystemprotectsthe
25010:2011.
protection privacyandhandlessensitiveinformationofthestake-
The extended model is depicted in Fig. 1. Definitions for holdersinvolved(users,peopleintrainingexamples).
quality attributes and sub-attributes are given in Table I. This Value TheextenttowhichtheAIsystembehaviourisaligned
Alignment withhumanvalues.[14]
methodology can be adapted as new standards emerge regard-
Self- The extent to which the system is aware of its state
ingAIsystemproductquality.Forthesafetycharacteristic,we Monitoring so it can respond appropriately to avoid going to a
recommend using domain-specific standards, where available, harmfulstate.
Documentability seeISO/IEC/IEEE24765[17]
for a more systematic approach. For instance, combining ISO
User Degreetowhichthefunctionalitiesofthesystemare
26262 [1], ISO 21448 [15], and the upcoming ISO PAS 8800 Transparency cleartotheintendeduser.
[14] for road vehicles. Interpretability The extent to which the inner workings of the AI
system can be analyzed in order to understand why
B. MappingEUAIActArticlestotheExtendedQualityModel itbehavesthewayitdoes.
Traceability Theextenttowhichthereexistsdataandprocessesthat
The Act articles for high-risk AI systems do not provide canrecordthesystem’sdecisionsandlinkartifactsat
guidelines for achieving compliance. To enhance clarity, we differentstages.[18]
Explainability seeISO22989[19]
propose to map these articles to our extended quality model.
Accountability Capabilityofaproducttoenableactionsofahuman
Such a mapping can be leveraged to assess the coverage of tobetraceduniquelytothehuman.
the Act based on measurable properties of AI systems. We Monitorability TheextenttowhichrelevantindicatorsofanAIsystem
are effectively observed/monitored and integrated in
used our own experiences and research, coming from diverse
theoperationofthesystem.
research backgrounds, to consolidate a detailed mapping of Representative- Thedistributionofdata(orprobabilityofdistribution)
high-level requirements to quality attributes. A high-level ness truly corresponds to the information in the environ-
mentorthephenomenontobecaptured.[14]
summary of the mapping is shown in Table II. Using the
Independence Thedataataspecificlevelofarchitecturalabstraction
mapping of the Act articles to quality attributes, relevant sub-
arenotaffectedbychangestolowerlevelsofabstrac-
attributescanbeselectedandverifiedusingthecontract-based tion.separatesetsofdataareusedforspecificpurposes
approach proposed in the next section. where required (e.g. AI training data, AI validation
data).[14]
DataFairness Degree to which the data is free from bias against a
C. Contract-BasedValidationApproachforQualityAttributes
givengroup.[9]
High-risk AI applications are typically part of complex Availability Thedegreetowhichdatahasattributesthatenableitto
beretrievedbyauthorizedusersand/orapplicationsin
global supply chains, in which several stakeholders are in-
aspecificcontextofuseandwithinthetimerequired.
volved. In this context, ensuring the fair, lawful, and ethical (see[7]and[14])
development of AI applications is notably challenging. Paral- Integrity The data are unaltered either by natural phenomenon
(e.g.noise)orintentionalaction(e.g.poisoning).[14]
lels can be drawn with the recently enacted Supply Chain Act
Temporality Ageneralpropertyreferringtotemporalcharacteristics
forcompaniesheadquarteredinGermany[20].Thislegislation ofdatae.g.itstimeliness,ageingorlifetime.[14]
extends the responsibility of organizations and mandates the
safeguarding of human rights and environmental protection
throughout the entire supply chain. While not specific to safety-critical systems, any manufacturer in the supply chain
AI, this legislation provides insights into how a company’s can also be assigned responsibility. Importers and distributors
responsibility forregulatory adherence isnot simple,and may arerequiredtoverifythataproviderhasmettheirobligations.
insomecasesincludeindirectsuppliers.Asimilarperspective End users, on the other hand, are mostly given rights in the
canbeappliedtotheActwheretheresponsibilityisdefinedfor framework of the Act, but proposals for amendments have
someactorswithintheAIvaluechain,yetremainsunspecified been made to impose more requirements on them. Given
for others. the complexities arising from an ambiguous assignment of
The Act defines a set of relevant AI actors, and outlines responsibilities, stakeholders will likely need to ensure not
responsibilities for compliance depending on these defined onlytheirowncompliance,butincertaincasesthecompliance
roles. Principal responsibility for compliance is assigned to of other involved actors.
theproviderofahigh-riskAIsystem.However,inthecaseof One of the few approaches to deriving a use-case agnostic,Fig.1. ExtendedQualityModelforAIproductsforsafety-criticalapplications.
TABLEII wishing to procure AI systems with a possible solution to en-
MAPPINGOFEUAIACTREQUIREMENTSTOQUALITYATTRIBUTESFOR suring compliance with the Act. The clauses are aligned with
SAFETY-CRITICALAISYSTEMS.
the Act, and support the ethical, transparent, and accountable
Article Sub-AttributeMapping developmentofAI[21].TheCommissionhighlightsthatthese
9. Risk Management Riskidentification,Testability,ValueAlign- clauses may need to be adjusted depending on the contractual
System ment relationships. These clauses are thus limited in the sense that
10.Dataanddatagover- Independence,DataCompleteness,Current-
they do not distinguish between the obligations of the many
nance ness, Independence, Data Fairness, Preci-
sion, Representativeness, Consistency, Ac- actors discussed in the Act. Additionally, there is a need
curacy, Credibility, Temporality, Confiden- for a concrete methodology to derive technical requirements
tiality,Compliance,DataTraceability
from such contractual clauses. We propose a contract-based
11. Technical Documen- Traceability
tation approachforthesystematicvalidationoftheActrequirements
12.Record-keeping Operability, Non-repudition, Traceability, across the value chain.
Self-descriptiveness, Accountability, Self-
Monitoring,UserEngagement,Monitorabil- Ourapproachisbasedondesigncontracts.Designcontracts
ity define guarantees which are guaranteed to be fulfilled by the
13. Transparency and User Engagement, Self-descriptiveness,
stakeholder. The fulfillment of said design contract is only
provision of information User Transparency, Interpretability,
tousers Documentability, Appropiateness guaranteed given that a set of assumptions is fulfilled [22].
Recognizability Verifying EU AI Act compliance thus boils down to the
14.HumanOversight Documentability,Learnability,ValueAlign- interfacewiththedesigncontracts.Giventhatallassumptions
ment, Accountability, Interpretability, Fair-
ness, Explainability, Intervenability, Moni- are fulfilled, guarantees are assumed to be fulfilled. We
torability,UserErrorProtection. demonstrate this approach using an exemplary automotive
15. Accuracy, robust- Functional Correctness, Faultlessness, Ro- supply chain use case, shown in Fig. 2. For the sake of
ness,andcybersecurity bustness, Appropiateness Recognizability,
simplicity, we consider a car manufacturer which integrates
Self-descriptiveness, Functional Adaptabil-
ity, Fault Tolerance, Robustness, Integrity, (n) sub-systems. Each stakeholder in the supply chain may
Resistance come from different entities. The design contracts (yellow
boxes) are shown for each relevant stakeholder. The technical
requirements (green boxes) are derived from the assumptions
stakeholder-specific approach to compliance is provided in and flow between stakeholders. Stakeholder definitions are
the EU Model contractual clauses for the procurement of AI taken from [23] and [19]. An example of this validation
systems from external stakeholders. The clauses are generic approach for a chosen quality attribute is presented in the
and adaptable to specific use cases, and provide organizations following section.Fig.2. Automotivesupplychaindemonstratingstakeholderinteractionsandrespectivedesigncontracts(DCs)andtechnicalrequirements(TRs).
IV. USE-CASEDEMONSTRATION:AUTOMOTIVESUPPLY TABLEIII
CHAIN DESIGNCONTRACTFORTHEAIPRODUCTORSERVICEPROVIDER.
To demonstrate the applicability of our contract-based val- Assumptions
idation approach, we consider the typical automotive supply 1 The TSR component can be analyzed to understand its be-
chain presented in Fig. 2. Suppose we have a Traffic Sign havior.Documentationwithglobalclass-wiseexplanationsis
providedandrepresentative.
Recognition (TSR) component as a sub-system for a car
2 Appropriatedocumentationregardingthedevelopmentofthe
manufacturer, as depicted in Fig. 3. We would like to verify TSRmodelisavailable.
compliance for a given quality attribute in Table II. Due to 3 TheTSRcanexpressimportantfactorsinfluencingitspredic-
tionsinawaythathumanscanunderstand.
its applicability to Article 14: Transparency and Provision
4 Documentation from the AI system integrator regarding how
of Information to Users and Article 15: Human Oversight, sub-systemsinteractintheoverallcarisavailable.
we select Explainability (for definition see Table I) as our Guarantees
quality sub-attribute. Starting with the AI Product or Service 1 Appropriatedocumentationregardingthedesign,development,
Providerasourprimarystakeholder,wewouldseestakeholder licensing,andusagerestrictionsoftheTSRisavailable.
interactions as illustrated in Fig. 3.
The AI Provider’s assumptions would be detailed as tech-
nical requirements for the relevant stakeholders. In Table
IV, we provide examples of how these requirements might
be formulated from the technical point of view in a legal
contract. This approach provides a formal method to derive
technical requirements for Act requirements using contract-
based design.
A. Discussion
This work describes a systematic methodology that can
be used to assess the Act requirements from the perspective
of different stakeholders. The proposed approach does not
claim complete coverage of the Act. Instead, the extended
Fig.3. DesigncontractsandtechnicalrequirementselicitedbytheAIProduct quality model and the mapping should be subject to iterative
orServiceProvider.
refinement. This allows for continuous improvement as new
We first specify the design contract for the primary stake- insights emerge, regulatory frameworks evolve, or additional
holder.Wedefinetheassumptionsthatarerequiredsothatthe AI-specific attributes are identified or modified.
primary stakeholder can demonstrate compliance to the Act. The mapping does not provide a measure of the degree
In this case, we define assumptions for explainability of the of coverage of each article. The goal of the mapping at
AI component. These assumptions are exemplary and would this stage is to highlight the utility of quality models for
be refined depending on the relevant use case. From these addressing properties of AI models not addressed by current
assumptions, the AI product or service provider would define standards.Extensionstobothourmodelandourmethodology
guarantees that it can satisfy, given that the assumptions are are expected in future work.
met. An example of a design contract for the AI Product or The quantification of quality attributes remains a challenge.
Service Provider is shown in Table III. Current models lack precise metrics for evaluating criticalTABLEIV ology allows researchers and practitioners to bridge the gap
REQUIREMENTSGIVENBYTHEAIPRODUCTORSERVICEPROVIDER. betweenexistingqualitymodelsandtheregulatorydemandsof
theAct.ThisfacilitatesthedevelopmentandassessmentofAI
Technical Description Owner systems that not only adhere to established quality standards
Requirement
but also comply with the regulatory requirements outlined in
TR1 Themodelarchitectureiswelldocumented AI De-
the Act.
so that an expert user can understand the veloper
innerworkingsoftheTSRcomponent.
TR2 An ex-ante explanation is available for the AI De-
REFERENCES
user of the AI system. For example, docu- veloper
[1] “ISO 26262:2018 - Road vehicles – Functional safety, 2nd Edition,”
mentation containing global class-wise ex-
2018.
planationsisprovided,usingastate-of-the-
[2] SAEInternational,“ARP4761-GuidelinesandMethodsforConducting
artexplainabilitymethod.
the Safety Assessment Process on Civil Airborne Systems and Equip-
TR3 Documentation containing AI De-
ment,”1996.
train/test/validation data, pre- and post- veloper
[3] RTCA, “DO-178C: Software Considerations in Airborne Systems and
processingoperations,optimizationmethod,
EquipmentCertification,”2011.
lossfunction,andhyperparamatersusedfor
[4] ——, “D0-254: Design Assurance Guidance for Airborne Electronic
training,isavailable.
Hardware,”2000.
TR4 An ex-post explanation is available for the AI De- [5] “ISO/IEC 25059:2022: Software engineering — Systems and software
useroftheAIsystemwhichsatisfiesthere- veloper Quality Requirements and Evaluation (SQuaRE) — Quality model for
quiredlevelofexplainability.Forexample,a AIsystems,”2022.
local,post-modellingexplainabilitymethod [6] “ISO/IEC 25010: Systems and software engineering — Systems and
suchasSHAPisimplemented. software Quality Requirements and Evaluation (SQuaRE) — Product
TR5 The AI system integrator shall provide re- AI Sys- qualitymodel,”2023.
quirementsfortheTSRinterfacewithinthe tem In- [7] “ISO/IEC 25012: Software engineering — Software product Quality
system. tegrator RequirementsandEvaluation(SQuaRE)—Dataqualitymodel,”2008.
[8] “ISO/IEC 24028: Information technology Artificial intelligence —
Overviewoftrustworthinessinartificialintelligence,”2020.
[9] J.Siebert,L.Joeckel,J.Heidrich,K.Nakamichi,K.Ohashi,I.Namba,
aspects such as fairness, transparency, and adaptability in AI R. Yamamoto, and M. Aoyama, “Towards Guidelines for Assessing
Qualities of Machine Learning Systems,” in Quality of Information
systems.Thislackofmetricsisparticularlyproblematicinthe
and Communications Technology, M. Shepperd, F. Brito e Abreu,
contextofcontractualagreements,whereclearandquantifiable A. Rodrigues da Silva, and R. Pe´rez-Castillo, Eds. Cham: Springer
measures are essential. InternationalPublishing,2020,vol.1266,pp.17–31.
[10] C.Novelli,F.Casolari,A.Rotolo,M.Taddeo,andL.Floridi,“TakingAI
The practical implementation of certain quality attributes,
risksseriously:anewassessmentmodelfortheAIact,”AI&SOCIETY,
such as human oversight, raises questions about the applica- pp.1–5,2023.
bility of these requirements in real-world scenarios. In fully [11] F.Sovrano,S.Sapienza,M.Palmirani,andF.Vitali,“Metrics,explain-
abilityandtheeuropeanaiactproposal,”J,vol.5,no.1,pp.126–138,
autonomous vehicles, the concept of oversight is unclear,
2022.
necessitating a rethinking of how such systems are evaluated [12] J.Walters,D.Dey,D.Bhaumik,andS.Horsman,“Complyingwiththe
and regulated. EUAIact,”2023.
[13] J. Siebert, L. Joeckel, J. Heidrich, A. Trendowicz, K. Nakamichi,
Additionally, while certain attributes were adequately de-
K.Ohashi,I.Namba,R.Yamamoto,andM.Aoyama,“Constructionofa
finedforconventionalsoftware,theirapplicationtoAIsystems qualitymodelformachinelearningsystems,”SoftwareQualityJournal,
reveals new complexity. ‘Faultlessness’ in AI, for instance, vol.30,no.2,pp.307–335,Jun.2022.
[14] “ISO/PAS8800:RoadVehicles-Safetyandartificialintelligence,”Tech.
must consider the probabilistic nature of AI decisions, ne-
Rep.,inwork.
cessitating a redefinition that accounts for AI-specific error [15] “ISO/PAS21448:SafetyOfTheIntendedFunctionality–SOTIF,”2022.
types and learning biases. This reassessment is crucial for [16] European Commission, “Ethics By Design and Ethics of Use Ap-
proachesforArtificialIntelligence,”2021.
ensuring that the extended model not only introduces new
[17] “ISO/IEC/IEEE 24765: International Standard - Systems and software
attributes for AI but also appropriately reinterprets existing engineering-Vocabulary,”2017.
ones to align with the unique characteristics and demands of [18] G. Li, B. Liu, and H. Zhang, “Quality Attributes of Trustworthy
ArtificialIntelligenceinNormativeDocumentsandSecondaryStudies:
AI technologies.
APreliminaryReview,”Computer,vol.56,no.4,pp.28–37,Apr.2023.
[19] InternationalOrganizationforStandardization,“ISO/IEC22989:Infor-
V. CONCLUSION
mation technology — Artificial intelligence — Artificial intelligence
conceptsandterminology,”2022.
The EU AI Act is a transformative legislation which re-
[20] FederalMinistryofLabourandSocialAffairs,“ActonCorporateDue
shapesthegloballandscapeoffairandethicalAIdevelopment. DiligenceObligationsinSupplyChains,”January2023.
In this paper, we present a systematic methodology for ad- [21] P. R. Jeroen Naves, “Proposal for standard contractual clauses for
the procurement of artificial intelligence (ai) by public organisations,”
dressingtherequirementsforhigh-riskAIproductsintroduced
September2023.
in the Act. We develop an extended quality model for AI [22] A. Benveniste, B. Caillaud, D. Nickovic, R. Passerone, J.-B. Raclet,
systems, and propose to map these quality attributes to the P.Reinkemeier,A.Sangiovanni-Vincentelli,W.Damm,T.A.Henzinger,
andK.G.Larsen,Contractsforsystemdesign. Hanover,Massachusetts:
Act requirements. To address compliance, a contract-based
NowPublishers,2018.
approach for defining technical requirements is presented, en- [23] N. N. G. d. Andrade and A. Zarra, “Artificial Intelligence Act: A
suring that stakeholders across complex supply chains adhere Policy Prototyping Experiment: Operationalizing the Requirements for
AISystems–PartI,”Rochester,NY,Nov.2022.
to the EU AI Act regulations. Our design contracts foster a
flexible and structured approach to compliance. This method-