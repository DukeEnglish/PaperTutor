Iterative Refinement of Project-Level Code Context for Precise Code
Generation with Compiler Feedback
ZhangqianBi1,YaoWan1,ZhengWang2,HongyuZhang3,BatuGuan1,
FangxinLu4,ZiliZhang5,YuleiSui6,XuanhuaShi1, and HaiJin1
{zqbi, wanyao, hjin}@hust.edu.cn
Abstract
(a) Task Prompt
Large language models (LLMs) have shown Enhance the image by first reducing
remarkable progress in automated code gen- noise and then adjusting brightness and
eration. Yet, incorporating LLM-based code contrast.


generationintoreal-lifesoftwareprojectsposes
(b) Generating and Identifying Errors
challenges,asthegeneratedcodemaycontain
errors in API usage, class, data structure, or def enhance_image(img: Image):

denoised_img = reduce_noise(img)

missingproject-specificinformation. Asmuch ...
ofthisproject-specificcontextcannotfitinto
thepromptsofLLMs,wemustfindwaystoal- Error: missing ‘reduce_noise’.

Synonyms:

lowthemodeltoexploretheproject-levelcode def denoising.denoise(img)
context. To this end, this paper puts forward
anovelapproach,termedPROCODER,which (c) Generating with Correct Context
iteratively refines the project-level code con-
import denoising

textforprecisecodegeneration,guidedbythe def enhance_image(img):

denoised_img = denoising.denoise(img)

compilerfeedback. Inparticular,PROCODER
...
firstleveragescompilertechniquestoidentify
a mismatch between the generated code and
Figure 1: Example illustrating limitations of LLM-
theproject’scontext. Ittheniterativelyaligns
basedcodegeneration: (a)taskprompt,(b)wrongso-
and fixes the identified errors using informa-
lutionanderroridentification,and(c)correctsolution
tion extracted from the code repository. We
utilizingprojectcontext.
integratePROCODERwithtworepresentative
LLMs, i.e., GPT-3.5-Turbo and Code Llama
generatingcodebasedonnaturallanguageintent
(13B),andapplyittoPythoncodegeneration.
andthecontextofsurroundingcode. Whileexist-
ExperimentalresultsshowthatPROCODERsig-
ingLLM-basedcodegenerationtoolsexcelinhan-
nificantlyimprovesthevanillaLLMsbyover
dlingsmallcodesamples,suchascompletingthe
80%ingeneratingcodedependentonproject
context,andconsistentlyoutperformstheexist- currentlineorthebodyofamethodorgivingex-
ingretrieval-basedcodegenerationbaselines. amplesofastandardAPI,integratingLLM-based
codegenerationintoreal-lifesoftwareprojectsre-
1 Introduction
mainschallenging(Lietal.,2024).
Largelanguagemodels(LLMs),especiallythose
Practicalcodegenerationforsoftwareprojects
pre-trained on code, as demonstrated by tools
requiresusingproject-specificcontextslikeclasses,
such as GitHub Copilot (Friedman, 2021), Ama-
methods, and data structures due to modularity,
zon’sCodeWhisperer(Amazon,2023),andChat-
maintenance,andcodeindependencerequirements.
GPT(OpenAI,2023a),arerevolutionizinghowde-
velopersapproachprogrammingbyautomatically
However,therepository’ssizeoftenexceedsthe
1 ServicesComputingTechnologyandSystemLab,Big capacityoftheprompt,challengingLLMstocom-
Data Technology and System Lab, Cluster and Grid Com-
prehend extensive contexts (Liao et al., 2023; Li
puting Lab, School of Computer Science and Technology,
HuazhongUniversityofScienceandTechnology,China etal.,2024). Also,studieshavedemonstratedthat
2 UniversityofLeeds,U.K. irrelevantcontextinpromptspotentiallycompro-
3 ChongqingUniversity,China
misesthemodelperformance(Shietal.,2023). In-
4 South–CentralMinzuCollegeforNationalities,China
5 ShanghaiJiaoTongUniversity,China puttingonlythetaskrequirementscanleadLLMs
6 UniversityofNewSouthWales,Australia to overlook project-specific APIs, classes, data
4202
raM
52
]LC.sc[
1v29761.3042:viXrastructures, or type information specific to a soft- code. For a given LLM-generated code sample,
wareproject’srepository,riskingomittingessential PROCODERfirstcompilesitandidentifiescontext-
logicduringcodegeneration(Gifanyetal.,2013). relatederrors. Itthenretrievestherelatedcontext
fromthecoderepositorytofixtheerrors. Thisiter-
Asamotivationexample,considerthethecase
ativegenerationandverificationprocessproceeds
shown in Figure 1. In this case, we use the Ope-
repetitively until no error is identified in the gen-
nAI GPT-3.5-Turbo API to generate an image-
enhancingfunctionbyfirstreducingthenoticeand
eratedsolution. Wedemonstratethat PROCODER
enhancestheaccuracyofgeneration(asindicated
thenadjustingbrightnessandcontrast. Giventhe
by pass rates) by bridging the gap between the
promptinFigure1a,theLLMwillproduceacode
repositorycontextandtheintendedsolution.
snippet of calling a reduce_noise method as
depictedinFigure1b. Althoughthegeneratedcode
We evaluate PROCODER by applying it to the
CoderEvalbenchmarkingdataset(Yuetal.,2023),
followsastandardworkflowspecifiedinthetask
which consists of code generation tasks utilizing
prompt, it leads to a compilation error in our ap-
plicationcontextbecausereduce_noiseisnot
project-specific context. We test PROCODER on
twopopularcodegenerationmodels: theGPT-3.5-
implemented. This is unsurprising as the prompt
Turbo(OpenAI,2023a)andCodeLlama(Rozière
doesnotprovideenoughproject-levelcontextfor
etal.,2023). Experimentalresultsdemonstratethat
theLLM,andcanbefixedbyprovidingtheproject-
specificfunctiondenoising.denoiseascon-
PROCODERsignificantlyimprovestherepository-
levelcodegenerationperformanceofdifferentde-
text,asillustratedinFigure1c. Whileacarefully
pendency levels, outperforming the baseline by
engineered prompt may resolve this issue, it is
over80%relativepassratesingeneratingfunctions
not always possible for the user to generate such
dependentonproject-specificcontexts. Moreover,
prompts,andtheprojectcontextmaybetoolarge
ouriterativemethodconsistentlyenhancestheper-
tofitintotheprompt. Aswewillshowlaterinthe
formanceofvanillaretrieval-augmentedgeneration.
paper,sucherrorsarecommonlyfoundwhenapply-
Wealsoprovideacomprehensiveanalysisoftheef-
ingLLMstorepository-levelcodegeneration(Li
etal.,2024).
fectivenessandlimitationsofPROCODER,offering
insightsforfutureresearch.
This paper investigates a way to effectively in-
Thispapermakesthefollowingcontributions:
tegrateLLM-basedcodegenerationwithexisting
code implementations within a software project. • Anempiricalstudytoanalyzetheerrordistribu-
Oursolutionistoleverageproject-levelcontextual tioninself-containedandrepository-levelcode
information,suchasproject-specificimplementa- generation,highlightingthesignificanceofpre-
tion of classes, methods, and data structures, to ciseandgroundedprogramcontextingenerating
reducecompilationerrorsandimprovecodequal- codeattheprojectlevel(Section2.2);
ity. Directlyincorporatingtheentireprojectcode
• Anewiterativegeneration-verification-retrieval
into a language model is infeasible due to model
method that leverages the program compiler to
inputsequencelengthlimitations. Instead,weuse
eliminate context-related errors in repository-
compiler-basedanalysistopost-processthemodel-
levelcodegeneration(Section3);
generatedcodebyfirstdetectingdiscrepanciesbe-
• Extensive experiments and analysis based on
tween the generated code and the project’s con-
twoLLMs,i.e.,GPT-3.5-TurboandCodeLlama
text. Wethenutilizeinformationextractedfromthe
(13B),validatetheeffectivenessofourproposed
projectcodebasetorectifythemismatchesinusing
modules, APIs, and classes. Our approach com-
PROCODER(Section5).
bines well-established compiler techniques with
2 Background
emerging generative methods, allowing software
developers to leverage the power of LLMs with- 2.1 LLM-basedCodeGeneration
out being overwhelmed and discouraged by the
Ourworktargetsthecodegenerationtask,which
frequent compilation and semantic errors in the
produces source code from a natural-language
model-generatedcode.
description complemented by programming con-
We present PROCODER, a method to allow an text (e.g., project-specific APIs, data structures,
LLMtoleveragethecoderepositoryofasoftware and so on). We denote such input as x. Given
project to enhance the quality of the generated x, it is first converted to a sequence of tokensTable1: Severaltypicalerrorsreportedincompilation Error Type API OBJECT UNDEF OTHER FUNC
andexecution.
14% 17%
ErrorType Example 2%
UNDEF Noname’AsyncBolt5x0’inmodule’neo4j._sync.io._bolt5’ 7% 34% 1%
API Novalueforargument’xmls’infunctioncall
OBJECT ’function’objectisnotsubscriptable 5%
FUNC Thegeneratedfunctionnotpassesatestcase
OTHER Parsingfailed:’expectedanindentedblockafterfunctiondefinition 1%
72%
47%
Function−level Project−level
x = [x ,...,x ],andagenerationmodelp (x)
1 |x| LM
predict new tokens sequentially. At each step t,
the LM calculates the probability distribution of Figure 2: Distribution of error types in the generated
thenexttokenasp (x |x ). Theprobability solutionsonCoderEvaldataset.
LM t 1:t−1
of generating a program y with token sequence
y = [x ,...,x ] is computed as a prod- Thisdatasetcomprises85function-leveltasksand
|x|+1 |x|+|y|
145project-leveltasks. Specifically,weselectthe
uctofnext-tokendistributionsgivenleftcontext:
GPT-3.5-TURBO(OpenAI,2023a)asatargetLLM
|x|+|y| for function-level code generation. Based on it,
(cid:89)
P(y|x) = p LM(x t|x 1:t). (1) we choose a state-of-the-art method, termed Re-
t=|x|+1 poCoder(Zhangetal.,2023a),whichretrievesthe
project-levelcontextasaugmentationandfeeds5
Forfew-shotlearningwithlargeLMs,thegenera-
codefragmentsthathavethehighestDPRsimilar-
tion is also often conditioned on a fixed set of m
ity score (Karpukhin et al., 2020) in prompt for
exemplars, {⟨x ,y ⟩} . Thus, the LLM-based
i i i≤m bettercodegeneration.
codegenerationcanbeformulatedas:
Asthecodeisgenerated,wecompilethecode
andcollecttheerrorsreportedbythecompileror
P (y|x) = P(y|x,{⟨x ,y ⟩} ). (2)
LM i i i≤m
in testing. Each generated code snippet contains
Practically, the probability of the next token x precisely one type of error. If multiple errors are
t
depends on a fixed number of preceding tokens reportedbythecompiler,themostcommonerror
x : x , defined by the model’s win- typeisselectedforanalysis. Theerrordistribution
max(1,t−w) t−1
dowlengthw,whichmaynotencompasstheentire revealed that four specific types of errors consti-
softwareproject’scodebase. tute the majority of all errors encountered. We
categorizetheseerrorsinto: 1)UNDEF,involving
2.2 ErrorAnalysisinCodeGeneration UseofUndefinedSymbol,2)API,involvingIncor-
Theperformanceofsimplefunction-levelcodegen- rectUseofAPIs,3)OBJECT,involvingImproper
eration has significantly improved, evidenced by UseofanObject,4)FUNC,involvingRuntimeor
an increase in the pass rate from a pass rate of FunctionalErrors,and5)OTHER,involvingOther
31.6%withCodeT5(Wangetal.,2021)to94.7% SyntaxandSemanticErrors. Table1presentssev-
in the state-of-the-art Code Llama model (Roz- eral errors encountered in compiling and testing.
ière et al., 2023) on the widely-used HumanEval Oneexampleisthe“UNDEF”error,whereavari-
benchmark(Chenetal.,2021). However,arecent able AsyncBolt5x0 is referenced but does not
study(Yuetal.,2023)showsthatexistingLLMs existinthespecifiedmodule.
forcodegenerationstruggletogeneratecodesnip- Figure2illustratesthedistributionoferrortypes,
pets that are dependent on the project context in- under the scenario of function-level code gener-
formation, such as private APIs, types, and vari- ation and project-level code generation. From
ables. Tothisend,variousbenchmarks,including this figure, we can observe that the majority of
ClassEval (Du et al., 2023) and CoderEval (Yu errorsareruntimeorfunctionalerrors,accounting
etal.,2023),havebeendevisedtoassesstheperfor- for 72% and 34% for function-level and project-
manceofLanguageModelsingeneratingcontext- level code generation, respectively. Furthermore,
dependentcodewithintheproject. theUNDEF errorsandtheAPI errorsaccountfor
Tobetterillustrateourmotivation,weperforman substantially high portions of 21% and 64% for
empiricalanalysisofwhentheLLMsfailtogener- function-level and project-level code generation,
atecomplexcodethatisdependentonproject-level respectively. PROCODERaddressesbothtypesof
context,ontheCoderEvaldataset(Yuetal.,2023). errorsassociatedwithprojectcontextbysupplyingExtracted Project Context
Code Files Abstract Syntax Trees async/bolt.py async/_bolt3.py main.py sync/bolt.py ...
amsayinnc./pby

olt3.py

 aas asy syn ync nc/ cb//obblot ol.p lty t33..ppy

y


c p . c p . l r .a c l r .a o .d “l d “s aa o .d “ys t ”e R Ress t ”e Rns of e fs e s of e ct c g tA u/ ct eouS gb s touS g rlry e _yo nlry e nn t hnl nn tt h b _ Bac. h b _ aBB hp B n oaBB h noo ay

 lo d tnoo a dll n l l t dll n pltt d e:
 rltt d re l:
 ( oe l:
 re ) tre sr :
 osr ( c ( o)
)
 l handlers”
 c h .A c h .n l a .S l a .aa n .d “ ya n .d “ms d ”e R ns d ”e Res lf e cs lf eet Bet c ruS g oruS gl sry e lsry ea nn t t nn ts b _ b _s BB h b BB hoo a o oo all n d fll ntt d y utt d l:
 n l:
 pe cperr trro( io(t)
 ot)
o noccooll c fl oa " rs " s " B o S lA e ts r y v pn e rc r oB to c ol o ct n o:
 n le .c t "i "o "

n c Bl oa " ls " ts " 3 H aA pns rdy oln tec orB c o ofl lot .r3 " : " " f3 c l a .s .s .
 SyncBo fl 2t:
 ...
<to be completed> g de ln t ea _ rm he an “ Bd R oo e lc t tu r .n .. .. ”. @ p d r ec " ofl <" ta t" os og cs e R om bt e le _ et t h u hh a cr ao n on nd d
m
dl
p
B le lo er el r( tt sp
e
._ d"v >"er "
):
 f1 c a l a " Bs " os " lt D eB cfo oil nnt neS est c a tst ite oas nt( .eE "sn " u fm "
o) r:
 R SCO E TN A RN D EE Y AC MT I=E N D G"R = E = A " "D SYCO " TN RN EE AC MT IE ND G" " FC Vu ala n rs ics at bio len
(a) Project-level Context Extraction
Iterations Retrieval Context Generated Solution Error Feedback
Task Requirement
I class SyncBolt:
 def get_handler(p_ver):

R h vaae lt n uu d er l n e or fB s p o b _l a vt s ep e rr d fo oot ro n c to hl e ( ) f2 d e f f S r yg o ne m ct B_ . oh _ la b tn o 3
d ll te 3r ( ip m_ pv oe rr t
):
 f Sr yo i nm m c p B. o o_ r lb t to 3l .St y h3 n a c nB do ll et r(3
 )... N mo o dn ua lm e ae s' yS ny cn .c _B bo ol lt t3 3' in
AsyncBolt.

 II module neo4j._sync.io._bolt3:
 def get_handler(p_ver):

class AsyncBolt:
 class AsyncBolt3:
 from ._bolt3
f 1 d e f <g te ot __ bh ea _n cd ol me pr l( ep t_ ev de >

r):
 f3 c ld ae sf s Bh oa ln td Sl te ar( te) s: :. . ...
 . LLMs i Am sp yo nr ct B olA ts 3y .nc hB ao nl dt l3
 er()... Compiler No compilation error
(b) Iterative Context Refinement
f1
Figure3:OverviewofthePROCODERmethod:(a)theproject-levelcodecontextextractionprocess,and(b)iterative
refinementtofixcompiler-reportederrors.
therelevantprojectcontext. Experimentsdemon- transformeachsourcecodefilewithintheproject
strate that PROCODER not only fixes these two intoanAbstractSyntaxTree(AST),extractingtree
typesoferrorbutalsomitigatesothercompilation nodesthatcorrespondtoclasses,functions,orvari-
errorsbyprovidingfeedbackonerrormessagesto ables. Subsequently, if a node of these types is
thelanguagemodel,leadingdirectlytoanimprove- foundtobeachildofanothernode(e.g.,thefunc-
mentinpredictionaccuracy. tion get_handler and the class AsyncBolt
in Figure 3(a)’s AST) , an edge is created from
3 Methodology
the parent node to the child node, establishing a
hierarchicalrelationship.
3.1 Overview
Take the function f from Figure 3(a) as an
1
Figure3depictstheworkflowof PROCODER,con-
example. From this figure, we can see that
sisting of two crucial components: 1) a method
both its semantics (e.g., its docstring), and
for extracting project-level code context through
its syntactic relation between the parent class
bothsyntacticandsemanticapproaches,and2)a
AsyncBoltandfileasync/bolt.pyarecap-
componentresponsibleforiterativegenerationand
tured. This establishes finding the function from
evaluationofsolutions. Thisprocessrefinestheso-
the project syntactically using its qualified name
lutionsincrementally,ensuringtheyevolvetowards
async/bolt.py:AsyncBolt.get_handler,
anerror-freestatethatseamlesslyalignswiththe
orsemanticallyaccordingtoitsdocstring“Return
project’senvironment.
Boltprotocolhandlers.”.
3.2 Project-LevelCodeContextExtraction
3.3 Retrieval-AugmentedCodeGeneration
Supposingthatthecodegenerationtoolsareacti-
vatedataspecificjuncture. Inlightofthenatural We leverage project-level code context in the
language requirement and the code produced by retrieval-augmentedgenerationparadigm(Zhang
LLMsafteraninitialiteration,ourobjectiveisto et al., 2023a; Ding et al., 2022; Karpukhin et al.,
extractthesemanticcontextofthegeneratedcode 2020),whichhasbeenwidelyadoptedtointegrate
fromtheproject’scodebase. factualknowledgeintoLLMsandaddresshalluci-
Unlike plain texts, source code has syntactic nation issues. In practice, we commence by ex-
structures that enable precise identification of el- tracting project-level context from the database
ements in a project. Thus, in practice, we em- through the construction of a Structured Query
ploy syntax-directed program analysis (Harrold Language (SQL) query. Following this, we en-
and Rothermel, 1996) at various points through- hance the acquired context by retrieving similar
outtheofflinestagetoextractthecodecontextat codesnippetsbasedonthedensepassageretrieval
the project level. We initially employ a parser to techniques(Karpukhinetal.,2020).
...
...(a) Prompt for SQL Synthesize utilizinganencodernetwork,asfollows:
Task instruction:Please generate SQL according to given error line
content and error message.
h = ENCODER(q). (3)
Error Line Content:loggerDict.RootLogger(msg) q
Error Message: No name 'RootLogger' in module ‘loggerDict’ Demonstration
FROM Module m, Variable v WHERE m.getName() = ‘loggerDict’ Examples
SELECT v In our experiments, the pre-trained Trans-
Error Line Content:from ._bolt3 import AsyncBolt3 former (Vaswani et al., 2017) is adopted as the
Error Message:No name ‘SyncBolt3’ in module ‘async._bolt3’
SQL:[to be completed] encodernetwork.
Aftergeneratingthequeryvector,wecalculate
(b) Prompt for Code Generation
the cosine similarity between the query and em-
Task instruction: Please generate code following the task requirement,
fixing errors in previous solution according to relevant context (if exist). bedding vectors of each context entry h . This
c
Task Requirement:Check if in given list of numbers, are any two num-
similaritymeasureisdefinedas:
bers closer to each other than given threshold. Demonstration
Desired Solution:def has_close_elements(numbers: List[float], Examples
threshold: float) -> bool ... ⊺
h h
Task Requirement:Return Bolt protocol handlers based on the value of sim(h ,h ) = q c . (4)
p_ver for AsyncBolt. q c ||h ||·||h ||
Last Solution: def handlers(p_ver): q c
from ._bolt3 import SyncBolt3
... Compiler
Error Line Content:from ._bolt3 import SyncBolt3 Feedback Thetop-nentriesexhibitingthehighestsimilarity
Error Message:No name ‘SyncBolt3’ in module ‘async._bolt3’
tothequeryareretrievedasresults.
Project Context: module neo4j._async._bolt3:
class AsyncBolt3: Retrieved
def get_handler(): ... Context
class BoltStates: ... 3.4 RefinementwithCompilerFeedback
Desired Solution: [to be completed]
Figure 3(b) showcases the iterative refinement
Figure 4: Prompt examples for SQL synthesize and pipeline. Given the task requirement and partial
codegeneration. function f 1, a semantic retrieval is activated to
identify similar functions. Specifically, the func-
Based onthe compiler feedback, weaim to re- tion f , which provides equivalent functionality
2
trieve the relevant project-level context from all in synchronous scenario, is identified. Utilizing
extractedones. Weimplementthisbytransforming both the retrieved context and the prompt illus-
the textual compiler feedback into an SQL query tratedinFigure4(b),thelanguagemodelgenerates
usingtheChatGPT.Thepromptusedispresented asolution;However,thegeneratedoutputmistak-
in Figure 4(a). Here, several examples of paired enlyinvokesSyncBolt3duetoitsintendeduse
compilerfeedbackandSQLqueriesareprovided in asynchronous scenarios, not aligning with the
asdemonstrationsforin-contextlearning1.
synchronous scenario in f The compiler’s feed-
2
For instance, consider the compiler feed- back highlights this error. With this feedback,
back: Noname’SyncBolt3’foundinmodule PROCODER conducts a hybrid structural and se-
’async._bolt3’,theresultingSQLquerygen- manticsearch,leadingtothediscoveryofthecor-
eratedbyChatGPTisasfollows: rectfunctionf forasynchronousscenarios. Incor-
3
poratingtheerrordetailsandcontextintothenext
FROMModulem,Classc
iterationensuresaccuratefunctioninvocation. This
WHEREm.contains(c)
process goes iteratively until no error is reported
andm.getName()=‘async._bolt3’
bythecompiler,resultinginanerror-freesolution
SELECTm,c
thatalignswiththeproject’senvironment.
Using this SQL query, the code snippets that 4 ExperimentalSetup
involvetheimplementationsofAsyncBolt3will
bereturnedfromourconstructeddatabase. 4.1 Datasets
To validate the effectiveness of PROCODER, we
Semantic Search. In addition to returning the
conductedexperimentsusingtheCoderEvalbench-
project-levellevelretrievedbytheSQLquery,we
mark(Yuetal.,2023),arecentlydevelopedbench-
also enhance the acquired context by retrieving
mark designed to evaluate models within realis-
similarcodesnippetsusingdensepassageretrieval.
ticsoftwaredevelopmentscenarios. Withoutloss
Specifically, given a natural language query q,
ofgeneralizability,weconcentrateonthePython
we first convert it into an embedding vector by
programming language within this dataset. This
benchmarkcategories230testsamplesintosixlev-
1Only one demonstration example is illustrated in Fig-
ure3(b),thefulllistofexamplescanbefoundinAppendixC. elsofcontextdependency: 1)self-contained: built-Table2: PassratesofPROCODERbasedontwoLLMs,i.e.,GPT-3.5-TurboandCodeLlama(13B),assessedagainst
variousbaselinesacrossdifferentdatasplitsofCoderEval.
DataSplit ClassRunnable FileRunnable ProjectRunnable
Method Pass@1 Pass@5 Pass@10 Pass@1 Pass@5 Pass@10 Pass@1 Pass@5 Pass@10
LLM:GPT-3.5-Turbo
Direct 8.73 12.57 14.55 19.85 27.62 30.88 9.57 12.08 13.04
ReACC 20.36 33.27 38.18 17.65 28.92 33.82 11.30 19.53 21.74
RepoCoder 35.45 40.46 41.82 29.41 34.61 36.76 16.96 19.57 21.74
PROCODER 28.00 44.92 49.09 30.29 43.58 47.06 21.30 36.73 39.13
LLM:CodeLlama(13B)
Direct 18.91 30.65 34.55 18.53 27.82 29.41 5.22 8.70 13.04
ReACC 20.36 33.27 38.18 17.65 27.61 33.82 11.30 19.53 21.74
RepoCoder 17.82 35.22 40.00 15.00 28.31 32.35 16.09 21.36 21.74
PROCODER 26.36 39.42 41.82 17.06 29.39 33.82 13.04 28.04 34.78
in types/functions, no imports required; 2) slib- ing them to augment the prompts of LLMs. One
runnable: standardlibraries/modules,noinstalla- distinguishingfeatureisthatthisbaselinedoesnot
tionneeded; 3)plib-runnable: publicly-available leveragecompilerfeedback.
librariesonPyPI/Maven;4)class-runnable: code
4.3 ImplementationDetails
outside the function but within a class; 5) file-
runnable: code outside the class but within the Intheinferenceprocess,wesetthedecodingtem-
file;and6)project-runnable: codeinothersource peratureto0.7,andadoptatop-ksamplingstrategy.
files. Weconcentrateonthelastthreedependency Weimplementtheretrievalmodulesbasedonthe
types,wherethesolutionsaredependentonproject- text-ada model introduced by OpenAI (OpenAI,
specificcontexts. Thereare55,68,and23tasksas- 2023b),whichiseffectiveinbothnaturallanguage
sociatedwitheachdependencylevel,respectively. search and code search. The dimension for each
embeddingis1,536. Weretrieveatmost5entries
4.2 BaselineMethods foreachquery. Alltheexperimentsinthispaperare
conductedonaLinuxserverwith128GBmemory,
PROCODERcanfunctionseamlesslybeintegrated
withasingle32GBTeslaV100GPU.
into existing LLMs, requiring only black-box ac-
cesstothesemodels. Inthispaper,weselecttwo 4.4 EvaluationMetrics
state-of-the-artLLMsforcodegeneration,namely
Followingpreviousstudies(Chenetal.,2021;Yu
GPT-3.5-Turbo(OpenAI,2023a)andCodeLlama
etal.,2023),weevaluatethefunctionalcorrectness
(13B) (Rozière et al., 2023), as our base models.
ofthegeneratedcodebyexecutingtestcases. We
To validate the effectiveness of PROCODER, we
employ the Pass@k metric, where k denotes the
compareitwiththefollowingbaselines:
number of programs generated for each task. A
▷ Direct Generation (Yu et al., 2023). This line
task is solved if at least one solution passes all
of method denotes directly inputting the task re-
unittests,andwereporttheoverallproportionof
quirementsintoLLMforcodegeneration,without
solved tasks. To reduce sampling variance, we
providingadditionalcontext.
generate n ≥ k solutions (for this study, n = 20
▷ ReACC (Lu et al., 2022). We employ the
andk = 1,5,10)foreachtask,countthenumber
retrieval-augmented generation technique intro-
ofcorrectsolutionsc ≤ nthatpasstheunittests,
duced in this baseline for code generation tasks.
andcalculatetheunbiasedestimator:
More precisely, we retrieve semantic contexts (cid:34) (cid:0)n−c(cid:1)(cid:35)
alignedwiththetaskinstructionsandleveragethem Pass@k = E 1− k . (5)
(cid:0)n(cid:1)
to augment the prompts of LLMs for better code
k
generation.
5 ResultsandAnalysis
▷ RepoCoder (Zhang et al., 2023a). Similar to
ourwork,thereferencedbaselinealsoproposesthe
5.1 OverallPerformanceof PROCODER
iterativerefinementofgeneratedcode. Specifically, Table 2 shows the overall performance of
itinvolvesretrievingsimilarcodesnippetsderived PROCODER based on two LLMs, i.e., GPT-3.5-
from the previously generated ones, and employ- Turbo and Code Llama (13B), assessed againstTable3: PassRatesonCoderEval-Pythonofeachap-
CoCoGen No Feedback RepoCoder
proachwithorwithoutcompilerfeedback.
UNDEF API
Method Pass@1 Pass@5 Pass@10
5000
Direct 20.65 26.66 29.13 4000 1500
Direct+CF 32.34 38.43 40.43 3000 1000
2000 500
ReACC 34.13 41.44 43.48 1000
ReACC+CF 36.60 44.05 46.52 0 1 2 3 0 1 2 3
RepoCoder 36.82 40.73 42.17
RepoCoder+CF 38.00 45.38 48.26 OBJECT OTHER
125
100
100
CoCoGen No Feedback RepoCoder 75
Class−level File−level Project−level 50 50
50 50 40 25
0 1 2 3 0 1 2 3
45
45 30
40 Number of Iterations
40
20
35
35 Figure 6: Compilation errors reported and fixed per
30 10
0 1 2 3 0 1 2 3 0 1 2 3
iterationofPROCODER,RepoCoder,andNoFeedback
baselines.
Number of Iterations
Figure5: PerformanceofPROCODER,RepoCoder,and
tableenhancementinmodelperformanceforcode
NoFeedbackbaselineacrossthreedependencylevels.
generation. Specifically, a comparison between
RepoCoder with and without compiler feedback
variousbaselinesacrossdifferentdatasplits. This
revealsasubstantialincreaseinPass@1from36.82
figureshowsthatthePROCODERcansignificantly
to 38.00. Note that, the RepoCoder+CF here is
outperform other baselines on the project-level
code generation across different data splits. This
equivalenttoourproposed PROCODER.
trendpersists,withafewexceptionsnotedspecif-
5.3 EffectivenessoftheIterativeRefinement
ically in terms of Pass@1. We attribute such ex-
ceptions to variations in the generated solutions. Here,weinvestigatetheeffectivenessofiterative
Selecting a significantly larger n (e.g., 1000), as refinementincodegenerationwithcompilerfeed-
discussed in (Li et al., 2022), stabilizes expec- back. WeconductanablationanalysisonbothRe-
tations. Significantly, according to Code Llama poCoderandPROCODER,viaremovingorretain-
(13B), when evaluated on the intricate project- ingtheiterativerefinementprocess. Figure5shows
runnabledataset, PROCODER demonstratessupe- the performance of RepoCoder and PROCODER,
riorperformancecomparedtothestate-of-the-art withrespecttovaryingiterations,ondifferentdata
RepoCoder,achievingan87.7%highersuccessrate splits. This figure clearly illustrates that as the
atPass@5anda79.9%improvementatPass@10. numberofiterationsincreases,theperformanceof
Moreover, it becomes evident that models incor- PROCODERalsoexhibitsacorrespondingimprove-
poratingcontextualinformation,suchasReACC, ment. Itsubstantiatestheefficacyofoursuggested
RepoCoder, and PROCODER, exhibit a notewor- iterativerefinementprocess,demonstratingitsabil-
thyperformancesuperiorityoverthevanillamodel, itytoenhancethegeneratedcodethroughmultiple
therebyaffirmingthepracticalvalueofcontextual iterationsprogressively.
information.
5.4 ErrorAnalysisandCaseStudy
5.2 UsefulnessofCompilerFeedback
Wealsoperformanerroranalysisofthegenerated
Here,weexaminetheusefulnessofcompilerfeed- codeiniterativegeneration. Wefollowthecatego-
back by integrating it into three baseline models: rizationoferrorsdefinedinSection2.2,examples
Vanilla,ReACC,andRepoCoder,eachconsidered of each error type can be found in Table 1. We
separately. We conducted experiments using the exclude FUNC errors because they are reported
GPT-3.5-Turboandsubsequentlyreportedtheav- inexecutioninsteadofbythecompiler. Figure6
eragescoreacrosstheentireCoderEvaldataset,as showsthedistributionoferrorsresolvediteratively
showninTable3. Thetableprovidesclearevidence byour PROCODER andtwobaselines. Fromthis
thatincorporatingcompilerfeedbackyieldsano- figure,wecanseethattheerrorsofvarioustypes
01@ssaP
srorrE
fo
rebmuNT a s k R e q u i r e m e n t Use the value in timedelta to generate the Structure class.
 CodeGeeX2(Zhengetal.,2023),alongsidecom-
def dehydrate_timedelta(value):
 Context class timedelta: self.days

:param value:
 self.seconds ... mercial offerings like GPT-3.5 (OpenAI, 2023a),
:type value: timedelta class Structure:

def __init__(self, tag, fields) Gemini(Google,2024),andLLM-poweredcoding
Reference Solution
def dehydrate_timedelta(value):
 assistanttoolssuchasGitHubCopilot(Microsoft,
days = value.days

seconds = value.seconds
 2024)andTabnine(Tabnine,2024). Thesemodels
microseconds = value.microseconds

nanoseconds = microseconds * 1000

return Structure(b\"E\", days, seconds, 0, nanoseconds) andtoolshavedemonstratedsignificantpromisein
Co dC efo G de en h’s y dS ro alu tt eio _n t: imedelta(value):
 enhancingcodegenerationcapabilities.
months = 0

days = value.days

seconds = value.seconds

nanoseconds = 1000 * value.microseconds
 Context-awareCodeGeneration. Inthecontext
return Structure(b\"E\", months, days, seconds, nanoseconds)
ofproject-levelcodegeneration,harnessinginfor-
mationbeyondthecurrentfilehasbeenfounduse-
Figure7: AnerrorcasefromCoderEval-Python.
ful. Theprojectcanbeextractedstructurallyinto
canbeeffectivelyresolvedafterasingleiterationof
variousformslikerelationaldatabase(Pashakhan-
refinement. Forinstance,UNDEF errorswereno-
looetal.,2022),APIdependencygraph(Lyuetal.,
tablyreducedfrom5133to1042afteroneiteration.
2021), and class hierarchies (Zhang et al., 2021).
Additionally,itwasobservedthattheRepoCoder
Shrivastavaetal.(2023)proposesacodecomple-
baseline, which operates without compiler feed-
tionframeworkusingrepository-levelpromptpro-
back, managed to rectify API and syntax errors,
posals,andthenapplyingaclassifiertoclassifyuse-
corroboratingthefindingsin Zhangetal.(2023a).
fulproposals. (Luetal.,2022;Zhangetal.,2023a)
Nonetheless,itprovedineffectiveagainstUNDEF
proposetousesingleormultiplelevelsofretrieval-
andOBJECT errors,likelyduetothemodel’slack
augmented generation mechanisms for code gen-
ofawarenessregardingtheseerrorsintheabsence
eration. (Yu et al., 2023; Liu et al., 2023; Zhou
ofcompilerfeedback.
etal.,2022)proposesbenchmarksanddatasetsfor
TothoroughlyevaluatePROCODER’seffective-
repository-levelcodesynthesistasks. Inourwork,
ness,wefocusedonscenarioswherecompilation
we select two code models, namely GPT-3.5 and
was successful, but execution failed. In the case
CodeLlama,andretrieveprojectcontextforfixing
illustratedinFigure7,PROCODERincorrectlyex-
context-relatedcompilationerrors,toenhancethe
cludes the mileseconds field and erroneously
precisionofcodegeneration.
addsamonthfield. Thiserrorstemsfromambigu-
ouslystatedtaskrequirementsandthemodel’slack 7 Conclusion
offamiliaritywiththeStructureclass’sformat,
despite its definition being available, resulting in Inthiswork,weshowhowtouseproject-specific
misinterpretationoftheintendedfunctionality. Fur- contextinformation,indexedstructuralandseman-
ther examples are detailed in Appendix A. This tic,tofixcompilationerrorsgeneratedbycompilers
observation inspires us to integrate a comprehen- andimprovethequalityofcodegeneratedbyLMs.
sivereferencecomprisingbothdocumentationand Ourexperimentalresultsshowtheincreasedpreva-
websearchresultstoprovideexplicitusageguide- lenceoferrorsrelatedtoprojectcontextsinproject-
linesinourfuturework. levelcodegenerationcomparedtofunction-level
code generation. The presented PROCODER can
6 RelatedWork effectivelyfixthecompilationerrorsbyretrieving
relatedcontextfromtheproject,thussignificantly
LLM-basedCodeGeneration. Automatedcode
improvingthenativeLLMbaselinesonover80%
generationhasahistoryspanningseveraldecades,
relative pass rates in generating functions depen-
with initial endeavors utilizing rule-based sys-
dentonproject-specificcontexts.
tems(Backusetal.,1957;Woods,1973)andstruc-
turedprediction(ZelleandMooney,1996;Zettle-
Limitations
moyer and Collins, 2005). In recent years, the
development of large-scale language models has In this study, we utilize compilation information
led to the emergence of many prominent mod- as a means to validate programs. However, it is
els in coding tasks. These include open-access importanttonotethatevenprogramsthatcompile
modelssuchasDeepSeekCoder(Bietal.,2024), successfullycanexperienceexecutionfailures. Fur-
CodeLlama(Rozièreetal.,2023),CodeGen(Ni- thermore,thesuccessfulcompilationofprograms
jkampetal.,2022),StarCoder(Lietal.,2023),and does not guarantee their safety for execution. Asaresult,whileourfindingsindicateimprovements plan, HarriEdwards, YuriBurda, NicholasJoseph,
inqualitymetricsthroughthecorrectionofcodeto Greg Brockman, et al. 2021. Evaluating large
language models trained on code. arXiv preprint
properlyleveragecontext,itisimperativetounder-
arXiv:2107.03374.
takeadditionalverificationmethodssuchastesting
andmanualreviewtoascertainthefunctionalcor- Yangruibo Ding, Zijian Wang, Wasi Uddin Ahmad,
rectnessofthegeneratedcode. Thechallengeofen- Murali Krishna Ramanathan, Ramesh Nallapati,
Parminder Bhatia, Dan Roth, and Bing Xiang.
suringfunctionalcorrectnessofcodeencompasses
2022. Cocomic: Codecompletionbyjointlymod-
variousaspects,includingcompliancewithtaskre-
eling in-file and cross-file context. arXiv preprint
quirements,adherencetopre/post-conditionsand arXiv:2212.10007.
securityrequirements,andpreservingrobustnessin
XueyingDu,MingweiLiu,KaixinWang,HanlinWang,
generatingcode. Withmanyquestionsunanswered,
Junwei Liu, Yixuan Chen, Jiayi Feng, Chaofeng
wehopeourstudycanpromoteabroaderviewof Sha, Xin Peng, and Yiling Lou. 2023. Classe-
utilizingcomputationallinguistictechnologiesin val: A manually-crafted benchmark for evaluating
therealmofautomatedsoftwareengineering. llmsonclass-levelcodegeneration. arXivpreprint
arXiv:2308.01861.
EthicsStatements
NatFriedman.2021. Introducinggithubcopilot:yourai
pairprogrammer. URLhttps://github.blog/2021-06-
We meticulously ensured that all code and mod-
29-introducing-github-copilot-ai-pair-programmer.
elsintegratedintoourresearchadheretoopenac-
cesspoliciesasoutlinedbytheCreativeCommons DGifany,ISAmiri,MRanjbar,andJAli.2013. Logic
license. The methodology ensures full compli- codesgenerationandtransmissionusinganencoding-
decodingsystem. InternationalJournalofAdvances
ancewithcopyrightandintellectualpropertylaws,
inEngineering&Technology,5(2):37.
therebyeliminatinganypotentialforinfringement
or unauthorized use of protected materials. By Google. 2024. Gemini. https://deepmind.
exclusivelyutilizingresourcesthatarefreelyavail- google/technologies/gemini/. [Online;
accessed1-Feb-2024].
ableandlegallydistributable,wemaintainthehigh-
eststandardsofethicalconductinresearch. This MaryJeanHarroldandGreggRothermel.1996. Syntax-
approach fosters an environment of transparency directedconstructionofprogramdependencegraphs.
and respect for the intellectual property rights of TechnicalReportOSU-CISRC-5/96-TR32.
others. Ourcommitmenttotheseprinciplesensures
VladimirKarpukhin,BarlasOg˘uz,SewonMin,Patrick
thatourworkadvancesthefrontiersofknowledge Lewis,LedellWu,SergeyEdunov,DanqiChen,and
inamannerthatisbothlegallysoundandethically Wen-tau Yih. 2020. Dense passage retrieval for
open-domain question answering. arXiv preprint
responsible.
arXiv:2004.04906.
JiaLi,GeLi,YunfeiZhao,YongminLi,ZhiJin,Hao
References
Zhu,HuanyuLiu,KaiboLiu,LechengWang,Zheng
Fang,etal.2024. Deveval: Evaluatingcodegener-
C Amazon. 2023. Ai code generator—amazon code-
ationinpracticalsoftwareprojects. arXivpreprint
whisperer.
arXiv:2401.06401.
J.W.Backus,R.J.Beeber,S.Best,R.Goldberg,L.M.
Haibt,H.L.Herrick,R.A.Nelson,D.Sayre,P.B. Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas
Sheridan, H. Stern, I. Ziller, R. A. Hughes, and Muennighoff,DenisKocetkov,ChenghaoMou,Marc
R. Nutt. 1957. The fortran automatic coding sys- Marone,ChristopherAkiki,JiaLi,JennyChim,etal.
tem. In Papers Presented at the February 26-28, 2023. Starcoder: maythesourcebewithyou! arXiv
1957, Western Joint Computer Conference: Tech- preprintarXiv:2305.06161.
niques for Reliability, IRE-AIEE-ACM ’57 (West-
YujiaLi,DavidChoi,JunyoungChung,NateKushman,
ern),page188–198,NewYork,NY,USA.Associa-
Julian Schrittwieser, Rémi Leblond, Tom Eccles,
tionforComputingMachinery.
James Keeling, Felix Gimeno, Agustin Dal Lago,
XiaoBi,DeliChen,GuantingChen,ShanhuangChen, etal.2022. Competition-levelcodegenerationwith
DamaiDai,ChengqiDeng,HonghuiDing,KaiDong, alphacode. Science,378(6624):1092–1097.
QiushiDu,ZheFu,etal.2024. Deepseekllm: Scal-
ingopen-sourcelanguagemodelswithlongtermism. DianshuLiao,ShidongPan,QingHuang,XiaoxueRen,
arXivpreprintarXiv:2401.02954. Zhenchang Xing, Huan Jin, and Qinying Li. 2023.
Context-awarecodegenerationframeworkforcode
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming repositories: Local, global, and third-party library
Yuan,HenriquePondedeOliveiraPinto,JaredKa- awareness. arXivpreprintarXiv:2312.05772.Tianyang Liu, Canwen Xu, and Julian McAuley. YueWang,WeishiWang,ShafiqJoty,andStevenCH
2023. Repobench: Benchmarkingrepository-level Hoi. 2021. Codet5: Identifier-aware unified pre-
code auto-completion systems. arXiv preprint trainedencoder-decodermodelsforcodeunderstand-
arXiv:2306.03091. ingandgeneration. InProceedingsofthe2021Con-
ferenceonEmpiricalMethodsinNaturalLanguage
Shuai Lu, Nan Duan, Hojae Han, Daya Guo, Seung- Processing,pages8696–8708.
wonHwang,andAlexeySvyatkovskiy.2022. Reacc:
Aretrieval-augmentedcodecompletionframework. W.A.Woods.1973. Progressinnaturallanguageun-
arXivpreprintarXiv:2203.07722. derstanding: an application to lunar geology. In
Proceedings of the June 4-8, 1973, National Com-
Chen Lyu, Ruyun Wang, Hongyu Zhang, Hanwen
puterConferenceandExposition,AFIPS’73,page
Zhang,andSonglinHu.2021. Embeddingapidepen-
441–450,NewYork,NY,USA.AssociationforCom-
dencygraphforneuralcodegeneration. Empirical
putingMachinery.
SoftwareEngineering,26:1–51.
HaoYu,BoShen,DezhiRan,JiaxinZhang,QiZhang,
Microsoft. 2024. Microsoft Copilot.
Yuchi Ma, Guangtai Liang, Ying Li, Tao Xie, and
https://www.microsoft.com/zh-cn/
Qianxiang Wang. 2023. Codereval: A benchmark
microsoft-copilot. [Online; accessed
of pragmatic code generation with generative pre-
1-Feb-2024].
trainedmodels. arXivpreprintarXiv:2302.00288.
ErikNijkamp,BoPang,HiroakiHayashi,LifuTu,Huan
Wang,YingboZhou,SilvioSavarese,andCaiming JohnM.ZelleandRaymondJ.Mooney.1996. Learn-
Xiong. 2022. Codegen: An open large language ingtoparsedatabasequeriesusinginductivelogic
model for code with multi-turn program synthesis. programming. InProceedingsoftheThirteenthNa-
arXivpreprintarXiv:2203.13474. tionalConferenceonArtificialIntelligence-Volume
2,AAAI’96,page1050–1055.AAAIPress.
OpenAI. 2023a. chatgpt. http://chat.openai.
com. [Online;accessed1-Feb-2023]. LukeS.ZettlemoyerandMichaelCollins.2005. Learn-
ing to map sentences to logical form: structured
OpenAI. 2023b. New and improved embedding classificationwithprobabilisticcategorialgrammars.
model. https://openai.com/blog/ In Proceedings of the Twenty-First Conference on
new-and-improved-embedding-model.
UncertaintyinArtificialIntelligence,UAI’05,page
[Online;accessed1-Feb-2023]. 658–666,Arlington,Virginia,USA.AUAIPress.
Pardis Pashakhanloo, Aaditya Naik, Yuepeng Wang,
FengjiZhang,BeiChen,YueZhang,JinLiu,Daoguang
HanjunDai,PetrosManiatis,andMayurNaik.2022.
Zan, Yi Mao, Jian-Guang Lou, and Weizhu Chen.
Codetrek: Flexiblemodelingofcodeusinganexten-
2023a. Repocoder: Repository-levelcodecomple-
siblerelationalrepresentation.
tionthroughiterativeretrievalandgeneration. arXiv
preprintarXiv:2303.12570.
BaptisteRozière,JonasGehring,FabianGloeckle,Sten
Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi,
Jingyu Liu, Tal Remez, Jérémy Rapin, et al. 2023. JiyangZhang,SheenaPanthaplackel,PengyuNie,Ray-
Codellama:Openfoundationmodelsforcode. arXiv mondJMooney,JunyiJessyLi,andMilosGligoric.
preprintarXiv:2308.12950. 2021. Learning to generate code comments from
classhierarchies. arXivpreprintarXiv:2103.13426.
Freda Shi, Xinyun Chen, Kanishka Misra, Nathan
Scales,DavidDohan,EdHChi,NathanaelSchärli, Tianyi Zhang, Tao Yu, Tatsunori Hashimoto, Mike
andDennyZhou.2023. Largelanguagemodelscan Lewis, Wen-tauYih, DanielFried, andSidaWang.
be easily distracted by irrelevant context. In Inter- 2023b. Coderreviewerrerankingforcodegeneration.
national Conference on Machine Learning, pages InInternationalConferenceonMachineLearning,
31210–31227.PMLR. pages41832–41846.PMLR.
Disha Shrivastava, Hugo Larochelle, and Daniel Tar- QinkaiZheng,XiaoXia,XuZou,YuxiaoDong,Shan
low.2023. Repository-levelpromptgenerationfor Wang,YufeiXue,ZihanWang,LeiShen,AndiWang,
largelanguagemodelsofcode. InInternationalCon- YangLi,etal.2023. Codegeex: Apre-trainedmodel
ferenceonMachineLearning,pages31693–31715. forcodegenerationwithmultilingualevaluationson
PMLR. humaneval-x. arXivpreprintarXiv:2303.17568.
Tabnine.2024. Tabnine. https://www.tabnine.
ShuyanZhou,UriAlon,FrankFXu,ZhengbaoJiang,
com/. [Online;accessed1-Feb-2024].
andGrahamNeubig.2022. Docprompting: Gener-
atingcodebyretrievingthedocs. InTheEleventh
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
International Conference on Learning Representa-
Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz
tions.
Kaiser,andIlliaPolosukhin.2017. Attentionisall
you need. In Proceedings of Advances in neural
informationprocessingsystems,pages5998–6008.T a s k R e q u i r e m e n t : Returns the key in the form of int.

def index(self, key):
 T a s k R e q u i r e m e n t : Dynamically Generating Point Class.

: : :p r re ta ytr u pa r em n : : i k nie n t
y d: e a x
 key
 Context: c l a s s _ _R ke ec yo sr :d ( t) .:
 Tuple[str] d e f : : p td yae prh eay m vd ar v la uat ee l :u_ tt e ii :
 mm ee dd ee ll tt aa(value):
 Context: c s sl r ra i is d ds _ _ t tP a ao b bi l ln e et
 _= l o{ c}
 k = Lock()

Reference Solution: def index(self, key):
 Reference Solution:
if isinstance(key, int):
 def point_type(name, fields, srid_map):

if 0 <= key < len(self.__keys):
 def srid(self):

return key
 try:

raise IndexError(key)
 return srid_map[len(self)]

elif isinstance(key, str):
 except KeyError:

try:
 return None

return self.__keys.index(key)
 attributes = {\"srid\": property(srid)}

except ValueError:
 for index, subclass_field in enumerate(fields):

raise KeyError(key)
 def accessor(self, i=index, f=subclass_field):

else:
 try:

raise TypeError(key)

 return self[i]

except IndexError:

CoCoGen’s Solution: raise AttributeError(f)

def index(self, key):
 for field_alias in {subclass_field, \"xyz\"[index]}:

return int(key) attributes[field_alias] = property(accessor)

cls = type(name, (Point,), attributes)

with srid_table_lock:

FigureA1: Anerrorcaseofdegenratesolution. for dim, srid in srid_map.items():

srid_table[srid] = (cls, dim)

return cls




A MoredetailsabouttheErrorCases
CoCoGen’s Solution:
def point_type(name, fields, srid_map):

fields_dict = {f: i for i, f in enumerate(fields)}

Inthissection,wedelveintoadditionalcaseswhere srid = srid_map.get(len(fields), None)

class Point:

PROCODERstrugglestogenerateviablesolutions, def __init__(self, *args):

if len(args) != len(fields):

elucidatingtheunderlyingcausestofosterfurther raise ValueError(\"Wrong number of arguments\")

self._coordinates = tuple(args)

self._srid = srid

research. Weidentifytwoprimaryfactorsleading @property

def srid(self):

toexecutionerrorsdespitesuccessfulcompilation: return self._srid

@srid.setter

degeneratesolutions,suchasoverlysimplisticorre- def srid(self, value):

self._srid = value

def __iter__(self):

dundantcode. Thisphenomenonisdiscoveredand return iter(self._coordinates)

def __eq__(self, other):

exploredin(Zhangetal.,2023b). FigureA1exem- return isinstance(other, Point) and
self._coordinates == other._coordinates

plifiesthisissue,showcasingasolutionthatomits def __repr__(self):

return f\"{name}({', '.join(

map(str, self._coordinates))})\"

necessaryvaliditychecksanderrorhandling,nei- return Point
therofwhicharespecifiedinthetaskrequirements, FigureA2:Anerrorcaseofmisinterpretingtaskrequire-
norproducedbyPROCODER’soutputs. Ouranaly- ments.
sisrevealsthatdegeneratesolutionsfrequentlypass tices. However,ourfocusissolelyontheerrors.
compilation,renderingcompiler-basedverification Eacherrorisidentifiedbyanerrorcodeandde-
ineffective. scribedwithanerrormessage. Theerrorcodeisa
Anotherprevalentmistakeinvolvesmisinterpret- numericalidentifierthatreflectstheerror’snature,
ing task requirements, resulting in solutions that whiletheerrormessageprovidesaconcisedescrip-
lack logical coherence. Figure A2 depicts an in- tionoftheerror. Pylintrecognizes133distinct
stance where the assignment was to leverage the errortypes,andonly12ofthesearereportedfre-
pre-existing Point class; instead, the language quentlyontheCoderEvaldataset. Wehavecatego-
modeldisregardsthisspecificationandredundantly rized these errors into four groups based on their
recreatestheclass. Thisunderscoresthechallenge characteristics, detailed in Table 1. The FUNC
largelanguagemodels(LLMs)faceinaccurately error category is also included in the error distri-
comprehendingpromptsandgeneratingappropri- butionanalysisbutisexcludedfromthecompiler
atesolutions. feedbackpipeline. Thisexclusionisbecausesuch
errorscanonlybeidentifiedwithexecution,apro-
B ErrorsReportedbytheCompiler
cessthatextendsbeyondthescopeofstaticanalysis
andisunsuitableforthereal-timegenerationand
Weutilizepylintforerrorchecking;itisastatic
refinementpipeline. Thespecifictypesofeacher-
code analyzer designed to inspect code within a
rorandcorrespondingerrorcodesaredocumented
projectwithoutexecutingit. Theanalyzeraccepts
inTableA1.
the entire file containing the solution along with
associatedsourcefilesasinput,andthenitextracts
C DemonstrationExamplesofStructural
errorsthatpertaindirectlytothelinesinthegener-
Queries
atedsolutionfromtheentiretyofidentifiederrors.
pylintgeneratesarangeofdiagnosticmessages, WepresentademonstrationexampleinSection3.3
encompassingerrors,warnings,recommendations tocomposethestructuralquery. Theexamplefo-
foradheringtolanguageconventions,andsugges- cuses on identifying and addressing instances of
tionsforrefactoringtoadheretobestcodingprac- missingorincorrectlyutilizedcontextentries. WeTableA1: Acompletelistoffrequentlyoccurrederrorsreportedbythecompiler
ErrorCategory ErrorID Corresponding ErrorReason
ErrorCode
UNDEF-P E0401 UnabletoimportaPackage.
UNDEF-CM E1101 AClassisaccessedforanunexistentMember.
UNDEF
UNDEF-API E0611 AfunctionorAPIcannotbefoundinamodule.
UNDEF-O E0602 AnundefinedvariableorObjectisaccessed.
API-TMA E1121 AfunctioncallpassesTooManypositionalArguments.
API-IA E1120 AfunctioncallpassesInsufficientArguments.
API
E1111 Assignmentfromthefunctionthatdoesn’treturnanything.
API-WA
E1123 Afunctioncallpassesakeywordargumentwhichhasnocorrespondingformalparameter.
OBJ-NI E1133 ANon-Iterablevalueisusedinplacewhereiterableisexpected.
OBJ OBJ-NC E1102 AnobjectbeingcalledisaNon-Callableobject.
OBJ-NS E1136 AsubscriptedvaluedoesNotsupportSubscription.
OTHER OTHER Othererrorsreportedbyanalyzer.
TableA2: Acompletelistofdemonstrationexamplespromptedtothelanguagemodel
ErrorType ExampleErrorMessage Action ExampleStructuralQuery
UNDEF-P Unabletoimport’keys’ Confine the search scope in all from Module m where
modules m.inSource() and
v.getScope() = m select
m
UNDEF-CM Instanceof’RootLogger’hasno Confine the search scope in all from Module m, Class
’loggerDict’member membersintheclass c, Function cf where
m.inSource() and
m.contains(c) and
c.contains(cf) and
cf.getScope() = c and
c.getName = ’RootLogger’
and not cf.isInitMethod()
select m, c, cf
UNDEF-API No name ’AsyncBolt5x0’ in Confine the search scope in all from Module m, Variable
module’neo4j._sync.io._bolt5’ namesinthemodule v where m.inSource()
and v.getScope() =
m and m.getName() =
’neo4j._sync.io._bolt5’
select m,
v.getDefinition()
API Novalueforargument’xmls’in Return the information of the from Module m, Function
functioncall’dumpXML’ function f where m.inSource()
and m.contains(f) and
f.getName() = ’dumpXML’
select m, f
detailseveralexampleerrormessagesalongwith files, we employ the tree-sitter-python
theircorrespondingstructuralqueries. Acompre- parser for generating abstract syntax trees and
hensivelistoftheseexamplescanbefoundinTa- codeql-python to extract the property of a
bleA2. context entry node. For passage encoding, we
utilize text-embedding-ada-002, a model
D AlgorithmforProjectDatabase providedbyOpenAIandaccessibleviaanonline
Construction API.
Wepresentthecomprehensivealgorithmforcon-
structingtheprojectdatabaseandgeneratingcode
with PROCODER.
Thealgorithmforbuildingtheprojectdatabase
isdetailedinAlgorithm1. Itinvolvesidentifying
sourcefilesintheprojectbyextractingallfilesthat
endwitha.pyextension. ToparsePythonsourceAlgorithm1ProjectDatabaseConstruction
Require: SOURCEFILESET: Asetofprojectsourcefiles
Require: PARSER: Aparserforsourcefiles
Require: ENCODER: Apassageencodertransformstexttonumericalvector
Ensure: databaseEntries: Entriesintheprojectdatabase
1: databaseEntries ← ∅
2: foreachsourceFilein SOURCEFILESETdo
3: nodesForVisit ← ⟨⟩
4: propertyPrefixSeq ← ⟨⟩
5: astFile ← PARSER(sourceFile)
6: nodesForVisit.ADD(astFile.rootNode)
7: whilenodesForVisitisnotemptydo
8: currentNode ← nodesForVisit.POP()
9: ifcurrentNodeis PREFIXMARKthen
10: propertyPrefixSeq.POP()
11: endif
12: ifcurrentNode.typeisin[VARIABLETYPE, FUNCTIONTYPE, CLASSTYPE]then
13: nodeProperty ← GETPROPERTIES(currentNode)
14: nodeSchema ← ⟨propertyPrefixSeq,currentNode,nodeProperty⟩
15: nodeEmbedding ← ENCODER(nodeSchema)
16: databaseEntries.ADD([nodeSchema,nodeEmbedding])
17: propertyPrefixSeq.PUSH(currentNode)
18: nodesForVisit.PUSH(PREFIXMARK)
19: endif
20: forchildNodeincurrentNode.CHILDS()do
21: nodesForVisit.PUSH(childNode)
22: endfor
23: endwhile
24: endfor