TEI GO: A Multilingual Approach for
2
Fast Temporal Expression Identification
HugoSousa RicardoCampos AlípioJorge
UniversityofPorto UniversityofBeiraInterior UniversityofPorto
INESCTEC INESCTEC INESCTEC
Porto,Portugal Covilhã,Portugal Porto,Portugal
hugo.o.sousa@inesctec.pt ricardo.campos@ubi.pt alipio.jorge@inesctec.pt
ABSTRACT thetimingofeventsoractions[5].Timexscanbebroadlycatego-
Temporalexpressionidenti￿cationiscrucialforunderstanding rizedintotwoclasses:explicit,suchas“26ofMay2023”,whichcan
textswritteninnaturallanguage.Althoughhighlye￿ectivesys- beunderstoodwithoutcontext,andimplicitexpressionslike“last
temssuchasHeidelTimeexist,theirlimitedruntimeperformance year”,whichrequireadditionalcontextforproperinterpretation.
hampersadoptioninlarge-scaleapplicationsandproductionenvi- Understandingtimexsiscriticalforaccuratenarrativecomprehen-
ronments.Inthispaper,weintroducetheTEI2GOmodels,matching sionandisavitalcomponentinthedevelopmentoftemporally
HeidelTime’se￿ectivenessbutwithsigni￿cantlyimprovedruntime, awarenaturallanguageprocessing(NLP)systems[29].
supportingsixlanguages,andachievingstate-of-the-artresultsin Theextractionoftemporalinformationfromatextbeginswith
fourofthem.TotraintheTEI2GOmodels,weusedacombination theidenti￿cationofthetokensthatrefertotimexs,ataskknown
ofmanuallyannotatedreferencecorpusanddeveloped“Profes- astimexidenti￿cation(TEI).Duetoitsfoundationalimportance
sorHeidelTime”,acomprehensiveweaklylabeledcorpusofnews andwidespreadimplicationsinNLPapplications,TEIhasgarnered
textsannotatedwithHeidelTime.Thiscorpuscomprisesatotalof signi￿cantinterestwithintheresearchcommunity.Inparticular,
138,069documents(oversixlanguages)with1,050,921temporal TEIhasbeenshowntogreatlyimpactdownstreamtaskssuchas
expressions,thelargestopen-sourceannotateddatasetfortemporal summarization[15],questionanswering[38],and,morebroadly,
expressionidenti￿cationtodate.Bydescribinghowthemodels ininformationretrieval[2,3,7].
wereproduced,weaimtoencouragetheresearchcommunityto WhilenumerousautomaticTEIsystemsexist[40],eachhasits
furtherexplore,re￿ne,andextendthesetofmodelstoadditional limitations.Rule-basedmodels[9,34],forexample,canachieve
languagesanddomains.Code,annotations,andmodelsareopenly highe￿ectivenessinspeci￿cdomainsandlanguagesbutarelabor-
availableforcommunityexplorationanduse.Themodelsarecon- intensivetodevelop,requiringexpertstode￿nerulesandanan-
venientlyonHuggingFaceforseamlessintegrationandapplication. notatedcorpustoevaluatethem.Deepneuralmodels[1,17],on
theotherhand,canmoreeasilygeneralizetonewdomainsand
CCSCONCEPTS languages,butrequiresubstantialamountsofannotateddatato
achievealevelofe￿ectivenesscomparabletorule-basedapproaches.
•Informationsystems Informationextraction;•Comput-
! Nevertheless,theprimarybottleneckforexistingsystemsliesin
ingmethodologies Machinelearning.
! theirslowruntimeperformance,i.e.,theamountoftimeittakesto
producethepredictionsatinferencetime.Forinstance,ittookus
KEYWORDS
eightdaystoannotateroughly25,000documentswithHeidelTime
temporalexpressionidenti￿cation,weaklabel,multilingualcorpus
(seeSection4fordetailsabouttheannotationprocess).Suchrun-
ACMReferenceFormat: timesareimpracticalformostapplicationsandlimittheadoptionof
HugoSousa,RicardoCampos,andAlípioJorge.2023.TEI2GO:AMultilin- thesystemsand,ultimately,thedevelopmentoftemporallyaware
gualApproachforFastTemporalExpressionIdenti￿cation.InProceedings systems.
ofthe32ndACMInternationalConferenceonInformationandKnowledge Totacklethesechallenges,weinvestigatearangeofneuralar-
Management(CIKM’23),October21–25,2023,Birmingham,UnitedKingdom. chitecturesandlibrariestocreateTEImodelsthataree￿ective,
ACM,NewYork,NY,USA,6pages.https://doi.org/10.1145/3583780.3615130
scalable,andabletoattainproduction-gradeperformance.Inthis
1 INTRODUCTION
paper,wepresenttheTEI2GOmodels,asetofsixmodelstrainedfor
TEI,eachtailoredtoaspeci￿clanguage:English,French,German,
Temporalexpressions(timexshenceforth)playapivotalroleinwrit- Italian,Portuguese,andSpanish.Thesemodelsstemfromtheappli-
tenandspokennarratives,providingessentialinformationabout cationoftheapproachwefoundtobemoste￿ectiveinthecontext
ofexistingresearch(Section2):framingthetaskasasequencela-
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalor
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed belingproblemandtrainingthespaCyentity-recognitionmodelon
forpro￿torcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation acorpusthatcombineshumanandweaklylabeleddata(Section3).
onthe￿rstpage.Copyrightsforcomponentsofthisworkownedbyothersthanthe
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or Totrainourmodels,wemadeuseof15high-qualitydatafrom
republish,topostonserversortoredistributetolists,requirespriorspeci￿cpermission benchmarkdatasetsanddevelopedaweaklylabeleddataset.For
and/orafee.Requestpermissionsfrompermissions@acm.org. thelatter,wecollectedalargecollectionofnewstexts,foreach
CIKM’23,October21–25,2023,Birmingham,UnitedKingdom
oftheabove-referredlanguages,andannotatedthemwithHeidel-
©2023Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM.
ACMISBN979-8-4007-0124-5/23/10...$15.00 Time.WedubbedthiscorpusProfessorHeidelTime(Section4).To
https://doi.org/10.1145/3583780.3615130CIKM’23,October21–25,2023,Birmingham,UnitedKingdom HugoSousa,RicardoCampos,andAlípioJorge
illustratethequalityofthedevisedmodelswepresentacompre- ofthesystems.However,recentlyAlmasianetal.[1]leveraged
hensiveevaluationstudy,andshowcasethattheproposedmodels acorpuslabeledwithHeidelTimetostabilizethetrainingofa
yieldresultsthatareeitherstate-of-the-art(SOTA)orcomparable transformer-basedsystemforTEIinGerman.Nevertheless,the
torule-basedsystemswhileretainingtheadaptabilityofneural corpushasneverbeenmadepublicduetoprivacyconcerns.With
modelsandaruntimetwoordersofmagnitudefasterthanbaseline ProfessorHeidelTimeweintendtobridgethisgapbyprovidinga
systems(Section5).Inpracticalterms,thismeansthatacorpus largeweaklylabeledcorpusforTEI.
annotationtakingonesecondwithourmodelswouldrequire100 Despiteconsiderablee￿ortsindevelopingamoree￿ectiveTEI
secondswithbaselinesystems.Weconcludebyhighlightingand system,currentsystemsdonottakeruntimeperformanceinto
discussingfutureresearchopportunities(Section6). consideration.OurmodelsareuniqueinthattheyachieveSOTA
Our main contributions are as follows: (1) we introduce the e￿ectivenesswhilealsohavingamuchfasterruntime.
TEI2GOmodels,asetofsixTEImodelsthatachieveHeidelTime
e￿ectivenesswithasubstantiallyfasterruntimethatcanbeim- 3 TEI 2GOMODELS
mediatelyusedbythecommunityinanyrelevantdownstream Applyingpre-trainedlargelanguagemodelstoNLPtaskshasproven
taskorapplication;(2)wemakeavailabletheannotationsofthe highlybene￿cialinvariousscenarios,particularlywhendealing
weakly-labeleddatasetproducedwithHeidelTime–ProfessorHei- withlimitedannotateddata[28].Althoughthisapproachhasbeen
delTime–alongwiththenecessarycodetoretrievethedocuments; showntoimprovetheSOTAresultsintwobenchmarkdatasets[8],
(3)wepresentacomprehensiveevaluationon21benchmarkcor- thesemodelstendtoberesource-intensiveandoftenrequirespe-
poraspanningsixlanguages,whereTEI2GOmodelsachieveSOTA cializedhardwarefore￿cientexecution,renderingthemunsuitable
results. foraddressingtheperformancelimitationsofexistingTEIsystems.
Afterexploringnumerousalternatives,weidenti￿edthespaCy
entity-recognitionmodelasasuitableapproach1.Threecentral
2 RELATEDWORK
aspectssetthismodelapart,makingitanidealcandidateforTEI.
Numerousstudieshavefocusedontherepresentationoftemporal First,themodelleverageshashembeddings,whicho￿ergreater
informationintext[5,20,31],leadingtotheemergenceofseveral e￿ciencyintermsofmemoryusageandruntimewhilemaintaining
annotatedcorpora[4,11,14].Theavailabilityofsuchresourcesen- comparablee￿ectiveness[30].Second,thecoreofthemodelisbuilt
abledtheTempEvalsharedtasksseries[40,42],whichsigni￿cantly onatransition-basedparser[16]thatemploysamultilayerpercep-
boostedthedevelopmentofTEIsystems.Duringthatperiod,several trontodeterminetheappropriatetransitionforeachtoken.This
highlye￿ectivesystemsemerged,includingHeidelTime[34,36], designchoiceresultsinafastmodelwithlinear-timeperformance,
whichiscurrentlythemostpredominantsystemfortheautomatic whileretainingtheadaptabilityofdeepneuralmodels.Lastly,the
identi￿cationoftimexs.Beingarule-basedsystem,HeidelTime modelistrainedusingtheBILUOscheme,whichhasbeenem-
wasdesignedtohavehighe￿ectiveness.However,toattainsuch piricallyobservedtooutperformthetraditionalIOBscheme[26].
e￿ectiveness,anexpertisrequiredtocreatetherulesandanan- Theseadvantages,coupledwithspaCy’sbuilt-infeaturessuchasto-
notatedcorpusisneededtotestthem,makingitchallengingto kenizationandextensivelanguagesupport,strengthenthecasefor
expandintonewlanguagesanddomains.ThismotivatedStrötgen leveragingthespaCyentity-recognitionmodelinTEIapplications.
andGertz[37]todevelopAuto-HeidelTime,whichautomatically TheideabehindtheTEI2GOmodelsistotrainthisarchitecture
extendstheHeidelTimerulesetto(practically)everylanguage. ona combinationofmanually annotated referencecorpus and
Unfortunately,theautomaticextensionresultedinasigni￿cant weaklylabeleddata.Bycombiningbothapproaches,weaimto
decreaseinthesystems’e￿ectiveness.Althoughotherrule-based leveragethebestofbothworlds,thatis,high-qualitywithlarge
methodsexist[9,13,43],theyarelesse￿ectivethanHeidelTime. volume.
Sincetheemergenceoflargelanguagemodels[12,41],mostof
theNLPbenchmarkleaderboardshavebeendominatedbythem.In 4 PROFESSORHEIDELTIME
therealmofTEI,thesepre-trainedmodelshavedemonstratedadapt-
Toaddressthechallengesposedbythescarcityofannotateddatato
abilitywhilemaintainingmoderatee￿ectiveness[1,8,10,17,18].
trainneuralmodels,weconstructedaweakly-labeledmultilingual
Thescarcityofannotateddata(evenforEnglish)hasledtoareliance
dataset2,whichwillbeused,togetherwithbenchmarkdatasets,to
ontechniquesthatcompilecorporafrommultiplelanguages.For
trainourTEI2GOmodels.Forthelabelingprocess,weemployed
instance,Langeet.al.[17]wasabletooutperformAuto-HeidelTime
HeidelTime,asithasalargelanguagecoverageandpresentsSOTA
infourout-of-domainlanguagesbyusingadversarialtrainingto
resultsinmostofthem.
aligntheembeddingsspacesacrosslanguages.Incomparisonto
Thedatasetcreatedencompassessixlanguages,namelyEnglish,
HeidelTime,though,theirmodelperformedpoorly.Anothernote-
French,German,Italian,Portuguese,andSpanish.Inthecaseof
worthyworkisXLTime[8],whichemployedmulti-tasklearning
Italian,English,German,andFrench,wewereableto￿ndlarge
andtranslationtoachieveSOTAresultsintwobenchmarkcorpus
open-sourcecollectionsofnewsdocumentsthatmetourrequire-
(PortugueseandBasque).
ments,namely:alicensethatallowstheredistributionofthedataset,
Weaksupervision[23,27],anotheralternativeforhandlingthe
havingmorethanonemilliontokens,andincludesnotjustthetext
lackofannotateddata,involvestrainingmodelsoncorporalabeled
butalsothepublicationdateofeachnewsarticlewhichisneeded
programmatically.Thisideawas￿rstusedintheTEItaskinthe
TempEval-3sharedtask[40]withtheTrainT3corpus.Atthetime, 1https://spacy.io/api/entityrecognizer
theweaklylabeledcorpusproveddetrimentaltothee￿ectiveness 2https://github.com/hmosousa/professor_heideltimeTEI2GO:AMultilingualApproachforFastTemporalExpressionIdentification CIKM’23,October21–25,2023,Birmingham,UnitedKingdom
forHeidelTimetonormalizethetemporalexpressions.Forthese Table2: Distributionofthenumberoftimexsforeachofthe
fourlanguages,wereleasetheannotationalongwiththetexts. corpusoverthetrain,validation,andtestset.Thereference
Fortheremainingtwolanguages,SpanishandPortuguese,we corpusforeachlanguageishighlightedinboldface.Column
werenotableto￿ndopen-sourcecollectionsthatmatchedour “D”standsfordomainandcantaketovalues“Nw”and“Na”
criteria.Tosurmountthisobstacle,wecreatedscriptstoscrape representingNewsandNarratives,respectively.
referencenewssourcesfromtherespectivecountries.Weareac-
tivelycollaboratingwiththesenewssourcestomakethedatasets D Train Validation Test
publiclyavailable.Meanwhile,we’vereleasedtheannotationand
TempEval-3[40] Nw 1,472 338 138
open-sourcedthescripts,completewithacomprehensiveguideon
howtoreplicatethecompilationofthenewsarticles3,allowing TCR[24] Nw 126 29 62
EN AncientTimes[33] Na 142 125 39
thecommunitytolegallyrecreatetheSpanishandPortuguesecol-
WikiWars[21] Na 2,166 117 357
lectionsofProfessorHeidelTime.Moredetailsaboutthecompiled
P.HeidelTime Nw 165,385 18,469 46,307
corpuscanbefoundinthecoderepositories.
TimeBank[11] Nw 911 171 145
AnnotationProcess. Theannotationofthedocumentswas PT
P.HeidelTime Nw 63,135 6,977 17,404
madewithHeidelTimePythonWrapperpy_heideltime4.Forthe
annotationprotocol,weallocatedacomputationtimebudgetof TimeBank[14] Nw 939 155 198
eightdaysperlanguage.Withinthistimeframe,theautomatic TrainT3[40] Nw 821 58 215
ES
annotatorsequentiallyprocessedthecollection,annotatingeach AncientTimes[33] Na 152 39 21
documentatthetime.Documentscontainingnon-UTF-8characters, P.HeidelTime Nw 226,393 25,242 63,110
malformedormissingdocumentcreationtimes,oranyHTMLcode EVENTI-NC[6] Nw 299 42 98
wereexcludedfromtheannotationprocess.Moreover,documents IT AncientTimes[33] Na 184 37 8
whereHeidelTimecouldnotidentifyanytimexswerealsoomitted P.HeidelTime Nw 35,351 3,897 9,956
fromtheProfessorHeidelTimecollection.The￿nalnumberof
annotateddocumentsforeachlanguageispresentedinTable1.
TimeBank[4] Nw 329 32 64
FR AncientTimes[33] Na 144 129 12
P.HeidelTime Nw 40,415 4,572 11,290
Table1: ProfessorHeidelTimecorpusstatistics.
KRAUTS[39] Nw 774 98 218
WikiWars[35] Na 1,721 98 398
#Docs #Sents #Tokens #Timexs DE
AncientTimes[33] Na 101 35 55
English 24,642 725,011 18,755,616 254,803 P.HeidelTime Nw 126,121 13,828 34,999
Portuguese 24,293 129,101 5,929,377 111,810
Spanish 33,266 410,806 21,617,888 348,011
Italian 9,619 135,813 3,296,898 58,823 Baselines. Asabaselinereference,weuseHeidelTimeandSpark
French 27,154 53,266 1,673,053 83,431 NLPNERmodel[19]tocomparewithTEI2GO.WhereasHeidel-
German 19,095 634,851 12,515,410 194,043 TimeprovidesSOTAe￿ectivenessforthelanguagesinthestudy,
SparkNLPprovidesareferenceforusinganalternativedeepneural
All 138,069 2,088,848 63,788,242 1,050,921
architecture.FortheSparkNLPbaselines,weproducedsixmod-
elsthatresultedfromtrainingthemodelonthereferencecorpus,
highlightedinboldfaceinTable2,ofeachlanguage.Allthemodels
5 EXPERIMENTS usethesameembeddings,themultilingualGloVeembeddings[25],
Corpora. Tocollectthecorpora,weemployedtieval[32],a andweretrainedwiththesamerationalethatisdepictedinthe
dedicatedPythonframeworktailoredforthedevelopmentandeval- paragraphpresentedbelow.
uationoftemporalmodels,facilitatingtheaccumulationofavast
Training. Foreachlanguage,wede￿nethreedi￿erentcombina-
setofbenchmarkcorporapertinenttothelanguagesincorporated
tionsofdatasetstotrainthemodel,named:Base,Compilation,and
inourexperiments.Table2depictsthe21corporaconsidered(15
All.TheBasemodelsareonlytrainedonthereferencecorpusfor
benchmarkscorpusplusProfessorHeidelTime),alongwiththeir
eachofthelanguages.Thisisausefulbaselinesincethereference
language,domain,anddistributionofthenumberoftimexsover
corpusisshortbutofhighquality.However,sinceallthereference
train/validation/testset.Thesplitwasperformedonthedocument
corporaareallofthenewsdomain,wealsointroducetheCom-
levelwitha80/20partitionforthedevelopment/testset.Subse-
pilationmodels,whicharetrainedinallthecorporagatheredfor
quently,thedevelopmentsetwasfurtherdividedintoan80/20
eachlanguage,excepttheweakly-labeleddatasets.Bydoingso,we
ratiofortrainingandvalidationpurposes.5
haveawaytoevaluatehowthemodeladaptstodi￿erentdomains.
3FortheSpanishcorpus:https://github.com/hmosousa/elmundo_scraper.ForthePor- Finally,wealsotrainthemodelsinallthecorporagatheredforeach
tuguesecorpus:https://github.com/hmosousa/publico_scraper. language,includingtheweakly-labeleddatasets–theAllmodels.
4https://pypi.org/project/py-heideltime Tokeeptheexperimentsreproducibleandcomparablewepre-
5WealsoconductedpreliminaryexperimentationwiththeTempEval-2[42]andMean-
de￿ned26hyperparameterscon￿gurationstobeemployedinevery
Time[22]corpora.However,thesewereexcludedfromfurtherinvestigationsincewe
foundthattheycontainseveralnon-annotatedtimexs. model/datacombination.EachmodelwastrainedforamaximumCIKM’23,October21–25,2023,Birmingham,UnitedKingdom HugoSousa,RicardoCampos,andAlípioJorge
Table3: Resultsofthedevisedmodelsonthetestsetofeachcorpus.Column 1and 1' presentthestrictandrelaxed 1
score[40],respectively.The“Time”columnpresentstheaveragetimeittooktocomputethepredictionsforonesentencein
milliseconds.Inboldarehighlightedthebest 1scoreforeachcorpus.
Baseline TEI2GO
HeidelTime SparkNLP Base Compilation All
 1  1' Time  1  1' Time  1  1' Time  1  1' Time  1  1' Time
TempEval-3 81.8 90.7 465.1 74.9 87.5 140.6 74.6 87.7 2.8 81.2 87.8 3.8 82.4 90.6 3.8
TCR 74.0 86.6 280.0 61.5 79.4 122.0 73.0 87.3 2.0 68.6 86.3 4.0 77.2 89.8 4.0
EN AncientTimes 89.2 91.9 150.0 35.5 53.3 154.5 11.8 35.3 4.5 68.4 84.2 4.5 66.7 74.2 4.5
WikiWars 83.6 91.4 62.9 50.1 74.3 92.7 50.7 78.0 2.0 90.8 96.7 2.6 84.7 91.9 2.6
P.HeidelTime 100.0 100.0 276.6 57.6 70.1 134.5 69.5 82.6 2.4 71.8 81.3 3.1 98.7 99.1 3.0
TimeBank 72.1 81.8 463.2 80.8 89.0 114.5 83.6 86.5 6.0 - - - 77.4 82.0 3.4
PT
P.HeidelTime 100.0 100.0 335.8 50.6 72.7 154.0 52.5 72.5 6.9 - - - 97.8 98.5 3.6
TimeBank 85.6 89.1 510.3 81.6 90.4 99.3 76.6 87.1 3.4 69.3 85.6 4.8 85.6 89.1 2.8
TrainT3 82.5 88.7 496.1 89.0 93.7 109.7 90.5 94.3 3.9 75.0 94.0 5.2 84.0 90.5 3.9
ES
AncientTimes 78.0 92.7 130.0 15.8 75.7 75.0 15.8 75.7 5.0 51.4 76.5 5.0 38.9 75.7 0.0
P.HeidelTime 100.0 100.0 418.1 68.4 82.6 249.6 66.8 82.6 4.4 60.7 80.4 7.5 97.0 98.3 3.9
EVENTI-NC 81.4 93.9 571.4 63.6 83.3 88.9 52.9 75.0 6.3 79.8 89.7 3.2 85.6 96.4 3.2
IT AncientTimes 36.4 54.5 86.5 28.4 49.7 159.5 36.4 54.5 2.7 82.4 82.4 0.0 46.2 61.5 0.0
P.HeidelTime 100.0 100.0 364.0 52.3 72.2 84.6 52.3 66.9 5.8 52.1 76.3 2.9 98.1 98.7 2.9
TimeBank 87.1 93.5 930.8 78.7 89.3 92.3 84.4 90.6 1.9 82.3 92.7 3.8 82.2 89.9 3.8
FR AncientTimes 87.0 95.7 192.3 10.5 31.6 76.9 0.0 22.2 0.0 88.0 96.0 0.0 44.4 66.7 0.0
P.HeidelTime 100.0 100.0 297.8 70.6 82.1 106.9 68.9 79.6 2.2 71.3 85.2 2.6 98.2 98.8 2.6
Krauts 77.7 82.7 675.6 60.6 77.8 163.7 75.9 82.2 4.4 67.1 79.2 3.7 70.5 82.9 5.2
WikiWars 87.3 91.9 37.3 49.3 86.5 60.1 50.4 74.0 1.5 61.5 87.7 1.3 67.6 93.6 1.7
DE
AncientTimes 75.3 79.6 96.9 30.0 64.0 143.8 33.3 64.4 3.1 73.6 83.9 3.1 72.9 83.3 3.1
P.HeidelTime 100.0 100.0 211.7 54.7 69.3 117.2 59.5 70.2 2.2 60.2 74.3 2.0 91.8 96.7 2.7
of30epochswithearlystoppingmonitoringvalidation 1withpa- AsthisapproachmitigatesthebottleneckofcurrentTEIsystems,
tiencesettothreeepochs.Themodelwiththehighestvalidation 1 webelieveitcouldfostertheemergenceofapplicationsoftimexs
amongthe26createdwaskeptasour￿nalmodel.Thetrainingand indownstreamtasks.Toalloweasyaccessandexplorationofthe
evaluationofthemodelswereexecutedonamachinewithanIntel models,wepublishedthesixTEI2GOmodelsthathavethehighest
Corei7-10510UCPUwith16GBofRAM.Weencourageinterested  1scoreonthereferencecorpusofeachlanguageonHuggingFace7.
readerstovisitthecoderepositoryforfurtherinformation6.
Results. ReferringtoTable3,TEI2GOmodelsattainSOTA 1
6 CONCLUSION&FUTURERESEARCH
resultsinthereferencecorpusacrossfourofthesixevaluated Inthispaper,weintroduceasetofsixmodelsforfasttemporalex-
languages(TempEval-3forEnglish,TimeBankforPortugueseand pressionidenti￿cation,dubbedTEI2GOmodels.Throughacompre-
Spanish,andEVENTI-NCforItalian)whilehavingatwoordersof hensiveevaluation,wedemonstratedthattheTEI2GOmodelsare
magnitudefasterruntimethanHeidelTimeandSparkNLP(which capableofachievingSOTAe￿ectivenesswhileensuringproduction-
canbeobservedbycomparingthe“Time”columnoftheBase- levelperformance,whichhasbeenalimitationofprevioussystems.
lineandTEI2GOsystems).Inthreelanguages–English,Spanish, Alsohighlightedinthismanuscriptisthefactthatthemethodology
andItalian–theAllmodelachievedSOTAresults,illustratingthe appliestolow-resourcelanguages,andcandistillknowledgefrom
potentialadvantagesofincorporatingaweaklylabeledcorpusin HeidelTime.Note,however,thatsinceHeidelTimealsonormalizes
certainscenarios.Incontrast,forPortuguese,theintroductionof thetimexs(inadditiontoitsidenti￿cation),thepresentedapproach
theweaklylabeledcorpusnegativelya￿ectedthemodel’se￿ective- isnotafullsubstituteforHeidelTime.Forthat,furtherresearchis
ness,sincetheSOTA 1wasachievedbytheBasemodel.Onthe required.
remainingtwolanguages–FrenchandGerman–ourmodelsseem
tostruggleto￿ndtheboundariesoftimexs,astheyachievecom- ACKNOWLEDGMENTS
parablevaluesof 1' toHeidelTime,butarenotabletocompetein
Thisworkis￿nancedbyNationalFundsthroughthePortuguese
termsofstrict 1.Finally,bylookingatthee￿ectivenessoftheAll
fundingagency,FCT-FundaçãoparaaCiênciaeaTecnologia,
modelsontheProfessorHeidelTimecorpus,onecanconcludethat
withinprojectLA/P/0063/2020.
theproposedapproachcandistillknowledgefromHeidelTime,asit
isabletoachieveastrict 1scoreabove91percentinalllanguages.
6https://github.com/hmosousa/tei2go 7https://huggingface.co/hugosousaTEI2GO:AMultilingualApproachforFastTemporalExpressionIdentification CIKM’23,October21–25,2023,Birmingham,UnitedKingdom
REFERENCES (2018),343–356.
[1] SatyaAlmasian,DennisAumiller,andMichaelGertz.2022. Timeforsome [19] XuezheMaandEduardHovy.2016. End-to-endSequenceLabelingviaBi-
German?Pre-TrainingaTransformer-basedTemporalTaggerforGerman.In directionalLSTM-CNNs-CRF.InProceedingsofthe54thAnnualMeetingof
Text2Story@ECIR,Vol.3117.CEUR-WS,Online. theAssociationforComputationalLinguistics(Volume1:LongPapers).Asso-
[2] OmarAlonso,JannikStrötgen,RicardoBaeza-Yates,andMichaelGertz.2011. ciationforComputationalLinguistics,Berlin,Germany,1064–1074. https:
Temporalinformationretrieval:Challengesandopportunities.InCEURWorkshop //doi.org/10.18653/v1/P16-1101
Proceedings,Vol.707.CEUR,Hyderabad,India,1–8. [20] InderjeetManiandGeorgeWilson.2000.RobustTemporalProcessingofNews.
[3] KlausBerberich,SrikantaBedathur,OmarAlonso,andGerhardWeikum.2010. InProceedingsofthe38thAnnualMeetingoftheAssociationforComputational
ALanguageModelingApproachforTemporalInformationNeeds.InAdvances Linguistics.AssociationforComputationalLinguistics,HongKong,69–76. https:
inInformationRetrieval.SpringerBerlinHeidelberg,Berlin,Heidelberg,13–25. //doi.org/10.3115/1075218.1075228
https://doi.org/10.1007/978-3-642-12275-0{_}5 [21] PawelMazurandRobertDale.2010.WikiWars:ANewCorpusforResearchon
[4] AndréBittar,PascalAmsili,PascalDenis,andLaurenceDanlos.2011.French TemporalExpressions.InProceedingsofthe2010ConferenceonEmpiricalMeth-
TimeBank:AnISO-TimeMLAnnotatedReferenceCorpus.InProceedingsofthe odsinNaturalLanguageProcessing.AssociationforComputationalLinguistics,
49thAnnualMeetingoftheAssociationforComputationalLinguistics:Human Cambridge,MA,913–922. https://aclanthology.org/D10-1089
LanguageTechnologies.AssociationforComputationalLinguistics,Portland, [22] Anne-LyseMinard,ManuelaSperanza,RubenUrizar,BegoñaAltuna,Mariekevan
Oregon,USA,130–134. https://aclanthology.org/P11-2023 Erp,AnneleenSchoen,andChantalvanSon.2016.MEANTIME,theNewsReader
[5] BranimirBoguraevandRieKubotaAndo.2005.TimeML-CompliantTextAnalysis MultilingualEventandTimeCorpus.InProceedingsoftheTenthInternational
forTemporalReasoning.InProceedingsofthe19thInternationalJointConfer- ConferenceonLanguageResourcesandEvaluation.EuropeanLanguageResources
enceonArti￿cialIntelligence(IJCAI’05).MorganKaufmannPublishersInc.,San Association(ELRA),Portorož,Slovenia,4417–4422.
Francisco,CA,USA,997–1003. [23] MikeMintz,StevenBills,RionSnow,andDanielJurafsky.2009.Distantsupervi-
[6] AliceBracchi,TommasoCaselli,andIrinaProdanof.2016.EnrichringtheIta- sionforrelationextractionwithoutlabeleddata.InProceedingsoftheJointConfer-
TimeBankwithNarrativeContainers.InProceedingsoftheThirdItalianConfer- enceofthe47thAnnualMeetingoftheACLandthe4thInternationalJointConfer-
enceonComputationalLinguistics.AccademiaUniversityPress,Napoli,83–88. enceonNaturalLanguageProcessingoftheAFNLP.AssociationforComputational
https://doi.org/10.4000/books.aaccademia.1732 Linguistics,Suntec,Singapore,1003–1011. https://aclanthology.org/P09-1113
[7] RicardoCampos,GaëlDias,AlípioM.Jorge,andAdamJatowt.2014.Surveyof [24] QiangNing,ZhiliFeng,HaoWu,andDanRoth.2018. JointReasoningfor
TemporalInformationRetrievalandRelatedApplications.Comput.Surveys47,2 TemporalandCausalRelations.InProceedingsofthe56thAnnualMeetingofthe
(12014),1–41. https://doi.org/10.1145/2619088 AssociationforComputationalLinguistics(Volume1:LongPapers).Association
[8] YuweiCao,WilliamGroves,TanayKumarSaha,JoelTetreault,AlejandroJaimes, forComputationalLinguistics,Stroudsburg,PA,USA,2278–2288. https://doi.
HaoPeng,andPhilipYu.2022.XLTime:ACross-LingualKnowledgeTransfer org/10.18653/v1/P18-1212
FrameworkforTemporalExpressionExtraction.InFindingsoftheAssociationfor [25] Je￿reyPennington,RichardSocher,andChristopherManning.2014. GloVe:
ComputationalLinguistics:NAACL2022.AssociationforComputationalLinguis- GlobalVectorsforWordRepresentation.InProceedingsofthe2014Conference
tics,Stroudsburg,PA,USA,1931–1942.https://doi.org/10.18653/v1/2022.￿ndings- onEmpiricalMethodsinNaturalLanguageProcessing(EMNLP).Associationfor
naacl.148 ComputationalLinguistics,Doha,Qatar,1532–1543. https://doi.org/10.3115/v1/
[9] AngelXChangandChristopherManning.2012. SUTime:Alibraryforrec- D14-1162
ognizingandnormalizingtimeexpressions.InProceedingsoftheEightInter- [26] LevRatinovandDanRoth.2009. DesignChallengesandMisconceptionsin
nationalConferenceonLanguageResourcesandEvaluation(LREC’12),Nicoletta NamedEntityRecognition.InProceedingsoftheThirteenthConferenceonCompu-
Calzolari(ConferenceChair),KhalidChoukri,ThierryDeclerck,MehmetUğur tationalNaturalLanguageLearning(CoNLL-2009).AssociationforComputational
Doğan,BenteMaegaard,JosephMariani,AsuncionMoreno,JanOdijk,andSte- Linguistics,Boulder,Colorado,147–155. https://aclanthology.org/W09-1119
liosPiperidis(Eds.).EuropeanLanguageResourcesAssociation(ELRA),Istanbul, [27] LivyReal,AlexandreRademaker,FabricioChalub,andValeriaDePaiva.2018.
Turkey. TowardsTemporalReasoninginPortuguese.In6thWorkshoponLinkedDatain
[10] SanxingChen,GuoxinWang,andBörjeFKarlsson.2019.ExploringWordRep- Linguistics:TowardsLinguisticDataScience.
resentationsonTimeExpressionRecognition.TechnicalReportMSR-TR-2019-46. [28] SebastianRuder,MatthewEPeters,SwabhaSwayamdipta,andThomasWolf.
MicrosoftResearch. https://www.microsoft.com/en-us/research/publication/ 2019.TransferLearninginNaturalLanguageProcessing.InProceedingsofthe2019
exploring-word-representations-on-time-expression-recognition/ ConferenceoftheNorthAmericanChapteroftheAssociationforComputational
[11] FranciscoCostaandAntónioBranco.2012.TimeBankPT:ATimeMLAnnotated Linguistics:Tutorials.AssociationforComputationalLinguistics,Minneapolis,
CorpusofPortuguese.InProceedingsoftheEighthInternationalConferenceon Minnesota,15–18. https://doi.org/10.18653/v1/N19-5004
LanguageResourcesandEvaluation(LREC’12).EuropeanLanguageResources [29] BrendaSantana,RicardoCampos,EvelinAmorim,AlípioJorge,Puri￿cação
Association(ELRA),Istanbul,Turkey,3727–3734. http://www.lrec-conf.org/ Silvano,andSérgioNunes.2023.ASurveyonNarrativeExtractionfromTextual
proceedings/lrec2012/pdf/246_Paper.pdf Data.Arti￿cialIntelligenceReview(12023). https://doi.org/10.1007/s10462-022-
[12] JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova.2019.BERT: 10338-7
Pre-trainingofDeepBidirectionalTransformersforLanguageUnderstanding.In [30] JoanSerràandAlexandrosKaratzoglou.2017.GettingDeepRecommendersFit:
Proceedingsofthe2019ConferenceoftheNorth.AssociationforComputational BloomEmbeddingsforSparseBinaryInput/OutputNetworks.InProceedingsof
Linguistics,Stroudsburg,PA,USA,4171–4186. https://doi.org/10.18653/v1/N19- theEleventhACMConferenceonRecommenderSystems(RecSys’17).Association
1423 forComputingMachinery,NewYork,NY,USA,279–287. https://doi.org/10.
[13] WentaoDing,GuanjiGao,LinfengShi,andYuzhongQu.2019.APattern-Based 1145/3109859.3109876
ApproachtoRecognizingTimeExpressions.ProceedingsoftheAAAIConference [31] AndreaSetzer.2001.Temporalinformationinnewswirearticles:anannotation
onArti￿cialIntelligence33,01(72019),6335–6342. https://doi.org/10.1609/aaai. schemeandcorpusstudy.Ph.D.Dissertation.
v33i01.33016335 [32] HugoSousa,RicardoCampos,andAlípioMárioJorge.2023.tieval:AnEvaluation
[14] MartaGuerreroNieto,RoserSaurí,andMiguel-AngelBernabé-Poveda.2011. FrameworkforTemporalInformationExtractionSystems.InProceedingsof
ModeSTimeBank:AmodernSpanishTimeBankCorpus.RevistadelaSociedad the46thInternationalACMSIGIRConferenceonResearchandDevelopmentin
EspañoladelProcesamientodelLenguajeNatural47(62011),259–267. InformationRetrieval.ACM,NewYork,NY,USA,2871–2879. https://doi.org/10.
[15] PhilipHausner,DennisAumiller,andMichaelGertz.2020. Time-CentricEx- 1145/3539618.3591892
plorationofCourtDocuments.InProceedingsofText2Story-ThirdWorkshop [33] JannikStrötgen,ThomasBögel,JulianZell,AyserArmiti,TranVanCanh,and
onNarrativeExtractionFromTextsco-locatedwith42ndEuropeanConferenceon MichaelGertz.2014.ExtendingHeidelTimeforTemporalExpressionsReferring
InformationRetrieval,.CEURWorkshopProceedings,31–37. toHistoricDates.InProceedingsoftheNinthInternationalConferenceonLanguage
[16] MatthewHonnibalandMarkJohnson.2015.AnImprovedNon-monotonicTran- ResourcesandEvaluation(LREC’14).EuropeanLanguageResourcesAssociation
sitionSystemforDependencyParsing.InProceedingsofthe2015Conferenceon (ELRA),Reykjavik,Iceland,2390–2397. http://www.lrec-conf.org/proceedings/
EmpiricalMethodsinNaturalLanguageProcessing.AssociationforComputational lrec2014/pdf/849_Paper.pdf
Linguistics,Lisbon,Portugal,1373–1378. https://doi.org/10.18653/v1/D15-1162 [34] JannikStrötgenandMichaelGertz.2010.HeidelTime:HighQualityRule-Based
[17] LukasLange,AnastasiiaIurshina,HeikeAdel,andJannikStrötgen.2020.Ad- ExtractionandNormalizationofTemporalExpressions.InProceedingsofthe5th
versarialAlignmentofMultilingualModelsforExtractingTemporalExpres- InternationalWorkshoponSemanticEvaluation.AssociationforComputational
sionsfromText.InProceedingsofthe5thWorkshoponRepresentationLearning Linguistics,Uppsala,Sweden,321–324. https://aclanthology.org/S10-1071
forNLP.AssociationforComputationalLinguistics,Online,103–109. https: [35] JannikStrötgenandMichaelGertz.2011.WikiWarsDE:AGermanCorpusof
//doi.org/10.18653/v1/2020.repl4nlp-1.14 NarrativesAnnotatedwithTemporalExpressions.InProceedingsoftheConference
[18] EgoitzLaparra,DongfangXu,andStevenBethard.2018. FromCharactersto oftheGermanSocietyforComputationalLinguisticsandLanguageTechnology.
TimeIntervals:NewParadigmsforEvaluationandNeuralParsingofTime HamburgerZentrumfürSprachkorpora,Hamburg,Germany,129–134.
Normalizations.TransactionsoftheAssociationforComputationalLinguistics6 [36] JannikStrötgenandMichaelGertz.2013.MultilingualandCross-DomainTem-
poralTagging. LanguageResourcesandEvaluation47,2(62013),269–298.CIKM’23,October21–25,2023,Birmingham,UnitedKingdom HugoSousa,RicardoCampos,andAlípioJorge
https://doi.org/10.1007/s10579-012-9179-y timeexpressions,events,andtemporalrelations.InSecondJointConferenceon
[37] JannikStrötgenandMichaelGertz.2015.ABaselineTemporalTaggerforall LexicalandComputationalSemantics(*SEM),Volume2:ProceedingsoftheSeventh
Languages.InProceedingsofthe2015ConferenceonEmpiricalMethodsinNatural InternationalWorkshoponSemanticEvaluation(SemEval2013).Associationfor
LanguageProcessing.AssociationforComputationalLinguistics,Stroudsburg, ComputationalLinguistics,Atlanta,Georgia,USA,1–9.
PA,USA,541–547. https://doi.org/10.18653/v1/D15-1063 [41] AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,
[38] JannikStrötgenandMichaelGertz.2016.Domain-SensitiveTemporalTagging. AidanN.Gomez,LukaszKaiser,andIlliaPolosukhin.2017.AttentionIsAllYou
SynthesisLecturesonHumanLanguageTechnologies,Vol.9.SpringerInterna- Need.InAdvancesinNeuralInformationProcessingSystems,Vol.abs/1706.03762.
tionalPublishing,Cham. https://doi.org/10.1007/978-3-031-02163-3 NeuralInformationProcessingSystemsFoundation,Inc.(NeurIPS),LongBeach,
[39] JannikStrötgen,Anne-LyseMinard,LukasLange,ManuelaSperanza,and California,USA,5998–6008. http://arxiv.org/abs/1706.03762
BernardoMagnini.2018.KRAUTS:AGermanTemporallyAnnotatedNewsCor- [42] MarcVerhagen,RoserSauri,TommasoCaselli,andJamesPustejovsky.2010.
pus.InProceedingsoftheEleventhInternationalConferenceonLanguageResources SemEval-2010Task13:TempEval-2.InProceedingsofthe5thinternationalwork-
andEvaluation(LREC2018),NicolettaCalzolari,KhalidChoukri,Christopher shoponsemanticevaluation.AssociationforComputationalLinguistics,Uppsala,
Cieri,ThierryDeclerck,KoitiHasida,HitoshiIsahara,BenteMaegaard,Joseph Sweden,57–62.
Mariani,AsuncionMoreno,JanOdijk,SteliosPiperidis,andTakenobuToku- [43] XiaoshiZhong,AixinSun,andErikCambria.2017.TimeExpressionAnalysis
naga(Eds.).EuropeanLanguageResourcesAssociation(ELRA),Miyazaki,Japan, andRecognitionUsingSyntacticTokenTypesandGeneralHeuristicRules.In
536–540. https://aclanthology.org/L18-1085 Proceedingsofthe55thAnnualMeetingoftheAssociationforComputational
[40] NaushadUzZaman,HectorLlorens,LeonDerczynski,JamesAllen,MarcVerha- Linguistics(Volume1:LongPapers).AssociationforComputationalLinguistics,
gen,andJamesPustejovsky.2013.Semeval-2013task1:Tempeval-3:Evaluating Vancouver,Canada,420–429. https://doi.org/10.18653/v1/P17-1039