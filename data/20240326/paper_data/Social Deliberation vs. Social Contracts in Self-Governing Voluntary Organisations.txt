Social Deliberation vs. Social Contracts in
Self-Governing Voluntary Organisations
Matthew Scott1, Asimina Mertzani1, Ciske Smit1,
Stefan Sarkadi2, and Jeremy Pitt1
1 Department of Electrical & Electronic Engineering, Imperial College London
2 Department of Informatics, King’s College London
Abstract. Self-organising multi-agent systems regulate their compo-
nents’ behaviour voluntarily, according to a set of socially-constructed,
mutually-agreed, and mutable social arrangements. In some systems,
these arrangements may be applied with a frequency, at a scale and
within implicit cost constraints such that performance becomes a press-
ing issue. This paper introduces the Megabike Scenario, which consists
ofanegotiatedagreementonarelatively‘large’setofconventionalrules,
‘frequent’ ‘democratic’ decision-making according to those rules, and a
resource-boundedimperativetoreach‘correct’decisions.Aformalismis
defined for effective rule representation and processing in the scenario,
and is evaluated against five interleaved socio-functional requirements.
System performance is also evaluated empirically through simulation.
Weconcludethattoself-organisetheirsocialarrangements,agentsneed
some awareness of their own limitations and the value of compromise.
1 Introduction
In a self-organising multi-agent system [15], the component agents voluntarily
agree to regulate their own behaviour according to a set of socially-constructed,
mutually-agreed,andmutablesocial arrangements.Informallyintroducedin[6],
wedefine“socialarrangements” asanumbrellatermforanytypeofconventional
rule-based system that members of a group agree on for voluntarily regulating
behaviour and holding themselves accountable to one another, whether this is a
convention, norm, procedure, regulation, institution, contract or law [13,21,26].
In principle, these social arrangements support self-governance through de-
liberativeprocesses,wherebythosewhoareaffectedbythearrangementspartic-
ipateintheirselection,modificationandenforcement,andself-determinecertain
configurationsofthesocialarrangementtobecongruentwith,orfit-for-purpose
for, prevailing environmental conditions [13,6]. In practice, the social arrange-
ments may need to be applied with a frequency, at a scale, and within implicit
cost constraints such that performance becomes a pressing issue, and especially
so in the presence of existential threats.
In such circumstances, it may be necessary to circumvent resource-intensive
deliberative processes, not by reducing participation through sortition or “rep-
resentative democracy”,butbyusinginsteadsocial contracts,whichcombinean
4202
raM
42
]AM.sc[
1v92361.3042:viXra2 Scott et al.
expressive rule representation combined with efficient rule processing. However,
given the centrality of ‘correctness’ in the outcomes of deliberative decision-
making3, this demands that an alternative approach based on social contracts
needs to be evaluated against five interleaved socio-functional requirements,
which concern the entanglement of social arrangements with computational op-
eration, namely:
– Scalability: do the social arrangements scale with the number of agents, the
number of rules, the cost and frequency of applying the rules, etc.?
– Complexity: are the social arrangements congruent with the ‘cognitive’ abil-
ityoftheagentstousethem,anddotheycorrespondtothedifficultyofthe
problem to be addressed (cf. [22])?
– Mutability:how‘easy’or‘quick’isittochangeboththesocialarrangements,
and agreements underpinning the choice of social arrangement, especially in
real-time, existential-risk situations (cf. [24])?
– Enforceability: can sanctions specified by the rules be enforced effectively in
decentralised systems with no form of coercion? and
– Versatility: how ‘seamlessly’ can the social arrangements, and conceptual
resources that are socially-constructed externalities produced by applying
these arrangements, be transposed to another context?
Therefore, the motivating problem for this work is the reduction in the bur-
denofself-governancebytheuseofexpressiveandtractablesocial contracts[23]
instead of expensive and potentially intractable deliberative processes. These
social contracts are evaluated against the socio-functional requirements in the
context of the Megabike Scenario. In this scenario, autonomous agents have
to, first, self-select membership of a group; secondly, within the group, negoti-
ate an agreement on a relatively ‘large’ set of social arrangements; and thirdly
make ‘frequent’ ‘democratic’ decisions according to these arrangements, within
aresource-boundedimperativetoreach‘correct’decisions.Beingusedtoresolve
iterativelyseveralinter-dependentsocialdilemmas(includingscarceresourceal-
locationandcollectiverisk),thesocialarrangementsaresubjecttotheidentified
performance issues, and so social contracts preferred to deliberative processes.
Accordingly, this paper is structured as follows. The next section introduces
theMegabike Scenario,whileSection3summarisesthe‘decision-makingarenas’
required by the scenario and exposes the limitations of social deliberation. Sec-
tion 4 specifies a formalism for effective representation of social contracts, as
an alternative to social deliberation, after which Section 5 evaluates the formal-
ism against the socio-functional requirements. The performance improvements
are evaluated empirically through a simulation of the Megabike, described in
Section 6. After a discussion of related research in Section 7, we conclude in
Section 8 that the significance of these results for self-organising multi-agent
systems is that the agents need an acute self-awareness of their own limitations
in selecting and modifying their social arrangements.
3 For example, Ober [12] attributes the success of the classical Athenian democracy
in outperforming other city-states, despite parity in other metrics, to its superior
knowledge management processes which produced ‘better’ decisions more often.Social Deliberation vs. Social Contracts 3
2 The Megabike Scenario
A megabike, based on “real world” bikes for multiple riders, allows a group of
otherwise autonomous agents to occupy a single vehicle collectively, and then
propel it (pedal) to navigate a typical AI/multi-agent gridworld, both in search
ofrewards(lootboxes)andtoavoidanexistentialthreat.Eachagentisindividu-
ally capable of pedalling, braking, and steering the megabike; consequently, the
agentsmustcollectivelyagreeon(andeachagentexplicitlyagreestovoluntarily
complywith)thesocialarrangementsthatdeterminedirection(steerage),effort
(pedalling and braking), lootbox targeting and loot allocation, and assignment
of social roles.
Ultimately each agent wants to maximise its own utility, measured in terms
of energy gained from lootboxes, duration of survival, and/or others’ apprecia-
tion of its individual contribution to a collective effort (e.g., energy expended,
compromising,performanceofasocialrole,etc.).Thescenariothereforeinvolves:
– institutional foundation, as the agents must negotiate firstly, with whom to
teamupwithtooccupyamegabike,andsecondly,whatsocialarrangements
(form of voluntary self-governance) are agreed to be in force;
– coordination, in terms of selecting a target lootbox and investing personal
resources (energy) into a collective effort to move there; and avoiding both
contradictoryactions(pedallingandbrakingatthesametime)orduplicating
actions (causing e.g., over-steering);
– distributive justice, in terms of how to allocate rewards from the successful
appropriation of the contents of a lootbox, according to negotiated criteria
also specified by the social arrangements;
– normative compliance, in terms of compliance, or otherwise, with group de-
cisions made according to the agreed social arrangements, and punishment
for non-compliance (although the collective with regards to...)
– ...cooperative survival, in that the megabike needs sufficient occupants with
sufficientenergyinordertoincreaseitschancesofacquiringlootboxesbefore
other megabikes take them, and avoiding an existential threat;
– contributive justice, in the form of opportunities to contribute meaningfully
to successful collective action, norm compliance, compromises, etc., and to
be appreciated for such contributions; and
– social construction, in the form of conceptual resources like esteem, trust-
worthiness, social networks, etc., which start from zero but accumulate (are
socially-constructed) over time.
An informal specification of the Megabike Scenario ‘game loop’ is given in
Algorithm 1. The ‘game’ is played over multiple iterations, each iteration con-
sisting of multiple rounds. At the start of each iteration, the agents negotiate
membership of, and social arrangements for, their own megabike, and perform
role assignment (in particular identifying a leader). In each round, they select a
target lootbox, then commit some of their own energy to pedalling, braking or
steering actions. If they succeed in acquiring a lootbox, then they have to dis-
tribute the resources according to the negotiated social arrangements. Finally,4 Scott et al.
theyfollowprotocolstoexcludeanagent(ultimatesanctionfornon-compliance)
or admit a new agent (if there is an unfilled ‘seat’ on the megabike).
Algorithm 1: Megabike Scenario ‘Game Loop’
1 i←0 ; initialise agents ;
2 repeat
3 (withinagents)negotiatemegabike membership;//self-selection phase
4 (within megabike) negotiate social arrangements ; //action phase
5 (within megabike) perform role assignment ;
6 j ←0 ;
7 repeat // operation phase
8 (within megabike) decide target lootbox ;
9 (within megabike) each agent decides pedal/brake/steer actions;
10 (environment) apply effects of actions ;
11 if lootbox reached then
12 (within megabike) apply resource allocation
13 (within megabike) admission/exclusion ;
14 inc(j) ;
15 until j == MaxRounds OR megabike terminated;
16 inc(i) ;
17 until i== MaxIterations OR deadlock;
Therefore, a Megabike game (in the simulation sense) consists of several
(inter-related) sub-games (in the game-theoretic sense), including:
– a veil of (decreasing) ignorance dilemma [19]: at the start of each iteration,
knowledge about negotiating which bike to join and which social arrange-
mentstoadoptchangesovertime,froma“risk” trustdecisiontoa“reliance”
trust decision as information is gained about the behaviour of other agents;
– a pair of collective action dilemmas [13]: the optimal utility-maximisation
and self-preservation strategy is (literally) free-riding, by not expending en-
ergywhileotheragentsdoallthepedalling;butifallagentsusethisstrategy,
all suffer, because being stationary is unsustainable as the megabike will be
terminatedbytheexistentialthreatorcompetitionwithothermegabikes for
lootboxes;
– a resource allocation dilemma [20], where the allocation of scarce resources
gathered from any lootboxes must be decided according to a protocol in-
cluded in the set of agreed social arrangements (rather than a brutal ‘real
time’ grab); and
– a balloon debate dilemma, in which some agent might have to convince
the others that it should not be excluded, or that another agent should be
excluded(e.g.,forreasonsofnon-compliancewiththeagreedsocialarrange-
ments or leadership decisions).
As per [13] and [11], resolving these dilemmas requires the negotiation of
social arrangements, as discussed in the next section.Social Deliberation vs. Social Contracts 5
3 Social Deliberation for Self-Governing Megabikes
Thissectionconsidersdecisionarenasinwhichsocialarrangementsarerequired
tonegotiateagreementsandreachdecisionsthroughprocessesofsocialdelibera-
tion. However, it also exposes some of the situational limitations of unrestricted
social deliberation.
3.1 Social Deliberation
As indicated by Algorithm 1, the individual demands on agents in the Megabike
Scenario are manifold, but also they need to engage in (potentially) substantial
processesofactionselection,collective(social)deliberationanddecision-making.
Fortheformer,eachagentwillneeditsindividualstrategy,whichisnotdiscussed
further here, except to the extent that preferences inform the latter. For this,
deliberation and decision-making, they need a relatively ‘large’ set of rules or
procedures (i.e., their social arrangements).
These social arrangements are negotiated once a group of agents have all
agreed to occupy a megabike, often involving a particular type of rule, and then
parameters for that rule. For example, decisions might be made by the assigned
leader, or by majority vote; if they take a vote, they have to decide which of
manyvotingmethodstouse(e.g.,plurality,alternativevote,Bordacount,etc.).
Rulesarederivedfrommultiplesources,includingself-governinginstitutions
forcommon-poolresourcemanagement[13],norm-governedmulti-agentsystems
usinginstitutionalisedpower[1],distributivejusticeusinglegitimateclaims[20],
theGameofNomic[27],Robert’sRulesofOrder[21],BasicDemocracy[11]and
democracy-by-design [18]. As such, the decision arenas [13] include:
Mutability [27,11]:anagreementisrequiredonwhetherornottodistinguish
between mutable and immutable rules. If a distinction is agreed, then there
needs to be one protocol for converting a mutable rule to an immutable rule,
and another protocol for converting an immutable rule to a mutable one.
Role Assignment [1]:minimally,aleader willbeassigned,whowillthenhave
the institutionalised power to assert certain (institutional) facts [7]. A protocol
for selection is required, alternative methods include by vote, weighted crite-
ria, torno (if equal participation is a key principle [11]), and historical (auto-
autocrat). Equally, a protocol for de-selection is required, if the elected repre-
sentative takes undue advantage of its position [18]. Note, the collective might
delegate other tasks to ‘responsible’ agents to minimise costs (e.g., steering, ob-
serving, etc.), which opens up further opportunities for investigating deception.
Lootboxes [13,20]: a protocol for lootbox target selection is required: this
might entail a phase of ‘democratic’ deliberation (knowledge aggregation) with
respect to social welfare optimisation, and a method for knowledge alignment,
i.e., having taken the decision, how to ensure that all agents act upon it effec-
tively.Theleader might,forinstance,useitsinstitutionalisedpowertoobligeall
agents to pedal with a certain intensity. Having acquired a lootbox, a protocol
for resource allocation is required. If there is no protocol fixed, the agents might
try to ‘grab’ loot, i.e., this introduces a hawk-dove game to the scenario.6 Scott et al.
Membership [13]: a key feature of collective action decision arenas are the
boundaries on who is and is not constrained by the social arrangements, and
which are and are not common interest (rather than factional) issues. However,
since the social arrangements are conventional, non-compliance is a possibility;
if the ultimate sanction is exclusion then a protocol for this is required (imply-
ing pre-conditions, process, appeals procedure, etc. [15]). Similarly, and since
agents may be eliminated due to depleted energy, an admissions protocol is also
required:sincetherearevariousalternativeadmissionsprocesses,thisisanother
parameter that needs to be negotiated.
Monitoring and Sanctions [13]: assuming an open system, there is no full
disclosure, and agents cannot see how much effort other agents are putting into
pedalling. However, they can know if someone under-contributed, and for this
reason, there needs to be an auditing protocol. This would require another role
assignment,achoicebetweenmethodsandoutcomes(e.g.,cheapbutunlikelyto
reveal non-compliance, expensive but likely). Note that a ‘monetised’ obligation
for monitoring and auditing also exposes risks of non-compliance with the role
(doing the work, reporting results honestly, etc.). Therefore, a graduated scale
of sanctions for non-compliance needs to be negotiated.
Crisis Response: to deal with an existential threat, a switch between decen-
tralised and centralised decision-making might be negotiated. The problem is to
ensure that once the crisis has passed (if it existed in the first place [8]), demo-
cratic backsliding is averted and the social arrangements revert to their original
form, and do not get stuck in an autocratic or hierarchical regime [6].
3.2 The Limitations of Social Deliberation
In the Megabike scenario, given the number of decision arenas, the frequency of
decision-making in those arenas, the cognitive and communicative overheads of
social deliberation, and the pressure of an existential threat, there are limits on
the use deliberative processes, and a more efficient but equally effective way of
reaching a ‘correct’ decision is required.
There are, in fact, precedents for substituting complex procedures in self-
organising multi-agent systems. For example, in previous work, e.g., [1], the
focus of attention was on events which determined the (institutionalised) pow-
ers, permissions and obligations of agents. For this purpose, the Event Calculus
(EC) was an effective tool for executable specification, but ‘simple’ Prolog im-
plementations of the EC proved unsuitable for simulations with large numbers
ofagentsor‘long’narratives.Forexperimentalsimulation,EC-basedlogicalrep-
resentationofOstrom’sdesignprinciplesforself-governinginstitutions[13]were
re-implemented in procedural or object-oriented languages to address issues of
scale and run-time ([17,16]). For real-world applications, this limitation of the
EC led to the development of a logic formalism for large-scale run-time event
recognition [2].
Fuirthermore, in the implementation of the thought experiment Demopolis
[11], the rules were conceived as defining a specification space of n rules eachSocial Deliberation vs. Social Contracts 7
with m parameters, with each parameter having x values, so the ‘k-th’ rule, R ,
k
was defined as in Equation 1.
 
P (V ,...,V )
1,k 11,k x1,k
R k
=
 
P 2,k(V 12,k,
.
....,V x2,k) 
  (1)
 . 
P (V ,...,V )
m,k 1m,k xm,k
WhilethismeantthatrulescouldbeconvenientlywrittenandexecutedasProlog
predicates, changing parameters meant retracting and re-asserting clauses, and
changing sets of rules meant re-consulting files. Both of these operations are
relatively ‘slow’, and so mutability was correspondingly problematic [18].
To compound matters, for agents embedded in the actual simulation, the
processesofsocialdeliberation,aspreviouslyenumerated,incursubstantialover-
heads in communication, especially as the number of agents, and the frequency
with which deliberation occurs, scale upwards. These overheads cause obvious
problems in situations where cooperative survival is a condition of continued
participation, both individually and collectively (i.e., no-one survives unless ev-
eryonesurvives).Therearefurtherproblemsofasynchronyandconcurrencythat
open distributed systems have to address, especially issues of timing, sequence
and causality in systems without global clocks, which generally do not present
comparable difficulties for social systems.
InthecontextoftheMegabikeScenario,weproposethatduringtheruleselec-
tion phase, the agents should also determine whether or not deliberation can be
replacedinsteadbyasocial contract [23].Thisisnotgoingagainstaprincipleof
Democracy-by-Design [18], “no short-cutting democratic processes”, but instead
is seeking to define a more efficient, and mutually-agreed, rule-based alterna-
tive to social deliberation. Note that this proposal implies that in the (second)
entrenchment phase of negotiating the social arrangements for a megabike, the
Θ-Learning algorithm [9] could be used for reaching consensus while exploiting
compromise and dissent as conceptual resources; and in the (third) operational-
isation phase, there is an opportunity to use learning algorithms to customise
thesocialcontractbyestablishingthepathwaystorequisitesocialinfluence[10].
Therefore, we need an appropriate (i.e., computationally tractable) rule rep-
resentation which can be used as a surrogate for (potentially computationally
intractable) social deliberation: for example, social contracts.
4 Social Contracts for Self-Governing Megabikes
In this section, we specify social contracts as a set of rules, which effectively
prune the search space of possible decisions. In this way, we can reframe social
deliberation as a social contract, whereby rule application and mutability are
re-interpreted as optimisation problems.
In this case, agents can avoid deliberation by mutually agreeing on a set
of rules that offsets the deliberation process by approximating it instead. For8 Scott et al.
example,rulesmaybeimposedusingquantitativefeaturesofthelootboxes(such
as relative distance or reward) to restrict the possible set of lootboxes that may
bevotedonbytheagents.A‘well-optimised’rulesetwouldbeonethateffectively
removestheneedforsocialdeliberation,asafterpruningthefullsetoflootboxes,
only one is left. This process, while not deliberative, yields the same outcome: a
single decision resulting from an initial search space of multiple valid decisions.
Assuch,therulesetservesasa‘proxy’fordeliberation,wherethesearchspaceis
prunednotthroughdeliberation(agentsgraduallyconvergeonasingledecision),
but by the elimination of invalid decisions through rules. This has the added
benefit of reducing the computation needed by the agents, and instead places
theloadontheserver,therebyallowingforfasteragentoperationifthisscenario
were translated to an asynchronous system, say.
Usinganoptimisationparadigmfavoursamathematicalrulerepresentation,
whereby techniques such as gradient descent or simple estimators can be used.
Therefore, we use a matrix representation, specifying other parameters required
for evaluating the rule and allowing for efficient rule retrieval. We formalise
the rule representation with respect to the design considerations outlined in
Section 1, and give an example of how a declarative rule can be converted into
matrix form. This gives an abstract, general-purpose rule model that can be
codified for efficient computation and evaluation.
4.1 Rule Representation Formalism
There are various parameters used to address the design considerations in this
rule representation. Table 1 illustrates this by giving the parameter name and
datatypeusedforeachelementintherepresentation.Wedescribetherepresen-
tation according to three sections: how the rules can have unique identification,
how the rules are built for efficient evaluation and how the rules are mutable.
Parameter Range
ruleID UUID
ruleName string
ruleIsMutable bool
ruleAction enum
ruleInputs [](func() → float)
ruleMatrix [][]float
ruleComparators []operators
Table 1. Rule representation data structure
Identification Firstly, all rules have a uniquely generated ruleID to allow all
rulestobeuniquelyidentifiable.Thisallowsforrulestobeaccessedfromaglobal
lookup (a hashmap cache, say) and for agents to store a reference to the rules
that they are currently using. We also supply a ruleName for a ‘quality of life’
benefit to the rule designer (the programmer), as this allows for a meaningful
description to be added to each rule such that the programmer can see whichSocial Deliberation vs. Social Contracts 9
rules are used by an agent without having to meticulously check UUIDs. The
final parameter used for identification is the ruleAction, which binds each rule
totheactionthattheyconstrain.Forexample,arulemayneedtobeappliedon
the lootbox decision, the election of an agent to power, or the direction that the
bike should travel. Binding this rule to an action allows for efficient extraction
of the relevant rules, to ensure that rules which do not affect the outcome of
an action (and would therefore pass as true anyway) are not evaluated, saving
computation time.
Inthecontextofasimulator,thereislikelytobeasystemcomprisingalarge
numberofthesetypesofrules.Thiscouldbecodifiedwithahashmap,mapping
theruleAction toalistofrules,forexample,asthiswouldallowfortherelevant
rules to be extracted in constant time.
Evaluation There are three components used for evaluating a rule. The first
is a set of ruleInputs, or the quantitative information that the rule concerns.
This allows for a rule to be suitably versatile, as it becomes applicable to any
object in the simulator, via a getter function. For example, a rule may need
to be evaluated against a lootbox, concerning its position or value. A rule may
alsobeapplicabletoanagent,concerningtheirresources(energy)oresteem.As
such, specifying the constraints of a rule becomes possible with a generic getter
function,allowingforasingleruleenginetobeappliedtoanykindofobject(or
interface, programmatically).
The second component needed for evaluating a rule is the ruleMatrix, which
is a 2-D array of numbers that applies weighting to the ruleInputs, thereby
allowing for numerical constraints to be applied. Taking the previous example
of the position of a lootbox as an input variable, the ruleMatrix may apply
a weighting of 100, to define a rule that compares the (relative) position of a
lootbox with a distance of 100 units. How this comparison is made is defined in
the final evaluation parameter, with the ruleComparators.
TheruleComparators definehowtheinputparameteriscomparedagainstits
numericalweighting,usinganoperator intheset{<,>,≤,≥,=}.Completing
the previous example, we can define a rule that a lootbox must be within a
distance of 100 units for consideration. The input parameter then becomes the
lootbox position, the matrix applies a weighting of 100 and the comparator
evaluates this with the ’less than or equal to’ operator (≤). In Section 4.2,
we give a more complex example of a rule that concerns multiple inputs, and
multipleclauses,demonstratingwhyamatrixisused,overasinglescalarweight.
Mutability A final design consideration is the importance of rule mutability.
Given the representation as a matrix of numbers, mutability becomes trivial, as
an agent/designer simply needs to change the value of a matrix element. Again,
using the example of a constraint on lootbox distance, the value of 100 can be
changed in the ruleMatrix to 50, say, to give a tighter restriction on the set
of feasible lootboxes. Conversely, this value may be changed to 200, to provide
more ‘slack’ on the constraint, and allow for a weaker constraint on the feasible10 Scott et al.
lootboxes, and hence a wider array of possible options. Naturally, these rules
may not be intended to be mutable, so we provide a ruleIsMutable flag that
dictates if the rule can be changed or not.
4.2 Example: Lootbox Pruning
The simplest way to define a rule in this grammar is to start with a declarative
rule and convert it to a numerical representation. The (simple) rule from the
previous section, A valid lootbox must be within 100 units, can be expressed as
an inequality using d for relative distance as d<=100.
In order to get a ‘better’ outcome, an agent may propose that the distance
shouldreflectthepayoffofthelootbox,addingasecondclausesuchthatA valid
lootbox must give a payoff of at least 1.5 times its distance. This can also be
interpreted as an inequality, with p representing payoff, as p>=1.5∗d.
As such, we arrive at two equations that must simultaneously be true for
a rule to pass. Reformatting these equations, setting them equal to zero and
ascribing scalars for all variables gives:
1∗d+0∗p−100∗1<=0
1.5∗d−1∗p+0∗1<=0
which can be interpreted in matrix form as:
 
(cid:20) (cid:21) d (cid:20) (cid:21)
1 0 −100 <= →−
p 0 (2)
1.5−1 0 <=
1
yielding,fromlefttoright,thethreecomponentsforruleevaluation:theruleMa-
trix, the ruleInputs and the ruleComparators, the result of which, after matrix
multiplication, is compared against the zero vector.
5 Evaluation of Socio-Functional Requirements
Inthissection,weevaluatetherulerepresentationwithrespecttothefivesocio-
functional requirements introduced in Section 1.
5.1 Complexity Reduction
RuleEvaluation Giventhecontextofascenariowithadifferentactions,andr
differentrules,andwithrepeatediteration,theimportanceofoptimisingtherule
evaluationisincreasinglyimportant.Followingfromtherulerepresentation,ifa
ruleisevaluatedforanirrelevantaction(alootboxruleagainstanelectionaction,
say) the input parameters will be unrelated to the problem (a lootbox’s value
isn’t necessary for checking an agent’s electoral eligibility), and therefore there
rulewillpassbydefault.Assuch,unnecessarycomputationisspentevaluatingall
rules. Given a rule matrix of size n∗m, with n clauses and m input parameters,Social Deliberation vs. Social Contracts 11
evaluation will run with O(n ∗ m) complexity. Given the full set of r rules,
which are evaluated for all a actions, this yields the complexity of a single agent
evaluating a decision as O(n∗m∗r∗a).
By ascribing a ruleAction to the representation, as in Table 1, the rules
canbecomestratified,suchthatonlyasubsetoftherulesrequireevaluation.We
denotethissubsetwithr′.Assuch,bystoringtheactiverulesinahashmap,such
that the rules can be extracted in O(1) time, the overall complexity is reduced
toO(n∗m∗r′∗a).Giventhatthefullrulesetispartitionedintoactions,wecan
saythatr′∗a<=r,andassuchthefinalcomplexityisO(n∗m∗r),simplifying
the complexity by a factor of a.
Deliberation vs Social Contracts We can also consider a complexity im-
provement from the perspective of deliberation in the simulator. Previously,
deliberation was the mechanism for action selection, which, in the context of
Megabikeoccurredineveryoperationphase,andthereforeineveryround(seeAl-
gorithm1).Thismeantthat,foreveryiteration,therewereatworstMaxRounds
operation phases being run.
Bytransitioningtosocialcontracts,thenegotiationofrulesisinsteadmoved
to the action phase, therefore being run only once per iteration. Considering i
iterations and j rounds per iteration, with k opportunities for deliberation from
Section 3.1, there were previously O(i∗j∗k) deliberation sessions. Using social
contracts allows for a single social contract negotiation session per iteration,
reducing the complexity to O(i).
5.2 Linear Optimisation
Insteadofinterpretingadecisionasrequiringtheiterationofanarrayofdistinct
rules, it is possible to combine all rules into a single matrix. For example, given
two distinct rules as follows (with arbitrary input parameters):
 
(cid:20) (cid:21) x (cid:20) (cid:21)
1 0 −100 <= →−
y 0 (3)
3−1 0 <=
1
 
(cid:20) (cid:21) z (cid:20) (cid:21)
4 3 −1 > →−
w 0 (4)
5−7 2 =
1
it is possible to ‘stack’ rules into a single large (potentially sparse) matrix:
 
  x  
1 0 0 0 −100 <=
y
3−10 0 0  <=→−
 z  0 (5)
0 0 4 3 −1   > 
w
0 0 5−7 2 =
112 Scott et al.
As such, this set of constraints may be reinterpreted as a linear optimisa-
tion problem, where agents may attempt to maximise some objective function
(survivability, or energy, say) based on a set of constraints.
5.3 Slack: Flexibility and Mutability
Further changes can be made to the representation to generate the ruleset as
a data tableau, so that slack variables can be used for linear optimisation. This
technique synergises well with the rule representation, as the mutability of the
data structure allows for not only convenient redefinition of the rule constraints
but the removal or addition of extra slack for a stricter or more lenient policy,
respectively. This makes the rules not only mutable, but flexible as well.
5.4 Enforceability and Transparency
By having the rules bound to each Megabike, the mutually agreed rulesets that
inform all decisions are visible not only to other agents, but to the simulator
designeraswell.Thebenefitofthisistwofold.Firstly,therulesetcanbeseenas
a tangible representation of the current agent state: that is, the algorithm they
would use to decide on an action becomes publicised and interpretable in the
form of a rule, i.e., instead of each agent deciding on which action to perform,
whichwouldbeintheformofablackboxprocess,theyinsteadmutuallydecide
on a rule which would prune the actions they wouldn’t carry out. The ruleset
then becomes an aggregation of all of the agents’ internal processes, such that
the action space yielded by evaluating the ruleset results in the set of actions
that would be voted on by the agents, anyway.
Thesecondbenefittothisrepresentationistheabilitytotakecomputational
demand away from the agents. Instead of having agents individually select an
actionusingtheirownalgorithm,therulesetcanbeevaluatedserver-sideinstead,
movingcomputationfromindividualagentsontotheserver.Givenasynchronous
system where runtime efficiency is imperative to avoiding race conditions, more
complexagentscanbebuiltthatdon’tsufferfromhavingtorunquicklytomove
first. Having rule evaluation performed by the server also means that the rules
becomesmoreenforceable;theservercannotbecoercedintomisevaluatingarule
for personal gain, unlike if an agent were to perform this role.
5.5 Versatility
There aretwo dimensionsto versatility: for the simulatorand for thesimulated.
Our concern here is for the simulated: what we want to evaluate is the extent
to which an agent which learns social arrangements for the megabike scenario
couldapplythat‘learning’toadifferentscenario.Thisisnotarequirementthat
can be evaluated in the current work, but is left for future work.Social Deliberation vs. Social Contracts 13
6 Empirical Simulation Results
In this section, we quantitatively demonstrate the functional design consider-
ations discussed in Section 1: scalability, complexity and mutability. For these
experiments, we consider a simulator comprising 100 iterations of 100 rounds
(per Algorithm 1), and run the simulator 30 times to aggregate the results.
6.1 Experiment 1: Scalability and Complexity
Thisfirstexperimentaimstodemonstratehowtheinclusionofrulestratification
by ruleAction results in decreased runtime for the program, and supports the
claims made to reducing time complexity in Section 5.1. In this experiment, we
evaluate the runtime of the program per iteration across ruleset sizes of 1, 10,
100 and 1000, and number of agents in the simulation at 1, 8, 16, and 32. The
results of this experiment are shown in Figure 1.
Tobenchmarktherulerepresentation,weneedtotesttheworst-caseruntime
for the simulator. This would occur when each agent needs to evaluate every
singlerule.Forsimplicity,wedefinearulethatisguaranteedtopass,irrespective
of the agents’ state, such that the rule evaluation isn’t prematurely stopped (as
thereisnopointevaluatingfurtherrulesonceonehasfailed).Todoso,wedefine
a ruleMatrix of all zeroes, and equate it directly with the zero vector. This rule
serves as a ‘null’ rule, which means that irrespective of the input parameters
(and therefore the agent’s state), the rule will pass, since all input parameters
are multiplied by zero. This simplifies the calculation to whether 0==0, which
is always true.
Runtime per iteration for stratified ruleset Runtime per iteration for non-stratified ruleset
1200 6000
1 80 00 00
me
(ms) 45 00 00 00
me
(ms)
46 00 00 Runti 23 00 00 00 Runti
200 1000
0 0
32 32
0 Number1 o0
f active1 r0 u0
les 1000
1
8
Numb1
er
6
of
agents
0 Number1 o0
f active1 r0 u0
les 1000
1
8
Numb1
er
6
of
agents
Fig.1. Runtime profiling of Megabike simulator for stratified (left) and non-stratified
(right) rulesets
The results of these experiments show that the runtime of the program per
iteration is significantly reduced. Given the subset of five actions we have de-
fined,theruntimeisreducedby(approximately)afactoroffive,whichsupports14 Scott et al.
the theoretical analysis performed in Section 5. This shows that the rule repre-
sentation is scalable in proportion to the number of actions, agents and ruleset
size. As such, more complex simulators can be built and run in a feasible time.
6.2 Experiment 2: Mutability
Thesecondexperimentisdesignedtoillustratetheimportanceof,andsimplicity
in, modifying rules at runtime for survivability. In this experiment, we define a
single rule that impacts the subset of lootboxes that are eligible for voting. This
rule (initially) states that all eligible lootboxes must be within a radius of 1000
units. If an agent’s energy falls below 50% of the maximal capacity, agents will
propose to amend the rule, once per turn, by applying a slack of 5% (that is,
increasing the radius of detection by 5%). Alternatively, if an agent’s energy is
at least 50%, the agent will propose to amend the rule by removing a slack of
5%, thereby shrinking the radius of detection by 5%.
Thisexperimentvariesthescarcityofresources,byvaryingtheratioofloot-
boxestoagent.Given100agents(acrossallruns),wefirstestablishabaselineby
givingaratioof0,therebyassessinghowagentswouldsurvivegivennoexternal
resources and increase this ratio to 0.5, 1.0, 1.5, 2.0 and 2.5. We also vary the
capacity to mutate the rule, and illustrate the results in Figure 2.
Average Number of Iterations Survived 80
70
60
50
40
30
0 0.5 1.0 1.5 2.0 2.5
Ratio of Resouces to Agents
Fig.2. Average survivability of agents in Megabike for varying degrees of resource
scarcity and mutability of rules
By increasing the ratio of available lootboxes to agents, thereby alleviating
the economy of scarcity, agent survivability is improved. Across all degrees of
scarcity, Figure 2 shows that the mutability of rules has a significant impact on
survivability, outperforming the immutable rules at every stage.
Using 0 lootboxes as a baseline, in either case, the agents survive for around
20 rounds, as the mutability of rules has no bearing on the number of lootboxes
that can be achieved. In the mutable case, increasing this ratio has a drastic
effect on survivability, where for an increase in 0.5x the resources, a further ≈20
rounds of survival are allowed, up to ≈80 when 2.5x the resources are present.
ytilibatuM
eluR
elbatuM
elbatummISocial Deliberation vs. Social Contracts 15
Conversely, with immutable rules, agents struggle to survive, even with 2.5x
the resources, where agents still only survive for ≈40 rounds on average. This is
duetotheagentsconsistentlydepletingthenearbylootboxesovertime,thereby
increasing the need for a larger perception radius to detect further away re-
sources. In the mutable case, this is exactly the kind of policy change being
negotiated: the bikes consistently agree on more and more slack to be given to
the rule until a sufficient number of lootboxes become visible.
6.3 Experiment 3: Future Work in Deliberation vs Contracts
Havingdemonstratedthattherulerepresentationisappropriateforuseinsocial
contracts, we aim to further prove that these social contracts can be used as
a ‘proxy’ for social deliberation, to give a good approximation of the optimal
solution. This experiment would be run over two (iterated) simulations: one
where social deliberation is allowed and social contracts are not (to serve as a
benchmark), and another with the opposite conditions. We would analyse these
simulations by considering how ‘happy’ the agents are with the Megabike they
are on, which is shown qualitatively by the (average) number of bike exclusions:
both voluntary and involuntary.
Wehypothesisethattheuseofsocialcontractsshouldbeabletoapproximate
thenumberofexclusionsoccurringwithsocialdeliberation.Fora‘good’approx-
imation, we would find that using social contracts only overshoots the number
of exclusions (under deliberation) by 10%, say, giving a confidence interval of
90%. Furthermore, through iteration, the probability of deviating by less than
10% should be within one standard deviation.
7 Related Research
Defeasibility, the property of a claim or rule to be falsified, changed, replaced,
or ‘mutated’, acts as a pillar in dynamic agent-agent communication [3,14]. The
MAS literature is not short of approaches for deciding which rules of a socio-
technical multi-agent system should be changed and how. However, most ap-
proaches tackle rule change by describing processes which, despite being trans-
parent, interpretable, and tractable, ultimately place a ‘heavy’ burden on AI
agents and MAS engineers from a socio-functional requirement standpoint.
A different perspective on addressing socio-cognitive properties is taken by
the agent-oriented programming languages (AOPLs) that specify how to imple-
ment agent communication languages such as FIPA and KQML. AOPLs have
previously been extended to integrate the multiple layers of abstraction in the
multi-agentsystemsliterature,whicharetheagentlayer,theenvironmentlayer,
and the organisational layer.
A modular and scalable example of the approach is the JaCaMo framework
[4]4, which integrates the agent, environment and organisational layers under a
4 https://jacamo-lang.github.io/getting-started16 Scott et al.
single unified multi-agent-oriented programming ‘language’. Indeed, an impor-
tantpropertyoftherulesimplementedinsuchsystemsistheirdefeasibility.The
processes that agents of such systems follow to interact should be able to allow
the agents to change the rules when it is reasonable to do so. More recently,
the JaCaMo framework has been used in the MAS community for creating dis-
tributed human loop systems that leverage argumentation and mentalisation
techniques,e.g.,whereAIagentsandhumanusersshareevidencetoreachmore
justified conclusions about each other’s mental attitudes [25].
Despite the ‘academic’ advancements in engineering socio-cognitive MAS,
fewer real-world applications of such systems have been deployed. This might
be because the problem of having a speedy and cognitively efficient approach
for both AI agents and experimenters regarding rule processing persists. One
exception is the MAIDS framework, a JaCaMo extension, that implements in-
tentionaldialogueAIsystemsforhuman-AIteamsthatself-organisetooptimise
hospital bed allocation [5]. However, the hospital bed allocation problem does
nothavethesameentangledcomplexityoftheMegabike scenario,whichinvolves
self-selection, self-determination of social arrangements, and existential threats.
Megabike aims to provide insights into social arrangements, whereas MAIDS is
tailored to a very specific domain problem.
8 Summary and Conclusions
In summary, this workshop paper is set in the context of self-organising multi-
agent systems, in which the agents have voluntarily joined an organisation, and
nowhavetonegotiateabinitio,andrepeatedly,thesocialarrangementsfortheir
own self-governance. It has specifically addressed both the abstract problem
of balancing (ideal) social deliberation vs. (practical) social contracts, and the
problemofdefininganexpressiverulerepresentationandefficientruleprocessing
for these social contracts.
The specific contributions of the current work are:
– tohavespecifiedtheMegabikeScenarioandtodefinethesocialarrangements
designed to address the multiple inter-dependent social problems that arise
in the scenario;
– to have identified a quintet of interleaved socio-functional requirements,
namely scalability, complexity, mutability, enforceability and versatility;
– to have discussed the contrast between social deliberation (for which both
consensus and majority decision-making can be problematic [9]) and social
contracts, which can be equally effective in reaching a ‘correct’ decision;
– to have defined an effective representational formalism for these social ar-
rangements, and algorithms for efficient processing; and
– to have derived some analytic results with respect to the socio-functional
requirements, and some empirical results fromsimulation, thatdemonstrate
the improved performance of social contracts over social deliberation.
However,thesignificanceofthisworkforself-organisingmulti-agentsystems
is to highlight that to cope with the burden of self-governance, the agents needSocial Deliberation vs. Social Contracts 17
some awareness of their own limitations. This includes, firstly, realising that the
cognitiveandcommunicativeoverheadsimposedbydeliberativedecision-making
under constraints imposed by the environment is having a deleterious effect on
their survivability; and secondly, recognising that by substituting social deliber-
ation with social contracts they can – ideally – produce approximately as good
a result. It also demands some awareness of the importance of compromise with
respect to values in the negotiation phase of joining a megabike, in deciding
the original set of social arrangements, as this agreement is the essential assur-
anceunderpinningeffectiveequivalenceofoutcomesofsocialdeliberationversus
social contracts.
Additionally, this work suggests that there is not necessarily an ‘optimal’
social arrangement: there may be mutatis mutandis more ‘preferable’ social ar-
rangements according to values, but the important requirements seem to be (a)
being able to subordinate personal preferences for benefit of the common good,
(b) being able to change ‘on demand’ existing arrangements to alternative ar-
rangements that are ‘fit for purpose’ for prevailing environmental conditions,
and (c) not getting stuck in those arrangements when conditions change.
Acknowledgements
We are grateful for the constructive comments of three anonymous reviewers,
which have improved this article. We also acknowledge the contribution of the
Imperial College London Department of Electrical and Electronic Engineering
SOMAS 23-24 Cohort, who developed the infrastructure used to run the exper-
iments described in Section 6. Thanks to Ella Bettison for assistance with that
experimentation.
References
1. Artikis,A.,Sergot,M.,Pitt,J.:Specifyingnorm-governedcomputationalsocieties.
ACM Trans. on Computational Logic 10(1), 1–42 (2009)
2. Artikis,A.,Sergot,M.J.,Paliouras,G.:Run-timecompositeeventrecognition.In:
Proc.oftheSixthACMInternationalConf.onDistributedEvent-BasedSystems,
DEBS. pp. 69–80. ACM (2012)
3. Boella, G., Governatori, G., Hulstijn, J., Riveret, R., Rotolo, A., van der Torre,
L.:TimeanddefeasibilityinFIPAACLsemantics.In:2008IEEE/WIC/ACMInt.
Conf. on Web Intelligence and Intelligent Agent Technology. vol. 3, pp. 634–637.
IEEE (2008)
4. Boissier, O., Bordini, R.H., Hübner, J.F., Ricci, A., Santi, A.: Multi-agent ori-
ented programming with jacamo. Science of Computer Programming 78(6), 747–
761 (2013)
5. Engelmann, D.C., Panisson, A.R., Vieira, R., Hübner, J.F., Mascardi, V., Bor-
dini, R.H.: MAIDS – a framework for the development of multi-agent intentional
dialogue systems. In: Proc. AAMAS. pp. 1209–1217 (2023)
6. Graeber,D.,Wengrow,D.:TheDawnofEverything:ANewHistoryofHumanity.
London, UK: Allen Lane (2021)18 Scott et al.
7. Jones,A.,Sergot,M.:Aformalcharacterisationofinstitutionalisedpower.Journal
of the IGPL 4(3), 427–443 (1996)
8. Klein, N.: The Shock Doctrine: The Rise of Disaster Capitalism. London, UK:
Penguin (2007)
9. Mertzani,A.,Ober,J.,Pitt,J.:Θ-learning:Analgorithmfortheself-organisation
of collective self-governance. In: IEEE International Conference on Autonomic
Computing and Self-Organizing Systems (ACSOS). pp. 97–106 (2023)
10. Mertzani,A.,Pitt,J.:Requisitesocialinfluenceinself-regulatedsystems.In:16th
Int. Conf. on Agents and Artificial Intelligence (ICAART). pp. 133–140 (2024)
11. Ober, J.: Demopolis: Democracy before liberalism in theory and practice. Cam-
bridge, UK: Cambridge University Press (2017)
12. Ober, J.: Democracy and Knowledge. Princeton, NJ: Princeton University Press
(2008)
13. Ostrom, E.: Governing the commons: The evolution of institutions for collective
action. Cambridge, UK: Cambridge University Press (1990)
14. Panisson, A.R., Meneguzzi, F., Vieira, R., Bordini, R.H.: An approach for
argumentation-based reasoning using defeasible logic in multi-agent programming
languages. In: 11th International Workshop on Argumentation in Multiagent Sys-
tems. pp. 1–15 (2014)
15. Pitt, J.: Self-Organising Multi-Agent Systems. Singapore: World Scientific (2021)
16. Pitt,J.,Busquets,D.,Macbeth,A.:Distributivejusticeforself-organisedcommon-
pool resource management. ACM TAAS 9(3), 14:1–14:39 (2014)
17. Pitt, J., Schaumeier, J., Artikis, A.: Axiomatisation of socio-economic principles
forself-organisinginstitutions:Concepts,experimentsandchallenges.ACMTAAS
7(4), 39:1–39:39 (2012)
18. Pitt,J.,Ober,J.:Democracybydesign:Basicdemocracyandtheself-organisation
ofcollectivegovernance.In:12thIEEEInternationalConf.SASO.pp.20–29(2018)
19. Rawls, J.: A Theory of Justice. Harvard, MA: Harvard University Press (1971)
20. Rescher, N.: Distributive Justice. Indianapolis, IN: Bobbs-Merrill Co., Inc. (1966)
21. Robert, S., Robert, H., Evans, W., Honemann, D., Balch, T.: Robert’s Rules of
Order, Newly Revised, 10th edition. New York, NY: Perseus Publishing (2000)
22. Rychwalska,A.,Roszczyńska-Kurasińska,M.,Ziembowicz,K.,Pitt,J.:Fitnessfor
purpose in online communities: Community complexity framework for diagnosis
anddesignofsocio-technicalsystems.FrontiersinPsychology12(Article739415),
1–13 (2021)
23. Scott, M., Dubied, M., Pitt, J.: Social motives and social contracts in cooperative
survivalgames.In:Ajmeri,N.,Morris-Martin,A.,Savarimuthu,T.(eds.) COINE
XV. LNCS, vol. 13549, pp. 148–166. Springer (2022)
24. Scott,M.,Pitt,J.:Interdependentself-organizingmechanismsforcooperativesur-
vival. Artificial Life 29(2), 198–234 (2023)
25. daSilva,H.H.,Rocha,M.,Trajano,G.,Morales,A.S.,Sarkadi,Ş.,Panisson,A.R.:
Distributed theory of mind in multi-agent systems. In: 16th International Confer-
ence on Agents and Artificial Intelligence (ICAART). pp. 451–460 (2024)
26. Southwood, N., Eriksson, L.: Norms and conventions. Philosophical Explorations
14, 195–217 (2011)
27. Suber,P.:TheParadoxofSelf-Amendment:AStudyofLaw,Logic,Omnipotence,
and Change. Oxford, UK: Peter Lang Publishing (1990)