Smartphone-based Eye Tracking System using Edge Intelligence and Model
Optimisation
NishanGunawardena,GoughYumuLui,JeewaniAnupamaGinige,BahmanJavadi
aWesternSydneyUniversity,LockedBag1797,Penrith,2751,NSW,Australia
Abstract
A significant limitation of current smartphone-based eye-tracking algorithms is their low accuracy when applied
to video-type visual stimuli, as they are typically trained on static images. Also, the increasing demand for real-
time interactive applications like games, VR, and AR on smartphones requires overcoming the limitations posed
by resource constraints such as limited computational power, battery life, and network bandwidth. Therefore, we
developed two new smartphone eye-tracking techniques for video-type visuals by combining Convolutional Neural
Networks(CNN)withtwodifferentRecurrentNeuralNetworks(RNN),namelyLongShortTermMemory(LSTM)
andGatedRecurrentUnit(GRU).OurCNN+LSTMandCNN+GRUmodelsachievedanaverageRootMeanSquare
Errorof0.955cmand1.091cm,respectively. Toaddressthecomputationalconstraintsofsmartphones,wedeveloped
anedgeintelligencearchitecturetoenhancetheperformanceofsmartphone-basedeyetracking. Weappliedvarious
optimisation methods like quantisation and pruning to deep learning models for better energy, CPU, and memory
usageonedgedevices,focusingonreal-timeprocessing. Usingmodelquantisation,themodelinferencetimeinthe
CNN+LSTMandCNN+GRUmodelswasreducedby21.72%and19.50%,respectively,onedgedevices.
Keywords:
Eyetracking,Edgeintelligence,Deeplearning,Quantisation,Pruning,Energyconsumption,Memoryusage.
1. Introduction
Eyetrackingistheprocessofmeasuringeyemovements. Ithelpstodeterminewhereusersarelookingandfor
howlongtheyfixatetheirgazeonaparticularlocation.AccordingtoGlobalMarketInsights,theEyeTrackingMarket
sizewasvaluedatUS$852.6millionin2023[1],anditisexpectedtogrowatacompoundannualgrowthrateofover
30.5% between 2024 and 2032. This implies a significant rise in the integration of eye-tracking technology across
variousindustries. Theincreasingdemandforeye-trackingsystemsinsectorssuchasautomotive,healthcare,retail,
andconsumerelectronicsdrivesthisgrowth[1]. Additionally, theadvancementineye-trackingtechnology, suchas
improvedaccuracy,easeofintegration,andaffordability,furtheracceleratesmarketexpansion. Asthemarketcontin-
uestogrow,itopensupnewopportunitiesforinnovativeapplicationsinhuman-computerinteraction,psychological
research,andaccessibilitysolutions,therebyshapingthefutureofeye-trackingtechnology.
Given theimportance ofeye tracking, itis necessaryto examine howdifferent typesof visualstimuli onsmart-
phonescanaffecthumangazeestimation. Goldbergetal. [2]usedfunctionalmagneticresonanceimagingtostudy
attention-relatedbrainactivitywhenviewingdynamicandstaticvisualstimuli. Thestudyfoundthatdynamicstimuli
activated brain regions linked to attentional control more than static stimuli. Smartphone eye-tracking applications
relying on user interaction with dynamic visual content, such as virtual reality (VR), augmented reality (AR), and
gaming,requireaccurateandefficienteye-trackingalgorithmstomonitorgazeandensureapositiveuserexperience.
Theseapplicationsdemandreal-timeprocessingandadaptabilitytovariousvisualstimuli.
However, a significant limitation of current smartphone-based eye-tracking algorithms [3, 4] is their reduced
accuracywithvideo-typevisualstimuli, asthesealgorithmsaretrainedonstaticimages. Toaddressthischallenge,
we proposed two appearance-based eye-tracking models for smartphones that utilise the front-facing camera. Our
approachcombinesCNNwithRecurrentNeuralNetworks(RNN),specificallyLSTMandGRUarchitectures.
Running a deep learning model for extended periods on a smartphone presents challenges due to resource con-
straintssuchaslimitedcomputationalpower,batterylife,andnetworkbandwidth,whichaffectreal-timeprocessing.
PreprintsubmittedtoInternetofThings August23,2024
4202
guA
22
]VC.sc[
1v36421.8042:viXraTo address these issues and improve the feasibility of the proposed eye-tracking algorithm on smartphones, we ex-
plore the use of edge intelligence. This approach shifts deep learning model inference from the device to nearby
edgeservers. Toassesstheperformanceofthesealgorithmsintermsofprocessingefficiencyandresourceutilisation,
we evaluated inference time, CPU and memory usage, and energy consumption on various edge devices, including
RaspberryPi4(RPi4),OdroidN2+,IntelNUC,andNvidiaJetsonAGX.
Theotherobjectiveofthisstudyistodeterminethelevelofperformanceimprovementobtainableviatheuseof
optimisation techniques such as pruning and quantisation and the magnitude of the accuracy trade-off that occurs.
Pruningistheprocessofidentifyingandremovingunnecessaryweightsfromaneuralnetwork. Incontrast,quanti-
sationfocusesonreducingtheprecisionoftheweightsandactivationsinaneuralnetwork. Therefore,theproposed
models were subjected to both pruning and quantisation to evaluate the effects of these techniques on their perfor-
mance. Byimplementingtheseoptimisations, weaimedtoenhancethemodel’sefficiency, makingitmoresuitable
fordeploymentonresource-constrainededgedevices.
Thispapermakesthefollowingcontributions:
• Designanddevelopmentofdeeplearning-basedmodelsforgazeestimationonsmartphonesforvideocontent
withhighaccuracy. (Section3)
• Propose an edge intelligence architecture for smartphone-based eye tracking and evaluate the inference time,
CPUandmemoryusage,andenergyconsumptionwithrealedgedevices. (Section4and5)
• Evaluationoftwomodeloptimisationtechniquescalledquantisationandpruningtoenhancetheefficiencyof
theproposedeye-trackingmodels. (Section4and5)
Thesubsequentsectionsofthispaperareorganisedasfollows:Section2providesanoverviewofrelatedmethod-
ologiesandapproaches. Section3includestheproposeddeeplearningarchitecture, thedatacollectionandprepro-
cessingmethods,animplementationoftheproposeddeeplearningarchitectures,andperformanceevaluationsofthe
proposedmodels. Section4exploresproposededgeintelligencearchitectureanddeeplearningmodeloptimisation
techniquessuchaspruningandquantisation. TheresultsandfindingsoftheexperimentsarediscussedinSection5.
Finally,wedrawaconclusioninSection6.
2. Relatedwork
This section provides an overview of previous research in eye tracking on smartphones and the integration of
edge intelligence and model optimisation for real-time applications. It highlights the evolution of methodologies,
challengesfaced,andgapsthatthisstudyaimstoaddress.
2.1. EyeTrackingonSmartphones
Traditional eye-tracking methods have faced challenges such as high costs, lack of portability, limited accuracy
indynamicenvironments,andextensivecalibrationneeds[5,6,7]. Theintegrationofadvancedcameratechnologies
andsophisticatedmachinelearningalgorithmsinsmartphonesoffersapromisingavenuetoaddressthesechallenges
[3,4,8].Overtheyears,researchershaveexploredvariousgazeestimationmethodologies,predominantlyfocusingon
model-based,appearance-based,andfeature-basedtechniques.Inmodel-basedgazeestimation,twoprimarymethods
havebeenidentified:shape-basedandcorneal-reflectiontechniques. Shape-basedmethodsestimategazedirectionby
analysingfacialfeatures,suchastheshapeoftheeyeball,asdemonstratedbySongetal. [9],orthegeometriccon-
figurationofthepupilandeyecorners,asdevelopedbyIshikawaetal. [10]. Conversely,corneal-reflectionmethods
utilisereflectionswithintheeye,pinpointinggazedirectionmoreaccuratelywiththehelpofanexternalinfraredlight
source,atechniquenotedbyDuchowski[11]andwidelyusedincommercialeyetrackersforitsprecision.
Theobjectiveofappearance-basedgazeestimationmethodsistoestablishadirectmappingfromimagestogaze
information.Theenhancementofsmartphonecameracapabilitieshasledtoincreasedresearchintoappearance-based
gazeestimationonmobiledevices.Leietal.[12]reportthatcommonlyusedeye-trackingalgorithmsforsmartphones
relyonCNNs,whicharegenerallyemployedforimageclassificationtasks. Krafkaetal. [3]appliedanAlexNet-type
CNN using face, face-grid, and two eyes asinputs to predict gaze locationon a fixed red dot, achieving an average
2RootMeanSquaredError(RMSE)of1.71cmonmobilephonesand2.53cmontablets. Baˆceetal. [13]developed
twoCNNsforfacedetectionandgazeestimation,resultinginaMatthewsCorrelationCoefficient(MCC)[14]of0.74.
Valliappan et al. [4] employed a modified CNN architecture, adjusted with calibration data and supplemented by a
regression model, resulting in an average RMSE of 1.92 ± 0.20 cm with 26 participants. These studies utilised the
GazeCapturedataset[3],andthefocusofthesestudieswasmainlyonstaticstimuli.
Humanattentionmaychangewiththetypeofvisualstimulithatarepresentedonthesmartphone. Forinstance,
dynamicvisualstimuli,likevideosandmobilegames,requiremoreattentionthanstaticvisualstimuli,suchasweb
pages and images [15]. The primary distinction between static and dynamic stimuli is the inclusion of motion and
temporal variations in the latter, which introduce additional complexities in gaze estimation. However, Mark et al.
[16] used a pre-recorded 30-second video to assess the perception of high-stress scenarios in an aviation mission
simulator. In [17] and [18], scholars have used eye tracking with video stimuli to assess participants’ attention in
pre-learningunknownwordsandvisuallanguage. Thesestudiesindicatethateyetrackingcanprovideusefulinsights
intounderstandinghumans’gazebehaviourwhenlookingatunfamiliarvideo-typedynamicvisuals. Allthesestudies
were performed using commercial eye trackers, and we have identified only one study that used both appearance-
basedmobiledeviceeyetrackingandacommercialeyetrackerwithavideostimulus.Ottoometal.[19]developedan
appearance-basedgazeestimationsystemforsmartphones,aimingtodeterminewhichoftheninepredefinedregions
on the screen a user is looking at while watching an American Sign Language video. They have achieved 91.3%
accuracycomparedtothecommercialeyetracker. Therefore, weseeaclearresearchgapinappearance-basedeye-
trackingalgorithmsinsmartphonesfordynamicvisualstimulienablingreal-timegazeestimationonvideos,games,
or interactive content on smartphones. While previous studies focused on static stimuli, our approach specifically
addressesthechallengesposedbydynamicvisualcontentonsmartphone-basedeyetracking.
ThereislimitedresearchexploringthecombinationofCNNandRNNarchitecturesfordevelopingappearance-
based eye-tracking systems. The advantage of employing both CNN and RNN lies in the ability to harness their
respectivestrengths,ultimatelyleadingtoenhancedaccuracyineyetracking. CNNsexcelatlearningspatialfeatures
within images, while RNNs are proficient in capturing temporal dependencies in sequential data. Palmero et al.
[20] introduced a gaze estimation algorithm based on CNN+LSTM for a 24” screen, resulting in a 4% accuracy
improvement compared to a static CNN approach. Park et al. [21] presented a gaze estimation algorithm utilising
a CNN+GRU model, achieving a 28% performance enhancement in gaze direction estimation error compared to
alternative models. However, none of these studies were performed in the context of eye tracking on a handheld
mobiledevice.
2.2. EdgeIntelligenceandModelOptimisationforEyeTracking
Smartphoneshavewitnessedasurgeinprocessingcapabilitiesinrecentyears;however,theyremainconstrained
bybatterylifeandcomputationalresources. Thisposesachallengeinexecutingreal-timeandcompute-intensiveap-
plications. Insuchcases,offloadingthesetaskstootherdevices,suchasedgedevicesorcloudcomputingplatforms,
becomesnecessary[22].Particularly,transferringthecomputationallyintensiveeye-trackingapplicationsfromsmart-
phonestoeithercloudoredgeinfrastructurecansubstantiallyreducecomputationalpower,memoryusage,andpower
consumptiononthesmartphone. This,inturn,contributestoenhancingtheoverallqualityofexperience.
Dao[23]exploredusingcloudcomputingsystemsforreal-timeeye-trackinganalysisforfixationdetection,heat
map visualisation, and eye-tracking data classification. Dao’s findings demonstrated that cloud computing offers
advantagesoversinglePCsintermsofrunningtime,dataaggregation,andscalability.However,cloudcomputinghas
somelimitationsintermsoflatency,networkbandwidth,andprivacy.
Theneedforedgeintelligence[24]becomesapparentinlightoftheselimitations. Inedgeintelligence,artificial
intelligence(AI)algorithms, suchas machinelearningmodels, aredeployedonedgedevices toperformtaskssuch
asdataanalysis, patternrecognition, anddecision-makinginrealtime. ThisbringscomputationandAI-drivendata
processingclosertothedatasource,reducinglatencyandenablingrapid,real-timedecision-making. Therefore,edge
intelligenceprovidesimmediatedecision-makingcapabilitiesandenhancesdataprivacyandsecuritybyminimising
data transfer to centralised servers. Moreover, it offloads the cloud infrastructure, reducing internet bandwidth and
transitcosts.
Future applications of eye tracking technology may require integration with more real-time applications such
as augmented reality (AR) systems and mobile games [25]. However, these integrations demand high-performance
3computationalplatformstohandleeye-trackingdataefficientlyandprovidefeedbackinreal-time[26].Inourprevious
study[27],wecomparedfourlightweightCNNmodelsforsmartphone-basedeyetrackingusingdifferentinference
modes,includingon-device,cloud-based,andedge-based. Theresultsofthisstudyprovedthaton-deviceinference
is constrained by energy consumption and memory usage, and the high communication time between smartphones
andthecloudcanmakereal-timeeye-trackingapplicationsimpracticalwithcloud-basedinference. Asaresult,edge
intelligence becomes a more effective solution for delivering a higher-quality user experience in smartphone-based
eye-trackingapplications.
Privacy is another important factor in eye-tracking applications as they capture the user’s facial features. Edge
intelligencecanhelptoreducetheriskofprivacybreachesbykeepingdatalocalandreducingtheneedtotransmitit
tothecloud.Thiscanbedonebyprocessingtheeye-trackingdataonthedeviceitselforonanearbyedgedevice.Edge
devicescanalsoencryptthedatabeforeitissenttothecloudorstoredinasecurelocation.Consideringtheadvantages
ofedgeintelligence,includinglowlatency,increasedsecurityandprivacy,lowcost,andimprovedbandwidthusage,
weproposeanedgeintelligence-basedsystemarchitectureforsmartphone-basedeye-trackingapplications.
Model optimisation is crucial for deploying deep learning models on edge devices, focusing on techniques like
quantisation, pruning, and compression to reduce model size and resource requirements. Chen et al. [28] achieved
a 4.25% accuracy improvement and 3.5x to 6.4x memory reduction in biomedical image segmentation using deep
learning model quantisation. Additionally, Han et al. [29] reduced the VGG-16 model size by 49x with no loss
of accuracy using pruning, quantisation, and Huffman coding. These results underscore the significant impact of
modeloptimisationinenhancingperformanceandefficiencyforedgeintelligenceapplications,especiallyinresource-
constrainedenvironments.
3. DeepLearning-basedEyeTrackingforSmartphones
This section presents the deep learning architectures used in this study for eye tracking on smartphones with
dynamicstimuli. Itincludesthedesignandimplementationdetailsofthreedifferentmodels,comparestheirperfor-
mance,anddiscussestheresultsintermsofaccuracyandon-deviceinferencetime. Thesectionalsointroducesthe
datacollectionmethodsusedtocreateanewdataset,whichaddressesthelackofdynamicvisualstimuliinexisting
datasets.
Inthisstudy, four deeplearningarchitectureswereused foreyetrackingonsmartphones withdynamicstimuli.
Theinitialarchitecture,theiTracker[3],servedasthebaselineforcomparison.Theotherthreearchitecturescombined
CNNandRNNlayers. Figure1presentsthearchitecturesusedinthisstudy. TheiTrackermodelisderivedfromthe
AlexNetarchitecture[30]andadaptedforgazeestimation.Itincorporatesinputsfromaface,twoeyes,andafacegrid.
TrainedusingtheGazeCapturedataset,theiTrackermodelregistersanerrorof1.71cmoniPhoneswithoutrequiring
calibration. Astreamlinedversionofthismodeloperatesinapproximately50msonaniPhone6s. Whenintegrated
with Apple’s face detection technology, it achieves a detection rate of 10-15 frames per second on an iPhone. This
architectureservesasthebenchmarkforcomparisoninthisresearch.
3.0.1. CNN
In our prior study [27], we analysed several CNN architectures such as AlexNet, LeNet-5, ShuffleNet-V2, and
MobileNet-V3 for eye tracking on smartphones using static stimuli. The results indicated that the MobileNet-V3
architecturesurpassedtheothersinaccuracyandcomputationalefficiency. Specifically,MobileNet-V3recordedthe
lowest RMSE at 1.42 cm and demonstrated an inference time of only 65ms per frame when evaluated using the
GazeCapture dataset. The first proposed architecture we used in this study is based on the findings of our previous
study[27].
We used the concept of depthwise and pointwise convolutions from the MobileNet-V3 architecture to enhance
efficiency,reducecomplexity,andincreasethenon-linearityofthemodelsproposedfordynamicstimuli. Depthwise
convolutioninvolvesapplyingaseparatefiltertoeachinputchannel,allowingthefiltertolearndistinctfeaturesfrom
eachchannel,whichcanenhanceperformance. Pointwiseconvolutionappliesasinglefilteracrossallinputchannels,
enabling the filter to learn features common to all channels, thereby also improving performance. By combining
depthwise and pointwise convolutions, depthwise separable convolutions are formed. This technique first applies a
depthwiseconvolution, followedbyapointwiseconvolution, improvingperformancewhilereducingthenumberof
parameters. ThearchitectureusedinthisstudyispresentedinFigure1a.
4(a)CNNArchitecture (b)CNN+LSTMArchitecture
(c)CNN+GRUArchitecture
Figure1:Architecturaldesignoftheproposedthreedeeplearningmodels.Theinputtothemodelsisgrayscaleimagesoftheuser’sfacecaptured
usingthefront-facingcameraofasmartphone.Theoutputofthemodelsisapairofcontinuousvalues(x,y)thatrepresentthepredictedcoordinates
oftheuser’sgazepointonthesmartphonescreen.
3.0.2. CNN+LSTM
Combining CNN and RNN architectures enables the model to learn both spatial and temporal features of eye-
trackingdata. LongShort-TermMemory(LSTM)architecture,atypeofRNN,isdesignedtomitigatethevanishing
gradientproblemoftenencounteredintraditionalRNNs. Thisissueariseswhenthegradientofthelossfunctionbe-
comestoosmallduringbackpropagation,hinderingthemodel’sabilitytolearnlong-termdependenciesinsequential
data. LSTMdiffersfromGatedRecurrentUnit(GRU)initsapproachtomanagingpastinputmemory. LSTMutilises
three gates: input, output, and forget, to regulate information flow into and out of the cell state, allowing selective
retentionordeletionofpriorinputinformation.Incontrast,GRUusestwogates:updateandreset,tomanagememory
retentionandupdates,makingitmorecomputationallyefficientthanLSTM.Previousstudieshavedemonstratedthe
effectiveness of the CNN+LSTM model. For example, Srinivasu et al. [31] achieved 85.34% accuracy using the
CNN+LSTMarchitectureforskindiseaseclassificationanddetectionwithminimalcomputationalpower.
Inthisstudy,theCNNarchitecturedescribedinSection3.0.1isusedtoextractfeaturesfromtheinput,whilethe
LSTMcapturesandmodelsthetemporaldependenciesbetweentheCNN’soutputvectorandthecorrespondinggaze
coordinatesovertime.Thisapproachimprovesthemodel’sabilitytocapturetherelationshipbetweeneyemovements
andgazepoints, leadingtomoreaccuratepredictions. TheLSTMlayerprocessesthesequenceofgazepointsover
timeandoutputsafixed-lengthrepresentationofthetemporalcontext. ByincorporatingtheLSTMlayer,themodel
bettercapturesthetemporaldynamicsofeyemovements,enhancingpredictionaccuracy. Totheauthors’knowledge,
thisisthefirststudytocombinetheCNN+LSTMapproachforsmartphone-basedeyetracking.
3.0.3. CNN+GRU
Compared to LSTM, GRU uses gating mechanisms that regulate information flow more efficiently, leading to
improvedperformanceinmodellingshort-termdependencies. Specifically,GRUemploystwogates:resetandupdate
gates. Theresetgatecontrolshowmuchofthepreviousstateisforgotten,whiletheupdategatedeterminesthenew
5informationtoincorporateintothecurrentstate. ThissimplifiedgatingstructureallowsGRUtomanageshort-term
dependenciesmoreeffectivelythanLSTM.Forinstance,inshort-termresidentialloadforecasting,Sajjadetal. [32]
utilised a CNN+GRU-based approach, achieving the lowest mean squared error (MSE) of 0.09 compared to other
models,includingCNN+LSTM.
Inthisstudy,wealsocombinedtheCNNarchitecturedescribedinSection3.0.1withaGRUlayerasthefourth
architecture. AlthoughtheCNN+LSTMmodelhasshownpromisingresultsinpriorstudies,weaimedtoassessthe
performanceofamorelightweightmodelwithfewerparameterstoidentifywhichapproachismoresuitableforeye
trackingondeviceswithlimitedresources.
3.1. DataCollection
Wehavemadeuseoftwodifferentdatasets.TheinitialdatasetusedisthepubliclyaccessibleGazeCapturedataset
[3].WehavecreatedanotherdatasetnamedDynamicGazedatasettoovercometheunavailabilityofsmartphone-based
eye-tracking data with dynamic visual stimuli and the lack of diversity in smartphones in the GazeCapture dataset.
Table 1summarisesthekeycharacteristicsofbothdatasets.
Wedevelopedaweb-basedapplicationtocollectdatafromvarioustypesofsmartphones. Weutilisedamoving
dotthattraversedrandompathsacrosstheentirescreentorepresentthedynamicnatureofthestimuli. Mostcrowd-
sourcing platforms do not optimise for smartphones, leading us to develop a web-based application specifically for
smartphones and tablets. For participant recruitment, we utilised the Amazon Mechanical Turk (AMT) 1 platform
andprovidedparticipantswithinstructionsonhowtousetheapplication. TheapplicationwashostedontheWestern
SydneyUniversityservers2toensuredatasecurityandresearchethicscompliance.
Table1:CharacteristicsoftheDynamicGazedatasetusedinthisstudy.
Feature DynamicGaze GazeCapture
Participants 173 1,474
DeviceModels 42 n/a
NumberofFrames 67,591 2,445,504
Min. screenResolution 720x1280 n/a
Max. screenResolution 1440x3200 n/a
Stimuli dynamic(random) staticdots
Referencepoint top-leftcornerofthescreen frontcamera
Platforms iOS/Android iOS
Participantswereaskedtocontributethreevideos,eachtakenwiththeirsmartphoneinadifferentpositionrelative
totheireyes(beloweyelevel,ateyelevel,andaboveeyelevel). Thediverserangeofdevicemodelsandscreenres-
olutionsensuresthatourmodelsaremorerobustandcangeneralisebetteracrossdifferentdevices. Participantswere
compensatedUSD0.50foreachsetofthree20-secondvideorecordings,whichtookapproximatelythreeminutesto
complete. This study was conducted under the ethics approval of the Western Sydney University ethics committee
(Ethics Approval Number - H14493). Once the participant has started the recording, they have to follow the circle
withtheireyeswithoutmovingtheirheads. Aftereachvideo,theyhadtowaitfortherecordedvideotouploadbefore
proceeding to the next one. The data was uploaded as videos, with metadata including user-agent strings, screen
resolution,motionsensordata,anddevicepixelratios. Uponcompletion,workersreceivedauniquestudycodethat
theyneededtosubmitforcredit.
Oncethedatawassubmitted,allthesubmitteddatawereexaminedcarefullybeforeacceptance.Figure2visualises
asetofframesfromtheDynamicGazedataset,illustratingthedifferencesineachposition,appearance,background,
and illumination. A moving dot following random paths covering the entire screen, introduces unpredictability and
complexity, resembling real-world scenarios where gaze behaviour is more dynamic. This dataset challenges the
algorithm’sabilitytoadapttochangingstimuliandassessesitsrobustnessandgeneralisability. Figure3displaysthe
distributionofcoordinatesintheDynamicGazedatasetwiththetopleftcornerofthescreenlocatedat(0,0).
1https://www.mturk.com
2https://mobileeyetracker.cdms.westernsydney.edu.au
6Figure2: SampleframesfromtheDynamicGazedatasetcollectedinthreedifferentpositionsincludingbeloweyelevel(firstrow),sameaseye
level(secondrow),andaboveeyelevel(thirdrow).Theindividualsdepictedinthefigurehaveexpresslyconsentedtothepublicationoftheirfaces.
3.2. Implementation
Followingastandardimageprocessingpipelineforgazetracking, thevideosequenceswerefirstconvertedinto
frames. Videosareessentiallyasequenceofframesdisplayedrapidlytocreatetheillusionofmotion. Byconverting
videosintoframes,thecontinuousstreamofthevideowasbrokendownintoindividualframes,allowingustoanalyse
each frame independently. This breakdown enabled us to apply various image processing techniques, such as face
detectionandfeatureextraction,toeachframe. Subsequently,facedetectionwasperformedusingtheDlibHoGface
detectionalgorithm,asithelpslocatethefacewithineachframeofthevideo,whichiscrucialfordeterminingwhere
thepersonislooking.
Afterfacedetection,theframeswereconvertedtograyscaletosimplifythedataandreducecomputationalrequire-
ments. Thissimplificationcanleadtofasterprocessingtimesandlowercomputationalcosts, makingthealgorithm
moreefficient,especiallywhenprocessinglargeamountsofdata.Colourinformationcanbeusefulincertaincontexts,
suchasdetectingspecificfeaturesorpatterns. Gazetrackingprimarilydependsonthepositionandmovementofthe
eyes[11],whichcanbeeffectivelycapturedingrayscale.
Allframeswerethennormalisedandresizedtoafixedsizeof128x128pixels. Thisnormalisationensuredthat
input features were on a similar scale, which helped the deep learning models converge faster during training and
improvedtheiroverallperformance. Italsohelpsavoidnumericalinstabilitythatcanarisewhenworkingwithdata
withawiderangeofvalues. Resizingtheframestoafixedsize,suchas128x128pixels,isbeneficialforconsistency
and efficiency in processing. It standardises the input size for all frames, making designing and training the deep-
learningmodelseasier. Additionally, afixedsizereducesthecomputationalcomplexityofthemodels, astheyonly
needtoprocessimagesofaconsistentsize,leadingtofasterinferencetimesandmoreefficientuseofresources. The
choiceof128x128pixelsforresizingisbasedonabalancebetweenimagequalityandcomputationalefficiency.
The coordinates of the moving circle, representing participants’ gaze locations, were stored in the database as
CascadingStyleSheetspixelvaluesrelativetothetopleftcornerofthescreen. Usingthepixelsperinchanddevice
pixel ratio values, the physical distance for the coordinates in inches and centimetres relative to the top left corner
(0,0)wascalculated. Thelaststepofthepreprocessingismappingcoordinatesintoframestoensureeachframein
thevideohasacorrespondinggazeposition. Oneofthechallengesencounteredduringthisstepwasthevariability
inthenumberofcoordinatesandframesinthevideowithinarecording. Themainreasonforthischallengeisusing
different smartphones with varying frame rates. Each device may capture a different number of frames per second
(fps), leading to variations in the total number of frames during a recording. The coordinates were generated at 20
coordinates per second, generating 400 coordinates per recording. Mapping between coordinates and interpolating
correspondingframeswasachievedusingthepresentationtimestampassignedtoeachframeandthetimestampof
eachcoordinate.
7Figure3:DistributionofcoordinatesoftheDynamicGazedataset. Axesindicatecentimetresfromthetopleftcornerofthescreen. Forexample,
thecoordinatesofthedotonthescreenareprojectedtothisspacewherethetopleftcornerisat(0,0).
Oncethedataisprocessed,thefourdeeplearningmodelswereimplementedusingtheTensorFlowframework[33]
andtrainedonthetwodatasetsmentionedearlier. Thetrainingprocedureincludedabatchsizeof32for1,564,320
iterationsontheGazeCapturedatasetand45,540iterationsontheDynamicGazedataset. TheAdamoptimiserwitha
learningrateof0.001andadecayrateof0.0001wasusedforallmodels. ThetrainingwasconductedonanNVIDIA
GridRTX6000p-6QGPUwith6GBmemory. ThecodewasdevelopedusingPython3.9andexecutedonaWindows
10machinewith32GBRAMandanIntelXeonGold5215CPU.
Consistentwithpriorwork[3],themodel’sperformanceisquantifiedintermsofthemeanEuclideandistance(in
centimetres)fromthetruefixationlocation,assumedtobethelocationofthemovingdotonthescreenatthatinstant
in time. The efficacy of each model is assessed using two metrics: the RMSE in centimetres and the R2 value. To
ensurearobustandreliableevaluationofthemodels,k-foldcross-validationwithk = 5isemployed. Thisapproach
allowsustoefficientlyutiliseourDynamicGazedatasetbyensuringthateachdatapointisusedforbothtrainingand
validation. Further, this will reduce the potential bias from a single train-test split and gain a more comprehensive
assessmentofthemodel’sgeneralisationcapabilities.
3.3. ResultsandDiscussion
3.3.1. Accuracy
Table 2 presents a comparison of the four models (iTracker, CNN, CNN+GRU, and CNN+LSTM) evaluated
on GazeCapture and the DynamicGaze dataset. These results suggest that the iTracker model with 6.780 million
parameters performs differently depending on the dataset, with better performance on DynamicGaze compared to
GazeCapture. The CNN model with 3.21 million parameters achieves RMSE values of 1.671 cm on GazeCapture
and 1.468 cm on DynamicGaze. This comparison implies that a higher number of parameters does not necessarily
result in better performance. In contrast, the CNN+LSTM and CNN+GRU architectures outperformed both CNN
and iTracker architectures. Specifically, the CNN+LSTM model achieved the lowest RMSE of 0.955 cm on the
DynamicGaze dataset, and the CNN+GRU model achieved the lowest RMSE of 1.091 cm on the DynamicGaze
dataset.
Among the proposed models, the CNN model exhibits lower accuracy across all two datasets due to its fewer
parametersthantheothertwomodels. However,theprimaryreasonforselectingtheCNNmodelwithfewerparam-
etersistoenableitsdeploymentonresource-constrainedmobiledevices. Thereducedparametercountsignificantly
decreasestrainingtime,particularlywhendealingwithlargedatasets. TheCNN+LSTMmodelhasmoreparameters
thantheCNN+GRUmodel,astheGRUarchitectureincorporatesfewergatesandparametersthanLSTM.
8Table2:Performancecomparisonoffourdeeplearningmodels(iTracker,CNN,CNN+GRU,CNN+LSTM)onGazeCaptureandDynamicGaze,
includingk-foldcross-validatedRMSE(cm),R2,andInferenceTime(ms).
Model Dataset Parameters RMSE(cm) R2 Inference(ms)
GazeCapture 1.821±0.232 0.86±0.045
iTracker 6.780M 742.22±17.47
DynamicGaze 1.499±0.210 0.83±0.055
GazeCapture 1.671±0.222 0.79±0.050
CNN 3.210M 255.67±8.11
DynamicGaze 1.468±0.195 0.87±0.045
GazeCapture 1.632±0.213 0.82±0.050
CNN+GRU 3.343M 414.81±9.66
DynamicGaze 1.091±0.130 0.80±0.035
GazeCapture 1.642±0.206 0.85±0.045
CNN+LSTM 3.344M 426.18±10.24
DynamicGaze 0.955±0.139 0.81±0.040
The CNN+LSTM and CNN+GRU models outperformed the CNN model because they could better capture the
temporaldynamicsofeyemovements. TheLSTMandGRUcomponentscouldtracktheeye’smovementovertime,
allowing the model to make more accurate predictions about where the user was looking. In DynamicGaze, the
CNN+LSTMmodeloutperformedothermodels,includingtheCNN+GRUmodel.Thisperformancedifferencecould
beduetothespecificcharacteristicsofDynamicGaze,whichinvolvedamovingdotfollowingrandompathscovering
theentirescreen. ThisisbecausetheLSTM’sabilitytoretaininformationoverlongersequencesandmanagelong-
termdependenciesismoreeffectiveintrackingthemovingdot’srandompaths. Furthermore,TheLSTM’sseparate
cell state and hidden state offer more control over memory retention, which enhances its performance in capturing
complexpatternsanddependenciesinthedata.
WefurtherconductedanANOVAtestfollowedbyTukey’sHSDtesttoevaluatetheperformanceofthesefourdeep
learningmodelsonDynamicGaze. TheANOVAtestrevealedasignificantdifferenceintheRMSEvaluesamongthe
models(F(3,396)=254.42,p<0.001). TheTukey’sHSDtestfurtheridentifiedthatCNN+LSTM(meanRMSE=
0.97)performedsignificantlybetterthanCNN(meanRMSE=1.47),CNN+GRU(meanRMSE=1.10),andiTracker
(mean RMSE = 1.48). These results indicate that CNN+LSTM is the most effective model for these two datasets,
significantlyoutperformingtheothers.
3.3.2. On-deviceInferenceTime
Inferencetimemeasurementsareimportanttodetermineifamodel’sperformancecanmeetthedemandsofreal-
timeapplications. Therefore,theinferencetimeforeachmodel,measuredinmilliseconds,wasrecordedtoevaluate
theirreal-timecapabilities. ThisassessmentwasconductedonaSamsungS22smartphoneusingaFlutterapplication
integratedwithTensorFlowLitemodels. Eachmodelunderwentfiveseparateevaluationstoconfirmtheconsistency
anddependabilityoftheresults. Table2collatestheaverageinferencetimeforprocessingasingleframe,alongwith
thestandarddeviationforeachmodel.
The data reveals a distinct correlation between the complexity of a model and its computational efficiency. The
iTrackermodel,whichhasthehighestnumberofparametersat6.780million,alsohadthelongestaverageinference
time at 742.22 ms, suggesting that its complexity reduces its performance in real-time scenarios. Also, the CNN
model,withfewerparametersat3.210million,registeredtheshortestaverageinferencetimeof255.67ms,indicating
itshighersuitabilityforreal-timeapplicationsduetoquickerprocessingtimes. Thehybridmodels,CNN+GRUand
CNN+LSTM,withparametersaround3.343millionand3.344million,respectively,displayedintermediateinference
timesof414.81msand426.18ms.
Itisimportanttonotethattheseinferencetimemeasurementsonlyaccountforthemodel’scomputationtimeand
donotincludeotherprocessingstepssuchasframecapture,facedetection,andimagepreprocessing. Nevertheless,
thereportedtimessuggestthatachievingreal-timeeyetrackingwiththesemodelsoncurrentmobiledevicesremains
challenging.
4. TheEdgeIntelligenceArchitectureforEyeTracking
This section introduces the edge intelligence architecture designed for real-time smartphone-based eye-tracking
applications. The section also discusses the proposed model optimisation techniques, including quantisation and
9pruning,toenhancetheefficiencyofdeeplearningmodelsonresource-constraineddevices. Theexperimentalsetup
forevaluatingthesemodelsondifferentedgedevicesispresented.
4.1. TheProposedArchitecture
Considering the advantages of edge intelligence, we propose an edge intelligence architecture for smartphone-
based eye-tracking applications as depicted in Figure 4. The proposed architecture is a three-layered approach that
includesthepresentation,edge,andcloudlayers.
Figure4:Proposededgeintelligencearchitectureforreal-timesmartphone-basedeyetrackingapplications
Thecloudlayerencompassesascalablecloudserverequippedwithhigh-performanceresourcescapableoftrain-
ingdeepneuralnetworks.LeveragingGPUprocessingpower,thisserverefficientlyhandleslargedatasetsfortraining
algorithms,thusenablingthedevelopmentofnewermodelsasmoredatabecomesavailable. Italsofeaturesdatastor-
ageforpreservingtrainingdataandeye-trackingdata,suchasgazeheatmaps. Additionally,awebserverisintegrated
toaddressrequestsfromdomainexperts.
The edge layer retrieves the pre-trained deep neural network model from the cloud data storage. This layer
encompasses a range of devices, from low-power Raspberry Pi to more powerful edge devices, contingent on the
specificeye-trackingapplication’srequirements. Oncetheedgelayerreceivesthevideostreamfromthepresentation
layer,itinitiatespreprocessingandinferenceoperationstodeliverreal-timepredictionsofgazecoordinatespromptly.
Theresultsareconveyedbacktothepresentationlayer,whilegazedataisperiodicallystoredonthecloudserverfor
domainexpertstoaccess.
Thepresentationlayeristhebridgeconnectingend-userstovariousreal-timeeye-trackingapplications,including
augmentedreality(AR)applicationsandhealthcareandmedicaldiagnosistools. Theseapplicationscaptureauser’s
faceandeyemovementsthroughthesmartphone’sfront-facingcamera.Thecapturedvideostreamisthentransmitted
wirelesslytotheedgelayerforgazedirectionprediction.
4.2. ModelOptimisation
Optimising deep learning models in the context of edge intelligence is crucial to harness the full potential of
this technology. Edge devices often have limited computational resources, including processing power and mem-
ory. DeepLearningmodels,knownfortheircomplexityandsize,canstraintheseresources,leadingtoperformance
bottlenecks,increasedenergyconsumption,andlongerresponsetimes. Deeplearningmodeloptimisationaddresses
10thesechallengesbytailoringmodelstooperateefficientlyonedgedevicesthroughmodelquantisation,pruning,and
compression,whichreducemodelsizewithoutsignificantlysacrificingaccuracy. Thebenefitsofdeeplearningmodel
optimisationinedgeintelligencearemanifold,includinglowerenergyconsumption,improvedreal-timeprocessing,
andtheabilitytodeployAI-drivenapplicationsonresource-constraineddevices,ultimatelyenhancingtheuserexpe-
rience.Inthisstudy,weemployedmodelquantisationandpruningtoenhancetheefficiencyofthethreedeep-learning
models.
4.2.1. Quantisation
Deeplearningmodelquantisationreducestheprecisionofamodel’sweightsandactivationsbyrepresentingthem
with fewer bits [34]. In deep learning models, weights and activations are typically stored as 32-bit floating-point
numbers, which offer high precision but require more memory and computational resources. When quantisation is
applied, these 32-bit floating-point numbers are converted to lower precision formats, such as 16-bit floating-point
numbersor8-bitintegers. Thisreductioninprecisionallowsthemodeltouselessmemoryandperformcomputations
faster,makingitmoreefficientfordeploymentonresource-constraineddeviceslikesmartphonesoredgedevices.
Theprocessofquantisationinvolvesseveralsteps. Quantisationcanbedoneintwoways: post-trainingquanti-
sation and quantisation-aware training. Post-training quantisation involves training the model in high precision and
thenconvertingittolowprecisionaftertraining. Duringthequantisation-awaretraining,modelswillbetrainedusing
low-precisionvalues,allowingthemodeltolearntocompensateforthequantisationerrors. Duringquantisation,the
rangeofvaluesthateachweightoractivationcantakeismappedtosmallervaluesusingtechniquessuchaslinearor
logarithmicscaling.
Quantisation helps to improve the inference time of deep learning models as lower precision data types require
fewerbitsforstorageandprocessing. Additionally,quantisedmodelsuselessmemory,benefitingedgedeviceswith
limitedmemoryresources. Thelowerprecisionarithmeticoperationsrequirefewercomputationalresources,andthis
canreduceCPUusagesignificantly. Thiswillalsodecreasetheenergyrequiredforcomputations.
4.2.2. Pruning
Pruningisaprocessinwhichunimportantweightsinaneuralnetworkmodelareidentifiedandremoved,particu-
larlythosewithsmallvalues. Thisprocesstypicallyinvolvesiterativetrainingofthemodelandthenidentifyingand
removingtheleastimportantweightsbasedonmagnitudeorconnectivity[35]. Thisiterativeprocessinvolvescycles
ofpruningandfine-tuningtoensurethattheprunedmodelretainsitsaccuracy.
Removingtheseunimportantweightscansignificantlyreducethemodel’soverallsize,reducingmemoryrequire-
ments. Thisreductioninmemoryusagecanalsoresultinmoreefficientdatatransferandstorage. Withfewerweights
and neurons to process, the computational load decreases, leading to faster inference times. Moreover, pruning de-
creasesCPUandenergyconsumptionasitrequiresfewercomputationsthanthebaselinemodel.
Both quantisation and pruning aim to make models more efficient but in different ways. Quantisation provides
immediatebenefitsintermsofreducedmemoryandfasterinferenceduetosimplerarithmeticoperations. Incontrast,
pruning reduces the overall model complexity and can be more effective in lowering the number of computations.
However,thereisatrade-offbetweenaccuracyandefficiency. Quantisationcanintroducequantisationerrorsdueto
thelowerprecision.Pruningcanalsoaffectthemodel’saccuracyduetotheremovalofweightsorneurons.Therefore,
balancingaccuracyandefficiencyiscrucialwhenapplyingthesetechniques.
Toimplementthequantisedmodel,weconvertedtheoriginalTensorFlowmodelfroma32-bitfloating-pointrepre-
sentation,thebaselinemodel,intoa16-bitfloating-pointTensorFlowLitemodelusingthepost-trainingquantisation.
During this process, the TensorFlow Lite Converter tool is utilised to transform the model, where the weights and
activationsareroundedortruncatedtofitintothelowerprecisionformat. Thistransformationyieldedaconsiderable
reductioninthemodelsize,resultinginareductionof74.2%fortheCNNmodel,69.3%fortheCNN+GRUmodel,
and69.19%fortheCNN+LSTMmodel.
Then, we converted the 32-bit TensorFlow model to a pruned model using a 0.1% pruning rate and the low
magnitude method. The pruning schedule gradually increased the sparsity from an initial value of 0.80 to a final
value of 0.90 over 2000 steps, with pruning applied every 500 steps. Continuous experiments were carried out in
ordertodecidetheseparameters,asamoreaggressivepruningprocessresultedinlessaccuratemodels. Thepruned
modelsretainedtheir32-bitfloating-pointnumberprecision. TheCNNmodel’ssizedecreasedby21.75%,whilethe
CNN+GRUandCNN+LSTMmodelsreducedby23.81%and23.19%,respectively.
114.3. ExperimentalSetup
We conducted a performance evaluation of the three deep-learning models that we proposed for eye tracking.
Our objective is to assess the trade-offs between model accuracy, inference time, and resource usage for baseline,
quantised and pruned models. This will help to determine the suitability of each model for specific deployment
scenarios,particularlyinthecontextofrealedgeintelligenceapplications. Further,weevaluatedtheRMSEofthese
optimisedmodelstoidentifythetrade-offsbetweenmaintainingmodelaccuracyandachievingoptimalefficiency.
To conduct this evaluation, we tested four edge devices: a Raspberry Pi 4 (RPi 4), Odroid N2+, Intel NUC,
and an Nvidia Jetson AGX. The key specifications of these devices (CPU, GPU, memory, storage, and operating
system) are presented in Table 3. The selection of these devices was based on their diverse hardware capabilities
andpopularitywithintheedgecomputingdomain, allowingustocomprehensivelyevaluatetheperformanceofour
eye-tracking models and draw meaningful conclusions regarding their suitability for various deployment scenarios
andedgeintelligenceapplications.
Table3:SpecificationofTestedEdgeDevicesforEvaluatingDevelopedEyeTrackingModels.
Specification RPi4 OdroidN2+ IntelNUC NvidiaJetsonAGX
CPU BroadcomBCM2711 Quad-coreCortex-A73 IntelCorei7-10710U 8-coreArm®
quad-coreCortex-A72 Dual-coreCortex-A53 Cortex®-A78AE
ClockRate 1.5GHz 2.4GHz 1.10GHz-4.70GHz 2.2GHz
GPU - Mali-G52(850MHz) IntelUHDGraphics630 NVIDIAAmpere
Memory LPDDR48GB DDR44GB DDR416GB LPDDR532GB
Storage microSD microSD SSD eMMC
OS Ubuntu22.04 Ubuntu22.04(Mate) Windows11 JetPack5.1.2(Linux)
In this study, we developed a Python-based program to perform inference on four selected edge devices. This
programwasdesignedtomeasureboththeinferencetimeandthetimeallocatedtoeachstepwithintheprocessing
pipeline. Simultaneously, we created another Python program to assess the memory and CPU usage. This second
programoperatedconcurrentlywiththefirst,continuously(foreachsecond)monitoringthememoryandCPUusage
oftheprimaryprogrambytrackingitsprocessID.Forourexperimentation,wecarefullyselectedrandomvideosfrom
thedatasetcreatedinSection3.1.
Furthermore,weemployedaRohdeandSchwarzNGM202Two-QuadrantProgrammablePowerSupplytopre-
ciselygaugethepowerconsumptionofeachmodelastheyoperatedonvariousedgedevices. AnotherPythonpro-
gram, runningonaseparatedevice, wasutilisedtointerfacewiththePowerSupply, continuouslyretrievingdataat
a rate of 10 readings per second. This data acquisition process encompassed simultaneous measurements of volt-
age (in volts, V) and current (in amperes, A). Subsequently, these collected data were used to compute the energy
consumptionofeachmodel,expressedinmilliwatt-hours(mWh).
5. PerformanceEvaluation
Thissectionprovidesananalysisoftheperformanceofthedevelopeddeeplearningmodelsforeyetrackingon
edge devices. The evaluation focuses on key metrics such as inference time, CPU and memory usage, and energy
consumption. The trade-offs between model accuracy and optimisation techniques, such as quantisation and prun-
ing, are examined to determine their impact on performance and resource efficiency. Finally, the limitations of the
experimentalsetupandfindingsarediscussed.
5.1. InferenceTime
Inference time is the main performance metric as it directly impacts the model’s ability to respond to incoming
data, makingitanessentialfactorindeterminingitssuitabilityforreal-timeandtime-sensitiveapplications. Inthis
experiment,wemeasurethetimeeachsteptakesintheprocessingpipeline,includingframereading,facedetection,
preprocessing,andinferencingonfouredgedevices. Thisanalysisaimedtoidentifypotentialprocessingbottlenecks.
Table 4 visualises the inference time and total time taken by baseline, quantised and pruned models for four edge
devicesusedinthepreviousiteration.
12Table4:ComparisonofProcessingPipelineandInferenceTiming(inmillisecondsperframe)forBaseline,Quantised,andPrunedModelsonfour
EdgeDevices
Model Device InitialSteps BaselineModel QuantisedModel PrunedModel
Fr.Read Face Preproc. Infer. Total Infer. Total Infer. Total
OdroidN2+ 4.04 86.10 1.96 181.22 273.32 56.24 148.34 162.05 254.15
RPi4 6.69 109.21 2.66 257.91 376.47 67.84 186.4 220.14 338.7
CNN
IntelNUC 1.45 35.59 0.86 84.89 122.79 10.52 48.42 75.24 113.14
JetsonAGX 2.42 53.90 3.19 102.82 162.33 27.51 87.02 89.91 149.42
OdroidN2+ 4.03 86.20 1.97 334.26 426.46 223.85 315.73 289.58 381.78
CNN+GRU RPi4 6.15 108.85 2.46 433.74 551.2 255.07 369.53 370.61 488.07
IntelNUC 1.66 35.42 0.97 114.38 152.43 85.62 122.70 96.33 134.38
JetsonAGX 2.36 53.50 3.08 120.69 179.63 113.53 182.18 116.4 175.34
OdroidN2+ 4.04 86.13 1.94 335.35 427.46 224.83 316.93 293.23 385.34
CNN+LSTM RPi4 6.15 109.08 2.46 442.56 560.25 257.39 371.85 385.15 502.84
IntelNUC 1.51 34.52 0.82 130.48 167.33 94.05 130.99 109.40 146.25
JetsonAGX 3.01 56.58 3.97 136.99 200.55 124.51 183.76 128.33 191.89
Among the devices tested with the CNN model (baseline), the Intel NUC performed best in all measured cate-
gories,showingthelowesttimeforinitialsteps(1.45ms),facereading(35.59ms),preprocessing(0.86ms),inference
(84.89ms),andtotaltime(122.79ms). TheJetsonAGXachievedpreprocessingandinferencetimesof3.19msand
102.82 ms, respectively, summing up to 162.33 ms. The Odroid N2+ and RPi 4 have their trade-offs between cost
andperformancewhenusingthemforsmartphone-basedeyetracking,wheretheOdroidN2+yieldedatotaltimeof
273.32ms,whiletheRPi4produced376.47ms.
For the CNN+GRU model (baseline), the Intel NUC produced the lowest times across all categories, with an
inferencetimeof114.38msandatotaltimeof152.43ms. TheJetsonAGXperformedbetterthantheOdroidN2+
andRPi4,withatotaltimeof179.63ms,butwasstilllessefficientthantheIntelNUC.Similartotheprevioustwo
models,theIntelNUCoutperformstheotherdevicesinthebaselineCNN+LSTMmodel.Itachievedthelowesttimes
ininitialsteps,facereading,preprocessing,andinference,culminatinginatotaltimeof167.33ms. TheJetsonAGX
takeslongerforpreprocessingandinferencecomparedtoitsperformancewiththeCNNmodel,leadingtoatotaltime
of 200.55 ms. The Odroid N2+ and RPi 4 continue to lag, with total times of 427.46 and 560.25 ms, respectively,
indicatingthesubstantialprocessingdemandsofLSTMlayers.
The primary reason for this achievement in Intel NUC is due to the Intel Core i7-10710U processor, which is
notablymoreperformantthantheARM-basedprocessorsfoundintheotherthreedevices. Further,thisperformance
maybeattributedtoitsoverallcomputationalstrengthandhigherpowerconsumption. Additionally,theJetsonAGX
appeared to be operating in a lower power-envelope mode, suggesting it might achieve faster performance if not
constrainedbypowerlimitations. Thismightindicatethesuitabilityforreal-timeapplicationswherefastinferenceis
needed;thisismadecapablethroughGPU-acceleratedprocessingbyJetsonAGXbutnotequaltoIntelNUC.
Accordingtotheresultsofthisexperiment,forthequantisedCNNmodel,theOdroidN2+deviceshowsareduc-
tionininferencetimefrom181.22msto56.24ms,representinga69%improvement. Also,theprunedCNNmodel
reducestheinferencetimeto162.05ms, a10.6%improvement. Similarly, ontheRPi4, thequantisedCNNmodel
reduces inference time by 73.7%, while the pruned CNN model shows a 14.7% improvement. The Intel NUC and
Jetson AGX also exhibit considerable improvements with the quantised CNN model, showing reductions of 87.6%
and73.2%,respectively,whiletheprunedmodelimprovesby11.4%and12.6%. Therefore,quantisationconsistently
offersmoresignificantreductionsininferencetimecomparedtopruningacrossdifferentedgedevicesfortheCNN
model.
For the CNN+GRU model, the quantised model on the Odroid N2+ decreases inference time from 334.26 ms
to223.85ms, whereastheprunedmodelreducesitto289.58ms. OntheRPi4, thequantisedmodelreducedfrom
433.74msto255.07ms,andwiththeprunedmodelto370.61ms. Thisisa41.2%improvementwiththequantised
modelanda14.5%improvementwiththeprunedmodel. OntheIntelNUC,thequantisedmodelimprovesinference
time by 25.2% and the pruned model by 15.8%. The Jetson AGX shows improvement with the quantised model,
reducingfrom120.69msto113.53msandwiththeprunedmodelto116.4ms.
13FortheCNN+LSTMmodel,OdroidN2+andRPi4exhibit33%and41.8%improvementintheinferencetime.
The Intel NUC shows a 27.9% improvement with the quantised model, which is a 2.7% decrease compared to the
CNN+GRUmodelonIntelNUC.OntheJetsonAGX,thequantisedmodelimprovedtheinferencetimefrom136.99
msto124.51ms,andtheprunedmodelachievedaninferencetimeof128.33ms.Thereasonforgettingsimilarresults
forbothCNN+GRUandCNN+LSTMmightbethesimilaritiesinthecomputationalpatternsanddatadependencies
ofGRUandLSTMlayers.
TheperformanceimprovementiscomparativelylowerforoptimisedCNN+RNNmodelsthanforoptimsedCNN.
BecausetherecurrentnatureofGRUandLSTMlayersneedstomaintaintheirstateacrosstimesteps,thiscanreduce
the efficiency gains through quantisation. In contrast, CNN layers contain more parallelisable operations such as
convolution,activationandpoolingoperations,whichcanincreasetheefficiencyofthequantisedmodel.
Overall, these results indicate that quantisation consistently achieves significantly greater inference time reduc-
tions than pruning. This can be because quantisation simplifies arithmetic operations by reducing data precision,
directlyspeedingupcomputations. Incontrast,pruningreducesthemodelsizebyeliminatinglessimportantweights
andneurons,reducingthenumberofcomputationstoalesserextentthanquantisation. Bothtechniquesmakemodels
moreefficientandsuitablefordeploymentonedgedevices.
Real-time eye tracking requires a frame rate of at least 30 fps. This means that the total processing time must
be under approximately 33 milliseconds per frame. The results show that only the quantised CNN model on the
Intel NUC comes close to meeting this requirement. This combination achieved a total time of 48.42 ms, which
can perform around 20fps in a real-time smartphone-based eye-tracking application. However, low accuracy in the
CNNmodelmaystillbeaproblemforthesekindsofapplications. ThemaximumframeratesfortheCNN+LSTM
andCNN+GRUmodelsareachievedwiththequantisedversionontheIntelNUC,whichare7.63fpsand8.15fps,
respectively.
Further, it became evident that inference time alone is not the sole obstacle to achieving real-time processing
speeds within the pipeline. Among the various preprocessing steps, we identified face detection as a notably time-
intensiveprocess.UtilisingtheDlibfacedetectionalgorithm,wedeterminedthattheIntelNUCexhibitedtheshortest
averagefacedetectiontime,surpassingtheRPi4(whichperformedtheslowest)byasubstantialmarginof67.45%.
However,it’sessentialtoacknowledgethetrade-offbetweentheaccuracyandspeedoffacedetectionalgorithms.Less
precisefacedetectionalgorithmsmayleadtoahigherincidenceofmissingvalueswithintheeye-trackingalgorithm.
OneofthefuturedirectionsistousefastandtinyfacedetectionalgorithmssuchasYuNet[36]andHaarClassifiers
[37]. Disparitiesinframereadingtimesmay,inpart,beattributedtodifferencesinstoragespeed,RAMbandwidth,
and CPU performance across the various edge devices. Additionally, the preprocessing step, which involves frame
resizing,normalisation,andconversiontograyscale,consistentlytooklessthan4msacrossallthedevices.
5.2. CPUandMemoryUsage
CPUusageismainlyapplicablewhenassessingthemodels’computationalefficiencyandsuitabilityfordeploy-
mentonvarioushardwareplatforms. HighCPUusagecanleadtoprocessesbeingqueued, whichincreaseslatency
and reduces responsiveness. Additionally, high CPU usage itself can cause increased power consumption, which is
acrucialconsiderationforresource-constraineddeviceslikemobilephonesandembeddedsystems. Memoryusage,
ontheotherhand,quantifiesthevolumeofworkingmemorynecessarytostoreandexecutetheeye-trackingmodels
duringinference. Thismeasurementissignificantinscenarioswherememoryresourcesarelimited,suchasonsmart-
phonesorembeddedsystems. Excessivememoryusagecanleadtoperformancedegradationduetomemorypaging
andswapping,wherethesystemmovesdatabetweenRAManddiskstoragetomanagememorydemands. Thiscan
slowdownapplicationsandpotentiallycausecrashesduetomemoryexhaustion. Therefore,findingtherightbalance
betweenmodelaccuracyandmemoryefficiencyisessentialforensuringsmoothandreliableoperationacrossvarious
devicesandenvironments.
The results visualised in Table 5 show the CPU and memory usage for the baseline deep learning model across
differentedgedevices,highlightingthevariableefficienciesandresourcerequirementsofeachplatform.Theseresults
reflect different capabilities and architectures among the tested devices. For the baseline CNN model, Odroid N2+
and RPi 4 have shown CPU usage of 174.95% and 178.15%, respectively, due to relatively low processing power.
Also,thisindicatesthattheyrequiremoreCPUcyclestohandlethecomputations. ThememoryusageoftheRPi4is
considerablyhighat1751MBcomparedtothatoftheOdroidN2+at1356.95MB.Incontrast,theIntelNUC,witha
14Table5:ResourceUtilisationPerFrameforBaseline,QuantisedandPrunedModelsonVariousEdgeDevices.
Model Device BaselineModel QuantisedModel PrunedModel
CPU Memory CPU Memory CPU Memory
% (MB) % (MB) % (MB)
OdroidN2+ 174.95 1356.95 106.64 417.09 144.13 1215.65
RPi4 178.15 1751 118.47 383.61 161.61 1420.82
CNN
IntelNUC 61.66 1949.62 60.69 309.33 59.66 1699.62
JetsonAGX 107.58 3884.91 135.42 1124.47 105.58 3184.91
OdroidN2+ 178.81 1547.68 103.33 440.17 146.51 1340.63
CNN+GRU RPi4 177.46 1880.71 109.07 403.18 166.58 1530.73
IntelNUC 67.59 2129.81 64.13 327.07 61.25 1839.52
JetsonAGX 124.41 4126.78 116.95 1800.15 107.18 3376.1
OdroidN2+ 179.38 1534.16 103.37 440.42 147.2 1351.8
CNN+LSTM RPi4 177.63 1892.9 108.99 403.09 167.1 1538.38
IntelNUC 67.26 2135.13 64.88 328.45 65.09 1847.7
JetsonAGX 110.44 4174.27 131.55 1757.09 107.49 3398.92
morepowerfulprocessor,exhibitsalowerCPUusageat61.66%,whichwasmeasuredacrossallcores,indicatingthat
computationsarehandledefficiently. However,thememoryusageontheIntelNUCishighat1,949.62MB,possibly
duetodifferencesincompileroutputforthex86architectureorvaryingOSprocessrequirementsbetweenWindows
11andLinux.
TheCPUandmemoryusageofthebaselineCNN+GRUandbaselineCNN+LSTMmodelsreflecttheadditional
computationaldemandsintroducedbytherecurrentunitsontopoftheconvolutionalunits.SimilartotheCNNmodel,
for the CNN+GRU model, the Odroid N2+ and Raspberry Pi 4 exhibit high CPU usage (178.81% and 177.46%
respectively) and high memory usage (1880.71 MB and 1547.68 MB, respectively). Regarding the CNN+LSTM
model, the Odroid N2+ and Raspberry Pi 4 again show high CPU usage (179.38% and 177.63%, respectively) and
highmemoryusage(1892.9MBand1534.16MB).Moreover,theIntelNUCagainoutperformedalltheedgedevices
inCPUandmemoryusagewhenrunningbothbaselineCNN+LSTMandbaselineCNN+GRUmodels.Therefore,the
variationsinCPUandmemoryusageacrossthesemodelsanddeviceshighlighttheimpactofhardwarespecifications
andmodelcomplexityonperformance.
Withregardtothemodelcomplexities, transitioningfromtheCNNmodeltotheCNN+GRUandCNN+LSTM
models (baseline) increases the CPU usage by 2.21% and 2.54%, respectively, on the Odroid N2+ device. Also,
memoryusageincreasedby14.06%and13.07%,respectively,onthelow-endOdroidN2+device. TheCPUusage
of the Intel NUC increased by 9.61% and 9.08%, respectively, and memory usage increased by 9.24% and 9.51%,
respectively, when transitioning from the CNN model to the CNN+GRU and CNN+LSTM models (baseline). The
main reason for this disparity is that the Odroid N2+ already operates near its maximum CPU capacity, leaving
less headroom for additional processing demands. In contrast, the NUC has more processing power available to
accommodatetheincreasedcomputationalload.
For the CNN model, quantisation leads to a notable reduction in both CPU usage and memory usage. On the
Odroid N2+, the CPU usage drops from 174.95% to 106.64%, and memory usage decreases from 1356.95 MB to
417.09MB.SimilartrendsareobservedontheRPi4andIntelNUC,wherethequantisedmodelsignificantlyreduces
CPUusageandmemoryusage. TheJetsonAGXshowsadifferentpatternwithaslightincreaseinCPUusagebuta
considerabledecreaseinmemoryusage,indicatingthatwhilethecomputationalcomplexityremainshigh,thememory
footprintissignificantlyreduced.
FortheCNN+GRUandCNN+LSTMmodels, thequantisationreducesbothCPUandmemoryusageacrossall
devices.OntheIntelNUC,thequantisedCNN+GRUmodelreducesCPUusagefrom67.59%to64.13%andmemory
usage from 2129.81 MB to 327.07 MB. The Jetson AGX shows a similar pattern, with memory usage dropping
significantly from 4126.78 MB to 1800.15 MB. Moreover, pruned models for CNN+GRU and CNN+LSTM also
show improvements, but again, these are less significant compared to quantised models. For example, the pruned
CNN+LSTM model on the Odroid N2+ reduces CPU usage from 179.38% to 147.2% and memory usage from
151534.16MBto1351.8MB.
Prunedmodelshavelessreducedmemoryusagecomparedtoquantisedmodelsbecausetheremainingweightsand
neuronsoftheprunedmodelstillretaintheiroriginalprecision,typically32-bitfloatingpoint. Thismeansthatwhile
the model’s structure becomes lighter, the memory required to store each weight remains unchanged. Therefore,
pruning is not the best optimisation technique for smartphone-based eye-tracking applications concerning memory
usage.
Moreover,improvingCPUandmemoryusageisnecessaryforimprovingtheperformanceandefficiencyofdeep
learning models on edge devices. Optimising models for these parameters ensures better resource management,
leadingtofasterprocessingtimes,reducedlatency,andoverallimproveduserexperience. Therefore,considerationof
hardwarespecificationsandmodelcomplexityisessentialinthedeploymentofdeeplearningmodelsonedgedevices,
asitdirectlyimpactsperformanceandefficiency.
5.3. EnergyConsumption
Energyconsumptionmeasureshowefficientlyedgedevicesutiliseelectricalpowertoperformtheirtasks. Min-
imisingenergyconsumptionwhilemaintainingadequateperformanceisakeychallengeindesigninganddeploying
energy-efficientedgeintelligencesystems. Table6providesacomprehensiveoverviewofenergyconsumptionmea-
surements across the four edge devices. The energy consumption metrics are categorised into “total energy” and
“additional energy.” Total energy signifies the energy the entire system expends to execute inference for a single
frame. Thismetricencompassesallenergyutilisationduringtheinferenceprocess,includinganyotherenergycon-
sumptionbythedevice(e.g.,bybackgroundprocesses,operatingsystem,idleperipherals,etc.). Ontheotherhand,
additionalenergyrepresentsthespecificenergyconsumedexclusivelyforinferencetaskswithinasingleframe. This
valueisderivedbysubtractingtheenergyconsumedbythedevicewhenidleforanequivalentlengthoftimefromthe
totalenergyconsumption.
Table6:EnergyConsumptionPerFrameforBaseline,QuntisedandPrunedModelsonVariousEdgeDevices.Theenergyconsumptionisbroken
downintothetotalenergy(Total)usageandtheadditionalenergy(Additional)usedspecificallyfortheeye-trackingprocess(excludingidleenergy
consumption).
Model Device BaselineModel QuntisedModel PrunedModel
Total Additional Total Additional Total Additional
(mWh) (mWh) (mWh) (mWh) (mWh) (mWh)
OdroidN2+ 0.6038 0.1917 0.1898 0.0548 0.5987 0.1770
RPi4 0.7053 0.2954 0.2120 0.0893 0.6894 0.2832
CNN
IntelNUC 1.0727 0.8784 0.4138 0.3326 1.0369 0.8497
JetsonAGX 0.7985 0.1970 0.2507 0.0549 0.6941 0.1520
OdroidN2+ 1.0173 0.3380 0.3897 0.1095 0.9987 0.3015
CNN+GRU RPi4 1.1540 0.4850 0.4105 0.1659 1.1109 0.4649
IntelNUC 1.3309 1.0904 1.1137 0.9055 1.3322 1.0458
JetsonAGX 0.9333 0.2539 0.6926 0.2335 0.9690 0.2486
OdroidN2+ 1.0280 0.3414 0.3949 0.1104 0.9997 0.3215
CNN+LSTM RPi4 1.1674 0.4920 0.4172 0.1682 1.1245 0.4781
IntelNUC 1.4897 1.2285 1.1791 0.9596 1.3888 1.1984
JetsonAGX 0.9856 0.5882 0.8203 0.3005 1.3202 0.4247
The results suggest that the baseline CNN model achieved the lowest total and additional energy consumption
per frame on Odroid N2+, which are 0.6038 mWh and 0.1917 mWh, respectively. For the baseline CNN+GRU
model, the Jetson AGX exhibits the lowest energy consumption, with a total energy consumption of 0.9333 mWh
andanadditionalenergyconsumptionof0.2539mWh. Also,forthebaselineCNN+LSTMmodel,theJetsonAGX
hasatotalenergyconsumptionof0.9856mWhandanadditionalenergyconsumptionof0.5882mWh,whichisthe
lowest compared to other devices. This is because the Jetson AGX’s GPU capabilities and optimised hardware for
deeplearningtasksenableittoeffectivelyprocessthemorecomplexLSTMandGRUunitswhilemaintaininglower
energyconsumption.
16TheOdroidN2+andtheRaspberryPi4, whichhavelowerprocessingpower, presentrelativelylowertotaland
additional energy consumption. However, the transition from the CNN model to the CNN+GRU and CNN+LSTM
modelsreflectsadditionalenergyincomputationswithrecurrentunits. Particularly,fortheOdroidN2+,theenergy
consumption increased by approximately 68.47% for CNN+GRU and 70.27% for CNN+LSTM. Similarly, for the
RaspberryPi4,theincreasewasabout63.62%forCNN+GRUand65.54%forCNN+LSTM.
ForthequantisedCNNmodel,thetotalenergyconsumptiondropsfrom0.6038mWhto0.1898mWh,a68.58%
improvement,andadditionalenergyconsumptiondecreasesfrom0.1917mWhto0.0548mWh,a71.41%improve-
ment On the Odroid N2+. Similar trends are observed on the RPi 4 and Intel NUC, where the quantised model
significantly reduces both total and additional energy consumption by 69.93% and 62.14%, respectively. The Jet-
sonAGXshowsaconsiderabledecreaseintotalenergyconsumptionfrom0.7985mWhto0.2507mWh, a68.61%
improvement,withadditionalenergyusagedroppingfrom0.1970mWhto0.0549mWh,a72.13%improvement.
FortheCNN+GRUandCNN+LSTMmodels,quantisationreducesbothtotalandadditionalenergyconsumption
acrossalldevices. OntheIntelNUC,thequantisedCNN+GRUmodelreducestotalenergyconsumptionfrom1.3309
mWh to 1.1137 mWh, a 16.33% improvement, and additional energy consumption from 1.0904 mWh to 0.9055
mWh, a 16.95% improvement. The Jetson AGX shows a similar pattern, with total energy consumption dropping
significantly from 0.9333 mWh to 0.6926 mWh, a 25.81% improvement, and additional energy usage decreasing
from0.2539mWhto0.2335mWh,an8.04%improvement.
PrunedmodelsforCNN+GRUandCNN+LSTMalsoshowimprovementsinenergyconsumption,buttheseim-
provementsarelesssignificantcomparedtoquantisedmodels. Thisindicatesthatwhilepruningeffectivelyreduces
theenergyrequiredforcomputationsbyeliminatinglesssignificantweightsandneurons,thebenefitsaremorepromi-
nent in memory usage rather than energy savings compared to quantisation. However, these results can be used in
futurewhendeployingsmartphone-basedeye-trackingapplicationsonedgedevices.
The Intel NUC exhibits the highest total energy consumption for all the models compared to the ARM-based
edgedevices. ThisdifferencecanbeattributedtotheIntelNUC’shardwarecharacteristics, includingitsIntelCore
i7-10710U processor. While delivering strong computational capabilities, this processor generally consumes more
power,particularlyathighclockspeeds. Additionally,theIntelCore-i7processorisbasedonthex86 64architecture
andtendstodemandgreaterpowercomparedtoARM-basedarchitecturesliketheARMCortex-A72orCortex-A73.
The range of these differences in energy consumption points out that consideration must be given not only to the
model complexity but also to the device’s capabilities in optimising energy-efficient deployments of deep learning
modelsattheedge.
5.4. AccuracyTrade-off
Oneofthelimitationsofmodeloptimisationisthepotentiallossofaccuracy,especiallywhenaggressiveoptimi-
sation techniques such as quantisation or pruning are applied. We calculated the RMSE for each model before and
after optimisation. Table 7 includes RMSE and R2 between the three models under baseline, quantised and Pruned
modes. Additionally,figure5illustratesthetrade-offbetweenRMSEandinferencetimeforbaseline,quantisedand
prunedmodelsonIntelNUC.
Table7: ComparisonofRMSEandR2betweenBaseline,QuantisedandPrunedModelsforthreeArchitectures. Thesemodelswererunonan
IntelNUCdevice.
BaselineModel QunatisedModel PrunedModel
RMSE(cm) R2 RMSE(cm) R2 RMSE(cm) R2
CNN 1.468 0.83 1.680 0.78 1.758 0.79
CNN+GRU 1.091 0.80 1.295 0.77 1.452 0.78
CNN+LSTM 0.955 0.81 1.192 0.78 1.366 0.76
ThetransitionfrombaselinetoquantisedconditionsresultedinanincreaseinRMSEacrossallmodels. Specif-
ically, for the CNN model, the baseline model achieves an RMSE of 1.468 cm and an R2 of 0.83. However, when
themodelisquantised,theRMSEincreasesby14.43%andtheR2 decreasesby6.02%. Similarly,theprunedmodel
showsanRMSEincreaseto1.758cmandanR2decreaseto0.79.FortheCNN+GRUandCNN+LSTMmodels,both
quantisationandpruningintroduceadeclineinaccuracy,withpruninghavingamorenoticeableeffect. Forinstance,
17theCNN+GRUmodelshowsanRMSEincreaseof18.71%to1.295cmandanR2 decreaseof3.75%to0.77after
quantisation,whilepruningleadstoanRMSEincreaseof33.11%to1.452cmandanR2 decreaseof2.50%to0.78.
Similarly,fortheCNN+LSTMmodel,quantisationresultsinanRMSEincreaseof24.81%andanR2dropof3.70%,
whereas pruning leads to an RMSE increase of 43.01% and an R2 reduction of 6.17%. The sequential and interde-
pendent nature of GRU and LSTM layers means that any reduction or alteration in weights through quantisation or
pruningcansignificantlyimpactaccuracy.
Figure5:Trade-offbetweenRMSEandinferencetimeforbaseline,quantisedandprunedmodelsonIntelNUC
Whilequantisationandpruningreducemodelaccuracy,theincreasesinperformance,powerconsumptionandre-
ducedresourcerequirementsmaybeworththetrade-offinconstrainedmobileapplications. Despitethesetrade-offs,
thesignificantimprovementsininferencetime,CPUusage,memoryusage,andenergyefficiencymaketheseoptimi-
sation techniques valuable, especially in resource-constrained environments. Therefore, it is essential to emphasise
that a balance between accuracy, latency, computational demands, and energy efficiency should guide the selection
ofanappropriateedgedeviceandmodelconfiguration. Thisapproachensuresthedevelopmentofedgeintelligence
solutionsthatarebothsustainableandcost-effective.
5.5. Limitations
One of the major limitations of this experiment is we couldn’t measure the GPU utilisation of the edge devices
withGPUs. ObtainingaccuratedetailsofGPUusageischallengingduetoseveralfactors. Firstly,manyedgedevices
do not have built-in tools or standardised methods for monitoring GPU power consumption in real-time. While
CPUsoftenhavewell-documentedpowermanagementinterfaces,GPUslacksuchconsistentmonitoringtoolsacross
different manufacturers and models. Secondly, the power consumption of GPUs can fluctuate rapidly based on the
workload,makingitdifficulttocaptureanaccurateandconsistentmeasurewithoutspecialisedequipment.
Another limitation of this study is the omission of evaluating the communication time between the smartphone
andtheedgedevice,whichisvitalinreal-worldedgeintelligenceapplications. Thecommunicationtimecansignif-
icantly impact the overall system performance and user experience. It can depend on several factors, including the
networklatency,bandwidth,theefficiencyofthecommunicationprotocolsused,anddatacompression. Additionally,
variations in network conditions, such as interference or congestion, can further influence the communication time.
18Sincethesefactorsintroducemorecomplexity,measurementofthecommunicationtimewasconsideredbeyondthe
scopeofourcontrolledexperiments.
One limitation in the model optimisation is that we use post-training quantisation instead of quantisation-aware
trainingduetoitssimplicity. Althoughthisapproachiseasiertoimplementandlesstime-consuming, itmayresult
ingreateraccuracyloss,asquantisation-awaretrainingcanbetteradaptthemodeltohandlereducedprecisionduring
thetraining process. Additionally, we excludedtheevaluation of8-bitfloatingpoint quantisedmodels, considering
thehigherrorobtainedwith16-bitfloatingpointquantisedmodels.
With regards to the pruned models, we kept their 32-bit floating point precision instead of converting them to
a lower precision pruned model. This decision maintained the model’s original precision but did not capitalise on
potentialmemoryandcomputationalsavingsthatcouldbeachievedthroughreducedprecision.Furtherimprovements
couldbeachievedbycombiningquantisationandpruning,whichwouldreduceboththemodelsizeandtheprecision
ofcomputations.
Further, these models were tested in a controlled environment. Real-world conditions, such as network latency,
packet loss, user interaction, and varying input data quality, were not simulated, which could impact the practical
applicabilityofthefindings. Finally, thestudydidnotincludeacomprehensivestatisticalanalysistodeterminethe
significanceoftheobserveddifferences.
6. Conclusion
This study aimed to address the limitations of existing smartphone-based eye-tracking algorithms, particularly
their reduced accuracy when applied to dynamic visual stimuli such as video content. We introduced two novel
architecturesthatcombineCNNwithRNN,specificallyLSTMandGRU,toenhancetheperformanceofeyetracking
on smartphones. Our models demonstrated improved accuracy, achieving a Root Mean Square Error (RMSE) of
0.955cmand1.091cmfor CNN+LSTMandCNN+GRU,respectively, highlightingtheireffectivenessinhandling
dynamicstimuli. Toovercometheresourceconstraintsinherentinsmartphones, weexplorededgeintelligenceasa
solution to offload computational tasks from the device to nearby servers. The evaluation of our models on various
edgedevices,includingRaspberryPi4,OdroidN2+,IntelNUC,andNvidiaJetsonAGX.Amongthesedevices,Intel
NUC was the fastest, processing a single frame in 167.33 ms. Notably, this processing time included 34.52 ms for
detectingandextractingthefacefromaselfievideo. Thesefindingshelpedusfindthemostsuitableedgedevicefor
real-timesmartphone-basedeyetrackingandidentifytheprocessingpipeline’sbottlenecks. Wefurtherinvestigated
deep learning model optimisation techniques, such as quantisation and pruning, to enhance energy efficiency and
reducecomputationaloverheadonedgedevices. ModelquantisationreducedtheinferencetimeoftheCNN+LSTM
modelfrom130.48msto94.05ms. Also,modelpruningreducedtheCPUconsumptionoftheIntelNUCby6.34%.
However, quantisation and pruning increased the error rate by 11.03% and 4.69%, respectively. Thus, our results
suggestthatitiscrucialtobalanceaccuracy, latency, computationaldemands, andenergyefficiencywhenselecting
theappropriateedgedeviceandmodelconfiguration.
Forfuturework,werecognisethesignificantpotentialforrefiningourmodelstoachievehigheraccuracyandeffi-
ciency,especiallyundervaryinglightingconditionsanddynamicuserenvironments.Ourstudyhascertainlimitations,
including the loss of accuracy associated with model optimisation and the challenges of achieving real-time perfor-
mance. Future work could explore combining quantisation-aware training and pruning to further balance accuracy
andefficiency.
CRediTauthorshipcontributionstatement
NishanGunawardena:Conceptualisation,Methodology,Software,Investigation,Writing-Originaldraft.Gough
YumuLui:Writing-ReviewingandEditing,Supervision,Resources,Software.JeewaniAnupamaGinige:Writing-
Reviewing and Editing, Supervision, Project administration. Bahman Javadi: Resources, Writing-Reviewing and
Editing,Supervision.
19Declarationofcompetinginterest
The authors declare that they have no known competing financial interests or personal relationships that could
haveappearedtoinfluencetheworkreportedinthispaper.
DeclarationofgenerativeAIandAI-assistedtechnologiesinthewritingprocess
DuringthepreparationofthisworktheauthorusedChatGPT4oinordertoimprovethereadabilityandlanguageof
themanuscript.Afterusingthistool,theauthorsreviewedandeditedthecontentasneededandtakefullresponsibility
forthecontentofthepublishedarticle.
References
[1] Global Market Insights, Eye tracking market size, industry analysis report, regional outlook, https://www.gminsights.com/
industry-analysis/eye-tracking-market,accessed:2024-08-01(2024).
[2] H.Goldberg,A.Christensen,T.Flash,M.A.Giese,R.Malach,Brainactivitycorrelateswithemotionalperceptioninducedbydynamic
avatars,Neuroimage122(2015)306–317.
[3] K. Krafka, A. Khosla, P. Kellnhofer, H. Kannan, S. Bhandarkar, W. Matusik, A. Torralba, Eye tracking for everyone (2016). arXiv:
1606.05814.
[4] N.Valliappan,N.Dai,E.Steinberg,J.He,K.Rogers,V.Ramachandran,P.Xu,M.Shojaeizadeh,L.Guo,K.Kohlhoff,etal.,Accelerating
eyemovementresearchviaaccurateandaffordablesmartphoneeyetracking,Naturecommunications11(1)(2020)1–12.
[5] X.Yang,I.Krajbich,Webcam-basedonlineeye-trackingforbehavioralresearch,JudgmentandDecisionMaking16(6)(2021)1486.
[6] A. Papoutsaki, J. Laskey, J. Huang, Searchgazer: Webcam eye tracking for remote studies of web search, in: Proceedings of the 2017
conferenceonconferencehumaninformationinteractionandretrieval,2017,pp.17–26.
[7] N.Gunawardena,J.A.Ginige,B.Javadi,Eye-trackingtechnologiesinmobiledevicesusingedgecomputing: Asystematicreview,ACM
ComputingSurveys(CSUR)(2022).
[8] Q.Huang,A.Veeraraghavan,A.Sabharwal,Tabletgaze:Unconstrainedappearance-basedgazeestimationinmobiletablets,arXiv:Computer
VisionandPatternRecognition(2015).
[9] C.Song,A.Wang,K.Ren,W.Xu,Eyeveri:Asecureandusableapproachforsmartphoneuserauthentication,in:IEEEINFOCOM2016-The
35thAnnualIEEEInternationalConferenceonComputerCommunications,IEEE,2016,pp.1–9.
[10] T.Ishikawa,Passivedrivergazetrackingwithactiveappearancemodels(2004).
[11] A.Duchowski,A.Duchowski,Eyetrackingtechniques,Eyetrackingmethodology:Theoryandpractice(2007)51–59.
[12] Y.Lei,S.He,M.Khamis,J.Ye,Anend-to-endreviewofgazeestimationanditsinteractiveapplicationsonhandheldmobiledevices,ACM
ComputingSurveys56(2)(2023)1–38.
[13] M. Baˆce, S. Staal, A. Bulling, Accurate and robust eye contact detection during everyday mobile device interactions, arXiv preprint
arXiv:1907.11115(2019).
[14] B. W. Matthews, Comparison of the predicted and observed secondary structure of t4 phage lysozyme, Biochimica et Biophysica Acta
(BBA)-ProteinStructure405(2)(1975)442–451.
[15] H.Pei,X.Huang,M.Ding,Imagevisualization:Dynamicandstaticimagesgenerateusers’visualcognitiveexperienceusingeye-tracking
technology,Displays73(2022)102175.
[16] J.Mark,A.Curtin,A.Kraft,T.Sands,W.D.Casebeer,M.Ziegler,H.Ayaz,Eyetracking-basedworkloadandperformanceassessmentfor
skillacquisition,in:AdvancesinNeuroergonomicsandCognitiveEngineering:ProceedingsoftheAHFE2019InternationalConferenceon
NeuroergonomicsandCognitiveEngineering,andtheAHFEInternationalConferenceonIndustrialCognitiveErgonomicsandEngineering
Psychology,July24-28,2019,WashingtonDC,USA10,Springer,2020,pp.129–141.
[17] M.MonteroPerez,Pre-learningvocabularybeforeviewingcaptionedvideo:Aneye-trackingstudy,TheLanguageLearningJournal47(4)
(2019)460–478.
[18] A.Stone,R.G.Bosworth,Exploringinfantsensitivitytovisuallanguageusingeyetrackingandthepreferentiallookingparadigm,JoVE
(JournalofVisualizedExperiments)147(2019)e59581.
[19] M.Otoom,M.A.Alzubaidi,Ambientintelligenceframeworkforreal-timespeech-to-signtranslation,AssistiveTechnology30(3)(2018)
119–132.
[20] C.Palmero,J.Selva,M.A.Bagheri,S.Escalera,Recurrentcnnfor3dgazeestimationusingappearanceandshapecues,arXivpreprint
arXiv:1805.03064(2018).
[21] S.Park,E.Aksan,X.Zhang,O.Hilliges,Towardsend-to-endvideo-basedeye-tracking,in:ComputerVision–ECCV2020:16thEuropean
Conference,Glasgow,UK,August23–28,2020,Proceedings,PartXII16,Springer,2020,pp.747–763.
[22] L.Lin,X.Liao,H.Jin,P.Li,Computationoffloadingtowardedgecomputing,ProceedingsoftheIEEE107(8)(2019)1584–1607.
[23] T.-C.Dao, Real-timeeyetrackinganalysisfromlargescaledatasetusingcloudcomputing, SchoolofComputing, UniversityofEastern
Finland(2014).
[24] S.Tuli,F.Mirhakimi,S.Pallewatta,S.Zawad,G.Casale,B.Javadi,F.Yan,R.Buyya,N.R.Jennings,Aiaugmentededgeandfogcomputing:
Trendsandchallenges,JournalofNetworkandComputerApplications216(2023)103648.
[25] J.Li,R.Barmaki,Trendsinvirtualandaugmentedrealityresearch: Areviewoflatesteyetrackingresearchpapersandbeyond,Preprints
(2019).
20[26] H. Chen, Y. Dai, H. Meng, Y. Chen, T. Li, Understanding the characteristics of mobile augmented reality applications, in: 2018 IEEE
InternationalSymposiumonPerformanceAnalysisofSystemsandSoftware(ISPASS),IEEE,2018,pp.128–138.
[27] N.Gunawardena,J.A.Ginige,B.Javadi,G.Lui,Performanceanalysisofcnnmodelsformobiledeviceeyetrackingwithedgecomputing,
ProcediaComputerScience207(2022)2291–2300.
[28] W.Chen,H.Qiu,J.Zhuang,C.Zhang,Y.Hu,Q.Lu,T.Wang,Y.Shi,M.Huang,X.Xu,Quantizationofdeepneuralnetworksforaccurate
edgecomputing,ACMJournalonEmergingTechnologiesinComputingSystems(JETC)17(4)(2021)1–11.
[29] S.Han,H.Mao,W.J.Dally,Deepcompression:Compressingdeepneuralnetworkswithpruning,trainedquantizationandhuffmancoding,
arXivpreprintarXiv:1510.00149(2015).
[30] A.Krizhevsky,I.Sutskever,G.E.Hinton,Imagenetclassificationwithdeepconvolutionalneuralnetworks,Advancesinneuralinformation
processingsystems25(2012).
[31] P.N.Srinivasu,J.G.SivaSai,M.F.Ijaz,A.K.Bhoi,W.Kim,J.J.Kang,Classificationofskindiseaseusingdeeplearningneuralnetworks
withmobilenetv2andlstm,Sensors21(8)(2021)2852.
[32] M.Sajjad, Z.A.Khan, A.Ullah, T.Hussain, W.Ullah, M.Y.Lee, S.W.Baik, Anovelcnn-gru-basedhybridapproachforshort-term
residentialloadforecasting,IEEEAccess8(2020)143759–143768.doi:10.1109/ACCESS.2020.3009537.
[33] M.Abadi,A.Agarwal,P.Barham,E.Brevdo,Z.Chen,C.Citro,G.S.Corrado,A.Davis,J.Dean,M.Devin,etal.,Tensorflow:Large-scale
machinelearningonheterogeneousdistributedsystems(2016).arXiv:1603.04467.
[34] S.Siddegowda,M.Fournarakis,M.Nagel,T.Blankevoort,C.Patel,A.Khobare,Neuralnetworkquantizationwithaimodelefficiencytoolkit
(aimet),arXivpreprintarXiv:2201.08442(2022).
[35] E. Diao, G. Wang, J. Zhan, Y. Yang, J. Ding, V. Tarokh, Pruning deep neural networks from a sparsity perspective, arXiv preprint
arXiv:2302.05601(2023).
[36] W.Wu,H.Peng,S.Yu,Yunet:Atinymillisecond-levelfacedetector,MachineIntelligenceResearch20(5)(2023)656–665.
[37] P.Viola,M.Jones,RapidObjectDetectionusingaBoostedCascadeofSimpleFeatures,Tech.rep.(2001).
21