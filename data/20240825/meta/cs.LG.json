[
    {
        "title": "Non-Homophilic Graph Pre-Training and Prompt Learning",
        "authors": "Xingtong YuJie ZhangYuan FangRenhe Jiang",
        "links": "http://arxiv.org/abs/2408.12594v1",
        "entry_id": "http://arxiv.org/abs/2408.12594v1",
        "pdf_url": "http://arxiv.org/pdf/2408.12594v1",
        "summary": "Graphs are ubiquitous for modeling complex relationships between objects\nacross various fields. Graph neural networks (GNNs) have become a mainstream\ntechnique for graph-based applications, but their performance heavily relies on\nabundant labeled data. To reduce labeling requirement, pre-training and prompt\nlearning has become a popular alternative. However, most existing prompt\nmethods do not differentiate homophilic and heterophilic characteristics of\nreal-world graphs. In particular, many real-world graphs are non-homophilic,\nnot strictly or uniformly homophilic with mixing homophilic and heterophilic\npatterns, exhibiting varying non-homophilic characteristics across graphs and\nnodes. In this paper, we propose ProNoG, a novel pre-training and prompt\nlearning framework for such non-homophilic graphs. First, we analyze existing\ngraph pre-training methods, providing theoretical insights into the choice of\npre-training tasks. Second, recognizing that each node exhibits unique\nnon-homophilic characteristics, we propose a conditional network to\ncharacterize the node-specific patterns in downstream tasks. Finally, we\nthoroughly evaluate and analyze ProNoG through extensive experiments on ten\npublic datasets.",
        "updated": "2024-08-22 17:57:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.12594v1"
    },
    {
        "title": "Identifying the Best Arm in the Presence of Global Environment Shifts",
        "authors": "Phurinut SrisawadJuergen BrankeLong Tran-Thanh",
        "links": "http://arxiv.org/abs/2408.12581v1",
        "entry_id": "http://arxiv.org/abs/2408.12581v1",
        "pdf_url": "http://arxiv.org/pdf/2408.12581v1",
        "summary": "This paper formulates a new Best-Arm Identification problem in the\nnon-stationary stochastic bandits setting, where the means of all arms are\nshifted in the same way due to a global influence of the environment. The aim\nis to identify the unique best arm across environmental change given a fixed\ntotal budget. While this setting can be regarded as a special case of\nAdversarial Bandits or Corrupted Bandits, we demonstrate that existing\nsolutions tailored to those settings do not fully utilise the nature of this\nglobal influence, and thus, do not work well in practice (despite their\ntheoretical guarantees). To overcome this issue, in this paper we develop a\nnovel selection policy that is consistent and robust in dealing with global\nenvironmental shifts. We then propose an allocation policy, LinLUCB, which\nexploits information about global shifts across all arms in each environment.\nEmpirical tests depict a significant improvement in our policies against other\nexisting methods.",
        "updated": "2024-08-22 17:47:01 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.12581v1"
    },
    {
        "title": "RuleAlign: Making Large Language Models Better Physicians with Diagnostic Rule Alignment",
        "authors": "Xiaohan WangXiaoyan YangYuqi ZhuYue ShenJian WangPeng WeiLei LiangJinjie GuHuajun ChenNingyu Zhang",
        "links": "http://arxiv.org/abs/2408.12579v1",
        "entry_id": "http://arxiv.org/abs/2408.12579v1",
        "pdf_url": "http://arxiv.org/pdf/2408.12579v1",
        "summary": "Large Language Models (LLMs) like GPT-4, MedPaLM-2, and Med-Gemini achieve\nperformance competitively with human experts across various medical benchmarks.\nHowever, they still face challenges in making professional diagnoses akin to\nphysicians, particularly in efficiently gathering patient information and\nreasoning the final diagnosis. To this end, we introduce the RuleAlign\nframework, designed to align LLMs with specific diagnostic rules. We develop a\nmedical dialogue dataset comprising rule-based communications between patients\nand physicians and design an alignment learning approach through preference\nlearning. Experimental results demonstrate the effectiveness of the proposed\napproach. We hope that our work can serve as an inspiration for exploring the\npotential of LLMs as AI physicians.",
        "updated": "2024-08-22 17:44:40 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.12579v1"
    },
    {
        "title": "A Percolation Model of Emergence: Analyzing Transformers Trained on a Formal Language",
        "authors": "Ekdeep Singh LubanaKyogo KawaguchiRobert P. DickHidenori Tanaka",
        "links": "http://arxiv.org/abs/2408.12578v1",
        "entry_id": "http://arxiv.org/abs/2408.12578v1",
        "pdf_url": "http://arxiv.org/pdf/2408.12578v1",
        "summary": "Increase in data, size, or compute can lead to sudden learning of specific\ncapabilities by a neural network -- a phenomenon often called \"emergence\".\nBeyond scientific understanding, establishing the causal factors underlying\nsuch emergent capabilities is crucial to enable risk regulation frameworks for\nAI. In this work, we seek inspiration from study of emergent properties in\nother fields and propose a phenomenological definition for the concept in the\ncontext of neural networks. Our definition implicates the acquisition of\nspecific structures underlying the data-generating process as a cause of sudden\nperformance growth for specific, narrower tasks. We empirically investigate\nthis definition by proposing an experimental system grounded in a\ncontext-sensitive formal language and find that Transformers trained to perform\ntasks on top of strings from this language indeed exhibit emergent\ncapabilities. Specifically, we show that once the language's underlying grammar\nand context-sensitivity inducing structures are learned by the model,\nperformance on narrower tasks suddenly begins to improve. We then analogize our\nnetwork's learning dynamics with the process of percolation on a bipartite\ngraph, establishing a formal phase transition model that predicts the shift in\nthe point of emergence observed in experiment when changing the data structure.\nOverall, our experimental and theoretical frameworks yield a step towards\nbetter defining, characterizing, and predicting emergence in neural networks.",
        "updated": "2024-08-22 17:44:22 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.12578v1"
    },
    {
        "title": "MuMA-ToM: Multi-modal Multi-Agent Theory of Mind",
        "authors": "Haojun ShiSuyu YeXinyu FangChuanyang JinLayla IsikYen-Ling KuoTianmin Shu",
        "links": "http://arxiv.org/abs/2408.12574v1",
        "entry_id": "http://arxiv.org/abs/2408.12574v1",
        "pdf_url": "http://arxiv.org/pdf/2408.12574v1",
        "summary": "Understanding people's social interactions in complex real-world scenarios\noften relies on intricate mental reasoning. To truly understand how and why\npeople interact with one another, we must infer the underlying mental states\nthat give rise to the social interactions, i.e., Theory of Mind reasoning in\nmulti-agent interactions. Additionally, social interactions are often\nmulti-modal -- we can watch people's actions, hear their conversations, and/or\nread about their past behaviors. For AI systems to successfully and safely\ninteract with people in real-world environments, they also need to understand\npeople's mental states as well as their inferences about each other's mental\nstates based on multi-modal information about their interactions. For this, we\nintroduce MuMA-ToM, a Multi-modal Multi-Agent Theory of Mind benchmark.\nMuMA-ToM is the first multi-modal Theory of Mind benchmark that evaluates\nmental reasoning in embodied multi-agent interactions. In MuMA-ToM, we provide\nvideo and text descriptions of people's multi-modal behavior in realistic\nhousehold environments. Based on the context, we then ask questions about\npeople's goals, beliefs, and beliefs about others' goals. We validated MuMA-ToM\nin a human experiment and provided a human baseline. We also proposed a novel\nmulti-modal, multi-agent ToM model, LIMP (Language model-based Inverse\nMulti-agent Planning). Our experimental results show that LIMP significantly\noutperforms state-of-the-art methods, including large multi-modal models (e.g.,\nGPT-4o, Gemini-1.5 Pro) and a recent multi-modal ToM model, BIP-ALM.",
        "updated": "2024-08-22 17:41:45 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.12574v1"
    }
]