[
    {
        "title": "RuleAlign: Making Large Language Models Better Physicians with Diagnostic Rule Alignment",
        "authors": "Xiaohan WangXiaoyan YangYuqi ZhuYue ShenJian WangPeng WeiLei LiangJinjie GuHuajun ChenNingyu Zhang",
        "links": "http://arxiv.org/abs/2408.12579v1",
        "entry_id": "http://arxiv.org/abs/2408.12579v1",
        "pdf_url": "http://arxiv.org/pdf/2408.12579v1",
        "summary": "Large Language Models (LLMs) like GPT-4, MedPaLM-2, and Med-Gemini achieve\nperformance competitively with human experts across various medical benchmarks.\nHowever, they still face challenges in making professional diagnoses akin to\nphysicians, particularly in efficiently gathering patient information and\nreasoning the final diagnosis. To this end, we introduce the RuleAlign\nframework, designed to align LLMs with specific diagnostic rules. We develop a\nmedical dialogue dataset comprising rule-based communications between patients\nand physicians and design an alignment learning approach through preference\nlearning. Experimental results demonstrate the effectiveness of the proposed\napproach. We hope that our work can serve as an inspiration for exploring the\npotential of LLMs as AI physicians.",
        "updated": "2024-08-22 17:44:40 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.12579v1"
    },
    {
        "title": "WhisperMask: A Noise Suppressive Mask-Type Microphone for Whisper Speech",
        "authors": "Hirotaka HirakiShusuke KanazawaTakahiro MiuraManabu YoshidaMasaaki MochimaruJun Rekimoto",
        "links": "http://dx.doi.org/10.1145/3652920.3652925",
        "entry_id": "http://arxiv.org/abs/2408.12500v1",
        "pdf_url": "http://arxiv.org/pdf/2408.12500v1",
        "summary": "Whispering is a common privacy-preserving technique in voice-based\ninteractions, but its effectiveness is limited in noisy environments. In\nconventional hardware- and software-based noise reduction approaches, isolating\nwhispered speech from ambient noise and other speech sounds remains a\nchallenge. We thus propose WhisperMask, a mask-type microphone featuring a\nlarge diaphragm with low sensitivity, making the wearer's voice significantly\nlouder than the background noise. We evaluated WhisperMask using three key\nmetrics: signal-to-noise ratio, quality of recorded voices, and speech\nrecognition rate. Across all metrics, WhisperMask consistently outperformed\ntraditional noise-suppressing microphones and software-based solutions.\nNotably, WhisperMask showed a 30% higher recognition accuracy for whispered\nspeech recorded in an environment with 80 dB background noise compared with the\npin microphone and earbuds. Furthermore, while a denoiser decreased the\nwhispered speech recognition rate of these two microphones by approximately 20%\nat 30-60 dB noise, WhisperMask maintained a high performance even without\ndenoising, surpassing the other microphones' performances by a significant\nmargin.WhisperMask's design renders the wearer's voice as the dominant input\nand effectively suppresses background noise without relying on signal\nprocessing. This device allows for reliable voice interactions, such as phone\ncalls and voice commands, in a wide range of noisy real-world scenarios while\npreserving user privacy.",
        "updated": "2024-08-22 15:51:07 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.12500v1"
    },
    {
        "title": "Smartphone-based Eye Tracking System using Edge Intelligence and Model Optimisation",
        "authors": "Nishan GunawardenaGough Yumu LuiJeewani Anupama GinigeBahman Javadi",
        "links": "http://arxiv.org/abs/2408.12463v1",
        "entry_id": "http://arxiv.org/abs/2408.12463v1",
        "pdf_url": "http://arxiv.org/pdf/2408.12463v1",
        "summary": "A significant limitation of current smartphone-based eye-tracking algorithms\nis their low accuracy when applied to video-type visual stimuli, as they are\ntypically trained on static images. Also, the increasing demand for real-time\ninteractive applications like games, VR, and AR on smartphones requires\novercoming the limitations posed by resource constraints such as limited\ncomputational power, battery life, and network bandwidth. Therefore, we\ndeveloped two new smartphone eye-tracking techniques for video-type visuals by\ncombining Convolutional Neural Networks (CNN) with two different Recurrent\nNeural Networks (RNN), namely Long Short Term Memory (LSTM) and Gated Recurrent\nUnit (GRU). Our CNN+LSTM and CNN+GRU models achieved an average Root Mean\nSquare Error of 0.955cm and 1.091cm, respectively. To address the computational\nconstraints of smartphones, we developed an edge intelligence architecture to\nenhance the performance of smartphone-based eye tracking. We applied various\noptimisation methods like quantisation and pruning to deep learning models for\nbetter energy, CPU, and memory usage on edge devices, focusing on real-time\nprocessing. Using model quantisation, the model inference time in the CNN+LSTM\nand CNN+GRU models was reduced by 21.72% and 19.50%, respectively, on edge\ndevices.",
        "updated": "2024-08-22 15:04:59 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.12463v1"
    },
    {
        "title": "VR4UrbanDev: An Immersive Virtual Reality Experience for Energy Data Visualization",
        "authors": "Saeed SafikhaniGeorg Arbesser-RastburgAnna SchreuerJürgen Suschek-BergerHermann EdtmayerJohanna Pirker",
        "links": "http://arxiv.org/abs/2408.12428v1",
        "entry_id": "http://arxiv.org/abs/2408.12428v1",
        "pdf_url": "http://arxiv.org/pdf/2408.12428v1",
        "summary": "In this demonstration paper, we present our interactive virtual reality (VR)\nexperience, which has been designed to facilitate interaction with\nenergy-related information. This experience consists of two main modes: the\nworld in miniature for large-scale and first-person for real-world scale\nvisualizations. Additionally, we presented our approach to potential target\ngroups in interviews. The results of these interviews can help developers for\nfuture implementation considering the requirements of each group.",
        "updated": "2024-08-22 14:22:05 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.12428v1"
    },
    {
        "title": "Enhancing Uncertainty Communication in Time Series Predictions: Insights and Recommendations",
        "authors": "Apoorva KaragappaPawandeep Kaur BetzJonas GilgMoritz ZeumerAndreas GerndtBernhard Preim",
        "links": "http://arxiv.org/abs/2408.12365v1",
        "entry_id": "http://arxiv.org/abs/2408.12365v1",
        "pdf_url": "http://arxiv.org/pdf/2408.12365v1",
        "summary": "As the world increasingly relies on mathematical models for forecasts in\ndifferent areas, effective communication of uncertainty in time series\npredictions is important for informed decision making. This study explores how\nusers estimate probabilistic uncertainty in time series predictions under\ndifferent variants of line charts depicting uncertainty. It examines the role\nof individual characteristics and the influence of user-reported metrics on\nuncertainty estimations. By addressing these aspects, this paper aims to\nenhance the understanding of uncertainty visualization and for improving\ncommunication in time series forecast visualizations and the design of\nprediction data dashboards.As the world increasingly relies on mathematical\nmodels for forecasts in different areas, effective communication of uncertainty\nin time series predictions is important for informed decision making. This\nstudy explores how users estimate probabilistic uncertainty in time series\npredictions under different variants of line charts depicting uncertainty. It\nexamines the role of individual characteristics and the influence of\nuser-reported metrics on uncertainty estimations. By addressing these aspects,\nthis paper aims to enhance the understanding of uncertainty visualization and\nfor improving communication in time series forecast visualizations and the\ndesign of prediction data dashboards.",
        "updated": "2024-08-22 13:03:55 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.12365v1"
    }
]