Position Paper: Rethinking Empirical Research in Machine Learning:
Addressing Epistemic and Methodological Challenges of Experimentation
MoritzHerrmann12 F.JulianD.Lange12 KatharinaEggensperger3 GiuseppeCasalicchio42 MarcelWever52
MatthiasFeurer42 DavidRu¨gamer42 EykeHu¨llermeier52 Anne-LaureBoulesteix12 BerndBischl42
Abstract consequences. Fromanepistemological∗ pointofview,it
meansthatresearchresultsareunreliableand,tosomeex-
We warn against a common but incomplete un-
tent,itcallsintoquestionprogressinthefield. Inpractice,
derstanding of empirical research in machine
itmayjeopardizeappliedempiricalresearchers’confidence
learning(ML)thatleadstonon-replicableresults,
inexperimentalresultsanddiscouragethemfromapplying makes findings unreliable, and threatens to un-
ML methods, although these novel approaches might be
dermineprogressinthefield. Toovercomethis
beneficial. Forexample,MLisincreasinglybeingusedin
alarmingsituation,wecallformoreawarenessof
themedicaldomain,andthisisoftenpromisingintermsof
thepluralityofwaysofgainingknowledgeexper-
patientbenefit. However,therearealsoexamplesindicating
imentallybutalsoofsomeepistemiclimitations.
thatappliedresearchers(arestartingto)haveconcernsabout Inparticular,wearguemostcurrentempiricalML
MLbeingusedinthishigh-stakesarea. Considerthequite
research is fashioned as confirmatory research
drastic warning by Dhiman et al. (2022, p. 2): “Machine
whileitshouldratherbeconsideredexploratory.
learningisoftenportrayedasofferingmanyadvantages[...].
However,theseadvantageshavenotyetmaterialisedinto
1.TheNon-ReplicableMLResearchEnigma patientbenefit[...]. Giventheincreasingconcernaboutthe
methodologicalqualityandriskofbiasofpredictionmodel
RichardFeynman(1974)describedinhis1974Caltechcom- studies[emphasisadded],cautioniswarrantedandthelack
mencementaddress,CargoCultScience∗1,practicesused
ofuptakeofmodelsinmedicalpracticeisnotsurprising.”
byresearcherstoadheretoacertainwayofdoingthings
That is, if the ML community does not improve rigor in
butwhichhebelievedwerecontrarytoscientificprinciples.
empiricalmethodologicalresearch,wethinktheremaybea
Inessence,thispaperwarnsagainstasimilartendencyin
riskofabacklashagainsttheuseofML.
currentempiricalMLanddiscussespotentialsolutions.
Ingeneral,thereisagrowingbodyofempiricalevidence
ThereisMLresearchthatdoesnotreplicate. Froman
showingthatconclusionsdrawnfromexperimentalresults
empiricalscientificperspective,non-replicableresearchisa
inMLwereoverlyoptimisticatthetimeofpublicationand
fundamentalproblem. AsKarlPopper(1959/2002,p.66)
couldnotbereplicatedinsubsequentstudies. Forexample,
phrasedit: “non-reproduciblesingleoccurrencesareofno
Melisetal.(2018,p.1)“arriveatthesomewhatsurprising
significancetoscience.”2 Consequently,MLresearchthat
conclusionthatstandardLSTMarchitectures,whenproperly
doesnotreplicatehasfar-reachingepistemic∗andpractical
regularized,outperformmorerecentmodels”;Henderson
etal.(2018,p.3213)foundfordeepreinforcementlearn-
1InstituteforMedicalInformationProcessing,Biometry,and
Epidemiology, Faculty of Medicine, LMU Munich, Munich, ing “that both intrinsic (e.g. random seeds, environment
Germany2MunichCenterforMachineLearning(MCML),Mu- properties) and extrinsic sources (e.g. hyperparameters,
nich, Germany 3University of Tu¨bingen, Tu¨bingen, Germany codebases)ofnon-determinismcancontributetodifficulties
4Department of Statistics, LMU Munich, Munich, Germany
in reproducing baseline algorithms”; Christodoulou et al.
5InstituteofInformatics,LMUMunich,Munich,Germany.Corre-
(2019,p.12)foundinasystematicreview“noperformance
spondenceto:MoritzHerrmann<moritz.herrmann@lmu.de>.
benefitofmachinelearningoverlogisticregressionforclin-
Proceedings of the 41st International Conference on Machine icalpredictionmodels”;Elor&Averbuch-Elor(2022,p.1)
Learning,Vienna,Austria.PMLR235,2024.Copyright2024by foundintheirstudyondatabalancinginclassification“that
theauthor(s).
balancingdoesnotimprovepredictionperformanceforthe
1Asourpaperissomewhatjargonheavy, wedecidedtoex-
strong”classifiers;seealsoLucicetal.(2018),Riquelme
plainterminologyinaglossaryintheappendix,withasuperscript
et al. (2018), Raff (2019), Herrmann et al. (2020), Fer-
asterisk(∗)indicatingsuchentries.
2Reproducibleheredoesnotrefertoexactcomputationalre- rari Dacrema et al. (2021), Marie et al. (2021), Buchka
producibility∗butgenerallytoarrivingatthesamescientificcon- etal.(2021),Narangetal.(2021),vandenGoorberghetal.
clusions,termedreplicability∗inthispaper.
1
4202
yaM
3
]GL.sc[
1v00220.5042:viXraRethinkingEmpiricalResearchinMachineLearning
(2022), Mateus et al. (2023), McElfresh et al. (2023), or improve their performance by interacting with their envi-
thesurveysbyLiaoetal.(2021)andKapoor&Narayanan ronment. Lastly,andespeciallyconcerningexperimentation
(2023)forsimilarfindings. Inconcreteterms,thismeans: inML,thereexistsanappliedstatisticalperspectivewitha
thereispublishedMLresearchthatis“ofnosignificanceto focusonthoroughinductivereasoning. Withitstraditionin
science”,butwedonotknowhowmuch! dataanalysisanddesignofexperiments,itemphasizesthe
Wehavebeenwarned;don’twelisten? Wearebyno empiricalaspectsofMLresearch.
meansthefirsttoraisetheseandrelatedissues,andthevery Thesedifferentperspectives,withtheirspecificobjectives,
factthatwearenotthefirstisamatterofevengravercon- methodology, andterminology, havetheiruniquevirtues,
cern. WethinkthatempiricalresearchinMLfindsitselfin but they also have their blind spots. The formal science
asituationwherepracticingquestionableresearchpractices, perspectiveaimsatprovidingabsolutecertaintyanddeepin-
suchasstate-of-the-art-hacking(SOTA-hacking;Gencoglu sightsthroughthedefinitionofabstractconceptsandmathe-
etal.,2019;Hullmanetal.,2022),hassometimesbecome maticalproofsbutisoftennotwellsuitedtoexplaincomplex
more rewarding than following the long line of literature real-worldphenomena,astheseconceptsandproofsvery
warningagainstit. LangleywroteaneditorialonMachine oftenhavetobebasedonstronglysimplifyingassumptions.
LearningasanExperimentalScienceasearlyas1988,and Theengineeringperspectivebroughtusincredibleapplica-
DrummondandHandpointedoutproblemswithexperimen- tionimprovements,butatthesametime,notallconducted
talmethodcomparisoninMLalreadyin2006. Apartfrom experiments are optimally designed to generalize results
thesespecificexamples,thereisarangeofliteratureoverthe beyondthespecificapplicationcontext(whichisalsooften
lastdecadesdealingwithsimilarissues(e.g.,Hooker,1995; onlyimplicitlydefined),asthereferencesprovidedatthe
McGeoch,2002;Johnson,2002;Drummond,2009;Drum- beginningdemonstrate.
mond & Japkowicz, 2010; Mannarswamy & Roy, 2018; A statistical perspective, which we adopt here, is very
Sculleyetal.,2018;Lipton&Steinhardt,2018;Bouthillier sensitive to such empirical issues – explaining/analyzing
etal.,2019;Liaoetal.,2021;D’Amouretal.,2022;Raff real-worldphenomenaandgeneralizingbeyondaspecific
&Farris,2022;Lones,2023;Trosten,2023). Specifically context(inductivereasoning)–andthusparticularlysuited
relevantisthepaperbyNakkiran&Belkin(2022,p.2),in toexplain1)whyMLisfacedwithnon-replicableresearch,
which they note a “perceived lack of legitimacy and real and2)howamorecompleteandnuancedunderstandingof
lack of community for good experimental science” (still) empiricalresearchinMLcanhelptoovercomethissituation.
exists. Ifwecontinuenottotakethesewarningsseriously WithempiricalMLwethusmeaninabroadsensethesys-
theamountofnon-replicableresearchwillonlycontinueto tematicinvestigationofMLalgorithms,techniques,andcon-
increase,asthecitedveryrecentempiricalfindingsindicate. ceptualquestionsthroughsimulations,experimentation,and
Wedonotbelievethatdeliberateactionsonthepartofindi- observation. Itdealswithrealobjects: implementationsof
vidualshaveledtothissituationbutthatthereisageneral algorithms–whichareusuallymorecomplexthantheirthe-
unawarenessofthefactthat,while“follow[ing]alltheappar- oreticalcounterparts(e.g.,Kriegeletal.,2017)–runningon
entpreceptsandformsofscientificinvestigation[inML],” physicalcomputers;datagatheredandproduced/simulated
onecanbe“missingsomethingessential.”Inparticular,this intherealworld;andtheirinterplay. Ratherthanfocusing
includes that “if you’re doing an experiment, you should solelyontheoreticalanalysisandproofs,empiricalresearch
reporteverythingthatyouthinkmightmakeitinvalid—not emphasizes practical evaluations using real-world and/or
onlywhatyouthinkisrightaboutit: othercausesthatcould syntheticdata. EmpiricalML,asunderstoodhere,requires
possiblyexplainyourresults;andthingsyouthoughtofthat amindsetverydifferentfromengineeringandformalsci-
you’veeliminatedbysomeotherexperiment,andhowthey encesandadifferentapproachtomethodologytoallowfor
worked”(quotesfromFeynman,1974,p.11). Misaligned thefullincorporationoftheuncertaintiesinherentindealing
incentivesandpressuretopublishpositiveresultscontribute withreal-worldentitiesinexperiments.
tothissituation(e.g.,Smaldino&McElreath,2016). Inourview,thediscussedliterature,raisingsimilarpoints,
Oneofakind?Attheintersectionofformalandempiri- hastwomainshortcomings: 1)theyaddressonlyspecific
calsciences. Webelievethatoneofthemainreasonsfor aspectsoftheproblemanddonotprovideacomprehensive
thisisthatMLstands,likefewotherdisciplines,attheinter- picture;2)thereisaconfusionofterminology. Forexample,
facebetweenformalsciencesandreal-worldapplications. Bouthillieretal.(2019)distinguishbetween“exploratory”
BecauseMLhasstrongfoundationsinformalsciencessuch and“empirical”research.Nakkiran&Belkin(2022)usethe
asmathematics,(theoretical)computerscience(CS),and term“goodexperimentalresearch”andcontrastitinparticu-
mathematical statistics, many ML researchers are accus- larwith“improvingapplications”. Sculleyetal.(2018)talk
tomedtoreasoningmathematicallyaboutabstractobjects about“empiricaladvancements”and“empiricalanalysis”
–MLmethods–usingformalproofs. Ontheotherhand, thatarenotcomplementedbysufficient“empiricalrigor”.
MLcanalsoverymuchbeconsidereda(software)engineer- AndDrummond(2006)discussesMLasan“experimental
ingscience,tocreatepracticalsystemsthatcanlearnand science”hardlyusingtheterm“empirical”atall.
2RethinkingEmpiricalResearchinMachineLearning
Toovercometheseissues,wegatheropinionsand(empir- [emphasisadded]butmaybeimportantinthefuture.”This
ical)evidencescatteredacrosstheliteratureanddifferent isexpressedinthetalkintroducingTMLR3too. Judgingby
domainsandtrytodevelopacomprehensivesynthesis.For theexampleofotherempiricalsciences,thisgenerallack
example,similarproblemshavebeendiscussedinbioinfor- ofawarenessofproperempiricalMLiscertainlythemost
maticsforsometime(e.g.,Yousefietal.,2010;Boulesteix, difficultthingtoovercome. Belowwediscussproblemswe
2010). Wealsotakeintoaccountliteraturefromother,more identifiedassymptomsofthislack.
distantfieldsfacingrelatedissues,suchaspsychologyand
Problem1: Lackofunbiasedexperimentsandscrutiny.
medicine. Webelievethiscomprehensivepicturewillallow
Mostmethodcomparisonsarecarriedoutaspartofapaper
forabroaderanddeeperunderstandingofthecomplexityof
introducinganewmethodandareusuallybiasedinfavorof
thesituation,whichmayatfirstglanceappeartoberather
thenewmethod(seeSection1forexamples).
easytosolve,e.g.,bymore(rigorous)statisticalmachinery
Sculleyetal.(2018,p.1)foundthat“[l]ookingoverpapers
or more open research artifacts. It is our conviction that
fromthelastyear,thereseemstobeacleartrendofmultiple
withoutthisdeeperunderstanding,asituationthathasbeen
groups finding that prior work in fast moving fields may
warnedaboutinvainforsolongcannotbeovercome.
havemissedimprovementsorkeyinsightsduetothingsas
simpleashyperparametertuningstudies[∗]orablationstud-
2.TheStatusQuoofEmpiricalML ies.”Moreover,foraneutralmethodcomparisonstudyof
survivalpredictionmethods,ithasbeenshownthatmethod
Recentadvances. Itisimportanttoemphasizethatthere
rankings can vary considerably depending on design and
havebeenencouragingfirststepsintermsofempiricalML
analysischoicesmadeatthemeta-level(e.g.,theselected
researchrecently. Thisincludesthenewlycreatedpublica-
set of datasets, performance metric, aggregation method)
tionformatsTransactionsonMachineLearningResearch
andthatanymethod–evenasimplebaseline–canachieve
(TMLR), Journal of Data-centric Machine Learning Re-
almostanyrank(Nießletal.,2022;seealsoSonabendetal.,
search(DMLR),ortheNeurIPSDatasetsandBenchmarks
2022). Weareconvincedthatitisnotfar-fetchedtocon-
Tracklaunchedin2021. Thesevenuesexplicitlyincludein
cludethatquiteoftenresultsdemonstratingthesuperiority
theirscope,e.g.,“reproducibilitystudiesofpreviouslypub-
ofanewlyproposedmethodareobtainedbyanexperimen-
lishedresultsorclaims”(TMLR,n.d.),“systematicanalyses
taldesignfavorabletothatmethod.
ofexistingsystemsonnoveldatasetsorbenchmarksthat
Asinotherdisciplines(Munafo` etal.,2017),therearestruc-
yieldimportantnewinsight”(DMLR,n.d.),and“system-
turalissues(e.g.,publicationbias,pressuretopublish,lack
aticanalysesofexistingsystemsonnoveldatasetsyielding
ofreplicationstudies)andquestionablepractices(e.g.,Hy-
importantnewinsight”(NeurIPS,n.d.). Furtherexamples
pothesizingAftertheResultsareKnown[HARKing,Kerr,
are the I Can’t Believe It’s Not Better! (ICBINB) Work-
1998] and p-hacking [Simonsohn et al., 2014]) that con-
shop Series (e.g., Forde et al., 2020) and Repository of
tributetothislackofunbiasedexperimentsandscrutiny. At
UnexpectedNegativeResults(ICBINBInitiative,n.d.) and
theindividuallevel,inparticular,thereisalackofawareness
efforts towards preregistration (e.g., Albanie et al., 2021)
thatmethodcomparisonsperformedaspartofapaperin-
andreproducibility(e.g.,Sinhaetal.,2023). Thesedevel-
troducinganewmethodarenotwellsuitedtodrawreliable
opments, while very important, are not sufficient in our
conclusions about a method beyond the datasets consid-
view to overcome the problems empirical ML faces. For
ered,especiallyif1)thenumberofdatasetsconsideredis
example, while computational reproducibility∗ may be a
small(Dehghanietal.,2021;Kochetal.,2021),2)thereis
necessarycondition,itisnotasufficientconditionforrepli-
meta-leveloverfittingonasinglebenchmarkdesign(Recht
cability(e.g.,Bouthillieretal.,2019). Furthermore,while
et al., 2019; Beyer et al., 2020), 3) the set of datasets se-
the topics in the above formats cover many important as-
lectedfortheexperimentsisbiasedinfavorofthenewly
pectsofempiricalML,wefeelthattheydonotemphasize
proposedmethod,and4)theauthorsaremuchmorefamiliar
enoughtheimportanceoftruereplicationofresearch,which
withthenewmethodthanwithitscompetitors,asisthecase
isparamountfromanempiricalperspective. Mostimpor-
frequently(Johnson,2002;Boulesteixetal.,2013;2017).
tantly,asituationinwhichalineofresearchwarningusfor
Furthermore,itisveryeasytoartificiallymakeamethodap-
alongtimehasbeenlargelyneglectedwillnotbeovercome
pearsuperior(e.g.,Jelizarowetal.,2010;Noreletal.,2011;
bysuchpracticalchangesalone. Italsorequiresachangein
Nießletal.,2022;Ullmannetal.,2023;Paweletal.,2024;
awareness–oftheimportanceofproperempiricalMLbut
Nießl et al., 2024), and publication bias towards positive
maybeevenmoreofitslimitations;andthattherearedif-
resultsisastrongincentivetoengageinSOTA-hackingand
ferent,equallyvalidtypesofproperempiricalinquiry. We
demonstrate the superiority of a newly proposed method
seethislackofawarenessevidencedbyTMLR(n.d.) itself:
(Sculleyetal.,2018;Gencogluetal.,2019).
“TMLRemphasizestechnicalcorrectnessoversubjective
significance,toensurethatwefacilitatescientificdiscourse 3TMLR-ANewOpenJournalForMachineLearning:https:
ontopicsthatmaynotyetbeacceptedinmainstreamvenues //youtu.be/Uc1r1LfJtds
3RethinkingEmpiricalResearchinMachineLearning
At the system level there is a publication bias and a lack tobe‘won’,ratherthanaprocessfordevelopinginsightand
ofreplicationandneutralmethodcomparisonstudies(e.g., understanding. Ideally,thebenefitofworkingwithrealdata
Boulesteixetal.,2013;2015b). Sculleyetal.(2018,p.1) istotuneandexaminethebehaviorofanalgorithmunder
“observethattherateofempiricaladvancement[largerand varioussamplingdistributions,tolearnaboutthestrengths
morecomplexexperiments]maynothavebeenmatchedby andweaknessesofthealgorithms,asonewoulddoincon-
consistentincreaseinthelevelofempiricalrigoracrossthe trolled studies.” And Rendsburg et al. (2020, p. 9) argue,
fieldasawhole.”Inunsupervisedlearning,theproblemis “itisparticularlyimportantthatourcommunityactivelyat-
morepronouncedthaninsupervisedlearningbecause“there temptstounderstandtheinherentinductivebiases,strengths,
ismuchlessofabenchmarkingtraditionintheclustering andalsotheweaknessesofalgorithms. Findingexamples
areathaninthefieldofsupervisedlearning”(VanMechelen whereanalgorithmworksisimportant–butmaybeeven
etal.,2023,p.2;seealsoZimmermann,2020). moreimportantistounderstandunderwhichcircumstances
thealgorithmproducesmisleadingresults.”
Problem2: Lackoflegitimacy. Thesecondproblem
highlightsaspecificaspectofthelackofawarenessofhow Problem3: Lackofconceptualclarityandoperational-
differenttypesofempiricalresearchcancontributetoML. ization. Thereisaperceivedlackofclarityaboutsomeim-
TheproblemwasaddressedbyNakkiran&Belkin(2022) portantabstractconceptsthataretheobjectsofMLresearch
andwecompletelyagreewiththeirdescription: on the one side and a lack of clear operationalization∗ in
“InmainstreamMLvenues,thereisaperceivedlackoflegit- empiricalinvestigationsontheotherside. Bothaspectsaf-
imacyandareallackofcommunityforgoodexperimental fectthevalidityofexperimentsinempiricalML.
science–whichneitherprovesatheoremnorimprovesan This problem is the most complex one and probably for
application. This effectively suppresses a mode of scien- that reason the most difficult to describe in precise terms
tificinquirywhichhashistoricallybeencriticaltoscientific (cf.Saitta&Neri,1998). However,sincewethinkthatthis
progress,andwhichhasshownpromiseinbothMLandin problemaffectsthevalidityofempiricalresearchinMLin
CSmoregenerally”(Nakkiran&Belkin,2022,p.2). afundamentalway,anaccountofempiricalMLthatdoes
Apparently,theyidentifyastrongbiasoftheMLcommunity notattempttomakeittangiblewouldbeincomplete. We
towardsmathematicalproofs(formalscienceperspective) aimtonarrowdowntheproblembyexplicatingexamples
and application improvements (engineering perspective), forsupervisedlearningandunsupervisedlearning.
while“goodexperimentalscience”thatdoesnotfocuson Inothersciencessuchaspsychologyandphysics,validity∗,
oneoftheaboveisnotincentivizednorencouraged. Nakki- thefactthattheexperimentalmeasurementprocessactually
ran&Belkin(2022)seethisevidencedbythelackofspe- measureswhatitisintendedtomeasure,isfundamental. It
cificsubjectareas,theexclusionfromrecentcallsforpapers, inevitablydependsonastrictandthoroughoperationaliza-
thelackofexplicitguidelinesforreviewers,andtheorga- tioninwhatwayabstractconceptsthataretobemeasured
nizationofseparateworkshopsonexperimentalscientific relate to measurable entities in the real world. Note that
investigation at major ML conferences. In particular, re- “[o]perational analysis is an excellent diagnostic tool for
viewers“oftenaskforapplicationimprovements”and“for revealingwhereourknowledgeisweak,inordertoguide
‘theoretical justification’ for purely experimental papers” oureffortstostrengtheningit. TheBridgmanianideal[∗]is
(Nakkiran&Belkin,2022,p.2-3). Togetherthesefactors alwaystobackupconceptswithoperationaldefinitions,that
pointtoastructuralproblemhinderingtherecognitionand is,toensurethateveryconceptisindependentlymeasurable
promotionofsomesortsofexperimentalresearchinML. ineverycircumstanceunderwhichitisused”(Chang,2004,
We completely agree with this view but think it may not p.147). Itispuzzlingthatvalidityandotherqualitycriteria
immediatelybeclearwhatdistinguishesimprovinganap- ofempiricalresearchhavegainedlittleattentioninMLso
plicationfrom“goodexperimentalscience”atfirstsight.4 far(e.g.,Myrtveitetal.,2005;Segebarthetal.,2020;Raji
Asweunderstandit,thefocusonapplicationimprovement etal.,2021).
meansthatmuchempirical/experimentalresearchinMLfo- Experimentalvalidityinsupervisedlearning. Forsu-
cusesondevelopinganewmethodanddemonstratingthatit pervisedlearning, theproblemcanbeexemplifiedbythe
issuperiortoexistingmethodsbyimprovingsome(predic- questionofinferencefromexperimentalresultsonrealdata
tive)performancemetriconspecificreal-worldbenchmark inmethodcomparisonandevaluationstudies.5 Typically,
datasets.“Goodexperimentalscience”,ontheotherhand,is thegoalistogeneralizetheobservedperformancediffer-
notaboutimprovingperformance. Itisaboutimprovingun- encebetweenmethodstodatasetsthatwerenotincludedin
derstandingandknowledgeofaproblem,a(classof)meth- astudy,whichwouldrequirespecifyingwhendatasetsare
ods,oraphenomenon. Sculleyetal.(2018,p.2)emphasize fromthesame/differentdomain.Theproblemisthatitisnot
that“[e]mpiricalstudies[inML]havebecomechallenges
5Anotherexampleindependentlyaffectingvalidityisunder-
4Toavoidmisunderstandings: wedoconsidermathematical specification,which“iscommoninmodernMLpipelines,suchas
proofsandapplicationimprovementsveryvaluableresearch! thosebasedondeeplearning”(D’Amouretal.,2022,p.2).
4RethinkingEmpiricalResearchinMachineLearning
atallclearinwhatsenseresultsobtainedfromonesetofreal senseoutlinedabove,biasedexperimentstendtomakethis
datasetscanbegeneralizedtoanyothersetofdatasets,as more difficult. These aspects are becoming specifically
thiswouldrequireaclearunderstandingofthedistribution importantindeeplearningwherethesheercomplexityof
ofthedata-generatingprocessesbywhicheachdatasetis today’s models, especially of foundation models, makes
generated(e.g.,Aha,1992;Salzberg,1997;Boulesteixetal., mathematicalanalysisextremelydifficult. Instead,theanal-
2015a;Herrmann,2022;Strobl&Leisch,2024). Without ysisoftenneedstobelargelyexperimentalandthusrequires
adefinitionofthepopulationofdata-generatingprocesses, thoroughexperimentationatthehighestpossiblelevel.
i.e.,(some)clarityaboutanabstractconcept,itcanbear-
guedthatitisnotclearwhatarealdatacomparisonstudy
3.ImprovingtheStatusQuo: MoreRichness
actuallymeasures. Inotherwords,thecollectionofdatasets
inEmpiricalMethodologicalResearch
considered“willnotberepresentativeofrealdatasetsinany
formalsense”(Hand,2006,p.12). Dietterich(1998,p.4) Aunifyingview: Weneedexploratoryandconfirmatory.
evenwentsofarasclaimingthathowtoperformbenchmark Confirmatoryresearch∗,alsoknownashypothesis-testing
experimentsonrealdatasetsproperlyis“perhapsthemost research,aimstotestpreexistinghypothesestoconfirmor
fundamentalanddifficultquestioninmachinelearning.” refuteexistingtheories. Researchersdesignspecificstudies
Experimental validity in unsupervised learning. Ar- to evaluate hypotheses derived from existing knowledge
guably,thesituationisevenmoreinvolvedinunsupervised experimentally. Typically,thisinvolvesastructuredandpre-
learning(e.g.,Kleinberg,2002;vonLuxburgetal.,2012; definedresearchdesign,apriorihypotheses,andoftensta-
Zimek&Filzmoser,2018;Herrmann,2022). Firstofall, tisticalanalysestodrawconclusiveinferences. Incontrast,
“thereisno[...] directmeasureofsuccess. Itisdifficultto exploratoryresearchisanopen-endedapproachthataims
ascertainthevalidityofinferencesdrawnfromtheoutput togaininsightandunderstandinginaneworunexplored
of most unsupervised learning algorithms” (Hastie et al., area. Itisoftenconductedwhenlittleisknownaboutthe
2009,p.487). Thisisaggravatedbyanambiguityaboutthe phenomenonunderstudy. Itinvolvesgatheringinformation,
abstractconceptsofinterest. Consider,forexample,cluster identifying patterns, and formulating specific hypotheses
analysis.6 Usually,clustersareconceptualizedasthemodes for further investigation. One of our main points is that
ofamixtureof(normal)distributions. However,thereisa toimproveempiricalMLtowardsmorethorough,reliable,
differentperspectivethatconsidersclusteranalysisfroma andinsightfulmethodologicalresearchbothexploratoryand
topologicalperspectiveandconceptualizesclustersasthe confirmatoryresearchareneededinML(cf.Tukey,1980).
connectedcomponentsofadataset(Niyogietal.,2011). It In general, the problems described can be placed in this
isnotclearifthesedifferentnotionsofclusters1)concep- broaderepistemic context. Wearguethatmostempirical
tualizeclustersequallywell,2)canberelatedtothesame researchinMLisperceivedasconfirmatoryresearch,when
real-worldentities,and3)whetherclusteringmethodsde- it should rather be considered to be exploratory from an
velopedbasedonthesedifferentnotionsareequallysuitable epistemicperspective(seealsoBouthillieretal.,2019). At
for all clustering problems. There is some evidence that thesametime,purelyexploratorymethodologicalresearch
suggeststhisisnotthecase(Herrmannetal.,2023a). focusing on improving insight and understanding experi-
mentally (cf. Dietterich, 1990) and research like neutral
Problemsummary. WearguethatmuchempiricalMLre-
methodcomparisonandreplicationstudies,whichcanbe
searchispronetooverlyoptimistic,unreliable,anddifficult-
consideredmorerigorousintheconfirmatorysense,arenot
to-refute judgments and conclusions. Many experiments
seenasanequallyimportantcontributiontothefield.
inempiricalMLresearcharebasedoninsufficientlyopera-
Forthetimebeing,itisworthmakingthisdistinction,yet,
tionalizedexperimentalsetups,partiallyduetoambiguous
we discuss why it is an oversimplification from an epis-
andinconclusiveconceptualizationsunderlyingtheexperi-
temicperspectiveinSection4–evenmoreso,becausewe
ments. Todrawmorereliableconclusions,weneedmore
distinguishtwotypesofexploratoryempiricalmethodologi-
explicit,context-specificoperationalizationsandclearerde-
calresearchinthefollowing:7 insight-orientedexploratory
lineationsoftheabstractconceptsthataretobeinvestigated.
research∗incontrasttomethod-developingexploratoryre-
Recallthat“[o]perationalanalysisisanexcellentdiagnostic
search∗. We think insight-oriented exploratory research
toolforrevealingwhereourknowledgeisweak,inorderto
iswhatNakkiran&Belkin(2022)meanby“goodexperi-
guideoureffortsinstrengtheningit”(Chang,2004,p.147).
mentalresearch”,andwhattheymeanby“applicationim-
Thatsometimes“goodexperimentalresearch”isnotencour-
provements”isaconflationofbothmethod-developingex-
agedenoughinML(seeProblem2)andbiasedexperiments
ploratoryand(supposedly)confirmatoryresearch.
stilloccurmoreoftenthandesirable(seeProblem1),exacer-
batesthesituationconsiderably. Theformerisanexcellent
approach for improving insight and understanding in the
7Itisnotourintentiontoestablishapreciseterminology,but
6SeealsoHerrmannetal.(2023b)foroutlierdetection.
wethinkthisstructurewillbeofassistancetothereader.
5RethinkingEmpiricalResearchinMachineLearning
More insight-oriented exploratory research. In prin- methodsunderconsideration(Boulesteixetal.,2013). Such
ciple,thegoodthingaboutmovingtowardsmoreinsight- studiesensuremoreneutralityandarelesspronetooverly
orientedexploratorymethodologicalresearchinMListhat optimistic conclusions than studies proposing a method,
there are no epistemological obstacles to overcome. The sincethereismuchlessofanincentivetopromoteapartic-
neighboring field data mining and knowledge discovery ularmethod. Second,properuncertaintyquantificationis
clearlyhasanexploratorynatureandisverymuchinthe requiredwhenanalyzingempiricalresultsinML,especially
spiritofTukey’sexploratorydataanalysis. Therearealso w.r.t. thedifferentstagesofinference(e.g.,modelfitting,
alreadysomeexamplesofinfluentialMLresearchthatcan modelselection,pipelineconstructionandperformanceesti-
beconsideredinsight-orientedandexploratory,e.g.,Frankle mation)(seeNadeau&Bengio,2003;Bengio&Grandvalet,
&Carbin(2019),Belkinetal.(2019),Rechtetal.(2019), 2004;Hothornetal.,2005;Batesetal.,2023). Moreover,
Rendsburgetal.(2020),Zhangetal.(2021),orPoweretal. ifstatisticalsignificancetestingistobeconductedtotest
(2021). So,ratherthanepistemicaspects,itistheincentives forstatisticallysignificantperformancedifferencesacross
andattitudesinscientificpracticetowardsthistypeofre- differentreal-worlddatasets,asdescribed,e.g.,byDemsˇar
searchthatareanobstacletoitssuccessfuldissemination. (2006),Eugsteretal.(2012),Boulesteixetal.(2015a),or
Inparticular, anallegedlackofnoveltyandoriginalityis Eisingaetal.(2017),themethodologicalrigorestablished
ofteninvoked,whichleadstorejections. Yet,withoutthe inotherempiricaldomainsshouldbeapplied(Munafo` etal.,
esteemexpressedbyacceptanceforpublication,inpartic- 2017),inparticular,effortstowardspriorsamplesizecalcu-
ularinmajorMLvenues,thereissimplylittleincentiveto lationsareimportant(Boulesteixetal.,2017).
engageinexploratoryMLresearch. Moreimportantly, it Moreover, we need more replication studies and meta
reinforces the impression among students and young sci- studies. Thesetypesofresearchfacesimilarreservations
entists that exploratory research is not an integral part of asinsight-orientedexploratoryexperimentalresearch. How-
science. Itisthereforenecessarytostimulate,encourage, ever, replication studies are indispensable to assess the
and provide opportunities to make such research visible. amount of non-replicable research and to prevent it from
Nakkiran&Belkin(2022,pp.4-5)proposetoestablisha beingincreased. Suchstudiesattempttoreachthesamesci-
specialsubjectareawithinMLconferences,Experimental entificconclusionsaspreviousstudies,toprovideadditional
ScienceofMachineLearning,focusingon“experimentalin- empiricalevidenceforobservedphenomena. Metastudies
vestigationintothenatureoflearningandlearningsystems.” analyzeandsummarizethesoaccumulatedevidenceona
The types of papers outlined include those with “surpris- specificphenomenon. Thisprocessisthedefaulttoreach
ingexperiments,“empiricalconjectures,”“refiningexisting conclusionsinothersciencesandisimportantassinglestud-
phenomena,” “formalizing intuition,” and presentation of iescanbefalseand/orcontradicteachother. InML,thiscan
“newmeasurementtool[s],”allaimingtoimprovetheunder- rangefromstudiesthatattempttoreplicateanexperiment
standingofMLempirically. Theyalsoprovideguidelines exactly(e.g.,Lohmannetal.,2022)orslightlymodifyan
specificallytailoredtothereviewofthistypeofresearch. experiment’sdesign(e.g., byusingadifferentsetofdata
in the replication of a neutral comparison study) to more
More(actual)confirmatoryresearch. Asoutlined,we
comprehensivetuningandablationstudiesofexperiments
believemostcurrentempiricalMLresearch(“application
conductedinmethod-developingresearch(e.g.,Rendsburg
improvements”) is a mixture of method-developing ex-
et al., 2020; Kobak & Linderman, 2021). The latter cer-
ploratoryresearchand(supposedly)confirmatoryresearch.8
tainlyoverlapswithinsight-orientedexploratoryresearch.
Forthisreason,weaddafocusonwell-designed,neutral
Itisimportanttoemphasizethatitisinthenatureofthings
methodcomparisonandreplicationstudies. Thescrutiny
thatareplicationisnotanoriginalornovelscientificcon-
andrigortheseexamplesof(actual)confirmatoryempirical
tributionintheconventionalsense,andnotnecessarilycan
researchprovidearesorelyneededifwearetoworktoward
‘importantnewinsights’begainedbeyondthereplicationof
morereliableandreplicableresearch.
previouslyobservedresults. Rather,itisanexplicitattempt
Neutralmethodcomparisonstudiesincludeexperiments
toarriveatthesameresultsandconclusionsasaprevious
that are less biased in favor of newly proposed methods
study. Thescientificrelevance,whichiswellacknowledged
(Boulesteixetal.,2013;Limetal.,2000;Ali&Smith,2006;
inotherempiricalsciencessuchasphysicsormedicine,lies
Ferna´ndez-Delgadoetal.,2014).First,thisincludesprespec-
ingatheringadditionalempiricalevidenceforahypothesis
ified,strictlyadhered-todesignsoftheexperimentalsetup,
through a successful replication. Moreover, a replication
includinginparticularaclearlyspecifiedsetofdatasetsand
study may, but does not necessarily, also raise epistemic
tasks. Ideally,neutralcomparisonstudiesfocusonthecom-
questions,pointtoexperimentalimprovements,orprovide
parisonofalreadyexistingmethodsandarecarriedoutbya
refinedconcepts,especiallyinfailedreplications.
groupofauthorsapproximatelyequallyfamiliarwithallthe
8Inasense,thislimitsthepotentialoftheformerandrenders
thelatterlargelyuseless,withbiasedexperimentsasaresult.
6RethinkingEmpiricalResearchinMachineLearning
More infrastructure. To achieve this, practical limita- (e.g.,seeTheTuringWayCommunity,2023). (3)Engage
tionsalsoneedtobeovercome. Werequiremorededicated with researchers from other disciplines as data (the one
infrastructuretomaketheproposedformsofresearchmore whichMLmodelsaretrainedon)canonlyreallybeunder-
(easily)realizable.Inparticular,thereisaneedformoreand stoodifoneunderstandshowitwasgenerated. (4)Consider
betteropendatabasesofwell-curatedandwell-understood makingempiricalresearchinMLa(partial)researchfocus.
datasets such as OpenML (Vanschoren et al., 2013) or Adviceforseniorresearchers. (1)Allowyourjuniorre-
OpenMLBenchmarkingSuites(Bischletal.,2021). More- searcherstowrite(great)papersonempiricalaspectsofML,
over, well-maintained open-source software for system- evenifthosemayberelativelydifficulttopublishinmajor
aticbenchmarkexperiments,suchastheAutoMLBench- venuesfornow.Ourpersonalexperienceisthatthesepapers
mark (Gijsbers et al., 2024), HPOBench (Eggensperger can still be highly cited and become very influential. (2)
et al., 2021), NAS-Bench-Suite (Mehta et al., 2022), or Learnfromotherfields;whatweareexperiencinginterms
AlgoPerf(Dahletal.,2023),areneeded. Platformsforpub- of non-replicable research is not a new phenomenon. (3)
lic leaderboards and model sharing (e.g., Hugging Face) Pleasedonotperceivethispaperasan‘attack’onMLbut
areanotherimportantaspect,althoughsomeoftheseplat- ratherasanhonestattempttoimproveitand,moreimpor-
formsaregearedtowards‘horseracing’basedonpredictive tantly,toimproveitsimpact.
performanceandthereforedonotnecessarilyalsoprovide Adviceforvenueorganizersandeditors(seealsoNakki-
scientificinsightsorinterpretability. Yet,thestandardsand ran & Belkin, 2022). (1) Encourage all forms of proper
automaticnatureofsuchplatformshavetheadvantagethat empiricalMLtobesubmitted(inparticular,thisincludes
theyofferconcretereferencepointsforcriticismanddebate. insight-orientedexploratoryresearch),e.g.,bycreatingspe-
Finally,reviewerguidelinesimplementingoursuggestions cialtracksoraddingkeywordsbutalsobyallowingsuch
anddedicatedvenuesforcurrentlyhard-to-publishempiri- workon‘maintracks’. Theideaistocreatespecialmea-
calworkwillallowthefullpotentialofempiricalMLtobe suresforthetopictoincreaseawarenessbutnotto‘isolate’
realized(Sculleyetal.,2018;Nakkiran&Belkin,2022). or‘ban’allsuchpaperstospecial(workshop)trackswith
Moreover, without more education, none of this will be (potentially)‘less’value. (2)Considergivingoutawardsfor
possible. Giventhedifferentperspectives–formalscience, positiveexamplesofthesetypesofresearch. (3)Consider
engineering,statistical–fromwhichMLcanbeviewed,it establishingpositionslikereproducibilityandreplicability
isverydifficulttoincludeeachintheappropriatedepthin editorsforvenuesandjournals. (4)Giveconcreteadvicefor
asinglestudyprogram. Whilearecentsurveyof101un- bestpractices, soauthorsandreviewershaveclearguide-
dergraduatedatascienceprogramsintheU.S.showedthat lines to follow. Note that this should not be confined to
allincludedanintroductorycourseinstatistics(BileHas- asking‘Weretheempiricalresultssubjectedtostatistical
san et al., 2021), statistics has only recently (2023) been tests?’ (without further information); this is close to the
includedasacoretopicinthecurriculumrecommendations oppositeofwhatwethinkisneeded.9
forCS∗(JointTaskForceonComputingCurricula,2023).It
isalsoquestionableifintroductorycoursesaresufficientto
4.BeyondtheStatusQuo: Rethinking
avoidcrucialgapsthatcanleadtotheadoptionofquestion-
EmpiricalMLasaMaturingScience
ableresearchpractices(cf.Gigerenzer,2018). Furthermore,
nearly no study program contains a dedicated course on The exploratory-confirmatory research continuum.
DesignandAnalysisof(Computer)Experiments(Santner WithML’sstrongfoundationinformalsciences,whereab-
etal.,2003;Boxetal.,2005;Deanetal.,2017),whichwe solutecertaintycanbeachievedbyformalproofs,theclear
deemespeciallyrelevantforourcontexthere. Ingeneral, distinctionbetweenexploratoryandconfirmatoryresearch
weagreewithDeVeauxetal.(2017,p.16-17)thatmany thathasbeeninvokedsofarmayseemnatural. Yet,froman
“coursestraditionallyfoundincomputerscience,statistics, empiricalperspective,i.e.,wheneveronedealswithentities
andmathematicsofferingsshouldberedesignedforthedata intherealworld,itisitselfanoversimplifyingdichotomy,
science[orML]majorintheinterestofefficiencyandthe andempiricalresearchisbetterthoughtofasacontinuum
potentialsynergythatintegratedcourseswouldoffer.” fromexploratorytoconfirmatory, withanidealofpurely
exploratory research at one end and of strictly confirma-
Finally,wewouldliketoofferconcreteandpracticable
toryresearchattheother(e.g.,Wagenmakersetal.,2012;
advicetospecifictargetgroups,inadditiontothegeneral
Oberauer&Lewandowsky,2019;Szollosi&Donkin,2021;
recommendationsabove.
Scheeletal.,2021;Devezeretal.,2021;Rubin&Donkin,
Adviceforjuniorresearchers. (1)Readthepositiveexam-
2022;Ho¨fleretal.,2022;Fife&Rodgers,2022).
plesofinsight-orientedexploratoryresearchinML(listed
above),aboutthedesignofexperiments,thecriticaldiscus- 9One anonymous reviewer also suggested that venues start
siononstatisticaltesting,andthebasicsofphilosophyof collecting meta data on reasons for rejection. Such data could
science. (2) Educate yourself in Open Science practices serveasabasistoevaluateifcertaintypesofMLresearchfacea
systematicbias.
7RethinkingEmpiricalResearchinMachineLearning
Based on that notion, Fife & Rodgers (2022) argue that cancewasnevermeanttoimplyscientificimportance”,and
“psychology may not be mature enough to justify confir- youshouldnot“concludeanythingaboutscientificorprac-
matoryresearch”(p.453)andthat“[t]hematurityofany tical importance based on statistical significance (or lack
scienceputsacapontheexploratory/confirmatorycontin- thereof)”(Wassersteinetal.,2019,pp.2,1). Onthecon-
uum”(p.462). Giventhesimilaritiesbetweenresearchin trary,themisguidedbeliefsinanduseofstatisticalrituals
psychologyandMLasdescribedbyHullmanetal.(2022), (Gigerenzer,2018)islargelyresponsibleforthereplication
wethinksimilarholdsforMLandwesuggestMLshould crisisinotherempiricaldisciplines.
beconsideredasamaturing(empirical)scienceaswell.10 The reasons are complex. First of all, the modern theory
Hullmanetal.(2022,p.355)“identifycommonthemesin of statistical hypothesis testing (SHT) is a conflation of
reformdiscussions,likeoverrelianceonasymptotictheory two historically distinct types of testing theory∗. Impor-
andnon-crediblebeliefsaboutreal-worlddata-generating tantepistemologicalquestionsaboutwhenstatisticaltests
processes.”Thatsaid,confirmatoryresearchinMLasad- are appropriate are obscured by this mixed theory (e.g.,
vocatedinSection3isstillverydifferentfromstrictconfir- Schneider, 2015; Gigerenzer & Marewski, 2015; Rubin,
matoryresearchinotherdisciplines. Ratheritcanbeseen 2020). More importantly, specifically for experiments in
as“rough”confirmatoryresearch(Fife&Rodgers,2022; ML,boththeoriesaredevelopedforexperimentaldesigns
Tukey,1973)thatfollowsthesameprinciples,but–asout- based on samples randomly drawn from a population of
lined – it is unclear how results can be generalized (e.g., interest(Schneider,2015). Ingeneral,theassumptionsun-
usingstatisticaltests)–acornerstoneofstrictconfirmatory derlyingthetheoryofstatisticaltestingasaninferentialtool
research. Butthisshouldnotbetakenasacaveat. Rough areusuallynotmetinmanyapplications(Greenland,2023).
confirmatoryresearchallowsforflexibilitythatstrictconfir- Infact,theeditorsoftheTheAmericanStatisticianspecial
matoryresearchdoesnot(Fife&Rodgers,2022). issueStatisticalInferenceinthe21stCentury: AWorldBe-
TheframeworkproposedbyHeinzeetal.(2024,p.1)can yondp<0.05wentsofarastoconclude,“basedon[their]
beseenasawayofmappingthisratherabstractideainto reviewofthearticlesinthisspecialissueandthebroader
moreconcreteguidelinesforscientificpractice. Inthecon- literature,thatitistimetostopusingtheterm‘statistically
textofbiostatistics, theyproposetoconsiderfourphases significant’entirely”(Wassersteinetal.,2019,p.2).
ofmethodologicalresearch,analogoustoclinicalresearch Notethatwewanttowarnagainstanoveremphasisonas
in drug development: “(I) proposing a new methodologi- well as an uncritical use of statistical tests; we do not ar-
calideawhileproviding,forexample,logicalreasoningor gueagainststatisticaltestingingeneral. Quitethecontrary,
proofs,(II)providingempiricalevidence,firstinanarrow weargueforamorediversesetofanalysistools(applied
target setting, then (III) in an extended range of settings withcareandcriticalreflection),includingbutnotlimited
andforvariousoutcomes,accompaniedbyappropriateap- tostatisticaltesting. Wealsowanttostressthatstatistical
plicationexamples,and(IV)investigationsthatestablisha testingcannotremedymorefundamentalproblemssuchas
methodassufficientlywell-understoodtoknowwhenitis poorexperimentaldesign. Tosummarizethemainpoints,
preferredoverothersandwhenitisnot;thatis,itspitfalls.” weemphasize:
Statisticalsignificancetests: Wordsofcaution,revisited! • Valid statistical testing inevitably depends on a thor-
Theproblemofempiricalresearchasacontinuumismore oughandwell-designedexperimentalsetup.
involvedepistemologicallyandcannotbediscussedinfull
• Statisticaltestingshouldnotbeappliedroutinelyand
detailhere. Animportantaspectthatneedstobediscussed
requires thought and careful preparation to be valid
isitsrelationtothemisguideduseofstatisticaltesting. This
andinsightful.
pointhasbeenmadebyDrummond(2006)beforeandin
moredetail. Werevisitithere, enrichingitwithmorere- • Improperstatisticaltestingand/oritsuneducatedinter-
centliteratureontheissue. Inparticular,routinelyadding pretationare–widelyacknowledged–amaindriver
statisticalmachinerytoan(alreadyunderspecifiedand/orbi- fornon-replicableresultsinotherempiricalsciences.
ased)experimentaldesigntotestforstatisticallysignificant
• Thediscussionabouttheseissueshasbeengoingonfor
differencesinperformance–asisfrequentlydoneand/or
decadesandhasresultedinalargebodyofliterature,
explicitly asked for (e.g., Henderson et al., 2018; Marie
someofwhichiscondensedinthementionedspecial
etal.,2021)–doesnotimprovetheepistemicrelevanceof
issueofTheAmericanStatistician.
theresultsbymuchnordoesitaddmuchadditionalinsight
overotherdataaggregations. Infact,“[s]tatisticalsignifi- So,whileweargueformoreexperimentsinaconfirmatory
spirittoimprovethestatusquoofempiricalML(seeSection
10TherearealsodifferencesbetweenMLandpsychologycon-
3),especiallyusingneutralmethodcomparisonandreplica-
siderablysimplifyingourlives:weusuallydonotexperimenton
tionstudies,wealsoemphasizethatitisimportanttokeep
humansbutalgorithmsoncomputersandhavemorecontrolover
in mind their current epistemic limitations. In particular,
experiments,largersamplesizes,andlowerexperimentalcosts.
wewarnagainstcommonmisconceptionsaboutandinap-
8RethinkingEmpiricalResearchinMachineLearning
propriateuseofSHT.Theproblemisthattheunderlying 5.Conclusion
“misunderstandingsstemfromasetofinterrelatedcognitive
This work offers perspectives on ML that outline how it
biasesthatreflectinnatehumancompulsionswhicheventhe
shouldmovefromafieldbeinglargelydrivenbymathemati-
mostadvancedmathematicaltrainingseemstodonothing
calproofsandapplicationimprovementstoalsobecominga
tostaunch,andmayevenaggravate: Dichotomania,theten-
full-fledgedempiricalfielddrivenbymultipletypesofexper-
dencytoreducequantitativescalestodichotomies;nullism,
imentalresearch. Byprovidingconcretepracticalguidance
thetendencytobelieveoratleastactasifanunrefutednull
butatthesametimemoderatingexpectationsofwhatempir-
hypothesisistrue;andstatisticalreification,thetendencyto
icalresearchcanachieve,wewishtocontributetogreater
forgetthatmathematicalargumentssaynothingaboutreal-
overallreliabilityandtrustworthiness.
ityexcepttotheextenttheassumptionstheymake(which
Foreverydon’t,thereisado. However,weareaware
areoftenimplicit)canbemappedintorealityinawaythat
thatourexplanationsmayinitiallyleavethereaderunsat-
makesthemallcorrectsimultaneously”(Greenland,2023,
isfied when it comes to translating the conclusions into
p.911).
scientificpractice. Forexample,thosewhowerehopingfor
MostcurrentempiricalMLresearchshouldratherbe guidelines on the correct use of statistical tests may well
viewed as exploratory. As outlined, confirmatory re- be at a complete loss. However, we do not believe that
searchaimstotestpreexistinghypotheses,whileexploratory this is actually the case. If you are inclined to perform
research involves gathering information, identifying pat- statisticaltestsasdescribedbyDemsˇar(2006),doso,but
terns, and formulating specific hypotheses for further in- alsobeawareoftheDo-listsdescribedbyWassersteinetal.
vestigation. Wethink,currently,mostoftheempiricalre- (2019,Ch. 3,7). Inthisregard,weconsiderthefollowing
searchinMLisconductedaspartofapaperintroducing commentbyWassersteinetal. (ib.,p.6)verynoteworthy:
a new method and is fashioned as confirmatory research “Researchersofanyilkmayrarelyadvertisetheirpersonal
even though it is exploratory in nature. In our view, this modesty. Yet,themostsuccessfulonescultivateapractice
isreflectedespeciallyintheroutineuseofstatisticaltests ofbeingmodestthroughouttheirresearch,byunderstanding
toaggregatebenchmarkresults: theexploratoryphaseof andclearlyexpressingthelimitationsoftheirwork.”Fur-
methoddevelopment(e.g.,tryingoutdifferentmethodvari- thermore,donotonlyrelyonrealdata,usesimulateddata
ants)largelyinvalidatespost-hocstatisticaltests. AsStrobl aswell. Simulationsareanexcellenttoolforoperationaliza-
&Leisch(2024,p.2)putit,“Inmethodologicalresearch, tion,i.e.,mappingabstractconceptstomeasurableentities.
comparisonstudiesareoftenpublishedeitherwiththeex- Yet,themostimportantpointisthatweshouldbeopento
plicitorimplicitaimtopromoteanewmethodbymeans differentwaysofdoingexperimentalresearchandshould
ofshowingthatitoutperformsexistingmethods.”Inother notpenalizeresearchjustbecauseitdoesnotfollowcertain
words,theconductedexperimentsaresetuptoconfirmthe establishedconventions. AsNakkiran&Belkin(2022,p.6)
(implicit)hypothesisthattheproposedmethodconstitutes putit: “Eachpapermustbeevaluatedonanindividualba-
animprovement. Systemicpressuresandconventions,as sis”;thisischallenging,buttheysuggestguidelines. The
wellasML’sstrongrootsinformalsciencesandfocuson communityshouldtakethemuptoaddressthisissue.
improvingapplications,encouragethismindsetandtheprac- Embracinginconclusiveness. Summarizingtheperspec-
ticeofinvokingconfirmatoryarguments. Thisisexpressed tivesonempiricalMLcoveredhere,andreturningtotheidea
instatementssuchasthat“[i]tiswell-knownthatreview- ofmaturesciences,webelievethatforMLtomatureasan
ersaskforapplicationimprovements”and“for‘theoretical (empirical)science,agreaterawarenessofsomeepistemic
justification’forpurelyexperimentalpapers,evenwhenthe limitations,butalsoofthepluralityofwaystogaininsights,
experimentsaloneconstituteavalidscientificcontribution” mightbeallitneeds. Webelievethatifempiricalresearch
(Nakkiran & Belkin, 2022, pp. 2-3). The problem with is one thing, it is not conclusive and no single empirical
notemphasizingtheexploratorynatureisthat“exploratory studycanproveanythingwithabsolutecertainty. Itmust
findingshaveaslipperywayof‘transforming’intoplanned bescrutinized,repeated,andreassessedinasenseofepis-
findingsastheresearchprocessprogresses”(Calin-Jageman temiciteration∗(Chang,2004). Thatsaid,weconcludeby
& Cumming, 2019, p. 275) and “[a]t the bottom of that quotingChang’sthoughts(ib.,p.243)onscienceingeneral:
slipperyslopeoneoftenfindsresultsthatdon’treproduce” “Ifsomethingisactuallyuncertain,ourknowledgeissupe-
(Wasserstein et al., 2019, p. 3). Shifting the focus to an riorifitisaccompaniedbyanappropriatedegreeofdoubt
exploratorynotionofmethoddevelopmentisanopportunity ratherthanblindfaith. Ifthereasonswehaveforacertain
tofullyallow“tounderstandunderwhichcircumstancesthe beliefareinconclusive,beingawareoftheinconclusiveness
algorithmproducesmisleadingresults”(Rendsburgetal., preparesusbetterforthepossibilitythatotherreasonsmay
2020, p. 9) and to “learn about [its] strengths and weak- emergetooverturnourbelief. Withacriticalawarenessof
nesses”(Sculleyetal.,2018,p.2)andclearlyreportthem. uncertaintyandinconclusiveness,ourknowledgereachesa
higherlevelofflexibilityandsophistication.”
9RethinkingEmpiricalResearchinMachineLearning
BroaderImpactStatement nal of Machine Learning Research, 5:1089–1105,
2004. https://www.jmlr.org/papers/v5/
Thispositionpaperaimstoadvancemachinelearningby
grandvalet04a.html.
addressingpractical challengesandepistemicconstraints
ofempiricalresearchthatareoftenoverlooked. Webelieve
Bergstra, J., Bardenet, R., Bengio, Y., and Ke´gl, B. Al-
thishasimplicationsformachinelearningresearchingen-
gorithms for hyper-parameter optimization. In Shawe-
eral,asitcanhelptoimprovethereliabilityandcredibility
Taylor,J.,Zemel,R.,Bartlett,P.,Pereira,F.,andWein-
of research results. We also believe that our contribution
berger, K.(eds.), AdvancesinNeuralInformationPro-
can have a broader positive social and ethical impact by
cessingSystems,volume24,Granada,Spain,2011.Cur-
preventingmisdirectedeffortsandresources.
ranAssociates,Inc.
Acknowledgments Bergstra, J., Yamins, D., and Cox, D. Making a sci-
ence of model search: Hyperparameter optimization
We thank the four anonymous reviewers for their valu- in hundreds of dimensions for vision architectures.
ablecommentsandsuggestions. KatharinaEggensperger In Dasgupta, S. and McAllester, D. (eds.), Proceed-
is a member of the Machine Learning Cluster of Excel- ings of the 30th International Conference on Machine
lence,EXCnumber2064/1–Projectnumber390727645. Learning, pp. 115–123, Atlanta, Georgia, USA, 2013.
Anne-Laure Boulesteix was partly funded by DFG grant PMLR. https://proceedings.mlr.press/
BO3139/9-1. v28/bergstra13.html.
References Beyer, L., He´naff, O. J., Kolesnikov, A., Zhai,
X., and van den Oord, A. Are we done with
Aha,D.W. Generalizingfromcasestudies: Acasestudy. ImageNet? arXiv:2006.07159 [cs.CV], 2020.
InSleeman,D.andEdwards,P.(eds.),MachineLearn-
doi:10.48550/arXiv.2006.07159.
ing Proceedings 1992, pp. 1–10, San Francisco, CA,
1992. Morgan Kaufmann. doi:10.1016/B978-1-55860- BileHassan,I.,Ghanem,T.,Jacobson,D.,Jin,S.,Johnson,
247-2.50006-1. K., Sulieman, D., and Wei, W. Data science curricu-
lum design: A case study. In Proceedings of the 52nd
Albanie,S.,Henriques,J.,Bertinetto,L.,Hernandez-Garcia,
ACMTechnicalSymposiumonComputerScienceEduca-
A., Doughty, H., and Varol, G. The pre-registration
tion,pp.529–534.AssociationforComputingMachinery,
workshop: An alternative publication model for ma-
2021. doi:10.1145/3408877.3432443.
chinelearningresearch[Workshop]. Thirty-FifthConfer-
enceonNeuralInformationProcessingSystems,Online,
Bischl,B.,Casalicchio,G.,Feurer,M.,Gijsbers,P.,Hutter,
2021. https://neurips.cc/Conferences/
F.,Lang,M.,GomesMantovani,R.,vanRijn,J.,andVan-
2021/Schedule?showEvent=21885.
schoren,J.OpenMLbenchmarkingsuites.InVanschoren,
Ali,S.andSmith,K.A. Onlearningalgorithmselection J.andYeung,S.(eds.),ProceedingsoftheNeuralInfor-
forclassification. AppliedSoftComputing,6(2):119–138, mationProcessingSystemsTrackonDatasetsandBench-
2006. doi:10.1016/j.asoc.2004.12.002. marks,volume1.CurranAssociates,Inc.,2021.
Barba, L. A. Terminologies for reproducible Bischl, B., Binder, M., Lang, M., Pielok, T., Richter,
research. arXiv:1802.03311 [cs.DL], 2018. J., Coors, S., Thomas, J., Ullmann, T., Becker, M.,
doi:10.48550/arXiv.1802.03311. Boulesteix, A.-L., Deng, D., and Lindauer, M. Hyper-
parameter optimization: Foundations, algorithms, best
Bates,S.,Hastie,T.,andTibshirani,R. Cross-validation:
practices,andopenchallenges. WileyInterdisciplinary
Whatdoesitestimateandhowwelldoesitdoit? Journal
Reviews: DataMiningandKnowledgeDiscovery,13(2):
oftheAmericanStatisticalAssociation,pp.1–12,2023.
e1484,2023. doi:10.1002/widm.1484.
doi:10.1080/01621459.2023.2197686.
Boulesteix, A.-L. Over-optimism in bioinformat-
Belkin, M., Hsu, D., Ma, S., and Mandal, S. Recon-
ics research. Bioinformatics, 26(3):437–439, 2010.
ciling modern machine-learning practice and the clas-
doi:10.1093/bioinformatics/btp648.
sical bias–variance trade-off. Proceedings of the Na-
tionalAcademyofSciences,116(32):15849–15854,2019.
Boulesteix, A.-L., Lauer, S., and Eugster, M. J. A.
doi:10.1073/pnas.1903070116.
A plea for neutral comparison studies in compu-
Bengio, Y. and Grandvalet, Y. No unbiased estima- tational sciences. PLoS ONE, 8(4):e61562, 2013.
tor of the variance of K-fold cross-validation. Jour- doi:10.1371/journal.pone.0061562.
10RethinkingEmpiricalResearchinMachineLearning
Boulesteix,A.-L.,Hable,R.,Lauer,S.,andEugster,M.J.A. Campell, D. T. Factors relevant to the validity of experi-
Astatisticalframeworkforhypothesistestinginrealdata mentsinsocialsettings. PsychologicalBulletin,54(4):
comparison studies. The American Statistician, 69(3): 297–312,1957. doi:10.1037/h0040950.
201–212,2015a. doi:10.1080/00031305.2015.1005128.
Chang,H. Inventingtemperature: Measurementandscien-
tificprogress. OxfordUniversityPress,2004.
Boulesteix, A.-L., Stierle, V., and Hapfelmeier, A.
Publication bias in methodological computational re-
Chang, H. Operationalism. In Zalta, E. N. (ed.), The
search. Cancer Informatics, 14(S5):11–19, 2015b.
StanfordEncyclopediaofPhilosophy.MetaphysicsRe-
doi:10.4137/CIN.S30747.
searchLab,StanfordUniversity,Fall2021edition,2021.
https://plato.stanford.edu/archives/
Boulesteix,A.-L.,Wilson,R.,andHapfelmeier,A. Towards
fall2021/entries/operationalism/.
evidence-based computational statistics: Lessons from
clinicalresearchontheroleanddesignofreal-databench- Christodoulou,E.,Ma,J.,Collins,G.S.,Steyerberg,E.W.,
markstudies. BMCMedicalResearchMethodology,17 Verbakel, J. Y., and Van Calster, B. A systematic re-
(1):138,2017. doi:10.1186/s12874-017-0417-2. view shows no performance benefit of machine learn-
ingoverlogisticregressionforclinicalpredictionmod-
Bouthillier, X., Laurent, C., and Vincent, P. Unre- els. JournalofClinicalEpidemiology,110:12–22,2019.
producible research is reproducible. In Chaudhuri, doi:10.1016/j.jclinepi.2019.02.004.
K. and Salakhutdinov, R. (eds.), Proceedings of the
36th International Conference on Machine Learning, Conference on Neural Information Processing Sys-
tems. NeurIPS 2023 Datasets and Benchmarks
pp. 725–734, Long Beach, California, USA, 2019.
PMLR. https://proceedings.mlr.press/ Track, n.d. Retrieved January 31, 2024, from
https://nips.cc/Conferences/2023/
v97/bouthillier19a.html.
CallForDatasetsBenchmarks.
Bouthillier, X., Delaunay, P., Bronzi, M., Trofimov, A.,
Dahl,G.E.,Schneider,F.,Nado,Z.,Agarwal,N.,Sastry,
Nichyporuk, B., Szeto, J., Mohammadi Sepahvand,
C.S.,Hennig,P.,Medapati,S.,Eschenhagen,R.,Kasim-
N., Raff, E., Madan, K., Voleti, V., Ebrahimi Kahou,
beg,P.,Suo,D.,Bae,J.,Gilmer,J.,Peirson,A.L.,Khan,
S., Michalski, V., Arbel, T., Pal, C., Varoquaux,
B.,Anil,R.,Rabbat,M.,Krishnan,S.,Snider,D.,Amid,
G., and Vincent, P. Accounting for variance in
E.,Chen,K.,Maddison,C.J.,Vasudev,R.,Badura,M.,
machine learning benchmarks. In Smola, A., Di-
Garg,A.,andMattson,P. Benchmarkingneuralnetwork
makis, A., and Stoica, I. (eds.), Proceedings of
training algorithms. arXiv:2306.07179 [cs.LG], 2023.
Machine Learning and Systems, volume 3, pp. 747–
doi:10.48550/arXiv.2306.07179.
769, 2021. https://proceedings.mlsys.
org/paper_files/paper/2021/hash/ D’Amour, A., Heller, K., Moldovan, D., Adlam, B., Ali-
0184b0cd3cfb185989f858a1d9f5c1eb- panahi,B.,Beutel,A.,Chen,C.,Deaton,J.,Eisenstein,
Abstract.html. J.,Hoffman,M.D.,Hormozdiari,F.,Houlsby,N.,Hou,
S.,Jerfel,G.,Karthikesalingam,A.,Lucic,M.,Ma,Y.,
Box, G.E.P., Hunter, J.S., and Hunter, W.G. Statistics McLean,C.,Mincu,D.,Mitani,A.,Montanari,A.,Nado,
forExperimenters: Design,Innovation,andDiscovery. Z., Natarajan, V., Nielson, C., Osborne, T. F., Raman,
Hoboken, NJ: Wiley, 2nd edition, 2005. ISBN 0-471- R.,Ramasamy,K.,Sayres,R.,Schrouff,J.,Seneviratne,
71813-0. M.,Sequeira,S.,Suresh,H.,Veitch,V.,Vladymyrov,M.,
Wang,X.,Webster,K.,Yadlowsky,S.,Yun,T.,Zhai,X.,
Bridgman,P.W. TheLogicofModernPhysics. NewYork: andSculley,D. Underspecificationpresentschallenges
Macmillan,1927. forcredibilityinmodernmachinelearning. Journalof
MachineLearningResearch,23:1–61,2022. https://
Buchka, S., Hapfelmeier, A., Gardner, P. P., Wilson, R., www.jmlr.org/papers/v23/20-1335.html.
and Boulesteix, A.-L. On the optimistic performance
evaluation of newly introduced bioinformatic methods. DeVeaux,R.D.,Agarwal,M.,Averett,M.,Baumer,B.S.,
GenomeBiology,22(1):152,2021. doi:10.1186/s13059- Bray,A.,Bressoud,T.C.,Bryant,L.,Cheng,L.Z.,Fran-
021-02365-4. cis, A., Gould, R., Kim, A. Y., Kretchmar, M., Lu, Q.,
Moskol, A., Nolan, D., Pelayo, R., Raleigh, S., Sethi,
Calin-Jageman,R.J.andCumming,G. Thenewstatistics R.J.,Sondjaja,M.,Tiruviluamala,N.,Uhlig,P.X.,Wash-
forbetterscience: Askhowmuch, howuncertain, and ington,T.M.,Wesley,C.L.,White,D.,andYe,P. Cur-
whatelseisknown. TheAmericanStatistician,73(sup1): riculumguidelinesforundergraduateprogramsindata
271–280,2019. doi:10.1080/00031305.2018.1518266. science. AnnualReviewofStatisticsandItsApplication,
11RethinkingEmpiricalResearchinMachineLearning
4:15–30,2017. doi:10.1146/annurev-statistics-060116- Eggensperger, K., Mu¨ller, P., Mallik, N., Feurer, M.,
053930. Sass, R., Klein, A., Awad, N., Lindauer, M., and
Hutter, F. HPOBench: A collection of reproducible
Dean,A.,Voss,D.,andDraguljic´,D. DesignandAnalysis
multi-fidelity benchmark problems for HPO. In
ofExperiments. SpringerTextsinStatistics.NewYork:
Vanschoren, J. and Yeung, S. (eds.), Proceedings of
Springer,2ndedition,2017. ISBN978-3-319-52248-7.
the Neural Information Processing Systems Track
doi:10.1007/978-3-319-52250-0.
on Datasets and Benchmarks, volume 1. Curran
Dehghani, M., Tay, Y., Gritsenko, A. A., Zhao, Z., Associates, Inc., 2021. https://datasets-
Houlsby,N.,Diaz,F.,Metzler,D.,andVinyals,O. The benchmarks-proceedings.neurips.
benchmark lottery. arXiv:2107.07002 [cs.LG], 2021. cc/paper_files/paper/2021/hash/
doi:10.48550/arXiv.2107.07002. 93db85ed909c13838ff95ccfa94cebd9-
Abstract-round2.html.
Demsˇar,J. Statisticalcomparisonsofclassifiersovermul-
tipledatasets. JournalofMachineLearningResearch, Eisinga,R.,Heskes,T.,Pelzer,B.,andTeGrotenhuis,M.
7:1–30, 2006. https://jmlr.org/papers/v7/ Exactp-valuesforpairwisecomparisonofFriedmanrank
demsar06a.html. sums, with application to comparing classifiers. BMC
Bioinformatics,18(1):68,2017. doi:10.1186/s12859-017-
Devezer,B.,Navarro,D.J.,Vandekerckhove,J.,andBuzbas,
1486-2.
E. O. The case for formal methodology in scientific
reform. RoyalSocietyOpenScience,8(3):200805,2021.
Elor, Y. and Averbuch-Elor, H. To SMOTE, or
doi:10.1098/rsos.200805.
not to SMOTE? arXiv:2201.08528 [cs.LG], 2022.
Dhiman, P., Ma, J., Andaur Navarro, C. L., Speich, B., doi:10.48550/arXiv.2201.08528.
Bullock, G., Damen, J. A. A., Hooft, L., Kirtley, S.,
Eugster,M.J.A.,Hothorn,T.,andLeisch,F. Domain-based
Riley, R. D., Van Calster, B., Moons, K. G. M., and
benchmarkexperiments:Exploratoryandinferentialanal-
Collins,G.S. Riskofbiasofprognosticmodelsdevel-
ysis. Austrian Journal of Statistics, 41(1):5–26, 2012.
oped using machine learning: A systematic review in
doi:10.17713/ajs.v41i1.185.
oncology. Diagnostic and Prognostic Research, 6:13,
2022. doi:10.1186/s41512-022-00126-w.
Ferna´ndez-Delgado, M., Cernadas, E., Barro, S., and
Dietterich, T. G. Exploratory research in ma- Amorim, D. Do we need hundreds of classifiers to
chine learning. Machine Learning, 5(1):5–9, 1990. solverealworldclassificationproblems? JournalofMa-
doi:10.1007/BF00115892. chineLearningResearch,15:3133–3181,2014. https:
//jmlr.org/papers/v15/delgado14a.html.
Dietterich, T. G. Approximate statistical tests for
comparing supervised classification learning algo- Ferrari Dacrema, M., Boglio, S., Cremonesi, P., and
rithms. Neural Computation, 10(7):1895–1923, 1998. Jannach, D. A troubling analysis of reproducibility
doi:10.1162/089976698300017197. and progress in recommender systems research. ACM
TransactionsonInformationSystems,39(2):1–49,2021.
Drummond,C.Machinelearningasanexperimentalscience
doi:10.1145/3434185.
(revisited). InAAAIWorkshoponEvaluationMethodsfor
MachineLearning,Boston,Massachusetts,USA,2006.
Feurer,M.andHutter,F. Hyperparameteroptimization. In
https://aaai.org/papers/ws06-06-002-
Hutter,F.,Kotthoff,L.,andVanschoren,J.(eds.),Auto-
machine-learning-as-an-experimental-
matedMachineLearning: Methods,Systems,Challenges,
science-revisited/.
pp.3–33.SpringerInternationalPublishing,Cham,2019.
Drummond,C. Replicabilityisnotreproducibility: Norisit doi:10.1007/978-3-030-05318-5 1.
goodscience. InProceedingsoftheEvaluationMethods
forMachineLearningWorkshopatthe26thAnnualInter-
Feynman,R.P.Cargocultscience.EngineeringandScience,
national Conference on Machine Learning, Montreal, 37(7):10–13,1974. Transcriptofcommencementaddress
Canada, 2009. https://www.site.uottawa. given at the California Institute of Technology. Avail-
ca/˜cdrummon/pubs/ICMLws09.pdf. able at http://calteches.library.caltech.
edu/51/2/CargoCult.htm.
Drummond, C. and Japkowicz, N. Warning: Statis-
tical benchmarking is addictive. Kicking the habit Fife, D. A. and Rodgers, J. L. Understanding the ex-
in machine learning. Journal of Experimental & ploratory/confirmatorydataanalysiscontinuum: Moving
Theoretical Artificial Intelligence, 22(1):67–80, 2010. beyondthe“replicationcrisis”. AmericanPsychologist,
doi:10.1080/09528130903010295. 77(3):453–466,2022. doi:10.1037/amp0000886.
12RethinkingEmpiricalResearchinMachineLearning
Forde, J. Z., Ruiz, F., Pradier, M. F., and Schein, A. Gundersen, O. E. The fundamental principles of repro-
I can’t believe it’s not better! Bridging the gap ducibility. PhilosophicalTransactionsoftheRoyalSoci-
between theory and empiricism in probabilistic ma- etyA:Mathematical,PhysicalandEngineeringSciences,
chine learning [Workshop]. Thirty-Fourth Conference 379(2197):20200210,2021. doi:10.1098/rsta.2020.0210.
on Neural Information Processing Systems, Online,
2020. https://neurips.cc/virtual/2020/ Hand, D. J. Classifier technology and the illusion
protected/workshop_16124.html. of progress. Statistical Science, 21(1):1–14, 2006.
doi:10.1214/088342306000000060.
Foster, C. Methodological pragmatism in educational
research: from qualitative-quantitative to exploratory- Hastie, T., Tibshirani, R., and Friedman, J. H. The Ele-
confirmatory distinctions. International Journal of ments of Statistical Learning: Data Mining, Inference,
Research & Method in Education, 47(1):4–19, 2024. andPrediction. SpringerSeriesinStatistics.NewYork:
doi:10.1080/1743727X.2023.2210063. Springer,2ndedition,2009. ISBN978-0-387-84857-0.
doi:10.1007/978-0-387-84858-7.
Frankle, J. and Carbin, M. The lottery ticket hypoth-
Heinze, G., Boulesteix, A.-L., Kammer, M., Morris,
esis: Finding sparse, trainable neural networks. In
T. P., White, I. R., and Simulation Panel of the
7th International Conference on Learning Representa-
STRATOSinitiative. Phasesofmethodologicalresearch
tions, New Orleans, Louisiana, USA, 2019. https:
in biostatistics—building the evidence base for new
//openreview.net/forum?id=rJl-b3RcF7.
methods. Biometrical Journal, 66(1):2200222, 2024.
doi:10.1002/bimj.202200222.
Franklin, A. and Perovic, S. Experiment in physics. In
Zalta, E. N. and Nodelman, U. (eds.), The Stanford
Henderson,P.,Islam,R.,Bachman,P.,Pineau,J.,Precup,
Encyclopedia of Philosophy. Metaphysics Research
D., and Meger, D. Deep reinforcement learning that
Lab, Stanford University, Fall 2023 edition, 2023.
matters. InProceedingsoftheThirty-SecondAAAICon-
https://plato.stanford.edu/archives/
ferenceonArtificialIntelligenceandThirtiethInnovative
fall2023/entries/physics-experiment/.
Applications of Artificial Intelligence Conference and
EighthAAAISymposiumonEducationalAdvancesinAr-
Gencoglu,O.,vanGils,M.,Guldogan,E.,Morikawa,C.,
tificialIntelligence,pp.3207–3214.AAAIPress,2018.
Su¨zen, M., Gruber, M., Leinonen, J., andHuttunen, H.
doi:10.1609/aaai.v32i1.11694.
HARK side of deep learning – From grad student de-
scenttoautomatedmachinelearning. arXiv:1904.07633
Herrmann, M. Towards more reliable machine learn-
[cs.LG],2019. doi:10.48550/arXiv.1904.07633.
ing: conceptual insights and practical approaches
for unsupervised manifold learning and supervised
Gigerenzer, G. Statistical rituals: The replication delu-
benchmark studies. PhD thesis, Ludwig-Maximilians-
sion and how we got there. Advances in Methods and
Universita¨t Mu¨nchen, Munich, Germany, 2022. Avail-
PracticesinPsychologicalScience,1(2):198–218,2018.
able at https://edoc.ub.uni-muenchen.de/
doi:10.1177/2515245918771329.
30789/1/Herrmann_Moritz.pdf.
Gigerenzer, G. and Marewski, J. N. Surrogate science: Herrmann, M., Probst, P., Hornung, R., Jurinovic,
The idol of a universal method for scientific infer- V., and Boulesteix, A.-L. Large-scale benchmark
ence. Journal of Management, 41(2):421–440, 2015. studyofsurvivalpredictionmethodsusingmulti-omics
doi:10.1177/0149206314547522. data. BriefingsinBioinformatics,22(3):bbaa167,2020.
doi:10.1093/bib/bbaa167.
Gijsbers,P.,Bueno,M.L.P.,Coors,S.,LeDell,E.,Poirier,
S.,Thomas,J.,Bischl,B.,andVanschoren,J. AMLB:an Herrmann, M., Kazempour, D., Scheipl, F., and Kro¨ger,
AutoMLbenchmark. JournalofMachineLearningRe- P. Enhancingclusteranalysisviatopologicalmanifold
search, 25:1–65, 2024. https://www.jmlr.org/ learning. Data Mining and Knowledge Discovery, pp.
papers/v25/22-0493.html. 1–48,2023a. doi:10.1007/s10618-023-00980-2.
Greenland, S. Connecting simple and precise P-values Herrmann, M., Pfisterer, F., and Scheipl, F. A geomet-
tocomplexandambiguousrealities(includesrejoinder ricframeworkforoutlierdetectioninhigh-dimensional
to comments on “Divergence vs. decision P-values”). data. Wiley Interdisciplinary Reviews: Data Min-
ScandinavianJournalofStatistics,50(3):899–914,2023. ing and Knowledge Discovery, 13(3):e1491, 2023b.
doi:10.1111/sjos.12645. doi:10.1002/widm.1491.
13RethinkingEmpiricalResearchinMachineLearning
Ho¨fler,M.,Scherbaum,S.,Kanske,P.,McDonald,B.,and recommendationwebsite.Thefinalversionisavailable
Miller,R. Meanstovaluableexploration: I.theblending athttps://csed.acm.org/final-report/.
of confirmation and exploration and how to resolve it.
JournalofData-centricMachineLearningResearch. Sub-
Meta-Psychology,6,2022. doi:10.15626/MP.2021.2837.
mission guidelines for authors, n.d. Retrieved Jan-
Hooker, J. N. Testing heuristics: We have it uary 31, 2024, from https://data.mlr.press/
all wrong. Journal of Heuristics, 1:33–42, 1995. submissions.html.
doi:10.1007/BF02430364.
Kapoor,S.andNarayanan,A.Leakageandthereproducibil-
Hothorn, T., Leisch, F., Zeileis, A., and Hornik, K. The itycrisisinmachine-learning-basedscience. Patterns,4
designandanalysisofbenchmarkexperiments. Journal (9):100804,2023. doi:10.1016/j.patter.2023.100804.
of Computational and Graphical Statistics, 14(3):675–
Kerr,N.L. HARKing: Hypothesizingaftertheresultsare
699,2005. doi:10.1198/106186005X59630.
known. PersonalityandSocialPsychologyReview,2(3):
Hullman,J.,Kapoor,S.,Nanayakkara,P.,Gelman,A.,and 196–217,1998. doi:10.1207/s15327957pspr0203 4.
Narayanan,A. Theworstofbothworlds: Acomparative
Kimmelman,J.,Mogil,J.S.,andDirnagl,U. Distinguish-
analysisoferrorsinlearningfromdatainpsychologyand
ingbetweenexploratoryandconfirmatorypreclinicalre-
machinelearning. InProceedingsofthe2022AAAI/ACM
search will improve translation. PLoS Biology, 12(5):
ConferenceonAI,Ethics,andSociety,pp.335–348,Ox-
e1001863,2014. doi:10.1371/journal.pbio.1001863.
ford,UnitedKingdom,2022.AssociationforComputing
Machinery. doi:10.1145/3514094.3534196. Kleinberg, J. An impossibility theorem for clus-
tering. In Becker, S., Thrun, S., and Ober-
ICBINB Initiative. ICBINB Repository of Unexpected
mayer, K. (eds.), Advances in Neural Informa-
NegativeResults,n.d. RetrievedJanuary31,2024,from
tion Processing Systems, volume 15, Vancouver,
http://icbinb.cc/icbinb-repository-
Canada, 2002. MIT Press. https://papers.
of-unexpected-negative-results/.
nips.cc/paper_files/paper/2002/hash/
43e4e6a6f341e00671e123714de019a8-
Jaeger,R.G.andHalliday,T.R. Onconfirmatoryversus
Abstract.html.
exploratoryresearch. Herpetologica,54:S64–S66,1998.
https://www.jstor.org/stable/3893289.
Kobak, D. and Linderman, G. C. Initialization is critical
for preserving global data structure in both t-SNE and
Jelizarow,M.,Guillemot,V.,Tenenhaus,A.,Strimmer,K.,
UMAP. Nature Biotechnology, 39(2):156–157, 2021.
andBoulesteix,A.-L. Over-optimisminbioinformatics:
doi:10.1038/s41587-020-00809-z.
Anillustration. Bioinformatics,26(16):1990–1998,2010.
doi:10.1093/bioinformatics/btq323. Koch,B.,Denton,E.,Hanna,A.,andFoster,J.G. Reduced,
reused and recycled: The life of a dataset in machine
Johnson,D.S. Atheoretician’sguidetotheexperimental
learning research. In Vanschoren, J. and Yeung, S.
analysisofalgorithms. InGoldwasser,M.H.,Johnson,
(eds.),ProceedingsoftheNeuralInformationProcessing
D.S.,andMcGeoch,C.C.(eds.),DataStructures,Near
SystemsTrackonDatasetsandBenchmarks,volume1.
Neighbor Searches, and Methodology: Fifth and Sixth
CurranAssociates,Inc.,2021. https://datasets-
DIMACSImplementationChallenges,volume59ofSe-
benchmarks-proceedings.neurips.
ries in Discrete Mathematics & Theoretical Computer
cc/paper_files/paper/2021/hash/
Science,pp.215–250.AmericanMathematicalSociety,
3b8a614226a953a8cd9526fca6fe9ba5-
2002. ISBN978-0-8218-2892-2.
Abstract-round2.html.
Joint Task Force on Computing Curricula. Computer
Kriegel,H.-P.,Schubert,E.,andZimek,A. The(black)art
Science Curricula 2013: Curriculum Guidelines for
ofruntimeevaluation: Arewecomparingalgorithmsor
Undergraduate Degree Programs in Computer Sci-
implementations? KnowledgeandInformationSystems,
ence. AssociationforComputingMachineryandIEEE
52(2):341–378,2017. doi:10.1007/s10115-016-1004-2.
Computer Society, 2013. ISBN 978-1-4503-2309-3.
doi:10.1145/2534860. Langley, P. Machine learning as an experimen-
tal science. Machine Learning, 3(1):5–8, 1988.
JointTaskForceonComputingCurricula. ComputerSci-
doi:10.1023/A:1022623814640.
enceCurricula2023–TheFinalReport. Associationfor
ComputingMachinery,IEEEComputerSociety,andAs- Liao, T., Taori, R., Raji, I. D., and Schmidt, L. Are we
sociationfortheAdvancementofArtificialIntelligence, learningyet? Ametareviewofevaluationfailuresacross
2023. ThereportisnotyetlistedontheACMcurricula machine learning. In Vanschoren, J. and Yeung, S.
14RethinkingEmpiricalResearchinMachineLearning
(eds.),ProceedingsoftheNeuralInformationProcessing Mateus,P.,Volmer,L.,Wee,L.,Aerts,H.J.W.L.,Hoebers,
SystemsTrackonDatasetsandBenchmarks,volume1. F.,Dekker,A.,andBermejo,I. Imagebasedprognosis
CurranAssociates,Inc.,2021. https://datasets- inheadandneckcancerusingconvolutionalneuralnet-
benchmarks-proceedings.neurips. works: Acasestudyinreproducibilityandoptimization.
cc/paper_files/paper/2021/hash/ ScientificReports,13:18176,2023. doi:10.1038/s41598-
757b505cfd34c64c85ca5b5690ee5293- 023-45486-5.
Abstract-round2.html.
McElfresh, D., Khandagale, S., Valverde, J., C, V. P.,
Lim, T.-S., Loh, W.-Y., and Shih, Y.-S. A compar- Feuer, B., Hegde, C., Ramakrishnan, G., Goldblum,
ison of prediction accuracy, complexity, and train- M., and White, C. When do neural nets outperform
ing time of thirty-three old and new classification al- boosted trees on tabular data? In Oh, A., Neumann,
gorithms. Machine Learning, 40(3):203–228, 2000. T., Globerson, A., Saenko, K., Hardt, M., and Levine,
doi:10.1023/A:1007608224229. S. (eds.), Advances in Neural Information Processing
Systems, volume 36, New Orleans, Louisiana, USA,
Lindstrom, L. Cargo cults. In The Open Encyclope-
2023. Curran Associates Inc. https://papers.
dia of Anthropology. Facsimile of the first edition in
nips.cc/paper_files/paper/2023/hash/
The Cambridge Encyclopedia of Anthropology, 2023.
f06d5ebd4ff40b40dd97e30cee632123-
doi:10.29164/18cargo.
Abstract-Datasets_and_Benchmarks.html.
Lipton,Z.C.andSteinhardt,J. Troublingtrendsinmachine
McGeoch, C. C. Experimental analysis of algorithms.
learningscholarship. arXiv:1807.03341[stat.ML],2018.
In Pardalos, P. M. and Romeijn, H. E. (eds.), Hand-
doi:10.48550/arXiv.1807.03341.
book of Global Optimization: Volume 2, pp. 489–513.
Lohmann,A.,Astivia,O.L.O.,Morris,T.P.,andGroen- Springer,Boston,MA,2002. ISBN978-1-4757-5362-2.
wold,R.H.H. It’stime! Tenreasonstostartreplicating doi:10.1007/978-1-4757-5362-2 14.
simulationstudies. FrontiersinEpidemiology,2:973470,
2022. doi:10.3389/fepid.2022.973470. Mehta,Y.,White,C.,Zela,A.,Krishnakumar,A.,Zabergja,
G.,Moradian,S.,Safari,M.,Yu,K.,andHutter,F. NAS-
Lones, M. A. How to avoid machine learning pitfalls: a
Bench-Suite: NASevaluationis(now)surprisinglyeasy.
guideforacademicresearchers. arXiv:2108.02497[cs],
In10thInternationalConferenceonLearningRepresen-
2023. doi:10.48550/arXiv.2108.02497. tations,Online,2022. https://openreview.net/
forum?id=0DLwqQLmqV.
Lucic, M., Kurach, K., Michalski, M., Gelly, S., and
Bousquet, O. Are GANs created equal? A large-
Melis, G., Dyer, C., and Blunsom, P. On the state of
scale study. In Bengio, S., Wallach, H., Larochelle,
theartofevaluationinneurallanguagemodels. In6th
H., Grauman, K., Cesa-Bianchi, N., and Garnett,
InternationalConferenceonLearningRepresentations,
R. (eds.), Advances in Neural Information Pro-
Vancouver, Canada, 2018. https://openreview.
cessing Systems, volume 31, Montre´al, Canada,
net/forum?id=ByJHuTgA-.
2018. Curran Associates Inc. https://papers.
nips.cc/paper_files/paper/2018/hash/ Merriam-Webster. Epistemic. In Merriam-
e46de7e1bcaaced9a54f1e9d0d2f800d- Webster.com dictionary, n.d. Retrieved May
Abstract.html. 1, 2024, from https://www.merriam-
webster.com/dictionary/epistemic.
Mannarswamy,S.andRoy,S. EvolvingAIfromresearch
to real life – Some challenges and suggestions. In Munafo`, M. R., Nosek, B. A., Bishop, D. V. M., Button,
Lang, J. (ed.), Proceedings of the Twenty-Seventh In- K.S., Chambers, C.D., duSert, N.P., Simonsohn, U.,
ternational Joint Conference on Artificial Intelligence, Wagenmakers,E.-J.,Ware,J.J.,andIoannidis,J.P.A. A
pp.5172–5179,Stockholm,Sweden,2018.AAAIPress. manifestoforreproduciblescience. NatureHumanBe-
doi:10.24963/ijcai.2018/717. haviour,1(1):1–9,2017. doi:10.1038/s41562-016-0021.
Marie,B.,Fujita,A.,andRubino,R. Scientificcredibility
Myrtveit, I., Stensrud, E., and Shepperd, M. Reliability
of machine translation research: A meta-evaluation of
andvalidityincomparativestudiesofsoftwareprediction
769papers. InProceedingsofthe59thAnnualMeeting
models. IEEETransactionsonSoftwareEngineering,31
oftheAssociationforComputationalLinguisticsandthe
(5):380–391,2005. doi:10.1109/TSE.2005.58.
11thInternationalJointConferenceonNaturalLanguage
Processing (Volume 1: Long Papers), pp. 7297–7306, Nadeau, C. and Bengio, Y. Inference for the generaliza-
Online,2021.AssociationforComputationalLinguistics. tion error. Machine Learning, 52(3):239–281, 2003.
doi:10.18653/v1/2021.acl-long.566. doi:10.1023/A:1024068626366.
15RethinkingEmpiricalResearchinMachineLearning
Nakkiran, P. and Belkin, M. Incentivizing empiri- Oberauer,K.andLewandowsky,S. Addressingthetheory
cal science in machine learning. In ML Evalu- crisisinpsychology. PsychonomicBulletin&Review,26
ation Standards Workshop at ICLR 2022, Online, (5):1596–1618,2019. doi:10.3758/s13423-019-01645-2.
2022. https://ml-eval.github.io/assets/
Pawel,S.,Kook,L.,andReeve,K. Pitfallsandpotentials
pdf/science_ml_proposal_2am.pdf.
insimulationstudies: Questionableresearchpracticesin
Narang, S., Chung, H. W., Tay, Y., Fedus, W., Fevry, T., comparativesimulationstudiesallowforspuriousclaims
Matena,M.,Malkan,K.,Fiedel,N.,Shazeer,N.,Lan,Z., ofsuperiorityofanymethod. BiometricalJournal,66(1):
Zhou,Y.,Li,W.,Ding,N.,Marcus,J.,Roberts,A.,and 2200091,2024. doi:10.1002/bimj.202200091.
Raffel,C. Dotransformermodificationstransferacross
Pineau, J., Vincent-Lamarre, P., Sinha, K., Larivie`re,
implementations and applications? In Moens, M.-F.,
V., Beygelzimer, A., d’Alche´ Buc, F., Fox, E., and
Huang,X.,Specia,L.,andYih,S.W.-t.(eds.),Proceed-
Larochelle, H. Improving reproducibility in machine
ingsofthe2021ConferenceonEmpiricalMethodsinNat-
learning research (a report from the NeurIPS 2019 re-
uralLanguageProcessing,pp.5758–5773,Onlineand
producibility program). Journal of Machine Learn-
PuntaCana,DominicanRepublic,2021.Associationfor
ingResearch,22:1–20,2021. https://jmlr.org/
ComputationalLinguistics.doi:10.18653/v1/2021.emnlp-
papers/v22/20-303.html.
main.465.
Plesser, H. E. Reproducibility vs. replicability: A brief
National Academies of Sciences, Engineering, and historyofaconfusedterminology. FrontiersinNeuroin-
Medicine. Reproducibility and Replicability in Sci- formatics,11:76,2018. doi:10.3389/fninf.2017.00076.
ence. Washington,DC:NationalAcademiesPress,2019.
doi:10.17226/25303. Popper,K.R. TheLogicofScientificDiscovery. Routledge,
2002.ISBN978-0-415-27844-7.Theworkwasoriginally
Nießl,C.,Herrmann,M.,Wiedemann,C.,Casalicchio,G., publishedin1935inGerman.ThefirstEnglishedition
andBoulesteix,A.-L. Over-optimisminbenchmarkstud- waspublishedin1959.
ies and the multiplicity of design and analysis options
Power, A., Burda, Y., Edwards, H., Babuschkin, I., and
wheninterpretingtheirresults. WileyInterdisciplinary
Misra,V.Grokking:Generalizationbeyondoverfittingon
Reviews: DataMiningandKnowledgeDiscovery,12(2):
smallalgorithmicdatasets. InMathematicalReasoning
e1441,2022. doi:10.1002/widm.1441.
inGeneralArtificialIntelligenceWorkshopatICLR2021,
Online, 2021. https://mathai-iclr.github.
Nießl,C.,Hoffmann,S.,Ullmann,T.,andBoulesteix,A.-
io/papers/papers/MATHAI_29_paper.pdf.
L. Explainingtheoptimisticperformanceevaluationof
newlyproposedmethods: Across-designvalidationex-
Raff, E. A step toward quantifying independently
periment. Biometrical Journal, 66(1):2200238, 2024.
reproducible machine learning research. In Wal-
doi:10.1002/bimj.202200238.
lach, H., Larochelle, H., Beygelzimer, A., d'Alche´-
Buc, F., Fox, E., and Garnett, R. (eds.), Advances
Nilsen, E. B., Bowler, D. E., and Linnell, J. D. C. Ex-
in Neural Information Processing Systems, vol-
ploratoryandconfirmatoryresearchintheopenscience
ume 32, Vancouver, Canada, 2019. Curran As-
era. JournalofAppliedEcology,57(4):842–847,2020.
sociates, Inc. https://papers.neurips.
doi:10.1111/1365-2664.13571.
cc/paper_files/paper/2019/hash/
c429429bf1f2af051f2021dc92a8ebea-
Niyogi, P., Smale, S., and Weinberger, S. A topolog-
Abstract.html.
ical view of unsupervised learning from noisy data.
SIAM Journal on Computing, 40(3):646–663, 2011. Raff, E. and Farris, A. L. A siren song of
doi:10.1137/090762932. open source reproducibility. In ML Evaluation
Standards Workshop at ICLR 2022, Online, 2022.
Norel, R., Rice, J. J., and Stolovitzky, G. The self- doi:10.48550/arXiv.2204.04372.
assessment trap: can we all be better than aver-
age? Molecular Systems Biology, 7(1):537, 2011. Raji, D., Denton, E., Bender, E. M., Hanna, A., and
doi:10.1038/msb.2011.70. Paullada, A. AI and the everything in the whole wide
world benchmark. In Vanschoren, J. and Yeung, S.
Nosek,B.A.,Ebersole,C.R.,DeHaven,A.C.,andMellor, (eds.), Proceedings of the Neural Information Pro-
D.T. Thepreregistrationrevolution. Proceedingsofthe cessing Systems Track on Datasets and Benchmarks,
NationalAcademyofSciences,115(11):2600–2606,2018. volume 1. Curran Associates, Inc., 2021. https:
doi:10.1073/pnas.1708274114. //datasets-benchmarks-proceedings.
16RethinkingEmpiricalResearchinMachineLearning
neurips.cc/paper/2021/hash/ Schneider,J.W. Nullhypothesissignificancetests.Amix-
084b6fbb10729ed4da8c3d3f5a3ae7c9- upoftwodifferenttheories: thebasisforwidespreadcon-
Abstract-round2.html. fusionandnumerousmisinterpretations. Scientometrics,
102(1):411–432,2015. doi:10.1007/s11192-014-1251-5.
Recht, B., Roelofs, R., Schmidt, L., and Shankar, V.
Do ImageNet classifiers generalize to ImageNet? In
Schwab,S.andHeld,L. Differentworldsconfirmatoryver-
Chaudhuri, K. and Salakhutdinov, R. (eds.), Proceed-
susexploratoryresearch. Significance,17(2):8–9,2020.
ings of the 36th International Conference on Machine
doi:10.1111/1740-9713.01369.
Learning, pp. 5389–5400, Long Beach, California,
USA,2019.PMLR. https://proceedings.mlr.
Sculley,D.,Snoek,J.,Wiltschko,A.,andRahimi,A. Win-
press/v97/recht19a.html.
ner’scurse? Onpace,progress,andempiricalrigor. In
Rendsburg, L., Heidrich, H., and von Luxburg, U. Net- 6th International Conference on Learning Representa-
GAN without GAN: From random walks to low-rank tions – Workshop, Vancouver, Canada, 2018. https:
approximations. In Daume´ III, H. and Singh, A.
//openreview.net/forum?id=rJWF0Fywf.
(eds.),Proceedingsofthe37thInternationalConference
Segebarth,D.,Griebel,M.,Stein,N.,vonCollenberg,C.R.,
on Machine Learning, pp. 8073–8082, Online, 2020.
PMLR. https://proceedings.mlr.press/ Martin,C.,Fiedler,D.,Comeras,L.B.,Sah,A.,Schoef-
v119/rendsburg20a.html. fler,V.,Lu¨ffe,T.,Du¨rr,A.,Gupta,R.,Sasi,M.,Lillesaar,
C.,Lange,M.D.,Tasan,R.O.,Singewald,N.,Pape,H.-
Riquelme,C.,Tucker,G.,andSnoek,J. DeepBayesianban- C.,Flath,C.M.,andBlum,R. Ontheobjectivity,reliabil-
ditsshowdown: AnempiricalcomparisonofBayesian ity,andvalidityofdeeplearningenabledbioimageanaly-
deepnetworksforThompsonsampling. In6thInterna- ses. eLife,9:e59780,2020. doi:10.7554/eLife.59780.
tionalConferenceonLearningRepresentations,Vancou-
ver, Canada, 2018. https://openreview.net/ Simonsohn, U., Nelson, L. D., and Simmons, J. P. P-
forum?id=SyYe6k-CW. curve: A key to the file-drawer. Journal of Exper-
imental Psychology: General, 143(2):534–547, 2014.
Roettger,T.B. Preregistrationinexperimentallinguistics:
doi:10.1037/a0033242.
applications,challenges,andlimitations. Linguistics,59
(5):1227–1249,2021. doi:10.1515/ling-2019-0048.
Sinha,K.,Forde,J.Z.,Samiei,M.,Ghosh,A.,Sutawika,L.,
Rubin,M. “Repeatedsamplingfromthesamepopulation?” andPanigrahi,S.S. AnnouncingMLRC2023. MLRe-
AcritiqueofNeymanandPearson’sresponsestoFisher. producibility Challenge, 2023, October 18. Retrieved
EuropeanJournalforPhilosophyofScience,10:42,2020. January 31, 2024, from https://reproml.org/
doi:10.1007/s13194-020-00309-6. blog/announcing_mlrc2023/.
Rubin, M. and Donkin, C. Exploratory hypothesis tests
Smaldino,P.E.andMcElreath,R. Thenaturalselectionof
can be more compelling than confirmatory hypothe-
badscience. RoyalSocietyOpenScience,3(9):160384,
sis tests. Philosophical Psychology, pp. 1–29, 2022.
2016. doi:10.1098/rsos.160384.
doi:10.1080/09515089.2022.2113771.
Saitta, L. and Neri, F. Learning in the “real Sonabend, R., Bender, A., and Vollmer, S. Avoiding c-
world”. Machine Learning, 30(2–3):133–163, 1998. hackingwhenevaluatingsurvivaldistributionpredictions
doi:10.1023/A:1007448122119. with discrimination measures. Bioinformatics, 38(17):
4178–4184,2022. doi:10.1093/bioinformatics/btac451.
Salzberg, S. L. On comparing classifiers: Pitfalls
to avoid and a recommended approach. Data Min- Steup,M. Epistemology. InZalta,E.N.(ed.),TheStanford
ing and Knowledge Discovery, 1:317–328, 1997. Encyclopedia of Philosophy. Metaphysics Research
doi:10.1023/A:1009752403260. Lab, Stanford University, Spring 2006 edition, 2006.
https://plato.stanford.edu/archives/
Santner,T.J.,Williams,B.J.,andNotz,W.I. TheDesign
spr2006/entries/epistemology/.
andAnalysisofComputerExperiments. SpringerSeries
in Statistics. New York: Springer, 2003. ISBN 978-1-
Steup, M. and Neta, R. Epistemology. In
4419-2992-1. doi:10.1007/978-1-4757-3799-8.
Zalta, E. N. (ed.), The Stanford Encyclope-
Scheel, A. M., Tiokhin, L., Isager, P. M., and Lakens, D. dia of Philosophy. Metaphysics Research Lab,
Why hypothesis testers should spend less time testing Stanford University, Fall 2020 edition, 2020.
hypotheses. PerspectivesonPsychologicalScience,16 https://plato.stanford.edu/archives/
(4):744–755,2021. doi:10.1177/1745691620966795. fall2020/entries/epistemology/.
17RethinkingEmpiricalResearchinMachineLearning
Strobl,C.andLeisch,F. Againstthe“onemethodfitsall VanMechelen,I.,Boulesteix,A.-L.,Dangl,R.,Dean,N.,
datasets”philosophyforcomparisonstudiesinmethod- Hennig,C.,Leisch,F.,Steinley,D.,andWarrens,M.J.
ologicalresearch. BiometricalJournal,66(1):2200104, Awhitepaperongoodresearchpracticesinbenchmark-
2024. doi:10.1002/bimj.202200104. ing: Thecaseofclusteranalysis. WileyInterdisciplinary
Reviews: DataMiningandKnowledgeDiscovery,13(6):
Szollosi,A.andDonkin,C. Arrestedtheorydevelopment:
e1511,2023. doi:10.1002/widm.1511.
Themisguideddistinctionbetweenexploratoryandconfir-
matoryresearch. PerspectivesonPsychologicalScience, Vanschoren, J., van Rijn, J. N., Bischl, B., and
16(4):717–724,2021. doi:10.1177/1745691620966796. Torgo, L. OpenML: Networked science in ma-
chine learning. SIGKDD Explorations, 15(2):
Tatman, R., VanderPlas, J., and Dane, S. A practical
49–60, 2013. doi:10.1145/2641190.2641198.
taxonomy of reproducibility for machine learning re-
https://datasets-benchmarks-
search. In Reproducibility in Machine Learning Work-
proceedings.neurips.cc/
shopatICML2018,Stockholm,Sweden,2018. https:
paper_files/paper/2021/hash/
//openreview.net/forum?id=B1eYYK5QgX.
c7e1249ffc03eb9ded908c236bd1996d-
The Turing Way Community. The Turing Way: A hand-
Abstract-round2.html.
bookforreproducible,ethicalandcollaborativeresearch.
vonLuxburg,U.,Williamson,R.C.,andGuyon,I. Clus-
Zenodo,2023. doi:10.5281/zenodo.7625728.
tering: Science or art? In Guyon, I., Dror, G.,
TransactionsonMachineLearningResearch. Transactions Lemaire, V., Taylor, G., and Silver, D. (eds.), Pro-
onMachineLearningResearch,n.d. RetrievedJanuary ceedings of ICML Workshop on Unsupervised and
31,2024,fromhttps://jmlr.org/tmlr/index. Transfer Learning, pp. 65–79, Bellevue, Washington,
html. USA,2012.PMLR. https://proceedings.mlr.
press/v27/luxburg12a.html.
Transactions on Machine Learning Research. Submis-
sion guidelines and editorial policies, n.d. Retrieved Wagenmakers, E.-J., Wetzels, R., Borsboom, D.,
January31,2024,fromhttps://jmlr.org/tmlr/ van der Maas, H. L. J., and Kievit, R. A. An
editorial-policies.html. agenda for purely confirmatory research. Perspec-
tives on Psychological Science, 7(6):632–638, 2012.
Trosten, D. J. Questionable practices in methodological doi:10.1177/1745691612463078.
deep learning research. In Proceedings of the North-
ern Lights Deep Learning Workshop, volume 4, 2023. Wasserstein, R. L., Schirm, A. L., and Lazar,
doi:10.7557/18.6804. N. A. Moving to a world beyond “p < 0.05”.
The American Statistician, 73(sup1):1–19, 2019.
Tukey,J.W. Exploratorydataanalysisaspartofalarger doi:10.1080/00031305.2019.1583913.
whole. InProceedingsoftheEighteenthConferenceon
theDesignofExperimentsinArmyResearch,Develop- Yousefi, M. R., Hua, J., Sima, C., and Dougherty, E. R.
mentandTesting,pp.1–10,Aberdeen,MD,1973.U.S. Reportingbiaswhenusingrealdatasetstoanalyzeclassi-
ArmyResearchOffice. https://apps.dtic.mil/ ficationperformance. Bioinformatics,26(1):68–76,2010.
sti/citations/AD0776910. doi:10.1093/bioinformatics/btp605.
Tukey, J. W. We need both exploratory and confirma- Zhang,C.,Bengio,S.,Hardt,M.,Recht,B.,andVinyals,O.
tory. The American Statistician, 34(1):23–25, 1980. Understanding deep learning (still) requires rethinking
doi:10.2307/2682991. generalization.CommunicationsoftheACM,64(3):107—
-115,2021. doi:10.1145/3446776.
Ullmann, T., Beer, A., Hu¨nemo¨rder, M., Seidl, T., and
Boulesteix,A.-L. Over-optimisticevaluationandreport- Zimek, A. and Filzmoser, P. There and back again: Out-
ing of novel cluster algorithms: An illustrative study. lierdetectionbetweenstatisticalreasoninganddatamin-
AdvancesinDataAnalysisandClassification,17(1):211– ingalgorithms. WileyInterdisciplinaryReviews: Data
238,2023. doi:10.1007/s11634-022-00496-5. Mining and Knowledge Discovery, 8(6):e1280, 2018.
doi:10.1002/widm.1280.
vandenGoorbergh,R.,vanSmeden,M.,Timmerman,D.,
andVanCalster,B. Theharmofclassimbalancecorrec- Zimmermann, A. Method evaluation, parameterization,
tionsforriskpredictionmodels: illustrationandsimula- and result validation in unsupervised data mining: A
tionusinglogisticregression. JournaloftheAmerican critical survey. Wiley Interdisciplinary Reviews: Data
MedicalInformaticsAssociation,29(9):1525–1534,2022. Mining and Knowledge Discovery, 10(2):e1330, 2020.
doi:10.1093/jamia/ocac093. doi:10.1002/widm.1330.
18RethinkingEmpiricalResearchinMachineLearning
Glossary
Bridgmanianideal. UsedbyChang(2004)todescribeaspecificnotionofoperationalization. ReferstoPercyWilliams
Bridgman(1882-1961),Nobellaureateinphysicsforhisworkonhigh-pressurephysics,whoalsomadecontributionstothe
philosophyofscience. OperationalanalysisisthetopicofhisbookTheLogicofModernPhysics,inwhichhearguesin
particularthat“[i]ngeneral,wemeanbyanyconceptnothingmorethanasetofoperations;theconceptissynonymouswith
thecorrespondingsetofoperations”(Bridgman,1927,p. 5). Thisstrictperspectiveonoperationalization(alsoreferredto
asoperationalism)hasattractedalotofcriticism,seeOperationalisminTheStanfordEncyclopediaofPhilosophy(Chang,
2021). Inparticular,Chang(2004,p. 148)pointsoutthatitbuildson“anoverlyrestrictivenotionofmeaning,whichcomes
downtoreductionofmeaningtomeasurement,which[Chang]refer[s]toasBridgman’sreductivedoctrineofmeaning.”
CargoCultScience. ThetermcargocultreferstosocialmovementsthatoriginatedinMelanesia: “Themodalcargocultwas
anagitationororganisedsocialmovementofMelanesianvillagersinpursuitof‘cargo’bymeansofrenewedorinvented
ritualactionthattheyhopedwouldinduceancestralspiritsorotherpowerfulbeingstoprovide”(Lindstrom,2023,p.1).
RichardPhillipsFeynman(1918-1988),theoreticalphysicistandNobellaureate,adaptedthetermtodescriberitualized
scientificpracticeswhich“followalltheapparentpreceptsandformsofscientificinvestigation,but[whichare]missing
somethingessential”(Feynman,1974,p.11).
Confirmatoryresearch. Alsoknownashypothesis-testingresearch,aimstotestpreexistinghypothesestoconfirmorrefute
existingtheories.Researchersdesignspecificstudiestoevaluatehypothesesderivedfromexistingknowledgeexperimentally.
Typically,thisinvolvesastructuredandpredefinedresearchdesign,apriorihypotheses,andoftenstatisticalanalysesto
drawconclusiveinferences. Itisawell-establishedterminmanyfieldsotherthanML.Forexample,generalreferences
are Schwab & Held (2020), Nosek et al. (2018), and Munafo` et al. (2017). Field-specific references include Jaeger &
Halliday(1998)orNilsenetal.(2020)forbiology,Wagenmakersetal.(2012)forpsychology,Kimmelmanetal.(2014)
forpreclinicalresearch,Roettger(2021)forlinguistics,orFoster(2024)foreducationalresearch. Thetermconfirmatory
mightappeartobeinconflictwiththeprincipleoffalsificationestablishedbyPopper(1959/2002). AccordingtoPopper,
scientifictheoriescannotbeconclusivelyconfirmed,onlyfalsified. Itisimportanttoemphasizethatconfirmatoryresearch
hasanarrowerscoperootinginNeyman-Pearsonstatisticaltestingtheory(seetheglossaryentryonTwohistoricallydistinct
typesoftestingtheory). Thistheoryprovidesaframeworkforastatisticallyjustifieddecisionbetweenanullhypothesisand
alternativehypothesisbasedontheavailabledata. Thehypothesistobeestablished(e.g.,thereisaneffect)isusuallystated
asthealternativehypothesisandconfirmationmeansrejectingthenullhypothesis(e.g.,thereisnoeffect)forthealternative.
Curricula recommendations for CS. The Final Report on Computer Science Curricula 2013 lists Intelligent Systems
(includingbasicsinML)asaCore(Tier2)topicbut“stillbelieve[s]itisnotnecessaryforallCSprogramstorequireafull
courseinprobabilitytheory[orstatistics]”(JointTaskForceonComputingCurricula,2013,p.50). Thishaschangedwith
thelatest(2023)versioninsofarasstatisticsisnowconsideredaCSCoretopicinMathematicalandStatisticalFoundations
(oneofseveralKnowledgeAreas)(JointTaskForceonComputingCurricula,2023).
Epistemic,epistemological. BothcomingfromtheGreekwordfor‘knowledge’or‘understanding’,thetermsaresometimes
usedsynonymouslyandsometimeswithdistinct,moreprecisemeanings. Ifthedistinctionismade,epistemicrelatesto
knowledgeitself,whileepistemologicalrelatesto“thestudyofthenatureandgroundsofknowledge”(Merriam-Webster,
n.d.),i.e.,epistemology. Forepistemology,anearlyeditionofTheStanfordEncyclopediaofPhilosophygivesthefollowing
definition: “Definednarrowly,epistemologyisthestudyofknowledgeandjustifiedbelief. [...] Understoodmorebroadly,
epistemologyisaboutissueshavingtodowiththecreationanddisseminationofknowledgeinparticularareasofinquiry”
(Steup,2006). Themostrecenteditionstatesinmoreabstracttermsthat“[m]uchrecentworkinformalepistemologyisan
attempttounderstandhowourdegreesofconfidencearerationallyconstrainedbyourevidence[...]”andthat“epistemology
seekstounderstandoneoranotherkindofcognitivesuccess[...]”(Steup&Neta,2020).
Epistemiciteration. Chang(2004)introducedtheconceptanddefinesitinhisglossary(p.253)asa“processinwhich
successivestagesofknowledge,eachbuildingontheprecedingone,arecreatedinordertoenhancetheachievementof
certainepistemicgoals. Itdifferscruciallyfrommathematicaliterationinthatthelatterisusedtoapproachacorrectanswer
thatisknown,oratleastinprincipleknowable,byothermeans.”Forthoroughdiscussions,seeChapters1(pp.46-48)and5.
Exploratoryresearch. Asalsospecifiedinthemainbodyofthepaper,referstoanopen-endedapproachthataimstogain
insightandunderstandinginaneworunexploredarea(incontrasttoconfirmatoryresearch). Itisoftenconductedwhen
littleisknownaboutthephenomenonunderstudy. Itinvolvesgatheringinformation,identifyingpatterns,andformulating
specifichypothesesforfurtherinvestigation.
19RethinkingEmpiricalResearchinMachineLearning
Hyperparametertuningstudies. Aimtofindthebest-performingconfigurationforanMLmodelclass,includingbaselines
(Feurer&Hutter,2019;Bischletal.,2023).Tunedmodelscanthenbecomparedmoreobjectivelyandfairly.Hyperparameter
tuning(orthelackofit)isanimportantsourceofvariationinbenchmarkstudies(Bouthillieretal.,2021)andhasbeen
shown to have a strong effect on the outcome of results, see for example the references in Bouthillier et al. (2021) or
ourintroduction. Treatingthehyperparameteroptimizationaspartoftheproblemofquantifyingtheperformanceofan
algorithmhasbeensuggestedbyBergstraetal.(2011)andBergstraetal.(2013).
Insight-oriented exploratory research. Refers to experimental research in ML that aims to gain insight, rather than
inventing/developinganewmethod. Itdoesnotnecessarilyinvolveaveryspecifichypothesistobepursued,butitisabout
improvingtheunderstandingandknowledgeofaproblem,a(classof)existingmethods,oraphenomenon.
Method-developingexploratoryresearch. ReferstoexperimentalresearchinMLcarriedoutintheprocessofdeveloping
anewMLmethod. Thiscanincludemethodcomparisonexperiments,butinparticularitreferstoexplorationthattakes
place during the development process. This may include, for example, trying different method variants or specifying
hyperparameterconfigurationsandimplementationdetails.
Operationalization. Chang (2004, p. 256) provides the following definition in his glossary: “The process of giving
operationalmeaningtoaconceptwheretherewasnonebefore. Operationalizationmayormaynotinvolvethespecification
ofexplicitmeasurementmethods.”Operationalmeaningrefersto“themeaningofaconceptthatisembodiedinthephysical
operationswhosedescriptioninvolvestheconcept.”ForathoroughdiscussionseeChapter4(pp. 197-219).
Replicability(vs. reproducibility). Thereisnoconsistentuseofthesetermsinthebroaderliterature(fordiscussions,e.g.,
seeBarba,2018;Plesser,2018;Gundersen,2021;Pineauetal.,2021). Weusethetermreproducibilityinanarrowtechnical
sense(seetheglossaryentryoncomputationalreproducibility). Incontrast,replicabilityheremeansarrivingatthesame
scientificconclusionsinabroadsense. ThisterminologyisinlinewiththeNationalAcademiesofSciences,Engineering,
andMedicine(2019). Intermsofthereliabilityofresults,itmeansthatreplicabilityismoreimportantthanreproducibility.
NotethatDrummond(2009),forexample,usesthetermsthereverseway.
Reproducibility(computational). Meansthattheprovidedcodetechnicallyachievesthesameresultontheprovideddata,
andnotthatcode,experimentaldesign,oranalysisareerror-freeandthatwecanqualitativelyreachthesameconclusionsfor
thesamegeneralquestionunderslightlydifferenttechnicalconditions. Itisthusnotasufficientconditionforreplicability.
NotethatTatmanetal.(2018)differentiatethreelevelsofreproducibility.
Twohistoricallydistincttypesoftestingtheory. ThisreferstotwoapproachestostatisticaltestingdevelopedbyRonald
AylmerFisher(1890-1962)ontheonesideandJerzyNeyman(1894-1981)andEgonSharpePearson(1895-1980)onthe
other. Onlytheformerincludesp-valuesandasingle(null)hypothesis. Thelatterincludestwohypothesesandhinges
on statistical power and Type I and II errors (Schneider, 2015, p. 413). More generally, Fisher’s approach is “[b]ased
on the concept of a ‘hypothetical infinite population’,” “[r]oots in inductive philosophy” and “[a]pplies to any single
experiment(shortrun),”whileNeyman-Pearson’sapproachis“[b]asedonaclearlydefinedpopulation,”“[r]ootsindeductive
philosophy,”and“[a]ppliesonlytoongoing,identicalrepetitionsofanexperiment,nottoanysingleexperiment(longrun)”
(Schneider,2015,p.415,Table1).
Validity. Notethatthereisnoconcisedefinitionoftheterm. Inpsychology,internalandexternalvalidityaredifferentiated
inparticular. AccordingtoCampell(1957,p.297)internalvalidityasksif“infacttheexperimentalstimulusmakesome
significantdifferenceinthisspecificinstance?”Externalvalidity,ontheotherhand,asks“towhatpopulations,settings,
andvariablescanthiseffectbegeneralized?”Theformerappearstobecloselyrelatedtoin-distributiongeneralization
performanceinML,thelattertoout-of-distributiongeneralization. Incontrast,TheStanfordEncyclopediaofPhilosophy
statesforExperimentsinPhysics(Franklin&Perovic,2023): “Physics,andnaturalscienceingeneral,isareasonable
enterprisebasedonvalid[emphasisadded]experimentalevidence,criticism,andrationaldiscussion.”Severalstrategiesthat
maybeusedtovalidateobservationsarespecified. Theseinclude: 1)“Experimentalchecksandcalibration,inwhichthe
experimentalapparatusreproducesknownphenomena”;2)“Reproducingartifactsthatareknowninadvancetobepresent”;
3)“Eliminationofplausiblesourcesoferrorandalternativeexplanationsoftheresult”;4)“Usingtheresultsthemselvesto
arguefortheirvalidity”;5)“Usinganindependentlywell-corroboratedtheoryofthephenomenatoexplaintheresults”;6)
“Usinganapparatusbasedonawell-corroboratedtheory”;7)“Usingstatisticalarguments.”However,itisemphasizedthat
“[t]herearemanyexperimentsinwhichthesestrategiesareapplied,butwhoseresultsarelatershowntobeincorrect[...].
Experimentisfallible. Neitherarethesestrategiesexclusiveorexhaustive. Nosingleoneofthem,orfixedcombinationof
them,guaranteesthevalidityofanexperimentalresult”(Franklin&Perovic,2023).
20