Assessing and Verifying Task Utility in LLM-Powered Applications
NegarArabzadeh1∗ SiqingHuo1 NikhilMehta3 QingyunWu3 ChiWang2
AhmedAwadallah2 CharlesL.A.Clarke1 JuliaKiseleva2
1UniverityofWaterloo
2MicrosoftResearch
3PennsylvaniaStateUniversity
4PurdueUniversity
Task
Abstract - Task Description
- Successful Execution A solution to be assessed
- Failed Execution
The rapid development of Large Language
Models (LLMs) has led to a surge in appli- Multi-
Criteria w/ Quantified dimensional
cationsthatfacilitatecollaborationamongmul- accepted Criteria Task Utility
tiple agents, assisting humans in their daily values for the
solution
tasks. However, a significant gap remains in
CriticAgent QuantifierAgent
assessingtowhatextentLLM-poweredappli-
VerifierAgent cationsgenuinelyenhanceuserexperienceand
taskexecutionefficiency. Thishighlightsthe Robustness Check
needtoverifyutilityofLLM-poweredappli- Updating
cations,particularlybyensuringalignmentbe- criteria
tweentheapplication’sfunctionalityandend-
Adversarial attack targeted solution
userneeds. WeintroduceAgentEval,anovel
frameworkdesignedtosimplifytheutilityver-
Figure 1: An overview of the AgentEval framework:
ificationprocessbyautomaticallyproposinga
CriticAgentcreatesasetofcriteriaandsuggestedval-
setofcriteriatailoredtotheuniquepurposeof
ues;QuantifierAgentquantifiesthecriteriaforaconsid-
anygivenapplication. Thisallowsforacom-
eredapplication;andVerifierAgentverifiesthecriteria
prehensiveassessment,quantifyingtheutility
basedonitsrobustness. TheoutputoftheQuantifierA-
ofanapplicationagainstthesuggestedcrite-
gentisamulti-dimensionalassessmentoftheutilityof
ria. Wepresentacomprehensiveanalysisof
theapplicationbasedonasuggestedlistofcriteriaand
theeffectivenessandrobustnessofAgentEval
theirevaluations.
fortwoopensourcedatasetsincludingMath
Problem solving and ALFWorld House-hold
relatedtasks. Forreproducibilitypurposes,we
thiscansignificantlyimpactitsimprovementjour-
makethedata,codeandallthelogspublicly
ney. Taking into account a range of applications,
availableathttps://bit.ly/3w3yKcS
itisunrealistictoassumebenchmarkingforevery
1 Introduction domain,includingbutnotlimitedtocodegenera-
tion(Liuetal.,2024),healthcare(Andrew,2024),
One of the long-lasting goals for intelligent
andmanyotherswhosedevelopmentwewitness
agents(Winograd,1972)isforthemtoseamlessly
every day (Wu et al., 2023). Moreover, directly
interactwithhumansinnaturallanguageandhelp
evaluating agentic applications poses challenges,
theirend-userswiththeirtasks,suchascompleting
ascurrentapproachespredominantlyrelyonend-
household tasks, math tutoring, and so on. The
to-end success metrics i.e., whether the applica-
rapid development of open-source libraries (Wu
tion accomplishes tasks (Shridhar et al., 2020b,
etal.,2023;Lietal.,2023a)helpsthatgoalbysim-
2019; Myers et al., 2023). However, understand-
plifyingthedevelopmentofLLM-poweredagentic
ing a user’s interactions with an application in-
applicationsforvarioususer-centeredtasks(Liang
volves much more than success alone (Kiseleva
et al., 2023b; Hong et al., 2023; Talebirad and
etal.,2022a,b;Zhangetal.,2023). Considermath
Nadiri, 2023). To ensure that the application’s
problemsolving,althoughitisimportantthatthe
behavior meets the requirements of the applica-
applicationsolvestheproblemcorrectly,itsability
tion developers, it is also crucial to assess its po-
topresentandexplainsolutionsbasedonvarious
tentialutility toend users (Dibia et al.,2023), as
criteria, such as completeness, conciseness, and
∗ WorkdoneduringaninternshipatMicrosoftResearch clarity, is crucial. Furthermore, success is not al-
4202
yaM
3
]LC.sc[
1v87120.5042:viXrawaysclearlydefinedforatask. Recognizingsuch and Eke, 2024), how they align to human pref-
criteria and being able to quantify them is essen- erences (Hendrycks et al., 2021a; Köpf et al.,
tialtoassesswhetherdeveloperrequirementsare 2024),theirrobustness(Wangetal.,2023b),and
beingsatisfiedandiftheapplicationbringsutility the knowledge, and reasoning capabilities they
totheend-users. Giventheobjectiveofassessing posses(Bianetal.,2023). Recentworkevaluates
arbitraryapplications,relyingsolelyonend-to-end LLMsonmorespecializedtasks,suchasmedical
successmetricsisuntenable,duetotheexpansive domain(Jinetal.,2019), multi-modaltasks(Mi-
rangeoftasksrequiringautomation. Thequestion alonetal.,2023;Bangetal.,2023),orasagentsin
ishowtodesignaflexiblemethodologytoassess interactiveenvironments(Liuetal.,2023).
thetaskutilityfordiversesetofapplications?
To bridge this gap, we introduce AgentEval, a 2.2 Usersatisfactionprediction
framework to gauge the utility of LLM-powered
Studies suggest that users interacting with var-
applications. Its goal is to assess the utility by
ious systems operate with specific utility func-
providingapplicationdeveloperswithinsightsinto
tions in mind (Li et al., 2020; Azzopardi et al.,
howthecurrentflowcanbecharacterized. Agen-
2018;Ahmadvandetal.,2022). Traditionally,met-
tEval builds on recent work showing that LLMs
rics defining user satisfaction were designed us-
canbeascalableandcost-effectivealternativeto
inglarge-scalecollectedbehavioralsignals(Kise-
humanevaluationforopen-endedtasks(Lietal.,
leva et al., 2014), and were tailored to specific
2023b). AgentEvalasillustratedinFig.1,consists
applications,suchasintelligentassistants(Kisel-
ofthethreefollowingagents,formallydefinedin
evaetal.,2016a,b),websearchengines(Williams
Sec. 3: (1) CriticAgent suggests the list of cri-
etal.,2016a,b;WilliamsandZitouni,2017),dia-
teria based on the task description and a pair of
logue systems (See et al., 2019), multi-turn con-
solutions, where one is preferred over the other
versations (Li et al., 2021) and general-purpose
one(e.g.,successfulandfailedexamples). Forin-
personalassistants(KiselevaanddeRijke,2017).
stance, for math problems, the criteria could be
Itwasdemonstratedthatassessingusers’satisfac-
beEfficiencyandClarityoftheproposedsolution;
tionrequiresgoesbeyondasinglemetric. Assuch,
(2) QuantifierAgent quantifies how the solution
here, we propose a flexible framework to assess
performsforeachcriterionandreturnstheutility
useranddeveloperrequirements,whichcaneven-
function, e.g. for math problems, if the ’ Clarity
tuallybeusedtoimprovetheapplicationflow.
is ‘not clear’, ‘moderately clear’, or ‘very clear’;
(3)VerifierAgentverifiesthequalityoftheassess-
2.3 UsingLLMsasevaluators
ment of the suggested criteria to make sure the
Morerecently, therehasbeenagrowingtrendin
criteriaareessential,robust,informativeandhave
utilizing LLMs as evaluators (Chiang and Lee,
highdiscriminativepower.
2023; Fu et al., 2023), such as for qualitative
Insummary,ourmaincontributionsare:
research (Bano et al., 2023), or summarization.
C1 IntroducingAgentEval,anovelframeworkthat
Specifically,Jainetal.(2023)studiedtheefficacy
leveragesLLM-poweredagentsasascalable
offew-shotpromptedLLMevaluatorsinevaluat-
andcost-effectivealternativetohumanevalu-
ing summaries that were written by other LLMs.
ations,toproducetaskutilitythroughthecol-
Similarly,Wangetal.(2023a)exploreifChatGPT
laborationofthreeagents: CriticAgent,Quan-
itselfcanbeusedasanevaluator,bypromptingitto
tifierAgentandVerifierAgent;and
scoretexts. Otherworks(Tjuatjaetal.,2023;Liu
C2 Anin-depthanalysisofAgentEvalrobustness
andSun,2023;ChiangandLee,2023)lookathow
fortwoapplicationsacrossdifferentsolutions,
LLMscanbeusedasproxiesforhumanbehavior,
thatcanbereplicatedonanunseendomain.
or work with humans, such as CoEval (Li et al.,
2 RelatedWork 2023b), which showed how LLMs can make hu-
manevaluationeasier. Panetal.(2024)alsoshow
2.1 EvaluationofLLMs
how LLM evaluators can help build models that
Prior work (Guo et al., 2023; Ziyu et al., 2023; increaseperformanceondownstreamtask. Build-
Chang et al., 2023; Liang et al., 2023a) has ex- ingontheabove,adifferentlineofworksidentify
tensively studied the evaluation of LLMs on var- weaknesses in single LLMs as direct evaluators
ious fronts: how ethically sound they are (Stahl (Huangetal.,2023),andproposetoimprovethem,suchasamulti-stepcalibrationframework(Wang
Tasks for LLM-powered
et al., 2023c). Given these drawbacks, recent applications
workhaslookedathowmultipleLLMagentscan Tasks where LLM-powered systems
can assist the end user
be used as evaluators. Chan et al. (2023), pro-
posedChatEval,amulti-agentteamthatdiscusses Success is not Success is clearly
clearly defined defined
andevaluatesresponsesfromagentsongeneration
When an agent assumes the role of
When success is clearly defined, it is
tasks(debate-style),leadingtotextthatalignswith an assistant, and success is not usually evaluated in a binary way
clearly defined
better human preferences. Similarly, Chern et al.
(2024)proposedamultipleagent-debate-assisted
Optimal Solution Multiple Solutions
meta-evaluationframework. Exists Exist
Building on these works, we propose an auto- There is a clear path to a Multiple trajectories are
successful event leading to success
matic multi-agent assessment of utility for arbi-
Figure2: Thetaxonomyoftasksassessment.
traryLLM-poweredapplications,toprovidedeep
insights for developers. Our framework can un-
AgentEvaliscurrentlyfocusedontaskswheresuc-
covercurrentflawsintheseapplications,andmay
cessisclearlydefinedandmultiplesuccessfulso-
lead to improvements in them, particularly if the
lutionsmayexist.
application flow changes after it is applied, and
Previous research on assistive agents suggests
thenitisre-used.
human pairwise preferences as one of the most
optimalassessments,i.e. whentheannotatorispre-
3 TaskUtility
sentedwithtwoagentssidebysideandaskedfor
Fig.2outlinesataxonomyoftargettasksforLLM- theirpreferences(Kiselevaetal.,2022b). Inthis
poweredapplications,intermsofsuccessmetrics. setupofside-by-sidepairwisecomparison,humans
Atahighlevel,thesetaskscanbecategorizedinto: tendtosuggestalistcriteria,explainingwhythey
1)Successisnotclearlydefined —Usersusethe preferoneagentovertheother. Forinstance,‘the
systeminanassistivemanner,seekingsuggestions first agent was faster’ or ‘the second agent con-
from it, rather than expecting it to solve the task. versesmorenaturally’. Thiscomparativesetupcan
Forexample,ausercanrequestthesystemtogen- guidehumanstocomeupwithalistofcriteriathat
erateanemail. Theuserusuallyusesthesystem’s helps to infer the utility of the task. With this in
responseasatemplate,whichcanlaterbeedited. mind,wedesignedAgentEval(Fig.1),byemploy-
Directlyevaluatingassistivetasksliketheseishard, ingLLMstohelpusunderstand,verify,andassess
particularly for online evaluation, or when deal- taskutility,namely:
ing with less well-defined tasks. One potential • CriticAgent: Thegoalofthisagentistosuggest
approach is to directly ask users how useful the asetofcriteriathatcanbeusedtoassesstaskutil-
helpwas, butthisisnotwell-calibrated(Borisov ity. TheCriticAgentisgivenataskdescription,
etal.,2018),hardtoquantify(Sepliarskaiaetal., as well as optionally several pairs of solutions,
2018),andexpensive. where preferably some are preferred over the
2)Successisclearlydefined —Itisclearwhether other ones, for instance, successful and failed
the system solved the task or not, for example, examples. CriticAgentwouldreturnasetofcri-
assisting with household tasks, where success is teriaC = {c ,...,c },whereeachcriterionc
1 n i
clearandmeasurable. Thiscategorycanbefurther is accompanied by a set of accepted values ω
dividedintotwosubcategories: asc : {ω }m . Forexample,forsolvingmath
i j j=1
• anoptimalsolutionexists—onlyonesuccessful problems, the CriticAgent generated accepted
outcomeispossible. Forexample,whenasking valuesandcriteriasuchasclarity,efficiency,and
anassistanttoturnonalight,successisclearly more-seeTab.1.
defined,asthereisonlyonewaytodoit. • QuantifierAgent: The goal of QuantifierAgent
• multiplesolutionsexist —Increasingly,weob- is to quantify each of the suggested criterion,
serve situations where multiple trajectories of to access the task utility of the system U , for
t
agentbehaviorcanleadtosuccess. Forexample, the end user. We define the Utility for task t
when asking an agent to suggest a food recipe, as: U (s) = {Q (s|c )}n . wheresrepresents
t i i i=1
successcouldbemultiplecuisinestastinggood, the task sample and Q(s|c .) is the quantifier
i
butperhapstherecipeshouldnotbeexpensive. output for sample s based on the criterion c .
iFor example, for math problem solving, given fromhighschoolcompetitions(Hendrycksetal.,
thegeneratedcriteriashowninTab.1,thesolu- 2021b). Eachproblemcomeswithastep-by-step
tion’s Accuracy could be quantified as “Incor- solutionandistaggedbydifficultylevels. Similar
rect”, “partially correct” or “correct”. Eligible tothemathproblemexperimentalsetupinWuetal.
quantifiedvaluesforquantificationprocessare (2023),wecarryoutevaluationson120problems
shownin“Acceptedvalues”columninTab.1 from level-5 by three different solutions. Due to
• VerifierAgent: Theremightbecaseswherenotall limitedspace,formoredetailsaboutthisdataset,
thecriteriasuggestedbyCriticAgenthelpassess wereferreaderstoAppendixA.2
utility. Somecriteriamightberedundant,while Solutions: Inestablishingsolutionsforthistaskto
othersmaynotaidindistinguishingperformance. assess,wedrawinspirationfromtheexperiments
VerifierAgentvalidatesthequalityofthecriteria showcased in (Wu et al., 2023). We evaluate the
intermsofrobustnessandtheirdistinguishability proposed methodology by AutoGen (Wu et al.,
ofnoisysamples. Essentially,itchecks(1)ifthe 2023), as well as Langchain ReAct (Yao et al.,
criteriacanbequantifiedrobustlyoverrepeated 2022)andaVanillasolverthatemploysGPT-4to
samples,and(2)ifQuantifierAgentcanidentify tackle the task. These solutions have previously
the adversarial attacked targeted samples from demonstrated promising and competitive perfor-
the original ones. If the sanity checks do not mance(Wuetal.,2023). InSec.5.2,weexplore
pass,VerifierAgentwillupdatethelistofcriteria, how the measured performance with AgentEval
toendupwithasetofrobust,stable,informative correlateswiththegroundtruths.
anddistinguishablecriteriaforassessment.
4.2 ALFWorldHouseholdTask
Finally,wenotethatAgentEvalallowsforincorpo-
ratingahumanintheloopintheroleofadomain Dataset: ALFWorld presents a set of language-
expert. Forinstance,CriticAgentcouldbereplaced basedinteractivedecision-makingtaskswithinsim-
byahumanexpertwhoeithercomesupwiththe ulated household environments (Shridhar et al.,
relevant criteria or helps VerifierAgent verify the 2020b). ALFWorld is the first interactive paral-
usefulcriteriaandfilterouttheunessentialones. lel environment that aligns text descriptions and
commandswithphysicallyembodiedroboticsimu-
4 DatasetsandSolutions lation. Finally,thedataset’sinclusionofhousehold
chorestomoreintricateproblem-solvingscenarios,
Thissectionprovidesanoverviewofthedatasets
provides a comprehensive testbed for evaluating
utilized in our study i.e., Math problem solving
theadaptabilityofmulti-agentsystems. Formore
andALFWorldhouseholdtask. Themathdataset
informationaboutthedatasetandexamplesofthe
is chosen for its widespread usage and complex
testcases,wereferthereaderstoAppendixA.3.1.
problem-solvingscenariosthatarefundamentalin
Solutions: AsforthesolutionstoassessforALF-
evaluating the effectiveness. ALFWorld dataset
WorldHouseholdtasks,similarto(Wuetal.,2023),
offersascenarioinvolvingmulti-turninteractions
weconsiderReAct(Yaoetal.,2022)aswellasAu-
withinamoderatelyapproximatedmulti-modalen-
toGen with two agents and AutoGen with three
vironment. Each dataset plays a critical role in
agents (Wu et al., 2023). In Appendix A.3.2, we
evaluatingdifferentaspectsofAgentEval’scapabil-
discussinmoredetailsthesolutionsunderassess-
ities,fromhandlingcomplextheoreticalproblems
ment. Weassessandcomparetheperformanceof
tonavigatingreal-worldscenarios. Inbothtasks,
thesethreesolutionsusingAgentEval.
althoughsuccessisclearlydefined,multiplesolu-
tions exist for accomplishing the objectives. An 5 Experiments
exampleofMathproblemsolvingandALFWorld
taskisshowninAppendixA.1. Duetospace,we 5.1 ImplementationDetails
reportallexperimentsaboutMathproblemsolving Forallexperiments,weuseGPT-4version0613,
inthemainpaperandwekeepalltheexperiments accessed through Azure OpenAI services, as the
relatedtoALFWorlddatasetintheAppendixA.3. LLMmodelandthetemperatureof0. AgentEval
utilizesAutoGen(Wuetal.,2023)forimplemen-
4.1 MATHProblemSolving
tation, since it provides a versatile environment
Dataset: TheMATHdatasetisasubstantialcollec- whereagentscanbefinelytunedandcustomized
tionof12,500challengingmathematicsproblems based on specific application needs. This is cru-CClalarirtiyty
Error_analysis Table1: VerificationCriteriaforMathProblems
ReAct- Success Vanilla Solver- Success Autogen- Success
ReAct- Failed Vanilla Solve - Failed Autogen- Failed
Criteria Description AcceptedValues
Clarity Theeaseofunderstandingthesteps, –NotClear(0)
explanations,andlanguageusedinthe –ModeratelyClear(1)
solution. –VeryClear(2)
Efficiency Theuseofoptimalmethodsor –Inefficient(0)
approachestosolvethemathproblem. –ModeratelyEfficient(1)
–Efficient(2)
Error Theidentificationanddescriptionof –NotAddressed(0)
Analysis possibleerrorsormisconceptionsinthe –PartiallyAddressed(1)
mathproblem-solvingprocess. –WellAddressed(2)
Completeness Qualityofcodeintermsofefficiencyand –Incomplete(0)
elegance –MostlyComplete(1)
–Complete(2)
Clarity Efficiency Error_analysis Completeness
Criteria
Figure3: AgentEvalassessmentofthreesolutionson
Weobservethatinmostcases,thesuccessfuland
mathproblemscategorizedbysuccessandfailedcases.
failedcasesaredistinguished,evenwith95%inter-
valconfidenceonallthesuccessandfailedcases.
cialformaintainingtheflexibilitytohandleawide
When examining the differences between suc-
range of applications. We tried to avoid much
cessfulandfailedcasesamongthethreesolutions,
promptengineeringandtriedtokeepeachagent’s
wenotethatnotallsuccessfulcasesareassessed
instructionsasifweareinstructinghumanannota-
identically,norareallfailedcasesquantifiedwith
tors. Moreover, another advantages of using Au-
toGen for implementation of AgentEval is that it thesameperformance. Thiscanbeinterpretedto
meanthateventhoughtwosolutionsmightbothbe
has the flexibility to involve human in the loop.
successful, onemightperformbetterorworsein
Eachagentcouldbereplacedbyahumanannota-
certaincriteria,suchasclarityorefficiency. This
tor. Wefurtherprovideallthepromptsusedinour
observation provides us with valuable additional
experimentsinourGitrepository.
insights, especially for the developers of the pro-
5.2 AgentEvalforMathProblems posed solutions, and goes beyond reporting the
WhenexecutingtheCriticAgentforMathproblem effectivenessofaapplicationbyonescalarvalue
solving,wefirstobtainasetofcriteriaaspresented e.g.,successrate.
inTab.1. Then,theQuantifierAgentistaskedwith
quantifyingeachcriterion,basedontheaccepted 6 RobustnessAnalysisandVerification
values. WepresenttheoutcomeofQuantifierAgent
Inthissection,wefirstanalyzetherobustnessof
measuringperformanceofthreesolutionsonthis
AgentEval,thenfurtherinvestigatehowVerifierA-
taskinFig.3. Notably,weseethatAgentevaldoes
gentcanincreasethestabilityofourassessment.
notquantifythethreesolutionsasiftheyperform
equally well across the different criteria. For in-
6.1 DiversityofCriteria
stance, while all three solutions leverage GPT-4
as the underlying language model, Autogen out- Here,ourmaingoalistostudythediversityofthe
performs ReAct and Vanilla GPT-4 in terms of suggestedcriteria. Weinvestigatetheextentinputs
accuracy. This observation, while confirmed by toAgentEval(Fig.1suchas‘TaskDescription’and
previousstudies(Wuetal.,2023),extendstosolu- ‘Successful/FailedExecutions’)contributetoCrit-
tioncompletenessandefficiencyaswell. icAgentforcreatingamorediversesetofcriteria.
As depicted in Fig. 3, the error analysis range Todoso,weusetwodistinctmethods,withCrit-
ofquantifiedvaluesdiffersfromothermetrics. We icAgentgenerating(1)“task-based”criteriasolely
scrutinizetheresultsbycategorizingthemintosuc- fromthetaskdescription,and(2)“solution-based”
cessfulandfailedcases. AutoGen,VanillaSolver criteria,derivedfromboththetaskandexecution
andReActsolutionsareeachpresentedinorange, examples. Forexample,asolutiontoamathemati-
blueandgreenrespectively,wherethedarkerbars calproblem,mightsatisfycriteriasuchas‘Accu-
representtheperformanceonsuccessfulcasesand racy’ and ‘Clarity’, independent of the solution.
lighterbarsrepresentthefailedcases. Thediffer- However,whenadditionaltoolssuchascodingare
encebetweenthedarkandlightbarofeachcolor, usedtosolvetheproblems,additionalcriterialike
verifyAgentEval’sperformance,asweexpectthat ‘CodeEfficiency’maybeintroducedtothesetof
eachpositivecriteriashouldbequantifiedhigher criteria. This makes sense, since the application
forsuccessfulcasescomparedtotheirfailedcases. leveragedcodingtosolvemathproblems.
eulaV
egarevA
ssenetelpmoC
Efficiency
eulaV
egarevAFigure4: Task-basedvssolution-basedcriteriaforMathproblems. Errorbarshowthe95%confidenceinterval.
Fig.4displaysthenumberofuniquecriteriaex- the task-based approach, although this varies by
tractedformathematicalproblemsolvingintask- thecreativityofthemodel. Forexample,whilethe
based mode, and three different solution-based AutoGensolutiondemonstratesthehighestdiver-
approaches. To keep the balance between com- sity,task-basedmethodsyieldmoreuniquecriteria
putationalcostsandanalyzingtherobustness,we thanReActandVanillaSolver. Anotherinteresting
conducted50runsoftheCriticAgentwithdifferent observationisthatrepeatingtheCriticAgent will
seeds. Subsequently, for N = 50 iterations, we eventuallyleadtoaconvergenceinthenumberof
randomly select M ≤ 50 samples, as shown on criteria. ThissuggeststhattheCriticAgent’sability
thex-axisofFig.4,andpresenttheaveragenum- tocreatenewcriteriawilldiminish,convergingto
berofuniqueextractedcriteria,alongwithits95% analmostfinitelistofcriteria,whichwillreduce
confidenceintervalafterrepeatingthisprocess50 thecostaswell.
times. We note that because the total pool of cri-
teriaincludes50iterationsintotal,theconfidence 6.2 Verification
intervalsbecomesmallerwhenM getclosertothe
AsoutlinedinSec.3andillustratedinFig.1,the
maximumnumberofsamplesi.e.,50
VerifierAgent’s primary role is to ensure the se-
Togaindeeperinsightsintodiversityofcriteria,
lectedcriteriaareeffectivetowardevaluatingthe
wetookacloserlookatthemtostudyiftheyare
utilityfortheend-user,whilemaintainingrobust-
trulyuniqueortowhatextenttheyhavesimilarities.
ness and high discriminative power. To achieve
ThisisimportanttodetermineifCriticAgent,when
this,theVerifierAgentundertakestwomainactions:
continually generating criteria, will always pro-
(1) Criteria Stability: The criteria should be es-
ducenewcriteria,orifitwilleventuallyconverge
sential and robust, meaning they should not be
toaset. Wenotedthatsomecriteriaaresimilarbut
redundantandweshouldbeabletoquantifythem
wordeddifferently. Forexample,‘ProblemCom-
stablyifwerepeatedlyquantifyitforanindividual
plexity’vs. ‘ProblemDifficulty’or‘TimeTaken’
solution, showing no divergence. As such, Veri-
vs. ‘TimetoCompletion’. Tab.3intheAppendix
fierAgent enhances the criteria by iterating over
listssuchinstances. Toconsolidatethesimilarcri-
the generation and quantification phases. It then
teriaandreducenoiseinthenumberofuniquecri-
consolidatesthesecriteriabyidentifyingandelim-
teriaandredundancy,inspiredfrompreviouswork
inatingredundancies, followedbyevaluatingthe
(Liu et al., 2022; Vahtola et al., 2022; Reimers
dispersionofthedistributionofthequantifiedcri-
and Gurevych, 2019), we employ a pre-trained
teria. Thisstepmodifiesthecriteria,ensuringthat
language model fine-tuned for paraphrasing1, to
onlythemostrobustcriteriaareretained.
measurethesemanticsimilarityofcriteriadescrip-
(2) Discriminative Power: A reliable evaluation
tions. Usingathresholdτ,weclassifypairswith
should detect and withstand noise. To test that,
cosinesimilaritygreaterthanτ assemi-identical
weproposetouseadversarialexamplesandthen
onesandselectoneofthemastherepresentative
assessthesystem’sabilitytodifferentiatebetween
ofthepair. Fig.4illustratestheimpactofdifferent
thesecompromisedexamplesandstandardcases.
τ values(0.7,0.85,1)onthediversityofcriteria.
Shouldthesystemfailtodistinguisheffectively,it
A threshold of 1 means no filtering occurs. This
indicates that the criteria are insufficient for reli-
analysis shows that the solution-based approach
ableassessmentundervariedconditions.
haspotentialtoproducemorediversecriteriathan
Wenotethatbothstepsinvolveatunablethresh-
1https://bit.ly/3UgsYOp oldthatcanbeadaptedbasedonapplicationneeds,Figure6: ∆sumofmeancoefficientofvariationacross
Figure 5: Distribution of QuantifierAgent output on
allcriteriawithincreasingnumberofseeds.
AutoGen results on successful (dark blue) and failed
(lightblue)casesondifferentcriteria.
tionally, as explained in Section 6.1, we remove
similarandredundantcriteriausingpre-trainedlan-
ensuringflexiblecriteriavalidation. Theproposed
guagemodels,thusobtainingacomprehensivelist
methodology for VerifierAgent is summarized in
ofcriteria. Therefinedcriteriaafter50repeatsare
Algorithm1intheAppendix.
detailedinTab.4intheAppendix.
Now,weaimtodeterminethestabilityofthese
6.2.1 CriteriaStability
criteriathroughrepeatedquantifications. Ourgoal
Our goal here is to explore the stability of crite-
is to identify criteria that maintain consistent re-
ria and robustness of the quantifier for having a
sults without significant divergence, even when
more essential, robust and stable set of criteria.
quantifiedmultipletimes. Usingthisconsolidated
WespecificallyevaluatetheQuantifierAgent’sro-
list,wemeasurethedispersionofquantifiedresults
bustnessusingcriteriaformathematicalproblems
using the coefficient of variation, a standardized
(Table1),conducting50repeatsofrunswithdif-
metric that facilitates comparison across various
ferentseedson120problems(Section4.1). Ideal
test cases when QuantifierAgent quantifies them.
expectedoutcomesincludeconsistentperformance
Giventheconsolidatedlistofcriteria,weusethe
across all criteria on all the repeats. Fig. 5 il-
QuantifierAgenttoquantifyvarioustestcasesand
lustrates the distribution of quantifier values for
report the coefficient of variation as a measure
bothfailed(darkblue)andsuccessfulcases(light
ofthedispersionoftheQuantifierAgent’soutputs
blue) across all criteria through box plots. The
withrespecttoeachcriterionacrossdifferentseeds
morerobustacriterion,thenarrowertherangeof
andreportthemeancoefficientofvariationacross
quantifiedperformance(narrowerboxplots). Also,
allsamples. werunQuantifierAgentwith50seeds
thelessoverlapbetweenthesuccessfulandfailed
and plot the change (∆) in the sum of mean co-
boxes,thehigherthedistinguishabilityofthecrite-
efficientofvariationacrossallcriteriaagainstthe
ria. Weobservethatallfourcriteria,except‘error
number of seeds, in Figure 6. For each criterion,
analysis’ allow for easy differentiation between
wecomputetheabsolutedifferencewiththemean
successfulandfailedcases. Additionally,somecri-
coefficientofvariationcalculatedwhenusingn−1
teriaprovetobemorerobustcomparedtoothers.
seeds,summinguptheabsolutedifferencesacross
Webelievethatsuchananalysisofthequantifier
all criteria. According to the plot, after approxi-
agent’s performance will yield valuable insights
mately18seeds,themagnitudeofmeancoefficient
forenhancingreliability,trustworthiness,andex-
ofvariationstabilizesandbecomesrathertrivial. In
plainabilityinperformanceevaluation. Adetailed
almostallcases,themeancoefficientofvariation
examination of the stability of each criterion, es-
is around or below 0.5, which is relatively small,
peciallyhowtheydifferentiatebetweensuccessful
suggestingthatQuantifierAgentisquiterobust.
andfailedcases,isprovidedinAppendixA.4.2.
Further,torefineandexpandthecriteriasetwith- 6.2.2 DiscriminativePower
outredundancy,weoperatetheCriticAgentmulti- Itiscrucialtoensurethequalityofquantification
pletimesi.e.,weexecuteCriticAgent50timeswith of each criterion. Ideally, this validation would
variedseeds. Thecriteriaarethensummarizedinto involvecomparisonswithknownpairwisesamples,
one list of useful criteria using the LLM. Addi- wheresampleS+ isdefinitivelysuperiortoS− fora given criterion. If the evaluator also confirms
superiority of S+ w.r.t S−, it has robust quantifi-
cation. However,duetorapidexpansionofLLM-
poweredapplications,obtainingannotateddatafor
manytasksisoftenunfeasible. Therefore,wepro-
pose using synthetically altered versions of sam-
ples for verification. Let us assume we have an
alternative disturbed version of sample S, which
iscalledS′. AssumingsampleS ismorelikelyto
outperformitsdisturbedversionS′,ourassessment
shouldconfirmthisassumptionbyassigningbetter
quantifiedperformanceS incomparisontoS′. In
experimentswithmathematicalproblems,weintro- Figure 7: Assessment of original and disturbed solu-
ducedrandomnoisebyremovingportionsofthe tionsonMathdataset(discriminativepowerstudy).
solutionsentencesfromAutoGen, VanillaSolver,
andReAct’sresultsrespectively,expectingthatcri- modify and update the criteria based on to what
terialike‘Completeness’or‘Clarity’wouldshow extendtheypassthetwotests,i.e.,ifthemeancoef-
be higherin S than in S′. We disturbed solutions ficientofvariationisbelowaspecificthresholdand
by removing 25% of the sentences and assessed thepercentageofadversarialtestingithaspassed.
theQuantifierAgent’sperformance. Asshownin The VerifierAgent will then update the criteria if
Fig.7,criteriameasuringaspectslike‘Clarity’and necessary. WebelievethathavingaVerifierAgent
‘Completeness’werelowerindisturbedsolutions would help continuously updating the criteria as
(lighterbars), confirmingQuantifierAgent’shigh needed because, by improving the systems, we
discriminativepowerandeffectiveness. mayrequirenewcriteriathatwerenotpreviously
Wehavealreadyfilteredoutthecriteriathatwere necessaryforutilityassessment.
unstable,i.e.,thosethathadahighmeanstandard
deviationanddispersionwhenbeingquantifiedin 7 ConclusionsandFutureWork
theprevioussection. Wereporttheresultsofthe
WeintroducedtheAgentEvalframework,designed
QuantifierAgentquantifyingdifferencesbetween
to swiftly gauge the utility of arbitrary LLM-
originalanddisturbedsamplesonthecomprehen-
powered agentic applications. Our framework
sive set of criteria shown in Appendix, as shown
leverages recent findings suggesting LLMs as a
inFig.13forthemathproblem-solving. Inmost
scalable and cost-effective alternative to human
cases,theQuantifierAgentquantifiesthedisturbed
evaluationsforopen-endedtasks. AgentEvalcon-
output to be worse than the original task output.
sists of three agents: CriticAgent suggests crite-
WebelieveanalyzingtheQuantifierAgent’sperfor-
ria based on task descriptions and executions of
mancewillenhancethereliability,trustworthiness,
the applications, QuantifierAgent quantifies how
andexplainabilityinevaluations..
well the application flow aligns with these crite-
6.2.3 VerifierAgent ria, and VerifierAgent modifies the list of criteria
Aftermodifyingthelistofcriteria(Sec.6.2.1),we ifneeded. Thisframeworkiscustomizable,adapt-
have developed a stable and robust list of crite- able,andcanoperateinvariousmodes,employing
riathattheQuantifierAgentcanreliablyquantify. combinations of LLMs, human inputs, and tools.
Further, we also proposed a method for assess- We believe that suggested AgentEval’s utility ex-
ing whether the criteria can distinguish between tends beyond immediate performance. It can un-
noise-adversariallyattackedsamplesandtheorigi- covernewsystemcapabilitiesovertimeandadapt
nalones. Thesetwotestswillserveasinputforthe to changes in user needs tracked by developers.
VerifierAgent (described in Algorithm 1), which AgentEval can also enable developers to assess
canalsohaveitsthresholdtunedfordifferentap- the alignment between application behavior and
plications. For instance, one might prioritize the suggesteduserrequirements,providingthemwith
stability of the criteria, while another may value insightsintoareasforimprovement. Insummary,
thediscriminativepoweroftheAgentEvalforspe- ourcontributionsincludeintroducingtheAgentE-
cificapplications. Assuch,theVerifierAgentwill valframework,andconductingarobustanalysisofitsperformanceacrossvariousdatasetsandbase- Our AgentEval system has a variety of uses in
lines. AgentEval represents a significant step to- realworldsettings,suchasimprovingapplications
wardsassessingLLM-poweredapplications. forendusersorhelpingdevelopers. However,we
cautionthatitmustbeusedcarefully,astheoutputs
8 LimitationsandEthics
are from a ML model and can have real world
consequences,ifusedincorrectly.
8.1 Limitations
Theseandmanyotherrelatedissuesareimpor-
Here, we discuss some limitations of the Agen-
tantaspectstoconsiderwhendeployingasystem
tEvalframework. Firstly,theperformanceofthe
likeAgentEvalintherealworld.
AgentEval is highly dependent on the quality of
theoutputlogsoftheapplications. Flawsorlimita-
tionsintheseoutputscansignificantlyimpactthe References
framework’sabilitytoaccuratelyassessutility.
Ali Ahmadvand, Negar Arabzadeh, Julia Kiseleva,
Secondly,ourexperimentswereconductedex-
Patricio Figueroa Sanz, Xin Deng, Sujay Jauhar,
clusively with closed-source LLMs, specifically Michael Gamon, Eugene Agichtein, Ned Friend,
with GPT-4. This may limit the generalizability etal.2022. Supportingcomplexinformation-seeking
tasks with implicit constraints. arXiv preprint
of our findings. Plans to include a broader array
arXiv:2205.00584.
ofLLMs,includingopen-sourcemodels,arecon-
sideredforfuturestudiestovalidateandpossibly Albert Andrew. 2024. Potential applications and im-
plicationsoflargelanguagemodelsinprimarycare.
enhancetherobustnessofourconclusions. Addi-
FamilyMedicineandCommunityHealth,12(Suppl
tionally, the tests conducted were limited to spe-
1).
cific scenarios within math problem solving and
household tasks. Expanding the diversity of test LeifAzzopardi,PaulThomas,andNickCraswell.2018.
Measuringtheutilityofsearchengineresultpages:
scenarioscouldhelpinunderstandingthebroader
aninformationforagingbasedmeasure. InThe41st
applicabilityoftheframework.
International ACM SIGIR conference on research
Thirdly, while AgentEval employs a novel &developmentininformationretrieval,pages605–
methodologyleveragingLLMstoestimateutility, 614.
theabsenceofhumanevaluationinourvalidation
YejinBang,SamuelCahyawijaya,NayeonLee,Wen-
process could be viewed as a drawback. Human liangDai,DanSu,BryanWilie,HolyLovenia,Ziwei
evaluationsprovideuniqueinsights,especiallyin Ji,TiezhengYu,WillyChung,QuyetV.Do,YanXu,
subjectiveaspectsofutilitythatautomatedsystems andPascaleFung.2023. Amultitask,multilingual,
multimodalevaluationofchatgptonreasoning,hal-
might overlook. However, such evaluations are
lucination,andinteractivity.
oftencost-prohibitiveandlogisticallychallenging,
restricting our ability to implement them within MuneeraBano,DidarZowghi,andJonWhittle.2023.
Exploring qualitative research using llms. arXiv
this study. Especially do developers of agentic
preprintarXiv:2306.13298.
LLM-poweredapplicationswhoneedsinsightsfast
astheygowiththedeployments. NingBian,XianpeiHan,LeSun,HongyuLin,Yaojie
Lastly,asLLMtechnologiesevolve,thecriteria Lu,andBenHe.2023. Chatgptisaknowledgeable
butinexperiencedsolver: Aninvestigationofcom-
andmetricsusedforevaluationmayneedtobeup-
monsenseprobleminlargelanguagemodels. arXiv
datedorrevised. Whatworksforassessingcurrent
preprintarXiv:2303.16421.
LLMsmaynotholdasthesemodelsbecomemore
advanced. Continuous updates to the evaluation Alexey Borisov, Julia Kiseleva, Ilya Markov, and
MaartendeRijke.2018. Calibration: Asimpleway
framework will be necessary to keep pace with
toimproveclickmodels. InProceedingsofthe27th
technologicaladvancements. ACMInternationalConferenceonInformationand
KnowledgeManagement,pages1503–1506.
8.2 Ethics
Chi-MinChan,WeizeChen,YushengSu,JianxuanYu,
To the best of our knowledge, we did not violate
WeiXue,ShanghangZhang,JieFu,andZhiyuanLiu.
anycodeofethicswiththeexperimentsdoneinthis 2023. Chateval: Towardsbetterllm-basedevaluators
paper. We reported technical details and results, throughmulti-agentdebate. InTheTwelfthInterna-
tionalConferenceonLearningRepresentations.
withdetailsinthemainpaper,Appendix,andcode
release. Ourexperimentalresultsareanoutcome
Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu,
ofaMachineLearningmodel. Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi,CunxiangWang,YidongWang,etal.2023. Asur- SameerJain,VaishakhKeshava,SwarnashreeMysore
veyonevaluationoflargelanguagemodels. ACM Sathyendra, Patrick Fernandes, Pengfei Liu,
TransactionsonIntelligentSystemsandTechnology. Graham Neubig, and Chunting Zhou. 2023.
Multi-dimensional evaluation of text summariza-
SteffiChern,EthanChern,GrahamNeubig,andPengfei tion with in-context learning. arXiv preprint
Liu. 2024. Can large language models be trusted arXiv:2306.01200.
for evaluation? scalable meta-evaluation of llms
QiaoJin,BhuwanDhingra,ZhengpingLiu,WilliamW
as evaluators via agent debate. arXiv preprint
Cohen,andXinghuaLu.2019. Pubmedqa:Adataset
arXiv:2401.16788.
forbiomedicalresearchquestionanswering. arXiv
Cheng-HanChiangandHung-yiLee.2023. Canlarge
preprintarXiv:1909.06146.
languagemodelsbeanalternativetohumanevalua-
Julia Kiseleva, Eric Crestan, Riccardo Brigo, and
tions? arXivpreprintarXiv:2305.01937.
Roland Dittel. 2014. Modelling and detecting
changesinusersatisfaction. InProceedingsofthe
Marc-AlexandreCôté,AkosKádár,XingdiYuan,Ben
23rdACMInternationalConferenceonConference
Kybartas,TavianBarnes,EmeryFine,JamesMoore,
onInformationandKnowledgeManagement,pages
Matthew Hausknecht, Layla El Asri, Mahmoud
1449–1458.
Adada, et al. 2019. Textworld: A learning envi-
ronmentfortext-basedgames. InComputerGames: JuliaKiselevaandMaartendeRijke.2017. Evaluating
7thWorkshop,CGW2018,HeldinConjunctionwith personalassistantsonmobiledevices. arXivpreprint
the 27th International Conference on Artificial In- arXiv:1706.04524.
telligence, IJCAI 2018, Stockholm, Sweden, July
13, 2018, RevisedSelectedPapers7, pages41–75. Julia Kiseleva, Ziming Li, Mohammad Aliannejadi,
Springer. Shrestha Mohanty, Maartje ter Hoeve, Mikhail
Burtsev, Alexey Skrynnik, Artem Zholus, Alek-
VictorDibia,AdamFourney,GaganBansal,Forough sandrPanov, KavyaSrinet, ArthurSzlam, Yuxuan
Poursabzi-Sangdeh,HanLiu,andSaleemaAmershi. Sun,KatjaHofmann,Marc-AlexandreCôté,Ahmed
2023. Aligningofflinemetricsandhumanjudgments Awadallah, Linar Abdrazakov, Igor Churin, Putra
ofvalueforcodegenerationmodels. Manggala,KataNaszadi,MichielvanderMeer,and
TaewoonKim.2022a. Interactivegroundedlanguage
JinlanFu,See-KiongNg,ZhengbaoJiang,andPengfei understandinginacollaborativeenvironment: Iglu
Liu.2023. Gptscore: Evaluateasyoudesire. arXiv 2021. In Proceedings of the NeurIPS 2021 Com-
preprintarXiv:2302.04166. petitionsandDemonstrationsTrack,volume176of
ProceedingsofMachineLearningResearch,pages
ZishanGuo,RenrenJin,ChuangLiu,YufeiHuang,Dan 146–161.PMLR.
Shi,LinhaoYu,YanLiu,JiaxuanLi,BojianXiong,
Julia Kiseleva, Alexey Skrynnik, Artem Zho-
DeyiXiong,etal.2023. Evaluatinglargelanguage
lus, Shrestha Mohanty, Negar Arabzadeh, Marc-
models: A comprehensive survey. arXiv preprint
AlexandreCôté,MohammadAliannejadi,Milagro
arXiv:2310.19736.
Teruel,ZimingLi,MikhailBurtsev,MaartjeterHo-
eve,ZoyaVolovikova,AleksandrPanov,YuxuanSun,
DanHendrycks,CollinBurns,StevenBasart,Andrew
KavyaSrinet,ArthurSzlam,AhmedAwadallah,Se-
Critch,JerryLi,DawnSong,andJacobSteinhardt.
ungeunRho,TaehwanKwon,DanielWontaeNam,
2021a. Aligningaiwithsharedhumanvalues. Pro-
FelipeBivortHaiek,EdwinZhang,LinarAbdraza-
ceedingsoftheInternationalConferenceonLearn-
kov,GuoQingyam,JasonZhang,andZhibinGuo.
ingRepresentations(ICLR).
2022b. Interactivegroundedlanguageunderstanding
inacollaborativeenvironment:Retrospectiveoniglu
DanHendrycks,CollinBurns,SauravKadavath,Akul
2022 competition. In Proceedings of the NeurIPS
Arora, Steven Basart, Eric Tang, Dawn Song, and
2022CompetitionsTrack,volume220ofProceed-
Jacob Steinhardt. 2021b. Measuring mathemati-
ingsofMachineLearningResearch,pages204–216.
cal problem solving with the math dataset. arXiv
PMLR.
preprintarXiv:2103.03874.
JuliaKiseleva,KyleWilliams,AhmedHassanAwadal-
Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng
lah,AidanCCrook,ImedZitouni,andTasosAnas-
Cheng,JinlinWang,CeyaoZhang,ZiliWang,Steven
tasakos. 2016a. Predicting user satisfaction with
KaShingYau,ZijuanLin,LiyangZhou,etal.2023.
intelligentassistants. InProceedingsofthe39thIn-
Metagpt:Metaprogrammingformulti-agentcollabo-
ternationalACMSIGIRconferenceonResearchand
rativeframework. arXivpreprintarXiv:2308.00352.
DevelopmentinInformationRetrieval,pages45–54.
Jie Huang, Xinyun Chen, Swaroop Mishra, JuliaKiseleva,KyleWilliams,JiepuJiang,AhmedHas-
Huaixiu Steven Zheng, Adams Wei Yu, Xiny- sanAwadallah,AidanCCrook,ImedZitouni,and
ingSong,andDennyZhou.2023. Largelanguage TasosAnastasakos.2016b. Understandingusersatis-
models cannot self-correct reasoning yet. In The factionwithintelligentassistants. InProceedingsof
Twelfth International Conference on Learning the2016ACMonConferenceonHumanInformation
Representations. InteractionandRetrieval,pages121–130.Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xu-
Sotiris Anagnostidis, Zhi Rui Tam, Keith Stevens, anyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding,
Abdullah Barhoum, Duc Nguyen, Oliver Stan- Kaiwen Men, Kejuan Yang, et al. 2023. Agent-
ley, Richárd Nagyfi, et al. 2024. Openassistant bench: Evaluating llms as agents. arXiv preprint
conversations-democratizinglargelanguagemodel arXiv:2308.03688.
alignment. AdvancesinNeuralInformationProcess-
ingSystems,36. YanchenLiu,TimoSchick,andHinrichSchütze.2022.
Semantic-orientedunlabeledprimingforlarge-scale
Guohao Li, Hasan Abed Al Kader Hammoud, Hani languagemodels. arXivpreprintarXiv:2202.06133.
Itani, Dmitrii Khizbullin, and Bernard Ghanem.
2023a. Camel: Communicativeagentsfor"mind" Grégoire Mialon, Clémentine Fourrier, Craig Swift,
exploration of large scale language model society. Thomas Wolf, Yann LeCun, and Thomas Scialom.
arXivpreprintarXiv:2303.17760. 2023. Gaia: abenchmarkforgeneralaiassistants.
arXivpreprintarXiv:2311.12983.
Qintong Li, Leyang Cui, Lingpeng Kong, and Wei
Bi.2023b. Collaborativeevaluation: Exploringthe VivekMyers,AndreWangHe,KuanFang,HomerRich
synergy of large language models and humans for Walke,PhilippeHansen-Estruch,Ching-AnCheng,
open-ended generation evaluation. arXiv preprint Mihai Jalobeanu, Andrey Kolobov, Anca Dragan,
arXiv:2310.19740. andSergeyLevine.2023. Goalrepresentationsfor
instructionfollowing: Asemi-supervisedlanguage
interfacetocontrol. InProceedingsofThe7thCon-
Ziming Li, Julia Kiseleva, Alekh Agarwal, Maarten
ferenceonRobotLearning,volume229ofProceed-
de Rijke, and Ryen W White. 2020. Optimizing
ings of Machine Learning Research, pages 3894–
interactivesystemsviadata-drivenobjectives. arXiv
3908.PMLR.
preprintarXiv:2006.12999.
JiayiPan,YichiZhang,NicholasTomlin,YifeiZhou,
ZimingLi,DookunPark,JuliaKiseleva,Young-Bum
SergeyLevine,andAlaneSuhr.2024. Autonomous
Kim,andSungjinLee.2021. Deus: Adata-driven
evaluation and refinement of digital agents. arXiv
approachtoestimateusersatisfactioninmulti-turn
preprintarXiv:2404.06474.
dialogues. arXivpreprintarXiv:2103.01287.
NilsReimersandIrynaGurevych.2019. Sentence-bert:
Percy Liang, Rishi Bommasani, Tony Lee, Dimitris
Sentenceembeddingsusingsiamesebert-networks.
Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian
arXivpreprintarXiv:1908.10084.
Zhang,DeepakNarayanan,YuhuaiWu,AnanyaKu-
mar,BenjaminNewman,BinhangYuan,BobbyYan,
AbigailSee,StephenRoller,DouweKiela,andJason
CeZhang,ChristianCosgrove,ChristopherD.Man-
Weston. 2019. What makes a good conversation?
ning,ChristopherRé,DianaAcosta-Navas,DrewA.
howcontrollableattributesaffecthumanjudgments.
Hudson, Eric Zelikman, Esin Durmus, Faisal Lad-
arXivpreprintarXiv:1902.08654.
hak, Frieda Rong, Hongyu Ren, Huaxiu Yao, Jue
Wang,KeshavSanthanam,LaurelOrr,LuciaZheng,
AnnaSepliarskaia,JuliaKiseleva,FilipRadlinski,and
Mert Yuksekgonul, Mirac Suzgun, Nathan Kim,
MaartendeRijke.2018. Preferenceelicitationasan
NeelGuha,NiladriChatterji,OmarKhattab,Peter
optimization problem. In Proceedings of the 12th
Henderson, QianHuang, RyanChi, SangMichael
ACMConferenceonRecommenderSystems,pages
Xie, Shibani Santurkar, Surya Ganguli, Tatsunori
172–180.
Hashimoto, Thomas Icard, Tianyi Zhang, Vishrav
Chaudhary,WilliamWang,XuechenLi,YifanMai,
Mohit Shridhar, Jesse Thomason, Daniel Gordon,
Yuhui Zhang, and Yuta Koreeda. 2023a. Holistic
YonatanBisk,WinsonHan,RoozbehMottaghi,Luke
evaluationoflanguagemodels.
Zettlemoyer, and Dieter Fox. 2019. ALFRED: A
benchmarkforinterpretinggroundedinstructionsfor
Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, everydaytasks. CoRR,abs/1912.01734.
Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng Tu,
and Shuming Shi. 2023b. Encouraging divergent Mohit Shridhar, Jesse Thomason, Daniel Gordon,
thinking in large language models through multi- YonatanBisk,WinsonHan,RoozbehMottaghi,Luke
agentdebate. Zettlemoyer, and Dieter Fox. 2020a. Alfred: A
benchmarkforinterpretinggroundedinstructionsfor
Alex Liu and Min Sun. 2023. From voices to valid- everyday tasks. In Proceedings of the IEEE/CVF
ity: Leveraginglargelanguagemodels(llms)fortex- conferenceoncomputervisionandpatternrecogni-
tualanalysisofpolicystakeholderinterviews. arXiv tion,pages10740–10749.
preprintarXiv:2312.01202.
Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté,
FangLiu,YangLiu,LinShi,HoukunHuang,Ruifeng Yonatan Bisk, Adam Trischler, and Matthew
Wang,ZhenYang,andLiZhang.2024. Exploring Hausknecht.2020b. Alfworld:Aligningtextandem-
andevaluatinghallucinationsinllm-poweredcode bodiedenvironmentsforinteractivelearning. arXiv
generation. arXivpreprintarXiv:2404.00971. preprintarXiv:2010.03768.BerndCarstenStahlandDamianEke.2024. Theethics QingyunWu,GaganBansal,JieyuZhang,YiranWu,
ofchatgpt–exploringtheethicalissuesofanemerg- Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang,
ingtechnology. InternationalJournalofInformation Xiaoyun Zhang, and Chi Wang. 2023. Auto-
Management,74:102700. gen: Enablingnext-genllmapplicationsviamulti-
agent conversation framework. arXiv preprint
YasharTalebiradandAmirhosseinNadiri.2023. Multi- arXiv:2308.08155.
agentcollaboration: Harnessingthepowerofintelli-
gentllmagents. arXivpreprintarXiv:2306.03314. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak
Shafran,KarthikNarasimhan,andYuanCao.2022.
Lindia Tjuatja, Valerie Chen, Sherry Tongshuang
React: Synergizingreasoningandactinginlanguage
Wu, Ameet Talwalkar, and Graham Neubig. 2023. models. arXivpreprintarXiv:2210.03629.
Do llms exhibit human-like response biases? a
case study in survey design. arXiv preprint Chi Zhang, Penglin Cai, Yuhui Fu, Haoqi Yuan, and
arXiv:2311.04076. ZongqingLu.2023. Creativeagents: Empowering
agents with imagination for creative tasks. arXiv
TeemuVahtola,MathiasCreutz,andJörgTiedemann.
preprintarXiv:2312.02519.
2022. Itisnoteasytodetectparaphrases: Analysing
semanticsimilaritywithantonymsandnegationus- ZhuangZiyu,ChenQiguang,MaLongxuan,LiMingda,
ingthenewsemantonegbenchmark. InProceedings HanYi,QianYushan,BaiHaopeng,ZhangWeinan,
of the Fifth BlackboxNLP Workshop on Analyzing andTingLiu.2023. Throughthelensofcorecompe-
and Interpreting Neural Networks for NLP, pages tency: Surveyonevaluationoflargelanguagemod-
249–262. els. In Proceedings of the 22nd Chinese National
ConferenceonComputationalLinguistics(Volume
JiaanWang,YunlongLiang,FandongMeng,Zengkui
2: Frontier Forum), pages 88–109, Harbin, China.
Sun,HaoxiangShi,ZhixuLi,JinanXu,JianfengQu,
ChineseInformationProcessingSocietyofChina.
andJieZhou.2023a. Ischatgptagoodnlgevaluator?
apreliminarystudy. InProceedingsofthe4thNew
FrontiersinSummarizationWorkshop,pages1–11.
Jindong Wang, Xixu HU, Wenxin Hou, Hao Chen,
RunkaiZheng,YidongWang,LinyiYang,WeiYe,
Haojun Huang, Xiubo Geng, Binxing Jiao, Yue
Zhang, and Xing Xie. 2023b. On the robustness
ofchatGPT:Anadversarialandout-of-distribution
perspective. InICLR2023WorkshoponTrustworthy
andReliableLarge-ScaleMachineLearningModels.
PeiyiWang,LeiLi,LiangChen,DaweiZhu,Binghuai
Lin,YunboCao,QiLiu,TianyuLiu,andZhifangSui.
2023c. Largelanguagemodelsarenotfairevaluators.
arXivpreprintarXiv:2305.17926.
KyleWilliams, JuliaKiseleva, AidanCCrook, Imed
Zitouni, Ahmed Hassan Awadallah, and Madian
Khabsa.2016a. Detectinggoodabandonmentinmo-
bilesearch. InProceedingsofthe25thInternational
ConferenceonWorldWideWeb,pages495–505.
KyleWilliams, JuliaKiseleva, AidanCCrook, Imed
Zitouni, Ahmed Hassan Awadallah, and Madian
Khabsa. 2016b. Is this your final answer? evalu-
ating the effect of answers on good abandonment
inmobilesearch. InProceedingsofthe39thInter-
national ACM SIGIR conference on Research and
DevelopmentinInformationRetrieval, pages889–
892.
KyleWilliamsandImedZitouni.2017. Doesthatmean
you’re happy? rnn-based modeling of user inter-
action sequences to detect good abandonment. In
Proceedingsofthe2017ACMonConferenceonIn-
formationandKnowledgeManagement,pages727–
736.
TerryWinograd.1972. Understandingnaturallanguage.
Cognitivepsychology,3(1):1–191.A Appendix Table2: VerificationCriteriaforALFWorldHoushold-
ingTasks.
A.1 TaskExamples
Criteria Description AcceptedValues
InFig.8and9,wedisplayexamplesofMathprob- TaskUnder- Howwelltheparticipantwasableto –Excellent(4)
standing comprehendtheproblemsetandfollow –Good(3)
lems and ALFWorld house-holding tasks solved
thetaskinstructions –Average(2)
–Poor(1)
withAutoGen. –Terrible(0)
Plan Theabilityoftheparticipanttostrategize –Excellent(4)
Making andmakeaplanfortacklingthetask. –Good(3)
A.2 MathProblemSolvingBenchmark –Average(2)
–Poor(1)
–Terrible(0)
For math problem solving, although success is
Action Theparticipant’sdecision-makingskills –Excellent(4)
clearlydefined,multiplesolutionsexistforaccom- Decision inchoosingtherightactiontoperform. –Good(3)
–Average(2)
plishingtheobjectives. TheMATHdataset,orig- –Poor(1)
–Terrible(0)
inally is a substantial collection of 12,500 chal- Action Howeffectivelytheparticipantisableto –Excellent(4)
Execution executethechosenaction. –Good(3)
lenging mathematics problems from high school –Average(2)
–Poor(1)
competitions(Hendrycksetal.,2021b). Eachprob- –Terrible(0)
Responseto Howwelltheparticipantadaptshis/her –Excellent(4)
lemcomeswithastep-by-stepsolution,enabling Feedback nextstepsbasedonthefeedbackfromthe –Good(3)
environment –Average(2)
modelstolearnhowtogeneratebothderivations
–Poor(1)
–Terrible(0)
andexplanations. Thedatasetcoversawiderange
Correctness Thecorrectnessoftheactionperformed –Correct(1)
ofmathematicalsubjectsandistaggedbydifficulty ofAction bytheparticipantwithrespecttothe –Incorrect(0)
availableactionsandthecurrentcontext
levels, offering a nuanced measure of model per- Useof Whethertheparticipantusesthe –Appropriate(1)
Terminate ’TERMINATE’commandappropriately –Inappropriate(0)
formanceacrossvariousaspectsofmathematical
problem-solving.
This dataset is particularly suitable for testing
multi-agentsystemsforseveralreasonincluding:
(i)TheproblemsintheMATHdatasetarenotsim-
plecomputationsbutrequireadeepunderstanding
for testing AI and multi-agent systems. This
ofmathematicalconcepts,heuristics,andproblem–
benchmark is particularly suited for such evalu-
solving strategies. (ii) Since the dataset includes
ationsbecausefirst,ALFWorldisthefirstinterac-
step-by-stepsolutions,itallowsfortheassessment
tiveparallelenvironmentthatalignstextdescrip-
ofanagent’sabilitytolearnandreasonthrougha
tions and commands with physically embodied
problem,notjustitsabilitytoarriveatthecorrect
robotic simulation. It extends two prior works:
answer. (iii)Thevarietyofsubjectsanddifficulty
TextWorld, an engine for interactive text-based
levelsintheMATHdatasetenablesacomprehen-
games, and ALFRED, a large-scale dataset for
siveevaluationofasystem’sversatilityandadapt-
vision-language instruction following in embod-
abilityindifferentmathematicaldomainswhichis
ied environments (Shridhar et al., 2020a; Côté
crucialformulti-agentsystemsthatareexpected
et al., 2019). The cross-modality framework of
tooperateacrossarangeofscenarios.
this benchmark allows for a variety of embodied
Similartomathproblemexperimentalsetupin
taskswithcorrespondingtext-basedcounterparts,
Wu et al. (2023), we carry out two experimental
allowingagentstobetrainedandevaluatedinboth
evaluationswhichinvolves120problemsfromthe
the language and embodied world. In addition,
mostchallengingcategory,andincludes20prob-
ALFWorldsupportsthedevelopmentofagentsthat
lemseachfromsixdifferentcategories,ofnumber
canreasonbothabstractlyandexecuteactionscon-
theory,countingandprobability,prealgebra,alge-
cretely, mimicking human-like decision-making
bra,intermediatealgebra,andprecalculus.
processesinvaryingcontexts. Finally,thedataset’s
inclusionofawiderangeoftasks,fromhousehold
A.3 ALFWorldHouse-holdingTask
chorestomoreintricateproblem-solvingscenarios,
A.3.1 ALFWorldDataset
provides a comprehensive testbed for evaluating
ALFWorld, presents a set of language-based in- theadaptabilityandproblem-solvingcapabilities
teractivedecision-makingtaskswithinsimulated of AI and multi-agent systems. In general, the
household environments (Shridhar et al., 2020b). datasetallowsagentstoexplore,interact,andlearn
This benchmark is distinguished by its diver- inanabstractlanguageenvironmentbeforedealing
sity of tasks, offering a comprehensive platform withthecomplexitiesofanembodiedenvironment."problem": "Howmanypositiveandnegativeintegersis12amultipleof?"
"level": "Level5"
"type": "Prealgebra"
"response_with_ans":
"messages": [
{
"content": "Howmanypositiveandnegativeintegersis12amultipleof?",
"role": "user"
},
{
"content": "Todeterminehowmanypositiveandnegativeintegers12isamultipleof,weneedto
findthedivisorsof12. Thenwewilldoublethenumberofdivisors,aseachpositivedivisorhasa
correspondingnegativedivisor. Let’suseaPythoncodesnippettofindallthedivisorsof12and
countthem.",
num = 12
1
divisors = [i for i in range(1, num + 1) if num \% i == 0]
2
positive_divisors_count = len(divisors)
3
negative_divisors_count = positive_divisors_count
4
total_divisors_count = positive_divisors_count +
5
(cid:44)→ negative_divisors_count
print(f"Positive divisors of 12: {divisors}")
6
divisors_negative = [-x for x in divisors]
7
print(f"Negative divisors of 12: {divisors_negative}")
8
print(f"Total divisors count: {total_divisors_count}")
9
Execute this code snippet to find the divisors of 12 and count how many positive and negative
integers12isamultipleof.
"role": "assistant"
}
],
"time": 17.360238790512085
Figure8: AnexampleofMathProblemsolvingsamplewithsolutiongeneratedbyAutoGen
A.3.2 SolutionsforALFWorldbenchmark whichcanleadtorepetitiveerrorsandgettingstuck
inloops.InAutoGenwiththreeagents,aground-
AsforthesolutionstoassessforALFWorldHouse- ing agent is provided just for the sake of critical
hold tasks, similar to (Wu et al., 2023), we con- common sense knowledge whenever the system
siderReAct(Yaoetal.,2022)aswellasAutoGen exhibitsearlysignsofrecurringerrors.
with two agents and AutoGen with three agents
A.3.3 AgentEvalResultsforALFWorld
(Wu et al., 2023). ReAct is an agent that oper-
ates within the ALFWorld environments and is TostudythegeneralizabilityofAgentEval,were-
responsibleforsuggestingplansandexecutingac- peattheexperimentsin5.2forAlfWorld,inwhich
tions. On the other hand, AutoGen Two-Agent real-worldhouseholdenvironmentsareemulated
SystemconsistsofanLLM-backedassistantagent throughtextualinterfaces(Shridharetal.,2020b).
responsible for suggesting plans, and an execu- Weprovidethecriteriacreatedforthistaskaswell
toragentresponsibleforexecutingactionsinthe astheresultsforthreesolutionsofthistaskinTab.
ALFWorldenvironments. BothReActandthisso- 2andFig.10,respectively. Followingtheextrac-
lutionoccasionallystruggleswithleveragingbasic tionofasetofcriteriaasdetailedinTab. 2,these
commonsenseknowledgeaboutthephysicalworld, criteriaarepassedtotheQuantifierAgentforquan-{
{ "content": "Perform actions and interact with a household to solve a task. At the beginning of
your interactions, you will be given the detailed description of the current environment and
(cid:44)→
your goal to accomplish. For each of your turn, you should choose from two actions: "think"
(cid:44)→
or "Action". If you choose "think", you should first think about the current condition
(cid:44)→
and plan for your future actions, and then output your action in this turn. Your output must
(cid:44)→
strictly follow this format:"think: your thoughts."
(cid:44)→
"Action: your next action\\n"; If you choose "ACTION", you should directly output the action in
this turn. Your output must strictly follow this format:"ACTION: your next action".
(cid:44)→
After each of your turn, the environment will give you immediate feedback based on which you
should plan your next few steps. if the envrionment output "Nothing happened", that means the
(cid:44)→
previous action is invalid and you should try more options.
(cid:44)→
Reminder:
1. the action must be chosen from the given available actions. Any actions except provided
available actions will be regarded as illegal.
(cid:44)→
2. Take the target household immediatly after you find it.
3. Reply 'TERMINATE' only under two circumstances: a). The task has given you clear instructions
to return 'TERMINATE' b). The task seems insolvable.\\n Here are two examples.\nYou are in
(cid:44)→
the middle of a room. Looking quickly around you, you see a cabinet 13, a cabinet 12, a
(cid:44)→
cabinet 11, a cabinet 10, a cabinet 9, a cabinet 8, a cabinet 7, a cabinet 6, a cabinet 5, a
(cid:44)→
cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a countertop 1, a
(cid:44)→
diningtable 1, a drawer 1, a fridge 1, a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a
(cid:44)→
shelf 1, a sinkbasin 1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1,
(cid:44)→
and a toaster 1.\nYour task is to: put a hot apple in fridge.\n",
(cid:44)→
"role": "user"},
{ "content": "THOUGHT: The task is to put a hot apple in fridge. So i need to first find an
apple and heat it. First I need to find an apple. An apple is more likely to appear in
(cid:44)→
diningtable (1), coffeetable (1), fridge (1), drawer (1), cabinet (1-13), garbagecan (1). I
(cid:44)→
can check one by one, starting with fridge 1.\n ACTION: go to diningtable 1\n",
(cid:44)→
"role": "assistant"},
{ "content": "On the diningtable 1, you see a apple 1, a bread 1, a fork 3, a fork 2, a fork 1,
a mug 2, a peppershaker 3, a plate 2, a pot 1, a soapbottle 3, a spatula 1, a spoon 3, a
(cid:44)→
spoon 2, a spoon 1, a winebottle 3, and a winebottle 2.\n",
(cid:44)→
"role": "user"},
{ "content": "ACTION: take apple 1 from diningtable 1\n",
"role": "assistant"},
{ "content": "You pick up the apple 1 from the diningtable 1.\n",
"role": "user"},
{ "content": "THOUGHT: I noticed that there is a microwave 1 in the room, i will use it to heat
the apple.\n ACTION: go to microwave 1\n",
(cid:44)→
"role": "assistant"},
...
...
{ "content": "You open the microwave 1. The microwave 1 is open. In it, you see a egg 1.",
"role": "user"
},
{ "content": "ACTION: heat mug 2 with microwave 1",
"role": "assistant"},
{ "content": "You heat the mug 2 using the microwave 1.Task success, now reply TERMINATE\n",
"role": "user"},
{ "content": "TERMINATE",
"role": "assistant"},
{ "content": "TERMINATE",
"role": "user"}
}
Figure9: AnexampleofALFWorldHouseholdingtaskfrom“Pick,Heat,thenPlace”category.Figure10: AgentEvalassessmentofthreedifferentsolutionsonALFWorldhouse-holdingTaskscategorizedby
successandfailedcases.
tificationoneachsample. Figure10presentsthere- Following the extraction of a set of criteria as
sultsforthreeintroducedsolutions: AutoGenwith detailed in Tab 2, these criteria are passed to the
twoagents,AutoGenwiththreeagents,andReAct, QuantifierAgentforquantificationoneachsample.
onthe134-testsetfrom(Wuetal.,2023). Further, Figure10presentstheresultsforthreeintroduced
wealsoverifythemeasuredperformanceofAgen- solutions: AutoGenwith2agents,AutoGenwith
tEval,bycomparingthefailed/successcasesinthe 3agents,andReAct,onthe134-testsetfrom(Wu
rightplotofFigure10. Asconfirmedhereandin et al., 2023). It is important to note that all crite-
mathproblemsolving,AgentEvalisclearlyableto ria, except “Use of TERMINATE” and “Correct-
distinguishbetweendifferentsolutionsintermsof nessofAction”employafive-levelgradingsystem,
differentcriterion. whilethesetwocriteriaarebinary. Fromthisfigure,
itisevidentthatReACTperformsnotablyworse
WeprovideanexampleofAgentEvalappliedto
across all criteria, while AutoGen with 2 agents
theALFWorldhouse-holdingtask,asmentioned
and3agentsdemonstratecompetitiveperformance.
in Sec. 5.2 in which real-world household envi-
Wealsocategorizesthe134gamesintogroupsof
ronments is emulated through textual interfaces
failedandsuccessfulones. SimilartoFig.3,darker
(Shridhar et al., 2020b). When running the Crit-
colors represent performance in successful cases
icAgent on this task, it identified specific criteria
for each solution, while lighter colors represent
suchas“Taskunderstanding”,“Planmaking”and
performanceinfailedcases. AutoGen3-agent,Au-
“ResponsetoFeedback”asoutlinedinTab.2. We
toGen2-agent,andReActarerepresentedbyblue,
consultedresearchersdeeplyinvolvedwiththese
green, and orange, respectively. For most crite-
tasks,andtheirexpertiseconfirmedthatthesecri-
ria, thedistinctionbetweenfailedandsuccessful
teriaarecriticallyrelevantandsignificantsimilar
casesisclear,evenwithina95%confidenceinter-
to(Lietal.,2023b). Forexample,giventhatthese
val. However, for certain criteria, such as “Task
tasks are language-based and require interactive
understanding”allsolutions,whethertheyfailedor
decision-making,anagentinALFWorldistasked
succeeded,exhibitverysimilarperformance. This
with high-level objectives, such as placing a hot
couldbeinterpretedaseither(1)allsolutionshave
appleinthefridge,andmustnavigateandinteract
agoodunderstandingofthetask,eveniftheyfailto
withasimulatedhouseholdenvironmenttoachieve
completeit,(2)thiscriterionmayberedundant,as
these objectives. Therefore, criteria displayed in
itdoesnotprovideadditionalinformationamong
Tab. 2 satisfy the assessment of this task. While
thesethreesolutionsor(3)theQuantifierAgentis
the criteria are pretty self-descriptive, about the
unabletoscorethecriterioninameaningfulway.
criterion“UseofTERMINATE”wenotethatthe
Werefrainfromconcludingwhichcriteriaaremost
agentispromptedtousetheterm“TERMINATE”
suitableforthisspecifictask. Instead,weempha-
upontaskcompletion,whichiscloselycorrelated
sizetheimportanceofconductingamorein-depth
withtasksuccess.Figure11: QuantifierRobustnessoncriteriaofMathProblemSolvingproblem. Eachbarrepresenttheaverage
performanceofsuccess(darkblue"//")andfailed(lightblue“\\”)casesand95%intervaloneachsetisshaded
acrosstheaveragepoint. Thetwoplotsareoverlaid.
Table3: Examplepairsofsimilarcriteria. ducted50runsofthequantifieragentonthe120
problemsdescribedinSection4.1. Ourexpectation
-ProblemDifficulty: Thecomplexityofthemathproblemthat
istoobserveconsistentquantifiedperformancefor
hasbeensolved.
-ProblemComplexity:Thelevelofdifficultyoftheproblem. each of the criteria. In Fig. 11, we present the
-Innovativeness: Thenoveltyandcreativityintheapproachto distribution of quantified performance across 50
solvetheproblem
runsforbothsuccessfulandfailedcases,focusing
-Innovation: Theabilitytosolveaproblemusingauniqueor
creativemethodnotcommonlyknown. onthefiveselectedcriteria. Aconsistentlyhorizon-
-TimeTaken:Thetimetakentosolvetheproblem.
talperformancetrendindicatesgreaterrobustness
-TimetoCompletion: Theamountoftimetakentosolvethe
problemcompletely inthequantifier,whereasmorefluctuationsinthe
-Understandability:Theclarityandeaseofcomprehensionofthe figuresuggestlessrobustnessandanoisierperfor-
solutionprovided.
manceoftheagent.
-Readability:Howeasyitistocomprehendtheprovidedsolution.
Asshownintheresults,forfouroutofthefive
analysisofperformancebeyondsuccessrates,tai- generatedcriteria,weconsistentlyobservesteady
loredtoone’sgoalsandapplicationrequirements. performance. Notonlydothesuccesscasesconsis-
Later,weshowthathowusingVerifierAgentcould tentlyoutperformthefailedcases,buttheirperfor-
be helpful in identifying criteria with higher dis- mancealsofallswithinasimilarrangeacrossruns.
criminativepowerandmorerobustness. However,whenitcomestothe“erroranalysis”cri-
terion, we observe a more variable performance
A.4 RobustnessAnalysis
of the quantifier. It does not consistently predict
A.4.1 SimilarCriteria onegroup(successorfailed)toperformbetterthan
AsexplainedinSection6.1,theremightbecases theother,andthequantifier’sperformancevaries
wheresomecriteriaarepointingtothesamecon- acrossdifferentruns. ThissuggeststhattheAgen-
ceptswithdifferentwordings. Inthesecases,we tEval tool may not exhibit promising robustness
needtomergethesimilarcriteriatoavoidhaving forthisparticularcriterion. Theunderlyingissues
redundant criteria. Table 3 shows some of these couldbeeitherthecriterionitselflacksclarityand
examples. appropriateness for the task, or the QuantifierA-
gentstrugglestoquantifythiscriterioneffectively.
A.4.2 QuantifierRobustness In either case, it is advisable to either modify or
TostudytherobustnessoftheQuantifierAgent,we eliminatethiscriteriontoenhancetrustworthiness
selectedaspecificsubsetofcriteriarelatedtomath- andreliability. WefurthershowthatVerifierAgent
ematicalproblems,asdetailedinTable1,andcon- isdesignedtotakecareofsuchcriteria.Werecognizetheimportanceofthoroughlyin- Algorithm1VerifierAgent
vestigatingtherobustnessofeachcriterioninquan- 1: fori = 1,2,...,50do
tificationstudies. Thisanalysisiscrucialasitsheds 2: RunCriticAgentwithseed = itoobtaina
lightonthestabilityofeachcriterion. Moreover, setofcriteriaC
i
whengroundtruthsareavailable,suchasincases
3: endfor
of success versus failure, they provide a bench- 4: Obtainsummarized_criteriabyusinganother
marktovalidateourassessments. Additionally,it LLMagenttosummarizeC ,C ,...,C .
1 2 50
isimportanttoacknowledgethatnotallcriteriaex- 5: fori = 1,2,...,18do
hibitthesamelevelofrobustness. Thisvariability 6: forallsinS do
demandscarefulconsiderationduringevaluations, 7: RunQuantifierAgentwithseed = ion
especially given the non-deterministic nature of samples
LLMs. Suchawarenessisessentialtoensurethe
8: endfor
reliabilityandaccuracyofourassessmentsinthe
9: endfor
dynamicfieldofLLMs. 10: forallcritinsummarized_criteriado
11: forallsinS do
A.5 VerifierAgent
12: Computethecoefficientofvariationof
Algorithm1showshowVerifierAgent works. To s’squantifiedresultwithrespecttocritacross
make VerifierAgent works, we need to study the allseed
stabilityofproposedcriteriaaswellashowrobust 13: endfor
theyarew.r.ttheinjectednoise. 14: Computemeancoefficientofvariationby
averagingallsample’scoefficientofvariation
A.5.1 CriteriaRobustness
15: endfor
we first report the full criteria list for Math prob-
16: final_criteria← []
lemssolvingandALFWorldhouseholdtaskswhen
17: forallcritinsummarized_criteriado
runningtheCriticAgentandQuantifierAgentfor50
18: ifcrit hasameancoefficientofvariation
timesafterconsolidation(asdescribedinsection
withinacertainrange,andcrithasdecentad-
6.1) in Tab 4 and 5. This process would exclude
versarialtestingperformancethen
criteriathathavemeanstandarddeviationabovea
19: Addcrittofinal_criteria
certainthresholdandcriteriathathaveahigheror
20: endif
equivalentaveragescoreforadversarialtaskoutput
21: endfor
thantheoriginaltaskoutput. Thisdoesnotneces-
22: Toevaluatefuturetasks,usefinal_criteriawith
sarilymeanthesecriteriaarebadcriteria,butrather
QuantifierAgent.
suggests the QuantifierAgent may not be able to
reliablyquantifythesecriteriaandthusitmightbe
offthantheoriginaltaskoutput. Webelievethat
bettertoexcludethemfromthefinalscoreassigned
such an analysis of the quantifier agent’s perfor-
toasample. Assuch,similartoFig. 6,wereport
mancewillyieldvaluableinsightsforenhancing
the mean of coefficient variation for ALFWorld
reliability, trustworthiness, and explainability in
task in Fig. 12. We note that having almost all
performanceevaluation.
ofthecoefficientbelow0.5indicatehighlevelof
One interesting observation here is that there
robustness of QuantifierAgent on the verified set
maybeinterdependenceamongsomecriteria. For
ofcriteriabyVerifierAgentonAlfWorlddataset.
examplelevelappropriatnessisdefinedas"How
A.5.2 AdversarialAttacks well-suitedthesolutionprovidedbythesystemis
forthegivenproblem’slevel",whichisdependent
We construct adversarial samples by randomly
on the criterion problemlevel. This observation
droppingaportionofsentencesintheLLMassis-
gives insight into potential future improvements
tant’sresponsefromtheoriginaltaskoutput. We
tothecurrentpipeline. Wemayfirstextractsome
verifytheQuantifierAgentagainsttheadversarial
characteristicsofthetaskoutput,suchascategor-
samples. Weusedthreedifferentbenchmarksfor
ical criteria like problemtype and problemlevel,
adversarial testing, namely AutoGen, ReAct and
andthenpotentiallygeneratedifferentcriteriaand
VanillaSolver. AsshowninFig.13fortheALF-
quantifythetaskoutputdifferentlybasedonthese
Worlddataset),inmostcasestheQuantifierAgent
characteristics.
quantifiestheadversarialtaskoutputtobeworseFigure12: EvaluatingtheQuantifierAgent’srobustnessonALFWorlddataset: themeancoefficientofvariationof
quantifiedresultsacrossn=18seeds.
Figure13: QuantifierAgentVerificationonoriginalsetoftasksolutionsagainstthedisturbedtasksolutionson
MathProblemSolvingdataset.Table4: ComprehensiveVerificationCriteriaforMath-
Problems.
Criteria Description AcceptedValues
efficiency Theconcisenessofthesolutionand –highly_efficient(2)
theuseofthemostefficientmethodto –moderately_efficient(1)
solvetheproblem. –inefficient(0) Table5: ComprehensiveVerificationCriteriaforALF-
accuracy Thecorrectnessofthesolution –100%-Completelycorrect(4) WorldHousholdingTasks.
providedforthemathproblem. –75%-Almostcorrect(3)
–50%-Mostlycorrect(2)
–25%-Partiallycorrect(1)
–0%-Completelyincorrect(0) Criteria Description AcceptedValues
completenessTheextenttowhichthesolution –100%-Fullycomplete(4) task Degreetowhichthetaskiscompleted –100%(4)
coversallaspectsoftheproblem. –75%-Almostcomplete(3) completion successfully –75%(3)
–50%-Mostlycomplete(2) –50%(2)
–25%-Partiallycomplete(1) –25%(1)
–0%-Notcomplete"(0) –0%(0)
clarity Theeasewithwhichthesolutioncan –100%-Veryclear(4) action Actionsmustbechosenfromthegiven –all_legal(3)
beunderstoodbythetargetaudience. –75%-Mostlyclear(3) validity availableactions,withillegitimate –one_illegal(2)
– –5 20 5% %- -F Sa oi mrl ey wc hle aa tr c( l2 ea) r(1) actionstakenintoaccount – –t tw hro e_ ei _l ole rg _a ml o(1 re) _illegal(0)
–0%-Notclear(0)
presentation Theorganizationandpresentationof –excellent(2) t ph ro ou ceg sh st T plh ae nnq iu na gli tt hy ro of ugth he outh to tu hg eh tat sp krocessand – –e gx oc oe dll (e 2n )t(3)
thesolution,includingproperuseof –fair(1) –fair(1)
notation,symbols,andformatting. –poor(0) –poor(0)
steps Howwellthesolutionbreaksdown –100%-Allstepsdelineated(4) systematic Howsystematicallytheplayersearched –excellent(3)
delineation theproblem-solvingprocessinto –75%-Moststepsdelineated(3) search foritemsandtargetlocations –good(2)
smaller,manageablesteps. –50%-Somestepsdelineated(2) –moderate(1)
–25%-Fewstepsdelineated(1) –poor(0)
–0%-Nostepsdelineated(0)
response Thetimetakentoprovidethesolution –>5min(5) −3-5min(4) i fln ot weraction T inh tee rs am cto ioo nth sn we is ts ha tn hd ec eo nvn it rin ou ni mty eno tf – –s sm omoo e_th di( s2 r) uptions(1)
time –1-3min(3) −31-60sec(2) –frequent_disruptions(0)
–16-30sec(1) −0-15sec(0)
notations Thenotationsusedintheproblem –consistent(2) tasktime Thetimetakentoaccomplishthetask – –v fae sr ty (_ 2f )ast(3)
solutionareappropriateand –mostlyconsistent(1) –average(1)
consistent. –inconsistent(0) –slow(0)
steps Theextenttowhicheachstepinthe –allsteps(4) planning Qualityofthedevisedplanfor –excellent(3)
explanation solutionisexplained. –moststeps(3) strategy completingthetask –good(2)
–halfsteps(2) –fair(1)
–somesteps(1) –poor(0)
–none(0)
error Howwellthesystemidentifiesand –Handledallerrors(4) a ec ffiti co in ency E sof lfi vc ii ne gnc thy eo tf asth kechosenactionsin – –v he igry hh (2ig )h(3)
handling addressespossibleerrorsinthe –Handledmosterrors(3) –moderate(1)
problem –Handledsomeerrors(2) –low(0)
–Handledveryfewerrors(1)
–Ignoredallerrors(0) response Adherencetotherequiredresponse –correct(2)
useof Theuseofrelevanttechniquesand –Excellentuse(2) format format – –p ina cr oti ra rl el cy tc (o 0r )rect(1)
methods conceptstoaddressandsolvethe –Adequateuse(1)
mathproblem. –Pooruse(0) adaptability Abilitytoadaptandmodifytheplan –veryhigh(3)
levelappro- Howwell-suitedthesolutionprovided –Highlyappropriate(4) tofeedback basedontheenvironment’sfeedback – –h mig oh de( r2 a) te(1)
priateness bythesystemisforthegiven –Appropriate(3) –low(0)
problem’slevel –Moderatelyappropriate(2)
–Slightlyappropriate(1) termination Properjudgmentofwhentoreplywith –correct(2)
–Notappropriate(0) judgement ’TERMINATE’ –partiallycorrect(1)
solution Thedepthofthesolutionprovidedin –Extremelydetailed(3) –incorrect(0)
depth termsofshowingallstepsand –Detailed(2) efficiency Assessesthenumberofstepstakenin –optimal(3)
importantcalculations –Moderate(1) comparisontotheminimumpossible –near_optimal(2)
–Superficial(0) stepsrequiredtocompletethetask –average(1)
terminology Correctandconsistentuseof –Appropriate(2) –below_average(0)
mathematicalterminologyinthe –Mostlyappropriate(1) problem Theabilitytoquicklyidentifyandadapt –fast_adaptation(3)
explanations –Inappropriate(0) solving tochangesintheenvironmentduringtask –moderate_adaptation(2)
reliability Thedependabilityofthe –Distrusted(2) execution – –s nl oo _w a_ da ad pa tap tt ia ot nio (n 0)(1)
procedure/algorithmusedin –MostlyTrusted(1)
providingthesolution –Trusted(0) target Howwelltheplayerfollowed –excellent(3)
c ea rrl ocu rlation P mr ae ts he en mce ato icf aa ln my ic so tam kep sut ia nti to hn ea sl oo lur
tion
– –N Mo ine or rro er rs ro( r2 s)
(1)
handling i hn os utr su ec ht oio ldnsforhandlingthetarget – – –g m po ooo odd re (r( 0a2 )t) e(1)
–Majorerrors(0)
creativity Novelapproachormethodusedin –exceptionallynovel(2) e un nv di er ro sn tam ne dn -t T enh ve ira ob ni mlit ey nt to du en scd re ir ps tt ia on nd at nh de ip dr eo nv ti id fyed – –e gx oc oe dll (e 2n )t(3)
providingthesolution – –m stao nd de ara rdte (l 0y )novel(1) ing relevantobjects – –f pa oi or r(1 (0)
)
relevance Thesolutionshouldfocusonsolving –Highlyrelevant(2) compliance Adherencetospecificrulesand –compliant(2)
thegivenproblemandavoidirrelevant –ModeratelyRelevant(1) with instructionssuchasreplyformattingand –partiallycompliant(1)
informationorsteps. –Irrelevant(0) instructions terminationconditions –non-compliant(0)
simplificationThedegreetowhichthesolution –Completely(3) legalactions Selectingactionsfromthegivenavailable –excellent(4)
simplifiestheproblemwhile –Mostly(2) actionsandavoidingillegalactions –good(3)
maintainingaccuracy –Partially(1) –average(2)
–Notatall(0) –below_average(1)
handling Theaccuracyofthesolutionin –Fullyrespected(2) –poor(0)
constraints addressinggivenconstraints –Partiallyrespected(1) target Acquiringthetargethouseholdobject –excellent(3)
–Disregarded(0) acquisition immediatelyafterfindingit –good(2)
problem Thetypeofthemathproblem –Excellent(4) −Good(3) –fair(1)
type –Average(2) −Poor(1) –poor(0)
–Terrible(0) format Theextenttowhichtheoutputformatis –Correctformat(2)
adaptability Adaptabilityreferstotheabilityofthe –Other(11) adherence strictlyfollowed –Minorformatissues(1)
solutionprovidedtobemodifiedand –Logic(10) –Incorrectformat(0)
adjustedtoalternativeorrelated –Topology(9) problemun- Understandingofthegiventaskand –3-Fullyunderstood(3)
problems. –DifferentialEquations(8) derstanding relevanceoftheenvironment –2-Adequatelyunderstood(2)
–LinearAlgebra(7) –1-Partiallyunderstood(1)
–NumberTheory(6) –0-Notunderstood(0)
–Combinatorics(5)−Statistics(4)
–Calculus(3) −Trigonometry(2) action Choosingtheappropriatesequenceand –3-Optimalselection(3)
–Geometry(1) −Algebra(0) selection typeofactions –2-Goodselection(2)
p ler vo eb llem T prh oe bd lei mfficultylevelofthemath – – –L L Le e ev v ve e el l l5 3 1( ( (4 2 0) )
)
− −L Le ev ve el l4 2( (3 1) ) – –1 s 0e- -leS Pco otim oo rne sw ( e1h le)a ct ta ioc nce (p 0t )able
solution Appropriatenessofthesolution –Appropriate(2)
approach approachused –Questionable(1)
–Inappropriate(0)
correct Theextenttowhichthesystems –100%(4)
reasoning responsedemonstratescorrect –75%(3)
mathematicalreasoning. –50%(2)
–25%(1)
–0%(0)