Online learning of quantum processes
Asad Raza1, Matthias C. Caro1, Jens Eisert1,2, and Sumeet Khatri1
1Dahlem Center for Complex Quantum Systems, Freie Universität Berlin, Berlin, Germany
2Helmholtz-Zentrum Berlin für Materialien und Energie, Berlin, Germany
June 7, 2024
Abstract
Among recent insights into learning quantum states, online learning and shadow tomography
proceduresarenotablefortheirabilitytoaccuratelypredictexpectationvaluesevenofadaptively
chosen observables. In contrast to the statecase, quantum process learningtasks with a similarly
adaptive nature have received little attention. In this work, we investigate online learning tasks
for quantum processes. Whereas online learning is infeasible for general quantum channels,
we show that channels of bounded gate complexity as well as Pauli channels can be online
learned in the regret and mistake-bounded models of online learning. In fact, we can online
learn probabilistic mixtures of any exponentially large set of known channels. We also provide a
provably sample-efficient shadow tomography procedure for Pauli channels. Our results extend
beyond quantum channels to non-Markovian multi-time processes, with favorable regret and
mistake bounds, as well as a shadow tomography procedure. We complement our online learning
upper bounds with mistake as well as computational lower bounds. On the technical side, we
make use of the multiplicative weights update algorithm, classical adaptive data analysis, and
Bell sampling, as well as tools from the theory of quantum combs for multi-time quantum
processes. Our work initiates a study of online learning for classes of quantum channels and,
more generally, non-Markovian quantum processes. Given the importance of online learning
for state shadow tomography, this may serve as a step towards quantum channel variants of
adaptive shadow tomography.
1 Introduction
Learning about quantum systems and their evolution over time is a task of fundamental importance
in quantum physics. “Learning”, broadly speaking, refers to the extraction of useful classical
information from quantum-mechanical systems and their evolution through experiments. Such
learning tasks first appeared in quantum information in the form of quantum state and process
tomography, in which the aim is to extract all classical information about the system, in terms of
the density matrix of the system in the case of quantum state tomography [1–6], and the transfer
matrix in the case of quantum process tomography [7–9]. These tomographic tasks, with their strict
measures of performance in terms of worst-case distance measures such as the trace and diamond
1
4202
nuJ
6
]hp-tnauq[
1v05240.6042:viXraρ
N
(b)
ρ (ρ)
ρ
N
N
Pr[✓]=Tr[M (ρ)]
N (c)
(a)
Figure 1: Learning of quantum processes. (a) To learn about the unknown evolution of a
quantum system (symbolized by the blue shaded region and represented mathematically by the
quantum channel N), we prepare a probe quantum state ρ, let it evolve, and then measure it
according to the POVM {M,1−M}. We encapsulate this process in the circuit diagram shown
in (b). (c) More generally, we can prepare an entangled probe state of two systems, let only one
of them evolve, and then jointly measure both systems. Our results apply to this more general
class of tests, and also more generally to classes of multi-time quantum processes, in which the
unknown evolution could be non-Markovian.
norm, require resources scaling exponentially with the system size [10–14]. Consequently, recent
years have seen a growing interest in less strict variants of state and process learning, defined by
relaxing the requirement of extracting full classical information about the objects of interest and
instead requiring that we learn only the values of certain observables of our state or process. In
the case of quantum states, notable such learning tasks include “pretty good tomography” in the
spirit of probably approximately correct (PAC) learning [15], shadow tomography [16–19], online
learning [20, 21], and classical shadows [22–24]. Inspired by this progress in understanding state
learning, also new perspectives on quantum channel learning have been explored [25–32].
We consider the following channel learning task, see also Figure 1. Let N be an unknown
quantum channel, describing the evolution of a quantum system. In order to learn the behavior
of the channel, we can prepare our system in a state of our choice, let it evolve according to the
channel N, and then measure the output. The input state and measurement constitute a “test” for
the quantum channel, and the probability of “passing” the test is given by Tr[MN(ρ)], where ρ
is the input state and M is the measurement operator corresponding to passing the test. Tests
of this type are ubiquitous in real-world physical setups used to learn the dynamics of quantum
systems, see, e.g., Refs. [7, 9, 33–35]. Our task is to accurately predict values of quantities of the
form f(x) = Tr[MN(ρ)] for test pairs x = (ρ,M), and in this sense “learn” the evolution of the
system.
In the typical setting of supervised learning used to achieve our task of interest, there is a
training phase, in which a set {(x,f(x))} of pairs of tests and their passing probabilities is given to
x
2the learner, and the learner uses these tests to form a hypothesis for the unknown channel. This
hypothesis should accurately predict passing probabilities on new, unseen tests, typically drawn
from the same distribution that generated the tests during training. Learning algorithms in this
setting are analyzed within the framework of PAC learning [36]. In this work, we go beyond the
setting of PAC learning. Instead of the data pairs (x,f(x)) being given to the learner in a batch,
we suppose that they are given to the learner sequentially, one by one, and perhaps even in an
adaptive and adversarial manner. The learner must produce a hypothesis for the unknown channel
at every step, using which they estimate the passing probability of the test pair. Upon learning
the true passing probability, they can update their hypothesis. The goal now is for the learner to
devise a sequence of hypotheses such that, over time, they make few mistakes in their estimates; see
Section 1.1 for a more formal description of this setting.
The framework of online learning [37] (see, e.g., Refs. [38, Chapter 21] and [39, Chapter 8] for
pedagogical introductions) has been developed precisely to address this arguably more realistic
learning setting. After all, data will often be processed sequentially, and it only makes sense to
update the hypothesis step by step. Indeed, the importance of online learning derives from its
ability to describe scenarios in which data is presented to the learner sequentially and adaptively.
Thereby, it removes assumptions on the data-generating process, such as the i.i.d. assumption
typical in PAC learning [36]. As such, it provides a more stringent type of learning compared
to PAC learning. In fact, broadly speaking, it has been shown that online learning implies PAC
learning [40–44]. Furthermore, if the learning algorithm is allowed unbounded computational
resources, then something stronger holds: any concept class of Boolean functions is learnable in the
online model if and only if is also learnable in the (distribution-free) PAC model [45].
While online learning of quantum states has been considered already [20, 21], and it has also
been lifted to shadow tomography of quantum states with adaptively chosen observables [16, 17],
the overwhelming majority of results on quantum process learning so far do not allow for accurate
predictions based on an adaptive choice of the state-measurement pairs. To fill this gap, we initiate
the study of online learning for quantum processes. We first show that general quantum channels
cannot be online learned with subexponential regret or number of mistakes. However, a priori
knowledge about the complexity or the structure of the unknown channel can make online learning
feasible. Indeed, we identify two physically relevant classes of channels—efficiently implementable
channels and Pauli channels—that can be online learned with regret and mistake bounds scaling
polynomially in the system size. We extend these results to classes of more general multi-time
processes, in particular quantum processes that are non-Markovian, establishing that they, too, can
be online learned with regret and mistake bounds scaling polynomially in the system size.
1.1 Statement of the problem
Consider an interaction between a learner and an adversary. At time step t ∈ N, the adversary
picks a state-measurement pair, (ρ(t),M(t)), where ρ(t) is an input state and M(t) is an effect
operator of a two-outcome POVM. More generally, we can allow for states and measurements with
arbitrary auxiliary systems, as in Figure 1(c) (see Section 2.4). The task for the learner is to predict
Tr[M(t)N(ρ(t))] for an unknown channel N. To do so, the learner produces their own channel
hypothesis, N(t), and outputs Tr[M(t)N(t)(ρ(t))] as their prediction. The adversary then provides
3the learner with feedback on what would have been the correct expectation value1. The goal of
the learner is to ensure that their output values are not too far from correct in most rounds of
the interaction. We can quantify the loss suffered by the learner at time step t by the absolute
difference between learner’s estimate of the expectation value and the correct expectation value,
(cid:12) (cid:12)
ℓ(N(t),ρ(t),M(t)) := (cid:12)Tr[M(t)N(ρ(t))]−Tr[M(t)N(t)(ρ(t))](cid:12). (1.1)
(cid:12) (cid:12)
The learner-adversary interaction proceeds for a total of T ∈ N rounds.
Now, how do we measure the learner’s performance over the course of T rounds of its interaction
withtheadversary? Notethatduetotheadversarialnatureoftheproblem, statisticalextrapolations
are of little use. Indeed, as soon as the learner models the interaction using some probability
distribution, the adversary can immediately change their strategy to make the learner fail. One
way to gauge the learner’s performance is to compare their total loss at the end of the T rounds of
interaction with the loss that they would have incurred if they were allowed to make all predictions
at the end of the T rounds, after having seen all of the state-measurement pairs. We do this by
considering the quantity
T T
R := X ℓ(N(t),ρ(t),M(t))−minX ℓ(N,ρ(t),M(t)), (1.2)
T
N
t=1 t=1
where the minimization is over channels N from some class of interest. The larger this quantity, the
more the learner would lament their choice of hypotheses N(t) at the end of the T rounds; hence,
√
this quantity is called regret. It is well-known [46] that any online learner suffers Ω( T) regret in
general. We aim for online learners that saturate this lower bound and achieve a regret scaling as
O(p Tpoly(logD)), where D is the dimension of the quantum system acted on by the channel.
Another intuitive way to evaluate whether the learner’s performance is “good” is in terms of the
number of rounds t ∈ [T] in which the learner makes a mistake. By a “mistake”, we mean that the
learner’s estimate of the expectation value is more than a given accuracy ε away (in absolute-value
distance) from the correct expectation value revealed by the adversary. In other words, the learner
should minimize the number of rounds in which ℓ(N(t),ρ(t),M(t)) > ε. More formally, we say that
the learner makes an ε-mistake in round t if ℓ(N(t),ρ(t),M(t)) > ε. Viewed this way, the goal in
online learning is to upper bound the number of ε-mistakes for any number T of rounds and any
adversarial/adaptive choice of state-measurement pairs presented to the learner. This is the so-called
mistake-bounded model of Littlestone [37]. In our work, we more specifically are interested in online
learners that incur a mistake bound scaling logarithmically with D and inverse polynomially in the
accuracy ε for, ideally, a low-degree polynomial.
1.2 Overview of the main results
For the task of online learning arbitrary n-qubit quantum states, it was shown in Ref. [20] that there
exist procedures that make at most linearly-in-n many mistakes. (Here, for ease of presentation, we
consider ε to be a constant, say 1/3, and then simply speak of a mistake instead of an ε-mistake.)
1In general, the adversary may only provide an approximation to the true expectation value (see Section 2.2), but
here we restrict our attention to the simpler version for ease of exposition in the introduction.
4Online learning G-gate channels Pauli channels
O(cid:16) Lp TGlog(Gn)(cid:17) O(cid:16) L√ Tn(cid:17)
Regret bounds
(Theorem 20) (Theorem 22)
O(cid:16) L2Glog(Gn)(cid:17) O(cid:16) L2n(cid:17)
Mistake bounds ε2 ε2
(Corollary 21) (Corollary 24)
Ω(min{2n,G}) Ω(n)
(Corollaries 37 and 39) (Corollary 39)
Computational ω(poly(n)) already for G = O(npolylog(n)) Ω˜(4n)
complexity (Corollary 47) (Theorem 41)
Table 1: Overview of our main results. For channels of gate complexity G as well as
for n-qubit Pauli channels, we give regret and mistake upper bounds that scale favorably with
G and n, respectively. Our bounds hold for general loss functions with Lipschitz constant L.
Additionally, complementary mistake lower bounds show that the dependencies on G and n are
almost optimal. Finally, we give computational complexity lower bounds for online learning
either of the two classes of channels with polynomially many mistakes.
In terms of channel learning, this implies the same mistake bound for online learning arbitrary
n-qubit state-preparation channels. However, as pointed out in Ref. [15, Footnote 18] and as we
formalize further in Section 4.1, if the underlying concept class consists of all n-qubit unitary
channels, then any (even computationally unbounded) online channel learner can be forced to make
exponentially-in-n many mistakes. Thus, in contrast to the case of quantum states, we have to
consider restricted classes of channels to achieve online channel learning with a polynomial-in-n
number of ε-mistakes. In fact, it was left open in Ref. [15] to find restricted classes of quantum
channels for which this goal, which is an online version of “pretty good process tomography”, can
be realized. While recent years have seen some progress on the batch version of this task, see, e.g.,
Refs. [47–50], the online case remains open.
In this work, we answer the question of pretty good process tomography within the online
learning framework for the following two concrete classes of channels (see Table 1 for a summary of
our results):
1. Channels that can be implemented by dissipative quantum circuits with a limited number of
local gates. Channels in this class can be regarded as having limited complexity.
2. Pauli channels or, more generally, mixtures of a fixed set of (potentially exponentially many)
known channels, each of which could have arbitrarily high gate complexity. This is a structural
assumption on the channel.
First, we show that there exists an online learner whose regret and number of mistakes can be
controlled in terms of the gate complexity of the class of channels to be learned.
5Theorem 1 (Online learning channels of bounded complexity—informal). The class of n-qubit
channels that can be implemented by circuits consisting of G arbitrary two-qubit channels can be
online learned with regret bound
O(cid:16)p TGlog(Gn)(cid:17)
and with ε-mistake bound
O(cid:16) Glog(Gn)(cid:17)
.
ε2
Theorem 1 extends beyond the absolute-value loss function from Equation (1.1) to more general
loss functions, in which case our bounds depend also on their Lipschitz constant L. General channels
require exponentially many gates to be implemented by a 2-local circuit, so Theorem 1 does not
provide useful guarantees in this case. However, if we focus on the physically relevant class of
channels with a polynomial gate complexity, then Theorem 1 gives polynomial regret and mistake
√
bounds. Additionally, we show with an O(1)-mistake lower bound of Ω(min{2n, G}) for general
G and of Ω(G) for G ≤ n that the G-dependence in the online learning guarantees of Theorem 1
cannot be significantly improved (Corollary 37).
Second, weproveregretandmistakeboundsforPaulichannelonlinelearningthatscaleefficiently
in the number of qubits. Pauli channels play an important role in quantum information theory,
specificallyinthefieldofquantumcomputation,wherePaulichannelnoiseeithernaturallyemergesor
is achievable via group twirls [51]. Thus, the following result establishes adaptive/online learnability
of an important class of quantum noise channels.
Theorem 2 (Online learning Pauli channels—informal). The class of n-qubit Pauli channels can
(cid:16)√ (cid:17) (cid:16) (cid:17)
be online learned with regret bound O Tn and with ε-mistake bound O n .
ε2
The linear-in-n scaling in the ε-mistake bound is optimal for constant ε (Corollary 39). Moreover,
establishing a connection to important notions from classical learning theory, we demonstrate that
Theorem 2 yields bounds on the (sequential) fat-shattering dimension of Pauli channels, and gives
rise to a sample compression scheme for Pauli channels (Section 3.4).
Theorems 1 and 2 give favorably scaling regret and mistake bounds. However, the respective
online learning procedures are computationally inefficient. We show that, under reasonable crypto-
graphic assumptions, this is unavoidable when aiming for good regret and mistake bounds in these
online learning problems:
Theorem 3 (Computational lower bounds for online learning—informal). On the one hand, any
online learner that makes at most O(poly(n)) many (1/3)-mistakes in online learning n-qubit Pauli
channels has to use runtime exponential in n. On the other hand, assuming that RingLWE cannot
be solved by classical polynomial-time algorithms, then already for G = O(npolylog(n)) there is
no polynomial-time online learner that makes at most O(poly(n)) many (1/3)-mistakes in online
learning G-gate n-qubit quantum channels.
While the computational inefficiency of our online learning procedures is of course undesirable,
Theorem 3 shows that this is not a flaw of our specific procedures. Rather, it is simply not possible
to computationally efficiently learn Pauli channels with a good mistake bound. And given that
RingLWE is widely believed to be hard [52–54], then as soon as G scales only slightly superlinearly
in n, we also do not expect there to be any computationally efficient online learners that achieve a
good regret for the class of G-gate channels.
6A problem related to online learning quantum processes is shadow tomography of quantum
processes. By analogy with shadow tomography of quantum states [16, 17], shadow tomography of
quantum processes is a stricter form of learning than mistake-bounded online learning: while in the
online learning task the number of mistakes should be bounded, in shadow tomography one has to
correctly estimate (i.e., with error ε) the expectation values of all the M observables provided, with
probability at least 1−δ. (See Problem 3 for a formal statement of the problem.) Furthermore, in
shadow tomography, only quantum access to the channel is provided, while classical descriptions of
tests and their passing probabilities (with respect to the unknown channel) are provided in online
learning. The main observation underlying our proof of Theorem 2 implies that techniques from
classical adaptive data analysis [55, 56] directly carry over to Pauli channel shadow tomography. In
particular, we obtain the following result.
Theorem 4 (Pauli channel shadow tomography—informal). Shadow tomography of an arbitrary
n-qubit Pauli channel can be solved using
√ nlog(M)log3/2((εδ)−1)!
k = O (1.3)
ε3
copies of the channel. The strategy runs in time poly(4n,k) per channel use.
We leverage Theorem 4 to make a more general statement about shadow tomography of arbitrary
channels. In particular, we show in Corollary 49 that we can solve the shadow tomography problem
for an arbitrary quantum channel N with a number of copies scaling as in (1.3), with ε therein
replaced by ε− 1∥N −NP∥ , for all ε > 1∥N −NP∥ . Here NP is the Pauli-twirled version of N.
2 ⋄ 2 ⋄
1.3 Extensions of our results
Many of the techniques underlying our main results in Section 1.2 can be applied to more general
settings, going beyond G-gate channels and Pauli channels. We now summarize these extensions.
Convex mixtures of known channels. While Theorem 2 is phrased for Pauli channels, we in
fact show the following more general statement: If we consider a class of channels that can be written
as probabilistic mixtures of a fixed set of K known quantum channels, then we can achieve online
learning for this class with regret and number of mistakes bounded in terms of log(K). Notably,
these bounds apply even if channels with high circuit complexity occur in the mixtures.
Theorem 5 (Online learning convex mixtures of known channels—informal). Given an arbitrary
set of K > 0 known and fixed quantum channels, any convex mixture of these channels can be
√
online learned with regret bound O(cid:0) T logK(cid:1) and ε-mistake bound O(log(K)).
ε2
Adaptive tests of channels. We may also want to learn the passing probabilities of more general
channel tests that make use of the channel multiple times, perhaps adaptively. Such tests have
the form shown in Figure 2(a). We can directly import results about convex mixtures of known
7R1 R2 R3
ρ 1 2 Pr[i]=Tr[E(i)C( )⊗3]
D D N
A1 N B1 A2 N B2 A3 N B3
(a)
R1 R2 R3
ρ 1 2 Pr[i]=Tr[E(i)C( [3])]
D D N
A1 1 B1 A2 2 B2 A3 3 B3
N N N
M1 M2
(b)
Figure 2: Extensions of our results to general quantum processes. (a) Going beyond
one use of a channel N, as shown in Figure 1, we may want to learn the value of the channel
on tests that make multiple, adaptive uses of the channel. Shown are three independent uses
of N, whose Choi representation is C(N). (b) We can similarly perform adaptive tests of a
non-Markovian process N[3], characterized by the blue quantum comb, with Choi representation
C(N[3]). The generalized Born rule [57] tells us that the outcome probabilities of measurements,
or “tests”, of quantum channels and multi-time quantum processes can be determined by an
analogue of the usual Born rule for quantum states, in which the Choi representation takes the
placeofthequantumstate,andthetestischaracterizedbyoperatorsE(i)thataregeneralizations
of effect operators for quantum states. (See Section 2.1 for details.)
channels to this setting. Indeed, given a channel N = PK p N that is a convex mixture of known
j=1 j j
channels N , it holds that
j
K
N⊗k = X p p ···p N ⊗N ⊗···⊗N . (1.4)
j1 j2 j
k
j1 j2 j
k
j1,j2,...,j k=1
This is itself a convex mixture of Kk known channels, so Theorem 5 applies and yields regret and
mistake bounds scaling with klog(K). We note, however, that Theorem 5 in this scenario will
generally not give a proper online learner. Namely, the learner’s hypotheses will be (nk)-qubit
channels given by convex combinations of {N ⊗N ⊗···⊗N }K , which in general cannot
j1 j2 j k j1,...,j k=1
be factorized into k copies of a single n-qubit channel.
Non-Markovian quantum processes. At the heart of the quantities that we aim to estimate is
Born’s rule [58], which tells us that the expected value of an observable (Hermitian operator) H for
a quantum state ρ is given by Tr[Hρ]. The Born rule generalizes not only to quantum channels
but also to multi-time/non-Markovian quantum processes [57, 59], where we model multi-time
processes mathematically as “quantum combs” [57], also called “quantum strategies” [60]; see also
Refs. [61–63]. Within the framework of quantum combs, the Choi representation of the process
takes the place of the state ρ and the observable H is replaced by a generalized “process observable”
O; see Figure 2(b). We provide formal definitions of quantum combs and process observables in
Section 2.1. Consequently, we can readily translate our results on bounded complexity channels and
8convex mixtures of known channels to bounded complexity non-Markovian processes and convex
mixtures of known non-Markovian processes. While full tomography of multi-time/non-Markovian
processes has been considered [64], to the best of our knowledge, the restricted tomographic setting
that we consider here has so far not been considered for multi-time quantum processes.
We start by considering multi-time processes of bounded complexity. We formally define these
processes by analogy with quantum channels of bounded gate complexity in Section 3.3. We can
then extend Theorem 1 as follows.
Theorem 6 (Online learning multi-time processes of bounded complexity—informal). The class of
n-qubit multi-time processes with complexity parameter G can be online learned with regret bound
O(cid:16)p TGlog(Gn)(cid:17)
and with ε-mistake bound
O(cid:16) Glog(Gn)(cid:17)
.
ε2
We also extend Theorem 5 to an online learning result for convex mixtures of arbitrary known
multi-time processes.
Theorem 7 (Online learning of convex mixtures of known multi-time processes—informal). Given
an arbitrary set of K > 0 known and fixed quantum multi-time processes, any convex mixture
√
of these processes can be online learned with regret bound O(cid:0) T logK(cid:1) and ε-mistake bound
O(log(K)).
ε2
Finally, we extend the shadow tomography result of Theorem 4 to arbitrary multi-time processes.
Here, theshadowtomographyproblemformulti-timeprocessesisdefinedanalogouslyasforchannels;
we refer to Problem 4 for the formal problem statement.
Theorem 8 (Shadow tomography of multi-time processes—informal). Shadow tomography of
an arbitrary n-qubit multi-time process with r ∈ {1,2,...} time steps can be solved to accuracy
ε > 1∥N −NP∥ using
2 ⋄r
√
nrlog(M)log3/2(((ε− 1∥N −NP∥ )δ)−1)!
k = O 2 ⋄r (1.5)
(ε− 1∥N −NP∥ )3
2 ⋄r
copiesoftheprocess,whereN istheChoirepresentationoftheprocess,NP istheChoirepresentation
of the Pauli-twirled version of the process, and ∥·∥ is the strategy r-norm.
⋄r
1.4 Related work
Online learning of quantum states. Ref. [20] introduced the problem of online learning
quantum states and proposed three conceptually different approaches that all achieve mistake
bounds scaling linearly in the system size. Recently, Ref. [21] investigated an adaptive variant of this
online learning problem, in which the underlying state may change over time. A notable application
of online state learning is its use as a subroutine in recent shadow tomography protocols [16, 17, 65].
A natural question to ask is whether we can simply apply known results on online learning
quantum states to the Choi state of the unknown channel to accomplish the channel online learning
task laid out above. This is certainly possible; however, we aim to predict quantities of the
9form Tr[M N (ρ )]. And while Choi states are efficiently (online) learnable, the so-called
B A→B A
“Choi-to-channel” translation incurs a dimension factor:
N (X ) = Tr [(XT ⊗1 )CN ] = d Tr [(XT ⊗1 )ΦN ], (1.6)
A→B A A A B A,B A A A B A,B
where CN is the Choi matrix of N, ΦN = 1 CN is the Choi state of N, and A and B are the
input anA d,B output systems, respectively,A o, fB N;d sAee SA e,B ction 2.1 for formal definitions. Because of the
dimension factor in the right-most equality above, we have
Tr[M N (ρ )] = Tr[(ρT ⊗M )CN ] = d Tr[(ρT ⊗M )ΦN ]. (1.7)
B A→B A A B A,B A A B A,B
Consequently, good regret and mistake bounds for online learning the Choi state do not give rise
to good regret and mistake bounds for online learning the channel. In Section 2.5, we discuss this
and further issues arising when merely applying quantum state learning algorithms from Ref. [20]
(such as the matrix multiplicative weights (MMW) algorithm) to the Choi state for channel online
learning. In particular, noting that the MMW algorithm for online learning quantum states cannot
be directly applied to the learning of Choi states (due to the fact that Choi states have an additional
partial trace requirement), we provide a projected MMW algorithm that can be used to learn the
Choi state, along with the associated regret bound analysis.
Learning channels of bounded complexity. With general quantum channels being impossible
to learn in many scenarios, recent work has investigated the learnability of channels with bounded
gate complexity in different settings. In variational quantum machine learning, a variety of works
derivedboundsonlearning-theoreticcomplexitymeasures,andhencethesamplecomplexitysufficient
for good PAC generalization bounds, in terms of the number of gates [48–50, 66–69]. For learning
classical-to-quantummappings,Refs.[70–72]gavesimilar-in-spiritsamplecomplexityboundsderived
from gate complexity assumptions. Finally, Refs. [25, 32] considered different scenarios of state and
process learning under assumptions of limited gate complexity.
Learning Pauli channels. Pauli channel learning has been considered in different (mostly non-
online) scenarios. Ref. [73] gave procedures for approximating the Pauli error rates of a general
unknown Pauli channel in different ℓ norms, with a recent improvement for the ℓ norm in
p ∞
Ref. [74]. Ref. [75] proved that the query complexities achieved by these procedures are optimal
among non-adaptive incoherent strategies, and also gave lower bounds for adaptive incoherent
strategies. If the Pauli noise is known to have a local structure, the query complexity can be
improved beyond the results of Refs. [73, 76], even if the conditional independence structure is not
known in advance [77]. Refs. [78–80] highlight the importance of auxiliary systems and entanglement
in learning the eigenvalues of an unknown Pauli channel. In Ref. [81], the authors provide an online
algorithm for learning the eigenvalues of a Pauli channel2, while in this work we consider the task
of learning the error rates of Pauli channels. Finally, Ref. [29] investigates the more general task
of learning the Pauli transfer matrix of a general channel, giving both non-adaptive and adaptive
procedures.
2We note that Ref. [81] is an updated version of Ref. [80].
101.5 Techniques and proof overview
Sequential covering numbers. In our proof of Theorem 1, we combine tools from two recent
lines of work in classical online learning and quantum machine learning. On the one hand, we rely
on regret bounds for online learning in terms of sequential complexity measures for the underlying
hypothesis class. In particular, we use regret bounds via sequential covering numbers [82, 83], which
can be viewed as a sequential version of Dudley’s theorem. Namely, as we recall in Theorem 11,
XT
ℓ (f (x
))−minXT
ℓ (f(x )) ≤ 2LT inf
(cid:26)
4α+
√12 Z 1q
logN (F,β,2)
dβ(cid:27)
, (1.8)
t t t t t T
f∈F α>0 T α
t=1 t=1
where N (F,β,2) denotes the worst-case sequential 2-norm β-covering number of F ⊆ [0,1]X over
T
all complete binary trees x of depth T whose nodes are labeled by elements of X. On the other
hand, for the class of channels with a given gate complexity G, we invoke covering number bounds
with respect to the diamond norm distance [25, 32, 68], and we demonstrate that these also control
sequential covering numbers. Concretely, in Corollary 19, we show that
n!G(cid:18)6G(cid:19)512G
N (CPTP ,ε,p) ≤ , (1.9)
T n,G 2 ε
where CPTP denotes the class of n-qubit channels with gate complexity G. Together, these
n,G
results imply the regret bound from Theorem 1. This in turn leads to the claimed mistake bound
via a standard argument (see Lemma 12).
Online convex optimization. Theorem 2 is based on efficient mistake-bounded learning of a
convex mixture of exponentially many known channels. A simple but crucial observation is that
the only unknown about such channels is a classical probability distribution p (for example, in the
special case of Pauli channels, the Pauli error rate distribution). Consequently, online learning of
these channels corresponds to online learning of p when the input states and the measurements
(on the output state evolved by the unknown channel) are adversarially revealed to the learner.
We show that this task can be achieved via an alternative online learning scenario, in which any
adversarially chosen state and measurement can be encoded in a ‘channel observable’ E(t) , which
A,B
when revealed to the learner is associated to a “challenge” vector m(t) given by
m(t) = (m(t) ) with m(t) ∝ Tr[E(t) Γz,x ], (1.10)
z,x z,x∈{0,1}n z,x A,B A,B
where E(t) = (ρ(t))T ⊗M(t), and Γz,x is the Choi representation of the Pauli unitary channel
A,B A B A,B
ρ 7→ Pz,xρPz,x†. The learner produces hypotheses p(t) of the unknown probability distribution
at times t ∈ {1,2,...,T}. The learner’s hypotheses should be such that, for T ∈ {1,2,...},
PT m(t)·p(t) is not too different from PT m(t)·p. Using known guarantees [84], the difference
t=1 t=1
between these two sums can be shown to scale only logarithmically with the size of p’s support
for the multiplicative weights update method. This implies regret bounds, and therefore mistake
bounds, that scale only linearly in the number of qubits.
11Mistake lower bounds. We prove our lower bounds by embedding classical online learning
problems into the quantum tasks of interest, thereby inheriting classical lower bounds. First, it
is easy to embed the task of online learning a general function f : {0,1}n−1 → {0,1} into that of
online learning a general n-qubit unitary. (Alternatively, when allowing for non-unitary channels,
we give such an embedding into (n−1)-qubit channels.) Thus, the folklore mistake lower bound of
Ω(2n) for the former problem immediately carries over to the latter, showing that the class of all
n-qubit unitaries cannot be online learned with a sub-exponential number of mistakes.
Second, to prove mistake lower bounds for learning channels of gate complexity G, we use
the fact that O(2k) many gates suffice to implement an arbitrary function f : {0,1}k → {0,1}
with a classical circuit. We can quantumly realize such a circuit either by first measuring in the
computational basis and then applying the classical circuit, or by implementing irreversible AND
and OR gates with reversible Toffoli gates, where the auxiliary system gets reset to a suitable
value after every gate. Both constructions demonstrate that the class of n-qubit channels of gate
complexity G contains the class of all Boolean functions on the first q = min{log (Θ(G)),n−1}
2
inputs (extended to the remaining subsystems by a trivial action). So, the classical folklore lower
bound gives an Ω(2q) = Ω(min{2n,G}) mistake bound here.
Third, by associating a general function f : {1,...,n} → {0,1} with the n-qubit Pauli channel
(cid:16) (cid:17) (cid:16) (cid:17)
N given by N (ρ) = Nn Zf(i) ρ Nn Zf(i) , we prove that online learning n-qubit Pauli
f f i=1 i i=1 i
channels is at least as hard as online learning a general {0,1}-valued function on ⌊log(n)⌋ bits.
Hence, the classical mistake lower bound for online learning arbitrary functions becomes a Ω(n)
mistake lower bound for Pauli channel online learning.
Computational complexity lower bounds. Our exponential computational complexity lower
bound for online learning Pauli channels with a polynomial mistake bound is a simple formalization
of the following intuition: The channel observables posed as challenges by the adversary are
exponentially-sized objects, and a successful online learner has to process all the exponentially many
entries. We give a simple adversary demonstrating that this intuition is correct, and applies even if
the adversary provides the channel observables already in the basis expansion that is most natural
for Pauli channels, namely the (unnormalized) n-qubit Bell basis.
To prove our computational complexity lower bound for online learning bounded-complexity
channels, we require a hardness assumption. Here, we consider the so-called ring learning with errors
(LWE) problem [85] (RingLWE), which underlies much of lattice-based cryptography. To establish
that hardness of RingLWE implies hardness of online learning slightly superlinear-sized quantum
circuits, we first show, via a known construction, that this class of quantum circuits can implement
a pseudorandom function class. This implies hardness of online learning, because pseudorandom
function classes are hard to learn, an intuition that we formalize specifically for mistake-bounded
online learning. Importantly, as the hardness arises from an underlying classical pseudorandom
function class, it persists even when all challenges consists of input states and projective effect
operators that are computational basis elements. In particular, online learning remains hard here,
even though the learner can efficiently read all challenges. Additionally, as our pseudorandom
function class is secure against adversaries that have query access to the function, the computational
hardness of online learning holds even if the learner can actively choose the (pairwise distinct)
12challenges, rather than those being chosen by the adversary.
Classical adaptive data analysis. In the problem of shadow tomography of quantum channels,
the learner’s task is to output values b ∈ R such that |b − Tr[M(t) N (ρ(t))]| ≤ ε for all
t t B A→B A
t ∈ {1,2,...,T}, where {(ρ(t) ,M(t))}T is a set of state-measurement pairs. They should do so
A B t=1
while minimizing the number k of times that they access the channel. The shadow tomography
problem for multi-time processes is formulated in a similar manner.
Our shadow tomography results are based on Bell sampling of the Choi state of the channel, i.e.,
sending one-half of the maximally-entangled state through the channel and then performing a joint
Bell-basis measurement on the output system and the second entangled copy of the input system.
If the unknown channel is a Pauli channel, then this procedure directly gives us samples from the
Pauli error rate distribution. Consequently, the desired expectation values Tr[M(t) N (ρ(t))] can
B A→B A
be interpreted as (classical) statistical queries with respect to the (unknown) Pauli error rate vector.
Specifically, we have that Tr[M(t) N (ρ(t))] = p·e(t), where p is the Pauli error rate vector and
B A→B A
e(t) = (e(t) ) , e = Tr[((ρ(t))T⊗M(t))Γz,x ]. With this observation, we can make use of
z,x z,x∈{0,1}n z,x A B A,B
the classical adaptive data analysis algorithms presented in Ref. [56] in order to obtain our bound
in Theorem 4 on the number k of accesses to the channel. For an arbitrary unknown channel, we
show that the same Bell sampling strategy enables us to sample from the error-rate vector of the
Pauli-twirled version of the channel, which we denote by NP . Then, as long as ε > 1∥N −NP∥ ,
A→B 2 ⋄
we obtain a similar guarantee as in Theorem 4.
Quantum combs. Our results on multi-time quantum processes make use of theory of quantum
combs [57], also known as “quantum strategies” [60]. We provide formal definitions of quantum
combs in Appendix B. In particular, the analysis of multi-time processes entails use of the so-called
“strategy norm” and its Hölder dual [86], which are the multi-time generalizations of the trace
and spectral norm, respectively, used in the analysis of algorithms for quantum states. They
also generalize the diamond norm and its Hölder dual in the case of quantum channels. A crucial
ingredient in the proof of Theorem 6 is submultiplicativity of the strategy norm under composition of
multi-timeprocesses. Asthecompositionofmulti-timeprocessesisgivenbythelinkproduct[57],the
technique for proving submultiplicativity of the diamond norm does not generalize straightforwardly
to the strategy norm. To the best of our knowledge, a proof of submultiplicativity of the strategy
norm under link product has not been provided before, and we provide such a proof in Appendix B.2
based on semi-definite programming duality.
1.6 Directions for future work
Motivated by the well known impossibility of online learning general unitaries and channels with a
subexponential number of mistakes, our work initiates a study of subclasses of channels that allow
for good regret and mistake bounds in online learning. We have identified two such classes: Channels
of bounded gate complexity and mixtures of arbitrary known channels, with Pauli channels as a
notable special case. However, we show that achieving favorably scaling regret and mistake bounds
13for these classes is not possible in a computationally efficient manner. Our results open up several
directions for future research; here we outline some of them.
First, while our computational complexity lower bounds put limitations on where we can hope
for computationally efficient channel online learning, they still leave relevant regions to explore. On
the one hand, by the same reasoning as in Section 5.2, the channel class under consideration must
not be expressive enough to implement known pseudorandom function constructions. Here, inspired
by the recent work [87], one may investigate the online learnability of shallow quantum circuits. On
the other hand, as we argue in detail in Section 5.1, a necessary condition for efficient online learning
is that the channels of interest admit efficient descriptions. Candidates for such channel classes may
be Clifford circuits or channels represented by matrix product operators of low bond-dimension.
Second, we believe that there is room for “onlinification” of other quantum learning scenarios.
For instance, recent work [28, 29] has proposed to avoid the exponential bottleneck of general process
tomography (compare, e.g., Refs. [13, 14]) by considering learning tasks with arbitrary channels
but restricted or structured input states and output measurements. Similarly, one may attempt to
circumvent exponential lower bounds in online learning arbitrarily complex channels by imposing
restrictions on the behavior of the adversary, for instance, with respect to the challenges that they
can pose. Another line of quantum learning research that has recently seen significant progress
is learning a Hamiltonian from access to the associated dynamics [29, 88–100]. Online learning
variants of the standard Hamiltonian learning task could give insights into whether one can learn to
fine-tune a Hamiltonian evolution according to adaptive feedback.
Finally, while general shadow tomography for quantum channels is not possible, we have
demonstrated that it can become feasible for a suitable subclass, in our case Pauli channels. Given
the important role of online learning quantum states in state tomography procedures, we envision
positive results, both ours and future ones, on online learning restricted classes of channels to serve
as a stepping stone towards shadow tomography procedures for such classes. Achieving the latter
would likely require analogues of threshold search [17] for these kinds of channels.
Acknowledgments
The authors thank Akshay Bansal, Ian George, Soumik Ghosh, Jamie Sikora, and Alice Zheng for
sharing a draft of their independent and concurrent work on online learning quantum objects. The
authors gratefully acknowledge support from the BMBF (QPIC-1, HYBRID), the ERC (DebuQC),
the Munich Quantum Valley, the Einstein Foundation, and Berlin Quantum. MCC was partially
supported by a DAAD PRIME fellowship.
14Table of Contents
1 Introduction 1
1.1 Statement of the problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
1.2 Overview of the main results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
1.3 Extensions of our results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
1.4 Related work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
1.5 Techniques and proof overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
1.6 Directions for future work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
2 Preliminaries 16
2.1 Basics of quantum information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
2.2 Basics of online learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
2.3 The multiplicative weights framework and corresponding guarantees . . . . . . . . . 25
2.4 Problem statement: Online learning classes of quantum channels . . . . . . . . . . . 27
2.5 Obstacles to online learning via the Choi state . . . . . . . . . . . . . . . . . . . . . 28
3 Online learning upper bounds 30
3.1 Regret bound for channels of bounded gate complexity . . . . . . . . . . . . . . . . . 30
3.2 Regret bound for mixtures of known channels . . . . . . . . . . . . . . . . . . . . . . 33
3.3 Regret bounds for multi-time processes . . . . . . . . . . . . . . . . . . . . . . . . . . 36
3.4 Learning-theoretic implications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
4 Mistake lower bounds 45
4.1 Mistake lower bounds for general unitaries and channels . . . . . . . . . . . . . . . . 45
4.2 Mistake lower bounds for channels of bounded complexity . . . . . . . . . . . . . . . 47
4.3 Mistake lower bounds for Pauli channels . . . . . . . . . . . . . . . . . . . . . . . . . 48
5 Computational complexity lower bounds 49
5.1 Computational complexity lower bounds for Pauli channels . . . . . . . . . . . . . . 49
5.2 Computational complexity lower bounds for channels of bounded complexity . . . . 51
6 Shadow tomography of quantum processes 55
6.1 Shadow tomography of multi-time processes . . . . . . . . . . . . . . . . . . . . . . . 57
Bibliography 60
A From qubits to qudits 69
B Multi-time quantum processes 71
B.1 Definitions and basic properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
B.2 Norms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
C Pauli-twirl of quantum channels 76
D Entropic analysis of the MMW algorithm 78
D.1 Proof of Proposition 14 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
D.2 The projected MMW algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81
152 Preliminaries
2.1 Basics of quantum information
Here we provide a brief review of fundamental quantum information concepts that we make use of
throughout this work. We refer to, e.g., Ref. [101] for further details on the concepts and definitions
presented in this subsection.
Pauli operators. For a quantum system of n ∈ N qubits, we define the n-qubit Pauli operators as
Pz,x := (+i)z·xZzXx, x,z ∈ {0,1}n, (2.1)
Zz := Zz1 ⊗Zz2 ⊗···⊗Zzn, Zz = |0⟩⟨0|+(−1)z|1⟩⟨1|, (2.2)
Xx := Xx1 ⊗Xx2 ⊗···⊗Xxn, Xx = |x⟩⟨0|+|x⊕1⟩⟨1|, (2.3)
where the operation “⊕” denotes addition modulo two. From this, we can define the n-qubit Bell
states as
1
Φz,x = |Φz,x⟩⟨Φz,x|, |Φz,x⟩ := (1⊗Pz,x)|Φ⟩, |Φ⟩ = √ X |x,x⟩, (2.4)
2n
x∈{0,1}n
for all z,x ∈ {0,1}n. The Bell state vectors |Φz,x⟩ form an orthonormal basis for (C2)⊗n⊗(C2)⊗n,
and the set {Φz,x} forms a positive operator-valued measure (POVM).
z,x∈{0,1}n
Quantum channels. A quantum channel is a completely positive trace-preserving (CPTP) linear
map N : L(Cd) → L(Cd′). We often write N to refer to a quantum channel with input system
A→B
A and output system B, with corresponding Hilbert spaces H
A
∼= CdA and H
B
=∼ CdB, respectively.
We let CPTP(A;B) denote the set of all quantum channels mapping system A to system B. In this
work, we mostly consider the case d = d = d = 2n, corresponding to a system of n qubits, and we
A B
use the notation CPTP to refer to the set of all quantum channels mapping n qubits to n qubits.
n
The Choi representation (or Choi matrix) of a linear map N : L(Cd) → L(Cd′) is defined as
d−1
C(N) := (id ⊗N)(|Γ ⟩⟨Γ |) = X |i⟩⟨j|⊗N(|i⟩⟨j|), (2.5)
d d d
i,j=0
where id : L(Cd) → L(Cd) is the identity superoperator, and
d
d−1
|Γ ⟩ := X |i,i⟩. (2.6)
d
i=0
The Choi state of N is the normalized Choi matrix, defined as
1 C(N)
Φ(N) := (id ⊗N)(|Γ ⟩⟨Γ |) = . (2.7)
d d d
d d
16WesometimeswriteCN ≡ C(N)andΦN ≡ Φ(N)fortheChoimatrixandChoistate,respectively,
A,B A,B
of a quantum channel N when we want to indicate explicitly the input and output systems
A→B
A and B of the channel. For a quantum channel N , its Choi representation CN is positive
A→B A,B
semi-definite and satisfies Tr [CN ] = 1 .
B A,B A
The function C defined in (2.5) has an inverse, such that we can identify every Hermitian
operator H ∈ L(H ⊗H ) with a Hermiticity-preserving map C−1(H ) : L(H ) → L(H ) as
A,B A B A,B A B
NH := C−1(H ), NH (X ) = Tr [(XT ⊗1 )H ]. (2.8)
A→B A,B A→B A A A B A,B
In particular, if H is positive semi-definite, then NH is completely positive. If in addition
A,B
Tr [H ] = 1 , then NH is a quantum channel. Consequently, the set CPTP(A;B) of quantum
B A,B A
channels is in one-to-one correspondence with the set CPTP′(A;B) := {N ∈ L(H ⊗ H ) :
A,B A B
N ≥ 0, Tr [N ] = 1 }. We let
A,B B A,B A
n o
CPTP′ := N ∈ L(H ⊗H ) : H ∼= H ∼= (C2)⊗n, N ≥ 0, Tr [N ] = 1 (2.9)
n A,B A B A B A,B B A,B A
denote the set of Choi matrices of quantum channels mapping n qubits to n qubits.
Quantum channels also have a Kraus representation, such that
r r
N(ρ) = X K ρK†, X K†K = 1 , (2.10)
ℓ ℓ ℓ ℓ A
ℓ=1 ℓ=1
where r ∈ N and K : H → H is a linear operator for every ℓ ∈ {1,2,...,r}.
ℓ A B
Pauli channels. A Pauli channel is a quantum channel whose Kraus operators are proportional to
the Pauli operators defined in Equation (2.1). Specifically, an n-qubit Pauli channel (by definition)
has the form
P(ρ) = X p Pz,xρPz,x†, (2.11)
z,x
z,x∈{0,1}n
where the Pauli error rates p form a probability distribution, i.e., p ∈ [0,1] for all z,x ∈ {0,1}n
z,x z,x
and P p = 1. The Choi representation of a Pauli channel P is
z,x∈{0,1}n z,x
C(P) = X p Γz,x, (2.12)
z,x
z,x∈{0,1}n
where
√
Γz,x := |Γz,x⟩⟨Γz,x|, |Γz,x⟩ = (1⊗Pz,x)|Γ⟩ = 2n|Φz,x⟩, (2.13)
are the unnormalized versions of the n-qubit Bell states defined in Equation (2.4). We let p = (p :
z,x
z,x ∈ {0,1}n) denote the 4n-dimensional probability vector of error rates.
We let PAULI be the set of all Pauli channels acting on n-qubit systems, and analogously to
n
(2.9), we let
 
PAULI′ :=  N : N = X p Γz,x , p = (p ) ∈ ∆  (2.14)
n A,B A,B z,x A,B z,x z,x 4n
 
z,x∈{0,1}n
17be the set of all Choi matrices of Pauli channels, where
( m )
∆ := p = (p ,p ,...,p ) ∈ Rm : p ∈ [0,1] ∀k ∈ {1,2,...,m}, X p = 1 (2.15)
m 1 2 m k k
k=1
denotes the probability simplex of m ∈ N elements. Depending on the context, we refer to a vectors
p = (p ,p ,...,p ) with values p ,p ,...,p ∈ [0,1] and Pm p = 1 as both a probability vector
1 2 m 1 2 m k=1 k
and a probability distribution.
Associated to every quantum channel N is its Pauli-twirled version, defined as [102]
1
NP(ρ) := X Pz,x†N(Pz,xρPz,x†)Pz,x, (2.16)
4n
z,x∈{0,1}n
where the superscript “P” in NP refers to the set P := {Pz,x : z,x ∈ {0,1}n} of n-qubit Pauli
operators. In other words, the Pauli-twirled version of a channel is given by applying a Pauli
operator, chosen uniformly at random, and its inverse at the input and output of the channel. As
we recall in Appendix C, the Pauli-twirled channel NP is indeed a Pauli channel, and the error
rates are given by p = 1Tr[Φz,xC(N)] for all z,x ∈ {0,1}n. In particular, we show that the Choi
z,x d
representation of the Pauli-twirled channel can be obtained via the pinching channel S in the Bell
P
basis, defined as
S (X) := X |Φz,x⟩⟨Φz,x|X|Φz,x⟩⟨Φz,x| = X Tr[Φz,xX]Φz,x, (2.17)
P
z,x∈{0,1}n x,z∈{0,1}n
for every linear operator X ∈ L((C2)⊗n). In particular, then, the Choi representation of the
Pauli-twirled version NP of a channel N is given by
1
C(NP) = X Tr[Φz,xC(N)]Γz,x = X Tr[Φz,xC(N)]Φz,x = S (C(N)). (2.18)
P
d
z,x∈{0,1}n z,x∈{0,1}n
Channel measurements and observables. An m-outcome measurement of a quantum state is
given by a positive operator-valued measure (POVM), i.e., a set {M(i)}m of m operators satisfying
i=1
0 ≤ M(i) ≤ 1 such that Pm M(i) = 1. Observables for states are simply Hermitian operators H,
i=1
and the expected value of the observable H when measured on a state ρ is Tr[Hρ].
Now, a measurement, or a test, for a quantum channel N is given by a pair consisting
A→B
of a bipartite state ρ and a POVM {M(i) }m , where R is an arbitrary memory/reference
R,A R,B i=1
system; see Figure 2(a). Using Equation (1.6), the probability of obtaining a particular outcome
i ∈ {1,2,...,m} of the test is given by
Tr[M(i) N (ρ )] = Tr[E(i) CN ], (2.19)
R,B A→B R,A A,B A,B
where E(i) = Tr [(1 ⊗ρTA )(1 ⊗M(i) )] for all i ∈ {1,2,...,m}. The right-hand side of this
A,B R B R,A A R,B
equation is the generalized Born rule for quantum channels; see Figure 1(c) for a depiction. The
channel test operators E(i) satisfy E(i) ≥ 0 for all i ∈ {1,2,...,m} and Pm E(i) = ρT ⊗1 ,
A,B A,B i=1 A,B A B
where ρ ≡ Tr [ρ ]. The converse is also true [59, 103], meaning that every channel test can be
A R R,A
18characterized by a set {E(i) }m such that 0 ≤ E(i) ≤ σ ⊗1 for all i ∈ {1,2,...,m}, for some
A,B i=1 A,B A B
density operator σ , and Pm E(i) = σ ⊗1 . The corresponding “physical realization” of the
A i=1 A,B A B
channel test is given by ρ = |ψσ⟩⟨ψσ| , where H ∼= H , |ψσ⟩ is a purification of σ, and
R,A R,A R A
M(i) = σ−1 2E(i) σ−1 2. (2.20)
R,B R R,B R
An especially simple example of a channel test is one without memory, involving an input state ρ at
A
the input of the channel and a measurement {M(i) }m at the output of a channel; see Figure 1(b).
B i=1
In this case, the channel test operators are in tensor-product form, given by E(i) = ρT ⊗M(i) for
A,B A B
all i ∈ {1,2,...,m}.
The statements above for measurements readily generalize to statements about observables
(Hermitian operators), due to the fact that every Hermitian operator has a spectral decomposition,
and the spectral projections form a POVM. Consequently, the expected value of an observable H ,
R,B
measured according to the general scenario depicted in Figure 1(c), is equal to
Tr[H N (ρ )] = Tr[O CN ], (2.21)
R,B A→B R,A A,B A,B
where the “channel observable” is O = Tr [(1 ⊗ρTA )(1 ⊗H )]. If the measurement scheme
A,B R B R,A A R,B
does not contain a memory, then O = ρT ⊗H .
A,B A B
Let us now consider the case that the memory system R has the same dimension as the input
system A of the channel, so let us make the relabeling R ≡ A′. Let us also suppose that ρ ≡ ψ
R,A A′A
is a pure state. Then, for every bipartite pure state ψ , there exists a state ρ such that
A′A A
1 1
ψ = ρ2Γ ρ2. The overall observable is then
A′A A A′A A
1 1
O
A,B
= Tr A′[(1 A⊗H A′B)((ρ A2Γ A′Aρ A2)TA ⊗1 B)]
= Tr A′[(1 A⊗H A′B)((ρT A′)1 2F A′A(ρT A′)1 2 ⊗1 B)]
=
d XA−1
Tr A′h (1 A⊗H A′B)((ρT A′) 21 |j,i⟩⟨i,j| A′A(ρT A′)1 2 ⊗1 B)i
i,j=0
=
d XA−1
|i⟩⟨j| A⊗Tr A′h H A′B(ρT A′) 21 |j⟩⟨i| A′(ρT A′)1 2i
i,j=0
=
d XA−1
|i⟩⟨j| A⊗⟨i| A′(ρT A′)1 2H A′B(ρT A′) 21 |j⟩
A′
i,j=0
= (ρT A)1 2H A,B(ρT A)1 2. (2.22)
Note that a special case of the observable in Equation (2.22) is when ρ = 1 A, which corresponds
to measuring H on the Choi state of the channel. In this case
A dA
A,B
1
O = H (ρ = 1 /d ), (2.23)
A,B A,B A A A
d
A
which means that
Tr[O CN ] = Tr[H ΦN ]. (2.24)
A,B A,B A,B A,B
19Now, the operator/spectral norm ∥·∥ is used to characterize measurement operators and
∞
observables for quantum states, because it is the (Hölder) dual to the trace norm ∥·∥ . For
1
quantum channels, the relevant norm is the diamond norm [104]. Let N : L(H ) → L(H ) be a
A B
Hermiticity-preserving linear map. The diamond norm of N can be expressed as
A→B
∥N∥ = ∥CN ∥
⋄ A,B ⋄1
n o
:= sup Tr[CN (S −T )] : S +T = σ ⊗1 , Tr[σ ] = 1
A,B A,B A,B A,B A,B A B A
SA,B,TA,B≥0
σA≥0
n o
= inf t : −Y ≤ CN ≤ Y , Tr [Y ] = t1
A,B A,B A,B B A,B A
t≥0
YA,B≥0
n o
= inf t : −tN ≤ CN ≤ tN , Tr [N ] = 1 . (2.25)
A,B A,B A,B B A,B A
t≥0
NA,B≥0
The norm ∥·∥ is referred to as the strategy 1-norm, and we define it formally in Appendix B. The
⋄1
relevant norm for channel observables is thus the Hölder dual of the strategy 1-norm, which is given
by [86, 105]
n o
∥O ∥∗ := sup Tr[O (X −Y )] : Tr [X +Y ] ≤ 1
A,B ⋄1 A,B A,B A,B B A,B A,B A
XA,B≥0,
YA,B≥0
n o
= inf Tr[Y ] : −Y ⊗1 ≤ O ≤ Y ⊗1
A A B A,B A B
YA≥0
n o
= inf t : −tσ ⊗1 ≤ O ≤ tσ ⊗1 , Tr[σ ] = 1 , (2.26)
A B A,B A B A
t≥0,
σA≥0
for every Hermitian operator O acting on H ⊗H . We note that channel test operators satisfy
A,B A B
∥E ∥∗ ≤ 1. Also, for channel observables without memory, it holds that
A,B ⋄1
∥ρT ⊗H ∥∗ = ∥ρT∥ ∥H ∥ = ∥H ∥ , (2.27)
A B ⋄1 A 1 B ∞ B ∞
as we might expect, and which is a property interesting in its own right; we refer to Appendix B
for a proof. In general, we have that ∥O ∥∗ ≥ ∥O ∥ for all Hermitian O ∈ L(H ⊗H ).
A,B ⋄1 A,B ∞ A,B A B
This follows immediately from (2.26), on account of the fact that ∥σ ∥ ≤ ∥σ ∥ = Tr[σ ] =
A ∞ A 1 A
1 ⇒ −1 ≤ σ ≤ 1 for every σ in the optimization in (2.26), and the fact that ∥H∥ = inf{t :
A A A A ∞
−t1 ≤ H ≤ t1 } for all Hermitian H ∈ L(Cd).
d d
Multi-time quantum processes. Multi-time quantum processes are those that occur over
multiple time steps, as opposed simply one time step for a quantum channel. A simple example of a
multi-time quantum process is the one depicted in Figure 2(a), in which the process (in blue) consists
of three (independent) uses of a quantum channel N. In Figure 2(b), we depict in blue a quantum
multi-time process with memory, which can model non-Markovian dynamics [61]. Measurements, or
testers, for multi-time processes consist of an input state to the process, several (possibly adaptive)
interactions with the process over multiple time steps, and finally a measurement. The testers are
depicted as the red processes in Figure 2.
20The mathematical objects describing multi-time processes and testers are known as quantum
combs [57, 106] and quantum strategies [60], and we provide formal definitions of these objects
in Appendix B. Briefly, quantum combs are multipartite operators that are defined as the Choi
representations of multi-time quantum processes. For k ∈ N, let H(k) ≡ H ⊗H ⊗H ⊗H ⊗
A,B A1 B1 A2 B2
···⊗H ⊗H , such that the systems A ,A ,...,A are the input systems and B ,B ,...,B
A k B k 1 2 k 1 2 k
are the output systems; see Figure 2. Then, the set of quantum combs describing r-step multi-time
quantum processes is defined as follows:
COMB (A ,...,A ;B ,...,B )
r 1 r 1 r
n
:= N ∈ L (H(r) ) : ∃N ∈ L (H(k) ), Tr [N ] = N ⊗1 ,
r + A,B k + A,B B k k k−1 A k
o
k ∈ {2,3,...,r}, Tr [N ] = 1 . (2.28)
B1 1 A1
We suppress the system labels and simply write COMB when the systems are unimportant or
r
understood in the context being considered. For the process in blue in Figure 2(b), its Choi
representation belongs to the set COMB . We also note that COMB = CPTP′. The set of inputs
3 1
to multi-time processes, sometimes called co-strategies, are defined as the Choi representations of
multi-time processes in which the first input system is trivial. Specifically, let He A(k ,)
B
≡ C⊗H
A1
⊗
···⊗H ⊗H , for k ∈ N. Then, the set of inputs to multi-time processes is defined as
B A
k−1 k
COMB∗(A ,...,A ;B ,...,B )
r 1 r 1 r−1
:= COMB (∅,B ,...,B ;A ,...,A )
r 1 r−1 1 r
n
= D
r
∈ L +(He A(r ,) B) : ∃D
k
∈ L +(He A(k ,) B),Tr
A
k[D k] = D k−1⊗1
B
k−1,
o
k ∈ {2,3,...,r}, Tr [D ] = 1 . (2.29)
A1 1
An example is the red process in Figure 2(b) (excluding the measurement), which belongs to the
set COMB∗. Again, we suppress the system labels and simply write COMB∗ when the systems are
3 r
unimportant or understood in the context being considered. Observe that every element of COMB∗
r
is a positive semi-definite operator with unit trace. In particular, the elements of COMB∗ are density
r
operators, and we can think of them as multi-time analogues of quantum states.
The analogue of a POVM for multi-time processes, and thus the multi-time generalization of a
channel test as we defined them above, is a mult-time tester: a set {E(i)}m of positive semi-definite
i=1
test operators E(i) ∈ L(H(r) ) such that 0 ≤ E(i) ≤ S ⊗1 for all i ∈ {1,2,...,m}, for some
A,B Br
S ∈ COMB∗, and Pm E(i) = S ⊗1 .
r i=1 r Br
The multi-time analogues of the norms in (2.25) and (2.26) are the strategy r-norm and its
Hölder dual, which can be expressed as [86]
n o
∥O∥ = inf t : t ≥ 0, −tN ≤ O ≤ tN, N ∈ COMB , (2.30)
⋄r r
n o
∥O∥∗ = inf t : t ≥ 0, −tS ⊗1 ≤ O ≤ tS ⊗1 , S ∈ COMB∗ , (2.31)
⋄r Br Br r
for every Hermitian operator O ∈ L(H(r) ). It holds that ∥O∥∗ ≥ ∥O∥ for every Hermitian
A,B ⋄r ∞
operator O ∈ L(H(r) ). For a multi-time test {E(i)}m with r time steps, it holds that every test
A,B i=1
21operator E(i), i ∈ {1,2,...,m}, satisfies ∥E(i)∥∗ ≤ 1. We also have the Hölder inequality
⋄r
|Tr[ON]| ≤ ∥O∥∗ ∥N∥ , (2.32)
⋄r ⋄r
for all Hermitian O,N ∈ L(H(r) ).
A,B
2.2 Basics of online learning
We view online learning a hypothesis class F ⊆ YX of functions as an interactive game between a
learner and an adversary. In round t of the interaction, the adversary challenges the learner with an
input x ∈ X. Then, the learner predicts the output f (x ) ∈ Y based on their current hypothesis f .
t t t t
(We focus on proper online learning, where f ∈ F for all t.) To conclude the round, the adversary
t
provides the learner with feedback in the form of a loss ℓ (f (x )), and the learner uses this piece of
t t t
information to update3 their hypothesis to f(t+1). For our purposes, the target space is Y = [0,1]
and every ℓ : [0,1] → R is convex and Lipschitz. Specific losses of interest are often of the form
t
ℓ (y) = ℓ(y−b ) for some convex and Lipschitz ℓ : [0,1] → [0,∞) and b ∈ [0,1]; for example, this
t t t
gives rise to the L -losses with ℓ(·) = |·|p. In these cases, we assume that the adversary provides the
p
loss ℓ (f (x )) = ℓ(f (x )−b ) by explicitly revealing the value of b , and that ℓ is known in advance.
t t t t t t t
Note that in general, the b here can be arbitrary. If there is an “approximately true” underlying
t
concept f∗ ∈ F such that |b −f∗(x )| ≤ ε/3 holds for all t, then we speak of a realizable scenario,
t t
otherwise we call the setting non-realizable.
Regret-bounded online learning. One way of phrasing desiderata in online learning is in terms
of bounds on the difference between the incurred and the in hindsight optimal incurred loss, the
so-called regret. Namely, after T rounds of interaction, we say that the learner has incurred a regret
of4
T T
R = X ℓ (f (x ))−minX ℓ (f(x )). (2.33)
T t t t t t
f∈F
t=1 t=1
The goal of an online learner now is to achieve a small regret, in particular scaling sub-linearly with
T. Note that this model makes sense even if no restrictions on how the adversary chooses the ℓ (or,
t
in the more concrete case of L -losses, the b above) are imposed.
p t
We make use of the following lemma throughout this work.
Lemma 9 (Regret bound). Consider the online learning scenario described above, in which the
functions ℓ are convex and differentiable. Then, for every f ∈ F, it holds that
t
T T
X(cid:16)
ℓ (f (x ))−ℓ (f(x
))(cid:17)
≤
X(cid:16)
ℓ′(f (x ))(f (x )−f(x
))(cid:17)
. (2.34)
t t t t t t t t t t t
t=1 t=1
3Weassumetheupdatingproceduretobedeterministic. Onecanthinkofrandomizedlearnersasdeterministically
updating a probability distribution over hypotheses, whose performance is measured by its expected loss.
4Here,weimplicitlyassumethattheminimumexists,whichwillbethecaseforourpurposesbecauseofcompactness
and continuity. More generally, one may replace the minimum by an infimum.
22The regret in (2.33) is therefore bounded from above as
T T
R ≤ X ℓ′(f (x ))f (x )−minX ℓ′(f (x ))f(x ). (2.35)
T t t t t t t t t t
f∈F
t=1 t=1
Proof. Since ℓ is convex and differentiable, it readily follows that
t
ℓ (y −y ) ≤ ℓ′(y )(y −y ), (2.36)
t 1 2 t 1 1 2
for all y ,y ∈ [0,1]. (See, e.g., Ref. [46, Chapter 2].) Consequently, for every f ∈ F,
1 2
ℓ (f (x ))−ℓ (f(x )) ≤ ℓ′(f (x ))(f (x )−f(x )), (2.37)
t t t t t t t t t t t
for all t ∈ {1,2,...,T}. Therefore,
T T
X(cid:16)
ℓ (f (x ))−ℓ (f(x
))(cid:17)
≤
X(cid:16)
ℓ′(f (x ))(f (x )−f(x
))(cid:17)
(2.38)
t f t t t t t t t t t
t=1 t=1
T T
= X ℓ′(f (x ))f (x )−X ℓ′(f (x ))f(x )
t t t t t t t t t
t=1 t=1
T T
≤ X ℓ′(f (x ))−minX ℓ′(f (x ))f(x ).
t t t t t t t
f∈F
t=1 t=1
The first inequality is (2.34). The inequality in (2.35) follows because the function f ∈ F is
arbitrary. ■
Next,werecallresultsfromRefs.[82,83],whichdemonstratehowtoobtainregretboundsinterms
of sequential complexity measures of the hypothesis class. To formulate these results, we introduce
the following pieces of notation: We use z = (z )T with labeling functions z : {±1}t−1 → Z to
t t=1 t
describe a complete rooted binary tree of depth T with nodes labeled by elements of Z. That is,
if we arrive at a node by following a path π = (π )t−1 ∈ {±1}t−1 of length t−1 from the root,
s s=1
then z assigns the label z (π) to that node. For notational convenience, if π ∈ {±1}T is a path of
t
length T > t−1, we identify z (π) = z (π ,...,π ). We can now introduce a notion of sequential
t t 1 t−1
covering to capture the effective size of a function class.
Definition 10 (Sequential covering numbers [82]). Let G ⊆ RZ, let z = (z )T be a complete
t t=1
rooted binary tree of depth T, and let ε > 0, p ≥ 1. We call a set V of R-valued complete binary
trees of depth T a sequential p-norm ε-cover of G on z if the following holds:
1 T
!1/p
∀g ∈ G ∀π ∈ {±1}T ∃v ∈ V : X |v (π)−g(z (π))|p ≤ ε. (2.39)
t t
T
t=1
The sequential p-norm ε-covering number of G on z is defined to be
N (G,ε,p) := inf{|V| : V is a sequential p-norm ε-cover of G w.r.t. z} . (2.40)
z
We write N (G,ε,p) = sup N (G,ε,p), where the supremum is over trees of depth T.
T z z
23Note that Definition 10 does not require a cover to consist of R-valued trees that can be realized
within G. In that sense, the above notion is one of exterior covering. Also, it will be useful to
observe that sequential covering numbers satisfy the monotonicity relation N (G,ε,p) ≤ N (G,ε,q)
z z
for 1 ≤ p ≤ q ≤ ∞.
Similarlytohowempiricalmetricentropies, definedasthelogarithmofcoveringnumbers, control
the generalization error in probably approximately correct learning, sequential metric entropies, the
logarithm of sequential covering numbers, can be used to bound the regret in online learning. This
result goes back to Refs. [82, 83], we state it in a form similar to Ref. [20, Theorem 9].
Theorem 11 (Regret bound from sequential covering [83, Theorem 3] and [82, Theorem 7]). Let
F ⊆ [0,1]X. For every t ∈ N , let ℓ : [0,1] → R be convex and L-Lipschitz. Then, there exists an
≥1 t
online learning strategy that, when presented sequentially with x ,...,x ∈ X and associated loss
1 T
functions ℓ ,...,ℓ , outputs a sequence f ,...,f ∈ F of hypotheses whose regret is bounded as
1 T 1 T
XT
ℓ (f (x
))−minXT
ℓ (f(x )) ≤ 2LT sup inf
(cid:26)
4α+
√12 Z 1q
logN (F,β,2)
dβ(cid:27)
(2.41)
t t t t t x
f∈F x α>0 T α
t=1 t=1
(cid:26) 12 Z 1q (cid:27)
≤ 2LT inf 4α+ √ logN (F,β,2) dβ .
T
α>0 T α
Here, the sup is a supremum over all complete binary trees of depth T with nodes labeled by
x
elements of X.
Mistake-bounded online learning. As an alternative to measuring the performance of an
online learner in terms of regret, we can count the number of rounds in which the learner incurs
a loss that exceeds a certain threshold. More formally, given ε ∈ (0,1), we say that the learner
makes an ε-mistake in round t if ℓ (f (x )) > ε. The goal of the online learner then becomes to
t t t
make only a small number of ε-mistakes. Note that this mistake-bounded model of online learning
only makes sense in the realizable scenario, since the number of ε-mistakes is in general infinite in
the non-realizable scenario.
To conclude our introductory discussion of online learning, we note a well known connection
between the models of regret- and mistake-bounded online learning. Informally, we can say that
good regret bounds lead to good mistake bounds, and the next result makes this formal.
Lemma 12 (From regret to mistake bounds (compare, e.g., Ref. [20, Section 3.3] or [107, Corollary
2.1.4])). Let F ⊆ RX. Suppose we have an online learner for F that is sequentially presented with
x ,...,x ∈ X and losses evaluated according to ℓ (·) = |(·)−b |, where there exists f ∈ F such
1 T t t ∗
that |b −f (x )| ≤ ε/3 holds for all t. For an update rule that results in a sequence f ,...,f ∈ F
t ∗ t 1 T
of outputs from the learner, suppose that the regret is bounded as R ≤ h (ε,T)+h (ε), where
T 1 2
h : (0,1)×N → R and h : (0,1) → R . Assume that h (ε,T) ∈ o(T) for every fixed ε, and
1 ≥1 ≥0 2 ≥0 1
that h (ε) < 2ε/3. Let T∗ = T∗(h ,h ,ε) be the smallest natural number such that
2 1 2
h (ε,T′)
T′ > T∗ implies T′ > 1 . (2.42)
(2ε/3)−h (ε)
2
Then, applying the update rule only in rounds in which the learner makes an ε-mistake, and
outputting the previous hypothesis otherwise, leads to a total number of ε-mistakes bounded by T∗,
independently of the overall number of rounds.
24Notice that the online learning procedure achieving the mistake bound T∗ in Lemma 12 is
mistake-driven: It updates the hypothesis only when an ε-mistake is made. After a round without
an ε-mistake, the learner just proceeds without changing their hypothesis.
Proof. Let T′ denote the number of ε-mistakes (i.e., the number of updates) and let us focus on the
subsequence of rounds in which the learner makes a mistake. First note that, by assumption, there
is a function f ∈ F such that the prediction f (x ) achieves loss ℓ(f (x )) ≤ ε/3 for all t. Hence,
∗ t t ∗ t
the optimal accumulated loss after T′ rounds is ≤ T′ε/3. As the described procedure applies the
update rule only when a loss > ε is incurred, this mistake-driven online learning procedure incurs an
accumulated loss of > T′ε. Thus, its regret is > 2T′ε/3. Comparing this with the assumed regret
upper bound of R ≤ h (ε,T′)+h (ε)T′ and rearranging, we see that T′ ≤ h1(ε,T′) . Thus, by
T′ 1 2 (2ε/3)−h2(ε)
the definition of T∗, we conclude T′ ≤ T∗. ■
2.3 The multiplicative weights framework and corresponding guarantees
In this section, we provide a brief overview of the multiplicative weights framework and refer to
Ref. [84] for a more comprehensive review. This toolkit has a variety of applications in areas such as
game theory and economics [108], machine learning [37, 109], and semidefinite programming [110,
111]. In quantum computing, the matrix multiplicative weights algorithm was used to prove that
the complexity classes QIP (problems with a quantum interactive proof system) and PSPACE
(problems solvable in polynomial amount of space) coincide [112].
Consider an interactive game, in which a learner is tasked with picking the best option from a
set of d ∈ N decisions over T ∈ N rounds of interaction. In each round 1 ≤ t ≤ T, every decision
i ∈ {1,2,...,d} is associated with a cost m(t) ∈ [−1,1]. Upon making their decision, the learner is
i
informed of the associated cost, which they can use to make their decisions in subsequent rounds.
The learner’s goal is to output a sequence of decisions over the T rounds such that their total
accumulated cost after T rounds is minimized.
In the multiplicative weights framework, the decision in round 1 ≤ t ≤ T is made according to
a d-dimensional probability vector p(t) = (p(t) ,p(t) ,...,p(t)). Explicitly, p(t) is the probability of
1 2 d i
making the decision i ∈ {1,2,...,d}. The expected cost of the distribution p(t) is then m(t)·p(t),
where m(t) = (m(t) ,...,m(t)) is the vector of costs. The expected accumulated cost after T rounds
1 d
is thus given by PT m(t)·p(t). The multiplicative weights update (MWU) algorithm, presented in
t=1
Algorithm 1, is a method for obtaining a sequence of probability distributions over decisions based
on the costs incurred in the previous rounds.
Arora, Hazan and Kale [84] have shown that if a learner makes their decisions according to the
MWU algorithm, then their expected accumulated cost only grows logarithmically in d, the number
of possible decisions.
Theorem 13 ([84, Theorem 2.1 & Corollary 2.2]). Consider the setting of an interactive game, as
described above, with cost vectors m(t) satisfying m(t) ∈ [−1,1] for all i ∈ {1,2,...,d} and for all
i
t ∈ {1,2,...,T}, and let q be an arbitrary probability distribution over the d decisions. Using the
MWU algorithm (Algorithm 1), the expected accumulated cost over T ∈ N rounds is bounded from
25Algorithm 1 Multiplicative weights update (MWU) algorithm [84]
Require: η ∈ (0, 1]; T ∈ N rounds; d ∈ N decisions; initial weights w(1) = (1,1,...,1).
2
1: for t = 1,2,...T do
2:
Output the decision/estimate p(t) = w(t), ϕ(t) = Pd w(t).
ϕ(t) i=1 i
3: Receive the cost vector m(t) = (m(t) ,m(t) ,...,m(t)), m(t) ∈ [−1,1], i ∈ {1,2,...,d}.
1 2 d i
4: Update the weights as w(t+1) = w(t)(1−ηm(t)), i ∈ {1,2,...,d}.
i i i
5:
Set w(t+1) = (w(t+1) ,w(t+1) ,...,w(t+1)).
1 2 d
6: end for
Algorithm 2 Matrix multiplicative weights (MMW) algorithm [110, 113]
Require: η ∈ (0,1]; Initialize W(1) = 1
d
1: for t = 1,2,...,T do
2:
Output the decision/estimate ω(t) = W(t) .
Tr[W(t)]
3: Receive the cost matrix L(t), −1 d ≤ L(t) ≤ 1 d.
h i
4:
Update the weight matrix: W(t+1) = exp −ηPt t′=1L(t′) = exp[log(W(t))−ηL(t)].
5: end for
above as
XT
m(t)·p(t) ≤
XT
(m(t)+η|m(t)|)·q+
logd
≤
XT
m(t)·q+ηT +
logd
. (2.43)
η η
t=1 t=1 t=1
The matrix multiplicative weights (MMW) algorithm [110, 113] is a generalization of the MWU
algorithm to costs specified d×d Hermitian matrices L(t) that satisfy −1 ≤ L(t) ≤ 1 ; equivalently,
d d
∥L(t)∥ ≤ 1. Here, the decisions are described by density operators ω(t), and the expected cost in
∞
round t is equal to Tr[L(t)ω(t)]. The MMW algorithm, presented in Algorithm 2, is a method for
obtaining a sequence of density operators ω(1),ω(2),...,ω(T), based on the costs incurred in the
previous rounds.
A bound on the expected accumulated cost for the MMW algorithm has been shown in Ref. [110,
Theorem 3.1]. By modifying the arguments in Ref. [110] via use of the relative entropy, we provide
a bound on the expected accumulated cost for the MMW algorithm that can in general be tighter
than the one obtained in Ref. [110, Theorem 3.1].
Proposition 14 (Bound on the expected accumulated cost for the MMW algorithm). Let ρ be
an arbitrary density operator. Let T ∈ N be the number of rounds of interaction, and consider a
sequence L(1),L(2),...,L(T) of cost matrices in dimension d ∈ {2,3,...} along with the updates
ω(t) provided by the MMW algorithm in Algorithm 2. Then, the expected accumulated cost over
the T rounds is bounded from above as
XT
Tr[L(t)ω(t)] ≤
Tr"
ρ
XT L(t)!# +ηXT
Tr[(L(t))2ω(t)]+
logd−H(ρ)
, (2.44)
η
t=1 t=1 t=1
where H(ρ) := −Tr[ρlogρ] is the von Neumann entropy of ρ.
26Proof. See Appendix D, where we also describe how the bound in Ref. [110, Theorem 3.1] arises as
a special case of our bound in Equation (2.44). ■
Remark 15 (The Hedge algorithm). If the cost matrices L(t) in the MMW algorithm are all
diagonal in the same basis, then Algorithm 2 reduces to the so-called Hedge algorithm, introduced
by Freund and Schapire [114]. We state this algorithm in Appendix D, and in Corollary 61 we state
the Hedge algorithm counterpart to Proposition 14 above. ◀
2.4 Problem statement: Online learning classes of quantum channels
OurtaskistoonlinelearnaclassC ⊆ CPTP ofn-qubitquantumchannels, inthesenseofpredicting
n
the quantities Tr[M(t) N (ρ(t) )], with the state-measurement pairs (ρ(t) ,M(t) ) provided by
R,B A→B R,A R,A R,B
an adversary, where R is an arbitrary finite-dimensional reference system; see Figure 1. Let us now
cast this problem in terms of the general framework of online learning laid out in Section 2.2.
We fix finite-dimensional Hilbert spaces H and H . Then, the input set/domain X comprises
A B
state-measurement pairs (ρ ,M ), where R is an arbitrary finite reference system. Equivalently,
R,A R,B
due to (2.19), X comprises channel test operators E . Precisely,
A,B
n o
X = E ∈ L(H ⊗H ) : ∃σ s.t. 0 ≤ E ≤ σ ⊗1 , σ ≥ 0, Tr[σ ] = 1 (2.45)
A,B A B A A,B A B A A
n o
= E ∈ L(H ⊗H ) : E ≥ 0, ∥E ∥∗ ≤ 1 ,
A,B A B A,B A,B ⋄1
where in the second equality we have used Equation (2.26). The output set is Y = [0,1], and F is
defined by the subclass C ⊆ CPTP of n-qubit channels (in which case H ∼= H ∼= (C2)⊗n), such
n A B
that for every N ∈ C we define the function f as f (E) = Tr[EC(N)] for all E ∈ X. In other
N N
words,
n o
F = f : X → [0,1] : N ∈ C, f (E) = Tr[EC(N)] ∀E ∈ X . (2.46)
N N
Notably, due to Equation (2.19), we can see that our online learning task is equivalently formulated
as the task of learning a class C′ of Choi matrices defined by the channels in C, where
n o
C′ := N : N = C(N), N ∈ C ⊆ CPTP′ . (2.47)
n
We therefore view the adversary as providing channel test operators E(t) and having the learner
A,B
predict the quantities Tr[E(t) CN ] based on hypotheses for the Choi matrix of the unknown
A,B A,B
channel. We denote the learner’s hypothesis Choi matrices by N(t) for t ∈ {1,2,...,T}.
A,B
As outlined in Section 2.2, we will evaluate the performance of an online learner in terms of
either the regret or the number of mistakes. That is, on the one hand, the learner aims to achieve a
small regret
T T
R = X ℓ (Tr[E(t) N(t) ])−minX ℓ (Tr[E(t) CN ]), (2.48)
T t A,B A,B t A,B A,B
N∈C
t=1 t=1
where the losses ℓ are revealed by the adversary. More precisely, we will aim for regret bounds
t
scaling as O(p T ·poly(n)). On the other hand, in the realizable scenario, where there exists a (to
27the learner unknown) channel N ∈ C such that all losses take the form
A→B
ℓ (·) = ℓ((·)−b ), (2.49)
t t
where ℓ is some fixed function and each b satisfies |b −Tr[E(t) CN ]| ≤ ε/3, the learner aims to
t t A,B A,B
achieve a small number of ε-mistakes. Here, our goal will be to guarantee mistake bounds scaling as
O(poly(n,ε−1)). We can summarize the formulation of our channel online learning task as follows:
Problem 1 (Online learning classes of quantum channels). Consider a subset C ⊆ CPTP of
n
n-qubit quantum channels, and let N ∈ C, with Choi representation CN ∈ C′, be unknown.
A→B A,B
Given a sequence of T ∈ N interactive rounds, in which two-outcome channel test operators
E(1) ,E(2) ,··· ,E(T) ∈ X are presented sequentially by an adversary, the problem is to output a
A,B A,B A,B
sequence of Choi matrices N(1) ,N(2) ,...,N(T) ∈ C′, such that for losses ℓ as defined in (2.49), the
A,B A,B A,B t
regret in (2.48) scales as O(p T ·poly(n)) and the number of ε-mistakes scales as O(poly(n,ε−1)). ◀
Remark 16. In this work, we primarily consider the case that the input system dimension d
A
and the output system dimension d are equal and satisfy d = d = d = 2n, although Problem 1
B A B
applies also to quantum channels with different input and output system dimensions. In particular,
if d = 1 and d = d = 2n, then every channel is a state-preparation channel for some n-qubit
A B
quantum state, and Problem 1 reduces to online learning of quantum states, as considered in
Ref. [20]. ◀
Remark 17. Successfully solving Problem 1 does not imply learning of the unknown channel with
respect to the diamond norm, i.e., the learner’s hypotheses N(t) could be very far from the true
A,B
Choi matrix CN with respect to the strategy 1-norm in (2.25). In our scenario, the learner’s only
A,B
goal is to ensure that their hypotheses are such that Tr[E(t) N(t) ] well approximates Tr[E(t) CN ]
A,B A,B A,B A,B
in most rounds, and this can be achieved by hypotheses that are not necessarily close to the true
Choi matrix with respect to the strategy 1-norm. ◀
2.5 Obstacles to online learning via the Choi state
As pointed out above, the problem of online learning classes of quantum channels (Problem 1) is
equivalent to the problem of online learning classes of Choi matrices. A natural first strategy for
solving this problem might then be to simply online learn the Choi state of the unknown channel
using the protocols presented in Ref. [20] for online learning of quantum states, such as the MMW
algorithm (Algorithm 2). However, we immediately encounter two issues.
First, the MMW algorithm (Algorithm 2) cannot be applied out of the box: while Choi states
ΦN of quantum channels N have unit trace, they also have to satisfy Tr [ΦN ] = 1 /d ,
A,B A→B B A,B A A
which the iterates of Algorithm 2 will generally not guarantee. Furthermore, the proof of Ref. [110,
Theorem 3.1], as well as the proof of Proposition 14 above, relies crucially on the fact that the
iterates of the MMW algorithm have unit trace. So, potential modifications of the update rule
would have to simultaneously ensure the unit trace and the partial trace conditions.
We can modify the MMW algorithm by adding a projection step: for every iterate W(t) of the
A,B
MMW algorithm, we find the closest Choi state ρ(t) with respect to relative entropy and use that
A,B
28as our hypothesis for the unknown Choi state. In other words, we let
1
n o
ρ(t) := argmin D(ρ ∥ω(t) ) : ρ ≥ 0, Tr [ρ ] = A , (2.50)
A,B ρA,B A,B A,B A,B B A,B d A
where ω(t) = W(t) /Tr[W(t) ] and the relative entropy D(P∥Q) of two positive semi-definite
A,B A,B A,B
operators P and Q is defined as [101]
(
Tr[P logP −P logQ] if supp(P) ⊆ supp(Q),
D(P∥Q) := (2.51)
+∞ otherwise.
We present the modified MMW algorithm in Algorithm 3. Then, because the relative entropy is a
Bregman divergence [115], we can regard Algorithm 3 as a particular instance of the online mirror
descent algorithm [46, Section 5.3]. Consequently, we obtain a regret bound for Choi states that is
similar to the regret bound in Proposition 14, thus similar to the MMW regret bound in Ref. [20]
for online learning of quantum states. We provide the details in Appendix D.2.
Algorithm 3 Projected MMW algorithm for Choi states of quantum channels
Require: η ∈ (0,1); Initialize W(1) = 1 ⊗1 and ρ(1) = 1 1 ⊗1
1: for t = 1,2,...,T do
A,B A B A,B dAdB A B
2:
Output the decision/estimate ρ(t)
A,B
3: Receive the cost matrix L( At ,) B, −1 A,B ≤ L( At ,) B ≤ 1 A,B
4:
Update the weight matrix: W(t+1) = exp[log(W(t) )−ηL(t) ], ω(t+1) = W(t+1) /Tr[W(t+1)]
A,B A,B A,B A,B A,B A,B
n o
5: Project: ρ( At ,+ B1) := argmin ρA,B D(ρ A,B∥ω A(t ,+ B1)) : ρ A,B ≥ 0, Tr B[ρ A,B] = 1 A/d A
6: end for
The second issue is that the above strategy of learning the Choi state of the unknown channel
leads to favorable regret and mistake bounds, but only as long as we modify Problem 1 as follows:
instead of predicting expectation values of the form Tr[E CN ], where CN is the Choi matrix of
A,B A,B A,B
the unknown channel N , we aim to predict values of the form Tr[E ΦN ], where ΦN is the
A→B A,B A,B A,B
Choi state of N . Now, because of Equation (1.6), we see that Tr[E CN ] = d Tr[E ΦN ].
A→B √ A,B A,B A A,B A,B
Thus, even though we show that the O(L Tn) regret bound of [20] carries over to (properly) online
√ √
learning the Choi state, this implies only a regret bound of O(dL Tn) = O(2nL Tn) when it
comes to our actual task of learning the Choi matrix (and thus the channel), which has a favorable
square root scaling in T but an unfavorable exponential scaling in the number of qubits5.
5Note that the dimension factor d=d =2n is dimension of the input system of the channel. As explained in
A
Remark16, inthecased =1, ourproblemreducestoonlinelearningofquantumstates, andthedimensionfactorin
A
the regret bound becomes 1, as expected [20].
293 Online learning upper bounds
3.1 Regret bound for channels of bounded gate complexity
In this section, we show online learnability for quantum channels of bounded gate complexity6. We
say that a quantum channel N has (exact) gate complexity (at most) G ∈ N [116, 117] if there
exists a (not necessarily geometrically) two-local7 quantum circuit with G two-qubit channels as
gates that implements N. Such quantum channels include, for example, noisy quantum circuits
modeled in terms of perfect two-qubit unitary gates followed by single-qubit noise channels. The
set of n-qubit channels of gate complexity (at most) G is denoted by CPTP . We abuse notation
n,G
and also use CPTP to denote the class of [0,1]-valued functions on channel test operators that
n,G
arises from G-gate channels as described in Section 2.4. We first bound the sequential covering
numbers for (the [0,1]-valued function classes associated to) such channels. Theorem 11 then gives
us a regret bound, from which we can derive a mistake bound via Lemma 12.
The (interior) covering number of the set CPTP of quantum channels with gate complexity
n,G
at most G is defined to be
N(CPTP ,ε,∥·∥ ) := inf{|N| : N ⊆ CPTP , ∀N ∈ CPTP ∃M ∈ N, ∥N −M∥ ≤ ε}. (3.1)
n,G ⋄ n,G n,G ⋄
The fact that quantum channels of bounded gate complexity also have bounded complexity in the
sense of covering numbers has previously been observed in Refs. [25, 32, 67, 68]. We recall this
insight and its proof in the following lemma.
Lemma 18 (Covering number bounds from gate complexity (see Refs. [68, Theorem C.2] and [32,
Theorem 8])). Let ε ∈ (0,1). The (interior) ε-covering number of CPTP with respect to ∥·∥ is
n,G ⋄
bounded as
n!G(cid:18)6G(cid:19)512G
N(CPTP ,ε,∥·∥ ) ≤ . (3.2)
n,G ⋄ 2 ε
Proof. Let ε′ = ε. From Ref. [68, Lemma C.2], we have that the covering number for the set of
G
two-qubit channels is
(cid:18)6(cid:19)512 (cid:18)6G(cid:19)512
N(CPTP ,ε′,∥·∥ ) ≤ = . (3.3)
2 ⋄ ε′ ε
If we consider the set of all possible channels that act on two out of n qubits, which we denote by
CPTP(n), then the covering number of this set is given by
2
n!(cid:18)6G(cid:19)512
N(CPTP(n) ,ε′,∥·∥ ) ≤ , (3.4)
2 ⋄ 2 ε
with the binomial factor (cid:0)n(cid:1) coming from the fact that we allow the two-qubit channels to act on
2
any pair of qubits.
6While we focus on exact gate complexity here, an extension to approximate gate complexities, defined in terms
of the number of two-qubit channel gates sufficient to achieve a desired degree of approximation in diamond norm
distance, is straightforward based on the triangle inequality.
7The results naturally extend to circuits with k-local gates, compare Ref. [68, Supplementary Note 3, Remark 1].
30Let us now consider an arbitrary N ∈ CPTP . By definition, every such channel has the
n,G
form N = N ◦N ◦···◦N , where N ∈ CPTP(n) for all i ∈ {1,2,...,G}. By definition of
G G−1 1 i 2
N(CPTP( 2n) ,ε′,∥·∥ ⋄), for every channel N i, we can find a corresponding Nfi in an ε′-covering net
for CPTP( 2n) such that ∥N i−Nfi∥
⋄
≤ ε′. Then, the channel Nf:= NfG◦NfG−1◦···◦Nf1 ∈ CPTP
n,G
satisfies
G
∥N −Nf∥
⋄
≤ X ∥N i−Nfi∥
⋄
≤ Gε′ = ε, (3.5)
i=1
where we made use of the subadditivity-under-composition property of the diamond norm; see, e.g.,
Ref. [101, Proposition 3.48]. Therefore, if we let Neε′ ⊆ CPTP( 2n) be an ε′-covering net for CPTP( 2n),
then the set
n o
N
ε
:= N G◦N G−1◦···◦N
1
: N
i
∈ Neε′ (3.6)
is an ε-covering net for CPTP n,G. Noting that |N ε| = |Neε′|G, we obtain N(CPTP n,G,ε,∥·∥ ⋄) ≤
|N ε| ≤ |Neε′|G, for every ε′-covering net for CPTP 2(n). As the covering number N(CPTP 2(n) ,ε′,∥·∥ ⋄)
is, by definition, the size of the smallest ε′-covering net for CPTP(n), we can conclude that
2
n!G(cid:18)6G(cid:19)512G
N(CPTP ,ε,∥·∥ ) ≤ N(CPTP(n) ,ε′,∥·∥ )G ≤ , (3.7)
n,G ⋄ 2 ⋄ 2 ε
as required. ■
We now observe that Lemma 18 immediately implies similar sequential covering number bounds.
In fact, this can be seen by a reasoning analogous to how Ref. [68] went from covering w.r.t. a norm
on the level of the channel to empirical covering.
Corollary 19 (Sequential covering number bounds from gate complexity). Let T ∈ N and let
≥1
ε ∈ (0,1), p ≥ 1. Then,
n!G(cid:18)6G(cid:19)512G
N (CPTP ,ε,p) ≤ . (3.8)
T n,G 2 ε
Proof. Because of Lemma 18 and the monotonicity of sequential covering numbers w.r.t. p, it suffices
to show that N (CPTP ,ε,∞) ≤ N(CPTP ,ε,∥·∥ ) holds for any complete rooted binary tree
z n,G n,G ⋄
z of depth T. This follows immediately from the fact that, if N and Nf are two quantum channels,
then
(cid:12) (cid:12)
(cid:12) (cid:12)Tr[M R,BN(ρ R,A)]−Tr[M R,BNf(ρ R,A)](cid:12)
(cid:12)
≤ ∥M R,B∥ ∞∥(N −Nf)(ρ R,A)∥
1
(3.9)
≤ ∥M R,B∥ ∞∥N −Nf∥ ⋄∥ρ R,A∥
1
≤ ∥N −Nf∥
⋄
holds for any bipartite effect operator M and for any bipartite state ρ . ■
R,B R,A
We can now plug this sequential covering number bound into Theorem 11. This leads to the
following regret bound for online learning channels of bounded gate complexity:
31Theorem 20 (Regret bound for online learning channels of bounded complexity). Let ℓ : [0,1] → R
beconvexandL-Lipschitz. Thereexistsanonlinelearningstrategythat,whenpresentedsequentially
with channel test operators E(t) , t ∈ {1,2,...,T}, and associated loss functions ℓ (·) = ℓ((·)−b ),
A,B t t
outputs a sequence of hypothesis Choi matrices N(t) ∈ CPTP′ whose regret is bounded as
A,B n,G
XT
ℓ (Tr[E(t) N(t) ])− min
XT
ℓ (Tr[E(t) CN ]) ≤
O(cid:18) Lq TGlog(Gn)(cid:19)
. (3.10)
t A,B A,B t A,B A,B
t=1
N∈CPTPn,Gt=1
Proof. Combining Theorem 11 and Corollary 19, we obtain the regret bounds from gate complexity
as
T T
X ℓ (Tr[E(t) N(t) )− min X ℓ (Tr[E(t) CN ]) (3.11)
t A,B A,B t A,B A,B
t=1
N∈CPTPn,Gt=1
v
≤
24L√ 512TGZ 1u
u
tlog(cid:18)6G(cid:19)
+log
n!
dβ
β 2
0
√ Z 1s (cid:18)1(cid:19) q !
≤ 24L 512TG log(6G)+log dβ+ 2log(n)
β
0
√ q Z 1s (cid:18)1(cid:19) q !
≤ 24L 512TG log(6G)+ log dβ + 2log(n)
β
0
√ q √ π q !
≤ 24L 512TG log(6G)+ + 2log(n)
2
(cid:18) q (cid:19)
≤ O L TGlog(Gn) ,
√ √ √
where we have used the inequalities a+b ≤ a+ b ≤ p2(a+b) for a,b ≥ 0 and the integral
√
identity R plog(1/x) dx = xplog(1/x)−( π/2)·erf(plog(1/x)), with the error function given as
erf(x) = √2 Rxexp(−t2) dt. ■
π 0
Finally, to conclude our discussion of online learning channels with gate complexity G, we can
combine Theorem 20 with Lemma 12 to obtain the following mistake bound.
Corollary 21 (Mistake bound for online learning channels of bounded complexity). Let ε ∈ (0,1).
There exists an online learning strategy that, in a realizable setting for CPTP , when presented
n,G
sequentially with channel test operators E(t) , t ∈ {1,2,...,T}, and associated loss functions
A,B
ℓ (·) = ℓ((·)−b ), for some L-Lipschitz ℓ, outputs a sequence N(t) ∈ CPTP′ , of hypothesis Choi
t t A,B n,G
matrices that makes at most
O(cid:16) L2Glog(Gn)(cid:17)
many ε-mistakes.
ε2
Proof. Thanks to Theorem 20, we can apply Lemma 12 with h (ε,T) = CLp TGlog(Gn) for a
1
suitable constant C > 0 and with h (ε) = 0. With these choices,
2
3CLp Glog(Gn)!2 L2Glog(Gn)!
T∗ = T∗(h ,h ,ε) = ≤ O . (3.12)
1 2 2ε ε2
32So, the mistake bound obtained from Lemma 12 in this case is exactly as claimed in the statement
of the corollary. ■
Together, Theorem 20 and Corollary 21 establish Theorem 1. In particular, this implies: For
the physically relevant class of channels implementable with polynomial-size circuits, we can solve
the online learning task with only polynomially many mistakes.
3.2 Regret bound for mixtures of known channels
In the previous section, it was shown that online learning quantum channels of bounded gate
complexity is possible with good regret and number of mistakes. Here we show that even if the
channel has unbounded (exponentially many in the number of qubits) gates that act on the input
state, regret- and mistake-bounded online learning is still possible if we know the gates but not
the probability with which they act. Even more generally, we show that any channel composed of
mixture of known channels is efficiently online learnable, even if the mixture is over exponentially
many known channels, which could be arbitrary quantum channels. A notable example of such
channels are mixed unitary channels (with known unitaries), for example Pauli channels. Since the
Pauli channel framework is better understood and well-known, we first prove regret upper bounds in
this setting for clearer exposition. Later we generalize this to mixtures of general known channels.
Theorem 22 (Regret bound for online learning Pauli channels). Let ℓ : [0,1] → R be convex and
L-Lipschitz. There exists an online learning strategy that, when presented sequentially with channel
test operators E(t) , t ∈ {1,2,...,T}, and associated losses ℓ (·) = ℓ((·)−b ), outputs Pauli channel
A,B t t
Choi matrix hypotheses N(t) ∈ PAULI′ whose regret is bounded as
A,B n
T T √
X ℓ (Tr[E(t) N(t) ])−X ℓ (Tr[E(t) CP ]) = O(L nT), (3.13)
t A,B A,B t A,B A,B
t=1 t=1
for every Pauli channel P ∈ PAULI .
A→B n
Proof. The result follows by applying Lemma 9 and applying the multiplicative weights update
(MWU) algorithm (Algorithm 1) with a particular choice of the loss vectors m(t). Specifically, we
let
m(t) := (m(t) ) , (3.14)
z,x z,x∈{0,1}n
1
m(t) := ℓ′(Tr[E(t) N(t) ])Tr[E(t) Γz,x ], ∀ z,x ∈ {0,1}n, (3.15)
z,x L t A,B A,B A,B A,B
where
N(t) := X p(t) Γz,x , (3.16)
A,B z,x A,B
z,x∈{0,1}n
with the probability vectors p(t) := (p(t) ) defined according to the MWU algorithm. Let
z,x z,x∈{0,1}n
us verify that m(t) ∈ [−1,1] for all z,x ∈ {0,1}n, as required by the MWU algorithm. Indeed, we
z,x
33readily have that 1ℓ′(Tr[E(t) N(t) ]) ∈ [−1,1] because ℓ is assumed to be L-Lipschitz. In addition,
L t A,B A,B
we have that
0 ≤ Tr[E(t) Γz,x ] ≤ Tr[(σ ⊗1 )Γz,x ] = Tr [σ Tr [Γz,x ]] = Tr[σ ] = 1, (3.17)
A,B A,B A B A,B A A B A,B A
where we have used the fact that, because E(t) is a channel test operator, there exists a density
A,B
operator σ such that E(t) ≤ σ ⊗1 . Therefore, m(t) ∈ [−1,1] for all z,x ∈ {0,1}n.
A A,B A B z,x
Now, for every Pauli channel P with associated error-rate vector q = (q ) , we
A→B z,x z,x∈{0,1}n
can use Equation (2.12) to see that
1 1
ℓ′(Tr[E(t) N(t) ])Tr[E(t) CP ] = X q ℓ′(Tr[E N(t) ])Tr[E(t) Γz,x ] (3.18)
L t A,B A,B A,B A,B z,x L t A,B A,B A,B A,B
z,x∈{0,1}n
= X m(t) q
z,x z,x
z,x∈{0,1}n
= m(t)·q,
and similarly, we find that
1
ℓ′(Tr[E(t) N(t) ])Tr[E(t) N(t) ] = m(t)·p(t). (3.19)
L t A,B A,B A,B A,B
Therefore, it follows from the known regret bound in Theorem 13 on the MWU algorithm that
T 1 T 1
X ℓ′(Tr[E(t) N(t) ])Tr[E(t) N(t) ]−X ℓ′(Tr[E(t) N(t) ])Tr[E(t) CP ]
L t A,B A,B A,B A,B L t A,B A,B A,B A,B
t=1 t=1
T T
= X m(t)·p(t)−X m(t)·q (3.20)
t=1 t=1
nlog4
≤ ηT + . (3.21)
η
Finally, combining this inequality with the result of Lemma 9, we obtain
T
X(cid:16)
ℓ (Tr[E(t) N(t) ])−ℓ (Tr[E(t) CP
])(cid:17)
t A,B A,B t A,B A,B
t=1
T
≤
X(cid:16)
ℓ′(Tr[E(t) N(t) ])(Tr[E(t) N(t) ]−Tr[E(t) CP
])(cid:17)
(3.22)
t A,B A,B A,B A,B A,B A,B
t=1
(cid:18) nlog4(cid:19)
≤ L ηT + , (3.23)
η
for every Pauli channel P ∈ PAULI . The claimed bound then follows by setting η = p n/T. ■
A→B n
While Theorem 22 focused solely on Pauli channels, as we show below, it readily translates to
any convex combination of known channels—even exponentially many known channels that may
have arbitrarily large gate complexity. This generalization captures a wide class of channels of
interest, such as mixed unitary channels, in which each known channel is a unitary. Pauli channels
are themselves a special case of such channels, because they are convex combinations of the 4n
unitary channels defined by the Pauli strings.
34Corollary 23 (Regret bound for convex combinations of known channels). Let K ∈ Z , and let
>0
{N }K be a set of K known n-qubit channels N ∈ CPTP . Let ℓ : [0,1] → R be convex and
j j=1 j n
L-Lipschitz. There exists an online learning strategy that, when presented sequentially with channel
test operators E(t) , t ∈ {1,2,...,T}, and associated losses ℓ (·) = ℓ((·)−b ), outputs Choi matrix
A,B t t
hypotheses N(t) of the form
A,B
K
N(t) = X p(t) C(N ), (3.24)
A,B j j
j=1
with p(t) := (p(t) ,p(t) ,...,p(t)) ∈ ∆ , whose regret is bounded as
1 2 K K
T T
X ℓ (Tr[E(t) N(t) ])−X ℓ (Tr[E(t) CN ]) = O(cid:16) Lp T logK(cid:17) , (3.25)
t A,B A,B t A,B A,B
t=1 t=1
for every N ∈ conv({N }K ).
j j=1
Proof. The proof is analogous to that of Theorem 22. In particular, we combine Lemma 9 with the
MWU algorithm (Algorithm 1) applied to a particular choice of loss vectors m(t). We let
m(t) := (m(t)) , (3.26)
j j∈{1,2,...,K}
1
m(t) := ℓ′(Tr[E(t) N(t) ])Tr[E(t) CNj ] ∀ j ∈ {1,2,...,K}, (3.27)
j L t A,B A,B A,B A,B
where
K
N(t) := X p(t) CNj , (3.28)
A,B j A,B
j=1
with the probability vectors p(t) := (p(t)) defined according to the MWU algorithm. As in
j j∈{1,2,...,K}
the proof of Theorem 22, it is straightforward to verify that m(t) ∈ [−1,1] for all j ∈ {1,2,...,K},
j
as required by the MWU algorithm.
Now, consider an arbitrary channel N in the convex hull of the channels N , specified as N =
j
Pk q N for some probability vector q = (q ,q ,...,q ). By linearity of the Choi representation,
j=1 j j 1 2 K
and using Theorem 13, we obtain
T 1 T 1
X ℓ′(Tr[E(t) N(t) ])Tr[E(t) N(t) ]−X ℓ′(Tr[E(t) N(t) ])Tr[E(t) CN ] (3.29)
L t A,B A,B A,B A,B L t A,B A,B A,B A,B
t=1 t=1
T T
= X m(t)·p(t)−X m(t)·q
t=1 t=1
logK
≤ ηT + .
η
Therefore, by Lemma 9, we obtain
T
X(cid:16)
ℓ (Tr[E(t) N(t) ])−ℓ (Tr[E(t) CN
])(cid:17)
(3.30)
t A,B A,B t A,B A,B
t=1
35T
≤
X(cid:16)
ℓ′(Tr[E(t) N(t) ])(Tr[E(t) N(t) ]−Tr[E(t) CN
])(cid:17)
t A,B A,B A,B A,B A,B A,B
t=1
(cid:18) logK(cid:19)
≤ L ηT + .
η
Setting η = plogK/T, we obtain the desired regret bound. ■
Corollary 24 (Mistake bounds for Pauli channels and convex combination of known channels).
Let ε ∈ (0,1). Let K ∈ Z , and let {N }K be a set of K known n-qubit channels N ∈ CPTP .
>0 j j=1 j n
Let N ∈ conv({N }K ) be a fixed channel unknown to the learner. There exists an online
A→B j j=1
learning strategy that, in a realizable setting for conv({N }K ), when presented sequentially with
j j=1
two-outcome channel test operators E(t) , t ∈ {1,2,...,T}, and associated losses ℓ (·) = ℓ((·)−b ),
A,B t t
for some L-Lipschitz ℓ, outputs a sequence N(t) ∈ conv({CNj }K ) of hypothesis Choi matrices
A,B A,B j=1
that makes at most O(L2log(K)) many ε-mistakes.
ε2
Proof. MimickingtheproofofCorollary21byinvokingLemma12, butnowforthechoiceh (ε,T) =
1
CL√ T logK for a suitable C > 0 and h (ε) = 0, we get that T∗ = (cid:16) 3CL√ logK(cid:17)2 ≤ O(L2log(K)). ■
2 2ε ε2
3.3 Regret bounds for multi-time processes
In this section, we generalize the developments of Sections 3.1 and 3.2 to multi-time processes. We
start by presenting the problem of online learning classes of multi-time processes, by casting it in
terms of the general framework of online learning laid out in Section 2.2. With that, we formally
state the problem in Problem 2 below.
Let r ∈ N. We fix finite-dimensional Hilbert spaces H ,H ,...,H ,H , and we let H(r) ≡
A1 B1 Ar Br A,B
H ⊗H ⊗H ⊗H ⊗···⊗H ⊗H . Then, the input set/domain X comprises multi-time
A1 B1 A2 B2 Ar Br
test operators corresponding to two-outcome multi-time tests
n o
X := E ∈ L(H(r) ) : E ≥ 0, ∥E∥∗ ≤ 1 . (3.31)
A,B ⋄r
The output set is Y = [0,1], and F is defined via a subclass C ⊆ COMB of interest, such that for
r
every N ∈ C we define the function f : X → Y as f (E) = Tr[EN] for all E ∈ X. In other words,
N N
n o
F = f : X → [0,1] : N ∈ C, f (E) = Tr[EN] ∀E ∈ X . (3.32)
N N
As in the case of channels, online learning proceeds is an interactive procedure with an adversary,
who provides test operators E(t) ∈ L(H(r) ) for two-output multi-time tests to the learner, and the
A,B
learner outputs hypotheses N(t) ∈ C. The goal of the learner is to achieve a small regret,
T T
R = X ℓ (Tr[E(t)N(t)])− min X ℓ (Tr[E(t)N∗]), (3.33)
T t t
N∗∈C
t=1 t=1
36(a)
(b) (c)
Figure 3: Multi-time processes with bounded complexity. (a) The basic unit of our
multi-time processes with bounded complexity is a process consisting of two two-qubit channels
connected by an inaccessible memory system. (b) By collapsing the causal structure of the
inputs and outputs of the process in (a), we obtain a three-qubit channel belonging to the set
CPTP . (c) An example of a multi-time process obtained by composing (ten of) the basic
3,2
elements in (a) in a circuit.
wherethelossesℓ arerevealedbytheadversary. WeaimforregretboundsscalingasO(p T ·poly(n)).
t
On the other hand, in the realizable scenario, where there exists a (to the learner unknown) comb
operator N∗ ∈ C such that all losses take the form ℓ (·) = ℓ((·) − b ), where ℓ is some fixed
t t
function and each b satisfies |b −Tr[E(t)N∗]| ≤ ε/3, the learner aims to achieve a small number of
t t
ε-mistakes. Here, our goal is to guarantee mistake bounds scaling as O(poly(n,ε−1)). We summarize
the formulation of our multi-time process online learning problem as follows.
Problem 2 (Online learning of multi-time quantum processes). Consider a subset C ⊆ COMB ,
r
for r ∈ N, and let N∗ ∈ C be unknown. Given a sequence of T ∈ N interactive rounds, in which
test operators E(1),E(2),...,E(T) ∈ X are presented sequentially by an adversary, the problem is to
output a sequence N(1),N(2),...,N(T) ∈ C of comb operators such that for losses ℓ of the form
t
ℓ (·) = ℓ((·)−b ), where ℓ is some fixed function and each b satisfies |b −Tr[E(t)N∗]| ≤ ε/3, the
t t t t
regret in (3.33) scales as O(p T ·poly(n)) and the number of ε-mistakes scales as O(poly(n,ε−1)).
We note that for r = 1, Problem 2 is equivalent to Problem 1. We also note that the projected
MMW algorithm for Choi states of quantum channels (Algorithm 3) generalizes straightforwardly
to Choi states of multi-time processes; see Algorithm 4.
Algorithm 4 Projected MMW algorithm for Choi states of r-step multi-time processes
Require: η ∈ (0,1); Initialize W(1) = Nr 1 and P(1) = 1W(1), d ≡ Qr d d
k=1 A k,B k d k=1 A k B k
1: for t = 1,2,...,T do
2:
Output the decision/estimate N(t)
3: Receive the cost matrix L(t), ∥L∥∗ ≤ 1.
⋄r
4:
Update the weight matrix: W(t+1) = exp[log(W(t))−ηL(t)], ω(t+1) = W(t+1)/Tr[W(t+1)].
n o
5: Project: P(t+1) := d1
A
argmin P D( d1 AP∥ω(t+1)) : P ∈ COMB r , d A = Qr k=1d A k.
6: end for
We provide an analysis of Algorithm 4 in Appendix D.2; see Remark 64 therein.
37Multi-time processes with bounded gate complexity. Wecanextendtheresultsabovetothe
case of multi-time processes with bounded complexity. The generalized form of multi-time processes
allows for many possibilities for how to define multi-time processes with bounded complexity.
Just as we defined n-qubit quantum channels with gate complexity G as being composed of at
most G two-qubit quantum channels, here we consider multi-time processes composed of the basic
“unit” shown in Figure 3(a). Specifically, we define COMB to be the set of all comb operators
n,G
corresponding to multi-time processes on n qubits that can be implemented by the composition of
at most G of the basic units in Figure 3(a), in the manner of a circuit as shown in Figure 3(c). The
number of time steps, r, in the multi-time process depends on G.
First, we prove an analogue of Lemma 18 for multi-time processes with gate complexity G.
While the diamond norm was the natural distance measure in the case of channels, here we use
strategy norms instead (see Appendix B for a definition and a discussion of their properties).
Lemma 25 (Covering number bounds from gate complexity for multi-time processes). Let ε ∈ (0,1).
The (interior) ε-covering number of COMB with respect to ∥·∥ is bounded as
n,G ⋄r
n!G(cid:18)6G(cid:19)1024G
N(COMB ,ε,∥·∥ ) ≤ . (3.34)
n,G ⋄r 2 ε
Proof. The proof again follows similar ideas as employed in the covering number bounds of [32, 68].
First, we recall (compare, e.g., Ref. [118]) a well-known fact about covering numbers of norm balls
in RK: If R > 0, ε ∈ (0,R], and if B∥·∥(x) denotes the ∥·∥-ball of radius R around x ∈ RK for some
R
norm ∥·∥, then
(cid:18) 2R(cid:19)K (cid:18)3R(cid:19)K
N(B∥·∥(x),ε,∥·∥) ≤ 1+ ≤ . (3.35)
R ε ε
To apply this in our scenario, notice that any basic unit as in Figure 3(a) lives in the ∥·∥ -unit-
⋄2
ball in a ((2·(24×24)) = 512)-dimensional complex space, where the ambient dimension is that
of two 2-qubit channels. Consequently, via the approximate monotonicity of covering numbers
w.r.t. inclusion of sets, the above standard bound implies for our case that COMB , the class of
2
basic units, admits
(cid:18) ε (cid:19) (cid:18)6(cid:19)1024
N(COMB ,ε,∥·∥ ) ≤ N B∥·∥⋄2(0), ,∥·∥ ≤ (3.36)
2 ⋄2 1 2 ⋄2 ε
as a covering number bound. If we let COMB(n) be the set of all basic units in Figure 3(a) that act
2
on two out of n qubits, then the covering number of this set is bounded from above as follows:
n!(cid:18)6(cid:19)1024
N(COMB(n) ,ε,∥·∥ ) ≤ , (3.37)
2 ⋄2 2 ε
with the binomial factor (cid:0)n(cid:1) coming from the fact that we allow the basic units to act on any pair
2
of qubits.
Now, consider an arbitrary N ∈ COMB . By definition, every such comb operator has the form
n,G
N = N ⋆N ⋆···⋆N , where N ∈ COMB(n). Let ε′ = ε. By definition of the covering number
1 2 G i 2 G
38N(COMB( 2n) ,ε′,∥·∥ ⋄2), for every N
i
∈ COMB( 2n), we can find a corresponding Nei in an ε′-covering
net for COMB( 2n) such that ∥N i−Nei∥
⋄2
≤ ε′. Then, if we let Ne := Ne1⋆Ne2⋆···⋆NeG, and by making
use of the subadditivity-under-composition property of the strategy norm, as shown in Corollary 57,
we obtain
G
∥N −Ne∥
⋄r
≤ X ∥N i−Nei∥
⋄2
≤ Gε′ = ε. (3.38)
i=1
Therefore, if we let Neε′ ⊆ COMB( 2n) be an ε′-covering net for COMB 2(n), then the set
n o
N
ε
:= Ne1⋆Ne2⋆···⋆NeG : N
i
∈ Neε′ (3.39)
is an ε-covering net for COMB n,G. Noting that |N ε| = |Neε′|G, we obtain N(COMB n,G,ε,∥·∥ ⋄r) ≤
|N ε| ≤ |Neε′|G for every ε′-covering net for COMB( 2n). As the covering number N(COMB( 2n) ,ε′,∥·∥ ⋄2)
is, by definition, the size of the smallest ε′-covering net for COMB(n), we can conclude that
2
n!G(cid:18)6G(cid:19)1024G
N(COMB ,ε,∥·∥ ) ≤ N(COMB(n) ,ε′,∥·∥ )G ≤ , (3.40)
n,G ⋄r 2 ⋄2 2 ε
as required. ■
Theorem 26 (Regret bound for online learning multi-time processes of bounded complexity). Let
ℓ : [0,1] → R be convex and L-Lipschitz. There exists an online learning strategy that, when
presented sequentially with multi-time test operators E(t) for r time steps, t ∈ {1,2,...,T}, and
associated loss functions ℓ (·) = ℓ((·) − b ), outputs a sequence of hypothesis comb operators
t t
N(t) ∈ COMB′ , corresponding to r-step multi-time quantum processes, whose regret is bounded
A,B n,G
as
XT
ℓ (Tr[E(t)N(t)])− min
XT
ℓ (Tr[E(t)N]) ≤
O(cid:18) Lq TGlog(Gn)(cid:19)
. (3.41)
t t
t=1
N∈COMBn,Gt=1
Proof. The proof is analogous to the proof of Theorem 20. First, it holds that
n!G(cid:18)6G(cid:19)1024G
N (COMB ,ε,p) ≤ , (3.42)
T n,G 2 ε
for T ∈ N , ε ∈ (0,1), and p ≥ 1. This holds due to the fact that N (COMB ,ε,p) ≤
≥1 z n,G
N (COMB ,ε,∞) ≤ N(COMB ,ε,∥·∥ ), where z is an arbitrary complete rooted binary tree
z n,G n,G ⋄r
of depth T. The first of these inequalities is due to monotonicity of the sequential covering numbers
with respect to p, and the second follows from the fact that
(cid:12) (cid:12)
(cid:12) (cid:12)Tr[EN]−Tr[ENe](cid:12)
(cid:12)
≤ ∥E∥∗ ⋄r∥N −Ne∥
⋄r
≤ ∥N −Ne∥ ⋄r, (3.43)
for arbitrary multi-time test operators E and arbitrary comb operators N and Ne, which holds
because of the Hölder inequality for strategy norms in (2.32) and the fact that ∥E∥∗ ≤ 1, by
⋄r
definition of a multi-time test operator. We have thus established (3.42). From here, an application
of Theorem 11, along with the reasoning in the proof of Theorem 20, gives us the desired result. ■
39Corollary 27 (Mistake bound for online learning multi-time processes of bounded complexity).
Let ε ∈ (0,1). There exists an online learning strategy that, in a realizable setting for COMB ,
n,G
when presented sequentially with multi-time test operator E(t), t ∈ {1,2,...,T}, and associated
loss functions ℓ (·) = ℓ((·)−b ), for some L-Lipschitz ℓ, outputs a sequence N(t) ∈ COMB of
t t n,G
hypothesis comb operators that makes at most
O(cid:16) L2Glog(Gn)(cid:17)
many ε-mistakes.
ε2
Proof. The proof follows the analogous arguments as in the proof of Corollary 21, in which we make
use of the regret bound from Theorem 26. ■
Convex mixtures of known multi-time processes. We now show that Theorem 22 and
Corollary23generalizestraightforwardlytoconvexmixturesofarbitrary,knownmulti-timeprocesses.
Theorem 28 (Regret bound for online learning convex mixtures of multi-time processes). Let
K ∈ Z and r ∈ N. Consider a convex combination of K known r-step multi-time processes,
>0
with Choi representations N ∈ COMB , j ∈ {1,2,...,K}, such that N∗ = PK q N , where the
j r j=1 j j
unknown probability distribution is given by q = (q ,q ,...,q ). Let ℓ : [0,1] → R be convex
1 2 K
and L-Lipschitz. There exists an online learning strategy that, when presented sequentially with
multi-time test operators E(t), t ∈ {1,2,...,T}, and associated losses ℓ (·) = ℓ((·)−b ), outputs
t t
hypotheses N(t) ∈ COMB of the form
r
K
N(t) = X p(t) N , (3.44)
j j
j=1
with p(t) := (p(t) ,p(t) ,...,p(t)) ∈ ∆ , whose regret is bounded as
1 2 K K
T T
X ℓ (Tr[E(t)N(t)])−X ℓ (Tr[E(t)N∗]) = O(cid:16) Lp T logK(cid:17) . (3.45)
t t
t=1 t=1
Proof. We combine Lemma 9 with the MWU algorithm (Algorithm 1) applied to a particular choice
of loss vectors m(t). We let
m(t) := (m(t)) , (3.46)
j j∈{1,2,...,K}
1
m(t) := ℓ′(Tr[E(t)N(t)])Tr[E(t)N ] ∀ j ∈ {1,2,...,K}, (3.47)
j L t j
where
K
N(t) := X p(t) N , (3.48)
j j
j=1
with the probability vectors p(t) := (p(t)) defined according to the MWU algorithm.
j j∈{1,2,...,K}
Let us verify that m(t) ∈ [−1,1] for all j ∈ {1,2,...,K}, as required by the MWU algorithm.
j
First, we readily have that 1ℓ′(Tr[E(t)N(t)]) ∈ [−1,1], because ℓ is assumed to be L-Lipschitz. In
L t
addition, we have that
Tr[E(t)N ] ≤ Tr[(S ⊗1 )N ] (3.49)
j Br j
40= Tr[STr [N ]]
Br j
= Tr[S(N(r−1) ⊗1 )]
j Ar
= Tr[Tr [S]N(r−1)]
Aj j
= Tr[(S(r−1)⊗1 )N(r−1)]
Br−1 j
.
.
.
= Tr[S(1)Tr [N(1)]]
B1 j
= Tr[S(1)]
= 1,
where the inequality is due to the fact that ∥E(t)∥∗ ≤ 1, which means by (2.31) that there
⋄r
exists S ∈ COMB∗ such that E(t) ≤ S ⊗ 1 ; the chain of equalities holds because of the fact
r Br
that N ∈ COMB and S ∈ COMB∗, such that there exists N(1) ,N(2) ,...,N(r−1) satisfying the
j r r j j j
constraints in (2.28) and there exists S(1),...,S(r−1) satisfying the constraints in (2.29).
Now, let N∗ = Pk q N for some probability vector q = (q ,q ,...,q ). Using Theorem 13,
j=1 j j 1 2 K
we obtain
T 1 T 1
X ℓ′(Tr[E(t)N(t)])Tr[E(t)N(t)]−X ℓ′(Tr[E(t)N(t)])Tr[E(t)N∗] (3.50)
L t L t
t=1 t=1
T T
= X m(t)·p(t)−X m(t)·q
t=1 t=1
logK
≤ ηT + .
η
Therefore, by Lemma 9, we obtain
T
X(cid:16)
ℓ (Tr[E(t)N(t)])−ℓ
(Tr[E(t)N∗])(cid:17)
(3.51)
t t
t=1
T
≤
X(cid:16) ℓ′(Tr[E(t)N(t)])(Tr[E(t)N(t)]−Tr[E(t)N∗])(cid:17)
t
t=1
(cid:18) logK(cid:19)
≤ L ηT + .
η
Setting η = plogK/T, we obtain the desired regret bound. ■
Corollary 29 (Mistake bound for convex mixtures of multi-time processes). Let ε ∈ (0,1). Let
K ∈ Z and r ∈ N. Consider a convex combination of K known r-step multi-time processes,
>0
with Choi representations N ∈ COMB , j ∈ {1,2,...,K}, such that N∗ = PK q N , where the
j r j=1 j j
unknown probability distribution is given by q = (q ,q ,...,q ). There exists an online learning
1 2 K
strategy that, in a realizable setting for conv({N }K ), when presented sequentially with multi-time
j j=1
test operator E(t), t ∈ {1,2,...,T}, and associated loss functions ℓ (·) = ℓ((·) − b ), for some
t t
41L-Lipschitz ℓ, outputs a sequence N(t) ∈ COMB of hypothesis comb operators of the form
n,G
K
N(t) = X p(t) N , (3.52)
j j
j=1
with p(t) := (p(t) ,p(t) ,...,p(t)) ∈ ∆ , that makes at most O(L2log(K)) many ε-mistakes.
1 2 K K ε2
Proof. Using Lemma 12, we can derive this mistake bound from the regret bound of Theorem 28,
analogously to how Corollary 24 followed from Corollary 23. ■
3.4 Learning-theoretic implications
To conclude our discussion of regret and mistake upper bounds for online learning certain classes of
quantum channels, we highlight some learning-theoretic implications of our bounds. On the one
hand, we note that our regret bounds immediately give rise to bounds on a complexity measure
called sequential fat-shattering dimension [82] of the respective channel classes. On the other hand,
our mistake-bounded online learner can be used to construct sample compression schemes. For
simplicity of presentation, we focus on Pauli channels in this discussion. However, these implications
immediately extend to all the classes of channels and the multi-time quantum processes that we
established regret and mistake bounds for. That is, also for these classes we obtain complexity
bounds and (approximate) compression schemes.
For the first implication, we rely on known results ([82, Proposition 9] and [83, Lemma 2]) to
derive a sequential fat-shattering dimension bound from the regret bound established in Theorem 22:
Corollary 30 (Sequential fat-shattering dimension bound). Let PAULI be the class of all n-qubit
n
(cid:16) (cid:17)
Pauli channels, and let ε ∈ (0,1). Then, sfat (PAULI ) ≤ O n .
ε n ε2
Proof. We start from Theorem 22 for the special case of ℓ(·) = |·|. This gives us a regret bound of
√
O(L nT). Combining this with the first inequality in Ref. [82, Proposition 9] or with [83, Lemma
2], we get
 s 
√1 sup ε min{sfat ε(F),T} ≤ 2p Tnlog4. (3.53)
4 2 ε  T 
We can now rearrange and, after plugging in T = 1 and using that clearly sfat (PAULI ) ≥ 1, we
ε n
(cid:16) (cid:17)
get the claimed bound of sfat (PAULI ) ≤ O n . ■
ε n ε2
Via Ref. [83, Corollary 1], this sequential fat-shattering dimension bounds also implies sequential
covering number bounds. While obtaining these complexity bounds from our regret bounds
(Theorem 22) is standard given prior work, we highlight that the obtained bounds are exponentially
better than what would arise from naive parameter counting. Namely, while a Pauli channel is
specified by a 4n-dimensional probability vector, these complexity measure bounds show that the
“effective” dimension relevant for online learning is only linear in n. Finally, we note that the
sequential fat-shattering dimension and covering numbers are upper bounds on their non-sequential
42counterparts. Thus, the above upper bounds immediately carry over to the complexity measures
relevant for (agnostic) probably approximately correct (PAC) learning and lead to corresponding
generalizationboundsforPAClearningPaulichannels. Inparticular, thisimpliesthatPaulichannels
are a restricted class of operations that allow for “pretty good process tomography”, as asked for
in Ref. [15, Section 4]. We note that Refs. [15, 20] obtained (sequential) fat-shattering bounds for
quantum states from bounds on quantum random access coding. It would be interesting to see
whether this implication can be reversed in our setting: Do our (sequential) fat-shattering bounds
imply limitations for encoding classical information into Pauli channels in a random access coding
fashion?
Next, we turn our attention to implications for compression. For the case of {0,1}-valued
functions, the connection between mistake-bounded online learning and sample compression via
the so-called one-pass compression scheme has already been observed in Ref. [119, Section 4]. We
notice that, with minor adaptations, this reasoning also applies to [0,1]-valued function classes when
considering ε-mistakes and uniformly ε-approximate compression schemes (defined in Ref. [120]):
Lemma 31 (Compression from mistake-driven online learning). Let F ⊆ [0,1]X. Let ε ∈ (0,1).
Suppose X admits some total order and suppose F admits a mistake-driven online learner A that
makes at most M = M (ε) many ε-mistakes when sequentially presented with challenges x ,...,x
F 1 m
and the corresponding values f (x ),...,f (x ) for some unknown f ∈ F. Then, F admits a
∗ 1 ∗ m ∗
uniformly ε-approximate sample compression scheme.
The assumption that X admits a total order is trivially satisfied whenever X is finite, which is
typically the case in computational learning theory. If we assume the ordering principle (i.e., that
every set can be totally ordered), then we can apply Lemma 31 for a general instance space X. We
note that the ordering principle is strictly weaker than the well-ordering theorem [121–123] (see
also [124, Section 4.4]), which in turn is well known to be equivalent to the axiom of choice.
Proof of Lemma 31. We first describe the compression and reconstruction maps, then we prove that
they have the desired compression scheme property. The compression map κ : S (X×[0,1])m →
m≥1
S (X×[0,1])m is defined as follows: Given a dataset S ⊆ X×[0,1], reorder S according to
1≤m≤M
the total order on X, run the online learner A with an adversary that sequentially presents the
learner with the reordered elements of S, and let κ(S) be the set of (labeled) examples on which A
made an ε-mistake. Next, we define the reconstruction map ρ : S (X×[0,1])m → [0,1]X. Let
1≤m≤M
S ⊂ X×[0,1] and x ∈ X. If ∃y ∈ [0,1] such that (x,y) ∈ S, then we set ρ(S)(x) = y. Otherwise,
we reorder S according to the total order on X, run the online learner A with an adversary that
sequentially presents the learner with the reordered elements of S that precede x in the total order
on X, and let ρ(S)(x) be the value predicted by A for x.
Now,weprovethatκandρasdefinedaboveindeedformaformauniformlyε-approximatesample
compression scheme for F. That is, we show that, for all f ∈ F and for all S = {(x ,f(x ))}m ⊂
i i i=1
X×[0,1], the function fˆ= ρ(κ(S)) satisfies max |fˆ(x )−f(x )| ≤ ε. So, let f ∈ F and let
1≤i≤m i i
S = {(x ,f(x ))}m ⊂ X×[0,1]. If 1 ≤ i ≤ m is such that ∃y ∈ [0,1] : (x ,y ) ∈ κ(S), then by
i i i=1 i i i
definitionofκandρwehavefˆ(x ) = y = f(x ). If1 ≤ i ≤ missuchthat∄y ∈ [0,1] : (x ,y ) ∈ κ(S),
i i i i i i
then by definition of κ, this means that the online learner A does not make an ε-mistake on x
i
when presented sequentially with the elements of S reordered according to the total order on X.
43As A is mistake-driven, this implies that A also does not make an ε-mistake on x when presented
i
sequentially only with the (reordered) elements of S that precede x in the total order on X and
i
on which A made an ε-mistake. This is exactly the sequence of examples that A is run on when
determining the value that fˆ= ρ(κ(S)) assigns to x , thus |fˆ(x )−f(x )| ≤ ε. ■
i i i
Remark 32. LetuscommentonanaturalvariantofLemma31: IftheonlinelearnerAforF makes
at most M = M (ε) many ε-mistakes even when presented only with (ε/3)-accurate approximations
F
to the true function values – as is for instance the case for our MWU-based Pauli channel online
learner –, this translates over to the resulting compression scheme. That is, even when sequentially
presented with a training data set S = {(x ,y )}m with |y − f(x )| ≤ ε/3 for all 1 ≤ i ≤ m
i i i=1 i i
(instead of a “perfect” data set with y = f(x ) for all 1 ≤ i ≤ m), the function fˆ= ρ(κ(S)) after
i i
compression still satisfies |fˆ(x )−f(x )| ≤ ε for all 1 ≤ i ≤ m. Thus, this sample compression
i i
scheme is successful also if applied to data that has been affected by (possibly adversarial) label
noise of strength ε/3. ◀
We can combine this with our mistake bound for Pauli channel learning to get a compression
scheme for Pauli channels:
Corollary 33 (Compression scheme for Pauli channels). The set PAULI of n-qubit Pauli channels
n
(cid:16) (cid:17)
admits a uniformly ε-approximate sample compression scheme of size O n . This sample compres-
ε2
sion scheme even succeeds on training data whose labels have been corrupted by adversarial label
noise of strength ε/3.
Proof. Given our mistake bound for online learning Pauli channels (Corollary 24) and Lemma 31
(together with Remark 32), we only have to show that our instance space, which is the space of
channel test operators, admits a total order. This can be seen as follows: Similar to Section 3.2, we
can associate to any channel test operator E the vector (e = Tr[E Γz,x ]) ∈ [0,1]4n.
A,B z,x A,B A,B z,x∈{0,1}n
The mapping E 7→ (e ) is injective, because the operators Γz,x form an orthogonal
A,B z,x z,x∈{0,1}n A,B
basis. Thus, any total order on [0,1]4n, for instance the lexicographic order, induces a total order
on the set of channel test operators. ■
Corollary 33 implies that, if we care about the statistics of quantum experiments, then Pauli
channels admit a significantly more parsimonious representation than via an exponentially long
vector of Pauli error rates. This can be illustrated as follows: Suppose A(lice) and B(ob) want to
understand how an unknown Pauli channel N in A’s lab acts on the channel test operators E(i) ,
A,B
1 ≤ i ≤ m. To do so, A performs experiments and collects data S = {(E(i) ,y )}m , where the y
A,B i i=1 i
are (ε/3)-approximations of the corresponding expectation values Tr[E(i) CN ]. She now wants
A,B A,B
to communicate her findings to B. Then, no matter how large m is, A can compress S to a set
(cid:16) (cid:17)
of size at most O n data points, send those to B, and B can ε-approximately reconstruct the
ε2
expectation values for all m test operators without doing any further experiments.
444 Mistake lower bounds
In the previous section, we provided regret and mistake upper bounds for online learning certain
subclasses of quantum channels and multi-time processes. In this section, we prove complementary
mistake lower bounds. While these, in principle, lead to regret lower bounds via (the contrapositive
of) Lemma 12, we only discuss mistake lower bounds here. Throughout this section, our focus is on
the dependence on ε-mistake lower bounds for a constant ε < 1/2. Thus, our lower bounds do not
scale with ε. We conjecture that the (1/ε2)-scaling achieved in Sections 3.1 and 3.2 is optimal, but
leave the proof to future work.
4.1 Mistake lower bounds for general unitaries and channels
We first recall the folkore result that the class of arbitrary Boolean functions on n bits cannot be
online learned with subexponentially many mistakes.
Lemma 34 (Arbitrary Boolean functions cannot be online learned with subexponentially many
mistakes). Let F = {0,1}{0,1}n be the class of all Boolean functions on n bits. Any online learner
for F makes at least 2n mistakes against a worst-case adversary. This remains true even if the
adversary is forced to decide on a labeling function before the interaction with the learner.
Proof. The class F of all {0,1}-valued functions on {0,1}n has VC-dimension [125] VCdim(F) = 2n
and thus Littlestone dimension [37] Ldim(F) ≥ VCdim(F) = 2n. Essentially by definition of the
Littlestone dimension, any online learner for F makes at least Ldim(F) ≥ 2n mistakes. This proves
the first part of the statement.
Now for the second part of the statement. Fix an arbitrary learning algorithm. Consider an
adversary that initially chooses a function uniformly at random from {0,1}{0,1}n and, in round
1 ≤ t ≤ 2n, asks for the label of x , where {x }2n is some (fixed) enumeration of {0,1}n. Let
t s s=1
F denote the function-valued random variable describing the function chosen by the learner, let
S = {(x ,F(x ))}t denote the instance-label pairs that the online learner has seen in the first t
t τ τ τ=1
rounds. Moreover, let Y be the label predicted by the online learner in round t+1. Note that the
t+1
random variable Y depends only on S (and on the internal randomness of the online learner).
t+1 t
Thus, as F(x ) is uniformly random and independent of S (as well as of the online learning
t+1 t
algorithm), also Y and F(x ) are independent. Therefore,
t+1 t+1
P[Y = F(x )] = E [P [Y = F(x )|Y ]] (4.1)
t+1 t+1 Yt+1 F t+1 t+1 t+1
= E [P [Y = F(x )]]
Yt+1 F t+1 t+1
(cid:20)1(cid:21) 1
= E = .
Yt+1 2 2
Hence, in each round, the online learner makes a mistake with probability 1/2. As mistakes occur
independently in each round, the probability that the online learner makes a mistake in every round
is strictly greater than zero. Thus, there exists a function f : {0,1}n → {0,1} that, when chosen
initially by the adversary, forces the online learner to make 2n mistakes. ■
45We can now embed the problem of online learning an arbitrary classical Boolean function into
that of learning an arbitrary quantum channel and therefore inherit similar mistake lower bounds.
In the following, we describe two different ways of achieving such lower bounds.
Corollary 35. Let U be the class of all unitary n-qubit channels, let ε < 1/2. Any online learner
n
for U makes Ω(2n) many ε-mistakes against a worst-case adversary. This remains true even if the
n
adversary is forced to decide on a unitary before the interaction with the learner.
Proof. OurproofisviareductiontoLemma34. Todoso,weassociatetoeveryf : {0,1}n−1 → {0,1}
the n-qubit unitary U defined via U |x,b⟩ = |x,b⊕f(x)⟩ for x ∈ {0,1}n−1 and b ∈ {0,1}. We
f f
denote the corresponding unitary channel by U 8. Now, if we consider a channel test operator
f
E (x) = ρ (x)T⊗M (x) with ρ (x) = |x,0⟩⟨x,0| and M (x) = |x,1⟩⟨x,1| for some x ∈ {0,1}n−1,
A,B A B A B
then
Tr[E (x)CU f ] = Tr[M (x)U (ρ (x))] = |⟨1|f(x)⟩|2 = f(x). (4.2)
A,B A,B B f A
Thus, if ε < 1/2, then any online learner for U that makes at most N ε-mistakes gives rise to an
n
online learner for {0,1}{0,1}n−1 that makes at most N mistakes, by rounding the produced estimates
to obtain a label in {0,1}. Hence, by Lemma 34, we conclude that N ≥ 2n−1 ≥ Ω(2n). ■
Corollary 36. Let CPTP be the class of all n-qubit quantum channels, let ε < 1/2. Any online
n
learner for CPTP makes Ω(2n) many ε-mistakes against a worst-case adversary. This remains true
n
even if the adversary is forced to decide on a channel before the interaction with the learner.
Proof. Our proof is via reduction to Lemma 34. To do so, we associate to every f : {0,1}n → {0,1}
the n-qubit channel N defined via
f
N (ρ) = X ⟨x|ρ|x⟩(|f(x)⟩⟨f(x)|⊗|0n−1⟩⟨0n−1|). (4.3)
f
x∈{0,1}n
Now, if we consider a channel test operator E (x) = ρ (x)T ⊗M (x) with ρ (x) = |x⟩⟨x| and
A,B A B A
M (x) = |1⟩⟨1|⊗|0n−1⟩⟨0n−1| for some x ∈ {0,1}n, then
B
Tr[E (x)CN f ] = Tr[M (x)N (ρ (x))] = |⟨1|f(x)⟩|2 = f(x). (4.4)
A,B A,B B f A
Thus, if ε < 1/2, then any online learner for CPTP n ⊃ {N f} f∈{0,1}{0,1}n that makes at most N
ε-mistakes gives rise to an online learner for {0,1}{0,1}n that makes at most N mistakes, by rounding
the produced estimates to obtain a label in {0,1}. Hence, by Lemma 34, we conclude N ≥ 2n. ■
These lower bounds demonstrate that, unsurprisingly, arbitrary quantum channels cannot be
online learned with a number of mistakes that scales efficiently with the system size. This should
be contrasted with the case of states: Ref. [20] proved that we can online learn the class of all
n-qubit states with a number of mistakes that grows only linearly in n. Moreover, the exponential
mistake lower bounds above motivate the focus on restricted subclasses of channels, such as channels
of bounded gate complexity or mixtures of known channels, which we considered in Sections 3.1
and 3.2. In the next two subsections, we prove mistake lower bounds to be juxtaposed with the
upper bounds established in Sections 3.1 and 3.2.
8Wenotethatthisstandardembeddingofclassicalfunctionsintounitarieshasalreadybeenobservedtogivelower
bounds for PAC learning quantum channels in Ref. [15].
464.2 Mistake lower bounds for channels of bounded complexity
Recall that Theorem 20 and Corollary 21 established regret and mistake upper bounds for online
learning channels of gate complexity G that scaled effectively linearly in G. Our next result, which
follows by combining Corollary 36 with a “zooming in” on a suitable subset of qubits (as previously
employed in Ref. [32]) shows that this scaling is essentially optimal.
Corollary 37 (Essentiallyoptimalscaling). LetCPTP betheclassofalln-qubitG-gatechannels,
n,G
i.e., channels of gate complexity (at most) G, and let ε < 1/2. Any online learner for CPTP
n,G
makes Ω(min{2n,G}) many ε-mistakes against a worst-case adversary. This remains true even if
the adversary is forced to decide on a G-gate channel before the interaction with the learner.
Proof. As we explain in Remark 40 below, for G ≤ n the claimed lower bound follows from our
analysis for Pauli channels. Therefore, for the rest of this proof, we consider only G > n.
Recall that there is a universal constant C > 0 such that every Boolean function f : {0,1}k →
{0,1} can be implemented with a de Morgan circuit of size at most C·2k/k [126]. Here, a de Morgan
circuit is a circuit consisting of AND, OR, and NOT gates, where the AND and OR gates have fan-in
two. Hence, as any classical two-bit gate can be implemented by a two-qubit quantum channel gate,
and as a computational basis measurement on a single qubit corresponds to one single-qubit channel
gate, we see that every k-qubit channel N as in the proof of Corollary 36, with f : {0,1}k → {0,1},
f
can be implemented with C ·2k/k+k ≤ C2k+1 many two-qubit channel gates. Therefore, if we set
k = ⌊log (G/2C)⌋, then CPTP ⊇ {N ⊗id } , where we consider the channels N
2 n,G f n−q f:{0,1}q→{0,1} f
fromtheproofofCorollary36andwherewesetq = min{n,k}. Wecannowstraightforwardlymodify
the states and effect operators used in the proof of Corollary 36 (by attaching, say, the all-zero state
on the last n−q qubits) to show that the ε-mistake bound from Lemma 34, with n replaced by q,
applies to {N ⊗id } . Because of the previously observed inclusion, we conclude that
f n−q f:{0,1}q→{0,1}
also CPTP comes with an ε-mistake lower bound of 2q ≥ min{2n,G/4C} = Ω(min{2n,G}). ■
n,G
Corollary 37 establishes a mistake lower bound for online learning the class CPTP whose
n,G
G-dependence matches our upper bound up to logarithmic factors. However, as the construction in
the proof above uses a measurement followed by an in general non-reversible classical circuit, it is
far from unitary. Therefore, we next give an alternative proof for Corollary 37 that, while still using
non-unitary building blocks, is motivated by reversible computation and therefore can maybe serve
as a stepping stone towards an analogue of Corollary 37 for unitary channels.
Alternative proof of Corollary 37. As before, Ref. [126] tells us that every Boolean function f :
{0,1}k → {0,1} can be implemented with a de Morgan circuit of size at most C ·2k/k. As any
OR gate can be rewritten in terms of three NOT gates and one AND gate, we can also achieve
such implementations with circuit size C ·2k+2/k using only AND and NOT gates. The NOT gate
can trivially be quantumly implemented by the Pauli-X gate. Using what Ref. [127] called the
AND/NAND gate, and which (with a different ordering convention for the inputs) is now known as
the Toffoli gate, we can implement an AND with a reversible three-bit gate when the “source” is a
suitable constant bit, thereby producing two garbage output bits in the “sink”. Therefore, we can
quantumly implement any two-bit AND gate using one three-qubit unitary in conjunction with a
47single-qubit channel gate that resets one of the “sink” qubits to the needed constant input, so that it
can serve as a “source” for the next AND. The reset also allows us to use a single auxiliary qubit only
throughout. Consequently, as any three-qubit unitary can be decomposed into a constant number
of two-qubit unitaries, we can implement every function f : {0,1}k → {0,1} with a (k+1)-qubit
quantum circuit of size C ·2k+3/k (where C is now a new constant).
By this line of reasoning, if we set k = ⌊log (G/8C)⌋ and q = min{n−1,k}, then CPTP ⊇
2 n,G
{N ⊗id |f : {0,1}q → {0,1}}, whereweabusednotation—bynotwritingouttherestriction
f n−(q+1)
tocomputationalbasisinputsandmeasurementsonthefirstq+1qubits,andbyignoringthe“source”
and the “sink” subsystems at the output, which we can achieve by having identity tensor factors on
the corresponding subsystems of the output effect operator. At this point, we again inherit a mistake
lower bound from Corollary 36, which here becomes 2q = min{2n−1,G/16C} ≥ Ω(min{2n,G}). ■
This second proof already hints at a challenge in establishing the same Ω(min{2n,G}) mistake
lower bound for U , the class of all unitary n-qubit channels of gate complexity G. Namely, when
n,G
aiming to implement a unitary U for f : {0,1}q → {0,1}, a natural approach is to take a classical
f
circuit implementation for f and make it reversible. Above, we relied on Toffoli’s construction to
achieve this with a small overhead in gate complexity. However, since there we need a specific
constant input in the “source”, this required us to reset (some of) our “sink” qubits. Such a reset
is a non-reversible operation. Without the ability to reset, making the implementation reversible
naively requires to add one auxiliary qubit per gate, thus exceeding the number of available qubits
if G ≥ n. While we do not yet know how to overcome this obstacle when only using unitary gates,
the following result at least demonstrates a lower bound for the unitary case that deviates from the
G-dependence in the upper bound by only a square root.
Corollary 38 (Lower bound for the unitary case). Let U be the class of all unitary n-qubit chan-
n,G √
nels of gate complexity (at most) G, let ε < 1/2. Any online learner for U makes Ω(min{2n, G})
n,G
many ε-mistakes against a worst-case adversary. This remains true even if the adversary is forced
to decide on a G-gate channel before the interaction with the learner.
Proof. WefirstrecallfromRefs.[128–130]: ThereisauniversalconstantC > 0suchthatanyk-qubit
unitarycanbeimplementedwithC4k manytwo-qubitgates. Thus,ifwesetk = ⌊log (G/C)⌋,thenG
4
many two-qubit gates suffice to implement arbitrary unitaries on k qubits. In particular, this implies
that U ⊃ U ⊗id , where q = min{n,k}. Therefore, a quantum circuit with G many unitary
n,G q n−q
2-qubit gates is able to implement all the unitaries U for functions f : {0,1}q−1 → {0,1} on the first
f
q qubits. Hence, with a straightforward modification of the reasoning used in proving Corollary 35—
tensoring the input states and output effects used there with, say, the all-zero state on the remaining
n−q qubits—, we inherit the ε-mistake bound from Lemma 34 with n replaced by q. That is, we
√
obtain a ε-mistake lower bound of ≥ 2q−1 = min{2n/2,p G/C/4} = Ω(min{2n, G}). ■
4.3 Mistake lower bounds for Pauli channels
To complement the linear-in-n mistake upper bound from Section 3.2, we now give a mistake lower
bound for online learning Pauli channels. Again, we obtain this as a consequence of Lemma 34.
48Corollary 39 (Mistake lower bound for online learning Pauli channels). Let PAULI be the class of
n
all n-qubit Pauli channels, let ε < 1/2. Any online learner for PAULI makes Ω(n) many ε-mistakes
n
against a worst-case adversary. This remains true even if the adversary is forced to decide on a
Pauli channel before the interaction with the learner.
Proof. OurproofisviareductiontoLemma34. Todoso, weassociatetoanyf : {1,...,n} → {0,1}
(cid:16) (cid:17) (cid:16) (cid:17)
the unitary n-qubit Pauli channel N defined via N (ρ) = Nn Zf(i) ρ Nn Zf(i) . Now, if
f f i=1 i i=1 i
we consider a channel test operator E (t) = ρ (t)T⊗M (t) with ρ (t) = |0t−1⟩⟨0t−1|⊗|+⟩⟨+|⊗
A,B A B A
|0n−t⟩⟨0n−t| and M (t) = |0t−1⟩⟨0t−1|⊗|−⟩⟨−|⊗|0n−t⟩⟨0n−t| for some t ∈ {1,...,b}, then
B
Tr[E (t)CN f ] = Tr[M (t)N (ρ (t))] = f(t). (4.5)
A,B A,B B f A
Thus, ifε < 1/2, thenanyonlinelearnerforPAULI thatmakesatmostN ε-mistakesgivesrisetoan
n
online learner for {0,1}{1,...,n} that makes at most N mistakes, by rounding the produced estimates
to obtain a label in {0,1}. Hence, by Lemma 34, we conclude N ≥ 2⌊log(n)⌋ ≥ Ω(2log(n)) = Ω(n). ■
Corollary 39 shows that the linear-in-n scaling achieved in Section 3.2 is optimal for the special
case of Pauli channel online learning. This also tells us that for learning a mixture of K known
channels, the log(K)-dependence in the mistake bound can in general not be improved.
Remark 40. The channels N used in the proof of Corollary 39 are unitary channels of gate
f
complexity n. We can use essentially the same construction to show that for G ≤ n, any online
learner for CPTP makes at least Ω(G) many ε-mistakes if ε < 1/2. To see this, consider unitary
n,G
(cid:16) (cid:17) (cid:16) (cid:17)
n-qubit channels of the form ρ 7→ NG Zf(i) ⊗1⊗(n−G) ρ NG Zf(i) ⊗1⊗(n−G) for functions
i=1 i 2 i=1 i 2
f : {1,...,G} → {0,1}, and argue as in the proof of Corollary 39. ◀
5 Computational complexity lower bounds
5.1 Computational complexity lower bounds for Pauli channels
In Section 4, we established mistake lower bounds for channels. In this section, we focus on
computationalcomplexitylowerboundsforonlinelearningclassesofquantumchannels. Inparticular,
we show that while we achieve polynomial mistake upper bounds for learning classes of quantum
channels, the exponential computational complexity of our learning algorithms cannot be avoided
understandardcryptographicassumptions. Butletusfirststartwithanunconditional computational
hardness lower bound for online learning Pauli channels. The heart of the proof strategy lies in
exploiting the fact that any polynomial time learner is only ever able to access polynomially many
entries of an exponentially sized input. By the adversarial nature of the game, the adversary can
always ‘hide’ the information useful for answering a challenge in an entry that was never seen by
the (polynomial-time) learner. We make this intuition formal in the following result.
Theorem 41. Consider any polynomial-time online learner of n-qubit Pauli channels that runs
in time q(t)(n) at time step t ∈ {1,2,...,T}, for any polynomials q(1)(n),q(2)(n),...,q(T)(n).
There exists an explicit adversarial strategy that forces the learner to make 4n−1 mistakes, where
Q
Q = min{q(t)(n) : t ∈ {1,2,...,T}}.
49Proof. Recall that for any unknown Pauli channel with associated Choi representation N
A,B
predicting Tr[E(t) N ] (the task of the online learner) for a given channel observable E(t) is
A,B A,B A,B
exactly equivalent to predicting e(t)·p, where p is the (unknown) error-rate distribution and the
vector e(t) = (e(t) ) has entries e(t) := Tr[E(t) Γz,x ] for all z,x ∈ {0,1}n.
z,x z,x∈{0,1}n z,x A,B A,B
We work in a simplified setting of a {0,1}-valued game, in which the learner does not have to
evaluate entries e(t) := Tr[E(t) Γz,x ] of the vector e(t) = (e(t) ) for all z,x ∈ {0,1}n; the
z,x A,B A,B z,x z,x∈{0,1}n
learner directly receives the vector e(t) (which we shall refer to as the ‘challenge’ vector), instead of
the test operators E(t) . The learning task is still not obviously computationally tractable, because
A,B
the challenge vector is of size 4n. We prove that a polynomial-time learner, who by definition
only looks at polynomially-many entries of e(t), can be forced to make Ω˜(4n) many mistakes by a
simple adversarial strategy. The adversarial strategy is to always play e(t) = 0 = (0,0,...,0), i.e.,
the all-zeros vector, corresponding to E(t) = 0.9 We now show that by using the same all-zeros
A,B
challenge vector in every round, the adversary can always contradict the learner’s prediction, and
thereby claim that they made a mistake. In any T-round interaction with the adversary, let the
(deterministic) learner predict y ∈ {0,1} in round t ∈ {1,2,...,T}. In response, the adversary
t
claims the correct answer to be b = ¬y . In other words, the adversary always contradicts the
t t
learner’s prediction, and thereby forces the learner to make a mistake. Note that this contradictory
feedback indeed constitutes a mistake when we take the loss function to be ℓ (y ) := |y −b |, because
t t t t
ℓ (y ) = |y −(¬y )| = 1 for all t ∈ {1,2,...,T}.
t t t t
Let us now prove that after the end of the T rounds, the adversary can claim to be “consistent”,
despite their contradictory feedback, as long as it does not contradict the entries that the learner has
seen. In other words, after the end of the T rounds, the adversary can always exhibit a p∗ ∈ ∆
4n
and challenge vectors e˜(t) such that, for all t ∈ {1,2,...,T}, ¬y = p∗·e˜(t) and such that e˜(t) has
t
0-entries at the positions of the challenge vector that the online learner accessed in round t. The
key to proving this is the fact that the learner is computationally bounded, and therefore, they can
only query polynomially-many entries of e(t) in every round.
In any given round, the adversarial feedback, ¬y , is either 0 or 1. For ¬y = 0, the adversary
t t
claims to actually have played the all-zero challenge vector. For the rounds where the adversary
claimed ¬y = 1, the adversary needs to demonstrate that, while the learner only saw all zeroes in
t
such rounds, there was in fact a non-zero entry in e(t) (that the learner did not look at) and that
this entry leads to p∗·e(t) = 1. In fact, as we argue below, it suffices for the adversary to only claim
that e(t) had a single non-zero entry. Vectors e(t) with this structure are indeed realized in our
learning scenario by choosing E(t) = Γz′,x′ /4n for some z′,x′ ∈ {0,1}n, because {Γz,x }
A,B A,B A,B z,x∈{0,1}n
forms an orthogonal basis and Tr[(Γz,x )2] = 4n. Thus, choosing E(t) = Γz′,x′ /4n ensures that e(t)
A,B A,B A,B
is has 4n−1 entries equal to 0 and a single entry e equal to 1, when z = z′ and x = x′.
z,x
Let us partition the set R := {1,2,...,T} into two disjoint subsets as R = R ∪R , where R
0 1 0
is the set of time steps in which the adversary claimed the correct answer to be 0 and R is the
1
set of time steps in which they claimed the correct answer to be 1. Let q(t)(n) be the polynomial
number of entries of e(t) accessed by the learner at time step t. Also, let I ⊆ {0,1}n×{0,1}n be the
t
9Note that we need to ensure that there is always a channel observable E(t) that realizes e(t) in each round,
A,B
because the input to the online learning game is defined with respect to E(t) .
A,B
50indices corresponding to the entries of e(t) accessed by the learner in round t. To be consistent, the
adversary sets to 0 all entries of e(t) and p∗ corresponding to the indices in (S I )∪(S I ),
t∈R0 t t∈R1 t
i.e., all entries that the learner saw. Then, retroactively, for the rounds in which they claimed 1
to be the correct answer, the adversary can always claim that the 1-entry in both e(t) and p∗ was
an entry that the learner never saw, i.e., an entry whose index is in (cid:0)(S I )∪(S I )(cid:1)c. It is
t∈R0 t t∈R1 t
sufficient that there exists at least one such index. Then, this adversarial strategy works as long as
the number of entries seen by the learner does not exceed 4n−1 (in order to account for at least
one entry that the learner has not seen). In other words,
4n−1 ≥ X q(t)(n)+ X q(t)(n) (5.1)
t∈R0 t∈R1
≥ q (n)|R |+q (n)|R |
0 0 1 1
≥ QT,
where q (n) := min{q(t)(n) : t ∈ R } and q (n) := min{q(t)(n) : t ∈ R }, and the final inequality
0 0 1 1
holds because q (n) ≥ Q, q (n) ≥ Q (recall that Q := min{q(t)(n) : t ∈ {1,2,...,T}}), and
0 1
|R | + |R | = T. Thus, the adversary can force the learner to make mistakes for 4n−1 many
0 1 Q
rounds. ■
Remark 42. The computational complexity of MWU (Algorithm 1) for online learning convex
combinations of K known channels scales polynomially with K, which in the worst case could be
exponential in the number of qubits, as is the case for general Pauli channels. If, however, the learner
is given challenge vectors e(t) with entries e(t) := Tr[E(t) Γz,x ] that are poly(n)-sparse (with known
z,x A,B A,B
sparsity structure), then an online learner can learn such a channel computationally efficiently and
also saturate optimal regret and mistake bounds using MWU (Algorithm 1). A relevant example
(from quantum error correction) of a class of channels that can be written as convex combinations
of polynomially many known channels is that of polynomially-sparse Pauli channels with a known
sparsity structure. Hence, our results imply that this class of channels is computationally efficiently
online learnable with regret and mistake bounds that scale with log(n). ◀
Remark 43. The proof strategy in Theorem 41 straightforwardly implies that any polynomial time
learner for online learning quantum states (in the sense defined in Ref. [20]) can be forced to make
exponentially many ε-mistakes as long as the ‘challenge’ effect operators admit exponentially long
descriptions. To see this, write, in its spectral decomposition, any n-qubit state ρ = P2n p |ψ ⟩⟨ψ |
i=1 i i i
that a learner wishes online learn. For the lower bound, it suffices to work in a simpler scenario in
which the learner knows the eigenbasis {|ψ ⟩}2n in advance but not the eigenvalues {p }2n . For
i i=1 i i=1
every effect operator E, we have Tr[ρE] = P2n p ⟨ψ |E|ψ ⟩. Defining a vector e = (e )2n with
i=1 i i i i i=1
entries e = ⟨ψ |E|ψ ⟩, we can rewrite this as Tr[ρE] = p·e, where p = (p )2n . Since e is still an
i i i i i=1
exponentially long challenge vector, the strategy in the proof of Theorem 41 suffices to make the
online learner make exponentially many mistakes. ◀
5.2 Computational complexity lower bounds for channels of bounded complexity
The online learner for CPTP presented in Section 3.1 achieves good regret and ε-mistake bounds,
n,G
but is computationally inefficient. In this section, we prove that, under a widely held cryptographic
51hardnessassumption,namelyhardnessof RingLWE,therecannotbeacomputationallyefficientonline
learning algorithm for CPTP that achieves favorably scaling mistake bounds. Via Lemma 12, this
n,G
alsoimpliesthatgoodregretboundsforonlinelearningCPTP cannotbeachievedcomputationally
n,G
efficiently, but we again focus on mistake bounds here. Our proof, which is conceptually analogous to
arguments in [32, 131], is yet another instance of the well known fact that pseudorandom functions
cannot be learned efficiently, which we phrase in an online learning framework.
First, we recall the definition of pseudorandom functions.
Definition 44 (Pseudorandom functions (PRFs) [132]). Let λ be a security parameter. Let K =
{K λ} λ∈N be key space, assumed to be efficiently sampleable. Let X = {X λ} λ∈N,{Y λ} λ∈N be families
of finite sets. Let F = {f λ} λ∈N be a family of efficiently-computable functions f λ : K λ×X λ → Y λ,
where the input from K corresponds to the function key. The family F is a pseudorandom function
λ
(family) secure against (classical) t(λ)-time adversaries if for every t(λ)-time probabilistic algorithm
Adv, there exists a negligible function negl(·)—that is, a function satisfying negl(λ) = o(1) for every
p(λ)
polynomial p—such that, for every security parameter λ ∈ N, it holds that
(cid:12) (cid:12)
(cid:12) (cid:12)
(cid:12) (cid:12) Pr [Advf(k,·)(·) = 1]− Pr [Advg(·) = 1](cid:12) (cid:12) ≤ negl(λ), (5.2)
(cid:12) (cid:12)k∼K λ g∼YXλ (cid:12) (cid:12)
λ
where the key k is drawn uniformly at random from K and g is drawn uniformly at random from
λ
the set of all functions from X to Y . Here, we use Adv with a function superscript to mean the
λ λ
action of the algorithm Adv when given oracle access to that function. ◀
Typically, the runtime t(·) of interest in this definition is taken to be polynomial. However, other
choices of t(·) are possible.
Next, we formalize the hardness of learning PRFs in the context of online learning:
Theorem 45 (Hardness of learning PRFs in online learning). Take the security parameter to be
λ = n. Let F = {f λ} λ∈N be a PRF that is secure against classical O(t(n))-time adversaries. Let
∆ : N → N be a polynomial and let p : N → N be a function such that p(n),ln( ∆(n) ) ≤ O(t(n)).
∆(n)−1
Suppose G ⊆ [0,1]{0,1}n is a function class such that F ⊆ G and ln(N (G,1/6,∞)) ≤ p(n).
T
There exists no classical O(t(n))-time algorithm for properly online learning G with at most
l m l m
6(p(n)+ ln( ∆(n) ) ) many (1/3)-mistakes in an online game with 18(p(n)+ ln( ∆(n) ) ) rounds.
∆(n)−1 ∆(n)−1
Theorem 45 in particular says: If a hypothesis class of interest has polynomial sequential metric
entropies and contains a class of PRFs secure against polynomial-time adversaries, then that class
cannot be efficiently online learned with polynomially many O(1)-mistakes.
Proof. Suppose for contradiction that A is an O(t(n))-time algorithm for properly online learning
l m
G with at most m(n) = 6(p(n)+ ln( ∆(n) ) ) many (1/3)-mistakes in an online learning game
∆(n)−1
with at least T(n) = 3m(n) many rounds. Note that T(n) ≤ O(t(n)), by our assumptions on p
and ∆. We then construct a procedure for distinguishing between a random element of F and
a truly random function with success probability ≥ 1/∆(n). Namely, we define D, when given
52query access to a function f, to act as follows: First, simulate an online learning game between
the learner A and an adversary that uses an arbitrary sequence of pairwise distinct challenges
x ,...,x ∈ {0,1}n and the corresponding true values f(x ),...,f(x ). Second, if A made at most
1 T 1 T
m(n) many (1/3)-mistakes, D outputs “f ∈ F”, otherwise D outputs “f truly random”.
Let us analyze the success probability of D. On the one hand, if f ∈ F ⊆ G, then the simulated
online learning game takes place in a realizable scenario. So A makes at most p(n) many (1/3)-
mistakes by assumption, and thus D correctly outputs “f ∈ F”. On the other hand, suppose f is
chosen as a truly random function from {0,1}n to {0,1}. As A is assumed to be proper, we know
that for any 1 ≤ m ≤ T(n),
P [A makes ≤ m many (1/3)-mistakes]
f
≤ P [∃g ,...,g ∈ G : |{|f(x )−g (x )| > 1/3}| ≤ m]. (5.3)
f 1 T(n) t t t
Next, notice that by the definition of sequential covering with p = ∞, if we let V = V(x) be a
smallest sequential ∞-norm (1/6)-cover for G, where x is a complete rooted binary tree of depth
T(n) such that there is a path π with x (π) = x for all 1 ≤ t ≤ T(n), then for any g ,...,g ∈ G,
t t 1 T(n)
there exists a v ∈ V such that |v (π)−g (x )| = |v (π)−g (π)| ≤ 1/6. So, by the triangle inequality
t t t t t
and a union bound,
P [∃g ,...,g ∈ G : |{|f(x )−g (x )| > 1/3}| ≤ m]
f 1 T(n) t t t
≤ P [∃v ∈ V : |{|f(x )−v (π)| > 1/6}| ≤ m]
f t t
≤ X P [|{|f(x )−v (π)| > 1/6}| ≤ m]. (5.4)
f t t
v∈V
As the x ,...,x are pairwise distinct and f is a random function, the values f(x ),...,f(x ) are
1 T 1 T
independent Bernoulli random variables, each with parameter 1/2.
Hence, for any fixed v and for any 0 ≤ m ≤ T(n), the probability that at most m of the
2
predictions made by v are (1/6)-mistakes is
2(T(n) −m)2!
P [|{|f(x )−v (π)| > 1/6}| ≤ m] = P[Binom(T(n),1/2) ≤ m] ≤ exp − 2 , (5.5)
f t t T(n)
where we have used a Chernoff-Hoeffding bound. Plugging this into our previous bound, we see that
2(T(n) −m(n))2!
P [A makes ≤ m(n) many (1/3)-mistakes] ≤ |V|·exp − 2 (5.6)
f T(n)
(cid:18) T(n)(cid:19)
≤ N (G,1/6,∞)·exp −
T(n) 18
(cid:18) T(n)(cid:19)
≤ exp p(n)−
18
1
≤ 1− ,
∆(n)
where we have used T(n) = 3m(n) and our choice of m(n). Thus, in the case of a truly random
f, the distinguisher D correctly outputs “f truly random” with probability ≥ 1 . As ∆ is by
∆(n)
53assumption polynomial, this means that D successfully distinguishes between pseudorandom and
random with non-negligible success probability.
Thus, to complete the proof by contradiction (to the pseudorandomness guarantee required in
Definition 44), it remains to argue that D runs in time O(t(n)). This can be seen as follows. On
the one hand, D plays the online learning game. Here, the learning side takes time O(t(n)) by
assumption, and the adversary side takes time O(T(n)), since oracle queries take unit time. On
the other hand, D checks how many mistakes the online learner makes, which takes time O(T(n)).
Thus, the overall time taken by D is O(t(n)+T(n)) ≤ O(t(n)). ■
Remark 46. Notice that in the proof of Theorem 45, the only property of the challenges x ,...,x
1 T
that mattered to the argument was that they are chosen to be pairwise distinct. Hence, this line of
reasoning can be extended to learner-adversary interactions in which the learner, rather than the
adversary, actively chooses pairwise distinct inputs to the unknown function.
We now apply Theorem 45 for our scenario of online learning bounded-complexity quantum
channels. To obtain efficiently implementable PRFs, we make a common hardness assumption,
namely the hardness of the ring learning with errors (RingLWE) problem [85]. Note that despite our
online learning problems revolving around function classes coming from quantum physics, the classes
and learners under consideration are all classical. Therefore, we only assume classical hardness of
RingLWE.
Corollary 47 (Computationalhardness). Takethesecurityparametertobeλ = n. LetCPTP be
n,G
theclassofalln-qubitchannelsofgatecomplexityatmostG. Ifthereisnoclassicalpolynomial-time
algorithm for solving RingLWE, then already for G = O(npolylog(n)) there exists no (classical)
polynomial-time algorithm for properly online learning CPTP with at most polynomially many
n,G
(1/3)-mistakes, even under the promise that all challenges consist of input states and output effect
operators given by rank-1 projections on computational basis elements (without an auxiliary system).
Proof. First, recall from Corollary 19 that the sequential metric entropies of CPTP satisfy the
n,G
bound lnN (CPTP ,1/6,∞) ≤ O(Glog(Gn)), which scales at most polynomially in n if G does.
T n,G
Thus, to apply Theorem 45, it remains to argue that CPTP contains a suitable PRF family. We
n,G
combine results from prior work to obtain such a PRF from the assumed hardness of RingLWE.
Namely, Ref. [133, Theorem 5.3] shows that polynomial-time hardness of (decision-)RingLWE with
suitable parameters (see Ref. [85, 133] for more context and a formal discussion) gives rise to a
PRF family RF = {f λ} λ∈N on m = ω(log(λ))-bit inputs that is secure against polynomial-time
classical adversaries. Moreover, as shown in Ref. [134, Lemma 3.16], every f ∈ RF can be
λ
computed by a TC0 circuit, that is, by a constant-depth, polynomial-size circuit consisting of AND,
OR, NOT, and MAJORITY gates with unbounded fan-in. As shown in Ref. [32, Proposition
2], if f : {0,1}m → {0,1} can be implemented by a TC0 circuit, then there is a quantum circuit
on n = O(poly(m)) qubits with size O(npolylog(n)) that implements the unitary U acting as
f
U |x⟩|b⟩ = |x⟩|b⊕f(x)⟩(ignoringauxiliaryqubits). Consequently,choosingthesecurityparameteras
f
λ = n,everyfunctioninRF canbeimplementedbyaunitaryquantumcircuitofsizeO(npolylog(n)),
and thus G = O(npolylog(n)) suffices to guarantee the inclusion RF ⊆ CPTP . (Note: Here, we
n,G
slightly abused notation by not explicitly restricting CPTP to the input space of RF, which can
n,G
be embedded into the Boolean hypercube.)
54Hence, for G = O(npolylog(n)), we can apply Theorem 45 with F = RF, G = CPTP
n,G
(again not writing out the restriction of the input space), ∆(n) = 3, p(n) = O(Glog(Gn)), and
t(n) = poly(n). This yields the claimed result. ■
As can be seen in the proof of Corollary 47, the hardness assumption on RingLWE is “only” used
to obtain a PRF class implementable by relatively small circuits. Therefore, one may replace this
widely believed assumption about the hardness of a concrete problem [52–54] by a more abstract
cryptographic assumption on the existence of PRFs implementable by small circuits, and the above
line of reasoning can still be applied.
6 Shadow tomography of quantum processes
For quantum states, shadow tomography [16, 17, 19] is the task of using few copies of an un-
known state to predict the expectation values of M effect operators, which may be chosen adap-
tively/adversarially. In this section, we consider the analogous problem for quantum processes,
starting with quantum channels and then going to multi-time processes.
Problem 3 (Shadow tomography of quantum channels). Let N ∈ CPTP be an (unknown)
A→B n
n-qubit channel, and let ε,δ > 0. When sequentially presented with any adversarially chosen
sequence of two-outcome test operators, E(1) ,E(2) ,...,E(M), for M ∈ N, return quantities b ∈ R
A,B A,B A,B i
such that |b −Tr[E(i) CN ]| ≤ ε for all i ∈ {1,2,...,M} with probability at least 1−δ. Do this
i A,B A,B
by querying the channel k times (adaptively or in parallel), with k being as small as possible. ◀
Embedding classical functions into quantum channels similarly to Section 4.1, one can see that
in the case of general quantum channels, no non-trivial shadow tomography strategy—achieving a
query complexity that is simultaneously sublinear in M and polynomial in n—is possible. Therefore,
we again have to consider restricted classes of channels. We primarily focus on Pauli channels
and Pauli multi-time processes, for which we introduce a shadow tomography scheme via classical
adaptive data analysis [55, 56] that requires few measurements (of the Choi state) of the unknown
process.
Theorem 48 (Shadow tomography of Pauli channels). There exists an explicit strategy that solves
Problem 3 for any n-qubit Pauli channel using
√ nlog(M)log3/2((εδ)−1)!
k = O (6.1)
ε3
copies of the channel. The strategy runs in time poly(4n,k) per query.
Proof. Let A and B be n-qubit systems, and consider a Pauli channel P as in (2.11), with
A→B
error-rate vector p = (p ) . Consider also test operators E(i) , for i ∈ {1,2,...,M}. For
z,x z,x∈{0,1}n A,B
every such operator, we have
Tr[E(i) CP ] = X p Tr[E(i) Γz,x ] = E [e(i) ], (6.2)
A,B A,B z,x A,B A,B (z,x)∼p z,x
z,x∈{0,1}n
55where we have defined e(i) := Tr[E(i) Γz,x ]. From this, we can see that every desired expectation
z,x A,B A,B
value is exactly the expectation value of the function (z,x) 7→ e(i) = Tr[E(i) Γz,x ] with respect
z,x A,B A,B
to the error-rate probability distribution p of the unknown Pauli channel P . Now, we can
A→B
obtain samples from the error-rate distribution by performing Bell measurements on the Choi
state. Specifically, to obtain one sample, we prepare a (2n)-qubit maximally-entangled state
Φ = |Φ⟩⟨Φ| (recall (2.4)), send the A′ system through the channel, and then measure systems
A,A′ A,A′
A and B with respect to the Bell basis POVM {Φz,x} . Note that this indeed amounts to
z,x∈{0,1}n
measuring the Choi state of the channel with respect to the Bell basis POVM. Then, using the
definition of the n-qubit Bell states in (2.4), the probability of obtaining an outcome (z,x) is given
by
Tr[Φz,x (id ⊗P )(Φ )] = Tr[Φz,x ΦP ] (6.3)
A,B A A′→B A,A′ A,B A,B
= X p Tr[Φz,x Φz′,x′]
z′,x′ A,B A,B
z′,x′∈{0,1}n
= p ,
z,x
for all z,x ∈ {0,1}n.
We can now combine (6.2) with the ability to sample from the error-rate distribution obtained
by Bell measurements to make use of known results in classical adaptive data analysis [55, 56]. In
classical data analysis, the goal is to answer a sequence of adaptively chosen queries q ,q ,...,q
1 2 M
with answers b ,b ,...,b , such that |b −q (p)| ≤ ε for all i ∈ {1,2,...,M}, given k samples from
1 2 M i i
the underlying (unknown) probability distribution p. This setting precisely matches our setting of
Pauli channel shadow tomography, by recognizing that the underlying distribution p can be taken
to be the error-rate distribution of the unknown Pauli channel, and the queries q can be taken
i
to be q (p) ≡ E [e(i) ], i ∈ {1,2,...,M}. Then, in the regime M ≫ k, we make direct use of
i (z,x)∼p z,x
Ref. [56, Corollary 6.3] to obtain our desired result. ■
We highlight that Theorem 48 for restricted/approximate shadow tomography of Pauli channels
canbeusedtoperformshadowtomographyofarbitrarychannels,essentiallybyapplyingTheorem48
to the Pauli twirled version of the channel. The upshot is that our bounds scale with the diamond
norm distance between the unknown channel and its corresponding Pauli twirled version.
Corollary 49 (Shadow tomography of arbitrary quantum channels). Let N ∈ CPTP be an
n
arbitrary quantum channel. There exists an explicit strategy that solves Problem 3 for N using
√
nlog(M)log3/2(((ε− 1∥N −NP∥ )δ)−1)!
k = O 2 ⋄ (6.4)
(ε− 1∥N −NP∥ )3
2 ⋄
copies of N, where NP is the Pauli twirled version of N and ε > 1∥N −NP∥ .
2 ⋄
Proof. WeperformaBellmeasurementontheChoistateoftheunknownchannel. Themeasurement
probabilities define the error-rate vector of the Pauli-twirled version of the channel, based on the
developmentsinAppendixC.Then, wemakeuseofthetriangleinequalityasfollows, foranarbitrary
b ∈ R and arbitrary channel test operator, to get
(cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12)
(cid:12)b−Tr[E CN ](cid:12) ≤ (cid:12)b−Tr[E CNP ](cid:12)+(cid:12)Tr[E CNP ]−Tr[E CN ](cid:12) (6.5)
(cid:12) A,B A,B (cid:12) (cid:12) A,B A,B (cid:12) (cid:12) A,B A,B A,B A,B (cid:12)
56(cid:12) (cid:12) (cid:12) (cid:12)
≤ (cid:12)b−Tr[E CNP ](cid:12)+ sup (cid:12)Tr[E CNP ]−Tr[E CN ](cid:12)
(cid:12) A,B A,B (cid:12) (cid:12) A,B A,B A,B A,B (cid:12)
EA,B
(cid:12) (cid:12) 1
= (cid:12)b−Tr[E CNP ](cid:12)+ ∥N −NP∥ ,
(cid:12) A,B A,B (cid:12) 2 ⋄
where in the final equality we made use of the fact that (see, e.g., [135, Section 4])
1
n o
∥N −M∥ = sup Tr[E (CN −CM )] : E ≤ σ ⊗1 , Tr[σ ] = 1 (6.6)
2 ⋄ A,B A,B A,B A,B A B A
EA,B≥0
σA≥0
n(cid:12) (cid:12) o
= sup (cid:12)Tr[E (CN −CM )](cid:12) : E ≤ σ ⊗1 , Tr[σ ] = 1 ,
(cid:12) A,B A,B A,B (cid:12) A,B A B A
EA,B≥0
σA≥0
for arbitrary channels N and M. Finally, as we assume ε− 1∥N −NP∥ > 0, can run the Pauli
2 ⋄
channel shadow tomography from Theorem 48 with accuracy parameter ε˜= ε− 1∥N −NP∥ to get
2 ⋄
(cid:12) (cid:12)
the desired approximation guarantee (cid:12)b−Tr[E CN ](cid:12) ≤ ε with the claimed sample complexity
(cid:12) A,B A,B (cid:12)
bounds. ■
6.1 Shadow tomography of multi-time processes
By analogy with the shadow tomography problem for quantum channels, we can formulate the
problem of shadow tomography for multi-time quantum processes.
Problem 4 (Shadow tomography of multi-time quantum processes). Let r ∈ {1,2,...}, let
N ∈ COMB be a comb operator corresponding to a multi-time quantum process with r time steps,
r
and let ε,δ > 0. When sequentially presented with any adversarially chosen sequence of two-outcome
multi-time test operators E(1),E(2),...,E(M), for M ∈ {1,2,...}, return quantities b ∈ R such
i
that |b −Tr[EN]| ≤ ε for all i ∈ {1,2,...,M} with probability at least 1−δ. Do this by querying
i
the process k times (adaptively or in parallel), with k being as small as possible. ◀
By following arguments similar to those in the proof of Corollary 49, we can prove a shadow
tomography result for arbitrary multi-time quantum processes as follows. In particular, this involves
introducing the idea of Pauli-twirling a multi-time process, which we illustrate in Figure 4(a).
Corollary 50. Let r ∈ {1,2,...}, let N ∈ COMB be a comb operator corresponding to a multi-
r
time quantum process with r time steps. There exists an explicit strategy that solves Problem 4 for
N using
√
nrlog(M)log3/2(((ε− 1∥N −NP∥ )δ)−1)!
k = O 2 ⋄r , (6.7)
(ε− 1∥N −NP∥ )3
2 ⋄r
where NP is the comb operator corresponding to the Pauli-twirled version of the multi-time process
(see Figure 4(a) for a depiction), and ε > 1∥N −NP∥ .
2 ⋄r
Proof. We proceed by performing “time-local” Bell measurements on the multi-time process; see
Figure 4(b). This means that, for every time step, we prepare a Bell state, send one-half of it
57A1
Pw1
A1
1
B1
Pw1†
B1 A2
Pw2
A2
2
B2
Pw2†
B2 A3
Pw3
A3
3
B3
Pw3†
B3
N N N
M1 M2
(a)
Φ
A1
Φ
A2
Φ
A3
w1 w2 w3
A1
1
B1 A2
2
B2 A3
3
B3
N N N
M1 M2
(b)
Figure 4: Twirling of multi-time quantum processes. (a) A “time-local” Pauli twirl of
a multi-time quantum process with r time steps consists of independently applying a random
Pauli channel Pwk(·):=Pwk(·)Pwk†, where w
k
≡(z k,x k)∈{0,1}n×{0,1}n, to the input and
output of every time step k ∈{1,2,...,r}. (b) After twirling, the process is characterized by an
error-rate probability vector, in the same way as Pauli channels. This error-rate vector can be
obtained via time-local Bell measurements, as shown. The outcomes of the measurements are
w ≡(z ,x ),w ≡(z ,x ),...,w ≡(z ,x ).
1 1 1 2 2 2 r r r
through the process, and then measure the output system and the other-half of the Bell state in
the (2n)-qubit Bell basis. Doing this once for each time step leads to measurement outcomes w ≡
1
(z ,x ),w ≡ (z ,x ),...,w ≡ (z ,x ). The probability of any such collection of measurement
1 1 2 2 2 r r r
outcomes is given by
1
h(cid:16) (cid:17) i
p = Tr Φz1,x1 ⊗Φz2,x2 ⊗···⊗Φzr,xr N , (6.8)
z1,x1,z2,x2,...,zr,xr 2nr A1,B1 A2,B2 Ar,Br A1,B1,A2,B2,...,Ar,Br
which is due to the fact that applying one-half of a maximally-entangled state to every input of the
process defines the Choi state of the process, which is equal to 1 N; see Appendix B.
2nr
Let us now consider the Pauli-twirl of the process, as depicted in Figure 4(a). By combining
Lemma 58 and Proposition 59, we find that the comb operator NP for the Pauli-twirled process is
equal to
NP = (S ⊗···⊗S )(N ) (6.9)
A1,B1,...,Ar,Br P P A1,B1,...,Ar,Br
= X Trh(cid:16) Φz1,x1 ⊗Φz2,x2 ⊗···⊗Φzr,xr (cid:17) N i
A1,B1 A2,B2 Ar,Br A1,B1,A2,B2...,Ar,Br
z1,x1,...,zr,xr∈{0,1}n
×Φz1,x1 ⊗Φz2,x2 ⊗···⊗Φzr,xr (6.10)
A1,B1 A2,B2 Ar,Br
= X p Γz1,x1 ⊗Γz2,x2 ⊗···⊗Γzr,xr .
z1,x1,z2,x2,...,zr,xr A1,B1 A2,B2 Ar,Br
z1,x1,z2,x2,...,zr,xr∈{0,1}n
We now observe that the comb operator for the Pauli-twirled process can be thought of as simply the
Choirepresentationofan(nr)-qubitPaulichannel. Assuch, wecanapplyTheorem48. Furthermore,
58for an arbitrary b ∈ R and an arbitrary test operator E, we have
(cid:12) (cid:12) (cid:12) (cid:12)
|b−Tr[EN]| ≤ (cid:12)b−Tr[ENP](cid:12)+(cid:12)Tr[ENP]−Tr[EN](cid:12) (6.11)
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
≤ (cid:12)b−Tr[ENP](cid:12)+sup(cid:12)Tr[ENP]−Tr[EN](cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
E
1
= |b−Tr[EN]|+ ∥N −NP∥ ,
2 ⋄r
where for the final equality we made use of the fact that
1
n o
∥N −M∥ = sup Tr[E(N −M)] : E ≤ S ⊗1 , S ∈ COMB∗ (6.12)
2 ⋄r Br r
E,S≥0
n o
= sup |Tr[E(N −M)]| : E ≤ S ⊗1 , S ∈ COMB∗ ,
Br r
E,S≥0
for arbitrary N,M ∈ COMB . To conclude, we again invoke the Pauli channel shadow tomography
r
of Theorem 48 ε with accuracy ε− 1∥N −NP∥ > 0 to obtain the desired approximation error
2 ⋄r
|b−Tr[EN]| ≤ ε with the claimed sample complexity bound. ■
59Bibliography
[1] J. Eisert, D. Hangleiter, N. Walk, I. Roth, D. Markham, R. Parekh, U. Chabaud, and
E. Kashefi. Quantum certification and benchmarking. Nature Reviews Physics, 2:382–390,
2020. doi: 10.1038/s42254-020-0186-4.
[2] Z. Hradil. Quantum-state estimation. Physical Review A, 55:R1561–R1564, 1997. doi:
10.1103/PhysRevA.55.R1561.
[3] G. Mauro D’Ariano, M. G.A. Paris, and M. F. Sacchi. Quantum tomography. Advances in
Imaging and Electron Physics, 128:205–308, 2003. doi: 10.1016/S1076-5670(03)80065-4.
[4] D. Gross, Y.-K. Liu, S. T. Flammia, S. Becker, and J. Eisert. Quantum state tomography via
compressed sensing. Physical Review Letters, 105:150401, 2010. doi: 10.1103/PhysRevLett.
105.150401.
[5] R. Blume-Kohout. Optimal, reliable estimation of quantum states. New Journal of Physics,
12(4):043034, 2010. doi: 10.1088/1367-2630/12/4/043034.
[6] K. Banaszek, M. Cramer, and D. Gross. Focus on quantum tomography. New Journal of
Physics, 15(12):125020, 2013. doi: 10.1088/1367-2630/15/12/125020.
[7] I. L. Chuang and M. A. Nielsen. Prescription for experimental determination of the dynamics
of a quantum black box. Journal of Modern Optics, 44(11–12):2455–2467, 1997. doi: 10.1080/
09500349708231894.
[8] G. M. D’Ariano and P. Lo Presti. Quantum tomography for measuring experimentally the
matrix elements of arbitrary quantum operation. Physical Review Letters, 86:4195–4198, 2001.
doi: 10.1103/PhysRevLett.86.4195.
[9] M. Mohseni, A. T. Rezakhani, and D. A. Lidar. Quantum-process tomography: Resource
analysis of different strategies. Physical Review A, 77:032322, 2008. doi: 10.1103/PhysRevA.
77.032322.
[10] J. Haah, A. W. Harrow, Z. Ji, X. Wu, and N. Yu. Sample-optimal tomography of quantum
states. IEEE Transactions on Information Theory, 63(9):5628–5641, 2017. doi: 10.1109/TIT.
2017.2719044.
[11] R. O’Donnell and J. Wright. Efficient quantum tomography. In Proceedings of the forty-eighth
annual ACM symposium on Theory of Computing, pages 899–912, 2016. doi: 10.1145/2897518.
2897544.
[12] S. Chen, J. Li, Brice Huang, and A. Liu. Tight bounds for quantum state certification with
incoherentmeasurements. In2022 IEEE 63rd Annual Symposium on Foundations of Computer
Science (FOCS), pages 1205–1213. IEEE, 2022. doi: 10.1109/FOCS54457.2022.00118.
[13] J.Haah, R.Kothari, R.O’Donnell, andE.Tang. Query-optimalestimationofunitarychannels
in diamond distance. 2023. arXiv:2302.14066.
60[14] A. Oufkir. Sample-optimal quantum process tomography with non-adaptive incoherent
measurements. 2023. arXiv:2301.12925.
[15] S. Aaronson. The learnability of quantum states. Proceedings of the Royal Society A:
Mathematical, Physical and Engineering Sciences, 463(2088):3089–3114, 2007. doi: 10.1098/
rspa.2007.0113.
[16] S. Aaronson. Shadow tomography of quantum states. In Proceedings of the 50th Annual ACM
SIGACT Symposium on Theory of Computing, STOC 2018, pages 325–338, New York, NY,
USA, 2018. Association for Computing Machinery. doi: 10.1145/3188745.3188802.
[17] C. Bădescu and R. O’Donnell. Improved quantum data analysis. TheoretiCS, Volume 3, 2024.
doi: 10.46298/theoretics.24.7.
[18] H.-Y. Huang, R. Kueng, and J. Preskill. Information-theoretic bounds on quantum advantage
in machine learning. Physical Review Letters, 126:190505, 2021. doi: 10.1103/PhysRevLett.
126.190505.
[19] R. King, D. Gosset, R. Kothari, and R. Babbush. Triply efficient shadow tomography. 2024.
arXiv:2404.19211.
[20] S. Aaronson, X. Chen, E. Hazan, S. Kale, and A. Nayak. Online learning of quantum
states. Journal of Statistical Mechanics: Theory and Experiment, 2019(12):124019, 2019. doi:
10.1088/1742-5468/ab3988.
[21] X. Chen, E. Hazan, T. Li, Z. Lu, X. Wang, and R. Yang. Adaptive online learning of quantum
states. 2022. arXiv:2206.00220.
[22] H.-Y. Huang, R. Kueng, and J. Preskill. Predicting many properties of a quantum system
from very few measurements. Nature Physics, 16:1050–1057, 2020.
[23] A. Elben, S. T. Flammia, H.-Y. Huang, R. Kueng, J. Preskill, B. Vermersch, and P. Zoller.
The randomized measurement toolbox. Nature Reviews Physics, 5:9–24, 2023.
[24] M. Ohliger, V. Nesme, and J. Eisert. Efficient and feasible state tomography of quantum
many-body systems. New Journal of Physics, 15(1):015024, 2013. doi: 10.1088/1367-2630/15/
1/015024.
[25] H.-Y. Huang, M. Broughton, J. Cotler, S. Chen, J. Li, Masoud Mohseni, Hartmut Neven,
Ryan Babbush, R. Kueng, John Preskill, and Jarrod R. McClean. Quantum advantage in
learning from experiments. Science, 376(6598):1182–1186, 2022. doi: 10.1126/science.abn7293.
[26] R. Levy, D. Luo, and R. K. Clark. Classical shadows for quantum process tomography on
near-term quantum computers. Physical Review Research, 6(1):013029, 2024. doi: 10.1103/
PhysRevResearch.6.013029.
[27] J. Kunjummen, M. C. Tran, D. Carney, and J. M. Taylor. Shadow process tomography of
quantum channels. Physical Review A, 107:042403, 2023. doi: 10.1103/PhysRevA.107.042403.
[28] Hsin-Yuan Huang, Sitan Chen, and John Preskill. Learning to predict arbitrary quantum
processes. PRX Quantum, 4(4):040337, 2023. doi: 10.1103/PRXQuantum.4.040337.
61[29] M. C. Caro. Learning quantum processes and Hamiltonians via the Pauli transfer matrix.
2022. arXiv:2212.04471.
[30] A. Angrisani. Learning unitaries with quantum statistical queries. 2023. arXiv:2310.02254.
[31] C. Wadhwa and M. Doosti. Learning quantum processes with quantum statistical queries.
2023. arXiv:2310.02075.
[32] H. Zhao, L. Lewis, I. Kannan, Y. Quek, H.-Y. Huang, and M. C. Caro. Learning quantum
states and unitaries of bounded gate complexity. 2023. arXiv:2310.19882.
[33] M. Riebe, K. Kim, P. Schindler, T. Monz, P. O. Schmidt, T. K. Körber, W. Hänsel, H. Häffner,
C. F. Roos, and R. Blatt. Process tomography of ion trap quantum gates. Phys. Rev. Lett.,
97:220407, 2006. doi: 10.1103/PhysRevLett.97.220407.
[34] R. C. Bialczak, M. Ansmann, M. Hofheinz, E. Lucero, M. Neeley, A. D. O’Connell, D. Sank,
H. Wang, J. Wenner, M. Steffen, A. N. Cleland, and J. M. Martinis. Quantum process
tomography of a universal entangling gate implemented with Josephson phase qubits. Nature
Physics, 6:409–413, 2010. doi: 10.1038/nphys1639.
[35] J. Helsen, M. Ioannou, J. Kitzinger, E. Onorati, A. H. Werner, J. Eisert, and I. Roth.
Estimating gate-set properties from random sequences. Nature Communications, 14:5039,
2023. doi: 10.1038/s41467-023-39382-9.
[36] L. G. Valiant. A theory of the learnable. Communications of the ACM, 27(11):1134–1142,
1984. ISSN 00010782. doi: 10.1145/1968.1972.
[37] N. Littlestone. Learning quickly when irrelevant attributes abound: A new linear-threshold
algorithm. Machine Learning, 2(4):285–318, 1988. ISSN 1573-0565.
[38] S.Shalev-ShwartzandS.Ben-D.UnderstandingMachineLearning: FromTheorytoAlgorithms.
Cambridge University Press, 2014. doi: 10.1017/CBO9781107298019.
[39] M. Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. Foundations of Machine Learning.
MIT Press, 2 edition, 2018.
[40] M.Kearns,M.Li,L.Pitt,andL.G.Valiant. RecentresultsonBooleanconceptlearning. InPat
Langley, editor, Proceedings of the Fourth International Workshop on Machine Learning, pages
337–352. Morgan Kaufmann, 1987. doi: https://doi.org/10.1016/B978-0-934613-41-5.50037-4.
[41] N. Littlestone. From on-line to batch learning. In Proceedings of the Second Annual Workshop
on Computational Learning Theory, COLT ’89, page 269–284, San Francisco, CA, USA, 1989.
Morgan Kaufmann Publishers Inc. doi: 10.1016/B978-0-08-094829-4.50022-2.
[42] L. Gretta and E. Price. An improved online reduction from PAC learning to mistake-bounded
learning. In 2023 Symposium on Simplicity in Algorithms (SOSA), pages 373–380, 2023. doi:
10.1137/1.9781611977585.ch34.
[43] N. Cesa-bianchi, A. Conconi, and C. Gentile. On the generalization ability of on-line learning
algorithms. In T. Dietterich, S. Becker, and Z. Ghahramani, editors, Advances in Neural
Information Processing Systems, volume 14. MIT Press, 2001.
62[44] N. Cesa-Bianchi, A. Conconi, and C. Gentile. On the generalization ability of on-line
learning algorithms. IEEE Transactions on Information Theory, 50(9):2050–2057, 2004. doi:
10.1109/TIT.2004.833339.
[45] A. L. Blum. Separating distribution-free and mistake-bound learning models over the Boolean
domain. SIAM Journal on Computing, 23(5):990–1000, 1994.
[46] E. Hazan. Introduction to online convex optimization. 2021. arXiv:1909.05207.
[47] H.-C.Cheng,M.-H.Hsieh,andP.-C.Yeh. Thelearnabilityofunknownquantummeasurements.
Quantum Information and Computation, 16(7), 2016.
[48] M.C.CaroandI.Datta.Pseudo-dimensionofquantumcircuits.QuantumMachineIntelligence,
2:14, 2020. doi: 10.1007/s42484-020-00027-5.
[49] C. M. Popescu. Learning bounds for quantum circuits in the agnostic setting. Quantum
Information Processing, 20(9):1–24, 2021.
[50] H. Cai, Q. Ye, and D.-L. Deng. Sample complexity of learning parametric quantum circuits.
Quantum Science and Technology, 7(2):025014, 2022.
[51] J. J. Wallman and J. Emerson. Noise tailoring for scalable quantum computation via
randomizedcompiling. Physical Review A,94:052325, 2016. doi: 10.1103/PhysRevA.94.052325.
[52] O. Regev. On lattices, learning with errors, random linear codes, and cryptography. Journal
of the ACM (JACM), 56(6):1–40, 2009. doi: 10.1145/1568318.1568324.
[53] P. Ananth, A. Poremba, and V. Vaikuntanathan. Revocable cryptography from learning
with errors. In Theory of Cryptography Conference, pages 93–122. Springer, 2023. doi:
10.1007/978-3-031-48624-1_4.
[54] D. Aggarwal, H. Bennett, Z. Brakerski, A. Golovnev, R. Kumar, Z. Li, S. Peters, N. Stephens-
Davidowitz, andV.Vaikuntanathan. Latticeproblems beyondpolynomialtime. InProceedings
of the 55th Annual ACM Symposium on Theory of Computing, pages 1516–1526, 2023. doi:
10.1145/3564246.3585227.
[55] C. Dwork, V. Feldman, M. Hardt, T. Pitassi, O. Reingold, and A. Roth. Preserving Statistical
Validity in Adaptive Data Analysis. In Proceedings of the Forty-Seventh Annual ACM
Symposium on Theory of Computing, STOC 2015, pages 117–126, New York, NY, USA, 2015.
Association for Computing Machinery. doi: 10.1145/2746539.2746580.
[56] R. Bassily, K. Nissim, A. Smith, T. Steinke, U. Stemmer, and J. Ullman. Algorithmic Stability
for Adaptive Data Analysis. SIAM Journal on Computing, 50(3):STOC16–377–STOC16–405,
2016. doi: 10.1137/16M1103646.
[57] G. Chiribella, G. Mauro D’Ariano, and P. Perinotti. Theoretical framework for quantum
networks. Physical Review A, 80:022339, 2009. doi: 10.1103/PhysRevA.80.022339.
[58] M. Born. Zur Quantenmechanik der Stoßvorgänge. Zeitschrift für Physik, 37:863–867, 1926.
63[59] M. Ziman. Process positive-operator-valued measure: A mathematical framework for the
description of process tomography experiments. Physical Review A, 77:062112, 2008. doi:
10.1103/PhysRevA.77.062112.
[60] G. Gutoski and J. Watrous. Toward a general theory of quantum games. In Proceedings of the
Thirty-NinthAnnualACMSymposiumonTheoryofComputing,STOC’07,pages565–574,New
York, NY, USA, 2007. Association for Computing Machinery. doi: 10.1145/1250790.1250873.
[61] F. A. Pollock, C. Rodríguez-Rosario, T. Frauenheim, M. Paternostro, and K. Modi. Non-
Markovian quantum processes: Complete framework and efficient characterization. Physical
Review A, 97:012127, 2018. doi: 10.1103/PhysRevA.97.012127.
[62] S. Milz and K. Modi. Quantum stochastic processes and quantum non-Markovian phenomena.
PRX Quantum, 2:030201, 2021. doi: 10.1103/PRXQuantum.2.030201.
[63] G. D. Berk, A. J. P. Garner, B. Yadin, K. Modi, and F. A. Pollock. Resource theories of
multi-time processes: A window into quantum non-Markovianity. Quantum, 5:435, 2021. ISSN
2521-327X. doi: 10.22331/q-2021-04-20-435.
[64] G. A. L. White, F. A. Pollock, L. C. L. Hollenberg, K. Modi, and C. D. Hill. Non-Markovian
quantum process tomography. PRX Quantum, 3:020344, 2022. doi: 10.1103/PRXQuantum.3.
020344.
[65] A. Abbas, R. King, H.-Y. Huang, W. J. Huggins, R. Movassagh, D. Gilboa, and J. McClean.
On quantum backpropagation, information reuse, and cheating measurement collapse. In
A. Oh, T. Neumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, editors, Advances in
Neural Information Processing Systems, volume 36, pages 44792–44819. Curran Associates,
Inc., 2023.
[66] C.-C. Chen, M. Watabe, K. Shiba, M. Sogabe, K. Sakamoto, and T. Sogabe. On the
expressibility and overfitting of quantum circuit learning. ACM Transactions on Quantum
Computing, 2(2):1–24, 2021. doi: 10.1145/3466797.
[67] Y. Du, Z. Tu, X. Yuan, and D. Tao. Efficient measure for the expressivity of variational
quantum algorithms. Physical Review Letters, 128(8):080506, 2022. doi: https://doi.org/10.
1103/PhysRevLett.128.080506.
[68] M. C. Caro, H.-Y. Huang, M. Cerezo, K. Sharma, A. Sornborger, L. Cincio, and P. J. Coles.
Generalization in quantum machine learning from few training data. Nature Communications,
13:4919, 2022. doi: 10.1038/s41467-022-32550-3.
[69] M. C. Caro, H.-Y. Huang, N. Ezzell, J. Gibbs, A. T. Sornborger, L. Cincio, P. J. Coles,
and Z. Holmes. Out-of-distribution generalization for learning quantum dynamics. Nature
Communications, 14:3751, 2023. doi: 10.1038/s41467-023-39381-w.
[70] K.-M. Chung and H.-H. Lin. Sample efficient algorithms for learning quantum channels in
PAC model and the approximate state discrimination problem. In Min-Hsiu Hsieh, editor,
16th Conference on the Theory of Quantum Computation, Communication and Cryptography
(TQC 2021), volume 197 of Leibniz International Proceedings in Informatics (LIPIcs), pages
3:1–3:22, Dagstuhl, Germany, 2021. Schloss Dagstuhl – Leibniz-Zentrum für Informatik.
64[71] M. C. Caro. Binary classification with classical instances and quantum labels. Quantum
Machine Intelligence, 3:18, 2021. doi: 10.1007/s42484-021-00043-z.
[72] M. Fanizza, Yihui Quek, and M. Rosati. Learning quantum processes without input control.
2022. arXiv:2211.05005.
[73] S. T Flammia and Joel J Wallman. Efficient estimation of Pauli channels. ACM Transactions
on Quantum Computing, 1(1):1–32, 2020. doi: 10.1145/3408039.
[74] S. T Flammia and R. O’Donnell. Pauli error estimation via population recovery. Quantum, 5:
549, 2021. doi: 10.22331/q-2021-09-23-549.
[75] O. Fawzi, A. Oufkir, and D. Stilck França. Lower bounds on learning Pauli channels. 2023.
arXiv:2301.09192.
[76] R. Harper, S. T. Flammia, and J. J. Wallman. Efficient learning of quantum noise. Nature
Physics, 16(12):1184–1188, 2020. doi: 10.1038/s41567-020-0992-8.
[77] C. Rouzé and D. S. França. Efficient learning of the structure and parameters of local Pauli
noise channels. 2023. arXiv:2307.02959.
[78] S. Chen, S. Zhou, A. Seif, and L. Jiang. Quantum advantages for Pauli channel estimation.
Physical Review A, 105(3):032435, 2022. doi: 10.1103/PhysRevA.105.032435.
[79] S. Chen, C. Oh, S. Zhou, H.-Y. Huang, and L. Jiang. Tight bounds on Pauli channel learning
without entanglement. 2023. arXiv:2309.13461.
[80] S. Chen and Weiyuan Gong. Futility and utility of a few ancillas for Pauli channel learning.
2023. arXiv:2309.14326v1.
[81] S. Chen and Weiyuan Gong. Efficient Pauli channel estimation with logarithmic quantum
memory. 2023. arXiv:2309.14326.
[82] A. Rakhlin, K. Sridharan, and A. Tewari. Online learning via sequential complexities. Journal
of Machine Learning Research, 16(6):155–186, 2015.
[83] A. Rakhlin, K. Sridharan, and A. Tewari. Sequential complexities and uniform martingale
laws of large numbers. Probability theory and related fields, 161:111–153, 2015. doi: 10.1007/
s00440-013-0545-5.
[84] S. Arora, E. Hazan, and S. Kale. The multiplicative weights update method: a meta-algorithm
and applications. Theory of Computing, 8(6):121–164, 2012. doi: 10.4086/toc.2012.v008a006.
[85] V. Lyubashevsky, C. Peikert, and O. Regev. On ideal lattices and learning with errors over
rings. In Advances in Cryptology–EUROCRYPT 2010: 29th Annual International Conference
on the Theory and Applications of Cryptographic Techniques, French Riviera, May 30–June 3,
2010. Proceedings 29, pages 1–23. Springer, 2010. doi: 10.1007/978-3-642-13190-5_1.
[86] G. Gutoski. On a measure of distance for quantum strategies. Journal of Mathematical
Physics, 53(3):032202, 2012. doi: 10.1063/1.3693621.
65[87] H.-Y. Huang, Yunchao Liu, M.Broughton, I.Kim, AnuragAnshu, Zeph Landau, andJarrodR
McClean. Learning shallow quantum circuits. 2024. arXiv:2401.10095.
[88] J. Haah, R. Kothari, and E. Tang. Optimal learning of quantum Hamiltonians from high-
temperatureGibbsstates. In2022 IEEE 63rd Annual Symposium on Foundations of Computer
Science (FOCS), pages 135–146. IEEE, 2022. doi: 10.1109/FOCS54457.2022.00020.
[89] Daniel Stilck França, Liubov A Markovich, VV Dobrovitski, Albert H Werner, and Johannes
Borregaard. Efficient and robust estimation of many-qubit hamiltonians. Nature Communica-
tions, 15(1):311, 2024. doi: 10.1038/s41467-023-44012-5.
[90] Andi Gu, Lukasz Cincio, and Patrick J Coles. Practical hamiltonian learning with
unitary dynamics and gibbs states. Nature Communications, 15(1):312, 2024. doi:
10.1038/s41467-023-44008-1.
[91] F. Wilde, A. Kshetrimayum, I. Roth, D. Hangleiter, R. Sweke, and J. Eisert. Scalably learning
quantum many-body Hamiltonians from dynamical data. 2022. arXiv:2209.14328.
[92] W. Yu, J. Sun, Z. Han, and X. Yuan. Robust and efficient Hamiltonian learning. Quantum, 7:
1045, 2023. ISSN 2521-327X. doi: 10.22331/q-2023-06-29-1045.
[93] H.-Y. Huang, Yu Tong, Di Fang, and Yuan Su. Learning many-body Hamiltonians with
Heisenberg-limited scaling. Physical Review Letters, 130(20):200403, 2023. doi: 10.1103/
PhysRevLett.130.200403.
[94] H. Li, Y. Tong, H. Ni, T. Gefen, and L. Ying. Heisenberg-limited Hamiltonian learning for
interacting bosons. 2023. arXiv:2307.04690.
[95] T. Möbus, A. Bluhm, M. C. Caro, A. H. Werner, and C. Rouzé. Dissipation-enabled bosonic
Hamiltonian learning via new information-propagation bounds. 2023. arXiv:2307.15026.
[96] J. Castaneda and N. Wiebe. Hamiltonian learning via shadow tomography of pseudo-Choi
states. 2023. arXiv:2308.13020.
[97] A.Bakshi,A.Liu,A.Moitra,andE.Tang. LearningquantumHamiltoniansatanytemperature
in polynomial time. 2023. arXiv:2310.02243.
[98] J. Haah, R. Kothari, and E. Tang. Learning quantum Hamiltonians from high-temperature
Gibbs states and real-time evolutions. Nature Physics, pages 1–5, 2024. doi: 10.1038/
s41567-023-02376-x.
[99] A. Bluhm, M. C. Caro, and A. Oufkir. Hamiltonian property testing. 2024. arXiv:2403.02968.
[100] Ainesh Bakshi, Allen Liu, Ankur Moitra, and Ewin Tang. Structure learning of Hamiltonians
from real-time evolution. 2024. URL https://arxiv.org/abs/2405.00082. arXiv preprint
arXiv:2405.00082.
[101] J. Watrous. The theory of quantum information. Cambridge University Press, 2018. doi:
10.1017/9781316848142.
66[102] W. Dür, M. Hein, J. I. Cirac, and H.-J. Briegel. Standard forms of noisy quantum operations
via depolarization. Physical Review A, 72:052326, 2005. doi: 10.1103/PhysRevA.72.052326.
[103] J. Burniston, M. Grabowecky, C. M. Scandolo, G. Chiribella, and G. Gour. Necessary
and sufficient conditions on measurements of quantum channels. Proceedings of the Royal
Society A: Mathematical, Physical and Engineering Sciences, 476(2236):20190832, 2020. doi:
10.1098/rspa.2019.0832.
[104] A. Y. Kitaev. Quantum computations: algorithms and error correction. Russian Mathematical
Surveys, 52(6):1191, 1997. doi: 10.1070/RM1997v052n06ABEH002155.
[105] G. Gutoski. Quantum strategies and local operations. PhD thesis, University of Waterloo,
2010. https://arxiv.org/abs/1003.0038.
[106] G. Chiribella, G. M. D’Ariano, and P. Perinotti. Quantum circuit architecture. Physical
Review Letters, 101:060401, 2008. doi: 10.1103/PhysRevLett.101.060401.
[107] A. Lowe. Learning Quantum States Without Entangled Measurements. Master’s thesis,
University of Waterloo, 2021.
[108] Y. Freund and R. E. Schapire. Adaptive Game Playing Using Multiplicative Weights. Games
and Economic Behavior, 29(1):79–103, 1999. ISSN 0899-8256.
[109] N. Littlestone and Manfred K Warmuth. The weighted majority algorithm. Information and
computation, 108(2):212–261, 1994. doi: 10.1006/inco.1994.1009.
[110] S. Arora and S. Kale. A Combinatorial, primal-dual approach to semidefinite programs. J.
ACM, 63(2), 2016. ISSN 0004-5411. doi: 10.1145/2837020.
[111] S.Arora,E.Hazan,andS.Kale. Fastalgorithmsforapproximatesemidefiniteprogramm.using
the multiplicative weights update method. In 46th Annual IEEE Symposium on Foundations
of Computer Science (FOCS’05), pages 339–348, 2005.
[112] R. Jain, Z. Ji, S. Upadhyay, and J. Watrous. QIP = PSPACE. Journal of the ACM, 58(6),
2011. ISSN 0004-5411.
[113] Koji Tsuda, Gunnar Rätsch, and Manfred K. Warmuth. Matrix exponentiated gradient
updates for on-line learning and Bregman projection. Journal of Machine Learning Research,
6(34):995–1018, 2005.
[114] Y. Freund and R. E. Schapire. A Decision-Theoretic Generalization of On-Line Learning and
an Application to Boosting. Journal of Computer and System Sciences, 55(1):119–139, 1997.
ISSN 0022-0000.
[115] D. Petz. Bregman divergence as relative operator entropy. Acta Mathematica Hungarica, 116:
127–131, 2007.
[116] F. G. S. L. Brandão, W. Chemissany, N. Hunter-Jones, R. Kueng, and J. Preskill. Models of
quantum complexity growth. PRX Quantum, 2:030316, 2021. doi: 10.1103/PRXQuantum.2.
030316.
67[117] J. Haferkamp, P. Faist, N. B. T. Kothakonda, J. Eisert, and N. Yunger Halpern. Linear
growth of quantum circuit complexity. 2021. arXiv:2106.05305.
[118] R. Vershynin. High-Dimensional Probability: An Introduction with Applications in Data
Science. Cambridge University Press, 2018. doi: 10.1017/9781108231596.
[119] S. Floyd and M. Warmuth. Sample compression, learnability, and the Vapnik-Chervonenkis
dimension. Machine learning, 21:269–304, 1995. doi: 10.1023/A:1022660318680.
[120] S. Hanneke, A. Kontorovich, and M. Sadigurschi. Sample compression for real-valued learners.
In A. Garivier and S. Kale, editors, Proceedings of the 30th International Conference on
Algorithmic Learning Theory, volume 98 of Proceedings of Machine Learning Research, pages
466–488. PMLR, 2019.
[121] J. D. Halpern and A. Levy. The ordering theorem does not imply the axiom of choice. Notices
of the American Mathematical Society, 11:56, 1964. doi: 10.1007/978-94-015-8988-8_4.
[122] J. D. Halpern and A. Levy. The Boolean prime ideal theorem does not imply the axiom of
choice. Axiomatic Set Theory, Proc. Sympos. Pure Math. 13, Part I, 83-134 (1971)., 1971.
[123] C. González. Dense orderings, partitions and weak forms of choice. Fundamenta Mathematicae,
147(1):11–25, 1995.
[124] A. A. Fraenkel and Y. Bar-Hillel. Foundations of Set Theory. Elsevier, Atlantic Highlands,
NJ, USA, 1973.
[125] V. N. Vapnik and A. Ya. Chervonenkis. On the uniform convergence of relative frequencies of
events to their probabilities. Theory of Probability & Its Applications, 16(2):264–280, 1971.
doi: 10.1137/1116025.
[126] O. Borisovich Lupanov. Ob odnom métodé sintéza shém (on a method of circuit synthesis).
Izvéstiá vysših učébnyh zavédénij, Radiofizika, 1:120–140, 1958.
[127] T. Toffoli. Reversible computing. In International colloquium on automata, languages, and
programming, pages 632–644. Springer, 1980. doi: 10.1007/3-540-10003-2_104.
[128] J. J. Vartiainen, M. Möttönen, and M. M. Salomaa. Efficient decomposition of quantum gates.
Physical Review Letters, 92(17):177902, 2004. doi: 10.1103/PhysRevLett.92.177902.
[129] M.Möttönen, J.J.Vartiainen, V.Bergholm, andM.M.Salomaa. Quantumcircuitsforgeneral
multiqubit gates. Physical Review Letters, 93(13):130502, 2004. doi: 10.1103/PhysRevLett.93.
130502.
[130] V. V. Shende, S. S Bullock, and I. L. Markov. Synthesis of quantum logic circuits. In
Proceedings of the 2005 Asia and South Pacific Design Automation Conference, pages 272–275,
2005. doi: 10.1145/1120725.1120847.
[131] A. A. Mele and Y. Herasymenko. Efficient learning of quantum states prepared with few
fermionic non-gaussian gates. 2024. arXiv:2402.18665.
68[132] O. Goldreich, S. Goldwasser, and S. Micali. How to construct random functions. Journal of
the ACM (JACM), 33(4):792–807, 1986.
[133] A. Banerjee, C. Peikert, and A. Rosen. Pseudorandom functions and lattices. In Annual
International Conference on the Theory and Applications of Cryptographic Techniques, pages
719–737. Springer, 2012. doi: 10.1007/978-3-642-29011-4_42.
[134] S.Arunachalam,A.B.Grilo,andA.Sundaram. Quantumhardnessoflearningshallowclassical
circuits. SIAM Journal on Computing, 50(3):972–1013, 2021. doi: 10.1137/20M1344202.
[135] J. Watrous. Semidefinite programs for completely bounded norms. Theory of Computing, 5:
217–238, 2009. doi: 10.4086/toc.2009.v005a011.
[136] R. R. Tucci. Quantum Bayesian nets. International Journal of Modern Physics B, 09(03):
295–337, 1995. doi: 10.1142/S0217979295000148.
[137] D. Beckman, Daniel Gottesman, M. A. Nielsen, and J. Preskill. Causal and localizable
quantum operations. Physical Review A, 64:052309, 2001. doi: 10.1103/PhysRevA.64.052309.
[138] T. Eggeling, D. Schlingemann, and R. F. Werner. Semicausal operations are semilocalizable.
Europhysics Letters, 57(6):782, 2002. doi: 10.1209/epl/i2002-00579-4.
[139] O. Oreshkov, F. Costa, and C. Brukner. Quantum correlations with no causal order. Nature
Communications, 3:1092, 2012.
[140] F. Costa and S. Shrapnel. Quantum causal modelling. New Journal of Physics, 18(6):063032,
2016. doi: 10.1088/1367-2630/18/6/063032.
[141] J.-M. A. Allen, J. Barrett, D. C. Horsman, C. M. Lee, and R. W. Spekkens. Quantum
common causes and quantum causal models. Physical Review X, 7:031021, 2017. doi:
10.1103/PhysRevX.7.031021.
[142] D. Kretschmann and R. F. Werner. Quantum channels with memory. Physical Review A, 72:
062323, 2005.
[143] Y. Aharonov, S. Popescu, J. Tollaksen, and L. Vaidman. Multiple-time states and multiple-
time measurements in quantum mechanics. Physical Review A, 79:052110, 2009. doi: 10.1103/
PhysRevA.79.052110.
[144] I. S. Dhillon and J. A. Tropp. Matrix Nearness Problems with Bregman Divergences. SIAM
Journal on Matrix Analysis and Applications, 29(4):1120–1146, 2008.
A From qubits to qudits
Although all of our results have been phrased for n-qubit systems and channels, they apply equally
well to qudit systems and qudit channels. This essentially amounts to replacing all of the Pauli
69operators Pz,x with the Heisenberg–Weyl operators, sometimes known as the qudit/generalized Pauli
operators. These operators are defined as [101]
Wz,x := Z(z)X(x), z,x ∈ {0,1,...,d−1}, (A.1)
d−1
Z(z) := Xe2π dikz |k⟩⟨k|,
k=0
d−1
X(x) := X |k+x⟩⟨k|,
k=0
where the addition in the definition of X(x) is performed modulo d, with d ∈ {2,3,...}. These
operators are unitary and orthogonal, i.e.,
(Wz,x)†Wz,x = Wz,x(Wz,x)† = 1, ⟨Wz,x,Wz′,x′ ⟩ = dδ δ , (A.2)
z,z′ x,x′
for z,x,z′,x′ ∈ {0,1,...,d−1}. Consequently, they form a basis for the vector space L(Cd) of linear
operators acting on Cd. The qudit Bell states are then defined as
1 d−1
Φz,x := |Φz,x⟩⟨Φz,x|, |Φz,x⟩ := (1 ⊗Wz,x)|Φ⟩, |Φ⟩ = √ X |k,k⟩. (A.3)
d
d
k=0
The qudit Bell state vectors |Φz,x⟩ form an orthonormal basis for Cd⊗Cd, and the qudit Bell states
Φz,x form a POVM, meaning that Pd−1 Φz,x = 1 ⊗1 .
z,x=0 d d
The qudit/generalized Pauli channels are defined analogously to n-qubit Pauli channels as
d−1
N(ρ) = X p(z,x)Wz,xρWz,x†, (A.4)
z,x=0
where p(z,x) ∈ [0,1] and Pd−1 p(z,x) = 1. The Choi representations of these channels have the
z,x=0
form
d−1
C(N) = X p(z,x)Γz,x, Γz,x := (1 ⊗Wz,x)|Γ⟩⟨Γ|(1 ⊗Wz,x)†. (A.5)
d d
z,x=0
It follows from this (and using orthonormality of the Bell states) that the error rates p(z,x) can be
obtained as
1
p(z,x) = Tr[Φz,xC(N)], (A.6)
d
for all z,x ∈ {0,1,...,d−1}. In other words, we can recover the error rates by performing the
qudit Bell basis measurement on the Choi state 1C(N) of the channel. Conversely, every positive
d
semi-definite bipartite operator Y ∈ L(Cd⊗Cd) of the form (A.5) corresponds to a Pauli channel
with error rates gives by p(z,x) = 1Tr[Φz,xY] for all z,x ∈ {0,1,...,d−1}.
d
For a quantum channel N : L(Cd) → L(Cd), d ∈ {2,3,...}, we define its (qudit) Pauli-twirled
version as
1 d−1
NW(ρ) = X Wz,x†N(Wz,xρWz,x†)Wz,x, (A.7)
d2
z,x=0
where the superscript “W” in NW refers to the set W := {Wz,x : z,x ∈ {0,1,...,d−1}} of qudit
Pauli operators. In Proposition 59, we show that the twirled channel NW is indeed a Pauli channel.
701
B1 A2
2
B2 A3
3
B3 A4
4
A1 N N N N B4
M1 M2 M3
B1
A1 1
N B2
M1 2
A2 N B3
M2 3
A3 N
M3 4 B4
A4 N
Figure 5: (Top) A multi-time quantum process with r = 4 time steps. The input systems
are A ,...,A , the output systems are B ,...,B , and the memory systems are M ,M ,M .
1 4 1 4 1 2 3
(Bottom) Every multi-time process is associated with the channel N[r], obtained by collapsing
the causal ordering of the inputs and outputs.
B Multi-time quantum processes
In this section, we provide some background on multi-time quantum processes. Such objects are also
known as “quantum strategies” [60] and “quantum combs” [57], and they also constitute specific
examples of quantum causal networks [57, 136–141] and quantum channels with memory [142]. They
also provide a model for discrete-time non-Markovian quantum stochastic processes [61, 62], and it
is in this context that they are known as “multi-time quantum processes”—see also Refs. [63, 143].
B.1 Definitions and basic properties
A general multi-time process is depicted in Figure 5 (top) as the comb object in blue with r = 4
time steps. The input systems are A ,A ,...,A , the output systems are B ,B ,...,B , and the
1 2 r 1 2 r
memory systems are M ,M ,...,M . Every multi-time process is associated with a quantum
1 2 r−1
channel N[r] : L(H ⊗H ⊗···⊗H ) → L(H ⊗H ⊗···⊗H ), defined by concatenating
A1 A2 Ar B1 B2 Br
the maps Ni in the manner shown in Figure 5 (bottom). As shown in Refs. [57, 60], due to the
causal constraints, the Choi representation of the channel N[r], which completely characterizes the
multi-time process, is in one-to-one correspondence with a set of so-called comb operators, which
have a very specific structure based on the causal ordering of the individual elements of the process.
Definition 51 (Comboperatorformulti-timequantumprocess). Everymulti-timequantumprocess
with r ∈ N time steps, as depicted in Figure 5, is represented by a positive semi-definite comb
operator N , defined to be the Choi representation of the quantum channel associated with the
r
process (see Figure 5). For every comb operator N , there exist positive semi-definite operators
r
N ∈ L(H(k) ), k ∈ {1,2,...,r−1}, such that the following constraints are satisfied:
k A,B
N ≥ 0, Tr [N ] = N ⊗1 , (B.1)
r Br r r−1 Ar
N ≥ 0, Tr [N ] = N ⊗1 , k ∈ {2,3,...,r−1}, (B.2)
k B k k k−1 A k
N ≥ 0, Tr [N ] = 1 . (B.3)
1 B1 1 A1
71A positive semi-definite operator P ∈ L(H(r) ) is the comb operator of an r-step multi-time quantum
A,B
process with input systems A ,...,A and output systems B ,...,B if and only if there exists a set
1 r 1 r
{N }r of positive semi-definite operators such that P = N and the constraints in (B.1)–(B.3) are
k k=1 r
satisfied. We let COMB (A ,...,A ;B ,...B ) denote the convex set of all operators in L(H(r) )
r 1 r 1 r A,B
representing r-step multi-time quantum processes with input systems A ,...,A and output systems
1 r
B ,...,B . ◀
1 r
To understand Definition 51, let us see how the constraints on the comb operators in (B.1)–(B.3)
are manifested in the Choi representation of the channel N[4] depicted in Figure 5 (bottom). By
definition, we have
(cid:16)
N ≡ C(N[4]) = N4 ◦N3
4 M3A′ 4→B4 M2A′ 3→M3B3
(cid:17)
◦N2 ◦N1 (Γ ⊗Γ ⊗Γ ⊗Γ ). (B.4)
M1A′ 2→M2B2 A′ 1→M1B1 A1A′
1
A2A′
2
A3A′
3
A4A′
4
It is clear that N ∈ L(H(4) is positive semi-definite. Now, observe that
4 A,B
Tr [N ]
B4 4
h(cid:16) (cid:17) i
= Tr N3 ◦N2 ◦N1 (Γ ⊗Γ ⊗Γ ⊗Γ )
M3A′
4
M2A′ 3→M3B3 M1A′ 2→M2B2 A′ 1→M1B1 A1A′
1
A2A′
2
A3A′
3
A4A′
4
(B.5)
h(cid:16) (cid:17) i
= Tr N3 ◦N2 ◦N1 (Γ ⊗Γ ⊗Γ ) ⊗Tr [Γ ]
M3 M2A′ 3→M3B3 M1A′ 2→M2B2 A′ 1→M1B1 A1A′
1
A2A′
2
A3A′
3
A′
4
A4A′
4
| {z }
1
A4
= N ⊗1 ,
3 A4
which is precisely the constraint in (B.1), where in the last line we let
h(cid:16) (cid:17) i
N ≡ Tr N3 ◦N2 ◦N1 (Γ ⊗Γ ⊗Γ ) . (B.6)
3 M3 M2A′ 3→M3B3 M1A′ 2→M2B2 A′ 1→M1B1 A1A′
1
A2A′
2
A3A′
3
In a similar manner, we find that
Tr [N ] = N ⊗1 , (B.7)
B3 3 2 A3
h(cid:16) (cid:17) i
N := Tr N2 ◦N1 (Γ ⊗Γ ) , (B.8)
2 M2 M1A′ 2→M2B2 A′ 1→M1B1 A1A′
1
A2A′
2
Tr [N ] = N ⊗1 , (B.9)
B2 2 1 A2
h(cid:16) (cid:17) i
N := Tr N1 (Γ ) , (B.10)
1 M1 A′ 1→M1B1 A1A′
1
Tr [N ] = 1 , (B.11)
B1 1 A1
which reproduces the constraints in (B.2) and (B.3).
We can also consider a multi-time process with a measurement in the final time step, sometimes
called a “measuring strategy”.
Definition 52 (Comb operators for multi-time quantum process with measurement). Every multi-
time quantum process with measurement, consisting of r ∈ N time steps and input systems
72R1 R2 R3 R4
ρ 1 2 3 Mx
x
1 B1 E A2 2 B2 E A3 3 B3 E A4 4 { }
A1 N N N N B4
M1 M2 M3
Figure 6: Concatenationofamulti-timeprocessN[4] withr =4timesteps, representedbythe
blue quantum comb, with a corresponding tester E[4], which is represented by the red quantum
comb. The operations Ni and Ei can be arbitrary quantum channels, and they can also more
generally be arbitrary Hermiticity-preserving maps.
A ,...,A and output systems B ,...,B , is represented by a set {N } of positive semi-definite
1 r 1 r r;x x
operators N ∈ L(H(r) ), such that P N ∈ COMB (A ,...,A ;B ,...,B ). A finite set
r;x A,B x r;x r 1 r 1 r
{S } of positive semi-definite operators in L(H(r) ) defines an r-step multi-time quantum process
x x A,B
with measurement, with input systems A ,...,A and output systems B ,...,B , if and only if
1 r 1 r
P S ∈ COMB (A ,...,A ;B ,...,B ). ◀
x x r 1 r 1 r
A measurement, or tester, for a multi-time process is another multi-time process that consists
of an input state ρ in the first time step and a measurement in the final time step, as shown by
the red comb object in Figure 6 for r = 4 time steps. Testers are sometimes called “measuring
co-strategies”.
Definition 53 (Comb operators for multi-time quantum tester). Every multi-time quantum tester
withr ∈ Ntimesteps,consistingofinputsystemsB ,...,B andoutputsystemsA ,...,A ,isrepre-
1 r 1 r
sentedbyaset{E } ofpositivesemi-definiteoperators,withE ∈ L(H(r) ),suchthatP E =
r;x x r;x A,B x r;x
S ⊗1 , with S ∈ COMB∗(A ,...,A ;B ,...,B ). Here, COMB∗(A ,...,A ;B ,...,B ) :=
r Br r r 1 r 1 r−1 r 1 r 1 r−1
COMB (∅,B ,...,B ;A ,...,A ) is the set of all multi-time processes in which the first input
r 1 r−1 1 r
system is trivial; see (2.29). A finite set {T } of positive semi-definite operators in L(H(r) ) defines
x x A,B
an r-step multi-time quantum tester, with input systems B ,...,B and output systems A ,...,A ,
1 r 1 r
if and only if there exists E ∈ COMB∗(A ,...,A ;B ,...,B ) such that P T = E ⊗1 . ◀
r r 1 r 1 r−1 x x r Br
B.2 Norms
Norms for multi-time quantum processes have been defined in Refs. [86, 106]. Here, we follow the
presentation in Ref. [86].
Definition 54 (Strategy norm and its dual [86]). Let r ∈ N. For every Hermitian operator
H ∈ L(H(r) ), we define the strategy norm ∥H∥ and its dual ∥H∥∗ as
A,B ⋄r ⋄r
n o
∥H∥ := sup Tr[H(T −T )] : T ,T ≥ 0, T +T = S ⊗1 , S ∈ COMB∗ (B.12)
⋄r 0 1 0 1 0 1 Br r
n o
= inf t : t ≥ 0, −tN ≤ H ≤ tN, N ∈ COMB , (B.13)
r
n o
∥H∥∗ := sup Tr[H(N −N )] : N ,N ≥ 0, N +N ∈ COMB (B.14)
⋄r 0 1 0 1 0 1 r
n o
= inf t : t ≥ 0, −tS ⊗1 ≤ H ≤ tS ⊗1 , S ∈ COMB∗ .
Br Br r
73For every Hermiticity-preserving linear map N[r] : L(H ⊗···⊗H ) → L(H ⊗···⊗H ), in
A1 Ar B1 Br
particular those corresponding to multi-time processes, its strategy r-norm is defined via the Choi
representation as ∥N[r]∥ := ∥C(N[r])∥ . ◀
⋄r ⋄r
The norms ∥·∥ and ∥·∥∗ are (Hölder) dual to each other, and the proof of this can be found
⋄r ⋄r
in Ref. [86]. These norms should be thought of as generalizations of the trace norm and its dual
(the spectral/operator norm) for quantum states and the diamond norm and its dual for quantum
channels. Indeed, with respect to Figure 6, in the case r = 1 and d = 1, it holds that ∥·∥ ≡ ∥·∥
A1 ⋄1 1
and ∥·∥∗ ≡ ∥·∥ , where we note that
⋄1 ∞
n o
∥H∥ = sup Tr[H(M −M )] : M ,M ≥ 0, M ≥ 0, M +M ≤ 1 (B.15)
1 1 2 1 2 2 1 2
n o
= inf t : t ≥ 0, −tσ ≤ H ≤ tσ, σ ≥ 0,Tr[σ] = 1 , (B.16)
n o
∥H∥ = sup Tr[H(M −M )] : M ,M ≥ 0, Tr[M +M ] ≤ 1 (B.17)
∞ 1 2 1 2 1 2
n o
= inf t : t ≥ 0,−t1 ≤ H ≤ t1 , (B.18)
for every Hermitian operator H. Similarly, in the case r = 1 and arbitrary dimension for the
system A , we have that ∥·∥ ≡ ∥·∥ . The norm ∥·∥∗ , i.e., the Hölder dual to the diamond norm,
1 ⋄1 ⋄ ⋄1
has been considered before in Ref. [105, Section 5.3]. This dual norm is the relevant norm when
considering observables for quantum channels, analogous to the role that the spectral norm ∥·∥
∞
has for observables for states. Using (B.14), it is straightforward to see that the diamond norm
dual is given by the following primal-dual pair of semi-definite programs, where H ∈ L(H ⊗H )
A B
is Hermitian:
n o
∥H∥∗ := sup Tr[H(S −S )] : S ,S ∈ L(H ⊗H ), S ,S ≥ 0, Tr [S +S ] ≤ 1 (B.19)
⋄1 0 1 0 1 A B 0 1 B 0 1 A
n o
= inf Tr[Y] : Y ∈ L(H ), Y ≥ 0, −Y ⊗1 ≤ H ≤ Y ⊗1 . (B.20)
A B B
We now show that this norm is multiplicative for tensor-product operators, which is a relevant
property when considering channel observables without memory; see Section 2.1 for the relevant
background information.
Lemma 55 (Diamond norm dual for tensor-product operators). Let K ∈ L(H ) and L ∈ L(H )
A B
be Hermitian operators. It holds that ∥K ⊗L∥∗ = ∥K∥ ∥L∥ .
⋄1 1 ∞
Proof. This follows straightforwardly from semi-definite programming duality. Let M ,M ∈ L(H )
1 2 A
be the operators achieving the trace norm ∥K∥ , as in (B.15), and let M′,M′ ∈ L(H ) be the
1 1 2 B
operators achieving the spectral norm ∥L∥ , as in (B.17). Then, S ≡ M ⊗M′ +M ⊗M′ and
∞ 0 1 1 2 2
S ≡ M ⊗M′ +M ⊗M′ are readily verified to be feasible points in the SDP (B.19), which means
1 1 2 2 1
that ∥K ⊗L∥∗ ≥ Tr[(K ⊗L)(S −S )] = ∥K∥ ∥L∥ . For the reverse inequality, observe that
⋄1 0 1 1 ∞
Y ≡ Z∥L∥ , where Z ∈ L(H ) achieves the trace norm ∥K∥ according to (B.16), is a feasible point
∞ A 1
intheSDP(B.20). Consequently,whichthischoiceofY,weobtain∥K⊗L∥∗ ≤ Tr[Y] = ∥K∥ ∥L∥ .
⋄1 1 ∞
This completes the proof. ■
74Let N be the comb operator of a multi-time process with r time steps, and let N be the comb
1 1 2
operator of a multi-time process with r time steps, such that both processes have some compatible
2
input and output Hilbert spaces. The multi-time process resulting from the composition of the two
processes is represented by the comb operator N ⋆N , where ⋆ represents the link product [57].
1 2
Just as the diamond norm is submultiplicative with respect to composition of linear maps, so too
is the strategy norm submultiplicative with respect to concatenation of comb operators according to
the link product. We prove this in our next result.
Proposition 56 (Submultiplicativity of the strategy norm). Let N be the representation of a
1
multi-time process with r time steps, and let N be the representation of a multi-time process with
1 2
r time steps. Suppose that the composition of these processes, represented by N ⋆N , produces a
2 1 2
multi-time process with r time steps. Then, it holds that
∥N ⋆N ∥ ≤ ∥N ∥ ∥N ∥ . (B.21)
1 2 ⋄r 1 ⋄r1 2 ⋄r2
Proof. This result follows straightforwardly from semi-definite programming duality. In particular,
we make use of (B.13), which we restate here for convenience as
n o
∥H∥ = inf t : t ≥ 0, −tP ≤ H ≤ tP, P ∈ COMB . (B.22)
⋄r r
Now, let (t ,P ) and (t ,P ) be the optimal feasible points corresponding to ∥N ∥ and ∥N ∥ ,
1 1 2 2 1 ⋄r1 2 ⋄r2
respectively, meaning that t = ∥N ∥ and t = ∥N ∥ . We now show that (t t ,P ⋆ P )
1 1 ⋄r1 2 2 ⋄r2 1 2 1 2
constitutes a feasible point in the SDP in (B.22) for ∥N ⋆N ∥ , implying the desired result.
1 2 ⋄r
By definition, we have
−t P ≤N ≤ t P , (B.23)
1 1 1 1 1
−t P ≤N ≤ t P . (B.24)
2 2 2 2 2
The right-most inequalities can be rewritten as t P − N ≥ 0 and t P − N ≥ 0. Using the
1 1 1 2 2 2
fact that the link product of positive semi-definite operators is positive semi-definite (see Ref. [57,
Theorem 2]), we obtain (t P −N )⋆(t P −N ) ≥ 0. Expanding the left-hand side of this inequality,
1 1 1 2 2 2
we have
t t P ⋆P −t P ⋆N −t N ⋆P +N ⋆N ≥ 0 (B.25)
1 2 1 2 1 1 2 2 1 2 1 2
⇒t t P ⋆P +N ⋆N ≥ t P ⋆N +t N ⋆P ≥ 0 (B.26)
1 2 1 2 1 2 1 1 2 2 1 2
⇒N ⋆N ≥ −t t P ⋆P . (B.27)
1 2 1 2 1 2
Similarly, we have
N +t P ≥ 0, t P −N ≥ 0 (B.28)
1 1 1 2 2 2
⇒(N +t P )⋆(t P −N ) ≥ 0 (B.29)
1 1 1 2 2 2
⇒ −N ⋆N +t t P ⋆P ≥ t P ⋆N −t N ⋆P , (B.30)
1 2 1 2 1 2 1 1 2 2 1 2
t P −N ≥ 0, N +t P ≥ 0 (B.31)
1 1 1 2 2 2
⇒(t P −N )⋆(N +t P ) ≥ 0 (B.32)
1 1 1 2 2 2
75⇒ −N ⋆N +t t P ⋆P ≥ t N ⋆P −t P ⋆N . (B.33)
1 2 1 2 1 2 2 1 2 1 1 2
Adding the inequalities in (B.30) and (B.33), we obtain
−N ⋆N +t t P ⋆P ≥ 0 ⇒ N ⋆N ≤ t t P ⋆P . (B.34)
1 2 1 2 1 2 1 2 1 2 1 2
As P ⋆P is positive semi-definite and defines a multi-time process with r steps, we conclude that
1 2
(t t ,P ⋆P ) is a feasible point in the SDP in (B.22) for ∥N ⋆N ∥ , which implies the desired
1 2 1 2 1 2 ⋄r
result. ■
Corollary 57 (Subadditivity of the strategy norm under composition). Let N ,M be representa-
1 1
tions of multi-time processes with r time steps, and let N ,M be representations of multi-time
1 2 2
processeswithr timesteps. SupposethatthecompositionofN withN andM withM produces
2 1 2 1 2
multi-time processes with r time steps. Then,
∥N ⋆N −M ⋆M ∥ ≤ ∥N −M ∥ +∥N −M ∥ . (B.35)
1 2 1 2 ⋄r 1 1 ⋄r1 2 2 ⋄r2
Proof. By the triangle inequality, and making use of Proposition 56, we have
∥N ⋆N −M ⋆M ∥ = ∥N ⋆N −N ⋆M +N ⋆M −M ⋆M ∥ (B.36)
1 2 1 2 ⋄r 1 2 1 2 1 2 1 2 ⋄r
≤ ∥N ⋆N −N ⋆M ∥ +∥N ⋆M −M ⋆M ∥
1 2 1 2 ⋄r 1 2 1 2 ⋄r
= ∥N ⋆(N −M )∥ +∥(N −M )⋆M ∥
1 2 2 ⋄r 1 1 2 ⋄r
≤ ∥N −M ∥ +∥N −M ∥ ,
2 2 ⋄r2 1 1 ⋄r1
as required. Here, the last step used Proposition 56 together with the fact that ∥N ∥ ,∥M ∥ ≤ 1.
1 r1 2 r2
The latter can for example easily be seen from Equation (B.22). ■
C Pauli-twirl of quantum channels
In this section, we prove (2.18), and thereby prove that the error-rate vector of the Pauli-twirled
version of an arbitrary quantum channel N : L(Cd) → L(Cd), d ∈ {2,3,...}, is given by p(z,x) =
1Tr[Φz,xC(N)] for all z,x ∈ {0,1,...,d−1}. For generality, we prove the result in terms of qudit
d
Pauli channels (see Appendix A), but an analogous proof to the one we present holds when the
qudit Pauli operators are replaced by the n-qubit Pauli operators.
Lemma 58. For every qudit quantum channel N : L(Cd) → L(Cd), d ∈ {2,3,...}, the Choi
representation of its Pauli-twirled version NW, as defined in (A.7), is given by
1 d−1
C(NW) = X (Wz,x⊗Wz,x)†C(N)(Wz,x⊗Wz,x). (C.1)
d2
z,x=0
Proof. By definition of the Choi representation, we have
C(NW) = (id ⊗NW)(|Γ⟩⟨Γ|) (C.2)
d
761 d−1
= X (1 ⊗Wz,x†)(id ⊗N)(cid:16) (1 ⊗Wz,x)|Γ⟩⟨Γ|(1 ⊗Wz,x)†(cid:17) (1 ⊗Wz,x)
d2 d d d d d
z,x=0
1 d−1
= X (1 ⊗Wz,x†)(id ⊗N)(cid:16) (Wz,xT⊗1 )|Γ⟩⟨Γ|(Wz,xT⊗1 )†(cid:17) (1 ⊗Wz,x)
d2 d d d d d
z,x=0
1 d−1
= X (Wz,xT⊗Wz,x†)C(N)(Wz,x⊗Wz,x)
d2
z,x=0
1 d−1
= X (Wz,x⊗Wz,x)†C(N)(Wz,x⊗Wz,x),
d2
z,x=0
asrequired,whereforthethirdequalitywehaveusedthe“transposetrick”(1 ⊗X)|Γ⟩ = (XT⊗1 )|Γ⟩,
d d
which holds for every linear operator X ∈ L(Cd). ■
Proposition 59. Let X ∈ L(Cd⊗Cd), d ∈ {2,3,...}, and define S to be the pinching channel in
W
the qudit Bell basis:
d−1
S (X) := X |Φz,x⟩⟨Φz,x|X|Φz,x⟩⟨Φz,x|. (C.3)
W
z,x=0
It holds that
1 d−1
S (X) = X (Wz,x⊗Wz,x)†X(Wz,x⊗Wz,x). (C.4)
W d2
z,x=0
Consequently, for every channel N : L(Cd) → L(Cd), the Choi representation of its Pauli-twirled
version NW, defined in (A.7), is given by C(NW) = S (C(N)). Furthermore, the corresponding
W
error-rate vector of the Pauli-twirled channel is given by p(z,x) = 1Tr[Φz,xC(N)] for all z,x ∈
d
{0,1,...,d−1}.
Proof. We make repeated use of the following facts about the qudit Pauli operators [101]:
Wz,x† = e−2π dizx W−z,−x, (C.5)
Wz,xT = e2π dizx Wz,−x, (C.6)
Wz,xWz′,x′ = e−2πi dxz′ Wz+z′,x+x′ , (C.7)
which hold for all choices of z,x,z′,x′ ∈ {0,1,...,d−1}. Now, let us start by showing that
1 d−1
Φz,x = X e2 dπi(x′z−xz′)Wz′,x′ ⊗Wz′,x′ , (C.8)
d2
z′,x′=0
for all z,x ∈ {0,1,...,d−1}. To show this, we use the definition of Φz,x in (A.3), the properties
in (C.5)–(C.7), and the fact that the operators {Wz 1′,x′ 1 ⊗Wz 2′,x′ 2 : z 1′,x′ 1,z 2′,x′ 2 ∈ {0,1,...,d−1}}
form a basis for L(Cd⊗Cd),
(cid:20)(cid:16) (cid:17)† (cid:21)
Tr Wz 1′,x′
1
⊗Wz 2′,x′
2
Φz,x (C.9)
771
h i
= Tr (Wz 1′,x′
1
⊗Wz 2′,x′ 2)†(1 d⊗Wz,x)|Γ⟩⟨Γ|(1 d⊗Wz,x†)
d
1
h i
= Tr Wz,x†Wz 2′,x′ 2†Wz,xWz 1′,x′
1
d
=
1 Tr(cid:20)(cid:16)
Wz 2′,x′
2Wz,x(cid:17)†
Wz,xWz 1′,x′
1(cid:21)
d
= 1 e2 dπi(x′ 2z−xz 1′)Tr(cid:20)(cid:16) Wz 2′+z,x′ 2+x(cid:17)† Wz+z 1′,x+x′ 1(cid:21)
d
| {z }
dδ z′+z,z+z′δ x′+x,x+x′
2 1 2 1
= e2 dπi(x′ 2z−xz 1′)δ z′,z′δ x′,x′.
2 1 2 1
Therefore, using (C.8), along with the properties in (C.5)–(C.7) once more, we obtain
d−1
S (X) = X Φz,xXΦz,x (C.10)
W
z,x=0
1 d−1 d−1 d−1
= X X X (cid:16) e2 dπi(−xz 1′+x′ 1z)Wz 1′,x′
1
⊗Wz 1′,x′ 1(cid:17) X(cid:16) e2 dπi(−xz 2′+x′ 2z)Wz 2′,x′
2
⊗Wz 2′,x′ 2(cid:17)
d4
z,x=0z′,x′=0z′,x′=0
1 1 2 2
1 d−1 d−1 d−1 ! d−1 !
= X X Xe−2 dπix(z 1′+z 2′) Xe2 dπiz(x′ 1+x′ 2) (Wz 1′,x′
1
⊗Wz 1′,x′ 1)X(Wz 2′,x′
2
⊗Wz 2′,x′ 2)
d4
z′,x′=0z′,x′=0 x=0 z=0
1 1 2 2 | {z }| {z }
dδ z′,−z′ dδ x′,−x′
1 2 1 2
1 d−1
= X (W−z,−x⊗W−z,−x)X(Wz,x⊗Wz,x)
d2
z,x=0
1 d−1
= X e2π dizx(Wz,−x⊗Wz,x†)X(Wz,x⊗Wz,x) (C.11)
d2
z,x=0
1 d−1
= X e2π dizxe−2π dizx(Wz,xT⊗Wz,x†)X(Wz,x⊗Wz,x)
d2
z,x=0
1 d−1
= X (Wz,x⊗Wz,x)†X(Wz,x⊗Wz,x),
d2
z,x=0
which proves (C.3). Then, if X ≡ C(N) is the Choi representation of a quantum channel N :
L(Cd) → L(Cd), using Lemma 58 we see that C(NW) = S (C(N)) = Pd−1 Tr[Φz,xC(N)]Φz,x =
W z,x=0
Pd−1 1Tr[Φz,xC(N)]Γz,x. By identifying with (A.5), we can see that the twirled channel is
z,x=0 d
indeed a Pauli channel, and using (A.6), we see that the error-rate vector of the twirled channel is
p(z,x) = 1Tr[Φz,xC(N)] for all z,x ∈ {0,1,...,d−1}. This completes the proof. ■
d
D Entropic analysis of the MMW algorithm
Inthissection,weprovideanentropicanalysisofthematrix multiplicative weights (MMW)algorithm
(Algorithm 2 and its projected variant for Choi states (Algorithm 3). We note that an entropic
78analysissimilartotheoneweprovideherecanbefoundinRef.[84,Theorem2.4]forthemultiplicative
weights update (MWU) algorithm. On it highest level, the MMW algorithm assigns initial weights
to experts iteratively updates these weights multiplicatively according to the feedback on how well
the expert has performed. It is known as a method for highly efficiently solve convex optimization
problems.
We start with a proof of Proposition 14. The bound we obtain applies also to the Hedge
algorithm (Algorithm 5 below), which is a special case of the MMW algorithm (Algorithm 2) when
the loss matrices L(t) of the MMW algorithm are all diagonal in the same basis, such that the
diagonal elements of L(t) constitute the loss vector m(t) in the Hedge algorithm. The bound we
obtain for the Hedge algorithm is in general tighter than the one obtained in Ref. [84, Theorem 2.3].
Algorithm 5 The Hedge algorithm [84, 114]
Require: 0 < η ≤ 1; Initialize w(1) = 1
1: for t = 1,2,...T do
2:
Output the decision/estimate p(t) = w(t) .
Tr[w(t)]
3: Receive the cost vector −1 ≤ m(t) ≤ 1 (element-wise inequalities).
4:
Update the weights as w(t+1) = w(t)e−ηm(t) (element-wise multiplication).
5: end for
D.1 Proof of Proposition 14
We start by noticing that in the proof of [110, Theorem 3.1], the inequality
Tr[W(t+1)] ≤ Tr[W(t)]e−ηTr[L(t)ω(t)]+η2Tr[(L(t))2ω(t)] (D.1)
can be written as
Tr[W(t+1)]
≤ e−ηTr[L(t)ω(t)]+η2Tr[(L(t))2ω(t)]. (D.2)
Tr[W(t)]
Taking the logarithm on both sides leads to
logTr[W(t+1)]−logTr[W(t)] ≤ −ηTr[L(t)ω(t)]+η2Tr[(L(t))2ω(t)]. (D.3)
Applying (D.3) recursively leads to
logTr[W(T+1)]−logTr[W(1)] = logTr[W(T+1)]−logTr[W(T)]
+logTr[W(T)]−logTr[W(T−1)]+···−logTr[W(2)]
+logTr[W(2)]−logTr[W(1)] (D.4)
T
≤
X(cid:16) −ηTr[L(t)ω(t)]+η2Tr[(L(t))2ω(t)](cid:17)
.
t=1
Now, let ρ be an arbitrary density operator. Then, noting that the von Neumann entropy of ρ is
given by H(ρ) := −Tr[ρlogρ], we have that the relative entropy between ρ and ω(t) is10
D(ρ∥ω(t)) := Tr[ρlogρ]−Tr[ρlogω(t)] (D.5)
10Observe that the updates ω(t) always have full rank, so the support condition in (2.51) is satisfied.
79= −H(ρ)−Tr[ρlogω(t)]
" #
W(t)
= −H(ρ)−Tr ρlog
Tr[W(t)]
= −H(ρ)+logTr[W(t)]−Tr[ρlogW(t)].
Noting further that
T !
logW(T+1) = logexp −ηX L(t) (D.6)
t=1
T+1
= −η X L(t)
t=1
T−1
= −ηL(T)−η X L(t)
t=1
= −ηL(T)+logW(T),
we obtain
D(ρ∥ω(t+1))−D(ρ∥ω(t)) = logTr[W(t+1)]−logTr[W(t)]−Tr[ρ(−ηL(t)+logW(t))]
+Tr[QlogW(t)]
= logTr[W(t+1)]−logTr[W(t)]+ηTr[ρL(t)]
≤ −ηTr[L(t)ω(t)]+η2Tr[(L(t))2ω(t)]+ηTr[ρL(t)], (D.7)
where for the inequality on the last line we have used (D.3). This implies that
D(ρ∥ω(T+1))−D(ρ∥ω(1)) = D(ρ∥ω(T+1))−D(ρ∥ω(T)) (D.8)
+D(ρ∥ω(T))−D(ρ∥ω(T−1))+···−D(ρ∥ω(2))
+D(ρ∥ω(2))−D(ρ∥ω(1))
T T T
≤
−ηXTr[L(t)ω(t)]+η2XTr[(L(t))2ω(t)]+ηXTr[L(t)ρ].
t=1 t=1 t=1
Then, because D(ρ∥ω(T+1)) ≥ 0, we obtain
T T T
0 ≤ D(ρ∥ω(T+1)) ≤ −ηXTr[L(t)ω(t)]+η2XTr[(L(t))2ω(t)]+ηXTr[L(t)ρ]+D(ρ∥ω(1)). (D.9)
t=1 t=1 t=1
Finally, because ω(1) = 11, and because D(ρ∥11) = logd−H(ρ), we can rearrange the inequality
d d
above to obtain the desired result.
Remark 60. Let us make the following observations about the result in (2.44).
• If we let ρ be a rank-one density operator, then H(ρ) = 0, and then we can further minimize
over all such rank-one density operators to obtain
XT
Tr[L(t)ω(t)] ≤ λ
XT L(t)! +ηXT
Tr[(L(t))2ω(t)]+
logd
, (D.10)
min
η
t=1 t=1 t=1
80which is precisely the result in Ref. [110, Theorem 3.1].
• It is worth noting that the MMW-based result for online learning of quantum states in Ref. [20,
Theorem 4] (see, in particular, the proof) presents the regret bound (using the notation of
this section, and d = 2n)
T " T !# T log(2n)
XTr[L(t)ω(t)] ≤ Tr ρ X L(t) +ηXTr[(L(t))2ω(t)]+ , (D.11)
η
t=1 t=1 t=1
for every density operator ρ. Note that the regret bound in (2.44) can in general be tighter
than this bound, because of the entropy term H(ρ) in (2.44), which is always non-negative.
• We can minimize the right-hand side of (2.44) with respect to ρ, in order to obtain the best
possible upper bound on the total expected loss. In other words,
XT
Tr[L(t)ω(t)] ≤ inf
Tr"
ρ
XT L(t)!#
−
H(ρ)! +ηXT
Tr[(L(t))2ω(t)]+
logd
. (D.12)
ρ≥0 η η
t=1 t=1 t=1
Tr[ρ]=1
From the connection between the MWW and Hedge algorithms noted at the beginning of
this section, we immediately obtain the following regret bound for the Hedge algorithm from
Proposition 14.
Corollary 61 (Entropic regret bound for the Hedge algorithm). Let T ∈ N, and consider a sequence
m(1),m(2),...,m(T) of loss vectors of size d ∈ {2,3,...} along with the updates p(t) provided by
the Hedge algorithm in Algorithm 5. Then, the following inequality holds:
XT
p(t)·m(t) ≤ q·
XT m(t)! +ηXT
p(t)·(m(t))2+
logd−H(q)
, (D.13)
η
t=1 t=1 t=1
where q is an arbitrary probability vector.
D.2 The projected MMW algorithm
We start by defining the projection map as
1
n o
Π(σ ) = argmin D(ρ ∥σ ) : ρ ≥ 0, Tr [ρ ] = A , (D.14)
A,B A,B A,B A,B B A,B
ρA,B d A
where σ is a density operator and the relative entropy is D(·∥·) is defined in (2.51). We make
A,B
use of the fact that the relative entropy is a Bregman divergence [113, 115, 144]. In particular, for
ρ,σ density operators, with σ positive definite, we have that
D(ρ∥σ) = B (ρ∥σ) := F(ρ)−F(σ)−Tr[∇F(σ)(ρ−σ)], (D.15)
F
where
F(P) := Tr[P logP −P], (D.16)
81∇F(Q) ≡ logQ, (D.17)
for P positive semi-definite and Q positive definite. It follows that the projection map in (D.14) is
a Bregman projection; consequently, we have the so-called Pythagorean inequality [144],
D(ρ∥σ) ≥ D(ρ∥Π(σ))+D(Π(σ)∥σ), (D.18)
for density operators ρ and σ. This inequality essentially tells us that projection only get us closer
to the set of CPTP maps, in the sense that
D(ρ∥Π(σ)) ≤ D(ρ∥σ), (D.19)
which follows directly from (D.18), due to the fact that D(ρ∥σ) ≥ 0 for all density operators ρ and
σ. We also require the Pinsker inequality [101]: for all density operators ρ and σ,
1
D(ρ∥σ) ≥ ∥ρ−σ∥2. (D.20)
2 1
Finally, we make the observation that the update step 4 in the MMW algorithm (Algorithm 2
and Algorithm 3) can be written as
h i h i
W(t+1) = exp log(W(t))−ηL(t) = exp ∇F(W(t))−ηL(t) , (D.21)
wherewerecalltheexpressionfor∇F in(D.17). Withthisobservation,wecanequivalentlyformulate
Algorithm 3 as the lazy version of Algorithm 6 below, which is a mirror descent algorithm [46,
Section 5.3].
Algorithm 6 Mirror descent algorithm for Choi states of quantum channels
Require: η ∈ (0,1); Initialize W(1) = 1 ⊗1 and ρ(1) = 1 1 ⊗1
1: for t = 1,2,...,T do
A,B A B A,B dAdB A B
2:
Output the decision/estimate ρ(t)
A,B
3: Receive the cost matrix L( At ,) B, −1 A,B ≤ L( At ,) B ≤ 1 A,B
Take the gradient step
4:
(Lazy version) W(t) → Y(t) := ∇F(W(t) )−ηL(t)
A,B A,B A,B A,B
(Agile version) W(t) → Y(t) := ∇F(ρ(t) )−ηL(t)
A,B A,B A,B A,B
5:
Set W(t+1) = exp[Y(t) ].
A,B A,B
6: Project: ρ(t+1) := Π(ω(t+1)), ω(t+1) ≡ W A(t ,+ B1) .
A,B A,B A,B Tr[W(t+1)]
A,B
7: end for
Proposition 62 (Regret bound for lazy mirror descent for Choi states). Let σ be an arbi-
A,B
trary Choi state. Let T ∈ N be the number of rounds of interaction, and consider a sequence
L(1) ,L(2) ,...,L(T) of cost matrices along with the updates ρ(t) provided by the lazy version of
A,B A,B A,B A,B
Algorithm 6. Then,
XT
Tr[L(t) ρ(t) ] ≤
Tr"
σ
XT
L(t)
!# +2ηXT
∥L(t) ∥2 +
log(d Ad B)−H(σ A,B)
. (D.22)
A,B A,B A,B A,B A,B ∞ η
t=1 t=1 t=1
82Proof. It turns out that the lazy version of Algorithm 6 is equivalent to the regularized follow-the-
leader algorithm [46, Section 5.3.1]. In particular, using Ref. [46, Lemma 5.5], it follows that the
projection step for the lazy version of Algorithm 6 is given by
ρ(t+1) := Π(ω(t+1))
A,B A,B
t 1
= argminn ηXTr[L(s) ρ ]+F(ρ ) : ρ ≥ 0, Tr [ρ ] = Ao , (D.23)
ρA,B s=1 A,B A,B A,B A,B B A,B d A
where the function F is defined in (D.16). Indeed, the gradient of the objective function on the
right-hand side is equal to
t ! T
∇ ηXTr[L(s) P ]+F(P ) = ηX(L(s) )T+∇F(P ) (D.24)
A,B A,B A,B A,B A,B
s=1 s=1
where P is an arbitrary positive semi-definite operator. At the same time, let us observe that
A,B
the gradient step of the lazy version of Algorithm 6 is given by
∇F(W(t+1)) = ∇F(W(t) )−ηL(t) (D.25)
A,B A,B A,B
= ∇F(W(t−1))−ηL(t−1) −ηL(t)
A,B A,B A,B
.
.
.
t
= ∇F(W(1) )−ηX L(s)
A,B A,B
s=1
t
= −ηX L(s) ,
A,B
s=1
where the last equality holds because W(1) = 1 and log(1 ) = 0. This implies that
A,B A,B A,B
∇F(ω(t+1)) = logω(t+1) (D.26)
A,B A,B
= logW(t+1) −(logTr[W(t+1)])1
A,B A,B A,B
= ∇F(W(t+1))−(logTr[W(t+1)])1
A,B A,B A,B
t
= −ηX(L(s) )T−(logTr[W(t+1)])1 .
A,B A,B A,B
s=1
Therefore,
h i
D(ρ ∥ω(t+1)) = F(ρ )−F(ω(t+1))−Tr ∇F(ω(t+1))(ρ −ω(t+1)) (D.27)
A,B A,B A,B A,B A,B A,B A,B
" t ! #
= F(ρ )−F(ω(t+1))+ηTr X L(s) (ρ −ω(t+1))
A,B A,B A,B A,B A,B
s=1
−log(Tr[W(t+1)])Tr[ρ −ω(t+1)]
A,B A,B A,B
| {z }
=0
83" t ! #
= F(ρ )−F(ω(t+1))+ηTr X L(s) (ρ −ω(t+1)) ,
A,B A,B A,B A,B A,B
s=1
which implies that
t
∇D(ρ ∥ω(t+1)) = −∇F(ρ )+ηX(L(s) )T. (D.28)
A,B A,B A,B A,B
s=1
Combining (D.24) and (D.28), and using the fact that the function F is strictly convex, we can
conclude that (D.23) holds. The desired regret bound then follows by Ref. [20, Theorem 3], which
considers the regularized follow-the-leader algorithm for quantum states. ■
Proposition 63 (Regret bound for agile mirror descent for Choi states). Let σ be an arbi-
A,B
trary Choi state. Let T ∈ N be the number of rounds of interaction, and consider a sequence
L(1) ,L(2) ,...,L(T) of cost matrices along with the updates ρ(t) provided by the agile version of
A,B A,B A,B A,B
Algorithm 6. Then,
XT
Tr[L(t) ρ(t) ] ≤
Tr"
σ
XT
L(t)
!#
+
η XT
∥L(t) ∥2 +
log(d Ad B)−H(σ A,B)
. (D.29)
A,B A,B A,B A,B 2 A,B ∞ η
t=1 t=1 t=1
Proof. Similar to the proof of Proposition 14 (see (D.7), in particular), the idea of the proof is to
bound D(σ ∥ρ(t) )−D(σ ∥ρ(t+1)) for every time step t ∈ {1,2,...,T}. To this end, we start
A,B A,B A,B A,B
by noting that from the gradient step of the agile version of Algorithm 6, it holds that
1
(cid:16) (cid:17)
L(t) = logρ(t) −logW(t+1) , (D.30)
A,B η A,B A,B
for all t ∈ {1,2,...,T}. Using this, and with straightforward manipulations, we obtain the following:
Tr[L(t) ρ(t) ]−Tr[L(t) σ ] = Tr[L(t) (ρ(t) −σ )] (D.31)
A,B A,B A,B A,B A,B A,B A,B
1
h(cid:16) (cid:17) i
= Tr logρ(t) −logW(t+1) (ρ(t) −σ )
η A,B A,B A,B A,B
1
h(cid:16) (cid:17) i
= Tr logW(t+1) −logρ(t) (σ −ρ(t) )
η A,B A,B A,B A,B
1
(cid:16) (cid:17)
= D(σ ∥ρ(t+1))−D(σ ∥W(t+1))+D(ρ(t) ∥W(t+1))
η A,B A,B A,B A,B A,B A,B
1
(cid:16) (cid:17)
= D(σ ∥ρ(t) )−D(σ ∥ω(t+1))+D(ρ(t) ∥ω(t+1))
η A,B A,B A,B A,B A,B A,B
1
(cid:16) (cid:17)
≤ D(σ ∥ρ(t) )−D(σ ∥ρ(t+1))+D(ρ(t) ∥ω(t+1)) ,
η A,B A,B A,B A,B A,B A,B
where for the inequality we have used (D.19), and we also made use of the fact that
logω(t+1) = logW(t+1) −log(Tr[W(t+1)])1 , (D.32)
A,B A,B A,B A,B
which means that D(σ ∥ω(t+1)) = D(σ ∥W(t+1)) + log(Tr[W(t+1)]). Now, let us bound
A,B A,B A,B A,B A,B
D(ρ(t) ∥ω(t+1)). Consider that
A,B A,B
D(ρ(t) ∥ω(t+1))+D(ω(t+1) ∥ρ(t) ) (D.33)
A,B A,B A,B A,B
84h (cid:16) (cid:17)i
= Tr (ρ(t) −ω(t+1)) logρ(t) −logω(t+1)
A,B A,B A,B A,B
h (cid:16) (cid:17)i
= Tr (ρ(t) −ω(t+1)) logρ(t) −logW(t+1)+log(Tr[W(t+1)])1
A,B A,B A,B A,B A,B A,B
h(cid:16) (cid:17) i
= Tr logρ(t) −logW(t+1) (ρ(t) −ω(t+1)) +log(Tr[W(t+1)])Tr[ρ(t) −ω(t+1)]
A,B A,B A,B A,B A,B A,B A,B
| {z }
=0
= ηTr[L(t) (ρ(t) −ω(t+1))]
A,B A,B A,B
(t) (t) (t+1)
≤ η∥L ∥ ∥ρ −ω ∥ ,
A,B ∞ A,B A,B 1
where we have used the Hölder inequality in the final line. Let us now use the fact that (x−y)2 ≥
0 ⇒ xy ≤ 1x2+ 1y2 for all x,y ∈ R. Letting x ≡ η∥L(t) ∥ and y ≡ ∥ρ(t) −ω(t+1) ∥ , and using
2 2 A,B ∞ A,B A,B 1
the Pinsker inequality (D.20), we obtain
η2 1
D(ρ(t) ∥ω(t+1))+D(ω(t+1) ∥ρ(t) ) ≤ ∥L(t) ∥2 + ∥ρ(t) −ω(t+1) ∥2 (D.34)
A,B A,B A,B A,B 2 A,B ∞ 2 A,B A,B 1
η2
≤ ∥L(t) ∥2 +D(ω(t+1) ∥ρ(t) ),
2 A,B ∞ A,B A,B
which implies that
η2
D(ρ(t) ∥ω(t+1)) ≤ ∥L(t) ∥2 , (D.35)
A,B A,B 2 A,B ∞
for all t ∈ {1,2,...,T}. Altogether, we have
1 (cid:16) (cid:17) η
Tr[L(t) ρ(t) ]−Tr[L(t) σ ] ≤ D(σ ∥ρ(t) )−D(σ ∥ρ(t+1)) + ∥L(t) ∥2 , (D.36)
A,B A,B A,B A,B η A,B A,B A,B A,B 2 A,B ∞
for all t ∈ {1,2,...,T}. Summing over all t, we obtain
T " T !#
XTr[L(t) ρ(t) ]−Tr σ X L(t)
A,B A,B A,B A,B
t=1 t=1
≤
η XT
∥L(t) ∥2 +
1 (cid:16)
D(σ ∥ρ(1) )−D(σ
∥ρ(T+1))(cid:17)
2 A,B ∞ η A,B A,B A,B A,B
t=1
≤
η XT
∥L(t) ∥2 +
1
D(σ ∥ρ(1) ), (D.37)
2 A,B ∞ η A,B A,B
t=1
where the second inequality is due to the fact that D(ρ∥σ) ≥ 0 for all density operators ρ and σ.
After substituting ρ(1) = 1 1 , we obtain the desired result. ■
A,B dAdB A,B
Remark 64 (Extending Proposition 63 to multi-time processes). The key elements of the proof of
Proposition 62 are the fact that we project onto a convex set in (D.14), such that the inequality
in (D.19) holds, and the Pinsker inequality in (D.20). Consequently, it is straightforward to
generalize Algorithm 6, and thus Proposition 62, to the Choi states of multi-times processes. In
particular, letting COMB ≡ COMB (A ,...,A ;B ,...,B ) be the set of multi-time processes with
r r 1 r 1 r
r ∈ {1,2,...} time steps, as given in Definition 51, we define the relative entropy projection onto
this set as
1 n (cid:16) 1 (cid:13) (cid:17) o
Π(σ) := argmin D P(cid:13)σ : P ∈ COMB , (D.38)
d d (cid:13) r
A P A
85for all σ ∈ L(H(r) ), σ ≥ 0, where d ≡ Qr d . Then, by replacing step 6 in Algorithm 6 with
A,B A k=1 A k
the projection in (D.38), we obtain a mirror descent algorithm for Choi states of multi-time quantum
processes. Then, the analogue of Proposition 62 is as follows. If σ = 1 Q, with Q ∈ COMB , is an
dA r
arbitrary Choi state of a multi-time process with r steps, L(1),L(2),...,L(T) ∈ L(H(r) ) are cost
A,B
matrices satisfying −1 ≤ L(t) ≤ 1 , with d ≡ Qr d , and ρ(1),ρ(2),...,ρ(T) are the
dAdB dAdB B k=1 B k
projected Choi state updates resulting from the algorithm, then
XT
Tr[L(t)ρ(t)] ≤
Tr"
σ
XT L(t)!#
+
η XT
∥L(t)∥2 +
log(d Ad B)−H(σ)
, (D.39)
2 ∞ η
t=1 t=1 t=1
which is directly analogous to (D.29). ◀
86