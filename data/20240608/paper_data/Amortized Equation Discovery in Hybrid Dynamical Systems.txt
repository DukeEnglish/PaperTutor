Amortized Equation Discovery in Hybrid Dynamical Systems
YongtuoLiu1 SaraMagliacane1 MiltiadisKofinas1 EfstratiosGavves1
Abstract designsofcyber-physicalsystems(Sanfeliceetal.,2016),
andsystemswithinteractingobjects(Liuetal.,2023).
Hybrid dynamical systems are prevalent in sci-
enceandengineeringtoexpresscomplexsystems Amajorchallengewithhybriddynamicalsystemsisthat
withcontinuousanddiscretestates. Tolearnlaws one cannot know a priori the number of possible modes
of systems, all previous methods for equation andwhentheswitchinghappenswithinthem. Thedynamic
discovery in hybrid systems follow a two-stage modesmightalternatefromonetoanotherconstantlyandat
paradigm, i.e. they first group time series into anytime,duetoeitherinternalmechanismsorexternalin-
smallclusterfragmentsandthendiscoverequa- fluences. Whenmodelinggeneralizedtimeseriesashybrid
tionsineachfragmentseparatelythroughmeth- dynamicalsystems,itisthuscrucialthatwecategorizethe
ods in non-hybrid systems. Although effective, complexdynamicsintothemostlikelydiscretemodeswhile
thesemethodsdonottakefullyadvantageofthe characterizingthecontinuousmotiondynamicsinbetween.
commonalitiesintheshareddynamicsofmulti-
Anotherchallengewithcharacterizingdynamicsinhybrid
plefragmentsthataredrivenbythesameequa-
systems,especiallyphysicalones,isthatpredictivemodels
tions. Besides,thetwo-stageparadigmbreaksthe
areoftennotinterpretable. Weareofteninterestedinthe
interdependence between categorizing and rep-
underlyinglawsthatgovernthedynamics,thuspreferring
resentingdynamicsthatjointlyformhybridsys-
analytic models, usually in the form of closed-form ordi-
tems. Inthispaper,wereformulatetheproblem
narydifferentialequations. Equationdiscoveryfromfirst
andproposeanend-to-endlearningframework,
principlesisachallengingprobleminallfieldsofscience.
i.e. AmortizedEquationDiscovery(AMORE),to
Tobypassexpensiveandcumbersometargetedexperimen-
jointlycategorizemodesanddiscoverequations
tation,researchershaveexploredusingdata-drivenmethods
characterizingthedynamicsofeachmodebyall
forequationdiscoveryofsystemsfromobservations(Lan-
segmentsofthemode. Experimentsonfourhy-
gley,1981;Lemosetal.,2023). Theydistillparsimonious
brid and six non-hybrid systems show that our
equationsfromdataandfindthatcomparedwithblack-box
methodoutperformspreviousmethodsonequa-
neuralnetworks,learnedequationscanprovideinsightinto
tiondiscovery,segmentation,andforecasting.
the essential dynamics of systems and tend to generalize
better(Lutteretal.,2019;Karniadakisetal.,2021).
Equationdiscoveryforhybriddynamicalsystemshasbeen
1.Introduction
atopicofinterestforalongtime (Vidaletal.,2003;Ozay
Complexsystemsinscienceandengineeringoftenexhibit et al., 2008; Bako, 2011; Ohlsson & Ljung, 2013). Re-
behaviorsandpatternsthatchangeovertime. Hybriddy- cently,Manganetal.(2019);Novellietal.(2022)proposed
namical systems (Van Der Schaft & Schumacher, 2007) methods for equation discovery in non-linear hybrid sys-
characterizethesesystemsbycontinuoustimeserieswhich tems. Bothmethodsconsistoftwostages: theyfirstgroup
areinterleavedwithstructuralchangesproducingdiscrete timeseriesfragmentsintoalargenumberofsmallcluster
modes. Forinstance,considerthemotionsofantelopesin fragments and then apply an equation discovery method
aherdandhowthesesuddenlychangeinthepresenceof proposedinnon-hybridsystems,e.g. SINDy(Bruntonetal.,
lions. Hybridsystemsareresearchedwidelywithapplica- 2016), to discover equations in each fragment separately.
tionsinepidemiology(Keelingetal.,2001),leggedloco- Theseparatemulti-stageprocessinglimitsthepotentialper-
motion(Holmesetal.,2006),robotics(Cortes,2008),the formancebecauseitdoesnotleveragethecommonalities
acrossfragmentsfromthesamemodeandsplitslearning
1UniversityofAmsterdam.Correspondenceto:YongtuoLiu
intotwoseparatestages,i.e.categorizingandthenrepresent-
<y.liu6@uva.nl>.
ingmotiondynamicswhichjointlyformhybridsystems.
Proceedings of the 41st International Conference on Machine
Inthispaper,wereformulatetheproblemofequationdis-
Learning,Vienna,Austria.PMLR235,2024.Copyright2024by
covery in hybrid dynamical systems and propose a one-
theauthor(s).
1
4202
nuJ
6
]VC.sc[
1v81830.6042:viXraAmortizedEquationDiscoveryinHybridDynamicalSystems
Hybrid Systems TIME Hybrid Systems TIME
k-NN
...
Cluster 0 Cluster 2 Amortized Equation Discovery
Cluster 1 Cluster 3
... Mode 0 Mode 1
SINDy 0 SINDy 1 SINDy 2 SINDy 3
Equations
... Segmentation
(a) Previous methods (b) Our method (AMORE)
Figure1.(a)Previousmethodsforequationdiscoveryinhybriddynamicalsystemstypicallyfollowatwo-stageparadigm,i.e.theyfirst
grouptimeseriesintosmallclusterfragmentsandthenapplymethodsproposedinnon-hybridsystems,e.g.SINDy(Bruntonetal.,2016)
todiscoverequationsineachfragmentseparately.(b)Differentfromallpreviousmethods,wereformulatetheproblemandproposea
one-stageend-to-endlearningframework,AmortizedEquationDiscovery(a.k.a. AMORE),tojointlycategorizehybridsystemsinto
discretemodesanddiscoverequationscharacterizingmotiondynamicsofeachmodebasedonallsegmentsbelongingtothemode.
stageend-to-endlearningframework,AmortizedEquation Juloskietal.,2005;Paolettietal.,2007;Ozayetal.,2008;
Discovery (a.k.a. AMORE), to jointly categorize motion Bako,2011;Ohlsson&Ljung,2013). Recently, Mangan
dynamicsanddiscoverequationsbymodelingcategorical etal.(2019);Novellietal.(2022)relievetheseconstraints
modesandmode-switchingbehaviorswithinsystems.Equa- andproposemethodsfornon-linearhybridsystems.Among
tionsarediscoveredtocharacterizethedynamicsofeach them,Hybrid-SINDy(Manganetal.,2019)proposesatwo-
modebasedonallsegmentsthatareassignedtothemode, stage method, i.e. it first uses k-NN to group time series
bylearningcombinationsofcandidatebasisfunctionsand intosmallclusterfragmentsandthendiscoversgoverning
encouragingparsimony. Tomodelswitchingbehaviors,in- equationsseparatelyineachfragmentbymodelsproposed
spired by REDSDS (Ansari et al., 2021), we infer latent innon-hybridsystems,e.g. SINDy(Bruntonetal.,2016).
categoricalvariables,i.e. modevariables,tocategorizemo- BasedonHybrid-SINDy,Novellietal.(2022)alsofollows
tiondynamicsintodiscretemodesandlearnprobabilistic atwo-stageparadigmwhileintroducingthenumberofdis-
transition behaviors within them. Equations, mode vari- continuitiesinhybridsystemsasaknownpriorforbetter
ables,andmode-switchingbehaviorsarejointlylearnedin performance. Althougheffective,thesetwo-stagemethods
theproposedend-to-endlearningframeworkbymaximiz- learn the mode of each segment individually and do not
ing the system observation likelihood. We also consider leverage the commonalities across segments. In this pa-
anotherchallengeinpreviousmethodsforequationdiscov- per,wereformulatetheproblemandproposeanamortized
ery for hybrid systems: they are limited to single-object end-to-endlearningframeworktojointlycategorizemodes,
scenarios where the dynamics of only one object or ob- discoverequations,andlearnmode-switchingbehaviors.
jects as a whole are considered. We extend our method
Equation discovery in non-hybrid dynamical systems.
tomulti-objectscenarios, AMORE-MIO,wheremultiple
Manymethodshavebeenproposedforequationdiscoveryin
objects interact with each other and change their dynam-
non-hybriddynamicalsystems. Bongard&Lipson(2007)
ics accordingly. Extensive experiments on single- and
and Schmidt & Lipson (2009) leverage genetic program-
multi-objecthybridsystemsdemonstratethesuperiorper-
ming(Kozaetal.,1994)todiscovernonlineardifferential
formance of our method on equation discovery, segmen-
equations from data. SINDy (Brunton et al., 2016) uses
tation, and forecasting. The code and datasets are avail-
symbolicsparseregressiononalibraryofcandidatemodel
ableathttps://github.com/yongtuoliu/Amortized-Equation-
terms to select the fewest terms required to describe the
Discovery-in-Hybrid-Dynamical-Systems.
observeddynamics. Severalmethodsextendthisapproach
to new settings, e.g. identifying partial differential equa-
2.RelatedWork
tions(Rudyetal.,2017), consideringadditionalphysical
constraints(Loiseau&Brunton,2018),includingcontrol
Equationdiscoveryinhybriddynamicalsystems. Prior
signals(Kaiseretal.,2018),andintroducingintegralterms
worksfocusonthesimplesthybriddynamicalmodels,i.e.
fordenoising(Schaeffer&McCalla,2017). Thesemethods
piece-wiseaffinesystemswithlineartransitionrules(Vidal
cannotbedirectlyappliedtohybridsystemsbecausethey
etal.,2003;Ferrari-Trecateetal.,2003;Rolletal.,2004;
cannotmodelanunknownnumberofmodesandunknown
2AmortizedEquationDiscoveryinHybridDynamicalSystems
mode-switchingbehaviors. tothenon-differentiabilityandthecombinatorialnatureof
allpossiblestates. Variouscontinuousrelaxationmethods
Switchingdynamicalsystems. Switchingdynamicalsys-
are proposed in the literature to handle the optimization
tems refer to the same systems as hybrid dynamical sys-
problemsofL norm,e.g. L ,L ,etc. Asourfocusinthis
tems,buthighlightdifferentaspectsintheliterature. Hybrid 0 1 2
paperisnottodesignadvancedoptimizationmethods,we
systemsdenotesystemswithamixtureofcontinuousand
utilizethesimpleandeffectiveL normtooptimizeEq.(3).
discrete states, while switching dynamical systems high- 1
lighttheswitchingbehaviorsofsystemstates. Manymeth- Weimplementthecoefficientsξ aslearnableweightsin
m
ods focus on switching linear dynamical systems where neuralnetworks. WesetthepolynomialdegreeasD and
they set matrix calculations to model linear state transi- useasetoflearnableweightsw“rw ,¨¨¨ ,w stomodel
1 C
tions(Ackerson&Fu,1970;Ghahramani&Hinton,2000; thecoefficientsofCcandidatebasisfunctions. Forinstance,
Oh et al., 2005). Recently, switching non-linear dynami- iftheobservationy “ ra,bsisatwo-dimensionalvector
t
calsystemsmodelstatetransitionsasneuralnetworks,e.g. and we set the polynomial degree D as 2, the candidate
SNLDS(Dongetal.,2020),REDSDS(Ansarietal.,2021), basispolynomialfunctionsareΘpy q“r1,a,b,a2,b2,abs.
t
andGRASS(Liuetal.,2023). Whileeffectiveinmodeling Inthiscase,C “6andw“rw ,¨¨¨ ,w s.
1 6
state-switchingbehaviors,theycannotdiscoverclosed-form
equationsfromdata. Tocategorizedynamics,ourmethodis 4.EquationDiscoveryinHybridSystems
inspiredbypreviousswitchingdynamicalsystems(Dong
et al., 2020; Ansari et al., 2021; Liu et al., 2023) to infer Hybriddynamicalsystemsproducegeneralizedtimeseries
latentmodevariables. Differently,ourmethodcanjointly withcontinuousstatesanddiscreteeventsthatneedtobe
discoverparsimoniousclosed-formequationstocharacter- modeled,featuringmultiplemodesthatrepresentdifferent
izedynamicsandinferthevaluesofthemodevariables. typesofdynamics. Insteadoflearningasingleequationfor
eachdimensionmPrMs,asdescribedinSec.3,welearn
K setsofequationsforeachdimensionmthatrepresentK
3.EquationDiscoveryinDynamicalSystems
differentmodesinhybridsystems. Wefirstintroducehow
Indynamicalsystems, thedynamicscanbeexpressedby wemodelmode-switchingbehaviorsandthenintroduceour
setsofdifferentialequationsintheform: wholeframeworkforequationdiscoveryinhybridsystems.
dy Modevariables. Tomodelmodesandmode-switching
y9 :“ t “fpy q. (1)
t t behaviorsinhybridsystems,inspiredbyREDSDS(Ansari
dt
etal.,2021),weintroducelatentcategoricalvariables,i.e.
Equation discovery in dynamical systems is the task of modevariables,tolearncategoricaldistributionsofmodes
learning the function f : RM Ñ RM from time-series andindexeachsetofequationsrepresentingeachtypeof
observations y “ ty 1,¨¨¨ ,y Tu where each state y t “ dynamics. Specifically, mode variables are discrete vari-
ry t1,¨¨¨ ,y tMs P RM. Following SINDy (Brunton et al., ables z :“ z 1:T, where each z
t
P t1,...,Ku categorizes
2016),weapproximateeachdimensiony9 tmformPrMsof themodeattimesteptPt1,...,Tu.
y9 inEq.(1)as
t
Countvariables. Besidesmodevariables,wealsomodel
dym latentcountvariablestolearnthedurationdistributionsof
y9m “ t “f py q«Θpy qξ , (2)
t dt m t t m eachmode.Countvariablescanhelpusavoidfrequentmode
switching,thankstothefactthatmodedurationstypically
where Θpy q “ rθ py q,θ py q,¨¨¨ ,θ py qqs is a set of
t 1 t 2 t P t followageometricdistribution(Ansarietal.,2021). They
candidatebasisfunctionsandξ isasparsevectorindicat-
m are modeled as discrete categorical variables c :“ c ,
ingwhichofthesefunctiontermsareactiveincharacterizing 1:T
whereeachstatec P t1,...,d uexplicitlymodelsthe
thedynamics. Weencouragethesparsityofξ basedon t max
m run-lengthofthecurrentlyactivemodeattimetandd is
Occam’srazorprinciple,wherethesimplestmodelislikely max
themaximalnumberofstepsbeforeamodeswitch. Count
thecorrectone. Ideally,wecouldencouragethisprinciple
variablesc areincrementedby1whenthemodez “ k
byminimizingtheL normofthecoefficientsandsolving t t
0 staysthesameatthenexttimestepz “k,ortheyreset
thefollowingconstrainedminimizationproblem t`1
to1whenmodez “kswitchestoanotheronez ‰k.
t t
min||ξ|| 0 subjectto ||Θpy tqξ´y9 t||ďϵ, (3) Mode-specificequationdiscovery. Eachmodek PrKs
ξ
isassigneditsownsetofcandidatebasisfunctionsΘ py q
k t
whereϵisahyperparameterrepresentingmaximaloptimiza- andlearnablecoefficientweightsw ,whichwewilluseto
k
tionerrors. TheL regularizationpenalizesthenumberof discoveritsequation. Forinstance,attimet,themodevari-
0
non-zeroentriestoencouragesparsity. However,optimiza- able z “ k indexes the candidate basis function Θ py q
t k t
tionunderthispenaltyiscomputationallyintractabledue and the learnable weights w , which together define the
k
3AmortizedEquationDiscoveryinHybridDynamicalSystems
c t 1 c t c t+1 vals∆ t,wefinallyachievey t “y9 t´1¨∆ t`y t´1assuming
− p(c t|c t −1,z t −1) thedynamicsdonotchangemuchinshorttimeintervals.
For inference of the latent mode and count variables, we
z t −1 z t z t+1 p(z t |z t −1,c t,y t −1) conductexactinferencesimilartotheforward-backwardal-
gorithminHMM(Eddy,1996).Thegraphicalmodelforthe
y t −1 y t y t+1
p(y t|y t −1,z t) e isx ia lc lut sin trf ae tr ee dnc ine Fis igth ue resa 2m
.
Te ha es nth ee urg ae ln ne era twtiv oe rkm imod pe ll e, mw eh nic tah
-
tionsanddetailsoftheinferencemodelareinAppendixA.1
Figure2.Generative model for amortized equation discovery. andA.2.
ppc t|c t´1,z t´1q and ppz t|z t´1,c t,y t´1q are count and mode
LearnableparametersofAMOREareoptimizedbymaxi-
transitionprobabilities,respectively. ppy t|y t´1,z tqdenotesthe
mizingtheobservationlikelihoodwithsparseregularization
observationtransitionprobabilitywhereequationsarediscovered
oncoefficientweightswofcandidatebasisfunctions
tocharacterizethedynamicsofeachmode.
“´logp pyq`||w||
AMORE θ 1
L
equationrepresentingthedynamicsofmodek. Inpractice, “´E rlogp py,z,cqs`||w|| . (5)
differentmodessharethesamecandidatebasisfunctions,
pθpz,c|yq θ 1
i.e. Θ jpy tq“Θ kpy tq,@j,k Pt1,¨¨¨ ,Ku,unlesswehave Thederivativesofthetrainingobjectiveandfurtherexpan-
somepriorknowledgeofthehybridsystem. However,the
sionsovertimearedetailedinAppendixA.3.
learnablecoefficientweightsofdifferentmodesareindivid-
ual and never shared, i.e. w ‰ w ,@j,k P t1,¨¨¨ ,Ku.
j k 5.EquationDiscoveryinMulti-objectHybrid
Wecollectallthecandidatebasisfunctionsinasinglevector
Systems
Θpy q “ pΘ py q,¨¨¨ ,Θ py qqandsimilarlywecollect
t 1 t K t
alllearnablecoefficientweightsw“pw ,¨¨¨ ,w q.
1 K Whileequationdiscoveryinhybriddynamicalsystemshas
GenerativemodelforAMORE. AssumingMarkovian beenresearchedinsingle-objectscenarios,themoregeneral
dynamics,thejointgenerativeprobabilityofhybridsystems settingofsystemswithmultiplepotentiallyinteractingob-
inourmodelisdescribedas jectsisanunexploredyetnaturalsetting. Inthissection,we
„ elaborateonhowourmodelcanbeextendedformulti-object
źT
scenarios,andpresentAMORtizedEquationdiscoveryin
ppy,z,cq“lppooyoo1o|oozm1qoopopoozo1onq¨ ppy t|y t´1,z tq
MultI-Objecthybridsystems,a.k.a. AMORE-MIO.Wefirst
t“2
InitialStates ȷ introduce how our method models interactions and then
introducethewholeframeworkofAMORE-MIO.
ppz |z ,c ,y qppc |c ,z q (4)
t t´1 t t´1 t t´1 t´1
Edge variables. Assume that N objects and K motion
Intheinitialstates,countvariablesareignoredastheyare modesexistinmulti-objecthybridsystems.InspiredbyKipf
always1whenstarting. ppz 1qistheinitialdistributionover et al. (2018); Liu et al. (2023), we model interactions
allpossiblemodes. ppy 1|z 1qmodelstheinitialobservation between objects by latent edge variables e “ e 11: :N T2 “
statesconditionedontheinitialmodes. Forlatertimesteps te1,¨¨¨ ,eN2uT includingself-loop,thustotallyN2 for
t t t“1
tě2,thecounttransitionprobabilityppc t|c t´1,z t´1qmod- N objects. For each pair of objects, interactions emÑn
t
elshowthecountvariablesattimetchangeovertimede-
modelwhetherobjectminteractswithobjectnattimet.
pendingontheirpreviousvaluesandmodevariablesattime
Theedgevariablesaremodeledinalatenttemporalgraph
t´1. Themodetransitionprobabilityppz t|z t´1,c t,y t´1q “p , q,whereedgesemÑn P andnodes sum-
modelsmode-switchingbehaviorsonhowmodesswitchat G mt arizeV stt atE et sofobjects. Forint stance,E vt m “tzm,cV mt ,ymu
t t t t
timetconditionedonthepreviousmodeandobservation for vm P defines one graph node summarizing states
statesattimet´1aswellastheupdatedcountstatec tat of
obt
ject
mVt
at time t which includes observation tymu
t
timet.Theobservationtransitionprobabilityppy t|y t´1,z tq andlatentstatestzm,cmu. EdgeemÑnsignalsinteraction
t t t
models how the observations at time t are influenced by relationshipsbetweennodevmandnodevningraph .
theirpreviousvaluesattimet´1conditionedontheup-
t t Gt
dated mode variables at time t. Equations are amortized Object-shared and mode-specific equation discovery.
andlearnedatppy |y ,z qbyallsegmentsofeachmode We set the number of all possible motion modes as K
t t´1 t
to characterize mode dynamics. More specifically, con- in multi-object hybrid dynamical systems. The K mo-
ditioned on motion mode z “ k, ppy |y ,z q first in- tionmodesaresharedacrossN objects,whichareimple-
t t t´1 t
dexesasetofcandidatebasisfunctionsΘ andcoefficient mented by K sets of candidate basis functions Θpy q “
k t
weightsw ,whichareusedtogethertoobtainderivatives pΘ py q,¨¨¨ ,Θ py qq and learnable coefficient weights
k 1 t K t
y9 “Θ ¨w ofy attimet´1.Withknowntimeinter- w “ pw ,¨¨¨ ,w q. Each mode k P rKs has its own
t´1 k k t´1 1 K
4AmortizedEquationDiscoveryinHybridDynamicalSystems
e1:N2 e1:N2 e1:N2 e1:N2 e1:N2 e1:N2
t −1 t t+1 p(e1:N2e1:N2,z1:N,c1:N,y1:N) t −1 t t+1
t | t −1 t −1 t −1 t −1
c1:N c1:N c1:N c1:N c1:N c1:N
t −1 t t+1 p(c1 t:N |c1
t
−:N 1,z1
t
−:N 1) t −1 t t+1
z1 t −:N 1 z1 t:N z1 t+:N 1 p(z1 t:N |z1 t −:N 1,c1 t:N,y t1 −:N 1,e t1:N2) y t1 −:N 1 y t1:N y t1 +:N 1 z1 t −:N 1 z1 t:N z1 t+:N 1
p(y1:N y1:N,z1:N)
y t1 −:N 1 y t1:N y t1 +:N 1 t | t −1 t e t1 −:N 12 e t1:N2 e t1 +:N 12 y t1 −:N 1 y t1:N y t1 +:N 1
(a)GenerativeModel (b)InferenceModel
Figure3.(a)GenerativemodelofAMORE-MIO.ppe1:N2 |e1:N2,z1:N,c1:N,y1:Nq,ppc1:N|c1:N,z1:Nq,ppz1:N|z1:N,c1:N,y1:N,e1:N2
q,
t t´1 t´1 t´1 t´1 t t´1 t´1 t t´1 t t´1 t
andppy1:N|y1:N,z1:Nqdenotestheedge,count,mode,andobservationtransitionprobabilities,respectively.Equationsaremodeledat
t t´1 t
ppy1:N|y1:N,z1:Nqwhichcharacterizeobject-sharedandmode-specificdynamics.(b)InferencemodelofAMORE-MIO.Left:posterior
t t´1 t
approximateinferenceofedgevariablese1:N2 . Right: Exactinferenceofdiscretemodeandcountvariablesz1:N andc1:N basedon
t t t
observationsy1:N andtheapproximateedgevariablese1:N2 .Orangearrowsdenotetheapproximateinferenceflow.
t t
Θ py qandw asinSec.4. ThusthereareKsetsoflearn- the observation transition probability ppy1:N|y1:N,z1:Nq
k t k ś t t´1 t
ableweightsforlearningdynamicsofKmodesacrossN canbefactorizedoverobjects N ppyn|yn ,znqwhere
n“1 t t´1 t
objects. BoththetimeandspacecomplexityofAMORE- equations of each mode are amortized and learned by all
MIOregardinglearnableweightsofbasisfunctionsis pKq. segmentsfromallobjectsbelongingtothesamemode. The
O
Forinstance,themodevariablez tn “ k oftheobjectnat furtherexpansionoverobjectsofthejointgenerativeprob-
timetindexesΘ kpy tqandw k whichtogetherformequa- ability is in Appendix B.1. For inference of latent mode,
tionstorepresentthedynamicsofmodek. Differentfrom count, and edge variables, we conduct posterior approxi-
single-object scenarios, the mode-switching behaviors of mateinferenceforedgevariablesq pe|yqconditionedon
ϕe
eachobjectarenotonlyinfluencedbytheirownevolving observationsy,andthenconductexactinferenceofmode
naturebutalsobyexternalinfluencesofpotentiallyinteract- and count variables p pz,c|y,e˜q conditioned on observa-
θ
ingobjects. Wemodeltheinfluencesofinteractionsonthe tionsyandtheapproximateedgevariablese˜ „ q pe|yq.
ϕe
mode-switchingbehaviorsbetweenobjects,whicharede- ThegenerativeandinferencemodelsofAMORE-MIOare
tailedinthefollowinggenerativemodelofAMORE-MIO. illustratedinFig.3. LearnableparametersofAMORE-MIO
areoptimizedbymaximizingtheevidencelowerboundwith
Generativemodelforamortizedequationdiscoveryin sparseregularizationonthelearnablecoefficientweights
multi-object settings. Assuming Markovian dynamics,
thejointgenerativeprobabilityofmulti-objecthybridsys-
“´logp pyq`
temsinAMORE-MIOiscalculatedas LAMORE-MIO θ
D rq pz,c,e|yq}p pz,c,e|yqs`||w|| (7)
KL ϕ θ 1
ppy,e,z,cq“lppooyoo1o:oNoo|ozoo1m:Noqoopopoozo1oo:Noonq¨
1 1 1
Neural network implementations, the derivations and the
InitialStates
„
źT detailedinferencemodelareinAppendixB.2, B.4. andB.3.
ppy1:N|y1:N,z1:Nqppz1:N|z1:N,y1:N,c1:N,e1:N2
q
t t´1 t t t´1 t´1 t t
t“2 ȷ 6.Experiments
ppc1:N|c1:N,z1:Nqppe1:N2 |e1:N2 ,c1:N,z1:N,y1:Nq (6)
t t´1 t´1 t t´1 t´1 t´1 t´1 Weextensivelyvalidateourmethodon10dynamicalsys-
tems. Specifically,wevalidateonsingle-objectscenarios
wheretheinitialstatesandcounttransitionprobabilityare usingtheMass-springHopperdataset,andtheSusceptible,
defined as in Eq. 4 of single-object scenarios but with InfectedandRecovered(SIR)diseasedatasetfromHybrid-
n objects. For later time steps t ě 2, the edge tran- SINDy(Manganetal.,2019). Wevalidateonmulti-object
sition probability ppe1:N2|e1:N2,c1:N,z1:N,y1:Nq mod- scenariosusingtheODE-drivenparticledatasetandSalsa-
t t´1 t´1 t´1 t´1
els how the edge variables evolve depending on all the dancing dataset from GRASS (Liu et al., 2023). Further,
states at the previous time step. We model the influ- wetesttherobustnessofourmethodsonnon-hybridsys-
ences of interactions on the mode transition probability temsusingdatasetsoftheCoupledlinear,Cubicoscillator,
ppz1:N|z1:N,y1:N,c1:N,e1:N2q, which characterizes the Lorenz’63,Hopfbifurcation,Seklovglycolysis,andDuff-
t t´1 t´1 t t
mode-switchingbehaviorsofmulti-objecthybriddynami- ingoscillatorfromCourse&Nair(2023). Detailedsettings
calsystems. Basedontheupdatedmodesofeachobject, ofthedatasetsareinAppendixC.1.
5AmortizedEquationDiscoveryinHybridDynamicalSystems
Ground Truth Modes False Positive Modes Observation Reconstruction
Ground Truth
Hybrid-SINDy
AMORE (ours)
AMORE w/o count (ours)
0 50 100 150
Figure4.QualitativetimeseriessegmentationresultsofAMOREcomparedtoHybrid-SINDy(Bruntonetal.,2016)ontheMass-spring
Hopperdataset.ForHybrid-SINDy,weaggregatethediscoveredequationswiththesamenumberofcoefficientsasonemode.Wecansee
thatwithjointlearningofmodesandequations,AMOREcancategorizetheexactnumberofmodesandachievesuperiorsegmentation
resultswithfewerswitchingerrors.
Table1.SegmentationresultsonMass-springHopperdataset. Table3. SegmentationresultsontheSIRdiseasedataset.
Method NMIÒ ARIÒ AccuracyÒ F 1Ò Method NMIÒ ARIÒ AccuracyÒ F 1Ò
Hybrid-SINDy 0.426 0.383 0.705 0.691 Hybrid-SINDy 0.296 0.283 0.538 0.519
AMORE(ours) 0.928 0.967 0.991 0.993 AMORE(ours) 0.475 0.483 0.731 0.735
Table2.Forecasting results of Location/Velocity on the Mass- Table4.Forecasting results of Susceptible/Infected on the SIR
springHopperdataset. diseasedataset.
Method NMAEÓ NRMSEÓ Method NMAEÓ NRMSEÓ
LLMTime 0.113/0.305 0.417/0.454 LLMTime 0.352/0.396 0.481/0.523
TimeGPT 0.092/0.217 0.322/0.340 TimeGPT 0.301/0.347 0.403/0.452
SVI 0.068/0.075 0.148/0.262 SVI 0.257/0.273 0.355/0.401
Hybrid-SINDy 0.240/0.314 0.336/0.372 Hybrid-SINDy 0.316/0.363 0.414/0.453
AMORE(ours) 0.008/0.039 0.026/0.059 AMORE(ours) 0.088/0.113 0.142/0.181
ImplementationDetails. Wetrainalldatasetswithafixed agescoreofeachexperimentinthemainpaperandputthe
batchsizeof40for20,000trainingsteps. WeusetheAdam statistics(errorbars)intheappendixduetolimitedspace.
optimizerwith10´5weight-decayandclipgradientsnorm
Baselines. Hybrid-SINDy (Mangan et al., 2019) uses a
to10.Thelearningrateiswarmeduplinearlyfrom5ˆ10´5
two-stageparadigmandcannotperformforecasting,thus
to2ˆ10´4forthefirst2,000steps,andthendecaysfollow-
wecomparewithitondiscoveredequationsandsegmen-
ingacosinemannerwitharateof0.99. Eachexperiment
tation. To compare with Hybrid-SINDy on forecasting,
isrunningononeNvidiaGeForceRTX3090GPU.d
min we continue the value of the last observable time point
and d of the count variables are simply set as 20 and
max as forecasting results of Hybrid-SINDy. For forecasting,
50,respectivelyforalldatasets. Thenumberofedgetypes
we compare with other three recent representative meth-
L is set as 2, containing one no-interaction type and one
ods, i.e. SVI (Course & Nair, 2023) which is designed
with-interactiontype. MoredetailsareinAppendixC.2.
forequationdiscoveryinnon-hybridsystemsandcanper-
Evaluationmetrics. Forevaluationofdiscoveredequa- form forecasting, LLMTime (Gruver et al., 2023) which
tions, following Course & Nair (2023), we use the re- utilizepre-trainedlargelanguagemodels(LLM)todofore-
construction error between the discovered cřoefficients of casting, and TimeGPT (Garza & Mergenthaler-Canseco,
equations and ground truth, i.e. RER “ 1 T p||w ´ 2023) which is the first foundation model for time series.
T t“1 t
ξ || {||ξ || qwherew andξ arethelearnedandground- GRASS(Liuetal.,2023)doesnotdiscoverequations,but
t 2 t 2 t t
truthcoefficientsattimet. Forevaluationofsegmentation, modelsmulti-objectswitchingdynamicalsystems,soitis
followingAnsarietal.(2021),weuseframe-wisesegmenta- usedforcomparisoninmulti-objectsystems.
tionaccuracy,i.e.AccuracyandF aftermatchingthelabels
1
usingtheHungarianalgorithm(Kuhn,1955),Normalized 6.1.Single-objectDynamicalSystems
MutualInformation(NMI)andAdjustedRandIndex(ARI)
6.1.1.MASS-SPRINGHOPPER
tomeasuresimilarities. Forevaluationofforecasting,we
useNormalizedMeanAbsoluteError(NMAE)andNormal- Inthemass-springhoppersystem,amassandspringconnect
izedRootMeanSquaredError(NRMSE).Weconducted andhoponthegroundwithtwomodes,i.e. flightandcom-
eachexperimentwith5randomseeds. Wereporttheaver- pression. DetailsofthedatasetareinAppendixC.1.1. Com-
6AmortizedEquationDiscoveryinHybridDynamicalSystems
parisonresultsoftimeseriessegmentationonthedataset
Table5.Forecastingresultsonnon-hybriddynamicalsystems.Re-
areinTable1. WecanseethatAMOREcanachievesignif-
sultsareshowninlog pNRMSEqwherelowerisbetter.
icantandconsistentperformanceimprovementsacrossall 10
metrics. AMOREcategorizesexactlytwomodesfromthe System LLMTime SVI AMORE(ours)
systemanddiscoversequationsforeachmode Coupledlinear -0.39 -1.13 -1.18
#
Cubicoscillator -0.45 -1.02 -1.06
l9“v and v9 “11.03´10.08l
Lorenz’63 -0.41 -1.27 -1.23
l9“v and v9 “´1 Hopfbifurcation -0.32 -0.94 -1.03
Selkovglycolysis -0.68 -1.55 -1.49
which are nearly identical to the ground truth in Eq. (8). Duffingoscillator -0.53 -1.12 -1.17
InHybrid-SINDy,equationsarediscoveredineachcluster
fragment,thusproducingamassivenumberofequations.To
quantitativelycomparediscoveredequations,wecompute findings as in the Mass-spring Hopper dataset. AMORE
RER for Hybrid-SINDy and AMORE which are 7.5e´3 canachieveconsistentlyhighersegmentationaccuracyand
and2.4e´4,respectively. lower forecasting errors across all metrics compared to
Hybrid-SINDy,SVI,LLMTime,andTimeGPT.AMORE
Qualitative segmentation results of Hybrid-SINDy and
categorizesexactlytwomodesfromthesystemanddiscov-
AMOREareshowninFig.4. Thankstotheamortizedjoint
ersequationsforeachmode
learningofmodesandequations,AMOREcancategorize
#
theexactnumberofmodes,achievesuperiorsegmentation S9“2.74´0.0172IS´0.0024S, I9“0.0171IS´0.2I
results,anddiscoverhigh-qualityequations. Intheseexperi-
S9“2.74´0.0057IS´0.0021S, I9“0.0051IS´0.2I
ments,themaximalnumberofpossiblemodesK issetas3
inourmodel. Afterlearning,ourmodelchooses2modes
whicharenearlyexacttothegroundtruthinEq.(9). Quan-
tobeenoughtocategorizeandexpressthedynamicsofthe
titative comparisons of the discovered equations are cal-
specifichybridsystems. Notethatthenumberofdiscovered
culated by RER where Hybrid-SINDy and AMORE are
equationsinHybrid-SINDyisthesameasthenumberof
3.4e´3and1.8e´4,respectively. WecanseethatAMORE
timepoints,whichismuchlargerthanthefixednumberof
candiscoverhigh-qualityequations,andachievesuperior
modes,e.g. K “3inourmodel. Tovisualizediscovered
segmentationandforecastingresultsthankstotheproposed
modesofHybrid-SINDy,weaggregatethediscoveredequa-
jointlearningframeworkdesignedforequationdiscovery
tions with the same type of function terms as one mode,
inhybriddynamicalsystems.
thusappearingmorethan3modesinthesystem. Besides,
“AMOREw/ocount”representsourmodelwithoutsetting
6.1.3.NON-HYBRIDDYNAMICALSYSTEMS
countvariables. Wecanseethatcountvariablescanhelp
AMORElearnfewerfalse-positivemode-switchingbehav- Insomecases,wehavepriorknowledgeofthedynamical
iors. Morequantitativeablationstudiesoncountvariables systemswhethertheyarehybridornot. Toanswertheques-
areinAppendixC.4.3. tionofwhetherourmethod,whichisoriginallydesigned
forhybridsystems,canstillperformwellifweknowthe
WesummarizetimeseriesforecastingresultsontheMass-
systemsarenon-hybridinadvance,weconductexperiments
spring Hopper dataset in Table 2. We can see that our
onsixnon-hybridphysicalsystems(Course&Nair,2023),
methodsignificantlyoutperformsSVIwhichisdesignedfor
includingCoupledlinear,Cubicoscillator,Lorenz’63,Hopf
non-hybrid systems, and LLMTime as well as TimeGPT
bifurcation,Selkovglycolysis,andDuffingoscillator. De-
which utilizes pre-trained large models for forecasting,
tailed settings of the datasets are in Appendix C.1.3. As
thankstotheproposedjointlearningframeworkoriginally
wehavetheprior,wesetthemaximalpossiblenumberof
designedforhybridsystems.
modesin AMOREas 1forall physicalsystems. Follow-
ingCourse&Nair(2023),wesummarizetheforecasting
6.1.2.SIRDISEASEDATASET
resultsinTable5. Wecanseethatalthoughourmodelis
The Susceptible, Infected and Recovered (SIR) disease notspecializedfornon-hybridsystems,AMOREcanstill
modelisanepidemiologicalmodelusedtounderstandthe achievebetterforecastingresultson4outof6non-hybrid
spreadofinfectiousdiseases. Numbersofsusceptible,in- physicalsystems,whichverifiestherobustnessofourmodel
fected, and recovered individuals are involved in model tonon-hybriddynamicalsystems.
dynamicswheresomeexternaleventsdescribethemodes,
e.g. school in session or not. Detailed settings for this 6.2.Multi-objectHybridDynamicalSystems
datasetareinAppendixC.1.2.
Equationdiscoveryinmulti-objecthybriddynamicalsys-
We summarize the segmentation and forecasting results tems is an unexplored but more general setting. In this
on the dataset inTables 3 and4. We can observe similar section,weverifytheeffectivenessofthemulti-objectvari-
7AmortizedEquationDiscoveryinHybridDynamicalSystems
Forward:
x˙=5.18 0.82y+0.17xy
−
y˙=0.42+0.16xy
x˙=4.73 1.04x2y+0.28xy x˙=3.13 1.26x2y+0.33x3
− −
B x˙ac =kw 4a .r 3d 9:
0.66y+0.21x2
y˙=1.27 −0.90xy+0.07y2 y˙= −2.51+0.84y3 −0.14xy
− −
y˙= 0.72+0.03y2
−
(a)ForwardandBackward (b)Clockwise (c)CounterClockwise
Figure5. DiscoveredequationsontheSalsa-dancingdataset.Locationspx,yqofthehipjointsareusedasobservations.
Table6.SegmentationresultsonODE-drivenParticleDataset. Table8.SegmentationresultsontheSalsa-dancingdataset.
Method NMIÒ ARIÒ AccuracyÒ F 1Ò Method NMIÒ ARIÒ AccuracyÒ F 1Ò
Hybrid-SINDy 0.205 0.192 0.414 0.407 Hybrid-SINDy 0.102 0.097 0.325 0.309
GRASS 0.445 0.437 0.732 0.726 GRASS 0.173 0.177 0.579 0.526
AMORE(ours) 0.418 0.405 0.692 0.684 AMORE(ours) 0.167 0.173 0.565 0.518
AMORE-MIO(ours) 0.453 0.442 0.741 0.735 AMORE-MIO(ours) 0.179 0.182 0.583 0.531
Table7.ForecastingresultsofintermsofNMAE/NRMSEon Table9.ForecastingresultsintermsofNMAE/NRMSEonthe
ODE-drivenParticledataset. Salsa-dancingdataset.
Method One-step Multi-step Method One-step Multi-step
LLMTime 0.335/0.438 0.370/0.473 LLMTime 0.402/0.452 0.449/0.480
TimeGPT 0.351/0.445 0.392/0.490 TimeGPT 0.341/0.417 0.394/0.446
SVI 0.319/0.432 0.346/0.465 SVI 0.384/0.441 0.423/0.465
Hybrid-SINDy 0.340/0.431 0.372/0.487 Hybrid-SINDy 0.362/0.405 0.416/0.433
GRASS 0.151/0.224 0.193/0.270 GRASS 0.285/0.344 0.313/0.359
AMORE(ours) 0.184/0.265 0.217/0.302 AMORE(ours) 0.291/0.361 0.334/0.373
AMORE-MIO(ours) 0.146/0.217 0.186/0.259 AMORE-MIO(ours) 0.272/0.335 0.301/0.352
antofourmethod,i.e. AMORE-MIO,ontwomulti-object which share the same number of coefficients and similar
datasets (Liu et al., 2023), i.e. the ODE-driven Particle valuesasthegroundtruthinEq.(10). RERofdiscovered
datasetandtheSalsa-dancingdataset. equationsbyHybrid-SINDy,AMORE,andAMORE-MIO
are2.7e´2,6.1e´3,and4.3e´3,respectively,whichshows
6.2.1.ODE-DRIVENPARTICLEDATASET thatasamulti-objectextensionofAMORE,AMORE-MIO
consistentlyoutperformsAMOREandHybrid-SINDyfor
InODE-drivenparticlesystems,trajectoriesofparticlesare
equationdiscoveryandmodecategorizationinmulti-object
drivenbyOrdinaryDifferentialEquationswhereparticles
hybridsystemsthankstothespecially-designedinteraction
switchtheirdrivenequations/modeswhentheycollidewith
modelingofAMORE-MIO.Wefurthershowtheforecasting
each other. Detailed settings of the ODE-driven Particle
resultsinTable7. WecanseethatAMORE-MIOconsis-
datasetareinAppendixC.1.4. Wesummarizethesegmen-
tentlyachievesthelowestforecastingerrorsforbothone-
tation results on the dataset in Table 6. We can see that
stepandmulti-steppredictions. ComparedwithGRASS,
our methods including both AMORE and AMORE-MIO
AMORE-MIOcanobtainbetterresultsthankstotheintro-
achieve better time series segmentation results compared
ducedequationpriorsonthelatentmotiondynamics.
to Hybrid-SINDy and GRASS. Besides, AMORE-MIO
can outperform AMORE consistently across all metrics.
AMORE-MIOcategorizes4modesfromthesystemandthe
6.2.2.SALSA-DANCINGDATASET
discoveredequationsforeachmodeare TheSalsa-dancingdatasetcontainsfourmodes,i.e. “mov-
$ ingforward”,“movingbackward”,“clockwiseturning”,and
’’’&x9 “1.08x´0.92xy; y9 “´0.93y`1.11xy “counter-clockwiseturning”. Detailsofthedatasetarein
x9 “´0.17x3`2.00y3; y9 “´2.13x3´0.06y3 AppendixC.1.5. Wesummarizethesegmentationandfore-
’’’%x9
“0; y9 “2.00
Tca as bt li en 9g .r Wes eul ot bs so en rvt ehe siS ma il ls aa r- fid na dn ic ni gn sg inda tt ha is se rt ei an l-T wa ob rl le d8 via dn ed
o
x9 “0; y9 “´2.00
dataset,aswiththeODE-drivenparticledataset. AMORE-
8AmortizedEquationDiscoveryinHybridDynamicalSystems
Table10.Analysesonrobustnesstodifferentordersofpolynomial Table12.Comparisonsonmodelcomplexityregardingthenum-
ascandidatebasisfunctionsonMass-springHopperdataset. bersoflearnableparameters.
Polynomialorder 2 3 5 Method Numberofparameters
NMIÒ RERÓ NMIÒ RERÓ NMIÒ RERÓ
Hybrid-SINDy 0
Hybrid-SINDy 0.426 7.5e´3 0.384 8.1e´3 0.316 9.7e´3 AMORE(ours) 2,240
AMORE(ours) 0.934 2.1e´4 0.936 2.3e´4 0.933 2.8e´4 AMORE-MIO(ours) 2,512
GRASS 4,628
SVI 2,826
LLMTime 175billion(GPT-3)
Table11.Analysesonrobustnesstodifferentmaximalnumbersof
predefinedmodesonMass-springHopperdataset.
Numberofmodes 3 5 10 equationsbyourmodelare
NMIÒ RERÓ NMIÒ RERÓ NMIÒ RERÓ #
x9 “0.97x`1.02x2`1.08cospxq
AMORE(ours) 0.934 2.1e´4 0.932 2.0e´4 0.937 2.1e´4
x9 “0.05`1.12x`0.96ex
When we set the basis functions as polynomials order 3
MIOachievessignificantlyhighersegmentationaccuracies
without tcospxq,sinpxq,exu. The discovered equations
comparedtoHybrid-SINDyandAMORE.Differentfrom
by our model are x9 “ 0.92 ` x ` 0.76x2 and x9 “
previousdatasets,thesalsa-dancingsystemisnotgenerated
1.26 ` 1.31x ` 0.83x2 ` 0.34x3, respectively. We can
syntheticallybyequationswhileresultsshowthatstructural
seethatourmodelcanbeextendedtoequationdiscovery
learningintheformofequationsstillbenefitsforecasting
with more complex basis functions. When the candidate
comparedtopurelyautoregressivedata-drivenmethods,i.e.
basis functions are limited to polynomial functions, our
LLMTime,SVI,andGRASS.Qualitativeresultsofthedis-
model can discover approximated ones with more terms,
coveredequationsonthedancingdatasetareinFigure5.
complexity,anderrors.
6.3.AblationStudies
Modelcomplexityanalysis Thenumbersofparameters
Sensitivitytoorderofpolynomialfunctions. Totestthe usedinbaselinemethodsaresummarizedinTable12. As
sensitivityofourmethodtodifferentordersofpolynomials Hybrid-SINDyisnotadeeplearningmethodanddoesnot
as candidate basis functions, we conduct experiments on useneuralnetworks, itdoesnotinvolvelearnableparam-
theMass-springHopperdatasetbychangingtheorderof etersanddoesnotneedmuchdataforthetrainingofany
polynomialfunctionsto2,3,and5. Wepresentresultsin littleparametersthemodelhas. Thiscomesattheexpense
Table 10. We observe that AMORE consistently outper- thatHybrid-SINDytendstonotgeneralizebeyondsimple
formsHybrid-SINDy,whileAMOREisnotsensitivetothe dynamicalsettings,asshowninourexperimentsinthemain
polynomialorderscomparedtoHybrid-SINDy. paper. Whengivenacomplexdynamicalsettingwithsuffi-
cientdata,AMOREandAMORE-MIOperformbetterand
Sensitivity to number of dynamic modes We test the haveslightlyfewerparametersthantheotherdeeplearning-
robustnessofourmethodtodifferentmaximumnumbersof basedapproaches,exceptLLMTime.
modes,thatis3,5,and10,whilethetruenumberis2on
theMass-springHopperdataset. Theresultsofsegmenta- 7.ConclusionandFuturework
tionanddiscoveredequationsareinTable11. Wecansee
thatAMOREisimpervioustothismisspecification,which Inthispaper,wereformulatetheproblemofequationdis-
indicatesthatwecansetalargenumberofpossiblemodes covery in hybrid dynamical systems and propose an end-
whileAMOREcanstilllearnthoseneeded. to-endlearningframework, i.e. AmortizedEquationDis-
covery (AMORE) to jointly categorize motion dynamics
Sensitivity to more complex dynamical systems We anddiscoverequationsbymodelingcategoricalmodesand
originallyfollowedthesetupofHybrid-SINDy,whereall mode-switchingbehaviors. Besides,weextendourmethod
ofthedynamicscanbeapproximatedbypolynomialbasis tomulti-objectscenarios,i.e. AMORE-MIO,whichisun-
functions. However,ourmodelisnotlimitedtothesefunc- exploredbypreviousmethodsandamorenaturalsetting.
tions. Toshowresultsonmorecomplexdynamicalsystems, Extensiveexperimentson10hybridandnon-hybridsystems
weconductexperimentsonasyntheticdatasetwheretwo demonstratetheeffectivenessofourmethod. Futurework
modesaredrivenbyx9 “x`x2`cospxqandx9 “x`ex, canincludeequationdiscoverywithpartialknownknowl-
respectively. Wesetthebasisfunctionsaspolynomialsor- edge, equation discovery from videos of hybrid systems,
der 3 together with tcospxq,sinpxq,exu. The discovered andmorecomplexcandidatebasisfunctions.
9AmortizedEquationDiscoveryinHybridDynamicalSystems
ImpactStatement Ghahramani,Z.andHinton,G.E. Variationallearningfor
switchingstate-spacemodels. Neuralcomputation,12
Thispaperpresentsworkwhosegoalistoadvancethefield
(4):831–864,2000.
ofMachineLearningandDynamicalSystems. Thereare
manypotentialsocietalconsequencesofourwork,noneof Gruver, N., Finzi, M., Qiu, S., and Wilson, A. G. Large
whichwefeelmustbespecificallyhighlightedhere. language models are zero-shot time series forecasters.
arXivpreprintarXiv:2310.07820,2023.
Acknowledgements
Holmes,P.,Full,R.J.,Koditschek,D.,andGuckenheimer,
This work is financially supported by NWO TIMING J. Thedynamicsofleggedlocomotion: Models,analyses,
VI.Vidi.193.129. WealsothankSURFforthesupportin andchallenges. SIAMreview,48(2):207–304,2006.
usingtheNationalSupercomputerSnellius.
Juloski, A. L., Weiland, S., and Heemels, W. M. H. A
bayesian approach to identification of hybrid systems.
References
IEEETransactionsonAutomaticControl,50(10):1520–
Ackerson,G.andFu,K. Onstateestimationinswitching 1533,2005.
environments. IEEEtransactionsonautomaticcontrol,
Kaiser,E.,Kutz,J.N.,andBrunton,S.L. Sparseidentifica-
15(1):10–17,1970.
tionofnonlineardynamicsformodelpredictivecontrol
Ansari,A.F.,Benidis,K.,Kurle,R.,Turkmen,A.C.,Soh, inthelow-datalimit. ProceedingsoftheRoyalSocietyA,
H.,Smola,A.J.,Wang,B.,andJanuschowski,T. Deep 474(2219):20180335,2018.
explicitdurationswitchingmodelsfortimeseries. Ad-
vances in Neural Information Processing Systems, 34: Karniadakis, G. E., Kevrekidis, I. G., Lu, L., Perdikaris,
29949–29961,2021. P., Wang, S., and Yang, L. Physics-informed machine
learning. NatureReviewsPhysics,3(6):422–440,2021.
Bako,L.Identificationofswitchedlinearsystemsviasparse
optimization. Automatica,47(4):668–677,2011. Keeling,M.J.,Rohani,P.,andGrenfell,B.T. Seasonally
forceddiseasedynamicsexploredasswitchingbetween
Bongard,J.andLipson,H. Automatedreverseengineering attractors. PhysicaD:NonlinearPhenomena,148(3-4):
ofnonlineardynamicalsystems. ProceedingsoftheNa- 317–335,2001.
tionalAcademyofSciences,104(24):9943–9948,2007.
Kingma,D.P.andWelling,M. Auto-encodingvariational
Brunton,S.L.,Proctor,J.L.,andKutz,J.N. Discovering
bayes. arXivpreprintarXiv:1312.6114,2013.
governingequationsfromdatabysparseidentificationof
nonlineardynamicalsystems.Proceedingsofthenational Kipf,T.,Fetaya,E.,Wang,K.-C.,Welling,M.,andZemel,
academyofsciences,113(15):3932–3937,2016. R. Neuralrelationalinferenceforinteractingsystems. In
Internationalconferenceonmachinelearning,pp.2688–
Cortes,J. Discontinuousdynamicalsystems. IEEEControl
2697.PMLR,2018.
systemsmagazine,28(3):36–73,2008.
Koza,J.R.etal. GeneticprogrammingII,volume17. MIT
Course, K.andNair, P.B. Stateestimationofaphysical
pressCambridge,1994.
systemwithunknowngoverningequations. Nature,622
(7982):261–267,2023.
Kuhn, H. W. The hungarian method for the assignment
problem. Navalresearchlogisticsquarterly,2(1-2):83–
Dong,Z.,Seybold,B.,Murphy,K.,andBui,H. Collapsed
97,1955.
amortizedvariationalinferenceforswitchingnonlinear
dynamicalsystems. InInternationalConferenceonMa-
Langley,P. Data-drivendiscoveryofphysicallaws. Cogni-
chineLearning,pp.2638–2647.PMLR,2020.
tiveScience,5(1):31–54,1981.
Eddy, S. R. Hidden markov models. Current opinion in
Lemos,P.,Jeffrey,N.,Cranmer,M.,Ho,S.,andBattaglia,P.
structuralbiology,6(3):361–365,1996.
Rediscoveringorbitalmechanicswithmachinelearning.
Ferrari-Trecate,G.,Muselli,M.,Liberati,D.,andMorari,M. MachineLearning:ScienceandTechnology,4(4):045002,
Aclusteringtechniquefortheidentificationofpiecewise 2023.
affinesystems. Automatica,39(2):205–217,2003.
Liu, Y., Magliacane, S., Kofinas, M., and Gavves, E.
Garza,A.andMergenthaler-Canseco,M. Timegpt-1. arXiv Graph switching dynamical systems. arXiv preprint
preprintarXiv:2310.03589,2023. arXiv:2306.00370,2023.
10AmortizedEquationDiscoveryinHybridDynamicalSystems
Loiseau, J.-C. and Brunton, S. L. Constrained sparse Schmidt, M. and Lipson, H. Distilling free-form natural
galerkin regression. Journal of Fluid Mechanics, 838: lawsfromexperimentaldata. science,324(5923):81–85,
42–67,2018. 2009.
Lutter, M., Ritter, C., andPeters, J. Deeplagrangiannet- Toda, A. A. Susceptible-infected-recovered (sir) dynam-
works: Usingphysicsasmodelpriorfordeeplearning. ics of covid-19 and economic impact. arXiv preprint
arXivpreprintarXiv:1907.04490,2019. arXiv:2003.11221,2020.
VanDerSchaft,A.J.andSchumacher,H. Anintroduction
Mangan, N. M., Askham, T., Brunton, S. L., Kutz, J. N.,
tohybriddynamicalsystems,volume251. springer,2007.
andProctor,J.L. Modelselectionforhybriddynamical
systemsviasparseregression. ProceedingsoftheRoyal
Vidal,R.,Soatto,S.,Ma,Y.,andSastry,S. Analgebraicge-
SocietyA,475(2223):20180534,2019.
ometricapproachtotheidentificationofaclassoflinear
hybridsystems. In42ndIEEEInternationalConference
McMahon,A.,Robb,N.C.,etal. Reinfectionwithsars-cov-
onDecisionandControl(IEEECat.No.03CH37475),
2:Discretesir(susceptible,infected,recovered)modeling
volume1,pp.167–172.IEEE,2003.
usingempiricalinfectiondata. JMIRpublichealthand
surveillance,6(4):e21168,2020.
Novelli, N., Lenci, S., and Belardinelli, P. Boosting the
modeldiscoveryofhybriddynamicalsystemsinanin-
formedsparseregressionapproach. JournalofComputa-
tionalandNonlinearDynamics,17(5):051007,2022.
Oh,S.M.,Ranganathan,A.,Rehg,J.M.,andDellaert,F. A
variationalinferencemethodforswitchinglineardynamic
systems. TRGIT-GVU-05-16,2005.
Ohlsson, H. and Ljung, L. Identification of switched lin-
earregressionmodelsusingsum-of-normsregularization.
Automatica,49(4):1045–1050,2013.
Ozay,N.,Sznaier,M.,Lagoa,C.,andCamps,O. Aspar-
sificationapproachtosetmembershipidentificationofa
classofaffinehybridsystems. In200847thIEEECon-
ference on Decision and Control, pp. 123–130. IEEE,
2008.
Paoletti,S.,Juloski,A.L.,Ferrari-Trecate,G.,andVidal,
R. Identificationofhybridsystemsatutorial. European
journalofcontrol,13(2-3):242–260,2007.
Roll, J., Bemporad, A., and Ljung, L. Identification of
piecewiseaffinesystemsviamixed-integerprogramming.
Automatica,40(1):37–50,2004.
Rudy,S.H.,Brunton,S.L.,Proctor,J.L.,andKutz,J.N.
Data-driven discovery of partial differential equations.
Scienceadvances,3(4):e1602614,2017.
Sanfelice,R.G.etal. Analysisanddesignofcyber-physical
systems.ahybridcontrolsystemsapproach. InCyber-
physicalsystems:Fromtheorytopractice,pp.1–29.CRC
PressBocaRaton,FL,USA,2016.
Schaeffer,H.andMcCalla,S.G.Sparsemodelselectionvia
integralterms. PhysicalReviewE,96(2):023302,2017.
11AmortizedEquationDiscoveryinHybridDynamicalSystems
Appendix
A.MoreDetailsofAMORE
A.1.NeuralNetworkImplementation
Weuseneuralnetworkstomodelthejointgenerativeprobabilitiesofhybridsystemsinourmodel,i.e. Eq.(4). Forthe
initialstates,wemodeltheinitialpriordistributionsas:
ppz q“Catpz ;πq,
1 1
ppy |z q“ py ;µ ;Σ q,
1 1
N
1 z1 z1
whereCatand denotecategoricalandmultivariateGaussiandistributions,respectively. Wesetthepriordistributionof
N
ppz qasuniformtoencouragediversity.
1
Countvariablesandcounttransitionprobability. Toimplementthecountvariables,wesetacategoricaldistributionover
td ,¨¨¨ ,d uforeachmode,whered andd aretheminimalandmaximalnumbersoftimestepsbeforemaking
min max min max
amodeswitch. Thecounttransitionprobabilityppc t|c t´1,z t´1qismodeledasalearnablematrixPPRKˆpdmax´dmin`1q,
whichisfixedacrossalltimesteps. Eachtermρ pcqinPrepresentstheprobabilityofthek-thmodeswitchingtoanother
k
modewhenitscurrentcountisc. Theprobabilityofacountincrementatcountcformodekcanbecalculatedas
ρ pcq
µ pcq“1´ ř k .
k dmaxρ pdq
d“c k
Thecounttransitionprobabilityisthusdefinedas
#
µ pc q if c “c `1
k t´1 t t´1
ppc |c ,z “kq“ .
t t´1 t´1
1´µ pc q if c “1
k t´1 t
Modevariablesandmodetransitionprobability. Sincethemodevariablesz takeoneoutofK possiblevalues,we
t
model them as categorical variables, parameterized by mode transition matrix T at timestep t. The mode transition
t
probabilityismodeledas
#
δ if c ą1
ppz |z ,c ,y q“
zt“zt´1 t
,
t t´1 t t´1
Catpz ;T q if c “1
t t t
whereweresamplethemodesorpreservethemdependingonwhethercountvariablesareresetto1ornot. Wemodelthe
parametersT ofthecategoricaldistributionswithaneuralnetwork,i.e. asimpleMLP,T “f py qthattakesasinput
t t z t´1
theobservations. ThenetworkreturnsaKˆK transitionmatrixpertimestept,whererowscorrespondtopastmodesz
t´1
andcolumnscurrentmodesz . Eachtermτj,k inT representstheprobabilityofmodej switchingtomodekattimestept.
t t t ř
Tosatisfythepositivityτj,k ą0, @j,k “1,¨¨¨ ,K andℓ constraints τj,k “1, @j “1,...,K,weapplyatempered
t 1 k t
softmaxafterf ,i.e. ˝f p¨q.
z Sτz z
A.2.InferenceModelofAMORE
Weperformconditionallyexactinferenceforthetwodiscretelatentvariables,i.e. modesz andcountsc ,similarto
1:T 1:T
theforward-backwardprocedureforHMM(Eddy,1996). Conditionedonobservationsy ,theposteriorjointdistribution
1:T
p pz ,c |y q is calculated by modifying the forward-backward recursions to handle the joint hierarchical latent
θ 1:T 1:T 1:T
variables. Specifically,theforwardα andbackwardβ partsaredefinedas
t t
α pz ,c q“ppz ,c ,y q,
t t t t t 1:t
β pz ,c q“ppy |y ,z ,c q.
t t t t`1:T t t t
12AmortizedEquationDiscoveryinHybridDynamicalSystems
Specifically,theposteriorjointprobabilityofmodeandcountvariablesz,cconditionedonobservationsyiscalculatedas
ppz ,c |y q9ppz ,c ,y q
t t 1:T t t 1:T
“plpoozotoo,ocmt,oyooo1o:otnqplpooyooto`oo1o:oTom|yoto,oozooto,ocootnq
Forward Backward
“α pz ,c q¨β pz ,c q.
t t t t t t
Thederivativesoftheforwardsectionα pz ,c qare
t t t
α pz ,c q“ppz ,c ,y q
1 1 1 1 1 1
“δ ppz qppy |z q,
c1“1 1 1 1
α pz ,c q“ppz ,c ,y q
t t t ÿt t 1:t
“ ppz ,c ,y ,z ,c q
t t 1:t t´1 t´1
zt´ÿ1,ct´1
“ ppz ,c ,y qppc |c ,z qppz |z ,c ,y qppy |y ,z q
t´1 t´1 1:t´1 t t´1 t´1 t t´1 t t´1 t t´1 t
zt´1,ct´1 ÿ
“ppy |y ,z q α pz ,c qppc |c ,z qppz |z ,c ,y q
t t´1 t t´1 t´1 t´1 t t´1 t´1 t t´1 t t´1
«zt´1,ct´1
ÿ ÿ
“ppy |y ,z q δ ppz |z ,c ,y q p1´µ qα pz ,c q
t t´1 t ct“1 t t´1 t t´1 zt´1pct´1q t´1 t´1 t´1
zt´1 ff ct´1
`δ zt c´ t1 ą“ 1zt µ zt´1pc t´1qα t´1pz t´1,c t´1q ,
ct´1“ct´1
whereα pz ,c qcanbeexpressedbyα pz ,c qrecursivelywithstatestransitions.
t t t t´1 t´1 t´1
Thederivativesofthebackwardsectionβ pz ,c qare
t t t
β pz ,c q“1
T T T
β pz ,c q“ppy |y ,z ,c q
t t t ÿt`1:T t t t
“ ppy ,z ,c |y ,z ,c q
t`1:T t`1 t`1 t t t
zt`ÿ1,ct`1
“ ppc |c ,z qppz |z ,c ,y qppy |y ,z qppy |y ,z ,c q
t`1 t t t`1 t t t t`1 t t`1 t`2:T t`1 t`1 t`1
zt`ÿ1,ct`1
“ ppc |c ,z qppz |z ,c ,y qppy |y ,z qβ pz ,c q
t`1 t t t`1 t t`1 t t`1 t t`1 t`1 t`1 t`1
zt`1,ct`1 ÿ
“δ p1´µ pc qq ppz |z ,c ,y qppy |y ,z qβ pz ,c q
ct`1“1 zt t t`1 t t`1 t t`1 t t`1 t`1 t`1 t`1
ctědmin zt`1
`δ µ pc qppy |y ,z qβ pz ,c q,
ct`1“ct`1 zt t t`1 t t`1 t`1 t`1 t`1
zt`1“zt
whereβ pz ,c qcanbecomputedviaβ pz ,c qrecursivelywithstatestransitions.
t t t t`1 t`1 t`1
A.3.DerivationofOptimizationObjective
Theoptimizationobjectiveofourmodelistomaximizetheobservationlikelihoodlogppyqwithsparseregularizationon
coefficientsofcandidatebasisfunctions,wheretheobservationlikelihoodlogppyqcanbecalculatedas
logppyq“E rlogppyqs
ppz,c|yq
“E rlogppy,z,cqs´E rlogppz,c|yqs
ppz,c|yq ppz,c|yq
“E rlogppy,z,cqs,
ppz,c|yq
13AmortizedEquationDiscoveryinHybridDynamicalSystems
whereE rlogppz,c|yqsiscalculatedas
ppz,c|yq
ż ż
logppz,c|yq
E rlogppz,c|yqs“ ppz,c|yq dpz,cq“ logppz,c|yqdpz,cq“1“0.
ppz,c|yq
ppz,c|yq
FollowingMarkovianproperty,weexpandlogppy,z,cqovertimeandcalculateitas
logppy,z,cq“ logppy ,z ,c q
1:T 1:T 1:T
ÿT
“ logrppy |z qppz qs` logrppy |y ,z qppz |z ,c ,y qppc |c ,z qs.
1 1 1 t t´1 t t t´1 t t´1 t t´1 t´1
t“2
Finally,combinedwithexpectations,logppyqcanbecalculatedas
logppyq“E rlogppy,z,cqs,
ppz,c|yq
“E rlogppy ,z ,c qs
ÿppz1:T,c1:T|y1:Tq 1:T 1:T 1:T
“ ppz “k|y qlogrppy |z qppz “kqs
1 1:T 1 1 1
k
ÿT ÿ
` ξpk,j,u,vq logrppy |y ,z “kqppz “k|z “j,c “v,y qppc “v|c “u,z “jqs
t t´1 t t t´1 t t´1 t t´1 t´1
ÿt“2k,j,u,v
“ γpkq logrB pkq¨πpkqs
1
k
ÿT ÿ
` ξpk,j,u,vq logrB pkq¨A pk,j,vq¨C pj,u,vqs
t t t
t“2k,j,u,v
whereπpkq,γpkq,ξpk,j,u,vq,B pkq,A pk,j,vq,andC pj,u,vqaredefinedas
t t t
πpkq“ppz “kq,
1
γpkq“ppz “k|y q,
1 1:T
ξpk,j,u,vq“ppz“k,z “j,c “v,c “u|y q,
t t´1 t t´1 1:T
B pkq“ppy |y ,z “kq,
t t t´1 t
A pk,j,vq“ppz “k|z “j,c “v,y q,
t t t´1 t t´1
C pj,u,vq“ppc “v|c “u,z “jq.
t t t´1 t´1
πpkqistheinitialdiscretemodeprobability. B pkqisthecontinuousstatetransitionprobabilityconditionedondifferent
t
typesofdiscretemodesk. A pk,j,vqisthediscretemodetransitionprobability. C pj,u,vqisthemodedurationcount
t t
transitionprobability. Besides,γpkq“ppz “k|y qandξpk,j,u,vq“ppz“k,z “j,c “v,c “u|y qcanbe
1 1:T t t´1 t t´1 1:T
calculatedsimilarlytotheforwardandbackwardalgorithminHMMs(Eddy,1996)whichisdetailedinAppendixA.2.
B.MoreDetailsofAMORE-MIO
B.1.ExpansionofGenerativeModeloverObjects
ThejointgenerativeprobabilityofAMORE-MIOformulti-objecthybridsystemsisexpandedoverobjectsas
«
źN źN źN źN źT źN źN
ppy,z,c,eq“ ppyn|znq¨ ppznq¨ ppemÑnq¨ ppyn|yn ,znq¨ ppcn|cn ,zn q¨
1 1 1 1 t t´1 t t t´1 t´1
nl“ooo1oooooooooooooooonoo“oo1oooomooooonoo“oo1oomoo“oo1oooooooooooon t“2 n“1 n“1
Initialstates ff
źN ÿN źN ÿN
ppzn|zm ,cn,emÑn,ym ,yn q¨ ppemÑn|emÑn,vm ,vn q ,
t t´1 t t t´1 t´1 t t´1 t´1 t´1
n“1m“1 n“1m“1
14AmortizedEquationDiscoveryinHybridDynamicalSystems
where in the initial states, we model for each object n an initial mode and observation distributions, i.e. ppznq and
1
ppyn|znq. For each pair of interactions, ppemÑnq models the initial edge distribution. For later time steps t ě 2,
1 1 1
ppemÑn|emÑn,vm ,vn qmodelstheedgevariabletransitionprobabilityconditionedonnodestatestvm ,vn uin
t t´1 t´1 t´1 t´1 t´1
graph . ppzn|zm ,cn,emÑn,ym,nqmodelshowthemodesofobjectsareaffectedbythemodesofallotherobjects,con-
Gt t t´1 t t t´1
ditionedoncountvariablescn,edgevariablesemÑn,andobservationstym ,yn u. ppyn|yn ,znqandppcn|cn ,zn q
t t t´1 t´1 t t´1 t t t´1 t´1
modelforeachobjectanobservationtransitionprobabilityandcountvariabletransitionprobability.
B.2.NeuralNetworkImplementation
Implementations of ppyn|znq, ppznq, ppyn|yn ,znq, and ppcn|cn ,zn q in multi-object scenarios are the same
1 1 1 t t´1 t t t´1 t´1
as those in single-object scenarios. Next, we elaborate on how we implement the other terms, i.e. ppemÑnq,
1
ppemÑn|emÑn,vm ,vn q,andppzn|zm ,cn,emÑn,ym ,yn q.
t t´1 t´1 t´1 t t´1 t t t´1 t´1
Edgevariablesandedgetransitionprobability. Weimplementtheedgevariableeasacategoricaldistributionover
t1,¨¨¨ ,LuforLpossibleinteractiontypesincludingano-interactiontype. Wesetthepriordistributiontobehigherfor
no-interactionedgesinppemÑnqtoencouragesparsegraphs. Theedgetransitionprobabilityismodeledas
1
ppemÑn|emÑn,vm ,vn q“CatpemÑn; pf pemÑn,vm ,vn qqq,
t t´1 t´1 t´1 t Sτe e t´1 t´1 t´1
where The neural network f takes emÑn, vm , and vn as input and outputs the probabilities of all possible edge
e t´1 t´1 t´1
typesattimestept,whicharefurtherpost-processedbyatemperedsoftmaxfunction withtemperatureτ toensure
Sτe e
normalization. Inpractice,theedgetransitionnetworkf isasinglehiddenlayerMLP.
e
Extensionofmodetransitionprobability. AftergettingemÑnbytheedgetransitionprobability,weshowhowemÑn
t t
affectsthemod-switchingbehaviors. Wemodelthemodetransitionprobabilityinmulti-objecthybridsystemsas
#
ppzn|zm ,cn,emÑn,ym ,yn q“ δ z tn“z tn ´1 ř if cn t ą1 ,
t t´1 t t t´1 t´1 Catpzn; p emÑnf pym ,yn qq if cn“1
t Sτz l t,l l t´1 t´1 t
whereδand areaKroneckerfunctionandatemperedsoftmaxfunction. emÑndenotestheprobabilityofeachedgetype
Sτz t,l
l. Wesetaneuralnetworkf foreachedgetypel(totallyL)tomodeldifferentinteractioneffects,whicharenormalizedby
l
emÑntoaggregateeffectsfromalltheinteractiontypes.
t,l
B.3.InferenceModelofAMORE-MIO
Approximateinferenceofedgevariables. Weuseagraphneuralnetworkf pyqtoconductapproximateinferenceof
ϕe
edgevariablese,i.e. q pe|yq. Thenodeembeddingsinthelatentgraph aretheobservationsy,andtheedgeembeddings
ϕe Gt
arecalculatedbytworoundsofmessage-passing
h1 “fembpynq,
n ϕe t
v Ñe: h1 “fe,1prh1 ,h1sq,
mÑn ϕz m n
ÿN
eÑv: h2 “fv,1p h1 q,
n ϕe mÑn
m“1
v Ñe: h2 “fe,2prh2 ,h2sq,
mÑn ϕe m n
whereh2 isfurtherprocessedbyatemperedGumbelsoftmaxsoftmaxpph2 `gq{τqtoachieveq pe|yq,tobe
mÑn mÑn ϕe
morespecificq pemÑn|ym,ynq. Here,weusecontinuousrelaxationandreparameterizationofdiscretedistributionsfor
ϕe t t t
gradient backpropagation (Kipf et al., 2018). g is a vector sampled from a Gumbelp0,1q distribution and the softmax
temperatureτ controlsrelaxationsmoothness.
Exactinferenceofmodeandcountvariables. Giventheapproximateedgevariablese˜„q pe|yq,wedoexactinference
ϕe
ofthemodeandcountvariablesp pz,c|y,e˜q. Similartothesingle-objectscenarios,theconditionaljointdistributionis
θ
15AmortizedEquationDiscoveryinHybridDynamicalSystems
calculatedbymodifyingtheforward-backwardalgorithm. Specifically,theforwardα andbackwardβ arecalculatedas
t t
α
pz1:N,c1:Nq“ppz1:N,c1:N,y1:N,e1:N2
q,
t t t t t 1:t 1:t
β pz1:N,c1:Nq“ppy1:N |y1:N,z1:N,c1:N,e1:N2 q.
t t t t`1:T t t t t
Specifically,thejointprobabilityofmodeandcountvariablesz,cconditionedonobservationsyandapproximateedge
variableseiscalculatedas
ppz ,c |y ,e q9ppz ,c ,y ,e q
t t 1:T 1:T t t 1:T 1:T
“lppoozotoo,ocooto,my 1oo:to,ooeoo1o:otnqlppooyooto`oo1o:oToo,ooeootm`1o:oToo|oyooto,oozotoo,ocontq
Forward Backward
“α pz ,c q¨β pz ,c q.
t t t t t t
Thederivativesoftheforwardsectionα pz ,c qiscalculatedas:
t t t
α pz ,c q“ppz ,c ,y ,e q
1 1 1 1 1 1 1
“ppz1:N,c1:N,y1:N,e1:N2
q
1 1 1 1
“δ ppz1:Nqppe1:N2 qppy1:N|z1:Nq
c1:N“1 1 1 1 1
1
źN
“δ ppz1:Nqppe1:N2 q ppyn|znq
c1:N“1 1 1 1 1
1
n“1
α pz ,c q“ppz ,c ,y ,e q
t t t t t 1:t 1:t
“ppz1:N,c1:N,y1:N,e1:N2
q
ÿt t 1:t 1:t
“ ppz1:N,c1:N,y1:N,e1:N2 ,z1:N,c1:Nq
t t 1:t 1:t t´1 t´1
z1:N,c1:N
t´1 t´1«
ÿ
“ ppz1:N,c1:N,y1:N ,e1:N2 qppy1:N|y1:N,z1:Nqppz1:N|z1:N,c1:N,y1:N,e1:N2 q
t´1 t´1 1:t´1 1:t´1 t t´1 t t t´1 t t´1 t
z1:N,c1:N
t´1 t´1 ff
¨ppc1:N|c1:N,z1:Nqppe1:N2 |e1:N2 ,z1:N,y1:Nq
t t´1 t´1 t t´1 t´1 t´1
«
ÿ źN źN źN
“ α pz ,c q¨ ppyn|yn ,znq¨ ppzn|zm ,cn,ym ,yn ,emÑnq¨
t´1 t´1 t´1 t t´1 t t t´1 t t´1 t´1 t
z1:N,c1:N n“1 n“1m“1
t´1 t´1 ff
źN źN źN
¨ ppcn|cn ,zn q ppemÑn|emÑn,zm ,zn ,cm ,cn ,ym ,yn q ,
t t´1 t´1 t t´1 t´1 t´1 t´1 t´1 t´1 t´1
n“1 n“1m“1
whereα pz ,c qarecalculatedbyα pz ,c qrecursivelywithstatestransitions.
t t t t´1 t´1 t´1
16AmortizedEquationDiscoveryinHybridDynamicalSystems
Thederivativesofthebackwardsectionβ pz ,c qiscalculatedas
t t t
β pz ,c q“1
T T T
β pz ,c q“ppy ,e |y ,z ,c q
t t t t`1:T t`1:T t t t
“ppy1:N ,e1:N2 |y1:N,z1:N,c1:Nq
ÿt`1:T t`1:T t t t
“ ppy1:N ,e1:N2 ,z1:N,c1:N|y1:N,z1:N,c1:Nq
t`1:T t`1:T t`1 t`1 t t t
z1:N,c1:N
t`1 t`1«
ÿ
“
ppy1:N|y1:N,z1:Nqppz1:N|z1:N,c1:N,y1:N,e1:N2
q
t`1 t t`1 t`1 t t`1 t t`1
z1:N,c1:N
t`1 t`1 ff
¨ppc1:N|c1:N,z1:Nqppe1:N2 |e1:N2 ,z1:N,y1:Nqppy1:N ,e1:N2 |y1:N,z1:N,c1:Nq
t`1 t t t`1 t t t t`2:T t`2:T t`1 t`1 t`1
«
ÿ źN źN źN
“ ppyn |yn,zn q¨ ppzn |zm,cn ,ym,n,emÑnq
t`1 t t`1 t`1 t t`1 t t`1
z1:N,c1:N n“1 n“1m“1
t`1 t`1 ff
źN źN źN
¨ ppcn |cn,znq¨ ppemÑn|emÑn,zm,zn,cm,cn,ym,ynq β pz ,c q ,
t`1 t t t`1 t t t t t t t t`1 t`1 t`1
n“1 n“1m“1
whereβ pz ,c qiscomputedviaβ pz ,c qrecursivelybystatetransitions.
t t t t`1 t`1 t`1
B.4.DerivationofOptimizationObjective
Learnableparametersofourmodelareoptimizedbymaximizingtheevidencelowerbound(ELBO)withsparseregularization
on coefficients of candidate basis functions where the derivatives of ELBO are as follows. For brevity, y, z, c, and e
representsy1:N,z1:N,c1:N,ande1:N2 respectively. N isthenumberofobjects. T isthenumberoftimesteps.
1:T 1:T 1:T 1:T
ELBO “logp pyq´D rq pz,c,e|yq}p pz,c,e|yqs
ż θ KL ϕ θ ż
q pz,c,e|yq
ϕ
“ q pz,c,e|yqlogp pyqdpz,c,eq´ q pz,c,e|yqlog dpz,c,eq
ϕ θ ϕ
p pz,c,e|yq
ż θ
“ q pz,c,e|yqrlogp pz,c,e,yq´logq pz,c,e|yqs dpz,c,eq
ϕ θ ϕ
“E rlogp pz,c,e,yq´logq pz,c,e|yqs
qϕpz,c,e|yq θ ϕ
“E rlogp py,eqp pz,c|y,eq´logq pe|yqp pz,c|y,eqs
qϕpe|yqpθpz,c|y,eq θ θ ϕ θ
“E rlogp py,eq´logq pe|yqs
qϕpe|yq θ ϕ
“E rlogp py,eqs`Hpq pe|yqq,
qϕpe|yq θ ϕ
wherelogp py,eqisajointlikelihood, andHpq pe|yqqisaconditionalentropyfortheapproximateposteriorofedge
θ ϕ
variablee.
B.4.1.TRAININGOFELBO
Weusethemini-batchstochasticgradientdescentalgorithmfortrainingofELBO.Thegradientswithrespecttoθorϕin
ELBOarecalculatedas
“ ‰
ELBO “ E logp py,eq “E logp py,eq,
∇θ ∇θ “ qϕpe|yq θ qϕpe|yq∇θ‰ θ
ELBO “ E logp py,eq`Hpq pe|yqq
∇ϕ ∇ϕ“ qϕpe|yq θ ‰ ϕ
“ E logp py,eq ` Hpq pe|yqq
∇ϕ qϕpe|yq θ ∇ϕ ϕ
“E r logp pe,y pe,ϵqqs` Hpq pe|yqq,
ϵ„ ϕ θ ϕ ϕ ϕ
N ∇ ∇ “ ‰
whereweusethereparameterizationtrick(Kingma&Welling,2013)tocalculatethegradientsof E logp py,eq .
∇ϕ qϕpe|yq θ
Hpq pe|yqqisanentropyloss. Amongthederivativeterms,thechallengingpartisthegradientsofjointprobability
ϕ ϕ
∇
17AmortizedEquationDiscoveryinHybridDynamicalSystems
logp py,eq,whichiscalculatedas
θ θ
∇
logppy,eq“E r logppy,eqs
∇
ppz,c|y,eq
∇
“E r logppy,e,z,cqs´E r logppz,c|y,eqs
ppz,c|y,eq
∇
żppz,c|y,eq
∇
logppz,c|y,eq
“E r logppy,e,z,cqs´ ppz,c|y,eq∇ dpz,cq
ppz,c|y,eq
∇ ppz,c|y,eq
“E r logppy,e,z,cqs,
ppz,c|y,eq
∇
FollowingtheMarkovianproperty,weunfoldthejointlikelihoodppy,e,z,cqovertimeas:
logppy,e,z,cq
∇
“ logppy1:N,e1:N2 ,z1:N,c1:Nq
∇ 1:T 1:T 1:T 1:T „
“ ‰ ÿT
“ log ppy1:N|z1:Nqppz1:Nq ` log ppy1:N|y1:N,z1:Nqppz1:N|z1:N,c1:N,y1:N,e1:N2 q¨
∇ 1 1 1 ∇ t t´1 t t t´1 t t´1 t
t“2 ȷ
ppc1:N|c1:N,z1:Nqppe1:N2 |e1:N2 ,z1:N,y1:Nq
t t´1 t´1 t t´1 t´1 t´1
« ff «
źN źN ÿT źN źN źN
“ log ppyn|znq¨ ppznq ` log ppyn|yn ,znq¨ ppzn|zm ,cn,ym ,yn ,emÑnq¨
∇ 1 1 1 ∇ t t´1 t t t´1 t t´1 t´1 t
n“1 n“1 t“2 n“1 n“1m“1 ff
źN źN źN
ppcn|cn ,zn q¨ ppemÑn|emÑn,zm ,zn ,cm ,cn ,ym ,yn q ,
t t´1 t´1 t t´1 t´1 t´1 t´1 t´1 t´1 t´1
n“1 n“1m“1
whereedgevariablesevolvebasedonallpreviousstatesofbothobjects. Wemodeltheinfluencesofinteractionsbetween
eachpairofobjectsbyppzn|zm ,cn,ym ,yn ,emÑnqwithoutinstantaneousdependences. Combiningwithexpectation,
t t´1 t t´1 t´1 t
logppy,eqisfinallycalculatedas
∇
logppy,eq“E r logppy,e,z,cqs
∇ ppz,c|y,eq ∇ ” ı
“E logppy1:N,e1:N2 ,z1:N,c1:Nq
ppz1 1: :N T,c1 1: :N T|y 11 :: TN,e1 1: :N T2q ∇ 1 «:T 1:T 1:T 1:T ff
ÿ źN
“ ppz1:N “k|y1:N,e1:N2 q log ppyn|zn “knq¨ppz1:N “kq
1 1:T 1:T ∇ 1 1 1
k « n“1
ÿT ÿ źN źN źN
` ξpk,j,u,vq log ppemÑn|emÑn,zm,n “km,n,ym,nq¨ ppyn|yn ,zn “knq
∇ t t´1 t t t t´1 t
t“2k,j,u,v n“1m“1 n“1 ff
źN źN źN
¨ ppzn“kn|zm “jm,cn“vn,ym,n,emÑnq¨ ppcn“vn|cn “un,zn “jnq
t t´1 t t´1 t´1 t t´1 t´1
ÿn“1m“1 n“1
“ γpkq logrB pknq¨πpkqs
1
∇
k
ÿT ÿ
` ξpk,j,u,vq logrB pkq¨E pkq¨A pk,j,vq¨C pu,v,jqs,
t t t t
∇
t“2k,j,u,v
18AmortizedEquationDiscoveryinHybridDynamicalSystems
whereπpkq,γpkq,ξpk,j,u,vq,B pkq,E pkq,A pk,j,vq,andC pu,v,jqaredefinedas
t t t t
πpkq“ppz1:N “kq,
1
γpkq“ppz1:N “k|y1:N,e1:N2 q,
1 1:T 1:T
ξpk,j,u,vq“ppz1:N“k,z1:N“j,c1:N“v,c1:N“u|y1:N,e1:N2
q,
t t´1 t t´1 1:T 1:T
źN
B pkq“ ppyn|yn ,zn “knq,
t t t´1 t
n“1
źN źN
E pkq“ ppemÑn|emÑn,zm,n “km,n,ym,nq,
t t t´1 t t
n“1m“1
źN źN
A pk,j,vq“ ppzn“kn|zm “jm,cn“vn,ym,n,emÑnq,
t t t´1 t t´1 t´1
n“1m“1
źN
C pu,v,jq“ ppcn“vn|cn “un,zn “jnq,
t t t´1 t´1
n“1
Amongthese,πpkqistheinitialjointdiscretemodeprobability. B pkqistheobservationtransitionprobabilityconditioned
t
onmotionmodesk. E pkqisthediscreteedgetransitionprobability. A pk,j,vqisthediscretemotionmodetransition
t t
probability. C pu,v,jqisthemodecounttransitionprobability. Besides,γpkqandξpk,j,u,vqareconditionalposterior
t
distributions,whichcanbecalculatedbytheforward-backwardalgorithminAppendixB.3.
C.MoreExperiments
C.1.DetailsofDatasets
Figure6. AnillustrationofMass-springhoppersystem(Bruntonetal.,2016).
C.1.1.MASS-SPRINGHOPPER
Figure6showsanillustrationofaMass-springsystemthatcontainstwomotionmodes,i.e. flyingandcompression. A
minimalmodeloftheMass-springhoppersystemisdefinedas
#
´kpx´x q´mg, xďx
0 0
mx:“ ,
´mg, xąx
0
wherek,m,andgarethespringconstant,mass,andgravity,respectively. x istheunstretchedspringlength,whichdefines
0
theflyingxąx andcompressionxďx modes. Afterscalingbyκ“kx {mg,theequationsabovebecomes
0 0 0
#
1´κpy´1q, y ď1
y:“ .
´1, y ą1
FollowingHybrid-SINDy(Manganetal.,2019),wesetκ“10fordatageneration. Denotingyaslandy9 asv,thusthe
targetclosed-formordinarydifferentialequationsare
#
l9“v and v9 “11´10l, lď1
(8)
l9“v and v9 “´1, lą1
19AmortizedEquationDiscoveryinHybridDynamicalSystems
Thegeneratedpositionsandvelocitiesareconcatenatedrl,vsandusedasobservations. Insteadofgeneratingonlyafew
samplesinHybrid-SINDy(Manganetal.,2019)(3fortrainingand5forvalidation),wescaleupthedatasetsandsample
240initialconditionsfromtherangesp0.5,3qandp´1,1qforpositionsaandvelocitiesb,respectively. Amongthem,200
samplesarefortraining,20forvalidation,and20fortesting. Thesystemissimulatedtogenerate150timestepsforeach
timeseries,withsamplingintervalsof “0.033. WeaddGaussiannoisewithmeanzeroandstandardderivation10´6to
τ
△
generatedsamples. Bydefault,weusethefirst100timestepsascontextandpredictthefollowingnext50timestepsone
byonebasedonthegroundtruthoftheprevioustimestep,i.e. one-stepprediction. Bydefault,theorderofpolynomial
functionsissetas2,andthemaximalnumberofpossiblemodesis3.
C.1.2.SUSCEPTIBLE,INFECTEDANDRECOVERED(SIR)DISEASEDATASET
TheSIRdiseasemodelintheepidemiologicalcommunityhasbeenwidelystudiedintheliterature(Toda,2020;McMahon
etal.,2020). Themodelcanbedefinedas
β
S9 “vN ´ t IS´dS,
N
β
I9“ t IS´pγ`dqI,
N
R9 “γI´dR,
wheretherateoftransmissionβ istime-varying,whichtakestwodiscretevaluesaccordingtowhethertheschoolisin
t
sessionornot
#
βˆ¨p1`bq, tPschool in session,
β “
t βˆ{p1`bq, tPschool out of session.
FollowingHybrid-SINDy(Manganetal.,2019),fordatasetgeneration,theratesthatdefineatwhichstudentsenterand
leavethepopulationaresetasv “1{365andd“1{365. ThetotalpopulationofstudentsissetasN “1000. Therecovery
rateissetasγ “1{5assuming5daysistheaverageinfectiousperiod. Thebasetransmissionrateissetasβˆ“9.336and
b“0.8tunesthetransmissionratechange. FollowingHybrid-SINDy(Manganetal.,2019),theconcatenationrS,IsofS
andI areusedasobservations. Thusthetargetclosed-formordinarydifferentialequationsare
#
S9 “2.74´0.0168IS´0.0027S and I9“0.0168IS´0.20I, tPschool in session
(9)
S9 “2.74´0.0052IS´0.0027S and I9“0.0052IS´0.20I, tPschool out of session.
Inaschoolyear,thein-classperiodsare35-155and225-365days. Thebreakperiodsare0-35and155-225days. Insteadof
creatingonlyonetimeseriesfortrainingandoneforvalidationinHybrid-SINDy,wescaleupthedatasetsandsample240
initialconditionsforS ,I ,andR . Forinstance,ineachsample,wefirstsampleaR fromtherangep900,980q,andthen
0 0 0 0
sampleaI fromtherangep0,1000´R q,andthencalculateS byS “1000´R ´I . Wesimulateeachtimeseries
0 0 0 0 0 0
for2yearswithadailyinterval,thusproducing730timestepsforeachtimeseries. Weaddarandomperturbationtothe
startofeachsessionbychangingthestatesofS,I andRbyeither-2,-1,0,1,or2,independently. Bydefault,weusethe
first600timestepsascontextandpredictthenext130timestepsonebyonebasedonthegroundtruthoftheprevioustime
step,i.e. one-stepprediction. Bydefault,theorderofpolynomialfunctionsissetas2,andthemaximalnumberofpossible
modesis3forourmethods.
C.1.3.NON-HYBRIDPHYSICALSYSTEMS
FollowingCourse&Nair(2023),non-hybridphysicalsystemsincludetheCoupledlinear,Cubicoscillator,Lorenz’63,Hopf
bifurcation,Seklovglycolysis,andDuffingoscillator.EquationsofaDampedlinearoscillatoraredefinedasx9 “´0.1x`2y
andy9 “´2x´0.1y. ADampedcubicoscillatorisx9 “´0.1x3`2y3andy9 “´2x3´0.1y3. Acoupledlinearsystem
isx: “ ´6x`2y andy: “ 2x´6y. ADuffingoscillatorisx9 “ y andy9 “ ´x3 `x´0.35y. ASelkovglycolysisis
x9 “ ´x`0.08y`x2y andy9 “ 0.6´0.08y´x2y. ALorenz’63systemisx9 “ 10y´10x, y9 “ 28x´xz´y, and
z9 “xy´2.67z. AHopfbifurcationisx9 “0.5x`y´x3´xy2andy9 “´x`0.5y´x2y´y3. Wereferreaderstosee
thedetailsin(Course&Nair,2023). Bydefault,theorderofpolynomialfunctionsoftheCoupledlinear,Cubicoscillator,
Lorenz’63,Hopfbifurcation,Seklovglycolysis,andDuffingoscillatorare2,3,2,3,3,and3,respectivelyforourmethods.
20AmortizedEquationDiscoveryinHybridDynamicalSystems
C.1.4.ODE-DRIVENPARTICLEDATASET
FollowingGRASS(Liuetal.,2023),OrdinaryDifferentialEquationsareintroducedasmotionmodestogeneratetrajectories
ofparticles,i.e. Lotka-Volterra,Spiral,andBouncingBall
Lotka´Volterra: x9 “x´xy; y9 “´y`xy,
Spiral: x9 “´0.1x3`2y3; y9 “´2x3´0.1y3,
Bouncing Ball`: x9 “0; y9 “2,
Bouncing Ball´: x9 “0; y9 “´2 (10)
Ballsareintroducedonasquared2dcanvasofsize64˚64whicharewithradiusr andwhoselocationsarerandomly
initialized. Trajectoriesofballsaregeneratedbynumericalvaluesofdifferentequationsovertimewhicharemappedtothe
canvasfield. Tosimulatemode-switchingbehaviors,thedrivenODEmodesoftwoobjectsareswitchedwhentheycollidein
thecanvas. DifferentfromGRASS(Liuetal.,2023),onemodeBouncing BallisregardedastwomodesBouncing Ball`
and Bouncing Ball´ in this work as they have different explicit equations for equation discovery. In summary, 4,928
samplesarefortraining,191samplesforvalidation,and204samplesfortesting. Eachtrajectoryhas150timestepswith10
framespersecond. Bydefault,theorderofpolynomialfunctionsissetas3,andthemaximalnumberofpossiblemodesis5
forourmethods.
C.1.5.SALSA-DANCINGDATASET
FollowingGRASS(Liuetal.,2023),fourmodesareannotatedandusedintheSalsa-dancingdataset,i.e. “movingforward”,
“movingbackward”,“clockwiseturning”,and“counter-clockwiseturning”. Insummary,1,321samplesarefortraining
and156samplesarefortesting. Eachsamplehas100timesteps,amongwhich80forcontextandtheremaining20for
predictionwith5framespersecond. Thecoordinatesoftheskeletaljointsofdancersin3Dspaceareasobservations. In
practice,forallmethods,weutilizetworepresentativejoints,i.e. righthipandlefthip. Bydefault,theorderofpolynomial
functionsissetas3,andthemaximalnumberofpossiblemodesis5forourmethods.
C.2.MoreImplementationDetails
Foreachdataset,wesetdifferentnumbersofmodesK andordersofpolynomialfunctionsDforourmodel. Bydefault,
K “ 3andD “ 2fortheMass-springHopperdataset. K “ 3andD “ 2fortheSIRdataset. DoftheCoupledlinear,
Cubicoscillator,Lorenz’63,Hopfbifurcation,Seklovglycolysis,andDuffingoscillatorare2,3,2,3,3,and3,respectively.
K “5andD “3fortheODE-drivenparticledataset. K “5andD “3fortheSalsa-dancingdataset.
C.3.StatisticsofExperiments
C.3.1.MASS-SPRINGHOPPER
ExperimentswithstatisticsontheMass-springHopperdatasetarereportedinTables13and14,whichareextendedversions
ofTables1and2inthemainpaper.
Table13. SegmentationresultswithstatisticsonMass-springHopperdataset.
Method NMIÒ ARIÒ AccuracyÒ F 1Ò
Hybrid-SINDy 0.426 0.383 0.705 0.691
AMORE(ours) 0.928˘0.011 0.967˘0.013 0.991˘0.005 0.993˘0.007
Table14. ForecastingresultswithstatisticsonMass-springHopperdataset.
Method NMAEÓ NRMSEÓ
LLMTime 0.113˘0.032/0.305˘0.036 0.417˘0.051/0.454˘0.072
SVI 0.068˘0.016/0.075˘0.011 0.148˘0.023/0.262˘0.030
AMORE(ours) 0.008˘0.003/0.039˘0.008 0.026˘0.005/0.059˘0.006
21AmortizedEquationDiscoveryinHybridDynamicalSystems
C.3.2.SIRDISEASE
ExperimentswithstatisticsontheSIRdiseasedatasetarereportedinTables15and16,whichareextendedversionsof
Tables3and4inthemainpaper.
Table15. SegmentationresultswithstatisticsontheSIRdiseasedataset.
Method NMIÒ ARIÒ AccuracyÒ F 1Ò
Hybrid-SINDy 0.296 0.283 0.538 0.519
AMORE(ours) 0.475˘0.027 0.483˘0.032 0.731˘0.054 0.735˘0.051
Table16. ForecastingresultsofSusceptible/InfectedwithstatisticsontheSIRdiseasedataset.
Method NMAEÓ NRMSEÓ
LLMTime 0.352˘0.073/0.396˘0.091 0.481˘0.084/0.523˘0.096
SVI 0.257˘0.031/0.273˘0.054 0.355˘0.050/0.401˘0.078
AMORE(ours) 0.088˘0.012/0.113˘0.018 0.142˘0.029/0.181˘0.035
C.4.AdditionalAblationStudies
C.4.1.SAMPLINGINTERVALSANALYSIS
Inourexperiments,wefollowedtheexperimentalsetupofHybrid-SINDyonthesamplingintervalsoftheMass-spring
HopperdatasetandtheSIRdiseasedataset. Thatmeansweusetheirstandardsamplingintervals∆ ,e.g. ∆ “0.033on
t t
theMass-springHopperdataset. InTable17,wereportthesegmentationcomparisonresultswhen∆ increases. Wedouble
t
theprevious∆ eachtimeandthusgett0.033,0.066,0.132,0.264u. Wecanseethatwhen∆ ě0.132,thesegmentation
t t
performanceofHybrid-SINDydecreasesconsiderablyduetothetemporalpatterndisruption,whileourmodelhasasmaller
decreaseinperformance. When∆ increases(e.g. ∆ ě0.132),thediscretizationobviouslydisruptstheoriginaltemporal
t t
patternsoftimeseries. Thus,afterlearningonthediscretization,themodelshowssignificantlydecreasedperformanceon
labelsthatareannotatedbasedontheoriginaltemporalpatterns.
Table17. Analysesof∆ onsegmentationresultsoftheMass-springHopperdataset.
t
Samplinginterval∆ t Method NMIÒ ARIÒ AccuracyÒ F 1Ò
0.033 Hybrid-SINDy 0.426 0.383 0.705 0.691
0.033 AMORE(ours) 0.928˘0.011 0.967˘0.013 0.991˘0.005 0.993˘0.007
0.066 Hybrid-SINDy 0.422 0.385 0.701 0.697
0.066 AMORE(ours) 0.925˘0.017 0.973˘0.014 0.986˘0.007 0.982˘0.010
0.132 Hybrid-SINDy 0.235 0.201 0.447 0.413
0.132 AMORE(ours) 0.458˘0.021 0.369˘0.016 0.627˘0.013 0.644˘0.017
0.264 Hybrid-SINDy 0.226 0.183 0.382 0.376
0.264 AMORE(ours) 0.417˘0.015 0.335˘0.008 0.574˘0.020 0.580˘0.012
C.4.2. NUMBEROFTRAININGSAMPLESANALYSIS
Toanswerthequestion: “GiventhesignificantlysmallerdatasetsusedbyHybrid-SINDy,cantheproposedmethodmaintain
thislevelofperformancedifference?”,wererunexperimentsontheMass-springHopperdatasetbyvaryingthenumberof
samplesinthetrainingsetfrom3(thesameasHybrid-SINDy)to20and200. Thecomparisonresultsaresummarizedin
Tables18,19,and20.Inthefew-shotsettingwithaverylownumberofsamples,e.g.3samples,Hybrid-SINDyoutperforms
AMORE.Thisisexpectedandacommonlimitationofdeeplearningmethods,whichusuallyrequirelargernumbersof
samplesfortraining. Ontheotherhand,whengivenmoresamples,e.g. largerthan20,AMOREoutperformsHybrid-SINDy
consistently.
22AmortizedEquationDiscoveryinHybridDynamicalSystems
Table18. AnalysesofnumbersoftrainingsamplesonsegmentationresultsoftheMass-springHopperdataset.
Numberoftrainingsamples Method NMIÒ ARIÒ AccuracyÒ F 1Ò
3 Hybrid-SINDy 0.425 0.377 0.693 0.684
3 AMORE(ours) 0.238˘0.052 0.217˘0.065 0.474˘0.134 0.429˘0.110
20 Hybrid-SINDy 0.422 0.383 0.698 0.693
20 AMORE(ours) 0.774˘0.037 0.762˘0.025 0.846˘0.094 0.853˘0.071
200 Hybrid-SINDy 0.426 0.383 0.705 0.691
200 AMORE(ours) 0.928˘0.011 0.967˘0.013 0.991˘0.005 0.993˘0.007
Table19.AnalysesofnumbersoftrainingsamplesonforecastingresultsofLocation/VelocityontheMass-springHopperdataset.
Numberoftrainingsamples Method NMAEÓ NRMSEÓ
3 LLMTime 0.113˘0.032/0.305˘0.036 0.417˘0.051/0.454˘0.072
3 SVI 0.173˘0.039/0.341˘0.053 0.450˘0.081/0.481˘0.094
3 AMORE(ours) 0.091˘0.018/0.160˘0.026 0.315˘0.049/0.348˘0.042
20 LLMTime 0.113˘0.032/0.305˘0.036 0.417˘0.051/0.454˘0.072
20 SVI 0.094˘0.020/0.147˘0.024 0.302˘0.038/0.381˘0.044
20 AMORE(ours) 0.036˘0.012/0.057˘0.018 0.106˘0.025/0.129˘0.031
200 LLMTime 0.113˘0.032/0.305˘0.036 0.417˘0.051/0.454˘0.072
200 SVI 0.068˘0.016/0.075˘0.011 0.148˘0.023/0.262˘0.030
200 AMORE(ours) 0.008˘0.003/0.039˘0.008 0.026˘0.005/0.059˘0.006
Table20.Analysesofnumbersoftrainingsamplesonreconstructionerrors(RER)ofdiscoveredequationsontheMass-springHopper
dataset.Numbersareofe´3.
Numberoftrainingsamples Method RER(e´3)Ó
3 Hybrid-SINDy 8.3
3 AMORE(ours) 17.2˘2.4
20 Hybrid-SINDy 8.2
20 AMORE(ours) 5.1˘0.6
200 Hybrid-SINDy 7.5
200 AMORE(ours) 2.4˘0.3
C.4.3.COUNTVARIABLESANALYSIS
ThecountvariablesareintroducedbyREDSDS(Ansarietal.,2021)tolearnthedurationdistributionsofeachmodefrom
thedataandtoavoidfrequentmode-switchingbehaviors. Weshowbelowsomeablationsstudiesoncountvariablesinthe
Mass-springHoppersystem,wheretheflyingmodeusuallytakesmorethantwiceasmanytimestepsasthecompression
mode. Toquantitatively compare the discovered equations, we first report theequation reconstruction error (RER) for
Hybrid-SINDy,AMORE,andAMOREw/ocountvariable,whicharerespectively7.5e´3,2.4e´4,and2.8e´4. Wecansee
thatwithcountvariables,AMOREhasalowerequationreconstructionerrorthanitscounterpartwithoutcountvariables.
InTables21and22,wecanseethatcountvariableshelpAMORElearnfewerfalse-positivemode-switchingbehaviors,
benefittingsegmentationandforecasting.
Table21. AnalyseofcountvariablesonsegmentationresultsoftheMass-springHopperdataset.
Method NMIÒ ARIÒ AccuracyÒ F 1Ò
Hybrid-SINDy 0.426 0.383 0.705 0.691
AMORE(ours) 0.928˘0.011 0.967˘0.013 0.991˘0.005 0.993˘0.007
AMOREw/ocount(ours) 0.903˘0.017 0.929˘0.019 0.970˘0.012 0.975˘0.013
23AmortizedEquationDiscoveryinHybridDynamicalSystems
Table22. AnalyseofcountvariablesonforecastingresultsofLocation/VelocityontheMass-springHopperdataset.
Method NMAEÓ NRMSEÓ
LLMTime 0.113˘0.032/0.305˘0.036 0.417˘0.051/0.454˘0.072
SVI 0.068˘0.016/0.075˘0.011 0.148˘0.023/0.262˘0.030
AMORE(ours) 0.008˘0.003/0.039˘0.008 0.026˘0.005/0.059˘0.006
AMOREw/ocount(ours) 0.014˘0.004/0.046˘0.007 0.052˘0.011/0.068˘0.014
C.4.4.POLYNOMIALORDERSANDMODENUMBERSANALYSIS
Toqualitativelyshowthediscoveredequationswhentheorderofcandidatesandthenumberofmodesareincreased,we
increasetheorderofcandidatesfrom2to5,i.e.D “5,andthenumberofmodesfrom3to5,i.e.K “5ontheMass-spring
Hopperdataset. ThediscoveredequationsaresummarizedinTable23. Wecanseethatourmodelcancategorizeexactly
2modes,i.e. thesameasthegroundtruth,nomatterhowmanypotentialmodesareintroduced. Besides,thediscovered
equationsofthe2modesareregularizedbysparsitypromotionanddonotinvolveirrelevantfunctiontermsthankstothe
sparsityregularizationwhenincreasingtheorderofpolynomialbasisfunctions.
Table23.AnalyseofequationdiscoveryofAMOREwhenincreasingthenumberofmodesKandtheorderofcandidatebasisfunctions
DontheMass-springHopperdataset.
Settings DiscoveredEquations Ground-truthEquations
K “3andD“2 l9“vandv9 “11.03´10.08l;l9“vandv9 “´1 l9“vandv9 “11´10l;l9“vandv9 “´1
K “5andD“5 l9“vandv9 “10.95´10.06l;l9“vandv9 “´1 l9“vandv9 “11´10l;l9“vandv9 “´1
24