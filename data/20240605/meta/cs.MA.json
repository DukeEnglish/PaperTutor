[
    {
        "title": "CityLight: A Universal Model Towards Real-world City-scale Traffic Signal Control Coordination",
        "authors": "Jinwei ZengChao YuXinyi YangWenxuan AoJian YuanYong LiYu WangHuazhong Yang",
        "links": "http://arxiv.org/abs/2406.02126v1",
        "entry_id": "http://arxiv.org/abs/2406.02126v1",
        "pdf_url": "http://arxiv.org/pdf/2406.02126v1",
        "summary": "Traffic signal control (TSC) is a promising low-cost measure to enhance\ntransportation efficiency without affecting existing road infrastructure. While\nvarious reinforcement learning-based TSC methods have been proposed and\nexperimentally outperform conventional rule-based methods, none of them has\nbeen deployed in the real world. An essential gap lies in the\noversimplification of the scenarios in terms of intersection heterogeneity and\nroad network intricacy. To make TSC applicable in urban traffic management, we\ntarget TSC coordination in city-scale high-authenticity road networks, aiming\nto solve the three unique and important challenges: city-level scalability,\nheterogeneity of real-world intersections, and effective coordination among\nintricate neighbor connections. Since optimizing multiple agents in a\nparameter-sharing paradigm can boost the training efficiency and help achieve\nscalability, we propose our method, CityLight, based on the well-acknowledged\noptimization framework, parameter-sharing MAPPO. To ensure the unified policy\nnetwork can learn to fit large-scale heterogeneous intersections and tackle the\nintricate between-neighbor coordination, CityLight proposes a universal\nrepresentation module that consists of two key designs: heterogeneous\nintersection alignment and neighborhood impact alignment for coordination. To\nfurther boost coordination, CityLight adopts neighborhood-integrated rewards to\ntransition from achieving local optimal to global optimal. Extensive\nexperiments on datasets with hundreds to tens of thousands of real-world\nintersections and authentic traffic demands validate the surprising\neffectiveness and generalizability of CityLight, with an overall performance\ngain of 11.66% and a 22.59% improvement in transfer scenarios in terms of\nthroughput.",
        "updated": "2024-06-04 09:10:14 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.02126v1"
    },
    {
        "title": "FightLadder: A Benchmark for Competitive Multi-Agent Reinforcement Learning",
        "authors": "Wenzhe LiZihan DingSeth KartenChi Jin",
        "links": "http://arxiv.org/abs/2406.02081v1",
        "entry_id": "http://arxiv.org/abs/2406.02081v1",
        "pdf_url": "http://arxiv.org/pdf/2406.02081v1",
        "summary": "Recent advances in reinforcement learning (RL) heavily rely on a variety of\nwell-designed benchmarks, which provide environmental platforms and consistent\ncriteria to evaluate existing and novel algorithms. Specifically, in\nmulti-agent RL (MARL), a plethora of benchmarks based on cooperative games have\nspurred the development of algorithms that improve the scalability of\ncooperative multi-agent systems. However, for the competitive setting, a\nlightweight and open-sourced benchmark with challenging gaming dynamics and\nvisual inputs has not yet been established. In this work, we present\nFightLadder, a real-time fighting game platform, to empower competitive MARL\nresearch. Along with the platform, we provide implementations of\nstate-of-the-art MARL algorithms for competitive games, as well as a set of\nevaluation metrics to characterize the performance and exploitability of\nagents. We demonstrate the feasibility of this platform by training a general\nagent that consistently defeats 12 built-in characters in single-player mode,\nand expose the difficulty of training a non-exploitable agent without human\nknowledge and demonstrations in two-player mode. FightLadder provides\nmeticulously designed environments to address critical challenges in\ncompetitive MARL research, aiming to catalyze a new era of discovery and\nadvancement in the field. Videos and code at\nhttps://sites.google.com/view/fightladder/home.",
        "updated": "2024-06-04 08:04:23 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.02081v1"
    },
    {
        "title": "An agent-based model of modal choice with perception biases and habits",
        "authors": "Carole AdamBenoit Gaudou",
        "links": "http://arxiv.org/abs/2406.02063v1",
        "entry_id": "http://arxiv.org/abs/2406.02063v1",
        "pdf_url": "http://arxiv.org/pdf/2406.02063v1",
        "summary": "This paper presents an agent-based model of mobility choice, influenced by\nhuman factors such as habits and perception biases. It is implemented in a\nNetlogo simulator, calibrated from results of an online survey about\nperceptions of mobility. The simulator can be played online. It allows to\nmodify urban infrastructure and observe modal report.",
        "updated": "2024-06-04 07:44:57 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.02063v1"
    },
    {
        "title": "Large Language Model-Enabled Multi-Agent Manufacturing Systems",
        "authors": "Jonghan LimBirgit Vogel-HeuserIlya Kovalenko",
        "links": "http://arxiv.org/abs/2406.01893v1",
        "entry_id": "http://arxiv.org/abs/2406.01893v1",
        "pdf_url": "http://arxiv.org/pdf/2406.01893v1",
        "summary": "Traditional manufacturing faces challenges adapting to dynamic environments\nand quickly responding to manufacturing changes. The use of multi-agent systems\nhas improved adaptability and coordination but requires further advancements in\nrapid human instruction comprehension, operational adaptability, and\ncoordination through natural language integration. Large language models like\nGPT-3.5 and GPT-4 enhance multi-agent manufacturing systems by enabling agents\nto communicate in natural language and interpret human instructions for\ndecision-making. This research introduces a novel framework where large\nlanguage models enhance the capabilities of agents in manufacturing, making\nthem more adaptable, and capable of processing context-specific instructions. A\ncase study demonstrates the practical application of this framework, showing\nhow agents can effectively communicate, understand tasks, and execute\nmanufacturing processes, including precise G-code allocation among agents. The\nfindings highlight the importance of continuous large language model\nintegration into multi-agent manufacturing systems and the development of\nsophisticated agent communication protocols for a more flexible manufacturing\nsystem.",
        "updated": "2024-06-04 01:57:37 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.01893v1"
    },
    {
        "title": "Multi-Agent Reinforcement Learning Meets Leaf Sequencing in Radiotherapy",
        "authors": "Riqiang GaoFlorin C. GhesuSimon ArberetShahab BasiriEsa KuuselaMartin KrausDorin ComaniciuAli Kamen",
        "links": "http://arxiv.org/abs/2406.01853v1",
        "entry_id": "http://arxiv.org/abs/2406.01853v1",
        "pdf_url": "http://arxiv.org/pdf/2406.01853v1",
        "summary": "In contemporary radiotherapy planning (RTP), a key module leaf sequencing is\npredominantly addressed by optimization-based approaches. In this paper, we\npropose a novel deep reinforcement learning (DRL) model termed as Reinforced\nLeaf Sequencer (RLS) in a multi-agent framework for leaf sequencing. The RLS\nmodel offers improvements to time-consuming iterative optimization steps via\nlarge-scale training and can control movement patterns through the design of\nreward mechanisms. We have conducted experiments on four datasets with four\nmetrics and compared our model with a leading optimization sequencer. Our\nfindings reveal that the proposed RLS model can achieve reduced fluence\nreconstruction errors, and potential faster convergence when integrated in an\noptimization planner. Additionally, RLS has shown promising results in a full\nartificial intelligence RTP pipeline. We hope this pioneer multi-agent RL leaf\nsequencer can foster future research on machine learning for RTP.",
        "updated": "2024-06-03 23:55:20 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.01853v1"
    }
]