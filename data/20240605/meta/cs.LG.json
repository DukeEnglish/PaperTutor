[
    {
        "title": "Learning to grok: Emergence of in-context learning and skill composition in modular arithmetic tasks",
        "authors": "Tianyu HeDarshil DoshiAritra DasAndrey Gromov",
        "links": "http://arxiv.org/abs/2406.02550v1",
        "entry_id": "http://arxiv.org/abs/2406.02550v1",
        "pdf_url": "http://arxiv.org/pdf/2406.02550v1",
        "summary": "Large language models can solve tasks that were not present in the training\nset. This capability is believed to be due to in-context learning and skill\ncomposition. In this work, we study the emergence of in-context learning and\nskill composition in a collection of modular arithmetic tasks. Specifically, we\nconsider a finite collection of linear modular functions $z = a \\, x + b \\, y\n\\;\\mathrm{mod}\\; p$ labeled by the vector $(a, b) \\in \\mathbb{Z}_p^2$. We use\nsome of these tasks for pre-training and the rest for out-of-distribution\ntesting. We empirically show that a GPT-style transformer exhibits a transition\nfrom in-distribution to out-of-distribution generalization as the number of\npre-training tasks increases. We find that the smallest model capable of\nout-of-distribution generalization requires two transformer blocks, while for\ndeeper models, the out-of-distribution generalization phase is\n\\emph{transient}, necessitating early stopping. Finally, we perform an\ninterpretability study of the pre-trained models, revealing the highly\nstructured representations in both phases; and discuss the learnt algorithm.",
        "updated": "2024-06-04 17:59:36 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.02550v1"
    },
    {
        "title": "Robust and highly scalable estimation of directional couplings from time-shifted signals",
        "authors": "Luca AmbrogioniLouis RouillardDemian Wassermann",
        "links": "http://arxiv.org/abs/2406.02545v1",
        "entry_id": "http://arxiv.org/abs/2406.02545v1",
        "pdf_url": "http://arxiv.org/pdf/2406.02545v1",
        "summary": "The estimation of directed couplings between the nodes of a network from\nindirect measurements is a central methodological challenge in scientific\nfields such as neuroscience, systems biology and economics. Unfortunately, the\nproblem is generally ill-posed due to the possible presence of unknown delays\nin the measurements. In this paper, we offer a solution of this problem by\nusing a variational Bayes framework, where the uncertainty over the delays is\nmarginalized in order to obtain conservative coupling estimates. To overcome\nthe well-known overconfidence of classical variational methods, we use a\nhybrid-VI scheme where the (possibly flat or multimodal) posterior over the\nmeasurement parameters is estimated using a forward KL loss while the (nearly\nconvex) conditional posterior over the couplings is estimated using the highly\nscalable gradient-based VI. In our ground-truth experiments, we show that the\nnetwork provides reliable and conservative estimates of the couplings, greatly\noutperforming similar methods such as regression DCM.",
        "updated": "2024-06-04 17:58:33 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.02545v1"
    },
    {
        "title": "To Believe or Not to Believe Your LLM",
        "authors": "Yasin Abbasi YadkoriIlja KuzborskijAndrás GyörgyCsaba Szepesvári",
        "links": "http://arxiv.org/abs/2406.02543v1",
        "entry_id": "http://arxiv.org/abs/2406.02543v1",
        "pdf_url": "http://arxiv.org/pdf/2406.02543v1",
        "summary": "We explore uncertainty quantification in large language models (LLMs), with\nthe goal to identify when uncertainty in responses given a query is large. We\nsimultaneously consider both epistemic and aleatoric uncertainties, where the\nformer comes from the lack of knowledge about the ground truth (such as about\nfacts or the language), and the latter comes from irreducible randomness (such\nas multiple possible answers). In particular, we derive an\ninformation-theoretic metric that allows to reliably detect when only epistemic\nuncertainty is large, in which case the output of the model is unreliable. This\ncondition can be computed based solely on the output of the model obtained\nsimply by some special iterative prompting based on the previous responses.\nSuch quantification, for instance, allows to detect hallucinations (cases when\nepistemic uncertainty is high) in both single- and multi-answer responses. This\nis in contrast to many standard uncertainty quantification strategies (such as\nthresholding the log-likelihood of a response) where hallucinations in the\nmulti-answer case cannot be detected. We conduct a series of experiments which\ndemonstrate the advantage of our formulation. Further, our investigations shed\nsome light on how the probabilities assigned to a given output by an LLM can be\namplified by iterative prompting, which might be of independent interest.",
        "updated": "2024-06-04 17:58:18 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.02543v1"
    },
    {
        "title": "Loki: Low-Rank Keys for Efficient Sparse Attention",
        "authors": "Prajwal SinghaniaSiddharth SinghShwai HeSoheil FeiziAbhinav Bhatele",
        "links": "http://arxiv.org/abs/2406.02542v1",
        "entry_id": "http://arxiv.org/abs/2406.02542v1",
        "pdf_url": "http://arxiv.org/pdf/2406.02542v1",
        "summary": "Inference on large language models can be expensive in terms of the compute\nand memory costs involved, especially when long sequence lengths are used. In\nparticular, the self-attention mechanism used in such models contributes\nsignificantly to these costs, which has resulted in several recent works that\npropose sparse attention approximations for inference. In this work, we propose\nto approximate the self-attention computation by focusing on the dimensionality\nof key vectors computed in the attention block. Our analysis reveals that the\nkey vectors lie in a significantly lower-dimensional space, consistently across\nseveral datasets and models. Exploiting this observation, we propose Loki, a\nnovel sparse attention method that ranks and selects tokens in the KV-cache\nbased on attention scores computed in low-dimensional space. Our evaluations\nshow that Loki is able to maintain the efficacy of the models better than other\npopular approximation methods, while speeding up the attention computation due\nto reduced data movement (load/store) and compute costs.",
        "updated": "2024-06-04 17:58:03 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.02542v1"
    },
    {
        "title": "Parrot: Multilingual Visual Instruction Tuning",
        "authors": "Hai-Long SunDa-Wei ZhouYang LiShiyin LuChao YiQing-Guo ChenZhao XuWeihua LuoKaifu ZhangDe-Chuan ZhanHan-Jia Ye",
        "links": "http://arxiv.org/abs/2406.02539v1",
        "entry_id": "http://arxiv.org/abs/2406.02539v1",
        "pdf_url": "http://arxiv.org/pdf/2406.02539v1",
        "summary": "The rapid development of Multimodal Large Language Models (MLLMs) like GPT-4V\nhas marked a significant step towards artificial general intelligence. Existing\nmethods mainly focus on aligning vision encoders with LLMs through supervised\nfine-tuning (SFT) to endow LLMs with multimodal abilities, making MLLMs'\ninherent ability to react to multiple languages progressively deteriorate as\nthe training process evolves. We empirically find that the imbalanced SFT\ndatasets, primarily composed of English-centric image-text pairs, lead to\nsignificantly reduced performance in non-English languages. This is due to the\nfailure of aligning the vision encoder and LLM with multilingual tokens during\nthe SFT process. In this paper, we introduce Parrot, a novel method that\nutilizes textual guidance to drive visual token alignment at the language\nlevel. Parrot makes the visual tokens condition on diverse language inputs and\nuses Mixture-of-Experts (MoE) to promote the alignment of multilingual tokens.\nSpecifically, to enhance non-English visual tokens alignment, we compute the\ncross-attention using the initial visual features and textual embeddings, the\nresult of which is then fed into the MoE router to select the most relevant\nexperts. The selected experts subsequently convert the initial visual tokens\ninto language-specific visual tokens. Moreover, considering the current lack of\nbenchmarks for evaluating multilingual capabilities within the field, we\ncollect and make available a Massive Multilingual Multimodal Benchmark which\nincludes 6 languages, 15 categories, and 12,000 questions, named as MMMB. Our\nmethod not only demonstrates state-of-the-art performance on multilingual\nMMBench and MMMB, but also excels across a broad range of multimodal tasks.\nBoth the source code and the training dataset of Parrot will be made publicly\navailable.",
        "updated": "2024-06-04 17:56:28 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.02539v1"
    }
]