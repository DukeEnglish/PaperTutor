[
    {
        "title": "Digital Privacy for Migrants: Exploring Current Research Trends and Future Prospects",
        "authors": "Sarah TabassumCori Faklaris",
        "links": "http://arxiv.org/abs/2406.02520v1",
        "entry_id": "http://arxiv.org/abs/2406.02520v1",
        "pdf_url": "http://arxiv.org/pdf/2406.02520v1",
        "summary": "This paper explores digital privacy challenges for migrants, analyzing trends\nfrom 2013 to 2023. Migrants face heightened risks such as government\nsurveillance and identity theft. Understanding these threats is vital for\nraising awareness and guiding research towards effective solutions and policies\nto protect migrant digital privacy.",
        "updated": "2024-06-04 17:41:20 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.02520v1"
    },
    {
        "title": "How Western, Educated, Industrialized, Rich, and Democratic is Social Computing Research?",
        "authors": "Ali Akbar SeptiandriMarios ConstantinidesDaniele Quercia",
        "links": "http://arxiv.org/abs/2406.02090v1",
        "entry_id": "http://arxiv.org/abs/2406.02090v1",
        "pdf_url": "http://arxiv.org/pdf/2406.02090v1",
        "summary": "Much of the research in social computing analyzes data from social media\nplatforms, which may inherently carry biases. An overlooked source of such bias\nis the over-representation of WEIRD (Western, Educated, Industrialized, Rich,\nand Democratic) populations, which might not accurately mirror the global\ndemographic diversity. We evaluated the dependence on WEIRD populations in\nresearch presented at the AAAI ICWSM conference; the only venue whose\nproceedings are fully dedicated to social computing research. We did so by\nanalyzing 494 papers published from 2018 to 2022, which included full research\npapers, dataset papers and posters. After filtering out papers that analyze\nsynthetic datasets or those lacking clear country of origin, we were left with\n420 papers from which 188 participants in a crowdsourcing study with full\nmanual validation extracted data for the WEIRD scores computation. This data\nwas then used to adapt existing WEIRD metrics to be applicable for social media\ndata. We found that 37% of these papers focused solely on data from Western\ncountries. This percentage is significantly less than the percentages observed\nin research from CHI (76%) and FAccT (84%) conferences, suggesting a greater\ndiversity of dataset origins within ICWSM. However, the studies at ICWSM still\npredominantly examine populations from countries that are more Educated,\nIndustrialized, and Rich in comparison to those in FAccT, with a special note\non the 'Democratic' variable reflecting political freedoms and rights. This\npoints out the utility of social media data in shedding light on findings from\ncountries with restricted political freedoms. Based on these insights, we\nrecommend extensions of current \"paper checklists\" to include considerations\nabout the WEIRD bias and call for the community to broaden research inclusivity\nby encouraging the use of diverse datasets from underrepresented regions.",
        "updated": "2024-06-04 08:17:47 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.02090v1"
    },
    {
        "title": "Why Would You Suggest That? Human Trust in Language Model Responses",
        "authors": "Manasi SharmaHo Chit SiuRohan PalejaJaime D. Peña",
        "links": "http://arxiv.org/abs/2406.02018v1",
        "entry_id": "http://arxiv.org/abs/2406.02018v1",
        "pdf_url": "http://arxiv.org/pdf/2406.02018v1",
        "summary": "The emergence of Large Language Models (LLMs) has revealed a growing need for\nhuman-AI collaboration, especially in creative decision-making scenarios where\ntrust and reliance are paramount. Through human studies and model evaluations\non the open-ended News Headline Generation task from the LaMP benchmark, we\nanalyze how the framing and presence of explanations affect user trust and\nmodel performance. Overall, we provide evidence that adding an explanation in\nthe model response to justify its reasoning significantly increases\nself-reported user trust in the model when the user has the opportunity to\ncompare various responses. Position and faithfulness of these explanations are\nalso important factors. However, these gains disappear when users are shown\nresponses independently, suggesting that humans trust all model responses,\nincluding deceptive ones, equitably when they are shown in isolation. Our\nfindings urge future research to delve deeper into the nuanced evaluation of\ntrust in human-machine teaming systems.",
        "updated": "2024-06-04 06:57:47 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.02018v1"
    },
    {
        "title": "Measure-Observe-Remeasure: An Interactive Paradigm for Differentially-Private Exploratory Analysis",
        "authors": "Priyanka NanayakkaraHyeok KimYifan WuAli SarvghadNarges MahyarGerome MiklauJessica Hullman",
        "links": "http://dx.doi.org/10.1109/SP54263.2024.00182",
        "entry_id": "http://arxiv.org/abs/2406.01964v1",
        "pdf_url": "http://arxiv.org/pdf/2406.01964v1",
        "summary": "Differential privacy (DP) has the potential to enable privacy-preserving\nanalysis on sensitive data, but requires analysts to judiciously spend a\nlimited ``privacy loss budget'' $\\epsilon$ across queries. Analysts conducting\nexploratory analyses do not, however, know all queries in advance and seldom\nhave DP expertise. Thus, they are limited in their ability to specify\n$\\epsilon$ allotments across queries prior to an analysis. To support analysts\nin spending $\\epsilon$ efficiently, we propose a new interactive analysis\nparadigm, Measure-Observe-Remeasure, where analysts ``measure'' the database\nwith a limited amount of $\\epsilon$, observe estimates and their errors, and\nremeasure with more $\\epsilon$ as needed.\n  We instantiate the paradigm in an interactive visualization interface which\nallows analysts to spend increasing amounts of $\\epsilon$ under a total budget.\nTo observe how analysts interact with the Measure-Observe-Remeasure paradigm\nvia the interface, we conduct a user study that compares the utility of\n$\\epsilon$ allocations and findings from sensitive data participants make to\nthe allocations and findings expected of a rational agent who faces the same\ndecision task. We find that participants are able to use the workflow\nrelatively successfully, including using budget allocation strategies that\nmaximize over half of the available utility stemming from $\\epsilon$\nallocation. Their loss in performance relative to a rational agent appears to\nbe driven more by their inability to access information and report it than to\nallocate $\\epsilon$.",
        "updated": "2024-06-04 04:48:40 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.01964v1"
    },
    {
        "title": "Enhancing Human-Robot Collaborative Assembly in Manufacturing Systems Using Large Language Models",
        "authors": "Jonghan LimSujani PatelAlex EvansJohn PimleyYifei LiIlya Kovalenko",
        "links": "http://arxiv.org/abs/2406.01915v1",
        "entry_id": "http://arxiv.org/abs/2406.01915v1",
        "pdf_url": "http://arxiv.org/pdf/2406.01915v1",
        "summary": "The development of human-robot collaboration has the ability to improve\nmanufacturing system performance by leveraging the unique strengths of both\nhumans and robots. On the shop floor, human operators contribute with their\nadaptability and flexibility in dynamic situations, while robots provide\nprecision and the ability to perform repetitive tasks. However, the\ncommunication gap between human operators and robots limits the collaboration\nand coordination of human-robot teams in manufacturing systems. Our research\npresents a human-robot collaborative assembly framework that utilizes a large\nlanguage model for enhancing communication in manufacturing environments. The\nframework facilitates human-robot communication by integrating voice commands\nthrough natural language for task management. A case study for an assembly task\ndemonstrates the framework's ability to process natural language inputs and\naddress real-time assembly challenges, emphasizing adaptability to language\nvariation and efficiency in error resolution. The results suggest that large\nlanguage models have the potential to improve human-robot interaction for\ncollaborative manufacturing assembly applications.",
        "updated": "2024-06-04 02:52:26 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.01915v1"
    }
]