Copyright © 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including
reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any
copyrighted component of this work in other works. Full citation: P. Nanayakkara, et al., “Measure-Observe-Remeasure: An Interactive Paradigm for Differentially-Private
ExploratoryAnalysis,”in2024IEEESymposiumonSecurityandPrivacy(SP),SanFrancisco,CA,USA,2024pp.231-231.doi:10.1109/SP54263.2024.00182
Measure-Observe-Remeasure:
An Interactive Paradigm for Differentially-Private Exploratory Analysis
Priyanka Nanayakkara∗, Hyeok Kim∗, Yifan Wu∗,
Ali Sarvghad†, Narges Mahyar†, Gerome Miklau†, Jessica Hullman∗
∗Northwestern University
†University of Massachusetts Amherst
{priyankan, hyeokkim2024, yifan.wu}@u.northwestern.edu
{asarv, nmahyar, miklau}@cs.umass.edu
jhullman@northwestern.edu
Abstract—Differentialprivacy(DP)hasthepotentialtoenable thatincreasednoiseimpliesstrongerprivacyguarantees,but
privacy-preserving analysis on sensitive data, but requires lower accuracy of estimates. The amount of expected noise
analysts to judiciously spend a limited “privacy loss budget” added is controlled by a privacy loss bound defined by ϵ
ϵ across queries. Analysts conducting exploratory analyses do (the “privacy loss budget”).
not, however, know all queries in advance and seldom have Each time the dataset is queried, the amount of spent
DP expertise. Thus, they are limited in their ability to specify ϵ accumulates. Once ϵ reaches the maximum bound, an
ϵ allotments across queries prior to an analysis. To support analyst is prevented from issuing further queries. Conduct-
analystsinspendingϵefficiently,weproposeanewinteractive ingadifferentially-privateanalysisthereforerequirescareful
considerations around how much ϵ to spend and on which
analysis paradigm, MEASURE-OBSERVE-REMEASURE, where
queries. Thus, it is natural to pre-specify all queries in
analysts “measure” the database with a limited amount of ϵ,
advance of an analysis so that the mechanism and distribu-
observe estimates and their errors, and remeasure with more
tion of ϵ can be optimized for the query set—for example,
ϵ as needed.
by minimizing repetition in information queried from the
Weinstantiatetheparadigminaninteractivevisualization
database—to maximize accuracy. In fact, DP research and
interface which allows analysts to spend increasing amounts
real-world implementations tend to fall under the “query-
of ϵ under a total budget. To observe how analysts interact
response” model [5], which assumes analysts specify all
with the MEASURE-OBSERVE-REMEASURE paradigm via the
queries in advance and is common in computer science.
interface,weconductauserstudythatcomparestheutilityofϵ
However,whilethismodelisnaturallysupportedbyDP,
allocations and findings from sensitive data participants make
it is at odds with the data-dependent process of exploratory
to the allocations and findings expected of a rational agent
dataanalysis(EDA),whichisrecognizedasanintegralpart
who faces the same decision task. We find that participants
of statistical modeling [6]. During EDA, analysts determine
are able to use the workflow relatively successfully, including
subsequent queries based on results earlier in the analysis,
using budget allocation strategies that maximize over half of
meaning they have only a myopic view of future queries
the available utility stemming from ϵ allocation. Their loss in
and their relative importance. The iterative nature of EDA
performance relative to a rational agent appears to be driven
poses a particular challenge to spending a total privacy loss
morebytheirinabilitytoaccessinformationandreportitthan
budget efficiently: for example, suppose an analyst issues a
to allocate ϵ. query with an initial amount of ϵ, then later realizes they
actually need better accuracy and re-issues the query with
1. Introduction a larger amount of ϵ. In this case, the initial amount of
ϵ essentially goes to waste because it still counts toward
Datasets about people often contain information that is the total budget but does not contribute to the final query
sensitive,butusefultolearninaggregate.Forexample,pub- estimate. Picture this pattern over multiple queries, and
lished census tables pose the risk of exposing individuals’ it is easy to see how analysts—especially those without
demographic information, but are necessary for allocating DP expertise—can quickly burn through their total budget
political representation and government funding [1]. Fortu- before meeting analysis goals.
nately,approachesbasedondifferentialprivacy(DP)[2],[3] Hence, capitalizing on DP’s potential for enabling
makeprivacy-preservinganalysesonsensitivedatapossible. privacy-preserving data analysis requires a new analysis
Differentially-privatealgorithms,however,constrainand paradigm that balances control and flexibility to support
reconfigurethedataanalysisprocess,posingnewchallenges analysts in spending ϵ efficiently, without an overwhelm-
fordataanalysts[4].Specifically,differentially-privatealgo- ing number of choices. While full interactivity—where the
rithms inject statistical noise into the analysis process such analyst determines which queries to submit and at which
4202
nuJ
4
]RC.sc[
1v46910.6042:viXraamounts of ϵ—is theoretically appealing, it would require data analysis. In particular, a differentially-private analysis
analysts to perform a complex optimization problem with placesalimitonhowmuchinformationaboutanindividual
limited information (i.e., the set of future queries) on top of is learned from an analysis based on their data’s inclusion
the reasoning that is already entailed in analyzing data. Ex- in said analysis.
pectinganalyststosolvethisproblemwelldoesnotaccount A randomized mechanism M satisfies (ϵ)-DP if for any
forourexpectationsabouthumaninformationprocessingas two neighboring datasets D and D’, which differ by the
boundedlyrational[7].Assuch,fullinteractivitycouldlead addition or deletion of one record, and for any subset S of
analysts to prematurely exhaust their allocated budget or the range of M, the following inequality holds:
obtain estimates too inaccurate to be useful [8].
Therefore, we propose the MEASURE-OBSERVE- Pr[M(D)∈S]≤exp(ϵ)×Pr[M(D′)∈S] (1)
REMEASUREparadigm(i.e.,workflow)whichhelpsanalysts
spend only what they need on each query to accomplish where ϵ is a non-negative parameter that controls the
their analysis goals. The paradigm is interactive, such that strengthofprivacyprotection.DPcanbeachievedbyinject-
analysts spend incrementally more ϵ as they observe esti- ing calibrated statistical noise into numerical query results.
matesandtheirerrors,thusimprovingestimatesateachstep ϵ(i.e.,theprivacylossbudget)controlstheamountofnoise
(in expectation). First, the analyst makes a query, which the mechanism adds during the computation. A smaller
is MEASURED under DP using an initial fraction of the privacylossbudgetenforcesstrongerprivacyprotection,but
total privacy loss budget. Second, the analyst OBSERVES typically implies worse accuracy of estimates.
the estimate. Third, based on the analyst’s observations in
2.2. Answering and Updating Query Answers
the second step, they decide whether to REMEASURE the
query, spending more ϵ to get additional information about
To build the interface instantiating the MEASURE-
the data, therefore improving the estimate. This process is
OBSERVE-REMEASURE workflow we use existing open-
interactive, such that once the analyst issues a query, they
source DP methods to answer queries privately, combine
may engage in the OBSERVE-REMEASURE loop until the
noisy queries into consistent estimates, and quantify error.
budget is depleted. They may issue and remeasure queries
in any order. Further, the workflow employs a mechanism 2.2.1. TheHighDimensionalMatrixMechanism.Ourin-
thatmakesmoreefficientuseofknowledgeaboutthe query stantiationoftheMEASURE-OBSERVE-REMEASUREwork-
setbytakingintoaccountpreviousqueriesand,uponremea- flow relies on the High Dimensional Matrix Mechanism
surement,weightingpreviousestimateswithafreshestimate (HDMM)[9],[10]toanswerqueriesunderDP.HDMMisan
in a way that yields lower expected error. Remeasurement extension of the Matrix Mechanism [11] and a state-of-the-
allows analysts to spend increasingly more ϵ on a given art mechanism for answering sets of multi-dimensional lin-
query, thus avoiding wasting any amount of ϵ. ear counting queries. Linear counting queries are a class of
We (1) instantiate the MEASURE-OBSERVE- queriesthatincludeone-andmulti-dimensionalhistograms,
REMEASURE workflow in an interactive visualization marginals, data cubes, etc.
interface that displays query estimates and supports HDMM takes as input a workload consisting of a set of
remeasurement. Through a user study, we (2) explore how linear queries. The method computes differentially-private
analysts respond to the paradigm. To analyze results, we answerstotheworkloadqueriesbyusingtheLaplaceMech-
(3) extend a rational agent framework for visualization anism [2], [3] to answer a different set of queries, called
studies with benchmarks designed specifically to evaluate ϵ the strategy, from which the workload query answers are
allocation, which allows us to (4) investigate opportunities derived. It can often increase accuracy (for a fixed value of
for improvement by comparing analysts’ responses to ϵ) to compute answers in this way. For example, multiple
optimal benchmarks under different assumptions. queries in a workload may rely on a common piece of
Our results indicate that participants’ allocation strate- information about the database; HDMM computes a near-
gies maximize over half the utility that stems from ϵ al- optimalsetofstrategyquerieswhichavoidsredundancyand
location. Their loss in performance relative to a rational inefficient use of the privacy loss budget.
agent appears to be driven more by their inability to access In addition to answering queries with reduced error, we
information and report it than to allocate ϵ. We compare use two other features of HDMM to support our interface.
participants’ performance to a variety of benchmarks repre- First, HDMM is a data-independent mechanism, which al-
senting different amounts of information and assumptions lows the straightforward calculation of expected root mean
about allocation strategies to gain insight into how the squarederror(RMSE)ofthereportedqueryanswerswithout
workflow might be improved in future work. spendingadditionalprivacylossbudget.Weusethesevalues
to plot error in our interface. Second, the machinery of
2. Background HDMM, called inference in Li et al. (2015) [11], can be
used to combine multiple noisy estimates of query answers
2.1. Differential Privacy (in our case derived through remeasures) into a consistent
set of estimates with reduced error. We use this feature to
Differential Privacy (DP) provides a mathematical combine observations from multiple remeasures and update
framework for accounting for privacy loss incurred during visualizations shown to the analyst.3. Related Work MEASURE OBSERVE REMEASURE
Prior work has demonstrated challenges associated with
integratingDPintoexistingworkflows,particularlywithre-
gardtoEDA.Inarecentstudy,Sarathyetal.[4]interviewed
practitioners without DP expertise about their experiences
Measurement with Analyst asseses Remeasurement
using DP Creator, a DP interface, and found that among
an initial ε whether erros with added ε
other challenges, analysts were skeptical of using DP for are acceptable
EDA given the additional constraint of the privacy loss
Figure1:TheMEASURE-OBSERVE-REMEASUREworkflow.Theanalyst
budget. Through a usability study of four Python-based DP
queriestheprivatedatabaseforaninitialmeasurement,observesestimates,
tools, Ngong et al. [12] found that “novices and experts in andremeasuresifbetteraccuracyisrequired.
[their] study were concerned with setting and tracking the
privacy budget.” While the privacy loss budget represents
an unavoidable constraint around how much information Finally, researchers have contributed tools and frame-
can be learned about a dataset, our work seeks to address works that support decisions outside setting privacy loss
thischallengebyreducingthecognitiveoverheadassociated budgets specifically in data analysis contexts. For example,
with keeping track of and spending ϵ well. Garrido et Bittneretal.[19]andGuoetal.[20]contributeinterfacesfor
al. [13] interviewed practitioners about hurdles to using DP DP in machine learning contexts. Furthermore, Hay et al.’s
inenterprisesettings.OneoftheirkeyfindingswasthatDP DPComp [21] is a visualization interface that supports data
has potential to “facilitate exploration that otherwise might analysts and curators alike in making comparisons between
not be possible or timely,” further emphasizing the need to the accuracy of multiple differentially-private algorithms,
support EDA under DP. while Hay et al. [22]’s DPBench formulates an evaluation
In terms of tool development, prior work has focused framework for differentially-private algorithms, where one
on developing interfaces that allow users to input data, of the evaluation principles includes an algorithm’s inputs,
queries, and other parameters (e.g., ϵ) and receive query like privacy loss budget. Finally, Zhang et al.’s εktelo [23]
estimates under DP. These tools, described below, make it supports people in designing custom differentially-private
possible for curators and analysts without DP expertise to algorithms and McSherry’s [24] PINQ is a querying plat-
employ differentially-private mechanisms. They largely fall form for differentially-private analyses.
under the query response model [5], where there is limited
interactivity in terms of spending ϵ. In other words, these 4. MEASURE-OBSERVE-REMEASURE
toolsenactaMEASURE-OBSERVEparadigm,whereinauser
specifies a query to MEASURE and some amount of ϵ (or We present the MEASURE-OBSERVE-REMEASURE
acceptable accuracy or risk) and OBSERVES the result. paradigm (Figure 1) for EDA under DP. The MEASURE-
Gaboardi et al. [14] introduce PSI (ψ) (a pre-cursor to OBSERVE-REMEASURE paradigm assumes an analyst who
DP Creator), a text-based interface that supports analysts in wishes to explore a private database. They are given a
allocatingϵbyspecifyingacceptableamountsoferror.Once total privacy loss budget—specified by a data curator1—
the analyst finalizes a distribution of ϵ across queries, they to spend during the analysis. Once the analyst depletes the
can submit the request (to the curator) and receive results. budget, they may no longer issue queries to the database.
Thaker et al. [15]’s Overlook is a system that supports both The analyst’s goal is to maximize the accuracy of estimates
data curators and analysts with visualization interfaces for in such a way that maximizes their utility for inference or
navigating differentially-private analyses. Data curators set decision making. While they may begin with some high-
a privacy loss budget with which to release a “synopsis” of level analysis goals (e.g., to identify factors associated with
thedatatoanalysts,whichanalystscanquerywithoutlimit. some outcome), they do not know specific queries in ad-
Nanayakkara et al. propose ViP [16], an interface which vance.WedesignedtheMEASURE-OBSERVE-REMEASURE
visualizes trade-offs between accuracy and disclosure risk paradigmtobewidelyaccessible,suchthatanalystswithout
to help data curators set and split privacy loss budgets. ViP deep knowledge of DP can interactively spend ϵ without
allows curators to test different amounts of ϵ for a given having to get the exact budget allocation for queries “right”
query, but does not account for privacy loss associated with on the first try.
such testing. While ViP is aimed at a data curator who is The analyst issues queries (MEASURE) and observes
permittedtoseetherawdata,ourworkisgearedtowardan- (OBSERVE) their estimates, which include DP noise. At
alystswhodonothavesuchaccess.St.Johnetal.introduce any point in their session, if they desire a more accurate
the DPP tool [17], which supports a data curator in setting estimate for a query, they can REMEASURE the query.
privacy loss budgets by interacting with visualizations de- Remeasuringaqueryconsumesadditionalϵ,alwaysyielding
picting risk, sensitivity (of damaged caused by a breach),
trustintherecipient,andaccuracy.Asanalternateapproach 1.Typically, data curators provide analysts with a total privacy loss
to helping analysts spend ϵ, Ge et al. [18] propose APEx, a budget. However, the paradigm is easily adapted to the setting where the
analystdeterminesthetotalbudgetthemselves.Insuchacase,theanalyst
system which allows the analyst to specify error tolerances
wouldset thetotal budgetand proceedinthe samewayasif thecurator
and inturn receive queryresults that satisfysaid tolerances. hadsetthetotalbudget.lower expected error in the query estimate. The information exploratoryanalyseswithintheparadigm.However,making
contained in previous queries is leveraged via the Matrix the paradigm usable by analysts without DP expertise war-
Mechanism and consequently maximizes the accuracy that rants operationalizing it such that they are able to make key
can be obtained under the privacy loss budget spent. By decisions (i.e., how to allocate remeasures) without being
using remeasures, they engage in a MEASURE-OBSERVE- exposed to the underlying DP machinery. An interface for
REMEASURE feedback loop, whereby they continually as- doingsocantakeseveralforms,fromaPythonorRpackage
sesswhichqueriesrequireimprovedaccuracyanddistribute with functions for using the Matrix Mechanism to measure
remeasures accordingly. In this way, they are not forced to and remeasure queries to a visualization-based graphical
allocate their privacy loss budget up front and can instead userinterface.Inthiswork,wefocusonthelattertoexplore
spend ϵ as needed. thepotentialfortheworkflowtosupportbudgetingdecisions
The workflow enables analysts to leverage their domain when users lack much DP expertise.
knowledge about the relative importance of each query. For We operationalize the MEASURE-OBSERVE-
example, an analyst might issue a query to check whether REMEASURE paradigm through an interactive visualization
there are roughly an equal number of people in each racial interface2 (Figure 2). The goal of the interface is to support
group represented in the dataset. Here, they probably do analysts without deep DP expertise in (1) remeasuring and
not require extremely high accuracy, since they are not in- tracking accumulated privacy loss budget (in the form of
terestedinspecificcounts,butratheranoveralldistribution. remeasures), (2) comparing accuracy of estimates across
Theymaylaterbeinterestedinlearningwhetherthenumber queries at any given time, and (3) observing changes in
of people living in any particular zip code in the dataset error upon remeasurement. In our instantiation, we assume
exceedssomethresholdvalue.Inthiscase,theymayrequire the data curator has pre-specified the amount of ϵ per
higher accuracy to be (more) certain whether any counts remeasure, but the interface can be easily extended to allow
exceed the threshold. analysts flexibility to set budget-per-remeasure.
Visualizations. The interface visualizes all queries is-
4.1. Implementing Remeasurement sued at any given point on a scrollable page. This enables
the analyst to compare relative errors across issued queries
to decide how to allocate remeasures.3 For each query, the
In the MEASURE-OBSERVE-REMEASURE paradigm,
interface displays one visualization per each variable spec-
thecurrentsetofqueriesisrepresentedasaworkloadunder
ified in the query (Figure 2A). For example, a query about
HDMM (see Section 2.2.1), for which a strategy matrix is
conditional counts of people in a dataset according to age
calculated. Query results are computed using the strategy
and marital status would be displayed in two visualizations:
matrix then converted to the response space of the original
(1)ahistogramdepictingnoisycountsbyagegroupand(2)
queries and can then be presented to the analyst. When a
a bar graph depicting noisy counts by marital status. These
query is remeasured, the approach applies a predetermined
visualizationsaredisplayedside-by-sideandare“linked”in
additional amount of the privacy loss budget to requerying
suchawaythattheanalystcanfilterdatadisplayedoneither
the data, and re-weights new results with all previously
visualization by making specifications on the other visual-
cached results (resulting from the original measurement of
ization(Figure2C).Forexample,iftheanalystisinterested
the data and all consequent remeasurements) to produce
in the distribution of marital-status groups across particular
an estimate with strictly lower expected error than errors
age groups, they can click the bars associated with the age
associated with measurements in the cache. We specifically
groups of interest, and the marital status visualization will
relyontheinferencestepfromHDMMtocombinemultiple
only display data for the specified age groups.
measurements into a single consistent set of estimated
query answers. New measurements are weighted as the Points at the top of each bar represent noisy estimates
inverse of their variance. as computed by HDMM (Figure 2B). The interface also
The amount of ϵ applied during each remeasure can be displays error bars representing RMSE of the estimates.
predetermined for the analyst (e.g., by the curator) or set Upon hovering a bar, a tooltip appears with values of the
by the analyst. A fixed amount of ϵ can be applied to each noisy count, error estimate, and an interval representing the
remeasurement or the analyst can adjust exactly how much noisy count ± error. Visually displaying error bars allows
ϵ is applied on each remeasurement. However, this level analysts to gauge how precise an estimate is, and in turn
of flexibility adds complexity. Fixing ϵ per remeasurement assesswhethertheywanttoallocatemoreϵtoagivenquery.
helps minimize how much added cognitive complexity DP Remeasuring. The analyst may remeasure any of the
introduces into analysts’ typical EDA workflows. displayed queries by using remeasure buttons in each
query’s control panel (Figure 2E), to the right of its visual-
izations.Clickingtheremeasurebuttonremeasuresthequery
4.2. Operationalizing the Paradigm in an
withthefixedamountofϵallocatedtoeachremeasure.The
Interactive Visualization Interface
analyst is guaranteed a reduction in the expected error each
In theory, analysts with deep DP expertise could
2.https://interactive-dp-analysis.github.io/
implement the machinery of the MEASURE-OBSERVE-
3.Note that initial measurements support the query set, but might not
REMEASURE paradigm as described above and perform betheoptimalmeasurementstoanswerallqueries.Figure 2: An interactive visualization interface that allows analysts to engage with the MEASURE-OBSERVE-REMEASURE workflow. Analysts may
observenoisyestimates(B)andremeasure(E)asneededuntiltheyreachthetotalremeasure(privacyloss)budget(D).
time a remeasure is applied to a query. A progress bar at 5. Observing the Paradigm: User Study
the top of the screen shows the number of remeasures used
across all queries, supporting the analyst in keeping track
The primary difference between the MEASURE-
of how much of the total privacy loss budget they have
OBSERVE-REMEASURE paradigm and the current practice
spent (Figure 2D). The progress bar remains fixed at the
indifferentially-privateEDA(i.e.,the MEASURE-OBSERVE
top of the page as the analyst scrolls through visualizations
paradigm), is the interactivity afforded by MEASURE-
of multiple queries’ estimates. Each query’s control panel
OBSERVE-REMEASURE. Under the current paradigm, an-
also keeps track of the number of remeasures used on that
alysts are forced to make high-stakes guesses about how
particular query.
much ϵ to apply to a query: if they spend some amount of
ϵ and decide it was not enough, and consequently re-query
When an analyst remeasures a query, the visualization with higher ϵ, the initial amount of ϵ does not contribute to
for that query updates to show the new noisy estimates the final estimate, yet counts toward their total budget use.
and error estimates. The error estimates from the measure- Thus, there is inherent performance loss due to wasted ϵ
ment directly preceding are also shown as dotted gray bars (i.e., not being able to spend ϵ interactively). The amount
beneath the new error bars; the previous errors are also oflossisafunctionofseveralfactors,includingthedataset,
centeredaroundthecurrentestimate(Figure2B).Displaying query, and how performance is scored (i.e., the utility func-
both sets of error bars, centered around the same point, tion).Toprovideintuitionofhowmuchperformancegainis
enables analysts to easily compare widths of previous and possible using our paradigm over the MEASURE-OBSERVE
current errors to assess the improvement in accuracy be- paradigm, we provide a comparison of RMSE of estimates
tween measurements. under both paradigms across multiple datasets and queries
from analysis tasks in our user study, in Appendix A.
Adjusting Visualizations. If the analyst wants to see In practice, however, there are various sources of hu-
estimates from the immediately-preceding measurement, man error that could impact how effectively people use
they can use the first toggle in the control panel for the the MEASURE-OBSERVE-REMEASURE paradigm. There-
query. Toggling shifts the dashed-line previous errors fore, we conducted an exploratory user study to observe
slightly to the right and centers them around previous esti- possible variations in performance that could occur in prac-
mates (Figure 2F). A second toggle in each query’s control tice,andgaininsightintoreasonswhyanalystsmaystruggle
panelautomaticallyre-scalesthevisualizations’y-axessuch with the paradigm as implemented in the visualization in-
that the maximum limit better reflects the largest estimate terface. For example, analysts may differ in how well they
displayed (Figure 2G). Re-scaling can be useful when the allocate ϵ across queries to maximize utility or interpret
analysthasfilteredthedisplayeddataonavisualizationand noisy estimates to form beliefs about the true (un-noised)
wants to “zoom in” by reducing the axis limit. Similarly, it data. Specifically, we study the following:
can be useful when a remeasure results in a large decrease
in estimated error and the analyst similarly needs to zoom 1) How well the interface supports analysts in using
in. By default, this toggle is off so that upon remeasuring, noised query results to accurately answer analysis
analysts see updated estimates on a common scale. questions2) Howwelltheinterfacesupportsanalystsinmaking fell. For binary questions, participants provided the prob-
efficient use of a total privacy loss budget, through ability they would assign to the ground truth being “yes”
remeasurement, to complete analysis tasks and the probability they would assign to the ground truth
3) Which aspects of the interface are perceived as being “no,” where the two probabilities must sum to one.
challenging versus helpful, and high-level ap- A scoring rule evaluates the quality of a probabilistic
praisals of the MEASURE-OBSERVE-REMEASURE forecast by assigning a numerical score based on the pre-
workflow broadly diction and the event or the actual value [26]. We scored
responses using proper scoring rules, where, conditional
Participants conducted analyses by using differentially-
on a belief distribution Q, the agent cannot do better by
private query results to answer questions about multiple
reporting some other distribution P ̸= Q. We used an
datasets, with the option of using some total budget of
interval scoring rule [26] for quantitative questions and the
remeasures per dataset. In addition to payment for com-
Brier (i.e., quadratic) scoring rule for binary questions [27]:
pletingthe study,participantsalsoreceived bonuspayments
commensurate with the accuracy of their responses. We • Interval Scoring Rule:
formalize the decision problem they faced and compare Sint(l,u;x)=u−l+ 21{x<l}+ 2(x−u)1{x>
α α α
the payoffs they received to those expected under different u}, where l and u are the lower and upper bounds
assumptionsabouttheirdecisionstrategy,includingrandom ontheparticipant’sreportedinterval,xistheground
allocationofremeasuresandoptimalreallocationasdefined truth, and α=.05
in a rational agent framework [25]. • Brier/Quadratic Scoring Rule:
S(p,θ) = (p−1(θ = yes))2 −((1−p)−1(θ =
5.1. Empirical Evaluation Setting no))2, where p is the participant’s probability guess
for “yes” and θ is the ground truth
There is flexibility in decisions an analyst can make The interval scoring rule rewards tighter intervals that
when using the workflow (e.g., which queries to issue and containthetruevalue;thatis,thereisapenaltyiftheinterval
howmuchϵtospendperremeasure).However,itisdifficult does not contain the true value and the score is worse for
to compare performance across analysts or to a notion of wider intervals. The Brier scoring rule rewards probabilities
best possible performance without a well-defined decision that are closer to the ground truth (e.g., if the ground truth
problem. We designed an empirical setting in which partic- is “yes,” the ground truth answer is probability 1 for “yes”
ipants used the MEASURE-OBSERVE-REMEASURE work- and probability 0 for “no”).
flow to answer specific questions about a common set of In order to associate each question with the same max-
datasets using a limited number of remeasures. We defined imum possible payment of $2.50 (up to $10 per block),
proper scoring rules that dictated the utility associated with we normalized scores to [0,1] by dividing by an expected
betteranswerstoaqueryinordertoensurethateachanalyst maximum bound on each question’s score (see Appendix B
was equally incentivized to maximize their score and con- for details). Across all three blocks, participants could earn
sequently, the bonus payment they earned during the study. up to a total of $30 (in addition to a guaranteed payment of
Thus, their goal was to provide answers to the questions $25 for completing the study).
(andthereforeallocatetheremeasures)thatmaximizedtheir
payoff under the given scoring rules. 5.1.2. Datasets. Each block asked questions about one of
Each participant in our experiment completed three the datasets described below. We chose these datasets be-
blocks of questions and stimuli. Each block posed four causetheyareinherentlyaboutpeople,thuscreatingrealistic
analysisquestionsaboutaparticulardataset,tobeanswered analysisscenarioswhereDPmightbeapplied.However,we
with up to six remeasures (each of ϵ = 0.3). Thus, each believeshowingthesedatasetstoparticipantsposednegligi-
block contained four visualizations (each contained a pair blereal-worldprivacyriskstopeopleinthedatasetsbecause
of linked histograms—see Section 4.2) each corresponding these data are not only all available (without identifiers) on
to a different analysis question. Participants were not re- theUCIrvineMachineLearningRepository,butparticipants
stricted in how they could allocate the remeasures across in our study were also only shown differentially-private
the visualizations (queries). estimates of the data.
NIST Diverse Communities Data [28] (CENSUS): The
5.1.1. Eliciting and Scoring Responses. Because we
data are based on the U.S. Census Bureau’s American
presented estimates (i.e., DP-noised query results), we
Community Survey, and includes demographics like race,
expected participants to be uncertain about the ground
age, and income.
truth values. Thus, we elicited answers that reflected the
uncertainty in their beliefs. We asked quantitative and
Diabetes 130 Dataset [29] (DIABETES): The dataset
describes patient visits at 130 U.S. hospitals over a ten-year
binary questions (further described in Section 5.1.3), where
periodandincludesinformationlikenumberofmedications
quantitativequestionsaskedforacountandbinaryquestions
and length of hospital stay.
asked whether a given count was above or below a certain
threshold. For quantitative questions, participants provided Tu¨rkiye Student Evaluation Dataset [30] (STUDENT):
anintervalinwhichtheywere95%confidentthetruevalue Thedatadescribestudentevaluationsofcoursesandinstruc-tors at Gazi University. Students answered questions rating within blocks. Participants could complete questions within
various aspects of courses and instructor performance. a block in whatever order they wished. We provided them
In each block, participants were shown a sample of size withasimplecalculator,buttheywerepermittedtousetheir
1,000 from each of the three datasets. Their responses were own if they preferred. There was no strict time limit on
scored against the query results for that sample. each block, however we gave them warnings to ensure they
completed the study in the allotted session time (one hour).
5.1.3. Analysis Question Types. Each block contained Finally, participants answered a series of exit interview
three quantitative questions and one binary question. Quan- questions (Appendix D), including about their remeasure
titative questions asked for the number of people in the strategy, how much of the $30 payoff they believed they
dataset satisfying some criteria (e.g., by race and age). earned, and their familiarity with DP.
Binary questions asked whether the number of people in Our study included 14 participants who were based
the dataset satisfying some criteria was lesser or greater in the U.S., at least 18 years old, and had experience
than a threshold value. We selected threshold values that with quantitative data analysis. We recruited participants
were purposefully challenging, such that the actual count by posting on listservs for graduate students in computer
wasnearthethresholdandthefirsterrorintervalparticipants science or computer-science-adjacent fields and through
encounteredwouldlikelycontainthethreshold.Examplesof our networks. We did not recruit directly from any courses
eachquestiontypedrawnfromtheCENSUSblockarebelow: taught by the authors. The first author conducted sessions
virtually, and upon completion, participants were given
Quantitative. How many “Black or African American
gift cards ($25 for completing the study plus some portion
alone” and “Asian alone” people are at least 55 years old?
of the $30 bonus). The study was deemed exempt by
Binary. Are there more than 327 people who have never Northwestern University’s IRB.
been married and make less than $100,000?
To add further variety and realism in question types, we 6. Rational Agent Benchmarks and Losses
asked a combination of “multi-value” and “single-value”
questions. Multi-value questions required participants to
We define best attainable performance and other mean-
sum multiple given values, while single-value questions
ingful comparison points in order to evaluate study results.
required reading only one value. Both questions above are
These comparison points allow us to contextualize par-
multi-value questions. For example, answering the quan-
ticipants’ performance and reflect on sources of observed
titative question requires filtering either the race or age
performance loss.
visualization and summing the appropriate bars—e.g., one
can sum the number of “Black or African American people
6.1. Benchmarks
alone”peoplewhoareatleast55yearsoldwiththenumber
of“Asianalone”peoplewhoareatleast55yearsold.There
weretwomulti-valueandonesingle-valuequantitativeques- Todevisecomparisonpoints(i.e.,benchmarks)weusea
tions per block. Two blocks contained a multi-value binary rationalagentframeworkbasedinstatisticaldecisiontheory.
questionwhileonecontainedasingle-valuebinaryquestion. The framework uses the notion of a rational Bayesian agent
All questions are in Appendix C. to quantify the maximum amount of information that can
be learned from some stimuli (i.e., visualization of a noisy
5.1.4. Protocol. Participants gave informed consent prior estimate)andappliedtoadecisionproblem(i.e.,forecasting
to beginning study sessions. We gave participants a high- thetruevalueunderlyingtheestimate)[25].Atahighlevel,
level introduction to the concept of injecting noise during weconceiveofarationalagentwhobeginswithapriorover
an analysis, then walked them through a tutorial question possible ground truth answers, is presented with the same
to familiarize them with the interface and its features.4 studytasksasparticipants,perfectlyperceivesthepresented
Participants could ask any questions about the interface and stimuli,Bayesianupdatestheirprior,andsubmitsanoptimal
aboutremeasuring.Wethenexplainedthescoringrules.For forecast. The expected performance of the rational agent
the duration of the study, they were allowed to reference a upper bounds participants’ performance.
document with the scoring rules and an explanation of how Toapplytherationalagentframework,wefirstformalize
scores would be converted to payoffs.5 the decision problem induced by our study by defining
Participants then completed each block (four questions, the payoff-relevant state (i.e., ground truth answers to the
up to six remeasures). We counterbalanced block order queries),adata-generatingmodel(DGM)thatdefinesajoint
and dataset version, and randomized the order of questions distribution over signals (noised visualizations that inform
ofthepayoff-relevantstate)andthestate,andascoringrule
4.Inaninitialroundofsessions,wemistakenlydescribederrorestimates thatmapsanagent’sforecastandthegroundtruthanswerto
as representing mean squared error (MSE) vs. RMSE (correct). We omit a payoff. The rational agent’s prior is defined by assuming
participantdatafromthesesessions,exceptintwocaseswhereparticipants therationalagenthasknowledgeoftheDGMthatproduces
said in a follow-up that they either thought error represented RMSE or
the experimental stimuli. In other words, the rational agent
wouldnothavechangedtheirresponseshadtheybeentoldRMSE.
understands how the visualizations are created: they are
5.See here for the scoring rule document, full protocol, and interface
showntoparticipants:https://interactive-dp-analysis.github.io/ awareofthegroundtruthdatasetversions,andthatforeachblock, one of four versions is drawn and noised using some andUPPERBOUNDthatcanbeusedtodisambiguatesources
known initial ϵ. of participants’ payoff loss, including their remeasure
We use the framework to devise benchmarks represent- allocation strategies. This benchmark, RPOSTERIOREx-ante,
ing worst-case lower and best-case upper bounds on perfor- allows us to compare participants’ allocations to that of a
mance under different conditions. Unless otherwise noted, rational agent who chooses their allocation strategy before
eachbenchmarkquantifiestheexpectedper-blockpayoffde- seeing any noisy estimates.
fined over blocks and where applicable, over specific seeds
(for noisy estimates) and dataset variations participants re-
RPOSTERIOREx-ante. The rational agent’s expected
payoff when using the optimal fixed (ex-ante)
ceived. Specific calculations are available in Appendix E.
allocationstrategy.Thisstrategyisonethatmaximizes
We begin by designing a worst-case expected payoff,
expected payoff over possible dataset versions
LOWERBOUND.Thisbenchmarkassumesparticipantsform
and possible noisy estimates (admitted by the DP
responses before seeing any noisy estimates and only using
mechanism)withoutknowledgeofanynoisyestimates.
information available to them before beginning the study
(the size of each dataset). This benchmark represents a We next define a benchmark to help study whether par-
baseline payoff if a participant did not pay any attention ticipants’allocationswerebetterthanrandom,andtherefore
to the tasks and answered questions without using any whether they appear to have obtained useful information
information beyond the task instructions. from the visualizations:
LOWERBOUND.Theexpectedpayoffofanagentwho RPOSTERIORRand.Therationalagent’sexpectedpay-
forms fixed forecasts by only using knowledge of the off when randomly allocating the remeasure budget
dataset size (e.g., by evaluating the CDF of a discrete across queries. Note: we calculate expected per-block
uniform distribution from 0 to 1,000). payoffs, over many possible random allocations, that
the rational agent would earn assuming they see the
LOWERBOUND is not a tight lower bound on the same noisy estimates and receive the same dataset
rational agent’s payoff since they, unlike participants, know versions as participants.
thefullexperimentaldesignwhenstartingthestudy.Hence,
we design a worst-case lower bound on payoff for the Theabovebenchmarksalonedonotallowustodirectly
rational agent, RPRIOR, which is obtained when they use quantify the value obtained from remeasuring. Thus, we
a best fixed strategy to determine forecasts accounting only define a benchmark corresponding to the rational agent not
for their prior knowledge (i.e., they do not account for any spending any remeasures, but still seeing the initial set of
noisy estimates). visualizations (i.e., those that appear on the interface when
it first loads). Comparing this benchmark to payoffs under
RPRIOR.Theexpectedpayoffofarationalagentwho strategieswhereremeasuresarespentcharacterizesthevalue
takes the best fixed action by accounting only for attributable to remeasurement.
their prior (i.e., by uniformly sampling over ground
truth answers and using the appropriate quantiles or RPOSTERIORZero. The rational agent’s expected
proportions of draws to determine responses). payoff when they do not spend any remeasures. In
other words, this payoff corresponds to when they
Next, we define an upper bound, UPPERBOUND, on Bayesian update on RPRIOR using only the initial set
performance for the rational agent, which naturally also of measurements.
upper bounds participants’ performance. Defining UPPER-
Last, we are interested in understanding how much the
BOUND also allows us to quantify the total gain in payoff
rational agent would have earned had they used the same
possible (UPPERBOUND−LOWERBOUND). The best pos-
remeasure allocation strategies as participants. This bench-
sible payoff is obtained when the rational agent optimally
mark allows us to, for example, isolate payoff loss due to
allocates remeasures such that information learned from the
allocation decisions separate from participants being non-
resulting noisy estimates maximizes their posterior scores.
Bayesian (because the comparisons we make are in rational
Unfortunately, identifying the optimal allocation is an NP-
agent space, where the agent is Bayesian).
hard problem, hence computationally infeasible. Thus, to
approximate the true upper bound, we instead assume the RPOSTERIORSame. The rational agent’s expected
rational agent spends six remeasures per query. Assuming payoff when making the same remeasure allocations
they spend six remeasures per query upper bounds payoffs as participants.
since the study task only allows six remeasures total across
queries. This is a tighter upper bound than the simplest $10
6.2. Losses
upper bound (total possible payoff per block).
UPPERBOUND. The rational agent’s expected payoff Participants can lose payoff due to two main sources:
when spending six remeasures per query. notoptimallyallocatingremeasuresacrossqueriesandbeing
non-Bayesian(includingnothavingtheexperimentaldesign,
Next, we define benchmarks between LOWERBOUND Bayesian updating, and optimally reporting forecasts basedon noisy estimates). The rational agent framework enables performance within the rational agent framework described
us to infer how much payoff loss for participants stems above.6
from each source using the benchmarks defined above. We
define the following losses in total possible payoff, where 7.1. Preliminaries
P denotes the average payoff participants earned per block:
Participants answered a total of 126 quantitative ques-
• reportingloss.Thelossinpayoffduetoparticipants
tions (3 per block × 3 blocks × 14 participants) and 42
notreportingtheoptimalbeliefs,conditionalontheir
binaryquestions(1perblock×3blocks×14participants).
remeasureallocation,duetonotbeingBayesian.Un-
Participants’ Backgrounds. Participants described
like participants, the rational agent always Bayesian
their level of familiarity with DP as an average of 2.2
updates their prior based on noisy estimates, which
(median=2; “slightly familiar”) on a 5-point Likert scale.
they perfectly interpret from visualizations. Hence,
Those with at least some familiarity understood the general
the difference in payoff when the rational agent
concept behind DP—for example, by reading an article or
and participants use the same remeasure allocation
strategy(RPOSTERIORSame−P)muststem fromei- watchingavideo—butwerenotDPexperts.Participantsall
hadexperience withquantitative dataanalysis,and theirex-
therparticipantsnothavingaccesstotheprior/using
periences ranged across domains (e.g., environmental data,
a different prior, not updating their beliefs like a
health data, social networks). Nine participants had back-
Bayesian, or not accurately interpreting the noisy
grounds leaning more toward classical statistics (vs. predic-
estimates. We quantify this loss as the fraction of
tive modeling or machine learning broadly) while five said
the total payoff increase theoretically possible that
the difference represents ( RPOSTERIORSame−P ). their backgrounds leaned more toward predictive modeling.
UPPERBOUND−LOWERBOUND
• allocation loss (overall). The loss in payoff due
7.2. Descriptive Statistics
to participants suboptimally allocating remeasures
across queries. The difference between UPPER-
Accuracy, Quantitative Questions. Nearly 70% of
BOUND and RPOSTERIORSame captures only the
interval responses contained the ground truth answer.
loss owing to participants’ allocations because it
Two (out of 14) participants always provided intervals
is computed in rational agent space, where being
containing the ground truth, while 11 participants provided
Bayesian is held constant. We contextualize this
intervals containing ground truth in over half of their
difference by dividing by the total possible payoff
intervals. Figure 4 shows the proportion of intervals
increase possible. Thus, we compute this loss as
UPPERBOUND−RPOSTERIORSame. containing ground truth, per participant. Most participants
UPPERBOUND−LOWERBOUND provided intervals with empirical coverage less than 95%,
Note that the above losses are on the scale of possi- aspredictedbypriorresearchonoverconfidenceinintervals
ble payoff increase, which includes both decisions partic- elicited from experts [31].
ipants must make, reporting and allocation. We can sep- The average width of a participant’s interval was about
arately look at the scale for payoff increase from alloca- 24 units, while the median was about 18. Recall that the
tionalone: UPPERBOUND−RPOSTERIORZero.Thebaseline number of records in each block’s dataset was 1,000, so
RPOSTERIORZerocorrespondstotherationalagentwhodoes ground truth answers could have ranged from 0 to 1,000.
not spend any remeasures but perfectly reports information. Intervalscontaininggroundtruth(meanwidth≈29)tended
We additionally compute allocation loss (separated) which to be wider than intervals not containing ground truth
captures the fraction of payoff loss under this scale of (mean width ≈ 13). The proportion of intervals containing
allocation payoff increase without the confounding factor ground truth across single- and multi-value questions were
of reporting loss: similar (0.71 and 0.67, respectively), but the mean interval
width for multi-value questions (≈31) was over triple that
• allocation loss (separated). We compute allocation
of single-value questions (≈9).
loss (separated) as UPPERBOUND−RPOSTERIORSame. When
we compute allocatU ioP nPER lB oO ssUN (D s− eR pP aO raST teER dI )OR fiZelrotered on Accuracy, Binary Questions. Mean absolute error
in “yes” probability responses (calculated relative to the
blocks where participants spent the full remeasure
ground truth of 0 or 1) was 0.37 (95% CI: [0.26, 0.49]).
budget, the denominator becomes UPPERBOUND−
Over 60% of probability responses were in the same
RPOSTERIORRand because RPOSTERIORRand repre-
direction as ground truth—that is, rounding responses
sents a tighter lower bound on the minimum payoff
to a whole number yields the ground truth. Participants
where all six remeasures are spent.
tended to provide “extreme” answers, where the probability
allocated to “yes”/“no” were close to 0 or 1: over 70%
7. Results of probabilities assigned to “yes” were either less than
or equal to 0.2 or greater than or equal to 0.8. As a
We begin with preliminaries, including participants’
6.Code to simulate the rational agent and compute benchmarks, as
backgrounds, then we present a descriptive analysis of
wellasdataanddescriptiveanalysiscodeareavailablehere:https://osf.io/
participants’ responses, and finally we benchmark their ewgkx/?view only=7fefb3b220ab46178e4002c9235b5a71Worst case Best case
allocation loss
A Breakdown of sources of participants’ payoff loss reporting loss (overall)
LOWERBOUND UPPERBOUND
$1.76 P $6.06 RPOSTERIORSame $8.78 $9.10
participants’ total loss
B Payoff loss from suboptimal remeasure allocation (across all blocks)
allocation loss (separated)
RPOSTERIORZero UPPERBOUND
$8.42 $8.78 RPOSTERIORSame $9.10
C Payoff loss from suboptimal remeasure allocation (*across blocks where the full budget was used)
allocation loss (separated)
RPOSTERIORRand* UPPERBOUND*
$8.75 $8.89RPOSTERIORSame* $9.19
Figure 3: Comparisonsbetweenparticipants’performanceandrationalagentbenchmarks.
Appendix F.2 shows the distribution of participant remea-
sures (in gray) across blocks.
7.2.2. Average Earnings and Self-Rated Confidence.
Participantsearnedanaveragepayoffof$6.06perblock(out
ofatotal$10attheblocklevel).Averagesperblockfollow:
CENSUS =$5.44; DIABETES =$6.33; STUDENT =$6.40.
They received an average of $18.17 out of the $30 bonus
available across all three blocks. When asked how much
Figure 4: Theplotshowstheproportionofintervalsthatcontainedthe
of the bonus they thought they earned, participants said
groundtruthanswer,perparticipant.Eachdotrepresentsaparticipant.The
verticalbluelinedepictsthemeanproportion(0.68)andtheverticalgray an average of $13.86. On average, the difference between
lineshows0.95,thecoverageparticipantswereaskedtoprovide. actual payoffs and perceived payoffs was $4.31 and only
four participants earned less than their perceived payoff.
Details on payoffs per question type are in Appendix F.
result, when participants provided answers in the opposite
When asked to rate their confidence in their answers on a
direction to ground truth, they were off by a substantial
scale from 0–100, participants said an average of about 75
amount (an average of 0.80). Participants were slightly
(median ≈78).
more likely to answer single-value binary questions in the
correct direction than multi-value questions (71% vs. 57%).
7.3. Benchmarking Participants’ Performance
7.2.1. RemeasureAllocation.Participantsallocatedremea-
suresfairlyuniformlyacrossquestions,spendinganaverage We compare participants’ performance to that expected
of 1.3 remeasures per question (median = 1). There were underthebenchmarksdefinedabove,andcomputelossesin
no instances of participants spending more than four re- payoffowingtoerrorsinreportingandremeasureallocation.
measures on a single question; in less than 3% of cases did
participants spend more than two remeasures on a question. 7.3.1. Amount of Possible Payoff Increase Participants
While participants usually spent all allotted remeasures per Earned. To begin, we compute the amount of possi-
block, in over a quarter of completed blocks (11 out of 42), ble payoff increase participants actually earned (P −
participants spent fewer than six remeasures. When asked LOWERBOUND) over the total possible payoff increase
during exit interviews about why they did not spend all (UPPERBOUND − LOWERBOUND)7. We find that partici-
available remeasures, one participant said they forgot they pants earned 59% of the possible increase (i.e., they lost
had remeasures in the first block, presumably because they 41% of the possible increase [participants’ total loss;
were occupied with the task of answering questions alone. Figure 3A]), suggesting that although participants earned a
Anotherparticipantattributednotusingallremeasurestoan substantial amount of the potential increase, there is still
issue of time management—if they were to remeasure, they room for improvement. Next, we investigate specifically
said they would want to recalculate their response. Hence, how much payoff increase participants lost due to reporting
we believe that participants understood that remeasuring and allocation decisions.
improved estimates, but failed to use all remeasures for
other reasons. The mean number of remeasures spent per 7.AsdescribedinSection6.1, UPPERBOUND upperboundstheactual
block was about five (median = 6). Further details on upper bound on total payoff possible. We cannot compute the true upper
remeasures by question type and participants’ distributions
bound, but know that it lies between RPOSTERIOREx-ante and UPPER-
BOUND;sincethevaluesforbothareclose($8.88and$9.10,respectively),
ofremeasuresoverquestionsareinAppendixF;Figure6in weproceedasif UPPERBOUNDisthetrueupperbound.7.3.2. Losses in Participants’ Payoff Increase. Recall indicatingthatwhenusingallremeasures,participantsmade
that participants could lose possible payoff increase due to decisions comparable to a strong allocation strategy, albeit
imperfect reporting (reporting loss) and imperfect remea- one that is determined ahead of seeing noisy estimates.
sure allocations (allocation loss [overall]). We quantify and Next,weturnourattentiontoallocationloss(separated),
compare how much of the total possible payoff increase which tells us the fraction of payoff increase possible as-
participants lost based on each source of error. suming perfect reporting that participants’ strategies lost.
We find that participants lost an average of 37% of Wefindthatallocationloss(separated)(Figure3B)is47%,
possible payoff increase due to reporting loss (Figure 3A). indicating that participants’ strategies maximized over half
Recall that reporting loss accounts for loss owing to par- the utility stemming from allocation, but there is still room
ticipants not being exposed to the DGM, not perfectly per- forimprovement.Notethatallocationloss(separated)isona
ceiving presented information, and not Bayesian updating. tighterscalethatcontrolsforreportingloss,hencethehigher
Hence, from these results alone, we cannot know whether value compared to allocation loss (overall). Next, we com-
(1) providing participants with more information about the puteallocationloss(separated)(Figure3C)onlyonblocks
experimental design (i.e., the prior), (2) helping them more where the full remeasure budget was used. Future tools can
accurately perceive presented information, or (3) helping easily prompt analysts to spend any remaining budget, and
them Bayesian update would help close the gap, but this is therefore it is useful to learn how much loss still occurs
a fruitful area of future work (e.g., through calibration [25], once controlling for spending the full budget. On blocks
which helps further disambiguate sources of error). where all remeasures were spent, we find that participants
Next, we investigate payoff loss resulting from partic- lost 70% of possible payoff (in this case, UPPERBOUND
ipants suboptimally allocating remeasures (i.e., allocation - RPOSTERIORRand). Considering we use a strong worst-
loss [overall]). We find that allocation loss (overall) (Fig- case payoff (RPOSTERIORRand) in this calculation, analysts
ure 3A) is 4%; that is, participants lost only 4% of total achieving 30% (i.e., losing 70%) of the possible payoff
possible payoff as a result of their allocation strategies. increase represents a relatively substantial portion of the
Thus, participants lost a greater fraction of total payoff possible payoff increase.
increaseduetoimperfectreportingvs.remeasureallocation.
7.4. Exit Interview Findings
7.3.3. Quality of Participants’ Allocation Strategies. We
furtherstudyparticipants’remeasureallocationstrategiesby
7.4.1. Remeasure Allocation Strategies. Participants em-
controlling for reporting loss, thus isolating errors owing to
ployed a variety of strategies when deciding how to allo-
imperfectallocation.Wecontrolforreportinglossbysetting
cate remeasures. Nine participants (P1-5, P8-9, P11, P13)
the baseline as RPOSTERIORZero and calculating allocation
describedusingthesizeoferrorestimatesinsomecapacity,
loss (separated) as defined in Section 6.2.
usually allocating remeasures to visualizations with large
We first investigate whether participants’ allocations
error estimates. As P13 described:
appear to be responsive to seeing noisy estimates. We
I was basically looking at upper bound minus
check on a block-by-block basis whether the rational
lower bound for whichever questions I feel like
agent who makes the same allocation as the partici-
[the gap is] a lot. I was trying to get it as tight as
pant (RPOSTERIORSame) earns more than if the rational
possible by using the remeasures.
agent makes a random allocation (RPOSTERIORRand). If
RPOSTERIORSame > RPOSTERIORRand, we conclude that P9 adopted this strategy after first trying a uniform
the allocation used by the participant appears to be respon- allocation strategy:
sive to seeing noisy estimates. We find that in just over
At first I just spread [remeasures] across [visual-
half of blocks (55%), participants’ remeasure allocations
izations]fairlyequally,butthenasIwentthrough
appear better than random.8 The fact that in some blocks
the study I realized there were definitely a range
participants did not allocate better than random could be
of variances across the different questions . . .
due to randomness in strategies (even if participants use a
becauseweareawardedforhavingtighterranges,
randomstrategy,thereisachancetheirpayoffislowerthan
I started using the remeasures on [visualizations]
the expected payoff over random allocations).
where there was a wider variation in the data.
Now, recall that in a little over a quarter of blocks,
In general, applying remeasures uniformly, at least as
participants did not use the full remeasure budget. We find
some part of the allocation strategy, was not uncommon.
that in blocks where participants used the full remeasure
This strategy is consistent with our finding that the average
budget, they had a higher chance of RPOSTERIORSame >
number of remeasures spent on each question is slightly
RPOSTERIORRand (65% vs. 27%). In fact, excluding blocks
over one. Four participants (P4, P6, P9-10) described first
where participants did not use the full budget, RPOSTE-
spending one remeasure on each question, then using dif-
RIORSame ($8.88) is close to RPOSTERIOREx-ante ($8.94),
ferent strategies to determine where to spend remaining
remeasures.Forexample,P4saidtheyallocatedremeasures
8.Foreachofthe42completedblocks,wecomparetherationalagent’s
uniformly, but held off on spending remeasures on visual-
payoff with the same remeasure allocation strategy the participant used
withtherationalagent’spayoffwitharandomallocationstrategy. izations with smaller error bars.Two participants (P6, P10) looked for “trends” in how brushing & linking, and the ability to adjust y-axis limits
visualizations changed between remeasures. For example, to customize how zoomed in the view of the data is. Last,
P6appliedremeasurestovisualizationswhichshowedlarge participants provided other interface-level feedback that can
changes in estimates: inform future DP tools. Three participants (P4, P9, P12)
Iwouldlookatthefirstmeanandthemeanofthe wanted the tool to support automatic summation of selected
first remeasure. If those means are far apart, then noisy estimates or said that summing presented challenges.
I would remeasure. Finally, four participants (P2-3, P9-10) did not find re-
A few participants described allocating remeasures in centeringaroundpreviouserrorstobeuseful,two(P2,P11)
ways that were independent of the error in estimates and wanted to tooltips to remain “on” when hovered (ostensibly
scoring rules, suggesting some deviation from the instruc- sotheycouldreferencenumbersastheymadecalculations),
tions. Three participants described allocating remeasures and one (P12) wanted to see all previous errors displayed.
based on question type. P8 and P5 tended to allocate re-
measurestomulti-valuequestions,andP2prioritizedspend- 8. Limitations
ing remeasures on binary questions. One participant (P14)
applied remeasures when error intervals contained negative Our study results are subject to some limitations. First,
values and two participants (P11-12) described spending we cannot separate loss from not understanding scoring
remeasures on either the first or last couple visualizations. rules from the sources of loss we describe above. Our
P11 said that if they had extra remeasures by the time results may also be sensitive to the elicitation interface
they answered the last question, they would spend extra we used. Further, due to a bug in our code for generating
remeasures on that visualization. differentially-private estimates, variable labels within two
questions were flipped. Thus, the noisy estimates shown
7.4.2. Future Strategies. When asked how they would to participants actually corresponded to a different subset
approach the analysis tasks differently were they to re-do of groups than expected. We therefore scored participants
them, four participants (P10, P12-13, P4) said they either basedonthegroundtruthunderlyingtheestimatestheysaw.
would not change their strategy or were unsure about how Duringanalysis,werecomputedthenormalizationconstants
they would change their approach. On the other hand, five forthesetwoquestionsusingthesameprocessasbefore,but
participants (P1-3, P9, P11), two of whom used strategies accounting for the flipped labels. We doubt this had much,
thatwereindependentoferrorinestimates,describedpaying if any, impact on results, but we cannot say for sure.
more attention to error estimates in some form, either by Mismatches between our experimental setting and real-
interpreting them differently or reviewing error estimates world analysis settings may also impact the validity of our
across queries before allocating remeasures. For example, results. We provided participants with datasets and analy-
P1 said they would first filter visualizations to focus on sis questions, whereas in practice, analysts iteratively form
estimates of interest, then observe errors across relevant analysis questions on datasets of their choosing during an
estimates, and complete “all questions sort of simultane- EDA. However, as an initial step in studying our paradigm,
ously.” Two participants (P6, P8) said they would employ we were interested in comparing analysts’ performance to
the strategy they developed in later blocks on the first best attainable performance, which is hard to do without
block. These results suggest that use of the MEASURE- a well-defined decision problem. Future work may conduct
OBSERVE-REMEASURE workflow may improve as analysts additional studies where participants define their own anal-
become more familiar with it, and that it might be useful ysis questions, perhaps on a dataset of their choosing, and
to suggest to analysts in real, evolving EDA workflows that qualitativelyevaluatetheiranalysesonthebasisofhowwell
they proceed through queries without remeasuring at first, analysts felt they met their EDA goals.
then circle back to apply remeasures once the query set has Further, our study is exploratory by nature and attempts
been determined. to get an initial sense of where participants struggled when
using the paradigm, and gain insight into why they may
7.4.3. InterfaceFeedback.Wesummarizefeedbackpartic-
have struggled. Our results, which are based on a relatively
ipants gave during exit interviews on their experience using
small sample size, therefore should not be interpreted as
the MEASURE-OBSERVE-REMEASURE paradigm via the
confirmatory evidence of analysts’ performance under our
interface. A handful of participants mentioned remeasuring
paradigm.Futureworkmightattemptlarger,controlledstud-
(P2-3,P7),thegraphsgenerally(P6-7,P14),thetooltip(P6-
ies that compare analysts’ use of our paradigm to their use
7, 9), and the ability to recenter errors (P1, P11) as helpful.
of approaches based in the MEASURE-OBSERVE paradigm.
Notably, participants’ independent, positive appraisals of
remeasuring suggests that the interactivity of the paradigm
9. Discussion
was simple for participants to adapt to.
Over half of participants (P2, P5-6, P8-13) mentioned
filtering as a helpful feature and exactly half of participants 9.1. Making Differential Privacy Usable
(P2-4,P7,P9,P14)saidthattheabilitytore-scalethey-axis
washelpful.ThesefindingssuggestthatDPtoolssupporting DPhasbeenadoptedbyseverallargeorganizations(e.g.,
histogram queries may benefit from enabling filtering via Apple[32],Google[33],Microsoft[34],Uber[35],andtheU.S. Census Bureau [36]) in recent years, but has yet to error. If adapted in the literature on interfaces for DP
be widely adopted by smaller organizations across indus- decision-making, this approach offers a rigorously-defined
try [13]. DP still has a high barrier to entry, often requiring notionofbestattainableperformancewithaninterface.The
expert teams to implement differentially-private systems, framework can be applied to improve experiment design
thereforemakingitlesslikelythatsmallerorganizationscan before a study is run by identifying where the incentive
useit.Ourworkattemptstomakeiteasierfororganizations for participants to use the query results is low relative to
withoutDPexpertstoconductdifferentially-privateanalyses the baseline expected payoff for completing the experiment
by using our approach. (for example, for our study, this incentive can be calculated
Given the fact that our study participants completed as UPPERBOUND − LOWERBOUND). Future work may
tasksrelativelywelldespitelimitedtraining,theMEASURE- also involve calibrating participants’ responses to account
OBSERVE-REMEASURE paradigm may help enable more for their not knowing the experimental design, allowing
organizationstoadoptDP.Futureworkshouldexpandtools further disambiguation among sources of behavioral er-
that support analysts, for example by creating tools that ror [25]. Calibration entails scoring the expected behavior
support the MEASURE-OBSERVE-REMEASURE paradigm of a rational agent who has access to the joint distribution
forotherqueriescommonindataanalysis(e.g.,mean,maxi- of the uncertain state and the participants’ reports, but not
mum,minimum).Supportingotherqueriesmaybenefitfrom thesignals(i.e.,visualization).Notethatthe frameworkcan
visualizationstrategiesbeyondhistograms,dependingonthe be applied to evaluate tools beyond interfaces, such as DP
nature of the query. For example, displaying differentially- querying systems or libraries [41], as long as they support
private scatterplots [37], [38], [39] raises questions around a common set of analysis tasks.
how to show changes in estimated error upon remeasure-
ment. In such cases, animation or other display strategies Conclusion
may be useful in conveying changes in error [40].
Additionally, somewhat surprisingly, participants in our
We propose the MEASURE-OBSERVE-REMEASURE
study did not always use the full remeasure (privacy loss)
paradigm for helping analysts conduct differentially-private
budget, despite being explicitly told that remeasuring im-
exploratory analyses. We instantiate the paradigm in an
proves estimates. Based on observation and probing dur-
interactive interface, which allows analysts to interactively
ing exit interviews, we believe that the cognitive load of
spend ϵ by observing results and allocating additional ϵ
interpreting noisy estimates and forming beliefs was great
where necessary. In this way, the paradigm aids in staying
enough at times to cause participants to forget about or
underatotalprivacylossbudgetwhileobtaininghigh-utility
discountthevalueofremeasuring.Thisunexpectedbehavior
results. We explore how analysts interact with the paradigm
highlights the challenge of supporting analysts in adopting
through a decision-theoretic user study, which allows for
DP in their workflows, and suggests that additional support
comparisons in utility obtained by participants with utility
in managing ϵ could be beneficial. Apart from simple re-
obtained by a rational agent faced with the same decision
minder mechanisms to use the full budget, tools might also
task. We find that analysts are able to use the paradigm
suggestvariousallocationstrategiesforanalyststoconsider.
relatively successfully; they are able to maximize over
Analysts can then adjust strategies according to their needs
half the utility stemming from allocation of ϵ. Compared
and the estimates they observe.
to allocating ϵ, they lose more payoff from suboptimally
We envision also supporting analysts in making more
interpreting noisy estimates and using them to form beliefs.
efficient use of ϵ by allowing query results to update “in
tandem” when ϵ is spent on any given question. For exam-
Acknowledgments
ple, if two questions overlap in data schema, results from
one question can potentially increase the accuracy of the
The authors would like to thank members of the MU
other. Thus, when an analyst spends ϵ on one question,
Collective for feedback on the interface. Gerome Miklau,
our interface could also dynamically update plots for other
Narges Mahyar, and Ali Sarvghad were supported by NSF
questions that can also “gain” from the additional informa-
SATC grant #1954814.
tion obtained for the first question. HDMM supports such
updating.However,ifthisfeatureisintegrated,analystsmay
need additional support to determine how to adjust their References
strategiestoaccountformultiplequeryrevisionsintandem.
[1] R. Steed, T. Liu, Z. S. Wu, and A. Acquisti, “Policy impacts of
9.2. Adapting the Rational Agent Framework to statistical uncertainty and privacy,” Science, vol. 377, no. 6609, pp.
928–931,2022.
Differential Privacy
[2] C.Dwork,F.McSherry,K.Nissim,andA.Smith,“Calibratingnoise
to sensitivity in private data analysis,” in Theory of Cryptography:
Our work contributes an adaption of a rational agent
ThirdTheoryofCryptographyConference,TCC2006,NewYork,NY,
framework to DP—specifically to evaluate privacy loss
USA,March4-7,2006.Proceedings3. Springer,2006,pp.265–284.
budget decisions against various benchmarks representing
[3] C.DworkandA.Roth,“Thealgorithmicfoundationsofdifferential
different strategies and access to information in a way
privacy,”FoundationsandTrends®inTheoreticalComputerScience,
that allows for identifying and characterizing sources of vol.9,no.3–4,pp.211–407,2014.[4] J. Sarathy, S. Song, A. Haque, T. Schlatter, and S. Vadhan, “Don’t [22] M. Hay, A. Machanavajjhala, G. Miklau, Y. Chen, and D. Zhang,
lookatthedata!howdifferentialprivacyreconfiguresthepracticesof “Principled evaluation of differentially private algorithms using dp-
datascience,”inProceedingsofthe2023CHIConferenceonHuman bench,” in Proceedings of the 2016 International Conference on
FactorsinComputingSystems,2023,pp.1–19. Management of Data, ser. SIGMOD ’16. New York, NY, USA:
AssociationforComputingMachinery,2016,p.139–154.
[5] L.Wasserman,“Minimaxity,statisticalthinkinganddifferentialpri-
vacy,”JournalofPrivacyandConfidentiality,vol.4,no.1,2012. [23] D.Zhang,R.McKenna,I.Kotsogiannis,M.Hay,A.Machanavajjhala,
and G. Miklau, “Ektelo: A framework for defining differentially-
[6] J.W.Tukeyetal.,Exploratorydataanalysis. Reading,MA,1977, privatecomputations,”inProceedingsofthe2018InternationalCon-
vol.2. ferenceonManagementofData,2018,pp.115–130.
[7] H.A.Simon,“Boundedrationality,”Utilityandprobability,pp.15– [24] F. D. McSherry, “Privacy integrated queries: an extensible platform
18,1990. forprivacy-preservingdataanalysis,”inProceedingsofthe2009ACM
SIGMODInternationalConferenceonManagementofdata,2009,pp.
[8] S.Nun˜ezvonVoigt,M.Pauli,J.Reichert,andF.Tschorsch,“Every
19–30.
query counts: Analyzing the privacy loss of exploratory data analy-
ses,”inDataPrivacyManagement,CryptocurrenciesandBlockchain [25] Y. Wu, Z. Guo, M. Mamakos, J. Hartline, and J. Hullman, “The
Technology:ESORICS2020InternationalWorkshops,DPM2020and rationalagentbenchmarkfordatavisualization,”IEEETransactions
CBT2020,Guildford,UK,September17–18,2020,RevisedSelected onVisualizationandComputerGraphics,2023.
Papers15. Springer,2020,pp.258–266.
[26] T.GneitingandA.E.Raftery,“Strictlyproperscoringrules,predic-
[9] R. McKenna, G. Miklau, M. Hay, and A. Machanavajjhala, “Opti- tion,andestimation,”JournaloftheAmericanstatisticalAssociation,
mizingerrorofhigh-dimensionalstatisticalqueriesunderdifferential vol.102,no.477,pp.359–378,2007.
privacy,”arXivpreprintarXiv:1808.03537,2018.
[27] G. W. Brier et al., “Verification of forecasts expressed in terms of
[10] McKenna, Ryan and Miklau, Gerome and Hay, Michael and probability,”Monthlyweatherreview,vol.78,no.1,pp.1–3,1950.
Machanavajjhala, Ashwin, “HDMM: Optimizing error of high- [28] TaskC.andBhagatK.andStreatD.andSimpsonA.andHowarth
dimensional statistical queries under differential privacy,” VLDB, G.S., “NIST Diverse Communities Data Excerpts,” 2023. [Online].
2021. Available:https://doi.org/10.18434/mds2-2895
[11] C.Li,G.Miklau,M.Hay,A.McGregor,andV.Rastogi,“Thematrix [29] B. Strack, J. P. DeShazo, C. Gennings, J. L. Olmo, S. Ventura,
mechanism: optimizing linear counting queries under differential K. J. Cios, and J. N. Clore, “Impact of hba1c measurement on
privacy,”TheVLDBjournal,vol.24,pp.757–781,2015. hospitalreadmissionrates:analysisof70,000clinicaldatabasepatient
records,”BioMedresearchinternational,vol.2014,2014.
[12] I. C. Ngong, B. Stenger, J. P. Near, and Y. Feng, “Evaluating the
usability of differential privacy tools with data practitioners,” arXiv [30] N.GunduzandE.Fokoue,“UCImachinelearningrepository,”2013.
preprintarXiv:2309.13506,2023. [Online]. Available: http://archive.ics.uci.edu/ml/datasets/turkiye+
student+evaluation
[13] G. M. Garrido, X. Liu, F. Matthes, and D. Song, “Lessons learned:
Surveying the practicality of differential privacy in the industry,” [31] J. B. Soll and J. Klayman, “Overconfidence in interval estimates.”
PrivacyEnhancingTechnologies(PETS),2023. JournalofExperimentalPsychology:Learning,Memory,andCogni-
tion,vol.30,no.2,p.299,2004.
[14] M.Gaboardi,J.Honaker,G.King,J.Murtagh,K.Nissim,J.Ullman,
andS.Vadhan,“Psi(Ψ):aprivatedatasharinginterface,”2018. [32] Apple Differential Privacy Team, “Learning with privacy at scale,”
2017. [Online]. Available: https://docs-assets.developer.apple.com/
[15] P.Thaker,M.Budiu,P.Gopalan,U.Wieder,andM.Zaharia,“Over- ml-research/papers/learning-with-privacy-at-scale.pdf
look: Differentially private exploratory visualization for big data,”
TheoryandPracticeofDifferentialPrivacy(TPDP),2020. [33] U´. Erlingsson, V. Pihur, and A. Korolova, “Rappor: Randomized
aggregatableprivacy-preservingordinalresponse,”inProceedingsof
[16] P.Nanayakkara,J.Bater,X.He,J.Hullman,andJ.Rogers,“Visual- the2014ACMSIGSACconferenceoncomputerandcommunications
izingprivacy-utilitytrade-offsindifferentiallyprivatedatareleases,” security,2014,pp.1054–1067.
Proceedings on Privacy Enhancing Technologies, vol. 2022, no. 2,
[34] B.Ding,J.Kulkarni,andS.Yekhanin,“Collectingtelemetrydatapri-
pp.601–618,2022.
vately,”AdvancesinNeuralInformationProcessingSystems,vol.30,
[17] M. F. S. John, G. Denker, P. Laud, K. Martiny, A. Pankova, and 2017.
D.Pavlovic,“Decisionsupportforsharingdatausingdifferentialpri-
[35] K. Tezapsidis, “Uber releases open source
vacy,”in2021IEEESymposiumonVisualizationforCyberSecurity
project for differential privacy,” 2017. [On-
(VizSec). IEEE,2021,pp.26–35.
line]. Available: https://medium.com/uber-security-privacy/
[18] C.Ge,X.He,I.F.Ilyas,andA.Machanavajjhala,“Apex:Accuracy- differential-privacy-open-source-7892c82c42b6
aware differentially private data exploration,” in Proceedings of the
[36] J.M.Abowd,“Theuscensusbureauadoptsdifferentialprivacy,”in
2019 International Conference on Management of Data, 2019, pp. Proceedingsofthe24thACMSIGKDDInternationalConferenceon
177–194. KnowledgeDiscovery&DataMining,2018,pp.2867–2867.
[19] D.M.Bittner,A.E.Brito,M.Ghassemi,S.Rane,A.D.Sarwate,and [37] D.Zhang,M.Hay,G.Miklau,andB.O’Connor,“Challengesofvisu-
R.N.Wright,“Understandingprivacy-utilitytradeoffsindifferentially alizingdifferentiallyprivatedata,”TheoryandPracticeofDifferential
privateonlineactivelearning,”JournalofPrivacyandConfidentiality, Privacy,vol.2016,pp.1–3,2016.
vol.10,no.2,2020.
[38] J. Zhou, X. Wang, J. K. Wong, H. Wang, Z. Wang, X. Yang,
[20] Y.Guo,F.Liu,T.Zhou,Z.Cai,andN.Xiao,“Seeingisbelieving: X.Yan,H.Feng,H.Qu,H.Yingetal.,“Dpviscreator:Incorporating
Towards interactive visual exploration of data privacy in federated patternconstraintstoprivacy-preservingvisualizationsviadifferential
learning,”InformationProcessing&Management,vol.60,no.2,p. privacy,”IEEETransactionsonVisualizationandComputerGraphics,
103162,2023. vol.29,no.1,pp.809–819,2022.
[21] M. Hay, A. Machanavajjhala, G. Miklau, Y. Chen, D. Zhang, and [39] L. Panavas, T. Crnovrsanin, J. L. Adams, J. Ullman, A. Sargavad,
G.Bissias,“Exploringprivacy-accuracytradeoffsusingdpcomp,”in M.Tory,andC.Dunne,“Investigatingthevisualutilityofdifferen-
Proceedingsofthe2016InternationalConferenceonManagementof tially private scatterplots,” IEEE Transactions on Visualization and
Data,2016,pp.2101–2104. ComputerGraphics,2023.[40] J. Hullman, P. Resnick, and E. Adar, “Hypothetical outcome plots was insufficient, where x is the starting value of ϵ. The
outperformerrorbarsandviolinplotsforinferencesaboutreliability followingpointsshowscenarioswheretheanalystdecidesto
ofvariableordering,”PloSone,vol.10,no.11,p.e0142444,2015. allocatemoreϵtothequeryafterrealizingtheinitialamount
[41] G. M. Garrido, J. Near, A. Muhammad, W. He, R. Matzutt, and was insufficient (i.e., they then instead allocate ϵ = 3x,
F. Matthes, “Do i get the privacy i need? benchmarking utility in ϵ=4x, etc.).
differentialprivacylibraries,”arXivpreprintarXiv:2109.10789,2021.
Appendix A.
Comparing to MEASURE-OBSERVE
We provide some intuition around the benefits of the
MEASURE-OBSERVE-REMEASURE paradigm by compar-
ing accuracy outcomes between our paradigm and the
MEASURE-OBSERVEparadigmacrossexampledatasetsand
different amounts of ϵ.
Imaginethefollowingscenario:Ananalystisconducting
an EDA and midway through, they issue a query to learn
how many people satisfying a given set of attributes (e.g.,
raceandage)areinthedataset.WeassumetheyuseHDMM
and the Laplace Mechanism to compute differentially-
private estimates. They MEASURE the query with ϵ = x
to get an initial estimate, p . They quickly realize the
original Figure 5: Theplotshowsdifferencesinexpectederrorsobtainedwhen
error associated with the estimate (relative to the estimate
the analyst continues the analysis under the MEASURE-OBSERVE vs.
itself)istoolarge,anddecidetospendanadditionalϵ=2x MEASURE-OBSERVE-REMEASURE paradigms. For the same amount of
on the query. Depending on which paradigm they are oper- total ϵ spent, the MEASURE-OBSERVE-REMEASURE paradigm leads to
ating under, they spend the additional ϵ in different ways: smaller expected error, owing to the fact that all previous estimates are
combinedwithafreshestimatetoproducethenewestimate.
MEASURE-OBSERVE Paradigm. The analyst decides to
MEASURE the query again with ϵ = 2x, which results in a
newestimatep new.They OBSERVE p new andtheassociated Appendix B.
error and are satisfied. They proceed with the EDA to other
Normalizing Scores
queries. Note that the full analysis of this query consumed
a total of ϵ=3x, but p was produced with only ϵ=2x.
new We normalize scores for a given question using x−score,
MEASURE-OBSERVE-REMEASURE Paradigm. The ana-
where x is a normalization constant. We use
questx
ion-
lystdecidestoREMEASUREthequerywithϵ=x.TheyOB-
specific normalization constants representing a “maximum
SERVE the new estimate, p interim, which already accounts bound”oneachquestion’sscore.Thenormalizationconstant
for information learned from p and a fresh estimate.
original for all binary questions is 2, since this is the highest (i.e.,
They quickly realize they require even better accuracy, so
worst)possiblescoreproducedbythequadraticscoringrule.
they REMEASURE again with ϵ = x. The resulting esti- On the other hand, scores produced by the interval scoring
mate,p ,accountsforinformationlearnedfromp ,
new original ruleareunbounded.Thus,toobtain“maximumbounds,”for
p ,andanotherfreshestimate.Theyaresatisfiedwith
interim quantitative questions, we imagine that a participant always
p
new
and proceed with the EDA. Like in the MEASURE-
reportsthe(noisy)estimate±errorastheirlowerandupper
OBSERVE version of the scenario, the full analysis of this bounds, and use the 95th quantile of scores produced with
query consumed a total of ϵ = 3x, however in this case,
this method as the normalization constant (see Table 1). If
p was also produced with ϵ=3x.
new normalized scores are negative (i.e., because a participant’s
Wecompareerrorsassociatedwitheachparadigmunder
answer exceeded our prediction of our expectations about
the above scenario on count queries on three datasets for
bounds),weconvertthescoreto0.Participantscouldearna
three example queries (CENSUS, Question 1; DIABETES,
maximumof$2.50perquestion,dependingontheaccuracy
Question 1; STUDENT, Question 1)9 for different starting
of their answers.
values of ϵ∈[0.1,0.3,0.5].
Figure 5 shows expected errors of the estimates the
analyst will receive under each paradigm. The errors are
computed using HDMM’s error equation, which is data-
independent. The first points on both curves show error ob-
tained from the example scenarios above, where the analyst
allocates ϵ=2x after realizing the initial amount of ϵ=x
9.For each dataset, we use one of the dataset variations that appeared
intheuserstudy.Dataset Question Normalization Constant
3) Are there more than 167 students who rated their
CENSUS 1 75.00 attendance as 2 or less, and the difficulty of the
2 2.00 course as 4 or more? (binary; multi-value)
3 217.69 4) How many students said they agreed or strongly
4 56.8 agreedthatthe instructor’sknowledgewasrelevant
DIABETES 1 113.4 and up-to-date, and also rated the difficulty of the
2 283.3 class as 3 or less? (quantitative; multi-value)
3 186.2
4 2.00
Appendix D.
STUDENT 1 178.8
2 185.6 Exit Interview Questions
3 2.00
4 56.8
1) Describe your strategy for deciding where to allo-
cate remeasures.
TABLE 1: Normalization constants.
2) How well do you think you did on the task?
3) How would you rate your confidence in your an-
swers on a scale from 0 to 100, where 100 is the
Appendix C.
most confident.
Task Questions
4) How much of the $30 bonus do you think you
earned?
Below are analysis questions shown to participants. We 5) Briefly describe which parts of the interface you
randomly ordered questions within each block. found challenging to use (and didn’t seem to help
you with the task).
CENSUS 6) Briefly describe which parts of the interface you
found easy to use (and helped you with the task).
1) Howmany“BlackorAfricanAmericanalone”and 7) What information would you have liked the inter-
“Asian alone” people are at least 55 years old? facetohaveincludedtobettersupportyouwiththe
(quantitative; multi-value) task?
2) Are there more than 327 people who have never 8) If you were to re-do the task, what would you do
been married and make less than $100,000? (bi- differently?
nary; multi-value) 9) How would you describe your level of familiarity
3) How many “White alone” people do not have chil- with differential privacy? (1 – Not at all familiar
dren? (quantitative; single-value) 2 – Slightly familiar 3 – Somewhat familiar 4 –
4) Howmanypeoplewhoareatleast65yearsoldare Moderately familiar 5 – Extremely familiar)
widowed or divorced? (quantitative; multi-value) 10) Brieflydescribethekindofanalysisyoutendtodo
or have a background in.
DIABETES
1) For people who had elective or newborn admission Appendix E.
types, how many had hospital stays for at least 3
Calculating Benchmarks
days? (quantitative; multi-value)
2) How many people under 60 years old take at least
10 medications? (quantitative; multi-value) E.1. Calculating RPRIOR
3) How many African American people had hospital
stayslastinglessthan5days?(quantitative;single-
We define the rational agent prior responses for each
value)
quantitative question by first sampling many draws (e.g.,
4) Are there 450 or fewer people who had emergency
10,000) with replacement from the four ground truth an-
admissiontypesandare50yearsorolder?(binary;
swers (corresponding to each dataset version for the block)
single-value)
to mimic the sampling procedure used in the study. The
STUDENT rationalagent’sintervalbeliefaboutthegroundtruthanswer
is then bounded by the 2.5th and 97.5th quantiles of the
1) How many students said that they agreed or draws. For each binary question, we imagine the rational
strongly agreed that Instructor 3’s knowledge was agentsamples10,000drawswithreplacementfromthefour
relevantandup-to-date?(quantitative;single-value) groundtruthanswers,andusestheproportionof“yes”/“no”
2) How many students said that they strongly dis- answers from the draws as their beliefs about the ground
agreed or disagreed that they greatly enjoyed and truth answer. We convert these prior responses first into
wereeagertoparticipateinInstructor1or2’sclass? scores, then into expected payoffs. With expected payoff
(quantitative; multi-value) per question, we then calculate expected payoff per block.E.2. Calculating LOWERBOUND Appendix G.
Meta-Review
To compute LOWERBOUND, we use only information
about the task setup without any noisy estimates: that there Thefollowingmeta-reviewwaspreparedbytheprogram
were 1,000 records per dataset, each block contained four committee for the 2024 IEEE Symposium on Security and
questions (three quantitative, one binary), and answer for- Privacy (S&P) as part of the review process as detailed in
mats(intervals,probabilities)foreachquestiontype.Hence, the call for papers.
for quantitative questions, we assume a discrete uniform
distribution over possible counts x ∈ {0,1,...,1000} and
G.1. Summary
compute the 2.5th and 97.5th quantiles of the distribution
as interval lower and upper bounds, respectively. Binary
The paper looks at differential privacy in the context
questions ask whether the count of records x satisfying a
of exploratory data analysis and proposes an interactive
set of constraints are above/below some threshold t. If a
analysis approach in which analysts first obtain estimates
question asks, for example whether x is less than t, we use
and then expend more of their privacy budget on follow-up
Pr[x < t] as the probability of “yes” and 1−Pr[x < t] as
queries. This approach is supported by an interactive visu-
the probability of “no.” We convert responses into scores
alization. The paper further presents a user study (n = 14)
and expected payoff per question, then block by summing.
demonstrating that analysts can use the proposed approach
pretty well when compared to various models of rational
Appendix F.
agents without extensive knowledge of differential privacy.
Additional Analysis Results
G.2. Scientific Contributions
F.1. Payoffs by Question Type
• Creates a New Tool to Enable Future Science
We examine differences in payoffs across types of • Provides a Valuable Step Forward in an Established
questions—each question was worth $2.50. Participants Field
earned an average of $1.41 (median = $1.65) for quanti-
tative questions and an average of $1.82 (median =$2.39) G.3. Reasons for Acceptance
for binary questions. There appears to be a difference be-
tween payoffs for single- and multi-value questions: the 1) Thepaperprovidesavaluablestepforwardinanes-
averagepayoffforsingle-valuequestionswas$1.97(median tablishedfield.Thispaperpresentsanewparadigm
=$2.36)whiletheaveragepayoffformulti-valuequestions for interactive Differential Privacy (DP) to be used
was $1.29 (median =$1.62). to support Exploratory Data Analysis (EDA). DP
and EDA are inherently at odds as DP is meant to
F.2. Remeasure Allocations protect against probing/exploration of databases to
protectagainstdifferencingattacks.But,aspointed
Participants spent an average of 1.3 remeasures on outinthepaper,thereareverylegitimatereasonsto
quantitative questions and an average of 1.1 remeasures on have to do exploratory data analysis and the paper
binaryquestions.Participantsspentanaverageofaboutone providesaninterestingsolutionforreconcilingthat
remeasureonsingle-valuequestionsandanaverageofabout need with DP protections.
1.4 remeasures on multi-value questions. 2) The paper creates a new tool to enable future
science. The paper operationalizes the MEASURE-
OBSERVE-REMEASURE paradigm through an in-
teractive visualization. They also make their code
anddatatomodelrationalagentspubliclyavailable.
This allows for both independent confirmation and
allows the tool to be used in future research.
G.4. Noteworthy Concerns
1) The study is conducted with a small sample (n =
Figure 6: Remeasure allocations for each participant (gray) 14) of participants. A larger sample size would be
and therational agent underthe ex-anteallocation (orange). preferable to obtain more robust results, but this
Questions not labeled “binary” are “quantitative” and those size is sufficient as this is exploratory work.
not labeled “single” are multi-value. 2) Participants were recruited from graduate student
listservs and through the authors’ personal net-
works. Participants were not asked to report their
professional experience, so it is not clear whetherthe sample included professionals, which would be
preferable as professionals might bring additional
expertisetothetask.However,ataminimum,these
results provide insights for early career analysts
with limited DP experience, and the study is de-
signed to limit the need for domain knowledge.