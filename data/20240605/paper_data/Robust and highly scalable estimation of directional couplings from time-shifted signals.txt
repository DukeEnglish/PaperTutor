Robust and highly scalable estimation of directional
couplings from time-shifted signals
LucaAmbrogioni∗ LouisRouillard∗
DondersInstituteforBrain,Cognition,andBehaviour Parietal,InriaSaclay
RadboudUniversity UniversitéParis-Sud
luca.ambrogioni@donders.ru.nl louis.rouillard@gmail.com
DemianWassermann
Parietal,InriaSaclay
UniversitéParis-Sud
demian.wassermann@inria.fr
Abstract
Theestimationofdirectedcouplingsbetweenthenodesofanetworkfromindirect
measurementsisacentralmethodologicalchallengeinscientificfieldssuchasneu-
roscience,systemsbiologyandeconomics. Unfortunately,theproblemisgenerally
ill-posed due to the possible presence of unknown delays in the measurements.
In this paper, we offer a solution of this problem by using a variational Bayes
framework,wheretheuncertaintyoverthedelaysismarginalizedinordertoobtain
conservativecouplingestimates. Toovercomethewell-knownoverconfidenceof
classicalvariationalmethods,weuseahybrid-VIschemewherethe(possiblyflat
ormultimodal)posterioroverthemeasurementparametersisestimatedusinga
forwardKLlosswhilethe(nearlyconvex)conditionalposterioroverthecouplings
isestimatedusingthehighlyscalablegradient-basedVI.Inourground-truthexper-
iments,weshowthatthenetworkprovidesreliableandconservativeestimatesof
thecouplings,greatlyoutperformingsimilarmethodssuchasregressionDCM.
1 Introduction
Severalphysical,biologicalandtechnologicalcomplexsystemscanbecharacterizedbythestructure
ofinterconnectionsbetweenalargenumberoftheirrelativelysimplecomponents. Forexample,the
humanbrainiscomposedofapproximately100billionneurons,whichareconnectedbypotentially
as many as 600 trillion synapses Herculano-Houzel [2009], Von Bartheld et al. [2016], Loomba
et al. [2022]. Similarly, the working of an individual cell is depends on a complex networks of
bio-chemicalinteractionsthatcanagainbeunderstoodintermsofcausalinteractionsbetweenits
componentsWhiteandAnderson[2005],Kravchenko-Balashaetal.[2012]. Thescientificstudy
ofsuchcomplexsystemsfundamentallyreliesontheuseofnon-invasivehigh-coveragemeasuring
methods. Unfortunately,thesemethodstendtoperformindirectmeasurementsthatofteninduces
variabletimedelaysintherecordedsignals. Forexample,fMRImeasuresneuronalactivitythrough
changesinconcentrationofoxygenatedblood,whichintroducesatemporalshiftduetothelatency
oftheneural-metaboliccouplingBuckner[1998],Lindquistetal.[2009]. Thesepotentiallyvariable
timedelaysposeaseriousproblemwhentheaimistoestimatedirectedcouplings,sincethepotential
timereversalofthecross-correlogramscanleadtospuriousinferenceStephanandRoebroeck[2012],
Ramseyetal.[2010],Rautetal.[2019].
∗Equalcontribution
Preprint.Underreview.
4202
nuJ
4
]GL.sc[
1v54520.6042:viXraInthispaper,weintroduceaninferencemethodthatusesamixtureofforwardandreversedvariational
inferencelossestorecoverthecomplexmultimodaljointposteriorofcouplingandshiftvariables. We
useaforwardamortizedvariationalinference(FAVI)approachtoestimatetheposteriordistributions
oftheshiftparameters[PapamakariosandMurray,2016,Ambrogionietal.,2019b];whileweuse
ahighlyscalablegradient-basedreverseKLapproachtoestimatethe(nearlyconvex)posteriorof
thecouplingmatrixgiventheshifts[MnihandRezende,2016,Kucukelbiretal.,2017,Frässleetal.,
2017]. Treatingtheshiftparametersdifferentlyfromthecouplingparametersallowsustoavoidthe
’catastrophic’collapseofuncertaintyduetothemodeseekingbehaviorofthereversedKL,while
keepingaveryhighlevelofscalability. Bymarginalizingouttheuncertaintyovertheshiftvariables,
weobtainawell-calibratedposteriordistributionoverthecouplings. Theapproachcanbeapplied
onnetworkswithhundredsofnodesandminimizestheriskofspuriousinferenceduetodifferential
shifts,therebysolvingoneofthefundamentalproblemsthataffectedeffectiveconnectivitymethods
inneuroscienceandotherfields.
2 RelatedWork
In classical statistical signal processing, directed linear coupling are estimated using cross-
correlograms [Barlow, 1959], vector autoregressive modeling [Zivot and Wang, 2006], Granger
causality[Granger,1969,ShojaieandFox,2022]andnon-parametricspectraldecompositionmeth-
ods[Westetal.,2020]. Allthesemethodscruciallydependontime-shiftsinthecross-correlation
between signals, which are assumed to be caused by delayed causal couplings. The problem of
estimatingdirectedcouplingsfromtime-shiftedsignalsgainedsubstantialattentioninneuroscience
duetothefactthatlargescalemeasurementsofneuralsignalareoftenindirect,relyingoncomplex
processessuchasneural-hemodynamiccouplinginfMRI[Buckner,1998,Lindquistetal.,2009]or
calcium-influxincalciumimaging[GrienbergerandKonnerth,2012]. Sincethemeasuredsignals
dependoncomplex,andpossiblyvariable,biologicalprocesses,adirectuseofcross-correlogramor
autoregressive-basedmethodscouldleadtospuriousresults[Ramseyetal.,2010]. Becausetempo-
raldelayswereconsideredunreliable,directedcouplingswereinitiallyestimatedfromindividual
temporally-averagedmeasurementsbyvaryinganexternalstimulus(orcondition)andobserving
the resulting changes in the correlation structure between different nodes. This form of analysis
usedstructuralequationmodelingmethods(SEM)andisparticularlyappropriatewhenthetemporal
resolutionofthesignalisverylowsuchasinPETscans[Lairdetal.,2008]. Thetemporalaspectof
thecouplinganalysiswasexploitedwiththeintroductionofdynamiccausalmodels,whichassume
anunderlyingdeterministicdynamicalsystemandacomplextime-shiftedemissionmodel[Friston
et al., 2003]. In this family of Bayesian techniques, the posterior distribution is estimated using
variationalBayesapproachwithLaplaceapproximationofthelikelihood[Fristonetal.,2003]. The
approachwasextendedtothestudyofrestingstatedynamicsbyincludingstochasticinputstothe
nodes[Daunizeauetal.,2012]. Unfortunately,thesemodelscouldonlybescaledtosmallnetworks
of selected nodes. Recently, regression DCM achieved high scalability by using linear emission
modelsandgradient-basedinferenceinthefrequencydomain[Frässleetal.,2017]. Thecurrent
workisadevelopmentonthemultivariatedynamicalsystems(MDS)approach[Ryalietal.,2011b].
MDSmodelsassumethatthelatentdynamicisdrivenbyastateequation. Thislatentstategenerates
(potentiallydelayed)observationsthroughan’observationequation’. MDShasbeenextensively
testedinneuralsimulations[Ryalietal.,2016a]andoptogeneticexperiments[Ryalietal.,2016b].
TheuseofforwardKLindirectedcouplinganalysiswasintroducedin[Ambrogionietal.,2019a]for
spikemeasurements. However,nthisworkthemeasurementsdidnotintroduceadelay.
3 Methods
Our goal is to infer the directed statistical coupling between latent signals. As an example, the
signalscanrepresenttheactivityofactivityinneuralpopulationsinthebraincoupledthroughaxonal
pathways. Weassumethatthemeasurementsaregeneratedbytheconvolutionofthelatentsignals
withresponsefunctionswithvariabletemporalshiftsandspectralproperties. Thisisoftenthecasein
neuralmeasurements,whereneuralactivitiesisofteninferredfromtime-shiftedproxy-signalssuchas
thehaemodynamic(BOLD)responseinfMRImeasurementsofbrainactivity[Lindquistetal.,2009].
Forthesakeofsimplicityandrobustness,weassumethelatentcouplingbetweenregionstobelinear
andatthelatentactivationlevel. Thevariabilityinthetime-shiftsshiftsintheresponsefunctions
canpotentiallychangethetemporalorderingofthecross-correlationsbecausemeasurementswith
2T
Hyper-Parameters (HP) Parameters (P)
C M
- multi-modal - Gaussian given HP
Generative - low-dimensional - high-dimensional
model - hard inference - fast inference
Large f-KL
HP
... synthetic amortized estimator
dataset training
r-KL P
training estimator
Observed Marginalization
Generative model Hybrid inference method BOLD over HP
signal no mode
collapse
Figure1: GraphicalrepresentationfortheMDSmodel,andgeneralprincipleofourhybridmethod.
Parametersareseparatedintotwogroups. Forthehyper-parameters(HP),weusetheforwardKLto
obtainawell-calibratedestimator. TheHPestimatorispluggedintoascalablereverse-KLtrainingto
estimatetheparameters(P).
lowerdelaywillpredatemeasurementswithhigherdelay. Thiscanleadtospuriousdirectedcoupling
estimatesincross-correlogrambasedmethods, becauseaA → B couplingcanbeinterpretedas
A→BifthemeasurementofAismoredelayedcomparedtothemeasurementofB.
Inthefollowing,wewilloutlineaBayesianmodeldesignedtointegrateouttheuncertaintyintroduced
bytheshifts,andtherebytoreducetheriskofspuriousinferences.
Latent activation dynamics Latent activations X are subject to the directed coupling between
differentregions. WeassumethiscouplingtobelinearandparameterizedbyacouplingmatrixA.
TheevolutionofthelatentsignalfollowsthelinearGaussianstate-spacemodel[Ryalietal.,2011a]:
x[t+1]=A[t]x[t]+ϵ
ϵ∼N(0,q) (1)
q ∈R+M
whereϵdenotessomelatentwhiteGaussiannoisethatweassumetobeindependentandofdifferent
amplitudeacrossregions.
Time-shifted measurements y ∈ RT denotes the measurable time series for the location m,
m
whereTdenotesthetemporaldurationofthesignal. WedenoteasMthenumberofregions. We
modely astheconvolutionofsomelatentactivationbyaresponsefunction(RF).x ∈RTdenotes
m m
thelatentactivation. TheRFisassumedtobelocation-specific: thelocationmisassociatedwiththe
RFh ∈RKoftemporaldurationK. Weobtainy as:
m m
y [t]=(h ∗x )[t]+η
m m m
η ∼N(0,r m) (2)
r =[r ... r ]∈R+M
1 M
where[t]denotesthetimeindexing,andη ∼N(0,r)denotesmeasurementwhiteGaussiannoise
thatweassumetobeindependentandofdifferentamplitudeacrossregions. FollowingGlover[1999],
wemodelthelocation-specificRFh asalinearcombinationofabaseRFh anditstimederivative
m 0
h′,bothoftemporaldurationK:
0
h =cos(α )h +sin(α
)h˙′
m m 0 m 0 (3)
α ∈]−π/4,π/4[
m
wherefollowingSteffeneretal.[2010],theRFcoefficientsareparameterizedontheunitcircle. This
meansthattheRFforalocationmisentirelydescribedbytheangleα . Wemodeltheparameters
m
3oftheRFasindependentacrosslocations. Consideringallthelocationsatonce,werespectively
denoteY,X ∈ RM×T andH ∈ RM×K theconcatenatedobservablesignals,latentsignalsandRFs.
Vectorizingtheconvolutionoperationacrossregions,wecanwritey[t]=(H∗X)[t]+η. Agraphical
representationoftheMDSmodelisvisiblein1.
3.1 Problemstatement: inferringregioncouplingfromtheconvolvedsignals
Inferringparameterssusceptibletoyieldtheobservedsignal GiventheMDSmodeldescribed
inSection3,theobservedsignalYandexperimentalconditionsc,weaimtoinfertheparameters
susceptible to generating Y. The MDS model is associated with the joint distribution p, which
factorizesas:
p(Y,c,X,A,q,r,H)=p(Y|X,r,H)
×p(X|c,A,q) (4)
×p(c)p(A)p(r)p(q)p(H)
wherep(c)isauniformcategoricalprior,p(A)isasparsity-inducingLaplaceprior,p(H)corresponds
to a uniform prior over the angle α between the bounds ]−π/4,π/4[, and p(q) and p(r) are log-
normalpriors. p(X|c,A,q)andp(Y|X,r,H)correspondtotheNormaldistributionsdescribedin
Eq. 1&2. FollowingtheBayesianinferenceformalism,wesearchfortheposteriordistributionof
thecouplingmatrix: p(A|Y,c). p(A|Y,c)denotesadistributionbecausethereareseveralsources
ofuncertaintyintheproblem,andthereforeAcannotbeinferredunequivocally. Inparticular,both
thelatentandtheobservablenoiselevelsareunknown. Moreimportantly,theRFHforthedifferent
regionsisalsounknown,whichcouldinduceatimereversalofthecross-correlogramsbetweenthe
observablesignalsatdifferentlocations. WhenestimatingthelatentsignalXandthecouplingmatrix
A,wewanttoensurethattheuncertaintyinalltheotherparametersisproperlymarginalized. Thatis
tosay,wedonotwanttounderestimatetheuncertaintywheninferringtheparametersofinterest. In
detail,ourmethodfocusesonthepropermarginalizationoftheRFH. Eachcombinationofdifferent
RFsforthelocationsyields—viade-convolution—adifferentsetoflatentsignalsX. Inturn,each
differentsetoflatentsignalsyieldsadifferentestimateforthecouplingmatrixA. Theoretically,
theBayesianframeworkallowsweightingallthosescenariosbytheirlikelihoodofgeneratingthe
observed BOLD signal Y. This results in a single posterior distribution p(A|Y,c) that integrates
allthesourcesofuncertaintyintheproblem. However,inpractice,inferencemethodsmayfailto
recoverthetrueposteriorp(A|Y,c),resultinginuncertaintyunderestimationandbiasedestimation.
Apracticalhurdleforinference: multiplemodesexplainingtheobserveddata Toexplainhow
inferencemayfailinpractice,webrieflyoverviewitsunderlyingmechanisms. Inferencemethods
explorethehigh-dimensionalparameterspace(q,r,H,X,A). Inthislargeparameterspace,several
regionsmayexplainwelltheobservedsignalY. Forinstance,differentcombinationsofRFsand
underlyingsignals. Low-probabilityregionsmayseparatethosehighlyexplanatoryregions,creating
separatedistributionmodes. Approximateinferencemethodsuchasreversedgradient-basedVIare
pronetobecomestuckinoneofthosemodesandignoreequallyrelevantsetsofsolutionstothe
problem. Multi-modalityisindeedaknownissueforoff-the-shelfinferencemethods. Inthecontext
ofMarkovchainMonteCarlo(MCMC)methods,thiscanresultinthenon-mixingofmultiplechains
[Andrieuetal.,2003].InthecontextofVariationalInference(VI),thephenomenonisknownasmode
collapse[Bleietal.,2017].Critically,whileinferencemethodsmayfailtorecoverthetrueuncertainty
inp(A|Y,c),theystilloutputthedistributioncorrespondingtothemodetheyarestuckinto. This
canbeamisleadingresult: recoveringaprobabilisticoutput, experimentersmayassumethatall
theuncertaintyintheproblemhasbeencaptured. Yet,inpractice,off-the-shelfmethodsmayonly
recoverpartoftheproblem’suncertainty. InthecontextoftheMDSgenerativemodel–described
inSection3—modecollapsecanresultinover-inflatedstatisticalconfidencewheninferringthe
connectionsbetweenlocations,andeveninspuriousconnectionsdiscovery. Inthispaper,wepropose
arobustinferencemethodtomarginalizetheuncertaintyintheRFHandthenoiselevelsqandr
properlywheninferringthelatentsignalXandthecouplingmatrixA.
3.2 HybridVariationalBayes
Inthissection,wedescribeourhybridvariationalBayesmethod(h-VB)totacklethemulti-modality
ininference. Thetermhybrid referstoseparatingtheparameters(q,r,H,X,A)intotwogroups
treatedusingdifferentinferencemethodsasillustratedinfigure1. Specifically,asdescribedbelow,
4weuseareverse-KLgradient-basedVIlossforthecouplingandlatentsignalparametersasthey
correspondtoawell-behavedunimodalconditionaloptimizationproblem. Ontheotherhand,weuse
aforward-amortizedloss(FAVI)Ambrogionietal.[2019b]forthenoiseandHRparameterssince
theirposteriordistributionisoftenhighlymulti-modalandtheFAVIapproachiscapableoflearning
multi-modalitiesintheposterior. Thisresultsinahybridapproachthatcombinestheefficiencyand
scalabilityofreverse-KLVIforlarge-scaleinferenceoflargecouplingmatriceswiththerobustness
ofFAVIonasmallersetofkey(hyper-)parameters.
Inferenceusingparameteroptimization: theautomaticdifferentiationvariationalinference
(ADVI) framework Variational Bayes, also referred to as variational inference (VI), frames
approximateinferenceasanoptimizationproblem. Inferencereducestochoosingavariationalfamily
Q and finding inside that family the distribution q(q,r,H,X,A;ϕ) ∈ Q closest to the unknown
posteriorp(q,r,H,X,A|Y,c). Tofindtheclosestdistributionq,weoptimizetheparametersϕto
minimizealossLthatwillbedetailedinthenextparagraphs.TominimizeL,weproceedviagradient
descent,whichentitlesbeingabletodifferentiatethroughL. YetthelossLfeaturesexpectationover
parametricdistributions,suchasq. Thisill-poseddifferentiationpreventsoff-the-shelfoptimization.
Tocircumventthisissue,weusethereparameterizationtrick[KingmaandWelling,2013]:parametric
distributions are reformulated as parametric transformations of fixed distributions —such as the
standardNormaldistributionN(0,1). ThisreparameterizationletsusdifferentiatethroughL. In
turn,differentiatingthroughLletsusleveragethepowerfulautomaticdifferentiationlibrariesand
optimizers developed in the deep learning community. As a result, we can infer the parameters
(q,r,H,X,A)susceptibletoproducingtheobservedBOLDsignalYinafastandscalablemanner.
Weoptimizethevariationaldistributionqtoapproximatetheunknownposteriorp(q,r,H,X,A|Y,c).
Wefactorizeqintotwodensities:
q(q,r,H,X,A;ϕ)=q (q,r,H;ϕ )×q (X,A|q,r,H;ϕ ) (5)
HP HP P P
whereq denotesourhyper-parameterestimator,andq ourparameterestimator. Perour"hybrid"
HP P
method,bothfactorsaretrainedusingdifferentlosses,asexplainedinthenexttwosections.
Hyper-parameter(HP)estimation Ourmaingoalwhentrainingq istoavoidmodecollapse,
HP
thephenomenondescribedinthepracticalhurdleparagraphof3.1. Avoidingmodecollapsewillbe
ensuredbythelossusedforthetraining. Weconsiderthedifferentregionsasindependentinference
problemsandfactorizeq as:
HP
(cid:89)
q (q,r,H|Y=Y;ϕ )= q (q ,r ,α ;f(y ;ϕ )) (6)
HP HP region m m m m HP
m=1..M
where q approximates a location’s noise levels and RF given a realization of the region’s
region
abservablesignaly. WeuseaMaskedAutoregressiveFlow[MAF,Papamakariosetal.,2017]to
buildq . Theflowapproximatesthejointdistributionof(α,q,r). Toconditionthisdistribution
region
bythevalueofy,wefeedtotheflowanencodingoftheobservedregion’sobservablesignalf(y ).
m
Asencoderf,weuseatimeconvolutionalneuralnetworkwhoseweightsarejointlytrainedwith
theflowweights. Combiningaflowandaneuralnetworkencoderyieldsaveryexpressivedensity
approximatorabletomodelmultimodal,heavy-tailed,andhighlycorrelateddistributions.
Wetrainq tominimizetheforwardKullback-Leibler(f-KL)loss[Papamakariosetal.,2019],
region
thatistosaytomaximizetheprobabilityof(q,r,α)giveny:
ϕ∗ HP =minLf H-K PL =minE q,r,α,y∼p[−logq region(q,r,α;f(y;ϕ HP))] (7)
ϕHP ϕHP
wheretheexpectationE denotesthetrainingoveralargesyntheticdatasetsampledfromthe
q,r,α,y∼p
generativemodel. Thealgorithmiteratesbetweenthefollowingsteps: 1)itusesthegenerativemodel
described in Section 3 to sample the latent parameters (q,r,H,X,A,c) and associated synthetic
BOLDsignalY; 2)foreachsyntheticsample, itseparatestheBOLDsignalsy andparameters
m
(α ,q ,r ) corresponding to the different regions m; 3) for each region m, it feeds y to the
m m m m
encoder f, and use the obtained encoding to condition our normalizing flow; 4) it evaluates the
probabilityoftheparameters(α ,q ,r )undertheconditionedflow;5)throughgradientdescent,
m m m
itmaximizesthatprobability,updatingtheweightsofboththeflowandtheencoder.
Afterseveralepochs—cyclingthroughsyntheticsamplesfromthegenerativemodel—q con-
region
vergestoagoodapproximationofp(q,r,α|y). Thetrainingofq isamortized,whichmeansthat
region
5oncetrained,q canestimatethehyper-parametersofanybrainregionbyfeedingtheregion’s
region
BOLDsignalytotheencoderf. Wecanthenreuseq acrosssymmetricalinferenceproblems
region
insidetheMDSIgenerativemodel,aconceptnamedplateamortizationintheautomaticVIliterature
[Rouillardetal.,2023].
Parameter(P)estimation Ourmaingoalwhentrainingq isinferencespeedandscalability. This
P
isduetothelargedimensionalityofXandA,whichscalebadlywiththenumberofregionsand
timepointsinourexperiments. WeusethereverseKullback-Leibler(r-KL)loss[Bleietal.,2017]
toensurethisscalability. ReverseKullback-LeiblertrainingaimsatminimizingtheKLdivergence
betweenthevariationalfamilyqandtheunknownposteriordistributionp(q,r,H,X,A|Y,c). Since
the posterior distribution is unknown, we cannot directly minimize this divergence. Instead, we
minimizeandupperboundofthatdivergence,whichamountstomaximizingtheevidencelower
bound(ELBO)underthevariationaldistribution:
ϕ∗ =minLr-KL
P P
ϕP
=minE ( logp(Y,c,X,A,q,r,H)
ϕP q, Xr ,, AH ∼∼ qq PHP (8)
−logq (X,A|q,r,H;ϕ )
P P
−logq (q,r,H|Y=Yobserved))
HP
where the estimator q —described in the previous paragraph— evaluated on the true observed
HP
signalYobserved isusedasthevariationalposteriorforthehyper-parametersq,r,H. q (q,r,H)is
HP
nottrainedduringthissecondphasetopreventmodecollapse.
Theoretically,iftheRFHandthenoiselevelsq andrwereknown,XcanbeinferredviaWiener
de-convolution. In turn, given the latent signals, A can be inferred in closed-form via Bayesian
linear regression. Informed by those considerations, we choose a Gaussian variational family to
approximatetheexactXandAposteriordistributions. Toscaleourmethodtohundredsofregions,
wedonotmodelthecovariancebetweenthedifferentcoefficientsofA,hencethecovariancematrix
for the posterior of A is modeled as diagonal. To obtain the mean and variance of the Gaussian
approximations,weregressthosefromthevalueofthehyper-parametersH,q,rusingasimpleMLP
architecture.
4 Syntheticexperiments
Thegoalofthissyntheticexperimentistovalidateourmethodologicalclaims. h-VBavoidsmode
collapse—thehurdledescribedinSection3.1—viatheseparateforward-KLtrainingoftheHP
estimator,asdescribedinSection3.2. Inpractice,thishelpsusrecoverthetrueuncertaintyinthe
inferenceofthecouplingmatrixA. Weshowthat,incontrary,anoff-the-shelfinferencemethod
underestimatestheuncertaintyinthecouplingmatrixA. Data: Inthisexperiment,weuseasynthetic
samplefromtheMDSIgenerativemodel—describedinSection3. Thismeansthatthegroundtruth
HRFH,varianceslevelsq,randcouplingAareknown. Wefeedtotwomethodsthethesynthetic
BOLDsignalY.Baseline:Asabaselineforcomparison,weuseavariationalBayesmethod.Contrary
toh-VB,theentiretyoftheparameters—includingthehyperparametersH,q,r—areinferredusing
thereverse-KLloss. Asaresult,thebaselinefocusesoncertainHRFsonlyandmissespartofthe
solutionspaceforA. ThebaselineusesaGaussianapproximationforAandX(similartoh-VB).
Thebaselinesapproximatestheposteriorforrandqusinglog-Normaldistributions. Thebaseline
approximatestheposteriorforαusingaNormaldistributionsoftclippedtotherange]π/2;π/2[
(usingarescaledsigmoidfunction).
Hyper-Parameter inference: HRF and variance levels 2 (left) displays the (α,q,r) posterior
distributionsofh-VBandthebaseline. Thebaseline’sposteriorcollapsestoasmallfractionofthe
posterior’ssupport,therebymissingthegroundtruthparameters. Onthecontrary,h-VBcorrectly
recoverstheentiretyofthesolutionspace. Notethat,withoutstrongpriorsontheunderlyingsignal
X, inferring the HRF H from the BOLD signal Y is ill-posed [Taylor et al., 2018]. As a result,
thesupportofh-VB’sαposteriorisverylarge. Parameterinference: couplingmatrix2(right)
displaystheAposteriordistributionsofh-VBandthebaseline. Sincethebaselineignoredmostof
theHRFHsolutionspace,itfeaturespeakedposteriorsonspuriouscouplingvalues. Thismeans
that the baseline outputs biased results with strong statistical confidence. On the contrary, h-VB
correctlyconsidersallthedifferentHRFscenariosthatcouldhavegeneratedtheBOLDsignalY.
6Figure2: SyntheticexampleinferencePosteriormarginaldistributionsofthehyper-parameterα
andtheparameterA—asdescribedinSection3.2.
As an example, consider the only non-null coupling in this synthetic example: a strong negative
couplingfromregion1toregion2. Placingthethresholdoftheexistenceofacouplingata0.1value,
thebaselineoutputsa1%chanceofapositivecouplinganda0%chanceofanegativecoupling(the
groundtruth). Onthecontrary,h-VBoutputsa46%chanceforapositivecouplinganda30%chance
foranegativecoupling(thegroundtruth). h-VBhelpstheexperimenterdeterminethat,thougha
couplingislikelytoexistbetweenthe2regions,inferringitssignisinconclusive.
Inthisexperiment,weshowedthatoff-the-shelfinferencemethods,thoughfeaturingaprobabilistic
output,canleadtoover-estimatedstatisticalconfidenceandspuriousresults. h-VB,onthecontrary,
recoversthetrueuncertaintyintheproblemandcanleadtomorenuancedandricherconclusions.
4.1 Modecollapseinpractice: effectongroundtruthcouplingcoverage
This experiment validates statistically the effect of mode collapse as illustrated in 4. Data: We
generateasyntheticdatasetusingtheMDSmodel—describedinSection4. Wegenerate20random
networks with sparse coupling matrix. Non-diagonal elements of A have a 70% chance to be
null,20%tobe0.2,anda10%chancetobe−0.2. Foreachnetwork,wesimulate10"subjects",
correspondingtoindependentrunsoftheMDSmodelwiththesamecouplingmatrix. Baseline: We
usethesamer-KLbaselineasdescribedinSection4. Inaddition,wecomparetor-DCM,arecent
scalableextensionofDCM[Frässleetal.,2017,FrässleandStephan,2022]. r-DCMusesasimilar
linear-couplingmodelingasintheMDSmodeldescribedinSection3. Toinvertitsmodel,r-DCM
uses Fourier analysis and Bayesian linear regression. One major difference with MDSI-h-VB is
thatr-DCMdoesnottakeintoaccountHRFvariability,andassumesthateveryregionisassociated
withthedefaultHRF.Mis-specificationoftheHRFisidentifiedbyFrässleetal.[2017]asoneof
their method’s main limitations. Metric: We leverage the probabilistic output of the compared
methods. Oncetheposteriorisfitted,wecomputethelogdensityovertheoff-diagonalcoupling
coefficients. This metric translates if the ground truth is statistically contained in the posterior
distribution. MDSI-h-VBrecoversthegroundtruthcouplingmorereliablyResultsarevisible
in1(left). BytakingintoaccountHRFvariability,yetavoidingmodecollapse,MDSI-h-VBcovers
7Network #nodes AUC
MDSI-h-VB r-DCM
5.0 1 5 0.82 0.92
2.5 2 5 0.79 0.92
3 5 0.95 0.88
0.0
4 10 0.94 0.83
2.5 5 5 0.91 0.70
5.0 6 8 0.93 0.88
7.5 7 6 0.82 0.72
8 8 0.89 0.78
10.0 MDSI-h-VB
9 9 0.82 0.87
r-KL baseline
12.5 r-DCM Macaque 28 0.92 0.76
15.0 Macaque 91 0.90 0.89
mean 0.88±0.05 0.83±0.08
Table1: ValidationonsyntheticdataLeft:MDSmodel,groundtruthcouplingposteriorcoverage
Posterior log density over the off-diagonal ground truth coupling coefficient values for different
methods.Right:neurophysiologicalmodel.Methodsarecomparedintermsofaccuracyinconnection
detection. Themacaquenetworks(bottomtwolines)haveabiologicallyrelevantstructure,obtained
fromtracerinjectionstudies[Sanchez-Romeroetal.,2018].
thefullsupportoftheposteriorforthecouplingmatrixA. Thisposteriorthuscontainstheground
truthcouplingvalue. Incontrast,thebaselinesfeaturemorepeakedposteriorsthattendto"miss"the
groundtruth—asillustratedin2. Thebaseline’sposteriordensityoverthegroundtruthisthuslower
thanforMDSI-h-VB.
5 Applicationonaneurophysiologicalsyntheticdataset: connectiondetection
Thegoalofthisexperimentistovalidateourmethodonsamplescomingfromadifferentgenerative
modelthantheMDS.Thegroundtruthcouplingisbinary: eitherthereisapositivecouplingbetween
regions, orthereisnocoupling(thestrengthofthecouplingdoesnotvary). Asaresult, wetest
ourmethodintermsoftheaccuracyofconnectiondetection. Data: Weusesyntheticdatasampled
usinganeurophysiologicalprocess[Sanchez-Romeroetal.,2018]. Underlyingneuraldynamicsare
simulatedusingthelineardifferentialequation∂z/∂t=σAz+Cu,whereAdenotestheground-
truthconnectivity. Tosimulateresting-statedata,theuinputwasmodeledusingaPoissonprocess
foreachoftheregions. Theneuronalsignalsz werethenpassedthroughtheBalloon-Windkessel
model[Friston,2009]toobtainsimulatedBOLDdata. Thenetworks1-9featuresmall-scalesynthetic
graphs,whichvarywidelyintheirdensityandnumberofcycles. TheMacaquenetworksconsist
oftwolargergraphsextractedfromthemacaqueconnectome. Baseline: Wecompareourselvesto
astate-of-the-artdirectionalcouplingestimationmethod: r-DCM[Frässleetal.,2017,Frässleand
Stephan, 2022]. r-DCM is a Bayesian linear regression method in the Fourier domain, that does
nottakeintoaccounttheHFRvariability. r-DCMhasbeendesignedwithscalabilityinmind,tobe
appliedinthecontextoffull-brainanalysis. Method: Foreachmethod,networkandsubject,we
inferthemeanvalueofthecouplingmatrixAposterior. Foreachcoefficient,wethencomputea
t-scoreacrosssubjects. Wethenfeedthatscoretoabinarylogisticregressionclassifier. Wereportthe
AUCoftheclassifier. MDSI-h-VBconnectiondetectionaccuracyismaintainedasthenumber
ofnodesaugments1reportstheconnectiondetectionAUCofMDSI-h-VBasthenumberofnodes
inthenetworkaugments. BoththeMacaquecasesfeatureseveraldozennodes. Inaddition,their
ground truth connections are based on axonal connectivity derived from tracer injection studies
[Sanchez-Romeroetal.,2018].Asaresult,theMacaque91setupisagoodproxyfortheperformance
ofMDSI-h-VBonafullbrainanalysisasin6. Inthischallengingsetup,MDSI-h-VBmaintainsan
AUCof0.90.
8
hturt
dnuorg
revo
ytisned
golDomain expert
hypothesis Full-brain data-driven validation
r-AI
Figure3: Full-brainanalysisconfirmsthedrivingroleofther-AIinworkingmemoryOnthe
left: directedoutflowanalysison11pre-selectedROIs. Workingmemoryregionsareselectedby
anexpert,whichcanincurconfoundingfromunobservedregions. Ontheright: full-brainanalysis,
removingpotentialconfounds. Ther-AIwashypothesizedtobeadrivingregioninthe11-ROIs
analysis(bluerectangle). Thefull-brainanalysisconfirmsthisanalysis: ther-AI(bluearrow)appears
asahotspotofthedirectedoutflow.
6 Data-drivendiscoveryofdrivingregionsinhumanworkingmemory
ThisexperimentleveragetheinferencespeedandscalabilityofMDSI-h-VBtoscaleupourcoupling
analysistothewholebrain. WeapplyMDSI-h-VBtodatafromtheHCPdataset[VanEssenetal.,
2012]: 737HCPsubjectsperformingWorkingMemorytasks. Subjectsundergothreeexperimental
conditions: a 2-backWM task, a0-backWM task, anda baselinestatebetween tasks. Foreach
subject,weuseMDS-h-VBtoinferthemeanvalueofthecouplingmatrixA,onecouplingmatrix
A perconditionc. Foreachsubjectandregion,wecomputethedirectedoutflowasthesumofthe
c
outwardscoefficientsminusthesumoftheinwardscoefficients:
(cid:88) (cid:88)
∀c=1..C∀m =1..M: directed_outflow = a − a
1 c,m1 c,m2,m1 c,m1,m2 (9)
m2=1..M,m2̸=m1 m2=1..M,m2̸=m1
The directed outflow translates whether a region mostly drives the signal of the rest of the brain
(positiveoutflow)orifitismostlydrivenbytherestofthebrain(negativeoutflow). Weconsider
twochoicesofROIs. Ontheonehand,11pre-determinedROIsassociatedbyexpertstoworking
memory[Caietal.,2021]. Ontheotherhand, 248regionscomingfromafullbrainparcellation
[Fanetal.,2016]. Workingonthewholebrainyieldsamoredata-drivenapproachthanworking
withpre-determinedROIs. Weinvestigatetheroleofther-AIasadrivinghubinhumanworking
memory. Results are visible in 3. First, we reproduce previous findings [Cai et al., 2021] in the
11-ROIscase,pickingupther-AIasthestrongestoutflownode. Second,wevalidatethosefindings
inadata-drivenway,outliningther-AIasahighoutflowhub. Workingatthefullbrainscale,we
ensurethatourfindingscannotbeconfoundedbyunobservedregion—ascouldbethecasewith
pre-selectedregions.
7 Discussion
Inthispaper, weintroducedamethodcapableofreliablyestimatinglargedirected networks, on
the order of hundred of nodes, from indirect and time-shifted measurement. In order to account
fromtheill-posednessoftheinference,ourBayesianestimatorautomaticallymarginalizes-outthe
measurementparameters. Thisimpliesthatourconnectivityestimatesareaveragedoverallplausible
time-shiftsandarethereforelesssensitivetospuriousinferenceduetotimeinversion. Toperform
this marginalization correctly in a variational framework, it is crucial to use a forward KL loss
overtheseshiftparametersastheconventionalreversedKLlossishighlyvulnerabletoverysevere
underestimationsoftheuncertainty.
Ourmethodopenthedoorforreliableandscalableanalysisofdirectedcouplingsinlargenetworks,
whichcouldleadtobreakthroughsinseveralfields. Forexample,reliableestimationofthedirected
9causalstructureofinterconnectionbetweenbrainregionsfromfMRIdatacanimproveourunder-
standingoffunctionalbrainnetworksbothduringrestandduringcognitiveactivityBresslerand
Menon[2010],Raichle[2015],Menon[2023]. Theapproachcanbepotentiallyscaledtohundredof
regions. However,thequadraticscalinginthenumberofpossibleconnectionsposesalimittothe
scalabilitytolargernetworks. Anotherlimitationofthecurrentapproachisthatitdoesnotaccount
forpotentialnon-linearitiesinthedynamicalandobservationmodels. Inthecaseofbrainnetworks,
theabsenceofthresholdnon-linearitiescomplicatestheinterpretationofnegativecouplings,since
in a linear models negative weights do not cause a suppression in activity. However, non-linear
modelscanbestraightforwardlyintegratedintoourvariationalinferencemethodandweleavethis
modificationtofuturework.
References
L.Ambrogioni,P.Ebel,M.Hinne,U.Güçlü,M.Gerven,andE.Maris. SpikeCaKe: Semi-analytic
nonparametricbayesianinferenceforspike-spikeneuronalconnectivity. InInternationalConfer-
enceonArtificialIntelligenceandStatistics,2019a.
L. Ambrogioni, U. Güçlü, J. Berezutskaya, E. Borne, Y. Güçlütürk, M. Hinne, E. Maris, and
M. Gerven. Forward amortized inference for likelihood-free variational marginalization. In
InternationalConferenceonArtificialIntelligenceandStatistics,pages777–786,2019b.
C.Andrieu,N.deFreitas,A.Doucet,andM.I.Jordan. AnIntroductiontoMCMCforMachine
Learning. MachineLearning,50(1):5–43,Jan.2003.
J.S.Barlow. Autocorrelationandcrosscorrelationanalysisinelectroencephalography. IRETransac-
tionsonMedicalElectronics,(3):179–183,1959.
D.M.Blei,A.Kucukelbir,andJ.D.McAuliffe. VariationalInference: AReviewforStatisticians.
JournaloftheAmericanStatisticalAssociation,112(518):859–877,Apr.2017.
S. L. Bressler and V. Menon. Large-scale brain networks in cognition: emerging methods and
principles. TrendsinCognitiveSciences,14(6):277–290,2010.
R.L.Buckner. Event-relatedfMRIandthehemodynamicresponse. HumanBrainMapping,6(5-6):
373–377,1998.
W.Cai,S.Ryali,R.Pasumarthy,V.Talasila,andV.Menon. Dynamiccausalbraincircuitsduring
workingmemoryandtheirfunctionalcontrollability. NatureCommunications,12(1):3314,2021.
J.Daunizeau,K.E.Stephan,andK.J.Friston. StochasticdynamiccausalmodellingoffMRIdata:
shouldwecareaboutneuralnoise? NeuroImage,62(1):464–481,2012.
L.Fan,H.Li,J.Zhuo,Y.Zhang,J.Wang,L.Chen,Z.Yang,C.Chu,S.Xie,A.R.Laird,etal. The
humanbrainnetomeatlas: anewbrainatlasbasedonconnectionalarchitecture. CerebralCortex,
26(8):3508–3526,2016.
S.Frässle,E.I.Lomakina,A.Razi,K.J.Friston,J.M.Buhmann,andK.E.Stephan. Regression
dcmforfMRI. NeuroImage,155:406–421,2017.
K. J. Friston. Modalities, modes, and models in functional neuroimaging. Science, 326(5951):
399–403,2009.
K.J.Friston,L.Harrison,andW.Penny. Dynamiccausalmodelling. NeuroImage,19(4):1273–1302,
2003.
S.FrässleandK.E.Stephan. Test-retestreliabilityofregressiondynamiccausalmodeling. Network
Neuroscience,6(1):135–160,Feb.2022.
S.Frässle,E.I.Lomakina,A.Razi,K.J.Friston,J.M.Buhmann,andK.E.Stephan. Regression
DCMforfMRI. NeuroImage,155,2017.
G.H.Glover. Deconvolutionofimpulseresponseinevent-relatedBOLDfMRI. NeuroImage,9(4):
416–429,1999.
10C.W.J.Granger. Investigatingcausalrelationsbyeconometricmodelsandcross-spectralmethods.
Econometrica,pages424–438,1969.
C.GrienbergerandA.Konnerth. Imagingcalciuminneurons. Neuron,73(5):862–885,2012.
S.Herculano-Houzel. Thehumanbraininnumbers: alinearlyscaled-upprimatebrain. Frontiersin
HumanMeuroscience,3:857,2009.
D.P.KingmaandM.Welling. Auto-encodingvariationalbayes. arXivpreprintarXiv:1312.6114,
2013.
N.Kravchenko-Balasha,A.Levitzki,A.Goldstein,V.Rotter,A.Gross,F.Remacle,andR.D.Levine.
Onafundamentalstructureofgenenetworksinlivingcells. ProceedingsoftheNationalAcademy
ofSciences,109(12):4702–4707,2012.
A. Kucukelbir, D. Tran, R. Ranganath, A. Gelman, and D. M. Blei. Automatic differentiation
variationalinference. JournalofMachineLearningResearch,18(14):1–45,2017.
A.R.Laird,J.M.Robbins,K.Li,L.R.Price,M.D.Cykowski,S.Narayana,R.W.Laird,C.Franklin,
andP.T.F. Modelingmotorconnectivityusingtms/petandstructuralequationmodeling. Neu-
roImage,41(2):424–436,2008.
M.A.Lindquist, J.M.Loh, L.Y.Atlas, andT.D.Wager. Modelingthehemodynamicresponse
functioninfMRI:efficiency,biasandmis-modeling. Neuroimage,45(1):S187–S198,2009.
S.Loomba,J.Straehle,V.Gangadharan,N.Heike,A.Khalifa,A.Motta,N.Ju,M.Sievers,J.Gempt,
H.S.Meyer,etal. Connectomiccomparisonofmouseandhumancortex. Science,377(6602):
eabo0924,2022.
V.Menon. 20yearsofthedefaultmodenetwork: Areviewandsynthesis. Neuron,2023.
A. Mnih and D. Rezende. Variational inference for monte carlo objectives. In International
ConferenceonMachineLearning,pages2188–2196.PMLR,2016.
G.PapamakariosandI.Murray. Fastε-freeinferenceofsimulationmodelswithbayesianconditional
densityestimation. AdvancesinNeuralInformationProcessingSystems,29,2016.
G.Papamakarios,T.Pavlakou,andI.Murray. Maskedautoregressiveflowfordensityestimation.
AdvancesinNeuralInformationProcessingSystems,30,2017.
G.Papamakarios,E.Nalisnick,D.J.Rezende,S.Mohamed,andB.Lakshminarayanan. Normalizing
FlowsforProbabilisticModelingandInference. arXiv:1912.02762,Dec.2019.
M.E.Raichle. Thebrain’sdefaultmodenetwork. Annualreviewofneuroscience,38:433–447,2015.
J. D. Ramsey, S. J. Hanson, C. Hanson, Y. O. Halchenko, R. A. Poldrack, and C. Glymour. Six
problemsforcausalinferencefromfMRI. NeuroImage,49(2):1545–1558,2010.
R.V.Raut,A.Mitra,A.Z.Snyder,andM.E.Raichle. Ontimedelayestimationandsamplingerror
inresting-statefMRI. NeuroImage,194:211–227,2019.
L.Rouillard,A.LeBris,T.Moreau,andD.Wassermann. PAVI:Plate-amortizedvariationalinference.
TransactionsonMachineLearningResearch,2023.
S.Ryali,K.Supekar,T.Chen,andV.Menon. Multivariatedynamicalsystemsmodelsforestimating
causalinteractionsinfMRI. NeuroImage,54(2):807–823,Jan.2011a.
S.Ryali,K.Supekar,T.Chen,andV.Menon. Multivariatedynamicalsystemsmodelsforestimating
causalinteractionsinfMRI. Neuroimage,54(2):807–823,2011b.
S.Ryali,T.Chen,K.Supekar,T.Tu,J.Kochalka,W.Cai,andV.Menon. Multivariatedynamical
systems-based estimation of causal brain interactions in fMRI: Group-level validation using
benchmark data, neurophysiological models and human connectome project data. Journal of
Neurosciencemethods,268:142–153,2016a.
11S. Ryali, Y.-Y. I. Shih, T. Chen, J. Kochalka, D. Albaugh, Z. Fang, K. Supekar, H. Lee, J., and
V.Menon. CombiningoptogeneticstimulationandfMRItovalidateamultivariatedynamical
systemsmodelforestimatingcausalbraininteractions. Neuroimage,132:398–405,2016b.
R.Sanchez-Romero,J.Ramsey,K.Zhang,M.Glymour,B.Huang,andC.Glymour. Estimating
feedforwardandfeedbackeffectiveconnectionsfromfMRItimeseries: Assessmentsofstatistical
methods.,2018.
A. Shojaie and E. B. Fox. Granger causality: A review and recent advances. Annual Review of
StatisticsandItsApplication,9:289–319,2022.
J.Steffener,M.Tabert,A.Reuben,andY.Stern. Investigatinghemodynamicresponsevariabilityat
thegrouplevelusingbasisfunctions. Neuroimage,49(3):2113–2122,2010.
K.E.StephanandA.Roebroeck. AshorthistoryofcausalmodelingoffMRIdata. NeuroImage,62
(2):856–863,2012.
A.J.Taylor,J.H.Kim,andD.Ress. Characterizationofthehemodynamicresponsefunctionacross
themajorityofhumancerebralcortex. NeuroImage,173:322–331,June2018.
D.C.VanEssen,K.Ugurbil,E.Auerbach,D.Barch,T.E.Behrens,R.Bucholz,A.Chang,L.Chen,
M.Corbetta,S.W.Curtiss,S.DellaPenna,D.Feinberg,M.F.Glasser,N.Harel,A.C.Heath,
L.Larson-Prior,D.Marcus,G.Michalareas,S.Moeller,R.Oostenveld,S.E.Petersen,F.Prior,
B.L.Schlaggar,S.M.Smith,A.Z.Snyder,J.Xu,andE.Yacoub.TheHumanConnectomeProject:
adataacquisitionperspective. NeuroImage,62(4):2222–2231,Oct2012.
C.S.VonBartheld,J.Bahney,andS.Herculano-Houzel. Thesearchfortruenumbersofneuronsand
glialcellsinthehumanbrain: Areviewof150yearsofcellcounting. JournalofComparative
Neurology,524(18):3865–3895,2016.
T.O.West,D.M.Halliday,S.L.Bressler,S.F.Farmer,andV.Litvak. Measuringdirectedfunctional
connectivityusingnon-parametricdirectionalityanalysis: Validationandcomparisonwithnon-
parametricgrangercausality. NeuroImage,218:116796,2020.
M.A.WhiteandR.G.W.Anderson. Signalingnetworksinlivingcells. Annu.Rev.Pharmacol.
Toxicol.,45:587–603,2005.
E.ZivotandJ.Wang. Vectorautoregressivemodelsformultivariatetimeseries. Modelingfinancial
timeserieswithS-PLUS®,pages385–429,2006.
12