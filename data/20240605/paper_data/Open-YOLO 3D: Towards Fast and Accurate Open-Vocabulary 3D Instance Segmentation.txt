Open-YOLO 3D: Towards Fast and Accurate
Open-Vocabulary 3D Instance Segmentation
MohamedElAmineBoudjoghra1,AngelaDai2,JeanLahoud1,
HishamCholakkal1,RaoMuhammadAnwer1,3,SalmanKhan1,4,FahadShahbazKhan1,4
1MohamedBinZayedUniversityofArtificialIntelligence(MBZUAI),
2TechnicalUniversityofMunich(TUM),3AaltoUniversity,
4AustralianNationalUniversity,5LinköpingUniversity
{mohamed.boudjoghra, jean.lahoud,hisham.cholakkal,
rao.anwer, salman.khan, fahad.khan}@mbzuai.ac.ae,angela.dai@tum.de
Abstract
Recentworksonopen-vocabulary3Dinstancesegmentationshowstrongpromise,
butatthecostofslowinferencespeedandhighcomputationrequirements. This
highcomputationcostistypicallyduetotheirheavyrelianceon3Dclipfeatures,
which require computationally expensive 2D foundation models like Segment
Anything(SAM)andCLIPformulti-viewaggregationinto3D.Asaconsequence,
thishamperstheirapplicabilityinmanyreal-worldapplicationsthatrequireboth
fastandaccuratepredictions. Tothisend, weproposeafastyetaccurateopen-
vocabulary 3D instance segmentation approach, named Open-YOLO 3D, that
effectivelyleveragesonly2Dobjectdetectionfrommulti-viewRGBimagesfor
open-vocabulary3Dinstancesegmentation. Weaddressthistaskbygenerating
class-agnostic3Dmasksforobjectsinthesceneandassociatingthemwithtext
prompts. Weobservethattheprojectionofclass-agnostic3Dpointcloudinstances
alreadyholdsinstanceinformation;thus,usingSAMmightonlyresultinredun-
dancythatunnecessarilyincreasestheinferencetime. Weempiricallyfindthat
abetterperformanceofmatchingtextpromptsto3Dmaskscanbeachievedin
afasterfashionwitha2Dobjectdetector. WevalidateourOpen-YOLO3Don
twobenchmarks,ScanNet200andReplica,undertwoscenarios: (i)withground
truth masks, where labels are required for given object proposals, and (ii) with
class-agnostic3Dproposalsgeneratedfroma3Dproposalnetwork. OurOpen-
YOLO3Dachievesstate-of-the-artperformanceonbothdatasetswhileobtaining
upto∼16×speedupcomparedtothebestexistingmethodinliterature. OnScan-
Net200val. set,ourOpen-YOLO3Dachievesmeanaverageprecision(mAP)of
24.7%whileoperatingat22secondsperscene. Codeandmodelareavailableat
github.com/aminebdj/OpenYOLO3D
1 Introduction
3Dinstancesegmentationisacomputervisiontaskthatinvolvesthepredictionofmasksforindi-
vidualobjectsina3Dpointcloudscene. Itholdssignificantimportanceinfieldslikeroboticsand
augmented reality. Due to its diverse applications, this task has garnered increasing attention in
recentyears. Researchershavelongfocusedonmethodsthattypicallyoperatewithinaclosed-set
framework,limitingtheirabilitytorecognizeobjectsnotpresentinthetrainingdata. Thisconstraint
poseschallenges, particularlywhennovelobjectsmustbeidentifiedorcategorizedinunfamiliar
environments. Recentmethods[34,42]addresstheproblemofnovelclasssegmentation,butthey
sufferfromslowinferencethatrangesfrom5minutesforsmallscenesto10minutesforlargescenes
Preprint.Underreview.
4202
nuJ
4
]VC.sc[
1v84520.6042:viXraGround truth Ours Open3DIS
Figure1: Open-vocabulary3DinstancesegmentationwithourOpen-YOLO3D.Theproposed
Open-YOLO3Discapableofsegmentingobjectsinazero-shotmanner. Here,Weshowtheoutput
foraScanNet200[38]scenewithvariousprompts,whereourmodelyieldsimprovedperformance
comparedtotherecentOpen3DIS[34]. Weshowzoomed-inimagesofhiddenpredictedinstancesin
thecoloredboxes. AdditionalresultsareinFigure4andsuppl. material.
duetotheirrelianceoncomputationallyheavyfoundationmodelslikeSAM[23]andCLIP[55]
alongwithheavycomputationforlifting2DCLIPfeatureto3D.
Open-vocabulary3Dinstancesegmentationisimportantforroboticstaskssuchas,materialhandling
wheretherobotisexpectedtoperformoperationsfromtext-basedinstructionslikemovingspecific
products,loadingandunloadinggoods,andinventorymanagementwhilebeingfastinthedecision-
makingprocess. Althoughstate-of-the-artopen-vocabulary3Dinstancesegmentationmethodsshow
highpromiseintermsofgeneralizabilitytonovelobjects,theystilloperateinminutesofinference
timeduetotheirrelianceonheavyfoundationmodelssuchasSAM.Motivatedbyrecentadvances
in2Dobjectdetection[7],welookintoanalternativeapproachthatleveragesfastobjectdetectors
insteadofutilizingcomputationallyexpensivefoundationmodels.
Thispaperproposesanovelopen-vocabulary3Dinstancesegmentationmethod,namedOpen-YOLO
3D, that utilizes efficient, joint 2D-3D reasoning, using 2D bounding box predictions to replace
computationally-heavysegmentationmodels. Weemployanopen-vocabulary2Dobjectdetector
togenerateboundingboxeswiththeirclasslabelsforallframescorrespondingtothe3Dscene;on
theotherside,weutilizea3Dinstancesegmentationnetworktogenerate3Dclass-agnosticinstance
masksforthepointclouds,whichprovestobemuchfasterthan3Dproposalgenerationmethods
from2Dinstances[34,32]. Unlikerecentmethods[42,34]whichuseSAMandCLIPtolift2Dclip
featuresto3Dforpromptingthe3Dmaskproposal,weproposeanalternativeapproachthatrelieson
theboundingboxpredictionsfrom2Dobjectdetectorswhichprovetobesignificantlyfasterthan
CLIP-basedmethods. WeutilizethepredictedboundingboxesinallRGBframescorrespondingto
thepointcloudscenetoconstructaLowGranularity(LG)labelmapforeveryframe. OneLGlabel
mapisatwo-dimensionalarraywiththesameheightandwidthastheRGBframe,withthebounding
boxareasreplacedbytheirpredictedclasslabel. Next,weuseintrinsicandextrinsicparametersto
projectthepointcloudsceneontotheirrespectiveLGlabelmapswithtop-kvisibilityforfinalclass
prediction. WepresentanexampleoutputofourmethodinFigure1. Ourcontributionsarefollowing:
• Weintroducea2Dobjectdetection-basedapproachforopen-vocabularylabelingof3D
instances,whichgreatlyimprovestheefficiencycomparedto2Dsegmentationapproaches.
• Weproposeanovelapproachtoscoring3Dmaskproposalsusingonlyboundingboxes
from2Dobjectdetectors.
• Our Open-YOLO 3D achieves superior performance on two benchmarks, while being
considerablyfasterthanexistingmethodsintheliterature. OnScanNet200val. set, our
Open-YOLO 3D achieves an absolute gain of 2.3% at mAP50 while being ∼16x faster
comparedtotherecentOpen3DIS[34].
2
doof
revotfel
eht
worhT"
eht
ot
sehsid
eht
ekaT"
"nib
hsart
eht
ni
"knis2 Relatedworks
Closed-vocabulary3Dsegmentation: The3Dinstancesegmentationtaskaimsatpredictingmasks
forindividualobjectsina3Dscene,alongwithaclasslabelbelongingtothesetofknownclasses.
Somemethodsuseagrouping-basedapproachinabottom-upmanner,bylearningembeddingsinthe
latentspacetofacilitateclusteringofobjectpoints[4,14,15,21,26,29,46,54].Conversely,proposal-
basedmethodsadoptatop-downstrategy,initiallydetecting3Dboundingboxesandthensegmenting
theobjectregionwithineachbox[10,17,31,49,52]. Notably, inspiredbyadvancementsin2D
works[5,6],transformerdesigns[43]havebeenrecentlyappliedto3Dinstancesegmentationtasks
[39,41,24,1,20]. Mask3D[39]introducesthefirsthybridarchitecturethatcombinesConvolutional
Neural Networks (CNN) and transformers for this task. It uses a 3D CNN backbone to extract
per-pointfeaturesandatransformer-basedinstancemaskdecodertorefineasetofqueries. Building
onMask3D,theauthorsof[1]showthatusingexplicitspatialandsemanticsupervisionatthelevel
ofthe3Dbackbonefurtherimprovestheinstancesegmentationresults. Oneformer3D[24]followsa
similararchitectureandintroduceslearnablekernelsinthetransformerdecoderforaunifiedsemantic,
instance,andpanopticsegmentation. ODIN[20]proposesanarchitecturethatuses2D-3Dfusion
togeneratethemasksandclasslabels. Othermethodsintroduceweakly-supervisedalternativesto
denseannotationapproaches,aimingtoreducetheannotationcostassociatedwith3Ddata[8,18,47].
Whilethesemethodologiesstrivetoenhancethequalityof3Dinstancesegmentation,theytypically
relyonapredefinedsetofsemanticlabels. Incontrast,ourproposedapproachaimsatsegmenting
objectswithbothknownandunknownclasslabels.
Open-vocabulary 2D recognition: This task aims at identifying both known and novel classes,
wherethelabelsoftheknownclassesareavailableinthetrainingset,whilethenovelclassesarenot
encounteredduringtraining. Inthedirectionofopen-vocabularyobjectdetection(OVOD),several
approacheshavebeenproposed[58,36,30,53,45,22,51,7]. Anotherwidelystudiedtaskisopen-
vocabularysegmentation(OVSS)[3,48,27,12,28]. Recentopen-vocabularysemanticsegmentation
methods [27, 12, 28] leverage pre-trained CLIP [55] to perform open-vocabulary segmentation,
wherethemodelistrainedtooutputapixel-wisefeaturethatisalignedwiththetextembedding
intheCLIPspace. Furthermore, AttrSeg[33]proposesadecomposition-aggregationframework
wherevanillaclassnamesarefirstdecomposedintovariousattributedescriptions,andthendifferent
attributerepresentationsareaggregatedintoafinalclassrepresentation. Open-vocabularyinstance
segmentation(OVIS)aimsatpredictinginstancemaskswhilepreservinghighzero-shotcapabilities.
One approach [19] proposes a cross-modal pseudo-labeling framework, where a student model
is supervised with pseudo-labels for the novel classes from a teacher model. Another approach
[44] proposes an annotation-free method where a pre-trained vision-language model is used to
produceannotationsatboththeboxandpixellevels. Althoughthesemethodsshowhighzero-shot
performanceandreal-timespeed,theyarestilllimitedto2Dapplicationsonly.
Open-vocabulary3Dsegmentation: Severalmethods[35,13,16]havebeenproposedtoaddress
thechallengesofopen-vocabularysemanticsegmentationwheretheyusefoundationmodelslike
clipforunknownclassdiscovery,whiletheauthorsof[2]focusonweaksupervisionforunknown
class discovery without relying on any 2D foundation model. OpenScene [35] makes use of 2D
open-vocabularysemanticsegmentationmodelstoliftthepixel-wise2DCLIPfeaturesintothe3D
space,whichallowsthe3Dmodeltoperform3Dopen-vocabularypointcloudsemanticsegmentation.
On the other hand, ConceptGraphs [13] relies on creating an open-vocabulary scene graph that
captures object properties such as spatial location, enabling a wide range of downstream tasks
includingsegmentation,objectgrounding,navigation,manipulation,localization,andremapping.
In the direction of 3D point cloud instance segmentation, OpenMask3D [42] uses a 3D instance
segmentationnetworktogenerateclass-agnosticmaskproposals,alongwithSAM[23]andCLIP
[55],toconstructa3DclipfeatureforeachmaskusingRGB-Dimagesassociatedwiththe3Dscene.
UnlikeOpenMask3Dwherea3Dproposalnetworkisused,OVIR-3D[32]generates3Dproposalsby
fusing2Dmasksobtainedbya2Dinstancesegmentationmodel. Open3DIS[34]combinesproposals
from2Dand3Dwithnovel2Dmasksfusionapproachesviahierarchicalagglomerativeclustering,
andalsoproposestousepoint-wise3DCLIPfeaturesinsteadofmask-wisefeatures. Thetwomost
recentapproachesin[34,42]showpromisinggeneralizabilityintermsofnovelclassdiscovery[42]
and novel object geometries especially small objects [34]. However, they both suffer from slow
inferencespeed,astheyrelyonSAMfor3Dmaskproposalclipfeatureaggregationinthecaseof
OpenMask3D[42],andfornovel3Dproposalmasksgenerationfrom2Dmasks[34].
3Input Output
2D Projection Input/ Output
3D Network
2D OVOD
"chair", "table",
..., "mattress"
Figure 2: Proposed open-world 3D instance segmentation pipeline. We use a 3D instance
segmentationnetwork(3DNetwork)forgeneratingclass-agnosticproposals. Foropen-vocabulary
prediction,a2DOpen-VocabularyObjectDetector(2DOVOD)generatesboundingboxeswithclass
labels. Thesepredictionsareusedtoconstructlabelmapsforallinputframes. Next,weassignthe
top-klabelmapstoeach3Dproposalbasedonvisibility. Finally,wegenerateaMulti-ViewPrompt
Distributionfromthe2Dprojectionsoftheproposalstomatchatextprompttoevery3Dproposal.
3 Preliminaries
Problemformulation: 3Dinstancesegmentationaimsatsegmentingindividualobjectswithina
3D scene and assigning one class label to each segmented object. In the open-vocabulary (OV)
setting,theclasslabelcanbelongtopreviouslyknownclassesinthetrainingsetaswellasnewclass
labels. Tothisend,letP denotea3Dreconstructedpointcloudscene,whereasequenceofRGB-D
imageswasusedforthereconstruction. WedenotetheRGBimageframesasI alongwiththeir
correspondingdepthframesD.Similartorecentmethods[35,42,34],weassumethattheposesand
cameraparametersareavailablefortheinput3Dscene.
3.1 BaselineOpen-Vocabulary3DInstanceSegmentation
WebaseourapproachonOpenMask3D[42],whichisthefirstmethodthatperformsopen-vocabulary
3D instance segmentation in a zero-shot manner. OpenMask3D has two main modules: a class-
agnosticmaskproposalhead, andamask-featurecomputationmodule. Theclass-agnosticmask
proposalheadusesatransformer-basedpre-trained3Dinstancesegmentationmodel[39]topredicta
binarymaskforeachobjectinthepointcloud. Themask-featurecomputationmodulefirstgenerates
2Dsegmentationmasksbyprojecting3Dmasksintoviewsinwhichthe3Dinstancesarehighly
visible,andrefinesthemusingtheSAM[23]model. Apre-trainedCLIPvision-languagemodel[55]
isthenusedtogenerateimageembeddingsforthe2Dsegmentationmasks. Theembeddingsarethen
aggregatedacrossallthe2Dframestogeneratea3Dmask-featurerepresentation.
Limitations: OpenMask3Dmakesuseoftheadvancementsin2Dsegmentation(SAM)andvision-
languagemodels(CLIP)togenerateandaggregate2Dfeaturerepresentations,enablingthequerying
ofinstancesaccordingtoopen-vocabularyconcepts. However,thisapproachsuffersfromahigh
computationburdenleadingtoslowinferencetimes, withaprocessingtimeof5-10minutesper
scene. Thecomputationburdenmainlyoriginatesfromtwosub-tasks: the2Dsegmentationofthe
largenumberofobjectsfromthevarious2Dviews,andthe3Dfeatureaggregationbasedonthe
objectvisibility. Wenextintroduceourproposedmethodwhichaimsatreducingthecomputation
burdenandimprovingthetaskaccuracy.
4 Method: Open-YOLO3D
Motivation: We here present our proposed 3D open-vocabulary instance segmentation method,
Open-YOLO 3D, which aims at generating 3D instance predictions in an efficient strategy. Our
proposedmethodintroducesefficientandimprovedmodulesatthetasklevelaswellasthedatalevel.
TaskLevel: UnlikeOpenMask3D,whichgeneratessegmentationsoftheprojected3Dmasks,we
pursueamoreefficientapproachbyrelyingon2Dobjectdetection. Sincetheendtargetistogenerate
labelsforthe3Dmasks,theincreasedcomputationfromthe2Dsegmentationtaskisnotnecessary.
DataLevel: OpenMask3Dcomputesthe3Dmaskvisibilityin2Dframesbyiterativelycounting
4
enecS
D3
D-BGR ecneuqes
D3
weiv-itluM
slasoporp
spam
lebalvisiblepointsforeachmaskacrossallframes. Thisapproachistime-consuming,andweproposean
alternativeapproachtocomputethe3Dmaskvisibilitywithinallframesatonce.
4.1 OverallArchitecture
OurproposedpipelineisshowninFigure2. First,wegenerateasetofinstanceproposalsM using
a3Dinstancesegmentationnetwork;theproposalsarerepresentedasbinarymasks,whereevery
3D mask has a dimension equal to the number of points as the input point cloud. For the open
vocabulary prediction, we use a 2D open-vocabulary object detection model to generate a set of
boundingboxesdenotedB foreveryframeI ;theboundingboxeswiththeirpredictedlabelsare
i i
usedtoconstructalow-granularitylabelmapL foreveryinputframeI . ToassignapromptIDto
i i
the3Dmaskproposals,wefirststartbyprojectingallN pointsinthepointcloudsceneP ontothe
N frames,whichresultsinN 2DprojectionwithN pointsforeach. Afterward,the2Dprojections
f f
andthe3Dmaskproposalsareusedtocomputethevisibilityofeverymaskineveryframeusingour
proposedacceleratedvisibilitycomputation(VAcc);thevisibilityisthenusedtoassigntop-kLow-
Granularitylabelmapstoeachmaskandtoselectthetop-k2Dprojectionscorrespondingtoevery
3Dmaskproposal;forasingle3Dmaskwecropthe(x,y)coordinatesfromtheprojectionsusing
theinstancemaskandfilteroutthepointsthatareoccludedoroutsidetheframe. Thefinalcropped
(x,y)coordinatesfromthetop-kframesareusedtoselectper-pointlabelsfromtheircorresponding
Low-Granularity labelmapsto finallyconstructa Multi-View PromptDistribution topredictthe
promptIDcorrespondingtothe3Dmaskproposal.
4.2 3DObjectProposal
To generate class-agnostic 3D object proposals, we rely on the 3D instance generation approach
Mask3D[39],whichallowsforfasterproposalgenerationcomparedto2Dmask-based3Dproposal
generationmethods[34,32]. Mask3Disahybridmodelthatcombinesa3DConvolutionalNeural
Network as a backbone for feature generation and a transformer-based model for mask instance
prediction. The3DCNNbackbonetakesthevoxelizedinputpointcloudsceneasinput,andoutputs
multi-levelfeaturemaps,whilethetransformerdecodertakesthemulti-levelfeaturemapstorefinea
setofqueriesthroughselfandcross-attention. Thefinalrefinedqueriesareusedtopredictinstance
masks. The3DproposalnetworkpredictsasetK ∈Nof3DmaskproposalsM ∈ZK3D×N fora
3D 2
givenpointcloudP ∈R4×N withN pointsinhomogeneouscoordinatesystem,whereZ ={0,1}.
2
4.3 LowGranularity(LG)Label-Maps
Asdiscussedearlier,thefocusofourapproachistogeneratefastandaccurateopen-vocabularylabels
forthegenerated3Dproposals. Insteadofrelyingoncomputationallyintensive2Dsegmentation,
weproposea2Ddetection-basedapproachinourpipeline. ForeveryRGBimageI wegenerate
i
asetofK boundingboxesB ={(b ,c ) | b ∈R4, c ∈N, ∀j ∈(1,...,K )}usingan
b,i i j j j j b,i
open-vocabulary2Dobjectdetector, whereb aretheboundingboxescoordinateswhilec isits
j j
predictedlabel. Weassignaweightw =bH +bW foreachoutputboundingboxb ,wherebH and
j j j j j
bW aretheboundingbox’sheightandwidth,respectively. Theweightsrepresenttheboundingbox
j
sizeandhelpdeterminetheorderofboundingboxeswhenusedtoconstructtheLGlabelmaps.
Afterobtainingthe2Dobjectdetections,werepresenttheoutputofeach2DimageframeI asan
i
LGlabelmapL ∈ ZW×H. ToconstructL , westartbyinitializingallofitselementsas-1. In
i i
ournotation, -1representsnoclassandisignoredduringprediction. Next, wesortallbounding
boxesfollowingtheirweightsandreplacetheregionoftheboundingboxb withitscorresponding
j
predictedclasslabelc inthelabelmap,startingwiththeboundingboxwiththehighestweight. The
j
weightw choiceismotivatedbythefactthatiftwoobjectsofdifferentsizesappearinthesame
j
directionthecameraispointingto,thesmallobjectisvisibleintheimageifitisclosertothecamera
thanthelargeobject.
4.4 AcceleratedVisibilityComputation(VAcc)
Inordertoassociate2Dlabelmapswith3Dproposals,wecomputethevisibilityofeach3Dmask.
Tothisend,weproposeafastapproachthatisabletocompute3Dmaskvisibilitywithinframesvia
tensoroperationswhicharehighlyparallelizable.
52D Projection
Selected set of labels
2D OVOD
Top-K LG label maps
"chair", "table", ..., "mattress"
Figure3: Multi-ViewPromptDistribution(MVPDist). AftercreatingtheLGlabelmapsforall
frames,weselectthetop-klabelmapsbasedonthe2Dprojectionofthe3Dproposal. Usingthe(x,
y)coordinatesofthe2Dprojection,wechoosethelabelsfromtheLGlabelmapstogeneratethe
MVPDist. ThisdistributionpredictstheIDofthetextpromptwiththehighestprobability.
GivenK ∈N2DRGBframesI ={I ∈R3×W×H | ∀i∈(1,...,K )}associatedwiththe3D
f i f
sceneP,alongwiththeirintrinsicmatricesI ∈RNf×4×4andextrinsicmatricesE ∈RNf×4×4. We
denotetheprojectionofthe3DpointcloudP onaframewithindexiP2D ∈R4×N,anditcanbe
i
computedasfollowsP2D =I ·E ·P. Afterstackingtheprojectionoperationsofallframes,the
i i i
projectionofthesceneontoallframescanbecomputedwithaGPUinasingleshotasfollows
P2D =(I⋆E)·P
where⋆isbatch-matrixmultiplication,·ismatrixmultiplication,andP2D ∈RNf×4×N definedas
P2D =[P2D,...,P2D].
1 Nf
Furthermore,wecomputethevisibilityVf ∈ ZNf×N ofallprojectedpointswithinallframesas
2
follows
Vf =1(0<P2D <W)⊙1(0<P2D <H)
x y
where 1 is the indicator function, W and H are the image width and height respectively , ⊙ is
elementwisemultiplication,P2D ∈RNf×N andP2D ∈RNf×N aretheprojected3Dpointsxand
x y
ycoordinatesonallN frames,respectively.
f
Forocclusion,wedefineanothervisibilitymatrixasVd ∈ZNf×N thatiscomputedasfollows
2
Vd =1(|P2D−D |<τ )
z z depth
whereD
z
∈ RNf×N istherealdepthofthe3Dpointcloudobtainedfromthedepthmaps,while
P2D =P2D isthedepthobtainedfromprojectingthepointcloudP,and|·|isthe
z 1≤i≤Nf,j=3,1≤k≤N
absolutevalue. Finally,theper3Dmaskproposalvisibility{V ∈RNf×K3D, 0≤V ≤1},canbe
computedinasingleshotusingaGPUasfollows
V =(cid:0) (Vf ⊙Vd)·MT(cid:1) ⊙M−1
count
whereM ∈ZK3D×N isthematrixof3Dmaskproposalsgeneratedbythe3Dproposalnetwork,and
2
M
count
∈NK3D isthecountofpointspermask,
Thepercentageofvisibilityofamaskj inaframeiisrepresentedwiththeelementV ∈V.
i,j
4.5 Multi-ViewPromptDistribution(MVPDist)
GivenanRGBsequenceIandtheircorrespondingLGlabel-mapsL={L | L ∈ZW×H, ∀i∈
i i
(1,...,K f)}. WedefinethelabeldistributionD j ∈ZN dj ist ofa3DmaskproposalM j as
D ={L (cid:2) P2D·M ,P2D·M (cid:3) | ∀i∈P }
j i i,x ji i,y ji k
where M = Vd ·Vf ·M is the mask for non-occluded in-frame points that belong to the jth
ji i i j
instance,P isthesetofframeindiceswherethejth3Dmaskhastop-kvisibility,computedusing
k
thevisibilitymatrixV,P2D andP2D aretheprojectedxandycoordinatesofthepointcloudscene
i,x i,y
6
depporC
D-BGR
lasoporP
D3
semarfTable1: State-of-the-artcomparisononScanNet200validationset. WeuseMask3Dtrainedon
theScanNet200trainingsettogenerateclass-agnosticmaskproposals. Ourmethoddemonstrates
betterperformancecomparedtothosethatgenerate3Dproposalsbyfusing2Dmasksandproposals
froma3Dnetwork(highlightedingrayinthetable). Itoutperformsstate-of-the-artmethodsbya
widemarginunderthesameconditionsusingonlyproposalsfroma3Dnetwork.
SAMfor
3Dproposals
Method 3Dmask mAP mAP50 mAP25 head comm tail time/scene(s)
from2Dmasks
labeling
Mask3D[39](ClosedVocab.) × × 26.9 36.2 41.4 39.8 21.7 17.9 13.41
SAM3D[50] ✓ × 6.1 14.2 21.3 7.0 6.2 4.6 482.60
OVIR-3D ✓ × 13.0 24.9 32.3 14.4 12.7 11.7 466.80
Open3DIS[34] ✓ × 23.7 29.4 32.8 27.8 21.2 21.8 360.12
OpenScene[35](2DFusion) × × 11.7 15.2 17.8 13.4 11.6 9.9 46.45
OpenScene[35](3DDistill) × × 4.8 6.2 7.2 10.6 2.6 0.7 0.26
OpenScene[35](2D-3DEns.) × × 5.3 6.7 8.1 11.0 3.2 1.1 46.78
OpenMask3D[42] × ✓ 15.4 19.9 23.1 17.1 14.1 14.9 553.87
Open3DIS[34] × × 18.6 23.1 27.3 24.7 16.9 13.3 57.68
Open-YOLO3D(Ours) × × 24.7 31.7 36.2 27.8 24.3 21.6 21.8
ontothei frame,respectively,while[·,·]:ZW×H (cid:55)→Znisacoordinate-basedselectionoperator
th
withnasanarbitrarynaturalnumber.
WedefinetheprobabilityforthemaskM tobeassignedtoaclasscastheoccurrenceofclassc
j
withinthedistributionD ;wedemonstratetheapproachinFigure3forone3Dproposal. Weassign
j
theclasswiththehighestprobabilitytothemaskM .
j
4.6 InstancePredictionConfidenceScore
Weproposeinthissectionawaytoscoreclass-agnostic3Dinstancemaskproposalsbyleveraging
2Dinformationfromboundingboxesalongwith3Dinformationfrom3Dmasks. Ourrationaleis
thatagoodmaskshouldleadtoahighclassandmaskconfidence,unlikepreviousOpen-Vocabulary
3Dinstancesegmentationmethods,whichuseonlyclassconfidence. Toachievethis,wedefinethe
scoreofa3Dmaskproposalass =s ·s ,wheres istheprobabilityoftheclasswith
m IoU class class
thehighestoccurrenceinMVPDist,whiles istheaverageIoUacrossmulti-viewsbetweenthe
IoU
boundingboxoftheprojected3DmaskandtheboundingboxwiththehighestIoUgeneratedwitha
2Dobjectdetectorintheview(Moredetailsareintheappendix).
5 Experiments
Datasets: WeconductourexperimentsusingtheScanNet200[38]andReplica[40]datasets. Our
analysisonScanNet200isbasedonitsvalidationset,comprising312scenes. Forthe3Dinstance
segmentationtask,weutilizethe200predefinedcategoriesfromtheScanNet200annotations. Scan-
Net200labelsarecategorizedintothreesubsets—head(66categories),common(68categories),and
tail(66categories)—basedonthefrequencyoflabeledpointsinthetrainingset. Thiscategorization
allowsustoevaluateourmethod’sperformanceacrossthelong-taildistribution,underscoringScan-
Net200asasuitableevaluationdataset. Additionally,toassessthegeneralizabilityofourapproach,
weconductexperimentsontheReplicadataset,whichhas48categories. Forthemetrics,wefollow
theevaluationmethodologyinScanNet[9]andreporttheaverageprecision(AP)attwomaskoverlap
thresholds: 50%and25%,aswellastheaverageacrosstheoverlaprangeof[0.5:0.95:0.05].
Implementation details: We use RGB-depth pairs from the ScanNet200 and Replica datasets,
processing every 10th frame for ScanNet200 and all frames for Replica, maintaining the same
settingsasOpenMask3Dforfaircomparison. TocreateLGlabelmaps,weusetheYOLO-World[7]
extra-largemodelforitsreal-timecapabilityandhighzero-shotperformance. WeuseMask3D[39]
withnon-maximumsuppressiontofilterproposalssimilartoOpen3DIS[34],andavoidDBSCAN
[11]topreventinferenceslowdowns. WeuseasingleNVIDIAA10040GBGPUforallexperiments.
5.1 Resultsanalysis
Open-Vocabulary3DinstancesegmentationonScanNet200: Wecompareourmethod’sperfor-
manceagainstotherapproachesontheScanNet200datasetinTable1. Weindicatewhethereach
7Table2: State-of-the-artcomparisononReplicadataset. WeuseMask3DtrainedontheScan-
Net200trainingsettogenerateclass-agnosticmaskproposals. Weshowthatourmethodgeneralizes
betterthanstate-of-the-artmethodsunderthesamesettingwithproposalsfrom3Dnetworksonly.
SAMfor
3Dproposals
Method 3Dmask mAP mAP50 mAP25 time/scene(s)
from2Dmasks
labeling
OVIR-3D ✓ × 11.1 20.5 27.5 52.74
Open3DIS[34] ✓ × 18.5 24.5 28.2 187.97
OpenScene[35](2Dfusion) × × 10.9 15.6 17.3 317.327
OpenScene[35](3DDistill) × × 8.2 10.5 12.6 04.29
OpenScene[35](2D-3DEns.) × × 8.2 10.4 13.3 320.127
OpenMask3D[42] × ✓ 13.1 18.4 24.2 547.32
Open3DIS[34] × × 14.9 18.8 23.6 35.08
Open-YOLO3D(Ours) × × 23.7 28.6 34.8 16.6
"Square Table" "plant"
Open3DIS Ours Open3DIS Ours
Figure4: Qualitativeresultsonsceneoffice0intheReplicadataset. Weshowinstanceswitha
confidencescoreabove0.5forbothmethods. Weshowthatourmethodismuchmoreprecisewhen
segmentingtheobjectinthetextcomparedtostate-of-the-artmethodOpen3DIS.
methoduses2Dinstancestogenerate3DproposalsandwhetherSAMisusedforlabelingthe3D
masks. Ourmethodachievesstate-of-the-artperformancewithproposalsfromonlya3Dinstance
segmentationnetworkcomparedtomethodsfromtwosettings(i)3Dmaskproposalsfromonlya3D
instancesegmentationnetwork(ii)usingacombinationof3Dmaskproposalsfroma3Dnetworkand
2Dinstancesfroma2Dsegmentationmodel. Additionally,ourmethodis∼16×fastercomparedto
state-of-the-artOpen3DIS.
Generalizabilitytest: Totestthegeneralizabilityofourmethod,weusethe3Dproposalnetwork
pre-trainedontheScanNet200trainingsetandevaluateontheReplicadataset;theresultsareshown
inTable2. Ourmethodshowscompetitiveperformancewith∼11×speedupagainststate-of-the-art
models[34],whichuseCLIPfeatures.
Performance with given 3D
masks: We further test our Table5:ComparativeresultswithoraclemasksonScanNet200
methodfor3Dproposalprompt- dataset. Our MVPDist significantly outperforms state-of-the-
ing from text against existing artmethodsusingCLIPfeatures. WeshowthatMVPDistwith
methods in the literature in the YOLO-WORLDpredictionscanusemulti-viewinformationto
case of ground truth 3D masks achievehighzero-shotcapabilities.
and report the results in Table 2DOV
Method mAP head comm tail
5. For Mask3D, oracle masks Prior
are assigned class predictions ClosedVocab.
Mask3D[39] None 35.5 55.2 27.2 22.2
from matched predicted masks
usingHungarianmatching. For OpenScene[35] 2DLSeg[27] 11.8 26.9 5.2 1.7
OpenScene[35] 2DOpenSeg[12] 22.9 26.2 22.0 20.2
open-vocabulary methods, we OpenMask3D[42] MaskwiseCLIP[37] 29.1 31.1 24.0 32.9
useground-truthmasksasinput Open3DIS[34] PointwiseCLIP[37] 30.9 33.1 25.1 35.4
proposals. We show the results Open-YOLO3D(Ours) MVPDist 39.6 43.3 36.8 38.5
inTable5thatMVPDistcanout-
performCLIP-basedapproachesinretrievingthecorrect3Dproposalmasksfromtextprompts,due
tothehighzero-shotperformanceachievedbystate-of-the-artopen-vocabulary2Dobjectdetectors.
8Table 3: Ablation study on Replica dataset with ground truth masks. We show the effect of
replacing SAM with a 2D object detector in rows R2 to R4 while we demonstrate the effect of
replacingCLIPfeatureswithMVPDistwithlabelmapsfromanOV2Dobjectdetector.
Labeling time/scene
RowID↓ 2DPrior MVPDist VAcc mAP
method (s)
R1 SAM[23]+CLIP Clipfeatures × × 33.0 675,6
R2 YoloV8+CLIP Clipfeatures × × 21.1 440.40
R3 RT-DETR[57]+CLIP Clipfeatures × × 28.4 487.95
R4 YoloWorld[7]+CLIP Clipfeatures × × 32.5 384.29
R5 YoloWorld LGLabelMaps ✓ × 46.2 376.42
R6 YoloWorld LGLabelMaps ✓ ✓ 46.2 17.86
Table4: Effectofnumberoftop-kviewsonthelabelingperformancewithHighGranularity
(HG)andLow-Granularity(LG)labelmaps. HGLabelmapsaregeneratedbypromptingSAM
withtheboundingboxesusedtogenerateLGlabelmaps.
Topk(→) 1 10 20 30 40
Maptype(↓) mAP/time(s) mAP/time(s) mAP/time(s) mAP/time(s) mAP/time(s)
HGlabelmaps 16.3/113.93 22.5/115.16 23.9/114.76 24.4/115.89 24.5/115.92
LGlabelmaps 16.3/20.7 22.8/21.6 24.3/21.7 24.6/22.1 24.7/22.2
AblationoverReplicadataset: TotesttheabilityofobjectdetectorstoreplaceSAMforgenerating
cropsfor3DCLIPfeatureaggregation,weconductthreeexperimentswithdifferentobjectdetectors
on the Replica dataset, using ground truth 3D mask proposals to compare our method’s labeling
abilityagainstothers. TheresultsareinTable3,rowsR2toR4,withrowR1showingOpenMask3D
[42] base code results. We generate class-agnostic bounding boxes with an object detector, then
assignthehighestIoUboundingboxtoeach3Dinstanceasacrop,selectingthemostvisibleviews.
For3DCLIPfeatureaggregation,wefollowOpenMask3D’sapproach,aggregatingfeaturesfrom
multiplelevelsandviews. TheseexperimentsshowthatYOLO-Worldcangeneratecropsnearlyas
goodasSAMbutwithsignificantspeedimprovements. RowR5demonstratesYOLO-World’sbetter
zero-shotperformanceusingourproposedMulti-ViewPromptDistributionwithLGlabelmaps. Row
R6showsspeedimprovementsusingtheGPUfor3Dmaskvisibilitycomputation.
TopKanalysis: WeshowinTable4thatnaivelyusingYOLO-Worldwithonlyonelabel-mapwith
thehighestvisibilityper3Dmaskproposalresultsinsub-optimalresultsandusingtop-Klabel-maps
canresultinbetterpredictionsasthedistributioncanprovidebetterestimateacrossmultipleframes,
since YOLO-World is also expected to make misclassifications in some views while generating
correctonesinothers. ThisapproachassumesthatYOLO-Worldmakesacorrectclasspredictionfor
thesame3Dobjectinmultipleviewsforittobeeffective.
High-Granularity(HG)vs. Low-Granularity(LG):Table4showsthatusingSAMtogenerate
HGlabelmapsslightlyreducesmAP,andslowsdowntheinferenceby∼5times. Thisisduetothe
natureofprojected3Dinstancesinto2D,wheretheprojectionalreadyholds2Dinstanceinformation
asshowninFigure3,andSAMwouldjustresultinredundancyintheprediction.
Qualitativeresults: WeshowqualitativeresultsontheReplicadatasetinFigure4andcompareit
toOpen3DIS.Open3DISshowsgoodperformanceinrecallingnovelgeometriesthat3Dproposal
networkslikeMask3Dgenerallyfailtocapture(small-sizedobjects). However,itcomesatthecost
ofverylowprecisionduetotheredundantmaskswithdifferentclasspredictions.
Limitations: Ourmethodmakesuseofa3Dproposalnetworkonlyforproposalgenerationinorder
toreachhighspeed. Otherproposalgenerationmethods[32,34]fuse2Dinstancemasksfroma2D
instancesegmentationmethodstogeneraterich3Dproposalsevenforverysmallobjects,whichare
generallyoverlookedby3DproposalnetworkslikeMask3D[39]duetolowresolutionin3D.Thus,
fast2DinstancesegmentationmodelslikeFastSAM[56]canbeusedtogenerate3Dproposalsfrom
the2Dimages,whichmightfurtherimprovetheperformanceofourmethod.
96 Conclusion
WepresentOpen-YOLO3D,anovelandefficientopen-vocabulary3Dinstancesegmentationmethod,
which makes use of open-vocabulary 2D object detectors instead of heavy segmentation models.
Ourapproachleveragesa2Dobjectdetectorforclass-labeledboundingboxesanda3Dinstance
segmentationnetworkforclass-agnosticmasks. WeproposetouseMVPDistgeneratedfrommulti-
viewlowgranularitylabelmapstomatchtextpromptsto3Dclassagnosticmasks. Ourproposed
methodoutperformsexistingtechniques,withgainsinmAPandinferencespeed. Theseresultsshow
anewdirectiontowardmoreefficientopen-vocabulary3Dinstancesegmentationmodels.
References
[1] S.AlKhatib,M.ElAmineBoudjoghra,J.Lahoud,andF.S.Khan. 3dinstancesegmentation
viaenhancedspatialandsemanticsupervision. InProceedingsoftheIEEE/CVFInternational
ConferenceonComputerVision,pages541–550,2023.
[2] M.E.A.Boudjoghra,S.K.A.Khatib,J.Lahoud,H.Cholakkal,R.M.Anwer,S.Khan,and
F.Khan. 3dindoorinstancesegmentationinanopen-world. InAdvancesinNeuralInformation
ProcessingSystems,2023.
[3] M.Bucher,T.-H.Vu,M.Cord,andP.Pérez. Zero-shotsemanticsegmentation. Advancesin
NeuralInformationProcessingSystems,32,2019.
[4] S.Chen,J.Fang,Q.Zhang,W.Liu,andX.Wang. Hierarchicalaggregationfor3dinstance
segmentation. InProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision,
pages15467–15476,2021.
[5] B. Cheng, I. Misra, A. G. Schwing, A. Kirillov, and R. Girdhar. Masked-attention mask
transformerforuniversalimagesegmentation. InProceedingsoftheIEEE/CVFConferenceon
ComputerVisionandPatternRecognition,pages1290–1299,2022.
[6] B.Cheng,A.Schwing,andA.Kirillov. Per-pixelclassificationisnotallyouneedforsemantic
segmentation. AdvancesinNeuralInformationProcessingSystems,34:17864–17875,2021.
[7] T. Cheng, L. Song, Y. Ge, W. Liu, X. Wang, and Y. Shan. Yolo-world: Real-time open-
vocabularyobjectdetection. InProc.IEEEConf.ComputerVisionandPatternRecognition
(CVPR),2024.
[8] J.Chibane,F.Engelmann,T.AnhTran,andG.Pons-Moll. Box2mask: Weaklysupervised3d
semanticinstancesegmentationusingboundingboxes. InComputerVision–ECCV2022: 17th
EuropeanConference,TelAviv,Israel,October23–27,2022,Proceedings,PartXXXI,pages
681–699.Springer,2022.
[9] A.Dai,A.X.Chang,M.Savva,M.Halber,T.Funkhouser,andM.Nießner. Scannet: Richly-
annotated3dreconstructionsofindoorscenes. InProc.ComputerVisionandPatternRecogni-
tion(CVPR),IEEE,2017.
[10] F. Engelmann, M. Bokeloh, A. Fathi, B. Leibe, and M. Nießner. 3d-mpa: Multi-proposal
aggregationfor3dsemanticinstancesegmentation. InProceedingsoftheIEEE/CVFconference
oncomputervisionandpatternrecognition,pages9031–9040,2020.
[11] M.Ester,H.-P.Kriegel,J.Sander,andX.Xu.Adensity-basedalgorithmfordiscoveringclusters
inlargespatialdatabaseswithnoise. InProceedingsoftheSecondInternationalConferenceon
KnowledgeDiscoveryandDataMining,KDD’96,page226–231.AAAIPress,1996.
[12] G.Ghiasi,X.Gu,Y.Cui,andT.-Y.Lin. Scalingopen-vocabularyimagesegmentationwith
image-levellabels. InEuropeanConferenceonComputerVision,pages540–557.Springer,
2022.
[13] Q.Gu,A.Kuwajerwala,K.M.Jatavallabhula,B.Sen,A.Agarwal,C.Rivera,W.Paul,R.Chel-
lappa, C.Gan, C.M.deMelo, etal. Conceptgraphs: Open-vocabulary3dscenegraphsfor
perceptionandplanning. In2ndWorkshoponLanguageandRobotLearning: Languageas
Grounding,2023.
10[14] L.Han,T.Zheng,L.Xu,andL.Fang. Occuseg: Occupancy-aware3dinstancesegmentation.
InProceedingsoftheIEEE/CVFconferenceoncomputervisionandpatternrecognition,pages
2940–2949,2020.
[15] T.He,C.Shen,andA.VanDenHengel. Dyco3d: Robustinstancesegmentationof3dpoint
cloudsthroughdynamicconvolution. InProceedingsoftheIEEE/CVFconferenceoncomputer
visionandpatternrecognition,pages354–363,2021.
[16] Y. Hong, C. Lin, Y. Du, Z. Chen, J. B. Tenenbaum, and C. Gan. 3d concept learning and
reasoningfrommulti-viewimages. InProceedingsoftheIEEE/CVFConferenceonComputer
VisionandPatternRecognition,pages9202–9212,2023.
[17] J.Hou,A.Dai,andM.Nießner. 3d-sis: 3dsemanticinstancesegmentationofrgb-dscans. In
ProceedingsoftheIEEE/CVFconferenceoncomputervisionandpatternrecognition,pages
4421–4430,2019.
[18] J.Hou,B.Graham,M.Nießner,andS.Xie. Exploringdata-efficient3dsceneunderstanding
withcontrastivescenecontexts. InProceedingsoftheIEEE/CVFConferenceonComputer
VisionandPatternRecognition,pages15587–15597,2021.
[19] D.Huynh,J.Kuen,Z.Lin,J.Gu,andE.Elhamifar. Open-vocabularyinstancesegmentationvia
robustcross-modalpseudo-labeling. InProceedingsoftheIEEE/CVFConferenceonComputer
VisionandPatternRecognition,pages7020–7031,2022.
[20] A.Jain,P.Katara,N.Gkanatsios,A.W.Harley,G.Sarch,K.Aggarwal,V.Chaudhary,and
K.Fragkiadaki.Odin:Asinglemodelfor2dand3dperception.InProceedingsoftheIEEE/CVF
ConferenceonComputerVisionandPatternRecognition,2024.
[21] L.Jiang,H.Zhao,S.Shi,S.Liu,C.-W.Fu,andJ.Jia. Pointgroup: Dual-setpointgroupingfor
3dinstancesegmentation. InProceedingsoftheIEEE/CVFconferenceoncomputervisionand
Patternrecognition,pages4867–4876,2020.
[22] P.Kaul,W.Xie,andA.Zisserman.Multi-modalclassifiersforopen-vocabularyobjectdetection.
InInternationalConferenceonMachineLearning,2023.
[23] A. Kirillov, E. Mintun, N. Ravi, H. Mao, C. Rolland, L. Gustafson, T. Xiao, S. Whitehead,
A.C.Berg,W.-Y.Lo,etal. Segmentanything. InProceedingsoftheIEEE/CVFInternational
ConferenceonComputerVision,pages4015–4026,2023.
[24] M.Kolodiazhnyi,A.Vorontsova,A.Konushin,andD.Rukhovich. Oneformer3d: Onetrans-
formerforunifiedpointcloudsegmentation. InProceedingsoftheIEEE/CVFConferenceon
ComputerVisionandPatternRecognition,2024.
[25] J.Lahoud,J.Cao,F.S.Khan,H.Cholakkal,R.M.Anwer,S.Khan,andM.-H.Yang. 3dvision
withtransformers: Asurvey,2022.
[26] J.Lahoud,B.Ghanem,M.Pollefeys,andM.R.Oswald.3dinstancesegmentationviamulti-task
metriclearning. InProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision,
pages9256–9266,2019.
[27] B.Li, K.Q.Weinberger, S.Belongie, V.Koltun, andR.Ranftl. Language-drivensemantic
segmentation. InInternationalConferenceonLearningRepresentations,2021.
[28] F.Liang,B.Wu,X.Dai,K.Li,Y.Zhao,H.Zhang,P.Zhang,P.Vajda,andD.Marculescu.Open-
vocabularysemanticsegmentationwithmask-adaptedclip. InProceedingsoftheIEEE/CVF
ConferenceonComputerVisionandPatternRecognition,pages7061–7070,2023.
[29] Z.Liang,Z.Li,S.Xu,M.Tan,andK.Jia. Instancesegmentationin3dscenesusingsemantic
superpoint tree networks. In Proceedings of the IEEE/CVF International Conference on
ComputerVision,pages2783–2792,2021.
[30] S.Liu,Z.Zeng,T.Ren,F.Li,H.Zhang,J.Yang,C.Li,J.Yang,H.Su,J.Zhu,etal. Grounding
dino: Marryingdinowithgroundedpre-trainingforopen-setobjectdetection. arXivpreprint
arXiv:2303.05499,2023.
11[31] S.-H.Liu,S.-Y.Yu,S.-C.Wu,H.-T.Chen,andT.-L.Liu. Learninggaussianinstancesegmenta-
tioninpointclouds. arXivpreprintarXiv:2007.09860,2020.
[32] S.Lu,H.Chang,E.P.Jing,A.Boularias,andK.Bekris. Ovir-3d: Open-vocabulary3dinstance
retrieval without training on 3d data. In Conference on Robot Learning, pages 1610–1620.
PMLR,2023.
[33] C.Ma,Y.Yuhuan,C.Ju,F.Zhang,Y.Zhang,andY.Wang. Open-vocabularysemanticsegmen-
tationviaattributedecomposition-aggregation. AdvancesinNeuralInformationProcessing
Systems,36,2024.
[34] P.D.Nguyen,T.D.Ngo,C.Gan,E.Kalogerakis,A.Tran,C.Pham,andK.Nguyen. Open3dis:
Open-vocabulary 3d instance segmentation with 2d mask guidance. In Proceedings of the
IEEE/CVFConferenceonComputerVisionandPatternRecognition,2024.
[35] S.Peng,K.Genova,C.Jiang,A.Tagliasacchi,M.Pollefeys,T.Funkhouser,etal. Openscene:
3dsceneunderstandingwithopenvocabularies. InProceedingsoftheIEEE/CVFConference
onComputerVisionandPatternRecognition,pages815–824,2023.
[36] C.Pham,T.Vu,andK.Nguyen. Lp-ovod: Open-vocabularyobjectdetectionbylinearprobing.
InProceedingsoftheIEEE/CVFWinterConferenceonApplicationsofComputerVision,pages
779–788,2024.
[37] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell,
P.Mishkin,J.Clark,etal.Learningtransferablevisualmodelsfromnaturallanguagesupervision.
InInternationalconferenceonmachinelearning,pages8748–8763.PMLR,2021.
[38] D.Rozenberszki,O.Litany,andA.Dai. Language-groundedindoor3dsemanticsegmentation
inthewild. InProceedingsoftheEuropeanConferenceonComputerVision(ECCV),2022.
[39] J. Schult, F. Engelmann, A. Hermans, O. Litany, S. Tang, and B. Leibe. Mask3D: Mask
Transformerfor3DSemanticInstanceSegmentation. InInternationalConferenceonRobotics
andAutomation(ICRA),2023.
[40] J.Straub,T.Whelan,L.Ma,Y.Chen,E.Wijmans,S.Green,J.J.Engel,R.Mur-Artal,C.Ren,
S.Verma,A.Clarkson,M.Yan,B.Budge,Y.Yan,X.Pan,J.Yon,Y.Zou,K.Leon,N.Carter,
J.Briales,T.Gillingham,E.Mueggler,L.Pesqueira,M.Savva,D.Batra,H.M.Strasdat,R.D.
Nardi,M.Goesele,S.Lovegrove,andR.Newcombe. Thereplicadataset: Adigitalreplicaof
indoorspaces,2019.
[41] J.Sun,C.Qing,J.Tan,andX.Xu. Superpointtransformerfor3dsceneinstancesegmentation.
InProceedingsoftheAAAIConferenceonArtificialIntelligence,2023.
[42] A.Takmaz,E.Fedele,R.Sumner,M.Pollefeys,F.Tombari,andF.Engelmann. Openmask3d:
Open-vocabulary 3d instance segmentation. Advances in Neural Information Processing
Systems,36,2023.
[43] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and
I.Polosukhin. Attentionisallyouneed. Advancesinneuralinformationprocessingsystems,
30,2017.
[44] V.VS,N.Yu,C.Xing,C.Qin,M.Gao,J.C.Niebles,V.M.Patel,andR.Xu. Mask-freeovis:
Open-vocabularyinstancesegmentationwithoutmanualmaskannotations. InProceedingsof
theIEEE/CVFConferenceonComputerVisionandPatternRecognition,pages23539–23549,
2023.
[45] L.Wang,Y.Liu,P.Du,Z.Ding,Y.Liao,Q.Qi,B.Chen,andS.Liu. Object-awaredistillation
pyramidforopen-vocabularyobjectdetection. InProceedingsoftheIEEE/CVFConferenceon
ComputerVisionandPatternRecognition,pages11186–11196,2023.
[46] W.Wang,R.Yu,Q.Huang,andU.Neumann. Sgpn: Similaritygroupproposalnetworkfor3d
pointcloudinstancesegmentation. InProceedingsoftheIEEEconferenceoncomputervision
andpatternrecognition,pages2569–2578,2018.
12[47] S.Xie,J.Gu,D.Guo,C.R.Qi,L.Guibas,andO.Litany. Pointcontrast: Unsupervisedpre-
trainingfor3dpointcloudunderstanding. InComputerVision–ECCV2020: 16thEuropean
Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part III 16, pages 574–591.
Springer,2020.
[48] J.Xu,S.DeMello,S.Liu,W.Byeon,T.Breuel,J.Kautz,andX.Wang. Groupvit: Semantic
segmentationemergesfromtextsupervision. InProceedingsoftheIEEE/CVFConferenceon
ComputerVisionandPatternRecognition,pages18134–18144,2022.
[49] B.Yang,J.Wang,R.Clark,Q.Hu,S.Wang,A.Markham,andN.Trigoni. Learningobject
boundingboxesfor3dinstancesegmentationonpointclouds. Advancesinneuralinformation
processingsystems,32,2019.
[50] Y.Yang,X.Wu,T.He,H.Zhao,andX.Liu. Sam3d: Segmentanythingin3dscenes,2023.
[51] L. Yao, J. Han, X. Liang, D. Xu, W. Zhang, Z. Li, and H. Xu. Detclipv2: Scalable open-
vocabulary object detection pre-training via word-region alignment. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 23497–23506,
2023.
[52] L.Yi,W.Zhao,H.Wang,M.Sung,andL.J.Guibas. Gspn: Generativeshapeproposalnetwork
for3dinstancesegmentationinpointcloud. InProceedingsoftheIEEE/CVFConferenceon
ComputerVisionandPatternRecognition,pages3947–3956,2019.
[53] Y.Zang,W.Li,K.Zhou,C.Huang,andC.C.Loy. Open-vocabularydetrwithconditional
matching. InEuropeanConferenceonComputerVision,pages106–122.Springer,2022.
[54] B.ZhangandP.Wonka. Pointcloudinstancesegmentationusingprobabilisticembeddings. In
ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition,pages
8883–8892,2021.
[55] J.Zhang,R.Dong,andK.Ma. Clip-fo3d: Learningfreeopen-world3dscenerepresentations
from2ddenseclip. InProceedingsoftheIEEE/CVFInternationalConferenceonComputer
Vision,pages2048–2059,2023.
[56] X.Zhao,W.Ding,Y.An,Y.Du,T.Yu,M.Li,M.Tang,andJ.Wang. Fastsegmentanything.
arXivpreprintarXiv:2306.12156,2023.
[57] Y.Zhao,W.Lv,S.Xu,J.Wei,G.Wang,Q.Dang,Y.Liu,andJ.Chen. Detrsbeatyoloson
real-timeobjectdetection. InProceedingsoftheIEEE/CVFConferenceonComputerVision
andPatternRecognition(CVPR),2024.
[58] Y. Zhong, J. Yang, P. Zhang, C. Li, N. Codella, L. H. Li, L. Zhou, X. Dai, L. Yuan, Y. Li,
etal. Regionclip: Region-basedlanguage-imagepretraining. InProceedingsoftheIEEE/CVF
ConferenceonComputerVisionandPatternRecognition,pages16793–16803,2022.
13