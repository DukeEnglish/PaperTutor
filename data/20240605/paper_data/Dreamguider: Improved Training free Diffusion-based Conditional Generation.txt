Dreamguider: Improved Training free Diffusion-based
Conditional Generation
NithinGopalakrishnanNair,VishalM.Patel
DepartmentofElectricalandComputerEngineering
JohnsHopkinsUniversity
Baltimore,MD,USA
{ngopala2, vpatel36}@jhu.edu
https://nithin-gk.github.io/dreamguider.github.io/
((11)) RReeaall wwoorrlldd C Coololorirzizaatitoionn (2) Real world Superresolution
(3) Style Guidance (4) Inpainting (4) Anime to Face (5) ID Guidance (5) Semantic Guidance
Figure 1: An illustration of the different applications of our method. We utilize a pretrained
diffusion model to generate images satisfying a predefined condition without backpropagation
throughthediffusionUNetoranyhand-craftedparametertuning. Wepresentresultson(1)Real-
worldcolorization,(2)Real-worldsuper-resolution,(3)Style-guidedText-to-ImageGeneration,(4)
Inpainting,(5)Sketch-to-Face,(6)FaceIDGuidance,and(7)FaceSemantics-to-Facesynthesis.
Abstract
Diffusionmodelshaveemergedasaformidabletoolfortraining-freeconditional
generation. However,akeyhurdleininference-timeguidancetechniquesisthe
needforcompute-heavybackpropagationthroughthediffusionnetworkforestimat-
ingtheguidancedirection. Moreover,thesetechniquesoftenrequirehandcrafted
parametertuningonacase-by-casebasis. Althoughsomerecentworkshaveintro-
ducedminimalcomputemethodsforlinearinverseproblems,agenericlightweight
Preprint.
4202
nuJ
4
]VC.sc[
1v94520.6042:viXraguidancesolutiontobothlinearandnon-linearguidanceproblemsisstillmissing.
Tothisend,weproposeDreamguider,amethodthatenablesinference-timeguid-
ancewithoutcompute-heavybackpropagationthroughthediffusionnetwork. The
keyideaistoregulatethegradientflowthroughatime-varyingfactor. Moreover,
we propose an empirical guidance scale that works for a wide variety of tasks,
henceremovingtheneedforhandcraftedparametertuning. Wefurtherintroduce
aneffectivelightweightaugmentationstrategythatsignificantlybooststheperfor-
manceduringinference-timeguidance.WepresentexperimentsusingDreamguider
onmultipletasksacrossmultipledatasetsandmodelstoshowtheeffectivenessof
theproposedmodules. Tofacilitatefurtherresearch,wewillmakethecodepublic
afterthereviewprocess.
1 Introduction
GenerativemodelingutilizingDenoisingDiffusionProbabilisticModels(DDPMs)[38,19,14,42]
hasmassivelyimprovedoverthepastfewyears. Multipleworkshaveextendedtheuseofdiffusion
modelsfortext-to-imagesynthesis[3,34,36],3Dsynthesis[32,22],videogeneration[18,5,45],as
wellasforconditioningtosolveinverseproblems. Moreover,likeconditionalgenerativeadversarial
networks(GANs)[15,2],DDPMscanbeadaptedtotasksbasedonalabels[34,14]orvisualprior-
basedconditioning[35]. However,likeconditionalGANs[43,33],DDPMsalsoneedtobetrained
withannotatedpairsoflabelsandinstructionstoobtainsatisfactoryresults. Thisposesalimitationin
manycaseswherethereisalackofpaireddatatotrainlargediffusionmodels. Duetothisreason,
therehasbeenrecentinterestinmodelsthatcanperformconditionalgenerationwithouttheneedfor
explicittraining[47,6,30,16].
Progressing towards this direction is prior research in plug-and-play models. First introduced in
[30],theinitialresearchonplug-and-playmodels[30,16]enabledconditionalsamplingfromGANs
trainedwithunlabeleddata. Forthis,apre-trainedclassifier[37,20]oracaptioningmodelwasused
toestimatethedeviationbetweentheGAN-generatedimageandagivenlabel,andbasedonthis
deviation,theGANinputnoisewasmodulateduntilthegeneratedsamplesatisfiedthegiventextor
classlabel. Asimilarapproachthathasbeenattemptedfordiffusionmodelstofacilitateconditional
samplingfromunconditionaldiffusionmodelsisclassifierguidance[14,16],whereanoise-robust
classifieristrainedalongwiththediffusionmodeltoguidethesamplingtowardsaparticulardirection.
However,classifierguidancebringsinthecomputationalcostsoftrainingaclassifier,whichisoften
undesirable. Somerecentworkshaveperformedconditionalgenerationwithoutexplicittrainingfor
theconditionbyutilizingtheimplicitguidancecapabilitiesofthediffusionmodel[9,47,29,4,8].
Diffusionposteriorsampling(DPS)[9]proposedatechniqueofusinganL norm-basedlossfunction
2
tosolvelinearinverseproblemsusingunconditionaldiffusionmodels. However,DPSoftenrequires
alargenumberofsamplingstepsforphotorealisticresults. Freedom[47],yetanotherwork,proposed
the use of general loss functions during sampling to achieve training-free conditional sampling.
SomevariantsofDPShavealsobeenproposedintheliterature[40]. Alltheaforementionedloss-
guided posterior sampling techniques involve a guidance function at each timestep that requires
backpropagationthroughthediffusionUNet. Recently,[17]proposedManifoldPreservingGuided
DiffusionModels(MGD)thatremovetheneedforbackpropagatingthroughthediffusionU-Netby
performingagradientdescentwithrespecttotheMinimumMeanSquareError(MMSE).Although
MGD[17]worksremarkablywellforlineartasksthatrequiremoreguidancetowardsthestartof
theguidanceprocess,itmayfailinsometaskswhereguidancehappensearlier,forexample,face
semantics-to-imageandsketch-to-image,wherestrongerguidanceisrequiredfromamuchearlier
stage. Moreover,like[47,29],MGDalsorequiresacase-by-casehandcraftedparameter. Hence,a
genericlightweightmethodthatworkswellforbothlinearandnon-linearguidancefunctionsisstill
missing. Moreover,theneedtofindahandcraftedguidanceparameteronacase-by-casebasisstill
remainsanopenchallenge.
Inthispaper,weintroduceanewframeworkthatcanadaptivelyperformzero-shotgenerationusing
diffusion models without the need for any manual intervention by the user. We found a rather
simple fix to the problem during the initial timesteps of diffusion, i.e., by utilizing the gradient
withrespecttothediffusionoutputnoiseininitialstepsofinference. Combinedwiththeguidance
withrespecttotheMMSEestimate,wefoundthatthecombinationgeneralizeswelltotasksthat
requireguidanceatveryearlystagesofguidance. Figure2presentsthevisualizationofourapproach
2Figure2: Anillustrationofthedifferencebetweentheexistingmethodandourmethod. Existing
worksbackpropagatethroughthediffusionnetworktoperformguidanceateachtimestep,whereaswe
findthegradientswithrespecttotheMMSEestimateandthepredictednoisebasedonthetimesteps,
therebybypassingtheexpensivebackpropagationoperation.
Table1: Tableillustratingthedifferenceoverexistingmethodsperforminginference-timeguidance.
Method Zerothorder LinearTasks Non-LinearTasks Automaticscaling
DPS[8] ✗ ✓ ✗ ✗
πGDM[39] ✗ ✓ ✗ ✗
Freedom[47] ✗ ✗ ✓ ✗
MGD[17] ✓ ✓ ✗ ✗
OURS ✓ ✓ ✓ ✓
overexistingworkspresentintheliterature. Utilizingthecorrectiontermalongwiththecorrection
withrespecttotheMMSEestimatesignificantlybooststheperformanceinnon-lineartasks. We
presentthecorrespondingresultsinSection5. Moreover,wetreattheenergy-basedinference-time
guidance[9,47]asastochasticgradientoptimizationoftheMMSEestimateandthenoisepresentin
theimage. Thisformulationenabledustoleveragerecentresearchinparameter-freelearning[11,21]
to develop a dynamic step size schedule. This step size adjusts itself adaptively based on the
initialnoiseseedinputofthediffusionmodelandguidancefunctions,henceremovingtheneedfor
manualparametertuningforinference-timeguidance. Moreover,motivatedbytheeffectivenessof
differentiableaugmentationswhiletrainingGANs[48],wefoundthatutilizingmultiplelevelsof
matchingdifferentiableaugmentationstotheMMSEestimateandguidancereferencesignificantly
improvesthesamplingquality,enablingveryhigh-qualitysamplingwithalownumberofguidance
steps. We present an overview of the different applications of our method in Figure 1 and an
illustrationofthedifferenceofdreamguiderwithexistingmethodsinTable1. Namely,wepresent
resultsusingStableDiffusion[34],unconditionaldiffusionmodelsreleasedby[31]for256×256
guidance,andclass-conditionaldiffusionmodelsforhigh-resolution512×512conditionalsynthesis.
ThedifferentfunctionalitiesofDreamguideraretabulatedinFigure2.
We present experiments on publicly released models on generic images, face images, and stable
diffusiontoshowtherelevanceofourmethod. Wefocusonthetasksof(1)Inpainting,(2)Super-
resolution,(3)Colorization,(4)GaussianDeblurring,(5)Semanticlabel-to-imagegeneration,(6)
Facesketch-to-image,(7)IDguidanceandidentitygeneration,andbeatexistingbenchmarksthat
utilizediffusionmodelsforthesetasks,obtainingasignificantboostinperformanceoverexisting
methodsleveragingloss-guidedmodels. Tosummarize,ourcontributionsare:
• Weproposeazeroth-orderloss-guideddiffusionguidancethatisapplicabletobothlinear
inverseproblemsandnon-linearinverseproblems.
• Weremovetheneedforamanuallytunedguidancescaleforclassifierguidancebyproposing
ascalingfunctionthatworksforawidevarietyoftasks.
• Weproposeatime-varyingguidancescaleforimprovingsamplingquality.
• Weproposeadifferentiableaugmentationstrategytoimprovesamplingquality.
2 Background
2.1 Training-freeConditionalSamplingusingDiffusionModels
Recently,therehasbeenariseinmultipleworksthatproposeutilizingunconditionaldiffusionmodels
forconditionalsampling[29,4,10,24]. Theearlierworksproposedsolvinglinearinverseproblems
usingdiffusionmodelswiththehelpofpriorsdependentontheinversetransformofdegradation.
3Recently,diffusionposteriorsampling[9]consideredthedegradationtobeconditionedonaGaussian
distributiongivenanyintermediatetimestepandderivedanL norm-basedregularizationateach
2
intermediate timestep to solve for linear inverse problems. Recent works such as Freedom [47]
exploredanenergy-basedperspectiveandextendedguidancetonon-linearfunctionsusinggeneral
lossfunctions. Universaldiffusionguidance[1]extendedthisguidanceprocesstostablediffusion
andimprovedtheperformancebyusingforward-backwardguidance. Morerecentworks,suchas
manifold-guideddiffusion[17],furtherproposedtoconstrainthemanifoldspacebyprojectingfor
thelatentspacealone.
2.2 PerturbedMarkovianKernelforDiffusionTransition
Let us assume that r(x ,y) gives a measure of the distance between an intermediate x and the
t t
conditionyandisapositiveboundedfunction. Hence,inthereverseprocess,thediffusiontrajectory
shouldproceedthroughdistributionswithahigherprobabilityofbeingclosertothedesiredcases.
Wemodelthesetrajectoryintermediatedistributionswith
pˆ(x )=p(x )r(x ,y). (1)
t t t
Dickenson et al. [38] first proposed the use of Markovian kernels to estimate the distribution of
diffusionintermediates. Specifically,giventhestatex attheequilibriumofthetrainingprocessfora
t
diffusionmodel,theintermediateofadiffusionmodelatatimeinstant,thedistributionatatimestep
t−1canbeestimatedas
(cid:90)
p(x )= p(x )p (x |x )dx . (2)
t−1 t θ t−1 t t
Asweknow,thekernelp(x |x )isaGaussiandistributionwhosemeancanbeestimatedusingthe
t−1 t
diffusionUNetandx . Toestimateaperturbedkernelpˆ(x |x ),theperturbeddistributionis
t t−1 t
(cid:90)
p(x )r(x ,y)= r(x ,y)p(x )pˆ (x |x )dx . (3)
t−1 t−1 t t θ t−1 t t
Bymergingtheconstanttermsinthetransitionintothenormalizationfactor,thetransitionstepis
pˆ (x |x )=p (x |x )r(x ,y). (4)
θ t−1 t θ t−1 t t−1
Theproofisgiveninthesupplementarymaterial. Hence,wecanseethatratherthanconsidering
aGaussianposterior,asinDPS[9],anydistanceorlossfunctioncanbeused. Similarly,oneother
validtransitionstepoftheperturbedprocessis
r(x ,y)
pˆ (x |x )=p (x |x ) t−1 , (5)
θ t−1 t θ t−1 t r(x ,y)
t
whichadoptsthenotionofreciprocaldistancefromtheprevioustimestep.
2.3 Inference-timeGuidanceofDiffusionModels
Forconditionalgenerationtasksusinganunconditionaldiffusionmodel,ideally,themodelwould
predict intermediates closer to the condition. The formulation can be seen in terms of transition
probabilities. Considerapretrainedunconditionaldiffusionmodelonaspecificdomain. Theproblem
athandneedstoguidethediffusionmodelduringinferencetimeconditionedwithaconditiony.
Dhariwaletal. [14]proposedageneralstrategytoperformthisbyconditioningontheconditiony
andfindingtheresultantmarginaldistribution
p(x |x ,y)=p(x |x )p(y|x ). (6)
t t+1 t t+1 t
Byassumingthedistributionp(y|x )hasmuchlowercurvaturecomparedtop(x |x ),considering
t t t+1
themarginaldistributionclosetox ,
t
logp(y|x )=(x −µ)∇ logp(y|x ), (7)
t t xt t
g =∇ logp(y|x ).
xt t
Pluggingbacktolog(p(x |x ,y)),
t t+1
log(p(x |x ,y))=(x−µ−Σg)TΣ−1(x−µ−Σg)+C, (8)
t t+1
p(x |x ,y)∼N(µ+Σg,Σ).
t t+1
Hence,thereversesamplingequationbecomes,
(cid:18) (cid:19)
1 1−α dr(x ,y)
x = √ x − √ t ϵ (x ) +σ ϵ+Σ t−1 ,ϵ∼N(0,I). (9)
t−1 α t 1−α¯ θ t t dx
t t t−1
42.4 ShortcomingsoftheExistingMethods
Althoughtheenergy-basedguidancetheorysupportsguidanceasafunctionofthecurrentlatent
estimate, almost all loss-based guidance techniques derive the distance function as a function of
x ratherthanx andderivethegradientbasedontheprevioussample. Althoughthisapproach
t t−1
worksformanytasks,itrequiresbackpropagatingthroughtheneuralnetworkandmodelingthescore
functionfortheguidancecorrectionterm. Thislimitstheuseofclassifierguidancesinceexisting
diffusionarchitecturesthatproducephotorealisticresultsareoftenverybulky. Onecanseewhythe
existingframeworkutilizesthederivativewithrespecttotheprevioussampleworksbytakingabetter
lookatEquation(5). Aswecansee,areciprocaldistanceovertheprevioustimestepdiffusionlatent
x isaperfectlyvaliddistanceguidancefunction. Inthenextsection,weelaborateonDreamguider.
t
3 ProposedMethod
Supposex denotesthecurrentstepandx denotesthepreviousstepintheinferenceprocessof
t−1 t
thediffusionmodule. Asmentionedintheprevioussection,existingworksutilizethederivative
withrespecttothepreviousstepforguidance;onereasonforthisistouseanoff-the-shelfauxiliary
distancefunctionontheMMSEestimateateachstepxˆ,whichenablestheuseofgeneralfunctions
t
definedonimagespaceforguidance. Here,theMMSEestimateisdefinedas
√
x − 1−α¯ ϵ (x )
xˆ = t √ t θ t , (10)
t α¯
t
whereα¯denotesthevariancescheduleofthediffusionprocessandϵ (x )isthenoiseestimatedby
θ t
thenetwork.Oneotherobservationtonoteisthatfindingthederivativewithrespecttothecurrentstep
requiresfindingxˆ ,whichagainrequiresanadditionalpropagationthroughthediffusionnetwork.
t−1
Hence,thedilemmaofbackpropagatingthroughtheUNetforguidancestillremainsunresolved.
3.1 TimeVariantClassifierGuidance
Wefoundasimpleyeteffectivesolutionforthisdilemma;ifwetakealookattheODEestimateat
eachstepproposedbySongetal. [41]. Hence,ratherthanperturbingtheGaussiankernelateach
timestep,weperturbthecomponentsxˆ andϵ (x )byasmallamount. Specifically,weperformthe
t θ t
followingoperations:
dr(xˆ ,y)
xˆ =xˆ −cΣ t ,t>t
t t dxˆ 0
t
dr(xˆ ,y)
ϵ (x )=ϵ (x )−dΣ t ,t<t
θ t θ t dϵ (x ) 0
θ t
(cid:18) (cid:19)
1 1−α dr(xˆ ,y) dr(xˆ ,y)
x = √ x − √ t ϵ (x ) +σ ϵ−c Σ t −d Σ t (11)
t−1 α t 1−α¯ θ t t t dxˆ t dϵ (x )
t t t θ t
wherer(xˆ ,y)isanonnegativedistancefunctionthatmeasuresthedistancebetweentheMMSE
t
estimateandcondition,ΣisthevarianceofthelatentestimateateachtimestepasinEquation(8).
Pleasenotethatweperformadoubledescenthere. Theintuitionbehindthedoubledescentisthat
performingdescentononeofthecomponents,sayxˆ,guideseffectivelyattheendofthediffusion
t
processwhereα isoneandviceversa. Hence,duringtheguidancewiththegradientw.r.t. xˆ,
t−1 t
themaximumcomponentofshiftthathappenstothesampleiswhenweconsidertheflowofthis
correctionthroughxˆ. Hence,wedefinethevalueasthemaximumcomponentofx presentinxˆ.
t t−1 t
√
c =c α . (12)
t t−1
Similarly,wedefined asthemaximalcomponentofϵ (x )inx . Hence,
t θ t t−1
1−α
d =−d.√ √ t . (13)
t
α 1−α¯
t t
Hence,thistermgivesefficientguidanceatalltimesteps,bypassingtheguidanceatthelatertimesteps
aloneasinMGD[17]. Inthefollowingsection,weproceedtoproposeaneffectiveempiricalestimate
forcanddthatworksforawiderangeoftasks.
53.2 AGradient-DependentScalingFactorEstimate
Recently,DistanceoverGradients(DOG)[21]wasproposedasaneffectiveparameter-freedynamic
stepsizescheduleforSGDproblems. GivenanyStochasticGradientDescent(SGD)optimization
problem,theDistanceoverGradientworksasaneffectivelearningrate. Recentworks[46]have
foundthediffusionprocessasastochasticoptimizationproblemandhavederivedanSGD-based
interpretationofthediffusionsamplingprocess.Hence,inspiredbybothoftheseworks,weattempted
anempiricalguidanceestimateoftheform:
 √1e−5, ift=T

γ
t
=

mag x√T2
i>t|fi−fT|, otherwise
(14)
ΣT g2
i=i t
whereg isthegradientofthelossfunctionasdefinedintheequation,f canbeanyofxˆ,x ,ϵ (t)
t t t t θ
attimesteptandf istheinitialestimateoff . Wenoticedthatthisempiricalestimateworkswell
0 t
forthefirst-ordersamplinginvolvingDPS[9]aswell. Weillustratemoreresultsontheeffectofthis
plug-invaluefordifferentcasesintheappendix. Hence,utilizingEquation(14),weestimatecandd
accordinglybysubstitutingf asxˆ andϵ (x )
i t θ t
3.3 DifferentialAugmentationClassifierGuidance
Acommonpracticewhileperformingclassifierguidancetoaugmentdiffusionmodelswithspecific
regularizationforguidanceistousethenoisyestimateattimesteptandutilizeittocomputethe
loss function to regularize the current prediction. However, in many cases, such guidance can
giveresultswithartifactsandcolorshifts,asportrayedinFigure3andFigure5,duetoexcessive
guidance or insufficient guidance at intermediate timesteps that shift the results off manifold or
cause color shifts. One effective solution for this is to imitate different versions of artifacts or
color shifts on both the source image and the target image and utilize these augmented versions
foraboostinperformance. Hence,toperformguidancewithamuchmorerobustguidanceloss,
weintroduceDiffuseAugment, anaugmentationstrategyfordiffusionguidanceduringinference
time. Specifically, given an intermediate sample x and condition y, we augment xˆ and y with
t t
differentiableaugmentationsdenotedby
xˆaug,yaug =T(xˆaug,yaug). (15)
t t
WechoosethreedifferenttypesofaugmentationsforT comprisingrandomcutouts,randomtrans-
lations, and color saturations. Please note that the augmentation of y is dependent on the input
signal. Forlabel-basedconditioningsuchasidentityortext,wedonotperformaugmentationfor
y. Forimagespaceaugmentations,weaugmenty withthesamerandomaugmentationasthatof
x. Whilecomputingtheeffectiveloss,wefindtheaverageacrossallaugmentations. Wefindthat
DiffuseAugmentsignificantlybooststhesamplingfidelityandqualityofthereconstructedimage.
WepresenttheseresultsinSection5.
4 Experiments
Sinceourmethodcomprisesbothlinearandnon-linearinversetasks,forlinearinversetasks,we
followDPSandevaluateourmethodutilizingtwodifferentbenchmarks: (1)ImageNet[12]and
(2)CelebA[26]. Fornon-lineartasks,wefollowFreedomandevaluateusingtheCelebAdataset.
For linear tasks, we evaluate our method quantitatively for Super-resolution (×4), Colorization,
Inpainting(Box),andGaussiandeblurringtasks. Fornon-lineartasks,weevaluateforFaceSketch
guidance,FaceParsemapsguidance,andFaceIDguidance. Sinceourmethodfallsintothecategory
of loss-guided diffusion models, we perform all quantitative evaluations using existing methods
thatfollowthiskindofsampling. Pleasenotethatalthoughweacknowledgetheparallelfieldof
researchintacklinginverseproblemswithoutbackpropagation[44,25],weexcludedthesemethods
forcomparisonastheytacklesolelyLinearinverseproblems. Incontrast,loss-guidedmodelsare
genericandapplicabletoawiderrangeofproblems.
4.1 ImplementationDetails
WeperformallexperimentsonNVIDIAA6000GPUs. ForImageNet[12]basedtasks,weutilize
theunconditionalmodelreleasedbyGuidedDiffusion. ForLinearTasksinvolvingfaces,weusethe
6GaussianDeblurring Colorization Inpainting
Figure3: QualitativecomparisonsforLinearTasksonImageNetfor100inferencesteps
GaussianDeblurring Colorization Inpainting
Figure4: QualitativecomparisonsforLinearTasksonCelebAdatasetfor100inferencesteps
modeltrainedontheFFHQdataset[23]andperformexperimentsontheCelebAdataset[26]similar
toDPS.Fornon-lineartasks,wefollowFreedomandutilizethemodeltrainedunconditionallyonthe
CelebAdataset.Weevaluateusingconditionsderivedfromexistingnetworks.Forthehigh-resolution
resultspresentedinFigure2,weutilizedtheclass-conditionalmodelofresolution512×512released
byGuidedDiffusion. Forallexperiments,weused100samplingsteps. Forstyletransfer,weutilized
StableDiffusion[34]v1.5. Pleasenotethatoursamplingmethodisgeneric,andanysamplercanbe
used. WefixthenumberofaugmentationsinDiffuseAugmentforalltheexperimentsto8. Forlinear
inverseproblemswesetthevalueoft to5inEquation(11)to30andforlinearinverseproblemswe
0
sett to5
0
4.2 QualitativeAnalysis
We present results on Gaussian Deblurring, super-resolution, and colorization. As we can see,
DPSfailssince100stepsofdiffusionareused,andtheDPSscalingfactorisnotstrongenoughto
performproperguidancewithin100stepsofdiffusion. Wesettheamountofposteriornoisefor
themeasurementas0.05inallexperiments. MGDworksremarkablywellforthedeblurringand
inpaintingtasks;however,itfailsforcolorizationsinceearlyguidanceisrequiredfortheflowof
naturalcolors.
ForImageNettasks,theperformanceofDPSfallsmorebecausetheproblemismoreill-posed. This
canbeseenintheeaglediagram,wherethemethodisunabletoreconstructtheeagleproperly. In
7
dedargeD
]9[SPD
]71[DGM
SRUO
dedargeD
]9[SPD
]71[DGM
SRUOInpaint(Box) Colorization SR(×4) GaussianDeblur
Method PSNR↑SSIM↑LPIPS↓FID↓Cons↑SSIM↑LPIPS↓FID↓PSNR↑SSIM↑LPIPS↓FID↓PSNR↑SSIM↑LPIPS↓FID↓
Score-SDE[42] 9.57 0.329 0.634 94.330.1627 0.3996 0.6609118.86 20.75 0.5844 0.3851 53.22 23.39 0.632 0.361 66.81
ILVR[42] - - - - - - - - 26.14 0.7403 0.2776 52.82 - - - -
DPS[8] 19.39 0.610 0.3766 58.890.0069 0.5404 0.5594 55.61 17.36 0.4969 0.4613 56.08 20.52 0.5824 0.3756 52.64
MGD[8] 27.21 0.7460 0.2197 11.830.0018 0.6865 0.4549 38.22 27.51 0.7852 0.2464 60.21 27.23 0.7695 0.2327 51.59
Ours 28.84 0.8491 0.1432 5.96 0.0014 0.7775 0.3036 20.89 29.47 0.8429 0.1757 46.95 27.30 0.7672 0.2202 42.70
Table2: QuantitativeevaluationofimagerestorationtasksonCelebA256×256-1kwithσ =0.05,
y
Weutilize100inferencestepsforallmethods
Inpaint(Box) Colorization SR(×4) GaussianDeblur
Method PSNR↑SSIM↑LPIPS↓FID↓Cons↑SSIM↑LPIPS↓FID↓PSNR↑SSIM↑LPIPS↓FID↓PSNR↑SSIM↑LPIPS↓FID↓
Score-SDE[42] 9.66 0.2087 0.7375133.540.17230.3105 0.8197194.87 14.07 0.2468 0.6766129.91 15.39 0.3158 0.620 134.67
ILVR[42] - - - - - - - - 15.51 0.4033 0.5253 64.13 - - - -
DPS[8] 15.23 0.4261 0.6087 97.90 0.021 0.3774 0.8011106.25 14.94 0.3258 0.6594 87.26 17.19 0.3980 0.5817 84.74
MGD[8] 21.94 0.6920 0.2410 40.300.00570.5809 0.5427 73.75 23.12 0.6025 0.3936 70.83 23.13 0.6092 0.3695 61.49
Ours 23.49 0.7271 0.2001 30.720.00550.6804 0.3362 52.76 24.23 0.6818 0.2884 43.00 23.31 0.6157 0.3566 58.38
Table3: QuantitativeevaluationofimagerestorationtasksonImageNet256×256-1kwith
σ =0.05. Bold: best,Weutilize100inferencestepsforallmethods
y
Face-sketchguidance Face-parseguidance IDguidance
Figure5: QualitativecomparisonsforNon-linearTasksonCelebAdatasetfor100inferencesteps
contrast,ourmethodperformsrelativelybetter,producingmuchmorerealisticimages. Wehighlight
theperformanceimprovementoncolorizationsincewearguethattheseresultsareobtainedbecause
oftheearlyflowofgradients. Fornonlinearinvereproblems,aswecansee,Freedomisableto
producerealistic-lookingresultsforeventhedifficulttaskofParseMapstoFaces. Wearguethatthis
isbecausebackpropagationthroughtheUNetpurifiesthegradientflow;hence,thegeneratedimages
lookmuchmorenaturalistic.
4.3 QuantitativeAnalysis
WeutilizeDreamguiderandquantitativelyevaluateCelebAandImageNetdatasets. Theresultsfor
facerestorationtasksareshowninTable2andTable3.Weevaluatethesetasksutilizingfourdifferent
metrics. SDEdit[28]failsforthetaskoffaceinpaintingandcolorizationasasingleperturbation
in the noisy domain throws the image off the manifold. DPS requires more inference steps for
properguidance. ILVRisoriginallydesignedforsuper-resolution. Hence,wequantitativelyevaluate
ILVR[7]onlyforthetaskofsuper-resolution. SinceDPSandMGDareapplicabletoallcases,we
evaluatewiththesemethods. Aswecansee,ourapproachobtainsbetterresultsthanthebaselines
because of the flow of gradients, which allows for better reconstruction quality. For faces, the
differenceismuchmorehighlightedinthetaskofcolorization,wherewegetasignificantboostof18
FIDscoreabovethebaseline. GenerallinearinverseproblemsinImageNetaremuchmorecomplex
thaninfaces;hence,thereisanoveralldropinmetricsforthenaturaldomainimagesinImageNet. In
ourcase,DiffAugmentpurifiesthegradient;hence,welookformuchbetterrealistic-lookingimages.
However,MGDdoesnotproducerealisticresultsforsketch-to-imageandanime-to-facesynthesis.
8
dedargeD
DGM
modeerF
SRUOSemanticParsing IDGuidance FaceSketch
Method Distance↓ LPIPS↓ FID↓ Distance↓ LPIPS↓ FID↓ Distance↓ LPIPS↓ FID↓
First-order
Freedom[47] 1864.51 0.6030 66.89 0.3767 0.7058 81.40 39.05 0.6583 86.51
Zeroth-order
MGD[17] 2698.27 0.6995 104.32 0.4291 0.7178 92.61 39.34 0.6576 70.42
Ours 2722.51 0.6199 79.42 0.3780 0.5932 82.70 39.03 0.5509 69.51
Table4: Non-lineartasks. Bestresultsoutofzeroth-orderoptimizationalgorithmsarehighlighted.
Augmentations vs LPIPS (Linear) Augmentations vs LPIPS (Non Linear)
0.60 T=20 0.68 T=20
0.55 T T= =5 70 5 0.66 T T= =5 70 5
0.50 T=100 0.64 T=100
0.45 0.62
0.40 0.60
0.35 0.58
0.56
0.30 0.54
1 2 4 8 1 2 4 8
Augmentations Augmentations
Figure6: Ablationanalysisonlinearandnon-lineartasks. FaceIDguidance&ImageNetsuperresolu-
tion
5 AblationStudies
WeperformextensiveablationstudieswithrespecttotheeffectofDiffuseAugmentaswellasthe
effectofeachguidanceterm. Fortheablationexperiments,ratherthanutilizingthewholetesting
datasetof1000images,weutilize100imagesandreporttheaverageLPIPSvalue.
5.1 EffectofDiffuseAugment
We notice that for linear tasks, even for low values of T such as T = 20, just by increasing the
numberofaugmentationsattheoutputto8,theperceptualqualitydrasticallyimproves,matching
thatofdiffusioninferencewithT =50withjust2augmentations. Further,wenoticethatalthough
theeffectofaugmentationsisverysignificantforlineartasks,theperformanceisnotthatsignificant
orratherdropsinsomecasesforlowT suchasT =20;thisisbecausewith20diffusionsteps,most
intermediateMMSEestimatesremainnoisy,andhencetheguidancenetworkArcFace[13]cannot
handlesuchinputandhencereturnsirregulargradientsaffectingthequality. However,wecansee
thatasT increasesandwhenthereareenoughgradientsteps,DiffuseAugmentplaysasignificant
roleinboostingtheperformance.
5.2 EffectofDifferentComponentsofGuidance
WepresenttheablationanalysisoftheeffectofdifferenttermsofguidanceinFigure6. Pleasenote
thatforthisexperiment,wesetthenumberofaugmentationsfromDiffuseAugmentas1. Wealso
turnofftimetravelsamplingforthisexperiment. Forthisexperiment,weperformguidancewith
respecttoϵ (t)untilt andperformguidancewithrespecttoxˆ fort>t . Heret=100represents
θ 0 t 0
puregaussiannoiseandt = 0representstheimage. Aswecansee,guidancewithxˆ alonefaces
t
adropinperformanceinitiallyforalownumberofinferencestepsfornonlinearcases. Weargue
thatthisisbecausetheguidanceflowthroughtheMMSEestimateisweakduringtheearliersteps
ofdiffusion. Althoughtimetravelsamplinghelpstoalleviatethisissue,carefulparametertuningis
requiredtoobtainsatisfactoryresults. Wealsonoticethatguidingutilizingthegradientsoftheoutput
noiseofthenetworkclosertothestartofthegenerationprocessproducesbetterresults.
6 LimitationsandFutureWorks
Althoughweillustratedtheworkingacrossvarioustasksforpixelspacediffusionmodels,thedirect
approach cannot be used for latent diffusion models for the task of linear inverse problems, and
one might have to apply multiple steps of time travel sampling to fix this issue, making a large
computationaloverheadoftheoverallsamplingtime. Weemphasizethatthisproblemarisesdueto
thereconstructionerrorintheVAEthatencodestheimagetothelatentspace. Inthefuture,wewill
attempttoimproveuponthiswithbetteroptimizationtechniques. Moreover,althoughtheproposed
empiricalestimatebasedondistanceovergradientsworksformosttasksandshowstheexistenceof
9
SPIPL SPIPLanoptimalparameterestimate,athoroughmathematicalevaluationandthemostoptimalparameters
arestillmissing.Weleavethisproblemuptofutureworkstoestimatetheoptimalguidanceparameter.
7 Conclusion
Inthispaper,weproposedanimprovementtoexistingloss-guidedtechniquesforzero-shotconditional
generationwithanunconditionaldiffusionmodel. Specifically,weproposedasamplingtechnique
thatremovestheneedtobackpropagatethroughthediffusionU-Netinordertotacklesamplingfor
generalinverseproblems. Wealsopresentanempiricalfunctionforautomaticscalingparameters
thatremovestheneedformanualscalingparametertuning, whichwaspreviouslyahugehurdle
in using classifier-free guidance. The newly proposed scaling parameter also removes the need
formodel-specifictuningofstartandendguidancesteps. Wealsointroducedadifferentiabledata
augmentationmethodthatsignificantlyimprovesthesamplingfidelity. Weillustratedtheworkingof
ourmethodacross4linearand3non-lineartasksacrossfacesandrealimagedomains. Oursampling
techniqueproducesphotorealisticsampleswithmuchlowersamplingtimeandhigherfidelitythan
existingmethods.
References
[1] Aggarwal,H.K.,Mani,M.P.,Jacob,M.: MoDL:Model-baseddeeplearningarchitecturefor
inverseproblems.IEEEtransactionsonmedicalimaging38(2),394–405(2018)
[2] Arjovsky,M.,Chintala,S.,Bottou,L.: Wassersteingenerativeadversarialnetworks.In: Interna-
tionalconferenceonmachinelearning.pp.214–223.PMLR(2017)
[3] Balaji, Y., Nah, S., Huang, X., Vahdat, A., Song, J., Kreis, K., Aittala, M., Aila, T., Laine,
S., Catanzaro, B., etal.: ediffi: Text-to-imagediffusionmodelswithanensembleofexpert
denoisers.arXivpreprintarXiv:2211.01324(2022)
[4] Bansal,A.,Chu,H.M.,Schwarzschild,A.,Sengupta,S.,Goldblum,M.,Geiping,J.,Goldstein,
T.: Universalguidancefordiffusionmodels.arXivpreprintarXiv:2302.07121(2023)
[5] Blattmann,A.,Rombach,R.,Ling,H.,Dockhorn,T.,Kim,S.W.,Fidler,S.,Kreis,K.: Align
yourlatents: High-resolutionvideosynthesiswithlatentdiffusionmodels.In: Proceedingsof
theIEEE/CVFConferenceonComputerVisionandPatternRecognition.pp.22563–22575
(2023)
[6] Chan,S.H.,Wang,X.,Elgendy,O.A.: Plug-and-playadmmforimagerestoration: Fixed-point
convergenceandapplications.IEEETransactionsonComputationalImaging3(1),84–98(2016)
[7] Choi, J., Kim, S., Jeong, Y., Gwon, Y., Yoon, S.: Ilvr: Conditioning method for denoising
diffusionprobabilisticmodels.arXivpreprintarXiv:2108.02938(2021)
[8] Chung,H.,Kim,J.,Mccann,M.T.,Klasky,M.L.,Ye,J.C.: Diffusionposteriorsamplingfor
general noisy inverse problems. In: International Conference on Learning Representations
(2023),https://openreview.net/forum?id=OnD9zGAGT0k
[9] Chung, H., Ryu, D., Mccann, M.T., Klasky, M.L., Ye, J.C.: Solving 3d inverse problems
usingpre-trained2ddiffusionmodels.IEEE/CVFConferenceonComputerVisionandPattern
Recognition(2023)
[10] Chung, H., Ye, J.C., Milanfar, P., Delbracio, M.: Prompt-tuninglatentdiffusionmodelsfor
inverseproblems.ArXivabs/2310.01110(2023)
[11] Defazio, A., Mishchenko, K.: Learning-rate-free learning by d-adaptation. arXiv preprint
arXiv:2301.07733(2023)
[12] Deng,J.,Dong,W.,Socher,R.,Li,L.J.,Li,K.,Fei-Fei,L.: Imagenet: Alarge-scalehierarchical
image database. In: 2009 IEEE conference on computer vision and pattern recognition. pp.
248–255.Ieee(2009)
[13] Deng,J.,Guo,J.,Xue,N.,Zafeiriou,S.: Arcface: Additiveangularmarginlossfordeepface
recognition. In: Proceedings of the IEEE/CVF conference on computer vision and pattern
recognition.pp.4690–4699(2019)
[14] Dhariwal,P.,Nichol,A.: Diffusionmodelsbeatgansonimagesynthesis.AdvancesinNeural
InformationProcessingSystems34(2021)
10[15] Goodfellow,I.,Pouget-Abadie,J.,Mirza,M.,Xu,B.,Warde-Farley,D.,Ozair,S.,Courville,A.,
Bengio,Y.: Generativeadversarialnetworks.CommunicationsoftheACM63(11),139–144
(2020)
[16] Graikos,A.,Malkin,N.,Jojic,N.,Samaras,D.:Diffusionmodelsasplug-and-playpriors.arXiv
preprintarXiv:2206.09012(2022)
[17] He, Y., Murata, N., Lai, C.H., Takida, Y., Uesaka, T., Kim, D., Liao, W.H., Mitsufuji, Y.,
Kolter, J.Z., Salakhutdinov, R., etal.: Manifoldpreservingguideddiffusion.arXivpreprint
arXiv:2311.16424(2023)
[18] Ho, J., Chan, W., Saharia, C., Whang, J., Gao, R., Gritsenko, A., Kingma, D.P., Poole, B.,
Norouzi,M.,Fleet,D.J.,etal.: Imagenvideo: Highdefinitionvideogenerationwithdiffusion
models.arXivpreprintarXiv:2210.02303(2022)
[19] Ho, J., Jain, A., Abbeel, P.: Denoising diffusion probabilistic models. Advances in Neural
InformationProcessingSystems33,6840–6851(2020)
[20] Hossain,M.Z.,Sohel,F.,Shiratuddin,M.F.,Laga,H.: Acomprehensivesurveyofdeeplearning
forimagecaptioning.ACMComputingSurveys(CsUR)51(6),1–36(2019)
[21] Ivgi,M.,Hinder,O.,Carmon,Y.: Dogissgd’sbestfriend: Aparameter-freedynamicstepsize
schedule.arXivpreprintarXiv:2302.12022(2023)
[22] Jun, H., Nichol, A.: Shap-e: Generating conditional 3d implicit functions. arXiv preprint
arXiv:2305.02463(2023)
[23] Karras,T.,Aila,T.,Laine,S.,Lehtinen,J.: ProgressivegrowingofGANsforimprovedquality,
stability,andvariation.arXivpreprintarXiv:1710.10196(2017)
[24] Kawar,B.,Elad,M.,Ermon,S.,Song,J.:Denoisingdiffusionrestorationmodels.arXivpreprint
arXiv:2201.11793(2022)
[25] Kawar,B.,Vaksman,G.,Elad,M.: Stochasticimagedenoisingbysamplingfromtheposterior
distribution.In: ProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision
(ICCV)Workshops.pp.1866–1875(October2021)
[26] Liu,Z.,Luo,P.,Wang,X.,Tang,X.: Deeplearningfaceattributesinthewild.In: Proceedings
ofInternationalConferenceonComputerVision(ICCV)(December2015)
[27] Lugmayr,A.,Danelljan,M.,Romero,A.,Yu,F.,Timofte,R.,VanGool,L.: Repaint: Inpainting
usingdenoisingdiffusionprobabilisticmodels.In: ProceedingsoftheIEEE/CVFConference
onComputerVisionandPatternRecognition.pp.11461–11471(2022)
[28] Meng,C.,Song,Y.,Song,J.,Wu,J.,Zhu,J.Y.,Ermon,S.: SDEdit: Imagesynthesisandediting
withstochasticdifferentialequations.arXivpreprintarXiv:2108.01073(2021)
[29] Nair, N.G., Cherian, A., Lohit, S., Wang, Y., Koike-Akino, T., Patel, V.M., Marks, T.K.:
Steereddiffusion: Ageneralizedframeworkforplug-and-playconditionalimagesynthesis.In:
ProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision.pp.20850–20860
(2023)
[30] Nguyen, A., Clune, J., Bengio, Y., Dosovitskiy, A., Yosinski, J.: Plug & play generative
networks: Conditionaliterativegenerationofimagesinlatentspace.In: Proceedingsofthe
IEEEconferenceoncomputervisionandpatternrecognition.pp.4467–4477(2017)
[31] Nichol,A.Q.,Dhariwal,P.: Improveddenoisingdiffusionprobabilisticmodels.In: International
ConferenceonMachineLearning.pp.8162–8171.PMLR(2021)
[32] Poole,B.,Jain,A.,Barron,J.T.,Mildenhall,B.: Dreamfusion: Text-to-3dusing2ddiffusion.
arXiv(2022)
[33] Radford,A.,Metz,L.,Chintala,S.: Unsupervisedrepresentationlearningwithdeepconvolu-
tionalgenerativeadversarialnetworks.arXivpreprintarXiv:1511.06434(2015)
[34] Rombach,R.,Blattmann,A.,Lorenz,D.,Esser,P.,Ommer,B.:High-resolutionimagesynthesis
withlatentdiffusionmodels(2021)
[35] Saharia,C.,Chan,W.,Chang,H.,Lee,C.,Ho,J.,Salimans,T.,Fleet,D.,Norouzi,M.: Palette:
Image-to-imagediffusionmodels.In: ACMSIGGRAPH2022ConferenceProceedings.pp.
1–10(2022)
11[36] Saharia,C.,Ho,J.,Chan,W.,Salimans,T.,Fleet,D.J.,Norouzi,M.: Imagesuper-resolutionvia
iterativerefinement.IEEETransactionsonPatternAnalysisandMachineIntelligence(2022)
[37] Simonyan,K.,Zisserman,A.: Verydeepconvolutionalnetworksforlarge-scaleimagerecogni-
tion.arXivpreprintarXiv:1409.1556(2014)
[38] Sohl-Dickstein,J.,Weiss,E.,Maheswaranathan,N.,Ganguli,S.: Deepunsupervisedlearning
usingnonequilibriumthermodynamics.In: InternationalConferenceonMachineLearning.pp.
2256–2265.PMLR(2015)
[39] Song,J.,Vahdat,A.,Mardani,M.,Kautz,J.: Pseudoinverse-guideddiffusionmodelsforinverse
problems.In: InternationalConferenceonLearningRepresentations(2022)
[40] Song,J.,Zhang,Q.,Yin,H.,Mardani,M.,Liu,M.Y.,Kautz,J.,Chen,Y.,Vahdat,A.: Loss-
guideddiffusionmodelsforplug-and-playcontrollablegeneration.In: InternationalConference
onMachineLearning.pp.32483–32498.PMLR(2023)
[41] Song, Y., Durkan, C., Murray, I., Ermon, S.: Maximum likelihood training of score-based
diffusionmodels.AdvancesinNeuralInformationProcessingSystems34(2021)
[42] Song,Y.,Sohl-Dickstein,J.,Kingma,D.P.,Kumar,A.,Ermon,S.,Poole,B.:Score-basedgenera-
tivemodelingthroughstochasticdifferentialequations.In:InternationalConferenceonLearning
Representations(2021),https://openreview.net/forum?id=PxTIG12RRHS
[43] Wang, T.C., Liu, M.Y., Zhu, J.Y., Tao, A., Kautz, J., Catanzaro, B.: High-resolution image
synthesis and semantic manipulation with conditional gans. In: Proceedings of the IEEE
conferenceoncomputervisionandpatternrecognition.pp.8798–8807(2018)
[44] Wang,Y.,Yu,J.,Zhang,J.: Zero-shotimagerestorationusingdenoisingdiffusionnull-space
model.In:TheEleventhInternationalConferenceonLearningRepresentations(2023),https:
//openreview.net/forum?id=mRieQgMtNTQ
[45] Wu,J.Z.,Ge,Y.,Wang,X.,Lei,S.W.,Gu,Y.,Shi,Y.,Hsu,W.,Shan,Y.,Qie,X.,Shou,M.Z.:
Tune-a-video: One-shot tuning of image diffusion models for text-to-video generation. In:
ProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision.pp.7623–7633
(2023)
[46] Wu, Z., Zhou, P., Kawaguchi, K., Zhang, H.: Fast diffusion model. arXiv preprint
arXiv:2306.06991(2023)
[47] Yu, J., Wang, Y., Zhao, C., Ghanem, B., Zhang, J.: Freedom: Training-free energy-guided
conditionaldiffusionmodel.arXivpreprintarXiv:2303.09833(2023)
[48] Zhao,S.,Liu,Z.,Lin,J.,Zhu,J.Y.,Han,S.: Differentiableaugmentationfordata-efficientgan
training.Advancesinneuralinformationprocessingsystems33,7559–7570(2020)
128 AlgorithmofDreamguider
We present the over algorithm of dreamguider without time travel sampling and the parameter
estimationalgorithminAlgorithm1
Algorithm1Dreamguider
Input: distancefunctionr(,.y),conditiony,TimestepsT
1: x T ∼N(x T;0,I)
2: fort=T √−1,...,1do
3: Σ= 1−α¯ t
4: ϵ∼N(ϵ;0,I)
√
5: xˆ t = xt− 1 √− αα¯ ¯ttϵθ(xt)
6: Compute dr(xˆt,y), dr(xˆt,y)
dxˆt dϵθ(xt)
7: updatec=ESTIMATE(t,ϵ θ(x t),d dr ϵ( θxˆ (t x, ty )))
8: update √d=ESTIMATE(t,xˆ t,dr( dxˆ xˆt t,y))
9: c t =c α t−1
10: d t =−d.√ α1 t(cid:16)−√α 1−t α¯t
(cid:17)
11: x t−1 = √1 αt x t− √1 1− −α αt ¯tϵ θ(x t) +σ tϵ−c tΣdr( dxˆ xˆt t,y) −d tΣd dr ϵ( θxˆ (t x, ty ))
12: endfor
13: functionESTIMATE(t,f i,g t)
14: ift=T then
15: γ t = √1e−5
g2
T
16: Storef T,
17: else
18: γ t = max√i>t|fi−fT|
ΣT g2
i=i t
19: endif
(cid:112)
20: Store ΣT g2
i=i t
21: returnγ t
22: endfunctionreturnx 0
9 ProofforperturbedMarkoviankernelequation
Inthemainpaper,weemphasizedthatanypositivedistancefunctioncanbeutilizedforperforming
conditionalgenerationusingtheperturbedMarkoviankernelequation. hHreweproceedtoderive
theperturbedtransitionstep. FortheproofwecloselyfollowtheworkfromDickensonetal[38].
Givenaunconditionaltransitiondistributionp (x |x )andadistancefunctionr(.,y),whereyis
θ t−1 t
theconditionprovidedPleasenotethatweassumer(.,y)hasrelativelysmallvariancecomparedto
p (x |x ),Weknowthatatequilibriumstate,thedistributionatanytimesteptinadiffusionmodel
θ t−1 t
canbewrittenas
(cid:90)
p(x )= p(x )p (x |x )dx . (16)
t−1 t θ t−1 t t
Toestimateaperturbedtransitionkernelpˆ(x |x ),westarttheperturbeddistributionas
t−1 t
(cid:90)
p(x )r(x ,y)= r(x ,y)p(x )pˆ (x |x )dx . (17)
t−1 t−1 t t θ t−1 t t
Bysimplealgebraicmanipulations,takingr(x ,y)totheotherside,weget
t−1
(cid:90) r(x ,y)
p(x )= t p(x )pˆ (x |x )dx . (18)
t−1 r(x ,y) t θ t−1 t t
t−1
13By comparing Equation (16) and Equation (18) we can see that one solution for the transitional
distributionis
r(x ,y)
pˆ (x |x )=p (x |x ) t−1 . (19)
θ t−1 t θ t−1 t r(x ,y)
t
Alsosincenormalizationconstantsdoesn’taffectthescorefunctionortransitionstep,Absorbingx
t
tothenormalizationfactorofp (x |x ),anothervalidperturbedtransitionkernelis
θ t−1 t
r(x ,y)
pˆ (x |x )=p (x |x ) t−1 . (20)
θ t−1 t θ t−1 t Z
PleasenotethatthetermZ doesnotaffectthetransitionstepinthereverseprocesswhenthevariance
ofr(.,y)issmall.
(a)FaceColorization (b)FaceSuperresolution(x4)
c=1.11,d=99.30 c=2.88,d=202.39
(c)FaceInpainting (d)GaussianDeblur
c=0.63,d=45.85 c=0.60,d=74.09
(e)SketchtoFace (f)FaceIDGuidance
c=0.28,d=3.85 c=33.10,d=593.15
(g)ParsemapstoFace
c=0.001,d=0.13
Figure7: Figureillustratingtheguidancescalesfordifferenttasks.
Method Freedom Dreamguider(1) Dreamguider(2) Dreamguider(3)
SketchtoFace 24.95 17.55 27.04 35.09
FaceIDtoFace 24.94 20.45 31.89 41.80
FaceParsetoFace 56.25 48.35 75.43 107.02
Table5: Non-lineartasksablationanalysisontimetaken,thevalueisrepresentedinseconds
1410 TimecomparisonforDreamguiderwithtimetravelsamplingand
Freedom(Firstorder)fornonlineartasks
WepresentthetimetakenbyFreedom,afirstorderalgorithmforonestepoftimetravelsampling
[27,47]inTable5
11 Estimatedparametervaluefordifferenttasks
Inthissection,wepresenttheresultandtheparameterestimatedbyourapproachfordifferenttasks.
Forthisexperiment,weuse100timestepsofdiffusionandpresentthevalueatthe100thtimestep.
Herewedefinedasthescalingfactorofthescalingconstantofthethelossderivativerelativeto
ϵ (x )andcasthatofxˆ asinthemainpaper. ThecorrespondingresultsareshowninFigure7
θ t t
12 Noncherrypickedresultsfordifferenttasks.
15Figure8: FigureillustratingNoncherrypickedresultsforImageNetcolorization
16Figure9: FigureillustratingNoncherrypickedresultsforImageNetsuperresolution
17Figure10: FigureillustratingNoncherrypickedresultsforGaussiandeblurringonImageNet
18Figure11: FigureillustratingNoncherrypickedresultsforfacecolorization
19Figure12: FigureillustratingNoncherrypickedresultsforfacesuperresolution
20Figure13: FigureillustratingNoncherrypickedresultsforGaussianDeblurring
21Figure14: FigureillustratingNoncherrypickedresultsforfaceinpainting
22Figure15: FigureillustratingNoncherrypickedresultsforsketchtofacesynthesis
23Figure16: FigureillustratingNoncherrypickedresultsforFaceIDguidance
24Figure17: FigureillustratingNoncherrypickedresultsforFaceParseGuidance
25