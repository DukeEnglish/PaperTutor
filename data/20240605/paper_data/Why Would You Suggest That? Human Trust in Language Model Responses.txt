Why Would You Suggest That? Human Trust in Language Model Responses
ManasiSharma1 HoChitSiu1 RohanPaleja1 JaimeD.Peña1
Abstract calibrated to avoid overtrust or distrust, the catalysts for
overrelianceandunderuseofsystems(LeeandSee,2004).
The emergence of Large Language Models
Mayeretal. arguethattrustworthinessisaffectedbythe
(LLMs)hasrevealedagrowingneedforhuman-
trustee’sperceivedpropertiesofability,benevolence,and
AIcollaboration,especiallyincreativedecision-
integrity(Mayeretal.,1995).
making scenarios where trust and reliance are
paramount. Through human studies and model Wetargettheuserpersonalizationsetting(LaMPBenchmark
evaluations on the open-ended News Headline (Salemietal.,2024)forlanguagemodelpersonalization)
GenerationtaskfromtheLaMPbenchmark,we duetoitsselectionofopen-endedtextgenerationtasksand
analyzehowtheframingandpresenceofexpla- investigatehowdistinctphrasingsoffree-formmodeljusti-
nationsaffectusertrustandmodelperformance. ficationsofresponsescanaffectusertrust. Werunhuman
Overall,weprovideevidencethataddinganex- studiesthatgatherpreferencesregardinganarrayofdiffer-
planationinthemodelresponsetojustifyitsrea- entmodelresponses,withvaryingdegreesofinsightinto
soningsignificantlyincreasesself-reporteduser theirdecision-makingprocess,andalsoevaluatethemodel
trust in the model when the user has the oppor- performanceonthetask,includingthesejustifications,in
tunity to compare various responses. Position ordertoanalyzeanytradeoffsthatmayoccurbetweentrust
andfaithfulnessoftheseexplanationsarealsoim- andperformance.
portantfactors. However,thesegainsdisappear
Weexaminethefollowingresearchquestions:
when users are shown responses independently,
RQ1 To what extent do the presence and framing of an
suggestingthathumanstrustallmodelresponses,
explanationofamodelrecommendationimpactusertrust?
includingdeceptiveones,equitablywhentheyare
RQ2 To what extent does the truthfulness of the model
showninisolation. Ourfindingsurgefuturere-
explanationofamodelrecommendationimpactusertrust?
searchtodelvedeeperintothenuancedevaluation
RQ3Arethereanytradeoffsbetweentypesofexplanations
oftrustinhuman-machineteamingsystems.
thatmaximizeusertrustandmodelperformance?
1.Introduction 2.RelatedWorks
TheadventofLargeLanguageModels(LLMs)marksasig- Thereexistsmuchliteraturethatdescribesandevaluatesthe
nificantmilestoneintherealmofartificialintelligence,rev- perceived“trustworthiness”oflanguagemodels(Sunetal.,
olutionizingnaturallanguageprocessing(NLP)bydemon- 2024;Wangetal.,2024a). However,theliteratureislargely
strating remarkable proficiency across diverse tasks like notfoundedonactualhumanstudiesthatevaluatetrustwor-
summarization(Yangetal.,2023b)andmathematicalrea- thiness,nordoesittypicallyevendefinetrust. Rather,some
soning(Friederetal.,2023),andapplicabilityindomains studieshaveusedotherlanguagemodelsfortrustevaluation
suchasfinance(Yangetal.,2023a)andevenrobotics(Mac- (sometimeswithhumanaudits)(Aheretal.,2023). More-
donaldetal.,2024). Asthesemodelsproliferate,wemust over,biasandmaliciousintentaretypicallyusedasproxies
considerusertrustininteractionswithLLMs. for trust (Sun et al., 2024; Wang et al., 2024a), but these
onlyexaminethebenevolenceproperty(Mayeretal.,1995)
LeeandSeedefinetrustas“theattitudethatanagentwill
oftrust,ignoringlessnefarioustrust-breakingaspectslike
help achieve an individual’s goals in a situation charac-
explanationframing. Wechoosetofocusontrustbetween
terized by uncertainty and vulnerability,” which must be
the user and the model apart from explicitly biased and
1MIT Lincoln Laboratory. Correspondence to: Man- harmfulbehavior.
asi Sharma <manasi.sharma@ll.mit.edu>, Ho Chit Siu <ho-
Additionally, there are quite a few works that aim to test
chit.siu@ll.mit.edu>, Rohan Paleja <rohan.paleja@ll.mit.edu>,
JaimeD.Peña<jdpena@ll.mit.edu>. fororimprovelogicallyconsistentreasoning(plausibility)
(Huangetal.,2023;Lampinenetal.,2022;Marasovic´etal.,
1
4202
nuJ
4
]LC.sc[
1v81020.6042:viXraWhyWouldYouSuggestThat?HumanTrustinLanguageModelResponses
2022; Ye and Durrett, 2022; Lanham et al., 2023; Chen Human-AITrustworthinessSurvey Weranhumanex-
etal.,2023)ortrustinahuman-computerinteractionsetting perimentsintheformofasurveytotesttheself-reported
(Kunkeletal.,2019;Yuetal.,2019),buttheyexclusively trustworthinessontheNewsGenerationTaskinLaMP-4(as
analyzecommon-sensereasoningtaskssuchasQAorclassi- mostpeopleconsumenewssourcesinsomeform(Liedke
ficationthatinvolveshortnumberofeasilyverifiablefactual andWang,2023))byaskingthemtoimaginethemselves
steps. Incontrast,weinvestigatemoreopen-endedcreative as a news reporter enlist AI agents for help in finalizing
tasks(suchasheadlinegeneration)withsubjectivesolutions headlines. Wethenpresentthemwithconsecutivemodelre-
ratherthanobjectiveonestobebinarilydeterminedcorrect sponses(withdifferenttypesofexplanations)andaskthem
orincorrect. Furthermore, someworksassessonlychain to judge them both independently and in relation to each
ofthought(CoT)explanationsorpositionalityintheform otheraccordingtoafewcriteriadiscussedbelow. In-depth
of pre and post-hoc justifications (Ye and Durrett, 2022; setupdetailsareprovidedintheAppendix(seeA.3). Each
Chenetal.,2023),butweexpandtoawidervarietyofex- responseisfirstindependentlyappraisedbytheparticipant
planations,includingfakejustificationsandcross-domain on three grounds: 1) competence (“This response makes
thinking. Mostsignificantly,wealsoevaluatethetrustwor- sense.”) 2)usefulness(“Thisresponseactivelyhelpsmede-
thinessofmodelresponsesthroughahumanstudy,whereas cideonafinalheadline.”) 3)trust(“Itrustthisassistant.”),
someotherworksutilizeolder,lesspowerfulmodelsthat usinga5-optionmultiplechoicequestionthattranslatesto
aremuchlessutilizedbythegeneralpublic(Bansaletal., Likertscale(1correspondingto“stronglydisagree”and5
2021)orevaluatetheplausibilityofthemodeloutputsvia correspondingto“stronglyagree.”). Aftertheratingsection,
heuristicchecks(YeandDurrett,2022;Turpinetal.,2023). three groups ofthe responses are directly compared with
oneanother,withsubjectsbeingaskedtoratetheresponses
ineachgrouponlyinorderoftrustworthiness. Otherwork
3.Methodology
(Ouyang et al., 2022; Fernandes et al., 2023) has demon-
Experiment Details We use model outputs from two stratedthatrankingdataisamorerobustrepresentationof
state-of-the-art RLHF fine-tuned models, GPT-3.5-Turbo humanpreferences.
(gpt-3.5-turbo-0613)(Ouyangetal.,2022)andGPT-4(Ope-
Weperformedamixed-effectslinearregressiononeachof
nAIetal.,2024)accessedon04/2024.LaMP(LaMP:When
thethreeLikertquestions(Norman,2010),withacategori-
Large Language Models Meet Personalization) (Salemi
calindependentvariableofresponsetype,andpredictorsof
etal.,2024)introducesabenchmarkfortrainingandeval-
gender,prompt(articlesnippet),response,age,education,
uating language models to generate personalized outputs.
LLMfamiliarity,computersciencefamiliarity,andAIgen-
Weusethevalidationsetof1500samplesfromtheLaMP-
eratedcontextexposure. Pairwiset-testswereperformed
4 task (News Headline Generation) for the human study
on significant factors on the regression. Pairwise Mann-
andevaluatingmodelperformance[wealsoevaluatemodel
WhitneyUtestswereperformedfortherankingdatawithin
performanceontheLaMP-5(ResearchPaperTitleGener-
eachofthethreegroups. ABonferronicorrectionwasmade
ation),andLaMP-7(TweetParaphrasing)tasks,seeA.3].
forthethresholdofstatisticalsignificanceforpairwisetests.
Toalsoassessmodelperformance(anddeterminetradeoffs
withrespecttotrustworthiness),weusetheopen-endedtext
4.Results
generationmetricROUGEscore(Lin,2004).
Prompts Weconsider17differentexplanationstylesfor HumanExperimentResults 99individualscompleted
modelperformanceevaluation(seeA.3),butduetosurvey theexperiment. TheLikertratingsforallthreequestions
timeconstraints,weselect11forthehumanstudy(Table showed that the majority of people either somewhat or
1). Wevaryjustificationtypeanduserhistory, forwhich stronglyagreedwitheachstatementforallresponses(Fig.
there are two scenarios — whether or not the model is 1). “Itrustthisassistant”wastheonlyquestionwithsome-
askedtocontextualizeitsresponsewithrespecttosomeuser whatmorevariationindistribution,butstillshowedmost
historyrelatedtotheprompt. Inthiscontext,userhistoryis answers to be Somewhat or Strongly Agree. The regres-
theentirebehavior(i.e.,textsamples)associatedwiththe sionforeachofthequestions,withtheresponsetypebeing
author(user)ofagiventext. Themodelgenerateszero-shot theindependentvariableshowednosignificantdifferences
explanationswhenitisnotprovidedwiththeuserhistory. betweentheresponsesgeneratedbythedifferentprompts
Few-shot explanations are generated when the model is (competencep=0.86,usefulnessp=0.92,trustp=0.60).
provided with the retrieved history (via RAG), obtained Self-reportedexposuretoAI-generatedcontentwasfound
usingthetopk=5mostsemanticallysimilarprevioustexts tobeasignificantfactorfortrust(p=0.006),thoughonly
theauthorgeneratedinthepast. Exampleresponsescanbe the“occasional”andthe“veryregular”groupsshowedsig-
foundonline1. nificantdifferences(p=0.0009)inpost-hoctests,butwith
onlyasmalleffectsize(d=0.125). Genderwasalsofound
1Dataandcodewillbeavailablesoon
2WhyWouldYouSuggestThat?HumanTrustinLanguageModelResponses
Table1. ExplanationstylesconsideredforinteractingwiththeLLM.
ID ExplanationStyle History Justification Description
E1 NoHistory No None Themodelisnotrequiredtojustifyitselfandcanrespondfreely.
E2 RetrievedHistory Yes None Themodelisnotrequiredtojustifyitselfandcanrespondfreely.
E3 NoHistoryPrefix No Prefix Themodelmentionsithasthoughtcarefullyaboutitsanswerasaprefix.
E4 NoHistoryPreJust No Pre-hoc Themodelfirstexplainsitsreasoningbeforeresponding(likeE-Pin(YeandDurrett,2022)).
E5 NoHistoryPostJust No Post-hoc Themodelfirstrespondsandthenexplainsitsreasoning.(likeP-Ein(YeandDurrett,2022)).
E6 NoHistoryCrossDomainJust No Cross-domain Themodelreasonsonarelatedtopicanddrawsuponthoseinsights.
E7 NoHistoryFakeJust No Fake Themodelprovidesapurposefullyfalseexplanationforitsresponse.
E8 RetrievedHistoryPreJust Yes Pre-hoc Themodelfirstexplainsitsreasoningbeforeresponding.
E9 RetrievedHistoryPostJust Yes Post-hoc Themodelfirstrespondsandthenexplainsitsreasoning.
E10 RetrievedHistoryCrossDomainJust Yes Cross-domain Themodelreasonsonarelatedtopicanddrawsuponthoseinsights.
E11 RetrievedHistoryFakeJust Yes Fake Themodelprovidesapurposefullyfalseexplanationw.r.trandomexamples.
Figure1. Combinedheatmapsandboxplotsofthethreerankinggroups.Significancebarsomittedforclarity.
isonsweresignificantlydifferent(p≤3.5×10−18)other
than RetrievedHistoryPrejust and RetrievedHistoryCross-
Domain(p = 0.083)andNoHistoryPrejustandNoHisto-
ryCrossDomain(p=0.062).
Subjectcommentaryprovidedattheendoftheexperiment
indicatedacollectionoffeaturesthatweredeemedtomake
theresponseslesstrustworthy,includingirrelevantinforma-
tion,hypothesizedheadlines,lackofexplanation,restating
thetask,theuseofmetaphors,andstatingthattheassistant
“thoughtlonganddeeply...” Featuresthatweredeemedto
maketheresponsesmoretrustworthyincludedconcisere-
Figure2.Combinedheatmapsandboxplotsofthethreeranking sponses, informallanguage, relevantexplanation, lackof
groups.Significancebarsomittedforclarity(seetext). explanation,andanswerfollowedbyjustification. Lackof
explanationwascitedasbothacontributortotrustworthi-
nessanduntrustworthiness,bydifferentpeople.
to be a significant factor for all three questions, though ModelPerformanceEvaluationResults TheROUGE-1
pairwisetestsshowedthatitwasonlyincomparisonswith and ROUGE-L scores for GPT-3.5 and GPT-4 results on
groupsotherthanmale/female,forwhichtherewereonly LaMP-4forthesamecomparisonsintherankingexperiment
threeparticipants,insufficentforvalidity. (Fig. 2)canbeseeninFig. 3; theerrorbarsarestandard
error. Overall,thetrendlinesformodelperformance(Fig.
Manydifferencesappearedwhenparticipantswereasked
3)seemtofollowtheoutlinesoftrustworthinessrankingre-
torankresponsetypes. Thevastmajorityofthepairwise
sults(Fig.2)(PrefixJustisnotconsideredasitwasmanually
comparisonsofrankingswerestatisticallysignificantlydif-
curated). Conversely,duetooverlappingerrorbars,theper-
ferentfromeachother(Fig. 2). Forsimplicity,wereportthe
formancedifferencesdonotrisetoastatisticallysignificant
higheststatistically-significantpvalueineachgroup. Inthe
threshold,withtheexceptionoftheRetrievedHistoryPreJust
NoHistorygroup, allpairwisecomparisonswerestatisti-
andNoHistoryCrossDomaincasesforGPT-3.5.
callysignificantlydifferent(p≤6.3×10−8)otherthanthe
pre-andpost-justificationconditions(p=0.53). IntheJus- However,someinterestingobservationscanstillbegleaned
tificationPlacementgroup,allpairwisecomparisonswere fromtherawvalues. Post-hocjustificationseemstooutpace
statisticallysignificantlydifferent(p≤1.4×10−7).Inthe the Pre-hoc and Fake justifications by a small amount in
JustificationvsCross-Domaingroup,allpairwisecompar-
3WhyWouldYouSuggestThat?HumanTrustinLanguageModelResponses
themodelisaskedtoactivelylieaboutitsreasoningpro-
cess versus self-described to align with the reasoning of
the model) negatively impacts user trust in the both the
no history and retrieved history ranking cases. Interest-
inglyhowever,thisresultvanishesintheLikertcase(see
2)aswell,suggestingthathumansmayidentifymisleading
replieswhencomparisonsareavailablebutarepooratcatch-
ingdeceptioninanisolatedcase. Thisinsighthascrucial
ramificationsforhumantrustinplausiblymis-informative
modelresponses.
No Tradeoffs between Explanation Types and Perfor-
manceThereisnostatisticallysignificanttradeoffbetween
explanationtypesandmodelperformance,withtheexcep-
tionoftheRetrievedHistoryPreJustandNoHistoryCrossDo-
Figure3.ROUGE-1 and ROUGE-L mean and standard error maincasesforGPT-3.5. Thispotentiallydemonstratesthat,
scoresforGPT-3.5andGPT-4resultsonLaMP-4forthecom- alongwiththeusertrustresults,nospecifictypeofexplana-
parisonsusedintherankinggroups. tionmaximizesusertrustandperformance. Anuanceisthat
post-hocjustificationseemstooutperformallothertypesof
explanations(includingpre-hoc)acrosstheLaMP-4,5and
the No History and Retrieved History cases across GPT-
7datasets,butitdoesnotrisetoastatisticalsignificance.
3.5andGPT-4,whilethePre-hoc,FakeandCross-domain
justificationsperformequivalently(seeFig. 3a-b). Theex- Limitations and Future Work A key limitation of our
planationsbasedonretrieveddataalsosurpassthosewithout workistheassumptionthatself-explanationsaccuratelyre-
dataonmodelperformance. (seeFig. 3c). flectthemodel’strueunderlyingreasoningprocess. This
notionhasbeenshowntobeimpreciseinthecaseoflogical
5.Discussion questions(eg. (Lampinenetal.,2022))buthasnotyetbeen
explored extensively for open-ended or creative analyses.
FeedbackMechanismsWefindthathumanrankingdata
A future examination can tackle this - it is possible that
betterelicitsstatisticallysignificantdifferencesinhuman
thetruefaithfulnessofmodeljustificationscouldalterthe
preferences(see3),affirmingthebasisforitscommonuse
results, although the current insights regarding regarding
inhumandatacollection(Ouyangetal.,2022;Fernandes
trustinself-providedexplanationsarealsovaluablesince,
etal.,2023). However,inmostreal-worldscenarios,model
regardless of true accuracy, they may already be used by
responses are displayed independently (without side-by-
peoplepromptingformoreunderstandingfromthemodel.
sidecomparisons),sohumansreactionswilllikelyadhere
Additionally,ourexperimentdoesnotexactlyfollowLee
morecloselytotheLikertratings(see1),implyingthata
and See’s definition of trust (Lee and See, 2004), as we
differenceintrustisnotexpressedunlessaskeddirectlyina
donotinculcatesituationaluncertainty. Furthermore,the
zero-sumrankingsetting.
originaldataandtheimaginedusersetting(anewsreporter
AddinganExplanationImprovesUserTrustIntherank- creating a headline) are not personalized to the user, and
ingsetting,weseethatpresenceofanexplanation(PreJust, usersareaskedtoself-reporttrustinsteadofitbeingmea-
PostJust,FakeJust)improvesself-reportedusertrustoverthe suredobjectively. Weareplanningstudiestobetteraddress
absenceofone(Prefixcase)(see3a). Post-hocjustifications bothdeficiencies.
inparticularoutrankothertypesofexplanationsintermsof
Finally, much of the work in current ML trustworthiness
trustinboththeNoHistoryandRetrievedHistorysettings,
definestrustwithinthelensofnegativeimpactssuchasbias,
while Pre-hoc and Cross-domain justifications fare simi-
unfairness, harmful content, misinformation, etc. While
larly. Moreover,displayingamorecomprehensiveresponse,
such work is vital, longstanding studies in trust (Lee and
throughreferencingretrievedexamplesinthejustification,
See,2004;Mayeretal.,1995;HoffandBashir,2015)show
alsopositivelyimpactsusertrust(see3c). However,these
ittobemoreinclusive,involvingbenignaspectssuchasthe
increasesdisappearintheLikertcaseimplyingthatthispref-
responsestructureanddegreeofmodelanthropomorphism.
erencemaybesubtle,onethehumanisnotactivelyaware
WethushopetoseemoreworkonMLtrustworthinessthat
of. Fromapracticalperspective,thismeanshumansseem
expandsthecurrentcutting-edgeanddrawsonestablished
totrustanymodelresponse(theaveragescoreoftheLikert
trustliteratureinthesocialsciences.
beingcloseto4/5)inthemomentitisdisplayed.
TheFaithfulnessoftheExplanationImpactsUserTrust
Thewillfullackoffaithfulnessofanexplanation(whether
4WhyWouldYouSuggestThat?HumanTrustinLanguageModelResponses
6.Conclusion G.C.deSouza,ShuyanZhou,TongshuangWu,Graham
Neubig,andAndréF.T.Martins.Bridgingthegap:Asur-
Humanstendtotrustlanguagemodelresponsesregardless
veyonintegrating(human)feedbackfornaturallanguage
oftheexplanationtypeoffered,althoughwhentheyhave
generation,2023.
comparisonswithavarietyofresponsesavailable,theytrust
a response with an explanation, especially a post-hoc ex- Simon Frieder, Luca Pinchetti, Alexis Chevalier, Ryan-
planation,more. Importantly,thefalsityofexplanationsis RhysGriffiths,TommasoSalvatori,ThomasLukasiewicz,
anegativefactorforusertrustintherankingsetting. Fur- PhilippChristianPetersen,andJuliusBerner. Mathemat-
thermore, as there is no model performance degradation, icalcapabilitiesofchatgpt,2023.
human-AI trustworthiness would benefit from prompting
Kevin Anthony Hoff and Masooda Bashir. Trust in au-
languagemodelsforexplanations.
tomation: Integratingempiricalevidenceonfactorsthat
influencetrust. Humanfactors,57(3):407–434,2015.
7.Acknowledgements
ShiyuanHuang,SiddarthMamidanna,ShreedharJangam,
TheauthorsacknowledgeMITLincolnLaboratorySuper- YilunZhou,andLeilaniH.Gilpin. Canlargelanguage
computingCenterforprovidingthehighperformancecom- models explain themselves? a study of llm-generated
putingresourcesthathavecontributedtotheresearchresults self-explanations,2023.
reportedwithinthispaperandtheBehavioralResearchLab
Alon Jacovi and Yoav Goldberg. Towards faithfully in-
at MIT for help with recruiting participants. We also ac-
terpretable NLP systems: How should we define and
knowledgeJacobMacdonaldforhishelpwithfeedbackand
evaluate faithfulness? Association for Computational
editing,andVinceMancusoandKimberlyTanguayforhelp
Linguistics, pages 4198–4205, 2020. URL https:
withclearingthefinalwork.
//aclanthology.org/2020.acl-main.386.
References Johannes Kunkel, Tim Donkers, Lisa Michael, Catalin-
MihaiBarbu,andJürgenZiegler. Letmeexplain: Impact
GatiAher,RosaI.Arriaga,andAdamTaumanKalai. Using ofpersonalandimpersonalexplanationsontrustinrec-
largelanguagemodelstosimulatemultiplehumansand ommender systems. In Proceedings of the 2019 CHI
replicatehumansubjectstudies,2023. Conference on Human Factors in Computing Systems,
CHI’19,page1–12,NewYork,NY,USA,2019.Associ-
GaganBansal,TongshuangWu,JoyceZhou,RaymondFok,
ationforComputingMachinery. ISBN9781450359702.
Besmira Nushi, Ece Kamar, Marco Tulio Ribeiro, and
doi: 10.1145/3290605.3300717. URLhttps://doi.
Daniel S. Weld. Does the whole exceed its parts? the
org/10.1145/3290605.3300717.
effectofaiexplanationsoncomplementaryteamperfor-
mance,2021. Andrew K. Lampinen, Ishita Dasgupta, Stephanie C. Y.
Chan,KoryMatthewson,MichaelHenryTessler,Antonia
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Creswell,JamesL.McClelland,JaneX.Wang,andFelix
Subbiah,JaredKaplan,PrafullaDhariwal,ArvindNee- Hill. Can language models learn from explanations in
lakantan,PranavShyam,GirishSastry,AmandaAskell, context?,2022.
SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,
TomHenighan,RewonChild,AdityaRamesh,DanielM. TameraLanham,AnnaChen,AnshRadhakrishnan,Benoit
Ziegler,JeffreyWu,ClemensWinter,ChristopherHesse, Steiner,CarsonDenison,DannyHernandez,DustinLi,
Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, EsinDurmus,EvanHubinger,JacksonKernion,Kamile˙
Benjamin Chess, Jack Clark, Christopher Berner, Sam Lukošiu¯te˙, Karina Nguyen, Newton Cheng, Nicholas
McCandlish, Alec Radford, Ilya Sutskever, and Dario Joseph,NicholasSchiefer,OliverRausch,RobinLarson,
Amodei. Languagemodelsarefew-shotlearners,2020. Sam McCandlish, Sandipan Kundu, Saurav Kadavath,
Shannon Yang, Thomas Henighan, Timothy Maxwell,
YandaChen,RuiqiZhong,NarutatsuRi,ChenZhao,HeHe, Timothy Telleen-Lawton, Tristan Hume, Zac Hatfield-
JacobSteinhardt,ZhouYu,andKathleenMcKeown. Do Dodds,JaredKaplan,JanBrauner,SamuelR.Bowman,
modelsexplainthemselves? counterfactualsimulatability and Ethan Perez. Measuring faithfulness in chain-of-
ofnaturallanguageexplanations,2023. thoughtreasoning,2023.
Finale Doshi-Velez and Been Kim. Towards a rigorous KevinLeahyandHoChitSiu. Tellmewhatyouwant(what
scienceofinterpretablemachinelearning,2017. youreally,reallywant): Addressingtheexpectationgap
forgoalconveyancefromhumanstorobots. End-User
PatrickFernandes,AmanMadaan,EmmyLiu,AntónioFar- DevelopmentforHuman-RobotInteractionWorkshopat
inhas, Pedro Henrique Martins, Amanda Bertsch, José HumanRobotInteractionConference,2024.
5WhyWouldYouSuggestThat?HumanTrustinLanguageModelResponses
JohnDLeeandKatrinaASee. Trustinautomation: De- Cann,BrittanyCarey,ChelseaCarlson,RoryCarmichael,
signingforappropriatereliance. Humanfactors,46(1): BrookeChan,CheChang,FotisChantzis,DerekChen,
50–80,2004. SullyChen,RubyChen,JasonChen, MarkChen, Ben
Chess, Chester Cho, Casey Chu, Hyung Won Chung,
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio
DaveCummings,JeremiahCurrier,YunxingDai,Cory
Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich
Decareaux,ThomasDegry,NoahDeutsch,DamienDev-
Küttler,MikeLewis,Wen-tauYih,TimRocktäschel,etal.
ille, Arka Dhar, David Dohan, Steve Dowling, Sheila
Retrieval-augmentedgenerationforknowledge-intensive
Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou,
nlptasks. AdvancesinNeuralInformationProcessing
David Farhi, Liam Fedus, Niko Felix, Simón Posada
Systems,33:9459–9474,2020.
Fishman,JustonForte,IsabellaFulford,LeoGao,Elie
Georges, Christian Gibson, Vik Goel, Tarun Gogineni,
Jacob Liedke and Luxuan Wang. News plat-
form fact sheet, 2023. URL https: Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gordon,
//www.pewresearch.org/journalism/ Morgan Grafstein, Scott Gray, Ryan Greene, Joshua
fact-sheet/news-platform-fact-sheet/. Gross, Shixiang Shane Gu, Yufei Guo, Chris Hallacy,
Jesse Han, Jeff Harris, Yuchen He, Mike Heaton, Jo-
Chin-Yew Lin. ROUGE: A package for automatic eval- hannes Heidecke, Chris Hesse, Alan Hickey, Wade
uation of summaries. Association for Computational Hickey, Peter Hoeschele, Brandon Houghton, Kenny
Linguistics, pages 74–81, 2004. URL https:// Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu
aclanthology.org/W04-1013. Jain, Shawn Jain, Joanne Jang, Angela Jiang, Roger
Jiang,HaozhunJin,DennyJin,ShinoJomoto,BillieJonn,
ScottMLundbergandSu-InLee. Aunifiedapproachto
HeewooJun,TomerKaftan,ŁukaszKaiser,AliKamali,
interpretingmodelpredictions. Advancesinneuralinfor-
Ingmar Kanitscheider, Nitish Shirish Keskar, Tabarak
mationprocessingsystems,30,2017.
Khan,LoganKilpatrick,JongWookKim,ChristinaKim,
Jacob P Macdonald, Rohit Mallick, Allan B Wollaber, YongjikKim,JanHendrikKirchner,JamieKiros,Matt
JaimeDPeña,NathanMcNeese,andHoChitSiu. Lan- Knight,DanielKokotajlo,ŁukaszKondraciuk,Andrew
guage,camera,autonomy! prompt-engineeredrobotcon- Kondrich, Aris Konstantinidis, Kyle Kosic, Gretchen
trolforrapidlyevolvingdeployment. InCompanionof Krueger,VishalKuo,MichaelLampe,IkaiLan,Teddy
the2024ACM/IEEEInternationalConferenceonHuman- Lee, Jan Leike, Jade Leung, Daniel Levy, Chak Ming
RobotInteraction,pages717–721,2024. Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz
Litwin,TheresaLopez,RyanLowe,PatriciaLue,Anna
BertramFMalle. Howthemindexplainsbehavior: Folk Makanju,KimMalfacini,SamManning,TodorMarkov,
explanations,meaning,andsocialinteraction.MITpress, YanivMarkovski,BiancaMartin,KatieMayer,Andrew
2006. Mayne, Bob McGrew, Scott Mayer McKinney, Chris-
tine McLeavey, Paul McMillan, Jake McNeil, David
AnaMarasovic´,IzBeltagy,DougDowney,andMatthewE.
Medina, Aalok Mehta, Jacob Menick, Luke Metz, An-
Peters. Few-shot self-rationalization with natural lan-
drey Mishchenko, Pamela Mishkin, Vinnie Monaco,
guageprompts,2022.
Evan Morikawa, Daniel Mossing, Tong Mu, Mira Mu-
RogerCMayer,JamesHDavis,andFDavidSchoorman. rati, Oleg Murk, David Mély, Ashvin Nair, Reiichiro
Anintegrativemodeloforganizationaltrust. Academyof Nakano, Rajeev Nayak, Arvind Neelakantan, Richard
managementreview,20(3):709–734,1995. Ngo, Hyeonwoo Noh, Long Ouyang, Cullen O’Keefe,
JakubPachocki,AlexPaino,JoePalermo,AshleyPan-
GeoffNorman. Likertscales, levelsofmeasurementand
tuliano, Giambattista Parascandolo, Joel Parish, Emy
the “laws” of statistics. Advances in health sciences
Parparita, Alex Passos, Mikhail Pavlov, Andrew Peng,
education,15(5):625–632,2010.
AdamPerelman,FilipedeAvilaBelbutePeres,Michael
Petrov,HenriquePondedeOliveiraPinto,Michael,Poko-
OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal,
rny, Michelle Pokrass, Vitchyr H. Pong, Tolly Powell,
Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman,
AletheaPower,BorisPower,ElizabethProehl,RaulPuri,
DiogoAlmeida,JankoAltenschmidt,SamAltman,Shya-
AlecRadford,JackRae,AdityaRamesh,CameronRay-
malAnadkat,RedAvila,IgorBabuschkin,SuchirBalaji,
mond, Francis Real, Kendra Rimbach, Carl Ross, Bob
ValerieBalcom, PaulBaltescu, HaimingBao, Moham-
Rotsted, Henri Roussez, Nick Ryder, Mario Saltarelli,
madBavarian,JeffBelgum,IrwanBello,JakeBerdine,
TedSanders,ShibaniSanturkar,GirishSastry,Heather
Gabriel Bernadett-Shapiro, Christopher Berner, Lenny
Schmidt,DavidSchnurr,JohnSchulman,DanielSelsam,
Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa
Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah
Brakman,GregBrockman,TimBrooks,MilesBrundage,
Shoker,PranavShyam,SzymonSidor,EricSigler,Mad-
Kevin Button, Trevor Cai, Rosie Campbell, Andrew
6WhyWouldYouSuggestThat?HumanTrustinLanguageModelResponses
dieSimens,JordanSitkin,KatarinaSlama,IanSohl,Ben- Meng Jiang, Mohit Bansal, James Zou, Jian Pei, Jian
jaminSokolowsky,YangSong,NatalieStaudacher,Fe- Liu,JianfengGao,JiaweiHan,JieyuZhao,JiliangTang,
lipePetroskiSuch,NatalieSummers,IlyaSutskever,Jie JindongWang,JoaquinVanschoren,JohnMitchell,Kai
Tang,NikolasTezak,MadeleineB.Thompson,PhilTillet, Shu,KaidiXu,Kai-WeiChang,LifangHe,LifuHuang,
Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle, MichaelBackes,NeilZhenqiangGong,PhilipS.Yu,Pin-
NickTurley,JerryTworek,JuanFelipeCerónUribe,An- YuChen,QuanquanGu,RanXu,RexYing,ShuiwangJi,
dreaVallone,ArunVijayvergiya,ChelseaVoss,Carroll SumanJana,TianlongChen,TianmingLiu,TianyiZhou,
Wainwright, JustinJayWang, AlvinWang, BenWang, WilliamWang,XiangLi,XiangliangZhang,XiaoWang,
Jonathan Ward, Jason Wei, CJ Weinmann, Akila Weli- Xing Xie, Xun Chen, Xuyu Wang, Yan Liu, Yanfang
hinda, Peter Welinder, Jiayi Weng, Lilian Weng, Matt Ye, Yinzhi Cao, Yong Chen, and Yue Zhao. Trustllm:
Wiethoff,DaveWillner,ClemensWinter,SamuelWol- Trustworthinessinlargelanguagemodels,2024.
rich,HannahWong,LaurenWorkman,SherwinWu,Jeff
Wu,MichaelWu,KaiXiao,TaoXu,SarahYoo,Kevin MilesTurpin,JulianMichael,EthanPerez,andSamuelR.
Yu, Qiming Yuan, Wojciech Zaremba, Rowan Zellers, Bowman. Language models don’t always say what
ChongZhang, MarvinZhang, ShengjiaZhao, Tianhao theythink: Unfaithfulexplanationsinchain-of-thought
Zheng,JuntangZhuang,WilliamZhuk,andBarretZoph. prompting,2023.
Gpt-4technicalreport,2024.
Boxin Wang, Weixin Chen, Hengzhi Pei, Chulin Xie,
LongOuyang,JeffWu,XuJiang,DiogoAlmeida,CarrollL. MintongKang,ChenhuiZhang,ChejianXu,ZidiXiong,
Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Ritik Dutta, Rylan Schaeffer, Sang T. Truong, Simran
Agarwal,KatarinaSlama,AlexRay,JohnSchulman,Ja- Arora, Mantas Mazeika, Dan Hendrycks, Zinan Lin,
cobHilton,FraserKelton,LukeMiller,MaddieSimens, YuCheng,SanmiKoyejo,DawnSong,andBoLi.Decod-
Amanda Askell, Peter Welinder, Paul Christiano, Jan ingtrust: Acomprehensiveassessmentoftrustworthiness
Leike, and Ryan Lowe. Training language models to ingptmodels,2024a.
followinstructionswithhumanfeedback,2022.
Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang,
GustavoPenhaandClaudiaHauff. Whatdoesbertknow YingxueZhou,EunahCho,XingFan,XiaojiangHuang,
aboutbooks,moviesandmusic? probingbertforconver- Yanbin Lu, and Yingzhen Yang. Recmind: Large lan-
sationalrecommendation.InFourteenthACMConference guagemodelpoweredagentforrecommendation,2024b.
onRecommenderSystems,RecSys’20.ACM,Septem-
ber2020. doi: 10.1145/3383313.3412249. URLhttp: Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
//dx.doi.org/10.1145/3383313.3412249. Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and
DennyZhou. Chain-of-thoughtpromptingelicitsreason-
MarcoTulioRibeiro,SameerSingh,andCarlosGuestrin. inginlargelanguagemodels,2023.
"whyshoulditrustyou?"explainingthepredictionsof
anyclassifier. InProceedingsofthe22ndACMSIGKDD HongyangYang,Xiao-YangLiu,andChristinaDanWang.
international conference on knowledge discovery and Fingpt: Open-source financial large language models,
datamining,pages1135–1144,2016. 2023a.
AlirezaSalemi,ShesheraMysore,MichaelBendersky,and Xianjun Yang, Yan Li, Xinlu Zhang, Haifeng Chen, and
Hamed Zamani. Lamp: When large language models WeiCheng. Exploringthelimitsofchatgptforqueryor
meetpersonalization,2024. aspect-basedtextsummarization,2023b.
HoChitSiu,JaimePeña,EdennaChen,YutaiZhou,Victor XiYeandGregDurrett. Theunreliabilityofexplanations
Lopez, KylePalko, Kimberlee Chang, andRossAllen. infew-shotpromptingfortextualreasoning,2022.
Evaluationofhuman-aiteamsforlearnedandrule-based
agentsinhanabi. AdvancesinNeuralInformationPro- KunYu,ShlomoBerkovsky,RonnieTaib,JianlongZhou,
cessingSystems,34:16183–16195,2021. and Fang Chen. Do i trust my machine teammate?
an investigation from perception to decision. In Pro-
LichaoSun,YueHuang,HaoranWang,SiyuanWu,Qihui ceedings of the 24th International Conference on In-
Zhang,YuanLi,ChujieGao,YixinHuang,WenhanLyu, telligent User Interfaces, IUI ’19, page 460–468, New
YixuanZhang,XinerLi,ZhengliangLiu,YixinLiu,Yijue York, NY, USA, 2019. Association for Computing
Wang,ZhikunZhang,BertieVidgen,BhavyaKailkhura, Machinery. ISBN 9781450362726. doi: 10.1145/
CaimingXiong,ChaoweiXiao,ChunyuanLi,EricXing, 3301275.3302277. URL https://doi.org/10.
FurongHuang,HaoLiu,HengJi,HongyiWang,Huan 1145/3301275.3302277.
Zhang, Huaxiu Yao, Manolis Kellis, Marinka Zitnik,
7WhyWouldYouSuggestThat?HumanTrustinLanguageModelResponses
A.Appendix model-agnosticfeatureattributionexplanationswhenself-
explanationmethodscanperformatparwithLIME(Ribeiro
A.1.Human-AIInteractioninCreativeSettings
etal.,2016),weinvestigateself-explanationsasamethod
The realization that LLMs generally have a capacity for for interpretability. In addition, we cover a wider assort-
creativitywarrantsdiscussionregardingtheirincorporation mentofexplanationstylesbeyondjustpre-andpost-hoc
intohumandecision-makingprocesses. Further,coupling explanations.
humanswithLLMsfordecision-makingprocessesholdsad-
LLMsandrecommendersystems Alineofrecentwork
ditionalimportance,especiallywhileLLMscontinuetooc-
hasfocusedonadaptinggenerativemodelsforservicein
casionallyhallucinateduringinference,ashavingahuman-
recommendation tasks - this can be a part of an existing
in-the-loop affords the means to check LLM outputs for
recommendationsystempipeline(describingtheitemsto
clear error. This relationship can be especially advanta-
be recommended) (Penha and Hauff, 2020) or to replace
geousinopen-endedsettingswithoutasoledefinitionfor
the entire pipeline (Wang et al., 2024b). However, these
correctness. Moreover, the success of this system hinges
worksprincipallygaugethemodels’aptitudesonitemrec-
heavilyupontrustandreliancebetweenthehumanandthe
ommendation. While this application is very useful for
model and, thus, the quality of model explanations. The
variousbusinessusecases,itdifferssignificantlyfromthe
future growth of the use of AI agents as assistants is an
kindofpreferencelearningthatmayhappenwithregular
importantmotivatorinourselectionofthemoresubjective
userswheninteractingwithalanguagemodel. Suchtasks
andopen-endedtasksintheLaMPbenchmark.
wouldfallagreatdealmoreintothemorecomplexcategory
ofhavinglonger-form, subjective, andmorecreativeout-
A.2.AdditionalRelatedWorks puts(asopposedtoasingleitem),forexample,generating
a research paper title; the inputs would also be similarly
LLMsandtrustworthiness LeeandSeedefinetrustto
longer-form(forexample,ahistoryoftweetsasopposedto
be“theattitudethatanagentwillhelpachieveanindivid-
quantitativemetricssuchasclick-throughrates). Wehave
ual’sgoalsinasituationcharacterizedbyuncertaintyand
notbeenabletofindanylarge,comprehensivebenchmarks
vulnerability,” and it must be appropriately calibrated to
thatspecificallytacklemoresubjective,long-formuserpref-
avoidovertrustordistrust,whicharerespectivelythecat-
erenceasidefromLaMP(Salemietal.,2024),whichiswhat
alystsforoverrelianceandunderuseofanAIsystem(Lee
weusedinourexperiments.
andSee,2004). Mayeretal. arguethattrustworthinessis
affectedbythreeperceivedpropertiesofthetrustee: ability,
benevolence, and integrity (Mayer et al., 1995). Ability A.3.Methodology
andintegritymapwelltothecommonAImeasuresoftask
AdditionalModelDetails Wetestusingtwostate-of-the-
performanceandpredictability,butitisimportanttonote
artRLHFfine-tunedmodels,GPT-3.5-Turbo(gpt-3.5-turbo-
that these factors are perceived by the trustor rather than
0613)andGPT-4accessedon04/2024. GPT-3.5andGPT-4
being objective measures. Interestingly, humans ascribe
are both trained using reward models similar to the ones
moralintentoralackthereoftoAIagents, eveninfairly
described in (Ouyang et al., 2022) for better instruction-
abstractsettingslikecardgameswithoutcommunication,
followingbehavior(OpenAIetal.,2024),butexactinforma-
and are more likely to ascribe malevolence to otherwise
tionaboutparametercount,architecture,andtrainingdata
high-abilityagents(Siuetal.,2021). Agentintentandthe
hasnotbeendisclosedpublicly. Weemploythefullevalua-
forming and breaking of human trust rely heavily on the
tionsetsforbothmodelsandsetthetemperatureforboth
human’s/trustor’sexpectationsoftheagent/trustee. LLM
models to 0 to control for any differences that may arise
collaborationisaparticularlyinterestingformofAIinter-
fromdistinctdecodingalgorithmsasopposedtodissimilar
action,asLLM—muchmoresothanotherformsofAI—
promptsandrequestsforjustifications. TheOpenAI-API
havelanguagepatternsthatcloselymimicthoseofentities
wasusedandonedatasettookaround10hourstoevaluate
intheworldtowhichhumanshaveascribedbehavioraland
ononemodelacrossallevaluationtypes.
moralagency(Malle,2006),andatleastsuperficiallymatch
thelanguagepragmaticsandreasoningcharacteristicsthat AdditionalDataDetails LaMP(LaMP:WhenLargeLan-
humansexpectofagenticentities(LeahyandSiu,2024). guageModelsMeetPersonalization)(Salemietal.,2024)
introducesanovelbenchmarkaimedattrainingandeval-
LLMsandinterpretability Interpretabilityresearchis
uating language models to generate personalized outputs.
a broad domain that includes model-aware feature attri-
LaMPprovidesathoroughassessmentframeworkincluding
butionexplanationslikegradientsaliancymethods[]and
variouslanguagetasksandcomprehensiveuserbehaviorhis-
model-agnostic feature attribution explanations such as
toryencapsulatedinprofiles. Theseprofilesareeithersplit
LIME (Ribeiro et al., 2016) and SHAP (Lundberg and
acrossusers(user-based)orforasingleuser(time-based).
Lee,2017). Nonetheless,asweexperimentwithbothopen
Weutilizethetime-basedversionsofthedatatozeroinon
andclosedmodels,andduetothecostlynatureofrunning
8WhyWouldYouSuggestThat?HumanTrustinLanguageModelResponses
learningpreferencesforasingleuserovertime,whichisa • Fake: queriesthemodeltoprovideacompletelyfalse
morepracticalscenariofortheuseAIagentassistants. We explanation to the user which differed from its true
utilize the Validation Sets for each of the tasks (LaMP-4: reasoningprocess. Intheretrievedcase,themodelpro-
NewsHeadlineGeneration,LaMP-5: ResearchPaperTitle videsapurposefullyfalseexplanationforitsresponse
Generation,andLaMP-7: TweetParaphrasing),whichcom- withregardstorandomlyretrievedexamples(instead
prise of 1500, 1500 and 1498 samples respectively. This ofexamplesretrievedduetosimilarity).
leavesuswith4498samplesfortheevaluation.FortheGPT-
4 model evaluation, 300 examples are randomly selected
Themodel’sbaselineresponseisgivenwhennojustification
duetocostconstraints.
is required. Prefix explanations test how comfortable the
Additional Task Details The LaMP benchmark com- user is with the model claiming to have performed some
prisessevenpersonalizedtasks,coveringthreetextclassifi- reasoning,withoutthatreasoningactuallybeingprovided.
cationtasksandfourtextgenerationtasks. Wefocusonthe Since this type of response is manually curated, it only
morecomplextextgenerationtasks,asopposedtoclassifi- appearsinthehumanstudyandnotinthemodeleval-
cation,andselectthreeofthetasksforexperimentation(the uation. We also only assessed it in the no history case.
fourth,EmailSubjectGeneration,isnotopen-source): Pre-hocandpost-hocjustificationsprovidedirectrationale
T1NewsHeadlineGeneration: themodelisprovidedwith ofthemodel’sresponse(Note:someworkshypothesizethat
anarticlesnippetusually1-2sentenceslong(assumedtobe ifthegeneratedexplanationispost-hoc,theexplanationhas
thefirstlinefromthearticle)andaskedtoextrapolateand morewaystobeunfaithful. (Lanhametal.,2023)). Cross-
baseaheadlineonit. domainhypothesizationprovidesinsightintothemodel’s
T2ResearchPaperTitleGeneration: themodelissimilarly generalizationcapabilitiesandhowsuchsecond-orderlev-
provided with an abstract and has to predict the research elsofcognitionimpactmodelperformance(i.e.,changein
paper’stitle. themodel’soutputswhenrelatedbutdistinctdomaininfor-
T3TweetParaphrasing: themodelhastoconvertadescrip- mationisprovided),andwhetherhumanusersmightfind
tionofatweettoauniquetweetintheuser’suniquestyle. themwell-foundedorextraneous. Forexample,inthenews
headlinegenerationtask,postulatingwhatagivenuser,with
AdditionalPromptDetailsPrompts Thefulllistof17
headlineswritteninPolitics,maywriteinanotherarealike
explanationstylesissummarizedinTable1.
Economics. Lastly,fakejustificationsprobetheaspectof
Wefirstrequirefiveprimarydifferenttypesofjustifications faithfulnessbytestingwhetherprovidinganyexplanation,
themodelshouldconsiderwithitsresponses,passedinto regardlessofthefidelitytothemodel’sself-describedtrue
theprompt. reasoningprocess,issufficientforthesustenanceofhuman
reliance.
• None:themodelisnotrequiredtojustifyitselfandcan Finally, to understand whether engendering any types of
respondfreely. explanationsinmodelresponsesaffectsitsultimateperfor-
mance,weincludethefollowingbaselines:
• Prefix: themodelisnotquerieddifferentlyfromthe
"None"case,butaprefixofthephrase"Afterthinking
• Zero-shot Chain-of-thought (CoT): Based on (Wei
deeplyandconsideringawiderangeofpossibilities,I
etal.,2023),themodelisaskedtothinkstep-by-step
cametotheconclusionthatthemostappropriatehead-
beforeanswering. Weconsiderboththeretrievedcase
lineis"ismanuallypre-pendedtothemodelresponse.
andnohistorycase.
• Pre-hoc: the model is first queried to provide a self-
• Few-shot Chain-of-thought (CoT): Based on (Lewis
explanationofitsreasoningbeforeresponding. Thisis
etal.,2020;Brownetal.,2020),themodelisaskedto
similartotheE-P(explain-then-predict)paradigmin
thinkstep-by-stepbyfollowingthereasoninggivenin
(YeandDurrett,2022).
examples. OnlytheNoHistorycaseisconsidered,as
• Post-hoc: query the model for a response first, fol- theexampleswerefixed(notretrieved)duetoresource
lowed by its self-explanation. This is similar to the constraints,andthereasoningforapreselectedsetof
P-E(predict-then-explain)paradigmin(YeandDur- exampleswaswrittenbyamemberofthelab.
rett,2022).
• Numerical: Extendingtheapproachoftokenapproach
• Cross-domainhypothesization: elicitthemodel’sadja- in(Huangetal.,2023),themodelisaskedtoprovide
centreasoningcapabilitiesbyaskingittofirstreason numericalvaluesindicatingimportancetoeachofits
in a different but similar domain and then using the retrievedexamples(asopposedtoindividualtokens).
insightsdrawn. Thus,onlytheretrievedcaseisconsidered.
9WhyWouldYouSuggestThat?HumanTrustinLanguageModelResponses
• Entire History: Model evaluation given the largest credibility. Theinstructionwasthenfollowedwithabrief
chunkpossibleoftheuserhistory(k=25). familiarizationgameofmatchingnewsheadlinestotheir
topicareastocheckforparticipantattention. Iftheywere
• Random History: Randomly selected examples not
able to pass this stage, the subjects would proceed to the
relatedtothepromptareprovided(k=5).
actualexperiment. Theywouldbeshownataskinstruction:
togenerateanewsheadlinebasedonasubsequentarticle
InordertoperformtheROUGEscoreanalysesofthehead- snippet. Thenthevariousresponsesfromdifferentprompts
lines,weextracttheheadlinesfromtheexplanationsusing to the model (from the model evaluation section), which
RegEx from a fixed output prompt template the model is encapsulatethediscreteexplanationstyles,wouldbeexhib-
promptedwith. ited to the subject one-at-a-time to assess according to a
fewcriteria. Toenablethis,onearticlesnippetisrandomly
Table3displayssamplepromptssuppliedtothemodelfor
selectedfromthe16examples(seedsetto23).
thedifferentexplanationstyles.
Each response is first independently appraised one three
Manystudiesdiscoveratrade-offbetweenperformanceand
grounds: 1)competence: “Thisresponsemakessense”2)
interpretability (Narang et al. 2020; Subramanian et al.
usefulness: “Thisresponseactivelyhelpsmedecideona
2020;Haseetal. 2020,i.a.),whileothersobserveapositive
finalheadline”and3)trust“Itrustthisassistant”,usinga5-
impact on the performance from including explanations
optionmultiplechoicequestionthattranslatestoLikertscale
(e.g.,CoT-styleprompting).
(1correspondingto“stronglydisagree”and5corresponding
SurveySetupDetails Weranhumanexperimentsinthe to“stronglyagree.”).Afteralltheresponsesaredisplayed,a
form of a survey to test the self-reported trustworthiness fewsubsetsoftheresponsesaredirectlycomparedwithone
thathumansexperiencebasedonvarioustypesofexplana- anotherthroughranking,assomeotherwork(Ouyangetal.,
tions. WeoperatewithinthesameLaMPdataset(Salemi 2022;Fernandesetal.,2023)hasdemonstratedthatranking
et al., 2024) as the model performance evaluation experi- dataisamorerobustrepresentationofhumanpreferences.
mentsandusetheoutputsfromGPT-3.5modeltodisplay Wecompared:
to the subjects. GPT-3.5 was used instead of GPT-4 as
morepeoplewouldhaveinteractedwiththeGPT-3.5model
1. Prefix,PreJust,PostJustandFakeJustintheNoHistory
duetoitsproximitytoChatGPT(asopposedtotheGPT-4
case
whichrequiresapaywall). Inordertoprobeawidervariety
ofthegeneralpublic,wechosetoexclusivelyemploythe 2. PreJust,PostJustandFakeJustintheRetrievedHistory
NewsGenerationTaskinLaMP,asmostpeopleconsume case
newssourcesinsomeform(LiedkeandWang,2023),while
researchpapertitlegenerationandeventhetweetparaphras- 3. PreJust and CrossDomainJust both in the cases of
ing task might require either specialized knowledge of a NoHistoryandRetrievedHistorytocomparewiththe
nichetopicoruniquefeatureslikeslang. Thisallowsusto CrossDomainexplanationtypeaswell
asksubjectstoputthemselvesinascenariowheretheycan
seethemselvesinteractingwithanAIagent,i.e. asanews Wewereabletocovermostoftheexplanationsatleastonce
reporterenlistAIagentsforhelpinfinalizingheadlines. intherankingdatathroughthesecomparisons.
Wethenpresentthemwithconsecutiveexplanationsandask We sought to design the survey with a timeframe of 15
themtojudgethembothindependentlyandinrelationto minutes in mind to maximize the number of participants
eachotheraccordingtoafewcriteriadiscussedbelow. In whocouldparticipate(eg. takingtimeoutonacoffeeor
ordertobalanceourdesiretodisplayavarietyofoutputsto lunchbreak). Displayingall14responsesfromthemodel
subjectswiththeneedtoreceiveadequatesignalforeach evaluationsectiontotheuserwouldexceedthattimelimit
specificoutputtoovercomenoise,outofthe1500samples duetotheincreasednumberofLikertscaleevaluations(3
inthedevelopmentset,werandomlyselected16examples per additional response) and the added time and mental
ofarticlesnippetsandtheircorrespondingheadlines(witha overhead in ranking more than 4 responses. Therefore,
seedof23)foruseinthehumanstudies.Wealsoprunedand wedecidedtolimitourresponsestoensurethatcondition,
resampledexamplesthatdealtwithconfoundingtopicsthat and entire experiment was timed in the pilot phase to be
mayadverselyimpacttrustworthinessofresponsessuchas approximately15minutes,thoughactualexperimenttime
politicsuntilwewereleftwith16un-confoundedexamples. tendedtobesomewhatlonger.
Thesurveyflowwasdesignedasfollows: participantswere Tocutdown,weelectedtoremove"RetrievedHistory"and
first introduced to the experiment and asked to envision "EntireHistory"responses,astheresponsescontainnojusti-
themselvesasstarnewsreportersthatmustenlistthehelp ficationandmaynotlookmeaningfullyseparatetoahuman
ofassistants,whoseresponsestheywillbeevaluatingfor fromthe"NoHistory"response. Moreover,wedecidedto
10WhyWouldYouSuggestThat?HumanTrustinLanguageModelResponses
Table2. Fulllistofexplanationstylesconsideredformodelevaluation.
ID ExplanationStyle History Justification Description
E1 NoHistory No None Themodelisnotrequiredtojustifyitselfandcanrespondfreely.
E2 RetrievedHistory Yes None Themodelisnotrequiredtojustifyitselfandcanrespondfreely.
E3 RandomHistory Yes None Themodelisnotrequiredtojustifyitselfandcanrespondfreely.
E4 EntireHistory Yes None Themodelisnotrequiredtojustifyitselfandcanrespondfreely.
E5 NoHistoryPrefix No Prefix Themodelmentionsithasthoughtcarefullyaboutitsanswerasaprefix.
E6 NoHistoryPreJust No Pre-hoc Themodelfirstexplainsitsreasoningbeforeresponding.
E7 NoHistoryPostJust No Post-hoc Themodelfirstrespondsandthenexplainsitsreasoning.
E8 NoHistoryCrossDomainJust No Cross-domain Themodelreasonsonarelatedtopicanddrawsuponthoseinsights.
E9 NoHistoryFakeJust No Fake Themodelprovidesapurposefullyfalseexplanationforitsresponse.
E10 NoHistoryZeroShotCoT No Zero-Shot Themodelisaskedtothinkstep-by-stepbeforeanswering.(Weietal.,2023)
E11 NoHistoryFewShotCoT No Few-Shot Themodelfollowsthestep-by-stepreasoninggiveninexamples.(Lewisetal.,2020;Brownetal.,2020)
E12 RetrievedHistoryPreJust Yes Pre-hoc Themodelfirstexplainsitsreasoningbeforeresponding.
E13 RetrievedHistoryPostJust Yes Post-hoc Themodelfirstrespondsandthenexplainsitsreasoning.
E14 RetrievedHistoryCrossDomainJust Yes Cross-domain Themodelreasonsonarelatedtopicanddrawsuponthoseinsights.
E15 RetrievedHistoryFakeJust Yes Fake Themodelprovidesapurposefullyfalseexplanationforitsresponse.
E16 RetrievedHistoryZeroShotCoT Yes Zero-Shot Themodelisaskedtothinkstep-by-stepbeforeanswering.(Weietal.,2023)
E17 RetrievedHistoryNumericalJust Yes Numerical Themodelprovidesnumbersindicatingtheimportanceeachexample.(Huangetal.,2023)
eliminatebothoftheCoTquestionsasthezero-shotcaseis A.4.AdditionalLLMResults
stylisticallyverysimilartothepre-hocjustificationmethod
TheROUGE-1andROUGE-Lresultsforeverymodelre-
ofexplanation-then-answerandthefew-shotcasefollows
sponsestyleinTables4and5acrossGPT-3.5andGPT-4
human-logicthatisexternallyappliedandmaynotbetrue
forLaMP-4,LaMP-5,LaMP-7,alongwithcorresponding
tohowtheexplanationisactuallygenerated. Finally, we
standarderrorbars. Thesevaluesarealsovisualizedinbar
feltthattheattributionquestionstoodabitaloneandcould
plotsinFigures4and5.
notbecomparedacrossthenohistoryandretrievedhistory
conditions,andthusthoughwefeltitwasaverycompelling
A.5.ParticipantDemographics
anddistinctivetypeofexplanation,wedeterminedtopush
itforafutureexperiment. Additional plots of participant demographic distributions
areshowinFigures6,7,8,9,10,and11.
This results in 9 remaining responses. We were also cu-
riouswhethersimplymentioningintheresponsethatthe
modelhadponderedthepromptandconsideredmanypos- A.6.AdditionalLimitations
sibilities,regardlessofthetruthofthatclaim,couldaffect
Even though self-explanations may not accurately reflect
trust;subsequently,weaddedamodelresponsethatsimply
themodel’sactualreasoningprocess(JacoviandGoldberg,
prependedsuchaprefixbeforestatingthegeneratedhead-
2020), there is some evidence they track with traditional
line. Additionally, toaccountforapotentialblanketbias
methodslikeocclusionandLIME(Huangetal.,2023). Ad-
by a participant against any AI generated content, which
ditionally, as Doshi-Velez and Kim (2017) argue, a true
may impact measures of trustworthiness, we add in the
estimateoffaithfulnessisultimatelyimpossibleformod-
groundtruthhumanresponse(whichistheheadlinewrit-
elsthatarenotinterpretableperse,whichincludesLLMs
tenbytheoriginaljournalistwhowrotethearticlesnippet).
(Doshi-VelezandKim,2017).
Wealsomakeitcleartoparticipantsthatresponsesmaybe
AI-modelgeneratedorgeneratedbyahuman. Thisresults TheROUGEscoreisalsonotaperfectmetricforthisap-
inatotalof11responsesdisplayedtotheuser. Afterthe plication-foropen-endedandcreativetaskssuchasnews
Likert questions, participants were asked to directly rank headline generation, there are many correct answers that
thetrustworthinessofresponsesinthreegroups(Table2). couldbegiven(notjustthegroundtruthheadlinethatwas
suggestedinreality)andsoproximitytoaground-truthmet-
Then, this entire procedure of Likert ratings and ranking
ricisnottheonlywaytomeasuremodelperformance. One
isrepeatedwithanotherrandomlyselectedarticlesnippet.
other metric is similarity to the question asked and infor-
Essentially,theexperimenthas2rounds,with2articlesnip-
mationprovided(inthiscase,thearticle). Anevenbetter
pets,11responses,and3rankinggroupseach. Therefore,
evaluation is using human feedback, which we acquired
eachpersonisanswering66Likertquestionsintotal,and
in this experiment. On the whole, however, we believe
foreachtypeofexplanation. Theorderofdisplayingthe
thattheMLdomainrequiresbettermetricsforopen-ended
responsesforbothLikertandrankingwasrandomizedto
responsesonthemodelside.
preventbiasesarisingfromthesequenceofresponses.
Participantsreceiveda$5USDgiftcardattheendoftheir
experiment. Eachexperimenttookapproximately30min-
utes. Thetotalamountspentonparticipantpaymentwas
$500. Experiments were conducted virtually and asyn-
chronouslythroughsupplyingonlinesurveyslinkshosted
onQualtrics.
11WhyWouldYouSuggestThat?HumanTrustinLanguageModelResponses
Table3.Listofexampleprompttemplatesandcorrespondingmodelsresponses.Thesamecontextandinitialpromptareprovidedtothe
modelforeachoftheexplanationstyles:
{context}:Youareatalentedjournalistwhoexcelsatwritingheadlines.
{prompt}(thisisaspecificexample):"Generateaheadlineforthefollowingarticlesnippet:Beinganexwifewasveryunexpected.I
wentintoitkickingandscreaming.Anddrunktexting.Oh-andalittlebitofstalking.TothosegoingthroughitnowIcantellyou,you
willsurvive."
ID ExplanationStyle Prompt Notes
E1 NoHistory { {c po ron mte px tt }}
{context}
E2 RetrievedHistory Hereisthehistoryofarticle{ sp aro nm dp tht} eircorrespondingheadlines: {retrieved e_ xd aa mta p} lei ss ft rh oe mk= th5 em uso es rt hsi im stoil ra yr .retrieved
{retrieved_data}
{context}
E3 RandomHistory Hereisthehistoryofarticle{ sp aro nm dp tht} eircorrespondingheadlines: {random_ ere xt ar mie pve led s_ fd ra ot ma} ti hs ek u= s5 erra hn isd to om ryl .yselected
{random_retrieved_data}
E4 EntireHistory Hereisthehistoryo {f ea nrt ti ic rele _{ { sc rp eo ar to nn rm idt ee vpx th ett }} e di _r dc ao tr ar }espondingheadlines: tha{ te cn ati nre ofi_ ftr te i hntr eti oe mv c oe od sn t_ te sd x ia mtta l ie} lani rgs lyta hs r( em w trh iu eic vch eh do ef ent xdh ase muu pps le b er se )h inis gto kr =y 25
E5 NoHistoryPrefix { {c po ron mte px tt }}
{context}
E6 NoHistoryPreJust Pleasefirstprovideanexplana{ tp ioro nm fop rt} howyouchosetogeneratethe
headlineandthenthegeneratedheadlinewiththeformat"GeneratedHeadline:"
{context}
E7 NoHistoryPostJust Pleaseprovidefirstthegenerat{ ep dro hm eap dt l} inewiththeformat"Generated
Headline:"andthenanexplanationforhowyouchosetogeneratetheheadline.
{context}
{prompt}
E8 NoHistoryCrossDomainJust First,pleasehypothesize5examplesofwhatotherheadlinesthepersonwhowrotetheseheadlineswouldwriteinanother
domain,likeArt,Science,PoliticsorPopCulture.Then,basedontheinsightsyougainedfromreasoningonthehypothesizedheadlines,generatethefinalanswer
(theheadlinefortheinitialarticle)withtheformat"GeneratedHeadline:".
{context}
{prompt}
E9 NoHistoryFakeJust Pleaseprovidefirstthegeneratedheadlinewiththeformat"Generated
Headline:"andthenprovideacompletelyfakeexplanationforhowyouchosetogeneratetheheadline
(thatisdifferentfromtheactuallogicyoufollowedtoreachtheanswer).
{context}
E10 NoHistoryZeroShotCoT Pleaseprovidethegeneratedheadl{ ip nr eo wm ip tht} theformat"GeneratedHeadline:"
Let’sthinkstepbystep.
{context}
{prompt}
Hereareexamplesofhowheadlinesareconstructedfromtheircorrespondingarticles:
Articletext:"Aboveall,showyourlove.Showup.Saysomething.Dosomething.Bewillingtostandbesidethe Theexamplesusedforreasoningarefixed(not
E11 NoHistoryFewShotCoT gapingholethathasopenedinyourfriend’slife,withoutflinchingorturningaway.Belove.Loveisthethingthatlasts." retrieved)duetoresourceconstraintsinlabeling
Explanation:Withthehintthata"gapinghole"hasopenedupinyourfriend’slifeandtherecommendation reasoningforallthesamplesintheval.set.
thatyoushouldbethereforyourfriend,wecangleanthatthefriendmustbeexperiencethegriefofaloss.
Headline:"HowtoHelpaGrievingFriend:11ThingstoDoWhenYou’reNotSureWhattoDo"
...
{context}
{prompt}
Hereisthehistoryofarticlesandtheircorrespondingheadlines:
E12 RetrievedHistoryPreJust {retrieved_data}
Pleasefirstprovideanexplanationforhowyouchosetogenerate
theheadlinewithrespecttothehistoryofpreviousheadlinesandtheirarticles,and
thenthegeneratedheadlinewiththeformat"GeneratedHeadline:"
{context}
{prompt}
Hereisthehistoryofarticlesandtheircorrespondingheadlines:
E13 RetrievedHistoryPostJust {retrieved_data}
Pleaseprovidefirstthegeneratedheadlinewiththeformat"Generated
Headline:"andthenanexplanationforhowyouchosetogenerate
theheadlinewithrespecttothehistoryofpreviousheadlinesandtheirarticles.
{context}
{prompt}
E14 RetrievedHistoryCrossDomainJust Hereisthehistoryofarticle ps la en asd eth he yi pr oc to hr er se is zp eo 5nd exin ag mh pe lea sdl oin fe ws: ha{ tre ot tr hie ev re hd e_ ad da lit na} es.F thir es pt, ei rn soa ndd wit hio on wt ro oc teon ths eid se er hin eg adth lie neh sistoryofpreviousheadlines,
wouldwriteinanotherdomain,likeArt,Science,PoliticsorPopCulture.Then,basedonthehistoryofarticlesandtheircorrespondingheadlinesandthe
insightsyougainedfromreasoningonthehypothesizedheadlines,generatethefinalanswer(theheadlinefortheinitialarticle)withtheformat"GeneratedHeadline:".
{context}
{prompt} Thefakeexplanationsinthiscasearewith
E15 RetrievedHistoryFakeJust Hereisafakehistoryofunrelatedarticlesandtheircorrespondingheadlines: respecttorandomlyselectedexamples.
{fake_retrieved_data}Now,provideanfakeexplanationforhowyouchosetogeneratetheheadlinewithdirect .
referencetothefakehistoryofthegivenpreviousheadlines(thatisdifferentfromtheactuallogicyoufollowedtoreachtheanswer).
{context}
{prompt}
E16 RetrievedHistoryZeroShotCoT Hereisthehistoryofarticlesandtheircorrespondingheadlines:
{retrieved_data}
Let’sthinkstepbystep.
{context}
{prompt}
Hereisthehistoryofarticlesandtheircorrespondingheadlines:{retrieved_data}Pleasefirst
E17 RetrievedHistoryNumericalJust providethegeneratedheadlinewiththeformat"GeneratedHeadline:"Then,youmustanalyzetheimportanceofeachexample
incontributingtoyourfinalgeneratedheadlineinthePythontupleformat:(<example>,<floatimportance>).Theimportanceshouldbeadecimal
numbertotwodecimalplacesrangingfrom0to1,with0implyingnocontributionatallsentimentand1
implyingthehighestcontribution.Allthefloatimportancesshouldsumto1.
12WhyWouldYouSuggestThat?HumanTrustinLanguageModelResponses
Table4.ThemeanROUGE-1andROUGE-Lscoresforeachmethod,testedonGPT-3.5,withaccompanyingone-sigmastandarderror
bars.ThehighestROUGE-1andROUGE-Lscoresineachsubsection(NoHistoryandRetrievedHistory)foreachdatasetarehighlighted
inblue,whilethelowestscoresarehighlightedinred.The"Other"section(EntireandRandomHistory)ishighlightedifthescoresare
higherthaninalltheothersections.
GPT-3.5
Type Method Metric LaMP-4 LaMP-5 LaMP-7
Plain ROUGE-1(↑) 0.133±0.00626 0.409±0.00877 0.322±0.00610
ROUGE-L(↑) 0.117±0.00544 0.335±0.00814 0.267±0.00561
PreJust ROUGE-1(↑) 0.128±0.00605 0.416±0.00890 0.355±0.00676
ROUGE-L(↑) 0.115±0.00535 0.340±0.00837 0.298±0.00621
PostJust ROUGE-1(↑) 0.136±0.00638 0.425±0.00986 0.336±0.00670
ROUGE-L(↑) 0.122±0.00575 0.362±0.00940 0.281±0.00613
NoHistory
CrossDomainJust ROUGE-1(↑) 0.125±0.00570 0.406±0.00950 0.342±0.00679
ROUGE-L(↑) 0.112±0.00510 0.340±0.00902 0.292±0.00635
FakeJust ROUGE-1(↑) 0.127±0.00618 0.313±0.00882 0.351±0.00715
ROUGE-L(↑) 0.113±0.00534 0.271±0.00805 0.294±0.00673
Zero-ShotCoT ROUGE-1(↑) 0.136±0.00655 0.434±0.00962 0.310±0.00596
ROUGE-L(↑) 0.120±0.00574 0.370±0.00928 0.252±0.00556
Few-ShotCoT ROUGE-1(↑) 0.137±0.00639 0.423±0.01053 0.439±0.00705
ROUGE-L(↑) 0.122±0.00565 0.368±0.01033 0.381±0.00681
Plain ROUGE-1(↑) 0.138±0.00614 0.419±0.00953 0.367±0.00648
ROUGE-L(↑) 0.123±0.00551 0.352±0.00899 0.310±0.00609
PreJust ROUGE-1(↑) 0.138±0.00636 0.420±0.00957 0.358±0.00659
ROUGE-L(↑) 0.123±0.00570 0.356±0.00932 0.306±0.00619
PostJust ROUGE-1(↑) 0.143±0.00665 0.443±0.01028 0.375±0.00706
ROUGE-L(↑) 0.130±0.00622 0.383±0.01001 0.321±0.00659
RetrievedHistory
CrossDomainJust ROUGE-1(↑) 0.136±0.00629 0.402±0.01025 0.325±0.00647
ROUGE-L(↑) 0.122±0.00556 0.338±0.00950 0.274±0.00615
FakeJust ROUGE-1(↑) 0.138±0.00644 0.266±0.01036 0.383±0.00727
ROUGE-L(↑) 0.126±0.00594 0.239±0.00957 0.325±0.00678
Zero-ShotCoT ROUGE-1(↑) 0.137±0.00634 0.427±0.01004 0.349±0.00657
ROUGE-L(↑) 0.121±0.00566 0.363±0.00980 0.293±0.00604
NumericalJust ROUGE-1(↑) 0.143±0.00657 0.425±0.01066 0.377±0.00721
ROUGE-L(↑) 0.128±0.00586 0.372±0.01027 0.322±0.00695
EntireHistory ROUGE-1(↑) 0.144±0.00686 0.235±0.01090 0.433±0.00755
ROUGE-L(↑) 0.128±0.00619 0.200±0.00946 0.379±0.00730
Other
RandomHistory ROUGE-1(↑) 0.134±0.00612 0.407±0.00890 0.320±0.00621
ROUGE-L(↑) 0.119±0.00544 0.333±0.00819 0.266±0.00567
13WhyWouldYouSuggestThat?HumanTrustinLanguageModelResponses
Table5.ThemeanROUGE-1andROUGE-Lscoresforeachmethod,testedonGPT-4,withaccompanyingone-sigmastandarderrorbars.
ThehighestROUGE-1andROUGE-Lscoresineachsubsection(NoHistoryandRetrievedHistory)foreachdatasetarehighlightedin
blue,whilethelowestscoresarehighlightedinred.The"Other"section(EntireandRandomHistory)ishighlightedifthescoresare
higherthaninalltheothersections.
GPT-4
Type Method Metric LaMP-4 LaMP-5 LaMP-7
Plain ROUGE-1(↑) 0.123±0.00847 0.389±0.01703 0.268±0.01172
ROUGE-L(↑) 0.110±0.00771 0.313±0.01493 0.224±0.01062
PreJust ROUGE-1(↑) 0.128±0.00834 0.358±0.01648 0.242±0.01279
ROUGE-L(↑) 0.116±0.00734 0.301±0.01539 0.200±0.01125
PostJust ROUGE-1(↑) 0.129±0.00845 0.395±0.01802 0.270±0.01184
ROUGE-L(↑) 0.115±0.00741 0.319±0.01561 0.222±0.01029
NoHistory
CrossDomainJust ROUGE-1(↑) 0.130±0.00832 0.371±0.01672 0.285±0.01288
ROUGE-L(↑) 0.114±0.00732 0.299±0.01500 0.240±0.01208
FakeJust ROUGE-1(↑) 0.131±0.00919 0.387±0.01819 0.260±0.01205
ROUGE-L(↑) 0.115±0.00808 0.311±0.01645 0.210±0.00994
Zero-ShotCoT ROUGE-1(↑) 0.125±0.00836 0.400±0.01783 0.268±0.01217
ROUGE-L(↑) 0.109±0.00724 0.331±0.01660 0.215±0.00964
Few-ShotCoT ROUGE-1(↑) 0.135±0.00947 0.401±0.01819 0.341±0.01414
ROUGE-L(↑) 0.117±0.00827 0.321±0.01610 0.294±0.01330
Plain ROUGE-1(↑) 0.139±0.0092 0.400±0.01769 0.283±0.01189
ROUGE-L(↑) 0.126±0.00863 0.319±0.01642 0.232±0.01031
PreJust ROUGE-1(↑) 0.141±0.00957 0.397±0.01881 0.279±0.01335
ROUGE-L(↑) 0.129±0.00893 0.336±0.01808 0.229±0.01188
PostJust ROUGE-1(↑) 0.150±0.01000 0.438±0.01946 0.273±0.01245
ROUGE-L(↑) 0.138±0.00941 0.351±0.01727 0.226±0.01109
RetrievedHistory
CrossDomainJust ROUGE-1(↑) 0.144±0.00905 0.400±0.01838 0.177±0.01636
ROUGE-L(↑) 0.129±0.00791 0.325±0.01593 0.142±0.01367
FakeJust ROUGE-1(↑) 0.139±0.00953 0.401±0.01893 0.277±0.01155
ROUGE-L(↑) 0.125±0.00856 0.332±0.01743 0.232±0.01077
Zero-ShotCoT ROUGE-1(↑) 0.135±0.00890 0.402±0.01757 0.272±0.01276
ROUGE-L(↑) 0.122±0.00823 0.331±0.01666 0.226±0.01132
NumericalJust ROUGE-1(↑) 0.143±0.01001 0.426±0.01874 0.290±0.01285
ROUGE-L(↑) 0.130±0.00929 0.343±0.01708 0.239±0.01147
EntireHistory ROUGE-1(↑) 0.146±0.00948 0.381±0.01707 0.319±0.01534
ROUGE-L(↑) 0.133±0.00877 0.311±0.01574 0.280±0.01501
Other
RandomHistory ROUGE-1(↑) 0.122±0.00851 0.383±0.01750 0.260±0.01132
ROUGE-L(↑) 0.110±0.00790 0.303±0.01509 0.217±0.01039
14WhyWouldYouSuggestThat?HumanTrustinLanguageModelResponses
Figure4.BarGraphvisualizationoftheresultsinTable Figure5.BarGraphvisualizationoftheresultsinTable
4forLaMP-4,LaMP-5andLaMP-7forGPT-3.5.The 5forLaMP-4,LaMP-5andLaMP-7forGPT-4. The
randomhistorybaselineisvisualizedasadottedlineto randomhistorybaselineisvisualizedasadottedlineto
compareotherresultsto. compareotherresultsto.
15WhyWouldYouSuggestThat?HumanTrustinLanguageModelResponses
Figure6. Participantagedistribution.
Figure8. Participanteducationdistribution.
Figure7.Participant gender distribution. N=3 for groups other
thanmale/female,sowedidnotperformstatisticaltestsforthose
groups.
16WhyWouldYouSuggestThat?HumanTrustinLanguageModelResponses
Figure9.Participantcomputerscienceexperiencedistribution.
Figure10. ParticipantexperiencewithLLMs.
17WhyWouldYouSuggestThat?HumanTrustinLanguageModelResponses
Figure11.Participantself-reportedexperiencewithAI-generated
content.
18