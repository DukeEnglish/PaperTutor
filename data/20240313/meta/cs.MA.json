[
    {
        "title": "Transforming Competition into Collaboration: The Revolutionary Role of Multi-Agent Systems and Language Models in Modern Organizations",
        "authors": "Carlos Jose Xavier Cruz",
        "links": "http://arxiv.org/abs/2403.07769v1",
        "entry_id": "http://arxiv.org/abs/2403.07769v1",
        "pdf_url": "http://arxiv.org/pdf/2403.07769v1",
        "summary": "This article explores the dynamic influence of computational entities based\non multi-agent systems theory (SMA) combined with large language models (LLM),\nwhich are characterized by their ability to simulate complex human\ninteractions, as a possibility to revolutionize human user interaction from the\nuse of specialized artificial agents to support everything from operational\norganizational processes to strategic decision making based on applied\nknowledge and human orchestration. Previous investigations reveal that there\nare limitations, particularly in the autonomous approach of artificial agents,\nespecially when dealing with new challenges and pragmatic tasks such as\ninducing logical reasoning and problem solving. It is also considered that\ntraditional techniques, such as the stimulation of chains of thoughts, require\nexplicit human guidance. In our approach we employ agents developed from large\nlanguage models (LLM), each with distinct prototyping that considers behavioral\nelements, driven by strategies that stimulate the generation of knowledge based\non the use case proposed in the scenario (role-play) business, using a\ndiscussion approach between agents (guided conversation). We demonstrate the\npotential of developing agents useful for organizational strategies, based on\nmulti-agent system theories (SMA) and innovative uses based on large language\nmodels (LLM based), offering a differentiated and adaptable experiment to\ndifferent applications, complexities, domains, and capabilities from LLM.",
        "updated": "2024-03-12 15:56:10 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.07769v1"
    },
    {
        "title": "Ariadne and Theseus: Exploration and Rendezvous with Two Mobile Agents in an Unknown Graph",
        "authors": "Romain Cosson",
        "links": "http://arxiv.org/abs/2403.07748v1",
        "entry_id": "http://arxiv.org/abs/2403.07748v1",
        "pdf_url": "http://arxiv.org/pdf/2403.07748v1",
        "summary": "We investigate two fundamental problems in mobile computing: exploration and\nrendezvous, with two distinct mobile agents in an unknown graph. The agents can\nread and write information on whiteboards that are located at all nodes. They\nboth move along one adjacent edge at every time-step. In the exploration\nproblem, both agents start from the same node of the graph and must traverse\nall of its edges. We show that a simple variant of depth-first search achieves\ncollective exploration in $m$ synchronous time-steps, where $m$ is the number\nof edges of the graph. This improves the competitive ratio of collective graph\nexploration. In the rendezvous problem, the agents start from different nodes\nof the graph and must meet as fast as possible. We introduce an algorithm\nguaranteeing rendezvous in at most $\\frac{3}{2}m$ time-steps. This improves\nover the so-called `wait for Mommy' algorithm which requires $2m$ time-steps.\nAll our guarantees are derived from a more general asynchronous setting in\nwhich the speeds of the agents are controlled by an adversary at all times. Our\nguarantees also generalize to weighted graphs, if the number of edges $m$ is\nreplaced by the sum of all edge lengths.",
        "updated": "2024-03-12 15:33:09 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.07748v1"
    },
    {
        "title": "Asynchronous Approximate Byzantine Consensus: A Multi-hop Relay Method and Tight Graph Conditions",
        "authors": "Liwei YuanHideaki Ishii",
        "links": "http://arxiv.org/abs/2403.07640v1",
        "entry_id": "http://arxiv.org/abs/2403.07640v1",
        "pdf_url": "http://arxiv.org/pdf/2403.07640v1",
        "summary": "We study a multi-agent resilient consensus problem, where some agents are of\nthe Byzantine type and try to prevent the normal ones from reaching consensus.\nIn our setting, normal agents communicate with each other asynchronously over\nmulti-hop relay channels with delays. To solve this asynchronous Byzantine\nconsensus problem, we develop the multi-hop weighted mean subsequence reduced\n(MW-MSR) algorithm. The main contribution is that we characterize a tight graph\ncondition for our algorithm to achieve Byzantine consensus, which is expressed\nin the novel notion of strictly robust graphs. We show that the multi-hop\ncommunication is effective for enhancing the network's resilience against\nByzantine agents. As a result, we also obtain novel conditions for resilient\nconsensus under the malicious attack model, which are tighter than those known\nin the literature. Furthermore, the proposed algorithm can be viewed as a\ngeneralization of the conventional flooding-based algorithms, with less\ncomputational complexity. Lastly, we provide numerical examples to show the\neffectiveness of the proposed algorithm.",
        "updated": "2024-03-12 13:24:19 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.07640v1"
    },
    {
        "title": "Ensembling Prioritized Hybrid Policies for Multi-agent Pathfinding",
        "authors": "Huijie TangFederico BertoJinkyoo Park",
        "links": "http://arxiv.org/abs/2403.07559v1",
        "entry_id": "http://arxiv.org/abs/2403.07559v1",
        "pdf_url": "http://arxiv.org/pdf/2403.07559v1",
        "summary": "Multi-Agent Reinforcement Learning (MARL) based Multi-Agent Path Finding\n(MAPF) has recently gained attention due to its efficiency and scalability.\nSeveral MARL-MAPF methods choose to use communication to enrich the information\none agent can perceive. However, existing works still struggle in structured\nenvironments with high obstacle density and a high number of agents. To further\nimprove the performance of the communication-based MARL-MAPF solvers, we\npropose a new method, Ensembling Prioritized Hybrid Policies (EPH). We first\npropose a selective communication block to gather richer information for better\nagent coordination within multi-agent environments and train the model with a\nQ-learning-based algorithm. We further introduce three advanced inference\nstrategies aimed at bolstering performance during the execution phase. First,\nwe hybridize the neural policy with single-agent expert guidance for navigating\nconflict-free zones. Secondly, we propose Q value-based methods for prioritized\nresolution of conflicts as well as deadlock situations. Finally, we introduce a\nrobust ensemble method that can efficiently collect the best out of multiple\npossible solutions. We empirically evaluate EPH in complex multi-agent\nenvironments and demonstrate competitive performance against state-of-the-art\nneural methods for MAPF.",
        "updated": "2024-03-12 11:47:12 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.07559v1"
    },
    {
        "title": "Bigraph Matching Weighted with Learnt Incentive Function for Multi-Robot Task Allocation",
        "authors": "Steve PaulNathan MaurerSouma Chowdhury",
        "links": "http://arxiv.org/abs/2403.07131v1",
        "entry_id": "http://arxiv.org/abs/2403.07131v1",
        "pdf_url": "http://arxiv.org/pdf/2403.07131v1",
        "summary": "Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and\nefficient decision-making, which is often achieved using heuristics-aided\nmethods such as genetic algorithms, auction-based methods, and bipartite graph\nmatching methods. These methods often assume a form that lends better\nexplainability compared to an end-to-end (learnt) neural network based policy\nfor MRTA. However, deriving suitable heuristics can be tedious, risky and in\nsome cases impractical if problems are too complex. This raises the question:\ncan these heuristics be learned? To this end, this paper particularly develops\na Graph Reinforcement Learning (GRL) framework to learn the heuristics or\nincentives for a bipartite graph matching approach to MRTA. Specifically a\nCapsule Attention policy model is used to learn how to weight task/robot\npairings (edges) in the bipartite graph that connects the set of tasks to the\nset of robots. The original capsule attention network architecture is\nfundamentally modified by adding encoding of robots' state graph, and two\nMultihead Attention based decoders whose output are used to construct a\nLogNormal distribution matrix from which positive bigraph weights can be drawn.\nThe performance of this new bigraph matching approach augmented with a\nGRL-derived incentive is found to be at par with the original bigraph matching\napproach that used expert-specified heuristics, with the former offering\nnotable robustness benefits. During training, the learned incentive policy is\nfound to get initially closer to the expert-specified incentive and then\nslightly deviate from its trend.",
        "updated": "2024-03-11 19:55:08 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.07131v1"
    }
]