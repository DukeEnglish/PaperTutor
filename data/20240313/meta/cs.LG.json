[
    {
        "title": "TeleMoMa: A Modular and Versatile Teleoperation System for Mobile Manipulation",
        "authors": "Shivin DassWensi AiYuqian JiangSamik SinghJiaheng HuRuohan ZhangPeter StoneBen AbbatematteoRoberto Martin-Martin",
        "links": "http://arxiv.org/abs/2403.07869v1",
        "entry_id": "http://arxiv.org/abs/2403.07869v1",
        "pdf_url": "http://arxiv.org/pdf/2403.07869v1",
        "summary": "A critical bottleneck limiting imitation learning in robotics is the lack of\ndata. This problem is more severe in mobile manipulation, where collecting\ndemonstrations is harder than in stationary manipulation due to the lack of\navailable and easy-to-use teleoperation interfaces. In this work, we\ndemonstrate TeleMoMa, a general and modular interface for whole-body\nteleoperation of mobile manipulators. TeleMoMa unifies multiple human\ninterfaces including RGB and depth cameras, virtual reality controllers,\nkeyboard, joysticks, etc., and any combination thereof. In its more accessible\nversion, TeleMoMa works using simply vision (e.g., an RGB-D camera), lowering\nthe entry bar for humans to provide mobile manipulation demonstrations. We\ndemonstrate the versatility of TeleMoMa by teleoperating several existing\nmobile manipulators - PAL Tiago++, Toyota HSR, and Fetch - in simulation and\nthe real world. We demonstrate the quality of the demonstrations collected with\nTeleMoMa by training imitation learning policies for mobile manipulation tasks\ninvolving synchronized whole-body motion. Finally, we also show that TeleMoMa's\nteleoperation channel enables teleoperation on site, looking at the robot, or\nremote, sending commands and observations through a computer network, and\nperform user studies to evaluate how easy it is for novice users to learn to\ncollect demonstrations with different combinations of human interfaces enabled\nby our system. We hope TeleMoMa becomes a helpful tool for the community\nenabling researchers to collect whole-body mobile manipulation demonstrations.\nFor more information and video results,\nhttps://robin-lab.cs.utexas.edu/telemoma-web.",
        "updated": "2024-03-12 17:58:01 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.07869v1"
    },
    {
        "title": "Exploring Safety Generalization Challenges of Large Language Models via Code",
        "authors": "Qibing RenChang GaoJing ShaoJunchi YanXin TanWai LamLizhuang Ma",
        "links": "http://arxiv.org/abs/2403.07865v1",
        "entry_id": "http://arxiv.org/abs/2403.07865v1",
        "pdf_url": "http://arxiv.org/pdf/2403.07865v1",
        "summary": "The rapid advancement of Large Language Models (LLMs) has brought about\nremarkable capabilities in natural language processing but also raised concerns\nabout their potential misuse. While strategies like supervised fine-tuning and\nreinforcement learning from human feedback have enhanced their safety, these\nmethods primarily focus on natural languages, which may not generalize to other\ndomains. This paper introduces CodeAttack, a framework that transforms natural\nlanguage inputs into code inputs, presenting a novel environment for testing\nthe safety generalization of LLMs. Our comprehensive studies on\nstate-of-the-art LLMs including GPT-4, Claude-2, and Llama-2 series reveal a\ncommon safety vulnerability of these models against code input: CodeAttack\nconsistently bypasses the safety guardrails of all models more than 80\\% of the\ntime. Furthermore, we find that a larger distribution gap between CodeAttack\nand natural language leads to weaker safety generalization, such as encoding\nnatural language input with data structures or using less popular programming\nlanguages. These findings highlight new safety risks in the code domain and the\nneed for more robust safety alignment algorithms to match the code capabilities\nof LLMs.",
        "updated": "2024-03-12 17:55:38 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.07865v1"
    },
    {
        "title": "Fairness Feedback Loops: Training on Synthetic Data Amplifies Bias",
        "authors": "Sierra WyllieIlia ShumailovNicolas Papernot",
        "links": "http://arxiv.org/abs/2403.07857v1",
        "entry_id": "http://arxiv.org/abs/2403.07857v1",
        "pdf_url": "http://arxiv.org/pdf/2403.07857v1",
        "summary": "Model-induced distribution shifts (MIDS) occur as previous model outputs\npollute new model training sets over generations of models. This is known as\nmodel collapse in the case of generative models, and performative prediction or\nunfairness feedback loops for supervised models. When a model induces a\ndistribution shift, it also encodes its mistakes, biases, and unfairnesses into\nthe ground truth of its data ecosystem. We introduce a framework that allows us\nto track multiple MIDS over many generations, finding that they can lead to\nloss in performance, fairness, and minoritized group representation, even in\ninitially unbiased datasets. Despite these negative consequences, we identify\nhow models might be used for positive, intentional, interventions in their data\necosystems, providing redress for historical discrimination through a framework\ncalled algorithmic reparation (AR). We simulate AR interventions by curating\nrepresentative training batches for stochastic gradient descent to demonstrate\nhow AR can improve upon the unfairnesses of models and data ecosystems subject\nto other MIDS. Our work takes an important step towards identifying,\nmitigating, and taking accountability for the unfair feedback loops enabled by\nthe idea that ML systems are inherently neutral and objective.",
        "updated": "2024-03-12 17:48:08 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.07857v1"
    },
    {
        "title": "Quantum Support Vector Machine for Prostate Cancer Detection: A Performance Analysis",
        "authors": "Walid El MaouakiTaoufik SaidMohamed Bennai",
        "links": "http://arxiv.org/abs/2403.07856v1",
        "entry_id": "http://arxiv.org/abs/2403.07856v1",
        "pdf_url": "http://arxiv.org/pdf/2403.07856v1",
        "summary": "This study addresses the urgent need for improved prostate cancer detection\nmethods by harnessing the power of advanced technological solutions. We\nintroduce the application of Quantum Support Vector Machine (QSVM) to this\ncritical healthcare challenge, showcasing an enhancement in diagnostic\nperformance over the classical Support Vector Machine (SVM) approach. Our study\nnot only outlines the remarkable improvements in diagnostic performance made by\nQSVM over the classic SVM technique, but it delves into the advancements\nbrought about by the quantum feature map architecture, which has been carefully\nidentified and evaluated, ensuring it aligns seamlessly with the unique\ncharacteristics of our prostate cancer dataset. This architecture succeded in\ncreating a distinct feature space, enabling the detection of complex,\nnon-linear patterns in the data. The findings reveal not only a comparable\naccuracy with classical SVM ($92\\%$) but also a $7.14\\%$ increase in\nsensitivity and a notably high F1-Score ($93.33\\%$). This study's important\ncombination of quantum computing in medical diagnostics marks a pivotal step\nforward in cancer detection, offering promising implications for the future of\nhealthcare technology.",
        "updated": "2024-03-12 17:46:38 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.07856v1"
    },
    {
        "title": "Distilling the Knowledge in Data Pruning",
        "authors": "Emanuel Ben-BaruchAdam BotachIgor KviatkovskyManoj AggarwalGérard Medioni",
        "links": "http://arxiv.org/abs/2403.07854v1",
        "entry_id": "http://arxiv.org/abs/2403.07854v1",
        "pdf_url": "http://arxiv.org/pdf/2403.07854v1",
        "summary": "With the increasing size of datasets used for training neural networks, data\npruning becomes an attractive field of research. However, most current data\npruning algorithms are limited in their ability to preserve accuracy compared\nto models trained on the full data, especially in high pruning regimes. In this\npaper we explore the application of data pruning while incorporating knowledge\ndistillation (KD) when training on a pruned subset. That is, rather than\nrelying solely on ground-truth labels, we also use the soft predictions from a\nteacher network pre-trained on the complete data. By integrating KD into\ntraining, we demonstrate significant improvement across datasets, pruning\nmethods, and on all pruning fractions. We first establish a theoretical\nmotivation for employing self-distillation to improve training on pruned data.\nThen, we empirically make a compelling and highly practical observation: using\nKD, simple random pruning is comparable or superior to sophisticated pruning\nmethods across all pruning regimes. On ImageNet for example, we achieve\nsuperior accuracy despite training on a random subset of only 50% of the data.\nAdditionally, we demonstrate a crucial connection between the pruning factor\nand the optimal knowledge distillation weight. This helps mitigate the impact\nof samples with noisy labels and low-quality images retained by typical pruning\nalgorithms. Finally, we make an intriguing observation: when using lower\npruning fractions, larger teachers lead to accuracy degradation, while\nsurprisingly, employing teachers with a smaller capacity than the student's may\nimprove results. Our code will be made available.",
        "updated": "2024-03-12 17:44:45 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.07854v1"
    }
]