pyvene: A Library for Understanding and Improving PyTorch Models
via Interventions
ZhengxuanWu†, AtticusGeiger‡, AryamanArora†, JingHuang†, ZhengWang†,
NoahD.Goodman†, ChristopherD.Manning†, ChristopherPotts†
†StanfordUniversity ‡Pr(Ai)2RGroup
{wuzhengx,atticusg,aryamana,hij,peterwz,ngd,manning,cgpotts}@stanford.edu
Abstract
Interventionsonmodel-internalstatesarefun-
damental operations in many areas of AI, in-
cluding model editing, steering, robustness,
andinterpretability. Tofacilitatesuchresearch,
weintroducepyvene,anopen-sourcePython
library that supports customizable interven-
tionsonarangeofdifferentPyTorchmodules.
pyvenesupportscomplexinterventionschemes
withanintuitiveconfigurationformat,andits
interventionscanbestaticorincludetrainable
parameters. Weshowhowpyveneprovidesa
unifiedandextensibleframeworkforperform-
ing interventions on neural models and shar-
ing the intervened upon models with others.
We illustrate the power of the library via in-
terpretabilityanalysesusingcausalabstraction
and knowledge localization. We publish our
librarythroughPythonPackageIndex(PyPI)
andprovidecode,documentation,andtutorials
athttps://github.com/stanfordnlp/pyvene.
1 Introduction
Whenweinterveneonaneuralnetwork,wemake
Figure 1: An inference-time intervention (Li et al.,
an in-place change to its activations, putting the
2023a)onTinyStories-33M.Themodelisprompted
model in a counterfactual state. This fundamen-
with“Onceuponatimetherewasa”,andisaskedto
tal operation has emerged as a powerful tool for completethestory.Weaddastaticwordembedding(for
both understanding and improving models; inter- “happy”or“sad”)intotheMLPoutputateachdecoding
ventionsofvariouskindsarekeytorecentefforts step for all layers with a coefficient of 0.3. pyvene’s
completeimplementationisprovided. Theoriginaland
inmodelrobustness(Heetal.,2019),modeledit-
intervenedgenerationsusegreedydecoding.
ing (Meng et al., 2022) and steering (Li et al.,
2023a), causal abstraction (Geiger et al., 2020,
2021, 2023; Wu et al., 2023) or activation patch-
ing(Chanetal.,2022;Wangetal.,2023),circuit etal.2023;Geigeretal.2023asexamples)thatlack
finding(Conmyetal.,2023;Goldowsky-Dilletal., extensibility and are hard to maintain and share,
2023),andknowledgetracing(Gevaetal.,2023). andcurrenttoolkitsfocusonsingleornon-nested
Asintervention-basedtechniqueshavematured, interventions(e.g.,ablationneuronsinasinglefor-
theneedhasarisentorunevermorecomplexinter- ward pass) and are often limited to interventions
ventionsoneverlargermodels. Currently,thereis onTransformers(Vaswanietal.,2017)withoutna-
nounifiedandgenericintervention-orientedlibrary tivelysupportingotherneuralarchitectures. Some
tosupportsuchresearch. Existinglibrariesareof- oftheseexistinglibraries(Bau,2022;Lloyd,2023;
tenproject-based(seeimplementationsforWang Fiotto-Kaufman,2023;Mossingetal.,2024)can
1
4202
raM
21
]GL.sc[
1v90870.3042:viXrasupportcomplexinterventionssuchasexchanging PythonPackageIndex(PyPI),1andtheprojectsite2
activationsacrossmultipleforwardpassesyetthey hostsmorethan20tutorialsthatcoverinterventions
requiresophisticatedknowledgeandheavyimple- atdifferentlevelsofcomplexitywithvariousmodel
mentations. architectures from simple feed-foward models to
To address these limitations, we introduce multi-modalmodels.
pyvene, an open-source Python library that sup-
portscustomizableinterventionsondifferentneu- 2 SystemDesignandArchitecture
ral architectures implemented in PyTorch. Dif-
Two primary components of pyvene are the in-
ferentfrompreviouslibraries(Bau,2022;Nanda
tervenable configuration, which outlines which
and Bloom, 2022; Lloyd, 2023; Fiotto-Kaufman,
model components will be intervened upon, and
2023;Mossingetal.,2024),pyveneisintervention-
theintervenablemodel,whichdecoratestheorigi-
oriented. Itsupportscomplexinterventionsbyma-
naltorchmodelwithhooksthatallowactivations
nipulatingorexchangingactivationsacrossmulti-
to be collected and overwritten.3 Here is a setup
plemodelforwardrunswhileallowingtheseinter-
forperformingazero-outintervention(oftencalled
ventionstobesharedwithaserializationconfigu-
azeroablation;Lietal.2023b)onthe10th,11th,
ration file. Specifically, pyvene has a number of
and 12th dimensions of the MLP output for 3rd
advantages:
tokenembeddingoflayer0inGPT-2:
1. Interventionastheprimitive. Theinterven-
tion is the basic primitive of pyvene. Inter- import torch
import pyvene as pv
ventionsarespecifiedwithadict-basedfor- # built-in helper to get a HuggingFace model
_, tokenizer, gpt2 = pv.create_gpt2()
mat,incontrasttopreviousapproacheswhere
# create with dict-based config
interventionsareexpressedascodeandexe- pv_config = pv.IntervenableConfig({
"layer": 0,
cutedduringruntime(Bau,2022;Lloyd,2023; "component": "mlp_output",
"intervention_type": pv.VanillaIntervention})
Fiotto-Kaufman,2023;Mossingetal.,2024). # initialize model
All pyvene intervention schemes and mod- pv_gpt2 = pv.IntervenableModel(
pv_config, model=gpt2)
elsareserializableobjectsthatcanbeshared # run an intervened forward pass
intervened_outputs = pv_gpt2(
throughapublicmodelhubsuchasHugging- # the base input
base=tokenizer(
Face.
"The capital of Spain is",
return_tensors="pt"),
# the location to intervene at (3rd token)
2. Complexinterventionschemes. pyvenesup-
unit_locations={"base": 3},
ports interventions at multiple locations, in- # the individual dimensions targetted
subspaces=[10,11,12],
volving arbitrary subsets of neurons, and in- # the intervention values
source_representations=torch.zeros(
terventionscanbeperformedinparallelorin
gpt2.config.n_embd)
sequence. ForgenerativeuseofLMs,pyvene )
# sharing
supportsinterventionsatdecodingsteps. Fur- pv_gpt2.save("./tmp/", save_to_hf_hub=True)
thermore,activationscaneasilybecollected
The model takes a tensor input base and runs
forprobetraining.
throughthemodel’scomputationgraphmodifying
3. Support for recurrent and non-recurrent activationsinplacetobeothervaluessource. In
models. Existinglibrariesofferonlylimited
thiscode,wespecifiedsourceintheforwardcall.
support for recurrent models. pyvene sup- Whensourceisaconstant,itcanalternativelybe
ports simple feed-forward networks, Trans- specified in the IntervenableConfig. To target
formers,andrecurrentandconvolutionalneu- completeMLPoutputrepresentations,onesimply
ralmodels. leavesoutthesubspacesargument. Thefinalline
ofthecodeblockshowshowtoserializeandshare
Inthispaper,weprovidetwodetailedcasestud- anintervenedmodelremotelythroughamodelhub
ies using pyvene as well: (1) we fully reproduce suchasHuggingFace.
Mengetal.(2022)’slocatingfactualassociationsin
GPT2-XL(Figure1intheoriginalpaper)inabout 1pip install pyvene
20 lines of code, and (2) we show intervention
2https://github.com/stanfordnlp/pyvene
3CodesnippetsprovidedinthepapercanberunonGoogle
andprobetrainingwithpyvenetolocalizegender
Colab at https://colab.research.google.com/github/
inPythia-6.9B.pyveneispublishedthroughthe stanfordnlp/pyvene/blob/main/pyvene_101.ipynb.
22.1 InterchangeInterventions basisfortrainingmodelstoberobusttothisnoising
process.
Interchangeinterventions(Geigeretal.,2020;Vig
etal.,2020;Wangetal.,2023,alsoknownasacti-
2.3 ActivationCollectionInterventions
vationpatching)fixactivationstotakeonthevalues
Thisisapass-throughinterventiontocollectactiva-
they would be if a different input were provided.
tions for operations like supervised probe train-
With minor changes to the forward call, we can
ing. Such interventions can be combined with
performaninterchangeinterventiononGPT-2:
otherinterventionsaswell,tosupportthingslike
causal structural probes (Hewitt and Manning,
# run an interchange intervention
intervened_outputs = pv_gpt2( 2019; Elazaret al., 2020; Leporiet al., 2023). In
# the base input
base=tokenizer( thefollowingexample,weperformaninterchange
"The capital of Spain is",
interventionatlayer8andthencollectactivations
return_tensors = "pt"),
# the source input atlayer10forthepurposesoffittingaprobe:
sources=tokenizer(
"The capital of Italy is",
return_tensors = "pt"),
# set up a upstream intervention
# the location to intervene at (3rd token)
probe_config = pv.IntervenableConfig({
unit_locations={"sources->base": 3},
"layer": 8,
# the individual dimensions targeted
"component": "block_output",
subspaces=[10,11,12]
"intervention_type": pv.VanillaIntervention})
)
# add downstream collector
probe_config = probe_config.add_intervention({
This forward call produces outputs for base but "layer": 10,
"component": "block_output",
withtheactivationvaluesforMLPoutputdimen- "intervention_type": pv.CollectIntervention})
sions10–12oftoken3atlayer0settothosethatob- probe_gpt2 = pv.IntervenableModel(
probe_config, model=gpt2)
tainedwhenthemodelprocessesthesource. Such # return the activations for 3rd token
collected_activations = probe_gpt2(
interventionsareusedininterpretabilityresearchto base=tokenizer(
"The capital of Spain is",
testhypothesesaboutwhereandhowinformation
return_tensors="pt"),
isstoredinmodel-internalrepresentations. unit_locations={"sources->base": 3})
2.2 AdditionInterventions 2.4 CustomInterventions
In the above examples, we replace values in the pyveneprovidesaflexiblewayofaddingnewinter-
base with other values (VanillaIntervention). ventiontypes. Thefollowingisasimpleillustration
Anothercommonkindofinterventioninvolvesup- inwhichwemultiplytheoriginalrepresentationby
datingthebasevaluesinasystematicway: aconstantvalue:
noising_config = pv.IntervenableConfig({ # multiply base with a constant
"layer": 0, class MultInt(pv.ConstantSourceIntervention):
"component": "block_input", def __init__(self, **kwargs):
"intervention_type": pv.AdditionIntervention}) super().__init__()
noising_gpt2 = pv.IntervenableModel( def forward(self, base, source=None,
config, model=gpt2) subspaces=None):
intervened_outputs = noising_gpt2( return base * 0.3
base=tokenizer(
"The Space Needle is in downtown", pv.IntervenableModel({
return_tensors = "pt"), "intervention_type": MultInt},
# target the first four tokens for intervention model=gpt2)
unit_locations={"base": [0, 1, 2, 3]},
source_representations = torch.rand( Theaboveinterventionbecomesusefulwhenstudy-
gpt2.config.n_embd, requires_grad=False))
inginterpretability-drivenmodelssuchastheBack-
As in this example, we add noise to a represen- packLMsofHewittetal.(2023). Thesensevectors
tation as a basic robustness check. The code acquiredduringpretraininginBackpackLMshave
above does this, targetting the first four input beenshowntohavea“multiplicationeffect”,and
token embeddings to a Transformer by using so proportionally decreasing sense vectors could
AdditionIntervention. Thisexampleservesas effectivelysteerthemodel’sgeneration.
thebuildingblockofcausaltracingexperimentsas
2.5 TrainableInterventions
inMengetal.2022,wherewecorruptembedding
inputsbyaddingnoisetotracefactualassociations. pyveneinterventionscanincludetrainableparam-
Buildingontopofthis,wereproduceMengetal.’s eters. RotatedSpaceIntervention implements
result in Section 3. pyvene allows Autograd on DistributedAlignmentSearch(DAS;Geigeretal.
thestaticrepresentations,sothiscodecouldbethe 2023),LowRankRotatedSpaceInterventionisa
3more efficient version of that model, and examplesandswappingthemintothebase’scom-
BoundlessRotatedSpaceIntervention imple- putationgraph:
ments the Boundless DAS variant of Wu et al.
(2023). Withtheseprimitives,onecaneasilytrain parallel_config = pv.IntervenableConfig([
{"layer": 3, "component": "block_output"},
DASexplainers. {"layer": 3, "component": "block_output"}],
# intervene on base at the same time
Intheexamplebelow,weshowasinglegradient mode="parallel")
updateforaDAStrainingobjectivethatlocalizes
parallel_gpt2 = pv.IntervenableModel(
the capital associated with the country in a one- parallel_config, model=gpt2)
dimensional linear subspace of activations from base = tokenizer(
"The capital of Spain is",
the Transformer block output (i.e., main residual
return_tensors="pt")
stream)atthe8thlayerbytrainingourintervention sources = [
tokenizer("The language of Spain is",
moduletomatchthegoldcounterfactualbehavior: return_tensors="pt"),
tokenizer("The capital of Italy is",
return_tensors="pt")]
das_config = pv.IntervenableConfig({
"layer": 8, intervened_outputs = parallel_gpt2(
"component": "block_output", base, sources,
"low_rank_dimension": 1, {"sources->base": (
"intervention_type": # each list has a dimensionality of
pv.LowRankRotatedSpaceIntervention}) # [num_intervention, batch, num_unit]
[[[1]],[[3]]], [[[1]],[[3]]])}
das_gpt2 = pv.IntervenableModel( )
das_config, model=gpt2)
In the example above, we interchange the activa-
last_hidden_state = das_gpt2(
base=tokenizer( tionsfromtheresidualstreamsontopofthesecond
"The capital of Spain is",
return_tensors="pt"), tokenfromthefirstexample(“language”)aswellas
sources=tokenizer(
thefourthtokenfromthesecondexample(“Italy”)
"The capital of Italy is",
return_tensors="pt"), intothecorrespondinglocationsofthebase’scom-
unit_locations={"sources->base": 3}
)[-1].last_hidden_state[:,-1] putation graph. The motivating intuition is that
nowthenexttokenmightbemappedtoasemantic
# gold counterfacutual label as " Rome"
label = tokenizer.encode( spacethatisamixtureoftwoinputsinthesource
" Rome", return_tensors="pt")
logits = torch.matmul( “ThelanguageofItaly”. (And,infact,“Italian”is
last_hidden_state, gpt2.wte.weight.t())
amongthetopfivereturnedlogits.)
m = torch.nn.CrossEntropyLoss()
loss = m(logits, label.view(-1))
loss.backward() 2.8 Multi-SourceSerialInterventions
Interventionscanalsobesequentiallyapplied,so
2.6 TrainingwithInterventions thatlaterinterventionsareappliedtoanintervened
modelcreatedbythepreviousones:
Interventionscanbeco-trainedwiththeintervening
modelfortechniqueslikeinterchangeintervention
serial_config = pv.IntervenableConfig([
training(IIT),whichinducespecificcausalstruc- {"layer": 3, "component": "block_output"},
{"layer": 10, "component": "block_output"}],
turesinneuralnetworks(Geigeretal.,2022):
# intervene on base one after another
mode="serial")
pv_gpt2 = pv.IntervenableModel({ serial_gpt2 = pv.IntervenableModel(
"layer": 8}, serial_config, model=gpt2)
model=gpt2)
# enable gradients on the model intervened_outputs = serial_gpt2(
pv_gpt2.enable_model_gradients() base, sources,
# run counterfactual forward as usual # src_0 intervenes on src_1 position 1
# src_1 intervenes on base position 4
{"source_0->source_1": 1,
Intheexampleabove,withthesupervisionsignals
"source_1->base" : 4}
fromthetrainingdataset, weinducecausalstruc- )
turesintheresidualstreamat8thlayer.
Intheexampleabove,wefirsttakeactivationsatthe
residualstreamofthefirsttoken(“language”)atthe
2.7 Multi-SourceParallelInterventions
3rdlayerfromthefirstsourceexampleandswap
In the parallel mode, interventions are applied to themintothesamelocationduringtheforwardrun
thecomputationgraphofthesamebaseexample of the second source example. We then take the
atthesametime. Wecanperforminterchangeinter- activations of the 4th token (“is”) at layer 10 at
ventionsbytakingactivationsfrommultiplesource upstreamofthisintervenedmodelandswapthem
4intothesamelocationduringtheforwardrunofthe results. Specifically, we restore the Transformer
baseexample. Themotivatingintuitionisthatthe blockoutput,MLPactivation,andattentionoutput
firstinterventionwillresultinthemodelretrieving for each token at each layer. For MLP activation
“The language of Italy” and the second interven- andattentionoutput,werestore10sitescentered
tionwillswaptheretrievedanswerintotheoutput aroundtheinterveninglayer(clippingontheedges).
streamofthebaseexample. (Onceagain,“Italian” Our Figure 2 fully reproduces the main Figure 1
isamongthetopfivereturnedlogits.) (p.2)inMengetal.’spaper. Toreplicatetheirex-
periments,wefirstdefineaconfigurationforcausal
2.9 IntervenableModel
tracing:
TheIntervenableModelclassisthebackendfor
decoratingtorchmodelswithintervenableconfig- def tracing_config(
l, c="mlp_activation", w=10, tl=48):
urations and running intervened forward calls. It s = max(0, l - w // 2)
e = min(tl, l - (-w // 2))
implementstwotypesofhooks: GetterandSetter config = IntervenableConfig(
[{"component": "block_input"}] +
hookstosaveandsetactivations.
[{"layer": l, "component": c}
Figure 1 highlights pyvene’s support for LMs. for l in range(s, e)],
[pv.NoiseIntervention] +
Interventionscanbeappliedtoanypositioninthe [pv.VanillaIntervention]*(e-s))
return config
inputpromptoranyselecteddecodingstep.
Thefollowinginvolvesamodelwithrecurrent Withthisconfiguration,wecorruptthesubjectto-
(GRU) cells where we intervene on two unrolled kenandthenrestoreselectedinternalactivationsto
recurrentcomputationgraphsatatimestep: their clean value. Our main experiment is imple-
mentedwithabout20linesofcodewithpyvene:
# built-in helper to get a GRU
_, _, gru = pv.create_gru_classifier(
trace_results = []
pv.GRUConfig(h_dim=32))
_, tokenizer, gpt = pv.create_gpt2("gpt2-xl")
# wrap it with config
base = tokenizer(
pv_gru = pv.IntervenableModel({
"The Space Needle is in downtown",
"component": "cell_output",
return_tensors="pt")
# intervening on time
for s in ["block_output", "mlp_activation",
"unit": "t",
"attention_output"]:
"intervention_type": pv.ZeroIntervention},
for l in range(gpt.config.n_layer):
model=gru)
for p in range(7):
# run an intervened forward pass
w = 1 if s == "block_output" else 10
rand_b = torch.rand(1,10, gru.config.h_dim)
t_config, n_r = tracing_config(l, s, w)
rand_s = torch.rand(1,10, gru.config.h_dim)
t_gpt = pv.IntervenableModel(t_config, gpt)
intervened_outputs = pv_gru(
_, outs = t_gpt(base, [None] + [base]*n_r,
base = {"inputs_embeds": rand_b},
{"sources->base": ([None] + [[[p]]]*n_r,
sources = [{"inputs_embeds": rand_s}],
[[[0, 1, 2, 3]]] + [[[p]]]*n_r)})
# intervening time step
dist = pv.embed_to_distrib(gpt,
unit_locations={"sources->base": (6, 3)})
outs.last_hidden_state, logits=False)
trace_results.append(
Ahookistriggeredeverytimethecorresponding {"stream": s, "layer": l, "pos": p,
"prob": dist[0][-1][7312]})
modelcomponentiscalled. Asaresult,avanilla
hook-based approach, as in all previous libraries
(Bau, 2022; Lloyd, 2023; Fiotto-Kaufman, 2023; 4 CaseStudyII:InterventionandProbe
Mossing et al., 2024), fails to intervene on any TrainingwithPythia-6.9B
recurrentorstate-spacemodel. Tohandlethislim-
Weshowcaseinterventionandprobetrainingwith
itation, pyvene records a state variable for each
pyvene using a simple gendered pronoun predic-
hook,andonlyexecutesahookatthetargetedtime
tion task in which we try to localize gender in
step.
hiddenrepresentations. Fortrainableintervention,
weuseaone-dimensionalDistributedAlignment
3 CaseStudyI:LocatingFactual
Search(DAS;Geigeretal.,2023),thatis,weseek
AssociationsinGPT2-XL
to learn a 1D subspace representing gender. To
WereplicatethemainresultinMengetal.(2022)’s localizegender,wefeedpromptsconstructedfrom
Locating Factual Associations in GPT2-XL with atemplateoftheform“[John/Sarah]walkedbe-
pyvene. Thetaskistotracefactsviainterventions cause [he/she]” (a fixed length of 4) where the
on fact-related datasets. Following Meng et al.’s nameissampledfromavocabularyof47typically
setup, we first intervene on input embeddings by male and 10 typically female names followed by
addingGaussiannoise. Wethenrestoreindividual theassociatedgenderedpronounastheoutputto-
statestoidentifytheinformationthatrestoresthe ken. Weusepythia-6.9B(Bidermanetal.,2023)
5p(Seattle) p(Seattle) p(Seattle)
0.8
0.75 0.75 0.6
0.50 0.50 0.4
0.25 0.25 0.2
0 10 20 30 40 0 10 20 30 40 0 10 20 30 40
single restored layer in GPT2-XL center of interval of 10 patched mlp layer center of interval of 10 patched attn layer
Figure2: WereproducetheresultsinMengetal.(2022)’sFigure1oflocatingearlysitesandlatesitesoffactual
associationsinGPT2-XLinabout20linesof pyvenecode. Thecausalimpactonoutputprobabilityismappedfor
theeffectofeachTransformerblockoutput(left),MLPactivations(middle),andattentionlayeroutput(right).
Trained Intervention (DAS) findssparsergenderrepresentationsacrosslayers
and positions, whereas a linear probe achieves
IIA
1 100%classificationaccuracyforalmostallcompo-
nents. Thisshowsthat a probemay achieve high
0.75
performance even on representations that are not
0.50
causallyrelevantforthetask.
0.25
0 5 LimitationsandFutureWork
0 10 20 30
layers Wearecurrentlyfocusedontwomainareas:
Trained Linear Probe
1. Expandingthedefaultinterventiontypesand
model types. Although pyvene is extensi- ACC
1 bletoothertypes,havingmorebuilt-intypes
0.9
helpsustoonboardnewuserseasily.
0.8
2. pyveneisdesignedtosupportcomplexinter-
0.7
0.6 ventionschemes,butthiscomesatthecostof
0.5 computationalefficiency. Aslanguagemodels
getlarger,wewouldliketoinvestigatehowto
0 10 20 30
layers scaleinterventionefficiencywithmulti-node
andmulti-GPUtraining.
Figure3: Resultsofinterchangeinterventionaccuracy
(IIA)with thetrainableintervention (DAS)andaccu-
racywiththetrainablelinearprobeondifferentmodel 6 Conclusion
componentswhenlocalizinggenderinformation.
We introduce pyvene, an open-source Python li-
brarythatsupportsintervention-basedresearchon
inthisexperiment,whichachieves100%accuracy neuralmodels. pyvenesupportscustomizablein-
on the task. We then train our interventions and terventionswithcomplexinterventionschemesas
probes at the Transformer block output at each well as different families of model architectures,
layerandtokenposition. Forinterventiontraining, and intervened models are shareable with others
weconstructpairsofexamplesandtraintheinter- throughonlinemodelhubssuchasHuggingFace.
ventiontomatchthedesiredcounterfactualoutput Ourhopeisthatpyvenecanbeapowerfultoolfor
(i.e.,ifweswapactivationsfromanexamplewith discoveringnewwaysinwhichinterventionscan
a male name into another example with a female helpusexplainandimprovemodels.
name,thedesiredcounterfactualoutputshouldbe
“he”). Forlinearprobetraining,weuseactivation
collectioninterventiontoretrieveactivationstopre- References
dictthepronoungenderwithalinearlayer.
David Bau. 2022. BauKit. https://github.com/
As shown in Figure 3, a trainable intervention davidbau/baukit.
6
SOE
>eman<deklawesuaceb
SOE
>eman<deklawesuaceb
*ehT*ecapS*deeN
*el
si
ninwotnwod
*ehT*ecapS*deeN
*el
si
ninwotnwod
*ehT*ecapS*deeN
*el
si
ninwotnwodStellaBiderman,HaileySchoelkopf,QuentinGregory ZhezhiHe,AdnanSirajRakin,andDeliangFan.2019.
Anthony, Herbie Bradley, Kyle O’Brien, Eric Hal- Parametric noise injection: Trainable randomness
lahan,MohammadAflahKhan,ShivanshuPurohit, toimprovedeepneuralnetworkrobustnessagainst
USVSNSaiPrashanth,EdwardRaff,AviyaSkowron, adversarialattack. InIEEE/CVFConferenceonCom-
Lintang Sutawika, and Oskar Van Der Wal. 2023. puterVisionandPatternRecognition(CVPR).
Pythia: Asuiteforanalyzinglargelanguagemodels
acrosstrainingandscaling. InInternationalConfer- JohnHewittandChristopherDManning.2019. Astruc-
enceonMachineLearning(ICML). turalprobeforfindingsyntaxinwordrepresentations.
In North American Chapter of the Association for
Lawrence Chan, Adrià Garriga-Alonso, Nicholas ComputationalLinguistics(NAACL).
Goldowsky-Dill, Ryan Greenblatt, Jenny Nitishin-
skaya, Ansh Radhakrishnan, Buck Shlegeris, and JohnHewitt,JohnThickstun,ChristopherManning,and
NateThomas.2022. Causalscrubbing: amethodfor PercyLiang.2023. Backpacklanguagemodels. In
rigorouslytestinginterpretabilityhypotheses. Align- AssociationforComputationalLinguistics(ACL).
mentForumBlogpost.
Michael A Lepori, Thomas Serre, and Ellie Pavlick.
Arthur Conmy, Augustine N Mavor-Parker, Aengus 2023. Uncovering intermediate variables in trans-
Lynch, Stefan Heimersheim, and Adrià Garriga- formersusingcircuitprobing. arXiv:2311.04354.
Alonso. 2023. Towards automated circuit discov-
eryformechanisticinterpretability. InAdvancesin Kenneth Li, Oam Patel, Fernanda Viégas, Hanspeter
NeuralInformationProcessingSystems(NeurIPS). Pfister, and Martin Wattenberg. 2023a. Inference-
timeintervention: Elicitingtruthfulanswersfroma
YanaiElazar,ShauliRavfogel,AlonJacovi,andYoav languagemodel. InAdvancesinNeuralInformation
Goldberg.2020. Amnesicprobing: Behavioralex- ProcessingSystems(NeurIPS).
planationwithamnesiccounterfactuals. InTransac-
tionsoftheAssociationofComputationalLinguistics MaximilianLi,XanderDavies,andMaxNadeau.2023b.
(TACL). Circuitbreaking: Removingmodelbehaviorswith
targetedablation. arXiv:2309.05973.
JadenFiotto-Kaufman.2023. nnsight. https://github.
com/JadenFiotto-Kaufman/nnsight. EvanLloyd.2023. graphpatch. https://github.com/
evan-lloyd/graphpatch.
AtticusGeiger,HansonLu,ThomasIcard,andChristo-
pherPotts.2021. Causalabstractionsofneuralnet- KevinMeng,DavidBau,AlexAndonian,andYonatan
works. InAdvancesinNeuralInformationProcess- Belinkov.2022. Locatingandeditingfactualassoci-
ingSystems(NeurIPS). ationsinGPT. InAdvancesinNeuralInformation
ProcessingSystems(NeurIPS).
AtticusGeiger,KyleRichardson,andChristopherPotts.
2020. Neuralnaturallanguageinferencemodelspar- DanMossing,StevenBills,HenkTillman,TomDupréla
tiallyembedtheoriesoflexicalentailmentandnega- Tour, Nick Cammarata, Leo Gao, Joshua Achiam,
tion. InProceedingsoftheThirdBlackboxNLPWork- Catherine Yeh, Jan Leike, Jeff Wu, and William
shoponAnalyzingandInterpretingNeuralNetworks Saunders. 2024. Transformer debugger. https:
forNLP,Online. //github.com/openai/transformer-debugger.
Atticus Geiger, Zhengxuan Wu, Hanson Lu, Josh Neel Nanda and Joseph Bloom. 2022. Trans-
Rozner, Elisa Kreiss, Thomas Icard, Noah Good- formerlens. https://github.com/neelnanda-io/
man,andChristopherPotts.2022. Inducingcausal TransformerLens.
structureforinterpretableneuralnetworks. InInter-
nationalConferenceonMachineLearning(ICML). Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
Atticus Geiger, Zhengxuan Wu, Christopher Potts, Kaiser,andIlliaPolosukhin.2017. Attentionisall
ThomasIcard,andNoahD.Goodman.2023. Find- youneed. InAdvancesinNeuralInformationPro-
ingalignmentsbetweeninterpretablecausalvariables cessingSystems(NeurIPS).
and distributed neural representations. In Causal
LearningandReasoning(CLeaR). Jesse Vig, Sebastian Gehrmann, Yonatan Belinkov,
SharonQian,DanielNevo,YaronSinger,andStuart
MorGeva,JasmijnBastings,KatjaFilippova,andAmir Shieber.2020. Investigatinggenderbiasinlanguage
Globerson. 2023. Dissecting recall of factual as- modelsusingcausalmediationanalysis. InAdvances
sociations in auto-regressive language models. In inNeuralInformationProcessingSystems(NeurIPS).
EmpiricalMethodsinNaturalLanguageProcessing
(EMNLP),Singapore. Kevin Wang, Alexandre Variengien, Arthur Conmy,
BuckShlegeris, andJacobSteinhardt.2023. Inter-
NicholasGoldowsky-Dill,ChrisMacLeod,LucasSato, pretabilityinthewild: Acircuitforindirectobject
andAryamanArora.2023. Localizingmodelbehav- identificationinGPT-2small. InInternationalCon-
iorwithpathpatching. arXiv:2304.05969. ferenceonLearningRepresentations(ICLR).
7ZhengxuanWu,AtticusGeiger,ThomasIcard,Christo-
pherPotts,andNoahGoodman.2023. Interpretabil-
ityatscale:IdentifyingcausalmechanismsinAlpaca.
InAdvancesinNeuralInformationProcessingSys-
tems(NeurIPS).
8