Label Dropout: Improved Deep Learning
Echocardiography Segmentation Using Multiple
Datasets With Domain Shift and Partial
Labelling
Iman Islam1, Esther Puyol-Antón1, Bram Ruijsink1 Andrew J. Reader1, and
Andrew P. King1
School of Biomedical Engineering & Imaging Sciences, King’s College London, UK
Abstract. Echocardiography (echo) is the first imaging modality used
whenassessingcardiacfunction.Themeasurementoffunctionalbiomark-
ersfromechoreliesuponthesegmentationofcardiacstructuresanddeep
learning models have been proposed to automate the segmentation pro-
cess. However, in order to translate these tools to widespread clinical
use it is important that the segmentation models are robust to a wide
variety of images (e.g. acquired from different scanners, by operators
with different levels of expertise etc.). To achieve this level of robust-
ness it is necessary that the models are trained with multiple diverse
datasets. A significant challenge faced when training with multiple di-
verse datasets is the variation in label presence, i.e. the combined data
areoftenpartially-labelled.Adaptationsofthecrossentropylossfunction
havebeenproposedtodealwithpartiallylabelleddata.Inthispaperwe
showthattrainingnaivelywithsuchalossfunctionandmultiplediverse
datasets can lead to a form of shortcut learning, where the model asso-
ciates label presence with domain characteristics, leading to a drop in
performance. To address this problem, we propose a novel label dropout
scheme to break the link between domain characteristics and the pres-
ence or absence of labels. We demonstrate that label dropout improves
echosegmentationDicescoreby62%and25%ontwocardiacstructures
when training using multiple diverse partially labelled datasets.
Keywords: Partial labels · Segmentation · Echocardiography.
1 Introduction
Echocardiography (echo) is the first imaging examination carried out when as-
sessing cardiac function. Based on segmentations of the cardiac structures from
echo images, useful biomarkers can be extracted to measure the function of the
heartfordiagnosisandtreatmentmanagement.Deeplearningmodelshavebeen
proposed to automate this segmentation process [2,5,7,8,10,13], but for clinical
translation it is important that such models are robust to the wide variation in
image characteristics that will be encountered in the real world (e.g. different
4202
raM
21
]VC.sc[
1v81870.3042:viXra2 I. Islam et al.
scannersandoperatorlevelsofexpertiseetc.).Inotherapplications,suchascar-
diac magnetic resonance, segmentation models have been trained using diverse
data sources and shown to be robust to such variations [6]. In this work we aim
to train a similarly robust model for echo segmentation.
One significant challenge that must be overcome when training with diverse
datasets is the variation in label presence in the training data. For instance, a
number of public datasets exist for training echo segmentation models but the
manually defined labels present are different. A summary of these datasets can
be found in Table 1. This means that the combination of these datasets will be
partially labelled, i.e. not all structures will be labelled in all training samples.
Training naively with partially labelled datasets such as these can cause a
conflictinthesupervisionduetostructuresbeinglabelledasforegroundinsome
samples and background in others. A number of methods have been proposed
to deal with such data by modifying the loss function to deal with the conflict.
For example, Petit et al [9] proposed a method that altered the loss function
from categorical cross entropy (CCE) to a summation of binary cross entropy
(BCE) losses, one for each foreground class. For samples with missing ground
truth labels, only the BCE terms with ground truth labels were computed. A
relatedapproachwasproposedbyShietal[12].Theirworkproposedamarginal
loss, in which any missing label was merged with the background class. In these
merged regions, the loss function considered both the missing label and the
backgroundtobeacorrectprediction.Finally,Mariscal-Haranaetal[6]proposed
the adaptive loss, which was similar in concept to the approach of Petit et al
[9], but removed the loss for the label not present in the ground truth from the
CCE loss calculation.
In this work, we show for the first time through a series of qualitative and
quantitative experiments that when training an echo segmentation model using
a loss function designed for use with partially labelled data, a form of shortcut
learningcanoccurwhichleadsthemodeltoassociateimagecharacteristicswith
label presence. This causes a significant drop in performance for the missing
labels.Weproposeanovelapproachtoaddressthisproblem,calledlabeldropout,
which aims to break the link between image characteristics and label presence
and hence prevent the shortcut learning. We demonstrate that label dropout
significantly improves segmentation performance when training using multiple
diverse partially labelled echo datasets.
2 Materials and Methods
Datasets: Three publicly available 2D echo datasets were exploited in this
work (see Table 1). CAMUS and EchoNet Dynamic contain images at end dias-
tole(ED)andendsystole(ES)foreachsubject.UnityImagingdoesnotprovide
informationatthesubjectlevel.Uponmanualreview,severaloftheUnityImag-
ingsegmentationswerediscardedduetotheleftventricularmyocardium(LVM)
being overlabelled into the right ventricular myocardium. Therefore, we utilised
400 mostly apical 2-chamber images out of the 1504 available. The extraneousLabel Dropout 3
information outside the echo cone in the Unity Imaging and EchoNet Dynamic
images were removed before use in our experiments using an nnU-Net [4] model
trained to segment the ultrasound cone. After pre-processing, all images were
resized to 256×256.
Table 1. Summary of the three datasets used in this work showing the number of
subjects,numberofimages,groundtruthsegmentationlabelspresentandimageviews.
LV = left ventricle, LVM = left ventricular myocardium, LA = left atrium, A2C =
apical 2-chamber, A4C = apical 4-chamber.
No. of subjectsNo. of imagesLVLVMLAImage view(s)
CAMUS [5] 500 1000 ✓ ✓ ✓ A2C + A4C
Unity Imaging [3] - 400 ✓ ✓ ✓ A2C
EchoNet Dynamic [7] 10024 20048 ✓ A2C + A4C
Baseline segmentation models: A U-Net [11] was used as the baseline seg-
mentation model. All models were trained using a stochastic gradient descent
optimizer with a variable learning rate and a Nestorov momentum of 0.9 for
500 epochs. The initial learning rate and batch size was selected using a grid
search and the model with the best foreground Dice score on the validation set
was used for evaluation on the test set. Models were trained using two different
loss functions. First, standard loss models were trained using a standard CCE
loss function calculated over all classes including the background. Second, we
trained adaptive loss models using the adaptive cross entropy loss proposed in
[6]. This loss was implemented by removing the labels which are missing from
the ground truth from the predicted segmentation, eliminating their contribu-
tion to the loss. Data augmentation was applied on the fly when training some
modelsasspecifiedinSection3.Thefollowingaugmentationswereapplied:scal-
ing,rotation,Gaussianblur,brightnessandcontrastadjustment.Thedatawere
randomly split into 80%/10%/10% for the training, validation and test sets.
Label dropout: AswewillshowinSection3,asignificantdropinperformance
of the adaptive loss model was observed when training with partially labelled
datasets which have a domain shift between them. It was hypothesised that
this was due to the model learning to associate domain specific characteristics
with the presence of labels. Therefore, we propose the label dropout scheme,
which aims to break the link between domain characteristics and the presence
orabsenceofcertainlabels.Inlabeldropout,weintroducearandomprobability
of a label being removed (i.e. set to background) from the ground truth mask of
each sample during training.4 I. Islam et al.
3 Experiments and Results
Thissectionwilldetailaseriesofexperimentswhichaimtoillustratetheproblem
when training with multiple diverse partially labelled datasets, as well as the
effectiveness of our proposed label dropout scheme in overcoming this problem.
Experiment 1 - The need for multiple diverse training datasets: We
first illustrate the need to train echo segmentation models using multiple di-
verse datasets. In this experiment we trained left ventricle (LV) segmentation
models with data augmentation using each of the datasets previously described
in Section 2. Each model was evaluated on each of the three datasets. Fig. 1
shows the test set Dice scores achieved for each evaluation. As can be seen, the
models perform worse when tested ondatasets they were nottrained on. There-
fore, training models using multiple diverse datasets is necessary to improve the
generalisability of echo segmentation models.
Fig.1. Experiment 1: Test Dice scores achieved by training and evaluating intra-
domain and cross-domain LV segmentation models using three different datasets. C
= CAMUS [5], UI = Unity Imaging [3], END = EchoNet Dynamic [7].
Experiment2-Trainingusingacombinationofthreediversepartially
labelled echo datasets: The purpose of this experiment was to illustrate the
problem of using the standard loss model when training with diverse partially
labelled datasets and explore if using the adaptive loss model would lead to
satisfactory results. We again used all three datasets in this experiment but
this time combined them into a single training dataset. Therefore, the training
dataset was partially labelled and highly diverse including various cone shapes
and sizes, intensity inhomogeneities within the cones and differing contrasts.
Using these data, we trained three different models to segment the LV, LVM
and LA: a standard loss model with augmentation and adaptive loss models
with and without augmentation. Fig. 2 shows a representative sample of theLabel Dropout 5
results for this experiment. The difference in quality between the model predic-
tions for the LV, where ground truth masks were always available is minimal.
However, the standard loss model completely fails to predict the LVM and LA
in the EchoNet Dynamic dataset whilst predicting all three labels in the other
datasets. This shows a form of shortcut learning in which the model has learnt
to associate domain characteristics with label presence or absence, resulting in
a model that only predicts labels which were present in the datasets’ ground
truths. Furthermore, contrary to expectations, the adaptive loss models do not
produce accurate predictions for structures with missing labels. Even with aug-
mentation,thepredictionsarelessthansatisfactory,particularlyfortheEchoNet
Dynamic dataset. Data augmentation improved the results to some extent by
providing a way to reduce the impacts of the domain shifts, however it did not
completely overcome the impact of the shortcut learning.
Fig.2.Experiment2:Exampletestresultsfromthethreedatasets.Fromlefttoright:
image, ground truth segmentation and model predictions using standard loss model,
adaptive loss without augmentation and adaptive loss with augmentation.
Experiment 3 - Investigating the adaptive loss in a controlled experi-
ment: Thepurposeofthisexperimentwastofurtherinvestigateourhypothesis
that domain shift has led to shortcut learning in the adaptive loss model. Here,
we investigate the viability of the adaptive loss model in a controlled environ-
ment, with no domain shift between the differently labelled samples. To achieve
this,groundtruthlabelswereartificiallyremovedfromasubsetofsamplesfrom
the CAMUS dataset. Three models were trained and evaluated. The first was a
benchmark model viewed as the best achievable performance with no partial la-
belling, using a standard loss. Then, a standard loss model and an adaptive loss6 I. Islam et al.
model(bothwithoutaugmentation)weretrainedwiththeLVMlabelartificially
removed from 50% of the training data.
ThetestsetresultsareshowninFig.3.Thebenchmarkmodel,standardloss
modelandadaptivelossmodelachievedmeanforegroundDicescoresof0.873±
0.05, 0.803±0.06, and 0.863±0.05 respectively. Therefore, in this controlled
experiment, although the adaptive loss model was trained with missing labels,
it performed comparably to the benchmark model. The standard loss model
suffered a significant drop in performance due to the conflict in supervision
information. The box plots in Fig. 3 show the breakdown of the Dice scores for
each class, with the adaptive loss model achieving a significantly higher Dice
score for the LVM compared to the standard loss model.
Fig.3. Experiment 3: Test set results when training using only the CAMUS dataset
with50%ofLVMlabelsremoved.BoxplotsshowDicecoefficientsforeachsegmented
structureandtheoverallmean.Green=benchmark,blue=standard,pink=adaptive.
This experiment shows the viability of the adaptive loss as a solution to the
problem of partial labelling. It also supports our hypothesis that the lack of
improvementoftheadaptivelossmodelinExperiment2wasduetothedomain
shift between the datasets leading to a form of shortcut learning.
Experiment 4 - Label dropout: Experiment3showedthattheadaptiveloss
has the potential to deal with partially labelled training data, but it did not
produce clinically acceptable segmentations in Experiment 2 when there were
domain shifts between the differently labelled datasets. In this experiment, the
utility of our proposed label dropout scheme in addressing this problem is ex-
plored.Twodatasetswereusedinthefirstpartofthisexperiment:CAMUSand
Unity Imaging. The LA was artificially removed in all Unity Imaging ground
truth masks in the training set to produce a combined training set with par-
tial labels and a domain shift. Two types of model were trained: adaptive loss
models with label dropout using the partially labelled data, and a benchmark
model with a standard loss and fully labelled data, which represents the best
achievable performance. For the label dropout model, different probabilities for
label dropout ranging from 0.0 to 1.0 in steps of 0.1 were tested. This is the
probability of the LA being dropped out from the ground-truth segmentation
for each training pair during training. Augmentation was used for training all
models in this experiment.Label Dropout 7
Fig. 4 shows the test set results of this experiment. The plot clearly shows
theimprovedperformancewhenusingthelabeldropouttechniquewhichpersists
across a range of dropout probabilities. Note that the 0% label dropout model
is equivalent to the adaptive loss model without label dropout. The benchmark
model and the 0% label dropout models achieved Dice scores of 0.83 and 0.71
respectively. The Dice scores of the adaptive loss models with label dropout
were approximately 0.8. 100% label dropout means that the LA is never seen
during training. Fig. 4 shows how introducing label dropout, even with a very
low probability of dropout at 10%, helps to break the link between domain
characteristics and the presence of labels. In Fig. 4, sample model predictions
Fig.4.Experiment4:LabelDropout.(i)TestsetDicescoresfrommodelstrainedwith
different probabilities of label dropout on the LA for images from the Unity Imaging
dataset. Models were trained three times with different random seeds and the error
bars show the mean and standard deviation of the results. Benchmark was trained
withastandardlossusingfullylabelleddata.(ii)SampleresultsontheUnityImaging
dataset. From left to right: image, ground truth segmentation and model predictions
without label dropout and with 50% label dropout.
fromthisexperimentarealsodisplayed.Whenthereisnolabeldropout,theLA
in the Unity Imaging dataset has a visibly worse segmentation compared to the
adaptive loss model with 50% label dropout. This experiment shows that label
dropout can improve model performance when training with diverse partially
labelled datasets. The Dice scores for the LV and LVM were similar for both
models for each dataset.
Asafinalexperiment,werepeatedExperiment2butnowusingthecombina-
tion of all three datasets using label dropout. Sample test set results are shown
in Fig. 5. We see a visible improvement in the performance of the adaptive loss
model when using label dropout, further supporting our hypothesis that a form
of shortcut learning can negatively affect the performance of the adaptive loss
when training using diverse partially labelled datasets.
Toquantifytheseimprovements,theLVMandLAweremanuallysegmented
by a trained observer (and checked by a cardiologist) in a random sample of 20
imagesfromEchoNetDynamictestset.ThemeanLVMDicescoresachievedfor8 I. Islam et al.
Fig.5. Repetition of Experiment 2 with label dropout. Randomly selected test set
results when training with all 3 datasets using label dropout (LD). From left to right:
image,groundtruthsegmentationandmodelpredictionsusingadaptivelosswithaug-
mentation and adaptive loss with augmentation and label dropout.
the adaptive loss with and without label dropout were 0.319 and 0.518 respec-
tively, and for LA they were 0.553 and 0.689 respectively. These respresent Dice
increasesof0.199and0.136(or62%and25%).Modelpredictionsfor10random
images from these 20 are displayed in Supplementary Fig. 1 with a summary of
the Dice scores in Supplementary Table 1.
4 Discussion and Conclusion
This paper has made two significant contributions: (i) we have highlighted for
the first time that state-of-the-art approaches for dealing with partially labelled
segmentationdatacanbenegativelyaffectedbyaformofshortcutlearningwhen
trained with datasets featuring domain shift, (ii) we have proposed a new label
dropout technique for dealing with this problem. For contribution (i), we note
that the adaptive loss that we employed to deal with the partially labelled data
was shown to work effectively in an experimental environment with no domain
shift (Experiment 3) and has previously been shown to be effective when there
was domain shift but no relationship between domain characteristics and label
presence(e.g.occasionallymissingLVMatESincinecardiacmagneticresonance
[6]). Thus, we conclude that its poorer performance in Experiment 2 was due
to the presence of such a relationship. For contribution (ii), label dropout was
shown to improve model performance in Experiment 4. It is noticeable that
the Dice score for the label dropout scheme plateaus when the label dropout is
introduced. We speculate that this could be because, after a certain number of
epochs, the model eventually sees all images with all labels.
Webelievethatthisworkisimportantfortrainingrobustsegmentationmod-
els. When combining multiple diverse echocardiography segmentation datasets,
the resulting training datasets are typically partially labelled and therefore this
technique could allow the training of more generalisable models.
Furtherworkwillincludeinvestigatingtheimpactoflabeldropoutondiffer-
ent network architectures, such as transformers [1], as well as alternative strate-
gies for dealing with partial labels, such as the marginal loss [12]. Furthermore,Label Dropout 9
the label dropout technique will also be evaluated on datasets from different
imaging modalities.
Acknowledgements
We would like to acknowledge funding from the EPSRC Centre for Doctoral
Training in Medical Imaging (EP/L015226/1).
References
1. Cao, H., Wang, Y., Chen, J., Jiang, D., Zhang, X., Tian, Q., Wang, M.: Swin-
Unet: Unet-like Pure Transformer for Medical Image Segmentation (May 2021),
http://arxiv.org/abs/2105.05537, arXiv:2105.05537 [cs, eess]
2. Ghorbani, A., Ouyang, D., Abid, A., He, B., Chen, J.H., Harrington, R.A.,
Liang, D.H., Ashley, E.A., Zou, J.Y.: Deep learning interpretation of echocardio-
grams. npj Digital Medicine 3(1), 10 (Jan 2020). https://doi.org/10.1038/
s41746-019-0216-8, https://www.nature.com/articles/s41746-019-0216-8
3. Huang, Z., Sidhom, M.J., Wessler, B.S., Hughes, M.C.: Fix-A-Step: Semi-
supervisedLearningfromUncuratedUnlabeledData(May2023),http://arxiv.
org/abs/2208.11870, arXiv:2208.11870 [cs]
4. Isensee, F., Jaeger, P.F., Kohl, S.A.A., Petersen, J., Maier-Hein, K.H.: nnU-Net:
a self-configuring method for deep learning-based biomedical image segmenta-
tion. Nature Methods 18(2), 203–211 (Feb 2021). https://doi.org/10.1038/
s41592-020-01008-z, http://www.nature.com/articles/s41592-020-01008-z
5. Leclerc, S., Smistad, E., Pedrosa, J., Ostvik, A., Cervenansky, F., Espinosa, F.,
Espeland, T., Berg, E.A.R., Jodoin, P.M., Grenier, T., Lartizien, C., Dhooge,
J., Lovstakken, L., Bernard, O.: Deep Learning for Segmentation Using an Open
Large-ScaleDatasetin2DEchocardiography.IEEETransactionsonMedicalImag-
ing 38(9), 2198–2210 (Sep 2019). https://doi.org/10.1109/TMI.2019.2900516,
https://ieeexplore.ieee.org/document/8649738/
6. Mariscal-Harana,J.,Asher,C.,Vergani,V.,Rizvi,M.,Keehn,L.,Kim,R.J.,Judd,
R.M., Petersen, S.E., Razavi, R., King, A.P., Ruijsink, B., Puyol-Antón, E.: An
artificial intelligence tool for automated analysis of large-scale unstructured clin-
ical cine cardiac magnetic resonance databases. European Heart Journal - Digi-
tal Health 4(5), 370–383 (Oct 2023). https://doi.org/10.1093/ehjdh/ztad044,
https://academic.oup.com/ehjdh/article/4/5/370/7223886
7. Ouyang, D., He, B., Ghorbani, A., Yuan, N., Ebinger, J., Langlotz, C.P., Hei-
denreich, P.A., Harrington, R.A., Liang, D.H., Ashley, E.A., Zou, J.Y.: Video-
based AI for beat-to-beat assessment of cardiac function. Nature 580(7802), 252–
256 (Apr 2020). https://doi.org/10.1038/s41586-020-2145-8, https://www.
nature.com/articles/s41586-020-2145-8
8. Painchaud,N.,Duchateau,N.,Bernard,O.,Jodoin,P.M.:EchocardiographySeg-
mentation With Enforced Temporal Consistency. IEEE Transactions on Medi-
calImaging41(10),2867–2878(Oct2022).https://doi.org/10.1109/TMI.2022.
3173669, https://ieeexplore.ieee.org/document/9771186/
9. Petit, O., Thome, N., Charnoz, A., Hostettler, A., Soler, L.: Handling Miss-
ing Annotations for Semantic Segmentation with Deep ConvNets. In: Deep
Learning in Medical Image Analysis and Multimodal Learning for Clinical10 I. Islam et al.
Decision Support, vol. 11045, pp. 20 − −28. Springer International Publish-
ing, Cham (2018). https://doi.org/10.1007/978-3-030-00889-5_3, https://
link.springer.com/10.1007/978-3-030-00889-5_3, series Title: Lecture Notes
in Computer Science
10. Puyol-Antón, E., Ruijsink, B., Sidhu, B.S., Gould, J., Porter, B., Elliott, M.K.,
Mehta, V., Gu, H., Xochicale, M., Gomez, A., Rinaldi, C.A., Cowie, M.,
Chowienczyk, P., Razavi, R., King, A.P.: AI-enabled Assessment of Cardiac Sys-
tolic and Diastolic Function from Echocardiography (Jul 2022), http://arxiv.
org/abs/2203.11726, arXiv:2203.11726 [physics]
11. Ronneberger, O., Fischer, P., Brox, T.: U-Net: Convolutional Networks for
BiomedicalImageSegmentation(May2015),http://arxiv.org/abs/1505.04597,
arXiv:1505.04597 [cs]
12. Shi,G.,Xiao,L.,Chen,Y.,Zhou,S.K.:Marginallossandexclusionlossforpartially
supervised multi-organ segmentation. Medical Image Analysis 70, 101979 (May
2021). https://doi.org/10.1016/j.media.2021.101979, https://linkinghub.
elsevier.com/retrieve/pii/S1361841521000256
13. Tromp, J., Seekings, P.J., Hung, C.L., Iversen, M.B., Frost, M.J., Ouwerkerk,
W., Jiang, Z., Eisenhaber, F., Goh, R.S.M., Zhao, H., Huang, W., Ling, L.H.,
Sim, D., Cozzone, P., Richards, A.M., Lee, H.K., Solomon, S.D., Lam, C.S.P.,
Ezekowitz, J.A.: Automated interpretation of systolic and diastolic function on
the echocardiogram: a multicohort study. The Lancet Digital Health 4(1), e46–
e54 (Jan 2022). https://doi.org/10.1016/S2589-7500(21)00235-1, https://
linkinghub.elsevier.com/retrieve/pii/S2589750021002351