CLEVR-POC: Reasoning-Intensive Visual Question Answering
in Partially Observable Environments
Savitha Sam Abraham∗, Marjan Alirezaie†, Luc De Raedt§
∗The University of Adelaide, Australia
savitha.samabraham@adelaide.edu.au
†Flybits Labs. TMU Creative AI Hub, Toronto, Canada
marjan.alirezaie@flybits.com
§O¨rebro University, Centre for Applied Autonomous Sensor Systems(AASS), O¨rebro, Sweden
Department of Computer Science, KULeuven, Belgium
luc.de-raedt@oru.se
Abstract
TheintegrationoflearningandreasoningishighontheresearchagendainAI.Nevertheless,thereisonlyalittle
attentiontouseexistingbackgroundknowledgeforreasoningaboutpartiallyobservedscenestoanswerquestions
about the scene. Yet, we as humans use such knowledge frequently to infer plausible answers to visual questions
(by eliminating all inconsistent ones). Such knowledge often comes in the form of constraints about objects and
it tends to be highly domain or environment-specific. We contribute a novel benchmark called CLEVR-POC for
reasoning-intensive visual question answering (VQA) in partially observable environments under constraints. In
CLEVR-POC,knowledgeintheformoflogicalconstraintsneedstobeleveragedtogenerateplausibleanswers to
questionsaboutahiddenobjectinagivenpartialscene. Forinstance,ifonehastheknowledgethatallcupsare
coloredeitherred,greenorblueandthatthereisonlyonegreencup,itbecomespossibletodeducethecolorofan
occluded cup as either red or blue, provided that all other cups, including the green one, are observed. Through
experiments, we observe that the low performance of pre-trained vision language models like CLIP (≈ 22%) and
alargelanguagemodel(LLM)likeGPT-4(≈46%)onCLEVR-POCascertainsthenecessityforframeworksthat
can handle reasoning-intensive tasks where environment-specific background knowledge is available and crucial.
Furthermore, our demonstration illustrates that a neuro-symbolic model, which integrates an LLM like GPT-4
withavisualperceptionnetworkandaformallogicalreasoner,exhibitsexceptionalperformanceonCLEVR-POC.
Keywords:LLM and Reasoning, visual question answering, partial observability, logical constraints
1. Introduction sions or limited field of view. Furthermore, in fac-
torysettings,reasoningcombinedwithbackground
VisualQuestionAnswering(VQA)hasbeenwidely
knowledgeabouttheenvironmentcanassistteams
investigated by researchers from various subfields
of robots in dealing with partial observability dur-
in AI like computer vision and natural language
ing navigation and other coordination and cooper-
understanding. As a result, we now have access to
ation tasks.
a vast corpus of VQA datasets coupled with nu-
In this paper, we introduce a synthetic dataset,
merous models addressing the task of VQA (Zou
CLEVR-POC1,forareasoning-intensiveVQAtask
and Xie, 2020; Wu et al., 2017).
set in partially observable scenarios involving ex-
Most existing VQA datasets (Johnson et al., 2017;
ternal knowledge in the form of constraints. The
Antol et al., 2015) have a collection of images
datasetconsistsofpairsofanimage,representinga
paired with questions such that all information re-
partialscene(BinFigure1a)insomeenvironment
quired to answer the question is provided in the
(D1inFigure1awheretheenvironmentisdefined
image,andhencethesceneisconsideredcomplete.
by a set of constraints), and a question in natural
But in real life, we often engage in tasks where
language about some hidden/missing object (C in
scenes may not be completely visible. We instead
Figure1a)inthescene. Althoughintheliterature,
mayhaveworldknowledgeaboutvariouslocations
there exist datasets for QA tasks in partially ob-
visited by us, acquired over time, that allows us
servable environments (e.g., CLEVR-dialog (Kot-
to generate plausible answers to queries about ob-
tur et al., 2019), Visual Dialog (Das et al., 2017),
jects we do not see in a scene. For example, in au-
Guess What? (De Vries et al., 2017)), these do
tonomousvehiclescenarios,reasoningiscrucialfor
not come with additional background knowledge.
dealing with partial observability. Comprehensive
knowledge of traffic enables the system to inter-
1The source code associated with this research
pretlimitedvisualinformationandmakeinformed
project is openly accessible at https://github.com/
decisions, ensuring safe navigation despite occlu-
savithasam88/CLEVR-POC/tree/master
4202
raM
5
]IA.sc[
1v30230.3042:viXra(a) The different components in VQA tasks.
(b) The different VQA tasks are based on expected inputs and outputs and the number of agents involved.
Figure 1: VQA task components and types of VQA tasks
The challenge presented in CLEVR-POC necessi- the detailed process of generating CLEVR-POC,
tates the integration of knowledge and multi-step while Section 4 outlines the research questions ex-
reasoninginvolvingeliminativeinduction,intoper- plored in this study. Additionally, this section
ception systems driven by learning. Given that presents the experiments conducted on CLEVR-
the knowledge associated with a scene typically POC and the corresponding results.
varies depending on the specific environment in-
2. Related Work
volved, it is not a constant across the dataset.
It becomes challenging for a learning system to In this section, we provide an overview of research
simply memorize this knowledge during training in two domains - datasets in VQA and LLMs and
iterations. Moreover, because this knowledge is reasoning.
environment-specific, employing Large Language
2.1. Datasets in VQA
Models (LLMs) such as GPT as the source of
knowledge, as demonstrated in some of the recent A VQA task may involve various combinations of
works like (Zhou et al., 2023) and (Shah et al., the different components shown in Figure 1a - a
2023), does not yield favorable results. We sub- complete scene (A), a partial scene (B), a ques-
stantiatetheseassertionsthroughempiricalexper- tion(C)aboutthescene,externalknowledgeinthe
iments. form of rules/constraints (D1), or facts in knowl-
The contributions of this paper are as follows: edgegraphs(D2),andthesetofplausibleanswers
to the question (E). Each combination results in a
• We introduce a dataset, CLEVR-POC, that
different VQA task (see Figure 1b).
introduces the task of reasoning-intensive
VQA - given a partial scene, the constraints 2.2. Types of VQA Tasks
(knowledge) to which the scene conforms and 2.2.1. Task 1
aquestion aboutahiddenobjectinthescene, Given a complete scene, and a question about an
find the set of all plausible answers. objectinthescene,findtheanswertothequestion.
• We evaluate the performance of state-of-the- Sincethesceneiscomplete,theagentcancomeup
with the exact answer implying that the solution
art pre-trained vision language and large lan-
set E has just one element (|E| = 1). DAQUAR
guage models on CLEVR-POC.
(Malinowski and Fritz, 2014), VQA (Antol et al.,
• We demonstrate that the synergistic use of 2015), CLEVR (Johnson et al., 2017) are datasets
LLMs alongside a visual perception network in this category.
and a formal reasoning system with access
2.2.2. Task 2
to external knowledge can efficiently and ef-
Given a complete scene, a question about one of
fectively address the challenges presented by
the objects in the scene and external knowledge
CLEVR-POC.
about objects (in the form of triples - D2), find
Theorganizationofthepaperisasfollows. Section theanswertothequestionleveragingthisexternal
2 provides an overview of existing work in VQA, knowledge. FVQA(fact-basedVQA)(Wangetal.,
focusing on various VQA datasets and briefly dis- 2017), and KVQA (knowledge aware VQA) (Shah
cussing LLM for reasoning. Section 3 delves into et al., 2019) are datasets in this category.2.2.3. Task 3 isfy a set of constraints given. These benchmarks
While the above two tasks involve a single agent are used to assess the capacity of language models
being posed with a scene and a question, this cat- inhandlingsymbolicreasoning,contributingtothe
egory of VQA tasks involves more than one agent. advancementsinthedevelopmentofmorelogically
Oneoftheagentshasaccesstothecompletescene sound systems.
while the other agent is provided with a partial
scene and a question. Answering the question
3. The CLEVR-POC Dataset
requires the agents to interact with each other.
CLEVR-dialog(Kotturetal.,2019),VisualDialog Now we describe in detail the generation of the
(Das et al., 2017), Guess What? (De Vries et al., CLEVR-POC dataset. The dataset, as the name
2017) are datasets handling Task 3. suggests, is based on the CLEVR (Johnson et al.,
2017) dataset, which generated scenes with geo-
2.2.4. Task 4 (CLEVR-POC) metrical shapes. Each object is associated with
Given a partial scene, knowledge in the form of four attributes - color, shape, material, and size.
rules(constraints)abouttheenvironmenttowhich The objects in CLEVR-POC can have one of the
the scene conforms and a question about the hid- four shapes - cone, sphere, cylinder, and cube,
den object in the scene, find the set of all plau- three sizes - large, medium, and small, two ma-
sible answers to the question. Since the question terials - rubber and metal, and eight colors - red,
is about a hidden object (for example, about the blue, green, yellow, gray, brown and purple. Be-
shape of the object), it may not be always possi- sides these four attributes, since a scene is divided
ble to provide an exact solution. Answering the into four regions (see Figure 1a), CLEVR-POC
question is more about eliminating all cases that also associates an object with the region it is in
are inconsistent with the background knowledge - 0,1,2 or 3. Each object belongs to exactly one
(for example: given the knowledge - there are no region. Divisionofasceneintoregionsenablesthe
spheresinthisenvironment)andreturningallcon- specification of constraints at multiple levels.
sistentanswersasthesolution(the shape is a cone
or a cylinder or a cube, which is why |E| ≥ 1). In • Region-based constraints - for example, all
contrasttoTask2, wheretheknowledgegraphen- objectsinRegion0areofshapescubeorcylin-
compasses general world facts (e.g.,“cows are her- der. These constraints must be satisfied by
bivores”), the knowledge in this context is consid- objects in the corresponding region.
erably more specific to an environment. While an
LLM can be presumed to possess awareness of the • Across-region constraints - for example, the
former category of knowledge, the same cannot be totalnumberofobjectssharingthesamecolor
said for the latter. in regions 1 and 2 is not more than 2. These
are constraints specified across two regions.
2.3. LLMs and Reasoning
In this paper, our emphasis lies on the process • Generic constraints - for example, there are
of reasoning which depends on a formal system at least two cubes in the scene. These con-
grounded in logical rules and principles. Such a straints apply to the whole scene.
system ensures that all transformations or manip-
ulations of symbols within it, leading to new in- One of the major points of distinction in the scene
ferences, adhere to the logical rules and princi- generationprocessofCLEVR-POCfromtheorigi-
ples governing the system (MacColl, 1897). While nalCLEVRisthatthescenesinCLEVR-POCare
LLMscanalsobeseenasperformingsymbolicma- generated such that they conform to a chosen set
nipulations,thesemanipulationsunliketraditional of constraints. The steps in creating an instance i
symbolic reasoning are based on statistical associ- in the dataset are:
ations or patterns learned from data (Huang and
Chang, 2023), because of which it may or may not • Generating an environment - Environment ,
i
be logically sound. Despite the progress in the de- defined by a set of constraints.
velopmentoflargelanguagemodels(LLMs),many
stillstrugglewithadeepunderstandingofsymbols • Generating a complete scene graph,
likehumansdo(AbrahamandAlirezaie,2022;Yao Complete , that conforms to Environment .
i i
etal.,2022). Toaddressthisgap,thereareongoing
efforts to create benchmarks (Huang and Chang, • Generating the partial scene graph, Partial
i
2023), like the proposed CLEVR-POC, to evalu- by removing one of the objects, Obj , from
i
ate the reasoning capabilities of LLMs. Complete .
i
InCLEVR-POC,weintroduceaVQAtaskthatin-
volvesconstraint-basedreasoning,aformoflogical • Generating a question, Q , about the partial
i
reasoning, where the generated response must sat- scene with object of interest Obj .
iTemplate-1 (Value Restriction)
:- object(X),at(X, R’), not hasProperty(X, P1’, V1’).
Translation All objects at region R’ have value V1’ for the property P1’.
An instantiation :- object(X),at(X, 0), not hasProperty(X, color, red).
Template-2 (Negation Constraint)
:- object(X), at(X, R’), hasProperty(X, P1’, V1’).
Translation All objects at region R’ cannot have value V1’ for the property P1’.
An instantiation :- object(X), at(X, 0), hasProperty(X, material, metal).
Template-3 (Exactly N Constraint)
:- #count{X: hasProperty(X, P1’, V1’), object(X), at(X, R’)}!=N’
Translation ThereareexactlyN’ objectsatregionR’ withvalueV1’ forthepropertyP1’.
An instantiation :- #count{X: hasProperty(X, size, small), object(X), at(X, R’)}!=2
Template-4 (Atleast N Constraint)
:- #count{X1, X2: sameProperty(X1, X2, P1’), object(X1), object(X2), at(X1, R1’),
at(X2, R2’)} < N’.
Translation There are at least N′ pairs of objects at regions R1’ and R2’ that has the
same value V1’ for the property P1’.
Aninstantiation:-#count{X1,X2: sameProperty(X1,X2,shape),object(X1),object(X2),
at(X1, 1), at(X2, 2)}<1.
Template-5 (OR Constraint)
:- object(X), at(X, R’), not hasProperty(X, P1’, V1’), not hasProperty(X, P1’, V2’).
Translation All objects in region R’ have value V1’ for property P1’ or V2’ for property
P2’.
An instantiation :- object(X), at(X, 1), not hasProperty(X, color, yellow), not hasProp-
erty(X, color, blue).
Table 1: A few constraint templates
3.1. Environment Representation at(0, 2).
An environment in CLEVR-POC is defined by a hasProperty(0, color, green).
hasProperty(0, size, large).
set of constraints. We provide a set of 11 con-
hasProperty(0, material, rubber).
straint templates with CLEVR-POC that are ex-
hasProperty(0, shape, cylinder).
pressed in answer set programming (ASP)2. Each
....
environment is created by at most 15 different in-
%Spatial relations between objects
stantiations of these templates, provided there are
front(1, 0). right(1, 0). ...
at least two constraints associated with each re-
gion. A few example constraint templates with The predicate object is used to define the dif-
their translation in English and an instantiation ferent objects (denoted using identifiers - 0, 1,
are shown in Table 1. Around 30 different envi- ..). hasProperty(Object, Attribute, Value)
ronments are generated (see Appendix A for an associates a Value for an Attribute of an
example) and the scenes in the dataset belong to Object. at(Object, Region) represents the re-
one of these 30 environments - the dataset genera- gion where the object is located. The spatial
tion process ensures that the scenes are uniformly relations between objects are represented with
distributed across the 30 environments. predicatesleft, right, front, behind-forex-
ample, left(Object1, Object2) represents that
3.2. Scene Representation
Object2 is located left of Object1.
CLEVR represented a scene in the form of a scene
graph whose nodes represented objects annotated 3.3. Image Generation
with its attributes and edges denoted the spatial
While the images in CLEVR are generated from a
relations (left, right, front, behind) between ob-
randomlysampledscenegraph,CLEVR-POCgen-
jects. In CLEVR-POC, besides the scene graph
representation, we also represent a scene in ASP. erates its images from scene graphs known to ad-
Below we show part of the ASP representation of heretoconstraintsdefininganenvironment. Scene
the partial scene in Figure 1a. graph creation is thus a reasoning problem - given
anenvironment(constraintsinASP)andadesired
%Objects in the scene
number of objects (n) in the scene, the goal is
object(0). object(1). object(2). object(3).
to assign each object to one of the four regions
%Attributes of objects and propose values to color, size, shape, and ma-
terial that are consistent with the constraints in
2ASP is a declarative programming paradigm ap- the environment. An ASP reasoning engine solves
pliedtosolvecomplexsearchproblems(Lifschitz,2008) this problem - each answer (a consistent property-(a) Pipeline for generating environment and complete scenes in that environment.
(b) Pipeline for generating partial scenes, and questions and then labeling them with answers.
Figure2: Twostepsindatasetgenerationprocess: Figure2ashowsthefirststep-environmentgeneration
from constraint templates and generating complete scenes satisfying these constraints. Figure 2b shows
Step 2 - partial scene and question generation from a complete scene.
value assignment for the n objects) in the answer the set of all values for the attribute A (for exam-
set returned is a scene graph or a possible configu- ple |size| = 3 = |{large,medium,small}|). If the
ration of the objects in the scene. Since there are question generated has |A| solutions (for instance,
manypossibleconfigurations-werandomlysample asolutionlike,‘size is large or small or medium’is
a million of these scene graphs for the subsequent trueforanyquestion),itisconsideredinvalid. The
image generation phase. A scene graph is then questions are balanced across the question types
rendered using Blender3. The image representing (thatdependonthequeryattribute-seeAppendix
the partial scene is generated from a partial scene B for the distribution). It should be noted that
graph constructed from the actual scene graph by the solution space of CLEVR-POC questions is 16
randomlyremovingoneoftheobjectsfromit. Fig- timesthatofCLEVRasthesolutionsexpectedare
ure2ashowsthescenegraphconstructionprocess. not always a single value, but a set of values.
3.4. Question Representation 3.5. Question Generation
ThequestionsinCLEVR-POCqueryaboutoneof The question in CLEVR-POC is generated from
thefourattributes-color,size,shape,andmaterial the question templates available in CLEVR. We
of the missing/hidden object in the partial scene. avoid the yes/no (existence, comparison) and
Besides representing the questions using an equiv- counting questions and focus on just the attribute
alent functional program as in CLEVR, CLEVR- querying templates. An example template is as
POC also represents it in ASP. An example ques- follows:
tion and its ASP form are shown below:
What shape is the < Z2 > (size) <
Question: C2 > (color) < M2 > (material) [that is]
Whatisthecoloroftheothercylinderthatis < R > (relation) the < Z > (size) < C >
thesamematerialasthemediumredthing? (color)<M >(material)<S >(shape)?
Question template instantiation is done based on
query(Q):- hasProperty(X,color,Q),
hasProperty(X,shape,cylinder), the complete scene graph of the associated image.
The object of interest is always the object that is
hasProperty(Y,size,medium),
removed from the complete scene to generate the
hasProperty(Y,color,red),
same material(Y,X), partial scene graph. The query attribute is picked
X!=Y. such that it satisfies the question type balancing
requirements. The known attributes of the query
If the query is about attribute A, A ∈ object (filling the slots < Z2 > or < C2 > or
{color,size,material,shape}, the questions are < M2 > in the above template) are randomly se-
generated such that the cardinality of the set of lected. While the filler for the slot < R > (one of
possiblesolutions(S)is1≤|S|<|A|,where|A|is the left, right, front, behind) is randomly picked,
thereferenceobjectinthequeryispickedbasedon
3https://www.blender.org/ thespatialrelationsavailableinthecompletescene- picking one of the objects that are in < R > re- and Wookey, 2019) that gives more penalty to the
lation of the query object. wrong prediction of minority class (as most of the
The ASP representations of the question, the in- labels in the output are 0, except for the ones in
completescene,andtheconstraintsintheenviron- theanswer-afalsenegativeisgivenmorepenalty).
mentaregiventoanASPsolvertoidentifytheset For each of the 17 labels, the weighted cross en-
of possible values for the query attribute. Figure tropy loss is thus defined as below:
2bshowsthepipelineofquestiongeneration. Refer
WCE(y,yˆ)=−(βylog(yˆ)+(1−y)log(1−yˆ)) (1)
to Appendix A and B for a detailed example and
statistics of CLEVR-POC.
β is the weight (is set > 1 to penalize false nega-
tives)4, y is the ground truth, yˆis the prediction.
4. Experiments
The experiments are designed to answer the fol- 4.1.2. Neuro-Symbolic Visual Question
lowing research questions (RQ): Answering
The architecture for the neuro-symbolic approach
• RQ1: How do neural-based vision language to solving CLEVR-POC task is shown in Figure
models perform on reasoning-intensive VQA 4. The idea is to convert both the image and the
tasks (with an emphasis on symbolic knowl- question into a unified space as in CLIP, with the
edge representation and reasoning)? difference that this space is symbolic (scene graph
and question in ASP). The architecture is based
• RQ2: How well do neuro-symbolic vi-
onthestate-of-the-artneuro-symbolicapproachon
sion language architectures handle reasoning-
theCLEVRdataset,NS-VQA(Yietal.,2018)and
intensive VQA tasks (in the context of map-
will be used here to study aspects of RQ2. We
ping raw inputs to symbolic space)?
modify this architecture to include an ASP solver
• RQ3: How can we leverage LLMs in thattakesasinput-thesceneinASP,thequestion
reasoning-intensive VQA tasks and what are in ASP, and the environment constraints in ASP
the challenges associated with it? to derive the answer to the question.
The question parser, (a Bidirectional Long Short
In the sections following, we describe the methods Term Memory (BiLSTM) sequence to sequence
implemented to answer these questions. model) is trained as in NS-VQA using REIN-
FORCE - the reward is positive if the ASP pro-
4.1. Methods
gramgeneratedbytheparserresultsinthecorrect
4.1.1. CLIP-based model
answer, else it is 0. The question parser is initially
CLIP (Contrastive Language Image Pre-training)
pre-trained in a fully supervised way with a small
(Radford et al., 2021) is a vision-language model
sample of (question, ASP program) pairs.
that is trained to align pairs of text and images
TheimageperceptionnetworkinNS-VQAisbased
to a unified space. We experimented with the
on Detectron (Girshick et al., 2018) and it was
CLIP model to investigate RQ1. Figure 3 shows
trained independently of the question parser in
the architecture of a CLIP-based model to solve
a supervised way. The ASP solver used is the
CLEVR-POC. The pre-trained vision transformer
same as the one used during the dataset genera-
(ViT-B/32) and the text encoders (masked self-
tion phase.
attention) in CLIP are leveraged to obtain en-
codings for the incomplete scene and the ques- 4.1.3. LLMs for solving CLEVR-POC
tion. Theencodingfortheenvironmentisobtained LLMs are leveraged in two ways for solving a rea-
from its constraints. A pre-trained GPT-2 (Rad- soning task like CLEVR-POC.
ford et al., 2019) model is used to encode the con- LLM as question parser in NS-VQA: In this
straints. As GPT-2 is more language-oriented, we approach, we use LLM as a question parser - con-
input the natural language version of ASP con- vertingthequestionintoasemanticrepresentation
straints (while experimenting with ASP-form con- like ASP. The image is converted to a scene graph
straints to assess their impact on performance). asdoneinNS-VQA.Bothsemanticrepresentations
Theproblemisformulatedasamulti-labelclassifi- arethenpassedontoaformalreasonerlikeanASP
cation problem where the output is one or more of solver to derive solutions consistent with the con-
the following 17 labels - {red, blue, green, yellow, straints.
cyan, brown, gray, purple, rubber, metal, large, Stand-alone LLM: The second approach is to
small, medium, cone, cube, cylinder, sphere}. provide both the image description and the ques-
Hence, the three encodings are passed to a multi- tionalongwiththeconstraints(inNL)asinputto
label classifier (feed-forward network) which is the LLM and generate as a response the consistent so-
only module of the whole model that is trained lutions. We,here,assumeasdoneinNS-VQAthat
from scratch. The classifier is trained with a
weighted binary cross entropy loss function (Ho 4The results in Section 4.3 are for β =5.Figure 3: CLIP for CLEVR-POC
Figure 4: NS-VQA for CLEVR-POC - architecture is updated with an ASP solver
the scene graphs are accurate, as our focus is on The value of Jaccard Index is between 0 (no com-
evaluating LLMs’ ability to perform symbolic rea- mon elements) and 1 (exact match). It gives some
soning. CLEVR-POC, a synthetic dataset where credit for partially correct answers as well.
environment-specific knowledge is not fixed, can
4.3. Results
assess LLMs’ symbolic reasoning ability without
data contamination (where the dataset becomes Tables 2a and 2b show the results for exact and
unusable once it has been exploited). partialansweraccuraciesrespectivelyforNS-VQA,
TheLLMusedintheexperimentsisGPT-4(Ope- CLIP-based models, and stand-alone GPT-4 on
nAI, 2023) (See Appendix C for details about CLEVR-POC. While NS-VQA (BiLSTM) uses a
prompts used). BiLSTM trained from scratch as the question
parser, NS-VQA (GPT-4) uses pre-trained GPT-
4.2. Evaluation 4 as the question parser. We experimented with
varying dataset sizes - 2000, 6000, and then 12000
Let A = {a1, a2,..} denote the set of values in
instances. 5 It can be seen that with a multifold
the actual answer and P = {p1, p2,..} denote the
increase in the dataset size, there is an improve-
predictedanswerset. Weevaluatetheperformance
ment in the answer accuracy, but the performance
of the two approaches on CLEVR-POC using the
is not satisfactory.
two metrics based on accuracy.
RQ1 - CLIP-based model analysis: Since the
Exact Accuracy checks whether the prediction
question is not about some object in the scene,
madeisexactlyaccurate,i.e.,Aisexactlyequalto
and the set of constraints to be satisfied is also
P.
not fixed across the instances in the dataset, it is
challenging to learn a mapping from the three in-
(cid:40)
1 if x∈A ⇐⇒ x∈P puts (the incomplete scene, the natural language
Exact Accuracy(A,P)=
question, and the constraints) to the output set of
0 otherwise
plausible values. Table 2 shows three sets of re-
(2)
Jaccard Index computes the similarity between sults for CLIP. The columns CLIP-NL and CLIP-
the actual answer and predicted answer sets as:
5The models are trained on Intel® CoreTM i7-
|A∩P| 12700K, 32GB RAM, and an NVIDIA GeForce RTX
Jaccard Index(A,P)= (3)
|A∪P| 3080 Ti for training.Dataset NS-VQA (BiLSTM) NS-VQA (GPT-4) CLIP-ASP CLIP-NL CLIP (no knowledge) GPT-4
2000 0.0200 0.9250 0.0350 0.0600 0.0500 0.4626
6000 0.1516 0.9550 0.1500 0.1700 0.1183 -
12000 0.2308 0.9441 0.1800 0.2283 0.1483 -
(a) Exact answer accuracies of CLIP, NS-VQA and GPT-4 models on CLEVR-POC.
Dataset NS-VQA (Bi-LSTM) NS-VQA (GPT-4) CLIP-ASP CLIP-NL CLIP (no knowledge) GPT-4
2000 0.0591 0.9287 0.1000 0.1557 0.1412 0.5164
6000 0.3602 0.9578 0.3100 0.3403 0.2447 -
12000 0.4331 0.9496 0.3600 0.4465 0.2912 -
(b) Jaccard Index of CLIP, NS-VQA and GPT-4 models on CLEVR-POC
Table 2: Exact accuracies and Jaccard index scores of NS-VQA with BiLSTM and GPT-4 as question
parsers,CLIPandGPT-4onCLEVR-POC.CLIP-NLandCLIP-ASPtakeconstraintsinnaturallanguage
and ASP, respectively. CLIP (no knowledge) is the performance of CLIP without constraints.
Sample Size PA (after pre-training) PA (after REINFORCE) PA (GPT-4)
28 (prompt size) - - 0.9250
≈ 200 0.0512 0 -
≈ 1000 0.4487 0.0366 -
≈ 2000 0.5043 0 -
Table 3: Drop of program accuracies (PA) after REINFORCE and the performance of GPT-4 provided
with just 28 (question, ASP program) pairs as prompt.
ASP correspond to instances of CLIP where the 1000and2000pairsof<question,ASPprogram>.
constraintsaregiveninnaturallanguageandASP Whenthesepre-trainedmodelsarefurthertrained
respectively. ItshouldbenotedthatCLIP-NLper- with REINFORCE, there is a drastic drop in the
forms better than CLIP-ASP, suggesting that rep- programaccuracyasthefocusoftheREINFORCE
resenting symbolic knowledge in natural language algorithm ison coming up withthe correct answer
may be ideal while incorporating knowledge into independent of the program’s accuracy. This fall
neural frameworks for QA. The performance of isobservedevenwiththeoriginalCLEVRdataset.
CLIP on CLEVR-POC when no external knowl- The chances of deriving the correct answer even
edge is provided is shown in the column CLIP (no with a wrong program by a fluke are higher in
knowledge). Althoughwithouttheexternalknowl- the case of CLEVR compared to CLEVR-POC
edge CLIP’s performance drops, there is not much considering the larger solution space of CLEVR-
of a difference indicating that we need to consider POC (see Section 3.4). REINFORCE clearly fails
better techniques for incorporating such symbolic to learn ASP programs through weak supervision
constraintsintoneuralframeworks. Thispointsus evenwhenitinitiatesitstrainingfromaproficient
toward existing neuro-symbolic frameworks. model.
RQ2 - NS-VQA analysis: While neural mod- RQ3 - LLM Analysis: In the first experi-
els failed in symbolic reasoning and incorporat- ment we used GPT-4 as a question parser. The
ing symbolic knowledge into the network, it can BiLSTM-based question parser of NS-VQA is re-
be seen that the major challenge faced by neuro- placed with GPT-4 (the results are shown in col-
symbolic architectures lies not in reasoning but in umn NS-VQA(GPT-4) in Tables 2a and 2b). The
mapping image or question to a symbolic repre- modelisprovidedwithjust28(question,ASPpro-
sentation in the absence of ground truth seman- gram) pairs of examples as prompts. GPT-4 with
tic representations. In our experiments, we focus no fine tuning was able to accurately predict the
on language perception while assuming 100% ac- equivalent ASP programs.
curacyinimageperception. Tacklingbothpercep-
tionssimultaneouslyisevenmoreformidablewith- The stand-alone GPT-4 approach gave less than
outaccesstogroundtruthrepresentations. Hence, 50% exact accuracy. The evidence indicates that
thepoorperformanceofNS-VQA(seecolumnNS- employing GPT-4 as a question parser to trans-
VQA(BiLSTM)inTables2aand2b)canbesolely late the question into an ASP program and subse-
attributed to the failure of REINFORCE in learn- quentlyutilizinganASPreasoningengineleadsto
ing accurate ASP programs. As mentioned in Sec- better results compared to placing the entire bur-
tion 4.1.2, a BiLSTM is initially pre-trained in a denofsymbolicreasoningonGPT-4. Itshouldalso
supervised fashion with a few examples. We ex- benotedthatGPT-4withnodata-specifictraining
perimented by varying the number of examples performed better than CLIP and NS-VQA (BiL-
provided for pre-training. Table 3 shows the pro- STM). There is still room for improvement with
gram accuarcy after pre-training with around 200, some fine-tuning.5. Discussion Autonomous Systems, and Software Program
(WASP).
We now discuss important challenges that our
dataset and work point to.
8. Bibliographical References
Reasoning and LLM: The experiments showed
that the direct application of LLMs is not a good
solution for such reasoning-intensive tasks. (Ma-
Savitha Sam Abraham and Marjan Alirezaie.
howald et al., 2023) also discusses the limitations
2022. Compositional generalization and neuro-
of LLMs in formal reasoning tasks. Our experi-
symbolic architectures. In Combining Learning
ments showed that a more appropriate approach
and Reasoning: Programming Languages, For-
to harnessing LLMs involved relieving them of the
malisms, and Representations.
task of symbolic reasoning and instead employ-
ing them for generating symbolic representations. Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu,
Progressing even further entails discovering mech- Margaret Mitchell, Dhruv Batra, C Lawrence
anismsforseamlesslyincorporatingspecificknowl- Zitnick, and Devi Parikh. 2015. Vqa: Visual
edge into LLMs and generating responses that are question answering. In IEEE international con-
consistent with this knowledge. ference on computer vision, pages 2425–2433.
Symbolic knowledge in visual perception
O Blender. 2018. Blender—a 3d modelling and
network: Although the focus of this paper was
rendering package. Retrieved. represents the se-
on language and reasoning, it may be noted that
quence of Constructs1 to, 4.
knowledge in the form of constraints in CLEVR-
POC can play a significant role during image per-
TomBrown,BenjaminMann,NickRyder,Melanie
ceptionasitcanprovidehintsonwhatcanorcan-
Subbiah, Jared D Kaplan, Prafulla Dhariwal,
notbeintheimage. Thisisaformofweaksupervi-
ArvindNeelakantan,PranavShyam,GirishSas-
sionwhichisalsorequiredintheabsenceofground
try, AmandaAskell, etal.2020. Languagemod-
truth scene graphs to accelerate the learning pro-
els are few-shot learners. Advances in neural in-
cess. Developing neuro-symbolic models with a
formation processing systems, 33:1877–1901.
strongerfeedbackmechanismforvisualperception,
such as DeepProbLog (Manhaeve et al., 2018), Abhishek Das, Samyak Datta, Georgia Gkioxari,
NeurASP (Yang et al., 2020), Semantic-Loss (Xu StefanLee,DeviParikh,andDhruvBatra.2018.
etal.,2018)andLTN(SerafiniandGarcez,2016)), Embodiedquestionanswering. InIEEE Confer-
would help in faster convergence. The aforemen- ence on Computer Vision and Pattern Recogni-
tionedframeworks,however,cannotstillbeapplied tion, pages 1–10.
to VQA tasks due to scalability issues.
Abhishek Das, Satwik Kottur, Khushi Gupta, Avi
Singh, Deshraj Yadav, Jos´e MF Moura, Devi
6. Conclusion
Parikh, and Dhruv Batra. 2017. Visual dialog.
Humans often have to interact with the partially InIEEE conference on computer vision and pat-
observable environment. In light of the need to tern recognition, pages 326–335.
deal with the inherent uncertainty in knowledge-
Harm De Vries, Florian Strub, Sarath Chandar,
richreal-worldscenarios,thisworkaimedtoestab-
Olivier Pietquin, Hugo Larochelle, and Aaron
lishabenchmarkforevaluatingreasoning-intensive
Courville. 2017. Guess what?! visual object dis-
VQA in partially observable environments. Ap-
covery through multi-modal dialogue. In IEEE
plying the benchmark to stand-alone LLMs and
Conference on Computer Vision and Pattern
othervision-languagemodelsyieldeddisappointing
Recognition, pages 5503–5512.
results due to their inability to perform symbolic
reasoning. We also demonstrated that combining
Artur d’Avila Garcez, Marco Gori, Luis C Lamb,
LLM with a visual perception network and a for-
Luciano Serafini, Michael Spranger, and Son N
mal reasoner produced positive results.
Tran. 2019. Neural-symbolic computing: An ef-
Futuredirectionsinvolvedevelopingvisualpercep-
fectivemethodologyforprincipledintegrationof
tion networks with knowledge-guided supervision,
machine learning and reasoning. arXiv preprint
enhancing LLMs’ reasoning capabilities, and mov-
arXiv:1905.06088.
ingCLEVR-POCtoanembodiedsetuplikevision
language navigation. RossGirshick,IlijaRadosavovic,GeorgiaGkioxari,
Piotr Doll´ar, and Kaiming He. 2018. Detectron.
7. Acknowledgements
YaoshiangHoandSamuelWookey.2019. Thereal-
This research was conducted during the au- world-weight cross-entropy loss function: Mod-
thors’ tenure at O¨rebro University, Sweden and eling the costs of mislabeling. IEEE access,
was financially supported by the Wallenberg AI, 8:4806–4813.Jie Huang and Kevin Chen-Chuan Chang. 2023. Giuseppe Marra, Sebastijan Dumanˇci´c, Robin
Towards reasoning in large language models: A Manhaeve, and Luc De Raedt. 2021. From
survey. In Findings of the Association for Com- statistical relational to neural symbolic arti-
putational Linguistics: ACL 2023, pages 1049– ficial intelligence: a survey. arXiv preprint
1065, Toronto, Canada. Association for Compu- arXiv:2108.11451.
tational Linguistics.
ShoyaMatsumori, KosukeShingyouchi, YukiAbe,
Justin Johnson, Bharath Hariharan, Laurens Van Yosuke Fukuchi, Komei Sugiura, and Michita
DerMaaten,LiFei-Fei,CLawrenceZitnick,and Imai. 2021. Unified questioner transformer for
RossGirshick.2017. Clevr: Adiagnosticdataset descriptive question generation in goal-oriented
for compositional language and elementary vi- visual dialogue. In IEEE/CVF International
sualreasoning. InIEEE conference on computer Conference on Computer Vision, pages 1898–
vision and pattern recognition,pages2901–2910. 1907.
Incheol Kim. 2020. Visual experience-based ques- Rui Da Silva Neves, Jean-Fran¸cois Bonnefon, and
tion answering with complex multimodal envi- Eric Raufaste. 2000. Rationality in human non-
ronments. Mathematical Problems in Engineer- monotonic inference.
ing, 2020.
OpenAI. 2023. Gpt-4 technical report.
Satwik Kottur, Jos´e MF Moura, Devi Parikh,
Dhruv Batra, and Marcus Rohrbach. 2019. Alec Radford, Jong Wook Kim, Chris Hallacy,
Clevr-dialog: A diagnostic dataset for multi- Aditya Ramesh, Gabriel Goh, Sandhini Agar-
round reasoning in visual dialog. arXiv preprint wal, Girish Sastry, Amanda Askell, Pamela
arXiv:1903.03166. Mishkin,JackClark,etal.2021. Learningtrans-
ferable visual models from natural language su-
Yann LeCun, L´eon Bottou, Yoshua Bengio, and
pervision. In International Conference on Ma-
Patrick Haffner. 1998. Gradient-based learn-
chine Learning, pages 8748–8763. PMLR.
ing applied to document recognition. IEEE,
86(11):2278–2324. Alec Radford, Jeffrey Wu, Rewon Child, David
Luan,DarioAmodei,IlyaSutskever,etal.2019.
Vladimir Lifschitz. 2008. What is answer set pro-
Language models are unsupervised multitask
gramming? In23rd National Conference on Ar-
learners. OpenAI blog, 1(8):9.
tificial Intelligence - Volume 3, AAAI’08, page
1594–1597. AAAI Press.
Luciano Serafini and Artur d’Avila Garcez. 2016.
Logic tensor networks: Deep learning and logi-
Hugh MacColl. 1897. Symbolic reasoning. Mind,
cal reasoning from data and knowledge. arXiv
6(24):493–510.
preprint arXiv:1606.04422.
Kyle Mahowald, Anna A Ivanova, Idan A Blank,
DhruvShah,MichaelRobertEqui,B(cid:32)laz˙ejOsin´ski,
Nancy Kanwisher, Joshua B Tenenbaum, and
Fei Xia, Sergey Levine, et al. 2023. Navigation
Evelina Fedorenko. 2023. Dissociating lan-
withlargelanguagemodels: Semanticguesswork
guage and thought in large language mod-
as a heuristic for planning. In 7th Annual Con-
els: a cognitive perspective. arXiv preprint
ference on Robot Learning.
arXiv:2301.06627.
Mateusz Malinowski and Mario Fritz. 2014. A Sanket Shah, Anand Mishra, Naganand Yadati,
multi-world approach to question answering and Partha Pratim Talukdar. 2019. Kvqa:
about real-world scenes based on uncertain in- Knowledge-aware visual question answering.
put. Advances in neural information processing Proceedings of the AAAI Conference on Artifi-
systems, 27. cial Intelligence, 33(01):8876–8884.
Robin Manhaeve, Sebastijan Dumancic, Angelika PengWang,QiWu,ChunhuaShen,AnthonyDick,
Kimmig,ThomasDemeester,andLucDeRaedt. and Anton Van Den Hengel. 2017. Fvqa: Fact-
2018. Deepproblog: Neural probabilistic logic based visual question answering. IEEE trans-
programming. advances in neural information actions on pattern analysis and machine intelli-
processing systems, 31. gence, 40(10):2413–2427.
Jiayuan Mao, Chuang Gan, Pushmeet Kohli, QiWu,DamienTeney,PengWang,ChunhuaShen,
Joshua B Tenenbaum, and Jiajun Wu. 2019. Anthony Dick, and Anton Van Den Hengel.
The neuro-symbolic concept learner: Interpret- 2017. Visual question answering: A survey of
ing scenes, words, and sentences from natural methods and datasets. Computer Vision and
supervision. arXiv preprint arXiv:1904.12584. Image Understanding, 163:21–40.JingyiXu,ZiluZhang,TalFriedman,YitaoLiang,
and Guy Broeck. 2018. A semantic loss func-
tion for deep learning with symbolic knowledge.
InInternationalconferenceonmachinelearning,
pages 5502–5511. PMLR.
Zhun Yang, AdamIshay, and Joohyung Lee. 2020.
Neurasp: Embracing neural networks into an-
swer set programming. In 29th International
Joint Conference on Artificial Intelligence (IJ-
CAI 2020).
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du,
Izhak Shafran, Karthik Narasimhan, and Yuan
Cao. 2022. React: Synergizing reasoning and
acting in language models. arXiv preprint
arXiv:2210.03629.
Kexin Yi, Jiajun Wu, Chuang Gan, Antonio Tor-
ralba, Pushmeet Kohli, and Josh Tenenbaum.
2018. Neural-symbolic vqa: Disentangling rea-
soning from vision and language understanding.
Advances in neural information processing sys-
tems, 31.
Gengze Zhou, Yicong Hong, and Qi Wu. 2023.
Navgpt: Explicit reasoning in vision-and-
languagenavigationwithlargelanguagemodels.
arXiv preprint arXiv:2305.16986.
Yeyun Zou and Qiyu Xie. 2020. A survey on vqa:
Datasets and approaches. In 2020 2nd Inter-
national Conference on Information Technology
and Computer Application (ITCA), pages 289–
297. IEEE.1-9. Objects must have 4 properties. They are color,
shape, size, and material.
1-4. Objects can be in one of the 8 colors. It can
be gray, or red, or blue, or green, or brown,
or purple, or cyan, or yellow.
5-6. Objects can be in one of the 4 shapes.
It can be cube, or a cylinder, or a sphere or cone.
7-8. Objects can be in one of the 3 sizes.
It can be small, medium, or large.
9. Objects can be in one of the 2 materials.
It can be rubber or metal.
Figure 5: A complete and incomplete scene from
10. The scene is divided into 4 regions.
CLEVR-POC
They are named 0, 1, 2, 3.
11. If there are two objects, the first object is
located in region 0 and the second object is to
A. An example from CLEVR-POC
the right of the first object, then the location
of the second object is either in region 0, 1, or
Complete and incomplete scene: Figure 5 is 2, or 3.
anexampleofacompletesceneandtheincomplete
12. If there are two objects, the first object is
scene generated from it by hiding the small red located in region 1 and the second object is to
rubber sphere. the right of the first object, then the location
of the second object is either in region 1, or 3.
Environment Every scene is generated such that
it satisfies the constraints in an environment. The 13. If there are two objects, the first object is
located in region 2 and the second object is to
following are the general rules shared by all envi- the right of the first object, then the location
ronments in CLEVR-POC. of the second object is either in region 0, 1, 2, or 3.
14. If there are two objects, the first object is
1. property(color, gray). property(color, red). located in region 3 and the second object is to
2. property(color, blue). property(color, green). the right of the first object, then the location
3. property(color, brown). property(color, purple). of the second object is either in region 1, or 3.
4. property(color, cyan). property(color, yellow).
5. property(shape, cube). property(shape, cylinder). 15. If there are two objects, the first object is
6. property(shape, sphere). property(shape, cone). to the right of the second object, then the second
7. property(size, small). property(size, medium). the object is to the left of the first object.
8. property(size, large).
9. property(material, rubber). 16. If there are two objects, the first object is
property(material, metal). located in region 0 and the second object is in
10. region(0). region(1). region(2). region(3). front of the first object, then the location of
11. right_R(0, 0). right_R(0, 1). right_R(0, 2). the second object is either in region 0, 1, or
right_R(0, 3). 2, or 3.
12. right_R(1, 1). right_R(1, 3).
13. right_R(2, 0). right_R(2, 1). right_R(2, 2). 17. If there are two objects, the first object is
right_R(2, 3). located in region 1 and the second object is in
14. right_R(3, 1). right_R(3, 3). front of the first object, then the location of
15. left_R(R1, R2) :- right_R(R2, R1). the second object is either in region 0, 1, or
16. front_R(0, 0). front_R(0, 1). front_R(0, 2). 2, or 3.
front_R(0, 3).
17. front_R(1, 0). front_R(1, 1). front_R(1, 2). 18. If there are two objects, the first object is
front_R(1, 3). located in region 2 and the second object is in
18. front_R(2, 2). front_R(2, 3). front of the first object, then the location of
19. front_R(3, 2). front_R(3, 3). second object is either in region 2, or 3.
20. behind_R(R1, R2) :- front_R(R2, R1).
21. sameProperty(X1, X2, P) :- hasProperty(X1,P,V),} 19. If there are two objects, the first object is
22. hasProperty(X2,P,V), X1!=X2. located in region 3 and the second object is in
23. same_color(X,Y):- sameProperty(X, Y, color). front of the first object, then the location of
24. same_size(X,Y):- sameProperty(X, Y, size). the second object is either in region 2, or 3.
25. same_shape(X,Y):- sameProperty(X, Y, shape).
26. same_material(X,Y):- sameProperty(X, Y, material). 20. If there are two objects, the first object is
27. 1{hasProperty(X, color, V) : in front of the second object, then the second
28. property(color, V)}1 :- object(X). the object is behind the first object.
29. 1{hasProperty(X, material, V) :
30. property(material, V)}1 :- object(X). 27-28. Every object must be assigned exactly one
31. 1{hasProperty(X, shape, V) : value for color.
32. property(shape, V)}1 :- object(X).
33. 1{hasProperty(X, size, V) : 29-30. Every object must be assigned exactly one
34. property(size, V)}1 :- object(X). value for the material.
35.1{at(X, R): region(R)}1 :- object(X).
36.:- sameProperty(X1, X2, color), 31-32. Every object must be assigned exactly one
37. sameProperty(X1, X2, material), value for shape.
38. sameProperty(X1, X2, size)},
39. sameProperty(X1, X2, shape), 33-34. Every object must be assigned exactly one
40. object(X1), object(X2), X1!=X2. value for size.
41.exceed_region_capacity(R) :-
42. #count{X: object(X), at(X, R)} >= 4, region(R). 35. Every object must be assigned exactly one value
43:- exceed_region_capacity(_). for region.
36-40. Two different objects cannot have the same values
Environment’s general rules in natural language:for all the 4 properties. The following is the same question represented
in ASP:
41-43. Every region can have at most 3 objects.
1. missing(Q) :-
ThefollowingconstraintsinASPrepresentthespe-
2. hasProperty(X,size,Q),
cific environment to which the scene in Figure 5 3. hasProperty(X,material,rubber),
4. hasProperty(X,color,red),
belongs.
5. hasProperty(Y,color,purple),
6. hasProperty(Y,size,large),
44. object(0..4). 7. X!=Y,
45. :- object(X), at(X, 0), 8. same_shape(Y,X).
hasProperty(X, size, large).
46. :- object(X), at(X, 0), Answer set: The answer set for the above ques-
hasProperty(X, shape, cylinder).
47. :- object(X), at(X, 0), tion that satisfies the constraints in the specified
hasProperty(X, shape, cone). environment is:
48. :- object(X), at(X, 1),
hasProperty(X, size, small).
49. :- object(X), at(X, 1), {small, medium}
hasProperty(X, shape, cone).
50. :- object(X), at(X, 1),
Reasoning Steps: The reasoning involved in de-
hasProperty(X, material, rubber).
51. :- object(X), at(X, 1), riving the answer set from the question, the in-
hasProperty(X, shape, cube).
completescene,andtheconstraintsinthespecified
52. :- object(X), at(X, 2),
not hasProperty(X, size, medium). environment is given below.
53. :- object(X), at(X, 2),
not hasProperty(X, material, metal).
54. :- object(X), at(X, 2), • Interpreting each line of the question:
hasProperty(X, material, rubber).
55. :- object(X), at(X, 2),
hasProperty(X, shape, sphere).
1. What are the possible values for Q such that:
56. :- object(X), at(X, 2),
2. Q is size of the missing object,
hasProperty(X, shape, cube).
57. :- object(X), at(X, 3), 3. the missing object’s material is rubber,
hasProperty(X, size, small). 4. the missing object’s color is red,
58 :- object(X), at(X, 3), 5. the reference object’s color is purple,
not hasProperty(X, material, metal), 6. the reference object’s size is large,
59. not hasProperty(X, color, blue). 7. the missing object is not equal to the
60. :- #count{X1, X2: sameProperty(X1, X2, shape), reference object,
61. object(X1), object(X2), at(X1, 3), at(X2, 2),
8. the missing object’s shape = the
62. hasProperty(X1, color, yellow),
reference object’s shape.
63. hasProperty(X2, color, yellow)} >= 4.
64. :- #count{X1, X2: sameProperty(X1, X2, color),
65. object(X1), object(X2), • Inferring the missing object’s properties:
66. at(X1, 0), at(X2, 3)} >= 2.
from the scene graph: =>
The following is a natural language interpretation
of each line of the preceding rules.
8. the reference object’s shape is a sphere.
9. => The missing object’s shape is also a sphere.
44. There are 5 objects in the scene. 10. => The missing object is a red rubber sphere.
45. There are no large size objects in region 0.
46. There are no cylinder shape objects in region 0.
47. There are no cone shape objects in region 0. • Inferring the missing object’s possible re-
48. There are no small size objects in region 1. gions based on the rules listed as the
49. There are no cone shape objects in region 1. Environment’s constraints:
50. There are no rubber material objects in region 1.
51. There are no cube shape objects in region 1.
Among the four regions:
52. All objects in region 2 have medium size.
53. All objects in region 2 have metal material.
54. There are no rubber material objects in region 2.
A red rubber sphere CAN be located at region 0,
55. There are no sphere shape objects in region 2.
as none of the constraints in lines 45-47 is
56. There are no cube shape objects in region 2.
57. There are no small size objects in region 3. violated.
58-59. All objects in region 3 have either metal
material or blue color. A red rubber sphere CAN’T be located in region
60-63. There are at most 1 pairs of color yellow 1, as it violates the constraint about the
objects with the same shape in regions 3 and 2 material at line 50.
together.
64-66. There are at most 0 pairs of objects with the
A red rubber sphere CAN’T be located in region
same color in regions 0 and 3 together.
2, as it violates the constraints in lines 53,
54, and 55.
Question: For each given incomplete scene, we
A red rubber sphere CAN’T be located in region
generate one question about (any property) of the
3, as it violates the constraints in lines 58-59.
missing object. The following is the question in
natural language that is associated with the in- => The missing red rubber sphere is located at
region 0.
complete scene in Figure 5:
There is another red rubber object that is the • Inferring the possible answer set for the prop-
same shape as the big purple object; what size erty of interest w.r.t the inferred location of
is it? the missing object:Figure 6: (a) Question templates distribution (b) Distribution of query attributes with object counts
between 5 to 9.
There are 3 possible values for the size for the dataset. Figure 7 (a) displays the question
property: typedistributionofthedatasetgeneratedbasedon
small, medium, large.
this setting.
The environment constraint at line 45 discards Distributionacrosssolutions: Figure7(b),(c),
the large size for region 0. (d), and (e) illustrate the distribution of potential
solutions for various question types: size, shape,
=> The possible answer set for Q is:
small, medium. material, and color, respectively. We aim for a
balanced distribution, avoiding a situation where
B. Dataset Statistics the majority of questions lead to the same set of
Distribution across question templates: Fig- answers. Forinstance,whenaquestionpertainsto
ure 6 (a) shows the distribution of questions thesizeofanobject,itspossiblesolutionscouldbe
across different question templates. Six templates oneof{large,medium}or{large,small},or{small,
present in the original CLEVR dataset are used in medium}or{large},or{medium}or{small}asde-
CLEVR-POC. pictedinFigure7(b). Sincethepossiblesolutions
Distribution of query attributes with num- for questions with query attribute color are large
ber of objects in the scene: Figure6(b)shows (ascolor cantake8values), theentirespaceisnot
the distribution of questions of a specific type listed in Figure 7(e). However, it can be seen that
based on the number of objects in the scene. the distribution is not favoring any specific solu-
Distribution across question types: The type tion.
of question asked depends on the attribute of the
C. Prompts for Language Model
object that is being inquired about. The genera-
tion process enables the user to have control over C.1. Stand-alone GPT-4 to solve
this distribution. For instance, when generating CLEVR-POC
the specific dataset that was used in the experi-
TheformatofthepromptprovidedtoGPT-4when
ments, we established the following criteria: 40%
employing it to solve CLEVR-POC is shown be-
of the questions pertain to the color attribute, an-
low. The prompt contains the task description,
other 40% focus on the shape attribute, 10% ad-
thescenedescription,theconstraintsorknowledge
dressthesizeattribute,andtheremaining10%re-
associated with the scene, the question about the
late to the material attribute. We made this selec-
scene, and the answer. The prompt contains two
tion based on the observation that attributes like
such examples.
color and shape encompasses a larger set of values
(8 values for color and 4 for shape) in comparison Task description: You are a helpful assistant who
answersquestionsabouthiddenobjectsbasedonscene
to material (which has just two values). Conse-
descriptionandtheconstraintsinthescene. Thescene
quently, the solution space for questions centered graphisinJSONformatwiththefollowingkeys. The
key objects contain a list of objects present in the
around color is more extensive than that for ma- scene. Each object has various attributes like mate-
terial, resulting in a more diverse solution spaceFigure 7: (a) Distribution of question types. (b) Distribution of solutions for questions with query
attribute size. (c) Distribution of solutions for questions with query attribute material. (d) Distribution
of solutions for questions with query attribute shape. (e) Distribution of solutions for questions with
query attribute color. Since the solution space of these questions is larger (>100), it is not listed here.
rial, color, shape, size, and region. The key relation- }
shipsholdinformationaboutthespatialrelationships
],
between objects in the scene. It contains sub-fields
like”front,””right,””left,””behind,”etc.,eachasso- ’relationships’:
ciatedwithalistofobjectindicesrepresentingobjects {’left’: [[4], [0, 2, 4, 5], [0, 4, 5],
that have that specific relationship with another ob-
[0, 1, 2, 4, 5], [], [0, 4]],
ject. For example, relationships[”front”][0] refers to
’front’: [[1, 3, 4, 5], [5], [0, 1, 3, 4,
theobjectsthatareinfrontoftheobjectatindex0.
5], [1, 5], [1, 3, 5], []],
Scene Observed: Thefollowingisthescenegraph:
’behind’: [[2], [0, 2, 3, 4], [], [0, 2,
4], [0, 2], [0, 1, 2, 3, 4]],
’right’: [[1, 2, 3, 5], [3], [1, 3], [],
{’objects’: [
[0, 1, 2, 3, 5], [1, 2, 3]]
{’material’: ’metal’, ’color’: ’red’,
}
’size’: ’medium’, ’region’: ’0’,
}
’shape’: ’cube’
}, Constraints: The scene contains several visible ob-
{’material’: ’metal’, ’color’: ’gray’,
jects, and has one additional object that is hidden.
’size’: ’medium’, ’region’: ’3’,
Objects must have 4 properties. They are color,
’shape’: ’sphere’
}, shape, size, and material. The scene must conform
{’material’: ’metal’, ’color’: ’brown’, tothefollowingconstraints.
’size’: ’medium’, ’region’: ’1’,
’shape’: ’sphere’
}, Objects can be in one of the 8 colors. It
{’material’: ’rubber’, ’color’: ’gray’, can be gray, or red, or blue, or green,
’size’: ’medium’, ’region’: ’3’, or brown, or purple, or cyan, or
’shape’: ’sphere’ yellow.
},
{’material’: ’metal’, ’color’: ’red’, Objects can be in one of the 4 shapes. It
’size’: ’medium’, ’region’: ’0’, can be a cube, cylinder, sphere, or
’shape’: ’sphere’ cone.
},
{’material’: ’rubber’, ’color’: ’red’, Objects can be in one of the 3 sizes. It can
’size’: ’medium’, ’region’: ’2’, be small, medium, or large.
’shape’: ’sphere’Objects can be in one of the 2 materials. It
can be rubber or metal. Every object must be assigned exactly one
value for color.
The scene is divided into 4 regions. They
are named 0, 1, 2, 3. Every object must be assigned exactly one
value for material.
If there are two objects and the first
object is located in region 0 and the Every object must be assigned exactly one
second object is to the right of the value for shape.
first object, then the location of the
second object is either in region 0, 1, Every object must be assigned exactly one
2, or 3. value for size.
If there are two objects and the first Every object must be assigned exactly one
object is located in region 1 and the value for region.
second object is to the right of the
first object, then the location of the Two different objects cannot have the same
second object is either in region 1, or values for all the 4 properties.
3.
Every region can have at most 3 objects.
If there are two objects and the first
object is located in region 2 and the There are 6 objects in the scene.
second object is to the right of the
first object, then the location of the There are at least 1 pair of color red
second object is either in region 0, 1, objects with the same size in regions 0
2, or 3. and 2 together.
If there are two objects, the first object There are no small-size objects in region 0.
is located in region 3 and the second
object is to the right of the first There are no cone-shaped objects in region
object, then the location of the second 0.
object is either in region
1, or 3. There are no purple color objects in region
0.
If there are two objects, the first object
is to the right of the second object, There are no blue color objects in region 0.
then the second object is to the left
of the first object. There are no cylinder shape objects in
region 1.
If there are two objects, the first object
is located in region 0 and the second There are no cyan color objects in region 1.
object is in front of the first object,
then the location of the second object There are no rubber material objects in
is either in region 0, 1, 2, or 3. region 1.
If there are two objects, the first object There are at least 1 pair of material metal
is located in region 1 and the second objects with the same size in regions 0
object is in front of the first object, and 3 together.
then the location of the second object
is either in region 0, or 1, or 2, or There are no metal material objects in
3. region 2.
If there are two objects, the first object There are no large-size objects in region 2.
is located in region 2 and the second
object is in front of the first object, There are at least 1 pair of size medium
then the location of the second object objects with the same shape in regions
is either in region 2, or 3. 1 and 3 together.
If there are two objects, the first object There are no red color objects in region 3.
is located in region 3 and the second
object is in front of the first object, There are no cube-shaped objects in region
then the location of the second object 3.
is either in region 2, or 3.
There are at least 1 pair of objects with
If there are two objects, the first object the same material in regions 0 and 1
is in front of the second object, then together.
the second object is behind the first
object. There are at least 1 pair of color grayobjects with the same size in regions 3
and 2 together.
Question: Answer the following question about the
hidden object. The solution should satisfy the con-
straints. Theothercylinderthatisthesamematerial
asthemediumredthingiswhatcolor?
Answer: ###{Gray}###
C.2. GPT-4 as Question Parser
WhenweuseGPT-4toparseaquestiontoitsASP
equivalent,wegiveasprompt28examplesofques-
tions in natural language to ASP representation.
The prompt with just one Question-ASP pair is
shown below.
Task description: You are a helpful assistant that
convertsquestionsinEnglishintoASPlogiclanguage.
Question: What is the color of the cylinder to the
rightofthebluesphere?
ASP:
###
unknown(Q):-hasProperty(X, color, Q),
hasProperty(X, shape, cylinder)
,
hasProperty(X1, color, blue),
hasProperty(X1, shape, sphere),
right(X1, X).
###