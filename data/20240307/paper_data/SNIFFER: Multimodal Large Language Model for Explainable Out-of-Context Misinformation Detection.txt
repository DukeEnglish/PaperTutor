SNIFFER: Multimodal Large Language Model
for Explainable Out-of-Context Misinformation Detection
PengQi,ZehongYan,WynneHsu,MongLiLee
NationalUniversityofSingapore
peng.qi@nus.edu.sg, e0787894@u.nus.edu,{whsu,leeml}@comp.nus.edu.sg
https://pengqi.site/Sniffer
Does this caption match its image?
Caption:Jeffrey E Thompson on Monday pleaded guilty in federal court to funding
a shadow campaign to help Vincent C Gray win the 2010 mayoral election.
Exis%ngdetectors No, the image is wrongly used in a No, the image is wrongly used Sniffer
different news context. The given GPT-4V in a different news context. (Ourdetector) No! news caption and image are On the one hand, the person
inconsistent in person. The person in the caption, Jeffrey E
in the caption is Jeffrey E Thompson, does not match
InstructBLIP
No, the image is wrongly Thompson, and the person in the the person in the image, Harry
used in a different news image is Vincent C Gray. To Thomas Jr. On the other hand,
context. The given news elaborate, the news caption is the image-retrieved webpages
caption and image are about Jeffrey E Thompson pleading contain a series of news
inconsistent in person. guilty to funding a shadow articles about Harry ThomasJr,
The person in caption is campaign, but the person depicted whicharenotrelevanttothe
Jeffrey E Thompson, and in the image is Vincent C Gray, who givencaption.Therefore, the
the person in image is is mentioned in the caption as the image is more likely to be
Vincent C Gray. beneficiary of the campaign. wrongly used in the caption.
Figure 1. Comparison between the proposed SNIFFER and other detectors1. In this out-of-context misinformation, the individual in
the image is Harry Thomas Jr, which contradicts the caption. Existing detectors often give a judgment without explanation. While
InstructBLIPandGPT-4Vcorrectlyidentifytheinconsistentnewselement(i.e.person)intheimage-textpair,theymistakenlyassociate
thepersonintheimagewithadifferentindividualmentionedinthecaption. Incontrast, SNIFFER analyzesboththeconsistencyofthe
image-textcontentandtheclaim-evidencerelevance,andaccuratelyidentifythepersonintheimageasHarryThomasJr,therebyproviding
apreciseandpersuasiveexplanation.
Abstract SNIFFERemploystwo-stageinstructiontuningonInstruct-
BLIP.Thefirststagerefinesthemodel’sconceptalignment
Misinformation is a prevalent societal issue due to its of generic objects with news-domain entities and the sec-
potential high risks. Out-Of-Context (OOC) misinforma- ondstageleverageslanguage-onlyGPT-4generatedOOC-
tion,whereauthenticimagesarerepurposedwithfalsetext, specific instruction data to fine-tune the model’s discrimi-
is one of the easiest and most effective ways to mislead natory powers. Enhanced by external tools and retrieval,
audiences. Current methods focus on assessing image- SNIFFER notonlydetectsinconsistenciesbetweentextand
text consistency but lack convincing explanations for their image but also utilizes external knowledge for contextual
judgments, which is essential for debunking misinforma- verification.OurexperimentsshowthatSNIFFERsurpasses
tion. WhileMultimodalLargeLanguageModels(MLLMs) theoriginalMLLMbyover40%andoutperformsstate-of-
have rich knowledge and innate capability for visual rea- the-art methods in detection accuracy. SNIFFER also pro-
soningandexplanationgeneration, theystilllacksophisti- videsaccurateandpersuasiveexplanationsasvalidatedby
cation in understanding and discovering the subtle cross- quantitativeandhumanevaluations.
modal differences. In this paper, we introduce SNIFFER, a
novel multimodal large language model specifically engi- 1.Introduction
neeredforOOCmisinformationdetectionandexplanation.
In recent years, Deepfake and other media manipulation
1Duetospaceconstraints, wehavemademinoreditstothemodels’ technologies[42,44,46,53]havegarneredconsiderableat-
responsesforbrevitywithoutalteringtheiroriginalmeaning. tention from both the computer vision community and the
1
4202
raM
5
]MM.sc[
1v07130.3042:viXrageneral public, due to their lifelike qualities and their sig- identifyingandcontextualizingevents.
nificant influence in accelerating the spread of fake news. To address these challenges, we introduce SNIFFER, an
Nevertheless, one of the easiest and most prevalent ways MLLM specifically engineered for detecting OOC misin-
to mislead audiences is to use unaltered images in a new formation. We utilize language-only GPT-4 [34] to gen-
but false or misleading context, known as out-of-context eratetheinstructiondatathatincludesbothjudgmentsand
(OOC)misinformation[12].Forexample,duringtherecent explanation,andemploytwo-stageinstructiontuningonIn-
Israel-Hamaswar,numerousinstancesofOOCmisinforma- structBLIP.Wefirstrefinethemodel’sconceptalignmentof
tion were observed on social media. These often involved generic objects with news-domain entities by image cap-
repurposing old images from unrelated armed conflicts or tioning data, and then leverage the OOC-specific data to
evenmilitaryfootagefromvideogames[2].Detectingsuch fine-tunethemodel’sdiscriminatorypowers. Throughtask-
OOC misinformation poses a unique challenge since the specific tuning, the inherent knowledge within the model
visual content remains authentic, and the deception stems can be activated and reorganized to align with the specific
solelyfromthecontextcreatedbycombiningtheseimages logic required by our task. This is the first attempt to ex-
withmisleadingorincorrecttext. tendmultimodalinstructiontuningtothenewsdomainfor
end-to-endtrainingofanOOCmisinformationdetector.
Facedwiththischallenge,currentstudies[3,16,17,29,
31,36,41]focusonlearningaunifiedlatentrepresentation
Moreover, SNIFFER is augmented with external knowl-
edgethrough retrievalandtoolusage. Itconducts internal
spacetoassesstheconsistencyofimage-textpairsorcom-
checking to spot inconsistencies between text and image,
parethemwithexternalreferences. Whiletheseapproaches
andexternalcheckingtoreasonbetweenthegiventextand
have made some progress, the development of convincing
retrieved image context. The judgments and explanations
explanations for these judgments, critical for establishing
derivedfromthesetwoperspectivesarethenintegratedinto
publictrustandmoreeffectivelydebunkingmisinformation
theLLMmoduleforamorecomprehensiveandunifiedout-
[7, 26], still remains unexplored. Although some works
put. Empoweredbymultimodalinstructiontuninganden-
[3, 29] visualize salient objects and words based on the
model’sattentionweights,itisstillunclearwhythesehigh-
hanced with external knowledge, SNIFFER demonstrates a
significant performance improvement, exceeding the orig-
lightedregionssignifymisinformation. Therefore,itisim-
inal MLLM by over 40% and surpassing current state-of-
portanttodeveloptechnologiescapableofnotonlydetect-
ingbutalsoexplainingout-of-contextmisinformation.
the-artmethods.Beyondaccuratejudgments,SNIFFERalso
excelsinprovidingpreciseandpersuasiveexplanations,as
Multimodallargelanguagemodels(MLLMs)havemade
evidencedbyquantitativeanalysisandhumanevaluations.
great advancements in a variety of multimodal tasks [19,
Ourcontributioncanbesummarizedasfollows:
49]. With their extensive world knowledge and robust vi-
• We design a novel data reformation pipeline assisted by
sual reasoning and generation capabilities, MLLMs have
language-only GPT-4 to convert the given OOC image-
the potential to detect factual inconsistency in image-text
text pairs into the appropriate instruction-following for-
pairs and to generate coherent, natural language-based ex-
matwithjudgmentsandexplanationssimultaneously.
planations. However,applyingexistingMLLMstothetask
• We propose a practical approach to adapt existing
ofOOCmisinformationdetectionisnon-trivial. Ontheone
general-purpose MLLMs for out-of-context misinforma-
hand, initial experiments on some open-sourced MLLMs
tion detection through two-stage instruction tuning. Our
(suchasInstructBLIP[9])revealedcommonshortcomings,
task-specific MLLM, SNIFFER, enhanced with external
including failure to follow instructions, misunderstanding
tools and retrieval, effectively models both the internal
of user’s intent, and hallucination (detailed in Supplemen-
image-textcluesandtheexternalclaim-evidencecluesfor
tary). These shortcomings may stem from the fundamen-
simultaneousOOCdetectionandexplanation.
tal differences between the training corpus for MLLMs
• Extensive experiments show that SNIFFER significantly
and the requirements of the specific task. In OOC detec-
surpassestheoriginalMLLMandSOTAmethodsinde-
tion,themodelmustdiscernwhentextandimagesdescribe
tection performance, achieves comparable results with
disparate news events, which are typically not present in
just 10% of the training data, and provides precise and
MLLMs’trainingdata. Ontheotherhand, thenewsevent
persuasive explanations validated by both quantitative
from which the image originates may not be discernible
andhumanassessments.
from the image itself. For example, news images accom-
panyingreportsofpublicfiguresspeakingatvariousevents
2.RelatedWork
aregenerallysimilarclose-upshotsoftheindividuals,mak-
ingitalmostimpossibletodistinguishfromtheimagecon- Out-of-ContextMisinformationDetection.Existingmul-
tent alone which news scene or event the image is from. timodalmisinformationdetectionmethodsextractandfuse
MLLMs have inherent limitations as they lack the ability featuresfromdifferentperspectives, suchaslinguisticpat-
toaccessreal-timeinformationorutilizeexternaltoolsfor terns [37], image tampered patterns [38, 42], multimodal
2inconsistency[39,54],userresponse[43],andpropagation is how to construct high-quality instructions that properly
structure [30], to classify the given news as real or fake. cover the desired target behaviors. In addition to adapting
Out-of-contextmisinformation,alsoknownasimagerepur- existingbenchmarks[9],someworks[18,27]collectsam-
posingandcheapfake,isaspecificformofmisinformation ples through self-instruction [48], which bootstraps LLMs
that is easy to create and highly misleading. It reuses au- to generate textual instruction-following data using a few
thentic images within a similar yet incorrect context, ren- hand-annotatedsamples. ThesuccessofLLMsinthegen-
deringmanytraditionaldetectionmethodsineffective[52]. eral domain has inspired interest in applications such as
To detect OOC misinformation, some methods uti- biomedical[20],law[15]andeducation[51]. Inthiswork,
lize knowledge-rich pre-trained models to conduct inter- we extend the ability of general-domain MLLM for OOC
nal checking for the given image-text pair. For example, misinformationdetectionviainstructiontuning.
[29, 36] use the multimodal pre-trained models CLIP [40]
and VisualBERT [23] to classify. Other methods employ 3.Method
external resources to do external checking. For example,
Our goal is to develop an explainable multimodal out-of-
[16,17,41]useareferencedatasetthatcontainsunmanipu-
contextmisinformationdetectionmodelthatcanjointlyout-
lated related claims to mimic world knowledge, and then
put the prediction and explanation. Figure 2 illustrates the
detect the OOC use by comparing the given claim with
the retrieved one. [3] uses the text and image to retrieve
overallarchitectureoftheproposedSNIFFER. Specifically,
for a given image-text pair, we feed it into the multimodal
related Web evidence separately, and compute the claim-
largelanguagemodelforcheckingtheinternalcross-modal
evidenceconsistencyunderbothtextualandvisualmodali-
inconsistencies. The image-retrieved textual evidence will
ties. Similarly,[31]proposesanunsupervisedcross-modal
befedintotheembeddedLLMmodulewiththeinputtext
entityconsistencyverificationmethod, whichretrievesim-
tofindtheexternalclaim-evidenceinconsistencies. Similar
ages using entities extracted from the given text, and then
toensemblelearning,theLLMmodulewilloutputthefinal
calculates the similarity between the entities in the given
judgmentandexplanation,drawingontheresultsfromboth
imageandretrievedimages. Differentfromjudgingtheve-
internal and external checks. We first introduce the base
racity of the given image-caption claim, [5] re-formulates
MLLMandthetwo-stageinstructiontuningprocedures,be-
this task as: If two captions refer to the same objects in
foredescribingthereasoningprocesswhichincludesinter-
thesameimagebutaresemanticallydifferent,thenitindi-
nal/externalchecking,andcomposedreasoning.
catesanout-of-contextuseofthisimage. Theyintroducea
self-supervisedtrainingstrategytotrainthemodel’svisual
3.1.BaseMLLM
groundingabilityandevaluatethemodelonOOCsamples.
Althoughexistingworkshavemadesomeprogress,they We employ InstructBLIP [9], a general-purpose vision-
often fail to explain their judgment. This lack of trans- language model as the base MLLM for further tuning. In-
parency hinders the effectiveness of these methods in de- structBLIP consists of an image encoder, an LLM, and a
bunkingmisinformation. [52]proposesaninterpretablede- QueryTransformer(Q-Former). AsshowninFigure2,Q-
contextualizationdetector,whichusesMLLMtoverifythe Former extracts instruction-aware visual features based on
sub-questions decomposed from the given text and selects theoutputofthefrozenimageencoder,andfeedsthevisual
supported question-answer pairs as the explanation. How- featuresassoftpromptinputtothefrozenLLM.Thelearn-
ever, the effectiveness of this method is heavily limited by ablequeryvectorsinteractwiththeinstructiontextthrough
the ability of existing general-domain MLLM. In contrast, self-attentionlayers,andinteractwiththefrozenimageem-
weuseatwo-stageinstructiontuningtoadaptthegeneral- beddingsthroughcross-attentionlayers. SimilartoBLIP-2
domain MLLM for the OOC detection task, enabling it to [22],Q-Formerispre-trainedforvision-languagerepresen-
concurrentlygeneratebothjudgmentandexplanation. tation learning and vision-to-language generative learning
andthenistunedformulti-taskvision-languageinstruction
Instruction Tuning for MLLMs. Multimodal large lan-
learningin[9].
guagemodelstypicallyusealightweightvisualpromptgen-
erator that produces soft prompts for the input images to 3.2.InstructionTuning
connecttoanexistingLLM.Earlymodels[4,22,55]focus
Weuseatwo-stagetrainingproceduretoadaptthegeneral-
on large-scale pre-training, while recent works [9, 18, 27]
domain InstructBLIP to the news domain and OOC detec-
employinstructiontuningforpre-trainedMLLMs. Instruc-
tiontasksequentially(seeFigure3).
tion tuning is a crucial technique to enhance the capabili-
tiesandcontrollabilityoflargelanguagemodels,whichin- Stage 1: News Domain Alignment. We observe that In-
volvesfurthertrainingpre-trainedmodelsonacollectionof structBLIPtendstorespondwithcoarse-grainednouns(e.g.
instruction-formatteddatasetstoenhancemodels’general- “person”, “woman”, and “man”) rather than fine-grained,
izationtounseentasks. Onechallengeofinstructiontuning specific names such as “Donald Trump”. OOC samples
3InputText
Jeffrey E Thompson on Monday pleaded guilty in federal court to funding
a shadow campaign to help Vincent C Gray win the 2010 mayoral elecOon.
VisualEn++es
Harry Thomas Jr
Judge whether the given image
Tool InternalChecking
is wrongly used in thegiventext.
Newscap(on:…
Queries Instruc+on Possiblevisualen((es:… Instruc+on
… Answer:
Combinetheinternalandexternalchecking
resultstogivethefinalanswer.
❄ Internal:…
Image 🔥 ❄ External:…
Q-Former LLM FinalAnswer:
Encoder
FinalAnswer
InputImage
Evidence
• Harry Thomas sentenced to Instruc+on
ExternalChecking
three years. Judge whether the given newscap=on
• Harry Thomas leKer to judge: issupportedbytheretrievedevidences.
I am truly sorry for what I did. Newscap(on:…
Retrieval Evidence:…
InputText Answer:
InternalChecking ExternalChecking ComposedReasoning
Figure 2. Architecture of the proposed framework SNIFFER. For a given image-text pair, SNIFFER conducts a two-pronged analysis:
(1)itcheckstheconsistencyoftheimageandtextcontent(internalchecking),and(2)itexaminestherelevancebetweenthecontextof
theretrievedimageandtheprovidedtext(externalchecking). Theoutcomesofboththeseverificationprocessesarethenconsideredby
SNIFFERtoarriveatafinaljudgmentandexplanation.
the generated questions should explicitly specify a “brief”
Stage1
InstructBLIP NewsDomainAlignment Sniffer descriptionoftheimages. ForanimageIanditsassociated
3HoursonImageCap*oning captionT , werandomlysampleonequestionT toform
c q
1epochon370Ksamples
thecorrespondinginstructionas
Stage2
Task-SpecificTuning Human: IT ⟨STOP⟩; Model:T ⟨STOP⟩. (1)
13HoursonOOCDetec*on q c
10epochon71Ksamples
During training, we keep both the image encoder and
Figure 3. SNIFFER was initialized with the general-domain In- LLM frozen, and only update the Q-former. In this way,
structBLIPaExntdractthneenwsceolenmtienntusoaussanlyswterrasianneddtoadaptittotheInf ner
e
wthe scap1-img2inconsistencies
thengeneratecorrespondingques<ons based on the cap1t-hcaep2imdifafegreencfeesaturesofvastnews-domainvisualconceptscan
domainandOOCmisinformationdetectiontasksequentially.
bImeagea2l’signedtothetextualembeddingsoftheircorresponding
SelenC aa p Gt oio mn e: z in NER EVENT Ty , Fp Ae Cs , GPE, Answer: Image2 Cde afipsc $nr oip net 1io -n grainedentitynamesinthepre-trainedLLM.
aretypcihoclaa sltyllye atc three ateMdodeblyrePL EpO RSClO, aN NO , cPR RPiO, OnDR UGgC, T ,origGSe oil me nn ea az lentitieswithonIensstructBLIPCaption2
that arM eTV s a iw mard is lar but not idW eO nRK_ tO iF c_A aRT l, and these subtle dYeiss, tthien imcag-e is wronglyS ustead ign ae diff2ere:nt nTewas sk-Specific Tuning. In out-of-context mis-
context. The given news cap?on and image are
tionsappeartobediFfifine-ctuuneldtT5forInstructBLIPtocapturineco.nsistent in {type}. Thie n{tyfpoe}r inm capa?toino is n, an image is repurposed with a false text,
GiventhQuees2corn:oWshso -wdoroe cmholaa sitynle adt tihfef metvr aewnarcdse?sinthelexical{ {peen nr?? tt eyy_ _fc imeap gr} }, -. and the {Cywpe}h ini imcahge isi s different from the typical visual-language tasks
thatgeneral-purposeMLLMsfocuson.Thesetasks,suchas
ence, we construct the news-domain instruction dataset to
image captioning and visual question answering, typically
adaptthegeneral-domainInstructBLIPtothenewsdomain.
involvetextandimagesthatcorrespondtothesameevent.
ThisinstructiondatasetiscuratedfromtheNewsCLIPpings
dataset2[29]whichconsistsof36,8013uniquenewsimage- Toaddressthis,weconstructtheinstructiondatatoprogres-
sively adapt the news-domain MLLM (developed in Stage
caption pairs covering a diverse and representative set of
1)tothetaskofOOCmisinformationdetection. Similarto
news-domainconcepts. InspiredbyLLaVA[27],welever-
Stage1,weonlyupdatetheparametersinQ-former.
age ChatGPT-4 [33] to construct the instruction-following
One of the primary challenges in creating an explain-
data from these image-caption pairs. Specifically, to keep
ableOOCmisinformationdetectoristhelackofsupervised
the diversity of instruction data, we prompt ChatGPT-4 to
data that includes both judgments and explanations. The
generate 11 questions (see Supplementary) with the intent
NewsCLIPpings dataset generates fake pairs by replacing
toinstructthemodeltodescribetheimagecontent. Given
theimg inarealpair(cap ,img )withanotherimg from
thatthesecaptionshavelessthan30words,westipulatethat 1 1 1 2
asimilarbutdifferentpair(cap ,img ),resultinginafab-
2 2
2Weexcludethevalidationandtestingsettopreventdataleakage. ricatedpair(cap 1,img 2). Whilelabelsindicatingtheirau-
4
no(curtsnoCataDno(curtsnIhaspreviouslyappeared,servesasavitalsupplementtothe
Does 𝑐𝑎𝑝 match 𝑖𝑚𝑔 ?
! " content of the image itself. Reverse image searches can
𝑖𝑚𝑔 ’s often reveal the original event where the image was first
"
descrip)on reported, to help verify if the accompanying text matches
𝑖𝑚𝑔
"
𝑐𝑎𝑝 ! the true context of the image. Given the strong analytical
InstructBLIP 𝑐𝑎𝑝
" reasoning ability of LLM, we input both the news caption
No, the image is wrongly used in a different news context. The and the text from webpages retrieved via image search [1]
given news cap;on and image are inconsistent in element. The intotheLLMmoduleinSNIFFER. TheLLMisthentasked
element in cap;on is ent_t,and the element in image is ent_v. withdeterminingwhethertheprovidednewscaptionissup-
portedbytheretrievedevidence.
Figure4.ProcessofOOCinstructiongeneration.
ComposedReasoning. Theinternalandexternalverifica-
thenticity are provided for these pairs, the specific incon- tionstepsanalyzetheinputimage-textpairsfromdifferent
sistencies between cap 1 and img 2—the crux of the misin- perspectives and may yield different conclusions. There-
formation—arenotexplicitlyidentified. Assuch,weinno- fore, we employ the LLM once again for an interpretable
vativelyextracttheinconsistenciesbetweencap 1 andcap 2 modelensemble,taskingittodeliveritsfinaldecisionbased
by prompting language-only GPT-4 as an alternative. As onbothoutcomesandtheinitialcaption,andtoclearlyex-
showninFigure4,givencap 1,cap 2,andtheInstructBLIP- plainitsdecision-makingprocess.
generated img ’s basic description, we prompts GPT-4 to
2
generate the inconsistencies between cap 1 and img 2 as if 4.PerformanceStudy
it could see the image (even though it only has access to
the text). We curate few-shot examples in the prompt and In this section, we conducted experiments to evaluate the
alsorestricttheoutputformat,requiringittospotthenews effectiveness of SNIFFER. Specifically, we aim to answer
elements that are inconsistent between cap and img , as thefollowingevaluationquestions:
1 2
wellasthespecificentities. Thecompletepromptisshown Q1: Can SNIFFER improve the performance of out-of-
in Supplementary. Although there may be multiple incon- contextmisinformationdetection?
sistentelementsbetweencap
1
andimg 2, werequireGPT- Q2: HoweffectivearethedifferentmodulesofSNIFFERin
4 to generate only the most likely one for clarity. In to- detection?
tal, we obtain 35,536 GPT-assisted instructions for out-of- Q3: CanSNIFFERgenerateaccurateandconvincingexpla-
context samples and supplement the real samples with an nationsfortheirjudgment?
equalnumberofinstructions(i.e.,“No,theimageisrightly Q4: How does SNIFFER perform in early detection, when
usedinthegivennewscontext. ”) thenumberoftrainingsamplesislimited?
Q5: HowdoesSNIFFERperformonotherdatasets?
3.3.ReasoningProcess
Q6: HowdoesSNIFFERperformcomparedtoGPT-4V?
To effectively tackle the challenge of OOC misinforma-
tion detection, the reasoning process in SNIFFER employs 4.1.ExperimentalSetup
a comprehensive strategy that integrates both internal and
Dataset. Weusethelargestout-of-contextmisinformation
externalverificationmethods.
detectionbenchmarkNewsCLIPpings[29]. Thisdatasetis
Internal Checking. The two-stage instruction tuning pro- built based on VisualNews [25], a large-scale corpus that
cessequipsSNIFFERwiththeabilitytoidentifyimage-text containsimage-captionpairsfromfournewsagencies(The
inconsistency for internal checking. However, the model Guardian, BBC, USA Today, and The Washington Post).
doesnothaveaccesstocurrentinformationasitislimited Theout-of-contextsamplesareautomaticallygeneratedby
by the training corpus. Therefore, we employ Google En- replacing the images in the original image-caption pairs
tityDetectionAPI[1]torecognizevisualentitiesinimages with retrieved images that are semantically related but be-
which are incorporated into the instruction as supplemen- long to different news events. [3] extends the NewsCLIP-
tary information. This allows SNIFFER to maintain rele- pingsdatasetbysupplementingtheretrievedtextualandvi-
vancy and accuracy in its analysis. Additionally, there is sualevidence. Here,weusepartofthetextualevidenceand
potential to further enhance SNIFFER’s detection capabili- detectedvisualentitiesprovidedinthisdatatset.
tiesbyintegratingitwithotherplug-intools,expandingits Following previous works [3, 36, 52], we report the re-
functionalityindetectinginconsistencies. sults on the Merged/Balance subset, which has a balanced
External Checking. In addition to image-text internal proportionofdifferentretrievalstrategiesandpositive/neg-
checking, leveraging retrieved web evidence for external ativesamples. Thenumberofsamplesinthetraining,vali-
verificationisacrucialstep, ashighlightedin[3,56]. The dation,andtestingsetsare71072,7024,and7264,respec-
context of an image, particularly the news text in which it tively.Asin[29],weusetheaccuracyoverallsamples(All)
5andseparatelyfortheFake(Out-of-Context)andReal(Not Table1.Performance(%)comparisonbetweenSNIFFERandbase-
Out-of-Context)samplesasevaluationmetrics. lines.Thebestresultsareinboldface.
ImplementationDetails. WeselectInstructBLIP[9]asthe Method All Fake Real
baseMLLM,ofwhichtheimageencoderisViT-G/14[11]
SAFE 52.8 54.8 52.0
and the LLM is Vicuna-13B [8]. During training, we ini-
EANN 58.1 61.8 56.2
tializethemodelfromthepre-trainedInstructBLIPandonly VisualBERT 58.6 38.9 78.4
finetunetheparametersofQ-Formerwhilekeepingboththe CLIP 66.0 64.3 67.7
image encoder and the LLM frozen. To reduce the mem- DT-Transformer 77.1 78.6 75.6
ory cost, we use FlashAttention-2 [10] to replace the stan- CCN 84.7 84.8 84.5
dardAttentionlayerinLLM.Ourimplementationusesthe Neu-Symdetector 68.2 - -
LAVISlibrary[21]. Thebatchsizeissetas8and4inthe SNIFFER(Ours) 88.4 86.9 91.8
stages of news domain alignment and task-specific tuning,
respectively. Themaxinputsequencelengthis550andthe Table2.AblationstudiesoneachcomponentinSNIFFER.
output length is 256. We use the AdamW [28] optimizer
InstructBLIP PT OOCTuning VisEnt Evidence All Fake Real
and apply a linear warmup of the learning rate, increasing
✓ ✗ ✗ ✗ ✗ 47.4 4.6 90.3
from10−8to10−5,followedbyacosinedecay.Themodels
✓ ✓ ✗ ✗ ✗ 49.3 9.4 89.2
aretrainedutilizing4NvidiaA100(40G)GPUs. ✓ ✗ ✓ ✗ ✗ 82.5 75.3 89.7
Baselines. Wecompared SNIFFER withtworepresentative ✓ ✗ ✓ ✓ ✗ 87.6 83.9 91.3
✓ ✓ ✓ ✗ ✗ 83.1 76.5 89.6
multimodalmisinformationdetectorstrainedfromscratch: ✓ ✓ ✓ ✓ ✗ 88.2 84.9 94.0
1) SAFE [54] which translates the input image into a sen- ✓ ✗ ✗ ✗ ✓ 84.5 92.9 76.0
tence,andcomputesthemultimodalrelevancebasedonthe ✓ ✓ ✓ ✓ ✓ 88.4 86.9 91.8
sentence similarity as the auxiliary loss; 2) EANN [47]
whichusesadversarialtrainingtoguidethemodeltolearn ture the subtle inconsistency in the OOC samples. Even
event-invariantmultimodalfeaturesfordetection. thoughSNIFFERonlyconsiderspartofthetextualevidence,
WealsocomparedSNIFFERwithpre-trainedmultimodal it still surpasses CCN by over 3.7%. Baselines trained
baselines: 1) VisualBERT [23], one of the earliest works from scratch (i.e. EANN and SAFE) are worse than pre-
onmultimodalpre-training,concatenatestheboundingbox trained multimodal baselines, verifying the importance of
featuresandtextualtokens. Thecombinedfeaturesarefed world knowledge in the pre-trained models in distinguish-
intoaunifiedencoder,consistingofaseriesoftransformer ing the OOC samples. The inferior performance of the
layers, to align them into one embedding space. The pre- Neu-Symdetectorcomparedtootherapproaches(e.g.DT-
training of VisualBERT involves masked language mod- Transformer) suggests that general-purpose MLLM may
eling and image-text matching objectives; 2) CLIP [40] notbewell-suitedfortheOOCdetectiontask.
passes image and text through separate encoders and uses
4.3.AblationStudies(Q2)
contrastive loss to guide the multimodal encoders to gen-
erate similar representations for related concepts; 3) DT- We conducted ablation experiments to analyze the impor-
Transformer [36] uses CLIP as the multimodal encoder tance of each component of SNIFFER in detecting OOC
andaddsauxiliaryTransformerlayerstoenhancethemul- misinformation. Specifically, we first tested the original
timodalfeaturesinteraction. Itcombinesdifferenttypesof InstructBLIP, and then incrementally integrated various
generateddataasthetrainingcorpus;4)CCN[3]proposes components: pre-training (PT) with news-domain data in
aconsistency-checkingnetworkassistedbyCLIP,thatcon- Stage1,task-specifictuningbasedonOOCdatainStage2
siders the consistency of the claim-evidence (image-image (OOC tuning), visual entities (VisEnt), and retrieved ex-
andtext-text),inadditiontotheimage-textpairing. Thisis ternalevidence(Evidence). FromTable2,wecanseethat:
theonlybaselinethatutilizesretrievedexternalevidence;5) • The original InstructBLIP exhibits a classification accu-
Neu-Symdetector[52]proposesaneural-symbolicmodel racy of only 47.4%, which is even lower than random
which symbolically disassembles the text into a set of fact guessing. Furthermore, the recall for fake samples was
queries, and forwards the query-image pairs into a pre- a mere 4.6%. These results indicate that the general-
trainedMLLM.Theoutputanswersarefurtherselectedand purposeInstructBLIPtendstomisclassifyOOCmisinfor-
combinedtoobtainthefinaljudgment. mationasreal,likelyduetothesimilarityinthetextand
imagecompositionofsuchchallengingmisinformation.
4.2.PerformanceComparison(Q1)
• All components in SNIFFER are important for achieving
Table 1 shows the performance of SNIFFER and the vari- itsbestperformance,especiallytheOOCtuning. Specif-
ous baselines. We observe that SNIFFER outperforms all ically, it improves the performance of InstructBLIP by
the baselines, which validates that it can effectively cap- over 35 percentage points, suggesting that task-specific
60.80
1.00
0.70
0.98
0.60
0.96
0.50
0.94 element-hit
0.40
element ent_t-sim
0.92 ent_t 0.30 ent_v-sim
ent_v ROUGE
0.90 0.20
InstructBLIP +PT +OOC Tuning +VisEnt InstructBLIP +PT +OOC Tuning +VisEnt
Figure5.Responseratio. Figure6.Explanationaccuracy.
tuning can aid the model in learning the logic necessary afterincorporatingvisualentities,indicatingthattheseenti-
toaccuratelyjudgeOOCsamples. tieshaveenhancedthemodel’sabilitytorecognizeentities.
• The incorporation of visual entities contributed to a 5- 2)ExplanationAccuracy: Althoughthereisadecline
point increase in accuracy. This indicates that the in- in the response ratio of the model, the accuracy of its re-
tegration of external tools can significantly enhance the sponsesacrossallthreepointsshowsanincrease. Figure6
model’sabilitytoidentifyvisualelements. shows that all components contribute to the improvement
• Relying solely on assessing the relevance between text ofexplanationaccuracyintermsofthehitratioforelement,
andimage-retrievedtextualevidencecanyieldrelatively average similarity for ent t and ent v, and ROUGE value
good detection results. However, while this approach forthewholeresponse. Specifically,thehitratioofelement
achieves high recall for fake samples, that of real sam- increasesby4%and44%bypre-trainingandOOCtuning
ples is notably lower than other methods. This discrep- withvisualentities,respectively,demonstratingthemodel’s
ancy is largely attributable to the noise in the retrieved increasing ability to capture inconsistencies between text
evidence. Evenforrealnews,relevantevidencemaynot andimages. Theaccuracyofent tconsistentlyoutperforms
alwaysberetrievable,leadingtomisclassificationofreal ent vby17%.Thisdisparitycanbeattributedtotherelative
samples. Additionally, since only less than 60% of the simplicityofdirectlyextractingent tfromtext,asopposed
samples have associated evidence, the overall improve- toent v,whichisderivedfromimagesandthusheavilyde-
mentinthemodel’saccuracyissomewhatlimited. pendentonthemodel’svisualrecognitioncapabilities.
Overall,aftertraining,themodelhasbecomemorecon-
4.4.ExplainabilityAnalysis(Q3)
servative yet more accurate in spotting the key detection
points. This indicates that the model has truly captured
We evaluated the quality of the explanations generated by
clues of inconsistencies between text and images, rather
SNIFFERintermsofaccuracyandpersuasiveness.
thanmerelyfittingtorealorfakelabels.
QuantitativeAnalysis.WecomparedSNIFFER’sgenerated
explanation with the ground truth obtained in Section 3.2 Human Evaluation. To assess the effectiveness of SNIF-
onthetestset. Wefocusonthreecriticalinformationpoints FERindebunkingmisinformationthroughitsgeneratedex-
withinOOCsamples,i.e.inconsistentnewselement,theen- planations, we conducted a human evaluation. We ran-
tityofthatelementinthetext(ent t)andimage(ent v). We domly selected 20 OOC misinformation samples from the
designtwotypesofevaluationmetrics:1)Responseratioof test set. Ten participants were asked to judge the veracity
thesethreepoints;2)Accuracyofthesethreepoints.Weuse of each news item (i.e. fake or real) and their confidence
hard match and compute the hit ratio for element, and use level (i.e. no, somewhat, high) both before and after read-
similarity of the CLIP embedding for ent t and ent v. We ing SNIFFER’sexplanations. Figure7showsthat: (a)69%
alsouseROUGE[24]tomeasuretheaccuracyofthegen- oftheitemswerecorrectlyidentifiedasfakebytheusers3,
erated explanations from an overall perspective. We com- a finding that aligns with the statistics in [29], indicating
pared the performance of various variants of SNIFFER on a certain level of user discernment in detecting OOC mis-
these metrics to demonstrate the role of different compo- information; (b) for the OOC samples initially misidenti-
nentsinenhancingthemodel’sexplainability. fied as real by the users, 87% of their judgments changed
1) Response Ratio: Figure 5 shows the response ratio tofakeafterreadingSNIFFER’sjudgmentandexplanations,
ofelement,ent t,andent vfordifferenttrainingsteps. We demonstratingthestrongpersuasivepowerofSNIFFER;(c)
seethatthemodel’sresponseratioiscloseto1initiallybut fortheOOCsamplesthatwereinitiallyidentifiedasfakeby
significantlydecreasesforent tandent vafterOOCtuning.
3Whenengagedindataannotation,userstendedtolabelnewsitemsas
Thisindicatesthatthemodelhasbecomemoreconservative
fakemorefrequentlycomparedtotheirusualbehaviorwhenreadingnews
initsoutputs. Further,theresponseratioimprovesslightly onsocialmedia.
7News400 TamperedNews
100 100
31% 13% CIn oi$ nfial d: eF na ck ee - 899 505 C SnM ifC feS r 90 C SnM ifC feS r
87% 58% Confidence↑ 78 50 78 00
70
69%
Ini$al:Real 66 05
top-5% top-10% top-25% random
60 top-5% top-10% top-25% random
42% ->Fake (a) (b)
->Real
Figure9.Cross-datasetdetectionperformanceofSNIFFER.
Figure7.Resultsofhumanevaluation.Theouterringdisplaysthe textSimilarity(CMCS),acompetitivebaselineproposedin
initialdistributionoftestsamplesjudgedasrealandfake, while [32]. CMCS quantifies the similarity between the textual
theinnercircleillustratesthechangesinusers’judgmentsandcon- context and visual scene labels within the textual feature
fidencelevelsafterreadingSNIFFER’sexplanations. space. Figure9showsthatSNIFFERoutperformsCMCSby
alargemarginatdifferentdifficultylevelsinbothdatasets,
83
confirmingthecross-datasetgeneralizabilityofSNIFFER.
82
81 4.6.ComparisonwithGPT-4V(Q6)
80
AsthemostpopularMLLM,GPT-4withvision(GPT-4V)
79
[35] has demonstrated unparalleled performance across a
78
varietyofmultimodaltasks, whichinspiredustotestiton
77
the OOC detection task. We randomly sampled 400 sam-
76
ples from the test set (200 fake and 200 real examples)
75
10% 25% 50% 100% andqueriedGPT-4Vusingthesamepromptsasthoseused
Proportion of data used in the training set
for SNIFFER. Table 3 shows that SNIFFER outperforms
Figure8.Performanceinearlydetection.
GPT-4V by 11% in terms of classification accuracy. This
demonstrates that task-specific (relatively) smaller models
theusers,SNIFFER’sexplanationsalsoincreasedtheusers’
are fully capable of outperforming general-purpose larger
confidenceintheirjudgmentsfor42%ofthesesamples.
modelsinspecifictasks4. Tofurtherunderstandthebehav-
4.5.PracticalSetting ioral differences between SNIFFER and GPT-4V, we com-
paretheirgeneratedexplanationsinSupplementary.
Early Detection (Q4). Detecting misinformation in its
early stage is important for timely mitigating its negative Table3.Comparisonofclassificationaccuracy(%)betweenSNIF-
influences[14]. Weconductedexperimentsusingdifferent FERandGPT-4Vonrandomlysampledtestset.
proportions of the training set to evaluate the model’s per-
formance. Specifically, we randomly selected 10%, 25%, Method All Fake Real
50%and100%trainingsamplesandconductedexperiments GPT-4V 75.5 77.0 74.0
on SNIFFER-, areducedversionof SNIFFER thatonlyem- SNIFFER(Ours) 86.8 79.0 94.5
ploysOOCTuningonInstructBLIP,forafaircomparison.
Figure8showsthat,withmerely10%ofthetrainingdata, 5.Conclusion
SNIFFER- achieves comparable detection performance as
baselinemodelsthatdonotutilizeexternalevidence. When In this paper, we proposed SNIFFER, a multimodal large
trained with 25% of the data, it can surpass their perfor- language model for out-of-context misinformation detec-
mance, underscoringthesuperiorityofMLLMintermsof tion, providing both judgment and explanation. To de-
trainingefficiencyanddetectionaccuracy. velop SNIFFER, we constructed multi-perspective instruc-
tiondataassistedbyGPT-4,andemployedinstructiontun-
Generalization Analysis (Q5). To validate the generaliz-
ingtocontinuouslyadaptthegeneral-purposeInstructBLIP
ability of SNIFFER, we tested the model that was trained
for the news domain and OOC detection task. We further
on the NewsCLIPpings dataset, on the other two datasets,
augmented the model by integrating external tools and re-
i.e.News400andTamperedNewsdatasets[32]. img isre-
1
placed by images of similar appearance (img ) based on
trievalmethods. Experimentsprovethat SNIFFER notonly
2
achievesSOTAperformanceindetection,butalsogenerates
top-k similaritytoimg ,creatingdifferentsubsetsaccord-
1
preciseandpersuasiveexplanations.
ingtothevalueofk.Asmallerkindicateshighersimilarity
betweenimg 1 andimg 2,andhence,agreaterchallengein 4Currently,thereisnoliteratureexplicitlystatingthesizeofGPT-4V,
detection. Wecompared SNIFFER withCross-ModalCon- butitisanticipatedtoexceedthe175billionparameterscaleofGPT-3[6].
8
)%(
ycaruccA
)%(
ycaruccA
)%( ycaruccATable4.Behaviorsofexistingopen-sourcedgeneral-purposeMLLMsindetectingOOCmisinformation.
Somerumormongersuseimagesfromothereventsasillustrationsofthecurrentnewseventtomakeupmul-
timodal misinformation. Given a news caption and a news image, judge whether the given image is rightly
usedinthegivennewscontext. Let’sanalyzetheirinconsistencyfromperspectivesofmainnewselements,
includingtime,place,person,event,artwork,etc. Youshouldanswerinthefollowingforms: “Yes,theimage
User
isrightlyused.”or“No,theimageiswronglyusedinadifferentnewscontext. Thegivennewscaptionand
image are inconsistent in <element>. The <element>in the caption is <ent t>, and the <element>in the
imageis<ent v>.”Newscaption:SaturnVboosterwasusedinNasaspacemissionsbetween1967and1972.
Theansweris
InstructBLIP 1967-1972,whichisthetimeperiodwhentheSaturnVboosterwasusedinNasaspacemissions.
No,theimageiswronglyusedinadifferentnewscontext. TheimageisofaSaturnVrocket,whichwasused
inNASAspacemissionsbetween1967and1972. However,thegivennewscaptionreferstoadifferentevent,
LLaVA-
theApollo11mission,whichtookplacein1969.Theimageandcaptionareinconsistentintime,astheSaturn
Adapter-V2
VrocketwasnotusedintheApollo11mission.
No,theimageiswronglyusedinadifferentnewscontext. Thegivennewscaptionandimageareinconsistent
intime.ThecaptionstatesthattheSaturnVboosterwasusedinNasaspacemissionsbetween1967and1972,
Woodpecker
whiletheimagedepictsarocketlaunchinginthe1980s.TheimageisnotrelatedtotheSaturnVbooster,which
wasusedinthe1960sand1970s.
Table5.Thelistofinstructionsforbriefnewsimagedescription.
• “Analyzethenewsimageandprovideabriefsummaryoftheeventitdepicts.”
• “Giveashortdescriptionofthesceneshowninthenewsphotograph.”
• “Offeraconcisereportbasedonthenews-relatedimageprovided.”
• “Summarizethenewsstoryasrepresentedbytheimage.”
• “Interpretthejournalisticimageanddetailthekeyelementsinasuccinctmanner.”
• “Provideabriefjournalisticoverviewofthenewspicture.”
• “Constructashortnarrativetoconveythenewseventshownintheimage.”
• “Deliveracompactexpositionoftheincidentcapturedinthenewsphoto.”
• “Expressthemainnewspointsillustratedbythegivenphotograph.”
• “Condensethenewscontextoftheimageintoaclear,briefdescription.”
• “Whatnewseventdoesthisimagedescribe?”
A. Behaviors of open-sourced general-purpose garding the desired output format, these MLLMs exhibit
MLLMs a failure to follow instructions accurately. InstructBLIP,
in particular, does not provide a clear judgment, instead
merely paraphrasing the given caption, which indicates a
We evaluated three representative open-sourced general-
misunderstandingoftheuser’sintent.
purpose MLLMs, including InstructBLIP [9], LLaVA-
Adapter-V2 [13] and Woodpecker [50], for their perfor- Furthermore,bothLLaVA-Adapter-V2andWoodpecker
mance in detecting out-of-context misinformation. As display hallucination phenomena: LLaVA-Adapter-V2 er-
demonstrated in Table 4, despite explicit instructions re- roneouslyattributesthecontentofthecaptiontotheimage
9# system message
You are an expert in fact-checking. Some news captions and accompanying images are
inconsistent in terms of key news elements (5W1H) because rumormongers have taken images from
other news and used them as illustrations for current news to make up multimodal
misinformation. Given the original news caption (i.e. caption_ori) for the image (i.e.
image_ori), the new news caption (i.e. caption_new), and a basic description of image_ori’s
content, I need you to analyze the inconsistencies between caption_ori and caption_new in key
news elements, and select from them the one most likely inconsistency between image_ori and
caption_new based on the description of image_ori. You should answer in the following forms:
"They are inconsistent in <element>. The <element> in caption_new is <ent_t>, and the <
element> in image_ori is <ent_v>.\n Element: <element> \n Entity_caption: <ent_t> \n
Entity_image: <ent_v>\". Please answer only one inconsistent element.
# in-context examples
Caption_ori: John Constable’s Brightwell Church and Village was part of the 2013 exhibition
Caption_new: From J Charles Eichhorn’s American Skat or The Game of Skat Defined
Basic description of image_ori: This image describes a rural landscape with a farmhouse, a
barn, and a field. The farmhouse is situated in the middle of the field, surrounded by the
barn and the open land. The painting captures the essence of a peaceful, pastoral setting,
with the farmhouse serving as the central focus of the scene.
The answer is: They are inconsistent in artwork. The artwork in caption_new is American Skat
or The Game of Skat Defined, and the artwork in image_ori is Brightwell Church and Village. \
n Element: artwork \n Entity_caption: American Skat or The Game of Skat Defined \n
Entity_image: Brightwell Church and Village
Caption_ori: Chris Huhne is among the ministers expected to address delegates at next week’s
Lib Dem conference
Caption_new: Urs Rohner CEO of Credit Suisse participates in a panel session in Bern
Switzerland on Tuesday
Basic description of image_ori: The image depicts a man wearing a suit and tie, standing at a
podium with a microphone in front of him. He appears to be giving a speech or addressing an
audience. In the background, there is a black screen or backdrop.
The answer is: They are inconsistent in person. The person in caption_new is Urs Rohner, and
the person in image_ori is Chris Huhne. \n Element: person \n Entity_caption: Urs Rohner \n
Entity_image: Chris Huhne
# query
Caption_ori: <CAPTION ORI>
Caption_new: <CAPTION NEW>
Basic description of image_ori: <BASIC DESCRIPTION OF IMAGE ORI>
The answer is:
Figure10.PromptusedtoaskGPT-4togeneratetheOOCinstructiondata.
andassigns anew, erroneousmeaning (i.e.“the Apollo11 B.InstructionDataConstruction
mission,whichtookplacein1969”)tothecaption;Wood-
Instructionsforbriefimagedescription. Table5shows
peckerattributesanincorrectnewcontexttotheimage(i.e.
the ChatGPT-generated questions to construct the diverse
“arocketlaunchinginthe1980s”).Thishallucinationeffect
instruction data for news domain alignment. They present
maybeattributedtothetrainingdata,wheretextandimage
thesamemeaningwithnaturallanguagevariance.
aregenerallyalignedtodepictthesameevent.
PrompttogeneratetheOOCinstruction. Figure10il-
We also analyzed InstructBLIP’s lexical preferences
lustratesthepromptutilizedforaskingGPT-4toidentifyin-
basedonthedescriptionsitgeneratedforimageswithinthe
consistenciesbetweencap andcap . Fromtheresponses,
1 2
NewsCLIPpings dataset. Our statistics reveal that in sam-
weextractelement,ent t,andent vtoformulatetheOOC
ples containing person nouns, only 27% of the responses
instructiondata,asdepictedinFigure4inthemainpaper.
utilizefine-grainedpropernouns(i.e.specificnamesofin-
dividuals),whiletheremaining73%employcoarse-grained
C.CaseStudies
common nouns (such as “person”, “woman” and “man”).
ThissuggeststhatInstructBLIPtendstofavormoregeneral WeshowthreerepresentativecasesinTable6torevealthe
nounsoverspecificpropernounsinitsresponses. behavioraldifferencesbetweenGPT-4VandSNIFFER.
10Table6.ComparisonbetweenGPT-4VandSNIFFER.Foreachcase,weannotatethegroundtruth(GT)andthecorrectnessofthemodel’s
judgment,indicatedbyeither✓(correct)or✗(wrong).
Caption:NickClegg(left)inOldhamwithLiberalDemocratcandidateElwynWatkins(centre)
andLibDemdeputyleaderSimonHughes.[GT:FAKE]
GPT-4V:Yes,theimageisrightlyused.✗ SNIFFER: No, the image is wrongly used in
a different news context. On the one hand,
the person in the caption, Nick Clegg, Simon
Hughes and Elwyn Watkins, do not match the
personintheimage,TimHenman.Ontheother
hand, thecaptionreferstoNickClegg, Simon
Hughes,andElwynWatkinsattendinganevent,
while the image-retrieved webpages are about
thefuneralofatennisplayernamedElenaBal-
tacha. Thetwoentitiesarenotconnected,and
there are no common elements or context that
linkthem. Therefore,theimageismorelikely
tobewronglyusedinthecaption.✓
Caption:Peoplecheerandtakepicturesasthepopearrivestomeetwithrepresentativesofthe
WorldofWorkorganizationinCiudadJuarez.[GT:FAKE]
GPT-4V: No, the image is wrongly used in a SNIFFER:Yes,theimageisrightlyused.✗
differentnewscontext. Thegivennewscaption
andimageareinconsistentinperson. Theper-
son in the caption is the pope, and the person
in the image is a man who does not appear to
bethepope. Themanseenintheimageisnot
dressedinpapalattire,whichisdistinctiveand
wouldtypicallyincludewhiterobesandsome-
timesazucchetto(skullcap)forthepope.Addi-
tionally,thecontextofthepicturedoesnotseem
tomatchthetypicalscenarioswherethepopeis
present,whichoftenfeatureheightenedsecurity
andmoreceremonialsettings,dependingonthe
occasion.✓
Caption:PassengersarestrandedoutsidetheGuangzhourailwaystationinChina’sGuangdong
provinceonTuesday.[GT:REAL]
GPT-4V: No, the image is wrongly used in a SNIFFER: Yes, the image is rightly used. On
differentnewscontext.Theeventinthecaption theonehand,theimagedepictsagroupofpeo-
is passengers stranded outside the Guangzhou ple,whichisconsistentwiththecaption.Onthe
railwaystation,andtheeventintheimageisa otherhand,theimage-retrievedwebpagesmen-
largegatheringofpeopleataneventthatisnot tion the Guangzhou railway station in China,
relatedtoatransportationdisruption. Thiscan the Chinese New Year and a situation where
beinferredfromthefactthatthepeopleappear passengers were stranded outside the railway
to be standing very close to one another in an station due to snow, which are relevant to the
organizedmanner,ratherthanhavingthedisor- caption.Therefore,theimageislikelytobecor-
ganized,possiblyfrustratedbehavioronemight rectlyusedinthecaption.✓
expectfromstrandedpassengers. Additionally,
therearenoclearsignsofarailwaystation,such
asplatforms,tracks,ortrains,visibleintheim-
age.Thesettingdoesnotmatchthecontextde-
scribedinthenewscaption.✗
Inthefirstexample,SNIFFERidentifiestheclaimasfake evidenceirrelevance.Incontrast,GPT-4Vfailstodetectany
based on both the image-text inconsistency and the claim- inconsistencies. This highlights SNIFFER’s superiority in
11recognizingnewsentitiesandutilizingexternalknowledge. Eliza Rutherford, Serkan Cabi, Tengda Han, Zhitao Gong,
In the second example, the image depicts a scene that Sina Samangooei, Marianne Monteiro, Jacob L. Menick,
aligns with the caption’s description of “people cheer and Sebastian Borgeaud, Andy Brock, Aida Nematzadeh, Sa-
takepictures”andnorelevantwebpageswereretrievedfor hand Sharifzadeh, Mikolaj Binkowski, Ricardo Barreira,
Oriol Vinyals, Andrew Zisserman, and Kare´n Simonyan.
this image, leading SNIFFER to incorrectly classify this
Flamingo: a visual language model for few-shot learning.
claim as real. However, GPT-4V, drawing on the Pope’s
InNeurIPS,2022. 3
attireandthesecurityconditionsattheevent,deducesthat
[5] ShivangiAneja,ChrisBregler,andMatthiasNießner. COS-
the image does not depict a scene of the Pope participat-
MOS: catching out-of-context image misuse using self-
ing in an event, and thus correctly classifies the claim as
supervisedlearning. InThirty-SeventhAAAIConferenceon
fake. ThisexampledemonstratesGPT-4V’ssuperiorworld
Artificial Intelligence, AAAI 2023, Thirty-Fifth Conference
knowledgeandreasoningcapabilities, farsurpassingthose on Innovative Applications of Artificial Intelligence, IAAI
ofsmallermodels. 2023, Thirteenth Symposium on Educational Advances in
Thethirdexamplepresentsarealnewsstoryaboutpas- Artificial Intelligence, EAAI 2023, Washington, DC, USA,
sengers stranded outside the Guangzhou railway station, February 7-14, 2023, pages 14084–14092. AAAI Press,
accompanied by an image of people queuing. SNIFFER, 2023. 3
evaluating both the image-text consistency and the claim- [6] TomB.Brown,BenjaminMann,NickRyder,MelanieSub-
biah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakan-
evidencerelevance,correctlyidentifiesthisnewsasreal. In
tan, Pranav Shyam, Girish Sastry, Amanda Askell, Sand-
contrast, GPT-4V erroneously classifies this news as fake,
hini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom
reasoning that the orderly crowd in the image does not re-
Henighan,RewonChild,AdityaRamesh,DanielM.Ziegler,
sembletheexpectedchaosofstrandedpassengersandnot-
JeffreyWu,ClemensWinter,ChristopherHesse,MarkChen,
ing the absence of any railway station signage. This in-
Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
stance illustrates GPT-4V’s overly cautious and sensitive JackClark,ChristopherBerner,SamMcCandlish,AlecRad-
judgment, predicated on the expectation that key elements ford, IlyaSutskever, andDarioAmodei. Languagemodels
ofarealnewsstoryshouldbevisiblyrepresentedintheac- are few-shot learners. In Advances in Neural Information
companyingimage.Infact,existingresearch[45]hasfound ProcessingSystems33:AnnualConferenceonNeuralInfor-
thatmorethanhalfofsocialmedianewsstoriesdonothave mationProcessingSystems2020,NeurIPS2020,December
their content words represented in the images. This ten- 6-12,2020,virtual,2020. 8
dencyalsoaccountsforGPT-4V’slowerrecallrateforreal [7] Lu Cheng, Kush R. Varshney, and Huan Liu. Socially re-
sponsible AI algorithms: Issues, purposes, and challenges.
newssamples,asoutlinedinTable3inthemainpaper.
J.Artif.Intell.Res.,71:1137–1181,2021. 2
In summary, SNIFFER integrates clues from both text-
[8] Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhang-
imageinconsistencyandclaim-evidencerelevance,leading
haoWu,HaoZhang,LianminZheng,SiyuanZhuang,Yong-
to more comprehensive judgments. Benefiting from task-
hao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P.
specific tuning, it demonstrates a deeper understanding of
Xing. Vicuna: An open-source chatbot impressing gpt-4
the complex logic inherent in the OOC detection task. On with90%*chatgptquality,2023. 6
the other hand, GPT-4V, with its vast repository of world [9] WenliangDai,JunnanLi,DongxuLi,AnthonyMengHuat
knowledge, is adept at detecting subtle anomalies, yet this Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale
sameattributecanleadtothemisclassificationofrealnews Fung,andStevenC.H.Hoi.InstructBLIP:Towardsgeneral-
asfake. purpose vision-language models with instruction tuning.
CoRR,abs/2305.06500,2023. 2,3,6,9
References [10] TriDao. Flashattention-2:Fasterattentionwithbetterparal-
lelismandworkpartitioning. CoRR,abs/2307.08691,2023.
[1] Google Vision API. https://cloud.google.com/ 6
vision/docs/detecting-web. 5 [11] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,
[2] Reading about the Israel-Hamas war on X? Beware fake Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,
news. https://wired.me/technology/x- MostafaDehghani,MatthiasMinderer,GeorgHeigold,Syl-
misinformation/,2023. 2 vain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image
[3] Sahar Abdelnabi, Rakibul Hasan, and Mario Fritz. Open- isworth16x16words: Transformersforimagerecognition
domain,content-based,multi-modalfact-checkingofout-of- atscale. In9thInternationalConferenceonLearningRep-
contextimagesviaonlineresources. InIEEE/CVFConfer- resentations, ICLR 2021, Virtual Event, Austria, May 3-7,
ence on Computer Vision and Pattern Recognition, CVPR 2021.OpenReview.net,2021. 6
2022, New Orleans, LA, USA, June 18-24, 2022, pages [12] Lisa Fazio. Out-of-context photos are a power-
14920–14929.IEEE,2022. 2,3,5,6 ful low-tech form of misinformation. https:
[4] Jean-BaptisteAlayrac, JeffDonahue, PaulineLuc, Antoine //theconversation.com/out-of-context-
Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Men- photos-are-a-powerful-low-tech-form-of-
sch, Katherine Millican, Malcolm Reynolds, Roman Ring, misinformation-129959,2020. 2
12[13] Peng Gao, Jiaming Han, Renrui Zhang, Ziyi Lin, Shijie [25] Fuxiao Liu, Yinghan Wang, Tianlu Wang, and Vicente Or-
Geng, Aojun Zhou, Wei Zhang, Pan Lu, Conghui He, Xi- donez. Visual news: Benchmark and challenges in news
angyuYue, HongshengLi, andYuQiao. LLaMA-Adapter image captioning. In Proceedings of the 2021 Confer-
V2: parameter-efficient visual instruction model. CoRR, ence on Empirical Methods in Natural Language Process-
abs/2304.15010,2023. 9 ing,EMNLP2021,VirtualEvent/PuntaCana,Dominican
[14] Bin Guo, Yasan Ding, Lina Yao, Yunji Liang, and Zhiwen Republic,7-11November,2021,pages6761–6771.Associa-
Yu. Thefutureoffalseinformationdetectiononsocialme- tionforComputationalLinguistics,2021. 5
dia: Newperspectivesandtrends. ACMComput.Surv., 53 [26] Haoyang Liu, Maheep Chaudhary, and Haohan Wang.
(4):68:1–68:36,2021. 8 Towards trustworthy and aligned machine learning: A
[15] QuzheHuang,MingxuTao,ZhenweiAn,ChenZhang,Cong data-centric survey with causality perspectives. CoRR,
Jiang, ZhibinChen, ZiruiWu, andYansongFeng. Lawyer abs/2307.16851,2023. 2
LLaMAtechnicalreport. ArXiv,abs/2305.15062,2023. 3 [27] HaotianLiu,ChunyuanLi,QingyangWu,andYongJaeLee.
[16] Ayush Jaiswal, Ekraam Sabir, Wael Abd-Almageed, and Visualinstructiontuning. InNeurIPS,2023. 3,4
Premkumar Natarajan. Multimedia semantic integrity as- [28] IlyaLoshchilovandFrankHutter. Fixingweightdecayreg-
sessmentusingjointembeddingofimagesandtext. InPro- ularizationinadam. CoRR,abs/1711.05101,2017. 6
ceedingsofthe25thACMInternationalConferenceonMul- [29] GraceLuo,TrevorDarrell,andAnnaRohrbach.NewsCLIP-
timedia, MM 2017, Mountain View, CA, USA, October 23- pings: Automatic generation of out-of-context multimodal
27,2017,pages1465–1471.ACM,2017. 2,3 media. In Proceedings of the 2021 Conference on Em-
[17] AyushJaiswal,YueWu,WaelAbdAlmageed,IacopoMasi, pirical Methods in Natural Language Processing, EMNLP
and Premkumar Natarajan. AIRD: adversarial learning 2021,VirtualEvent/PuntaCana,DominicanRepublic,7-11
frameworkforimagerepurposingdetection. InIEEECon- November,2021,pages6801–6817.AssociationforCompu-
ferenceonComputerVisionandPatternRecognition,CVPR tationalLinguistics,2021. 2,3,4,5,7
2019, Long Beach, CA, USA, June 16-20, 2019, pages [30] JingMa,WeiGao,andKam-FaiWong.Detectrumorsinmi-
11330–11339. Computer Vision Foundation / IEEE, 2019. croblogpostsusingpropagationstructureviakernellearning.
2,3 InProceedingsofthe55thAnnualMeetingoftheAssocia-
[18] Bo Li, Yuanhan Zhang, Liangyu Chen, Jinghao Wang, tion for Computational Linguistics, ACL 2017, Vancouver,
Jingkang Yang, and Ziwei Liu. Otter: A multi-modal Canada,July30-August4,Volume1: LongPapers,pages
model with in-context instruction tuning. arXiv preprint 708–717.AssociationforComputationalLinguistics,2017.
arXiv:2305.03726,2023. 3 3
[19] Chunyuan Li, Zhe Gan, Zhengyuan Yang, Jianwei Yang, [31] EricMu¨ller-Budack,JonasTheiner,SebastianDiering,Max-
LinjieLi,LijuanWang,andJianfengGao.Multimodalfoun- imilianIdahl, andRalphEwerth. Multimodalanalyticsfor
dation models: From specialists to general-purpose assis- real-worldnewsusingmeasuresofcross-modalentitycon-
tants. CoRR,abs/2309.10020,2023. 2 sistency. InProceedingsofthe2020onInternationalCon-
[20] Chunyuan Li, Cliff Wong, Sheng Zhang, Naoto Usuyama, ference on Multimedia Retrieval, ICMR 2020, Dublin, Ire-
HaotianLiu,JianweiYang,TristanNaumann,HoifungPoon, land,June8-11,2020,pages16–25.ACM,2020. 2,3
andJianfengGao. LLaVA-Med: Trainingalargelanguage- [32] EricMu¨ller-Budack,JonasTheiner,SebastianDiering,Max-
and-vision assistant for biomedicine in one day. CoRR, imilianIdahl,SherzodHakimov,andRalphEwerth. Multi-
abs/2306.00890,2023. 3 modalnewsanalyticsusingmeasuresofcross-modalentity
[21] Dongxu Li, Junnan Li, Hung Le, Guangsen Wang, Silvio andcontextconsistency.Int.J.Multim.Inf.Retr.,10(2):111–
Savarese, and Steven C. H. Hoi. LAVIS: A one-stop li- 125,2021. 8
braryforlanguage-visionintelligence.InProceedingsofthe [33] OpenAI. ChatGPT. https://openai.com/blog/
61st Annual Meeting of the Association for Computational chatgpt/. 4
Linguistics: System Demonstrations, ACL 2023, Toronto, [34] OpenAI. GPT-4technicalreport,2023. 2
Canada, July 10-12, 2023, pages 31–41. Association for [35] OpenAI. GPT-4v(ision) system card. https://cdn.
ComputationalLinguistics,2023. 6 openai.com/papers/GPTV_System_Card.pdf,
[22] Junnan Li, Dongxu Li, Silvio Savarese, and Steven C. H. 2023. 8
Hoi. BLIP-2: bootstrapping language-image pre-training [36] Stefanos-Iordanis Papadopoulos, Christos Koutlis, Symeon
withfrozenimageencodersandlargelanguagemodels. In Papadopoulos, and Panagiotis Petrantonakis. Synthetic
InternationalConferenceonMachineLearning,ICML2023, misinformers: Generating and combating multimodal mis-
23-29 July 2023, Honolulu, Hawaii, USA, pages 19730– information. In Proceedings of the 2nd ACM Interna-
19742.PMLR,2023. 3 tionalWorkshoponMultimediaAIagainstDisinformation,
[23] Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, MAD@ICMR2023,Thessaloniki,Greece,June12-15,2023,
andKai-WeiChang. VisualBERT:Asimpleandperformant pages36–44.ACM,2023. 2,3,5,6
baseline for vision and language. CoRR, abs/1908.03557, [37] Piotr Przybyla. Capturing the style of fake news. In The
2019. 3,6 Thirty-Fourth AAAI Conference on Artificial Intelligence,
[24] C Lin. Recall-oriented understudy for gisting evaluation AAAI 2020, The Thirty-Second Innovative Applications of
(rouge). RetrievedAugust,20:2005,2005. 7 Artificial Intelligence Conference, IAAI 2020, The Tenth
13AAAISymposiumonEducationalAdvancesinArtificialIn- versarialneuralnetworksformulti-modalfakenewsdetec-
telligence,EAAI2020,NewYork,NY,USA,February7-12, tion. In Proceedings of the 24th ACM SIGKDD Interna-
2020,pages490–497.AAAIPress,2020. 2 tionalConferenceonKnowledgeDiscovery&DataMining,
[38] PengQi,JuanCao,TianyunYang,JunboGuo,andJintaoLi. KDD 2018, London, UK, August 19-23, 2018, pages 849–
Exploiting multi-domain visual information for fake news 857.ACM,2018. 6
detection. In2019IEEEInternationalConferenceonData [48] YizhongWang,YeganehKordi,SwaroopMishra,AlisaLiu,
Mining,ICDM2019,Beijing,China,November8-11,2019, NoahA.Smith,DanielKhashabi,andHannanehHajishirzi.
pages518–527.IEEE,2019. 2 Self-Instruct:Aligninglanguagemodelswithself-generated
[39] Peng Qi, Juan Cao, Xirong Li, Huan Liu, Qiang Sheng, instructions. In Proceedings of the 61st Annual Meeting
Xiaoyue Mi, Qin He, Yongbiao Lv, Chenyang Guo, and of the Association for Computational Linguistics (Volume
Yingchao Yu. Improving fake news detection by using an 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14,
entity-enhancedframeworktofusediversemultimodalclues. 2023, pages 13484–13508. Association for Computational
InProceedingsofthe29thACMInternationalConferenceon Linguistics,2023. 3
Multimedia,MM’21,VirtualEvent,China,October20-24, [49] Shukang Yin, Chaoyou Fu, Sirui Zhao, Ke Li, Xing Sun,
2021,pages1212–1220.ACM,2021. 3 TongXu,andEnhongChen. Asurveyonmultimodallarge
[40] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya languagemodels. CoRR,abs/2306.13549,2023. 2
Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, [50] ShukangYin,ChaoyouFu,SiruiZhao,TongXu,HaoWang,
Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Dianbo Sui, Yunhang Shen, Ke Li, Xing Sun, and Enhong
Krueger, and Ilya Sutskever. Learning transferable visual Chen.Woodpecker:Hallucinationcorrectionformultimodal
modelsfromnaturallanguagesupervision. InProceedings largelanguagemodels. CoRR,abs/2310.16045,2023. 9
ofthe38thInternationalConferenceonMachineLearning, [51] Jingsi Yu, Junhui Zhu, Yujie Wang, Yang Liu, Hongxiang
ICML 2021, 18-24 July 2021, Virtual Event, pages 8748– Chang, Jinran Nie, Cunliang Kong, Ruining Cong, Xin-
8763.PMLR,2021. 3,6 Liu, Jiyuan An, Luming Lu, Mingwei Fang, and Lin Zhu.
[41] Ekraam Sabir, Wael AbdAlmageed, Yue Wu, and Prem TaoliLLaMA. https://github.com/blcuicall/
Natarajan. Deep multimodal image-repurposing detection. taoli,2023. 3
In Proceedings of the 26th ACM International Conference [52] Yizhou Zhang, Loc Trinh, Defu Cao, Zijun Cui, and
onMultimedia,MM2018,Seoul,RepublicofKorea,Octo- Yan Liu. Detecting out-of-context multimodal misinfor-
ber22-26,2018,pages1337–1345.ACM,2018. 2,3 mation with interpretable neural-symbolic model. CoRR,
[42] Rui Shao, Tianxing Wu, and Ziwei Liu. Detecting and abs/2304.07633,2023. 3,5,6
groundingmulti-modalmediamanipulation. InIEEE/CVF [53] HanqingZhao,WenboZhou,DongdongChen,TianyiWei,
Conference on Computer Vision and Pattern Recognition, WeimingZhang, andNenghaiYu. Multi-attentionalDeep-
CVPR 2023, Vancouver, BC, Canada, June 17-24, 2023, fake detection. In IEEE Conference on Computer Vision
pages6904–6913.IEEE,2023. 1,2 and Pattern Recognition, CVPR 2021, virtual, June 19-
25,2021,pages2185–2194.ComputerVisionFoundation/
[43] Kai Shu, Limeng Cui, Suhang Wang, Dongwon Lee, and
IEEE,2021. 1
Huan Liu. dEFEND: Explainable fake news detection. In
Proceedings of the 25th ACM SIGKDD International Con- [54] XinyiZhou,JindiWu,andRezaZafarani.SAFE:similarity-
ference on Knowledge Discovery & Data Mining, KDD aware multi-modal fake news detection. In Advances in
2019, Anchorage, AK, USA, August 4-8, 2019, pages 395– KnowledgeDiscoveryandDataMining-24thPacific-Asia
405.ACM,2019. 3 Conference, PAKDD 2020, Singapore, May 11-14, 2020,
Proceedings,PartII,pages354–367.Springer,2020. 3,6
[44] Ruben Tolosana, Rube´n Vera-Rodr´ıguez, Julian Fie´rrez,
AythamiMorales,andJavierOrtega-Garcia. Deepfakesand [55] Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mo-
beyond: Asurveyoffacemanipulationandfakedetection. hamedElhoseiny. MiniGPT-4: Enhancingvision-language
Inf.Fusion,64:131–148,2020. 1 understandingwithadvancedlargelanguagemodels. arXiv
preprintarXiv:2304.10592,2023. 3
[45] AlakanandaVempalaandDanielPreotiuc-Pietro.Categoriz-
[56] DimitrinaZlatkova,PreslavNakov,andIvanKoychev. Fact-
ingandinferringtherelationshipbetweenthetextandimage
checking meets fauxtography: Verifying claims about im-
ofTwitterposts. InProceedingsofthe57thConferenceof
ages. InProceedingsofthe2019ConferenceonEmpirical
the Association for Computational Linguistics, ACL 2019,
MethodsinNaturalLanguageProcessingandthe9thInter-
Florence,Italy,July28-August2,2019,Volume1:LongPa-
nationalJointConferenceonNaturalLanguageProcessing,
pers,pages2830–2840.AssociationforComputationalLin-
EMNLP-IJCNLP2019, HongKong, China, November3-7,
guistics,2019. 12
2019,pages2099–2108.AssociationforComputationalLin-
[46] Xueyu Wang, Jiajun Huang, Siqi Ma, Surya Nepal, and
guistics,2019. 5
ChangXu. DeepFakedisrupter: ThedetectorofDeepFake
is my friend. In IEEE/CVF Conference on Computer Vi-
sionandPatternRecognition,CVPR2022,NewOrleans,LA,
USA,June18-24,2022,pages14900–14909.IEEE,2022. 1
[47] YaqingWang,FenglongMa,ZhiweiJin,YeYuan,Guangxu
Xun, KishlayJha, LuSu, andJingGao. EANN:eventad-
14