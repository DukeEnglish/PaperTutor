[
    {
        "title": "FAR: Flexible, Accurate and Robust 6DoF Relative Camera Pose Estimation",
        "authors": "Chris RockwellNilesh KulkarniLinyi JinJeong Joon ParkJustin JohnsonDavid F. Fouhey",
        "links": "http://arxiv.org/abs/2403.03221v1",
        "entry_id": "http://arxiv.org/abs/2403.03221v1",
        "pdf_url": "http://arxiv.org/pdf/2403.03221v1",
        "summary": "Estimating relative camera poses between images has been a central problem in\ncomputer vision. Methods that find correspondences and solve for the\nfundamental matrix offer high precision in most cases. Conversely, methods\npredicting pose directly using neural networks are more robust to limited\noverlap and can infer absolute translation scale, but at the expense of reduced\nprecision. We show how to combine the best of both methods; our approach yields\nresults that are both precise and robust, while also accurately inferring\ntranslation scales. At the heart of our model lies a Transformer that (1)\nlearns to balance between solved and learned pose estimations, and (2) provides\na prior to guide a solver. A comprehensive analysis supports our design choices\nand demonstrates that our method adapts flexibly to various feature extractors\nand correspondence estimators, showing state-of-the-art performance in 6DoF\npose estimation on Matterport3D, InteriorNet, StreetLearn, and Map-free\nRelocalization.",
        "updated": "2024-03-05 18:59:51 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.03221v1"
    },
    {
        "title": "Self-supervised 3D Patient Modeling with Multi-modal Attentive Fusion",
        "authors": "Meng ZhengBenjamin PlancheXuan GongFan YangTerrence ChenZiyan Wu",
        "links": "http://arxiv.org/abs/2403.03217v1",
        "entry_id": "http://arxiv.org/abs/2403.03217v1",
        "pdf_url": "http://arxiv.org/pdf/2403.03217v1",
        "summary": "3D patient body modeling is critical to the success of automated patient\npositioning for smart medical scanning and operating rooms. Existing CNN-based\nend-to-end patient modeling solutions typically require a) customized network\ndesigns demanding large amount of relevant training data, covering extensive\nrealistic clinical scenarios (e.g., patient covered by sheets), which leads to\nsuboptimal generalizability in practical deployment, b) expensive 3D human\nmodel annotations, i.e., requiring huge amount of manual effort, resulting in\nsystems that scale poorly. To address these issues, we propose a generic\nmodularized 3D patient modeling method consists of (a) a multi-modal keypoint\ndetection module with attentive fusion for 2D patient joint localization, to\nlearn complementary cross-modality patient body information, leading to\nimproved keypoint localization robustness and generalizability in a wide\nvariety of imaging (e.g., CT, MRI etc.) and clinical scenarios (e.g., heavy\nocclusions); and (b) a self-supervised 3D mesh regression module which does not\nrequire expensive 3D mesh parameter annotations to train, bringing immediate\ncost benefits for clinical deployment. We demonstrate the efficacy of the\nproposed method by extensive patient positioning experiments on both public and\nclinical data. Our evaluation results achieve superior patient positioning\nperformance across various imaging modalities in real clinical scenarios.",
        "updated": "2024-03-05 18:58:55 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.03217v1"
    },
    {
        "title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis",
        "authors": "Patrick EsserSumith KulalAndreas BlattmannRahim EntezariJonas MüllerHarry SainiYam LeviDominik LorenzAxel SauerFrederic BoeselDustin PodellTim DockhornZion EnglishKyle LaceyAlex GoodwinYannik MarekRobin Rombach",
        "links": "http://arxiv.org/abs/2403.03206v1",
        "entry_id": "http://arxiv.org/abs/2403.03206v1",
        "pdf_url": "http://arxiv.org/pdf/2403.03206v1",
        "summary": "Diffusion models create data from noise by inverting the forward paths of\ndata towards noise and have emerged as a powerful generative modeling technique\nfor high-dimensional, perceptual data such as images and videos. Rectified flow\nis a recent generative model formulation that connects data and noise in a\nstraight line. Despite its better theoretical properties and conceptual\nsimplicity, it is not yet decisively established as standard practice. In this\nwork, we improve existing noise sampling techniques for training rectified flow\nmodels by biasing them towards perceptually relevant scales. Through a\nlarge-scale study, we demonstrate the superior performance of this approach\ncompared to established diffusion formulations for high-resolution\ntext-to-image synthesis. Additionally, we present a novel transformer-based\narchitecture for text-to-image generation that uses separate weights for the\ntwo modalities and enables a bidirectional flow of information between image\nand text tokens, improving text comprehension, typography, and human preference\nratings. We demonstrate that this architecture follows predictable scaling\ntrends and correlates lower validation loss to improved text-to-image synthesis\nas measured by various metrics and human evaluations. Our largest models\noutperform state-of-the-art models, and we will make our experimental data,\ncode, and model weights publicly available.",
        "updated": "2024-03-05 18:45:39 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.03206v1"
    },
    {
        "title": "Triple-CFN: Restructuring Conceptual Spaces for Enhancing Abstract Reasoning process",
        "authors": "Ruizhuo SongBeiming Yuan",
        "links": "http://arxiv.org/abs/2403.03190v2",
        "entry_id": "http://arxiv.org/abs/2403.03190v2",
        "pdf_url": "http://arxiv.org/pdf/2403.03190v2",
        "summary": "Abstract reasoning problems pose significant challenges to artificial\nintelligence algorithms, demanding cognitive capabilities beyond those required\nfor perception tasks. This study introduces the Triple-CFN approach to tackle\nthe Bongard-Logo problem, achieving notable reasoning accuracy by implicitly\nreorganizing the concept space of conflicting instances. Additionally, the\nTriple-CFN paradigm proves effective for the RPM problem with necessary\nmodifications, yielding competitive results. To further enhance performance on\nthe RPM issue, we develop the Meta Triple-CFN network, which explicitly\nstructures the problem space while maintaining interpretability on progressive\npatterns. The success of Meta Triple-CFN is attributed to its paradigm of\nmodeling the conceptual space, equivalent to normalizing reasoning information.\nBased on this ideology, we introduce the Re-space layer, enhancing the\nperformance of both Meta Triple-CFN and Triple-CFN. This paper aims to\ncontribute to advancements in machine intelligence by exploring innovative\nnetwork designs for addressing abstract reasoning problems, paving the way for\nfurther breakthroughs in this domain.",
        "updated": "2024-03-06 04:21:38 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.03190v2"
    },
    {
        "title": "Solving the bongard-logo problem by modeling a probabilistic model",
        "authors": "Ruizhuo SongBeiming Yuan",
        "links": "http://arxiv.org/abs/2403.03173v1",
        "entry_id": "http://arxiv.org/abs/2403.03173v1",
        "pdf_url": "http://arxiv.org/pdf/2403.03173v1",
        "summary": "Abstract reasoning problems challenge the perceptual and cognitive abilities\nof AI algorithms, demanding deeper pattern discernment and inductive reasoning\nbeyond explicit image features. This study introduces PMoC, a tailored\nprobability model for the Bongard-Logo problem, achieving high reasoning\naccuracy by constructing independent probability models. Additionally, we\npresent Pose-Transformer, an enhanced Transformer-Encoder designed for complex\nabstract reasoning tasks, including Bongard-Logo, RAVEN, I-RAVEN, and PGM.\nPose-Transformer incorporates positional information learning, inspired by\ncapsule networks' pose matrices, enhancing its focus on local positional\nrelationships in image data processing. When integrated with PMoC, it further\nimproves reasoning accuracy. Our approach effectively addresses reasoning\ndifficulties associated with abstract entities' positional changes,\noutperforming previous models on the OIG, D3$\\times$3 subsets of RAVEN, and PGM\ndatabases. This research contributes to advancing AI's capabilities in abstract\nreasoning and cognitive pattern recognition.",
        "updated": "2024-03-05 18:08:29 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.03173v1"
    }
]