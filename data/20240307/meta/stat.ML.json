[
    {
        "title": "LC-Tsalis-INF: Generalized Best-of-Both-Worlds Linear Contextual Bandits",
        "authors": "Masahiro KatoShinji Ito",
        "links": "http://arxiv.org/abs/2403.03219v1",
        "entry_id": "http://arxiv.org/abs/2403.03219v1",
        "pdf_url": "http://arxiv.org/pdf/2403.03219v1",
        "summary": "This study considers the linear contextual bandit problem with independent\nand identically distributed (i.i.d.) contexts. In this problem, existing\nstudies have proposed Best-of-Both-Worlds (BoBW) algorithms whose regrets\nsatisfy $O(\\log^2(T))$ for the number of rounds $T$ in a stochastic regime with\na suboptimality gap lower-bounded by a positive constant, while satisfying\n$O(\\sqrt{T})$ in an adversarial regime. However, the dependency on $T$ has room\nfor improvement, and the suboptimality-gap assumption can be relaxed. For this\nissue, this study proposes an algorithm whose regret satisfies $O(\\log(T))$ in\nthe setting when the suboptimality gap is lower-bounded. Furthermore, we\nintroduce a margin condition, a milder assumption on the suboptimality gap.\nThat condition characterizes the problem difficulty linked to the suboptimality\ngap using a parameter $\\beta \\in (0, \\infty]$. We then show that the\nalgorithm's regret satisfies\n$O\\left(\\left\\{\\log(T)\\right\\}^{\\frac{1+\\beta}{2+\\beta}}T^{\\frac{1}{2+\\beta}}\\right)$.\nHere, $\\beta= \\infty$ corresponds to the case in the existing studies where a\nlower bound exists in the suboptimality gap, and our regret satisfies\n$O(\\log(T))$ in that case. Our proposed algorithm is based on the\nFollow-The-Regularized-Leader with the Tsallis entropy and referred to as the\n$\\alpha$-Linear-Contextual (LC)-Tsallis-INF.",
        "updated": "2024-03-05 18:59:47 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.03219v1"
    },
    {
        "title": "Active Statistical Inference",
        "authors": "Tijana ZrnicEmmanuel J. Candès",
        "links": "http://arxiv.org/abs/2403.03208v1",
        "entry_id": "http://arxiv.org/abs/2403.03208v1",
        "pdf_url": "http://arxiv.org/pdf/2403.03208v1",
        "summary": "Inspired by the concept of active learning, we propose active\ninference$\\unicode{x2013}$a methodology for statistical inference with\nmachine-learning-assisted data collection. Assuming a budget on the number of\nlabels that can be collected, the methodology uses a machine learning model to\nidentify which data points would be most beneficial to label, thus effectively\nutilizing the budget. It operates on a simple yet powerful intuition:\nprioritize the collection of labels for data points where the model exhibits\nuncertainty, and rely on the model's predictions where it is confident. Active\ninference constructs provably valid confidence intervals and hypothesis tests\nwhile leveraging any black-box machine learning model and handling any data\ndistribution. The key point is that it achieves the same level of accuracy with\nfar fewer samples than existing baselines relying on non-adaptively-collected\ndata. This means that for the same number of collected samples, active\ninference enables smaller confidence intervals and more powerful p-values. We\nevaluate active inference on datasets from public opinion research, census\nanalysis, and proteomics.",
        "updated": "2024-03-05 18:46:50 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.03208v1"
    },
    {
        "title": "How Well Can Transformers Emulate In-context Newton's Method?",
        "authors": "Angeliki GiannouLiu YangTianhao WangDimitris PapailiopoulosJason D. Lee",
        "links": "http://arxiv.org/abs/2403.03183v1",
        "entry_id": "http://arxiv.org/abs/2403.03183v1",
        "pdf_url": "http://arxiv.org/pdf/2403.03183v1",
        "summary": "Transformer-based models have demonstrated remarkable in-context learning\ncapabilities, prompting extensive research into its underlying mechanisms.\nRecent studies have suggested that Transformers can implement first-order\noptimization algorithms for in-context learning and even second order ones for\nthe case of linear regression. In this work, we study whether Transformers can\nperform higher order optimization methods, beyond the case of linear\nregression. We establish that linear attention Transformers with ReLU layers\ncan approximate second order optimization algorithms for the task of logistic\nregression and achieve $\\epsilon$ error with only a logarithmic to the error\nmore layers. As a by-product we demonstrate the ability of even linear\nattention-only Transformers in implementing a single step of Newton's iteration\nfor matrix inversion with merely two layers. These results suggest the ability\nof the Transformer architecture to implement complex algorithms, beyond\ngradient descent.",
        "updated": "2024-03-05 18:20:10 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.03183v1"
    },
    {
        "title": "On a Neural Implementation of Brenier's Polar Factorization",
        "authors": "Nina VesseronMarco Cuturi",
        "links": "http://arxiv.org/abs/2403.03071v1",
        "entry_id": "http://arxiv.org/abs/2403.03071v1",
        "pdf_url": "http://arxiv.org/pdf/2403.03071v1",
        "summary": "In 1991, Brenier proved a theorem that generalizes the $QR$ decomposition for\nsquare matrices -- factored as PSD $\\times$ unitary -- to any vector field\n$F:\\mathbb{R}^d\\rightarrow \\mathbb{R}^d$. The theorem, known as the polar\nfactorization theorem, states that any field $F$ can be recovered as the\ncomposition of the gradient of a convex function $u$ with a measure-preserving\nmap $M$, namely $F=\\nabla u \\circ M$. We propose a practical implementation of\nthis far-reaching theoretical result, and explore possible uses within machine\nlearning. The theorem is closely related to optimal transport (OT) theory, and\nwe borrow from recent advances in the field of neural optimal transport to\nparameterize the potential $u$ as an input convex neural network. The map $M$\ncan be either evaluated pointwise using $u^*$, the convex conjugate of $u$,\nthrough the identity $M=\\nabla u^* \\circ F$, or learned as an auxiliary\nnetwork. Because $M$ is, in general, not injective, we consider the additional\ntask of estimating the ill-posed inverse map that can approximate the pre-image\nmeasure $M^{-1}$ using a stochastic generator. We illustrate possible\napplications of \\citeauthor{Brenier1991PolarFA}'s polar factorization to\nnon-convex optimization problems, as well as sampling of densities that are not\nlog-concave.",
        "updated": "2024-03-05 15:59:54 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.03071v1"
    },
    {
        "title": "Improving Variational Autoencoder Estimation from Incomplete Data with Mixture Variational Families",
        "authors": "Vaidotas SimkusMichael U. Gutmann",
        "links": "http://arxiv.org/abs/2403.03069v1",
        "entry_id": "http://arxiv.org/abs/2403.03069v1",
        "pdf_url": "http://arxiv.org/pdf/2403.03069v1",
        "summary": "We consider the task of estimating variational autoencoders (VAEs) when the\ntraining data is incomplete. We show that missing data increases the complexity\nof the model's posterior distribution over the latent variables compared to the\nfully-observed case. The increased complexity may adversely affect the fit of\nthe model due to a mismatch between the variational and model posterior\ndistributions. We introduce two strategies based on (i) finite\nvariational-mixture and (ii) imputation-based variational-mixture distributions\nto address the increased posterior complexity. Through a comprehensive\nevaluation of the proposed approaches, we show that variational mixtures are\neffective at improving the accuracy of VAE estimation from incomplete data.",
        "updated": "2024-03-05 15:57:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.03069v1"
    }
]