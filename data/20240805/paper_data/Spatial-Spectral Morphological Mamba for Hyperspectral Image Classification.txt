1
Spatial-Spectral Morphological Mamba for
Hyperspectral Image Classification
Muhammad Ahmad, Muhammad Hassaan Farooq Butt, Muhammad Usama, Adil Mehmood Khan, Manual
Mazzara, Salvatore Distenano
Abstract—Inrecentyears,Transformershavegarneredsignif- information across a wide range of wavelengths, providing
icant attention for Hyperspectral Image Classification (HSIC) detailed insights that are often unattainable with traditional
due to their self-attention mechanism, which provides strong imaging techniques. This spectral richness enables the identi-
classification performance. However, these models face major
fication and classification of materials, substances, and condi-
challenges in computational efficiency, as their complexity in-
creases quadratically with the sequence length. The Mamba tionswithahighdegreeofaccuracyandspecificity.However,
architecture, leveraging a State Space Model, offers a more theefficacyofmodelsdesignedtoanalyzeHyperspectral(HS)
efficient alternative to Transformers. This paper introduces the data hinges critically on their ability to manage and interpret
Spatial-SpectralMorphologicalMamba(MorpMamba)model.In
this rich, high-dimensional information effectively [18]. The
theMorpMambamodel,atokengenerationmodulefirstconverts
challenge lies in developing robust algorithms that can handle
theHyperspectralImage(HSI)patchintospatial-spectraltokens.
These tokens are then processed by a morphology block, which the complex data structures inherent in Hyperspectral Images
computes structural and shape information using depthwise (HSIs), ensuring accurate and reliable classifications across
separable convolutional operations. The extracted information various applications.
is enhanced in a feature enhancement module that adjusts
TherecentsuccessofDeepLearning(DL)hassignificantly
the spatial and spectral tokens based on the center region
advanced HSIC [19]–[24]. Convolutional Neural Networks
of the HSI sample, allowing for effective information fusion
within each block. Subsequently, the tokens are refined in a (CNNs), in particular, have played a pivotal role in this
multi-head self-attention block to further improve the feature progressbyeffectivelycapturingbothspatialandspectralfea-
space. Finally, the combined information is fed into the state tures, which are crucial for accurate classification [1]. CNNs
space block for classification and the creation of the ground excel at learning hierarchical representations from HS data,
truth map. Experiments on widely used Hyperspectral (HS)
enabling the extraction of intricate patterns that traditional
datasets demonstrate that the MorpMamba model outperforms
(parametric efficiency) both CNN and Transformer models. The methods often miss [25]. However, CNNs have inherent limi-
sourcecodewillbemadepubliclyavailableathttps://github.com/ tations, such as their reliance on local receptive fields, which
MHassaanButt/MorpMamba. maynotfullyexploittheglobalcontextualinformationinHSIs
Index Terms—Hyperspectral Imaging, Spatial-Spectral [26]. This local focus can lead to suboptimal performance,
Mamba, Morphological Operations; Hyperspectral Image especiallyinscenarioswhereunderstandingthebroaderspatial
Classification context is essential for accurate classification [18]. Moreover,
CNNstypicallyrequiresubstantialamountsoflabeledtraining
data to achieve high performance, which can be a significant
I. INTRODUCTION
drawbackgiventhescarcityofannotatedHSdatasets[20].As
HYPERSPECTRAL Image Classification (HSIC) is cru-
a result, while CNNs have undeniably advanced the field of
cial in diverse fields such as remote sensing [1], Earth
HSIC, their limitations highlight the need for more advanced
observation [2], urban planning [3], agriculture [4], forestry
architectures that can overcome these challenges and further
[5], target/object detection [6], mineral exploration [7], envi-
enhance classification accuracy.
ronmental and climate monitoring [8]–[10], forensic sciences
In recent years, Transformer architecture has emerged as
[11], [12], and even food, meat, and bakery processing [13]–
a leading approach for learning long-range contextual depen-
[17]. The versatility and applicability of HSIC in these do-
dencies[27].TheinclusionofTransformer-basedarchitectures
mains stem from its ability to capture and analyze spectral
in HSIC has led to significant advancements, often outper-
forming Traditional DL (TDL) models. With growing interest
M. Ahmad and M. Usama are with the Department of Computer Sci-
ence, National University of Computer and Emerging Sciences, Islam- in Transformer models to further enhance HSIC, the field
abad, Chiniot-Faisalabad Campus, Chiniot 35400, Pakistan. (e-mail: mah- haswitnessednotableimprovementsoverTDLmethods[28]–
mad00@gmail.com)
[38]. Unlike CNNs, which are limited by their local receptive
M. H. F. Butt is with the Institute of Artificial Intelligence, School
of Mechanical and Electrical Engineering, Shaoxing University, Shaoxing fields, Transformer models excel at capturing long-range de-
312000,China.(e-mail:hassaanbutt67@gmail.com) pendencies and global contextual information. This capability
A. M. Khan is with the School of Computer Science, University of Hull,
is particularly beneficial for HSIs, which contain rich spec-
HullHU67RX,UK.(e-mail:a.m.khan@hull.ac.uk)
M. Mazzara is with the Institute of Software Development and tral information across numerous bands. By leveraging self-
Engineering, Innopolis University, Innopolis, 420500, Russia. (e-mail: attention mechanisms, Transformers can effectively model the
m.mazzara@innopolis.ru)
complex relationships between different spectral bands and
S. Distefano is with Dipartimento di Matematica e Informatica—MIFT,
UniversityofMessina,Messina98121,Italy.(e-mail:sdistefano@unime.it) spatial regions, leading to more accurate and robust classi-
4202
guA
2
]VC.sc[
1v27310.8042:viXra2
fication results [25]. However, despite these advancements, cies while maintaining linear computational complexity. De-
Transformers face substantial challenges related to compu- spiteimprovedclassificationperformance,theauthorsstressed
tational efficiency, as their complexity scales quadratically the need for further optimization to robustly handle high-
with sequence length. This scaling issue is especially prob- dimensional data and explore additional strategies for better
lematic in HSIC, where the high dimensionality of HS data generalization across diverse HS datasets.
requiressignificantcomputationalresources.Consequently,the Sheng et al. [45] introduced DualMamba, a spatial-spectral
inefficiency of Transformers in managing large datasets and Mamba architecture for HSIC. This design integrates Mamba
their reliance on extensive labeled data limit their practical with CNNs, effectively capturing complex spectral-spatial
application in this field. relationships while ensuring computational efficiency. How-
TheMambaarchitecture,withitsStateSpaceModel(SSM) ever, the authors noted limitations, including redundancy in
inspiredbycontroltheory,presentsamoreefficientalternative multi-directional scanning strategies and challenges in fully
totheTransformerarchitecture[39].Byreplacingtheattention leveraging spectral information. Similarly, Zhou et al. [46]
mechanism with SSMs, Mamba achieves linear complexity developedanotherspatial-spectralMambaarchitecture,featur-
scaling with sequence length, drastically reducing the com- ing a centralized Mamba-Cross-Scan mechanism that trans-
putational overhead [39], [40]. This efficiency is particularly forms HSI data into diverse sequences, enhancing feature
beneficial for HSIC, where handling long spectral sequences extraction through a Tokenized Mamba encoder. Despite its
is crucial. Mamba’s ability to manage long sequences more strengths, this method is sensitive to variations in periph-
efficiently, combined with its hardware-aware optimizations, eral pixels and requires significant computational resources
makes it a superior choice for processing the vast amounts of for larger patches. Yang et al. [47] proposed GraphMamba,
data inherent in HSIs. which enhances spatial-spectral feature extraction through
Yao et al. [41] introduced SpectralMamba, leveraging the components like HyperMamba and SpatialGCN, addressing
Mamba architecture for HSIC. Their approach integrates the efficiency and contextual awareness. Nevertheless, the authors
Mamba framework with DL techniques to address ineffi- identified shortcomings, such as the need for optimization of
ciencies common in sequential architectures like Recurrent encoding modules to accommodate diverse HS datasets and
Neural Networks (RNNs) and Transformers. SpectralMamba potential overfitting in high-dimensional spaces.
features a Gated Spatial-Spectral Merging (GSSM) module Therefore, this paper introduces a Morphology-based
and a Piece-wise Sequential Scanning (PSS) strategy, effec- Spatial-SpectralMamba(MorpMamba)architecturetoaddress
tively encoding spatial regularity and spectral uniqueness, the limitations of previous HSIC models. Firstly: Erosion
which enhances discriminative representation while ensuring emphasizes the boundaries and edges of objects, which is
computational efficiency. However, the authors acknowledge crucial for distinguishing between different regions in HSIs.
limitations, including opportunities to reduce computational Dilation, on the other hand, fills gaps and connects disjointed
overhead and improve handling of spectral variability. Huang parts of objects, enhancing the structural integrity of features.
et al. [42] proposed the Spatial-Spectral Mamba (SSMamba) Both erosion and dilation are effective in reducing noise by
architecture for HSIC. This model capitalizes on the Mamba smoothing out small irregularities and highlighting prominent
framework’s efficiency and long-range feature extraction ca- features. By integrating these operations into the tokenization
pabilities by incorporating a spectral-spatial token generation process, MorpMamba ensures that the spatial and spectral to-
module and multiple stacked spectral-spatial Mamba blocks. kenscapturebothfinedetailsandglobalstructures,resultingin
Each block consists of two basic Mamba blocks and a feature more robust and informative token representations. Secondly:
enhancement module to facilitate the fusion of spectral and Byincorporatingmorphologicaloperationsinthetokenization
spatial information. Despite its innovative design, the authors enhancement module, our model refines the token represen-
recognized the need for further optimization to robustly man- tations, making them less sensitive to noise and artifacts.
ageextremelyhigh-dimensionaldataandexplorestrategiesfor This leads to more stable and reliable features. Combined
better generalization across diverse HS datasets. with multi-head self-attention, the model can simultaneously
Wang et al. [43] introduced the S2Mamba architecture for focus on different aspects of the spatial and spectral features,
HSIC, which integrates spatial and spectral features using which helps capture complex relationships and dependencies
SSMs. This model employs Patch Cross Scanning and Bi- within the data. Lastly: The SSM module, which models the
directional Spectral Scanning to capture spatial and spectral temporalevolutionoffeatures,benefitsfromtheenhancedand
features, respectively, merging them with a Spatial-Spectral more interpretable features extracted through morphological
Mixture Gate to enhance classification accuracy. Nonetheless, operations. This results in a clearer understanding of how the
the authors noted the necessity for further optimization to features evolve and contribute to the final classification.
effectively handle complex spatial-spectral interactions and In summary, erosion and dilation help capture fine details
improve computational efficiency. He et al. [44] developed andglobalstructures,leadingtorobustandinformativespatial-
the 3D-Spectral-Spatial Mamba (3DSSMamba) architecture spectral token representations. These operations smooth out
forHSIC.ThisframeworkutilizesthestrengthsoftheMamba irregularitiesandenhanceprominentfeatures,producingstable
architecture by incorporating a Spectral-Spatial Token Gen- and reliable tokens. By separately processing the spatial and
eration module (SSTG) and a 3D Spectral-Spatial Selective spectral dimensions, the multi-head self-attention mechanism
Scanning (3DSS) mechanism, enabling the model to effec- can effectively capture complex relationships and dependen-
tively capture global spectral-spatial contextual dependen- cies. Integrating these benefits, the proposed morphology-3
Fig. 1: A joint spatial-spectral feature token is first computed from the HSI using morphological operations. These tokens
are then integrated into the MorpMamba model, which includes Erosion and Dilation operations, token enhancement, and a
multi-head attention module. This method allows for a more selective and effective representation of information compared
to standard fixed-dimension encodings. The output is then processed through a SSM, followed by normalization and a linear
layer with l2 regularization. Finally, this output is passed to the classification head for generating the ground truth.
2
based tokenization process significantly improves the perfor- A. Token Generation with Erosion and Dilation
mance of the Mamba model for HSIC.
Initially, the Erosion is performed on each spatial and
Theremainderofthepaperisorganizedasfollows:Section
spectralpatchindividuallyasErosion:Theerosionofaninput
II describes the components of the proposed methodology,
tensor X by a kernel k is defined as:
while Section III details the experimental datasets used in
this study. Section IV outlines the essential parameter-tuning ε (X)= min X(i)⊟k(i−j) (2)
k
process for our approach. Section V provides a comparison i∈N(j)
of the proposed MorpMamba with state-of-the-art models and
where N(j) denotes the neighborhood of the pixel at location
discussesitsperformance.SectionVIcoversanablationstudy j, and the subtraction X(i) ⊟ k(i−j) is performed element-
tofurthervalidatetheperformanceofMorpMambaincompar- wise with ⊟ defined the erosion operation. This operation
ison to the SSMamba architecture. This section also provides
reduces the shape of the background object in the HSI patch
model embeddings, illustrating the model’s effectiveness in
token. Erosion perhaps eliminates minor details and enlarges
capturing the feature space for classification. Finally, Section
holes, making them more distinguishable from each other in
VIIconcludesthepaperandoutlinesimportantfutureresearch
different texture regions. Dilation: The dilation of an input
directions.
tensor X by a kernel k is defined as:
II. PROPOSEDMETHODOLOGY
δ (X)= max X(i)⊞k(i−j) (3)
k
Assume the HSI data X ∈ RH,W,C has a shape of i∈N(j)
(H,W,C), where H and W are the height and width, and wheretheadditionX(i) ⊞ k(i−j)isperformedelement-wise,
C is the number of bands. The HSI cube X is divided into where ⊞ represent the dilations operation. A dilated patch is
overlapping 3D patches as: produced by combining the input patch with the Structuring
(cid:18) (cid:19) Element (SE), selecting the pixel with the maximum value in
H W
N = × (1) the local neighborhood. As a result of the dilation procedure,
P P
the boundaries of the foreground objects in the input patch
where X ∈ RN×(P×P×C), e.g., (N ×8×8×C) used as are broadened. In other words, the SE kernel’s size affects
input to subsequent modules, where N be the total number the apparent texture size for various regions within the patch
of patches. These patches are divided into spectral and spatial and token. The Erosion (equation 2) and Dilation (equation
patches, individually, each undergoing separate processing to 3) operations are performed per channel using depthwise 2D
generate spectral and spatial morphological profiles (Erosion convolution layers with kernel size (5 × 5) and the same
and Dilation) [48]. Figure 1 provides an overview of the pending, initialized with weights set to one (representing the
MorpMamba model. SE) and the sign is inverted.4
The spatial-spectral morphology combines the spatial and
spectral aspects of the input tensor X to generate spatial-
spectral tokens. The spatial morphology is obtained by ap-
plying the erosion and dilation operations to the input tensor
X along the spatial dimensions (H and W):
Xeroded =εk(X) (4)
spatial
Xdilated =δk(X) (5)
spatial
The resulting spatial features are then concatenated and
passed through a 1 × 1 convolution layer to obtain the
combined spatial token:
t =DepthwiseConv2D(∥(Xeroded,Xdilated)) (6)
spatial spatial spatial
Fig. 2: Spatial-Spectral Token Enhancement module adopted
where ∥ stands for concatenation. The spectral morphology is
to refine and enhance the spatial and spectral features.
obtainedbyapplyingtheerosionanddilationoperationstothe
transposed input tensor X⊤, effectively treating the channels
as the ”spatial” dimension:
To further enhance the model’s learning capabilities, we
employ a multi-head attention mechanism. This allows the
Xeroded =εk(X⊤) (7)
spectral model to attend to different segments of the input tokens
simultaneously, as illustrated in Figure 3. By projecting the
Xdilated =δk(X⊤) (8) input tokens into multiple attention heads, the model can
spectral
capture complex dependencies within the HSI data, which is
The resulting spectral features are then transposed back to crucialforeffectivefeatureextraction.Foreachattentionhead
the original shape and concatenated, followed by a 1 × 1 i, the computations are defined as follows:
convolution layer to obtain the combined spectral token:
t =DepthwiseConv2D(∥(Xeroded,Xdilated)) (9)
spectral spectral spectral
The final output of the class (EDSSTokenGeneration)
layer is the pair of combined spatial and spectral tokens
(t ,t ). The spatial-spectral morphology aims to cap-
spatial spectral
ture both the spatial structure and the spectral (channel-
wise) characteristics of the input tensor X, providing a more
comprehensive representation of the data.
B. Token Enhancement and Multi-head Attention
This module includes a gating mechanism that works with
spatial and spectral tokens, using the central region of the
HSI patch for contextual information [49]. This allows Morp-
Mamba to dynamically adjust the importance of different
tokens, improving its feature extraction capabilities. The en-
Fig. 3: Multi-Head Self-Attention Module adopted to process
hancement of tokens occurs in the following manner:
the enhanced spatial and spectral features.
(cid:101)t( spl)
ectral
=t( spl) ectral⊙σ(W
spectral
c+b spectral) (10)
(cid:101)t( spl)
atial
=t( spl) atial⊙σ(W
spatial
c+b spatial) (11) Q i =(cid:101)t( spl) ectralW iQ; K i =(cid:101)t( spl) atialW iK; V i =(cid:101)t( spl) atialW iV (12)
where WQ, WK, and WV are learned weight matrices asso-
In this context, W spectral and W spatial represent the i i i
ciated with the query, key, and value projections, respectively.
learnedweightmatrices,whileσdenotesthesigmoidfunction,
Theattentionscoresforeachheadiarecomputedusingscaled
as illustrated in Figure 2. This gating mechanism allows the
dot-product attention:
model to dynamically enhance the importance of spatial and
spectral features based on contextual information from the (cid:18) Q K⊤(cid:19)
A =softmax √i i (13)
central region of the HSI sample. i
d
k5
Each attention head works with key vectors of dimension using a sensor mounted on a drone. The weather was clear
d . The output for each head, denoted by O , is calculated withatemperaturearound36°Cand65%humidity.Thescene
k i
as O = A V . These individual outputs are then combined consistsofsixcrops:corn,cotton,sesame,broad-leafsoybean,
i i i
using concatenation: O =∥(O ,O ,...,O ). This combined narrow-leafsoybean,andrice.Thedroneflewatanaltitudeof
1 2 h
output,O,representsafusedfeaturerepresentation.Itcaptures 500 meters and captured an image of 550 × 400 pixels. This
diverse and refined features from both the spatial and spectral imagehas270spectralbands,coveringwavelengthsfrom400
domains of the HSI data. This enrichment enhances the to 1000 nanometers. Each pixel in the image represents an
model’s ability to extract meaningful information. area of about 0.463 meters on the ground.
Salinas(SA)scenewascollectedbythe224-bandAirborne
Visible/Infrared Imaging Spectrometer (AVIRIS) sensor over
C. State Space Model (SSM)
Salinas Valley, California, and is characterized by high spatial
MorpMamba captures complex relationships within HSI
resolution with 3.7-meter pixels. The area covered comprises
data by combining several techniques: spectral-spatial token
512 lines by 217 samples. This image is available only as at-
generation, token enhancement, multi-head attention, and an
sensor radiance data and includes vegetables, bare soils, and
SSM. It starts with a sequence of improved tokens, denoted
vineyard fields. The Salinas ground truth contains 16 classes.
by O = (E ,E ,E ,...,E ). The state transition, which
1 2 3 T Pavia University (PU) and Pavia Center (PC) are two
captures these intricate dependencies, is then computed as:
scenes acquired by the Reflective Optics System Imaging
Spectrometer (ROSIS) sensor during a flight campaign over
h =ReLU(W h +W E ) (14)
t transition t−1 update t Pavia, northern Italy. The number of spectral bands is 102 for
Pavia Centre and 103 for Pavia University. Pavia Centre is a
where W and W denote learned weights, and
transition update
1096 × 1096 pixels image, while Pavia University is 610 ×
h represents the hidden state at time t. To obtain the final
t
610pixels.Thegeometricresolutionis1.3meters.Bothimage
output for classification, a linear classifier is applied to h :
t
ground truths differentiate nine classes each.
y =σ(h W −λ|W |2) (15) The IEEE Geoscience and Remote Sensing Society pub-
t classifier classifier 2
lished the University of Houston (UH) dataset—collected
where |W |2 represents the squared l2 norm of the by the Compact Airborne Spectrographic Imager (CASI)—in
classifier 2 2
weights W . λ = 0.01 is the regularization coefficient, 2013 as part of its Data Fusion Contest. This dataset is
classifier
controlling the strength of regularization and σ denotes the composed of 340 × 1905 pixels with 144 spectral bands.
sigmoid function used for classification. l2 regularization The spatial resolution is 2.5 meters per pixel (MPP), with
2
penalizes large values in W , encouraging the model wavelengths ranging from 0.38 to 1.05 µm. The ground truth
classifier
to prefer smaller and simpler models, which help prevent comprises 15 different land-cover classes.
overfitting. This approach enables MorpMamba to effectively
leverage both spatial and spectral information, enhancing its
ability to classify HSI data by combining complementary
insights from these modalities.
III. EXPERIMENTALDATASETS
To assess MorpMamba’s performance, we evaluated it on
severalpubliclyavailableHSIdatasets.Thesedatasetsinclude
WHU-Hi-LongKou,PaviaUniversity(PU),PaviaCentre(PC),
Salinas (SA), and the University of Houston (UH). Table I
summarizesthekeycharacteristicsofeachdatasetusedinour
experiments and true maps are presented in Figure 4.
(a) SA (b) PU (c) PC (d) LK
TABLEI:SummaryoftheHSIdatasetsusedforexperimental
evaluation.
— SA PU PC UH LK
Source AVIRIS ROSIS-03 ROSIS-03 CASI UAV
Spatial 512×217 610×610 1096×1096 340×1905 550×400
Spectral 224 103 102 144 270
(e) UH
Wavelength 0.35−1.05 430−860 430−860 0.35−1.05 400−1000nm
Samples 111104 372100 1201216 647700 220000
Classes 16 9 9 15 9 Fig. 4: True Maps of Experimental Datasets.
Sensor Aerial Aerial Aerial Aerial Aerial
Resolution 3.7mpp 1.3m 1.3m 2.5mpp 0.463m
The WHU-Hi-LongKou (LK) dataset captures a scene in
IV. PARAMETERTUNING
Longkou Town, Hubei province, China, using an 8-mm focal
lengthHeadwallNano-Hyperspecimagingsensormountedon The MorpMamba’s weights were randomly initialized and
a DJI Matrice 600 Pro (DJI M600 Pro) UAV platform. It was optimized over 50 epochs using the Adam optimizer with a
collected on July 17, 2018, between 1:49 PM and 2:37 PM learning rate of 0.001 and softmax loss. The training was6
Fig. 5: Overall accuracy of MorpMamba across different training data ratios, patch sizes, number of heads, and kernel sizes
over 50 epochs on WHU-Hi-LongKou, Pavia Centre, Pavia University, Salinas, and University of Houston datasets.
Fig.6:TrainingTimeofMorpMambaacrossdifferenttrainingdataratios,patchsizes,numberofheads,andkernelsizesover50
epochs on WHU-Hi-LongKou, Pavia Centre, Pavia University, Salinas, and University of Houston datasets. The training ratio
andpatchsizehaveastronginfluenceoncomputationaltime,whereastheheadsizewithinmulti-headself-attentionandthe
kernel size within morphological operations do not significantly affect the computational load. This demonstrates that the
Mamba model maintains a linear computational load even after incorporating multi-head self-attention and morphological
operations. However, these additions significantly improve performance, as shown in the subsequent sections.
conducted in mini-batches of 256 samples per epoch. The
Mamba block’s embedding dimensions were set to 64, with 4
heads for multi-head attention and state space dimensions of
128. This configuration enabled the model to effectively learn
patterns by minimizing loss.
Various random split percentages for training samples (1%,
2%,5%,10%,15%,20%,and25%)weretested,startingwith
an initial patch size of 4 × 4. Different patch sizes 2 × 2,
4×4, 6×6, 8×8, and 10×10 were also evaluated to find
the optimal setup. Additionally, different numbers of attention
heads (2, 4, 6, and 8) were tested, as well as various kernel Fig. 7: The accuracy and loss for both the training and
sizes for morphological operations 3×3, 5×5, 7×7, 9×9, validation sets were computed using a 4×4 patch and 20%
and 11×11 were also tested. All these results are presented training samples over 50 epochs on the WHU-Hi LongKou
in Figure 5. Moreover, the computational time for all the dataset.
above experiments was also considered a contributing factor.
Minimizing computational time is essential for deploying
the MorpMamba model on resource-constrained devices. The
The results illustrated in Figure 5 highlight the OA of the
computational time is shown in Figure 6.
MorpMamba model across various training data ratios, patch
Thebestsettingsfromtheseexperimentswereusedtoeval- sizes, number of heads for attention, and kernel sizes for
uate the MorpMamba in comparison with other methods. All morphology.Thetrenddemonstratesaconsistentimprovement
experiments were performed on an Intel i9-13900k machine in accuracy as the training data ratio increases. Notably, the
with an RTX 4090 GPU and 32GB of RAM using Jupyter LK dataset achieved the highest accuracy of 99.73% at the
Notebook. Figure 7 presents the convergence of loss and 25% data ratio, indicating the model’s robustness in utilizing
accuracy of the MorpMamba model over 50 epochs. larger training sets. Similarly, the PC and SA datasets showed7
(a) CNN2D (b) CNN3D (c) HybCNN (d) IN2D (e) IN3D
(f) HybIN (g) base ViT (h) hir transformer (i) SSMamba (j) MorpMamba
Fig. 8: The predicted ground truth maps for LK datasets using various SOTA methods, alongside the proposed MorpMamba
model, are presented. While most competing methods achieved equivalent accuracy, their parameter efficiency remains
constrained and too high for deployment on resource-limited devices. In contrast, the MorpMamba model offers significantly
better parameter efficiency and overall performance compared to all competing methods.
TABLE II: Performance comparison of MorpMamba with SOTA models on various datasets. The metrics shown are Overall
Accuracy (OA), Average Accuracy (AA), and the Kappa coefficient (κ). The datasets include the UH, WHU-Hi-LongKou
(LK), PU, PC, and SA. The number of parameters for each model is also provided.
OA AA κ OA AA κ OA AA κ OA AA κ OA AA κ
Model Parameters
UniversityofHouston WHU-Hi-LongKou(LK) PaviaUniversity PaviaCenter Salinas
2DCNN 97.49 97.04 97.29 99.71 99.29 99.62 97.97 96.99 97.30 99.66 99.06 99.52 97.54 98.82 97.26 322752
3DCNN 99.01 98.81 98.93 99.81 99.58 99.75 98.70 97.86 98.28 99.87 99.65 99.81 98.86 99.48 98.73 4042880
HybCNN 98.93 98.71 98.84 99.84 99.60 99.79 43.59 — — 99.78 99.45 99.69 98.76 99.42 98.62 594048
2DIN 99.09 98.96 99.02 99.83 99.56 99.78 98.74 98.10 98.33 99.82 99.52 99.74 98.65 99.28 98.50 3285844
3DIN 98.73 98.43 98.63 99.80 99.49 99.74 98.51 97.61 98.03 99.86 99.61 99.81 98.23 99.16 98.03 47448680
HybIN 98.81 98.56 98.71 99.75 99.56 99.67 98.79 98.26 98.40 99.82 99.45 99.75 98.74 99.38 98.60 1349848
Hybrid-ViT 98.45 97.85 98.33 99.75 99.36 99.68 98.15 97.24 97.55 99.71 99.13 99.59 97.99 99.05 97.76 790736
Hir-Transformer 97.12 96.25 96.89 99.68 99.14 99.59 97.99 96.79 97.34 99.64 98.79 99.49 98.09 98.95 97.87 4219094
SSMamba 90.36 90.54 89.58 99.51 98.45 99.36 95.67 93.20 94.25 99.48 98.60 99.27 95.20 97.81 94.65 49744
MorpMamba 98.28 97.91 98.14 99.70 99.25 99.61 97.67 96.93 96.91 99.71 98.85 99.59 98.52 99.25 98.35 67142
substantial performance, peaking at 99.71% and 98.93%, re- efficiency by evaluating the number of parameters for each
spectively. The UH dataset exhibited significant gains from a model. Table II provides a comprehensive overview of these
lower baseline of 79.16% at 1% to 97.64% at 25%, reflecting metrics across five prominent HS datasets: the UH, LK, PU,
the model’s ability to improve with more training data. These PC,andSA.Whereas,Figures8,9,10,11,and12presentthe
findings underscore the efficacy of the MorpMamba model predicted ground truth maps for all the competing methods,
in handling diverse datasets and its potential for enhanced including the proposed MorpMamba model. OA represents
performance with increased training data. the percentage of correctly classified samples out of the total
samples, AA is the mean accuracy across all classes, and κ
V. COMPARISONWITHSOTAMETHODSANDDISCUSSION is a statistical measure of inter-rater agreement adjusted for
Inthissection,wepresentadetailedcomparativeanalysisof chance agreement.
the proposed MorpMamba model against several SOTA HSIC Thecomparativemodelsincludedinthecomparisonare2D
models.Thecomparisonisbasedonkeyperformancemetrics: CNN [50], 3D CNN [19], HybCNN (a hybrid of 2D and 3D
Overall Accuracy (OA), Average Accuracy (AA), and the convolutions) [51], 2D IN (2D CNN with instance normal-
Kappa coefficient (κ). Additionally, we assess computational ization) [52], 3D IN (3D CNN with instance normalization)8
(a) CNN2D (b) CNN3D (c) HybCNN (d) IN2D (e) IN3D
(f) HybIN (g) base ViT (h) hir transformer (i) SSMamba (j) MorpMamba
Fig. 9: The predicted ground truth maps for PC datasets using various SOTA methods, alongside the proposed MorpMamba
model, are presented. While most competing methods achieved equivalent accuracy, their parameter efficiency remains
constrained and too high for deployment on resource-limited devices. In contrast, the MorpMamba model offers significantly
better parameter efficiency and overall performance compared to all competing methods.
[53], HybIN (a hybrid of 2D and 3D CNNs with instance activation. The second layer increases the filter count to 16,
normalization) [54], [55], Hybrid-ViT (a hybrid vision Trans- with a kernel size of (3,3,5) and the same padding and
former) [56], Hir-Transformer (a hierarchical Transformer) activation functions. The third layer utilizes 32 filters with
[57], SSMamba (a state-space model-based Mamba architec- a (3,3,3) kernel size, followed by a fourth layer with 64
ture without Morphology operation), and MorpMamba (the filtersandthesamekerneldimensions.Aftertheconvolutional
proposedmodelintegratingmorphologicaloperationswiththe layers, the feature maps are flattened into a 1D vector. This
Mambaarchitecture).Thedetailedsettingsforeachcompeting vector is then processed through two fully connected (dense)
methodareprovidedbelow,includingthenumberoflayersand layers: the first with 256 units and ReLU activation, and
the number of filters per layer. the second with 128 units, also using ReLU activation. The
The 2D CNN architecture initiates with four sequential networkconcludeswithadenseoutputlayerusingthesoftmax
convolutional layers with 8, 16, 32, and 64 filters with a 3×3 activation function to generate classification probabilities.
kernelsize,usingthesamepaddingandReLUactivation.The The HybCNN model integrates both 3D and 2D convolu-
convolutional layers are succeeded by a flattening layer that tional layers to leverage the strengths of spatial and spectral
transforms the 2D feature maps into a 1D vector, which is feature extraction. The model begins with three successive
then processed by two dense layers. Two dense layers consist 3D convolutional input layers: the first applies 8 filters with
of 256 and 128 units with ReLU activation and are followed a kernel size of (3,3,7), the second applies 16 filters with
by a Dropout layer with a dropout rate of 0.4 to mitigate a kernel size of (3,3,5), and the third applies 32 filters
overfitting. The network concludes with an output layer that with a kernel size of (3,3,3), all using ’same’ padding and
uses the softmax activation function to provide classification ReLU activation. After the 3D convolutions, the output is
probabilities, where the number of units corresponds to the reshapedfroma5Dtensortoa4Dtensor,combiningthedepth
number of classes. dimensions into a single dimension. This reshaped tensor is
The 3D CNN architecture starts with a series of four 3D then processed by a 2D convolutional layer with 64 filters
convolutional layers. The first layer applies 8 filters with and a kernel size of (3,3), followed by a flattening layer.
a kernel size of (3,3,7), using ’same’ padding and ReLU The flattened output is passed through two dense layers:9
(a) CNN2D (b) CNN3D (c) HybCNN (d) IN2D (e) IN3D
(f) HybIN (g) base ViT (h) hir transformer (i) SSMamba (j) MorpMamba
Fig. 10: The predicted ground truth maps for PU datasets using various SOTA methods, alongside the proposed MorpMamba
model, are presented. While most competing methods achieved slightly higher accuracy, ranging from 0.32% to 1.12%, their
parameterefficiencyremainsconstrainedandtoohighfordeploymentonresource-limiteddevices.Incontrast,theMorpMamba
model offers significantly better parameter efficiency and overall performance compared to all competing methods.
the first with 256 units and ReLU activation, followed by a second with 10 filters and a (1,1) kernel size. The outputs
Dropout layer with a rate of 0.4, and the second with 128 from these three blocks are concatenated along the channel
units and ReLU activation, also followed by a Dropout layer dimension, and the combined feature maps are processed
with a rate of 0.4. The model concludes with a dense output by an additional convolutional layer with 128 filters and a
layer employing the softmax activation function to produce (1,1) kernel size. The network concludes with a classification
classification probabilities. module that includes a flattening layer, followed by three
dense layers with 1200, 600, and 150 units, respectively, all
The 2D IN model captures multi-scale features from the usingReLUactivation.Thefinaloutputlayeremployssoftmax
input patch and comprises three distinct blocks of convolu- activation to generate class probabilities.
tional operations. In Block 1, the network applies a sequence
of three convolutional layers: the first with 30 filters and a The 3D IN model is a 3D-CNN designed to capture
(1,1)kernelsize,thesecondwith20filtersanda(1,1)kernel spatiotemporalfeaturesfromvolumetricinputdataeffectively.
size, and the third with 10 filters and a (3,3) kernel size, all The network architecture includes three distinct convolutional
using ’same’ padding and ReLU activation. Block 2 employs blocks. In Block 1, the model starts with a 3D convolutional
a different configuration, starting with a (1,1) convolutional layer featuring 30 filters with a kernel size of (5,5,7), fol-
layer with 40 filters, followed by a (1,1) convolutional layer lowed by another 3D convolutional layer with 20 filters and a
with 20 filters, and concluding with a (5,5) convolutional kernelsizeof(3,3,5),andconcludeswithathird3Dconvolu-
layer with 10 filters. Block 3 initiates with a max pooling tionallayerwith10filtersandakernelsizeof(3,3,3).Block
layer of size (3,3), followed by two convolutional layers: 2 mirrors this configuration but with increased filter counts:
the first with 20 filters and a (1,1) kernel size, and the the first layer uses 40 filters, the second uses 20 filters, and10
(a) CNN2D (b) CNN3D (c) HybCNN (d) IN2D (e) IN3D
(f) HybIN (g) base ViT (h) hir transformer (i) SSMamba (j) MorpMamba
Fig. 11: The predicted ground truth maps for SA datasets using various SOTA methods, alongside the proposed MorpMamba
model, are presented. While most competing methods achieved equivalent accuracy, their parameter efficiency remains
constrained and too high for deployment on resource-limited devices. In contrast, the MorpMamba model offers significantly
better parameter efficiency and overall performance compared to all competing methods.
the third also uses 10 filters. Block 3 further enhances feature layer with a rate of 0.4. The subsequent dense layer, with 128
extraction with 60 filters in the first layer, and 30 filters in the units, is also followed by a Dropout layer, and the final dense
second, and maintains 10 filters in the final layer, each using layer, with 64 units, is followed by another Dropout layer.
the same kernel sizes as in previous blocks. The outputs from The output layer employs softmax activation to produce class
these blocks are concatenated along the channel dimension, probabilities.
and the combined features are processed by an additional 3D
convolutional layer with 128 filters and a (1,1,1) kernel size. The HybIN model is a hybrid architecture combining both
Thenetworkthentransitionstoaclassificationmodule,which 3D and 2D convolutional layers to leverage the strengths of
includesaflatteninglayerfollowedbythreedenselayers.The each for feature extraction from volumetric input data. This
first dense layer, with 512 units, is followed by a Dropout architecture also begins with three distinct 3D convolutional
blocks. In Block 1, the model uses a 3D convolutional layer11
(a) CNN2D (b) CNN3D
(c) HybCNN (d) IN2D
(e) IN3D (f) HybIN
(g) base ViT (h) hir transformer
(i) SSMamba (j) MorpMamba
Fig. 12: The predicted ground truth maps for UH datasets using various SOTA methods, alongside the proposed MorpMamba
model, are presented. While most competing methods achieved equivalent accuracy, their parameter efficiency remains
constrained and too high for deployment on resource-limited devices. In contrast, the MorpMamba model offers significantly
better parameter efficiency and overall performance compared to all competing methods.
with30filtersandakernelsizeof(5,5,7),followedbylayers with a kernel size of (1,S,S), reduces the spatial dimensions
with20and10filtersandkernelsizesof(3,3,5)and(3,3,3), and creates patch embeddings. A learnable class token is
respectively. After extracting features with 3D convolutions, concatenated with these patch embeddings, and positional
the output is reshaped into a 2D structure, applying max encodings are added to provide spatial context. The core
pooling and subsequent 2D convolutions with 16, 32, and of the model consists of several Transformer encoder lay-
64 filters, each with a (1,1) kernel size. Block 2 follows a ers, each with a configurable number of heads and depth.
similar process but with different filter counts: starting with Each Transformer layer processes the patch embeddings to
40 filters, then 20, and ending with 10, each using the same capture complex dependencies and relationships within the
kernel sizes as Block 1. After reshaping the output to 2D, data. In addition to self-attention, the model incorporates a
max pooling and 2D convolutions with 16, 32, and 64 filters cross-attention mechanism between the class token and patch
are applied. Block 3 increases the depth of the convolutional embeddingstoenhancefeatureextraction.Thiscross-attention
layers, using 60 filters in the first layer, 30 in the second, and mechanism is implemented by computing the attention scores
10 in the third, followed by 2D reshaping, max pooling, and between the class token and patch embeddings, followed by
2D convolutions with 16, 32, and 64 filters. The outputs from a weighted aggregation of the patch embeddings based on
all three blocks are concatenated along the channel dimension these scores. Finally, the model concatenates the output of
and processed by an additional 2D convolutional layer with the Transformer layers with the cross-attention output and
128 filters and a (1,1) kernel size. The classification module processesitthroughseveraldenselayerswithReLUactivation.
includes flattening followed by three dense layers with 512, The final output layer, using a softmax activation function,
128, and 64 units, respectively, each with ReLU activation produces class probabilities based on the number of classes.
and Dropout for regularization. The final layer uses softmax The hir_transformer models integrate pyramid-based
activation to produce class probabilities.
3D convolutional layers with Transformer-based mechanisms
The Hybrid_ViT model combines 3D convolutional lay- to leverage multi-scale features for enhanced volumetric data
ers with Transformer layers to effectively capture both spatial analysis.Themodelstartswitha3Dinputofshape(S,S,B,1)
and spectral features from volumetric input data. The model and further constructs a pyramid of convolutional layers with
first applies a patch embedding layer using a 3D convolution varying scales, where each level of the pyramid applies 3D
withanembeddingdimensionof64.Thisconvolutionallayer, convolutionswithincreasingkernelsizesandscales.Theinput12
is scaled down for each pyramid level by a factor of 2l, datasets.Thecomparativeanalysisunderscoresthestrengthsof
where l is the pyramid level. The output from each level, the MorpMamba model in HSIC, consistently delivering high
consisting of feature maps extracted at different scales, is accuracyandefficiency,andoutperformingormatchingSOTA
then concatenated along the channel dimension to capture models while maintaining a lower computational footprint.
multi-scale information. The model extends this architecture Theseresultsvalidatetheeffectivenessofintegratingmorpho-
by incorporating Transformer layers. It begins with the output logical operations with the Mamba architecture, establishing
fromthepyramid_3d_cnn,whichprovidesmulti-scalefea- MorpMamba as a leading model for HSIC.
tures. The model applies a ReLU activation and processes the
feature maps through several Transformer layers. Each Trans-
former layer consists of multi-head self-attention followed
VI. ABLATIONSTUDYANDDISCUSSION
by a convolutional block, which includes 3D convolutions
This section presents a detailed discussion of the abla-
with kernel sizes designed to maintain spatial dimensions.
tion study concerning the proposed MorpMamba model, both
TheTransformermechanismincludeslayernormalizationand
with and without morphological operations. The MorpMamba
residual connections to ensure stable training and effective
model with morphological operations is called MorpMamba,
feature learning. Regularization techniques are employed to
while the version without morphological operations is termed
prevent overfitting. The feature maps are flattened and passed
SSMamba.
through dense layers with ReLU activation and L2 regular-
ization, followed by a final softmax layer to produce class
probabilities.
A. Comparison of Spatial-Spectral Mamba With and Without
To ensure a fair comparison across all methods in our
Morphology
experiments,weemployedaconsistentsetup.Weusedapatch
size of 4 and selected 15 bands for the analysis. The data was As shown in Table III, MorpMamba exhibited the highest
split with a training ratio of 40%, a validation ratio of 20%, OA of 97.69%, significantly outperforming the SSMamba
and a test ratio of 40%. The models were trained over 50 model,whichachievedanOAof95.67%.Theκcoefficient,a
epochs with a batch size of 256. measureofclassificationreliability,ishighestforMorpMamba
We analyzed the performance of the MorpMamba model at 96.91%, followed by SSMamba at 94.25%, indicating
across various HS datasets, detailed in Section III. For the strongagreementbetweenpredictedandactualclassifications.
Uh dataset, MorpMamba achieves an OA of 98.28%, an Despite variations in performance, both models maintained
AA of 97.91%, and a κ of 98.14. Although the 3D CNN high classification accuracies across most classes.
model shows slightly higher OA (99.01%) and AA (98.81%), Similar observations can be made for the PC and LK
MorpMamba remains competitive with significantly fewer pa- datasets. For the PC dataset, MorpMamba achieved the high-
rameters (67,013 compared to 4,042,751). On the LK dataset, est OA at 99.71%, slightly outperforming SSMamba, which
MorpMamba attains an OA of 99.70%, an AA of 99.25%, achievedanOAof99.48%.TheκcoefficientforMorpMamba
andaκof99.61,closelymatchingthetop-performingmodels is also higher at 99.59%, followed by SSMamba at 99.27%,
like the 3D CNN (OA of 99.81%) while excelling in compu- indicatingstrongagreementbetweenpredictedandactualclas-
tationalefficiencywithsubstantiallyfewerparameters(66,239 sifications. Both models achieved near-perfect classification
compared to 4,041,977). For the PU dataset, MorpMamba accuracy (100%) for several classes in PC, such as Water,
achieves an OA of 97.67%, an AA of 96.93%, and a κ of Meadows, and Soil. Notably, MorpMamba achieved 100%
96.91, maintaining competitive performance and efficiency accuracy in the challenging Bricks class, whereas SSMamba
with a lower parameter count (66,239) compared to the 3D had slightly lower accuracy. Table III also showcases the
CNN model (OA of 98.70%). In the PC dataset, MorpMamba comparative analysis of both models on the LK dataset,
recordsanOAof99.71%,anAAof98.85%,andaκof99.59, revealing exceptional classification accuracy. Both models
comparable to the 3D CNN model (OA of 99.87%) but with achieved 100% accuracy in multiple classes, such as Corn,
fewer parameters (66,239). Lastly, on the SA dataset, Morp- Rice, and Water. Notably, MorpMamba achieved the highest
Mamba achieves an OA of 98.52%, an AA of 99.25%, and a OA at 99.70% and the highest κ at 99.61%, indicating robust
κ of 98.35. Although the 3D CNN remains slightly superior performance. Overall, MorpMamba marginally outperformed
in OA (98.86%), MorpMamba’s performance is noteworthy SSMamba across the datasets.
given its reduced parameter count (67,142). The results presented in Table IV highlight the strong
The MorpMamba model demonstrates superior compu- performance of MorpMamba on the SA dataset. MorpMamba
tational efficiency compared to Transformer-based models, achieved the highest OA at 98.52% and the highest kappa
whichsufferfromquadraticcomplexitywithsequencelength. coefficient at 98.35%, indicating excellent classification re-
Bymaintaininglinearcomplexity,MorpMambaensuresscala- liability. It achieved perfect accuracy (100%) in numerous
bility to larger datasets while providing competitive accuracy. classes, such as Weeds 1, Weeds 2, and Celery. Similarly,
Additionally, the use of morphological operations in Morp- MorpMamba demonstrated its efficacy by achieving a high
Mambaenhancesrobustnessandstability,effectivelyreducing OA of 98.28% and the highest AA at 97.91%. The kappa
noise and highlighting structural features in HS data. This ap- coefficient for MorpMamba was also impressive at 98.14%,
proach mitigates challenges associated with high-dimensional underscoring its strong classification reliability. In contrast,
data, as evidenced by consistent performance across diverse SSMamba recorded the lowest OA at 90.36%.13
TABLE III: Both the models (Spatial-Spectral Mamba with
and without Morphology) are trained using 20% of training
samples with patch size set to 4×4.
PaviaUniversity PaviaCentre WHU-Hi-LongKou
Class
Without With Without With Without With
1 96 98 100 100 100 100
2 98 99 99 98 99 99
3 82 90 97 96 100 100
4 93 97 95 100 99 100
5 100 100 98 100 95 98
6 97 98 99 99 100 100
7 92 96 99 99 100 100 (a) Pavia University
8 88 92 100 100 98 98
9 99 99 100 100 98 99
OA 95.67 97.67 99.48 99.71 99.51 99.70
AA 93.20 96.93 98.60 98.95 98.45 99.25
κ 94.25 96.91 99.27 99.59 99.36 99.61
TABLE IV: Both the models (Spatial-Spectral Mamba with
and without Morphology) are trained using 20% of training
samples with patch size set to 4×4.
Salinas UniversityofHouston
Class
Without With Without With
1 100 100 100 99 (b) Pavia Center
2 100 100 100 99
3 99 100 99 100
4 100 100 98 99
5 99 99 100 100
6 100 100 96 99
7 100 100 96 98
8 89 97 94 98
9 100 100 96 96
10 99 99 99 99
11 100 100 99 97
12 100 100 95 98
13 100 100 86 92
14 99 99 99 99
(c) Salinas
15 82 96 100 100
16 100 98 — —
OA 95.20 98.52 90.36 98.28
AA 97.81 99.25 90.54 97.91
κ 94.65 98.35 89.58 98.14
B. Feature Spaces
t-Distributed Stochastic Neighbor Embedding (t-SNE) is an
effective method for visualizing high-dimensional HSI data
[58].t-SNEoperatesinanunsupervised,non-linearmannerto
(d) University of Houston
preserve pairwise similarities between data points in a lower-
dimensional space, focusing on maintaining small pairwise
distances. It achieves this by first determining similarity mea-
sures between pairs of instances in both higher and lower-
dimensionalspaces[59],[60],thenoptimizingthesemeasures
through gradient descent. t-SNE models the likelihood of one
pointbeinganeighborofanotherinbothhighandlowdimen-
sions.Itcomputespairwisesimilaritiesinthehigh-dimensional
space using a Gaussian kernel, mapping these points onto a
lower-dimensional space while preserving their similarities.
(e) WHU-Hi-LongKou
This is achieved by minimizing the divergence between the
probability distributions of high and low-dimensional spaces. Fig. 13: Learned features representation for Pavia University,
The process results in clusters of similar data points in Pavia Center, Salinas, University of Houston, and WHU-Hi-
the lower-dimensional space, aiding in the visualization and LongKou Datasets.
understandingofhigh-dimensionaldata.Figures13a,13b,13c,
13d, and 13e show the feature representations learned by the
MorpMambamodelforthePU,PC,SA,UH,andLKdatasets,14
respectively, highlighting its effectiveness in feature learning REFERENCES
for classification.
[1] M.Ahmad,S.Shabbir,S.K.Roy,D.Hong,X.Wu,J.Yao,A.M.Khan,
M.Mazzara,S.Distefano,andJ.Chanussot,“Hyperspectralimageclas-
sification—traditional to deep models: A survey for future prospects,”
IEEE Journal of Selected Topics in Applied Earth Observations and
VII. CONCLUSIONSANDFUTURERESEARCHDIRECTIONS RemoteSensing,2021.
[2] D. Hong, C. Li, B. Zhang, N. Yokoya, J. A. Benediktsson, and
J. Chanussot, “Multimodal artificial intelligence foundation models:
MorpMamba introduces a novel approach to HSIC by Unleashingthepowerofremotesensingbigdatainearthobservation,”
integrating spatial-spectral morphological operations with the TheInnovationGeoscience,vol.2,no.1,p.100055,2024.
[3] Y. Li, D. Hong, C. Li, J. Yao, and J. Chanussote, “Hd-net: High-
Mamba architecture. The model has demonstrated SOTA
resolutiondecouplednetworkforbuildingfootprintextractionviadeeply
performance across multiple publicly available HS datasets, supervisedbodyandboundarydecomposition,”ISPRSJournalofPho-
achieving superior results in terms of overall accuracy, aver- togrammetryandRemoteSensing,vol.209,pp.51–65,2024.
age accuracy, and Kappa (κ) coefficient. Additionally, Morp- [4] B. Lu, P. D. Dao, J. Liu, Y. He, and J. Shang, “Recent advances
of hyperspectral imaging technology and applications in agriculture,”
Mamba shows remarkable computational efficiency, utilizing
RemoteSensing,vol.12,no.16,p.2659,2020.
significantlyfewerparameterswhilemaintainingorsurpassing [5] T. Ada˜o, J. Hrusˇka, L. Pa´dua, J. Bessa, E. Peres, R. Morais, and
the classification accuracy of other SOTA models. The inte- J. J. Sousa, “Hyperspectral imaging: A review on uav-based sensors,
data processing and applications for agriculture and forestry,” Remote
gration of morphological operations (erosion and dilation) in
sensing,vol.9,no.11,p.1110,2017.
thetokenizationprocessenablesthemodeltocapturebothfine [6] C.Li,B.Zhang,D.Hong,J.Yao,andJ.Chanussot,“Lrr-net:Aninter-
detailsandglobalstructuresinspatialandspectraldimensions. pretable deep unfolding network for hyperspectral anomaly detection,”
IEEETransactionsonGeoscienceandRemoteSensing,2023.
Moreover,thetokenenhancementmoduledynamicallyadjusts
[7] E. Bedini, “The use of hyperspectral remote sensing for mineral ex-
theimportanceofspatialandspectralfeatures,leadingtomore ploration:Areview,”JournalofHyperspectralRemoteSensing,vol.7,
robust and context-aware feature representation. The multi- no.4,pp.189–211,2017.
[8] C. Weber, R. Aguejdad, X. Briottet, J. Avala, S. Fabre, J. Demuynck,
head self-attention mechanism effectively captures complex
E.Zenou,Y.Deville,M.S.Karoui,F.Z.Benhaloucheetal.,“Hyper-
relationships and dependencies within the HS data. spectral imagery for environmental urban planning,” in IGARSS 2018-
2018 IEEE International Geoscience and Remote Sensing Symposium.
Further optimization is needed to robustly handle high-
IEEE,2018,pp.1628–1631.
dimensional HS data, focusing on more efficient data pro-
[9] M.B.Stuart,A.J.McGonigle,andJ.R.Willmott,“Hyperspectralimag-
cessing techniques tailored for HS imagery. To enhance the inginenvironmentalmonitoring:Areviewofrecentdevelopmentsand
model’sabilitytogeneralizeacrossdiversedatasets,strategies technological advances in compact field deployable systems,” Sensors,
vol.19,no.14,p.3071,2019.
such as transfer learning, domain adaptation, or meta-learning
[10] C. B. Pande and K. N. Moharir, “Application of hyperspectral remote
should be explored. Integrating advanced feature extraction sensingroleinprecisionfarmingandsustainableagricultureundercli-
techniques, like graph neural networks or novel attention- matechange:Areview,”ClimateChangeImpactsonNaturalResources,
EcosystemsandAgriculturalSystems,pp.503–520,2023.
based mechanisms, could improve the model’s ability to
[11] M. H. F. Butt, H. Ayaz, M. Ahmad, J. P. Li, and R. Kuleev, “A fast
capturecomplexspatial-spectralrelationships.Comprehensive and compact hybrid cnn for hyperspectral imaging-based bloodstain
evaluations on larger and more diverse HS datasets are nec- classification,” in 2022 IEEE Congress on Evolutionary Computation
(CEC). IEEE,2022,pp.1–8.
essary to validate the model’s performance and identify areas
[12] M. Zulfiqar, M. Ahmad, A. Sohaib, M. Mazzara, and S. Distefano,
for improvement, including testing on datasets from various “Hyperspectralimagingforbloodstainidentification,”Sensors,vol.21,
geographical regions, sensor types, and challenging environ- no.9,p.3045,2021.
[13] M.H.Khan,Z.Saleem,M.Ahmad,A.Sohaib,H.Ayaz,M.Mazzara,
mental conditions. Developing hardware-aware optimizations
andR.A.Raza,“Hyperspectralimaging-basedunsupervisedadulterated
and deployment strategies for MorpMamba could enable its red chili content transformation for classification: Identification of red
use on resource-constrained devices, allowing for on-board chiliadulterants,”NeuralComputingandApplications,vol.33,no.21,
pp.14507–14521,2021.
processing in satellite or drone-based systems. Enhancing the
[14] M.H.Khan,Z.Saleem,M.Ahmad,A.Sohaib,H.Ayaz,andM.Maz-
interpretability of the model’s decisions by visualizing the zara, “Hyperspectral imaging for color adulteration detection in red
importanceof different spectral bands orspatial regionscould chili,”AppliedSciences,vol.10,no.17,p.5955,2020.
[15] Z.Saleem,M.H.Khan,M.Ahmad,A.Sohaib,H.Ayaz,andM.Maz-
providevaluableinsightsfordomainexpertsandincreasetrust
zara,“Predictionofmicrobialspoilageandshelf-lifeofbakeryproducts
inthemodel’soutputs.ExploringthepotentialofMorpMamba through hyperspectral imaging,” IEEE Access, vol. 8, pp. 176986–
for multi-task learning scenarios, such as simultaneous classi- 176996,2020.
fication and segmentation of HS images, could maximize the [16] H. Ayaz, M. Ahmad, M. Mazzara, and A. Sohaib, “Hyperspectral
imaging for minced meat classification using nonlinear deep features,”
utility of the extracted features. Investigating the application
AppliedSciences,vol.10,no.21,p.7783,2020.
of MorpMamba to multi-temporal HS data could leverage its [17] H. Ayaz, M. Ahmad, A. Sohaib, M. N. Yasir, M. A. Zaidan, M. Ali,
ability to model the temporal evolution of features for change M.H.Khan,andZ.Saleem,“Myoglobin-basedclassificationofminced
meatusinghyperspectralimaging,”AppliedSciences,vol.10,no.19,p.
detection or time-series analysis of land cover changes. Addi-
6862,2020.
tionally, integrating MorpMamba with other remote sensing [18] D. Hong, B. Zhang, X. Li, Y. Li, C. Li, J. Yao, N. Yokoya, H. Li,
data sources, such as LiDAR or SAR, could create more P. Ghamisi, X. Jia, A. Plaza, P. Gamba, J. A. Benediktsson, and
J.Chanussot,“Spectralgpt:Spectralremotesensingfoundationmodel,”
comprehensive and accurate Earth observation models. By
IEEETransactionsonPatternAnalysisandMachineIntelligence,2024,
addressingthesefuturedirections,theresearchcommunitycan dOI:10.1109/TPAMI.2024.3362475.
build upon the foundations laid by MorpMamba to further [19] M. Ahmad, A. M. Khan, M. Mazzara, S. Distefano, M. Ali, and
M. S. Sarfraz, “A fast and compact 3-d cnn for hyperspectral image
advance HSI analysis and its applications in remote sensing
classification,” IEEE Geoscience and Remote Sensing Letters, vol. 19,
and Earth observation. pp.1–5,2022.15
[20] U. Ghous, M. S. Sarfraz, M. Ahmad, C. Li, and D. Hong, “(2+1)d [40] K. Ayonrinde. (2024) Mamba explained. [Online]. Available: https:
extreme xception net for hyperspectral image classification,” IEEE //thegradient.pub/mamba-explained/
Journal of Selected Topics in Applied Earth Observations and Remote [41] J. Yao, D. Hong, C. Li, and J. Chanussot, “Spectralmamba:
Sensing,pp.1–14,2024. Efficientmambaforhyperspectralimageclassification,”2024.[Online].
[21] D. Hong, J. Yao, C. Li, D. Meng, N. Yokoya, and J. Chanussot, Available:https://arxiv.org/abs/2404.08489
“Decoupled-and-couplednetworks:Self-supervisedhyperspectralimage [42] L.Huang,Y.Chen,andX.He,“Spectral-spatialmambaforhyperspec-
super-resolution with subpixel fusion,” IEEE Transactions on Geo- tralimageclassification,”arXivpreprintarXiv:2404.18401,2024.
scienceandRemoteSensing,2023. [43] G. Wang, X. Zhang, Z. Peng, T. Zhang, X. Jia, and L. Jiao, “S 2
[22] A. Jamali, S. K. Roy, D. Hong, P. M. Atkinson, and P. Ghamisi, mamba: A spatial-spectral state space model for hyperspectral image
“Attentiongraphconvolutionalnetworkfordisjointhyperspectralimage classification,”arXivpreprintarXiv:2404.18213,2024.
classification,”IEEEGeoscienceandRemoteSensingLetters,pp.1–1, [44] Y. He, B. Tu, B. Liu, J. Li, and A. Plaza, “3dss-mamba: 3d-spectral-
2024. spatial mamba for hyperspectral image classification,” arXiv preprint
[23] M.AhmadandM.Mazzara,“Scsnet:Sharpenedcosinesimilarity-based arXiv:2405.12487,2024.
neuralnetworkforhyperspectralimageclassification,”IEEEGeoscience [45] J. Sheng, J. Zhou, J. Wang, P. Ye, and J. Fan, “Dualmamba: A
andRemoteSensingLetters,vol.21,pp.1–4,2024. lightweightspectral-spatialmamba-convolutionnetworkforhyperspec-
[24] J. Yao, X. Cao, D. Hong, X. Wu, D. Meng, J. Chanussot, and Z. Xu, tralimageclassification,”arXivpreprintarXiv:2406.07050,2024.
“Semi-active convolutional neural networks for hyperspectral image [46] W. Zhou, S.-I. Kamata, H. Wang, M.-S. Wong et al., “Mamba-in-
classification,”IEEETransactionsonGeoscienceandRemoteSensing, mamba: Centralized mamba-cross-scan in tokenized mamba model for
vol.60,pp.1–15,2022. hyperspectral image classification,” arXiv preprint arXiv:2405.12003,
[25] M. Ahmad, S. Distifano, M. Mazzara, and A. M. Khan, “Traditional 2024.
to transformers: A survey on current trends and future prospects for [47] A.Yang,M.Li,Y.Ding,L.Fang,Y.Cai,andY.He,“Graphmamba:An
hyperspectral image classification,” arXiv preprint arXiv:2404.14955, efficientgraphstructurelearningvisionmambaforhyperspectralimage
2024. classification,”arXivpreprintarXiv:2407.08255,2024.
[26] G.Jaiswal,A.Sharma,andS.K.Yadav,“Criticalinsightsintomodern [48] S. K. Roy, A. Deria, C. Shah, J. M. Haut, Q. Du, and A. Plaza,
hyperspectral image applications through deep learning,” Wiley Inter- “Spectral–spatialmorphologicalattentiontransformerforhyperspectral
disciplinaryReviews:DataMiningandKnowledgeDiscovery,vol.11, image classification,” IEEE Transactions on Geoscience and Remote
no.6,p.e1426,2021.
Sensing,vol.61,pp.1–15,2023.
[49] L.Huang,Y.Chen,andX.He,“Spectral-spatialmambaforhyperspec-
[27] M. Ahmad, M. Usama, A. M. Khan, S. Distefano, H. A. Altuwaijri,
tralimageclassification,”RemoteSensing,vol.16,no.13,2024.
andM.Mazzara,“Spatialspectraltransformerwithconditionalposition
[50] X.Yang,Y.Ye,X.Li,R.Y.Lau,X.Zhang,andX.Huang,“Hyperspec-
encodingforhyperspectralimageclassification,”IEEEGeoscienceand
tralimageclassificationwithdeeplearningmodels,”IEEETransactions
RemoteSensingLetters,pp.1–1,2024.
onGeoscienceandRemoteSensing,vol.56,no.9,pp.5408–5423,2018.
[28] J.Yao,B.Zhang,C.Li,D.Hong,andJ.Chanussot,“Extendedvision
[51] M. Ahmad, A. M. Khan, M. Mazzara, S. Distefano, S. K. Roy, and
transformer (exvit) for land use and land cover classification: A mul-
X.Wu,“Hybriddensenetworkwithattentionmechanismforhyperspec-
timodal deep learning framework,” IEEE Transactions on Geoscience
tral image classification,” IEEE Journal of Selected Topics in Applied
andRemoteSensing,2023.
EarthObservationsandRemoteSensing,vol.15,pp.3948–3957,2022.
[29] M.Ahmad,U.Ghous,M.Usama,andM.Mazzara,“Waveformer:Spec-
[52] Z. Xiong, Y. Yuan, and Q. Wang, “Ai-net: Attention inception neural
tral–spatialwavelettransformerforhyperspectralimageclassification,”
networksforhyperspectralimageclassification,”inIGARSS2018-2018
IEEEGeoscienceandRemoteSensingLetters,vol.21,pp.1–5,2024.
IEEEInternationalGeoscienceandRemoteSensingSymposium. IEEE,
[30] X. Huang, M. Dong, J. Li, and X. Guo, “A 3-d-swin transformer-
2018,pp.2647–2650.
basedhierarchicalcontrastivelearningmethodforhyperspectralimage
[53] X. Zhang, “Improved three-dimensional inception networks for hyper-
classification,”IEEETransactionsonGeoscienceandRemoteSensing,
spectralremotesensingimageclassification,”IEEEAccess,vol.11,pp.
vol.60,pp.1–15,2022.
32648–32658,2023.
[31] Y.Wang,Y.Gu,andA.Nanding,“Sstu:Swin-spectraltransformeru-net
[54] T. Shwetha, S. A. Thomas, V. Kamath et al., “Hybrid xception model
for hyperspectral whole slide image reconstruction,” Computerized
forhumanproteinatlasimageclassification,”in2019IEEE16thIndia
Medical Imaging and Graphics, vol. 114, p. 102367, 2024.
CouncilInternationalConference(INDICON). IEEE,2019,pp.1–4.
[Online]. Available: https://www.sciencedirect.com/science/article/pii/ [55] H. Fırat, M. E. Asker, M. ˙I. Bayındır, and D. Hanbay, “Hybrid 3d/2d
S0895611124000442
completeinceptionmoduleandconvolutionalneuralnetworkforhyper-
[32] Y. Long, X. Wang, M. Xu, S. Zhang, S. Jiang, and S. Jia, “Dual self-
spectralremotesensingimageclassification,”NeuralProcessingLetters,
attention swin transformer for hyperspectral image super-resolution,”
vol.55,no.2,pp.1087–1130,2023.
IEEE Transactions on Geoscience and Remote Sensing, vol. 61, pp.
[56] J. Z. Tahir Arshad and I. Ullah, “A hybrid convolution transformer
1–12,2023.
for hyperspectral image classification,” European Journal of Remote
[33] L.Wang,Z.Zheng,N.Kumar,C.Wang,F.Guo,andP.Zhang,“Mul- Sensing,vol.0,no.0,p.2330979,2024.
tilevel class token transformer with cross tokenmixer for hyperspectral [57] M. Ahmad, M. H. F. Butt, M. Mazzara, and S. Distifano, “Pyramid
images classification,” IEEE Transactions on Geoscience and Remote hierarchicaltransformerforhyperspectralimageclassification,”2024.
Sensing,vol.62,pp.1–13,2024.
[58] B.Li,L.Fang,N.Chen,J.Kang,andJ.Yue,“Enhancinghyperspectral
[34] J. Li, Z. Zhang, R. Song, Y. Li, and Q. Du, “Scformer: Spectral imageclassification:Leveragingunsupervisedinformationwithguided
coordinate transformer for cross-domain few-shot hyperspectral image group contrastive learning,” IEEE Transactions on Geoscience and
classification,” IEEE Transactions on Image Processing, vol. 33, pp. RemoteSensing,vol.62,pp.1–17,2024.
840–855,2024. [59] Y. Lu, S. Mei, F. Xu, M. Ma, and X. Wang, “Separable deep graph
[35] Z. Shu, Y. Wang, and Z. Yu, “Dual attention transformer network convolutional network integrated with cnn and prototype learning for
for hyperspectral image classification,” Engineering Applications of hyperspectral image classification,” IEEE Transactions on Geoscience
ArtificialIntelligence,vol.127,p.107351,2024. andRemoteSensing,vol.62,pp.1–16,2024.
[36] S.Li,L.Liang,S.Zhang,Y.Zhang,A.Plaza,andX.Wang,“End-to- [60] N. A. A. Braham, J. Mairal, J. Chanussot, L. Mou, and X. X. Zhu,
endconvolutionalnetworkandspectral-spatialtransformerarchitecture “Enhancingcontrastivelearningwithpositivepairminingforfew-shot
forhyperspectralimageclassification,”RemoteSensing,vol.16,no.2, hyperspectralimageclassification,”IEEEJournalofSelectedTopicsin
2024. Applied Earth Observations and Remote Sensing, vol. 17, pp. 8509–
[37] J.Ma,Y.Zou,X.Tang,X.Zhang,F.Liu,andL.Jiao,“Spatialpooling 8526,2024.
transformernetworkandnoise-tolerantlearningfornoisyhyperspectral
image classification,” IEEE Transactions on Geoscience and Remote
Sensing,2024.
[38] X. Wang, L. Sun, C. Lu, and B. Li, “A novel transformer network
with a cnn-enhanced cross-attention mechanism for hyperspectral
image classification,” Remote Sensing, vol. 16, no. 7, 2024. [Online].
Available:https://www.mdpi.com/2072-4292/16/7/1180
[39] A. Gu and T. Dao, “Mamba: Linear-time sequence modeling with
selectivestatespaces,”arXivpreprintarXiv:2312.00752,2023.