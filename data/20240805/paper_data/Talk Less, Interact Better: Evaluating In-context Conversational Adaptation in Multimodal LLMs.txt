PublishedasaconferencepaperatCOLM2024
Talk Less, Interact Better: Evaluating In-context
Conversational Adaptation in Multimodal LLMs
YilunHuaandYoavArtzi
DepartmentofComputerScienceandCornellTech
CornellUniversity
{yilunhua, yoav}@cs.cornell.edu
Abstract
Humansspontaneouslyuseincreasinglyefficientlanguageasinteractions
progress,byadaptingandformingad-hocconventions. Thisphenomenon
hasbeenstudiedextensivelyusingreferencegames,showingpropertiesof
humanlanguagethatgobeyondrelayingintents. Itremainsunexplored
whethermultimodallargelanguagemodels(MLLMs)similarlyincrease
communicationefficiencyduringinteractions,andwhatmechanismsthey
mayadoptforthispurpose. WeintroduceICCA,anautomatedframework
to evaluate such conversational adaptation as an in-context behavior in
MLLMs. We evaluate several state-of-the-art MLLMs, and observe that
while they may understand the increasingly efficient language of their
interlocutor, they do not spontaneously make their own language more
efficientovertime. Thislatterabilitycanonlybeelicitedinsomemodels
(e.g.,GPT-4)withheavy-handedprompting. Thisshowsthatthisproperty
oflinguisticinteractiondoesnotarisefromcurrenttrainingregimes,even
thoughitisacommonhallmarkofhumanlanguage.
1 Introduction
Human interlocutors adapt to each other during interactions, developing increasingly
efficientwaystorefertoconceptsandobjects. Hawkinsetal.(2020b)exemplifythisvia
communicationbetweenanurseandabed-riddenpatientathome. Initially,thepatient
mayrefertoamedicinewiththemedicineformybackpaininasmallbluemedicinebottle...,but
afteraweekofcare,theyarelikelytojustaskfortheirbackmeds. Thisincreaseinefficiency
reliesontheinterlocutorsformingad-hoclinguisticconventions: themutuallyunderstood,
concisephrasestocommunicatereferentialcontent. Thisphenomenonhasbeenrepeatedly
observedandcharacterizedincontrolledstudiesusingrepeatedreferencegames(Figure1;
e.g.,Krauss&Weinheimer,1964;Brennan&Clark,1996;Hawkinsetal.,2020a).
Westudythisabilityinmultimodallargelanguagemodels(MLLMs).LLMsandMLLMsare
wellpositionedtoacquirethisbehavioranddisplayitspontaneouslyininteractions. They
aretrainedonlargeamountsofhumanlanguagedata,inwhichthisbehavioriscommon
andthehistoryofanongoinginteractionisoftenretained,therebyexplicitlykeepingthe
informationneededathand. Beyondthescientificquestion,suchad-hocadaptationhas
significant application impacts: enabling more natural interactions, reducing the costs
involvedinconversations(e.g.,usingshorterutterancestocommunicatethesameamount
ofinformation),andincreasingtheaccuracyofrelayingintent.
WeproposeICCA,1 anautomatedframeworktoevaluateandcharacterizetheabilityof
modelstoformad-hocconventions. ICCAusesacorpusofhuman-humanreferencegame
interactions,allowingforcompletelyautomatedevaluation,whichdoesnotrequirefurther
humaninteraction,makingiteasytodeployfortheanalysisofnewmodels. Theinteraction
followsthestandardrepeatedreferencegamesetup(Clark&Wilkes-Gibbs,1986),where
aspeakerreferstoanimagewithinasharedcontextofimages,andalistenerresolvesthe
1ICCAstandsforIn-contextConversationalAdaptation.
1
4202
guA
2
]LC.sc[
1v71410.8042:viXraPublishedasaconferencepaperatCOLM2024
Context Repetition 1 Repetition 6
Photo with a bowl of 3
black
bananas with pokadot
Image B Image A
A B
A bowl full of mixed fruit,
pokadot
black background
C D
Image A Image B
Figure1: Illustrationofareferencegame. Thespeaker(blue)andlistener(orange)observea
sharedsetofimages.2Theinteractionprogressesinsixrepetitions,eachincludesatrialfor
everycontextimage. Ineachtrial,thespeakerdescribesatargetimage,andthelistenerhas
toselectthecorrecttargetgiventhedescriptiononly. Forsimplicity,thisfigureomitsthe
feedbackonlisteneractions. Thisinteractionillustratessomeoftheeffectsofconvention
formation: thedescriptionsbecomeshorterastheinteractionprogresses,andlexicalchoices
convergetoasubsetofthewordsusedinearlierrepetitions.
referencetoselectoneoftheimages,ideallytheoneoriginallyreferredto.Figure1illustrates
thescenario. Wefocusonin-contextadaptation–astheinteractionprogresses,theentire
historyisretainedin-context. Coretoourapproachiscomparingthechangesinmodel
behavior,eitherasspeakerorlistener,throughoutaninteractiontothechangesobserved
in humans. We measure different properties that have been shown to be influenced by
conventionformation: utterancelength,lexicalconvergence,andselectionaccuracy.
WeapplyourapproachtofiverepresentativeMLLMs:IDEFICS(Huggingface,2023),LLaVa-
1.5(Liuetal.,2023a),GPT4-vision(OpenAIetal.,2024),Gemini1.0ProVision(Google,2023),
andClaude3opus(Anthropic,2024). Wefindthatallmodelsstruggletospontaneously
introduceconventionsandadaptasspeakers. Promptengineeringanexplicitin-context
instructionspecifictothereferencegamescenariocanaddressthistosomedegree. The
strongestmodels(GPT4, Gemini, andClaude)canthengraduallyuseshortermessages
(gaininglexicalefficiency)butstillstrugglewithconvergenceorstability,whichhinders
theemergenceoftrulyefficientcommunication. Whenactingasalistener,GPT4displays
adaptationtrendsclosetohumans,improvingitsaccuracyastheinteractionprogresses,
whileothermodelsshowthisbehaviortoalesserdegreeoronlyundersomesimplified
setups. Overall,weshowthatwhiletoday’sMLLMsmaypassivelyunderstandtheevolv-
ing language of their interlocutor, the ability to adapt their own language for efficient
communicationdoesnotnaturallyemergefromtheirtrainingorinstruction-tuning. This
outlinesimportantfutureresearchproblems. WereleaseICCAundertheMITlicenseat
https://github.com/lil-lab/ICCA.
2 BackgroundandRelatedWork
RepeatedReferenceGames Areferencegameisaninteractionwhereaspeakeranda
listener(i.e.,adyad)interactoverasharedcontext. Thesharedcontextisasetofimages.
Thespeakerdescribesatargetimage. Thetargetdesignationisonlyrevealedtothespeaker.
Thelistenerhastoselectanimagefollowingthespeaker’sdescription. Eachparticipant
seestheimagesinadifferentorder,sotheycannotusepositioninformationtocommunicate
thereferent. Referencegameshavebeenusedextensivelyinthestudyofcomputational
models,includingrecentlytoevaluatevisualabstraction(Jietal.,2022)andconversational
aptitude(Chalamalasettietal.,2023).
A repeated reference game (Figure 1) includes multiple repetitions. Each repetition has
onetrialforeachimageinthesharedcontext. Thelistenerreceivesfeedbackafterevery
2InFigure1,weshowthesharedcontextonlyonceforcompactness.Inourexperiments,weshuffle
andshowthecontextforeachtrial,butalsoexperimentwithshowingitonlyonce.
2PublishedasaconferencepaperatCOLM2024
trial, which indicates the correct selection. The repetition and feedback allow the dyad
toformmessageagreementsovertherepeatingstimuli(i.e.,thespeakerwouldnaturally
usegraduallyshorterbutrelatedmessagesacrossrepetitions,andthelistenerlearnswhat
they refer to). ICCA’s repeated reference games are developed based on the setup and
datafromHawkinsetal.(2020b). Thesharedcontextincludesfourimages,andthereare
sixrepetitions,givingatotalof24trials. Theorderofimagesisshuffledacrossthetrials.
Werefertothisasthestandardsetup. Hawkinsetal.(2020b)onlyusesthisstandardsetup.
Beyondthisstandardsetup,wedesignvariantstofurtherdisentanglethetypesandcauses
ofmodelfailuresforin-contextLLMadaptation(Section4andSection5).
Ad-hocAdaptationinInteractions Existingliteratureshowsthathumansareinclined
toreducetheeffortneededtoconveytheirintendedinformationandfortheiraudience
tocomprehendit,leadingtoefficientcommunication(e.g.,Zipf,1949;Gibsonetal.,2019;
Yinetal.,2024). Whenhumanindividualsinteractthroughdialogue,thisismanifestedby
developingandusingad-hoclinguisticconventions. Thisphenomenonhasbeenobserved
withrepeatedreferencegames(Krauss&Weinheimer,1964;1966;Clark&Wilkes-Gibbs,
1986;Hawkinsetal.,2020a),andrelatedinteractionscenarios(Haberetal.,2019). Studies
havealsoshownvariouspropertiesoftheseconventions,suchasarbitrariness,stability,
stickiness,andconvergence(Lewis,1969;Brennan&Clark,1996;Markman&Makin,1998;
Hawkinsetal.,2020a;Eliavetal.,2023). Thisadaptationwasmodeledwiththepragmatic
rational speech act model (RSA; Goodman & Frank, 2016), leading to development of
modelsthatreplicatethisbehaviorinreferencegames(e.g.,Monroeetal.,2017;McDowell
&Goodman,2019;Whiteetal.,2020)anduseittoimprovemodelperformanceonother
tasks (e.g., Andreas & Klein, 2016; Fried et al., 2018). Adaptation was studied beyond
referencegames,showinghowthecomplexityofthescenarioinfluenceshowconventions
manifestinthelanguage(Effenbergeretal.,2021).
Ad-hocconventionsareaparticularinstantiationofthebroaderphenomenonofcommon
ground,whichisdefinedasthemutuallyrecognizedsharedinformationbetweenthepar-
ticipantsofaconversation(Clark&Brennan,1991;Lewis,1969;Stalnaker,2002). Common
ground has been studied extensively, with focus on both human cognition (Clark, 1996;
Horton&Gerrig,2016)andmachinereasoning(Cohen&Levesque;Grosz&Sidner;Traum,
1994;DelTredicietal.,2022;Shaikhetal.,2024;Andukurietal.,2024;Testoni&Ferna´ndez,
2024).
ModelAdaptation Adaptingmodelsduringaninteractiontoimprovecommunication
efficiencyorsuccessisrelativelyunderstudied. Hawkinsetal.(2020b)proposesacontinual
learningmethodforCNN-RNNmodelstogaincommunicationefficiencyinrepeatedrefer-
encegamesthroughcontinualweightupdates. Zhuetal.(2021)proposesexplicitlytraining
modelsforad-hocadaptationthroughmeta-learning.Wefocusonthein-contextcapabilities
ofLLMsandMLLMs,whichofferanupdate-freerouteforadaptationthatisparticularly
compellinggiventhecostsofupdatinglargemodels. Ouruseofin-contextlearningdiffers
fromhowthismechanismisusuallyusedeitherbyprovidinginstructions(Ouyangetal.,
2022) or few-shot examples (Brown et al., 2020). While reference games can be seen as
relatedtothefew-shotapproach,ad-hocadaptationisnotaboutreplicatingpatterns,but
showingchangeandadaptationovertime.
3 TheICCAFramework
ICCAusesadatasetofhuman-humaninteractions,andallowstoeasilycustomizedifferent
partsoftheinteraction. Thisflexibilityenablesdifferentresearchquestions. Forexample,
inSection5, wecustomizetheinteractionstructuretoanalyzehowwellmodelshandle
longinteractionswithmultipleimagesinterleavedinthem. ICCAsupportsstudieswiththe
modelactingeitherasspeakerorlistener,andincludesseveralmetricstotrackdifferent
propertiesofadaptationduringtheinteraction.
ICCA is fully automated and easily applicable to new MLLMs. Our design does not
requirecollectingnewdataorhumanstudies, butinsteadusesHawkinsetal.(2020b)’s
human-human interaction data to simulate a human interacting with an MLLM. Each
3PublishedasaconferencepaperatCOLM2024
interaction in the dataset was collected under the standard setup (Section 2) and uses a
visually challenging reference context, consisting of four similar images (Figure 1). The
datasetcontains54human-humaninteractions,whichweincorporateintoICCA.
ArepeatedreferencegameinteractionRisasequenceoftuples⟨(C,c,s,l, f )⟩n ,where
i i i i i i=1
C isthesetofimagesformingthereferencecontext,c istheindexofthetargetimage,s is
i i i
thespeakerutterance,l isthelistenerselection,and f isthefeedbackbasedonthelistener’s
i i
selection. Ateverytrialt,withtheevaluatedmodelaseitherthelistenerorspeaker,ICCA
constructs the MLLM prompt from an instruction text I, the history (i.e., all prior trials
R[: t]),andthestimuliforthecurrenttrialwithauser-definedpre-processingfunctionF.
Uponreceivingthemodel’sresponse,ICCAcomputesthefeedback f tohelpthenexttrial.
t
ThefunctionFpreparesthepromptdependingontheexperiment,andiskeytotheflexibility
ofICCA.Forexample, whenevaluatingamodelasalistenerunderthestandardsetup,
thefunctioninputwouldbeF(I,R[: t],C ,s ),anditwouldformatandconcatenateallthe
t t
elementsinorder. Figure7intheappendixshowsanexampleprompt. ICCAallowsto
easilymodifythisstandardsetup,forexamplebyprocessingthedatasuchthatFdropsall
referencecontextsexceptC ,therebycreatingasimplerinputwheretheimagesappearonly
1
onceatthebeginningoftheinteraction.
ICCAsimulatestheinterlocutorofthemodelevaluatedeitherwithadeterministiccounter-
partorbyhavinganothermodeltaketherole.Adeterministicspeakeroutputsthemessages
fromrecordedhumaninteractionsdataset,showingpredetermined,realistictrajectoriesof
messageshorteningovertime,butitdoesnotadaptitslanguagebasedonthelistener’s
selections. Itcanbeconsideredasa“conventioncomprehension”task,potentiallymore
challenging due to the non-adapting speaker messages. We use this simulated speaker
forourmodel-as-listenerexperiments(Section5)becauseitexposesthemodellistenerto
behaviorsandlinguisticconventionsnaturallyoccurringinhumaninteractions. Inversely,
forourspeakerexperiments(Section4),weuseahigh-performancemodellistener(GPT4),
whichweobservetohaveperformancesimilartohumanlisteners(Section5).
Weevaluatemodelbehaviorwithadaptationsofthemetricsusedinhumanstudieswith
referencegames(Hawkinsetal.,2020a;b). Forlistenerexperiments,wefollowHawkins
etal.(2020b)andreporttheaverageaccuracyineachrepetition. Speakerexperimentsare
evaluatedusingseveralmetrics. Wereporttheaveragemessagelengthandthelistener’s
accuracyineachrepetition. Additionally,weevaluatethesimilaritybetweencorresponding
messagesfromconsecutiverepetitions. WhilethiswasdoneusingGloVeembeddings(Pen-
ningtonetal.,2014)inpastwork(Hawkinsetal.,2020a),wedesignanewmetriccalled
WordNoveltyRate(WNR),whichissensitivetoexactwordchoices. WNRisamodified
worderrorratethatonlycountsinsertionsandsubstitutions,andignoresdeletions. Itis
motivated by how people naturally drop words from their messages as the interaction
progresses (Hawkins et al., 2020a), whereas additions and substitutions of words often
reflectimportantchangesininformationbasedonourobservations. ComparedtoGloVe,
WNRismoresensitivetolexicalinconsistenciesthatcanincreasethelistener’scognitive
load. AppendixApresentsmoredetailsofourmetrics,includingacomparisonofWNR
andembedding-basedsimilaritymetricsandavariantofWNRthatisnotnormalizedby
messagelength(referredtoasWordNoveltyDistance).
4 Model-as-speakerExperiments
Westudymodelbehaviorasspeakerwithfivestate-of-the-artvisionMLLMs: IDEFICS-
80b-instruct,3 LLaVa-1.5-13b, GPT4-vision, Gemini 1.0 Pro Vision, and Claude 3 opus.
Throughoutallspeakerexperiments,wecustomizethedatatoonlyshowthereferential
contextonceatthebeginningoftheinteraction,sothereisnoshufflingofcontextthrough-
out the interaction. We engineer prompts for each model individually to best evaluate
its capability. We use GPT4 as the listener. It exhibits high performance in our listener
experiments(Section5),especiallywhenthecontextappearsonlyonceatthebeginning,
3IDEFICSisanopen-sourcereproductionofFlamingo(Alayracetal.,2022).
4PublishedasaconferencepaperatCOLM2024
IDEFICS LLaVa GPT4 Gemini Claude Human(StandardSetup)
S4: ExplicitInstruc-
S1: StandardSpeaker S2: GriceanInstruction S3: ExplicitInstruction tion+ConsistencyRequest
100
80
60
40
20
20
15
10
5
1.0
0.8
0.6
0.4
0.2
0
1 2 3 4 5 6 1 2 3 4 5 6 1 2 3 4 5 6 1 2 3 4 5 6
Repetition#
Figure2: Speakerexperiments. Marginsoferrorsarebootstrapped95%CIs.
so it is a suitable substitute for a human listener in this study. Appendix A.3 provides
implementationdetails.
WedesignfourspeakervariantsbymodifyingtheinstructionI.Thevariantsweredeveloped
throughoutourexperiments,byobservingthedifficultyofmodelstopresentpatternssimilar
tohumanlinguisticbehavior. Thevariantsinstructthemodeltodisplaytheconvention
formationbehaviorobservedinhumanspeakersinincreasinglyexplicitandspecificways:
S1: StandardSpeaker Thestandardspeakersetup(Section2).Themodelspeakeronly
receivesthebasicgameinstruction,withnomentionofcommunicationefficiency.
Figure6intheappendixshowsanexampleprompt.
S2: GriceanInstruction Arelativelylight-handedandgeneralwaytointroducethe
expectedconventionformationbehavioristoexplicitlyinstructthemodeltofollow
theGriceanquantitymaxim. Thiskindofinstructionisnotspecifictoreference
games,anddoesnotexplicitlymentionmessagelength. Itsfocusisinformation,
and it entails that cooperative interlocutors would provide enough information
toidentifythereferentbutwouldnotmakethemessagemoreinformativethan
necessary. Weaddadditionalinstructionsbasedonthemaximandfurtherinstruct
themodeltothinkabouthowtheamountofinformationneededmaychangeasmoretrials
arecompletedandbasedonthelistener’sperformanceinprevioustrials.4,5
S3: ExplicitInstruction Weinstructthemodeltoexplicitlyreducemessagelengthas
theinteractionprogresses. UnlikeS1andS2,thisinstructionisspecifictoreference
games,aslanguageadaptationinotherscenariosisnotnecessarilyaccompaniedby
lengthreduction(Effenbergeretal.,2021). WeaddtoS1anexplicitinstructionto
4Themodelsdidnotshowsubstantialimprovementwithoutthisadditionalinstruction.
5Nottheexactpromptusedforexperiments;shortenedandrevisedforillustrativepurposes.
5
%ccA
)snekot(nelgsM
RNWPublishedasaconferencepaperatCOLM2024
reduceutterancelength: asmoretrialsarecompletedandasthelistenerunderstandsyou
better,graduallycondenseyourmessages,makingthemshorterandshortereverytrial.5
S4: ExplicitInstruction+ConsistencyRequest Conventionformationinreference
gamesisnotonlycharacterizedbyreductioninutterancelength,butalsobylexical
consistency.Thisvariantexplicitlyinstructsthemodeltofollowthispattern.Similar
toS3,itisspecifictotherepeatedreferencegamesetupanditsuseofarepeating
context. WeaddtoS3theinstruction: whencreatingashortermessageforanimage,try
toextractsalienttokensfromthepreviousmessagesforthisimageratherthanintroducing
newwords. Theshortmessagesshouldstillallowthelistenertochoosethetargetcorrectly.
Foreachimage,whenyoureachamessagethatcannotbefurthershortened,youshould
keepusingthatmessagefortherestofthegame.5
Figure2showstheresultsforallvariants,alongwithpropertiesofthehumanmessages
from Hawkins et al. (2020b), which were collected using the standard setup. We report
meanmessagelength,WNR,andlisteneraccuracyforeachrepetition. Overall,allmodels
failtospontaneouslyimprovecommunicationefficiency. Itisonlywithfairlyheavy-handed
instructionthatGPT4,Gemini,andClaudeshowadaptationtrendssimilartohumans.
Variant S1 shows that without any explicit instruction, the models show trends that are
farfromhumanbehavior. GPT4,Gemini,andClaudegeneratelongerutterancesinlater
repetitions. IDEFICS and LLaVa maintain consistent message lengths. But, upon close
inspection,weobservetheysimplytendtorepeatpreviouslyusedmessagesforthesame
image. ThisexplainstheirverylowandalmostconstantWNR.Weanalyzethisfurtherin
Section6. Also,themessagesofIDEFICSandLLaVaarelesseffectiveindistinguishingthe
targetimages,asshownbythelowerlisteneraccuracies. Thisdemonstratestheinabilityof
thesemodelstocorrecttheirbehaviorbasedonfeedback. NomodelsshowWNRtrends
similartohumans. GPT4,Gemini,andClaudeconstantlyintroducenewwordsasthegame
progresses,asshownbyhigherWNRcurves,eventhoughwedonotusetokensamplingfor
decoding. Geminishowsadownwardtrend,butachievesthisbytheundesirablepracticeof
makingitsmessageslongereverytrialwhilemakingarelativelyconstantnumberofword
insertionsorchanges,soabiggerportionofthemessageismaintained.6
Griceaninstruction(S2)leadsGPT4andClaudetoreducemessagelengthovertime,though
GPT4’sreductionisfarfromhumans’. BothmodelshaveWNRcurvessignificantlyhigher
thanhumans. Astheirmessagesshorten,theystillfrequentlyintroducenewwordsand
donotstabilizethemessages,abehavioradversetocommunicationefficiency. Wefurther
discussthisissuewithS3,wheremoremodelsdisplaythisissue.
S3’sexplicitinstructionhasnoimpactonIDEFICSandLLaVa. Bothcontinuerepeating
messages,failingtofollowtheinstructions. GeminiandGPT4showdecreasingmessage
lengthtrendssimilartohumansbutstillhavelongermessagesthanhumansthroughout.
Claude eventually produces messages as short as humans but starts with much longer
messagesthanothermodels. Allmodelsshowingmessageshorteningfrequentlyintroduce
new words as they shorten the messages. Even when the message is too short to be
condensed, themodelsmayadoptnewwordsnexttimewithoutchangingthemessage
length. Figure8intheappendixexemplifiesthesebehaviors. Suchbehaviorsdeviatefrom
thestabilitypropertyofconventionsandtheobservationthathumanmessagesshowhigh
consistency and convergence. The gap between the WNR curves of these models and
humansillustratesthisissue. Whilethesemodelsshowincreasinglexicalefficiency,theuse
ofnewwordsreducescommunicationefficiency,burdeningthelistenertoreasonaboutthe
wordsthatdidnotappearthelasttimetheimagewasreferenced. Wefurtherdiscussthis
issueinSection6.
S4addressestheconsistencyissuebutrequiresfurtherexplicitinstruction. Thefinalprompt
elicitsfromGPT4,Gemini,andClaudebothlengthreductionandmessageconvergence,as
observedwithhumans. However,theS4promptisveryspecifictoICCA’ssetupanddoes
notgeneralizebeyondreferencegames. Heavy-handedpromptinterventionslikethisare
6ThisisdueWNR’slength-normalization,whichiscriticaltoreflectsimilarity(AppendixA.2).
6PublishedasaconferencepaperatCOLM2024
alsoknowntocauseunintendedmodelbehaviors(Shaikhetal.,2024). Promptengineering
isnotlikelytobethesolution.
5 Model-as-listenerExperiments
Listenerexperimentsfollowasetupsimilartothespeakerexperimentsasfarasmodels
andpromptoptimization(Section4). Gemini,LLaVa,andClaudecapthenumberofinput
images,limitingtheiruseinsomeofourlistenervariants. Overall,wedesignfourmain
variants,eachimplementedthroughthepre-processingfunctionF. Ourdesignprocessis
iterative,withsomevariantsdesignedbasedonthebehaviorobservedwithearlierones.
Throughoutthelistenervariants,wekeeptheinstruction I largelyconstantandaboutthe
roleofthelistener. Wevaryhowwedisplaythereferentialcontext.
Thelisteneractionspaceismorelimited,simplyrequiringthemodeltoselectthereferenced
image. Wefocusonevaluatingmodelaccuracy,similartohowlistenerbehaviorischarac-
terizedinhumanstudies. Figure3visualizesthebehaviorsweobserve. Wealsoinclude
humanlisteneraccuracytrendsasreferencetomodelaccuracies.
Thestartingpointforthelistenerstudyisthestandardreferencegamesetup(Section2):
L1: Standard Listener Images are shuffled and re-displayed for each trial, so each
imagewillpotentiallyhaveanewlabelrelativetoprevioustrials.
L1requiresagrowingnumberofimagesinthepromptastheinteractionprogresses. With
sixrepetitionsoffourtrialsandacontextoffourimages,themaximumnumberofimages
inthepromptattheendoftheinteractionis96. Gemini,LLaVa,andClaudecantakeat
most16,4,and20images,soweonlyuseGPT4andIDEFICSwithL1.
Weexpectaneffectivemodeltoexploittheconversationhistorytoreasonaboutthehuman
speaker’sconventionalizedwaysofspeaking. Evenifthemodelstartswithlowaccuracy,it
hastheopportunitytoimprovebecausethepromptatlaterstagesincludesfeedbackforits
choices,andasthemessagesconventionalize,latermessagesforanimageareoftenexact
repetitions,albeitwiththereferentialcontextshuffled.
BothGPT4andIDEFICSdosignificantlyworsethanhumans(Figure3,left). Asexpected,
humansdemonstratestrongperformancetostartwith,andshowanupwardtrendinac-
curacy,astheinterlocutorsadapttoeachother. GPT4issignificantlyworsethanhumans,
thoughperformingfairlywell. Itshowsamarginalimprovementtrend(88.9%→92.5%in
repetition5),butitisnotsignificant,andweakensinthelastrepetition(91.2%). IDEFICS
ismuchworseimmediatelyinthebeginning(46.8%),andratherthanimproving,itsper-
formancedeterioratesastheinteractionprogresses,reachingrandomchanceinthelater
trials. Thishappenseventhoughitisreceivinganincreasingamountofinformationthat
shouldallowittoimproveitsperformance. Apossiblecauseforthistrendisthedramatic
increaseinthepromptsize,especiallyasmoreandmoreimagesareadded,astheinteraction
progresses. WefurtherdiscussthisissueanditspotentialcausesinSection6.
5.1 HistoryandContextImpact
FollowingtheobservationswithL1,wedesignthreevariantswithsimplifiedreferential
contextsandhistorytobetterunderstandhowwellthemodelshandletheinteractionhistory
andthereferentialcontext:
L2: NoHistory Eachofthe24trialsisgiventothemodelinisolation,withoutany
history. The model input includes the context of four images and the speaker
utterance, as well as the basic game instruction. This variant reveals the extent
towhichthemodelcanreasonaboutthead-hocconventionsformedinrepeated
human-humaninteractionwithoutaccesstothehistoryinwhichtheywereformed.
L3: Images Once A potential challenge of L1 is the large number of images in the
prompt. A model’s architecture or training may not be suitable for handling a
largenumberofimages,andLLMpromptlengthisknowntoadverselyinfluence
7PublishedasaconferencepaperatCOLM2024
IDEFICS LLaVa GPT4 Gemini Claude Human(StandardSetup)
L1: StandardListener L2: NoHistory L3: ImagesOnce L4: NoShuffle
100
75
50
25
1 2 3 4 5 6 1 2 3 4 5 6 1 2 3 4 5 6 1 2 3 4 5 6
Repetition#
Figure3: Listenerexperiments. MarginsofErrorare95%bootstrappedCIs.
performance(Liuetal.,2023b). L3usesashorterhistory, byonlyprovidingthe
referentialcontext(fourimages)tothemodelonceinthefirsttrial. Imagelabelsare
persistentacrossalltrials,whichalsoavoidstheimpactofshuffling. UnlikeL2,this
variantincludesthecompletemessage,selection,andfeedbackhistory.
L4: NoShuffle ThefourimagesappeareverytrialsimilartoL1butarenotshuffled
across trials. L4 shows the effects of image shuffle if compared with L1. It also
showstheeffectofimagequantityifcomparedwithL3,whichdoesnotinvolve
shufflingeither.
L2andL3needonlyfourimagesintheprompt,allowingustotestallthemodels.
Theno-historyvariant(L2)revealsdifferentperformancetrendsforIDEFICSandGPT4
comparedtothestandardsetup(L1). IDEFICSisstillnotdoinggreat(45.8%onthefirst
repetition),butperformancelargelyremainsconsistentacrossrepetitions,indicatingthat
possiblythecomplexityofthepromptisattherootofitsdownwardtrendintheL1scenario.
GPT4startswithsimilarperformance(87.5%)toitsresultsinL1,butthenshowsaslight
downward trend (83.8% at the end), in contrast to the initial upward trend in L1. This
indicatesthatthegraduallyconventionalized,shortermessagesahumanspeakerusestend
tobemoredifficultforthemodeltoresolveandthattheconversationhistorycanbean
effectiveremedy. Gemini(80.2→78.8%),LLaVa(72.7→71.3%),andClaude(57.4→55.5%)
showsimilartrendstoGPT4fromRepetition1to6,withoverallloweraccuracies.
Thebenefitofhistorybecomesmoreconspicuouswhenthereferentialcontextisonlygiven
once (L3). This variant dramatically simplifies the prompt, but retains the information
needed for convention formation (i.e., prior message, selection, and feedback). All the
models show an upward trajectory as the interactions progress. GPT4 and Claude are
thestrongest,eventuallyreaching100%accuracy,matchinghumanlisteners’performance
(99.54%). Thissuggeststhatallmodelscanassociatethecurrentmessagewiththerelevant
priormessages,therebyincreasingtheirpredictionaccuracyastheinteractionprogresses.
Admittedly,becauseanimagealwayshasthesamelabelthroughoutthegameunderthis
setup,themodelsmaydowellbysimplydrawingassociationsbetweenanimage’slabel
andthemessagesthathavereferredtothatimage(i.e.,label-messageassociations). Under
thismechanism,themodelcanimproveitsaccuracywithoutreasoningabouttheactual
visualinput. WeexplorethispossiblemechanismwithmoregamevariantsinAppendixD.
Nonetheless,thisexperimentshowsthatMLLMspossesssomecapabilitiesforincreasingly
efficientcommunicationwithhumanswhenactingasthelistener.
Theno-shuffle(L4)experimentalsoprovideskeyinsights. GPT4’saccuracyissimilarto
thatinL3andhigherthanthatinL1. Thisdemonstratessensitivitytoimageshufflingand
theconstantlychangingimagelabels. GPT4inL3andL4mayberelyingtosomedegreeon
textsimilaritybetweenrepetitionsbyexploitingthelabel-messageassociations,ratherthan
groundingtothevisualinput. WestudythisfurtherinAppendixD. IDEFICS’performance
8
%ccAPublishedasaconferencepaperatCOLM2024
ontheotherhandisdifferentfrombothL3andL1,showinganalmostunnoticeabletrend
up. Thisshowsthatitisnotonlytheshufflingbutalsotheincreaseinthenumberofimages
thatIDEFICScannotseemtohandlewell. WefurtherdiscussthisissueinSection6.
6 Discussion
Our studies point to various issues that likely hinder specific models from displaying
communicationefficiencygains,andpointoutdirectionsforfutureworks.
TendencytoRepeatMessages Inthespeakerstudy,IDEFICSandLLaVatendtorepeat
thefirstmessagetheyuseforeachimage,showingnoadaptation. Tofurtherstudyhow
muchthesemodelspreferpatternsofrepetition,wedesignatestthatusesthesemodels
forlanguagemodelingratherthantextgeneration. Weconstructtwotranscriptsforeach
ofthe54human-humaninteractionsinouroriginaldataset. Oneistheoriginaltranscript
fromhuman-humaninteractions,showingthenaturalevolutionofmessages. Theotheris
amanipulatedtranscriptwherethespeakerrepeatsthemessagesfromRepetition1inall
thelaterrepetitions. WecalculatethelogprobabilityandperplexityIDEFICSandLLaVa
assigntothesetranscripts,countthenumberoftimesonetypeoftranscripthasbetterlog-
probability/perplexitythantheother,andapplyasigntest. Wefindthatthemanipulated
transcript showing message repetitions consistently receives higher log probability and
lowerperplexityforall54interactions,showingthemodels’significanttendencytowards
repeatedpatterns(signtestp-valuesarenearzero). Unfortunately,thisexperimentcannot
bedonewithGPT4,Gemini,orClaudeduetoAPIlimitations.
LexicalEfficiency̸=CommunicationEfficiency Theconvergenceofhumanspeakermes-
sagesforaparticularimagetoashort,stableconventionoftentakestheformofextracting
salienttokensfromthepreviousmessageandstickingtothesamemessageonceitbecomes
very short (Hawkins et al., 2020a). Unless directly instructed to do so through a highly
engineered prompt (S4), GPT4, Gemini, and Claude often introduce new words when
shortening their messages or even when the messages cannot be further shortened, as
shownintheS3explicitinstructionvariant. Suchinconsistencywithhumanbehaviorsis
problematic. Whenmessagesforthesameimagedonotconverge,noconventionscanform
andthelistenerwilllikelyneedadditionalcognitiveefforttoprocessthepreviouslyunseen
words. Intuitively,evenifanewmessageissemanticallysimilartoapreviousonebyusing
synonyms,resolvingitstilllikelyentailagreatercognitiveloadthananexactrepetition.
Moreover, whennewwordsdescribinganewaspectofanimageareintroducedaftera
fewroundsofrelativelysimilarmessages,theyviolatethehumanlistener’sexpectation,
potentiallyleadingtomiscommunicationandslowerresponse(Metzing&Brennan,2003).
PerformanceDegradationwithMany-imageInputs Amongthemodelsthatsupporta
largenumberofimages,IDEFICSperformsmuchworseasthenumberofimagesincreases.
EventhoughtheimagesinL4arenotshuffledacrosstrials,whichcouldhaveallowedthe
modeltoexploitlabel-messageassociationsasanefficientwaytogainhighaccuracy,the
modelstillhadmuchloweraccuracythanwhentheimagesonlyappearonce(L3)(Figure3).
Whenthehistorycontainsagrowingnumberofimagesthatareshuffledbetweentrials(L1),
IDEFICSshowsanevenworseaccuracytrend.
Alikelyhypothesisisthatagreaternumberofimagescreateschallengesforcapturingthe
dependencybetweenspecificvisualinputandtextualcues,whichcanmanifestasfailuresto
associateanimage’slabelwiththeactualcontentoftheimage. Inaqualitativeexperiment,
we supply a sequence of images and their labels as input to IDEFICS, and instruct it to
describeImage[X].WeobservethatIDEFICScandescribethecorrectimageeasilywhenwe
giveuptofourlabeledimages,butoftenmakesmistakesasthenumberincreases(Figure9
in the appendix). Therefore, even though IDEFICS is designed and trained to support
multi-imageinference,7itsmulti-imagecapabilitiesdonotgeneralizebeyondafewimages.
7TheFlamingoarchitecturebehindIDEFICSsupportsanarbitrarynumberofimagesasinputand
itistrainedoninterleavedtextsandmultipleimages(Huggingface,2023).
9PublishedasaconferencepaperatCOLM2024
AnotherpotentialcauseistheFlamingoarchitecturebehindIDEFICS.Eachtoken’scross-
modalattentiononlyappliestothevisualfeaturesofthelastimagethatprecedesit,rather
thanalltheimages. Informationaboutotherimagescanonlybeindirectlyaccessedthrough
self-attentiononthehiddenstatesoftheirrespective <image>tokensinthetextsequence.
Thisarchitecturemaydegradetheabilityofthemodeltoreasonaboutimages,depending
ontheirlocationsintheinput. Whenthetargetisnotthelastimage,ImageD,themessage
tokenswillnothavedirectcross-modalattentiontothetarget’svisualfeatures,whichmay
hurtIDEFICS’prediction.InL3,whereIDEFICSdidperformwell,thislimitationmighthave
beenmitigatedbythestrongtextualcuesandlabel-messageassociations,whereashaving
moreimagesmaydistractIDEFICSfromthesecuesandthusmanifeststhislimitation.
7 Conclusion
ICCAprovidesaperspectiveintotheperformanceoftoday’sMLLMsthatismissingin
existingbenchmarking,andcanbeeasilyappliedtonewMLLMswithoutcollectingnew
humandata. Weobservethatstate-of-the-artmodelslackthein-contextabilitiestoadapt
theirownlanguageforefficientcommunication,eventhoughtheymaysometimesperform
betterwhilepassivelyreceivingincreasinglyefficientlanguagefromtheirinterlocutor. This
issue is fundamental because, unlike humans, the models do not perceive the effort or
cost needed for communication, thus having no inherent reason to reduce them. It is
stillsurprisingthough,giventhatLLMs/MLLMshavesuccessfullydisplayedmanyother
humanbehaviorsandimpressiveabilitiesinvariousapplications,bylearningfromthelarge
amountsofhumandata,whereadaptationforefficiencyiscommon. Overall,thecurrent
paradigmforcreatingLLMsfailstoaddresstheneedforconversationaladaptationand
futureresearchisneededonimprovingtheirabilitiestospontaneouslyimprovelanguage
efficiency,maintainlanguageconsistencyforthesamereferent,avoidexcessivetendency
forrepetitions,andhandlemoreimagesinasinglequery.
Acknowledgments
ThisresearchwassupportedbyAROW911NF21-1-0106,NSFundergrantNo. 1750499,a
giftfromOpenPhilanthropy,andagiftfromApple. WethankRobertHawkinsandMarten
vanSchijndelforinsightfuldiscussions. Wethanktheanonymousreviewersandthearea
chairfortheirvaluablefeedback.
References
Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Has-
son, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, Roman
Ring, Eliza Rutherford, Serkan Cabi, Tengda Han, Zhitao Gong, Sina Samangooei,
Marianne Monteiro, Jacob Menick, Sebastian Borgeaud, Andrew Brock, Aida Ne-
matzadeh, Sahand Sharifzadeh, Mikolaj Binkowski, Ricardo Barreira, Oriol Vinyals,
Andrew Zisserman, and Karen Simonyan. Flamingo: a visual language model
for few-shot learning. In Proceedings of Advances in Neural Information Processing
Systems, 2022. URL https://proceedings.neurips.cc/paper files/paper/2022/file/
960a172bc7fbf0177ccccbb411a7d800-Paper-Conference.pdf.
Jacob Andreas and Dan Klein. Reasoning about pragmatics with neural listeners and
speakers.InProceedingsoftheConferenceonEmpiricalMethodsinNaturalLanguageProcessing,
2016. URLhttps://www.aclweb.org/anthology/D16-1125.
ChinmayaAndukuri, Jan-PhilippFra¨nken, TobiasGerstenberg, andNoahD.Goodman.
Star-gate: Teaching language models to ask clarifying questions. arXiv, 2024. URL
https://arxiv.org/abs/2403.19154.
Anthropic. IntroducingthenextgenerationofClaude,2024. URLhttps://www.anthropic.
com/news/claude-3-family.
10PublishedasaconferencepaperatCOLM2024
SusanE.BrennanandHerbertH.Clark. Conceptualpactsandlexicalchoiceinconversation.
JournalofExperimentalPsychology: Learning,Memory,andCognition,22,1996.
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla
Dhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,Sandhini
Agarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,RewonChild,Aditya
Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric
Sigler,MateuszLitwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,Sam
McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are
few-shotlearners. InProceedingsofAdvancesinNeuralInformationProcessingSystems,vol-
ume 33, 2020. URL https://proceedings.neurips.cc/paper files/paper/2020/file/
1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.
KrantiChalamalasetti,JanaGo¨tze,SherzodHakimov,BrielenMadureira,PhilippSadler,
andDavidSchlangen. Clembench: Usinggameplaytoevaluatechat-optimizedlanguage
modelsasconversationalagents. arXiv,2023. URLhttps://arxiv.org/abs/2305.13455.
HerbertH.Clark. Commonground. CambridgeUniversityPress,1996.
HerbertH.ClarkandSusanE.Brennan. Groundingincommunication. InPerspectiveson
SociallySharedCognition.AmericanPsychologicalAssociation,1991.
Herbert H. Clark and Deanna Wilkes-Gibbs. Referring as a collaborative process.
Cognition, 22, 1986. URL https://www.sciencedirect.com/science/article/pii/
0010027786900107.
PhilipR.CohenandHectorJ.Levesque. RationalInteractionastheBasisforCommunication.
TheMITPress. URLhttps://doi.org/10.7551/mitpress/3839.003.0014.
MarcoDelTredici,XiaoyuShen,GianniBarlacchi,BillByrne,andAdria` deGispert. From
rewritingtoremembering: Commongroundforconversationalqamodels. 2022. URL
https://arxiv.org/abs/2204.03930.
AnnaEffenberger,RhiaSingh,EvaYan,AlaneSuhr,andYoavArtzi. Analysisoflanguage
changeincollaborativeinstructionfollowing. InFindingsoftheAssociationforComputa-
tionalLinguistics: EMNLP,2021. URLhttps://aclanthology.org/2021.findings-emnlp.
239.pdf.
Ron Eliav, Anya Ji, Yoav Artzi, and Robert Hawkins. Semantic uncertainty guides the
extensionofconventionstonewreferents. arXiv,2023. URLhttp://arxiv.org/abs/2305.
06539.
Daniel Fried, Jacob Andreas, and Dan Klein. Unified pragmatic models for generating
andfollowinginstructions. InProceedingsoftheConferenceoftheNorthAmericanChapter
oftheAssociationforComputationalLinguistics: HumanLanguageTechnologies,2018. URL
https://www.aclweb.org/anthology/N18-1177.
EdwardGibson,RichardFutrell,StevenP.Piantadosi,IsabelleDautriche,KyleMahowald,
LeonBergen,andRogerLevy. Howefficiencyshapeshumanlanguage. TrendsinCog-
nitive Sciences, 23, 2019. URL https://www.sciencedirect.com/science/article/pii/
S1364661319300580.
NoahD.GoodmanandMichaelC.Frank.Pragmaticlanguageinterpretationasprobabilistic
inference. TrendsinCognitiveSciences,20,2016. URLhttps://api.semanticscholar.org/
CorpusID:3632786.
Google. IntroducingGemini: OurlargestandmostcapableAImodel,2023. URLhttps:
//blog.google/technology/ai/google-gemini-ai/.
BarbaraJ.GroszandCandaceL.Sidner. Plansfordiscourse. InIntentionsinCommunication.
TheMITPress. URLhttps://doi.org/10.7551/mitpress/3839.003.0022.
11PublishedasaconferencepaperatCOLM2024
JanoschHaber,TimBaumga¨rtner,EceTakmaz,LiekeGelderloos,EliaBruni,andRaquel
Ferna´ndez.ThePhotoBookdataset:Buildingcommongroundthroughvisually-grounded
dialogue.InProceedingsoftheAnnualMeetingoftheAssociationforComputationalLinguistics,
2019. URLhttps://aclanthology.org/P19-1184v2.pdf.
RobertHawkins,MichaelC.Frank,andNoahD.Goodman. Characterizingthedynamics
of learning in repeated reference games. Cognitive Science, 44, 2020a. URL https://
onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12845.
RobertHawkins,MinaeKwon,DorsaSadigh,andNoahGoodman. Continualadaptation
forefficientmachinecommunication. InProceedingsoftheConferenceonComputational
NaturalLanguageLearning,November2020b.
WilliamS.HortonandRichardJ.Gerrig. Revisitingthememory-basedprocessingapproach
to common ground. Topics in Cognitive Science, 8, 2016. URL https://onlinelibrary.
wiley.com/doi/full/10.1111/tops.12216.
Huggingface. HuggingFaceM4/idefics-80b-instruct,2023. URLhttps://huggingface.co/
HuggingFaceM4/idefics-80b-instruct.
Anya Ji, Noriyuki Kojima, Noah Rush, Alane Suhr, Wai Keen Vong, Robert Hawkins,
and Yoav Artzi. Abstract visual reasoning with tangram shapes. In Proceedings of the
Conference on Empirical Methods in Natural Language Processing, December 2022. URL
https://aclanthology.org/2022.emnlp-main.38.
RobertM.KraussandSidneyWeinheimer. Changesinreferencephrasesasafunctionof
frequencyofusageinsocialinteraction: Apreliminarystudy. PsychonomicScience,1,1964.
URLhttps://link.springer.com/article/10.3758/BF03342817.
RobertM.KraussandSidneyWeinheimer. Concurrentfeedback, confirmation, andthe
encodingofreferentsinverbalcommunication. JournalofPersonalityandSocialPsychology,
4,1966.
DavidKelloggLewis. Convention: APhilosophicalStudy. Wiley-Blackwell,1969.
HaotianLiu,ChunyuanLi,YuhengLi,andYongJaeLee. Improvedbaselineswithvisual
instructiontuning. arXiv,2023a. URLhttps://arxiv.org/pdf/2310.03744.
NelsonF.Liu,KevinLin,JohnHewitt,AshwinParanjape,MicheleBevilacqua,FabioPetroni,
andPercyLiang.Lostinthemiddle:Howlanguagemodelsuselongcontexts.Transactions
oftheAssociationforComputationalLinguistics,12,2023b. URLhttps://aclanthology.org/
2024.tacl-1.9.pdf.
ArthurB.MarkmanandValerieS.Makin. Referentialcommunicationandcategoryacquisi-
tion. JournalofExperimentalPsychology: General,127,1998.
BillMcDowellandNoahD.Goodman. Learningfromomission. InProceedingsoftheAnnual
MeetingoftheAssociationforComputationalLinguistics,2019. URLhttps://aclanthology.
org/P19-1059.pdf.
CharlesMetzingandSusanE.Brennan. Whenconceptualpactsarebroken: Partner-specific
effectsonthecomprehensionofreferringexpressions. JournalofMemoryandLanguage,49,
2003. URLhttps://www.sciencedirect.com/science/article/pii/S0749596X03000287.
Will Monroe, Robert Hawkins, Noah D. Goodman, and Christopher Potts. Colors in
context: Apragmaticneuralmodelforgroundedlanguageunderstanding. Transactions
oftheAssociationforComputationalLinguistics,5,2017. URLhttps://aclanthology.org/
Q17-1023.pdf.
OpenAI,JoshAchiam,StevenAdler,SandhiniAgarwal,LamaAhmad,IlgeAkkaya,Floren-
ciaLeoniAleman,DiogoAlmeida,JankoAltenschmidt,SamAltman,ShyamalAnadkat,
RedAvila,IgorBabuschkin,SuchirBalaji,ValerieBalcom,PaulBaltescu,HaimingBao,
MohammadBavarian,JeffBelgum,IrwanBello,JakeBerdine,GabrielBernadett-Shapiro,
12PublishedasaconferencepaperatCOLM2024
ChristopherBerner,LennyBogdonoff,OlegBoiko,MadelaineBoyd,Anna-LuisaBrak-
man, Greg Brockman, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie
Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke
Chan, Che Chang, Fotis Chantzis, Derek Chen, Sully Chen, Ruby Chen, Jason Chen,
MarkChen,BenChess,ChesterCho,CaseyChu,HyungWonChung,DaveCummings,
JeremiahCurrier,YunxingDai,CoryDecareaux,ThomasDegry,NoahDeutsch,Damien
Deville,ArkaDhar,DavidDohan,SteveDowling,SheilaDunning,AdrienEcoffet,Atty
Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix, Simo´n Posada Fishman,
JustonForte,IsabellaFulford,LeoGao,ElieGeorges,ChristianGibson,VikGoel,Tarun
Gogineni,GabrielGoh,RaphaGontijo-Lopes,JonathanGordon,MorganGrafstein,Scott
Gray,RyanGreene,JoshuaGross,ShixiangShaneGu,YufeiGuo,ChrisHallacy,JesseHan,
JeffHarris,YuchenHe,MikeHeaton,JohannesHeidecke,ChrisHesse,AlanHickey,Wade
Hickey, Peter Hoeschele, Brandon Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost
Huizinga,ShantanuJain,ShawnJain,JoanneJang,AngelaJiang,RogerJiang,Haozhun
Jin,DennyJin,ShinoJomoto,BillieJonn,HeewooJun,TomerKaftan,ŁukaszKaiser,Ali
Kamali,IngmarKanitscheider,NitishShirishKeskar,TabarakKhan,LoganKilpatrick,
JongWookKim,ChristinaKim,YongjikKim,JanHendrikKirchner,JamieKiros,Matt
Knight,DanielKokotajlo,ŁukaszKondraciuk,AndrewKondrich,ArisKonstantinidis,
KyleKosic,GretchenKrueger,VishalKuo,MichaelLampe,IkaiLan,TeddyLee,JanLeike,
JadeLeung,DanielLevy,ChakMingLi,RachelLim,MollyLin,StephanieLin,Mateusz
Litwin, TheresaLopez, RyanLowe, PatriciaLue, AnnaMakanju, KimMalfacini, Sam
Manning,TodorMarkov,YanivMarkovski,BiancaMartin,KatieMayer,AndrewMayne,
BobMcGrew,ScottMayerMcKinney,ChristineMcLeavey,PaulMcMillan,JakeMcNeil,
DavidMedina,AalokMehta,JacobMenick,LukeMetz,AndreyMishchenko,Pamela
Mishkin,VinnieMonaco,EvanMorikawa,DanielMossing,TongMu,MiraMurati,Oleg
Murk,DavidMe´ly,AshvinNair,ReiichiroNakano,RajeevNayak,ArvindNeelakantan,
RichardNgo,HyeonwooNoh,LongOuyang,CullenO’Keefe,JakubPachocki,AlexPaino,
JoePalermo,AshleyPantuliano,GiambattistaParascandolo,JoelParish,EmyParparita,
Alex Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe de Avila Belbute
Peres, MichaelPetrov, HenriquePondedeOliveiraPinto, Michael, Pokorny, Michelle
Pokrass,VitchyrH.Pong,TollyPowell,AletheaPower,BorisPower,ElizabethProehl,
Raul Puri, Alec Radford, Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real,
KendraRimbach,CarlRoss,BobRotsted,HenriRoussez,NickRyder,MarioSaltarelli,Ted
Sanders,ShibaniSanturkar,GirishSastry,HeatherSchmidt,DavidSchnurr,JohnSchul-
man,DanielSelsam,KylaSheppard,TokiSherbakov,JessicaShieh,SarahShoker,Pranav
Shyam, SzymonSidor, EricSigler, MaddieSimens, JordanSitkin, KatarinaSlama, Ian
Sohl,BenjaminSokolowsky,YangSong,NatalieStaudacher,FelipePetroskiSuch,Natalie
Summers,IlyaSutskever,JieTang,NikolasTezak,MadeleineB.Thompson,PhilTillet,
AminTootoonchian,ElizabethTseng,PrestonTuggle,NickTurley,JerryTworek,JuanFe-
lipeCero´nUribe,AndreaVallone,ArunVijayvergiya,ChelseaVoss,CarrollWainwright,
Justin Jay Wang, Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei, C. J. Weinmann,
AkilaWelihinda,PeterWelinder,JiayiWeng,LilianWeng,MattWiethoff,DaveWillner,
ClemensWinter,SamuelWolrich,HannahWong,LaurenWorkman,SherwinWu,JeffWu,
MichaelWu,KaiXiao,TaoXu,SarahYoo,KevinYu,QimingYuan,WojciechZaremba,
RowanZellers,ChongZhang,MarvinZhang,ShengjiaZhao,TianhaoZheng,Juntang
Zhuang, William Zhuk, and Barret Zoph. GPT-4 Technical Report. arXiv, 2024. URL
http://arxiv.org/abs/2303.08774.
LongOuyang,JeffWu,XuJiang,DiogoAlmeida,CarrollL.Wainwright,PamelaMishkin,
Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob
Hilton,FraserKelton,LukeE.Miller,MaddieSimens,AmandaAskell,PeterWelinder,
PaulFrancisChristiano,JanLeike,andRyanJ.Lowe. Traininglanguagemodelstofollow
instructionswithhumanfeedback. InProceedingsoftheConferenceonNeuralInformation
Processing Systems, 2022. URL https://proceedings.neurips.cc/paper files/paper/
2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf.
Jeffrey Pennington, Richard Socher, and Christopher Manning. Glove: Global vectors
forwordrepresentation. InProceedingsoftheConferenceonEmpiricalMethodsinNatural
LanguageProcessing,2014. URLhttp://www.aclweb.org/anthology/D14-1162.
13PublishedasaconferencepaperatCOLM2024
OmarShaikh,KristinaGligoric,AshnaKhetan,MatthiasGerstgrasser,DiyiYang,andDan
Jurafsky.Groundinggapsinlanguagemodelgenerations.InProceedingsoftheConferenceof
theNorthAmericanChapteroftheAssociationforComputationalLinguistics: HumanLanguage
Technologies,June2024. URLhttps://aclanthology.org/2024.naacl-long.348.
Robert Stalnaker. Common ground. Linguistics and Philosophy, 25, 2002. URL https:
//link.springer.com/article/10.1023/A:1020867916902.
AlbertoTestoniandRaquelFerna´ndez. Askingtherightquestionattherighttime: Human
and model uncertainty guidance to ask clarification questions. In Proceedings of the
ConferenceoftheEuropeanChapteroftheAssociationforComputationalLinguistics,2024. URL
https://aclanthology.org/2024.eacl-long.16.pdf.
DavidTraum. AComputationalTheoryofGroundinginNaturalLanguageConversation. PhD
thesis,UniversityofRochester,1994.
JuliaWhite,JesseMu,andNoahD.Goodman.Learningtoreferinformativelybyamortizing
pragmaticreasoning. InProceedingsoftheAnnualMeetingoftheCognitiveScienceSociety,
2020. URLhttps://cognitivesciencesociety.org/cogsci20/papers/0175/0175.pdf.
KayoYin,TerryRegier,andDanKlein.Americansignlanguagehandshapesreflectpressures
forcommunicativeefficiency. arXiv,2024. URLhttps://arxiv.org/abs/2406.04024.
HaoZhu,GrahamNeubig,andYonatanBisk. Few-shotlanguagecoordinationbymodeling
theoryofmind. InProceedingsoftheInternationalConferenceonMachineLearning,2021.
URLhttps://proceedings.mlr.press/v139/zhu21d/zhu21d.pdf.
GeorgeKingsleyZipf. HumanBehaviorandthePrincipleofLeastEffort: AnIntroductionto
HumanEcology. Addison-WesleyPress,1949.
14PublishedasaconferencepaperatCOLM2024
A ImplementationDetails
A.1 MessageLengthMeasurement
Wemeasurethelengthofthegeneratedmessagesbycountingthenumberoftokens.Because
differentMLLMshavedifferenttokenizers,wechoosetoonlyuseIDEFICS’stokenizerfor
messagelengthcalculationsforallmodels.
A.2 WordNoveltyRate
WordNoveltyRateisamodifiedWordErrorRate,whichonlycountsinsertionsandsubsti-
tutions,andignoresdeletions. Thenumberofinsertionsandsubstitutionsisnormalizedby
thelengthofthereferencemessage,asdoneinthestandardWordErrorRatecalculation.
Fortwo messagesfromRepetition N-1and N,we usethe messagefrom RepetitionN-1
as the reference and the one from Repetition N as the hypothesis. We follow Hawkins
etal.(2020a)’smetricdesignanddropmostfunctionwordstoonlyconsideropen-class
contentwords(nouns,adjectives,verbs,andadverbs)aswellaspronouns,numbers,and
adpositions.
WNRaddressesthelimitationofmetricsusingcosinesimilaritybetweenaveragedembed-
dings(e.g.,GloVe),whichoperateinthesemanticspace,forexampleasinHawkinsetal.
(2020a). Semantic similarity between messages is not sensitive to some lexical changes,
ignoringtheimportanceofexactwordchoiceinconventionformation. Forexample,oncea
conventionisformedtousethecartorefertoanimage,changingittoasemanticallysimilar
message,theautomobile,violatesthestabilitypropertyofconventions,whichmayincrease
thelistener’scognitiveload. Empirically,wefindthatWNRproducesresultsconsistent
withHawkinsetal.(2020a)’saveragedGloVeembeddingsimilarity,asshowninFigure4
(WNRmovesintheoppositedirectiontotheGloVe-basedsimilaritybecauseWNRdirectly
measuresdissimilarity).
GloVe-Sim
WNR
1
0.8
0.6
0.4
0.2
0
1 2 3 4 5 6
Repetition#
Figure 4: GloVe embedding similarity and WNR between messages from consecutive
repetitions. EveryincreaseinGloVeembeddingsimilarityiscapturedbyacorresponding
decreaseinWNR,andviceversa. MarginsofErrorare95%bootstrappedCIs.
WealsoreportavariantofWNR,whichisnotnormalizedbylength. Werefertothisvariant
asWordNoveltyDistance(WND).WNDissometimesmoreinterpretablebecauseeach
15PublishedasaconferencepaperatCOLM2024
unitdifferenceinitdirectlycorrespondstoawordinsertionordeletion. However,because
WNDissmallbetweenanytwoshortmessages,itcanbehardertointerpretwhenmessages
areshort. Figure5reportsWNDforourspeakerexperiments.
IDEFICS LLava GPT4 Gemini Claude Human(StandardSetup)
S4: ExplicitInstruc-
S1: StandardSpeaker S2: GriceanInstruction S3: ExplicitInstruction tion+ConsistencyRequest
7
6
5
4
3
2
1
0
1 2 3 4 5 6 1 2 3 4 5 6 1 2 3 4 5 6 1 2 3 4 5 6
Repetition#
Figure 5: Word Novelty Distance for speaker experiments. Margins of Error are 95%
bootstrappedCIs.
A.3 MLLMImplementationDetails
TheexactversionsoftheMLLMsusedareidefics-80b-instruct,llava-1.5-13b,gpt-4-1106-
vision-preview,Gemini1.0ProVision,andclaude-3-opus-20240229. ForIDEFICS,weuse
8-bitquantizationtofitthe80bmodelinto3A6000GPUs.ForallMLLMs,weuseadecoding
temperatureof0toavoidtheuncertaintycausedbysampling,whichwasalsothedefault
forIDEFICSandLLaVa. Weusethemodels’defaultvaluesforotherhyperparameters.
TheGPT4listenerusedtoevaluatemodelspeakersfollowsthelistenerinteractionsetupin
L3: ImagesOnce. L3isthescenariowhereGPT4showsitsbestperformanceandalmost
perfectlymatcheshumanperformance.
LLaVaonlysupportstaking1imageasinput. Tobypassthisconstraint,wemergethe4
imagesinthereferentialcontextinto1image,usinga2-by-2grid. Insteadofusingimage
labels(A,B,C,D),experimentswithLLaVarefertoanoriginalimageusingitslocationin
themergedimage(topright,topleft,bottomright,andbottomleft).
We conduct prompt engineering for each model individually to find the most suitable
phrasingoftheinstructions. Thepromptengineeringwasdoneoverthepilotstudydataset
releasedinHawkinsetal.(2020b)’sofficialGithubrepository. Thepilotstudydatasetis
distinctfromthe54humaninteractionsinICCAthatweuseforevaluation. Thispilotstudy
datasetcontainshuman-humaninteractionsoneasyreferentialcontexts,wherethetarget
imagesaremoreeasilydistinguishabletohumanswithveryshortmessages. Forthisreason,
thehumaninteractionsinthispilotstudydatasetshowlesslanguageadaptation,andwe
onlyuseitforpromptengineeringandnotevaluation.
16
DNWPublishedasaconferencepaperatCOLM2024
B ExamplePrompts
Model-as-speakerPrompt:
[System]Playagamewithalistener.Thisgameconsistsofmultipletrialsand4images(labeledA,
B,C,D).Youwillactasthespeakerinthisgame. Ineachtrial,oneoftheimagesisgivenasthe
target.Youwillgenerateamessagetotellthelistenerwhichimageisthetargetwithoutmentioning
anyimagelabel.Thelistenerwilltrytochoosethetargetcorrectlybasedonyourmessage.Youwill
knowwhichimagethelistenerguesses,soyoumayadjustyourmessagesbasedonthelistener’s
accuracy.Yourreplyshouldonlycontainthemessageandbeshorterthan20words.Donotmention
anyimage’slabel(A,B,C,D)inyourmessage.
ImageA:<img1>
ImageB:<img2>
ImageC:<img3>
ImageD:<img4>
Trial1,thetargetisImageB.
[Speaker]Message:Twobananasandapplesinawhitebowlonpolkadotcloth.
[System]ThelistenercorrectlyansweredImageB.
Trial2,thetargetisImageA.
[Speaker]Message:BananasonafloralclothwithanAmazonbox.
[System]ThelistenercorrectlyansweredImageB.
Trial3,thetargetisImageD.
[Speaker]Message:Bananasandapplesinabowl,stripedclothunderneath.
[System]ThelistenermistakenlyansweredImageC.
Trial4,thetargetisImageC.
[Speaker]Message:Assortedfruitinapaintedceramicbowl.
[System]ThelistenercorrectlyansweredImageC.
Trial5,thetargetisImageB.
[Speaker]Message:
Figure6: Examplepromptformodel-as-speakerstandardsetup. Thepromptisshortened
andrevisedforillustrativepurposes.
17PublishedasaconferencepaperatCOLM2024
Model-as-listenerPrompt:
[System]Playagamewithmultipletrialsinvolvingthesamesetofimages.Ineachtrial,Iwillrefer
tooneoftheimageswithamessage.YouwillguesswhichimageI’mreferringto. Ifpresent,the
historyoftheprevioustrialsmayhelpyoubetterunderstandhowIrefertospecificimages.
Trial1
ImageA:<img4>
ImageB:<img2>
ImageC:<img3>
ImageD:<img1>
Whichimageisthismessagereferringto:Thephotowith‘amazon’ontheback,with2bananas.
[Listener]ImageD
[System]Correct.IwasreferringtoImageD.
Trial2
ImageA:<img1>
ImageB:<img3>
ImageC:<img2>
ImageD:<img4>
Whichimageisthismessagereferringto:Photowithabowlof3bananaswithapokadotbackground.
[Listener]ImageB
[System]Wrong.IwasreferringtoImageC.
Trial3
ImageA:<img3>
ImageB:<img1>
ImageC:<img2>
ImageD:<img4>
Whichimageisthismessagereferringto:Abowlfullofmixedfruit,blackbackground.
[Listener]ImageA
[System]Correct.IwasreferringtoImageA.
Trial4
ImageA:<img3>
ImageB:<img4>
ImageC:<img2>
ImageD:<img1>
Whichimageisthismessagereferringto: Photowithabowlof3bananaswithstripesandother
patternsinthebackground.
[Listener]ImageB
[System]Correct.IwasreferringtoImageB.
Trial5
ImageA:<img3>
ImageB:<img2>
ImageC:<img4>
ImageD:<img1>
Whichimageisthismessagereferringto:Amazoninbackwith2bananas.
[Listener]Image
Figure7: Examplepromptformodel-as-listenerstandardsetup. Thepromptisshortened
andrevisedforillustrativepurposes.
18PublishedasaconferencepaperatCOLM2024
C FiguresforErrorAnalysis
Human Messages
1. dirty truck going towards the bridge
2. dirty truck going to bridge
3. how is this even guessing, it’s so easy, dirty truck going to bridge
4. dirty truck
5. dirty truck
6. dirty truck
GPT4 Messages
1. construction bridge with a concrete mixer truck underneath
2. bridge construction with a white truck
3. bridge work, dirty truck below
4. bridge construction
5. overpass work
6. concrete mixer
Figure8: Evolutionofanimage’scorrespondingmessagesacross6repetitionsinS3. Both
thehumanspeakerandtheGPT4speakershowlengthreduction,butGPT4’smessagesare
moreinconsistent.
Image A: Image B: Image C: Image D:
Image E: Image F: Image G: Image H:
User: describe Image D.
IDEFICS: a truck is parked in a parking lot.
Figure9: ExampleofIDEFICS’issuewithassociatingimageswiththeircorrectlabels. The
inputisasequenceofimagesinterleavedwiththeirlabelsandaprompttoaskthemodelto
describeImage[X].Wetrieddifferentformatstolabeltheimages,suchas<img>isImageA
andImageA:<img>butnonehelpedIDEFICSproducereliableresultsasthenumberof
imagesincreases.
19PublishedasaconferencepaperatCOLM2024
D ImageGroundingImpact
IDEFICS llava GPT4 Gemini Claude Human(StandardSetup)
L7: ImagesMis-
L5: ImagesMasked L6: ImagesMisleading leadinginRep. 6
100
75
50
25
1 2 3 4 5 6 1 2 3 4 5 6 1 2 3 4 5 6
Repetition#
Figure10: AverageaccuracyforvariantsL5-7. MarginsofErrorare95%bootstrappedCIs.
TheresultswithL3(Section5.1)raisedconcernsaboutwhetherthemodelsareusingimages
effectivelyorjustexploitinglabel-messageassociation. Wedevelopthreevariantstostudy
this:
L5: ImagesMasked Eachimageisreplacedbyanimagemask,whereallpixelshave
the black color, (0, 0, 0). The image order is persistent, so the same label refers
always to the same underlying image that is masked. For the first four trials in
Repetition1,themodelhastomakeaguess. Regardlessoftheguess,thecorrect
targetisgivenbythesystemfeedbackasusual. Theoretically,themodelcanuse
thefeedbackforlaterrepetitions. Foramodeltosucceedinthisvariant,itmust
associatethemessageswiththeimagelabelssincenoactualimagesaregiven. This
variant tests theextent to which amodel can exploit label-messageassociations
throughin-contextlearningasawayofconventionunderstanding.
L6: ImagesMisleading ThisvariantcomplementsL5tofurtherstudytheimpactof
textsignalsandimages. ThesetupherefollowsL3,showingthereferentialcontext
once,exceptthatwemanipulatetheimagestobemisleading. Forthemanipulation,
weshuffletheimageswhenpresentingthemtothemodellisteneratthebeginning
ofthegame,butwedonotchangethegoldimagelabelsinthesystem. Therefore,
Image[X]fromthespeakerandthesystem’sperspectiveislikelydifferentfromthe
Image[X]fromthelistener’sperspective,andsoon. Forexample,usingthecontext
in Figure 11, the model may see the message Photo with a bowl of 3 bananas with
pokadotandchooseImageCbutthesystemandthespeakerwouldalwaysthinkthe
imagethatfeaturesbananasandpolkadotisImageB,sinceweshuffledtheimages
withoutupdatingthegoldlabelsaccordingly. Thenthesystemfeedbackwouldbe
wrong,thecorrectanswerisImageB.Tosucceedunderthissetting,themodelmust
learntoignoretheimagesandjustassociateallthedescriptionsrelatedtopolka
dot(forexample)withthelabelImageB.
L7: ImagesMisleadinginRep. 6 Thisvariantfurthertestsifthemodels’previous
promisingperformanceinL3comesfromjustexploitingthetextualsignals(the
label-messageassociations)andignoringthevisualinput. Weshowthecontext
oncesimilartoL3atthebeginning,butthenshowshuffledversionsduringeach
trialinthelastrepetition,withoutupdatingthegoldlabels(samemanipulationas
L6). Wehypothesizethatifthemodeltendstoignoretheimageinputandrelyon
textualassociationsintheconversationhistory,thismanipulationwillhavelittle
impact on its prediction or the accuracy calculated based on the old gold label.
Thisvariantrequires20imagesinthelasttrialsoitcannotbeusedwithLLaVaor
Gemini.
20PublishedasaconferencepaperatCOLM2024
When models cannot utilize the image input (L5 and L6), all models start with around
orbelowrandomchanceaccuracies(25%). Astheinteractionprogresses,modelsexploit
pastmessagesandfeedbackvialabel-messageassociationstoimproveperformanceand
displayatrendofimprovement. L5andL6resultstogetherdemonstratethatexploiting
label-message associations while ignoring the images can easily emerge as an effective
mechanism for MLLMs’ convention understanding behavior, provided that the image
referenthasaconsistenttextuallabel.
Injecting misleading images in the last repetition (L7) leads to a significant drop in per-
formancerelativetopreviousrepetitionsforIDEFICS(87.5→69.4%),GPT4(99.5→27.3%),
and Claude (98.6→22.2%). The drop is particularly conspicuous for GPT4 and Claude,
whereperformancegoesdowntoaroundrandomchance. ThissuggeststhatGPT4and
Claudedonotoverlyexploittheconsistenttextualassociationsfromthehistory,because
otherwisetheywouldnothavebeen‘misled’bythemanipulationsinthelastrepetition.
This is desirable because it shows that the visual input matters to these models’ output.
Ontheotherhand,whileIDEFICSalsoshowsadropinperformance,itisnotasstrongas
whattheothertwomodelsshow. ThisindicatesthatalthoughIDEFICSisnotcompletely
ignoringthevisualinput,itdoesexploitthetextualassociationsbeyondwhatisdesired.
Speaker’s Perspective Listener’s Perspective
Trial 1
Speaker: Photo with a
bowl of 3 bananas with
pokadot
A B A B
Listener: Image C
Speaker: wrong, I was
referring to Image B.
C D C D
Figure11: ExampleTrial1fromL6: ImagesMisleading
21