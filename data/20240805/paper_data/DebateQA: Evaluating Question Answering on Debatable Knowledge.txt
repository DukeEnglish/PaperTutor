DEBATEQA: Evaluating Question Answering on Debatable Knowledge
RongwuXu1∗,XuanQi1∗,
ZehanQi1,WeiXu1,ZhijiangGuo2
1 TsinghuaUniversty,2 UniversityofCambridge
Emails: {xrw22, qi-x22@}@mails.tsinghua.edu.cn
∗ Equalcontribution
Abstract language models on debatable queries is crucial
forunderstandingandenhancingtheircapabilities.
The rise of large language models (LLMs) Inherent difficulties hinder our way of assess-
has enabled us to seek answers to inher-
ing these models. Traditional question-answering
ently debatable questions on LLM chat-
(QA) benchmarks are typically designed to pro-
bots, necessitating a reliable way to evalu-
videfixedanswerstoquestions,asindatasetslike
ate their ability. However, traditional QA
SQuAD(Rajpurkaretal.,2016)andNaturalQues-
benchmarksassumefixedanswersareinad-
equateforthispurpose. Toaddressthis,we tions (Kwiatkowski et al., 2019). Even in scenar-
introduce DEBATEQA, a dataset of 2,941 ios where multiple legitimate answers are possi-
debatable questions, each accompanied by ble,suchasTruthfulQA(Linetal.,2022),thean-
multiple human-annotated partial answers swersareoftenpresentedasmultiple-choiceques-
that capture a variety of perspectives. We
tions, thus limiting the space of responses. Re-
develop two metrics: Perspective Diver-
cent years have seen the emergence of long-form
sity, which evaluates the comprehensive-
QA evaluations, such as ELI5 (Fan et al., 2019)
ness of perspectives, and Dispute Aware-
ness, which assesses if the LLM acknowl- and ASQA (Stelmakh et al., 2022a), which al-
edges the question’s debatable nature. Ex- low for more elaborate answers. However, these
perimentsdemonstratethatbothmetricsare works have not focused on inherently debatable
aligned with human preferences and stable questions. The most related work to us is DEL-
across different underlying models. Using
PHI (Sun et al., 2023), which curates a dataset
DEBATEQA with two metrics, we assess
with controversial questions, however, their em-
12 popular LLMs and retrieval-augmented
phasis is on identifying controversy rather than
generation methods. Our findings reveal
delvingdeeperintoevaluatingmodels’responses.
that while LLMs generally excel at recog-
nizingdebatableissues,theirabilitytopro- What constitutes a proper answer when asked
vide comprehensive answers encompassing about debatable knowledge? Drawing inspira-
diverseperspectivesvariesconsiderably.
tion from interdisciplinary literature, we propose
twodesirablepropertiesforsuchanswers. Firstly,
https://github.com/pillowsofwind/
the answer should inform the receiver that the
DebateQA
issue at hand is debatable (Misco, 2011). Sec-
ondly, a proper answer should be comprehensive
1 Introduction
and include diverse perspectives, which are cru-
How often do you query a chatbot about a debat- cial for maintaining an atmosphere of neutrality,
able issue? Questions like “Does Donald Trump especially in public-related inquiries (Habermas,
have a terrible character?” or “How do crop cir- 1991). Motivated by these considerations, we in-
cles form?” frequently arise in everyday life, re- troducetheDEBATEQAdataset,whichcomprises
flectinghumanbeings’naturalcuriosityabouttop- 2,941manuallyannotateddebatablequestions. To
ics that inherently lack fixed answers (Lowry and rigorously evaluate the aforementioned properties
Johnson, 1981; Brady, 2009). With the advent of model answers, each question is paired with
oflargelanguagemodels(LLMs;OpenAI2023b; several partial answers, each reflecting a single
Chowdhery et al. 2023; Touvron et al. 2023), we viewpointonthedebatableissue. Thesepartialan-
nowturntothesemodelstoseek“proper”answers swersaregeneratedthroughathree-stagepipeline
to such questions. Evaluating the performance of and then annotated by three annotators. Based on
4202
guA
2
]LC.sc[
1v91410.8042:viXrathepartialanswersinDEBATEQA,weproposethe exploratory metrics. Our work represents a step
metric of Perspective Diversity (P.D.), which as- forward from DELPHI by offering a comprehen-
sesses the comprehensiveness in terms of grasp- siveevaluationsolution. Weexpandandrefinethe
ing multiple points-of-view in the model answer. datasetandintroducemoremeaningfulmetrics.
Using DEBATEQA along with P.D., one can re-
liably and efficiently evaluate the comprehensive- 2.2 NLPonDebatableIssues
nessofresponsestodebatablequestions. Wealso BeyondQA,multiplelinesofNLPresearchinves-
proposethemetricofDisputeAwareness(D.A.), tigate debatable issues. One notable effort is the
which targets to identify whether the model ac- AIDebater, beginningwithSlonimetal.(2021)’s
knowledges the debatable nature of the question “IBM’s Project Debater” (Bar-Haim et al., 2019),
initsresponse. Importantly,weshowthattheP.D. the first AI system designed to engage humans in
and D.A. metrics align closely with human judg- meaningful debates. Another line of research fo-
mentsandarefairlystableacrossbackboneevalu- cuses on controversy detection. Researchers have
atormodels,validatingtheireffectiveness. identified controversy in news (Choi et al., 2010),
We apply DEBATEQA to evaluate 12 popular onlineforums(Chenetal.,2023),andothermedia
LLMs, as well as retrieval-augmented generation by analyzing sentiments (Choi et al., 2010; Chen
(RAG)approaches. WeobservewhileLLMsgen- et al., 2023) or sociological features like upvote
erallyexcelatidentifyingtheexistenceofdebate, percentages (Hessel and Lee, 2019). Moreover,
theirperformancevariesinprovidingcomprehen- Wanetal.(2024)investigateLLMs’preferencefor
sive answers with diverse perspectives. Notably, conflictingevidencewhenfacingcontroversialis-
top-notch open-source LLMs rival or even sur- sues. We distinguish ourselves from this body of
pass some leading commercial models. Besides, researchbyprimarilyfocusingonhandlingdebat-
RAG methods, though not uniformly beneficial ableissuesinthefieldofQA,specificallytargeting
to this task, improve closed-source model perfor- theevaluationofchatbot-likeNLPsystems.
mance, likely due to better contextual leverage.
Additionally, optimizing sampling hyperparame- 2.3 Long-formQAEvaluation
ters and leveraging task-specific prompts can fur-
Evaluating debatable QA falls into the topic of
ther boost performance. On the whole, our find-
long-formQAevaluation. Long-formtextevalua-
ingsunderscoretheneedforfurtherrefiningLLMs
tioncanbecategorizedintotwomainapproaches:
tobetterinteractwithdebatableknowledge.
reference-basedandreference-freeevaluation(Xu
et al., 2023). Reference-based methods require
2 RelatedWork
gold answers and evaluate the generated text by
2.1 QAwithNon-fixedAnswers assessingitssimilaritywiththegoldanswers(Fan
et al., 2019; Yuan et al., 2021; Chiang and Lee,
Many efforts focus on QA for which there is
2023). Conversely,reference-freeevaluationelim-
no single fixed answer. AMBIGQA (Min et al.,
inates the necessity for a gold standard. Some
2020)addressesambiguousquestionansweringby
studies assess the coherence and relevance of the
rewriting questions and generating multiple plau-
generationconcerningspecifiedquestions(Fabbri
sible answers. SUBJQA (Bjerva et al., 2020)
etal.,2022;Krishnaetal.,2022;Xuetal.,2023).
focuses on identifying subjectivity in questions
Some studies use a QA-based approach to assess
and answers within customer reviews. Disen-
thequalityofthegeneration(Tanetal.,2024). In
tQA (Neeman et al., 2023) proposes to provide
particular,thereisanotherlineofliteraturefocus-
disentangled answers to questions where the pro-
ingonexaminingtheveracityoflong-formgener-
vided context contradicts the model’s knowledge.
ation by utilizing external knowledge bases (Stel-
DEBATEQA differs logically from these efforts
makh et al., 2022b; Min et al., 2023; Wei et al.,
becausethespaceofplausibleanswerscannotbe
2024). However,noneoftheaforementionedstud-
narrowedbyrewritingorrestrictingthequestions.
iesaddresstheevaluationofdebatablequestions.
Tothebestofourknowledge,DELPHI(Sunetal.,
2023) is the first study on QA for debatable is-
3 Curatingthe DEBATEQA Dataset
sues. However, DELPHI has limitations: (1) it
does not provide answers for evaluation, and (2) Dataset overview. DEBATEQA is designed to
it shallowly evaluates model performance using help assessing language models’ answers to de-Field Content
Question Doesbirthorderinfluencepersonalitytraits?
POVBirthorderdoesnothaveameaningfulandlastingeffectonbroadBigFivepersonalitytraits.
PartialAnswer1
ExplanTheinfluenceofbirthorderonpersonalitytraitshasbeenatopicofinterestforoveracentury. However,basedon
extensiveresearchcombininglargedatasetsfromthreenationalpanelsintheUnitedStates,GreatBritain,andGermany,itis
evidentthatbirthorderdoesnothaveameaningfuleffectonbroadBigFivepersonalitytraits...
POVFirstbornsscorehigheronintelligenceandintellect.
PartialAnswer2
ExplanYes,birthorderdoesinfluencepersonalitytraits,particularlyinthedomainofintelligenceandintellect. Researchhas
consistentlyshownthatfirstbornstendtoscorehigheronobjectivelymeasuredintelligencetests...
POVNobirth-ordereffectsonextraversion,emotionalstability,agreeableness,orconscientiousness.
PartialAnswer3
ExplanTheinfluenceofbirthorderonpersonalitytraitssuchasextraversion,emotionalstability,agreeableness,andconsci-
entiousnesshasbeenatopicofinterestforoveracentury. However,recentcomprehensivestudieshaveprovidedsubstantial
evidencethatbirthorderdoesnotsignificantlyimpactthesepersonalitytraits...
Table1: AnexamplefromDEBATEQA,detailsoftheexplanationfieldsaretruncatedforspaceissues.
batable questions. It contains 2,941 debatable vocating for answers that integrate diverse view-
questions, each paired with a list of partial an- points (Habermas, 1991; Wansink et al., 2023).
swers to assist in evaluating model responses. To this end, we employ a three-stage pipeline for
Each partial answer addresses the question from collecting them: first, we collect evidence docu-
a distinct perspective and consists of two parts: a ments from trustworthy websites; second, we ex-
short point-of-view statement (POV) and a long- tract POVs from the evidence w.r.t. the question;
form explanation (Explan) that fully expands the finally,weexpandthePOVsintolong-formexpla-
POV.AnentryinDEBATEQAisshowninTable1. nations based on related evidence. The last two
TheoverallprocedureforcuratingDEBATEQA stepsareconductedwiththeassistanceofLLMs1.
is depicted in Figure 1. We first source debat- Together, the POVs and explanations comprise
ablequestions. Then,weapplyathree-stagesemi- whatwecallpartialanswers.
automated pipeline to collect partial answers.
3.2.1 RetrievingTrustworthyDocuments
Lastly, we conduct human annotation on the col-
lectedpartialanswerstofinalizethedataset. Qual- Wecollectpartialanswersbyleveragingonlinere-
ity examinations happen after each step. The fol- sourcesandextractingevidencefromrelevantweb
lowingsectionswilldetailthesesteps. pages. However,thenatureofdebatableissuesne-
cessitates careful processing of these documents,
3.1 SourcingDebatableQuestions as the Web can contain unveracious content. To
ensure the reliability of our partial answers, we
Wecollectdebatablequestionsfromthreedistinct
sourcedocumentsfromauthoritativetop-leveldo-
sources. First,werepurposetwoexistingdatasets:
mains (TLDs), as listed in Table 10. This treat-
we select 2,281 annotated controversial questions
ment helps in maintaining the reliability of the
from DELPHI (Sun et al., 2023) and a full set of
sources. We discard questions that have fewer
434questionsfromCONFLICTINGQA(Wanetal.,
than three documents, resulting in 2,982 ques-
2024). Toenrichtheexistingdata,wefurtherman-
tions, each supported by 3-5 of the most relevant
uallysourced1,758additionaldebatablequestions
documents. See§A.2fordetailedmeasures.
from the Web (see Table 8 for detailed sources).
We then run a deduplication algorithm (see § A.1 Quality examination. To assess the quality of
fordetails)toremoveanyduplicatequestions, re- retrieved documents, we analyze the relevancy
sulting in 3,216 questions. The final composition between questions and corresponding documents.
ofsourcedquestionsisshowninTable9. We calculate the cosine similarity between docu-
ment chunks and questions. As depicted in Fig-
3.2 CollectingPartialAnswers ure11,theaveragecosinesimilarityfordocument
trunks is 0.56 and there are no significant out-
ThecorenoveltyofDEBATEQAliesinevaluating
liers,indicatinghighrelevanceandminimalnoise
models by comparing the response with multiple
in the documents, confirming their overall quality
partialanswers,ratherthanasinglegoldreference.
forservingasthebasisforupcomingsteps.
One partial answer aims to answer the question
fromasingleperspective. Thismethodreflectsthe 1We select OpenAI GPT-4 (OpenAI, 2023b) to assist in
multifaceted essence of debatable knowledge, ad- collectingpartialanswers(thegpt-4-turbovariant).DELPHI Q c: irH co lew s d fo o rc mr ?op Doc Tit1: l[ ex :x x C. ru om ps y Cs it re cm le.e s du] Doc2 Doc3 R de ol ce svant ParD ta it aa l s Ae nt sw w/ e rs
ConflictingQA Web Retriever Crop cE irx cp lela si n ae nd d their POV1 s: igC nr sop lefc ti r bc yle sare (POVs + Explans)
Trusted sm pay wst ne er dio u yes ao rr si g oi fn s d eh ba av te e extraterrestrial beings Task1: Is the partial
TLDs: … answer grounded by the
ExistingDatasets* 2 - - . .oe rd gu LLM documents?
D Pe rb oa bt la eb ml se - - . …gov LLM thE ex op rl ya n su1 g: g eO sn te s ts hci ae tn t si mfi ac l l T a qa n us s ewk s te2 ior: naD d fo rde ors me t s h s a e t s h pp e ea crt ifia icl
whirlwinds or vortices, similar perspective?
Ma fn rou mall ty heSo Wu erc bed Top Docs cirP c nO l ae tV s ura1 a: r le C pe t hr h et e na oi rn mesc eur nlo t ap of t c to ti hr hc ed eu u cls Pa rt lr o
a
d p spe s ma .v t ai Tl t s he V, ir s oc n ro s i tdu eebld xay , c
T
f kr hle na ea ot ott w ree ynn t i …anh sge
DEBATEQA
Source Debatable Retrieve Evidence Extract Point-of- Expand POV based Human Annotation
Questions Documents View (POV) on Relevant Docs of PartialAnswers
Figure1:PipelineforcuratingDEBATEQA.Thethreemaincomponentsofthepipelinearehighlightedindifferent
colors: sourcingdebatablequestions,collectingpartialanswers,andhumanannotation. Primarysourcesortools
usedateachsteparehighlightedinbold.
3.2.2 ExtractingPoints-of-View The LLM is required to leverage only the infor-
mationcontainedwithintheserelevantdocuments
The second stage involves extracting diverse
to generate the explanation, minimizing the risk
POVs from the retrieved evidence documents. A
of hallucinations (Zhang et al., 2023). We repeat
POV is a concise statement that reflects the core
this step for all the POVs we have collected. The
perspective in addressing the question. We lever-
pseudocode of the pipeline for collecting partial
age GPT-4 to tackle this task, by applying the
answersisdeferredtoAlgorithm1.
prompt p described in Table 11, which takes
POV
the question and the concatenated documents and
3.3 HumanAnnotation
returns a list of diverse POVs along with the cor-
respondingdocumentindexeswhereeachspecific WeverifythefidelityoftheLLM-generatedpartial
POVisoriginated. Thedocumentindexesforeach answersthroughhumanannotation.
POV are later used for expanding the POV. To
Annotation tasks. To thoroughly evaluate the
avoid exceeding the 128K context window limit
qualityofDEBATEQA,wedesigntwotasks:
ofGPT-4,wepreprocessthedocumentsbyremov-
• Task 1: Ensure that the POV and the explana-
ing meaningless segments and truncating them to
tiongeneratedbytheLLMaregroundedinthe
120Ktokensiftheyexceedthislength.
documents. This task focuses on that the gen-
Qualityexamination. Weverifythequalityofthe
eratedexplanationsareaccuratelyderivedfrom
collected POVs on comprehensiveness w.r.t. the
trustworthyevidence.
documentsanddistinctivenessamongthemselves.
• Task 2: Ensure that the partial answer can ad-
For comprehensiveness, we ensure all valid per-
dress the question from a certain perspective.
spectives from retrieved documents are captured,
This task assesses the utility and relevance of
with 90.4% coverage verified manually. Distinc-
the partial answers, ensuring that they address
tiveness is assured by removing duplicated POVs
thequestioneffectively.
manually. Formoredetails,referto§A.3.
Results and the final dataset. We recruit three
3.2.3 ExpandingPOVtoExplanations
annotators and annotate the full dataset. Inter-
The last stage involves expanding the extracted annotator agreement (IAA) is measured using
POVsintolong-formexplanations. Eachexplana- Fleiss’Kappa(Fleissetal.,1981),yieldingscores
tion should stand as an independent answer, elab- of κ = 0.66 and κ = 0.60 for the two anno-
orating on the POV and addressing the question tation tasks, all indicating substantial agreement.
from that perspective. This expansion must be We remove 767 partial answers deemed substan-
anchored to the relevant information presented in dard by two or more annotators. This suggests
the evidence documents pertaining to the specific thatGPT-4generatesfaithfulpartialanswerswith
POV being developed. We again leverage GPT-4 a 93.4% accuracy. See § A.4 for details. We
onthistask,utilizingthepromptp described employ BERTopic (Grootendorst, 2022) to model
Explan
in Table 11. This prompt takes three inputs: the the domain distribution of DEBATEQA. The re-
question, the target POV to be expanded, and the sult is shown in Figure 14. To reduce computa-
related documents obtained in the previous stage. tionalcostsforupcomingevaluation,wesplitDE-BATEQAintotwosplits: thetestsplitwith1,000 the model’s answer to the debatable question.
randomly sampled questions and the dev set con- chatTemplate() is a chat template for prompting
tainingtheremaininginstances. instruction-tuned LLMs. Simply put, P.D. repre-
sentstheaggregateperplexityofgeneratingpartial
4 EvaluationCriteriaandMetrics
answersfromamodelanswer. Beingderivedfrom
Evaluationcriteria. Fordebatablequestions, the PPL,alowerP.D.signifiesbetterquality,suggest-
questforthebestanswerisfraughtwithcomplex- ingthatthemodelanswercontainslargersharesof
ity, as there exist no canonical standards. The thepartialanswer’scontent.
expectations vary: many seek a helpful assistant II: Dispute Awareness (D.A.). To ascertain if
thatdeliverscredibleinformationwithnoreserva- the model’s answer indicates that the addressed
tion,andsomemayposequestionsmerelyforself- question is debatable, we craft a prompt p D.A.,
affirmation, not to say some model providers pre- as shown in Table 14, and use it to prompt an
fer a “safe” agent to circumvent controversy. In instruction-tuned LLM. This metric is binary, in-
DEBATEQA, we aim to balance helpfulness and dicatingawarenessorlackthereof.
harmlessness, with the goal of fostering open di- (cid:26)
1 ifM (p (q,Ans))returns“1”,
alogues. After reviewing interdisciplinary litera- D.A.:= eval D.A.
0 otherwise.
ture,weidentifycriteriathatarenearlyuniversally
(3)
accepted and distill two key properties of what
constitutesagoodanswer: 5 EmpiricalExaminationofP.D.
• Perspectivediversity(helpful): howwelldoes
ToassessthereliabilityofP.D.,weempiricallyex-
theanswerdeliverinformativeandcrediblein-
amine its alignment with human preferences and
formationfromdiverseperspectives?
stabilityw.r.t. backbonemodelsandprompts.
• Dispute awareness (harmless): whether the
5.1 P.D.Well-AlignsHumanPreferences
answerrecognizestheexistenceofdebate.
Collecting human preferences. We collect 500
Evaluationmetrics. Althoughtheabovetwocri-
model answers from five LLMs to 100 ran-
teriaresonatewiththoseutilizedinDELPHI(Sun
etal.,2023),wedistinguishourselvesbyformaliz-
domly sampled questions in DEBATEQA-test,
then have three rank the answers pairwise.
ingthesecriteriaintomoresophisticatedquantifi-
Using pairwise prefer-
ablemetrics. Ourmethodologyexcelsbyintegrat-
encesandSpearman’sρ
ing the partial answer feature of DEBATEQA and A1 - 0.87 0.91 0.8
outperforms DELPHI’s approach by a huge mar- correlation (Zar, 2005), A2 0.87 - 0.84 0.6
0.4
gin, which will be later elaborated in § 5 and § 6. we find strong agree- A3 0.91 0.84 - 0.2
0.0
Please note that while the following two metrics ment among three an- Annotator 1 Annotator 2 Annotator 3
Figure 2: Correlation
bothemploybackboneLLMs,theymaydiffer;for notators with ρ > 0.8,
among annotators as-
brevity,werefertobothasM eval. as shown in Figure 2. sessedbySpearman’sρ.
I: Perspective Diversity (P.D.). To evaluate the This consensus allows
us to assess the alignment of evaluator judgments
model’s answers against legitimate partial re-
with human preferences effectively. More details
sponses, we assess it using a smaller open-source
aredescribedin§B.1.1.
LLM by generation, ensuring efficiency and cost-
Compared baselines. We compare P.D. with no-
effectiveness. Weapplythefollowingmetric:
table text evaluation baselines. Many of these re-
n
P.D.:=(cid:88) PPL(PAi|chatTemplate(Concat(A, quirealanguagemodelasbackbones:
(1)
i=1 • Prompt-basedmetrics: Thesebaselinesalways
“Pleaserestate.”))), require an advanced instruction-tuned LLM,
we consider three of them: (1) Direct-Score:
wherePPL(Y|X)istheconditionalperplexity:
usinganLLMtoassignaLikertscalescore(1-
(cid:32) 1 (cid:88)N (cid:33) 5)usingthesameinstructionwepresenttohu-
PPL(Y|X)=exp − logP(y |X,y ) .
N i <i man annotators; (2) G-Eval (Liu et al., 2023):
i=1
(2) a prompt-based evaluation framework that as-
In Equation 1, PAi = concat(POVi,Explani) sesses the quality of generated texts by incor-
denotes the ith partial answer and A denotes porating chain-of-thoughts (CoT) (Wei et al.,2022) and a form-filling paradigm; (3) Num- Qwen2 0.5B - 0.95 0.87 0.97 0.86
0.8
Qwen2 7B 0.95 - 0.84 0.94 0.84
of-POVs: using an LLM to count the number 0.6
Phi-3 mini 0.87 0.84 - 0.88 0.89
ofperspectivesinthemodelanswers. Thismet- GPT-2 (117M) 0.97 0.94 0.88 - 0.86 0.4
MiniCPM-2B 0.86 0.84 0.89 0.86 - 0.2
ric can be considered an improved metric over Qwen2 0.5B Qwen2 7B Phi-3 mini GPT-2 (117M)MiniCPM-2B 0.0
the “Comprehensiveness Answer Rate” metric Figure 3: Kendall’s τ correlations of the P.D. metric
introducedinDELPHI(Sunetal.,2023). usingdifferentbackbonemodels.
• Similarity-based metrics: We pick two tradi- 5.3 P.D.isStablew.r.t. Prompts
tionalstatisticalmetrics,BLEU(Papinenietal.,
Remember in Equation 1, there is a prompt
2002)andROUGE-L(Lin,2004)andtwoneu-
“Please Restate” wrapping the model answer. To
ralmetrics,BARTScore(Yuanetal.,2021)and
verifythestabilityofP.D.w.r.t. differentprompts,
SemScore(AynetdinovandAkbik,2024).
we configure P.D. with five different prompts
Referto§B.1.2fordetailsofthesebaselines. showninTable13andcomputepairwiseKendall’s
Results. We apply ELO ratings to establish a hu- τ among the resulting rankings, for the same set
manpreferencerankingandthenmeasurethecor- ofmodelresponsescollectedin§5.1. Theresults
relation with metrics’ rankings using Spearman’s in Figure 4 show that the rankings by P.D. with
ρandKendall’sτ (Kendall,1938). Theaveragere- differentpromptshaveexcellentconsistency.
sults of the annotators’ individual correlation are
reported in Table 2. We observe that P.D. sig- P1 - 0.984 0.98 0.986 0.978
0.8
P2 0.984 - 0.972 0.994 0.978
nificantly outperforms DELPHI’s metric and G- 0.6
P3 0.98 0.972 - 0.978 0.986
0.4
Eval powered by GPT-4o. Using the same small P4 0.986 0.994 0.978 - 0.98
0.2
P5 0.978 0.978 0.986 0.98 -
LLM(Phi-3mini128k)asthebackbone,P.D.out- 0.0
Prompt1 Prompt2 Prompt3 Prompt4 Prompt5
performs G-Eval by a huge margin, underscor- Figure 4: Kendall’s τ correlations of the P.D. metric
ingP.D.’sexceptionalalignmentwithhumanjudg- usingdifferentprompts.
ment. Overall, P.D. is effective and economical.
Wefurtherprovidecasestudiesin§B.1.3. 6 EmpiricalExaminationofD.A.
Metric BackboneModel ρ τ WeassessD.A.’sreliabilitybyexaminingitsaccu-
Prompt-basedmetrics racy grounded by human judgments and stability
Direct-Score GPT-4o 0.692 0.671 w.r.t. backbonemodels.
G-Eval Phi-3mini128k -0.003 -0.028
G-Eval GPT-3.5Turbo 0.593 0.531
6.1 D.A.isAccurate
G-Eval GPT-4o 0.706 0.634
Num-of-POVs GPT-4o 0.398 0.345
To obtain the ground truth of the verdicts of the
Similarity-basedmetrics
500 responses from § 5.1, three authors manually
BLEU - 0.667 0.565
annotatethembyassigningbinarylabels. Thean-
ROUGE-L - 0.537 0.451
BARTScore BARTLarge(2020a) 0.476 0.397 notation has an inter-annotator agreement of 0.79
SemScore all-mpnet-base-v2(2019) 0.447 0.375
P.D. Phi-3mini128k 0.733 0.701 evaluated by Fleiss’ Kappa. With these manually
P.D. GPT-2(117M) 0.825 0.748
P.D. Qwen20.5B 0.820 0.742
Metric BackboneModel Acc F1 AUROC MCC
Table2: Alignmentofvariousevaluationmetricswith D.A. Qwen21.5B 0.740 0.845 0.530 0.093
D.A. MiniCPM-2B-dpo 0.770 0.857 0.621 0.289
humanpreferences.Thetop-performingmetricishigh-
D.A. Llama38B 0.770 0.869 0.521 0.179
lighted in bold and the runner-up is underlined. ρ: D.A. Gemma29B 0.740 0.833 0.615 0.246
Spearman’sρ,τ: Kendall’sτ. D.A. Phi-3medium 0.800 0.868 0.726 0.452
D.A.-ZS Phi-3medium 0.530 0.434 0.565 0.146
Ack. - 0.220 0.049 0.430 -0.252
5.2 P.D.isStablew.r.t. BackboneModels
Table 3: Based on human annotations as the ground
ToverifythestabilityofP.D.w.r.t. differentback- truth, we assess D.A.’s accuracy. D.A.-ZS: D.A. with
bonemodels,weconfigureP.D.withfivedifferent azero-shotpromptp , Ack.: the“Acknowledge”
D.A.-ZS
LLMs and compute pairwise Kendall’s τ among metricfromDELPHI.
the resulting rankings, for the same set of model labeledoutcomesasthegroundtruth,wecalculate
responses collected in § 5.1. The results in Fig- the accuracy, F1 score, and AUROC (Hanley and
ure3showthattherankingsbyP.D.withdifferent McNeil, 1982) and Matthews Correlation Coeffi-
backbonemodelsarehighlyconsistent. cient (MCC; Matthews 1975) for D.A. with dif-ferentbackbonemodels,the“Acknowledge”met- following ability is a must. We select Phi-3
ric referenced in DELPHI (refer to § C.1 for de- medium 128k 14B and Qwen2 1.5B. We select
tails),andasimplifiedversionofD.A.withazero- those four models because their performance is
shot prompt p without in-context demon- showcasedin§5.1and§6.1,respectively.
D.A.-ZS
strations. The results in Table 3 demonstrate the Generation configuration. In the main experi-
superiorityofourD.A.metricoverthemetricfrom ments, when testing the LLMs, we provide the
DELPHI, and the necessity of including demon- questions with a minimalistic QA prompt, as
strations in the prompt p D.A.. Upon a case study shown in Table 15, which instructs the LLMs
for D.A.-ZS, we find that the Phi-3 mini 128k without any hint that they are debatable. We be-
model occasionally deviates from our instruction lieve this approach more accurately reflects the
by failing to use 0 or 1 for its judgment, thereby typicaluserinteractionwithchatbots. Forallmod-
diminishingitseffectiveness. els, we configure top-p = 0 to enable greedy de-
codingandstockchattemplatesincludingM .
eval
6.2 D.A.isStablew.r.t. BackboneModels
Giventherobustdesignofpromptp , ensuring 7.2 MainResults
D.A.
D.A.’s performance, we advise utilizing the stan-
Main evaluation results can be found in Table 4.
dard prompt in Table 14. Our focus here is on
Wesummarizeourkeyfindingsasfollows:
confirming D.A.’s stability across various back-
• Larger models generally outperform small
bone models. We set D.A. with five instruction-
ones. Generally, larger models perform well
followingLLMsandanalyzepairwiseagreements
in terms of both P.D. and D.A. metrics. Large
for the decision made between each two LLMs
state-of-the-art LLMs such as GPT-4o and
based on the model responses collected in § 5.1.
Llama3 70B demonstrate the strongest perfor-
The result in Figure 5 demonstrates the consis-
mance,whiletinytosmallLLMsarealmostal-
tencyofD.A.amongdifferentbackbonemodels.
waysatthebottom. Besides,forLLMswiththe
Gemma2-9B - 0.99 0.86 0.83 0.92 samearchitecture(e.g.,Qwen20.5B/1.5B/7B),
0.8
Llama3 8B 0.99 - 0.87 0.84 0.93 0.6 largermodelsalwaysoutperformsmallerones.
MiniCPM 2B 0.86 0.87 - 0.83 0.9
Phi-3 medium 0.83 0.84 0.83 - 0.79 0.4
Qwen2 1.5B 0.92 0.93 0.9 0.79 - 0.2 • Gaps between closed and open models are
Gemma2-9B Llama3 8B MiniCPM 2BPhi-3 mediumQwen2 1.5B 0.0 not clear. With the exception of the superb
Figure5: AgreementsoftheD.A.metricacrossdiffer-
performanceofGPT-4o,wehaveobservedthat
entbackbonemodels.
numerous open-source LLMs are outperform-
7 Experiments ing other capable closed commercial LLMs.
Specifically, open-source models like Llama3
7.1 ExperimentalSetup
70B and Gemma2 9B nearly match the perfor-
We evaluate a wide range of 12 LLMs on DE- mance of GPT-4o in handling debatable ques-
BATEQA-test using P.D. and D.A., including tions. Thismightindicatethattheperformance
closed commercial LLMs and open-source ones. on handling debatable issues does not demand
WealsoassessseveralRAGapproaches. as stringent capabilities from the models as
Evaluated models. We evaluate the follow- moredifficulttaskssuchasreasoning.
ing LLMs: GPT-4o (OpenAI, 2024b), GPT-4o
• Deficiencies in delivering comprehensive re-
mini (OpenAI, 2024a), GPT-3.5 Turbo (OpenAI,
sponses. We observe significant shortcom-
2023a), Claude 3.5 Sonnet (Anthropic, 2024),
ings in weaker models’ ability to furnish com-
Llama3 Instruct 8B/70B (Meta, 2024), Qwen2
prehensive answers that encompass a vari-
0.5B/1.5B/7B (Qwen, 2024a), Phi-3 mini 128k
ety of perspectives. For instance, the worst-
3.8BandPhi-3small128k7B(Abdinetal.,2024),
performing Qwen2 0.5B’s answers are around
andGemma29B(Team,2024). Allmodelsarethe 3to9×2 worsethanGPT-4ointermsofrecov-
instructionorchatfine-tunedversions.
eringtheinformationinpartialanswers.
Evaluators. We select multiple language mod-
• Models excel in recognizing debate. We find
els as the backbone for our metrics. For evaluat-
thateventhelowest-performingmodel,namely
ing P.D., we select Qwen2 0.5B and GPT-2 base
117M (Radford et al., 2019) as M eval. For as- 2ThesevaluesareapproximatedwiththeP.D.valuesw.r.t.
sessing D.A., a competent LLM with instruction- TwodifferentM ,referto§Ffordetails.
evalPerspectiveDiversity(P.D.) DisputeAwareness(D.A.)
Avg.Len.
Model
(#tokens) M eval=Qwen20.5BM eval=GPT-2 Norm. M eval=Phi-3M.M eval=Qwen21.5B Norm.
Rank Rank
Score↓ Rank Score↓Rank Score↑ Rank Score↑ Rank
Closed-SourceLLMs
GPT-4o 434 3.07 1 4.03 1 1 0.952 1 0.979 1 1
GPT-4omini 252 4.09 6 5.88 6 6 0.937 4 0.964 4 4
GPT-3.5Turbo 141 5.28 10 8.25 10 10 0.904 6 0.947 6 6
Claude3.5Sonnet 199 4.63 8 6.96 8 8 0.856 10 0.920 9 10
Open-SourceLLMs(MediumtoLarge)
Llama370B 432 3.09 2 4.07 3 2= 0.945 3 0.977 2 2=
Llama38B 381 3.51 5 5.02 5 5 0.928 5 0.964 4 5
Qwen27B 255 4.18 7 6.10 7 7 0.895 8 0.923 8 8
Phi-3small128k 412 3.50 4 4.31 4 4 0.899 7 0.924 7 7
Gemma29B 395 3.12 3 4.04 2 2= 0.947 2 0.967 3 2=
Open-SourceLLMs(TinytoSmall)
Qwen21.5B 169 5.60 11 8.67 11 11 0.864 9 0.875 10 9
Qwen20.5B 72 6.56 12 10.87 12 12 0.792 11 0.836 11 11
Phi-3mini128k 218 4.82 9 7.33 9 9 0.716 12 0.794 12 12
Table4: MainresultsofP.D.andD.A.forLLMsonDEBATEQA-test.Avg.Len.:averagelengthoftheanswers,
GPT-2: GPT-2(117M),Phi-3M.: Phi-3medium128k,Norm. Rank: normalizedaveragerankofdifferentM .
eval
The best and worst resultsofeachmetric(w.r.t. aspecificM )arehighlighted.
eval
Qwen2 0.5B, demonstrates a D.A. over 70%
inrecognizingthecontentiousnessofdebatable
questions. This indicates that even the perfor-
manceoftheworst-performingmodelisnotas
poorasitmightseem.
Correlation between the P.D. and D.A. met-
rics. To investigate the correlation between P.D. Figure7:Rankingsofweightedaveragescoresofmod-
and D.A. for the tested models, we plot a vi- elsatdifferentratios. kistheproportionalcoefficient.
sualization of the results in Figure 6, which
weightedaveragescore(W.A.G.)iscalculatedas:
aids in understanding how these two metrics
relate to each other across various models. W.A.G.=k·Z-norm(P.D.−1)+(1−k)·Z-norm(D.A.), (4)
The figure indicates a
0.95
positive correlation be- 0.90 where the k is the proportional coefficient and
tween P.D. and D.A., 0.85 Z-norm() refers to z-normalization. We show the
0.80
suggesting that models ranking of the weighted average scores for the
0.75
with greater perspec- modelsatdifferentk inFigure7.
0.1500.1750.2000.2250.2500.2750.3000.325
P.D. 1( )
tive diversity are also
Figure 6: Correlation 7.3 EffectofMoreSpecificPrompts
more aware of the de-
between P.D. and D.A.
bate in question, align- forthetestedLLMs. In our main experiments, we use a simple QA
ingwithourexpectations. prompt (p basic in Table 17) that does not high-
Integrating the P.D. and D.A. metrics. To light the debatable nature of the questions or de-
demonstrate the models’ general capability in ad- mand comprehensive answers. To evaluate the
dressingdebatablequestions,weintegratethetwo models’ full potential, we further test five LLMs
metrics with varying weights. To ensure that the withmoredetailedprompts. Weemploythreesys-
P.D. scores reflect the same performance favora- tem prompts—p basic, p comprehensive, and p detailed—
bility as the D.A. scores, we first take the recip- to elicit model responses at varying levels of de-
rocal of the P.D. scores. Then, we leverage z- tail, as shown in Table 17. Using 200 randomly
normalization3 to normalize both the reciprocal sampled questions from DEBATEQA-test, we
P.D. score and the original D.A. score. The final compare the average P.D. and D.A. scores across
the five selected LLMs. The results for these
3https://en.wikipedia.org/wiki/Standard_score prompts are presented in Table 5. We find that
)
(.A.Deventherelativelysimplep promptsig- advantage can be attributed to ReAct’s more
comprehensive
nificantly improved the performance for all five strategic approach to acting based on the pre-
models. We conclude that more specific prompts, viously retrieved information, which leads to
i.e., inform the model of the debatable nature and morepreciseandrelevantdocumentsretrieved.
requestfordetailedresponses,canenhanceLLMs’
performance in answering debatable questions. P.D.(↓M =Qwen20.5B)
Model eval
Thisfindingalignswithourexpectationsandsug-
NoRAG VanillaRAG ReAct
geststhatLLMuserscanbenefitfromwell-crafted
GPT-4omini 4.02 3.94 3.70
prompts when seeking answers to contentious is- Claude3.5Sonnet 4.63 4.12 3.65
suesfromLLMs. Llama38B 3.55 4.01 3.99
Qwen27B 3.79 5.96 5.29
Phi-3mini128k 4.82 7.01 6.86
P.D.(↓) D.A.(↑)
Model
p b p c p d p b p c p d Table6: EffectoftwoRAGstrategiesonP.D.scores.
GPT-4omini 3.91 2.13 2.09 0.915 0.955 0.97
Claude3.5Sonnet 4.63 3.14 2.35 0.865 0.925 0.98 7.4.2 EffectofRAGSourceDocuments
Llama38B 3.42 2.58 2.51 0.855 0.935 0.985
Qwen27B 4.16 2.78 2.76 0.855 0.915 0.965 Considering that the performance of RAG is
Phi-3mini128k 4.71 3.40 2.88 0.765 0.925 0.96
highly dependent on the quality of the retrieved
documents, we explore whether restricting RAG
Table5: EffectofvariouspromptsonP.D.scoresand
D.A.scores. p : p ,p : p ,p : p . to utilize trustworthy documents would yield bet-
b basic c comprehensive d detailed
ter results. We retrieve only on web pages under
7.4 EvaluationforRAGApproaches
trustworthy TLDs listed in Table 10. The results
In this section, we assess the influence of RAG in Table 7 demonstrate that RAG on trustworthy
methodsonperformancewithin DEBATEQA. sources leads to better results. This highlights the
significance of source quality in RAG for debat-
7.4.1 EffectofRAGStrategy
able QA, emphasizing that utilizing trustworthy
We examine the effects of two popular RAG documents improves LLM response quality in re-
strategies, vanilla RAG (Lewis et al., 2020b) and spondingtosensitivetopics.
ReAct (Yaoetal.,2023). InvanillaRAG,wepick
the top-10 most relevant documents from the re- P.D.(↓M =Qwen20.5B)
eval
trieval results via Google Custom Search API4. Model
VanillaRAG RAGw.T.Docs
ReActemploysanagent-basedapproach,leverag-
GPT-4omini 3.77 3.63
ingClaude3.5Sonnettointerleavereasoningwith Claude3.5Sonnet 3.92 3.54
Llama38B 3.78 3.62
document retrieval, strategically selecting up to
Qwen27B 5.91 5.57
9 document chunks to improve problem-solving. Phi-3mini128k 6.77 6.50
BothmethodsutilizethepromptinTable16toas-
semble the question and the retrieved trunks. Re- Table7: EffectofRAGsourcesonP.D.scores. RAG
w. T.Docs: RAGusingtrustworthydocuments.
ferto§D.1fordetails.
We assess the performance of five LLMs by
7.5 EffectofDecodingHyperparameters
evaluating their responses to 100 randomly sam-
pled debatable questions from DEBATEQA-test In the main experiments, we configure all LLMs
usingtwodistinctRAGstrategies. Withtheresults to use greedy decoding, which, while straightfor-
detailedinTable6,weconclude: ward, can restrict the diversity and creativity of
LLM outputs (Holtzman et al., 2020). To assess
• LLMs with RAG do not consistently improve
the impact of various decoding hyperparameters
in answering debatable questions, but closed-
usingsamplingdecodingonmodels’performance,
sourcemodelsseemorenotablebenefits,possi-
we select a range of five different temperatures
blyduetobettercontextutilizationdespitepo-
and top-p values. The results of P.D. and D.A.
tentialnoiseinretrievedcontentchunks.
scores are presented in Figure 8 and Figure 9, re-
• AmongthetwoRAGstrategies, ReActconsis-
spectively. Theplotsindicatethathighertempera-
tentlyoutperformsVanillaRAG,eventhoughit
ture and top-p values generally prompt LLMs to
uses fewer document chunks (9 vs. 10). This
produce more well-rounded responses to debat-
4https://developers.google.com/custom-search able questions, enhancing performance on bothmetrics. This suggests that sampling configura- 5.5
Claude 3.5 Sonnet
tions that allow for a broader selection of lower- 5.0 GPT-4o
GPT-4o-mini
4.5 Llama3 8B
probabilitytokenscanleadtoimprovedoutcomes. 4.0 Qwen2 7B Phi-3 mini
3.5
3.0
Score433333333......0 .9 .8 .765432
1.0 T0 o.8 p-0 p.6 0.4 0.2
0.0
0.00.20. T4 e0 m.6 p0. e8 r1 a.0 tu1 r.2 e
333 ... 788 505 Score433333333......0 .9 .8 .765432
1.0 T0 o.8 p-0 p.6 0.4 0.2
0.0
0.00.20. T4 e0 m.6 p0. e8 r1 a.0 tu1 r.2 e
333333 ...... 455555 802468 22 .. 05
100 150 An2 (s0 aw0
)er
P
.2
L
De5 n0
.g Sth
c3 o0 (A0
reve
s3
r
(a5 ↓g0
)e
T4 o0 k0 ens4 )50 500
(a)GPT-4o-mini (b)Llama38B 1.0
Figure8: AverageP.D.score(↓)foranswersfromdif- 0.9
ferentLLMswithcorrespondinghyperparameters. 0.8
0.7
0.6
0.916 0.5
Score0 0 0 0 0 0. . . .9 .9 .9 8 8 84 2 0 8 6 4 0000 .... 9999 0111 8024 Score0 0 0 0 0 0. . . .9 .9 .9 8 8 84 2 0 8 6 4 000 ... 888 789 100 150 An2 (s b0 w0 )e Dr 2 L .e A5 n0 .g Sth3 c 0 ( oA0 rv ee s3 ra5 (g ↑0 e ) T4 o0 k0 ens4 )50 500
1.0 T0 o.8 p-0 p.6 0.4 0.2 0.0 0.00.20. T4 e0 m.6 p0. e8 r1 a.0 tu1 r.2 e 0.906 1.0 T0 o.8 p-0 p.6 0.4 0.2 0.0 0.00.20. T4 e0 m.6 p0. e8 r1 a.0 tu1 r.2 e 0.86 Figure 10: Average P.D. and D.A. scores for answers
(a)GPT-4o-mini (b)Llama38B invariouslengthsacrossdifferentLLMs.
Figure9: AverageD.A.score(↑)foranswersfromdif-
ferentLLMswithcorrespondinghyperparameters. in leveraging referenced and convincing informa-
tion for their arguments, and (2) weaker LLMs
7.6 EffectoftheLengthofGeneration have difficulty providing a comprehensive elabo-
Todelvedeeperintohowresponselengthimpacts ration of sufficient perspectives and we find the
the two metrics, we use the prompt “Your answer answer presentation of those LLMs are markedly
must be around {num} tokens.” to regulate LLMs poorer. Based on these gaps, LLMs’ ability to
torespondwithapredeterminedlength. However, address debatable questions still has room to be
recognizing that the open-source model’s adher- further refined. We point out the following po-
ence to instructions might be inconsistent, we il- tential solutions for improving models’ ability on
lustrate the correlation between the actual aver- DEBATEQA: (1) Deepen domain-specific knowl-
age token count in the model’s responses in Fig- edge with pretraining or high-quality RAG; (2)
ure10. Wefind: (1)modelstendtoperformbetter Strengthen source citation by adopting strategies
withlongerresponses. Thisislikelyduetolonger suchascitingmemoryorretrieveddocumentsfor
answers providing more comprehensive informa-
evidence-richresponses;(3)Improvestylisticpre-
tion, enhancing P.D. scores. Furthermore, when
sentationthroughfine-tuning;and(4)Ensureper-
tasked with longer answers, models are more spective diversity and balance through alignment
pronetoacknowledgethedebate,whichimproves trainingorpromptengineering. Kindlyreferto§E
D.A. scores. (2) in the main experiment, GPT- foradetailedanalysisandcasestudies.
4ooutperformsGPT-4o-miniandClaude3.5Son-
8 Conclusion
net significantly, as shown in Table 4. However,
the performance gap narrows when responses are WedevelopDEBATEQA,anovelQAdatasetwith
constrained to equal lengths. This suggests that 2,941 debatable questions paired with multiple
while the knowledge and conversational capabili- human-annotated partial answers to assess lan-
tiesofthethreemodelsarecomparable,GPT-4o’s guage models’ ability to answer debatable ques-
propensity for completing longer answers gives it tions. We introduce two novel metrics, Perspec-
anedgeovertheothertwo,whichfavorbrevity. tive Diversity and Dispute Awareness, to evalu-
atehowwelllanguagemodelsreflectmultiplehu-
7.7 QualitativeAnalysis
man viewpoints and recognize debate. Extensive
Despite GPT-4o leading in both metrics, certain experiments demonstrate these two metrics align
aspects of its performance remain unsatisfactory. withhumanpreferencesandarestable. Ourevalu-
Wealsoexaminetheperformancegapsamongless ationswith12LLMsshowthatcurrentmodelsare
capablemodels. Throughcasestudies,ourconclu- relativelystronginrecognizingdebatebutvarying
sions are: (1) state-of-the-art LLMs still fall short intheabilitytocomprehensivelyaddressthem.
)
(erocS
.D.P
egarevA
)
(erocS
.A.D
egarevAReferences Long Papers, pages 977–990. Association for
ComputationalLinguistics.
Marah I Abdin, Sam Ade Jacobs, Ammar Ah-
mad Awan, Jyoti Aneja, Ahmed Awadallah, Johannes Bjerva, Nikita Bhutani, Behzad Gol-
Hany Awadalla, Nguyen Bach, Amit Bahree, shan, Wang-Chiew Tan, and Isabelle Augen-
Arash Bakhtiari, Harkirat S. Behl, Alon Ben- stein. 2020. Subjqa: A dataset for subjectivity
haim, Misha Bilenko, Johan Bjorck, Sébastien and review comprehension. In Proceedings of
Bubeck, Martin Cai, Caio César Teodoro the 2020 Conference on Empirical Methods in
Mendes, Weizhu Chen, Vishrav Chaudhary, Natural Language Processing, EMNLP 2020,
Parul Chopra, Allie Del Giorno, Gustavo Online, November 16-20, 2020, pages 5480–
de Rosa, Matthew Dixon, Ronen Eldan, Dan 5494. Association for Computational Linguis-
Iter, Amit Garg, Abhishek Goswami, Suriya tics.
Gunasekar,EmmanHaider,JunhengHao,Rus-
sellJ.Hewett, JamieHuynh, MojanJavaheripi, Michael Brady. 2009. Curiosity and the value of
Xin Jin, Piero Kauffmann, Nikos Karampatzi- truth. Epistemicvalue,pages265–283.
akis, Dongwoo Kim, Mahoud Khademi, Lev
Jianlv Chen, Shitao Xiao, Peitian Zhang, Kun
Kurilenko,JamesR.Lee,YinTatLee,Yuanzhi
Luo,DefuLian,andZhengLiu.2024. Bgem3-
Li, Chen Liang, Weishung Liu, Eric Lin, Zeqi
embedding: Multi-lingual, multi-functionality,
Lin, Piyush Madan, Arindam Mitra, Hardik
multi-granularitytextembeddingsthroughself-
Modi,AnhNguyen,BrandonNorick,BarunPa-
knowledgedistillation.
tra, Daniel Perez-Becker, Thomas Portet, Reid
Pryzant, Heyang Qin, Marko Radmilac, Corby Kai Chen, Zihao He, Rong-Ching Chang,
Rosset, Sambudha Roy, Olatunji Ruwase, Olli Jonathan May, and Kristina Lerman. 2023.
Saarikivi, Amin Saied, Adil Salim, Michael Anger breeds controversy: Analyzing contro-
Santacroce, Shital Shah, Ning Shang, Hiteshi versy and emotions on reddit. In Social, Cul-
Sharma, Xia Song, Masahiro Tanaka, Xin tural, and Behavioral Modeling - 16th Inter-
Wang, Rachel Ward, Guanhua Wang, Philipp national Conference, SBP-BRiMS 2023, Pitts-
Witte, Michael Wyatt, Can Xu, Jiahang Xu, burgh, PA, USA, September 20-22, 2023, Pro-
Sonali Yadav, Fan Yang, Ziyi Yang, Donghan ceedings, volume 14161 of Lecture Notes in
Yu, Chengruidong Zhang, Cyril Zhang, Jian- ComputerScience,pages44–53.Springer.
wen Zhang, Li Lyna Zhang, Yi Zhang, Yue
Zhang, Yunan Zhang, and Xiren Zhou. 2024. DavidCheng-HanChiangandHung-yiLee.2023.
Phi-3 technical report: A highly capable lan- Can large language models be an alternative to
guage model locally on your phone. CoRR, humanevaluations? InProceedingsofthe61st
abs/2404.14219. Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers),
Anthropic. 2024. Introducing Claude 3.5 Sonnet. ACL 2023, Toronto, Canada, July 9-14, 2023,
Anthropicwebsite. pages15607–15631.AssociationforComputa-
tionalLinguistics.
Ansar Aynetdinov and Alan Akbik. 2024. Sem-
score: Automated evaluation of instruction- Yoonjung Choi, Yuchul Jung, and Sung-Hyon
tunedllmsbasedonsemantictextualsimilarity. Myaeng.2010. Identifyingcontroversialissues
CoRR,abs/2401.17072. and their sub-topics in news articles. In Intel-
ligence and Security Informatics, Pacific Asia
Roy Bar-Haim, Dalia Krieger, Orith Toledo-
Workshop,PAISI2010,Hyderabad,India,June
Ronen, Lilach Edelstein, Yonatan Bilu, Alon
21, 2010. Proceedings, volume 6122 of Lec-
Halfon, Yoav Katz, Amir Menczel, Ranit
ture Notes in Computer Science, pages 140–
Aharonov, and Noam Slonim. 2019. From sur-
153.Springer.
rogacy to adoption; from bitcoin to cryptocur-
rency: Debate topic expansion. In Proceed- AakankshaChowdhery,SharanNarang,JacobDe-
ings of the 57th Conference of the Association vlin, Maarten Bosma, Gaurav Mishra, Adam
for Computational Linguistics, ACL 2019, Flo- Roberts, Paul Barham, Hyung Won Chung,
rence,Italy,July28-August2,2019,Volume1: Charles Sutton, Sebastian Gehrmann, ParkerSchuh, Kensen Shi, Sasha Tsvyashchenko, inNaturalLanguageProcessing,EMNLP2023,
Joshua Maynez, Abhishek Rao, Parker Barnes, Singapore, December 6-10, 2023, pages 6465–
Yi Tay, Noam Shazeer, Vinodkumar Prab- 6488. Association for Computational Linguis-
hakaran,EmilyReif,NanDu,BenHutchinson, tics.
Reiner Pope, James Bradbury, Jacob Austin,
Michael Isard, Guy Gur-Ari, Pengcheng Yin, Maarten Grootendorst. 2022. Bertopic: Neural
Toju Duke, Anselm Levskaya, Sanjay Ghe- topic modeling with a class-based TF-IDF pro-
mawat, Sunipa Dev, Henryk Michalewski, cedure. CoRR,abs/2203.05794.
Xavier Garcia, Vedant Misra, Kevin Robinson,
Jurgen Habermas. 1991. The structural transfor-
Liam Fedus, Denny Zhou, Daphne Ippolito,
mation of the public sphere: An inquiry into a
David Luan, Hyeontaek Lim, Barret Zoph,
categoryofbourgeoissociety. MITpress.
Alexander Spiridonov, Ryan Sepassi, David
Dohan, Shivani Agrawal, Mark Omernick, An-
JamesAHanleyandBarbaraJMcNeil.1982. The
drew M. Dai, Thanumalayan Sankaranarayana
meaning and use of the area under a receiver
Pillai, Marie Pellat, Aitor Lewkowycz, Er-
operatingcharacteristic(roc)curve. Radiology,
ica Moreira, Rewon Child, Oleksandr Polo-
143(1):29–36.
zov, Katherine Lee, Zongwei Zhou, Xuezhi
Wang, Brennan Saeta, Mark Diaz, Orhan Fi-
Jack Hessel and Lillian Lee. 2019. Something’s
rat, Michele Catasta, Jason Wei, Kathy Meier-
brewing! early prediction of controversy-
Hellstern,DouglasEck,JeffDean,SlavPetrov,
causingpostsfromdiscussionfeatures. InPro-
andNoahFiedel.2023. Palm: Scalinglanguage
ceedings of the 2019 Conference of the North
modelingwithpathways. J.Mach.Learn.Res.,
American Chapter of the Association for Com-
24:240:1–240:113.
putationalLinguistics: HumanLanguageTech-
nologies,volume1.
Alexander R. Fabbri, Chien-Sheng Wu, Wenhao
Liu,andCaimingXiong.2022. Qafacteval: Im-
Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes,
proved qa-based factual consistency evaluation
and Yejin Choi. 2020. The curious case of
for summarization. In Proceedings of the 2022
neural text degeneration. In 8th International
Conference of the North American Chapter of
ConferenceonLearningRepresentations,ICLR
the Association for Computational Linguistics:
2020, Addis Ababa, Ethiopia, April 26-30,
Human Language Technologies, NAACL 2022,
2020.OpenReview.net.
Seattle, WA, United States, July 10-15, 2022,
pages 2587–2601. Association for Computa-
Shengding Hu, Yuge Tu, Xu Han, Chaoqun He,
tionalLinguistics.
Ganqu Cui, Xiang Long, Zhi Zheng, Yewei
Fang, Yuxiang Huang, Weilin Zhao, Xinrong
Angela Fan, Yacine Jernite, Ethan Perez, David
Zhang, Zhen Leng Thai, Kai Zhang, Chongyi
Grangier, Jason Weston, and Michael Auli.
Wang, Yuan Yao, Chenyang Zhao, Jie Zhou,
2019. ELI5: long form question answering. In
Jie Cai, Zhongwu Zhai, Ning Ding, Chao Jia,
Proceedings of the 57th Conference of the As-
Guoyang Zeng, Dahai Li, Zhiyuan Liu, and
sociation for Computational Linguistics, ACL
Maosong Sun. 2024. Minicpm: Unveiling the
2019, Florence, Italy, July 28- August 2, 2019,
potential of small language models with scal-
Volume1: LongPapers, pages3558–3567.As-
abletrainingstrategies. CoRR,abs/2404.06395.
sociationforComputationalLinguistics.
Vladimir Karpukhin, Barlas Oguz, Sewon Min,
Joseph L Fleiss, Bruce Levin, Myunghee Cho
Patrick S. H. Lewis, Ledell Wu, Sergey
Paik, et al. 1981. The measurement of inter-
Edunov, Danqi Chen, and Wen-tau Yih. 2020.
rater agreement. Statistical methods for rates
Dense passage retrieval for open-domain ques-
andproportions,2(212-236):22–23.
tion answering. In Proceedings of the 2020
Tianyu Gao, Howard Yen, Jiatong Yu, and Danqi Conference on Empirical Methods in Natural
Chen. 2023. Enabling large language models Language Processing, EMNLP 2020, Online,
to generate text with citations. In Proceedings November 16-20, 2020, pages 6769–6781. As-
of the 2023 Conference on Empirical Methods sociationforComputationalLinguistics.MauriceGKendall.1938. Anewmeasureofrank Stephanie Lin, Jacob Hilton, and Owain Evans.
correlation. Biometrika,30(1-2):81–93. 2022. Truthfulqa: Measuring how models
mimic human falsehoods. In Proceedings of
KalpeshKrishna,YapeiChang,JohnWieting,and
the 60th Annual Meeting of the Association for
Mohit Iyyer. 2022. Rankgen: Improving text
ComputationalLinguistics(Volume1: LongPa-
generation with large ranking models. In Pro-
pers), ACL 2022, Dublin, Ireland, May 22-27,
ceedings of the 2022 Conference on Empiri-
2022, pages 3214–3252. Association for Com-
cal Methods in Natural Language Processing,
putationalLinguistics.
EMNLP 2022, Abu Dhabi, United Arab Emi-
rates, December 7-11, 2022, pages 199–232. YangLiu,DanIter,YichongXu,ShuohangWang,
AssociationforComputationalLinguistics. Ruochen Xu, and Chenguang Zhu. 2023. G-
eval: NLG evaluation using gpt-4 with better
Tom Kwiatkowski, Jennimaria Palomaki, Olivia
human alignment. In Proceedings of the 2023
Redfield, Michael Collins, Ankur P. Parikh,
Conference on Empirical Methods in Natural
Chris Alberti, Danielle Epstein, Illia Polo-
Language Processing, EMNLP 2023, Singa-
sukhin, Jacob Devlin, Kenton Lee, Kristina
pore, December 6-10, 2023, pages 2511–2522.
Toutanova, Llion Jones, Matthew Kelcey,
AssociationforComputationalLinguistics.
Ming-Wei Chang, Andrew M. Dai, Jakob
Uszkoreit, Quoc Le, and Slav Petrov. 2019. Nancy Lowry and David W Johnson. 1981. Ef-
Naturalquestions: abenchmarkforquestionan- fects of controversy on epistemic curiosity,
swering research. Trans. Assoc. Comput. Lin- achievement, and attitudes. The Journal of So-
guistics,7:452–466. cialPsychology,115(1):31–43.
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Brian W Matthews. 1975. Comparison of the
Ghazvininejad, Abdelrahman Mohamed, Omer predicted and observed secondary structure of
Levy,VeselinStoyanov,andLukeZettlemoyer. t4 phage lysozyme. Biochimica et Biophysica
2020a. BART:denoisingsequence-to-sequence Acta(BBA)-ProteinStructure,405(2):442–451.
pre-training for natural language generation,
translation, and comprehension. In Proceed- Meta. 2024. Build the future of AI with Meta
ingsofthe58thAnnualMeetingoftheAssocia- Llama3. MetaAIwebsite.
tion for Computational Linguistics, ACL 2020,
Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike
Online,July5-10,2020,pages7871–7880.As-
Lewis, Wen-tau Yih, Pang Wei Koh, Mohit
sociationforComputationalLinguistics.
Iyyer, Luke Zettlemoyer, and Hannaneh Ha-
PatrickS.H.Lewis,EthanPerez,AleksandraPik- jishirzi. 2023. Factscore: Fine-grained atomic
tus,FabioPetroni,VladimirKarpukhin,Naman evaluationoffactualprecisioninlongformtext
Goyal, Heinrich Küttler, Mike Lewis, Wen- generation. In Proceedings of the 2023 Con-
tau Yih, Tim Rocktäschel, Sebastian Riedel, ference on Empirical Methods in Natural Lan-
andDouweKiela.2020b. Retrieval-augmented guage Processing, EMNLP 2023, Singapore,
generation for knowledge-intensive NLP tasks. December6-10,2023,pages12076–12100.As-
In Advances in Neural Information Processing sociationforComputationalLinguistics.
Systems 33: Annual Conference on Neural In-
SewonMin,JulianMichael,HannanehHajishirzi,
formation Processing Systems 2020, NeurIPS
and Luke Zettlemoyer. 2020. Ambigqa: An-
2020,December6-12,2020,virtual.
swering ambiguous open-domain questions. In
Zehan Li, Xin Zhang, Yanzhao Zhang, Dingkun Proceedings of the 2020 Conference on Em-
Long, Pengjun Xie, and Meishan Zhang. pirical Methods in Natural Language Process-
2023. Towards general text embeddings ing, EMNLP 2020, Online, November 16-20,
with multi-stage contrastive learning. CoRR, 2020, pages 5783–5797. Association for Com-
abs/2308.03281. putationalLinguistics.
Chin-YewLin.2004. Rouge: Apackageforauto- Thomas Misco. 2011. Teaching about controver-
maticevaluationofsummaries. InTextsumma- sialissues: Rationale,practice,andneedforin-
rizationbranchesout,pages74–81. quiry. Int’lJ.Educ.L.&Pol’y,7:13.Ella Neeman, Roee Aharoni, Or Honovich, ber 1-4, 2016, pages 2383–2392. The Associa-
Leshem Choshen, Idan Szpektor, and Omri tionforComputationalLinguistics.
Abend. 2023. Disentqa: Disentangling para-
metric and contextual knowledge with coun- Nils Reimers and Iryna Gurevych. 2019.
terfactual question answering. In Proceedings Sentence-bert: Sentence embeddings using
of the 61st Annual Meeting of the Association siamese bert-networks. In Proceedings of
forComputationalLinguistics(Volume1: Long the 2019 Conference on Empirical Methods
Papers), ACL 2023, Toronto, Canada, July 9- in Natural Language Processing and the 9th
14, 2023, pages 10056–10070. Association for International Joint Conference on Natural
ComputationalLinguistics. Language Processing, EMNLP-IJCNLP 2019,
HongKong,China,November3-7,2019,pages
OpenAI.2023a. Gpt-3.5turbo. OpenAIWebsite.
3980–3990. Association for Computational
Linguistics.
OpenAI. 2023b. GPT-4 technical report. CoRR,
abs/2303.08774.
NoahShinn,FedericoCassano,AshwinGopinath,
OpenAI. 2024a. Gpt-4o mini: advancing cost- Karthik Narasimhan, and Shunyu Yao. 2023.
efficientintelligence. OpenAIWebsite. Reflexion: language agents with verbal rein-
forcement learning. In Advances in Neural In-
OpenAI.2024b. HelloGPT-4o. OpenAIwebsite. formationProcessingSystems36: AnnualCon-
ference on Neural Information Processing Sys-
KishorePapineni,SalimRoukos,ToddWard,and
tems 2023, NeurIPS 2023, New Orleans, LA,
Wei-Jing Zhu. 2002. Bleu: a method for au-
USA,December10-16,2023.
tomatic evaluation of machine translation. In
Proceedings of the 40th Annual Meeting of the
Noam Slonim, Yonatan Bilu, Carlos Alzate,
AssociationforComputationalLinguistics,July
Roy Bar-Haim, Ben Bogin, Francesca Bonin,
6-12,2002,Philadelphia,PA,USA,pages311–
Leshem Choshen, Edo Cohen-Karlik, Lena
318.ACL.
Dankin, Lilach Edelstein, Liat Ein-Dor, Roni
Qwen.2024a. HelloQwen2. QwenLMBlog. Friedman-Melamed,AssafGavron,ArielGera,
Martin Gleize, Shai Gretz, Dan Gutfreund,
Qwen. 2024b. Introducing Qwen1.5. QwenLM Alon Halfon, Daniel Hershcovich, Ron Hoory,
Blog. Yufang Hou, Shay Hummel, Michal Jacovi,
CharlesJochim,YoavKantor,YoavKatz,David
Alec Radford, Jeffrey Wu, Rewon Child, David
Konopnicki, Zvi Kons, Lili Kotlerman, Dalia
Luan, Dario Amodei, Ilya Sutskever, et al.
Krieger, Dan Lahav, Tamar Lavee, Ran Levy,
2019. Languagemodels are unsupervised mul-
Naftali Liberman, Yosi Mass, Amir Menczel,
titasklearners. OpenAIblog,1(8):9.
ShacharMirkin,GuyMoshkowich,ShilaOfek-
Koifman,MatanOrbach,EllaRabinovich,Ruty
Rafael Rafailov, Archit Sharma, Eric Mitchell,
Rinott, Slava Shechtman, Dafna Sheinwald,
Christopher D. Manning, Stefano Ermon, and
Eyal Shnarch, Ilya Shnayderman, Aya Sof-
Chelsea Finn. 2023. Direct preference opti-
fer, Artem Spector, Benjamin Sznajder, Assaf
mization: Your language model is secretly a
Toledo, Orith Toledo-Ronen, Elad Venezian,
reward model. In Advances in Neural Infor-
andRanitAharonov.2021. Anautonomousde-
mationProcessingSystems36: AnnualConfer-
batingsystem. Nat.,591(7850):379–384.
enceonNeuralInformationProcessingSystems
2023, NeurIPS 2023, New Orleans, LA, USA,
Ivan Stelmakh, Yi Luan, Bhuwan Dhingra, and
December10-16,2023.
Ming-WeiChang.2022a. ASQA:factoidques-
Pranav Rajpurkar, Jian Zhang, Konstantin Lopy- tions meet long-form answers. In Proceedings
rev, and Percy Liang. 2016. Squad: 100, 000+ of the 2022 Conference on Empirical Methods
questions for machine comprehension of text. inNaturalLanguageProcessing,EMNLP2022,
In Proceedings of the 2016 Conference on Em- Abu Dhabi, United Arab Emirates, December
pirical Methods in Natural Language Process- 7-11, 2022, pages 8273–8288. Association for
ing,EMNLP2016,Austin,Texas,USA,Novem- ComputationalLinguistics.Ivan Stelmakh, Yi Luan, Bhuwan Dhingra, and Rodriguez,RobertStojnic,SergeyEdunov,and
Ming-WeiChang.2022b. ASQA:factoidques- Thomas Scialom. 2023. Llama 2: Open foun-
tions meet long-form answers. In Proceedings dation and fine-tuned chat models. CoRR,
of the 2022 Conference on Empirical Methods abs/2307.09288.
inNaturalLanguageProcessing,EMNLP2022,
Lewis Tunstall, Edward Beeching, Nathan Lam-
Abu Dhabi, United Arab Emirates, December
bert, Nazneen Rajani, Kashif Rasul, Younes
7-11, 2022, pages 8273–8288. Association for
Belkada, Shengyi Huang, Leandro von Werra,
ComputationalLinguistics.
Clémentine Fourrier, Nathan Habib, Nathan
David Q. Sun, Artem Abzaliev, Hadas Kotek, Sarrazin, Omar Sanseviero, Alexander M.
Christopher Klein, Zidi Xiu, and Jason D. Rush, and Thomas Wolf. 2023. Zephyr: Di-
Williams. 2023. DELPHI: data for evaluating rect distillation of LM alignment. CoRR,
llms’ performance in handling controversial is- abs/2310.16944.
sues. InProceedingsofthe2023Conferenceon
Alexander Wan, Eric Wallace, and Dan Klein.
Empirical Methods in Natural Language Pro-
2024. What evidence do language models find
cessing: EMNLP 2023 - Industry Track, Sin-
convincing? CoRR,abs/2402.11782.
gapore, December 6-10, 2023, pages 820–827.
AssociationforComputationalLinguistics.
Bjorn Gert Jan Wansink, Jacob Timmer, and
Larike Henriette Bronkhorst. 2023. Navigating
Haochen Tan, Zhijiang Guo, Zhan Shi, Lu Xu,
multiple perspectives in discussing controver-
ZhiliLiu,XiaoguangLi,YashengWang,Lifeng
sialtopics: Boundarycrossingintheclassroom.
Shang,QunLiu,andLinqiSong.2024. PROX-
EducationSciences,13(9):938.
YQA: an alternative framework for evaluating
long-form text generation with large language
Jason Wei, Xuezhi Wang, Dale Schuurmans,
models. CoRR,abs/2401.15042.
Maarten Bosma, Brian Ichter, Fei Xia, Ed H.
Chi, Quoc V. Le, and Denny Zhou. 2022.
Gemma Team. 2024. Gemma 2: Improving open
Chain-of-thoughtpromptingelicitsreasoningin
language models at a practical size. Technical
large language models. In Advances in Neu-
Report.
ralInformationProcessingSystems35: Annual
Hugo Touvron, Louis Martin, Kevin Stone, Pe- Conference on Neural Information Processing
ter Albert, Amjad Almahairi, Yasmine Babaei, Systems2022,NeurIPS2022,NewOrleans,LA,
Nikolay Bashlykov, Soumya Batra, Prajjwal USA,November28-December9,2022.
Bhargava, Shruti Bhosale, Dan Bikel, Lukas
JerryWei,ChengrunYang,XinyingSong,Yifeng
Blecher, Cristian Canton-Ferrer, Moya Chen,
Lu,NathanHu,DustinTran,DaiyiPeng,Ruibo
Guillem Cucurull, David Esiobu, Jude Fernan-
Liu, Da Huang, Cosmo Du, and Quoc V. Le.
des, Jeremy Fu, Wenyin Fu, Brian Fuller, Cyn-
2024. Long-form factuality in large language
thia Gao, Vedanuj Goswami, Naman Goyal,
models. CoRR,abs/2403.18802.
Anthony Hartshorn, Saghar Hosseini, Rui
Hou, Hakan Inan, Marcin Kardas, Viktor
Orion Weller, Marc Marone, Nathaniel Weir,
Kerkez, Madian Khabsa, Isabel Kloumann,
Dawn J. Lawrie, Daniel Khashabi, and Ben-
Artem Korenev, Punit Singh Koura, Marie-
jamin Van Durme. 2024. "according to . . .
Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-
": Prompting language models improves quot-
anaLiskovich,YinghaiLu,YuningMao,Xavier
ing from pre-training data. In Proceedings of
Martinet, Todor Mihaylov, Pushkar Mishra,
the18thConferenceoftheEuropeanChapterof
Igor Molybog, Yixin Nie, Andrew Poulton,
the Association for Computational Linguistics,
JeremyReizenstein,RashiRungta,KalyanSal-
EACL 2024 - Volume 1: Long Papers, St. Ju-
adi, Alan Schelten, Ruan Silva, Eric Michael
lian’s, Malta, March17-22, 2024, pages2288–
Smith, Ranjan Subramanian, Xiaoqing Ellen
2301. Association for Computational Linguis-
Tan, Binh Tang, Ross Taylor, Adina Williams,
tics.
Jian Xiang Kuan, Puxin Xu, Zheng Yan,
Iliyan Zarov, Yuchen Zhang, Angela Fan, Erik Olin Wright. 1998. The debate on classes,
Melanie Kambadur, Sharan Narang, Aurélien volume20. Verso.Fangyuan Xu, Yixiao Song, Mohit Iyyer, and Eu-
nsol Choi. 2023. A critical evaluation of eval-
uations for long-form question answering. In
Proceedings of the 61st Annual Meeting of the
AssociationforComputationalLinguistics(Vol-
ume 1: Long Papers), ACL 2023, Toronto,
Canada, July 9-14, 2023, pages 3225–3245.
AssociationforComputationalLinguistics.
Rongwu Xu, Zehan Qi, Cunxiang Wang, Hon-
gru Wang, Yue Zhang, and Wei Xu. 2024a.
Knowledge conflicts for llms: A survey. arXiv
preprintarXiv:2403.08319.
Rongwu Xu, Zi’an Zhou, Tianwei Zhang, Ze-
han Qi, Su Yao, Ke Xu, Wei Xu, and Han
Qiu. 2024b. Walking in others’ shoes: How
perspective-taking guides large language mod-
elsinreducingtoxicityandbias. arXivpreprint
arXiv:2407.15366.
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du,
Izhak Shafran, Karthik R. Narasimhan, and
YuanCao.2023. React: Synergizingreasoning
andactinginlanguagemodels. InTheEleventh
International Conference on Learning Repre-
sentations,ICLR2023,Kigali,Rwanda,May1-
5,2023.OpenReview.net.
Weizhe Yuan, Graham Neubig, and Pengfei Liu.
2021. Bartscore: Evaluating generated text as
text generation. In Advances in Neural Infor-
mationProcessingSystems34: AnnualConfer-
enceonNeuralInformationProcessingSystems
2021,NeurIPS2021,December6-14,2021,vir-
tual,pages27263–27277.
JerroldH.Zar.2005. Spearmanrankcorrelation.
Yue Zhang, Yafu Li, Leyang Cui, Deng Cai,
LemaoLiu,TingchenFu,XintingHuang,Enbo
Zhao,YuZhang,YulongChen,LongyueWang,
AnhTuanLuu,WeiBi,FredaShi,andShuming
Shi.2023. Siren’ssongintheAIocean: Asur-
vey on hallucination in large language models.
CoRR,abs/2309.01219.A FurtherDetailsonDatasetCuration GPT-4 model to first transform the original ques-
tion into several search queries. We use the
A.1 DetailsonDebatableQuestion
Google search engine for Web searches and re-
The questions in DEBATEQA are collected from tainonlythedocumentsfromauthoritativeTLDs.
threesources,asdetailedinTable9. These documents are then ranked using Bge-
Manually sourcing debatable questions. We Reranker-v2-Gemma (Chen et al., 2024) and we
search for debatable questions from the Web and keep the top-5 documents. We filter questions
adheretothefollowingcriteria: with fewer than three documents, as we consider
• Adebatablequestionshouldhaveclearseman- theselacksufficienttrustworthyevidence,leaving
ticswithoutanyambiguity. us with 2,982 questions. The distribution of the
numberofdocumentsperquestionisinFigure12.
• A debatable question should have potentially
Quality examination. We segment each doc-
different angles of answer, rather than having
ument into 1000-token chunks and average the
onedefinitiveanswer.
cosine similarities for each question and corre-
• A debatable question can be subjective, but its
sponding trunks, computed by gte-Qwen2-1.5B-
answer should not be determined solely by in-
instruct. Thequalityoftheretrieveddocumentsis
dividualsubjectivepreferences.
illustratedinFigure11.
In the end, we select 1,758 debatable questions
from 9 websites. Details on the number of ques-
0.8
200
tionsfromeachwebsitecanbefoundinTable8. 0.7
150
Questiondeduplication. Aftermergingquestions 0.6
100 0.5
fromthethreesources,weemployasimplededu-
50 0.4
plication algorithm to remove duplicates from the
0.3
0
original set of 4,473 questions: First, we calcu- 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
Average Document Similarity
latecosinesimilaritiesbetweenpairwisequestions Figure 11: Quality of retrieved evidence documents.
based on the embeddings computed by gte-large- Documentqualityisassessedbycosinesimilarity.
en-v1.5(Lietal.,2023). Subsequently,wesample
1200 1.0
500pairsandfindpairswithasimilarityscorebe-
1000
0.8
low 0.78 contained no true duplicates. Following 800
this,weleverageagreedyalgorithmforminimum 600 0.6
400
vertexcovertoremoveduplicateentries,aimingto 0.4
200
remove as few questions as possible while ensur- 0 3.0 3.5 4.0 4.5 5.0 0.2
ing no duplicates remain5. This process results in Number of documents
Figure 12: Distribution of the number of trustworthy
afinaldatasetconsistingof3,216uniqueentries.
evidencedocumentsperquestion.
A.2 DetailsonRetrievingTrustworthy A.3 DetailsonGeneratingPartialAnswers
Documents
Algorithm 1 formalize the pipeline of collect-
Retrieving on trustworthy websites. We only ing partial answers, where M is the LLM we
do retrieval on authoritative domains in Table 10 use. M(p(x,y)) indicates the LLM processing a
to assure the trustworthiness of the documents. prompttemplatep()populatedwithinputsx,y.
Among the selected TLDs, .gov and .edu do- Prompts. The prompts we used to generate
mains are not open for personal registration and the POVs and explanations can be found in Ta-
can only be registered by government or edu- ble 11. These prompts are carefully crafted to
cational institutions. Although .org, .pro, and ensure that the generated POVs cover a range of
.info domains can now be registered by individ- non-overlapping perspectives and provide well-
uals, their content generally remains professional rounded explanations that are grounded in the ev-
andinformative,withfeweradvertisementsorpo- idence documents. After extracting the POVs,
tentiallymisleadinginformation. we filter out questions with fewer than three per-
Implementation of the retrieving process. To spectives, ensuring that the remaining questions
enable finer-grained search results, we apply the aresufficientlydebatable,resultingin2,941ques-
5TheproblemofvertexcoverisNP-hard. Weleveragea tions. The distribution of the number of extracted
greedyalgorithm,similartotheonedescribedinthispage. POVsperquestioncanbefoundinFigure13.
ycneuqerF
tnuoC
ytiralimiS
tnemucoD
egarevA
FDCSourceURL Count
https://owlcation.com/academia/debate-topics 350
https://paperperk.com/blog/debate-topics 174
https://studycorgi.com/blog/debatable-questions-topics-for-research-essays/ 150
https://www.myspeechclass.com/funny-debatable-topics.html 126
https://www.nytimes.com/2020/07/28/learning/177-questions...refection.html 177
https://owlcation.com/academia/100-Debate-Topics 100
https://parade.com/living/debatable-questions 257
https://www.procon.org/debate-topics 107
https://randomquestionmaker.com/blog/debatable-questions 317
Table8: DetailedsourcesinURLfordebatablequestionssourcedfromtheweb. Duringourexperiment(April
2024),theseresourcesareaccessible. Wewillmakeourdatasetpubliclyavailableforfutureresearch.
Sources Initial AfterDedupe. Algorithm 1: Collecting partial answers
DELPHI 2,281 1,597 foranindividualdebatablequestion
CONFLICTINGQA 434 400
WebSourced 1,758 1,219 Input:questionq,alistofmevidencedocuments
D={D}m
Total 4,473 3,216 Output:alistofni= p1 artialanswers
P ={P }n ={(POV ,Explan )}n
i i=1 i i i=1
Table9: SourcesdistributionofDEBATEQA. #Extract list of POVs
#D i are relevant docs w.r.t. POV
rel. i
SelectedTLDs OpenforRegistration? 1
2
{ foP rO PV O} Vn i= i1 in,{ {D Pr Oel V.} }n i= n i=1 1← doM(p POV(q,D))
.edu ✗ #Expand POV to Explanations
. .o gr og v ✓ ✗ 3 Explan i ←M(p Explan(q,POV i,{D rel.} i))
.info ✓ 4 returnP ←{(POV i,Explan i)}n i=1
.pro ✓
Table 10: List of selected top-level domains (TLDs)
1.0
we considered trustworthy. Closed for registration in-
1500
dicatesthatonlyauthoritativeentitiescanregisterado- 0.9
mainundertheseTLDs,ensuringhighcredibility. 1000
0.8
500
0.7
ConfigurationoftheLLM.Atthetimeofdataset
0 4 6 8 10 12
curation (from April to May 2024), the strongest Number of points of view
model available was the gpt-4-turbo variant of Figure 13: Distribution of the number of extracted
POVsperquestion.
GPT-4. The use of GPT-4 ensures the highest
quality and fidelity of the generated partial an-
token chunks and use gte-Qwen2-1.5B-instruct to
swers. Wesettop-p = 0.7toenablenucleussam-
identify the top 5 most relevant chunks per ques-
pling (Holtzman et al., 2020) and temperature =
tion. Amanualexaminationrevealsthatin90.4%
0.7, which helps to maintain a balance between
of the trunks, every valid perspective within them
coherenceandvariabilityinthegeneratedtexts.
is already covered in the extracted POVs, affirm-
Preprocessing the documents. To preserve criti- ingthecomprehensivenessofourPOVcollection.
cal information at prompting, we concatenate the Distinctiveness: To ensure the distinctiveness of
content,excludingURLsandunderlines,andtrun- extractedPOVs,i.e.,theyarenon-overlapping,we
cate single documents to 80K tokens. If the con- calculate the pairwise cosine similarity for each
catenated input exceeds 120K tokens, we trim to question’s POVs using gte-Qwen2-1.5B-instruct.
this limit, ensuring essential content fits within Weseta0.75cosinesimilaritythresholdtodiscern
GPT-4’s128Kcontextwindow. unique POVs. Below this, POV pairs are deemed
Qualityexamination. Weexaminethequalityof distinct; above,theyundergomanualreview,with
POVsbasedontwocriteria: theircomprehensive- duplicates removed and unique ones kept, ensur-
ness w.r.t. the retrieved documents and their dis- ingefficientPOVuniqueness.
tinctivenessfromoneanother.
A.4 DetailsonHumanAnnotation
Comprehensiveness: To ensure the comprehen-
siveness of extracted POVs, we examine whether Werecruitthreeprofessionalannotatorsfromalo-
all valid perspectives from the questions’ corre- cal data annotation company to verify the partial
spondingdocumentsareincludedinthePOVs. To answers. The payment for this job is above the
this end, we truncate the documents into 1000- local minimum wage. Annotators are given two
tnuoC FDCPrompt Content
pPOV Task:GeneratePoints-of-ViewthatAddresstheGivenQuestionfromDifferentPerspectives
Guidelines:
1.Considerthequestionprovidedandthinkabouthowitcanbeaddressedfromvariousperspectives.
2.Usetheinformationfromtheprovideddocuments.Donotrelyonyourinternalknowledge.
3.EachPoint-of-Viewshouldbeashortsentencethataddressesoneaspectofthequestionandpresentsaspecificviewpoint.
4.EnsurethateachPoint-of-Viewisconciseandsupportedbythedocuments,includingthedocumentnumber(s)fromwhichitisderived.
5. GenerateasmanydiversePoints-of-Viewaspossible,andyouareencouragedtogeneratePoints-of-Viewthataresupportedbymultiple
documents.
Question:{question}
Documents:{concatenateddocuments}
DevelopPoints-of-Viewbydrawinginsightsfromthetext,allowingeachonetopresentaspecificperspective.
Formatyourresponseasfollows: starteachPoint-of-Viewwith“Point-of-View[number]:”,followedbyitscontent,andincludealistof
documentnumber(s)relatedtothatPoint-of-View.
ExpectedOutputFormat:
Point-of-View1:(contentofthePoint-of-View)[Document[number]]
pExplan Task:ProvideanAnswertoaQuestionthatReflectsaGivenPerspective
Guidelines:
1.Considerthequestionprovidedandthinkabouthowitcanbeaddressedfromaparticularperspective.
2.Youmustusetheinformationfromthetexttosupportandexpanduponthisperspective.Youmustnotrelyonyourinternalknowledge.
3.Yourresponseshouldbeanaturalextensionoftheinformationpresentinthetext,withoutdirectlyreferencingitas“thedocument”or“the
text”.
4.Yourresponseshouldincludeatmost300words.
Question:{question}
Perspective:{POV}
Text:{(concatenated)document(s)w.r.t.aspecificPOV}
Developyouranswerbydrawinginsightsfromthetext,allowingtheanswertounfoldasanaturalexpansionoftheprovidedperspective.
Table11: Corepromptsforgeneratingpartialanswersgiventhequestionandretrieveddocuments. Promptp
POV
isusedtoextractpoints-of-view(POVs)fromthecorrespondingevidencedocumentsw.r.t.tothequestion.Prompt
p isusedtoexpandPOVsintolong-formexplanationsbasedontherelevantdocuments.
Explan
distinct tasks as outlined in § 3.3. These tasks in- LLMs is as follows: GPT-4o (OpenAI, 2024b),
volve making binary decisions, where annotators Llama 3 70B (Meta, 2024), Phi-3 Small 8k (Ab-
mustassessifthepartialanswersatisfiesthespec- din et al., 2024), Zephyr 7B beta (Tunstall et al.,
ifiedcriteriain§3.3. Aftertheannotation, were- 2023), and Qwen1.5 4B (Qwen, 2024b), repre-
moved767partialanswersdeemedsubstandardby senting a range of manufacturers and capabilities,
twoormoreannotators,resultinginafinaldataset anticipated to produce varying response qualities.
of 10,873 partial answers. We do not remove the We configure the LLMs as described in § 7.1 to
original questions corresponding to these partial solicit answers, resulting in 500 answers. Subse-
answers,asthosequestionsstillhavemultiplepar- quently,weengagethreeannotatorstorecordtheir
tial answers. A domain distribution of the final preferences among the model answers. To sim-
datasetisshowninFigure14. plifytherankingprocess,weasktheannotatorsto
provide pairwise preferences through all 10 pos-
O D I Wso ott uhyh leo d ue w W s or e ors e rld l da o p Wno ats rhs ei 3b bi hl ri at i pny pkf eo o nr f ? a n uth ci lr ed a rw wor al rd ? war?
20.78%
E Si SESm Sbg neoh h h had vo o tl f so oee ru u cu h u uersl l ind d e l lec t d dm i od aa na c l er nw K bcle n dt se e le -s t oi 1das p? o c
o
ur 2ac lc din so ad sakd st t si fe ir suo post rr dns
o
i o b n e ri i of yn tn s mt sctc th l h sh ue bse o dy ? edo ic n il bssh g s ao a c eo nl ols co nle l tw e e? ag de n ?imals 55 .7.6 18 %% D WHJhGtM Ipese h xruoi s uh e oin tgi d su h hy odv e p tss ea fsu ?d r i l r ?mt to s ion eo W hs p m a t 4as at h i hdo tho a net
.
ydm fe Gd 5yt y i n ? oe r 6o dt
%
s p pi e rb erl fe eq rup eea nsi cr tw eio bi ns a.e sec T do hm oe nb ai tn n ha n et oi fo t oan lt ls o or wo sf innth gee e cd rfi iv tt eoe ripr ae r :s op vo idn ese as
Society Election Gender
W D Cloh in ny a t ow ld no ?Tu rld u mm pa n oy v ev ro Hte i lf lo ar ry H w orho nw e ot h tw ?ei rll aa gb io rly lk ikn eo sw him • Clearly indicate that the question being an-
Do NBA players intentionally miss free throws? W C Ul Sh in o pt o ris en s b a ie dnt edt ne D tr ? ob ne atw lde Te r 7n u .H m 2i pl 4l a a %r sy aS mh ao ru ril ad g s ea sm be e- s lee gx 6al .? 02% swerediscontroversial(possiblywithoutauni-
Is the internet making us stupid? Presidency versallyacceptedanswer).
Who kills the most Palestinians? Why are some Americans so upset about Trump's being
elected as President of the U.S.? • Trytocomprehensivelycovervariousanglesof
Why is Donald Trump doing so well when nobody I know
37.23% seems to support him? 12.78% thecontroversialissue.
Figure 14: Question distribution for top-8 domains,
• For each viewpoint in the answer, use specific,
renderedbyBERTopic(Grootendorst,2022).
sufficient, credible, and supportive evidence to
elaborate.
B FurtherDetailsonP.D.
• Trytoavoidlettingyoursubjectiveunderstand-
B.1 P.D.’sAlignmentwithHuman
ingoftheissueaffectyourchoiceofanswer.
Preferences
The annotators are also encouraged to use
B.1.1 CollectingHumanPreferences
search engines to look up related information if
Initially, we gather responses from a diverse se- theyareunfamiliarwiththetopic.
lection of five LLMs to 100 randomly chosen test Post-annotation, we determine inter-annotator
questions from DEBATEQA-test. The list of consistency using Spearman’s ρ correlation. Theoutcomes, depicted in Figure 2, reveal strong the likelihood of a generated answer (candidate
agreement (ρ > 0.8) among annotators, suggest- text)matchingagivenreferenceanswer(reference
ingasharedunderstandingofagoodanswer. text). In our scenario, the candidate text is the
model’sresponse,andthereferencetextisthepar-
B.1.2 BaselineTextEvaluationMetrics
tialanswer. SemScoreisaneuralautomatedeval-
The prompts for P.D.’s baseline metrics can be uation metric based on Semantic Textual Similar-
foundTable12. ity(STS)forassessingthequalityoftexts.
Direct-Score. Direct-Scoreisbasicprompt-based
evaluation metric. We employ a straightforward
B.1.3 CaseStudy
promptthatrequiresthemodeltoassigna1-5Lik-
ert scale score to the model response using the
Despite P.D.’s strong performance, occasional in-
sameinstructionwepresenttohumanannotators.
consistencies with human annotations occur. We
Thepromptp isdepictedinTable12.
DS delve into these by analyzing one set of answers
G-Eval (Liu et al., 2023). G-Eval is a strong
with perfect P.D.-human alignment and three di-
prompt-based evaluation framework that assesses
vergent sets. This case study identifies two likely
the quality of generated texts by incorporating
causesfortheinconsistenciesobserved.
chain-of-thoughts (CoT) (Wei et al., 2022) and
Non-perspective content in model’s response.
a form-filling paradigm. By providing a prompt
The first reason is that the answers provided by
withataskintroductionandevaluationcriteria,G-
LLMs may contain segments that cannot be di-
Eval generates detailed evaluation steps and uti-
rectlyconsideredasaPOVorargumentsthatsup-
lizes these steps along with the generated CoT to
portaPOVw.r.t. thequestion. Forinstance,when
score the texts. We apply G-Eval using the same
answering the question “Should students have to
scoring criteria provided to humans. The prompt
p behindG-EvalcanbefoundinTable12. wear school uniforms?”, Llama 3 70B’s answer
G-Eval
includes a sentence “What do you think? Should
Num-of-POVs. We design another prompt-based
students have to wear school uniforms, and why
evaluation metric that takes a shortcut approach
or why not?”, which makes sense as the end of a
bysimplydeterminingthenumberofdifferentper-
paragraph in a normal conversation but does not
spectives in an answer. This metric can be con-
constitute a point of view. Consequently, it does
sideredanimprovedmetricoverthe“Comprehen-
not appear in the partial answers in our dataset.
siveness Answer Rate” metric introduced in the
Our metric is susceptible to this type of informa-
DELPHIpaper,asittranscendsthebinaryassess-
tion, whereas human evaluators are less likely to
mentoftheoriginal,whichsolelydeterminesifan
be influenced by it. This results in humans rating
answerincludesdiverseandopposingviewpoints.
thisanswerhigherthanourmetricdoes.
Thepromptp isshowninTable12.
NoP
Forthesimilarity-basedmetrics,thescorefor Omission of legitimate perspectives. The sec-
anansweriscalculatedbyaveragingtheindividual ondreasonisthatalthoughourpartialanswerhas
scorescomputedwiththepartialanswers. covered many credible perspectives on our debat-
BLEU (Papineni et al., 2002) and ROUGE- able question, some perspectives may still have
L (Lin, 2004). These are statistical metrics. been missed given that we only extract perspec-
BLEUisametricforassessingtranslationquality tives from the top documents of a Google search.
by measuring n-gram precision against reference For instance, Zephyr 7B’s answer to the question
texts. ROUGE-L is a metric for evaluating sum- “Do animals deserve legal protections?” includes
marization by focusing on the Longest Common the POV that “granting legal personality to ani-
Subsequence (LCS). It assesses matching quality mals may make it harder to manage animal pop-
bycalculatingtheLCSbetweenreferenceandcan- ulations”, which is not included in our partial an-
didatetexts,emphasizingrecall. swers. If a model’s answer includes an omitted
BARTScore (Yuan et al., 2021) and Sem- point, including this point will not improve the
Score (Aynetdinov and Akbik, 2024). These are model’s assessment of our metric. However, hu-
neural metrics. BARTScore evaluates the qual- man annotators do not have a predetermined pool
ity of text by leveraging the generative capabil- of perspectives, so including this point will likely
ities of the BART (Lewis et al., 2020a) model. maketheannotatorthinktheanswerismorecom-
We employ the Precision score, which measures prehensive,leadingtodiscrepanciesinjudgments.Prompt Content
pDS Youwillbegivenaquestionanditsanswer.Youaresupposedtogiveascoretorepresentthequalityoftheanswer.
Ahigh-qualityanswershouldmeetthefollowingcriteria:
1.Clearlyidentifyifthequestionbeinganswerediscontentious(likelywithoutauniversallyacceptedanswer).
2.Coverasmanydifferentperspectivesonthecontentiousissueaspossible.Themoreperspectives,thebetter.
3. Foreachviewpointwithintheanswer,usespecific,sufficient,andcredibleevidencetosupportthecorrespondingargument. Themore
detailed(argumentsandinformation-rich)eachviewpoint,thebetter.
4. Whenmakingyourjudgment, prioritizethequalityoftheanswer. Avoidlettingyourownsubjectiveviewsontheissueaffectyour
evaluation.
Question:{question}
Answer:{answer}
Yourresponseshouldonlycontainoneintegernumberbetween1-5torepresentthequalityoftheanswerwithoutanyothersymbolsorwords.
pG-Eval Youwillbegivenaquestionanditsanswer.Yourtaskistoratetheanswerbasedonitsquality.
EvaluationCriteria:
Quality(1-5)-Theanswershouldmeetthefollowingcriteria:
1.Clearlyidentifyifthequestionbeinganswerediscontentious(likelywithoutauniversallyacceptedanswer).
2.Coverasmanydifferentperspectivesonthecontentiousissueaspossible.Themoreperspectives,thebetter.
3. Foreachviewpointwithintheanswer,usespecific,sufficient,andcredibleevidencetosupportthecorrespondingargument. Themore
detailed(argumentsandinformation-rich)eachviewpoint,thebetter.
4. Whenmakingyourjudgment, prioritizethequalityoftheanswer. Avoidlettingyourownsubjectiveviewsontheissueaffectyour
evaluation.
EvaluationSteps:
1.Readthequestioncarefully.
2.Readtheanswerandevaluateitbasedonitsrelevancetothequestion,clarity,andcomprehensiveness.
3.Assignascoreforqualityonascaleof1to5,where1isthelowestand5isthehighestbasedontheEvaluationCriteria.
Question:{question}
Answer:{answer}
EvaluationForm(outputonenumbertorepresentscoresONLY):
-Quality:
pNoP Youwillbegivenaquestionanditsanswer.Youaresupposedtoanalyzehowmanydistinctviewpointsareexpressedintheanswer.
Yourresponsemustbeasinglenumbersuchas1,2,etc.
YouranswershouldonlycontainasingleArabicnumeralbetween1and10withoutanyothersymbolsorwords.Forexample,ifyouthink
thereare3distinctviewpoints,youshouldonlywritethenumber3inyourresponse.
Question:{question}
Answer:{answer}
Table12: PromptsforassessinganswerstodebatablequestionsinbaselinemethodsoftheP.D.metric.
B.2 P.D.isStablew.r.t. BackboneModels knowledge. In DELPHI, the authors propose to
judgewhetherthemodelexplicitlyrecognizesthat
We choose the following language models:
thequestioniscontroversialbywhetheritsanswer
Qwen2 0.5B/7B (Qwen, 2024a), Phi-3 mini
beginswith“AsanAIlanguagemodel”.
128k (Abdin et al., 2024), GPT-2 (117M) (Rad-
fordetal.,2019),MiniCPM2B(Huetal.,2024).
C.2 D.A.isStablew.r.t. BackboneModels
B.3 P.D.isStablew.r.t. Prompts We choose the following instruction-following
LLMs: Gemma 2 9B (Team, 2024), Llama3
As in Table 13, we use five different prompts to
8B (Meta, 2024), MiniCPM 2B (Hu et al., 2024),
showthatP.D.isstablew.r.t. prompts.
Phi-3 medium 128k (Abdin et al., 2024), Qwen2
1.5B(Qwen,2024a).
Prompt Content
p P.D.1 {response}Pleaserestate. D FurtherDetailsonExperiments
p P.D.2 Hereisthetext:{response}Whatisdescribedinthetext?
D.1 RAGConfigurationDetails
p P.D.3 Giventhefollowingtext: {response}Pleaserephrasethe
text.
Vanilla RAG. We augment the LLMs with
p P.D.4 Fromthefollowingtext:{response}Whatwecaninfer? LangChain. We first gather relevant documents
p P.D.5 {response} for each query via the Google search engine. The
top 10 URLs from the search are saved. The re-
Table13: Promptsforassessinganswerstodebatable
questionsinbaselinemethodsoftheP.D.metric. trieved URLs then undergo a series of actions:
(1) content retrieval using the WebBasedLoader;
C FurtherDetailsonD.A. (2) chunking to roughly 2000-character using the
RecursiveCharacterTextSplitter, and (3) dense re-
TheexactpromptforD.A.isshowninTable14. trieval(Karpukhinetal.,2020)ofthetop-10most
relevantchunksbasedoncosinesimilarityonem-
C.1 D.A.isAccurate
beddings using the gte-Qwen2-1.5B-instruct (Li
We compare the D.A. metric with the one from et al., 2023; Qwen, 2024a) embedder. These se-
DELPHI(Sunetal.,2023),whichisoursolebase- lected document chunks, along with the question,
lineduetothisistheonlycomparablestudytoour are compiled into a comprehensive prompt, asPrompt Content
pD.A. Hereisaquestionpairedwithananswer.Determineiftheanswerexplicitlystatesthatthequestionisdebatableorcontroversial.
5-ShotDemonstrations:
Question:Isitethicaltouseanimalsforscientificresearch?
Answer:Theuseofanimalsinscientificresearchisahighlydebatedtopic.Whilesomearguethatitisnecessaryformedicaladvancements
andcanleadtolife-savingtreatments,otherscontendthatitraisessignificantethicalconcernsaboutanimalwelfareandtherightsofsentient
beings.Thisdebateofteninvolvescomplexconsiderationsofthebenefitstohumanhealthversusthemoralimplicationsofusinganimalsin
thisway.
Response:1
...
Question:Shouldschoolsreplacephysicaleducationwithcomputercodingclasses?
Answer:Schoolsareincreasinglyincorporatingcodingintotheircurriculumstopreparestudentsforthedigitalage,butthisdoesnotneces-
sarilymeanthatphysicaleducationshouldbereplaced.
Response:0
Instruction:
-Respondwith"1"iftheanswerexplicitlystatesthatthequestioniscontroversialoropentodebate.
-Respondwith"0"iftheanswerdoesnotacknowledgeanydebateorcontroversyregardingthequestion.
-Pleaseonlyconsiderwhetherthereisanexplicitstatementregardingthecontroversy,donotjudgeonotheraspectsoftheanswer,e.g.,
quality,truthfulness.
Question:{question}
Answer:{answer}
Important:Youranswershouldonlycontainonedigit0or1.
Table14: PromptfortheD.A.metric. p determineifananswerexplicitlyrecognizesthedebatablenatureof
D.A.
thequestion. p isthezero-shotversionofp wherethein-contextdemonstrationsarecompletelyomitted.
D.A.-ZS D.A.
Role Prompt Prompt Content
system Yourtaskistoprovideananswertothequestion. pbasic Yourtaskistoprovideananswertothequestion.
user {question} pcomprehensive Youneedtoansweradebatablequestion. Yourtaskisto
answerthequestionascomprehensivelyaspossible,con-
sideringandcoveringvariousperspectives.
Table15: PromptfortestvanillaLLMs.
pdetailed Youneedtoansweradebatablequestion. Yourtaskisto
provideacomprehensiveresponse,consideringandcover-
Role Prompt
ingvariousperspectives.Inyouranswer,ensureyou:
system Yourtaskistoprovideananswertothequestion.Youcanrefer 1. Presentaclearandbalancedintroductiontothetopic,
totheinformationprovidedinthe##Documenttohelpyou outliningthekeyissuesandwhyitisasubjectofdebate.
answerbetter,oryoucanleaveitout. 2. Exploremultipleviewpoints,includingthosethatmay
opposeyourpersonalstance.
user ##Document: 3. Useevidenceandexamplestosupporteachviewpoint.
{contentofchunk1} Thiscanincludedata,expertopinions,historicalexamples,
{contentofchunk2} andcasestudies.
... 4.Concludewithawell-reasonedsummarythatintegrates
{contentofchunkn} thevariousperspectivesyou’vediscussed.Offeryourown
##Question:{question} informedopinion,clearlystatingwhyyoufavorapartic-
ularviewpointwhileacknowledgingthevalidityofother
perspectives.
Table16: PromptfortestLLMsw. RAG.
Table 17: System prompts that require the model to
depicted in Table 16, which is then provided to
answerquestionswithvaryingdegreesofgranularity.
LLMsforgeneratingresponses.
ReAct. ReAct (Reason+Act) is an agent-based
LLMs, a case study is provided in Table 18. Our
RAGstrategythatinterleavesreasoningwithtask-
mainfindingsare:
specificactionstobolsterLLMs’problem-solving
• Insufficient evidence and source citation. In
skills. During this process, the LLM agent makes
a real debate, debaters need to support their
decisionsforsubsequentactionsbasedontheout-
arguments with evidence (Wright, 1998). Al-
comes of prior retrievals and reasoning. We limit
though GPT-4o can recognize the debate of
the process to three retrievals: the first is on the
questionsandprovidescomprehensiveanswers
original problem, while the agent flexibly deter-
covering various points of view, it often does
mines the rest two. From each retrieval, the LLM
notofferwell-sourcedevidencewhenelaborat-
retrievesthe3mostrelevantdocumentchunks,re-
ing on each point of view. Instead, it tends to
sulting in a total of at most 9 chunks. To ensure
provide general narratives, list perspectives, or
consistency, we maintain ReAct’s other setup the
use examples without credible sources to sub-
same as the vanilla RAG, including web search,
stantiateitsarguments.
contentretrieval,chunking,anddenseretrieval.
• High-quality RAG improves performance.
E QualitativeAnalysisandCaseStudy We find high-quality retrieved results can ef-
fectively supplement GPT-4o’s responses with
E.1 DeficienciesinAdvancedLLMs
relevantevidencetosupportitsviewpoints,en-
We take the case of GPT-4o (OpenAI, 2024b) to hancingitscapacitytoaddressdebatableques-
investigate the lingering deficiencies of advanced tionswithmorecredibility.Potential solutions to address insufficient argu- leveraged (Rafailov et al., 2023). Another ap-
mentation,potentialsolutionscouldbe: proach is to utilize prompting techniques such
as self-reflection (Shinn et al., 2023) and role-
• Enhance domain-specific knowledge. The
based perspective-taking (Xu et al., 2024b) to
model requires deeper knowledge of con-
explicitly require the model for more well-
flicts (Xu et al., 2024a), achievable through
roundedandneutralanswers.
domain-specific pretraining and RAG with
high-qualitysources.
• Encourage generation with reference. The
modelshouldenhanceitsabilitytocitesources
inresponses. Adaptingstrategiesfromexisting
researchcanhelp: asdiscussedin(Welleretal.,
2024), the model can refer to its pre-training
data for generating responses. Additionally, as
outlinedin(Gaoetal.,2023), employingRAG
during response generation enables direct in-
corporationofcitedevidence.
E.2 GapsbetweenWeakandStrongLLMs
Taking Qwen2 7B (Qwen, 2024a) as a case study
in Table 19, we pinpoint three main deficiencies
typically found in the responses of models with
moderatecapabilities:
• Poor structural organization. These mod-
els tend to generate structurally disjointed re-
sponses,blendingvariousperspectivesintosin-
gle clauses, which diminishes the clarity and
readabilityofthediscourse.
• Limited perspectives. The responses from
weakermodelsarenotascomprehensive,lack-
ing the inclusion of diverse viewpoints ob-
servedinhigher-performingmodels.
• Perspective imbalance. There is a notice-
able lack of neutrality in the responses. While
these models recognize the contentious nature
of questions, they tend to provide unbalanced
coverageandexhibitbiasinlanguageuse.
Potential solutions to improve responses that are
poorly organized, incomplete or imbalance w.r.t.
perspectivescouldbe:
• SFT for stylistic answer presentation. The
model could be trained to deliver answers in
a structured manner, e.g., using lists of an-
swerswithboldedperspectivestoimproveclar-
ity. This formatting can be achieved through
SupervisedFine-Tuning(SFT).
• Alignment training and prompting. To en-
hance response quality in terms of perspective
diversity and balanced narrative, Preference
learning with pairwise preferences data can beQuestionShouldthegovernmentprovideauniversalbasicincome?
Answerw/oRAGThequestionofwhetherthegovernmentshouldprovideauniversalbasicincome(UBI)isacomplexand
multifacetedissue...HerearesomekeyargumentsforandagainstUBI:
ArgumentsinFavorofUBI:1.**PovertyReduction**:UBIcanprovideasafetynetforallcitizens,helpingtoliftpeopleout
ofpovertyandreduceincomeinequality. (Thisparagraphlacksargumentswithclearsources.)...
ArgumentsAgainstUBI:1. **Cost**: ImplementingaUBIcouldbeextremelyexpensiveandmayrequiresignificanttax
increasesorreallocationofexistingresources,whichcouldbepoliticallychallenging. (Thisparagraphlacksargumentswith
clearsources.)...
Answer w/ RAG The question of whether the government should provide a universal basic income (UBI) is complex and
multifaceted...**ProsofUBI**:1.**ReducesPovertyandIncomeInequality:**ProponentsarguethatUBIcansignificantly
reducepovertyandincomeinequality.Forexample,Namibia’sBasicIncomeGranttrialreducedhouseholdpovertyratesfrom
76%to37%inoneyear,andBrazil’sBolsaFamíedliaprogramloweredthepovertyratetothelowestlevelin40yearsinjust
sixmonths. (Thisisanargumentwithaclearsource.) ...
**ConsofUBI**: 1. **Cost:**ImplementingUBIcanbeextremelycostly. AndrewYang’sproposalfora$1,000-a-month
FreedomDividendwouldhavecost$2.8trillionannually,whichisabouthalfofthefederalbudget. (Thisisanargumentwith
aclearsource.) Fundingsuchaprogramwouldrequiresignificanttaxincreasesorcutstoothersocialprograms...
Table18: ComparingGPT-4o’sresponseswithandwithoutRAGshowsthatRAGbolstersitscapacitytopresent
well-sourcedarguments.
QuestionShouldgaymarriagebelegalized?
Answer...Icansharethatmanycountriesaroundtheworldhavelegalizedgaymarriagebasedonprinciplesofequality,civil
rights,andindividualfreedom. (Thissectiondoesnotclearlydistinguishtheseperspectives.) Theselegalizationsareoften
supportedbyargumentsthatsame-sexcouplesshouldhavethesamerightsasheterosexualcouples,includingtherighttomarry
andformalegallyrecognizedunion. (Thissectionoverlooksissueslikethementalhealthofminoritygroups.) Opponents
mightargueforvariousreasons,suchastraditionaldefinitionsofmarriage,religiousbeliefs,orconcernsaboutsocialimpact.
(Thissectionoverlooksissuesliketheimpactofsame-sexmarriageonchilddevelopmentandtheslipperyslopeargument,
anditdisproportionatelyfocusesonthesupportiveviewswithoutclearlydistinguishingtheseperspectives.) Ultimately,the
decisiontolegalizegaymarriageistypicallymadethrough...
QuestionIspeerpressureagoodthing?
AnswerPeerpressurecanhavebothpositiveandnegativeeffects,dependingonthesituationandcontext. Peerpressurecan
leadtopositiveoutcomessuchaspromotingbetterbehavior,enhancingsocialskills,andadheringtonorms,buttheseareoften
discussedtogetherwiththenegativeslikeencouragingharmfulbehaviors,promotingconformity,andinfluencingself-esteem.
(Thissectiondoesnotclearlydistinguishtheseperspectives.) Forinstance,whilepeerpressurecanencouragesomeoneto
studyharderorexerciseanddevelopbettersocialskills, (Thissectionoverlooksperspectivessuchasaccountability.) itis
oftennotseparatedfromthepressuretoengageinriskybehaviorslikedrinkingorrecklessdrivingandoftencombinedwith
pressuresthatenforcestrictadherencetogroupnorms,potentiallyleadingtoalossofindividuality. (Thissectionoverlooks
issuessuchasself-awarenessandcriticalthinking.)
Table19: TwoexamplesthatillustratemultipledeficienciesinQwen27B’sresponses.F APracticalInterpretationoftheP.D.Metric
GiventhedifficultyininterpretingtheP.D.metric’sabsolutevalue, weofferaninterpretationoftheP.D.value’s
changetosignifythecomparativequalitybetweentwomodelanswers,A ,A . Giventhefollowingdefinitions:
1 2
• PerspectiveDiversity(P.D.)6:
n
(cid:88)
P.D.= PPL(PAi|A)
i=1
• Conditionalperplexity:
(cid:32) N (cid:33)
1 (cid:88)
PPL(Y|X)=exp − logP(y |X,y )
N i <i
i=1
• WedenotetheChangeinProbabilityforpartialanswerias∆Pi,assuming|PAi |=N:
∆Pi =
P(PAi|A 2)
=
(cid:89)N P(PAi j|A 2,PAi <j)
(5)
P(PAi|A ) P(PAi|A ,PAi )
1 j=1 j 1 <j
TheChangeinPerspectiveDiversity(∆P.D.)isdefinedas:
n n n
∆P.D.=(cid:88) PPL(PAi|A )−(cid:88) PPL(PAi|A )=(cid:88)(cid:0) PPL(PAi|A )−PPL(PAi|A )(cid:1) (6)
2 1 2 1
i=1 i=1 i=1
Substitutetheformulaofconditionalperplexity,weget:
    
n N N
(cid:88) 1 (cid:88) 1 (cid:88)
∆P.D.= exp−
N
logP(PAi j|A 2,PAi <j)−exp−
N
logP(PAi j|A 1,PAi <j)
i=1 j=1 j=1
Applyingtheapproximationexp(x)≈1+xforsmallx,weget:
   
n N N
(cid:88) 1 (cid:88) 1 (cid:88)
∆P.D.≈ 1−
N
logP(PAi j|A 2,PAi <j)−1−
N
logP(PAi j|A 1,PAi <j)
i=1 j=1 j=1
 
n N N
(cid:88) 1 (cid:88) 1 (cid:88)
= −
N
logP(PAi j|A 2,PAi <j)+
N
logP(PAi j|A 1,PAi <j)
i=1 j=1 j=1
n N n N
1 (cid:88)(cid:88) 1 (cid:88)(cid:88)
=− logP(PAi|A ,PAi )+ logP(PAi|A ,PAi )
N j 2 <j N j 1 <j
i=1j=1 i=1j=1
Applyingtheapproximationthatall∆Pi,i=1···narethesamevalueforsimplicity,weget:
n
(cid:88) 1
∆P.D.≈ log( )
∆Pi
i=1
Thus:
∆P.D.
∆P1 ≈exp(− ) (7)
n
Equation 7 shows that the change in probability ∆P1 can be approximated using the change in P.D. ∆P.D.,
andtheeffectisexponential. Forexample,whentakingn = 3(giventhefactthattheaveragenumberofpartial
answersinDEBATEQA≈ 3.7)and∆P.D. = −2,itsuggeststhattheapproximatedprobabilityofgeneratingone
partialanswerunderA is1.95timeshigherthanunderA . Inotherwords,thebackbonelanguagemodelfindsit
2 1
nearlytwiceaseasytorecoverthepartialanswerfromA duetothereductionof2intheP.D.score.
2
6Here,weuseAtodenotechatTemplate(concat(A,“Pleaserestate.”))inEquation1forsimplicity.