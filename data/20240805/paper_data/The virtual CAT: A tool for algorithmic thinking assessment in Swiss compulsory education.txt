The virtual CAT: A tool for algorithmic thinking assessment in Swiss
compulsory education
GiorgiaAdornia,‚àó, AlbertoPiattib
aDalleMolleInstituteforArtificialIntelligence(IDSIA),Universit√†dellaSvizzeraItalianaandUniversityofAppliedSciencesandArtsofSouthern
Switzerland(USI-SUPSI),PolouniversitarioLugano-CampusEst,VialaSanta1,6962,Lugano-Viganello,Switzerland
bDepartmentofEducationandLearning(DFA),UniversityofAppliedSciencesandArtsofSouthernSwitzerland(SUPSI),PiazzaS.Francesco
19,6600,Locarno,Switzerland
ARTICLE INFO Abstract
Keywords: In today‚Äôs digital era, holding algorithmic thinking (AT) skills is crucial, not only in computer
Algorithmicthinkingskills science-relatedfields.Theseabilitiesenableindividualstobreakdowncomplexproblemsintomore
Large-scaleassessment manageablestepsandcreateasequenceofactionstosolvethem.
ChildComputerInteraction ToaddresstheincreasingdemandforATassessmentsineducationalsettingsandthelimitationsof
Swisscompulsoryeducation currentmethods,thispaperintroducesthevirtualCrossArrayTask(CAT),adigitaladaptationofan
Educationaltechnology unpluggedassessmentactivitydesignedtoevaluatealgorithmicskillsinSwisscompulsoryeducation.
Usabilityevaluation Thistooloffersscalableandautomatedassessment,reducinghumaninvolvementandmitigating
potential data collection errors. The platform features gesture-based and visual block-based pro-
gramminginterfaces,ensuringitsusabilityfordiverselearners,furthersupportedbymultilingual
capabilities.
ToevaluatethevirtualCATplatform,weconductedapilotevaluationinSwitzerlandinvolving
a heterogeneous group of students. The findings show the platform‚Äôs usability, proficiency and
suitabilityforassessingATskillsamongstudentsofdiverseages,developmentstages,andeducational
backgrounds,aswellasthefeasibilityoflarge-scaledatacollection.
and basic knowledge recall, failing to align with the real-
1. Introduction
world problem-solving nature of AT [13, 16, 69, 87, 97].
Algorithmicthinking(AT)isthesystematicapproachto
Alternative approaches like open-ended questions have the
breakingdowncomplexproblemsintomanageablestepsand
advantageofshowcasingproblem-solvingskillsandcritical
devisingsequentialactionstosolvethem[9,23,74,86,99].
thinkingbutcanbetime-consumingandsubjecttograding
Itisanindispensableskillintoday‚Äôsdigitalera,transcending
inconsistencies[16].Programmingassignmentsandcoding
its origins in computer science [7, 41, 99, 100, 102]. AT
challengesemphasisepracticalapplicationandofferhands-
empowersindividualstoexcelinvariouspersonalandpro-
on evaluation of algorithmic skills. While they provide
fessional domains by enhancing problem-solving abilities,
valuable real-world learning experiences, grading can be
logical reasoning, and creativity [52]. Consequently, it has
labour-intensive and evaluating code quality may require
becomeincreasinglyimportantineducationalcontexts[67],
significanteffort[90].Roboticactivitiesprovideahands-on
where it serves as a foundational pillar for comprehending
approachtoATassessment,engagingstudentsinreal-world
essential concepts such as algorithms and data structures
problem-solvingwithphysicalrobots[44,57].Despitetheir
[17, 48, 49, 68]. As a result, a growing need exists to
benefits,challengesariseconcerningaccesstoroboticequip-
assessthisskilltomeasurestudents‚Äôdevelopmentandtailor
ment, resource requirements, and the need for specialised
teachingmethodstotheirneeds[22,72,83].
knowledge to facilitate these activities effectively. The do-
In the current landscape of AT assessment, educators
main of automatic assessment systems offers a promising
haveaspectrumofapproachesattheirdisposal.Traditional
avenue to mitigate some of the challenges associated with
methods, such as closed-ended questions and multiple-
standardisation and subjectivity [75, 80]. These systems
choice tests, are commonly used in education and train-
provideimmediatefeedbacktostudents,ensuringmorecon-
ing. They are often used to assess students‚Äô knowledge,
sistentevaluationsandcontributingtoamoredynamicand
skills and understanding in various educational contexts.
interactivelearningexperience[75].Automatedassessment
Closed-endedquestionselicitbrief,directresponses,while
tools are well-suited for large-scale educational programs.
multiple-choice tests require selecting answers from pre-
However,researchisstillrefiningtheirabilitytocomprehen-
defined options. Such methods can assess mastery of spe-
sivelyassessAT,especiallyinmonitoringlearners‚Äôprogress
cificconcepts,memorisationofinformationandtheability
[89].Finally,theseassessmentmethodssometimesoverlook
to answer questions clearly and concisely. However, they
developmental aspects, social and environmental contexts,
have been criticised for their limitations in evaluating AT
and the availability of appropriate educational resources
comprehensively,astheyoftenprioritiserotememorisation
[12,49,50,56,73,78,79,81,93,100].Theseemphasisethe
‚àóCorrespondingauthor needforacomprehensive,reliable,andobjectiveassessment
giorgia.adorni@idsia.ch(G.Adorni);alberto.piatti@supsi.ch toolthatcanbebroadlyappliedandscaledtoaccommodate
(A.Piatti) diverseagegroupsandeducationalsettings[9,30,65,96].
ORCID(s):0000-0002-2613-4467(G.Adorni)
G Adorni et al. Page1of21
4202
guA
2
]CH.sc[
1v36210.8042:viXraThe virtual CAT
To overcome the inherent limitations in existing ap- achieve this, we enlisted the expertise of a UX inspector.
proaches,thisstudybuildsuponpreviouswork,introducing With their knowledge of UX design guidelines and profes-
theCrossArrayTask(CAT)[71],anunpluggedassessment sional experience, they carefully examined our prototype
activity designed to align seamlessly with the distinctive to identify any potential issues. Based on their findings,
educational landscape of Switzerland. This activity con- we developed an improved prototype that addressed these
siders tasks‚Äô developmental and situated nature in social concernsandprovidedabetteruserexperience[34].
and artefactual environments, aspects that are often over- In the final cycle, we engage children in participatory
looked in the literature. The CAT‚Äôs focus on these char- design, considering their needs and preferences to extract
acteristics complements the Swiss educational philosophy, newuserrequirements[28,29,76,77,84].Usabilityremains
whichstronglyemphasisesdiversityandintegration.Swiss central as we actively involve children as informants and
schoolsareknownforaccommodatingstudentswithdiverse evaluators,withteachersfacilitatingtheprocess[8,11,19,
backgrounds, capabilities, and linguistic proficiencies, and 27,35,42,63,64,82].Multipledataelicitationtechniques
the CAT‚Äôs flexibility enables it to support these goals ef- are used to gain insights into usability and effectiveness
fectively.WhiletheCAThasdemonstrateditseffectiveness [31, 32]. More in-depth details are provided in Sections 4
in evaluating AT abilities in K-12 students, nonetheless, it and5.
presents certain limitations. The CAT was conceived as a
bilateral activity between a student and a specialist. Thus, 2.1. TheCAT:fromunpluggedtovirtual
it cannot be feasibly administered to an entire class simul- interactions
taneously by a single expert. Consequently, it proves to be The Cross Array Task (CAT), illustrated in Figure 1,
time-consumingandimpracticalwhenappliedtolarge-scale is an assessment activity for K-12 pupils conceived us-
assessments.Furthermore,thepresenceofahumanagentin ing the CT-cube [71]. This theoretical framework guaran-
theassessmentprocesscanintroduceadditionalchallenges. tees that any Computational Thinking Problem (CTP) de-
Itcanmaketheprocessraisethepotentialforerrors,given signed includes the necessary cognitive processes involved
thepossibilityofinconsistentinterpretationsofinstructions. in problem-solving while also considering the social and
This paper introduces a digital version of the CAT activity environmentalfactorsthatinfluencetheseprocesses.
designedtoovercomeitslimitationsandenablelarge-scale The CAT revolves around the concept of a cross array
assessment, focusing on Switzerland‚Äôs compulsory educa- ‚Äì a cross-shaped array of 20 dots forming a 2-thick cross,
tion system. While our main objective in this study is to consistingoffive2√ó2squarearraysofcoloureddots,with
assess AT on a large scale, it also encompasses the design colourschosenfromasetofùëòcolours,usuallyyellow,green,
of a tool that can effectively achieve this goal and lays the blue,orred.Eachstudentinthisactivityreceives12refer-
foundation for understanding how to develop such a tool. ence schemas, essentially coloured cross arrays exhibiting
This virtual CAT offers multiple interfaces as interaction differentregularitiesandincreasingcomplexities.Theprob-
modes and multilingual support, making it adaptable and lem solver‚Äôs task is to devise a set of instructions, referred
accessibletoawiderangeofpupils.Itcanbeadministered to as algorithm, to replicate these intricate patterns on a
throughindividualdevices,allowingmultiplepupilstotake blankcrossarray.Theseinstructionsneedtobeconveyedto
the assessment simultaneously. This streamlines and auto- anagent forexecution.To communicatethealgorithm, the
mates the assessment process, making it faster and more problem solver has the flexibility to use various artefacts,
efficientwhilereducinghumaninvolvementandminimising depending on the version of the CAT used. The human
errors in data collection and interpretation inconsistencies. or artificial agent is tasked with interpreting the student‚Äôs
Given the characteristics of the virtual adaptation of the instructionsandreplicatingthecolouringpatternonablank
unpluggedCAT,itshowspromiseinaddressingthelimita- cross array, also known as a colouring schema. Typically,
tionsofcurrentassessmenttoolsandfacilitatinglarger-scale duringthisinteraction,avisualbarrierpreventstheproblem
assessmentsofATincompulsoryeducation. solver from seeing the colouring schema to enhance the
task‚Äôschallenge.However,ifnecessary,theproblemsolver
can remove this barrier and rely on visual clues of the
2. Designprocess
colouringprocess.
This section discusses the design process of the virtual Within the CT-cube framework, the CAT is structured
CAT.Weemployaformativeevaluationapproach,drawing aroundthreedimensions:
fromvariousmethodologies,focusedonusability,tocontin- 1. Typeofactivity:TheCATfocusesonalgorithmdevel-
uouslyrefineourdesign[14,18,34,85,98]. opment,orbreakingdowncomplexprocessesintomore
Our design process comprises three distinct User Ex- straightforwardinstructionsthatahumanoranartificial
perience (UX) Design Lifecycles. In the initial phase, we agentcanexecutetosolvetheproblem.
define objectives, analyse prior experiences, and establish 2. Cognitive artefacts: These are the tools and resources
tool requirements [47]. We proceed to the designing and used during the activity. The CAT employs two main
prototypingphase,prioritisinguserexperienceandusability. types of artefacts: embodied (rooted in sensory experi-
During the second phase of our design process, we aimed ences)andsymbolic(basedonabstractrepresentations).
toimprovetheuser-friendlinessofourinitialprototype.To
G Adorni et al. Page 2 of 21The virtual CAT
Pupil Pupil
cross array
to be coloured empty cross array
empty cross array reference cross array
reference
cross array
screen
protocol
pencils cro ts os ba err ay
coloured
Researcher
router computer + database
(a) The unplugged CAT (Adapted from [71]). The problem (b)ThevirtualCAT.Theproblemsolver,astudent,istasked
solver,astudent,istaskedwithinstructingtheagent,typically to reproduce a reference schema using a gesture-based inter-
aresearcher,toreproduceareferenceschema.Theinstructions faceorablock-basedinterfacebasedonaformalprogramming
canbecommunicatedorallyorthroughgesturesonasupport language that combines visual blocks to compose a set of
schema. A physical, removable barrier between the problem instructions. The task‚Äôs default setting limits the problem
solver and the agent prevents visual cues between them and solver‚Äôs ability to see the outcome of their actions due to a
heightens the challenge. The agent interprets and records visual cue prevention feature that can be easily turned on or
the student‚Äôs instructions on a protocol and replicates the off. The system automatically logs all actions and algorithms.
colouring pattern on a blank cross array.
Figure 1: Comparison of the setting between the unplugged and virtual CAT.
3. Levelofautonomy:Thedegreeofindependenceexhib- To better understand the evolution of the CAT activity
itedbystudentsduringtheactivity.IntheCAT,inactive from its original unplugged domain to the virtual one and
pupilsdonotattempttosolvethetask;non-autonomous easilyallowforavisualcomparisonofthem,Figure1visu-
ones rely on visual feedback to do it; autonomous ones ally illustrates the setup of the two versions, while Table 1
provideintelligibleinstructionswithoutclues. highlightstheirdifferences.
The CAT assessment process is designed to evaluate TheCATwasconceivedasanunpluggedactivity,char-
pupils based on these dimensions: algorithm complexity, acterisedbyaface-to-faceinteractionbetweentheproblem
artefact choice, and autonomy level. Specifically, the com- solverandahumanagent.Inthistaskversion,theproblem
plexityofthealgorithmisassessedbasedontheoperations‚Äô solver‚Äôsprimaryobjectivewastoconceptualiseanalgorithm
dimensionsinvolved:0Doperationsinvolvecolouringdots andeffectivelycommunicateittotheagent.
individually,1Doperationsinvolvecolouringmultipledots Withinthissetup,twodifferentrepresentationalartefacts
withthesamecolourbasedonpatternssuchasrows,diago- areatthestudent‚Äôsdisposal.Thefirstwasasymbolicarte-
nals,andsquares,2Dinvolvemorecomplexpatternswithal- fact, where students could verbally communicate their in-
ternatingcolours,repetitionormirroringofoperations.The structions,describingtheprocessusingwords.Thisincludes
mostcomplexoperationusedinanalgorithmdeterminesits using natural language, which is considered symbolic as it
finalclassification. employswordsandphrasestorepresentideasandconcepts.
Thetaskissuccessfulifthestudentconceivesacomplete Alternatively,anembodiedartefactallowedstudentstoaug-
andcorrectalgorithm,regardlessofitscomplexity,thearte- mentvoiceinstructionswithphysicalgestures.Forinstance,
factual environmentor autonomy. A comprehensive metric they could use hand movements to point to specific dots
called the CAT score is used to quantify this multi-facet on an empty cross array schema, physically illustrating the
performance, consisting of two components: the combina- commandstheywishedtoconvey.
tion of artefact used and autonomy level, referred to as the Regarding the interaction dynamics between the prob-
interaction dimension, and the algorithm dimension. Each lem solver and the agent, they were seated in front of each
componentisassignedanumericalscore,withahigherscore otheracrossatable,withaphysicalbarrierseparatingthem.
indicativeofastudentwhohasnavigatedthecomplexitiesof Thisscreenobstructedthedirectvisualexchangeofactions
challenging artefacts, assumed an autonomous role, and/or between the student and the agent. It effectively prevented
conceivedahigher-dimensionalalgorithm. thestudentfromobservinghowtheagentexecutedthetask
ofcolouringtheemptycrossarrayandviceversa.
G Adorni et al. Page 3 of 21The virtual CAT
Table 1
Comparison of unplugged and virtual CAT. The table compares the unplugged and virtual CAT, highlighting key differences in
interaction types, available artefacts, autonomy settings, algorithm classification and data collection approaches.
Unplugged CAT Virtual CAT
Face-to-face Face-to-device
Interaction type (problemsolver&humanagent) (problemsolver&virtualagent)
Embodied artefact S:handgesturesonaschema G:gestureinterface
Symbolic artefact V:voice P:visualprogramminginterface
Autonomy F(ornot):removablephysicalbarriertoenablevisual F(ornot):buttontoenablevisualfeedback
feedback
Ahumanagentinterpretsinstructionsandmanually A virtual agent translates actions into formal pro-
Algorithm classification codifiesthealgorithm gramminglanguageusinganinterpreter
Data collection Manual Automatic
The agent has the role of interpreting student instruc-
Table 2
tions,documentingthemonaprotocol,andfinallyreplicat-
CAT score metric to assess task performance. In the tables,
ingthecolouringpatternonablankcrossarraybasedsolely
rows represent algorithm dimensions, while columns represent
onthealgorithmcommunicatedbythestudent. interaction dimensions, determined by the combination of
TheevolutionfromtheCATunpluggedversiontoitsvir- artefactusedandautonomylevel.Thetwotablesdifferinthe
tualcounterpartrequiredatransformationintheinteraction scoringsystemapplied,withtheunpluggedCATgoingfrom0
methodsbetweentheproblemsolverandtheartificialagent. to 4 and the virtual CAT going from 0 to 5.
The problem solver now interacts with a device, a virtual (a) Unplugged CAT. Interac- (b) Virtual CAT. Interaction
agent,replacingface-to-faceinteractionwithahumanagent. tion dimension acronyms V, dimension acronyms G and P
The original idea of using two different representation VS, and VSF stand for voice, stand for gesture and visual
methodstoconveythealgorithmremains,buttheyhavebeen voicewithhandgesturesona programming interfaces, with
adjusted. A gesture-based interface is available to replicate schema, and the latter incor- GF and PF incorporating vi-
porating visual feedback. sual feedback.
hand gestures, maintaining the embodied artefact aspect.
Theoriginalvoiceinteractionwasremovedasitposedmul- VSF VS V GF G PF P
tiplechallengesinamultilingualcontextandwithyounger
0D 0 1 2 0D 0 1 2 3
learners. Speech recognition technology struggled to accu- 1D 1 2 3 1D 1 2 3 4
ratelyinterpretspokeninstructionsinthesescenarios,result- 2D 2 3 4 2D 2 3 4 5
inginalesspracticallearningexperience.Asareplacement,
weintroducedanalternativesymbolicartefact,avisualpro-
AsthevirtualCATintroducesanewsetofartefactsfor
gramminginterface,hereafterreferredtoasCAT-VPI,with
studentstointeractwithcomparedtotheunpluggedversion,
ready-made building blocks, reproducing commands akin
we have slightly adjusted the performance metric used for
to those encountered in the unplugged CAT. These blocks
assessment,asreflectedinTable2.
come in two variations: one conveys commands through
textual instructions, while the other employs symbols. The
2.2. Thefirstprototype
advantage of this block-based coding approach lies in its
In the design of our platform, we prioritised accessi-
user-friendlynature,enablingstudentstoconstructinstruc-
bilityandusability.Ineducationaltechnology,accessibility
tions through simple drag-and-drop actions, enhancing ac-
centres on crafting solutions to meet users‚Äô needs from
cessibilityandreducingthelikelihoodofsyntaxerrors.
various backgrounds, regardless of their physical or cogni-
Regarding interaction dynamics, as in the unplugged
tive abilities [43]. In contrast, usability focuses on the user
version, the problem solver cannot observe the executed
experience, aiming at delivering an intuitive and effective
code or the cross-colouring points reached, however, the
learning environment [6, 26]. To achieve these goals, we
interfacesallowtheusertoactivatethevisualisationofthe
madeaseriesofstrategicdecisions,includingconsiderations
progressofthecolouring.
suchasthechoiceofcompatibledevices,languagesupport,
Theagentmaintainstheroleofinterpretingthestudent‚Äôs
and the design and layout of various interfaces, following
instructions.Aprogramminglanguageinterpreterisusedto
guidelinesandbestpracticesfoundin[34].
translategestureinteractionandvisualblocksintoaformal
For practical reasons, we opted to skip certain stages,
programminglanguagethatmimicstheoperationsobserved
such as crafting paper prototypes, and directly develop a
in the unplugged activity, which we assumed the student
functional prototype. This decision was influenced by lim-
wouldreuseinthevirtualversion.Thealgorithmsarethus
ited access to schools and children, along with time con-
automaticallyrecordedbythevirtualagent.
straints,whichmadeastreamlinedapproachnecessary.Ad-
ditionally, the involvement of very young children in the
G Adorni et al. Page 4 of 21The virtual CAT
1 2 3
(a) CAT-VPI. (b) Textual CAT-VPI. (c) Symbolic CAT-VPI.
Figure 2: CAT visual programming interface (CAT-VPI). (1) The left column organises predefined building blocks using a
colour-codingsystemthatgroupstogethercommandswithsimilarfunctionalities.(2)Thecentralcolumnistheworkspacewhere
users arrange and combine visual coding blocks from the left column. At the top are three buttons for users to switch between
different interfaces. (3) The right column comprises two sections: the reference schema at the top, and the cross representing
thecurrentprogressatthebottom.Aneyebuttonisavailableaboveittotogglevisualfeedbackonandoff.Thebottomsection
provides a restart button and a green arrow to confirm and move to the next exercise.
participatorydesign,whomayfindabstractreasoningchal- visualimpairmentsandcolourblindness.Toachievethis,we
lenging, makes it necessary to opt for a different type of used high-contrast visuals and colours that are easy to see.
prototype[19,31,33,55]. Users can switch to a colour-blind mode and also use our
TheappistailoredforiPads,primarilyduetotheirtouch- text-to-speechfeature.Wemaintainedconsistencybyusing
screen interaction, which closely aligns with the intuitive similar names and labels for similar objects and functions
and interactive learning experiences sought in educational and employing precise wording in menus, icons, and data
settings. This design choice ensures that students, particu- fieldstoenhanceclarity.Weavoidedsynonymstoensurean
larly those in K-12 educational contexts, can engage with intuitiveuserexperience.Toalignwithestablishedconven-
the application user-friendly and pedagogically effectively, tions,weplacedcommonlyusedfeaturesineasilyaccessible
fosteringanenrichingeducationalexperience[82]. locations. Our platform features a responsive design that
The app is available in four languages: Italian, French, adaptsseamlesslytodifferentdevicesforoptimalusability.
and German to cater to the diverse linguistic landscape Overall, our adherence to these mobile application design
of Switzerland; English to extend the app‚Äôs utility to a principles aimed to create a user-friendly and accessible,
broader range of educational institutions, ensuring that a enhancingtheoverallexperienceforallusers,regardlessof
wider student demographic can benefit from the learning theirabilitiesorpriorexperiencewithsimilarapplications.
experience it offers, paving the way for potential adoption
beyondSwitzerland‚Äôsborders(seeFigureA.1). 2.3. Expertevaluationanddesignofarefined
The platform provides users with two distinct methods prototype
to engage with it - a gesture interface (CAT-GI) and a After developing the initial prototype of the platform,
visual programming interface (CAT-VPI). We adhered to we collaborated with experts to enhance its usability and
standardmobileapplicationdesignprincipleswhencrafting accessibility.First,weconsultedwithaninteractiondesign
the interfaces to ensure their usability and effectiveness researcher and teacher, who recommended more intuitive
[15, 34, 61, 92]. This includes incorporating common el- icons and a restructuring of the interfaces to establish a
ements, like a top bar and a left-side menu list, to create shared uniform page layout. This resulted in adopting a
an interface familiar to users with experience with other consistent design featuring three columns, each optimised
applications.Weprioritisedthelegibilityandreadabilityof for specific functions: the left column featured predefined
text,ensuringthatfontsizeswerelargeenoughforallusers code blocks or buttons, the central column served as the
andthatthebackgroundhadagoodcontrast.Weensuredour workspace for user interactions, and the right column dis-
system was accessible to everyone, including people with playedthecolouredschemastobereplicated.Additionally,
G Adorni et al. Page 5 of 21The virtual CAT
1 2 3
Figure 3: CAT gesture interface (CAT-GI). (1) The left column provides buttons to select colours and actions. (2) The central
column is the workspace where users can directly touch the dots to colour the cross. At the top are three buttons for users to
switchbetweendifferentinterfaces.(3)Therightcolumncomprisestwosections:thereferenceschemaatthetop,andthecross
representing the current progress at the bottom. An eye button is available above it to toggle visual feedback on and off. The
bottom section provides a restart button and a green arrow to confirm and move to the next exercise.
we sought the expertise of three pedagogical specialists in with the cross by selecting colours and touching the dots,
computerscienceeducationandpedagogytorefinetheedu- mimickingthephysicalengagementoftheunpluggedactiv-
cationalaspectsofourinitiative.Theyprovidedstrategiesfor ity. By dragging their fingers across the screen, users can
introducingtheactivityandplatformtopupilsinanengaging create patterns, while additional complex actions such as
andage-appropriatemanner. repeatinginstructionsormirroringpatternscanbeexecuted
using action buttons, adding layers of complexity to their
Visual programming interface The development of the algorithm,asshowcasedinFigure3.
CAT-VPI has given rise to a visual programming language
(CAT-VPL)designedtomakecodingaccessibletoabroad
audience, particularly K-12 students, including those with 3. Implementation
nopriorprogrammingexperience.TheCAT-VPIisdepicted The final application [4] was developed using Flutter
inFigure2a.Withinthisvirtualenvironment,usersengage [25]. This choice of framework yielded multiple advan-
with a drag-and-drop mechanism, which facilitates the or- tages. Its extensive platform support, including Android,
ganisation of predefined building blocks for constructing iOS, Linux, macOS, Windows, and the web, ensures com-
a colouring algorithm. These building blocks inherently patibility across various devices. Although the app is de-
possess predefined functions that mirror their counterparts signed to be used on an iPad, thanks to the cross-platform
in the formal programming language. Nevertheless, users framework,wedevelopedasinglecodebasethatrunsseam-
cancustomisetheseblocksbyadjustingparameterssuchas lesslyonmultipleplatforms,savingusmuchtimeandeffort
colourorpatternchoices.Toensureinclusivityforlearners in platform-specific development. The application design
ofdiversebackgrounds,ages,andcognitiveabilities,wepro- is responsive, which means it has a consistent look across
videdtwodifferentrepresentationsforcommands,onetex- different platforms and screen sizes. Another benefit is the
tual, offering explicit linguistic command expressions (see streamlinedandeffectivedevelopmentexperienceprovided
Figure2b)andonesymbolic,enablingnon-literatelearners bythehotreloadfeature,whichallowsdeveloperstoseethe
tointeracteffectivelywiththeinterface(seeFigure2c). effectsofcodechanges,makingiterativedevelopmentmore
seamless and increasing productivity. Additionally, Flutter
Gesture interface The CAT-GI is intentionally designed
providesamplepre-builtwidgetsandlibraries,offeringthe
toemulatethehandgesturesobservedduringtheunplugged
necessary tools to create visually engaging and interactive
CATactivity.Thisinterfaceallowsengaginginahands-on,
user interfaces. The latest version of the application, along
tactile experience similar to interacting with the physical
with its comprehensive source code and documentation, is
empty cross array, bridging the gap between physical and
availableonlineandcanbeaccessedthroughreference[4].
virtual learning environments. Users can directly interact
G Adorni et al. Page 6 of 21The virtual CAT
3.1. Definitionofaformalprogramminglanguage It translates student actions, including gesture interactions
Toestablishastandardisedsetofinstructionsthatusers and arranged visual programming blocks, into executable
could employ within the application interfaces to design machine-readable instructions. It analyses the user‚Äôs input,
thealgorithm,wedefinedtheCATprogramminglanguage, converting actions into a formal algorithm specified using
whichcodifiesandformalisesallthecommandsandactions theCATprogramminglanguage.
observed during the original experimental study with the Each command that composes the algorithm, such as
unpluggedCAT. colour selections and other operations, undergoes a valida-
tionprocesstoidentifyandaddresssemanticerrors.Notably,
Cross representation The cross-board dots are manipu- the interface‚Äôs design, featuring predefined programming
latedandreferencedusingacoordinatesystem,whererows blocksandbuttons,obviatestheneedforsyntaxchecking,as
are labelled from bottom to top using letters (A-F), and itinherentlyeliminatesthepossibilityofsucherrors,signif-
columnsarenumberedfromlefttoright(1-6). icantly streamlining the process. However, semantic errors
can still occur during command execution, for instance,
Moves Movingaroundthecross-boardcanbedoneintwo
when users attempt to move outside the board boundaries
ways.ThegoCell(cell)methodallowsjumpingdirectlytoa
usinginvaliddirectionsorapplyaninappropriatepatternfor
specificcoordinate.Alternatively,thego(move, repetitions) acolouringcommand.
methodallowstraversingacertainnumberofdotsinoneof
Upon validation, the code is executed, and real-time
theeightavailabledirections(eithercardinalordiagonal)to
feedback is provided to the user, including the display of
reachthedesireddestination.
currentprogressonthecolouringcrossandtheCATscore.
Iftheinterpreterdetectserrors,ithandlesthemandprovides
Basic colouring Colouring the board is a fundamental
users with error notifications and potential suggestions for
aspect of the CAT application, and we offer various meth-
correction.
ods to achieve this. The paintSingleCell(color) method
allows colouring the dot they are currently positioned on
3.3. Serveranddatahandling
withasinglecolour.ThepaintPattern(colors, repetitions, Consideringtheoftenlimitedavailabilityofsecurenet-
pattern) method allows colouring multiple dots accord- works in educational settings, we implemented a technical
ing to predefined patterns. A sequence of colours can be
frameworktoprioritiseparticipantprivacyandresponsible
specified, which will alternate following the selected pat-
data management [2]. To use this system, a local network
tern.Additionally,userscanchoosefromfivepatterntypes
infrastructureshouldbeestablishedusingaroutertoconnect
(cardinal, diagonal, square, L, zigzag), each with various
alldevicesinvolvedintheactivitytoadesignatedcomputer,
directions.ThepaintMultipleCells(colors,cellsPositions)
which serves as the data collection point. Within this net-
method enables colouring multiple dots with custom pat-
work, a database should be configured to securely receive
terns, defined by specifying the coordinates of the cells to
and store the acquired data from the iPads. Afterwards, all
be coloured. The fillEmpty(color) method colours all the collecteddatacanbetransferredfromthelocaldatabasetoa
uncoloureddotsontheboardwiththesamecolour.
dedicatedrepositorythroughaprivatenetworkconnection.
Repetition-based colouring Moving beyond the basics,
other methods allow for more complex operations. The 4. Experimental
repeatCommands(commands, positions) method allows speci- Thissectionprovidesanin-depthoverviewoftheforma-
fyingasequenceofcommands(e.g.,aseriesofgoandpaint
tiveevaluationconductedtoevaluatetheplatform‚Äôsusabil-
operations) and applying them to specific coordinates. The
ity,proficiency,andsuitability.
copyCells(origin, destination) method copies the colours We organised our pilot study as a participatory design
fromorigincoordinatestodestinationcoordinates.
involving three roles: a researcher, students and teachers
[84]. Pupils were at the heart of the study, and their inter-
Symmetry-basedcolouring Finally,symmetricalcolour-
actionswiththeplatformwerecrucialforassessingourtool
ing approaches are available. The mirrorBoard(direction) [20,51,94,95].Theinclusionofchildreninthedesignand
method,whichreflectsthecoloureddotsontheboardonto
evaluation of their artefacts aimed at empowering them to
thenon-colouredones,followingtheprincipleofsymmetry.
takeanactiveroleindriving[37,40,45,46]andcritically
This mirroring can be done horizontally on the x-axis or
reflecting on the developed tool, as well as making the
verticallyonthey-axis.ThemirrorCells(cells, direction) process enjoyable and rewarding [10, 58, 59, 60]. In this
methodperformssimilarmirroringoperationsbutonaspec-
phase,childrenareencouragedtosharetheirevolvingideas
ified set of dots. The mirrorCommands(commands, direction) astheyperformtheactivityandtestthetool[36,38,39,101].
methodappliesthemirroringtoalistofcommands.
Teachersalsoplayedavitalroleinfacilitatingthestudy,
providingassistanceasneeded,andensuringasmoothclass-
3.2. DefinitionofthevirtualCATinterpreter
roomexperience.
The virtual CAT programming language interpreter [3]
The researcher, responsible for administering the ac-
is a dedicated Dart package that can be integrated into
tivity, closely monitored pupil progress and interactions,
any Flutter project, in our case, the virtual CAT app [4].
collected empirical data on task performance and gathered
G Adorni et al. Page 7 of 21The virtual CAT
4.2. Trainingmodule
Table 3
Inourstudy,werecognisedtheimportanceofensuring
Demographic analysis of students by school type, age cate-
pupils‚Äôfamiliaritywiththeassessmenttool.Toachievethis,
goryandgender.Thetableprovidesanoverviewofthegender
distribution among students in different school types and age we designed and integrated a training module within the
ranges.TheFemaleandMalecolumnsrepresentthenumberof app that serves as a preparatory step for scholars, allowing
femaleandmalestudents,respectively,whiletheTotalcolumn them to become acquainted with the tool‚Äôs interface and
displaysthecombinedcount.Themeanage(ùúá)andstandard functionalities (see Figure A.2). This module included 15
deviation (¬±) are presented for each age range. samplecross-arrayschemastosolve.Additionally,astep-by-
stepguidetotheapp‚Äôsfeaturesandfunctionswasprovided
School Age Female Male Total
byaresearcherduringlive,in-personsessionsheldinevery
3-6yearsold
Preschool 3 4 7 class. During this phase, we fostered a collaborative and
(ùúá =5.0¬±1.0)
interactive environment to ensure pupil understanding of
Secondary 10-13yearsold
18 6 24 the activity. Teachers played a crucial role in assisting the
school (ùúá =11.3¬±0.6)
researcher and guiding the class, ensuring they received
Total 21 10 31
clear guidance. The training sessions were held in groups
basedondeviceavailabilityandlastedabout30-45minutes.
feedback from students and teachers. Multiple data elicita- Toensurearespectfultestingenvironmentforchildren,we
tion techniques, including think-aloud and observation, are tailored the training approach to their developmental level,
employedtogaininsightsintotheusabilityandeffectiveness including age-appropriate guidance, particularly directing
ofthedesign[32,34]. kindergarten pupils to use only the gesture interface [33].
We gathered empirical data through a combination of Thisadaptationinvolvedsimplifyinginstructions,ensuring
user-centred techniques, including think-aloud sessions for comfort,andpacingthetestaccordingly.Nodatacollection
real-time verbalised feedback, note-taking to capture ob- occurredduringthisphase,allowingstudentstoconcentrate
servations and essential points, and observational analysis onbecomingcomfortablewiththetoolanditsfunctions.
to understand underlying phenomena and user reactions,
allfollowingHuman-ComputerInteraction(HCI)principles 4.3. Validationmoduleanddatacollection
In the pilot study, data collection occurred within the
andUXdesignpractices[21,32,34,36,53,54].
validationsession,amoduleintegratedintotheapptomimic
the original activity with the 12 schemas to solve. Session
4.1. Selectionandparticipation
In March 2023, we conducted a pilot study to evaluate and student details must be manually input into the app
thevirtualCATasanassessmenttool.Itinvolvedasample to start the data collection process (see Figures A.4 and
of31students,21girlsand10boys,fromtwoschoolsinthe A.5). Specifically, we recorded the date, the canton, the
Ticinocanton(seeTable3).Ineachclass,weconductedthe schoolwheredatawascollected,andtheclass‚Äôsgradelevel.
activitywithallthepupilswhowerepronetoparticipateand Pupils‚Äôdetailswerelimitedtotheirgenderanddateofbirth.
wereexplicitlyallowedbytheirparents. To uphold anonymity, each student was assigned a unique
Toensurearepresentativesample,werandomlyselected identifier.
schools, including a preschool class (4-6 ys) and two low Throughout the entire activity, the application‚Äôs log
secondary classes (11-12 ys), representing opposite ends meticulouslytrackedeveryactionperformedbythepupils.
of the compulsory education system in Switzerland. This This included recording the timestamp and type of opera-
aimedtodemonstratetheplatform‚Äôseffectivenessfordiverse tion carried out, such as adding, confirming, removing, or
school types, which can be extended to cover compulsory reordering commands, updating command properties like
education. colours or directions, resetting the algorithm, changing the
Given the participation of young students, we strictly mode of interaction or visibility, confirming task comple-
adhered to ethical guidelines and maintained transparent tion, or surrendering. This comprehensive data collection
communication with pupils, parents, and schools [5, 70]. wasinstrumentalinassessingpupilperformance,providing
Initially, we obtained authorisation from school directors valuableinsightsforthestudy‚Äôsanalysisandfindings.
and teachers to conduct the research within their schools WefollowedthecurrentopensciencepracticeinSwitzer-
and classes. Next, we provided parents with an exhaustive land[88]andpseudonymisedallthedata.Thedatahasbeen
document explaining the research project, data collection made available through Zenodo for public access [1] after
andstorageprocedures,andthepersonnelinvolved.Wealso removinganyinformationthatcouldidentifythepupil(e.g.,
requestedtheirconsentfortheirchildren‚Äôsparticipationand schoolandclass).
publishing the collected data. Teachers obtained informed
consentfromparentswithoutrecordingpupils‚Äôfullnamesto 5. Results
safeguardprivacy,ensuringdataanonymityfromtheoutset.
Thissectionpresentstheresultsofourformativeevalua-
tionaimedatassessingthetoolandtheinterfaceprototypes,
shown in Section 2.3, all in the context of our educational
objectives. Additionally, we explore the tool‚Äôs practicality
G Adorni et al. Page 8 of 21The virtual CAT
Table 4 Table 6
Definition of evaluation criteria. The table provides the Analysis of activity completion time across interaction di-
definitionsfortheestablishedcriteriausedtoevaluatethetool mensions. The table presents a comprehensive overview of
and interface prototypes. the time taken by students to complete all schemas using
different interfaces, gestures (G) or visual programming (P),
Criterion Definition
withandwithoutvisualfeedback(F).Theaverage,minimum,
Pupils ability to use all interfaces, regardless of and maximum completion times, in minutes, are reported for
Usability
age each interface.
Pupilsproficiencyingeneratingalgorithmsacross
Proficiency Interface Avg time Min time Max time
allthreedimensions,regardlessofage
Pupils success in completing all provided GF 16min 4min 29min
Suitability schemas,regardlessofage G 13min 4min 29min
PF 18min 8min 28min
Platform practicality of large-scale administra-
Feasibility P 17min 7min 28min
tion,datacollectionandanalysis
Total 16min 4min 29min
Table 5
Criteria evaluation measures. The table provides the specific From3to6yearsold From10to13yearsold
measures to assess the tool and interface prototypes. 52% 48% 0% 0% 27% 25% 26% 22%
7% 5% 11% 3% 0% 6% 2% 10%
Criterion Measures
Completion time for interaction dimensions and 28% 30% 57% 14% 15% 20% 19% 68%
Usability
usedinterfaces
18% 13% 31% 10% 10% 0% 1% 21%
Proficiency Developedalgorithms
Suitability Successratesofindividualschemas GF G PF P GF G PF P
Interactiondimension Interactiondimension
Time efficiency, resource requirements, automa-
Feasibility
tionandscalability Figure 4: Algorithmic and interaction strategies. The table
illustratesthedistributionofalgorithmicdimensions‚Äì0D,1D,
2D‚Äìacrossinteractiondimensions‚Äìgestureinterfaceandvi-
for assessing algorithmic skills among K-12 pupils on a
sualfeedback(GF),gestureinterface(G),visualprogramming
large scale. For this assessment, we established specific interface and visual feedback (PF), and visual programming
criteria and defined corresponding measures, customised interface (P) ‚Äì for younger and older pupils. Percentages
to our educational context, as detailed in Tables 4 and 5, represent the proportion of each combination within their
drawinguponestablishedusabilitystandardsintheliterature respective age groups. It‚Äôs worth noticing that the younger
[34,62,66]. age category was not allowed to use the visual programming
Weevaluateusabilitybyanalysingthecompletiontime interfaces (PF and P).
acrossdifferentinteractiondimensions.Table6revealsthat
thegestureinterface,bothwithandwithoutfeedback,leads
pupilsintheyoungeragegroupconsistentlyusedallavail-
to quicker task completion times than the visual program-
able interfaces. In contrast, the distribution of interaction
ming interface counterparts. This observation aligns with
dimensionsconcerningthealgorithmdimensionintheolder
expectations,asthegestureinterfacerepresentsalesscom-
age category shows noteworthy variations. Older pupils
plex dimension of the artefactual environment, making it
tend to employ simpler algorithms more frequently with
moreintuitiveandefficientforstudents.However,it‚Äôsinter-
the gesture interface, while they conceive more complex
estingtonotethatwhenconsideringthemaximumcomple-
algorithms with the visual programming interface. These
tiontimes,thegestureinterface,particularlywithfeedback,
differences highlight the nuanced ways in which students
recorded the longest time. One possible explanation is that
engage with different interfaces and how this impacts their
less proficient students may gravitate towards the gesture
problem-solvingstrategies.Toevaluateproficiency,Figure4
interface, which could lead to longer completion times.
provides insights into younger and older pupils‚Äô strategies
This suggests that interface choice may not solely reflect
to solve the tasks. Pupils exhibit proficiency in generating
usability but also user proficiency. It is important to note
algorithmsacrossallthreedimensions.Inbothagegroups,
that students who rely on visual feedback take more time
1D algorithms are the most used, consistent with findings
tocompletetheirtasksonaverage.Thiscouldindicatethat
from the unplugged CAT. Among younger pupils, about
whilefeedbackaidspupilsintaskcomprehension,itmight
31% employed straightforward 0D algorithms, while only
extend the overall interaction duration as they process and
a tiny portion used 2D algorithms, indicating a preference
respondtothefeedback.
for simplicity. For older pupils, 1D algorithms were even
Additionally, Figure 4 provides insights into younger
moreprevalent,withahigherpercentageofpupilsadopting
and older pupils‚Äô strategies to solve the tasks based on
this approach. Additionally, there was a reliance on 2D
the algorithmic and interaction dimensions. Pupils across
algorithms,demonstratingacombinationofsequentialand
different age groups display a balanced usage of multiple
branchingstrategiesintheirproblem-solving.
interfaces and autonomy levels on the platform. Notably,
G Adorni et al. Page 9 of 21
noisnemidmhtiroglA
D2
D1
D0
noisnemidmhtiroglA
D2
D1
D0The virtual CAT
36hoursofdatacollectionforall109participants,thevirtual
Table 7
CAT‚Äôs administration is contingent on device availability.
Analysis of student performance across age categories and
Providing each student with individual devices allows the
schemas. The table presents the number and percentage of
studentswhoattemptedandsolvedeachschemaforeachage activity to be orchestrated for the entire class simultane-
category.Thepercentageof‚Äúsolved‚Äùschemasiscalculatedonly ouslyandseamlessly.Thistransitiondrasticallyreducesthe
among pupils who attempted it. overalltimeinvestmentrequired.Moreover,itopensupthe
possibilityofconductingassessmentsacrossmultipleclass
Num. pupils who solved the schema
Schema groups.AfterthedatacollectionwiththevirtualCAT,there
3-6yearsold 10-13yearsold Total
wasanadditionalsignificantadvantage‚Äìthedatacollected
1 3/6 (50%) 22/24(92%) 25/30(83%)
wasautomaticallydigitised,eliminatingtheneedforlabour-
2 3/5 (60%) 21/24(88%) 24/29(83%)
3 4/6 (67%) 19/23(83%) 23/29(79%) intensive manual data entry required with the unplugged
4 4/6 (67%) 17/20(85%) 21/26(81%) CAT, saving considerable time and effort. These features
5 6/6(100%) 16/20(80%) 22/26(85%)
underscoretheplatform‚Äôsscalabilityandefficiency,demon-
6 2/6 (33%) 21/22(95%) 23/28(82%)
stratingitsfeasibilityforlarge-scaleassessments.However,
7 1/5 (20%) 12/20(60%) 13/25(52%)
8 2/5 (40%) 18/21(86%) 20/26(77%) the current structure of the training module can be an ob-
9 3/4 (75%) 20/21(95%) 23/25(92%) stacle to the actual large-scale implementation. The only
10 3/5 (60%) 18/19(95%) 21/24(88%)
obstacle to large-scale implementation currently lies in the
11 2/4 (50%) 14/18(78%) 16/22(73%)
12 1/3 (33%) 14/17(82%) 15/20(75%) structure of the training module. The presence of a human
researcher during the data collection to illustrate the tool
and its functionalities could result in varying explanations,
To assess suitability, we investigate success rates in especiallyifdifferentpersonsprovidethetutorial.Thismay
individual schemas for the two age groups. Not all pupils introduceinconsistenciesthatcanaffecthowothergroupsof
couldcompleteall12proposedschemasduringtheactivity pupilsengagewiththetask,unintentionallyinfluencingtheir
due to various factors. The interruptions were primarily behavioursandperformance.
due to the allotted time for the experiment to end or other
classroom-related factors necessitating them to move on 5.1. User-drivenplatformrefinements
to other activities. Additionally, some pupils voluntarily Delving into the process of refining the virtual CAT,
discontinued the assessment in the younger age group due in this section, we explore how active collaboration with
to their limited attention spans, which is typical for young teachers and pupils from different age groups and schools
kindergarteners. To gain further insights into how students guided the improvement of the platform. In particular, by
attempted the provided tasks, Table 7 reports the success collectingfeedbackanddocumentingpertinentobservations
rates in the 12 schemas. The average success rate for all about the users‚Äô interactions with the tool, including their
schemasisapproximately75%,indicatingthatpupilsofall command preferences and progress throughout the activity
agescouldcompletethesetaskssuccessfully.Schemas9and phases, we identified areas for refinement, leading to sig-
10,inparticular,recordedimpressivelyhighpercentagesof nificant adjustments to enhance usability, proficiency and
92%and88%,respectively.Fromthetable,itisapparentthat suitability.Thefinaldesignoftheuserinterfacesisvisually
older students (10‚Äì13 years old) generally achieved higher depictedinAppendixAinFiguresA.6,A.7andA.8.
success rates, while younger students (3‚Äì6 years old), on Collaborating with the students yielded invaluable in-
the other hand, demonstrated varying degrees of success. sights for enhancing the platform. First, we noticed that as
These varying success rates reflect the intentional design timewasrunningout,concludingtheactivityrequiredindi-
strategytoincreasetaskdifficultyasschemasprogress.For viduallyconfirmingeachschema.Thisprocesswasunneces-
example, Schema 7 posed a significant challenge across saryandtime-consuming.Moreover,itledtoschemasbeing
all age groups, registering the lower success rate. Interest- marked as failed instead of not attempted. In response, we
ingly, some students successfully tackled even more com- introducedasurrenderbutton,allowinguserstoskipspecific
plex schemas. This demonstrates the platform‚Äôs flexibility schemas(seeFigure5).Thisfeaturealsoallowsusersifthey
andadaptability,demonstratingitscapacitytoaccommodate feel stuck on a task and want to move on. Additionally, to
arangeofdifficultylevels. satisfy the curiosity of some pupils who wanted to explore
Finally, to assess the feasibility of the virtual CAT for forthcoming schema, we included navigation arrows (see
large-scale assessment, a comparison with the unplugged Figure5).Inresponsetofeedbackprovidedbysomestudents
CATmethodwasnecessary.TheoriginalCAT,designedfor whofoundthevisualfeedbackbuttonunclearanddifficultto
one-on-one interactions between a student and a specialist, interpret, we took measures to improve it. We replaced the
provedimpracticalforadministeringtoanentireclasswitha buttonwithtwonewicons,onewithanopeneyeindicating
singleexpert,resultinginatime-consumingandunsuitable active visual feedback and one with a closed eye implying
choice for large-scale assessments. The virtual CAT intro- thatvisualfeedbackisturnedoff(seeFigure5).
duced a pivotal shift in the administration process. Unlike Duringthecourseoftheactivities,somestudentsshowed
the unplugged CAT, which necessitated a time-intensive interestinknowingthenumberofremainingschemastobe
individual administration process, totalling approximately completed. For this reason, we decided to add a progress
G Adorni et al. Page 10 of 21The virtual CAT
score
previous restart next
visual visual
feedback feedback
restart confirm surrender confirm
(a) Before. (b) After.
Figure 5:Changes in the interface right column.Thecurrent
schema score is added at the top. Below, navigation arrows (a) Before. (b) After.
provideawaytonavigateschemas.Theresetbuttonismoved
Figure 7: Changes in the left column of the visual program-
within the navigation controls. The surrender button is added
ming interface. Commands are reorganised into four coloured
at the bottom to skip the current schema.
menus ‚Äì moves, basic colouring, repetition-based colouring,
and symmetry-based colouring.
enhancement aligns with usability principles that recom-
Figure 6: Progress bar. Completed schemas are marked as mendindicatingactivedefaultstosuggestchoicesandvalues
correct, wrong, or skipped; the ongoing schema is in orange. andguidingdataentryinformattedfields[34].
Finally, despite having written instructions, some users
founditdifficulttounderstandhowtofillnestedblocks.To
bar at the top of the central column of the interfaces (see improveclarityandenhanceuserunderstanding,weaddeda
Figure6).Thisenhancementwasalignedwiththeusability transparentrepresentationofthetypeofblocksthatcouldbe
principle of ‚Äúprogress indicators‚Äù to help users plan and insertedwithinnestedblocks,accompaniedbymoredetailed
managetasksequencingwhilestayingmotivatedandorgan- and clearer instructions for each label (see Figure 9). This
isedthroughouttheactivities[34]. design improvement aligns with usability principles that
While observing the pupils engaging with the visual emphasiseassistingusersingettingstartedwithataskand
programminginterface,wenoticedthattheydidnotemploy providing them with comprehensive instructions to under-
alltheavailablecommandsbutonlythosethatwerereadily standhowtousedifferentinterfaceelementseffectively[34].
visible.Thiswasduetothefactthatsomecommandswere
notimmediatelyaccessibleandrequiredscrollingdownthe While observing the users engaging with the gesture
columntoseethem.Forthisreason,wegroupedcommands interface,wenoticedsomeissues.Forinstance,somecom-
into menus and revised their colours (see Figure 7). These mands were found to be unintuitive, such as the fillEmpty
adjustmentsalignwithusabilityprinciplesemphasisingthe buttonbeingusedwithoutfirstselectingthedesiredcolour.
organisation and grouping of design elements to simplify To address this, we implemented a conditional activation
content complexity, improve visibility, accessibility, intu- and deactivation of buttons based on their appropriateness
itiveness,andstreamlineuserexperience[34]. in a given context, aligning with usability principles that
Another observation we made was that some pupils recommend disabling buttons or menu choices to prevent
occasionally forgot to select the colour parameter within inappropriate choices and greying out unavailable options
the paint blocks. To make it easier for users to identify [34].Furthermore,weimplementedavisualfeedbackmech-
and adjust these parameters, we enclosed all customisable anism, which includes a shaking effect on the cross and
parameterswithinshadedboxes(seeFigure8).Thisdesign flashing available commands when users perform actions
against the intended workflow. This feature aims to guide
G Adorni et al. Page 11 of 21The virtual CAT
Ourvisionforfuturedevelopmentsinvolvescontinuous
refinementandexpansionoftheplatform.Toformallyassess
user experience, we have designed a brief survey to be
incorporated at the end of the validation module (see Fig-
ureA.10)tocollectsubjectiveimpressionsfrompupilsabout
how they perceive the tool and their overall experience.
This survey aligns with established UX design techniques
fordataelicitation[32,34]andtheTechnologyAcceptance
Model[34,91],whichconsidersfactorssuchaseaseofuse,
perceivedusefulness,attitudetowardsuse,andbehavioural
intentiontoassessusers‚Äôacceptanceofasystem.Thesurvey
coversvariousaspects,includingperceivedusability,satis-
faction,emotionalimpact,andoverallacceptanceoftheplat-
form. These factors are essential for understanding pupils‚Äô
attitudesandexperienceswithtechnologyinaneducational
context.Itdelvesintovariousfacetsoftheuserexperience,
fromtheinitialenjoymentandfamiliaritywithsuchappsto
theclarityoftheapp‚Äôsrulesandtheuser‚Äôspreferredmodeof
interaction.Italsogaugesthedifficultyleveloftheexercises
and the time taken to complete them. Towards the end,
participantsarepromptedtoreflectonwhetherthey‚Äôdrevisit
the app. We also considered that our users span different
(a) Before. (b) After. agegroupsandliteracylevels.Toaccommodatethisdiver-
sity, we have incorporated a feature that reads the survey
Figure 8: Changes in the custom parameter presentation.
questions aloud, ensuring that even younger students who
Shaded boxes distinguish customisable parameters.
maynotbeproficientreaderscaneffectivelyparticipate.The
surveyformatisdesignedtobeengagingandaccessibleto
students.Theycanrespondusingemoticons(happy,neutral,
sad),whichisconsistentwithresearchindicatingthatchild-
specific data collection methods, like smileyometers, are
valuableforassessingchildren‚Äôssubjectiveattitudestoward
interactive products [24, 31, 76]. By collecting feedback
throughthiswell-structuredsurvey,weaimtogainadeeper
understanding of pupils‚Äô perspectives and further enhance
(a) Before. (b) After.
theplatformtocatertotheirspecificneedsandpreferences.
Figure 9: Changes in the nested blocks. The updated design
includes transparent representations of possible inner blocks
within the main block. 6. DiscussionandConclusion
This research comprehensively evaluated the virtual
CAT platform, primarily focusing on its usability, profi-
pupilstowardthecorrectactions,enhancingtheoveralluser
ciency,andsuitabilityforassessingalgorithmicskillsamong
experience.
K-12studentsanditsfeasibilityforlarge-scaledatacollec-
Finally,teachersalsoofferedvaluableinsights.Onenote-
tion.Theresultsofourstudysuggestseveralkeyfindingsand
worthysuggestionwastoprovidereal-timefeedbacktohelp
offerinsightsintothepotentialofthisplatformforbroader
studentsmonitortheirprogressandperformanceduringthe
applications in educational contexts. Usability: balanced
assessment.Inresponse,weincludedaboxthatdisplaysthe
interfaceusageacrossagegroups.Thefirstoutcomeofour
current score for the ongoing schema (see Figure 5). Ad-
investigation was thebalanced usage of multipleinterfaces
ditionally, we introduced a final dashboard with a compre-
withinthevirtualCATplatformacrossdifferentagegroups
hensivesummaryofstudentperformanceacrosscompleted
andbackgrounds.Thisunderscorestheplatform‚Äôsversatility
schemas(seeFigureA.9).
and ability to cater to learners from diverse demographics,
Alltheserefinementsaimtoenhancetheplatform‚Äôsus-
ensuring they can engage effectively with the assessment
ability,proficiencyandsuitability.Tomaketheplatformen-
tasks.Thisaspectalignswiththeusabilitycriterion,reflect-
tirelyfeasibleforlarge-scaledatacollectionandassessment,
ingtheplatform‚Äôsuser-friendlinessandadaptability.
we redesigned the training module. Rather than relying on
Proficiency:diversealgorithmicapproachesacrossage
a researcher to introduce the app, we‚Äôve integrated in-app
groups. Our analysis revealed that students from different
video tutorials to let users navigate the platform indepen-
agegroupsapproachedalgorithmictaskswithvaryinglevels
dently,therebyeliminatingpotentialbiasesstemmingfrom
researcherexplanations(seeFigureA.3).
G Adorni et al. Page 12 of 21The virtual CAT
of complexity. This finding aligns with the proficiency cri- interpreter (https://doi.org/10.5281/zenodo.10016535),
terion, showcasing the platform‚Äôs ability to cater to a wide virtualCATdatainfrastructure(https://doi.org/10.5281/ze
rangeofstudentabilities. nodo.10015011).
Suitability: high engagement and success across age
groups. Our study found that students of all ages were
Funding
highlyengagedintheassessmenttasks.Thisshowsthatthe
platform effectively encourages active participation among ThisresearchwasfundedbytheSwissNationalScience
diversepupils.Manystudentsnotonlyparticipatedactively Foundation(SNSF)undertheNationalResearchProgram77
but also succeeded in completing their tasks. This combi- (NRP-77)DigitalTransformation(No:407740_187246).
nation of high engagement and success rates aligns with
the suitability criterion, demonstrating that the platform is
Declarationofcompetinginterest
effectiveinmotivatingandhelpingstudentslearn,regardless
oftheirbackgroundsandabilities. Theauthorsdeclarethattheyhavenoknowncompeting
Feasibility: large-scale assessment possible. Addition- financial interests or personal relationships that could have
ally,ourstudyexploredthepotentialforlarge-scaleassess- appearedtoinfluencetheworkreportedinthispaper.
ments,showingthatthevirtualCATiswell-equippedtohan-
dle extensive assessments efficiently. These findings align
Acknowledgements
withpriorresearchemphasisingthepotentialoftechnology-
enhancedassessmentstoyieldrichdataandfacilitateforma- WeexpressourgratitudetoSimonePiattiandVolodymyr
tiveassessmentpractices. Karpenko for contributing to implementing the CAT lan-
Our study encountered several limitations that should guageinterpreterandthevirtualCATapplication.
be acknowledged. The relatively small sample size of 31 We extend our appreciation to the contributions of Lu-
students, while suitable for a pilot study, restricts the gen- cioNegrini,FrancescoMondada,FrancescaMangili,Dorit
eralisabilityofthefindings.Technicalissues,suchasserver Assaf, and Luca Maria Gambardella, members of this re-
disconnections,dataloss,andinterruptionsduetotimecon- search project, and J√©r√¥me Guillaume Brender and Gio-
straints, class schedules, or student attention spans, might vanniProfeta.Theygenerouslydevotedtheirtimeandexper-
have impacted task attempts and success rates, particularly tise to testing the application and providing valuable feed-
among younger pupils. The study primarily focused on back.Theirinsightsandsupporthavebeenhighlyvaluable
Swiss educational settings, which limits the direct appli- throughouttherefinementandusabilityoftheapplication.
cability of the findings in other countries with different
curriculaandteachingapproaches.
DeclarationofgenerativeAIandAI-assisted
In conclusion, despite these acknowledged limitations,
technologiesinthewritingprocess
our research suggests that the virtual CAT platform shows
promiseforassessingalgorithmicskillsacrossdiverseedu- During the preparation of this work, the authors used
cationalsettingsandagegroups.Itprovidesafoundationfor ChatGPTandGrammarlytoenhancelanguageandreadabil-
futureimprovementsandapplications,especiallylarge-scale ity.Afterusingthistool/service,theauthor(s)reviewedand
assessments. edited the content as needed and take(s) full responsibility
forthecontentofthepublication.
Ethicalapproval
CRediTauthorshipcontributionstatement
This study adhered to EPFL Human Research Ethics
Committee‚Äôs (HREC) ethical standards and received ap- GiorgiaAdorni:Conceptualization,Methodology,Soft-
proval (HREC No: 048-2023). Participants and, for those ware,Validation,Formalanalysis,Investigation,Resources,
under12,theirparentsorlegalguardiansprovidedinformed Datacuration,Writing‚Äìoriginaldraft&review&editing,
consent;thoseover12alsogaveassent.FollowingSwissand Visualization, Supervision. Alberto Piatti: Conceptualiza-
international guidelines, data was handled confidentially, tion, Validation, Writing ‚Äì review & editing, Supervision,
withpseudonymisationforparticipantprotection. Projectadministration,Fundingacquisition.
Dataavailability
ThedatasupportingthisresearchisavailableinaZenodo
repository:https://doi.org/10.5281/zenodo.10018292.
Softwareavailability
The software components used in this study are open-
source: virtual CAT platform (https://doi.org/10.5281/
zenodo.10027851), virtual CAT programming language
G Adorni et al. Page 13 of 21The virtual CAT
A. Revisedplatforminterfaces
Figure A.1: Language selection.
Figure A.2: Module selection.
G Adorni et al. Page 14 of 21The virtual CAT
FigureA.3:Trainingmodule.Anintroductoryvideoabouttheapplicationisprovidedonthetrainingscreen,followedbyaseries
of explanatory videos for all practice tasks in each interface. After watching the video, users can attempt to solve the schema
using the provided instructions. When a schema is successfully solved, the video icon is marked with a green checkmark.
Figure A.4: Session form in the validation module.
G Adorni et al. Page 15 of 21The virtual CAT
Figure A.5: Student form in the validation module.
Figure A.6: CAT visual programming interface (CAT-VPI) with textual commands.
G Adorni et al. Page 16 of 21The virtual CAT
Figure A.7: CAT visual programming interface (CAT-VPI) with symbolic commands.
Figure A.8: CAT gesture interface (CAT-GI).
G Adorni et al. Page 17 of 21The virtual CAT
Figure A.9: Results dashboard. It comprehensively summarises pupils‚Äô performance across all schemas. This dashboard includes
a visual representation of reference schemas alongside those resulting from student instructions, the pupil‚Äôs score, an indication
of whether each schema was completed correctly, incorrectly, or skipped, and the time taken to complete the schema.
Figure A.10: Pupil feedback survey. The voice-assisted questions evaluate user interactions with the app. Each question is
accompanied by three distinct emoticon-style response options: a contented smiling face, a neutral face, and a discontented
frowning face. A concluding button invites users to view aggregated results.
G Adorni et al. Page 18 of 21The virtual CAT
References da7d3dbad1d4630d63a.
[19] A. Druin. Cooperative inquiry: developing new technologies for
[1] G.Adorni.DatasetfromthepilotstudyofthevirtualCATplatform childrenwithchildren. InProceedingsoftheSIGCHIconference
for algorithmic thinking skills assessment in Swiss Compulsory onHumanfactorsincomputingsystemstheCHIisthelimit-CHI
Education(1.0.0),2023. ZenodoDataset.https://doi.org/10.528 '99,pages592‚Äì599.ACMPress,1999.10.1145/302979.303166.
1/zenodo.10018292. [20] A.Druin. Theroleofchildreninthedesignofnewtechnology.
[2] G.AdorniandV.Karpenko.virtualCATdatainfrastructure(1.0.0), Behaviour and information technology, 21(1):1‚Äì25, 2002. URL
2023.ZenodoSoftware.https://doi.org/10.5281/zenodo.10015011. https://citeseerx.ist.psu.edu/viewdoc/download?amp=&amp=
[3] G.AdorniandV.Karpenko. virtualCATprogramminglanguage &doi=10.1.1.134.4492&rep=rep1&type=pdf.
interpreter(1.0.0),2023.ZenodoSoftware.https://doi.org/10.5281/ [21] A.Druin,J.Hammer,A.Kruskal,A.Lal,T.P.Schwenn,L.Sumida,
zenodo.10016535. R.Wagner,H.Alborzi,J.Montemayor,andL.Sherman. Howdo
[4] G. Adorni, S. Piatti, and V. Karpenko. virtual CAT: An app for adultsandchildrenworktogethertodesignnewtechnology? ACM
algorithmicthinkingassessmentwithinSwisscompulsoryeducation SIGCHIBulletin,32(2):7‚Äì8,Apr.2000.10.1145/360405.360411.
(1.0.1),2023. ZenodoSoftware.https://doi.org/10.5281/zenodo.1 [22] N. O. Ezeamuzie and J. W. Leung. Computational thinking
0027851. throughanempiricallens:asystematicreviewofliterature. Jour-
[5] R.E.Aebi-M√ºller,I.Blatter,J.Brigger,E.C.Constable,N.Eglin, nal of Educational Computing Research, 60(2):481‚Äì511, 2021.
P.Hoffmeyer,C.Lautensch√ºtz,A.Lienhard,C.Pirinoli,M.R√∂thlis- 10.1177/07356331211033158.
berger,andK.M.Spycher. Codeofconductforscientificintegrity. [23] G. Futschek. Algorithmic thinking: The key for understanding
https://doi.org/10.5281/ZENODO.4707560,2021. computerscience. InInformaticsEducation‚ÄìTheBridgebetween
[6] N.A.N.AhmadandM.Hussaini.Ausabilitytestingofahighered- Using and Understanding Computers, pages 159‚Äì168. Springer
ucationmobileapplicationamongpostgraduateandundergraduate BerlinHeidelberg,2006.10.1007/11915355_15.
students. InternationalJournalofInteractiveMobileTechnologies [24] M. Giannakos, P. Markopoulos, J. P. Hourcade, and A. N. An-
(iJIM),15(09):88,May2021.10.3991/ijim.v15i09.19943. tle. ‚Äòlots done, more to do‚Äô: The current state of interaction
[7] R. Amini, L. A. Stolz, J. Z. Kartchner, M. Thompson, N. Stea, designandchildrenresearchandfuturedirections. International
N.Hawbaker,R.Joshi,andS.Adhikari.Bedsideechoforchestpain: Journal of Child-Computer Interaction, 33:100469, Sept. 2022.
Analgorithmforeducationandassessment. AdvancesinMedical 10.1016/j.ijcci.2022.100469.
EducationandPractice,page293,2016.10.2147/amep.s103083. [25] Googleandcommunity. Flutterframework. https://flutter.dev/,
[8] R.M.Baecker. ReadingsinHuman-ComputerInteraction:toward 2017.[Accessed5July2023].
theyear2000.Elsevier,2014. [26] J.D.GouldandC.Lewis.Designingforusability:keyprinciplesand
[9] V.BarrandC.Stephenson. Bringingcomputationalthinkingtok- whatdesignersthink.CommunicationsoftheACM,28(3):300‚Äì311,
12:Whatisinvolvedandwhatistheroleofthecomputerscience Mar.1985.10.1145/3166.3170.
educationcommunity? ACMInroads,2(1):48‚Äì54,feb2011. ISSN [27] J.GreenbaumandM.Kyng.Designatwork:Cooperativedesignof
2153-2184.10.1145/1929887.1929905. computersystems.CRCPress,2020.
[10] R.BogdanandS.K.Biklen. Qualitativeresearchforeducation. [28] A.D.Greig,M.J.Taylor,andT.MacKay. Doingresearchwith
Allyn&BaconBoston,MA,1997. URLhttp://math.buffalostate. children.Sage,2007.
edu/dwilson/MED595/Qualitative_intro.pdf. [29] A.D.Greig,J.Taylor,andT.MacKay.Doingresearchwithchildren:
[11] N.Borgers,E.deLeeuw,andJ.Hox. Childrenasrespondentsin Apracticalguide.Sage,2012.
surveyresearch:Cognitivedevelopmentandresponsequality1.Bul- [30] S.GroverandR.Pea.Computationalthinkingink‚Äì12:Areviewof
letinofSociologicalMethodology/BulletindeM√©thodologieSoci- thestateofthefield. Educationalresearcher,42(1):38‚Äì43,2013.
ologique,66(1):60‚Äì75,Apr.2000.10.1177/075910630006600106. 10.3102/0013189X12463051.
[12] K.BrennanandM.Resnick. Newframeworksforstudyingandas- [31] A.-M.Guran,G.-S.Cojocar,andA.Turian. Towardspreschool-
sessingthedevelopmentofcomputationalthinking.InProceedings ers‚Äô automatic satisfaction assessment. an experience report. In
ofthe2012annualmeetingoftheAmericaneducationalresearch 2020 IEEE 14th International Symposium on Applied Compu-
association,Vancouver,Canada,volume1,page25,2012. https: tational Intelligence and Informatics (SACI). IEEE, May 2020.
//web.media.mit.edu/~kbrennan/files/Brennan_Resnick_AERA201 10.1109/saci49304.2020.9118824.
2_CT.pdf. [32] B.HaningtonandB.Martin.Universalmethodsofdesignexpanded
[13] V.Campbell-Barr,M.Lavelle,andK.Wickett. Exploringalterna- andrevised:125Waystoresearchcomplexproblems,developin-
tiveapproachestochildoutcomeassessmentsinchildren'scentres. novativeideas,anddesigneffectivesolutions. Rockportpublishers,
Early Child Development and Care, 182(7):859‚Äì874, July 2012. 2019.
10.1080/03004430.2011.590937. [33] L. Hanna, K. Risden, and K. Alexander. Guidelines for usabil-
[14] J. M. CARROLL, M. K. SINGLEY, and M. B. ROSSON. ity testing with children. Interactions, 4(5):9‚Äì14, Sept. 1997.
Integrating theory development with design evaluation. Be- 10.1145/264044.264045.
haviour & Information Technology, 11(5):247‚Äì255, Sept. 1992. [34] R.HartsonandP.S.Pyla. TheUXbook:AgileUXdesignfora
10.1080/01449299208924345. qualityuserexperience.MorganKaufmann,2018.
[15] C.K.CoursarisandD.J.Kim.Ameta-analyticalreviewofempirical [35] K.HoltzblattandH.Beyer. Contextualdesign:definingcustomer-
mobileusabilitystudies. J.UsabilityStudies,6(3):117‚Äì171,may centeredsystems. Elsevier,1997. https://dl.acm.org/doi/book/10.5
2011. URLhttp://uxpajournal.org/a-meta-analytical-review-of-e 555/2821566.
mpirical-mobile-usability-studies/. [36] J. P. Hourcade. Interaction design and children. Foundations
[16] M.Csernoch,P.Bir√≥,J.M√°th,andK.Abari. Testingalgorithmic andTrends¬ÆinHuman-ComputerInteraction,1(4):277‚Äì392,2007.
skillsintraditionalandnon-traditionalprogrammingenvironments. 10.1561/1100000006.
Informatics in Education, 14(2):175‚Äì197, 2015. 10.15388/in- [37] N. Iivari and M. Kinnula. Empowering children through de-
fedu.2015.11. sign and making. In Proceedings of the 15th Participatory
[17] V.DagieneÀôandS.Sentance. It‚ÄôsComputationalThinking!Bebras Design Conference: Full Papers - Volume 1. ACM, Aug. 2018.
TasksintheCurriculum.InInternationalconferenceoninformatics 10.1145/3210586.3210600.
in schools: Situation, evolution, and perspectives, pages 28‚Äì39. [38] O.S.IversenandC.Dindler. Autopianagendainchild‚Äìcomputer
Springer,Springer,Cham,2016.10.1007/978-3-319-46747-4_3. interaction.InternationalJournalofChild-ComputerInteraction,1
[18] W. Dick, L. Carey, and J. O. Carey. The systematic design of (1):24‚Äì29,Jan.2013.10.1016/j.ijcci.2012.08.002.
instruction. Citeseer,2005. URLhttps://citeseerx.ist.psu.edu/
document?repid=rep1&type=pdf&doi=671f411d07f151f589184
G Adorni et al. Page 19 of 21The virtual CAT
[39] O.S.IversenandR.C.Smith. Scandinavianparticipatorydesign: [56] M.L.Mart√≠nez,O.L√©v√™que,I.Ben√≠tez,C.Hardebolle,andJ.D.
dialogiccurationwithteenagers.InProceedingsofthe11thInterna- Zufferey. Assessing computational thinking: Development and
tionalConferenceonInteractionDesignandChildren.ACM,June validation of the algorithmic thinking test for adults. Jour-
2012.10.1145/2307096.2307109. nalofEducationalComputingResearch,60(6):1436‚Äì1463,2022.
[40] O.S.Iversen,R.C.Smith,andC.Dindler.Childasprotagonist:Ex- 10.1177/07356331211057819.
pandingtheroleofchildreninparticipatorydesign.InProceedings [57] K.I.McCormickandJ.A.Hall. Computationalthinkinglearning
ofthe2017ConferenceonInteractionDesignandChildren,pages experiences,outcomes,andresearchinpreschoolsettings:ascoping
27‚Äì37.ACM,2017.10.1145/3078072.3079725. reviewofliterature.EducationandInformationTechnologies,pages
[41] J. Jocz, K. A. Peterson, and D. Pfeif. Motivating youth to learn 1‚Äì36,2022.10.1007/s10639-021-10765-z.
STEMthroughagenderinclusivedigitalforensicscienceprogram. [58] M.J.MullerandS.Kuhn.Participatorydesign.Communicationsof
SmartLearningEnvironments,10(1),2023. 10.1186/s40561-022- theACM,36(6):24‚Äì28,June1993.10.1145/153571.255960.
00213-x. [59] M.J.Muller,D.M.Wildman,andE.A.White.‚Äúequalopportunity‚Äù
[42] Y.B.Kafai,C.C.Ching,andS.Marshall. Childrenasdesignersof PDusingPICTIVE. CommunicationsoftheACM,36(6):64,June
educationalmultimediasoftware.Computers&Education,29(2-3): 1993.10.1145/153571.214818.
117‚Äì126,Nov.1997.10.1016/s0360-1315(97)00036-5. [60] M.J.Muller,D.M.Wildman,andE.A.White.Participatorydesign
[43] Y. Kali and T. R. Fuhrmann. Teaching to design educational throughgamesandothergroupexercises.InConferencecompanion
technologies. InternationalJournalofLearningTechnology,6(1): onHumanfactorsincomputingsystems-CHI'94.ACMPress,1994.
4,2011.10.1504/ijlt.2011.040147. 10.1145/259963.260530.
[44] P.K.Keith,F.R.Sullivan,andD.Pham. Roles,collaboration,and [61] F. Nayebi, J.-M. Desharnais, and A. Abran. The state of the art
thedevelopmentofcomputationalthinkinginaroboticslearning of mobile application usability evaluation. In 2012 25th IEEE
environment. In ComputationalThinking Education, pages223‚Äì Canadian Conference on Electrical and Computer Engineering
245.SpringerSingapore,2019.10.1007/978-981-13-6528-7_13. (CCECE).IEEE,Apr.2012.10.1109/ccece.2012.6334930.
[45] M. Kinnula and N. Iivari. Manifesto for children‚Äôs genuine par- [62] J.Nielsen. Usabilityengineering. Elsevier,1993. 10.1016/c2009-
ticipationindigitaltechnologydesignandmaking. International 0-21512-1.
Journal of Child-Computer Interaction, 28:100244, June 2021. [63] J.Nielsen.Usabilityinspectionmethods.InConferencecompanion
10.1016/j.ijcci.2020.100244. onHumanfactorsincomputingsystems-CHI'94.ACMPress,1994.
[46] M. Kinnula, N. Iivari, T. Molin-Juustila, E. Keskitalo, and 10.1145/259963.260531.
T.Leinonen. Cooperation,combat,orcompetencebuilding-what [64] J.Nielsen.Scenariosindiscountusabilityengineering.InScenario-
do we mean when we are ‚Äôempowering children‚Äô in and through BasedDesign:Envisioningworkandtechnologyinsystemdevelop-
digital technology design? In Proceedings of the International ment,pages59‚Äì83.JohnWiley&Sons,Inc.,1995.https://dl.acm.o
Conference on Information Systems - Transforming Society with rg/doi/abs/10.5555/209227.209233.
DigitalInnovation,ICIS2017,Seoul,SouthKorea,December10- [65] OECD.PISA2018Results(VolumeVI):Arestudentsreadytothrive
13,2017.AssociationforInformationSystems,2017.http://aisel.ai inaninterconnectedworld?OECD:OrganisationforEconomicCo-
snet.org/icis2017/TransformingSociety/Presentations/15. operationandDevelopment,2020.10.1787/d5f68679-en.
[47] J.Kolko.Movingonfromrequirements.Interactions,22(6):22‚Äì23, [66] I. S. . E. of Human-System Interaction (Subcommittee). Er-
Oct.2015.10.1145/2824754. gonomicRequirementsforOfficeWorkwithVisualDisplayTermi-
[48] S.-C.Kong,H.Abelson,andM.C.Lai. IntroductionToComputa- nals(VDTs).:GuidanceonUsability.InternationalOrganizationfor
tionalThinkingEducation,pages1‚Äì10. SpringerSingapore,2019. Standardization,1998.https://www.iso.org/standard/63500.html.
10.1007/978-981-13-6528-7_1. [67] N.V.Olkhova. Developmentofalgorithmicthinkinginprimary
[49] √ñ.KorkmazandX.Bai. AdaptingComputationalThinkingScale schoolstudentswhenstudyingcomputerscience.ScientificBulletin
(CTS)forChineseHighSchoolStudentsandTheirThinkingScale ofMukachevoStateUniversity.SeriesPedagogyandPsychology,8
SkillsLevel.ParticipatoryEducationalResearch,6(1):10‚Äì26,2019. (2):25‚Äì32,2022.10.52534/msu-pp.8(2).2022.25-32.
10.17275/per.19.2.6.1. [68] A.Olukand√ñ.Korkmaz. Comparingstudents‚Äôscratchskillswith
[50] √ñ.Korkmaz,R.√áakir,andM.Y.√ñzden. Avalidityandreliability theircomputationalthinkingskillsintermsofdifferentvariables.
study of the computational thinking scales (cts). Computers in InternationalJournalofModernEducationandComputerScience,
HumanBehavior,72:558‚Äì569,2017.10.1016/j.chb.2017.01.005. 8(11):1‚Äì7,2016.10.5815/ijmecs.2016.11.01.
[51] S.Kujala. User involvement: Areviewof thebenefitsand chal- [69] S.S.Oyelere,F.J.Agbo,andI.T.Sanusi.Developingapedagogical
lenges. Behaviour & Information Technology, 22(1):1‚Äì16, Jan. evaluationframeworkforcomputationalthinkingsupportingtech-
2003.10.1080/01449290301782. nologiesandtools. FrontiersinEducation,7,2022. ISSN2504-
[52] B.Kules.Computationalthinkingiscriticalthinking:Connectingto 284X.10.3389/feduc.2022.957739.
universitydiscourse,goals,andlearningoutcomes. Proceedingsof [70] V.PetousiandE.Sifaki. Contextualisingharmintheframeworkof
theAssociationforInformationScienceandTechnology,53(1):1‚Äì6, researchmisconduct.findingsfromdiscourseanalysisofscientific
2016.10.1002/pra2.2016.14505301092. publications.InternationalJournalofSustainableDevelopment,23
[53] F.K.Lehnert,J.Niess,C.Lallemand,P.Markopoulos,A.Fischbach, (3/4):149,2020.10.1504/ijsd.2020.115206.
and V. Koenig. Child-computer interaction: From a systematic [71] A.Piatti,G.Adorni,L.El-Hamamsy,L.Negrini,D.Assaf,L.Gam-
review towards an integrated understanding of interaction design bardella,andF.Mondada.TheCT-cube:Aframeworkforthedesign
methods for children. International Journal of Child-Computer andtheassessmentofcomputationalthinkingactivities.Computers
Interaction,32:100398,June2022.10.1016/j.ijcci.2021.100398. in Human Behavior Reports, 5:100166, 2022. ISSN 2451-9588.
[54] P.MarkopoulosandM.Bekker. Interactiondesignandchildren. 10.1016/j.chbr.2021.100166.
InteractingwithComputers,15(2):141‚Äì149,2003. 10.1016/s0953- [72] M. Pilotti, E. Nazeeruddin, N. Mohammad, I. Daqqa, H. Abdel-
5438(03)00004-3. salam, and M. M. Abdullah. Is initial performance in a course
[55] P.Markopoulos,M.Bekker,etal.Howtocompareusabilitytesting informative?machinelearningalgorithmsasaidsfortheearlyde-
methodswithchildrenparticipants. InProceedingsoftheInterna- tectionofat-riskstudents. Electronics,11(13):2057,2022. https:
tionalWorkshop"InteractionDesignandChildren",Eindhoven,The //doi.org/10.3390/electronics11132057.
Netherlands,August28-29,2002,volume2,pages153‚Äì158.Shaker- [73] E.Polat,S.Hopcan,S.Kucuk,andB.Sisman. Acomprehensive
Verlag,2002.URLhttps://www.researchgate.net/publication/22888 assessment of secondary school students‚Äô computational thinking
9371_How_to_compare_usability_testing_methods_with_childre skills.BritishJournalofEducationalTechnology,52(5):1965‚Äì1980,
n_participants. 2021.10.1111/bjet.13092.
G Adorni et al. Page 20 of 21The virtual CAT
[74] E.PoulakisandP.Politis.ComputationalThinkingAssessment:Lit- [91] P.Surendran. TechnologyAcceptanceModel:ASurveyofLitera-
eratureReview,pages111‚Äì128. SpringerInternationalPublishing, ture. InternationalJournalofBusinessandSocialResearch,2(4):
Cham,2021.10.1007/978-3-030-64363-8_7. 175‚Äì178,August2012.URLhttps://ideas.repec.org/a/mir/mirbus/v
[75] Y.QianandJ.D.Lehman. Usingtechnologytosupportteaching 2y2012i4p175-178.html.
computer science: a study with middle school students. Eurasia [92] J.Tidwell. Designinginterfaces:Patternsforeffectiveinteraction
JournalofMathematicsScienceandTechnologyEducation,14(12), design.O‚ÄôReillyMedia,2010.
2018.10.29333/ejmste/94227. [93] M. J. Tsai, J. C. Liang, and C. Y. Hsu. The computa-
[76] J. C. Read and S. MacFarlane. Using the fun toolkit and other tional thinking scale for computer literacy education. Jour-
survey methods to gather opinions in child computer interaction. nal of Educational Computing Research, 59(4):579‚Äì602, 2020.
InProceedingsofthe2006conferenceonInteractiondesignand 10.1177/0735633120972356.
children.ACM,June2006.10.1145/1139073.1139096. [94] S.ValguarneraandM.Landoni. Designwithandforchildren:The
[77] J. C. Read, S. MacFarlane, and P. Gregory. Requirements for challenge of inclusivity. In Lecture Notes in Computer Science,
thedesignofahandwritingrecognitionbasedwritinginterfacefor pages171‚Äì184.SpringerNatureSwitzerland,2023. 10.1007/978-
children. In Proceedings of the 2004 conference on Interaction 3-031-35681-0_11.
design and children: building a community. ACM, June 2004. [95] S.Valguarnera,C.M.Sylla,andM.Landoni. TheIDCresearch
10.1145/1017833.1017844. and design challenge throughout the years: achievements, reflec-
[78] M.Rom√°n-Gonz√°lez,J.Moreno-Le√≥n,andG.Robles.Complemen- tions and next steps. In Proceedings of the 22nd Annual ACM
taryToolsforComputationalThinkingAssessment.InProceedings Interaction Design and Children Conference. ACM, June 2023.
ofInternationalConferenceonComputationalThinkingEducation 10.1145/3585088.3589382.
(CTE2017),S.CKong,JSheldon,andK.YLi(Eds.).TheEducation [96] J.VoogtandN.P.Roblin. Acomparativeanalysisofinternational
UniversityofHongKong,pages154‚Äì159,2017. https://www.eduh frameworksfor21stcenturycompetences:Implicationsfornational
k.hk/cte2017/doc/CTE2017%20Proceedings.pdf. curriculumpolicies.JournalofCurriculumStudies,44(3):299‚Äì321,
[79] M.Rom√°n-Gonz√°lez,J.Moreno-Le√≥n,andG.Robles. Combining 2012.10.1080/00220272.2012.668938.
assessmenttoolsforacomprehensiveevaluationofcomputational [97] F. Wickey da Silva Garcia, S. Ronaldo Bezerra Oliveira, and
thinking interventions. Computational thinking education, pages E.daCostaCarvalho. Applicationofateachingplanforalgorithm
79‚Äì98,2019.10.1007/978-981-13-6528-7_6. subjectsusingactivemethodologies:Anexperimentalreport. In-
[80] M. Romero, A. Lepage, and B. Lille. Computational thinking ternationalJournalofEmergingTechnologiesinLearning(Ijet),17
developmentthroughcreativeprogramminginhighereducation.In- (07):175‚Äì207,2022.10.3991/ijet.v17i07.28733.
ternationalJournalofEducationalTechnologyinHigherEducation, [98] R. Williges. Evaluating human-computer software interfaces.
14(1):1‚Äì15,2017.10.1186/s41239-017-0080-z. In Proceedings of International Conference on Occupational Er-
[81] M. Rom√°n-Gonz√°lez, J.-C. P√©rez-Gonz√°lez, and C. Jim√©nez- gonomics,pages81‚Äì87,1984.
Fern√°ndez. Whichcognitiveabilitiesunderliecomputationalthink- [99] J.M.Wing.Computationalthinking.CommunicationsoftheACM,
ing?criterionvalidityofthecomputationalthinkingtest.Computers 49(3):33‚Äì35,2006.10.1145/1118178.1118215.
inHumanBehavior,72:678‚Äì691,2017.10.1016/j.chb.2016.08.047. [100] A.Yadav,C.Mayfield,N.Zhou,S.E.Hambrusch,andJ.T.Korb.
[82] M. Scaife, Y. Rogers, F. Aldrich, and M. Davies. Designing for Computationalthinkinginelementaryandsecondaryteachereduca-
or designing with? informant design for interactive learning en- tion.AcmTransactionsonComputingEducation,14(1):1‚Äì16,2014.
vironments. In Proceedings of the ACM SIGCHI Conference on 10.1145/2576872.
Humanfactorsincomputingsystems,pages343‚Äì350,1997. URL [101] S.Yarosh,I.Radu,S.Hunter,andE.Rosenbaum.Examiningvalues:
https://dl.acm.org/doi/pdf/10.1145/258549.258789. an analysis of nine years of idc research. In Proceedings of the
[83] R. Scherer, F. Siddiq, and B. S. Viveros. The cognitive benefits 10thInternationalConferenceonInteractionDesignandChildren.
of learning computer programming: a meta-analysis of transfer ACM,June2011.10.1145/1999030.1999046.
effects.JournalofEducationalPsychology,111(5):764‚Äì792,2019. [102] C. D. Yildiz. Ideal classroom setting for english language
10.1037/edu0000314. teaching through the views of english language teachers (a sam-
[84] D.SchulerandA.Namioka. Participatorydesign:Principlesand ple from turkey). English Language Teaching, 13(3):31, 2020.
practices.CRCPress,1993.10.1201/9780203744338. 10.5539/elt.v13n3p31.
[85] M.Scriven. Themethodologyofevaluation. In.Tyler,Rw,Gagne,
Rm,Scriven,M.(Ed.):PerspectivesofCurriculumEvaluation,Rand
McNally,Chicago,1972.10.25656/01:1423.
[86] D.Seehorn,S.Carey,B.Fuschetto,I.Lee,D.Moix,D.O‚ÄôGrady-
Cunniff, B. B. Owens, C. Stephenson, and A. Verno. CSTA K‚Äì
12 Computer Science Standards: Revised 2011. Association for
ComputingMachinery,2011. https://dl.acm.org/doi/pdf/10.11
45/2593249.
[87] V.R.Simmering,L.Ou,andM.Bolsinova.Whattechnologycanand
cannotdotosupportassessmentofnon-cognitiveskills. Frontiers
inPsychology,10,2019.10.3389/fpsyg.2019.02168.
[88] SNSF. OpenScience. https://www.snf.ch/en/dah3uC2QX95tfPNd
/topic/open-science,2021.[Accessed26August2023].
[89] J.Stanja,W.Gritz,J.Krugel,A.Hoppe,andS.Dannemann.Forma-
tiveassessmentstrategiesforstudents‚Äôconceptions‚Äîthepotentialof
learninganalytics. BritishJournalofEducationalTechnology,54
(1):58‚Äì75,2022.10.1111/bjet.13288.
[90] D.Sun,F.Ouyang,Y.Li,andC.Zhu. Comparinglearners‚Äôknowl-
edge, behaviours, and attitudes between two instructional modes
ofcomputerprogramminginsecondaryeducation. International
JournalofSTEMEducation,8(1),Sept.2021.10.1186/s40594-021-
00311-1.
G Adorni et al. Page 21 of 21