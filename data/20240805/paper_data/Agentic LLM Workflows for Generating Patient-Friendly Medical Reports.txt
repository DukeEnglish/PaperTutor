Agentic LLM Workflows for Generating Patient-Friendly
Medical Reports
Malavikha Sudarshan¹, Sophie Shih², Estella Yee², Alina Yang², John Zou³,
Cathy Chen⁴, Quan Zhou⁵, Leon Chen⁵ ,Chinmay Singhal⁵ and George Shih6
¹DepartmentofElectricalEngineeringandComputerSciences,UniversityofCalifornia,Berkeley,CA,USA
²StuyvesantHighSchool,NY,USA
³DepartmentofComputerScience,BrownUniversity,RI,USA
⁴SternSchoolofBusiness,NewYorkUniversity,NY,USA
⁵MD.ai,NY,USA
6DepartmentofRadiology,WeillCornellMedicine,NY,USA
malavikhasudarshan@berkeley.edu,{sshih60,eyee60,ayang61}@stuy.edu,john_zou@brown.edu,
hc2845@nyu.edu,{chinmay,quan,leon}@md.ai,george@cornellradiology.org
Abstract
The applicationofLargeLanguageModels(LLMs)inhealthcareisexpandingrapidly,withonepotentialusecase
being thetranslationofformalmedicalreportsintopatient-legibleequivalents.Currently,LLMoutputsoftenneed
to be edited and evaluated by a human to ensure both factual accuracy andcomprehensibility,andthisistruefor
the above use case. We aim to minimize this step by proposing an agentic workflow with the Reflexion
framework, which uses iterative self-reflection to correct outputs from an LLM. This pipeline was tested and
comparedtozero-shotpromptingon16randomizedradiologyreports.Inourmulti-agentapproach,reportshadan
accuracy rate of 94.94% when looking at verification of ICD-10 codes, compared tozero-shotpromptedreports,
which had an accuracy rate of 68.23%. Additionally,81.25%ofthefinalreflectedreportsrequirednocorrections
for accuracy or readability, while only 25% of zero-shot prompted reports met these criteria without needing
modifications. These results indicate that our approach presents a feasible method for communicating clinical
1findings to patients in a quick, efficient and coherent manner whilst also retaining medical accuracy. All code is
availableforviewingathttp://github.com/malavikhasudarshan/Multi-Agent-Patient-Letter-Generation.
Keywords: Large Language Models, Patient-Friendly Letters, Patient Literacy, Radiology, Report
Generation,GPT.
1. Background
The 21st Century Cures Act grants patients the right to access their electronic health record data, and since its
implementation, the number of patients accessing their Electronic Health Records (EHRs) before the ordering
provider has increased significantly [1]. While intended to improve transparency and promote a shared flow of
information, this increased level of accessibility can oftenleadtopatientanxiety,misinterpretationandconfusion
when reading jargon-filled medical reports that they are not theprimaryaudiencefor[2].Radiologyreportsarea
prime example of these; mostly intended for referring physicians, when abnormal or ambiguous results are
received by patients before discussion with their physician, the impact canoftenbemoreharmfulthanbeneficial
[3]. To address this, the creation of patient-friendly letters that simplify complex medical information has been
explored [4]. These letters aim to explain medical terms clearly, ensure factual accuracy, and also maintain a
compassionateandreassuringtone.
In recent years, Large Language Models (LLMs) have been increasingly leveraged in healthcare applications,
from producing discharge summaries [5] to structured radiology reports [6]. In applying generative artificial
intelligence to the creation of patient-friendly reports, the pipeline can be made more efficient and patients can
have access to more meaningful and legibleletters[7,8].Mostcurrentdevelopmentsinvokezero-shotprompting
to create a patient-friendly version of a medical report included in the input prompt, where the LLM’s internal
representations are relied upon to produce a suitable letter, and no template or example output is providedinthe
prompt forguidingthestructure,styleorcomprehensivenessofthegeneratedletters[9,10].Throughthismethod,
LLMs often generate outputs that need to be manually reviewed or go through alternative mechanisms to be
critiqued andimprovedbeforebeingdeliveredtothepatient.Oneresearchstudyconcludedthat80.4%(n=41)of
2tested patient-friendly LLM-generated summaries of medical reports required editing before being released to
patients [11]. Our goal was to develop an agentic pipeline where verification would be minimized, and where
patientletterswouldbeevaluatedforbothaccuracyandreadabilitybeforebeingreleased.
2. Methods
Agentic workflows are iterative and consist of several intermediary steps performed in addition to LLM
prompting, as opposed to non-agentic or zero-shot/few-shot prompts which consist of a single inputandasingle
output [12]. The former approach means that multiple agents can be leveraged, and they are often structured
similar to professional businesses, where each agent plays a specific role in the organization.
Addition-by-Subtraction collaboration is one example of a multi-agent method, where one agent provides
informationandtheotherremovesunnecessarydetailsandprovidesfeedback[13].
Agentic workflows allow for reinforcement learning through reflection [12], and can utilize chain-of-thought
prompting by appending reflected feedback at the end of the next prompt. We leveraged an existing framework,
Reflexion [14], which incorporates verbal reinforcement into its iterative refinement process. Typically, agents
receive feedback from their environment in a simple form, like a binary signal (e.g., success/failure) or a scalar
value (a numerical score). Reflexion agents take this basic feedback and translate it into a more detailed, verbal
form—atextualsummarythatexplainsthefeedbackinnaturallanguage.Thisverbalfeedbackisthenaddedtothe
context of the following prompt, and acts as a 'semantic' gradient signal, meaning that it provides theagentwith
specific,meaningfuldirectionsonhowtoimprove.
Our implementation prompts an LLM to generate a specific number of patient-friendly letters based on aformal
medical report.Theaccuracyandreadabilityofeachgeneratedletteriscalculatedandweightedappropriately,and
the Reflexion model is then used to run a certain number of self-reflection trials and output the letter that it
considers to be optimal at the end of this. Reflexion has three separate legs – AlfWorld (for decision-making
problems), HotPotQA (for reasoning on single-step iterations) and Programming (for programming tasks using
3interpreters and compilers). We used AlfWorld, as decision-making made the most sense when prompting for
multiplelettersandaskingforthemostoptimaloutput.
The original medical report can either be provided as anargument,or,aswepresentedattheSocietyforImaging
Informatics in Medicine (SIIM) 2024 Hackathon, be pulled from an EHR server. Our integration involved
extracting one of the five medical reports available on the SIIM Fast Healthcare Interoperability Resources
(FHIR) server and pushing our results back onto the server. Manually including the medical report in the input
was also later tested on 15 other test radiology reports of various modalities: Computed Tomography (CT),
Magnetic Resonance Imaging (MR), and Ultrasound (US) (see Figs. 1, 2 and 3 in the Appendix). These reports
differed in length, ranging from 84 to 264 words, and covered a range of medical findings and body parts,
includingtheabdomen,pelvis,chest,head,andlumbarspine.
Our pipeline (Fig. 1) operatesasfollows:wefirstmakeoneLLMcalltoextracttheInternationalClassificationof
Diseases, Tenth Revision (ICD-10) codes from the original report. The temperature is kept at 0 to minimize
variance, andthesecodesarestoredtobecomparedlater.AsecondLLMcallisthenusedtogenerateanumberof
patient-friendly reports (n=5, for example) based on the original, and this time we ask the agent to produce
ICD-10 codes based on the content of each patient-friendly letter. These ICD-10 codes are verified against the
master ICD-10 code database (using the simple-icd-10 package [15]) and the description for each code is also
retrieved and compared against theLLM’soutputtoseeiftheymatch.Theaccuracyofeachletteriscalculatedas
the number of validated and identical ICD-10codesbetweenthepatient-friendlyversionandtheoriginalmedical
report, divided by the total number of ICD-10 codes on the original report. This value should be maximized.
Readability is quantified using the Flesch-Kincaid Grade Level. This value is calculated using a predefined
formula incorporating the average sentence length, number of syllables and number of words per sentence [16]
and can be accessed by importing the readability module [17]. The average American’s reading ability is
equivalent to a US 8th-grade level [18]. A previous study examining 97,052 radiology reportsrevealedthatonly
4% were at a reading level equal to or below the readingabilityofaUS8th-grader[19],suggestingthatmuchof
4thisinformationmaybeunintelligibletoasignificantportionofthepopulation.Our16testreportshadanaverage
Flesch-KincaidGradeLevelof11.03,correspondingtoan11th-grader’sexpectedlevelofvocabulary.
A Flesch-Kincaid Grade Level of 6.0 (corresponding to a US 6th-grader’s reading ability) is the recommended
level of readability advised by the American Medical Association [20] and the National Institute of Health [21]
for patient-facing medical materials, to allow forgreatercomprehensibilityandaccessibility[22].Eachgenerated
patient letter’s overall score is calculated by weighting the readability and accuracy - we wanted to prioritize
medical accuracy so opted to compute the score as follows: overall_score = (readability * 0.3) +
(accuracy * 0.7)
The readability value is standardized to be as close to 6.0 as possible, therefore,wecanaimforanoverall_score
that has a maximum value of 1.0. Reflexion’s Alfworld module is then used to reflect on the overall_score,
looking to improve both the accuracy and readability of each letter on each iteration. The algorithm outputs the
best version of the letter, whichisthendirectlypushedtothelinkedEHRserverforpatientaccess,demonstrating
end-to-endintegration.TheLLMusedinourtestswasOpenAI’sGPT-4o(gpt-4o-2024-05-13).
5Figure1:FlowchartoftheMulti-AgentAlgorithm
63. Results
Our reflection agent increased the medical accuracy of reports, ensuring that ICD-10 codes were retained in the
final patient letter which the zero-shot output sometimes missed. Whengivenanidenticalmedicalreport,system
prompt and user prompt, the reflected output consistently scored higher in terms of accuracy and readability, as
well as in theoverall_scoremeasure.Zero-shotpromptsweresometimesnotprofessionalenough,andevenwhen
specified in the prompt that the reading level should match that of a US 6th grader’s, the language usedwastoo
juvenile. However, when the reflected agent was used, the final outputs seemed to be consistentlymoreconcise,
structured and formal. In the example below (Fig. 2 and Fig. 3), the same medical report was usedtocomparea
zero-shot (Fig. 2) and reflection agent output (Fig. 3). With zero-shotprompting,onlyhalfofthedesiredICD-10
codes were registered, whereas the reflection agent successfully generated all 4 ICD-10 codes. Additionally, the
ICD-10 codes generated by the reflection agent precisely matched those from the original medical report, while
thecodesfromthezero-shotreportdidnot.
7Figure2:Zero-ShotGeneratedPatient-FriendlyLetter
8Figure3:Reflection/Multi-AgentGeneratedPatient-FriendlyLetter
From 16 test radiology reports, zero-shot prompting (using the same original prompt as given inourmulti-agent
workflow) led to 11/16 patient-friendly versions needing to be edited, whilst our agentic workflow resulted in
only3/16reportsthatrequiredmodification.Weconsidered‘modification’tobeanychangesinmedicalfactuality
(including ICD-10 codes), grammar, punctuation, tonality and readability. On average, accuracy was 26.71%
better, and readability scored 3.29% higher in the reflected patient letters, compared to the zero-shotletters(Fig.
4).Thisresultedina17.51%increaseinoverall_scoreinreflectedlettersvszero-shotgeneratedletters.
Summaryof Readability Accuracy OverallScore(0.7*Accuracy+
Results (Flesch-KincaidGrade) (ICD-10CodeMatches) 0.3*Readability)
LLMPipeline Average %Difference Average %Difference Average %Difference
Zero-shot 3.648 0.682 0.320
+3.29 +26.71 +17.51
ReflectionAgent 3.846 0.949 0.495
Figure4:SummaryTableofResults
94. Discussion
The use of ChatGPT and similarLLMsforthegenerationofpatientfriendlylettersissomethingthatmanyothers
in the healthcare space have been experimenting with [5][10][23][24][25]. However, LLMs are known to
hallucinate and are extremely sensitive to input, which can often lead to errors in the outputted patient-friendly
letter. Additionally, the more complex the medical report, the higher the tendency for LLMs to hallucinate [26].
The inclusion of multiple agents and programmatic prompts1 aim to manage the complexity of medical reports,
whilst simultaneously minimizing hallucinations. This workflow reducestheneedforproofreading,asthepatient
lettersareevaluatedforbothaccuracyandreadabilitybeforebeingoutputted.
As part of our accuracy metric, we make use of the get_description(icd10_code) [15] function to verifywhether
the ICD-10codedefinitionsmatchindustry-standardfortheoriginalandpatient-friendlyreports.However,asthis
function uses string matching, it is possible that we may miss out on synonymous definitions or phrases with a
few variances in words. A better alternative may be to use fuzzy matching algorithms such as calculating the
Levenshtein distance [27], or looking at theK-NearestNeighbors[28]ofthetwodescriptionstringstocategorize
them,insteadofcomparingtwostringsforanexactmatch.
One assumption we make is the accuracy of the ICD-10 codes generated by the LLM model (GPT-4o). In
separate human validation tests, we have seen high accuracy and consistency when generating these codes from
testradiologyreports,sointhisstudyweassumethatthesegeneratedICD-10codescanbetrusted.
This is still a very early prototype and can be improved upon in several ways. In the future, wehopetobemore
inclusive of different reading levels, languages, and medical fields. Currently, we have standardized the level of
readability to a 6th grade level; however, it would be beneficial to have a variety of literacy levels available
depending on the patient. Additionally, adding the functionality for accurate translation in various languages
would significantly enhance communication abilities as well as global applicability and reach. Finally, we are
aimingtobeapplicabletovariousmedicalfieldsoutsideradiology.
1LLMpromptshavebeenprogrammedandcannotbealteredbyusers—handlesissueofsensitivitytoinput.
10As of now, our weightingsystemisbaseduponreadabilityandaccuracy.However,weunderstandtheimportance
of maintaining a certain level of compassion within these letters. One possible approach is utilizingthePERMA
model [29] as a metric for factoring in compassion into our weighting system. The PERMA scale can help our
model determine whether a patient letterhastheappropriatetoneandlevelofsensitivity.Otheradditionalmetrics
we are looking into to further enhance patient letters include CDE codes [30], which can help to accurately
conveyapatient'streatmentprocessandfutureactionrequired.
5. Conclusion
Our objective was to find a method of generating patient-friendly radiology reports that would really reduce the
need for a medical professional to review and verifythem.Althoughourapproachdoessignificantlyimprovethe
quality of patient-legible letters, it doesn’t have an100%successrate,andthereforecannoteradicatetheneedfor
verification completely. However, by significantly reducing the percentage of LLM-generated reports requiring
edits—from 68.75% to 18.75%—through the incorporation of amulti-agentworkflow,wecanshowthatthetime
spent making changes in medical accuracy and readability will also be substantially decreased. Our method not
only enhances the efficiency of report generation but also contributes to the overall goal of making healthcare
information more accessible and understandable to patients. This development has strong potential to streamline
clinical workflows, lessen the burden on medical professionals and administrators, and improve the patient
experiencebyswiftlyprovidingclearerandmoreaccuratemedicalinformation.
6. Acknowledgements
The authors would like to thank the SIIM community, most notably Teri M. Sippel Schmidt, Alex Barrington,
TomO’Sullivan,MohannadHussain,andthosewhotookthetimetoprovidefeedback,forsupportingourwork.
117. References
[1] Pollock JR, Petty SA, Schmitz JJ, Varner J, Metcalfe AM, Tan N. Patient access of their radiology reports
before and after implementationof21stCenturycuresactinformation-blockingprovisionsatalargemulticampus
healthsystem.AmJRoentgenol.2024;222(6).doi:10.2214/ajr.23.30343
[2] Gerber DE. 21st Century cures act: Implementation without understanding implication? JCO Oncol Pract.
2022;18(2):85-87.doi:10.1200/OP.21.00436
[3] Winget M, Haji-Sheikhi F, Brown-Johnson C, et al. Electronic release of pathology and radiology results to
patients:Opinionsandexperiencesofoncologists.JOncolPract.2016;12(8).doi:10.1200/JOP.2016.011098
[4] Smolle C, Schwarz CM, Hoffmann M, et al. Design and preliminary evaluation of a newly designed
patient-friendly discharge letter: A randomized, controlled participant-blind trial. BMC Health Serv Res.
2021;21:450.doi:10.1186/s12913-021-06468-3
[5] Zaretsky J, et al. Generative artificial intelligence to transform inpatient discharge summaries to
patient-friendlylanguageandformat.JAMANetwOpen.2024;7(3).doi:10.1001/jamanetworkopen.2024.0357
[6]LiuJ,WangC,LiuS.UtilityofChatGPTinclinicalpractice.JMedInternetRes.2023;25.doi:10.2196/48568
[7] Doo FX, Cook TS, Siegel EL, et al. Exploring the clinical translation of generative models like ChatGPT:
Promise and pitfalls in radiology, from patients to population health. J Am Coll Radiol. 2023;20(9):877-885.
doi:10.1016/j.jacr.2023.07.007
[8] Park J, Oh K, Han K, et al. Patient-centered radiology reports with generative artificial intelligence: Adding
valuetoradiologyreporting.SciRep.2024;14:13218.doi:10.1038/s41598-024-63824-z
[9]CorkSC,HopcroftK.EvaluatingtheutilityofChatGPTtoconvertcliniclettersintopatient-friendlylanguage.
PublishedonlineJuly9,2024.doi:10.1101/2024.07.09.24310132
[10] Roberts RHR, Ali SR, Dobbs TD, Whitaker IS. Can large language modelsgenerateoutpatientclinicletters
at first consultation that incorporate complication profiles from UK and USA aesthetic plastic surgery
associations?AesthetSurgJOpenForum.2023;6.PublishedDecember6,2023.doi:10.1093/asjof/ojad109
[11] Berigan K, Short R, Reisman D, et al. The impact of large language model-generated radiology report
summaries on patient comprehension: A randomized controlled trial. J Am Coll Radiol. Published online July 1,
2024.doi:10.1016/j.jacr.2024.06.018
[12] Ng A. Issue 242. One agent for many worlds, cross-species cell embeddings, and more. April 2, 2024.
AccessedJuly22,2024.https://www.deeplearning.ai/the-batch/issue-242/
[13] Wu M, Yuan Y, Haffari G, Wang L. (Perhaps) beyond human translation: Harnessing multi-agent
collaboration for translating ultra-long literary texts. arXiv. Published online May 20, 2024. Accessed July 24,
2024.https://arxiv.org/abs/2405.11804
[14] Shinn N, Cassano F, Berman E, Gopinath A, NarasimhanK,YaoS.Reflexion:Languageagentswithverbal
reinforcementlearning.arXiv.Publishedonline2023.doi:10.48550/arXiv.2303.11366
[15]TravasciS.Simple-ICD-10.PyPI.AccessedJuly24,2024.https://pypi.org/project/simple-icd-10/
[16] Kincaid JP, Fishburne RP Jr, Rogers RL, Chissom BS. Derivation of new readability formulas (Automated
Readability Index, Fog Count and Flesch Reading Ease Formula) for Navy enlisted personnel. Institute for
SimulationandTraining;1975.ReportNo.56.
[17] Readability.PyPI.AccessedJuly30,2024.https://pypi.org/project/readability/
12[18] Amin K, Khosla P, Doshi R, Chheang S, Forman HP. Artificial Intelligence to Improve Patient
Understanding of Radiology Reports. Yale J Biol Med. 2023;96(3):407-417. Published 2023 Sep 29.
doi:10.59249/NKOY5498
[19] Martin-Carreras T, Cook TS, Kahn CE Jr. Readability ofradiologyreports:implicationsforpatient-centered
care.ClinImaging.2019;54:116-120.doi:10.1016/j.clinimag.2018.12.006
[20] Weiss BD. HealthLiteracy:AManualforClinicians.Chicago,IL:AmericanMedicalAssociation,American
MedicalFoundation;2003.
[21]BadarudeenS,SabharwalS.Assessingreadabilityofpatienteducationmaterials:Currentrolein
orthopaedics.ClinOrthopRelatRes.2010;468(10):2572-2580.doi:10.1007/s11999-010-1380-y
[22]Davis,T.C.,Crouch,M.A.,Wills,G.,Miller,S.,&Abdehou,D.M.(1990).Thegapbetweenpatient
readingcomprehensionandthereadabilityofpatienteducationmaterials.JfamPract,31(5),533-8.
[23]AliS,DobbsTD,HutchingsHA,WhitakerIS.UsingChatGPTtowritepatientclinicletters.ResearchGate.
Publishedonline2023.
https://www.researchgate.net/publication/369076647_Using_ChatGPT_to_write_patient_clinic_letters
[24]GuoR,FarnanG,McLaughlinN,DevereuxB.QUB-Cirdanat“Dischargeme!”:Zeroshotdischargeletter
generationbyopen-sourceLLM.arXiv.PublishedonlineJune27,2024.AccessedJuly26,2024.
https://arxiv.org/abs/2406.00041
[25]DoshiR,AminKS,KhoslaP,BajajS,ChheangS,FormanHP.Quantitativeevaluationoflargelanguage
modelstostreamlineradiologyreportimpressions:Amultimodalretrospectiveanalysis.Radiology.2024;310(3).
doi:10.1148/radiol.231593
[26]1.XuZ,JainS,KankanhalliM.Hallucinationisinevitable:Aninnatelimitationoflargelanguagemodels.
arXiv.org.January22,2024.AccessedJuly29,2024.https://arxiv.org/abs/2401.11817.
[27]LeeC,KimY,KimYS,JangJ.Automaticdiseaseannotationfromradiologyreportsusingartificial
intelligenceimplementedbyarecurrentneuralnetwork.AmJRoentgenol.2019;212(4):734-740.
doi:10.2214/AJR.18.19869
[28]1.LüschowA,WartenaC.Classifyingmedicalliteratureusingk-nearest-neighboursalgorithm.Classifying
MedicalLiteratureUsingk-Nearest-NeighboursAlgorithm.January1,1970.AccessedJuly29,2024.
https://serwiss.bib.hs-hannover.de/frontdoor/index/index/docId/1146.
[29]ButlerJ,KernML.ThePERMA-Profiler:Abriefmultidimensionalmeasureofflourishing.IntJWellbeing.
2016.https://www.internationaljournalofwellbeing.org/index.php/ijow/article/view/526
[30]NationalInstitutesofHealth.Commondataelements:Standardizingdatacollection.U.S.NationalLibraryof
Medicine.AccessedJuly24,2024.
https://www.nlm.nih.gov/oet/ed/cde/tutorial/03-100.html#:~:text=A%20common%20data%20element%20(CDE),
to%20ensure%20consistent%20data%20collection
8. Appendix
ThisappendixcontainsexamplesofLLMoutputsforMR,CT,andUltrasoundreports,providingstraightforward
13visualcomparisonsbetweenzero-shotandmulti-agentgeneratedpatient-friendlyreports.
Figure2:Patient-FriendlyLettersgeneratedfromaCTChestReport
14Figure1:Patient-FriendlyLettersgeneratedfromanMRHeadReport
15Figure3:Patient-FriendlyLettersgeneratedfromaUSThyroidReport
16