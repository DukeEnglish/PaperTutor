[
    {
        "title": "Mission Impossible: A Statistical Perspective on Jailbreaking LLMs",
        "authors": "Jingtong SuJulia KempeKaren Ullrich",
        "links": "http://arxiv.org/abs/2408.01420v1",
        "entry_id": "http://arxiv.org/abs/2408.01420v1",
        "pdf_url": "http://arxiv.org/pdf/2408.01420v1",
        "summary": "Large language models (LLMs) are trained on a deluge of text data with\nlimited quality control. As a result, LLMs can exhibit unintended or even\nharmful behaviours, such as leaking information, fake news or hate speech.\nCountermeasures, commonly referred to as preference alignment, include\nfine-tuning the pretrained LLMs with carefully crafted text examples of desired\nbehaviour. Even then, empirical evidence shows preference aligned LLMs can be\nenticed to harmful behaviour. This so called jailbreaking of LLMs is typically\nachieved by adversarially modifying the input prompt to the LLM. Our paper\nprovides theoretical insights into the phenomenon of preference alignment and\njailbreaking from a statistical perspective. Under our framework, we first show\nthat pretrained LLMs will mimic harmful behaviour if present in the training\ncorpus. Under that same framework, we then introduce a statistical notion of\nalignment, and lower-bound the jailbreaking probability, showing that it is\nunpreventable under reasonable assumptions. Based on our insights, we propose\nan alteration to the currently prevalent alignment strategy RLHF. Specifically,\nwe introduce a simple modification to the RLHF objective, we call E-RLHF, that\naims to increase the likelihood of safe responses. E-RLHF brings no additional\ntraining cost, and is compatible with other methods. Empirically, we\ndemonstrate that E-RLHF outperforms RLHF on all alignment problems put forward\nby the AdvBench and HarmBench project without sacrificing model performance as\nmeasured by the MT-Bench project.",
        "updated": "2024-08-02 17:55:50 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.01420v1"
    },
    {
        "title": "Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs",
        "authors": "Yilun HuaYoav Artzi",
        "links": "http://arxiv.org/abs/2408.01417v1",
        "entry_id": "http://arxiv.org/abs/2408.01417v1",
        "pdf_url": "http://arxiv.org/pdf/2408.01417v1",
        "summary": "Humans spontaneously use increasingly efficient language as interactions\nprogress, by adapting and forming ad-hoc conventions. This phenomenon has been\nstudied extensively using reference games, showing properties of human language\nthat go beyond relaying intents. It remains unexplored whether multimodal large\nlanguage models (MLLMs) similarly increase communication efficiency during\ninteractions, and what mechanisms they may adopt for this purpose. We introduce\nICCA, an automated framework to evaluate such conversational adaptation as an\nin-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and\nobserve that while they may understand the increasingly efficient language of\ntheir interlocutor, they do not spontaneously make their own language more\nefficient over time. This latter ability can only be elicited in some models\n(e.g., GPT-4) with heavy-handed prompting. This shows that this property of\nlinguistic interaction does not arise from current training regimes, even\nthough it is a common hallmark of human language. ICCA is available at\nhttps://github.com/lil-lab/ICCA.",
        "updated": "2024-08-02 17:51:57 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.01417v1"
    },
    {
        "title": "The Quest for the Right Mediator: A History, Survey, and Theoretical Grounding of Causal Interpretability",
        "authors": "Aaron MuellerJannik BrinkmannMillicent LiSamuel MarksKoyena PalNikhil PrakashCan RagerAruna SankaranarayananArnab Sen SharmaJiuding SunEric ToddDavid BauYonatan Belinkov",
        "links": "http://arxiv.org/abs/2408.01416v1",
        "entry_id": "http://arxiv.org/abs/2408.01416v1",
        "pdf_url": "http://arxiv.org/pdf/2408.01416v1",
        "summary": "Interpretability provides a toolset for understanding how and why neural\nnetworks behave in certain ways. However, there is little unity in the field:\nmost studies employ ad-hoc evaluations and do not share theoretical\nfoundations, making it difficult to measure progress and compare the pros and\ncons of different techniques. Furthermore, while mechanistic understanding is\nfrequently discussed, the basic causal units underlying these mechanisms are\noften not explicitly defined. In this paper, we propose a perspective on\ninterpretability research grounded in causal mediation analysis. Specifically,\nwe describe the history and current state of interpretability taxonomized\naccording to the types of causal units (mediators) employed, as well as methods\nused to search over mediators. We discuss the pros and cons of each mediator,\nproviding insights as to when particular kinds of mediators and search methods\nare most appropriate depending on the goals of a given study. We argue that\nthis framing yields a more cohesive narrative of the field, as well as\nactionable insights for future work. Specifically, we recommend a focus on\ndiscovering new mediators with better trade-offs between human-interpretability\nand compute-efficiency, and which can uncover more sophisticated abstractions\nfrom neural networks than the primarily linear mediators employed in current\nwork. We also argue for more standardized evaluations that enable principled\ncomparisons across mediator types, such that we can better understand when\nparticular causal units are better suited to particular use cases.",
        "updated": "2024-08-02 17:51:42 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.01416v1"
    },
    {
        "title": "Conditional LoRA Parameter Generation",
        "authors": "Xiaolong JinKai WangDongwen TangWangbo ZhaoYukun ZhouJunshu TangYang You",
        "links": "http://arxiv.org/abs/2408.01415v1",
        "entry_id": "http://arxiv.org/abs/2408.01415v1",
        "pdf_url": "http://arxiv.org/pdf/2408.01415v1",
        "summary": "Generative models have achieved remarkable success in image, video, and text\ndomains. Inspired by this, researchers have explored utilizing generative\nmodels to generate neural network parameters. However, these efforts have been\nlimited by the parameter size and the practicality of generating\nhigh-performance parameters. In this paper, we propose COND P-DIFF, a novel\napproach that demonstrates the feasibility of controllable high-performance\nparameter generation, particularly for LoRA (Low-Rank Adaptation) weights,\nduring the fine-tuning process. Specifically, we employ an autoencoder to\nextract efficient latent representations for parameters. We then train a\nconditional latent diffusion model to synthesize high-performing model\nparameters from random noise based on specific task conditions. Experimental\nresults in both computer vision and natural language processing domains\nconsistently demonstrate that COND P-DIFF can generate high-performance\nparameters conditioned on the given task. Moreover, we observe that the\nparameter distribution generated by COND P-DIFF exhibits differences compared\nto the distribution obtained through normal optimization methods, indicating a\ncertain level of generalization capability. Our work paves the way for further\nexploration of condition-driven parameter generation, offering a promising\ndirection for task-specific adaptation of neural networks.",
        "updated": "2024-08-02 17:43:34 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.01415v1"
    },
    {
        "title": "Derivation of Back-propagation for Graph Convolutional Networks using Matrix Calculus and its Application to Explainable Artificial Intelligence",
        "authors": "Yen-Che HsiaoRongting YueAbhishek Dutta",
        "links": "http://arxiv.org/abs/2408.01408v1",
        "entry_id": "http://arxiv.org/abs/2408.01408v1",
        "pdf_url": "http://arxiv.org/pdf/2408.01408v1",
        "summary": "This paper provides a comprehensive and detailed derivation of the\nbackpropagation algorithm for graph convolutional neural networks using matrix\ncalculus. The derivation is extended to include arbitrary element-wise\nactivation functions and an arbitrary number of layers. The study addresses two\nfundamental problems, namely node classification and link prediction. To\nvalidate our method, we compare it with reverse-mode automatic differentiation.\nThe experimental results demonstrate that the median sum of squared errors of\nthe updated weight matrices, when comparing our method to the approach using\nreverse-mode automatic differentiation, falls within the range of $10^{-18}$ to\n$10^{-14}$. These outcomes are obtained from conducting experiments on a\nfive-layer graph convolutional network, applied to a node classification\nproblem on Zachary's karate club social network and a link prediction problem\non a drug-drug interaction network. Finally, we show how the derived\nclosed-form solution can facilitate the development of explainable AI and\nsensitivity analysis.",
        "updated": "2024-08-02 17:33:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.01408v1"
    }
]