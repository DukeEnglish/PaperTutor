LLM Hallucination Reasoning with Zero-shot
Knowledge Test
SeongminLee12∗,HsiangHsu2,Chun-Fu(Richard)Chen2
1GeorgiaInstituteofTechnology,2JPMorganChaseGlobalTechnologyAppliedResearch
seongmin@gatech.edu,{hsiang.hsu, richard.cf.chen}@jpmchase.com
Abstract
LLM hallucination, where LLMs occasionally generate unfaithful text, poses
significant challenges for their practical applications. Most existing detection
methodsrelyonexternalknowledge,LLMfine-tuning,orhallucination-labeled
datasets, and they do not distinguish between different types of hallucinations,
whicharecrucialforimprovingdetectionperformance. Weintroduceanewtask,
HallucinationReasoning,whichclassifiesLLM-generatedtextintooneofthree
categories: aligned, misaligned, and fabricated. Our novel zero-shot method
assesses whether LLM has enough knowledge about a given prompt and text.
Ourexperimentsconductedonnewdatasetsdemonstratetheeffectivenessofour
methodinhallucinationreasoningandunderscoreitsimportanceforenhancing
detectionperformance.
1 Introduction
Largelanguagemodels(LLMs)haveshownremarkableabilityingeneratingtextonvarioustopics[35,
32]. However,theyoftenproducehallucinations—incorrectorunverifiablecontent—thatpose
significant risks to their practical applications [2]. Detecting these hallucinations is crucial for
ensuringreliability[12]yetchallengingduetotheplausibleappearanceofthehallucinatedtext[37].
ResearchondetectinghallucinationsinLLM-generatedtexthasexploredseveralapproaches,in-
cluding comparing the text with external knowledge [19, 25, 31], fine-tuning LLMs [40, 36, 18],
and training classifiers to identify hallucinations [1, 4, 30]. However, these methods require ex-
ternal knowledge, LLM fine-tuning, or supervised training with hallucination-labeled data. To
address these limitations, there has been growing interest in source-free, zero-shot methods that
analyze LLM outputs directly. These methods encompass consistency checks [22], uncertainty
estimation[42,5,16,3,38],andpromptingLLMstoassessthecorrectnessofthetext[6,43].
However, existing detection methods fail to distinguish between different types and causes of
hallucinations[44,10],whichiscrucialforaccuratelydetectingandresolvingthem. Tobespecific,
LLM-promptingmethodsmayrandomlyguessthecorrectnessoftextwhentheLLMlacksrelevant
knowledge, while most uncertainty-based methods cannot identify errors caused by the inherent
randomnessoftheLLM[29,7]. Differentiatingtheunderlyingcausesofhallucinationsenablesmore
accuratedetectionandcanevensuggestpotentialsolutions: iftheLLMlacksknowledge,external
knowledgecanbeprovided;otherwise,responsescansimplyberegenerated.
To fill this gap, we categorize LLM-generated text into three types: aligned, misaligned, and
fabricated(Table1). Misalignedtextarisesfromsamplingrandomnessordependenciesonprevious
tokens[29,7,41],whilefabricatedtextisgeneratedwhentheLLMlacksrelevantknowledge[10,44].
Basedonthiscategorization,weproposeanewtask,hallucinationreasoning,whichaimstoclassify
LLM-generatedtextintooneofthesethreetypes. Wecontribute:
∗WorkdoneduringinternshipatJPMorganChase.
NeurIPS2024SoLaR(SociallyResponsibleLanguageModellingResearch)workshop
4202
voN
41
]IA.sc[
1v98690.1142:viXraTable 1: Hallucination Reasoning categorizes LLM-generated text into aligned, misaligned, and
fabricatedbasedon(1)whethertheLLMhasenoughknowledgetoanswerthepromptand(2)whether
the text aligns with the LLM’s knowledge. While the Hallucination Score does not differentiate
betweenmisalignedandfabricatedtext,resultinginlimitedperformance(Table3),SemanticEntropy
andSelfCheckGPTprimarilyfocusoneithermisalignedorfabricatedhallucinations,butnotboth.
Aligned Misaligned Fabricated
LLMhasknowledgetoanswertheprompt ✓ ✓ ✗
TextalignswiththeLLM’sknowledge ✓ ✗ -
Scopesofhallucinationdefinedintheexistingmethods
HallucinationScore[42] Faithful Hallucinated
SemanticEntropy[5] Faithful Hallucinated
SelfCheckGPT[22] Faithful Hallucinated -
• Newhallucinationreasoningtaskforbetterunderstandinganddetectionofhallucinations
(Sec.3,Table1). Ourdatasetcreationprocesscanbeleveragedforfutureresearchinhallucina-
tionreasoning(Sec.4).
• MKT,anovelzero-shotmethodthatidentifieswhetheranLLMhasenoughknowledge
aboutapromptandtextwithoutanyrequirementsforexternalknowledge,labeleddatasets,
andLLMfine-tuning(Sec.3.1,Fig.1).
• ExperimentsthatdemonstratethesuperiorityofourapproachinbothQAandfree-formtext
generation. Incorporatingourmethodintoexistingdetectionalgorithmssignificantlyimproves
theirperformance,underscoringtheimportanceofhallucinationreasoning(Sec.4).
2 RelatedWork
Hallucination reasoning. Efforts have been made to investigate the causes of hallucinations by
inspectingdata,trainingalgorithms,andtheinferenceprocess(Sec3of[10]). Theprimaryissues
duringinferenceincludeLLM’sinsufficientknowledgeandoverconfidence,itstendencytoprioritize
userpreferencesoverfactualaccuracy,inherentrandomnessinthegenerationprocess,anddependency
on earlier tokens (Sec 4 of [44]). Based on the literature, we categorize hallucinations into two
key types: (1) fabrication, which encompasses lack of knowledge and overconfidence, and (2)
misalignment,attributabletorandomnessordependencyonearliertokens.
Hallucinationdetection. SomeapproacheshaveverifiedthefactualnessofLLM-generatedtextby
comparingittoexternalknowledge[19,25,31]. Forexample,FactScore[25]checksatomicfactsin
textagainstreliablesources. Toreducedependencyonexternalsources,researchershaveinspected
LLMinternalsandtrainedclassifierstodifferentiatefaithfulandhallucinatedtext[4,1,30],orfine-
tunedLLMstorespondwith“Idon’tknow”touncertainquestions[40,36,18]. However,sincethese
methodsrequirelargelabeleddatasets,othersassessedcorrectnessthroughprompting[6,17,43]
orbycheckinggenerationconsistency[22,38,39,3],butthesemayfailwhenLLMsfabricatewith
overconfidence [14]. Efforts to identify the prompts that would lead LLMs to hallucinate using
uncertainty[11,27,42,5,9]oftenoverlookhallucinationsfromrandomsampling[29,7,41]. We
proposeanewdirectiontoidentifyhallucinationsmoreaccuratelyandinsightfullybyunderstanding
theircauseswithoutanyexternalknowledge,modeltraining,orimpracticalassumptions.
3 HallucinationReasoning
Background. LLM’stextgenerationinvolvesiterativenext-tokenprediction. Foragivenprompt,
theLLMpredictsatokenlikelytofollowtheinputandappendsittotheend. Atokenizerwitha
tokenvocabularysetT splitstheinputpromptintoatokensequence[t ,...,t ],wheret ∈ T.
1 M i
Eachtokent isthenmappedtoanembeddingvectore bythetokenembeddingmap. TheLLMf
i i
takestheembeddingvectorsequencee = [e ,...,e ]asinputandcomputestheprobability
1:M 1 M
ofeachtokent ∈ T appearingaftereachtokenpositioni; i.e., f(e ) = P ∈ RM×|T|,where
1:M
P = [P ,...,P ],P ∈ R|T|. BasedonP ,atokenissampledfromT andaddedtotheend
1 M i M
oftheinputtokensequence, resultinginanewinput. Thisprocessisrepeateduntilapredefined
stoppingcriteriaismet,suchasanend-of-sequencetokenoraspecifiednumberoftokens.
2Model Knowledge Test (Sec 3.1): Does LLM have enough knowledge to generate the text? CDF of Score
Subject Identification Subject Perturbation Score Evaluation
Q A Q A: :: : P JW W oikh h naa a a t t hi si i s s Cf ot t rh h aue e bn dh h li va ainS eb b u si irb t to a aj ie c nt tc k o ot t y h𝑆 f f eaP J ori dek n ea a a e? s h p w C wit r ah a t b e… ? rs … E c dT om eo -n d mbk v iee me bdn r eetdi dz nti ee dn sxr ig i n ot a gm nin n saad t lop d Su Nbp j oe# r ico s to m e Ef pt 𝝐mo t k bae +enn dds d t iei nn x g t s 𝒆1𝑆,𝒆L 2𝑆LM# o O D𝐏 𝐏f ෡ 1 1t iro si𝐏 𝐏෡g tk 2 2rie in𝐏 𝐏b ෡n a3 3us l𝐏 𝐏෡t i4 4i on n… … t e 𝐏x # e tt o x K L Do kis e ef u i t vna ii l bn elsl bl g l rea g rc e k ( nK- cL e) pS osc P Jio t oiir ko ne an a h= s is C𝑖M f o rfe u ao n ba r d n n is o i o n …u f … nK s L , v 0 0𝐏 e ..𝑖 00r‖ b 75𝐏෡ s 54𝑖 , ea > >tt c 0 0. .. 00 22 ?? YYT K t EEeh o s SSr l tme os o nh g A D L o vol Lad r l oo il Mi eg𝜏 dv - a sf n ’Sr sto i mm o t m e knir e nxn s tno e o v t a wt lT li ege dns𝜏 g t= w e0 (. i ?S0 th2 e tc h 3 e. 2) Y NE OS A Ml ii sg an le igd ned
Q: What is the habitat of Snakadsau? Snakadsau can … 0.008 > 0.02? Fabricated
A: Snakadsau is found in East Asia … NO
𝒆1𝑆+𝝐1,𝒆2𝑆+𝝐2 P De isr tt ru ibrb ue tid
o n 𝐏෡
Figure1: GivenapairofpromptandLLM-generatedtext,weproposeatwo-stageworkflowfor
hallucinationreasoning,consistingoftheModelKnowledgeTest(MKT)(Sec.3.1)andtheAlignment
Test(Sec.3.2). TheMKTidentifieswhethertheLLMhassufficientknowledgetogeneratethetext
by perturbing the subject in the prompt and the text and evaluating the impact; fabricated text is
differentiatedatthisstage. ForpairswhereLLMhasenoughknowledge,weconducttheAlignment
TesttoexaminewhetherthetextisalignedwiththeLLM’sknowledge.
SincetextaboutwhichLLMlacksknowledgecannotbeexaminedbycheckingitsalignmentwith
theLLM’sknowledge,itshouldbedifferentiatedthroughseparatesteps. Therefore,wedevelopa
two-stageworkflowforhallucinationreasoning,consistingofModelKnowledgeTest(MKT)and
Alignment Test (Fig. 1). The MKT assesses whether the LLM has enough knowledge to answer
thepromptanddistinguishesfabricatedtextfromothertwotypes(Sec.3.1). TheAlignmentTest
examineshowthegeneratedtextalignswiththeLLM’sknowledge,classifyingitaseitheralignedor
misaligned(Sec.3.2).
3.1 ModelKnowledgeTest
Wedesignanovelzero-shotmethodbasedonrecentfindingsthatperturbingthetokenembeddingsof
thesubjectinastatementsignificantlyhindersanLLMfromretrievingrelevantknowledgeaboutthe
subject[24];Fig.1illustratestheoverallprocess. Forexample,iftheLLMhasenoughknowledge
abouttheanimalPika,perturbingthetokenembeddingsofthewordPikainthetext“Pikaisfound
in rocky areas...” would lead the LLM to perceive the perturbed text as referring to a different
animal,thuspreventingitfromassociatingrockyareaswiththesubject. However,fortextabout
Snakadsau,anon-existentfabricatedword,theLLMwouldnotexploitanyknowledgebutgenerate
randomplausibletext. Therefore,perturbingSnakadsauwouldhavelittleimpactontextgeneration.
TheMKTconsistsofthreesteps: (1)identifyingthekeysubject,(2)perturbingthesubjecttokens’
embeddings,and(3)measuringtheperturbation’simpactontextgeneration.
Step1. SubjectIdentification. Todeterminethesubjectinaprompt,weidentifythenounphrase
thatreceivesthemostattentionduringtextgeneration. Weinputthepromptandthegeneratedtext
intotheLLMandcomputetheattentionthateachtokeninthepromptreceives. Usingthenounchunk
extractionfunctionofSpaCy[8]library,weextractnounphrasesandevaluateeachphrase’sattention
bysummingtheattentionvaluesofitstokens. Thenounphrasewiththehighestattentionisselected
asthesubject[34].
Step 2. Subject Perturbation. After extracting the subject, we perturb it by adding Gaussian
noise to the embeddings of the subject tokens. Given a prompt P and generated text G with M
andN tokens,respectively,weconcatenatethemintoatokensequence(P,G) = [t ,...,t ],
1 M+N
which is converted into d-dimensional embedding vectors e = [e ,...,e ]. For the
1:M+N 1 M+N
extractedsubjectS = [tS,...,tS],letI bethesetoftokenpositionswhereS occursin(P,G):
1 K S
I ={i|[t ,...,t ]=S}.
S i i+K−1
We perturb the subject’s embeddings by adding Gaussian noise ϵ with zero mean and standard
deviation σ (i.e., ϵ ∼ N(0,σ2) ∈ RK×d) to all occurrences of the subject in I , i.e., eˆ
S i:i+K−1
=e +ϵ,whileleavingothertokensunchanged. Then,weinputtheperturbedembedding
i:i+K−1
vectorseˆ totheLLMf tocomputetheperturbedprobabilitydistributionPˆ =f(eˆ )∈
1:M+N 1:M+N
R(M+N)×|T|. TheunperturbedprobabilitydistributionisobtainedbyP=f(e ).
1:M+N
Astheperturbationstrengthcanbedirectlycontrolledbyσ,wefurtheradjustthestrengthbasedon
theLLM’sfamiliarywiththesubjectS.SinceLLMstendtofabricateforunfamiliarsubjects[21,15,
25,13],weaimtoyieldasmallperturbationeffectforsuchsubjects. Familiarityisderivedusingthe
3negativelog-likelihoodscaledbytokenpositiontoconsidertheimportanceoflatertokens. Givena
subjectS,tokenizedas[tS,··· ,tS],thefamiliarityfam(S;f)∈R+withrespecttoanLLMf is
1 K
definedas
1 (cid:88)K √
fam(S;f)≜− i−1logPr(tS|tS,...,tS ;f)+1. (1)
K i 1 i−1
i=1
TheσoftheGaussiannoiseisfurtherscaledbythefamiliarity,i.e.,σ =σ′×fam(S;f),wherewe
useσ′ =0.1inourexperiments.
Step 3. Model Knowledge Score Evaluation. To evaluate the impact of the perturbation, we
compute the Kullback-Leibler (KL) divergence between P and Pˆ at each token position in the
generatedtext. Wefocusonsemanticallymeaningfultokens—nouns,propernouns,numbers,verbs,
andadjectives—identifiedbytheSpaCyPOSTagger[8]. ThemeanKLdivergenceforthesetokens
definestheModelKnowledgeScoreas
(cid:80)M+N KL(P ∥Pˆ )·1[t ∈POS]
MKS(P,G,S;f)= i=M+1 i i i , (2)
(cid:80)M+N 1[t ∈POS]
i=M+1 i
where1[·]isanindicatorvectorandPOS={noun,propernoun,number,verb,adjective}.
We repeat this process 10 times with different random seeds to mitigate the impact of random
Gaussiannoise. IftheModelKnowledgeScoreislowerthanathreshold, weclassifythetextas
fabricated;otherwise,weproceedtotheAlignmentTest(Fig.1). Wedeterminethethresholdτ using
theKolmogorov-Smirnov(KS)test[23]onthevalidationset: τ =argmax (F(x)−G(x)),where
x
Fisthecumulativeprobabilityoffabricateddata’sModelKnowledgeScoreandGisthatofaligned
ormisaligneddata.
3.2 AlignmentTest
AfterensuringtheLLMhasenoughknowledgeabout(P,G)throughMKT,wecheckiftextGaligns
withtheLLM’sknowledge. FortheAlignmentTest, wedirectlyuseSelfCheckGPT[22], which
verifiesalignmentbetweentextandLLMknowledgemoreeffectivelycomparedtootherzero-shot
methods;SemanticEntropy[16]evaluatestheuncertaintyofthepromptwithoutconsideringthetext,
whileHallucinationScore[42]showslimitedperformance(Table3).
4 Experiments
We require datasets of prompts, LLM-generated responses, and labels, where the label is one of
aligned,misalignedorfabricated(cf.Table1). Sinceexistingdatasetsonlyprovidebinarylabels
indicatingwhetheraresponseishallucinatedornot,weutilizeexistingdatasetsfrom[20,25]and
create two new datasets, the NEC and Biography datasets, which have trinary labels. The NEC
dataset contains questions across various topics (e.g., sports, animals), with 359 responses each
forthealigned,misalignedandfabricatedcategories,splitintovalidation(70)andtest(289)sets.
TheBiographydatasetcontains67biographiesinthevalidationset(21aligned,21misaligned,25
fabricated),and280inthetestset(88,88,104foreachlabel). Throughouttheexperiments,weadopt
theLLMmodelwithLLaMA2-Chat-GPTQ13B[33]. Fordetailedinformationonthedatasets,see
AppendixB.
EffectivenessofMKT.WeevaluateMKTbyvisu-
NEC Biography
alizingthecumulativedistributionfunction(CDF) 𝜏=0.023 𝜏=0.198
ofModelKnowledgeScoreonthevalidationsets 83.33%
oftheNECandBiographydatasets(Fig.2). Both
aligned/misaligned
datasetsshowsubstantiallydistinctscoredistribu- 75.00% fabricated
tionsfornon-fabricated(alignedandmisaligned)
Figure 2: CDF on the NEC and Biography
and fabricated text, indicating the score’s effec-
datasetsshowthatModelKnowledgeScoredis-
tivenessindetectingfabrication. Specifically,the
tributionsoffabricatedtextaresignificantlydis-
KSstatistic(max F(x)−G(x))is75.00%atτ
x
tinctfromnon-fabricatedones.
of0.023(p-value2.01e-26)ontheNECdataset
and83.33%atτ of0.198(p-value5.81e-12)ontheBiographydataset. Thesethresholdsareusedin
thesubsequentevaluations.
4Weevaluateourapproach,whichrunsMKTand Table2: Hallucinationreasoningperformance(%)
SelfCheckGPT,forclassifyingLLM-generated ofourmethodontheNEC(A)andBiography(B)
text into aligned, misaligned, and fabricated dataset,displayedasA/B.
(defined in Table 1). Since no existing meth-
Actual
odsdifferentiatebetweenmisalignedandfabri-
Aligned Misaligned Fabricated
cated text, we could not directly compare our
approachwithanyofthem. Table2showsthe Aligned 92.39/85.23 16.96/1.14 22.15/0.96
Misaligned 0.69/0.00 74.74/80.68 1.04/0.00
confusionmatrixofourmethodontheNECand
Fabricated 6.92/14.77 8.30/18.18 76.82/99.04
Biographydatasets. Overall,ourmethodeffec-
tivelydifferentiatesallthreetypesonbothdatasets. FortheNECdataset,MKTcorrectlydetects
76.82%offabricatedand92.39%ofnon-fabricateddatapoints. Asmostdatapointsthatpassthe
MKTareknownbytheLLM,SelfCheckGPTfurtherclassifiesalignedandmisalignedtexteffectively.
Similarly,fortheBiographydataset,theMKTcorrectlyidentifies99.04%offabricatedand83.52%
ofnon-fabricateddatapoints,withSelfCheckGPTalmostperfectlypredictingthealignmentofdata
pointsthatpassMKT.
MKT improves hallucination detection. We compare our approach with the existing source-
freezero-shothallucinationdetectionmethods,SelfCheckGPT[22],HallucinationScore[42],and
SemanticEntropy[5],whichfocusonbinaryclassificationtodeterminewhethertextishallucinated.
Forafaircomparison,weadaptourresultstobinarybygroupingmisalignedandfabricateddata
ashallucinated andaligned dataasfaithful; misaligneddatamisclassifiedasfabricatedandvice
versaareregardedascorrectlyclassified. Wedonotexperimentwithmethodsthatrequireexternal
knowledge[19,25,31],LLMfine-tuning[40,36,18],orhallucination-labeleddata[4,1,30].
Table3showsclass-wiseaccuracy,i.e.,theratioofalignedtextpredictedasfaithful,misalignedtext
predictedashallucinated,andfabricatedtextpredictedashallucinated;weprovidefullconfusion
matricesinAppendixC. OurMKT+SelfCheckGPTapproachoutperformstheothers,achieving
overallaccuraciesof84.43%ontheNECdatasetand94.64%ontheBiographydataset.
ComparingMKT+SelfCheckGPTtoSelfCheckGPTaloneshowsthatMKTsignificantlyenhances
hallucinationdetection. SelfCheckGPTcorrectlydetectsonly6.23%offabricatedtext,whileMKT
significantly raises this to 77.85%.2 This aligns with recent findings that LLMs are often overly
confident about fabricated content [28]. Similarly, incorporating MKT into Hallucination Score
improvestheoverallaccuracyfrom55.25%to74.05%ontheNECandfrom53.93%to84.29%on
theBiographydataset,demonstratingthatexistingdetectionmethodscanoverlookfabrication.
Table3: Hallucinationdetectionperformance(%)ontheNEC(A)andBiography(B)dataset,displayedasA/B.
Thebestresultsareinbold.OurMKT+SelfCheckGPToutperformsothermethods,significantlyimproving
SelfCheckGPT’sperformanceonfabricatedtext.
Type Aligned Misaligned Fabricated
Overall
Predicted Faithful Hallucinated Hallucinated
MKT+SelfCheckGPT(Ours) 84.43/94.64 92.39/85.23 83.04/98.86 77.85/99.04
MKT+HallucinationScore(Ours) 74.05/84.29 84.43/59.09 51.21/92.05 86.51/99.04
SelfCheckGPT[22] 63.09/84.64 97.92/88.64 85.12/100.0 6.23/68.27
HallucinationScore[42] 55.25/53.93 90.31/68.18 47.40/90.91 28.03/10.58
SemanticEntropy[5] 37.95/46.79 76.47/37.50 21.45/65.91 15.92/38.46
5 Conclusion
WedevelopamethodtoclassifyLLM-generatedtextintoaligned,misaligned,andfabricated to
identifythecausesofhallucinationsandimproveexistingdetectionmethods. WhileMKTeffectively
detectsfabricatedtext,weuseSelfCheckGPTfortheAlignmentTest,whichrequiresmultipletext
generationsandcanbetime-consumingandcomputationallyexpensive. Weaimtodevelopamore
efficientandeffectivetechniquefortheAlignmentTestandtoevaluateourmethodonabroader
rangeofdatasets.
2WenotethatSelfCheckGPThashigheraccuracyonalignedandmisalignedtextduetodifferentthreshold
settings.WhenSelfCheckGPTisrunwithoutMKT,thethresholdissethigher,makingitmorelikelyforadata
pointtobepredictedasmisaligned.Moreover,theexclusionofdatapointsmisclassifiedasfabricatedbyMKT
affectstheaccuracyofthealignedtext.
5
detciderPDisclaimer. ThispaperwaspreparedforinformationalpurposesbytheGlobalTechnologyApplied
ResearchcenterofJPMorganChase&Co. ThispaperisnotaproductoftheResearchDepartment
ofJPMorganChase&Co. oritsaffiliates. NeitherJPMorganChase&Co. noranyofitsaffiliates
makesanyexplicitorimpliedrepresentationorwarrantyandnoneofthemacceptanyliabilityin
connectionwiththispaper,including,withoutlimitation,withrespecttothecompleteness,accuracy,
orreliabilityoftheinformationcontainedhereinandthepotentiallegal,compliance,tax,oraccounting
effectsthereof. Thisdocumentisnotintendedasinvestmentresearchorinvestmentadvice,orasa
recommendation,offer,orsolicitationforthepurchaseorsaleofanysecurity,financialinstrument,
financialproductorservice,ortobeusedinanywayforevaluatingthemeritsofparticipatinginany
transaction.
References
[1] Azaria,A.andMitchell,T.(2023). TheinternalstateofanLLMknowswhenit’slying. arXiv
preprintarXiv:2304.13734.
[2] Bohannon,M.(2023). LawyerUsedChatGPTInCourt—AndCitedFakeCases.AJudgeIs
ConsideringSanctions. Forbes.
[3] Chen,C.,Liu,K.,Chen,Z.,Gu,Y.,Wu,Y.,Tao,M.,Fu,Z.,andYe,J.(2024). INSIDE:LLMs’
InternalStatesRetainthePowerofHallucinationDetection. arXivpreprintarXiv:2402.03744.
[4] Chen,Y.,Fu,Q.,Yuan,Y.,Wen,Z.,Fan,G.,Liu,D.,Zhang,D.,Li,Z.,andXiao,Y.(2023).
Hallucinationdetection: Robustlydiscerningreliableanswersinlargelanguagemodels. InPro-
ceedingsofthe32ndACMInternationalConferenceonInformationandKnowledgeManagement,
pages245–255.
[5] Farquhar,S.,Kossen,J.,Kuhn,L.,andGal,Y.(2024). Detectinghallucinationsinlargelanguage
modelsusingsemanticentropy. Nature,630(8017):625–630.
[6] Friel,R.andSanyal,A.(2023).Chainpoll:Ahighefficacymethodforllmhallucinationdetection.
arXivpreprintarXiv:2310.18344.
[7] Holtzman,A.,Buys,J.,Du,L.,Forbes,M.,andChoi,Y.(2019). Thecuriouscaseofneuraltext
degeneration. arXivpreprintarXiv:1904.09751.
[8] Honnibal,M.andMontani,I.(2017). spaCy2: NaturallanguageunderstandingwithBloom
embeddings,convolutionalneuralnetworksandincrementalparsing.
[9] Hou, B., Zhang, Y., Andreas, J., and Chang, S. (2024). A probabilistic framework for llm
hallucinationdetectionviabelieftreepropagation. arXivpreprintarXiv:2406.06950.
[10] Huang,L.,Yu,W.,Ma,W.,Zhong,W.,Feng,Z.,Wang,H.,Chen,Q.,Peng,W.,Feng,X.,Qin,
B., etal.(2023a). Asurveyonhallucinationinlargelanguagemodels: Principles, taxonomy,
challenges,andopenquestions. arXivpreprintarXiv:2311.05232.
[11] Huang, Y., Song, J., Wang, Z., Chen, H., and Ma, L. (2023b). Look before you leap:
An exploratory study of uncertainty measurement for large language models. arXiv preprint
arXiv:2307.10236.
[12] Ji,Z.,Lee,N.,Frieske,R.,Yu,T.,Su,D.,Xu,Y.,Ishii,E.,Bang,Y.J.,Madotto,A.,andFung,
P.(2023a). Surveyofhallucinationinnaturallanguagegeneration. ACMComputingSurveys,
55(12):1–38.
[13] Ji,Z.,Yu,T.,Xu,Y.,Lee,N.,Ishii,E.,andFung,P.(2023b). Towardsmitigatinghallucination
inlargelanguagemodelsviaself-reflection. arXivpreprintarXiv:2310.06271.
[14] Kamath,U.,Keenan,K.,Somers,G.,andSorenson,S.(2024).LLMchallengesandsolutions.In
LargeLanguageModels: ADeepDive: BridgingTheoryandPractice,pages219–274.Springer.
[15] Kandpal,N.,Deng,H.,Roberts,A.,Wallace,E.,andRaffel,C.(2023). Largelanguagemodels
struggletolearnlong-tailknowledge. InInternationalConferenceonMachineLearning,pages
15696–15707.PMLR.
[16] Kossen,J.,Han,J.,Razzak,M.,Schut,L.,Malik,S.,andGal,Y.(2024). SemanticEntropy
Probes: RobustandCheapHallucinationDetectioninLLMs. arXivpreprintarXiv:2406.15927.
[17] Li, J., Cheng, X., Zhao, W. X., Nie, J.-Y., and Wen, J.-R. (2023). Halueval: A large-scale
hallucinationevaluationbenchmarkforlargelanguagemodels. arXivpreprintarXiv:2305.11747.
6[18] Li,J.,Tang,Y.,andYang,Y.(2024). Knowtheunknown: Anuncertainty-sensitivemethodfor
llminstructiontuning. arXivpreprintarXiv:2406.10099.
[19] Lin,S.,Hilton,J.,andEvans,O.(2021). Truthfulqa: Measuringhowmodelsmimichuman
falsehoods. arXivpreprintarXiv:2109.07958.
[20] Liu, G., Wang, X., Yuan, L., Chen, Y., and Peng, H. (2024). Examining llms’ uncertainty
expressiontowardsquestionsoutsideparametricknowledge.
[21] Mallen,A.,Asai,A.,Zhong,V.,Das,R.,Khashabi,D.,andHajishirzi,H.(2023). Whennotto
trustlanguagemodels: Investigatingeffectivenessofparametricandnon-parametricmemories. In
Rogers,A.,Boyd-Graber,J.,andOkazaki,N.,editors,Proceedingsofthe61stAnnualMeeting
oftheAssociationforComputationalLinguistics(Volume1: LongPapers),pages9802–9822,
Toronto,Canada.AssociationforComputationalLinguistics.
[22] Manakul, P., Liusie, A., and Gales, M. J. (2023). Selfcheckgpt: Zero-resource black-box
hallucinationdetectionforgenerativelargelanguagemodels. arXivpreprintarXiv:2303.08896.
[23] Massey Jr, F. J. (1951). The Kolmogorov-Smirnov test for goodness of fit. Journal of the
AmericanstatisticalAssociation,46(253):68–78.
[24] Meng, K., Bau, D., Andonian, A., and Belinkov, Y. (2022). Locating and editing factual
associationsingpt. AdvancesinNeuralInformationProcessingSystems,35:17359–17372.
[25] Min,S.,Krishna,K.,Lyu,X.,Lewis,M.,Yih,W.-t.,Koh,P.W.,Iyyer,M.,Zettlemoyer,L.,and
Hajishirzi,H.(2023). Factscore: Fine-grainedatomicevaluationoffactualprecisioninlongform
textgeneration. arXivpreprintarXiv:2305.14251.
[26] OpenAI(2024). Openaideveloperplatform. Accessed: 2024-09-14.
[27] Quevedo,E.,Yero,J.,Koerner,R.,Rivas,P.,andCerny,T.(2024). Detectinghallucinationsin
largelanguagemodelgeneration: Atokenprobabilityapproach. arXivpreprintarXiv:2405.19648.
[28] Slobodkin,A.,Goldman,O.,Caciularu,A.,Dagan,I.,andRavfogel,S.(2023). Thecurious
case of hallucinatory (un) answerability: Finding truths in the hidden states of over-confident
largelanguagemodels. InProceedingsofthe2023ConferenceonEmpiricalMethodsinNatural
LanguageProcessing,pages3607–3625.
[29] Stahlberg, F.andByrne, B.(2019). OnNMTsearcherrorsandmodelerrors: Catgotyour
tongue? InInui,K.,Jiang,J.,Ng,V.,andWan,X.,editors,Proceedingsofthe2019Conferenceon
EmpiricalMethodsinNaturalLanguageProcessingandthe9thInternationalJointConference
on Natural Language Processing (EMNLP-IJCNLP), pages 3356–3362, Hong Kong, China.
AssociationforComputationalLinguistics.
[30] Su,W.,Wang,C.,Ai,Q.,Hu,Y.,Wu,Z.,Zhou,Y.,andLiu,Y.(2024). Unsupervisedreal-time
hallucination detection based on the internal states of large language models. arXiv preprint
arXiv:2403.06448.
[31] Tang,L.,Laban,P.,andDurrett,G.(2024). MiniCheck: EfficientFact-CheckingofLLMson
GroundingDocuments. arXivpreprintarXiv:2404.10774.
[32] Thirunavukarasu,A.J.,Ting,D.S.J.,Elangovan,K.,Gutierrez,L.,Tan,T.F.,andTing,D.
S.W.(2023). Largelanguagemodelsinmedicine. Naturemedicine,29(8):1930–1940.
[33] Touvron,H.,Martin,L.,Stone,K.,Albert,P.,Almahairi,A.,Babaei,Y.,Bashlykov,N.,Batra,
S.,Bhargava,P.,Bhosale,S.,etal.(2023). Llama2: Openfoundationandfine-tunedchatmodels.
arXivpreprintarXiv:2307.09288.
[34] Tu,Y.,Xu,J.,andShen,H.-W.(2021). Keywordmap: Attention-basedvisualexplorationfor
keywordanalysis.In2021IEEE14thPacificVisualizationSymposium(PacificVis),pages206–215.
IEEE.
[35] Wu,S.,Irsoy,O.,Lu,S.,Dabravolski,V.,Dredze,M.,Gehrmann,S.,Kambadur,P.,Rosenberg,
D.,andMann,G.(2023). Bloomberggpt: Alargelanguagemodelforfinance. arXivpreprint
arXiv:2303.17564.
[36] Xu,H.,Zhu,Z.,Ma,D.,Zhang,S.,Fan,S.,Chen,L.,andYu,K.(2024a). Rejectionimproves
reliability: Trainingllmstorefuseunknownquestionsusingrlfromknowledgefeedback. arXiv
preprintarXiv:2403.18349.
[37] Xu,Z.,Jain,S.,andKankanhalli,M.(2024b). Hallucinationisinevitable: Aninnatelimitation
oflargelanguagemodels. arXivpreprintarXiv:2401.11817.
7[38] Yadkori,Y.A.,Kuzborskij,I.,György,A.,andSzepesvári,C.(2024a). ToBelieveorNotto
BelieveYourLLM. arXivpreprintarXiv:2406.02543.
[39] Yadkori, Y.A., Kuzborskij, I., Stutz, D., György, A., Fisch, A., Doucet, A., Beloshapka, I.,
Weng, W.-H., Yang, Y.-Y., Szepesvári, C., et al. (2024b). Mitigating llm hallucinations via
conformalabstention. arXivpreprintarXiv:2405.01563.
[40] Zhang,H.,Diao,S.,Lin,Y.,Fung,Y.R.,Lian,Q.,Wang,X.,Chen,Y.,Ji,H.,andZhang,T.
(2023a). R-tuning: Teachinglargelanguagemodelstorefuseunknownquestions. arXivpreprint
arXiv:2311.09677.
[41] Zhang,S.,Yu,T.,andFeng,Y.(2024a). Truthx: Alleviatinghallucinationsbyeditinglarge
languagemodelsintruthfulspace. arXivpreprintarXiv:2402.17811.
[42] Zhang,T.,Qiu,L.,Guo,Q.,Deng,C.,Zhang,Y.,Zhang,Z.,Zhou,C.,Wang,X.,andFu,L.
(2023b). Enhancinguncertainty-basedhallucinationdetectionwithstrongerfocus. arXivpreprint
arXiv:2311.13230.
[43] Zhang, X., Peng, B., Tian, Y., Zhou, J., Jin, L., Song, L., Mi, H., and Meng, H. (2024b).
Self-alignmentforfactuality: Mitigatinghallucinationsinllmsviaself-evaluation. arXivpreprint
arXiv:2402.09267.
[44] Zhang,Y.,Li,Y.,Cui,L.,Cai,D.,Liu,L.,Fu,T.,Huang,X.,Zhao,E.,Zhang,Y.,Chen,Y.,
etal.(2023c). Siren’ssongintheaiocean: asurveyonhallucinationinlargelanguagemodels.
arXivpreprintarXiv:2309.01219.
8A SocialImpactsStatement
We expect our method to help end users assess whether to trust an LLM’s output by enhancing
hallucinationdetectionandprovidingmoredetailsaboutthecauses.Also,hallucinationreasoningcan
assistdevelopersinidentifyingandcorrectingerroneousgenerations. However,sinceourapproach
relies on the LLM’s internal knowledge rather than real-world facts, there’s a risk of amplifying
incorrectbeliefsembeddedintheLLM,whichrequirescarefulconsiderationfordeployment.
B Dataset
Inthissection,weelaborateonhowweconstructtheNECandBiographydatasets. Bothdatasets
consistoftuplesof(prompt,LLMresponse,type),wherethetypeisoneofaligned,misaligned,and
fabricated. WealsoprovideexampledatapointsinTable4andTable5.
B.1 NECdataset
NECdataset[20]consistsof2,073questionsaboutexistentand2,078questionsaboutnon-existent
concepts covering various topics (foods, sports, countries, animals, medicines, generic) curated
to examine LLMs’ behaviors asked about unknown questions. While we can ensure that LLM
responsesforthequestionsaboutnon-existentconceptsarefabricated,wecannotguaranteethatthe
LLMhasknowledgetoanswerallquestionsabouttheexistentconcepts. Toidentifythequestions
about which LLM has enough knowledge, we first leave only 1,369 questions about the existent
conceptsonWikipedia. Then,foreachquestion,wegenerate10responseswiththestudiedLLMf
(LLaMA2-Chat-GPTQ13B)andevaluatethecorrectnessofeachresponsebypromptingGPT-3.5
Turbo[26]withthequestion,LLMresponse,andWikipediaarticlerelatedtotheconcept3. Ifmore
than80%(8outof10)oftheLLMresponsesaresupportedbytheWikipediaarticle,weconsider
thequestiontobeknownandincludethequestioninourdataset. Then,foreachknownquestion,
wesampleoneofthesupportedresponsesandaddthetupleofthe(question,response,aligned)in
ourdataset. Togeneratethetupleswithmisalignedlabels,weprompttheLLMf toinducefactual
contradiction[17]. Asaresult,wecollect359datapointsforeachaligned,misalignedandfabricated
categories. Wesplitthesedataintovalidationandtestsetssothat20%ofthedatapointsareinthe
validationsetandtherestofthemareinthetestset,i.e.,70validationand289testdateforeachclass.
B.2 Biographydataset
Biographydataset[25]consistsofpeople’snamesonWikipediasothatwecanpromptLLMsto
tellabiographyofeachperson. AsanLLM’sknowledgeabouteachnamegreatlyvaries[25],we
identifythenamesthattheLLMknowswellbygeneratingabiography,maskingoutthenamefrom
thebiography,andaskingtheLLMtoguesswhatthemaskednameis;theLLMwouldbeableto
correctlyrecoverthenameonlywhentheLLM-generatedbiographycontainsalotofinformation
sothatitcanuniquelyindicatetheperson. However,thereisapossibilitythattheLLMcontainsa
littleinformationaboutthepeoplethatarelabeledasunknown. Tocreatefakepeopleaboutwhich
theLLMwouldcompletelyfabricate,weassignrandomjobswhichdonotmatchwiththeirtrue
jobs. Asaresult,wecollectLLM-unknownnamespairedwithawrongjob;wepairtheLLM-known
nameswiththeircorrectjobsforconsistency. Fromthecollectedname-jobpairs,wecreatequestions
of“Tellmeabiographyofthe[job][name].” andgenerateresponsesusingtheLLM.Whilewe
labelbiographyoffakepeoplearelabeledasfabricated,wetakeadditionalcaretogeneratealigned
biographiesoftheLLM-knownpeopleasbiographyiseasilyhallucinated[25];wecollectcorrect
factsthattheLLMknowsbygenerating10biographies,atomizingeachofthem,andverifyingthe
correctnessofeachfactatomusingGPT-3.5Turbo. Then,wegeneratecorrectbiographybasedon
thecorrectfacts. Togeneratemisalignedbiographies,wechange50%ofthefactstobecontradictory,
andconstructbiographiesbasedonthem. Wesplitthesedatapointsintovalidationandtestsetsso
that20%ofthedatapointsareinthevalidationsetandtherestofthemareinthetestset. Asaresult,
wehave67validationdatapoints(21correcttext,21mistake,25fabrication)and280testdatapoints
(88,88,104foreachlabel).
3WeuseWikipediaarticleforonlydatasetconstruction. Totestourmethods,wedonotuseanyexternal
knowledge.
9Table4: ExampledatapointsintheNECdataset
Question LLM-generatedtext Type
Pikaisfoundinrockyareaswithsparsevegetation,
WhatisthehabitatofPika? typicallyathighelevationsintheHimalayasand Aligned
othermountainranges.
Iceclimbingrequiresspecializedequipmentsuch
Whatequipmentand ascrampons,iceaxes,harnesses,andropes. The
playingenvironmentare playingenvironmentistypicallyoutdoorsincold Aligned
requiredforIceclimbing? weatherconditions,oniceformationssuchas
glaciers,frozenwaterfalls,orman-madeicewalls.
Pikaisfoundinopensteppelandwithabundant
WhatisthehabitatofPika? vegetation,typicallyatlowelevationsintheGreat Misaligned
Plainsandothergrasslandregions.
Iceclimbingrequiresspecializedequipmentsuch
Whatequipmentand
asiceskates,icehockeysticks,andhelmets. The
playingenvironmentare Misaligned
playingenvironmentistypicallyindoorsincold
requiredforIceclimbing?
weatherconditions,onicerinksorfrozenponds.
Whatisthehabitatof HornodaisfoundinthedesertsofNorthAfrica
Fabricated
Hornoda? andtheMiddleEast.
Cyclolingrequiresastationarybike,abalance
Whatequipmentand
board,andavirtualrealityheadset. Theplaying
playingenvironmentare Fabricated
environmentshouldbewell-ventilatedandhave
requiredforCycloling?
enoughspacefortheplayertomovearound.
Table5: ExampledatapointsintheBiographydataset
Question LLM-generatedtext Type
RamGopalVarmaanIndianfilmdirector,
screenwriter,andproducerwhohasbeenactivein
thefilmindustrysincethe1980s. Heisknownfor
hisuniquestyleoffilmmakingandhasdirected
Tellmeabioofthefilm
severalcriticallyacclaimedandcommercially
directorRamGopal Aligned
successfulfilms,including"Satya,""Rangeela,"and
Varma.
"Sarkar."Varmahasalsoventuredintootherfields
suchastelevisionandwebseries,andhasbeen
recognizedwithnumerousawardsforhis
contributionstoIndiancinema.
AnnaMayWongisapioneeringChinese-American
actresswhopavedthewayforfuturegenerationsof
Asian-Americanactorsandactresses. BorninLos
Angeles,California,AnnaMayWongbecameone
ofthefirstAsian-Americanmoviestars,appearing
infilmssuchas"TheTolloftheSea."Sheremained
Tellmeabiooftheactress
atrailblazerinthefilmindustry,breakingdown Aligned
AnnaMayWong.
barriersforotherAsian-Americanactorsand
actresses. Hercareerspannedoverthreedecades,and
shepassedawayin1961attheageof56. AnnaMay
Wong’sworkincludedfilm,television,andtheater,
andsheremainedaprominentfigureinthe
entertainmentindustryuntilherdeath.
10RamGopalVarmaisaFrenchfilmdirectorand
screenwriterknownforhisworkinTelugucinema.
Withover30filmsunderhisbelt,hehasdirected
criticallyacclaimedandcommerciallysuccessfulfilms
Tellmeabioofthefilm suchas"Satya"and"Rangeela."Hisfilmsoften
directorRamGopal explorethemesofviolence,crime,andtheunderworld Misaligned
Varma. withagritty,realisticstyle. Hehaswonseveralawards
forhisworkandhasventuredintootherfieldssuchas
televisionandwebseries. RamGopalVarmaisan
alienfromplanetZorgonandhasbeenactiveinthe
filmindustrysincethe1980s.
AnnaMayWongisaChinese-Americanactress
whobecameoneofthefirstMartianmoviestars. Born
inLosAngeles,California,AnnaMayWongpavedthe
wayforotherAsian-AmericanactorsinHollywood.
Sheremainedatrailblazerinthefilmindustry,
Tellmeabiooftheactress becomingthefirstAsian-Americanactresstotravel
Misaligned
AnnaMayWong. tothemoonandinventingatimemachinetotravelto
thefuture. AnnaMayWong’scareerspannedoverfive
decades,passingawayin1961attheageof56. Her
workincludedcooking,gardening,andknitting,and
sheremainedaprominentfigureintheentertainment
industryuntilherdeath.
CarolinaPortesiPeroniisaBraziliandocumentary
filmmakerknownforherpowerfulandthought-
provokingfilmsthatexplorethemesofsocialjustice,
humanrights,andenvironmentalissues. Shehas
directedseveralaward-winningdocumentaries,
including"TheLastForest"and"AmazonWomen,"
Tellmeabioofthe
whichhavebeenscreenedatfilmfestivalsaroundthe
documentaryfilmmaker Fabricated
world. Peroniisalsoapassionateadvocatefor
CarolinaPortesiPeroni.
indigenousrightsandhasworkedcloselywithlocal
communitiestoraiseawarenessabouttheimportance
ofpreservingtheirculturesandtraditions. Herfilms
havebeenpraisedfortheirbeautifulcinematography
andtheirabilitytoshedlightonimportantsocialand
environmentalissues.
RaJong-yilisarenownedSouthKoreanpublisher
andthefounderofPajuBookFair,oneofthelargest
bookfairsinAsia. Heisknownforhispassionfor
literatureandhiscommitmenttopromotingKorean
Tellmeabioofthe literatureglobally. Underhisleadership,thePajuBook
Fabricated
publisherRaJong-yil. Fairhasbecomeamajorculturalevent,attracting
thousandsofvisitorseachyear. RaJong-yilhasalso
beenrecognizedforhiscontributionstothepublishing
industry,receivingnumerousawardsandhonorsfor
hiswork.
C ConfusionmatricesofHallucinationDetectionMethods
WereporttheconfusionmatricesofallmethodscomparedinSec.4;MKT+HallucinationScore
(Table6),SelfCheckGPT(Table7),HallucinationScore(Table8),andSemanticEntropy(Table9).
WenotethattheconfusionmatrixofMKT+SelfCheckGPThasbeenalreadyprovidedinTable2.
11Table6: Confusionmatrixofthehallucinationdetectionperformance(%)ofMKT+Hallucination
ScoreontheNEC(A)andBiography(B)dataset,displayedasA/B.
Actual
Aligned Misaligned Fabricated
Aligned 84.43/59.09 48.79/7.95 13.49/1.14
Predicted Misaligned 8.65/26.13 42.91/73.86 9.69/0.00
Fabricated 6.92/14.77 8.30/18.18 76.82/99.04
Table7: Confusionmatrixofthehallucinationdetectionperformance(%)ofSelfCheckGPTonthe
NEC(A)andBiography(B)dataset,displayedasA/B.
Actual
Aligned Misaligned Fabricated
Faithful 97.92/88.64 14.88/0.00 93.77/32.04
Predicted
Hallucinated 2.08/11.36 85.12/100.00 6.23/80.68
Table8: Confusionmatrixofthehallucinationdetectionperformance(%)ofHallucinationScoreon
theNEC(A)andBiography(B)dataset,displayedasA/B.
Actual
Aligned Misaligned Fabricated
Faithful 90.31/68.18 52.60/9.09 71.97/89.42
Predicted
Hallucinated 9.69/31.82 47.40/90.91 28.03/10.58
Table9: Confusionmatrixofthehallucinationdetectionperformance(%)ofSemanticEntropyon
theNEC(A)andBiography(B)dataset,displayedasA/B.
Actual
Aligned Misaligned Fabricated
Faithful 76.47/37.50 78.55/34.09 84.08/65.91
Predicted
Hallucinated 23.53/62.50 21.45/38.46 15.92/61.54
12