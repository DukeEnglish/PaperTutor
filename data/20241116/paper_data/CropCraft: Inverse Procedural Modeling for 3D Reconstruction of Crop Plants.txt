CropCraft: Inverse Procedural Modeling for 3D Reconstruction of Crop Plants
AlbertJ.Zhai1 XinleiWang1 KaiyuanLi1 ZhaoJiang1 JunxiongZhou2
ShengWang1 ZhenongJin2 KaiyuGuan1 ShenlongWang1
1 UniversityofIllinoisUrbana-Champaign 2 UniversityofMinnesotaTwinCities
Abstract Camera Images 3D Mesh Model
The ability to automatically build 3D digital twins of Inverse
plants from images has countless applications in agri- Procedural
Modeling
culture, environmental science, robotics, and other fields.
However,current3Dreconstructionmethodsfailtorecover
completeshapesofplantsduetoheavyocclusionandcom- Biophysical Simulations
plexgeometries.Inthiswork,wepresentanovelmethodfor
3Dreconstructionofagriculturalcropsbasedonoptimizing
aparametricmodelofplantmorphologyviainverseproce-
duralmodeling. Ourmethodfirstestimatesdepthmapsby
fitting a neural radiance field and then employs Bayesian
optimization to estimate plant morphological parameters
Figure1. Inverseproceduralmodelingforagriculturalcrops.
that result in consistent depth renderings. The resulting
Weproposeanovelmethodfor3Dreconstructionofagricultural
3D model is complete and biologically plausible. We val-
crops based on inverse procedural modeling. Unlike standard
idateourmethodonadatasetofrealimagesofagricultural
multi-view reconstruction pipelines, our method outputs a com-
fields,anddemonstratethatthereconstructionscanbeused
plete,interpretable,andbiologicallyplausible3Dmeshmodelof
foravarietyofmonitoringandsimulationapplications.
the crop canopy, lending itself to simulations of important bio-
physicalprocessessuchasphotosynthesis.
1.Introduction
struction methods such as those based on neural render-
Plants are ubiquitous objects that appear all around the ing[24,29,46,49,54]ormulti-viewstereo[38,50,53,57]
world and serve as the foundation for agriculture, which do not reconstruct the invisible regions of the scene, lead-
underpinsourcivilization’sgrowthandsurvival. Theabil- ing to incomplete plant shapes and extraneous geometry.
ity to automatically build 3D digital twins of plants from Learning-based methods [15, 26] can overcome this issue
images has countless applications in agriculture, environ- butrequirelargeamountsofground-truth3Ddatafortrain-
mentalscience,robotics,andotherfields. Inparticular,the ing,whichisextremelydifficulttocollectfordensevegeta-
developmentofsuchreconstructionmethodsinthecontext tionduetothesameocclusionreasons.
ofagriculturewillenableautomatic,large-scalemonitoring Ontheotherhand,thereisalargebodyofworkthathas
of crops. The collected data can provide decision support found success in modeling 3D plant shapes via procedural
forfarmers,aidcarbonbudgetingfordecision-makers,sup- generation[23,27,33,34,42,43]. Theseproceduralmod-
port the development of new agricultural techniques, and els are grounded in scientific knowledge and are carefully
inform the design of new genotypes [10, 40, 59]. All of designedtoproducebiologicallyplausibleplantshapesthat
theseadvanceswillcontributetoincreasingcropproductiv- consistofanatomicallycompletearrangementsofplantor-
ity,alleviatingtherisingfoodcrisisoftoday’sworld[4,30]. ganswithrealisticshapes.However,thesemodelsgenerally
However, 3D reconstruction of plants remains to be a require human input to set their parameters, and the task
challenging vision problem. Many plants, including most ofautomaticallygeneratingplantsthataccuratelyrepresent
of those found in agriculture, are composed of complex plant instances observed in the real world (“inverse proce-
arrangements of thin leaves and branches that heavily oc- duralmodeling”)remainstobedifficult.
clude one another. These low visibility conditions cause In this work, we present a novel method for 3D recon-
existingreconstructionpipelinestofail. Multi-viewrecon- struction of agricultural crops based on optimizing the pa-
1
4202
voN
41
]VC.sc[
1v39690.1142:viXrarameters of a procedural plant morphology model. Our inputviews. Multi-viewstereo(MVS)methodsattemptto
methodcombinestheflexibilityofdata-drivenneuralrecon- match correspondences across images and then triangulate
struction methods with the robust foundational knowledge the 3D coordinates of the points [38, 50, 53, 57]. Another
in procedural models. To this end, we first use neural ra- approachfor3Dreconstructionisbasedonfittinganeural
diancefield(NeRF)techniques[29,46]toestimatethege- radiance field (NeRF) to the scene [24, 25, 29, 46, 49, 54,
ometryofthevisiblesurfacesinthescene. Wethenapply 55]. NeRF is a high-fidelity and compact 3D scene repre-
RANSAC [36] to estimate plant row locations and deter- sentation that consists of a color field and a density field,
mine a canonical camera pose from which to render depth bothparameterizedbyneuralnetworksandfittedtothein-
maps. Next,werenderdepthmapsfromboththeNeRFand put images via differentiable volume rendering [29]. Af-
avirtualscenegeneratedbyaproceduralgenerationmodel, tertraining,depthmapscanbeobtainedbyvolumerender-
anduseBayesianoptimizationtominimizealossfunction ingwiththedensityfield. NeRF-basedmethodscanmodel
withrespecttotheproceduralmodel’sparameters. view-dependent effects and tend to give better surface ge-
Thedesignofthelossfunctionandtheparameterization ometrythanMVS.Recently,analternativescenerepresen-
of the procedural model are crucial for obtaining a 3D re- tation based on 3D Gaussians has been proposed [13, 22],
construction that is useful for field-level analysis applica- achieving higher visual fidelity and more efficient render-
tions.Importantly,wenotethatthefine-grainedpositionsof ingthanNeRF,butwithlessaccurategeometry. Inourap-
eachindividualleafaremostlyirrelevant,aslongastheag- proach,weuseastandardoff-the-shelfNeRF[46]torecon-
gregateshapecharacteristicsofthecropcanopyarefaith- struct visible surfaces of plants, which has been explored
ful. Thus, wedefineourlossfunctiononhistogramstatis- before[2,16,35,41].However,duetotheinevitableocclu-
ticsofthedepthmapandoptimizeahighlycompactsetof sioninagriculturalscenes,thisisinadequateforfullcanopy
parameterstoensurethatthekeycanopycharacteristicsfor reconstruction. To solve this issue, we turn to procedural
determiningcropproductivityareaccuratelycapturedwith- generationmodels,whichincorporatescientificknowledge
outbeingdistractedbyfittingirrelevantdetails. Andthanks and define a space of complete plant shapes that we can
to the strong priors imposed by the procedural model, this constrainoursolutionto.
processjointlyoptimizesthecompleteplantshape,includ-
ingportionsnotvisibleintheinputimages.
Inverse Procedural Modeling. Inverse procedural mod-
Tovalidateourapproach,wecollectamulti-viewdataset
eling(IPM)referstotheproblemoffindingaprocedurefor
ofrealsoybeanandmaizefields, pairedwithmanualmea-
generating a 3D representation of a given object or scene.
surements of leaf area and leaf angle. We show that the
ThekeydesignchoicesforIPMpipelinesarethechoiceof
proposedmethodcansuccessfullyreconstructrealisticcrop
proceduralmodelandthemethodforoptimizingtheparam-
canopies across different growth stages and estimate key
eters of the model. Inverse procedural modeling has been
canopy structure variables more accurately than baselines.
applied for various input categories, with works focusing
Wealsoshowthatthereconstructed3Dcanopiescanbedi-
on building interiors [5, 11, 17, 18, 28], facades [8, 51],
rectly fed into radiative transfer modeling software to pro-
and driving scenes [7, 20]. The procedural models range
vide accurate predictions of photosynthesis rates. The re-
fromscenegrammars[12,18,20]toconstructivesolidge-
sultshighlightthepotentialformonitoringcropproductiv-
ometry trees [56] to L-systems [23, 27, 33, 43], which are
itydirectlyfromcameraimagesinsteadofcostlyfluxtower
especially popular for modeling botanical trees. To fit the
equipment. Ourcontributionsaretwofold:
model, a structural similarity measure is defined based on
• Wepresentanovelapproachforreconstructingcomplete
geometric and or semantic agreement. Depending on the
3Dmorphologicalmodelsoflarge-scalecropplantfields
type of model, which may require estimating procedural
fromacollectionofimages.
rules and or parameters [1], various search-based or dy-
• We introduce the first framework for image-based crop
namic programming-based optimization methods may be
productivity quantification, making scalable carbon ex-
usedtomaximizethesimilaritymeasure. Unlikethemulti-
changemonitoringapossibility.
viewreconstructionmethodsdescribedabove,inversepro-
ceduralmodelingmethodstendtofocuslessonphotomet-
2.RelatedWork
rically exact reconstructions, aiming to obtain structurally
3D Reconstruction. The task of reconstructing the 3D similarapproximationsusefulforsimulationapplications.
geometry of a scene given images is a longstanding prob- To the best of our knowledge, our work is the first to
lemincomputervision. Mostreconstructionpipelinesstart useinverseproceduralmodelingtoreconstructagricultural
from Structure-from-Motion (SfM), which infers camera cropsinthefield. Somepreviousworkshavetackledindi-
parametersfortheinputimagesthroughjointoptimization vidualplants[23,43,45],butmodelingdensecropcanopies
withdetectedkeypoints[37,47]. Afterwards,3Dgeometry posesanewsetofchallengesduetothehighlevelsofocclu-
can be estimated based on photometric consistency across sionandscaleofthedata.Weproposeanapproachcombin-
2Multi-view Images NeRF Reconstruction
Depth Map Depth Derivative Lateral Profile
Volume
Camera Poses
Rendering
Structure-from- L( , )
Row-Aligned NeRF-Rendered Stats Model-Rendered Stats
Motion RANSAC Row Fitting
Camera Pose
Morphological Parameters Procedurally Generated Mesh
Depth Map Depth Derivative Lateral Profile
Forward
Rendering
Bayesian Optimization
Figure2.Overviewofourmethod.Weaimtoestimatetheparametersforaproceduralgenerationmodeltogenerateashapethatmatches
theobservedimages. First,weusestandardstructure-from-motionandneuralradiancefield(NeRF)techniquestoreconstructthevisible
geometryofthescene. WethenapplyRANSACtoacquireacameraposealignedwiththeplantingrowsofthecrops. Thisposeisused
torenderdepthmapsfromboththeNeRFandtheproceduralmodel. Wedefinealossfunctionbasedonhistogramstatisticsofthedepth
mapsandminimizeitwithrespecttothemorphologicalparametersusingBayesianoptimization.
ingconventionalmulti-viewreconstructiontechniqueswith drastically across different species, these models should
procedural generation to estimate 3D meshes that can be be species-dependent. In this work, we focus on soybean
usedforplantphenotyping,visualization,andsimulationof (Glycine max) and maize (Zea mays), the two most-grown
biophysicalprocesses. cropsintheUnitedStates[48].
Our procedural generation models are heavily based on
3.InverseProceduralModelingforCrops existing work in the crop morphology literature. For soy-
bean,webuilduponthemCanopymodelbySongetal.[42],
Ourproposedmethodtakesasinputasetofimagesofafield andformaize, webuilduponthecoupledmaizemodelby
ofcrops,andoutputsasetofparametersthatcanbefedinto Qian et al. [34]. The mCanopy model consists of nodes
aproceduralgenerationmodeltoproducea3Dmeshofthe oftrifoliateleavesattachedviaapetioletoeitherthemain
crops in the images. An overview of our method is pro- plant stem or a branch stem. The maize model consists
vided in Fig. 2. By constraining the space of possible 3D of large curved leaves growing from a single main stem.
shapestotheoutputspaceoftheproceduralmodel,wecan Weintroduceourownparameterizationforeachmodel,as
ensure that the reconstructed plants are complete and have illustrated in Fig. 3. The parameterization is designed to
realistic leaf shapes and branch topology. Of course, we be flexible enough to capture the primary shape variations
alsoneedourreconstructiontomatchwhatwecanobserve across instances of each species while remaining as low-
in the input images. We achieve this by searching for pa- dimensional as possible (5 parameters for soybean, 4 for
rametersthatminimizealossfunctionbasedondepthmaps maize). Note that the procedural generation process is in
estimated from the input images and corresponding depth general stochastic; e.g. the model samples leaf angles ac-
mapsrenderedfromthereconstruction. cordingtoaprobabilitydistribution. Wereferreaderstothe
The layout for the rest of this section as follows. In supplementaryforadditionaldetailsabouteachmodel.
Sec.3.1,wedescribetheproceduralgenerationmodelswe
use for plant morphology. In Sec. 3.2, we describe how 3.2.DepthRendering
we use a neural radiance field (NeRF) [29] and geometric
The procedural generation model defines a space of 3D
heuristicstoobtainrow-aligneddepthmapsfromtheinput
shapes that can represent plants of various stages of ma-
images. In Sec. 3.3, we describe our loss function and in
turity,growingconditions,andcultivars. Inordertosearch
Sec.3.4,wedescribeouroptimizationalgorithm.
withinthisspacefortheshapethatbestmatchestheplants
in input observations, we define a loss function based on
3.1.ProceduralMorphologyModel
depth maps estimated from the input images and corre-
At the core of our method is a procedural morphology spondingdepthmapsrenderedusingtheproposedshape.
model that defines a primitive for the leaf shape and the Toestimatedepthmapsfromtheinputimages,weusean
possibletopologiesfortheplantstructure. Sincethisvaries off-the-shelfNeRF(Nerfacto[46])andrendertheexpected
3Soybean Plant Maize Plant canopy are accurate. With this in mind, we design a loss
function around histogram statistics of the rendered depth
Parameters Parameters
Leaf length •Leaf length •Leaf length maps,aimingtorecoverthekeyshapepropertiesnecessary
multiplier Leaf length multiplier
Petiole angle •P me uti lo til pe ll ie en rgth •L (de ea tf e o rmrd ie nr e ss hift forphotosynthesissimulationwhileavoidingoverfittingto
Petiole length
• •P m Ine u tt ei lo rti nl pe ol a dien erg ll ee
n gth
I len nte gr tn hode •b I mne utn e ld r tini pn o lg d
ie
ea
r
n leg nle g) th irrelevantaspectsofthescenegeometry.
multiplier •Number of
Internode length •Number of nodes
nodes Order 1 Order 2 Depth Profile Term. The first term of the loss function
Branch petiole angle istheL2distancebetweenhistogramsofforegrounddepth
valuesintheobservedandpredicteddepthmaps. Formally,
Figure3. Proceduralplantmorphologymodels. Weadoptpro-
ceduralgenerationmodelsfromexistingsoybeanmorphology[42] L =||h −h ||2, (1)
and maize morphology [34] models. This (stylized) illustration depth obs pred 2
showstheparametersthatweallowtobeoptimizedtomodelvari-
whereh andh arehistogramsoftheforegrounddepth
ationsacrossindividualinstancesofeachspecies. obs pred
valuesinI andI respectively. Unlikethedepthmaps
obs pred
themselves,thehistogramsareinvarianttotranslationalong
depth via volume rendering. In order to produce compa-
the ground plane, while still containing information about
rabledepthmapsfortheprocedurallygeneratedscene, we
thecropheight.
needtoknowwheretoplacetheplantsrelativetothecam-
era. Sinceitisextremelydifficulttodeterminetheprecise Lateral Profile Term. The lateral profile term L is
lateral
base position of every individual plant under heavy occlu- essentially the same as the depth profile term but for y-
sion, we assume that the plants are planted in rows with a coordinate absolute values instead of z-coordinates. This
known planting density and estimate the row locations us- term helps to constrain the extent to which the canopy
ing a heuristic approach that operates on a 3D point cloud spreadsoutontheground,whichthedepthprofileismostly
extractedfromtheNeRF. invariant to. We do not include another term for the x-
Specifically,werenderthedepthforeachinputviewand coordinate because the x-axis is aligned with the planting
unprojecteachpixeltoa3Dpoint.Then,werandomlysam- rows,makingthedistributionclosetouniform.
pleafixednumberofpointswithinaboundingboxforthe
sceneandperformvoxeldownsampling. Next,wesegment Depth Derivative Term. To capture more information
the points into ground and plant using a threshold on their about surface normals, we include a loss L sobel on (his-
colorinLABspace. Wefitaplanetothegroundpointsus- tograms of) magnitudes of Sobel derivatives of the depth
ingRANSAC[36]andtakeanuppersliceoftheplantpoints maps. We sum absolute values of the Sobel derivatives in
basedontheirdistancetothegroundplane. Finally,wefita bothdirectionswithakernelsizeof3.
linetoeachrowbysequentiallyrunningRANSACandre-
MaskAreaTerm. Thefinaltermisasquared-erroronthe
movingtheinliersforeachfittedline.Additionaldetailsfor
foregroundmaskarea:
therow-fittingprocedureareprovidedinthesupplementary.
Giventhegroundplaneandrows,wedefineastandard- L =(||M || −||M || )2. (2)
mask obs 1 pred 1
izedcameratorenderfromatapredeterminedheightabove
the center of the row with the most inliers, facing straight Ourfinallossisaweightedcombinationoftheaboveterms:
downwardswithitsx-axisalignedwiththerow. Thiscam-
era is used to render both the observation depth map I L=L +λ L +λ L +λ L . (3)
obs depth lateral lateral sobel sobel mask mask
fromtheNeRFandthedepthmapI inducedbythepro-
pred
cedurally generated scene. We also use a color threshold 3.4.BayesianOptimization
and a bounding box to acquire foreground (plant) masks
Since the procedural generation model directly adds new
M andM correspondingtoeachdepthmap.
obs pred mesh faces to create plants with different topology, the
transformation from parameters to generated shape is not
3.3.LossFunction
differentiable.Thus,itisdifficulttominimizethelossfunc-
Oneofthekeymotivationsforestimatingthe3Dstructure tion with respect to the parameters using gradient-based
ofagriculturalcropsistoenablephotosynthesissimulations optimization methods. Instead, we employ Bayesian op-
that provide accurate predictions of primary productivity timization, a black-box optimization method that is com-
andotherecologicalvariables. Ingeneral,weareinterested monly used for hyperparameter tuning [39]. Bayesian op-
in these variables at a large scale, at the level of patches timizationcreatesasurrogatefortheobjectivefunctionus-
or fields, not at the level of individual plants. Thus, the ingGaussianprocessregression,andthendecideswhereto
reconstructionofindividualleaflocationsmaynotbenec- samplenextbyoptimizinganacquisitionfunctionthatcom-
essary as long as certain statistics of the aggregated crop binesuncertaintyandtheexpectedobjectivevalue[9]. We
4Input ObservationDepth PredictedDepth 3DMesh
June16
June27
July05
July11
July20
August01
Figure4. Qualitativereconstructionresults(soybean). Wevalidatethereconstructionqualityfromourmethodonimagesfromreal
agricultural fields. From left to right: example images from the multi-view data, row-aligned NeRF-rendered depth, procedural model
depth,renderedvisualizationoftheproceduralmesh. Bymatchingstatisticsofthepredicteddepthwiththeobserveddepth,ourmethod
isabletoestimatethekeyshapeparametersneededtocharacterizethegrowthoftheplantsthroughoutthegrowingseason,consistently
producingrealisticreconstructions.
5Input ObservationDepth PredictedDepth 3DMesh
August16
August28
Sept14
Figure5.Qualitativereconstructionresults(maize).Weshowthatourmethodcanbeappliedtomodelmaizeaswellassoybean.From
lefttoright: exampleimagesfromthedrone-capturedmulti-viewdata,row-alignedNeRF-rendereddepth,proceduralmodeldepth,ren-
deredvisualizationoftheproceduralmesh.Theresultingreconstructionsarecompleteandanatomicallyrealisticdespiteheavyocclusion.
perform Bayesian optimization with a Matern kernel and leaf area was measured, not leaf angles. Both the soybean
the simple expected-improvement (EI) acquisition func- andmaizedatawillbemadepubliclyavailable.
tion [9] to estimate the procedural generation parameters
that minimize our loss function. We find that, in many
scenes, there may be multiple solutions with similar loss
Metrics. Ourevaluationmetrics(andfieldmeasurements)
values. Inordertomakeourmethodmorerobusttodiffer-
arecenteredaroundthecommonlyconsideredcanopystruc-
entrandominitializationseeds,weruntheoptimization10
turevariablesofleafareaindex(LAI)andtheleafangledis-
times(inparallel)andaveragethesolutions.
tribution.LAIisdefinedtobethetotalsurfaceareaofleaves
per unit of ground area and is widely used in productivity
4.Experiments
models,climatemodels,andmethodstoestimateotherveg-
Dataset. Tovalidateourapproach,wecollectedadataset etative surface properties [31]. Similarly, leaf angle is re-
of multi-view images in real crop fields in the U.S. Mid- gardedasakeycomponentofplantecologicalstrategywith
west,pairedwithmanualmeasurementsofkeymorpholog- significant impact on land surface properties such as car-
icalvariables. Forsoybean,wecollectedat3geographical bon flux, surface temperature and spectral signature [52].
locationsat6differenttimepointsthroughoutthegrowing Toassesshowaccuratelyourreconstructionscapturethese
season,foratotalof18scenes. Theimageswerecaptured key traits, we consider the following metrics: LAI Error
coveringa2m×2mareausingthePolycamapponaniPad (LAIE) is the root mean squared error (RMSE) between
Pro,around50perscene.Thepairedmanualmeasurements the predicted and ground-truth (manually measured) LAI.
consistofleafareasandleafangles(anglebetweensurface LAIPercentError(LAIPE)istheabsolutepercenterror
normalandzenithdirection).Leafareawasmeasuredusing betweenthepredictedandground-truthLAI.AngleMean
a LAI-2200 scanner, and leaf angle was measured using a Error (AME) is the RMSE between the mean of the pre-
protractor. For maize, we collected 5 different time points dicted leaf angles and the mean of the ground-truth leaf
inonelocation,witheachscenecontainingaround500im- angles. Angle Standard Deviation Error (ASDE) is the
agesfromaDJIMavicUAVflyingataheightof13m. The RMSEbetweenthestandarddeviationofthepredictedleaf
imageswerealignedusingAgisoftMetashape. Here, only anglesandthatoftheground-truthleafangles.
6NetPhotosynthesis EarlyMorning(6AM) Noon(12PM) LateAfternooon(4PM)
40 Predicted
Ground truth
30
20
10
0
6:00 10:00 14:00 18:00
40
30
20
10
0
6:00 10:00 14:00 18:00
40
30
20
10
0
6:00 10:00 14:00 18:00
40
30
20
10
0
6:00 10:00 14:00 18:00
40
30
20
10
0
6:00 10:00 14:00 18:00
Figure6.Photosynthesissimulationresults.WeperformsimulationsusingHelios[3]onsoybeancanopiesreconstructedbyourmethod.
Theleftcolumnshowsatimeseriesofthenetphotosynthesisrateforthecropcanopyoverthecourseofaday,inunitsofµmolCO /m2/s.
2
Theothercolumnsshowameshvisualizationwhereeachleaffaceiscoloredaccordingtotherateofphotosynthesisoverthatface(brighter
=higherrate).Theresultsdemonstratethepotentialofusingourreconstructionpipelineformonitoringcropproductivity.
7Table1.Canopyreconstructionresults.Bold:best,Blue:secondbest.
Soybean Maize
LAIE(↓) LAIPE(↓) AME(↓) ASDE(↓) LAIE(↓) LAIPE(↓)
Poisson 1.11 0.57 31.60 4.10 1.63 0.42
MLP 0.92 0.24 29.79 3.91 2.79 0.88
Trust-Region 1.37 0.28 10.34 7.10 1.71 0.53
Random 3.38 2.84 27.92 11.83 2.42 0.75
Ours 0.69 0.15 12.07 7.39 0.97 0.26
Baselines. We compare our reconstruction method with isalsoeasilydecomposable(atboththeplant-levelandpart-
the following baselines: Poisson refers to applying Pois- level)andisguaranteedtobebiologicallyreasonablethanks
sonsurfacereconstruction[21]onthepointcloudextracted totheconstraintsimposedbytheproceduralmodel.
from NeRF, and then thresholding in 3D to remove the WealsoshowexampleresultsformaizeinFig.5.Dueto
backgroundgeometry. Alloftheremainingmeshfacesare windyconditions,largerscenescale,andnoisycamerapose
thenconsideredasleaffaces.MLPreferstousingalearned estimation,thequalityoftheNeRFissignificantlylowerin
multilayerperceptron(MLP)topredictproceduralgenera- themaizedatacomparedtosoybean. However,ourmethod
tionparametersgiventhehistograms,maskarea,andview is still able to produce reasonable canopy reconstructions
height of the observation depth map. The MLP is trained usingthoseobservations.
on20Kpairsofhistogramstatisticsandmodelparameters,
synthesized by running the procedural generation model QuantitativeResults. Weprovidequantitativeresultsfor
and rendering depth maps. Trust-Region is the same as the canopy reconstruction in Tab. 1. In all metrics except
our proposed method but uses a (constrained) trust-region ASDE,wefindthatourproposedmethodachievesthehigh-
method [6] for optimization instead of Bayesian optimiza- est performance. The angle standard deviation may be es-
tion. This requires an estimate of the gradient of the loss timated less accurately than the other variables because it
function,whichisobtainedvia2-pointfinitedifferencees- doesnothaveasstrongofanimpactonthelossfunction.
timation[44]. Randomreferstouniformlyrandomlysam- The Poisson reconstruction fails because it completely
plingvaluesfortheproceduralgenerationparameters. ignoresoccludedregionsandalsofrequentlystitchesnearby
leavestogether, creatingextraneousfaces. TheMLPgives
Implementation Details. For soybean, we train Ner- reasonable predictions in terms of soybean leaf area, but
facto [46] with default parameters for 20K iterations. For tendstogivehighlyerroneousleafanglesasaresultofthe
maize, we set the near-plane and far-plane to 0.05 and 6.0 domaingapbetweenthesynthetichistogramsitwastrained
respectively, the MLP width to 128, and the orientation on and the actual histograms from the NeRF depth maps.
methodto“vertical”. WedeferdetailsabouttheRANSAC This is exacerbated with the maize data, where the NeRF
row-fitting and depth rendering to the supplementary. For renderings are blurrier. The trust-region optimization pro-
ourlossfunction,weuseλ lateral = 2,λ sobel = 4,λ mask = 1 ducesleafanglescomparablewithourmethod,butdoesnot
forsoybeanandλ lateral =1,λ sobel =0,λ mask =1formaize. performaswellforleafarea,mostlikelyduetofallinginto
This is because the low NeRF quality in the maize scenes localminimaormakingerroneousstepsduetothestochas-
makesthedepthderivativesunreliable. ForBayesianopti- ticityoftheproceduralgenerationmodel.
mization,weusescikit-optimize[14]andrunfor500itera-
4.2.AblationStudies
tions,with200iterationsforrandominitialization. Details
abouthistogrambinsandbaselineimplementationscanbe Weconductanablationstudyonthecomponentsofourloss
foundinthesupplementary. function in Tab. 2. We observe that each of the compo-
nents contribute to producing a more accurate reconstruc-
4.1.CanopyReconstruction
tion,somesignificantlymorethanothers.Thedepthderiva-
Qualitative Results. We show example results at differ- tivelosshasapronouncedbeneficialeffectontheleafarea
ent stages of soybean growth for the same geographic lo- metrics. Thisisbecausetheotherstatisticsmayhavetrou-
cation in Fig. 4. We observe that our method produces bleconstrainingtheleafsizewhenthecanopyhascovered
completereconstructionsthatcapturehowtheshapeofthe most of the ground, while the depth derivative distribution
canopy evolves over time, from small seedlings to large will be strongly shifted upwards with smaller leaves com-
bushes. Unlike most existing reconstruction methods, our pared to larger ones. Interestingly, removing most of the
methodisabletoestimatetheinvisible(occluded)portions other terms one at a time does not actually significantly
oftheplantsaswellasthevisibleportions. Thefinalmesh harm the final performance. The hard constraints imposed
8Table2.Lossfunctionablations.Bold:best,Blue:secondbest.
LossComponents Soybean
L L L L LAIE(↓) LAIPE(↓) AME(↓) ASDE(↓)
depth lateral sobel mask
✓ 1.62 0.52 17.00 9.26
✓ ✓ ✓ 0.67 0.19 12.08 6.81
✓ ✓ ✓ 0.71 0.16 10.37 7.69
✓ ✓ ✓ 1.94 0.49 9.73 8.15
✓ ✓ ✓ 0.78 0.19 12.30 8.03
✓ ✓ ✓ ✓ 0.69 0.15 12.07 7.39
bytheproceduralmodelandthesoftconstraintsimposedby tohyperparameterssuchastheinlierthresholdandsegmen-
theremainingtermsareabletoforceasimilarsolution. We tationthreshold,whichmayneedtobetunedperdataset.
stilldecidetoincludeallthetermsinourfinalmethoddue
totheimprovedLAIPE,whichwepreferoverLAIEasitis 5.Conclusion
notbiasedtowardsthelatertimepointswithlargerplants.
Wepresentedanovelmethodfor3Dreconstructionofagri-
4.3.PhotosynthesisSimulation cultural crops that combines conventional multi-view re-
construction with inverse procedural modeling to produce
Theoutputsofourmethodcanbedirectlyusedwithradia-
completeplantshapesdespiteheavyocclusion.Ourmethod
tive transfer models to predict photosynthesis rates, which
firstconstructsaneuralradiancefield(NeRF)andthenopti-
directlyimpactscropproductivity.UsingHelios[3],astate-
mizesaprocedurallygeneratedmodeltobeconsistentwith
of-the-artbiophysicalmodelingframework,weperformra-
the NeRF in a visibility-aware manner. We validate our
diativetransfersimulationsonthesoybeancanopiesrecon-
method on data collected in real-world agricultural fields
structed by our method. Helios can predict the net photo-
and show that it can reconstruct realistic crop canopies
synthesisrateforeveryleafmeshfaceatanypointintime
across a variety of plant growth stages. We also show
given a set of environmental variables measured by a flux
that the reconstructions can enable realistic simulations of
towerwithsensorsfortemperature,humidity,radiation,etc.
crop photosynthesis using a radiative transfer model. The
Weshowvisualizationsoftheper-facephotosynthesisrate
method could potentially be improved in the future by in-
as well as timeseries of the aggregate rate across the en-
corporatingplantgrowthpriorsfortemporalconsistency,or
tire canopy in Fig. 6. Ground-truth values for the photo-
optimizing the model in a coarse-to-fine manner to enable
synthesisrateareusuallycalculatedatalandscape-levelus-
reconstructingmoreshapedetails.
ingeddycovariancedatafromafluxtower[32]. Sincewe
donothavepairedfluxtowermeasurementsforourdataset
(collectedin2023),weusefluxtowermeasurementsfroma
Acknowledgments. This work is supported by NSF
soybeanfieldinthepreviousyear(2022).Becausethemea-
Awards #2331878, #2340254, #2312102, #2414227, and
surements were collected in a similar location and climate
#2404385,aswellasanIntelresearchgift,theNCSAFac-
as our data, we can reasonably expect that they reflect the
ultyFellowship,andtheAgroecosystemSustainabilityCen-
correspondingvariablesforthefieldinourdata.
teratUIUC.
The results suggest that the predictions made by the
modelcanaccuratelyrepresentthenetphotosynthesisover
References
timeaswellasitsspatialvariationsthroughoutthecanopy.
This validates the potential of our reconstruction pipeline [1] Daniel G Aliaga, ˙Ilke Demir, Bedrich Benes, and Michael
forfacilitatinglarge-scalemonitoringofcropproductivity. Wand. Inverseproceduralmodelingof3dmodelsforvirtual
worlds. In ACM SIGGRAPH 2016 Courses, pages 1–316.
4.4.Limitations 2016. 2
[2] Muhammad Arbab Arshad, Talukder Jubery, James Afful,
Onelimitationofourmethodisthattheinverseprocedural
AnushrutJignasu,AdityaBalu,BaskarGanapathysubrama-
modelingisdependentontheNeRFreconstructionperfor-
nian, SoumikSarkar, andAdarshKrishnamurthy. Evaluat-
mance, which may degrade due to wind-induced leaf mo- ingnerfsfor3dplantgeometryreconstructioninfieldcondi-
tion. Another limitation is that the procedural generation tions. arXivpreprintarXiv:2402.10344,2024. 2
models used cannot model certain details, e.g. damaged [3] Brian N Bailey. Helios: A scalable 3d plant and environ-
leavesandnon-leaforgansoftheplants. Afinallimitation mentalbiophysicalmodelingframework. FrontiersinPlant
is that our RANSAC-based row-fitting method is sensitive Science,10:1185,2019. 7,9
9[4] RameshChand. Theglobalfoodcrisis: causes,severityand [21] Michael Kazhdan, Matthew Bolitho, and Hugues Hoppe.
outlook. Economic and Political Weekly, pages 115–122, Poissonsurfacereconstruction. InProceedingsofthefourth
2008. 1 Eurographics symposium on Geometry processing, page 0,
[5] Jiacheng Chen, Chen Liu, Jiaye Wu, and Yasutaka Fu- 2006. 8
rukawa. Floor-sp: Inverse cad for floorplans by sequential [22] Bernhard Kerbl, Georgios Kopanas, Thomas Leimku¨hler,
room-wise shortest path. In Proceedings of the IEEE/CVF and George Drettakis. 3d gaussian splatting for real-time
InternationalConferenceonComputerVision,pages2661– radiancefieldrendering.ACMTransactionsonGraphics,42
2670,2019. 2 (4),2023. 2
[6] AndrewRConn,NicholasIMGould,andPhilippeLToint. [23] Bosheng Li, Jacek Kałuz˙ny, Jonathan Klein, Dominik L
Trustregionmethods. SIAM,2000. 8 Michels,WojtekPałubicki,BedrichBenes,andSo¨renPirk.
[7] Jeevan Devaranjan, Amlan Kar, and Sanja Fidler. Meta- Learningtoreconstructbotanicaltreesfromsingleimages.
sim2:Unsupervisedlearningofscenestructureforsynthetic ACM Transactions on Graphics (TOG), 40(6):1–15, 2021.
datageneration. InEuropeanConferenceonComputerVi- 1,2
sion,pages715–733,2020. 2 [24] Zhaoshuo Li, Thomas Mu¨ller, Alex Evans, Russell H Tay-
[8] Lubin Fan, Przemyslaw Musialski, Ligang Liu, and Peter lor, MathiasUnberath, Ming-YuLiu, andChen-HsuanLin.
Wonka. Structure completion for facade layouts. ACM Neuralangelo:High-fidelityneuralsurfacereconstruction.In
TransactionsonGraphics,33:1–11,2014. 2 CVPR,2023. 1,2
[9] PeterIFrazier. Atutorialonbayesianoptimization. arXiv [25] Chen-Hsuan Lin, Wei-Chiu Ma, Antonio Torralba, and Si-
preprintarXiv:1807.02811,2018. 4,6 monLucey. Barf: Bundle-adjustingneuralradiancefields.
[10] PierreFriedlingstein,MichaelO’sullivan,MatthewWJones, In Proceedings of the IEEE/CVF International Conference
Robbie M Andrew, Luke Gregor, Judith Hauck, Corinne onComputerVision,pages5741–5751,2021. 2
LeQue´re´,IngridTLuijkx,AreOlsen,GlenPPeters,etal. [26] Ruoshi Liu, Rundi Wu, Basile Van Hoorick, Pavel Tok-
Globalcarbonbudget2022. EarthSystemScienceData,14 makov, Sergey Zakharov, and Carl Vondrick. Zero-1-to-3:
(11):4811–4900,2022. 1 Zero-shotoneimageto3dobject. InCVPR,2023. 1
[11] Yasutaka Furukawa, Brian Curless, Steven M Seitz, and [27] StevenLongay,AdamRunions,Fre´de´ricBoudon,andPrze-
RichardSzeliski.Reconstructingbuildinginteriorsfromim- myslaw Prusinkiewicz. Treesketch: Interactive procedural
ages. In2009IEEE12thinternationalconferenceoncom- modelingoftreesonatablet. InSBIM@Expressive,pages
putervision,pages80–87.IEEE,2009. 2 107–120.Citeseer,2012. 1,2
[12] AdityaGaneshan,RKennyJones,andDanielRitchie. Im- [28] Kevis-KokitsiManinis,StefanPopov,MatthiasNießner,and
proving unsupervised visual program inference with code VittorioFerrari.Vid2cad:Cadmodelalignmentusingmulti-
rewritingfamilies. InICCV,pages15791–15801,2023. 2 viewconstraintsfromvideos. IEEETransactionsonPattern
[13] Antoine Gue´don and Vincent Lepetit. Sugar: Surface- AnalysisandMachineIntelligence,45(1):1320–1327,2023.
aligned gaussian splatting for efficient 3d mesh recon- 2
struction and high-quality mesh rendering. arXiv preprint [29] Ben Mildenhall, Pratul P Srinivasan, Matthew Tancik,
arXiv:2311.12775,2023. 2 JonathanTBarron,RaviRamamoorthi,andRenNg. Nerf:
[14] TimHead,ManojKumar,HolgerNahrstaedt,GillesLouppe, Representingscenesasneuralradiancefieldsforviewsyn-
and Iaroslav Shcherbatyi. scikit-optimize/scikit-optimize: thesis. InECCV,2020. 1,2,3
v0.8.1. Zenodo,2020. 8 [30] WorldHealthOrganizationetal. Thestateoffoodsecurity
[15] YicongHong,KaiZhang,JiuxiangGu,SaiBi,YangZhou, andnutritionintheworld2022:Repurposingfoodandagri-
DifanLiu,FengLiu,KalyanSunkavalli,TrungBui,andHao culturalpoliciestomakehealthydietsmoreaffordable.Food
Tan. Lrm: Largereconstructionmodelforsingleimageto &AgricultureOrg.,2022. 1
3d. arXivpreprintarXiv:2311.04400,2023. 1 [31] Geoffrey G Parker. Tamm review: Leaf area index (lai) is
[16] Kewei Hu, Ying Wei, Yaoqiang Pan, Hanwen Kang, and bothadeterminantandaconsequenceofimportantprocesses
Chao Chen. High-fidelity 3d reconstruction of plants us- in vegetation canopies. Forest Ecology and Management,
ingneuralradiancefield. arXivpreprintarXiv:2311.04154, 477:118496,2020. 6
2023. 2 [32] GilbertoPastorello,CarloTrotta,EleonoraCanfora,Housen
[17] SatoshiIkehata,HangYang,andYasutakaFurukawa. Struc- Chu, Danielle Christianson, You-Wei Cheah, Cristina
tured indoor modeling. In Proceedings of the IEEE inter- Poindexter, Jiquan Chen, Abdelrahman Elbashandy, Marty
nationalconferenceoncomputervision, pages1323–1331, Humphrey, et al. The fluxnet2015 dataset and the oneflux
2015. 2 processingpipelineforeddycovariancedata.Scientificdata,
[18] HamidIzadinia,QiShan,andStevenM.Seitz. Im2cad. In 7(1):225,2020. 9
CVPR,2017. 2 [33] PrzemyslawPrusinkiewicz,JimHanan,andRadom´ırMeˇch.
[19] Eric Jones, Travis Oliphant, Pearu Peterson, et al. SciPy: An l-system-based plant modeling language. In Interna-
OpensourcescientifictoolsforPython,2001–. 13 tional workshop on applications of graph transformations
[20] AmlanKar,AayushPrakash,Ming-YuLiu,EricCameracci, withindustrialrelevance,pages395–410.Springer,1999.1,
JustinYuan,MattRusiniak,DavidAcuna,AntonioTorralba, 2
andSanjaFidler. Meta-sim: Learningtogeneratesynthetic [34] BinxiangQian,WenjiangHuang,DonghuiXie,HuichunYe,
datasets. InICCV,pages4551–4560,2019. 2 AntingGuo,YuhaoPan,YinJin,QiaoyunXie,QuanjunJiao,
10Biyao Zhang, et al. Coupled maize model: A 4d maize [48] USDANationalAgriculturalStatisticsService.NASS-quick
growth model based on growing degree days. Computers stats. UNASService(Ed.),2021. 3
andElectronicsinAgriculture, 212:108124, 2023. 1, 3, 4, [49] PengWang,LingjieLiu,YuanLiu,ChristianTheobalt,Taku
12 Komura,andWenpingWang.Neus:Learningneuralimplicit
[35] Farah Saeed, Jin Sun, Peggy Ozias-Akins, Ye Juliet Chu, surfacesbyvolumerenderingformulti-viewreconstruction.
andChangyingCharlieLi. Peanutnerf:3dradiancefieldfor InNeurIPS,2021. 1,2
peanuts. InCVPRW,pages6253–6262,2023. 2 [50] ZizhuangWei,QingtianZhu,ChenMin,YisongChen,and
[36] Ruwen Schnabel, Roland Wahl, and Reinhard Klein. Ef- GuopingWang.Aa-rmvsnet:Adaptiveaggregationrecurrent
ficientransacforpoint-cloudshapedetection. InComputer multi-viewstereonetwork. InCVPR,2021. 1,2
graphicsforum,pages214–226.WileyOnlineLibrary,2007. [51] Fuzhang Wu, Dong Ming Yan, Weiming Dong, Xiaopeng
2,4 Zhang, and Peter Wonka. Inverse procedural modeling of
[37] JohannesLSchonbergerandJan-MichaelFrahm. Structure- facadelayouts. ACMTransactionsonGraphics,33(4):121,
from-motion revisited. In Proceedings of the IEEE con- 2014. 2
ference on computer vision and pattern recognition, pages [52] XiYang,RongLi,AndrewJablonski,AtticusStovall,Jong-
4104–4113,2016. 2 min Kim, Koong Yi, Yixin Ma, Daniel Beverly, Richard
[38] Steven M Seitz, Brian Curless, James Diebel, Daniel Phillips,KimNovick,etal. Leafangleasaleafandcanopy
Scharstein, and Richard Szeliski. A comparison and eval- trait: Rejuvenatingitsroleinecologywithnewtechnology.
uation of multi-view stereo reconstruction algorithms. In EcologyLetters,2023. 6
CVPR,2006. 1,2
[53] YaoYao,ZixinLuo,ShiweiLi,JingyangZhang,YufanRen,
[39] Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P
LeiZhou,TianFang,andLongQuan.Blendedmvs:Alarge-
Adams, and Nando De Freitas. Taking the human out of
scaledatasetforgeneralizedmulti-viewstereonetworks. In
theloop:Areviewofbayesianoptimization. Proceedingsof
CVPR,2020. 1,2
theIEEE,104(1):148–175,2015. 4
[54] LiorYariv,JiataoGu,YoniKasten,andYaronLipman. Vol-
[40] RebeccaASlatteryandDonaldROrt. Perspectivesonim-
umerenderingofneuralimplicitsurfaces.InNeurIPS,2021.
proving light distribution and light use efficiency in crop
1,2
canopies. PlantPhysiology,185(1):34–48,2021. 1
[55] Lior Yariv, Peter Hedman, Christian Reiser, Dor Verbin,
[41] Claus Smitt, Michael Halstead, Patrick Zimmer, Thomas
Pratul P Srinivasan, Richard Szeliski, Jonathan T Barron,
La¨be,EsraGuclu,CyrillStachniss,andChrisMcCool. Pag-
andBenMildenhall.Bakedsdf:Meshingneuralsdfsforreal-
nerf: Towardsfastandefficientend-to-endpanoptic3drep-
timeviewsynthesis.arXivpreprintarXiv:2302.14859,2023.
resentationsforagriculturalrobotics.IEEERoboticsandAu-
2
tomationLetters,9(1):907–914,2023. 2
[56] Fenggen Yu, Qimin Chen, Maham Tanveer, Ali Mah-
[42] Qingfeng Song, Venkatraman Srinivasan, Steve P Long,
daviAmiri,andHaoZhang.D2csg:Unsupervisedlearning
and Xin-Guang Zhu. Decomposition analysis on soybean
ofcompactcsgtreeswithdualcomplementsanddropouts.
productivity increase under elevated co2 using 3-d canopy
NeurIPS,36,2024. 2
modelrevealssynergesticeffectsofco2andlightinphoto-
[57] JingyangZhang,ShiweiLi,ZixinLuo,TianFang,andYao
synthesis. Annalsofbotany,126(4):601–614,2020. 1,3,4,
Yao. Vis-mvsnet: Visibility-aware multi-view stereo net-
12
work. International Journal of Computer Vision, 131(1):
[43] Ondrej Stava, So¨ren Pirk, Julian Kratt, Baoquan Chen,
199–214,2023. 1,2
Radom´ırMeˇch,OliverDeussen,andBedrichBenes.Inverse
[58] Qian-Yi Zhou, Jaesik Park, and Vladlen Koltun. Open3d:
proceduralmodellingoftrees.InComputerGraphicsForum,
A modern library for 3d data processing. arXiv preprint
pages118–131.WileyOnlineLibrary,2014. 1,2
arXiv:1801.09847,2018. 13
[44] John C Strikwerda. Finite difference schemes and partial
[59] RongshengZhu,KaiSun,ZhuangzhuangYan,XuehuiYan,
differentialequations. SIAM,2004. 8
Jianglin Yu, Jia Shi, Zhenbang Hu, Hongwei Jiang, Dawei
[45] PingTan,TianFang,JianxiongXiao,PengZhao,andLong
Xin,ZhanguoZhang,etal. Analysingthephenotypedevel-
Quan. Single image tree modeling. ACM Transactions on
opmentofsoybeanplantsusinglow-cost3dreconstruction.
Graphics(TOG),27(5):1–7,2008. 2
ScientificReports,10(1):7055,2020. 1
[46] Matthew Tancik, Ethan Weber, Evonne Ng, Ruilong Li,
Brent Yi, Terrance Wang, Alexander Kristoffersen, Jake
Austin, KamyarSalahi, AbhikAhuja, etal. Nerfstudio: A
modular framework for neural radiance field development.
InACMTransactionsonGraphics(SIGGRAPH),2023.1,2,
3,8,12,13
[47] Bill Triggs, Philip F McLauchlan, Richard I Hartley,
and Andrew W Fitzgibbon. Bundle adjustment—a mod-
ern synthesis. In Vision Algorithms: Theory and Prac-
tice: International Workshop on Vision Algorithms Corfu,
Greece, September 21–22, 1999 Proceedings, pages 298–
372.Springer,2000. 2
11CropCraft: Inverse Procedural Modeling for 3D Reconstruction of Crop Plants
Supplementary Material
Abstract Maize Model. Our procedural maize model is based no
thecoupledmaizemodelfromQianetal.[34]. Eachplant
In the following supplementary material, we provide addi- consists of a main stem with up to 18 nodes with one leaf
tional experimental details (Sec. A) and additional experi- each. Each leaf consists of 10 trapezoidal segments that
mentalresults(Sec.B).Weinvitereaderstowatchthesup- bend towards the ground following a polynomial function
plementaryvideo(supp.mp4)forfurthervisualization. that depends on the leaf order [34]. To allow for different
bending angles, we introduce a parameter that additively
shifts all of the leaf orders by the same amount. The leaf
A.AdditionalExperimentalDetails lengths,widths,andinternodelengthsfollowaprofilefrom
bottomtotopbasedonfielddatameasuredintheU.S.Mid-
A.1.AdditionalProceduralModelDetails west. Each node grows on alternating sides of their stem,
withadditionalazimuthalrotationfollowingaGaussiandis-
SoybeanModel. Ourproceduralsoybeanmodelisbased
tribution with mean 0 and standard deviation 60 degrees.
on the mCanopy model from Song et al. [42]. Each plant
Therangeofpossiblevaluesforeachmodelparameterare
consistsofamainstemwithupto14(trifoliate)nodes,and
providedinTab4.
up to 6 branch stems with up to 2 nodes each. Each node
consistsofthreecoplanarleaves,withthemiddleleafcon-
Parameter Range
nected by a small petiole, and is connected to its stem by
a larger petiole. The leaf length (and width), the petiole Leaflengthmultiplier 0.8-1.2
length, the angle with the stem, and the distance between Leafordershift -4.0-4.0
Internodelengthmultiplier 0.8-1.2
nodesarevariable,astheyareaffectedbythemultiplierpa-
Numberofnodes 1.0-18.0
rameters. Onthemainstem,whenallthemultipliersareset
to1,thevariablesfollowaprofilefromtoptobottombased
Table4.Maizemodelparameterranges.
on field data measured by Song et al. [42]. Branches start
growing with every new main stem node starting from the
8th, withonebranchpermainstemnodestartingfromthe A.2. Additional Row Fitting and Depth Rendering
bottomanduptothe6th. Thenumberofnodesperbranch Details
is selected randomly according to the distribution defined
Our row fitting procedure operates on a point cloud sam-
bySongetal.[42]. Thevariablesforthebranchnodesare
pledfromtheNeRF,usingthesamplingimplementationin
thesameacrossnodes(butareaffectedbythemultipliers).
Nerfstudio [46]. For the soybean data, we sample 100K
When the number of nodes is not an integer, it is rounded
pointsina2m×2m×3mboxcenteredat(0,0,−1.5)m.
upandthelastnodeisscaleddowninsizelinearlyaccord-
Voxel-downsampling is performed at a resolution of 1cm.
ing to the remainder. Additionally, random noise is added
Color-thresholding is performed in LAB color space. All
toeachpetioleanglefollowingaGaussiandistributionwith
pointswithL∗ < 0andb∗ < 1areremoved. Then,points
mean0andstandarddeviation5degrees. Eachnodegrows
witha∗ <2areclassifiedasgroundpoints,andtherestare
onalternatingsidesoftheirstem,withadditionalazimuthal
classified as plant points. RANSAC is used to fit a plane
rotationfollowingaGaussiandistributionwithmean0and
to the ground points using an inlier threshold of 5cm and
standarddeviation60degrees. Therangeofpossiblevalues
1000maxiterations. Forrowfitting,thepointswhosedis-
foreachmodelparameterareprovidedinTab3.
tancefromthegroundarebelowthe50thpercentilearedis-
carded. RANSAC is applied sequentially to fit lines with
Parameter Range an inlier threshold of 20cm until the number of points re-
Leaflengthmultiplier 0.5-1.5 maining is either less than 1000 or less than 20% of the
Petiolelengthmultiplier 0.5-2.0 startingnumber. Wethentaketherowwiththemostinliers
Petioleanglemultiplier 0.5-4.0 and fit a line through the inliers again using least-squares
Internodelengthmultiplier 0.5-2.0 fitting. Thecameraposefordepthrenderingissettobedi-
Numberofnodes 1.0-14.0 rectlyabovethemeanoftheinlierpointsataheightof1m
fromtheground, facingdownwardsandwiththecamera’s
Table3.Soybeanmodelparameterranges.
x-axis aligned with the row line. If the number of initial
plantpointsisgreaterthan75%ofthetotal,weinsteaduse
12Input Poisson MLP Trust-Region Ours
June27
July11
Figure7. Qualitativereconstructioncomparison. Wecompareexamplereconstructionsfromeachofthebaselinemethods. Thefirst
columnshowsexampleimagesfromthemulti-viewdatacollectedateachtimepoint,andtheremainingcolumnsshowthecorresponding
meshreconstructions.
the70thpercentilefordistancefromtheground, arowin- ofSobelderivatives,sincetheNeRFrenderingisgenerally
lierthresholdof25cm,andarenderheightof1.25m. The blurrierthantheproceduralmeshrendering. Formaize,the
render resolution is 994×738 with a vertical FOV of 50 depthhistogramhas10equallyspacedbinsfrom2mtothe
degrees. renderheight,andtheblurkernelsizeis55.
For the maize data, we sample 5M points in a 2×2×
A.4.BaselineImplementationDetails
2 box around the origin in the scaled scene. The L∗,a∗,
and b∗ thresholds are set to 32, 0, and 0 respectively. The We provide implementation details for the baseline recon-
ground-inlierthresholdissetto10cmandtherenderheight structionmethods:
issetto5m.TherowfittingisdoneinaROIwiththeshape • Poisson: We use the Poisson surface reconstruction im-
ofacylinderwithradius2mwhoseaxisisperpendicularto plementation by Open3D [58] integrated into Nerfstu-
thegroundplane. dio[46].Forsoybean,weuse100Kpointswith50Kfaces
inthesameboundingboxasinourmethodandfilterout
A.3.MaskandHistogramDetails
points whose z-coordinates are lower than 0.2 plus the
The foreground mask M is obtained by color- 1stpercentile. Formaize, weusea4m×4mbounding
obs
thresholdingontheRGBrendercombinedwiththreshold- columnand0.1minsteadof0.2.
ing on 3D coordinates. For soybean, points are marked as • MLP: The MLP input consists of the same histograms
background if their a∗ channel is less than -8 and their z- used for optimization, concatenated with the render
coordinateisgreaterthan0.25mshortoftherenderheight, height and mask area. The training data is generated
ortheirz-coordinateislessthan0.1m,ortheiry-coordinate by uniformly randomly sampling parameter values and
is at least 0.5m away from zero. For maize, points are computing the corresponding MLP inputs. For soybean,
marked as background if a∗ channel is less than -8 and we sample 10K pairs with render height 1.0m and 10K
their L∗ channel is greater than 40 and their z-coordinate pairs with render height 1.25m. For maize, we sample
is greater than 2m short of the render height, or their z- 20K pairs with render height 5.0m. The MLP has two
coordinateislessthan0.1m,ortheiry-coordinateisatleast hidden layers of size 512, and we train for 200 epochs
3mawayfromzero. M isobtainedtriviallybynotren- using an Adam optimizer with α = 0.001,(β ,β ) =
pred 1 2
deringanybackground. (0.9,0.999),andweightdecayof10−5.
Forsoybean,thedepthhistogramhas20equallyspaced • Trust-Region: We use the trust-region method im-
bins from 0.1m to the render height. The lateral his- plemented by the “trust-constr” option of SciPy’s
togramhas10equallyspacedbinsfromzerotohalftheren- optimize.minimize function [19], with the maxi-
der height. The depth derivative histogram has 10 equally mum number of iterations set to 500. For fair compari-
spacedbinsfromzeroto0.004. AGaussianblurwithker- sonwithourBayesianoptimizationmethod,werunit10
nelsize25isappliedtothedepthmapbeforethecalculation times with different random initializations. We take the
13Soybean
2.5 leaf length multiplier
petiole length multiplier #ofruns LAIE(↓) LAIPE(↓) AME(↓) ASDE(↓)
petiole angle multiplier
1 0.76 0.23 12.18 7.81
internode length multiplier
2.0
number of nodes 2 0.79 0.20 12.18 7.74
5 0.78 0.16 12.13 7.74
1.5 10 0.69 0.15 12.07 7.39
20 0.69 0.14 12.23 7.77
1.0
Table5.Effectofaveragingsolutionsoverruns.Bold:best.
0.5
previous metrics, we report the average value of the min-
imized loss function and time per run. Performance does
Figure8.Jitterplotsofoptimizedparametervalues.Thevalues
tend to improve with more iterations, but takes increasing
arenormalizedbydividingbytheper-sceneaverage.Theindivid-
amountsoftimeperiterationduetolargerandlargerkernel
ualoptimizationrunsgenerallydonotstrayfarfromtheaverage,
buttakingtheaverageultimatelygivesabetterresult. computations.Inaddition,beyondacertainpoint,decreases
in the loss function does not necessarily translate to better
reconstructionquality.
solution with the lowest loss value instead of averaging,
B.3.WindSimulation
sincewefinditgivesbetterperformance.
The procedurally generated meshes from our model can
B.AdditionalResults alsobe usedfordynamicssimulations. Weshow rendered
framesofawindsimulationusingNVIDIAPhysXinFig.9.
B.1.AdditionalQualitativeResults
Visually, the results appear to show a physically plausible
animation of leaves blowing in the wind. Video visualiza-
Weprovidequalitativecomparisonsofthedifferentrecon-
tionscanbefoundinthesupplementaryvideo.
structionbaselinesinFig.7.WeobservethatPoissonrecon-
struction gives incomplete and implausible canopy shape,
motivating the use of inverse procedural modeling. Com-
pared to the other procedural generation baselines, our
methodgenerallyproducestheparametersthatbestreflects
the true real-world canopy. In the examples shown, the
MLPproducesleavesthataretoosmall,andthetrust-region
optimizationproducesleavesthataretoolarge.
B.2.BayesianOptimizationPerformanceAnalysis
We visualize the distributions of the optimized parameter
values before averaging in Fig. 8. The values include the
10 runs for all 18 soybean scenes and are normalized by
the averaged result. We observe that there is a moderate
amountofvarianceintheoptimizationresults. Wethenex-
amine how reconstruction performance changes as we av-
erageacrossdifferentnumbersofrandominitializationsfor
BayesianoptimizationinTab.5. Althoughthereisnosig-
nificantimprovementintheleafanglemetrics,weobserve
thattheleafareaestimatesimproveoverallwhenaveraging
over more runs, eventually plateauing around 10-20 runs.
Notethattheconstraintsoftheproceduralmodelgenerally
ensure that all possible combinations of parameters yield
plausible 3D reconstructions, so there is no real concern
overtheaveragegivinganunreasonableresult.
Wealsoexaminehowperformancechangesasthenum-
ber of Bayesian optimization iterations varies in Tab. 6.
Here,wearestillaveragingover10runs. Inadditiontothe
14
eulav
retemarap
dezilamronSoybean
#ofiterations LAIE(↓) LAIPE(↓) AME(↓) ASDE(↓) AverageL(↓) Time(↓)
300 0.73 0.18 12.32 7.77 0.0172 3m
400 0.77 0.17 12.18 7.77 0.0133 9m
500 0.69 0.15 12.07 7.39 0.0110 16m
600 0.70 0.13 12.56 8.01 0.0096 26m
Table6.EffectofnumberofBayesianoptimizationiterations.Bold:best.
t = 0 t = 1 t = 2 t = 3
Figure9. Windsimulation. Weshowthattheprocedurallygeneratedmeshoutputscanbeusedforphysicallyrealisticdynamicssimula-
tions.Here,auniformwindforceisapplieddirectlyfromtheright.
15