Adaptive Decoding via Latent Preference Optimization
ShehzaadDhuliawala12 IliaKulikov1 PingYu1 AsliCelikyilmaz1
JasonWeston1 SainbayarSukhbaatar1 JackLanchantin1
Abstract solution, and benefit from a low temperature, or greedy
decoding(Shietal.,2024). Others,likestorygeneration,
Duringlanguagemodeldecoding,itisknownthat
benefit from diverse and creative outputs, and a high de-
using higher temperature sampling gives more
codingtemperature. Intuitively,acomplextaskinvolving
creativeresponses,whilelowertemperaturesare
anumberoftheserequirementsmightthusbenefitfroman
morefactuallyaccurate. However,suchmodels
adaptivetemperaturefordifferentpartsofitssolution.
arecommonlyappliedtogeneralinstructionfol-
lowing, which involves both creative and fact- Existing LLM evaluation pipelines often rely on a fixed
seeking tasks, using a single fixed temperature choice of temperature which is therefore suboptimal on
acrossallexamplesandtokens. Inthiswork,we some tasks, or else manual tuning is used to control the
introduce Adaptive Decoding, a layer added to levelofdiversityinLLMs,whichcanbetime-consuming,
themodeltoselectthesamplingtemperaturedy- task-specific, and limited in its ability to adapt to chang-
namicallyatinferencetime,ateitherthetokenor ing requirements and prompts. To overcome this limita-
examplelevel,inordertooptimizeperformance. tion,weintroduceAdaptiveDecoding,whichconsistsofa
TolearnitsparametersweintroduceLatentPref- new learnable layer, as well as a novel method to train
erenceOptimization(LPO)ageneralapproachto it. The new learnable neural layer, which we call the
traindiscretelatentvariablessuchaschoicesof ADAPTIVEDECODER, is added to the final layers of the
temperature.Ourmethodoutperformsallfixedde- transformerarchitecture,enablingtheLLMtodynamically
codingtemperaturesacrossarangeoftasksthat adjustitsoutputdiversitybasedoncontext(i.e,thetaskat
require different temperatures, including Ultra- hand). Specifically, the ADAPTIVEDECODER allows the
Feedback,CreativeStoryWriting,andGSM8K. modeltoselectanidealtemperaturefordecodingthenext
tokenbyaddinganewdecoderheadattachedtothelasthid-
denstate.Wecaneitherapplythisattheexample(sequence)
1.Introduction levelwhereasingletemperatureispredictedforallgener-
atedtokens,orthetokenlevelwhereanewtemperatureis
Large language models (LLMs) are powerful generalist
predictedforeachgeneratedtoken.
modelsthatcanbeusedonawidevarietyoftasks,ranging
from fine-grained reasoning to open-ended creative writ- Training the ADAPTIVEDECODER layer requires discrete
ing(OpenAI,2023;Dubeyetal.,2024). Yet,earlyworks optimizationoverlatentvariables(i.e.,thechoiceoftemper-
showedthataftertraining,thedecodingmethodstillhasa ature). Inordertomakethisfeasible,weintroduceageneral
largeeffectonperformanceacrossthesetasks,leadingto methodforsuchtraining,calledLatentPreferenceOptimiza-
the proposal of various temperature sampling techniques tion(LPO).LPOinvolvessamplingmultipleresponsesfrom
(Holtzman et al., 2019; Welleck et al., 2019; Fan et al., themodel,wheretheADAPTIVEDECODERlayerwillselect
2018). IncurrentLLMs,temperature(Ackleyetal.,1985) temperatures(latentvariables)thatwillaffectthefinaltoken
isakeypost-trainingparameterforgeneration.Temperature choices. Those responses are then evaluated by a reward
isusedtoscalethenexttokenprobabilitiestobeeithermore modelinordertobuildchosenandrejectedpreferencepair
uniform or more sharp. Lower temperature leads to less examples. Giventhesepairs,weusetheLPOlosstolearn
creative,morefactualgenerations,andhighertemperature theoptimalparametersofthe ADAPTIVEDECODER layer
leads to more creative and original generations. Certain forselectingtemperaturesduringdecoding. Ourapproach
tasks,suchasmathproblemsorfactualquestionanswering, thuslearnsthehyperparametersofgeneratingtextacross
requirethemodeltooptimizeaccuracyofasinglecorrect diversetasks,allowingthemodeltobalanceexplorationand
exploitationinatask-awaremanner.
1FAIRatMeta. 2ETHZu¬®rich. Correspondenceto: JackLan-
chantin<jacklanchantin@meta.com>. Tovalidateourmethod,weexperimentonadiversesetof
tasks,rangingfrommathreasoningtocreativewritingand
4202
voN
41
]LC.sc[
1v16690.1142:viXraToken Prob
AdaptiveDecodingviaLatentPreferenceOptimization
mat 1.00
floor 0.00
Sequence Level Adaptive Decoder Token Level Adaptive Decoder
... ...
ùúè Adaptive Decoder Module
ùúè ùúè y
‚Ä¶ ùúè ùúè ùúè ùúè t+1
ùúè Predicted
Temperature
(latent variable)
Softmax
AD AD AD AD AD
ùúè
LM Adaptive Decoder Module LM Adaptive Decoder Module
AD
Token Prob
x x x x x y y y ‚Ä¶ x x x x x y y y ‚Ä¶ h mat 0.50
1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 t
floor 0.20
Prompt Response Prompt Response ... ... ùúè=0.8
Figure1: TheADAPTIVEDECODER. Thislearnedmoduleisaddedtothestandardtransformerinordertoselectdecoding
y y y ‚Ä¶ y y y ‚Ä¶
hyperparameters. Itconsistsofa6newd7ecode8r headattachedtothelasthiddenstatew6hich7assign8s probabilitiestodifferent
hyperparameterchoicespertokenR(ersipgohnt)seorsequence(left), andthehighestprobabiRleitsypocnhsoeiceisselectedineachcase.
ThisallowstheLLMtoselectlowtemperaturesfortokensrequiringfactualconsistency,andhighertemperaturesfortasks
requiringcreativityanddiversity. Forthetokenleveladaptivedecoder,adifferenttemperaturecanbeselectedfordifferent
partsoftheresponsegivenasingleinstruction.
general instruction following. We show that the decoder strategiesworkbetterfordifferenttasks. Zhangetal.(2020)
learns to select low temperatures for reasoning tasks like evaluatesdifferentdecodingstrategiesincludingfixedtem-
math,highertemperaturesforcreativewriting,andsome- perature,top-k,andtop-p. Theyfindthatwhendiversityis The cat sat on the
whereinbetweenforgeneralprompts. Wefindthatwhen thepriority,allmethodsperformsimilarly,butwhenquality
thetrainingdataincludesalltypesoftasks,themodeladap- isthepriority,top-pisthebest.Usingdifferenttemperatures
tivelyadjuststhetemperaturetotheidealvalueforeachtask todecodefordifferenttaskshasalsocementeditselfascom-
by conditioning output token temperature choices on the mon wisdom for prompting LLMs (Achiam et al., 2023).
inputcontext. ThisenablestheADAPTIVEDECODERtobe CommercialLLMAPIguidesevenrecommendusingalow
incorporatedaspartofthestandardpost-trainingpipeline temperatureforanalyticaltasksandatemperaturecloseto
toproduceamodelthatcanadjustitsdiversityadaptively 1.0forcreativetasks1.
dependingonthetaskathandforgeneralinstructionfollow-
AdaptiveDecoding.Priorworkstudiedtheadaptivechange
ing, and even use different decoding parameters within a
ofdecodingparametersunderdifferentcriteriasuchasbased
singleresponseforthebestoutcome. Additionally,ourpro-
onthetargettask,approximaterewardofthedesiredoutput,
posed approach is general, and the ADAPTIVEDECODER
orthetargetlikelihoodscore. (Zhuetal.,2024)developed
couldbepotentiallyusedtoconverthyperparametersother
adecodingstrategythatcanadaptbasedontheprobability
thantemperature(e.g. top-p,top-k)effectivelyintomodel
distributionoftheprevioustokenwhile(Zhuetal.,2023)
parameters. Furthermore,weshowthatLPOisalsoagen-
uses a rule-based method to predict a temperature value
eraltooltotraindiscretelatentvariablesthatcanbeusedfor
foreachtoken. Basuetal.(2020)usesthedesiredperplex-
otherarchitecturechoicesthatcontaindiscretedecisions.
ityvaluetopredicttheoptimaltop-khyper-parameterfor
eachtoken. Finlaysonetal.(2023)proposesbasis-aware
2.RelatedWork samplingthatfindstheoptimalsupportoverthenexttoken
distributionbyaddressingthesoftmaxbottleneckissue. Un-
Fixed Decoding Strategies. Various methods have pro-
likeourapproach,noneofthesemethodslearntopredict
poseddifferentfixeddecodingstrategiesthatoftendepend
an adaptive decoding strategy, but rather use various test
on one or more hyperparameters. Beam search is a clas-
timeheuristics. Lietal.(2024)proposeamethodtolearn
sical approach for tasks like machine translation (Freitag
samplespecificdiversityvaluesondialoguetasksusingan
& Al-Onaizan, 2017), but is typically not used for LLM
MSEloss, wherethediversityvaluesarethenmappedto
instruction following. A beam size of 1 corresponds to
temperaturesusingamappingfunction. Zhangetal.(2024)
greedydecoding. Holtzmanetal.(2019)introducednucleus
dynamically select a temperature as a function of the en-
sampling,Fanetal.(2018)introducedtop-ksampling,and
tropy where the parameters of the function are treated as
sincethenvariousfurthersamplingapproacheshavebeen
proposed. Shietal.(2024)showedthatdifferentdecoding 1https://docs.anthropic.com/en/api/complete,https:
//ai.google.dev/gemini-api/docs/text-generationAdaptiveDecodingviaLatentPreferenceOptimization
RM(Generated Response ) > RM(Generated Response )
1 2
ùúè=0.6
Latent Variable
ùúè=0.2
Latent Variable
AD AD
LM LM
Adaptive Decoder Module Adaptive Decoder Module
x x x x x y y y ‚Ä¶ x x x x x y y y ‚Ä¶
1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8
Prompt Generated Response Prompt Generated Response
1 2
Figure 2: Latent Preference Optimization (LPO) Training Mechanism. We demonstrate how preference pairs are
constructedfortrainingtheLPOloss(weshowaSequence-Level ADAPTIVEDECODER,buttheprocedureremainsthe
sameforToken-Level). HerewehaveN=2generatedresponsesamplesforasingleprompt,andtheRewardModel(RM)
scoresResponse betterthanResponse . Therefore,weuseœÑ =0.6asthechosentemperature,andœÑ =0.2astherejected
1 2
temperature,andthenapplythelosstopreferthechosentemperatureovertherejectedoneforthegivencontext(prompt).
hyperparameters which they tune for each different task. the ADAPTIVEDECODER module and LPO loss in more
Ad-hoc temperature prediction has been commonly used detail.
forcalibration,asexploredbyKumar&Sarawagi(2019)
and Xie et al. (2024). To the best of our knowledge, we 3.1.ADAPTIVEDECODERModule
proposethefirstmethodtopredictthetemperaturedirectly
usingpreferenceoptimization,allowingthemodeltolearn
HereweintroducetheADAPTIVEDECODERmodule,which
isasmallneuralnetworkthatcanbeattachedontopofany
taskdependenttemperaturesatboththesequenceandtoken
existingLLM.Ittakesasaninputlatentrepresentationsof
levels.
thelasthiddenlayerandoutputsaprobabilitydistribution
PreferenceOptimization. ReinforcementLearningfrom overpossibletemperaturechoices. LetMbeatransformer
HumanFeedback(RLHF)hasemergedasamajoringredi- core(Vaswani,2017)withinanLLMthatmapsasequence
entofLLMtraining(Ouyangetal.,2022). DPO(Rafailov oftokens{x }toalatentrepresentation,h ,atthelastlayer.
t t
etal.,2024)andotherpreferenceoptimizationmethods(Xu Thislatentrepresentationisthenusuallyconvertedtotoken
etal.,2023;Mengetal.,2024)havesignificantlysimplified probabilitiesusinganun-embeddingmatrixW followedby
theRLHFprocess. Whilemanyofthesemethodsimprove asoftmax. Thus,aregularLLMgeneratesthenexttoken
performance and generalization they can also negatively x asfollows:
t+1
affectdiversityandcalibration(Achiametal.,2023;Kirk
h =M(x ,...x ),
etal.,2023).Inparticular,RLHFmethodsoptimizethefinal t 1 t (1)
rewardwhichdoesnottakediversityintoaccount,soithas x t+1 ‚àº SOFTMAX(Wh t).
becomecommonpracticetoaddaKLregularizationterm Afixedtemperaturevalue,œÑ,canbeusedtoscalethesoft-
tomaintainsomeofthemodel‚Äôsoriginaldiversity(Ziegler maxdistributioninthefollowingway:
etal.,2019;Rafailovetal.,2024). Tothebestofourknowl-
edge,ourmethodisthefirsttousepreferenceoptimization
x
t+1
‚àº SOFTMAX(Wh t/œÑ), (2)
fortraininglatentvariablesinsteadofwordtokens. wheresmalltemperaturevalues(toward0)makethedistri-
butionsharper,andhightemperaturevalues(toward1)will
3.Method resultintheoriginaldistribution.
AdaptiveDecodingworksbypredictingtheoptimalœÑ value
The goal of our method is to make the language model
foraspecificinput{x }. ToaddAdaptiveDecodingtothis
itselfchooseanidealtemperatureforgeneratingtokensde- t
LLM,wealsofeedthesamelatentrepresentationh toan
pendingonthecurrentcontext. Toachievethis,weadda t
ADAPTIVEDECODERmodulethatmapsittoacategorical
smalldifferentiablemoduletoanexistingLLMthatpredicts
probabilitydistributionoverasetofpre-definedtemperature
atemperaturevaluetobeusedfordecodingwordtokens,
valuesœÑ ,...,œÑ :
which we call the ADAPTIVEDECODER. For training an 1 K
ADAPTIVEDECODERmodule,wedevelopapreferenceop- P(œÑ k|h t)= ADAPTIVEDECODER(h t),
timizationmethod,LPO,thatisdesignedforlearningsuch (cid:88) (3)
where P(œÑ |h )=1.
hyperparameters. Inthefollowingsubsectionswedescribe k t
kAdaptiveDecodingviaLatentPreferenceOptimization
Wecanthenstraightforwardlymakeuseofthisdistribution lasttokenx oftheprompttopredictatemperaturevalueœÑ
T
forgeneratingagivenoutputtoken,x ,byselectingthe tobeusedfortheentireresponsegeneration:
t+1
temperaturewiththehighestprobability,andthenusethat
temperaturefordecodingthenexttoken:
œÑ ‚àº ADAPTIVEDECODER(h T),
(8)
y
t+1
‚àº SOFTMAX(Wh t/œÑ) for T ‚â§t<T‚Ä≤.
œÑ =argmax P(œÑ |h ),
œÑk k t (4) Suchacoarse-grainedtemperatureadjustmentmaybesuf-
x
t+1
‚àº SOFTMAX(Wh t/œÑ).
ficientformostapplicationswherethetaskrequireseither
concisenessorcreativity,butnotboth,andisstillpotentially
Alternatively,onecansampleatemperaturefromthedistri-
muchmoreflexiblethantheclassicalapproachofchoosing
butionandthensampleatokenwithit:
asinglefixedtemperatureforallinputprompts.
œÑ ‚àºP(œÑ |h ),
k t
(5) 3.3.LatentPreferenceOptimization
x
t+1
‚àº SOFTMAX(Wh t/œÑ).
TolearntheADAPTIVEDECODERparameters,weemploya
Thislatterapproachcanalsobewrittenasasinglesampling preferenceoptimizationtrainingwherewegeneratemultiple
operation: responsesfromthemodelandlabelsomeofthemaschosen
andothersrejected. Theoverallgoalofthetrainingisto
(cid:88)
x
t+1
‚àº P(œÑ k|h t)SOFTMAX(Wh t/œÑ k). (6) makethelikelihoodofgeneratingchosenresponseshigher
k than the rejected ones, similar to the existing preference
optimizationmethodssuchasDPO(Rafailovetal.,2024).
Whilethelasttwooperationsareidentical,thesecondver-
However,thoseexistingmethodsaredesignedtotraintoken
sionwillallowustodevelopanewlossfunctionfortraining
probabilities,notlatentvariableswithinthemodel. Thereby,
aswewillseeinthenextsection.
weproposeageneralizationofDPO,whichwecallLatent
Anyneuralnetworkarchitecturecanbeusedfortheinternals PreferenceOptimization(LPO),thatisageneralapproach
of the ADAPTIVEDECODER module, but we use a multi- to train discrete latent variables, such as the choices of
layerperceptron(MLP)withasoftmaxoutputforsimplicity temperature2.
(detailsin Section4.1). Notethatitisalsostraightforward
To use LPO to learn optimal temperatures, we first gen-
to generalize the ADAPTIVEDECODER to other decoding
eratemultipleresponses{y1,...,yN}foreachpromptx
hyperparameterssuchastop-kbysimplymodifyingEqua-
bysamplingtemperaturesfromthe ADAPTIVEDECODER
tion2tothecorrespondingoperation. Inaddition,Mcan
output, which then affect how tokens are sampled. Let
be another neural model besides a transformer, such as a
œÑn ={œÑn ,...,œÑn}bethetemperaturesusedwhengen-
recurrentneuralnetwork. T+1 T‚Ä≤
erating tokens in response yn = {yn ,...,yn }. The
T+1 T‚Ä≤
responsesarethenscored,eitherusinganexternalreward
3.2.TokenvsSequenceLevelADAPTIVEDECODER.
model,ormeasuringthecorrectnessoftheiranswer,depend-
ingonthetask. Thehighestandlowestscoringresponses
We propose two variants of the ADAPTIVEDECODER, as
demonstrated in Figure 1. Let x = {x ,...,x } be
becomeourchosenandrejectedresponsepair(yc,yr).This
1 T
processisdepictedinFigure2.RegularDPOtrainingwould
the sequence of given input prompt tokens, and y =
optimizethetokenprobabilitiesoftheseresponsepairs,but
{y ,...,y }bethegeneratedresponsetokens.Intheto-
T+1 T‚Ä≤
ourgoalistolearnthecorrespondingchosenandrejected
kenlevelvariant,ADAPTIVEDECODERtok (AD seq),atem-
temperaturevalues(œÑc,œÑr)thatareusedwhensampling
peratureispredictedforeachnewtokentobedecoded.This
the response tokens. For this, there are multiple ways to
isachievedbyapplyingtheADAPTIVEDECODERatevery
adapttheDPOloss,whichweoutlinebelow.
step of generation and using the selected temperature for
samplingthefollowingtoken: Temperaturesastokens. Thesimplestformulationisto
treatthetemperatureselectionjustlikeanothertoken.Inthis
œÑ
t
‚àº ADAPTIVEDECODER(h t),
view,themodelgeneratestwotokensperstep:atemperature
(7)
y t+1 ‚àº SOFTMAX(Wh t/œÑ t) for T ‚â§t<T‚Ä≤. tokenœÑ tandawordtokeny t. Thetemperaturetokenshave
adifferentvocabulary,consistingofpossibletemperature
Suchfine-grainedtemperatureadjustmentallowsthemodel values, but that does not complicate training. Similar to
tolearnanindividualtemperaturevalueforeachtoken. howthepreviouswordtokenchoiceaffectsthenextword
token,thetemperaturetokenalsoaffectsthefollowingword
In the sequence level variant ADAPTIVEDECODERseq
(AD ), a single temperature is predicted for the entire
seq 2Whiletemperatureisacontinuousvalue,wearefocusingon
response. Unlikethetokenlevel,theADAPTIVEDECODER discretetemperatureoptionsinthispaper.Thisalsomakesiteasy
moduleisusedonlyonceperinputprompt,appliedatthe togeneralizeourmethodtootherdiscretevariables,suchastop-k.AdaptiveDecodingviaLatentPreferenceOptimization
tokenprobabilities. Sincethemodelisgeneratingasingle normal LLMs, but those probabilities are altered by the
sequence of ‚Äútokens‚Äù, yÀÜn = (yn,œÑn), we can apply the ADAPTIVEDECODER,asfollows:
usualDPOlosstothisjointtokensequence:
(cid:88)
y ‚àºP‚Ä≤(y)= P(y|œÑ)P(œÑ).
t
(cid:20) P(yÀÜc) P(yÀÜr) (cid:21) œÑ
L =‚àílogœÉ Œ≤log ‚àíŒ≤log
LPO P ref(yÀÜc) P ref(yÀÜr)
NowwecanapplytheDPOlosstothesetokenprobabilities
(cid:20) P(yc,œÑc) P(yr,œÑr) (cid:21) wherethetemperatureismarginalizedout
=‚àílogœÉ Œ≤log ‚àíŒ≤log ,
P (yc,œÑc) P (yr,œÑr)
ref ref (cid:20) P‚Ä≤(yc) P‚Ä≤(yr) (cid:21)
L =‚àílogœÉ Œ≤log ‚àíŒ≤log
where P are reference model probabilities. Since our LPO P‚Ä≤ (yc) P‚Ä≤ (yr)
ref ref ref
reference model does not have an ADAPTIVEDECODER (cid:34)
(cid:88) P‚Ä≤(yc) (cid:88) P‚Ä≤(yr)
(cid:35)
module,weomititforthetemperaturetokens3,andtheloss =‚àílogœÉ Œ≤ log t ‚àíŒ≤ log t
P‚Ä≤ (yc) P‚Ä≤ (yr)
thereforebecomes: t ref t t ref t
L
LPO
=‚àílogœÉ(cid:20)
Œ≤log
PP( (y yc c)
)
‚àíŒ≤log
PP( (y yr r)
)
=‚àílogœÉ(cid:34) Œ≤(cid:88)
t
log(cid:80)(cid:80) œÑPœÑ rP ef( (y yt tc c| |œÑ œÑ) )P
P
r( eœÑ f()
œÑ)
ref ref (cid:21) (cid:88) (cid:80) P(yr|œÑ)P(œÑ) (cid:35)
+Œ≤logP(œÑc)‚àíŒ≤logP(œÑr) . (9) ‚àíŒ≤ log(cid:80) PœÑ (yt
r|œÑ)P (œÑ)
. (11)
t œÑ ref t ref
Theadvantageofthislossisthatittakesintoaccountboth Note that the actual temperatures used in generation are
wordtokenandtemperatureprobabilities,makingitpossible irrelevanthere,thusreducingthenoisecausedbysampling
totrainbothusingasingleloss. HereŒ≤isahyperparameter temperatures during training. The reference temperature
ofDPOthatcontrolstheKLterm. probabilitiesP (œÑ)areuniformifthatistheinitialization.
ref
Temperatures as tokens (separate). Like the previous
4.Experiments
formulation,weviewthetemperaturesastokens,buttreat
thewordtokengenerationasanexternalmechanismand
4.1.Setup
focusonlyonthe ADAPTIVEDECODER. Inthisview,the
ADAPTIVEDECODERmodulegeneratesatokenœÑ t,which Forallexperiments,wetrainan ADAPTIVEDECODER on
is a temperature value in this case, that is then fed to topofaLlama3.0-8B-Instructmodel(Dubeyetal.,2024).
an external mechanism that generates the word token y t. The ADAPTIVEDECODER module is a 3-layer MLP with
This framing makes things simpler because we have the hiddendimension2048,andSiLU(Hendrycks&Gimpel,
ADAPTIVEDECODERgeneratingtwosequencesoftemper- 2016) activations. We freeze the weights of the Llama
aturevalues(œÑc,œÑr)whereoneispreferredovertheother. modeltobetterunderstandtheeffectofsamplingtempera-
SowecandirectlyapplytheDPOlosswithonlythetem- tureinisolationfromfinetuningthewholemodel. ForLPO
peraturetokensœÑ : training,bydefaultweusethelossinEquation10forits
t
simplicity,unlessotherwisespecified. Duringtraining,re-
L LPO =‚àílogœÉ[Œ≤logP(œÑc)‚àíŒ≤logP(œÑr)]. (10) sponsesaregeneratedusingEquation5wheretemperatures
are sampled, but we use greedy temperature selection at
Againweomitthereferenceprobabilitiesforthetempera-
inferencetimeusingEquation4,unlessotherwisespecified.
turetokens. Thislossissimpleanddoesnottakeaccount
oftokenprobabilities,butonecanalsouseaseparateDPO
4.2.ReducingN-gramRepetitions
lossforthewordtokens.
Westartwithasimplefirstexperimentwhereweknowtem-
Temperaturesaslatents. Inthisversion,wetakeadvan-
perature choice matters. It is understood that LLMs are
tageofthefactthatthechosenandrejectedlabelsareonly
pronetoerroneousrepetitions,particularlywhengreedyde-
conditioned on word tokens, and the temperature values
coding(œÑ=0)isused(Holtzmanetal.,2019). Wetherefore
thatareuseddonotdirectlyaffectthisranking. Thereal
sought to validate whether the ADAPTIVEDECODER can
objective we want to optimize is the probability of sam-
learntopickhighertemperaturesforspecifictokenstoavoid
plingchosenandrejectedwordsequences. Therefore,we
treattheADAPTIVEDECODERasaninternalmechanismof
repeats. WeuseanADAPTIVEDECODERtok andprovideit
with 5 temperature options: œÑ ‚àà {0.0,0.1,0.2,0.4,0.6}.
the model and the temperature values as latent variables.
We feed text from Wikitext-2 (Merity et al., 2016) to
Thisway,themodelonlyoutputstokenprobabilitieslike
the model and ask it to complete it. We use 3-gram-
3Thisisthesameasassumingthereferencemodelhasalways repeats to rank the responses and create preference train-
uniformprobabilitiesoverpossibletemperatures. ing pairs (see Appendix A for details). We find that theAdaptiveDecodingviaLatentPreferenceOptimization
FixedTemp. AdaptiveDecoder FixedTemp. AdaptiveDecoder
seq tok
54 54
52 52
50 50
48 48
46 46
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
Fixedtemperature Fixedtemperature
Figure 3: UltraMathStories Results. UltraMathStories is a superset of UltraFeedback, GSM8K, and Stories. The
Adaptive Decoding models are trained on all 3 subtasks simultaneously. Winrates are shown as the average winrate
acrossthetestsetsofthe3subtasksinUltraMathStories. (left)ADAPTIVEDECODERseq vsFixedTemperatureWinrates.
(right)ADAPTIVEDECODERtok vsFixedTemperatureWinrates. Inbothcases,AdaptiveDecodingoutperformsallfixed
temperatures.
Method 3-gram-repeats‚Üì %ofnon-greedy
GreedyDecoding 0.36% 0%
ADAPTIVEDECODERtok 0.22% 94%
Table1: ReducingRepeatsusingthe ADAPTIVEDECODER. WefeedtextfromWikitext-2tothemodelandaskitto
completeit. Whencompletingatext,ADAPTIVEDECODERtok learnstoavoidgreedydecodinginordertoreducerepeats.
In94%ofsamples,ADAPTIVEDECODERtok learnstopickanon-greedytemperature.
ADAPTIVEDECODERtok effectively learns to reduce re- ‚Ä¢ CreativeWriting(Stories). Incontrast,whensolving
peatsby42%comparedtogreedydecodingontheWikitext- open-endedcreativewritingproblems,LLMsbenefitfrom
2 test set (Table 1). We also note that in around 94% of hightemperaturesamplingtowritemoreinterestingand
casesADAPTIVEDECODERtok learnstopickanon-greedy originalresponses. Weintroduceacreativestorywriting
temperature. ThisservesasaproofofconceptthatLPOcan task, whichwecall‚ÄúStories‚Äù, toevaluatethecreativity
successfully optimize the temperature values in the right andcoherenceofamodelonopenendedprompts. We
directionatthetokenlevel. promptthemodeltowriteashortstoryofagiventitle,
whereweusealanguagemodeltocreatetheinitialtask
4.3.UltraMathStories titles. WeusetheArmorewardmodel(ArmoRM)(Wang
etal.,2024)forscoringresponsesandselectingtraining
Next,weconsideramuchmorerealisticgeneralinstruction
preferencepairs,aswellasforscoringresponsesduring
following setting to test if the ADAPTIVEDECODER can
finalevaluation. ArmoRMgivesascalarscorevaluefor
learntoselectdifferenttemperaturesdependingonthegiven
aresponsegivenitsprompt. Wetakethetopandbottom
promptquery. Wethusdeliberatelyconsideradatasetthat
scoredresponsesforselectingthechosen/rejectedpairs
is a mixture of the following subtasks that require both
SeeAppendixSectionA.4formoredetailsoncreating
formulaic,aswellascreativeresponses:
thedataset,andconstructingthepreferencepairs.
‚Ä¢ Math(GSM8K).Whensolvingmathreasoningprob- ‚Ä¢ GeneralInstructions(UltraFeedback). Finally,many
lems,LLMsrequiregreedy,orlow-temperaturesampling real-worldpromptsliesomewhereinbetweenstructured
to produce accurate and reliable results (Kojima et al., reasoning and open-ended creativity, or contain a mix-
2022).Themodelshouldnotdeviatefromhigh-likelihood ture of both. We therefore consider the UltraFeedback
tokensinthissettingsincefactualityiscrucialforfind- (Cui et al., 2023) dataset, which covers a wide variety
ingthecorrectanswer. GSM8K(Cobbeetal.,2021)is ofrealuserprompts,rangingfromrigidreasoningtasks
acommonmathreasoningdatasetusedtoevaluatesuch to open-ended writing. We use the same ArmoRM for
capabilities. Sincewehavethegroundtruthanswers,we constructingtrainingpreferencepairsandevaluating.
usethemtoscoreresponsestoselecttrainingpairs,and
forfinaltestevaluation. We combine 2,000 training samples from UltraFeedback,
)%(setarniW )%(setarniWAdaptiveDecodingviaLatentPreferenceOptimization
GSM8K UltraFeedback Stories
100 50 100
80 40 80
60 30 60
40 20 40
20 10 20
0 0 0
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
Temperature ( ) Temperature ( ) Temperature ( )
Figure4: ADAPTIVEDECODERseq predictedtemperaturedistributions. Weshowthedistributionofpredictedtempera-
turesonthetestsetofeachsubtaskinUltraMathStories. Asexpected,themodelpredictslowtemperaturesforGSM8K,
hightemperaturesforStories,andtemperaturesmostlyinbetweenforUltraFeedback.
Prompt PredictedœÑ
DetailedInstructions:Inthistask,youaregivenacountrynameandyouneedtoreturnthecapitalcityofthegiven 0.0
country\nProblem:Guinea-Bissau\nSolution:
Writeacompellingshortstoryaboutabitterandintenserivalrybetweentwoindividuals,whereone 1.0
musthaveanadvantageintermsoftheirsocioeconomicstatusorphysicalability. Thestorymustalso
incorporateasurprisingtwistthatleadstoanunforeseenoutcome.
Table2: ExamplesofADAPTIVEDECODERseq PredictedTemperatures(œÑ)onUltraFeedback. Hereweshowexamples
of UltraFeedback test prompts where the ADAPTIVEDECODERseq model predicted œÑ ‚àà {0.0,1.0}. That is, our model
predictsthetoppromptrequiresafactualdeterministicresponse(œÑ =0.0),whilethebottompromptrequiresacreative,
stochasticresponse(œÑ =1.0). MoreexamplesareshowninAppendixTable13.
1,000 training samples from GSM8K, and 1,000 training aremostlyinbetweenforgeneralinstructionprompts(Ultra-
samplesfromtheStoriesdataset,andcallitthe‚ÄúUltraMath- Feedback). Thelatterhasthebiggesttemperaturevariance,
Stories‚Äùdataset. Wetrainasinglemodelonthepreference whichmakessensegiventhatithasmorediverseprompts.
pairs from this dataset to test if Adaptive Decoding can
Sequence-levelvs.Token-levelADAPTIVEDECODER. In
adapttoeachsubtask.Weevaluateoneachsubtask‚Äôstestset
individuallyandtaketheaveragewinrateacrossthe3test
thistask, ADAPTIVEDECODERseq showedastrongerper-
sets. Furtherdetailsofeachsubtaskincludedinthisdataset,
formancecomparedtoADAPTIVEDECODERtok asshown
inFigure3,eventhoughbothoutperformfixedtemperatures.
includinghowtheLPOpairsarecreated,aredescribedin
Thereareseveralreasonswhythiscanbethecase. First,the
AppendixA. Weexperimentwithbothasequenceleveland
subtasksinUltraMathStoriesthemselvesmightnotrequire
tokenlevelADAPTIVEDECODER,andprovideeachwith6
fine-grainedtemperatureadjustment. Secondly,learninga
temperatureoptions: œÑ ‚àà{0.0,0.2,0.4,0.6,0.8,1.0}.
single temperature value per sample is much easier, thus
likelytorequirefewertrainingsamples(weonlytrainon
ADAPTIVEDECODERcanlearntousetheidealtemper- 4000samplesintotal). However,wewillexploretheadvan-
atureadaptedforeachsubtask. InFigure3,wedirectly tageofADAPTIVEDECODERtok insubsequentsections.
compare our method against fixed temperature decoding.
The winrate in each subtask is computed (shown in Ap- 4.4.ConstrainedCreativeWriting(ConstrainedStories)
pendix B) and their average is plotted. We observe the
Whengivenrigidinstructionssuchassolvingamathprob-
ADAPTIVEDECODER outperforming all of the fixed tem-
lem, themodelneedstobegreedy, butwhengivenopen-
peratures,whichindicatesthatthedecoderhaslearnedto
endedinstructionssuchaswritingacreativestory,themodel
choosean idealdecodingtemperaturesuited to eachsub-
needstobenon-greedy. However,certaininstructionscan
task. In fact, Figure 4 demonstrates this clearly with the
containbothrigidandopen-endedinstructions.Weconsider
predictedtemperaturedistributionsforeachsubtask. Asex-
theproblemofconstrainedcreativewriting,whichrequires
pected,theADAPTIVEDECODERpredictslowtemperature
the model to be both greedy and non-greedy at different
formathprompts(GSM8K),hightemperatureforcreative
tokensofasingleresponse.
writingprompts(Stories),andamixoftemperatureswhich
selpmaS
fo
tnecreP
selpmaS
fo
tnecreP
selpmaS
fo
tnecrePAdaptiveDecodingviaLatentPreferenceOptimization
FixedTemp. AdaptiveDecoder tok Adapti v eDecodertok
0.6
80
0.5
60
0.4
40
0.3
20
0.2
0
0.0 0.2 0.4 0.6 0.8 1.0 0 10 20 30 40 50
Sentence Token Index
Fixedtemperature
Figure5: ConstrainedCreativeWriting(ConstrainedStories)Results. Hereweshowaquantitativeanalysisofthe
ADAPTIVEDECODERontheconstrainedcreativewritingtask,ConstrainedStories. (left)ADAPTIVEDECODERtok winrates
vsfixedtemperatures. Thehighfixedtemperaturesperformworsebecausetheyfailtofollowtheconstraint. Fixedgreedy
decodingworkswellatfollowingtheconstraint,butADAPTIVEDECODERtok outperformsitbyusinghighertemperatures
whenpossible. (right)MeantemperaturepredictedbytheADAPTIVEDECODERtok forthefirst50tokensofeachsentence.
Thisplotconfirmsourhypothesisthatthefirsttokenofeachsentenceshouldbelowtemperatureinordertofollowthe
constraint,andallothertokensshouldbehightemperatureinordertowriteagoodstory. Theaveragetemperatureforthe
firsttokenisœÑ =0.21,andtheaveragetemperatureforallothertokensisœÑ =0.55,showingamoregreedydecodingfor
theconstraint,andlessgreedyeverywhereelse.
Accuracy‚Üë Accuracy‚Üë
DecodingMethod
(MajorityofN=8responses) (N=1response)
BestFixedTemperature 87.46 81.59
ADAPTIVEDECODERtok(œÑ ‚àà{0.0,0.4,0.8,1.0}) 87.70 80.47
ADAPTIVEDECODERtok(œÑ ‚àà{0.0,0.4,0.8,1.0,1.2}) 87.95 80.51
Table3: ADAPTIVEDECODERtok formajorityvoting(8samples)ontheGSM8Kdataset. ADAPTIVEDECODERtok
learns to assign appropriate temperatures at different parts of the generation which allows for more accurate sampled
reasoningchainswhichresultsinahigheraccuracythanusingasingletunedtemperatureforthedataset. Wealsoinclude
theaccuracyforN=1response,whichunderperformsmajorityvoting.
We construct a dataset based on the Stories dataset from lowtheconstraint,resultinginalowwinrate. Thegreedy
the previous subsection, and call it ‚ÄúConstrainedStories‚Äù. decodingperformswellasitsatisfiestheconstraintmore
SimilartotheStoriestask,wepromptthemodeltowrite often,butthestoryqualityisloweredbythelackofdiver-
a creative story of a given title, but with an extra instruc- sity. Table12showstheindividualwinratesforconstraint
tion saying that each sentence must start with a specific satisfactionandArmoscore. AsshowninFigure5(right),
substring,‚ÄúAb‚Äùinthiscase. Intuitively,onewouldexpect the ADAPTIVEDECODERtok manages to have the best of
theidealmodelshouldbegreedywhengeneratingthestart bothworlds. Theaveragetemperatureforthefirsttokenof
ofeachsentencetosatisfytheconstraint,andnon-greedy eachsentenceisœÑ =0.21,andtheaveragetemperaturefor
everywhereelseforbettercreativity. TheLPOpreference allothertokensisœÑ = 0.55. Thisshowsthatthemodelis
pairsarecreatedusingbothArmoRMscoresandconstraint mostlygreedyontheconstrainttokens(inordertogenerate
satisfaction rates. During evaluation, a higher constraint an‚ÄúAb‚Äùwordatthestartofeachsentence),andmostlynon-
satisfactionwins,buttiesarebrokenbytheArmoRMscore. greedyonallothertokens(inordertogenerateacreative
MoredetailscanbefoundinAppendixSectionA.5. andcoherentstory). AppendixFigure6showsanexample
ADAPTIVEDECODERtokcanlearntodynamicallyadjust o af teth ste sA amD pA lP eT pI rV oE mD pE tC inO tD hE isR tt ao sk kp .redictedtemperaturesfor
thetemperatureatthetoken-level. Figure5(left)shows
thewinratesofADAPTIVEDECODERtok comparedtofixed
4.5.MajorityVoting
temperature decoding. The ADAPTIVEDECODERtok al-
ways outperforms fixed temperature decoding. When a Wangetal.(2022)proposeself-consistency,amethodtoim-
highfixedtemperatureisusedonalltokens,itfailstofol- provethereliabilityofanswersgeneratedbylanguagemod-
)%(setarniW
erutarepmeT
naeMAdaptiveDecodingviaLatentPreferenceOptimization
FixedTemperature ADAPTIVEDECODERseq
L L
œÑ =0 œÑ =0.6 œÑ =1.0 LPO LPO L
(Equation10) (Equation11) NLL
81.59 79.15 78.32 81.59 81.59 78.92
Table4: GSM8KAccuracycomparingdifferentlossfunctionsfortrainingasequence-levalADAPTIVEDECODER
(AD ). WecomparetwodifferentL lossfunctions,asoutlinedinSection3.3,aswellasnegativeloglikelihoodloss,
seq LPO
L ,trainedonthechosenresponsesfromthepreferencepairs.
NLL
TemperatureSelection
Greedy(Equation4) Sample(Equation5)
œÑ =0.0 53.10 52.80
œÑ =0.2 53.35 53.15
Fixed œÑ =0.4 50.80 51.75
Temp. œÑ =0.6 52.15 52.50
œÑ =0.8 52.78 53.65
œÑ =1.0 54.89 53.95
Table5: ADAPTIVEDECODERTemperatureSelectionMethodsonUltraFeedback. TheADAPTIVEDECODERoutputsa
distributionovertemperaturevaluesœÑ,sowecaneithersampleœÑ fromthatdistributionorgreedilyselectthehighestprobabil-
ityœÑ. Hereweshowwinratesagainstthefixedtemperaturedecodingintheleftcolumn,usingtheADAPTIVEDECODERseq
modeltrainedonUltraMathStories(Section4.3). Allthewinratesareabove50%,whichmeanstheADAPTIVEDECODER
alwaysoutperformsthefixedtemperature. Also,wedonotobserveasignificantdifferencebetweenthetwotemperature
selectionmethods.
elsbygeneratingN multipleindependentreasoningchains ity voting. However, the ADAPTIVEDECODERtok learns
andselectingtheanswerthatappearsmostfrequently.When toassigntemperaturesappropriatelyandweobservethat
performingmajorityvoting,severalreasoningchainscanbe the higher temperature options help the model‚Äôs perfor-
sampled(usingahighertemperature)fromthemodel,after mance, as shown in Table 3. This demonstrates that the
whichthemostfrequentanswerischosen. Whilegreedy ADAPTIVEDECODERtok trained by LPO can result in a
decodingisempiricallyfoundtobeoptimalforsinglere- modelthatcanperformwellonbothsingleresponses(see
sponseaccuracy,obviouslyself-consistencycannotbenefit Table4forsingleresponseaccuracy)andmajorityvoting
fromitasallofthegeneratedresponseswillbeidentical. setupsatthesametime.
Therefore,itisimportanttofindtheidealtemperaturesto
useforgeneratingtheN differentresponsesperprompt. 4.6.Ablations
Specifically,weexplorewhethertheADAPTIVEDECODER 4.6.1.LPOLOSSTYPE
can learn to ascertain which parts of the reasoning chain
AsdescribedinSection3.3,thereareseveralvariationsof
shouldbesampledmorestochasticallyandwhichshouldbe
theLPOlossthatwecanuse. Herewecomparetwodif-
decodedgreedily. WefirsttrainaADAPTIVEDECODERtok
ferent LPO variants on the GSM8K math reasoning task:
modelonGSM8Ktooptimizethesingleresponseaccuracy.
temperaturesastokens(separate)(Equation10)andtemper-
WedothisbysamplingN =8responsesandcreatingpref-
aturesaslatents(Equation11). Table4showsthewinrates
erencepairsusingtheground-truthanswersprovided,and
applyLPO(Equation10). Thenweevaluatethismodelina
oftheADAPTIVEDECODERseq modeltrainedwiththetwo
different losses on the GSM8K math reasoning task. We
majorityvotingsettingandcomparetothebestfixedtemper-
see that both losses work well and match the greedy de-
aturedecoding(tunedonthetrainset). Weexperimentwith
coding(optimal)baseline. Wealsocomparetoanegative
twocategoriesofpossibletemperatures: {0.0,0.4,0.8,1.0}
log-likelihoodloss(L ),whichistrainedononlythecho-
and{0.0,0.4,0.8,1.0,1.2}. NLL
senresponses. ThisperformsworsethanbothLPOlosses
Generally, we find that increasing the fixed temperature since it tends to predict the most frequently chosen tem-
above 1.0 can cause the LLM‚Äôs generation to start to de- perature,whichisnotnecessarilythebesttemperature,as
grade and this can also hurt the performance of major- demonstrated in the training sample distribution plots inAdaptiveDecodingviaLatentPreferenceOptimization
Appendix Figure7. References
JoshAchiam,StevenAdler,SandhiniAgarwal,LamaAh-
4.6.2.ADAPTIVEDECODERTEMPERATURESELECTION
mad, Ilge Akkaya, Florencia Leoni Aleman, Diogo
TheobjectiveoftheADAPTIVEDECODERistopredictthe Almeida, Janko Altenschmidt, Sam Altman, Shyamal
besttemperaturetouseforaparticularsampleortoken.This Anadkat, et al. Gpt-4 technical report. arXiv preprint
temperatureisthenusedtoscalethetokenprobabilitiesfor arXiv:2303.08774,2023.
samplingatoken. However,theLPOtraininglearnsadistri-
David H Ackley, Geoffrey E Hinton, and Terrence J Se-
butionoftemperatures,notjustasinglevalue. Therefore,
jnowski. Alearningalgorithmforboltzmannmachines.
atinferencetimewecaneithergreedilyselectthetoptem-
Cognitivescience,9(1):147‚Äì169,1985.
peratureasinEquation4,orsamplefromthetemperature
distribution following Equation 5, aswe do forsampling Sourya Basu, Govardana Sachitanandam Ramachandran,
from the token distribution. Here we compare these two Nitish Shirish Keskar, and Lav R. Varshney. Mirostat:
differentwaysofselectingtemperatures. Table5showsthe Aneuraltextdecodingalgorithmthatdirectlycontrols
winratesonUltraFeedbackoftheADAPTIVEDECODERseq perplexity,2020.
modeltrainedonUltraMathStories(Section4.3).Bothmeth-
odsoutperformallfixedtemperaturedecodingtemperatures, KarlCobbe,VineetKosaraju,MohammadBavarian,Mark
andweseeamarginaldifferencebetweenthetwosampling Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert,
methods. Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al.
Training verifiers to solve math word problems. arXiv
preprintarXiv:2110.14168,2021.
5.Conclusion
GanquCui,LifanYuan, NingDing,GuanmingYao, Wei
As large language models continue to advance, users are
Zhu,YuanNi,GuotongXie,ZhiyuanLiu,andMaosong
stillleftwithimportanthyperparameterchoiceswhenwork-
Sun. Ultrafeedback: Boosting language models with
ingwiththemonenduseapplications. Notably,decoding
high-qualityfeedback. arXivpreprintarXiv:2310.01377,
temperatureisacrucialparameteratinferencetimefordeter-
2023.
mininghowmuchthemodelshouldexplore(generatenovel,
creativetext)vsexploit(generateconventional,factualtext). AbhimanyuDubey,AbhinavJauhri,AbhinavPandey,Ab-
hishekKadian,AhmadAl-Dahle,AieshaLetman,Akhil
Inthispaper,weintroducetheADAPTIVEDECODER,aneu-
Mathur,AlanSchelten,AmyYang,AngelaFan,etal.The
ral module that sits on top of a pretrained LLM to pre-
llama3herdofmodels.arXivpreprintarXiv:2407.21783,
dict what temperature should be used to sample the next
2024.
token. The ADAPTIVEDECODER is trained with our pro-
posedLatentPreferenceOptimization(LPO)method,which AngelaFan,MikeLewis,andYannDauphin. Hierarchical
canoptimizediscretelatentvariablessuchastemperature. neuralstorygeneration.arXivpreprintarXiv:1805.04833,
Wefindthatacrossavarietyoftasks, ourmethodoutper- 2018.
formsallfixedtemperaturevalues,eliminatingtheneedfor
users to select a fixed temperature in advance, or tuning MatthewFinlayson,JohnHewitt,AlexanderKoller,Swabha
therighttemperatureforeachtaskatevaluationtime. Our Swayamdipta,andAshishSabharwal.Closingthecurious
experiments demonstrate the effectiveness of training an caseofneuraltextdegeneration,2023.
ADAPTIVEDECODERmoduleontopofanexisting(frozen)
MarkusFreitagandYaserAl-Onaizan. Beamsearchstrate-
languagemodel,makingourapproachusableandsimple
gies for neural machine translation. arXiv preprint
toemploywithexistinglanguagemodels,aswellasbeing
arXiv:1702.01806,2017.
usedwhendevelopingnewones.
DanHendrycksandKevinGimpel. Gaussianerrorlinear
Finally,AdaptiveDecodingisageneralapproach,andthe
units(gelus). arXivpreprintarXiv:1606.08415,2016.
ADAPTIVEDECODERcouldbepotentiallyusedtoconvert
other hyperparameters than temperature effectively into AriHoltzman,JanBuys,LiDu,MaxwellForbes,andYejin
training parameters. LPO is also a general tool to train Choi. Thecuriouscaseofneuraltextdegeneration. arXiv
discrete latent variables that could similarly be used for preprintarXiv:1904.09751,2019.
otherhyperparameterssuchastop-portop-k. Ourapproach
alsoopensthepossibilityofdefiningandexploringlarger Robert Kirk, Ishita Mediratta, Christoforos Nalmpantis,
numbersofdecodinghyperparameters,astheynowcanbe Jelena Luketina, Eric Hambro, Edward Grefenstette,
trainedratherthanbemanuallyset. and Roberta Raileanu. Understanding the effects of
rlhfonllmgeneralisationanddiversity. arXivpreprint
arXiv:2310.06452,2023.AdaptiveDecodingviaLatentPreferenceOptimization
TakeshiKojima,ShixiangShaneGu,MachelReid,Yutaka Chain-of-thought prompting elicits reasoning in large
Matsuo,andYusukeIwasawa. Largelanguagemodels languagemodels. Advancesinneuralinformationpro-
arezero-shotreasoners. Advancesinneuralinformation cessingsystems,35:24824‚Äì24837,2022.
processingsystems,35:22199‚Äì22213,2022.
Sean Welleck, Ilia Kulikov, Stephen Roller, Emily Di-
AviralKumarandSunitaSarawagi. Calibrationofencoder nan, Kyunghyun Cho, and Jason Weston. Neural text
decoder models for neural machine translation. arXiv generation with unlikelihood training. arXiv preprint
preprintarXiv:1903.00802,2019. arXiv:1908.04319,2019.
YiweiLi,FeiMi,YitongLi,YashengWang,BinSun,Shaox- JohnathanXie,AnnieSChen,YoonhoLee,EricMitchell,
iong Feng, and Kan Li. Dynamic stochastic decoding and Chelsea Finn. Calibrating language models
strategy for open-domain dialogue generation. arXiv with adaptive temperature scaling. arXiv preprint
preprintarXiv:2406.07850,2024. arXiv:2409.19817,2024.
YuMeng,MengzhouXia,andDanqiChen. Simpo: Sim- Jing Xu, Andrew Lee, Sainbayar Sukhbaatar, and Jason
plepreferenceoptimizationwithareference-freereward. Weston. Somethingsaremorecringethanothers: Pref-
arXivpreprintarXiv:2405.14734,2024. erenceoptimizationwiththepairwisecringeloss. arXiv
preprintarXiv:2312.16682,2023.
Stephen Merity, Caiming Xiong, James Bradbury, and
RichardSocher. Pointersentinelmixturemodels. arXiv Hugh Zhang, Daniel Duckworth, Daphne Ippolito, and
preprintarXiv:1609.07843,2016. Arvind Neelakantan. Trading off diversity and qual-
ity in natural language generation. arXiv preprint
OpenAI. Gpt-4technicalreport,2023. arXiv:2004.10450,2020.
LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,Car- Shimao Zhang, Yu Bao, and Shujian Huang. Edt: Im-
rollWainwright,PamelaMishkin,ChongZhang,Sand- provinglargelanguagemodels‚Äôgenerationbyentropy-
hiniAgarwal,KatarinaSlama,AlexRay,etal. Training based dynamic temperature sampling. arXiv preprint
languagemodelstofollowinstructionswithhumanfeed- arXiv:2403.14541,2024.
back.Advancesinneuralinformationprocessingsystems,
35:27730‚Äì27744,2022. WenhongZhu,HongkunHao,ZhiweiHe,YimingAi,and
Rui Wang. Improving open-ended text generation via
Rafael Rafailov, Archit Sharma, Eric Mitchell, Christo- adaptive decoding. arXiv preprint arXiv:2402.18223,
pherDManning,StefanoErmon,andChelseaFinn. Di- 2024.
rect preference optimization: Your language model is
secretlyarewardmodel. AdvancesinNeuralInformation YuqiZhu,JiaLi,GeLi,YunFeiZhao,JiaLi,ZhiJin,and
ProcessingSystems,36,2024. HongMei. Improvingcodegenerationbydynamictem-
peraturesampling. arXive-prints,pp.arXiv‚Äì2309,2023.
ChufanShi,HaoranYang,DengCai,ZhisongZhang,Yifan
Wang, Yujiu Yang, and Wai Lam. A thorough exami- Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B
nation of decoding methods in the era of llms. arXiv Brown, Alec Radford, Dario Amodei, Paul Christiano,
preprintarXiv:2402.06925,2024. andGeoffreyIrving. Fine-tuninglanguagemodelsfrom
human preferences. arXiv preprint arXiv:1909.08593,
AVaswani. Attentionisallyouneed. AdvancesinNeural 2019.
InformationProcessingSystems,2017.
HaoxiangWang,WeiXiong,TengyangXie,HanZhao,and
TongZhang.Interpretablepreferencesviamulti-objective
rewardmodelingandmixture-of-experts. arXivpreprint
arXiv:2406.12845,2024.
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,
Ed Chi, Sharan Narang, Aakanksha Chowdhery, and
Denny Zhou. Self-consistency improves chain of
thought reasoning in language models. arXiv preprint
arXiv:2203.11171,2022.
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
Bosma,FeiXia,EdChi,QuocVLe,DennyZhou,etal.AdaptiveDecodingviaLatentPreferenceOptimization
A.TaskDetails A.4.CreativeWriting(Stories)
A.1.N-gramRepeat For this task, we consider a simple creative writing task
where the model is prompted to write a short story of a
WeusetheWikitext-2benchmark.Weusea50tokensprefix
giventitle. Eachpromptinthisdatasethasthefollowing
as the prompt, allowing the LLM to continue generating.
structure: ‚ÄúWriteashort200wordstorywiththefollowing
AftergeneratingN =10completionsperprompt,werank
title.\n\nTitle:[TITLE]‚Äù. We call this the ‚ÄúStories‚Äù task.
thesecompletionsby3-gram-repeats. Wethenconstructed
Each of the 1,000 training and test titles were generated
LPOpreferencepairswherethesequenceswiththelowest
withLlama3.0-70B.
andhighest3-gram-repeatsareselectedasthe‚Äòchosen‚Äôand
‚Äòrejected‚Äôsequencesrespectively. WethenuseLPOtotrain WeusethesamemethodasUltraFeedbackforconstructing
theADAPTIVEDECODERtok model. trainingpreferencepairsandevaluating.
A.2.Math(GSM8K) A.5.ConstrainedCreativeWriting(ConstrainedStories)
Forthistask,weusetheGSM8Kmathreasoningdataset Eachsamplehasthefollowingstructure: ‚ÄúWriteacreative
(Cobbeetal.,2021). Weusechain-of-thoughtprompting andcoherentstorywiththefollowingtitle. Youmustbegin
(Weietal.,2022),wherethemodelisinstructedtoexplain eachsentencewithawordthatstartswith‚ÄúAb‚Äù.\n\nTitle:
itsreasoningbeforewritingafinalanswer. Wetrainona [TITLE]‚Äù.
random1,000samplesubsetofthefull7,473samples. We
The preference pairs are generated as follows. For each
evaluateonthefull1,319testsamples.
prompt, we first generate N = 16 response samples. To
TheLPOpreferencepairsforthisdatasetareconstructed selectthechosenresponse,weconsiderthetop4ArmoRM
bygeneratingN =16responsesamplesperprompt,where scored responses, and then take the one of those that sat-
each generation samples a temperature from the original isfytheconstraintthebest(hasthehighestpercentageof
ADAPTIVEDECODER distribution(roughlyuniform), and sentencesthatstartwith‚ÄúAb‚Äù). Similarly,fortherejected
thenselectingachosenandrejectedsamplebasedonthe response, we consider the bottom 4 ArmoRM scored re-
oracleGSM8Ktraininglabels. sponses and take the one of those that least satisfies the
constraint.
We evaluate the performance of ADAPTIVEDECODERseq
comparedto6differentfixedtemperaturedecodings: œÑ = Winratesarecomputedinthefollowingway. Ifaresponse
{0.0,0.2,0.4,0.6,0.8,1.0}. We measure the winrate of satisfies the constraint better (i.e., a higher percentage of
each test sample using the ground truth labels from the ‚ÄúAb‚Äùstartsentences),thenitwins. Ifthereisatieandboth
GSM8Ktestset. Thewinrateiscomputedbycomparing responseshavethesameconstraintsatisfactionrate, then
thecorrectnessofeachmethod‚Äôsresponse. Ifonemethod itisdecidedbywhicheverresponsehasahigherArmoRM
gets it correct and the other does not, the correct method score,wheretheArmorewardmodelisrunusingtheprompt
getsawarded1point. Ifbothmethodsgeneratedacorrect withouttheconstraint(i.e. ‚ÄúWriteacreativeandcoherent
orincorrectresponse,theneachmethodgets0.5points. storywiththefollowingtitle.\n\nTitle: [TITLE]‚Äù).
A.3.GeneralInstructionFollowing(UltraFeedback) B. ADAPTIVEDECODERseq WinrateValues
ThefullUltraFeedbackdatasetcontains64ksamples. We Tables 6, 7 and, 8 show ADAPTIVEDECODERseq winrate
train on a random subset of 2,000 samples, and test on valuesoneachofthe3UltraMathStoriessubtasks.
anotherrandomsubsetof1,000samples.
The training preference pairs for this dataset are con- C. ADAPTIVEDECODERtok WinrateValues
structedbygeneratingN =16samplesperprompt,where
each generation samples a temperature from the original
Tables9,10and,11showADAPTIVEDECODERseq winrate
valuesoneachofthe3UltraMathStoriessubtasks.
ADAPTIVEDECODER distribution(roughlyuniform), and
selectingachosenandrejectedsampleusingthebestand
worstArmorewardmodel(ArmoRM)(Wangetal.,2024) C.1.ConstrainedCreativeStoryWritingExample
scores,respectively. Temperatures
WemeasurethewinrateofADAPTIVEDECODERseq gener- Figure 6 shows an example of the predicted temperature
ationscomparedtoeachthe6fixedtemperature(œÑ={0.0, values for the ADAPTIVEDECODERtok model trained on
0.2,0.4,0.6,0.8,1.0})generationsusingArmoRMscores. constrainedcreativestorygeneration.AdaptiveDecodingviaLatentPreferenceOptimization
FixedTemp
ADAPTIVEDECODERseq FixedTemp
Winrate Winrate
œÑ =0.0 53.10 46.90
œÑ =0.2 53.35 46.65
œÑ =0.4 50.80 49.20
œÑ =0.6 52.15 47.85
œÑ =0.8 52.78 47.22
œÑ =1.0 54.89 45.11
Table6: ADAPTIVEDECODERseq vsFixedTemperaturesWinratesontheUltraFeedbackTask.
FixedTemp
ADAPTIVEDECODERseq FixedTemp
Winrate Winrate
œÑ =0.0 58.75 41.25
œÑ =0.2 57.25 42.75
œÑ =0.4 57.05 42.95
œÑ =0.6 56.65 43.35
œÑ =0.8 54.55 45.45
œÑ =1.0 52.10 47.90
Table7: ADAPTIVEDECODERseq vsFixedTemperaturesWinratesontheStoriesTask.
FixedTemp
ADAPTIVEDECODERseq FixedTemp
Winrate Winrate
œÑ =0.0 50.68 49.32
œÑ =0.2 51.10 48.90
œÑ =0.4 51.14 48.86
œÑ =0.6 51.40 48.60
œÑ =0.8 51.42 48.58
œÑ =1.0 51.82 48.18
Table8: ADAPTIVEDECODERseq vsFixedTemperaturesWinratesontheGSM8KTask.
FixedTemp
ADAPTIVEDECODERtok FixedTemp
Winrate Winrate
œÑ =0.0 49.60 50.40
œÑ =0.2 50.70 49.30
œÑ =0.4 48.75 51.25
œÑ =0.6 49.60 50.40
œÑ =0.8 49.25 50.75
œÑ =1.0 52.75 47.25
Table9: ADAPTIVEDECODERtok vsFixedTemperaturesWinratesontheUltraFeedbackTask.AdaptiveDecodingviaLatentPreferenceOptimization
FixedTemp
ADAPTIVEDECODERtok FixedTemp
Winrate Winrate
œÑ =0.0 54.40 45.60
œÑ =0.2 53.40 46.60
œÑ =0.4 54.20 45.80
œÑ =0.6 52.30 47.70
œÑ =0.8 51.10 48.90
œÑ =1.0 47.25 52.75
Table10: ADAPTIVEDECODERtok vsFixedTemperaturesWinratesontheStoriesTask.
FixedTemp
ADAPTIVEDECODERtok FixedTemp
Winrate Winrate
œÑ =0.0 49.66 50.34
œÑ =0.2 50.08 49.92
œÑ =0.4 50.11 49.89
œÑ =0.6 50.38 49.62
œÑ =0.8 50.49 49.51
œÑ =1.0 51.55 48.45
Table11: ADAPTIVEDECODERtok vsFixedTemperaturesWinratesontheGSM8KTask.
FixedTemp
ADAPTIVEDECODERtok ADAPTIVEDECODERtok ADAPTIVEDECODERtok
ConstraintWinrate ArmoRMWinrate AvgWinrate
œÑ =0.0 50.95 52.55 51.75
œÑ =0.2 53.70 49.50 51.60
œÑ =0.4 58.05 48.25 53.15
œÑ =0.6 68.05 41.05 54.55
œÑ =0.8 77.85 36.45 57.15
œÑ =1.0 87.80 31.50 59.65
Table12: ADAPTIVEDECODERtok ConstrainedCreativeWritingIndividualWinrates. Hereweshowtheindividual
winratesoftheADAPTIVEDECODERtok forbothconstraintfollowingandArmoRMscore. TheADAPTIVEDECODERtok
learnstofollowtheconstraintbetterthanallfixedtemperatures,butaswecomparetohigherfixedtemperatures,thestory
winrategoesdownbecauseitfollowstheconstraintbetter.AdaptiveDecodingviaLatentPreferenceOptimization
Color Key: ùúè=0.0, ùúè=0.2, ùúè=0.4, ùúè=0.6, ùúè=0.8, ùúè=1.0
Figure6: ADAPTIVEDECODERtok predictedtemperaturesforConstrainedCreativeStoryWriting. Wedemonstrate
anexampleofADAPTIVEDECODERtok predictedtemperatures(œÑ)ontheconstrainedcreativestorywritingtaskforthe
prompt‚ÄúWriteacreativeandcoherentstorywiththefollowingtitle. Youmustbegineachsentencewithawordthatstarts
with‚ÄúAb‚Äù.\n\nTitle: TheVillageoftheBlindfolded‚Äù. Wecanseethatthemodelismoregreedy(œÑ closeto0.0)when
generatingtheconstrainttokens(Allsentencesmustbeginwithwordsthatstartwith‚ÄúAb‚Äù),andlessgreedy(œÑ closeto1.0)
onallothertokens.
GSM8K UltraFeedback Stories
14
14 Chosen Chosen 12 Chosen
12 Rejected 12 Rejected Rejected
10
10 10
8
8 8
6
6 6
4 4 4
2 2 2
0 0 0
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
Temperature ( ) Temperature ( ) Temperature ( )
Figure7: ADAPTIVEDECODERseq TrainingPreferenceDistributions. Hereweshowthepercentageofsamplesinthe
trainingsetthatarechosenorrejectedforeachofthe6differenttemperateure(œÑ)values. TheLPOlossusesbothchosen
andrejectedresponses,andtheratioofchosentorejectedisanimportantfactorforlearningtherighttemperature. Avanilla
negativelog-likelihoodlossonlyusesthechosenresponses,whichleadstosuboptimaltemperaturepredictionssincehigh
temperaturevaluesarethemostchosenregardlessofthetask.
selpmas
fo
tnecreP
selpmas
fo
tnecreP
selpmas
fo
tnecrePAdaptiveDecodingviaLatentPreferenceOptimization
PredictedœÑ =0.0
Inthistask,givenasentenceintheEnglishlanguage,yourtaskistoconvertitintotheThailanguage.
Problem:Thesecondaryprincipals‚Äôassociationhead, GrahamYoung, said: T¬®heNCEAsystemputpressureon
schoolstoaccumulatecredits-andtheeasiestwaytodothatwastoencouragestudentsintointernallyassessedunit
standards.
Solution:
Youaregivenamathwordproblemandyouaresupposedtoapplymultiplemathematicaloperatorslikeaddition,
subtraction,multiplication,ordivisiononthenumbersembeddedinthetexttoanswerthefollowingquestionand
thenonlyreportthefinalnumericalanswer.
Input: ConsiderInput: debbymakes67pancakes. sheaddsblueberriesto20ofthemandbananasto24ofthem.
therestareplain. howmanyplainpancakesarethere?
Youhavebeentaskedwitharrangingagroupoftravelers,eachwithdifferentpreferencesandneeds,ontovarious
modesoftransportation. Therearefourmodesoftransportationavailable: A,B,C,andD.Eachmodehasitsown
uniquefeaturesandlimitations. Thetravelersandtheirpreferencesareasfollows:
1. Alice: IsafraidofflyingandpreferstotakemodeCorD
2. Bob: CanonlytravelbymodeAduetomotionsickness
3. Charlie: WantstotakemodeBbecauseithastheshortesttraveltime
4. Dave: NeedstotakemodeDbecausehehasalotofluggage
5. Ellie: WantstotakemodeAbecausesheenjoysthescenicroute
Yourtaskistoassigneachtravelertothemodeoftransportationthatbestsuitstheirneedsandpreferences. Keep
inmindthateachmodeoftransportationcanonlyaccommodateacertainnumberofpeople, andsomemodes
mayhavealreadyreachedtheircapacity. Canyousolvethispuzzleandsuccessfullygroupthetravelersontotheir
preferredmodesoftransportation?‚Äù
PredictedœÑ =1.0
Writea70,000wordfantasynovelaboutahiddenworldofmagicandmythicalcreatures. Themaincharactermust
beahumanwhodiscoversthisworldandbecomesinvolvedinaconflictbetweenthemagicalcreatures. Thenovel
shouldhaveafast-pacedplotwithplentyofactionandsuspense. Thestyleshouldbedescriptiveandimmersive,
withdetaileddescriptionsofthemagicalworldanditsinhabitants. Thenovelshouldalsoexplorethemessuchas
thenatureofpowerandtheimportanceofloyaltyandfriendship.
Writemea1000wordghoststoryinacampfiresetting
WriteastoryaboutEgoMust,aprominentinnovatorwithtechnologywholeverageshisvastwealthtocommunicate
hisviews. However,despitebeingexceptionallysmartheseemstonotunderstandthebasicswhenitcomestothe
‚Äôusandthem‚Äôproblemthatisattherootofalotofhumanconflict.
Table13:ExamplesofADAPTIVEDECODERseqPredictedTemperatures(œÑ)onUltraFeedback.Hereweshowexamples
ofUltraFeedbacktestpromptswherethe ADAPTIVEDECODERseq modelpredictedœÑ ‚àà {0.0,1.0}. Wecanseethatthe
œÑ =0.0promptsrequirefactual,deterministicresponses,andtheœÑ =1.0promptsrequirecreative,stochasticresponses.
ThisshowsgeneralizationoutsideoftheGSM8KandStoriessubtaskstospecificpromptswithinUltraFeedback.