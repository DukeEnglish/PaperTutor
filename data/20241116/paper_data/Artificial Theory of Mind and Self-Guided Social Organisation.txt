Artificial Theory of Mind and Self-Guided Social Organisation
Michael S. Harr´e, Jaime Ruiz-Serra, Catherine Drysdale
Oneofthechallengesartificialintelligence(AI)facesishowacollectionofagentscoordinatetheirbehaviourtoachieve
goals that are not reachable by any single agent [1, 2]. In a recent article by Ozmen et al [3] this was framed as one
of six grand challenges: That AI needs to respect human cognitive processes at the human-AI interaction frontier. We
suggestthatthisextendstothe AI-AIfrontierandthatitshouldalsoreflecthumanpsychology,asitistheonlysuccessful
frameworkwehavefromwhichtobuildout. Inthisextendedabstractwefirstmakethecaseforcollectiveintelligenceina
generalsetting,drawingonrecentworkfromsingleneuroncomplexityinneuralnetworksandantnetworkadaptabilityin
antcolonies. Fromtherewe introducehowspeciesrelateto oneanotherinanecologicalnetworkvianiche selection, niche
choice, and niche conformity with the aim of forming an analogy with human social network development as new agents
join together and coordinate. From there we show how our social structures are influenced by our neuro-physiology, our
psychology,andour language. This emphasises how individual people within a socialnetwork influence the structure and
performance of that network in complex tasks, and that cognitive faculties such as Theory of Mind play a central role.
We finishbydiscussingthe currentstateofthe artinAIandwherethereis potentialforfurther developmentofasocially
embodied collective artificial intelligence that is capable of guiding its own social structures.
Biological agents are composed of sub-units such as organs, cells, and molecular networks [4], in which, for example,
individual neurons display computational intelligence, or “competencies”, that can scale freely [5]. Beniaguev et al.[6]
demonstrated that a single cortical neuron requires five to eight layers in a deep neural network to approximate its
input-output mapping, and so we may conceptualise a neuron as an artificial agent with complex computational abilities
that adapts its connections to other agents. Similarly, ant colonies have conserved social structures and division of labor
across species separated by over 100 million years of evolution [7], with leadership roles in individual ants enhancing
collective performance [8]. In response to pathogenic threats, ants adapt by reorganizing their social behaviors [9] and
modifyingtheirneststoslowdiseasespread[10]. Whileneuralnetworksexhibit“solidbrain”connectivity(agent-to-agent
connectivity is rigid in time) and ant colonies demonstrate “liquid brain” dynamics [11] (agent-to-agent interactions are
fluid in time), both systems continuously integrate information and adjust their connectivity for the collective benefit.
Therearehoweverdifferencesinhowfreelynewagentsconnectinthesetwomodelsystems. Theadultbrainhaslimited
capacityforneurogenesissothatrecruitment,placement,andintegrationofnewcellsplaysarelativelysmallroleinadult
mammals. But in liquid brains new agents can freely join collectives and contribute to the collective outcomes of joint
actions. The process by which this occurs in ecologicalnetwork is detailed in [12], where the interaction between a single
plant, for example, and its ecological environment results in individualised niches via three main processes: niche choice,
niche conformance, and niche construction. Niche choice occurs when an individual selects environmental conditions
that align with its phenotype, while niche conformance involves adjusting its phenotype to suit the environment. Niche
construction is the modification of the environment to meet individual needs, which may also impact other species [13].
These processes affect both individual, improving the match between the individual and its ecological network, thereby
improvingtheiroverallfitness. Effectivenicherealisationreliesoncommunicationbetweenencoders-sendersandreceivers-
decoders using so-called info-chemicals as the signalling mechanism. In sum, interactions between individual plants and
animals, communicated over information carrying channels, shape network relations at all levels in ecological networks.
This is also the case in the context of human social networks, where, as we argue later, Theory of Mind (ToM) has a
key role to play. In his review of Darwin’s strange inversion of reasoning, Dennet [14] opens with the following:
Darwin’s theory of evolution by natural selection unifies the world of physics with the world of meaning and
purpose by proposing a deeply counterintuitive “inversion of reasoning” (according to a 19th century critic):
“to make a perfect and beautiful machine, it is not requisite to know how to make it” [15].
Here we suggest that this was inverted again by the evolution of our very human capacity to be consciously aware of
ourselves and our social and cultural constructs, and to purposefully manipulate them to our collective benefit. Take this
observation about manipulating inter-cellular communication by Watson and Levin [16]:
This framework [of collective cellular intelligence] makes a strong prediction: if intercellular signalling (not
genes) is the cognitive medium of a morphogenetic individual, it should be possible to exploit the tools of
behavioural and neuro-science and learn to read, interpret and re-write its information content in a way that
allows predictive control over its behaviour (in this case, growth and form) without genetic changes.
1
4202
voN
41
]AM.sc[
1v96190.1142:viXraA counter question then arises: How do humans read, interpret, and re-write our inter-personal information content in
order to exert predictive control over a social group? Similar to how a scientist external to a cell collective manipulates
inter-cellular signaling to control collective outcomes, individuals internal to a human collective can influence inter-
personal behaviors to (re)shape social structures in order to alter group outcomes. In both cases, an agent with a goal-
directedpsychologymanipulatesinter-agentrelationships—whetherinter-cellularorinter-personal—tocontrolhigher-level
outcomes, be it at the organism or societal scale. And so, as new people join a social group and just as new species form
niches,ratherthanintegratinganewpersonbasedonmechanismssuchasrandomconnectivityorrich-get-richerprocesses,
a dynamic integration occurs whereby the networked agents and the prospective agent selectively adjust relationships to
accommodate (orreject) the newcomer. This requirescomplex psychologicalabilities in orderto do it at the time scale of
the phenotype, ratherthan at the evolutionarytime-scale, which we addresslater in this work. It is achievedvia a highly
evolved set of cognitive tools that humans achieve this, as we discuss next.
ToM is the ability to mentally represent the internal states of another person [17] and a surprising connection exists
between the development of ToM and language. The representational view suggests that both children [18] and adults
use specific grammaticalstructures to represent complex events and reasonfrom them [19]. These complement structures
are an example of language-as-cognitivetool that has special utility in representing the mental states of other people, for
example they allow for the expression of mistakes, lies, or false beliefs. Complement structures are strong predictors of
children’s false belief understanding (a canonicaltest of ToM) in longitudinal studies, and training in complement syntax
has been shown to improve children’s false belief reasoning. It is interesting to note that in developmental learning there
is a stronger effect from language to ToM ability than vice versa [20].
Language and ToM also strongly interact with our causal reasoning in social settings. Lombard and G¨ardenfors [21]
put forward three hypotheses: (1) ToM is a crucial component of causal cognition; (2) The more sophisticated causal
cognition becomes, the more it relies on ToM; and (3) The evolution of causal cognition increasingly depends on mental
representations of hidden variables. The aspect we wish to focus on here is the causal modelling. At the individual level,
recent workby Momennejad [22] reviewedneuro-imagingevidence for people neurologicallyencoding their socialnetwork
topologies and the sharing of these encodings across a social group. This was also demonstrated in the work of Lau et
al. [23] showing that people are able to integrate information about how agents relate to one another in addition to how
theyrelatetooneselfinordertoinfersocialgroupstructures. Thisallowsagentstohaveacollectivecausalunderstanding
of how individuals socially interact with one another. Finally, there is also evidence for improved collective intelligence
when individuals with higher competencies in ToM are present in a social setting [24]. From this we conclude that
language, a shared collective understanding of social causal relationships, and our ToM are part of a highly integrated
cognitive toolbox that we have developed to understand how we collectively fit together to improve our coordination
towards collective goals. We emphasise that the collective goals are also psychological constructs of individuals, and in
pursuit of these goals people take advantage of their ability to read, interpret, and even re-write the social connections
between themselves and other agents in order to achieve a greater collective outcome than any single agentcould achieve
by themselves.
Where does artificial intelligence sit with respect to these cognitive tools? Inverse reinforcement learning (IRL) has
beensuggestedasamodelforToMinAI[25,26]whereanagentinfersthepreferences,e.g. rewardsasafunctionofstate,
of another agent based solely on its behaviour. Jara-Ettinger [25] discusses some key limitations of IRL but misses the
socialnetworkwithin whichthe agentsaresituatedandthe causalcognitivemodelofsocialinteractions. LargeLanguage
Models (LLMs) have also been a very popular test-bed for ToM in AI [27], however it has been shown that while LLMs
can replicate causal reasoning in some scenarios, they also have highly unpredictable failure modes [28] and there are
very few studies on causal social cognition. There is also no evidence to date that the complete suite of cognitive skills
mentioned above have been demonstrated by an LLM. In particular, there are no LLMs that are socially embodied in
a communication network whereby an individual agent articulates a collective goal, manipulates the social connections
between other agents in order to optimise the network structure in order to achieve that goal, and to do so based on a
shared representation of each agent’s causal model as even early humans could do [29]. However, there has been some
promising advances made in formally progressing the state of the art, for example in [30], where Watson et al. show that
... when self-interestedagents canmodify how they are affectedby other agents(e.g., whenthey caninfluence
whichotheragentstheyinteractwith),then,inadaptingtheseinter-agentrelationshipstomaximizetheirown
utility, they will necessarily alter them in a manner homologous with Hebbian learning. Multi-agent systems
with adaptable relationships will thereby exhibit the same system-level behaviors as neural networks under
Hebbian learning.
There are many other avenues that are being explored in the artificial context that we cannot cover in this extended
abstract,butinourtalkatGSO-2025wewillcoversomeofthemajorthemesthathavebeencontributingtothisresearch
and where their strengths and weaknesses lie. In broad strokes our presentation will take a leaf from Shevlin and Halina
and urge caution in applying rich psychologicalterms in AI [31].
2References
[1] David H Wolpert and Kagan Tumer. An introduction to collective intelligence. arXiv preprint cs/9908014, 1999.
[2] MichaelLevin.Bioelectricnetworks: thecognitiveglueenablingevolutionaryscalingfromphysiologytomind. Animal
Cognition, 26(6):1865–1891,2023.
[3] Ozlem Ozmen Garibay, Brent Winslow, Salvatore Andolina, Margherita Antona, Anja Bodenschatz, Constantinos
Coursaris, Gregory Falco, Stephen M Fiore, Ivan Garibay, Keri Grieman, et al. Six human-centered artificial intelli-
gence grand challenges. International Journal of Human–Computer Interaction, 39(3):391–437,2023.
[4] Michael Levin. The computational boundary of a “self”: developmental bioelectricity drives multicellularity and
scale-free cognition. Frontiers in psychology, 10:2688,2019.
[5] MichaelLevin.Technologicalapproachtomindeverywhere: anexperimentally-groundedframeworkforunderstanding
diverse bodies and minds. Frontiers in systems neuroscience, 16:768201,2022.
[6] DavidBeniaguev,IdanSegev,andMichaelLondon. Singlecorticalneuronsasdeepartificialneuralnetworks. Neuron,
109(17):2727–2739,2021.
[7] TomasKay,Alba Motes-Rodrigo,Arthur Royston,ThomasORichardson,Nathalie Stroeymeyt,andLaurentKeller.
Ant social network structure is highly conserved across species. Proceedings B, 291(2027):20240898,2024.
[8] Thomas O Richardson, Andrea Coti, Nathalie Stroeymeyt, and Laurent Keller. Leadership–not followership–
determines performance in ant teams. Communications biology, 4(1):535, 2021.
[9] Sebastian Stockmaier, Nathalie Stroeymeyt, Eric C Shattuck, Dana M Hawley, Lauren Ancel Meyers, and Daniel I
Bolnick. Infectious diseases and social distancing in nature. Science, 371(6533):eabc8881,2021.
[10] Luke Leckie, Mischa Sinha Andon, Katherine Bruce, and Nathalie Stroeymeyt. Architectural immunity: ants alter
their nest networks to prevent epidemics. bioRxiv, pages 2024–08,2024.
[11] Ricard Sol´e, Melanie Moses, and Stephanie Forrest. Liquid brains, solid brains, 2019.
[12] Caroline Mu¨ller, Barbara A Caspers, Ju¨rgen Gadau, and Sylvia Kaiser. The power of infochemicals in mediating
individualized niches. Trends in Ecology & Evolution, 35(11):981–989,2020.
[13] Andrew D Clark, Dominik Deffner, Kevin Laland, John Odling-Smee, and John Endler. Niche construction affects
the variability and strength of natural selection. The American Naturalist, 195(1):16–30,2020.
[14] DanielDennett. Darwin’s“strangeinversionofreasoning”.ProceedingsoftheNationalAcademyofSciences,106(sup-
plement 1):10061–10065,2009.
[15] Robert Mackenzie Beverley. The Darwinian theory of the transmutation of species. J. Nisbet, 1867.
[16] RichardWatsonandMichaelLevin. The collective intelligence ofevolutionanddevelopment. Collective Intelligence,
2(2):26339137231168355,2023.
[17] Uta Frith and Chris Frith. The social brain: allowing humans to boldly go where no other species has been.
Philosophical Transactions of the Royal Society B: Biological Sciences, 365(1537):165–176,2010.
[18] MJeffreyFarrarandLisaMaag. Earlylanguagedevelopmentandtheemergenceofatheoryofmind. First language,
22(2):197–213,2002.
[19] Jill G de Villiers. The role (s) of language in theory of mind. In The neural basis of mentalizing, pages 423–448.
Springer, 2021.
[20] Karen Milligan, Janet Wilde Astington, and Lisa Ain Dack. Language and theory of mind: Meta-analysis of the
relation between language ability and false-belief understanding. Child development, 78(2):622–646,2007.
[21] Marlize Lombard and Peter G¨ardenfors. Causal cognition and theory of mind in evolutionary cognitive archaeology.
Biological Theory, 18(4):234–252,2023.
[22] Ida Momennejad. Collective minds: social network topology shapes collective cognition. Philosophical Transactions
of the Royal Society B, 377(1843):20200315,2022.
3[23] TatianaLau,HillardTPouncy,SamuelJGershman,andMinaCikara. Discoveringsocialgroupsvialatentstructure
learning. Journal of Experimental Psychology: General, 147(12):1881,2018.
[24] Anita Williams Woolley, Christopher F Chabris, Alex Pentland, Nada Hashmi, and Thomas W Malone. Evidence
for a collective intelligence factor in the performance of human groups. science, 330(6004):686–688,2010.
[25] Julian Jara-Ettinger. Theory of mind as inverse reinforcement learning. Current Opinion in Behavioral Sciences,
29:105–110,2019.
[26] Jaime Ruiz-Serra and Michael S Harr´e. Inverse reinforcement learning as the algorithmic basis for theory of mind:
current methods and open problems. Algorithms, 16(2):68, 2023.
[27] JamesWAStrachan,DalilaAlbergo,GiuliaBorghini,OrianaPansardi,EugenioScaliti,SaurabhGupta,KratiSaxena,
AlessandroRufo, Stefano Panzeri,Guido Manzi,etal. Testing theoryofmind inlargelanguagemodels andhumans.
Nature Human Behaviour, pages 1–11, 2024.
[28] EmreKıcıman,RobertNess,AmitSharma,andChenhaoTan. Causalreasoningandlargelanguagemodels: Opening
a new frontier for causality. arXiv preprint arXiv:2305.00050, 2023.
[29] Miriam No¨el Haidle. Working-memory capacity and the evolution of modern cognitive potential: implications from
animal and early human tool use. Current anthropology, 51(S1):S149–S166,2010.
[30] Richard A Watson, Rob Mills, and Christopher L Buckley. Global adaptation in networks of selfish components:
Emergent associative memory at the system scale. Artificial Life, 17(3):147–166,2011.
[31] Henry Shevlin and Marta Halina. Apply rich psychological terms in ai with care. Nature Machine Intelligence,
1(4):165–167,2019.
4This figure "frog.jpg" is available in "jpg"(cid:10) format from:
http://arxiv.org/ps/2411.09169v1