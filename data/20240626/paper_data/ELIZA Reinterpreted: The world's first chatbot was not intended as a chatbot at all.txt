ELIZA Reinterpreted: The world’s first chatbot
was not intended as a chatbot at all
Jeff Shrager1
1Blue Dot Change and Stanford University Symbolic Systems
Program (Adjunct); jshrager@stanford.edu
April 2024
Abstract
ELIZA, often considered the world’s first chatbot, was written by
Joseph Weizenbaum in the early 1960s. Weizenbaum did not intend to
inventthechatbot,butrathertobuildaplatformforresearchintohuman-
machine conversation and the important cognitive processes of interpre-
tationandmisinterpretation. HispurposewasobscuredbyELIZA’sfame
resulting,inlargepart,from thefortuitoustimingofit’screation andit’s
escape into the wild. In this paper I provide a rich historical context for
ELIZA’screation, demonstrating thatELIZA arose from theintersection
ofsomeof thecentralthreadsin thetechnicalhistory ofAI.Ialso briefly
discusshowELIZAescapedintotheworld,andhowitsaccidentalescape,
alongwithseveralcoincidentalturnsoftheprogramminglanguagescrews,
led both to the misapprehension that ELIZA was intended as a chatbot,
and tothe loss of theoriginal ELIZA to history for over 50 years.
“We can only see a short distance ahead, but we can see plenty there that
needs to be done.” (The last line of Turing’s 1950 MIND paper [44])
1 Introduction
ELIZA,oftenconsideredtheworld’sfirstchatbot,waswrittenbyJosephWeizen-
baum at MIT in the early 1960s.[47] In building ELIZA, Weizenbaum did not
intend to invent the chatbot.1 Instead, he intended to build a platform for re-
searchintohuman-machineconversation. Thismayseemobvious–afterall,the
titleofWeizenbaum’s1966CACMpaperis“ELIZA–AComputerProgramFor
the Study of Natural Language Communication Between Man And Machine.”,
not,forexample,“ELIZA-AComputerProgramthatEngagesinConversation
1Ofcourse,itwouldnothavebeencalleda“chatbot”atthethattimeanyway,asthatterm
was not invented until the mid 1990’s[1], but we’ll use that term here as it is the currently
appropriateterm.
1
4202
nuJ
52
]IA.sc[
1v05671.6042:viXrawith a Human User”. But Weizenbaum’s purpose for ELIZA was obscured by
the circumstances of its creation, and by its own fame resulting, in large part,
from the fortuitous timing of it’s creation and it’s escape into the wild.
In this paper I try to provide a rich historicalcontext for ELIZA’s creation.
ELIZAarosefromtheintersectionofsomeofthecentralthreadsinthetechnical
history of AI. In addition to explaining how these intersect in Weizenbaum’s
creation of ELIZA, I also briefly discuss how ELIZA escaped into the world
throughno actionorintention ofWeizenbaum’s, andhow its accidentalescape,
along with a coincidental turn of the programming language screw, led to the
misapprehension that ELIZA was intended as a chatbot.
2 Why ELIZA?
WhyJosephWeizenbaumbuiltELIZAdoesnotappeartobemuchofamystery;
Isn’t the answer just as simple as Pamela McCorduck put it in Machines Who
Think[33]:
“[...] Weizenbaumgot interestedinlanguage. EdFeigenbaumintroduced
himto[...] KennethColby,apsychiatristwhohad[...] turnedtocomput-
ers as a possible way of gaining new insights into neurotic behavior. [...]
In 1963, Weizenbaum went to MIT, [where] he designed a program that
wouldanswer[simplequestions]. Itwasashort,trickyprogram,basedon
sleight of hand, and it led Weizenbaum to ask himself some very serious
questions about mystification and the computer [...]. [If] you could do
a simple question-answering machine, why not a complicated one? How
different would complexity make such a machine? Could you seem to
have complex responses based on simple rules? [...] Weizenbaum drove
into work many a morning with his neighbor Victor Yngve, who had de-
veloped the COMIT language, for pattern matching. If you were going
to play around with matching patterns, why not the patterns in English
wordsandsentences? ELIZAwastheresult. ELIZAwasintendedtosim-
ulate—or caricature, as Weizenbaum himself suggests—the conversation
betweenaRogerianpsychoanalystandapatient,withthemachineinthe
role of analyst.”
The reason that Weizenbaum gives McCorduck for choosing the Rogerian
setting was the simplicity of creating an “illusion of mutual understanding”:
“What I mean here is the cocktail party conversation. Someone says
something to you that you really don’t fully understand, but because of
thecontextandlotsofotherthings,youareinfactabletogivearesponse
which appears appropriate, and in fact the conversation continues for
quite a long time. We do it all the time, not only at cocktail parties.
Indeed, I think it’s a very necessary mechanism, because we can’t, even
in serious discussion, probe to the limit of possible understanding. [...]
That’s necessary. It’snot cheating.”[33, pp.251–253]
When Weizenbaum was looking for a context where he could carry on that
sort of illusion, he needed one where ignorance would not destroy the illusion
2of understanding: “For example [he goes on], in the psychiatric interview the
psychiatrist says, tell me about the fishing fleet in San Francisco. One doesn’t
say, “Look, he’s a smart man—how come he doesn’t know about the fishing
fleet in San Francisco?” What he really wants to hear is what the patient has
to say about it. [...]”[33, pp. 251–253][italics as in the original]
However, as mentioned above, the title of Weizenbaum’s 1966 paper belies
– or at least complexifies – the post hoc account he gave McCorduck. The
title of the paper is not “ELIZA – A Computer Program that Simulates or
Caricaturesthe conversationbetweenaRogerianpsychoanalystandapatient.”
butrather: “ELIZA–AComputerProgramFortheStudyofNaturalLanguage
Communication Between Man And Machine”.[47] This, and other features of
that paper that I go into below, as well as a recently discovered manuscript
signedinWeizenbaum’sownhand[2],suggestthatELIZAwasnot,asquotedby
McCorduck “intended to simulate—or caricature [...] the conversationbetween
a Rogerian psychoanalyst and a patient”, but rather that it was intended, just
as the title of the paper says, as a platform for research in [human]-machine
communication. To understand the details of this misinterpretation, we need
to understand the context in which ELIZA appeared, and how ELIZA came it
into the public eye.
3 The Intelligence Engineers
The founding father of the effort to build intelligent machines was, of course,
Alan Turing (although Ada Lovelace may have been the founding mother, as
will be seen shortly). Turing is publicly most famous for having led the team
that built the “bombe”, the machine that made it possible to decipher enemy
messages in the second World War.[24] However, in academic circles, Turing
is best known for the mathematical construct that now bears his name, the
UniversalTuringMachine. AndinAIcircles–andrecentlyinpublic,asAI has
come more into public focus – Turning is associated with the Imitation Game,
which we now call the Turing Test.[44]
Since we are discussing ELIZA, which was apparently a chatbot, the reader
might expect me to go straight to the Turing Test. However, I am concerned
hereprimarilywithELIZAasacomputationalartifact,notwithwhetherELIZA
was or was not intelligent; We can all agree that it was not, and we shall see
later that Weizenbaum himself had specific reasons for not thinking of ELIZA
as intelligent. Thus the Turing Test plays little role with respect to ELIZA, at
leastasitthatprogramwasconceivedbyWeizenbaum,soweshallleaveitaside
in the present exploration, except for one important detail that arises, almost
in passing, in Turing’s Mind paper.
Turing notes that over a century before his effort, Ada Lovelace had de-
scribed the potential of Babbage’s Analytical Engine to “act upon other things
besides number[s]”:
“Theoperatingmechanism[...] mightactuponotherthingsbesidesnum-
ber,wereobjects foundwhosemutualfundamentalrelationscouldbeex-
3pressedbythoseoftheabstractscienceofoperations,andwhichshouldbe
alsosusceptibleofadaptationstotheactionoftheoperatingnotationand
mechanism of the engine. Supposing, for instance, that the fundamental
relationsofpitchedsoundsinthescienceofharmonyandofmusicalcom-
position were susceptible of such expression and adaptations, the engine
might compose elaborate and scientific pieces of music of any degree of
complexity or extent[...]”[23]
We shall soon see that Ada’s insight that machines could act upon other
things besides numbers was enormously prescient, foreshadowing the concept
of symbolic computing, which was to become, and remains today, one of the
foundations of artificial intelligence, and which is central to the pre-history of
ELIZA.
But first let us return to Turing’s mathematical contribution, Turing’s Uni-
versalMachine, the now so-called “Turing Machine”. The Turing Machine was
Turing’s contribution to a line of inquiry in the early part of the 20th century
whichincludedTurning,KurtGodel,andAlonsoChurch,alladdressingaprob-
lemposedin1928byHilbertandAckermancalledthe“Entscheidungsproblem”.[3]
Hilbert’s challengewasto findanalgorithmto determine whether amathemat-
ical proposition is provable. Godel addressed this problem through what we
now call “Godel Numbering”, his method of turning mathematical expressions
into numbers, and showing that there are expressions that cannot be proved in
a complete system. Churchreachedthe same conclusionby formalizinggeneral
recursive functions in a system called the “Lambda Calculus”. And Turing ad-
dressed the problem by describing a universal machine that can compute any
function. Turingthenshowed,equivalentlytoGodelandChurch,thatthereare
programs for which it is impossible to prove that they will come to a halt on
his machine, which we now call “the halting problem”.[37]
The connection between Turing’s interests in universal computers, com-
putable functions, and intelligence is obvious: If a machine can compute any
function (leaving aside provability, which is not prima facie relevant as regards
human intelligence), and intelligence is supposed to be some sort of function
(which may be separately debated, but which was assumed by Turing), then if
one’s goal is to understand intelligence and perhaps even to create an intelli-
gent machine, it is important to be able to tell when you’ve succeeded – thus,
Turing’s invention of The Imitation Game, now famously called the “Turing
Test”.
Turing’s Universal Machine was a theoretical construct. But in 1943, he
designed and succeeded in building, with other engineers at Bletchley Park, a
near-instantiation of his theoretical machine, called Colossus. Dyson observes
thatColossus“wasanelectronicTuringmachine,andifnotyetuniversal,ithad
alltheelementsinplace.”[24,p.256]The TuringMachine,andits instantiation
in Colossus, represented an extremely important advance in computing, even
though computing was only in its infancy. Up until that time, all computers
were “hardwired” – that is, they executed a program that was wired into their
hardware. The bombe was of this type. The important conceptual advance
due to Turing, and at about the same time John von Neumann in the EDVAC
4project, was to store the program on a medium that is not fixed, but can be
changed by the program itself. In Turning’s machine (and Colossus) this was
a tape. In von Neumann’s case it was an electronic memory[4]. This way of
thinking about computers – as “stored program”,as opposed to “hardwired”–
was the engineering revolution hidden in Turing’s theoretical construct – that
computers could not only do complex calculations, but that they could ma-
nipulate their own programs, much like intelligent agents engage in reasoning,
planning, and other meta-cognitive activities wherein we think about and modify
our own thoughts. We now call such machines “von Neumann-style” machines,
although they could just as reasonably, and perhaps even more so, be called
“Turing-style”.
4 Newell, Shaw, and Simon’s IPL Logic Theo-
rist: The First True AIs
Beginning in 1950, almost exactly at the same time that Turing’s Mind pa-
per appeared, there was an explosion in von Neumann/Turing style computer
hardware. At that time, all of the existing computers, such as Colossus and
EDVAC, were one-off machines. Although UNIVAC, the company spun off
from Penn’s ENIAC project by Eckert and Mauchley, had promised a mass-
produced machine, none had yet been delivered when RAND decided to build
the JOHNNIAC.[30] This was the machine on which Shaw, Newell, and Simon
pioneered the IPL series of programming languages, which they used to imple-
ment what were are almost certainly the first real AIs:
“IPL was first utilized to demonstrate that the theorems in Principia
Mathematicawhichwereprovenlaboriouslybyhand,byBertrandRussell
and Alfred North Whitehead, could in fact be proven by computation.
According to Simon’s autobiography Models of My Life, this application
was originally developed first by hand simulation, using his children as
the computing elements, while writing on and holding up note cards as
the registers which contained the state variables of the program. IPL
was used to implement several early artificial intelligence programs, also
by the same authors: the Logic Theorist (1956), the General Problem
Solver (1957), and their computer chess program NSS (1958). Several
versions of IPL were created: IPL-I (never implemented), IPL-II (1957
forJOHNNIAC),IPL-III(existedbriefly),IPL-IV,IPL-V(1958,forIBM
650, IBM 704, IBM 7090, Philco model 212, many others.”[5]
IPL introducedwhat became the most important concepts in classicalArti-
ficialIntelligence(and,infact,incomputingmoregenerally),includinglistpro-
cessing,symboliccomputing(asforeshadowedbyAdaLovelace!),andrecursion.[5]
Notably, although Turing’s bombe, the code-breaking machine, was not a
“modern” computer, in the sense that is was hardwired, as opposed to being
of the von Neumann/Turing stored programtype, the programthat it ran was
explicitly engagedinmechanicalheuristic search,thatis,intrying ahugenum-
ber of operators (e.g., combinations of code keys) in a cleverly arranged order
5(e.g., beginning with the most probable), in hopes of reaching a goal (e.g., the
key that would break the day’s code). Much later,Newell and Simon described
heuristic search as a fundamental process of intelligence,[35], and remains one
of the most important tools of AI.2
However, IPL was an ugly programming language – not very far from as-
sembly language – and, as an interpreted languageit was slower than assembly
orthe soon-to-follow“highlevel”compiledlanguagessuchas COBOLandFor-
tran. These promised programmers both high performance and simplicity of
expression. This brings us to SLIP and Lisp, which took different paths to
bring simplicity and additional power to the important AI concepts pioneered
in IPL.
5 From IPL to SLIP and Lisp
Recall (from McCorduck) that Weizenbaum was connected to AI through a
number of paths, including Kenneth Colby, a Stanford psychiatrist who was
interested in modeling neurosis and paranoia[22], and Ed Feigenbaum, a com-
puter scientist at Berkeley. Feigenbaum had been a student of Simon’s, and
was creating various AI programs in IPL.[26] Once Weizenbaum got to MIT,
he became associated with Project MAC, which was begun, in part, by John
McCarthy, the inventor of Lisp and the person who coined the term “Artificial
Intelligence”[6].3
But Weizenbaum was, first and foremost, what we would now call a soft-
ware engineer4, having just come from GE where he worked on highly prac-
tical programs. There were several projects mounted to build on the clear
successes of Newell and Simon’s IPL work without having to cope with its ug-
liness and inefficiency. As mentioned above, there were already several much
more programmer-friendly languages, notably Fortran and COBOL. But these
languageswereaimedatscience,engineering,andbusiness,anddidnotprovide
the AI-related functionalities of IPL, such as symbol processing, lists, and re-
cursion. So the question naturally arose as to how to add these capabilities to
those already-existing languages.
The inventive entanglement between Fortran, IPL, and Lisp is concisely
captured in a brief mention by Gelernter and coworkers in creating FLPL, the
“Fortran List Processing Language”:
“[...] consideration was given to the translation of a JOHNNIACIPL for
use with the IBM 704 computer. However, J. McCarthy, who was then
consulting for the project, suggested that Fortran could be adapted to
serve the same purpose. He pointed out that the nesting of functions
thatisallowedwithintheFortranformatmakespossibletheconstruction
2AllenNewell once told me, inpassing, that AI’s onlyhad one tool, the abilityto search
hugemulti-dimensionalspaces efficiently,butthatonetool isallyouneed.
3AlthoughMcCarthymovedtoStanfordin1962,twoyearsbeforeWeizenbaumarrivedat
MIT.[7]
4Thattermwascoinedinthelate1960s.[18]
6of elaborate information-processing subroutines with a single statement.
The authors have since discovered [...] the close analogy that exists be-
tweenthestructureof[aNewell,Shaw,andSimon]listandacertainclass
of algebraic expressions that may be written within the language. [...]
Not to be overlooked is the considerable sophistication incorporated into
the Fortran compiler itself, all of which carries over, of course, into our
Fortran-compiled list-processing language. It is reasonable to estimate
that aroutinewritten in ourlanguage would runabout fivetimes asfast
as the same program written in an interpretive language [like IPL].”[27,
pp. 88–89]
LikeGelernter,WeizenbaumimplementedasetofIPL-inspiredlist-processing
facilitiesasasetofFortran-(andlaterMAD-)-callablefunctions,whichhecalled
SLIP. In creating SLIP, Weizenbaum took a route similar to Gelernter’s. In his
1963 paper, Weizenbaum (in addition to citing IPL and FLPL as influences)
critiques McCarthy’s Lisp (although not mentioning it by name):
“List processing has won a number of dedicated converts. Some have,
however, become somewhat too fervent in their advocacy of list process-
ing. While there may be some programming tasks which are best solved
entirely within some list processing system, most taskscoming totheor-
dinary programmer require the application of a number of distinct tech-
niques. Thepackagingofavarietyoftoolswithinasingletoolboxappears
to be a good, if not an optimum, way of outfitting a worker setting out
to solve complex problems. FORTRAN, ALGOL, and other languages
of the same type provide excellent vehicles for such provisioning. Apart
from the fact that they are very powerful in themselves, they have the
advantage that they are well known. The task of coming to grips with
thesenewtechniquesisthenthatofaddingtoavocabularyofanalready
assimilatedlanguageratherthanthatoflearninganentirelynewone.”[49,
pp. 535–536]
The acknowledgementin the 1963SLIP paper is worth quoting in full, as it
makes many of the connections explicit:
“[...] SLIP owes a considerable debt to previous list processing systems.
Certainofitsfeaturesare,however,moretheresultofattemptstobuilda
symbolmanipulatorfortheuseofbehavioralscientiststhantogeneralize
other processors. In this connection, the continuing and generous advice
and support of Kenneth Colby, M.D., of Stanford University and of Dr.
Edward Feigenbaum of the University of California at Berkeley is grate-
fully acknowledged. The author also wishes to thank Howard Sturgis of
theUniversityofCalifornia atBerkeleyandLarryBreedofStanfordUni-
versity for their parts in making the system operative on the computers
at their respective computation centers.”[49, p.536]5
5SymbolsinLispandIPL-Varenamedpointersandthoselanguages,beingself-contained,
havespecificsupportforsymbolmanipulation. BecauseSLIPisembeddedinanotherlanguage
(initially Fortran, later MAD in which ELIZA was implemented), the naming, should the
programmer choose to do so, results from Fortran assignment to variables. It would require
another whole paper to track the meaning of “symbol” through the history of programming
languages,AI,andcognitivescience.
7Although the SLIP paper makes no mention of ELIZA, nor of any specific
application, this acknowledgement makes clear that SLIP was motivated by
“previouslistprocessingsystems”(specificallyIPL-V,andFLPL),asa“symbol
manipulatorfortheuseofbehavioralscientists”,andthatSLIPwasrunningon
computers at both Stanford and Berkeley. Although the SLIP paper explicitly
cites Gelernter’s FLPL, it is likely, given the above acknowledgement, close
timing, and length of publication cycles, that SLIP was developed essentially
simultaneously with FLPL, and that the citation was a publication-sequence
nod,ratherthanFLPLhavingdirectlyinfluencedSLIP’sdevelopment. Whereas
Weizenbaum originally embedded SLIP for Fortran, the SLIP that ELIZA is
writteninwasembeddedinMAD(althoughusingthe sameunderlyingforeign-
function callingmachineryas Fortran– anintermediate languagecalled“FAP”
– the Fortran Assembly Program). Intriguingly, this SLIP implementation for
the 7090 MAD programming language came from Yale[42, p. 62L1],suggesting
some interaction with Gelernter, although the details are obscure.
Notable from the above is McCarthy’s involvement with FLPL, and espe-
cially the point made by McCarthy about functional nesting of Fortran state-
ments. McCarthy’sownapproachtocreatingahigh-levelAIlanguagewasvery
differentfromtheoneherecommendedtoGelernter,whichwasalsoadoptedby
Weizenbaum. In addition to his interest in formal matters of logic and math-
ematics, McCarthy was coincidentally playing around with Church’s lambda
calculus, which, as discussed above, was the motivation for Turing’s work that
led to universal computers. This aligned nicely with the functional nesting
pointed out by McCarthy to Gelernter. Recursion is central to both univer-
sal computation and AI.[32] McCarthy, along with his students, most notably,
Steve Russell, figured out, perhaps coincidentally, how to bring list processing
andrecursiontogetherintoanelegantprogrammingparadigmthatwasfarsim-
pler and more elegantthan IPL, FLPL or SLIP; thus, the birth of Lisp, among
the world’s most influential and enduring programming languages.[19]
6 A Critical Tangent into Gomoku
Before getting to ELIZA itself, It will be useful to take a brief look at an ob-
scure1962paperofWeizenbaum’s–hisfirst–publishedinthetrademagazine,
Datamation.[48] Still with GE at the time, this brief paper has the odd and
telling name: “How to make a computer appear intelligent” [emphasis as in the
original]. The article, only a bit over two pages long, reports a simple strategy
for playing gomoku – a GO-like game. Weizenbaum didn’t actually write the
programdescribedinthepaper,althoughheapparentlydesignedthealgorithm6
Regardless,Weizenbaum’sinterestinthisprogramisinnotthealgorithmitself,
which he describes as “simple”. Rather, he is interested in the fact that the
program was able to “create and maintain a wonderful illusion of spontaneity”
(p. 24). Indeed, the paper (again, only a bit over two pages long) spends the
6“A program implementing the strategy here outlined has been written by R. C.
Shepardson”[48,p.26]
8first half page presenting a caustic screed against AI that is worth reproducing
in full:
“There exists a continuum of opinions on what constitutes intelligence,
hence on what constitutes artificial intelligence. Perhaps most workers
in the fields of heuristic programming, artificial intelligence, et al, now
agree that the pursuit of a definition in this area is, at least for the time
being, a sterile activity. No operationally significant contributions can
be expected from the abstract contemplation of this particular semantic
navel. Minsky has suggested in a number of talks that an activity which
produces results in a way which does not appear understandable to a
particularobserverwillappeartothatobservertobesomehowintelligent,
or at least intelligently motivated. When that observer finally begins to
understandwhathasbeengoingon,heoftenhasafeeling ofhavingbeen
fooledalittle. Hethenpronouncestheheretofore“intelligent”behaviorhe
has been observing as being “merely mechanical” or “algorithmic.” The
author of an “artificially intelligent” program is, by theabove reasoning,
clearlysettingouttofoolsomeobserversforsometime. Hissuccesscanbe
measuredbythepercentageoftheexposedobserverswhohavebeenfooled
multiplied by the length of time they have failed to catch on. Programs
which become so complex (either by themselves, e.g. learning programs,
or by virtue of the author’s poor documentation and debugging habits)
that the author himself loses track, obviously have the highest IQ’s.”[48,
p. 24]
The paper then goes on to describe the “simple” algorithm in typical algo-
rithmic terms, and at the end, far from closing the loop on his opening salvo,
simply suggests some ways to potentially improve the program’s play.
This curious paper provides a deep and interesting insight into the dual
forces tearing at Weizenbaum and leading to ELIZA. He is, first and foremost,
a software engineer. However, here we have a paper about a game-playing
program that begins with a screed about how AI engineers are out to fool
people. Weizenbaum clearly has a direct interest in AI, and he does not think
muchofit. Specifically,heisconcernedabouthoweasilypeoplecanbe“fooled”
by complex programs into the “illusion” of intelligence. A more generous and
interesting way to put this is that Weizenbaum is focused on the users, not on
the programs. Specifically, what is interesting to him is not AI per se, which
Weizenbaum has only a little to say about, and notmuch good, but the human
psychological process of interpretation – in this case, how the users interpret a
“simple algorithm” as playing intelligently.
7 Interpretation is the Core of Intelligence
Interpretation is the process through which humans – one might say, intelli-
gencesofwhateversort,or,moregenerally,“cognitiveagents”–assignmeaning
toexperiences. By“meaning”herewemeanapproximatelywhatlinguistsmean
by the term “semantics” or cognitive scientists mean by “mental models”. It is
the abilitytoassignmeaning,separatefromthe experienceitself, andthence to
9draw inferences based upon this assignment, that enables cognitive agents to,
at the same time, abstract away from the specifics of experiences, and reason
about those specifics.7
The importance of interpretation has been rediscovered in both psychology
andAI dozensoftimesunderalmostasmanynames,includingputativemental
structures such as scripts, plans, frames, schemas, and mental models (e.g.,
[39], [28]), and putative mental processes such as analogy, view application,
commonsense perception, analogy, and conceptual combination or conceptual
blending (e.g., [9]). In AIs driven by Artificial Neural Networks (ANNs), the
structuresandprocessesinvolvedininterpretationarediffuse,butthesesystems
engage none-the-less in interpretation.
InterpretationisalsocentraltoColby’sworkonparanoia. Indeed,Colbyde-
scribesoneofhisearliestimplementationsofparanoiaaspreciselyinterpretation
gone awry: “A parser takes a linear sequence of words as input and produces
a treelike structure [...] The final result is a pointer to one of the meaning
structures which the interpretation-action module uses in simulating paranoid
thinking for both the paranoid and the nonparanoid modes.”[21, p. 520]
Weizenbaum, who it will be recalled had worked with Colby, explicitly rec-
ognized that ELIZA had no interpretive machinery - no way to assign meaning
to the content of the conversation. Indeed, he chose the Rogerian framework
precisely for the reason that that framework (or at least Weizenbaum’s gloss
of it) puts almost all of the content work on the patient/user, who presumably
has intact interpretive machinery: “This mode of conversation was chosen be-
causethe psychiatric interviewis one ofthe few examples ofcategorizeddyadic
natural language communication in which one of the participating pair is free
to assume the pose of knowing almost nothing of the real world.”[47, p. 42]
Weizenbaumevenpoints to thisasthe thing thatneeds mosttobe improvedin
ELIZAinordertocreateafullerconversant: “Inthelongrun,ELIZAshouldbe
able to build up a belief structure [...] of the subject and on that: basis detect
the subject’s rationalizations, contradictions, etc.”[47, p. 43]
Yet, at the same time, interpretation is central to Weizenbaum’s work, but
not the interpretations that ELIZA makes, which are, per Weizenbaum him-
self,non-existent,but the interpretations made by the human interlocutors with
ELIZA (or, as described above, with the gomoku player).
8 The Threads Come Together: Interpretation,
Language, Lists, Graphs, and Recursion
Interpretation is the process through which a cognitive agent assigns meaning
toexperience. InthecaseofELIZA(orPARRY)“experience”ismerelytextual
interactionwith the user. Weizenbaum recognizedthatELIZAhas no interpre-
tive structures or processes at all. It is, however, worth making a connection
7Ofcourse, termssuchas “meaning” and“experience” arevague, andinapaper focused
oninterpretationthesewouldneedtobespecifiedmorecarefully,buttheyarenotcentralto
thepresentexploration. Forabroadreview,see[8].
10between interpretation, and the focus described above on recursion and lists,
and language, because this connects all of the threads of research that are de-
scribed here. To create a completely tied-together coherent explication of this
complexknotofconceptswouldrequiremuchmorespacethanisavailableatthe
moment, so we will merely touch the topic at a few points which will hopefully
be sufficient to give the reader the sense of the whole.
First, observe that at the simplest level, a sentence is a “merely” list of
words. However,aspointedoutbyChomsky,humanlanguageisfundamentally
recursive, as can easily be seen in either the understanding or production of
novel,potentially infinitely deeply nestedsentences thatmay be hardto under-
stand, but which, like this one, are nonetheless grammatical and sensible, for
example: “The rat that the cat that the dog chased killed ate the malt.”[20,
p. 286]
Second,observethatalist(perhapsrepresentingasentence)isaspecialcase
ofagraph,and,moreover,anestedlist(perhapsrepresentinganestedsentence,
like the example above)is just a tree, which is a specific kind of graph. Indeed,
Chomsky’sunderlyinggrammarsaregraphsaswell,whereelementslinktoother
elements. Andevenwithoutgoingintothatdepth,itisobviousthatlanguageis
graph-structured, not merely tree-structured even on the surface, through, for
example, pronouns which refer to other constituents of the sentences, creating
edges in the graph.
Third,observethatthebeliefstructuresthatareusedinmostAItorepresent
beliefs are generally graphs, wherein symbols, which might represent concepts,
arelinkedtooneanotherbyedges,whichmightrepresentrelationshipsbetween
concepts.8
Fourth, observe that graph (or tree or list) traversalis a naturally recursive
process, proceeding from vertex to vertex along the edges of the graph, and
that many of the core algorithms of classical “symbolic” AI rely upon various
9
versions of efficient graph (or tree) traversal.
Finally(fifth), observethatextendedconversations(discourse),isanalogous
to individual sentences in that at the surface it is linear (list-like), but even
going one level down one finds that real discourse contains explicit connections
(e.g.,“...beforeyousaid...”),and,againanalogoustoourstoryofinterpretation,
as well at both the levels of semantic and pragmatic connections that connect
parts of the conversationto one another.
Given these glosses,it canbe seen(roughly)that interpretationis a process
– indeed, a computable recursive function, precisely in Turing’s sense – that
8In AIs built out of ANNs the concepts and their inter-relationships are not so concisely
represented – usually being diffused across the network, however, the networks themselves
arestillgraphs(indeed,theterm“network”isjustasynonymfor“graph”),andtheanalytic
basesfortheconstructionandanalysisofANNsrestfirmlyongraphtheory.
9TheoperationofANNsreliesuponmatrixmultiplicationratherthanupongraphtraver-
sal,howeverthesearecloselyrelated,and,indeed,onecommonlyimplementsgraphtraversal
viamatrixmultiplication. Furthermore,advancedusersofANNsarecomingtotherealization
that in order to understand what the ANN is doing, and to guide it “intelligently” we are
likelytoenduprelyinguponmoreclassicalsortsofalgorithms,resultinginahybridofANN
andsymbolicAI.
11transforms one sort of graph structure, the surface structure of sentences, and
indeed of whole discussions, to another – the meaning – and then back again,
into the next turn of the conversation.10 Although ELIZA only engages in the
shallowestsuchrecursiveoperationsintransforminginputsentencesintooutput
sentences directly in accord with its script, Weizenbaum was explicitly aware
that ELIZA’s users – and indeed the users of any AI (or for that matter ev-
ery human everywhere all the time) – were engaged in interpretation in all is
complexity and glory. Putting this more clearly, the users of an AI are inter-
preting the program as intelligent, and they are led – or perhaps mis-led – to
this interpretation by virtue of the program putting forward an appearance of
intelligence, or what Weizenbaum called “the illusion of understanding” in his
conversation with McCorduck, and, as we shall soon see, in the ELIZA paper
itself.
It is critical to understand that this “illusion” does not arise through trig-
gering some sort of abnormal cognitive error. Quite to the contrary, it relies –
asdoesallmagic–upontheperfectlynormal,continuous,andcentralcognitive
process of interpretation that humans are engagedin all the time in everything
they do. Without the continuous cognitive process of interpretation, we could
not operate, and indeed, we would not be cognitive agents at all. Mistaken in-
terpretationis a common and normalfeature of cognition, and is usually easily
11
corrected, if becomes relevant at all.
Armed with this insight, we come, finally, to ELIZA itself.
9 Finally ELIZA: A Platform, Not a Chat Bot!
In short order, after the Datamation article, Weizenbaum publishes a series of
papers in the Communications of the ACM (CACM), the premier publication
in computing research and development at that time. His SLIP paper appears
in 1963[49], and just three years later, in 1966, having moved to Stanford and
then MIT, all of this comes together into the ELIZA paper.[47]
Again, let’s carefully read what should be obvious, but is commonly over-
looked, the title of the paper: “ELIZA– A Computer Program For the Study
10NN-basedAIs,especiallymodernLargeLanguageModels(LLMs)usuallyoperateword-
by-word(more precisely,token bytoken), generating the next “mostlikely”word(token) as
resultofbubblingthecontext–i.e.,thewholepreviousinteraction(includingtheLLM’sown
outputs)backthroughthenetworkinwhatiscalleda“recurrent”pattern. Thesearemorelike
ELIZAthantheyareliketheAIsbuiltbyColby,Schank,etc. Insteadofanauthorcreatinga
script,thescriptsforLLMsacreatedbytransformingenormousamountsoflanguage,usually
scrapedfromtheweb,intotheincrediblycomplexgraphsdescribinghowwordsrelatetoother
words in their context, but they have no explicit representation of meaning, aside from the
nest of interrelationships burned into and buriedinthe network. As a result, when engaged
indiscourse,LLMsact strikinglikeELIZAinthat theycanbrieflymaintaintheappearance
of understanding but once one attempts to carry on the conversation in a new direction, or
refer (directly or indirectly) to previous conversational context, they are essentially as lost
asELIZA, andengage inwhat mightbemostcharitablydescribed asgrammaticallycorrect
confabulation.
11Uncorrectedmistakeninterpretationmaybebesaidtobethecoreprobleminsomeofthe
cognitiveimpairmentsstudiedbyColbyandother psychiatrists.
12ofNaturalLanguageCommunicationBetweenManAnd Machine.” This paper
begins with a somewhatless negative versionof the same plaint as the gomoku
paper:
“Introduction. It is said that to explain is to explain away. This maxim
isnowheresowellfulfilledasintheareaofcomputerprogramming,espe-
cially in what is called heuristic programming and artificial intelligence.
For in those realms machines are made to behave in wondrous ways, of-
ten sufficient to dazzle even the most experienced observer. But once a
particular program is unmasked, once its inner workings are explained
in language sufficiently plain to induce understanding, its magic crum-
bles away; it stands revealed as a mere collection of procedures, each
quitecomprehensible. Theobserversaystohimself“I couldhavewritten
that”. With that thought he moves the program in question from the
shelf marked “intelligent”, to that reserved for curios, fit to be discussed
only with people less enlightened than he.”[47, p.36]
Weizenbaum continues in the next shortparagraph: “The object of this pa-
peristocausejustsuchare-evaluationoftheprogramabouttobe“explained”.
Few programs ever needed it more.”[47, p. 36] This last sentence reveals some-
thing hidden: “Few programs needed it more.” This echo of the gomoku paper
tells us that it is exceedingly likely that Weizenbaum had already had the ex-
periences that become so famous much later, of people talking intimately to
ELIZA, and which became so antithetical to Weizenbaum, leading him to his
later positions on AI.
He only briefly revisits this later in the paper: “A large part of whatever
elegance may be credited to ELIZA lies in the fact that ELIZA maintains the
illusionofunderstandingwithsolittle machinery.” Buthe immediately returns
to technical matters “But, there are bounds on the extendability of ELIZA’s
“understanding”...” Andoncemore,theverylastparagraphofthepaperreads:
“The intentoftheaboveremarks[about translating processors] is tofur-
ther rob ELIZA of the aura of magic to which its application to psy-
chological subject matter has to some extent contributed. Seen in the
coldest possible light, ELIZA is a translating processor [...] which has
been especially constructed to work well with natural language text.”
Interestingly, this is almost identical to Searle’s “Chinese Room” argument
about AI, which appeared significantly later, in 1980.[40] If any program was
ever to work in exactly the version described by Searle, it would be ELIZA!
Indeed, Searle specifically mentions ELIZA: “I will consider the work of Roger
Schank and his colleagues at Yale [...]. But nothing that follows depends upon
the details of Schank’s programs. The same arguments would apply to Wino-
grad’sSHRDLU[...],Weizenbaum’sELIZA[...],andindeedanyTuringmachine
simulation of human mental phenomena.” [italics added]
Let us pause to take note of how this last phrase of Searle’s ties together
(under his critique, in this case) another set of threads, this time from Hilbert
through Turing and up to ELIZA and its descendants. Under the present hy-
pothesis, Searle and other critics of ELIZA as an AI miss the point of ELIZA;
13ELIZA was not intended as an AI (orchatbot) at all, but as a platform for
experiments in human interaction with AIs, and in particular the problem of
interpretation;aproblemthatisnowmuchmoreimportant,andequallyunder-
studied as it was 60 years ago, when Joseph Weizenbaum set out to (by this
hypothesis) build a platform for research in this area, even going to far as the
describe ELIZA as a vehicle for running a version of Turing’s imitation game:
“With ELIZA as the basic vehicle, experiments may be set up in which
thesubjectsfinditcredibletobelievethattheresponseswhichappearon
his typewriter are generated by a human sitting at a similar instrument
inanotherroom. Howmustthescriptbewritteninordertomaintainthe
credibility of this idea over a long period of time? How can the perfor-
manceofELIZAbesystematicallydegradedinordertoachievecontrolled
andpredictablethresholdsofcredibilityinthesubject? What,inallthis,
is the role of the initial instruction to the subject? On the other hand,
suppose the subject is told he is communicating with a machine. What
is he led to believe about the machine as a result of his conversational
experience with it? Some subjects-have been very hard to convince that
ELIZA (with its present script) is not human. This is a striking form
of Turing’s test. What experimental design would make it more nearly
rigorous and airtight?”[47, p. 42]
Understanding ELIZA as a platform for researchinto human-machine com-
munication is a very different framing of ELIZA than is commonly attributed
to Weizenbaum. Onthe one hand, in his 1975book[46] Weizenbaum frames AI
asdangerousand/orimmoral,andmentionsELIZAverylittle. Hispaperscirca
ELIZA, around the mid 1960s, as we saw above, describe a weaker, although
related framing of ELIZA and other AIs of the time as intentional illusions.
But there is a third way of framing ELIZA that aligns both of these, and
finallydrawstogetherallofthethreadsthatwehavediscussed. Thisthirdfram-
ing might be rendered as: “AI could be dangerous, and is possibly immoral, if
people interpret it the wrong way. Therefore, we need to study how people in-
terpret their interactionwith complex computer programs,especially ones that
may appear to be intelligent. ELIZA is a platform in support of that project.”
Under this theory ELIZA is not an AI at all, and is only barely a chatbot.
Rather,ELIZA is a platform for research into how human interpretation works,
and potentially how it may go awray or be abused. Indeed, Weizenbaumhimself
wroteadetailedoutline ofapaperdiscussingpotentialexperiments alongthese
lines that was recently uncovered in Weizenbaum’s archives at MIT.[2]. That
paper, signed in Weizenbaum’s own hand, describes experiments he envisioned
to be carriedout with ELIZA,including detailed discussionofpotential experi-
mentsindiscourseanddiscoursecorrection. The veryfirstpageofthatoutline,
after a brief introduction, dives right into the heart of the questions we have
describedinthepresentpaperastheonesthatWeizenbaumwasmostinterested
in, and which ELIZA was designed to explore:
“Understanding and misunderstanding. A. Our concern with partial un-
derstandingandthusunderstandingandmisunderstanding,indiadiccom-
municationderivesfromboththeclinicalobservationandtheexperimen-
14tally demonstratable facts that one or both parties in a two-party com-
munication can beundertheimpression thatthey areunderstood bythe
other, while, in fact all that is understood is but a fragment of what is
said or typed.”
Thatoutlinewasapparentlyintendedtobecomeapaperpublishedalongside
theELIZApaper,but,sadly,asfarasweknowitnevermadeitbeyondthedraft
stage. And, unfortunately, Weizenbaum never explored the potential potential
for ELIZA as an experimental platform. Instead, at least at MIT, ELIZA was
primarily explored for its educational potential (also mentioned briefly on the
above-describedoutline),aprojectcarriedforwardforatimebyPaulHayward,
Edmund Taylor, and Walter Daniels.[31, 43]
Although Weizenbaum neverhimself usedELIZAas a platformfor research
into human-machine interpretation, some researchers did. In particular, a trio
of researchers working right across the Charles river from MIT, at The Stan-
ley Cobb Laboratory for Psychiatric Research, of the Massachusetts General
Hospital and Harvard Medical School, explored ELIZA as “a new researchtool
in psychology.”[34] They observed that ELIZA “allows the stabilization of one
partyindyadiccommunication,forongoinganalysisofcertaintypesofcommu-
nication and for systematic hypothesis testing about such communication”[34,
p.190]Althoughtheseresearcherwerenotexplicitstudyingtheinterpretiveas-
pects of human-computer communication that interested Weizenbaum, it came
upregardless: “Theplausibleconversationwhichcanbegeneratedbythesema-
chinesoftenleadstodisputesovertheallegedintelligenceofthecomputer. Such
disagreement may distract attention from the important contributions such a
machinemaymaketothe understandingofcommunication. Foreachcomputer
program is a simplified model of dyadic communication and may greatly assist
in theory construction and testing.”[38, p. 165]. These researchers were using
Weizenbaum’s MAD-SLIP version of ELIZA,although with a slightly different
script (called “YapYap” [10]) and recently researchers studying the archives of
HaroldGarfinkel discoveredoriginaltranscripts of their subjects’ conversations
with this ELIZA, and the YapYap script, and demonstrated that this script
exactly recreated the original conversations.[10]
Garfinkel and his coworkers interests seem to have been more aligned with
whatWeizenbaumhadinmind: “Garfinkelwasinterestedinhowhuman–computer
interactionwasexploitinghumansocialinteractionalrequirementsinwaysthat
notonlyforcedparticipantstodotheworkofmakingsenseofachatbot’sturns,
butalsogavethemthe feelingofanauthenticconversation.”[25]Unfortunately,
Garfinkel’sresearchinthis areawasneverpublished,andresearchwithELIZA,
and indeed all research into the important interpretive phenomena that inter-
ested, andlaterhorrifiedWeizenbaum, appearsto haveended atthis point.1213
12WiththeexceptionoftheHaywardetal. educationalresearch,mentionedpreviously.[31]
ThisworkwascarriedoutonahighlymodifiedELIZA,andwithanexpliciteducationalgoal,
againnotdirectlyaddressingtheinterpretiveprobleminhuman-computer communication.
13Garfinkelandhiscoworkersdidtakethistopicupquitedirectly,andworkedforatimewith
theMGHteam, although theGarfinkel-relatedresearchendedupusingadifferentplatform,
calledLYRIC,fortheirwork. And,again,wasneverpublished.[25]
1510 A Perfect Irony: A Lisp ELIZA Escapes and
is Misinterpreted by the AI Community
OurthesisisthatJosephWeizenbaum,afraidofpeoplemisinterpretingcomput-
ersandAI,developedELIZAnotasanAI,butasaplatformtosupportresearch
about people’s interpretive process, perhaps more specifically their interaction
with AIs. Weizenbaum, of course, had to provide an example – the DOCTOR
script – to demonstrate the platform, but, as above, he had no illusion that it
was actually intelligent, nor even very easily interpreted as intelligent; Much
more “intelligent” programsalready existing in various game playing programs
(even his own, from the Datamation paper!), in Colby’s Parry, and in other
programs that solved math word problems[17], did database lookups from nat-
ural language queries[29], and others. Although some of the sort of research
envisioned by Weizenbaum was carried out by the MGH team, a specific event
thwartedthis use caseforELIZA,and,inalmostthe deepestpossible irony,led
to exactly the conflation of ELIZA with AI that Weizenbaum set out to study,
not to bring into being.
Weizenbaum built his ELIZA in MAD-SLIP on the IBM 7090, which was
the primary machine at MIT’s Project MAC, on the 5th-through-9th floors of
Tech Square. Almost immediately after ELIZA’s publication in 1966, Bernie
Cosell created a Lisp knock-off of ELIZA, based on the algorithm and DOC-
TOR script in Weizenbaum’s paper. Cosell worked at Bolt Beranek and New-
man(BBN), alargeRAND-like consultingcompanysituated nearbyMIT, that
commonlyhiredMIT graduates. Coincidentally,atalmostthe sametime,BBN
wasafoundingsiteoftheARPAnet14,andCosell’sLispELIZAdiffusedrapidly
throughthatnetworkandacrossthesoon-to-beLisp-centeredworldofacademic
AI. As a result, Cosell’s Lisp ELIZA rapidly became the dominant strain, and
Weizenbaum’s MAD-SLIP version, inaccessible on the ARPAnet, was almost
instantly forgotten.
Throughinterestingand complex criss-crossinghistories,describedin detail
in [45], Danny Bobrow, a recent MIT AI graduate who headed up BBN’s AI
program,broughtMcCarthy,andthus Lisp, to BBN,where Cosellwas exposed
to it, and built an ELIZA knock-off in Lisp as a side-project.15 Cosell reports:
“WhenI wasworkingonthe PDP-1time-sharingsystem[...] I thoughtI would
learn Lisp. That spring, Joe Weizenbaum had written an article for Communi-
cations of the ACM on ELIZA. I thought that was way cool. [...] He described
how ELIZA works and I said, “I bet I could write something to do that.” And
soI startedwritingaLispprogramon[the]PDP-1systematBBN.”[41,p.540]
He continues, “I wrote that program and got it up and working. Playing with
it was an all-BBN project. [...] It was written, at first, in the PDP-1 Lisp. But
they were building a Lisp on the PDP-6 at that point—or maybe the PDP-10.
14Atthe timewhat became the internet, and then the web, was calledthe ARPAnet, and
BBNbuiltitscorehardwareanddeveloped theprogramsthatranit.[11])
15Coincidentally,BobrowwasalsotheauthorofSTUDENT,theprogrammentionedabove
thatsolvedmathwordproblems.[17]
16But it was the Lisp that had spread across the ARPANet. So [ELIZA] went
along with it [...].”[41, p. 541]
OnceCosell’sLispELIZAhittheacademicworldviatherapidspreadofthe
ARPANet, Weizenbaum’s MAD-SLIP version was no longer relevant, and the
name “ELIZA” (andthe “DOCTOR”script), as well as the concept, was,from
thatpointforward,associatedwithCosell’sLispversion,althoughitsoriginwas
still correctly attributed to Weizenbaum via the CACM paper, leading to a 50-
year-long, community-wide misapprehension that ELIZA had been written in
Lisp. Inadditionto beingpromulgatedbyCosell’sknock-offbeingthe one that
wasmosteasilyavailable,viathe ARPANet, itwasanaturalconfusionbecause
Lisp was rapidly becoming the go-to language of AI. Once Lisp came onto the
scene no one thought much again about SLIP, or, for that matter, IPL-V.
11 Another Wave: A BASIC ELIZA turns the
PC Generation on to AI
AnotherdefiningeventinELIZA’sdescendancyoccurredalmostexactlyadecade
later,in1977CreativeComputing,oneofthemagazinesthat,alongwithBYTE,
was the “Hacker News” and “GitHub” of the mid-70s personal computer ex-
plosion, published an ELIZA knock-off written in BASIC.[36] This was coin-
cidentally well-timed as it coincided nearly exactly with the so-called “1977
trinity”: The year that the Commodore Pet, the Apple II, and the TRS-80
all appeared.[12] Within a few years, millions of computer hobbyists – neither
academics nor otherwise professionally involvedwith computers – had personal
computersofallsorts,mostly withBASIC astheir primaryuser-levelprogram-
ming language. Not a small number of those hobbyists were interested enough
by the possibility of AI – perhaps with HAL9000, the murderous computer
from 2001[13], still in recent memory – to type in this BASIC ELIZA (which
wasonlyacouplepagesofcode),andexperimentwithitthemselves. Becauseof
itssimplicity,andthe personalcomputerexplosion,this ELIZAbegathundreds
of knock-offs through the decades, in every conceivable programminglanguage,
making it perhaps the most copied and knocked-off program in history.16 Just
as Cosell’s Lisp ELIZA was spread by the ARPANet, this BASIC ELIZA, was
spread by the wide-spread availability of personal computers.
Asaresultofthesecoincidences,andaninherentinterestinAI(oratleastin
talking with computers) the version of ELIZA that was known in the academic
community was Cosell’s Lisp version, and the version known to the public was
the BASIC version. But until it was rediscovered in 2021, the original MAD-
SLIP ELIZA, was forgotten, and had not been seen by anyone for at least 50
16Indeed, I curate a web site, ELIZAGen.org[14], dedicated to the history of ELIZA and
ELIZA-like programs. In that capacity I am regularly sent new, or newly-discovered knock-
offsofoneoranother oftheELIZA threads,usuallymyownBASIC ELIZA.Justlastweek,
asIwritethisinAprilof2024,IreceivedanemailpointingoutaversionofmyELIZA that
endedup,throughchannelsunknown,inApple’sHyperCardprogrammablenotecardsystem
fortheoriginalAppleMacintoshcomputers.[15]
17years.[16, 14]
12 Conclusion: A certain danger lurks there
Weizenbaum’s goal to use ELIZA as a platform for the study of the human
process of interpretation was thwarted by exactly what he did not want to see;
The “kludge” [in nearly the original sense of the term] supplanted the reality.
Instead of using ELIZA as a tool to study interpretation and interaction with
AI, it became a cause celebre in-and-of-itself, the DOCTOR script being the
only one ever seen, because it was so good for such a simple program– exactly
the opposite of Weizenbaum’s point! Moreover, exactly what Weizenbaum did
not want to happen with regard to Lisp vs. SLIP came to pass; instead of
people using Fortran to build complex AI programs. Nearly everyone in AI, or
involvedinsymbolicand/orlistprocessingturnedto Lisp,andSLIPeventually
faded away.
In 1950, Alan Turing wrote:
“I believethatinabout fiftyyears’timeit willbepossible toprogramme
computers, with a storage capacity of about 109, to make them play the
imitation game so well that an average interrogator will not have more
than70percent,chanceofmakingtherightidentificationafter fivemin-
utesofquestioning. Theoriginalquestion,‘Canmachinesthink!’ Ibelieve
to be too meaningless to deserve discussion. Nevertheless I believe that
at the end of the century the use of words and general educated opin-
ion will have altered so much that one will be able to speak of machines
thinking without expecting to be contradicted. I believe further that no
usefulpurposeisservedbyconcealingthesebeliefs. Thepopularviewthat
scientistsproceedinexorablyfromwell-establishedfacttowell-established
fact,neverbeinginfluencedbyanyunprovedconjecture,isquitemistaken.
Provided it is made clear which are proved facts and which are conjec-
tures,noharmcanresult. Conjecturesareofgreatimportancesincethey
suggest useful lines of research.”[44,p. 442]
A mere decade and a half later, Joseph Weizenbaum wrote:
“With ELIZA as the basic vehicle, experiments may be set up in which
thesubjectsfinditcredibletobelievethattheresponseswhichappearon
his17 typewriteraregeneratedbyahumansittingatasimilarinstrument
in another room.”[47, p. 42]
Regardless of how close this description may seem to Turing’s test, Weizen-
baum did not build ELIZA to pass that test. Rather he built it to run exper-
iments, including ones akin to the Turing Test, that could be used to study
human interpretive processes (especially in the case of artificial intelligence).
He believed that this research was critically important, but not merely for the
academic reasons that motivated Turing and most AI researchers:
17Even for the time, it is striking that Weizenbaum constantly refers to ELIZA’s inter-
locutors as male, given that the only example he provides of a conversation with ELIZA is
(putatively) withawoman!
18“[The] whole issue of the credibility (to humans) of machine output de-
mands investigation [...] [Important] decisions increasingly tend to be
madeinresponsetocomputeroutput. Theultimatelyresponsiblehuman
interpreter of ’What the machine says’ is, not unlike the correspondent
with ELIZA, constantly faced with the need to make credibility judg-
ments. ELIZA shows, if nothing else, how easy it is to create and main-
tain the illusion of understanding, hence perhaps of judgment deserving
of credibility. A certain danger lurks there.”[47,pp. 42–43]
The problem of how humans impute agency,correctness,and intelligence to
machines is not only still present, but has become exponentially more impor-
tant in recent years, with the widespread diffusion of internet bots and large
language models. Our modern computational lives might have been better had
Weizenbaumpursued his goalofusing ELIZAto study people’s interpretivein-
teractionwith computers, and especially with AIs. Unfortunately, his fear that
“[t]hereisadanger[...] thattheexamplewillrunawaywithwhatitissupposed
to illustrate”[47, p. 43] was too prescient.
1913 Acknowledgements
This paper developed through extensive discussions over several years with
“Team ELIZA”, including Anthony Hay, Art Schwarz, Sarah Ciston, Peggy
Weil, Peter Millican, David Berry, and Mark Marino. I am especially indebted
toAnthonyHayandArtSchwarzfordetaileddiscussionabouttechnicalaspects
of ELIZA and SLIP, such as how symbol manipulation worked in SLIP. Terry
WinogradandJohnMarkoffparticipatedinhelpfulbackgrounddiscussions,and
Anne RawlsandClemens Eisenmannprovidedaccessto the Garfinkelarchives,
and Andrei Korbut introduced us to them. Many anonymous commenters in
the Hacker News community helped clarify concepts, and provided additional
pointerstoinformationthatIcouldnothaveeasilydiscoveredonmyown. Iam
especially indebted to the MIT Archivists, Myles Crowley, Mikki Macdonald,
and Allison Schmitt.
20References
[1] https://grammarist.com/new-words/chatbot/.Accessed 2024-04-18.
[2] https://sites.google.com/view/elizagen-org/news#h.ykbzq5nuiccs.
Accessed 2024-04-18.
[3] https://plato.stanford.edu/entries/church-turing/.Accessed 2024-04-18.
[4] https://en.wikipedia.org/wiki/Von_Neumann_architecture.Accessed
2024-04-18.
[5] https://en.wikipedia.org/wiki/Information_Processing_Language.
Accessed 2024-04-18.
[6] https://en.wikipedia.org/wiki/Dartmouth_workshop.Accessed2024-
04-18.
[7] https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist).
Accessed 2024-04-18.
[8] https://plato.stanford.edu/entries/meaning/.Accessed2024-04-18.
[9] https://en.wikipedia.org/wiki/Conceptual_blending.Accessed2024-
04-18.
[10] https://sites.google.com/view/elizagen-org/news#h.74lv9le8r29u.
Accessed 2024-04-18.
[11] https://en.wikipedia.org/wiki/ARPANET. Accessed 2024-04-18.
[12] https://en.wikipedia.org/wiki/History_of_personal_computers.Ac-
cessed 2024-04-18.
[13] https://en.wikipedia.org/wiki/HAL_9000. Accessed 2024-04-18.
[14] https://sites.google.com/view/elizagen-org/.Accessed2024-04-18.
[15] https://en.wikipedia.org/wiki/HyperCard. Accessed 2024-04-18.
[16] https://sites.google.com/view/elizaarchaeology/. Accessed 2024-
04-18.
[17] D. G. Bobrow. “Natural language input for a computer problem solving
system”. PhD Dissertation. Cambridge, MA: Massachusetts Institute of
Technology, May 1964.
[18] L.Cameron.Whattoknowaboutthescientistwhoinventedtheterm”soft-
wareengineering”.https://www.computer.org/publications/tech-news/events/what-to-know-abou
Accessed: 2024-04-18.Oct. 2018.
[19] D.Chisnall.Influentialprogramminglanguages,Part4:Lisp.https://www.informit.com/articles/art
Accessed 2024-04-18.2011.
[20] NoamChomskyandGeorgeA.Miller.“Introductiontotheformalanalysis
of natural languages”. In: Handbook of Mathematical Psychology. Ed. by
R.DuncanLuce,RobertR.Bush,andEugeneGalanter.Vol.2.Hoboken,
NJ: John Wiley and Sons, 1963, pp. 269–321.
21[21] K.M. Colby.“Modeling a paranoidmind”.In: The Behavioral and Brain
Sciences 4 (1981), pp. 515–560.
[22] K. M. Colby and J. P. Gilbert. “Programming a computer model of neu-
rosis”. In: J. Math Psych 1 (1964), pp. 405–416.
[23] AdaAugustaCountessofLovelace.Notes on L. F. Menabrea’s “Sketch of
theanalyticalengineinventedbyCharlesBabbage”.http://imaginaryinstruments.org/lovelace-anal
Accessed 2024-04-18.Sept. 1843.
[24] G. Dyson. Turing’s cathedral. Vintage Books, 2012.
[25] C.Eisenmannetal.““MachineDown”:makingsenseofhuman–computer
interaction—Garfinkel’sresearchonELIZAandLYRICfrom1967to1969
anditscontemporaryrelevance”.In:AI&Soc(2023).doi:10.1007/s00146-023-01793-z.
[26] E.Feigenbaum.Aninformationprocessingtheoryofverballearning.Paper
P-1817.The RAND Corporation, 1959.
[27] H. Gelernter, J. R. Hansen, and L. L. Gerberich. “A Fortran-compiled
list-processing language”.In: JACM 7.2 (Apr. 1960), pp. 87–101.
[28] D. Gentner and A. L. Stevens. Mental models. Hillsdale, NJ: Lawrence
Erlbaum Associates, 1983.
[29] B.F. Green etal. “Baseball:An automatic question-answerer”.In: Name
of Journal or Conference Volume Number.Issue Number (1961). Addi-
tional Information, Page Numbers.
[30] F. J. Gruenberger. The history of the JOHNNIAC. RAND memorandum
RM-5654-PR.1968.
[31] P.Hayward.Flexible discussion under student control in the ELIZA com-
puter program. Educational Research Center, Massachusetts Institute of
Technology, Cambridge. 1967.
[32] D.R.Hofstadter.G¨odel,Escher,Bach:Aneternalgoldenbraid.NewYork:
Basic Books, 1979.
[33] P. McCorduck. Machines who think. W.H. Freeman and Co., 1979.
[34] M. T. McGuire, S. Lorch, and G. C. Quarton. “Man-machine natural
language exchanges based on selected features of unrestricted input—II.
Theuseofthetime-sharedcomputerasaresearchtoolinstudyingdyadic
communication”. In: J. Psychiat. Res. 5.2 (1967).
[35] A.NewellandH.A.Simon.“Computerscienceasempiricalinquiry:Sym-
bols and search”. In: Communications of the ACM 19.3 (1976), pp. 113–
126.
[36] S. North. “ELIZA”. In: Creative Computing (1977), pp. 100–103.
[37] C. Petzold. The annotated turing. Wiley, 2008.
[38] G.C.Quarton,M.T.McGuire,andS.Lorch.“Man-machinenaturallan-
guage exchanges based on selected features of unrestricted input—I. The
development of the time-shared computer as a research tool in studying
dyadic communication”. In: J. Psychiat. Res. 5.2 (1967).
22[39] R. C. Schank and R. P. Abelson. Scripts, plans, goals, and understand-
ing: An inquiry into human knowledge structures.Hillsdale,NJ:Lawrence
Erlbaum Associates, 1977.
[40] J. R. Searle. “Minds, brains, and programs”. In: Behavioral and Brain
Sciences 3.3 (1980), pp. 417–457.
[41] P. Seibel. Coders at Work. APress, 2009.
[42] SLIP: University of Michigan executive system for the IBM 7090 com-
puter. Vol. 2. University of Michigan Computing Center, 1965.
[43] E. F. Taylor. ELIZA: A skimmable report on the ELIZA conversational
tutoring system. EducationalResearchCenter,MassachusettsInstitute of
Technology, Cambridge. 1968.
[44] A. Turing. “Computing machinery and intelligence”. In: Mind 49 (1950),
pp. 433–460.
[45] D.WaldenandR.Nickerson,eds.Acultureofinnovation:Insideraccounts
of computing and life at BBN. A Sixty Year Report 18 October 1948 to 1
July 2010. Waterside Publishing, 201.
[46] J. Weizenbaum. Computer power and human reason. W.H. Freeman and
Co., 1976.
[47] J. Weizenbaum. “ELIZA—a computer program for the study of natural
languagecommunicationbetweenmanandmachine”.In:Communications
of the ACM 9.1 (1966), pp. 36–45. doi: 10.1145/365153.365168.
[48] J. Weizenbaum. “How to make a computer appear intelligent”. In: Data-
mation (Feb. 1962), pp. 24–26.
[49] J.Weizenbaum. “Symmetric list processor”.In: Comm. ACM 6.9(1963),
pp. 524–536.
23