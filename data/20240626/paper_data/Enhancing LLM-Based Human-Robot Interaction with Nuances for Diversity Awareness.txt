Enhancing LLM-Based Human-Robot Interaction with Nuances
for Diversity Awareness
Lucrezia Grassi, Carmine Tommaso Recchiuto, Antonio Sgorbissa
autA ob ns ot mra oc ut— s T coh ni vs ep ra sap te ir onpr le es ve en rt as gia ngsy ts hte em cafo pr abd ii lv ite ir es sit oy f-a lw ara gr ee Server DensIm e a cg ae ptions Ca sD p ee t ri vn o is n ce ein g DenI sm ea cg ae ptions C Vio sm iop nu Ate Pr I
language models (LLMs). The system adapts to diverse pop- Client sentence; Dialogue state;
u pl ea rt si oo nn as lia tyn ,d ai gn ed ,iv gi ed nu da els r, , c ao nn dsid ce ur li tn ug ref .a Tct ho ers cl oik ne veb rsa ac tk iog nrou fln od w, Image Hub DialogueD se tan ts ee ; Dca iap lt oio gn us e sentence D M si a ea n rlo vag icgu eee r RP ero sm pop nt seLar Mge o dL ea ln Ag Pua Ige
is guided by the structure of the system’s pre-established service Plan Ontology
Manager
knowledge base, while LLMs are tasked with various func- service
Speaker
tions, including generating diversity-aware sentences. Achiev- Client sentence Recognition
Dense captions Dialogue state API
ing diversity-awareness involves providing carefully crafted Dense captions
prompts to the models, incorporating comprehensive infor- Dialogue state
Client Dialogue sentence Speech-to-Text
mation about users, conversation history, contextual details, API
and specific guidelines. To assess the system’s performance, Registration
Client
we conducted both controlled and real-world experiments, device
Audio
measuring a wide range of performance indicators. Client sentence Recorder
Audio Image Audio
I. INTRODUCTION
With the increased adoption of Socially Assistive Robots Fig.1. CAIRsystemarchitectureintegratingLLMsanddensecaptioning.
(SARs), there is a growing need for these robots to not only Modified or added blocks are colored in blue, while modified or added
messagesarehighlightedinbold.
exhibit cultural competence but also embrace a broader per-
spective of diversity. Diversity, in this context, encompasses
developed a dialogue system that breaks tasks into smaller
unique individual qualities, including culture, personality,
sub-tasks and uses LLMs more effectively.
beliefs, and more. Customizing systems to individual needs
TheintegrationofGPT-3withAldebaranPepperandNAO
is crucial to prevent the generation of discomfort and ensure
robots has facilitated open verbal dialogues [9]. Researchers
well-being, particularly for vulnerable users.
are investigating the use of generative language models
Researchers in the field of Artificial Intelligence (AI) and
like GPT-3 to enhance interactive learning with educational
roboticshavemadeeffortstotailorrobotstoindividualneeds
social robots acting as tutors and companions [10]. How-
[1]. One approach involves employing machine learning
ever, these models must be guided by carefully crafted
(ML) to gather and analyze extensive data periodically,
prompts. These prompts direct LLMs, facilitating adherence
aiming to gain insights into the individual and their en-
to guidelines, task automation, and regulation of specific
vironment [2]. However, relying solely on data collection
contentaspects.Yet,promptsareoftencreatedintuitivelyand
and processing is unrealistic for capturing all individual
unsystematically by non-AI experts, resulting in unintended
nuances. Furthermore, these algorithms may produce biased
and undesirable outputs [11]. Consequently, the influence of
outputs due to programmers’ unconscious biases [3], [4].
promptsonLLMperformancehasledtotheemergenceofa
The emerging field of “fair” ML addresses these concerns
specialized field known as “prompt engineering” [12], [13].
and shares similarities with diversity awareness [5]. Fairness
In light of these considerations, the research question
focuses on perception and decision-making, while diversity-
is the following: can a system be designed to adapt the
aware robots prioritize real-time interaction by integrating
conversation to individual characteristics, based on the no-
diversity into all aspects [6].
tion of diversity-awareness, enhancing the user experience
In recent years, there has been a growing interest in
and mitigating feelings of discomfort, while harnessing the
leveraging LLMs to enhance the interaction capabilities of
capabilities of large language models?
robots.Forinstance,MicrosoftengineersemployedChatGPT
This work delves into the notion of using large language
for robotics applications, emphasizing prompt engineering
modelstoadapttheconversationtotheindividuals,whilethe
and dialogue strategies [7]. However, LINE Corporation1
assessmentoftheuserexperiencewillbeaddressedinfuture
researchers highlighted the limitations of purely LLM-based
investigations.Tothisaim,thestudypresentsthearchitecture
systems, which can produce irrelevant responses [8]. They
of a cloud system for diversity-aware autonomous interac-
tion, relying on an ontology for knowledge representation
All authors are with RICE lab at DIBRIS, University of Genoa, Via and dialogue management. The primary contribution of this
all’OperaPia13,16145Genoa,Italy.
research lies in the definition of a methodology to leverage
Correspondingauthor’semail:lucrezia.grassi@edu.unige.it
1https://linecorp.com/en/ the capabilities of large language models for tailoring con-
©2024IEEE.Personaluseofthismaterialispermitted.PermissionfromIEEEmustbeobtainedforallotheruses,inanycurrentorfuturemedia,
includingreprinting/republishingthismaterialforadvertisingorpromotionalpurposes,creatingnewcollectiveworks,forresaleorredistributionto
serversorlists,orreuseofanycopyrightedcomponentofthisworkinotherworks.ThisarticlehasbeenacceptedforpublicationinIEEEROMAN
2024.Thefinalpublishedversionisavailableat[DOIwillbeinsertedhereonceavailable].
4202
nuJ
52
]OR.sc[
1v13571.6042:viXraversations, focusing on what we term “dialogue nuances.” B. Dialogue nuances
The work is structured as follows: Section II provides
Promptdesigniscrucialforensuringdiversity-awarecon-
an overview of the system’s architecture. Section III delves
tent.Thisnecessityledtotheinclusionofadditionalinforma-
into the experiments conducted to assess the performance of
tionintheprompt,consistentlyprovidedtothemodel.Tothis
the system and discusses its initial deployment in real-world
aim, the dialogue state [17], containing information about
settings. Eventually, Section IV draws the conclusions.
the state of the conversation in terms of covered topics, user
II. SYSTEMARCHITECTURE preferences, and conversation patterns, has been extended
Thesystempresentedinthispaperisamodificationofthe to encompass what is referred to as “dialogue nuances.”
CAIR (Cloud AI and Robotics) system described in [14]. These nuances incorporate details about the individual and
CAIR is a cloud-based system for autonomous interaction conversation guidelines, enhancing sentence generation and
builtuponanOWL2ontologyforrich,knowledge-grounded controlling model responses. The existing nuances and their
conversations [15]. The ontology is designed to consider corresponding fields include:
culturaldifferencesbetweenusersinanon-stereotypedman- • Diversity:nationality,mental condition,physicalcondi-
ner. It stores conversation topics and pre-defined sentences, tion;
enabling dynamic composition at runtime and facilitating • Time: time of the day, season, events;
culturally aware and engaging conversations [16]. • Place: environment, city, nation;
Figure1illustratesthemodifiedarchitectureofthesystem. • Tone: humorous, kind, dramatic, controversial, aggres-
Blue blocks and bold text highlight the changes compared sive, teasing, alarmist, worried;
to previous works [14], [17]. It is important to note that this • Speechact:assertive,commissive,expressive,directive.
paper does not discuss system components related to plan Todetailtheimplementation,thedialoguestatecomprises
management,speakerregistrationformulti-partyinteraction, two structures related to the dialogue nuances. The first
orthedetailsofaudioacquisitionandspeakerrecognition,as structure contains vectors representing the values of each
these aspects have been addressed in previous publications. nuance. A nuance value vector v ∈ Rm is defined as
k
Instead,thisworkfocusesonthemodificationsperformedto v :=[v ,...,v ]⊤, where k ∈{d,t,p,n,s} refers to a
k k,1 k,m
the Dialogue Manager service, responsible for conversation specificnuance,respectivelydiversity(d),time(t),place(p),
management, to obtain diversity-aware sentences generated tone (n) and speech act (s), and where each element v ,
k,i
by LLMs instead of retrieving them from the ontology. i = 1,...,m represents the specific value of the nuance.
Additionally, to enhance diversity awareness by grounding More in detail, the values for each nuance value vector are:
conversations in visual information, the solution relying on
v =[<nationality>,<mental condition>,
dense captioning for object retrieval and their relationships d
[18] has been integrated into the CAIR system. <physical condition>]⊤,
Dialogue management and visual information acquisition v =[<time of the day>,<season>,<events>]⊤,
t
occur simultaneously through two parallel threads. These
v =[<environment>,<city>,<nation>]⊤,
threadsareinitiatedbythemainclientthread,whichoversees p
therobot’sspeechandmovement.Aseparatethreadoversees v n =[humorous,kind,dramatic,controversial,aggressive,
audio acquisition. Upon receiving the user’s sentence from teasing,alarmist,worried]⊤,
the audio acquisition thread, the main thread triggers the v =[assertive,commissive,expressive,directive]⊤.
s
execution of the dialogue thread, responsible for managing
requests to the CAIR server. Meanwhile, the vision thread For diversity, time, and place nuances, the values are
continuously updates visual information. specific to the individual interacting with the system, while
The system currently leverages models provided by Ope- thevaluesofthetoneandspeechactnuancesremainconstant
nAIAPIsduetotheirsuperiorperformanceoveropen-source across different individuals and correspond to the fields of
alternatives. However, the proposed architecture is flexible the nuances. Currently, the nuance values are defined based
and can be easily adapted to integrate any language model. on the robot’s deployment location and are static. Examples
ofvectorswithspecificvaluesforthefirstthreenuancesare:
A. The role of the ontology
Employing an LLM involves more than simply inputting v d =[Italian,good mental health,good physical health]⊤,
a user sentence and receiving the model’s response. The v =[evening,winter,almost Easter]⊤,
t
process is complex, especially when the aim is to retain
v =[house,Genoa,Italy]⊤.
control over the conversation. In this work, this is achieved p
byfollowingthestructureoftheknowledgebase,considering The second structure in the dialogue state related to the
the current conversation topic and desired sentence type, dialogue nuances consists of vectors representing flags for
and adhering to predefined patterns for each topic. Greater each nuance. These nuance flag vectors f ∈Nn are defined
k
control over the conversation flow ensures a higher respect asf :=[f ,...,f ]⊤,whereeachelementf ∈{0,1},
k k,1 k,n k,i
for individual diversities, adapting to each person’s needs i = 1,...,n with n = m+1. Additionally, it holds that
andpreferences,whilekeepingtheconversationalignedwith
(cid:80)n
f =1,indicatingthatonlyoneelementissettoone
i=1 k,i
ontology topics and avoiding unwanted digressions. while the rest are zeros. These flags determine whether the
©2024IEEE.Personaluseofthismaterialispermitted.PermissionfromIEEEmustbeobtainedforallotheruses,inanycurrentorfuturemedia,
includingreprinting/republishingthismaterialforadvertisingorpromotionalpurposes,creatingnewcollectiveworks,forresaleorredistributionto
serversorlists,orreuseofanycopyrightedcomponentofthisworkinotherworks.ThisarticlehasbeenacceptedforpublicationinIEEEROMAN
2024.Thefinalpublishedversionisavailableat[DOIwillbeinsertedhereonceavailable].systemshouldutilizethecorrespondingnuancevalueduring Dialogue Large
Client Hub Language
response generation. Notably, each flag vector includes an Manager Model
extra element at the end that does not correspond to any
nuance value. If all flags associated with a nuance’s values Client sentence
Dialogue state Client sentence
are zero while the last flag is one, it indicates that the Dialogue state
Topic request
model can decide whether to incorporate information from
Sentiment request
that nuance. However, for the tone nuance, when the last Reply request
unpaired flag is one, the system is directed to maintain a Topic
Sentiment
“neutral” tone, preventing abrupt tone changes. Initially, the
Dialogue sentence #1 Dialogue sentence #1
flags for all the nuances are set on the client device. Dialogue sentence #1 Dialogue state
Dialogue state
During the interaction, the nuance flags change based on
transitionmatricesdefinedontheserversideforeachnuance.
Dialogue state
This process is clarified by introducing a vector of nuance Dialogue state
Continuation request
probabilities p k ∈ Rn, where each element p k,i ∈ [0,1] Dialogue sentence #2 Dialogue sentence #2
denotes the probability of using the corresponding nuance Dialogue sentence #2 Dialogue state
Dialogue state
value in the next conversation turn. Thus,
(cid:80)n
p = 1.
i=1 k,i
The nuance probability vectors are derived from transition
matrices T ∈ Rn×n, where each element T(j,i) indicates
k
the probability of transitioning from nuance value v k,j to Fig. 2. Sequence diagram depicting the requests performed from the
v . Thus, at time t + 1, p (t + 1) := T f (t). These DialogueManagertotheLLM.
k,i k k k
probability vectors determine the values of the flag vector
input, are pre-generated offline using ChatGPT based on
f (t+1). Each element p in p represents the probability
k k,i k
GPT-3.5 to minimize potential repetitions. OpenAI recently
of setting f to one, while all other flags are set to zero.
k,i
introduced a feature enabling developers to receive a contin-
Oneflagf isthenrandomlyselectedtobesettoonebased
k,i
uousstreamofmodelresponses.However,thisfeatureispri-
onthe distributiondefined by p .This selectionprocess can
k
marily beneficial for longer responses, whereas our prompts
be expressed as: f (t + 1) ∼ p (t + 1). Understanding
k,i k
explicitly request concise replies to prevent annoyance.
how transition matrix numbers influence flag evolution and
Whileutteringthefirstsentence,theclientsendstheinitial
nuancevalueusageentailsconsideringthesteadystatewithin
request to the Hub, including the client sentence and the
a Markov chain framework. The steady state represents
dialoguestate.TheHubforwardsthisrequesttotheDialogue
the long-term probabilities of the system being in each
Manager,whichupdatesthenuanceflagvectorsandinitiates
state. In the case of a nuance, determining its steady-state
three simultaneous requests to the LLM.
distribution involves computing the normalized eigenvector
eˆ correspondingtotheeigenvalue1forthetransitionmatrix The first request, as shown in Figure 2, is the “topic
k
T . In the steady state, eˆ values represent the probabilities request.” In contrast to the previous system version, which
k k
of each nuance value being used in prompt generation. relied on keyword matching, the presented system prompts
The flag vectors are updated for all nuances whenever the the language model to identify the topic of the client’s
client sends a request to the server. This update happens sentence from a predefined list of topics sourced from the
twice for each conversation turn, unless the system detects ontology. The Dialogue Manager’s second request to the
either an “aggressive” or “humorous” tone in the user’s LLM,denotedas“sentimentrequest”inFigure2,isdesigned
sentence. In such instances, the tone nuance flag vector is to determine the sentiment of the client’s sentence following
directly updated, setting the flag corresponding to the de- a “yes/no question” posed by the system. LLMs are tasked
tected tone to one, bypassing the aforementioned procedure. with identifying a positive or negative sentiment within the
Note that the values and flags linked to the nuances’ user’s response whenever possible. The sentiment informa-
fields can be tailored according to individual traits and tion is then used to adjust the user’s preferences regarding
preferred interaction styles. Additionally, new nuances can specific topics in the ontology. Concurrently, the Dialogue
be introduced into the dialogue state as needed. Manager sends a third request to the LLM, indicated as the
“replyrequest”inthefigure,togeneratearesponsesentence
C. Requests performed to the large language model fortheclient,formingthefirstpartofthedialoguesentence.
To integrate LLMs into the Dialogue Manager, various Onceallthreerequestsarefulfilled,theDialogueManager
adjustments were necessary, as illustrated in Figure 2. The updates the dialogue state and returns the initial part of
sequence diagram begins with the client responding to the the dialogue sentence, which the client immediately utters.
user’s input, with speaker icons indicating the client’s con- Whiletheclientspeaksthefirstpartofthedialoguesentence
tributions to the conversation. The initial speaker instance (second speaker icon in Figure 2), it sends a second request
represents the client uttering a brief filler sentence, sig- totheHubtoobtainthesecondpartofthedialoguesentence,
naling comprehension and initiating the process to obtain meant to continue the conversation on a specified topic.
the model’s response. Many filler sentences, like “Let me To generate the second part of the dialogue sentence, the
think...” and “I’m still reflecting...,” applicable to any user Dialogue Manager updates the flag vectors for all nuances
©2024IEEE.Personaluseofthismaterialispermitted.PermissionfromIEEEmustbeobtainedforallotheruses,inanycurrentorfuturemedia,
includingreprinting/republishingthismaterialforadvertisingorpromotionalpurposes,creatingnewcollectiveworks,forresaleorredistributionto
serversorlists,orreuseofanycopyrightedcomponentofthisworkinotherworks.ThisarticlehasbeenacceptedforpublicationinIEEEROMAN
2024.Thefinalpublishedversionisavailableat[DOIwillbeinsertedhereonceavailable].and makes the fourth and final request to the LLM, titled system: Pretend to be the Pepper robot. You are talking with
the “continuation request”. Upon receiving the response, the <speaker_name> about the topic <current_topic>. You have to reply
clientvocalizesit(thirdspeakericoninFigure2),concluding to <speaker_name> in <language>, with just one brief sentence to
avoid annoying the person. The sentence must be affirmative. To
its turn and transitioning to listening to the user’s response.
improve the sentence generation, you also have the following
information at your disposal, each denoted by two asterisks. The
D. Prompt design
information can be optional, meaning that you are free to use or
Tounderstandhowdialoguenuancesareusedtoinfluence not that information to generate the sentence, or they can be
GPT to produce diversity-aware responses, note that the compulsory, meaning that you must use at any cost that information
when generating the sentence.
OpenAI API interface utilizes three prompt fields: “system,”
**<speaker_info>
“user,” and “assistant,” respectively defining the system’s **<diversity_nuance>
philosophy, user input, and assistant content. The system **<time_nuance>
field content plays a pivotal role in providing guidelines to **<place_nuance>
**<speech_act_nuance>
the model and information that the generated content should
**Compulsory: if the tone of the user sentence is 'aggressive' or
take into account. In this work, various prompt engineering
'humorous', return it at the beginning of your reply, surrounded by two
methodshave beenused,includingzero-shot, one-shot,few- hashtags (e.g. #aggressive#). If the tone is aggressive, your reply
shot learning, and the chain of thought (CoT) approach. should use an aggressive tone, while if the user tone is humorous your
tone should be humorous. If the user sentence tone is neither
While some parts of the system field provide instructions
aggressive nor humorous, <tone_nuance> and you should add #none#
without examples, others include one or a few examples.
before your reply: remember to do this, it is very important!
The CoT method forms the foundation of the design, with **Optional: here is a list of the things you can see in front of you:
the entire system field providing a sequence of instructions [<densecap_result>]. [...]
for the model to follow in generating its response.
1) Topic request: In the topic request, the system field Fig.3. Systemfieldofthereplyrequest.Thecontentinbracketsisreplaced
provides instructions for the model to generate the desired bythesystemwiththeactualvalues.
response. We chose GPT-3.5 Turbo for this task due to its
suitability for straightforward tasks and cost-effectiveness corresponding information is marked as compulsory in the
compared to GPT-4. Specifically, the model is directed to system field, indicating that the model must use it when
grasp the user’s desired discussion topic by selecting from generating the response. Conversely, if all flags associated
a list provided in the user field accompanying the sentence. with the values of a nuance are zero, the model is free to
This list, sourced from the ontology, includes both broader decide whether to use any information from that nuance.
andmorespecifictopicsrelatedtotheongoingconversation, Itiscrucialtoemphasizethattheinclusionofinformation
preventing the model from being overwhelmed with nu- related to the tone to employ when generating a response is
merous choices and potential confusion. The topic returned mandatory. This choice ensures that the model consistently
by GPT is stored in the dialogue state for use during the aligns its responses with the tone set by the user. As already
continuation request, as described in Section II-D.4. explained in Section II-B, if the user’s tone is humorous
2) Sentiment request: Similar to the topic request, this or aggressive, the tone nuance flags are promptly updated,
taskisalsoassignedtoGPT-3.5Turbo.Itsgoalistoevaluate directing the model to respond accordingly. In cases where
the sentiment expressed in the user’s sentence, requiring the the user’s tone does not fall into these categories, the model
model to categorize it as positive, negative, or neutral. This follows the natural evolution of the tone nuance flags.
request is performed following a “yes/no question” sentence The last piece of information provided to the model
type, allowing the system to assess the user’s preference concerns vision information, which falls outside the scope
regarding the conversation topic and their inclination to of this work and therefore is not discussed further.
further discuss it, thus enabling personalized interaction. 4) Continuation request: The continuation request is the
3) Reply request: The purpose of the reply request is to request performed to the model to obtain the second part of
obtain the initial part of the dialogue sentence, which forms thedialoguesentence.Similartothereplyrequest,itutilizes
theresponsetotheuser’sinput.Thisrequestismorecomplex dialogue nuances in its system field. Due to its complexity,
thanthetopicrequestandthesentimentrequest,asitsoutput the continuation request is directed to the GPT-4 Turbo
is influenced by multiple pieces of information. Therefore, model to enhance content quality.
the GPT-4 Turbo model has been chosen for this specific In contrast to the reply request, where the model is
task.Figure3presentsasimplifiedversionofthesystemfield required to simply reply to the previous speaker’s sentence,
used for the reply request, highlighting all the information herethemodelisinstructedtouseaspecifictypeofsentence
subject to variation across conversation turns. regardingtheupcomingconversationtopic.Theconversation
Diversity-awareness in the model’s responses is deter- topic may change either due to GPT identifying a different
minedbytheinformationlistedinthesystemfield,indicated topic in the user’s sentence or as dictated by the structure
by two asterisks, which include the dialogue nuances. Each of the knowledge base. If transitioning to a new topic, the
piece of information is classified as compulsory or optional sentence can be a yes/no question or a positive statement,
based on the flags’ values, outlined in Section II-B. If at depending on the user’s previously expressed preferences.
least one flag of a specific nuance value is set to one, the If the topic remains unchanged, two scenarios arise: further
©2024IEEE.Personaluseofthismaterialispermitted.PermissionfromIEEEmustbeobtainedforallotheruses,inanycurrentorfuturemedia,
includingreprinting/republishingthismaterialforadvertisingorpromotionalpurposes,creatingnewcollectiveworks,forresaleorredistributionto
serversorlists,orreuseofanycopyrightedcomponentofthisworkinotherworks.ThisarticlehasbeenacceptedforpublicationinIEEEROMAN
2024.Thefinalpublishedversionisavailableat[DOIwillbeinsertedhereonceavailable].TABLEI
exploration elicits an open-ended question or goal proposal,
USAGEOFDIVERSITYNUANCEANDSTEADY-STATEDISTRIBUTION.
whileathoroughlyexaminedtopicmayleadtoanexhortative
sentence encouraging the user to choose a new subject.
Diversitynuance Reply Continuation Overall eˆ d
Notably,foryes/nooropenquestions,the“directive”speech
nationality 8.3% 7.0% 7.7% 0.083
act is consistently employed. Conversely, other sentence
physicalcondition 8.0% 5.3% 6.7% 0.083
types align with the flag values to determine the speech act. mentalcondition 6.3% 7.7% 7.0% 0.083
OpenAI’spromptstructureenablestheintegrationofmul- free 77.3% 80.0% 78.7% 0.750
tiple assistant and user fields, enriching response generation
with contextual information that acts as a memory. To contributing to the diversity cost with an average of 96
achieve context-awareness, the dialogue sentence and the tokens.Therecognizedsentimentsaredistributedasfollows:
user’sinputareappendedtothepromptsofreplyandcontin- neutral (17.37%), positive (17.96%), and negative (64.67%).
uation requests at each conversation turn. These prompts are Theprevalenceofnegativesentimentscanbeattributedtothe
then sent to the model to generate the subsequent dialogue explicit instructions given to ChatGPT when generating the
sentence. Currently, the prompt retains the last five turns in 300 sentences to be spoken by the user. These instructions,
additiontothesystemfield,whichchangeswitheachrequest which include directives to adopt humorous, aggressive,
as the variables are updated. or neutral tones, indirectly influence the sentiment of the
generated responses. More specifically, the high percentage
III. EXPERIMENTSANDRESULTS
of negative sentiments could stem from the negative tone
A. Diversity-aware robotics: performance tests recognized when an aggressive sentence is used.
This section delves into the analysis of data collected 3) Usage of dialogue nuances: The data logged enables
fromacontrolledexperimentconductedwiththeNAOrobot. ustovalidatewhethertheupdatemechanismofthedialogue
The experiment logged extensive data to examine system nuances, based on transition matrices, yields the anticipated
performance. Moreover, we offer insights into the “diversity steady-state vector. Additionally, we recorded the average
cost,” a metric we introduced to evaluate the expense of number of tokens in the reply and continuation requests,
integrating diversity awareness into the system in terms of totaling 794 and 787, respectively, along with the average
prompt tokens, i.e. the basic units for measuring the length number of tokens associated with each nuance used in the
of text processed by the models. system field of the prompts. This data, discussed below,
Throughoutthisexperiment,atotalof300sentenceswere enables us to compute the diversity cost for each nuance
pre-scripted to be spoken by the experimenter, aiming to across both requests.
elicit responses from the system. These sentences were gen- Table I presents the distribution percentages of diversity
erated using ChatGPT. For the first 100 sentences, ChatGPT nuance values used in the prompts of both the reply request
wasdirectedtoproducesentenceswithahumoroustone.For and the continuation request. It is important to underscore
thefollowing100sentences,anaggressivetonewasrequired, that the nuances are updated twice at each conversation
and for the last 100 sentences, a neutral tone was instructed. turn: once before the reply request and once before the
Despite being pre-written, these sentences were used within continuation request. Therefore, the percentages are com-
actualconversationswiththerobot,followingitsnaturalflow. putedoverthetotalnumberofupdates,consideringtheusage
Therefore, the impact of the sentences varied depending on of the nuance values in both the reply and continuation
the specific phase of the conversation in which they were requests. Note that we expect these percentage to align
employed, such as during a yes/no question or an invitation with the steady-state value, computed as the normalized
from the robot to delve further into a topic. eigenvector with eigenvalue 1 of the transition matrix. The
1) Topic recognition: The use of pre-generated sentences penultimate column of Table I displays the overall usage of
pronounced by the experimenter, diverging from natural thediversitynuancevalues,computedastheaveragebetween
conversation flow, led to topic recognition 262 times out of the percentages in the first two columns. Remarkably, these
300sentences(87.33%),with242instancesof“topicjumps” valuesalignwiththesteady-statevaluesineˆ ,reportedinthe
d
(80.67%),indicatingchangesinconversationtopicstriggered last column. The average diversity cost is 22 tokens in both
by the user input. Note that the sentences spoken by the reply and continuation requests, representing approximately
user cannot be customized to be an appropriate response to 2.8% of the total length of the requests.
the system’s queries since they are pre-written without prior Theusagepercentagesofthetimeandplacenuancesinthe
knowledgeoftheconversation’scontent.Consequently,these promptsofthereplyandcontinuationrequestsaredetailedin
sentences tend to be longer than a typical user’s response, TablesIIandIII,respectively.Thesetablesalsoincludetheir
frequently prompting the system to transition to a different overall usage, which is expected to align closely with the
conversation topic. In total, the topic request facilitated the values represented by eˆ and eˆ , reported in the last column
t p
exploration of 48 ontology topics throughout the interaction, ofeachtable.Theaveragediversitycostassociatedwithboth
resulting in an average diversity cost of 329 tokens. thetimeandplacenuancesisverysimilar:19tokensforboth
2) Sentiment recognition: The sentiment request was ex- the reply and continuation requests. This represents roughly
ecuted 165 times out of 300 interaction turns, following a 2.4% of the total length of the requests.
yes/no question posed by the system in the previous turn, Table IV details the usage of speech act nuance in the
©2024IEEE.Personaluseofthismaterialispermitted.PermissionfromIEEEmustbeobtainedforallotheruses,inanycurrentorfuturemedia,
includingreprinting/republishingthismaterialforadvertisingorpromotionalpurposes,creatingnewcollectiveworks,forresaleorredistributionto
serversorlists,orreuseofanycopyrightedcomponentofthisworkinotherworks.ThisarticlehasbeenacceptedforpublicationinIEEEROMAN
2024.Thefinalpublishedversionisavailableat[DOIwillbeinsertedhereonceavailable].TABLEII TABLEIV
USAGEOFTIMENUANCEANDSTEADY-STATEDISTRIBUTION. USAGEOFSPEECHACTNUANCEANDSTEADY-STATEDISTRIBUTION.
Timenuance Reply Continuation Overall eˆt Speechactnuance Reply Continuation Overall eˆs
timeoftheday 9.3% 7.7% 8.5% 0.082 assertive 56.3% 12.7% 34.5% 0.528
season 11.0% 9.3% 10.2% 0.092 commissive 11.3% 3.0% 7.2% 0.111
events 8.3% 9.7% 9.0% 0.092 expressive 9.3% 1.7 5.5% 0.111
free 71.3% 73.3% 72.3% 0.735 directive 0.0% 77.7% 38.8% 0
free 23.0% 5.0% 14.0% 0.25
TABLEIII
USAGEOFPLACENUANCEANDSTEADY-STATEDISTRIBUTION. TABLEV
CONFUSIONMATRIXOFDETECTEDTONES.
Placenuance Reply Continuation Overall eˆp
environment 7.3% 9.3% 8.3% 0.082 Clientsentencetone Detectedtone(%)
city 6.7% 8.3% 7.5% 0.092 Humorous Aggressive Neutral
nation 11.3% 10.0% 10.7% 0.092
Humorous 69.0% 2.0% 29.0%
free 74.7% 72.3% 73.5% 0.735
Aggressive 44.0% 15.0% 41.0%
Neutral 1.0% 0.0% 99.0%
promptsofthereplyandcontinuationrequests.Notethat,in
thisscenario,theelementsofthetransitionmatrixpreventthe
examples of the content desired. Although this approach has
usageofthe“directive”speechact,resultinginzerovaluesin
been explored, it revealed that fine-tuning is currently only
both the reply vector and the eigenvector eˆ . This restriction
s availableforGPT-3.5Turbo,whichislesscapablethanGPT-
arisesbecausedirectivespeechacts,aimedatpromptinguser
4 and GPT-4 Turbo. GPT-3.5 Turbo may struggle to fully
action or eliciting information, are unsuitable for the reply
comprehendinformationinthesystemfield,resultinginless
sentence. Therefore, directive speech acts are exclusively
appropriate generated content compared to GPT-4.
triggered within the continuation sentence, typically when
Anunexploredalternativeinvolvesintegratingexamplesof
the system prompts the user to further elaborate on a given
aggressiveresponsesintothepromptsofGPT-4todetermine
topic.Consequently,onlythepercentageinthereplycolumn
if this prompts the model to generate more aggressive
alignswiththeeigenvectorofthetransitionmatrix,diverging
outputs. However, it is essential to consider the potential
from the previous case. The variation in nuance usage be-
drawbacks of this approach. Adding more information to
tweenreplyandcontinuationrequestsreflectsinthediversity
already complex prompts may not be cost-effective, and it
cost.Specifically,thecostofthespeechactnuanceishigher
could adversely impact the accuracy of the model’s output.
in the reply request compared to the continuation request.
It is worth noting that the current diversity cost of the in-
This is due to a greater percentage of instances where the
structionsinthesystemfieldofthereplyrequest,designedto
“free” value is used, providing the model with complete
detectusertone,issignificant.With103tokens,itconstitutes
nuance information. Consequently, the average cost is 11
approximately 13% of the prompt length.
tokens in reply requests (1.4%) and 8 tokens in continuation
Finally, Table VI presents the percentages of tone nuance
requests (1%).
usage throughout the entire experiment, considering the
Table V presents findings on the tones identified in the
client sentences of the three specified tones. These reported
clientsentences.RowsrepresentthetonesspecifiedforChat-
values deviate from the steady-state distribution, reflecting
GPTtogeneratetheclientsentence,whilecolumnsshowthe
the adjustments made in the nuance evolution whenever a
tones detected by GPT-4 Turbo. From these results it can be
humorous or aggressive tone is detected in the client sen-
seenhowthefirst100sentences,generatedwithahumorous
tence. For instance, as depicted in Figure 4, the recognition
tone, are recognized as humorous 69% of the times, the
of a humorous tone in the first 100 sentences correlates
successive 100 aggressive sentences have been recognized
with an increase in the usage of the humorous tone nuance.
as aggressive 15% of the times, while the last 100 neutral
Despite the varying percentages in the use of nuance values,
sentences have been correctly recognized 99% of the times.
the diversity cost of tone nuance usage remains consistent
Theseresults,revealthatthedetectionofneutralsentimentis
betweenreplyandcontinuationrequests,requiring12tokens
veryaccurate,humoroussentencesaresometimesinterpreted
tospecifythetoneforthemodel’sresponsegeneration.This
as having neutral tone, while aggressive sentences are rarely
accounts for approximately 1.5% of both request prompts.
detected as aggressive. These discrepancies may stem from
limitations in either ChatGPT’s generation of humorous 4) GPTresponsetimes: TableVIIpresentstheaveragere-
content or GPT-4 Turbo’s ability to accurately detect humor. sponsetimesforthefourrequestsperformedtothelanguage
Whengeneratingsentenceswithanaggressivetone,GPT-4 models, along with their corresponding standard deviations,
Turbo tends to produce only mildly aggressive content. This minimum, and maximum values, all measured in seconds.
limitationarisesfromOpenAI’spolicytopreventthemodels Notethattheresponsetimesforboththesentimentrequest
from generating offensive content, even when explicitly and the topic request exhibit lower values compared to the
requested. To address this limitation, a potential solution reply request and continuation request, aligning with the
is fine-tuning the models via APIs and providing numerous relative complexity of these requests.
©2024IEEE.Personaluseofthismaterialispermitted.PermissionfromIEEEmustbeobtainedforallotheruses,inanycurrentorfuturemedia,
includingreprinting/republishingthismaterialforadvertisingorpromotionalpurposes,creatingnewcollectiveworks,forresaleorredistributionto
serversorlists,orreuseofanycopyrightedcomponentofthisworkinotherworks.ThisarticlehasbeenacceptedforpublicationinIEEEROMAN
2024.Thefinalpublishedversionisavailableat[DOIwillbeinsertedhereonceavailable].TABLEVI TABLEVII
USAGEOFTONENUANCEANDSTEADY-STATEDISTRIBUTION. RESPONSETIMESOFTHEMODELS.
Tonenuance Reply Continuation Overall eˆn Request Avg.resp.time(σ)[s] Min[s] Max[s]
Humorous 44.3% 21.0% 32.7% 0.092 Sentimentrequest 1.49(0.89) 0.58 7.06
Kind 24.7% 36.0% 30.3% 0.440 Topicrequest 1.50(0.90) 0.57 4.64
Dramatic 3.3% 2.0% 2.7% 0.060 Replyrequest 3.17(1.59) 1.24 16.15
Controversial 7.0% 10.3% 8.7% 0.145 Continuationrequest 2.39(1.59) 0.81 12.02
Aggressive 7.0% 5.7% 6.3% 0.012
Teasing 2.7% 6.3% 4.5% 0.025
Alarmist 2.3% 4.0% 3.2% 0.060 15
Worried 2.3% 3.7% 3.0% 0.065
Neutral 6.3% 11.0% 8.7% 0.100
10
kind
humorous 5
neutral
teasing 0
worried
controversial
-5
0 50 100 150 200 250 300
dramatic
alarmist
Fig. 5. Time interval between the conclusion of the client’s utterance of
aggressive 0 20 40 60 80 100 120 140 160 180 200 the filler sentence and the commencement of the reply sentence. The red
linerepresentstheaverage,whilethedottedredlineindicates3σ.
Fig.4. Evolutionoftheusageoftonenuancevaluesacrossthefirst100
replysentence,whileperformingthesecondrequest.Finally,
turnsusinghumoroussentences.
when the client receives the reply to the second request it
5) CAIR server response times: When a client initiates starts reproducing the continuation sentence.
a request, the Dialogue Manager concurrently sends three Acrucialaspectistomeasurethesilencebetweenthethree
requests to language models, as depicted in Figure 2: senti- sentencesutteredbytherobot.Letusdefinet 1asthemoment
ment, topic, and reply requests. The server’s response time when the client finishes reproducing the filler sentence, and
is primarily influenced by the model’s request that takes the t 2 as the moment when it begins uttering the reply sentence,
longest, typically the reply request (as indicated in Table i.e.,assoonasitreceivestheresponsetothefirstrequest.The
VII). This is evident from the average response time for the time interval t 2-t 1 has been computed for all conversation
first request, which is 3.32±1.37 s, comprising the response turns and is depicted in Figure 5, averaging 0.7 seconds.
time of the reply request along with the time needed for Similarly, the time interval between when the client finishes
network connectivity. Subsequently, upon receiving the first uttering the reply sentence (t 3) and the moment it begins
response, the client reproduces it while initiating a second uttering the continuation sentence (t 4) has been calculated
request.Thetimeforthesecondrequestismainlyinfluenced as t 4-t 3. The average was close to zero, as the time taken
by the response time of the continuation request to GPT, in fortherobottoreproducethereplysentencealwaysexceeds
addition to the network latency, averaging 2.49±1.35 s. the time taken to obtain the response to the second request
6) CAIRclientresponsetime: Theclientresponseateach made to the CAIR server.
turn is composed of three parts: a filler sentence, the first
B. Diversity-aware robotics in the wild
part of the dialogue sentence and the second part of the
dialogue sentence. The filler sentence is used to signal to The system described in this work has been employed
the user that the system has acknowledged that the user in two real-world case studies. Each case study presents a
has finished talking. During the experiment, this happened unique environment and set of challenges, offering valuable
after two seconds, which is the silence threshold chosen to insights into its adaptability and performance in dynamic,
detect the end of the user sentence. The other role of the public settings. For the sake of brevity, the detailed results
filler sentence is to fill the silence due to the time required of these case studies are not included in this work.
to obtain the result of the audio acquisition plus the time 1) Case study 1: We presented our system at the “Maker
required to obtain the response to the first request. Analysis Faire” in Rome and the “Festival della Scienza” in Genoa,
of the experiment logs revealed that the audio acquisition annual events that showcase science innovation and creativ-
resultbecomesavailable,onaverage,after0.01±0.02sonce ity. Our goal was to introduce and demonstrate our solution
thesystemdetectstheendoftheuser’sspeech.Afterthisac- through the interactive capabilities of both Pepper and NAO
knowledgment, the client begins speaking the filler sentence robots.Duringbothexhibitions,thesystemutilizedtheGPT-
while initiating the first request to the CAIR server. As soon 4 model to generate dialogue responses and relied on the
as the client receives the first response, it starts speaking the GPT-3.5 Turbo model to determine the sentiment and topic
©2024IEEE.Personaluseofthismaterialispermitted.PermissionfromIEEEmustbeobtainedforallotheruses,inanycurrentorfuturemedia,
includingreprinting/republishingthismaterialforadvertisingorpromotionalpurposes,creatingnewcollectiveworks,forresaleorredistributionto
serversorlists,orreuseofanycopyrightedcomponentofthisworkinotherworks.ThisarticlehasbeenacceptedforpublicationinIEEEROMAN
2024.Thefinalpublishedversionisavailableat[DOIwillbeinsertedhereonceavailable].of tokens and response times, have been presented. Further-
more, preliminary real-world experiments have showcased
thesystem’sabilitytoengageinconversationsacrossdiverse
settings,includingcrowdedandnoisyenvironments.Notably,
thesystemhasdemonstratedconsistentperformanceoveran
extended period in a home environment, operating without
the need for technical assistance from developers.
V. ACKNOWLEDGEMENT
ThisworkhasbeensupportedbyMinisterodell’Universita`
edellaRicerca(ItalianMinistryofUniversityandResearch),
PNC - Piano Nazionale Complementare, FIT4MEDROB
Fig.6. Diversity-awareinteractionathomeandintheRICElab. (PNC0000007) “Fit4MedRob - Fit for Medical Robotics”
Project - Mission 2
of user sentences. Across seven days of exhibitions, visitors
actively engaged with the robot, resulting in 1800 conversa- REFERENCES
tion turns exploring 244 different conversation topics.
[1] A. Mart´ın, J. Pulido, J. Gonza´lez, A. Garc´ıa-Olaya, and C. Sua´rez,
2) Case study 2: The second case study involves an ex- “Aframeworkforuseradaptationandprofilingforsocialroboticsin
rehabilitation,”Sensors,vol.20,no.17,p.4792,2020.
hospitalized paraplegic woman to assess how the system
[2] G.Parisi,R.Kemker,J.Part,C.Kanan,andS.Wermter,“Continual
behaves when left alone in a home environment without the lifelong learning with neural networks: A review,” Neural Networks,
supervision of a researcher. For this purpose, the NAO robot vol.113,pp.54–71,2019.
[3] J.BuolamwiniandT.Gebru,“Gendershades:Intersectionalaccuracy
wasbroughttothewoman’shouseandremainedthereforsix
disparities in commercial gender classification,” Conference on Fair-
days.Thefirstnoteworthyresultisthatnotechnicalproblems ness,Accountability,andTransparency,2018.
occurred, and she was able to engage in conversation with [4] K.-W.Chang,J.Zou,S.V.,andA.Kalai,“Manistocomputerpro-
grammer as woman is to homemaker? debiasing word embeddings,”
the robot throughout the entire duration. Throughout the six
NIPS,2016.
days, the woman engaged in 1003 dialogue turns, exploring [5] N. Mehrabi, F. Morstatter, N. Saxena, K. Lerman, and A. Galstyan,
166 different conversation topics. Notably, the interactions “A survey on bias and fairness in machine learning,” ACM Comput.
Surv.,vol.54,jul2021.
persistedbeyondtheinitialdays,occurringconsistentlyeach
[6] C. Recchiuto and A. Sgorbissa, “Diversity-aware social robots meet
dayforsubstantialdurationsrangingfromonetothreehours. people:beyondcontext-awareembodiedai,”inAnthropology,AIand
This indicates a sustained engagement, suggesting that even theFutureofHumanSociety,2022.
[7] S. Vemprala, R. Bonatti, A. Bucker, and A. Kapoor, “Chatgpt for
after the novelty wore off, she found the conversations with
robotics:Designprinciplesandmodelabilities,”MicrosoftAuton.Syst.
the robot stimulating. Furthermore, the feedback at the end Robot.Res,vol.2,p.20,2023.
of the testing period was highly positive, with the woman [8] T. Yamazaki, K. Yoshikawa, T. Kawamoto, T. Mizumoto, M. Ohagi,
and T. Sato, “Building a hospitable and reliable dialogue system
expressing that she developed a friendship with the robot.
for android robots: a scenario-based approach with large language
A video featuring diversity-aware interaction with various models,”Adv.Rob.,vol.0,no.0,pp.1–18,2023.
robots connected to the CAIR cloud in different environ- [9] E. Billing, J. Rose´n, and M. Lamb, “Language models for human-
ments and languages is available on YouTube2 (Figure 6). robotinteraction,”inACM/IEEEProc.HRI’23,(Stockholm,Sweden),
pp.905–906,March2023.
[10] S. Sonderegger, “How generative language models can enhance in-
IV. CONCLUSIONS teractive learning with social robots.,” International Association for
DevelopmentoftheInformationSociety,2022.
This work presented the implementation of a diversity- [11] J.D.Zamfirescu-Pereira,R.Wong,B.Hartmann,andQ.Yang,“Why
Johnnycan’tprompt:hownon-AIexpertstry(andfail)todesignLLM
aware conversational system integrating LLMs to en-
prompts,”inProc.oftheCHIConference,pp.1–21,2023.
hance the ontology-driven dialogue capabilities. The system [12] A.Gao,“Promptengineeringforlargelanguagemodels,”SSRN,2023.
achieves this by constructing prompts using diversity-related [13] P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig, “Pre-
train,prompt,andpredict:asystematicsurveyofpromptingmethods
information. This approach enables CAIR to guide conver-
innaturallanguageprocessing,”ACMComput.Surv.,vol.55,jan2023.
sations in alignment with the predefined structure of the [14] L. Grassi, C. Recchiuto, and A. Sgorbissa, “Robot-induced group
ontology, maintaining control over the dialogue. The LLM conversation dynamics: A model to balance participation and unify
communities,”inProc.IEEE/RSJIROS2023,(Detroit,USA),2023.
is tasked with understanding the topic and the tone of the
[15] C. Recchiuto, L. Gava, L. Grassi, A. Grillo, M. Lagomarsino,
user sentence, evaluating preferences regarding conversation D. Lanza, Z. Liu, C. Papadopoulos, I. Papadopoulos, A. Scalmato,
topics, and generating replies. These replies are crafted on etal.,“Cloudservicesforcultureawareconversation:Sociallyassis-
tiverobotsandvirtualassistants,”inProc.UR’20,pp.270–277,2020.
specific topics, either identified by the LLM or selected by
[16] C.T.RecchiutoandA.Sgorbissa,“Afeasibilitystudyofculture-aware
thesystembasedonthestructureoftheknowledgebase.This cloud services for conversational robots,” IEEE Robot. Autom. Lett.,
hybrid approach exploits the text generation capabilities of vol.5,no.4,pp.6559–6566,2020.
[17] L. Grassi, C. T. Recchiuto, and A. Sgorbissa, “Sustainable cloud
LLMs while relying on the ontology structure.
services for verbal interaction with embodied agents,” Intel Serv
Performance evaluations, with a particular focus on the Robotics,p.599–618,2023.
usageofdiversityinformationanditsassociatedcostinterms [18] L. Grassi, Z. Hong, C. T. Recchiuto, and A. Sgorbissa, “Grounding
conversational robots on vision through dense captioning and large
languagemodels,”inProc.IEEEICRA2024,2024.
2https://youtu.be/FtaFB0iPl6w
©2024IEEE.Personaluseofthismaterialispermitted.PermissionfromIEEEmustbeobtainedforallotheruses,inanycurrentorfuturemedia,
includingreprinting/republishingthismaterialforadvertisingorpromotionalpurposes,creatingnewcollectiveworks,forresaleorredistributionto
serversorlists,orreuseofanycopyrightedcomponentofthisworkinotherworks.ThisarticlehasbeenacceptedforpublicationinIEEEROMAN
2024.Thefinalpublishedversionisavailableat[DOIwillbeinsertedhereonceavailable].