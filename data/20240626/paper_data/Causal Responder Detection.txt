Causal Responder Detection
Tzviel Frostig∗1, Oshri Machluf†1, Amitay Kamber1, Elad
Berkman1, and Raviv Pryluk1
1Research Department, PhaseV
June 26, 2024
Abstract
Weintroducethecausalrespondersdetection(CARD),anovelmethod
for responder analysis that identifies treated subjects who significantly
respond to a treatment. Leveraging recent advances in conformal pre-
diction, CARD employs machine learning techniques to accurately iden-
tify responders while controlling the false discovery rate in finite sample
sizes. Additionally,weincorporateapropensityscoreadjustmenttomit-
igate bias arising from non-random treatment allocation, enhancing the
robustness of our method in observational settings. Simulation studies
demonstrate that CARD effectively detects responders with high power
in diverse scenarios.
1 Introduction
Personalized medicine is expected to advance healthcare in the near future
[Vicente et al., 2020]. In contrast to a one-size-fits-all approach, personalized
medicineadvocatesfortreatmentstailoredtoindividualpatientsbasedontheir
clinical characteristics.
Responder analysis in clinical trials is a method used to evaluate the ef-
fectiveness of a treatment by identifying and analyzing the subset of partici-
pants who respond significantly to the treatment [Henschke et al., 2014]. This
approach contrasts with the traditional method of evaluating average effects
across all participants, which can sometimes obscure the benefits seen in a par-
ticular group of responders [Guyatt et al., 1998]. This approach is particularly
important in trials with heterogeneous treatment effects, where understanding
individual responses can lead to more effective therapies. Responder analysis
is a common practice in clinical trials [Moore et al., 2010, Straube et al., 2010,
Chuang et al., 2022]. In the context of this manuscript we focus on minimal
∗tzviel@phasevtrials.com
†oshri@phasevtrials.com
1
4202
nuJ
52
]EM.tats[
1v17571.6042:viXraevidenceforresponsivenessratherthanclinicallymeaningfulresponses[Snapinn
and Jiang, 2007].
Another approach to understanding heterogeneous treatment effects is es-
timating the conditional average treatment effect (CATE), which focuses on
understanding how the effect of a treatment varies across different segments of
thepopulation,ratherthanonlycalculatingtheaveragetreatmenteffect(ATE).
Unlike ATE, which provides a single overall effect, CATE enables the identifi-
cation of treatment benefits that may be specific to subgroups defined by their
unique characteristics [Angus and Chang, 2021].
CATEandresponderanalysiscomplementeachother. CATEoffersinsights
into the heterogeneous treatment effects in terms of the expected values of cer-
tain population segments. Meanwhile, responder analysis provides additional
context by indicating the proportion of total responders and extends beyond
the expected value. For instance, consider a scenario where a certain treatment
increasesthevariabilitywithinasubgroupofthepopulationwithoutnecessarily
affecting their expected value. Some subjects in this subgroup would be iden-
tified as responders, however the CATE estimation will offer no information
regarding it.
Individualtreatmenteffects(ITE)provideacomprehensiveviewofthetreat-
ment response. Lei and Cand`es [2021] proposed a method for constructing con-
fidence intervals for the ITE distribution using split conformal prediction and
counterfactual prediction [Papadopoulos, 2008]. These confidence intervals of-
fermoreinformationthantheCATEpointestimatealone. However,theyoften
lack the statistical power to detect differences between treated and untreated
responses. These confidence intervals can be used for responder analysis, where
subjects with confidence intervals that exclude 0 can be determined as respon-
ders.
CARD(causalresponderdetection),ourproposedresponderanalysismethod,
builds on AdaDetect (adaptive detection, Marandon et al. [2024]). AdaDetect
is a conformal prediction method for detecting out-of-distribution samples us-
inganadaptivenon-conformityscore. CARDofferstwosubstantialinnovations
over AdaDetect for the task of responder identification. First, we suggest a
specialized scorer aimed at discovering responders. This scorer uses recursive
partitioning of the feature space to maximize the differences in response be-
tween treated and untreated subjects within the nodes, similar to the causal
tree algorithm [Athey and Imbens, 2016]. This approach increases the power
substantially compared to AdaDetect, which utilizes off-the-shelf classifiers as
scorers. Second, we address the issue of potential bias from non-random alloca-
tion of treatment by applying a propensity score based adjustment [Tibshirani
et al., 2019].
The rest of section 1 provides background on the inference task at hand.
In section 2 we overview AdaDetect and causal trees, as they serve as building
blocks for our method. In section 3 we present CARD, discuss its components,
suggestanadjustmenttohandlecaseswherethetreatmentassignmentdepends
on the covariates. In section 4 we examine the performance of CARD in RCT
and observational study settings. Finally, we conclude with a discussion in
2section 5.
1.1 Causal Inference
In this paper, we follow the potential outcomes framework [Imbens and Rubin,
2015] with a binary treatment. Given n subjects, we denote by T ∈ 0,1 the
i
binarytreatmentindicator,by(Y (1),Y (0))thepairofpotentialoutcomes,and
i i
by X the vector of other covariates of length p. We assume that
i
(Y (1),Y (0),T ,X )∼(Y(1),Y(0),T,X),
i i i i
where(Y(1),Y(0),T,X)denotesagenericrandomvector. Ourfocuswillbe
onabinarytreatment,T ∼Ber(e(x)),wheree(x)isthepropensityscore. Under
the commonly assumed stable unit treatment value assumption (SUTVA), the
observeddatasetcomprisestriplets(Y ,T ,X )whereY =T ×Y (1)+(1−
obs i i obs i i
T )×Y (0).
i i
The ITE τ is defined as
i
τ ≡Y (1)−Y (0).
i i i
Bydefinition,foreachunit,onlyonepotentialoutcomeisobservedwhilethe
otherremainsunobserved. Consequently,theITEsareunobservedandmustbe
inferred. We also assume strong ignorability throughout the paper:
(Y(1),Y(0))⊥T |X.
Strong ignorability assumes that there are no unmeasured confounders af-
fecting both the treatment assignment and the potential outcomes. Under this
assumption, the treatment assignment is essentially randomized conditional on
the covariate values. These assumptions allow us to claim that
Y (1)|X =x∼Y |X =x,T =1, Y (0)|X =x∼Y |X =x,T =0,
i i i i i i i i
making it possible to identify moments of interest in the distribution of Y(1)−
Y(0). Typically, the interest lies in estimating the CATE,
τ(x)=E(Y(1)−Y(0)|X =x)=E(Y|X =x,T =1)−E(Y|X =x,T =0),
where the second equality is due to the strong ignorability assumption. The
estimationofCATEgarneredmuchattentioninrecentyears, multiplemethods
have been developed to estimate CATE using machine learning [Ku¨nzel et al.,
2019,WagerandAthey,2018,NieandWager,2021]. Forexample,theS-learner
consists of training an outcome prediction algorithm µˆ(X,T), which aims to
predict E(Y|X =x,T =t). The CATE estimate is then given by
τˆ(x)=µˆ(x,T =1)−µˆ(x,T =0).
Other parameters of the ITE distribution (besides CATE) are also valuable
targetsforestimation. Fort[2016]proposedestimatingtheconditionalquantile
treatment effect.
31.2 Inferential Goal
The objective ofresponder analysisis todetermine whethereachtreatedobser-
vation is a responder, as defined by:
H :Y (1)∼Y (0).
0,i i i
Under the strong ignorability assumption, the above is equivalent to
H :(Y (1),X )∼P ×P . (1)
0,i i i Y|X,T=0 X|T=1
One could argue that the objective should be to test Y (1) ∼ P .
i Y|X=Xi,T=0
However, such conditional testing requires assumptions of smoothness and in-
creasinglylargesamplesizes[FoygelBarberetal.,2021]. Sincethetesteddistri-
bution also depends on P , in some settings, testing individual hypotheses
X|T=1
becomes meaningless (see appendix A). Consequently, we aim to control the
false discovery rate (FDR) across all treated observations.
Remark 1. The hypothesis presented in eq. (1), is closely related to the task of
testing if the ITE is 0, but does not cover all possible scenarios. For example,
suppose that Y (1),Y (0)∼N(0,1)i=1,2 are independent. It is clear the ITE
i i
is not zero, yet the hypothesis remains true.
2 Related Work
In the following section we provide the relevant background for CARD.
2.1 Causal Tree and Forest
Causal tree (CT) is a type of decision tree specifically design for estimating
CATEAtheyandImbens[2016]. Atreeisapartition, Π, ofthecovariatespace
X. We denote by l(x;Π) the partition x ∈ l,l ∈ Π. A partition is obtained
by applying a partitioning algorithm, which is used to minimize a loss function
on some sample (y ,x ,t ),i ∈ I. Denote by I = {i : t = j}, j = 0,1, and
i i i j i
n = |I |. Finally, denote L(I ,x,Π) = {i : i ∈ I ,x ∈ l(x;Π)}. In CTs at
j j j j i
each partition the ATE is estimated by,
1 (cid:88) 1 (cid:88)
τˆ(x ;Π)= y − y . (2)
i |L(I ,x ,Π)| j |L(I ,x ,Π)| v
0 i 1 i
j∈L(I0,xi,Π) v∈L(I1,xi,Π)
4The partition, Π is obtained by minimizing the modified CATE mean square
error loss,
1 (cid:88)
Loss(Π,I)=− τˆ2(x ;Π)
n i
i∈I0∪I1
+
2 (cid:88)(cid:18) n 0Vˆ({y
i
:i∈I 0,x
i
∈l})
(3)
n n
l∈Π
n Vˆ({y :i∈I ,x ∈l})(cid:19)
+ 1 i 1 i ,
n
where n = n +n is the total number of observations, and Vˆ is the standard
0 1
sample variance estimator. To tackle the selective inference issue, the authors
suggest splitting the data into a training and test sets. The training set is
used to find the partitions that minimize eq. (3), and the test-set is used for
estimating the CATE within each terminal node (eq. (2)).
The use of sample splitting ensures that the estimates of the CATE in the
terminalnodesareunbiased. Thus,anystandardinferenceapproachcanbeused
to test the difference in means between the treated and untreated subjects in
eachterminalleafusingthetestset. Thetrade-offisthattherearefewerobser-
vations for finding the optimal partition. Furthermore, the method is effective
only when generating a single tree. When growing a forest, sample-splitting
is not sufficient to ensure valid testing, and different methods for estimating
the variance must be applied. These methods have only asymptotic guarantees
[Wager and Athey, 2018].
2.2 Conformal Prediction
Conformal prediction is a framework that provides a method to generate a
prediction set that contains the true target value with a 1−α confidence [An-
gelopoulosetal.,2023]. Wefocusoninductiveconformalpredictioninwhichthe
calibration set is independent of the samples used for training fˆ[Papadopou-
los, 2008]. Suppose there is a predictive model fˆ, trained on some (X ,Y ),
i i
where Y is a continuous response and X are the covariates. Conformal pre-
i i
diction requires a specification of a non-conformity score, s(x,y), (where larger
values correspond to worse agreement between x and y) and a calibration set
(X ,Y ), i = 1,...,k. The non-conformity score is often learnt based on a
i i
training set. To test a new observation, the non-conformity score is computed
for the calibration set, s(fˆ(X ),Y ),...,s(fˆ(X ),Y ). Assuming that a new
1 1 k k
observation is from the same distribution as the calibration set, then their non-
conformity scores are also distributed identically, thus,
(cid:18) (cid:18) (cid:19)(cid:19)
k+1
P s(X ,Y )>q (1−α) ≤α,
test test k
whereq(p)istheempiricalquantilebasedonthecalibrationsetnon-conformity
scores. ThiscanbeusedtotestH :Y |X ∼Y |X ,orbyinvertingtheac-
0 test test i i
5ceptanceregiongeneratingprediction-intervals[ShaferandVovk,2008,Haroush
et al., 2021]. The choice of the score function is critical for the performance of
the conformal predictor, Romano et al. [2019] suggested conformal quantile re-
gression (CQR), an adaptive score function based on quantile regression. This
allowed for the conformal interval to vary as function of x, making it adap-
tive when facing heteroscedasticity. Later, Romano et al. [2019] generalized the
approach and suggested conformal-intervals that are based on the conditional
histogram of Y|X.
To test H : Y ∼ P ×P , using the procedure described above, one
0 test Y|X X
mustassumethatX ∼P . Whenoneisunwillingtomakesuchassumption,
test X
weighted conformal prediction can be used. Tibshirani et al. [2019] suggested
a modification to conformal prediction when facing covariate shift, where the
score is weighted according to the likelihood ratio w(x)= dPtest(x), where P is
dP0(x) 0
the distribution of the calibration set covariates.
Lei and Cand`es [2021] proposed confidence intervals for the ITE. In the
process,theydemonstratedhowtoconstructcounterfactualconfidenceintervals.
The method builds on the CQR and utilizes the weighted conformal prediction
to handle propensity.
2.2.1 AdaDetect
Suppose there are two samples, a reference sample I = {i : X ∼ P }, and
0 i 0
a test sample I = {i : X ∼ P }, where P can either be P or some other
1 i i i 0
distribution. The interest lies in identifying the specific observations in the test
sample who differ from the reference sample, i.e., testing,
H :X ∼P ,∀i∈I . (4)
0,i i 0 1
Conformal prediction can be used for this purpose. First, a non-conformity
score, s, which measures the degree of disagreement of an observation being
sampled from P is applied to I to estimate its empirical distribution under
0 0
the null hypothesis [Haroush et al., 2021]. Then, the same non conformity is
applied to each observation in I . A p-value for each observation obtained
1
according to pv =
1+(cid:80) j∈I01(s(xj)>s(xi))
, where 1 is the indicator function.
i |I0|+1
Bates et al. [2023] have shown that the resulting p-values adhere to a spe-
cific type of dependency and that the Benjamini-Hochberg (BH) multiplicity
adjustment[BenjaminiandHochberg,1995]canbesafelyappliedtocontrolthe
FDR. While the procedure is valid, it still remains to decide on s, as different
scores will be powerful for different P and P .
1 0
Recently, Marandon et al. [2024] proposed AdaDetect, an adaptive method
forlearningthenon-conformityscoresforsuchhypotheses. Thenon-conformity
score is learned using a classifier aimed at discriminating between the reference
and test sets. However, even when the null hypothesis of eq. (4) is true for all
observations in the test set, the application of this classification method may
still result in different distribution of non-conformity scores between the two
samples.
6Toaddressthisissue,AdaDetectemploysknockoffs,observationsdesignedto
beindistinguishablefromactualtestobservationstotheclassifier,yetforwhich
the null hypothesis holds. These knockoffs generate non-conformity scores that
are distributed similarly to the scores of true test observations under the null
hypothesis, thus enabling more accurate hypothesis testing. To overcome the
issue, the method employs knockoffs, observations that appear to the classifier
asiftheybelongtoI butforwhicheq.(4)holdstrue. Theseknockoffsgenerate
1
non-conformity scores that are distributed similarly to the scores of true test
observations under the null hypothesis, thus enabling more accurate hypothesis
testing.
The procedure involves sampling k observations from I (denote as I ),
0 ko
that will serve as our knockoffs, we will combine them with I , such we are left
1
with I∗ =I ∪I and I∗ =I /I .
1 ko 1 0 0 ko
The non-conformity score is learnt by training a classifier aimed at discrim-
inating between I∗ and I∗, where higher values indicate the sample is more
0 1
likelytobefromI∗. Thepredictionwillalsoserveasournon-conformityscore.
1
Intuitively, s(X ),i∈I :X ∼P , are exchangeable with s(X ),j ∈I under
i 1 i 0 j ko
H , thus a p-value can be obtained by,
0
1+(cid:80)k
1(s(x )>s(x ))
pv = j=1 j i . (5)
i k+1
The use of a classifier generates an adaptive non-conformity score, which
was shown to asymptotically achieve the optimal Neyman-Pearson test power
[Marandon et al., 2024].
3 CARD
CARD applies a targeted approach using a specialized scorer to improve the
power in detecting changes in response distribution for treated subjects. Sim-
ilar to AdaDetect, it employs a classifier to detect the observations of interest
and knockoffs to obtain FDR control in finite samples. CARD employs scorer
tailored to the specific structure of the problem, substantially improving its
power over AdaDetect which uses generic classifiers.
WeinitiallydiscussthesuggestedmethodinanRCTsetting,whichnaturally
avoidsconfoundingduetodifferencesinthedistributionsofX|T =1andX|T =
0. In section 3.3, we also discuss approaches for addressing such differences in
non-randomized settings.
We define I and I as the indices for untreated and treated observations,
0 1
respectively. Additionally, define the set of treated observations indices where
(eq. (1)) holds true, H ={i∈I :Y |T =1,X ∼Y |T =0,X }.
0 1 i i i i i i
3.1 Inference in RCTs
To test the hypotheses eq. (1), the untreated subjects are split into two groups,
I = I ∪I∗. A classifier is trained to differentiate between I∗ = I ∪I
0 ko 0 1 1 ko
7and I∗. Let s(x ,y ) be the resulting score according to the classifier. Finally,
0 i i
p-values are obtained as in eq. (5),
(cid:80)
1+ 1(s(x ,y )>s(x ,y ))
pv = j∈Iko j j i i .
i k+1
In RCTs, randomization ensures that X|T = 1 ∼ X|T = 0. If the null
hypothesis(eq.(1))istrueforobservationi, thenY |T =1,X ∼Y |T =0,X .
i i i i i i
Thus, {(X ,Y )} are exchangeable with {(X ,Y )} . If the classifier
i i i∈Iko j j j∈I1∩H0
is invariant (as defined by eq. 8 in [Marandon et al., 2024]), a property of
most practical classifiers, then according to Lemma 3.2 and Theorem 3.3 of
[Marandonetal.,2024], theBHprocedureappliedtotheresultingp-valueswill
control the FDR.
To handle the setting of observational studies, where X|T = 1 ̸∼ X|T =
0, we suggest a weighted version of Adadetect based on weighted conformal
prediction [Tibshirani et al., 2019], see section 3.3. A graphical illustration of
the procedure is provided in fig. 1.
3.2 Scorer
ToincreasethepoweroftheAdaDetect,wesuggestlearningthenon-conformity
scoresusingarespondertree. TherespondertreemirrorstheprinciplesofCTs,
wherein the data is recursively partitioned on X to minimize the overall Loss
y
across partitions until certain stopping criteria, such as reaching a maximum
tree depth or convergence of loss, are met. While the splits are done according
to X the evaluation in the terminal leaves is based solely on Y and T.
The splits the responder tree makes are driven by the loss on the terminal
nodes(whereonlyY isconsidered). Theaimofthetreeistobestclassifyobser-
vations by their treatment assignment (treated or not). The loss the responder
tree attempts to minimize is
(cid:88)
Loss(Π,I ,I )= c Loss (Π ,{y :x ∈l,i∈I },{y :x ∈l,i∈I }), (6)
0 1 l y y i i 0 i i 1
l∈Π
where Π is a partition that spans Y, Loss can be any loss applicable for
y y
classification such as Gini or entropy loss, and
|{i∈I ∪I :x ∈l}|
c = 0 1 i .
l |I ∪I |
0 1
We minimize the specified loss (eq. (6)) using recursive partitioning, a stan-
dardapproachtooptimizeclassificationtrees[RokachandMaimon,2005]. The
primary partitions are based on X. For each subset of observations defined
by these partitions, we fit a shallow classification tree (depth of 2) where Y is
used to classify T. The loss associated with each partition is calculated based
on the weighted classification loss of the shallow trees applied to each subset.
Partitioning continues provided there is an improvement in the loss or until
8predefined stopping criteria are met, such as a meeting the minimal number of
observations in the terminal nodes or reaching the maximal tree depth.
While a single responder tree is described, we can also consider a forest of
scorers, where in a similar vain to Random Forest (RF), a bootstrap sample of
observations and a sample of features are taken to grow each tree [Hastie et al.,
2009]. The score is the average prediction across the different trees as standard
in classification random-forest.
3.3 Propensity Adjusted CARD
If the propensity is a function of X and Y(0) ̸⊥ X then the knockoffs are no
longer exchangeable with the treated observations under the null. To overcome
this issue, we suggest a propensity adjusted p-value,
(cid:88)
pvw =w∗+ w∗·1(s(x ,y )>s(x ,y )), (7)
i i j j j i i
j∈Iko
where the weights are defined by w = e(xj) j ∈ {i} ∪ I and w∗ =
j 1−e(xj) ko j
wj . This is similar to the weighting used in [Lei and Cand`es, 2021].
(cid:80) l∈{i}∪Ikowl
Lemma 1. Under the null hypothesis (eq. (1)), the weighted p-values (eq. (7))
control the type I error at level α,
P(w−pv <α)≤α.
i
The proof is given in appendix D. It should be noted, that the resulting
p-values have no theoretical control of the FDR in finite sample, however, in
practicetheyindeedcontroltheFDR.Furthermore,itisshownthatasn→∞,
the BH procedure using the weighted p-values recover the theoretical control of
the FDR [Jin and Cand`es, 2023].
Although results are typically presented with oracle propensity, in practice,
the propensity score is estimated from the same data we intend to analyze. To
reduce over-fitting, we fit the propensity estimator using m-fold fitting [Jacob,
2020], training on m−1 folds and estimating the propensity on the remaining
fold. We examine the empirical validity of this adjustment in section 4.2.
4 Simulations
4.1 RCT Simulations
We begin by investigating the performance of the suggested method in RCT
settings using a simulation study. We use a variant of the data generation
process that was used by Lei and Cand`es [2021] and Wager and Athey [2018].
Thedatagenerationprocessisoutlinedasfollows: WesampleX∗ ∼N(0,Σ ),
p×p
9Figure 1: An illustration of CARD is provided where red fill indicates treated
samples,andbluefillrepresentsuntreatedsamples. Knockoffsaredepictedwith
a red frame. In step A, the propensity model is fit, and knockoffs are sampled
from the untreated observations. Step B involves preparing the data for the
classifier by combining the knockoffs with the treated observations. In step C,
the responder forest is trained to classify between I∗ and I∗. Finally, in step
0 1
D, the predictions from the responder forest are used as non-conformity scores.
These scores are then weighted according to the propensity score to calculate
p-values.
where Σ = ρ|i−j|. To obtain X we transform X = Φ(X∗). The potential
i,j i i
outcomes are generated according to,
Y(0)=4·(X +X )+ϵ, Y(1)=4·(X +X )+rf(X )·f(X )+ϵ,
1 2 1 2 1 2
where ϵ∼N(0,σ(x)2) and
2
f(x)=1(x>0.5)· .
1+exp(−12·(x−0.5))
Treatment assignments are randomly determined following a Bernoulli dis-
tribution, Ber(0.5). We explore variations in the parameters: r ∈ {−1,+1} to
assess the effect of signal sign, σ(x)∈{1,−2·ln(x)} to compare homoscedastic
and heteroscedastic settings, ρ ∈ {0,0.9} to distinguish between independent
10anddependentsettings,andp∈{10,100}toevaluatetheimpactofthenumber
of features. We vary the number of observations, n ∈ {250,500,1000,2000}.
Each setting is repeated 100 times, and the averages are reported.
The null hypothesis tested by the suggested method eq. (1), is false for
X > 0.5,X > 0.5. To handle multiplicity, we adjust the p-values using the
1 2
BH procedure. The FDR is expected to controlled at level 0.1. We compare
CARD (using 20% of the untreated subjects as knockoffs) with several other
methods of detecting responders.
1. Global Testing - Testing if Y ,T = 1 ∼ Y(0), which is also valid for
i i
testing eq. (1). The p-value is obtained on the basis of the Y(0) eCDF
(see appendix C).
2. AdaDetect [Marandon et al., 2024] - Applying the original AdaDetect
method with RF as the classifier. 20% of the untreated observations are
used as knockoffs.
3. CQR [Romano et al., 2019] - We apply the CQR non-conformity score
to obtain p-values (see appendix B), this is equivalent to counter factual
confidence-intervalssuggestedbyLeiandCand`es[2021]. Boostingisused
for the estimation of the conditional quantiles, 80% of the untreated sam-
ple is used for estimation and 20% for testing.
Allmethodsarevalidfortestingeq.(1)andcontrolingFDRinfinitesamples.
Other methods of CATE estimation can also be used for testing for responders
suchasCF,BARTandbootstrapwithMeta-Learners[WagerandAthey,2018,
Chipman et al., 2012, Ku¨nzel et al., 2019]. However, Lei and Cand`es [2021]
showed they lack finite coverage control, and thus are omitted from this and
subsequent simulation studies.
The FDR and additional power results are given in appendix E. The use of
AdaDetectwithRFastheclassifieryieldspoorresults,whichisunsurprisingas
RFattemptstodetectdifferencesacrossallfeatures,unlikecompetingmethods
focusing on Y or Y|X.
Responder knockoffs is powerful in all scenarios, significantly outperform-
ing competing methods in most cases, except in homoscedastic scenarios with
positive signals where they are surpassed by the CQR and global methods for
n<2000. It’s power increases the most as the sample size increases.
As implied by its name, the global method performs well when responders
are discernible solely by considering Y, particularly in scenarios with positive
signal sign and homoscedastic noise. Because the global method does not split
the data, it significantly outperforms other methods in this specific scenario.
However, when the differences in distributions are only discernible upon con-
ditioning on X (see appendix C for an illustrative example), the method has
virtually no power.
Unlike CARD, the CQR non-conformity score is learnt only on the basis of
the untreated distribution. This leads to much better performance of CARD
across all settings except for positive signal and homoscedastic noise.
11Negative Signal Positive Signal
0.8
0.6
0.4
0.2
0.0
0.8
0.6
0.4
0.2
0.0
500 1,000 1,500 2,000 500 1,000 1,500 2,000
Sample Size (n)
CARD CQR Global AdaDetect
Figure 2: Power analysis of various methods for different sample sizes. The
plots display the power as a function of sample size (n) in the p=10 scenario.
ThepowerofCARDishigherinallscenariosexceptforthehomoscedasticnoise
andpositivesignal,whereitreachesparitywhennissufficientlylarge. Intervals
indicate ±1 SD around the estimate.
4.2 Observational Study Simulation
Although the asymptotic control of the FDR in the weighted CARD procedure
is theoretically guaranteed, the effects of weighting in finite samples and in
practical settings remains unknown.
Weemploythesamedatagenerationprotocolasoutlinedinsection4;chang-
ing only the propensity function to mimic an observational study with con-
founders, e = 1 . The propensity function ensures that the
1+exp(1.75·X1−0.825)
probability of receiving treatment is 0.5. We present results for the p=10 and
positive signal scenario, as the results are consistent across scenarios. Further-
more, we restrict our simulations to CARD.
We consider four methods of handling non-trivial propensity: 1) None, ig-
noring propensity and applying CARD without any adjustment; 2) Oracle ad-
justment, where weighting is based on true propensity; 3) RF classifier propen-
sity adjustment; 4) Logistic Regression propensity adjustment. The propensity
models are fit using 10-fold cross-fitting.
The results, shown in fig. 3, indicate that all methods except ’None’ control
the FDR at the expected level of 0.1. The estimating methods exhibit higher
powerthantheoracle,aresultattributedtocross-fittinganderrorsinpropensity
estimation. However, since the method is generally conservative, it controls the
12
rewoP
Heteroscedastic
Noise
Homoscedastic
NoiseHeteroscedastic Noise Homoscedastic Noise
0.5
0.0
500 1,000 1,500 2,000 500 1,000 1,500 2,000
0.10
0.05
0.00
500 1,000 1,500 2,000 500 1,000 1,500 2,000
Sample Size (n)
Logistic Regression Random Forest Oracle None
Figure 3: Power and FDR of the various methods of handling propensity. The
None method is removed from the power (upper row) plots, since it fails to
control the FDR at the expected level (bottom row). Intervals indicate ±1 SD
around the estimate.
FDR at the expected level, which is promising for real-world applications.
5 Discussion
CARDisapowerfulmethodforidentifyingresponderswithinatreatmentgroup.
It offers FDR control in finite samples and is applicable in both observational
studies and RCTs. The detection of responders provides a perspective that
complementstheanalysisofCATE.WhileCATEmeasurestheaverageeffectof
treatment for each segment of the population, CARD estimates the proportion
of affected samples. For example, consider a clinical trial where for a particu-
lar subgroup in the population there is substantial CATE; however, responder
analysis might reveal that only a small fraction of this subgroup truly benefits
from the clinical treatment. Moreover, the inference on CATE is restricted to
asymptotic regimes (where the sample size increases to infinity), while CARD
provides finite sample control of the FDR.
The main drawback of CARD is that it offers only marginal control over
the type I error, and not conditional on the covariates, X. This results from
13
rewoP
RDFthe finite sample control provided by the method [Foygel Barber et al., 2021],
a limitation also shared by counter-factual ITE confidence intervals [Lei and
Cand`es, 2021]. Extending the method to test conditional hypotheses remains
an area for future research.
While CARD is presented as a method for detecting responders, it can also
be applied to other use-cases:
1. A global null test for treatment effectiveness, allowing for quick screening
of various datasets.
2. Identifying subspaces of X in which the treatment and non-treatment re-
sponse distributions differ. A single responder tree tries to find subspace
ofX inwherethedistributionsY(0)|X ∈AandY(1)|X ∈Aaredifferent.
Testingthedifferencebetweenthetwodistributionsusingonlytheknock-
offsintheidentifiedsubspace,I ∩Aprovidesavalidtestfordistribution
ko
differences given A.
3. Enrichinguntreatedsamplesintrialsbyselectingcontrolsamplesthatare
sufficiently similar from previous trials. –
These applications also present further research opportunities.
Finally, CARD provides an estimate of the proportion of responders while
controlling for the FDR. Pairing this method with various approaches to con-
structing valid confidence intervals for the true discovery proportion [Hemerik
and Goeman, 2018, Millstein et al., 2022] can provide even additional informa-
tion on the proportion of responders, and is a promising research avenue.
References
Anastasios N Angelopoulos, Stephen Bates, et al. Conformal prediction: A
gentle introduction. Foundations and Trends® in Machine Learning, 16(4):
494–591, 2023.
Derek C Angus and Chung-Chou H Chang. Heterogeneity of treatment effect:
estimatinghowtheeffectsofinterventionsvaryacrossindividuals. Jama,326
(22):2312–2313, 2021.
SusanAtheyandGuidoImbens.Recursivepartitioningforheterogeneouscausal
effects. Proceedings of the National Academy of Sciences, 113(27):7353–7360,
2016.
StephenBates,EmmanuelCand`es,LihuaLei,YanivRomano,andMatteoSesia.
Testing for outliers with conformal p-values. The Annals of Statistics, 51(1):
149–178, 2023.
Yoav Benjamini and Yosef Hochberg. Controlling the false discovery rate: a
practical and powerful approach to multiple testing. Journal of the Royal
statistical society: series B (Methodological), 57(1):289–300, 1995.
14Hugh A Chipman, Edward I George, and Robert E McCulloch. Bart: Bayesian
additive regression trees. Annals of Applied Statistics, 6(1):266–298, 2012.
Chien-Chia Chuang, Isabelle Guillemin, Claus Bachert, Stella E Lee, Pe-
ter W Hellings, Wytske J Fokkens, Nicolas Duverger, Chunpeng Fan, Nadia
Daizadeh,NikhilAmin,etal. Dupilumabincrswnp: responderanalysisusing
clinically meaningful efficacy outcome thresholds. The Laryngoscope, 132(2):
259–264, 2022.
MargheritaFort. Unconditionalandconditionalquantiletreatmenteffect: Iden-
tification strategies and interpretations. Topics in theoretical and applied
statistics, pages 15–24, 2016.
Rina Foygel Barber, Emmanuel J Candes, Aaditya Ramdas, and Ryan J Tib-
shirani. The limits of distribution-free conditional predictive inference. In-
formation and Inference: A Journal of the IMA, 10(2):455–482, 2021.
Gordon H Guyatt, Elizabeth F Juniper, Stephen D Walter, Lauren E Griffith,
and Roger S Goldstein. Interpreting treatment effects in randomised trials.
Bmj, 316(7132):690–693, 1998.
Matan Haroush, Tzviel Frostig, Ruth Heller, and Daniel Soudry. A statistical
framework for efficient out of distribution detection in deep neural networks.
In International Conference on Learning Representations, 2021.
TrevorHastie,RobertTibshirani,JeromeFriedman,TrevorHastie,RobertTib-
shirani, and Jerome Friedman. Random forests. The elements of statistical
learning: Data mining, inference, and prediction, pages 587–604, 2009.
Jesse Hemerik and Jelle J Goeman. False discovery proportion estimation by
permutations: confidence for significance analysis of microarrays. Journal of
the Royal Statistical Society Series B: Statistical Methodology, 80(1):137–155,
2018.
Nicholas Henschke, Annefloor van Enst, Robert Froud, and Raymond WG Os-
telo. Responder analyses in randomised controlled trials for chronic low back
pain: an overview of currently used methods. European Spine Journal, 23:
772–778, 2014.
Guido W Imbens and Donald B Rubin. Causal inference in statistics, social,
and biomedical sciences. Cambridge university press, 2015.
Daniel Jacob. Cross-fitting and averaging for machine learning estimation of
heterogeneous treatment effects. arXiv preprint arXiv:2007.02852, 2020.
YingJinandEmmanuelJCand`es.Model-freeselectiveinferenceundercovariate
shiftviaweightedconformalp-values. arXivpreprintarXiv:2307.09291,2023.
S¨oren R Ku¨nzel, Jasjeet S Sekhon, Peter J Bickel, and Bin Yu. Metalearners
for estimating heterogeneous treatment effects using machine learning. Pro-
ceedings of the national academy of sciences, 116(10):4156–4165, 2019.
15LihuaLeiandEmmanuelJCand`es. Conformalinferenceofcounterfactualsand
individual treatment effects. Journal of the Royal Statistical Society Series
B: Statistical Methodology, 83(5):911–938, 2021.
Ariane Marandon, Lihua Lei, David Mary, and Etienne Roquain. Adaptive
noveltydetectionwithfalsediscoveryrateguarantee.TheAnnalsofStatistics,
52(1):157–183, 2024.
Joshua Millstein, Francesca Battaglin, Hiroyuki Arai, Wu Zhang, Priya Jay-
achandran, Shivani Soni, Aparna R Parikh, Christoph Mancao, and Heinz-
Josef Lenz. fdrci: Fdr confidence interval selection and adjustment for large-
scale hypothesis testing. Bioinformatics Advances, 2(1):vbac047, 2022.
R Andrew Moore, Owen A Moore, Sheena Derry, Paul M Peloso, Arnold R
Gammaitoni, and Hongwei Wang. Responder analysis for pain relief and
numbers needed to treat in a meta-analysis of etoricoxib osteoarthritis trials:
bridging a gap between clinical trials and clinical practice. Annals of the
rheumatic diseases, 69(2):374–379, 2010.
Xinkun Nie and Stefan Wager. Quasi-oracle estimation of heterogeneous treat-
ment effects. Biometrika, 108(2):299–319, 2021.
Harris Papadopoulos. Inductive conformal prediction: Theory and application
to neural networks. In Tools in artificial intelligence. Citeseer, 2008.
LiorRokachandOdedMaimon. Top-downinductionofdecisiontreesclassifiers-
a survey. IEEE Transactions on Systems, Man, and Cybernetics, Part C
(Applications and Reviews), 35(4):476–487, 2005.
Yaniv Romano, Evan Patterson, and Emmanuel Candes. Conformalized quan-
tile regression. Advances in neural information processing systems, 32, 2019.
Glenn Shafer and Vladimir Vovk. A tutorial on conformal prediction. Journal
of Machine Learning Research, 9(3), 2008.
Steven M Snapinn and Qi Jiang. Responder analyses and the assessment of a
clinically relevant treatment effect. Trials, 8:1–6, 2007.
SebastianStraube,SheenaDerry,RAndrewMoore,JocelynPaine,andHenryJ
McQuay. Pregabalin in fibromyalgia-responder analysis from individual pa-
tient data. BMC Musculoskeletal Disorders, 11:1–8, 2010.
Ryan J Tibshirani, Rina Foygel Barber, Emmanuel Candes, and Aaditya Ram-
das. Conformalpredictionundercovariateshift. Advances in neural informa-
tion processing systems, 32, 2019.
Astrid M Vicente, Wolfgang Ballensiefen, and Jan-Ingvar J¨onsson. How per-
sonalised medicine will transform healthcare by 2030: the icpermed vision.
Journal of Translational Medicine, 18:1–4, 2020.
16Stefan Wager and Susan Athey. Estimation and inference of heterogeneous
treatment effects using random forests. Journal of the American Statistical
Association, 113(523):1228–1242, 2018.
17A Marginal vs Conditional Responder Testing
The test proposed for H : (X ,Y ) ∼ (X ,Y ), is a test of the joint distribu-
0,i i i 0 0
tions,asopposedtoatestoftheconditionaldistributionsH :Y (1)|X =x ∼
0,i i i i
Y (0)|X = x . This implies, that the type I error is not controlled conditional
i i i
on X, but rather marginalized over X, i.e.,
(cid:90)
P (PV ≤α)= P (X =x)P (PV ≤α))dx≤α. (8)
(X0,Y0)|T=1 i X|T=1 Y(0)|X=x i
In most practical examples, the CARD’s Type I error rate when testing condi-
tional hypotheses is negligibly above the nominal level. However, it is possible
to construct scenarios where the CARDs test’s Type I error rate reaches up to
1 when testing these hypotheses.
Consider the case where Y(0)|X = 0+ϵ, Y(1)|X = 1(X > 0.01)+ϵ, and
ϵ ∼ N(0,10−7). Furthermore, let T ∼ Ber(0.5) and X ∼ U[0,1]. For a very
large number of observations, the discriminators will make the correct split on
X > 0.01, with a following split on Y > 10−5 (or any other value which
1
separates the distributions well). Due to these splits all of the null conditional
hypotheses would be rejected (all observations for which X < 0.01), yet, the
1
joint type I error will be controlled at the expected level.
B Conformal Quantile Regression (CQR)
To produce CQR, we split the data into a training set, I , and a calibration
tr
set, I . First, the training set is used for fitting a quantile regression model
cal
(such as linear quantile regression, quantile boosting, quantile trees, etc.). The
model is trained to predict the conditional quantiles q (x) and q (x), where
αl αh
α +α =α, and 1−α is the coverage probability. Then, the calibration set is
l h
used to estimate the non-conformity score,
s(X ,Y )=max(q (X )−Y ,Y −q (X )).
i i αl i i i αh i
ToconstructtheCI,the1−αquantileofthenon-conformityscoresarecomputed
on the calibration set, denoted by Q . Finally, the confidence interval is,
1−α
C(X )=[q (X )−Q ,q (X )+Q ].
n+1 αl i 1−α αh i 1−α
To obtain p-values, we use the following,
(cid:80)
1+ 1(s(x ,y )≥s(x ,y ))
pv =
xj,yj∈Ical j j i i
. (9)
i |I |+1
cal
C Global Testing
Thetaskofdetectingrespondersisessentiallyataskofdetectingout-of-distribution
observation based on the response. A simple approach would be to calculate
18the empirical p-values of Y ,T = 1 observations based on the null sample, the
i i
p-values is,
(cid:32) 1+(cid:80)n0
1(y ≥y )
1+(cid:80)n0
1(y ≤y
)(cid:33)
pvglobal =2min j=1 j i , j=1 j i .
i n +1 n +1
0 0
A major drawback of the method is its inability to handle subjects which are
responders conditional on some X. To illustrate the issue, we will use a some-
what contrived example, which exaggerates what otherwise is a very common
phenomena. Suppose that X ∼U[0,1],
Y(0)=−5·1(x<0.5)+5·1(x>0.5)+ϵ,
and
Y(1)=−5·1(x<0.25)+5·1(x>0.5)+ϵ,
where ϵ∼N(0,1).
Theglobaltestingapproachhasnopower,sincetheresponderdonotappear
extreme considering Y (see fig. 4 A), while when considering 0.25<X <0.75,
it is clear that the observation centered around Y =0 are anomalies (see fig. 4
B).Indeed,inthisexamplethepoweroftheCARDis1,whiletheglobaltesting
has a power of 0.
A Untreated B
1750
Treated 7.5
1500
5.0
1250 2.5
1000 0.0
750 2.5
500 5.0
250 7.5
0
7.5 5.0 2.5 0.0 2.5 5.0 7.5 0.0 0.2 0.4 0.6 0.8 1.0
Y X
Figure4: A.HistogramofY,therespondersarelocatedbetweenthetwomodal-
ities of Y(0). B. Scatter plot of Y X, it is clear to see the responders around
Y =0 and 0.25<X <0.5.
D Proof of Lemma 1
Proof. For simplicity, we assume that I ={1,...,k} and i=k+1.
ko
Denote Z =(X ,Y ), z =(x ,y ). Let c=
P(T=0),
and let
i i i i i i P(T=1)
(cid:40)
1 1≤i≤k
w˜ (x,y)= .
i c e(x) i=k+1
1−e(x)
19
ycneuqerF
YUnder the null hypothesis, it holds that for every x,y, 1≤i ≤k
0
P((X,Y)=(x,y)|T =0)w˜ (x,y)=P((X,Y)=(x,y)|T =1)w˜ (x,y). (10)
k+1 i0
Indeed, the left hand side of eq. (10) is
P((X,Y)=(x,y)|T =0)P(T =0)P(T =1|X =x)
=
P(T =1)P(T =0|X =x)
P(T =0|(X,Y)=(x,y))P((X,Y)=(x,y))P(T =1|X =x)
=
P(T =1)P(T =0|X =x)
P((X,Y)=(x,y))P(T =1|X =x)
=
P(T =1)
P((X,Y)=(x,y)|T =1).
The first equality is by Bayes rule, the second equality is due to the null
hypotheses (P(Y = y,T = t|X = x) = P(Y = y|X = x)P(T = t|X = x)) and
the last equality is by definition.
Equation (10) implies that (Z ,...,Z ) are weighted exchangeable ([Tib-
1 k+1
shirani et al., 2019, Definition 1]) – for every permutation σ,
P(Z =v ,...,Z =v ) P(Z =v ,...,Z =v )
1 1 k+1 k+1 = 1 σ(1) k+1 σ(k+1) .
w˜ (v )···w˜ (v ) w˜ (v )···w˜ (v )
1 1 k+1 k+1 1 σ(1) k+1 σ(k+1)
Now, we let E be the event that {Z ,...,Z } = {z ,...,z }. By the
z 1 k+1 1 k+1
above, there is a constant C such that
z
P(Z =v ,...,Z =v )=C w˜ (v )···w˜ (v )=C w˜ (v ).
1 σ(1) k+1 σ(k+1) z 1 1 k+1 k+1 z k+1 σ(k+1)
Assumingforsimplicitythatallthevaluesaredifferent,usingthesamesteps
as in the proof of [Tibshirani et al., 2019, Lemma 3], it holds that
(cid:80) P(Z =v ,...,Z =v )
P(Z =z |E )= σ:σ(k+1)=j 1 σ(1) k+1 σ(k+1)
k+1 j z (cid:80) P(Z =v ,...,Z =v )
σ 1 σ(1) k+1 σ(k+1)
k!w˜ (z )
= k+1 j =w∗.
(cid:80)k+1k!w˜
(z )
j
l=1 k+1 l
Finally, notice that the score s is constant given E . This implies together
z
with the above
P(pvw <α|E )≤α.
i z
And after marginalizing we get the required result.
20E Additional RCT Simulations
E.1 Power Results
Additional power results for the RCT setting simulations (section 4.1). The
plots are illustrate the power as a function of the number of observations. The
conclusions from the section 4.1 are similar across the various scenarios. The
CARD method outperforms all methods except in the positive signal and ho-
moscedastic noise scenario.
E.1.1 p=10,ρ=0.9
Negative Signal Positive Signal
0.8
0.6
0.4
0.2
0.0
0.8
0.6
0.4
0.2
0.0
500 1,000 1,500 2,000 500 1,000 1,500 2,000
Sample Size (n)
CARD CQR Global AdaDetect
Figure 5: Power analysis of various methods for different sample sizes. The
plots display the power as a function of sample size (n) in the (p = 10,ρ =
0.9) scenario. Due to the correlations the AdaDetect method performs better
compared to its performance when the covaraites are independent from one
another, but still the best performing method is CARD except in the positive
signal and homoscedastic noise, where the CQR and Global methods achieve
better power for n<2000.
21
rewoP
Heteroscedastic
Noise
Homoscedastic
NoiseE.1.2 p=100,ρ=0
Negative Signal Positive Signal
0.8
0.6
0.4
0.2
0.0
0.8
0.6
0.4
0.2
0.0
500 1,000 1,500 2,000 500 1,000 1,500 2,000
Sample Size (n)
CARD CQR Global AdaDetect
Figure 6: Power analysis of various methods for different sample sizes. The
plots display the power as a function of sample size (n) in the (p=100,ρ=0)
scenario. ThepoweroftheCARDmethodismuchhigherinallscenariosexcept
for the homoscedastic noise and positive signal.
22
rewoP
Heteroscedastic
Noise
Homoscedastic
NoiseE.1.3 p=100,ρ=0.9
Negative Signal Positive Signal
0.8
0.6
0.4
0.2
0.0
0.8
0.6
0.4
0.2
0.0
500 1,000 1,500 2,000 500 1,000 1,500 2,000
Sample Size (n)
CARD CQR Global AdaDetect
Figure 7: Power analysis of various methods for different sample sizes. The
plotsdisplaythepowerasafunctionofsamplesize(n)inthe(p=100,ρ=0.9)
scenario. The power of CARD method is much higher in all scenarios except
for the homoscedastic noise and positive signal.
23
rewoP
Heteroscedastic
Noise
Homoscedastic
NoiseE.2 FDR Results
Acrossallsimulations,allmethodscontroltheFDRattheexpectedlevelof0.1.
E.2.1 p=10,ρ=0
Negative Signal Positive Signal
0.10
0.08
0.06
0.04
0.02
0.00
0.10
0.08
0.06
0.04
0.02
0.00
500 1,000 1,500 2,000 500 1,000 1,500 2,000
Sample Size (n)
CARD CQR Global AdaDetect
Figure 8: FDR of various methods for different sample sizes. The plots display
the FDR as a function of sample size (n) in the (p=10,ρ=0) scenario.
24
rewoP
Heteroscedastic
Noise
Homoscedastic
NoiseE.2.2 p=10,ρ=0.9
Negative Signal Positive Signal
0.10
0.08
0.06
0.04
0.02
0.00
0.10
0.08
0.06
0.04
0.02
0.00
500 1,000 1,500 2,000 500 1,000 1,500 2,000
Sample Size (n)
CARD CQR Global AdaDetect
Figure 9: FDR of various methods for different sample sizes. The plots display
the FDR as a function of sample size (n) in the (p=10,ρ=0.9) scenario.
25
rewoP
Heteroscedastic
Noise
Homoscedastic
NoiseE.2.3 p=100,ρ=0
Negative Signal Positive Signal
0.10
0.08
0.06
0.04
0.02
0.00
0.10
0.08
0.06
0.04
0.02
0.00
500 1,000 1,500 2,000 500 1,000 1,500 2,000
Sample Size (n)
CARD CQR Global AdaDetect
Figure10: FDRofvariousmethodsfordifferentsamplesizes. Theplotsdisplay
the FDR as a function of sample size (n) in the (p=100,ρ=0) scenario.
26
rewoP
Heteroscedastic
Noise
Homoscedastic
NoiseE.2.4 p=100,ρ=0.9
Negative Signal Positive Signal
0.10
0.08
0.06
0.04
0.02
0.00
0.10
0.08
0.06
0.04
0.02
0.00
500 1,000 1,500 2,000 500 1,000 1,500 2,000
Sample Size (n)
CARD CQR Global AdaDetect
Figure11: FDRofvariousmethodsfordifferentsamplesizes. Theplotsdisplay
the FDR as a function of sample size (n) in the (p=100,ρ=0.9) scenario.
27
rewoP
Heteroscedastic
Noise
Homoscedastic
Noise