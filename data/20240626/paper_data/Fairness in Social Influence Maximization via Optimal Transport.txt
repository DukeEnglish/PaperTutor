Fairness in Social Influence Maximization
via Optimal Transport
Shubham Chowdary
Department of Computer Science, ETH Zürich, Switzerland
schowdhary@student.ethz.ch
Giulia De Pasquale∗
Automatic Control Laboratory, ETH Zürich, Switzerland
degiulia@ethz.ch
Nicolas Lanzetti
∗
Automatic Control Laboratory, ETH Zürich, Switzerland
lnicolas@ethz.ch
Ana-Andreea Stoica
Social Foundations of Computation Department,
Max Planck Institute for Intelligent Systems, Tübingen, Germany
ana-andreea.stoica@tuebingen.mpg.de
Florian Dörfler †
Automatic Control Laboratory, ETH Zürich, Switzerland
dorfler@ethz.ch
June 26, 2024
Abstract
We study fairness in social influence maximization, whereby one seeks to select seeds that
spread a given information throughout a network, ensuring balanced outreach among different
communities (e.g. demographic groups). In the literature, fairness is often quantified in terms of
the expected outreach within individual communities. In this paper, we demonstrate that such
fairnessmetricscanbemisleadingsincetheyignorethestochasticnatureofinformationdiffusion
processes. When information diffusion occurs in a probabilistic manner, multiple outreach
scenarios can occur. As such, outcomes such as “in 50% of the cases, no one of group 1 receives
the information and everyone in group 2 receives it and in other 50%, the opposite happens”,
which always results in largely unfair outcomes, are classified as fair by a variety of fairness
metrics in the literature. We tackle this problem by designing a new fairness metric, mutual
fairness, that captures variability in outreach through optimal transport theory. We propose a
new seed-selection algorithm that optimizes both outreach and mutual fairness, and we show its
efficacy on several real datasets. We find that our algorithm increases fairness with only a minor
decrease (and at times, even an increase) in efficiency.
∗Equalcontribution.
†This work was partly supported by the National Center of Competence in Research «Dependable, ubiquitous
automation»
1
4202
nuJ
52
]IS.sc[
1v63771.6042:viXra1 Introduction
Problem Description. Social networksplaya fundamentalrolein thespread ofinformation, asin
the context of commercial products endorsement [18], job vacancy advertisements [3], public health
awareness [25], etc. Information, ideas, or new products can either go viral and potentially bring
significant changes in a community or die out quickly. In this context, a fundamental algorithmic
problem arises, known as Social Influence Maximization (SIM) [12, 13]. SIM studies how to strategi-
cally select a pre-specified small proportion of nodes in the social network, the early adopters or seeds
so that the outreach generated by a diffusion process that starts at these early adopters is maximized.
Consider, for example, a product endorsement campaign: the early adopters are strategically selected
users who receive the product first to promote it to their friends, who in turn may or may not adopt
it. The optimal selection of early adopters is known to be an NP-hard problem [12]. Thus, many
heuristic strategies have been proposed, based on iterative processes such as greedy algorithms or on
network centrality measures. However, all these algorithms purely rely on the graph topology and
are agnostic to users’ demographics, which raises significant fairness concerns, especially in contexts
of health awareness campaigns, education, and job advertisements, where one wants to ensure an
equitable spreading of information. Indeed, real-world social networks are populated by different
social groups, based on gender, age, race, geography, etc., with different group sizes or connectivity
patterns. Ignoring these aspects and only focusing on the outreach maximization process usually
leadstotheearlyadoptersbeingthemostcentralnodes. Consequently, low-interconnectedminorities
are often neglected from the diffusion process, thus causing fundamental inequity in the information
propagation and biases exacerbation [11, 23].
Related Work. The problem of SIM was first introduced in 2003 in Kempe et al. [12], where the
problemofoptimallyselectinga(limited)setofearlyadopterswasprovedtobeNP-hard. Thestudyof
SIMunderfairnessguaranteeshasamorerecenthistory[6]. Severalmultiplegroup-levelmetricsoffair-
nesshavebeenproposedovertheyears[7]. Theyfallunderthenotionsofequity [22,10,11],equality [7],
max-min fairness [8, 28], welfare [17], and diversity [23]: All of them quantify the fair distribution of
influenceacrossgroups. Inparticular,Stoicaetal.[22]proposeanewSIMalgorithmthatoperatesun-
dertheconstraintthat,inexpectation,thesamepercentageofusersineachcategoryisreached.Junaid
et al. [10] optimize outreach under fairness and time constraints, by ensuring that the expected frac-
tionofinfluencednodesineachgroupisthesamewithinaprescribedtimedeadline.Farnadietal.[7]
proposeaunifyingframeworkthatencodesalldifferentdefinitionsoffairnessintheSIMprocessascon-
straintsinalinearprogramthatoptimizesoutreach. Severalotherworks[8,28]adoptamax-minstrat-
egy. Specifically,inFishetal.[8]fairnessisensuredbymaximizingtheminimumprobabilityofagroup
receivingtheinformationthroughmodificationsofthegreedyalgorithm.Zhuetal.[28]ensurethatthe
outreach contains a pre-specified proportion of each group in a population. Finally, Tsang et al. [23]
optimizeoutreachundertheconstraintthatnogroupshouldbebetteroffbyleavingtheinfluencemax-
imization process with their proportional allocation of resources done internally. All these definitions
involveamarginalexpectedvalueoffairnessingroups,withoutconsideringthecorrelations–orother
higher-ordermoments–forthejointprobabilitydistributionofdifferentgroupsadoptingtheinforma-
tion(seeFarnadietal.[7]foranoverview). Incontrast,ourworkintroducesanovelformalismfortak-
ingintoaccounttheactualjointdistributionofoutreachamonggroups,highlightinglimitationsofvari-
ousfairnessmetricsanddevelopinganewseedselectionpolicythatstrategicallyextractsandoptimizes
ourproposednotionoffairness.Finally,ourworkisinspiredbyarecentlineofworkthatdrawsonOp-
timalTransporttheory[26]forfairnessguarantees[2,4,20,27]. Toourknowledge,thisisthefirstwork
to develop novel metrics and seeding algorithms that leverage optimal transport for the SIM problem.
Motivation. Many models of diffusion processes in the SIM problem are inherently stochastic,
meaning that who gets the information transmitted can vary greatly from one run to another.
Consider, as an example, the case in which 50% of simulations over a diffusion process, no one in
2group1receivestheinformationandeveryoneingroup2does, whereasintheother50%theopposite
happens. This largely unfair circumstance, would be classified as fair in expectation. We show how
this phenomenon is also common in real-world data and how our proposed framework can detect
such undesired scenarios. This prompts us to study a novel fairness metric.
Contributions. Our main contribution is two fold: first, a new fairness metric based on optimal
transport, called mutual fairness, and second, a novel seeding algorithm that optimizes for both the
group-wise total outreach (termed efficiency) and fairness. Our proposed fairness metric provides
stronger fairness guarantees; specifically, it reveals and overcomes known limitations of various other
fairness metrics in the literature. We leverage optimal transport theory to build mutual fairness,
a metric that accounts for all groups simultaneously in terms of the distance between an ideal
distribution where all groups receive the information in the same proportion. We leverage our
proposed mutual fairness metric to provide a unifying framework that classifies the most celebrated
information-spreading algorithms both in terms of fairness and efficiency. All algorithms are tested
on a variety of real-world datasets. We show how our approach unveils new insights into the role
of network topology on fairness; in particular, we observe that selecting group-label blind seeds in
networks with moderate levels of homophily induces inequality in information access. In contrast,
very integrated or very segregated networks tend to have quite fair and efficient access to information
across different groups upon greedy seedset selection. We then extend our mutual fairness metric to
also account for efficiency, thus introducing the notion of β-fairness. Finally, we design a new seedset
selection algorithm that optimizes over the proposed β-fairness metric and enhances fairness with
either a small trade-off or even improved efficiency. This novel approach provides a comprehensive
evaluation and design tool that bridges the gap between fairness and efficiency in SIM problems.
2 Preliminaries
Notation. Given m∈N, we let [m] denote the interval of integers from 1 to m. We denote by V a
network,consideredundirected,andby(C ) themgroupsofdifferentsensitiveattributes. Inthis
i i∈[m]
paper, we consider m=2 groups, noting that our framework is easily generalizable to more groups.
We denote by ϕ (S) the influence function of a seedset S over a network V, through some diffusion
V
process. In other words, ϕ (S) measures the set of nodes reached by the seedset under a diffusion
V
process. Then, |ϕ (S)| is often referred to as the outreach, a measure of efficiency for the selection of
V
a seedset S. Under a stochastic diffusion process (e.g., independent cascade, linear threshold model,
etc.), |ϕ (S)|isarandomvariable, forwhichweareinterestedintheexpectedvalueanddistribution.
V
For a particular outreach, we define the final configuration at the end of a diffusion process as follows.
Definition 2.1 (Final configuration) For a network V with communities (C ) and a seedset
i i∈[2]
S, we let x , i ∈ [2], denote the fraction of nodes in each community in the outreach ϕ (S). The
i V
final configuration, is the tuple (x ,x ).
1 2
In many definitions in the literature, fairness is operationalized as measuring the expected value
of the final configuration, where the expectation is taken over the diffusion process. In particular,
the equity definition introduced by Stoica et al. [22], Junaid et al. [10] checks that the expected value
of the proportions of each group reached in the outreach is the same for all groups. For a formal
definition of equity and other fairness definitions in the literature, see Appendix A. We now show
that relying solely on the expected value can compromise fairness.
3 Fairness via Optimal Transport
In contrast to the literature, we propose using the joint outreach probability distribution, instead
of its marginals, to capture the correlation between the two groups and therefore address questions
3(y ,y )
1 2
γ γ
b a
z(x ,x ,y ,y )
1 2 1 2
(x ,x )
1 2
%outreachgroup1 %outreachgroup1
Figure 1: Illustration of the (γ ,γ ) example. Figure 2: The transportation cost measures the
a b
length of the solid segment; shifts along the diag-
onal (dotted) are not considered for fairness and
are only relevant for efficiency.
like i) When group 1 receives the information, will group 2 also receive it? ii) Even if the two groups
have the same marginal outreach probability distributions will the final configuration always be fair?
We argue that capturing these aspects is crucial for understanding and assessing fairness, as shown
in the motivating example below.
Notation. Wecollecttheoutputoftheinformation-spreadingprocessviaaprobabilitydistribution
γ ∈ P([0,1]×[0,1]) over all possible final configurations. Informally, γ(x ,x ) is the probability
1 2
that a fraction x of group 1 receives the information and a fraction x of group 2 receives the
1 2
information;e.g.,γ(0.3,0.4)representstheprobabilitythat30%ofgroup1and40%ofgroup2receive
the information. We can marginalize γ to obtain the outreach probability distributions associated
(cid:80)
with each group; i.e., µ ∈P([0,1]) and µ ∈P([0,1]). Informally, we can write µ (x)= γ(x,y).
1 2 1 y
As in the example above, µ (0.3) is the probability that 30% of group i receives the information.
i
Motivating Example. Consider the SIM problem with nodes belonging to two groups, C and C ,
1 2
eachgrouphavingtheoutreachprobabilitydistributionµ = 1δ +1δ ,i∈{1,2},withδ representing
i 2 0 2 1 k
the Dirac delta centered at k ∈[0,1]. That is, in 50% of the cases all members in group i receive the
information (i.e., we get x =1.0) and in 50% of the cases no one in group i receives the information
i
(i.e., we get x =0.0). It is therefore tempting to say that this setting is fair since µ and µ coincide
i 1 2
andthereforesharethesameexpectedvalue. Wearguethatthisinformationdoesnotsufficetoclaim
fairness. Indeed, consider the two following probability distributions over the final configurations:
γ =0.5·δ +0.5·δ , γ =0.25·δ +0.25·δ +0.25·δ +0.25·δ .
a (0,0) (1,1) b (0,0) (1,1) (0,1) (1,0)
Interestingly, both γ and γ are “compatible” with µ and µ : if we compute their marginals, we
a b 1 2
obtain µ and µ . However, γ and γ encode two fundamentally different final configurations. In γ ,
1 2 a b a
thepercentageofmembersofgroup1whogettheinformationalways coincideswiththepercentageof
people of group 2. Conversely, in γ , more outcomes are possible; in particular, there is a probability
b
of0.25+0.25=0.5thatallmembersofonegroupreceivetheinformationandnomemberoftheother
group receives it (see Fig. 1). Thus, from a fairness perspective, γ and γ encode very different out-
a b
comes. Wethereforearguethatafairnessmetricshouldbeexpressedintermsofjoint probabilitydistri-
butionγ,andnotsolelybasedonitsmarginalsµ andµ ,ascommonlydoneintheliterature[22,10].
1 2
4
2puorghcaertuo% 2puorghcaertuo%3.1 A Fairness Metric Based on Optimal Transport
Ourmotivatingexamplepromptsustoreasonaboutfairnessintermsofthejointprobabilitymeasure
γ, instead of its marginal distributions µ and µ . Since γ is a probability distribution (over all
1 2
possible final configurations), we can quantify fairness by computing its “distance” from an “ideal”
reference distribution γ∗ along the diagonal, capturing the ideal situation in which both groups
receive the information in the same proportion. We do so by using tools from optimal transport.
Background in optimal transport. For a given (continuous) transportation cost c : ([0,1]×
[0,1])×([0,1]×[0,1])→R ,theoptimaltransportdiscrepancybetweentwoprobabilitydistributions
≥0
γ ∈P([0,1]×[0,1]) and γ ∈P([0,1]×[0,1]) is defined as
a b
W (γ ,γ )= min E ,[c((x ,x ),(y ,y ))] (1)
c a b
π∈Π(γa,γb)
(x1,x2),(y1,y2)∼γ 1 2 1 2
where Π(γ ,γ ) is the set of probability distributions over ([0,1]×[0,1])×([0,1]×[0,1]) so that its
a b
firstmarginalisγ anditssecondmarginalisγ . Intuitively,theoptimaltransportproblemquantifies
a b
the minimum transportation cost to morph γ into γ when transporting a unit of mass from (x ,x )
a b 1 2
to (y ,y ) costs c((x ,x ),(y ,y )). The optimization variable π is called transportation plan and
1 2 1 2 1 2
π((x ,x ),(y ,y )) indicates the amount of mass at (x ,x ) displaced to (y ,y ). Thus, its first
1 2 1 2 1 2 1 2
marginal has to be γ (x ,x ) (that is, (x ,x ) has to be transported to some (y ,y )) and its second
a 1 2 1 2 1 2
marginal must be γ (y ,y ) (that is, the mass at (y ,y ) has to arrive from some (x ,x )). If c is
b 1 2 1 2 1 2
chosen to be a p≥1 power of a distance d, then (W (·,·))1/p is a distance on the probability space.
dp
When the probability distributions are discrete (or the space [0,1] is discretized), the transportation
problem (1) is a finite-dimensional linear program and can therefore be solved efficiently [16].
Our proposed fairness metric. Tooperationalizetheoptimaltransportproblem(1),wetherefore
needtodefine(i)atransportationcostand(ii)areferencedistributionγ∗. Todefinethetransportation
cost, we start with the following two considerations. First, moving mass along the diagonal should
have a cost of 0, as it does not affect fairness but only the efficiency (the proportion of population
reached in respective groups). Second, moving mass orthogonally towards the diagonal should come
at a price, since the difference in group proportion outreach between groups 1 and 2 decreases. We
quantify this price as the squared Euclidean distance. This is illustrated in Fig. 2, which shows how
the joint distribution captures unfairness, by depicting the percentage outreach in each group on
each axis; thus, the diagonal represents a “fair” line, where the probability of reaching a particular
outreach percentage is the same for both groups.
These two insights suggest decomposing the distance between the initial configuration (x ,x )
1 2
(e.g., belonging to γ ) and (y ,y ) (e.g., belonging to γ ) into two components: one capturing
a 1 2 b
efficiency and the other one being the fairness component (see Fig. 2). Since the aim of our metric is
to measure fairness, we therefore obtain the transportation cost
c((x ,x ),(y ,y ))=∥z(x ,x ,y ,y )−(x ,x )∥=|(x −x )−(y −y )| (2)
1 2 1 2 1 2 1 2 1 2 2 1 1 2
where z(x ,x ,y ,y ) is the point indicated in green in Fig. 2 and ∥·∥ is the standard Euclidean
1 2 1 2
norm. Thus, the fairness “distance” between two distributions γ and γ can be readily quantified by
a b
W (γ ,γ ). Sincemovingalongthediagonalisfree,wequantifythefairnessofagivenγ asits“fairness”
c a b
distance from the “ideal” distribution γ∗ = δ , which represents the case where all members of
(1,1)
both groups receive the information. We can now formally introduce our proposed fairness metric.
Definition 3.1 (Mutual Fairness) Given a network with communities (C ) , a SIM algorithm
i i∈[2]
is said to be mutually fair if the algorithm propagation is such that it maximizes
Fairness(γ):=1−W (γ,γ∗),
c
5with W (γ,γ∗) the optimal transport discrepancy between the probability measure γ and the desired
c
probability measure γ∗ defined as in (1).
The mutual fairness from Definition 3.1 can be seen as a normalized expression of W (γ,γ∗) to
c
contain its values in [0,1]. Indeed, its lowest value is 0 and it is achieved with γ =δ , for which is
(0,1)
W (γ,γ∗)=1; its largest value is 1 and it is achieved with δ =δ∗, for which W (γ∗,γ∗)=0. Since
c c
γ∗ is a delta distribution, we can solve the transportation problem (1) in closed form to
(cid:20) (cid:21)
Fairness(γ)=1−W (γ,γ∗)=E 1−|x −x | ,
c (x1,x2)∼γ 1 2
which reduces to Fairness(γ)=1− 1 (cid:80)N |x −x | when the distribution γ is empirical with
N i=1 1,i 2,i
N samples {(x ,x )} . In particular, our fairness metric can also be interpreted as the average
1,i 2,i i∈[N]
distance between the outreach proportions within the two groups.
Discussion. We note that while we considered two groups in the aforementioned definitions, our
methodology readily extends the setting with n groups. Second, since moving mass “diagonally” is
free, any distribution γ∗ supported on the diagonal yields the same fairness metric. In practice, it
is often not the case that all the network members receive the information and the best one could
hope for is to project γ onto the diagonal; since moving along the diagonal is free, the fairness cost
is the same whether the ideal distribution is that projection or γ∗. Moreover, it is easy to see that
the “fairness distance” is symmetric, namely W (γ ,γ )=W (γ ,γ ). Finally, our definition readily
c a b c b a
extends to any other distance function besides the standard Euclidean metric.
Back to the motivating example. Armed with a definition of fairness that captures the nature
of a diffusion process, we now revisit the motivating example. To start, we evaluate the “fairness
distance” between γ and γ :
a b
√ √ √
1 2 1 2 2
W (γ ,γ )= · + · = ,
c a b 4 2 4 2 4
whichamountstothecostoftransportingthepoints(0,1)and(1,0),eachwithweight1/4,tothediag-
onal. Notably,incontrasttosimplycomputingtheexpectedoutreachofeachgroup,ourfairnessmetric
distinguishesthetwooutcomes. Similarly,wecaneasilycomputethefairnessmetric: Fairness(γ )=
a
1 and Fairness(γ )=0.5. In particular, γ achieves the highest fairness score. Indeed, its outcome
b a
will always be fair. Instead, Fairness(γ ) achieves a lower fairness score, capturing the fact that
b
in 50% of the cases the outcome is perfectly fair while in the remaining 50% it is largely unfair.
3.2 Mutual Fairness in Practice
Wenowinvestigatetheuseofournewlydefinedfairnessmetricacrossavarietyofreal-worlddatasets:
Add Health (AH), Antelope Valley variants 0 to 23 (AV_{0-23}) [24], APS Physics (APS) [14], Deezer
(DZ) [19], High School Gender (HS) [15], Indian Villages (IV) [1], and Instagram (INS) [21]. Each
dataset contains a social network with a chosen demographic dividing the population into two
non-overlapping groups (see Appendix B for details). We load the datasets as graphs G(V,E). We
then select a seedset S of size 2-90 (depending on the dataset) using the following heuristics: two
group-agnostic seed selection strategies as our baselines, namely degree centrality (bas_d), and greedy
(bas_g), proposed in Kempe et al. [12]. In addition, we implement two fair seed selection heuristics,
namely degree-central fair heuristic (hrt_d), and greedy fair heuristic (hrt_g), proposed in Stoica
et al. [22]. To model the information spread, we use the Independent Cascade Model, IC, for the
diffusion of information [12] with a probability p∈[0,1] for all edges. This process, being stochastic,
is simulated R times in a Monte Carlo sampling to achieve R final configurations (Definition 2.1)
6AH,p=0.5 AH,p=0.1 APS,p=0.3 AV_0,p=0.3
bas_g, S =10 bas_g, S =20 hrt_g, S =6 bas_g, S =4
| | | | | | | |
1 0.4 0.6
0.4
0.4
0.2
0.2
0.8 0.2
0 0 0
0.8 1 0 0.2 0.4 0 0.2 0.4 0 0.2 0.4 0.6
%outreachgroup1 %outreachgroup1 %outreachgroup1 %outreachgroup1
(a) (b) (c) (d)
Figure 3: Joint outreach probability distribution for different datasets, different propagation proba-
bilities p, and seedsets cardinalities |S|.
plotted together as a joint outreach distribution, in Fig. 3. Then we apply our distribution-aware
notionoffairnessfromSection3.1. WekeepR=1,000throughout,butexploreseveralvaluesinp,|S|–
mentioned per experiment in figures below, and exhaustively recorded with other hyperparameters
in Appendix C. All details related to computational resources and development environment are
available in Appendix F.
Aretheoutcomesfair? Asafirstexperiment,westudythejoint outreachprobabilitydistribution
for different datasets. We identify four qualitatively different outcomes, shown in Fig. 3 for a few
of the datasets. Additional experiments with different propagation probability and seed selection
strategies can be found in Appendix C. Fig. 3a is obtained on AH with bas_g selection strategy and
p = 0.5,|S| = 10. We note how the joint outreach distribution is almost concentrated on the top
right of the plane, i.e., the outcome is almost deterministic and highly fair and efficient. In turn, this
trivializes both the expected value in the equity metric and the cost in the mutual fairness metric in
Definition 3.1, which therefore essentially boils down to comparing the almost deterministic outreach
fraction within each group. In these cases, our fairness metric does not provide additional insights.
Such deterministic outcomes are typical of degree or greedy seedset outreach in dense graphs, such as
AH, DZ, INS (refer to Appendix C), with extreme probability of conduction (p≥0.5 or p→0), and
cross-group interconnectivity (see Table 1 in Appendix B). For moderate p (e.g., 0.1), the outreach
probability distribution is concentrated along the diagonal (Fig. 3b). Thus, both the equity metric
and our fairness measure are maximal. Nonetheless, our fairness metric provides additional insights:
not only does the expected outreach within each group coincide, but also the outreach at every
realization coincides (see the example in Section 3). Thus, our fairness metric provides a stronger
certificate of fairness. As before, the same applies to AH, DZ, INS in Appendix C. Intuitively, high
cross-groupinterconnectivityinadensegraphalreadyensuresfairness. Additionally,extremepvalues
ensure deterministic outreach (either the information dies out at the seedset, or reaches everyone in
the population). When propagation happens with moderate propagation probabilities, p, outreach
appears as Fig. 3b. Fig. 3c represents APS for its hrt_g seedset outreach and p=0.3,|S|=6. Here,
we observe a highly stochastic outcome, with many realizations for which almost no member of one
group receives the information. We argue such an outcome should not be classified as fair, despite
the expected value of the proportions being similar. Finally, Fig. 3d shows the AV_0 dataset with
p=0.3,|S|=4, and bas_g selection strategy. We observe a more stochastic outreach compared to
Fig. 3b with variance spread along, but not on the diagonal, with a little bias towards one group.
The impact of the conduction probability. As a second experiment, we investigate the
differencebetweenmutualfairnessandequity(differenceintheexpectedvalueofthe proportions), as
7
2puorghcaertuo% 2puorghcaertuo% 2puorghcaertuo% 2puorghcaertuo%IV,bas_g, S =2
| |
1 1
0.95 0.95
0.9 0.9
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
ConductionProbability
Figure 4: Optimal transport fairness (left axis, red) and equity (right axis, blue) calculated on IV
dataset as p varies in [0,1].
afunctionoftheconductionprobabilityp. WeconsidertheIVdatasetasacasestudyandselectseeds
by using bas_g. We show our results in Fig. 4. Our mutual fairness metric shows a fundamentally
different trend compared to the equity metric. Importantly, for p∈(0,0.5), both metrics have an
opposite trend: equity fairness increases to some extent meanwhile our metric suggests a huge fall in
fairnessinthisregion. Forp∈(0.5,0.7), thereisafallinequityfairness, whileourfairnessevaluation
remains relatively constant. It is only for p∈(0.8,1.0) that both metrics agree in trend. Thus, as in
the previous experiment, the equity metric fails to adequately capture changes in fairness. For more
experiments on other datasets, we refer to Appendix C.2.
3.3 Trading off Fairness and Efficiency
To construct our fairness metric, we completely discarded the efficiency of the final configuration. For
instance, the “fairness distance” between a configuration whereby no agent receives the information
(i.e., γ =δ ) and the “ideal” configuration whereby everyone receives the information (i.e., γ∗) is
(0,0)
zero, as both probability distributions lay on the diagonal. As such, the fairness score of γ =δ is
(0,0)
1 and therefore maximal. Thus, in practice, one seeks a fairness-efficiency tradeoff.
In our setting, we can easily introduce the tradeoff in the transportation cost (2). Specifically, we
can define the transportation cost as a weighted sum of the “diagonal distance” (measuring difference
in efficiency, dotted segment in Fig. 2) and the “orthogonal distance” (measures difference in fairness,
solid segment in Fig. 2). Formally, for a given weight β ≥0, the arising transportation cost
c ((x ,x ),(y ,y ))=β∥z(x ,x ,y ,y )−(x ,x )∥+(1−β)∥z(x ,x ,y ,y )−(y ,y )∥
β 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2
=β|(x −x )−(y −y )|+(1−β)|(x +x )−(y +y )|. (3)
2 1 1 2 1 2 1 2
Inparticular,forβ =1,werecoverthetransportationcost(2). WecanthenproceedasinSection3.1.
The “β-fairness-efficiency distance” between γ and γ is W (γ ,γ ) and the β-fairness metric can
a b cβ a b
be then defined as follows.
Definition 3.2 (β-Fairness) Consider a network with groups C ,C , a SIM algorithm is said to be
1 2
β-fair if the algorithm propagation is such that it maximizes
1
β−Fairness(γ):=1− W (γ,γ∗), (4)
2−β cβ
with W (γ,γ∗) defined as in (1) with transportation cost as in (3) and ideal distribution γ∗ =δ .
cβ (1,1)
8
ssenriaftropsnartlamitpO
)hcaertuo.pxeni.ffid(ytiuqEThe factors 1 and and 1/(2−β) in (4) ensure that the metric is non-negative and in [0,1]. Again,
the optimal transport problem can be solved in closed form, which yields
(cid:20) (cid:21)
β|x −x |+(1−β)|x +x −2|
β−Fairness(γ)=E 1− 1 2 1 2
(x1,x2)∼γ 2−β
In particular, for β =1, we recover the mutual fairness Fairness(γ) in Definition 3.1 and for β =0
we obtain the efficiency metric E [1− |x1+x2−2|].
(x1,x2)∼γ 2
4 Improving Fairness
4.1 Fairness-promoting Seed-selection Algorithm
Armed with a novel fairness metric, we now design an iterative seed-selection algorithm, which we
call Stochastic Seedset Selection Descent (S3D), that strategically selects seeds taking into account all
communities simultaneously. The pseudo-code is summarized in Algorithm 1. For more details, we
refer to Appendix D. For a given initial seedset, our algorithm explores new seeds and evaluates them
on the efficiency-fairness metric β−Fairness as in (4) for a desired value of the fairness-efficiency
tradeoff parameter β (S3D_STEP() in Appendix D), to decide if the new seedset becomes a candidate
fortheoptimizedseedset. Theseseedsaresearchedforbyiterativelysamplingstochasticallyreachable
nodesfromthecurrentseedset(SEEDSET_REACH()inAppendixD)whilemakingsuretheycontribute
to a non-overlapping outreach (Algorithm 1::5-7). To prevent getting stuck at some local minima of
the generally non-convex objective, the procedure allows for visiting inferior seedsets on β−Fairness
or even selecting completely random ones on rare occasions (Algorithm 1::12-18) using Metropolis
Sampling [5]. Otherwise, a high β−Fairness encourages opting for the new seedset with high
probability. Finally, we revisit all the seedset candidates collected so far and pick the one with the
largest β−Fairness as the optimal seedset. For a sparse graph G(V,E), with E =O(V), choosing
|S| seeds, averaging over R realizations to approximate outreach via Monte-Carlo sampling and
exploring k candidates using S3D_STEP suggests a total running time upper bound of O(kR|S||V|)
(see Appendix D for details about the algorithm complexity). In practice, k ∈[500,1000],R=1000
for S ∈[2,100] works well for all datasets.
4.2 Real-world Data
Are the outcomes more fair? We test our algorithm across a variety of datasets (Appendix B)
against our baselines (bas_d, bas_g). We initialize S3D algorithm with the two baseline seedsets
and hence include results from two separately optimized seedsets, S3D_d, S3D_g. Our results are
shown in Fig. 5. Informally, we observe that our seed-selection mechanism “moves” the probability
mass of the joint outreach probability distribution towards the diagonal, which, ultimately, increases
thefairnessoftheresultingconfiguration. Atthesametime, weeitherimproveinefficiencyaswellor
the sacrifice in efficiency is eventually minor, as we investigate more in detail in our next experiment.
Generally speaking, datasets with high cross-group connections (AH, DZ, INS) can already benefit a
lot from label-blind seed selection to get moderately fair outreach. Similarly, for datasets with low
cross-group connections (APS) a label-blind strategy, in order to maximize efficiency, selects a diverse
population of seeds from which all communities are reached. Therefore, label-blind algorithms work
similarlytoS3D.Inothermoderatecases(AV, HS, IV),instead,weobservesignificantimprovements
of S3D over label-blind strategies.
Classification of seed-selection algorithms. Inourlastexperiments,wecompare,acrossvarious
datasets (Appendix B), several algorithms along with ours in terms of efficiency and mutual fairness.
We consider the following algorithms: bas_d, bas_g, their fair heuristic counterparts, hrt_d, hrt_g,
9Algorithm 1 Stochastic Seedset Selection Descent
Input: Social Graph G(V ,E ), initial seed set S, β fairness weight, ϵ-tolerance
G G
Output: Optimal seedset S∗
1: S ←{} ▷ collection of candidates
2: for k iterations do ▷ configurable k
3: V S ←nodes reachable from S via cascade, using seedset_reach routine
4:
Sˆ←{}
5: for |S| iterations do
6: Sˆ←Sˆ∪{v}|v ∼V S
7: V Sˆ ←nodes reachable from Sˆ in a fixed horizon, using seedset_reach
8: V S ←V S \V Sˆ
9: E S ←−beta_fairness(S,β)
10: E Sˆ ←−beta_fairness(Sˆ,β)
11: p accept ←min{1,eES−E Sˆ} ▷ S acceptance based on energy change
12: if x∼B(p accept) then ▷ Metropolis Sampling in 12−18
13: S+ ←Sˆ ▷ get a better seedset
14: else
15: if x∼B(ϵ) then ▷ for some small constant ϵ
16: S+ ←{v i}| iS =| 1 | ∼S| V G ▷ random seedset
17: else
18: S+ ←S ▷ retain existing choice
19: S ←S∪{S+}
20: S ←S+ ▷ for next iteration
21: S∗ ←S ∈S |beta_fairness(S,β) is maximum ▷ via s3d_iterate
22: return S∗
against our S3D_d, S3D_g, initialized via greedy and degree centrality baseline seeds, respectively.
We show our results in Fig. 6. S3D achieves in almost all cases the highest fairness score (y-axis)
and generally a slightly lower efficiency score (x-axis), compared to others. Thus, our seed-selection
mechanism leads to fairer outcomes with only a minor decrease in efficiency.
5 Conclusions and Limitations
Conclusions. We propose a new fairness metric, called mutual fairness, in the context of SIM.
Mutual fairness draws on optimal transport and captures various fairness-related aspects (e.g., when
members of group 1 receive the information will members of group 2 receive it?) that are obscure to
the fairness metrics in the literature. We also leverage our novel fairness metric to design a new seed
selection strategy that tradeoffs fairness and efficiency. Across various real datasets, our algorithm
yields superior fairness with a minor decrease (and in some cases even an increase) in efficiency.
Limitations. Our proposed algorithm, S3D, is essentially a random combinatorial search in the
graph defining the social network. As such, its performance will generally depend on the quality of
the seedset initialization. Moreover, there is no guaranteed bound on the number of iterations needed
in S3D to achieve a desired level of fairness. Both aspects can be limiting in real-world applications.
10APS,p=0.3 IV,p=0.1 HS,p=0.01 HS,p=0.5
bas_d, S =6,β=0.8 bas_d, S =2,β=0.8 bas_g, S =10,β=0.5 bas_g, S =6,β=0.8
| | | | | | | |
00..66 00..22 00..22 11
00..44
00..11 00..11
00..22 00..88
00 00 00
00 00..22 00..44 00..66 00 00..11 00..22 00 00..11 00..22 00..88 11
%%oouuttrreeaacchhggrroouupp11 %%oouuttrreeaacchhggrroouupp11 %%oouuttrreeaacchhggrroouupp11 %%oouuttrreeaacchhggrroouupp11
(a) (b) (c) (d)
Figure5: DemonstrateS3D(red)improvementoveritslabel-blindbaselinecounter-partinitializations
(blue) for several datasets and propagation probabilities.Fig. 5d provides the strongest evidence that,
besides improving in fairness, our strategy can also be more efficient, from 83.1% to 87.9%.
APS,p=0.3 AV_0,p=0.3 HS,p=0.01 HS,p=0.5
S =6,β=0.8 S =4,β=0.8 S =10,β=0.5 S =6,β=0.8
| | | | | | | |
1 1 1 1
0.98 0.98
0.95
0.9 0.96 0.96
0.94 0.94
0.9
0.8 0.92 0.92
0.85 0.9 0.9
0 0.1 0.2 0.3 0.4 0.2 0.25 0.3 0.35 0.06 0.08 0.1 0.80.820.840.860.880.9
Efficiency Efficiency Efficiency Efficiency
Figure 6: S3D trade-off and improvement against other label-aware and label-blind algorithms. Filled
markers refer to greedy-based algorithms: ■= bas_g, = S3D_g, and ♦= hrt_g. Empty markers
refer to degree-based algorithms: □= bas_d, = S3D(cid:32)_d, and ♢= hrt_d. For statistical bounds,
we refer to Appendix E. (cid:35)
References
[1] Abhijit Banerjee, Arun G Chandrasekhar, Esther Duflo, and Matthew O Jackson. The diffusion
of microfinance. Science, 341(6144):1236498, 2013.
[2] EmilyBlack,SamuelYeom,andMattFredrikson. Fliptest: fairnesstestingviaoptimaltransport.
Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (FAT’20),
pages 111–121, 2020.
[3] Wei Chen, Wei Lu, and Ning Zhang. Time-critical influence maximization in social networks
withtime-delayeddiffusionprocess. In Proceedings of AAAI Conference of Artificial Intelligence,
26(1):1–7, 2012.
[4] Silvia Chiappa, Ray Jiang, Tom Stepleton, Aldo Pacchiano, Heinrich Jiang, and John Aslanides.
A general approach to fairness with optimal transport. Proceedings of the 2020 Conference on
Fairness, Accountability, and Transparency (FAT’20), pages 3633–3640, 2020.
[5] P. Robert Christian. The metropolis-hastings algorithm, 2016.
[6] Tang Fangshuang, Qi Liu, Zhu Hengshu, Chen Enhong, and Feida Zhu. Diversified social
11
ssenriaF
22ppuuoorrgghhccaaeerrttuuoo%% 22ppuuoorrgghhccaaeerrttuuoo%%
ssenriaF
22ppuuoorrgghhccaaeerrttuuoo%%
ssenriaF
22ppuuoorrgghhccaaeerrttuuoo%%
ssenriaFinfluence maximization. 2014 IEEE/ACM International Conference on Advances in Social
Networks Analysis and Mining (ASONAM 2014), pages 455–459, 2014.
[7] Golnoosh Farnadi, Behrouz Babaki, and Michel Gendreau. A unifying framework for fairness-
aware influence maximization. International World Wide Web Conference 2020, pages 714–722,
2020.
[8] Benjamin Fish, Ashkan Bashardoust, Danah Boyd, Sorelle Friedler, Carlos Scheidegger, and
Suresh Venkatasubramanian. Gaps in information access in social networks? International
World Wide Web Conference 2019, San Francisco, USA, pages 480–490, 2020.
[9] Aric Hagberg, Pieter Swart, and Daniel Chult. Exploring network structure, dynamics, and
function using networkx. 01 2008.
[10] Ali Junaid, Babaei Mahmoudreza, Abhijnan Chakraborty, Baharan Mirzasoleiman, Krishna P.
Gummadi, and Adish Singla. On the fairness of time-critical influence maximization in social
network. IEEE Transaction on knowledge and data engineering, 35(3):480–490, 2023.
[11] Fariba Karimi, Mathieu Génois, Claudia Wagner, Philipp Singer, and Markus Strohmaier.
Homophily influences ranking of minorities in social networks. Scientific reports, 8(1):11077,
2018.
[12] David Kempe, Jon Kleinberg, and Eva Tardos. Maximizing the spread of influence through a
social network. Proceedings of the 9th ACM SIGKDD Conference on Knowledge Discovery and
Data Mining, pages 137–146, 2003.
[13] David Kempe, Jon Kleinberg, and Éva Tardos. Influential nodes in a diffusion model for social
networks. In Automata, Languages and Programming: 32nd International Colloquium, ICALP
2005, Lisbon, Portugal, July 11-15, 2005. Proceedings 32, pages 1127–1138. Springer, 2005.
[14] EunLee,FaribaKarimi,ClaudiaWagner,Hang-HyunJo,MarkusStrohmaier,andMirtaGalesic.
Homophily and minority-group size explain perception biases in social networks. Nature human
behaviour, 3(10):1078–1087, 2019.
[15] Rossana Mastrandrea, Julie Fournet, and Alain Barrat. Contact patterns in a high school: a
comparisonbetweendatacollectedusingwearablesensors,contactdiariesandfriendshipsurveys.
PloS one, 10(9):e0136497, 2015.
[16] Gabriel Peyré, Marco Cuturi, et al. Computational optimal transport: With applications to
data science. Foundations and Trends® in Machine Learning, 11(5-6):355–607, 2019.
[17] Aida Rahmattalabi, Shahin Jabbari, Himabindu Lakkaraju, Phebe Vayanos, Max Izenberg,
Ryan Brown, Eric Rice, and Milind Tambe. Fair influence maximization: A welfare optimization
approach. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages
11630–11638, 2021.
[18] Matthew Richardson and Pedro Domingos. Mining knowledge-sharing sites for viral marketing.
In Proceedings of 8th International Conference on Knowledge, Discovery and Data Mining,pages
61–70, 2002.
[19] Benedek Rozemberczki and Rik Sarkar. Characteristic functions on graphs: Birds of a feather,
from statistical descriptors to parametric models. In Proceedings of the 29th ACM international
conference on information & knowledge management, pages 1325–1334, 2020.
[20] Nian Si, Karthyek Murthy, Jose Blanchet, and Viet Anh Nguyen. Testing group fairness via
optimal transport projections. Proceedings of the 38th International Conference on Machine
Learning, pages 9649–9659, 2021.
12[21] Ana-Andreea Stoica, Christopher Riederer, and Augustin Chaintreau. Algorithmic glass ceiling
in social networks: The effects of social recommendations on network diversity. In Proceedings
of the 2018 World Wide Web Conference, pages 923–932, 2018.
[22] Ana-Andreea Stoica, Jessy Xinyi Han, and Augustin Chaintreau. Seeding network influence in
biased networks and the benefits of diversity. Proceedings of The Web Conference 2020, pages
2089–2098, 2020.
[23] Alan Tsang, Bryan Wilder, Eric Rice, Milind Tambe, and Yair Zick. Group-fairness in influence
maximization. Proceedings of the Twenty-Eighth International Joint Conference on Artificial
Intelligence (IJCAI-19), pages 5997–6005.
[24] Alan Tsang, Bryan Wilder, Eric Rice, Milind Tambe, and Yair Zick. Group-fairness in influence
maximization. Proceedings of the Twenty-Eighth International Joint Conference on Artificial
Intelligence (IJCAI-19), pages 5997–6005, 2019.
[25] Thomas W. Valente and Patchareeya Pumpuang. Identifying opinion leaders to promote
behaviour change. Health, Education & Behaviour, 34(6):881–896, 2007.
[26] Cédric Villani. Optimal transport: old and new, volume 338. Springer, 2009.
[27] Meike Zehlike, Alex Loosley, Håkan Jonsson, Emil Wiedemann, and Philipp Hacker. Beyond
incompatibility: Trade-offs between mutually exclusive fairness criteria in machine learning and
law. arXiv preprint arXiv:2212.00469, 2022.
[28] Jianming Zhu, Smita Ghosh, and Weili Wu. Group influence maximization problem in social
networks. IEEE Transactions on Computational Social Sciences, 6(6):1156–1164, 2019.
13A Existing Fairness Metrics
Definition A.1 (Expected outreach ratio) Given a network with communities C ,...,C , the
1 m
SIM algorithm expected outreach ratio in C , x¯ , is the expected ratio of nodes reached in C , namely
i i i
E[|v reached |v ∈C |]
x¯ := i , ∀i∈{1,...,m}.
i |C |
i
Definition A.2 (Equality [22]) Given the groups C ,...,C , a configuration is said to be equal,
1 m
if the SIM algorithm chooses a seed set S in a way such that the proportion of all communities in the
seed set is the same, namely
E[|v ∈S|v ∈C |] E[|v ∈S|v ∈C |]
i = j ∀i,j ∈{1,...,m}.
|C | |C |
i j
The notion of equality focuses on the fair allocation of seeds to the groups proportional to the
size of the group within the population. This notion of fairness applies, for example, in the context
of advertising companies that aim at having a fair distribution of resources among groups.
Definition A.3 (Equity [22]) Given a network with communities C ,...,C , a SIM algorithm
1 m
that selects a seedset S is said to be equitable if the algorithm propagation reaches all communities in
a balanced way, i.e. x¯ =x¯ , ∀i,j ∈{1,...,m}.
i j
The notion of equity focuses on the outcome of the diffusion process, e.g. independent cascade, linear
threshold model and it is suitable in contexts in which one aims to reach a diverse population in
a calibrated way.
Definition A.4 (Max-min fairness [7]) GiventhegroupsC ,...,C , the max-minfairnesscrite-
1 m
rion maximizes the minimum expected outreach ratio among all groups, namely maxmin x¯ .
i∈{1,...,m} i
The goal of the maxmin fairness is to minimize the gap among different groups in the outreach. The
SIM problem under maxmin constraints has been investigated in [7, 8, 28].
Definition A.5 (Diversity [7]) Given the groups C ,...,C , let k = (cid:6) k· |Ci|(cid:7), where k is the
1 m i |V|
pre-specified total seed budget. Let x¯∗(C ):=max x¯ . A configuration is said to be diverse
if for each i∈{1,...,m} it holds
x¯i ≥i
x¯∗(C ),
wS h⊂ erC ei: x| ¯S|= rk eiferi
s to the expected outreach ratio in C
i i i i i
obtained from the seed set S, with |S|=k.
The notion of diversity ensures that each group receives influence at least equal to their internal
spread of influence. The SIM problem under diversity constraints has been investigated in [7, 23].
B Description and Properties of Datasets
To associate the notion of fairness developed in Sections 3.1 and 3.3 with the datasets and the
outcomes from experiments in Section 3.2 and 4.2, we summarize the dataset statistics in Table 1.
Minority Frac. is calculated as the fraction of the minority group nodes in the entire population.
Fraction of Cross Edges evaluates heterophily in the dataset, by calculating the fraction of edges that
connect different groups. A higher value means a more heterophilic network, whereas a lower value
means a more homophilic network.
14Add Health (AH). The Add Health datasets consists of a social network of students in schools
and a relation between them is represented by whether they nominated each other in the Add Health
surveys. We select a school at random with 1,997 students and use race as the sensitive attribute
(white and non-white).1
Antelope Valley (AV), [24]. We choose 4 random networks among the 24 available in the
AntelopeValleydatasettocompareourfairnessimprovingalgorithm,S3D,against[24],whichworked
on the same dataset. We also run our baselines and other fair seed selection heuristics from [22]
on these datasets to get a fair comparison. The two sensitive attribute groups are male and female,
self-reported in the dataset with binary attributes.
APS Physics (APS), [14]. The APS citation network contains 1,281 nodes, representing papers
written in two main topics: Classical Statistical Mechanics (CSM), constituting 31.8% of the papers,
and Quantum Statistical Mechanics (QSM), accounting for the rest. As Lee et al. [14] analyze, the
dataset has high homophily, meaning that each subfield cites more papers in their own field than
in the other field. For simplicity, we use only the largest connected component in the full dataset
(component stats in 1) between the two groups, for this study.
Deezer (DZ), [19]. A social network from Europe with 18,442 nodes, where each node has a
self-reported attributed gender (male or female). Men are the minority (44.3%) and women are the
majority (55.6%). The data has moderate homophily.
High School (HS), [15]. A highschool friendship network collected from Mastrandrea et al. [15],
with 133 nodes in its main connected component represented by students who self-identify as male
of female. The majority are female (60%), and the network is homophilic.
IndianVillages(IV), [1]. Thedatasetcontainsdifferentdemographicattributesfortheindividual
networks and the household networks collected in 77 Indian villages, from which we select Mother-
tongue (Telugu or Kannada) as the sensitive attribute. We note that most villages contain a majority
mothertongue, either Telugu or Kannada. We pick a random village with 90 individuals for our study.
Instagram (INS), [21]. An interaction network from Instagram containing 553,628 nodes, where
everyone has a labeled gender (45.57% men and 54.43% women). Each edge between two users
representsa‘like’or‘comment’thatoneusergaveanotheronapostedphoto. Thedatahasmoderate
homophily.
C Details on the Experiments and Extended Results
We use R=1000 throughout our experiments. For the outreach, we discretize the space [0,1]×[0,1]
into100×100equalsizedbins. ForS3D(refertoAppendixD),weuseconstants,exploit_to_explore=
1.3, non_acceptance_retention_prob=0.95, and shallow_horizon=4.
C.1 Outreach Distribution
We report additional experiments in Figs. 7 to 10.
1TheAddHealthprojectisfundedbygrantP01HD31921(Harris)fromtheEuniceKennedyShriverNational
InstituteofChildHealthandHumanDevelopment(NICHD),withcooperativefundingfrom23otherfederalagencies
andfoundations. AddHealthiscurrentlydirectedbyRobertA.HummerandfundedbytheNationalInstituteon
AgingcooperativeagreementsU01AG071448(Hummer)andU01AG071450(AielloandHummer)attheUniversityof
NorthCarolinaatChapelHill. AddHealthwasdesignedbyJ.RichardUdry,PeterS.Bearman,andKathleenMullan
15Dataset # Nodes # Edges Avg. Degree Diameter Minority % Frac. Cross Edges
AH 1997 8523 8.54 10 34.6 0.452
AV_0 500 969 3.87 12 49 0.189
AV_2 500 954 3.81 14 49.6 0.183
AV_16 500 949 3.8 13 47.6 0.210
AV_20 500 959 3.84 15 48.4 0.198
APS 1281 3064 4.78 26 31.8 0.056
DZ 18442 46172 5.00 25 44.4 0.476
HS 133 401 6.03 10 40.6 0.394
IV 90 238 5.29 13 26.7 0.265
INS 553628 652830 2.36 16 45.6 0.417
Table 1: Summary statistics of Datasets used.
HarrisattheUniversityofNorthCarolinaatChapelHill.
16AH,p=0.1 AH,p=0.1 AH,p=0.1 AH,p=0.1
hrt d, S =20 hrt g, S =20 bas d, S =20 bas g, S =20
| | | | | | | |
0.2 0.2 0.2 0.2
0 0 0 0
0 0.2 0 0.2 0 0.2 0 0.2
%outreachgroup1 %outreachgroup1 %outreachgroup1 %outreachgroup1
AH,p=0.5 AH,p=0.5 AH,p=0.5 AH,p=0.5
hrt d, S =10 hrt g, S =10 bas d, S =10 bas g, S =10
| | | | | | | |
1 1 1 1
0.8 0.8 0.8 0.8
0.8 1 0.8 1 0.8 1 0.8 1
%outreachgroup1 %outreachgroup1 %outreachgroup1 %outreachgroup1
APS,p=0.3 APS,p=0.3 APS,p=p=0.3 APS,p=0.3
hrt d, S =6 hrt g, S =6 bas d, S =6 bas g, S =6
| | | | | | | |
0.6 0.6 0.6 0.6
0.4 0.4 0.4 0.4
0.2 0.2 0.2 0.2
0 0 0 0
0 0.2 0.4 0.6 0 0.2 0.4 0.6 0 0.2 0.4 0.6 0 0.2 0.4 0.6
%outreachgroup1 %outreachgroup1 %outreachgroup1 %outreachgroup1
APS,p=0.3 APS,p=0.3 APS,p=p=0.3 APS,p=0.3
hrt d, S =6 hrt g, S =6 bas d, S =6 bas g, S =6
| | | | | | | |
0.6 0.6 0.6 0.6
0.4 0.4 0.4 0.4
0.2 0.2 0.2 0.2
0 0 0 0
0 0.2 0.4 0.6 0 0.2 0.4 0.6 0 0.2 0.4 0.6 0 0.2 0.4 0.6
%outreachgroup1 %outreachgroup1 %outreachgroup1 %outreachgroup1
Figure 7: Outreach distribution.
17
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%AV 0,p=0.3 AV 0,p=0.3 AV 0,p=p=0.3 AV 0,p=0.3
hrt d, S =4 hrt g, S =4 bas d, S =4 bas g, S =4
| | | | | | | |
0.6 0.6 0.6 0.6
0.4 0.4 0.4 0.4
0.2 0.2 0.2 0.2
0 0 0 0
0 0.2 0.4 0.6 0 0.2 0.4 0.6 0 0.2 0.4 0.6 0 0.2 0.4 0.6
%outreachgroup1 %outreachgroup1 %outreachgroup1 %outreachgroup1
AV 2,p=0.2 AV 2,p=0.2 AV 2,p=p=0.2 AV 2,p=0.2
hrt d, S =4 hrt g, S =4 bas d, S =4 bas g, S =4
| | | | | | | |
0.4 0.4 0.4 0.4
0.2 0.2 0.2 0.2
0 0 0 0
0 0.2 0.4 0 0.2 0.4 0 0.2 0.4 0 0.2 0.4
%outreachgroup1 %outreachgroup1 %outreachgroup1 %outreachgroup1
AV 2,p=0.2 AV 2,p=0.2 AV 2,p=p=0.2 AV 2,p=0.2
hrt d, S =4 hrt g, S =4 bas d, S =4 bas g, S =4
| | | | | | | |
0.4 0.4 0.4 0.4
0.2 0.2 0.2 0.2
0 0 0 0
0 0.2 0.4 0 0.2 0.4 0 0.2 0.4 0 0.2 0.4
%outreachgroup1 %outreachgroup1 %outreachgroup1 %outreachgroup1
AV 16,p=0.1 AV 16,p=0.1 AV 16,p=p=0.1 AV 16,p=0.1
hrt d, S =10 hrt g, S =10 bas d, S =10 bas g, S =10
| | | | | | | |
0.2 0.2 0.2 0.2
0 0 0 0
0 0.2 0 0.2 0 0.2 0 0.2
%outreachgroup1 %outreachgroup1 %outreachgroup1 %outreachgroup1
AV_20,p=0.5 AV_20,p=0.5 AV_20,p=0.5 AV_20,p=0.5
hrt_d, S =15 hrt_g, S =15 bas_d, S =15 bas_g, S =15
| | | | | | | |
1 1 1 1
0.8 0.8 0.8 0.8
0.6 0.6 0.6 0.6
0.4 0.4 0.4 0.4
0.4 0.6 0.8 1 0.4 0.6 0.8 1 0.4 0.6 0.8 1 0.4 0.6 0.8 1
%outreachgroup1 %outreachgroup1 %outreachgroup1 %outreachgroup1
Figure 8: Outreach distribution.
18
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%DZ,p=0.1 DZ,p=0.1 DZ,p=0.1 DZ,p=0.1
hrt d, S =90 hrt g, S =90 bas d, S =90 bas g, S =90
| | | | | | | |
0.2 0.2 0.2 0.2
0 0 0 0
0 0.2 0 0.2 0 0.2 0 0.2
%outreachgroup1 %outreachgroup1 %outreachgroup1 %outreachgroup1
HS,p=0.01 HS,p=0.01 HS,p=0.01 HS,p=0.01
hrt d, S =10 hrt g, S =10 bas d, S =10 bas g, S =10
| | | | | | | |
0.2 0.2 0.2 0.2
0 0 0 0
0 0.2 0 0.2 0 0.2 0 0.2
%outreachgroup1 %outreachgroup1 %outreachgroup1 %outreachgroup1
HS,p=0.5 HS,p=0.5 HS,p=0.5 HS,p=0.5
hrt d, S =6 hrt g, S =6 bas d, S =6 bas g, S =6
| | | | | | | |
1 1 1 1
0.8 0.8 0.8 0.8
0.6 0.6 0.6 0.6
0.6 0.8 1 0.6 0.8 1 0.6 0.8 1 0.6 0.8 1
%outreachgroup1 %outreachgroup1 %outreachgroup1 %outreachgroup1
HS,p=0.1 HS,p=0.1 HS,p=0.1 HS,p=0.1
hrt d, S =4 hrt g, S =4 bas d, S =4 bas g, S =4
| | | | | | | |
0.4 0.4 0.4 0.4
0.2 0.2 0.2 0.2
0 0 0 0
0 0.2 0.4 0 0.2 0.4 0 0.2 0.4 0 0.2 0.4
%outreachgroup1 %outreachgroup1 %outreachgroup1 %outreachgroup1
Figure 9: Outreach distribution.
19
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%IV,p=0.1 IV,p=0.1 IV,p=0.1 IV,p=0.1
hrt d, S =2 hrt g, S =2 bas d, S =2 bas g, S =2
| | | | | | | |
0.2 0.2 0.2 0.2
0 0 0 0
0 0.2 0 0.2 0 0.2 0 0.2
%outreachgroup1 %outreachgroup1 %outreachgroup1 %outreachgroup1
IV,p=0.1 IV,p=0.1 IV,p=0.1 IV,p=0.1
hrt d, S =2 hrt g, S =2 bas d, S =2 bas g, S =2
| | | | | | | |
0.2 0.2 0.2 0.2
0 0 0 0
0 0.2 0 0.2 0 0.2 0 0.2
%outreachgroup1 %outreachgroup1 %outreachgroup1 %outreachgroup1
Figure 10: Outreach distribution.
20
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%
2puorghcaertuo%C.2 The Impact of the Conduction Probability for Various Dataset
We report additional experiments in Figs. 11 and 12.
AH,bas_g, S =6
| |
1 1
0.98 0.98
0.96 0.96
00 0.1 00..22 0.3 00..44 0.5 00..66 0.7 00..88 0.9 11
ConductionProbability
(a) bas_g seeds in AH, |S|=6
APS,bas_d, S =15
| |
1 1
0.9 0.9
0.8 0.8
0.7 0.7
00 0.1 00..22 0.3 00..44 0.5 00..66 0.7 00..88 0.9 11
ConductionProbability
(b) bas_d seeds in APS, |S|=15
APS,bas_g, S =15
| |
1 1
0.95 0.95
0.9 0.9
00 0.1 00..22 0.3 00..44 0.5 00..66 0.7 00..88 0.9 11
ConductionProbability
(c) bas_g seeds in APS, |S|=15
Figure 11: Part 1: Different definitions of fairness VS conduction probability on an outreach
distribution created by the bas_g or bas_d heuristic.
21
ssenriaftropsnartlamitpO
ssenriaftropsnartlamitpO
ssenriaftropsnartlamitpO
)hcaertuo.pxeni.ffid(ytiuqE
)hcaertuo.pxeni.ffid(ytiuqE
)hcaertuo.pxeni.ffid(ytiuqEAV_0,bas_g, S =20
| |
1
1
0.98
0.99
0.96
0.98
0.94
0.92 0.97
00 0.1 00..22 0.3 00..44 0.5 00..66 0.7 00..88 0.9 11
ConductionProbability
(a) bas_g seeds in AV_0, |S|=20
DZ,bas_g, S =50
| |
1 1
0.98 0.98
0.96 0.96
0.94 0.94
00 0.1 00..22 0.3 00..44 0.5 00..66 0.7 00..88 0.9 11
ConductionProbability
(b) bas_g seeds in DZ, |S|=50
HS,bas_g, S =6
| |
1 1
0.95 0.95
0.9 0.9
00 0.1 00..22 0.3 00..44 0.5 00..66 0.7 00..88 0.9 11
ConductionProbability
(c) bas_g seeds in HS, |S|=6
IV,bas_g, S =2
| |
1 1
0.95 0.95
0.9 0.9
00 0.1 00..22 0.3 00..44 0.5 00..66 0.7 00..88 0.9 11
ConductionProbability
(d) bas_g seeds in IV, |S|=2
Figure 12: Part 2: Different definitions of fairness VS conduction probability on an outreach
distribution created by the bas_g heuristic.
22
ssenriaftropsnartlamitpO
ssenriaftropsnartlamitpO
ssenriaftropsnartlamitpO
ssenriaftropsnartlamitpO
)hcaertuo.pxeni.ffid(ytiuqE
)hcaertuo.pxeni.ffid(ytiuqE
)hcaertuo.pxeni.ffid(ytiuqE
)hcaertuo.pxeni.ffid(ytiuqEC.3 Fairness-Efficiency performance of seedset selection algorithms
We report more experiments in Fig. 13.
AH,p=0.1 AH,p=0.5 APS,p=0.3 APS,p=0.3
S =10,β=0.8 S =10,β=0.8 S =6,β=0.5 S =6,β=0.8
| | | | | | | |
1 1 1 1
0.99 1
0.9 0.9
0.98 0.99
0.97 0.99
0.8 0.8
0.96 0.98
0.10.120.140.160.180.2 0.94 0.94 0.95 0.95 0.96 0 0.1 0.2 0.3 0.4 0.1 0.2 0.3 0.4
Efficiency Efficiency Efficiency Efficiency
AV_0,p=0.3 AV_2,p=0.2 AV_2,p=0.2 AV_16,p=0.1
S =4,β=0.8 S =4,β=0.5 S =4,β=0.8 S =10,β=0.8
| | | | | | | |
1 1 1 1
0.98
0.96 0.98 0.98 0.98
0.94
0.92 0.96 0.96 0.96
0.9
0.2 0.25 0.3 0.35 0.06 0.08 0.1 0.06 0.08 0.1 0 0.020.040.060.080.1
Efficiency Efficiency Efficiency Efficiency
AV_20,p=0.5 DZ,p=0.1 HS,p=0.01 HS,p=0.5
S =15,β=0.8 S =90,β=0.8 S =10,β=0.5 S =6,β=0.8
| | | | | | | |
1 1 1 1
0.98 0.98 0.98
0.96 0.96 0.96
0.94 0.94 0.94
0.92 0.92 0.92
0.9 0.99 0.9 0.9
0.6 0.65 0.7 0.75 0.8 0.060.080.10.120.14 0.06 0.08 0.1 0.80.820.840.860.880.9
Efficiency Efficiency Efficiency Efficiency
HS,p=0.1 IV,p=0.1 IV,p=0.1 INS,p=0.5
S =4,β=0.8 S =2,β=0.5 S =2,β=0.8 S =28,β=0.8
| | | | | | | |
1 1 1 1
0.98 0.98 0.98
0.96 0.96 0.96 0.98
0.94 0.94 0.94
0.92 0.92 0.92 0.96
0.9 0.9 0.9
0.060.080.10.120.14 0 0.020.040.060.080.1 0 0.020.040.060.080.1 0.460.480.50.520.54
Efficiency Efficiency Efficiency Efficiency
Figure 13: S3D trade-off and improvement against other label-aware and label-blind algorithms.
Filled markers refer to greedy-based algorithms: ■= bas_g, = S3D_g, and ♦= hrt_g. Empty
markers refer to degree-based algorithms: □= bas_d, = S3D(cid:32)_d, and ♢= hrt_d.
(cid:35)
23
ssenriaF
ssenriaF
ssenriaF
ssenriaF
ssenriaF
ssenriaF
ssenriaF
ssenriaF
ssenriaF
ssenriaF
ssenriaF
ssenriaF
ssenriaF
ssenriaF
ssenriaF
ssenriaFD Details on the Algorithm
D.1 Pseudocode
We provide more details on our algorithm, S3D, in two routines, Algorithm 2 and Algorithm 3.
D.2 Estimating Runtime
We estimate the running time of Algorithm 2 and 3 combined. For the S3D_STEP, lines 9-13 are
constant operations and comprise dataset properties. Line 14,15 cost O(|S|). FIT_TO_SIZE can cost
up to O(|S|log|V|) for sampling new |S| nodes. SEEDSET_REACH does repeated BFS, and so costs
O(R(|V|+|E|)). Lines 19-24 cost as follows,
O((|S−1)(RdDmax +R|V|+logR|V|)
avg
where d is the average degree of the graph, and D is the largest diameter of the graph. The
avg max
first term here upper bounds the max computation in BFS for D horizon. Other terms follow
max
from the remaining operations in the while loop. Now, lines 25−26 first create an outreach from
the corresponding seedsets, costing O(R(|V|+|E|)) each, and then analytically calculate β-fairness
for all the R final configurations, costing O(R∗1) each. In the worst case, we might additionally
execute lines 37−39 costing O(|S|log|V|). So, a single S3D_STEP costs,
O(2|S|+|S|log|V|+R(|V|+|E|)+(|S−1)(RdDmax +R|V|+logR|V|)
avg
+2(R(|V|+|E|)+R)+|S|log|V|)
=O(|S|log|V|+R(|V|+|E|)
+R|S|+R|S||V|+|S|log|V|)
=O(|S|log|V|+R|S||V|)
=O(R|S||V|).
Here, we used the assumption that d =O(2E/V)=O(1) for a sparse graph (E =O(V)). Now
avg
this S3D_STEP is run k times using S3D_ITERATE to find the best seedset in these k runs. Moreover,
we avoid any redundant calculations and memoize β-fariness for any seedset we discover. Hence, the
total runtime is O(kR|S||V|), as claimed.
D.3 Illustrative Example
Consider the information spreading over the graph in Fig. 14 as an independent cascade model
with probability p = 0.1, with blue and red nodes belonging to two different groups. A greedy
strategy would choose the seed set as S =3,5 (enlarged nodes) as shown in Fig. 14a, thus leading
g
to the highly unfair outreach in Fig. 14b. On the contrary, our algorithm S3D promotes the choice
S =1,4 reflected in 14c, which gives the more fair outreach plotted in Fig. 14d, showing that it
S3D
improves over greedy/sophisticated label-blind seed selection strategies.
24Algorithm 2 Seed Selection Stochastic Descent (S3D) Step: Pseudo Code
1: function seedset_reach(seedset,G,p,horizon) ▷ nodes reached from seedset until horizon
2: realizations←1000 ▷ for MCMC sampling, configurable
3: reach←[]
4: while realizations do
5: reach←reach+ independent_cascade(seedset, G, p, horizon) ▷ collect nodes
reached
6: realizations←realizations−1
7: return reach ▷ repetition of nodes reached
8: function s3d_step(seedset, G, p, fair_to_efficacy) ▷ each step delivers a new seedset
9: exploit_to_explore←1.3 ▷ experimentally chosen, configurable
10: non_acceptance_retention_prob←0.95 ▷ prob. of retaining set
11: max_horizon← get_diam(G)
12: horizon_factor← max_horizon/4 ▷ limit runtime
13: shallow_horizon←max_horizon/horizon_factor
14: num_seeds←len(seedset)
15: seedset← distinct(seedset)
16: seedset← fit_to_size(seedset, num_seeds) ▷ fit to size with random nodes
17: reach←seedset_reach(seedset, G, p, max_horizon)
18: candidate_set←[sample(reach,1)] ▷ get first in candidate seedset
19: while num_seeds do
20: last_seed←candidate_set[−1] ▷ get latest seed
21: ▷ remove shallow reach of last seed from current reach
22: reach←reach− seedset_reach([last_seed], G, p, shallow_horizon)
23: candidate_set←candidate_set+[sample(reach,1)] ▷ extend new seedset
24: num_seeds←num_seeds−1
25: curr_score← -beta_fairness(seedset, fair_to_efficacy)
26: candidate_score← -beta_fairness(candidate_set, fair_to_efficacy)
27: ▷ Metropolis Sampling
28: energy_change←curr_score−candidate_score
29: accept_prob← clip(exp(exploit_to_explore∗energy_change), [0,1])
30: nonce_1←U(0,1)
31: if nonce_1<accept_prob then
32: return candidate_set ▷ get a better seedset
33: else
34: nonce_2←U(0,1)
35: if nonce_2<non_acceptance_retention_prob then
36: return seedset ▷ retain existing choice
37: else
38: random_set← sample(G.nodes, num_seeds)
39: return random_set ▷ completely random selection rarely
25Algorithm 3 S3D Iteration: Pseudo Code
1: function s3d_iterate(seedset, G, p, fair_to_efficacy, num_iters)
2: least_score_seedset←seedset
3: least_score← -beta_fairness(seedset, fair_to_efficacy)
4: while num_iters do
5: seedset← s3d_step(seedset, G, p, fair_to_efficacy)
6: score← -beta_fairness(seedset, fair_to_efficacy)
7: if score<least_score then
8: least_seedset←seedset
9: num_iters←num_iters−1
10: return least_seedset
26(a) Greedy Choice: Graph (b) Greedy Choice: Outreach
(c) S3D Choice: Graph (d) S3D Choice: Outreach
Figure 14: Toy example to show label-aware choice using S3D over a label-blind seedset selection process.
The enlarged nodes are selected seeds. Since the graph is small, the outreach discretization bucket have been
granularized for improved readability.
27E Error Bars on Fairness and Efficiency Experiments
Referring to Fig. 6, we mention 2-sigma symmetrical error bars as follows.
- Eff-Mean Efficiency-Err-Bar (±2σ) Fair-Mean Fairness-Err-Bar (±2σ)
s3d_d 0.24 0.0022 0.94 0.002
hrt_d 0.105 0.005 0.911 0.004
bas_d 0.173 0.0016 0.803 0.003
s3d_g 0.25 0.002 0.945 0.002
hrt_g 0.17 0.0058 0.868 0.006
bas_g 0.318 0.002 0.898 0.003
Table 2: APS.
- Eff-Mean Efficiency-Err-Bar (±2σ) Fair-Mean Fairness-Err-Bar (±2σ)
s3d_d 0.241 0.005 0.95 0.002
hrt_d 0.227 0.005 0.951 0.002
bas_d 0.277 0.004 0.935 0.002
s3d_g 0.241 0.005 0.951 0.002
hrt_g 0.258 0.005 0.945 0.003
bas_g 0.3 0.004 0.926 0.003
Table 3: AV_0.
- Eff-Mean Efficiency-Err-Bar (±2σ) Fair-Mean Fairness-Err-Bar (±2σ)
s3d_d 0.08 0.0004 0.99 0.0008
hrt_d 0.08 0.0004 0.967 0.0007
bas_d 0.08 0.0004 0.91 0.001
s3d_g 0.08 0.0004 0.988 0.0008
hrt_g 0.08 0.0004 0.965 0.0008
bas_g 0.08 0.0004 0.938 0.0009
Table 4: HS, p=0.01.
28- Eff-Mean Efficiency-Err-Bar (±2σ) Fair-Mean Fairness-Err-Bar (±2σ)
s3d_d 0.88 0.002 0.96 0.001
hrt_d 0.83 0.002 0.94 0.002
bas_d 0.83 0.002 0.94 0.002
s3d_g 0.87 0.002 0.96 0.002
hrt_g 0.86 0.002 0.935 0.002
bas_g 0.89 0.002 0.94 0.002
Table 5: HS, p=0.5.
F Declaration of Computational Resources
All experiments were performed on a local PC on a single CPU core 3.5 GHz. Except for datasets DZ,
INS,alldatasetswereloadedandoperatedonalocalPCwith32GBofRAM.Forthelargestdatasets
(DZ, INS),weusedremotecomputeclusterswith∼64GBmemoryandsimilarCPUcapabilities. For
the code development, we broadly used Python 3.10+, numpy, jupyter, and networkx [9]. Runtime
for each non-S3D configured experiment on datasets except DZ, INS, was 10−15 minutes. For DZ,
INS, this was approximately 1−2 hours. For S3D optimizations to be satisfactory, we ran each small
dataset (except DZ, INS) for 1.5 hours additionally. For massive datasets DZ, INS, the compute
cluster took ∼4 days for k =10 steps. The total set of experiments made, including the failed and
passed or submitted ones, roughly took the same order of resources separately.
29