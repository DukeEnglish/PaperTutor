[
    {
        "title": "A New Perspective on Shampoo's Preconditioner",
        "authors": "Depen MorwaniItai ShapiraNikhil VyasEran MalachSham KakadeLucas Janson",
        "links": "http://arxiv.org/abs/2406.17748v1",
        "entry_id": "http://arxiv.org/abs/2406.17748v1",
        "pdf_url": "http://arxiv.org/pdf/2406.17748v1",
        "summary": "Shampoo, a second-order optimization algorithm which uses a Kronecker product\npreconditioner, has recently garnered increasing attention from the machine\nlearning community. The preconditioner used by Shampoo can be viewed either as\nan approximation of the Gauss--Newton component of the Hessian or the\ncovariance matrix of the gradients maintained by Adagrad. We provide an\nexplicit and novel connection between the $\\textit{optimal}$ Kronecker product\napproximation of these matrices and the approximation made by Shampoo. Our\nconnection highlights a subtle but common misconception about Shampoo's\napproximation. In particular, the $\\textit{square}$ of the approximation used\nby the Shampoo optimizer is equivalent to a single step of the power iteration\nalgorithm for computing the aforementioned optimal Kronecker product\napproximation. Across a variety of datasets and architectures we empirically\ndemonstrate that this is close to the optimal Kronecker product approximation.\nAdditionally, for the Hessian approximation viewpoint, we empirically study the\nimpact of various practical tricks to make Shampoo more computationally\nefficient (such as using the batch gradient and the empirical Fisher) on the\nquality of Hessian approximation.",
        "updated": "2024-06-25 17:34:51 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.17748v1"
    },
    {
        "title": "Probing the effects of broken symmetries in machine learning",
        "authors": "Marcel F. LangerSergey N. PozdnyakovMichele Ceriotti",
        "links": "http://arxiv.org/abs/2406.17747v1",
        "entry_id": "http://arxiv.org/abs/2406.17747v1",
        "pdf_url": "http://arxiv.org/pdf/2406.17747v1",
        "summary": "Symmetry is one of the most central concepts in physics, and it is no\nsurprise that it has also been widely adopted as an inductive bias for\nmachine-learning models applied to the physical sciences. This is especially\ntrue for models targeting the properties of matter at the atomic scale. Both\nestablished and state-of-the-art approaches, with almost no exceptions, are\nbuilt to be exactly equivariant to translations, permutations, and rotations of\nthe atoms. Incorporating symmetries -- rotations in particular -- constrains\nthe model design space and implies more complicated architectures that are\noften also computationally demanding. There are indications that non-symmetric\nmodels can easily learn symmetries from data, and that doing so can even be\nbeneficial for the accuracy of the model. We put a model that obeys rotational\ninvariance only approximately to the test, in realistic scenarios involving\nsimulations of gas-phase, liquid, and solid water. We focus specifically on\nphysical observables that are likely to be affected -- directly or indirectly\n-- by symmetry breaking, finding negligible consequences when the model is used\nin an interpolative, bulk, regime. Even for extrapolative gas-phase\npredictions, the model remains very stable, even though symmetry artifacts are\nnoticeable. We also discuss strategies that can be used to systematically\nreduce the magnitude of symmetry breaking when it occurs, and assess their\nimpact on the convergence of observables.",
        "updated": "2024-06-25 17:34:09 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.17747v1"
    },
    {
        "title": "Identifying Nonstationary Causal Structures with High-Order Markov Switching Models",
        "authors": "Carles Balsells-RodasYixin WangPedro A. M. MedianoYingzhen Li",
        "links": "http://arxiv.org/abs/2406.17698v1",
        "entry_id": "http://arxiv.org/abs/2406.17698v1",
        "pdf_url": "http://arxiv.org/pdf/2406.17698v1",
        "summary": "Causal discovery in time series is a rapidly evolving field with a wide\nvariety of applications in other areas such as climate science and\nneuroscience. Traditional approaches assume a stationary causal graph, which\ncan be adapted to nonstationary time series with time-dependent effects or\nheterogeneous noise. In this work we address nonstationarity via\nregime-dependent causal structures. We first establish identifiability for\nhigh-order Markov Switching Models, which provide the foundations for\nidentifiable regime-dependent causal discovery. Our empirical studies\ndemonstrate the scalability of our proposed approach for high-order\nregime-dependent structure estimation, and we illustrate its applicability on\nbrain activity data.",
        "updated": "2024-06-25 16:38:27 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.17698v1"
    },
    {
        "title": "Diffusion-based Adversarial Purification for Intrusion Detection",
        "authors": "Mohamed Amine MerzoukErwan BeurierReda YaichNora Boulahia-CuppensFrédéric Cuppens",
        "links": "http://arxiv.org/abs/2406.17606v1",
        "entry_id": "http://arxiv.org/abs/2406.17606v1",
        "pdf_url": "http://arxiv.org/pdf/2406.17606v1",
        "summary": "The escalating sophistication of cyberattacks has encouraged the integration\nof machine learning techniques in intrusion detection systems, but the rise of\nadversarial examples presents a significant challenge. These crafted\nperturbations mislead ML models, enabling attackers to evade detection or\ntrigger false alerts. As a reaction, adversarial purification has emerged as a\ncompelling solution, particularly with diffusion models showing promising\nresults. However, their purification potential remains unexplored in the\ncontext of intrusion detection. This paper demonstrates the effectiveness of\ndiffusion models in purifying adversarial examples in network intrusion\ndetection. Through a comprehensive analysis of the diffusion parameters, we\nidentify optimal configurations maximizing adversarial robustness with minimal\nimpact on normal performance. Importantly, this study reveals insights into the\nrelationship between diffusion noise and diffusion steps, representing a novel\ncontribution to the field. Our experiments are carried out on two datasets and\nagainst 5 adversarial attacks. The implementation code is publicly available.",
        "updated": "2024-06-25 14:48:28 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.17606v1"
    },
    {
        "title": "Causal Responder Detection",
        "authors": "Tzviel FrostigOshri MachlufAmitay KamberElad BerkmanRaviv Pryluk",
        "links": "http://arxiv.org/abs/2406.17571v1",
        "entry_id": "http://arxiv.org/abs/2406.17571v1",
        "pdf_url": "http://arxiv.org/pdf/2406.17571v1",
        "summary": "We introduce the causal responders detection (CARD), a novel method for\nresponder analysis that identifies treated subjects who significantly respond\nto a treatment. Leveraging recent advances in conformal prediction, CARD\nemploys machine learning techniques to accurately identify responders while\ncontrolling the false discovery rate in finite sample sizes. Additionally, we\nincorporate a propensity score adjustment to mitigate bias arising from\nnon-random treatment allocation, enhancing the robustness of our method in\nobservational settings. Simulation studies demonstrate that CARD effectively\ndetects responders with high power in diverse scenarios.",
        "updated": "2024-06-25 14:09:06 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.17571v1"
    }
]