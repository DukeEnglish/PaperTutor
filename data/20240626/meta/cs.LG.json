[
    {
        "title": "EXTRACT: Efficient Policy Learning by Extracting Transferrable Robot Skills from Offline Data",
        "authors": "Jesse ZhangMinho HeoZuxin LiuErdem BiyikJoseph J LimYao LiuRasool Fakoor",
        "links": "http://arxiv.org/abs/2406.17768v1",
        "entry_id": "http://arxiv.org/abs/2406.17768v1",
        "pdf_url": "http://arxiv.org/pdf/2406.17768v1",
        "summary": "Most reinforcement learning (RL) methods focus on learning optimal policies\nover low-level action spaces. While these methods can perform well in their\ntraining environments, they lack the flexibility to transfer to new tasks.\nInstead, RL agents that can act over useful, temporally extended skills rather\nthan low-level actions can learn new tasks more easily. Prior work in\nskill-based RL either requires expert supervision to define useful skills,\nwhich is hard to scale, or learns a skill-space from offline data with\nheuristics that limit the adaptability of the skills, making them difficult to\ntransfer during downstream RL. Our approach, EXTRACT, instead utilizes\npre-trained vision language models to extract a discrete set of semantically\nmeaningful skills from offline data, each of which is parameterized by\ncontinuous arguments, without human supervision. This skill parameterization\nallows robots to learn new tasks by only needing to learn when to select a\nspecific skill and how to modify its arguments for the specific task. We\ndemonstrate through experiments in sparse-reward, image-based, robot\nmanipulation environments that EXTRACT can more quickly learn new tasks than\nprior works, with major gains in sample efficiency and performance over prior\nskill-based RL. Website at https://www.jessezhang.net/projects/extract/.",
        "updated": "2024-06-25 17:50:03 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.17768v1"
    },
    {
        "title": "DiffusionPDE: Generative PDE-Solving Under Partial Observation",
        "authors": "Jiahe HuangGuandao YangZichen WangJeong Joon Park",
        "links": "http://arxiv.org/abs/2406.17763v1",
        "entry_id": "http://arxiv.org/abs/2406.17763v1",
        "pdf_url": "http://arxiv.org/pdf/2406.17763v1",
        "summary": "We introduce a general framework for solving partial differential equations\n(PDEs) using generative diffusion models. In particular, we focus on the\nscenarios where we do not have the full knowledge of the scene necessary to\napply classical solvers. Most existing forward or inverse PDE approaches\nperform poorly when the observations on the data or the underlying coefficients\nare incomplete, which is a common assumption for real-world measurements. In\nthis work, we propose DiffusionPDE that can simultaneously fill in the missing\ninformation and solve a PDE by modeling the joint distribution of the solution\nand coefficient spaces. We show that the learned generative priors lead to a\nversatile framework for accurately solving a wide range of PDEs under partial\nobservation, significantly outperforming the state-of-the-art methods for both\nforward and inverse directions.",
        "updated": "2024-06-25 17:48:24 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.17763v1"
    },
    {
        "title": "Solving Hard Mizar Problems with Instantiation and Strategy Invention",
        "authors": "Jan JakubůvMikoláš JanotaJosef Urban",
        "links": "http://arxiv.org/abs/2406.17762v1",
        "entry_id": "http://arxiv.org/abs/2406.17762v1",
        "pdf_url": "http://arxiv.org/pdf/2406.17762v1",
        "summary": "In this work, we prove over 3000 previously ATP-unproved Mizar/MPTP problems\nby using several ATP and AI methods, raising the number of ATP-solved Mizar\nproblems from 75\\% to above 80\\%. First, we start to experiment with the cvc5\nSMT solver which uses several instantiation-based heuristics that differ from\nthe superposition-based systems, that were previously applied to Mizar,and add\nmany new solutions. Then we use automated strategy invention to develop cvc5\nstrategies that largely improve cvc5's performance on the hard problems. In\nparticular, the best invented strategy solves over 14\\% more problems than the\nbest previously available cvc5 strategy. We also show that different\nclausification methods have a high impact on such instantiation-based methods,\nagain producing many new solutions. In total, the methods solve 3021 (21.3\\%)\nof the 14163 previously unsolved hard Mizar problems. This is a new milestone\nover the Mizar large-theory benchmark and a large strengthening of the hammer\nmethods for Mizar.",
        "updated": "2024-06-25 17:47:13 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.17762v1"
    },
    {
        "title": "CaLMQA: Exploring culturally specific long-form question answering across 23 languages",
        "authors": "Shane AroraMarzena KarpinskaHung-Ting ChenIpsita BhattacharjeeMohit IyyerEunsol Choi",
        "links": "http://arxiv.org/abs/2406.17761v1",
        "entry_id": "http://arxiv.org/abs/2406.17761v1",
        "pdf_url": "http://arxiv.org/pdf/2406.17761v1",
        "summary": "Large language models (LLMs) are commonly used for long-form question\nanswering, which requires them to generate paragraph-length answers to complex\nquestions. While long-form QA has been well-studied in English via many\ndifferent datasets and evaluation metrics, this research has not been extended\nto cover most other languages. To bridge this gap, we introduce CaLMQA, a\ncollection of 2.6K complex questions spanning 23 languages, including\nunder-resourced, rarely-studied languages such as Fijian and Kirundi. Our\ndataset includes both naturally-occurring questions collected from community\nweb forums as well as questions written by native speakers, whom we hire for\nthis purpose. Our process yields diverse, complex questions that reflect\ncultural topics (e.g. traditions, laws, news) and the language usage of native\nspeakers. We conduct automatic evaluation across a suite of open- and\nclosed-source models using our novel metric CaLMScore, which detects incorrect\nlanguage and token repetitions in answers, and observe that the quality of\nLLM-generated answers degrades significantly for some low-resource languages.\nWe perform human evaluation on a subset of models and see that model\nperformance is significantly worse for culturally specific questions than for\nculturally agnostic questions. Our findings highlight the need for further\nresearch in LLM multilingual capabilities and non-English LFQA evaluation.",
        "updated": "2024-06-25 17:45:26 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.17761v1"
    },
    {
        "title": "Interpreting Attention Layer Outputs with Sparse Autoencoders",
        "authors": "Connor KissaneRobert KrzyzanowskiJoseph Isaac BloomArthur ConmyNeel Nanda",
        "links": "http://arxiv.org/abs/2406.17759v1",
        "entry_id": "http://arxiv.org/abs/2406.17759v1",
        "pdf_url": "http://arxiv.org/pdf/2406.17759v1",
        "summary": "Decomposing model activations into interpretable components is a key open\nproblem in mechanistic interpretability. Sparse autoencoders (SAEs) are a\npopular method for decomposing the internal activations of trained transformers\ninto sparse, interpretable features, and have been applied to MLP layers and\nthe residual stream. In this work we train SAEs on attention layer outputs and\nshow that also here SAEs find a sparse, interpretable decomposition. We\ndemonstrate this on transformers from several model families and up to 2B\nparameters.\n  We perform a qualitative study of the features computed by attention layers,\nand find multiple families: long-range context, short-range context and\ninduction features. We qualitatively study the role of every head in GPT-2\nSmall, and estimate that at least 90% of the heads are polysemantic, i.e. have\nmultiple unrelated roles.\n  Further, we show that Sparse Autoencoders are a useful tool that enable\nresearchers to explain model behavior in greater detail than prior work. For\nexample, we explore the mystery of why models have so many seemingly redundant\ninduction heads, use SAEs to motivate the hypothesis that some are long-prefix\nwhereas others are short-prefix, and confirm this with more rigorous analysis.\nWe use our SAEs to analyze the computation performed by the Indirect Object\nIdentification circuit (Wang et al.), validating that the SAEs find causally\nmeaningful intermediate variables, and deepening our understanding of the\nsemantics of the circuit. We open-source the trained SAEs and a tool for\nexploring arbitrary prompts through the lens of Attention Output SAEs.",
        "updated": "2024-06-25 17:43:13 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.17759v1"
    }
]