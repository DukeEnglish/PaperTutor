[
    {
        "title": "ELIZA Reinterpreted: The world's first chatbot was not intended as a chatbot at all",
        "authors": "Jeff Shrager",
        "links": "http://arxiv.org/abs/2406.17650v1",
        "entry_id": "http://arxiv.org/abs/2406.17650v1",
        "pdf_url": "http://arxiv.org/pdf/2406.17650v1",
        "summary": "ELIZA, often considered the world's first chatbot, was written by Joseph\nWeizenbaum in the early 1960s. Weizenbaum did not intend to invent the chatbot,\nbut rather to build a platform for research into human-machine conversation and\nthe important cognitive processes of interpretation and misinterpretation. His\npurpose was obscured by ELIZA's fame, resulting in large part from the\nfortuitous timing of it's creation, and it's escape into the wild. In this\npaper I provide a rich historical context for ELIZA's creation, demonstrating\nthat ELIZA arose from the intersection of some of the central threads in the\ntechnical history of AI. I also briefly discuss how ELIZA escaped into the\nworld, and how its accidental escape, along with several coincidental turns of\nthe programming language screws, led both to the misapprehension that ELIZA was\nintended as a chatbot, and to the loss of the original ELIZA to history for\nover 50 years.",
        "updated": "2024-06-25 15:41:40 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.17650v1"
    },
    {
        "title": "The experience of humans' and robots' mutual (im)politeness in enacted service scenarios: An empirical study",
        "authors": "Victor KaptelininSuna BenschThomas HellströmPatrik BjörnfotShikhar Kumar",
        "links": "http://arxiv.org/abs/2406.17641v1",
        "entry_id": "http://arxiv.org/abs/2406.17641v1",
        "pdf_url": "http://arxiv.org/pdf/2406.17641v1",
        "summary": "The paper reports an empirical study of the effect of human treatment of a\nrobot on the social perception of the robot's behavior. The study employed an\nenacted interaction between an anthropomorphic \"waiter\" robot and two\ncustomers. The robot and one of the customers (acted out by a researcher) were\nfollowing four different interaction scripts, representing all combinations of\nmutual politeness and impoliteness of the robot and the customer. The\nparticipants (N=24, within-subject design) were assigned the role of an\n\"included observer\", that is, a fellow customer who was present in the\nsituation without being actively involved in the interactions. The participants\nassessed how they experienced the interaction scenarios by providing Likert\nscale scores and free-text responses. The results indicate that while impolite\nrobots' behavior was generally assessed negatively, it was commonly perceived\nas more justifiable and fairer if the robot was treated impolitely by the\nhuman. Politeness reciprocity expectations in the context of the social\nperception of robots are discussed.",
        "updated": "2024-06-25 15:24:08 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.17641v1"
    },
    {
        "title": "Enhancing LLM-Based Human-Robot Interaction with Nuances for Diversity Awareness",
        "authors": "Lucrezia GrassiCarmine Tommaso RecchiutoAntonio Sgorbissa",
        "links": "http://arxiv.org/abs/2406.17531v1",
        "entry_id": "http://arxiv.org/abs/2406.17531v1",
        "pdf_url": "http://arxiv.org/pdf/2406.17531v1",
        "summary": "This paper presents a system for diversity-aware autonomous conversation\nleveraging the capabilities of large language models (LLMs). The system adapts\nto diverse populations and individuals, considering factors like background,\npersonality, age, gender, and culture. The conversation flow is guided by the\nstructure of the system's pre-established knowledge base, while LLMs are tasked\nwith various functions, including generating diversity-aware sentences.\nAchieving diversity-awareness involves providing carefully crafted prompts to\nthe models, incorporating comprehensive information about users, conversation\nhistory, contextual details, and specific guidelines. To assess the system's\nperformance, we conducted both controlled and real-world experiments, measuring\na wide range of performance indicators.",
        "updated": "2024-06-25 13:15:36 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.17531v1"
    },
    {
        "title": "FacePsy: An Open-Source Affective Mobile Sensing System -- Analyzing Facial Behavior and Head Gesture for Depression Detection in Naturalistic Settings",
        "authors": "Rahul IslamSang Won Bae",
        "links": "http://arxiv.org/abs/2406.17181v1",
        "entry_id": "http://arxiv.org/abs/2406.17181v1",
        "pdf_url": "http://arxiv.org/pdf/2406.17181v1",
        "summary": "Depression, a prevalent and complex mental health issue affecting millions\nworldwide, presents significant challenges for detection and monitoring. While\nfacial expressions have shown promise in laboratory settings for identifying\ndepression, their potential in real-world applications remains largely\nunexplored due to the difficulties in developing efficient mobile systems. In\nthis study, we aim to introduce FacePsy, an open-source mobile sensing system\ndesigned to capture affective inferences by analyzing sophisticated features\nand generating real-time data on facial behavior landmarks, eye movements, and\nhead gestures -- all within the naturalistic context of smartphone usage with\n25 participants. Through rigorous development, testing, and optimization, we\nidentified eye-open states, head gestures, smile expressions, and specific\nAction Units (2, 6, 7, 12, 15, and 17) as significant indicators of depressive\nepisodes (AUROC=81%). Our regression model predicting PHQ-9 scores achieved\nmoderate accuracy, with a Mean Absolute Error of 3.08. Our findings offer\nvaluable insights and implications for enhancing deployable and usable mobile\naffective sensing systems, ultimately improving mental health monitoring,\nprediction, and just-in-time adaptive interventions for researchers and\ndevelopers in healthcare.",
        "updated": "2024-06-24 23:40:19 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.17181v1"
    },
    {
        "title": "Toward Ubiquitous 3D Object Digitization: A Wearable Computing Framework for Non-Invasive Physical Property Acquisition",
        "authors": "Yunxiang ZhangXin SunDengfeng LiXinge YuQi Sun",
        "links": "http://arxiv.org/abs/2406.17156v1",
        "entry_id": "http://arxiv.org/abs/2406.17156v1",
        "pdf_url": "http://arxiv.org/pdf/2406.17156v1",
        "summary": "Accurately digitizing physical objects is central to many applications,\nincluding virtual/augmented reality, industrial design, and e-commerce. Prior\nresearch has demonstrated efficient and faithful reconstruction of objects'\ngeometric shapes and visual appearances, which suffice for digitally\nrepresenting rigid objects. In comparison, physical properties, such as\nelasticity and pressure, are also indispensable to the behavioral fidelity of\ndigitized deformable objects. However, existing approaches to acquiring these\nquantities either rely on invasive specimen collection or expensive/bulky\nlaboratory setups, making them inapplicable to consumer-level usage.\n  To fill this gap, we propose a wearable and non-invasive computing framework\nthat allows users to conveniently estimate the material elasticity and internal\npressure of deformable objects through finger touches. This is achieved by\nmodeling their local surfaces as pressurized elastic shells and analytically\nderiving the two physical properties from finger-induced wrinkling patterns.\nTogether with photogrammetry-reconstructed geometry and textures, the two\nestimated physical properties enable us to faithfully replicate the motion and\ndeformation behaviors of several deformable objects. For the pressure\nestimation, our model achieves a relative error of 3.5%. In the interaction\nexperiments, the virtual-physical deformation discrepancy measures less than\n10.1%. Generalization to objects of irregular shape further demonstrates the\npotential of our approach in practical applications. We envision this work to\nprovide insights for and motivate research toward democratizing the ubiquitous\nand pervasive digitization of our physical surroundings in daily, industrial,\nand scientific scenarios.",
        "updated": "2024-06-24 22:02:10 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.17156v1"
    }
]