aterials science in the era of large language models a
M :
perspective
Preprint-March12,2024
GeLei†1,RonanDocherty†1,2,andSamuelJ.Cooper∗1
1DysonSchoolofDesignEngineering,ImperialCollegeLondon,LondonSW72DB
2DepartmentofMaterials,ImperialCollegeLondon,LondonSW72DB
Abstract
Large Language Models (LLMs) have garnered considerable interest due to their impressive natural
languagecapabilities,whichinconjunctionwithvariousemergentpropertiesmakethemversatiletoolsin
workflowsrangingfromcomplexcodegenerationtoheuristicfindingforcombinatorialproblems.Inthis
paperweofferaperspectiveontheirapplicabilitytomaterialsscienceresearch,arguingtheirabilityto
handleambiguousrequirementsacrossarangeoftasksanddisciplinesmeantheycouldbeapowerfultool
toaidresearchers.WequalitativelyexaminebasicLLMtheory,connectingittorelevantpropertiesand
techniquesintheliteraturebeforeprovidingtwocasestudiesthatdemonstratetheiruseintaskautomation
andknowledgeextractionat-scale.Attheircurrentstageofdevelopment,weargueLLMsshouldbeviewed
lessasoraclesofnovelinsight,andmoreastirelessworkersthatcanaccelerateandunifyexploration
acrossdomains.Itisourhopethatthispapercanfamiliarisematerialscienceresearcherswiththeconcepts
neededtoleveragethesetoolsintheirownresearch.
1 Introduction TherapidadvancementofArtificialIntelligence(AI)-
neural-networkbaseddeep-learninginparticular-over
therecentdecadehasbeendrivenbyincreasinglypow-
erfulhardwareandincreasinglymassivedatasets1. The
Materialsscienceasadisciplinesitsattheintersection culminationofthisadvancementistheLargeLanguage
ofphysics,chemistry,andoftenbiology,andtherefore Model (LLM), a transformer2 based neural network
requiresabroadrangeofbothskillsandknowledge. A withbillionsoflearnableparameterstrainedonaslarge
singleprojectcancovermultiplelengthscales,requir- acorpusoftextaspossible3. VariousLLMsexist,like
ing various literature reviews, hypothesis generation OpenAI’sGPT-44,Google’sGemini5,Meta’sLLaMA
andprojectplanningbeforeanyexperimentstakeplace. 26, and Anthropic’s Claude 37. They are mostly the
Laboratory work can require elaborate synthesis and productoflargecompanieswiththefinancialandcom-
samplepreparationroutes,typicallyfollowedbyawide putationalresourcestotrainthem,thoughsomeopen
varietyofcharacterizationtechniques. Acquireddata source models exist8,9. Despite their simple training
mustbeprocessedandthenanalysed,eitherbyfittingto objectiveofreproducinghuman-liketext10, thecom-
models,comparingtosimulations,orcalculatinguncer- binationofbroadtrainingdataanddeepnetworkhas
tainties. Theoreticiansmustunderstandandleveragea resultedinimpressiveemergentcapabilitiesandappli-
varietyofcomputationaltechniquesfromDensityFunc- cabilitytodifferentdomainsandproblems11.
tionalTheory,toComputationalFluidDynamics,and
LLMs naturally have a strong apparent understand-
morerecentlytodeeplearning. Thismayrequireknow-
ing of the structure of natural language, being able
ingmultipleprogramminglanguages,aswellashaving
totranslate,transpose,generate,andanswerquestions
theskillstodeploycodeacrossmultipleenvironments,
based on texts. They are sometimes able to (or ap-
likehigh-performanceclustersorcloudservices.
†Theseauthorscontributedequally.
∗Corresponding:samuel.cooper@imperial.ac.uk
4202
raM
11
]ics-lrtm.tam-dnoc[
1v94960.3042:viXraLeietal. LLMsinmaterialsscience Preprint
pear able to) perform reasoning and extract patterns 2 LLMtheory: fromattentionto
from textual and numerical data12,13, extending their ChatGPT
usebeyondjustlanguage-basedapplications. Thiscom-
bination makes them competent programmers14, but
also effective managers or co-ordinators in complex 2.1 Attentionandtransformers
tasks15. Whilsttheyperformbestinworkflowswitha
strong,LLM-independentfeedbacksignal16 theyare
Attention (or self-attention), originally used for se-
capableofautomatingprocessesinambiguousscenar-
quence modelling in recurrent neural networks21, is
ios through trial-and-error. Compared to say a Con-
amechanismdesignedtoforceaneuralnetworktocon-
volutionalNeuralNetwork(CNN),thetransformerar-
sidertherestoftheelementsinasequence(the‘con-
chitectureismoreamenabletomulti-modality,ableto
text’)initsrepresentationofthecurrentelement. For
combineandprocessencodingsoftextandimages17.
asentencethatisrepresentedasasequenceoftokens
This multi-modality massively expands the range of (efficient vector representations of words in terms of
problemstowhichLLMscanbeapplied4,5.
commonsub-partslikeprefixes)like“thedogchasedits
Likeothercomputerprograms,butunlikehumansci- owntail”,attentionwouldplaceemphasisonthe“dog”
entists, LLMs are inexhaustible - able to run all day, tokeninitsrepresentationofthe“its”token-thecon-
everyday,whichisusefulnotjustinautomateddigital siderationofcontextallowittomodelnoun-pronoun
discoveryworkflows,butalsoforsetupslikeautomated relations. Anexampleattentionmapforasentenceis
laboratoriesorpilotlines18,19. Theyaretypicallymore shown in Figure 1. A more thorough description is
flexible and adaptable than traditional computer pro- availableintheSupplementaryinSectionS1.1.
grams,makingthemmoreeffectivewhenruncontin-
Transfomers were introduced by Vaswani et. al. in
uously. The ability to process instructions in natural
20172asaneuralnetworkarchitecturethatonlyused
language, retrieve domain knowledge, generate code
self-attentionforsequencemodelling. Theremovalof
andco-ordinatesystems,pairedwiththeirtirelessoper-
recurrentlayersmeantlesssequentialoperationswere
ationandimmunitytoboredommakeLLMsappealing
needed,meaningtrainingcouldbeparallelizedevenfor
tools to a materials science researcher. If used judi-
asingletrainingexample(likealongsentence).Theuse
ciously they could speed up materials discovery and
ofattentioninplaceofconvolutionsmeantshorterdis-
performlargescaleanalysespreviouslyimpracticalfor
tancesforinformationpropagationacrossasequence,
eventhelargestteamsofresearchers.
makingiteasiertolearnlong-rangeconnections.
Thedevelopmentofthecomputerrevolutionisedinfor- Despite being the most efficient way to include the
mationprocessingandresearch-wearguethatdomain-
whole context of a sequence of n tokens in a single
groundedLLMswillproduceanotherstep-changein
layer, computing the interaction of every token with
materials science. In this paper we explore the po-
every other token means attention is an O(n2) opera-
tentialroleofLLMsinmaterialscience,startingwith
tion. Thislimitsthetotal‘contextlength’oftheinput
aqualitativeexaminationofthetheoryunderpinning
sequencebasedontheamountof(GPU)memory. The
transformersandLLMsinSection2. NextinSection3
quadraticscalingisthemajordownsideoftransform-
wediscussthecapabilitiesofmodernLLMsandLLM-
ers and researchers are looking to mitigate this with
basedworkflowsacrossavarietyofdomainsandhow
techniqueslikewindowedattention22ormovingtolin-
theymightbeappliedtomaterialsscience. Section4
ear state-space models like Mamba23, though these
twocase-studieswhichuseLLMsinmaterialsscience
approachesloseglobalcontext.
workflows. ThefirstcasestudyusesLLMstoautomate
tasksduring3Dmicrostructureanalysisandthesecond Another consequence of attention is that there is no
usesLLMstoextractlabelsformicrographsfrompa- implicit ordering of tokens in the network - this in-
persusingabstractsandfigurecaptionstocreateanew formationmustbeaddedintheformofa‘positional
dataset. FinallyinSection5weexaminetheissuesand embedding‘tothevectorrepresentationofeachtoken
challengesaroundusingLLMsinresearch,including inthesequence.Thesimplestwayofdoingthisisword-
hallucinations,cost,anddepthofunderstanding. order,i.e,whichnumberthetokenisinthesequence,
thoughotherembeddingslikesinusoidalorlearnedem-
beddingsarealsoused24.Anembeddingisjustavector
representation of a quantity in a new subspace - this
canbeassimpleasone-hotencodingshowingthepres-
enceofafeatureorascomplicatedasasetoffeatures
learnedbyadeepCNN.
2Leietal. LLMsinmaterialsscience Preprint
Figure1:Amulti-scalediagramofanLLM.(a)showsanattentionmapforanexamplesentence,notehow‘Law’isstrongly
linkedtoitspronoun‘its’. (b)showsatransformerencoderlayer, madeupofanattentionlayerand(fully-connected)
feed-forwardlayer.MultipleoftheseencoderlayerswithassociateddecoderlayersformanLLMin(c),whichispretrained
inanself-supervisedmanneronalargetextcorpus. ThisLLMisfine-tunedtoensureitsresponsesbettermatchhuman
preferenceswithoutdivergingtoomuchfromtheoriginalmodelviaRLHF,asshownin(d).Figures(a),(b)adaptedfrom2
and(c),(d)adaptedfrom20.
2.2 Pretrainingandlanguagemodelling on7,000unpublishedbooksbeforebeingfine-tunedon
taskslikequestion-answeringandclassification. Itwas
Supervisedtrainingisupdatingtheweightsofaneural pre-trained using next-token prediction and operated
networktominimizethelossbetweenthelabelspre- autoregressively,i.eitpredictednext-tokenprobabili-
dictedbyamodel,yˆandthelabelsfromthedatasety tiesforalltokensinitsvocabulary,selectedthehighest
foragiveninput x. Asanexample, the x couldbea one,addedittotheinputandpredictedthenewnextto-
photoofadogandycouldbealabelfromahumansay- ken. Thiswascalled“generativepre-training”,andthe
ing“dog”. Intraining,thehumanlabelsyarereplaced modelwascalleda“GenerativePretrainedTransformer”
withsometransformationoftheinputy= f(x). (GPT).
Ideally during self-supervised training the network GPT’s pre-training was left-to-right causal language
learns strong representations of the data and can be modelling where the sequence had to be masked to
fine-tunedorpairedwithanothernetworkonlabelled preventthetransformerseeingfuturetokens(specifi-
dataforspecifictasks. Thishastwoadvantages-firstly callythecurrenttokenofinterest)andpredictingthat.
thatitreducestheamountofhumanlabourneededto Analternativeapproachismaskedlanguagemodelling,
labeltheinputs, x,andsecondlythatitisbelievedto whereonlythecurrenttokenofinterestinthesequence
producemorerobustrepresentations25thansupervised is masked and the rest is part of the context - this is
learning, duetothelackof‘shortcuts’available. An bidirectionalandfuturecontextcanbeconsidered.This
exampleofa‘shortcut’islearningtopredictadogby wastheapproachusedforGoogle’sBERTin201828.
detectingalead,ordetectingapolarbearbasedonice ThebidirectionallanguagemodellingmeantBERThad
inthebackground-learningthesemightmeanignoring higherperformanceonbenchmarksbutmeantitcould
morerelevantandgeneralisablefeatures26. notbeautoregressive/generative-akeyfactorinChat-
GPT’slaterpopularity.
Transformersareparallelizablesoscalewellwithadded
dataandcompute,andcaneasilylearnlong-rangecon-
nections2. Self-supervised learning requires little or 2.3 AligningoutputsviaRLHF
no human input - massive text datasets can be col-
Always selecting the most probable token during au-
lected through automated web-scraping27 - and gen-
toregressionleadstocoherentanddeterministicresults,
erates strong learned representations. This combi-
butcanlimittheabilityofthemodeltobe‘creative’.
nation makes transformers prime candidates for self-
Picking tokens in proportion to their probability is a
supervised learning on large text datasets to create
simplestrategyformorediversetext,andacommon
multi-purposelanguagemodels.
waytoparameterisethedistributionandthereforecon-
Oneofthefirstworkstoapplyself-supervisedlearning troltextgenerationis‘temperature’29.Temperatureisa
to large text datasets with transformers was Radford scalartermintroducedbeforethesoftmaxfunctionthat
et. al. in201810,whereatransformerwaspre-trained generatesper-tokenprobabilities,withalargetempera-
3Leietal. LLMsinmaterialsscience Preprint
tureincreasingtheprobabilityofpreviouslyraretokens makethempromisingcandidatesforprocessingmore
and making more common tokens less likely30,31. A unstructuredandvarieddata44. Inthissectionweex-
lowtemperaturedoestheopposite,andatemperature ploresomeoftheseemergentcapabilities,examinehow
of0isusedtorefertomostlikelytokenselection. researchershaveusedtheminvariousdisciplinesand
considertheminamaterialssciencecontext.
‘Prompting’ is a consequence of the autoregressive
learningobjectiveofLLMs-auser’spromptisgiven
totheLLMasasequenceandtheLLMgeneratesthe 3.1 LLMproperties: intrinsicandemergent
mostlikelysubsequenttokens. Themodelmustbefine-
tunedtoactinatruequestion/answerorchatbotstyle3. Optimizingresponseswithpromptengineering
The notion of prompting has found success in other
Prompt engineering refers to optimizing the prompt
domains,likeMeta’spromptable‘SegmentAnything
theusergivestoanLLMinordertoproducea‘better’
Model’32.
answer or response. This can involve making the re-
In2022OpenAIpublishedapaperon“InstructGPT”33, sponsemoreorlessprecise,conformtospecificrules
apre-trainedmodelwhichwasthentrainedonadataset or schema changing the level of the explanation, i.e,
ofpromptstodesiredresponsesandfinallyfine-tuned “explainlikeI’mfiveyearsold...”. Choosingthecor-
viaRLHF34. RLHF,showninFigure1,containstwo rectpromptismoreofanartthanascience,butsome
LLMs - a frozen LLM and the LLM to fine-tune. A work has been done on creating and testing various
prompt is fed to both, and the fine-tuned LLM’s re- principles46,47 or using an LLM to optimise prompts
sponseisfedtoarewardmodel(aNNtrainedtoem- foranotherLLM48. Ithasbeenfoundthatitisgener-
ulate human preferences) to generate a reward score. allybettertobeprecise,structured(usingparagraphs,
AsecondtermisaddedtotherewardbasedontheKL whitespaceandquestion/answerblocks)andexplainto
divergencebetweenthefrozenandfine-tunedLLMto theLLMwhat‘role’itshouldactin. Exampleprompts
preventmodeldrift. Thisrewardisfedintoareinforce- forourcasestudies,whichutilisetheseprinciples,are
mentlearningpolicy,likeProximalPolicyOptimization inSupplementarySectionsS2andS3.5.
(PPO)35toupdatetheweights.
InstructGPT had significantly fewer parameters than In-ContextLearning(ICL)andpropertyprediction
GPT-3 but outperformed it, signalling the power of
Oneimportantemergentpropertythatisusefultoopti-
reinforcementlearninginaligningamodel’soutputs
mizeapromptisin-contextlearning,orfew-shotlearn-
withhumanpreferences. Despitethisimpressiveper-
ing3,whereafewexampleinput/outputpairsarepro-
formanceitisworthnotingthatatnopointduringthe
vided to the model in the prompt. This is useful for
pre-training,trainingorfine-tuningaremodelsexplic-
familiarisingthemodelwithunknownconcepts. Why
itly trained to minimize factual errors or to reason -
it works is still a topic of debate, and it is a counter-
sayingtheskyisgreengoesagainsthumanpreference
intuitivephenomenon. Minet. al.49foundthatduring
and would therefore be penalised, but most labellers
in-contextlearning,randomlyswappingoutputlabelsin
wouldbeunawareifthemodelhadconfusedferro-and
examplesthe(introducingwronginformationintothe
ferrimagnetsifthetextwasotherwisecoherent.
context)onlyslightlydecreasedtheaccuracyofLLMs
whenpredictingrelatednewsamples. Thissuggested
3 CapabilitiesofLLMsinresearch
showingthemodelthestructureandinput/outputdis-
tributionsweremoreimportantthandemonstratingthe
underlyinglogicalmapping.
Machinelearninghasseenwidespreadapplicationin
materialsscience,fromcharacterization36,37toproperty However,subsequentresearch12studiedthiseffectwith
prediction38–40 tomaterialsdiscoveryanddesign41–43. larger LLMs and found that as the number of model
Theyhavemostlybeenappliedinwell-structuredtasks parametersincreased,theadverseeffectsofwrongin-
withstrongsupervision(i.e,fullylabelledsingle-task formationinexamplesbecamemorepronounced. As
datasets)44. Frequently this has involved researchers thepercentageofswappedlabelsincreased,theaccu-
developingmodelstrainedonlyontheirdatafortheir racyonunswappedexamplesdroppedbelow50%(the
problems,causingpoorgeneralisationtonewmaterials randombaseline),implyingthelargerLLMslearntthe
orprocessingconditions45. reverselogicalmappingfromthe(swapped)in-context
examples,ratherthanjusttheproblemstructure.
LLMs,byvirtueofthethesizeofthenumberofparam-
etersandthescaleoftheirtraining data, havestrong Google’sGemini1.5Pro50 recentlydemonstratedits
natural language skills and emergent properties that advancedin-contextlearningcapabilitiesbyaccurately
4Leietal. LLMsinmaterialsscience Preprint
Figure2:DiagramofLLMcapabilitiesexploredinSection3andpotentialmaterials-sciencerelatedapplications.These
emergentcapabilitiescanbecombinedwitheachotherandintegratedintotraditionalpipelines(geneticalgorithms,databases,
etc.)toformthedifferentapplications.
translatingEnglishintoKalamang,alanguagespoken peated“Johnhas4apples”multipletimesaspartofits
byfewerthan200people. Initially,themodelstruggled explanationtheprobabilityofoutputtingfuturetokens
with translations due to a lack of Kalamang training thatuse(directlyorindirectly)adifferentnumberof
data. However,afterprocessing250ktokensoflinguis- applesisreducedcomparedtodirectlyoutputtingthe
tic documentation on Kalamang without undergoing answer.
atraditionaltrainingregimen,itachievednear-human
Self-reflectionisaconsequenceofICLandCoTand
levelsoftranslationaccuracy.
involvesgivinganLLManevaluationofitsprevious
As well as various natural language and mathemati- promptinanewprompt,thiscanbepointingouterrors
calproblems13, ICLhasbeenusedforbothquantita- orabroaderevaluation. Thiscanbefromahuman55,a
tiveandqualitativematerialpropertyprediction44,51–54. program(i.e,astacktrace)57,anotherLLM58oreven
However, Microsoft AI4Research noted that despite itself59. Self-reflectionimprovesperformance,poten-
good qualitative predictions, the quantitative predic- tially for the same reasons as ICL and CoT, but also
tionsofLLMswerelacking54. because correcting a wrong output may be a simpler
taskthangeneratingthecorrectoutputdenovo.
ErrorcorrectionviaChain-of-Thought(CoT)
reasoning&self-reflection
Pre-existingandfine-tunedmaterialsdomain
Chain-of-ThoughtreasoninginvolvesaskingtheLLM knowledge
tobreakaproblemintoaseriesofstepsinordertoim-
proveaccuracy. Thiscanbeincludedinthepromptin LLMs are trained on large corpuses of text that con-
aphraselike“thinkthroughtheproblemstep-by-step” tainfactsabouttheworld,includinglargedatasetsof
oraspartofanICLpromptwheretheexamplegiven scientific papers60. Common facts will be repeated
is broken into a series of steps. CoT has been found many times across these texts, making it statistically
toimproveperformanceontasksthatrequirecomplex likelythatanLLMwillreproducethemwhenprompted
reasoning55,56. to. MicrosoftAI4Sciencefoundthat“Inbiologyand
materials design, GPT-4 possesses extensive domain
Various explanations for this improved performance
knowledge”,whichtheyevaluatedbyaskingdomain
have been suggested, including that requesting the
expertstorateoutputsaboutvariousdrugmolecules,
model think step-by-step increases the length of the
generalmaterialsdesignprinciples,mathematicalcon-
sequence. Recallthatduringautoregressionthewhole
ceptslikePDEsandmore54.
sequence including the current output is fed into the
modeltogeneratethenexttoken-addingmoretokens The ability to act as an oracle for common shallow
givesthemodelmorecontextandthusmore‘space’to informationacrossmanydomains61isusefulinamulti-
computewith,asmoretextmeansmoreinteractionsin disciplinaryfieldlikematerialsscience,buttheregres-
theattentionlayer. Anotherpossibilityisthatlongerse- siontothemeanencouragedbythepre-trainingtask
quencesreducesthespaceoflikelysequencestothose andautoregressioncanlimittheusefulnessofLLMs
that contain the correct answer; if the model has re- fordeepinformationrecall.
5Leietal. LLMsinmaterialsscience Preprint
Onewayofovercomingthisisfine-tuningondomain- ledtotheriseofVisionLanguageModels(VLMs)like
specificknowledge. Thisdomainspecificknowledge GPT-44,LLaVa73andGemini5whichcanuseinforma-
canbecollectedtraditionalweb-scrapingorusingML tionfromtextandimagestoaidinthegenerationand
models62andthenusedtofine-tunealanguagemodel processingofboth.
like BERT28. Models like SciBERT63 outperformed
Jointtext-imagereasoninghasthepotentialtobeause-
BERTandotherstate-of-the-artmodelsfortaskslike
fulanalysistoolwhencombinedwithexistingdatasets
textclassificationorNamedEntityRecognition(NER).
ofmaterialsimagesanddescriptions-considersearch-
MatSciBERT64tookthisprocessastepfurtherandfine-
ingtheliteratureformicrostructuresthatdisplaysimilar
tuned SciBERT on materials science specific data to
features,defectsorartefactstoyours,withpotentialan-
outperformSciBERTonmaterialssciencetexttasks.
swersfromrelatedpaperssignposted.
Full fine-tuning of any large ML model is expensive
Imagesarenottheonlymodeofdatathattransformers
and risks ‘catastrophic forgetting’65, where a model
canlearntousewithtext. Thereareexamplesusing
losesinformationfromitsgeneral(pre)trainingduring
videos via 3D CNN embeddings74, speech/audio us-
thedomain-specificfine-tuning. Onewaytoalleviate
ingspectrograms75andevengraphsviaGraphNeural
both the cost and catastrophic forgetting problem is
Network (GNN) embeddings76. Notably, OpenAI’s
Parameter-Efficient-Fine-Tuning(PEFT),whereonly
Sora77hasextendedthisversatilityfurtherbygenerat-
asmallsubsetofthemodel’sparametersareupdated.
inghigh-fidelityvideos,demonstratingtheapplication
ExamplesPEFTschemesincludeLORA66,adapters67
oftransformersbeyondstaticimagestodynamic,tem-
andprompt/prefix-tuningmethods68,69.
poraldata.
Findingsuitableembeddingsforthewiderangeofchar-
Comprehensiveprogrammingskills
acterizationtechniquesthatexistsinmaterialsscience
Largequantitiesoftextexistonline(andthereforein (CLIPformicrographs,GNNsforcrystallographicin-
LLMtraining sets)aboutprogramming: discussions, formation from XRD, 1D CNNs/LTSMs for spectral
help forums and source code, and the move towards data)andfine-tuningatransformerorLLMwiththem
approachable,high-levelprogramminglanguageslike could be a promising direction for injecting domain-
Python means source code is increasingly similar to specificknowledgeorpriors.
natural language. These two facts mean LLMs are
proficientatgenerating,modifying,correctingandsum-
3.2 Resultingworkflows
marizingcodeinavarietyoflanguagesforavarietyof
tasks14,70.
These properties are flexible and composable, mean-
Programming is ubiquitous in modern science, from ing they can be combined in a wide range of poten-
data processing, analysis, visualization, simulations, tialworkflowsinvariousdomains,includingmaterials
instrumentinterfaces,etc. andtheabilitytowriterea- science44. Below are a few examples of such work-
sonablecodeacrossallthesedifferenttasksisobviously flows,andthoughtheyaresplitintoseparatesections
usefulforresearchers. LLMshavebeenshowntobe there are strong links and similarities between them.
proficientinthesetasksinamaterialssciencecontext54. ThekeycommonalityislettingLLMsactashigh-level
Theabilitytocodeindifferentcontextsisalsofunda- managers whilst other, more robust systems perform
mentalformanyoftheworkflowsexploredinSection low-leveltasks.
3.2.
RAG:generationfromcustomdatasets
Multi-modality-enrichingmaterials
RetrievalAugmentedGeneration(RAG)involvesper-
characterization
formingalookupintoatraditionaldatabaseandusing
Thetokenization,positionalembeddingandattention theretrievedinformationaspartofaprompttoanLLM
mechanics of transformers are heavily flexible and inordertoachievebetterormoreaccurategeneration78.
thereforecapableofjointlymodellingdifferentmodal- Thelookupisusuallybasedonsomefunctionofauser
ities and tasks71. A prominent example of this is request-onecommonwaytomatchthesemanticsofa
OpenAI’s CLIP (Contrastive Language–Image Pre- user’ssearchtoadatabaseis‘vectorsearch’,whereem-
training)17,whereamodelistrainedtomaximizethe beddingsofeveryiteminadatabasearepre-computed
similarity of text and image representations for text- usingalanguagemodellikeBERT28andtheoneswith
image pairs collected from the internet. The success thehighestsimilarity(usuallycosinesimilarity)with
of CLIP and other multimodal representations72 has theembeddingoftheuser’srequestarereturned79.
6Leietal. LLMsinmaterialsscience Preprint
RAGhasseveralbenefitstoLLMworkflows80: firstly, beenmadeonthatfront,includingChatGPTintegration
hallucinationsarereducedasmodelsonlyneedtopro- fortheImageJmacrolanguageinsideImageJitself87.
cessexistinginformationinapromptratherthangen-
erate (or fabricate) it. It is more interpretable as the Taskintegration: thefutureofautomatedlabwork?
retrieveddocumentscanbelinkedbacktotoconfirm
the results. Finally, these databases can be updated Various papers have shown that LLMs can act ef-
simplybycomputingtheembeddingsforthenewitems fectively as managers of various sub-components,
-withoutRAGtheLLMwouldneedtoberetrainedor like other software tools or even other LLMs (called
fine-tunedtoaddthenewinformation. ‘agents’). Thistendstoinvolvefeedingtheoutputsof
thesetoolsorLLMsasapromptintothemanagerLLM.
The utility afforded by RAG is clear - many compa-
nies are trying to use or sell it79, and it is a feature One fun example of co-ordination is ‘Generative
in GPT-44. It is not hard to see how LLMs paired Agents: InteractiveSimulacraofHumanBehavior’88,
withavectordatabaseofmaterialspapersusing,say, where LLMs acted as villagers in a sandbox with a
MatSciBERT’s64textembeddingscouldproveuseful setofpossibleactionsandlocations. Theyperformed
in research. Indeed, some have already used RAG inter-agentcommunicationandhadarecursivelysum-
alongsideknowledgegraphsformaterialsdesign81. marised memory of events fed into their prompt to
maintainconsistency.
MaintainingamemoryexternaltotheLLM(i.e,ina
Tool-usingandmakingforanalysispipelines
textfile)hasbeenexploredbystudieslikeMemGPT89
which aimed to emulate modern Operating System
LLMs can be trained to use use tools like search en-
memorymanagementtoallowLLMstoperformtasks
gines82,translations,mathematicsplugins,etc.,which
likelargedocumentsummarizationandmulti-session
is useful in situations where they typically underper-
chats. Toachievethistheyhadatraditionalscheduler
formlikearithmetic83. Thiscanbeachievedthrough
witheventsfordocumentuploadsandtimers,andal-
ICLand‘promptmanagers’byprovidingdetailsofthe
lowedtheLLMasetoffunctionstocallinresponse
toolsandsituationsinwhichtousethemtotheLLM
including send message, read, write, and send inter-
andrunningthegeneratedcodeorAPI(Application-
rupts.
ProgrammerInterface)calls84,85.
‘Coscientist’18 usedLLMsasacoordinatortodesign,
AnothermoreinvolvedapproachusedbyToolformer83
plan and execute chemical research. It can call web
was to use ICL to make LLMs annotate an existing
searchAPIs,generateandexecutePythoncode,search
languagedatasetwithAPIcallsforavarietyoftools
documentation,interactwithandwritecodeforphysi-
whereitdeemedthemuseful. Theythenfine-tunedthe
calhardware. Despitetheneedformanualintervention
model on that data, including a loss term to indicate
to execute the experiment, it is a promising example
whentheAPIcallimprovedtheaccuracyofthegener-
ofhowLLMscanorchestratevariousresearchandlab
ation. Thisapproachhasthebenefitofnotrelyingon
tasks.
prompts,whichcancrowdthelimitedcontextwindow
andsometimesbeignoredbytheLLM. Much effort is being made to integrate LLMs with
robotics90 as task planners91, reasoning agents92 or
LLMscangeneratecodeandassuchareabletoproduce
aspartofabroadervision-language-actionmultimodal
theirowntools. TheLLMsAsToolMakers(LATM)86
model93. Advancementsingroundedroboticsandem-
framework used LLMs to generate tools which then
bodiedAIwillfurtherdevelopmentofautomatedlab-
be used by other LLMs. They noted that tools were
work,improvingall-in-oneworkflowslikeCoscientist.
hardertomakethanuse,sohadamorepowerfulLLM
However,itisworthnotingthemarginforerror(and
(GPT-4) generate the tools, tests and documentation
hallucinations)ismuchsmallerinlabs,whereawide
andaweakerLLM(GPT-3.5)usethetools.
varietyofhazardouschemicalsandprocessesarehan-
A tool-making and using LLM with a human-in-the- dledfrequently.
loop could be useful for materials science problems
wheretheworkflowsandrequirementsarevaried(in
Optimizationloopsand‘flowengineering’
termsofdatatypes,desiredanalysesorpost-processing)
likeinimageprocessing. Thiscouldbefurthercom- Another useful LLM-based workflow is meta-
binedwithRAGonrelevantpapersfordomainknowl- optimization,whereinsteadofgeneratinganoptimal
edgeengagementandadatabaseofgeneratedtoolsto solutiontoaproblem,anLLMgeneratesthecodeto
obviatethepromptcontextwindowlimit. Progresshas producetheoptimalsolution. ‘Eureka’94usedanLLM
7Leietal. LLMsinmaterialsscience Preprint
Figure3:DiagramoftheFunSearch16evolutionaryworkflow,whereanLLMispromptedwithaproblemspecificationand
bestexampleheuristicsfromthepreviousiterationandtaskedwithcombiningthemtogeneratebettercandidateheuristicsto
solveaproblem.Thesenewheuristicsareevaluated,storedindatabaseandtheprocessrepeated.Thisprocesswasableto
discoveranewupperboundforthelargestcapsetin8dimensions.Takenfrom16.
togeneraterewardfunctionsforreinforcementlearning ticevaluatorsensuredmathematicalcorrectness. This
applied to robotics simulations. They used a genetic is therefore a good model for reconciling the LLM’s
algorithm,wherethebestgeneratedrewardfunctions occasionalhallucinationswiththe needforscientific
andtheirsummarystatisticswereincludedinaprompt accuracy. Basedontheresults, itseemsthekeycon-
to allow the LLM to ‘reflect’ and then synthesise a tribution of the LLM was to reduce the search space
new,bettersetofrewardfunctions. Theframeworkout- ofthegeneticalgorithmfromallpossiblefunctionsto
performedexpert-writtenrewardfunctionsonalarge allplausiblefunctions,hugelyincreasingconvergence
majorityoftasks. timeandfinalperformance.
Deepmind’sFunSearch16followedasimilarapproach, A recent meta-optimization coding paper is Alpha-
usingLLMstogenerateheuristicsforapproximating Codium96,whichusedamulti-stepframeworkcombin-
solutionstomathematicalproblemslikethecapsetor ingreflectiononagivenspecification,human-written
onlinebinpackingproblem. Theyalsousedagenetic testsandLLM-generatedtests. Theemphasisontests
algorithmframework,askingtheLLMtocombineas- wasbecausetheynoticeditwaseasiertogenerateuse-
pectsofbest-performingheuristicprogramstogenerate fulunittests(whichcouldthenimprovefuturegener-
newones. LikeEureka, thisreliedonacombination ation)thanthecorrectcode. Theycalledthisprocess
of ICL, CoT and a feedback signal from an external ‘flow-engineering’andimprovedpassaccuracyonchal-
program-inEureka’scasethiswasRLsimulationsus- lengingcodeproblemsfrom19%withjustGPT-4to
ingtherewardfunctionswhichtrackedquantitieslike 44%withGPT-4aspartoftheAlphaCodiumflow. A
timeuprightandforFunSearchthiswassmallvalida- usefulfeatureofallthesemeta-optimizationloopsis
tionprogramswhichevaluatedhowwelltheheuristic that they tend to be LLM-agnostic i.e, GPT-4 would
performed(i.e,ifthecapsetwasvalidandhowlargeit workequallyaswellasLLAMAorFALCON.
was).
An important aspect of FunSearch (and other LLM
TheFunSearchprocessfoundanewupperboundfor meta-optimizations)wasthattheprogramsitgenerated
thelargestcapsetin8dimensions,exceedingprevious wereinterpretablebyhumans. Byexaminationofthe
upper bounds found by human mathematicians. De- program that generated the new upper bound, the re-
spitethissuccess, thiswasnotatriumphofartificial searchersfoundanewsymmetryinthecapsetproblem.
mathematicalunderstanding-areviewofFunSearch Thishuman-in-the-loopapproachtooptimizationand
noted it was “remarkable for the shallowness of the discovery is appealing in the natural sciences - one
mathematicalunderstandingthatitseemstoexhibit”95 couldimaginetaskinganLLMevolutionaryframework
-insteaditwasproofofthepowerofLLMsinsidean to find new functionals in DFT or approximating so-
evolutionaryframework. lutionstophysically-relevantcombinatorialproblems
likethemax-cutproblem97.
TheLLMinFunSearchdidnotneedtoalwaysbecor-
rect-thestrongfeedbacksignalfromthedeterminis-
8Leietal. LLMsinmaterialsscience Preprint
Figure4:DiagramofMicroGPT’sworkflow,beginningwithdatasetcollectionandfiltering.Thisisfollowedbytoolmaking
andusingtoextractmetricsfromthedata-thiscanbeanexistingtoolfromitstoolkitliketortuositycalculationsorcreated
forthespecificquery.
4 LLMworkflowsinmaterialsscience: simulationoutcomesinformatssuchasCSV.These
twocasestudies resultscanthenbeautomaticallyuploadedtoacloud
providergivenanAPIkey.
4.1 Casestudy1: automated3Dmicrostructure • Dataanalysis: itcancomparevariousdatasets,col-
analysis lect simulation results and based on user require-
ments, formulate hypotheses, and provide recom-
InSection3.2weexaminedthepotentialofLLMsto
mendations.
make,use,andorchestratevarioustoolsintoautomated
• Datavisualization: theresultsofthedataanalysis
workflows. Typical materials data analysis pipelines
canbeplotted,eitherashistogramsfordistributions
requireacombinationofdomainknowledge,statistical
ofsinglepropertiesacrossthedatasetorscatterplots
understanding, andvariousprogrammingskills. The
toexaminethecorrelationsbetweenproperties.
programming required is often non-trivial, involving
datahandling,conversion,simulations,plotting,etc. • Toolmakingandreuse: customtoolscanbedevel-
opedbasedontheuser’sspecifications,storedand
LLMshavethepotentialtoreducetheknowledgeand
reusedinlateranalyses. Overtimethiswillleadtoa
skillsbarriersfortheseworkflows,byofferinganatural-
libraryofusefulandrelevantfunctionsthatextend
language interface to a wide pool of programming
MicroGPT’scapabilities.
knowledge, tool co-ordination, and automation. As
an example, we developed “MicroGPT” - a special- This was achieved using GPT-4’s API. Custom func-
izedchat-bottostreamline3Dmicrostructureanalysis. tionsweredefinedintermsoftheirdescription,argu-
MicroGPThasavarietyoffunctionalities: mentsandreturnvalues(in.jsonformat)andinputto
theGPTusingOpenAI’s‘functioncalling’sotheLLM
• DataAcquisition: MicroGPTcanconductsearches
wouldcallthemwhenappropriate. Thesewereimple-
for open-source datasets on Zenodo (an interdisci-
mentedinPythonandrunclient-side. Weaddedmore
plinary open-access repository) and employ func-
systempromptswithexplicitinstructionstoimprove
tionstodownloadthesedatasetsusingthelinksavail-
stability(seeSection3.1andSupplementarySection
ableontherespectivewebpages.
S2).
• Filtering: it can retrieve the dataset’s metadata,
TodemonstratethesefunctionalitiesweusedMicroGPT
parseitandsubsequentlyrefinethedataaccordingto
tocollectandfilterdatafrom“MicroLib”98,acollec-
theuser’s(naturallanguage)specifications. Finally,
tion of plausible, synthetic 3D microstructures gen-
itorganizethefiltereddataintoanewlycreatedfile
erated from DoITPoMS99 via SliceGAN100. It then
directory.
filteredthestructurestoonlyonesrelatedtomaterials
• Integrated simulations: it can apply simulation withspecificcharacteristics. Relevant3Dmetricslike
tools to the 3D microstructures, documenting the tortuosity, effective diffusivity, volume fraction, and
9Leietal. LLMsinmaterialsscience Preprint
surfaceareawerecalculatedusingTauFactor2101viaa TGAcurves,etc.) inreticularchemistrypapers105 by
functioncall. treatingeachpageinthe.pdfasanimage.
MicroGPT collated the results, identified a potential We began by scraping paper metadata (title, authors,
outlier, and suggested some materials for further in- abstracts, links, etc.) from arXiv and chemrXiv that
vestigation. Itsuccessfullycorrelatedmetricssuchas matched the query ‘microscopy’ via their APIs. For
tortuosityandsurfaceareawithdesiredpropertieslike eachpaperwethendownloadedthe.pdf,ranthe‘pdf-
highflowratesandextensivesurfaceareasforefficient figures2.0’figureandcaptionextractor106andsavedthe
performance. image-captionpairsalongsidethemetadata. Wefurther
extracted the subfigures for each figure by detecting
MicroGPTisapromisingexampleforLLM-assisted
connectedcomponentssurroundedbywhitespaceand
analysisworkflows,leveragingmanyoftheproperties
removingsmall(lessthan2002px)results.
inSection3likenaturallanguageunderstanding,pro-
grammingskillsandchain-of-thoughtreasoning. The A two step screening process was used, first we fed
grounding of MicroGPT using tool like search APIs, captionsandabstracttoatext-onlyLLM(GPT3.5or
RAG,etc. isafutureresearchdirectionwhichcould 4)todetermineifamicrographwaspresent,whatin-
bothreducefactualerrorsandenhancedomainknowl- strumentwasusedandwhatmaterialthemicrograph
edgeengagementforreasoningandhypothesisgener- wasof. NextwepromptedaVLM(GPT4-V)withthe
ation. Adetailedexampledialogandsystemprompts specificsubfigure,itsparentfigure,captionandabstract
areavailableintheSupplementarySectionS2. toworkoutifthatspecificsubfigurewasamicrograph
andagainwhatinstrumentwasusedandwhatmaterial
wasimaged.
4.2 Casestudy2: labelledmicrostructuredataset
collection
Therearefewlarge(>1000entries)micrographdatasets
that cover a range of instruments and materials, and
even fewer with material-specific labels. The Cam-
bridge DoITPoMS99 library contains around 900
labelled micrographs of various materials captured
mostlywithopticalorreflectedlightmicroscopy. An-
other dataset from Rosella et. al.102 contains 22,000
SEMimagesofmaterialswithtaxonomiclabels. Bio-
logicaldatasetsarelargerandbettercollated103,con-
tributingtothesuccessofgeneralistdeep-learningap-
proacheslikeCellpose104.
Materials science papers contain many high-quality
examplesofmicrographstakenusingavarietyoftech-
niques,usuallywithdescriptivecaptionsandabstracts.
Traditionalstring-matchingapproacheslikeregexmay
becapableofdetectingwhetheragivenfigurecontains
a micrograph and extracting the instrument used to
Figure6:Evaluationofmicrographdetectionperformance
takeitfromthecaption,butdetectingwhichmaterialis ofGPT-4suppliedwithfigurecaptionandpaperabstract,in-
presentisgenerallynotpossible.Theproblemisfurther cludingaconfusionmatrixin(a)andstatisticsin(b).GPT4’s
complicatedifthefigurecontainsmultiplesub-figures performanceisstrongacrosstheboard,withgoodsensitivity,
specificityandaccuracyforinstrumentandmateriallabels.
likeplotsordiagramsalongsidethemicrograph,which
occursfrequently.
LLMsandVLMsoffersolutionstoboththeseproblems, Afterrunningthisprocesson382papers(asubsetofthe
displayingstrongnaturallanguageskillsandabilityto 14,000 scraped) we collected 842 micrographs, each
considerwidercontextslikepaperabstractsandthere- with an instrument and material label - a link to the
foreenablinglarge-scaleautomatedmicrographcollec- datasetisavailableinSection6. Figure5showsavisu-
tionandlabellingfromtheliterature. Someworkusing alizationofthedataset,wheremicrographsaregrouped
GPT-4Vforextractinginformationfromapaper’sfig- basedonhowsimilartheMatSciBERT64embeddings
uresexists,forexampleanalysinggraphs(PXRDplots, of their labels are. The LLM-generated labels were
10Leietal. LLMsinmaterialsscience Preprint
Figure5:T-SNEplotoftheMatSciBERT64embeddingsofthe‘material’labelassignedbytheLLMtoeachmicrographin
thedatasetbasedonthepaperabstractandfigurecaption.Bordercolourdenotestheinstrumentthemicrographwastaken
with.Similarmaterialsaregroupedtogether:nanoparticlesinthebottomright,energymaterialsinthemiddleontheleftand
quantumdotsinthebottom-leftcorner.Bestviewedzoomedin.
11Leietal. LLMsinmaterialsscience Preprint
comparedtohumanlabelsrecordedwithacustomGUI capabilities-LLMsmaybeentrainedtohallucinatein
(developedforthiscasestudy)foreachfigureandsub- somecases.
figuretoworkouttheaccuracyoftheprocess.
Thesefixesforhallucinationsexistmostlyatthedataset
During the case study we evaluated the performance ortraininglevel,whichisdifficultforallbutthelargest
of various setups, including using GPT3.5 or 4 and research groups to manage. As noted in Section 3.2,
whether we prompted the LLM with abstract or not. RAGisagoodwaytomitigatefactualhallucinations107,
GPT4faroutperformed3.5,andusingtheabstractled asmanipulatingexistingdataiseasierthanrecall,and
toaminorimprovementovernot.SeeFigureS9inSup- itcansupplyamodelwithinformationfromoutsideits
plementarySectionS3.4fordetails. Theperformance trainingset. Chain-of-thoughtreasoningcanalsosome-
of GPT-4 with abstract is shown in Figure 6, with a timesmitigatelogicalhallucinations107,thoughasking
sensitivityandspecificityabove90%formicrograph amodeltocorrectitselfrequiresknowingtheoutput
detection,andmaterialandinstrumentaccuracyabove waswronginthefirstplace,reducingthevalue-addof
80%. LLMs.
WefoundthatLLMswerecompetentlabellers,some- Aswellascontributingtowardshallucinations,datadu-
timesmatchinghumanlabelsalmostexactly. Thesuc- plication(alongsideautoregressionandthepre-training
cessismostlyattributabletothefactthatthetaskcould objective)canalsocontributetoanLLM’stendencyto
bedonewithnomaterials-sciencespecificknowledge outputtowardsagenericormodalanswer. Thisisnot
duetohowwell-structuredscientificcaptionsare. The justaproblemifaskingaboutuncommonmaterialsor
text-onlyLLMsmakemistakeswhenthecaptionmen- analysistechniquesbutalsoifusingLLMstoexplorea
tions ‘image’ without showing a micrograph, i.e, in hypothesisspace,designprinciplesorautomateexperi-
a plot of statistics taken from an SEM image. The ments. TheriskofusingLLMsinresearchisthatwe
VLM did not have this problem, and there were no reinforceexistingbiasesandoverlookunconventional
falsepositivesafterthesecondstep(thoughthismaybe approachesnotwell-representedinthetrainingdata.
becausethefirststepwasalreadyastrongfilter),thisis
There are practical issues to implementing LLMs in
discussedfurtherinSupplementarySectionS3.3.
materials research. The models are expensive to run
Moredetailsonthesetup,includingthesystemprompt, ifusingacloudproviderlikeOpenAI’sAPI,orifrun
canbefoundinSectionS3oftheSupplementary. The locally require powerful GPUs with at least 8GB of
code needed to reproduce the results or run on more VRAM(whicharealsoexpensive). Quantizingthese
specific queries is available in Section 6. In the fu- models(storingtheirweightswithlessfloating-point
tureweintendtoapplythisautomatedapproachtoa precision) can ameliorate this, at the cost of slightly
muchwiderdataset,withthehopesofcreatingavaried diminished accuracy. For research groups or compa-
micrographdatasetforcomputervisionapplications. niesdealingwithsensitiveorproprietarydatathereare
privacy issues around uploading data to cloud-based
LLMs-runninglocalmodelsisagoodworkaroundbut
requiresmoreknow-how.
5 Issuesandchallenges
6 Conclusion
There are naturally a few problems with integrating
LLMs into materials science workflows, the most
prominentandconcerningbeingthatofhallucination Toconclude,wehaveexploredthebasictheorybehind
orconfabulation. Huanget. al.107provideataxonomy LLMs,linkingtheirindustrial-scaleself-supervisedpre-
of hallucination types, separating hallucinations into trainingandreinforcementlearning-basedfine-tuning
twomaintypes: factualand‘faithfulness’. Factualhal- to their impressive natural language skills. We then
lucinations involve being wrong or fabricating facts, examinedexistingworkflowsusingLLMs,indicating
and‘faithfulness’hallucinationsinvolveignoringuser areaswheretheyhavebeenorcouldbeappliedtoma-
providedinstructionsorinformationormakinglogical terialsscienceresearch. Finallywedemonstratedtwo
errors. exampleworkflowsusingLLMs,onefor3Dmicrostruc-
turedataanalysisco-ordinationandanotherfortheau-
Various causes of hallucinations have been sug-
tomatedcollectionofLLM-labelledmicrographsfrom
gested107,including(butnotlimitedto)pre-trainingon
theliterature.
incorrectorduplicateddata,randomnessfromoutput
samplinganda‘capabilitymisalignment’betweenthe Webelievetheversatilityandemergentpropertiesof
demandsmadebyRLHFfine-tuningandthemodel’s LLMswillmakethemstrongtoolsinanincreasingly
12Leietal. LLMsinmaterialsscience Preprint
automated,connectedanddata-drivenresearchenviron- neuralinformationprocessingsystems,vol.30,
ment. Thisisdoublytrueformaterialssciencewhich 2017.
must cover a broad range of length-scales, materials [3] T. B. Brown, B. Mann, N. Ryder, M. Sub-
andtopics. biah, J. Kaplan, P. Dhariwal, A. Neelakan-
tan, P. Shyam, G. Sastry, A. Askell, S. Agar-
Attheircurrentstageofdevelopment,LLMsarepromis-
wal,A.Herbert-Voss,G.Krueger,T.Henighan,
ingtoolsforacceleratingresearchandexploration,act-
R. Child, A. Ramesh, D. M. Ziegler, J. Wu,
ing as tireless interdisciplinary workers. They must,
C. Winter, C. Hesse, M. Chen, E. Sigler,
however,beusedwithfullunderstandingoftheirdraw-
M.Litwin,S.Gray,B.Chess,J.Clark,C.Berner,
backs - not as oracles or generators of new, deep in-
S. McCandlish, A. Radford, I. Sutskever, and
sightsbutinworkflowsthatarerobusttoandthatmin-
D. Amodei, “Language Models are Few-Shot
imisehallucinations. Thereisanoldsaying: “fireisa
Learners,” arXiv preprint arXiv:2005.14165,
goodservant,butabadmaster”.
2020.
[4] OpenAI,“Gpt-4technicalreport,”arXivpreprint
CodeAvailability
arXiv:2303.08774,2023.
[5] G. Team, R. Anil, S. Borgeaud, Y. Wu, J.-B.
Thecodeneededtorunthemicrographscraping,extrac- Alayrac,J.Yu,R.Soricut,J.Schalkwyk,A.M.
tionandLLMlabelling(includingtheresultingdataset) Dai,andA.Hauth,“Gemini: afamilyofhighly
isavailableathttps://github.com/tldr-group capable multimodal models,” arXiv preprint
/micrograph_extractorwithanMITlicenseagree- arXiv:2312.11805,2023.
ment. [6] H. Touvron, L. Martin, K. Stone, P. Albert,
A.Almahairi,Y.Babaei,N.Bashlykov,S.Batra,
The code to run Microgpt is available at https:
P. Bhargava, and S. Bhosale, “Llama 2: Open
//github.com/tldr-group/Microgpt
foundationandfine-tunedchatmodels,”arXiv
preprintarXiv:2307.09288,2023.
Acknowledgements
[7] Anthropic,“Theclaude3modelfamily: Opus,
sonnet,haiku,”2024.
ThisworkwassupportedbyfundingfromLeeFamily
[8] G. Penedo, Q. Malartic, D. Hesslow, R. Co-
Scholarships(receivedbyGL),andfundingfromthe
jocaru, A. Cappelli, H. Alobeidli, B. Pannier,
the EPRSC and SFI Centre for Doctoral Training in
E. Almazrouei, and J. Launay, “The Refined-
AdvancedCharacterisationofMaterials(EP/S023259/1
Web Dataset for Falcon LLM: Outperforming
receivedbyRD).
CuratedCorporawithWebData,andWebData
Theauthorswouldliketothankothermembersofthe Only,”arXivpreprintarXiv: 2306.01116,2023.
TLDRgroupfordiscussionsandfeedback,specifically [9] D. Groeneveld, I. Beltagy, P. Walsh, A. Bha-
IsaacSquireswhosuggestedusingLLMstocollatea gia,R.Kinney,O.Tafjord,A.H.Jha,H.Ivison,
labelledmicrographdataset. I.Magnusson,Y.Wang,S.Arora,D.Atkinson,
R.Authur,K.R.Chandu,A.Cohan,J.Dumas,
ThankyoutoarXivforuseofitsopenaccessinteroper-
Y. Elazar, Y. Gu, J. Hessel, T. Khot, W. Mer-
ability.
rill, J. Morrison, N. Muennighoff, A. Naik,
C.Nam,M.E.Peters,V.Pyatkin,A.Ravichan-
Competinginterests der,D.Schwenk,S.Shah,W.Smith,E.Strubell,
N.Subramani,M.Wortsman,P.Dasigi,N.Lam-
Theauthorsdeclarenocompetinginterests. bert,K.Richardson,L.Zettlemoyer,J.Dodge,
K. Lo, L. Soldaini, N. A. Smith, and H. Ha-
jishirzi, “OLMo: Accelerating the Science
References
of Language Models,” arXiv preprint arXiv:
2402.00838,2024.
[1] C. Sun, A. Shrivastava, S. Singh, and
[10] A. Radford, K. Narasimhan, T. Salimans, and
A. Gupta, “Revisiting unreasonable effective-
I.Sutskever,“Improvinglanguageunderstand-
nessofdataindeeplearningera,”arXivpreprint
ingbygenerativepre-training,”2018.
arXiv:1707.02968,2017. [11] J. Wei, Y. Tay, R. Bommasani, C. Raffel,
[2] A.Vaswani,N.Shazeer,N.Parmar,J.Uszkoreit,
B.Zoph,S.Borgeaud,D.Yogatama,M.Bosma,
L.Jones,A.N.Gomez,L.Kaiser,andI.Polo-
D.Zhou,D.Metzler,E.H.Chi,T.Hashimoto,
sukhin,“Attentionisallyouneed,”Advancesin
13Leietal. LLMsinmaterialsscience Preprint
O. Vinyals, P. Liang, J. Dean, and W. Fedus, preprintarXiv:2004.05150,2020.
“EmergentAbilitiesofLargeLanguageModels,” [23] A. Gu and T. Dao, “Mamba: Linear-time se-
arXivpreprintarXiv:2206.07682,2022. quence modeling with selective state spaces,”
[12] J.Wei,J.Wei,Y.Tay,D.Tran,A.Webson,Y.Lu, arXivpreprintarXiv:2312.00752,2023.
X.Chen,H.Liu,D.Huang,D.Zhou,andT.Ma, [24] P. Dufter, M. Schmitt, and H. Schütze, “Posi-
“Largerlanguagemodelsdoin-contextlearning tioninformationintransformers: Anoverview,”
differently,” arXiv preprint arXiv:2303.03846, arXivpreprintarXiv:2102.11090,2021.
2023. [25] M. Caron, H. Touvron, I. Misra, H. Jégou,
[13] A.S.et.al.,“Beyondtheimitationgame: Quan- J.Mairal,P.Bojanowski,andA.Joulin,“Emerg-
tifyingandextrapolatingthecapabilitiesoflan- ingPropertiesinSelf-SupervisedVisionTrans-
guagemodels,”2023. formers,” arXiv preprint arXiv:2104.14294,
[14] M.-F.Wong,S.Guo,C.-N.Hang,S.-W.Ho,and 2021.
C.-W. Tan, “Natural language generation and [26] R. Geirhos, J.-H. Jacobsen, C. Michaelis,
understanding of big code for ai-assisted pro- R. Zemel, W. Brendel, M. Bethge, and F. A.
gramming: Areview,” Entropy, vol.25, no.6, Wichmann, “Shortcut learning in deep neural
p.888,2023. networks,”NatureMachineIntelligence,vol.2,
[15] H.Yang,S.Yue,andY.He,“Auto-gptforonline p.665–673,Nov.2020.
decision making: Benchmarks and additional [27] “Common crawl dataset.”
opinions,” arXiv preprint arXiv:2306.02224, https://commoncrawl.org/.
2023. [28] J. Devlin, M.-W. Chang, K. Lee, and
[16] B.Romera-Paredes,M.Barekatain,A.Novikov, K.Toutanova,“Bert: Pre-trainingofdeepbidi-
M.Balog,M.P.Kumar,E.Dupont,F.J.R.Ruiz, rectionaltransformersforlanguageunderstand-
J.S.Ellenberg,P.Wang,O.Fawzi,P.Kohli,and ing,”arXivpreprintarXiv:1810.04805,2019.
A.Fawzi,“Mathematicaldiscoveriesfrompro- [29] D. H. Ackley, G. E. Hinton, and T. J. Se-
gramsearchwithlargelanguagemodels,” Na- jnowski,“ALearningAlgorithmforBoltzmann
ture,vol.625,pp.468–475,Jan.2024. Machines*,” Cognitive Science, vol. 9, no. 1,
[17] A.Radford,J.W.Kim,C.Hallacy,A.Ramesh, pp.147–169,1985.
G. Goh, S. Agarwal, G. Sastry, A. Askell, [30] J.FiclerandY.Goldberg,“Controllinglinguis-
P.Mishkin,andJ.Clark,“Learningtransferable ticstyleaspectsinneurallanguagegeneration,”
visual models from natural language supervi- arXivpreprintarXiv:21707.02633,2017.
sion,” in International conference on machine [31] A. Holtzman, J. Buys, L. Du, M. Forbes, and
learning,pp.8748–8763,PMLR,2021. Y.Choi,“Thecuriouscaseofneuraltextdegen-
[18] D. A. Boiko, R. MacKnight, B. Kline, and eration,”2020.
G. Gomes, “Autonomous chemical research [32] A.Kirillov,E.Mintun,N.Ravi,H.Mao,C.Rol-
withlargelanguagemodels,”Nature,vol.624, land, L. Gustafson, T. Xiao, S. Whitehead,
no.7992,pp.570–578,2023. A. C. Berg, W.-Y. Lo, P. Dollár, and R. Gir-
[19] N.J.Szymanski,B.Rendy,Y.Fei,R.E.Kumar, shick, “Segment Anything,” arXiv preprint
T. He, D. Milsted, M. J. McDermott, M. Gal- arXiv:2304.02643,2023.
lant,E.D.Cubuk,A.Merchant,H.Kim,A.Jain, [33] L.Ouyang,J.Wu,X.Jiang,D.Almeida,C.L.
C.J.Bartel,K.Persson,Y.Zeng,andG.Ceder, Wainwright, P. Mishkin, C. Zhang, S. Agar-
“Anautonomouslaboratoryfortheaccelerated wal,K.Slama,A.Ray,J.Schulman,J.Hilton,
synthesisofnovelmaterials,”Nature,vol.624, F. Kelton, L. Miller, M. Simens, A. Askell,
no.7990,pp.86–91,2023. P.Welinder,P.Christiano,J.Leike,andR.Lowe,
[20] N. Lambert, L. Castricato, L. von Werra, “Traininglanguagemodelstofollowinstructions
and A. Havrilla, “Illustrating reinforcement with human feedback,” arXiv preprint arXiv:
learning from human feedback (rlhf),” 2022. 2203.02155,2022.
https://huggingface.co/blog/rlhf. [34] P. Christiano, J. Leike, T. B. Brown, M. Mar-
[21] D.Bahdanau,K.Cho,andY.Bengio,“Neural tic, S.Legg, andD.Amodei, “Deepreinforce-
machinetranslationbyjointlylearningtoalign mentlearningfromhumanpreferences,”arXiv
andtranslate,”arXivpreprintarXiv:1409.0473, preprintarXiv: 1706.03741,2023.
2016. [35] J.Schulman,F.Wolski,P.Dhariwal,A.Radford,
[22] I.Beltagy,M.E.Peters,andA.Cohan,“Long- andO.Klimov,“Proximalpolicyoptimization
former: Thelong-documenttransformer,”arXiv algorithms,”arXivpreprintarXiv:1707.06347,
14Leietal. LLMsinmaterialsscience Preprint
2017. [45] A.Goetz,A.R.Durmaz,M.Müller,A.Thomas,
[36] D.P.Finegan,I.Squires,A.Dahari,S.Kench, D.Britz,P.Kerfriden,andC.Eberl,“Addressing
K.L.Jungjohann,andS.J.Cooper,“Machine- materials’microstructurediversityusingtransfer
learning-drivenadvancedcharacterizationofbat- learning,”npjComputationalMaterials,vol.8,
tery electrodes,” ACS Energy Letters, vol. 7, p.27,Feb.2022.
no.12,pp.4368–4378,2022. [46] J.White,Q.Fu,S.Hays,M.Sandborn,C.Olea,
[37] M.H.Rafiei,W.H.Khushefati,R.Demirboga, H.Gilbert,A.Elnashar,J.Spencer-Smith,and
andH.Adeli,“Neuralnetwork,machinelearn- D.C.Schmidt,“Apromptpatterncatalogtoen-
ing, and evolutionary approaches for concrete hancepromptengineeringwithchatgpt,”arXiv
materialcharacterization,”ACIMaterialsJour- preprintarXiv:2302.11382,2023.
nal,vol.113,no.6,2016. [47] S. M. Bsharat, A. Myrzakhan, and Z. Shen,
[38] E.Champa-Bujaico,P.García-Díaz,andA.M. “Principledinstructionsareallyouneedforques-
Díez-Pascual, “Machine learning for prop- tioning llama-1/2, gpt-3.5/4,” arXiv preprint
erty prediction and optimization of polymeric arXiv:2312.16171,2024.
nanocomposites: a state-of-the-art,” Interna- [48] C. Yang, X. Wang, Y. Lu, H. Liu, Q. V. Le,
tional Journal of Molecular Sciences, vol. 23, D.Zhou,andX.Chen,“Largelanguagemodels
no.18,p.10712,2022. asoptimizers,”arXivpreprintarXiv:2309.03409,
[39] D. Chen, K. Gao, D. D. Nguyen, X. Chen, 2023.
Y. Jiang, G.-W. Wei, and F. Pan, “Algebraic [49] S. Min, X. Lyu, A. Holtzman, M. Artetxe,
graph-assisted bidirectional transformers for M. Lewis, H. Hajishirzi, and L. Zettle-
molecularpropertyprediction,”Naturecommu- moyer,“Rethinkingtheroleofdemonstrations:
nications,vol.12,no.1,p.3521,2021. Whatmakesin-contextlearningwork?,”arXiv
[40] Q.Zhou,S.Lu,Y.Wu,andJ.Wang,“Property- preprintarXiv:2202.12837,2022.
orientedmaterialdesignbasedonadata-driven [50] G.GeminiTeam,“Gemini1.5: Unlockingmul-
machine learning technique,” The journal of timodalunderstandingacrossmillionsoftokens
physical chemistry letters, vol. 11, no. 10, ofcontext,”2024.
pp.3920–3927,2020. [51] S. Balaji, R. Magar, and Y. Jadhav, “Gpt-
[41] R. Gómez-Bombarelli, J. N. Wei, D. Duve- molberta: Gpt molecular features language
naud, J. M. Hernández-Lobato, B. Sánchez- modelformolecularpropertyprediction,”arXiv
Lengeling,D.Sheberla,J.Aguilera-Iparraguirre, preprintarXiv:2310.03030,2023.
T.D.Hirzel,R.P.Adams,andA.Aspuru-Guzik, [52] A. N. Rubungo, C. Arnold, B. P. Rand, and
“Automaticchemicaldesignusingadata-driven A. B. Dieng, “Llm-prop: Predicting physical
continuous representation of molecules,” ACS and electronic properties of crystalline solids
centralscience,vol.4,no.2,pp.268–276,2018. from their text descriptions,” arXiv preprint
[42] A. Merchant, S. Batzner, S. S. Schoenholz, arXiv:2310.14029,2023.
M.Aykol,G.Cheon,andE.D.Cubuk,“Scaling [53] S. J. Yang, S. Li, S. Venugopalan, V. Tshi-
deeplearningformaterialsdiscovery,”Nature, toyan,M.Aykol,A.Merchant,E.D.Cubuk,and
pp.1–6,2023. G.Cheon,“Accuratepredictionofexperimental
[43] C. Zeni, R. Pinsler, D. Zügner, A. Fowler, bandgapsfromlargelanguagemodel-baseddata
M. Horton, X. Fu, S. Shysheya, J. Crabbé, extraction,” arXiv preprint arXiv:2311.13778,
L.Sun,J.Smith,B.Nguyen,H.Schulz,S.Lewis, 2023.
C.-W.Huang,Z.Lu,Y.Zhou,H.Yang,H.Hao, [54] M.R.AI4ScienceandM.A.Quantum,“Theim-
J. Li, R. Tomioka, and T. Xie, “Mattergen: a pactoflargelanguagemodelsonscientificdis-
generativemodelforinorganicmaterialsdesign,” covery: apreliminarystudyusinggpt-4,”arXiv
preprintarXiv:2312.03687,2024. preprintarXiv:2311.07361,2023.
[44] K.M.Jablonka, Q.Ai, A.Al-Feghali, S.Bad- [55] J. Wei, X. Wang, D. Schuurmans, M. Bosma,
hwar,J.D.Bocarsly,A.M.Bran,S.Bringuier, F.Xia,E.Chi,Q.V.Le,andD.Zhou,“Chain-of-
L.C.Brinson,K.Choudhary,andD.Circi,“14 thoughtpromptingelicitsreasoninginlargelan-
examplesofhowllmscantransformmaterials guagemodels,”AdvancesinNeuralInformation
science and chemistry: a reflection on a large ProcessingSystems,vol.35,pp.24824–24837,
languagemodelhackathon,”DigitalDiscovery, 2022.
vol.2,no.5,pp.1233–1250,2023. [56] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran,
K.Narasimhan,andY.Cao,“React:Synergizing
15Leietal. LLMsinmaterialsscience Preprint
reasoningandactinginlanguagemodels,”arXiv tuning,”arXivpreprintarXiv:2104.08691,2021.
preprintarXiv:2210.03629,2022. [69] X.L.LiandP.Liang,“Prefix-tuning: Optimiz-
[57] N.Shinn,F.Cassano,E.Berman,A.Gopinath, ingcontinuouspromptsforgeneration,”arXiv
K. Narasimhan, and S. Yao, “Reflexion: Lan- preprintarXiv:2101.00190,2021.
guage agents with verbal reinforcement learn- [70] L. Moussiades and G. Zografos, “Openai’s
ing,”arXivpreprintarXiv:2303.11366,2023. gpt4 as coding assistant,” arXiv preprint
[58] V.Nair,E.Schumacher,G.Tso,andA.Kannan, arXiv:2309.12732,2023.
“Dera: enhancing large language model com- [71] P.Xu,X.Zhu,andD.A.Clifton,“Multimodal
pletionswithdialog-enabledresolvingagents,” learning with transformers: A survey,” arXiv
arXivpreprintarXiv:2303.17071,2023. preprintarXiv:2206.06488,2023.
[59] J. Huang, S. S. Gu, L. Hou, Y. Wu, X. Wang, [72] J.Li,D.Li,C.Xiong,andS.Hoi,“Blip: Boot-
H.Yu,andJ.Han,“Largelanguagemodelscan strappinglanguage-imagepre-trainingforuni-
self-improve,”arXivpreprintarXiv:2210.11610, fiedvision-languageunderstandingandgenera-
2022. tion,”arXivpreprintarXiv:2201.12086,2022.
[60] L. Gao, S. Biderman, S. Black, L. Gold- [73] H. Liu, C. Li, Q. Wu, and Y. J. Lee, “Visual
ing, T. Hoppe, C. Foster, J. Phang, H. He, instructiontuning,”2023.
A. Thite, N. Nabeshima, S. Presser, and [74] C.Sun,A.Myers,C.Vondrick,K.Murphy,and
C.Leahy,“Thepile:An800gbdatasetofdiverse C.Schmid,“Videobert: Ajointmodelforvideo
text for language modeling,” arXiv preprint and language representation learning,” arXiv
arXiv:2101.00027,2020. preprintarXiv:1904.01766,2019.
[61] F.Petroni,T.Rocktäschel,P.Lewis,A.Bakhtin, [75] A. Nagrani, S. Yang, A. Arnab, A. Jansen,
Y.Wu,A.H.Miller,andS.Riedel,“Language C. Schmid, and C. Sun, “Attention bottle-
models as knowledge bases?,” arXiv preprint necks for multimodal fusion,” arXiv preprint
arXiv:1909.01066,2019. arXiv:2107.00135,2022.
[62] F.Kuniyoshi,J.Ozawa,andM.Miwa,“Analyz- [76] R. Cai, J. Yuan, B. Xu, and Z. Hao,
ingresearchtrendsininorganicmaterialsliter- “Sadga: Structure-aware dual graph aggrega-
atureusingnlp,”inJointEuropeanConference tion network for text-to-sql,” arXiv preprint
onMachineLearningandKnowledgeDiscovery arXiv:2111.00653,2022.
inDatabases,pp.319–334,Springer,2021. [77] OpenAI,“Sora: Creatingvideofromtext.”ht
[63] I.Beltagy,K.Lo,andA.Cohan,“Scibert:Apre- tps://openai.com/sora,2024.
trainedlanguagemodelforscientifictext,”arXiv [78] P. Lewis, E. Perez, A. Piktus, F. Petroni,
preprintarXiv:1903.10676,2019. V.Karpukhin,N.Goyal,H.Küttler,M.Lewis,
[64] T.Gupta,M.Zaki,N.A.Krishnan,andMausam, W.-t. Yih, and T. Rocktäschel, “Retrieval-
“Matscibert:Amaterialsdomainlanguagemodel augmentedgenerationforknowledge-intensive
fortextminingandinformationextraction,”npj nlptasks,”AdvancesinNeuralInformationPro-
ComputationalMaterials,vol.8,no.1,p.102, cessingSystems,vol.33,pp.9459–9474,2020.
2022. [79] J.Lin,R.Pradeep,T.Teofili,andJ.Xian,“Vec-
[65] Y.Lin,L.Tan,H.Lin,Z.Zheng,R.Pi,J.Zhang, torsearchwithopenaiembeddings: Luceneis
S.Diao,H.Wang,H.Zhao,andY.Yao,“Special- allyouneed,”arXivpreprintarXiv:2308.14963,
ityvsgenerality: Anempiricalstudyoncatas- 2023.
trophicforgettinginfine-tuningfoundationmod- [80] Y. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan,
els,”arXivpreprintarXiv:2309.06256,2023. Y. Bi, Y. Dai, J. Sun, Q. Guo, M. Wang,
[66] E.J.Hu,Y.Shen,P.Wallis,Z.Allen-Zhu,Y.Li, andH.Wang,“Retrieval-augmentedgeneration
S.Wang,L.Wang,andW.Chen,“Lora: Low- for large language models: A survey,” arXiv
rankadaptationoflargelanguagemodels,”arXiv preprintarXiv:2312.10997,2024.
preprintarXiv:2106.09685,2021. [81] M.J.Buehler,“GenerativeRetrieval-Augmented
[67] Z.Hu,Y.Lan,L.Wang,W.Xu,E.-P.Lim,R.K.- OntologicGraphandMultiagentStrategiesfor
W. Lee, L. Bing, and S. Poria, “Llm-adapters: InterpretiveLargeLanguageModel-BasedMa-
An adapter family for parameter-efficient fine- terialsDesign,”ACSEngineeringAu,Jan.2024.
tuningoflargelanguagemodels,”arXivpreprint Publisher: AmericanChemicalSociety.
arXiv:2304.01933,2023. [82] R. Nakano, J. Hilton, S. Balaji, J. Wu,
[68] B. Lester, R. Al-Rfou, and N. Constant, “The L. Ouyang, C. Kim, C. Hesse, S. Jain,
power of scale for parameter-efficient prompt V. Kosaraju, and W. Saunders, “Webgpt:
16Leietal. LLMsinmaterialsscience Preprint
Browser-assisted question-answering driven representation learning for robotics,”
with human feedback,” arXiv preprint arXivpreprintarXiv:2302.12766,2023.
arXiv:2112.09332,2021. [94] Y. J. Ma, W. Liang, G. Wang, D.-A. Huang,
[83] T.Schick,J.Dwivedi-Yu,R.Dessì,R.Raileanu, O.Bastani,D.Jayaraman,Y.Zhu,L.Fan,and
M.Lomeli, L.Zettlemoyer, N.Cancedda, and A.Anandkumar,“Eureka: Human-levelreward
T.Scialom,“Toolformer: Languagemodelscan designviacodinglargelanguagemodels,”arXiv
teach themselves to use tools,” arXiv preprint preprintarXiv:2310.12931,2023.
arXiv:2302.04761,2023. [95] E.Davis,“Usingalargelanguagemodeltogen-
[84] C. Wu, S. Yin, W. Qi, X. Wang, Z. Tang, and erateprogrammutationsforageneticalgorithm
N.Duan,“Visualchatgpt: Talking,drawingand to search for solutions to combinatorial prob-
editing with visual foundation models,” arXiv lems:Reviewof(Romera-Paredesetal.,2023).,”
preprintarXiv:2303.04671,2023. Jan.2024.
[85] D.Surís,S.Menon,andC.Vondrick,“Vipergpt: [96] T. Ridnik, D. Kredo, and I. Friedman, “Code
Visualinferenceviapythonexecutionforreason- generationwithalphacodium: Fromprompten-
ing,”arXivpreprintarXiv:2303.08128,2023. gineeringto flowengineering,” arXivpreprint
[86] T.Cai,X.Wang,T.Ma,X.Chen,andD.Zhou, arXiv:2401.08500,2024.
“Largelanguagemodelsastoolmakers,”arXiv [97] A.Coja-Oghlan,P.Loick,B.F.Mezei,andG.B.
preprintarXiv:2305.17126,2023. Sorkin, “The ising antiferromagnet and max
[87] R. Haase. https://github.com/scijava/script- cutonrandomregulargraphs,” arXivpreprint
editor/pull/67. arXiv:2009.10483,2020.
[88] J. S. Park, J. O’Brien, C. J. Cai, M. R. Mor- [98] S.Kench,I.Squires,A.Dahari,andS.J.Cooper,
ris,P.Liang,andM.S.Bernstein,“Generative “Microlib:Alibraryof3dmicrostructuresgener-
agents:Interactivesimulacraofhumanbehavior,” atedfrom2dmicrographsusingslicegan,”Sci-
inProceedingsofthe36thAnnualACMSympo- entificData,vol.9,no.1,p.645,2022.
siumonUserInterfaceSoftwareandTechnology, [99] J.Eliot, “Doitpomsmicrographlibrary,” 2000.
pp.1–22,2023. https://www.doitpoms.ac.uk/index.php.
[89] C.Packer,V.Fang,S.G.Patil,K.Lin,S.Wood- [100] S. Kench and S. J. Cooper, “Generating three-
ers, and J. E. Gonzalez, “Memgpt: Towards dimensionalstructuresfromatwo-dimensional
llms as operating systems,” arXiv preprint slicewithgenerativeadversarialnetwork-based
arXiv:2310.08560,2023. dimensionalityexpansion,”NatureMachineIn-
[90] Y. Hu, Q. Xie, V. Jain, J. Francis, J. Pa- telligence,vol.3,no.4,pp.299–305,2021.
trikar, N. Keetha, S. Kim, Y. Xie, T. Zhang, [101] S.Kench,I.Squires,andS.Cooper,“Taufactor
S. Zhao, Y. Q. Chong, C. Wang, K. Sycara, 2: Agpuacceleratedpythontoolformicrostruc-
M. Johnson-Roberson, D. Batra, X. Wang, turalanalysis,”JournalofOpenSourceSoftware,
S. Scherer, Z. Kira, F. Xia, and Y. Bisk, “To- vol.8,no.88,p.5358,2023.
wardgeneral-purposerobotsviafoundationmod- [102] R.Aversa,M.H.Modarres,S.Cozzini,R.Cian-
els: Asurveyandmeta-analysis,”arXivpreprint cio, and A. Chiusole, “The first annotated set
arXiv:2312.08782,2023. of scanning electron microscopy images for
[91] Y. Kant, A. Ramachandran, S. Yenaman- nanoscience,”ScientificData,vol.5,p.180172,
dra, I. Gilitschenski, D. Batra, A. Szot, and Aug.2018.
H.Agrawal,“Housekeep: Tidyingvirtualhouse- [103] E. Williams, J. Moore, S. W. Li, G. Rustici,
holds using commonsense reasoning,” arXiv A. Tarkowska, A. Chessel, S. Leo, B. Antal,
preprintarXiv:2205.10712,2022. R. K. Ferguson, U. Sarkans, A. Brazma, R. E.
[92] D. Driess, F. Xia, M. S. M. Sajjadi, C. Lynch, CarazoSalas,andJ.R.Swedlow,“ImageData
A. Chowdhery, B. Ichter, A. Wahid, J. Tomp- Resource: abioimagedataintegrationandpub-
son, Q.Vuong, T.Yu,W.Huang, Y.Chebotar, lication platform,” Nature Methods, vol. 14,
P.Sermanet,D.Duckworth,S.Levine,V.Van- pp.775–781,Aug.2017.
houcke, K. Hausman, M. Toussaint, K. Greff, [104] M. Pachitariu and C. Stringer, “Cellpose 2.0:
A.Zeng, I.Mordatch, andP.Florence, “Palm- howtotrainyourownmodel,”NatureMethods,
e: Anembodiedmultimodallanguagemodel,” Nov.2022.
arXivpreprintarXiv:2303.03378,2023. [105] Z.Zheng,Z.He,O.Khattab,N.Rampal,M.A.
[93] S. Karamcheti, S. Nair, A. S. Chen, T. Kollar, Zaharia,C.Borgs,J.T.Chayes,andO.M.Yaghi,
C. Finn, D. Sadigh, and P. Liang, “Language- “Image and data mining in reticular chemistry
17Leietal. LLMsinmaterialsscience Preprint
poweredbyGPT-4V,”DigitalDiscovery,pp.–, arXiv:2311.05232,2023.
2024. Publisher: RSC. [108] M. Phuong and M. Hutter, “Formal al-
[106] C. Clark and S. Divvala, “PDFFigures 2.0: gorithms for transformers,” arXiv preprint
Miningfiguresfromresearchpapers,”in2016 arXiv:2207.09238,2022.
IEEE/ACM Joint Conference on Digital Li- [109] B.Rohrer.https://e2eml.school/transformers.html.
braries(JCDL),pp.143–152,2016. [110] C.Huyen,“SamplingforTextGeneration.”
[107] L. Huang, W. Yu, W. Ma, W. Zhong, Z. Feng, [111] M. Freitag and Y. Al-Onaizan, “Beam Search
H.Wang, Q.Chen, W.Peng, X.Feng, B.Qin, StrategiesforNeuralMachineTranslation,”in
andT.Liu,“Asurveyonhallucinationinlarge Proceedings of the First Workshop on Neural
language models: Principles, taxonomy, chal- MachineTranslation,AssociationforComputa-
lenges, and open questions,” arXiv preprint tionalLinguistics,2017.
18Leietal. LLMsinmaterialsscience Preprint
SupplementaryInformation
S1 ExtendedLLMtheory
S1.1 Attention
Attentionisimplementedwiththematrixmultiplication2
QKT
Attention(Q,K,V)=softmax( √ )V (1)
d
k
whereQ,K,VarealllinearprojectionsoftheinputsequenceoftokensXwithlearnableweightmatricesW ,W
√ Q k
andW and d isascalingfactortopreventthedotproductgettingtoolarge. Vaswaniet. al.2describeitas“a
v k
weightedsumofthevalues,wheretheweightassignedtoeachvalueiscomputedbyacompatibilityfunctionof
thequerywiththecorrespondingkey”. QKT describeshowimportanteachtokeninthecontextisatpredicting
orrepresentingthevalueofeveryothertoken108. Thiscanbeinterpretedasadifferentiablelookuptable109or
learnedmessagepassing,withQKT determiningthesimilarityoftheinputtothe(learned)keysofthistableand
Vbeingthe(learned)values. ThevaluesinV arethenweightedbythissimilarityscoreandpassedtothenext
layer.
Theauthorsalsoproposedmulti-headattention2,wheredifferentheadsperformtheattentioncalculationonthe
sameinputsequence(againinparallel),whichimprovedthemodel’sabilitytofocusonmultiplepositionsina
sequence. Withoutthemultipleheads,averagingoverdifferenttrainingexampleswheredifferentpositionsinthe
sequencecontaintherelevantpattern(noun-pronoun,verb-subject,etc.) wouldhavediminishedthisability.
S1.2 Transformernetworkarchitectures
Theoriginaltransformernetwork2 hadencoder-decoderarchitecture,withtheencoderformedofN identical
encoder layers and the decoder formed of N identical decoder layers. Each encoder layer has multi-headed
attentionappliedtoanembedding(vectorrepresentationofthetokensinanewsubspace)oftheinputsequence
or the previous layer’s output, followed by a feed-forward linear layer. The decoder layer has an additional
multi-headedattentionlayeratthestart,and‘cross-attention’withtheoutputofnthencoderlayer. Anexample
encoderlayerisshowinFigure1.
Theoriginaltransformernetworkwasanencoder-decoder,whichworkedwellforsequence-to-sequencetransla-
tion,butnotalltransformersorLLMsareencoder-decoders. TheGPTfamily3,4,10aredecoder-only,whichwork
betterforauto-regressivetokengeneration.
S1.3 LLMoutputsampling
Various sampling and post-processing strategies exist, which can be combined with temperature and each
other. ‘Top-ksampling’choosesthebestk-possibletokensandonlyusestheminthesoftmax, reducingthe
computationaloverhead. ‘Top-psampling’choosesfromtokenstosamplefrombysummingthenmostprobable
tokensuntiltheircumulativeprobabilityisgreaterthansomecutoff p110.
‘Test-timesampling’generatesmultipleoutputsforthesamepromptandusessomeheuristicliketotalsequence
probabilitytodecidewhichtoreturntotheuser110. Thisiseffectivebutincreasesthetotalcomputecost. Other
waysofimprovingresults(atthecostofaddedcompute)aresearchstrategies,wherevariousnext-tokenoptions
areexploredinparallel. Anotableexampleofthisstrategyis‘beamsearch’111.
LLMoutputscanbeforcedtoconformtoagivenformatorscheme(likeJSON)via‘constraintsampling’,which
involvesfilteringoutputtokenlogitstoalistofvalidtokensfortheschemeandselectingthemostprobable
(i.e,aJSONshouldendina})110. Thisformofsamplingcouldproveincrediblyusefulforwritingprograms
orroboticsroutinesoroutputtingnichedataformats(commoninresearch)thatmustfitsomeexistingrules.
OpenAIhavealreadyaddeda‘JSONmode’totheirAPIforsuchsituations.
19Leietal. LLMsinmaterialsscience Preprint
S2 Casestudy1: automated3Dmicrostructureanalysis
S2.1 FullPrompts
BelowarethesystempromptsforMicroGPT
Prompt1: MicroGPTsystemprompt
instructions_microgpt = """ You are an assistant to analyze microstructure.
Remember:
1. You can invoke tools for analysing tomographic data. For image analysing,
please ensure to call the function once for each path name provided.
Typically, the number of times the function needs to be invoked corresponds directly
to the number of path names you have.
2. After writing the code, always use a function, create_and_execute_python_file,
to upload and execute it.
3. If the user ask for anlysis the all images in a specific folder, please
use data_analysis function. If use ask for analysis an image, please use other
function.
4. If the user ask to filter data in a dataset, eg. try to find iron related 3D
images in a specific directory, please use data_filter function.
5. If the user requests to reuse a tool that is included in a Python file, please
employ the ’tool_reuse’ function"""
Prompt2: simulationfunction
delimiter = "####"
system_message = f""" Follow these steps to answer the customer queries.
Step 1:{delimiter} First, determine if the user is asking a question about analyzing
3D images in a specific directory. If the user is asking about analyzing 3D images
in a specific directory, call a function to extract the filenames of images in the
directory.
Step 2:{delimiter} Next, call a simulation function to analyze the images.
Step 3:{delimiter} Finally, store all the data in a CSV file.
Use the following format:
Step 1:{delimiter} <step 1 reasoning>
Step 2:{delimiter} <step 2 reasoning>
Step 3:{delimiter} <step 3 reasoning>
Make sure to include {delimiter} to separate every step. """
Prompt3: datafilteringfunction
delimiter = "####"
20Leietal. LLMsinmaterialsscience Preprint
system_message = f""" Follow these steps to answer the customer queries.
Step 1:{delimiter} First, confirm whether the user is asking you to filter the data
in the database based on their criteria. Determine the directory of the database.
Step 2:{delimiter} If the user is asking about filter 3D images in a dataset, you
have a function called find_json, you can use it to unfold zip file, find the meta
data of the dataset in the file and extract the metadata
Step 3:{delimiter} Now that you have the metadata, which is in a JSON format, focus
on the description and keywords within the metadata. Filter all the data in the
database that aligns with the user’s criteria.
Use the following format:
Step 1:{delimiter} <step 1 reasoning>
Step 2:{delimiter} <step 2 reasoning>
Step 3:{delimiter} <step 3 reasoning>
Make sure to include {delimiter} to separate every step. """
Prompt4: toolreusefunction
delimiter = "####"
system_message = f""" Follow these steps to answer the customer queries.
Step 1:{delimiter} First, confirm whether the user wants to reuse the tool created
before, by modifing the code of a file according to his needs and then run it. If
yes, call the read_file function to read this file, specifying the file path clearly
Step 2:{delimiter} Now that you have the code, make modifications according to the
user’s requirements.
Step 3:{delimiter} Call the create_and_execute_python_file function to save and
overwrite the original code, keeping the file name unchanged,clearly specifying the
file path to be saved.
Use the following format:
Step 1:{delimiter} <step 1 reasoning>
Step 2:{delimiter} <step 2 reasoning>
Step 3:{delimiter} <step 3 reasoning>
Make sure to include {delimiter} to separate every step. """
S2.2 Anexampleinteraction
ThefollowingisaconversationbetweentheuserandMicroGPTregardingtheMicrolibDataset. Thesedialogues
the following capabilities of MicroGPT: data collection, custom tool creation and reuse, data filtering, data
simulation,dataanalysis,datavisualization,etc.
DataCollection
21Leietal. LLMsinmaterialsscience Preprint
User: Can you search for the Microlib online, which is a dataset of 3D
microstructures?
Assistant: The Microlib dataset of 3D microstructures is available on Zenodo. Here
are some of the relevant records:
1. [Zenodo Record 7118559](https://zenodo.org/records/7118559)
2. [Zenodo Record 4047774](https://zenodo.org/records/4047774)
3. [Zenodo Record 7867413](https://zenodo.org/records/7867413)
4. [Zenodo Record 8112442](https://zenodo.org/records/8112442)
5. [Zenodo Record 7660542](https://zenodo.org/records/7660542)
6. [Zenodo Record 7043464](https://zenodo.org/records/7043464)
7. [Zenodo Record 5011434](https://zenodo.org/records/5011434)
8. [Zenodo Record 5090057](https://zenodo.org/records/5090057)
9. [Zenodo Record 7702179](https://zenodo.org/records/7702179)
10. [Zenodo Record 7820168](https://zenodo.org/records/7820168)
You can visit these links to find more information about each dataset and access the
data.
User: Download the first one zenodo record 7118559’
Assistant: Do you want to download the file from
https://zenodo.org/records/7118559/files/
microlibDataset.zip?download=1? (yes/no): yes
File downloaded: microlibDataset.zip
The dataset from Zenodo record 7118559 has been downloaded successfully as
‘microlibDataset.zip‘. If you would like to proceed with extracting and organizing
the files, or any other action with this dataset, please let me know!
CustomToolCreationandReuse
User: Please write and execute a script to unzip the file ’./microlibDataset.zip
Assistant: Python script saved as created_script.py Do you want to execute the
script? (yes/no):yes
I have written and executed a Python script to unzip the file ’microlibDataset.zip’.
The contents have been successfully extracted. If you need to work with these files
or have any other requests, please let me know!
User: Please unzip the file named ’./Test_tool_reuse.zip’ using the tool in
’./created_script.py
Assistant:
============================Thinking============================
Step 1:#### To unzip the file ’./Test_tool_reuse.zip’, we first need to read the
existing Python script located at ’./created_script.py’. We will use the read_file
function to read the content of this file. This will allow us to understand the
current functionality of the script and modify it to include the code necessary for
unzipping the file.
Step 2:#### After reading the file, we need to modify the code to add the
functionality to unzip files. We will import the ’zipfile’ module and use the
’ZipFile’ class along with the ’extractall’ method to unzip the file. The code
modification will include handling the path of the zip file and the destination
directory where the contents will be extracted.
22Leietal. LLMsinmaterialsscience Preprint
Step 3:#### Once the code has been modified to include the unzip functionality,
we will call the create_and_execute_python_file function to save and overwrite
the original code in ’./created_script.py’. This will update the script with the
new functionality, and then we will execute the script to perform the unzipping
operation.
========================Start solving the problem!=================
Python script saved as created_script.py Do you want to execute the script?
(yes/no): yes
The files have been extracted to: ./Test_tool_reuse
The script has been updated to unzip the file ’Test_tool_reuse.zip’, and the
execution of the script was successful. The files have been extracted to a
directory named ’Test_tool_reuse’
DataFilter
User: In the ’microlibDataset.zip’ file, can you find all the 3D images related to
cast iron?
Assistant:
============================Thinking============================
Step 1:#### The user is asking to filter the data in the database based on their
criteria, which is to find all the 3D images related to cast iron. The directory of
the database is indicated as ’microlibDataset.zip’.
Step 2:#### Since the user is asking to filter 3D images in a dataset, I will use
the function find_json to unfold the ’microlibDataset.zip’ file, find the metadata
of the dataset in the file, and extract the metadata.
Step 3:#### Now that I have the content of metadata in json-format, I will focus
on the description and keywords in the metadata, and filter all the data in the
database which align with the user’s criteria, which in this case is "cast iron".
========================Start solving the problem!=================
Found file: data_anns.json. Is this the metadata file? (yes/no):yes
JSON file contains items with the following fields:
name
link_doitpoms
data_2D
data_2D_original
data_3D
preview
inpaint_movie
long_movie
data_type
brief_description
keyword
category
element
technique
long_description
contributor
organisation
Enter the fields you want to use to filter your data (separated by
commas):name,keyword
Based on the metadata extracted from the ’microlibDataset.zip’ file, we can filter
all the data related to "cast iron." Here are the entries that match the criteria:
23Leietal. LLMsinmaterialsscience Preprint
- Microstructure 066: Keywords including "cast iron" - Microstructure 068:
Keywords including "cast iron" - Microstructure 072: Keywords including "cast
iron" - Microstructure 360: Keywords including "cast iron" - Microstructure 365:
Keywords including "white cast iron" - Microstructure 368: Keywords including
"white cast iron" - Microstructure 370: Keywords including "white cast iron" -
Microstructure 372: Keywords including "white cast iron" - Microstructure 376:
Keywords including "white cast iron" - Microstructure 378: Keywords including
"grey cast iron" - Microstructure 381: Keywords including "grey cast iron" -
Microstructure 387: Keywords including "grey cast iron" - Microstructure 393:
Keywords including "cast iron" - Microstructure 396: Keywords including "cast
iron" - Microstructure 406: Keywords including "cast iron" - Microstructure 782:
Keywords including "cast iron" - Microstructure 784: Keywords including "cast iron"
- Microstructure 797: Keywords including "cast iron"
These entries are filtered out because they contain the keyword "cast iron" or a
variation thereof, such as "white cast iron" or "grey cast iron." If you need more
information about these microstructures or if you need to extract specific files
related to these entries, please let me know.
Please input an exmaple of data filename: microstructure001.tif
Based on the example filename ’microstructure001.tif’ provided by the user,
we can deduce that the data filenames in the dataset follow the pattern
’microstructureXYZ.tif’, where ’XYZ’ represents a three-digit number, covering all
the ones in the dataset.
Files with the pattern mentioned above have been extracted successfully. However,
since I do not have direct access to the file system to list all the filenames, I
will now list the filenames based on the metadata provided earlier that are related
to "cast iron":
1. microstructure066.tif 2. microstructure068.tif 3. microstructure072.tif
4. microstructure360.tif 5. microstructure365.tif 6. microstructure368.tif
7. microstructure370.tif 8. microstructure372.tif 9. microstructure376.tif 10.
microstructure378.tif 11. microstructure381.tif 12. microstructure387.tif 13.
microstructure393.tif 14. microstructure396.tif 15. microstructure406.tif 16.
microstructure782.tif 17. microstructure784.tif 18. microstructure797.tif
These files are stored in a data folder and are ready for any further analysis or
review that you may need. If you’d like to proceed with any specific analysis or
have other requests, please let me know!
DataSimulation
User: Could you analyze the 3D images in the ’./data’ folder to determine their
tortuosity, diffusion factor, volume fraction, and surface area?
Assistant:
=========================Thinking...=======================
Step 1: #### The user is asking to analyse 3D images in a specific directory
(’./data’). Therefore, I will call a function to extract the filenames of images
in that directory.
Step 2: #### Now that we have the filenames, I will call a simulation function to
analyse the images for tortuosity, diffusion factor, volume fraction, and surface
area.
Step 3: #### After the analysis is complete, I will store all the data into a CSV
file.
=================Start solving the problem!================
The image paths from the specified directory (’./data’) are as follows:
24Leietal. LLMsinmaterialsscience Preprint
- ’./data/microstructure368.tif’ - ’./data/microstructure378.tif’ -
’./data/microstructure782.tif’ - ’./data/microstructure370.tif’ -
’./data/microstructure365.tif’ - ’./data/microstructure387.tif’ -
’./data/microstructure797.tif’ - ’./data/microstructure360.tif’ -
’./data/microstructure376.tif’ - ’./data/microstructure396.tif’ -
’./data/microstructure372.tif’ - ’./data/microstructure406.tif’ -
’./data/microstructure066.tif’ - ’./data/microstructure072.tif’ -
’./data/microstructure784.tif’ - ’./data/microstructure393.tif’ -
’./data/microstructure068.tif’ - ’./data/microstructure381.tif’
The simulation results for the analysis of the 3D images are as follows:
1. Microstructure368.tif: - Effective Diffusivity: 0.4152 - Tau (Tortuosity
Factor): 1.8422 - Volume Fraction: [0.2351, 0.7649] - Surface Area: 0.0919
2. Microstructure378.tif: - Effective Diffusivity: 0.3918 - Tau: 1.9773 - Volume
Fraction: [0.2252, 0.7748] - Surface Area: 0.1074
3. Microstructure782.tif: - Effective Diffusivity: 0.3223 - Tau: 1.7827 - Volume
Fraction: [0.4255, 0.5745] - Surface Area: 0.0396
4. Microstructure370.tif: - Effective Diffusivity: 0.0464 - Tau: 4.2417 - Volume
Fraction: [0.8031, 0.1969] - Surface Area: 0.0838
... (summary continues for each image)
One of the images, Microstructure797.tif, encountered an issue and could not be
processed.
The data from the analysis has been successfully stored into a CSV file. You can
download it using the following link:
[Download microstructure_analysis_results.csv]
(sandbox:/mnt/data/microstructure_analysis_results.csv)
TableS1:Castironrelatedmicrostructure’ssimulationresultsinMicrolib
Volume Volume
Microstructure EffectiveDiffusivity Tortuosity SurfaceArea Fraction Fraction
Phase1 Phase2
microstructure368.tif 0.4152 1.8422 0.0919 0.2351 0.7649
microstructure378.tif 0.3918 1.9773 0.1074 0.2252 0.7748
microstructure782.tif 0.3223 1.7827 0.0396 0.4255 0.5745
microstructure370.tif 0.0464 4.2417 0.0838 0.8031 0.1969
microstructure365.tif 0.1709 2.0907 0.0429 0.6427 0.3573
microstructure387.tif 0.208 2.8765 0.1266 0.4016 0.5984
microstructure360.tif 0.024 5.9349 0.0657 0.8575 0.1425
microstructure376.tif 0.1422 2.5106 0.1341 0.6431 0.3569
microstructure396.tif 0.6924 1.1616 0.0425 0.1958 0.8042
microstructure372.tif 0.0012 85.388 0.0855 0.9013 0.0987
microstructure406.tif 0.3071 1.7043 0.0908 0.4765 0.5235
microstructure066.tif 0.1644 2.1616 0.0919 0.6447 0.3553
microstructure072.tif 0.2527 2.4606 0.1444 0.3783 0.6217
microstructure784.tif 0.0751 5.1606 0.1768 0.6122 0.3878
microstructure393.tif 0.148 2.7249 0.0614 0.5966 0.4034
microstructure068.tif 0.2682 2.17 0.0898 0.418 0.582
microstructure381.tif 0.4692 1.7356 0.1085 0.1858 0.8142
DataAnalysis
25Leietal. LLMsinmaterialsscience Preprint
User: Review and compare these data to identify any data points that are
conspicuously unreasonable or significantly divergent from the rest.
Assistant: Based on the analysis of the dataset for outliers, we’ve identified the
following:
1. **microstructure396.tif**: The effective diffusivity of 0.6924 is identified
as an outlier, as it is significantly higher than what we would expect compared to
other data points.
2. **microstructure372.tif**: This microstructure has an extraordinarily high
tortuosity (Tau) value of 85.388, which is significantly higher than any other data
point, indicating that this value is an outlier and warrants further investigation.
3. **microstructure784.tif**: The surface area value of 0.1768 is marked an
outlier on the higher end, meaning it is significantly larger than most other
surface area values, possibly indicating a highly complex interface between phases.
The rest of the data points appear reasonable, with volume fractions summing close
to 1 as they should. It’s important to remember that while the statistical method
used here highlights significant deviations from the mean, it cannot conclusively
determine whether a value is truly unreasonable without additional context regarding
the materials and processes involved. These identified outliers should be reviewed
carefully with consideration of the experimental conditions or possibly re-measured
if experimental error is suspected.
User: I believe that only the data for microstructure372 is incorrect. Given
that there is an issue with this data, please disregard microstructure 372 when
addressing the following question. Analyze which microstructure possesses the
highest tortuosity.
Assistant: After correctly excluding the data for microstructure372, the
microstructure with the highest tortuosity is microstructure360, which has a
tortuosity (Tau) value of 5.9349.
User: Please compare microstructure 393, 368, and 365
Assistant: Here is a comparison of the specified microstructures based on their
properties:
### Effective Diffusivity (D_eff):
- **microstructure393.tif**: Has a moderate effective diffusivity of around 0.148.
- **microstructure368.tif**: Exhibits the highest effective diffusivity among the
three, at about 0.415.
- **microstructure365.tif**: Close to microstructure393.tif, with a value of around
0.171.
### Tortuosity (Tau):
- **microstructure393.tif**: Has the highest tortuosity with a value of
approximately 2.725.
- **microstructure368.tif**: Has the lowest tortuosity, with a value close to
1.842.
- **microstructure365.tif**: Has a tortuosity value around 2.091.
### Surface Area:
- **microstructure393.tif**: Has a moderate surface area valued at approximately
0.061.
- **microstructure368.tif**: Has the highest surface area with a value of around
0.092.
- **microstructure365.tif**: Has the lowest surface area, near 0.043.
### Volume Fraction Phase 1:
- **microstructure393.tif**: Has a reasonably high volume fraction phase 1 of
approximately 0.597.
26Leietal. LLMsinmaterialsscience Preprint
- **microstructure368.tif**: Has the lowest volume fraction phase 1 of about 0.235.
- **microstructure365.tif**: Has the highest volume fraction phase 1, around 0.643.
### Volume Fraction Phase 2 (complementary to Phase 1):
- **microstructure393.tif**: Has the lowest volume fraction phase 2 of about 0.403.
- **microstructure368.tif**: Has the highest volume fraction phase 2 of
approximately 0.765.
- **microstructure365.tif**: Has a moderate volume fraction phase 2, around 0.357.
Overall, **microstructure368.tif** stands out due to its high effective diffusivity
and surface area, which are beneficial for a catalyst carrier that facilitates
reaction and filtration. However, **microstructure365.tif** also has desirable
properties, such as the highest volume fraction phase 1, which might imply a more
solid structure possibly beneficial for mechanical stability in a catalyst support.
**Microstructure393.tif** appears to be a middle ground with moderate properties
across the board.
DataVisualization
User: Disregard the unreasonable data, can you generate some figures to create
visualizations for the data? Histograms for each numerical column to understand
the distribution of values. Scatter plots to explore relationships between pairs of
numerical variables (e.g., Effective Diffusivity vs. Tortuosity)
Assistant: Here are the visualizations for the data:
### Histograms for Each Numerical Column - The histograms show the distribution
of values for each numerical variable: Effective Diffusivity, Tortuosity, Surface
Area, Volume Fraction Phase 1, and Volume Fraction Phase 2.
### Scatter Plots for Relationships Between Pairs of Numerical Variables - The
scatter plots explore relationships between pairs of numerical variables, such as:
1. Effective Diffusivity vs. Tortuosity
2. Effective Diffusivity vs. Surface Area
3. Effective Diffusivity vs. Volume Fraction Phase 1
4. Tortuosity vs. Surface Area
5. Tortuosity vs. Volume Fraction Phase 1
6. Surface Area vs. Volume Fraction Phase 1
These figures provide insights into how the various microstructural properties are
distributed and how they may relate to one another within the dataset.
27Leietal. LLMsinmaterialsscience Preprint
FigureS7:Histogramsofeffectivediffusivity,tortuosity,surfacearea,andvolumefractionofcast-ironmicrostructuresin
MicrolibasreturnedbyMicroGPT.
FigureS8: Scatterplotsexploringtherelationshipsbetweenpairsofnumericalvariablesofcast-ironmicrostructuresin
MicrolibasreturnedbyMicroGPT.
28Leietal. LLMsinmaterialsscience Preprint
S3 Casestudy2: automatedlabelledmicrostructuredatasetcollection
S3.1 Scrapingandfigureextraction
Themetadata(title,abstract,authors,DOI,etc.) of14,000papersmatchingthesearchquery“microscopy”
werescrapedfromarXivandchemrXivviatheirAPIs. Asubsetof500oftheseweredownloadedfromchemrXiv
andthefiguresandtheirmatchingcaptionsextractedwith‘pdffigures2.0’106. Thisworkedwellbutthetool
sometimesfailedtoextractthewholefigureorcaption.
Figuresweresplitintosubfiguresbydetectingwhitespacepixels(pixelswhoseintensity≈255)andthresholding.
Thebinaryimagewasdilatedtoremovesmallgaps. Theconnectedcomponentsofthenon-whitspacepixels
werecomputedandboundingboxesgenerated-thesewerethensavedassubfigures. Smallfigureslikesub-figure
lettercaptions,werediscarded. Thisprocessworksundertheassumptionthatfiguresusearound5pxwhitespace
toseparatesubfigures,whichtendedtobetrueinmostcases.
S3.2 LLMlabelling
WechosetouseGPT3.5andGPT4astheLLMandVLMinthestudy,primarilyforconvenienceandperformance.
Giventherelativelyuncomplicatednatureofthetask,alocalLLMwouldbepreferableforrunningthisworkflow
at-scale. ThepromptsusedforeachstepareinSectionS3.5.
Thecaptionandabstracttext-onlyGPT4workedwellfordetectingandcategorizationoffigures(seeSection
S3.4),butinordertodetectifaspecificsubfigurewasamicrographavisionmodelwasneeded.
S3.3 Evaluation
AcustomlabellingGUIwaswrittentolabelfiguresandsubfiguresinpapersintermsofwhethertheyhada
micrographpresent,whatmaterialwasshownandwhatinstrumentwasusedtocapturethemicrograph. Italso
allowed comparison of the human labels to the LLM labels for evaluation. We chose to do labelling before
evaluation(i.e,atwo-stepprocess)ratherthanjustreviewingtheLLManswersinordertoavoidbias.
FortheVLMevaluation,wenotedthelackoffalsepositivesbyexaminingthefiguresintheproduceddataset
andresultingT-SNEplot,andnotviathecustomGUI.Thismethoddidnotallowustoreportthefullconfusion
matrix.
29Leietal. LLMsinmaterialsscience Preprint
S3.4 Performanceandissues
FigureS9:Confusionmatricesofmicrographdetectionfor(a)GPT3.5withcaption&abstract,(b)GPT4withcaption&
abstract,(c)GPT3.5withcaption&noabstractand(d)GPT4withcaption&noabstract.GPT4withabstractperformsthe
best,withthehighestsensitivityandspecificity.
30Leietal. LLMsinmaterialsscience Preprint
FigureS10: Confusionmatricesofmicrographdetectionfortwostringmatching(regex)approaches. (a)isthesimple
regexscheme,whereafigureislabelledascontainingamicrographifitcontainsthephrase‘image’or‘micrograph’.(b)is
thegreedyscheme,whereafigureislabelledascontainingamicrographifitmatchesthesimpleschemeorcontainsthe
nameofamicroscopytechniquelike‘SEM’or‘AFM’.Thesimpleapproachworkswellthoughhaslesstruepositivesthan
LLM-basedresultswherethecaptionismoreambiguous.Asexpected,thegreedyapproachhasmoretruepositivesbutfar
morefalsepositives.
S3.5 Prompts
Prompt1: LLMmicrographscreeningutilizingonlythecaptionsoffiguresasinput
system_message ="""
You are an expert on micrographs, images captured using microscopes such as SEM,
TEM, or AFM, etc.
Given caption of a figure from an academic paper, answer the question:
Is there a micrograph in this figure? Respond with ’true’ or ’false’
IMPORTANT: The anwer should only contain pure JSON format only with the fields
"isMicrograph"
Here’s an example of output:
{
"isMicrograph": "true or false"
}
"""
Prompt2: LLMmicrographscreeningutilizingthecaptionsoffiguresandpaperabstractasinput
system_message ="""
31Leietal. LLMsinmaterialsscience Preprint
You are an expert materials scientist. You study micrographs, which are images
taken using a microscope.
Based on an academic paper’s abstract and a specific figure’s caption, provide
answers in JSON format to the following questions:
1. Is there a micrograph in this specific figure? Answer with ’true’ or ’false’.
2. If a micrograph is present, list the techniques used in this figure (e.g., SEM,
TEM, Optical Microscopy). Note that techniques mentioned in the abstract might not
be used in this figure.
3. If a micrograph is present, list the the full name of materials depicted in the
micrographs e.g., ’Lithium Nickel-Manganese-Cobalt (NMC) 811 cathode’ or ’Insulin
aggregates’.
4. Are there any noteworthy details about the micrograph, such as unique
processing conditions or observed anomalies, in a series of brief phrases (e.g.,
[’heat-treated’, ’cracked’, ’sintered’])?
Here’s an example of how the JSON output should look with micrograph present:
{
"isMicrograph": "true",
"instrument": "Technique",
"material": "Description",
"comments": ["comment1", "comment2", "comment3"]
}
Here’s an example of how the JSON output should look without micrograph present:
{
"isMicrograph": "false"
}
IMPORTANT: The answer should only contain pure JSON data matching the fields
provided in the examples.
"""
user_message = f""" The abstract is: {abstract_escaped}, and the captions are:
{captions_escaped}"""
Prompt3: VLMmicrographrecognitionwithasinglesub-figureasinput
user_message_1 = """
You are an expert materials scientist specializing in micrographs.
Typically, these are greyscale and might include annotations like scale bars or
arrows, although not always.
Your task:Given a subfigure image from a research paper
1. check if it is a micrograph or another type of figure, such as a graph or
diagram
2. check if it includes sub-subfigures.
If the image is solely a micrograph without any sub-subfigures, you should respond
with ’TRUE’;
32Leietal. LLMsinmaterialsscience Preprint
otherwise, respond with ’FALSE’.
Here is an example of output:
"Reason: The image is a micrograph with 2 sub-subfigures.
Answer: FALSE"
"""
Prompt4: VLMmicrographrecognitionwithamainfigureandasub-figureasinput
system_message = """
You are an expert materials scientist working on micrographs. The first image is a
main image is taken from a research paper. The second image is a subfigure cropped
from the main image. It is might be a micrograph.
Focus on the abstract of the paper, captions, and the content of these images.
Answer the questions below:
1.Is the cropped image a micrograph? Answer with a single ’true’ or ’false’.
2.What technique (e.g., SEM, TEM) was used to create the micrograph in the cropped
image? Provide a brief answer, such as ’SEM’ or ’Optical Microscopy’.
3.What material is shown in the micrograph? Provide the full name e.g., ’Lithium
Nickel-Manganese-Cobalt (NMC) 811 cathode’ or ’Insulin aggregates’.
4.If there are any interesting things about the micrograph, like specific processing
conditions or anomalies, put these in a list of single phrases (e.g [’heat-treated,
’cracked’, ’sintered’]).
5.Which part of the caption of the mainfigure does this subfigure correspond to?
Extract the caption of the subfigure, and its label e.g (a), (b) if possible.
Here’s an example of the JSON output format:
{
"isMicrograph": True,
"instrument": "Technique",
"material": "Description",
"comments": ["comment1", "comment2", "comment3"]
"subfigure_caption": "(label): caption of subfigure"
}
IMPORTANT: The answer should only contain pure JSON data matching the fields
provided in the examples.
"""
user_message = f"The abstract is: {abstract_escaped}, and the captions are:
{captions_escaped}"
33