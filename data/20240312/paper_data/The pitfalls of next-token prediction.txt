THE PITFALLS OF NEXT-TOKEN PREDICTION
GregorBachmann*1 VaishnavhNagarajan*2
Abstract executingthem. Suchstrategiesareunfortunatelynotex-
plicitlybuiltintothebackboneofthepresent-daylanguage
Canamerenext-tokenpredictorfaithfullymodel
model. Thiscriticismhasbeenfloatingaroundasaninfor-
humanintelligence? Wecrystallizethisintuitive mal viewpoint (LeCun, 2024; Bubeck et al., 2023). Our
concern, which is fragmented in the literature.
paperisaimedatcrystallizingthisintuitivecriticismofnext-
Asastartingpoint,wearguethatthetwooften-
tokenprediction,anddevelopingthecoreargumentsofthis
conflatedphasesofnext-tokenprediction—au-
debate.
toregressive inference and teacher-forced train-
ing — must be treated distinctly. The popular Letusstartbymakingmoreprecise,whatitmeanstosay
criticismthaterrorscancompoundduringautore- thathuman-generatedlanguage,orproblem-solving,does
gressiveinference,cruciallyassumesthatteacher- not follow next-token prediction. When formalizing this,
forcinghaslearnedanaccuratenext-tokenpredic- wehitanimmediateroadblock: isn’teverysequencegen-
tor.Thisassumptionsidestepsamoredeep-rooted erationtaskpossibleautoregressively? Putdifferently,an
problem we expose: in certain classes of tasks, optimistwouldsay,everydistributionoverasequenceof
teacher-forcingcansimplyfailtolearnanaccu- tokens can be captured by an appropriately sophisticated
rate next-token predictor in the first place. We next-tokenpredictorsimulatingthechainruleofprobability
describe a general mechanism of how teacher- i.e., P(r 1,r 2,...) = (cid:81) iP(r i|r 1...r i−1). Thus, the au-
forcingcanfail,anddesignaminimalplanning toregressivityinoursystemsisnotantitheticaltolearning
taskwhereboththeTransformerandtheMamba humanlanguage,afterall.
architecture empirically fail in that manner —
Althoughthisargumentiscompelling,apessimistwould
remarkably, despite the task being straightfor-
worry, realistically, even with minor imperfections in the
wardtolearn. Weprovidepreliminaryevidence
next-token predictor, the accuracy may break down spec-
that this failure can be resolved when training
tacularly for long sequences (Kääriäinen, 2006; Ross &
topredictmultipletokensinadvance. Wehope
Bagnell,2010;LeCun,2024;Dzirietal.,2023).Say,evenif
this finding can ground future debates and in-
everynext-tokenerrorisaslittleas0.01,theprobabilityof
spireexplorationsbeyondthenext-tokenpredic-
encounteringanerroneoustokenexponentiallycompounds
tionparadigm. Wemakeourcodeavailableun-
alongtheway,andbytheendof200tokens,blowsupto
der https://github.com/gregorbachmann/
0.86.
Next-Token-Failures
Thisisasimpleandpowerfulobservation. Yet,thisdoesnot
completelycapturetheintuitionthatnext-tokenpredictors
1. INTRODUCTION may be poor planners. Crucially, this argument does not
carefullydistinguishbetweenthetwotypesofnext-token
Long after its inception in the seminal work of Shannon prediction: inference-timeautoregression(wherethemodel
(1948;1951),next-tokenpredictionhasmadeitswayinto consumesitsownpreviousoutputsasinputs),andtraining-
becomingacorepartofthemodernlanguagemodel. But timeteacher-forcing(Williams&Zipser,1989)(wherethe
despite its long list of achievements, there is a small but model is taught to predict token-by-token consuming all
growingbeliefthatanext-tokenpredictingmodelismerely previousgroundtruthtokensasinputs). Framedthisway,
animpressiveimprovartistthatcannottrulymodelhuman thecompoundingoferrorsonlypinpointsasuperficialfail-
thought. Humans,whennavigatingtheworld,meticulously uretoexecuteaplanduringinference. Itleavesopenthe
imagine,curateandbacktrackplansintheirheadsbefore possibility that we may have still learned a near-perfect
next-tokenpredictor;perhaps,withanappropriatepost-hoc
*Equal contribution 1ETH Zürich, Switzerland 2Google
wrapperthatverifiesandbacktracks,wecanelicittheright
Research, US. Correspondence to: Gregor Bachmann <gre-
planwithoutcompoundingerrors.
gorb@ethz.ch>,VaishnavhNagarajan<vaishnavh@google.com>.
Drawingthisdistinctionallowsustoarticulateamuchmore
Preprint.
1
4202
raM
11
]LC.sc[
1v36960.3042:viXraTHEPITFALLSOFNEXT-TOKENPREDICTION
concerningpossibility: isitsafetoassumethatnext-token Wesummarizeourcontributionsbelow.
basedlearning(teacher-forcing)alwayslearnsanaccurate
next-token predictor? We identify this is not always the
1. Weconsolidateexistingcritiquesagainstnext-tokenpre-
case. Consider a task where we expect the model to wit-
dictionandcrystallizenewcorepointsofcontention(§6
nessaproblemstatementp=(p ,p ...,)andproducethe
1 2 and§3,§4).
groundtruthresponsetokens(r ,r ,...). Teacher-forcing
1 2
2. Weidentifythatthenext-tokenpredictiondebatemust
trainsthemodeltoproduceeachtokenr bynotonlyprovid-
i
not conflate autoregressive inference with teacher-
ingtheproblemstatementpbutalsobyrevealingpartofthe
forcing. Bothleadtovastlydifferentfailures(§3,§A).
groundtruthr ,...r . Dependingonthetask, wefirst
1 i−1
argue that this can induce shortcuts that use the revealed 3. We conceptually argue that in lookahead tasks, next-
prefix of the ground truth answer to spuriously fit future token prediction during training (i.e., teacher-forcing)
answertokens. WecallthistheCleverHanscheat. 1 Next, cangiverisetoproblematiclearningmechanismsthat
while the later tokens (r for large i) become easy to fit aredetrimentaltoevenin-distributionperformance(§4).
i
by the Clever Hans cheat, in contrast, the earlier answer
4. Wedesignaminimallookaheadtask(§4.1). Weempiri-
tokens (say, r ,r etc.,) become harder to learn. This is
0 1 callydemonstratethefailureofteacher-forcingforthe
becausetheynolongercomewithanysupervisionaboutthe
TransformerandMambaarchitectures,despitethetask
fullanswer—partofthesupervisionislosttotheClever
beingeasytolearn(§5).
Hanscheat. Wearguethatthesetwoflawswouldtogether
arisein“lookaheadtasks”:tasksthatrequireimplicitlyplan- 5. Weidentifythatateacherlessformoftrainingthatpre-
ningalatertokeninadvanceofanearliertoken. Insuch dicts multiple future tokens at once — proposed in
tasks, teacher-forcing would result in a highly inaccurate Monea et al. (2023) for orthogonal inference-time ef-
next-tokenpredictorthatwouldfailtogeneralizetounseen ficiencygoals—showspromiseincircumventingthese
problemsp,eventhosesampledin-distribution. training-timefailuresinsomesettings(§5,Eq7). This
furtherdemonstratesthelimitsofnext-tokenprediction.
Empirically, we demonstrate that the above mechanism
leads to complete in-distribution failure in a path-finding
2. THE TWO MODES OF NEXT-TOKEN
setuponagraph,thatweproposeasaminimallookahead
task. We design our setup in a way that it is demonstra- PREDICTION
blystraightforwardtosolvethatthefailureofanymodel
ConsiderasetoftokensV. LetDbeagroundtruthdistribu-
isremarkable. Yet,weobservefailureforboththeTrans-
tionoversequencesthatconsistofaprefixpandaresponse
former(Vaswanietal.,2017)andtheMambaarchitecture,
astructuredstatespacemodel(Gu&Dao,2023). Wealso
r,denotedass = p,r wherep = (p 1,p 2,...,) ∈ VLpref
findthataformofteacherlesstrainingthatpredictsmultiple
and r = (r 1,r 2,...) ∈ VLresp. We assume sequences of
fixedlengthmerelyforsimplicity.
futuretokens(Moneaetal.,2023)is(insomesettings)able
tocircumventthisfailure. Thus,wepinpointapreciseand For any sequence s, let s denote the first i−1 tokens
<i
easy-to-learnscenariowhere,ratherthanpropertiesthatare ofs,ands thetokensfollowingtheithtoken. Notethat
i<
criticizedinexistingliterature—likeconvolutionorrecur- s is the empty prefix. With an abuse of notation, let
<1
renceorautoregressiveinference(see6),—itisnext-token P (s |s )denotethegroundtruthprobabilitymassons
D i <i i
predictionduringtrainingthatisatfault. beingtheithtokengiventheprefixs . Consideranext-
<i
token-predictinglanguagemodelLM (withparametersθ)
Wehopethatthesefindingsinspireandsetfuturedebates θ
suchthatLM (sˆ =s ;s )istheprobabilitythatthemodel
aroundnext-tokenpredictiononsolidground. Inparticu- θ i i <i
assignstotheithoutputsˆ takingthevalues ,givenasinput
lar,webelievethatthefailureofthenext-tokenprediction i i
thesequences . Notethatthenext-tokenpredictoronly
objectiveonourstraightforwardtaskcastsashadowover <i
defines the probability for a single future token given an
itspromiseonmorecomplextasks(suchassay,learningto
input,butnotthejointprobabilityofmultiplefuturetokens.
writestories). Wealsohopethatthisminimalexampleof
Thisjointprobabilityisaxiomaticallydefinedanalagousto
failureandthepositiveresultsonteacherlesstrainingcan
thechainruleofprobability:
motivatealternativeparadigmsoftraining.
1CleverHans(Pfungst&Rahn,1911)wasafamousshowhorse L (cid:89)resp
thatcouldsolvesimplearithmetictasksbyrepeatedlytappingwith LM θ(rˆ=r ;p):= LM θ(rˆ i =r i;p,r <i) (1)
hishoofuntilhereachedthecorrectcount. Itturnsouthowever, i=1
that Clever Hans did not really solve the problem, but merely
stoppedtappingupondetectingcertain(involuntary)facialcues whererˆ=rdenotesanexacttoken-by-tokenmatch.
fromhiscoach.CleverHans’answerswerewrongwhenthecoach
Totraintheabovemodel,twodistincttypesofnext-token
wasabsent.
prediction are used. First, during inference, for a given
2THEPITFALLSOFNEXT-TOKENPREDICTION
prefix,weautoregressivelysamplefromthemodeltoken- we have P (r | p) = (cid:81)LrespP (r | p,r ). There-
D i=1 D i <i
by-token,providingasinputtheprefixandallpreviously- fore, define a next-token predictor LM such that for every
generatedtokens. Formally, validvalueofi,p,andr,wehaveLM(rˆ =r ;p,r ):=
i i <i
P (r |p,r<i). Then,samplingr ∼D|p,isequivalentto
Definition 1. (Inference-time next-token prediction via D i
autoregression) Autoregressive inference is a form of autoregressivelysamplingr ∼ag LM(·;p).
inference-timenext-tokenpredictioninthattogeneratea
Theclevernessofthisargumentliesinthefactthatitcan
responserˆ,weiterateoveri=1,...,L ,tosamplethe
resp
applytoanyimaginabledistribution. Thus,aslongasthe
nexttokenrˆ withthedistributiongivenbyLM (rˆ ;p,rˆ ).
i θ i <i
Wedenotethisasrˆ∼ag LM (·;p). next-tokenpredictorissufficientlyexpressive(byscaling
θ
upthecontext, memoryandcompute), itcanmodelboth
Thereisalsoasecondphaseofnext-tokenprediction,one naturallanguageandproblem-solving. Thus,itmayseem
thatisappliedduringthetrainingprocess,calledteacher- thatnext-tokenpredictorsarenotantitheticaltoplanning-
forcing. Here,insteadoffeedingthemodelitsownoutput basedtasks,afterall.
backasinput,themodelisfedwithprefixesoftheground
Thesnowballingerrorscriticism: Askepticwouldhow-
truthresponser . Meanwhile, themodelisassignedas
<i everraisethefollowingconcern. Regardlessoftheabun-
supervisorytarget, r , thenextgroundtruthtoken. Then,
i danceofcomputationalresources,realisticmodelsaretypi-
themodelmaximizesasumofnext-tokenlog-probabilities:
callynotperfectnext-tokenpredictors. Theremayalways
Definition 2. (Training-time next-token prediction via beaslightchanceoferrorineachstep,andonceanerror
teacher-forcing) Teacher-forced training is a form of iscommitted,thereisnoexplicitbacktrackingmechanism
training-timenext-tokenpredictioninthatwefindparame- torescuethemodel. Theargumentthengoesthat,theprob-
tersθthatmaximizethenext-tokenlog-probabilitysum: abilityoferrorsineachtoken,howeverminiscule,would
exponentiallysnowballalongtheway. Bytheendofalong
J (θ)=E [logLM (rˆ=r ;p)]
next-token (p,r)∼D θ sequence of tokens, the accuracy (of having produced an
(cid:104)L (cid:88)resp (cid:105) error-freeresponse)becomestrivial. Thishasbeenformal-
=E logLM (rˆ =r ;p,r ) (2) izedinvariouscontexts,fromthatofautoregressivemodels
D θ i i <i
i=1 LeCun(2024),tothatofthelimitsofTransformersincom-
positionaltasksDzirietal.(2023),andinadifferentform,
The key property of the objective is that we extract the inmuchearlierworkinimitationlearningandstructured
model’s output, allowing the model access to the ground predictionKääriäinen(2006);Ross&Bagnell(2010)(see
truthresponseprecedingthecurrenttoken. Thisproperty §6). Wepresentaminimalformalizationofthisbelow:
willbecrucialtothefailurewedescribein§4.
Failure1. (Snowballingerrorduetoautoregressiveinfer-
ence)ConsideramodelLM ,prefixpandauniqueground
θ
3. FAILURE DUE TO AUTO-REGRESSIVE truthresponsersuchthatthenext-tokenerrorobeys
INFERENCE
∀i≤L , LM (rˆ ̸=r ;p,r )≈ϵ. (3)
resp θ i i <i
A broad criticism against next-token predictors is that in-
tuitively these models are not explicitly designed to plan Then,forrˆ∼ag LM (·;p)theprobabilitythatthegenerated
θ
ahead,andduringinference,theydonotknowhowtore- responseexactlymatchesthegroundtruthrobeys
coverfromtheirownerrors. Thisdiscoursehasbeenfrag-
mentedinliterature. Furthermore,theumbrellaterm“next- P(rˆ=r)≈(1−ϵ)Lresp.
tokenprediction”isusedinterchangeablywith“autoregres-
sivearchitecture”. Ourgoalistoanalyzetheseintuitions
more systematically, and be careful about distinguishing
betweenthetwophasesofnext-tokenprediction: teacher- Wearguethatthesnowballfailuremodeonlyindicateshow
forcingandautoregression. Akeyinsightwewillarriveat anautoregressivemodelcanfailtoexecuteaplanduring
isthatexistingargumentscaptureonlyapartoftheintuitive inference-time. Itdoesnotprecludethepossibilitythatthe
concernthatnext-tokenpredictorsmaynotbeabletoplan. modelmayhavelearnedagoodplanthatitsimplyfailsto
executeduringinference.Concretely,itmaystillbepossible
The chain-rule-of-probability defense: We first outline
that,ateachstep,themodelhashighaccuracyofpredicting
whatisarguablythemosttemptingdefensefornext-token
anexttokenthatisconsistentwithagoodplan(asassumed
prediction: thechainruleofprobabilityalwayspromisesus
in Eq 3). Depending on the setting, one can potentially
anext-tokenpredictorthatcanfitourdistribution.
exploitthisaccuracytoelicitagoodplanduringinference.
Fact1. (Everysequencedistributioncanberepresented For instance, one may be able to use a post-hoc wrapper
byanext-tokenpredictor)Bythechainruleofprobability that first verifies whether an error has taken place, then
3THEPITFALLSOFNEXT-TOKENPREDICTION
backtracksandre-executesadifferentaction. Onemayeven
9
simulatebacktrackingusingmoreelaboratetechniquessuch
1
aschain/tree/graphofthought(Weietal.,2022;Yaoetal.,
2023a;Bestaetal.,2023;Yaoetal.,2023b),orusingthe 4
modeltogiveitselffeedback(Madaanetal.,2023;Huang 3 2
et al., 2022; Shinn et al., 2023) to elicit the plan that the 5 7
modelhaslearned.
Figure1.Illustrationofapath-stargraph.Theprefixprepresents
Thus,thesnowballfailuremodecaptureswhatisprimarily
theadjacencylistandthe(central)startandgoalnode.Thetargetis
ashortcomingofanautoregressivearchitecture. Likewise,
representedbyr.Under“standard”teacher-forcing,wecondition
thechain-rule-of-probabilitydefensecapturesonlytheex-
the model on prefixes of r to predict r. But in §5 we explore
pressivepowerofanautoregressivearchitecture. Neitherof alternativeswherewetrainwithoutateacher(conditiononr$and
theseargumentsaddressthepossibilitythatlearningwith predictr)ortrainwithareversal(conditiononandpredictrrev).
next-tokenpredictionmayitselfhaveshortcomingsinlearn-
ing how to plan. In this sense, we argue that existing ar-
guments capture only a part of the intuitive concern that
wesampleagraphGwhichisrepresentedasanadjacency
next-tokenpredictorsfarepoorlyatplanning.
list as adj(G) = e ,e ,... where each edge e = (v,v′)
1 2
is represented such that v′ farther away from v than
4. FAILURE DUE TO TEACHER-FORCING start
v. Wethensettheprefixasp=(adj(G),v ,v )so
start goal
themodelknowswhatthegraph,andthedesiredstartand
Canamodeltrainedtopredictthenexttoken,failtopredict
goalstatesare. Thegroundtruthresponsercorrespondsto
thenexttokenwithhighaccuracyduringtest-time? Math-
thesequenceofverticesr =v ,...v onthestart-to-
ematically,thiswouldmeanshowingthatamodeltrained start goal
goalpath. WevisualizethisconstructioninFig.1.
with the teacher-forcing objective of Eq 2 has high next-
tokenpredictionerrorontheverydistributionitwastrained Thestraightforwardlookaheadsolution.Ideally,wewant
on(thusbreakingtheassumptioninEq3ofthesnowballing themodeltolearnamappingfromtheinputpconsisting
failuremode). Consequently,nopost-hocwrappercansal- onlyof(adj(G),v ,v )toanoutputthatisthefull
start goal
vageaplanoutofthemodel. Thegoalofthissectionisto pathr. Twosuchsolutionsarepossible. Oneideaistoplan
conceptuallyarguethatthisfailurecanhappenforlooka- byexaminingallthepathsemanatingfromv andchoos-
start
headtasks: tasksthatimplicitlyrequirecomputingafuture ingtheonethatendsatv . Butasecond,straightforward
goal
tokeninadvancebeforeanearliertoken. solution exists: the model simply needs to look ahead at
thesequence“right-to-left”andobservethatitcorresponds
Asarunningexampleforourargument,wedesignapath-
to the one unique path starting from v and ending at
finding problem on a simple class of graphs. We view goal
v . Afterinternallycomputingthepathfromv and
this example as a minimal setting that captures the core start goal
reversingit,themodelcanemititsresponse.
essenceofwhatitmeanstosolveproblemswithlookahead,
without irrelevant confounding factors. This task is also
demonstrablystraightforwardtosolve,aswewillsee,thus 4.2.Outlineoffailuremechanism
makinganyobservedfailuresremarkable.Thusweviewthis
While we will use the path-star example as a running ex-
runningexampleasatemplateforanintuitiveargumentthat
ample, we make our claim more generally for problems
canbemadeaboutteacher-forcedmodelsonmoregeneral
that require lookahead (such as story-writing, as we will
andharderproblemsthatrequirelookahead.
discusslater). Insuchclassesofproblems,weclaimthat
teacher-forcingpreventslearningthetruemechanisms,caus-
4.1.Path-FindingonPath-StarGraphs: AMinimaland
ingfailure. Intuitively,inteacher-forcing,wedecompose
EasyLookaheadTask thelearningofp→rintomultipleproblems,oneforeach
tokenr . Specifically,wemakethemodellearnamapping
Considerapath-findingproblemonadirectedgraphGwith i
from the input (p,r ) — not just p — to the output r .
a set of nodes {v ,v ,v ,v ,...}. The graph is a <i i
start goal 1 2
The additional information r in the input, we argue, is
“path-star” graph with v as the central node, with at <i
start
problematic and destroys the core challenge in what the
least2paths(eachoflengthl ≥2edges)emanatingfrom
model has to learn. Specifically, our argument puts forth
it, withauniquepathendinginv . Thetaskistofind
goal
two debilitating mechanisms that would together emerge
a path from v to v . Correspondingly, we assume
start goal
underteacher-forcing(explainedoverthenexttwosubsec-
thatthedistributionDisoversequenceswheretheprefixp
tions). While,wewillempiricallyverifythesemechanisms
representsa(randomlygenerated)graph,andtheresponse
forpath-stargraphsin§5,wealsoprovideadiscussionof
representsthepathfromthestarttothegoal. Inparticular,
howourideasapplytoatext-basedscenarioattheendof
4THEPITFALLSOFNEXT-TOKENPREDICTION
Start 33 33 First,theseshortcutsareunlikepreviously-identifiedshort-
Path 17 17 cuts (see §6) that map from the original input prefixes p
0
Goal
20 Easy
Tokens
10 0
20
10
tothegroundtruthr. Thebehaviorweidentifyisunique
7 1 9 7 1 9 tothemappingfromtheteacher-forcedprefixp,r tor .
5 3 2 4 5 3 2 4 <i i
31 31 First Token WenamethisbehaviorasCleverHanscheating. Another
19 35 Difficult Token 19 35 Wrong notable point is that this does not come from a dearth of
14 27 14 27
39 15 39 15 samples:evenifwehadinfinitetrainingdataatourdisposal,
37 18 37 "C Ple rev der ic-H tia on ns" 18 the model can still fit the easy tokens of all that data by
CleverHanscheating.
Figure2.Illustrationofthefailureofteacher-forcingonapath-star
graph. Theleftimagemarksthe“easytokens”whichcanbefit 4.4.TheIndecipherableToken
bytheCleverHanscheat(Failure2a),whilethe“difficulttoken”
cannotbelearned(Failure2b)duetolostsupervision.Theright Perhaps, notall is lost. While the later tokens maybe fit
imageshowshowthemodelwouldbehaveduringautoregressive using the Clever Hans cheat, we may still have some of
inference,undertheabsenceofthe“teacher”. theearliertokens(forsmalli),forwhichsuchcheatsmay
be unavailable. The supervision from these tokens may
eventuallycoercethemodelintolearningthetruesolution.
thissection.
Forexample,inthepath-startask,themodelstillneedsto
learn to predict the first node v , where it is not possible
1
4.3.TheCleverHansCheat
to fit the training data by the Clever Hans cheat. If not
First,andmostimportantly,byrevealingpartsoftheanswer memorizethistokenonthetrainingdata,themostgeneral
to the model as input, we allow the model to fit the data waytofitthistokenisbyactuallysolvingtheunderlying
bycheatingi.e., byusingtrivialmechanismsthatusethe task.
extrainformationinr toproducer . Suchcheatsmust
<i i However, we argue that it is significantly harder for the
especiallybeabundantforthelatertokens(largei)forwhich
modeltolearnthecorrectsolutionnow. Considerthepoint
alargerprefixisrevealed.
in training when the Clever Hans cheat is perfected. At
Toillustratethisinourpath-starexample,withoutlossof thispoint,themodelisdeprivedofinformationaboutmuch
generality,consideragroundtruthpaththatisoftheform ofthefullsolutionwhichwasoncepresentassupervisory
r = v ,v ,v ,...,v . With a slight abuse of the targets. Themodelissimplyleftwiththetaskofmapping
start 1 2 goal
indexing notation, let r = v ,v ,...,v be the theinputptoanincompletesolution(e.g.,thefirstvertex
<i start 1 i−1
prefix of length i (so we index from 0 instead of 1). Ob- v 1 inthepath-stargraph). Recoveringtheplaninthissce-
servethatnodesfromv onwards,untilbeforev ,have nariomustfirstofallberelativelyharderfromastatistical
2 goal
preciselyoneedgegoing“away”fromv . Thus,con- pointofviewduetotheincompletesupervision. Butmore
start
sider when the model is given as input, (p,r ) where importantly,learningthistaskmaybecomecomputationally
<i
p=(adj(G),v ,v ),tofitthetargetv . Themodel harder,orsimply,intractable(Wiesetal.,2023).
start goal i
firstmerelyneedstoscantheadjacencylistadj(G)within
We provide an informal intuition of intractability for the
pfortheoneedgecontainingv inthefirstposition.Then,
i−1 path-starproblem,butthisintuitionshouldextendtomore
themodelonlyhastopredicttheothernodeonthatedgeas
generalproblemsaswell. Intuitively,ourlearnerhastofind
v . Notethough,thischeatcannotworkonfittingthetarget
i anend-to-endalgorithmthatcomposesmultiplesubroutines
v giventheinputr =v sincev hasmanyout-
1 <1 start start overoneanother. Forinstance,recallthatthestraightfoward
wardedges—wewilladdressthisnodeinthenextsection.
solution consists of l steps: start from the current vertex
Weillustratethisdifferencebetweenr andtheremaining
1 asv ,andfindtheprecedingvertexinthegraphineach
goal
tokensasthe“easy”vs. “difficult”tokensinFig.2.
subsequentstep. Eachvertexinthispathcanbethoughtof
Crucially,theabovecheatingmechanismforfittingtheeasy as“intermediatesupervision”tolearnacorresponding“find-
tokens does not require any lookahead. It is simple, and the-adjacent-vertex”subroutinefromaspaceofcandidate
implementablebyaninductionhead-likemodule(Olsson subroutines.2 Evenifweconservativelyassumethatthere
etal.,2022). Owingtothissimplicity,wehypothesizethat isonlyaconstant-sizedspaceofC candidatesubroutines,
thesetokenswillbequicklyfitandignoredduringtraining.
2Asanillustrationofwhatthesecandidatesubroutinescouldbe,
Thisdestroysusefulsignalforthemodeltoefficientlylearn
imaginethatthemodelcanimplementaninductionhead(Olsson
the underlying “right-to-left” solution: the solution that et al., 2022) Ind (p,v) that finds v in the adjacency list of p,
k
requireslookingatalltokensinr,andthenlearningthatthey andoutputsthetokenthatprecedesitbyk positions. Thenthe
aresimplytheuniquepathfromv spelledinreverse. candidatespacecouldbeparameterizedbykas{Ind k(p,v)|k=
goal
1,2,...,}.Forourspecifictokenization,thecorrectsubroutineat
We emphasize two key aspects of this cheating behavior. eachofthelstepsistheinductionheadforwhichk=2.
5THEPITFALLSOFNEXT-TOKENPREDICTION
theend-to-endsearchspaceisanexponentialspaceofCl 4.5.Beyondthepath-starsetting
algorithmscomposinglsubroutines.
Framingourargumentmoregenerally,andinformally,we
Now,aftertheCleverHanscheatisineffect,theonlysuper- arguethatteacher-forcingcansufferthefollowingfailures
vision for this search is a single-token loss of the form inorder,especiallyintasksthatrequireadvancelookahead.
−logLM (rˆ =r ;p). However, this loss is an “all-or-
θ 1 1 Failure2a. (CleverHanscheatingduetoteacher-forcing)
nothing”loss. Crucially,bythediscretenatureofthetask,
Althoughthereisatruemechanismthatcanrecovereach
evenifthelearnergetsonesubroutineincorrect,thefinalan-
r from the original prefix p, there can be multiple other
i
swerrˆ wouldlikelybeincorrectonallinputs. Forinstance,
1 mechanismsthatcanrecoveratokenr fromtheteacher-
i
imaginethatthefirstsubroutineisincorrectlylearnedandits
forcedprefix(p,r ). Thesemechanismscanbesimplerto
<i
outputtakesustoanarbitrarylocationonthegraph. Then,
learnthusdisincentivizingthemodelfromlearningthetrue
even if all subsequent subroutines were correctly learned
mechanism.
(i.e.,theyare“find-the-adjacent-vertex”subroutines),the
Failure2b. (Indecipherabletokenduetolostsupervision)
finaloutputwouldbearbitrary. Thus,wehaverˆ =r pre-
1 1
AftertheCleverHanscheatisperfectedduringtraining,the
ciselyforthealgorithmwherealllsubroutinesarecorrect,
modelisdeprivedofapartofthesupervision(especially,
andrˆ ̸=r foranyotherchoiceofthealgorithm. Forsuch
1 1
r forlargeri). Thismakesitharderandpotentiallyeven
anall-or-nothinglosssurface,theend-to-endlearnermust i
intractableforthemodeltolearnthetruemechanismfrom
necessarilybrute-forcesearchthroughtheexponentialspace
theremainingtokensalone.
ofalgorithms. 3
We encapsulate the overall claim more generally via the Aswedemonstrateinthenextsection,theabovefailures
followingconditions: cancausethemodeltofailontheverydistributionitwas
trainedon. Thisbreakdownofplanningabilitiesemerges
Proposition3. Considerlearningataskthatsatisfiesthe
rightfromtraining, andisorthogonaltotheSnowballing
followingconditions:
Failurethatisprimarilyaninference-timeissue(See§A).
1. It requires composing l discrete-output subroutines Whilethepath-starproblemprovidesaconcreteandempir-
overoneanother. icallyverifiablesettingofthisfailure(whereitiseasyto
reasonandtestthemechanisms),itcanhelpusspeculate
2. Thekleadingresponsetokensaresensitiveinthateven
howsuchfailurescouldoccurinmorecomplexandnebu-
ifonesubroutineisaltered,thefirstktokensareeach
loustasks. Intuitivelyweexpectthisfailuretooccurwhen
completelyaltered.
there are right-to-left dependencies: a token that appears
latermustbeplannedbeforeanearlier-appearingtoken. We
3. The subroutine search space consists of at least C
provideanexamplebelow.
candidatesubroutines.
Story-writing. Considertrainingwithteacher-forcingon
Thenlearningthetaskwithonlysupervisionfromthefirstk novels. Imaginethatthe(sub)plotstaketheformofacon-
groundtruthtokensrequiresexponentialtimeofΩ(Cl). flict, followed by a backstory, followed by a resolution
of the conflict, utilizing the backstory (illustrated in de-
Indeed,literatureonchain-of-thoughthasidentifiedmany tail in §B). Crucially, although the story explicitly reads
instancesofsimilar“multi-hopreasoningtasks”thatcan- asv ,v ,v ,themodelmustlearnto
conflict backstory resolution
not be solved end-to-end — both empirically (Wei et al., decideonv beforeallelse.
backstory
2022)andtheoretically(Wiesetal.,2023)—unlessthere
is“completesupervision”. Weelaborateonthisin§6. However, we hypothesize that a teacher-forced model
trainedwouldfailtolearnthisstory-writingplan. First,the
In§5,wewillverifyexperimentstodemonstratethatour teacher-forcedmodelwouldutilizetheCleverHanscheat:
modelsindeedfailtolearntheIndecipherableTokenasa it would learn the deductive skills required to fit the last
result of Clever Hans cheating, and that conversely, they segmentv usingtheprecedingsegmentsrevealed
resolution
succeedinconditionswheretheCleverHanscheatispre- bytheteacherintheinput, v ,v . Withthe
conflict backstory
vented. supervisionfromv lost,themodelhasnoexplicit
resolution
3Theonlyconditionunderwhichthelearnermayidentifythe indicationofhowv conflict andv backstory dependoneach
rightalgorithmefficientlyiswhenthemodelhasaccidentallyseen other. These would become Indecipherable Tokens. We
similarproblemsduringpretrainingandthushasausefulprior. hypothesize that the resulting model would learn to gen-
Forexample,thepriormaybethatitassignshighprobabilityto
erate uninteresting stories, interjecting arbitrary conflicts
thecorrectsubroutine(s). Or, inthespecificpath-starexample,
andbackstoriesonawhim,subsequentlyforcingcontrived
themodelmayassignhighprobabilitytoalllsubroutinesbeing
identical.Insuchacase,onecanconstructslightvariationsofthe resolutionsuponthem. Whilethishypothesisisnotstraight-
tasksthatdefythisprior,todemonstrateintractability. forwardtoempiricallytestfor,weprovideamoredetailed
6THEPITFALLSOFNEXT-TOKENPREDICTION
conceptualillustrationin§B. 5.1.Observations.
Verifying in-distribution failure. For a given distribu-
5. EXPERIMENTAL VERIFICATION
tion,weevaluateallourteacher-forcedmodelsbyautore-
gressivelygeneratingsolutions,andcomparingthatsolution
In this section, we demonstrate our hypothesized failure
withthetrueoneforanexact-match:
modesinpracticeonthegraphpath-findingtask. Weper-
formourexperimentsinbothTransformersandMambato Acc (LM ):=P(rˆ=r), p,r ∼D, rˆ∼ag LM . (4)
ag θ θ
demonstratethatthesefailuresaregeneraltoteacher-forced
models. Webeginbyestablishingthatourteacher-forced WereportAcc (LM )forpath-stargraphsofvaryingtopolo-
ag θ
models fit the training data but fail in-distribution. Next, giesinFig.3andTable2. Weobservethatallmodels(even
wedesignmetricstoquantifytheextenttowhichthetwo whenpre-trained)struggletolearnthetaskaccurately. The
hypothesizedmechanismsoccur(Failures2a,2b). Finally, accuracy values are precisely limited to the value achiev-
we design alternative objectives to intervene and remove able if the model uniformly guesses a path starting from
each of the two failure modes, to test whether the perfor- v i.e.,≈ 1,thusestablishingcompletein-distribution
start d
manceimproves. Wereportadditionalexperimentsin§D.1 failure. This is so even when trained to fit sample sizes
quantifying the Snowballing Failure 1. We describe our upto200kto100%accuracy,anddespitethefactthatthe
experimentalsettingmorepreciselybelow. trainingandtestgraphshaveidenticaltopology. Next,we
quantitativelydemonstratehowthisstarkfailurearisesfrom
ourtwohypothesizedmechanisms(Failure2a,2b).
Dataset. WedenotebyG (N)ford,l,N ∈ N,apath-
d,l
star graph consisting of a center node v with degree
d∈N,meaningthereareddifferentpaths sta er mt
ergingfrom
VerifyingFailure2a(TheCleverHanscheat) Wehad
hypothesized that the teacher-forcing model would use
thecenternode,eachconsistingofl−1nodes(excluding
cheatingtofitthetrainingtokens(theonesthatfollowr in
thestartnode). Nodevaluesareuniformlysampledfrom 1
eachinstance). Specifically,topredictnodev inthetrue
({0,...,N −1}) where N can be larger than the actual i
path,themodelcanexploitthegroundtruthnodev that
numberofnodesinthepath-stargraph. Ineverygraph,we i−1
isrevealedasinput. Ratherthanlearningtoplan,themodel
usethecenternodeasthestartingnodev andthenpick
start wouldsimply predictthenode thatisoutwardly adjacent
asv ,thelastnodeofoneofthepathschosenuniformly
goal to v . To quantify whether this behavior emerges, we
atrandom. Theorderoftheedgesintheadjacencylistis i−1
“teacher-force”themodelwithauniformrandomneigbhor
randomized. Wedescribethetokenizationin§E.1.
v′ ofv . Wethenlookforwhetherthemodelindiscrim-
1 start
For each experiment, we generate the training and test inatelyappliesthelearnedCleverHanscheathere: doesthe
graphs from the same distribution D, all with the same modelsimplyfollowalongthepaththatemanatesfromthe
topologyofG d,l(N)withfixedd,landN. Thus,anyfail- neigbhorv 1′,notnecessarilyendinginv goal?
urewedemonstrateisanin-distributionfailure,anddoes
Formally, letUnif(N(v ))denoteauniformdistribu-
notarisefromtheinabilitytogeneralizetodifferentproblem start
tionoverthesetofadjacentnodesofv . Foranynodev
lengths(Aniletal.,2022).Wenotethatwhilethegraphsare start
inthegraph,denotebypath(v)thepathemanatingfromv
allofthesametopology,thisisnotatrivialmemorization
andgoingoutwards,awayfromthestartnode. Noticethat
problemforthemodel,sincethegraphsarelabeleddiffer-
exceptforv =v ,thispathisunique. Wethusmeasure
ently,andtheadjacencylistrandomized—themodelhas start
tolearnageneralalgorithm. Throughouttheexperiments, Acc (LM ):=P(rˆ =path(v′)) (5)
cheat θ 1< 1
wefixthenumberofsamplesto200kandfixthenumberof
nodevaluestoN =100acrosstopologiestoenablediverse where p,r ∼D, rˆ ∼ag LM (·;p,v ,v′)
1< θ start 1
instantiationsofthetopologyfortrainingandtesting.
v′ ∼Unif(N(v )).
1 start
Models. Weevaluatemodelsfromtwoarchitecturalfami- Empirically,wefindthatAcc (LM )onaheld-outtest
cheat θ
liestohighlightthatthefailuresarenottiedtoaparticular setis≈ 100%almostacrosstheboard(exceptforgraphs
architecturebutstemfromthenext-tokenpredictionobjec- withveryhighdegreewheretrainingischallenging). The
tive. ForTransformers,weusefrom-scratchGPT-Mini,and exactvaluesarein§D.1,Table1. Thisestablishesthattofit
pretrainedGPT-2large(Radfordetal.,2019). Forrecurrent thetrainingdata,theteacher-forcedmodelhasexploitedthe
models,weusefrom-scratchMamba(Gu&Dao,2023).We CleverHanscheat.
optimizeusingAdamW (Loshchilov&Hutter,2019)until
perfecttrainingaccuracy. Toruleoutgrokkingbehaviour VerifyingFailure2b(TheIndecipherableToken) Re-
(Poweretal.,2022),wetrainedthecheapermodelsforas callthattheCleverHanscheatonlyappliestoallbutthefirst
longas500epochs. Moredetailsarein§E.2. nodev afterv lyingonthepath.AftertheCleverHans
1 start
7THEPITFALLSOFNEXT-TOKENPREDICTION
Standard Teacherless Reverse
Mamba(fromscratch) GPT-Mini(fromscratch) GPT2-Large
100
80
60
40
20
0
G2,5 G2,20 G5,5 G10,5 G20,5 G2,5 G2,20 G5,5 G10,5 G20,5 G2,5 G2,20 G5,5 G10,5 G20,5
Figure3.Fordifferentarchitectures,wereporttheaccuracyofthestandardteacher-forcedmodel(Acc ,Eq4),teacherless-trained
ag
model’saccuracy(Acc ,Eq8)andaccuracyofthemodeltrainedwithreversedtargets(Acc ,Eq9)evaluatedonpath-findingarangeof
$ rev
graphs(withdegreeinthefirstsubscript,andpathlengthinthesecond).
inptolookaheadandfitallthetargetsv fori = 1,...,l.
GPT-Mini Mamba 1 1st 2nd 3rd i
d Formally,wemaximize:
50 1.0
40 0.8
23 00 00 .. 46 J t-less(θ)=E D(cid:104)L (cid:88)resp logLMθ(cid:16) rˆ
i
=r i;p,r <$ i(cid:17)(cid:105) . (7)
i=1
10 0.2
2 3 4 5 6 7 8 9 10 0.0 0 2 4 6 8 10 12 14
Degreed Number of Steps [1k] WedenoteamodeltrainedinthisfashionbyLM$ andper-
θ
forminferencesimplybyconditioningon$tokensi.e.
Figure4.Acc (LM )(inpercent%, Eq6)forpath-stargraphs
1st θ
ofvariousdegreesd ∈ {2,3,5,10}forfixedpathlengthl = 5
rˆ∼$ LM$(·;p)whererˆ ∼LM$(·;p,r$ ).
(left). Individualtokenaccuracies(forv ,v ,v )forthegraph θ i θ <i
1 2 3
G underteacherlesstraining(Eq7)withGPT2-large(right).
5,5
andaccordinglyevaluatetheaccuracy:
cheatfitstherestofthepathduringtraining,wehypothe- Acc (LM$)=P(rˆ=r) p,r ∼D, rˆ∼$ LM$(·;p). (8)
$ θ θ
sizedthatnodev maybecomeimpossibletolearnsincethe
1
modelisdeprivedofallinformationaboutthesubsequent
targets. Toquantifythisbehavior,weevaluatehowwellthe ThistrainingandinferencesetupwasproposedinMonea
modelisabletopredictthedifficultfirstnode,v : etal.(2023)fortheorthogonalpurposeofimprovingthe
1
computational efficiency of inference. Our goal however
Acc (LM )=P(rˆ =r ), p,r ∼D,rˆ∼ag LM (·;p). istoevaluatewhetherforcingthemodeltolookaheadcan
1st θ 1 1 θ
(6) preventtheCleverHanscheatfrombeingpickedup,and
therebyallowthemodeltogeneralizesuccessfully. Were-
whichweestimateusingtheheld-outtestset. Asshownin porttheaccuracyoftheseteacherlessmodelsinFig.3and
Fig.4themodelachievesalowAcc 1st(LM θ),approximately Table3. Unfortunately,inmostcases,theteacherlessobjec-
1/d. Thus,themodelindeedfailstoidentifythatv 1 isthe tiveistoohardforthemodelstoevenfitthetrainingdata,
oneonthepathtov goal. Itinsteadresortstoemittingone likelybecausethereisnosimplecheattoemployhere.How-
ofthedneighborsofv startatrandom. ever,surprisingly,onsomeoftheeasiergraphs,themodels
notonlyfitthetrainingdata,butgeneralizewelltotestdata.
RemovingtheCleverHanscheatviateacherlesstraining Thispositiveresult(evenifinlimitedsettings)verifiestwo
(Moneaetal.,2023). Wenowconsideratrainingsetup hypotheses.First,theCleverHanscheatisindeedacauseof
where we prevent Clever Hans cheating (Failure 2a) and failureintheoriginalteacher-forcedmodel. Secondly,and
examinehowlearningdiffers. Concretely,considermodify- remarkably,withthecheatgone,thesemodelsareableto
ingteacher-forcingbyreplacingtheinputr(whichreveals fitthefirstnodewhichhadoncebeenindecipherableunder
thegroundtruth)withanuninformativeinputr$,consisting teacher-forcing. ThisverifiesourhypothesisthattheClever
ofthesamespecial(“lookahead”)token$repeatedltimes. Hanscheatabsorbsawaysupervisionthatiscriticaltolearn
Forsupervisionintheloss,westillusetheoriginaltarget thefirsttoken. Shortlyattheendofthissection,weprovide
r. Thus,themodelcannotfitthetargetsbylookingatthe more intuition about how exactly teacherless models are
prefixesr andbypredictingthenexttokenv viacheating. able to solve this task with the Clever Hans cheat out of
<i i
Instead,themodelonlyhasaccesstothegraphdescription theirway.
8
]%[ycaruccA
]%[
.ccAnekoTtsriF ]%[
ycaruccATHEPITFALLSOFNEXT-TOKENPREDICTION
Removing the Indecipherable Token failure via path precedes the goal (and can be discovered using a simple
reversal. Back in the teacher-forcing setup, we make a scan of the prefix). Once the model figures this out, the
slight change: we train the model to predict the reversal modelcansimilarlyworkbackwardstofiteachnoder
i−1
of the true path r. Indeed, prior works (Lee et al., 2023; usingthepreviously-fitr . (Wenotethatthissolutionisstill
i
Shenetal.,2023)haveproposedreversalinthecontextof afairlydifficultonetoimplementintheteacherlesssetting,
additiontasksasawayofexplicitlyguidingthenext-token whichsurprisinglysomemodelsneverthelesslearn—we
predictor to learn a simpler algorithm. Likewise, in our describethisin§C.)
“reversed”path-findingtask,themodelnowneedstopredict
OurhypothesisisborneoutinFig.4whereweseethatthe
v firstandmakeitswaytov ;thehopeisthatsince
goal start teacherlessmodelautomaticallylearnsright-to-left:thelater
thereisonlyoneuniquepathemanatingfromv ,there
goal tokensachievehigheraccuracyearlier.Thus,theteacherless
isnoplanningrequired. Thusweshouldneverrunintoan
objectiveprovidesonepossiblewayforfutureworktobuild
IndecipherableToken. Everynextnodecanbelearnedas
alternativestonext-tokenpredictionthatforcethemodels
thenodethatisinwardlyadjacenttothepreviousnode.
tolookahead,withoutfallingintothenext-tokentrapsof
Notationally,weletLMrevbethemodeltrainedtomaximize theCleverHanscheatortheIndecipherableTokenfailure.
θ
J withthetargets(andtheteacher-forcedinputs)
next-token
settorrev =r ,...r ,thereversalofr. Wethenmea-
Lresp 1 6. RELATED WORK
suretheautoregressiveaccuracybycomparingagainstrrev:
Weprovideanelaboratesurveyofthevariousargumentsthat
Acc rev(LMr θev)=P(rˆ=rrev), p,r ∼D,rˆ∼ag LMr θev(·;p) havebeenmadeinfavoroforagainstnext-tokenprediction.
(9) Wehopethiscanhelpconsolidateadebatethathasbeen
scatteredovertheliterature. Partofthesurveyisdeferredto
WedisplaytheresultsinFig.3andTable4.Asexpected,we
§F.
observethatreversingsignificantlyboostslearning,allowing
even models trained from scratch to solve the task. This Arguments in support of next-token prediction. Shan-
verifiesthatforthestandardmodel,indecipherabilityofthe non(1948;1951);Alabdulmohsinetal.(2024)demonstrate
firsttokenwasindeedaroadblocktosuccessfullearning. thatlanguagehasenoughredundancytobeconducivefor
next-tokenprediction. Empirically,Shlegerisetal.(2022)
find that modern language models are surprisingly better
5.2.Whythefailureofteacher-forcingisremarkable.
than humans at next-token prediction on the text dataset,
Weconcludebyemphasizingthatthesuccessofthereversed OpenWebText (Gokaslan & Cohen, 2019). But this does
training (and also, the occasional success of teacherless notprecludethepossibilitythatnext-tokenpredictorsmay
training)makethein-distributionfailureofteacher-forcing stillbepooratplanning. Furthermore,theaboveresultmay
particularly surprising. Recall that, when viewed left-to- beconfoundedbytheabilityoflanguagemodelstostore
right, ourproblemrequirescomplexplanning—evaluat- moregeneralknowledgethanhumans.
ingmultiplepathsandselectingtherightone—butwhen
Onthetheoreticalside,Merrill&Sabharwal(2023b);Feng
viewed right-to-left, the problem is straightforward. The
et al. (2023) show that autoregressive Transformers that
experimentsonthereversedformulationconfirmthatthe
generatechainsofthoughthaveamarkedlylargerexpres-
right-to-left solution is not only expressible by our archi-
sivepower. Mostrelevanttousisthepositivelearnability
tectures,butalsolearnableviagradientdescent. Evidently,
resultsofMalach(2023);Wiesetal.(2023)whichargue
theleft-to-rightteacher-forcedmodelisunabletoviewthe
thatcomplexmulti-hoptasksthatareotherwiseunlearnable,
problemanydifferentlyandfallsintothetrapsoutlinedin
becomelearnablevianext-tokenpredictionwhenthereisa
§4.
precedingchain-of-thoughtsupervisionforeachhop. Our
Intuition for teacherless training. We hypothesize that negativeresultdoesnotcontradictthis. Inourpath-finding
eventeacherlesstrainingallowsthemodeltoimplicitlylearn problem,learningthefirsttokenrequiresanimplicitchain
theright-to-leftview. Concretely,theteacherlessmodelcan- ofthought(thereversedpath)thatwedonotprovidebefore
notusethetrivialCleverHanscheattofitthedata, since thefirsttoken.
thegroundtruthprefixesarenotavailableduringtraining.
Argumentsagainstnext-tokenprediction. Themostwell-
Norisitexplicitlyprescribedtofitthetargetright-to-left.
formulated criticism of next-token prediction is what we
Insteadthemodelistaskedwithusingonlythegraphde-
termasthesnowballingerror,scatteredinliterature,both
scriptioninptofitallthetargetnodesr(implicitlyrequiring
inrecentworkDzirietal.(2023);LeCun(2024)andmuch
alookaheadbeyondjustthenexttoken). Inthisparadigm,
earlierinKääriäinen(2006);Ross&Bagnell(2010). The
themodelwouldfirstfitthetargettokenthatissimplestto
earlierworkscaptureanadditionalnotionofsnowballing,
deduceusingonlyinformationavailableintheprefixp: this
wherein,onceanerroneuoussub-optimalactioniscommit-
isthepenultimatevertexr whichistheuniquetokenthat
l−1
9THEPITFALLSOFNEXT-TOKENPREDICTION
ted,themodelismorelikelytocommitmoresub-optimal diction (and not of the Transformer architecture as some
actionssinceithaswanderedintoterritoriesthatitwasnot existingcriticismsareframed). Importantly,existinglitera-
trainedon. Implicitly,theerrorhereisnotevaluatedasan turepinsthesefailuresbroadlyonthenext-tokenprediction
exactmatchoftheresponse(i.e.,r ̸=rˆ)butasacumulative paradigm and interchangeably, on the inability of the au-
(cid:80)
notionoferroroverallsteps(e.g., 1[r ̸= rˆ]). Inthis toregressivearchitecturetobacktrack. Weemphasizethe
i i
setting,thereisanadditionalcauseoffailurecalledexpo- needtodifferentiatebetweenthetwotypesofnext-token
surebias: theteacher-forcedmodelhasonlybeentrained prediction(teacher-forcingandautoregressiveinference)as
oncorrecttrajectories,andhasnotlearnedhowtorecover they lead to distinct planning-related failures and require
frompoortrajectories. Nevertheless,allexistingcriticisms distinctsolutions.
assumesthatteacher-forcinghaslearnedanaccuratenext-
Goingbeyondnext-tokenprediction. Inference-timetech-
tokenpredictorinthefirstplace,whichistheveryassump-
niques like chain-of-thought and its variants (Wei et al.,
tionourcounterexamplechallenges. Indeed,inoursetting
2022;Yaoetal.,2023a;Bestaetal.,2023;Yaoetal.,2023b)
theerrorhappens“instantaneously”atthebeginningofin-
orthosethatelicitfeedbackfromthemodel(Madaanetal.,
ference.
2023;Huangetal.,2022;Shinnetal.,2023)canbethought
Ourmaincounterexamplecanbeseenasawayofformaliz- ofasgoingbeyondconventionalformofinferencebyal-
inganemerging,informalintuitionthatisoftenwordedas lowingthemodeltothinkmorebeforeproducingitsfinal
“autoregressivenext-tokenpredictorsareill-suitedforplan- answer. However, the backbone in these models are still
ningtasks”. Indeed,Momennejadetal.(2023);Valmeekam trainedbystandardteacher-forcing. Whileothertechniques
etal.(2023)reportfailuresonseveralplanningtasksframed (Burtsevetal.,2020;Xueetal.,2023;Goyaletal.,2023)
aswordproblems(includingpath-findinginMomennejad train the model to explicitly think more, even these boil
etal.(2023))andBubecketal.(2023)onvariousarithmetic, downtonext-tokenpredictionduringtraining.
summarizationandpoem/storygenerationproblems(which
Other works have explored architectures and objectives
theyspeculateisalimitofautoregressivity). McCoyetal.
thattrainthebackbonetogobeyondnext-tokenprediction.
(2023) argue that, for such tasks, the performance of the
Thisincludesnon-autoregressivemodels(Guetal.,2018),
modelmustgreatlydependonitsfrequencyduringpretrain-
energy-based models (Dawid & LeCun, 2023), diffusion
ing. However,wedemonstratethatevenwhentrainedon
models(Gongetal.,2023),andvariantsofTransformers
manysamplesfromadistribution,thenext-tokenpredictor
learningtopredictmultipletokensatthesamego(Qietal.;
canfailontheverydistribution.
Moneaetal.,2023)orinjecting“lookahead”data(Duetal.,
Aclosely-relatedcriticism(Bubecketal.,2023;Dawid& 2023a). Teacherlesstraining—proposedas“parallelspecu-
LeCun, 2023; LeCun, 2024; Du et al., 2023a) is that to lativesampling(PaSS)”inMoneaetal.(2023)—provides
model human thinking, we need to model two types of an arguably simple such approach that involves a trivial
thinkingasoutlinedinKahneman(2011): afast(System1) modificationtoteacher-forcing. Notethatwhileresearch
thinkingprocessthatisalsoguidedbyaslower(Sytem2) inparalleldecodingtooisconcernedwithpredictingmul-
thinkingprocess. Theoretically,Linetal.(2021)showthat tiple future tokens (Stern et al., 2018), the goal is purely
thereareformallanguagesforwhichexpressingsomenext- inference-timeefficiency—whichisalsothesettingunder
tokens may require super-polynomial time or parameter whichMoneaetal.(2023)proposeteacherlesstraining.
countduringinference. Duetal.(2023a)informallynote
Onemayarguethatreinforcementlearning-basedtraining
thatsomenexttokenscanbehardtolearnastheyrequirea
(Ranzatoetal.,2016;Wuetal.,2016;Bahdanauetal.,2017;
globalunderstandingofwhatwillbeutteredinthefuture. 4
Paulusetal.,2018;Ziegleretal.,2019;Stiennonetal.,2020;
Ourworkextendsandclarifiesthisdiscoursebyintroducing Ouyangetal.,2022)isanotherwaytobuildbackbonesthat
theCleverHanscheatandtheIndecipherableTokenfailure. go beyond teacher-forcing. However, it is worth noting
Next,weempiricallyreportourfailuremodesinboththe thatthegradientsinthesetechniquesboildowntoteacher-
Transformer(Vaswanietal.,2017)andtheMambastruc- forcingonthemodel’sowngeneratedanswer. Furthermore,
turedstatespacemodel(Gu&Dao,2023). Thisestablishes ifwedesirethatthemodelbeabletogenerateasolution
thatwhatwewitnessisindeedafailureofnext-tokenpre- thatcanplanaheadoftime,itisunclearhowamodelcan
gofromacompleteinabilitytoplan(thatmayassignnear-
4The Indecipherable Token failure is related to the “locally
zeroprobabilitytothetrueplaninanexponentialspaceof
unlearnable”hypothesisofDuetal.(2023a),butisnotthesame.
solutions),todiscoveringthecorrectplansimplythrough
The(first)IndecipherableTokeninthepath-starproblemislocally
learnablebytheteacherlessmodel,evenwithoutaccesstothefull preference-basedfeedback(see(Havrillaetal.,2024)for
targetsequence(whichisonlypresentedafterthistoken). Thus, relatedempiricalevidence).
theinabilityoftheteacher-forcedmodeltolearntheIndeciperhable
Tokeniscruciallyrelatedtothefactthatthesupervisorytargets Anotherlineofwork—spanninglanguage(Bengioetal.,
thatcomeafterthistokenarelosttotheCleverHanscheat. 2015; Goyal et al., 2016), imitation learning (Ross et al.,
10THEPITFALLSOFNEXT-TOKENPREDICTION
2011;Ross&Bagnell,2010;2014)andstructuredpredic- foretheendtarget.
tion (Daumé III et al., 2009; Chang et al., 2015) — has
Shortcut-learninginlanguagemodels. Alineofworkhas
beenaimedataddressingtheSnowballFailure,underthe
empirically and theoretically analyzed how Transformer-
assumptionthatthemodelhasotherwiselearnedanaccurate
basedlanguagemodelslearnsuperficialshortcutsto(par-
next-steppredictor. Broadly,theideaistotrainthemodel
tially) solve tasks such as learning multiplication (Dziri
onamixtureofthegroundtruthsequencesandthemodel-
etal.,2023),automata(Liuetal.,2023),recursion(Young
generated sequences themselves, as a way to ensure that
&You,2023),readingcomprehension(Laietal.,2021)and
thetest-timeandtraining-timedistributionsareassimilar
multiple-choicequestions(Ranaldi&Zanzotto,2023)
aspossible. Thesetechniqueshoweverdonotaddressthe
failuretolearnagoodnext-steppredictorinthefirstplace. However, these shortcuts must not be confused with the
Clever Hans cheating induced by teacher-forcing. First,
Asforreversal-basedtraining,Leeetal.(2023);Shenetal.
theseaforementionedshortcutsexistindependentofteacher-
(2023) observe that addition tasks become much simpler
forcing: thesearecorrelationsbetweentheprefix(suchas
when the digits are reversed. Their argument is that this
theinitialdigitsoftwomultiplicands)andthefinalanswer
explicitly assists the model to learn a simpler algorithm.
(the initial digits of the product) in the underlying train-
Whenitcomestonaturallanguagehowever,Papadopoulos
ing distribution. But Clever Hans cheats arise only upon
etal.(2024)findthatreversinghurtsthemodel’sperplexity.
teacher-forcing as they are correlations between the pre-
End-to-endreasoningandchain-of-thoughtsupervision. fixesoftheansweritselftotherestoftheanswer. Second,
Inourpath-stargraph,learningtheIndecipherableToken the above shortcuts only fail out-of-distribution (such as
(thefirstnodev )canbethoughtofasataskwhoseendtar- whenthenumberofmultiplieddigitsisincreased, where
1
getisv ,butwhoseimplicitintermediatetargets(or“chain- thefailureisinlengthgeneralization(Aniletal.,2022)). In
1
of-thought”) correspond to the unique path starting from contrast,theCleverHanscheatismuchmoresevereasit
v headedtowardsv (althoughthisisonlyprovidedas causesin-distributionfailure. Thirdly,theaforementioned
goal 1
supervisionafterthefirsttoken). Inthisterminology, we empirical observations are specific to Transformers, and
canrephraseourclaimasthemodelfailingtolearntheend thetheoreticalargumentsrelycruciallyonpropertiesofthe
target once the intermediate targets are lost to the Clever Transformer (such as its non-recurrence and convolution,
HansCheat. oritsself-attentionmodules). Ourargumenthoweveronly
reliesontheteacher-forcingobjectivewithnorelianceon
Such limits of end-to-end learning have been echoed in
theTransformerarchitecture,andisdemonstratedevenfor
literatureonlearningwithchain-of-thought-typesupervi-
therecurrentMambaarchitecture.
sion. Recenttheoreticalworkshaveshownbroadclassesof
tasks(e.g.,anyfunctionefficientlycomputedbyaTuring Pleasesee§Fformorerelatedworks.
machine)whereprependingCoTtotheendtargetallowsef-
ficientlylearningtasks;yet,thereare“multi-hopreasoning”
7. LIMITATIONS
tasksthatareunlearnableend-to-end(i.e.,withoutintermedi-
atesupervision)eitherduetocomputationalhardness(Wies Wenotethatourargumentsareempiricalandconceptual.
etal.,2023)orrepresentationallimits(Malach,2023)). Ear- Wehavenotprovidedaformalproofforourarguments. We
liertheoreticalworksShalev-Shwartzetal.(2017);Shalev- have also not demonstrated failure for very large models
Shwartz&Shashua(2016)havesimilarlyprovennegative suchasLlama2(Touvronetal.,2023)orMistral(Jiang
resultsforend-to-endlearninginsimilarsettings. Similar et al., 2023). Next, beyond the minimal path-finding set-
empiricalargumentshavebeenmadeinneuralnetworklit- ting,wehavenotdemonstratedorcharacterizedtherange
erature(Gülçehre&Bengio,2016;Glasmachers,2017)and ofproblemswhereteacher-forcing-inducedfailuremayoc-
alsomorerecently,inlanguagemodelsoncomplexreason- cur. We only intuitively believe it should extend to other
ingandmathproblems(Nyeetal.,2021;Lingetal.,2017; problem-solvingtasksandcreative-writingtasksthatrequire
Cobbeetal.,2021;Piekosetal.,2021;Zelikmanetal.,2022; lookahead. Itisalsounclearifitgeneralizestorun-of-the-
Recchia,2021;Cobbeetal.,2021). milltext-generationtasks.
Itisworthnotingthoughthattheabovelinesofworkarecon-
cernedwithchain-of-thoughtthatispresentbeforetheend 8. CONCLUSION
target;inoursetup,thissupervisionispresentedonlyafter
Next-tokenpredictionliesattheheartofmodernlanguage
theendtarget. Surprisingly,someofourteacherlessmod-
modelswhichhavedemonstratedtremendousempiricalsuc-
elsmanagetoutilizeevensuchhindsightchain-of-thought.
cessinarangeofgeneraltasks. Theoreticallytoo,weknow
Thissuccessisnotfullyexplainedbyexistingpositivere-
bythechainruleofprobabilitythat,next-tokenpredictors
sultsaboutchain-of-thoughtsupervision,suchasWiesetal.
canexpressanyimaginabledistributionovertokens. Thus,
(2023);Malach(2023),wheresupervisionisprovidedbe-
11THEPITFALLSOFNEXT-TOKENPREDICTION
itistemptingtoviewnext-tokenpredictionasaformidable Processing Systems 35: Annual Conference on Neural
approachtomodelinglanguageandintelligence. Ourwork Information Processing Systems 2022, NeurIPS 2022,
crystallizesthecoreargumentsaroundwhythisoptimism NewOrleans,LA,USA,November28-December9,2022,
maybemisplaced. 2022.
First, we emphasize not to conflate the two modes of Arkoudas, K. Chatgpt is no stochastic parrot. but it also
next-tokenprediction: autoregressiveinferenceandteacher- claimsthat1isgreaterthan1. Philosophy&Technology,
forced training. While existing criticisms primarily chal- 36(3):54,2023.
lenge autoregressive inference, they assume that teacher-
Artetxe,M.,Du,J.,Goyal,N.,Zettlemoyer,L.,andStoy-
forcinglearnsagoodnext-tokenpredictor. Wechallenge
anov,V. Ontheroleofbidirectionalityinlanguagemodel
thisveryassumption,findingthateveninastraightforward
pre-training. InGoldberg,Y.,Kozareva,Z.,andZhang,
task, there is failure due to teacher-forcing — not due to
Y.(eds.),FindingsoftheAssociationforComputational
autoregressive inference or the architecture. This casts a
Linguistics: EMNLP2022,AbuDhabi,UnitedArabEmi-
shadowovermorecomplextasks. Forinstance,aswespec-
rates,December7-11,2022,pp.3973–3985.Association
ulatein§B,canamodeltrainedtopredictthenexttoken
forComputationalLinguistics,2022.
oftensofthousandsoffictionnovels,learntogenerateplot
twists? Bahdanau, D., Brakel, P., Xu, K., Goyal, A., Lowe, R.,
Pineau,J.,Courville,A.C.,andBengio,Y.Anactor-critic
Animmediatewaytocircumventthis,asourreversalexperi-
algorithmforsequenceprediction. In5thInternational
mentssuggest,istotrainwithchain-of-thoughtsupervision,
Conference on Learning Representations, ICLR 2017,
echoing Malach (2023); Wies et al. (2023). However, it
Toulon, France, April 24-26, 2017, Conference Track
isunclearhowthatispossibleinmoreunstructuredtasks
Proceedings,2017.
likestory-writing. Tothatend,ourminimalcounterexample
and the idea of teacherless training (Monea et al., 2023) Bender, E. M., Gebru, T., McMillan-Major, A., and
mayinspirealternativeparadigmstonext-tokenprediction Shmitchell,S. Onthedangersofstochasticparrots: Can
inpractice. Overall,wehopeouranalysesprovideasolid languagemodelsbetoobig? InElish,M.C.,Isaac,W.,
groundtopursuefuturedebatesonnext-tokenprediction. and Zemel, R. S. (eds.), FAccT ’21: 2021 ACM Con-
ferenceonFairness, Accountability, andTransparency,
9. IMPACT VirtualEvent/Toronto,Canada,March3-10,2021,pp.
610–623.ACM,2021.
Ourresults outlinethelimitsof afoundationaltechnique
Bengio,S.,Vinyals,O.,Jaitly,N.,andShazeer,N. Sched-
thatliesattheheartofmodernAIsystems. Naturally,there
uled sampling for sequence prediction with recurrent
aremanypotentialdownstreamsocietalconsequencesthat
neural networks. In Advances in Neural Information
wouldapplyatlargetosuchfoundationalwork,nonewe
Processing Systems 28: Annual Conference on Neural
feelmustbespecificallyhighlightedhere.
InformationProcessingSystems2015, December7-12,
Acknowledgments: WewouldliketothankColinRaffel, 2015,Montreal,Quebec,Canada,pp.1171–1179,2015.
TiagoPimentel,andSurbhiGoelfortheirextensivefeed-
backonadraftofthispreprint, especiallyforpointersto Besta, M., Blach, N., Kubicek, A., Gerstenberger, R.,
somekeyreferences. Gianinazzi, L., Gajda, J., Lehmann, T., Podstawski,
M., Niewiadomski, H., Nyczyk, P., and Hoefler, T.
Graph of thoughts: Solving elaborate problems with
REFERENCES
large language models. CoRR, abs/2308.09687, 2023.
Alabdulmohsin, I., Tran, V. Q., and Dehghani, M. Frac- doi: 10.48550/ARXIV.2308.09687. URLhttps://doi.
tal patterns may unravel the intelligence in next-token org/10.48550/arXiv.2308.09687.
prediction,2024.
Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J.,
Horvitz, E., Kamar, E., Lee, P., Lee, Y. T., Li, Y.,
Allen-Zhu,Z.andLi,Y. Physicsoflanguagemodels: Part
Lundberg, S.M., Nori, H., Palangi, H., Ribeiro, M.T.,
3.2, knowledge manipulation. CoRR, abs/2309.14402,
and Zhang, Y. Sparks of artificial general intelligence:
2023. doi: 10.48550/ARXIV.2309.14402. URLhttps:
EarlyexperimentswithGPT-4. CoRR,abs/2303.12712,
//doi.org/10.48550/arXiv.2309.14402.
2023. doi: 10.48550/ARXIV.2303.12712. URLhttps:
//doi.org/10.48550/arXiv.2303.12712.
Anil,C.,Wu,Y.,Andreassen,A.,Lewkowycz,A.,Misra,
V.,Ramasesh,V.V.,Slone,A.,Gur-Ari,G.,Dyer,E.,and Burtsev,M.S.,Kuratov,Y.,Peganov,A.,andSapunov,G.V.
Neyshabur,B. Exploringlengthgeneralizationinlarge Memorytransformer. arXivpreprintarXiv:2006.11527,
language models. In Advances in Neural Information 2020.
12THEPITFALLSOFNEXT-TOKENPREDICTION
Chang, K., Krishnamurthy, A., Agarwal, A., III, H. D., Gong, S., Li, M., Feng, J., Wu, Z., and Kong, L. Dif-
and Langford, J. Learning to search better than your fuseq: Sequence to sequence text generation with dif-
teacher. InProceedingsofthe32ndInternationalCon- fusion models. In The Eleventh International Confer-
ferenceonMachineLearning,ICML2015,volume37of ence on Learning Representations, ICLR 2023, Kigali,
JMLRWorkshopandConferenceProceedings,pp.2058– Rwanda,May1-5,2023.OpenReview.net,2023. URL
2066. JMLR.org, 2015. URL http://proceedings. https://openreview.net/pdf?id=jQj-_rLVXsj.
mlr.press/v37/changb15.html.
Goyal,A.,Lamb,A.,Zhang,Y.,Zhang,S.,Courville,A.C.,
Cobbe,K.,Kosaraju,V.,Bavarian,M.,Chen,M.,Jun,H.,
andBengio,Y. Professorforcing: Anewalgorithmfor
Kaiser,L.,Plappert,M.,Tworek,J.,Hilton,J.,Nakano,
trainingrecurrentnetworks. InAdvancesinNeuralIn-
R.,Hesse,C.,andSchulman,J.Trainingverifierstosolve
formationProcessingSystems29: AnnualConferenceon
mathwordproblems.CoRR,abs/2110.14168,2021.URL
NeuralInformationProcessingSystems2016,December
https://arxiv.org/abs/2110.14168.
5-10,2016,Barcelona,Spain,pp.4601–4609,2016.
DauméIII,H.,Langford,J.,andMarcu,D. Search-based
Goyal,S.,Ji,Z.,Rawat,A.S.,Menon,A.K.,Kumar,S.,and
structured prediction. Mach. Learn., 75(3):297–325,
Nagarajan,V.Thinkbeforeyouspeak:Traininglanguage
2009.
modelswithpausetokens. CoRR,abs/2310.02226,2023.
Dawid, A. and LeCun, Y. Introduction to latent vari-
ableenergy-basedmodels: Apathtowardsautonomous Gu,A.andDao,T.Mamba:Linear-timesequencemodeling
machine intelligence. CoRR, abs/2306.02572, 2023. withselectivestatespaces,2023.
doi: 10.48550/ARXIV.2306.02572. URLhttps://doi.
org/10.48550/arXiv.2306.02572. Gu, J., Bradbury, J., Xiong, C., Li, V. O. K., and Socher,
R. Non-autoregressive neural machine translation. In
Du, L., Mei, H., and Eisner, J. Autoregressive modeling
6th International Conference on Learning Representa-
withlookaheadattention. CoRR,abs/2305.12272,2023a.
tions, ICLR 2018, Vancouver, BC, Canada, April 30
- May 3, 2018, Conference Track Proceedings. Open-
Du,L.,TorrobaHennigen,L.,Pimentel,T.,Meister,C.,Eis-
Review.net, 2018. URL https://openreview.net/
ner,J.,andCotterell,R.Ameasure-theoreticcharacteriza-
forum?id=B1l8BtlCb.
tionoftightlanguagemodels. InProceedingsofthe61st
Annual Meeting of the Association for Computational
Gülçehre, Ç.andBengio, Y. Knowledgematters: Impor-
Linguistics (Volume 1: Long Papers), pp. 9744–9770,
tance of prior information for optimization. J. Mach.
Toronto,Canada,July2023b.AssociationforComputa-
Learn. Res., 17:8:1–8:32, 2016. URL http://jmlr.
tionalLinguistics. doi: 10.18653/v1/2023.acl-long.543.
org/papers/v17/gulchere16a.html.
URLhttps://aclanthology.org/2023.acl-long.
543.
Gurnee, W., Nanda, N., Pauly, M., Harvey, K., Troitskii,
Dziri,N.,Lu,X.,Sclar,M.,Li,X.L.,Jiang,L.,Lin,B.Y., D., and Bertsimas, D. Finding neurons in a haystack:
West, P., Bhagavatula, C., Bras, R. L., Hwang, J. D., Casestudieswithsparseprobing. CoRR,abs/2305.01610,
Sanyal,S.,Welleck,S.,Ren,X.,Ettinger,A.,Harchaoui, 2023. doi: 10.48550/ARXIV.2305.01610. URLhttps:
Z.,andChoi,Y. Faithandfate: Limitsoftransformerson //doi.org/10.48550/arXiv.2305.01610.
compositionality. CoRR,abs/2305.18654,2023.
Havrilla, A., Du, Y., Raparthy, S. C., Nalmpantis,
Feng,G.,Zhang,B.,Gu,Y.,Ye,H.,He,D.,andWang,L.
C., Dwivedi-Yu, J., Zhuravinskyi, M., Hambro, E.,
Towardsrevealingthemysterybehindchainofthought:
Sukhbaatar,S.,andRaileanu,R. Teachinglargelanguage
atheoreticalperspective. CoRR,abs/2305.15408,2023.
modelstoreasonwithreinforcementlearning,2024.
Glasmachers,T. Limitsofend-to-endlearning. InZhang,
Huang,W.,Xia,F.,Xiao,T.,Chan,H.,Liang,J.,Florence,
M. and Noh, Y. (eds.), Proceedings of The 9th Asian
P., Zeng, A., Tompson, J., Mordatch, I., Chebotar, Y.,
Conference on Machine Learning, ACML 2017, Seoul,
Sermanet,P.,Jackson,T.,Brown,N.,Luu,L.,Levine,S.,
Korea, November 15-17, 2017, volume 77 of Proceed-
Hausman,K.,andIchter,B. Innermonologue:Embodied
ingsofMachineLearningResearch,pp.17–32.PMLR,
reasoning through planning with language models. In
2017. URL http://proceedings.mlr.press/v77/
Liu,K.,Kulic,D.,andIchnowski,J.(eds.),Conference
glasmachers17a.html.
onRobotLearning,CoRL2022,14-18December2022,
Gokaslan,A.andCohen,V. Openwebtextcorpus. http: Auckland, New Zealand, volume 205 of Proceedings
//Skylion007.github.io/OpenWebTextCorpus, ofMachineLearningResearch,pp.1769–1782.PMLR,
2019. 2022.
13THEPITFALLSOFNEXT-TOKENPREDICTION
Jiang, A. Q., Sablayrolles, A., Mensch, A., Bamford, C., OpenReview.net, 2023. URL https://openreview.
Chaplot,D.S.,delasCasas,D.,Bressand,F.,Lengyel, net/pdf?id=De4FYqjFueZ.
G.,Lample,G.,Saulnier,L.,Lavaud,L.R.,Lachaux,M.-
Loshchilov,I.andHutter,F. Decoupledweightdecayregu-
A.,Stock,P.,Scao,T.L.,Lavril,T.,Wang,T.,Lacroix,
larization. InInternationalConferenceonLearningRep-
T.,andSayed,W.E. Mistral7b,2023.
resentations,2019. URLhttps://openreview.net/
Kääriäinen, M. Lower bounds for reductions. In Atomic forum?id=Bkg6RiCqY7.
LearningWorkshop,2006.
Lv,A.,Zhang,K.,Xie,S.,Tu,Q.,Chen,Y.,Wen,J.,and
Yan, R. Are we falling in a middle-intelligence trap?
Kahneman,D. Thinking,fastandslow. Farrar,Strausand
ananalysisandmitigationofthereversalcurse. CoRR,
Giroux,2011.
abs/2311.07468,2023.
Lai,Y.,Zhang,C.,Feng,Y.,Huang,Q.,andZhao,D. Why
Madaan, A., Tandon, N., Gupta, P., Hallinan, S., Gao,
machinereadingcomprehensionmodelslearnshortcuts?
L., Wiegreffe, S., Alon, U., Dziri, N., Prabhumoye, S.,
In Findings of the Association for Computational Lin-
Yang,Y.,Welleck,S.,Majumder,B.P.,Gupta,S.,Yaz-
guistics: ACL/IJCNLP2021,OnlineEvent,August1-6,
danbakhsh, A., and Clark, P. Self-refine: Iterative re-
2021,volumeACL/IJCNLP2021ofFindingsofACL,pp.
finement with self-feedback. CoRR, abs/2303.17651,
989–1002. Association for Computational Linguistics,
2023. doi: 10.48550/ARXIV.2303.17651. URLhttps:
2021.
//doi.org/10.48550/arXiv.2303.17651.
LeCun,Y. Dolargelanguagemodelsneedsensoryground-
Malach,E. Auto-regressivenext-tokenpredictorsareuni-
ingformeaningandunderstanding? UniversityLecture,
versallearners. CoRR,abs/2309.06979,2023. doi: 10.
2024.
48550/ARXIV.2309.06979. URL https://doi.org/
10.48550/arXiv.2309.06979.
Lee, N., Sreenivasan, K., Lee, J. D., Lee, K., and Papail-
iopoulos,D. Teachingarithmetictosmalltransformers. McCoy,R.T.,Yao,S.,Friedman,D.,Hardy,M.,andGrif-
CoRR,abs/2307.03381,2023. fiths, T. L. Embers of autoregression: Understanding
large language models through the problem they are
Li,Y.,Huang,Y.,Ildiz,M.E.,Rawat,A.S.,andOymak,S.
trainedtosolve. CoRR,abs/2309.13638,2023.
Mechanicsofnexttokenpredictionwithself-attention.In
27thInternationalConferenceonArtificialIntelligence Meng,K.,Bau,D.,Andonian,A.,andBelinkov,Y.Locating
andStatistics(AISTATS),2024. andeditingfactualassociationsinGPT. InKoyejo,S.,
Mohamed,S.,Agarwal,A.,Belgrave,D.,Cho,K.,and
Lin, C., Jaech, A., Li, X., Gormley, M. R., and Eisner, J. Oh,A.(eds.),AdvancesinNeuralInformationProcessing
Limitations of autoregressive models and their alterna- Systems35: AnnualConferenceonNeuralInformation
tives. In Toutanova, K., Rumshisky, A., Zettlemoyer, ProcessingSystems2022,NeurIPS2022,NewOrleans,
L., Hakkani-Tür, D., Beltagy, I., Bethard, S., Cotterell, LA,USA,November28-December9,2022,2022.
R.,Chakraborty,T.,andZhou,Y.(eds.),Proceedingsof
the2021ConferenceoftheNorthAmericanChapterof Merrill, W. and Sabharwal, A. The parallelism tradeoff:
theAssociationforComputationalLinguistics: Human Limitationsoflog-precisiontransformers,2023a.
LanguageTechnologies,NAACL-HLT2021,Online,June
Merrill, W. and Sabharwal, A. The expressive power
6-11, 2021, pp. 5147–5173. Association for Computa-
of transformers with chain of thought. CoRR,
tionalLinguistics,2021.
abs/2310.07923, 2023b. doi: 10.48550/ARXIV.2310.
07923. URL https://doi.org/10.48550/arXiv.
Ling,W.,Yogatama,D.,Dyer,C.,andBlunsom,P. Program
2310.07923.
inductionbyrationalegeneration: Learningtosolveand
explain algebraic word problems. In Barzilay, R. and Momennejad, I., Hasanbeig, H., Frujeri, F. V., Sharma,
Kan,M.(eds.),Proceedingsofthe55thAnnualMeeting H., Ness, R. O., Jojic, N., Palangi, H., and Larson, J.
oftheAssociationforComputationalLinguistics, ACL Evaluating cognitive maps and planning in large lan-
2017, Vancouver, Canada, July 30 - August 4, Volume guage models with cogeval. CoRR, abs/2309.15129,
1: LongPapers,pp.158–167.AssociationforComputa- 2023. doi: 10.48550/ARXIV.2309.15129. URLhttps:
tionalLinguistics,2017. //doi.org/10.48550/arXiv.2309.15129.
Liu,B.,Ash,J.T.,Goel,S.,Krishnamurthy,A.,andZhang, Monea, G., Joulin, A., and Grave, E. Pass: Parallel
C. Transformers learn shortcuts to automata. In The speculative sampling. CoRR, abs/2311.13581, 2023.
Eleventh International Conference on Learning Repre- doi: 10.48550/ARXIV.2311.13581. URLhttps://doi.
sentations,ICLR2023,Kigali,Rwanda,May1-5,2023. org/10.48550/arXiv.2311.13581.
14THEPITFALLSOFNEXT-TOKENPREDICTION
Nye, M.I., Andreassen, A.J., Gur-Ari, G., Michalewski, Piekos,P.,Malinowski,M.,andMichalewski,H.Measuring
H., Austin, J., Bieber, D., Dohan, D., Lewkowycz, A., andimprovingbert’smathematicalabilitiesbypredicting
Bosma,M.,Luan,D.,Sutton,C.,andOdena,A. Show the order of reasoning. In Zong, C., Xia, F., Li, W.,
your work: Scratchpads for intermediate computation andNavigli, R.(eds.), Proceedingsofthe59thAnnual
with language models. CoRR, abs/2112.00114, 2021. MeetingoftheAssociationforComputationalLinguistics
URLhttps://arxiv.org/abs/2112.00114. andthe11thInternationalJointConferenceonNatural
Language Processing, ACL/IJCNLP 2021, (Volume 2:
Olsson,C.,Elhage,N.,Nanda,N.,Joseph,N.,DasSarma, ShortPapers),VirtualEvent,August1-6,2021,pp.383–
N., Henighan, T., Mann, B., Askell, A., Bai, Y., Chen, 394.AssociationforComputationalLinguistics,2021.
A.,Conerly,T.,Drain,D.,Ganguli,D.,Hatfield-Dodds,
Z.,Hernandez,D.,Johnston,S.,Jones,A.,Kernion,J., Power, A., Burda, Y., Edwards, H., Babuschkin, I., and
Lovitt,L.,Ndousse,K.,Amodei,D.,Brown,T.,Clark, Misra,V. Grokking: Generalizationbeyondoverfitting
J.,Kaplan,J.,McCandlish,S.,andOlah,C. In-context onsmallalgorithmicdatasets,2022.
learning and induction heads. abs/2209.11895, 2022.
Qi, W., Yan, Y., Gong, Y., Liu, D., Duan, N., Chen, J.,
doi: 10.48550/ARXIV.2209.11895. URLhttps://doi.
Zhang,R.,andZhou,M. Prophetnet: Predictingfuture
org/10.48550/arXiv.2209.11895.
n-gramforsequence-to-sequencepre-training. InCohn,
T.,He,Y.,andLiu,Y.(eds.),FindingsoftheAssociation
Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright,
for Computational Linguistics: EMNLP 2020, Online
C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K.,
Event,16-20November2020,volumeEMNLP2020of
Ray,A.,Schulman,J.,Hilton,J.,Kelton,F.,Miller,L.,
FindingsofACL,pp.2401–2410.
Simens, M., Askell, A., Welinder, P., Christiano, P. F.,
Leike, J., and Lowe, R. Training language models to
Radford,A.,Wu,J.,Child,R.,Luan,D.,Amodei,D.,and
followinstructionswithhumanfeedback. InAdvances
Sutskever,I.Languagemodelsareunsupervisedmultitask
in Neural Information Processing Systems 35: Annual
learners. 2019.
ConferenceonNeuralInformationProcessingSystems
2022,NeurIPS2022,NewOrleans,LA,USA,November Ranaldi,L.andZanzotto,F.M.Hans,areyouclever?clever
28-December9,2022,2022. hanseffectanalysisofneuralsystems,2023.
Ranzato, M., Chopra, S., Auli, M., andZaremba, W. Se-
Pal,K.,Sun,J.,Yuan,A.,Wallace,B.C.,andBau,D. Fu-
quence level training with recurrent neural networks.
turelens: Anticipatingsubsequenttokensfromasingle
In4thInternationalConferenceonLearningRepresen-
hiddenstate. InJiang,J.,Reitter,D.,andDeng,S.(eds.),
tations, ICLR 2016, San Juan, Puerto Rico, May 2-
Proceedingsofthe27thConferenceonComputational
4, 2016, Conference Track Proceedings, 2016. URL
Natural Language Learning, CoNLL 2023, Singapore,
http://arxiv.org/abs/1511.06732.
December6-7,2023,pp.548–560.AssociationforCom-
putationalLinguistics,2023.
Recchia,G. Teachingautoregressivelanguagemodelscom-
plex tasks by demonstration. CoRR, abs/2109.02102,
Papadopoulos,V.,Wenger,J.,andHongler,C. Arrowsof
2021. URLhttps://arxiv.org/abs/2109.02102.
timeforlargelanguagemodels,2024.
Ross,S.andBagnell,D. Efficientreductionsforimitation
Paulus, R., Xiong, C., and Socher, R. A deep reinforced
learning. In Teh, Y. W. and Titterington, D. M. (eds.),
modelforabstractivesummarization.In6thInternational
ProceedingsoftheThirteenthInternationalConference
Conference on Learning Representations, ICLR 2018,
onArtificialIntelligenceandStatistics, AISTATS2010,
ConferenceTrackProceedings.OpenReview.net,2018.
ChiaLagunaResort, Sardinia, Italy, May13-15, 2010,
volume9ofJMLRProceedings,pp.661–668.JMLR.org,
Pfau, J., Infanger, A., Sheshadri, A., Panda, A., Michael,
2010.
J.,andHuebner,C. Elicitinglanguagemodelbehaviors
usingreverselanguagemodels. InSociallyResponsible Ross, S.and Bagnell, J.A. Reinforcement andimitation
Language Modelling Research, 2023. URL https:// learningviainteractiveno-regretlearning.abs/1406.5979,
openreview.net/forum?id=m6xyTie61H. 2014. URLhttp://arxiv.org/abs/1406.5979.
Pfungst, O. and Rahn, C. L. Clever Hans (the Ross, S., Gordon, G. J., and Bagnell, D. A reduction of
horse of Mr. Von Osten) a contribution to exper- imitationlearningandstructuredpredictiontono-regret
imental animal and human psychology. New onlinelearning. InProceedingsoftheFourteenthInterna-
York, H. Holt and company, 1911. URL https: tionalConferenceonArtificialIntelligenceandStatistics,
//www.biodiversitylibrary.org/item/116908. AISTATS 2011, volume 15 of JMLR Proceedings, pp.
https://www.biodiversitylibrary.org/bibliography/56164. 627–635.JMLR.org,2011.
15THEPITFALLSOFNEXT-TOKENPREDICTION
Shalev-Shwartz, S.andShashua, A. Onthesamplecom- Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi,
plexity of end-to-end training vs. semantic abstraction A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P.,
training. CoRR, abs/1604.06915, 2016. URL http: Bhosale,S.,Bikel,D.,Blecher,L.,Ferrer,C.C.,Chen,
//arxiv.org/abs/1604.06915. M.,Cucurull,G.,Esiobu,D.,Fernandes,J.,Fu,J.,Fu,W.,
Fuller,B.,Gao,C.,Goswami,V.,Goyal,N.,Hartshorn,
Shalev-Shwartz, S., Shamir, O., and Shammah, S. Fail-
A.,Hosseini,S.,Hou,R.,Inan,H.,Kardas,M.,Kerkez,
uresofgradient-baseddeeplearning. InProceedingsof
V.,Khabsa,M.,Kloumann,I.,Korenev,A.,Koura,P.S.,
the34thInternationalConferenceonMachineLearning,
Lachaux,M.-A.,Lavril,T.,Lee,J.,Liskovich,D.,Lu,Y.,
ICML2017,Sydney,NSW,Australia,6-11August2017,
Mao,Y.,Martinet,X.,Mihaylov,T.,Mishra,P.,Molybog,
volume70ofProceedingsofMachineLearningResearch,
I.,Nie,Y.,Poulton,A.,Reizenstein,J.,Rungta,R.,Saladi,
pp.3067–3075.PMLR,2017.
K.,Schelten,A.,Silva,R.,Smith,E.M.,Subramanian,R.,
Tan,X.E.,Tang,B.,Taylor,R.,Williams,A.,Kuan,J.X.,
Shannon,C.E. Amathematicaltheoryofcommunication.
Xu,P.,Yan,Z.,Zarov,I.,Zhang,Y.,Fan,A.,Kambadur,
TheBellSystemTechnicalJournal,27(3):379–423,1948.
M.,Narang,S.,Rodriguez,A.,Stojnic,R.,Edunov,S.,
doi: 10.1002/j.1538-7305.1948.tb01338.x.
andScialom,T.Llama2:Openfoundationandfine-tuned
Shannon,C.E. Predictionandentropyofprintedenglish. chatmodels,2023.
TheBellSystemTechnicalJournal, 30(1):50–64, 1951.
Valmeekam, K., Marquez, M., Olmo, A., Sreedharan, S.,
doi: 10.1002/j.1538-7305.1951.tb01366.x.
andKambhampati,S. Planbench: Anextensiblebench-
markforevaluatinglargelanguagemodelsonplanning
Shen, R., Bubeck, S., Eldan, R., Lee, Y. T., Li, Y., and
andreasoningaboutchange,2023.
Zhang,Y. Positionaldescriptionmattersfortransform-
ers arithmetic. CoRR, abs/2311.14737, 2023. doi: 10. Vaswani,A.,Shazeer,N.,Parmar,N.,Uszkoreit,J.,Jones,
48550/ARXIV.2311.14737. URL https://doi.org/ L.,Gomez,A.N.,Kaiser,L.,andPolosukhin,I. Atten-
10.48550/arXiv.2311.14737. tionisallyouneed. InAdvancesinNeuralInformation
ProcessingSystems30: AnnualConferenceonNeuralIn-
Shinn, N., Cassano, F., Berman, E., Gopinath, A.,
formationProcessingSystems2017,December4-9,2017,
Narasimhan,K.,andYao,S. Reflexion: Languageagents
LongBeach,CA,USA,pp.5998–6008,2017.
withverbalreinforcementlearning,2023.
Wei,J.,Wang,X.,Schuurmans,D.,Bosma,M.,Ichter,B.,
Shlegeris, B., Roger, F., Chan, L., and McLean, E. Lan-
Xia, F., Chi, E. H., Le, Q. V., and Zhou, D. Chain-of-
guage models are better than humans at next-token
thought prompting elicits reasoning in large language
prediction. CoRR, abs/2212.11281, 2022. doi: 10.
models. InKoyejo,S.,Mohamed,S.,Agarwal,A.,Bel-
48550/ARXIV.2212.11281. URL https://doi.org/ grave,D.,Cho,K.,andOh,A.(eds.),AdvancesinNeu-
10.48550/arXiv.2212.11281. ralInformationProcessingSystems35: AnnualConfer-
ence on Neural Information Processing Systems 2022,
Springer,J.M.,Kotha,S.,Fried,D.,Neubig,G.,andRaghu-
NeurIPS2022, NewOrleans, LA,USA,November28-
nathan,A. Repetitionimproveslanguagemodelembed-
December9,2022,2022.
dings,2024.
Welleck,S.,Kulikov,I.,Kim,J.,Pang,R.Y.,andCho,K.
Stern, M., Shazeer, N., and Uszkoreit, J. Blockwise par-
Consistencyofarecurrentlanguagemodelwithrespect
alleldecodingfordeepautoregressivemodels. InBen-
toincompletedecoding. InWebber,B.,Cohn,T.,He,Y.,
gio, S., Wallach, H. M., Larochelle, H., Grauman, K.,
andLiu,Y.(eds.),Proceedingsofthe2020Conference
Cesa-Bianchi, N., and Garnett, R. (eds.), Advances in
onEmpiricalMethodsinNaturalLanguageProcessing
NeuralInformationProcessingSystems31: AnnualCon-
(EMNLP),November2020.
ferenceonNeuralInformationProcessingSystems2018,
NeurIPS2018,December3-8,2018,Montréal,Canada, Wies,N.,Levine,Y.,andShashua,A. Sub-taskdecomposi-
pp.10107–10116,2018. tionenableslearninginsequencetosequencetasks. In
TheEleventhInternationalConferenceonLearningRep-
Stiennon, N., Ouyang, L., Wu, J., Ziegler, D. M., Lowe, resentations,ICLR2023,Kigali,Rwanda,May1-5,2023.
R., Voss, C., Radford, A., Amodei, D., andChristiano, OpenReview.net, 2023. URL https://openreview.
P. F. Learning to summarize from human feedback. net/pdf?id=BrJATVZDWEH.
CoRR, abs/2009.01325, 2020. URL https://arxiv.
Williams,R.J.andZipser,D. Alearningalgorithmforcon-
org/abs/2009.01325.
tinuallyrunningfullyrecurrentneuralnetworks. Neural
Thrampoulidis, C. Implicitbiasofnext-tokenprediction, Computation, 1(2):270–280, 1989. doi: 10.1162/neco.
2024. 1989.1.2.270.
16THEPITFALLSOFNEXT-TOKENPREDICTION
Wu, Y., Schuster, M., Chen, Z., Le, Q. V., Norouzi, M.,
Macherey,W.,Krikun,M.,Cao,Y.,Gao,Q.,Macherey,
K.,Klingner,J.,Shah,A.,Johnson,M.,Liu,X.,Kaiser,
L.,Gouws,S.,Kato,Y.,Kudo,T.,Kazawa,H.,Stevens,
K.,Kurian,G.,Patil,N.,Wang,W.,Young,C.,Smith,J.,
Riesa,J.,Rudnick,A.,Vinyals,O.,Corrado,G.,Hughes,
M., and Dean, J. Google’s neural machine translation
system: Bridgingthegapbetweenhumanandmachine
translation. CoRR,abs/1609.08144,2016. URLhttp:
//arxiv.org/abs/1609.08144.
Xue, F., Likhosherstov, V., Arnab, A., Houlsby, N., De-
hghani, M., and You, Y. Adaptive computation with
elasticinputsequence. InInternationalConferenceon
MachineLearning,ICML2023,ProceedingsofMachine
LearningResearch.PMLR,2023.
Yao,S.,Yu,D.,Zhao,J.,Shafran,I.,Griffiths,T.L.,Cao,
Y., and Narasimhan, K. Tree of thoughts: Deliberate
problem solving with large language models. CoRR,
abs/2305.10601,2023a.
Yao,S.,Zhao,J.,Yu,D.,Du,N.,Shafran,I.,Narasimhan,
K. R., and Cao, Y. React: Synergizing reasoning and
acting in language models. In The Eleventh Interna-
tional Conference on Learning Representations, ICLR
2023,Kigali,Rwanda,May1-5,2023.OpenReview.net,
2023b. URLhttps://openreview.net/pdf?id=WE_
vluYUL-X.
Young, T. and You, Y. On the inconsistencies of con-
ditionals learned by masked language models. CoRR,
abs/2301.00068, 2023. URL https://doi.org/10.
48550/arXiv.2301.00068.
Zelikman, E., Wu, Y., Mu, J., and Goodman, N. D.
Star: Bootstrapping reasoning with reasoning. In
Koyejo, S., Mohamed, S., Agarwal, A., Belgrave,
D., Cho, K., and Oh, A. (eds.), Advances in Neural
Information Processing Systems 35: Annual Con-
ference on Neural Information Processing Systems
2022, NeurIPS 2022, New Orleans, LA, USA, Novem-
ber 28 - December 9, 2022, 2022. URL http://
papers.nips.cc/paper_files/paper/2022/hash/
639a9a172c044fbb64175b5fad42e9a5-Abstract-Conference.
html.
Ziegler,D.M.,Stiennon,N.,Wu,J.,Brown,T.B.,Radford,
A., Amodei, D., Christiano, P. F., and Irving, G. Fine-
tuninglanguagemodelsfromhumanpreferences. CoRR,
abs/1909.08593,2019. URLhttp://arxiv.org/abs/
1909.08593.
17THEPITFALLSOFNEXT-TOKENPREDICTION
A. TEACHER-FORCING FAILURE AND SNOWBALLING FAILURE ARE DISTINCT
Weemphasizethat,whileboththeCleverHansfailuremodeandtheSnowballmodearebothindicativeoftheinabilityto
plan,thesefailuremodesarealsoorthogonaltoeachother,anddemanddifferentsolutions. Wemakethisabitmoreformal:
Proposition4. Inthepathfindingproblemof§4.1,thereexistsanext-tokenpredictorthatexperiencesFailures2a,2b
duetoteacher-forcing,butnotthesnowballingerrorFailure1duetoautoregressiveinference. Conversely,thereexistsa
next-tokenpredictorthatexperiencesthelatterfailurebutnottheformer.
Proof. Considerthemodellearnedviateacher-forcingonthegraphproblem. Duringinference,wesawthatitsuffersa
debilitatingerrorrightinthefirststep(withaccuracyof1/dfordegreedofthestartnode). Thus,duringinferencethe
error that is experienced is not from an accumulation over length. In fact, if only the first node is set correctly during
inference,amodelwiththeperfectCleverHanscheat,wouldachieve100%accuracyrate. Suchamodeldoesnotexperience
snowballingerrors.
Ontheotherhand,consideramodel,thatineachsteppredictsthecorrectnextvertexwithahighaccuracyof1−ϵfor
smallϵ. Suchamodelclearlyhaslearnedthecorrectplan,albeitwithminorerrorsineachtoken. Theseerrorshowever
cansnowballduringinference. Thus,thismodelhasnofailureduetoteacher-forcing,butwillfailduringautoregressive
inference,ifthepathlengthislong.
Differingsolutions. Basedontheabovesimpleillustration,wenotethatthetwofailuresneeddifferentsolutionapproaches.
Specifically,whilesnowballingerrorsmaybefixablevia“backtracking-and-planning”wrappers,teacher-forcingfailuresis
apathologythatcannotbesolvedpost-hoc.
B. AN ILLUSTRATION VIA STORY-TELLING
Canateacher-forcedmodelmerelytrainedonthousandsofstorieslearntowriteplottwists? Indeed,Bubecketal.(2023)
reportinstanceswheremodelscanfailtoaccomplishtasksinvolvingcreative-writing(e.g.,poems). Wespeculativelyextend
ourdiscussionin§4toreasonaboutthisscenario. Considerforexample,teacher-forcingonthefollowingstorythatfollows
anoften-usedplotoutline:
• Event 1 (Setup):AlexandBob,whoarefriends,aretryingtodefeattheEvilKing.
• Event 2 (Conflict):Oneday,surprisingly,BobturnsagainstAlex,andtriestothwartAlex’splans,albeitunsuccessfully.
• Event 3:AlexthinksBobiseviltoo,defeatsBobfirst.
• Event 4 (Backstory):Losingthebattle,Bobrevealsheisadouble-agent.Inhisfinalwords,Bobexplainshewasorderedto
defeatAlex.
• Event 5 (Resolution): TopreservetheKing’strust,Bobobeyedthecommand,butalsodeliberatelyfailedatit.Bobthen
relayscriticalinformationheextractedfromtheKing’sinnercircles.
• Event 6:AlexusesBob’sinsiderinformationtodefeattheKing.
Evidently,thisstoryrequiresaplan:Event 5isakeyplotresolutionthatthenarratormusthaveplannedbeforemethodically
generatingpartsofthesetupinEvent 1(introducingBobasafriend)andtheconflictinEvent 2(Bob’sturningagainst
Alex,andfailingatit). Whiletraining,themodelmustthustreatthestoryasawhole,andteaseapartthesedependencies
betweentheevents,someofwhichmaybeanti-chronological(akintohow,inthepath-stargraph,themodelmustlearnthat
theproblemisstraightforwardlysolvablewhenviewedfromright-to-left).
However,wehypothesizethatateacher-forcedmodelwouldtakearigidchronological(left-to-right)view. First,itwould
usetheCleverHanscheattoeasilyfittheplotresolutioninEvent 5: themodelwouldusethefactsofEvent 4andEvent
2(revealedasinput)tofitthecontentofBob’sfinalwords. Thus,thecontentofEvent 5wouldnolongerbeavailable
assupervisiontoguidehowthemodelfitsEvent 1andEvent 2. Whenthemodeltriestofittheseearlierevents,these
eventswouldbecomeIndecipherableTokens—themodelwouldsimplylearntofitthemasarbitraryevents. Thus,we
conjecturethatamodeltrainedviateacher-forcingmerelyonraw,unannotatedtextsofstories—howevermanystories
theymaybe—wouldnotlearntoplanitsstories,andwouldinsteadcreatearbitrarytwistsandturnsduringinference,and
improvizeuponthat.
18THEPITFALLSOFNEXT-TOKENPREDICTION
C. MORE ON TEACHERLESS TRAINING
Recallthatourhypothesisisthattheteacherlessmodelautomaticallylearnstofitthetargetsinthereverseorder,sincethe
pathfromthev isunique. ThisisindeedwhatwefindinFig4,wheretheaccuraciesofthelatertokensbecomehigher
goal
earlier.
Notethoughthatthisisafairlydifficultcomputationtoimplement. First,whenthemodelpredictsv ,itmustrequirethe
i
identifyofv . However,thisidentityisnotfedasinputtothemodel,intheabsenceoftheteacher. Thusthemodelmust
i+1
havecomputedv andcrucially,storedthatinoneofitsitsinternalrepresentations. Then,byinduction,whenpredicting
i+1
thefirstnodev ,themodelmustknowtheidentityofalltheothernodesinthepath. Inotherwords,themodelmusthave(a)
1
computedand(b)storedthewholesolutioninitshiddenrepresentationsbeforeitoutputsthefirsttoken. Thisisasubstantial
typeoflookaheadthatsomeofourmodelsareabletoachieveunderteacherlesstraining.
D. MORE EXPERIMENTAL RESULTS
D.1.SnowballFailure
Toexplicitlymeasuretowhatdegreethemodelfallsvictimtothesnowballeffect,wetrainGPT-Miniongraphsofvarious
pathlengthsl. Inordertoremovethefailurestemmingfromthedifficultfirsttoken,weteacher-forcethemodelforthefirst
tokenandthencheckhowaccuratethegenerationsareforsubsequenttokens. Moreconcretely,weevaluate
Acc (LM )=P(rˆ =r ) (10)
sb θ 1< 1<
where p,r ∼D, rˆ ∼ag LM (·;p,r )
1< θ 1
If Acc (LM ) is ≈ 1, then Failure 1 is not prominent in our task. If Acc (LM ) ≪ 1, then clearly teacher-forcing is
sb θ sb θ
responsibleforsurpressingerrorsingeneration,stronglyhintingatthefactthatFailure1isatplay. Wedisplaytheresultsin
Fig.5(left). WeobservethattheaccuracyAcc isbarelyaffectedevenforgraphswithverylongpathsL=40.
sb
Asanothermetric,weproceedtokenbytokenduringinference,andevaluatetheprobabilityofcorrectlypredictingall
tokensuptothecurrentone. WereportthisforG inFig.5(right). Similarly,whilethesuccessprobabilitydoesdecay
2,40
forlargerlength(atanexponentialrate),itremainsveryhighduetothefailureeventsbeingsounlikely. Wethusconclude
thatFailure1isnotasprominentinthissetting.
101.0
MiniGPT
100.5 1.0 (0.999996)x
100.0
99.5
0.99996
99.0
98.5
0.99994
98.0
97.5
0.99991
97.0
5 10 15 20 25 30 35 40 0 5 10 15 20 25 30 35
Pathlength
Path length
Figure5.AccuracyofLM whenconditionedonthefirstdifficulttoken(left)forgraphsofvariouslength.Probabilityofcorrectprediction
θ
ofLM asafunctionofcurrenttokenpositiononG ,aswewalktowardsthegoal.
θ 2,40
D.2.CleverHansCheatingAccuracies
InTable1wedisplaytheCleverHanscheatingaccuraciesAcc (LM ). Weobservethatinalmostallcases,allthemodels
cheat θ
achievenearlyperfectcheatingaccuracies. Theonlyexceptionisthehigh-degreegraphG whereallmodelsstruggleto
20,5
evenfitthetrainingdata.
19
]%[
ycaruccA
evitareneG
sseccuSfoytilibaborPTHEPITFALLSOFNEXT-TOKENPREDICTION
G G G G G
2,5 2,20 5,5 10,5 20,5
GPT-MINI 99.7 100 100 99.8 0.0
GPT2-LARGE 99.8 99.7 100 99.8 0.0
MAMBA 97.6 98.3 99.5 95.9 0.0
Table1. EvaluatingCleverHanscheatingaccuraciesAcc (LM )(inpercent%)fordifferenttypesofgraphs.
cheat θ
D.3.MoreDetailedAccuracies
Wereportmoredetailedaccuracyvaluespermodelinthefollowingtables. WedisplaystandardaccuracyAcc (LM )in
ag θ
Table.2,teacherlessaccuracyAcc (LM )inTable.3andreverseaccuracyAcc (LM )inTable.4. Ingeneralweobserve
$ θ rev θ
thatsolvingthetaskwithstandardnext-tokenpredictionisverytoughandperformanceislimitedto 1 wheredisthedegree
d
ofthegraphG .
d,l
G G G G G
2,5 2,20 5,5 10,5 20,5
GPT-MINI 49.8 49.1 19.1 8.1 0.0
GPT2-LARGE 48.9 49.2 19.4 10.3 3.5
MAMBA 48.5 48.7 20.2 9.3 0.0
Table2. AutoregressiveaccuraciesAcc (LM )(inpercent%)fordifferenttypesofgraphs.
ag θ
TeacherlesstrainingontheotherhandworksverywellwithGPT2-Large,allowingittosolvemostgraphtasksperfectly.
From-scratchmodelshoweveralsostruggletolearnthetaskinthisfashion(exceptforGPT-Minionthesimplestgraph,
G ).
2,5
G G G G G G
2,5 2,10 2,20 5,5 10,5 20,5
GPT-MINI 99.9 0.0 0.0 0.0 0.0 0.0
GPT2-L 99.9 98.8 0.0 99.0 97.8 0.0
MAMBA 0.0 0.0 0.0 0.0 0.0 0.0
Table3. AutoregressiveaccuracyAcc whenusingateacherlessresponse.
$
Finally,reversingthesequencesignificantlysimplifiestheproblemforallthemodels,allowingnearperfectaccuracies
acrossallgraphs.
G G G G G
2,5 2,20 5,5 10,5 20,5
GPT-MINI 99.7 99.8 100 99.8 0.0
GPT2-LARGE 99.9 99.9 99.6 99.8 99.9
MAMBA 98.5 96.2 99.1 99.5 0.0
Table4. AutoregressiveaccuracyAcc whenreversingtheresponser.
rev
20THEPITFALLSOFNEXT-TOKENPREDICTION
E. OTHER EXPERIMENTAL DETAILS
E.1.Tokenization
Wetokenizethegraphinthefollowingmanner: (1)wefirsttokenizetherandomlyshufflededgelistas“|v v |v v |...”
1 2 3 4
wherethefirstvertexineachedgeistheoneclosesttov ,(2)thenappendstartandgoalnodeas“/v v = ”
start start goal
and(3)thenappendthefullpathrepeatingstartandgoalnode,”v v ...v v ”. Notethat(1)and(2)makeup
start i1 il−1 goal
theprefixp,whichthemodeldoesnotlearntopredict. Then,(3)isthetargetsequencethatthemodelaimstolearn. The
vocabularysizeisthusgivenbyN +3,whereweaddentriesforthespecialtokens“|”,“/”and“=”. Whenusingthe
pre-trainedmodelsGPT2weusethetokenizerthatwasemployedforpre-training, inthiscasetheByte-Pairtokenizer
(Radfordetal.,2019).
E.2.Models
WhentrainingTransformermodelsfromscratch,weuseasmallmodelconsistingofn =12blockswithembedding
layers
dimensione = 384,n = 6attentionheadsandMLPexpansionfactore = 4,coinedGPT-Mini. Forpre-trained
dim heads
models,weconsiderGPT2-Largewithn =36,e =1280,n =20andexpansionfactore=4(Radfordetal.,
layers dim heads
2019). Tofurtherevaluatepurelyrecurrentmodels,weperformexperimentswiththerecentMambamodel(Gu&Dao,
2023). WetraintheMambamodelsfromscratchwith12layersandembeddingdimension784. Wetrainallthemodelswith
theAdamW optimizer(Loshchilov&Hutter,2019). Formodelstrainedfromscratchweusealearningrateofη =0.0005
whileforpre-trainedmodelsweuseasmalleroneofη = 0.0001. Inbothcasesweuseweightdecayofstrength0.01.
Modelsfromscratcharetrainedforupto500epochsinordertoensureconvergence. Pre-trainedmodelsrequirelesstraining
timeandweusuallyfitthetrainingdataperfectlyafter10epochs.
F. MORE RELATED WORK
Otherargumentsaboutnext-tokenpredictionWesurveyrelatedargumentsofnext-tokenprediction,orthogonaltoour
maindiscussionregardingplanning.Allen-Zhu&Li(2023);Lvetal.(2023)reportthatlanguagemodelsthataretrainedonA
equals BareunabletoinferB equals A,whichAllen-Zhu&Li(2023)suggestisduetoautoregressiveleft-righttraining.
Duetal.(2023b);Wellecketal.(2020)formalizethelimitationthatautoregressivemodelsmaypotentiallyassignnon-zero
probabilitytoinfinite-lengthstrings,thusleadingtonon-terminatinginference. Lietal.(2024)provideaTransformer-
specificanalysisofhowself-attentionaffectstheoptimizationgeometryofnext-tokenprediction. Thrampoulidis(2024)
provideananalysisoftheimplictbiasofoptimizationwithnext-tokenpredictionforlinearmodels.
Other limitations of Transformers Merrill & Sabharwal (2023a) identify limitations of the representative power of
Transformerarchitecturewhenthearithmeticprecisionislogarithmicinthenumberofinputtokens. Benderetal.(2021)
criticizeGPT-likelanguagemodelsassimplyparrotingouttrainingdatawithminorstochasticity,whileArkoudas(2023)
reportthatsuchmodelsstrugglewithreasoning,evenifnotastochasticparrot. Young&You(2023)studymaskedlanguage
(T5,BERT)models(notcausally-trained)andarguethereareinconsistenciesintheprobabilitiesthattheyassign. E.g.,when
conditionedon‘white’,theprobabilityof‘rice’maybehigher‘bread’buttheprobabilityof‘white bread’and‘white
rice’ are the opposite. Artetxe et al. (2022) empirically analyze the effect of bidirectional attention and bidirectional
supervision(asinmaskedlanguagemodeling)duringpretrainingontheabilityofthemodeltodovariousthings,including
next-tokenprediction. Springeretal.(2024)arguethatautoregressiveTransformerscomputesub-optimalembeddingsthat
canbeimprovedbyrepeatingtheinputtexttwice.
Finally,wenotethat(Ranaldi&Zanzotto,2023)usethetermCleverHanseffecttodenotehowmodelscanpickupspurious
correlationsbetweenthepositionofachoiceinamultiple-choicequestion,andthecorrectnessoftheanswer. Wenotethat
theabovecorrelationisinherenttothedistribution,andindependentofteacher-forcing. WedistinguishthisfromtheClever
Hanscheatingwhichhappensundertheguidanceofteacher-forcing.
Goingbeyondnext-tokenprediction-basedtraining. Finally,wenotethatsomeworks(Gurneeetal.,2023;Mengetal.,
2022;Paletal.,2023)aimtorecoverfuturetokensthatanalready-trainedmodelmaypredictbasedontheinternallayersof
thecurrenttoken. Notethatthesuccessofthisdoesnotimplythatthemodelnecessarilyplanswell. Thisonlymeansthatit
ispossibletorecoverwhatthealready-trainedmodelwantstogenerateinthefuture(whichmaysimplybeabadplan).
Pfauetal.(2023)trainalanguagemodeltopredictinreversewiththeorthogonalgoaloffindingprefixesthatelicitcertain
behaviors.
21