[
    {
        "title": "Wolf: Captioning Everything with a World Summarization Framework",
        "authors": "Boyi LiLigeng ZhuRan TianShuhan TanYuxiao ChenYao LuYin CuiSushant VeerMax EhrlichJonah PhilionXinshuo WengFuzhao XueAndrew TaoMing-Yu LiuSanja FidlerBoris IvanovicTrevor DarrellJitendra MalikSong HanMarco Pavone",
        "links": "http://arxiv.org/abs/2407.18908v1",
        "entry_id": "http://arxiv.org/abs/2407.18908v1",
        "pdf_url": "http://arxiv.org/pdf/2407.18908v1",
        "summary": "We propose Wolf, a WOrLd summarization Framework for accurate video\ncaptioning. Wolf is an automated captioning framework that adopts a\nmixture-of-experts approach, leveraging complementary strengths of Vision\nLanguage Models (VLMs). By utilizing both image and video models, our framework\ncaptures different levels of information and summarizes them efficiently. Our\napproach can be applied to enhance video understanding, auto-labeling, and\ncaptioning. To evaluate caption quality, we introduce CapScore, an LLM-based\nmetric to assess the similarity and quality of generated captions compared to\nthe ground truth captions. We further build four human-annotated datasets in\nthree domains: autonomous driving, general scenes, and robotics, to facilitate\ncomprehensive comparisons. We show that Wolf achieves superior captioning\nperformance compared to state-of-the-art approaches from the research community\n(VILA1.5, CogAgent) and commercial solutions (Gemini-Pro-1.5, GPT-4V). For\ninstance, in comparison with GPT-4V, Wolf improves CapScore both quality-wise\nby 55.6% and similarity-wise by 77.4% on challenging driving videos. Finally,\nwe establish a benchmark for video captioning and introduce a leaderboard,\naiming to accelerate advancements in video understanding, captioning, and data\nalignment. Leaderboard: https://wolfv0.github.io/leaderboard.html.",
        "updated": "2024-07-26 17:59:09 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.18908v1"
    },
    {
        "title": "AppWorld: A Controllable World of Apps and People for Benchmarking Interactive Coding Agents",
        "authors": "Harsh TrivediTushar KhotMareike HartmannRuskin MankuVinty DongEdward LiShashank GuptaAshish SabharwalNiranjan Balasubramanian",
        "links": "http://arxiv.org/abs/2407.18901v1",
        "entry_id": "http://arxiv.org/abs/2407.18901v1",
        "pdf_url": "http://arxiv.org/pdf/2407.18901v1",
        "summary": "Autonomous agents that address day-to-day digital tasks (e.g., ordering\ngroceries for a household), must not only operate multiple apps (e.g., notes,\nmessaging, shopping app) via APIs, but also generate rich code with complex\ncontrol flow in an iterative manner based on their interaction with the\nenvironment. However, existing benchmarks for tool use are inadequate, as they\nonly cover tasks that require a simple sequence of API calls.\n  To remedy this gap, we built $\\textbf{AppWorld Engine}$, a high-quality\nexecution environment (60K lines of code) of 9 day-to-day apps operable via 457\nAPIs and populated with realistic digital activities simulating the lives of\n~100 fictitious users. We then created $\\textbf{AppWorld Benchmark}$ (40K lines\nof code), a suite of 750 natural, diverse, and challenging autonomous agent\ntasks requiring rich and interactive code generation. It supports robust\nprogrammatic evaluation with state-based unit tests, allowing for different\nways of completing a task while also checking for unexpected changes, i.e.,\ncollateral damage. The state-of-the-art LLM, GPT-4o, solves only ~49% of our\n'normal' tasks and ~30% of 'challenge' tasks, while other models solve at least\n16% fewer. This highlights the benchmark's difficulty and AppWorld's potential\nto push the frontiers of interactive coding agents. The project website is\navailable at https://appworld.dev/.",
        "updated": "2024-07-26 17:55:45 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.18901v1"
    },
    {
        "title": "Embedding And Clustering Your Data Can Improve Contrastive Pretraining",
        "authors": "Luke Merrick",
        "links": "http://arxiv.org/abs/2407.18887v1",
        "entry_id": "http://arxiv.org/abs/2407.18887v1",
        "pdf_url": "http://arxiv.org/pdf/2407.18887v1",
        "summary": "Recent studies of large-scale contrastive pretraining in the text embedding\ndomain show that using single-source minibatches, rather than mixed-source\nminibatches, can substantially improve overall model accuracy. In this work, we\nexplore extending training data stratification beyond source granularity by\nleveraging a pretrained text embedding model and the classic k-means clustering\nalgorithm to further split training data apart by the semantic clusters within\neach source. Experimentally, we observe a notable increase in NDCG@10 when\npretraining a BERT-based text embedding model on query-passage pairs from the\nMSMARCO passage retrieval dataset. Additionally, we conceptually connect our\nclustering approach to both the Topic Aware Sampling (TAS) aspect of the TAS-B\nmethodology and the nearest-neighbor-based hard-negative mining aspect of the\nANCE methodology and discuss how this unified view motivates future lines of\nresearch on the organization of contrastive pretraining data.",
        "updated": "2024-07-26 17:36:40 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.18887v1"
    },
    {
        "title": "Granularity is crucial when applying differential privacy to text: An investigation for neural machine translation",
        "authors": "Doan Nam Long VuTimour IgamberdievIvan Habernal",
        "links": "http://arxiv.org/abs/2407.18789v1",
        "entry_id": "http://arxiv.org/abs/2407.18789v1",
        "pdf_url": "http://arxiv.org/pdf/2407.18789v1",
        "summary": "Applying differential privacy (DP) by means of the DP-SGD algorithm to\nprotect individual data points during training is becoming increasingly popular\nin NLP. However, the choice of granularity at which DP is applied is often\nneglected. For example, neural machine translation (NMT) typically operates on\nthe sentence-level granularity. From the perspective of DP, this setup assumes\nthat each sentence belongs to a single person and any two sentences in the\ntraining dataset are independent. This assumption is however violated in many\nreal-world NMT datasets, e.g. those including dialogues. For proper application\nof DP we thus must shift from sentences to entire documents. In this paper, we\ninvestigate NMT at both the sentence and document levels, analyzing the\nprivacy/utility trade-off for both scenarios, and evaluating the risks of not\nusing the appropriate privacy granularity in terms of leaking personally\nidentifiable information (PII). Our findings indicate that the document-level\nNMT system is more resistant to membership inference attacks, emphasizing the\nsignificance of using the appropriate granularity when working with DP.",
        "updated": "2024-07-26 14:52:37 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.18789v1"
    },
    {
        "title": "The power of Prompts: Evaluating and Mitigating Gender Bias in MT with LLMs",
        "authors": "Aleix SantCarlos EscolanoAudrey MashFrancesca De Luca FornaciariMaite Melero",
        "links": "http://arxiv.org/abs/2407.18786v1",
        "entry_id": "http://arxiv.org/abs/2407.18786v1",
        "pdf_url": "http://arxiv.org/pdf/2407.18786v1",
        "summary": "This paper studies gender bias in machine translation through the lens of\nLarge Language Models (LLMs). Four widely-used test sets are employed to\nbenchmark various base LLMs, comparing their translation quality and gender\nbias against state-of-the-art Neural Machine Translation (NMT) models for\nEnglish to Catalan (En $\\rightarrow$ Ca) and English to Spanish (En\n$\\rightarrow$ Es) translation directions. Our findings reveal pervasive gender\nbias across all models, with base LLMs exhibiting a higher degree of bias\ncompared to NMT models. To combat this bias, we explore prompting engineering\ntechniques applied to an instruction-tuned LLM. We identify a prompt structure\nthat significantly reduces gender bias by up to 12% on the WinoMT evaluation\ndataset compared to more straightforward prompts. These results significantly\nreduce the gender bias accuracy gap between LLMs and traditional NMT systems.",
        "updated": "2024-07-26 14:47:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.18786v1"
    }
]