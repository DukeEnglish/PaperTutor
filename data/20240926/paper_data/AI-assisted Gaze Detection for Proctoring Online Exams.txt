AI-assisted Gaze Detection for Proctoring Online Exams
Yong-SiangShih1,ZachZhao1,ChenhaoNiu1,BruceIberg2,JamesSharpnack1,
MirzaBasimBaig1
Duolingo,Inc.
1{yongsiang,zach,chenhao,james.sharpnack,basim}@duolingo.com,2bruceiberg@duolingocontractors.com
Abstract
Forhigh-stakesonlineexams,itisimportanttodetectpoten-
tial rule violations to ensure the security of the test. In this
study, we investigate the task of detecting whether test tak-
ersarelookingawayfromthescreen,assuchbehaviorcould
beanindicationthatthetesttakerisconsultingexternalre-
Camera video of test taker Screen recording
sources. For asynchronous proctoring, the exam videos are
recorded and reviewed by the proctors. However, when the
length of the exam is long, it could be tedious for proctors
towatchentireexamvideostodeterminetheexactmoments
whentesttakerslookaway.WepresentanAI-assistedgaze
detectionsystem,whichallowsproctorstonavigatebetween Video player timeline
differentvideoframesanddiscovervideoframeswherethe
test taker is looking in similar directions. The system en- Gaze plot
ablesproctorstoworkmoreeffectivelytoidentifysuspicious
momentsinvideos.Anevaluationframeworkisproposedto
Figure1:Theuserinterfaceofthegazesystemallowsproc-
evaluatethesystemagainsthuman-onlyandML-onlyproc-
tors to navigate to different video frames using the video
toring,andauserstudyisconductedtogatherfeedbackfrom
player timeline. The points on the gaze plot represent the
proctors,aimingtodemonstratetheeffectivenessofthesys-
gaze direction of each frame. When proctors select regions
tem.
on the gaze plot, the corresponding frames on the time-
linewouldbehighlighted.Thegazedirectionofthecurrent
Introduction frameiscoloredinredinthegazeplot.
Theadoptionofonlineproctoringsystemshasgrowninre-
cent years (Nigam et al. 2021). Online tests offer greater
flexibilitybecausetesttakerscantakethetestremotelywith- resources.Therearetwochallengesproctorsfacewhenex-
outgoingtoaspecifictestcenter.However,theproblemof aminingsuchbehaviors.Firstly,whentheexamvideolength
cheating is a threat to the validity of the test results (Bilen islong,itcouldbetediousfortheproctorstowatchtheen-
andMatros2021).Therefore,securitymeasuresneedtobe tirevideotofindallmomentswherethetesttakerislooking
builttodetectandpreventcheatingbehaviors. away.Inaddition,aspointedoutbyBelzak,Lockwood,and
Onlineproctoringcomesinvariousforms,includinglive Attali (2024), a test taker could also naturally look at ar-
synchronous proctoring where the proctor watches the test bitrary spots as part of their cognitive processing. With the
taker remotely during the test session, and asynchronous limitedamountofinformationavailableintheexamvideos,
proctoring where video recordings of the test sessions are differentproctors’decisionscouldbelessconsistentforthis
recorded and reviewed by proctors. In this study, we focus taskcomparedtoothertaskssuchasdetectingplagiarism.
ontheapplicationofonlineproctoringintheDuolingoEn- In this study, we present an AI-assisted gaze detection
glish Test (DET) (Cardwell et al. 2024), which is an on- system,wherethe predicted gazedirectionofthetest taker
line,high-stakesEnglishassessmenttestwhereatesttaker’s ineachframeisshownonascatterplot.Theuserinterface
video is recorded with the test taker’s webcam. The test isshowninFigure1.Proctorscanselectregionsonthegaze
taker’svideo,thescreenrecording,theresponses,andother plot, and the related timestamps on the video player time-
relevantinformationarecollected,andproctorsrevieweach linewillbehighlighted.Thisallowsproctorstonavigateto
testsessionasynchronously. relevant video frames more efficiently, which improves the
Wefocusourstudyonthetaskofdetectingiftesttakers proctoring experience. In addition, because the system en-
arelookingawayfromthescreensuspiciously,assuchabe- ables a consistent view on the test taker’s gaze directions,
haviorcouldindicatethattesttakersareconsultingexternal thequalityoftheproctoringcouldalsobeimproved.
4202
peS
52
]IA.sc[
1v32961.9042:viXraFigure2:Eachframeofthetestsessionisshownasapoint
inthegazeplot,andthepositionofeachpointrepresentsthe
gazedirectionineachframe.Thecurrentframe’slocationis
coloredinred. (a)Thegazeplotwithaselectedregion.
We propose to evaluate our AI-assisted gaze detection
systemagainst(1)thehuman-onlysystem,and(2)theML-
onlysysteminanend-to-endfashion.Wechoosetoevaluate
theend-to-endperformancesothatwecouldcapturetheef- (b)Thevideoplayertimelinewithframeshighligted.
fectsofthebiasesthatarisewhenproctorsinteractwiththe
AI system (Cummings 2017; Selten, Robeer, and Grimme- Figure3:Thevideoplayertimelineallowsproctorstonav-
likhuijsen 2023; Bashkirova and Krpan 2024). Our frame- igatetospecificmomentsbyclickingonthedesiredtimes-
workallowsustoproperlydetermineiftheproposedsystem tamp.Timestampswheregazepredictionsfallwithinthese-
couldhaveapositiveimpactwhendeployedintoproduction. lected region of the gaze plot are highlighted in blue. The
space on top of the timeline can be used to show other no-
The remaining part of this paper is organized into four
tableevents.Thewhitebarbelowisusedtoselectaspecific
sections. Firstly, we describe how the proposed gaze de-
timeintervaltozoominto.
tection system works, including the user interface and how
proctors would interact with the system. Secondly, we de-
scribeourproposedevaluationframework,includingacon-
location,andselectaregionaroundit.Thesystemwillhigh-
crete definition of the task being evaluated. Thirdly, we
light all other relevant timestamps, allowing the proctor to
presenttheresultsofauserstudywhereweletproctorstry
navigate to those timestamps and confirm whether the test
outthesystem.Finally,weconcludethepaperwithadiscus-
taker is also exhibiting suspicious behaviors at those mo-
siononthelimitationsandfutureworksforourstudy.
ments.
SystemOverview
EvaluationFramework
Oursystemisdesignedforasynchronousproctoringofon- Toevaluatetheeffectivenessofthesysteminhuman-based
lineexams.Whenatesttakertakesatest,avideoisrecorded asynchronous proctoring, we apply the concept of human-
fortheentiretestsession,andoncethevideoisuploaded,a MLcomplementarity(Rastogietal.2023)todefinetheeval-
gazedetectionmodelcanberunoneachframeofthevideo uationgoalsandproposeourexperimentplans.
to predict the gaze direction in each frame. In practice, a
suitable frame rate would need to be selected for inference Human-MLComplementarity
accordingtotheresourceconstraints. Inahybriddecision-makingsystemlikeAI-assistedproctor-
Thegazedirectionpredictionswillbedisplayedtoproc- ing,human-MLcomplementarityistheconditionwherethe
torsasascatterplotasshowninFigure2.Inparticular,the hybrid system outperforms both humans and ML models.
gaze angles predicted by the model can be represented as FollowingthenotationusedbyRastogietal.(2023),denote
unitdirectionalvectorsoriginatingfromtheorigin,andthese X asthesetofallavailablefeaturesofagiventestsession,
vectorsareprojectedontothe2Dplane,witheachpointon includingvideorecording,responses,scores,etc.Denotethe
the plot representing a frame and its associated gaze direc- action space as A, where for a test session with T frames,
tion.Currently,ourgazeplotonlyrepresentsthegazedirec- a ∈ AisabinarysequencewithlengthT,anda indicates
t
tions(i.e.,theanglesofthegazes),andnottheexactlocation whetherthet-thframeislabeledpositive(i.e.lookingaway
onthescreenwherethetesttakerislookingat.However,a fromthescreen)ornot.Thenadecision-makingsystemfor
similarplotcanalsobeusedformodelsthatpredicttheexact labeling gaze direction in a test session can be written as a
screenlocation. mappingπ :X →A.DenoteΠasthesetofallpossibleπ.
Proctors can select regions on the eye gaze plot and In this work, there are three systems of interest: (1) the
the corresponding frames will be highlighted on the video human-onlysystemπ ,wherehumanproctorslabelthetest
H
player timeline. This allows proctors to navigate to frames sessionmainlybywatchingthevideo;(2)theML-onlysys-
with similar gaze directions within the selected region. For temπ ,wherebinarypredictionsaremadebythresholding
M
instance, if a proctor observes a suspicious moment when predictedgazedirectionsoneachframe;and(3)thehybrid
the test taker is looking away from the screen, the proctor systemπ ,wherehumanproctorslabelthetestsession
H+M
can consult the gaze plot to find the current video frame’s withadditionalaccesstopredictedgazedirections.Empirically, it is less likely that a π M is better than π H, Q1 4.09
as the gaze detection system only has access to a frame to Q2 3.73
makeeachprediction,whilehumanproctorshavemorecon- Q3 4.64
text from the whole test session than a frame. However, it Q4 4.36
Q5 4.18
is possible that π is a better system than π and π
H+M H M
throughhuman-MLcomplementarity.Thatis,withaneval- 1 2 3 4 5
uationfunctionF : Π → R,wewanttoverifyhuman-ML averagedscorefromthesurvey
complementarity:F(π )>max{F(π ),F(π )}.
H+M H M
Figure 4: Survey questions1: (Q1) I felt comfortable utiliz-
ProposedExperiments
ing the tool, (Q2) I felt confident that the tool was provid-
OnadatasetwithN testsessions,wedefinetheevaluation ingmewithcorrectinformation,(Q3)Ifeltthedocumenta-
functionF as: tion/videos provided allowed me to easily understand how
to use the tool, (Q4) I didn’t have difficulty interpreting or
N
F(π)= 1 (cid:88) s(X(i),π(X(i))) understandinganyvisualelementsofthetool,(Q5)Ifound
N iteasytoincorporatethetoolinmynormalproctoringpro-
i=1
cesses.
Where s : X ×A → R is a scoring function of a labeling
resultforagiventestsession,regardlessofwherethelabel-
ingresultcomesfrom.Withoutaccesstogroundtruthlabels,
Conclusion
weusealabelingprocesswithmultipleproctorstogenerate
high-precisionlabelstodefines.
This paper presents an AI-assisted gaze detection system,
Specifically,giventhei-thtestsession,a(i) = π (X(i)) whichenablesproctorstoworkeffectivelyinfindingthemo-
H H
is the labeling result from a proctor without using the gaze mentswhereatesttakerislookingawayfromthescreen.For
plot,a(i) =π (X(i))isthelabelingresultmadebythresh- the demo, we plan to show the gaze detection system on a
M M
olding the predicted gaze directions in each frame, and laptopwithanexampletestsession,andtheaudiencewould
a(i) =π (X(i))isthelabelingresultfromaproctor beabletoplaywiththesystemandgiveusfeedback.
H+M H+M
using the gaze plot. For the three binary vectors a(i), a(i),
H M Limitations
anda(i) ,wecollectallthepositiveintervals,andpresent
H+M
theintervalsforagroupofKproctorstolabel(withoutgaze We acknowledge that our system still has limitations, and
plot),andtakethemajorityopiniona∗(i)asthereferencefor future work will be needed to further improve the design.
comparison. Firstly, the gaze plot only shows the gaze directions of the
Notethatweensurehighprecisionfora∗(i)byusingmul- testtakers,itdoesn’tshowwhereonthescreenthetesttaker
tipleproctorstoreducevarianceandselectingonlypositive isactuallylookingat.Therefore,thegazeplotshouldnotdi-
intervals instead of the entire video to reduce tediousness. rectlybeusedalonetodetermineifthetesttakerislooking
However,thisalsomeansthatifanintervalislabeledasneg- away.WeexpecttheML-onlysystemtoperformpoorlybe-
ative by all three systems, it will not be labeled differently causecalibrationwillbeneededtodeterminetheexactrel-
inthisprocess. ative positional relationships between the screen, the cam-
Comparinga(i),a(i),anda(i) witha∗(i),wecancal- era, and the test taker. Secondly, our system currently only
H M H+M works in an asynchronous proctoring environment, where
culate the average precision and (upper-bounded) recall of
theexamvideoisrecorded.Ifsynchronousproctoringisre-
each system as F(π ), F(π ), and F(π ). Conduct-
H+M H M quired,real-timepredictionwouldbeneededandthepredic-
ingthisexperimentisthenextstepinthisproject.
tionsneedtobegraduallyaddedintothegazeplot.Finally,
our proposed evaluation is still based on proctor decisions,
UserStudy
andthereforeislimitedbytheinformationthatcouldbede-
Wealsoconductedauserstudy,wherewerecruited11DET rivedfromtherecordedinformation.Tofurtherimprovethe
proctorstotryouttheAI-assistedgazedetectionsystemon accuracy of the evaluation, we could have test takers tak-
300testsessionssampledfromDET.Theproctoringresults ingtheexamsinacontrolledenvironmentwherethecamera
werenotusedfortheofficialcertification,butwecollected andthescreenarecarefullycalibrated.Thiswillallowusto
thefeedbackfromtheproctorsregardingthegazedetection gatheraccuratemeasurementsfortesttakers’eyegazes.
systemwithasurveyform.
Thesurveyisbasedonascaleof1-5,where1represents
Acknowledgments
“absolutely disagree” and 5 represents “absolutely agree”.
Here we show the survey questions and the final averaged
We thank the colleagues who had tested the system, pro-
scores in Figure 4. Positive responses were received in the
videdfeedback,reviewedthecode,orreviewedthepaper.
userstudy.
1Questionsthatarerelatedtothedetailsoftheinternalproctor- reversedtomaketheinterpretationofthescoresmoreconsistent.
ingprocessareomitted,andtheexpressionofQ4anditsscorewere TheoriginalQ4askedifproctorshaddifficulty.References
Bashkirova, A.; and Krpan, D. 2024. Confirmation bias
inAI-assisteddecision-making:AItriagerecommendations
congruentwithexpertjudgmentsincreasepsychologisttrust
andrecommendationacceptance. ComputersinHumanBe-
havior:ArtificialHumans,2(1):100066.
Belzak, W.; Lockwood, J.; and Attali, Y. 2024. Measuring
VariabilityinProctorDecisionMakingonHigh-StakesAs-
sessments:ImprovingTestSecurityintheDigitalAge. Ed-
ucationalMeasurement:IssuesandPractice,43(1):52–65.
Bilen, E.; and Matros, A. 2021. Online cheating amid
COVID-19.JournalofEconomicBehavior&Organization,
182:196–211.
Cardwell, R.; Naismith, B.; LaFlair, G. T.; and Ny-
dick, S. 2024. Duolingo english test: technical manual.
https://go.duolingo.com/dettechnicalmanual.
Cummings,M.L.2017. Automationbiasinintelligenttime
criticaldecisionsupportsystems.InDecisionmakinginavi-
ation,289–294.Routledge.
Nigam, A.; Pasricha, R.; Singh, T.; and Churi, P. 2021. A
systematic review on AI-based proctoring systems: Past,
present and future. Education and Information Technolo-
gies,26(5):6421–6445.
Rastogi,C.;Leqi,L.;Holstein,K.;andHeidari,H.2023. A
TaxonomyofHumanandMLStrengthsinDecision-Making
toInvestigateHuman-MLComplementarity.InProceedings
oftheAAAIConferenceonHumanComputationandCrowd-
sourcing,volume11,127–139.
Selten,F.;Robeer,M.;andGrimmelikhuijsen,S.2023.‘Just
likeIthought’:Street-levelbureaucratstrustAIrecommen-
dationsiftheyconfirmtheirprofessionaljudgment. Public
AdministrationReview,83(2):263–278.