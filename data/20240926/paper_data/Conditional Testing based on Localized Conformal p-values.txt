Conditional Testing based on Localized
Conformal p-values
Xiaoyang Wu∗, Lin Lu∗, Zhaojun Wang, and Changliang Zou†
School of Statistics and Data Sciences, LPMC, KLMDASR and LEBPS,
Nankai University, Tianjin, China
Abstract
In this paper, we address conditional testing problems through the conformal in-
ference framework. We define the localized conformal p-values by inverting prediction
intervals and prove their theoretical properties. These defined p-values are then ap-
plied to several conditional testing problems to illustrate their practicality. Firstly, we
propose a conditional outlier detection procedure to test for outliers in the conditional
distribution with finite-sample false discovery rate (FDR) control. We also introduce
a novel conditional label screening problem with the goal of screening multivariate re-
sponse variables and propose a screening procedure to control the family-wise error
rate (FWER). Finally, we consider the two-sample conditional distribution test and
define a weighted U-statistic through the aggregation of localized p-values. Numerical
simulations and real-data examples validate the superior performance of our proposed
strategies.
Keywords: Conditional testing; Conformal inference; False discovery rate; Family-wise error
rate; U-statistic.
*The first two authors equally contributed to this work.
†Corresponding author: nk.chlzou@gmail.com.
1
4202
peS
52
]EM.tats[
1v92861.9042:viXra1 Introduction
Nowadays, conformal inference has become an increasingly popular framework for quanti-
fying uncertainty of machine learning models. Suppose we have i.i.d. training data D =
1
{(X ,Y )}n and test data D = {(X ,Y )}m , where test responses {Y }m are unob-
1i 1i i=1 2 2j 2j j=1 2j j=1
served. The goal is to construct prediction intervals PI(X ) for X ∈ D with marginal
2j 2j 2
coverage guarantee
Pr(Y ∈ PI(X )) ≥ 1−α. (1)
2j 2j
By sample splitting or cross-fitting, conformal prediction methods (Vovk et al., 2005) can
be coupled with any machine learning algorithm to construct distribution-free prediction
intervals with finite-sample coverage guarantee. However, the marginal coverage (1) alone is
not sufficient for an efficient prediction interval. A marginally valid prediction interval could
have a miscoverage rate much higher than α in some subgroups of the data. Therefore, the
conditional coverage is also an important aspect:
Pr(Y ∈ PI(X ) | X = x) ≥ 1−α. (2)
2j 2j 2j
Although appealing, achieving (2) in a finite-sample and distribution-free context is im-
possible (Vovk, 2013). Recent works have proposed many methods to construct prediction
intervals with approximate or asymptotic conditional coverage guarantee by either modifying
the calibration step (Lei and Wasserman, 2013; Guan, 2023) or using different score functions
(Romano et al., 2019; Chernozhukov et al., 2021).
In addition to prediction intervals, the conformal inference framework is also valuable
for other inference problems. With a similar calibration procedure, the conformal p-value
is defined to address various testing problems. This includes classical two-sample tests (Hu
and Lei, 2023) and multiple testing problems such as outlier detection (Bates et al., 2023;
Zhang et al., 2022) and data selection/sampling (Jin and Cand`es, 2023b; Wu et al., 2023).
Therefore, asaparalleldevelopment, ourpapermovesbeyondconditionalpredictionintervals
and defines conformal p-values tailored for conditional testing problems.
We define localized conformal p-values by leveraging recent works Guan (2023) and Hore
2and Barber (2023) which constructed prediction intervals to adapt to the conditional distri-
bution of the response. We present some fundamental properties of our defined p-values and
demonstrate why they can effectively resolve these problems. More importantly, we also con-
sider several non-trivial applications of localized conformal p-values, encompassing various
testing problems with different error criteria (e.g., FDR, FWER or type I error). We show
that the proposed testing rule can ensure valid corresponding error rate control. Here we
provide a brief overview of those problems and defer rigorous formulations to later sections.
• Conditional outlier detection: Outlyingness in data sets may come from various
forms of heterogeneity. One of the important cases is that a few individuals in the
test data do not share the same regression functions with majority (Peng et al., 2023).
This amounts to detecting outliers in the functional relationship between the response
and covariates that can be represented by the conditional distribution of Y | X. This
is common in many spatial or temporal contexts where the scale or variance of the
response variable varies with location or time (Catterson et al., 2010).
• Two-sample conditional distribution test: The goal is to test for equality of
conditional distributions of Y | X between two samples (Hu and Lei, 2023). This is also
known as the problem of comparison of regression curves (Dette and Neumeyer, 2003).
Some contemporary applications include assessing casuality by testing whether the
conditional distribution of the response given the covariates remains the same between
two samples (Bu¨hlmann, 2020) and testing whether the pre-trained model can still
perform well on a new test sample (Farahani et al., 2021).
• Conditional label screening: Consider a scenario where the response Y is multi-
variate. Our goal is to determine whether each component of the response satisfies
a pre-specified rule for an unlabeled data point. For example, in the LLM factuality
problem (Mohri and Hashimoto, 2024; Cherian et al., 2024) we have a vector of claims
output by a LLM. It is desirable to screen out false claims to ensure reliability. In this
example, the conditional performance of the screening procedure is important, which
needs to be addressed properly to avoid extreme or imbalanced results.
31.1 Our contributions
In this article, building on Hore and Barber (2023)’s randomly localized conformal prediction
interval, we construct localized conformal p-values, study their theoretical properties, and
apply them to several conditional testing problems. Our contributions to the applications
are as follows:
• For the conditional outlier detection problem, we propose a detection procedure by
utilizing the Benjamini-Hochberg (BH) procedure (Benjamini and Hochberg, 1995) and
conditional calibration technique (Fithian and Lei, 2022). Our procedure controls the
FDR in finite-sample.
• We elaborate a novel conditional label screening problem with rigorous formulation.
We use the localized conformal p-value to construct a screening procedure with finite-
sample marginal FWER control. We also present a conditional FWER inflation bound
of our procedure to demonstrate its robustness against conditionality.
• We propose a U-statistic for the two-sample conditional distribution testing problem
by aggregating the localized conformal p-values. The asymptotic normality of the test
statistic under null and local alternatives is established.
We also validate our methods through simulations and real-data experiments. With com-
monly used prediction algorithms, our proposed methods exhibit superiority in terms of both
validity and power compared to existing approaches.
1.2 Related works
Conformal inference was originally designed to construct prediction intervals and enjoy valid
and distribution-free properties with the only assumption that the data are exchangeable.
There have been several extensions to this framework. For example, Tibshirani et al. (2019)
proposed weighted conformal prediction for covariate shift settings, and Romano et al. (2019)
introducedconformalizedquantileregressiontoaccountforheteroscedasticity. Otherapplica-
tions of the conformal inference framework include causal inference (Lei and Cand`es, 2021),
4selective inference (Bao et al., 2024), and survival analysis (Cand`es et al., 2023), among
others.
Besides conformal inference, we also briefly review recent literature about our application
problems.
• Outlier detection. Classical outlier detection methods include multivariate outlier
detection methods that use model assumptions to identify outliers (Riani et al., 2009;
Cerioli, 2010), and machine learning algorithms (Liu et al., 2008; Erfani et al., 2016).
Most existing works on conditional outlier detection fall into these two categories (Song
et al., 2007; Catterson et al., 2010; Hong and Hauskrecht, 2015). Recent studies have
used the conformal inference framework to test for outliers with advanced machine
learningmodels(Batesetal.,2023;Marandonetal.,2024;Liangetal.,2024). Although
thesemethodsensurefinite-sampleFDRcontrol, theyfocusprimarilyonmarginalcases
and do not address outlier detection in conditional distributions.
• Two-sample conditional distribution test. Most existing works focus on testing
the equality of two conditional moments (Hall and Hart, 1990; Dette and Neumeyer,
2003), which is less stringent than testing for equality of distributions. A notable
contribution is Hu and Lei (2023), which proposed a U-statistic based on the conformal
inference framework by aggregating conformal p-values. Chen and Lei (2024) improved
this method by de-biasing the functions estimated using machine learning algorithms.
Our porposed test statistic, a kernel-weighted U-statistic, is closely related to Hu and
Lei (2023) by aggregating localized conformal p-values instead.
• Data selection and subsampling. Our introduced label screening problem is similar
to label-based data selection (Jin and Cand`es, 2023a,b; Rava et al., 2021) and subsam-
pling problems (Wu et al., 2023). These works consider a semi-supervised setting where
the selection or sampling rule is based on the value of the response variable. The key
difference in our problem is that we focus on screening within the multivariate response
vectorforeachdatapoint, ratherthanselectingdifferentdatapointsfromtheunlabeled
dataset. Additionally, existing works do not account for the conditional properties of
5their methods, which is the main concern of our paper.
1.3 Organization and notations
The remainder of this paper is organized as follows. We briefly review conformal inference
and then give the definitions and theoretical properties of the localized conformal p-value in
Section 2. In Section 3, we apply the proposed p-values to several conditional testing prob-
lems. Simulation and real-data experiments results for all three applications are displayed in
Section 4 and Section 5. Finally, we conclude the article in Section 6 with some remarks.
Notations. The I{·} is the indicator function and ∥·∥ ,∥·∥ are the L - and L -norm.
2 ∞ 2 ∞
The [n] denotes the set {1,2,...,n}. The δ denotes the point mass at value z. The notation
z
Q(α;P) denotes the α-th quantile of distribution P. The subscripts of E and Pr indicate
distributions of random variables in the expectations and probabilities.
2 Localized conformal p-values
In this section, we first revisit the definition of the split conformal prediction and its localized
extensions by Guan (2023) and Hore and Barber (2023) in Section 2.1. Then we propose the
localized conformal p-values by inverting the localized prediction intervals in Section 2.2. At
last we discuss basic properties of the defined p-values in Section 2.3.
2.1 Recap: conformal prediction and localization
We consider data pair (X,Y) ∈ X × Y. Suppose we have D = {(X ,Y )}n ∼ P =
1 1i 1i i=1 1
P ×P andD = {(X ,Y )}m witheachdatapoint(X ,Y ) ∼ P = P ×P .
1,X 1,Y|X 2 2j 2j j=1 2j 2j 2,j 2,X 2,j,Y|X
In different problems, the responses Y of the second sample can be observed or unobserved.
2j
In the classical split conformal prediction, D is divided into the training and calibration
1
sets D = D ∪ D with index sets T ∪ C = {1,2,...,n}. The training set D is used to
1 T C T
train a prediction function µ(X) for the response Y and construct a non-conformity function
(cid:98)
V(X,Y) which measures the similarity between the prediction and the true response. We
then apply the score function to the calibration set D to compute calibration scores {V }
C 1i i∈C
6and obtain the quantile threshold
(cid:32) (cid:33)
1 (cid:88) 1
q = Q 1−α; δ + δ . (3)
(cid:98)α
|C|+1
V1i
|C|+1
∞
i∈C
The split conformal prediction interval is defined as PI(X ) = {y : V(X ,y) ≤ q }. If D ∪
2j 2j (cid:98)α 1
{(X ,Y )} are exchangeable, the prediction interval PI(X ) is finite-sample valid in the
2j 2j 2j
sense that Pr(Y ∈ PI(X )) ≥ 1−α.
2j 2j
However, calibrating marginally with (3) does not account for the local information of
the test point. Guan (2023) proposed the localized conformal prediction by calibrating with
the quantile of a weighted empirical distribution
(cid:32) (cid:33)
(cid:88)
q∗ = Q 1−α; H∗(X ,X )δ +H∗(X ,X )δ ,
(cid:98)α (cid:98),L (cid:98) 1i 2j V1i 2j 2j ∞
i∈C
where H∗(x,x′) = H(x,x′) for some kernel function H(·,·) characterizing
(cid:80) k∈CH(X 1k,X2j)+H(X2j,X2j)
the similarity between its two arguments. Here α is the adjusted level to guarantee finite-
(cid:98)
sample coverage. Despite its efficiency, the LCP method needs to compute the adjusted level
α, which is complex and computationally inefficient. As an improvement, Hore and Barber
(cid:98)
(2023) proposed a randomization technique to circumvent level adjustment. Their method
˜
first samples X from the distribution H(X ,·), takes the threshold as
2j 2j
(cid:32) (cid:33)
(cid:88)
q = Q 1−α;
H˜∗(X ,X˜
)δ
+H˜∗(X ,X˜
)δ ,
(cid:98)α,L 1i 2j V1i 2j 2j ∞
i∈C
and define the prediction interval as
PI (X ) = {y : V(X ,y) ≤ q }, (4)
L 2j 2j (cid:98)α,L
where
H˜∗(x,x′)
=
H(x,x′)
. If {(X ,Y )} ∪ D are exchangeable, we can
(cid:80) k∈CH(X 1k,X˜ 2j)+H(X2j,X˜ 2j) 2j 2j 1
7˜
compute the density ratio of X and X conditional on X as
2j 1i 2j
dP 2,X|X˜ 2j(x) = f 2,X(x)H(x,X˜ 2j) = H(x,X˜ ),
2j
dP f (x)
1,X 1,X
which exactly matches the weights in the empirical distribution. By the weighted exchange-
ability in Tibshirani et al. (2019), the randomly localized conformal prediction interval is
finite-sample valid in the sense that
(cid:110) (cid:16) (cid:17)(cid:111)
Pr(Y ∈ PI (X )) = E Pr V(X ,Y ) ≤ q | X˜ ≥ 1−α.
2j L 2j 2j 2j (cid:98)α,L 2j
2.2 From prediction intervals to p-values
Motivated by the capability of (randomly) localized conformal prediction to capture local
information, we invert these prediction intervals to construct the localized conformal p-value.
Duetoitssimplicity, wefollowHoreandBarber(2023)andtaketherandomizationtechnique
as in (4).
Let H(x,x′) be a bi-variate kernel function with bandwidth h
1
(cid:18) x−x′(cid:19)
H(x,x′) = K ,
hd h
where K(·) is a kernel density function. Here K(·) can be taken as the Gaussian kernel, the
box kernel or any other nonparametric kernel function as long as it is a symmetric density
function. Define the localized conformal p-value for (X ,Y ) ∈ D as
2j 2j 2
(cid:80) H(X ,X˜ )I{V ≤ V }+ξ ·H(X ,X˜ )
p = i∈C 1i 2j 2j 1i j 2j 2j , (5)
L,j (cid:80) ˜ ˜
H(X ,X )+H(X ,X )
i∈C 1i 2j 2j 2j
˜
where ξ ∼ U[0,1] is an independent random variable and X is randomly sampled from
j 2j
density H(X ,·). The non-conformity score V may depend on both X and Y or only on
2j
X, contingent on the specific problem. The p can be viewed as a localized counterpart
L,j
of the conformal p-value investigated by Bates et al. (2023) by using weighted empirical
distributions. To simplify terminology, we will use CP and LCP to refer to the unweighted
8conformal p-value and our localized conformal p-value, respectively in the rest of the article.
Since we do not discuss prediction intervals, this should not lead to confusion.
2.3 Basic properties
In this section we state some basic properties of the localized conformal p-value. The first
property is its finite-sample validity.
Theorem 1. Under the condition P = P , the localized conformal p-value satisfies
1 2,j
Pr(p ≤ α) ≤ α, 0 ≤ α ≤ 1.
L,j
Furthermore, if the score V(X,Y) has a continuous distribution, then
Pr(p ≤ α) = α, 0 ≤ α ≤ 1.
L,j
This theorem is a direct corollary of the weighted exchangeability of {(X ,Y )}∪C given
2j 2j
˜
X . By leveraging this property, the LCP can be used for multiple testing to guarantee
2j
finite-sample FDR or FWER control.
By the nature of the local-weighting scheme, the LCP can adapt to potential covariate
shifts. The following theorem is an analog of the robustness result in Hore and Barber (2023).
Theorem 2. Under the condition P = P , denote the covariate density ratio as
1,Y|X 2,j,Y|X
g(x) :=
dP2,X(x).
The LCP satisfies
dP1,X
Pr(p ≤ α) ≤ α+∥f ∥ E {|g(X+hU)−g(X)|},
L,j 1,X ∞ X∼PH,X,U∼K(·)
where the distribution P has a density function f (x) = E {H(X,x)}.
H,X H,X X∼P1,X
ThistheoremgivesadeviationboundofthedistributionofLCPfromuniformdistribution
under covariate shift. The excess term will be small with a small h when the density ratio
function g satisfies some regularity conditions. For example, if g is Lipchitz continuous, the
excess term will vanish as h → 0. If we otherwise take g as the normalized indicator of some
9fixed B ⊂ X, the excess term will also vanish, indicating the LCP is approximately valid
conditional on any fixed subset B.
As an indirect power characterization, the next theorem studies the point-wise limit of
the LCP function which is defined as
(cid:80) H(X ,X˜ )I{v ≤ V }+ξ ·H(x,X˜ )
p (x,y) = i∈C 1i 1i ,
L (cid:80) ˜ ˜
H(X ,X)+H(x,X)
i∈C 1i
˜
where v = V(x,y) and X is sampled from H(x,·). With a score function V chosen properly
based on the specific problem, a larger score value v will indicate stronger evidence against
the pre-specified null hypothesis. Our defined p-value therefore reflects evidence against the
null contained in a single data point. For the p-value to be powerful, the value of p (X,Y)
L
should be small if (X,Y) is sampled under the alternative. Therefore, for a fixed score value
v under the alternative, we can regard a p-value function to be asymptotically more powerful
than another if its limit function takes smaller value at v.
We need some regularity conditions which are commonly used in nonparametric estima-
tions.
Assumption 1. The following conditions hold for (X,Y) ∼ P :
1
• V(X,Y) has a continuous distribution with bounded density;
• The conditional distribution of the score V = V(X,Y) satisfies
∥F (v)−F (v)∥ ≤ L·∥x−x′∥β
V|X=x V|X=x′ ∞ 2
for some constant L > 0,0 < β ≤ 1. That is, the conditional distribution function
F varies smoothly with x.
V|X=x
• The density function f (x) is continuous, and the conditional density function f (y |
1,X 1
x) is continuous in x.
Theorem 3. Assume Assumption 1 holds and the split ratio |C|/|D | = γ for some constant
1
10γ > 0, then the LCP function converges in probability
(cid:32)(cid:114) (cid:33)
1
|p (x,y)−(1−F (v))| = O h2β +
L V|X=x p nhd
for any fixed (x,y), as h → 0,nhd → ∞.
By the weak law of large number, the unweighted CP function satisfies
(cid:80) I{v ≤ V }+1
p (x,y) = i∈C 1i →p 1−F (v),
CP V
|C|+1
where F (·) is the marginal distribution function of score V. If we take h such that h →
V
0,nhd → ∞, the LCP function converges to 1 − F (v) in probability. Comparing the
V|X=x
powerthenamountstocomparingthevalueof1−F (v)and1−F(v). Forascorevaluev
V|X=x
under the alternative, our conditional testing problem can generally ensure a uniformly small
value of 1−F (v) since the signal lies in the deviation of the conditional distribution. In
V|X=x
contrast, the value of 1−F (v) could be quite large for (x,y) pairs with a small conditional
V
scale V | X = x, even if these pairs are sampled under the alternative. Although not
uniformly more powerful, the LCP can identify signals in these regions of X with a small
conditional scale V | X = x, which tends to be missed by the CP. This property further
motivates us to apply the LCP on conditional testing problems.
Remark 1. The deviation bound in Theorem 3 has two terms corresponding to the bias and
variance of p-value functions. This is different from Theorem 2 in which we only need h → 0
to eliminate bias and ensure validity. Fixing the sample size n and taking h → 0, the LCP
will degenerate to the independent uniform random variable ξ, which remains valid but does
not contain any information of the data. Otherwise if we take h → ∞ it will degenerate to
the unweighted CP. Therefore, the bandwidth h controls the trade-off between the conditional
validity of the LCP and the effective sample size.
113 Applications on conditional testing
In this section, we apply the LCP on several conditional testing problems. We first provide
a straightforward application on sample selection problem in Section 3.1. Then in Section
3.2 we study the conditional outlier detection problem and adopt the conditional calibration
technique to achieve finite-sample FDR control. In Section 3.3 we introduce a novel condi-
tional label screening problem and leverage the LCP to design a screening procedure with
FWER control. Finally, we propose a two-sample U-statistic by aggregating the simplified
LCP for the two-sample conditional distribution test in Section 3.4.
3.1 Warm-up: balanced data selection
Consider the sample selection problem which was investigated by Jin and Cand`es (2023b)
and Wu et al. (2023). The test sample D = {X }m is unlabeled. The goal is to select test
2 2j j=1
samples satisfying a pre-specified rule Y ∈ A. Therefore, whether to select the jth sample
amounts to conducting the following hypothesis test:
H : Y ∈/ A, versus H : Y ∈ A.
0j 2j 1j 2j
In this case, the CP can be accordingly defined as
(cid:80) I{V ≤ V }+ξ
p =
i∈C,Y1i∈/A 2j 1i j
,
j
|{i ∈ C : Y ∈/ A}|+1
1i
and if p ≤ α we select X . Such methods directly controls the per selection error rate
j 2j
(PSER), say
Pr(X selected | Y ∈/ A) ≤ α.
2j 2j
Analogously, we can apply our proposed localized conformal p-value instead to achieve
certain improvement in terms of conditional performance. The LCP is defined as
(cid:80) H(X ,X˜ )I{V ≤ V }+ξ ·H(X ,X˜ )
p =
i∈C,Y1i∈/A 1i 2j 2j 1i j 2j 2j
,
rL,j (cid:80) ˜ ˜
H(X ,X )+H(X ,X )
i∈C,Y1i∈/A 1i 2j 2j 2j
12where V is a non-conformity score function depending on A. We use δ = 1,0 to indicate
j
selecting X or not, where δ = I{p ≤ α}. As a corollary of Theorems 1-2, the following
2j j rL,j
theorem provides the marginal and conditional properties of this simple selection rule.
Theorem 4. Suppose {(X ,Y )}n and {(X ,Y )}m are exchangeable, the selection rule
1i 1i i=1 1i 1i j=1
δ = I{p ≤ α} can ensure finite-sample marginal PSER control Pr(δ = 1 | Y ∈/ A) ≤ α.
j rL,j j 2j
Moreover, the conditional PSER inflation bound is given by
Pr (∥U∥ ≥ h−1d(X,∂B))
Pr(δ = 1 | Y ∈/ A,X ∈ B) ≤ α+2∥f ∥
X∼PH,X,A,U∼K(·) 2
,
j 2j 2j 1,X,A ∞
Pr(X ∈ B | Y ∈/ A)
2j 2j
where f is the conditional density of X | Y ∈/ A, P has a density function
1,X,A 1i 1i H,X,A
f (x) = E {H(X,x)} and ∂B is the boundary set of B.
H,X,A X∼f1,X,A
The second result is obtained by taking the function g(x) = I{x ∈ B}/Pr(X ∈ B)
2j
in Theorem 2 and simplifying the deviation term. For general sets B of regular form (e.g.,
balls or hypercubes), the excess term will be small with a small h. This indicates that using
the LCP for data selection can lead to a more balanced selection result since the PSER
inflation for different sub-groups is bounded. For instance, by choosing an appropriate B,
we can expect that the burden of incorrect selection probability (PSER) will be more evenly
distributed among different genders and races via our LCP. Similar issue is also considered
by Rava et al. (2021) from the perspective of fairness.
3.2 Conditional outlier detection
In the conditional outlier detection problem, the available data consists of clean data D
1
and test data D with potential outliers. Both samples are labeled with observed responses.
2
The inliers in D have the same conditional distribution P = P with D while the
2 2,j,Y|X 1,Y|X 1
outliers may have different conditional distributions from each other. Detecting conditional
outliers can be formulated as the following multiple testing problem:
H : P = P for almost all x, versus H : otherwise, (6)
0j 2,j,Y|X=x 1,Y|X=x 1j
13where (X ,Y ) ∈ D is an inlier if H holds and outlier if H holds. Our goal is to
2j 2j 2 0j 1j
determine the detection set (or the rejection set equivalently) R ⊆ {1,2,...,m} based on
the observed data D and D . Denote I,O ⊆ {1,2,...,m} as the index sets of inliers
1 2
and outliers. The rejection set R should contain as many indices in O as possible while
guaranteeing finite-sample false discovery rate (FDR) control
(cid:18) (cid:19)
|I ∩R|
FDR = E(FDP) = E ≤ α.
|R|∨1
Bates et al. (2023) utilized the conformal p-value to test for marginal outliers by applying the
BH procedure on conformal p-values computed on the test data. However, this is generally
not effective when testing for conditional outliers. As discussed in the previous section, the
classical CP targets on the joint distribution of (X,Y) rather than Y | X, and thus cannot
identify all information in the conditional distribution of score variables. In light of the
capability of the LCP to capture deviations in conditional distributions, we can take it as a
refinement to detect conditional outliers.
As proved by Bates et al. (2023), the unweighted conformal p-values based on the same
calibration set is PRDS, under which the BH procedure can still guarantee finite-sample FDR
control. This property, however, does not hold for the weighted conformal p-values. In order
to achieve the finite-sample property, we adopt the conditional calibration technique (Fithian
and Lei, 2022) to prune the rejection set output by the BH procedure.
ToperformmultipletestingwiththeLCP,wefirsttrainthenon-conformityscorefunction
V(x,y) on D and then compute scores {V } and {V }m on D and D , respectively.
T 1i i∈C 2j j=1 C 2
After sampling X˜ for each X , the LCP’s {p }m are computed as in Eq. (5). Define
2j 2j L,j j=1
the auxiliary p-values as
(cid:80) H(X ,X˜ )I{V ≤ V }+ξ ·H(X ,X˜ )I{V ≤ V }
p(l) = i∈C 1i 2j 2j 1i j 2j 2j 2j 2l . (7)
L,j (cid:80) ˜ ˜
H(X ,X )+H(X ,X )
i∈C 1i 2j 2j 2j
for l ∈ {1,2,...,m} \ {j}. Let R(cid:98) be the rejection set of the BH procedure applied
j→0
on {p(j),...,p(j) ,0,p(j) ,...,p(j) } and Rinit = {j : p ≤ α|R(cid:98) |/m} be the initial
L,1 L,j−1 L,j+1 L,m L,j j→0
rejection set. We determine the final rejection set by generating independent ζ ,...,ζ ∼
1 m
14U[0,1] and pruning Rinit into
(cid:40) (cid:41)
α|R(cid:98) |
R = j : p ≤ j→0 ,ζ |R(cid:98) | ≤ r∗ , (8)
L,j j j→0
m
(cid:110) (cid:110) (cid:111) (cid:111)
where r∗ = max r : (cid:80)m I p ≤ α|R(cid:98) |/m,ζ |R(cid:98) | ≤ r ≥ r .
j=1 L,j j→0 j j→0
The outlier detection procedure is summarized in Algorithm 1.
Algorithm 1 Conditional Outliers Detection via the LCP
Input: Clean data D = {(X ,Y )}n and test data D = {(X ,Y )}m ; FDR target
1 1i 1i i=1 2 2j 2j j=1
level α ∈ (0,1); Kernel function H(·,·)
1: Randomly split D into D ∪D , train the non-conformity score function V(x,y) on D
1 T C T
and compute score values {V } and {V }m on D and D
1i i∈C 2j j=1 C 2
- Outlier detection -
2: for j = 1,...,m do
˜
3: Sample X from density H(X ,·), sample ξ ∼ U[0,1] and construct the LCP p as
2j 2j j L,j
in (5)
4: Compute auxiliary p-values p(ℓ) as in (7)
L,j
(cid:110) (cid:111)
5: (BH procedure) Compute r∗ = max r : 1+(cid:80) I{p(ℓ) ≤ αr/m} ≥ r
j ℓ̸=j L,j
6: Compute R(cid:98) = {j}∪{ℓ ̸= j: p(ℓ) ≤ αr∗/m}
j→0 L,j j
7: end for
8: Compute the first-step rejection set Rinit = {j : p ≤ α|R(cid:98) |/m}
L,j j→0
9: Prune the initial set Rinit and obtain the final rejection set R as in (8)
Output: Detected conditional outlier set R
The following theorems shows that our detection procedure can guarantee finite-sample
FDR control if the distribution of the covariates does not change.
Theorem 5 (Finite-sample FDR control). Under the condition that P = P , the final
1,X 2,X
output R given by Algorithm 1 ensures FDR ≤ α.
Remark 2. Testing for conditional outliers may not be restricted to the regression setting.
Consider the case where only the covariate X is available. By splitting the covariate vector
X into X = (X(1),X(2)), one can compute weights with respect to X(1) and test for outliers
regarding the conditional distribution X(2) | X(1). This approach is applicable in various
spatial or temporal settings where X(1) can be taken as the location or time variable.
153.3 Conditional label screening
In the conditional label screening problem, the response variable is multivariate with Y =
(Y ,Y ,...,Y ) for some random variable S. The first sample D is the labeled data while the
1 2 S 1
second sample D is unlabeled. The response vectors are denoted as Y = (Y ,...,Y )
2 ℓi ℓi,1 ℓi,S
ℓi
for ℓ = 1,2. Our goal is to determine whether each component of the unobserved response
Y = (Y ,...,Y ) satisfies a pre-specified rule for each X ∈ D . For each entry s, we
2j 2j,1 2j,S2j 2j 2
define the screening rule as Y ∈ A with pre-chosen sets A . This can be formulated as a
2j,s s s
multiple testing problem for each test sample
H : Y ∈/ A , versus H : Y ∈ A , 1 ≤ s ≤ S . (9)
0j,s 2j,s s 1j,s 2j,s s 2j
For example, Mohri and Hashimoto (2024); Cherian et al. (2024) considered using confor-
mal prediction techniques to improve the output factuality of large language models (LLM).
Specifically, they transform the output of the LLM into a set of claims and aim to construct
a filtered claim set that contains no false claims with high probability. Such application
can be framed into our conditional label screening problem stated above. The covariate X
2j
includes the input prompt P , the output R of the LLM model and a claim vector C of
2j 2j 2j
length S summarized by another language model. The response vector is a 0-1 vector with
2j
Y = 1 or 0 indicating whether the corresponding claim is correct or not. Here we can take
2j,s
A = {1} for every 1 ≤ s ≤ S to screen out false claims.
s 2j
To ensure reliability of the screening procedure, we seek to control the probability of
failing to screen out any component of Y that does not meet the rule. Let δ = 1 or 0
2j j,s
indicate whether Y is retained after screening. This can be rigorously formulated as
2j,s
 
S2j
(cid:88)
Pr I{Y
2j,s
∈/ A s,δ
j,s
= 1} > 0 ≤ α, (10)
s=1
say, controlling the FWER for (9). However, the marginal FWER might not be sufficient in
real problems. We can use the localization technique to improved conditional validity while
still guaranteeing marginal FWER control.
16Since the test data D is unlabeled in the current problem, the non-conformity score
2
function V should depend only on the covariate X. We can use the training data D to
T
estimatetheprobabilityPr(Y ∈ A ). Thiscanbeachievedbytrainingclassificationmodels
2j,s s
for each component of Y if the length S is a fixed constant or fitting a joint classification
model that outputs a probability vector. In both scenarios, we can define the score vector
V(X ) = (V ,V ,...,V )⊤,
2j 2j,1 2j,2 2j,S2j
where each V approximates Pr(Y ∈ A ). By this definition, we should reject H if
2j,s 2j,s s 0j,s
V is large, and controlling the FWER amounts to examining the distribution of max{V :
2j,s 2j,s
Y ∈/ A }. This motivates us to define the localized p-value
2j,s s
(cid:80) H(X ,X˜ )I{V ≤ V¯ }+ξ ·H(X ,X˜ )
p = i∈C 1i 2j 2j,s 1i j 2j 2j , (11)
L,j,s (cid:80) ˜ ˜
H(X ,X )+H(X ,X )
i∈C 1i 2j 2j 2j
¯
where V = max{V : Y ∈/ A }. We can show that the p ’s satisfy the group super-
1i 1i,s 1i,s s L,j,s
uniform property, i.e.,
 
(cid:91)
Pr {p
L,j,s
≤ α} ≤ α,
Y2j,s∈/As
and thus we can screen out components of Y with p ≤ α, We summarize our label
2j L,j,s
screening procedure in Algorithm 2.
We have the following result.
Theorem 6. Suppose {(X ,Y ,S )} ∪ {(X ,Y ,S )}m are exchangeable, then the
1i 1i 1i i∈C 2j 2j 2j j=1
label screening procedure given by Algorithm 2 ensures finite-sample FWER control
 
S2j
(cid:88)
FWER = Pr I{Y
2j,s
∈/ A s,p
L,j,s
≤ α} > 0 ≤ α.
s=1
Regarding the conditional property, we can also establish the finite-sample conditional
FWER deviation bound for our procedure.
Theorem 7. Suppose the assumptions in Theorem 6 hold. For any fixed set B ⊂ X with
17Algorithm 2 Conditional Label Screening via the LCP
Input: Labeled data D = {(X ,Y )}n and test data D = {X }m ; FWER target level
1 1i 1i i=1 2 2j j=1
α ∈ (0,1); Kernel function H(·,·)
1: Randomly split D into D ∪D and train the non-conformity score function, compute
1 T C
score vectors {V(X )} , {V(X )}m on D , D and summary scores {V¯ }
1i i∈C 2j j=1 C 2 1i i∈C
- Screening -
2: for j = 1,...,m do
˜
3: Sample X from density H(X ,·) and ξ ∼ U[0,1]
2j 2j j
4: for s = 1,...,S do
2j
5: Construct the LCP p as in (11)
L,j,s
6: Determine the screening decision δ = I{p ≤ α}
j,s L,j,s
7: end for
8: end for
Output: Screening decision vectors δ = (δ ,...,δ )⊤ for each 1 ≤ j ≤ m
j j,1 j,s
Pr(X ∈ B) > 0, the conditional FWER has the following bound
2j
 
(cid:88)S2j
(cid:12)
Pr I{Y
2j,s
∈/ A s,p
L,j,s
≤ α} > 0 (cid:12)
(cid:12)
X
2j
∈ B
s=1
Pr (∥U∥ ≥ h−1d(X,∂B))
≤ α+2∥f ∥
X∼PH,X,U∼K(·) 2
,
1,X ∞
Pr(X ∈ B)
2j
where ∂B is the boundary of set B.
In this theorem, the inflation bound is similar to that in the second result of Theorem 4.
By a similar rationale, this demonstrate the advantage of our method to mitigate conditional
error rate inflation.
3.4 Two-sample conditional distribution test
In the two-sample conditional testing problem, the second sample D is labeled and i.i.d.
2
following a potentially different distribution (X ,Y ) ∼ P ×P from the first sample
2j 2j 2,X 2,Y|X
D . The conditional distribution test can be formulated as
1
H : P = P for almost all x, versus H : otherwise. (12)
0 1,Y|X=x 2,Y|X=x 1
18Hu and Lei (2023) proposed a two-sample conditional distribution test based on the
conformalinferenceframework. Tobespecific, theyfirstsplitbothsamplesasD = D ∪D
1 T1 C1
and D = D ∪D with |D | = |D | = n ,|D | = |D | = n . For notation convenience,
2 T2 C2 C1 C2 1 T1 T2 2
we perform an equal-sized sample splitting with n = n and let C = C = {1,...,n } in
1 2 1 2 1
this section. Thereafter, the score function and density ratio estimator
(cid:92) (cid:92)
f (y | x) f (x)
1 2,X
V(x,y) = , g(x) =
(cid:98)
f (y | x) f (x)
2 1,X
are trained on D ∪ D by fitting classification models to distinguish D and D . After
T1 T2 T1 T2
computing scores {V } and {V } , the weighted conformal p-values are obtained as
1i i∈C1 2j j∈C2
n−1(cid:80) g(X )D(cid:98)∗
p = 1 i∈C1 (cid:98) 1i ij , j ∈ C .
(cid:98)j n−1(cid:80)
g(X )
2
1 i∈C1 (cid:98) 1i
The test statistic is constructed by averaging these p-values
1 − 1 (cid:80) p
T(cid:98) = 2 n1 j∈C2 (cid:98)j ,
σ
(cid:98)
where D(cid:98)∗ = I{V < V }+ξ I{V = V } and σ2 is the variance estimator. Under the null
ij 2j 1i j 2j 1i (cid:98)
√
hypothesis, they proved that n T(cid:98) is asymptotically normally distributed and the rejection
1
√
region is given by n T(cid:98) > Φ−1(1−α).
1
We extend the above strategy by aggregating the localized conformal p-values computed
on the second sample. Since p-values are no longer necessary to be finite-sample valid in this
case,hereweuseasimplifiedvariantofthelocalizedconformalp-valuewithoutrandomization
(cid:80) H(X ,X )I{V ≤ V }+ξ ·H(X ,X )
p = i∈C 1i 2j 2j 1i j 2j 2j , (13)
SL,j (cid:80)
H(X ,X )+H(X ,X )
i∈C 1i 2j 2j 2j
and our proposed test statistic is defined as
1 (cid:80)n1 1 (cid:80)n1 H(X ,X )D(cid:98)
T(cid:98) = n1 i=1 n1 j=1 1i 2j ij , (14)
w
σ
(cid:98)w
where D(cid:98) = 1/2 − I{V < V } − ξ I{V = V } and σ2 is the variance estimator. This
ij 2j 1i j 2j 1i (cid:98)w
19test statistic is constructed by averaging unnormalized LCP’s in Eq. (13) and performing
standardization. From a different perspective, it is also related to the classical U-statistic
for model checking problems (Zheng, 1996; Gao and Gijbels, 2008) in which the D(cid:98) ’s are
ij
replaced by the residuals. Inherited from the nice property of conformal techniques, our
method enjoys model-agnostic features and allows us to employ state-of-the-art algorithms
to construct efficient score function V that is able to better measure the discrepancy between
two conditional distributions.
We need the following technical assumptions to establish the asymptotic normality of T(cid:98) .
w
We also make the same regularity assumptions to those in Hu and Lei (2023) without further
declaration in theorems, which guarantee identifiability of the problem.
Assumption 2. Let V∗(x,y) = f (y|x)/f (y|x) be the true conditional density ratio. Denote
2 1
the oracle statistics as V∗ = V∗(X ,Y ),V∗ = V∗(X ,Y ) and D = 1/2 − I{V∗ <
1i 1i 1i 2j 2j 2j ij 1i
V∗}−ξ I{V∗ = V∗}. Suppose that
2j j 1i 2j
• V∗ has a continuous distribution;
2j
√
• E{H(X ,X )(D(cid:98) −D )} = o (1/ n ).
1i 2j ij ij p 1
Recall that we use classification to construct the score function V(x,y) to approximate
the true conditional density ratio V∗(x,y) in this problem. This assumption requires the
approximation error is sufficiently small after local-weighting. A similar assumption has been
made in Hu and Lei (2023) with H(X ,X ) replaced by g(X ). These two assumptions are
1i 2j (cid:98) 1i
introduced both to ensure a vanishing asymptotic bias and achieve asymptotic normality in
the presence of covariate shift.
Theorem 8 (Asymptotic normality). Under the null hypothesis, suppose Assumption 1 holds
for P ,P and h → 0,n hd → ∞. Further assume P = P or Assumption 2 holds. Then
1 2 1 1,X 2,X
the test statistic (14) is asymptotically normally distributed
1 (cid:80)n1 1 (cid:80)n1 H(X ,X )D(cid:98)
T(cid:98) = n1 i=1 n1 j=1 1i 2j ij →d Z ∼ N(0,1),
w
σ
(cid:98)w
20where the variance estimator is given by
1
(cid:88)n1
(cid:40)
1
(cid:88)n1
(cid:41)2
1
(cid:88)n1
(cid:40)
1
(cid:88)n1
(cid:41)2
σ2 = H(X ,X )D(cid:98) + H(X ,X )D(cid:98)
(cid:98)w n2 n 1i 2j ij n2 n 1i 2j ij
1 i=1 1 j=1 1 j=1 1 i=1
1
(cid:88)n1 (cid:88)n1
2
(cid:40)
1
(cid:88)n1 (cid:88)n1
(cid:41)2
− H(X ,X )2D(cid:98)2 − H(X ,X )D(cid:98) .
n4 1i 2j ij n n2 1i 2j ij
1 i=1 j=1 1 1 i=1 j=1
Note that the convergence of the score function is only needed under covariate shift
settings. Given the asymptotic normality property, we can construct our testing procedure
as summarized in Algorithm 3.
Algorithm 3 Two-sample conditional distribution test via aggregation of simplified LCP’s
Input: Two samples D and D ; density ratio estimation subroutines A ,A , kernel density
1 2 1 2
H(·,·), the nominal type I error level α ∈ (0,1)
1: Randomly split the two samples as D = D ∪D and D = D ∪D
1 T1 C1 2 T2 C2
2: g(·) = A [{X ,i ∈ T ,X ,j ∈ T }]
(cid:98) 1 1i 1 2j 2
3: v(·,·) = A [{(X ,Y ),i ∈ T ,(X ,Y ),j ∈ T }]
2 1i 1i 1 2j 2j 2
4: for j ∈ C do
2
5: Sample ξ ∼ U[0,1], independently
j
6: Calculate D(cid:98) = 1/2−I{V < V }−ξ I{V = V }
ij 1i 2j j 1i 2j
7: Calculate the kernel weights H(X ,X ),i ∈ C
1i 2j 1
8: end for
9: Calculate the variance estimator σ2 and obtain the weighted statistic T(cid:98) as in (14)
(cid:98)ω ω
10: Reject H if Φ(T(cid:98) ) ≥ 1−α
0 ω
Output: The decision for two-sample conditional distribution test
Theorem 9 (Behavior under local alternatives). Suppose Assumption 1 holds for P ,P ,
1 2
Assumption 2 holds, and n σ2 →p σ2 > 0.Then we have
1(cid:98)w w
√
n δ
1 w
T(cid:98) = (1+o (1))+Z +o (1),
w p p
4σ
w
where δ = E {f (X)|V∗(X,Y)−V∗(X,Y′)|} and Z ∼ N(0,1).
w X∼P2,X,Y,Y′∼P
2,Y|X
1,X
This theorem is similar to Proposition 1 in Hu and Lei (2023). The main difference lies
in the form of “signal strength” δ , which is δ = E {|V∗(X,Y)−V∗(X′,Y′)|}
w (X,Y),(X′,Y′)∼P2
in their article. In comparison, the difference term in δ is based on the same covariate
w
21value and therefore better captures the deviation in conditional distribution. This reflects
the superiority of our proposed test statistic in the two-sample conditional testing problem.
4 Simulation experiments
In this section, we provide extensive synthetic experiment results to show the validity and
efficiency of our proposed methods for three main applications in Sections 4.1-4.3, respec-
tively.
4.1 Results for conditional outlier detection
For the conditional outlier detection problem, we consider two scenarios:
• Scenario A1 (with label Y): Aheterogeneouslinearregressionmodel. Thecovariate
vector consists of X = (X ,...,X )⊤ ∈ Rd−1 with d = 10 and an additional time
1 d−1
feature t ∈ R. The model is
Y = Xβ +(3+2·sin(2π ·t))·ε,
with X ,...,X ∼ U[−1,1],t ∼ U[0,1] and ε ∼ N(0,1) independently. The coef-
1 d−1
ficient vector is β = (0.5,−0.5,0.5,−0.5,0.5,0,0,0,0). The test data contains 10%
outliers following the model
Y = Xβ +(3+2·sin(2π ·t))·ε+r(t)·ξ,
where r(t) = 3·(3+1.5sin(2π ·t)) and Pr(ξ = ±1) = 1/2.
• Scenario B1 (without label Y): Another example which does not include the label
Y. To fit our problem, we consider a spatial setting with X = (s,X∗) where s is the
spatial variable and X∗ contains the remaining features. We consider X ∈ Rd with
22s = (s ,s ) ∈ R2 and X∗ ∈ Rd−2 with d = 50:
1 2
X∗ | s ∼ N(0,r(s)·I ), r(s) = 0.2+0.9∥s∥2
d−2 2
where s ,s ∼ U[−1,1] independently. The test data contains 10% outliers with the
1 2
same distribution for s and a different conditional distribution
X∗ | s ∼ N(0,4·r(s)·I ).
d−2
Benchmarks. We abbreviate our method as LCP-od (outlier detection) and compare it
with a benchmark method abbreviated as CP. The CP method is implemented by computing
the unweighted conformal p-values as defined in Bates et al. (2023) and then applying the BH
procedure. For the LCP-od and CP methods, we use two score functions and apply various
regression or classification algorithms, which are detailed in the implementation part.
Implementation details. Since our goal is to test for outliers conditional on t or s
in Scenarios A1 and B1, we only use these variables when computing the weights. For
both scenarios, the kernel function of the LCP-od method is taken as the Gaussian kernel
H(x,x′) = (2πh2)−d/2exp{−∥x−x′∥2/(2h2)} with bandwidth h = (n/2)−1/(d+2) for d = 1,2
2
in Scenarios A1 and B1. This corresponds to the optimal convergence rate for β = 1. For
Scenario A1, we consider two kinds of score functions: the CQR score and the absolute
residual of different regression algorithms. Similar to Romano et al. (2019), for the CQR
score, we consider using quantile neural networks (CQR-QNN) and quantile random forests
(CQR-QRF). For the absolute residual score, we take two regression algorithms: random
forest (Res-RF), and support vector machine (Res-SVM). For Scenario B1, we use one-
class classifiers for both the LCP-od and CP methods. We take three kinds of one-class
classification algorithms: the isolation forest (IOF), k-Nearest-Neighbor (k-NN) with k = 5
and one-class support vector machine (one-class SVM).
Results. For each scenario, we consider either fixing α = 0.1 or 0.15,m = 2000 and
varying n ∈ {800,1600,2400,3200,4000} or fixing the sample size n = m = 2000 and varying
α ∈ {0.05,0.1,0.15,0.2}. The results for Scenario A1 are shown in Figure 1-2, and the results
23for Scenario B1 are shown in Figure 3-4. In both scenarios, the LCP-od method accurately
controls the FDR around the nominal level, which validates its finite-sample FDR control
property. In terms of power, the LCP-od method demonstrates higher power than the CP
benchmark in Scenario A1 with both two score functions when the sample size n and the
nominal level α are relatively large. Compared with the absolute residual score, the CQR
score leads to relatively higher power due to its adaptivity to the conditional distribution
Y | X. However, the power gain is still significant after applying the LCP-od method,
illustrating the advantage of local weighting.
In Scenario B1, the power of the LCP-od method grows significantly with the sample
size n and the nominal level α, while the power of the CP method only rises slightly. As
discussed in the main text, the unweighted CP cannot identify those outliers with small
conditional variance of the score. This explains why the power of the CP method remains
“stuck” around the same value. In contrast, the power of the LCP-od method approaches 1
as the sample size increases, demonstrating the full identifiability of the LCP-od method in
testing for conditional outliers.
CQR−QNN CQR−QRF Res−RF Res−SVM
0.8
0.6
0.4
0.2
0.0
0.8
0.6
0.4
0.2
0.0
800 1600240032004000 800 1600240032004000 800 1600240032004000 800 1600240032004000
n
Method LCP−od CP
Figure 1: FDP above the nominal level and power under different sample sizes n for Scenario
A1. The test sample size is fixed at m = 2000 and the nominal level is fixed at α = 0.15.
24
FDP
above
nominal
PowerCQR−QNN CQR−QRF Res−RF Res−SVM
0.8
0.6
0.4
0.2
0.0
0.8
0.6
0.4
0.2
0.0
0.05 0.1 0.15 0.2 0.05 0.1 0.15 0.2 0.05 0.1 0.15 0.2 0.05 0.1 0.15 0.2
a
Method LCP−od CP
Figure 2: FDP above the nominal level and power under different nominal levels α for
Scenario A1. The sample sizes are fixed at n = m = 2000.
IOF KNN one−class SVM
1.00
0.75
0.50
0.25
0.00
1.00
0.75
0.50
0.25
0.00
800 1600 2400 3200 4000 800 1600 2400 3200 4000 800 1600 2400 3200 4000
n
Method LCP−od CP
Figure 3: FDP above the nominal level and power under different sample sizes n for Scenario
B1. The test sample size is fixed at m = 2000 and the nominal level is fixed at α = 0.1.
4.2 Results for conditional label screening
For the conditional label screening problem, we consider a nonlinear regression model:
• Scenario A2 (nonlinear regression): We take a constant S = 2 and the response
25
FDP
above
nominal
Power
FDP
above
nominal
PowerIOF KNN one−class SVM
1.00
0.75
0.50
0.25
0.00
1.00
0.75
0.50
0.25
0.00
0.05 0.1 0.15 0.2 0.05 0.1 0.15 0.2 0.05 0.1 0.15 0.2
a
Method LCP−od CP
Figure 4: FDP above the nominal level and power under different nominal levels α for
Scenario B1. The sample sizes are fixed at n = m = 2000.
Y = (Y ,Y ) with Y = −2X + 7X2 + 3exp(X + 2X2) + ε, Y = −6X + 5X2 +
1 2 1 1 2 3 4 2 1 2
3exp(2X + X2) + ε, X ∼ U[−1,1]4 and ε ∼ N(0,1). The screening target is Y ∈
3 4 s
A = [a ,+∞) where a is the 70% quantile of Y for s = 1,2, respectively.
s s s s
Implementation details. We fix the sample sizes n = 500,m = 2000 and vary α ∈
{0.05,0.1,0.15,0.2}. We apply three different algorithms to train a probability prediction
function for each component of Y: linear logistic regression (LL), neural network (NN) and
random forest (RF).
Benchmarks. We compare our conditional label screening method via the LCP (abbre-
viated as LCP-ls) as summarised in Algorithm 2 with the thresholding procedure without
weighting (abbreviated as THR). The THR method is performed by only replacing the LCP
by the classical unweighted CP.
Results. We calculate the empirical marginal FWER and four kinds of conditional
FWER’s (conditional on X ∈ B for four different sets B). The evaluation measures are
defined as follows:
(cid:16) (cid:17)
• (Marginal FWER): mFWER = Pr (cid:80)S2j I{Y ∈/ A ,δ = 1} > 0
j s=1 2j,s s j,s
26
FDP
above
nominal
Power(cid:16) (cid:17)
• (Conditional FWER): cFWER = Pr (cid:80)S2j I{Y ∈/ A ,δ = 1} > 0 | X ∈ B for
ij s=1 2j,s s j,s i
i ∈ {1,2,3,4} and j ∈ {1,...,m}, where B = {X ∈ Rd : X < 0 and X < 0},
1 1 3
B = {X ∈ Rd : X > 0 and X < 0}, B = {X ∈ Rd : X < 0 and X > 0}, and
2 1 3 3 1 3
B = {X ∈ Rd : X > 0 and X > 0}.
4 1 3
cFWER1 above nominal cFWER2 above nominal cFWER3 above nominal cFWER4 above nominal mFWER above nominal
0.3
0.2
0.1
0.0
0.3
0.2
0.1
0.0
0.3
0.2
0.1
0.0
0.05 0.1 0.15 0.2 0.05 0.1 0.15 0.2 0.05 0.1 0.15 0.2 0.05 0.1 0.15 0.2 0.05 0.1 0.15 0.2
a
Method LCP−ls THR
Figure 5: Conditional FWER (cFWER) and marginal FWER (mFWER) above α with
different nominal levels α for Scenario A2. The sample sizes are fixed at n = 500,m = 2000.
The results for Scenario A2 are reported in Figure 5. As theoretically ensured, both
methods control the marginal FWER at nominal levels. However, the LCP-ls is much more
robust against conditionality and exhibit a much smaller conditional FWER inflation than
the THR method on subsets B and B . Accordingly, while the FWER conditional on B
3 4 2
of both the THR and LCP-ls methods approach 0 as the nominal level α increases, the
conditional error rate of the LCP-ls method remains much closer to the nominal level. This
also suggests that the LCP-ls method offers a more balanced screening result.
27
LL
NN
RF4.3 Results for two-sample conditional distribution test
We consider three different scenarios for the problem of two-sample conditional distribution
test, which are analogous to those in Hu and Lei (2023):
Scenario A3: Let Y = α + X⊤β + ε ,i = 1,...,n and Y = α + X⊤β + ε ,j =
1i 1 1i 1i 2j 2 2j 2j
1,...,m, where X i ∼id N(0,I ),X i ∼id N(µ,I ) with µ = (1,1,−1,−1,0)⊤ and ε ,ε i ∼id
1i d 2j d 1i 2j
N(0,1) independently. We set α = α = 0 under the null and α = 0,α = 0.5 under the
1 2 1 2
alternative.
Scenario B3: LetY = α +β X +β X +β X2 +β X2 +β X3 +ε ,i = 1,...,n
1i 1 1 1i,1 2 1i,2 3 1i,3 4 1i,4 5 1i,5 1i
and Y = α + β X + β X + β X2 + β X2 + β X3 + ε ,j = 1,...,m, where
2j 2j 1 2j,1 2 2j,2 3 2j,3 4 2j,4 5 2j,5 2j
X i ∼id 0.5N(0,I ) + 0.5N(µ,I ) with µ = (0.5,0.5,−0.5,−0.5,0)T, X i ∼id 0.5N(0,I ) +
1i d d 2i d
iid
0.5N(0,1.5I ) and ε ,ε ∼ t(5) independently. We set α = α = 0 under the null and
d 1i 2j 1 2
α = 0,α = 0.8×(1−0.1·∥X ∥2) under the alternative.
1 2j 2i 2
Scenario C3: Let Y = θ(X )+ϵ ,i = 1,...,n and Y = θ(X )+ϵ ,j = 1,...,m,
1i 1i 1i 2j 2j 2j
where θ(X) = E(y | x) is an additive function of B-splines, and X i ∼id 0.5N(0,I ) +
1i d
0.5N(µ,I ) with µ = (0.5,0.5,−0.5,−0.5,0)T, X i ∼id 0.5N(0,I ) + 0.5N(0,1.5I ) and
d 2i d d
we set ε i ∼id N(0,4/(1 + X2(1))) under the null and ε i ∼id N(0,4/(1 + X2(1))), ε i ∼id
ℓi ℓi 1i 1i 2i
N(0,1.5/(1+X2(1))) under the alternative.
2i
Implementation details. Under each scenario, we fix d = 5 and consider different
sample sizes n = m ∈ {200,400,600,800,1000} with equal splitting. The coefficient β
in model A and B are taken as β = (1,1,1,−1,−1)⊤. For our localized conformal test
(LCT) method, we take the Gaussian kernel function and choose the same bandwidth h =
(n/2)−1/(d+2). For all three scenarios, we use three different probabilistic classification models
to estimate density ratios: linear logistic (LL), random forest (RF) and neural network (NN).
The type I error (size) under the null and the power under the alternative are calculated for
each scenario across 500 replications with nominal type I error level α = 0.05.
Benchmarks. We compare our localized conformal test (LCT) as summarised in Algo-
rithm 3 with the following two tests:
• CT: Hu and Lei (2023)’s conformal test as described in Section 3.4.
28• DCT: Chen and Lei (2024)’s de-biased conformal test, where they formulate the covari-
ate shift problem within the nonparametric framework and utilize the doubly-robust
technique to correct the bias of the test statistic.
Results. The results for all three scenarios are summarised in Figure 6. Regarding
type I error, the CT method is only valid when the training model is correctly specified and
exhibits a severely inflated type I error rate under mis-specified models. The DCT method
is more robust than the CT method and controls the type I error rate under the nominal
level for most scenarios and training models. This corresponds to its doubly-robust property,
which relaxes the requirement on accuracy of the estimated density ratios. In contrast,
the LCT method controls the type I error rate accurately around the nominal level for any
combinationofscenarioandtrainingmodel. Thisshowstherobustnessandwideapplicability
of our proposed test statistic.
In terms of power, the CT method is not valid with misspecified training models, so we
only discuss the DCT and LCT methods. In Scenarios A3 and B3, the LCT method exhibits
higher power than the DCT method especially when the sample size is large. In Scenario C3,
the LCT method is more powerful than the DCT method using the NN algorithm and the
two methods perform similarly when using the LL or RF algorithm. In general, the power
improvement is more significant when the classification algorithm can distinguish the two
populations better. Except for the numerical performance, the DCT method involves not
only data splitting but also a cross-fitting step. The LCT test does not require the latter and
is therefore much easier to implement and computationally more efficient.
5 Real data examples
5.1 Conditional outlier detection on spatial data
Dataset. We use the House Sales in the King County, USA dataset (Kaggle, 2016) to
demonstrate the performance of our method in a spatial scenario with label Y. The dataset
contains n = 21613 observations with 21 attributes including two spatial features: longitude
(s ) and latitude (s ). The response Y is the price of houses.
1 2
29LL NN RF
1.00
0.75
0.50
0.25
0.00
1.00
0.75
0.50
0.25
0.00
200 400 600 800 1000 200 400 600 800 1000 200 400 600 800 1000
n
LL NN RF
1.00
0.75
0.50
0.25
0.00
1.00
0.75
0.50
0.25
0.00
200 400 600 800 1000 200 400 600 800 1000 200 400 600 800 1000
n
LL NN RF
1.00
0.75
0.50
0.25
0.00
1.00
0.75
0.50
0.25
0.00
200 400 600 800 1000 200 400 600 800 1000 200 400 600 800 1000
n
Method LCT CT DCT
Figure 6: Type I error (size) under H and power under H of three methods under Scenario
0 1
A3-C3 across different sample sizes n = m ∈ {200,400,600,800,1000}. The red dashed lines
mark the nominal level α = 0.05 and the shading represents error bars of one standard error
above and below.
30
3A
oiranecS
3B
oiranecS
3C
oiranecS
Type
I
error
Power
Type
I
error
Power
Type
I
error
PowerImplementation details. We randomly sample three parts of the data from the whole
dataset: n = 2,000 training data, n = 2,000 calibration data and n = 3,000 test data.
tr cal te
Since the original dataset contains no conditional outliers, we create synthetic outliers and
apply different methods for detection. We randomly sample 10% of the testing data to be
outliers. For the outliers, we add a random noise ε to the original response Y . We consider
i i
two kinds of synthetic outliers.
• Conditional quantile-based outlier:
˜
Y = Y +ε , ε = 0.75·Quantile (Y | s )·ξ,
i i i i 0.9 2
where Quantile (Y | s ) is the 90% conditional quantile of Y given s and Pr(ξ =
0.9 2 2
±1) = 1/2.
• Conditional variance-based outlier:
˜ (cid:112)
Y = Y +ε , ε = 2· Var(Y | s )·ξ,
i i i i 2
where Var(Y | s ) is the conditional variance of Y given s and Pr(ξ = 2) = Pr(ξ =
2 2
−1) = 1/2.
All results are based on 500 replications.
Results. We compare the LCP-od and the CP methods with the CQR score constructed
by two different algorithms: quantile random forest (QRF) and quantile neural network
(QNN). The empirical FDR and power for conditional outlier detection are reported in Table
1-2. The result is similar to the simulation part, where all methods control the FDR below
the nominal. While the advantage is not as significant as before, the LCP-od method still
enjoys the highest power in all cases.
5.2 Conditional label screening on health data
Dataset. We use the health indicators dataset from Kaggle (Kaggle, 2021) to illustrate the
performance of our conditional label screening method. The dataset comprises n = 70,692
31Table 1: Empirical FDR and power for the House Sales dataset with quantile-based outliers. Bold
numbers represent the best results. The brackets contain the standard errors.
Method LCP-od CP
α
Score CQR-QNN CQR-QRF CQR-QNN CQR-QRF
FDR 0.139 (0.087) 0.131 (0.030) 0.128 (0.047) 0.145 (0.036)
0.15
Power 0.657 (0.096) 0.871 (0.048) 0.593 (0.037) 0.858 (0.070)
FDR 0.177 (0.033) 0.175 (0.030) 0.174 (0.049) 0.175 (0.037)
0.2
Power 0.882 (0.131) 0.913 (0.021) 0.824 (0.078) 0.907 (0.022)
Table 2: Empirical FDR and power for the House Sales dataset with variance-based outliers. Bold
numbers represent the best results. The brackets contain the standard errors.
Method LCP-od CP
α
Score CQR-QNN CQR-QRF CQR-QNN CQR-QRF
FDR 0.141 (0.051) 0.127 (0.029) 0.142 (0.043) 0.128 (0.035)
0.15
Power 0.520 (0.168) 0.628 (0.092) 0.480 (0.085) 0.581 (0.119)
FDR 0.181 (0.036) 0.176 (0.038) 0.196 (0.034) 0.186 (0.030)
0.2
Power 0.630 (0.084) 0.722 (0.056) 0.597 (0.099) 0.692 (0.106)
samples and 22 variables, including demographic attributes (e.g., sex, age, BMI), lifestyle-
related features, as well as several binary health indicators. These indicators capture whether
an individual has conditions such as diabetes, coronary heart disease, or has experienced a
myocardial infarction, among others. Accordingly, we define the response variable Y as these
disease-related binary labels, with the goal of predicting the risk of these conditions in test
data. More specifically, the response vector Y = (Y ,Y ,Y ) ∈ {0,1}3 is set as follows:
1 2 3
• Y : Indicates whether an individual has diabetes.
1
• Y : Indicateswhetheranindividualhascoronaryheartdiseaseormyocardialinfarction.
2
• Y : Indicates whether an individual has experienced a stroke.
3
Consequently, the label screening targets are Y ∈ A = {1} for s = 1,2,3.
s s
Implementation details. We fix the size of the labeled data D at n = 500 and
1
the test data D at m = 2,000, randomly sampling them from the original dataset without
2
replacement in each replication. We fix the nominal level at α = 0.05, and apply two different
algorithms to compute the score vectors: linear logistic regression (LL) and random forest
32(RF). We calculate the empirical marginal FWER and conditional FWER (conditional on
X ∈ B for a specific set B) across 500 replications for the screening procedure via LCP-ls and
the simple thresholding rule, respectively. The evaluation measures are defined as follows:
(cid:16) (cid:17)
• (Marginal FWER): mFWER = Pr (cid:80)S2j I{Y ∈/ A ,δ = 1} > 0
j s=1 2j,s s j,s
(cid:16) (cid:17)
• (Conditional FWER): cFWER = Pr (cid:80)S2j I{Y ∈/ A ,δ = 1} > 0 | X ∈ B for
ij s=1 2j,s s j,s
j ∈ {1,...,m}, where B = {X ∈ Rd : sex = female and BMI > 30}.
Results. We show the average of measures for all m test samples. The results are
reported in Table 3. We observe that both benchmarks can ensure valid marginal FWER
control, while only the label screening procedure via the LCP-ls is capable of controlling both
conditional and marginal FWER simultaneously.
Table 3: Empirical conditional FWER (cFWER) and marginal FWER (mFWER) with nominal
level α = 0.05 for the health indicator dataset. The brackets contain the standard errors.
Method cFWER cFWER mFWER mFWER
LL RF LL RF
LCP-ls 0.0329 (0.018) 0.0372 (0.018) 0.0487 (0.009) 0.0507 (0.009)
THR 0.0740 (0.028) 0.0887 (0.029) 0.0500 (0.011) 0.0538 (0.012)
5.3 Two-sample conditional distribution test on the airfoil data
Dataset. Refer to previous related works (Hu and Lei, 2023; Chen and Lei, 2024), we
consider using the airfoil dataset (Brooks et al., 2014) from the UCI Machine Learning
Repository to demonstrate the effectiveness of our proposed LCT on real data. This dataset
investigates the sound pressure of various airfoils with n = 1503 observations of the response
Y: thescaledsoundpressureandthecovariatesXwithd = 5dimensions: logfrequency,angle
of attack, chord length, free-stream velocity, and suction side log displacement thickness.
Implementation details. We use part of the rules in Hu and Lei (2023) to split the
observations into two samples as follows:
(i) Random partition. Randomly partition the dataset into two groups with sizes |D | =
1
751 and |D | = 752.
2
33˜
(ii) Exponential tilting. First randomly partition the data into D ,D . Then construct D
1 2 2
˜
by sampling 25% of the points from D with replacement, with probabilities propor-
2
tional to ω(x) = exp(xTα), where α = (−1,0,0,0,1).
(iii) Partition along the response. Split the data according to the value of response, where
the first group contains the samples with smaller response values.
In the first two partitions, the two samples satisfy the null hypothesis. The first partition has
samples from the same distribution, while the second shows a non-trivial covariate shift. In
thelastpartition,thecovariateshiftassumptionisnotsatisfiedandthealternativehypothesis
holds. For all three cases, we use the linear logistic (LL) and neural network (NN) to estimate
the density ratios. All results are based on 500 replications.
Results. Similar to Hu and Lei (2023), we use out-of-sample marginal classification error
as a proxy of the accuracy of marginal density ratio estimation for all cases. The percentage
of rejections for cases (i-ii) are summarised in Table 4. The rejection proportions of both
the LCT and DCT methods are close to the nominal level when using LL or NN algorithms,
while the CT test fails to control the type I error when using the NN algorithm due to its low
accuracy. For case (iii), we only have a single deterministic generation of the training and
test data for each replication. We therefore report the median p-values for case (iii) in Table
5. While all three tests correctly reject the null, the LCT test gives the smallest p-value and
is therefore the most powerful among all three tests.
Table 4: Percentage of rejections (PR) and average classification error of g (Err) in cases (i–ii) with
(cid:98)
nominal level α = 0.05. The brackets contain the standard errors.
Cases Method PR PR Err Err
LL NN LL NN
LCT 0.054 (0.0325) 0.053 (0.0374)
Case (i) CT 0.058 (0.0289) 0.441 (0.0610) 0.429 0.608
DCT 0.053 (0.0299) 0.066 (0.0268)
LCT 0.067 (0.0323) 0.066 (0.0390)
Case (ii) CT 0.056 (0.0320) 0.135 (0.0405) 0.213 0.367
DCT 0.056 (0.0327) 0.035 (0.0250)
34Table 5: Medianp-values(Pval)andaverageclassificationerrorofg (Err)incase(iii)withnominal
(cid:98)
level α = 0.05.
Cases Method Pval Pval Err Err
LL NN LL NN
LCT 0.000 0.000
Case (iii) CT 0.000 0.022 0.279 0.429
DCT 0.000 0.018
6 Concluding remarks
We conclude the paper with two remarks. Firstly, the localized conformal prediction is
efficient in capturing local or conditional information, but this comes at the cost of a much
smaller effective sample size. In our simulation experiments, the power of localized methods
grows significantly as the sample size increases in many scenarios. However, when the sample
size is small, our proposed methods often exhibit lower power compared to other methods.
Therefore, it would be beneficial to increase the effective sample size by utilizing additional
data or modifying the definition of the LCP.
Secondly, we define the LCP with a random sampling step for each test point to achieve
finite-sample validity. However, the random sampling step introduces external randomness,
whichdegradesthestabilityoftherelatedmethods. Additionally, theLCPisdefinedbycom-
˜
puting the similarity between covariates of the calibration data and the sampled covariate X
instead of the test point X itself. Although these two issues are equivalent asymptotically,
they generally differ in finite-samples. This makes the LCP not effective enough in character-
izing local information. A potential solution is to use a different definition for the localized
conformal p-value to ensure finite-sample validity without randomization, which warrants
further consideration.
References
Bao, Y., Huo, Y., Ren, H., and Zou, C. (2024), “Selective conformal inference with false
coverage-statement rate control,” Biometrika, asae010.
Bates, S., Cand`es, E., Lei, L., Romano, Y., and Sesia, M. (2023), “Testing for outliers with
35conformal p-values,” The Annals of Statistics, 51, 149–178.
Benjamini, Y. and Hochberg, Y. (1995), “Controlling the false discovery rate: a practical and
powerful approach to multiple testing,” Journal of the Royal Statistical Society: Series B
(Statistical Methodology), 57, 289–300.
Brooks, T., Pope, D., and Marcolini, M. (2014), “Airfoil Self-Noise,” UCI Machine Learning
Repository https://archive.ics.uci.edu/dataset/291/airfoil+self+noise.
Bu¨hlmann, P. (2020), “Invariance, Causality and Robustness,” Statistical Science, 35, 404–
426.
Cand`es, E., Lei, L., and Ren, Z. (2023), “Conformalized Survival Analysis,” Journal of the
Royal Statistical Society: Series B, 85, 24–45.
Catterson, V. M., McArthur, S. D. J., and Moss, G. (2010), “Online Conditional Anomaly
DetectioninMultivariateDataforTransformerMonitoring,” IEEE Transactions on Power
Delivery, 25, 2556–2564.
Cerioli, A. (2010), “Multivariate Outlier Detection with High-Breakdown Estimators,” Jour-
nal of the American Statistical Association, 105, 147–156.
Chen, Y. and Lei, J. (2024), “De-Biased Two-Sample U-Statistics With Application To
Conditional Distribution Testing,” arXiv preprint arXiv:2402.00164.
Cherian, J. J., Gibbs, I., and Cand`es, E. J. (2024), “Large language model validity via
enhanced conformal prediction methods,” arXiv preprint arXiv:2406.09714.
Chernozhukov, V., Wu¨thrich, K., and Zhu, Y. (2021), “Distributional conformal prediction,”
Proceedings of the National Academy of Sciences, 118, e2107794118.
Dette, H. and Neumeyer, N. (2003), “Nonparametric comparison of regression curves: an
empirical process approach,” The Annals of Statistics, 31, 880–920.
36Erfani, S. M., Rajasegarar, S., Karunasekera, S., and Leckie, C. (2016), “High-dimensional
and large-scale anomaly detection using a linear one-class SVM with deep learning,” Pat-
tern Recognition, 58, 121–134.
Farahani, A., Voghoei, S., Rasheed, K., and Arabnia, H. R. (2021), “A Brief Review of
Domain Adaptation,” in Advances in Data Science and Information Engineering, pp. 877–
894.
Fithian, W. and Lei, L. (2022), “Conditional calibration for false discovery rate control under
dependence,” The Annals of Statistics, 50, 3091 – 3118.
Gao, J. and Gijbels, I. (2008), “Bandwidth Selection in Nonparametric Kernel Testing,”
Journal of the American Statistical Association, 103, 1584–1594.
Guan, L. (2023), “Localized conformal prediction: A generalized inference framework for
conformal prediction,” Biometrika, 110, 33–50.
Hall, P. and Hart, J. D. (1990), “Bootstrap Test for Difference Between Means in Nonpara-
metric Regression,” Journal of the American Statistical Association, 85, 1039–1049.
Hong,C.andHauskrecht,M.(2015),“MCODE:MultivariateConditionalOutlierDetection,”
arXiv preprint arXiv:1505.04097.
Hore, R. and Barber, R. F. (2023), “Conformal prediction with local weights: randomization
enables local guarantees,” arXiv preprint arXiv:2310.07850.
Hu, X. and Lei, J. (2023), “A Two-Sample Conditional Distribution Test Using Conformal
Prediction and Weighted Rank Sum,” Journal of the American Statistical Association, 0,
1–19.
Jin, Y. and Cand`es, E. J. (2023a), “Model-free selective inference under covariate shift via
weighted conformal p-values,” arXiv preprint arXiv:2307.09291.
— (2023b), “Selection by Prediction with Conformal p-values,” Journal of Machine Learning
Research, 24, 1–41.
37Kaggle (2016), “House Sales in King County, USA,” https://www.kaggle.com/datasets/
harlfoxem/housesalesprediction.
— (2021), “Diabetes Health Indicators Dataset,” https://www.kaggle.com/datasets/
alexteboul/diabetes-health-indicators-dataset.
Lei, J. and Wasserman, L. (2013), “Distribution-free Prediction Bands for Non-parametric
Regression,” Journal of the Royal Statistical Society Series B: Statistical Methodology, 76,
71–96.
Lei, L. and Cand`es, E. J. (2021), “Conformal inference of counterfactuals and individual
treatment effects,” Journal of the Royal Statistical Society Series B: Statistical Methodol-
ogy, 83, 911–938.
Liang, Z., Sesia, M., and Sun, W. (2024), “Integrative conformal p-values for out-of-
distribution testing with labelled outliers,” Journal of the Royal Statistical Society Series
B: Statistical Methodology, qkad138.
Liu, F. T., Ting, K. M., and Zhou, Z.-H. (2008), “Isolation Forest,” in Proceedings of the
2008 Eighth IEEE International Conference on Data Mining, IEEE Computer Society, pp.
413–422.
Marandon, A., Lei, L., Mary, D., and Roquain, E. (2024), “Adaptive novelty detection with
false discovery rate guarantee,” The Annals of Statistics, 52, 157 – 183.
Mohri, C. and Hashimoto, T. (2024), “Language Models with Conformal Factuality Guaran-
tees,” arXiv preprint arXiv:2402.10978.
Peng, L., Wang, G., and Zou, C. (2023), “MEASURING, TESTING, AND IDENTIFYING
HETEROGENEITY OF LARGE PARALLEL DATASETS,” Statistica Sinica, 33, 1–22.
Powell, J. L., Stock, J. H., and Stoker, T. M. (1989), “Semiparametric estimation of index
coefficients,” Econometrica, 57, 1403–1430.
38Rava, B., Sun, W., James, G. M., and Tong, X. (2021), “A burden shared is a burden halved:
A fairness-adjusted approach to classification,” arXiv preprint arXiv:2110.05720.
Riani, M., Atkinson, A. C., and Cerioli, A. (2009), “Finding an Unknown Number of Multi-
variate Outliers,” Journal of the Royal Statistical Society: Series B (Statistical Methodol-
ogy), 71, 447–466.
Romano, Y., Patterson, E., and Candes, E. (2019), “Conformalized quantile regression,”
Advances in Neural Information Processing Systems, 32.
Song, X., Wu, M., Jermaine, C., and Ranka, S. (2007), “Conditional Anomaly Detection,”
IEEE Transactions on Knowledge and Data Engineering, 19, 631–645.
Tibshirani, R. J., Foygel Barber, R., Candes, E., and Ramdas, A. (2019), “Conformal Pre-
diction Under Covariate Shift,” in Advances in Neural Information Processing Systems,
vol. 32.
Vovk, V. (2013), “Conditional validity of inductive conformal predictors,” Mach. Learn., 92,
349–376.
Vovk, V., Gammerman, A., and Shafer, G. (2005), Algorithmic learning in a random world,
New York: Springer.
Wu, X., Huo, Y., Ren, H., and Zou, C. (2023), “Optimal Subsampling via Predictive Infer-
ence,” Journal of the American Statistical Association, 0, 1–29.
Zhang, Y., Jiang, H., Ren, H., Zou, C., and Dou, D. (2022), “AutoMS: Automatic Model Se-
lection for Novelty Detection with Error Rate Control,” in Advances in Neural Information
Processing Systems, vol. 35, pp. 19917–19929.
Zheng, J. X. (1996), “A consistent test of functional form via nonparametric estimation
techniques,” Journal of Econometrics, 75, 263–289.
39Appendix
A Technical details
A.1 Proof of Theorem 2
˜
Proof. Denote P ,P as the marginal distribution of X if we fist sample X from P or
1,X˜ 2,X˜ 1,X
˜
P andthensampleXfromH(X,·). Thedistributionsofthecalibrationandtestpointsare
2,X
P ×P andP ×P whereP andP denotethecorresponding
1,(X,Y)|X˜ 1,X˜ 2,(X,Y)|X˜ 2,X˜ 1,(X,Y)|X˜ 2,(X,Y)|X˜
conditional distributions of calibration and test data points.
Noticethatthesuper-uniformpropertystillholdsiftheconditionaldistributionP =
1,(X,Y)|X˜
P .
Therefore,thesuper-uniformboundholdsforanindependenttuple(X∗,Y∗,X˜∗)
∼
2,(X,Y)|X˜
P ×P . That is
1,(X,Y)|X 2,X˜
(cid:80) H(X ,X˜∗)I{V˜∗ ≤ V }+ξ∗ ·H(X∗,X˜∗)
p∗ = i∈C 1i 1i ,
L (cid:80)
H(X
,X˜∗)+H(X∗,X˜∗)
i∈C 1i
Pr(p∗ ≤ α) ≤ α.
L
˜
The probability for (X ,Y ,X ) is then upper bounded by
2n+j 2n+j 2n+j
(cid:110) (cid:16) (cid:17)(cid:111)
Pr(p ≤ α) ≤α+E d P ,P
L,j X˜∼P
2,X˜
TV 1,(X,Y)|X˜ 2,(X,Y)|X˜
(cid:110) (cid:16) (cid:17)(cid:111)
=α+E d P ,P .
X˜∼P
2,X˜
TV 1,X|X˜ 2,X|X˜
40˜
For a fixed X we have
(cid:40)(cid:12) (cid:12)(cid:41)
d
(cid:16)
P ,P
(cid:17) =1
E
(cid:12) (cid:12)dP 2,X|X˜(X) −1(cid:12)
(cid:12)
TV 1,X|X˜ 2,X|X˜ 2 X∼P 1,X˜|X (cid:12)dP (X) (cid:12)
(cid:12) 1,X|X˜ (cid:12)
(cid:40)(cid:12) (cid:12)(cid:41)
1 (cid:12) g(X) (cid:12)
= E (cid:12) −1(cid:12)
2 X∼P 1,X˜|X (cid:12)E {g(X′)} (cid:12)
(cid:12) X′∼P
1,X|X˜
(cid:12)
E {|g(X)−g(X′)|}
≤
X,X′∼P
1,X|X˜
2E {g(X)}
X∼P 1,X|X˜
E {H(X,X˜ )}
=E {|g(X)−g(X′)|} X∼P1,X .
X,X′∼P 1,X|X˜ 2E {g(X)H(X,X˜ )}
X∼P1,X
˜
Taking expectation with respect to X we have
(cid:110) (cid:16) (cid:17)(cid:111)
E d P ,P
X˜∼P
2,X˜
TV 1,X|X˜ 2,X|X˜
(cid:90) E {H(X,x)}
≤ E {g(X)H(X,x)}E {|g(X)−g(X′)|} X∼P1,X dx
X∼P1,X X,X′∼P 1,X|X˜=x 2E {g(X)H(X,x)}
X∼P1,X
(cid:90)
1
= E {|g(X)−g(X′)|}E {H(X,x)}dx
2 X,X′∼P 1,X|X˜=x X∼P1,X
(cid:90)
1
= E {|g(X)−g(X′)|}E dP
2 X,X′∼P 1,X|X˜=x X∼P1,X H,X
where P has a density function f (x) = E {H(X,x)}.
H,X H,X X∼P1,X
By integration
E {|g(X)−g(X′)|}
X,X′∼P
1,X|X˜=x
(cid:90) 1 (cid:18) x′ −x(cid:19) (cid:18) x′′ −x(cid:19)
= K K f (x′)f (x′′)|g(x′)−g(x′′)|dx′dx′′
h2d h h 1,X 1,X
(cid:90)
= K(u)K(v)|g(x+hu)−g(x+hv)|f (x+hu)f (x+hv)dudv
1,X 1,X
≤2∥f ∥ E {|g(x+hU)−g(x)|}.
1,X ∞ U∼K(·)
41Combining the results above we conclude
(cid:110) (cid:16) (cid:17)(cid:111)
Pr(p ≤ α) ≤α+E d P ,P
L,j X˜∼P
2,X˜
TV 1,X|X˜ 2,X|X˜
≤α+∥f ∥ E {|g(X+hU)−g(X)|}.
1,X ∞ X∼PH,X,U∼K(·)
A.2 Proof of Theorem 3
Proof.
Remember the definition of the RBF and box kernel
1 (cid:26) ∥x−x′∥2(cid:27) 1 √
H (x,x′) = exp − 2 , H (x,x′) = I{∥x−x′∥ ≤ 2h}
RBF V hd 2h2 box V hd 2
d,RBF d,box
where V ,V are normalizing constants.
d,RBF d,box
The LCP function is
(cid:80) H(X ,X˜ )I{v ≤ V }+ξ ·H(x,X˜ )
p (x,y) = i∈C 1i 1i . (15)
L (cid:80) ˜ ˜
H(X ,X)+H(x,X)
i∈C 1i
For the difference we have
|p (x,y)−(1−F (v))|
L V|X=x
(cid:12) (cid:12)
(cid:12)(cid:80) H(X ,X˜ )[I{v ≤ V }−{1−F (v)}]+[ξ −{1−F (v)}]·H(x,X˜ )(cid:12)
=(cid:12) i∈C 1i 1i V|X=x V|X=x (cid:12)
(cid:12) (cid:80) ˜ ˜ (cid:12)
(cid:12) i∈CH(X 1i,X)+H(x,X) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12)(cid:80) H(X ,X˜ )[I{v ≤ V }−{1−F (v)}](cid:12) (cid:12) ∥H(x,x′)∥ (cid:12)
≤(cid:12) i∈C 1i 1i V|X=x (cid:12)+(cid:12) ∞ (cid:12)
(cid:12) (cid:80) ˜ (cid:12) (cid:12)(cid:80) ˜ (cid:12)
(cid:12) i∈CH(X 1i,X) (cid:12) (cid:12) i∈CH(X 1i,X)(cid:12)
42(cid:80) ˜
For the denominator n = H(X ,X), first notice for the RBF kernel
H i∈C 1i
(cid:40) (cid:41)
(cid:88) 1 ∥X −X˜ ∥2
n = exp − 1i 2
RBF V hd 2h2
d,RBF
i∈C
V (cid:88) 1 √
≥ exp{−1} d,box I{∥X −X˜ ∥ ≤ 2h}
V V hd 1i 2
d,RBF d,box
i∈C
V
d,box
= exp{−1} ·n .
box
V
d,RBF
√
Define n∗ = (cid:80) I{∥X −X˜ ∥ ≤ 2h}, for constants 0 < λ,ϵ < 1 we have
box i∈C 1i 2
(cid:16) (cid:17)
Pr E(n∗ )−n∗ ≥ λE(n∗ ) | X˜
box box box
(cid:16) (cid:17)
=Pr exp{E(n∗ )−n∗ } ≥ exp{λE(n∗ )} | X˜
box box box
(cid:104) (cid:105)
≤E exp{E(n∗ )−n∗ } | X˜ exp{−λE(n∗ )}
box box box
(cid:104) (cid:110) (cid:111) (cid:105)|C|
=E exp I{X′ ∈ B√ (X˜ )}−Pr(X′ ∈ B√ (X˜ )) | X˜ exp{−λE(n∗ )}
2h 2h box
(cid:104) (cid:110) (cid:111) (cid:110) (cid:111)(cid:105)|C|
= Pr(X ∈ B√ (X˜ ))exp Pr(X ∈/ B√ (X˜ )) +Pr(X ∈/ B√ (X˜ ))exp −Pr(X ∈ B√ (X˜ ))
2h 2h 2h 2h
·exp{−λE(n∗ )}
box
(cid:104) (cid:105)|C|
≤ Pr(X ∈ B√ (X˜ ))exp{1}+{1−Pr(X ∈ B√ (X˜ ))}{1−ϵ·Pr(X ∈ B√ (X˜ ))} exp{−λE(n∗ )}
2h 2h 2h box
(cid:104) (cid:105)|C| (cid:110) (cid:111)
= 1+(e−1−ϵ)Pr(X ∈ B√ (X˜ ))+ϵPr(X ∈ B√ (X˜ ))2 exp −λ|C|Pr(X′ ∈ B√ (X˜ ))
2h 2h 2h
(cid:110) (cid:111)
≤exp −|C|(1+ϵ+λ−e)Pr(X ∈ B√ (X˜ ))+ϵ|C|Pr(X ∈ B√ (X˜ ))2
2h 2h
and
C hdf(x)
2C hdf(x) ≥ C hd{f(x)+o(1)} ≥ Pr(X ∈ B (X˜ )) ≥ C hd{f(x)−o(1)} ≥ d
d d h d
2
for sufficiently large n, where C > 0 only depends on d. Taking ϵ = λ = 0.9 we have
d
(cid:18) (cid:19) (cid:26) (cid:27)
|C|f(x) 2.8−e
Pr n ≥ ≥ 1−exp − nhdγC f(x)+3.6nh2dγC2f(x)2 → 1.
box 20V 2 d d
d,box
Therefore with probability tending to 1 we have n ≥ C · |C|f(x) for some fixed constant
H
43C > 0. Then
|p (x,y)−(1−F (v))|
L V|X=x
≤
1 (cid:40)(cid:12) (cid:12) (cid:12)(cid:80) i∈CH(X 1i,X˜ )[I{v ≤ V 1i}−{1−F V|X=x(v)}](cid:12) (cid:12) (cid:12)+(cid:12) (cid:12)
(cid:12)
1 (cid:12) (cid:12) (cid:12)(cid:41)
.
(16)
Cf(x) (cid:12) |C| (cid:12) (cid:12)nhdγV (cid:12)
(cid:12) (cid:12) d,H
For the first term
(cid:40) ((cid:80) H(X ,X˜ )[I{v ≤ V }−{1−F (v)}])2(cid:41)
E i∈C 1i 1i V|X=x
|C|2
1 (cid:16) (cid:17)
= E H(X ,X˜ )2[I{v ≤ V }−{1−F (v)}]2
1i 1i V|X=x
|C|
|C|−1 (cid:16) (cid:17)
+ E H(X ,X˜ )H(X ,X˜ )[I{v ≤ V }−{1−F (v)}]·[I{v ≤ V }−{1−F (v)}]
1i 1j 1i V|X=x 1j V|X=x
|C|
1 (cid:110) (cid:111) (cid:110) (cid:111)
≤ E H(X ,X˜ )2 +E H(X ,X˜ )H(X ,X˜ )∥F −F ∥ ∥F −F ∥
|C|
1i 1i 1j V|X=X1i V|X=x ∞ V|X=X1j V|X=x ∞
By integration
(cid:110) (cid:111)
E H(X ,X˜ )2
1i
(cid:40) (cid:32) (cid:33) (cid:41)
(cid:90) 1 x′ −X˜
=E K2 f (x′)dx′
h2d h 1,X
(cid:26)(cid:90) (cid:27)
1
= E K2(u)f (X˜ +hu)du
hd 1,X
(cid:90)
∥f ∥
≤ 1,X ∞ K2(u)du
hd
44(cid:110) (cid:111)
E H(X ,X˜ )H(X ,X˜ )∥F −F ∥ ∥F −F ∥
1i 1j V|X=X1i V|X=x ∞ V|X=X1j V|X=x ∞
(cid:40) (cid:32) (cid:33) (cid:32) (cid:33) (cid:41)
(cid:90) 1 x′ −X˜ x′′ −X˜
=E K K ∥F −F ∥ ∥F −F ∥ f (x′)f (x′′)dx′dx′′
h2d h h V|X=x′ V|X=x ∞ V|X=x′′ V|X=x ∞ 1,X 1,X
(cid:26)(cid:90) (cid:27)
≤∥f ∥2 E K(u)K(u′)∥F −F ∥ ∥F −F ∥ dudu′
1,X ∞ V|X=X˜+hu V|X=x ∞ V|X=X˜+hu′ V|X=x ∞
(cid:26)(cid:90) (cid:27)
≤∥f ∥2 E K(u)K(u′)∥X˜ −x+hu∥β∥X˜ −x+hu′∥βdudu′
1,X ∞ 2 2
(cid:90) (cid:18) (cid:19)
1 x˜ −x
=∥f ∥2 K(u)K(u′)∥x˜ −x+hu∥β∥x˜ −x+hu′∥β H dudu′dx˜
1,X ∞ 2 2hd h
(cid:90)
=h2β∥f ∥2 K(u)K(u′)K(u′′)∥u+u′′∥β∥u′ +u′′∥βdudu′du′′
1,X ∞ 2 2
(cid:40) (cid:41)
(cid:18)(cid:90) (cid:19)2 (cid:90)
≤3h2β∥f ∥2 K(u)∥u∥βdu + K(u)∥u∥2βdu
1,X ∞ 2 2
As all integrations in the final expressions exist, we have
(cid:40) ((cid:80) H(X ,X˜ )[I{v ≤ V }−{1−F (v)}])2(cid:41)
E i∈C 1i 1i V|X=x
|C|2
C ∥f ∥
≤ K,1 1,X ∞ +C ∥f ∥2 h2β.
nhd K,2 1,X ∞
Together with inequality (16) we complete the proof.
A.3 Proof of Theorem 4
Proof. By the construction of the refined LCP’s, they are valid conditional on the event
Y ∈/ A in finite sample
2j
Pr(p ≤ α) ≤ α,
rL,j
and marginal PSER control result is proved. For the conditional PSER inflation bound, the
proof is exactly the same to Theorem 7 with the only difference that the distribution of X
is replaced by the conditional distribution of X given the event Y ∈/ A. We therefore delay
the computation of the deviation term to the proof of Theorem 7.
45A.4 Proof of Theorem 5
Proof.
Denote the index set of inliers in D as H∗, We firstly need a lemma commonly used in
2 0
literature relating the conditional calibration technique.
Lemma A.1. The pruned rejection set R satisfies
FDR =
E(cid:34)(cid:80)m
j=1I{j ∈ R,j ∈ H∗
0}(cid:35)
≤
(cid:88)m
E(cid:34)
I{p
L,j
≤ α|R(cid:98) mj→0|,j ∈ H∗
0}(cid:35)
.
|R|∨1 |R(cid:98) |
j=1 j→0
TheproofofLemmaA.1canbefoundinJinandCand`es(2023a)andisthereforeomitted.
Denote Z and Z as tuples Z = (X ,Y ),Z = (X ,Y ) and the index set of
1i 2j 1i 1i 1i 2j 2j 2j
calibration data C = {i ,i ,...,i } where |C| = n . Let Z = [Z ,...,Z ,Z ] be the
1 2 nc c 1i1 1inc 2j
˜ ˜ ˜
unordered value set of Z ,...,Z ,Z . Let X = {X ,...,X } be the set of all sampled
1i1 1inc 2j 21 2m
covariates. Note that the unordered value set [p(j)] are fully determined by X˜ , Z and
L,l l̸=j
˜
{Z } . Moreover, the p-value p is fully determined by X , Z and Z . As {Z }
2l l̸=j L,j 2j 2j 2l l̸=j
˜
is independent of {Z ,...,Z ,Z } conditional on X, we know p is independent of
1i1 1inc 2j L,j
{p(j)} conditional on X˜ and Z. By the fact that |R(cid:98) | is fully determined by [p(j)] , we
L,l l̸=j j→0 L,l l̸=j
further have
(cid:12)
p ⊥⊥ |R(cid:98) | (cid:12) X˜ ,Z.
L,j j→0 (cid:12)
By the independency we have
(cid:34) (cid:35) (cid:34) (cid:35)
I{p ≤ α|R(cid:98)j→0|,j ∈ H } (cid:12) I{p ≤ α|R(cid:98)j→0|} (cid:12)
E L,j m 0 (cid:12) X˜ ,Z ≤ E L,j m (cid:12) X˜ ,Z
(cid:12) (cid:12)
|R(cid:98) | |R(cid:98) |
j→0 j→0
(cid:16) (cid:12) (cid:17)
Pr p ≤ α|R(cid:98)j→0| (cid:12) X˜ ,Z
L,j m (cid:12)
=
|R(cid:98) |
j→0
(cid:16) (cid:12) (cid:17)
Pr p∗ ≤ α|R(cid:98)j→0| (cid:12) X˜ ,Z
L,j m (cid:12)
≤ .
|R(cid:98) |
j→0
46where
(cid:80) H(X ,X˜ )(I{V < V }+ξ ·I{V = V })+ξ ·H(X ,X˜ )
p∗ = i∈C 1i 2j 2j 1i j 2j 1i j 2j 2j .
L,j (cid:80) ˜ ˜
H(X ,X )+H(X ,X )
i∈C 1i 2j 2j 2j
By the weighted exchangeability, p∗ | X˜ ,Z ∼ U[0,1]. Taking the expectation we have
L,j
 (cid:16) (cid:12) (cid:17)
FDR ≤ (cid:88)m E(cid:34) E(cid:40) I{p L,j ≤ α|R(cid:98) mj→0|} (cid:12) (cid:12) X˜ ,Z(cid:41)(cid:35) ≤ (cid:88)m EPr p∗ L,j ≤ α|R(cid:98) mj→0| (cid:12) (cid:12) X˜ ,Z 
(cid:12)
j=1
|R(cid:98) j→0|
j=1
 |R(cid:98) j→0| 
m
(cid:88) α
= = α,
m
j=1
which completes the proof.
A.5 Proof of Theorem 6
Define the uncomputable oracle p-value as
(cid:80)
H(X
,X˜ )I{V¯
≤
V¯
}+ξ ·H(X
,X˜
)
p∗ = i∈C 1i 2j 2j 1i j 2j 2j .
L,j (cid:80) ˜ ˜
H(X ,X )+H(X ,X )
i∈C 1i 2j 2j 2j
By Theorem 1, if {(X ,Y ,S )} ∪ {(X ,Y ,S )}m are exchangeable, this oracle p-
1i 1i 1i i∈C 2j 2j 2j j=1
value will be super-uniform
Pr(p∗ ≤ α) ≤ α.
L,j
¯
Note that V = max{V : Y ∈/ A }. This indicates
2j 2j,s 2j,s s
p∗ = min{p : Y ∈/ A }.
L,j L,j,s 2j,s s
47By direct tranformation we have
 
S2j
(cid:88)
FWER = Pr I{Y
2j,s
∈/ A s,p
L,j,s
≤ α} > 0
s=1
 
(cid:91)
= Pr {p
L,j,s
≤ α}
Y2j,s∈/As
= Pr(p∗ ≤ α) ≤ α,
L,j
which completes the proof.
A.6 Proof of Theorem 7
Proof. By our screening procedure, the conditional FWER can be transformed as
   
(cid:88)S2j
(cid:12) (cid:91) (cid:12)
Pr I{Y
2j,s
∈/ A s,δ
j,s
= 1} > 0 (cid:12)
(cid:12)
X
2j
∈ B = Pr {p
L,j,s
≤ α} (cid:12)
(cid:12)
X
2j
∈ B
s=1 Y2j,s∈/As
= Pr(p∗ ≤ α | X ∈ B).
L,j 2j
Since we assume exchangeability, this is equivalent to the covariate shift setting with
g(x) = I{x ∈ B}/Pr(X ∈ B). Therefore, we only need to compute the excess term in
2j
Theorem 2 with this specific g. By transformation
E {|g(x+hU)−g(x)|}
U∼K(·)
(cid:90)
1
= K(u)(I{x+hu ∈ B,x ∈/ B}+I{x+hu ∈/ B,x ∈ B})du
Pr(X ∈ B)
2j
(cid:90)
2
≤ K(u)I{∥u∥ ≥ h−1d(x,∂B)}du
2
Pr(X ∈ B)
2j
Pr (∥U∥ ≥ h−1d(x,∂B))
U∼K(·) 2
=2· .
Pr(X ∈ B)
2j
48Following the same proof to Theorem 2 we conclude
 
Pr(cid:88)S2j
I{Y
2j,s
∈/ A s,δ
j,s
= 1} > 0
(cid:12)
(cid:12)
(cid:12)
X
2j
∈ B ≤ α+2∥f 1,X∥
∞Pr
X∼PH,X,U∼K P( r·)
(( X∥U∥
∈2
≥ B)h−1d(X,∂B))
.
2j
s=1
A.7 Proof of Theorem 8
Proof. Remember that we assume n = n in the main text. We first introduce a lemma
1 2
about our defined U-statistic.
Lemma A.2. For some kernel function k(z,z′) depending on n , define the two-sample U-
1
statistic and its projection as
1
(cid:88)n1 (cid:88)n1
U = k(Z ,Z )
n1 n2 1i 2j
1 i=1 j=1
and
1
(cid:88)n1
1
(cid:88)n1
U(cid:98) = E{k(Z ,Z ) | Z }+ E{k(Z ,Z ) | Z }−E{k(Z ,Z )}.
n1
n
1i 21 1i
n
11 21 2j 1i 2j
1 1
i=1 j=1
Then if E{k(Z ,Z )2} = o(n ), U and U(cid:98) satisfy
1i 2j 1 n1 n1
√
n (U −U(cid:98) ) = o (1).
1 n1 n1 p
This theorem is an extension of Lemma 3.1 in Powell et al. (1989) which constructs a
similar result for one sample U-statistics of degree 2. The proof follows exactly the same and
is therefore omitted.
Denote the unnormalized version of T(cid:98) and its projection as T(cid:98)∗ and T(cid:98)∗ . In our defined
w w w,p
statistic k(Z ,Z ) = H(X ,X )D(cid:98) . We first check the condition in Lemma A.2. By
1i 2j 1i 2j ij
49integration and D(cid:98) < 1
ij
E{k(Z ,Z )2} ≤E{H(X ,X )2}
1i 2j 1i 2j
(cid:90) 1 (cid:18) x′ −x(cid:19)
= K f (x)f (x′)dxdx′
h2d h 1,X 2,X
(cid:90)
1
= K(u)2f (x)f (x+hu)dxdu
hd 1,X 2,X
(cid:90)
1
≤ K(u)2du.
hd
Together with the assumption n hd → ∞ we have E{k(Z ,Z )2} = o(n ).
1 1i 2j 1
Definethecentralizedprojectionstatisticsasψ (Z ) = E{k(Z ,Z ) | Z },ψ (Z ) =
1,n1 1i 1i 21 1i 2,n1 2j
E{k(Z ,Z ) | Z } and
11 2j 2j
1
(cid:88)n1
ψ = E{k(Z ,Z ) | Z }−E{k(Z ,Z )},
1,n1
n
1i 21 1i 1i 2j
1
i=1
1
(cid:88)m1
ψ = E{k(Z ,Z ) | Z }−E{k(Z ,Z )}.
2,n1
n
11 2j 2j 1i 2j
1
j=1
The projection can be decomposed as
ψ (Z ) =E{k(Z ,Z ) | Z }
1,n1 1i 1i 21 1i
(cid:90) (cid:18) (cid:19)(cid:20) (cid:21)
1 x−X 1 1
= K 1i −I{V < V(x,y)}− I{V = V(x,y)} f (x)f (y | x)dxdy
hd h 2 1i 2 1i 2,X 2
(cid:90) (cid:20) (cid:21)
1 1
= K(u) −I{V < V(X +hu,y)}− I{V = V(X +hu,y)}
1i 1i 1i 1i
2 2
·f (X +hu)f (y | X +hu)dudy
2,X 1i 2 1i
(cid:90) (cid:20) (cid:21)
1 1
= K(u) −I{V < V(cid:98)∗(X ,y)}− I{V = V(cid:98)∗(X ,y)} f (X )f (y | X )dudy
1i 1i 1i 1i 2,X 1i 2 1i
2 2
+ψ (Z ).
1,n1,r 1i
=ψ (Z )+ψ (Z ).
1 1i 1,n1,r 1i
By Assumption 1 and h → 0 we know ψ (Z ) = o (1). Similar results also hold for
1,n1,r 1i p
ψ (Z ) and ψ (Z ).
2,n1 2j 2,n1,r 2j
50Note that under the null hypothesis v(x,y) ≡ 1. So we have
(cid:26) (cid:18) (cid:19)(cid:27)
1
E{H(X ,X )D } = E H(X ,X ) −ξ = 0
1i 2j ij 1i 2j j
2
If Assumption 2 holds then
√ √
n E{H(X ,X )D(cid:98) } = n E{H(X ,X )(D(cid:98) −D )} = o (1)
1 1i 2j ij 1 1i 2j ij ij p
IfP = P thenunderthenullhypothesiswehaveP = P andthereforeE{H(X ,X )D(cid:98) } =
1,X 2,X 1 2 1i 2j ij
0 by symmetric.
Now the statistic can be decomposed as
1
(cid:88)n1
1
(cid:88)n1
T(cid:98)∗ =(T(cid:98)∗ −T(cid:98)∗ )+ [ψ (Z )−E{ψ (Z )}]+ [ψ (Z )−E{ψ (Z )}]
w w w,r n 1 1i 1 1i n 2 2j 2 2j
1 1
i=1 j=1
1
(cid:88)n1
1
(cid:88)n1
+ [ψ (Z )−E{ψ (Z )}]+ [ψ (Z )−E{ψ (Z )}]
n
1,n1,r 1i 1,n1,r 1i
n
2,n1,r 2j 2,n1,r 2j
1 1
i=1 j=1
+E{H(X ,X )D(cid:98) }
1i 2j ij
1
(cid:88)n1
1
(cid:88)n1
√
= [ψ (Z )−E{ψ (Z )}]+ [ψ (Z )−E{ψ (Z )}]+o (1/ n ).
1 1i 1 1i 2 2j 2 2j p 1
n n
1 1
i=1 j=1
As ψ (Z ) and ψ (Z ) are independent random variables not depending on n , we have
1 1i 2 2j 1
T(cid:98) w∗
→d
N (0,1). (17)
σ
n1
where
1 1
σ2 = Var{ψ (Z )}+ Var{ψ (Z )}.
n1 n 1 1i n 2 2j
1 1
Hereafter we only need to prove the consistency of the variance estimator. Denote σ∗2 =
n1
51Var(T(cid:98)∗), the non-asymptotic variance can be decomposed as
w
1 n −1 (cid:110) (cid:111)
σ∗2 = E{H(X ,X )2D(cid:98)2}+ 1 E H(X ,X )H(X ,X )D(cid:98) D(cid:98)
n1 n2 1i 2j ij n2 1i 2j 1k 2j ij kj
1 1
n −1 (cid:110) (cid:111) 2n −1 (cid:104)(cid:110) (cid:111)(cid:105)2
+ 1 E H(X ,X )H(X ,X )D(cid:98) D(cid:98) − 1 E H(X ,X )D(cid:98)
n2 1i 2j 1i 2k ij ik n2 1i 2j ij
1 1
By similar integration computation, the cross-term expectation converges to Var{ψ (Z )}
1 1i
and Var{ψ (Z )} in probability. Removing the vanishing term we have σ∗2−σ2 = o (1/n )
2 2j n1 n1 p 1
and σ∗ /σ →p 1.
n1 n1
The variance estimator σ2 takes the form
(cid:98)w
1
(cid:88)n1
(cid:40)
1
(cid:88)n1
(cid:41)2
1
(cid:88)n1
(cid:40)
1
(cid:88)n1
(cid:41)2
σ2 = H(X ,X )D(cid:98) + H(X ,X )D(cid:98)
(cid:98)w n2 n 1i 2j ij n2 n 1i 2j ij
1 i=1 1 j=1 1 j=1 1 i=1
1
(cid:88)n1 (cid:88)n1
2
(cid:40)
1
(cid:88)n1 (cid:88)n1
(cid:41)2
− H(X ,X )2D(cid:98)2 − H(X ,X )D(cid:98)
n4 1i 2j ij n n2 1i 2j ij
1 i=1 j=1 1 1 i=1 j=1
(cid:40) (cid:41)
1 1
(cid:88)n1 (cid:88)n1
1 1
(cid:88)n1
(cid:88)
= H(X ,X )2D(cid:98)2 + · H(X ,X )H(X ,X )D(cid:98) D(cid:98)
n2 n2 1i 2j ij n n3 1i 2j 1i 2k ij ik
1 1 i=1 j=1 1 1 i=1 j̸=k
1 1
(cid:88)n1
(cid:88) 2
(cid:40)
1
(cid:88)n1 (cid:88)n1
(cid:41)2
+ · H(X ,X )H(X ,X )D(cid:98) D(cid:98) − H(X ,X )D(cid:98)
n n3 1i 2j 1k 2j ij kj n n2 1i 2j ij
1 1 j=1 1̸=k 1 1 i=1 j=1
It is easy to see that σ2 consists of term-wise approximations of the expectations in σ∗2. By
(cid:98)w n1
further computing the second moments of the estimators and Markov’s inequality we have
σ2 −σ∗2 = o (1/n ). Together with (17) we conclude
(cid:98)w n1 p 1
T(cid:98) =
T(cid:98) w∗
→d
N(0,1).
w
σ
(cid:98)w
52A.8 Proof of Theorem 9
Proof. By the same proof with Theorem 5 we know
T(cid:98) w∗ −E{H(X 1i,X 2j)D(cid:98) ij}
→d
Z ∼ N(0,1). (18)
σ
(cid:98)w
√
By Assumption 2 we have E{H(X ,X )(D(cid:98) − D )} = o (1/ n ). Combining with the
1i 2j ij ij p 1
√
p
consistency of σ we know n σ /σ → 1 and
(cid:98)w 1(cid:98)w w
T(cid:98)∗ −E{H(X ,X )D(cid:98) } E{H(X ,X )D }
w 1i 2j ij = Z + 1i √ 2j ij (1+o (1))+o (1).
p p
σ σ / n
(cid:98)w w 1
The rest is to compute the bias term E{H(X ,X )D }. By integration
1i 2j ij
E{H(X ,X )D }
1i 2j ij
(cid:90) (cid:18) (cid:19)(cid:20) (cid:21)
1 x −x 1
= K 1 2 −I{V∗(x ,y ) < V∗(x ,y )} f (x )f (x )f (y | x )f (y | x )dx dx dy dy
hd h 2 1 1 2 2 1,X 1 2,X 2 1 1 1 2 2 2 1 2 1 2
(cid:90) (cid:20) (cid:21)
1
= K(u) −I{V∗(x ,y ) < V∗(x +hu,y )} f (x )f (x +hu)f (y | x )f (y | x +hu)
1 1 1 2 1,X 1 2,X 1 1 1 1 2 2 1
2
dx dudy dy
1 1 2
(cid:18)(cid:90) (cid:20) (cid:21) (cid:19)
1
= −I{V∗(x ,y ) < V∗(x ,y )} f (x )f (x )f (y | x )f (y | x )dx dy dy (1+o (1))
1 1 1 2 1,X 1 2,X 1 1 1 1 2 2 1 1 1 2 p
2
(cid:18)(cid:90) (cid:20) (cid:21) (cid:19)
1
= −I{V∗(x ,y ) < V∗(x ,y )} V∗(x ,y )f (x )f (x )f (y | x )f (y | x )dx dy dy (1+o (1))
1 1 1 2 1 1 1,X 1 2,X 1 2 1 1 2 2 1 1 1 2 p
2
(cid:26) (cid:18) (cid:19)(cid:27)
1
=E f (X) −E [V∗(X,Y )I{V∗(X,Y ) < V∗(X,Y )}] (1+o (1))
X∼P2,X 1,X
2
Y1,Y2∼P
2,Y|X
1 1 2 p
And by transformation
E [V∗(X,Y )I{V∗(X,Y ) < V∗(X,Y )}]
Y1,Y2∼P
2,Y|X
1 1 2
1 1 1
= E [V∗(X,Y )I{V∗(X,Y ) < V∗(X,Y )}]+ − E [V∗(X,Y )I{V∗(X,Y ) ≥ V∗(X,Y )}]
2
Y1,Y2∼P
2,Y|X
1 1 2
2 2
Y1,Y2∼P
2,Y|X
1 1 2
1 1
= − E [{V∗(X,Y )−V∗(X,Y )}I{V∗(X,Y ) ≥ V∗(X,Y )}]
2 2
Y1,Y2∼P
2,Y|X
1 2 1 2
1 1
= − E {|V∗(X,Y )−V∗(X,Y )|}.
2 4
Y1,Y2∼P
2,Y|X
1 2
53The bias term is then simplified as
1
E{H(X ,X )D } = E {f (X)|V∗(X,Y)−V∗(X,Y′)|}(1+o (1)).
1i 2j ij
4
X∼P2,X,Y,Y′∼P
2,Y|X
1,X p
Combining all the results above we conclude
√
T(cid:98) =
T(cid:98) w∗
= Z +
E{H(X 1i, √X 2j)D ij}
{1+o (1)}+o (1) =
n 1δ
w
{1+o (1)}+Z +o (1).
w p p p p
σ σ / n 4σ
(cid:98)w w 1 w
B Additional details
B.1 A flow chart of our work
Applications Theoretical guarantee
Balanced PSER control
data selection Conditional PSER bound
New tools
Conditional
Localized
Finite-sample FDR control
Conformity outlier detection
ML model conformal
score
p-values
Conditional Finite-sample FWER control
label screening Conditional FWER bound
Theoretical property
Two-sample Asymptotic normality
conditional Behavior under local
distribution test alternatives
54