CoverBench: A Challenging Benchmark for Complex Claim Verification
AlonJacovi1 MoranAmbar1 EyalBen-David1 UriShaham1
AmirFeder1 MorGeva1,2 DrorMarcus1 AviCaciularu1
1GoogleResearch 2TelAvivUniversity
alonjacovi@google.com
Abstract Information-Rich Contexts
Thereisagrowinglineofresearchonverify-
Financial table
ing the correctness of language models’ out-
Wiki, Finance, Legal Biomedical
puts. At the same time, LMs are being used Statistics Contracts Abstracts PubMed abstract
totacklecomplexqueriesthatrequirereason- Tables (etc.)
Legal Contract
ing. WeintroduceCoverBench,achallenging
Complex Reasoning Claims
benchmark focused on verifying LM outputs
Quantitative: Three companies (X, Y, Z)
in complex reasoning settings. Datasets that
saw revenue increase 5%.
canbeusedforthispurposeareoftendesigned
Multi-hop: The lead actor in X’s
for other complex reasoning tasks (e.g., QA)
first movie was Y.
targetingspecificuse-cases(e.g.,financialta-
+ long context reasoning, domain
bles),requiringtransformations,negativesam-
expertise, structured data…
plingandselectionofhardexamplestocollect
suchabenchmark. CoverBenchprovidesadi- Figure 1: CoverBench contains true and false claims
versified evaluation for complex claim verifi- thatrequireimplicitcomplexreasoningtoverifyina
cation in a variety of domains, types of rea- varietyofdomainsandsettings.
soning, relatively long inputs, and a variety
ofstandardizations,suchasmultiplerepresen- sideredareductionfromNLI(Daganetal.,2005;
tations for tables where available, and a con-
Bowmanetal.,2015)orAIS(Rashkinetal.,2021).
sistentschema. Wemanuallyvetthedatafor
Inthiswork,wefocusoncomplexclaims. Natu-
qualitytoensurelowlevelsoflabelnoise. Fi-
rally, as LMs are used frequently to solve com-
nally,wereportavarietyofcompetitivebase-
line results to show CoverBench is challeng- plex queries (Suzgun et al., 2022), their verify-
ing and has very significant headroom. The ingtheiroutputs’correctnessmayrequiremultiple
data is available at https://huggingface. hopsofreasoning(Gevaetal.,2021),quantitative
co/datasets/google/coverbench. reasoning(Lewkowyczetal.,2022),domainexper-
tise(Mageshetal.,2024),andsoon,basedonthe
1 Introduction
reasoninglevelrequiredintheoriginalquery. Are
Recent work has focused on measuring various generalopen-endedcomplexreasoningtasksand
properties of language models’ outputs (Leiter complexclaimverificationequivalent? Weargue
et al., 2022; Golovneva et al., 2022). One estab- thatthereisadifference: Byfocusingonabinary
lishedpropertytomeasureisthecorrectnessofgen- classificationofgivenstatementsinawell-defined
erated text, against its context (Tang et al., 2024) context, verifiers can—and should—be held to a
orexternalsources(e.g.,fact-checking,Panetal., higherstandardcomparedtothesourcetask. We
2023;Chenetal.,2023). Thismeans,forexample, proposesuchastandardinthiswork.
to verify whether a summary correctly refers to Toevaluatecomplexclaimverificationsolutions,
itssourcedocument(Bishopetal.,2023;Krishna we collect CoverBench—a benchmark for this
et al., 2023), or that some logical inference has task—byleveragingadiversesetofninedatasets
been made correctly based on claims that can be (§2)acrossdifferentsettingsthatrequirecomplex
verified (Jacovi et al., 2024). We refer to this as reasoning (Fig. 1). The benchmark targets a va-
claimverification,wheretheclaimisafalsifiable riety of language domains (Wikipedia, finance,
statementtobeverifiedagainstagivengrounding biomedical,legal,statistics,andothers),sourcesof
context (Honovich et al., 2022). It can be con- complexity(structureddata,quantitativereasoning,
1
4202
guA
6
]LC.sc[
1v52330.8042:viXraDataset Domain Task SourcesofComplexity
FinQA(Chenetal.,2021) Finance QA Quantitative,multi-step,tables
QRData(Liuetal.,2024) Statistics QA Longcontext,quantitative,multi-step,domainexpertise,tables
TabFact(Chenetal.,2020a) Wikipedia Verification Multi-step,tables
MultiHiertt(Zhaoetal.,2022) Finance QA Longcontext,quantitative,multi-step,tables
HybridQA(Chenetal.,2020b) Wikipedia QA Verylongcontext,tables
ContractNLI(Chenetal.,2020b) Legal NLI Longcontext,domainexpertise
PubMedQA(Jinetal.,2019) Biomedical QA Domainexpertise
TACT(Caciularuetal.,2024) Various QA Quantitative,multi-step,tables
Feverous(Alyetal.,2021) Wikipedia Verification Multi-step,quantitative,tables
Table1: AnoverviewofthedatasetsusedinCoverBench(§2).
multi-stepreasoning,domainexpertise,reasoning includedaswell,withintheirlimitedavailability.
overlongcontext),anddifficultyandquality(via
Sources of complexity. Complex reasoning
variousfilteringsteps,bothmanualandautomatic).
can colloquially refer to many different tasks in
TobuildCoverBench(§3),weconvertalltasks
practice. In the scope of this paper, we consider
toaunifiedformatwithdeclarativeclaims,meta-
complexreasoningtoinclude: (1)Reasoningover
data about the required type of reasoning, and
structureddata—inparticular,tables;(2)Reason-
parsing and standardization of all table represen-
ing over a long context; (3) Quantitative reason-
tations (we use HTML, JSON, and Markdown). We
ing—calculation, aggregation, counting, and so
additionallycarefullysamplefalseclaimsandchal-
on;(4)Reasoningthatrequiresdomainexpertise;
lenging examples: In particular, challenging ex-
(5) Multi-hop reasoning—i.e., multiple inter-de-
amples are selected through leveraging metadata
pendent steps of reasoning. Importantly, we are
andmodel-basedselection. AndsimilarlytoTiny-
interestednotonlyinexamplesthatexhibitanyof
Benchmarks(MaiaPoloetal.,2024),weselectan
the above sources of complexity, but specifically
efficientsubsetofexamplesthatwillbethemost
asmanyuniquecombinationsaspossibleofthem.
representativeformodelranking.
Datasets. InTab.1wedescribeallofthedatasets
Thefinalbenchmark,followingthisprocess,con-
included in CoverBench. Some contexts with ta-
tains733examplesofcontent-richgroundingcon-
bles (e.g., in MultiHiertt) contain a mix of table
textsandcomplexclaimsbasedonthemwithcor-
and text. Where possible, we leverage metadata
rectness labels. The contexts are long, with an
from the datasets to select the examples that re-
averageof3,500tokens. Themajorityofmodels
quire reasoning (e.g., as FinQA contains the an-
we evaluated, including recent competitive LMs,
swers’ calculation, we can select examples with
achieveperformanceneartherandombaseline,de-
multiplesteps). Twooriginally-includeddatasets,
spite manual vetting we have done to ensure that
SciTab(Luetal.,2023)andREVEAL(Jacovietal.,
thetasksaresolvable. Thebestmodelsachievebe-
2024),wereexcludedduringamanualinspection
lowa65Macro-F1score,whilesmallermodels(7
processdescribedin§3. InFeverous,differentex-
to13billionparameterLMs)achieveperformance
amplescanexhibitdifferentsourcesofcomplexity,
attherandombaselinelevel. Theseresultsshowa
and we select examples that exhibit at least one.
significantheadroomforthetask.
Extendeddetailsareavailablein§A.
2 BenchmarkScope
3 ConstructingCoverBench
Forournewbenchmarkaboutcomplexclaimver-
ification,weprioritizevarietyanddifficulty. This Wedescribetheprocessofcollectingandbuilding
sectionexplainsthefacetofvariety. ourbenchmark. Thisinvolvesconversiontoauni-
fiedschema,negativesamplingwithseedmodels,
Domains. Weaimtoincludeavarietyoflanguage
andcarefulselectionofinformativeexamples.
domains. Inparticular: Thefinancial, Wikipedia,
biomedical,andlegaldomainsarewell-represented
3.1 ConversiontotheSchema
indatasetsforcomplexreasoning. Asmallquantity
of examples in a large variety of other domains, Many of the datasets described in §2 require nu-
such as statistical inference and literature, were anced transformation into the claim verification
2setting. Belowarerelevantdetailsthatrequireat- Mixtral-8x7b,andmanuallyverifiedperfectaccu-
tentioninthistransformation. racyforthissimpletaskonarepresentativesample
of100cases). Ifthegeneratedanswerwasjudged
Schema. EachexampleinCoverBenchcontains
differentthanthegoldanswerforbothheuristics,
thefollowing: Thegroundingcontext;afalsifiable
itwasconsideredincorrect.
claimintheformofadeclarativestatement;abi-
naryentailmentlabel;thelanguagedomainofthe
3.3 ExampleSelection
instance;andthesourcesofcomplexitythatmake
thisinstancerequirecomplexreasoning(see§2). Following the methodology above, we derived a
totalofroughly7,000examples. Fromthislarger
QA pairs to declarative statements. Claims
set, we selected a subset of examples with three
which come in the format of a QA pair (e.g., “Q:
goals: (I) Most difficult examples, without intro-
WhatisthecapitalofFrance? A:Paris.”) werecon-
ducinglabelnoisebias. (II)Examplesthatareleast
vertedtodeclarativeform(“ThecapitalofFrance
likelytosufferfrommemorizationviadatacontam-
is Paris.”) through both manual annotation and a
promptedLMwithmanualreview.1 ination. (III)Examplesthataremostindicativeof
thedifferencebetweenmodels’capabilities.
Representing structure. The various table for-
Toclarifygoal(I):Itisexpectedthatalldatasets
matsacrossdatasetswereparsedintoastandardfor-
have annotation errors (Klie et al., 2022). E.g.,
mat,whichwerepresentedinoneofthreetextfor-
if we simply select examples of model mistakes,
mats,chosenatrandom: HTML,JSON,orMarkdown.
whilethiswillselectdifficultexamples(Klieetal.,
2023), it would also select a greater ratio of
3.2 SamplingNegativeExamples
incorrectly-labeledexamples. Thus,wecannotse-
TabFact,ContractNLI,PubMedQA,andFeverous lectexamplesofmodelmistakesdeliberately.
aredatasetsthatcontainbothtrueandfalseclaims Goals (I) and (II) can be targeted by selecting
(in the case of PubMedQA, since answers are bi- examplesthatareincorrectlypredictedbymodels
nary,theinverseanswercanalsobeused.). in the claim-only baseline setting. In this setting,
FinQA, QRData, MultiHiertt, HybridQA and onlytheclaimisprovidedtothemodelwithoutits
TACT areQAdatasets—andso,theycontainonly grounding context, so the example is intractable,
positiveexamplesasquestionsandtheirassociated whichavoidstheincorrectlabelbias. Ifthemodel
goldanswers. Forthesetasks,werequireamethod iscorrect—itisviaarandomguess,someshallow
togeneratenegativeexamples(i.e.,claimswhich heuristic(McCoyetal.,2019),ordatacontamina-
arenotentailedbythecontext). Thenegativeex- tion (Deng et al., 2023).2 By choosing examples
amplesshouldbedifficult,whichprecludessimpler where at least two models were incorrect in this
heuristicsfornegativesampling(Lietal.,2019). baseline, we reduce the possibility of discarding
GiventheoriginalQAformat,asimplemethod correctnessviaarandomguess.
toderivedifficultnegativecasesistousetheques- Goals(II)and(III)canbetargetedbyselecting
tiontogeneratemodels’answers. Theanswersare modeldisagreements. Sinceonanydisagreement
comparedtothegoldanswer,andiftheyarewrong, onemodelwascorrectandonewasincorrect,we
thenewQApairisselectedasanegativeexample. canselectexamples—withoutusinggoldlabels—
Thesenegativeanswersrepresentrealmodelerrors, whichdemonstrablydifferentiatebetweenmodels.
sotheyarelikelydifficultformodelstoverify.
We made both selections by using two
We used the following three seed models: comparable-performance seed models: Mixtral-
GPT-4o (OpenAI et al., 2024), gemma-1.1-7b- 8x7b-Instruct and Starling-LM-7B-beta-ExPO
1.1-it (Gemma et al., 2024), and Mixtral-8x7b- (Zhuetal.,2023). Performanceonthefinalsubset
Instruct (Jiang et al., 2024). After extracting the was3to7Macro-F1pointslowerthanonarandom
“finalanswer”fromthemodels’long-formanswer, subsetinourtesting(§B).
wecomparedthegoldandmodelanswersintwo
ways: Lowercasedexactmatch(fornumbers,we 2Importantly,wecannotguaranteeagainstdatacontami-
convertedpercentagesandremovedcurrenciesand nationwithinthescopeofthispaper,sincemanymodelsuse
hiddentrainingdata,andnofuture-proofmechanismfornew
commas), and using a prompted LM (we used
models.Nevertheless,werelyonoverallsimilaritiesbetween
modelsandtheirsimilarinternet-derivedtrainingdata. We
1WeusedmultipleLMs,includingLlama-2-7bandMixtrl- refertotheindividualmodeldeveloperstoindexCoverBench
8x7b;allperformedwell,asthetaskisverysimple. andcheckforcontaminationwhenreportingevaluationsonit.
3TACT QRData Model 0-shot 0-shotCoT
Feverous HybridQA
∗Gemma-1.1-7b-it 43.4 46.1
MultiHiertt
∗Mixtral-8x7B-Instruct 45.3 49.0
∗Starling-LM-7B-beta-ExPO 47.7 52.1
PubMedQA ContractNLI NLI-Entailment-Verifier-xxl 43.7 —
T5-11b-TrueTeacher&ANLI 48.2 —
Llama-2-13b-Chat 48.3 48.7
TabFact Qwen1.5-14B-Chat 49.0 50.8
FinQA
Llama-2-70b-Chat 50.3 52.6
Yi-1.5-34B-Chat 51.0 54.2
Gemini1.5Flash 54.4 54.5
Wikipedia Biomed Statistics Qwen2-72B-Instruct 54.3 57.0
Finance Legal Other (17)
Gemini1.5Pro 59.9 62.1
Figure2:Distributionofthesourcedatasetsandthetext
Table2: Macro-F1performanceonCoverBench. 50is
domainsinCoverBench.
therandombaselinethreshold,andbelow50impliesa
classbias,where0isthemajoritybaseline. (∗)denotes
3.4 Vetting
seedmodelsforsampling—weincludetheirresultsfor
Due to the various steps described above, we re- completeness,butnotethattheyareunreliable.
quire a phase of manual inspection to check for
solvability of the derived data and diagnose pos- settingandourapproachareavailablein§B.
sible issues. We selected 10 examples at random
Baseline details. The baselines use prompted
fromeachdatasetforamanualvettingphase. The
LMs(Gemmaetal.,2024;01.AIetal.,2024;Qwen,
datasetshadbetween0and1incorrectlabels.
2024a,b; Reid et al., 2024; Touvron et al., 2023)
During this phase, two datasets originally se-
andoff-the-shelfNLIclassifiers(Gekhmanetal.,
lectedwereomitted: SciTab(Luetal.,2023)was
2023;Sanyaletal.,2024). InthecaseoftheLMs,
omittedduetoahighleveloflabelnoise,andRE-
theywerepromptedin0-shotand0-shotChain-of-
VEAL (Jacovi et al., 2024) was omitted due to a
Thought(Weietal.,2023)formats,afterextensive
lossofdifficulty(notably,thislossofdifficultywas
“promptengineering”usingpromptsfromprevious
anartifactoftheconversion,andnotpresentinthe
worksandtrial-and-error. Whilewemadesignifi-
original data). PubMedQA also exhibited a loss
cantattemptsatfew-shotpromptstoimproveper-
of difficulty during the conversion process via a
formance, none succeeded, likely due to the fact
correlation between negation in the claim and a
thattheexamplesinCoverBenchareoftenlong(we
non-entailmentlabel. However,thisissuewasneu-
havetestedbothsimplifiedandfull-lengthdemon-
tralizedwiththeclaim-onlysamplingstep(§3.3).
strations),asfew-shotisknowntostruggleinlong-
context(Jiangetal.,2023). FortheNLIclassifiers,
3.5 TheCoverBenchBenchmark
contradictionandneutralwereconsideredasnoten-
The final challenge set contains 733 examples. tailed. Incaseswherethecontextlengthexceeded
Fig.2showsthedistributionofthesourcedatasets themodel’scontextwindow,ifthemodeldidnot
and domains. The examples have 3,500 tokens includeanextrapolationtechnique,thecontextwas
onaverageviatheMixtral-8x7b-Instructtokenizer. trimmedfromitsbeginning.
Theoveralllabeldistributionisbalancedat45:55
towardsthepositiveclass(andbetween58:42and 5 Conclusions
44:56persourcedataset). Moredetailsarein§A.
We collect a new claim verification benchmark
specificallytargetingdifficultyandcomplexityof
4 ExperimentalSetupandResults
reasoning,towardsthegoalofdevelopingnotonly
In this section, we describe the experiments and models with good complex reasoning, but better
resultswemadetoevaluatethedifficultyofCover- verificationtoclassifywhenageneratedclaimis
Bench. TheMacro-F1resultsareinTab.2. Overall, false. CoverBench involves a wide variety of do-
weseethatavarietyofcompetitivemodelsstruggle mainsandsourcesofcomplexity,haslonginputs
onthistask. Fine-graineddetailsoftheexperiment with thousands of tokens on average, and is rela-
4tively efficient in size. The benchmark provides SamuelR.Bowman,GaborAngeli,ChristopherPotts,
asignificantchallengetocurrentmodels,andcan and Christopher D. Manning. 2015. A large anno-
tatedcorpusforlearningnaturallanguageinference.
serveasagroundworkforfutureworkinthearea.
InConferenceonEmpiricalMethodsinNaturalLan-
guageProcessing.
Limitations
Avi Caciularu, Alon Jacovi, Eyal Ben-David, Sasha
Domain-specificLMs. Inthiswork,wefocused Goldshtein,TalSchuster,JonathanHerzig,GalEli-
dan, and Amir Globerson. 2024. Tact: Advancing
onvalidatingthedifficultyofthebenchmarkbased
complexaggregativereasoningwithinformationex-
on readily-available off-the-shelf LMs. Some of
tractiontools. ArXiv,abs/2406.03618.
the tasks will likely be better addressed by LMs
ShiqiChen,YiranZhao,JinghanZhang,EthanChern,
that use specialized tools or specialized prompt-
Siyang Gao, Pengfei Liu, and Junxian He. 2023.
ingtechniques(Kimetal.,2024),LMsthatwere
Felm: Benchmarkingfactualityevaluationoflarge
specifically trained for a specific domain such as languagemodels. ArXiv,abs/2310.00741.
finance (Wu et al., 2023), and so on. Our goal is
WenhuChen, HongminWang, JianshuChen, Yunkai
tomeasuregeneralabilityindiversesettings,but
Zhang, HongWang, ShiyangLi, XiyouZhou, and
specializeduse-casesmaybenefitfrominvestigat- WilliamYangWang.2020a. Tabfact: Alarge-scale
ingspecializedmodelsonatherelevantsubsetof datasetfortable-basedfactverification. In8thInter-
CoverBench. national Conference on Learning Representations,
ICLR 2020, Addis Ababa, Ethiopia, April 26-30,
Datacontaminationdisclaimer. Asmentioned 2020.OpenReview.net.
in the paper, despite some steps we took against
WenhuChen,HanwenZha,ZhiyuChen,WenhanXiong,
this (such as generating negative examples, con-
HongWang,andWilliamWang.2020b. Hybridqa:A
verting QA to declarative statements, converting datasetofmulti-hopquestionansweringovertabular
tablestodifferentformatsthanthoseintheoriginal andtextualdata. FindingsofEMNLP2020.
datasets,andsamplingless-memorizedexamples),
ZhiyuChen,WenhuChen,ChareseSmiley,Sameena
theproblemofdatacontaminationlimitstheability Shah,IanaBorova,DylanLangdon,ReemaMoussa,
ofevaluationdatasetscurrently. Evaluatorsusing MattBeane,Ting-HaoHuang,BryanRRoutledge,
thedatashouldtakecaretocheckfortheindividual etal.2021. Finqa: Adatasetofnumericalreasoning
overfinancialdata. InProceedingsofthe2021Con-
examples’presenceintheirmodels’trainingdata,
ferenceonEmpiricalMethodsinNaturalLanguage
iftheyhaveaccesstoit,andotherwisetheyshould
Processing,pages3697–3711.
notrelyonthemetricsforcriticaldecisionsabout
Ido Dagan, Oren Glickman, and Bernardo Magnini.
modelswhosetrainingdataisunknown.
2005. ThePASCALrecognisingtextualentailment
challenge. InMachineLearningChallenges,Eval-
uatingPredictiveUncertainty,VisualObjectClassi-
References fication and Recognizing Textual Entailment, First
PASCAL Machine Learning Challenges Workshop,
01.AI,AlexYoung,BeiChen,ChaoLi,ChengenHuang,
MLCW2005,Southampton,UK,April11-13,2005,
Ge Zhang, Guanwei Zhang, Heng Li, Jiangcheng
Revised Selected Papers, volume 3944 of Lecture
Zhu,JianqunChen,JingChang,KaidongYu,Peng
NotesinComputerScience,pages177–190.Springer.
Liu, Qiang Liu, Shawn Yue, Senbin Yang, Shim-
ingYang,TaoYu,WenXie,WenhaoHuang,Xiao- ChunyuanDeng,YilunZhao,XiangruTang,MarkB.
hui Hu, Xiaoyi Ren, Xinyao Niu, Pengcheng Nie, Gerstein, and Arman Cohan. 2023. Investigating
Yuchi Xu, Yudong Liu, Yue Wang, Yuxuan Cai, datacontaminationinmodernbenchmarksforlarge
ZhenyuGu,ZhiyuanLiu,andZonghongDai.2024. languagemodels. ArXiv,abs/2311.09783.
Yi: Open foundation models by 01.ai. Preprint,
arXiv:2403.04652. ZorikGekhman,JonathanHerzig,RoeeAharoni,Chen
Elkind,andIdanSzpektor.2023. Trueteacher:Learn-
Rami Aly, Zhijiang Guo, Michael Sejr Schlichtkrull, ing factual consistency evaluation with large lan-
James Thorne, Andreas Vlachos, Christos guagemodels. Preprint,arXiv:2305.11171.
Christodoulopoulos, Oana Cocarascu, and Arpit
Mittal. 2021. FEVEROUS: Fact extraction and Team Gemma, Thomas Mesnard, Cassidy Hardin,
VERification over unstructured and structured RobertDadashi,SuryaBhupatiraju,ShreyaPathak,
information. Laurent Sifre, Morgane Rivière, Mihir Sanjay
Kale,JulietteLove,PouyaTafti,LéonardHussenot,
Jennifer A Bishop, Qianqian Xie, and Sophia Anani- PierGiuseppeSessa,AakankshaChowdhery,Adam
adou.2023. Longdocfactscore: Evaluatingthefac- Roberts, Aditya Barua, Alex Botev, Alex Castro-
tualityoflongdocumentabstractivesummarisation. Ros, Ambrose Slone, Amélie Héliou, Andrea Tac-
ArXiv,abs/2309.12455. chetti, Anna Bulanova, Antonia Paterson, Beth
5Tsai, Bobak Shahriari, Charline Le Lan, Christo- TimothéeLacroix,andWilliamElSayed.2024. Mix-
pherA.Choquette-Choo,ClémentCrepy,DanielCer, tralofexperts. Preprint,arXiv:2401.04088.
Daphne Ippolito, David Reid, Elena Buchatskaya,
HuiqiangJiang,QianhuiWu,XufangLuo,Dongsheng
Eric Ni, Eric Noland, Geng Yan, George Tucker,
Li,Chin-YewLin,YuqingYang,andLiliQiu.2023.
George-ChristianMuraru,GrigoryRozhdestvenskiy,
Longllmlingua: Accelerating and enhancing llms
HenrykMichalewski,IanTenney,IvanGrishchenko,
in long context scenarios via prompt compression.
Jacob Austin, James Keeling, Jane Labanowski,
ArXiv,abs/2310.06839.
Jean-Baptiste Lespiau, Jeff Stanway, Jenny Bren-
nan,JeremyChen,JohanFerret,JustinChiu,Justin
Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William
Mao-Jones, Katherine Lee, Kathy Yu, Katie Milli-
Cohen,andXinghuaLu.2019. Pubmedqa: Adataset
can, Lars Lowe Sjoesund, Lisa Lee, Lucas Dixon,
forbiomedicalresearchquestionanswering. InPro-
MachelReid,MaciejMikuła,MateoWirth,Michael
ceedingsofthe2019ConferenceonEmpiricalMeth-
Sharman, Nikolai Chinaev, Nithum Thain, Olivier
odsinNaturalLanguageProcessingandthe9thIn-
Bachem,OscarChang,OscarWahltinez,PaigeBai-
ternationalJointConferenceonNaturalLanguage
ley, Paul Michel, Petko Yotov, Rahma Chaabouni,
Processing(EMNLP-IJCNLP),pages2567–2577.
RamonaComanescu,ReenaJana,RohanAnil,Ross
McIlroy,RuiboLiu,RyanMullins,SamuelLSmith, JoongwonKim,BhargaviParanjape,TusharKhot,and
SebastianBorgeaud,SertanGirgin,SholtoDouglas, Hanna Hajishirzi. 2024. Husky: A unified, open-
ShreePandya,SiamakShakeri,SohamDe,TedKli- sourcelanguageagentformulti-stepreasoning.
menko, Tom Hennigan, Vlad Feinberg, Wojciech
Stokowiec, Yu hui Chen, Zafarali Ahmed, Zhitao Jan-Christoph Klie, Bonnie Webber, and Iryna
Gong,TrisWarkentin,LudovicPeran,MinhGiang, Gurevych. 2023. Annotation Error Detection: An-
Clément Farabet, Oriol Vinyals, Jeff Dean, Koray alyzing the Past and Present for a More Coherent
Kavukcuoglu,DemisHassabis,ZoubinGhahramani, Future. ComputationalLinguistics,49(1):157–198.
Douglas Eck, Joelle Barral, Fernando Pereira, Eli
Jan-Christoph Klie, Bonnie Lynn Webber, and Iryna
Collins,ArmandJoulin,NoahFiedel,EvanSenter,
Gurevych.2022. Annotationerrordetection:Analyz-
AlekAndreev,andKathleenKenealy.2024. Gemma:
ingthepastandpresentforamorecoherentfuture.
Openmodelsbasedongeminiresearchandtechnol-
ComputationalLinguistics,49:157–198.
ogy. Preprint,arXiv:2403.08295.
Yuta Koreeda and Christopher Manning. 2021. Con-
MorGeva,DanielKhashabi,EladSegal,TusharKhot,
tractNLI:Adatasetfordocument-levelnaturallan-
DanRoth,andJonathanBerant.2021. Didaristotle
guage inference for contracts. In Findings of the
usealaptop? aquestionansweringbenchmarkwith
AssociationforComputationalLinguistics: EMNLP
implicit reasoning strategies. Transactions of the
2021,pages1907–1919,PuntaCana,DominicanRe-
Association for Computational Linguistics, 9:346–
public.AssociationforComputationalLinguistics.
361.
KalpeshKrishna,ErinBransom,BaileyKuehl,Mohit
O.Yu.Golovneva,MoyaChen,SpencerPoff,Martin
Iyyer,PradeepDasigi,ArmanCohan,andKyleLo.
Corredor,LukeZettlemoyer,MaryamFazel-Zarandi,
2023. LongEval:Guidelinesforhumanevaluationof
and Asli Celikyilmaz. 2022. Roscoe: A suite of
faithfulnessinlong-formsummarization. InProceed-
metrics for scoring step-by-step reasoning. ArXiv,
ingsofthe17thConferenceoftheEuropeanChap-
abs/2212.07919.
teroftheAssociationforComputationalLinguistics,
pages1650–1669,Dubrovnik,Croatia.Association
OrHonovich, RoeeAharoni, JonathanHerzig, Hagai
forComputationalLinguistics.
Taitelbaum,DoronKukliansy,VeredCohen,Thomas
Scialom, Idan Szpektor, Avinatan Hassidim, and Christoph Leiter, Piyawat Lertvittayakumjorn,
YossiMatias.2022. True: Re-evaluatingfactualcon- M. Fomicheva, Wei Zhao, Yang Gao, and Steffen
sistencyevaluation. ArXiv,abs/2204.04991. Eger. 2022. Towards explainable evaluation
metrics for natural language generation. ArXiv,
AlonJacovi,YonatanBitton,BerndBohnet,Jonathan
abs/2203.11131.
Herzig, Or Honovich, Michael Tseng, Michael
Collins, Roee Aharoni, and Mor Geva. 2024. A AitorLewkowycz,AndersAndreassen,DavidDohan,
chain-of-thoughtisasstrongasitsweakestlink: A EthanDyer,HenrykMichalewski,VinayVenkatesh
benchmarkforverifiersofreasoningchains. Preprint, Ramasesh, Ambrose Slone, Cem Anil, Imanol
arXiv:2402.00559. Schlag, Theo Gutman-Solo, Yuhuai Wu, Behnam
Neyshabur, Guy Gur-Ari, and Vedant Misra. 2022.
Albert Q. Jiang, Alexandre Sablayrolles, Antoine
Solving quantitative reasoning problems with lan-
Roux, Arthur Mensch, Blanche Savary, Chris guagemodels. ArXiv,abs/2206.14858.
Bamford, Devendra Singh Chaplot, Diego de las
Casas, Emma Bou Hanna, Florian Bressand, Gi- Jia Li, Chongyang Tao, Wei Wu, Yansong Feng,
anna Lengyel, Guillaume Bour, Guillaume Lam- DongyanZhao,andRuiYan.2019. Samplingmat-
ple, Lélio Renard Lavaud, Lucile Saulnier, Marie- ters! anempiricalstudyofnegativesamplingstrate-
AnneLachaux,PierreStock,SandeepSubramanian, gies for learning of matching models in retrieval-
Sophia Yang, Szymon Antoniak, Teven Le Scao, baseddialoguesystems. InConferenceonEmpirical
Théophile Gervet, Thibaut Lavril, Thomas Wang, MethodsinNaturalLanguageProcessing.
6Xiao Liu, Zirui Wu, Xueqing Wu, Pan Lu, Kai-Wei Christina Kim, Yongjik Kim, Jan Hendrik Kirch-
Chang,andYansongFeng.2024. Arellmscapable ner, Jamie Kiros, Matt Knight, Daniel Kokotajlo,
ofdata-basedstatisticalandcausalreasoning? bench- Łukasz Kondraciuk, Andrew Kondrich, Aris Kon-
markingadvancedquantitativereasoningwithdata. stantinidis, Kyle Kosic, Gretchen Krueger, Vishal
arXivpreprintarXiv:2402.17644. Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan
Leike, Jade Leung, Daniel Levy, Chak Ming Li,
XinyuanLu,LiangmingPan,QianLiu,PreslavNakov, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz
and Min-Yen Kan. 2023. Scitab: A challeng- Litwin, Theresa Lopez, Ryan Lowe, Patricia Lue,
ing benchmark for compositional reasoning and AnnaMakanju,KimMalfacini,SamManning,Todor
claim verification on scientific tables. Preprint, Markov, Yaniv Markovski, Bianca Martin, Katie
arXiv:2305.13186. Mayer,AndrewMayne,BobMcGrew,ScottMayer
McKinney, Christine McLeavey, Paul McMillan,
VarunMagesh,FaizSurani,MatthewDahl,MiracSuz- Jake McNeil, David Medina, Aalok Mehta, Jacob
gun, Christopher D. Manning, and Daniel E. Ho. Menick, Luke Metz, Andrey Mishchenko, Pamela
2024. Hallucination-free? assessing the reliabil- Mishkin, Vinnie Monaco, Evan Morikawa, Daniel
ity of leading ai legal research tools. Preprint, Mossing,TongMu,MiraMurati,OlegMurk,David
arXiv:2405.20362. Mély,AshvinNair,ReiichiroNakano,RajeevNayak,
ArvindNeelakantan,RichardNgo,HyeonwooNoh,
Felipe Maia Polo, Lucas Weber, Leshem Choshen, LongOuyang,CullenO’Keefe,JakubPachocki,Alex
Yuekai Sun, Gongjun Xu, and Mikhail Yurochkin. Paino, Joe Palermo, Ashley Pantuliano, Giambat-
2024. tinybenchmarks: evaluatingllmswithfewer tistaParascandolo,JoelParish,EmyParparita,Alex
examples. arXivpreprintarXiv:2402.14992. Passos,MikhailPavlov,AndrewPeng,AdamPerel-
man,FilipedeAvilaBelbutePeres,MichaelPetrov,
R.ThomasMcCoy,ElliePavlick,andTalLinzen.2019. Henrique Ponde de Oliveira Pinto, Michael, Poko-
Rightforthewrongreasons: Diagnosingsyntactic rny,MichellePokrass,VitchyrH.Pong,TollyPow-
heuristicsinnaturallanguageinference. InAnnual ell, Alethea Power, Boris Power, Elizabeth Proehl,
Meeting of the Association for Computational Lin- RaulPuri,AlecRadford,JackRae,AdityaRamesh,
guistics. CameronRaymond,FrancisReal,KendraRimbach,
Carl Ross, Bob Rotsted, Henri Roussez, Nick Ry-
OpenAI,JoshAchiam,StevenAdler,SandhiniAgarwal, der,MarioSaltarelli,TedSanders,ShibaniSanturkar,
Lama Ahmad, Ilge Akkaya, Florencia Leoni Ale- GirishSastry,HeatherSchmidt,DavidSchnurr,John
man,DiogoAlmeida,JankoAltenschmidt,SamAlt- Schulman, Daniel Selsam, Kyla Sheppard, Toki
man,ShyamalAnadkat,RedAvila,IgorBabuschkin, Sherbakov, Jessica Shieh, Sarah Shoker, Pranav
SuchirBalaji,ValerieBalcom,PaulBaltescu,Haim- Shyam,SzymonSidor,EricSigler,MaddieSimens,
ing Bao, Mohammad Bavarian, Jeff Belgum, Ir- JordanSitkin,KatarinaSlama,IanSohl,Benjamin
wanBello,JakeBerdine,GabrielBernadett-Shapiro, Sokolowsky, Yang Song, Natalie Staudacher, Fe-
ChristopherBerner,LennyBogdonoff,OlegBoiko, lipePetroskiSuch,NatalieSummers,IlyaSutskever,
MadelaineBoyd,Anna-LuisaBrakman,GregBrock- Jie Tang, Nikolas Tezak, Madeleine B. Thompson,
man, Tim Brooks, Miles Brundage, Kevin Button, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng,
TrevorCai,RosieCampbell,AndrewCann,Brittany PrestonTuggle,NickTurley,JerryTworek,JuanFe-
Carey, Chelsea Carlson, Rory Carmichael, Brooke lipeCerónUribe,AndreaVallone,ArunVijayvergiya,
Chan,CheChang,FotisChantzis,DerekChen,Sully ChelseaVoss,CarrollWainwright,JustinJayWang,
Chen, Ruby Chen, Jason Chen, Mark Chen, Ben AlvinWang,BenWang,JonathanWard,JasonWei,
Chess,ChesterCho,CaseyChu,HyungWonChung, CJWeinmann,AkilaWelihinda,PeterWelinder,Ji-
Dave Cummings, Jeremiah Currier, Yunxing Dai, ayiWeng,LilianWeng,MattWiethoff,DaveWillner,
Cory Decareaux, Thomas Degry, Noah Deutsch, Clemens Winter, Samuel Wolrich, Hannah Wong,
Damien Deville, Arka Dhar, David Dohan, Steve Lauren Workman, Sherwin Wu, Jeff Wu, Michael
Dowling,SheilaDunning,AdrienEcoffet,AttyEleti, Wu,KaiXiao,TaoXu,SarahYoo,KevinYu,Qim-
TynaEloundou,DavidFarhi,LiamFedus,NikoFelix, ingYuan,WojciechZaremba,RowanZellers,Chong
SimónPosadaFishman, JustonForte, IsabellaFul- Zhang, Marvin Zhang, Shengjia Zhao, Tianhao
ford,LeoGao,ElieGeorges,ChristianGibson,Vik Zheng, Juntang Zhuang, William Zhuk, and Bar-
Goel,TarunGogineni,GabrielGoh,RaphaGontijo- ret Zoph. 2024. Gpt-4 technical report. Preprint,
Lopes, Jonathan Gordon, Morgan Grafstein, Scott arXiv:2303.08774.
Gray,RyanGreene,JoshuaGross,ShixiangShane
LiangmingPan,XiaobaoWu,XinyuanLu,AnhTuan
Gu,YufeiGuo,ChrisHallacy,JesseHan,JeffHarris,
Luu,WilliamYangWang,Min-YenKan,andPreslav
YuchenHe,MikeHeaton,JohannesHeidecke,Chris
Nakov. 2023. Fact-checking complex claims with
Hesse,AlanHickey,WadeHickey,PeterHoeschele,
program-guidedreasoning. ArXiv,abs/2305.12744.
Brandon Houghton, Kenny Hsu, Shengli Hu, Xin
Hu, Joost Huizinga, Shantanu Jain, Shawn Jain,
The pandas development team. 2020. pandas-
Joanne Jang, Angela Jiang, Roger Jiang, Haozhun
dev/pandas: Pandas.
Jin, Denny Jin, Shino Jomoto, Billie Jonn, Hee-
woo Jun, Tomer Kaftan, Łukasz Kaiser, Ali Ka- TeamQwen.2024a. Introducingqwen1.5.
mali, Ingmar Kanitscheider, Nitish Shirish Keskar,
Tabarak Khan, Logan Kilpatrick, Jong Wook Kim, TeamQwen.2024b. Qwen2technicalreport.
7Hannah Rashkin, Vitaly Nikolaev, Matthew Lamm, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu,
Michael Collins, Dipanjan Das, Slav Petrov, Gau- Teven Le Scao, Sylvain Gugger, Mariama Drame,
rav Singh Tomar, Iulia Turc, and D. Reitter. 2021. QuentinLhoest,andAlexanderM.Rush.2020. Hug-
Measuringattributioninnaturallanguagegeneration gingface’stransformers: State-of-the-artnaturallan-
models. ComputationalLinguistics,49:777–840. guageprocessing. Preprint,arXiv:1910.03771.
Machel Reid, Nikolay Savinov, Denis Teplyashin, ShijieWu,OzanIrsoy,StevenLu,VadimDabravolski,
Dmitry Lepikhin, Timothy Lillicrap, Jean-baptiste MarkDredze,SebastianGehrmann,PrabhanjanKam-
Alayrac,RaduSoricut,AngelikiLazaridou,OrhanFi- badur, David Rosenberg, and Gideon Mann. 2023.
rat,JulianSchrittwieser,etal.2024. Gemini1.5: Un- Bloomberggpt: Alargelanguagemodelforfinance.
lockingmultimodalunderstandingacrossmillionsof ArXiv,abs/2303.17564.
tokensofcontext. arXivpreprintarXiv:2403.05530.
YilunZhao,YunxiangLi,ChenyingLi,andRuiZhang.
Soumya Sanyal, Tianyi Xiao, Jiacheng Liu, Wenya 2022. MultiHiertt: Numericalreasoningovermulti
Wang, and Xiang Ren. 2024. Are machines better hierarchicaltabularandtextualdata. InProceedings
at complex reasoning? unveiling human-machine of the 60th Annual Meeting of the Association for
inferencegapsinentailmentverification. Preprint, ComputationalLinguistics(Volume1: LongPapers),
arXiv:2402.03686. pages6588–6600,Dublin,Ireland.Associationfor
ComputationalLinguistics.
Mirac Suzgun, Nathan Scales, Nathanael Scharli, Se-
bastian Gehrmann, Yi Tay, Hyung Won Chung, Banghua Zhu, Evan Frick, Tianhao Wu, Hanlin Zhu,
Aakanksha Chowdhery, Quoc V. Le, Ed Huai hsin KarthikGanesan,Wei-LinChiang,JianZhang,and
Chi,DennyZhou,andJasonWei.2022. Challenging JiantaoJiao.2023. Starling-7b: Improvingllmhelp-
big-bench tasks and whether chain-of-thought can fulness&harmlessnesswithrlaif.
solvethem. InAnnualMeetingoftheAssociationfor
ComputationalLinguistics.
Liyan Tang, Philippe Laban, and Greg Durrett. 2024.
Minicheck:Efficientfact-checkingofllmsonground-
ingdocuments. ArXiv,abs/2404.10774.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti
Bhosale,DanBikel,LukasBlecher,CristianCanton
Ferrer,MoyaChen,GuillemCucurull,DavidEsiobu,
JudeFernandes,JeremyFu,WenyinFu,BrianFuller,
CynthiaGao,VedanujGoswami,NamanGoyal,An-
thonyHartshorn,SagharHosseini,RuiHou,Hakan
Inan,MarcinKardas,ViktorKerkez,MadianKhabsa,
IsabelKloumann,ArtemKorenev,PunitSinghKoura,
Marie-AnneLachaux,ThibautLavril,JenyaLee,Di-
anaLiskovich,YinghaiLu,YuningMao,XavierMar-
tinet,TodorMihaylov,PushkarMishra,IgorMoly-
bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-
stein,RashiRungta,KalyanSaladi,AlanSchelten,
Ruan Silva, Eric Michael Smith, Ranjan Subrama-
nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-
lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,
ZhengYan,IliyanZarov,YuchenZhang,AngelaFan,
Melanie Kambadur, Sharan Narang, Aurelien Ro-
driguez,RobertStojnic,SergeyEdunov,andThomas
Scialom.2023. Llama2: Openfoundationandfine-
tunedchatmodels. Preprint,arXiv:2307.09288.
JasonWei,XuezhiWang,DaleSchuurmans,Maarten
Bosma,BrianIchter,FeiXia,EdChi,QuocLe,and
DennyZhou.2023. Chain-of-thoughtpromptingelic-
its reasoning in large language models. Preprint,
arXiv:2201.11903.
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Chaumond,ClementDelangue,AnthonyMoi,Pier-
ricCistac,TimRault,RémiLouf,MorganFuntow-
icz,JoeDavison,SamShleifer,PatrickvonPlaten,
8A BenchmarkCollection
Dataset Tokens LabelRatio(+) Size
BenchmarkstatisticsaregiveninTab.3andFig.3.
ContractNLI 2,572 42.7% 12.1%
Examplesfromeachdatasetinthebenchmarkare Feverous 5,204 56.2% 16.5%
inTab.5. FinQA 1,252 57.3% 16.0%
The 17 domains which are included under HybridQA 19,297 55.8% 5.9%
“Other”inFig.2,andarerepresentedbyveryfew MultiHiertt 4,829 58.3% 8.2%
examplesinthedataset(atotalof31examples),are: PubMedQA 360 56.3% 16.2%
business,media,culinary,emergency,environment, QRData 5,512 57.5% 5.5%
fashion,medicine,archaeology,ethics,real-estate, TACT 314 56.3% 4.4%
politics,technology,biology,transportation,retail, TabFact 1,239 56.3% 15.3%
education,andarchitecture. Thesedomainsareall
fromtheTACTdatasetwhichhasawidevarietyof Table3: Statisticspersourcedataset.
domains.
cludesnaturallanguageinferenceexamples,where
A.1 Datasets
the premises are non-disclosure agreements, and
Below we describe each dataset and what it was
thehypothesesareasetof17standardizedconclu-
usedfor. Thepublictestsetswereusedwhenavail-
sions. Inthemajorityofcases,domainexpertiseis
able, and otherwise, thepublic dev sets. Eachin-
requiredtoderivethecorrectlabel.
stance of CoverBench contains the precise ID of
PubMedQA (Jin et al., 2019) includes binary
wheretheinstancecamefromwithrespecttothe
(true-false) QA pairs over PubMed abstracts. A
sourcedatasets.
largequantityofexamplesrequirereasoningover
FinQA (Chen et al., 2021) includes QA pairs
multiple sentences to answer, and all require do-
thatrequirequantitativereasoning(withanumeri-
mainexpertise.
calanswer)overamedium-lengthtextandatable
TACT(Caciularuetal.,2024) includestext-table
extracted from a financial report. Since the data
alignments alongside QA pairs that require mul-
includestheentirecalculationbehindtheanswer,
tiple complex calculations, formalized as chains
weselectedQApairsthatrequireatleasttwosteps
oftable-manipulationqueries,inalargevarietyof
ofcalculations.
domains.
QRData(Liuetal.,2024) containsQApairsthat
Feverous(Alyetal.,2021) includesclaimsover
requirestatisticalinferenceorcausalinferenceover
Wikipedia documents, many of which include ta-
a large table. We selected QA pairs that require
bles and quantitative reasoning or multi-step rea-
statistics,asdifficultexamplesofquantitativerea-
soning. Weselectedtheexamplesthatrequireta-
soning.
bles,andeitherquantitativereasoningormulti-step
TabFact(Chenetal.,2020a) containsWikipedia
reasoning.
tablesanddeclarativestatementsbasedontheta-
bles,someofwhichrequirereasoningovermulti-
A.2 ConversiontotheSchema
plecellsinthetable(e.g.,aggregationorarg-max).
Wemanuallyselectedexamplesthatrequirereason- Tables. Each dataset’s tables were parsed using
ingovermultiplecells. thedataset’sassociatedsourcecodewhenavailable,
andotherwise,theparsingwaswrittenbyus. All
MultiHiertt (Zhao et al., 2022) similarly to
tables wereparsed intopandas DataFrames(pan-
FinQA includes QA pairs that require multi-step
dasdevelopmentteam,2020). Thetables’textrep-
quantitativereasoning,withanumericalanswer,in
resentationsofHTML,JSON,andMarkdownwerede-
the finance domain. The contexts in MultiHiertt
rivedusingthedefaultimplementationsinpandas
arelong,withmultipletables(someofthemhierar-
(theJSONrepresentationusesthe“records”setting)
chical)interspersedthroughoutalongdocument.
and chosen at random for each example. Since
HybridQA(Chenetal.,2020b) includesmulti-
someofthedatasetsusethesamecontextformulti-
hopQApairsoveramixoftextandatableinthe
pledifferentclaims,thesomecontextsmayappear
Wikipediadomain.
multipletimesinCoverBench,eitherwiththesame
ContractNLI(KoreedaandManning,2021) in- tablerepresentationordifferentones. Inthecase
9Model Oursample Randomsample
Tables 69.3%
Multi Step 53.5% ∗Gemma-1.1-7b-it 46.1 48.5
Reasoning ∗Starling-LM-7B-beta-ExPO 52.1 58.2
Quantitative 52.5% ∗Mixtral-8x7B-Instruct 49.0 59.6
Reasoning
Gemini1.5Flash 54.5 57.8
Long Context 29.1%
Yi-1.5-34B-Chat 54.2 61.1
Domain 28.4% Qwen2-72B-Instruct 57.0 62.0
Expertise
Gemini1.5Pro 62.1 68.8
HTML 19.9%
JSON 18.1% Table4: Macro-F1performanceonCoverBench(0-shot
CoT)forcomparisonbetweenourselectionofexamples
Markdown 17.1%
(§3.3)andarandomsampleofthesamesize.(∗)denotes
0 20 40 60 seedmodelsforsampling—weincludetheirresultsfor
completeness,butnotethattheyareunreliable.
Figure 3: Distribution of the sources of complexity
in CoverBench. Long context in this figure refers to
2001?” is “The stocks in 2005 rose
exampleswithover3,000tokenswiththeMixtral-8x7b-
$50from2001.”,generate“$50”. Ifthe
Instructtokenizer.
modeldidn’tgiveaclearanswer,output
“None”.
of Feverous, due to the unique typesetting of the Question: [question]
Wikipediatablesemployedinthatdataset,theta-
Modelanswer: [modelanswer]
blesweretakenas-is.
Extractedfinalanswer:”
Negativesampling. Thefinaldistributionofneg-
ativeexamplesbytheiransweringmodel,afterall GoldAnswerComparisonCheck:
selectionandsamplingsteps,are: 48.8%(Mixtral-
“Given two terms, Term 1 and Term 2,
8x7B-Instruct), 28.8% (gpt-4o), 22.4% (gemma-
your task is to compare the two terms
1.1-7b-it).
and say whether they are equivalent or
not.
A.3 Prompts.
For example, “12%” and “0.12” are
Thepromptsweusedforthesub-tasksinthecon-
equivalent, and “2 thousand dollars” is
versionprocessaregivenbelow.
equivalentto“$2,000”,butdifferentval-
QAtoDeclarativeStatement: ues, different units or different entities
are not equivalent. Generate “Yes” or
“Editthefollowingquestionandanswer
“No”.
intoadeclarativeform.
Term1: [modelanswer]
Forexample, giventhequestion"What
Term2: [goldanswer]
is the population of Europe? Round
to the nearest million." and answer Equivalent:”
"741,000,000", output "The population
ofEurope,roundedtothenearestmillion, B ExperimentDetails
is741,000,000."
B.1 Implementations
Question: [question]
FortheLMbaselines,binarymodeldecisionswere
Answer: [answer] parsedfrommodeloutputsundergreedydecoding,
according to the format below. If a model failed
Declarativeform:”
tocomplywiththepromptformat,weadditionally
FinalAnswerExtraction: concatenated“Finalanswer(correctorincorrect):”
totheendofthemodel’sanswerandre-prompted
“Givenaquestionandamodel’sanswer,
ittogetthefinalanswerforparsing.
extract the pure term answer from this
Theimplementationsandpromptswerechecked
text.
forsoundnessbyseeingthegapbetweenourmea-
For example if the answer to the ques- surements on a random subset compared to mea-
tion “How much did the stocks rise in surementsintheliterature,toobservethattheyare
10overall similar. The code to use the models was
based on standard available HuggingFace (Wolf
etal.,2020)codeforeachmodel,alongsidetheir
associatedtokenizersandchattemplates. ForGem-
ini1.5FlashandPro,theAPIversionwasused.
B.2 AdditionalResults
Tab. 4 shows a comparison of results between a
randomselectionofexamplesandourmodel-based
selection.
B.3 Prompts
Below are the prompts we used in the baseline
evaluations. We have tested various edits of the
prompts on a random subset of examples which
werenotincludedinthefinalbenchmark.
Zero-Shot:
“YourtaskistocheckiftheClaimiscor-
rectaccordingtotheEvidence. Generate
’Correct’iftheClaimiscorrectaccord-
ingtotheEvidence,or’Incorrect’ifthe
claimisincorrectorcannotbeverified.
Evidence: [context]
Claim: [claim]
Answer:”
Zero-ShotwithChain-of-Thought:
“YourtaskistocheckiftheClaimiscor-
rectaccordingtotheEvidence. Generate
’Correct’iftheClaimiscorrectaccord-
ingtotheEvidence,or’Incorrect’ifthe
claimisincorrectorcannotbeverified.
Evidence: [context]
Claim: [claim]
Let’sthinkstep-by-step:”
11Dataset Context(snippet) Claim
FinQA PaperTitle:One-to-Xanalogicalreasoningonwordembeddings:acasefordiachronic ForbothGigawordandNOW
armedconflictpredictionfromnewstexts datasets(andthecorresponding
Table3:Averagediachronicperformance embeddings),usingthe
||[EMPTY]|[BOLD]Algorithm|[BOLD]Precision|[BOLD]Recall|[BOLD]F1| cosine-basedthresholdincreases
|—:|:———-|:—————–|—————:|————–:|:———-| recallanddecreasesprecision
|0|Giga|Baseline|0.19|0.51|0.28| (differencesarestatistically
|1|Giga|Threshold|0.46|0.41|[BOLD]0.41|[...] significantwitht-test,p<0.05).
QRData TheStanfordUniversityHeartTransplantStudywasconductedtodeterminewhether Thedifferenceinsurvivalrate
anexperimentalhearttransplantprogramincreasedlifespan.Eachpatiententeringthe betweenthecontroland
programwasdesignatedanofficialhearttransplant[...] treatmentgroupscanbe
ThedataisintheCSVfileheart_transplant.csv. estimatedusingaconfidence
heart_transplant.csv intervalconstructedwiththe
||id|acceptyear|age|survived|survtime|prior|transplant|wait| normalapproximation.
|—-:|—–:|———-:|——:|:——–|——–:|:——|:———-|—–:|
|0|15|68|53|dead|1|no|control|nan|
|1|38|70|41|dead|5|no|treatment|5|[...]
TabFact {"artist":{"0":"ophiolatry","1":"ophiolatry","2":"blackflame","3":"tangorodrim", BlackFlame’stitlewasreleased
"4":"tangorodrim","5":"triumfall"},"title":{"0":"transmutation",[...] fivemonthsandtwodaysafter
Ophiolatry’s2008title.
MultiHiertt HEWLETTPACKARDENTERPRISECOMPANYANDSUBSIDIARIES TwoamountsforCreditCard(a)
Management’sDiscussionandAnalysisofFinancialConditionandResults[...] exceededtheaverageofAmount
##Table0## forCreditCard(a)in2012.
<table><tr><td></td><tdcolspan="3">ForthefiscalyearsendedOctober
31,</td>[...]<td>2019</td><td>2018</td><td>2017</td></tr><tr><td></td><td
colspan="3">Dollarsinmillions</td></tr><tr><td>Netrevenue[...]
Fiscal2019comparedwithFiscal2018CorporateInvestmentsnetrevenuedecreasedby
$36million,or6.6%(decreased4.4%onaconstantcurrencybases),in[...]
##Table1##
<table><tr><td>[...]
HybridQA 1998IAAFWorldHalfMarathonChampionships Ethiopiafinishedin3:05:18at
The7thIAAFWorldHalfMarathonChampionshipswasheldonSeptember27,1998, theIAAFWorldHalfMarathon
inthecityofUster,Switzerland.Atotalof236athletes,139menand97women,from Championshipsof1998
54countriestookpart.Detailedreportsontheeventandanappraisaloftheresultswas southeastofthecountry.
given.Completeresultswerepublished.
TeamResults–Men’s
<tableborder="1"class="dataframe"><thead><trstyle="text-align:right;"><th></th>
<th>Rank</th><th>Country</th>[...]
ContractNLI DEPARTMENTOFHOMELANDSECURITY ConfidentialInformationshall
NON-DISCLOSUREAGREEMENT onlyincludetechnical
I,__,anindividualofficial,employee,consultant,orsubcontractoroforto__(the information.
AuthorizedEntity),intendingtobelegallybound,herebyconsenttothetermsinthis
Agreementinconsiderationofmybeinggrantedconditionalaccesstocertain
information,specifiedbelow,thatisownedby,producedby,orinthepossessionofthe
United[...]
PubMedQA Toexaminewhethergovernment-funded,low-incomevisioncareprogramsimproveuse Governmentassistancemay
ofeyecareservicesbylow-incomeindividualsinCanada. improveutilizationofeyecare
Cross-sectionalsurvey. servicesbylow-income
27,375whiterespondentstotheCanadianCommunityHealthSurvey(CCHS)Healthy individuals.
Aging2008/2009.Government-funded,low-incomevisioncareprogramswere
reviewed.Theamountofassistanceprovidedwascomparedwithprofessionalfee
schedulesforgeneral/routineeyeexaminations[...]
TACT [{"JobTitle":"RegisteredNurse(RN)","JobDescription":"Full-Timepositionforcaring Theaveragesalarydescribedin
forpatientsatGentivaHomeHospice,Monday-Friday,daytimeschedule,reportsto thetextis27.52perhour.
Hospice,RN,PatientCare.","Location":"Bloomington,IL","Salary":"$20.04[...]
Feverous [H]Position:|[[Offensive_tackle|Offensive JonKolb(played200gamesas
tackle]]/[[Guard_(gridiron_football)|Guard]] aprofessionalfootballplayer
[H]Personalinformation|[H]Personalinformation andheweighs199lb).
[H]Born:|(1947-08-30)August30,1947(age73)
[[Ponca_City,_Oklahoma|PoncaCity,Oklahoma]]
[H]Height:|6ft2in(1.88m)
[H]Weight:|262lb(119kg)[...]
Table5: ExamplesfromeachofthesourcedatasetsusedinCoverBench. Thelabelsaretrueorfalse.
12