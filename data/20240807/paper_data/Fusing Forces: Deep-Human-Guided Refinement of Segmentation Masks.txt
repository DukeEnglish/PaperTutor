Fusing Forces: Deep-Human-Guided Refinement
of Segmentation Masks⋆
Rafael Sterzinger , Christian Stippel , and Robert Sablatnig
Computer Vision Lab, TU Wien, Vienna, AUT
{firstname.lastname}@tuwien.ac.at
Abstract. Etruscan mirrors constitute a significant category in Etr-
uscanart,characterizedbyelaboratefigurativeillustrationsfeaturedon
their backside. A laborious and costly aspect of their analysis and doc-
umentation is the task of manually tracing these illustrations. In pre-
vious work, a methodology has been proposed to automate this pro-
cess, involving photometric-stereo scanning in combination with deep
neural networks. While achieving quantitative performance akin to an
expert annotator, some results still lack qualitative precision and, thus,
require annotators for inspection and potential correction, maintaining
resourceintensity.Inresponse,weproposeadeepneuralnetworktrained
to interactively refine existing annotations based on human guidance.
Ourhuman-in-the-loopapproachstreamlinesannotation,achievingequal
qualitywithupto75%lessmanualinputrequired.Moreover,duringthe
refinement process, the relative improvement of our methodology over
pure manual labeling reaches peak values of up to 26%, attaining dras-
tically better quality quicker. By being tailored to the complex task of
segmenting intricate lines, specifically distinguishing it from previous
methods, our approach offers drastic improvements in efficacy, transfer-
able to a broad spectrum of applications beyond Etruscan mirrors.
Keywords: Binarization · Interactive Segmentation · Human-in-the-
Loop · Etruscan Art · Cultural Heritage
1 Introduction
With more than 3,000 identified specimens, Etruscan hand mirrors represent
one of the biggest categories within Etruscan art. On the front, these ancient
artworks feature a highly polished surface, whereas, on the back, they typically
depictengravedand/orchasedfigurativeillustrationsofGreekmythology[5].A
primary component of their examination involves the labor- and cost-intensive
taskofmanuallytracingtheartworks;anexemplarymirrorisillustratedinFig.2
together with the sought-after tracing.
⋆ This project has received funding from the Austrian Science Fund/O¨sterreichischer
Wissenschaftsfonds (FWF) under grant agreement No. P 33721.
4202
guA
6
]VC.sc[
1v40330.8042:viXra2 R. Sterzinger et al.
(a) Initial Prediction Y (b) Human Interaction ∆ (c) Refined Prediction Y′
Fig.1: Illustrating interactive refinement of segmentation masks: Starting from
an initial segmentation Y, the user can add (∆+) or erase (∆−) parts to bring
itclosertothegroundtruthY∗ (inblue),creatinganupdatedmaskY∆.Next,
using a separate model conditioned on the human input ∆ and Y, we aim that
for the refined segmentation Y′ it holds that ||Y′−Y∗|| <||Y∆−Y∗|| .
1 1
In previous works, Sterzinger et al. [13] propose a methodology to automate
the segmentation process through photometric-stereo scanning in combination
with deep learning; expediting the process of manual tracing and contributing
to increased objectivity. Although their segmentation model – trained on depth
maps of Etruscan mirrors to recognize intentional lines over scratches – already
quantitatively achieves performance on par with an expert annotator, in some
instances it lags behind. Based on this, manual inspection and potential refine-
ment by humans are still required, therefore, although alleviated, the tracing
remains resource-intensive.
In this paper, we continue their line of work and propose a methodology to
simplifytheremainingrequiredrefinementbyaddinginteractivitytotheprocess:
Startingfromaninitialprediction,weaimtoreachqualitativelysatisfyingresults
as quickly as possible while keeping necessary labor to a minimum. We achieve
this by training a deep neural network to refine the initial segmentation based
on a series of hints, i.e., parts being added or erased, illustrated in Fig. 1.
In summary, our contribution entails the development of an interactive re-
finementnetworkforimprovedannotationresultsobtainedinlesstime,requiring
less labor. Compared to refining the initial segmentation manually, fusing forces
andperformingtherefinementinteractivelyoffersnotonlyadrasticreductioninDeep-Human-Guided Refinement of Segmentation Masks 3
labor(upto-75%)butalsoexpeditestheprocessbyattainingsignificantrelative
performanceimprovementsovermanuallabeling(upto+26%).Wedifferentiate
ourselvesfrompriorworkbyproposingamethodologytailoredspecificallytothe
task of segmenting intricate lines scattered across, in our case, Etruscan mirrors
versus,e.g.,segmentinglocally-concentratedhepaticlesions[1].Additionally,in-
steadofstartingfromscratch,westartfromaninitialprediction,asteprequired
due to the non-locality of lines as otherwise labor would be drastically higher.
Finally, we provide public access to both the code and data utilized in this
work (see github.com/RafaelSterzinger/etmira-interaction) to promote trans-
parency and reproducibility.
(a) High-Pass Filtered Depth Map (b) Ground Truth Segmentation Mask
Fig.2: Etruscan mirrors typically feature scenes from Greek mythology. During
their examination, archaeologists seek to extract the drawings for visualization.
2 Related Work
Segmentation: Inthefieldofimagesegmentation,techniquesareledbyadvanced
deep learning architectures such as the UNet [12], DeepLabV3++ [2], Pyramid
Attention Network [7], etc. These advancements are particularly propelled by
industries where precise segmentation is paramount: For example, in medical
imaging, intricate segmentations are crucial for identifying vascular structures
within the retina, a crucial aspect for diagnosing retinal diseases [8].
Photometric Stereo: When considering historical artifacts where the content of
interest is engraved or chased into the object, as is the case with Etruscan mir-4 R. Sterzinger et al.
rors,insteadofRGB,modalitiesthatcapturesurfacedetailsarepotentiallybet-
ter suited. Photometric Stereo (PS), a technique introduced by Woodham [17],
allowsforcapturingsuchdetails,providinginsightsintothesurfacegeometryof
an object. For instance, McGunnigle and Chantler [10] extract handwriting on
paper based on depth profiles. In addition to this, PS is also employed, e.g., to
detectcracksinsteelsurfaces[6],extractleafvenation[20],ordetectairvoidsin
concrete [16]. In the context of Etruscan mirrors, Sterzinger et al. [13] resort to
a deep-learning-based segmentation approach due to the damage these mirrors
have sustained. By integrating PS-scanning with deep segmentation, they learn
to recognize intentional lines over scratches.
Interactive Segmentation: Independent of the segmentation methodology em-
ployed,resultingmasksmightnotmeetperformancerequirementsand,therefore,
requirecorrection.Withthisregard,Lietal.[8],introduceIterNet,aUNet-based
iterative approach to enforce connectivity of retinal vessels post segmentation,
requiringno-externalinput.Similarly,interactivemethodsexistthatincorporate
humanexpertisewithintheprocess.Xuetal.[18]andMahadevanetal.[9]focus
onobjectsegmentationbasedonmouseclicks.Ontheotherhandandclosestto
our work, Amrehn et al. [1], propose an approach that refines the segmentation
based on pictorial scribbles for hepatic lesions.
3 Methodology
In the following we will detail our methodology comprised of:
– the dataset; general information, splitting the data into training, validation,
and testing, as well as, the preprocessing of depth maps
– the simulation of human interaction; details on the statistics of engravings,
acquiringindividuallinesegments,andtheprocedureforaddinganderasing
– thearchitecture;describingtheoveralldeepneuralnetworkusedforrefining
the initial segmentation
3.1 Dataset
Our dataset includes a diverse array of Etruscan mirrors from public collections
in Austria. It consists of PS-scans of 59 mirrors, with 53 located at the Kun-
sthistorischen Museum (KHM) Wien and the remaining 6 scattered throughout
Austria. Annotations were acquired for 19 mirrors, encompassing 19 backsides
and10fronts,resultinginatotalof29annotatedexamples.Notably,engravings
predominantly adorn the backside to avoid interference with reflectance, how-
ever, they are also occasionally found on the front, albeit with less density, near
the handle or around the border. For information on the acquisition process, we
refer the reader to Sterzinger et al. [13].
Dividing these annotations into training, validation, and test sets is chal-
lengingduetothreefactors:limitedsamplesize,strongvariationsinthedensityDeep-Human-Guided Refinement of Segmentation Masks 5
of engravings, and overall mirror conditions. Mirrors with dense engravings are
prioritized for training due to the stronger learning signal they offer. To en-
surefairevaluation,weselectthreemirrorsofdifferentconditionsandengraving
densities for testing: one from Wels and two from the KHM Wien. We create
non-overlappingpatchesofsize512×512pixels,shuffle,andsplittheminhalfto
form the validation and test set of similar underlying distributions. One outlier,
characterizedbyadifferentartstyle(pointsinsteadoflines),isexcluded,leaving
25 annotated samples for training.
Preprocessing With regards to preprocessing, we employ the depth modality
(whichworkedbestaccordingto[13])andremovelowfrequencies.Weaccomplish
this by subtracting a Gaussian-filtered version of the depth map with values
capped between µ±3σ. In addition, employing the Segment Anything Model
(SAM)[4],globalsegmentationmasksaregeneratedtoidentifythemirrorobject
withinashot.Weusethesemaskstodifferentiatebetweenmirrorandnon-mirror
parts (see Fig. 4; compare red versus green, top-left), for instance, to calculate
per-channel means and standard deviations only on mirror parts which we use
to normalize the input.
Addressingthelackofannotations,aper-patchinferenceapproachisadopted.
For validation and testing, non-overlapping quadratic patches measuring 512×
512 pixels are extracted. Regarding our training data, we pad four pixels, since
6720≡0 (mod 2240),totheoriginalresolution(8,964×6,716pixels)toextract
25 overlapping tiles of size 2,988×2,240 pixels using a stride of half the size;
tiles, containing no annotation, are discarded. Diversifying the dataset for each
epoch, ten patches per tile are extracted, all resized to dimensions of 256×256
pixels to streamline model complexity.
3.2 Simulation of Human Interaction
Inordertosimulaterealistichumaninteractions,wefirstlookintothestatistics
of the annotations included in the dataset; necessary to quantitatively capture
human-stroke width. Next, to refine initial predictions, we describe the process
offilteringandcorrectingfalsepositivesandnegatives.Withinthis,wemotivate
and denote the algorithm used to extract line segments. Tying all components
together, we finally describe simulating human interaction: Starting from either
false positives or negatives, we extract the largest error segment and provide a
hint in the form of a line with width taken from the acquired statistics of the
ground truth annotations.
Statistics With the goal of simulating realistic interaction, one crucial compo-
nent to consider is the stroke width. For this, we look into the statistics of the
annotations included in our dataset by extracting individual thickness, using
Algorithm 1: Starting from a binary mask, the ground truth Y∗ in our case,
we obtain distance information via the euclidean distance transform which,
for each pixel, returns the Euclidean distance in pixels to the closest non-mask6 R. Sterzinger et al.
Algorithm 1: Calculating Stroke Widths for Statistics
Data: ground truth Y∗
def get stroke widths(Y∗):
distance map ← euclidean distance transform(Y∗)
gt skelet ← skeletonize(Y∗)
return distance map[gt skelet]
pixel. Next, employing skeletonize [19], we acquire a skeletonized version of
the input (essential the center of lines), used to extract the thickness at each
section.
From this information, we calculate initial µ and σ of the collected line
widths, which we use to remove outliers (long right tail) using the two-sigma
rule,keepingvalueswithintwostandarddeviations,toobtainfinalµ=6.19and
σ = 1.49. Based on this filtered set of stroke widths, we fit a Gamma distribu-
tionG fromwhichwecanrandomlysamplerealisticwidths.Fig.3visualizesthe
distribution of stroke widths as well as the fitted distribution G.
Mean: 6.19
Gamma Fit
0.25
0.20
0.15
0.10
0.05
0.00
0 2 4 6 8 10 12
Line Width
Fig.3: Illustration of the distribution of stroke widths: After removing outliers
from our data, using the two-sigma rule, we fit a Gamma distribution (shape-
parameter a=49.13, loc=−4.28, scale=0.21).
ytisneDDeep-Human-Guided Refinement of Segmentation Masks 7
Operations In general, when an expert annotator is entrusted with the task
ofrefiningsegmentationmasks,oneoftwooperationswillbeperformed:adding
missing parts or erasing superfluous ones. Simulating these operations consists
of multiple steps: (1) finding an area that requires correction (we assume areas
will be selected in decreasing order depending on the magnitude of correction
required), (2) deciding on an operation, and (3) performing the operation. In
essence, however, steps (1) and (2) go hand in hand, i.e., when deciding on an
area based on error, the operation to be performed is already clear.
Let Y = f (X) ∈ BH,W be the initial segmentation mask produced by a
init
baselinenetworkf basedonthedepthmapX∈RH,W.Giventhatwegener-
init
allyworkwithpatches,usingthisinitialmask,wefindthesegmentthatrequires
the most correction w.r.t. our ground truth Y∗, considering the pFM (formally
introduced in Section 4).
Algorithm 2: False Positive/Negative Detection for ∆−/∆+
Data: ground truth Y∗, prediction Y, line statistics µ and σ
def get add(Y∗, Y):
gt skelet ← skeletonize(Y∗)
false negatives ← gt skelet ∧ ¬ Y
return false negatives
def get erase(Y∗, Y, µ, σ):
// dilate gt for more lenient detection
expanded gt ← dilate(skeletonize(Y∗), round(µ + 2σ))
pred skelet ← skeletonize(Y)
false positives ← ¬expanded gt ∧ pred skelet
return false positives
Next, for the remaining steps, we propose Algorithms 2 and 3: For (2), we
first employ Algorithm 2 to obtain a binary mask of missing or superfluous
skeletonized segments, i.e., false positives or negatives. Note that in order to
avoid the correction of minor superfluous parts, in get erase, we dilate the
ground truth to a constant of µ+2σ s.t. only false positives which drastically
diverge from Y∗ will be detected.
After obtaining skeletonized binary masks for false positives and negatives,
for step (3), we obtain, for both, the longest line segment utilizing Algorithm 3.
Within Algorithm 3, we leverage a key property of skeletonizing: In a pixel-
based, skeletonized representation (i.e., one where lines have been reduced to
theirmedialaxis,whichis1-pixelwide),asinglecontinuousline,willhaveexactly
two neighbors in its 8-neighborhood, except for endpoints and junctions.
Let∆+ ∈{0,+1}H,W and∆− ∈{0,−1}H,W denotethemissing/superfluous
linesegmentthatwillbeadded/erased.Sincetheseoperationswillbeperformed
interactively, we summarize with ∆ multiple interactions and thus contains val-
ues {−1,0,+1}. Finally, we combine previous interactions ∆ with ∆+ or ∆−8 R. Sterzinger et al.
Algorithm 3: Obtain Edge Segments, Sorted by Length
Data: skeletonized mask S
   
1 1 1 111
Let K
edge
=1101 and K
label
=111.
1 1 1 111
def get edges(S):
conv skelet ← convolve(S, kernel=K )
edge
edges ← conv skelet == 12
// 8-connectivity
edge list ← label connectivity(edges, kernel=K )
label
edge list ← sort(edge list, ord=’desc’)
return edge list
by leaving previously set values of ±1 fixed, only updating 0-valued values. For
simplicity, we introduce Y∆, a quantity which denotes the union between the
initial prediction Y and the human interactions ∆, i.e.:

1 if ∆ ==+1
 i,j
Y∆ = 0 if ∆ ==−1 (1)
i,j i,j
Y
otherwise.
i,j
Interaction After introducing the three necessary steps for the adding/erasing
operation, we move on to performing realistic human interactions: We continue
from the previously found quantities ∆+ or ∆− for adding missing/erasing
superfluous segments and either pick one of the two at random during training
or the longer segment for maximum correction during inference. Within the
skeletonized segment, we proceed by randomly sampling a sub-segment of up
to eleven pixels (a parameter that we did not vary) and dilating it, based on
the statistics of G, with one of the following: (a) a width sampled from the
distribution, (b) the mean µ, or (c) a width of µ−2σ.
In Section 4, options (a) and (b) will be evaluated w.r.t. validation perfor-
mance, and option (c) will be used for the final evaluation on whole mirrors s.t.
human interactions are with high probability aligned with Y∗, i.e., reduce the
risk of strokes being too wide.
Finally,usingaseparatenetworkf ,trainedtorefineY conditionedon∆
iter
andX,weobtainarefinedpredictionY′.Withthis,wemotivatetheinteractivity
of our method: Starting over, i.e., Y ← Y′, we again find the segment that
requiresthemostcorrectionandupdate∆withnewlyfound∆+/∆−.Ageneral
overviewoftheinteractivityisprovidedbyFig.4,illustratinginferenceonaper-
patch level, the initial prediction Y and its refinement over time, based on ∆.Deep-Human-Guided Refinement of Segmentation Masks 9
Fig.4: An illustration of the overall methodology: In general, segmentation is
performed on a per-patch level (512×512, resized to 256×256; red denotes
patches that are filtered a priori using SAM [4]). In an interactive paradigm,
startingfromtheinitialpredictionY attimestept ,basedoninputX,ahuman
0
provides hints in the form of ∆ (the “union” between Y and ∆ is denoted
with Y∆), on which a separately trained network f is conditioned on to
iter
produce a refined mask at timestep t .
1
3.3 Architecture
With regards to our architecture, we employ a UNet [12] with an EfficientNet-
B6[15]followingtheproposalbySterzingeretal.[13]butexpandupontheinput
to condition the network on the (simulated) human input ∆. For clarification,
the input is now comprised of a 3×H×W tensor, including the depth map X,
the human input ∆, as well as the initial prediction Y with all three quantities
concatenated. Given that our data resources are limited, we train on a per-
patch-levelemployingaugmentationsamongwhicharerotations,flips,andshifts,
optimizingtheDiceloss.FortheinitialpredictionY,weemploytheexactsame
methodology as proposed by Sterzinger et al. [13].10 R. Sterzinger et al.
4 Evaluation
In this section, we evaluate our design choices: During this process, we report
the Intersection-over-Union (IoU) as well as the pseudo-F-Measure (pFM), a
metric commonly used for evaluating the binarization quality of handwritten
documents. It is thus well-suited for our binarization task, i.e., a task where
shifting the mask by a single pixel will have a significant impact on per-pixel
metrics. Compared to the standard F-Measure, the pFM relies on the pseudo-
Recall (p-Recall) which is calculated based on the skeleton of Y∗ [11]:
2×p-Recall(Y′,Y∗)×Precision(Y′,Y∗)
pFM(Y′,Y∗)= (2)
p-Recall(Y′,Y∗)+Precision(Y′,Y∗)
Given that we work within an interactive paradigm, we are required to also
provide a metric that excludes the human input ∆ from the evaluation and
hence report the relative pFM improvement over Y∆, i.e.:
pFM(Y′,Y∗)−pFM(Y∆,Y∗)
pFM (Y′,Y∆,Y∗)= (3)
∆ pFM(Y∆,Y∗)
In addition, based on the fact that during training we introduce random-
ness, i.e., by chance, missing parts can be added (∆+) or superfluous ones
erased (∆−), and that sub-segments are sampled and dilated at random, we
evaluate on the test/validation set five times and report the average.
4.1 Training
Our model f is trained on an NVIDIA RTX A5000 until convergence, i.e.,
iter
no improvement ≥1e−3 w.r.t. the pFM (see Equation 3) for ten consecutive
∆
epochs, using a batch size of 32 and a learning rate of 3e−4. As a loss function,
weemployageneralizedDiceoverlap(Diceloss)thatiswellsuitedforhighlyun-
balanced segmentation masks [14] and optimize it using Adam [3]. Additionally,
we incorporate a learning rate scheduler that also monitors the pFM on our
∆
validation set: If there is no improvement for three consecutive training epochs,
the learning rate is halved.
4.2 Ablation Study
In the following, we present our ablation study, focusing on input options, dif-
ferent stroke widths (widths kept fixed and sampled randomly), as well as the
necessity of our two operations (add and erase).
Input Options: Starting with the evaluation of different input options and their
impact on the predictive patch-wise performance of f (fixed stroke width,
iter
one interaction; results are denoted in Table 1): As expected, simply iterat-
ing over the initial prediction Y (stemming from network f ) results in no
init
improvement, rendering the human an essential part of the refinement process.Deep-Human-Guided Refinement of Segmentation Masks 11
Table 1: Evaluating input options and their effect on the per-patch predictive
performance (fixed stroke width, one interaction): Iterating over Y again does
not cause improvement whereas providing ∆ yields ca. +6% over Y∆. Note
that, although part of the input, we hide X for clarity.
Input Modality IoU pFM pFM
∆
Init. Prediction [13] - 32.86 49.28 −
Prediction Y 32.72 49.27 −
Interaction ∆ 35.83±.1 53.60±.2 +5.8±.23%
Both Y,∆ 36.04±.2 53.44±.3 +5.5±.55%
Moreover,bymeansofhumanguidance,i.e.,providing∆,thenetworkcaneffec-
tively leverage additional information on missing or superfluous parts, resulting
in an increase of around +6% over Y∆. Finally, when utilizing both Y and ∆,
we attain a comparable improvement over Y∆, with the difference deemed not
statistically significant at a confidence level of 95%. However, the latter results
in faster convergence, the reason for which we proceed with this option.
Stroke Widths: Next, we consider different options for the stroke width during
the simulation of human interaction, namely: (a) keeping the stroke width con-
stant at µ and (b) sampling it from G. Our evaluation reveals that sampling
does not significantly improve performance, with results showing +5.5±.55%
improvement for fixed width versus +4.9±.35% for sampled one.
Table 2: Evaluating the impact of adding and erasing when refining mirror
ANSA-1700: Employing both operations will result in the highest pFM of
∆
ca.+12%,whereaddinghasagreaterimpact(ca.+8%)thanerasing(ca.+2%);
note that results are reported at the maximum pFM .
∆
Interaction IoU pFM pFM
∆
Only Erasing ∆− 38.25±.06 58.92±.07 +1.9±.12%
Only Adding ∆+ 55.19±.13 73.55±.11 +8.4±.16%
Both ∆ 58.41±.28 76.56±.16 +12.3±.17%
Operations: In order to illustrate the necessity of our two operations, namely
adding ∆+ and erasing ∆−, we perform multiple interactions until convergence
and report results at the maximum attained pFM . For this, we inspect an
∆
entire mirror, ANSA-1700: Employing both operations jointly yields the highest
pFM of approximately +12% (redline in Fig. 5). Notably, add has a more
∆
significantimpact(ca.+8%)comparedtoerase (ca.+2%).However,thisisvery12 R. Sterzinger et al.
dependent on the initial prediction, thus only demonstrating that one operation
supplements the other.
Insummary,comparedtotheinitialpredictionY,stemmingfromf ,pro-
init
viding human guidance via ∆ will yield improvements exceeding Y∆, utilizing
bothoperationsisbeneficial,andaugmentingstrokewidthsbyrandomsampling
performs worse than leaving it constant.
n 430
+25%
n 880
+20%
+15%
n 1510
+10%
+5%
ANSA-VI-1701
Wels-11944
ANSA-VI-1700
+0%
0% 20% 40% 60% 80% 100%
Number of Interactions until Convergence
Fig.5: An illustration of pFM , i.e., the relative pFM improvement of our
∆
method over pure manual refinement; n denotes the number of human inter-
actions: With the relative improvement peaking at values between ca. +12%
and +26%, our human-in-the-loop approach immediately overtakes manual la-
beling, leading to drastically better annotations earlier.
5 Results
After verifying the effectiveness of our methodology, we pick the three mirrors
from our validation/test set, namely ANSA-1700, ANSA-1701, and Wels-11944,
andevaluateourhuman-in-the-loopapproachonwholemirrors,performingmul-
tipleinteractions(limitedto3,000;typicallyrequiringmuchless).Again,dueto
the introduced randomness, we repeat this process ten times and report the av-
erageresult,skippingthevariationasitisnegligible.AsdescribedinSection4.2,
for this, we start greedily by selecting the patch with the lowest pFM, simulate
adding missing/erasing superfluous parts, selecting the operation which yields a
tnemevorpmI
erusaeM-F
oduesP
.leRDeep-Human-Guided Refinement of Segmentation Masks 13
larger improvement, refine the prediction based on the additional human input,
and proceed from there until convergence, i.e., when neither adding nor erasing
by itself increases the metric. We report the results of this in two figures: Fig. 5,
which illustrates the relative pFM improvement over-performed interactions, as
well as Fig. 6, which depicts potential reduction in annotation workload when
employing our proposed interactive refinement paradigm.
Inspecting Fig. 5, we observe for all three mirrors significant relative im-
provements over the purely manual annotation baseline Y∆ when employing
our method, with maximum improvements ranging from +12% to +26% de-
pending on the mirror under consideration. Based on these results, we conclude
thatourhuman-in-the-loopapproachquicklyovertakesmanuallabeling,leading
to drastically better annotations at an earlier stage. Interestingly, towards the
end, relative improvement starts to decrease slightly before convergence (most
notably for ANSA-1701), showcasing that at a point, the network will undo
previously correctly annotated parts.
140k
127.7k Manual
Interactive
120k
100k
80k
68.7k
60k -55.6%
40k 34.9k
20k -75.4%
-67.1%
0k
ANSA-VI-1700_R ANSA-VI-1701_R Wels-11944_R
Fig.6: An illustration of reduced workload: At convergence, our interactive ap-
proachrequiresdrasticallyfewerannotatedpixelstoreachequalperformancein
pFM, resulting in a reduction of annotation effort ranging from 56% to 75%.
In Fig. 6, we directly contrast pure manual refinement against our interac-
tive approach. For this, we determine the maximum attained pFM, calculated
usingY∆,whichcorrespondstothefinalsimulatedhumaninteraction.Wethen
compare the amount of required human input to the human input necessary to
reachequalorhigherperformanceusingourproposedmethod.Bydoingthis,we
namuH
yb
detatonnA
slexiP14 R. Sterzinger et al.
are able to report a notion of workload reduction: Depending on the mirror un-
derinspection,annotationrequirementswillexperienceareductionrangingfrom
around-56%to-75%,positioningourmodelwelltobeemployedforsimplifying
the task of correcting erroneous segmentation masks.
6 Limitations and Future Work
Whileourproposedmethodshowspromisingresults,itisimportanttoacknowl-
edge its limitations: At the moment human guidance aids refinement only lo-
cally, i.e., modifications happen just in the vicinity of the provided annotation.
Movingforward,onecouldfocusonfurtherrefiningourmethodologybyexplor-
ing additional techniques to enhance efficiency. For instance, it would be mean-
ingfultoinvestigatetheintegrationofquicklytrainablelearningalgorithms,such
as Gaussian processes which can immediately be adapted to newly provided an-
notation and thus allow for global adjustments, potentially further reducing the
amount of human input required. Additionally, leveraging Gaussian processes is
accompanied by the option of active learning strategies, which could allow the
identificationandannotationofpatcheswherethemodelismostuncertainwith
the chance of expediting refinement further.
7 Conclusion
Insummary,ourresearchaddressesthelabor-intensiveprocessofmanuallytrac-
ingintricatefigurativeillustrationsfound,forinstance,onancientEtruscanmir-
rors. In an attempt to automate this process, previous work has proposed the
useofphotometric-stereoscanninginconjunctionwithdeepneuralnetworks.By
doing so, quantitative performance comparable to expert annotators has been
achieved; however, in some instances, they still lack precision, necessitating cor-
rectionthroughhumanlabor.Inresponsetotheremainingresourceintensity,we
proposedahuman-in-the-loopapproachthatstreamlinestheannotationprocess
by training a deep neural network to interactively refine existing annotations
based on human guidance. For this, we first developed a methodology to mimic
human annotation behavior: We began by analyzing annotation statistics to
capture stroke widths accurately and proceeded by introducing algorithms to
select erroneous patches, identify false positives and negatives, as well as cor-
rect them by erasing superfluous or adding missing parts. Next, we verified our
design choices by conducting an ablation study; its results showed that provid-
inghumanguidancewillyieldimprovementsexceedingpuremanualannotation,
utilizing both operations is beneficial, and augmenting stroke widths by ran-
dom sampling performs worse than leaving it constant. Finally, we evaluated
our method by considering mirrors from our test and validation set. Here, we
achieved equal quality annotations with up to 75% less manual input required.
Moreover,therelativeimprovementoverpuremanuallabelingreachedpeakval-
uesofupto26%,highlightingtheefficacyofourapproachinreachingdrastically
better results earlier.Deep-Human-Guided Refinement of Segmentation Masks 15
References
1. Amrehn, M., Gaube, S., Unberath, M., Schebesch, F., Horz, T., Strumia, M.,
Steidl,S.,Kowarschik,M.,Maier,A.K.:UI-Net:InteractiveArtificialNeuralNet-
works for Iterative Image Segmentation Based on a User Model. arXiv preprint
arXiv:1709.03450 (2017)
2. Chen, L.C., Zhu, Y., Papandreou, G., Schroff, F., Adam, H.: Encoder-Decoder
withAtrousSeparableConvolutionforSemanticImageSegmentation,p.833–851.
Springer International Publishing (2018)
3. Kingma,D.,Ba,J.:Adam:AMethodforStochasticOptimization.In:International
Conference on Learning Representations (ICLR). San Diega, CA, USA (2015)
4. Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland, C., Gustafson, L., Xiao, T.,
Whitehead,S.,Berg,A.C.,Lo,W.Y.,Dollar,P.,Girshick,R.:SegmentAnything.
In: Proceedings of the IEEE/CVF International Conference on Computer Vision
(ICCV). pp. 4015–4026 (Oct 2023)
5. Kluge, S.: Through the Looking-Glass: Der etruskische Spiegel VI 2627 aus dem
Bestand des Kunsthistorischen Museums als Fallbeispiel fu¨r die rituelle Manip-
ulation und Defunktionalisierung im Kontext der Grablege in der etruskischen
Kultur. In: Weidinger, A., Leskovar, J. (eds.) Interpretierte Eisenzeiten. Fallstu-
dien, Methoden, Theorie. Tagungsbeitra¨ge der 10. Linzer Gespra¨che zur inter-
pretativen Eisenzeitarcha¨ologie, pp. 241–254. Studien zur Kulturgeschichte von
Ober¨osterreich, Folge 55, Linz (2024)
6. Landstrom, A., Thurley, M.J., Jonsson, H.: Sub-Millimeter Crack Detection in
Casted Steel Using Color Photometric Stereo. In: 2013 International Conference
on Digital Image Computing: Techniques and Applications (DICTA). IEEE (Nov
2013)
7. Li,H.,Xiong,P.,An,J.,Wang,L.:PyramidAttentionNetworkforSemanticSeg-
mentation. In: British Machine Vision Conference 2018, BMVC 2018, Newcastle,
UK, September 3-6, 2018. p. 285. BMVA Press (2018)
8. Li, L., Verma, M., Nakashima, Y., Nagahara, H., Kawasaki, R.: IterNet: Retinal
ImageSegmentationUtilizingStructuralRedundancyinVesselNetworks.In:2020
IEEE Winter Conference on Applications of Computer Vision (WACV). IEEE
(Mar 2020)
9. Mahadevan,S.,Voigtlaender,P.,Leibe,B.:Iterativelytrainedinteractivesegmen-
tation. In: British Machine Vision Conference 2018, BMVC 2018, Newcastle, UK,
September 3-6, 2018. p. 212. BMVA Press (2018)
10. McGunnigle, G., Chantler, M.: Resolving handwriting from background printing
using photometric stereo. Pattern Recognition 36(8), 1869–1879 (Aug 2003)
11. Pratikakis, I., Gatos, B., Ntirogiannis, K.: ICFHR 2012 Competition on Hand-
written Document Image Binarization (H-DIBCO 2012). In: 2012 International
Conference on Frontiers in Handwriting Recognition. IEEE (Sep 2012)
12. Ronneberger,O.,Fischer,P.,Brox,T.:U-Net:ConvolutionalNetworksforBiomed-
ical Image Segmentation, p. 234–241. Springer International Publishing (2015)
13. Sterzinger, R., Brenner, S., Sablatnig, R.: Drawing the Line: Deep Segmentation
for Extracting Art from Ancient Etruscan Mirrors. In: 2024 ICDAR International
Conference on Document Analysis and Recognition, submitted (2024)
14. Sudre,C.H.,Li,W.,Vercauteren,T.,Ourselin,S.,JorgeCardoso,M.:Generalised
DiceOverlapasaDeepLearningLossFunctionforHighlyUnbalancedSegmenta-
tions, p. 240–248. Springer International Publishing (2017)16 R. Sterzinger et al.
15. Tan,M.,Le,Q.V.:EfficientNet:RethinkingModelScalingforConvolutionalNeural
Networks. In: Chaudhuri, K., Salakhutdinov, R. (eds.) Proceedings of the 36th
InternationalConferenceonMachineLearning,ICML2019,9-15June2019,Long
Beach, California, USA. Proceedings of Machine Learning Research, vol. 97, pp.
6105–6114. PMLR (2019)
16. Tao, J., Gong, H., Wang, F., Luo, X., Qiu, X., Huang, Y.: Automated image
segmentation of air voids in hardened concrete surface using photometric stereo
method. International Journal of Pavement Engineering 23(14), 5168–5185 (Nov
2021)
17. Woodham, R.J.: Photometric method for determining surface orientation from
multiple images. Optical Engineering 19(1) (Feb 1980)
18. Xu, N., Price, B.L., Cohen, S., Yang, J., Huang, T.S.: Deep Interactive Object
Selection.In:2016IEEEConferenceonComputerVisionandPatternRecognition,
CVPR2016,LasVegas,NV,USA,June27-30,2016.pp.373–381.IEEEComputer
Society (2016)
19. Zhang, T.Y., Suen, C.Y.: A fast parallel algorithm for thinning digital patterns.
Communications of the ACM 27(3), 236–239 (Mar 1984)
20. Zhang, W., Hansen, M.F., Smith, M., Smith, L., Grieve, B.: Photometric stereo
for three-dimensional leaf venation extraction. Computers in Industry 98, 56–67
(Jun 2018)