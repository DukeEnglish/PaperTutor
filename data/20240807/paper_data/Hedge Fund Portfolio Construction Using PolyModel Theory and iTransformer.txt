Hedge Fund Portfolio Construction Using PolyModel Theory
and iTransformer
Siqiao Zhao∗ Zhikang Dong Zeyu Cao
Morgan Stanley Stony Brook University Barclays Capital
alysia.zhao@gmail.com zhikang.dong.1@stonybrook.edu josephcao891011@gmail.com
Raphael Douady
University of Paris I: Pantheon-Sorbonne
rdouady@gmail.com
1 Introduction
Portfolio construction remains a central topic in quantitative finance research. Beginning with the
Capital Asset Pricing Model (CAPM) [FF04], the theory of portfolio construction has continuously
evolved, incorporating a range of new techniques and theories over time. Data-driven methods,
particularly in fields like computer vision [LLSH23, DKP24, RKH+21, KDP23], audio processing
[GCG21, DLC+24, LDZ24], and science [AAD+24, DP23], have shown significant advancements. In
recentyears,thosetechniqueshavenotablyimpactedquantitativefinance,frompredictingassetprices
[KSV22] to hedging risks in derivatives [BGTW19].
However, when constructing portfolios, a key problem is that a lot of financial time series data are
sparse,makingitchallengingtoapplymachinelearningmethods. Polymodeltheorycansolvethisissue
and demonstrate superiority in portfolio construction from various aspects. To implement the Poly-
Model theory for constructing a hedge fund portfolio, we begin by identifying an asset pool, utilizing
over 10,000 hedge funds for the past 29 years’ data. PolyModel theory also involves choosing a wide-
ranging set of risk factors, which includes various financial indices, currencies and commodity prices.
This comprehensive selection mirrors the complexities of the real-world environment. Leveraging on
the PolyModel theory, we create quantitative measures such as Longterm Alpha, Long-term Ratio,
and SVaR. We also use more classical measures like the Sharpe ratio or Morningstar’s MRAR. To en-
hancetheperformanceoftheconstructedportfolio,wealsoemploythelatestdeeplearningtechniques
(iTransformer) to capture the upward trend, while efficiently controlling the downside, using all the
features. TheiTransformermodelisspecificallydesignedtoaddressthechallengesinhigh-dimensional
timeseriesforecastingandcouldlargelyimprovesourstrategies. Moreprecisely,ourstrategiesachieve
better Sharpe ratio and annualized return. The above process enables us to create multiple portfolio
strategiesaimingforhighreturnsandlowriskswhencomparedtovariousbenchmarks. Theintegration
ofPolyModeltheorywithmachinelearningmethodsfacilitatesanuancedandpreciseunderstandingof
hedge fund returns. This amalgamation enables us to overcome challenges related to hedge fund data,
offering a more robust methodology for analyzing hedge fund performance and guiding investment
decisions. This is a very meaningful attempt to combine fundamental statistical analysis with latest
machine learning techniques.
2 PolyModel Theory
The origin of the idea of PolyModel theory and its mathematical foundations can be dated back to
[CDM10] and [CDZ10]. Since PolyModel theory is more a framework rather than a single statistical
analysis tool, after its first introduction, quite a few extensions and applications have been proposed
and studied. For a nice overview of more applications and the history of this theory, one can check
∗Correspondingauthor.
1
4202
guA
6
]MP.nif-q[
1v02330.8042:viXra[Dou19] while for more concise mathematical description and its implementation, one can consult
[BD22] and [Zha23].
Before we step into the mathematical descriptions, let’s first discuss the core idea and intuition
behind PolyModel theory to get a better understand of it.
The core idea of PolyModel theory is to combine a large enough collection of valid description of
one aspect of the same target or reality in order to get a as close as possible fully understanding of
the target’s nature. In financial industry, the target is usually the return of some asset in which one
wants to invest.
If we image that the target is alive, like an animal, then PolyModel theory can be regarded as a
methodology to observe how this animal reacts to the outside environment, especially, to each single
environment factor. If we can capture and understand all its reactions, then we can fully characterize
this animal. This idea is, surprisingly, similar to a Python terminology called ”Duck Typing”: ”when
anobjectquackslikeaduck,swimslikeaduck,eatslikeaduckorsimplyactslikeaduck,thatobjectis
aduck.”Thoughcomingfromverydifferentfields, thetwoideasintroducedabovecanbothbeviewed
as an variant of Phenomenology [BD22]: ”Literally, phenomenology is the study of ’phenomena’:
appearances of things, or things as they appear in our experience, or the ways we experience things,
thus the meanings things have in our experience.”
After the high-level description of PolyModel theory, we now turn back to its mathematical de-
scriptions and how to construct features with strong description or prediction power.
2.1 Mathematical formulation and model estimation
2.1.1 Model description and estimation
There are two fundamental components in PolyModel theory:
• Apooloftargetassets{Y } whicharethecomponentsoftheportfoliosonewanttoconstruct.
i i∈I
• A very large pool of risk factors {X } which form a proxy of the real-world financial environ-
j j∈J
ment.
The mathematical description of the PolyModel theory can be formulated as follows:
For every target Y , i∈I, there is a collection of (relatively simple) regression models:
i

Y =Φ (X )+ϵ
Yi =Φi1 (X1 )+ϵ1
i i2 2 2 (1)
. Y.... =.
Φ (X )+ϵ
i in n n
where
• n is the number of the risk factors.
• Φ isassumedtocapturethemajorrelationshipbetweenindependentvariableX anddependent
ij j
variable Y ; in practice, it is usually a polynomial of some low degree.
i
• ϵ is the noise term in the regression model with zero mean; usually it is assumed to be normal
j
distribution but does not have to be.
In practice, we usually assume that
Φ (x)=Σ4 βkH (x), (2)
ij k=0 ij k
where H (x) is the Hermitian polynomial of degree k. Based on authors’ practical experience, a
k
polynomial of degree of 4 is flexible enough to capture nonlinear but essential relation between target
and risk factor while usually suffer bearable overfitting.
For each target and risk factor pair (Y ,X ), assume that we have their observations: Y and X
i j i j
for time t=1,2,...,T, then we can write each regression model from (1) into matrix format
→−
Y
=HT− β→ +− ϵ→
, (3)
i j ij ij
where
2→−
• Y denotes the vector of the target time series such of return of hedge fund
i
 
Y (t )
i 1
Y i(t 2)
 . .
 . 
 . 
Y (t )
i T
• H denotes the following matrix of the risk factor X
j i
 
H (X (t )), H (X (t )), H (X (t )),..., H (X (t ))
0 j 1 0 j 2 0 j 3 0 j T
 H 1(X j(t 1)), H 1(X j(t 2)), H 1(X j(t 3)),..., H 1(X j(t T))
.
 ... 
H (X (t )), H (X (t )), H (X (t )),..., H (X (t ))
4 j 1 4 j 2 4 j 3 4 j T
which is a 5×T matrix, where H (x) is the Hermitian polynomial of degree k.
k
• − ϵ→ denotes the regression error vector
ij
 
ϵ (t )
ij 1
ϵ ij(t 2)
 . .
 . 
 . 
ϵ (t )
ij T
−→
• β is the coefficient vector of length 5
ij
 β0
ij
β i1 j
 . .
 . 
 . 
β4
ij
.
Now let’s briefly discuss how to estimate the coefficients. From the model description above, we
can see that PolyModel theory technically belongs to the realm of statistical regression models, thus,
all the common well-established parameter estimation methods can be applied to it. From a practical
point of view, we choose to use the Ridge regression [HTF09]
→− →− −→ →− −→ −→
(cid:99)β ij,λ :=arg min {− β→ ij∈R5}[(Y i −HT jβ ij)T(Y i −HT jβ ij)+λ||β ij||2, (4)
We can see that the fitted coefficients are functions of the hyper-parameter λ; to determine the
optimal value for each simple regression, one can apply any state-of-art hyper-parameter tuning trick
such as grid search plus cross-validation. However, we would like to point out that in PolyModel
theory, we need to deal with a huge amount of risk factors, and our polynomial in the regression
equation is only of degree 5, thus, our major concern for using ridge regression is to make the matrix
H HT +λI invertible, thus, we usually choose a relatively small number as the value of λ for all
j j 5×5
the target time series and risk factor pairs.
2.2 Feature Importance and Construction
OneofthemajorgoalsofPolyModeltheoryistofindasetofriskfactorswhicharemostimportantto
the target time series after fitting hundreds of simple regressions. In this section, we will first discuss
the fundamental statistical quantities based on fitting the numerous simple regressions, then we will
use them as building blocks to construct the features which will be used by the machine learning
algorithms.
32.2.1 Fundamental statistical quantities
1. R2 and adjusted R2
As PolyModel is a collection of simple regression models, then it is quite natural to talk about
R2 for every simple regression model.
R2, also known as coefficient of determination, is one of the most common criteria to check the
fitting goodness of a regression model. It is defined as follows:
ESS RSS
R2 := =1− , (5)
TSS TSS
→− →− →−
where, if we denote HT(cid:99)β by (cid:99)Y , and denote the vector of average of entries of Y with the
j ij i i
same length by Y , then
i
→− →−
• ESS is the explained sum of squares which is ((cid:99)Y −Y )T((cid:99)Y −Y ).
i i i i
→− →− →− →−
• RSS is the residual sum of squares which is (Y −(cid:99)Y )T(Y −(cid:99)Y ).
i i i i
→− →−
• TSS is the total sum of squares which is (Y −Y )T(Y −Y ).
i i i i
Moreover, it is a well-known fact in regression theory that TSS = RSS + ESS.
R2 measures how much total uncertainty is explained by the fitted model based on the observed
data,thus,thehigherR2 is,thebetterthemodelshouldbe. However,thisstatisticdoesnottake
thenumberofmodelcomplexityintoconsideration,thus,ahighR2 mayalsoindicatesoverfitting
andusuallythisisthecase(forinstance,inaonedimensionproblemgivengeneralndatapoints,
there is usually a degree n+1 polynomial which can pass through every one of them). Various
RSS
modifications have been introduced, one very direct generalization is the adjusted-R2: 1− (n−p)
TSS
(n−1)
wherenisthenumberofobservationsandpisthenumberofcoefficientsintheregressionmodel.
2. Target Shuffling and P-Value Score
Toavoidfakestrongrelationshipbetweentargetandriskfactors,weapplytargetshufflingwhich
is particular useful to identify ”cause-and-effect” relationship. By shuffling the the targets, we
have the chance to determine if the relationship fitted by the regression model is significant
enough by checking the probability of the R2 we have seen based on the observations.
The procedure can be summarized as follows:
• Do random shuffles on the target time series observations many times, say N times. For
each X , let we assume that there are T data points {(Y (t ),X (t )}T . We fix the order
j i k j k k=1
of X (t ), and we do N times of random shuffle of Y (t ). In this way, we try to break any
j k i k
relation from the original data set and create any possible relations between the target and
risk factor.
• Foreachnewlyorderedtargetobservations{(Y′(t ),X (t )}T ,wecanfitasimpleregres-
i k j k k=1
sion model and calculate the R2. Then we get
R2 ={R2 ,R2 ,··· ,R2 }.
shuffle (1) (2) (N)
Thus, we have a population of R2 based on above procedures.
• Evaluate the significance of the R2 calculated from the original data, for instance, we can
calculate the p-value of it based on the R2 population from last step. Here we assume that
our original R2 for target asset Y and risk factor X is denoted as R2. Then, we could
i j ij
define
p =P(R2 >R2).
ij ij
• We compute −log(p ) and callit P-Value Scoreof target asset Y and risk factor X which
ij i j
indicates the importance of the risk factor X to the target asset time series Y .
j i
4The higher the P-Value Score is, the more important the risk factor is. As we also need to take
different regimes over the time into the picture, at each time stamp, we only look at the past 3
years’ return data, and thus, we can have a dynamic P-Value Score series for each target asset
Y and risk factor X pair.
i j
2.2.2 Feature construction
Now we are ready to construct the features based on the statistical quantities introduced above and
the data themselves. We will briefly discuss how to construct them and their meanings. More detials
can be found in [Zha23].
1. Sharpe Ratio
It is one of the most common statistical metric to estimate the performance of a portfolio.
Roughly speaking, it is the ration between the portfolio return and its volatility, thus, usually is
regarded as a measure of the ratio between reward and risk.
AssumeRrepresentsthereturnofthetargetportfolio,R representsthereturnofthebenchmark
f
financial time series, for instance, RFR. Then Sharpe Ratio is defined as
Sharpe Ratio := √E(R−Rf) .
var(R−Rf)
In practice, one may also ignore the benchmark if it is very small or static. Notice that Sharpe
Ratio is a feature that is only dependent on target portfolio itself.
2. Morningstar Risk-adjusted Return (MRaR)
Thisisanotherfeaturemostlydependentonthetargetportfolioitself. Giventhetargetportfolio
(e.g. hedge fund return Y ), denote its return at time t as r ; denote the return of benchmark at
i t
time t as r , the MRaR over n months is defined as follows [MRac]
f
MRaR=( n1Σn i=1(1+r Gt)−γ)−n γ −1,
r
Gt
=( 11 ++ rr ft)−1,
where n is the total number of months in calculation period; r is the geometric excess return
Gt
at month t; γ is the risk aversion parameter, and MorningstarTM uses 2. Investors can adjust
the value of γ according to their own risk flavors.
As mentioned in [MRab], the main assumption is that investors are rational and willing to give
upasmallportionoftheirexpectedreturntoachieveabettercertainty. Thisismetricissimilar
to Sharpe ratio but has more advantages. More discussions on its advantages can be found in
[MRaa].
3. StressVaR (SVaR)
SVaR can be regarded as a good alternative risk measure instead of VaR, in fact, it can be
regarded as a factor model-based VaR. However, its strength resides in the modeling of nonlin-
earities and the capability to analyze a very large number of potential risk factors[CDZ09].
There are three major steps in the estimation of StressVaR of a hedge fund Y .
i
(a) Most relevant risk factors selection: for each risk factor X , we can calculate the P-Value
j
Score of it with respect to Y . Recall Section 2.5.2, this score can indicate the explanation
i
power of risk factor X , and the application of target shuffling improves the ability of our
j
model in preventing discovering non-casual relations. Once a threshold of P-Value Score is
set, we can claim that all the risk factors X whose P-Value Score is above the threshold
j
are the most relevant risk factors, and denote the whole set of them as Γ .
i
5(b) Estimation of the Maximum Loss of Y : For every risk factor X ∈ Γ , using the fitted
i j i
polynomial for the pair (Y ,X ), we can predict the return of Y for all risk factor returns
i j i
from 1st to 99th quantiles of the risk factor distributions. In particular, we are interested
in the potential loss of Y corresponding to α% = 98% of the factor returns. Once this is
i
estimated for one factor X , we can define SVaR for the pair (Y ,X ) as follows:
j i,j i j
(cid:113)
SVaR := Yˆ2 +σ(Y )2·(1−R2)·ξ2
i,j i,j,max i
where
• Yˆ is the maximum potential loss corresponding to α quantile of risk factor X .
i,j,max j
• σ(Y )2·(1−R2) is unexplained variance under the ordinary least square setting which
i
can be estimated by the following unbiased estimator if penalty terms are added to the
regression models
Σ(Yi−Yˆ i)2
,
n−p
where p is the degree of freedom of the regression model.
• ξ = φ−1(α) ≈ 2.33 where φ is the cumulative distribution function (cdf) of standard
normal distribution.
(c) Calculation of StressVaR: The definition of StressVaR of Y is
i
SVaR :=max SVaR .
i j∈Γi ij
4. Long-term alpha (LTA)
For the given hedge fund and risk factor pair (Y ,X ), assume we already fitted the regression
i j
polynomial Φ (x). Assume that θ represents the q-quantile of the empirical distribution of
ij j,q
X whereq =1%, 16%, 50%, 84%, 99%. Theyarecalculatedusingtheverylonghistoryofthe
j
factor. The extremes 1% and 99% are computed by fitting a Pareto distribution on the tails.
Then we define
LTA(Y ,X ):=Σ99% w Φ (θ ),
i j q=1% q ij j,q
subject to E(X )=Σ99% w θ , where w correspond to Lagrange method of interpolating an
j q=1% q j,q q
integral and are hyper-parameters.
TheglobalLTA(long-termaverage)isthemedianofthefactorexpectationsforselectedfactors.
LTA for Y is defined as the 50th quantile among all the LTA(Y , X ) values, where X ∈ Γ
i i i j j i
represents the selected ones.
5. Long-term ratio (LTR)
Once we get the LTA and SVaR for Y , LTR is simply defined as
i i i i
LTR i := SL VT aA Ri i.
6. Long-term stability (LTS)
For fund Y , LTS :=LTA −κ·SVaR where κ is a hyper-parameter whose value is set to 5%.
i i i i
Besidesthefeaturesconstructedabove,wealsoincludesomemorestandardfeaturesforourfinancial
time series research: asset under management (AUM) of each hedge fund, volume of each hedge fund,
and historical returns for each hedge fund and risk factor. All of them will be used as input features
when applying machine learning techniques below.
63 Methodology
Giventhecarefullychosenriskfactorpoolandthesetofhedgefundstoinvest,wefirstapplyPolyModel
theory to construct the features introduced in the previous section. Notice that these features can be
regarded as a dynamical encoding of the hedge funds’ returns and their interactions with the whole
financial environment.
We then will apply modern machine learning algorithms to predict the performance of each hedge
fund. We particularly choose to apply transformer techniques in our prediction due to its string
performance in time series related forecasting researches during recent years [WZZ+22]. Moreover, we
will apply one of its latest variants called inverted transformer in our study.
In the rest of this section, we first introduce inverted transformer, then discuss how to apply it to
our hedge fund performance prediction task in details.
3.1 Inverted Transformers (iTransformer)
InvertedTransformers(iTransformer)[LHZ+23]isdesignedformultivariatetimeseriesforecasting. We
combine this method with PolyModel theory to generate effective portfolio construction. Suppose we
extractN featureswithT timesteps, denotedasX={x ,...,x }∈RT×N. Basedonthosehistorical
1 T
observations, we can forecast the future S time steps target Y ={x ,...,x }∈RS×N. Instead
T+1 T+S
ofregardingmultivariatefeaturesofthesametimestepasatemporaltoken,theiTransformertokenize
the whole time series input of each feature as the token, which focus on representation learning and
correlation measurement of multivariate time series.
h=Embedding(X), (6)
where h = {h ,...,h } ∈ RN×D. We use multi-layer perceptron (MLP) to project raw time se-
1 N
ries data into D-dimensional latent space. [LHZ+23] shows that the temporal information has been
processedbyMLP,thepositionembeddinginoriginalTransformer[VSP+17]isnotnecessaryanymore.
We apply Layer normalization (LN) [BKH16] to token h across time steps. Unlike the common
Transformer frameworks, which apply LN across different features, iTransformer [LHZ+23] normalizes
each feature token to a standard Gaussian distribution, which helps keep patterns in each feature.
[KKT+21, LWWL22] also prove that this technique are helpful in solving non-stationary time series
problem.
h −Mean(h )
H= n n ,n=1,...,N. (7)
(cid:112)
Var(h )
n
TheoriginalTransformer[VSP+17]usestheattentionmechanismtoprocesstemporalinformation
for encoded features. The iTransformer [LHZ+23] uses this attention mechanism to model feature
correlations since each token represents the whole time series data of a feature. Suppose there are
linear projections W
Q
∈ RD×dk,W
K
∈ RD×dk and W
V
∈ RD×dk. We can obtain query, key and
value matrices as Q = HW , K = HW and V = HW . Then, the self-attention mechanism is
Q K V
computed as
(cid:18) QKT(cid:19)
Attention(Q,K,V)=softmax √ V. (8)
d
k
Traditional transformer models typically utilize temporal tokens, analyzing all features at a single
timestamp,whichcanlimittheirabilitytoeffectivelylearndependencies. Oneapproachtoaddressthis
limitation involves patching, where data points along the time axis are grouped prior to tokenization
and embedding. However, this method may suffer from insufficiently large grouping ranges, failing to
capture all necessary dependencies. In contrast, the iTransformer adopts an innovative approach by
viewingthetimeseriesfromaninvertedperspective. Thisallowsittoconsiderthesamefeatureacross
multiple timestamps, significantly enhancing its capacity to discern dependencies and multivariate
correlations. This distinct capability positions the iTransformer as a superior alternative in scenarios
demanding nuanced temporal analysis.
73.2 Hedge fund performance prediction
We apply iTransformer algorithm directly in our research. The input features are those described in
section2.2.2. Regardingtheoutput,foreachtargethedgefund,wepredicttheprobabilityofthetrend
rather than the value of its return, in particular, we assume that there are three status of the return
trend: up, down and unchanged (we set a prior threshold for the hedge fund return. If the absolute
value of the return is smaller than the threshold, we define its status as unchanged. Otherwise, the
status is up if the return is positive and the status is down if the return is negative).
We apply the implementation of iTransformer from [LHZ+23] in a straight forward manner where
interestedreaderscanfindallthetechnicaldetails. Thus,ratherthanmorediscussionsoniTransformer,
we will discuss why we choose the trend rather than the value of hedge fund returns as our prediction
output.
As already pointed out in some recent research such as [SDR23], [VPC24], it is more useful to
correctly classify the trend of returns rather than to provide a predicted result which is close to the
realreturn. Forinstance, onehasaportfolioandcanpredictitsreturnascloseastherealizedonebut
with an opposite sign, this may cause a significant negative impact on one’s pnl and is not favored.
Moreover,ourtargetassetsarehedgefundswhosereturnsusuallyhaveverylargemagnitude,thus,
once we can predict the return status correctly and select those hedge funds whose next returns are
positive, we will have a good chance to achieve a reasonably high total return. On the other side,
PolyModel theory is quite good at identifying risk factors which may cause large drops of the target
assets. Thus, the combination of these two theories can give us a better chance to create a portfolio
with large positive return and small drawdown.
4 Portfolio Construction
Basedonthetheoriesandmethodologiesintroducedinprevioussections,wearereadytoconstructour
portfolio. We rebalance our portfolio monthly. Before the end of each month, we apply iTransformer
to predict the probability on whether the return of hedge fund Y for the next month is positive which
i
is denoted as p . We select the top 50% hedge funds with the largest probabilities of having a positive
i
returnforthenextmonth. Wekeepthosehedgefundswhicharecurrentlyheldinourportfolioifthey
areselected,andsellthein-selectedonesinourhands. Thecollectedcasharereinvestedevenlytobuy
the rest selected hedge funds which are not in current portfolio. We call this strategy simple average
portfolio (SA). A second proposed strategy, which is denoted as weighted average portfolio (WA), is
almost identical to SA except that the weights of the selected fund in the portfolio are based on the
their AUM.
5 Experiments and Results
In this section, we will give an overview of the data used for our study, the benchmarks to compare
with and the performance of our portfolio. The same set of data and benchmarks are also used in
[SDR23].
5.1 Data description
As mentioned in the introduction of PolyModel theory, there are two datasets: risk factors and target
hedge funds. The data sets cover a long period from April 1994 to May 2023. These data will be
used to construct the features introduced in section 2.2.2, and the set of hedge fund will be used to
construct the portfolio. Below let’s look at the snapshots of some of the representatives of these two
data sets.
Regarding risk factors, our study incorporates an extensive universe comprising hundreds of risk
factors from different domains, including equities, coupons, bonds, industrial indexes, and more. We
list some of the risk factors:
8Label Code
T-Bil INGOVS USAB
SWAP 1Y Zone USA In
INMIDR USAB
USD DIRECT VAR-LOG
American Century Zero Coupon
BTTTX
2020 Inv (BTTTX) 1989
COMMODITY GOLD Zone USA
COGOLD USAD
In USD DIRECT VAR-LOG
EQUITY MAIN Zone NORTH AMERICA
EQMAIN NAMM
In USD MEAN VAR-LOG
... ...
Table 1: List of the Risk Factors for Hedge Funds Portfolio Construction
we collect more than 10,000 hedge funds’ data, including their monthly returns and AUMs. The
selected hedge funds encompass a diverse range of strategies and characteristics. In terms of invest-
mentstrategy, wehaveincludedfixedincome, eventdriven, multi-strategy, long-shortequities, macro,
and various others. Geographically, the hedge funds under consideration span global, Europe, north
America, Asia, and other regions. Here are some of the representatives:
Fund Name
400 Capital Credit Opportunities Fund LP
Advent Global Partners Fund
Attunga Power & Enviro Fund
Barington Companies Equity Partners LP
BlackRock Aletsch Fund Ltd
Campbell Managed Futures Program
...
Table 2: List of Hedge Funds
5.2 Benchmark description
We select two fund of fund portfolios as the benchmarks, they are listed in Hedge Fund Research
(HFR) [hfr], and let’s quote their descriptions here directly:
• HFRI Fund of Funds Composite Index (HFRIFOF)
“FundofFundsinvestwithmultiplemanagersthroughfundsormanagedaccounts. Thestrategy
designs a diversified portfolio of managers with the objective of significantly lowering the risk
(volatility) of investing with an individual manager. The Fund of Funds manager has discretion
in choosing which strategies to invest in for the portfolio. A manager may allocate funds to
numerous managers within a single strategy, or with numerous managers in multiple strategies.
The minimum investment in a Fund of Funds may be lower than an investment in an individual
hedge fund or managed account. The investor has the advantage of diversification among man-
agers and styles with significantly less capital than investing with separate managers. PLEASE
NOTE: The HFRI Fund of Funds Index is not included in the HFRI Fund Weighted Composite
Index.”
• HFRI Fund Weighted Composite Index (HFRIFWI)
“TheHFRIFundWeightedCompositeIndexisaglobal,equal-weightedindexofsingle-manager
fundsthatreporttoHFRDatabase. Constituentfundsreportmonthlynetofallfeesperformance
in US Dollar and have a minimum of $50 Million under management or $10 Million under
management and a twelve (12) month track record of active performance. The HFRI Fund
Weighted Composite Index does not include Funds of Hedge Funds.”
95.3 Performance of the constructed portfolio
We follow the strategy discussed in section 4 to construct our portfolios. To calculate the features
based on PolyModel theory, we use the past 36 months data to compute features such as SVaR and
LTS for the next month’s prediction purpose. We compare the performance of our strategies against
the two benchmarks from section 5.2, assuming that we start with 1 dollar at 4/30/1994; the four
portfolios are SA and WA, which are based on the selection method discussed in Section 4, and the
two benchmarks HFRIFOF and HFRIFWI:
Figure 1: This figure plots the cumulative returns of the 4 strategies.
We can see that SA has the best performance regarding the cumulative return; WA is more stable
and suffers much less drawdown than SA. Both strategies outperform the benchmarks significantly. It
supportsthepowerofthecombinationofPolyModelfeatureconstructionanddeeplearningtechniques.
6 Conclusion
In this work, we considered the problem of portfolio construction when the available data is sparse.
Especially, we considered to construct a portfolio of hedge funds.
Toresolvethisissue,weproposedthecombinationofPolyModeltheoryandiTransformerforhedge
funds selection; the proposed strategies achieved much higher returns than the standard fund of fund
benchmarks. This research also shows the power of combining domain knowledge and modern deep
learning techniques.
References
[AAD+24] JoshAbramson,JonasAdler,JackDunger,RichardEvans,TimGreen,AlexanderPritzel,
OlafRonneberger,LindsayWillmore,AndrewJBallard,JoshuaBambrick,etal. Accurate
structurepredictionofbiomolecularinteractionswithalphafold3. Nature,pages1–3,2024.
[BD22] Thomas Barrau and Raphael Douady. Artificial Intelligence for Financial Markets: The
Polymodel Approach. Springer Nature, 2022.
[BGTW19] HansBuehler,LukasGonon,JosefTeichmann,andBenWood.Deephedging.Quantitative
Finance, 19(8):1271–1291, 2019.
10[BKH16] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv
preprint arXiv:1607.06450, 2016.
[CDM10] Alexander Cherny, Raphael Douady, and Stanislav Molchanov. On measuring nonlinear
risk with scarce observations. Finance and Stochastics, 14:375–395, 2010.
[CDZ09] Cyril Coste, Raphael Douady, and Ilija I. Zovko. The stressvar: A new risk concept for
superior fund allocation. arXiv preprint arXiv:0911.4030, 2009.
[CDZ10] Cyril Coste, Raphael Douady, and Ilija I Zovko. The stressvar: A new risk concept for
extreme risk and fund allocation. The Journal of Alternative Investments, 13(3):10–23,
2010.
[DKP24] Zhikang Dong, Juni Kim, and Pawel(cid:32) Polak. Mapping the invisible: Face-gps for facial
muscle dynamics in videos. In 2024 IEEE First International Conference on Artificial
Intelligence for Medicine, Health and Care (AIMHC), pages 209–213. IEEE, 2024.
[DLC+24] Zhikang Dong, Xiulong Liu, Bin Chen, Pawel Polak, and Peng Zhang. Musechat: A
conversationalmusicrecommendationsystemforvideos. InProceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition, pages 12775–12785, 2024.
[Dou19] Raphael Douady. Managing the downside of active and passive strategies: Convexity and
fragilities. Journal of portfolio management, 46(1):25–37, 2019.
[DP23] Zhikang Dong and Pawel Polak. Cp-pinns: Changepoints detection in pdes using physics
informedneuralnetworkswithtotal-variationpenalty. InMachine Learning and the Phys-
ical Sciences Workshop, NeurIPS 2023, 2023.
[FF04] Eugene F Fama and Kenneth R French. The capital asset pricing model: Theory and
evidence. Journal of economic perspectives, 18(3):25–46, 2004.
[GCG21] Yuan Gong, Yu-An Chung, and James Glass. Ast: Audio spectrogram transformer. arXiv
preprint arXiv:2104.01778, 2021.
[hfr] Hedge fund research, https://www.hfr.com/hfri-indices-index-descriptions.
[HTF09] T. Hastie, R. Tibshirani, and J.H. Friedman. The Elements of Statistical Learning: Data
Mining, Inference, and Prediction. Springer series in statistics. Springer, 2009.
[KDP23] Juni Kim, Zhikang Dong, and Pawel Polak. Face-gps: A comprehensive technique for
quantifying facial muscle dynamics in videos. In Medical Imaging Meets NeurIPS: An
official NeurIPS Workshop, 2023.
[KKT+21] TaesungKim,JinheeKim,YunwonTae,CheonbokPark,Jang-HoChoi,andJaegulChoo.
Reversible instance normalization for accurate time-series forecasting against distribution
shift. In International Conference on Learning Representations, 2021.
[KSV22] DeepakKumar,PradeeptaKumarSarangi,andRajitVerma. Asystematicreviewofstock
market prediction using machine learning and statistical techniques. Materials Today:
Proceedings, 49:3187–3191, 2022.
[LDZ24] Xiulong Liu, Zhikang Dong, and Peng Zhang. Tackling data bias in music-avqa: Crafting
a balanced dataset for unbiased question-answering. In Proceedings of the IEEE/CVF
Winter Conference on Applications of Computer Vision, pages 4478–4487, 2024.
[LHZ+23] YongLiu,TenggeHu,HaoranZhang,HaixuWu,ShiyuWang,LintaoMa,andMingsheng
Long. itransformer: Inverted transformers are effective for time series forecasting. arXiv
preprint arXiv:2310.06625, 2023.
[LLSH23] Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. Blip-2: Bootstrapping language-
imagepre-trainingwithfrozenimageencodersandlargelanguagemodels. InInternational
conference on machine learning, pages 19730–19742. PMLR, 2023.
11[LWWL22] Yong Liu, Haixu Wu, Jianmin Wang, and Mingsheng Long. Non-stationary transformers:
Exploring the stationarity in time series forecasting. Advances in Neural Information
Processing Systems, 35:9881–9893, 2022.
[MRaa] The morningstar rating for funds.
[MRab] Morningstar risk-adjusted return.
[MRac] Mrar illustrated.
[RKH+21] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini
Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning
transferable visual models from natural language supervision. In International conference
on machine learning, pages 8748–8763. PMLR, 2021.
[SDR23] Zhao Siqiao, Wang Dan, and Douady Raphael. Using machine learning technique to
enhance the portfolio construction based on polymodel theory. Research in Options 2023,
2023.
[VPC24] Milena Vuleti´c, Felix Prenzel, and Mihai Cucuringu. Fin-gan: Forecasting and classifying
financialtimeseriesviagenerativeadversarialnetworks. QuantitativeFinance,pages1–25,
2024.
[VSP+17] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N
Gomez, L(cid:32) ukaszKaiser,andIlliaPolosukhin. Attentionisallyouneed. Advances in neural
information processing systems, 30, 2017.
[WZZ+22] Qingsong Wen, Tian Zhou, Chaoli Zhang, Weiqi Chen, Ziqing Ma, Junchi Yan, and Liang
Sun. Transformers in time series: A survey. arXiv preprint arXiv:2202.07125, 2022.
[Zha23] Siqiao Zhao. PolyModel: Portfolio Construction and Financial Network Analysis. PhD
thesis, Stony brook University, 2023.
12