[
    {
        "title": "ClassiFIM: An Unsupervised Method To Detect Phase Transitions",
        "authors": "Victor KasatkinEvgeny MozgunovNicholas EzzellUtkarsh MishraItay HenDaniel Lidar",
        "links": "http://arxiv.org/abs/2408.03323v1",
        "entry_id": "http://arxiv.org/abs/2408.03323v1",
        "pdf_url": "http://arxiv.org/pdf/2408.03323v1",
        "summary": "Estimation of the Fisher Information Metric (FIM-estimation) is an important\ntask that arises in unsupervised learning of phase transitions, a problem\nproposed by physicists. This work completes the definition of the task by\ndefining rigorous evaluation metrics distMSE, distMSEPS, and distRE and\nintroduces ClassiFIM, a novel machine learning method designed to solve the\nFIM-estimation task. Unlike existing methods for unsupervised learning of phase\ntransitions, ClassiFIM directly estimates a well-defined quantity (the FIM),\nallowing it to be rigorously compared to any present and future other methods\nthat estimate the same. ClassiFIM transforms a dataset for the FIM-estimation\ntask into a dataset for an auxiliary binary classification task and involves\nselecting and training a model for the latter. We prove that the output of\nClassiFIM approaches the exact FIM in the limit of infinite dataset size and\nunder certain regularity conditions. We implement ClassiFIM on multiple\ndatasets, including datasets describing classical and quantum phase\ntransitions, and find that it achieves a good ground truth approximation with\nmodest computational resources. Furthermore, we independently implement two\nalternative state-of-the-art methods for unsupervised estimation of phase\ntransition locations on the same datasets and find that ClassiFIM predicts such\nlocations at least as well as these other methods. To emphasize the generality\nof our method, we also propose and generate the MNIST-CNN dataset, which\nconsists of the output of CNNs trained on MNIST for different hyperparameter\nchoices. Using ClassiFIM on this dataset suggests there is a phase transition\nin the distribution of image-prediction pairs for CNNs trained on MNIST,\ndemonstrating the broad scope of FIM-estimation beyond physics.",
        "updated": "2024-08-06 17:58:29 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.03323v1"
    },
    {
        "title": "Hedge Fund Portfolio Construction Using PolyModel Theory and iTransformer",
        "authors": "Siqiao ZhaoZhikang DongZeyu CaoRaphael Douady",
        "links": "http://arxiv.org/abs/2408.03320v1",
        "entry_id": "http://arxiv.org/abs/2408.03320v1",
        "pdf_url": "http://arxiv.org/pdf/2408.03320v1",
        "summary": "When constructing portfolios, a key problem is that a lot of financial time\nseries data are sparse, making it challenging to apply machine learning\nmethods. Polymodel theory can solve this issue and demonstrate superiority in\nportfolio construction from various aspects. To implement the PolyModel theory\nfor constructing a hedge fund portfolio, we begin by identifying an asset pool,\nutilizing over 10,000 hedge funds for the past 29 years' data. PolyModel theory\nalso involves choosing a wide-ranging set of risk factors, which includes\nvarious financial indices, currencies, and commodity prices. This comprehensive\nselection mirrors the complexities of the real-world environment. Leveraging on\nthe PolyModel theory, we create quantitative measures such as Long-term Alpha,\nLong-term Ratio, and SVaR. We also use more classical measures like the Sharpe\nratio or Morningstar's MRAR. To enhance the performance of the constructed\nportfolio, we also employ the latest deep learning techniques (iTransformer) to\ncapture the upward trend, while efficiently controlling the downside, using all\nthe features. The iTransformer model is specifically designed to address the\nchallenges in high-dimensional time series forecasting and could largely\nimprove our strategies. More precisely, our strategies achieve better Sharpe\nratio and annualized return. The above process enables us to create multiple\nportfolio strategies aiming for high returns and low risks when compared to\nvarious benchmarks.",
        "updated": "2024-08-06 17:55:58 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.03320v1"
    },
    {
        "title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters",
        "authors": "Charlie SnellJaehoon LeeKelvin XuAviral Kumar",
        "links": "http://arxiv.org/abs/2408.03314v1",
        "entry_id": "http://arxiv.org/abs/2408.03314v1",
        "pdf_url": "http://arxiv.org/pdf/2408.03314v1",
        "summary": "Enabling LLMs to improve their outputs by using more test-time computation is\na critical step towards building generally self-improving agents that can\noperate on open-ended natural language. In this paper, we study the scaling of\ninference-time computation in LLMs, with a focus on answering the question: if\nan LLM is allowed to use a fixed but non-trivial amount of inference-time\ncompute, how much can it improve its performance on a challenging prompt?\nAnswering this question has implications not only on the achievable performance\nof LLMs, but also on the future of LLM pretraining and how one should tradeoff\ninference-time and pre-training compute. Despite its importance, little\nresearch attempted to understand the scaling behaviors of various test-time\ninference methods. Moreover, current work largely provides negative results for\na number of these strategies. In this work, we analyze two primary mechanisms\nto scale test-time computation: (1) searching against dense, process-based\nverifier reward models; and (2) updating the model's distribution over a\nresponse adaptively, given the prompt at test time. We find that in both cases,\nthe effectiveness of different approaches to scaling test-time compute\ncritically varies depending on the difficulty of the prompt. This observation\nmotivates applying a \"compute-optimal\" scaling strategy, which acts to most\neffectively allocate test-time compute adaptively per prompt. Using this\ncompute-optimal strategy, we can improve the efficiency of test-time compute\nscaling by more than 4x compared to a best-of-N baseline. Additionally, in a\nFLOPs-matched evaluation, we find that on problems where a smaller base model\nattains somewhat non-trivial success rates, test-time compute can be used to\noutperform a 14x larger model.",
        "updated": "2024-08-06 17:35:05 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.03314v1"
    },
    {
        "title": "Pre-training and in-context learning IS Bayesian inference a la De Finetti",
        "authors": "Naimeng YeHanming YangAndrew SiahHongseok Namkoong",
        "links": "http://arxiv.org/abs/2408.03307v1",
        "entry_id": "http://arxiv.org/abs/2408.03307v1",
        "pdf_url": "http://arxiv.org/pdf/2408.03307v1",
        "summary": "Accurately gauging uncertainty on the underlying environment is a\nlongstanding goal of intelligent systems. We characterize which latent concepts\npre-trained sequence models are naturally able to reason with. We go back to De\nFinetti's predictive view of Bayesian reasoning: instead of modeling latent\nparameters through priors and likelihoods like topic models do, De Finetti has\nlong advocated for modeling exchangeable (permutation invariant) sequences of\nobservables. According to this view, pre-training autoregressive models\nformulates informed beliefs based on prior observations (\"empirical Bayes\"),\nand forward generation is a simulated instantiation of an environment\n(\"posterior inference\"). This connection allows extending in-context learning\n(ICL) beyond predictive settings, highlighting sequence models' ability to\nperform explicit statistical inference. In particular, we show the sequence\nprediction loss over exchangeable documents controls performance on downstream\ntasks where uncertainty quantification is key. Empirically, we propose and\ndemonstrate several approaches for encoding exchangeability in sequence model\narchitectures: data augmentation, regularization, and causal masking.",
        "updated": "2024-08-06 17:16:10 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.03307v1"
    },
    {
        "title": "Fusing Forces: Deep-Human-Guided Refinement of Segmentation Masks",
        "authors": "Rafael SterzingerChristian StippelRobert Sablatnig",
        "links": "http://arxiv.org/abs/2408.03304v1",
        "entry_id": "http://arxiv.org/abs/2408.03304v1",
        "pdf_url": "http://arxiv.org/pdf/2408.03304v1",
        "summary": "Etruscan mirrors constitute a significant category in Etruscan art,\ncharacterized by elaborate figurative illustrations featured on their backside.\nA laborious and costly aspect of their analysis and documentation is the task\nof manually tracing these illustrations. In previous work, a methodology has\nbeen proposed to automate this process, involving photometric-stereo scanning\nin combination with deep neural networks. While achieving quantitative\nperformance akin to an expert annotator, some results still lack qualitative\nprecision and, thus, require annotators for inspection and potential\ncorrection, maintaining resource intensity. In response, we propose a deep\nneural network trained to interactively refine existing annotations based on\nhuman guidance. Our human-in-the-loop approach streamlines annotation,\nachieving equal quality with up to 75% less manual input required. Moreover,\nduring the refinement process, the relative improvement of our methodology over\npure manual labeling reaches peak values of up to 26%, attaining drastically\nbetter quality quicker. By being tailored to the complex task of segmenting\nintricate lines, specifically distinguishing it from previous methods, our\napproach offers drastic improvements in efficacy, transferable to a broad\nspectrum of applications beyond Etruscan mirrors.",
        "updated": "2024-08-06 17:11:40 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.03304v1"
    }
]