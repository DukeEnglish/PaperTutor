Enhancing Stochastic Optimization for Statistical
Efficiency Using ROOT-SGD with Diminishing Stepsize
Tong Zhang⋄ Chris Junchi Li†
Siebel School of Computing and Data Science
University of Illinois, Urbana, IL⋄
Department of Electrical Engineering and Computer Sciences
University of California, Berkeley, CA†
July 16, 2024
Abstract
In this paper, we revisit ROOT-SGD, an innovative method for stochastic optimization to
bridge the gap between stochastic optimization and statistical efficiency. The proposed method
enhances the performance and reliability of ROOT-SGD by integrating a carefully designed di-
minishing stepsize strategy. This approach addresses key challenges in optimization, providing
robust theoretical guarantees and practical benefits. Our analysis demonstrates that ROOT-SGD
withdiminishingstepsizeachievesoptimalconvergencerateswhilemaintainingcomputationalef-
ficiency. By dynamically adjusting the learning rate, ROOT-SGD ensures improved stability and
precision throughout the optimization process. The findings of this study offer valuable insights
for developing advanced optimization algorithms that are both efficient and statistically robust.
Keywords: Stochastic Optimization, ROOT-SGD Algorithm, Statistical Efficiency, Diminishing
Stepsize, Non-Asymptotic Bounds
1 Introduction
Stochastic optimization has become a cornerstone in machine learning and statistical learning, par-
ticularlyforlarge-scaleandhigh-dimensionaldata. Amongthevariousstochasticoptimizationtech-
niques, stochastic gradient descent (SGD) stands out due to its simplicity and effectiveness [RM51].
However, the performance of SGD can be significantly influenced by the stepsize schedule, which
determines the balance between convergence speed and stability. In special, the diminishing step-
size strategy has been proposed to address the limitations of fixed stepsize schemes, offering a way
to enhance the efficiency and robustness of SGD. This strategy allows for adaptive learning rates
that decrease over time, facilitating better convergence properties in nonconvex settings. Despite
its potential, integrating diminishing stepsize strategies with SGD in a way that optimally balances
stochastic optimization and statistical efficiency remains a challenge.
In this paper, we revisit ROOT-SGD recently studied by [Li20], a novel optimization framework
that leverages diminishing stepsize techniques to improve both the convergence and stability of
stochastic gradient methods. ROOT-SGD is designed to be theoretically optimal and practically
effective, providing a comprehensive solution to the inherent trade-offs in stochastic optimization.
In the mean time, the estimator produced by the ROOT-SGD algorithm share the same optimal
statistical properties typically possessed by the empirical risk minimizer. The notion of statisti-
cal efficiency, in both asymptotic and non-asymptotic forms, allows for assessment of optimality.
The (Bayesian) Cram´er-Rao lower bounds relate the fundamental limit of the mean-squared error
1
4202
luJ
51
]LM.tats[
1v55901.7042:viXra(MSE) of an estimator to the Fisher information;1 moreover, local asymptotic minimax theorems
further show that the optimal asymptotic distribution, under any bowl-shaped loss function, takes
a Gaussian form [VdV00, DR21]. The asymptotic covariance provides a form of local complexity,
and it is desirable to achieve this optimal bound with a unity pre-factor. Under relatively mild
conditions, the empirical risk minimizer itself does so.
In contrast, our understanding of which first-order stochastic algorithms are optimal (or non-
optimal) in this fine-grained way remains complete. Most existing performance guarantees are too
coarse for this purpose, as the convergence rates are measured with worst-case problem-specific
parameters, and bounds are given up to universal constants instead of unity in the asymptotic
limit.2 This motivates us to establish performance guarantees for an efficient algorithm that match
theoptimalstatisticalefficiencywithunity pre-factor, bothasymptoticallyandnon-asymptotically.
In particular, given a function f : Rd ×Ξ → R that is differentiable as a function of its first
argument, consider the unconstrained minimization problem
minF(θ), for a function of the form F(θ) :=
E(cid:2) f(θ;ξ)(cid:3)
(1)
θ∈Rd
Here the expectation is taken over a random vector ξ ∈ Ξ with distribution P. Throughout this
paper, weconsiderthecasewhereF isstronglyconvexandsmooth. Supposethatwehaveaccessto
an oracle that generates samples ξ ∼ P. Let θ∗ denote the minimizer of F, we defined the matrices
H∗ := ∇2F(θ∗) and Σ∗ := E(cid:2) ∇f(θ∗;ξ)∇f(θ∗;ξ)⊤(cid:3) . Under certain regularity assumptions, given
(ξ )n i. ∼i.d. P, the following asymptotic limit holds true for the exact minimizer of empirical risk:
i i=1
θ(cid:98) nERM := arg min
(cid:88)n
f(θ,ξ i) satisfies
√ n(cid:16)
θ(cid:98)
nERM−θ∗(cid:17)
−→d N (cid:0) 0,(H∗)−1Σ∗(H∗)−1(cid:1) (2)
θ∈Rd
i=1
Furthermore,theasymptoticdistribution(2)isknowntobelocallyoptimal—see[VdV00]and[DR21]
fortheprecisestatementsabouttheoptimalityclaim. Thequestionnaturallyarises: can a stochas-
tic optimization algorithm, taking the sample ξ as input in its i-th iteration without storing it,
i
achieve the optimal guarantee as in equation (2)?
An affirmative answer to this question at least qualitatively, is provided by the seminal work
by[PJ92,Pol90,Rup88]. Inparticular, theyshowthatbytakingtheCes´aro-averageofthestochas-
tic gradient descent (SGD) iterates, one can obtain an optimal estimator that achieves locally min-
imax limit (2), as the number of samples grows to infinity. This algorithm lays the foundations
of online statistical inference [CLTZ20, SZ23] and fine-grained error guarantees for stochastic op-
timization algorithms [MB11, DDB20]. However, the gap still exists between the averaged SGD
algorithm and the exact minimizer of empirical risk, both asymptotically and non-asymptotically.
The following questions remain unresolved:
• The asymptotic properties of the estimators produced by the Polyak-Ruppert algorithm are
derived under the Lipschitz or H¨older condition of the Hessian matrix ∇2F, at least with
respect to the global optimum θ∗ in all existing literature (see, e.g., [PJ92, DR21]). However,
the asymptotic guarantee (2) for the exact minimizer holds true as long as the matrix-valued
1The vanilla Cram´er-Rao lower bounds are valid only for unbiased estimator; the Bayesian Cram´er-Rao lower
bound, on the other hand, gives lower bound on the Bayes risk for any estimator [GL95]
2To motivate the readers on the importance of unity pre-factor, consider the following thought experiment: an
algorithmthatrandomlydiscardshalfofthetrainingdataisundesirableinpractice,butthiscannotbecapturedby
any performance metric that ignores constant multiplicative factors.
2function ∇2F is continuous at θ∗, along with mild moment assumptions (see, e.g., [VdV00]).
On a historical note, the mis-match in the assumptions is particularly undesirable, given a
large portion of literature is devoted to identify the optimal smoothness conditions required for
the asymptotic normality of M-estimators to admit [LeC70, VdV00]. Is there a (single-loop)
stochastic optimization algorithm that achieves the asymptotic guarantee (2) under the mildest
smoothness conditions including that the Hessian is continuous but not H¨older continuous at its
global optimum?
• On the non-asymptotic side, one would hope to prove a finite-sample upper bound for the
estimator produced by the stochastic optimization algorithm under proper smoothness condi-
tion, which matches the exact behavior of the asymptotic Gaussian limit (2) with additional
terms that decays faster as n → +∞. For example, under the one-point Hessian Lipschitz
condition, [MB11, Xu11, GP23] established bounds in the form of
E(cid:13) (cid:13)θ(cid:98)PRJ−θ∗(cid:13) (cid:13)2
≤
1 Tr(cid:0) (H∗)−1Σ∗(H∗)−1(cid:1)
+high order terms (3)
(cid:13) n (cid:13) 2 n
for the Polyak-Ruppert estimator θ(cid:98)PRJ. Under the optimal trade-off, the higher-order terms in
n
their bound scale at the order O(n−7/6) and O(n−5/4), respectively. Compared to the rates for
the M-estimator, these bounds on the additional term do not appear to be sharp or optimal.
Under suitable Lipschitz conditions, the natural scaling for the additional term would scale as
O(n−3/2) (see the discussion following Theorem 4 for details). Very recently, [Li20] achieves an
O(n−3/2) higher-order term
E(cid:13) (cid:13)θ(cid:98)PRJ−θ∗(cid:13) (cid:13)2
≤
1 Tr(cid:0) (H∗)−1Σ∗(H∗)−1(cid:1) +O(cid:18) 1 (cid:19)
(4)
(cid:13) n (cid:13) 2 n n3/2
with a sharp dependency on problem-specific constants. However, the design requires prior
knowledge of the total number of observations n, which can limit its practicality. The question
of whether an algorithm exists that is agnostic to n remains open.
We answer both questions affirmatively using ROOT-SGD with a diminishing stepsize strategy. In
the following, we describe the algorithm and explain the connection and differences between our
results and [Li20].
The ROOT-SGD algorithm with varying stepsizes For the stochastic optimization problem
in the strongly-convex and mean-squared smooth setup, [Li20] recently proposed a stochastic ap-
proximation algorithm named Recursive One-Over-T SGD, or ROOT-SGD for short. To recap at
each iteration t = 1,2,... ROOT-SGD performs the following steps:
• receives an sample ξ ∼ P, and
t
• performs the updates
t−1
v = ∇f(θ ;ξ )+ (v −∇f(θ ;ξ )) (5a)
t t−1 t t−1 t−2 t
t
θ = θ −η v (5b)
t t−1 t t
for a suitably chosen sequence {η }∞ of positive stepsizes.
t t=1
3For the purposes of stabilizing the iterates, Algorithm (5) is initialized with a burn-in phase of
length T > 1, in which only the v variable is updated with the θ variable held fixed. Given some
0
initial vector θ ∈ Rd, we set θ = θ for all t = 1,...,T , and compute
0 t 0 0
t
1 (cid:88)
v = ∇f(θ ,ξ ) for all t = 1,...,T
t 0 s 0
t
s=1
The last iterate θ is used as the output of the algorithm.
t
[Li20] analyzed this algorithm when it is run with a constant stepsize, and showed that ROOT-
SGD simultaneously achieves non-asymptotic convergence rates and asymptotic normality with a
near-optimal covariance. While the asymptotic limit includes the optimal quantity, it also includes
an additional term due to the stepsize choice. In this paper, we provide a sharper analysis that
yields non-asymptotic bounds matching the asymptotic behavior in its leading-order term, with
lower-order additional terms being sharp and state-of-the-art. Our work is also motivated by the
practical question of stepsize schedule in ROOT-SGD. The asymptotic and non-asymptotic guar-
antees are established for a spectrum of rate of decaying stepsizes. The optimal trade-off between
fast convergence and well-behaved limiting variance is also addressed, leading to the optimal choice
of stepsize sequences under different regimes. In significance, our diminishing stepsize sequence
requires no prior knowledge of n in advance.
Building upon the proof techniques in the non-asymptotic bounds of [Li20], our work provide
fine-grained guarantees for ROOT-SGD, addressing both aforementioned questions immediately
before introducing ROOT-SGD with affirmative answers. A key technical novelty is a two-time-
scale characterization of the iterates (5) for a diminishing stepsize strategy. This allows us to
effectively bound various cross terms in the error decomposition, yielding better bounds than those
obtained by na¨ıve application of Young’s inequality. In addition, we also propose an improved
re-starting schedule for the multi-loop algorithm, achieving exponential forgetting of the initial
condition without affecting the statistical efficiency on its leading order term.
1.1 Contribution and organization
Let us summarize the contributions of this paper:
• On the asymptotic side, we show in Theorem 1 that ROOT-SGD with a wide range of dimin-
ishing stepsize sequence converges asymptotically to the optimal Gaussian limit as n → +∞.
Notably, this result only requires strong convexity, smoothness, and a set of noise moment
assumptions standard in asymptotic statistics. The result does not require any higher-order
smoothness other than the continuity of Hessian matrix at θ∗, another standard condition for
asymptotic normality. To our knowledge, this provides a first result for a stochastic approxi-
mation algorithm that enjoys asymptotic optimality without additional smoothness conditions
and the prior knowledge of n.
• On the contrary, we show that without additional smoothness conditions, a constant-stepsize
variantofPolyak-Ruppertalgorithmfailstoconvergeatadesirablerate,foranyfeasiblescalings
of stepsize and burn-in time choices. This manifests the difference in asymptotics between
variance-reduced methods and Polyak-Ruppert averaging methods. The result is stated in
Theorem 2 serving as complementary to the asymptotic Theorem 1.
• Under the same set of assumptions, in Theorem 3, we establish a non-asymptotic gradient
norm upper bound with the optimal leading term that exactly matches the optimal asymptotic
4risk, plus a higher-order term that scales as O(n−4/3). When restarting is employed with an
appropriateschedule, theresultingupperboundmeasuredingradientnormisofunityprefactor
(arbitrarily close to 1) of the optimal asymptotic risk, with exponentially-decaying additional
terms.
• In addition, when the one-point Hessian Lipschitz at the global optimum θ∗ and certain fourth-
moment conditions are assumed, in Theorem 4, we show an upper bound on the mean-squared
error (MSE) in the form of (3). Taking an optimal trade-off leads to a higher-order term that
scales as O(n−3/2) as n → +∞ with a sharp problem-specific prefactor, and such a bound is
achieved without the prior knowledge of n. With some efforts, we also establish a similar upper
bound on the excess risk in Theorem 5.
This paper is organized as follows. §2 describes the asymptotic normality results of ROOT-SGD
and also the sub-optimality of Polyak-Ruppert averaging under the Hessian continuity assumption
at the optimum. §3 state the nonasymptotic upper bound results on the gradient norm and also
the estimation error. We prove the non-asymptotic upper bounds with sharp pre-factors in §4. In
§5, we prove the asymptotic results, establishing optimality of ROOT-SGD and sub-optimality of
Polyak-Ruppert averaging without high-order smoothness conditions. Additional related works are
discussed in §6. We finalize the paper with some discussions in §7.
Notations: Given a pair of vectors u,v ∈ Rd, we write ⟨u, v⟩ = (cid:80)d u v for the inner product,
j=1 j j
and ∥v∥ for the Euclidean norm. For a matrix M, the operator norm is defined as |||M||| :=
2 op
sup ∥Mv∥ . For scalars a,b ∈ R, we adopt the shorthand notation a∧b := min(a,b) and
∥v∥ =1 2
2
a∨b := max(a,b). Throughout the paper, we use the σ-fields F := σ(ξ ,ξ ,··· ,ξ ) for any t ≥ 0.
t 1 2 t
Due to the burn-in period T introduced before, the stochastic processes are indexed from time
0
t = T . Given vector-valued martingales (X ) ,(Y ) adapted to the filtration (F ) , we
0 t t≥T0 t t≥T0 t t≥T0
use the following notation for cross variation for t ≥ T :
0
t
(cid:88)
[X,Y] := ⟨X −X , Y −Y ⟩
t t t−1 t t−1
s=T0+1
We also define [X] := [X,X] to be the quadratic variation of the process (X ) .
t t t t≥T0
2 Asymptotic results
In this section, we present the asymptotic guarantees for ROOT-SGD and a counter-example for
the Polyak-Ruppert algorithm, both under weak smoothness assumptions. We first describe the
assumptions on the objective function F and associated stochastic oracles. We define the noise
term
ε(θ;ξ) = ∇ f(θ;ξ)−∇F(θ) (6)
θ
for each θ ∈ Rd. We also use the shorthand notation ε (θ) := ε(θ;ξ ). Throughout this section and
t t
the next non-asymptotic section, we make the following assumptions:
Assumption 1. The population objective function F is µ-strongly-convex and L-smooth.
Assumption 2. The noise function θ (cid:55)→ ∇ f(θ,ξ) in the stochastic gradient satisfies the bound
θ
E∥ε(θ ;ξ)−ε(θ ;ξ)∥2 ≤ ℓ2 ∥θ −θ ∥2 for all pairs θ ,θ ∈ Rd (7)
1 2 2 Ξ 1 2 2 1 2
5Assumption 3. At the optimum θ∗, the stochastic gradient noise ε(θ∗;ξ) has a positive definite
covariance matrix, and σ2 := E∥∇f(θ∗;ξ)∥2 is finite.
∗ 2
Assumption 4. The Hessian matrix ∇2F(θ) is continuous at the optimum θ∗, i.e.,
lim |||∇2F(θ)−∇2F(θ∗)||| = 0
op
θ→θ∗
Assumption 2 (sometimes referred to as mean-squared-smoothness) as well as Assumptions 3
and4arestandardones neededforprovingasymptoticnormalityofM-estimatorsandZ-estimators
(see, e.g., [VdV00], Theorem 5.21). They are satisfied by a broad class of statistical models and
estimators. Note that we assume only the continuity of Hessian matrix at θ∗, without assuming
any bounds on its modulus of continuity. This requires merely slightly more than second-order
smoothness, and is usually considered as the minimal assumption needed in the general setup.
The weak condition manifests the difference between ROOT-SGD and Polyak-Ruppert averaging
procedure.
The strong convexity and smoothness Assumption 1 is a global condition stronger than those
typicallyusedintheasymptoticanalysisofM-estimators. Theyareneededforthefastconvergence
of the optimization algorithm, and makes it possible to establish non-asymptotic bounds. Finally,
we note that in making Assumption 2, we separate the stochastic smoothness of the noise ε(θ,ξ) =
∇f(θ,ξ)−∇F(θ) with the smoothness of the population-level objective itself. The magnitude of
ℓ and L is not comparable in general. This flexibility allows, for example, mini-batch algorithms
Ξ
where the population-level Lipschitz constant L remains the same but the parameter ℓ decreases
Ξ
with batch-size. This setting is called Lipschitz stochastic noise (LSN) in [Li20], which requires
weaker conditions than the individual smooth and convex (ISC) setting in their paper.
2.1 Asymptotic normality
Under the conditions above, we are ready to state our asymptotic guarantees.
Theorem 1. Under Assumptions 1, 2 and 3, there exists universal constants c,c > 0, such that for
1
any α ∈ (0,1), ROOT-SGD with burn-in time T = c(L +
ℓ2
Ξ) and stepsize sequence η = 1
0 µ µ2 t µT01−αtα
for t ≥ T satisfies the asymptotic limit:
0
√
T(θ −θ∗) −→d N (cid:0) 0,(H∗)−1Σ∗(H∗)−1(cid:1)
T
where H∗ := ∇2F(θ∗) and Σ∗ := E(∇f(θ∗;ξ)∇f(θ∗;ξ)⊤).
See §5.1 for the proof of this theorem. En route to the proof of this asymptotic guarantee, we
establish non-asymptotic bounds on the second moments of the processes (θ ,v ,z ) , where a
t t t t≥T0
central object in our analysis is the tracking error process:
z := v −∇F(θ ) for t ≥ T (8)
t t t−1 0
See Proposition 1 for details.
Afewremarksareinorder. First,wenotethatthislimitingdistributionislocallyasymptotically
optimal (see, e.g., [DR21]). This result for diminishing stepsize sequence is complementary to the
constant-stepsizeresultinthepaper[Li20],wheretheasymptoticcovarianceisinflatedbyastepsize-
dependent matrix.3 Moreover, our method achieves optimal asymptotic covariance in a single loop
3In the meantime, the asymptotic normality result for multi-loop ROOT-SGD has a triangular array format
(n → ∞, η → 0 with ηn → ∞), which can be difficult to interpret and impractical for practitioners, and
log(η−1)
undesirably necessitates prior knowledge of n.
6and is agnostic to the knowledge of n in advance, enhancing its practicality. Theorem 4 allows for
flexible choice of stepsize decaying rate α ∈ (0,1), albeit requiring knowledge about the structural
parameters (L,ℓ ,µ). This requirement, on the other hand, can be relaxed with some efforts: given
Ξ
a stepsize sequence η = h t−α for some h > 0 and arbitrary constant burn-in time, the iterates
t 0 0
may suffer from exponential blow-up for constant number of steps, but will eventually decay at
the desired rate, leading to the same asymptotic results. We omit this for simplicty. In contrast
to the asymptotic guarantees by the Polyak-Ruppert averaging scheme [PJ92, Rup88], Theorem 1
requiresnoquantitativeLipschitzorH¨olderassumptionsontheHessianmatrix∇F,whilerequiring
a stochastic continuity condition (Assumption 2) on the stochastic gradient. As we will see in the
next sub-section, in contrast to our guarantees, the Polyak-Ruppert procedure is asymptotically
sub-optimal for a function within the given class.
2.2 Asymptotic sub-optimality of Polyak-Ruppert averaging
In this section, we explicitly construct a problem instance under above set-up, for which Polyak-
Ruppert procedure fails to converge to the optimal asymptotic distribution. In conjunction with
Theorem 1, this exhibits an asymptotic separation between Polyak-Ruppert averaging and ROOT-
SGD.
Specifically, we consider the following tail-averaged SGD estimator:
θ = θ −η ∇f(θ,ξ) for t = 1,2,... (9a)
t t−1 t
T−1
1 (cid:88)
θ¯ = θ (9b)
T t
T −T
0
t=T0
We consider a simple special case where the stepsize sequence is constant and fixed in advance,
depending on the number of iterations in the algorithm. For the algorithm with T iterations, we
consider stepsize η = η = η T−α for some constant η > 0 and t = 1,2,.... This simplification
t 0 0
makes the iterate (9a) a time-homogeneous Markov process, which is amendable to our analysis.
Such a simplification has been employed in existing literature [Bac14, DDB20], and the constant-
stepsize algorithm usually behaves qualitatively similar to the one with diminishing stepsize η =
t
η t−α.
0
The following theorem shows the asymptotic sub-optimality of the estimator (9), even if started
from the optimum, for any choice of burn-in period and step size.
Theorem 2. There exists a function F : R → R that satisfies Assumptions 1 and 4 with constants
(µ = 1,L = 2) and noise model f(·,ξ) satisfying Assumptions 2 and 3 with constants (ℓ = 0,σ =
Ξ ∗
2). For any α ∈ [0,1), β ∈ [0,1) and η > 0,S > 0, the procedure (9) starting from θ = θ∗, with
0 0 0
step size η = η T−α and burn-in time T = S Tβ leads to the following limit:
0 0 0
T→lim +∞T ·E(cid:13) (cid:13)θ¯
T
−θ∗(cid:13) (cid:13)2
2
= +∞ (10)
See §5.2 for the proof of this theorem.
Note that Theorem 2 shows that without the Hessian Lipschitz condition, the Polyak-Ruppert
algorithm does not even converge with the desired rate, let alone the optimal asymptotic distribu-
tion. The proof is done via an explicit construction of a pathological function. With the Hessian
Lipschitz condition removed, one could construct a strongly convex and smooth function, whose
second derivative has a sharp spike at the optimum θ∗. This will break the local linearization ar-
guments for the proof of Polyak-Ruppert algorithm. By employing recent progress in the analysis
7of MCMC algorithms [DM19], we can furthermore show that this leads to large bias that cannot
be corrected using averaging. On the other hand, for ROOT-SGD, not only the asymptotic guaran-
tees in Theorem 1 but also the non-asymptotic bounds on the gradient norm in Theorem 3 works.
Moreover, note that [PJ92] considered the case where the Hessian matrix is λ-H¨older at θ∗, and
allows for stepsize choice η ∝ t−α for α ∈ [1−λ,1). Theorem 2 can be extended to show that
t
stepsize outside this range does not yield the correct rate. The construction we exploit, on the
other hand, is by driving λ to 0 so that no stepsize choice is allowed.
3 Non-asymptotic results
In this section, we present the non-asymptotic results. We first establish sharp bounds on the gra-
dient norm with near-unity pre-factor on the optimal complexity term, and exponentially decaying
additional term. Then, we establish an estimation error bound with the pre-factor being unity and
the additional term decaying as n−3/2. Note that the former result holds true under exactly the
same assumptions as needed in §2, while the latter requires additional conditions, as with existing
literature [GP23, MB11].
3.1 Upper bounds on the gradient norm
We first establish the following (non-sharp) bound on the moments of processes z and v . Despite
t t
the worse multiplicative constants, this bound serves as a starting point of the sharp inequalities
with the constant being unity.
Proposition 1. Under Assumptions 1, 2, and 3, there exist universal constants c ,c ,C > 0, using
1 2
burn-in time T ≥ C(ℓ2 Ξ +L), if the step sequence is non-increasing, and c1 < η < c ( µ ∧ 1) when
0 µ2 µ µt t 2 ℓ2 L
Ξ
t > T . We have the following bounds for any T ≥ 2T logT :
0 0 0
(cid:18) σ2 ℓ2T logT (cid:19) (cid:18) σ2 T (cid:19)
E∥z ∥2 ≤ C ∗ + Ξ 0 ∥∇F(θ )∥2 and E∥v ∥2 ≤ C ∗ + 0 ∥∇F(θ )∥2
T 2 T µ2T2 0 2 T 2 µη T2 µ2T3η2 0 2
T T
See §4.1 for the proof of this claim.
By the decomposition ∇F(θ ) = v −z , it is easy to see that Proposition 1 implies the
t t+1 t+1
following bound on the gradient norm of the last iterate:
E∥∇F(θ )∥2 ≤ cσ ∗2 + cT 0logT(cid:0) ℓ2 +η−2(cid:1) ∥∇F(θ )∥2
T 2 T µ2T2 Ξ T 0 2
When taking largest possible stepsize η = c(cid:0)1 ∧ µ (cid:1) , this bound matches the gradient norm bound
L ℓ2
Ξ
in the original ROOT-SGD paper [Li20], up to logarithmic factors in the high-order term. Our
bound allows a more flexible choice of diminishing stepsizes. This flexibility allows us to achieve
the exact asymptotically optimal limiting covariance, as opposed to the slightly larger covariance in
theconstantstepsizeregime[Li20]. Moreimportantly,thisallowsustotunethestepsizesequencein
ordertoaddresstheoptimaltrade-offbetweenfastconvergenceandsmallvarianceintheasymptotic
limit. Notethatthepre-factorintheleadingtermσ2/T isnot unity. However,owingtotheinherent
∗
martingale structure in the process (z ) ,4 one could extract the main part of the variance and
t t≥T0
bound the additional parts using Proposition 1. The multiplicative constant in such bounds will
4It can be shown that the process (tz ) is a martingale adapted to the natural filtration (see §A for details).
t t≥T0
8Algorithm 1: ROOT-SGD with cold start
Input: Burn-in time T , stepsize sequence (η ) , number of restart epochs B, initial
0 t t≥T0
point θ .
0
Output: The last-iterate estimator θ(cid:98)n.
(1)
1 Set initial point for first epoch θ
0
= θ 0.
2 for b = 1,2,··· ,B do
3 Run ROOT-SGD with burn-in time T 0, initial point θ 0(b) and stepsize η t := µTc
0
for
T♭ := cT logT iterations, and obtain the sequence (cid:0) θ(b)(cid:1)T♭ .
0 0 t t=T0+1
(b+1) (b)
4 Set the initial point θ := θ for the next round.
0 T♭
5 end
6 Run ROOT-SGD for T := n−BT♭ rounds with stepsize sequence (η t) t≥T0 and burn-in
(B+1)
period T 0, and output the last iterate θ(cid:98)n := θ
T
.
only contribute to the high-order terms in the final conclusion. See Theorem 3 and its proofs for
details.
NotethattheboundsinProposition1dependsontheinitialcondition∥∇F(θ )∥2withpolynomially-
0 2
decaying factor T−2 and T−3η−2. For the algorithm ROOT-SGD, this cannot be avoided in general,
T
as the stochastic gradients from initial rounds are being counted in the averaging process. On
the other hand, this issue can be easily mitigated by re-starting the process for a few epochs. In
Algorithm 1, we present a cold-start version of the algorithm. The algorithm consists of B short
epochs and one long epoch. Each short epoch only uses constant number of data points, while the
long epoch uses the rest of data points. Throughout the discussion related to Algorithm 1 and
associated theorems, we always assume the mild condition that the quantity ∥∇F(θ )∥ /σ scales
0 2 ∗
as a polynomial of n.5
Theorem 3. Under above set-up, given α ∈ (0,1), there exists constants c > 0 depending only
1
on α, such that the iterates (5) with any burn-in time T ≥
c(cid:0)ℓ2
Ξ +
L(cid:1)
and stepsize sequence
0 µ2 µ
η = 1 satisfies the bound:
t cµT01−αtα
E∥∇F(θ )∥2 ≤ (cid:18) 1+c(cid:0)T 0(cid:1)1− 2α∧α(cid:19) · σ ∗2 +clogT ·(cid:18) T 0(cid:19)2∧5− 23α ∥∇F(θ )∥2 (11a)
T 2 T T T 0 2
Furthermore, for B > clogn, the multi-loop estimator produced by Algorithm 1 satisfies the bound:
E(cid:13)
(cid:13)
(cid:13)∇F(θ(cid:98)n)(cid:13)
(cid:13)
(cid:13)2
2
≤
(cid:18) 1+c(cid:0)T n0(cid:1)1− 2α∧α log2n(cid:19) σ n∗2
(11b)
See §4.2 for the proof of this theorem.
A few remarks are in order. First, by taking α = 1/3, for any constant ω ∈ (0,1), we can obtain
an MSE bound on the gradient for the multi-loop estimator.
(cid:13) (cid:13)2 Tr(Σ∗) c (cid:18) L ℓ2 (cid:19) T
E(cid:13) (cid:13)∇F(θ(cid:98)n)(cid:13)
(cid:13) 2
≤ (1+ω)
n
for n ≥
ω3 µ
+ µΞ
2
log3 ω0 (12)
5Thisassumptionisusedonlytosimplifythepresentation. Ifitdoesnotholdtrue,thelogntermsinthebounds
(cid:0) (cid:1)
will be replaced by logn+log 1+∥∇F(θ )∥ /σ .
0 2 ∗
9In other words, we obtain a near-optimal bound on the gradient norm with (1 + ω) pre-factor
compared to the asymptotic optimal limit, as long as the sample size is larger than the threshold
O(cid:0)L
+
ℓ2 Ξ(cid:1)
, up to log factors. We remark that this threshold is also sharp: the term
O(cid:0)L(cid:1)
is the
µ µ2 µ
(cid:0)ℓ2 (cid:1)
number of iterations needed for gradient descent, while the O Ξ term is the smallest sample size
µ2
needed to distinguish the quadratic function µ ∥x∥2 from the constant function 0, under the noise
2 2
Assumption 2. This establish a gradient-norm result complementary to the function value bound
in [FGKS15]. The gradient norm bound does not require the self-concordant condition needed
in [FGKS15], and achieves a sharper convergence rate in terms of both the (1+ω) factor and the
initial condition.6
With a potentially sub-optimal choice of α ∈ (0,1), one would get a worse exponent in the
dependency of n on ω in the bound (12), while the rest parts of the bound remain unchanged. If
ω is taken as a constant, the near-optimal bounds are available for the entire range of parameter
α ∈ (0,1). Finally, we note that the bound (12) lead to an O(cid:101)(n−4/3) bound on the additional
term, achieved by the stepsize choice η = 1 . This rate and step-size choice, however, is
t cµT02/3t1/3
not always optimal. In particular, as we will see in the next section, with the one-point Hessian
Lipschitz condition on the objective function F, we can obtain an improved O(cid:101)(n−3/2) bound on
the additional term.
3.2 Upper bounds on the estimation error
To obtain a precise upper bound for the estimation error E∥θ −θ∗∥2 that matches the asymptotic
T 2
limit, we need the following one-point Hessian Lipschitz condition, as a quantitative counterpart of
the continuity Assumption 4:
Assumption 4′. There exists L > 0, such that for any θ ∈ Rd, we have:
2
|||∇2F(θ)−∇2F(θ∗)||| ≤ L ∥θ−θ∗∥
op 2 2
NotethatsomeformofquantitativedescriptiononthemodulusofcontinuityoftheHessianma-
trixatθ∗isnecessarytogetanyboundontheestimationerrorthatscalesas 1Tr(cid:0) (H∗)−1Σ∗(H∗)−1(cid:1) .
n
If the Hessian can change sharply in a neighborhood of θ∗, the Hessian at this specific point will
becomeirrelevant. Here, wemakeastandardone-pointHessianLipschitzcondition, whileitiseasy
to extend our analysis to the case with one-point H¨older conditions.
We also need the following stronger fourth moment conditions for technical reasons. Note that
these conditions are also exploited in prior works [MB11, GP23].
Assumption 2′. The noise function θ (cid:55)→ ∇ f(θ,ξ) in the stochastic gradient satisfies the bound
θ
E∥ε(θ 1;ξ)−ε(θ 2;ξ)∥4
2
≤ ℓ(cid:101)Ξ4 ∥θ 1−θ 2∥4
2
for all pairs θ 1,θ
2
∈ Rd (13)
Assumption 3′. At the optimum θ∗, the stochastic gradient noise ε(θ∗;ξ) has bounded fourth
moment: σ 4 := E∥∇f(θ∗;ξ)∥4 is finite.
(cid:102)∗ 2
By H¨older’s inequality, it is clear that the constants in Assumptions 2′ and 3′ are larger than their
second-moment counterparts, i.e., ℓ
Ξ
≤ ℓ(cid:101)Ξ and σ
∗
≤ σ (cid:102)∗.
Under the fourth moment conditions, we can establish the following fourth-moment bounds for
the processes z and v , analogous to the second-moment results in Proposition 1.
t t
6The dependency on ∥∇F(θ )∥ decays exponentially fast and is omitted for simplicity.
0 2
10Proposition 2. Under Assumptions 1, 2′, and 3′, there exist universal constants c ,c ,C > 0,
1 2
2
using burn-in time T ≥ C(ℓ(cid:102)Ξ +L), if the step sequence is non-increasing, and c1 < η < c ( µ ∧1)
0 µ2 µ µt t 2 ℓ2 L
Ξ
when t > T . We have the following bounds for any T ≥ 2T logT :
0 0 0
E∥z ∥4 ≤
C(cid:32) σ (cid:102)∗2
+
ℓ(cid:101)Ξ2 T 0logT
∥∇F(θ
)∥2(cid:33)2
and E∥v ∥4 ≤
C(cid:32) σ (cid:102)∗2
+
T
0 ∥∇F(θ
)∥2(cid:33)2
T 2 T µ2T2 0 2 T 2 µη T2 µ2T3η2 0 2
T T
See §4.3 for the proof of this claim.
Compared to Proposition 1, the variance parameters (σ ,ℓ ) are replaced with their fourth-
∗ Ξ
moment counterparts (σ (cid:102)∗,ℓ(cid:101)Ξ). These fourth-moment estimates are utilized to control the er-
ror induced by approximation the estimation error θ − θ∗ using the pre-conditioned gradient
T
(H∗)−1∇F(θ ). As with the case of Proposition 1, these terms appear only in the high-order terms
T
of Theorem 4.
Now we are ready to present our main theorem, which provides the MSE bounds on the es-
timation error θ −θ∗, with the sharp pre-factor. To state the theorem, we define the following
T
auxiliary quantities that appears in the high-order terms:
H(∇) := logT ·
σ ∗2 (cid:18) T 0(cid:19)α∧1−α
+logT ·E∥∇F(θ
)∥2(cid:18) T 0(cid:19)2∧7 2−2α
(14a)
T T T 0 2 T
(cid:114)
r :=
σ (cid:102)√∗
+
logT T 0 ·(cid:0)E∥∇F(θ )∥4(cid:1)1/4
and (14b)
(cid:101)T µ T µ T 0 2
σ2log2n (cid:18) T (cid:19)α∧1−α L σ 3log2n L2σ 4log2n
H(σ) := ∗ 0 + 2(cid:102)∗ + 2(cid:102)∗ (14c)
n λ (H∗)2n n λ (H∗)µ3n3/2 λ (H∗)2µ4n2
min min min
(∇)
The term H is part of the high-order term that appears in the bound for the gradient norm.
T
It is indeed the upper bound for the superfluous part of the noise in the processes (z ) and
t t≥T0
(v ) , without taking into account the cross term E⟨z , v ⟩. The quantity r is a coarse upper
t t≥T0 t t (cid:101)T
bound on the convergence rate ∥θ −θ∗∥ in terms of the fourth moment. In combination with the
t 2
one-point Hessian Lipschitz Assumption 4′, this quantity controls the additional linearization error
induced by relating the non-asymptotic behavior of the gradient to the iterates. Finally, the term
(σ)
H is used to characterize the high-order terms for the error in the multi-loop estimator produced
n
by Algorithm 1.
Theorem 4. Under Assumptions 1, 2′, 3′ and 4′, there exists universal constant c,c > 0, for
1
(cid:18) (cid:19)
2
burn-in-time T = c ℓ(cid:102)Ξ + L and stepsize η = c1 for t ≥ T , we have the following bounds
0 µ2 µ t µT01−αtα 0
holding true for t ≥ 2T logT :
0 0
Tr(cid:0) (H∗)−1Σ∗(H∗)−1(cid:1) cH(∇) cL r3 cL r4
E∥θ −θ∗∥2 ≤ + T + 2(cid:101)T + 2(cid:101)T (15a)
T 2 T λ (H∗)2 λ (H∗) λ (H∗)2
min min min
Furthermore, for B ≥ clogn, the multi-loop estimator by Algorithm 1 satisfies the bound
(cid:13) (cid:13)2
Tr(cid:0) (H∗)−1Σ∗(H∗)−1(cid:1)
E(cid:13) (cid:13)θ(cid:98)n−θ∗(cid:13)
(cid:13) 2
≤
n
+cH n(σ) (15b)
See §4.4 for the proof of this theorem.
11Afewremarksareinorder. First,wenotethattheasymptoticallyoptimal
1Tr(cid:0) (H∗)−1Σ∗(H∗)−1(cid:1)
n
variance is achieved with the exact pre-factor 1. Taking the optimal stepsize choice with α = 1/2,
the high order term scales as O(n−3/2) in both bounds (15a) and (15b). This is made possible by
the stochastic Lipschitz condition for the gradient noise, and strictly improves existing bounds of
O(n−7/6) in the paper [MB11] and the O(n−5/4) bound in the paper [Xu11, GP23]. It is easy to
see that the bound (15b) is obtained by removing the terms depending on the initial condition,
up to logarithmic factors in the additional term. This is natural because the initial condition is
forgotten exponentially fast in the first B restarting epochs of Algorithm 1. Finally, when taking
(σ)
the optimal parameter α = 1/2, the three high-order terms in the expression of H have a clean
n
interpretation.
(cid:16) √ (cid:17)
• The first term O(cid:101)
σ ∗2 T0
characterizes the additional gradient noise collected in a neigh-
λmin(H∗)2n3/2
borhood of θ∗. Since θ∗ itself is unknown, the best possible estimator naturally take the average
ofgradientnoiseinaneighborhoodaroundθ∗ ofradiusO(cid:0) σ √∗ (cid:1) , whichistherateforestimating
µ n
θ∗. Under Assumption 2, the variance for gradient noise at θ ∈ B(cid:0) θ∗, σ √∗ (cid:1) , pre-conditioned
µ n
with Hessian H∗, scales as:
E(cid:13) (cid:13)(H∗)−1ε t(θ)(cid:13) (cid:13)2
2
≤ E(cid:13) (cid:13)(H∗)−1ε t(θ∗)(cid:13) (cid:13)2
2
(cid:113)
+2 E(cid:13) (cid:13)(H∗)−1(cid:0) ε t(θ)−ε t(θ∗)(cid:1)(cid:13) (cid:13)2 2·E∥(H∗)−1ε t(θ∗)∥2 2+E(cid:13) (cid:13)(H∗)−1(cid:0) ε t(θ)−ε t(θ∗)(cid:1)(cid:13) (cid:13)2
2
≤ Tr(cid:0) (H∗)−1Σ∗(H∗)−1(cid:1) +2 ℓ Ξσ ∗ ∥θ−θ∗∥ + ℓ2 Ξ ∥θ−θ∗∥2
λ (H∗)2 2 λ (H∗)2 2
min min
=
Tr(cid:0) (H∗)−1Σ∗(H∗)−1(cid:1) +O(cid:18) σ ∗2ℓ Ξ (cid:19)
µλ2 (H∗)n3/2
min
(cid:16) √ (cid:17)
The above derivations is tight in the worst case. Compared to the term O(cid:101)
σ ∗2 T0
in
λmin(H∗)2n3/2
our bound (15b), the difference is that we replace
ℓ2
Ξ with T =
c(cid:16)
L +
ℓ2 Ξ(cid:17)
and is optimal up
µ2 0 µ µ2
to a polylogarithmic factor when L ≪
ℓ2
Ξ.7
µ µ2
• The rest two terms involves the one-point Hessian-Lipschitz parameter L . A natural lineariza-
2
tion argument in the neighborhood of θ∗ on the (generally non-linear) gradient function leads
to these terms. In particular, simple calculus yields the following bounds:
(cid:13) (cid:13)(H∗)−1∇F(θ)−(θ−θ∗)(cid:13) (cid:13) ≤ L 2 ∥θ−θ∗∥2
2 λ (H∗) 2
min
Substituting with the L4 convergence rate for the iterates θ − θ∗ yields the bound on this
T
(σ)
linearization error, which matches the latter two terms in H .
n
The arguments in the proof of Theorem 4 indeed applies to any function that is locally quadratic
around θ∗. Applying it to the function F itself, we arrive at the following theorem:
7Intheoppositecase,thenon-tightprefactorisconsideredunavoidablebecauseourmethoddoesnotaccountfor
n in advance.
12Theorem 5. Under the same setup as in Theorem 4, we have the following bounds on the excess
risk:
Tr(cid:0) Σ∗(H∗)−1(cid:1) cH(∇) cL r4
E[F(θ )]−F(θ∗) ≤ + T +cL r3 + 2(cid:101)T (16a)
T 2T λ (H∗) 2(cid:101)T λ (H∗)
min min
and for the multi-loop estimator θ(cid:98)n with B ≥ clogn, we have that
Tr(cid:0) Σ∗(H∗)−1(cid:1)
E[F(θ )]−F(θ∗) ≤ +cλ (H∗)·H(σ) (16b)
T 2n min n
See §4.5 for the proof of this theorem.
(cid:0) (cid:1)
Tr Σ∗(H∗)−1
Notethatundertheone-pointHessian-LipschitzAssumption4′,theleading-orderterm
2n
istheasymptoticriskunderthelimitingGaussiandistribution. Thehigh-ordertermsinTheorem5
differ from those in Theorme 4 by a factor of λ (H∗). This bound replaces the self-concordance
min
assumption in [FGKS15] with a less structural one-point Hessian-Lipschitz condition. Theorem 5
and their results are not comparable in general, as they are based on different assumptions. When
taking the optimal trade-off, Theorem 5 leads to an O(n−3/2) high-order term in addition to the
sharp leading-order one. This result matches the bounds for ERM in [FGKS15], and improves the
bounds for streaming SVRG in [FGKS15] in terms of the rate of convergence for the additional
term.
4 Proof of the non-asymptotic bounds with sharp pre-factor
Inthissection,wepresenttheproofsforTheorem3,Theorem4andTheorem5. Thesethreeresults
provide upper bounds on three different metrics (gradient norm, iterate distance, and function
value),withtheleading-ordertermexactlymatchingtheoptimalnormallimit,andsharphigh-order
terms. Enrouteourproof,in§4.1and§4.3,wepresenttheproofsofProposition1andProposition2,
the non-asymptotic convergence rates for the process (v ) and (z ) . These results serve as
t t≥T0 t t≥T0
the basic building blocks for the fine-grained asymptotic and non-asymptotic guarantees.
4.1 Proof of Proposition 1
Our main technical tools are the following two lemmas, which bound the second moments of v and
t
z based on other parameters.
t
Lemma 1. Under Assumption 1, 2, 3, when η ≤ 1 ∧ µ , we have:
t 2L ℓ2
Ξ
(cid:18) 1(cid:19)2(cid:16) η µ(cid:17) 26 2σ2
E∥v ∥2 ≤ 1− 1− t−1 E∥v ∥2+ E∥∇F(θ )∥2+ ∗
t 2 t 2 t−1 2 µη t2 t−1 2 t2
t−1
√
For the process z , we have the following lemma which leads to an O(1/ t) bound.
t
Lemma 2. Under Assumptions 1, 2 and 3, for t ≥ 1, we have:
E∥z ∥2 ≤
T 02∥z 0∥2
2 +
2σ ∗2
+
2ℓ2
Ξ
(cid:88)t−1
E∥∇F(θ )∥2+
ℓ2
Ξ
(cid:88)t−1
s2η2E∥v ∥2
t 2 t2 t µ2t2 s 2 t2 s s 2
s=T0 s=T0
13The proofs of the Lemmas are postponed to Section A.1 and Section A.2 respectively. Given these
lemmas, we now give a proof of this proposition.
We first note that for any t ≥ 2 and η < 1 , we have:
t 2L
E∥∇F(θ )∥2 ≤ 2E∥∇F(θ )∥2+2E∥∇F(θ )−∇F(θ )∥2
t 2 t−1 2 t t−1 2
≤ 2E∥v −z ∥2+2L2η2E∥v ∥2 ≤ 6E∥v ∥2+4E∥z ∥2
t t 2 t t 2 t 2 t 2
Therefore, by Lemma 1, if t and η satisfies tη µ > 1 , we obtain:
t−1 t−1 4C
(cid:16) η µ(cid:17)(cid:18) 1(cid:19)2 C 2σ2
E∥v ∥2 ≤ 1− t−1 1− E∥v ∥2+ (E∥v ∥2+E∥z ∥2)+ ∗
t 2 2 t t−1 2 µη t2 t−1 2 t−1 2 t2
t−1
(cid:16) η µ(cid:17)(cid:18) 1(cid:19)2 2C 2σ2
≤ 1− t−1 1− E∥v ∥2+ E∥z ∥2+ ∗
4 t t−1 2 t2µη t−1 2 t2
t−1
Consequently, we obtain:
2C
t2E∥v ∥2 ≤ (1−cη µ)(t−1)2E∥v ∥2+ E∥z ∥2+2σ2 (17)
t 2 t−1 t−1 2 µη t−1 2 ∗
t−1
for a universal constant C > 0.
Similarly, by Lemma 2, if s satisfies sη µ > 1 for any s > T , we have:
s−1 4C 0
E∥z ∥2 ≤
T 02E∥z T0∥2
2 +
2σ ∗2
+C
ℓ2
Ξ
(cid:88)t−1
(E∥z ∥2+E∥v ∥2)+
ℓ2
Ξ
(cid:88)t−1
s2η2E∥v ∥2
t 2 t2 t µ2t2 s 2 s 2 t2 s s 2
s=T0 s=T0
≤
T 02E∥z T0∥2
2 +
2σ ∗2
+C
ℓ2
Ξ
(cid:88)t−1
E∥z
∥2+C′ℓ2
Ξ
(cid:88)t−1
s2η2E∥v ∥2 (18)
t2 t µ2t2 s 2 t2 s s 2
s=T0 s=T0
for a universal constant C′ > 0.
Note that the bounds (17) and (18) give recursive upper bounds on the second moments of the
processes (z ) and (v ) , i.e., they bound the quantities E∥z ∥2 and E∥v ∥2 based on their
t t≥T0 t t≥T0 t 2 t 2
history. In the following, we solve the recursive inequalities.
We define the following quantities for T ≥ T :
0
W := T2E∥v ∥2 and H := sup tE∥z ∥2
T T 2 T t 2
T0≤t≤T
First, for any T > T , by taking the supremum in Eq (18) over t ∈ [T ,T], we obtain the
0 0
following bound:
sup tE∥z ∥2 ≤ T E∥z
∥2+2σ2+Cℓ2
Ξ sup
1 (cid:88)t−1 Es∥z s∥2
2 +C′ℓ2 sup
1 (cid:88)t−1
η2 s2E∥v ∥2
t 2 0 T0 2 ∗ µ2 t s Ξ t t−1 s 2
T0≤t≤T T0≤t≤T
s=T0
T0≤t≤T
s=T0
 
ℓ2 1 (cid:88)t 1 1 (cid:88)t−1
≤ T 0E∥z T0∥2 2+2σ ∗2+C µΞ 2 sup  t s· sup tE∥z t∥2 2+C′ℓ2 Ξ sup t η t2 −1s2E∥v s∥2 2
T0≤t≤T
s=T0
T0≤t≤T T0≤t≤T
s=T0
ℓ2
For T > 2C Ξ, we have:
0 µ2
ℓ2 1 (cid:88)t 1 Cℓ2 1
C Ξ sup ≤ Ξ <
µ2 t s µ2T 2
T0≤t≤T
s=T0
0
14So we can discard the term involving z itself in the right hand side of the above bound at a price
t
of factor 2:
t−1
1 (cid:88)
H ≤ 2H +4σ2+2C′ℓ2 sup η2 W (19a)
T T0 ∗ Ξ t s−1 s
T0≤t≤T
s=T0
On the other hand, the bound (17) implies the bound:
C
W ≤ (1−cη µ)W + H +2σ2 (19b)
T T−1 T−1 Tµη T−1 ∗
T−1
for universal constants c,C > 0.
The solution to above recursive relations are given by the following lemma:
Lemma 3. For a pair of sequences (H ) and (W ) satisfying the recursive relation (19a)
t t≥T0 t t≥T0
with non-increasing stepsize sequence (η ) . Assuming that (H ) is non-decreasing, there
t t≥T0 t t≥T0
exists universal constants c > 0, such that for T ≥ T , we have the bound:
0
(cid:18) ℓ2T η (cid:19)
H ≤ c σ2+ Ξ 0 T0W +H and (20a)
T ∗ µ T0 T0
(cid:32) (cid:33)
W
T
≤ ηc µσ ∗2+c Tµ2T η0
2
+e−µ(cid:80)T t=T0+1ηtT 02 W
T0
(20b)
T T−1
See Section A.3 for the proof of this lemma. Taking this lemma as given, we now proceed with the
proof of this proposition.
First, we note that the exponent in the bound (20b) satisfies the bound:
T T
(cid:88) (cid:88) 1 T
µ η ≥ c ≥ c log
t 1 1
t T
0
t=T0+1 t=T0+1
For c
1
≥ 2 and η
T
≤ µc T′ 0, we have that Tµ2T η0
T2
−1
≥ e−µ(cid:80)T t=T0+1ηtT 02. So the bound (20b) implies
that:
cσ2 cT
E∥v ∥2 ≤ ∗ + 0 E∥v ∥2
t 2 µη t2 t3η2µ2 T0 2
t t
For the process z , by substituting the bounds in Lemma 3 into Eq (18), for stepsize η < 1 ,
t t µT0
we obtain:
 
E∥z t∥2
2
≤
T 02E t∥ 2z T0∥2
2 +
2σ t∗2 +Cℓ µ2
Ξ
2H
t2t
(cid:88)t−1 1 s+C′ℓ t2
Ξ
2
(cid:88)t−1
η s2W
s
s=T0 s=T0
≤
T 02E∥z T0∥2
2 +
2σ ∗2 +Cℓ2 Ξlogt (cid:18)
σ2+
ℓ2 ΞT 0η
T0E∥v
∥2(cid:19) +C′ℓ2
Ξ
(cid:88)t
η
σ ∗2 +C′ℓ2
Ξ
(cid:88)t−1 T
0 E∥v ∥2
t2 t µ2t2 ∗ µ T0 2 t2 s µ t2 sµ2 T0 2
s=T0+1 s=T0
σ2 T 2E∥z ∥2 ℓ2T logt
≤ c ∗ +c 0 T0 2 +c Ξ 0 E∥v ∥2
t t2 µ2t2 T0 2
15For the initial conditions at burn-in period, we have:
(cid:13) (cid:13)2
E∥z ∥2 = T
−2E(cid:13) (cid:13)(cid:88)T0
ε (θ
)(cid:13)
(cid:13) ≤
σ ∗2+ℓ2 Ξ∥θ 0−θ∗∥2
2
T0 2 0 (cid:13) t 0 (cid:13) T
(cid:13) (cid:13) 0
t=0 2
2(σ2+ℓ2 ∥θ −θ∗∥2)
E∥v ∥2 ≤ 2∥∇F(θ )∥2+E∥z ∥2 ≤ 2∥∇F(θ )∥2+ ∗ Ξ 0 2
T0 2 0 2 T0 2 0 2 T
0
Note that ∥θ −θ∗∥2 ≤ 1 ∥∇F(θ )∥2 and T > ℓ2 Ξ, we have ℓ2 Ξ∥θ0−θ∗∥2 2 ≤ E∥∇F(θ )∥2. For
0 2 µ2 0 2 0 µ2 T0 0 2
T ≥ 2T logT , we also have:
0 0
(cid:18) T ℓ2T logT(cid:19) σ2 3σ2 T 2 σ2 σ2
0 + Ξ 0 ∗ ≤ ∗ and 0 · ∗ ≤ ∗
T3η2µ2 T2µ2 T T T2 T T
T 0 0
Putting them together, we have the bounds:
(cid:18) σ2 ℓ2T logT (cid:19) (cid:18) σ2 T (cid:19)
E∥z ∥2 ≤ C ∗ + Ξ 0 ∥∇F(θ )∥2 and E∥v ∥2 ≤ C ∗ + 0 ∥∇F(θ )∥2
T 2 T µ2T2 0 2 T 2 µη T2 µ2T3η2 0 2
T T
which complete the proof of this proposition
4.2 Proof of Theorem 3
We first establish the results for the single-loop algorithm, and then use it to prove the results with
the re-starting loops.
Throughout the proof, we use the following notations for the risk functions
(cid:16) (cid:17)1/2 1 (cid:16) (cid:17)1/2
r (t) := E∥v ∥2 and r (t) := E∥∇F(θ )∥2
v t 2 θ µ T 2
Clearly, by the strong convexity Assumption 1, we have the bound E∥θ −θ∗∥2 ≤ r (t)2.
T 2 θ
We start by observing the following decomposition:
E∥∇F(θ )∥2 = E∥z ∥2+E∥v ∥2−2E⟨z , v ⟩ (21)
T 2 T+1 2 T+1 2 T+1 T+1
The following lemma provides sharp bounds on the leading-order term E∥z ∥2.
T+1 2
Lemma 4. Under above set-up, for T ≥ 2T logT and any G ∈ Rd×d, the following bounds hold
0 0
true for the process (z ) :
t t≥T0
1 (cid:16) (cid:17)
E∥Gz ∥2 ≤ Tr GΣ∗G⊤ +c|||G|||2 H(z) (22a)
T 2 T op T
(z)
where the high order term H is defined as
T
(cid:32)(cid:114) (cid:33) (cid:32) (cid:33)
T T α σ2 T 2logT T2α−3/2
H(z) := c 0 + 0 ∗ +c 0 1+ ∥∇F(θ )∥2 (22b)
T T Tα T T2 T 2α−3/2 0 2
0
16See §A.4 for the proof of this lemma.
Invoking Proposition 1, we have the bound for v :
T
(cid:18) σ2 T (cid:19)
E∥v ∥2 ≤ c ∗ + 0 ∥∇F(θ )∥2
T 2 µη T2 µ2T3η2 0 2
T T
For the stepsize choice η = 1 , we have the bound
t µT01−αtα
T 1−α σ2 T 3−2α
E∥v ∥2 ≤ c 0 · ∗ +c 0 ·∥∇F(θ )∥2 (23)
T 2 T1−α T T3−2α 0 2
Combining the bounds (22a) and (23) and substituting into the decomposition (21), we arrive at
the following bound by applying Young’s inequality:
(cid:113) (cid:113)
E∥∇F(θ )∥2 ≤ E∥z ∥2+E∥v ∥2+2 E∥z ∥2· E∥v ∥2
T 2 T+1 2 T+1 2 T+1 2 T+1 2
(cid:18) (cid:19) (cid:18) (cid:19)
≤ 1+(cid:0)T 0(cid:1)1− 2α ·E∥z ∥2+ 1+(cid:0)T (cid:1)1− 2α E∥v ∥2
T T+1 2 T T+1 2
0
≤
σ ∗2 +c(cid:18) T 0(cid:19)1− 2α∧α σ ∗2 +c(cid:18) T 0(cid:19)2∧5− 23α
logT ·∥∇F(θ )∥2
T T T T 0 2
which proves the first claim (11a).
Now we turn to the proof of multi-loop results. By applying the one-loop result to each short
epoch, we have the bound for b = 1,2,··· ,B:
E(cid:13) (cid:13)∇F(cid:0) θ(b+1)(cid:1)(cid:13) (cid:13)2
≤
σ ∗2 +c(cid:18) T 0(cid:19)1− 2α∧α σ ∗2 +c(cid:18) T 0(cid:19)2∧5− 23α
logT
·E(cid:13) (cid:13)∇F(cid:0) θ(b)(cid:1)(cid:13) (cid:13)2
(cid:13) 0 (cid:13) 2 T♭ T♭ T♭ T♭ (cid:13) 0 (cid:13) 2
( ≤i) 2σ ∗2
+
1 E(cid:13) (cid:13)∇F(cid:0) θ(b)(cid:1)(cid:13) (cid:13)2
T♭ 2 (cid:13) 0 (cid:13) 2
In step (i), we use the fact that T♭ ≥ 2cT logT and that 2∧ 5−3α > 1 for α ∈ (0,1).
0 0 2
Solving the recursion, we arrive at the bound:
E(cid:13) (cid:13) (cid:13)∇F(cid:0) θ 0(B+1)(cid:1)(cid:13) (cid:13) (cid:13)2
2
≤ 4 Tσ 0∗2 +2−BE(cid:13) (cid:13)∇F(cid:0) θ 0(cid:1)(cid:13) (cid:13)2
2
Substituting this initial condition into the bound (11a), we obtain the final bound:
E(cid:13) (cid:13)∇F(cid:0) θ(B+1)(cid:1)(cid:13) (cid:13)2 ≤ σ ∗2 +c(cid:18) T 0(cid:19)1− 2α∧α σ ∗2 +c(cid:18) T 0(cid:19)2∧5− 23α logT ·(cid:16) 4σ2+2−B∥∇F(θ )∥2(cid:17)
(cid:13) T (cid:13) 2 T T T T ∗ 0 2
Taking B ≥ clogn and substituting with T = n−BT♭, we arrive at the conclusion:
E(cid:13)
(cid:13)
(cid:13)∇F(θ(cid:98)n)(cid:13)
(cid:13)
(cid:13)2
2
≤
(cid:18) 1+c(cid:0)T n0(cid:1)1− 2α∧α log2n(cid:19) σ n∗2
which proves the bound (11b).
174.3 Proof of Proposition 2
Throughout the proof, we frequently use the following inequalities for the moments of stochastic
gradients, which holds true for any θ ∈ Rd:
4
E∥∇f(θ,ξ )∥4 ≤ 27σ 4+27(cid:0) 1+ ℓ(cid:101)Ξ (cid:1)E∥∇F(θ)∥4 (24)
t 2 (cid:102)∗ µ4 2
To see why this is true, we note that:
E∥∇f(θ,ξ )∥4 ≤ 27E∥∇F(θ)∥4+27E∥ε (θ∗)∥4+27E∥ε (θ)−ε (θ∗)∥4
t 2 2 t 2 t t 2
≤ 27σ (cid:102)∗4+27E∥∇F(θ)∥4 2+27ℓ(cid:101)Ξ4 E∥θ−θ∗∥4
2
4
≤ 27σ
4+27(cid:0)
1+
ℓ(cid:101)Ξ (cid:1)E∥∇F(θ)∥4
(cid:102)∗ µ4 2
Now we turn to the proof of this proposition. Similar to the proof of Proposition 1, we need
the following technical lemmas:
Lemma 5. Under Assumption 1, 2′, 3, there exists universal constants c,c′ > 0, when η ≤
t
c(cid:0)1 ∧ µ (cid:1) , we have the bound
L 2
ℓ(cid:102)Ξ
(cid:113) (cid:18) 1(cid:19)2(cid:16) µη (cid:17)(cid:113) c′ (cid:18) 1 (cid:113) (cid:19)
E∥v ∥4 ≤ 1− 1− t−1 E∥v ∥4+ σ 2+ E∥∇F(θ )∥4
t 2 t 2 t−1 2 t2 (cid:102)∗ µη t−1 2
t−1
Lemma 6. Under Assumption 2′, we have the bound
(cid:113)
E∥z ∥4 ≤
cT 02∥z 0∥2
2 +
cσ (cid:102)∗2
+
cℓ(cid:101)Ξ2 (cid:88)t−1 (cid:113)
E∥∇F(θ )∥4+
cℓ(cid:101)Ξ2 (cid:88)t−1 s2η2(cid:113)
E∥v ∥4
t 2 t2 t µ2t2 s 2 t2 s s 2
s=T0 s=T0
See Section A.5 and A.6 for the proofs of the two lemmas. Taking these two lemmas as given, we
now proceed with the proof of the proposition.
The rest of proof goes in parallel with the proof of Proposition 1. We first note that:
(cid:113) (cid:113) (cid:113)
E∥∇F(θ )∥4 ≤ 4 E∥∇F(θ )∥4+4 E∥∇F(θ )−∇F(θ )∥4
t 2 t−1 2 t t−1 2
(cid:113) (cid:113) (cid:113) (cid:113) (cid:113)
≤ 4 E∥z ∥2+4 E∥v ∥2+4(η L)4 E∥v ∥4 ≤ 4 E∥z ∥4+6 E∥v ∥4
t 2 t 2 t t 2 t 2 t 2
(cid:113)
SubstitutingintotheboundsinLemma5and6,anddefiningthequantitiesH := sup t E∥z ∥4,
T T0≤t≤T t 2
(cid:113)
W := T2 E∥v ∥4, we arrive at the following recursive inequalities:
T T 2
t−1
H
T
≤ 2H
T0
+4σ
(cid:102)∗2+2C′ℓ(cid:101)Ξ2
sup
1
t
(cid:88)
η s2 −1W
s
(25a)
T0≤t≤T
s=T0
C
W ≤ (1−cη µ)W + H +2σ 2 (25b)
T T−1 T−1 T−1 (cid:102)∗
Tµη
T−1
18Invoking Lemma 3 by replacing (ℓ Ξ,σ ∗) with (ℓ(cid:101)Ξ,σ (cid:102)∗), we obtain the following bounds:
(cid:18) ℓ2T η (cid:19)
H ≤ c σ2+ Ξ 0 T0W +H and
T ∗ µ T0 T0
(cid:32) (cid:33)
W
T
≤ ηc µσ ∗2+c Tµ2T η0
2
+e−µ(cid:80)T t=T0+1ηtT 02 W
T0
T T−1
For the initial conditions, by applying Khintchine’s inequality as well as Young’s inequality, we
note that:
E∥z T0∥4
2
= T
0−4E(cid:13)
(cid:13) (cid:13)
(cid:13)(cid:88)T0
ε t(θ
0)(cid:13)
(cid:13) (cid:13)
(cid:13)4
≤ T
0−4E(cid:32) (cid:88)T0
∥ε t(θ 0)∥2
2(cid:33)2
≤ 8T 0−2(cid:16) σ (cid:102)∗4+ℓ(cid:101)Ξ4 ∥θ 0−θ∗∥4 2(cid:17)
(cid:13) (cid:13)
t=1 2 t=1
E∥v T0∥4
2
≤ 8E∥∇F(θ 0)∥4 2+E∥z T0∥4
2
≤ 8∥∇F(θ 0)∥4 2+8T 0−2(cid:16) σ (cid:102)∗4+ℓ(cid:101)Ξ4 ∥θ 0−θ∗∥4 2(cid:17)
Following exactly the same arguments as in the proof of Proposition 1, we arrive at the desired
bounds.
4.4 Proof of Theorem 4
We define the quantities r (t) and r (t) the same as in the proof of Theorem 3. Furthermore, we
θ v
denote the following quantities:
(cid:16) (cid:17)1/4 1 (cid:16) (cid:17)1/4
r (t) := E∥v ∥4 and r (t) := E∥∇F(θ )∥4
(cid:101)v t 2 (cid:101)θ µ t 2
Clearly, by the strong convexity Assumption 1, we have the bound E∥θ −θ∗∥4 ≤ r (t)4.
T 2 θ
We also note the following decomposition of the gradient:
(cid:90) 1
∇F(θ ) = ∇2F(cid:0) γθ∗+(1−γ)θ (cid:1) (θ −θ∗)dγ
T T T
0
which leads to the following bound under Assumption 4′:
(cid:90) 1
(cid:13) (cid:13)(H∗)−1∇F(θ T)−(θ T −θ∗)(cid:13) (cid:13) 2 ≤ (cid:13) (cid:13)(H∗)−1(cid:0) ∇2F(cid:0) γθ∗+(1−γ)θ T(cid:1) −H∗(cid:1) (θ T −θ∗)(cid:13) (cid:13) 2dγ
0
L L
≤ 2 ∥θ −θ∗∥2 ≤ 2 ∥∇F(θ )∥2 (26)
λ (H∗) T 2 λ (H∗)µ2 T 2
min min
We can then upper bound the mean-squared error using the processes (z ) and (v ) :
t t≥T0 t t≥T0
E∥θ T −θ∗∥2 2 ≤
E(cid:18)
(cid:13) (cid:13)(H∗)−1∇F(θ T)(cid:13) (cid:13) 2+ µ2λ L 2 (H∗) ∥∇F(θ T)∥2
2(cid:19)2
min
≤ E(cid:13) (cid:13)(H∗)−1(cid:0) v T+1−z T+1(cid:1)(cid:13) (cid:13)2 2+2
λ
L (2 H∗)r (cid:101)θ3(T)+
λ
L (H2 2 ∗)2r (cid:101)θ4(T) (27)
min min
The leading-order term in the bound (27) admits the following decomposition:
E(cid:13) (cid:13)(H∗)−1(cid:0) z T+1−v T+1(cid:1)(cid:13) (cid:13)2
2
= E(cid:13) (cid:13)(H∗)−1z T+1(cid:13) (cid:13)2 2+E(cid:13) (cid:13)(H∗)−1v T+1(cid:13) (cid:13)2 2−2E(cid:2) ⟨(H∗)−1z T, (H∗)−1.v T⟩(cid:3)
19In the following, we bound the three terms in above equation, respectively. Invoking Lemma 4
with G = (H∗)−1, we have the bound:
E(cid:13) (cid:13)(H∗)−1z T+1(cid:13) (cid:13)2
2
≤ Tr(cid:0) (H∗)−1 TΣ∗(H∗)−1(cid:1) +
λ
c (σ H∗2
∗)2T
(cid:18) T T0(cid:19)α∧ 21 + c∥∇ λF(θ (0 H)∥ ∗2 2 )l 2ogT (cid:18) T T0(cid:19)2∧7 2−2α
min min
(28a)
For the process v , Proposition 1 yields the following upper bound:
t
E(cid:13) (cid:13)(H∗)−1v T+1(cid:13) (cid:13)2
2
≤
λ
(1 H∗)2E∥v T+1∥2
2
≤
λ
c (σ H∗2
∗)2T
(cid:18) T T0(cid:19)1−α + c λ∥∇F (( Hθ 0 ∗) )∥ 22 2 (cid:18) T T0(cid:19)3−2α
min min min
(28b)
The bound for the cross term is given by the following lemma:
Lemma 7. Under above set-up, for T ≥ cT logT , for any d × d deterministic matrix G, the
0 0
following bound holds true:
|E[⟨Gz , Gv ⟩]| ≤ c|||G|||2 (cid:0)T 0(cid:1)1−α(cid:18) σ ∗2 +(cid:0)T 0(cid:1)2−α ∥∇F(θ )∥2(cid:19) logt
t t op t t t 0 2
(cid:32) (cid:33)
+c|||G|||2 opL 2(cid:0)T 0(cid:1)1− 2α σ (cid:102)∗3 +(cid:0)T 0(cid:1)3−3α/2 log2t∥∇F(θ )∥3
µ2 t t3/2 t 0 2
See §A.7 for the proof of this lemma.
Substituting with G = (H∗)−1, we obtain the bound for the cross term:
(cid:12) (cid:12)E(cid:2) ⟨(H∗)−1z t, (H∗)−1v t⟩(cid:3)(cid:12) (cid:12) ≤ λcσ ∗2 (Hlog ∗)T
2T
(cid:18) T T0(cid:19)1−α + c∥∇ λF(θ (0 H)∥ ∗2 2 )l 2ogT (cid:18) T T0(cid:19)3−2α
min min
+
cL 2σ (cid:102)∗3 (cid:18) T 0(cid:19)1− 2α
+
cL 2∥∇F(θ 0)∥3 2log2T (cid:18) T 0(cid:19)7 2−2α
(28c)
λ (H∗)2µ2T3/2 T λ (H∗)2µ2 T
min min
For the rest two terms in the expression (27), we invoke Proposition 2, and obtain the rate:
√
cσ c logT
(cid:18)
T
(cid:19)1∧3/2−α
r (T) ≤
√(cid:102)∗
+ ∥∇F(θ )∥
0
(28d)
(cid:101)θ µ T µ 0 2 T
Combining the bounds (28a)-(28d) and substituting into the decomposition (27), we arrive at the
bound
E∥θ −θ∗∥2 ≤
Tr(cid:0) (H∗)−1Σ∗(H∗)−1(cid:1)
+
cσ ∗2logT (cid:18) T 0(cid:19)α∧1−α +cE∥∇F(θ 0)∥2 2logT (cid:18) T 0(cid:19)2∧ 27−2α
T 2 T λ (H∗)2T T λ (H∗)2 T
min min
+
cL 2σ (cid:102)∗3
+
cL 2E∥∇F(θ 0)∥3 2log2T (cid:18) T 0(cid:19)7 2−2α∧3
λ (H∗)µ3T3/2 λ (H∗)µ3 T
min min
cL2σ 4 cL2E∥∇F(θ )∥4log2T (cid:18) T (cid:19)6−4α∧4
+ 2(cid:102)∗ + 2 0 2 0
λ (H∗)2µ4T2 λ (H∗)2µ4 T
min min
Noting that 7 −2α∧3 ≥ 3 and 6−4α∧4 ≥ 4, we complete the proof of the bound (15a).
2 2
20Now we turn to the proof of the multi-loop result (15b). Invoking Proposition 1 and 2 and
noting that ∥∇F(θ )∥ ≤ ∥z ∥ +∥v ∥ , we obtain the bound for T♭ ≥ cT logT :
t 2 t+1 2 t+1 2 0 0
E(cid:13) (cid:13)∇F(cid:0) θ(b+1)(cid:1)(cid:13) (cid:13)2
≤
1 E(cid:13) (cid:13)∇F(cid:0) θ(b)(cid:1)(cid:13) (cid:13)2
+
cσ ∗2
and
(cid:13) 0 (cid:13) 2 2 (cid:13) 0 (cid:13) 2 T♭
(cid:114) E(cid:13) (cid:13)∇F(cid:0) θ(b+1)(cid:1)(cid:13) (cid:13)4
≤
1(cid:114) E(cid:13) (cid:13)∇F(cid:0) θ(b)(cid:1)(cid:13) (cid:13)4
+
cσ (cid:102)∗2
(cid:13) 0 (cid:13) 2 2 (cid:13) 0 (cid:13) 2 T♭
Solving the recursion, we have that:
E(cid:13) (cid:13) (cid:13)∇F(cid:0) θ 0(B+1)(cid:1)(cid:13) (cid:13) (cid:13)2
2
≤ 2−BE(cid:13) (cid:13)∇F(cid:0) θ 0(cid:1)(cid:13) (cid:13)2 2+ 2 Tcσ ♭∗2 and
(cid:114) E(cid:13) (cid:13) (cid:13)∇F(cid:0) θ 0(B+1)(cid:1)(cid:13) (cid:13) (cid:13)4
2
≤ 2−B(cid:113) E(cid:13) (cid:13)∇F(cid:0) θ 0(cid:1)(cid:13) (cid:13)4 2+ 2c Tσ (cid:102) ♭∗2
Taking B ≥ clogn and substituting into the bound (15a), we have the following guarantee for the
multi-loop estimator:
(cid:13) (cid:13)2 Tr(cid:0) (H∗)−1Σ∗(H∗)−1(cid:1) cσ2log2n (cid:18) T (cid:19)α∧1−α
E(cid:13) (cid:13)θ(cid:98)n−θ∗(cid:13)
(cid:13) 2
≤
n
+
λ
min∗
(H∗)2n
n0
cL σ 3log2n cL2σ 4log2n
+
2(cid:102)∗
+
2(cid:102)∗
λ (H∗)µ3n3/2 λ (H∗)2µ4n2
min min
which completes the proof.
4.5 Proof of Theorem 5
Applying second-order Taylor expansion with integral remainder, for any θ ∈ Rd, we note the
following identity.
(cid:90) 1
F(θ) = F(θ∗)+⟨θ−θ∗, ∇F(θ∗)⟩+(θ−θ∗)⊤ ∇2F(cid:0) γθ+(1−γ)θ∗(cid:1) dγ ·(θ−θ∗)
0
Noting that ∇F(θ∗) = 0 and invoking Assumption 4′, we have that:
F(θ) ≤ F(θ∗)+ 1 (θ−θ∗)⊤H∗(θ−θ∗)+∥θ−θ∗∥ ·(cid:90) 1 |||∇2F(cid:0) γθ+(1−γ)θ∗(cid:1) −H∗||| dγ ·∥θ−θ∗∥
2 2 op 2
0
1
≤ F(θ∗)+ (θ−θ∗)⊤H∗(θ−θ∗)+L ∥θ−θ∗∥3 (29)
2 2 2
Similar to Eq (26), we have the bound:
(cid:13) (cid:13) (cid:90) 1(cid:13) (cid:13)
(cid:13)(H∗)1/2(θ−θ∗)−(H∗)−1/2∇F(θ)(cid:13) ≤ (cid:13)(H∗)−1/2(cid:0) ∇2F(cid:0) γθ∗+(1−γ)θ (cid:1) −H∗(cid:1) (θ −θ∗)(cid:13) dγ
(cid:13) (cid:13) (cid:13) T T (cid:13)
2 0 2
L L
≤ 2 ∥θ −θ∗∥2 ≤ 2 ∥∇F(θ )∥2
(cid:112) λ (H∗) T 2 (cid:112) λ (H∗)µ2 T 2
min min
21Denote the residual q := (H∗)1/2(θ −θ∗)−(H∗)−1/2∇F(θ ). Substituting into the bound (29),
t t t
we have that:
1 (cid:13) (cid:13)2
E[F(θ )]−F(θ∗) ≤ E(cid:13)(H∗)−1/2∇F(θ)+q (cid:13) +L E∥θ −θ∗∥3
T 2 (cid:13) T(cid:13) 2 2 T 2
1 (cid:13) (cid:13)2
≤ E(cid:13)(H∗)−1/2(z +v )(cid:13) +2L r3(T)+E∥q ∥2
2 (cid:13) T+1 T+1 (cid:13) 2 2(cid:101)θ T 2
1 (cid:13) (cid:13)2 L2
≤ E(cid:13)(H∗)−1/2(z +v )(cid:13) +2L r3(T)+ 2 r4(T)
2 (cid:13) T+1 T+1 (cid:13) 2 2(cid:101)θ λ min(H∗)(cid:101)θ
Invoking Proposition 1, Lemma 4 and 9 with G = (H∗)−1/2, we have the bounds
E(cid:13)
(cid:13)(H∗)−1/2z
(cid:13) (cid:13)2
≤
Tr(cid:0) Σ∗(H∗)−1(cid:1)
+
cσ ∗2 (cid:18) T 0(cid:19)α∧1 2
+
c∥∇F(θ 0)∥2 2logT (cid:18) T 0(cid:19)2∧7 2−2α
(cid:13) T+1(cid:13) 2 T λ min(H∗)T T λ min(H∗) T
(cid:13) (cid:13)2 E∥v ∥2 cσ2 (cid:18) T (cid:19)1−α c∥∇F(θ )∥2 (cid:18) T (cid:19)3−2α
E(cid:13)(H∗)−1/2v (cid:13) ≤ T+1 2 ≤ ∗ 0 + 0 2 0
(cid:13) T+1(cid:13) 2 λ min(H∗) λ min(H∗)T T λ min(H∗) T
and
(cid:104) (cid:105) cσ2logT (cid:18) T (cid:19)1−α c∥∇F(θ )∥2logT (cid:18) T (cid:19)3−2α
E ⟨(H∗)−1/2z , (H∗)−1/2v ⟩ ≤ ∗ 0 + 0 2 0
t t λ (H∗)T T λ (H∗) T
min min
+
cL 2σ (cid:102)∗3 (cid:18) T 0(cid:19)1− 2α
+
cL 2∥∇F(θ 0)∥3 2log2T (cid:18) T 0(cid:19) 27−2α
(30)
λ (H∗)µ2T3/2 T λ (H∗)µ2 T
min min
Putting them together, we arrive at the bound
Tr(cid:0) (H∗)−1Σ∗(cid:1) cσ2logT (cid:18) T (cid:19)α∧1−α
E[F(θ )−F(θ∗)] ≤ + ∗ 0
T 2T λ (H∗)T T
min
+
cE∥∇F(θ 0)∥2 2logT (cid:18) T 0(cid:19)2∧ 27−2α
+cL r3
+cL2
2r4
λ (H∗) T 2(cid:101)T µ (cid:101)T
min
(cid:113)
for the quantity r
(cid:101)T
:= µσ (cid:102)√∗
T
+ log µT T T0 ·(cid:0)E∥∇F(θ 0)∥4 2(cid:1)1/4 .
For the multi-loop algorithm, applying the same argument on the initial gradient norm as in
the proof of Theorem 4, we arrive at the desired bound.
5 Proof of asymptotic results
In this section, we present the proofs for the asymptotic results, Theorem 1 and Theorem 2.
The former guarantees the asymptotic normality of ROOT-SGD under our assumptions, while the
latter shows an example that satisfies our assumptions but makes Polyak-Ruppert algorithm fail
asymptotically.
5.1 Proof of Theorem 1
ByProposition1,fort ≥ T ,takingη = 1 ,thereexistconstantsa ,a > 0dependingonthe
0 t µT01−αtα 1 2
problem-specific parameters (µ,L,ℓ ,σ ,θ ,α) but independent of t, such that for t ≥ 2T logT ,
Ξ ∗ 0 0 0
22we have the bounds:
(cid:18) (cid:19)
1 1 1 3a
E∥v ∥2 ≤ a + + ≤ 1
t 2 1 t2η t3η2 t2 t2−α
t t
a a logt 2a
E∥z ∥2 ≤ 2 + 2 ≤ 2
t 2 t t2 t
and consequently, we have:
(cid:18) (cid:19)
1 2 2 3a 2a a
E∥θ −θ∗∥2 ≤ E∥∇F(θ )∥2 ≤ (E∥v ∥2+∥z ∥2) ≤ 1 + 2 ≤ 3
t 2 µ t 2 µ t+1 2 t+1 2 µ2 t2−α t t
for a constant a = 6 (a +a ) < +∞.
3 µ2 1 2
For the martingale Ψ , we note that:
t
t t
(cid:88) (cid:88)
E∥Ψ ∥2 = (s−1)2E∥ε (θ )−ε (θ )∥2 ≤ (s−1)2ℓ2E∥θ −θ ∥2
t 2 s s−1 s s−2 2 Ξ s−1 s−2 2
s=T0 s=T0
t t−1
≤ (cid:88) (s−1)2η2 E∥v ∥2 ≤ 1 (cid:88) s2−2α· 3a 1 ≤ 3a 1 t1−α
s−1 s−1 2 µ2T 2−2α s2−α (1−α)µ2T 2−2α
0 0
s=T0 s=0
Define the process N := (cid:80)t ε (θ∗). We note that:
t s=1 s
t t
(cid:88) (cid:88)
E∥M −N ∥2 = E∥ε (θ )−ε (θ∗)∥2 ≤ ℓ2 E∥θ −θ∗∥2 ≤ ℓ2a logt
t t 2 s s−1 s 2 Ξ s 2 Ξ 3
s=1 s=1
Putting together the pieces, we obtain:
tE(cid:13) (cid:13) (cid:13) (cid:13)z t− 1 tN t(cid:13) (cid:13) (cid:13) (cid:13)2 ≤ 3
t
∥z 0∥2 2+ 3 tE∥Ψ t∥2 2+ 3 tE∥M t−N t∥2
2
2
3 3a t1−α 3
≤ ∥z ∥2+ 1 + ·ℓ2Clogt → 0 (31)
t 0 2 (1−α)µ2T 2−2αt t Ξ
0
Note that N is sum of i.i.d. random vectors. By standard CLT, we have:
t
√
N / T −→d N(0,Σ∗)
T
The second moment bound (31) implies that:
(cid:13)√ √ (cid:13)
(cid:13) Tz −N / T(cid:13) →−p 0
(cid:13) T T (cid:13)
2
Combining these results with Slutsky’s theorem, we find that
√
Tz −→d N(0,Σ∗)
T
Note that ∇F(θ ) = v −z . Since we have the bound E∥v ∥2 ≤ 3a1 for α ∈ (0,1), it is easy to
√ t−1 t t t 2 t2−α
p
see that Tv →− 0. Consequently, by Slutsky’s theorem, we obtain:
T
√
T ·∇F(θ ) −→d N(0,Σ∗)
T
23Finally, we note that for θ ∈ Rd, there is:
(cid:13)(cid:90) 1 (cid:13)
∥∇F(θ)−H∗(θ−θ∗)∥ = (cid:13) (cid:13) ∇2F(θ∗+γ(θ−θ∗))(θ−θ∗)dγ −H∗(θ−θ∗)(cid:13) (cid:13)
2 (cid:13) (cid:13)
0 2
(cid:90) 1
≤ |||∇2F(θ∗+γ(θ−θ∗))−H∗||| ·∥θ−θ∗∥ dγ
op 2
0
≤ ∥θ−θ∗∥ · sup |||∇2F(θ′)−H∗|||
2 op
∥θ′−θ∗∥ ≤∥θ−θ∗∥
2 2
Therefore, since F ∈ C2, we have:
∥∇F(θ)−H∗(θ−θ∗)∥
lim 2 = 0
θ→θ∗ ∥θ−θ∗∥
2
By Assumption 1, we have ∥∇F(θ)−∇F(θ∗)∥ ≥ µ∥θ−θ∗∥ , plugging into above bounds, we
2 2
∥∇F(θ)−H∗(θ−θ∗)∥
obtain lim θ→θ∗ ∥∇F(θ)∥ 2 = 0.
√ 2 √
Therefore, since T ·∇F(θ ) −→d N(0,Σ∗), we have T ∥∇F(θ )−H∗(θ −θ∗)∥ →−p 0. This
√ T T T 2
leads to TH∗(θ −θ∗) −→d N(0,Σ∗), and consequently,
T
√
T(θ −θ∗) −→d N(0,(H∗)−1Σ∗(H∗)−1)
T
which finishes the proof.
5.2 Proof of Theorem 2
The proof is by explicit construction of a function (and associated noise) satisfying the Assump-
tions 1, 2, 3 and 4, for which the Polyak-Ruppert procedure fails.
Consider the following function:
(cid:40) x2− 1 (cid:82)x z dz x ≥ 0
F(x) := 2 0 log(e+|z|−1)
x2− 1 (cid:82)x z dz x < 0
4 0 log(e+|z|−1)
Some algebra yields:
(cid:40)
2x− x x ≥ 0
F′(x) = 2log(e+|x|−1)
2x− x x < 0
4log(e+|x|−1)
and

2− 1 − 1 x ≥ 0
F′′(x) = 2log(e+|x|−1) 2log2(e+|x|−1)·(e|x|+1)
2− 4log(e+1
|x|−1)
− 4log2(e+|x|1
−1)·(e|x|+1)
x < 0
Clearly, F istwicecontinuouslydifferentiableeverywhereonR, satisfyingtheboundforanyx ∈ R:
1 ≤ F′′(x) ≤ 2
It is easy to see that F has an unique minimizer 0, with H∗ = F′′(0) = 2.
24We consider an additive Gaussian noise model
√
f(θ,ξ ) := F(θ)− 2⟨ξ , θ⟩ where ξ ∼ N(0,1)
t t t
√
Clearly, the noise model satisfies Assumption 2 and 3 with constants σ = 2 and ℓ = 0.
∗ Ξ
Now we consider the SGD update rule on function F:
√
θ = θ −η∇F(θ )+ 2ηξ
t+1 t t t+1
Given η = η T−α, we consider the following re-scaled function:
0
∀x > 0 F (x) :=
η−1F(cid:0)√ ηx(cid:1)
(32)
η
√
Clearly, F is a strongly-convex and smooth function, with 1 ≤ F′′(x) ≤ 2. Denote ψ := θ / η
η √ η t t
and ψ¯ := θ¯ / η. The SGD iterates can be re-written as
T T
(cid:112)
ψ = ψ −η∇F (ψ )+ 2ηξ
t+1 t η t t+1
√
We also define the re-scaled function δ η(x) := √1 ηδ(x η). Clearly we have the relation δ η(x) =
(t)
2x−∇F (x). We denote π := L(ψ ), the probability law of the iterate ψ .
η η t t
This is an instance of unadjusted Langevin algorithm (ULA) on the function F , which is known
η
to converge to an approximation to the target density π
η
∝ e−Fη. More precisely, the following
non-asymptotic error bounds are known from the paper [DM19] (for notational simplicity, we
suppressthedependencyonthestrongconvexityandsmoothnessparameter, aswellastheproblem
dimension, as they are all universal constants in above problem):
Proposition 3 (Special case of [DM19], Theorem 5). Under above setup, we have the following
bound for k = 1,2···
(cid:16) (cid:17)
W2 π(k),π ≤ 2e−c1ηk(cid:0) ∥ψ ∥2+1(cid:1) +c η (33a)
2 η η 0 2 2
for constants c ,c > 0 independent of η,k and ψ .
1 2 0
The mean-square error bounds for estimation expectation of a Lipschitz functional is also given
by [DM19].
Proposition 4 (Special case of [DM19], Eq (27) and Theorem 15). Under above set-up, given any
Lipschitz test function h, let h¯ := 1 (cid:80)T−1 h(ψ ), the following bounds hold true:
T0,T T−T0 t=T0 t
(cid:0)E(cid:2) h¯ (cid:3) −E (cid:2) h(X)(cid:3)(cid:1)2 ≤
∥h∥2
Lip
(cid:88)T
W2(cid:16)
π(t),π
(cid:17)
(33b)
T0,T πη T −T 2 η η
0
t=T0
∥h∥2
var(cid:0) h¯ (cid:1) ≤ c Lip (33c)
T0,T
η(T −T )
0
for a universal constant c > 0.
Notethatψ = 0. SowehavethefollowingboundonthesumofsquaresofWassersteindistance
0
T T
(cid:88) (cid:16) (cid:17) (cid:88) 2
W2 π(k),π ≤ 2 e−c1ηk +c (T −T )η ≤ +c (T −T )η
2 η η 2 0 c η 2 0
1
k=T0 k=T0
25SubstitutingintotheMSEboundinProposition4,foranychoiceofburn-inparameterβ ∈ [0,1),
we have the bound:
(cid:18) (cid:19)
E(cid:0) ψ¯ −E [X](cid:1)2 ≤ c η+ 1 ≤ c′T−min(α,1−α) (34)
T πη
η(T −T )
0
where the constants c,c′ > 0 can depend on ∥θ ∥ and η , but are independent of T.
0 2 0
It remains to study the stationary distribution π . The following lemma characterizes the size
η
of bias under the stationary distribution π .
η
Lemma 8. For the 1-dimensional probability distribution π defined above, we have that
η
(cid:18) 1(cid:19)−1
E [X] ≥ c· log
πη
η
for a universal constant c > 0.
Combining the bound (34) and Lemma 8, we arrive at the lower bound:
E(cid:2) ψ¯2(cid:3)
≥
c 1
−
c 2
T log2T Tmin(α,1−α)
for constants c ,c > 0 that are independent of T.
1 2
Recovering the original scaling, we obtain the lower bound for the Polyak-Ruppert estimator:
E(cid:13) (cid:13)θ¯
T
−θ∗(cid:13) (cid:13)2
2
≥ Tαlc o′ 1
g2T
− Tminc (′ 2
2α,1)
Taking the limit, we have:
T→lim +∞T ·E(cid:13) (cid:13)θ¯
T
−θ∗(cid:13) (cid:13)2
2
= +∞
which completes the proof of this theorem.
Proof of Lemma 8. Denote the normalization constant:
(cid:90)
Z := e−Fη(x)dx
η
Since x2 ≤ F(x) ≤ 2x2 for any x ∈ R, we have the bound (cid:112) π/2 ≤ Z ≤ √ π for any choice of
η
η > 0. By definition, we have the expression:
(cid:90) +∞ (cid:16) (cid:17)
E [X] = Z−1 x e−Fη(x)−e−Fη(−x) dx
πη η
0
Note that F(x) ≤ F(−x) for any x ≥ 0. So we have that E [X] ≥ 0, and the following bound
πη
holds:
1 (cid:90) 2(cid:16) (cid:17)
E [X] ≥ √ e−Fη(x)−e−Fη(−x) dx
πη
π
1
26Given x ∈ [1,2] fixed, we lower bound the difference in the density function as follows:
e−Fη(x)−e−Fη(−x) = e−x2(cid:16) e1/2(cid:82) 0xδη(z)dz −e1/4(cid:82) 0xδη(z)dz(cid:17) ≥ e−4 (cid:90) x δ η(z)dz
4
0
e−4 (cid:90) 1 z e−4 1
≥ 4
1/2
log(cid:0) e+(z√ η)−1(cid:1)dz ≥ 8 · log(cid:0) e+ √2 η(cid:1)
Integrating with x ∈ [1,2], we arrive at the lower bound:
(cid:18) 1(cid:19)−1
E [X] ≥ c· log
πη
η
for universal constant c > 0.
6 Additional related works
Gradient descent and stochastic gradient descent methods have gained unprecedented popularity
in the past decade amidst the era of big data [Bub15, BCN18], driven by the rapid growth of deep
learning applications [GBC16]. These methods excel in handling large-scale datasets due to their
efficient processing of online samples. A myriad of variants have emerged from both theoretical
advancements and practical needs, including variance-reduced methods [RSB12, JZ13, DBLJ14],
momentum-accelerated methods [Nes83, BT09], second-order methods [DM74, NP06], adaptive
gradient methods [DHS11, KB14], iteration averaging [Rup88, PJ92], and coordinate descent
[Wri15], among others. The Polyak-Ruppert iteration averaging method [PJ92, Pol90, Rup88]
and its generalized form [KY93] have been shown to enhance robustness with respect to step
size selection, achieving asymptotic normality with optimal covariance matching local minimax
optimality [ZCDL16, DR21]. Recent studies have further explored the nonasymptotic behavior
of stochastic gradient descent with iteration averaging [MB11, Xu11, BM13, Bac14, FB15, GP23,
DFB17,DDB20]. Inthestudiesoflinearregressionandstochasticapproximation,[Zha04,JNK+18,
JKK+18] have analyzed the ”tail-averaging” technique, achieving exponential forgetting and opti-
mal statistical risk simultaneously. [LS18] investigates the Ruppert-Polyak averaging method for
general linear stochastic approximation, which extends beyond optimization algorithms to appli-
cations in reinforcement learning. Under more stringent noise conditions, [MLW+20] establishes
Gaussian limit and concentration inequalities for constant stepsize algorithms, with related ad-
vancements discussed in [LWC+24].
The weak convergence result from [PJ92] has recently been generalized to functional weak con-
vergence by [LLSS22] and [LLCZ22] within the framework of i.i.d. online convex stochastic opti-
mization. However,applyingthistononlinearstochasticapproximationwithMarkoviandataintro-
ducesseveralchallengesthatneedaddressing[DNPR20,KMN+20,NWB+20,XZ22,LLZ23,RB23,
STNM24]. Referenced works beyond this overview delve deeper into topics such as asymptotic nor-
mality, statistical inference using gradient-based methods, and variants thereof [TTA16, TA17,
LLKC18, LS19, SY19, KMMW19, CLS21, SSLL21, YBVE21, JXB21, ZD21, CLZ22, NYF+22,
LHM22, Mey22, MPW23, WZW23, LLCZ23, XKWJ23, ZCW23, CLLZ24, HCX24, ZLWW24].
The asymptotic efficiency of variance-reduced stochastic approximation methods has been rel-
atively underexplored in research. [FGKS15] introduces an online variant of the SVRG algorithm
[JZ13] and establishes a non-asymptotic upper bound on excess risk, aligning its leading term with
optimalasymptoticsunderspecificself-concordantconditionsontheobjectivefunction. [AMH+19]
27proposes Implicit Gradient Transportation (IGT) to reduce algorithmic variance. In the context of
reinforcement learning for policy evaluation, [KPR+21, MKW+22] provides an instance-dependent
non-asymptotic upper bound on ℓ estimation error for variance-reduced stochastic approximation
∞
algorithms, matching the risk of the optimal Gaussian limit up to constant or logarithmic factors.
Central to our study, [Li20] introduces the ROOT-SGD algorithm that achieves local minimax op-
timality. This algorithm can be viewed as an online variant of SARAH [NLST17] and connects
with extrapolation-smoothing methods like (N)IGT and STORM [AMH+19, CO19, CM20]. In a
different approach, [Nes09, Xia10, LW12] propose dual averaging for the regularized or proximal
case.8 ROOT-SGD distinguishes itself by averaging past stochastic gradients with proper de-bias
corrections, achieving both statistical efficiency and non-asymptotic high-order terms.
7 Discussion
In this paper, we conduct a two-time-scale analysis of the ROOT-SGD algorithm proposed by [Li20]
withadiminishingstepsizesequence,establishingitsfine-grainedoptimalityunderdifferentregimes.
We demonstrate that the algorithm converges to the optimal normal limit under minimal smooth-
ness assumptions. In contrast, the Polyak-Ruppert averaged SGD is found to be sub-optimal under
these assumptions in a presented example. Additionally, we derive non-asymptotic upper bounds
on gradient norm, estimation error, and excess risk for ROOT-SGD, achieving a leading term that
precisely matches the asymptotic risk under the limiting Gaussian law, alongside high-order terms
showing sharp dependencies on problem-specific parameters. Moreover, with a one-point Hessian
Lipschitz condition imposed, these additional terms decay at a rate of O(n−3/2), achieving optimal-
ity without prior knowledge of the sample size n. Our analysis potentially extends to non-strongly
convex, non-convex, and stochastic approximation problems with varying geometric properties, in-
dicating critical avenues for future research. Additionally, exploring applications to Markovian or
distributed data settings remains an important direction for further study.
References
[AMH+19] S´ebastienArnold,Pierre-AntoineManzagol,RezaBabanezhadHarikandeh,IoannisMitliagkas,
and Nicolas Le Roux. Reducing the variance in online optimization by transporting past gra-
dients. Advances in Neural Information Processing Systems, 32:5391–5402, 2019.
[Bac14] Francis Bach. Adaptivity of averaged stochastic gradient descent to local strong convexity for
logistic regression. The Journal of Machine Learning Research, 15(1):595–627, 2014.
[BCN18] L´eonBottou,FrankECurtis,andJorgeNocedal. Optimizationmethodsforlarge-scalemachine
learning. SIAM Review, 60(2):223–311, 2018.
[BM13] Francis Bach and Eric Moulines. Non-strongly-convex smooth stochastic approximation with
convergence rate O(1/n). Advances in Neural Information Processing Systems, 26:773–781,
2013.
[BT09] Amir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for linear
inverse problems. SIAM journal on imaging sciences, 2(1):183–202, 2009.
[Bub15] S´ebastien Bubeck. Convex optimization: Algorithms and complexity. Foundations and
Trends® in Machine Learning, 8(3-4):231–357, 2015.
8See also [DR21, TFBJ18] for manifold first-order optimization methods.
28[CLLZ24] Xi Chen, Zehua Lai, He Li, and Yichen Zhang. Online statistical inference for stochastic
optimization via Kiefer-Wolfowitz methods. Journal of the American Statistical Association,
pages 1–24, 2024.
[CLS21] Haoyu Chen, Wenbin Lu, and Rui Song. Statistical inference for online decision making via
stochasticgradientdescent. Journal of the American Statistical Association,116(534):708–719,
2021.
[CLTZ20] Xi Chen, Jason D Lee, Xin T Tong, and Yichen Zhang. Statistical inference for model param-
eters in stochastic gradient descent. The Annals of Statistics, 48(1):251–273, 2020.
[CLZ22] Xi Chen, Weidong Liu, and Yichen Zhang. First-order Newton-type estimator for distributed
estimationandinference. Journal of the American Statistical Association, 117(540):1858–1874,
2022.
[CM20] Ashok Cutkosky and Harsh Mehta. Momentum improves normalized SGD. In International
Conference on Machine Learning, pages 2260–2268. PMLR, 2020.
[CO19] Ashok Cutkosky and Francesco Orabona. Momentum-based variance reduction in non-convex
SGD. Advances in Neural Information Processing Systems, 32:15210–15219, 2019.
[DBLJ14] Aaron Defazio, Francis Bach, and Simon Lacoste-Julien. SAGA: A fast incremental gradi-
ent method with support for non-strongly convex composite objectives. Advances in Neural
Information Processing Systems, 27:1646–1654, 2014.
[DDB20] AymericDieuleveut,AlainDurmus,andFrancisBach. Bridgingthegapbetweenconstantstep
size stochastic gradient descent and Markov chains. The Annals of Statistics, 48(3):1348–1382,
2020.
[DFB17] Aymeric Dieuleveut, Nicolas Flammarion, and Francis Bach. Harder, better, faster, stronger
convergence rates for least-squares regression. Journal of Machine Learning Research,
18(101):1–51, 2017.
[DHS11] JohnDuchi, EladHazan, andYoramSinger. Adaptivesubgradientmethodsforonlinelearning
and stochastic optimization. Journal of Machine Learning Research, 12(61):2121–2159, 2011.
[DM74] John E Dennis and Jorge J Mor´e. A characterization of superlinear convergence and its appli-
cation to quasi-Newton methods. Mathematics of Computation, 28(126):549–560, 1974.
[DM19] Alain Durmus and E´ric Moulines. High-dimensional Bayesian inference via the unadjusted
Langevin algorithm. Bernoulli, 25(4A):2854–2882, 2019.
[DNPR20] Thinh T Doan, Lam M Nguyen, Nhan H Pham, and Justin Romberg. Finite-time analysis of
stochasticgradientdescentunderMarkovrandomness. arXiv preprint arXiv:2003.10973, 2020.
[DR21] John C Duchi and Feng Ruan. Asymptotic optimality in stochastic optimization. The Annals
of Statistics, 49(1):21–48, 2021.
[FB15] NicolasFlammarionandFrancisBach. Fromaveragingtoacceleration,thereisonlyastep-size.
In Conference on Learning Theory, pages 658–695. PMLR, 2015.
[FGKS15] RoyFrostig,RongGe,ShamMKakade,andAaronSidford. Competingwiththeempiricalrisk
minimizer in a single pass. In Conference on Learning Theory, pages 728–763. PMLR, 2015.
[GBC16] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. MIT Press, 2016. http:
//www.deeplearningbook.org.
[GL95] Richard D Gill and Boris Y Levit. Applications of the van Trees inequality: A Bayesian
Cram´er-Rao bound. Bernoulli, 1(1-2):59–79, 1995.
[GP23] S´ebastienGadatandFabienPanloup. Optimalnon-asymptoticanalysisoftheRuppert-Polyak
averagingstochasticalgorithm. Stochastic Processes and their Applications,156:312–348,2023.
29[HCX24] Dongyan Lucy Huo, Yudong Chen, and Qiaomin Xie. Effectiveness of constant stepsize in
Markovian LSA and statistical inference. In Proceedings of the AAAI Conference on Artificial
Intelligence, volume 38, pages 20447–20455, 2024.
[JKK+18] Prateek Jain, Sham M Kakade, Rahul Kidambi, Praneeth Netrapalli, and Aaron Sidford. Ac-
celerating stochastic gradient descent for least squares regression. In Conference on Learning
Theory, pages 545–604, 2018.
[JNK+18] Prateek Jain, Praneeth Netrapalli, Sham M Kakade, Rahul Kidambi, and Aaron Sidford. Par-
allelizingstochasticgradientdescentforleastsquaresregression: Mini-batching,averaging,and
model misspecification. Journal of Machine Learning Research, 18(223):1–42, 2018.
[JXB21] Yanhao Jin, Tesi Xiao, and Krishnakumar Balasubramanian. Statistical inference for Polyak-
Ruppertaveragedzeroth-orderstochasticgradientalgorithm. arXivpreprintarXiv:2102.05198,
2021.
[JZ13] RieJohnsonandTongZhang.Acceleratingstochasticgradientdescentusingpredictivevariance
reduction. In Advances in Neural Information Processing Systems, pages 315–323, 2013.
[KB14] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv
preprint arXiv:1412.6980, 2014.
[KMMW19] BelhalKarimi,BlazejMiasojedow,EricMoulines,andHoi-ToWai. Non-asymptoticanalysisof
biased stochastic approximation scheme. In Conference on Learning Theory, pages 1944–1974.
PMLR, 2019.
[KMN+20] Maxim Kaledin, Eric Moulines, Alexey Naumov, Vladislav Tadic, and Hoi-To Wai. Finite time
analysis of linear two-timescale stochastic approximation with Markovian noise. In Conference
on Learning Theory, pages 2144–2203. PMLR, 2020.
[KPR+21] KoulikKhamaru, AshwinPananjady, FengRuan, MartinJWainwright, andMichaelIJordan.
Is temporal difference learning optimal? an instance-dependent analysis. SIAM Journal on
Mathematics of Data Science, 3(4):1013–1040, 2021.
[KY93] Harold J Kushner and Jichuan Yang. Stochastic approximation with averaging of the iterates:
Optimal asymptotic rate of convergence for general processes. SIAM Journal on Control and
Optimization, 31(4):1045–1062, 1993.
[LeC70] LucienLeCam. Ontheassumptionsusedtoproveasymptoticnormalityofmaximumlikelihood
estimates. The Annals of Mathematical Statistics, 41(3):802–828, 1970.
[LHM22] Yiling Luo, Xiaoming Huo, and Yajun Mei. Covariance estimators for the ROOT-SGD algo-
rithm in online learning. arXiv preprint arXiv:2212.01259, 2022.
[Li20] Chris Junchi Li. ROOT-SGD: Sharp nonasymptotics and near-optimal asymptotics in a single
algorithm. arXiv e-prints, 2020.
[LLCZ22] Xiang Li, Jiadong Liang, Xiangyu Chang, and Zhihua Zhang. Statistical estimation and online
inference via local SGD. In Conference on Learning Theory, pages 1613–1661. PMLR, 2022.
[LLCZ23] Xiang Li, Jiadong Liang, Xinyun Chen, and Zhihua Zhang. Stochastic approximation
MCMC, online inference, and applications in optimization of queueing systems. arXiv preprint
arXiv:2309.09545, 2023.
[LLKC18] Tianyang Li, Liu Liu, Anastasios Kyrillidis, and Constantine Caramanis. Statistical inference
using SGD. In Thirty-Second AAAI Conference on Artificial Intelligence, 2018.
[LLSS22] Sokbae Lee, Yuan Liao, Myung Hwan Seo, and Youngki Shin. Fast and robust online inference
with stochastic gradient descent via random scaling. In Proceedings of the AAAI Conference
on Artificial Intelligence, volume 36, pages 7381–7389, 2022.
30[LLZ23] XiangLi,JiadongLiang,andZhihuaZhang. Onlinestatisticalinferencefornonlinearstochastic
approximation with Markovian data. arXiv preprint arXiv:2302.07690, 2023.
[LS18] Chandrashekar Lakshminarayanan and Csaba Szepesvari. Linear stochastic approximation:
How far does constant step-size and iterate averaging go? In International Conference on
Artificial Intelligence and Statistics, pages 1347–1355, 2018.
[LS19] TengyuanLiangandWeijieJSu. Statisticalinferenceforthepopulationlandscapeviamoment-
adjusted stochastic gradients. Journal of the Royal Statistical Society: Series B (Statistical
Methodology), 81(2):431–456, 2019.
[LW12] Sangkyun Lee and Stephen J Wright. Manifold identification in dual averaging for regularized
stochastic online learning. Journal of Machine Learning Research, 13(55):1705–1744, 2012.
[LWC+24] Gen Li, Weichen Wu, Yuejie Chi, Cong Ma, Alessandro Rinaldo, and Yuting Wei. High-
probabilitysamplecomplexitiesforpolicyevaluationwithlinearfunctionapproximation. IEEE
Transactions on Information Theory, 2024.
[MB11] Eric Moulines and Francis Bach. Non-asymptotic analysis of stochastic approximation algo-
rithms for machine learning. Advances in Neural Information Processing Systems, 24:451–459,
2011.
[Mey22] Sean Meyn. Control Systems and Reinforcement Learning. Cambridge University Press, 2022.
[MKW+22] Wenlong Mou, Koulik Khamaru, Martin J Wainwright, Peter L Bartlett, and Michael I Jor-
dan. Optimal variance-reduced stochastic approximation in Banach spaces. arXiv preprint
arXiv:2201.08518, 2022.
[MLW+20] Wenlong Mou, Chris Junchi Li, Martin J Wainwright, Peter L Bartlett, and Michael I Jor-
dan. On linear stochastic approximation: Fine-grained Polyak-Ruppert and non-asymptotic
concentration. In Conference on Learning Theory, pages 2947–2997, 2020.
[MPW23] Wenlong Mou, Ashwin Pananjady, and Martin J Wainwright. Optimal oracle inequalities for
projected fixed-point equations, with applications to policy evaluation. Mathematics of Opera-
tions Research, 48(4):2308–2336, 2023.
[Nes83] Yurii Nesterov. A method for unconstrained convex minimization problem with the rate of
convergence O(1/k2). Dokl. Akad. Nauk. SSSR, 269(3):543–547, 1983.
[Nes09] YuriiNesterov. Primal-dualsubgradientmethodsforconvexproblems. Mathematical Program-
ming, 120:221–259, 2009.
[NLST17] Lam M Nguyen, Jie Liu, Katya Scheinberg, and Martin Tak´aˇc. SARAH: A novel method for
machine learning problems using stochastic recursive gradient. In International Conference on
Machine Learning, pages 2613–2621. PMLR, 2017.
[NP06] Yurii Nesterov and Boris T Polyak. Cubic regularization of Newton method and its global
performance. Mathematical Programming, 108:177–205, 2006.
[NWB+20] DheerajNagaraj, XianWu, GuyBresler, PrateekJain, andPraneethNetrapalli. Leastsquares
regression with Markovian data: Fundamental limits and algorithms. Advances in Neural
Information Processing Systems, 33:16666–16676, 2020.
[NYF+22] Jeffrey Negrea, Jun Yang, Haoyue Feng, Daniel M Roy, and Jonathan H Huggins. Tuning
stochastic gradient algorithms for statistical inference via large-sample asymptotics. arXiv
preprint arXiv:2207.12395, 2022.
[PJ92] BorisTPolyakandAnatoliBJuditsky. Accelerationofstochasticapproximationbyaveraging.
SIAM Journal on Control and Optimization, 30(4):838–855, 1992.
[Pol90] Boris T Polyak. A new method of stochastic approximation type. Automat. i Telemekh, 7(98-
107):2, 1990.
31[RB23] AbhishekRoyandKrishnakumarBalasubramanian.Onlinecovarianceestimationforstochastic
gradient descent under Markovian sampling. arXiv preprint arXiv:2308.01481, 2023.
[RM51] Herbert Robbins and Sutton Monro. A stochastic approximation method. The Annals of
Mathematical Statistics, pages 400–407, 1951.
[RSB12] Nicolas Roux, Mark Schmidt, and Francis Bach. A stochastic gradient method with an ex-
ponential convergence rate for finite training sets. Advances in Neural Information Processing
Systems, 25, 2012.
[Rup88] David Ruppert. Efficient estimations from a slowly convergent Robbins-Monro process. Tech-
nical report, Cornell University Operations Research and Industrial Engineering, 1988.
[SSLL21] ChengchunShi, RuiSong, WenbinLu, andRunzeLi. Statisticalinferenceforhigh-dimensional
models via recursive online-score estimation. Journal of the American Statistical Association,
116(535):1307–1318, 2021.
[STNM24] Sergey Samsonov, Daniil Tiapkin, Alexey Naumov, and Eric Moulines. Improved high-
probability bounds for the temporal difference learning algorithm via exponential stability.
InThe Thirty Seventh Annual Conference on Learning Theory,pages4511–4547.PMLR,2024.
[SY19] RayadurgamSrikantandLeiYing. Finite-timeerrorboundsforlinearstochasticapproximation
and TD learning. In Conference on Learning Theory, pages 2803–2830. PMLR, 2019.
[SZ23] Weijie J Su and Yuancheng Zhu. HiGrad: Uncertainty quantification for online learning and
stochastic approximation. Journal of Machine Learning Research, 24(124):1–53, 2023.
[TA17] Panos Toulis and Edoardo M Airoldi. Asymptotic and finite-sample properties of estimators
based on stochastic gradients. The Annals of Statistics, 45(4):1694–1727, 2017.
[TFBJ18] Nilesh Tripuraneni, Nicolas Flammarion, Francis Bach, and Michael I Jordan. Averaging
stochastic gradient descent on Riemannian manifolds. In Conference On Learning Theory,
pages 650–687. PMLR, 2018.
[TTA16] Panos Toulis, Dustin Tran, and Edo Airoldi. Towards stability and optimality in stochastic
gradient descent. In International Conference on Artificial Intelligence and Statistics, pages
1290–1298. PMLR, 2016.
[VdV00] Aad W Van der Vaart. Asymptotic Statistics, volume 3. Cambridge University Press, 2000.
[Wri15] StephenJWright. Coordinatedescentalgorithms. Mathematical Programming,151:3–34,2015.
[WZW23] Ziyang Wei, Wanrong Zhu, and Wei Biao Wu. Weighted averaged stochastic gradient descent:
Asymptotic normality and optimality. arXiv preprint arXiv:2307.06915, 2023.
[Xia10] Lin Xiao. Dual averaging methods for regularized stochastic learning and online optimization.
Journal of Machine Learning Research, 11(88):2543–2596, 2010.
[XKWJ23] Eric Xia, Koulik Khamaru, Martin J Wainwright, and Michael I Jordan. Instance-dependent
confidence and early stopping for reinforcement learning. Journal of Machine Learning Re-
search, 24(392):1–43, 2023.
[Xu11] Wei Xu. Towards optimal one pass large scale learning with averaged stochastic gradient
descent. arXiv preprint arXiv:1107.2490, 2011.
[XZ22] Chuhan Xie and Zhihua Zhang. A statistical online inference approach in averaged stochastic
approximation. Advances in Neural Information Processing Systems, 35:8998–9009, 2022.
[YBVE21] Lu Yu, Krishnakumar Balasubramanian, Stanislav Volgushev, and Murat A Erdogdu. An
analysis of constant step size SGD in the non-convex regime: Asymptotic normality and bias.
Advances in Neural Information Processing Systems, 34:4234–4248, 2021.
32[ZCDL16] Yuancheng Zhu, Sabyasachi Chatterjee, John Duchi, and John Lafferty. Local minimax com-
plexityofstochasticconvexoptimization. Advances in Neural Information Processing Systems,
pages 3431–3439, 2016.
[ZCW23] Wanrong Zhu, Xi Chen, and Wei Biao Wu. Online covariance matrix estimation in stochastic
gradient descent. Journal of the American Statistical Association, 118(541):393–404, 2023.
[ZD21] Yi Zhu and Jing Dong. On constructing confidence region for model parameters in stochastic
gradient descent via batch means. In 2021 Winter Simulation Conference (WSC), pages 1–12.
IEEE, 2021.
[Zha04] Tong Zhang. Solving large scale linear prediction problems using stochastic gradient descent
algorithms. In Proceedings of the Twenty-First International Conference on Machine learning,
pages 919–926, 2004.
[ZLWW24] Wanrong Zhu, Zhipeng Lou, Ziyang Wei, and Wei Biao Wu. High confidence level inference is
almost free using parallel stochastic optimization. arXiv preprint arXiv:2401.09346, 2024.
33A Proof of auxiliary lemmas
For the proofs of auxiliary lemmas, we first describe a simple decomposition result for the process
(z ) which plays a central role in our analysis.
t t≥T0
A key decomposition result The proof for all the results about ROOT-SGD relies on a decom-
position of the difference z := v −∇F(θ ) that exposes the underlying martingale structure. In
t t t−1
particular, beginning with the definition (5) of the updates, for any iterate t ≥ T , we have
0
(cid:18) (cid:19) (cid:18) (cid:19)
1 1 1
z = v −∇F(θ ) = ε (θ )+ 1− (v −∇F(θ ))+ 1− (ε (θ )−ε (θ ))
t t t−1 t t−1 t−1 t−2 t t−1 t t−2
t t t
(cid:18) (cid:19) (cid:18) (cid:19)
1 1 1
= ε (θ )+ 1− z + 1− (ε (θ )−ε (θ ))
t t−1 t−1 t t−1 t t−2
t t t
Unwinding this relation recursively yields
t t
1 (cid:88) T 0 1 (cid:88)
z = ε (θ )+ z + (s−1)(ε (θ )−ε (θ )) (35)
t
t
s s−1
t
T0
t
s s−1 s s−2
s=T0 s=T0
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
:=Mt :=Ψt
It can be seen that both both of the sequences {M } and {Ψ } are martingales adapted to
t t≥T0 t t≥T0
the filtration (F ) . We make use of this martingale decomposition throughout our analysis.
t t≥T0
A.1 Proof of Lemma 1
By definition, we note that:
(cid:18) (cid:19)
1 1
v = 1− (v +∇f(θ ;ξ )−∇f(θ ;ξ ))+ ∇f(θ ;ξ )
t t−1 t−1 t t−2 t t−1 t
t t
Taking the second moments for both sides, we have:
(cid:18) 1(cid:19)2
1
E∥v ∥2 = 1− E∥v +∇f(θ ;ξ )−∇f(θ ;ξ )∥2+ E∥∇f(θ ;ξ )∥2
t 2 t t−1 t−1 t t−2 t 2 t2 t−1 t 2
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
I1 I2
t−1
+2 E⟨v +∇f(θ ;ξ )−∇f(θ ;ξ ), ∇f(θ ;ξ )⟩
t2 t−1 t−1 t t−2 t t−1 t
(cid:124) (cid:123)(cid:122) (cid:125)
I3
For the first term, using the fact that θ −θ = −η v , we start with the following decom-
t−1 t−2 t−1 t−1
position:
(cid:16) (cid:17)
E ∥v +∇f(θ ;ξ )−∇f(θ ;ξ )∥2 | F
t−1 t−1 t t−2 t 2 t−1
(cid:16) (cid:17)
= ∥v ∥2+2E(⟨v , ∇f(θ ;ξ )−∇f(θ ;ξ )⟩ | F )+E ∥∇f(θ ;ξ )−∇f(θ ;ξ )∥2 | F
t−1 2 t−1 t−1 t t−2 t t−1 t−1 t t−2 t 2 t−1
2 (cid:16) (cid:17)
= ∥v ∥2− ⟨θ −θ , ∇F(θ )−∇F(θ )⟩+E ∥∇f(θ ;ξ )−∇f(θ ;ξ )∥2 | F
t−1 2 η t−1 t−2 t−1 t−2 t−1 t t−2 t 2 t−1
t−1
34Since F is µ-strongly convex and L-smooth, we have the following standard inequality:
∥θ −θ ∥2µL ∥∇F(θ )−∇F(θ )∥2
⟨θ −θ , ∇F(θ )−∇F(θ )⟩ ≥ t−1 t−2 2 + t−1 t−2 2
t−1 t−2 t−1 t−2
µ+L µ+L
Hence, when the step size satisfies the bound η ≤ 1 ∧ µ , there is the bound:
t 2L 2ℓ2
Ξ
(cid:32) (cid:33)
2 ∥θ −θ ∥2µL ∥∇F(θ )−∇F(θ )∥2
I ≤ E∥v ∥2− E t−1 t−2 2 + t−1 t−2 2
1 t−1 2 η µ+L µ+L
t−1
(cid:16) (cid:17)
+2E∥∇F(θ )−∇F(θ )∥2+2E ∥ε(θ ,ξ )−ε(θ ,ξ )∥2
t−1 t−2 2 t−1 t t−2 t 2
(cid:18) (cid:19)
1
≤ (1−η µ+2η2 ℓ2)E∥v ∥2+2 1− E∥∇F(θ )−∇F(θ )∥2
t−1 t−1 Ξ t−1 2 η (µ+L) t−1 t−2 2
t−1
(cid:16) η µ(cid:17)
≤ 1− t−1 E∥v ∥2
2 t−1 2
Now we study the second term, note that
E∥∇f(θ ;ξ )∥2 ≤ 2E∥∇f(θ ;ξ )−∇f(θ∗;ξ )∥2+2E∥∇f(θ∗;ξ )∥2
t−1 t 2 t−1 t t 2 t 2
≤ 4E∥∇F(θ )∥2+4E∥ε(θ ,ξ )−ε(θ∗,ξ )∥2+2E∥∇f(θ∗;ξ )∥2
t−1 2 t−1 t t 2 t 2
≤ 4E∥∇F(θ )∥2+4ℓ2E∥θ −θ∗∥2+2σ2
t−1 2 Ξ t−1 2 ∗
(cid:18) ℓ2 (cid:19)
≤ 4 1+ Ξ E∥∇F(θ )∥2+2σ2
µ2 t−1 2 ∗
For the cross term, we note that:
E(⟨v +∇f(θ ;ξ )−∇f(θ ;ξ ), ∇f(θ ;ξ )⟩ | F )
t−1 t−1 t t−2 t t−1 t t−1
= E(⟨v , ∇f(θ ,ξ )⟩ | F )+E(⟨∇f(θ ,ξ )−∇f(θ ,ξ ), ∇F(θ )⟩ | F )
t−1 t−1 t t−1 t−1 t t−2 t t−1 t−1
+E(⟨∇f(θ ,ξ )−∇f(θ ,ξ ), ε (θ )⟩ | F )
t−1 t t−2 t t t−1 t−1
= ⟨v , ∇F(θ )⟩+⟨∇F(θ )−∇F(θ ), ∇F(θ )⟩+E(⟨ε(θ ,ξ )−ε(θ ,ξ ), ε(θ ,ξ )⟩ | F )
t−1 t−1 t−1 t−2 t−1 t−1 t t−2 t t−1 t t−1
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
:=T1 :=T2
For the term T , we note that:
1
T ≤ ∥v ∥ ·∥∇F(θ )∥ +∥∇F(θ )−∇F(θ )∥ ·∥∇F(θ )∥ ≤ (1+η L)∥v ∥ ·∥∇F(θ )∥
1 t−1 2 t−1 2 t−1 t−2 2 t−1 2 t−1 t−1 2 t−1 2
For the term T , we have:
2
T ≤ E(∥ε(θ ,ξ )−ε(θ ,ξ )∥ ·∥ε(θ ,ξ )∥ | F )
2 t−1 t t−2 t 2 t−1 t 2 t−1
(cid:113)
≤ E(∥ε(θ ,ξ )−ε(θ ,ξ )∥2 | F )·E(∥ε(θ ,ξ )∥2 | F )
t−1 t t−2 t 2 t−1 t−1 t 2 t−1
≤ ℓ2η ∥v ∥ ·∥θ −θ∗∥
Ξ t−1 t−1 2 t−1 2
ℓ2
≤ Ξη ∥v ∥ ·∥∇F(θ )∥
µ t−1 t−1 2 t−1 2
So we have:
(cid:113)
I ≤ 3E(∥v ∥ ·∥∇F(θ )∥ ) ≤ 3 E∥v ∥2·E∥∇F(θ )∥2
3 t−1 2 t−1 2 t−1 2 t−1 2
tη µ 18
≤ t−1 E∥v ∥2+ E∥∇F(θ )∥2
8 t−1 2 tµη t−1 2
t−1
35Putting above estimates together, we obtain:
E∥v ∥2 ≤ (cid:18) 1− 1(cid:19)2(cid:16) 1− η t−1µ(cid:17) E∥v ∥2+ 1 (cid:18) 2σ2+4(cid:0) 1+ ℓ2 Ξ(cid:1)E∥∇F(θ )∥2(cid:19)
t 2 t 2 t−1 2 t2 ∗ µ2 t−1 2
(t−1)η µ 18
+ t−1 E∥v ∥2+ E∥∇F(θ )∥2
8t t−1 2 t2µη t−1 2
t−1
(cid:18) 1(cid:19)2(cid:16) η µ(cid:17) 26 2σ2
≤ 1− 1− t−1 E∥v ∥2+ E∥∇F(θ )∥2+ ∗
t 4 t−1 2 t2µη t−1 2 t2
t−1
which finishes the proof.
A.2 Proof of Lemma 2
Taking the squared norm of z in the martingale decomposition (35) and applying the triangle
t
inequality yields
2 T 2 2
E∥z ∥2 ≤ E∥M ∥2+ 0 ∥z ∥2+ E∥Ψ ∥2
t 2 t2 t 2 t2 0 2 t2 t 2
For the martingale M , we have:
t
t t
(cid:88) (cid:88)
E∥M ∥2 = E∥ε (θ )∥2 ≤ 2tσ2+2ℓ2 E∥θ −θ∗∥2
t 2 s s−1 2 ∗ Ξ s−1 2
s=1 s=1
For the martingale Ψ , we have:
t
t t
(cid:88) (cid:88)
E∥Ψ ∥2 = (s−1)2∥ε (θ )−ε (θ )∥2 ≤ ℓ2 (s−1)2η2 E∥v ∥2
t 2 s s−1 s s−2 2 Ξ s−1 s−1 2
s=1 s=1
Combining the pieces yields
E∥z ∥2 ≤
T 02∥z 0∥2
2 +
4σ ∗2
+
4ℓ2
Ξ
(cid:88)t
E∥θ −θ∗∥2+
ℓ2
Ξ
(cid:88)t
(s−1)2η2 E∥v ∥2
t 2 t2 t t2 s−1 2 t2 s−1 s−1 2
s=1 s=1
Notethattheµ-strongconvexitycondition(cf.Assumption1)ensuresthat∥θ −θ∗∥ ≤ 1 ∥∇F(θ )∥ .
s−1 2 µ t−1 2
Plugging this bound into the inequality above completes the proof.
A.3 Proof of Lemma 3
Denote ℓ :=
(cid:80)t
η , which is the aggregated step sizes up to time t.
t s=T0 s
Recursively applying the inequality (19b), and noting that H is a non-decreasing sequence and
t
that η is non-increasing, we obtain:
t
T (cid:88)−1 T (cid:88)−1 e−µ(ℓT−ℓt) T (cid:88)−1
W
T
≤ 2σ ∗2 e−µ(ℓT−ℓt)+2CH
T−1
tµη
+ e−µ(ℓT−ℓT0)W
T0
t−1
t=T0 t=T0 t=T0
2σ2 CH
≤
η
µ∗ + T(µηT−1
)2
+e−µ(ℓT−ℓT0)T 02E∥v T0∥2
2
T T−1
36Substituting the bound into Eq (19a), we obtain:
2σ2 1 (cid:88)t−1 1 (cid:88)t−1 1
H ≤ 4σ2+2E∥z ∥2T +C′ℓ2 ∗ sup η +2CC′ℓ2H sup
T ∗ T0 2 0 Ξ µ t s Ξ T t sµ2
T0≤t≤T
s=T0
T0≤t≤T
s=T0
t−1
1 (cid:88)
+C′ℓ2 ΞT 02E∥v T0∥2 2· sup
t
e−µ(ℓs−ℓT0)η s2
−1
T0≤t≤T
s=T0
For the quantities involving step size sequences in the inequality above, we have:
t−1 t−1
1 (cid:88) 1 (cid:88)
sup η ≤ sup η ≤ η
t
s
t−T +1
s T0
T0≤t≤T
s=T0
T0≤t≤T 0
s=T0
t−1 T−1
sup 1
t
(cid:88) e−µ(ℓs−ℓT0)η s2
−1
≤ T1 (cid:88) e−µ(ℓs−ℓT0)η s2
−1
≤ Tη T µ0
T0≤t≤T
s=T0
0
s=T0
0
For T > 4CC′ℓ2 Ξ, we have 2CC′ℓ2 sup 1 (cid:80)t−1 1 ≤ 1, and consequently:
0 µ2 Ξ T0≤t≤T t s=T0 sµ2 2
(cid:18) ℓ2T η (cid:19)
H ≤ c σ2+ Ξ 0 T0W +H
T ∗ µ T0 T0
for universal constants c > 0.
Substituting back into the bound (19b), for T ≥ T ≥ (µη )−1, we obtain:
0 T
(cid:32) (cid:33)
c′ T
W
T
= T2E∥v T∥2
2
≤
η
µσ ∗2+c′ Tµ2η0
2
+e−µ(ℓT−ℓT0)T 02 W
T0
T T−1
A.4 Proof of Lemma 4
By the martingale decomposition (35), for any t ≥ T , we have the identity
0
t2E∥Gz ∥2 = T 2E∥Gz ∥2+E([GM] )+E([GΨ] )+2E([GM,GΨ] ) (36)
t 2 0 T0 2 t t t
For the quadratic variation terms, we note that
t
(cid:88)
E([GM] ) = E∥Gε (θ )∥2
t s s−1 2
s=T0+1
t (cid:18)(cid:113) (cid:113) (cid:19)2
(cid:88)
≤ E∥Gε (θ∗)∥2+|||G||| E∥ε (θ )−ε (θ∗)∥2
s 2 op s s−1 s 2
s=T0+1
t (cid:18)(cid:113) (cid:113) (cid:19)2
(cid:88)
≤ Tr(GΣ∗G⊤)+ℓ |||G||| E∥θ −θ∗∥2
Ξ op s−1 2
s=T0+1
(cid:16) (cid:17) (cid:88)t (cid:113) (cid:88)t
≤ (t−T )Tr GΣ∗G⊤ +2 Tr(GΣ∗G⊤)ℓ |||G||| r (s)+ ℓ2|||G|||2 r2(s)
0 Ξ op θ Ξ op θ
s=T0+1 s=T0+1
t
≤ (t−T )Tr(cid:16) GΣ∗G⊤(cid:17) +|||G|||2 (cid:88) (cid:0) 2σ ℓ r (s)+ℓ2r2(s)(cid:1) (37)
0 op ∗ Ξ θ Ξ θ
s=T0+1
37and
t
(cid:88)
E([GΨ] ) = (s−1)2E∥Gε (θ )−Gε (θ )∥2
t s s−1 s s−2 2
s=T0+1
t
(cid:88)
≤ ℓ2|||G|||2 (s−1)2E∥θ −θ ∥2
Ξ op s−1 s−2 2
s=T0+1
t
(cid:88)
≤ ℓ2|||G|||2 (s−1)2η2 r2(s) (38)
Ξ op s−1 v
s=T0+1
We decompose the cross variation term in two parts, and bound them separately.
t
(cid:88)
E([GM,GΨ] ) = (s−1)E⟨Gε (θ ), Gε (θ )−Gε (θ )⟩
t s s−1 s s−1 s s−2
s=T0+1
t
(cid:88)
= (s−1)E⟨Gε (θ )−Gε (θ∗), Gε (θ )−Gε (θ )⟩
s s−1 s s s−1 s s−2
s=T0+1
(cid:124) (cid:123)(cid:122) (cid:125)
:=Q1(t)
t
(cid:88)
+ (s−1)E⟨Gε (θ∗), Gε (θ )−Gε (θ )⟩
s s s−1 s s−2
s=T0+1
(cid:124) (cid:123)(cid:122) (cid:125)
:=Q2(t)
For the term Q , Cauchy–Schwartz inequality leads to the bound:
1
t (cid:113)
(cid:88)
Q (t) ≤ (s−1)|||G|||2 E∥ε (θ )−ε (θ∗)∥2·E∥ε (θ )−ε (θ )∥2
1 op s s−1 s 2 s s−1 s s−2 2
s=T0+1
t (cid:113)
(cid:88)
≤ ℓ2|||G|||2 (s−1)η E∥θ −θ∗∥2·E∥v ∥2
Ξ op s−1 s−1 2 s−1 2
s=T0+1
t
(cid:88)
≤ ℓ2|||G|||2 (s−1)η r (s)r (s) (39)
Ξ op s−1 v θ
s=T0+1
For the term Q , we note that
2
t
(cid:88)
Q (t) = (s−1)(E⟨Gε (θ∗), Gε (θ )⟩−E⟨Gε (θ∗), Gε (θ )⟩)
2 s s s−1 s−1 s−1 s−2
s=T0+1
t−1
( =i) (T −1)E⟨Gε (θ∗), Gε (θ )−Gε (θ )⟩+ (cid:88) E⟨Gε (θ∗), Gε (θ )−Gε (θ )⟩
0 t t t−1 t T0−1 t t t−1 t s−1
s=T0
(ii) (cid:113) (cid:88)t−1 (cid:113)
≤ (T −1)σ ℓ |||G|||2 E∥θ −θ ∥2+σ ℓ |||G|||2 E∥θ −θ ∥2
0 ∗ Ξ op t−1 T0−1 2 ∗ Ξ op t−1 s−1 2
s=T0
 
t−1
(cid:88)
≤ 2σ ∗ℓ Ξ|||G|||2 opT 0∥θ 0−θ∗∥ 2+tr θ(t)+ r θ(s) (40)
s=T0
38In step (i), we apply Abel’s summation formula, and in step (ii), we use the Cauchy–Schwartz
inequality.
Finally, for the initial condition, we have the bound:
2(σ2+ℓ2 ∥θ −θ∗∥2)
E∥Gz ∥2 ≤ |||G|||2 ·E∥z ∥2 ≤ |||G|||2 · ∗ Ξ 0 2 (41)
T0 2 op T0 2 op T
0
Collecting the bounds (37)-(41) and substituting into the decomposition (36), we obtain the
inequality:
E∥Gz ∥2 ≤
(cid:18)
1+
T 0(cid:19)
·
Tr(cid:0) GΣ∗G⊤(cid:1) +c|||G|||2 opσ ∗ℓ
Ξ
(cid:88)T
r (s)
T 2 T T T2 θ
s=T0
+c|||G|||2 opℓ2
Ξ
(cid:88)T
(cid:0) r (s)+(s−1)η r (s)(cid:1)2
+cT 0|||G|||2 op(σ ∗+ℓ Ξ∥θ 0−θ∗∥ 2)2
T2 θ s−1 v T2
s=T0
for a universal constant c > 0.
Invoking Proposition 1, we note that:
√ √
(cid:18) (cid:19)
σ T logt 1 σ T
∗ 0 ∗ 0
r (t) ≤ c √ + ℓ + √ ∥∇F(θ )∥ and r (t) ≤ c √ + ∥∇F(θ )∥
θ µ t µ2t Ξ η t t 0 2 v t µη t µη tt3/2 0 2
Substituting into above upper bound, we obtain:
E∥Gz ∥2 ≤ Tr(cid:0) GΣ∗G⊤(cid:1) +c|||G|||2 (cid:32) ℓ Ξ + ℓ2 Ξ(cid:80)T s=T0η s + T 0(cid:33) σ2
T 2 T op µT3/2 µT2 T2 ∗
 
+c|||G|||2
opℓ2 ΞT
µ0
2Tlo 2gT
1+
µ1
ℓ
(cid:88)T η2s1
5/2∥∇F(θ 0)∥2
2
Ξ s=T0 s
For the stepsize choice η = 1 , we have the bound
t µT01−αtα
Tr(cid:0) GΣ∗G⊤(cid:1) (cid:18) T (cid:19)1/2∧α σ2 T 2logT (cid:32) T2α−3/2 (cid:33)
E∥Gz ∥2 ≤ +c|||G|||2 0 ∗ +c|||G|||2 0 1+ ∥∇F(θ )∥2
T 2 T op T T op T2 T 2α−3/2 0 2
0
which proves this lemma.
A.5 Proof of Lemma 5
Similar to the proof of Lemma 1, we use the decomposition
(cid:18) 1(cid:19)4
E∥v ∥4 ≤ 1− E∥v +∇f(θ ,ξ )−∇f(θ ,ξ )∥4
t 2 t t−1 t−1 t t−2 t 2
4
(cid:18) 1(cid:19)3
(cid:16) (cid:17)
+ 1− E ∥v +∇f(θ ,ξ )−∇f(θ ,ξ )∥2⟨v +∇f(θ ,ξ )−∇f(θ ,ξ ), ∇f(θ ,ξ )⟩
t t t−1 t−1 t t−2 t 2 t−1 t−1 t t−2 t t−1 t
6
(cid:18) 1(cid:19)2
(cid:16) (cid:17)
+ 1− E ∥v +∇f(θ ,ξ )−∇f(θ ,ξ )∥2·∥∇f(θ ,ξ )∥2
t2 t t−1 t−1 t t−2 t 2 t−1 t 2
(cid:18) (cid:19)
4 1 (cid:16) (cid:17)
+ 1− E ∥v +∇f(θ ,ξ )−∇f(θ ,ξ )∥ ·∥∇f(θ ,ξ )∥3
t3 t t−1 t−1 t t−2 t 2 t−1 t 2
1
+ E∥∇f(θ ,ξ )∥4 (42)
t4 t−1 t 2
39WeclaimthefollowingboundsontherelevanttermsinEq(42),forstepsizechoiceη ≤ 1(cid:0)1∧ µ (cid:1)
t−1 8 L 2
ℓ(cid:102)Ξ
E∥v +∇f(θ ,ξ )−∇f(θ ,ξ )∥4 ≤ (1−µη )E∥v ∥4 (43a)
t−1 t−1 t t−2 t 2 t−1 t−1 2
and
(cid:16) (cid:17)
E ∥v +∇f(θ ,ξ )−∇f(θ ,ξ )∥2⟨v +∇f(θ ,ξ )−∇f(θ ,ξ ), ∇f(θ ,ξ )⟩
t−1 t−1 t t−2 t 2 t−1 t−1 t t−2 t t−1 t
(cid:18) (cid:19)
≤ tµη t−1E∥v ∥4+ c σ 2+ 1 (cid:0)E∥∇F(θ )∥4(cid:1)1/2 ·(cid:16) E∥v ∥4(cid:17)1/2 (43b)
3 t−1 2 t (cid:102)∗ µη t−1 2 t−1 2
t−1
Recall that Eq (24) implies the bound
27
E∥∇f(θ ,ξ )∥4 ≤ 27σ 4+ E∥∇F(θ )∥4 (43c)
t−1 t 2 (cid:102)∗ (µη )2 t−1 2
t−1
Taking these two bounds as given, we now bound the fourth moment E∥v ∥4. First, by H¨older’s
t 2
inequality and Young’s inequality, we have the following bounds:
(cid:16) (cid:17)
E ∥v +∇f(θ ,ξ )−∇f(θ ,ξ )∥2·∥∇f(θ ,ξ )∥2
t−1 t−1 t t−2 t 2 t−1 t 2
(cid:16) (cid:17)1/2 (cid:16) (cid:17)1/2
≤ E∥v +∇f(θ ,ξ )−∇f(θ ,ξ )∥4 · E∥∇f(θ ,ξ )∥4
t−1 t−1 t t−2 t 2 t−1 t 2
(cid:18) (cid:19)
≤ c(cid:16) E∥v ∥4(cid:17)1/2 · σ 2+ 1 (cid:0)E∥∇F(θ )∥4(cid:1)1/2
t−1 2 (cid:102)∗ µη t−1 2
t−1
and
(cid:16) (cid:17)
E ∥v +∇f(θ ,ξ )−∇f(θ ,ξ )∥ ·∥∇f(θ ,ξ )∥3
t−1 t−1 t t−2 t 2 t−1 t 2
(cid:16) (cid:17)1/4 (cid:16) (cid:17)3/4
≤ E∥v +∇f(θ ,ξ )−∇f(θ ,ξ )∥4 · E∥∇f(θ ,ξ )∥4
t−1 t−1 t t−2 t 2 t−1 t 2
(cid:18) (cid:19) (cid:18) (cid:19)
≤ ct(cid:16) E∥v ∥4(cid:17)1/2 · σ 2+ 1 (cid:0)E∥∇F(θ )∥4(cid:1)1/2 + c σ 4+ 1 E∥∇F(θ )∥4
t−1 2 (cid:102)∗ µη t−1 2 t (cid:102)∗ µ2η2 t−1 2
t−1 t−1
Collecting above bounds, we arrive at the conclusion
E∥v ∥4 ≤
(cid:18)
1−
1(cid:19)4
(1−µη )E∥v ∥4+ c 1
(cid:18)
σ 2+ 1 (cid:0)E∥∇F(θ
)∥4(cid:1)1/2(cid:19)
·(cid:16) E∥v ∥4(cid:17)1/2
t 2 t t−1 t−1 2 t2 (cid:102)∗ µη t−1 2 t−1 2
t−1
(cid:18) (cid:19)
c 1
+ 2 σ 4+ E∥∇F(θ )∥4
t4 (cid:102)∗ µ2η2 t−1 2
t−1
(cid:34)
(cid:18) 1(cid:19)2 (cid:113) c′ (cid:18) 1 (cid:113)
(cid:19)(cid:35)2
≤ 1− (1−µη /2) E∥v ∥4+ σ 2+ E∥∇F(θ )∥4
t t−1 t−1 2 t2 (cid:102)∗ µη t−1 2
t−1
for universal constants c ,c ,c′ > 0. This completes the proof of this lemma.
1 2
40Proof of Eq (43a): We note the following expansion:
E∥v +∇f(θ ,ξ )−∇f(θ ,ξ )∥4
t−1 t−1 t t−2 t 2
(cid:16) (cid:17) (cid:16) (cid:17)
≤ E∥v ∥4+4E ∥v ∥2⟨v , ∇F(θ )−∇F(θ ⟩ +6E ∥v ∥2·∥∇f(θ ,ξ )−∇f(θ ,ξ )∥2
t−1 2 t−1 2 t−1 t−1 t−2 t−1 2 t−1 t t−2 t 2
(cid:16) (cid:17)
+4E ∥v ∥ ·∥∇f(θ ,ξ )−∇f(θ ,ξ )∥3 +E∥∇f(θ ,ξ )−∇f(θ ,ξ )∥4
t−1 2 t−1 t t−2 t 2 t−1 t t−2 t 2
(cid:18) (cid:19) (cid:18) (cid:19)
≤ 1−4η
t−1
µµ +L
L
+6η t2 −1ℓ(cid:101)Ξ2 E∥v t−1∥4 2+ 8− (µ+L4
)η
E(cid:16) ∥∇F(θ t−1)−∇F(θ t−2∥2 2·∥v t−1∥2 2(cid:17)
t−1
+3E∥∇f(θ ,ξ )−∇f(θ ,ξ )∥4
t−1 t t−2 t 2
For the last term, we note that
E∥∇f(θ ,ξ )−∇f(θ ,ξ )∥4
t−1 t t−2 t 2
≤ 8E∥∇F(θ )−∇F(θ )∥4+8E∥ε(θ ,ξ )−ε(θ ,ξ )∥4
t−1 t−2 2 t−1 t t−2 t 2
≤ 8L2η t2 −1E(cid:16) ∥∇F(θ t−1)−∇F(θ t−2)∥2 2·∥v t−1∥2 2(cid:17) +8ℓ(cid:101)Ξ4 η t4 −1E∥v t−1∥4
2
Putting them together, for η ≤ 1(cid:0)1 ∧ µ (cid:1) , we arrive at the contraction bound
t−1 8 L 2
ℓ(cid:102)Ξ
E∥v +∇f(θ ,ξ )−∇f(θ ,ξ )∥4
t−1 t−1 t t−2 t 2
(cid:18) (cid:19)
≤ 1−4η
t−1
µµ +L
L
+6η t2 −1ℓ(cid:101)Ξ2 +24η t4 −1ℓ(cid:101)Ξ4 E∥v t−1∥4
2
(cid:18) (cid:19)
4 (cid:16) (cid:17)
+ 8− +24L2η2 E ∥∇F(θ )−∇F(θ ∥2·∥v ∥2
(L+µ)η t−1 t−1 t−2 2 t−1 2
t−1
≤ (1−µη )E∥v ∥4
t−1 t−1 2
which proves this bound.
Proof of Eq (43b): Denote the following random variables for notational convenience
λ := v +∇F(θ )−∇F(θ ) and ζ := ε(θ ,ξ )−ε(θ ,ξ )
t−1 t−1 t−1 t−2 t t−1 t t−2 t
For η ≤ 1 , it is easy to see the bound ∥λ ∥ ≤ ∥v ∥ almost surely. And we note by
t−1 2L t−1 2 t−1 2
Assumption 2′ that
E(cid:16) ∥ζ t∥4
2
| F t−1(cid:17) ≤ ℓ(cid:101)Ξ4 ∥θ t−1−θ t−2∥4
2
= ℓ(cid:101)Ξ4 η t4 −1∥v t−1∥4
2
We note the decomposition
(cid:16) (cid:17)
E ∥λ +ζ ∥2⟨λ +ζ , ∇f(θ ,ξ )⟩
t−1 t 2 t−1 t t−1 t
(cid:16) (cid:17) (cid:16) (cid:17)
≤ E ∥λ ∥2⟨λ , ∇F(θ )⟩ +6E ∥ζ ∥ ·(cid:0) ∥λ ∥2+∥ζ ∥2(cid:1) ·∥∇f(θ ,ξ )∥
t−1 2 t−1 t−1 t 2 t−1 2 t 2 t−1 t 2
Applying Eq (24) accompanied with H¨older’s inequality, we can bound the above terms as follows
(cid:16) (cid:17) (cid:16) (cid:17)3/4 (cid:16) (cid:17)1/4
E ∥λ ∥2⟨λ , ∇F(θ )⟩ ≤ E∥v ∥4 · E∥∇F(θ )∥4
t−1 2 t−1 t−1 t−1 2 t−1 2
41(cid:32) (cid:33)
E(cid:16) ∥ζ t∥ 2∥λ t−1∥2 2∥∇f(θ t−1,ξ t)∥ 2(cid:17) ≤ 3ℓ(cid:101)Ξη t−1E ∥v t−1∥3 2·(cid:0) σ (cid:102)∗+ ℓ µ(cid:101)Ξ ∥∇F(θ t−1)∥ 2(cid:1)
(cid:32) (cid:33)
≤ 3ℓ(cid:101)Ξη t−1(cid:16) E∥v t−1∥4 2(cid:17)3/4 · σ (cid:102)∗+ ℓ µ(cid:101)Ξ(cid:0)E∥∇F(θ t−1)∥4 2(cid:1)1/4
and
(cid:16) (cid:17) (cid:16) (cid:17)3/4 (cid:16) (cid:17)1/4
E ∥ζ ∥3·∥∇f(θ ,ξ )∥ ≤ E∥ζ ∥4 · E∥∇f(θ ,ξ )∥4
t 2 t−1 t 2 t 2 t−1 t 2
(cid:32) (cid:33)
≤ 3ℓ(cid:101)Ξ3 η t3 −1(cid:16) E∥v t−1∥4 2(cid:17)3/4 · σ (cid:102)∗+ ℓ µ(cid:101)Ξ(cid:0)E∥∇F(θ t−1)∥4 2(cid:1)1/4
(cid:113)
Collecting the three terms, and noting that η ≤ (cid:0)1 ∧ µ (cid:1) ≤ 1 µ ≤ 1 , we have
t−1 L ℓ(cid:102)Ξ2 ℓ(cid:102)Ξ L ℓ(cid:102)Ξ
(cid:16) (cid:17)
E ∥λ +ζ ∥2⟨λ +ζ , ∇f(θ ,ξ )⟩
t−1 t 2 t−1 t t−1 t
≤
c(cid:16)
E∥v t−1∥4
2(cid:17)3/4 ·(cid:16)
(cid:0)E∥∇F(θ t−1)∥4 2(cid:1)1/4 +ℓ(cid:101)Ξη t−1σ
(cid:102)∗(cid:17)
(cid:18) (cid:19)
≤ tµη t−1E∥v ∥4+ c σ 2+ 1 (cid:0)E∥∇F(θ )∥4(cid:1)1/2 ·(cid:16) E∥v ∥4(cid:17)1/2
3 t−1 2 t (cid:102)∗ µη t−1 2 t−1 2
t−1
which proves this inequality.
A.6 Proof of Lemma 6
By Eq (35) and Minkowski’s inequality, we have the bound
T 4 8 8
E∥z ∥4 ≤ 0 E∥z ∥4+ E∥M ∥4+ E∥Ψ ∥4
t 2 t4 T0 2 t4 t 2 t4 t 2
Invoking the BDG inequality for Hilbert-space-valued martingales, we have the moment bound
 2
t
E∥M t∥4
2
≤ cE(cid:0) [M]2 t(cid:1) = c·E  (cid:88) ∥ε s(θ s−1)∥2 2 and
s=T0+1
 2
t
E∥Ψ t∥4
2
≤ cE(cid:0) [Ψ]2 t(cid:1) ≤ c·E  (cid:88) (s−1)2∥ε s(θ s−1)−ε s(θ s−2)∥2 2
s=T0+1
Invoking Cauchy–Schwartz inequality, we note that
t
(cid:88) (cid:88) (cid:16) (cid:17)
E∥M ∥4 ≤ c E∥ε (θ )∥4+2c E ∥ε (θ )∥2·E∥ε (θ )∥4
t 2 s s−1 2 s s−1 2 u u−1 2
s=T0+1 T0+1≤s≤u≤t
t (cid:113) (cid:113)
(cid:88) (cid:88)
≤ c E∥ε (θ )∥4+2c E∥ε (θ )∥4· E∥ε (θ )∥4
s s−1 2 s s−1 2 u u−1 2
s=T0+1 T0+1≤s≤u≤t
 2
t (cid:113)
(cid:88)
= c E∥ε s(θ s−1)∥4 2
s=T0+1
42Similarly, for the martingale (Ψ ) , we have the bound
t t≥T0
(cid:113) t (cid:113)
(cid:88)
E∥Ψ ∥4 ≤ c (s−1)2 E∥ε (θ )−ε (θ )∥4
t 2 s s−1 s s−2 2
s=T0+1
By Eq (24), we have the bound
(cid:32) 2 (cid:33)
(cid:113)
E∥ε (θ )∥4 ≤ c σ 2+
ℓ(cid:101)Ξ (cid:113)
E∥∇F(θ )∥4
s s−1 2 (cid:102)∗ µ2 s−1 2
By Assumption 2′, we note that
(cid:113) (cid:113) (cid:113)
E∥ε s(θ s−1)−ε s(θ s−2)∥4
2
≤ ℓ(cid:101)Ξ2 E∥θ s−1−θ s−2∥4
2
= ℓ(cid:101)Ξ2 η t2
−1
E∥v s−1∥4
2
Collecting the terms above, we arrive at the conclusion.
A.7 Proof of Lemma 7
We first note the following decomposition, which holds true for any T(cid:101) ∈ [0,t−T 0]
(cid:12) (cid:12) (cid:12) (cid:12)
|E⟨tGz t, Gv t⟩| ≤ (t−T(cid:101))(cid:12) (cid:12)E⟨Gz t−T(cid:101), Gv t⟩(cid:12) (cid:12)+(cid:12) (cid:12)E⟨G(cid:0) tz t−(t−T(cid:101))z t−T(cid:101)(cid:1) , Gv t⟩(cid:12) (cid:12).
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
(cid:0) (cid:1) (cid:0) (cid:1)
:=Q3 t,T(cid:101) :=Q4 t,T(cid:101)
WeclaimthefollowingupperboundsforthetermsQ 3(t,T(cid:101))andQ 4(t,T(cid:101)),forT(cid:101) ∈
(cid:2)
cT
01−αtαlogt,t/2(cid:3)
:
(cid:32) (cid:33)
Q 3(t,T(cid:101)) ≤ c|||G| µ||2 o 2pL 2 t1+ 2α T 01− 2α tσ (cid:102) 3∗ /3
2
+(cid:0)T t0(cid:1)3−3α/2 log2t∥∇F(θ 0)∥3
2
(44a)
Q 4(t,T(cid:101)) ≤ c|||G|||2 op(cid:113) T(cid:101)T 01−αtα·(cid:18) σ t∗2 +(cid:0)T t0(cid:1)2−α ∥∇F(θ 0)∥2 2(cid:19) (44b)
Takingthesetwoboundsasgiven,wechoosethetime-lagparameterT(cid:101) := cT 01−αtαlogt,andarrive
at the bound:
|E⟨Gz , Gv ⟩| ≤ c|||G|||2 (cid:0)T 0(cid:1)1−α(cid:18) σ ∗2 +(cid:0)T 0(cid:1)2−α ∥∇F(θ )∥2(cid:19) logt
t t op t t t 0 2
(cid:32) (cid:33)
+c|||G|||2 opL 2(cid:0)T 0(cid:1)1− 2α σ (cid:102)∗3 +(cid:0)T 0(cid:1)3−3α/2 log2t∥∇F(θ )∥3
µ2 t t3/2 t 0 2
which completes the proof of this lemma.
Proof of the bound (44a): To bound the term Q , we use the following lemma
3
Lemma 9. For t > T and s > 0, the following bound holds true
0
E∥E(v
t+s
| F t)∥2
2
≤ cr (cid:101)v2(t)e−µ(cid:80)s k− =1 1η k +cL µ22 2r (cid:101)v2(t)r (cid:101)θ2(t)
43See §A.8 for the proof of this lemma.
Taking Lemma 9 as given, the bound for the term Q 3(t,T(cid:101)) directly follows from Cauchy–
Schwartz inequality.
(cid:114) (cid:114)
(cid:12) (cid:16) (cid:17) (cid:12) (cid:13) (cid:13)2 (cid:13) (cid:16) (cid:17)(cid:13)2
Q 3(t,T(cid:101)) = (t−T(cid:101))(cid:12) (cid:12)E⟨Gz t−T(cid:101), GE v
t
| F
t−T(cid:101)
⟩(cid:12)
(cid:12)
≤ t|||G|||2
op
E(cid:13) (cid:13)z t−T(cid:101)(cid:13)
(cid:13)
2· E(cid:13) (cid:13)E v
t
| F
t−T(cid:101)
(cid:13)
(cid:13)
2
For the time-lag T(cid:101) ≤ t, Proposition 1 yields the bound:
2
(cid:114)
(cid:13) (cid:13)2 √ (cid:112)
t E(cid:13)z (cid:13) ≤ cσ t+T logt∥∇F(θ )∥ (45a)
(cid:13) t−T(cid:101)(cid:13)
2
∗ 0 0 2
By Lemma 9, for a non-increasing stepsize sequence, when the time-lag T(cid:101) satisfies µT(cid:101)η
t
≥ clogt,
we have the bound e−µ(cid:80)s k− =1 1η k ≤ t1 3. Therefore, given the stepsize choice η t = µT011 −αtα, we have
the following bound holding true for T(cid:101) ≥ cT 01−αtαlogt:
(cid:13) (cid:16) (cid:17)(cid:13)2
E(cid:13)E v | F (cid:13) ≤ cL r2(t)r2(t) (45b)
(cid:13) t t−T(cid:101) (cid:13)
2
2(cid:101)v (cid:101)θ
Combining the bounds (45a) and (45b), we have the following bound holds true for the time-
lag taking values in the interval T(cid:101) ∈
(cid:2)
cT
01−αtαlogt,t/2(cid:3)
(the interval is non-empty for any t ≥
cT logT ):
0 0
Q 3(t,T(cid:101)) ≤
cL 2||| µG|||2
op
(cid:16)
σ
∗√
t+T
0(cid:112)
logt∥∇F(θ 0)∥
2(cid:17)
r (cid:101)v(t)·r (cid:101)θ(t)
Noting that σ
∗
≤ σ
(cid:102)∗
and ℓ
Ξ
≤ ℓ(cid:101)Ξ, above bounds lead to the inequality:
(cid:32) (cid:33)
Q 3(t,T(cid:101)) ≤ cL 2|| µ|G 2|||2 opt1+ 2α T 01− 2α tσ (cid:102) 3∗ /3
2
+(cid:0)T t0(cid:1)3−3α/2 log2t∥∇F(θ 0)∥3
2
which proves the desired result.
Proof of the bound (44b): For the term Q , we also apply Cauchy-Schwartz inequality, and
4
obtain the following bound:
(cid:114)
(cid:13) (cid:13)2 (cid:13) (cid:13)2 (cid:113)
Q 4(t,T(cid:101)) ≤ |||G|||2
op
2E(cid:13) (cid:13)M t−M t−T(cid:101)(cid:13)
(cid:13)
2+2E(cid:13) (cid:13)Ψ t−Ψ t−T(cid:101)(cid:13)
(cid:13)
2· E∥v t∥2
2
The mean-squared norms of martingales are just their expected quadratic variation:
t
(cid:13) (cid:13)2 (cid:16) (cid:17) (cid:88)
E(cid:13) (cid:13)M t−M t−T(cid:101)(cid:13)
(cid:13)
2
= E [M] t−[M]
t−T(cid:101)
≤ 2T(cid:101)σ ∗2+2 ℓ2 Ξr θ2(s)
s=t−T(cid:101)+1
t
(cid:13) (cid:13)2 (cid:16) (cid:17) (cid:88)
E(cid:13)Ψ −Ψ (cid:13) = E [Ψ] −[Ψ] ≤ ℓ2 (s−1)2η2 r2(s)
(cid:13) t t−T(cid:101)(cid:13)
2
t t−T(cid:101) Ξ s−1 v
s=t−T(cid:101)+1
44Substituting with the rates in Proposition 1, we have the bounds:
E(cid:13) (cid:13) (cid:13)M t−M t−T(cid:101)(cid:13) (cid:13) (cid:13)2
2
≤ cT(cid:101)(cid:18) σ ∗2+ ℓ2 ΞT µ0 4tlo 2gt (cid:0) ℓ2 Ξ+ η1 t2t(cid:1) ∥∇F(θ 0)∥2 2(cid:19) and (46a)
(cid:13) (cid:13)2 (cid:18) ℓ2σ2η T 2 (cid:19)
E(cid:13) (cid:13)Ψ t−Ψ t−T(cid:101)(cid:13)
(cid:13)
2
≤ cT(cid:101) Ξ µ∗ t + t0
3
∥∇F(θ 0)∥2
2
(46b)
For the stepsize choice η = 1 , we have the bound:
t µT01−αtα
E(cid:13) (cid:13) (cid:13)M t−M t−T(cid:101)(cid:13) (cid:13) (cid:13)2 2+E(cid:13) (cid:13) (cid:13)Ψ t−Ψ t−T(cid:101)(cid:13) (cid:13) (cid:13)2
2
≤ cT(cid:101)(cid:18) σ ∗2+T 0(cid:0)T t0(cid:1)min(2,3−2α) ∥∇F(θ 0)∥2 2(cid:19)
Invoking Proposition 1, we can bound the moment of v as:
t
σ2T 1−α (cid:18) T (cid:19)3−2α
E∥v ∥2 ≤ c ∗ 0 + 0 ∥∇F(θ )∥2
t 2 t2−α t 0 2
Combining above bounds, we conclude that
Q 4(t,T(cid:101)) ≤ c|||G|||2 op(cid:113) T(cid:101)T 01−αtα·(cid:18) σ t∗2 +(cid:0)T t0(cid:1)2−α ∥∇F(θ 0)∥2 2(cid:19)
A.8 Proof of Lemma 9
Given t > T fixed, denote ∆ := E(v | F ) for any s > 0.
0 s t+s t
Taking conditional expectations on both sides of Eq (5a), for s > 0, we have that
t+s−1 1
E[v | F ] = E[v +∇F(θ )−∇F(θ ) | F ]+ E[∇F(θ ) | F ]
t+s t t+s−1 t+s−1 t+s−2 t t+s−1 t
t+s t+s
(47)
By the decomposition ∇F(θ ) = v −z and the fact that (z ) is a martingale, we note
t+s−1 t+s t+s t t≥T0
that
E[∇F(θ ) | F ] = E[v | F ]
t+s−1 t t+s t
By the one-point Hessian Lipschitz condition, we note that
∥∇F(θ )−∇F(θ )+η H∗v ∥
t+s−1 t+s−2 t+s−1 t+s−1 2
(cid:13)(cid:90) 1 (cid:13)
= η
t+s−1(cid:13)
(cid:13)
(cid:0) ∇2F(cid:0)
γθ t+s−1+(1−γ)θ
t+s−2)−∇2F(θ∗)(cid:1)
v t+s−1
dγ(cid:13)
(cid:13)
(cid:13) (cid:13)
0 2
(cid:90) 1
≤ η L ∥v ∥ · ∥γθ +(1−γ)θ −θ∗∥ dγ
t+s−1 2 t+s−1 2 t+s−1 t+s−2 2
0
≤ η L ∥v ∥ ·(∥θ −θ∗∥ +∥θ −θ∗∥ )
t+s−1 2 t+s−1 2 t+s−1 2 t+s−2 2
Substituting into the identity (47), we obtain the following inequality, which holds true almost
surely for any s > 0:
∥∆ ∥ ≤ ∥(I −η H∗)∆ ∥ +η L E(cid:2) ∥v ∥ ·(cid:0) ∥θ −θ∗∥ +∥θ −θ∗∥ (cid:1) | F (cid:3)
s 2 t+s−1 s−1 2 t+s−1 2 t+s−1 2 t+s−1 2 t+s−2 2 t
≤ (1−η µ)∥∆ ∥ +η L E(cid:2) ∥v ∥ ·(cid:0) ∥θ −θ∗∥ +∥θ −θ∗∥ (cid:1) | F (cid:3)
t+s−1 s−1 2 t+s−1 2 t+s−1 2 t+s−1 2 t+s−2 2 t
45Taking the second moment and applying Cauchy-Schwartz inequality, we arrive at the bound
(cid:113)
E∥∆ ∥2
s 2
≤ (1−η
µ)(cid:113)
E∥∆ ∥2+2η L
(cid:16)
E∥v ∥4·(cid:0)E∥θ −θ∗∥4+E∥θ
−θ∗∥4(cid:1)(cid:17)1/4
t+s−1 s−1 2 t+s−1 2 t+s−1 2 t+s−1 2 t+s−2 2
(cid:113)
≤ (1−η µ) E∥∆ ∥2+2η L r (t)r (t)
t+s−1 s−1 2 t+s−1 2(cid:101)v (cid:101)θ
Solving the recursion, we obtain the bound
E∥∆ s∥2
2
≤ cr (cid:101)v2(t)e−µ(cid:80)s k− =1 1η k +cL µ22 2r (cid:101)v2(t)r (cid:101)θ2(t)
which finishes the entire proof.
46