VGBench: Evaluating Large Language Models on Vector Graphics
Understanding and Generation
BochengZou* MuCai∗ JianruiZhang YongJaeLee
DepartmentofComputerScience
UniversityofWisconsin-Madison
{bochengz,mucai,harrisz,yongjaelee}@cs.wisc.edu
https://vgbench.github.io/
Abstract and polygons, as shown in Figure 1 (a). Vector
graphicshavebeencriticalfordesignersandartists
In the realm of vision models, the primary
since the geometry primitives can be easily ma-
mode of representation is using pixels to ras-
nipulated. VectorrepresentationsincludeScalable
terize the visual world. Yet this is not al-
VectorGraphics(SVG),TikZ,Graphviz,etc.
ways the best or unique way to represent vi-
sualcontent,especiallyfordesignersandartists VectorGraphicsvectorrepresentationsmakeit
who depict the world using geometry primi- possibletoconductvisualunderstandingandgener-
tivessuchaspolygons. Vectorgraphics(VG), ationwithLLMssuchasGPT-4(OpenAI,2023b).
on the other hand, offer a textual representa- Recent studies (Bubeck et al., 2023; Cai et al.,
tionofvisualcontent,whichcanbemorecon-
2023; Rodriguez et al., 2023) showcase LLMs’
ciseandpowerfulforcontentlikecartoonsor
superior capability across different perspectives.
sketches.Recentstudieshaveshownpromising
However,thoseworkseither(1)onlyshowquali-
resultsonprocessingvectorgraphicswithca-
tativeresults(Bubecketal.,2023),(2)onlystudy
pableLargeLanguageModels(LLMs). How-
ever, such works focus solely on qualitative vectorgraphicsunderstanding(Wangetal.,2024a)
results,understanding,oraspecifictypeofvec- andnotgeneration,or(3)onlystudyonespecific
torgraphics. WeproposeVGBench,acompre- type of vector graphics such as SVG (Cai et al.,
hensivebenchmarkforLLMsonhandlingvec- 2023;Wangetal.,2024a;Rodriguezetal.,2023)
torgraphicsthroughdiverseaspects,including
orTikZ(Belouadietal.,2023). Therefore,thecom-
(a)bothvisualunderstandingandgeneration,
munitylacksacomprehensiveLLMbenchmarkfor
(b) evaluation of various vector graphics for-
vectorgraphics.
mats,(c)diversequestiontypes,(d)widerange
of prompting techniques, (e) under multiple
Inthispaper,weproposeVGBenchtocompre-
LLMs. Evaluating on our collected 4279 un- hensivelyevaluateLLMs’vectorgraphicsprocess-
derstandingand5845generationsamples,we ingcapabilitiesviadifferentaspects: VGBench(1)
findthatLLMsshowstrongcapabilityonboth includes both visual understanding (VGQA) and
aspectswhileexhibitinglessdesirableperfor-
generation (VGen); (2) evaluates diverse vector
manceonlow-levelformats(SVG).Bothdata
graphicsformatssuchasSVG,TikZ,andGraphviz;
andevaluationpipelinewillbeopen-sourcedat
(3) covers a set of taxonomies from low-level vi-
https://vgbench.github.io.
siontohigh-levelsemantics,fromcolor,shape,to
1 Introduction categoryandadvancedreasoningquestionssuchas
usageandtherelationbetweenobjects;(4)adoptsa
Current vision models are mostly built on pixels,
varietyofpromptingtechniques,suchaszero-shot
rasterizingthevisualworldintoamatrixrepresen-
prediction,chain-of-thoughtreasoning,in-context
tation. Suchrasterziationrepresentsdiversevisual
learning,etc.;and(5)evaluatesdiverseLLMsin-
content with equally sized elements. But pixels
cluding GPT-4 (OpenAI, 2023b), GPT-3.5 (Ope-
arenottheonlywaytorepresentthevisualworld.
nAI, 2023a), Llama-3-8B-Instruct, and Llama-3-
For simple content such as cartoons or sketches,
70B-Instruct(Meta,2024).
adifferentrepresentationusingexplicitgeometry
We collect 4279 high-quality visual question-
primitivescanbemoreconciseandbeneficial. Vec-
answer (QA) pairs for vector graphics (VG) un-
torgraphicsoffersuchatextualrepresentationfor
derstanding and 5845 VG-caption pairs for vec-
visualcontentviageometryprimitives,e.g.,circles
torgraphicsgeneration. Thevectorgraphicscode
*EqualContribution. is collected from existing datasets and the Inter-
1
4202
luJ
51
]VC.sc[
1v27901.7042:viXraVector Graphics Types Question Types Tasks
Q: What is the color of Q: What does this SVG Q: What is its function in a Q: What does this SVG Q: Generate a SVG based
the zigzag shape? image depict? software application? image depict? on the caption below.
black and white icon,
A: Yellow A: Airplane A: Email sending A: Airplane representing a battery,
B: Red B: Rocket B: Document printing B: Rocket horizontal, positive
C: Blue C: Bullet C: Music playing C: Bullet terminal on the right side,
D: Green D: Tank D: Picture editing D: Tank thick black outline ……
(i) SVG (ii) TiKz (iii) Graphviz (i) Color (ii) Category (iii) Usage (i)Understanding (ii)Generation
Figure1: VGBenchisthefirstcomprehensivevectorgraphics(VG)understandingandgenerationbenchmark
acrossdiversevectorgraphicstypes,questiontypes,andpromptingtechniquesonarichsetofSoTALLMs. Our
largescalebenchmarkconsistsof4279multi-choicequestion-answerpairsand5845VG-captionpairs.
net. For visual question answering, we use a competitive performance in understanding
semi-automated pipeline to curate the questions. tasks.
Specifically, we prompt GPT-4V(ision) to gener-
ate question-answer pairs given the provided in-
context examples. Human annotators then filter Wehopethatourworkcanserveasafoundation
thegeneratedQApairstogetthefinalhigh-quality forLLMvectorgraphicsunderstandingandgener-
vector graphicsQA dataset. Weuse thegathered ationbenchmarking,andmotivatefurtherworkto
questionstoevaluateifanLLMcanunderstandvec- improvesuchcapabilities. Ourbenchmarkdataset
tor graphics correctly. For text-to-vector-graphic andevaluationpipelinewillbereleased.
generation (T2VG), we utilize GPT-4V to gener-
ate the captions and then use CLIP Score (Hes-
2 RelatedWork
sel et al., 2021) and Fréchet Inception Distance
(FID)(Heuseletal.,2017)toevaluatethequality
oftheLLMgeneratedvectorgraphicscode. 2.1 VectorGraphics
Ourkeyfindingsareasfollows:
Vector graphics represent images using basic ge-
• LLMsshowmuchbettervectorgraphicunder- ometric elements like points, lines, and curves,
standingcapabilityinTikZandGraphvizthan rather than pixels. This method offers an alterna-
SVGs. TikZandGraphvizincludemorehigh- tivetorastergraphics,providingadvantagessuch
level semantics compared to SVG, which is asinfinitescalabilitywithoutlosingdetailandeasy
composed of low-level geometry primitives. humanmanipulation.
This demonstrates that LLMs are more ca-
There are a variety of vector graphics formats,
pableinunderstandingvectorgraphicscode
such as SVG (Quint, 2003), TikZ (Mertz and
withhigh-levelsemantics.
Slough,2007)andGraphviz(Gansner,2009). SVG
format defines 14 functional areas or feature sets
• Advanced prompting techniques such as in-
and represents graphics by recording basic infor-
contextlearningorchain-of-thoughtprompt-
mationassociatedtotheseprimitives,suchastheir
ing can bring significant performance boost
coordination and scales, in an XML file. TikZ
forSVG,alow-levelVGformat.
formatdefinessomecommandstobuildbasicgeo-
• LLMs show strong vector graphics genera- metric elements and is mainly used with LATEX.
tionabilityonTikZandGraphvizformatcom- In practice, third-party packages are also com-
pared to SVG format, hinting that TikZ or monlyusedwithTikZtobuildmorediverseimages.
GraphvizmightbeabettermediumforLLMs Graphviz(Gansner,2009)isavectorgraphicsfor-
tomanipulatevectorgraphics. matthatfocusesonrepresentingdifferentkindsof
graphs. In this paper, we explore the said three
• Inbothunderstandingandgeneration,GPT-4 kindsofvectorgraphicstoprovideathoroughand
shows the strongest performance, yet open- comprehensive analysis regarding the reasoning
source models such as Llama-3-70b shows capabilitiesofLLMsonvectorgraphics.
22.2 EvaluationforImageUnderstandingand 2.3 PromptingTechniquesforLarge
Generation LanguageModels
Avarietyofpromptingstrategieshavebeenproven
capable of boosting the performance of LLMs,
WorksonImageUnderstandingaremainlybased such as GPT4 (Achiam et al., 2023). Few-shot
on raster images. VQA (Antol et al., 2015) first learning(Brownetal.,2020b)requirestheuserto
introduced the task of free-form and open-ended giveafewexamplesofthetasktotheLLM,while
Visual Question Answering and evalauted exist- Chain of Thought (Wei et al., 2022) instructs the
ing LSTM-CNN based methods. CLIP (Radford LLMtothinkstepbysteptoachievehigherperfor-
etal.,2021)introducestwoencodersforbothtexts mance. In-contextlearning(Brownetal.,2020a)
and images to achieve an aligned representation providesfew-shotexamplesatinferencetime,and
toserveasabaselineformanyimageunderstand- showsstrongperformanceboostwithoutupdating
ingtasks. LLaVA(Liuetal.,2024)andLLaMA- themodel’sparameters. Inthispaper,webroadly
Adapter(Zhangetal.,2023)proposeapproachesto evaluateLLMs’vectorgraphicunderstandingcapa-
solvegeneral-purposevisualandlanguageunder- bilitybyemployingtheaforementionedprompting
standingproblemsbasedonlargelanguagemodels. techniques.
3 TasksandExperiments
Whilevectorgraphicscanusuallybeconverted
toarasterimageeasily(Gharachorlooetal.,1989),
Wefirstintroducethesourceofourvectorgraphics
therearefewworksthattrytodirectlyunderstand
images in Sec. 3.1, and then describe the experi-
the vector graphics format. (Jiang et al., 2021)
mentsettingsinSec.3.2. Afterthat,wedetailour
exploressuchawayusinggraphneuralnetworks.
tasks,benchmarkcreation,evaluationpipelineand
(Wangetal.,2024b)utilizeslargelanguagemod-
resultsforvectorgraphicsunderstandingandgener-
els to understand vector graphics. In our work,
ationinSec.3.3andSec.3.4,respectively. Finally,
weutilizemultiplepromptingmethods,tobemen-
weprovidein-depthanalysesontheperformance
tionedinthefollowingsection,toevaluatedifferent
underdifferentLLMs,differentsequencelengths,
LLMs’vectorgraphicsunderstandingcapabilities
andreasoningprocessesinSec.3.5.
bypromptingthemwiththevectorgraphicscode
directly. 3.1 VectorGraphicsDataCollection
Wecollectvectorgraphicssamplesforbothunder-
Mostmachinelearningbasedimagegeneration
standingtasksandgenerationtasksfromavariety
modelsaimtogeneraterasterimages(Kingmaand
of sources. For samples in SVG format, we col-
Welling,2013;Goodfellowetal.,2020;Hoetal.,
lectthemfromalarge-scaleSVGrepository.1 We
2020;Rameshetal.,2021). Someresearchfocus
sampletheTikZformatvectorgraphicscodefrom
ongeneratingvectorgraphicsintextformat. Many
the DaTikZ dataset (Belouadi et al., 2023). We
works generate vector graphics from a raster im-
sampletheGraphvizcodeusedtobuildourdataset
age (Diebel, 2008; Xia et al., 2009; Ha and Eck,
bycrawlingGitHub.2
2017;Maetal.,2022). Leveraginglanguagemod-
els, some try to generate text representing vector
3.2 ExperimentSettings
graphics directly (Carlier et al., 2020; Wu et al.,
VectorGraphicsTypes Hereweconsiderthree
2023; Rodriguez et al., 2023). In our work, we
major types of vector graphics: Scalable Vector
provide a different approach to evaluate vector
Graphics(SVG),TikZ,andGraphviz. SVGisex-
graphicsgenerationvialeveragingcompetentmul-
ceptionallyversatileandsuitableforwebapplica-
timodalmodelssuchasGPT4-V(OpenAI,2023b)
tions, allowing for detailed graphical representa-
to generate a detailed caption from a rasterized
tions that scale infinitely without loss of quality.
imageofavectorgraphicsobject,basedonwhich
This enables SVGs to theoretically represent any
otherLLMswillbegeneratingvectorgraphicscode
visualcontentincludingcomplexanimationsand
for the same object during evaluation. We argue
thatmodelslikeGPT4-Vcanprovidehigh-quality
1https://www.kaggle.com/datasets/
captionsforustoautomatepartoftheevaluation
victorcondino/svgicons
process. 2https://github.com/
3SVG TikZ Graphviz
Q: In the SVG image, Q: What does this SVG Q: Which function might Q: What is the general Q: How many circles are Q: What is the position of Q: What is the orientation of Q: What is the main concept? Q: What is connected to
what is the color of the image depict? this icon represent in a theme of this image? there in this image? B relative to A? the text inside the box? both 'Client' blocks?
zigzag shape? software application?
A: Yellow A: Airplane A: Email sending A: Musical score A: 1 A: B is to the right of A A: horizontal A: Organizational Chart A: MySQL Server
B: Red B: Rocket B: Document printing B: Organizational chart B: 2 B: B is to the left of A B: vertical B: Software Architecture B: MySQL Proxy
C: Blue C: Bullet C: Music playing C: Math concept C: 3 C: B is above A C: diagonal C: Flowchart C: app
D: Green D: Tank D: Picture editing D: Architectural blueprint D: 4 D: B is below A D: circular D: Family Tree D: network core
(i) Color (ii) Category (iii) Usage (i) Concept (ii) Counting (iii) Relation (i) Layout (ii) Domain (iii) Relation
Figure2: ExamplesofthevectorgraphicsQAsfordiverseformatsincludingSVG,TikZ,andGraphvizinVGQA.
SVG TikZ Graphviz
Category Color Usage Overall Concept Counting Relation Overall Layout Domain Relation Overall
869 671 688 2228 580 239 320 1139 319 418 175 912
Table1: StatisticsofVGQA.WecollectalargesetofQAsforeachvectorgraphicsformatunderdiversetasks,
resultingin4279QAsintotal.
Q: Which function might this icon Tasks Weconsidertwomajortasksincomputer
represent in a software
application?
vision: (1) visual understanding, and (2) visual
A: Email sending
B: Document printing
C D: : M Picu ts uic re p ela dy iti in ng g generation. Wedesignmultiplechoicequestionsto
VectorGraphics PNGFormat GPT-4V QA Generation Human Filter evaluatevectorgraphicsunderstandingwhileusing
imagegenerationmetricsincludingFréchetIncep-
Figure 3: The semi-automatic curation pipeline in
VGQA.VectorgraphicsareconvertedintoPNGformat, tionDistance(FID)(Heuseletal.,2017)andCLIP
thenGPT-4Visutilizedtogeneratethequestionsand score(Hesselet al.,2021)tomeasure thequality
answers (QA) candidates. Finally, human annotators andcorrectnessofgeneratedvectorgraphics.
filtertheQApairstoobtainthehigh-qualityQAdataset.
PromptingTechniques Weadoptthreewidely
used prompting techniques: zero-shot, chain-of-
interactive elements. TikZ, in contrast, is specifi- thought(CoT)prompting,andin-contextlearning
callytailoredforcreatinghigh-precisionscientific (few-shot prompting). For CoT, we instruct the
illustrationswithinLaTeXdocuments, offeringa LLM to think step by step by appending “Please
comprehensivesuiteoftoolsfordetaileddiagram- think step by step" to the initial question, using
maticrepresentations;itencompassesabroadspec- multi-round dialog to let the LLM consider each
trum of high-level semantics such as "circuit di- option separately before figuring out the answer.
agrams, complex mathematical illustrations, and Forin-contextlearning,weprovide3examplesof
structureddiagrams". Graphviz,ontheotherhand, thesamequestiontype.
belongstothefamilyofautomatedgraphdrawing
3.3 VGQA:VectorGraphicsUnderstanding
tools,whichareoptimizedforgeneratingdiagrams
Benchmark
fromabstractdescriptionsanddatastructures,mak-
Tasks VGQAisdesignedtoevaluatemodels’vec-
ingitidealforvisualizinghierarchicalinformation,
torgraphicsunderstandingcapability. Wesystem-
suchasstatemachines,organizationalcharts,and
aticallydesignarangeoftasksbasedonthenature
networkinfrastructures.
ofeachvectorgraphicscategory,aimingatacom-
prehensiveevaluationacrossdifferentsemanticlev-
Language Models We primarily use GPT-4
els. ForSVG,wedesignthreetypesofquestions:
(1106 version) (OpenAI, 2023b) as the medium
color, category, and usage; for TikZ, we use con-
forvectorgraphicsunderstandingandgeneration.
cept,counting,andrelationsastypesofquestions;
ThisisbecauseGPT-4showssuperiorlanguagerea-
whileforGraphviz,wedesignlayout,domain,and
soning and generation capabilities, as previously
relations. ExamplesareshowninFigure2.
mentionedinSection2.3. WealsoevaluateGPT-
3.5(OpenAI,2023a)andotheropen-sourceLLMs BenchmarkCreationandEvaluation Weem-
that are highly capable, including Llama-3-70B- ployasemi-automaticbenchmarkcurationpipeline
Instruct(Meta,2024)andLlama-3-8B-Instruct. forVGQA,asshowninFigure3. Specifically,we
4g
yw
r
eh er osle rib li
e
lt
o
adl bve nu
rw n
pee
o
ub
gr r
Ol wea
p
Tlc
n
Hk
e ERS
musicO cT H E R oS
newlo settinr
gsic
o
nu s
a
pa
pc gaph to en fe ie lec gam o ve r ir dna y eot
d
oe f oil cse uyf mmo
s
eo ec
b
ncd
r
to
oo vd
lv inm
cd
eolp
t
ep
vw
a
eu u ft s ie
na teu
ce m
a
tma bmr
g
eat ste Omo eeh a
e
teor
T
ule rt u der k rHp ev s iaEh i icso Rin o Se n 23
5 O1
TH64
ERSco riu
ghtnO T H E R tS
li inn eg nodere lel
ftacs tt oru ict onure c
n
1ma ep pf tlo nw uc li mh la n ir bnt e eebo rr sg ca im
b
rni a cc ltz i
u
lra eht ei ce go ru Oin m data al c Tt ipi a hc Hha gl a Er r Ra tm
S
mb cuo
s irl l
cr it
t
acni et ig yupo
g
ntn h ollmo
l ta
Oo
e e
ut rp Td
r
atn He lo Ed Re Ss
la
nO oT yH dE eR S
out r ee
d g
el
ad to ifl oow m ncha ar it so nf >twar ce om dp iu rtt ee or
e
cp tdo rl geo c eg lh ay sa tOor iot nr
T
ng e
H
sa ht En w ipRiz o Sa rt kional
(a)SVG (b)TikZ (c)Graphviz
Figure4:Worddistributionbasedonquestioncategoriesforeachvectorgraphictype. Thetop20wordsaresampled
fromtheanswerstoeachtypeofquestion. Wordswithafrequencyoflessthan4%arerepresentedas"OTHERS".
SVG TikZ Graphviz
Category Color Usage Average Concept Counting Relation Average Layout Domain Relation Average
86.9 67.1 68.8 74.3 58.0 47.8 32.0 45.6 58.0 83.6 31.8 57.0
Table2: HumanfilteringpassingrateofVGQA.TikZandGraphvizshowlowerandlessthanhalfpassingratethan
SVG,indicatingthatevenSoTAmodelsexhibitpoorvectorgraphicunderstandingcapabilitiesincertainareas.
themostcompetitiveLMMsthatcanprovidehigh
begin{tikzpicture}[scale= You are looking at a digital image
0.5] % % S De rt a s wc a fale c eto 0.5 of a stylized yellow face with a qualitycandidates;(iii)thehumanfilteringprocess
\draw[fill=yellow!80!whit simple, cartoon-like appearance.
e] (0,0) circle (5); The face is circular with a solid
…… yellow background. It has ……. ensuresthecorrectnessofthefinalvectorgraphics
\end{tikzpicture}
Ground Truth Ground Truth GPT-4V Captioning understandingbenchmark.
Vector Graphics Rasterized VG
Finally, we collect 4279 samples in total, as
CLIP Score
\begin{tikzpicture} shown in Table 1 and 2. The word distribution
\fill[yellow] (0,0) circle
FID \ 0d .r 5a ,w 0.[ 5th ) i( cc2 ik r) c; , b lel a (0c .k 3] ) ( ;- of answers in the VGQA dataset is illustrated in
…… Figure 4. Specifically, we have 2228, 1139, and
Evaluate & Compare Generated \end{tikzpicture}
Rasterized VG T2VG via LLM 912samplesforSVG,TikZ,andGraphviz,respec-
tively. AfteranLLMmakesresponsestothevector
Figure5: TheautomaticgenerationpipelineinVGen.
ThevectorgraphicscollectedfromtheInternetisfirst graphicsquestions,wecomparethefinalresponses
renderedintothegroundtruthimagethencaptionedby withtheground-truthanswerstocomputeaccuracy.
GPT-4V.ThecaptionisfedintothetargetLLMtogen-
eratenewvectorgraphics,whichwillbecomparedwith Results EvaluationresultsofVGQAunderGPT-
thecaptionusingCLIPScoreandFIDforasimilarity 4(OpenAI,2023b)areshowninTable3. Several
score. Thescoreisthencomparedwiththesimilarity interestingfindingsarisefromtheresults:
scorebetweenthegroundtruthandthesamecaptionas
GPT-4generallyshowsstrongvectorgraphics
theupperbound.
understandingcapability. Inthezero-shotsetting,
GPT-4showsnon-trivialaccuracyfarbeyondran-
render code representing vector graphics into a domaccuracy(25%)acrossallcategories. Specif-
PNG image before leveraging GPT-4V (OpenAI, ically, GPT-4 shows strong performance in TikZ,
2023b) to generate the 4-choice question-answer withanaverageaccuracyof78%.
candidates. Then, human annotators with rich GPT-4 shows stronger performance in high-
vision-linguistic knowledge make binary annota- level vector graphics language (e.g., TikZ,
tionstomarkwhetherboththequestionandthean- Graphviz) compared to low-level vector graph-
swerofacandidatearerational,correctandbelong icslanguageSVG. Ineitherzero-shot,few-shot,
tothatspecifictype. Ourapproachbringsseveral orChain-of-Thoughtsettings,TikZandGraphviz
benefits: (i)annotationcostisgreatlyreduceddue show at least 17% better performance than SVG.
toGPT-4V’slowAPIcost;(ii)GPT-4Visoneof Asareminder,TikZandGraphvizarefundamen-
5SVG TikZ Graphviz
Prompting Category Color Usage Avg Concept Counting Relation Avg Domain Layout Relation Avg
Zero-Shot 41.2 72.8 50.6 54.9 89.4 77.5 76.0 81.0 84.6 82.3 86.6 84.5
In-ContextLearning 49.4 74.1 61.4 61.6 89.4 75.0 77.0 80.5 86.0 82.3 87.8 85.4
ChainofThought 49.2 77.5 53.4 60.0 89.3 77.3 78.4 81.7 86.3 82.9 86.0 85.1
Table3: EvaluationofVGQAacrossdiversevectorgraphicsformatsforGPT-4. ItcanbeseenthatGPT-4performs
betteronhigher-levelsemanticswithTikZandGraphvizthanonlower-levelSVGs. Itcanalsobeseenthatusing
specificpromptingtechniquesimprovesperformance,especiallywithChainofThoughtprompting.
Format Ground Truth Caption GPT 3.5 GPT 4
The image shows a simple black outline of a heart
shape on a white background. The heart outline is
symmetrical with a smooth, curved top that tapers
SVG down to a sharp point at the bottom. ……
This is a simple, flat design illustration featuring two
cartoon characters sitting behind a brown desk or
table. The character on the left is wearing a dark suit
with a blue tie and has brown hair, ……
The image shows a schematic representation of a two-
dimensional surface with a dumbbell-like shape. The
surface is symmetrical, with two bulbous ends
connected by a narrower middle section. ……
TikZ
You are looking at a digital image of a stylized yellow
face with a simple, cartoon-like appearance. The face is
circular with a solid yellow background. It has two
large, round eyes with black outlines; ……
The image shows a simple flowchart or diagram with
five oval shapes connected by arrows, representing a
process or a set of relationships. At the center, there is
an oval labeled "ssgtest," which appears ……
Graphviz
The image depicts a flowchart or diagram with four
rectangular blocks, each representing a step or
component in a process. The blocks are connected by
arrows indicating the flow of data or control. ……
Figure6: Examplesofgeneratedvectorgraphics. Thegroundtruthimagesarerenderedbyvectorgraphicscode
directlyfromInternet. ThecaptionsaregeneratedbyGPT-4V,Theimagesontherightsidearerenderedbyvector
graphicscodegeneratedbyGPT-3.5orGPT-4.
tallydifferentfromSVGintermsofthesemantic againdemonstratesthatGPT-4showsinferiorper-
levels, as SVG is composed of geometry primi- formanceinlow-levelvectorgraphicstasks,espe-
tiveswhileTikZandGraphvizcontainhigh-level ciallyontasksrelatedtoreasoning.
semanticssuchas“above",“below",explicitrepre-
sentationofnodesandedges,etc. 3.4 VGen: VectorGraphicsGeneration
ChainofThought(CoT)andIn-ContextLearn- Benchmark
ing(ICL)showsomeperformanceimprovements
Tasks WeintroduceVGen,abenchmarkevaluat-
for some tasks, but not significant. CoT and
ing LLMs’ vector-graphics generation capability.
ICLshow∼7%performanceboostforSVGwhich
Weusetexttovector-graphics(T2VG)generation
ownslowestperformanceamongthreeformats. Yet
totestanLLM’sabilitytogeneratevectorgraphics
CoTandICLshownobenefitsforTikZandlimited
codeconditionedonatextprompt.
improvementsforGraphviz,whereGPT-4already
obtains∼83%accuracyunderTikZandGraphviz. Benchmark Creation and Evaluation Again
Differentvector-graphicformatsshowdiverse weevaluateonthreevectorgraphicsformats: SVG,
behaviorsuponquestiontypes. ForSVG,GPT- TikZ and Graphviz. First, we obtain captions for
4 struggles at high-level questions and receives each vector graphics image by leveraging GPT-
∼50%accuracyoncategoryandreasoningtypes, 4V (OpenAI, 2023b) over its rasterized image.
whileinTikZandGraphviz,GPT-4showsdecent Then we prompt the LLM to generate the vector
performance across all types of questions. This graphicscodecorrespondingtothecaption.
6SVG TikZ Graphviz els, including GPT-4, GPT-3.5, Llama-3-70B-
Instruct(Meta,2024)andLlama-3-8B-Instruct. Re-
#ofVG-captionspairs 2000 2000 1845
sultsareshowninTable7. Theresultsshowthat
Table4: StatisticsofVGenonthreeVGformats. GPT-4hasthebestVGunderstandingabilityover
vectorgraphicsamongthosemodelswhileLlama-
3-70BshowsbetterperformancethanGPT-3.5.
Finally, we map the generated vector graphics
into rasterzied images, then use CLIP Score and
Impact of Vector Graphics Sequence Length
FréchetInceptionDistance(FID)Scoretoevaluate
We next study the influence of the length of the
thequalityofthegeneratedvectorgraphics.
vectorgraphicsonvectorgraphicsunderstanding.
We use CLIP Score to measure the similarity
Results for GPT-4 are shown in Table 8, where
betweeneachgeneratedvectorgraphicsanditsas-
GPT-4showsconsistentperformanceacrossdiffer-
sociated caption. We utilize Long-CLIP (Zhang
ent length groups. Specifically, low-level vector
etal.,2024)insteadofthevanillaCLIP(Radford
graphicsformatsuchasSVGismostsensitiveto
et al., 2021) since our detailed captions are often
thelength. Whenthelengthincreases, theunder-
longerthanCLIP’smaximumcontextlengthof77.
standingperformanceonSVGdecreasessteadily,
FIDisutilizedtoevaluatethedistributiongapbe-
whiletheunderstandingperformanceonotherhigh
tween the original vector graphics and generated
level format remains stable. Another noticeable
ones. For both metrics, we use the score of our
findingisthatquestionsrequiringcomplexreason-
groundtruthsastheupperboundtoreflectthequal-
ing,suchasUsageinSVGorRelationinGraphviz,
ityofthegeneratedimages. Theoverallpipelineis
suffermorefromtheincreasingsequencelength.
showninFigure5.
LLM SVG TikZ Graphviz CanLLMsReasonoverVectorGraphics? The
Ground-Truth 25.61 24.63 23.67 reasoningprocessofGPT-4undertheCoTsetting
GPT-4 23.97 24.42 24.50
isshowninFigure7. ResultsshowthatGPT-4can
GPT-3.5-Turbo 22.88 24.21 23.88
detectthekeyinformationoverthosesamples,such
as"twolarge,similarshapesthatcouldrepresent
Table 5: CLIP score between captions and rasterized
imagesfromthegeneratedvectorgraphics. theeyepieces...",forcorrectreasoning. Weinclude
thefullconversationinAppendix6.3.
LLM SVG TikZ Graphviz
4 Conclusion
GPT-4 44.81 39.38 77.03
GPT-3.5-Turbo 60.67 17.49 88.20
Our study unveils new insights into the capabili-
Table6:TheFIDscorebetweenthegroundtruthimages tiesofLLMsinunderstandingandgeneratingvec-
andthegeneratedimages. Lowerisbetter. tor graphics. We discovered that LLMs demon-
stratedecentvectorgraphicsunderstandinginTikZ,
Results CLIPandFIDscoreundereachVGtype Graphviz,andSVGs,withaparticularstrengthin
isshowninTable5andTable6,respectively. Qual- understanding vector graphics code with higher-
itativeexamplesareshowninFigure6. levelsemantics. WealsofoundthatLLMsoftenex-
Both GPT-3.5 and GPT-4 show strong vector hibitstrongvectorgraphicsgenerationcapabilities.
graphicsgenerationcapability. BothLLMsshow Interestingly,advancedpromptingtechniquescan
similarCLIPscoreasthegroundtruth. Resultson significantly improve performance for low-level
FID score also support this claim. GPT-4 shows formats such as SVG, and while GPT-4 had the
better performance than GPT-3.5 on CLIP score. strongest performance, open-source models like
Qualitativeexamplesincludingtheheartshapeand Llama-3-70Bshowcompetitiveperformance. Our
flowchartgenerationalsodemonstratethepromis- work lays a groundwork for future studies into
ingcapabilityofVGgenerationusingLLMs. LLMs’ vector graphics understanding and gener-
ation benchmarking, and we hope it will inspire
3.5 InDepthAnalysis
further efforts to enhance these capabilities. We
ImpactofDifferentLLMs Wenextperformex- willreleaseourbenchmarkdatasetandevaluation
periments over a variety of large language mod- pipeline.
7SVG TikZ Graphviz
Model Category Color Usage Avg Concept Counting Relation Avg Domain Layout Relation Avg
GPT-4 41.2 72.8 50.6 54.9 89.4 77.5 76.0 81.0 84.6 82.3 86.6 84.5
GPT-3.5-Turbo 33.4 50.5 47.1 43.7 76.7 56.8 54.4 62.6 83.6 62.5 63.5 69.9
Llama-3-70B 46.3 58.7 55.3 53.4 78.5 68.2 66.7 71.1 72.8 61.4 74.4 69.5
Llama-3-8B 32.3 39.8 48.0 40.0 64.6 53.0 45.9 54.5 68.0 52.5 55.8 58.8
Table7: EvaluationofVGQAacrossdiversevectorgraphicsformatsfordifferentLLMsinthezero-shotsetting.
SVG TikZ Graphviz
Length Category Color Usage Avg Concept Counting Relation Avg Domain Layout Relation Avg
1-1000 59.3 72.2 65.5 65.7 83.2 79.8 69.9 77.6 78.4 84.1 90.4 84.3
1000-2000 47.0 75.3 60.8 61.0 88.0 83.8 79.7 83.8 90.4 77.6 87.9 85.3
2000-3000 46.8 76.4 50.6 57.9 85.5 66.7 80.0 77.4 96.2 80.0 77.8 84.7
3000-4000 51.5 64.1 54.1 56.6 89.7 69.2 70.0 76.3 90.5 82.4 75.0 82.6
>4000 48.9 70.1 52.5 57.2 95.8 55.0 81.2 77.3 87.0 82.5 72.2 80.6
Table8: VGQAperformanceunderdifferentlengthsofvectorgraphicsforGPT-4withzero-shotprompting. GPT-4
performsbetteronsomelengthsthanothers. Forinstance,intheGraphvizDomainquestiontype,GPT-4performs
atanoutstanding96%accuracyonthe2k-3krangewhileshowingmostsubparperformanceonthe<1krange.
<svgversion=\“1.1\” /svg\“ \\begin{document}\n\n\\begin{t \"digraph G{\n ordering=out;\n
<path d=\”m485.729,236.892c- ikzpicture}[auto,scale=1.5]\n\\b {rank=same;\"1\";\"2\"};\n \"1\"-
0.21-0.313-0.437-0.618-0.699- egin{scope}\n\\draw[line >\"2\";\n{rank=same;\"4\";\"5\"}
0.904l-.718-.783c-1.699-1.99- width=2.5 pt] (0,0) to (2,0); (0,0) ;\n \"4\"->\"5\";\n \"7\"->\"5\";\n
3.467-3.92-5.3-5.786l-… to (0,1); (0,1) to (2,1);… \"7\"->\"4\";\n \"6\"->\"1\...
What object is represented by What is the mathematical What is the direction of the flow
this SVG image? concept illustrated? in the graph?
A: Glasses A: Probability Distributions A: Left to right
B: Telescope B: Algebraic Equations B: Right to left
C: Binoculars C: Combinatorial Configs C: Top to bottom
D: Camera D: Graph Theory D: Bottom to top
Please think step by step. Please think step by step. Please think step by step.
The SVG code provided describes The TikZcode illustrates points In the absence of a `rankdir`
an image with two large, similar connected by lines, potentially attribute or any other layout-
shapes that could represent the forming a graph. The thicker lines related code, the default layout in
eyepieces of binoculars… may indicate relationships Graphvizis indeed from top to
Therefore, C: Binoculars is the between points... Hence, D: bottom… That’s why the direction
correct answer. Graph Theory is the best answer. of the flow is top to bottom.
(i) SVG (ii) TikZ (iii) Graphviz
Figure7: ExamplesofpromptingGPT-4usingChain-of-ThoughtwithdifferenttypesofvectorgraphicsinVGQA.
WeonlyshowGPT-4thevectorgraphicscode,butweincludetherasterizedimageshereforthesakeofthereaders.
5 Limitations ourstudy.
We acknowledge that one cannot systematically
Acknowledgements
evaluate the behavior of the closed-source mod-
elsweemployed, namelyGPT-4, GPT-35-Turbo, This work was supported in part by NSF CA-
andGPT-4V.Besides,moreevaluationsonrecent REER IIS2150012, Adobe Data Science award,
LLMscanbeconducted,whichcanprovidemore MicrosoftAccelerateFoundationModelsResearch
supportingexperimentsonLLMs’behavioronvec- Program,andInstituteofInformation&communi-
torgraphicsunderstandingandgeneration. cationsTechnologyPlanning&Evaluation(IITP)
Furthermore, recent works propose more grants funded by the Korea government (MSIT)
prompting techniques such as Tree of Thoughts (No. 2022-0-00871, Development of AI Auton-
(ToT) (Yao et al., 2024) and Everything of omy and Knowledge Enhancement for AI Agent
Thoughts(XoT)(Dingetal.,2023). Incorporating Collaboration)and(No. RS-2022-00187238,De-
thesepromptingtechniquescouldfurtherenhance velopmentofLargeKoreanLanguageModelTech-
8nologyforEfficientPre-training). Everything of thoughts: Defying the law of pen-
rosetriangleforthoughtgeneration. arXivpreprint
arXiv:2311.04254.
References
EmdenRGansner.2009. Drawinggraphswithgraphviz.
JoshAchiam,StevenAdler,SandhiniAgarwal,Lama Technicalreport,AT&TBellLaboratories,Murray,
Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Tech.Rep,Tech.Rep.
DiogoAlmeida,JankoAltenschmidt,SamAltman,
ShyamalAnadkat,etal.2023. Gpt-4technicalreport. Nader Gharachorloo, SatishGupta, RobertF Sproull,
arXivpreprintarXiv:2303.08774. andIvanESutherland.1989. Acharacterizationof
tenrasterizationtechniques. InProceedingsofthe
StanislawAntol,AishwaryaAgrawal,JiasenLu,Mar- 16thannualconferenceonComputergraphicsand
garetMitchell,DhruvBatra,CLawrenceZitnick,and interactivetechniques,pages355–368.
DeviParikh.2015. Vqa: Visualquestionanswering.
InProceedingsoftheIEEEinternationalconference Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
oncomputervision,pages2425–2433. BingXu,DavidWarde-Farley,SherjilOzair,Aaron
Courville, and Yoshua Bengio. 2020. Generative
Jonas Belouadi, Anne Lauscher, and Steffen Eger. adversarialnetworks. CommunicationsoftheACM,
2023. Automatikz: Text-guided synthesis of sci- 63(11):139–144.
entific vector graphics with tikz. arXiv preprint
arXiv:2310.00367. David Ha and Douglas Eck. 2017. A neural rep-
resentation of sketch drawings. arXiv preprint
Tom Brown, Benjamin Mann, Nick Ryder, Melanie arXiv:1704.03477.
Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind
Neelakantan,PranavShyam,GirishSastry,Amanda JackHessel,AriHoltzman,MaxwellForbes,RonanLe
Askell, Sandhini Agarwal, Ariel Herbert-Voss, Bras,andYejinChoi.2021. Clipscore: Areference-
Gretchen Krueger, Tom Henighan, Rewon Child, freeevaluationmetricforimagecaptioning. arXiv
AdityaRamesh,DanielZiegler,JeffreyWu,Clemens preprintarXiv:2104.08718.
Winter, Chris Hesse, Mark Chen, Eric Sigler, Ma-
teusz Litwin, Scott Gray, Benjamin Chess, Jack MartinHeusel,HubertRamsauer,ThomasUnterthiner,
Clark, ChristopherBerner, SamMcCandlish, Alec BernhardNessler,andSeppHochreiter.2017. Gans
Radford,IlyaSutskever,andDarioAmodei.2020a. trainedbyatwotime-scaleupdateruleconvergetoa
Languagemodelsarefew-shotlearners. InNeurIPS. localnashequilibrium. Advancesinneuralinforma-
tionprocessingsystems,30.
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind JonathanHo,AjayJain,andPieterAbbeel.2020. De-
Neelakantan,PranavShyam,GirishSastry,Amanda noising diffusion probabilistic models. Advances
Askell,etal.2020b. Languagemodelsarefew-shot inneuralinformationprocessingsystems,33:6840–
learners. NeurIPS,33:1877–1901. 6851.
Sébastien Bubeck, Varun Chandrasekaran, Ronen El- XinyangJiang,LuLiu,CaihuaShan,YifeiShen,Xu-
dan, Johannes Gehrke, Eric Horvitz, Ece Kamar, anyiDong,andDongshengLi.2021. Recognizing
Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund- vector graphics without rasterization. Advances in
berg,etal.2023. Sparksofartificialgeneralintelli- NeuralInformationProcessingSystems,34:24569–
gence: Earlyexperimentswithgpt-4. arXivpreprint 24580.
arXiv:2303.12712.
Diederik P Kingma and Max Welling. 2013. Auto-
MuCai, ZeyiHuang, YuhengLi, HaohanWang, and encoding variational bayes. arXiv preprint
YongJaeLee.2023. Leveraginglargelanguagemod- arXiv:1312.6114.
elsforscalablevectorgraphics-drivenimageunder-
standing. arXivpreprintarXiv:2306.06094. HaotianLiu,ChunyuanLi,QingyangWu,andYongJae
Lee.2024. Visualinstructiontuning. Advancesin
AlexandreCarlier,MartinDanelljan,AlexandreAlahi, neuralinformationprocessingsystems,36.
andRaduTimofte.2020. Deepsvg: Ahierarchical
generative network for vector graphics animation. XuMa, YuqianZhou, XingqianXu, BinSun, Valerii
AdvancesinNeuralInformationProcessingSystems, Filev,NikitaOrlov,YunFu,andHumphreyShi.2022.
33:16351–16361. Towardslayer-wiseimagevectorization. InProceed-
ingsoftheIEEE/CVFConferenceonComputerVi-
JamesRichardDiebel.2008. BayesianImageVector- sionandPatternRecognition,pages16314–16323.
ization: theprobabilisticinversionofvectorimage
rasterization. StanfordUniversity. Andrew Mertz and William Slough. 2007. Graphics
withtikz. ThePracTEXJournal,1:1–22.
RuomengDing,ChaoyunZhang,LuWang,YongXu,
Minghua Ma, Wei Zhang, Si Qin, Saravan Raj- Meta.2024. Llama-3. https://ai.meta.com/blog/
mohan, Qingwei Lin, and Dongmei Zhang. 2023. meta-llama-3/.
9OpenAI. 2023a. Chatgpt. https://openai.com/ RenruiZhang,JiamingHan,ChrisLiu,PengGao,Ao-
blog/chatgpt/. junZhou, XiangfeiHu, ShilinYan, PanLu, Hong-
shengLi,andYuQiao.2023. Llama-adapter: Effi-
OpenAI.2023b. Gpt-4technicalreport. cientfine-tuningoflanguagemodelswithzero-init
attention. arXivpreprintarXiv:2303.16199.
A.Quint.2003. Scalablevectorgraphics. IEEEMulti-
Media,10(3):99–102. 6 Appendix
AlecRadford,JongWookKim,ChrisHallacy,Aditya
6.1 Thespecificpromptweused
Ramesh,GabrielGoh,SandhiniAgarwal,GirishSas-
try, Amanda Askell, Pamela Mishkin, Jack Clark, 6.1.1 Promptsusedtobuildthedataset
etal.2021. Learningtransferablevisualmodelsfrom
naturallanguagesupervision. InInternationalconfer- QuestionGeneration Systemprompt: Thesys-
enceonmachinelearning,pages8748–8763.PMLR. tem prompts used to generate questions are dif-
ferent for different types of vector graphics and
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott
different types of questions. See the code in sup-
Gray,ChelseaVoss,AlecRadford,MarkChen,and
plementalmaterialfordetails.
IlyaSutskever.2021. Zero-shottext-to-imagegener-
ation. InInternationalconferenceonmachinelearn- Userprompt: Thecaptionofthisimageis{cap-
ing,pages8821–8831.Pmlr. tion},generatethejsonaccordingtotheinstruction.
<IMAGE>
JuanARodriguez,ShubhamAgarwal,IssamHLaradji,
Pau Rodriguez, David Vazquez, Christopher Pal,
CaptionGeneration Systemprompt: Generate
and Marco Pedersoli. 2023. Starvector: Generat-
ingscalablevectorgraphicscodefromimages. arXiv adetailedcaptionforthegivenimage. Thereader
preprintarXiv:2312.11556. of your caption should be able to replicate this
picture.
ZhenhailongWang,JoyHsu,XingyaoWang,Kuan-Hao
Userprompt: <IMAGE>
Huang,ManlingLi,JiajunWu,andHengJi.2024a.
Text-basedreasoningaboutvectorgraphics. Preprint,
6.1.2 Promptsusedtoevaluatethemodels’s
arXiv:2404.06479.
understandingability
ZhenhailongWang,JoyHsu,XingyaoWang,Kuan-Hao
Zero-shot Systemprompt: Iwillpresenta{for-
Huang,ManlingLi,JiajunWu,andHengJi.2024b.
mat}code. Pleaseanswermyquestionsonlybased
Text-basedreasoningaboutvectorgraphics. arXiv
preprintarXiv:2404.06479. on code. Answer and only answer the letter cor-
respondingtothecorrectoption. Donotaddany
JasonWei,XuezhiWang,DaleSchuurmans,Maarten
additionalcommentinyourresponse
Bosma,FeiXia,EdChi,QuocVLe,DennyZhou,
User prompt: "{code}". Given this image, an-
etal.2022. Chain-of-thoughtpromptingelicitsrea-
soninginlargelanguagemodels. Advancesinneural swer{question}. Optionsare{options}
informationprocessingsystems,35:24824–24837.
Few-shot Systemprompt: I will presenta {for-
RonghuanWu,WanchaoSu,KedeMa,andJingLiao. mat}code. Pleaseanswermyquestionsonlybased
2023. Iconshop: Text-guidedvectoriconsynthesis
on code. Answer and only answer the letter cor-
withautoregressivetransformers. ACMTransactions
respondingtothecorrectoption. Donotaddany
onGraphics(TOG),42(6):1–14.
additional comment in your response. For your
Tian Xia, Binbin Liao, and Yizhou Yu. 2009. Patch- reference,Iwillgiveyousomeexamples.
basedimagevectorizationwithautomaticcurvilinear
User prompt: This is an example, the code is:
featurealignment. ACMTransactionsonGraphics
{code}
(TOG),28(5):1–10.
User prompt: Given this image, answer
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, {few_shot_sample_question}. Options are
TomGriffiths,YuanCao,andKarthikNarasimhan.
{few_shot_sample_options}
2024. Treeofthoughts: Deliberateproblemsolving
Simulated assistant prompt:
with large language models. Advances in Neural
InformationProcessingSystems,36. {few_shot_sample_answer}
Repeat the last three prompts for three times,
Beichen Zhang, Pan Zhang, Xiaoyi Dong, Yuhang
eachtimepassadifferentsamples.
Zang, and Jiaqi Wang. 2024. Long-clip: Unlock-
User prompt: "{code}". Given this image, an-
ing the long-text capability of clip. arXiv preprint
arXiv:2403.15378. swer{question}. Optionsare{options}
10(a) SVG (b) TikZ (b) Graphviz
Figure8: ThedistributionofvectorgraphicslengthinVGBench. X-axisdenotesthestringlengthofvectorgraphics
filesineachvectorgrapicsformat.
I will present an SVG code. I will present a TikZcode. I will present a Graphvizcode.
Answer only based on code. Answer only based on code. Answer only based on code.
Please consider step by step. Please consider step by step. Please consider step by step.
<svgversion=\“1.1\” /svg\“ <path \\begin{document}\n\n\\begin{tikz \"digraph G{\n ordering=out;\n
d=\”m485.729,236.892c-0.21- picture}[auto,scale=1.5]\n\\begin{ {rank=same;\"1\";\"2\"};\n \"1\"-
0.313-0.437-0.618-0.699-0.904l- scope}\n\\draw[line width=2.5 pt] >\"2\";\n{rank=same;\"4\";\"5\"};\n
.718-.783c-1.699-1.99-3.467-3.92- (0,0) to (2,0); (0,0) to (0,1); (0,1) to \"4\"->\"5\";\n \"7\"->\"5\";\n \"7\"-
5.3-5.786l-… (2,1);… >\"4\";\n \"6\"->\"1\...
What object is represented by this What is the major mathematical What is the direction of the flow in
SVG image? concept illustrated? the graph?
A: Glasses A: Probability Distributions A: Left to right
B: Telescope B: Algebraic Equations B: Right to left
C: Binoculars C: Combinatorial Configurations C: Top to bottom
D: Camera D: Graph Theory D: Bottom to top
Consider each option individually. Consider each option individually. Consider each option individually.
Carefully consider if A is correct. Carefully consider if A is correct. Carefully consider if A is correct.
The code suggests a pair of The given TikZcode does not By default, Graphviz's'dot' engine
objects that are similar and depict probability distributions. arranges directed graphs from top
connected, which is consistent There are no explicit references to to bottom. To specify a bottom-to-
with the structure of glasses. probabilities, random variables, or top flow, the code needs to
Therefore, A is potentially correct. statistics. A is incorrect. include rankdir=LR. A is incorrect.
Carefully consider if B is correct. Carefully consider if B is correct. Carefully consider if B is correct.
The code includes similar shapes The code includes some text that By default, Graphviz's'dot' engine
and symmetrical elements, which could be interpreted as algebraic arranges directed graphs from top
does not align with the singular, expressions, yet we can’t claim to bottom. To specify a bottom-to-
elongated structure of a that this is the major concept top flow, the code needs to
telescope. B is incorrect. without additional context. include rankdir=RL. B is incorrect.
Carefully consider if C is correct. Carefully consider if C is correct. Carefully consider if C is correct.
The SVG code provided describes In the code there is no explicit In the absence of a `rankdir`
an image with two large, similar indication of counting, attribute or any other layout-
shapes that could represent the permutations, combinations, or related code, the default layout in
eyepieces of binoculars… other typical combinatorial Graphvizis indeed from top to
Therefore, C is potentially correct. concepts… Hence, C is incorrect. bottom… That’s why C is correct.
Carefully consider if D is correct. Carefully consider if D is correct. Carefully consider if D is correct.
The two symmetrical shapes do The TikZcode illustrates points By default, Graphviz's'dot' engine
not align with the structure of a connected by lines, potentially arranges directed graphs from top
camera, with a single, forming a graph. The thicker lines to bottom. To specify a bottom-to-
asymmetrical shape… Therefore, may indicate relationships top flow, the code needs to
D is incorrect. between points... D is correct. include rankdir=BT. D is incorrect.
Which one do you think is the best? Which one do you think is the best? Which one do you think is the best?
C. D. C.
(i) SVG
(ii) TikZ (iii) Graphviz
Figure9:WeincludethefullconversationwithGPT-4asindicatedinFigure7. Weaskthemodeltoconsiderifeach
optioniscorrectindividually,thenaskanotherGPT-4modeltojudgeifthereasoningmatchesthecorrectanswer.
11Zero-shot-cot System prompt: I will present a 6.4 Llamavariantsusedinthispaper
{format} code. Please answer my questions only
We evaluated Llama’s variants, Llama-3-8B-
basedoncode. Pleaseconsiderthequestionstep Instruct-262k3andLlama-3-70B-Instruct-Gradient-
bystep. 262k4 in this paper because they have extended
Userprompt: {code} contextlength.
Userprompt: Giventhisimage,thequestionis
6.5 Humanfiltering
{question}. Optionsare{options}. Donotanswer
directly,considereachoptionindividually. Theauthorsofthisstudy,proficientinEnglishwith
Userprompt: CarefullyconsideriftheoptionA extensive research experience in vision-language
iscorrect learning,performthevectorgraphicsQAfiltering.
Waitforthelargelanguagemodel’sreponseand
6.6 ProgramsandDataRelease
additsresponsetothecontext.
Ourcodeanddataisincludedinthesupplementary
Userprompt: CarefullyconsideriftheoptionB
materials.
iscorrect
Waitforthelargelanguagemodel’sreponseand
additsresponsetothecontext.
Userprompt: CarefullyconsideriftheoptionC
iscorrect
Waitforthelargelanguagemodel’sreponseand
additsresponsetothecontext.
Userprompt: CarefullyconsideriftheoptionD
iscorrect
Waitforthelargelanguagemodel’sreponseand
additsresponsetothecontext.
Userprompt: Whichoptionisthebest? Answer
and only answer the letter corresponding to the
correctoption. Donotaddanyadditionalcomment
inyourresponse
6.1.3 Promptsusedtoevaluatemodels’
generationability
Systemprompt: Generatea{format}basedonthe
captionbelow. Youshouldoutputthecompilable
codewithoutanyadditionalinformation.
Userprompt: {caption}
6.2 Datadistribution
WeincludethedistributionofVGQAgroupedby
eachvectorgraphiccategoryinFigure8, eachin
itself grouped by the specific question categories
weassigned.
6.3 Detailedexamplesforreasoning
We include the full version of the three example
conversations previously put in Figure 7 now in
Figure 9. The three conversations show how we
only input the vector graphics code, exhibit the
3https://huggingface.co/gradientai/Llama-3-8B-Instruct-
262k
question,askthemodeltoconsidereachquestion
4https://huggingface.co/gradientai/Llama-3-70B-Instruct-
carefully,andfinallymakeitsbestchoice. Gradient-262k
12