XEQ Scale for Evaluating XAI Experience Quality
Grounded in Psychometric Theory
AnjanaWijekoona,NirmalieWiratungaa,DavidCorsara,KyleMartina,*,IkechukwuNkisi-Orjia,
BelenDíaz-Agudob andDerekBridgec
aRobertGordonUniversity,Aberdeen,Scotland
aUniversidadComplutensedeMadrid,Spain
aUniversityCollegeCork,Ireland
ORCID(AnjanaWijekoon): https://orcid.org/0000-0003-3848-3100,ORCID(NirmalieWiratunga):
https://orcid.org/0000-0003-4040-2496,ORCID(DavidCorsar): https://orcid.org/0000-0001-7059-4594,ORCID
(KyleMartin): https://orcid.org/0000-0003-0941-3111,ORCID(IkechukwuNkisi-Orji):
https://orcid.org/0000-0001-9734-9978,ORCID(BelenDíaz-Agudo): https://orcid.org/0000-0003-2818-027X,
ORCID(DerekBridge): https://orcid.org/0000-0002-8720-3876
Abstract. Explainable Artificial Intelligence (XAI) aims to im- inrecentliterature,theevaluationoftheseinteractionsremainsakey
provethetransparencyofautonomousdecision-makingthroughex- researchchallenge.Currentworksprimarilytargetthedevelopment
planations.Recentliteraturehasemphasisedusers’needforholistic ofobjectivemetricsforsingle-shottechniques[24,28],emphasising
“multi-shot”explanationsandtheabilitytopersonalisetheirengage- theneedforreproduciblebenchmarksonpublicdatasets[16].Such
mentwithXAIsystems.Werefertothisuser-centredinteractionas metricsaresystem-centredandmodel-agnostic,givingtheadvantage
anXAIExperience.DespiteadvancesincreatingXAIexperiences, of generalisability. However, objective metrics fail to acknowledge
evaluatingtheminauser-centeredmannerhasremainedchallenging. therequirementsofdifferentstakeholdergroups.Asatisfactoryex-
To address this, we introduce the XAI Experience Quality (XEQ) planation is reliant on the recipient’s expertise within that domain
Scale (pronounced "Seek" Scale), for evaluating the user-centered andofAIingeneral[20].Subjectivemetrics,suchasthosedescribed
qualityofXAIexperiences.Furthermore,XEQquantifiesthequality in[10,11],allowanevaluationwhichispersonalisedtotheindivid-
of experiences across four evaluation dimensions: learning, utility, ual and domain. However, existing subjective evaluations lack the
fulfilmentandengagement.Thesecontributionsextendthestate-of- capacitytomeasuretheinteractiveprocessthatunderpinsmulti-shot
the-artofXAIevaluation,movingbeyondtheone-dimensionalmet- explanationsandhowtheyimpactuserexperience.
ricsfrequentlydevelopedtoassesssingle-shotexplanations.Inthis We address this challenge by introducing the XAI Experience
paper,wepresenttheXEQscaledevelopmentandvalidationprocess, Quality(XEQ)Scale(pronounced:"seek"Scale).WedefineanXAI
includingcontentvalidationwithXAIexpertsaswellasdiscriminant Experience as the user-centred process of a stakeholder interacting
andconstructvalidationthroughalarge-scalepilotstudy.Outpilot withanXAIsystemtogainknowledgeand/orimprovecomprehen-
studyresultsofferstrongevidencethatestablishestheXEQScaleas sion.XAIExperienceQuality(XEQ)isdefinedastheextenttowhich
acomprehensiveframeworkforevaluatinguser-centredXAIexperi- astakeholder’sexplanationneedsaresatisfiedbytheirXAIExperi-
ences. ence.Aglossaryofallrelatedterminologyusedthroughoutthispa-
perisincludedinTable1.Specifically,weasktheresearchquestion:
“HowtoevaluateanXAIexperience,incontrasttoassessingsingle-
1 Introduction
shot (non-interactive) explanations?”. To address this, we follow a
formalpsychometricscaledevelopmentprocess[3]andoutlinethe
ExplainableArtificialIntelligence(XAI)describesarangeoftech-
followingobjectives:
niques to elucidate autonomous decision-making and the data that
informed that AI system [19, 12, 2]. Each technique typically pro- 1. conductaliteraturereviewtocompileacollectionofXAIevalua-
videsexplanationsthatfocusonaspecificaspectofthesystemand tionquestionnaireitems;
its decisions. Accordingly, the utility of employing multiple tech- 2. conductacontentvaliditystudywithXAIexpertstodevelopthe
niques for a holistic explanation of a system becomes increasingly XEQscale;and
clear [2, 27]. The collection of explanations, provided by different 3. performapilotstudytorefineandvalidatetheXEQscaleforin-
techniquesanddescribingdifferentcomponentsofthesystem,forms ternalconsistency,constructanddiscriminantvalidity.
what we describe as “multi-shot” explanations. Previous work has
demonstratedtheeffectivenessofdeliveringmulti-shotexplanations Therestofthispaperexpandsoneachobjective.Wediscussre-
usinggraphicaluserinterfaces[2]andconversation[18,27]. latedworkinSection2.Section3presentskeypreviouspublications
Whiletheutilityofuser-centredinteractiveexplanationsisevident andthecreationoftheinitialitemsbank.TheContentValiditystudy
detailsandresultsarepresentedinSection4followedbySection5
∗CorrespondingAuthor.Email:k.martin3@rgu.ac.uk presentingpilotstudydetailsfortherefinementandvalidationofthe
4202
luJ
51
]IA.sc[
1v26601.7042:viXraTerm Definition Table1. Glossary
XAISystem Anautomateddecision-makingsystemthatisdesignedanddevelopedtoprovideinformationaboutitsreasoning.
Stakeholder AnindividualorgroupwithavestedinterestintheXAIsystem.Stakeholdersareadiversegroup,encompassingsystem
designers and developers, who hold an interest in the system’s technical functionality, the end consumers relying on its
decisions,andregulatoryauthoritiesresponsibleforensuringfairandethicaluse.
XAIExperience(XE) Auser-centredprocessofastakeholderinteractingwithanXAIsystemtogainknowledgeand/orimprovecomprehension.
XEQuality(XEQ) Theextenttowhichastakeholder’sexplanationneedsaresatisfiedbytheirXE.
XEQScale.KeyimplicationsoftheXEQScalearediscussedinSec- 3.2 Findings:EvaluationDimensionsandMetrics
tion6.Finally,weofferconclusionsinSection7.
Hoffmanetal.[9]areoneoftheleadingcontributorsandtheirwork
has been widely utilised in many user-centred XAI research. They
2 RelatedWork conceptuallymodelledthe“processofexplaininginXAI”outlining
dimensionsandmetricsforevaluatingsingle-shotexplanationsfrom
Intheliterature,thereareseveralmethodologiesfordevelopingeval-
stakeholders’ perspectives. They considered six evaluation dimen-
uationmetricsorinstrumentsforuser-centredXAI.
sions:goodness,satisfaction,mentalmodel,curiosity,trustandper-
Hoffman et al. [9] employed Psychometric Theory to construct
formance,Foreachdimension,theyeithersystematicallydeveloped
theSatisfactionScale,evaluatingbothcontentvalidityanddiscrim-
anevaluationmetricorcritiquedmetricsavailableinliteratureoffer-
inant validity. A similar methodology was adopted in [17] to de-
ingacomprehensiveevaluationmethodologyforXAIpractitioners.
veloptheMadsen-Gregorhuman-machinetrustscale,relyingonpre-
SystemCausabilityScale[11]istheothermostprominentworkin
existingitemlistsfrompreviousscalesinconjunctionwithexpertin-
XAIevaluation.Wediscusseachscalebrieflybelow.
sights[21].Jianetal.[13]pursuedafactoranalysisapproachinvolv-
ingnon-expertuserstoformulateahuman-machinetrustscale.They
Hoffman’sGoodnessChecklist is utilised to objectively evaluate
compiled words and phrases associated with trust and its variants,
explanations with an independent XAI expert to improve the
organisingthembasedontheirrelevancetotrustanddistrust,which
“goodness”. It consists of 7 items answered by either selecting
werethenclusteredtoidentifyunderlyingfactorsandformulatecor-
’yes’or’no’.Itwasdevelopedbyreferringtoliteraturethatpro-
respondingstatements.Thismethodologyisparticularlysuitablein
poses“goodness”propertiesofexplanations.
caseswherenoprioritemsexistforinitialcompilation.Whilethese
HoffmanSatisfactionScale wasdesignedusingpsychometricthe-
methodologiesarerobusttoproducereliablescalestheyareresource
ory to evaluate the subjective “goodness” of explanations with
andknowledge-intensiveprocesses.
stakeholders. It consists of 8 items responded in a 5-step Likert
Amorefrequentapproachtoscaledevelopmentisderivingthem
Scale. It is viewed as the user-centred variant of the Goodness
fromexistingscalesinpsychologyresearch.Forinstance,theSystem
Checklist with many shared items. However, conversely, it has
CausabilityScale[11]drawsinspirationfromthewidelyusedSys-
been evaluated for content validity with XAI experts as well as
temUsabilityScale[4],whiletheHoffmanCuriosityChecklistorig-
constructanddiscriminantvalidityinpilotstudies.
inatesfromscalesdesignedtoassesshumancuriosity[9].Similarly,
HoffmanCuriosityChecklist isdesignedtoelicitstakeholderex-
theCahour-ForzyTrustScale[5]selectedquestionsfromresearchon
planationneeds,i.e.whichaspectsofthesystempiquetheircu-
human trust, and the Hoffman Trust Scale incorporates items from riosity.ThismetricconsistsofonequestionWhyhaveyouasked
previoustrustscales[5,13].Notably,thesederivedscaleswerenot foranexplanation?Checkallthatapply.andtheresponsesinform
evaluated for reliability or other desirable factors, they rely on the
thedesignandimplementationoftheXAIsystem.
qualityoftheoriginalscalesforvalidity.Inthispaper,weoptforthe
HoffmanTrustScale measuresthedevelopmentoftrustwhenex-
psychometrictheoryapproachtoestablishthecontent,constructand
ploring a system’s explainability. The authors derived this trust
discriminant validity of the resulting scale. While this approach is
scale by considering the overlaps and cross-use of scales from
resource-intensive,thecomplexityandthenoveltyoftheevaluation
trust scales in literature for measuring trust in autonomous sys-
tasknecessitatearigorousapproachtoscaledevelopment.
tems(notinthepresenceofexplainability,e.g.trustbetweenhu-
manandarobot)[13,1,25,5].
3 LiteratureReviewandInitialItemsBank SystemCausabilityScale measures the effectiveness, efficiency
Compilation andsatisfactionoftheexplainabilityprocessinsystemsinvolving
multi-shotexplanations[11].Derivedfromthewidely-usedSys-
This section presents the literature review findings that led to the temUsabilityScale[4],thisscalecomprises10itemsratedona
compilationoftheinitialitemsbankfortheXEQScale. 5-stepLikertscale.Notably,itincludesitemsthatmeasurestake-
holderengagement,addressingagapinpreviousscalesdesigned
3.1 Methodology forone-shotexplainabilitysettings.However,thevalidationofthe
scaleislimitedtoonesmall-scalepilotstudyinthemedicaldo-
Toscopetheexistingworkandformtheinitialitembank,wecon- main.
ductedatargetedliteraturereviewinthedomainofXAIevaluation
metrics. The reasoning for a targeted review instead of a system-
3.2.1 OtherDimensions
aticreviewistwofold:1)thepurposeofthereviewistoformthe
initialitembankwhichinvolvesindepthanalysisofselectedliter- Manyotherpublicationsemphasisedtheneedforuser-centredXAI
ature(depthoverbreadth);and2)literatureunderthistopicissig- evaluations and explored evaluation dimensions. Two other dimen-
nificantly limited. The initial findings highlighted that while many sions considered in [9] are mental model and performance con-
publicationsdiscussandemphasisetheimportanceofevaluationdi- cerningtaskcompletion.Hoffmanetal.recommendedelicitingthe
mensions(whatshouldbeorisevaluated),onlyafewactuallypro- mental model of stakeholders in think-aloud problem-solving and
poseandsystematicallydevelopmetricsforXAIevaluation. question-answeringsessions.Performanceismeasuredbyobservingthe change in productivity and change in system usage. The eval- Engagement: thequalityoftheinteractionbetweentheuserandthe
uation of these dimensions requires metrics beyond questionnaire- XAIsystem.
basedtechniques.Anotherdomain-agnosticsurveyfindsmanyover-
lapswithHoffmanetal.,defining4user-centredevaluationdimen- In the next sections, we describe the development, refinement and
sions: mental model, usefulness and satisfaction, trust and reliance validationoftheXEQScalefollowingPsychometricTheory[23].
andhuman-taskperformance[20].Zhouetal.,[29]summarisepre-
viousliterature,emphasisingthreesubjectivedimensions-trust,con- 4 XEQScaleDevelopment
fidenceandpreferencethatoverlapwithdimensionsidentifiedin[9].
ConverselytoHoffmanetal.,theyconsidertaskcompletiontobean Thissectionpresentsthedetailsandresultsofanexpertuserstudy
objectivedimensioninuser-centredXAIevaluation. performedtoestablishthecontentvalidityoftheXEQScale.
Carvalhoetal.,delineatecharacteristicsofahuman-friendlyex-
planationinthemedicaldomain,includingsomesubjectiveoruser- 4.1 StudyDesign
centred properties such as comprehensibility, novelty, and consis-
tencywithstakeholders’priorbeliefs[6].Notably,consistencywith Inthisstudy,participantsevaluatedtheinitialsetof32itemsusing
stakeholders’priorbeliefsalignswiththementalmodelfromHoff- the Content Validity Ratio (CVR) method [15]. The CVR method
man et al. [9], while novelty can influence stakeholder engage- isrecommendedforquantifyingthestrengthofpsychometricscale
ment[11].NautaandSeifert[22]recognise12propertiesofexplana- itemswithasmallgroupofexperts(5-10).
tionqualityforimageclassificationapplications.Theyidentifythree Atthestart,participantsarefamiliarisedwiththeterminologyand
user-centredproperties:context-howrelevanttheexplanationisto theyexplore3sampleXAIexperiences:1)astudentinteractingwith
the user; coherence - how accordant the explanation is with prior achatbotthatassistswithcourserecommendationsandsupport;2)
knowledgeandbeliefs;andcontrollability-howinteractiveandcon- a clinician interacting with the graphical interface of a radiograph
trollabletheexplanationis.Incomparisontootherliterature,control- fracturedetectionsystemforclinicaldecisionsupport;and3)areg-
labilityalignswithengagement[11]andcoherencealignswiththe ulatoryofficerinteractingwithalocalcouncilwelfarewebpageto
mentalmodel[9,6].Contextcanbeassociatedwithseveralproper- explore the fairness and biases with the recommender system used
tiessuchascuriosity,satisfaction,andpreference[9,29]. forpredictingapplicationoutcomes.Asampledialoguewiththein-
Thesefindingshighlightedthattherearemanyoverlapsbetween teractiveCourseAssistchatbotisshowninFigure1.Thisdialogue,
evaluationdimensionsidentifiedinrecentyears.However,wehigh- in its entirety, captures the explanation experience that we wish to
lighttwomaingapsinthiscurrentwork:1)thereisnoconsensusin evaluate. Next, participants are asked to rate the 32 items in terms
previousliteratureregardingtheapplicablemetricstomeasurethese oftheirrelevanceformeasuringXAIexperiencequalityusinga5-
evaluationdimensions;and2)themajorityoftheexistingdimensions pointLikertscale.TherelevancescalerangesfromNotRelevantat
andmetricsfocusonevaluatingindividualexplanations,nottheXAI AlltoExtremelyRelevant.Additionally,weincludedratingsrelated
experiences. toclarity,whichalsouseaLikertscalerangingfromNotClearatAll
toExtremelyClear.Thisclarityratingwasaddedtogetfeedbackon
howeasilytheitemsareunderstoodbytheparticipants.Finally,we
3.3 CompilingtheInitialItemBank
providedparticipantstheopportunitytosuggestrephrasingforitems
The initial item bank of 40 items included 7 from the Goodness theyfoundrelevantbutnotclear.
Checklist[10];8fromtheSatisfactionScale[10];8fromtheTrust
Scale [10]; and 10 from the System Causability Scale [11]. Seven 4.2 RecruitmentDetails
additional items were authored and included by the research team.
Theseweredesignedtocapturestakeholderviewsontheinteractive The participants of this study consisted of XAI experts both from
experiencewhichislessexplicitlyaddressedinpreviousliterature. academiaandtheindustry.38expertswerecontactedviaemailand
Thisinitiallistunderwentarigorousreviewandrevisionprocess, 13participatedinthestudy.The13participantsrepresentedadiverse
duringwhichtheresearchteameliminatedduplicates,consolidated setofinterestsinthehuman-centredXAIresearchdomainandare
similar items, and rephrased items to reflect the measurement of eitheractivelyconductingresearchorhavepublishedXAIresearch
XAIexperiencesinsteadofexplanations.Theresulting32statements outcomessince2020.ThestudywashostedontheJiscOnlineSur-
formedtheinitialXEQScale(includedinSupplementaryMaterial). veysplatformfor3weeksbetweenNovemberandDecember2023.
Responseforeachitemisrecordedona5-pointLikertscale,ranging
from“IStronglyAgree”to“IStronglyDisagree”. 4.3 Metrics
4.3.1 ContentValidity
3.3.1 EvaluationDimensions
TheContentValidityIndex(CVI)assessesitemvaliditybasedonre-
Wereviewedevaluationdimensionsfrompreviousliteratureandcon-
sponsestotherelevanceproperty.Lowerscoresindicateitemsthat
solidated XEQ items into four evaluation dimensions representing
may need modification or removal. Given scale S with M items
XAI experience quality: learning, utility, fulfillment, and engage-
where i indicates an item, ri denotes the response of participant j
ment. These dimensions are relevant to capturing personalised ex- j
toitemi.Foranalysis,eachresponse(ri)ismodifiedasfollows.
periencesforagivenstakeholder.Wedefinethemasfollows: j
(cid:40)
Learning: theextenttowhichtheexperiencedevelopsknowledge 1, ifri ∈[ExtremelyRelevantorSomewhatRelevant]
ri = j
orcompetence; j 0, otherwise
Utility: thecontributionoftheexperiencetowardstaskcompletion;
Fulfilment: the degree to which the experience supports the We calculate the following two forms of the Content Validity In-
achievementofXAIgoals;and dex(CVI)scores.Item-LevelCVI: measuresthevalidityofeachitemindependently; weredesignedonerelativelypositiveandonerelativelynegativeex-
thenumberofresponsesisN andtheexpectedscoreis≥0.78. perience. The two samples differ in the quality of the explanations
presentedtotheparticipantandtheresultingimpactontheoverallin-
I-CVI =
(cid:80)N j=1(r ji) teractionflow.Participantsaccessedallsamplesinvideoformat.Fig-
i N ure1presentsthestaticviewsofthetwosamplesoftheCourseAssist
Chatbot.AssistHubsamplesareincludedinSupplementaryMaterial.
Scale-LevelCVI: measures the overall scale validity using a) Av-
Thesesampleexperiencescreateacontrolledexperimentwherethe
eragemethodi.e.themeanItem-LevelCVIscorewheretheex-
discriminantpropertiesofthescalecanbevalidated.
pectedscoreis≥ 0.90;andb)UniversalAgreementmethodi.e.
First,theparticipantsexploretheXAIexperienceandtheyproceed
thepercentageofitemsexpertsalwaysfoundrelevantwiththeex-
torespondtotheXEQScale.Inaddition,theyarealsoqueriedabout
pectedvalueof≥0.80.
theclarityofitemswithinthescopeofthesampleexperience.Lastly,
(cid:80)M
(I-CVI )
participantscanofferfree-textfeedbackaboutthestudy.
S-CVI(a)= i=1 i
M
5.2 RecruitmentDetails
(cid:80)M
1
S-CVI(b)= i=1 [I-CVIi=1] Thisstudyenlisted203participants,comprisingundergraduatestu-
M
dents from the leading research institute and participants recruited
Here, once the average of the I-CVIs is calculated for all items fromtheProlific.coplatform.33studentsfromtheresearchinstitute
withS-CVI(a),S-CVI(b)countsthenumberofitemswithanI- and70ProlificparticipantswererecruitedfortheCourseAssistap-
CVIof1(indicatingcompleteagreementamongexpertsthatthe plicationwheretheinclusioncriteriawere:Currenteducationlevel-
itemisrelevant)anddividesthisbythetotalnumberofitems. Undergraduatedegree;Degreesubjects-Mathematicsandstatistics,
Information and Communication Technologies, Natural sciences;
and Year of study - 1st, 2nd, 3rd or 4th. 100 Prolific participants
4.4 Results
wererecruitedfortheAssistHubapplicationwiththefollowingin-
We refer to the first two columns of Table 2 for the results of the clusioncriteria:Householdsizeis3orlarger;Propertyownershipis
Content Validity study. We first removed items with low validity eithersocialhousingoraffordable-rentedaccommodation;Employ-
(I-CVI ≤0.75)andthereafterS-CVIscoreswereusedtoestablish mentstatusiseitherpart-time,duetostartanewjobwithinthenext
i
thecontentvalidityoftheresultingscale.Herewemarginallydivert month,unemployed,ornotinpaidwork(e.g.homemakerorretired).
fromtheestablishedbaselineof0.78forI-CVItofurtherinvestigate Intherestofthispaper,wewillrefertoallresponsestopositive
itemswith0.75 ≤ I-CVI ≤ 0.78duringthepilotstudy.TheLikert experiencesasGroupAandallresponsestonegativeexperiencesas
responsestotheclaritypropertyandfreetextfeedbackinfluencedthe Group B. To represent application-specific groups we will use the
re-wordingof7itemstoimproveclarity(indicatedby†).Theitem applicationnameasaprefix;e.g.CourseAssist-A.Eachparticipant
selection and rephrasing were done based on the suggestions from was randomly assigned to one of the sample experiences and after
theXAIexpertsandtheconsensusoftheresearchteam.Theresult- review,weexcluded5,1and1responsesfromgroupsCourseAssist-
ing scale comprised 18 items, which we refer to as the XEQ Scale A,AssistHub-AandAssistHub-Bwhofailedthefollowingattention
-pronounced:"Seek".InTable2,itemsareorderedbytheirI-CVI checks: 1) spend less than half of the allocated time; and/or 2) re-
scores. spondedtothequestionnaireinapattern.Thisresultedin53,50,50,
S-CVI(a) and S-CVI(b) of the scale were 0.8846 and 0.2222. and50respondentsforCourseAssist-A,CourseAssist-B,AssistHub-
WhileS-CVI(a)iscomparabletothebaselineof0.9,S-CVI(b)indi- AandAssistHub-Bgroupsrespectively.
cateuniversalagreementisnotachieved.However,existingliterature
suggeststhatmeetingoneofthebaselinecriteriaissufficienttopro- 5.3 Metrics
ceedtopilotstudies.Notably,the14itemswithI-CVI≥ 0.78also
For analysis, we introduce the following notations.Given ri is the
onlyachieveaverageagreement(S-CVI(a) = 0.9179)andnotuni- j
participantj’sresponsetoitemi,theparticipant’stotalisr andthe
versal agreement (S-CVI(b) = 0.2667). Following the item selec- j
item total is ri. We transform 5-step Likert responses to numbers
tionandrefinement,eachitemwasassignedanevaluationdimension
as follows: Strongly Disagree-1, Somewhat Disagree-2, Neutral-3,
basedontheconsensusoftheresearchteam(seeColumn“Factor”
SomewhatAgree-4,andStronglyAgree-5.Accordingly,forthe18-
inTable2).Thesewillbeusedinfurtherinvestigationsusingfactor
itemXEQScale,r ≤90(5×18).
analysistoestablishtheconstructvalidityofthescale. j
5.3.1 InternalConsistency
5 XEQScaleRefinementandValidation
Internalconsistencyreferstothedegreeofinter-relatednessamong
In this section, we present the pilot study conducted to refine the
itemswithinascale.Weemploythefollowingmetricsfrompsycho-
XEQScaleforinternalconsistency,constructvalidityanddiscrimi-
metrictheorytoassesstheXEQScaleitems.
nantvalidity.
Item-TotalCorrelation calculates the Pearson correlation coeffi-
cientbetweentheitemscoreandthetotalscoretheexpectedvalue
5.1 StudyDesignandApplications
peritemis≥0.50.TheItem-TotalCorrelationofitemi,iT iscal-
culatedasfollows.
Thestudyinvolvedtwoapplicationdomains:1)CourseAssistChat-
bot for new students to guide their course selection processes and (cid:80)N (ri −r¯i)(r −r¯)
2) AssistHub website for welfare applicants to assist with applica- iT = (cid:113) j=1 j j
(cid:80)N (ri −r¯i)2(cid:80)N (r −r¯)2
tion outcomes. For each application, two sample XAI experiences j=1 j j=1 jFigure1. Thestaticpreviewsoftherelativelypositive(left2columns)andnegative(rightcolumn)XAIExperienceswiththeCourseAssistChatbotdesigned
forthePilotStudyHerer¯iistheaverageresponsescorefortheithitem,andr¯iisthe 5.4.2 DiscriminantValidity
overallresponseaverage.
We performed discriminant analysis over 100 trials where at each
Inter-ItemCorrelation isameasureofthecorrelationbetweendif-
trialadifferenttrain-testsplitoftheresponseswasused.Eachtrial
ferentitemswithinascaleandvaluesbetween0.2and0.8arecon-
usedastratifiedsplit,with70%oftheresponsesfortrainingand30%
sideredexpectedsince≥ 0.80indicateredundancyand≤ 0.20
fortesting.Overthe100trials,weobservedaccuracyof0.63±0.05
indicatepooritemhomogeneity.Thecalculationissimilartothe
and a macro F1-score of 0.63 ± 0.05 which is significantly over
previousbutisbetweentwoitems.
thebaselineaccuracyof0.50forabinaryclassificationtask.Mixed-
Cronbach’salpha measurestheextenttowhichallitemsinascale
modelANOVAtestshowedastatisticallysignificantdifferencebe-
are measuring the same underlying construct [7]. High internal
tween groups A and B with a p-value of 1.63e − 12 where the
consistencyisindicatedbyα≥0.7.Ifsiisthestandarddeviation
mean participant total for groups A and B were 70.96±0.47 and
ofresponsestoitemi,andsisthestandarddeviationofresponse
57.97±1.84.Also,itrevealedasubstantialvariabilitywithingroups
totals,αiscalculatedasfollows.
indicatedbythegroupvarianceof104.86,whichweaccountforin-
M
(cid:32) (cid:80)M (si)2(cid:33) cludingresponsesfromtwoapplicationdomains.Furthermore,Co-
α= 1− i=1 hen’s d was 1.7639 which indicates a large effect size confirming
M −1 s2
a significant difference between groups A and B. A standard t-test
alsoobtainedclosetozerop-valueassociatedwiththet-statisticat
Assuchthishelpstoquantifyhowmuchofthetotalvarianceis
1.13e−09furtherverifyingstatisticaldifference.Basedonthisev-
duetothesharedvarianceamongitems,whichreflectstheircon-
idence we reject the null hypothesis and confirm the discriminant
sistencyinmeasuringthesameunderlyingconstruct.
validityofthescale.
5.3.2 DiscriminantValidity
5.4.3 ConstructValidity
Discriminantvaliditymeasurestheabilityofthescaletodiscernbe-
tweenpositiveandnegativeexperiencesandweusedthefollowing WefirstexplorethenumberoffactorspresentintheXEQScaleusing
twomethods. ExploratoryFA.Figure2plotstheeigenvaluesforPCAcoefficients
derivedfromthescaleresponses.Thereissignificantonefactorthat
DiscriminantAnalysis treatsthepilotstudyresponsesasalabelled isevidentthroughoutthescaleresponseswhichwerefertoas“XAI
datasettotrainaclassificationmodelwithalineardecisionbound- ExperienceQuality”.Thisisevidencedbythesharpdropandplateau
ary.Theitemsareconsideredasfeaturesandthegroup(AorB)is ofeigenvaluesforPCAcoefficient2onwards.ToperformtheCon-
consideredasthelabel.Aholdoutsetthenevaluatesthemodel’s
abilitytodistinguishbetweengroupsAandB.
ParametricStatisticalTest uses a mixed-model ANOVA test to
measureifthereisastatisticallysignificantdifferencebetweenthe
twogroupsAandB(agnosticofthedomain).Ournullhypothesis
is “no significant difference is observed in the mean participant
total between groups A and B“. Our sample sizes meet the re-
quirementsforaparametrictestdeterminedbyanaprioripower
analysisusingG*Power[8].
5.3.3 ConstructValidity
Construct validity evaluates the degree to which the scale assesses
firmatoryFAweFicgrueraete2.afEaxcptolorramtoordyeFlacatsorsuAgngaelysstiesdbyexploratory
the characteristic of interest [14]. We perform two forms of Factor
FA.ConfirmatoryFAshowsthatallitemfactorloadingsare≥ 0.5
Analysis (FA) to uncover underlying factors (i.e. dimensions) and
baselinemeaning,allitemscontributetotheover-archingfactormea-
validatethem.
suredbythisscale.Tovalidatetheevaluationdimensionsassigned
ExploratoryFA findsthenumberofunderlyingfactorsinthescale toitemsbytheresearchteam,wecreateanotherfactormodelwith
4factorseachassignedwiththesubsetoftheitemsindicatedinTa-
byassessingthevarianceexplainedthroughthePrincipalCompo-
ble2lastcolumn.Againwefindthateachitemmeets≥ 0.5factor
nentAnalysis(PCA)coefficients(i.e.eigenvalues).
ConfirmatoryFA hypothesiseafactormodel(e.g.modelproposed loadingfortheirassignedfactor.Thisconfirmsthatwhilethereisan
over-arching factor about “XAI Experience Quality”, it is substan-
intheExploratoryFAoraFactormodelproposedbyXAIexperts)
tially underpinned by the four factors Learning, Utility, Fulfilment
andcalculatefactorloadingswheretheexpectedloadingforeach
itemisexpectedtobe≥0.5. andEngagement.Thisconcludesourmulti-facetedrefinementofthe
XEQScalebasedonpilotstudyresults.
5.4 Results
6 Discussion
5.4.1 InternalConsistency
6.1 ImplicationsandLimitations
Table2column3reportstheItem-TotalCorrelation.Allitemsmet
thebaselinecriteriaofiT ≥ 0.5andbaselinecriteriaforInter-Item Inpsychometrictheory,conductingapilotstudyinvolvesadminis-
correlation.Cronbach’salphais0.9562whichalsoindicatesstrong teringboththescaleunderdevelopmentandexistingscalestopar-
internalconsistency. ticipants.Theobjectiveistoassessthecorrelationbetweenthenew# Item Table2. Results I-CVI Item-Total OneFactor Factor
Correlation Loading
1 Theexplanationsreceivedthroughouttheexperiencewereconsistent†. 1.0000 0.6274 0.6076 Engagement
2 TheexperiencehelpedmeunderstandthereliabilityoftheAIsystem. 1.0000 0.6416 0.6300 Learning
3 IamconfidentaboutusingtheAIsystem. 1.0000 0.7960 0.7790 Utility
4 Theinformationpresentedduringtheexperiencewasclear. 1.0000 0.7666 0.7605 Learning
5 Theexperiencewasconsistentwithmyexpectations†. 0.9231 0.7959 0.7831 Fulfilment
6 Thepresentationoftheexperiencewasappropriateformyrequirements†. 0.9231 0.8192 0.8083 Fulfilment
7 TheexperiencehasimprovedmyunderstandingofhowtheAIsystemworks. 0.9231 0.6169 0.5859 Learning
8 TheexperiencehelpedmebuildtrustintheAIsystem. 0.9231 0.7160 0.7018 Learning
9 Theexperiencehelpedmemakemoreinformeddecisions. 0.9231 0.7460 0.7279 Utility
10 Ireceivedtheexplanationsinatimelyandefficientmanner. 0.8462 0.7015 0.6841 Engagement
11 Theinformationpresentedwaspersonalisedtotherequirementsofmyrole†. 0.8462 0.7057 0.6801 Utility
12 Theinformationpresentedwasunderstandablewithinthereq.ofmyrole†. 0.8462 0.7876 0.7803 Utility
13 TheinformationpresentedshowedmethattheAIsystemperformswell†. 0.8462 0.8112 0.8016 Fulfilment
14 TheexperiencehelpedtocompletetheintendedtaskusingtheAIsystem. 0.8462 0.8299 0.8241 Utility
15 Theexperienceprogressedsensibly†. 0.7692 0.8004 0.7912 Engagement
16 Theexperiencewassatisfying. 0.7692 0.7673 0.7529 Fulfilment
17 Theinformationpresentedduringtheexperiencewassufficientlydetailed. 0.7692 0.8168 0.8035 Utility
18 Theexperienceprovidedanswerstoallofmyexplanationneeds. 0.7692 0.8472 0.8444 Fulfilment
scaleandthosefoundinexistingliterature,particularlyinshareddi- Table3. XEQSSctaalkeehinolPdrearcItiDce Factor
Factor Item#
mensions.However,ourpilotstudiesdidnotincorporatethis,sinceto #1 #2 #3 #4 #5 Mean
thebestofourknowledgetherearenopreviousscalesthatmeasured Learning 2 3 2 4 3 3
4 2 1 4 3 4
the XAI experience quality or multi-shot XAI experiences. While
7 4 3 3 4 2
the System Causability Scale [11] is the closest match in the liter- 8 3 3 2 1 4 2.90
ature, it was not applicable as it featured in the initial items bank. Utility 3 2 4 5 3 4
Also,thecurrentpilotstudieshadlimitedvariabilityinapplication 9 4 2 4 4 5
domains. To address this limitation, we are currently planning pi- 11 4 2 3 5 3
12 5 2 5 2 3
lot studies with two medical applications: 1) fracture prediction in
14 5 3 5 3 4
Radiographs;and2)liverdiseasepredictionfromCTscans.Inthe 17 4 2 4 4 5 3.67
future,wewillfurthervalidateandrefinethescaleasnecessary. Fulfilment 5 3 5 4 2 5
6 3 4 5 5 4
13 3 3 3 2 3
6.2 XEQScaleinPractice 16 4 3 4 5 4
18 4 4 3 2 5 3.68
Engagement 1 1 2 4 2 3
Table3presentsarepresentativescenarioofhowtheXEQScaleis
10 4 3 2 4 3
usedinpractice.ItpresentstheXAIExperienceQualityanalysisof
15 2 1 3 3 1 2.40
a hypothetical XAI system based on the XEQ scale administered Stakeholders’sXEQ
3.22 2.72 3.72 3.17 3.61
to 5 stakeholders. The items in Table 3 are organised according to Score
their evaluation dimensions and the stakeholder responses are ran- SystemXEQScore 3.16
domlygeneratedandquantifiedasfollows:StronglyAgree-5;Some-
whatAgree-4;Neutral-3;SomewhatDisagree-2;StronglyDisagree-
6.3 XEQBenchmarkDevelopment
1.Basedontheresponses,wecalculatethefollowingscores.
StakeholderXEQScore quantifies individual experiences and is
calculatedasthemeanofstakeholder’sresponsestoallitems.
FactorScore quantifies the quality along each evaluation dimen- The next phase for the XEQ scale entails developing a benchmark
sionandiscalculatedasthemeanofallresponsestotherespective forXAIexperiencequality.Thisprocessincludesadministeringthe
subsetofitems.ForXAIsystemdesigners,FactorMeansindicates XEQscaletoover100real-worldAIsystemsthatprovideexplain-
thedimensionsthatneedimprovement.Forinstance,intheexam- ability to stakeholders and establishing a classification system. We
pleXAIsystem,theLearningandEngagementdimensionsneed plantofollowtheestablishedbenchmarkmaintenancepolicyofthe
improvement whereas stakeholders found the Utility and Fulfil- User Experience Questionnaire [26] where we develop and release
mentdimensionstobesatisfactorywithroomforimprovement. anXEQAnalysistoolwiththebenchmarkupdatedregularly.
SystemXEQScore quantifies the XAI experience quality of the We envision when the scale is administered to stakeholders of
system as a whole and is calculated as the aggregate of Factor a new XAI system, the benchmark will categorise the new system
Means.TheSystemXEQScorehelpstheXAIsystemdesigners basedonthemeanparticipanttotalineachevaluationdimensionas
toiterativelydevelopawell-roundedsystemgroundedinuserex- follows-Excellent:Withinthetop10%ofXAIsystemsconsidered
perience.Thedesignerscanalsochoosetoassignahigherweight inthebenchmark;Good:Worsethanthetop10%andbetterthanthe
to one or a subset of dimensions that they find important at any lower75%;Aboveaverage:Worsethanthetop25%andbetterthan
iteration.SystemXEQScorecanalsobeutilisedbyexternalpar- thelower50%;Belowaverage:Worsethanthetop50%andbetter
ties(e.g.regulators,government),eithertoevaluateorbenchmark thanthelower25%;andBad:Withinthe25%worstXAIsystems.
XAIsystems. Accordingly,theXEQbenchmarkwillenableXAIsystemownersto
iterativelyenhancetheXAIexperienceofferedtotheirstakeholders.7 Conclusion [11] A.Holzinger,A.Carrington,andH.Müller. Measuringthequalityof
explanations:thesystemcausabilityscale(scs)comparinghumanand
In this paper, we presented the XEQ scale for evaluating XAI ex- machineexplanations.KI-KünstlicheIntelligenz,34(2):193–198,2020.
[12] B.Hu,P.Tunison,B.Vasu,N.Menon,R.Collins,andA.Hoogs.Xaitk:
periences.TheXEQscaleprovidesacomprehensiveevaluationfor
Theexplainableaitoolkit.AppliedAILetters,2(4):e40,2021.
user-centredXAIexperiencesandfillsanovelgapintheevaluation [13] J.-Y. Jian, A. M. Bisantz, and C. G. Drury. Foundations for an em-
ofmulti-shotexplanationswhichiscurrentlynotadequatelyfulfilled piricallydeterminedscaleoftrustinautomatedsystems. International
journalofcognitiveergonomics,4(1):53–71,2000.
by any other evaluation metric(s). Throughout this paper, we have
[14] A.E.Kazdin.Researchdesigninclinicalpsychology.CambridgeUni-
describedthedevelopmentandvalidationofthescalefollowingpsy- versityPress,2021.
chometrictheory.Wemakethisscaleavailableasapublicresource [15] C.H.Lawsheetal.Aquantitativeapproachtocontentvalidity.Person-
for evaluating the quality of XAI experiences. In future work, we nelpsychology,28(4):563–575,1975.
[16] P. Q. Le, M. Nauta, V. B. Nguyen, S. Pathak, J. Schlötterer, and
plantoinvestigatethegeneralisabilityoftheXEQscaleonadditional
C.Seifert. Benchmarkingexplainableai:asurveyonavailabletoolk-
domains,AIsystemsandstakeholdergroups.Beyondthis,wepro- itsandopenchallenges. InInternationalJointConferenceonArtificial
posetoestablishabenchmarkusingtheXEQscale.Ourgoalisto Intelligence,2023.
[17] M.MadsenandS.Gregor. Measuringhuman-computertrust. In11th
facilitatetheuser-centredevaluationofXAIandsupporttheemerg-
australasianconferenceoninformationsystems,volume53,pages6–8.
ingdevelopmentofbestpracticesintheexplainabilityofautonomous Citeseer,2000.
decision-making. [18] L.Malandri,F.Mercorio,M.Mezzanzanica,andN.Nobani. Convxai:
asystemformultimodalinteractionwithanyblack-boxexplainer.Cog-
nitiveComputation,15(2):613–644,2023.
EthicalStatement [19] T.Miller. Explanationinartificialintelligence:Insightsfromthesocial
sciences.Artificialintelligence,267:1–38,2019.
[20] S. Mohseni, N. Zarei, and E. D. Ragan. A multidisciplinary survey
Both content validity study and pilot study protocols passed the
and framework for design and evaluation of explainable ai systems.
ethics review of the leading institution (references removed for re- ACMTransactionsonInteractiveIntelligentSystems(TiiS),11(3-4):1–
view).InformedconsentwasobtainedfromallXAIexpertsandpilot 45,2021.
[21] G.C.MooreandI.Benbasat. Developmentofaninstrumenttomea-
studyparticipants.
suretheperceptionsofadoptinganinformationtechnologyinnovation.
Informationsystemsresearch,2(3):192–222,1991.
[22] M.NautaandC.Seifert. Theco-12recipeforevaluatinginterpretable
Acknowledgements
part-prototypeimageclassifiers. InWorldConferenceonExplainable
ArtificialIntelligence,pages397–420.Springer,2023.
WethankallXAIexpertsandpilotstudyparticipantsfortheircon- [23] J.C.NunnallyandI.H.Bernstein.PsychometricTheory:Nunnallyand
tributions. Bernstein.McGrawHill,3rdedition,1993.
[24] A.Rosenfeld. Bettermetricsforevaluatingexplainableartificialintel-
This work is done as part of the iSee project. iSee is an EU
ligence. In Proceedings of the 20th international conference on au-
CHIST-ERA project which received funding for the UK from EP- tonomousagentsandmultiagentsystems,pages45–50,2021.
SRCundergrantnumberEP/V061755/1;forIrelandfromtheIrish [25] K.Schaefer. Theperceptionandmeasurementofhuman-robottrust.
2013.
Research Council under grant number CHIST-ERA-2019-iSee and
[26] M.Schrepp,J.Thomaschewski,andA.Hinderks. Constructionofa
for Spain from the MCIN/AEI and European Union “NextGenera-
benchmarkfortheuserexperiencequestionnaire(ueq).2017.
tionEU/PRTR”undergrantnumberPCI2020-120720-2. [27] A.Wijekoon,N.Wiratunga,K.Martin,D.Corsar,I.Nkisi-Orji,C.Pal-
ihawadana,D.Bridge,P.Pradeep,B.D.Agudo,andM.Caro-Martínez.
Cbrdriveninteractiveexplainableai. InInternationalConferenceon
References Case-BasedReasoning,pages169–184.Springer,2023.
[28] C.-K.Yeh,C.-Y.Hsieh,A.Suggala,D.I.Inouye,andP.K.Ravikumar.
[1] B. D. Adams, L. E. Bruyn, S. Houde, P. Angelopoulos, K. Iwasa- Onthe(in)fidelityandsensitivityofexplanations. AdvancesinNeural
Madge,andC.McCann. Trustinautomatedsystems. MinistryofNa- InformationProcessingSystems,32,2019.
tionalDefence,2003. [29] J.Zhou,A.H.Gandomi,F.Chen,andA.Holzinger. Evaluatingthe
[2] V. Arya, R. K. Bellamy, P.-Y. Chen, A. Dhurandhar, M. Hind, S. C. quality of machine learning explanations: A survey on methods and
Hoffman, S. Houde, Q. V. Liao, R. Luss, A. Mojsilovic´, et al. One metrics.Electronics,10(5):593,2021.
explanationdoesnotfitall:Atoolkitandtaxonomyofaiexplainability
techniques.arXivpreprintarXiv:1909.03012,2019.
[3] G.O.Boateng,T.B.Neilands,E.A.Frongillo,andS.L.Young. Best
Appendix
practicesfordevelopingandvalidatingscalesforhealth,social,andbe-
havioralresearch:aprimer.Frontiersinpublichealth,6:366616,2018.
7.1 InitialItemsBank
[4] J.Brookeetal. Sus-aquickanddirtyusabilityscale. Usabilityevalua-
tioninindustry,189(194):4–7,1996.
7.2 ContentValidityStudy
[5] B.CahourandJ.-F.Forzy. Doesprojectionintouseimprovetrustand
exploration?anexamplewithacruisecontrolsystem. Safetyscience,
47(9):1260–1270,2009. ThisstudyaimedtoestablishthecontentvalidityoftheXEQscale
[6] D.V.Carvalho,E.M.Pereira,andJ.S.Cardoso. Machinelearning withXAIexperts.BeingXAIExperiencesareanovelconcept,wein-
interpretability:Asurveyonmethodsandmetrics. Electronics,8(8): cludedthreeexampleXAIexperiencesthatcaptureavarietyofstake-
832,2019.
holdertypesandapplicationdomains.InadditiontotheCourseAssist
[7] L.J.Cronbach.Essentialsofpsychologicaltesting.1949.
[8] F. Faul, E. Erdfelder, A.-G. Lang, and A. Buchner. G* power 3: A chatbotexampleincludedinthepaper,theywerepresentedwiththe
flexible statistical power analysis program for the social, behavioral, followingexperiencesinvideoformat.
andbiomedicalsciences. Behaviorresearchmethods,39(2):175–191,
2007.
• The AssistHub AI platform is a website for processing welfare
[9] R. R. Hoffman, S. T. Mueller, G. Klein, and J. Litman. Met-
rics for explainable ai: Challenges and prospects. arXiv preprint applicationsandisusedbyalocalcounciltoacceleratetheappli-
arXiv:1812.04608,2018. cationprocess.Aregulationofficerisexploringthewebsiteand
[10] R.R.Hoffman,S.T.Mueller,G.Klein,andJ.Litman. Measuresfor itsXAIfeaturestounderstandthefairnessandbiasoftheAIsys-
explainableai:Explanationgoodness,usersatisfaction,mentalmodels,
tembeingusedinthedecision-makingprocess.Anon-interactive
curiosity,trust,andhuman-aiperformance. FrontiersinComputerSci-
ence,5:1096257,2023. previewoftheexperienceispresentedinFigure3.Item Table4. ItemsBank
Ilikeusingthesystemfordecision-making.
Theinformationpresentedduringtheexperiencewasclear.
Theexplanationsreceivedthroughouttheexperiencedidnotcontainin-
consistencies.
Icouldadjustthelevelofdetailondemand.
Theexperiencehelpedmemakemoreinformeddecisions.
Theexperiencehelpedmeestablishthereliabilityofthesystem.
Ireceivedtheexplanationsinatimelyandefficientmanner.
Theexperiencewassatisfying.
Theexperiencewassuitablefortheintendedpurposeofthesystem.
Iwasabletoexpressallmyexplanationneeds.
Theexperiencerevealedwhetherthesystemisfair.
Theexperiencehelpedmecompletemytaskusingthesystem.
Theexperiencewasconsistentwithmyexpectationswithinthecontextof
myrole.
Thepresentationoftheexperiencewasappropriate.
Theexperiencehasimprovedmyunderstandingofhowthesystemworks.
Theexperiencehelpedmeunderstandhowtousethesystem.
Theexperiencewasunderstandableinthecontextofmyrole.
Theexperiencehelpedmebuildtrustinthesystem.
Theexperiencewaspersonalisedtothecontextofmyrole.
Icouldrequestmoredetailondemandifneeded.
Ididnotneedexternalsupporttounderstandtheexplanations.
Theexperiencewashelpfultoachievemygoals.
Theexperienceprogressedlogically.
Theexperiencewasconsistentwithmyunderstandingofthesystem.
Thedurationoftheexperiencewasappropriatewithinthecontextofmy
role.
Theexperienceimprovedmyengagementwiththesystem.
Theexperiencewaspersonalisedtomyexplanationneeds.
Throughouttheexperience,allofmyexplanationneedswereresolved.
Theexperienceshowedmehowaccuratethesystemis.
Allpartsoftheexperienceweresuitableandnecessary.
Theinformationpresentedduringtheexperiencewassufficientlydetailed
formyunderstandingofthedomain.
Iamconfidentinthesystem.
• RadioAssistAIplatformisadesktopapplication,usedbythelo-
calhospitaltosupportcliniciansintheirclinicaldecision-making
processes.AnAIsystempredictsthepresenceoffractureinRa-
diographs and explains its decisions to the clinicians. A non-
interactivepreviewoftheexperienceispresentedinFigure4.
Both Figures 4 and 3 are annotated with notes that describe the
XAIfeaturesthatwereavailabletothestakeholder.Finally,Figure5
presentsapreviewoftheStudypage.
7.3 PilotStudy
A pilot study was conducted with 203 participants over two appli-
cation domains where they evaluated either a positive or negative
XAI experience. In addition to the CourseAssist chatbot examples
providedinthepaper,weincludedtwoXAIexperiencesofwelfare
applicantsinteractingwiththeAssistHubAIplatform(seeFigures6
and7).Notesrefertohowdifferentaspectsoftheexplanationscan
leadtoapositiveornegativeXAIexperience.Similartotheprevi-
ousstudy,allXAIexperienceswereavailabletoparticipantsinvideo
format.FinallyFigure8presentsapreviewofthePilotstudywhere
pages1and2werecustomisedbasedontheapplicationparticipants
wereassignedto.Figure3. PositiveXAIExperienceofaRegulationOfficerexploringtheAssistHubAIplatform;Apop-upisshownwhenclickedontheAIINSIGHTSbutton,
withfournavigationpagesprovidingdifferenttypesofexplanations.Thehelpdescriptionpop-upappearswhenclickingonthequestionmarkbutton.Figure4. PositiveXAIExperienceofaClinicianusingtheRadioAssistAIplatform;Thecliniciancanclickonthetwominimisedpagestoexpandandview
explanationsabouttheAIsystemandthedecision.Thequestionmarkbuttonshowsthehelpdescription.Figure5. StudyPreview;ExamplesremovedfromPage3andlistofitemsshortenedinPage4.Figure6. RelativelypositiveXAIExperienceofawelfareapplicantusingtheAssistHubAIplatformFigure7. RelativelynegativeXAIExperienceofawelfareapplicantusingtheAssistHubAIplatformFigure8. PilotStudyPreview;ExampleremovedfromPage2andlistofitemsshortenedinPage3.