[
    {
        "title": "Q-Sparse: All Large Language Models can be Fully Sparsely-Activated",
        "authors": "Hongyu WangShuming MaRuiping WangFuru Wei",
        "links": "http://arxiv.org/abs/2407.10969v1",
        "entry_id": "http://arxiv.org/abs/2407.10969v1",
        "pdf_url": "http://arxiv.org/pdf/2407.10969v1",
        "summary": "We introduce, Q-Sparse, a simple yet effective approach to training\nsparsely-activated large language models (LLMs). Q-Sparse enables full sparsity\nof activations in LLMs which can bring significant efficiency gains in\ninference. This is achieved by applying top-K sparsification to the activations\nand the straight-through-estimator to the training. The key results from this\nwork are, (1) Q-Sparse can achieve results comparable to those of baseline LLMs\nwhile being much more efficient at inference time; (2) We present an\ninference-optimal scaling law for sparsely-activated LLMs; (3) Q-Sparse is\neffective in different settings, including training-from-scratch,\ncontinue-training of off-the-shelf LLMs, and finetuning; (4) Q-Sparse works for\nboth full-precision and 1-bit LLMs (e.g., BitNet b1.58). Particularly, the\nsynergy of BitNet b1.58 and Q-Sparse (can be equipped with MoE) provides the\ncornerstone and a clear path to revolutionize the efficiency, including cost\nand energy consumption, of future LLMs.",
        "updated": "2024-07-15 17:59:29 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.10969v1"
    },
    {
        "title": "Spider2-V: How Far Are Multimodal Agents From Automating Data Science and Engineering Workflows?",
        "authors": "Ruisheng CaoFangyu LeiHaoyuan WuJixuan ChenYeqiao FuHongcheng GaoXinzhuang XiongHanchong ZhangYuchen MaoWenjing HuTianbao XieHongshen XuDanyang ZhangSida WangRuoxi SunPengcheng YinCaiming XiongAnsong NiQian LiuVictor ZhongLu ChenKai YuTao Yu",
        "links": "http://arxiv.org/abs/2407.10956v1",
        "entry_id": "http://arxiv.org/abs/2407.10956v1",
        "pdf_url": "http://arxiv.org/pdf/2407.10956v1",
        "summary": "Data science and engineering workflows often span multiple stages, from\nwarehousing to orchestration, using tools like BigQuery, dbt, and Airbyte. As\nvision language models (VLMs) advance in multimodal understanding and code\ngeneration, VLM-based agents could potentially automate these workflows by\ngenerating SQL queries, Python code, and GUI operations. This automation can\nimprove the productivity of experts while democratizing access to large-scale\ndata analysis. In this paper, we introduce Spider2-V, the first multimodal\nagent benchmark focusing on professional data science and engineering\nworkflows, featuring 494 real-world tasks in authentic computer environments\nand incorporating 20 enterprise-level professional applications. These tasks,\nderived from real-world use cases, evaluate the ability of a multimodal agent\nto perform data-related tasks by writing code and managing the GUI in\nenterprise data software systems. To balance realistic simulation with\nevaluation simplicity, we devote significant effort to developing automatic\nconfigurations for task setup and carefully crafting evaluation metrics for\neach task. Furthermore, we supplement multimodal agents with comprehensive\ndocuments of these enterprise data software systems. Our empirical evaluation\nreveals that existing state-of-the-art LLM/VLM-based agents do not reliably\nautomate full data workflows (14.0% success). Even with step-by-step guidance,\nthese agents still underperform in tasks that require fine-grained,\nknowledge-intensive GUI actions (16.2%) and involve remote cloud-hosted\nworkspaces (10.6%). We hope that Spider2-V paves the way for autonomous\nmultimodal agents to transform the automation of data science and engineering\nworkflow. Our code and data are available at https://spider2-v.github.io.",
        "updated": "2024-07-15 17:54:37 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.10956v1"
    },
    {
        "title": "MMM: Multilingual Mutual Reinforcement Effect Mix Datasets & Test with Open-domain Information Extraction Large Language Models",
        "authors": "Chengguang GanQingyu YinXinyang HeHanjun WeiYunhao LiangYounghun LimShijian WangHexiang HuangQinghao ZhangShiwen NiTatsunori Mori",
        "links": "http://arxiv.org/abs/2407.10953v1",
        "entry_id": "http://arxiv.org/abs/2407.10953v1",
        "pdf_url": "http://arxiv.org/pdf/2407.10953v1",
        "summary": "The Mutual Reinforcement Effect (MRE) represents a promising avenue in\ninformation extraction and multitasking research. Nevertheless, its\napplicability has been constrained due to the exclusive availability of MRE mix\ndatasets in Japanese, thereby limiting comprehensive exploration by the global\nresearch community. To address this limitation, we introduce a Multilingual MRE\nmix dataset (MMM) that encompasses 21 sub-datasets in English, Japanese, and\nChinese. In this paper, we also propose a method for dataset translation\nassisted by Large Language Models (LLMs), which significantly reduces the\nmanual annotation time required for dataset construction by leveraging LLMs to\ntranslate the original Japanese datasets. Additionally, we have enriched the\ndataset by incorporating open-domain Named Entity Recognition (NER) and\nsentence classification tasks. Utilizing this expanded dataset, we developed a\nunified input-output framework to train an Open-domain Information Extraction\nLarge Language Model (OIELLM). The OIELLM model demonstrates the capability to\neffectively process novel MMM datasets, exhibiting significant improvements in\nperformance.",
        "updated": "2024-07-15 17:50:43 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.10953v1"
    },
    {
        "title": "Representing Rule-based Chatbots with Transformers",
        "authors": "Dan FriedmanAbhishek PanigrahiDanqi Chen",
        "links": "http://arxiv.org/abs/2407.10949v1",
        "entry_id": "http://arxiv.org/abs/2407.10949v1",
        "pdf_url": "http://arxiv.org/pdf/2407.10949v1",
        "summary": "Transformer-based chatbots can conduct fluent, natural-sounding\nconversations, but we have limited understanding of the mechanisms underlying\ntheir behavior. Prior work has taken a bottom-up approach to understanding\nTransformers by constructing Transformers for various synthetic and formal\nlanguage tasks, such as regular expressions and Dyck languages. However, it is\nnot obvious how to extend this approach to understand more naturalistic\nconversational agents. In this work, we take a step in this direction by\nconstructing a Transformer that implements the ELIZA program, a classic,\nrule-based chatbot. ELIZA illustrates some of the distinctive challenges of the\nconversational setting, including both local pattern matching and long-term\ndialog state tracking. We build on constructions from prior work -- in\nparticular, for simulating finite-state automata -- showing how simpler\nconstructions can be composed and extended to give rise to more sophisticated\nbehavior. Next, we train Transformers on a dataset of synthetically generated\nELIZA conversations and investigate the mechanisms the models learn. Our\nanalysis illustrates the kinds of mechanisms these models tend to prefer -- for\nexample, models favor an induction head mechanism over a more precise, position\nbased copying mechanism; and using intermediate generations to simulate\nrecurrent data structures, like ELIZA's memory mechanisms. Overall, by drawing\nan explicit connection between neural chatbots and interpretable, symbolic\nmechanisms, our results offer a new setting for mechanistic analysis of\nconversational agents.",
        "updated": "2024-07-15 17:45:53 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.10949v1"
    },
    {
        "title": "Learning from Naturally Occurring Feedback",
        "authors": "Shachar Don-YehiyaLeshem ChoshenOmri Abend",
        "links": "http://arxiv.org/abs/2407.10944v1",
        "entry_id": "http://arxiv.org/abs/2407.10944v1",
        "pdf_url": "http://arxiv.org/pdf/2407.10944v1",
        "summary": "Human feedback data is a critical component in developing language models.\nHowever, collecting this feedback is costly and ultimately not scalable. We\npropose a scalable method for extracting feedback that users naturally include\nwhen interacting with chat models, and leveraging it for model training. We are\nfurther motivated by previous work that showed there are also qualitative\nadvantages to using naturalistic (rather than auto-generated) feedback, such as\nless hallucinations and biases. We manually annotated conversation data to\nconfirm the presence of naturally occurring feedback in a standard corpus,\nfinding that as much as 30% of the chats include explicit feedback. We apply\nour method to over 1M conversations to obtain hundreds of thousands of feedback\nsamples. Training with the extracted feedback shows significant performance\nimprovements over baseline models, demonstrating the efficacy of our approach\nin enhancing model alignment to human preferences.",
        "updated": "2024-07-15 17:41:34 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.10944v1"
    }
]