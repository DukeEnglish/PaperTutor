[
    {
        "title": "Diffusion Meets DAgger: Supercharging Eye-in-hand Imitation Learning",
        "authors": "Xiaoyu ZhangMatthew ChangPranav KumarSaurabh Gupta",
        "links": "http://arxiv.org/abs/2402.17768v1",
        "entry_id": "http://arxiv.org/abs/2402.17768v1",
        "pdf_url": "http://arxiv.org/pdf/2402.17768v1",
        "summary": "A common failure mode for policies trained with imitation is compounding\nexecution errors at test time. When the learned policy encounters states that\nwere not present in the expert demonstrations, the policy fails, leading to\ndegenerate behavior. The Dataset Aggregation, or DAgger approach to this\nproblem simply collects more data to cover these failure states. However, in\npractice, this is often prohibitively expensive. In this work, we propose\nDiffusion Meets DAgger (DMD), a method to reap the benefits of DAgger without\nthe cost for eye-in-hand imitation learning problems. Instead of collecting new\nsamples to cover out-of-distribution states, DMD uses recent advances in\ndiffusion models to create these samples with diffusion models. This leads to\nrobust performance from few demonstrations. In experiments conducted for\nnon-prehensile pushing on a Franka Research 3, we show that DMD can achieve a\nsuccess rate of 80% with as few as 8 expert demonstrations, where naive\nbehavior cloning reaches only 20%. DMD also outperform competing NeRF-based\naugmentation schemes by 50%.",
        "updated": "2024-02-27 18:59:18 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.17768v1"
    },
    {
        "title": "Opening Cabinets and Drawers in the Real World using a Commodity Mobile Manipulator",
        "authors": "Arjun GuptaMichelle ZhangRishik SathuaSaurabh Gupta",
        "links": "http://arxiv.org/abs/2402.17767v1",
        "entry_id": "http://arxiv.org/abs/2402.17767v1",
        "pdf_url": "http://arxiv.org/pdf/2402.17767v1",
        "summary": "Pulling open cabinets and drawers presents many difficult technical\nchallenges in perception (inferring articulation parameters for objects from\nonboard sensors), planning (producing motion plans that conform to tight task\nconstraints), and control (making and maintaining contact while applying forces\non the environment). In this work, we build an end-to-end system that enables a\ncommodity mobile manipulator (Stretch RE2) to pull open cabinets and drawers in\ndiverse previously unseen real world environments. We conduct 4 days of real\nworld testing of this system spanning 31 different objects from across 13\ndifferent real world environments. Our system achieves a success rate of 61% on\nopening novel cabinets and drawers in unseen environments zero-shot. An\nanalysis of the failure modes suggests that errors in perception are the most\nsignificant challenge for our system. We will open source code and models for\nothers to replicate and build upon our system.",
        "updated": "2024-02-27 18:58:54 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.17767v1"
    },
    {
        "title": "The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits",
        "authors": "Shuming MaHongyu WangLingxiao MaLei WangWenhui WangShaohan HuangLi DongRuiping WangJilong XueFuru Wei",
        "links": "http://arxiv.org/abs/2402.17764v1",
        "entry_id": "http://arxiv.org/abs/2402.17764v1",
        "pdf_url": "http://arxiv.org/pdf/2402.17764v1",
        "summary": "Recent research, such as BitNet, is paving the way for a new era of 1-bit\nLarge Language Models (LLMs). In this work, we introduce a 1-bit LLM variant,\nnamely BitNet b1.58, in which every single parameter (or weight) of the LLM is\nternary {-1, 0, 1}. It matches the full-precision (i.e., FP16 or BF16)\nTransformer LLM with the same model size and training tokens in terms of both\nperplexity and end-task performance, while being significantly more\ncost-effective in terms of latency, memory, throughput, and energy consumption.\nMore profoundly, the 1.58-bit LLM defines a new scaling law and recipe for\ntraining new generations of LLMs that are both high-performance and\ncost-effective. Furthermore, it enables a new computation paradigm and opens\nthe door for designing specific hardware optimized for 1-bit LLMs.",
        "updated": "2024-02-27 18:56:19 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.17764v1"
    },
    {
        "title": "Massive Activations in Large Language Models",
        "authors": "Mingjie SunXinlei ChenJ. Zico KolterZhuang Liu",
        "links": "http://arxiv.org/abs/2402.17762v1",
        "entry_id": "http://arxiv.org/abs/2402.17762v1",
        "pdf_url": "http://arxiv.org/pdf/2402.17762v1",
        "summary": "We observe an empirical phenomenon in Large Language Models (LLMs) -- very\nfew activations exhibit significantly larger values than others (e.g., 100,000\ntimes larger). We call them massive activations. First, we demonstrate the\nwidespread existence of massive activations across various LLMs and\ncharacterize their locations. Second, we find their values largely stay\nconstant regardless of the input, and they function as indispensable bias terms\nin LLMs. Third, these massive activations lead to the concentration of\nattention probabilities to their corresponding tokens, and further, implicit\nbias terms in the self-attention output. Last, we also study massive\nactivations in Vision Transformers.",
        "updated": "2024-02-27 18:55:17 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.17762v1"
    },
    {
        "title": "Learning to Program Variational Quantum Circuits with Fast Weights",
        "authors": "Samuel Yen-Chi Chen",
        "links": "http://arxiv.org/abs/2402.17760v1",
        "entry_id": "http://arxiv.org/abs/2402.17760v1",
        "pdf_url": "http://arxiv.org/pdf/2402.17760v1",
        "summary": "Quantum Machine Learning (QML) has surfaced as a pioneering framework\naddressing sequential control tasks and time-series modeling. It has\ndemonstrated empirical quantum advantages notably within domains such as\nReinforcement Learning (RL) and time-series prediction. A significant\nadvancement lies in Quantum Recurrent Neural Networks (QRNNs), specifically\ntailored for memory-intensive tasks encompassing partially observable\nenvironments and non-linear time-series prediction. Nevertheless, QRNN-based\nmodels encounter challenges, notably prolonged training duration stemming from\nthe necessity to compute quantum gradients using backpropagation-through-time\n(BPTT). This predicament exacerbates when executing the complete model on\nquantum devices, primarily due to the substantial demand for circuit evaluation\narising from the parameter-shift rule. This paper introduces the Quantum Fast\nWeight Programmers (QFWP) as a solution to the temporal or sequential learning\nchallenge. The QFWP leverages a classical neural network (referred to as the\n'slow programmer') functioning as a quantum programmer to swiftly modify the\nparameters of a variational quantum circuit (termed the 'fast programmer').\nInstead of completely overwriting the fast programmer at each time-step, the\nslow programmer generates parameter changes or updates for the quantum circuit\nparameters. This approach enables the fast programmer to incorporate past\nobservations or information. Notably, the proposed QFWP model achieves learning\nof temporal dependencies without necessitating the use of quantum recurrent\nneural networks. Numerical simulations conducted in this study showcase the\nefficacy of the proposed QFWP model in both time-series prediction and RL\ntasks. The model exhibits performance levels either comparable to or surpassing\nthose achieved by QLSTM-based models.",
        "updated": "2024-02-27 18:53:18 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.17760v1"
    }
]