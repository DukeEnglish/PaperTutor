Learning to Program Variational Quantum Circuits
with Fast Weights
Samuel Yen-Chi Chen
Wells Fargo
New York, NY, USA
yen-chi.chen@wellsfargo.com
Abstract—QuantumMachineLearning(QML)hassurfacedas quantumcomputershandleadvantageoustasks,whileclassical
a pioneering framework addressing sequential control tasks and counterparts manage computations, such as gradient calcu-
time-series modeling. It has demonstrated empirical quantum
lations. Known as variational quantum algorithms (VQA),
advantagesnotablywithindomainssuchasReinforcementLearn-
these methods have excelled in various machine learning
ing (RL) and time-series prediction. A significant advancement
lies in Quantum Recurrent Neural Networks (QRNNs), specifi- (ML) tasks such as classification [4]–[6], sequential model-
cally tailored for memory-intensive tasks encompassing partially ing/control [7], [8], generative models [9], [10] and natural
observable environments and non-linear time-series prediction. language processing [11]–[15]. Time-series modeling and re-
Nevertheless,QRNN-basedmodelsencounterchallenges,notably
inforcement learning (RL) within the realm of ML demand
prolonged training duration stemming from the necessity to
specific memory mechanisms to retain past observations for
compute quantum gradients using backpropagation-through-
time (BPTT). This predicament exacerbates when executing optimal performance. Classical ML fields have extensively
the complete model on quantum devices, primarily due to explored these tasks using deep neural networks, achieving
the substantial demand for circuit evaluation arising from the significant progress as evidenced by seminal works [16]–
parameter-shift rule. This paper introduces the Quantum Fast
[18]. However, the exploration of these tasks within QML
Weight Programmers (QFWP) as a solution to the temporal or
remains largely uncharted territory. Current QML methods
sequential learning challenge. The QFWP leverages a classical
neuralnetwork(referredtoasthe’slowprogrammer’)function- designed for addressing time-series modeling or RL tasks,
ing as a quantum programmer to swiftly modify the parameters demanding the retention of past observations, such as those
ofavariationalquantumcircuit(termedthe’fastprogrammer’). utilizing quantum recurrent neural networks (QRNNs), en-
Instead of completely overwriting the fast programmer at each
counter prolonged training time. This challenge arises from
time-step, the slow programmer generates parameter changes
the necessity to compute quantum gradients across extensive
or updates for the quantum circuit parameters. This approach
enables the fast programmer to incorporate past observations ordeepcircuitsandthesubstantialquantumcircuitevaluations
or information. Notably, the proposed QFWP model achieves required to gather expectation values. This paper presents the
learning of temporal dependencies without necessitating the use Quantum Fast Weight Programmers (QFWP), a framework
of quantum recurrent neural networks. Numerical simulations
utilizing a classical NN termed the ’slow programmer’ to
conducted in this study showcase the efficacy of the proposed
efficiently adjust the parameters of a quantum circuit known
QFWP model in both time-series prediction and RL tasks.
The model exhibits performance levels either comparable to or as the ’fast programmer’. This methodology is proposed to
surpassing those achieved by QLSTM-based models. address challenges in time-series prediction and RL without
Index Terms—Quantum machine learning, Quantum neural relying on QRNN, as depicted in Figure 1. Our numerical
networks, Reinforcement learning, Recurrent neural networks,
simulations demonstrate that the proposed QFWP framework
Long short-term memory
achievesperformancelevelscomparabletoorsurpassingthose
I. INTRODUCTION of fully trained QRNN counterparts, such as QLSTM, under
equivalent model sizes and training configurations.
Whilequantumcomputing(QC)holdspromiseforexcelling
incomplexcomputationaltaskscomparedtoclassicalsystems II. RELATEDWORK
[1], the current challenge lies in the absence of error cor-
Quantum reinforcement learning (QRL) has been an area
rection and fault tolerance, complicating the implementation
of study since the seminal work by Dong et al. in 2008
of deep quantum circuits for complex quantum algoruthms.
[19]. Initially, its applicability was constrained by the neces-
These noisy intermediate-scale quantum (NISQ) devices [2]
sity to construct the environment in a completely quantum
require specialized quantum circuit designs to fully harness
manner,limitingitspracticalutility.Subsequentadvancements
their potential advantages. A recent hybrid quantum-classical
in QRL, leveraging Variational Quantum Circuits (VQCs),
computing approach [3] strategically combines both realms:
have extended its scope to address classical environments
The views expressed in this article are those of the authors and do not with both discrete [20] and continuous observation spaces
representtheviewsofWellsFargo.Thisarticleisforinformationalpurposes [21], [22]. The progression of QRL has seen enhancements in
only. Nothing contained in this article should be construed as investment
performancethroughtheadoptionofpolicy-basedlearningap-
advice. Wells Fargo makes no express or implied warranties and expressly
disclaimsalllegal,tax,andaccountingimplicationsrelatedtothisarticle. proaches,includingProximalPolicyOptimization(PPO)[23],
4202
beF
72
]hp-tnauq[
1v06771.2042:viXrahybrid-qFWP
objectives.
Hybrid Quantum FWP RL Agent
III. FASTWEIGHTPROGRAMMERS
rewrite quantum parameters
Output from Hybrid The concept of Fast Weight Programmers (FWP), illus-
⋮ |0⟩ Quantum FWP model A3C Algorithm
⋮ | |0 0⟩
⟩
U(x) V(θ) trated in Figure2, was initially introduced in the works by
|0⟩ Update only classical Schmidhuber[33],[34].Inthissequentiallearningmodel,two
parameters Classical Computer
Slow Programmer Fast Programmer distinct neural networks (NN) are employed, termed the slow
Classical NN VQC
programmer and the fast programmer. The NN weights in
sstate rerward aaction
this context serve as the model/agent’s program. The funda-
t t t
Environment mental idea of FWP involves the slow programmer, during
a given time-step, generating updates or changes to the NN
Fig.1. HybridQuantumFastWeightProgrammer(FWP)asaRLagent. weights of the fast programmer based on observations. This
reprogrammingprocessswiftlyredirectsthefastprogrammer’s
focus to more salient information within the incoming data
stream.Itiscrucialtonotethattheslowprogrammerdoesnot
Soft Actor-Critic (SAC) [24], REINFORCE [25], Advantage entirelyoverwritethefastprogrammer;rather,onlychangesor
Actor-Critic (A2C) [26] and Asynchronous Advantage Actor- updatesareapplied.Thismethodenablesthefastprogrammer
Critic (A3C) [27]. Furthermore, to address the challenges to consider previous observations or information, offering a
posed by partially observable environments, researchers have mechanismforasimplefeed-forwardNNtohandlesequential
employedquantumrecurrentneuralnetworksasreinforcement prediction or control without resorting to recurrent neural
learning policies [28], [29]. Time-series modeling and predic- networks(RNN),whichtypicallydemandsignificantcomputa-
tion represent significant application scenarios within QML. tionalresources.Intheoriginalconfiguration,eachconnection
Recent investigations in QML have drawn inspiration from ofthefastprogrammerisassociatedwithadistinctoutputunit
successful methodologies in classical ML, particularly RNN- in the slow programmer. The evolution of fast programmer
based approaches. Quantum RNNs have exhibited promise in weights is characterized by the update rule Wfast(t+1) ←
accurately modeling time-series data, as evidenced by notable Wfast(t) + ∆W(t), where ∆W(t) denotes the output from
works [7], [8], [30]. However, the training of quantum RNNs the slow programmer at time-step t. The original scheme may
is susceptible to prolonged duration due to the necessity of encounter scalability issues when the fast programmer NN is
backpropagation-through-time (BPTT) [7] and the potential large, as the slow programmer requires an equal number of
involvement of deep quantum circuits [8]. The primary aim outputneuronsastheconnectionsinthefastprogrammerNN.
of the proposed QFWP model is to emulate the memory Analternativemethodisproposedin[33],wheretheslowNN
capabilities inherent in QRNNs while eliminating the require- includesaspecializedunitforeachunitinthefastNN,labeled
ment for recurrent connections, a notable factor contributing as FROM, corresponding to units from which at least one fast
to prolonged training periods as emphasized in [28], [29]. NNconnectionoriginates.Similarly,theslowNNhasaspecial
Notably, the QFWP model demonstrates comparable time- unitforeachunitinthefastNN,labeledasTO,corresponding
series modeling proficiency to QRNN-based models without tounitstowhichatleastonefastNNconnectionleads.Under
necessitating intricate backpropagation-through-time (BPTT) this configuration, updates for fast NN weights are computed
across quantum circuits or the use of deep quantum circuits. as ∆W (t)=WFROM(t)×WTO(t), where ∆W (t) signifies
ij i j ij
ThisstudyemploystheA3CRLlearningalgorithm[27],[31], the update for fast NN weight Wfast(t). The entire FWP
ij
optimizing the utilization of multiple-core CPU computing model can be optimized end-to-end using gradient-based or
resources. This choice underscores potential applications in gradient-freemethods.FWPhasdemonstratedeffectivenessin
scenariosinvolvingarraysofquantumcomputers.Theworkin solving time-series modeling [33] and reinforcement learning
[32] introduces a framework employing a classical RNN for tasks [35]. The proposed Quantum Fast Weight Programmer
optimizing VQC parameters. This method involves utilizing (QFWP)modeldrawsinspirationfromtheoriginalFWP,with
VQCparametersandobservableoutputsfromprecedingtime- a generalization that the fast programmer can be implemented
steps as inputs to the RNN, generating subsequent VQC using trainable quantum circuits, as detailed in SectionV-A.
parameters. Such an approach demonstrates proficient param-
eter initialization for various VQC-based tasks. Our approach
IV. VARIATIONALQUANTUMCIRCUITS
differssignificantlyfromtheaforementionedmethodaswedo Variational quantum circuits (VQC), also known as pa-
not employ an RNN to generate quantum parameters. Instead, rameterized quantum circuits (PQC), is a special kind of
we utilize a simple feed-forward NN solely responsible for quantum circuit with trainable parameters. VQC has been
updatingquantumparameters.Furthermore,ourapproachdoes used widely in current hybrid quantum-classical computing
not necessitate feeding quantum parameters from the previous framework [3] and shown to have certain kinds of quan-
time-step into the NN for generating new parameters. The tum advantages [36]–[38]. In general, a VQC includes three
motivation behind our approach is to simplify the classical fundamental components: encoding circuit, variational cir-
NN to minimize computational load while achieving our cuit and the final measurements. As shown in Figure3, theclassical FWP
sor networks) or quantum (e.g. other VQCs) components and
output thewholemodelcanbeoptimizedinanend-to-endmannervia
gradient-based [5], [6] or gradient-free [39] methods. When
gradient-based methods such as gradient descent are used, the
input ⋮ Fast gradients of quantum components can be calculated through
⋮ Programmer
the parameter-shift rules [4], [40], [41]. In ordinary VQC-
based ML models, the parameters Θ are randomly initialized
|0⟩ and then updated iteratively. In our proposed QFWP model,
Slow Programmer input these quantum circuit parameters, or more specifically, the
|0⟩
VQC useudp idna qteFsWoPr wchoarknges of the quantum circuit parameters, are the
⋮Fig.2. GeUne(x ri)cStructurVe(oθft 1⃗ a+1F)astVW(θet 2i⃗+g1h)t ⋯PrograVm(mθet l⃗+r1)(FWP ⋮).
output from another classical NN (slow programmer in the
FWP setting).
e|n0co⟩ding circuit U(x) transforms the initial quantum state
|0⟩⊗n into |Ψ⟩ = U(x)|0⟩⊗n. Here the n represents the
number of qubits and the U(x) represents the unitary which |0⟩ H R y(x 1) R y(α 1)
depends on the input value x. The VQC used in this paper
|0⟩ H R y(x 2) R y(α 2)
|0⟩ H R y(x 3) R y(α 3)
|0⟩
|0⟩ H R y(x 4) R y(α 4)
|0⟩
⋮
U(x ) V 1(θ 1⃗ ) V 2(θ 2⃗ )
⋯
V L(θ L⃗ )
⋮
|0⟩ H R y(x 5) R y(α 5)
|0⟩ H R y(x 6) R y(α 6)
|0⟩
|0⟩ H R y(x 7) R y(α 7)
Fig.3. GenericStructureofaVariationalQuantumCircuit(VQC). |0⟩ H R y(x 8) R y(α 8)
is shown in Figure 4. The encoding layer U(x) includes L
×
Hadamard gates on all qubits to initialize an unbiased state
H|0⟩⊗···⊗H|0⟩=(cid:80)
(q1,q2,...,qn)∈{0,1}n
√1
2n
|q 1⟩⊗|q 2⟩⊗
Fig.4. VQCusedinthispaper.
··· ⊗ |q ⟩ and R gates with rotation angles correspond-
n y
ing to the input data x ,··· ,x . It can be expressed as
1 n
U(x) = R (x )H ⊗ ··· ⊗ R (x )H. The encoded state V. METHODS
y 1 y n
then go through the variational circuit (shown in dashed box) A. Quantum FWP
which includes multiple layers of trainable quantum circuits
Intheproposedquantumfastweightprogrammers(QFWP),
V (θ⃗). The V circuit block used in this work is shown
j j j we employ the hybrid quantum-classical architecture to lever-
in the boxed region in Figure 4 and can be implemented
age the best part from both the quantum and classical worlds.
L repetitions to increase the number of trainable parame-
We employ the classical neural networks to build the slow
ters. Each of the V circuit block includes CNOT gates to
j networks, which will generate the values to update the pa-
entangle quantum information and parameterized R gates.
y rameters of the fast networks, which is actually a VQC. As
The overall action W(Θ) in the trainable part is therefore
showninFigure5,theinputvector⃗xisloadedintotheclassical
W(Θ) = V (θ⃗ )V (θ⃗ )···V (θ⃗) where L represents
L L L−1 L−1 1 1 neural network encoder, the output from the encoder network
the number of layers and Θ is the collection of all trainable
is then processed by another two neural networks. One of the
parameters θ⃗ ···θ⃗ . The measurement process furnishes data
1 L network will generate an output vector [L ] with the length
i
by evaluating a subset or entirety of the qubits, generating
equals to the number of VQC layers, and the other network
a classical bit sequence for subsequent utilization. Executing
will generate an output vector [Q ] with the length equals to
j
thecircuitonceproducesabitsequencesuchas”0,0,1,1.”Yet,
the number of qubits of the VQC. We then calculate the outer
conducting the circuit multiple times (shots) provides expec-
product of [L ] and [Q ]. It can be written as [L ]⊗[Q ] =
i j i j
tation values for each qubit. This study particularly focuses  
L ×Q L ×Q ··· L ×Q
1 1 1 2 1 n
on the evaluation of Pauli-Z expectation values derived from
L 2×Q 1 L 2×Q 2 ··· L 2×Q n
m VQea Csu ure sm eden ints ti hn isV wQ oC rks. iT sh − fe − (xm − ;−a Θ→th )em =a (cid:16)tic (cid:68)a Zˆl e (cid:69)xp ,r ·e ·s ·s ,io (cid:68)n Zˆof (cid:69)(cid:17)the
,
[M ij]=[L i×Q j]= 

. .
.
... . .
.
  ,
1 n
where (cid:68) Zˆ k(cid:69) =(cid:68) 0(cid:12) (cid:12) (cid:12)U†(x)W†(Θ)Zˆ kW(Θ)U(x)(cid:12) (cid:12) (cid:12)0(cid:69) . wherel isthenumberoL fl l× earQ na1 bleL lal y× erQ s2 inV· Q·· CaL ndl× nQ isn the
Inthehybridquantum-classicalframework,theVQCcanbe number of qubits. At time t+1, we can calculate the updated
integratedwithotherclassical(e.g.deepneuralnetworks,ten- VQC parameters as θt+1 = f(θt ,L × Q ), where f is a
ij ij i j
⋮
⋮
⋮function to combine the parameters from the previous time- 8×8+8=72 parameters. Considering an 8-qubit VQC with
step θt and the newly computed L ×Q . In the time series 2 variational layers as the fast programmer, the total quantum
ij i j
modeling and RL tasks considered in this work, we adopted parameters subject to slow programmer updating amount to
the additive update rule in which the new circuit parameters 8×2=16. Measurement is performed on only 4 qubits from
are calculated according to θt+1 = θt +L ×Q . Through the fast programmer, followed by a post-processing NN (with
ij ij i j
this method, the information from previous time steps can be 4×1+1=5parameters)togeneratethefinalresult.Thispost-
kept in the form of circuit parameters and affect the VQC processingNNfollowsthesamestructureastheoneemployed
behavior when a new input ⃗x is given. The output from the in [30]. In the time-series modeling experiments conducted,
VQC can be further processed by other components such as solely the first qubit is employed for loading the time-series
scaling, translation or a classical neural network to refine the data, given that only one value is present at each time-step.
Quantum Fast Weight Programmer
final results. The number of parameters for both the proposed QFWP and
the QLSTM model baseline, as reported in [30], are detailed
in TableI.
⋮
LAYER: [L i]
⋮
⋮ [L i]⊗[Q j] NUMBEROFPARAMETERST IA NB QL FE WI
PANDQLSTMMODELS.
⋮
⋮ QUBIT: [Q j] modify parameters QLSTM[30] QFWP
⋮ Classical Quantum Classical Quantum
input θ(t+1) ij=f(θ(t) ij,L i×Q j) DampedSHM/Bessel 5 144 111 16
NARMA5/NARMA10 5 288 111 16
|0⟩
1) Function Approximation-Damped SHM: Damped har-
|0⟩
⋮
U(x) V(θt 1⃗+1) V(θt 2⃗+1)⋯V(θt l⃗+1)
⋮
output monic oscillators find utility in representing or approximating
diverse systems, such as mass-spring systems and acoustic
|0⟩
systems. The dynamics of damped harmonic oscillations are
encapsulated by the following equation:
Fig.5. QuantumFastWeightProgrammers
d2x dx
+2ζω +ω2x=0, (1)
dt2 0dt 0
VI. EXPERIMENTS
(cid:113)
In this research, we use the following open-source package where ω = k is the (undamped) system’s characteristic
0 m
to perform the simulation. We use the PennyLane [41] for the frequency and ζ = √c is the damping ratio. In this paper,
2 mk
construction of quantum circuits and PyTorch for the overall weconsideraspecificexamplefromthesimplependulumwith
hybrid quantum-classical model building. the following formulation:
A. Time-Series Modeling d2θ b dθ g
+ + sinθ =0, (2)
dt2 m dt L
We explore four distinct cases (Damped SHM, Bessel
function, NARMA5, and NARMA10), previously examined in which the gravitational constant g = 9.81, the damping
in related studies, to assess the performance of the pro- factor b = 0.15, the pendulum length l = 1 and mass
posed QFWP against quantum RNN-based methods [7], [30]. m=1.Theinitialconditionatt=0hasangulardisplacement
The training and testing methodology follows the approach θ = 0, and the angular velocity θ˙ = 3 rad/sec. We present
outlined in [7], [30]. In essence, the model is tasked with the QFWP learning result of the angular velocity θ˙. As
predicting the (N +1)-th value, given the first N values in depicted in Figure 6, the QFWP successfully captures the
the sequence. For instance, if at time-step t, the input to the periodic features after just a single epoch of training, and it
model is [x ,x ,x ,x ] (where N = 4), the model approximately captures the essential amplitude features after
t−4 t−3 t−2 t−1
is expected to generate the output y , which ideally should 15 epochs of training. The performance of QFWP in this
t
closely align with the ground truth x . In all experiments context is comparable to the previously reported results of
t
regarding time-series modeling, we set N =4. The presented a fully trained QLSTM model in [30]. While QFWP does
results showcase the ground truth through an orange dashed not surpass the fully trained QLSTM in performance, it is
line, while the blue solid line represents the output from the noteworthy that the function-fitting performance is closely
models.Theverticalreddashedlinedelineatesthetrainingset matched, and QFWP is, in fact, a smaller model, as indicated
(left)fromthetestingset(right).Acrossalldatasetsconsidered in TableI.
inthispaper,67%ofthedataisallocatedfortraining,withthe 2) Function Approximation-Bessel Function: Bessel func-
remaining33%dedicatedtotesting.TheslowprogrammerNN tions are commonly encountered in various physics and
fortime-seriesmodelingtaskswithintheQFWPcomprisesan engineering applications, particularly in scenarios such as
encoder with 1×8+8=16 parameters, a NN for layer index electromagnetic fields or heat conduction within cylindrical
with8×2+2=18parameters,andaNNforqubitindexwith geometries. Bessel functions of the first kind, denoted as1.0
0.5 0.5
Epoch 1 0.0 Epoch 1 0.0
0.5 0.5
Ground Truth Ground Truth
1.0 Prediction 1.0 Prediction
1.0
0.5 0.5
Epoch 15 0.0 Epoch 15 0.0
0.5 0.5
1.0 1.0
1.0
0.5 0.5
Epoch 30 0.0 Epoch 30 0.0
0.5 0.5
1.0 1.0
1.0
0.5 0.5
Epoch 100 0.0 Epoch 100 0.0
0.5 0.5
1.0 1.0
Time Time
Fig.6. Results:QuantumFWPfordampedSHM. Fig.7. Results:QuantumFWPforBesselfunctionJ2.
TABLEII TABLEIII
RESULTS:TIME-SERIESMODELING-DAMPEDSHM RESULTS:TIME-SERIESMODELING-BESSELFUNCTIONJ2
QLSTM[30] QFWP QLSTM[30] QFWP
Epoch1 1.66×10−1/1.35×10−2 3.33×10−1/3.26×10−2 Epoch1 1.04×10−1/1.66×10−2 1.17×10−1/1.58×10−2
Epoch15 2.89×10−2/5.53×10−3 7.21×10−2/1.65×10−2 Epoch15 2.30×10−2/5.35×10−3 1.22×10−2/4.56×10−3
Epoch30 9.06×10−3/3.41×10−4 5.96×10−2/1.34×10−2 Epoch30 1.27×10−2/2.42×10−3 5.52×10−3/7.80×10−4
Epoch100 2.86×10−3/1.94×10−4 1.09×10−2/2.70×10−3 Epoch100 6.97×10−4/1.21×10−5 8.57×10−4/2.30×10−3
J (x), serve as solutions to the Bessel differential equation
α NARMA series that we use in this work can be defined by
given by:
[43]:
x2 dd x2y
2
+x dd xy +(cid:0) x2−α2(cid:1) y =0, (3)  n (cid:88)o−1 
and can be defined as
y t+1 =αy t+βy t y t−j+γu t−no+1u t+δ (5)
j=0
(cid:88)∞ (−1)m (cid:16)x(cid:17)2m+α
J (x)= , (4) where (α,β,γ,δ) = (0.3,0.05,1.5,0.1) and n is used to
α m=0m!Γ(m+α+1) 2 determinethenonlinearity.Theinput{u t}M t=1for0 theNARMA
where Γ(x) is the Gamma function. In this study, we specif- tasks is:
ically opt for J
2
as the function used for QFWP training. As (cid:18) (cid:18) 2πα¯t(cid:19) (cid:18) 2πβ¯t(cid:19) (cid:18) 2πγ¯t(cid:19) (cid:19)
illustrated in Figure7, the QFWP adeptly captures periodic u t =0.1 sin T sin T sin T +1 (6)
featuresafterjustasingleepochoftrainingandapproximately
captures essential amplitude features after 15 epochs. The where (α¯,β¯,γ¯,T) = (2.11,3.73,4.11,100) as used in [44].
QFWP demonstrates a nearly perfect approximation of the J We set the length of inputs and outputs to M = 300. In
2
functionafter100epochsoftraining.AsindicatedinTableIII, this paper, we consider n = 5 and n = 10, NARMA5
0 0
despite the smaller size of the QFWP model compared to and NARMA10 respectively. As demonstrated in Figure 8
QLSTM,asreportedin[30],theQFWPachievesperformance and Figure9, the proposed QFWP successfully captures the
closely aligned with the previously reported QLSTM results. patternsofbothNARMA5andNARMA10aftertraining.The
Notably, at Epochs 15 and 30, the QFWP model achieves complexity of the task in this scenario is notably higher than
training and testing losses lower than those of the QLSTM. that of the previously considered Damped SHM and Bessel
3) Time Series Prediction (NARMA Benchmark): In this functions, requiring a longer time for the model to learn
part of the simulation, we examine the NARMA (Non-linear accurate predictions. As indicated in TableIV and TableV,
Auto-Regressive Moving Average) time series [42] to assess the QFWP model achieves performance closely aligned with
theQFWP’scapabilityinnonlineartimeseriesmodeling.The the QLSTM model results, as previously reported in [30]. Itis worth noting that the QFWP model exhibits a smaller size 0.24
than QLSTM, as detailed in TableI. 0.22
Epoch 1 0.20
0.18
0.22
0.16 Ground Truth
Prediction
0.20
Epoch 1 0.24
0.18
0.22
0.16 G Prr eo du in cd ti oT nruth Epoch 15 0.20
0.18
0.22
0.16
0.20
Epoch 15 0.24
0.18 0.22
0.16 Epoch 30 0.20
0.18
0.22 0.16
0.14
0.20
Epoch 30 0.24
0.18
0.22
0.16 Epoch 100 0.20
0.18
0.22
0.16
0.20
Epoch 100 Time
0.18
Fig.9. Results:QuantumFWPforNARMA10.
0.16
0.14
Time only the first three actions bear practical significance within
Fig.8. Results:QuantumFWPforNARMA5.
thiscontext,demandingtheagent’sdiscernment.Furthermore,
successfulnavigationtothegoalendowstheagentwithascore
of1.Yet,thisachievementistemperedbyapenaltycomputed
TABLEIV
RESULTS:TIME-SERIESMODELING-NARMAvq5FWP in QRLvia 1−0.9×(number of steps/max steps allowed), with the
maximum steps permitted set at 4×n×n, predicated on the
QLSTM[30] QFWP
grid size n [45]. We consider the two cases with n = 5 and
Epoch1 3.99×10−3/4.07×10−4 4.44×10−2/3.48×10−4
Epoch15 3.30×10−4/4.23×10−4 2.99×10−4/8.76×10−5 n=6 in this study.
Epoch30 1.86×10−4/2.06×10−4 2.71×10−4/1.57×10−4
Epoch100 9.85×10−5/2.52×10−5 5.15×10−5/1.68×10−5
(a) (b)
TABLEV
RESULTS:TIME-SERIESMODELING-NARMA10
QLSTM[30] QFWP
Epoch1 4.19×10−3/4.71×10−4 4.43×10−2/9.00×10−5
Epoch15 3.35×10−4/4.73×10−4 4.95×10−4/2.24×10−4
Epoch30 3.20×10−4/3.74×10−4 2.79×10−4/1.56×10−4
Epoch100 2.59×10−4/9.50×10−5 2.58×10−4/9.70×10−5
B. Reinforcement Learning
Fig.10. MiniGridenvironments.
1) Environments: Within this study, we engage the
MiniGrid-Empty environment, a widely utilized maze nav- 2) QLSTM baseline: The proposed QFWP model has the
igation framework [45]. The primary focus of our QRL capability to memorize the information of previous time-steps
agent is to craft effective action sequences based on real- in the form of quantum circuit parameters. In quantum RL,
time observations, facilitating traversal from the starting point quantum recurrent neural networks (QRNN) can be used to
to the green box as illustrated in Figure 10. Noteworthy is achieve the same goal. Here, we consider the QLSTM-based
thedistinctivefeatureoftheMiniGrid-Emptyenvironment—a QRL agent developed in the works [28], [29]. To improve
147-dimensional observation vector denoted as s . This en- the training efficiency, we employ the asynchronous methods
t
vironment offers an action spectrum, denoted as A, encom- [27],[31].WeconsiderQLSTMmodelswithdifferentnumber
passing six actions: turn left, turn right, move forward, pick of VQC layers to evaluate how good the proposed QFWP
up an object, drop the carried object, and toggle. However, model is. The QLSTM models we consider in this workare of a structure as shown in Figure11. In this simulation, NN is 147×8+8 = 1184. Outside the main QFWP model,
we employ classical neural networks (NNs) for two primary there are two NN for processing the outputs from QFWP to
purposes:compressingtheinputvectortoadimensionsuitable generate the final action logits and state values. The number
for quantum simulation and processing the output from a of parameters of these two NNs are 8 × 6 + 6 = 54 and
QLSTM to derive final results. Specifically, we utilize an 8- 8 × 1 + 1 = 9, respectively. The entire architecture of the
qubit QLSTM, allocating the initial 4 qubits for input and QFWP as a RL agent is depicted in Figure12. We summarize
QFWP as QRL agent
the subsequent 4 qubits for the hidden dimension. The NN the number of parameters of QFWP in TableVI.
responsible for transforming the input vector into a com-
pressed representation possesses an input dimension of 147
and an output dimension of 4 (with a number of parameters:
⋮
LAYER:[L i]
147×4+4=592).Additionally,weincorporatetwootherNNs ⋮
intothesystem:onefortranslatingQLSTMoutputsintoaction ⋮
[L i]⊗[Q j]
⋮
logits (referred to as the ”actor”) and another for determining ⋮ QUBIT:[Q j] modify parameters
the state value (referred to as the ”critic”). Both NNs share ⋮ θ(t+1)ij=θ(t)ij+Li×Qj
input
an input dimension equivalent to the hidden dimension of the
QLSTM(whichinthiscaseis4).TheactorNNhasanoutput Action
|0⟩ logits
dimension of 6, while the critic NN has an output dimension
|0⟩
of1.ThenumberofparametersfortheactorNNiscalculated ⋮ ⋮ ⋮ U(x) V(θt 1⃗+1) V(θt 2⃗+1)⋯V(θtl⃗+1) ⋮
as 4×6+6=30, and for the critic NN, it is 4×1+1=5. |0⟩ State
The number of quantum circuit parameters in QLSTM with ⋮ value
n VQC layer is: 8×3×5×n = 120n in which the VQCs
Fig.12. QFWPasaRLagent.
are 8-qubit and each general rotation gate is parameterized by
QLSTM baseline in qFWP
3 parameters (angles). There are 5 VQCs in a QLSTM. The
detailed description of QLSTM can be found in [7], [30]. We
TABLEVI
summarize the number of parameters of QLSTM we compare NUMBEROFPARAMETERSINQFWPANDQLSTMMODELSINQRL
in this work in TableVI. EXPERIMENTS.
Classical Quantum
QLSTM-2VQCLayer 627 240
QLSTM-4VQCLayer 627 480
Action QLSTM-6VQCLayer 627 720
logits QLSTM-8VQCLayer 627 960
QLSTM-10VQCLayer 627 1200
QuantumFWP-2VQCLayer 2521 16
input QuantumFWP-4VQCLayer 2539 32
⋮ State
⋮ ⋮ value
4) Hyperparameters: The hyperparameters for the pro-
posed QFWP in RL with QA3C training [27], [29] are
Fig.11. QLSTMbaselineusedinthiswork.
configured as follows: Adam optimizer with a learning rate of
3) QFWP in RL: The QFWP used in this part of the 1×10−4, beta = 0.92, beta = 0.999, model lookup steps
1 2
simulation includes a classical NN-based slow programmer denotedasL=5,andadiscountfactorγ =0.9.IntheQA3C
which is consisted of a slow programmer encoder (with trainingprocess,thelocalagentsormodelscalculatetheirown
number of parameter (state dim+1)×latent dim) and two gradientseveryLsteps,whichcorrespondstothelengthofthe
separate NN for generating parameter updates for different trajectory used during model updates. The number of parallel
quantum layer (with number of parameter (latent dim + processes (local agents) is 80. We present the average score
1) × num VQC layer) and qubit indexes (with number of along with its standard deviation over the past 5,000 episodes
parameter (latent dim + 1) × num qubits) as shown in to illustrate both the trend and stability.
Figure5. The state dim and num qubits here are set to be 5) Results: MiniGrid-Empty-5x5 As depicted in Fig-
8. There are 147 × 8 + 8 = 1184 parameters in the slow ure13, the QFWP with two and four VQC layers surpasses
programmer encoder, (8+1)×num VQC layer in the NN all considered QLSTM models. The QFWP not only attains
for different quantum layers and 8×8+8 = 72 in the NN higher scores but also achieves these results more rapidly, as
forqubitindexes.Thefastprogrammer isconsistedofaVQC measured by the number of training episodes. For instance,
with architecture described in Figure4. We consider 8-qubit the QLSTM model with 10 VQC layers eventually achieves
VQCs with L = 2 and L = 4 in this part of simulation. the optimal score, but this accomplishment requires approxi-
The number of quantum parameters are therefore 16 and mately 60,000 episodes. Additionally, we observe that QFWP
32, respectively. In addition, there is a NN for transforming models, once reaching optimal scores, exhibit greater stability
input observation vector into a compressed vector suitable for compared to QLSTM models.
existing VQC simulation. The number of parameters for this MiniGrid-Empty-6x6 As illustrated in Figure14, the QFWP
⋮ ⋮
⋮ ⋮with two and four VQC layers outperforms all considered
QLSTM models. The QFWP not only attains higher scores
but also achieves these results more rapidly, as indicated by
the number of training episodes. For instance, the QLSTM
model with 6 VQC layers also reaches the optimal score, but
this accomplishment requires approximately 80,000 episodes.
Furthermore, we observe that QFWP models, once achieving
optimal scores, exhibit greater stability compared to QLSTM
models.
VII. CONCLUSION
In this study, we introduce a hybrid quantum-classical
framework of fast weight programmers for time-series mod-
eling and reinforcement learning. Specifically, classical neural
networksfunctionasslowprogrammers,generatingupdatesor
changesforfastprogrammersimplementedthroughvariational
quantumcircuits.Weassesstheproposedmodelintime-series
prediction and reinforcement learning tasks. Our numerical
simulation results demonstrate that our framework achieves
time-series prediction capabilities comparable to fully trained
quantum long short-term memory (QLSTM) models reported
in prior works. Furthermore, our model exhibits superior
performance in navigation tasks, surpassing QLSTM models
with higher stability and average scores under quantum A3C
Fig.13. Results:QuantumFWPinMiniGrid-Empty-5x5environment. training. The proposed approach establishes an efficient av-
enueforpursuinghybridquantum-classicalsequentiallearning
without the need for quantum recurrent neural networks.
REFERENCES
[1] M.A.NielsenandI.L.Chuang,“Quantumcomputationandquantum
information,”2010.
[2] J.Preskill,“Quantumcomputinginthenisqeraandbeyond,”Quantum,
vol.2,p.79,2018.
[3] K. Bharti, A. Cervera-Lierta, T. H. Kyaw, T. Haug, S. Alperin-Lea,
A.Anand,M.Degroote,H.Heimonen,J.S.Kottmann,T.Menkeetal.,
“Noisy intermediate-scale quantum algorithms,” Reviews of Modern
Physics,vol.94,no.1,p.015004,2022.
[4] K. Mitarai, M. Negoro, M. Kitagawa, and K. Fujii, “Quantum circuit
learning,”PhysicalReviewA,vol.98,no.3,p.032309,2018.
[5] J.Qi,C.-H.H.Yang,andP.-Y.Chen,“Qtn-vqc:Anend-to-endlearning
frameworkforquantumneuralnetworks,”PhysicaScripta,vol.99,12
2023.
[6] S.Y.-C.Chen,C.-M.Huang,C.-W.Hsing,andY.-J.Kao,“Anend-to-
end trainable hybrid classical-quantum classifier,” Machine Learning:
ScienceandTechnology,vol.2,no.4,p.045021,2021.
[7] S. Y.-C. Chen, S. Yoo, and Y.-L. L. Fang, “Quantum long short-term
memory,” in ICASSP 2022-2022 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2022, pp.
8622–8626.
[8] J. Bausch, “Recurrent quantum neural networks,” Advances in neural
informationprocessingsystems,vol.33,pp.1368–1379,2020.
[9] C. Chu, G. Skipper, M. Swany, and F. Chen, “Iqgan: Robust quantum
generativeadversarialnetworkforimagesynthesisonnisqdevices,”in
ICASSP2023-2023IEEEInternationalConferenceonAcoustics,Speech
andSignalProcessing(ICASSP). IEEE,2023,pp.1–5.
[10] S. A. Stein, B. Baheri, D. Chen, Y. Mao, Q. Guan, A. Li, B. Fang,
and S. Xu, “Qugan: A quantum state fidelity based generative adver-
sarial network,” in 2021 IEEE International Conference on Quantum
ComputingandEngineering(QCE). IEEE,2021,pp.71–81.
[11] C.-H. H. Yang, J. Qi, S. Y.-C. Chen, P.-Y. Chen, S. M. Siniscalchi,
Fig.14. Results:QuantumFWPinMiniGrid-Empty-6x6environment.
X.Ma,andC.-H.Lee,“Decentralizingfeatureextractionwithquantum
convolutional neural network for automatic speech recognition,” in
ICASSP2021-2021IEEEInternationalConferenceonAcoustics,Speech
andSignalProcessing(ICASSP). IEEE,2021,pp.6523–6527.[12] S.S.Li,X.Zhang,S.Zhou,H.Shu,R.Liang,H.Liu,andL.P.Garcia, [34] ——, “Reducing the ratio between learning complexity and number
“Pqlm-multilingualdecentralizedportablequantumlanguagemodel,”in of time varying variables in fully recurrent nets,” in ICANN’93: Pro-
ICASSP2023-2023IEEEInternationalConferenceonAcoustics,Speech ceedingsoftheInternationalConferenceonArtificialNeuralNetworks
andSignalProcessing(ICASSP). IEEE,2023,pp.1–5. Amsterdam,TheNetherlands13–16September19933. Springer,1993,
[13] C.-H.H.Yang,J.Qi,S.Y.-C.Chen,Y.Tsao,andP.-Y.Chen,“Whenbert pp.460–463.
meets quantum temporal convolution learning for text classification in [35] F.GomezandJ.Schmidhuber,“Evolvingmodularfast-weightnetworks
heterogeneous computing,” in ICASSP 2022-2022 IEEE International forcontrol,”inInternationalConferenceonArtificialNeuralNetworks.
Conference on Acoustics, Speech and Signal Processing (ICASSP). Springer,2005,pp.383–389.
IEEE,2022,pp.8602–8606. [36] A.Abbas,D.Sutter,C.Zoufal,A.Lucchi,A.Figalli,andS.Woerner,
[14] R.DiSipio,J.-H.Huang,S.Y.-C.Chen,S.Mangini,andM.Worring, “The power of quantum neural networks,” Nature Computational Sci-
“Thedawnofquantumnaturallanguageprocessing,”inICASSP2022- ence,vol.1,no.6,pp.403–409,2021.
2022 IEEE International Conference on Acoustics, Speech and Signal [37] M. C. Caro, H.-Y. Huang, M. Cerezo, K. Sharma, A. Sornborger,
Processing(ICASSP). IEEE,2022,pp.8612–8616. L.Cincio,andP.J.Coles,“Generalizationinquantummachinelearning
[15] J.Stein,I.Christ,N.Kraus,M.B.Mansky,R.Mu¨ller,andC.Linnhoff- fromfewtrainingdata,”Naturecommunications,vol.13,no.1,pp.1–
Popien,“Applyingqnlptosentimentanalysisinfinance,”in2023IEEE 11,2022.
International Conference on Quantum Computing and Engineering [38] Y. Du, M.-H. Hsieh, T. Liu, and D. Tao, “Expressive power of
(QCE),vol.2. IEEE,2023,pp.20–25. parametrizedquantumcircuits,”PhysicalReviewResearch,vol.2,no.3,
[16] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural p.033125,2020.
computation,vol.9,no.8,pp.1735–1780,1997. [39] S.Y.-C.Chen,C.-M.Huang,C.-W.Hsing,H.-S.Goan,andY.-J.Kao,
[17] A.Vaswani,N.Shazeer,N.Parmar,J.Uszkoreit,L.Jones,A.N.Gomez, “Variationalquantumreinforcementlearningviaevolutionaryoptimiza-
Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” Advances in tion,” Machine Learning: Science and Technology, vol. 3, no. 1, p.
neuralinformationprocessingsystems,vol.30,2017. 015025,2022.
[18] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G. [40] M.Schuld,V.Bergholm,C.Gogolin,J.Izaac,andN.Killoran,“Eval-
Bellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski uating analytic gradients on quantum hardware,” Physical Review A,
et al., “Human-level control through deep reinforcement learning,” vol.99,no.3,p.032331,2019.
nature,vol.518,no.7540,pp.529–533,2015. [41] V. Bergholm, J. Izaac, M. Schuld, C. Gogolin, C. Blank, K. McK-
[19] D. Dong, C. Chen, H. Li, and T.-J. Tarn, “Quantum reinforcement iernan, and N. Killoran, “Pennylane: Automatic differentiation of hy-
learning,” IEEE Transactions on Systems, Man, and Cybernetics, Part bridquantum-classicalcomputations,”arXivpreprintarXiv:1811.04968,
B(Cybernetics),vol.38,no.5,pp.1207–1220,2008. 2018.
[20] S. Y.-C. Chen, C.-H. H. Yang, J. Qi, P.-Y. Chen, X. Ma, and H.-S. [42] A. F. Atiya and A. G. Parlos, “New results on recurrent network
Goan, “Variational quantum circuits for deep reinforcement learning,” training: unifying the algorithms and accelerating convergence,” IEEE
IEEEAccess,vol.8,pp.141007–141024,2020. transactionsonneuralnetworks,vol.11,no.3,pp.697–709,2000.
[21] O. Lockwood and M. Si, “Reinforcement learning with quantum vari- [43] A. Goudarzi, P. Banda, M. R. Lakin, C. Teuscher, and D. Stefanovic,
ational circuit,” in Proceedings of the AAAI Conference on Artificial “A comparative study of reservoir computing for temporal signal pro-
IntelligenceandInteractiveDigitalEntertainment,vol.16,no.1,2020, cessing,”arXivpreprintarXiv:1401.2224,2014.
pp.245–251. [44] Y.Suzuki,Q.Gao,K.C.Pradel,K.Yasuoka,andN.Yamamoto,“Nat-
[22] A. Skolik, S. Jerbi, and V. Dunjko, “Quantum agents in the gym: a uralquantumreservoircomputingfortemporalinformationprocessing,”
variationalquantumalgorithmfordeepq-learning,”Quantum,vol.6,p. Scientificreports,vol.12,no.1,pp.1–15,2022.
720,2022. [45] M. Chevalier-Boisvert, L. Willems, and S. Pal, “Minimalistic grid-
[23] J.-Y. Hsiao, Y. Du, W.-Y. Chiang, M.-H. Hsieh, and H.-S. Goan, world environment for openai gym,” https://github.com/maximecb/
“Unentangled quantum reinforcement learning agents in the openai gym-minigrid,2018.
gym,”arXivpreprintarXiv:2203.14348,2022.
[24] Q. Lan, “Variational quantum soft actor-critic,” arXiv preprint
arXiv:2112.11921,2021.
[25] S. Jerbi, C. Gyurik, S. Marshall, H. J. Briegel, and V. Dunjko, “Vari-
ational quantum policies for reinforcement learning,” arXiv preprint
arXiv:2103.05577,2021.
[26] M. Ko¨lle, M. Hgog, F. Ritz, P. Altmann, M. Zorn, J. Stein, and
C.Linnhoff-Popien,“Quantumadvantageactor-criticforreinforcement
learning,”arXivpreprintarXiv:2401.07043,2024.
[27] S. Y.-C. Chen, “Asynchronous training of quantum reinforcement
learning,” Procedia Computer Science, vol. 222, pp. 321–330, 2023,
international Neural Network Society Workshop on Deep Learning
InnovationsandApplications(INNSDLIA2023).[Online].Available:
https://www.sciencedirect.com/science/article/pii/S1877050923009365
[28] ——, “Quantum deep recurrent reinforcement learning,” in ICASSP
2023-2023 IEEE International Conference on Acoustics, Speech and
SignalProcessing(ICASSP). IEEE,2023,pp.1–5.
[29] ——,“Efficientquantumrecurrentreinforcementlearningviaquantum
reservoircomputing,”arXivpreprintarXiv:2309.07339,2023.
[30] S. Y.-C. Chen, D. Fry, A. Deshmukh, V. Rastunkov, and C. Stefanski,
“Reservoir computing via quantum recurrent neural networks,” arXiv
preprintarXiv:2211.02612,2022.
[31] V. Mnih, A. P. Badia, M. Mirza, A. Graves, T. Lillicrap, T. Harley,
D.Silver,andK.Kavukcuoglu,“Asynchronousmethodsfordeeprein-
forcement learning,” in International conference on machine learning.
PMLR,2016,pp.1928–1937.
[32] G. Verdon, M. Broughton, J. R. McClean, K. J. Sung, R. Babbush,
Z. Jiang, H. Neven, and M. Mohseni, “Learning to learn with quan-
tum neural networks via classical neural networks,” arXiv preprint
arXiv:1907.05415,2019.
[33] J.Schmidhuber,“Learningtocontrolfast-weightmemories:Analterna-
tivetodynamicrecurrentnetworks,”NeuralComputation,vol.4,no.1,
pp.131–139,1992.