Robustly Learning Single-Index Models via Alignment Sharpness
Nikos Zarifis∗‖ Puqian Wang†‖ Ilias Diakonikolas‡
UW Madison UW Madison UW Madison
zarifis@wisc.edu pwang333@wisc.edu ilias@cs.wisc.edu
Jelena Diakonikolas§
UW Madison
jelena@cs.wisc.edu
Abstract
We study the problem of learning Single-Index Models under the L2 loss in the agnostic
2
model. We give an efficient learning algorithm, achieving a constant factor approximation to the
optimal loss, that succeeds under a range of distributions (including log-concave distributions)
and a broad class of monotone and Lipschitz link functions. This is the first efficient constant
factor approximate agnostic learner, even for Gaussian data and for any nontrivial class of link
functions. Prior work for the case of unknown link function either works in the realizable setting
or does not attain constant factor approximation. The main technical ingredient enabling our
algorithm and analysis is a novel notion of a local error bound in optimization that we term
alignment sharpness and that may be of broader interest.
∗Supported in part by NSF Medium Award CCF-2107079 and NSF award 2023239.
†Supported in part by NSF Award CCF-2007757.
‡Supported by NSF Medium Award CCF-2107079 and a DARPA Learning with Less Labels (LwLL) grant.
§Supported by NSF Award CCF-2007757 and by the U. S. Office of Naval Research under award number N00014-
22-1-2348.
‖Equal contribution.
4202
beF
72
]GL.sc[
1v65771.2042:viXra1 Introduction
Single-index models (SIMs) [Ich93, HJS01, HMS+04, DJS08, KS09, KKSK11, DH18] are a classical
supervised learning model extensively studied in statistics and machine learning. SIMs capture
the common assumption that the target function f depends on an unknown direction w, i.e.,
f(x) = u(w·x) for some link (a.k.a. activation) function u : R (cid:55)→ R and w ∈ Rd. In most settings,
the link function is unknown and is assumed to satisfy certain regularity properties. Classical
works [KS09, KKSK11] studied the efficient learnability of SIMs for monotone and Lipschitz link
functions and data distributed on the unit ball. These early algorithmic results succeed in the
realizable setting (i.e., with clean labels) or in the presence of zero-mean label noise.
The focus of this work is on learning SIMs in the challenging agnostic (or adversarial label noise)
model [Hau92, KSS94], where no assumptions are made on the labels of the examples and the goal
is to compute a hypothesis that is competitive with the best-fit function in the class. Importantly, as
will be formalized below, we will not assume a priori knowledge of the link function. In more detail,
let D be a distribution on labeled examples (x,y) ∈ Rd×R and L (h) = E [(h(x)−y)2] be
2 (x,y)∼D
the squared loss of the hypothesis h : Rd → R with respect to D. Given i.i.d. samples from D, the
goal of the learner is to output a hypothesis h with squared error competitive with OPT, where
OPT = inf L (f) is the best attainable error by any function in the target class C.
f∈C 2
In the context of this paper, the class C above is the class of SIMs, i.e., all functions of the form
f(x) = u(w·x) where both the weight vector w and the link function u are unknown. For this task
to be even information-theoretically solvable, one requires some assumptions on the vector w and the
link function u. We will assume, as is standard, that the ℓ -norm of w is bounded by a parameter
2
W. We will similarly assume that the link function lies in a family of well-behaved functions that
are monotone and satisfy certain Lipschitz properties (see Definition 1.3).
For a weight vector w and link function u, the L2 loss of the SIM hypothesis u(w·x) (defined by
2
u and w) is L (w;u) = E [(u(w·x)−y)2]. Our problem of robustly learning SIMs is defined
2 (x,y)∼D
as follows.
Problem 1.1 (Robustly Learning Single-Index Models). Fix a class of distributions G on Rd and a
class of link functions1 F. Let D be a distribution of labeled examples (x,y) ∈ Rd×R such that its
x-marginal D belongs to G. We say that an algorithm is a C-approximate proper SIM learner, for
x
some C ≥ 1, if given ϵ > 0, W > 0, and i.i.d. samples from D, the algorithm outputs a link function
uˆ ∈ F and a vector w ∈ Rd such that with high probability it holds L (w;uˆ) ≤ COPT+ϵ, where
(cid:98) 2 (cid:98)
OPT ≜ min L (w;u).
∥w∥2≤W,u∈F 2
Throughout this paper, we use u∗(w∗·x) to denote a fixed (but arbitrary) optimal solution to
the above learning problem, i.e., one satisfying L (w∗;u∗) = OPT.
2
Some comments are in order. First, Problem 1.1 does not make realizability assumptions on the
distribution D. That is, the labels are allowed to be arbitrary and the goal is to be competitive
against the best-fit function in the class C = {u(w·x) | w ∈ Rd,∥w∥ ≤ W,u ∈ F} . Second, our
2
focus is on obtaining efficient learners that achieve a constant factor approximation to the optimum
loss, i.e., where C in Problem 1.1 is a universal constant — independent of the dimension d and the
radius W of the weight space.
Ideally, one would like an efficient learner that succeeds for all marginal distributions and achieves
optimal error of OPT+ϵ (corresponding to C = 1). Unfortunately, known computational hardness
results rule out this possibility. Even for the very special case that the marginal distribution is
Gaussian and the link function is known (e.g., a ReLU), there is strong evidence that any algorithm
1Throughout this paper, we will use the terms “link function” and “activation” interchangeably.
1achievingerrorOPT+ϵrequiresdpoly(1/ϵ) time[DKZ20,GGK20,DKPZ21,DKR23]. Moreover, even
if we relax our goal to constant factor approximation (i.e., C = O(1)), distributional assumptions
are required both for proper [Sím02, MR18] and improper learning [DKMR22]. As a consequence,
algorithmic research in this area has focused on constant factor approximate learners that succeed
under mild distributional assumptions.
Recent works [DGK+20, DKTZ22, ATV23, WZDD23] gave efficient, constant factor approximate
learners, under natural distributional assumptions, for the special case of Problem 1.1 where the link
function is known a priori (see also [FCG20]). For the general setting, the only prior algorithmic
result was recently obtained in [GGKS23]. Specifically, [GGKS23] gave an efficient algorithm that
succeeds for the class of monotone 1-Lipschitz link functions and any marginal distribution with
second moment bounded by λ. Their algorithm achieves L2 error
2
√ √
O(W λ OPT)+ϵ (1)
under the assumption that the labels are bounded in [0,1]. The error guarantee (1) is substantially
weaker—bothqualitativelyandquantitatively—fromthegoalofthispaper. Firstly,thedependence
on OPT scales with its square root, as opposed to linearly. Secondly, and arguably more importantly,
the multiplicative factor inside the big-O scales (linearly) with the diameter of the space W.
Interestingly, [GGKS23] showed — via a hardness construction from [DKMR22] — that, under
their distributional assumptions, a multiplicative dependence on W (in the error guarantee) is
inherent for efficient algorithms. That is, to obtain an efficient constant factor approximation, it is
necessary to restrict ourselves to distributions with additional structural properties. This discussion
raises the following question:
Can we obtain efficient constant factor learners for Problem 1.1 under mild distributional
assumptions?
The natural goal here is to match the guarantees of known algorithmic results for the special case of
known link function [DKTZ22, WZDD23].
As our main contribution, we answer this question in the affirmative. That is, we give the
first efficient constant-factor approximate learner that succeeds for natural and broad families of
distributions (including log-concave distributions) and a broad class of link functions. We emphasize
that thisis the first polynomial-time constant factorapproximate learner even for Gaussian marginals
and for any nontrivial class of link functions. Roughly speaking, our distributional assumptions
require concentration and (anti)-anti-concentration (see Definition 1.2).
1.1 Overview of Results
We start by stating the distributional assumptions and defining the family of link functions for which
our algorithm succeeds.
Distributional Assumptions Our algorithm succeeds for the following class of structured
distributions.
Definition 1.2 (Well-Behaved Distributions). Let L,R > 0. Let V be any subspace in Rd of
dimension at most 2. A distribution D on Rd is called (L,R)-well-behaved if for any projection
x
(D ) of D onto subspace V, the corresponding pdf γ on R2 satisfies the following:
x V x V
• For all x ∈ V such that ∥x ∥ ≤ R, γ (x ) ≥ L (anti-anti-concentration).
V V ∞ V V
• For all x
V
∈ V, γ V(x V) ≤ (1/L)(e−L∥xV∥2) (anti-concentration and concentration).
2As a consequence of sub-exponential concentration, we can assume without loss of generality
that the operator norm of E [xx⊤] is bounded above by an absolute constant. For simplicity,
x∼Dx
we take E [xx⊤] ≼ I, which can be ensured by simple rescaling of the data.
x∼Dx
The distribution class of Definition 1.2 was introduced in [DKTZ20], in the context of learning
linear separators with noise, and has since been used in a number of prior works — including for
robustlylearningSIMswithknownlinkfunction[DKTZ22]. TheparametersL,RinDefinition1.2are
viewed as universal constants, i.e., L,R = O(1). Indeed, it is known that many natural distributions,
most importantly isotropic log-concave distributions, fall in this category; see, e.g., [DKTZ20].
Unbounded Activations Our algorithm succeeds for a broad class of link functions that con-
tains many well-studied activations, including ReLUs. This class, defined in [DKTZ22] and used
in [WZDD23], requires the link function to be monotone, Lipschitz-continuous and strictly increasing
in the positive region.
Definition 1.3 (Unbounded Activations). Let u : R (cid:55)→ R. Given a,b ∈ R such that 0 < a ≤ b, we
say that u(z) is (a,b)-unbounded if u(0) = 0 and u(z) is non-decreasing, b-Lipschitz-continuous, and
u(z)−u(z′) ≥ a(z−z′) for all z ≥ z′ ≥ 0. We denote this function class by U .
(a,b)
A simplified version of our main algorithmic result is as follows (see Theorem 4.2 for a more
detailed statement):
Theorem 1.4 (Main Algorithmic Result, Informal). Given Problem 1.1, where G is the class of
(L,R)-well behaved distributions with L,R = O(1) and F = U such that (1/a),b = O(1), there
(a,b)
is an algorithm that draws N = poly(W)O˜(d/ϵ2) samples from D, runs in poly(N,d) time, and
outputs a hypothesis uˆ(w·x) with uˆ ∈ U ,∥w∥ ≤ W such that L (w;uˆ) = COPT+ϵ with high
(cid:98) (a,b) (cid:98) 2 2 (cid:98)
probability, where C > 0 is an absolute constant.
We reiterate that the approximation factor C in Theorem 1.4 is a universal constant, independent
of the dimension and the diameter of the space. That is, our main result provides the first efficient
learning algorithm achieving a constant factor approximation, even for the most basic case of
Gaussian data and any non-trivial class of link functions.
1.2 Technical Overview
When it comes to learning SIMs in the agnostic model with target error COPT+ϵ, to the best of
our knowledge, all prior work that achieves such a guarantee with C being an absolute constant
only applies to the special case of known link function u∗. Such results are established by proving
growth conditions (local error bounds) that relate either the L2 loss or a surrogate loss to (squared)
2
distance to the set of target solutions, using assumptions about the link function and the data
distribution, such as concentration and (anti-)anti-concentration [DGK+20, DKTZ22, WZDD23].
Among these, most relevant to our work is [WZDD23], which proved a “sharpness” property for the
convex surrogate function defined by
(cid:20)(cid:90) w·x (cid:21)
L (w;u) = E (u(r)−y)dr , (2)
sur
(x,y)∼D 0
based on certain assumptions about the link function (that are the same as ours) and distributional
assumptions (that are somewhat weaker but comparable to ours). Their sharpness result corresponds
to guaranteeing that for vectors w that are not already O(OPT)+ϵ accurate solutions, the following
holds:
∇L (w;u∗)·(w−w∗) ≳ ∥w−w∗∥2, (3)
sur 2
3where w∗ is a vector that achieves error O(OPT)+ϵ and u∗ is the (a priori known) link function.
One may hope that the sharpness result of [WZDD23] can be generalized to the case of unknown
link function and leveraged to obtain constant factor robust learners in this more general setting.
However, as we discuss below, such direct generalizations are not possible and there are several
technical challenges that had to be overcome in our work. To illustrate some of the intricacies,
consider first the following example.
Example 1.5. Let x ∼ N(0,I) and w = (1/2)w∗, where w∗ is an arbitrary but fixed target unit
vector. Let b > 2a. Suppose that the link function at hand is u(z) = bz and the target link function
is u∗(z) = az. Observe that both u,u∗ ∈ U , as required by our model. Furthermore, suppose
(a,b)
there is no label noise, in which case OPT = 0. Note that the L2 error of u(w·x) in this case is
2
L (w;u) = E [(u(w·x)−u∗(w∗·x))2]
2
x∼N(0,I)
= E [(b/2−a)2z2] = (b/2−a)2 = Θ(1).
z∼N(0,1)
However, the gradient of the surrogate loss, ∇L (w;u) = E[(u(w·x)−u∗(w∗·x))x], is negatively
sur
correlated with w−w∗, i.e., ∇L (w;u)·(w−w∗) < 0, contrary to what we would hope for if a
sur
sharpness property as in [WZDD23] were to hold. Thus, although w and u are both still far away
from the target parameters w∗ and u∗, the gradient of the surrogate loss cannot provide useful
information about the direction in which to update w.
What Example 1.5 demonstrates is that we cannot hope for the surrogate loss to satisfy a local
error bound for an arbitrary parameter pair (u,w) that would guide the convergence of an algorithm
toward a target parameter pair (u∗,w∗). This seemingly insurmountable obstacle is surpassed by
observing that we do not, in fact, need the surrogate loss to contain a “signal” that would guide
us toward target parameters for an arbitrary pair (u,w). Instead, we can restrict our attention
to pairs (u,w) satisfying that u is a “reasonably good” link function for the vector w. Ideally, we
would like to only consider link functions u that minimize the L2 loss — considering that u∗ must
2
minimize the L2 loss for a given, fixed w∗ — but it is unclear how to achieve that in a statistically
2
and computationally efficient manner. As a natural approach, we consider link functions that
are the best fitting functions in an empirical distribution sense. In particular, given a sample set
S = {(x(i),y(i))}m and a parameter w, we select a function uˆ that solves the following (convex)
i=1 w
optimization problem:
m
1 (cid:88)
uˆ ∈ argmin (u(w·x(i))−y(i))2. (P)
w
m
u∈U
(a,b) i=1
For notational simplicity, we drop the parameter wt from uˆ and use uˆt instead. It is worth pointing
wt
out here that in general the problem of finding the best function that minimizes the L2 error fails
2
under the category of non-parametric regression, which unfortunately requires exponentially many
samples (namely, Ω(1/ϵd)). Fortunately, in our setting, we are looking for the best function that lies
in a one-dimensional space. Therefore, instead of looking at all possible directions, we can project
all the points of the sample set S to the direction w and find the best fitting link function efficiently.
We provide the full details for efficiently solving the optimization problem (P) in Appendix E.
Having set on the “best-fit” link functions in the sense of the problem (P), the next obstacle
one encounters when trying to prove a “sharpness-like” result is that neither the L2 loss nor its
2
surrogate convey information about the scale of w and w∗. This is because models determined by
u,w and u/c,cw for some parameter c > 0 can have the same value of both loss functions. Thus, it
seems unlikely that a more traditional local error bound, as in (3), can be established in general,
4for either the surrogate loss or the original L2 loss. Instead, we prove a weaker property that
2
establishes strong correlation between the gradient of the empirical surrogate loss ∇L(cid:98)sur(wt;uˆt) =
(1/m)(cid:80)m (uˆt(wt ·x(i))−y(i))x(i) and the direction wt −w∗ that holds whenever wt is not an
i=1
O(OPT)+ϵ error solution and which is independent of the scale of wt. This constitutes our key
structural result, stated as Proposition 3.1 and discussed in detail in Section 3. We further discuss
how this result relates to classical and recent local error bounds in Appendix B.
In addition to this weaker version of a sharpness property, we further prove in Corollary 3.4 that
given a parameter wt and a dataset of m samples from D, the activation uˆt(wt·x) generated by
optimizing the empirical risk on the dataset as in (P) satisfies E [(uˆt(wt·x)−u∗(w∗·x))2] ≲
x∼Dx
b2∥wt−w∗∥2 with high probability. As a result, we can guarantee that when ∥wt−w∗∥ decreases,
2 2
the L2 distance between uˆt and u∗ diminishes as well. This is crucial, since without such a coupling
2
we would not be able to argue about convergence over both model parameters u,w.
Leveragingtheseresults,wearriveatanalgorithmthatalternatesbetween“gradientdescent-style”
updates for w and best-fit updates for u. We note in passing that similar alternating updates have
been used in classical work on SIM learning in the less challenging, non-agnostic setting [KKSK11].
In more detail, our algorithm fixes the scale β of ∥wt∥ and alternates between taking a Riemannian
2
gradient descent step on a sphere for wt with respect to the empirical surrogate loss and solving (P).
The unknown scale for the true parameter vector w∗ is resolved by applying this approach using
β chosen from a sufficiently fine grid of the interval [0,W] and employing a testing procedure at
the end to select the best parameter vector. Although the idea is simple, the proof of correctness is
quite technical, as it requires ensuring that the entire process does not accumulate spurious errors
arising from the stochastic nature of the problem, adversarial labels, and approximate minimization
of the surrogate loss, and, as a result, that it converges to the target error.
Technical Comparison to [GGKS23] The only prior work addressing SIM learning (with
unknown link functions) in the agnostic model is [GGKS23], thus here we provide a technical
comparison. While both [GGKS23] and our work make use of the surrogate loss function from
(2), on a technical level the two works are completely disjoint. [GGKS23] uses a framework of
omnipredictors to minimize the surrogate loss and then relates this result to the L2 loss. Although
2
they handle more general distributions and activations, their learner outputs a hypothesis with error
that cannot be considered constant factor approximation (see (1)) and is improper. By contrast, our
work does not seek to minimize the surrogate loss. Instead, our main insight is that the gradient of
the surrogate loss at a vector w conveys information about the direction of a target vector w∗, for
a fixed link function that minimizes the L2 loss. We leverage this property to construct a proper
2
learner achieving constant factor approximation.
2 Preliminaries
Basic Notation For n ∈ Z , let [n] := {1,...,n}. We use lowercase boldface characters for
+
vectors. We use x·y for the inner product of x,y ∈ Rd and θ(x,y) for the angle between x,y. For
x ∈ Rd and k ∈ [d], x denotes the kth coordinate of x, and ∥x∥ denotes the ℓ -norm of x. We use
k 2 2
1 = 1{A} to denote the characteristic function of the set A. For vectors v,u ∈ Rd, we denote by
A
v⊥u the projection of v onto the subspace orthogonal to u, i.e., v⊥u := v−((v·u)u)/∥u∥2. We use
2
B(r) to denote the ℓ ball in Rd of radius r, centered at the origin.
2
Asymptotic Notation We use the standard O(·),Θ(·),Ω(·) asymptotic notation. We use O(cid:101)(·)
to omit polylogarithmic factors in the argument. We use O (·) to suppress polynomial dependence
p
5on p, i.e., O (ω) = O(poly(p)ω). Θ (·) and Ω (·) are defined similarly. We write E ≳ F for two
p p p
non-negative expressions E and F to denote that there exists some positive universal constant c > 0
(independent of the variables or parameters on which E and F depend) such that E ≥ cF. The
notation ≲ is defined similarly.
Probability Notation We use E [X] for the expectation of a random variable X according
X∼D
to the distribution D and Pr[E] for the probability of event E. For simplicity of notation, we omit
the distribution when it is clear from the context. For (x,y) distributed according to D, we use D
x
to denote the marginal distribution of x.
Organization In Section 3, we establish our main structural result of alignment sharpness. In
Section 4, we describe and analyze our constant factor approximate SIM learner. We conclude the
paper in Section 5. Some of the proofs and technical details are deferred to the Appendix.
3 Main Structural Result: Alignment Sharpness of Surrogate Loss
In this section, we establish our main structural result (Proposition 3.1), which is what crucially
enables us to obtain the target O(OPT)+ϵ error for the studied problem. Proposition 3.1 states that
the empirical gradient of the surrogate loss (2) positively correlates with the direction of wt−w∗
whenever wt does not correspond to an O(OPT)+ϵ error solution; and, moreover, the correlation is
proportional to the quantity ∥(w∗)⊥ wt∥2 2. This is a key property that is leveraged in our algorithmic
result (Theorem 4.2), both in obtaining an O(OPT)+ϵ error result, and in arguing about the
convergence and computational efficiency of our algorithm.
Intuitively, what Proposition 3.1 allows us to argue is that as long as the angle between wt
and w∗ is not close to zero, we can update wt to better align it with w∗ (in the sense that we
reduce the angle between these two vectors). To understand this statement better, note that when
∥wt∥
2
≈ ∥w∗∥ 2, we also have ∥(w∗)⊥ wt∥
2
≈ ∥wt−w∗∥ 2. Additionally, ∥wt−w∗∥
2
= O(OPT+ϵ)
implies that the L2 error of the hypothesis defined by uˆt,wt is O(OPT+ϵ) (see Claim 4.4). Thus,
2
for a sufficiently good guess of the value of ∥w∗∥ , Proposition 3.1 provides a local error bound of
2
the form ∇L(cid:98)sur(wt;uˆt)·(wt−w∗) ≳ µ∥wt−w∗∥2
2
that holds outside of the set of O(OPT+ϵ) error
solutions, allowing us to contract the distance to this set.
Proposition 3.1 (Alignment Sharpness of the Convex Surrogate). Suppose that D is (L,R)-well-
x
behaved, U is as in Definition 1.3, and ϵ,δ > 0. Let µ ≳ a2LR4/b. Given any wt ∈ B(W), denote
(a,b)
by uˆt the optimal solution to (P) with respect to wt and the sample set S = {(x(i),y(i))}m drawn
i=1
i.i.d. from D. If m satisfies
m ≳ dW9/2b4L−4log4(d/(ϵδ))(1/ϵ3/2+1/(ϵδ)) ,
then, with probability at least 1−δ,
√ √
∇L(cid:98)sur(wt;uˆt)·(wt−w∗) ≥ µ∥(w∗)⊥ wt∥2 2−2(OPT+ϵ)/b−2( OPT+ ϵ)∥wt−w∗∥
2
.
To prove Proposition 3.1, we rely on the following key ingredients. In Section 3.1, we prove our
maintechnicallemma(Lemma3.2), whichstatesthattheL2 distancebetweenthehypothesisu(w·x)
2
and the target u∗(w∗ ·x) is bounded below by the misalignment of wt and w∗, i.e., the squared
norm of the component of w∗ that is orthogonal to wt, ∥(w∗)⊥ wt∥2 2. As will become apparent in
the proof of Proposition 3.1, the inner product ∇L(cid:98)sur(wt;uˆt)·(wt−w∗) can be bounded below as
6a function of the empirical L2 error for wt and a different (but related) activation uˆ∗t, which can
2
in turn be argued to be close to the population L2 error for a sufficiently large sample size, using
2
concentration. Thus, Lemma 3.2 can be leveraged to obtain a term scaling with ∥(w∗)⊥ wt∥2
2
in the
lower bound on ∇L(cid:98)sur(wt;uˆt)·(wt−w∗).
In Section 3.2, we characterize structural properties of the population-optimal link functions ut
and u∗t (see (EP) and (EP*)), which play a crucial role in the proof of Proposition 3.1. Specifically,
we show that the activation ut is close to the idealized activation u∗t (the optimal activation without
noise, given wt) in L2 distance (Lemma 3.3). Since by standard uniform convergence results we
2
have that uˆt and uˆ∗t are close to their population counterparts ut and u∗t, respectively, Lemma 3.3
certifies that uˆt is not far from uˆ∗t. This property enables us to replace uˆt by (the idealized) uˆ∗t in
the empirical surrogate gradient ∇L(cid:98)sur(wt;uˆt), which is easier to analyze, since uˆ∗t is defined with
respect to the “ideal” dataset (with uncorrupted labels).
Finally, as a simple corollary of Lemma 3.3, we obtain Corollary 3.4, which gives a clear
explanation of why our algorithm, which alternates between updating wt and uˆt, works: we show
that the L2 loss between the hypothesis generated by our algorithm uˆt(wt·x) and the underlying
2
optimal hypothesis u∗(w∗ ·x) is bounded above by the distance between wt and w∗. Since our
structural sharpness result (Proposition 3.1) enables us to decrease ∥wt−w∗∥ , Corollary 3.4 certifies
2
that choosing the empirically-optimal activation leads to convergence of the hypothesis uˆt(wt·x).
Equipped with these technical lemmas, we prove our main structural result (Proposition 3.1) in
Section 3.3.
3.1 L2 Error and Misalignment
2
Our first key result is Lemma 3.2 below, which plays a critical role in the proof of Proposition 3.1. As
discussed in Section 1.2, for two different activations u and u∗ and parameters w and w∗ such that w
and w∗ are parallel, even when the L2 error is Ω(1), the gradient ∇L (w;u) might not significantly
2 sur
align with the direction of w−w∗, and thus cannot provide sufficient information about the direction
to decrease ∥w−w∗∥ . Intuitively, the following lemma shows that this is the only thing that can
2
go wrong, and it happens when w and w∗ are parallel. In particular, Lemma 3.2 shows that for any
square integrable link function f, we can relate the L2 distance E [(f(w·x)−u∗(w∗·x))2] to
2 x∼Dx
the magnitude of the component of w∗ that is orthogonal to w. Although its proof is quite technical,
this lemma is the main supporting result allowing us to prove Proposition 3.1, thus we provide its full
proof below. It is however possible to follow the rest of this section by only relying on its statement.
Lemma 3.2 (LowerBoundonL2 ErrorbyMisalignment). Let u∗ ∈ U , D be (L,R)-well-behaved,
2 (a,b) x
and f : R (cid:55)→ R be square-integrable with respect to the measure of the distribution D . Then, for any
x
w,w∗ ∈ Rd,
E [(f(w·x)−u∗(w∗·x))2] ≳ a2LR4∥(w∗)⊥w∥2 .
2
x∼Dx
Proof. The statement holds trivially if w is parallel to w∗, so assume this is not the case. Let
v = (w∗)⊥w = w∗−(w∗·w)w/∥w∥2. Suppose first that w·w∗ ≥ 0. Then w∗ = αw+v, for some
2
α > 0. Let V be the subspace spanned by w,v. Then,
E [(f(w·x)−u∗(w∗·x))2] = E [(f(w·x )−u∗(w∗·x ))2] ≥ E [(f(w·x )−u∗(w∗·x ))21{x ∈ A}] ,
V V V V V
x∼Dx x∼Dx x∼Dx
for any A ⊆ Rd. For ease of notation, we drop the subscript V, and we assume that all x are
projected to the subspace V. We denote by w˜ = w/∥w∥ (resp. v˜ = v/∥v∥ ) the unit vector in the
2 2
direction of w (resp. v). We choose A = {x ∈ Rd : w·x ≥ 0,v˜ ·x ∈ (R/16,R/8)∪(3R/8,R/2)}.
7The idea of the proof is to utilize the non-decreasing property of u∗ and the fact that the marginal
distribution D is anti-concentrated on the subspace V. In short, for any x such that |v˜·x| ≤ R, by
x
the non-decreasing property of u∗ we know that f(w·x) falls into one of the following four intervals:
(−∞, u∗(αw·x+∥v∥ R/32)], (u∗(αw·x+∥v∥ R/32), u∗(αw·x+∥v∥ R/4)],
2 2 2
(u∗(αw·x+∥v∥ R/4), u∗(αw·x+∥v∥ R)], (u∗(αw·x+∥v∥ R), +∞) .
2 2 2
Whenf(w·x)belongsto anyof theintervals above, we canshow thatwith some constantprobability,
the difference between w∗ ·x and w·x is proportional to ∥v∥ , and hence u∗(w∗ ·x) is far from
2
f(w·x) (due to the well-behaved property of the marginal D ).
x
To indicate that f(w·x) belongs to one of the intervals above, denote
I (x) = f(w·x)−u∗(αw·x+∥v∥ R/32) ,
1 2
I (x) = f(w·x)−u∗(αw·x+∥v∥ R/4) ,
2 2
I (x) = f(w·x)−u∗(αw·x+∥v∥ R) .
3 2
For any x ∈ Rd, using the assumption that u∗ is non-decreasing, we have that I (x) ≥ I (x) ≥ I (x);
1 2 3
as a consequence, it must be that I (x)I (x) ≥ 0 or I (x)I (x) ≥ 0.
1 2 2 3
Figure 1: Under the assumption that v˜ ·x ∈ (R/16,R/8), and I (x) ≥ 0,I (x) ≥ 0, the distance
1 2
between f(w·x) and u∗(w∗·x) is at least |u∗(αw·x+∥v∥ R/4)−u∗(w∗·x)| ≥ a∥v∥ R/8.
2 2
Case 1: f(w·x) ∈ (u∗(αw·x+∥v∥ R/4), ∞). Then I (x) ≥ I (x) ≥ 0. Let
2 1 2
B := {x ∈ Rd : w·x ≥ 0,v˜ ·x ∈ (R/16,R/8)}
and notice that B ⊆ A. We have that when x ∈ B,
u∗(w∗·x) = u∗(αw·x+∥v∥ v˜ ·x) ∈ (u∗(αw·x+∥v∥ R/16), u∗(αw·x+∥v∥ R/8)),
2 2 2
thus we can conclude that
(f(w·x)−u∗(w∗·x))21{x ∈ B}
= (cid:0) {f(w·x)−u∗(αw·x+∥v∥ R/4)}+{u∗(αw·x+∥v∥ R/4)−u∗(w∗·x)}(cid:1)21{x ∈ B}
2 2
≥ (u∗(αw·x+∥v∥ R/4)−u∗(w∗·x))21{x ∈ B} ,
2
where in the last inequality we used that I (x) = f(w · x) − u∗(αw · x + ∥v∥ R/4) ≥ 0 and
2 2
u∗(αw·x+∥v∥ R/4)−u∗(w∗·x) ≥ 0 by the non-decreasing property of u∗, and the elementary
2
inequality (a+b)2 ≥ max(a,b)2 for a,b ≥ 0. Further, using u∗(t)−u∗(t′) ≥ a(t−t′) for t ≥ t′ ≥ 0
(which holds by assumption) and w∗ = αw+v, we have
(u∗(αw·x+∥v∥ R/4)−u∗(w∗·x))21{x ∈ B} ≥ a2(∥v∥ R/4−v·x)21{x ∈ B}
2 2
≥ a2∥v∥2(R/8)21{x ∈ B} ,
2
8where in the last inequality we used that 0 ≤ v˜ ·x ≤ R/8 (by the definition of the event B). A
visual illustration of the argument above is given in Figure 1.
Case 2: f(w·x) ∈ (−∞, u∗(αw·x+∥v∥ R/32)). Then 0 ≥ I (x) ≥ I (x). We follow a similar
2 1 2
argument as in the previous case. In particular, we begin with
(f(w·x)−u∗(w∗·x))21{x ∈ B}
= (cid:0) {f(w·x)−u∗(αw·x+∥v∥ R/32)}+{u∗(αw·x+∥v∥ R/32)−u∗(w∗·x)}(cid:1)21{x ∈ B}.
2 2
(4)
Note that I (x) ≤ 0 and u∗(w∗ · x) = u∗(αw · x + ∥v∥ v˜ · x) ≥ u∗(αw · x + ∥v∥ R/32) since
1 2 2
v˜·x ≥ R/16 ≥ R/32 for x ∈ B; thus, the two terms in curly brackets in (4) have the same sign and
we further have:
(f(w·x)−u∗(w∗·x))21{x ∈ B} ≥ (u∗(αw·x+∥v∥ R/32)−u∗(w∗·x))21{x ∈ B}
2
≥ a2∥v∥2(R/32)21{x ∈ B} ,
2
where in the first inequality we used the fact that (a+b)2 ≥ max{a2,b2} when both a,b ≤ 0.
By the analysis of Case 1 and Case 2, we can conclude that when I (x)I (x) ≥ 0, it must be:
1 2
(f(w·x)−u∗(w∗·x))21{x ∈ B} ≥ a2∥v∥2R2/2101{x ∈ B} . (5)
2
Case 3: f(w·x) ∈ (u∗(αw·x+∥v∥ R), +∞). Then I (x) ≥ I (x) ≥ 0 and we choose
2 2 3
B′ = {x ∈ Rd : w·x ≥ 0,v˜ ·x ∈ (3R/8,R/2)} .
Following the same reasoning as in the previous two cases, we have
(f(w·x)−u∗(w∗·x))21{x ∈ B′}
= (cid:0) {f(w·x)−u∗(αw·x+∥v∥ R)}+{u∗(αw·x+∥v∥ R)−u∗(w∗·x)}(cid:1)21{x ∈ B′}
2 2
≥ (u∗(αw·x+∥v∥ R)−u∗(w∗·x))21{x ∈ B′}
2
≥ a2∥v∥2(R/2)21{x ∈ B′} .
2
Case 4: f(w·x) ∈ (−∞,u∗(αw·x+∥v∥ R/4)). Then 0 ≥ I (x) ≥ I (x). It follows that
2 2 3
(f(w·x)−u(w∗·x))21{x ∈ B′}
= (cid:0) {f(w·x)−u∗(αw·x+∥v∥ R/4)}+{u∗(αw·x+∥v∥ R/4)−u(w∗·x)}(cid:1)21{x ∈ B′}
2 2
≥ a2∥v∥2(R/8)21{x ∈ B′} .
2
Thus, from the analysis of Case 3 and Case 4, we conclude that when I (x)I (x) ≥ 0, we have
2 3
(f(w·x)−u∗(w∗·x))21{x ∈ B′} ≥ a2∥v∥2(R2/64)1{x ∈ B′} . (6)
2
Recall that for any x, at least one of the inequalities I (x)I (x) ≥ 0 or I (x)I (x) ≥ 0 happens, thus,
1 2 2 3
1{I (x)I (x) ≥ 0} ≥ 1−1{I (x)I (x) ≥ 0}. Therefore, the probability mass of the region
1 2 2 3
(B∩{I (x)I (x) ≥ 0})∪(B′∩{I (x)I (x) ≥ 0})
1 2 2 3
9can be bounded below by:
(cid:20) (cid:21)
Pr x ∈ (B∩{I (x)I (x) ≥ 0})∪(B′∩{I (x)I (x) ≥ 0})
1 2 2 3
(cid:90) (cid:18) (cid:19)
= 1{x ∈ B}1{I (x)I (x) ≥ 0}+1{x ∈ B′}1{I (x)I (x) ≥ 0} γ(x)dx
1 2 2 3
V
(cid:90) (cid:18) (cid:19)
≥ 1{x ∈ B}1{I (x)I (x) ≥ 0}+1{x ∈ B′}1{I (x)I (x) ≥ 0} Ldx
1 2 2 3
V,∥x∥∞≤R
(cid:90) (cid:18) (cid:19)
≥ L 1{x ∈ B}+(1{x ∈ B′}−1{x ∈ B})1{I (x)I (x) ≥ 0} dx , (7)
2 3
V,∥x∥∞≤R
where in the first inequality we used the assumption that D is (L,R)- well-behaved. As a visual
x
illustration of the lower bound argument above, the reader is referred to Figure 2.
Figure 2: On the 2-dimensional space V spanned by (x ,x ), at each point x ∈ B ∪B′, it must
v w
be that I (x)I (x) ≥ 0 or I (x)I (x) ≥ 0. Γ denotes the interval of x = w · x such that
1 2 2 3 1 w
f(w·x) ≥ u∗(αw·x+∥v∥ R), hence both I (x)I (x) ≥ 0, I (x)I (x) ≥ 0; Γ denotes the interval of
2 1 2 2 3 2
x such that f(w·x) ∈ (u∗(αw·x+∥v∥ R/32),u∗(αw·x+∥v∥ R/4)), hence I (x)I (x) ≥ 0; finally,
w 2 2 2 3
Γ denotes the interval of x such that f(w·x) ∈ (u∗(αw·x+∥v∥ R/4),u∗(αw·x+∥v∥ R/)),
3 w 2 2
hence I (x)I (x) ≥ 0. The area of the union of the red and blue regions is the lower bound on the
1 2
probability in (7). As displayed in the figure, the sum of the blue and red region is lower bounded by
1{x ∈ B}+(1{x ∈ B′}−1{x ∈ B})1{I (x)I (x) ≥ 0}.
2 3
To finish bounding below the probability in (7), it remains to bound the integral from its
final inequality, which now does not involve the probability density function anymore, as we used
the anti- concentration property of D to uniformly bound below γ(x). Recall that by definition,
x
I (x),I (x),I (x) are functions of w·x that do not depend on v˜ ·x. Denote the projection of x on
1 2 3
10the standard basis of space V by x = w˜ ·x and x = v˜ ·x. Then, we have:
w˜ v˜
(cid:90) (cid:18) (cid:19)
1{x ∈ B′}−1{x ∈ B} 1{I (x)I (x) ≥ 0}dx
2 3
V,∥x∥∞≤R
(cid:90) (cid:90) (cid:18) (cid:26) (cid:18) (cid:19)(cid:27) (cid:26) (cid:18) (cid:19)(cid:27)(cid:19)
3R R R R
= 1 x ∈ , −1 x ∈ , dx 1{x ≥ 0,I (x)I (x) ≥ 0}dx
v˜ v˜ v˜ w˜ 2 3 w˜
8 2 16 8
|xw˜|≤R |xv˜|≤R
(cid:90) (cid:90) (cid:18) (cid:26) (cid:18) (cid:19)(cid:27) (cid:26) (cid:18) (cid:19)(cid:27)(cid:19)
3R R R R
= 1{x ≥ 0,I (x)I (x) ≥ 0}dx 1 x ∈ , −1 x ∈ , dx
w˜ 2 3 w˜ v˜ v˜ v˜
8 2 16 8
|xw˜|≤R |xv˜|≤R
≥ 0 .
Plugging the inequality above back into (7), we get:
(cid:20) (cid:21)
Pr x ∈ (cid:0) B∩{I (x)I (x) ≥ 0}(cid:1) ∪(cid:0) B′∩{I (x)I (x) ≥ 0}(cid:1)
1 2 2 3
(cid:90)
≥ L 1{w·x ≥ 0,v˜ ·x ∈ (R/16,R/8)}dx
V,∥x∥∞≤R
(cid:90)(cid:90)
= L (1{x ∈ (0,R)}dx )1{x ∈ (R/16,R/8)}dx = LR2/16 . (8)
w˜ w˜ v˜ v˜
We are now ready to provide a lower bound on the L2 distance between f(w·x) and u∗(w∗ ·x).
2
Combining the inequalities from (5) and (6), we get
E [(f(w·x)−u∗(w∗·x))2]
x∼Dx
≥ E [(f(w·x )−u∗(w∗·x ))21{x ∈ A}]
V V V
x∼Dx
≥ a2(R2/1024)∥v∥2 E [1(cid:8) {x ∈ B∩{I (x)I (x) ≥ 0}}∪{B′∩{I (x)I (x) ≥ 0}}(cid:9) ]
2 V 1 2 2 3
x∼Dx
≥ a2(R4/213)L∥v∥2 ,
2
where we used (8) in the last inequality.
Now for the case where w·w∗ ≤ 0, it holds w∗ = αw+v with α ≤ 0. Considering instead
A = {x ∈ Rd : w·x ≤ 0,v˜ ·x ∈ (R/16,R/8)∪(3R/8,R/2)} and similarly B = {x ∈ Rd : w·x ≤
0,v˜ ·x ∈ (R/16,R/8)}, B′ = {x ∈ Rd : w·x ≤ 0,v˜ ·x ∈ (R/3,R/2)}, then all the steps above
remains valid without modification. This completes the proof of Lemma 3.2.
3.2 Closeness of Idealized and Attainable Activations
In this section, we bound the contribution of the error incurred from working with attainable link
functions uˆt in the iterations of the algorithm. The error incurred is due to both the arbitrary noise
in the labels and due to using a finite sample set. In bounding the error, for analysis purposes, we
introduce auxiliary population-level link functions.
Concretely, given w ∈ B(W), a population-optimal activation is a solution to the following
stochastic convex program:
u ∈ argmin E [(u(w·x)−y)2]. (EP)
w
u∈U (x,y)∼D
(a,b)
We further introduce auxiliary “idealized, noiseless” activations, which, given noiseless labels y∗ =
u∗(w∗·x) and a parameter weight vector w, are defined via
u∗ ∈ argmin E [(u(w·x)−y∗)2]. (EP*)
w
u∈U (x,y)∼D
(a,b)
11Below we relate ut := u and u∗t := u∗ and show that their L2 error for the parameter vector
wt wt 2
wt is bounded by OPT. The proof of Lemma 3.3 is deferred to Appendix C.1.
Lemma 3.3 (Closeness of Population-Optimal Activations). Let wt ∈ B(W) and let u∗t, ut be
defined as solutions to (EP*), (EP), respectively. Then,
E [(ut(wt·x)−u∗t(wt·x))2] ≤ OPT.
x∼Dx
As a consequence of the lemma above, we are able to relate uˆt to the “noiseless” labels y∗ =
u∗(w∗·x) by showing that the L2 distance between u∗(w∗·x) and the sample-optimal activation
2
uˆt(wt·x)isboundedby∥wt−w∗∥2. AlthoughCorollary3.4isnotusedintheproofofProposition3.1,
2
we still present it here as it justifies the mechanism of our approach alternating between updates for
wt and uˆt. The proof of Corollary 3.4 can be found in Appendix C.2.
Corollary 3.4 (Closeness of Idealized and Attainable Activations). Let ϵ,δ > 0. Given a parameter
wt ∈ B(W) and m ≳ dlog4(d/(ϵδ))(b2W3/(L2ϵ))3/2 samples from D, let uˆt be the sample-optimal
activation on these samples given wt, as defined in (P). Then, with probability at least 1−δ,
E [(uˆt(wt·x)−u∗(w∗·x))2] ≤ 3(ϵ+OPT+b2∥wt−w∗∥2) .
2
x∼Dx
3.3 Proof of Proposition 3.1
We are now ready to prove our main structural result. We focus here on the main argument, while
the proofs of supporting technical claims are deferred to Appendix C.
Proof of Proposition 3.1. Givenanyweightparameterwt ∈ B(W)anduˆt chosenasitscorresponding
sample-optimal solution to problem (P), let ut be the population-optimal activation, as defined by
Problem (EP). Given a sample set S = {(x(i),y(i))}m , consider an idealized, “noise-free” set S∗
i=1
that assigns realizable labels to data vectors from S, i.e., S∗ = {(x(i),y∗(i))}m , y∗(i) = u∗(w∗·x(i)).
i=1
Further define idealized sample-optimal activations by
m
1 (cid:88)
uˆ∗ ∈ argmin (u(w·x(i))−y∗(i))2. (P*)
w m
u∈U
(a,b) i=1
For a parameter wt, denote uˆ∗t := uˆ∗ , for simplicity, and recall that the population version of uˆ∗t
wt
was defined by (EP*). To prove Proposition 3.1, we decompose ∇L(cid:98)sur(wt;uˆt)·(wt−w∗) into three
summation terms:
∇L(cid:98)sur(wt;uˆt)·(wt−w∗)
m
1 (cid:88)
= (uˆt(wt·x(i))−y(i))(wt−w∗)·x(i)
m
i=1
m m
1 (cid:88) 1 (cid:88)
= (uˆt(wt·x(i)−uˆ∗t(wt·x(i)))(wt−w∗)·x(i)+ (uˆ∗t(wt·x(i))−y∗(i))(wt−w∗)·x(i)
m m
i=1 i=1
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Q1 Q2
m
1 (cid:88)
+ (y∗(i)−y(i))(wt·x(i)−w∗·x(i)) . (9)
m
i=1
(cid:124) (cid:123)(cid:122) (cid:125)
Q3
12We tackle each term Q to Q in (9) separately, using the following arguments relying on three
1 3
auxiliary claims. Because the proofs of these claims are technical, we defer them to Appendix C.
√ √
The first claim states that Q is of the order ( ϵ+ OPT)∥wt−w∗∥ +(OPT+ϵ)/b with high
1 2
probability.
Claim 3.5. Let S = {(x(i),y(i))}m be i.i.d. samples from D where m is as specified in the statement
i=1
of Proposition 3.1. Let uˆt be the solution of optimization problem (P) given wt ∈ B(W) and S.
Furthermore, denote the idealized version of S by S∗ = {(x(i),y∗(i))}m , where y∗(i) = u∗(w∗·x(i)).
i=1
Let uˆ∗t be the solution of problem (P*). Then, with probability at least 1−δ,
1 (cid:88)m √ √
Q = ((uˆt(wt·x(i))−uˆ∗t(wt·x(i)))(wt−w∗)·x(i) ≥ −( ϵ+ OPT)∥wt−w∗∥ −(ϵ+OPT)/b .
1 2
m
i=1
TheproofofClaim3.5isbasedonthefollowingargument: first,standardconcentrationarguments
ensure that uˆt and uˆ∗t are close to their population counterparts, ut and u∗t, in L2 distance (see
2
Appendix F). Therefore, applying Chebyshev’s inequality, we are able to swap the sample-optimal
activations in (9) by their population-optimal counterparts with high probability and focus on
bounding
m
1 (cid:88)
(ut(wt·x(i))−u∗t(wt·x(i)))(wt−w∗)·x(i) .
m
i=1
To bound this quantity, we leverage the result from Lemma 3.3, namely that E [(ut(wt·x)−
x∼Dx
u∗t(wt·x))2] ≤ OPT.
The second claim leverages the misalignment lemma (Lemma 3.2) and shows that, up to small
errors, Q
2
is a constant multiple of ∥(w∗)⊥ wt∥2 2.
Claim 3.6. Let S∗ = {(x(i),y∗(i))}m be a sample set such that x(i)’s are i.i.d. samples from D
i=1 x
and y∗(i) = u∗(w∗·x(i)) for each i. Let m be the value specified in the statement of Proposition 3.1.
Then, given a parameter wt ∈ B(W), with probability at least 1−δ,
1 (cid:88)m Ca2LR4 √
Q
2
=
m
(uˆ∗t(wt·x(i))−y∗(i))(wt−w∗)·x(i) ≥
b
∥(w∗)⊥ wt∥2 2− ϵ∥wt−w∗∥ 2−ϵ/b ,
i=1
where C is an absolute constant.
The proof of Claim 3.6 is rather technical. We first define an ‘empirical inverse’ of the activation
u∗, and denote it by fˆ. Note that u∗(z) ∈ U is not necessarily strictly increasing when z ≤ 0,
(a,b)
therefore (u∗)−1 is not defined everywhere on R, and the introduction of this ‘empirical inverse’
function fˆis needed. Then, adding and subtracting fˆ(uˆ∗t(wt·x(i))) in the wt·x(i)−w∗·x(i) term,
we get
m
1 (cid:88)
(uˆ∗t(wt·x(i))−u∗(w∗·x(i)))(wt−w∗)·x(i)
m
i=1
m
1 (cid:88)
= (uˆ∗t(wt·x(i))−u∗(w∗·x(i)))(wt·x(i)−fˆ(uˆ∗t(wt·x(i))))
m
i=1
m
1 (cid:88)
+ (uˆ∗t(wt·x(i))−u∗(w∗·x(i)))(fˆ(uˆ∗t(wt·x(i)))−w∗·x(i)) .
m
i=1
13Analyzing the KKT conditions of the optimization problem (P*), we argue that the first term in
the equation above is always positive. Then, we argue that our definition of the empirical inverse
fˆensures that the second term can be bounded below by 1 (cid:80)m (uˆ∗t(wt·x(i))−u∗(w∗·x(i)))2.
bm i=1
Using standard concentration arguments, the quantity above concentrates around its expectation
E [(uˆ∗t(wt·x)−u∗(w∗·x))2], hence we complete the proof applying Lemma 3.2.
x∼Dx √
Similar to Claim 3.5, the last claim shows that Q is of the order OPT∥w∗−wt∥ , which is
3 2
small compared to the positive term in Claim 3.6 outside the set of O(OPT)+ϵ error solutions.
Claim 3.7. Let S = {(x(i),y(i))}m be i.i.d. samples from D, and denote by S∗ = {(x(i),y∗(i))}m
i=1 i=1
the idealized version of S, where y∗(i) = u∗(w∗·x(i)). Under the condition of Proposition 3.1, given
a parameter wt ∈ B(W), with probability at least 1−δ,
1 (cid:88)m √
Q = (y∗(i)−y(i))(wt·x(i)−w∗·x(i)) ≥ − OPT∥w∗−wt∥ −(OPT+ϵ)/b .
3 2
m
i=1
The proof of Claim 3.7 follows via similar arguments as the proof of Claim 3.5.
Plugging the bounds from Claim 3.5, Claim 3.6, and Claim 3.7 back into (9) and using a union
bound, we get that with probability at least 1−3δ,
Ca2LR4 √ √
∇L(cid:98)sur(wt;uˆt)·(wt−w∗) ≥
b
∥(w∗)⊥ wt∥2 2−2( OPT+ ϵ)∥wt−w∗∥ 2−2(OPT+ϵ)/b,
for some absolute constant C, completing the proof.
4 Robust SIM Learning via Alignment Sharpness
As discussed in Section 1.2, our algorithm can be viewed as employing an alternating procedure:
taking a Riemannian gradient descent step on a sphere with respect to the empirical surrogate,
given an estimate of the activation, and optimizing the activation function on the sample set for
a given parameter weight vector. This procedure is performed using a fine grid of guesses of the
scale of ∥w∗∥ . For this process to converge with the desired linear rate (even for a known value
2
of ∥w∗∥ ), the algorithm needs to be properly initialized to ensure that the initial weight vector
2
has a nontrivial alignment with the optimal vector w∗. The initialization process is handled in the
following subsection.
4.1 Initialization
We begin by showing that the Initialization subroutine stated in Algorithm 1 returns a point w¯0
that has a sufficient alignment with w∗. As will become apparent later in the proof of Theorem 4.2,
this property of the initial point is critical for Algorithm 2 to converge at a linear rate.
Lemma 4.1 (Initialization). Let µ = Ca2LR4/b for an absolute constant C > 0 and let ϵ,δ > 0.
Choose the step size η = µ3/(27b4) in Algorithm 1. Then, drawing m i.i.d. samples from D at each
0
iteration such that
W9/2b10dlog4(d/(ϵδ))
m ≳ ,
0
L4µ6δϵ3/2
ensuresthatwithint ≲ b6log(b/µ)/µ6 iterations, theinitializationsubroutineAlgorithm1generatesa
0 √
l √ist of size t
0
that contains a point w¯0 such that ∥(w∗)⊥ w¯0∥
2
≤ max{µ∥w∗∥ 2/(4b),64b2/µ3( OPT+
ϵ)}, with probability at least 1 − δ. The total number of samples required for Algorithm 1 is
N = t m .
0 0 0
14Algorithm 1 Initialization
1: Input: w0 = 0; ϵ,δ > 0; positiveparametersa,b,L,R,W; µ ≲ a2LR4/b,stepsizeη = µ3/(27b4),
number of iterations t ≲ (b/µ)6log(b/µ);
0
2: for t = 0 to t 0 do
3: Draw m 0 ≳ W9/2b10dlog4(d/(ϵδ))/(L4µ6δϵ3/2) i.i.d. samples from D
4: uˆt = argmin 1
m (cid:80)0
(u(wt·x(i))−y(i))2.
u∈U (a,b)
m0
i=1
5: ∇L(cid:98)sur(wt;uˆt) = m1
0
m (cid:80)0
(uˆt(wt·x(i))−y(i))x(i).
i=1
6: wt+1 = wt−η∇L(cid:98)sur(wt;uˆt).
7: end for
8: Return: {w0,...,wt0}
√ √
Proof. Consider first the case that ∥w∗∥ ≤ 64b2/µ3( OPT+ ϵ). Then, for the parameter vector
2
w0 = 0, we have
√ √
∥(w∗)⊥ w0∥
2
= ∥w∗∥
2
≤ 64b2/µ3( OPT+ ϵ)
and the claimed statement holds trivially.
√ √
Thus, in the rest of the proof we assume ∥w∗∥ ≥ 64b2/µ3( OPT+ ϵ). Let vt denote the
2
component of w∗ that is orthogonal to wt; i.e., vt = w∗ −(w∗ ·wt)wt/∥wt∥2
2
= (w∗)⊥ wt, where
wt is defined in Algorithm 1. Our goal is to show that when ∥vt∥ ≥ µ∥w∗∥ /(4b) at iteration
2 2
t, the distance between wt+1 and w∗ contracts by a constant factor 1 − c for some c < 1, i.e.,
∥wt+1 −w∗∥ ≤ (1−c)∥wt −w∗∥ . This implies that when ∥vt∥ is greater than µ∥w∗∥ /(4b),
2 2 2 2
∥wt+1 −wt∥
2
contracts until ∥vt∥
2
≥ µ∥w∗∥ 2/(4b) is violated at step t 0; this wt0 is exactly the
initial point we are seeking to initialize the optimization subroutine.
Applying Proposition 3.1, we get that under our choice of batch size m, with probability at least
1−δ, at each iteration it holds
Ca2LR4 √ √
∇L(cid:98)sur(wt;uˆt)·(wt−w∗) ≥
b
∥(w∗)⊥ wt∥2 2−2( OPT+ ϵ)∥wt−w∗∥ 2−2(OPT+ϵ)/b .
We now study the distance between wt+1 and w∗, where wt+1 is updated from wt according to
Algorithm 1.
∥wt+1−w∗∥2
2
= ∥wt−η∇L(cid:98)sur(wt;uˆt)−w∗∥2
2
= ∥wt−w∗∥2 2+η2∥∇L(cid:98)sur(wt;uˆt)∥2 2−2η∇L(cid:98)sur(wt;uˆt)·(wt−w∗) . (10)
Applying Lemma 4.3 to (10), and plugging in Proposition 3.1, we get that under our choice of batch
size m it holds that with probability at least 1−δ,
∥wt+1−w∗∥2 ≤ ∥wt−w∗∥2+η2(10(OPT+ϵ)+4b2∥wt−w∗∥2)
2 2 2
√ √
+2η(2(OPT+ϵ)/b+2( OPT+ ϵ)∥wt−w∗∥ −µ∥vt∥2)
2 2
√ √
≤ (1+4b2η2)∥wt−w∗∥2+2η(2( OPT+ ϵ)∥wt−w∗∥ −µ∥vt∥2)
2 2 2
+5η(OPT+ϵ) , (11)
where µ = Ca2LR4/b and C is an absolute constant. Note that in the last inequality we used that
η ≤ 1/10, hence 10η2 ≤ η, and that b ≥ 1.
15When t = 0, v0 = w∗, hence we have ∥v0∥ ≥ µ∥w∗∥ /(4b). Suppose that at iteration t,
2 2
∥vt∥ ≥ µ∥w∗∥ /(4b) is still valid. Then, (11) is transformed to:
2 2
∥wt+1−w∗∥2 ≤ (1+4b2η2)∥wt−w∗∥2+5η(OPT+ϵ)
2 2
+2η((µ3/(32b2))∥wt−w∗∥ ∥w∗∥ −(µ3/(16b2))∥w∗∥2) . (12)
2 2 2
Weuseaninductiveargumenttoshowthatatiterationt,∥wt−w∗∥ ≤ ∥w∗∥ ,whichmusteventually
2 2
yield a contraction ∥wt+1 −w∗∥2 ≤ (1−c)∥wt −w∗∥2 for some constant c < 1. This condition
2 2
∥wt−w∗∥ ≤ ∥w∗∥ certainly holds for the base case t = 0 as w0 = 0, hence ∥w0−w∗∥ = ∥w∗∥ .
2 2 2 2
Now, suppose ∥wt − w∗∥ ≤ ∥w∗∥ holds for all the iterations from 0 to t. Then, plugging
2 2
η = µ3/(27b4) into (12), we get:
∥wt+1−w∗∥2 ≤ (1+4b2η2)∥wt−w∗∥2+2η((µ3/(32b2))−(µ3/(16b2)))∥wt−w∗∥ ∥w∗∥ +5η(OPT+ϵ)
2 2 2 2
≤ (1+4η2b2−2ηµ3/(32b2))∥wt−w∗∥2+5µ3/(27b4)(OPT+ϵ)
2
≤ (1−µ6/(211b6))∥wt−w∗∥2+5µ3/(27b4)(OPT+ϵ) .
2
√ √
Sincewehaveassumed OPT+ ϵ ≤ µ3/(64b2)∥w∗∥ ,itholds∥wt−w∗∥ ≥ ∥vt∥ ≥ µ∥w∗∥ /(4b) ≥
√ √ 2 2 2 2
(16b/µ2)( OPT+ ϵ), thus, we have (noting that µ ≤ 1):
√ √
5µ3/(27b4)(OPT+ϵ) ≤ 5µ3/(27b4)( OPT+ ϵ)2 ≤ µ6/(212b6)∥wt−w∗∥ .
2
Therefore, combining the results above, we get:
∥wt+1−w∗∥2 ≤ (1−µ6/(212b6))∥wt−w∗∥2 ,
2 2
for any iteration t such that ∥vt∥ ≥ µ∥w∗∥ /(4b) holds. This validates the induction argument
2 2
that ∥wt−w∗∥ ≤ ∥w∗∥ for every t = 0,...,t and at the same time yields the desired contraction
2 2 0
propertyofthesequence∥wt−w∗∥ ,t = 0,...,t . Now,since∥w0−w∗∥ = ∥w∗∥ and∥wt−w∗∥ ≥
2 0 2 2 2
∥vt∥ , we have
2
∥vt+1∥2 ≤ (1−µ6/(212b6))t∥w∗∥2 ≤ exp(−tµ6/(212b6))∥w∗∥2 .
2 2 2
Thus, after at most t = 212b6log(4b/µ)/µ6 iterations, it must hold that among all those vectors
0
v1,...,vt0, there exists a vector vt∗ 0 such that ∥vt∗ 0∥ 2 ≤ µ∥w∗∥ 2/(4b). Since there are only a constant
number of candidates, we can feed each one as the initialized input to the optimization subroutine
Algorithm 2. This will only result in a constant factor increase in the runtime and sample complexity.
Finally, recall that we need to draw
W9/2b4log4(d/(ϵδ))(cid:18)
1 1
(cid:19)
m ≳ +
L4 ϵ3/2 ϵδ
new samples at each iteration for (11) to hold with probability 1−δ, and the total number of
iterations is t . Thus, applying a union bound, we know that the probability that (11) holds for all
0
t is 1−t δ. Hence, choosing δ ← δt , and noting that t ≈ b6/µ6log(b/µ), it follows that setting
0 0 0 0
the batch size to be
(cid:18) W9/2b4log4(d/(ϵδ))(cid:18)
1
b6log(b/µ)(cid:19)(cid:19) (cid:18) W9/2b10dlog4(d/(ϵδ))(cid:19)
m = Θ + = Θ ,
0 L4 ϵ3/2 µ6ϵδ L4µ6δϵ3/2
suffices and the total number of samples required for the initialization process is t m .
0 0
164.2 Optimization
Our main optimization algorithm is summarized in Algorithm 2 (see Algorithm 4 for a more
detailed version). We now provide intuition for how guessing the value of ∥w∗∥ is used in the
2
convergence analysis. Let wt = ∥w∗∥ 2w¯t/∥w¯t∥
2
so that ∥wt∥
2
= ∥w∗∥
2
and let vt := (w∗)⊥ wt.
Observe that ∥vt∥ = ∥wt−w∗∥ cos(θ(wt,w∗)/2). Applying Proposition 3.1, it can be shown that
2 2
∥w¯t+1−w∗∥2 ≤ ∥wt−w∗∥2−C∥vt∥2 for some constant C. Thus, as long as the angle between wt
2 2 2
and w∗ is not too large (ensured by initialization), ∥wt−w∗∥ ≈ ∥vt∥ . Hence, we can argue that
2 2
∥wt−w∗∥ contracts in each iteration, by observing that ∥wt−w∗∥2 ≈ ∥vt+1∥2 ≤ ∥w¯t+1−w∗∥2.
2 2 2 2
Algorithm 2 Optimization
1: Input: wini = 0; ϵ > 0; positive parameters: a, b, L, R, W, µ; step size η
2: {wini,...,wini} = Initialization[wini] (Algorithm 1)
0 t0
3: P = {(w = 0;u(z) = 0)}
4: for k = 0 to t 0 ≲ (b/µ)6l √og(b/µ) do
5: for j = 1 to J = W/(η ϵ) do
√
6: w¯ j0 ,k = w kini, β j = jη ϵ
7: for t = 0 to T = O((b/µ)2log(1/ϵ)) do
8: w (cid:98)jt
,k
= β j(w¯ jt ,k/∥w¯ jt ,k∥ 2)
9: Draw m = Θ˜ (d/ϵ3/2) new samples
W,b,1/L,1/µ
m
10: uˆt
j,k
= argmin m1 (cid:80) (u(w (cid:98)jt
,k
·x(i))−y(i))2
u∈U (a,b) i=1
11: w¯ jt+ ,k1 = w (cid:98)jt
,k
−η∇L(cid:98)sur(w (cid:98)jt ,k;uˆt j,k)
12: end for
13: P ← P ∪{(w (cid:98)jT ,k;uˆT j,k)}
14: end for
15: end for
16: (w (cid:98);uˆ) = Test[(w;u) ∈ P] (Algorithm 3)
17: Return: (w (cid:98);uˆ)
Our main result is the following theorem (see Theorem D.1 for a more detailed statement and
proof in Appendix D.1):
Theorem 4.2 (Main Result). Let D be a distribution in Rd ×R and suppose that D is (L,R)-
x
well-behaved. Let U be as in Definition 1.3 and let ϵ > 0. Then, Algorithm 2 uses N =
(a,b) √
O˜ (d/ϵ2) samples, it runs for O˜ (1/ ϵ) iterations, and, with probability at least 2/3, re-
W,b,1/L,1/µ W,b,1/µ
turns a hypothesis (uˆ,w), where uˆ ∈ U and w ∈ B(W), such that L (w;uˆ) = O (OPT)+
(cid:98) (a,b) (cid:98) 2 (cid:98) 1/L,1/R,b/a
ϵ .
To prove Theorem 4.2, we make use of two technical results stated below. First, Lemma 4.3
provides an upper bound on the norm of the empirical gradient of the surrogate loss. The proof of
the lemma relies on concentration properties of (L,R)-well behaved distributions D , and leverages
x
the uniform convergence of the empirically-optimal activations uˆt. A more detailed statement
(Lemma D.5) and the proof of Lemma 4.3 is deferred to Appendix D.2.
Lemma 4.3 (Bound on Empirical Gradient Norm). Let S be a set of i.i.d. samples from D of size
m = Θ˜ (d/ϵ3/2+d/(ϵδ)). Given any wt ∈ B(W), let uˆt ∈ U be the solution of optimization
W,b,1/L (a,b)
problem (P) with respect to wt and sample set S. Then, with probability at least 1−δ,
∥∇L(cid:98)sur(wt;uˆt)∥2
2
≤ 4b2∥wt−w∗∥2 2+10(OPT+ϵ) .
17The following claim bounds the L2 error of a hypothesis uˆ (w·x) by the distance between w
2 w
and w∗. We defer a more detailed statement (Claim D.6) and the proof to Appendix D.3.
Claim 4.4. Let w ∈ B(W) be any fixed vector. Let uˆ be defined by (P) given w and a sample set
w
of size m = Θ˜ (d/ϵ3/2). Then, E [(uˆ (w·x)−y)2] ≤ 8(OPT+ϵ)+4b2∥w−w∗∥2.
W,b,1/L (x,y)∼D w 2
√ √
Proof Sketch of Theorem 4.2. For this sketch, we consider the case ∥w∗∥ ≳ b3/µ4( OPT+ ϵ)
2
so that the initialization subroutine generates a point w kin ∗i ∈ {w kini}t k0
=1
such that ∥(w∗)⊥ w kin ∗i∥
2
≤
µ∥w∗∥ /(4b), by Lemma 4.1. Fix this initialized parameter w¯0 = wini at step k∗ and drop the
2 j,k∗ √k∗
subscript k∗ for simplicity. Since we constructed a grid with width η ϵ, there exists an index j∗
√
such that |β −∥w∗∥ | ≤ η ϵ. We consider the intermediate for-loop at this iteration j∗, and show
j∗ 2
that the inner loop with normalization factor β outputs a solution with error O(OPT)+ϵ. This
j∗
solution can be selected using standard testing procedures. We now focus on the iteration j∗, and
drop the subscript j∗ for notational simplicity.
Let wt = ∥w∗∥ 2(w¯t/∥w¯t∥ 2) and denote vt := (w∗)⊥ w(cid:98)t. Expanding ∥w¯t+1−w∗∥2
2
and applying
Proposition 3.1 and Lemma 4.3, we get
∥w¯t+1−w∗∥2
2
= ∥w (cid:98)t−η∇L(cid:98)sur(w (cid:98)t;uˆt)−w∗∥2
2
= ∥w (cid:98)t−w∗∥2 2+η2∥∇L(cid:98)sur(w (cid:98)t;uˆt)∥2 2−2η∇L(cid:98)sur(w (cid:98)t;uˆt)·(w (cid:98)t−w∗)
≤ ∥wt−w∗∥2+η2(10(OPT+ϵ)+4b2∥wt−w∗∥2)
(cid:98) 2 (cid:98) 2
√ √
+2η(2( OPT+ ϵ)∥wt−w∗∥ −µ∥vt∥2)+4η(OPT+ϵ)/b
(cid:98) 2 2
≤ (1+4η2b2)∥wt−w∗∥2+(24η2+4η/b)(OPT+ϵ)
2
√ √
+2η(2( OPT+ ϵ)∥wt−w∗∥ −µ∥vt∥2), (13)
2 2
√
where in the last inequality we used ∥wt−wt∥ = |β −∥w∗∥ | ≤ η ϵ.
(cid:98) 2 j∗ 2
Since wt and w∗ are on the same sphere, ∥wt − w∗∥ ≤ ∥vt∥ . In particular, letting ρ =
2 2 t
∥vt∥ /∥w∗∥ , we have ∥wt−w∗∥2 ≤ (1+ρ2)∥vt∥2 ≤ 2∥vt∥2. Recall that the algorithm is initialized
2 2 2 t 2 2
from w¯0 that satisfies ρ ≤ µ/(4b). If ρ ≤ µ/(4b), then ∥wt − w∗∥2 ≤ (1 + (µ/(4b))2)∥vt∥2.
0 √t √ 2 2
Assuming in addition that ∥vt∥ ≳ (1/µ)( OPT+ ϵ), and choosing the step-size η = µ/(4b2), (13)
2
implies that
∥vt+1∥2 ≤ ∥w¯t+1−w∗∥2 ≤ (1−µ2/(32b2))∥vt∥2 ,
2 2 2
and thus, in addition, ρ ≤ µ/(4b). Therefore, by an inductive argument, we show that as long as
t+1 √ √
wt is still far from w∗, i.e., ∥vt∥ ≳ (1/µ)( OPT+ ϵ), we have
2
∥vt+1∥2 ≤ (1−µ2/(32b2))∥vt∥2 and ρ ≤ µ/(4b) .
2 2 t+1
√ √
Hence, after T = O((b2/µ2)log(1/ϵ)) iterations, it must be ∥vT∥ ≲ (1/µ)( OPT+ ϵ), which
2
implies
∥wT −w∗∥2 ≤ 2∥vT∥2 = O(OPT)+ϵ .
2 2
Finally, by Claim 4.4, hypothesis uˆT(wT ·x) achieves L2-error O(OPT)+ϵ, which completes the
(cid:98) 2
proof.
4.3 Testing
We now briefly discuss the testing procedure, which allows our algorithm to select a hypothesis
with minimum empirical error while maintaining validity of the claims. This part relies on standard
arguments and is provided for completeness. Concretely, we rely on the following claim, whose proof
can be found in Appendix D.4.
18Algorithm 3 Testing
1: Input: ϵ > 0; positive parameters: a, b, L, R, W; list of solutions P; let r ≳
1 log(bW/(Lϵ)log2(1/ϵ))
L
2:
Draw m′ ≳ (bW/L)4log5(1/ϵ)/ϵ2 new i.i.d. samples from D.
3: (w (cid:98);uˆ) = argmin (w;u)∈P{ m1
′
(cid:80)m i=′ 1(u(w·x(i))−y(i))21{|w·x(i)| ≤ Wr}}.
4: Return: (w (cid:98);uˆ)
Claim 4.5. Let µ, ϵ , δ ∈ (0,1) be fixed. Let r = 1 log(Cb4W4 log2(bW)), where C is a sufficiently
1 L L6ϵ2
1
ϵ1
large absolute constant. Given a set of parameter-activation pairs P = {(w ;u )}t0J such that
√ j j j=1
w ∈ B(W) and u ∈ U for j ∈ [t J], where t J = 4b9W/(µ8 ϵ ), we have that using
j j (a,b) 0 0 1
(cid:18) b4W4log(1/δ) (cid:18) bW (cid:19)(cid:19)
m′ = Θ log5 ,
L4ϵ2 Lµϵ
1 1
i.i.d. samples from D, for any (w ;u ) ∈ P it holds with probability at least 1−δ,
j j
(cid:12) m′ (cid:12)
(cid:12) (cid:12) (cid:12)m1 ′ (cid:88) (u j(w j ·x(i))−y(i))21{|w j ·x(i)| ≤ Wr}− (x,yE )∼D[(u j(w j ·x)−y)2](cid:12) (cid:12) (cid:12) ≤ 2ϵ 1.
i=1
Therefore, Claim 4.5 guarantees that selecting a hypothesis using the provided testing procedure
introduces an error at most 2ϵ , with high probability.
1
5 Conclusion
We presented the first constant-factor approximate SIM learner in the agnostic model, for the class
of (a,b)-unbounded link functions under mild distributional assumptions. Immediate questions for
future research involve extending these results to other classes of link functions. More specifically, our
results require that b/a is bounded by a constant. It is an open question whether the constant-factor
approximation result in the agnostic model can be extended to all b-Lipschitz functions (with a = 0).
This question is open in full generality, even when the link function is known to the learner.
References
[ATV23] P. Awasthi, A. Tang, and A. Vijayaraghavan. Agnostic learning of general ReLU
activation using gradient descent. In The Eleventh International Conference on Learning
Representations, ICLR, 2023.
[BNPS17] J. Bolte, T. P. Nguyen, J. Peypouquet, and B. W. Suter. From error bounds to
the complexity of first-order descent methods for convex functions. Mathematical
Programming, 165(2):471–507, 2017.
[BNS16] S. Bhojanapalli, B. Neyshabur, and N. Srebro. Global optimality of local search for low
rank matrix recovery. Advances in Neural Information Processing Systems, 29, 2016.
[DGK+20] I. Diakonikolas, S. Goel, S. Karmalkar, A. R. Klivans, and M. Soltanolkotabi. Approxi-
mation schemes for ReLU regression. In Conference on Learning Theory, COLT, volume
125 of Proceedings of Machine Learning Research, pages 1452–1485. PMLR, 2020.
19[DH18] R. Dudeja and D. Hsu. Learning single-index models in Gaussian space. In Conference
on Learning Theory, COLT, volume 75 of Proceedings of Machine Learning Research,
pages 1887–1930. PMLR, 2018.
[DJS08] A. S. Dalalyan, A. Juditsky, and V. Spokoiny. A new algorithm for estimating the
effective dimension-reduction subspace. The Journal of Machine Learning Research,
9:1647–1678, 2008.
[DKMR22] I. Diakonikolas, D. Kane, P. Manurangsi, and L. Ren. Hardness of learning a single
neuron with adversarial label noise. In Proceedings of the 25th International Conference
on Artificial Intelligence and Statistics (AISTATS), 2022.
[DKPZ21] I. Diakonikolas, D. M. Kane, T. Pittas, and N. Zarifis. The optimality of polynomial
regressionforagnosticlearningunderGaussianmarginalsintheSQmodel. InProceedings
of The 34th Conference on Learning Theory, COLT, 2021.
[DKR23] I. Diakonikolas, D. M. Kane, and L. Ren. Near-optimal cryptographic hardness of
agnostically learning halfspaces and ReLU regression under Gaussian marginals. In
ICML, 2023.
[DKTZ20] I. Diakonikolas, V. Kontonis, C. Tzamos, and N. Zarifis. Learning halfspaces with
massart noise under structured distributions. In Conference on Learning Theory, COLT,
2020.
[DKTZ22] I. Diakonikolas, V. Kontonis, C. Tzamos, and N. Zarifis. Learning a single neuron with
adversarial label noise via gradient descent. In Conference on Learning Theory (COLT),
pages 4313–4361, 2022.
[DKZ20] I. Diakonikolas, D. M. Kane, and N. Zarifis. Near-optimal SQ lower bounds for agnosti-
cally learning halfspaces and ReLUs under Gaussian marginals. In Advances in Neural
Information Processing Systems, NeurIPS, 2020.
[FCG20] S. Frei, Y. Cao, and Q. Gu. Agnostic learning of a single neuron with gradient descent.
In Advances in Neural Information Processing Systems, NeurIPS, 2020.
[FP03] F. Facchinei and J-S. Pang. Finite-dimensional variational inequalities and complemen-
tarity problems. Springer, 2003.
[GGK20] S. Goel, A. Gollakota, and A. R. Klivans. Statistical-query lower bounds via functional
gradients. In Advances in Neural Information Processing Systems, NeurIPS, 2020.
[GGKS23] A. Gollakota, P. Gopalan, A. R. Klivans, and K. Stavropoulos. Agnostically learning
single-index models using omnipredictors. In Thirty-seventh Conference on Neural
Information Processing Systems, 2023.
[Hau92] D. Haussler. Decision theoretic generalizations of the PAC model for neural net and
other learning applications. Information and Computation, 100:78–150, 1992.
[HJS01] M. Hristache, A. Juditsky, and V. Spokoiny. Direct estimation of the index coefficient in
a single-index model. Annals of Statistics, pages 595–623, 2001.
[HMS+04] W.Härdle, M.Müller, S.Sperlich, A.Werwatz, etal. Nonparametric and semiparametric
models, volume 1. Springer, 2004.
20[Hof52] A. J. Hoffman. On approximate solutions of systems of linear inequalities. Journal of
Research of the National Bureau of Standards, 49:263–265, 1952.
[Ich93] H. Ichimura. Semiparametric least squares (SLS) and weighted SLS estimation of
single-index models. Journal of econometrics, 58(1-2):71–120, 1993.
[JGN+17] C. Jin, R. Ge, P. Netrapalli, S. Kakade, and M. Jordan. How to escape saddle points
efficiently. In International conference on machine learning, pages 1724–1732. PMLR,
2017.
[KKSK11] S. M Kakade, V. Kanade, O. Shamir, and A. Kalai. Efficient learning of generalized
linear and single index models with isotonic regression. Advances in Neural Information
Processing Systems, 24, 2011.
[KNS16] H. Karimi, J. Nutini, and M. Schmidt. Linear convergence of gradient and proximal-
gradient methods under the Polyak-łojasiewicz condition. In Joint European conference
on machine learning and knowledge discovery in databases, pages 795–811, 2016.
[KS09] A. T. Kalai and R. Sastry. The isotron algorithm: High-dimensional isotonic regression.
In COLT, 2009.
[KSS94] M. Kearns, R. Schapire, and L. Sellie. Toward efficient agnostic learning. Machine
Learning, 17(2/3):115–141, 1994.
[LCP22] J. Liu, Y. Cui, and J-S. Pang. Solving nonsmooth and nonconvex compound stochastic
programs with applications to risk measure minimization. Mathematics of Operations
Research, 2022.
[LH22] C. Lu and D. S. Hochbaum. A unified approach for a 1D generalized total variation
problem. Mathematical Programming, 194(1-2):415–442, 2022.
[Łoj63] S. Łojasiewicz. Une propriété topologique des sous-ensembles analytiques réels. Les
équations aux dérivées partielles, 117:87–89, 1963.
[Łoj93] S. Łojasiewicz. Sur la géométrie semi-et sous-analytique. In Annales de l’institut Fourier,
volume 43, pages 1575–1595, 1993.
[MR18] P. Manurangsi and D. Reichman. The computational complexity of training ReLU(s).
arXiv preprint arXiv:1810.04207, 2018.
[Rd17] V. Roulet and A. d’Aspremont. Sharpness, restart and acceleration. Advances in Neural
Information Processing Systems, 30, 2017.
[Sím02] J. Síma. Training a single sigmoidal neuron is hard. Neural Computation, 14(11):2709–
2728, 2002.
[WZDD23] P. Wang, N. Zarifis, I. Diakonikolas, and J. Diakonikolas. Robustly learning a single
neuron via sharpness. 40th International Conference on Machine Learning, 2023.
[ZL16] Q. Zheng and J. Lafferty. Convergence analysis for rectangular matrix completion using
Burer-Monteiro factorization and gradient descent. arXiv preprint arXiv:1605.07051,
2016.
[ZY13] H. Zhang and W. Yin. Gradient methods for convex minimization: better rates under
weaker conditions. arXiv preprint arXiv:1303.4645, 2013.
21Appendix
Organization The appendix is organized as follows. In Appendix A, we highlight some useful
properties about the distribution class and the activation class. Appendix B reviews local error
bounds and discussed their relation to our alignment sharpness structural result. In Appendix C,
we provide detailed proofs omitted from Section 3, and in Appendix D we complete the proofs
omitted from Section 4. In Appendix E, we provide a detailed discussion about computing the
sample-optimal activation. Finally, in Appendix F we state and prove standard uniform convergence
results that are used throughout the paper.
A Remarks about the Distribution Class and the Activation Class
In this section, we show that without the loss of generality we can assume that the parameters L,R
in the distributional assumptions (Definition 1.2) can be taken less than 1, while the parameters a,b
of the activations functions (see Definition 1.3) can be taken as a,1/b ≤ 1.
Remark A.1 (Distribution/Activation Parameters, (Definition 1.2 & Definition 1.3)). We observe
that if a distribution D is (L,R)-well-behaved, then it is also (L′,R′)-well-behaved for any 0 < L′ ≤
x
L,0 < R′ ≤ R. Hence, it is without loss of generality to assume that L,R ∈ (0,1]. Similarly, if an
activation is (a,b)-unbounded, it is also an (a,b′)-unbounded activation with b′ ≥ b. Thus, we assume
that b ≥ 1. We can similarly assume a ≤ 1.
In addition, we remark that the (L,R)-well behaved distributions are sub-exponential.
Remark A.2 (Sub-exponential Tails of Well-Behaved Distributions, Definition 1.2). Definition 1.2
might seem abstract, but to put it plain it implies that the random variable x has a (1/L)-sub-
exponential tail, and that the pdf of the projected random variable x onto the space V is lower
V
bounded by L. To see the first statement, given any unit vector p, let x be the projection of x onto
p
the one-dimensional linear space V = {z ∈ Rd : z = tp,t ∈ R}, i.e., x = p·x ∈ V . Then, by the
p p p
anti-concentration and concentration property, we have
(cid:90) (cid:90) ∞ 1 2
Pr[|p·x| ≥ r] = Pr[|x | ≥ r] ≤ γ(x)dx ≤ 2 exp(−Lx)dx = exp(−Lr),
p L L2
|x|≥r r
which implies that x possesses a sub-exponential tail.
B Local Error Bounds and Alignment Sharpness
Givenagenericoptimizationproblemmin f(w)andanon-negativeresidualfunctionr(w)measuring
w
the approximation error of the optimization problem, we say that the problem satisfies a local error
bound if in some neighborhood of “test” (typically optimal) solutions W∗ we have that
r(w) ≥ (µ/ν)dist(w,W∗)ν. (14)
In other words, low value of the residual function implies that w must be close to the test set W∗.
Local error bounds have been studied in the optimization literature for decades, starting with the
seminal works of [Hof52, Łoj63]; see, e.g., Chapter 6 in [FP03] for an overview of classical results and
[BNPS17, KNS16, Rd17, LCP22] and references therein for a more cotemporary overview. While
local error bounds can be shown to hold generically under fairly minimal assumptions on f and for
22r(w) = f(w)−min f(w′) [Łoj63, Łoj93], it is rarely the case that they can be ensured to hold
w′
with a parameter µ that is not trivially small.
On the other hand, learning problems often possess very strong structural properties that can
lead to stronger local error bounds. There are two main such examples we are aware of, where local
error bounds can be shown to hold with ν = 2 and an absolute constant µ > 0. The first example
are low-rank matrix problems such as matrix completion and matrix sensing, which are unrelated
to our work [BNS16, ZL16, JGN+17]. More relevant to our work is the recent result in [WZDD23],
which proved a local error bound of the form
µ
r(w) ≥ dist(w,W∗)2 (15)
2
for the more restricted problem than ours (with a known activation function) but under somewhat
more general distributional assumptions. In [WZDD23], the residual function was defined by
r(wt) = ∇L(cid:98)sur(wt;u∗)·(wt−w∗), where ∇L(cid:98)sur(wt;u∗) is the gradient of an empirical surrogate
loss, and the resulting local error bound referred to as “sharpness.”2
Our structural result can be seen as a weak notion of a local error bound, where the residual
functionfortheempiricalsurrogatelossexpressedasr(wt,uˆt) = ∇L(cid:98)sur(wt;uˆt)·(wt−w∗)isbounded
below as a function of the magnitude of the component of w∗ that is orthogonal to wt. Compared to
more traditional local error bounds and the bound from [WZDD23], which bound below the residual
error function as a function of the distance to W∗, this is a much weaker local error bound since it
does not distinguish between vectors of varying magnitudes along the direction of w∗. Since our lower
bound is related to the “sharpness” notion studied in [WZDD23], we refer to it as the “alignment
sharpness” to emphasize that it only relates the misalignment (as opposed to the distance) of vectors
wt and w∗ to the residual error. To the best of our knowledge, such a form of a local error bound,
which only bounds the alignment of vectors as opposed to their distance, is novel. We expect it to
find a more broader use in learning theory and optimization.
C Omitted Proofs from Section 3
This section provides full technical details for results omitted from Section 3.
C.1 Proof of Lemma 3.3
To prove Lemma 3.3, we first prove the following auxiliary claim, which is inspired by [KKSK11,
Lemma 9].
Claim C.1. Let wt ∈ B(W) and let u∗t,ut be defined as solutions to (EP*), (EP), respectively.
Then,
E [(ut(wt·x)−v(wt·x))(y−ut(wt·x))] ≥ 0, ∀ ∈ U .
(a,b)
(x,y)∼D
Similarly,
E [(u∗t(wt·x)−v′(wt·x))(y∗−u∗t(wt·x))] ≥ 0, ∀v′ ∈ U .
(a,b)
(x,y)∼D
Proof of Claim C.1. Denote by F the set of functions of the form f(x) = u(wt·x), where u ∈ U
t (a,b)
and wt is a fixed vector in B(W). We first argue that F is a convex set, using the definition of
t
2A local error utilizing the same type of a residual was introduced in [ZY13] under the name “restricted secant
inequality.”
23convexity. In particular, for any α ∈ (0,1) and any f ,f ∈ F such that f (x) = u (wt·x),f =
1 2 t 1 1 2
u (wt·x), let u (·) = αu (·)+(1−α)u (·). Then:
2 3 1 2
αf (x)+(1−α)f (x) = αu (wt·x)+(1−α)u (wt·x) = u (wt·x).
1 2 1 2 3
It is immediate that u is also (a,b)-bounded, non-decreasing, and u (0) = 0, hence u ∈ U and
3 3 3 (a,b)
f (x) = u (wt·x) ∈ F . Thus, F is convex.
3 3 t t
Since F is a convex set of functions, we can regard ut(wt·x) as the orthogonal projection of y
t
(which is a function of x) onto the convex set F . Classic inequalities for orthogonal projections can
t
then be applied to our case. In particular, below we prove that
E [(ut(wt·x)−v(wt·x))(y−ut(wt·x))] ≥ 0, ∀v ∈ U . (16)
(a,b)
(x,y)∼D
To prove (16), note first that f (x) = ut(wt·x) ∈ F and f (x) = v(wt·x) ∈ F since ut,v ∈ U .
u t v t (a,b)
Thus, for any α ∈ (0,1), we have αf (x)+(1−α)f (x) ∈ F . Furthermore, by definition of ut,
v u t
∀f ∈ F we have E [(ut(wt·x)−y)2] ≤ E [(f(x)−y)2], therefore, it holds:
t (x,y)∼D (x,y)∼D
1 1
0 ≤ E [(αf (x)+(1−α)f (x)−y)2]− E [(ut(wt·x)−y)2]
v u
α (x,y)∼D α (x,y)∼D
1
= E [(ut(wt·x)−y+α(v(wt·x)−ut(wt·x)))2−(ut(wt·x)−y)2]
α (x,y)∼D
= E [2(ut(wt·x)−y)(v(wt·x)−ut(wt·x))+α(v(wt·x)−ut(wt·x))2].
(x,y)∼D
Let α ↓ 0, and note that E [(v(wt·x)−ut(wt·x))2] < +∞, we thus have
x∼Dx
E [(ut(wt·x)−v(wt·x))(y−ut(wt·x))] ≥ 0,
(x,y)∼D
proving the claim.
The second claim can be proved following the same argument and is omitted for brevity.
We now proceed to the proof of Lemma 3.3.
Lemma 3.3 (Closeness of Population-Optimal Activations). Let wt ∈ B(W) and let u∗t, ut be
defined as solutions to (EP*), (EP), respectively. Then,
E [(ut(wt·x)−u∗t(wt·x))2] ≤ OPT.
x∼Dx
Proof. Summing up the first and second statement of Claim C.1 with v = u∗t ∈ U in (16) and
(a,b)
v′ = ut ∈ U , we get:
(a,b)
0 ≤ E [(ut(wt·x)−u∗t(wt·x))(y−ut(wt·x))+(u∗t(wt·x)−ut(wt·x))(y∗−u∗t(wt·x))]
(x,y)∼D
= E [(ut(wt·x)−u∗t(wt·x))(y−y∗+u∗t(wt·x)−ut(wt·x))]
(x,y)∼D
= E [(ut(wt·x)−u∗t(wt·x))(y−y∗)]− E [(ut(wt·x)−u∗t(wt·x))2]
(x,y)∼D x∼Dx
Rearranging and applying the Cauchy-Schwarz inequality, we have
E [(ut(wt·x)−u∗t(wt·x))2] ≤ E [(ut(wt·x)−u∗t(wt·x))(y−y∗)]
x∼Dx (x,y)∼D
(cid:114)
≤ E [(ut(wt·x)−u∗t(wt·x))2]E[(y−y∗)2].
x∼Dx
To complete the proof, it remains to recall that E[(y − y∗)2] = OPT and rearrange the last
inequality.
24C.2 Proof of Corollary 3.4
Corollary 3.4 (Closeness of Idealized and Attainable Activations). Let ϵ,δ > 0. Given a parameter
wt ∈ B(W) and m ≳ dlog4(d/(ϵδ))(b2W3/(L2ϵ))3/2 samples from D, let uˆt be the sample-optimal
activation on these samples given wt, as defined in (P). Then, with probability at least 1−δ,
E [(uˆt(wt·x)−u∗(w∗·x))2] ≤ 3(ϵ+OPT+b2∥wt−w∗∥2) .
2
x∼Dx
Proof. The corollary follows directly from the combination of Lemma F.4 and Lemma 3.3, as we
have:
E [(uˆt(wt·x)−u∗(w∗·x))2]
x∼Dx
= E [(uˆt(wt·x)−ut(wt·x)+ut(wt·x)−u∗t(wt·x)+u∗t(wt·x)−u∗(w∗·x))2]
x∼Dx
≤ 3( E [(uˆt(wt·x)−ut(wt·x))2]+ E [(ut(wt·x)−u∗t(wt·x))2])
x∼Dx x∼Dx
+3 E [(u∗t(wt·x)−u∗(w∗·x))2]
x∼Dx
≤ 3(ϵ+OPT+b2∥wt−w∗∥2),
2
whereweusedthatbecauseu∗t ∈ argmin E [(u(wt·x)−u∗(w∗·x))2],wehaveE [(u∗t(wt·
u∈U
(a,b)
x∼Dx x∼Dx
x)−u∗(w∗ ·x))2] ≤ E [(u∗(wt ·x)−u∗(w∗ ·x))2] ≤ b2∥wt −w∗∥2, with the last inequality
x∼Dx 2
following from the fact that u∗ ∈ U .
(a,b)
C.3 Proof of Claim 3.5
In this subsection, we prove Claim 3.5 that appeared in Section 3.3, the proof of Proposition 3.1.
Claim 3.5. Let S = {(x(i),y(i))}m be i.i.d. samples from D where m is as specified in the statement
i=1
of Proposition 3.1. Let uˆt be the solution of optimization problem (P) given wt ∈ B(W) and S.
Furthermore, denote the idealized version of S by S∗ = {(x(i),y∗(i))}m , where y∗(i) = u∗(w∗·x(i)).
i=1
Let uˆ∗t be the solution of problem (P*). Then, with probability at least 1−δ,
1 (cid:88)m √ √
Q = ((uˆt(wt·x(i))−uˆ∗t(wt·x(i)))(wt−w∗)·x(i) ≥ −( ϵ+ OPT)∥wt−w∗∥ −(ϵ+OPT)/b .
1 2
m
i=1
Proof. Adding and subtracting ut(wt·x(i)) and u∗t(wt·x(i)), we have
m
1 (cid:88)
((uˆt(wt·x(i))−uˆ∗t(wt·x(i)))(wt−w∗)·x(i)
m
i=1
m m
1 (cid:88) 1 (cid:88)
= (uˆt(wt·x(i))−ut(wt·x(i)))(wt−w∗)·x(i)+ (u∗t(wt·x(i))−uˆ∗t(wt·x(i)))(wt−w∗)·x(i)
m m
i=1 i=1
m
1 (cid:88)
+ (ut(wt·x(i))−u∗t(wt·x(i)))(wt−w∗)·x(i). (17)
m
i=1
To proceed, we use that both uˆ∗t(z) and uˆt(z) are close to their population counterparts ut(z) and
u∗t(z), respectively. In particular, in Lemma F.4 and Lemma F.2, we show that using a dataset S of
m samples such that
(cid:18) b2W3(cid:19)3/2
m ≳ dlog4(d/(ϵδ)) ,
L2ϵ
25we have that with probability at least 1−δ, for all wt,w∗ ∈ B(W) it holds
E [(uˆt(wt·x)−ut(wt·x))2] ≤ ϵ, E [(uˆ∗t(wt·x)−u∗t(wt·x))2] ≤ ϵ. (18)
x∼Dx x∼Dx
Now suppose that the inequalities in (18) hold for the given wt ∈ B(W) (which happens with
probability at least 1−δ). Applying Chebyshev’s inequality to the first summation term in (17), we
get:
(cid:20)(cid:12) m (cid:12) (cid:21)
Pr (cid:12) (cid:12) 1 (cid:88) (uˆt(wt·x(i))−ut(wt·x(i)))(wt−w∗)·x(i)− E [(uˆt(wt·x)−ut(wt·x))(wt−w∗)·x](cid:12) (cid:12) ≥ s
(cid:12)m x∼Dx (cid:12)
i=1
1
≤ E [(uˆt(wt·x)−ut(wt·x))2(wt·x−w∗·x)2], (19)
ms2 x∼Dx
since x(i) are i.i.d. random variables. The next step is to bound the variance. Note that D possesses
x
a 1/L-sub-exponential tail, thus we have Pr[|(wt −w∗)·x| ≥ ∥wt −w∗∥ r] ≤ (2/L2)exp(−Lr).
2
Choose r = 2W log(2/(L2ϵ′)); then, we have Pr[|(wt −w∗)·x| ≥ r] ≤ ϵ′. Now we separate the
L
variance under the event A = {x : |(wt−w∗)·x| ≤ r} and its complement.
E [(uˆt(wt·x)−ut(wt·x))2(wt·x−w∗·x)2]
x∼Dx
= E [(uˆt(wt·x)−ut(wt·x))2(wt·x−w∗·x)21{A}] (20)
x∼Dx
+ E [(uˆt(wt·x)−ut(wt·x))2(wt·x−w∗·x)2(1−1{A})].
x∼Dx
Using that E [(uˆt(wt·x)−ut(wt·x))2] ≤ ϵ, the first term in (20) can be bounded as follows:
x∼Dx
E [(uˆt(wt·x)−ut(wt·x))2(wt·x−w∗·x)21{A}] ≤ r2 E [(uˆt(wt·x)−ut(wt·x))2]
x∼Dx x∼Dx
4W2ϵ
≤ r2ϵ = log2(2/(L2ϵ′)). (21)
L2
The second term in (20) can be bounded using that both uˆt and ut are non-decreasing b-Lipschitz
and vanish at zero (thus |uˆt(wt·x)| ≤ b|wt·x| and |ut(wt·x)| ≤ b|wt·x|, with their signs determined
by the sign of wt·x), and then applying Young’s inequality:
E [(uˆt(wt·x)−ut(wt·x))2(wt·x−w∗·x)2(1−1{A})]
x∼Dx
≤ b2 E [(wt·x)2(wt·x−w∗·x)2(1−1{A})]
x∼Dx
≤ 2b2 E [((wt·x)4+(wt·x)2(w∗·x)2)(1−1{A})] .
x∼Dx
Since D is sub-exponential, we have E[(v·x)8] ≤ c2/L8 for some absolute constant c, hence
x
(cid:114) √
E [(wt·x)4(1−1{A})] ≤ E [W8((wt/∥wt∥ )·x)8]Pr[|wt·x| ≥ r] ≤ cW4 ϵ′/L4.
2
x∼Dx x∼Dx
Similarly, for E[(wt·x)2(w∗·x)2(1−1{A})], we have:
√
E [(wt·x)2(w∗·x)2(1−1{A})] ≤ 2 E [((wt·x)4+(w∗·x)4)(1−1{A})] ≤ 2c(W/L)4 ϵ′.
x∼Dx x∼Dx
26Combining the inequalities above with (21), we get the final upper bound on the variance in (20):
4W2ϵ √
E [(uˆt(wt·x)−ut(wt·x))2(wt·x−w∗·x)2] ≤ log2(2/(L2ϵ′))+6cb2(W/L)4 ϵ′.
x∼Dx L2
Thus, choosing s = ϵ/b in (19), ϵ′ = ϵ2, and using m ≳ W4b4log2(1/ϵ)/(ϵδL4) samples we get
√
1 (cid:18) 4W2ϵ 12cb2W4 ϵ′(cid:19) b2L4ϵδ (cid:18) W2ϵ (cid:18) 1 (cid:19) b2W4ϵ(cid:19)
log2(2/(Lϵ′))+ ≲ log2 + ≤ δ .
ms2 L2 L4 ϵ2W4b4log2(1/ϵ) L2 Lϵ L4
Plugging the inequality above back into (19) and recalling that E [(uˆt(wt·x)−ut(wt·x))2] ≤ ϵ
x∼Dx
(from (18)), we finally have with probability at least 1−δ,
m
1 (cid:88)
(uˆt(wt·x(i))−ut(wt·x(i)))(wt−w∗)·x(i)
m
i=1
≥ E [(uˆt(wt·x)−ut(wt·x))(wt−w∗)·x]−ϵ/b
x∼Dx
(cid:114)
≥ − E [(uˆt(wt·x)−ut(wt·x))2] E [(wt·x−w∗·x)2]−ϵ/b
x∼Dx x∼Dx
√
≥ − ϵ∥wt−w∗∥ −ϵ/b,
2
where in the second inequality we used the Cauchy-Schwarz inequality and in the last inequality we
used the assumption that E [xx⊤] ≼ I. Finally, noting that (18) holds with probability at least
x∼Dx
1−δ, applying a union bound we get that with probability at least 1−2δ, we have
1 (cid:88)m √
(uˆt(wt·x(i))−ut(wt·x(i)))(wt−w∗)·x(i) ≥ − ϵ∥wt−w∗∥ −ϵ/b .
2
m
i=1
In summary, to guarantee that the inequality above remains valid, we need the batch size to be:
dW9/2b4log4(d/(ϵδ)(cid:18)
1 1
(cid:19)
m ≳ + . (22)
L4 ϵ3/2 ϵδ
We finished bounding the first term in (17).
Since the same statements hold for the relationship between uˆ∗t and u∗t as they do for uˆt and ut,
using the same argument we also get that with probability at least 1−2δ,
1 (cid:88)m √
(uˆ∗t(wt·x(i))−u∗t(wt·x(i)))(wt−w∗)·x(i) ≥ − ϵ∥wt−w∗∥ −ϵ/b,
2
m
i=1
which is the lower bound for the second term in (17).
Lastly, for the third term in (17), since in Lemma 3.3 we showed that for any wt it always holds:
E [(ut(wt·x)−u∗t(wt·x))2] ≤ OPT,
x∼Dx
the only change of the previous steps is at the right-hand side of (21), where instead of having the
upper bound of r2ϵ, we have
4W2OPT
E [(ut(wt·x)−u∗t(wt·x))2(wt·x−w∗·x)21{A}] ≤ r2OPT = log2(2/(L2ϵ′)).
x∼Dx L2
27By the same token, we have
√
E [(ut(wt·x)−u∗t(wt·x))2(wt·x−w∗·x)2(1−1{A})] ≤ 6cb2(W/L)4 ϵ′.
x∼Dx
As a result, Chebyshev’s inequality yields:
(cid:20)(cid:12) m (cid:12) (cid:21)
Pr (cid:12) (cid:12) 1 (cid:88) (ut(wt·x(i))−u∗t(wt·x(i)))(wt−w∗)·x(i)− E [(ut(wt·x)−u∗t(wt·x))(wt−w∗)·x](cid:12) (cid:12) ≥ s
(cid:12)m x∼Dx (cid:12)
i=1
1
≤ E [(ut(wt·x)−u∗t(wt·x))2(wt·x−w∗·x)2]
ms2 x∼Dx
√
1 (cid:18) 4W2OPT 6cb2W4 ϵ′(cid:19)
≤ log2(2/(L2ϵ′))+ .
ms2 L2 L4
Now instead of choosing s = ϵ, we let s = (OPT+ϵ)/b and keep ϵ′ as ϵ2 to get
√
1 (cid:18) 4W2OPT (cid:18) 2 (cid:19) 12cb2W ϵ′(cid:19)
log2 +
ms2 L2 L2ϵ′ L4
b2L4ϵδ (cid:18) W2OPT (cid:18) 1 (cid:19) b2W4ϵ(cid:19)
≲ log2 +
dW9/2b4log4(d/(ϵδ))(OPT+ϵ)2 L2 Lϵ L4
≤ δ,
under our choice of m as specified in (22). Thus, we have that with probability at least 1−δ, it holds
m
1 (cid:88)
(ut(wt·x(i))−u∗t(wt·x(i)))(wt−w∗)·x(i) ≥ E [(ut(wt·x)−u∗t(wt·x))(wt−w∗)·x]−(OPT+ϵ)/b
m x∼Dx
i=1
√
≥ − OPT∥wt−w∗∥ −(OPT+ϵ)/b,
2
where in the last inequality we used the fact that
(cid:114)
| E [(ut(wt·x)−u∗t(wt·x))(wt−w∗)·x]| ≤ E [(ut(wt·x)−u∗t(wt·x))2] E [((wt−w∗)·x)2]
x∼Dx x∼Dx x∼Dx
√
≤ OPT∥wt−w∗∥ ,
2
since E [(ut(wt·x)−u∗t(wt·x))2] ≤ OPT by Lemma 3.3.
x∼Dx
Therefore, combining the upper bounds on the three terms in (17), we get that with probability
at least 1−5δ, it holds:
1 (cid:88)m √ √
((uˆt(wt·x(i))−uˆ∗t(wt·x(i)))(wt−w∗)·x(i) ≥ −(2 ϵ+ OPT)∥wt−w∗∥ −(3ϵ+OPT)/b. (23)
2
m
i=1
Since (23) was proved using arbitrary ϵ,δ > 0, it remains to replace δ ← δ/5 and ϵ ← ϵ/4 to complete
the proof of Claim 3.5.
C.4 Proof of Claim 3.6
In this subsection, we prove Claim 3.6 that appeared in the proof of Proposition 3.1 in Section 3.3.
28Claim 3.6. Let S∗ = {(x(i),y∗(i))}m be a sample set such that x(i)’s are i.i.d. samples from D
i=1 x
and y∗(i) = u∗(w∗·x(i)) for each i. Let m be the value specified in the statement of Proposition 3.1.
Then, given a parameter wt ∈ B(W), with probability at least 1−δ,
1 (cid:88)m Ca2LR4 √
Q
2
=
m
(uˆ∗t(wt·x(i))−y∗(i))(wt−w∗)·x(i) ≥
b
∥(w∗)⊥ wt∥2 2− ϵ∥wt−w∗∥ 2−ϵ/b ,
i=1
where C is an absolute constant.
Proof. Before we proceed to the proof of the claim, let us consider first the inverse of u∗. Since
u∗(z) ∈ U is strictly increasing when z ≥ 0, (u∗)−1(α) exists for α ≥ 0. However, when z ≤ 0,
(a,b)
u∗(z) could be constant on some intervals, hence (u∗)−1(α) might not exist for every α ≤ 0. We
consider instead an ‘empirical’ version of (u∗)−1(α) based on S∗, which is defined on every α ∈ R.
Given a sample set S∗ = {(x(i),y∗(i))} where y∗(i) = u∗(w∗ ·x(i)), let us sort the index i in the
increasing order of w∗·x(i), i.e., w∗·x(1) ≤ ··· ≤ w∗·x(m). Since u∗ is a monotone function, this
implies y∗(i)’s are also in increasing order, i.e., we have y∗(1) ≤ ··· ≤ y∗(m). We then partition the
set {y∗(i)}m into blocks
i=1
∆ = {y∗(ks−1+1),...,y∗(ks)}, s.t. y∗(ks−1+1) = ··· = y∗(ks) = τ ,
s s
for s = 1,...,s′. Since {y∗(i)} is sorted in increasing order, we have τ < τ for s = 2,...,s′. Note
s−1 s
that since u∗(z) is strictly increasing when z ≥ 0 and as u∗(0) = 0, ∆ is a singleton set whenever
s
τ > 0. Furthermore, let us denote by s∗ the largest index among 1,...,s′ such that τ ≤ 0.
s s∗
Suppose first that τ < 0 and define a function fˆ: R → R in the following way:
s∗

(u∗)−1(α), α > 0


  

w∗·x(k s∗)+ α−
τ
sτ ∗s∗(w∗·x(k s∗)), α ∈ [τ s∗,0]
fˆ(α) = w∗·x(ks), α = τ s,s = 1,...,s∗−1 (24)
  


w∗·x(ks−1)+ τα s− −τ τs s− −1 1(w∗·x(ks−1+1)−w∗·x(ks−1)), α ∈ (τ s−1,τ s),s = 2,...,s∗
w∗·x(1)+ 1(α−τ ) . α ∈ (−∞,τ )
b 1 1
When τ = 0, we define (0−τ )/τ = −1, and hence fˆ(0) = 0. The rest remains unchanged. A
s∗ s∗ s∗
visualization of fˆwith respect to the ReLU activation is presented in Figure 3.
The function fˆ has the following properties. First, fˆ(α) satisfies fˆ(0) = 0, (α − α )/a ≥
1 2
fˆ(α )−fˆ(α ), for all α ≥ α ≥ 0, since fˆ(α) = (u∗)−1(α) when α > 0 and u∗ ∈ U . Second,
1 2 1 2 (a,b)
fˆ(α )−fˆ(α ) ≥ (α −α )/b for all α ,α ∈ R, α ≥ α . This is because each segment of fˆhas slope
1 2 1 2 1 2 1 2
at least 1/b. Third, for any α ≥ u∗(w∗·x(i)), it holds that fˆ(α)−w∗·x(i) ≥ (α−u∗(w∗·x(i)))/b.
To see this, suppose u∗(w∗·x(i)) ∈ ∆ . Then for any α ≥ τ , we have
s s
fˆ(α)−w∗·x(i) ≥ fˆ(α)−w∗·x(ks) = fˆ(α)−fˆ(τ ) = fˆ(α)−fˆ(u∗(w∗·x(i))) ≥ (α−u∗(w∗·x(i)))/b,
s
using that the slope of fˆ(α) is at least 1/b. On the other hand, when α < u∗(w∗ ·x(i)), we have
w∗·x(i)−fˆ(α) ≥ (u∗(w∗·x(i))−α)/b. This can be seen similarly from the construction of fˆ.
Finally, suppose u∗(w∗·x(i)) ∈ ∆ . Then for any α < τ , we have
s s
w∗·x(i)−fˆ(α) ≥ w∗·x(ks−1+1)−fˆ(α) = fˆ(τ )−fˆ(α) = fˆ(u∗(w∗·x(i)))−fˆ(α) ≥ (u∗(w∗·x(i))−α)/b.
s
Again, we used the fact that fˆ(α )−fˆ(α ) ≥ (α −α )/b for all α ,α ∈ R, α ≥ α in the last
1 2 1 2 1 2 1 2
inequality.
29Figure 3: An illustration of fˆ for u∗(z) = max{0,z} and a dataset S∗ = {(x(1),u∗(w∗ ·
x(1))),...,(x(6),u∗(w∗·x(6)))} where w∗·x(1) < w∗·x(2) < w∗·x(3) < 0.
Now we turn to the summation displayed in the statement of the claim. To proceed, we add and
subtract fˆ(uˆ∗t(wt·x)) in the second component in the inner product, which yields:
m
1 (cid:88)
(uˆ∗t(wt·x(i))−u∗(w∗·x(i)))(wt−w∗)·x(i)
m
i=1
m
1 (cid:88)
= (uˆ∗t(wt·x(i))−u∗(w∗·x(i)))(wt·x(i)−fˆ(uˆ∗t(wt·x(i))))
m
i=1
m
1 (cid:88)
+ (uˆ∗t(wt·x(i))−u∗(w∗·x(i)))(fˆ(uˆ∗t(wt·x(i)))−w∗·x(i)). (25)
m
i=1
To bound below the first term in (25), we make use of the following fact, whose proof can be found
in Appendix C.5.
Fact C.2. Let wt ∈ B(W). Given m samples S = {(x(1),y∗(1)),··· ,(x(m),y∗(m))}, let uˆ∗t be one of
the solutions to the optimization problem (P*) , i.e., uˆ∗t ∈ argmin (1/m)(cid:80)m (u(wt·x(i))−
u∈U (a,b) i=1
y∗(i))2. Then
m
(cid:88)
(uˆ∗t(wt·x(i))−y∗(i))(wt·x(i)−f(uˆ∗t(wt·x(i)))) ≥ 0,
i=1
for any function f : R → R such that f(0) = 0, (α −α )/a ≥ f(α )−f(α ) for all α ≥ α ≥ 0,
1 2 1 2 1 2
and f(α )−f(α ) ≥ (α −α )/b, ∀α ,α ∈ R, α ≥ α .
1 2 1 2 1 2 1 2
As we have already argued, fˆsatisfies the assumptions of Fact C.2, hence
m m
1 (cid:88) 1 (cid:88)
(uˆ∗t(wt·x(i))−y∗(i))(wt−w∗)·x(i) ≥ (uˆ∗t(wt·x(i))−y∗(i))(fˆ(uˆ∗t(wt·x(i)))−w∗·x(i)).
m m
i=1 i=1
(26)
Recall that we have shown the function fˆsatisfies fˆ(α)−w∗·x(i) ≥ (α−u∗(w∗·x(i)))/b ≥ 0
whenever α ≥ u∗(w∗ · x(i)), and moreover, w∗ · x(i) − fˆ(α) ≥ (u∗(w∗ · x(i)) − α)/b ≥ 0 when
30α < u∗(w∗·x(i)). Therefore, letting α = uˆ∗t(wt·x(i)) and combining these results we get
1
(uˆ∗t(wt·x(i))−u∗(w∗·x(i)))(f(uˆ∗t(wt·x(i)))−w∗·x(i)) ≥ (uˆ∗t(wt·x(i))−u∗(w∗·x(i)))2.
b
Plugging the inequality above back into (26) we then get
m m
1 (cid:88) 1 (cid:88)
(uˆ∗t(wt·x(i))−y∗(i))(wt−w∗)·x(i) ≥ (uˆ∗t(wt·x(i))−y∗(i))2 . (27)
m mb
i=1 i=1
The goal now is to bound below the right-hand side of (27) by E[(uˆ∗t(wt·x)−y∗)2] and some small
error terms using Chebyshev inequality as we did in Claim 3.5. Plugging in Lemma 3.2, we can
further lower bound E[(uˆ∗t(wt·x)−y∗)2] by ∥(w∗)⊥ wt∥2
2
and then we are done with the proof of
this claim. Note that Chebyshev’s inequality yields
(cid:20)(cid:12) m (cid:12) (cid:21)
Pr (cid:12) (cid:12) 1 (cid:88) (uˆ∗t(wt·x(i))−y∗(i))2− E [(uˆ∗t(wt·x)−y∗)2](cid:12) (cid:12) ≥ s ≤ 1 E [(uˆ∗t(wt·x)−y∗)4].
(cid:12)m x∼Dx (cid:12) ms2 x∼Dx
i=1
(28)
We now bound E [(uˆ∗t(wt·x)−y∗)4]. Observe that
x∼Dx
E [(uˆ∗t(wt·x)−y∗)4] = E [(uˆ∗t(wt·x)−u∗t(wt·x)+u∗t(wt·x)−y∗)2(uˆ∗t(wt·x)−y∗)2]
x∼Dx x∼Dx
≤ 4 E [(uˆ∗t(wt·x)−u∗t(wt·x))2((uˆ∗t(wt·x))2+(y∗)2)]
x∼Dx
+4 E [(u∗t(wt·x)−y∗)2((uˆ∗t(wt·x))2+(y∗)2)]. (29)
x∼Dx
We focus on the two terms in (29) separately. Again, choosing r = 2W log(2/(L2ϵ′)), then by the
L
L-sub-exponential tail bound of D , it holds Pr[|wt ·x| ≥ r] ≤ ϵ′,Pr[|w∗ ·x| ≥ r] ≤ ϵ′. Since
x
y∗ = u∗(w∗·x) and both u∗ and uˆ∗t are non-decreasing b-Lipschitz, it holds:
E [(uˆ∗t(wt·x)−u∗t(wt·x))2((uˆ∗t(wt·x))2+(y∗)2)]
x∼Dx
≤ b2 E [(uˆ∗t(wt·x)−u∗t(wt·x))2((wt·x)2+(w∗·x)2)]
x∼Dx
= b2 E [(uˆ∗t(wt·x)−u∗t(wt·x))2((wt·x)2+(w∗·x)2)1{|wt·x| ≤ r,|w∗·x| ≤ r}]
x∼Dx
+b2 E [(uˆ∗t(wt·x)−u∗t(wt·x))2((wt·x)2+(w∗·x)2)1{|wt·x| ≥ r or |w∗·x| ≥ r}]
x∼Dx
≤ 2b2r2 E [(uˆ∗t(wt·x)−u∗t(wt·x))2]
x∼Dx
+2b4 E [2(wt·x)2((wt·x)2+(w∗·x)2)1{|wt·x| ≥ r or |w∗·x| ≥ r}]. (30)
x∼Dx
The first term in (30) can be upper bounded using Lemma F.2, which states that when
m ≳ dlog(1/δ)(b2W3log2(d/ϵ)/(L2ϵ))3/2),
with probability at least 1−δ it holds E [(uˆ∗t(wt ·x)−u∗t(wt ·x))2] ≤ ϵ for all wt ∈ B(W).
x∼Dx
Now suppose this inequality is valid given wt ∈ B(W) (which happens with probability at least
1−δ). For the second term in (30), note that for any unit vector a it holds E [(a·x)8] ≤ c2/L8
x∼Dx
31for some absolute constant c > 0, and furthermore, the magnitude of r ensures that Pr[|wt·x| ≥
r or |w∗·x| ≥ r] ≤ 2ϵ′; therefore, combining these bounds, we get:
E [2(wt·x)2((wt·x)2+(w∗·x)2)1{|wt·x| ≥ r or |w∗·x| ≥ r}]
x∼Dx
(cid:114)
≤ 2 E [(wt·x)8]Pr[|wt·x| ≥ r or |w∗·x| ≥ r]
x∼Dx
(cid:114)
+2 2( E [(wt·x)8]+ E [(w∗·x)8])Pr[|wt·x| ≥ r or |w∗·x| ≥ r]
x∼Dx x∼Dx
√
≤ 24c(W/L)4 ϵ′.
Plugging back into (30), we have
√
E [(uˆ∗t(wt·x)−u∗t(wt·x))2((uˆ∗t(wt·x))2+(y∗)2)] ≤ 2b2r2ϵ+48c(bW/L)4 ϵ′,
x∼Dx
which is the upper bound on the first term of (29).
For the second term in (29), since by definition we have u∗t ∈ argmin E [(u(wt·x)−
u∈U
(a,b)
x∼Dx
y∗)2], it holds that
E [(u∗t(wt·x)−y∗)2] ≤ E [(u∗(wt·x)−u∗(w∗·x))2] ≤ b2 E [((wt−w∗)·x)2] ≤ b2∥wt−w∗∥2,
2
x∼Dx x∼Dx x∼Dx
noting in addition that E [xx⊤] ≼ I. Thus, using similar steps as in (30), we have
x∼Dx
E [(u∗t(wt·x)−y∗)2((uˆ∗t(wt·x))2+(y∗)2)]
x∼Dx
≤ 2b2r2 E [(u(wt·x)−y∗)2]
x∼Dx
+2b4 E [2((wt·x)2+(w∗·x)2)21{|wt·x| ≥ r or |w∗·x| ≥ r}]
x∼Dx
√
≤ 2b4r2∥wt−w∗∥2+48c(bW/L)4 ϵ.
2
In summary, combining all the results and plugging them back into (29), we finally get the upper
bound for the variance:
32b2W2 √
E [(uˆ∗t(wt·x)−y∗)4] ≤ log2(2/(L2ϵ′))(b2∥wt−w∗∥2+ϵ)+384c(bW/L)4 ϵ′.
x∼Dx L2 2
√
Let s = b ϵ∥wt−w∗∥ +ϵ/b and plug the last inequality back into (28) to get:
2
Pr(cid:20)(cid:12) (cid:12) (cid:12) 1 (cid:88)m (uˆ∗t(wt·x(i))−y∗(i))2− E [(uˆ∗t(wt·x)−y∗)2](cid:12) (cid:12) (cid:12) ≥ b√ ϵ∥wt−w∗∥ 2+ϵ/b(cid:21)
(cid:12)m x∼Dx (cid:12)
i=1
1 (cid:18) 32b2W2 (cid:18) 2 (cid:19) √ (cid:19)
≤ log2 (b2∥wt−w∗∥2+ϵ)+384c(bW/L)4 ϵ′ .
m(ϵb2∥wt−w∗∥2+ϵ2/b2) L2 L2ϵ′ 2
2
Choosing ϵ′ = ϵ2/b4 and using similar arguments as in Claim 3.5, we get that the right-hand side of
the inequality above is bounded by δ, given our choice of m ≳ db4W9/2log4(d/(ϵδ))(1/ϵ3/2+1/(ϵδ))
as specified in the statement of Proposition 3.1. In summary, after a union bound on the probability
above and the event that E [(uˆ∗t(wt·x)−u∗t(wt·x))2] ≤ ϵ, we have with probability at least
x∼Dx
1−2δ,
1 (cid:88)m √
(uˆ∗t(wt·x(i))−y∗(i))2 ≥ E [(uˆ∗t(wt·x)−y∗)2]− ϵb∥wt−w∗∥ −ϵ/b.
2
m x∼Dx
i=1
32Recall that in Lemma 3.2 we showed that E x∼Dx[(uˆ∗t(wt·x)−u∗(w∗·x))2] ≥ Ca2LR4∥(w∗)⊥ wt∥2
2
for an absolute constant C; thus, our final result is that with probability at least 1−δ,
m m
1 (cid:88) 1 (cid:88)
(uˆ∗t(wt·x(i))−y∗(i))(wt−w∗)·x(i) ≥ (uˆ∗t(wt·x(i))−y∗(i))2
m mb
i=1 i=1
Ca2LR4 √
≥
b
∥(w∗)⊥ wt∥2 2− ϵ∥wt−w∗∥ 2−ϵ/b.
This completes the proof of Claim 3.6.
C.5 Proof of Fact C.2
WeproveamodifiedversionofLemma1[KKSK11],presentedasthestatementbelow. Thestatement
considers a smaller activation class and a function f with different properties compared to [KKSK11],
and the proof is based on a rigorous KKT argument.
Fact C.2. Let wt ∈ B(W). Given m samples S = {(x(1),y∗(1)),··· ,(x(m),y∗(m))}, let uˆ∗t be one of
the solutions to the optimization problem (P*) , i.e., uˆ∗t ∈ argmin (1/m)(cid:80)m (u(wt·x(i))−
u∈U (a,b) i=1
y∗(i))2. Then
m
(cid:88)
(uˆ∗t(wt·x(i))−y∗(i))(wt·x(i)−f(uˆ∗t(wt·x(i)))) ≥ 0,
i=1
for any function f : R → R such that f(0) = 0, (α −α )/a ≥ f(α )−f(α ) for all α ≥ α ≥ 0,
1 2 1 2 1 2
and f(α )−f(α ) ≥ (α −α )/b, ∀α ,α ∈ R, α ≥ α .
1 2 1 2 1 2 1 2
Proof. We transform the optimization problem (P*) to a quadratic optimization problem with linear
constraints. To guarantee that the solution of this quadratic problem corresponds to a function that
is (a,b)-unbounded, we add a sample (x(k),y∗(k)) = (0,0) to the sample set. Let z = wt·x(i) such
i
that (after sorting the indices) z ≤ z ≤ ··· ≤ z and z = 0. We solve the following optimization
1 2 m k
problem:
m
(cid:88)
min (y˜(i)−y∗(i))2
y˜(i),i∈[m]
i=1
s.t. 0 ≤ y˜(i+1)−y˜(i), 1 ≤ i ≤ k−1 ,
(31)
a(z −z ) ≤ y˜(i+1)−y˜(i), k ≤ i ≤ m−1 ,
i+1 i
y˜(i+1)−y˜(i) ≤ b(z −z ), 1 ≤ i ≤ m−1 ,
i+1 i
y˜(k) = 0 .
Denote the solution of (31) as yˆ∗(i), i = 1,··· ,m. Let uˆ∗t(z) be the linear interpolation function of
(z ,yˆ∗(i)), thenuˆ∗t ∈ U sinceuˆ∗t(0) = uˆ∗t(z ) = yˆ∗(k) = 0, uˆ∗t isb-Lipschitzanduˆ∗t(z)−uˆ∗t(z′) ≥
i (a,b) k
a(z−z′) for all z ≥ z′ ≥ 0. In other words, finding a solution of (P*) is equivalent to solving (31).
Now observe that the summation (cid:80)m (yˆ∗(i)−y∗(i))(z −f(yˆ∗(i))) can be transformed into the
i=1 i
following:
m m (cid:18) i (cid:19)
(cid:88) (cid:88) (cid:88)
(yˆ∗(i)−y∗(i))(z −f(yˆ∗(i))) = (yˆ∗(j)−y∗(j)) (z −f(yˆ∗(i))−(z −f(yˆ∗(i+1)))), (32)
i i i+1
i=1 i=1 j=1
where we let z = 0, yˆ∗ = 0 (and hence f(yˆ∗ ) = 0 as f(0) = 0).
m+1 m+1 m+1
33To utilize the information that yˆ∗(i) is the minimizer of the optimization problem (31), we write
down the KKT conditions for the optimization problem (31) described above:
yˆ∗(i) = y∗(i)+(λ′ −λ′ )/2−(λ −λ )/2−(ν /2)1{i = k}, i = 1,··· ,m; (33)
i i−1 i i−1 k
−λ (yˆ∗(i+1)−yˆ∗(i)) = 0, i = 1,··· ,k−1; (34)
i
λ (a(z −z )−(yˆ∗(i+1)−yˆ∗(i))) = 0, i = k,··· ,m−1; (35)
i i+1 i
λ′((yˆ∗(i+1)−yˆ∗(i))−b(z −z )) = 0, i = 1,··· ,m−1; (36)
i i+1 i
ν yˆ∗(k) = 0 , (37)
k
where λ ,λ′ ≥ 0, for i = 1,...,m−1, and ν ∈ R are dual variables, and we let λ = λ′ = 0 for the
i i k 0 0
convenience of presenting (33).
Summing up (33) recursively, we immediately get that
i
(cid:88) 1
(yˆ∗(i)−y∗(i)) = ((λ′ −λ )−ν 1{i ≥ k}).
2 i i k
j=1
Plugging the equality above back into (32), we have
m
(cid:88)
(yˆ∗(i)−y∗(i))(z −f(yˆ∗(i)))
i
i=1
m m
1 (cid:88) 1 (cid:88)
= (λ′ −λ )(z −f(yˆ∗(i))−(z −f(yˆ∗(i+1))))+ ν (z −f(yˆ∗(i))−(z −f(yˆ∗(i+1))))
2 i i i i+1 2 k i i+1
i=1 i=k
m
1 (cid:88)
= (λ′ −λ )(z −f(yˆ∗(i))−(z −f(yˆ∗(i+1))))+ν (z −f(yˆ∗(k))−(z −f(yˆ∗(m+1)))).
2 i i i i+1 k k m+1
i=1
(38)
Since by definition, z = f(yˆ∗(m+1)) = 0, z = 0, and as yˆ∗(i), i ∈ [m], is a feasible solution of
m+1 k
(31), it holds yˆ∗(k) = 0, we thus have
ν (z −f(yˆ∗(k))−(z −f(yˆ∗(m+1)))) = 0.
k k m+1
Plugging this back into (38), we get
m m
(cid:88) 1 (cid:88)
(yˆ∗(i)−y∗(i))(z −f(yˆ∗(i))) = (λ′ −λ )(z −f(yˆ∗(i))−(z −f(yˆ∗(i+1))))
i 2 i i i i+1
i=1 i=1
k−1
1 (cid:88)
= (λ′ −λ )(z −f(yˆ∗(i))−(z −f(yˆ∗(i+1))))
2 i i i i+1
i=1 (39)
(cid:124) (cid:123)(cid:122) (cid:125)
S1
m
1 (cid:88)
+ (λ′ −λ )(z −f(yˆ∗(i))−(z −f(yˆ∗(i+1)))).
2 i i i i+1
i=k
(cid:124) (cid:123)(cid:122) (cid:125)
S2
Consider first S . Suppose that for some i ∈ {1,...,k−1} we have λ′,λ > 0. Then, according to
1 i i
the complementary slackness condition (34) and (35), it holds that 0 = yˆ∗(i+1)−yˆ∗(i) = b(z −z ).
i+1 i
Therefore,
(λ′ −λ )(z −f(yˆ∗(i))−(z −f(yˆ∗(i+1)))) ≥ 0.
i i i i+1
34Suppose now that for some i ∈ {1,...,k−1}, it holds λ′ > 0,λ = 0. Then, it must be the case that
i
yˆ∗(i+1)−yˆ∗(i) = b(z −z ) ≥ 0,
i+1 i
according to the KKT condition (36). Since
f(yˆ∗(i+1))−f(yˆ∗(i)) ≥ (yˆ∗(i+1)−yˆ∗(i))/b
by assumption on f, we thus have
(z −f(yˆ∗(i))−(z −f(yˆ∗(i+1)))) ≥ 0.
i i+1
Finally, if λ > 0,λ′ = 0, then (34) indicates that 0 = yˆ∗(i+1)−yˆ∗(i). Therefore, as z ≥ z , the ith
i i+1 i
summand is also positive. In summary, S ≥ 0.
1
Now consider S . Observe that if for some i ∈ {k,...,m} it holds λ > 0 and λ′ > 0 at the same
2 i i
time, then KKT conditions (35) and (36) imply that
a(z −z ) = yˆ∗(i+1)−yˆ∗(i) = b(z −z ),
i+1 i i+1 i
as a < b and it has to be z −z = yˆ∗(i+1)−yˆ∗(i) = 0, which indicates that the ith summand in
i+1 i
the second term must be 0, i.e.,
(λ′ −λ )(z −f(yˆ∗(i))−(z −f(yˆ∗(i+1)))) = 0.
i i i i+1
Now suppose for some i ∈ {1,...,m}, λ′ > 0 and λ = 0. Then by the complementary slackness
i i
conditions (35) and (36), it must be that
yˆ∗(i+1)−yˆ∗(i) = b(z −z ) ≥ 0.
i+1 i
Again, since f satisfies
f(yˆ∗(i+1))−f(yˆ∗(i)) ≥ (yˆ∗(i+1)−yˆ∗(i))/b
for any yˆ∗(i+1) ≥ yˆ∗(i), we thus have
z −z +(f(yˆ∗(i+1))−f(yˆ∗(i))) ≥ 0.
i i+1
Thus, it holds that
(λ′ −λ )(z −f(yˆ∗(i))−(z −f(yˆ∗(i+1)))) ≥ 0.
i i i i+1
On the other hand, if λ′ = 0 and λ > 0, then complementary slackness implies that
i i
yˆ∗(i+1)−yˆ∗(i) = a(z −z ) ≥ 0.
i+1 i
Furthermore, since yˆ∗(i) ≥ yˆ∗(k) ≥ 0 when i ≥ k, using the assumption that
(α −α )/a ≥ f(α )−f(α )
1 2 1 2
when α ≥ α ≥ 0, we get
1 2
z −z +(f(yˆ∗(i+1))−f(yˆ∗(i))) ≤ 0,
i i+1
and hence
(λ′ −λ )(z −f(yˆ∗(i))−(z −f(yˆ∗(i+1)))) ≥ 0
i i i i+1
holds as well. Thus we conclude that S ≥ 0.
2
In summary, since each summand in (39) is non-negative, we finally get that
m m (cid:18) i (cid:19)
(cid:88) (cid:88) (cid:88)
(yˆ∗(i)−y∗(i))(z −f(yˆ∗(i))) = (yˆ∗(j)−y∗(j)) (z −f(yˆ∗(i))−(z −f(yˆ∗(i+1)))) ≥ 0.
i i i+1
i=1 i=1 j=1
This completes the proof of Fact C.2.
35C.6 Proof of Claim 3.7
We restate and prove Claim 3.7 that appeared in the proof of Proposition 3.1 in Section 3.3.
Claim 3.7. Let S = {(x(i),y(i))}m be i.i.d. samples from D, and denote by S∗ = {(x(i),y∗(i))}m
i=1 i=1
the idealized version of S, where y∗(i) = u∗(w∗·x(i)). Under the condition of Proposition 3.1, given
a parameter wt ∈ B(W), with probability at least 1−δ,
1 (cid:88)m √
Q = (y∗(i)−y(i))(wt·x(i)−w∗·x(i)) ≥ − OPT∥w∗−wt∥ −(OPT+ϵ)/b .
3 2
m
i=1
Proof. By Chebyshev’s inequality, we can write
(cid:20)(cid:12) m (cid:12) (cid:21)
Pr (cid:12) (cid:12) 1 (cid:88) (y∗(i)−y(i))(wt·x(i)−w∗·x(i))− E [(y∗−y)(wt−w∗)·x](cid:12) (cid:12) ≥ s
(cid:12)m (x,y)∼D (cid:12)
i=1
E [(y∗−y)2(wt·x−w∗·x)2]
(x,y)∼D
≤ .
ms2
Let r = 2W log(2/(L2ϵ′)), then by the fact that D is sub-exponential, we have Pr[|(wt−w∗)·x| ≥
L x
r] ≤ ϵ′. Furthermore, since |y| ≤ M where M = bW log(16b4W4/ϵ2), as stated in Fact F.3, the
L
variance can be bounded as follows:
E [(y∗−y)2(wt·x−w∗·x)2]
(x,y)∼D
≤ E [(y∗−y)2(wt·x−w∗·x)21{|(wt−w∗)·x| ≤ r}]
(x,y)∼D
+ E [(y∗−y)2(wt·x−w∗·x)21{|(wt−w∗)·x| ≥ r}]
(x,y)∼D
≤ r2 E [(u∗(w∗·x)−y)2]
(x,y)∼D
+ E [(2(u∗(w∗·x))2+y2)(wt·x−w∗·x)21{|(wt−w∗)·x| ≥ r}]
(x,y)∼D
≤ r2OPT+ E [2(b2(wt·x)2+M2)(wt·x−w∗·x)21{|(wt−w∗)·x| ≥ r}].
x∼Dx
Since for any unit vectors a,b we have E [(a·x)4] ≤ c2/L4 and E [(a·x)4(b·x)4] ≤ c2/L8,
x∼Dx x∼Dx
we have:
2b2 E [(wt·x)2(wt·x−w∗·x2)21{|(wt−w∗)·x| ≥ r}]
x∼Dx
(cid:114)
≤ 4b2(W/L)4 E [((wt/∥wt∥ )·x)4(((wt−w∗)/∥wt−w∗∥ )·x)4]Pr[|(wt−w∗)·x| ≥ r]
2 2
x∼Dx
√
≤ 4cb2(W/L)4 ϵ′,
and in addition,
E [M2((wt−w∗)·x)21{|(wt−w∗)·x| ≥ r}]
x∼Dx
(cid:114) √
≤ 2M2W2 E [((wt−w∗)·x)4]Pr[|(wt−w∗)·x| ≥ r] ≤ cM2(W/L)2 ϵ′.
x∼Dx
36Let s = (OPT+ϵ)/b, ϵ′ = ϵ2, under our choice of m ≳ db4W9/2log4(d/(ϵδ))(1/ϵ3/2 +1/(ϵδ)), it
holds that
1 (cid:18) 4W2log2(1/(L2ϵ′))OPT √ (cid:19)
+(4cb2(W/L)4+cM2(W/L)2) ϵ′ ≤ δ.
ms2 L2
Thus, with probability at least 1−δ it holds that
m
1 (cid:88)
(y∗(i)−y(i))(wt·x(i)−w∗·x(i)) ≥ E [(y−y∗)(wt−w∗)·x]−(OPT+ϵ)/b.
m (x,y)∼D
i=1
Since
(cid:12) (cid:12) (cid:114) √
(cid:12) (cid:12) E [(y−y∗)(wt−w∗)·x](cid:12) (cid:12) ≤ E [(y−y∗)2] E [((wt−w∗)·x)2] ≤ OPT∥w∗−wt∥ 2,
(cid:12)(x,y)∼D (cid:12) (x,y)∼D x∼Dx
we finally have
1 (cid:88)m √
(y∗(i)−y(i))(wt·x(i)−w∗·x(i)) ≥ − OPT∥w∗−wt∥ −(OPT+ϵ)/b,
2
m
i=1
completing the proof of Claim 3.7.
D Omitted Proofs from Section 4
D.1 Proof of Theorem 4.2
In this subsection, we restate and prove our main theorem Theorem 4.2. The full version of the
optimization algorithm as well as the main theorem Theorem 4.2 is displayed below:
Theorem D.1 (Main Result). Let D be a distribution in Rd ×R and suppose that D is (L,R)-
x
well-behaved. Furthermore, let U be as in Definition 1.3, and ϵ > 0. Let µ = Ca2LR4/b,
(a,b)
where C is an absolute constant. Running Algorithm 4 with the following parameters: step size
η = µ/(4b2), batch size to be m ≳ dW11/2b17log5(d/ϵ)/(L4µ12ϵ3/2) and the total number of iterations
√
to be T′ = t JT = O(Wb11/(µ10 ϵ)log(1/ϵ)), where T = O((b/µ)2log(1/ϵ)), then with probability
0
at least 2/3, Algorithm 4 returns a hypothesis (uˆ,w) where uˆ ∈ U and w ∈ B(W) such that
(cid:98) (a,b) (cid:98)
(cid:18) b4 (cid:19)
L (w;uˆ) = O OPT+ϵ ,
2 (cid:98) a4L2R8
using N = O(T′m) = O˜(dW13/2b28/(L4µ22ϵ2)) samples.
Proof. As proved in Lemma 4.1, the initialization subroutine Algorithm 1 outputs a list of points
{wini}t0 that contains a point wini such that
k k=1 k∗
∥(w∗)⊥ w kin ∗i∥
2
≤ max{µ∥w∗∥ 2/(4b),64b2/µ3(√ OPT+√ ϵ)}.
√ √
Suppose first that µ∥w∗∥ /(4b) ≤ 64b2/µ3( OPT + ϵ). Then this implies that ∥w∗∥ ≤
√ √ 2 2
256b3/µ4( OPT + ϵ). Therefore, applying Claim 4.4 we immediately get that the trivial hy-
pothesis (w = 0,u(z) = 0) works as a constant approximate solution, as in this case
L (w;u) ≤ 8(OPT+ϵ)+4b2∥w∗∥ = O((b/µ)8)OPT+ϵ.
2 2
37Algorithm 4 Optimization
1: Input: wini = 0; ϵ > 0; positive parameters: a, b, L, R, W; let µ ≲ a2LR4/b; step size
η = µ/(4b2), number of iterations T = O((b/µ)2log(1/ϵ)).
2: {wini,...,wini} = Initialization[wini] (Algorithm 1)
0 t0
3: for k = 0 to t 0 ≲ (b/µ)6log(b/µ) do
4: P k = {} √
5: for j = 1 to J = W/(η ϵ) do
6: w¯0 = wini.
j,k √k √
7: β j = jη ϵ. ▷ find an η ϵ approximation of ∥w∗∥ 2
8: for t = 0 to T −1 do
9: w (cid:98)jt
,k
= β j(w¯ jt ,k/∥w¯ jt ,k∥ 2). ▷ normalize w¯
10: Draw m ≳ W11/2b17log5(d/ϵ)d/(L4µ12ϵ3/2) new i.i.d. samples from D
11: uˆt
j,k
= argmin
u∈U
(a,b)(1/m)(cid:80)m i=1(u(w (cid:98)jt
,k
·x(i))−y(i))2.
12: ∇L(cid:98)sur(w (cid:98)jt ,k;uˆt j,k) = (1/m)(cid:80)m i=1(uˆt j,k(w (cid:98)jt
,k
·x(i))−y(i))x(i).
13: w¯ jt+ ,k1 = w (cid:98)jt
,k
−η∇L(cid:98)sur(w (cid:98)jt ,k;uˆt j,k)
14: end for
15: P k ← P k ∪{(w (cid:98)jT ,k;uˆT j,k)}.
16: end for
17: P = ∪t k0 =1P k ∪{(w = 0;u(z) = 0)}
18: end for
19: (w (cid:98);uˆ) = Test[(w;u) ∈ P] (Algorithm 3) ▷ testing
20: Return: (w (cid:98);uˆ)
This hypothesis (w = 0,u(z) = 0) is contained in our solution set P (see Algorithm 4) and tested in
Algorithm 3.
Thus, in the rest of the proof we assume that wini satisfies
k∗
∥(w∗)⊥ w kin ∗i∥
2
≤ µ∥w∗∥ 2/(4b).
Let us consider this initialized parameter at k∗ step in the outer loop (line 4), w¯0 = wini. In the
j,k∗ k∗
rest of the proof we drop the subscript k∗ since the context is clear.
√
Since we constructed a grid with grid width η ϵ from 0 to W to find the (approximate) value
√
of ∥w∗∥ , there must exist an index j∗ such that the value of β is η ϵ close to ∥w∗∥ , i.e.,
2 √ j∗ 2
|β −∥w∗∥ | ≤ η ϵ. We now consider this j∗th outer loop and ignore the subscript j∗ for simplicity.
j∗ 2
Let wt = ∥w∗∥ (w¯t/∥w¯t∥ ), which is the true normalized vector of w¯t that has no error.
2 2
We study the squared distance between w¯t+1 and w∗:
∥w¯t+1−w∗∥2
2
= ∥w (cid:98)t−η∇L(cid:98)sur(w (cid:98)t;uˆt)−w∗∥2
2
= ∥w (cid:98)t−w∗∥2 2+η2∥∇L(cid:98)sur(w (cid:98)t;uˆt)∥2 2−2η∇L(cid:98)sur(w (cid:98)t;uˆt)·(w (cid:98)t−w∗). (40)
Applying Lemma 4.3 to (40), and plugging in Proposition 3.1, we get that when drawing
dW9/2b4log4(d/(ϵδ))(cid:18)
1 1
(cid:19)
m ≳ + , (41)
L4 ϵ3/2 ϵδ
samples from the distribution, it holds with probability at least 1−δ that:
∥w¯t+1−w∗∥2 ≤ ∥wt−w∗∥2+η2(10(OPT+ϵ)+4b2∥wt−w∗∥2)
2 (cid:98) 2 √ √ (cid:98) 2 (42)
+2η(2(OPT+ϵ)/b+2( OPT+ ϵ)∥wt−w∗∥ −µ∥vt∥2),
(cid:98) 2 2
38where µ = Ca2LR4/b with C being an absolute constant, and where vt is the component of w∗ that
is orthogonal to wt, i.e.,
(cid:98)
vt = w∗−(w∗·w (cid:98)t)w (cid:98)t/∥w (cid:98)t∥2
2
= (w∗)⊥ w(cid:98)t.
Note that ∥vt∥ is invariant to the rescaling of wt, in other words, w∗ has the same orthogonal
2 (cid:98)
component vt for all w¯t, wt and wt.
√ (cid:98)
Since ∥wt−wt∥ ≤ η ϵ, we have
(cid:98) 2
√
∥wt−w∗∥2 = ∥wt−wt+wt−w∗∥2 ≤ ∥wt−w∗∥2+η2ϵ+2η ϵ∥wt−w∗∥ . (43)
(cid:98) 2 (cid:98) 2 2 2
√
In addition, by triangle inequality we have ∥wt−w∗∥ ≤ ∥wt−w∗∥ +η ϵ. Therefore, substituting
(cid:98) 2 2
wt with wt in (42), we get:
(cid:98)
√
∥w¯t+1−w∗∥2 ≤ ∥wt−w∗∥2+η2ϵ+2η ϵ∥wt−w∗∥
2 2 2
√
+η2(10(OPT+ϵ)+4b2∥wt−w∗∥2+4b2η2ϵ+8b2η ϵ∥wt−w∗∥ )
2 2
√ √ √
+2η(2(OPT+ϵ)/b+2( OPT+ ϵ)(∥wt−w∗∥ +η ϵ)−µ∥vt∥2)
2 2
≤ ∥wt−w∗∥2+η2(24(OPT+ϵ)+4b2∥wt−w∗∥2)
2 2
√ √
+2η(2(OPT+ϵ)/b+4( OPT+ ϵ)∥wt−w∗∥ −µ∥vt∥2), (44)
2 2
where we used 4b2η2 ≤ 1, which holds because η = µ/(4b2).
Our goal is to show that ∥vt+1∥2 ≤ ∥w¯t+1 −w∗∥2 ≤ (1−c)∥vt∥2 +ϵ, where c ∈ (0,1) is a
2 2 2
constant and ϵ is a small error parameter. However, this linear contraction can only be obtained
when ∥vt∥ is relatively small compared to ∥w∗∥ . Specifically, as will be manifested in Claim D.2
2 2
and the proceeding proof, the linear contraction is achieved only when ∥vt∥ ≤ µ∥w∗∥ /(4b). Luckily,
2 2
we can start with a v0 such that this condition is satisfied, due to the initialization subroutine
Algorithm 1, as proved in Lemma 4.1. We prove the following claim.
Claim D.2. Let η = µ/(4b2). Then, under the assumptions of Theorem 4.2, with probability at least
1−δ, we have
(cid:18) µ2 (cid:19)
∥w¯t+1−w∗∥2 ≤ 1− ∥vt∥2,
2 32b2 2
√ √
whenever ∥vt∥ ≥ (96/µ)( OPT+ ϵ).
2
Proof of Claim D.2. Since the norm of wt is normalized to w∗, the quantity ∥wt−w∗∥2 is controlled
by∥vt∥2. Inparticular,letw∗ = α wt+vt. Then,sincevt ⊥ wt,wehave∥w∗∥2 = α2∥wt∥2+∥vt∥2 =
2 t 2 t 2 2
α2∥w∗∥2+∥vt∥2, thus, α2 = 1−∥vt∥2/∥w∗∥2, and ∥vt∥2 = (1−α2)∥w∗∥2. In addition, ∥wt−w∗∥2
t 2 2 t 2 2 2 t 2 2
can be expressed as a function of α and w∗, as
t
∥wt−w∗∥2 = (1−α )2∥w∗∥2+∥vt∥2 = 2(1−α )∥w∗∥2. (45)
2 t 2 2 t 2
Note that since α = (cid:112) 1−∥vt∥2/∥w∗∥2, denoting ρ = ∥vt∥ /∥w∗∥ , we further have:
t 2 2 t 2 2
(cid:113) (cid:113) 1 1
1−α = 1− 1−∥vt∥2/∥w∗∥2 = 1− 1−ρ2 ≤ ρ2+ ρ4 ≤ ρ2, ∀ρ ∈ [0,1]. (46)
t 2 2 t 2 t 2 t t t
39Therefore, plugging (45) and (46) back into (44), we get:
√ √ (cid:112)
∥w¯t+1−w∗∥2 ≤ 2(1−α )∥w∗∥2+4b2η2(2(1−α )∥w∗∥2)+8η( OPT+ ϵ) 2(1−α )∥w∗∥
2 t 2 t 2 t 2
−2ηµ∥vt∥2+24η2(OPT+ϵ)+4η(OPT+ϵ)/b
2
√ √ √
≤ (ρ2+ρ4)∥w∗∥2+4b2η2(ρ2+ρ4)∥w∗∥2+8 2η( OPT+ ϵ)ρ ∥w∗∥
t t 2 t t 2 t 2
−2ηµ∥vt∥2+24η2(OPT+ϵ)+4η(OPT+ϵ)/b
2
√ √
= (1+ρ2+4b2η2(1+ρ2))∥vt∥2+12η( OPT+ ϵ)∥vt∥ −2ηµ∥vt∥2
t t 2 2 2
+4(6η2+η/b)(OPT+ϵ)
√ √
≤ (1+ρ2+4b2η2(1+ρ2))∥vt∥2+12η( OPT+ ϵ)∥vt∥ −2ηµ∥vt∥2+5η(OPT+ϵ),
t t 2 2 2
(47)
where in the last inequality we observed that since η = µ , it holds that 24η ≤ 1, as µ is small and
4b2
b ≥ 1.
√ √
Note that we have assumed that ∥vt∥ ≥ (96/µ)( OPT+ ϵ), which indicates
2
√ √ 1
12η( OPT+ ϵ)∥vt∥ ≤ ηµ∥vt∥2,
2 8 2
√ √
since b ≥ 1 was assumed without loss of generality. Furthermore, when ∥vt∥ ≥ (96/µ)( OPT+ ϵ),
2
it also holds that
1 (96)2
ηµ∥vt∥2 ≥ ηµ(OPT+ϵ) ≥ 5η(OPT+ϵ),
8 2 8µ2
since we have assumed µ = Ca2LR4/b ≤ 1 without loss of generality. Finally, as we will show in
the rest of the proof, it holds that ∥vt+1∥ ≤ ∥vt∥ for t = 0,1,...,T, thus as η = µ/(4b2), we have
√ 2 2 √
∥vt∥ ≤ ηµ∥w∗∥ /2 = µ∥w∗∥ /(4b), since ∥v0∥ ≤ ηµ∥w∗∥ /2. This condition guarantees that
2 2 2 2 2
1
ρ2 = ∥vt∥2/∥w∗∥2 ≤ ηµ.
t 2 2 4
Pluggingtheseconditionsbackinto(47), itisthensimplifiedas(notethat1+ρ2 ≤ 1+(1/4)ηµ ≤ 9/8
t
for ηµ ≤ 1/2):
(cid:18) (cid:19)
9 3
∥w¯t+1−w∗∥2 ≤ 1+ b2η2− ηµ ∥vt∥2.
2 2 2 2
Therefore, when η = µ/(4b2) we have
(cid:18) µ2 (cid:19)
∥w¯t+1−w∗∥2 ≤ 1− ∥vt∥2,
2 32b2 2
completing the proof.
√ √
We proceed first under the condition that ∥vt∥ ≥ (96/µ)( OPT+ ϵ) holds for t = 0,...,T
2
and show that after some certain number of iterations T this condition must be violated. Observe
√ √
that if ∥vt∥ ≤ (96/µ)( OPT+ ϵ), then it holds ∥wt−w∗∥2 ≲ (1/µ2)(OPT+ϵ), implying that
2 2
uˆt(wt·x) is a hypothesis achieving constant approximation error according to Claim 4.4, hence the
algorithm can be terminated. However, note that T only works as an upper bound for the iteration
√ √
complexity of our algorithm, and it is possible that the condition ∥vt∥ ≥ (96/µ)( OPT+ ϵ) is
2
violated at some step t∗ < T. However, as we show later, the value of ∥vT∥ cannot be larger than
2
c∥vt∗∥ , where c is an absolute constant. We observe that:
2
vt+1 = w∗−(w∗·wt+1)wt+1/∥wt+1∥2
2
= w∗−(w∗·w¯t+1)w¯t+1/∥w¯t+1∥2
2
= (w∗)⊥ w¯t+1,
40therefore, ∥vt+1∥2 ≤ ∥w¯t+1−w∗∥2, which, combined with Claim D.2, yields
2 2
(cid:18) µ2 (cid:19) (cid:18) µ2 (cid:19)t (cid:18) µ2t (cid:19)
∥vt+1∥2 ≤ 1− ∥vt∥2 ≤ 1− ∥v0∥2 ≤ exp − 2W2.
2 32b2 2 32b2 2 32b2
√ √
The above contraction only holds when ∥vt∥ ≥ (96/µ)( OPT+ ϵ). Hence, after at most
2
(cid:18) b2 (cid:18) µW(cid:19)(cid:19)
T = O log
µ2 ϵ
√ √
inner iterations, the algorithm outputs a vector wt∗ with ∥vt∗∥ ≤ 96( OPT+ ϵ), where t∗ ∈ [T].
2 µ √ √
Now suppose that at step t∗ < T it holds that ∥vt∗∥ ≤ 96( OPT + ϵ)/µ but at the
√ √ 2
next iteration ∥vt∗+1∥ ≥ 96( OPT + ϵ)/µ. Recall first that in Lemma 4.3 we showed that
2
∥∇L(cid:98)sur(w (cid:98)t;uˆt)∥2
2
≤ 4b2∥w (cid:98)t−w∗∥2 2+10(OPT+ϵ). Therefore, revisiting the updating scheme of the
algorithm we have
∥vt∗+1∥2
2
≤ ∥w¯t∗+1−w∗∥2
2
= ∥w (cid:98)t∗ −η∇L(cid:98)sur(w (cid:98)t∗ ;uˆt∗ )−w∗∥2
2
≤ 2∥w (cid:98)t∗ −w∗∥2 2+2η2∥∇L(cid:98)sur(w (cid:98)t∗ ;uˆt∗ )∥2
2
≤ (2+8b2η2)∥wt∗ −w∗∥2+20η2(OPT+ϵ)
(cid:98) 2
≤ 3∥wt∗ −w∗∥2+(OPT+ϵ),
(cid:98) 2
where in the last inequality we plugged in the value of η = µ/(4b2), and used the assumption that
µ ≤ 1 and b ≥ 1, hence 20η2 ≤ 1 and 8b2η2 ≤ 1. Furthermore, recall that by the construction of the
√
grid, ∥wt∗ −wt∥ ≤ η ϵ, implying that ∥wt∗ −w∗∥2 ≤ 2∥wt∗ −w∗∥2+2η2ϵ by triangle inequality.
(cid:98) 2 (cid:98) 2 2
Therefore, going back to the inequality of ∥vt∗+1∥2 above, we get
2
∥vt∗+1∥2 ≤ 6∥wt∗ −w∗∥2+6η2ϵ+OPT+ϵ ≤ 6∥wt∗ −w∗∥2+2(OPT+ϵ).
2 2 2
√
Finally, observe that since ∥wt∗∥ = ∥w∗∥ , it holds ∥wt∗ −w∗∥ ≤ 2∥vt∗∥ , hence, we get
2 2 2 2
∥vt∗+1∥2 ≤ 12∥vt∗ ∥2+2(OPT+ϵ).
2 2
√ √
Nowsince∥vt∗+1∥ ≥ 96( OPT+ ϵ)/µ, thevalueof∥vt∥2 willstarttodecreaseagainfort ≥ t∗+1.
2 2
This implies that the value of ∥vT∥ satisfies
2
√ √ √ √ 384 √ √
∥vT∥ ≤ 12∥vt∗ ∥ + 2( OPT+ ϵ) ≤ ( OPT+ ϵ).
2 2
µ
√ √
CombiningClaim4.4andLemmaF.4,aswehaveguaranteedthat∥vT∥ ≤ (384/µ)( OPT+ ϵ),
2
the hypothesis uˆT(wT ·x) has the L2 error that can be bounded as:
(cid:98) 2
(cid:18) b2 (cid:19)
L (wT;uˆT) ≤ 6OPT+3b2(4∥vT∥2+η2ϵ)+ϵ = O (OPT+ϵ) .
2 (cid:98) 2 µ2
For any ϵ > 0, setting ϵ = C′(µ2/b2)ϵ with C′ being some small universal absolute constant, we
1 1
finally get L (wT;uˆT) ≤ O((b2/µ2)OPT)+ϵ .
2 (cid:98) 1
It still remains to determine the batch size as drawing a sample set of size m as displayed in (41)
only guarantees that the contraction of ∥vt∥ at step t holds with probability 1−δ. Applying a union
2
bound on all t 0JT = O(W µ9b√10
ϵ
log(1/ϵ)) = O( µW 10b √11
ϵ1
log(1/ϵ 1)) iterations yields that the contraction
41holds at every step with probability at least 1−t JTδ. Therefore, setting δ ← δ(t JT) and bringing
0 0
the value of δ back to (41), we get that it suffices to choose the batch size as:
(cid:18) dW9/2b4log4(d/(ϵδ))(cid:18) 1 Wb10 (cid:19)(cid:19) (cid:18) dW11/2b17log5(d/(ϵ δ))(cid:19)
1
m = Θ + = Θ ,
L4 ϵ3/2 µ9ϵ3/2δ L4µ12δϵ3/2
1
to guarantee that we get an O(OPT)+ϵ -solution with probability at least 1−δ. Note that we
1
have set ϵ = C′(µ2/b2)ϵ in the last equality above.
1 √
The argument above justifies the claim that among all t J = Wb7log(b/µ)/(ηµ7 ϵ ) hypotheses
0 1
in P = {(wT;uˆT)}t0J , there exists at least one hypothesis that achieves L2 error O(OPT)+ϵ .
(cid:98)j j j=1 2 1
To select the correct hypothesis from the set P, one only needs to draw a new batch of m′ =
Θ˜(b4W4log(1/δ)/(L4ϵ2)) i.i.d. samples from D, and choose the hypothesis from P that achieves
1
the minimal empirical error defined in Algorithm 4. As discussed in Section 4.3, this procedure
introduces an error at most ϵ .
1
In conclusion, it holds by a union bound that Algorithm 4 delivers a solution with O(OPT)+ϵ
1
error with probability at least 1−2δ. The total sample complexity of our algorithm is
(cid:18) W13/2b28dlog5(d/(ϵ δ)) b4W4log(1/δ)log5(1/ϵ )(cid:19) (cid:18) W13/2b28dlog6(d/(ϵ δ))(cid:19)
N = t JTm+m′ = Θ 1 + 1 = Θ 1 .
0 L4µ22δϵ2 L4ϵ2 L4µ22δϵ2
1 1 1
Choosing δ = 1/6 above we get that the Algorithm 4 succeeds to generate an O(OPT)+ϵ -
1
solution for any ϵ > 0 with probability at least 1−2δ = 2/3, hence replacing ϵ with ϵ completes
1 1
the proof of Theorem D.1.
D.2 Proof of Lemma 4.3
This subsection is devoted to the proof of Lemma 4.3. To this aim, we first show the following
lemmas that bound from above the norm of the population gradient ∇L (wt;uˆt) and the difference
sur
between the population gradient and the empirical gradient ∇L(cid:98)sur(wt;uˆt).
LemmaD.3. LetS beasamplesetofmi.i.d.samplesofsizeatleastm ≳ dlog4(d/(ϵδ))(b2W3/L2ϵ)3/2.
Furthermore, given wt ∈ B(W), let uˆt be defined as in (P). Then, it holds that with probability at
least 1−δ,
∥∇L (wt;uˆt)∥2 ≤ 8(OPT+ϵ)+2b2∥wt−w∗∥2.
sur 2 2
Proof. By the definition of ℓ norms, we have:
2
∥∇L (wt;uˆt)∥ = max ∇L (wt;uˆt)·v
sur 2 sur
∥v∥2=1
= max E [(uˆt(wt·x)−y)v·x]
∥v∥2=1(x,y)∼D
(cid:26)
= max E [(uˆt(wt·x)−ut(wt·x)+ut(wt·x)−u∗t(wt·x))(v·x)]
∥v∥2=1 (x,y)∼D
(cid:27)
+ E [(u∗t(wt·x)−u∗(w∗·x)+u∗(w∗·x)−y)(v·x)] .
(x,y)∼D
42By the Cauchy-Schwarz inequality, we further have:
∥∇L (wt;uˆt)∥
sur 2
(cid:26)(cid:114) (cid:114)
≤ max E [(uˆt(wt·x)−ut(wt·x))2] E [(v·x)2]+ E [(ut(wt·x)−u∗t(wt·x))2] E [(v·x)2]
∥v∥2=1 x∼Dx x∼Dx x∼Dx x∼Dx
(cid:114) (cid:114) (cid:27)
+ E [(u∗t(wt·x)−u∗(w∗·x))2] E [(v·x)2]+ E [(u∗(w∗·x)−y)2] E [(v·x)2]
x∼Dx x∼Dx x∼Dx x∼Dx
(cid:114) (cid:114)
≤ E [(uˆt(wt·x)−ut(wt·x))2]+ E [(ut(wt·x)−u∗t(wt·x))2]
x∼Dx x∼Dx
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
T1 T2
(cid:114) (cid:114)
+ E [(u∗t(wt·x)−u∗(w∗·x))2]+ E [(u∗(w∗·x)−y)2],
x∼Dx x∼Dx
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
T3 T4
where in the last inequality we used the assumption that E [xx⊤] ≼ I, hence E [(v·x)2] ≤ 1.
√x∼Dx x∼Dx
It remains to bound T −T . Observe first that T ≤ ϵ for every wt ∈ B(W), with probability
1 4 1 √
at least 1 − δ, due to Lemma F.4. By definition, T = OPT. Recall that in Lemma 3.3
4
we showed the following T2 = E [(ut(wt · x) − u∗t(wt · x))2] ≤ OPT. For T , note that
2 x∼Dx 3
u∗t ∈ argmin E [(u(wt·x)−u∗(w∗·x))2], therefore, since u∗ ∈ U , we have
u∈U
(a,b)
x∼Dx (a,b)
T2 = E [(u∗t(wt·x)−u∗(w∗·x))2] ≤ E [(u∗(wt·x)−u∗(w∗·x))2] ≤ b2∥wt−w∗∥2,
3 2
x∼Dx x∼Dx
after applying the assumption that u∗ is b-Lipschitz. Thus, in conclusion, we have
√ √
∥∇L (wt;uˆt)∥ ≤ 2 OPT+ ϵ+b∥wt−w∗∥ .
sur 2 2
Furthermore, since (a+b)2 ≤ 2a2+2b2 for any a,b ∈ R, we get with probability at least 1−δ:
∥∇L (wt;uˆt)∥2 ≤ 8OPT+8ϵ+2b2∥wt−w∗∥2,
sur 2 2
completing the proof of Lemma D.3.
We now prove that the distance between ∇L sur(wt;uˆt) and ∇L(cid:98)sur(wt;uˆt) is bounded by b2∥wt−
w∗∥2+OPT+ϵ with high probability.
2
Lemma D.4. Let S be a sample set of m ≳ (dW9/2b4log4(d/(ϵδ))/L4)(1/ϵ3/2+1/(ϵδ)) i.i.d. samples.
Given a vector wt ∈ B(W), it holds that with probability at least 1−δ,
(cid:113)
∥∇L(cid:98)sur(wt;uˆt)−∇L sur(wt;uˆt)∥
2
≤ b2∥wt−w∗∥2 2+OPT+ϵ.
Proof. Sinceforanyzero-meanindependentrandomvariablez ,wehaveE[||(cid:80) z ||2] = (cid:80) E[∥z ∥2],
j j j 2 j j 2
by Chebyshev’s inequality:
1
Pr[∥∇L(cid:98)sur(wt;uˆt)−∇L sur(wt;uˆt)∥
2
≥ s] ≤
ms2
(x,yE )∼D[∥(uˆt(wt·x)−y)x∥2 2] . (48)
By linearity of expectation, we have:
d
(cid:88)
E [∥(uˆt(wt·x)−y)x∥2] = E [(uˆt(wt·x)−y)2(x )2],
2 k
(x,y)∼D (x,y)∼D
k=1
43where x = e ·x and e is the kth unit basis of Rd. Let r = O(W/Llog(1/(Lϵ′))), then it holds
k k k
Pr[|x | ≥ r] ≤ ϵ′. Then, the variance above can be decomposed into the following parts:
k
E [(uˆt(wt·x)−y)2x2] = E [(uˆt(wt·x)−y)2x21{|x | ≥ r}]
k k k
(x,y)∼D (x,y)∼D
+ E [(uˆt(wt·x)−y)2x21{|x | ≤ r}].
k k
(x,y)∼D
Since |y| ≤ M = O(bW/Llog(bW/ϵ)), and E [(wt·x)4x4] ≤ W4c2/L8, E [x4] ≤ c2/L4 for
x∼Dx k x∼Dx k
D is L-sub-exponential, we have
x
E [(uˆt(wt·x)−y)2x21{|x | ≥ r}] ≤ 2 E [(uˆt(wt·x))2+y2)x21{|x | ≥ r}]
k k k k
(x,y)∼D (x,y)∼D
≤ 2 E [(b(wt·x))2+y2)x21{|x | ≥ r}]
k k
(x,y)∼D
(cid:114)
≤ 2b2 E [((wt·x)4x4]Pr[|x | ≥ r]
k k
x∼Dx
(cid:114)
+2M2 E [x4]Pr[|x | ≥ r]
k k
x∼Dx
√ √ √
≤ (2cb2W2/L4) ϵ′+(2cM2/L2) ϵ′ ≤ (4cM2/L2) ϵ′.
(49)
In addition, (uˆt(wt·x)−y)2 can be decomposed as the following:
E [(uˆt(wt·x)−y)2] ≤ 4 E [(uˆt(wt·x)−ut(wt·x))2]+4 E [(ut(wt·x)−u∗t(wt·x))2]
(x,y)∼D x∼Dx x∼Dx
+4 E [(u∗t(wt·x)−u∗(w∗·x))2]+4 E [(u∗(w∗·x)−y)2].
x∼Dx (x,y)∼D
The first term is bounded above by 4ϵ with probability at least 1−δ for every wt ∈ B(W) whenever
m ≳ dlog4(d/(ϵδ))(b2W3/L2ϵ)3/2, as proved in Lemma F.4. The second term is smaller than 4OPT,
which is shown in Lemma 3.3. The third term can be bounded above using again the definition of
u∗t = argmin E [(u(wt·x)−y∗)2], as
u∈U
(a,b)
x∼Dx
4 E [(u∗t(wt·x)−u∗(w∗·x))2] ≤ 4 E [(u∗(wt·x)−u∗(w∗·x))2] ≤ 4b2∥wt−w∗∥2,
2
x∼Dx x∼Dx
using the fact that u∗ is b-Lipschitz and E [xx⊤] ≼ I. Lastly, the fourth term is bounded by
x∼Dx
4OPT by the definition of u∗(w∗·x). In summary, we have
E [(uˆt(wt·x)−y)2x21{|x | ≤ r}] ≤ r2 E [(uˆt(wt·x)−y)2]
k k
(x,y)∼D (x,y)∼D
≤ 4r2(b2∥wt−w∗∥2+2OPT+ϵ),
2
which, combining with (49), implies that the expectation E [(uˆt(wt·x)−y)2x2] is bounded
(x,y)∼D k
by:
E [(uˆt(wt·x)−y)2x2] ≤ 4r2b2∥wt−w∗∥2+4r2(2OPT+2ϵ)
k 2
(x,y)∼D
CW2 (cid:18) b (cid:19)
≤ log2 (b2∥wt−w∗∥2+OPT+ϵ),
L2 Lϵ 2
44where C is a large absolute constant. Note to get the inequality above we chose ϵ′ = Cϵ2(L/b)4,
√
which then indicates that 4c(M/L)2 ϵ′ ≤ r2ϵ. Summing the inequality above from k = 1 to d
delivers the final upper bound on the variance:
dCW2 (cid:18) b (cid:19)
E [∥(uˆt(wt·x)−y)x∥2] ≤ log2 (b2∥wt−w∗∥2+OPT+ϵ).
(x,y)∼D 2 L2 Lϵ 2
Thus,pluggingtheupperboundonthevarianceabovebackto(48),aslongasm ≳ (dW2/L2)log2(b/(Lϵ))/δ,
we get with probability at least 1−δ,
(cid:113)
∥∇L(cid:98)sur(wt;uˆt)−∇L sur(wt;uˆt)∥
2
≤ b2∥wt−w∗∥2 2+OPT+ϵ.
Noting that m ≳ (dW9/2b4log4(d/(ϵδ))/L4)(1/ϵ3/2+1/(ϵδ)) certainly satisfies the condition on m
above as m ≳ (dW2/L2)log2(b/(Lϵ))/δ, thus, we completed the proof of Lemma D.4
We can now proceed to the proof of Lemma 4.3 (detailed statement in Lemma D.5 below), which
can be derived directly from the preceding lemmas.
Lemma D.5 (Upper Bound on Empirical Gradient Norm). Let S be a set of i.i.d. samples of
size m ≳ (dW9/2b4log4(d/(ϵδ))/L4)(1/ϵ3/2+1/(ϵδ)). Given any wt ∈ B(W), let uˆt ∈ U be the
(a,b)
solution of optimization problem (P) with respect to wt and sample set S. Then, with probability at
least 1−δ, we have that ∥∇L(cid:98)sur(wt;uˆt)∥2
2
≤ 4b2∥wt−w∗∥2 2+10(OPT+ϵ).
Proof. The lemma follows directly by combining Lemma D.3, Lemma D.4 and the triangle inequality.
D.3 Proof of Claim 4.4
We restate (providing a more detailed statement for the sample size) and prove Claim 4.4.
Claim D.6. Let w be any vector from B. Let uˆ be a solution to (P) for a fixed parameter vector
w
w ∈ Rd with sample size m ≳ dlog4(d/(ϵδ))(b2W3/(L2ϵ))3/2. Then
E [(uˆ (w·x)−y)2] ≤ 8(OPT+ϵ)+4b2∥w−w∗∥2.
w 2
(x,y)∼D
Proof. Let u∗ , u be the optimal activations for problems (EP*) and (EP) under parameter w,
w w
respectively. Then, a direct calculation gives:
E [(uˆ −y)2]
w
(x,y)∼D
= E [(uˆ (w·x)−u (w·x)+u (w·x)−u∗ (w·x)+u∗ (w·x)−u∗(w∗·x)+u∗(w∗·x)−y)2]
w w w w w
(x,y)∼D
≤ 4 E [(uˆ (w·x)−u (w·x))2]+4 E [(u (w·x)−u∗ (w·x))2]
w w w w
x∼Dx x∼Dx
+4 E [(u∗ (w·x)−u∗(w∗·x))2]+4OPT
w
x∼Dx
≤ 8(OPT+ϵ)+4b2∥w−w∗∥2, (50)
2
where in the second inequality we used the results from Lemma 3.3, Lemma F.4 and we applied the
observation that:
E [(u∗ (w·x)−u∗(w∗·x))2] ≤ E [(u∗(w·x)−u∗(w∗·x))2] ≤ b2∥w−w∗∥2,
w 2
x∼Dx x∼Dx
by the definition of u∗ .
w
45D.4 Proof of Claim 4.5
We restate Claim 4.5 and show the number of samples needed for the testing subroutine Algorithm 3.
Claim 4.5. Let µ, ϵ , δ ∈ (0,1) be fixed. Let r = 1 log(Cb4W4 log2(bW)), where C is a sufficiently
1 L L6ϵ2
1
ϵ1
large absolute constant. Given a set of parameter-activation pairs P = {(w ;u )}t0J such that
√ j j j=1
w ∈ B(W) and u ∈ U for j ∈ [t J], where t J = 4b9W/(µ8 ϵ ), we have that using
j j (a,b) 0 0 1
(cid:18) b4W4log(1/δ) (cid:18) bW (cid:19)(cid:19)
m′ = Θ log5 ,
L4ϵ2 Lµϵ
1 1
i.i.d. samples from D, for any (w ;u ) ∈ P it holds with probability at least 1−δ,
j j
(cid:12) m′ (cid:12)
(cid:12) (cid:12) (cid:12)m1 ′ (cid:88) (u j(w j ·x(i))−y(i))21{|w j ·x(i)| ≤ Wr}− (x,yE )∼D[(u j(w j ·x)−y)2](cid:12) (cid:12) (cid:12) ≤ 2ϵ 1.
i=1
Proof. Fix (w ,u ) ∈ P. Since D is sub-exponential, we have Pr[|w ·x| ≥ ∥w ∥ r] ≤ 1 exp(−Lr).
j j x j j 2 L2
Consider random variables Z = (u (w ·x(i))−y(i))21{|w·x(i)| ≤ r}, i = 1,··· ,m, j = 1,··· ,t J,
i,j j j 0
where (x(i),y(i)) are independent random variables drawn from D. Using Fact F.3 (Appendix F),
we can truncate the labels y such that |y| ≤ M, where M = C(bW/L)log(bW/ϵ ) for some large
1
absolute constant C. Hence, |Z | ≤ 2(u2(w ·x(i))+(y(i))2)1{|w ·x(i)| ≤ Wr} ≤ 2(b2W2r2+M2),
i,j j j j
where we used the assumption that u is b-Lipschitz in the last inequality. Therefore, applying
Hoeffding’s inequality to Z we get:
i,j
Pr(cid:20)(cid:12) (cid:12)
(cid:12)
(cid:12)(cid:88)m′
(Z i,j −E[Z
i,j])(cid:12) (cid:12)
(cid:12)
(cid:12)
≥
m′t(cid:21)
≤
2exp(cid:18)
−
8(b2W2m r2′t2 +M2)2(cid:19)
.
i=1
√ √
Since there are t J = Wb7/(µ7η ϵ ) = 4b9W/(µ8 ϵ ) elements in the set P, applying a union
0 1 1
bound leads to:
Pr(cid:20)(cid:12) (cid:12) (cid:12) (cid:12)(cid:88)m′ Z i,j −E[Z i,j](cid:12) (cid:12) (cid:12) (cid:12) ≥ m′t,∀j ∈ [J](cid:21) ≤ 2exp(cid:18) − 8(b2W2m r2′t2 +M2)2 +log(4b9W/(µ8√ ϵ 1))(cid:19) .
i=1
Therefore, when
8(b2W2r2+M2)2(cid:18) (cid:18) 4b9W (cid:19) (cid:19)
m′ ≥ log √ +log(2/δ) , (51)
ϵ2 µ8 ϵ
1 1
we have that with probability at least 1−δ:
(cid:12) m′ (cid:12)
(cid:12) (cid:12) (cid:12)m1
′
(cid:88) (u j(w j·x(i))−y(i))21{|w j·x(i)| ≤ Wr}− (x,yE )∼D[(u j(w j·x)−y)21{|w j·x| ≤ Wr}](cid:12) (cid:12)
(cid:12)
≤ ϵ 1, (52)
i=1
for any (w ,u ) ∈ P. In addition, as Pr[|w ·x| ≥ Wr] ≤ Pr[|w ·x| ≥ ∥w ∥ r] ≤ 2 exp(−Lr),
j j j j j 2 L2
letting ϵ′ = 2 exp(−Lr), we further have:
L2
E [(u (w ·x)−y)21{|w ·x| ≥ Wr}]
j j j
(x,y)∼D
≤ 2 E [((u (w ·x))2+M2)1{|w ·x| ≥ Wr}]
j j j
x∼Dx
(cid:114)
≤ 2b2 E [(w ·x)4]Pr[|w ·x| ≥ Wr]+M2Pr[|w ·x| ≥ Wr]
j j j
x∼Dx
√ √
≤ 2cb2(W/L)2 ϵ′+M2ϵ′ ≤ (2cb2(W/L)2+M2) ϵ′,
46where in the second inequality we used Cauchy-Schwarz inequality and in the last inequality we used
the property that for any unit vector a it holds E[(a·x)4] ≤ c2/L4 for some absolute constant c as x
possesses a 1-sub-exponential tail. Therefore, choosing r = 1 log(C2b4W4 log2(bW)) = O˜(1 log(bW))
L √ L L6ϵ2 1 ϵ1 L Lϵ1
for some large absolute constant C renders ϵ′ ≤ ϵ /(2Cb2(W/L)2log2(bW/ϵ )), and we have
1 1
E [(u (w ·x)−y)21{|w ·x| ≥ Wr}] ≤ ϵ .
j j j 1
(x,y)∼D
Observe that as E [(u (w ·x)−y)2] is the sum of E [(u (w ·x)−y)21{|w ·x| ≥ Wr}]
(x,y)∼D j j (x,y)∼D j j j
and E [(u (w ·x)−y)21{|w ·x| ≤ Wr}], we have
(x,y)∼D j j j
0 ≤ E [(u (w ·x)−y)2]− E [(u (w ·x)−y)21{|w ·x| ≤ Wr}]
j j j j j
(x,y)∼D (x,y)∼D
≤ E [(u (w ·x)−y)21{|w ·x| ≥ Wr}] ≤ ϵ .
j j j 1
(x,y)∼D
Plugging the choice of r back into (51), we get that it is sufficient to choose m′ as
Clog(log(1/ϵ ))(cid:18) (cid:18) W(cid:19)2 (cid:18) bW(cid:19)(cid:19)2(cid:18) (cid:18) 4b9W (cid:19) (cid:19) (cid:18) b4W4log(1/δ) (cid:18) bW (cid:19)(cid:19)
m′ = 1 b2 log2 log √ +log(1/δ) = Θ˜ log5 .
ϵ2 L Lϵ2 µ8 ϵ L4ϵ2 Lµϵ
1 1 1 1 1
Therefore, using m′ = Ω˜(b4W4/(L4ϵ2)) samples, (52) indicates that with probability at least 1−δ,
1
for any (w ,u ) ∈ P it holds
j j
(cid:12) m′ (cid:12)
(cid:12) (cid:12) (cid:12)m1 ′ (cid:88) (u j(w j ·x(i))−y(i))21{|w j ·x(i)| ≤ Wr}− (x,yE )∼D[(u j(w j ·x)−y)2](cid:12) (cid:12) (cid:12)
i=1
(cid:12) m′ (cid:12)
≤ (cid:12) (cid:12) (cid:12)m1 ′ (cid:88) (u j(w j ·x(i))−y(i))21{|w j ·x(i)| ≤ Wr}− (x,yE )∼D[(u j(w j ·x)−y)21{|w j ·x| ≤ Wr}](cid:12) (cid:12) (cid:12)
i=1
(cid:12) (cid:12)
+(cid:12) (cid:12) E [(u j(w j ·x)−y)2]− E [(u j(w j ·x)−y)21{|w j ·x| ≤ Wr}](cid:12) (cid:12)
(cid:12)(x,y)∼D (x,y)∼D (cid:12)
≤ 2ϵ ,
1
thus completing the proof of Claim 4.5.
E Efficiently Computing the Optimal Empirical Activation
In this section, we show that the optimization problem (P) can be solved efficiently, following
the framework from [LH22] with minor modifications. We show that, for any ϵ > 0, there is
an efficient algorithm that runs in O˜(m2log(1/ϵ)) time and outputs a solution vˆt(z) such that
∥vˆt(z)−uˆt(z)∥ ≤ ϵ. We then argue that using such approximate solutions to the optimization
∞
problem (P) does not negatively impact our error guarantee, sample complexity, or runtime (up to
constant factors).
Proposition E.1 (Approximating the Optimal Empirical Activation). Let ϵ > 0, and D be (L,R)-
x
well behaved. Let uˆt ∈ U be the optimal solution of the optimization problem (P) given a sample
(a,b)
set S of size m drawn from D and a parameter wt ∈ B(W). There exists an algorithm that produces
an activation vˆt ∈ U such that ∥vˆt−uˆt∥ ≤ ϵ, with runtime O˜(m2log(bW/(Lϵ))).
(a,b) ∞
To prove Proposition E.1, we leverage the following result:
47Lemma E.2 (Section 5 [LH22]). Let f (y) and h (y) be any convex lower semi-continuous functions
i i
for i = 1,...,m. Consider the following convex optimization problem
m m−1
(cid:88) (cid:88)
(yˆ ,...,yˆ ) = argmin f (y )+ h (y −y ), (53)
1 m i i i i i+1
y1,...,ym
i=1 i=1
where y ∈ [−U,U] for all i = 1,...,m for some positive constant U. Then, for any ϵ > 0, there
i
exists an algorithm (the cc-algorithm [LH22]) that outputs an ϵ-close solution {y ,...,y } such that
1 m
|y −yˆ| ≤ ϵ for all i ∈ [m] with runtime O(m2log(U/ϵ)).
i i
Proof of Proposition E.1. We first reformulate problem (P) as a quadratic optimization problem
with linear constraints. To guarantee that uˆt is an element in U that satisfies uˆt(0) = 0, we add
(a,b)
a zero point (x(0),y(0)) = (0,0) to the data set S if S does not contain (0,0) in the first place. We
can thus assume without loss of generality that the data set contains (0,0). Denote z = w·x(i)
i
such that z ≤ z ≤ ··· ≤ z after rearranging the order of (x(i),y(i))’s, and suppose z = w·x = 0
1 2 m k 0
for a k ∈ [m]. Then (P) is equivalent to the following optimization problem:
m
(cid:88)
(yˆ(1),··· ,yˆ(m)) = argmin (y˜(i)−y(i))2
y˜(i),i∈[m]
i=1
s.t. 0 ≤ y˜(i+1)−y˜(i), 1 ≤ i ≤ k−1,
a(z −z ) ≤ y˜(i+1)−y˜(i), 1 ≤ i ≤ k−1,
i+1 i
y˜(i+1)−y˜(i) ≤ b(z −z ), 1 ≤ i ≤ m−1,
i+1 i
y˜(k) = 0.
Define h (y) = I (y) for i = 1...,k − 1, h (y) = I (y) for
i [−b(zi+1−zi),0] i [−b(zi+1−zi),−a(zi+1−zi)]
i = k...,m−1, where I (y) is the indicator function of a convex set Y, i.e., I (y) = 0 if y ∈ Y
Y Y
and I (y) = +∞ otherwise. It is known that h ’s are convex and sub-differentiable on their domain
Y i
Y . In addition, let f (y) = 1(y−y(i))2 for i ̸= k and f (y) = I (y). Then, we have the following
i i 2 k {0}
formulation for problem (P):
m m−1
(cid:88) (cid:88)
(yˆ(1),··· ,yˆ(m)) = argmin f (y˜(i))+ h (y˜(i)−y˜(i+1)) (P1)
i i
y˜(i),i=1,...,mi=1
i=1
Note that the functions f and h we defined above satisfy the conditions of Lemma E.2. Thus, it
i i
only remains to find the bounds on the variables y˜(i). This is easy to achieve as all y˜(i) must satisfy
|y˜(i)| ≤ b|z | = b|w·x(i)| and we know that x(i) are sub-exponential random variables. Therefore,
i
followingthesameideafromtheproofofLemmaF.2, weknowthatforU = 2W log(m/(Lδ)), itholds
L
thatwithprobabilityatleast1−δ,|y˜(i)| ≤ b|w·x(i)| ≤ bU foralli ∈ [m]. Hence,applyingLemmaE.2
to problem (P1), we get that it can be solved within ϵ-error in runtime O˜(m2log(bW/(Lϵ))).
The effect of approximation error in (P) Sincethesolutionvˆt isϵ-closetouˆt,thisapproximated
solution will only result in an ϵ-additive error in the sharpness result Proposition 3.1 and the gradient
norm concentration Lemma 4.3. In more detail, for the result of Proposition 3.1, we have
(cid:12) (cid:12) (cid:12) m (cid:12)
(cid:12) (cid:12)(∇L(cid:98)sur(wt;vˆt)−∇L(cid:98)sur(wt;uˆt))·(wt−w∗)(cid:12)
(cid:12) =
(cid:12)
(cid:12)
1 (cid:88) (vˆt(wt·x(i))−uˆt(wt·x(i)))(wt−w∗)·x(i)(cid:12)
(cid:12)
(cid:12) (cid:12) (cid:12)m (cid:12)
i=1
m
≤
ϵ (cid:88)(cid:12) (cid:12)(wt−w∗)·x(i)(cid:12)
(cid:12) ≤ 2ϵU,
m
i=1
48since |wt·x(i)| ≤ U and |w∗·x(i)| ≤ U with probability at least 1−δ. Therefore, choosing ϵ′ = ϵ/U
we have that Proposition 3.1 holds for approximate activations vˆt with an additional ϵ error. Observe
that this does not affect the approximation factor in our final O(OPT)+ϵ result, while the value
of ϵ only needs to be rescaled by a constant factor, effectively increasing the sample size and the
runtime by constant factors.
Let us denote the unit ball by B. For the gradient norm concentration lemma Lemma 4.3, note
that at any iteration t, it always holds that
m m
1 (cid:88) ϵ (cid:88)
∥∇L(cid:98)sur(wt;vˆt)−∇L(cid:98)sur(wt;uˆt)∥
2
= max (vˆt(wt·x(i))−uˆt(wt·x(i)))x(i)·v ≤ max |x(i)·v|.
v∈B m v∈B m
i=1 i=1
Since E [xx⊤] ≼ I and v ∈ B, we have E [|x·v|] ≤ (cid:112) E[(x·v)2] ≤ 1. Now since |x(i)·v|
x∼Dx x∼Dx
are independent 1/L-sub-exponential random variables, applying Bernstein’s inequality it holds that
for any v ∈ B and an absolute constant c,
Pr(cid:20)(cid:12) (cid:12) (cid:12) 1 (cid:88)m |x(i)·v|− E [|x·v|](cid:12) (cid:12) (cid:12) ≥ s(cid:21) ≤ 2exp(cid:18) −cmin(cid:26) m2s2 , ms (cid:27)(cid:19) = 2exp(−cmL2s2).
(cid:12)m x∼Dx (cid:12) m/L2 1/L
i=1
Let N(B,ϵ;ℓ ) be the ϵ-net of the unit ball B. Note that the cover number of these v ∈ B is of
2 √
order (1/ϵ)O(d), therefore, applying a union bound on N(B,ϵ;ℓ ) and for all t JT = O(log(1/ϵ)/ ϵ)
2 0
iterations, and setting s = 1, it holds
(cid:20) (cid:12) m (cid:12) (cid:21)
Pr ∀v ∈ N(B,ϵ;ℓ 2), (cid:12) (cid:12) 1 (cid:88) |x(i)·v|− E [|x·v|](cid:12) (cid:12) ≥ 1 ≤ 2exp(−cmL2+c′dlog(1/ϵ)) ≤ δ,
(cid:12)m x∼Dx (cid:12)
i=1
wherethelastinequalitycomesfromthefactthatwehavem ≳ W9/2b14dlog(1/δ)log4(d/ϵ)/(L4µ9δϵ3/2)
as the batch size. Let v∗ = argmax (cid:80)m |x(i)·v|. Then there exists a v′ ∈ N(B,ϵ;ℓ ) such that
v∈B i=1 2
∥v′−v∗∥ ≤ ϵ and hence,
2
m m m
1 (cid:88) 1 (cid:88) 1 (cid:88)
|x(i)·v∗| ≤ |x(i)·(v∗−v′)|+ |x(i)·v′|
m m m
i=1 i=1 i=1
ϵ (cid:88)m v∗−v′ 1 (cid:88)m
= |x(i)· |+ |x(i)·v′|
m ϵ m
i=1 i=1
m m
ϵ (cid:88) 1 (cid:88)
≤ |x(i)·v∗|+ |x(i)·v′|,
m m
i=1 i=1
where the last inequality comes from the observation that as (v∗−v′)/ϵ ≤ B, it holds (cid:80)m |x(i)·
i=1
((v∗−v′)/ϵ)| ≤ (cid:80)m |x(i)·v∗|, by the definition of v∗. Therefore, with probability at least 1−δ we
i=1
have
m m
1 (cid:88) 1 1 (cid:88)
|x(i)·v∗| ≤ |x(i)·v′| ≤ 2(1+ E [|v·x|]) ≤ 4.
m 1−ϵm x∼Dx
i=1 i=1
This implies that ∥∇L(cid:98)sur(wt;vˆt)∥
2
≤ ∥∇L(cid:98)sur(wt;uˆt)∥
2
+4ϵ for all iterations with probability at
least 1−δ. Therefore, Lemma 4.3 continues to hold for the ϵ-approximate activation vˆt.
Thus, we have that the inequalities (40) and (42) in the proof of Theorem 4.2 remain valid for
ϵ-approximate vˆt, and hence the results in Theorem 4.2 are unchanged.
49F Uniform Convergence of Activations
In this section, we review and provide standard uniform convergence results showing that the
sample-optimal activations concentrate around their population-optimal counterparts. We first
bound the L2 distance between the sample-optimal and population-optimal activations under wt.
2
To do so, we build on Lemma 8 in [KKSK11]. Note that Lemma 8 from [KKSK11] only works
for bounded 1-Lipschitz activations u : R (cid:55)→ [0,1], hence it is not directly applicable to our case.
Fortunately, since D has a sub-exponential tail (see Definition 1.2), we are able to bound the range
x
of u(w·x) for u ∈ U and w ∈ B(W) with high probability. Concretely, we prove the following
(a,b)
lemma. Note that in the lemma statement, uˆ∗t is a random variable defined w.r.t. the (random)
dataset S∗, and thus the probabilistic statement is for this random variable.
We make use of the following fact from [KKSK11]:
Fact F.1 (Lemma 8 [KKSK11]). Let V be the set of non-deceasing 1-Lipschitz functions such that
v : R → [0,1], ∀v ∈ V. Given S = {(x(i),y(i))}m , where (x(i),y(i)) are sampled i.i.d. from some
m i=1
distribution D′, let
m
1 (cid:88)
vˆ ∈ argmin (v(w·x(i))−y(i))2.
w
m
v∈V
i=1
Then, with probability at least 1−δ over the random dataset S , for any w ∈ B(W) it holds uniformly
m
that
(cid:18) (cid:18) dlog(Wm/δ)(cid:19)2/3(cid:19)
E [(vˆ (w·x)−y)2]− inf E [(v(w·x)−y)2] = O W .
w
(x,y)∼D′ v∈V(x,y)∼D′ m
The first lemma states that with sufficient many of samples, the idealized sample-optimal
activation uˆ∗t defined as the optimal solution of (P*) is close to its population counterpart u∗t, the
optimal solution of (EP*).
Lemma F.2 (Approximating Population-Optimal Noiseless Activation by Sample-Optimal). Let
D be (L,R)-well behaved and let wt ∈ B(W). Provided a dataset S∗ = {(x(i),y∗(i))}, where x(i) are
x
i.i.d. samples from D and y∗(i) = u∗(w∗·x(i)), let uˆ∗t be the sample-optimal activation on S∗ as
x
defined in (P*). In addition, let u∗t be the corresponding population-optimal activation, following the
definition in (EP*). Then, for any ϵ,δ > 0, if the size m of the dataset S∗ is sufficiently large
(cid:18) b2W3(cid:19)3/2
m ≳ dlog4(d/(ϵδ)) ,
L2ϵ
we have that with probability at least 1−δ, for any wt ∈ B(W):
E [(uˆ∗t(wt·x)−u∗(w∗·x))2] ≤ E [(u∗t(wt·x)−u∗(w∗·x))2]+ϵ ,
x∼Dx x∼Dx
and, furthermore,
E [(uˆ∗t(wt·x)−u∗t(wt·x))2] ≤ ϵ.
x∼Dx
Proof. Our goal is to show that with high probability, the sample-optimal activation uˆ∗t ∈ U and
(a,b)
the population optimal activation u∗t ∈ U can be scaled to 1-Lipschitz functions mapping R to
(a,b)
[0,1], then, Fact F.1 can be applied.
Since x possesses a sub-exponential tail, for any w ∈ B(W) we have Pr[|w ·x| ≥ ∥w∥ r] ≤
2
2 exp(−Lr). Therefore, with probability at least 1−(δ /m)2 it holds |w·x| ≤ 2W log(m/(Lδ )).
L2 1 L 1
50Since we have m samples, a union bound on these m samples yields that with probability at least
1−δ2/m it holds |w·x(i)| ≤ 2W log(m/(Lδ )), for any given w ∈ B(W). Let r = 2W log(m/(Lδ )).
1 L 1 L 1
In the remainder of the proof, we assume that wt·x(i) ≤ r holds for every x(i) in the dataset S∗,
which happens with probability at least 1−δ2/m ≥ 1−δ .
1 1
Let V be the set of non-decreasing 1-Lipschitz functions v : R → [0,1] such that v(0) = 1/2, and
v(z )−v(z ) ≥ (a/(2br))(z −z ) for all z ≥ z ≥ 0. We observe that restricted on the interval
1 2 1 2 1 2
|z| ≤ r, (uˆ∗t(z)/(2br)+1/2)| is 1-Lipschitz, non-decreasing and bounded in the interval [0,1].
|z|≤r
Thus, (uˆ∗t(z)/(2br)+1/2)| = vˆ∗t(z)| , for some vˆ∗t ∈ V. Furthermore, under the condition
|z|≤r |z|≤r
that |wt · x(i)| ≤ r, since (uˆ∗t(z)/(2br) + 1/2)| = vˆ∗t(z)| , we observe that v∗t(z) is the
|z|≤r |z|≤r
optimal activation in the function space V, given the dataset S∗ and parameter wt, i.e.,
m
1 (cid:88)
vˆ∗t ∈ argmin (v(wt·x(i))−(u∗(w∗·x(i))/(2br)+1/2))2.
m
v∈V
i=1
In other words, uˆ∗t(z)/(2br)+1/2 is the sample-optimal activation in the function class V when
restricted to the interval |z| ≤ r. Consider x ∼ D . Then Pr[|wt ·x| ≥ r] ≤ (δ /m)2 and for any
x 1
wt ∈ B(W), the expectation E [(uˆ∗t(wt·x)−u∗(w∗·x))2] can be decomposed into the following
x∼Dx
terms
E [(uˆ∗t(wt·x)−u∗(w∗·x))2] = E [(uˆ∗t(wt·x)−u∗(w∗·x))21{|wt·x| ≤ r}]
x∼Dx x∼Dx
+ E [(uˆ∗t(wt·x)−u∗(w∗·x))21{|wt·x| > r}]
x∼Dx
≤ E [(uˆ∗t(wt·x)−u∗(w∗·x))21{|wt·x| ≤ r}]
x∼Dx
+2 E [(uˆ∗t(wt·x))2+(u∗(w∗·x))21{|wt·x| > r}] . (54)
x∼Dx
Since both uˆ∗t and u∗ are (a,b)-unbounded functions such that uˆ∗t(0) = u∗(0) = 0, we have
(uˆ∗t(wt · x))2 ≤ b2W2((wt/∥wt∥ ) · x)2 and similarly, (u∗(w∗ · x))2 ≤ b2W2((w∗/∥w∗∥ ) · x)2.
2 2
Furthermore, since for any unit vector a, the random variable a·x follows a (1/L)-sub-exponential
distributionasD is(L,R)-wellbehaved, thus, itholdsthatE [(a·x)4] ≤ c/L4 forsomeabsolute
x x∼Dx
constant c. Therefore, after applying Cauchy-Schwarz inequality to E[(uˆ∗t(wt·x))21{|wt·x| ≥ r}],
we get
(cid:114)
E[(uˆ∗t(wt·x))21{|wt·x| ≥ r}] ≤ b2W2 E [((wt/∥wt∥ )·x)4]Pr[|wt·x| ≥ r]
2
x∼Dx
≤ cb2W2δ /(L2m), (55)
1
and similarly, E[(u∗(w∗·x))21{|wt·x| ≥ r}] ≤ cb2W2δ /(L2m). Thus, plugging these inequalities
1
back into (54), we get
E [(uˆ∗t(wt·x)−u∗(w∗·x))2] ≤ E [(uˆ∗t(wt·x)−u∗(w∗·x))21{|wt·x| ≤ r}]
x∼Dx x∼Dx
+2cb2W2δ /(L2m).
1
We are now ready to apply Fact F.1 (note that V is a smaller function class compared to the class
of 1-Lipschitz functions described Fact F.1, hence Fact F.1 applies). Denote A = {x : |wt·x| ≤ r}.
Let y′ = y∗/(2br) + 1/2, y∗ = u∗(w∗ · x). Since conditioning on A, uˆ∗t(z)/(2br) + 1/2 is the
51sample-optimal activation, applying Fact F.1 we get that with probability at least 1−δ :
2
E [(uˆ∗t(wt·x)/(2br)+1/2−(u∗(w∗·x)/(2br)+1/2))2|A]
x∼Dx
= E [(vˆ∗t(wt·x)−y′)2|A]
x∼Dx
≤ inf E [(v(wt·x)−y′)2|A]+O˜(W(dlog(m/δ )/m)2/3).
2
v∈Vx∼Dx
Let V| and U | be the functions from V and U restricted on the interval |z| ≤ r,
|z|≤r (a,b) |z|≤r (a,b)
respectively. It is not hard to see that by the definition of U and V, (U | )/(2br)+1/2 ⊂
(a,b) (a,b) |z|≤r
V| . Therefore,
|z|≤r
inf E [(v(wt·x)−y′)2|A] ≤ inf E [(u(wt·x)/(2br)+1/2−y′)2|A]
v∈Vx∼Dx u∈Ux∼Dx
1
≤ inf E [(u(wt·x)−y∗)2|A].
4b2r2 u∈Ux∼Dx
Hence, with probability at least 1−δ ,
2
E [(uˆ∗t(wt·x)−u∗(w∗·x))21{A}]
x∼Dx
= 4b2r2 E [(vˆ∗t(wt·x)−y′)2|A]Pr[A]
x∼Dx
≤ 4b2r2 inf E [(v(wt·x)−y′)2|A]Pr[A]+O˜(b2r2W(dlog(m/δ )/m)2/3)Pr[A]
2
v∈Vx∼Dx
≤ inf E [(u(wt·x)−u∗(w∗·x))21{A}]+O˜(b2r2W(dlog(m/δ )/m)2/3)
2
u∈Ux∼Dx
≤ inf E [(u(wt·x)−u∗(w∗·x))2]+O˜(b2r2W(dlog(m/δ )/m)2/3) .
2
u∈Ux∼Dx
Setting δ = δ = δ/2 and plugging everything back into (56), we finally get that with probability at
1 2
least 1−δ,
E [(uˆ∗t(wt·x)−u∗(w∗·x))2]
x∼Dx
(cid:18) b2W3 (cid:18) m(cid:19)(cid:18) dlog(m/δ)(cid:19)2/3(cid:19)
≤ inf E [(u(wt·x)−u∗(w∗·x))2]+O log2 .
u∈Ux∼Dx L2 Lδ m
To complete the first part of the claim, it remains to choose m as the following value
(cid:18) (cid:18) b2W3(cid:19)3/2(cid:19)
m = Θ dlog4(d/(ϵδ)) .
L2ϵ
For the second part of the claim, note that U is a closed convex set of functions, and that the
(a,b)
infimum inf E [(u(wt·x)−u∗(w∗·x))2] is attained by u∗t(z). Observe that we have shown
u∈U x∼Dx
that with the sample size m specified above, with probability at least 1−δ, it holds
ϵ ≥ E [(uˆ∗t(wt·x)−u∗(w∗·x))2−(u∗t(wt·x)−u∗(w∗·x))2]
x∼Dx
= E [(uˆ∗t(wt·x)−u∗t(wt·x))(uˆ∗t(wt·x)+u∗t(wt·x)−2u∗(w∗·x))]
x∼Dx
= E [(uˆ∗t(wt·x)−u∗t(wt·x))2]+2 E [(uˆ∗t(wt·x)−u∗t(wt·x))(u∗t(wt·x)−u∗(w∗·x))].
x∼Dx x∼Dx
52Since uˆ∗t(z) ∈ U , applying the second part of Claim C.1 with v′ = uˆ∗t we get
(a,b)
E [(u∗t(wt·x)−uˆ∗t(wt·x))(u∗(w∗·x)−u∗t(wt·x))] ≥ 0.
x∼Dx
Thus, we have:
E [(uˆ∗t(wt·x)−u∗t(wt·x))2] ≤ ϵ.
x∼Dx
This completes the proof of Lemma F.2.
To prove a similar uniform convergence result for the attainable activations uˆt, we make use of
the following fact from prior literature, which shows that we can without loss of generality take the
noisy labels to be bounded by M = O(bW log(bW/ϵ)), due to D being (L,R)-well behaved.
L x
Fact F.3 (Lemma D.8 [WZDD23]). Let y′ = sign(y)min(|y|,M) for M = bW log(16b4W4 ). Then:
L ϵ2
E [(u∗(w∗·x)−y′)2] = OPT+ϵ.
(x,y)∼D
In other words, we can assume |y| ≤ M without loss of generality by truncating labels that are
larger than M. Under this assumption, as stated in Lemma F.4 below, we bound the L2 distance
2
between uˆt and ut using similar arguments as in Lemma F.2.
Lemma F.4 (Approximating Population-Optimal Activation by Sample-Optimal). Let wt ∈ B(W).
Given a distribution D whose marginal D is (L,R)-well behaved, let S = {(x(i),y(i))}m , where
x i=1
(x(i),y(i)) for i ∈ [m] are i.i.d. samples from D. Let uˆt be a sample-optimal activation for the
dataset S and parameter vector wt, as defined in (P). In addition, let ut be the corresponding
population-optimal activation, as defined in (EP). Then, for any ϵ,δ > 0, choosing a sufficiently
large
(cid:18) b2W3(cid:19)3/2
m ≳ dlog4(d/(ϵδ)) ,
L2ϵ
we have that for any wt ∈ B(W), with probability at least 1−δ over the dataset S:
E [(uˆt(wt·x)−y)2] ≤ E [(ut(wt·x)−y)2]+ϵ ,
(x,y)∼D (x,y)∼D
and, furthermore,
E [(uˆt(wt·x)−ut(wt·x))2] ≤ ϵ.
x∼Dx
Proof. As in the proof of Lemma F.2, we choose r = 2cW log(m/(Lδ )) so that |wt·x(i)| ≤ r for all
L 1
x(i)’s from the dataset with probability at least 1−δ2/m ≥ 1−δ . We now condition on the event
1 1
that |wt ·x(i)| ≤ r for all i = 1,...,m. Let V be the set of non-decreasing 1-Lipschitz functions
such that ∀v ∈ V, v(0) = 1/2, and v(z )−v(z ) ≥ (a/(2br))(z −z ) for all z ≥ z ≥ 0. Then,
1 2 1 2 1 2
conditioned on this event, we similarly have that (uˆt(z)/(2br)+1/2)| = vˆt(z) ∈ V, and vˆt(z)
|z|≤r
satisfies:
m
1 (cid:88)
vˆt(z) ∈ argmin (v(wt·x(i))−y(i))2.
m
v∈V
i=1
Again, studying the L2 distance between uˆt(z) and ut(z), we have:
2
E [(uˆt(wt·x)−y)2] = E [(uˆt(wt·x)−y)21{|wt·x| ≤ r}]
(x,y)∼D (x,y)∼D
+ E [(uˆt(wt·x)−y)21{|wt·x| > r}].
(x,y)∼D
53The probability of |wt · x| > r is small due to the fact that D possesses sub-exponential tail:
x
Pr[|wt ·x| > r] ≤ (δ /m)2. Now note that |y| ≤ M and E [((wt/∥wt∥ )·x)4] ≤ c/L4 by the
1 x∼Dx 2
sub-exponential property of D , we thus have:
x
E [(uˆt(wt·x)−y)21{|wt·x| > r}]
(x,y)∼D
≤ 2 E [((uˆt(wt·x))2+y2)1{|wt·x| > r}]
(x,y)∼D
≤ 2 E [b2W2((wt/∥wt∥ )·x)21{|wt·x| > r}]+2M2Pr[|wt·x| > r]
2
x∼Dx
(cid:114)
≤ 2b2W2 E [((wt/∥wt∥ )·x)4]Pr[|wt·x| > r]+2M2Pr[|wt·x| > r]
2
x∼Dx
≤ 2cb2W2δ /(L2m)+2M2(δ /m)2,
1 1
whereinthesecondinequalityweusedthefactthatuˆt isb-Lipschitzandwt ∈ B(W), andinthethird
inequality we applied Cauchy-Schwarz. Since M = bW log(16b4W4 ), we have M2(δ /m) ≲ cb2W2/L2
L ϵ2 1
for m ≳ log(bW/ϵ), thus, we get
E [(uˆt(wt·x)−y)21{|wt·x| > r}] ≤ 4c(bW/L)2δ /m, (56)
1
(x,y)∼D
for some absolute constant c.
The rest remains the same as in the proof of Lemma F.2. Let A = {x : |wt ·x| ≤ r}. Let
y′ = y/(2br)+1/2. As vˆt(z) = uˆt(z)/(2br)+1/2 is the sample-optimal activation in V given wt
(conditioned on A), applying Fact F.1 we have that with probability at least 1−δ:
E [((uˆt(wt·x)/(2br)+1/2)−y′)2|A] = E [(vˆt(wt·x)−y′)2|A]
(x,y)∼D (x,y)∼D
≤ inf E [(v(wt·x)−y′)2|A]+O˜(W(dlog(m/δ )/m)2/3).
2
v∈V(x,y)∼D
Since U | /(2br)+1/2 ⊂ V| , we further have
(a,b) |z|≤r |z|≤r
inf E [(v(wt·x)−y′)2|A] ≤ inf E [(u(wt·x)/(2br)+1/2−y′)2|A]
v∈V(x,y)∼D u∈U (a,b)(x,y)∼D
1
≤ inf E [(u(wt·x)−y)2|A].
4b2r2 u∈U (a,b)(x,y)∼D
Therefore, E [(uˆt(wt·x)−y)21{A}] can be bounded from above by
(x,y)∼D
E [(uˆt(wt·x)−y)21{A}]
(x,y)∼D
= 4b2r2 E [(vˆt(wt·x)−y′)2|A]Pr[A]
(x,y)∼D
≤ 4b2r2 inf E [(v(wt·x)−y′)2|A]Pr[A]+O˜(b2r2W(dlog(m/δ )/m)2/3)
2
v∈V(x,y)∼D
≤ inf E [(u(wt·x)−y)21{A}]+O˜(b2r2W(dlog(m/δ )/m)2/3)
2
u∈U (a,b)(x,y)∼D
≤ inf E [(u(wt·x)−y)2]+O˜(b2r2W(dlog(m/δ )/m)2/3).
2
u∈U (a,b)(x,y)∼D
Thus, combining with (56), we get that with probability at least 1−δ −δ ,
1 2
(cid:18) (cid:18)
dlog(m/δ
)(cid:19)2/3(cid:19) (cid:18) bW(cid:19)2δ
E [(uˆt(wt·x)−y)2] ≤ E [(ut(wt·x)−y)2]+O˜ Wb2r2 2 + 1 .
(x,y)∼D (x,y)∼D m L m
54Choosing the size of the sample set to be:
(cid:18) (cid:18) b2W3(cid:19)3/2(cid:19)
m = Θ dlog4(d/(ϵδ)) ,
L2ϵ
and recalling that r = 2cW log(m/(Lδ )), we finally have
L 1
E [(uˆt(wt·x)−y)2] ≤ E [(ut(wt·x)−y)2]+ϵ,
(x,y)∼D (x,y)∼D
with probability at least 1−δ, after choosing δ = δ = δ/2.
1 2
To prove the final claim of the lemma, we follow the same argument as in the proof of Lemma F.2.
Since we have just shown that with probability at least 1−δ, it holds
ϵ ≥ E [(uˆt(wt·x)−y)2−(ut(wt·x)−y)2]
x∼Dx
= E [(uˆt(wt·x)−ut(wt·x))2]+2 E [(uˆt(wt·x)−ut(wt·x))(ut(wt·x)−y)],
x∼Dx x∼Dx
applying the first statement in Claim C.1 completes the proof.
55