Replicating Electoral Success
Kiran Tomlinson∗1, Tanvi Namjoshi1, Johan Ugander2, and Jon Kleinberg1
1Cornell University
2Stanford University
Abstract
A core tension in the study of plurality elections is the clash between the classic Hotelling–Downs
model,whichpredictsthattwooffice-seekingcandidatesshouldpositionthemselvesatthemedianvoter’s
policy, and the empirical observation that real-world democracies often have two major parties with
divergentpolicies. Motivatedinpartbythistensionanddrawingfromboundedrationality,weintroduce
adynamicmodelofcandidatepositioningbasedonasimplebehavioralheuristic: candidatesimitatethe
policyofpreviouswinners. Theresultingmodeliscloselyconnectedtoevolutionaryreplicatordynamics
and, despite its simplicity, exhibits complex behavior and contrasts considerably with existing modeling
approaches. For uniformly-distributed voters, we prove in our model that when there are k = 2, 3, or
4 candidates per election, any symmetric candidate distribution converges over time to a concentration
of candidates at the center. With k ≥ 5 or more candidates per election, however, we prove that the
candidate distribution does not converge to the center. For initial distributions of k ≥ 5 candidates
without any extreme candidates, we prove a stronger statement than non-convergence, showing that
the density in an interval around the center goes to zero. As a matter of robustness, our conclusions
are qualitatively unchanged (though require different analyses) if a small fraction of candidates are not
winner-copiers and are instead positioned uniformly at random in each election. Beyond our theoretical
analysis,weillustrateourresultsinextensivesimulations;forfiveormorecandidates,wefindatendency
towardstheemergenceoftwoclusters,amechanismsuggestiveofDuverger’sLaw,theempiricalfinding
that plurality leads to two-party systems. Our simulations also explore several variations of the model,
including non-uniform voter distributions, other forms of noise, and replication with memory of earlier
rounds of elections. In these simulated variants, we find the same general pattern: convergence to the
center with four or fewer candidates, but not with five or more. Finally, we discuss the relationship
between our replicator dynamics model and prior work on strategic equilibria of candidate positioning
games.
1 Introduction
In a democracy, election outcomes determine the trajectory of public policy. A central question in the
study of elections is therefore whether we can model which policies are electorally successful. However,
elections are extremely complex, with layered interactions between voters, candidates, and the incentives
that guide them. To understand the principles governing elections, we therefore need to pare down this
complexity and begin with simple models. The literature around this topic traces its roots to Hotelling [33]
andDowns[20]. IntheHotelling–Downsmodel, candidatescompeteforelectioninaone-dimensionalpolicy
space. Undertheassumptionthatvotersprefercandidatesclosertotheminpolicyspace,tworationaloffice-
seeking candidates will adopt the policy of the median voter, since any other position receives strictly fewer
votes. Thus, the central prediction of the Hotelling–Downs model is that we should expect candidates to
espouse near-identical moderate policies; in economic contexts, this is often called the principle of minimum
∗kt@cs.cornell.edu
1
4202
beF
72
]TG.sc[
1v90171.2042:viXraF 3,0 rs F 3,1 rs F 3,2
0 0.5 1 0 0.5 1 0 0.5 1
sample winners
0 0.5 1 0 0.5 1 0 0.5 1
elections at t = 1 elections at t = 2 elections at t = 3
Figure 1: Replicator dynamics for candidate positioning with k = 3 candidates per election. The top row
showsthewinnerdistributionsF foreachgenerationt,startingfromauniformdistributionatt=0,while
k,t
the bottom row shows four example elections per generation. In each generation, candidates sample their
positions from the winner distribution from the previous generation. Plurality winners (with voters uniform
over [0,1]) are indicated in green.
differentiation [23, 17]. However, this is not what we observe in modern democracies: countries using
plurality often have two dominant parties with markedly different policies [56, 30, 57]. Decades of research
have attempted to reconcile this observed policy divergence with the intuitive arguments of Hotelling and
Downs [30, 53], postulating additional factors like the threat of third-party entry [54] or policy- rather than
office-motivated candidates [72]. Subsequent research has also expanded beyond two-candidate analysis to
consider k-candidate elections [16].
Themajorityofthisworkhascontinuedunderthetraditionalassumptionthatcandidatesarerationaland
abletomakestrategicallyoptimaldecisions. However,thegrowingliteratureonboundedrationality[65,66]
and decision-making heuristics [69], as well as the complexity of elections, casts doubt on whether this is
likely in practice. In a notable exception to the literature on rational candidate positioning, Bendor et al.
[4] argue that heuristics play a crucial role in electoral strategy:
Campaigns are of chess like complexity—worse, probably; instead of a fixed board, campaigns
are fought out on stages that can change over time, and new players can enter the game. Hence,
cognitive constraints (e.g., the inability to look far down the decision tree, to anticipate your
opponent’s response to your response to their response to your new ad) inevitably matter. [...]
Thus, political campaigns, like military ones, are filled with trial and error. A theme is tried,
goes badly (or seems to), and is dropped. The staff hurries to find a new one, which seems to
work initially and then weakens. A third is tried, and then a fourth. [...] In short, there are good
reasons for believing that the basic properties of experiential learning—becoming more likely to
use something that has worked in the past and less likely to repeat something that has failed—hold
in presidential campaigns. [4, emphasis ours]
Our model. In this paper, we introduce a model of candidate positioning based on the above heuristic:
candidates imitate success. We focus on plurality elections, where each voter casts one vote and the candi-
date with the most votes wins. We assume voters have 1-Euclidean preferences [15, 24], where voters and
candidates occupy points in the unit interval [0,1] and voters prefer closer candidates. To represent a large
voting population, our model uses a continuum of voters and continuous vote shares rather than discrete
counts. Divergingfrompriorwork,wemodelalargenumberofk-candidateelectionsthatproceedingenera-
tions rather than an individual election or election sequence. In each generation, we assume that candidates
copy the policy position of a winner from the previous generation, a simple heuristic in line with Bendor
2k=2 k=3 k=4 k=5 k=6 k=7
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
Figure2: Replicatordynamicsrunsfork =2,...,7and200generations. Eachplotshows50runslayeredon
topofeachother,whereeachrunsimulates100,000electionspergeneration. Wealsouseenhancedsymmetry,
atricktokeepthesymmetryoftheanalyticalmodelbyreflectingcopiedpointsacross1/2(discussedfurther
in Section 5). Darker regions indicate higher candidate density; we use a log-scaled colormap to make low-
density regions visible. As our theory establishes, the candidate distribution converges to the center for
k =2,3,4, but does not for k ≥5. The convergence is very fast for k =2 and 3, but much slower for k =4.
etal.’ssuggestionthatcandidatesusestrategiesthatworkedinthepast. Thisheuristicisalsosupportedby
a wealth of political science research arguing that the imitation of policies, especially electorally successful
ones, is a major feature of politics [63, 7, 25]. As with voters, our model uses a continuous distribution of
candidate positions in each generation, which can be viewed as either capturing the expected behavior of a
finite number of elections or as the infinite-election limit.
This simple assumption about candidate behavior (sample a position from the distribution of winners in
the last election cycle) yields a mathematical model equivalent to the well-studied replicator dynamics from
evolutionary biology [67, 62], which have also found widespread use in economics [59, 47]. In the classic
replicator dynamics, n strategies (or alleles) compete in a population, increasing in prevalence at a rate
proportional to their average fitness in pairwise contests drawn from the current population. Our model
arises from taking such dynamics and moving to a continuous strategy space with k-way interactions in
discrete time (i.e., k-candidate elections), treating the plurality win probability as fitness; we therefore refer
to it as replicator dynamics for candidate positioning.
In summary, then, our model operates in a sequence of generations; each generation involves a large
number of identically distributed elections, and the candidates in a given generation are drawn from the
distribution of winners of the previous generation’s elections. Figure 1 provides a schematic visualization of
the process with k =3 candidates. While our model is phrased in terms of a large population of elections—
justastheclassicreplicatordynamicsmodelsapopulationoforganisms—thereisadeepconnectionbetween
replicator dynamics and reinforcement learning [9, 5], so our conclusions are likely to generalize to models
of individual-level trial-and-error.
Ourresults. Ourmaintechnicalcontributionscharacterizethelong-runbehaviorofthereplicatordynam-
ics for different values of k, the number of candidates per election. We find a dramatic qualitative change
in the dynamics as the number of candidates k increases. For our analysis, we focus on the case in which
the initial distribution of candidates is symmetric and has a continuous CDF and that voters are uniformly
distributed over [0,1], but we find evidence in simulation that the same patterns hold with other symmetric
voter distributions. When k = 2, we prove that the candidate distribution converges to a point mass at
1/2 under the replicator dynamics, just like rational candidates in the Hotelling–Downs model. However,
we also prove in our model that the candidate distribution converges to the center for k =3 and 4, in stark
contrast to three- and four-candidate extensions of the Hotelling–Downs argument [16]. Given the behavior
for k = 2,3, and 4, one might be tempted to hypothesize that the replicator dynamics always cause the
candidate distribution to converge to the center. Surprisingly, we prove that the pattern ends there: for any
k ≥5,weshowthatthecandidatedistributiondoesnotconvergeto1/2. SeeFigure2forsimulationsdemon-
strating the patterns that we characterize theoretically. These simulations reveal a tendency for candidate
counts larger than 4 to result in two distinct clusters of policies (around 1/4 and 3/4 with uniform voters).
ThisisstronglyreminiscentofDuverger’s Law [22,57],theobservationthatpluralityelectionstendtowards
3two-party systems; it is striking that itemerges here from a model that does notinclude anyexplicit reward
forclusteringatpointsawayfromthecenteroranymechanismslikethethreatofthird-partycandidates[8].
To strengthen this characterization of the long-run replicator dynamics, we show that our convergence
resultsarerobusttonoise: evenifasmallfractionofcandidatespositionthemselvesuniformlyatrandom,we
can still show (approximate) convergence to the center for k =2,3,4 and non-convergence for k ≥5. While
we are not able to theoretically derive the asymptotic distribution for k ≥5 in general, we show that when
theinitialcandidatedistributionissupportedonlyon(1/4,3/4),thecandidatedensityinanintervalaround
1/2 goes to 0. Additionally, we explore several variants of the model in simulation, including non-uniform
voter distributions, noisy position-copying, memory of prior rounds of elections, and mixtures of candidate
counts.1 Across these variants, we observe the same general pattern: convergence to the center with up
to four candidates, but not with five or more. For candidate counts k > 5 we sometimes see complex and
chaotic finite-sample effects in simulation. We conclude by relating our replicator dynamics model back to
traditional analyses of Nash equilibria in the style of Hotelling and Downs. The close relationship between
replicatordynamicsfixedpointsandNashequilibriaiswell-known[32],butwearguethatignoringdynamics
and focusing only on Nash equilibria leads to brittle conclusions. In particular, we show that different
assumptions on voter behavior when candidates occupy the same points lead to dramatically different Nash
equilibria than reported in prior work [16]; in contrast, this choice has no effect on our replicator dynamics
results.
To summarize, our main finding is that a simple imitation heuristic can cause candidates to either
converge to the median voter or to form two distinct parties, depending on how many candidates run in
eachelection. Intuitively,thisphenomenonisdrivenbythebogeymanofone-dimensionalpluralityelections:
being flanked. If a candidate is stuck between two others, they lose votes from both the left and the right.
Whentherearetoomanycandidatesallimitatingpreviousmoderatewinners,onlytheleftmostorrightmost
of them will avoid being flanked, making more extreme candidates more successful. However, with a small
enough pool of opponents, the higher vote share a moderate can receive is worth the risk of ending up stuck
between two others. This emerges naturally from our dynamics, without the need for strategic forethought.
The surprising fact that falls out of our mathematical analysis is that when candidates are imitators rather
than optimizers, the tipping point between the Hotelling–Downs centripetal force and the centrifugal force
fueled by the problem of flanking occurs between four- and five-candidate elections.
1.1 Related work
Before diving into our theoretical analysis, we briefly summarize the literature in relevant areas.
One-shot candidate positioning games. Expanding on the two-candidate Hotelling–Downs founda-
tion, subsequent research has explored higher-dimensional spaces [55, 34], more than two candidates [16],
policy motivation [72], uncertainty about voter positions [12], and candidate valence (i.e., charisma or name
recognition)[31,10],amongmanyothervariations(seeOsborne[53],Kurella[38]forsurveys).2 Somemodels
allow a third-party candidate to enter the race after the established candidates select their positions, which
can lead to non-central two-party equilibria [54, 70, 8].
Dynamic models of candidate positioning. In addition to the work on one-shot games, there is also
a literature on candidate positioning dynamics [21], although in contrast to our work, the focus of this
literature has been on rational two-candidate contests. One notable early paper in this line of work studies
a two-party system where the party which lost the previous election is allowed to reformulate its policy to
maximizevotesinthenextelection,whichcanyieldpredictabletrajectorieseveninhigher-dimensionalpolicy
spaces [37]. As in the one-shot literature described above, extensions of this model of two-party dynamics
1Allofoursimulationcodeandresultsareavailableathttps://github.com/tomlinsonk/plurality-replicator-dynamics.
2Hotellingframedthegameintermsoftwoshopspositioningthemselvesalongaline(orthedesignoftwocompetinggoods
alongasingleaxis),whileDownsappliedtheideatopluralityelections. Thetwomotivationsyieldequivalentmodels,sosome
ofthepapersweciteusethelanguageoffacilitylocationorproductdesignratherthancandidatepositioning.
4have added a variety of features, including policy motivation [71, 13], forward-looking parties [58, 27, 49],
and—most closely related to our work—boundedly-rational candidates who are unable to exactly optimize
theirpositions[35,36,4]. Ourpaperissetapartfromthispriorresearchonelectoraldynamicswithbounded
rationalityinourreplicatordynamicsapproach,andoursuccessderivinganalyticalresultsformorethantwo
candidates. We are aware of one paper [39] combining a spatial model of elections and replicator dynamics,
but the number of parties is fixed to two and the focus is instead on competition between office- and policy-
motivated party members (“opportunists” and “militants”), where opportunists may defect to the other
party.
Evolutionary game theory and replicator dynamics. Replicator dynamics [67, 62, 32] were intro-
duced to study the evolution of biological populations, but have since found much broader use. Economists
haveusedevolutionarymodels—includingreplicatordynamics—tounderstandinvestmentbehavior[6],tech-
nologicalinnovation[61,60],andresourceharvesting[48],amongmanyotherphenomena. SeeFriedman[28]
for an introduction to evolutionary game theory from an economic perspective and Nelson et al. [47], Sa-
farzyn´ska and van den Bergh [59] for surveys of evolutionary economics. Evolutionary models can even be
justified without population-level evolution: models of individual-level learning can give rise to behavior
equivalent to replicator dynamics [9]; see Bloembergen et al. [5] for a survey of the connection between
replicator dynamics and reinforcement learning. Evolutionary models are much less common in political
science than in economics, but have been used to model the corruption of elected officials [1], coordination
by voters [43], and party defection [40]. Extensions of the classical replicator dynamics have explored the
various modifications found in our model, including multi-way interactions [29], discrete time [42], and a
continuous strategy space [52, 14].
Elections with strategic voters. Another line of research around strategic aspects of elections focuses
instead on the strategic choices made by voters rather than candidates [19, 68, 51] (with some papers
combiningbothvoterandcandidatestrategy[26,46]). Dynamicshavefeaturedprominentlyinthestrategic
votingliterature[18,11]—inparticular,undertheframeworkofiterative voting [44,41,50],wherevotersare
allowed to update their votes in successive rounds until they are satisfied. Intriguingly, this style of voter-
dynamics analysis can also produce conclusions paralleling Duverger’s Law, where two major candidates
emerge, despite using a completely different approach to ours [45]. Evolutionary dynamics have also been
applied to voter behavior to explain the paradox of voting (why do people vote when their probability of
affecting the outcome is near zero?) [64].
2 Replicator dynamics for candidate positioning
We now formally introduce our model. We consider a one-dimensional policy space represented by the
unit interval [0,1]. Candidates and voters reside at points in the interval. To model a large population of
voters, we treat the voting population as a continuum; for our theoretical analysis, we assume voters are
uniform over [0,1], but we later relax this assumption in simulation. We assume voters have 1-Euclidean
preferences [24]—that is, they vote for the closest candidate. The vote share of a candidate i is the fraction
of voters who vote for i. With uniform voters, the vote share of a candidate is equal to half the distance
between the candidates to its left and right (a candidate adjacent to a boundary gets the entire vote share
on its boundary side). Under plurality voting, the candidate with the largest vote share wins; in the case of
tied maximum vote shares, the tie is broken uniformly at random.
Our replicator dynamics model of candidate positioning supposes that elections proceed in generations
t = 1,2,..., with (infinitely) many elections per generation. We assume the number of candidates in each
election is fixed at k (later, we relax this assumption in simulation). The core idea of our model is that
candidates in generation t chose their policy positions by copying the position of a winner from the previous
generationt−1. Moreformally,letF betheinitialcandidatedistributionandletF denotethedistribution
0 k,t
ofwinnerpositionsingenerationtwithk candidatesperelection. WedefineF =F forallk,althoughwe
k,0 0
typically write F since the initial distribution does not depend on k. In generation t, each election consists
0
5of k candidates with positions X ,...,X ∼ F . We use F (x) to denote the CDF of the winner
1,t k,t k,t−1 k,t
distribution in generation t and f (x) to denote the PDF. Let Plurality(X ,...,X ) be the position of
k,t 1,t k,t
the plurality winner given candidate positions X ,...,X and uniformly distributed voters.
1,t k,t
Definition 1. Given an initial candidate distribution F and a candidate count k, the replicator dynamics
0
for candidate positioning (under plurality with uniform 1-Euclidean voters) are, for all t>0,
F (x)=Pr(Plurality(X ,...,X )≤x), (1)
k,t 1,t k,t
X ∼F , ∀i=1,...,k.
i,t k,t−1
Or, in terms of the PDF:
f (x)=k·Pr(Plurality(x,X ,...,X )=x)·f (x). (2)
k,t 2,t k,t k,t−1
This model can be viewed through the lens of evolutionary replicator dynamics [67, 62, 32], although
there are several differences from the classical case. In the classic replicator dynamics, there are n discrete
strategies, each of which increases in frequency proportionally to how well that strategy performs against
the current population. This proportionality is exactly what Equation (2) captures: strategy x increases in
density proportional to its plurality win rate against the current population.
The main question we study is how the candidate distribution evolves over time under the replicator
dynamics. We focus on cases where F is symmetric about 1/2 and contains no point masses (i.e., the
0
initial CDF F (x) is continuous); we call such distributions symmetric and atomless. This ensures that the
0
probability multiple candidates share the exact same point is 0, so we can ignore these cases for now. Since
we assume F is symmetric, all subsequent winner distributions are also symmetric by the symmetry of
0
plurality with a uniform voter distribution—we lean heavily on this fact in our analysis. Some of our results
require an additional assumptions on F . We say F is positive near 1/2 if F (x) < 1/2 for all x < 1/2
0 0 0
(equivalently, f (x) > 0 in an interval around 1/2); the symmetry of F allows us to phrase definitions like
0 0
thisintermsofthelefthalfoftheunitinterval,anditthenappliesequivalentlytotherighthalfaswell. We
define F to be the set of all symmetric and atomless distributions over [0,1] and F+ ⊂ F to be the subset
of such distributions which are also positive near 1/2.
In this section, we prove our main result piece-by-piece.
Theorem 1. Let F ∈ F+. For k ∈ {2,3,4}, the candidate distribution converges to a point mass at 1/2
0
under the replicator dynamics. In contrast, for k ≥5, the candidate distribution does not converge to a point
mass at 1/2.
Theorem 1 follows from Theorems 2 to 5. Our results for k ∈{2,3,4} give fine-grained characterizations
of the dynamics, which imply convergence to the center: for k =2, we derive a closed form for the CDF at
generation t (Theorem 2), while for k = 3 and 4 we derive closed-form bounds for the CDF (Theorems 3
and 4). The negative portion of Theorem 1 offers less insight into the dynamics for k ≥ 5, only showing
non-convergence to the center (Theorem 5), but in Section 4 we prove a stronger result in the special case
where F has no extreme candidates. All proofs omitted from this section for the sake of readability can be
0
found in Appendix B.1.
2.1 k = 2
Two-candidatepluralitywithsymmetricvotersissimple: whichevercandidateiscloserto1/2hasthelarger
vote share and wins. This simplicity allows us to fully characterize the dynamics with k =2. In particular,
we derive a closed form for the CDF F (x).
2,t
Theorem 2. Let F ∈F. For all x<1/2 and t≥0, F (x)=[2·F
(x)]2t
/2.
0 2,t 0
Proof. Let x < 1/2. Since the candidate closer to 1/2 wins with k = 2, Plurality(X ,X ) ∈/ (x,1−x) if
1,t 2,t
and only if both X ∈/ (x,1−x) and X ∈/ (x,1−x), which occurs with probability (2·F (x))2. By
1,t 2,t 2,t−1
6symmetry, wethenhaveF (x)=Pr(Plurality(X ,X )≤x)=(2·F (x))2/2=2·F (x)2. Wecan
2,t 1,t 2,t 2,t−1 2,t−1
now prove the claim by induction on t. For the base case t = 0, (2·F (x))20/2 = F (x). For the inductive
0 0
case t≥1, applying the inductive hypothesis yields:
F (x)=2·F (x)2
=2(cid:104)
(2·F (x))2t−1
/2(cid:105)2
=[2·F (x)]2t /2.
2,t 2,t−1 0 0
This result shows that for k = 2, the CDF at any point x < 1/2 with F (x) < 1/2 rapidly goes to
2,0
0—that is (apart from degenerate initial distributions) the candidate distribution converges toward a point
mass at 1/2.
Corollary 1. Let F ∈F+. For all x<1/2, lim F (x)=0.
0 t→∞ 2,t
Note that by symmetry, it follows from such a statement that for all x>1/2, lim F (x)=1.
t→∞ 2,t
2.2 k = 3
Fork =3,pluralitybecomesmorecomplex: thewinnerneednotbetheclosestto1/2(forinstance,consider
candidatesatpositionedat1/3,1/2,and2/3). Nonetheless,wecanstillshowthatthecandidatedistribution
converges to the center. To do so, we find an upper bound on F (x) which goes to 0. The idea behind the
3,t
proofistoenumeratecaseswhereacandidateinaninnerinterval(x,1−x)winsandadduptheprobability
of these cases, as a function of F (x). For example, if there are two candidates in [0,x) and one in
k,t−1
(1/2,1−x), then the candidate in (1/2,1−x) gets vote share greater than 1/2 and wins; this case occurs
with probability (cid:0)3(cid:1) F (x)2 ·(1/2−F (x)). By symmetry, we can then transform this lower bound
2 3,t−1 3,t−1
on the probability the winner is inside (x,1−x) into an upper bound on F (x), the probability that the
3,t
winner is in [0,x].
Theorem 3. Let F ∈F. For all x<1/2 and t>0,
0
F (x)≤3/4·F (x)+F (x)3. (3)
3,t 3,t−1 3,t−1
This can be written as a looser closed form
F (x)≤F
(x)·(cid:2)
3/4+F
(x)2(cid:3)t
. (4)
3,t 0 0
This result reveals that the candidate distribution for k = 3 also converges rapidly to the center. In
particular, (4) shows that the CDF at any point x with F (x) < 1/2 decays exponentially towards 0 in t.
0
Thiscanalsobeseenbyanalyzingthecubiciteratedmapsuggestedbytheupperbound(3),whichconverges
to a stable fixed point at 0 for all initial values in [0,1/2).
Corollary 2. Let F ∈F+. For all x<1/2, lim F (x)=0.
0 t→∞ 3,t
2.3 k = 4
As with k = 3, we derive an upper bound on the CDF which converges to 0. However, the bound suggests
convergence is much slower for k =4 than for 2 or 3 (which we will see later confirmed in simulation). The
proof follows the same case-enumeration strategy as k = 3, but simple cases only show that the CDF is
non-increasing in t for x∈(1/3,1/2), giving us the following lemma.
Lemma 1. Let F ∈F. For all x∈(1/3,1/2) and t≥0, F (x)≤F (x).
0 4,t 4,0
ByusingLemma1, wecanstrengthenthecaseanalysiswithoneadditionalcasethattipstherecurrence
frombreakingeventoshrinkingexponentiallytowards0. However,thebaseoftheexponentialdependsvery
strongly on x, increasing rapidly towards 1 near 1/2.
7Theorem 4. Let F ∈F. For all x∈(1/3,1/2) and t≥0,
0
F (x)≤F
(x)·(cid:2)
1−4(1/2−F
(x/3+1/3))3(cid:3)t
. (5)
4,t 0 0
Note that x/3+1/3 is the point two-thirds of the way from x to 1/2. As long as F (x/3+1/3) < 1/2,
0
which is true for any x<1/2 if F is positive near 1/2, this result shows that the CDF left of 1/2 decays to
0
0 as t grows. That is, the candidate distribution converges to the center again.
Corollary 3. Let F ∈F+. For all x<1/2, lim F (x)=0.
0 t→∞ 4,t
2.4 k ≥ 5
In contrast to k = 2,3,4, we now show that for any larger k, the candidate distribution does not converge
to the center. The proof is based on the following observation.
Lemma 2. For any k, if all candidates are in (1/4,3/4), then only the left- or rightmost candidate can win
with uniform voters.
Proof. Suppose all candidates are in (1/4,3/4). Any candidate between two others gets vote share less than
(1/2)/2=1/4,sincenotwocandidatesaredistance1/2orgreaterapart. Meanwhile,theleft-andrightmost
candidates each get vote share >1/4.
Intuitively, if the candidate distribution starts converging to the center, then all candidates will likely be
inside(1/4,3/4),atwhichpointonlythemostextremecandidatescanwin. Whenk issufficientlylarge(i.e.,
≥ 5), the left- and rightmost candidates are likely on opposite sides and farther from 1/2 than the average
candidate. This results in a centrifugal force preventing further progress towards the center. Formally, we
prove the following theorem.
Theorem 5. Let F ∈F. For any k ≥5, there exists some x<1/2 such that lim F (x)̸=0. That is,
0 t→∞ k,t
the candidate distribution does not converge to a point mass at 1/2.
Morespecifically,ourproofassumesforacontradictionthatthedistributionconvergesto1/2,soatsome
generation t∗, the probability mass left of 1/4 must be less than some small α. We then show that the
CDFcanneverdecreaseatF−1(1/4)aftergenerationt∗, sinceallcandidateswilllikelybeinside(1/4,3/4),
k,t∗
causing only the most extreme candidates to win. This contradicts convergence to the center.
3 Replicator dynamics with noise
So far, we have assumed that all candidates copy winner positions from the previous generation. We now
show that our results still hold in approximate forms if some of the candidates violate this behavior and
instead position themselves uniformly at random. This demonstrates a way in which the convergence of the
model is robust to alternative specifications.
Definition2. GivenaninitialcandidatedistributionF ,acandidatecountk,andanoiselevelϵ∈(0,1],the
0
replicatordynamicsforcandidatepositioningwithϵ-uniformnoise (underpluralitywithuniform1-Euclidean
voters) are, for all t>0,
Fϵ (x)=Pr(Plurality(Xϵ ,...,Xϵ )≤x), (6)
k,t 1,t k,t
Fϵ =F
k,0 0
(cid:40)
Uniform(0,1) w.p. ϵ,
Xϵ ∼
i,t Fϵ w.p. 1−ϵ.
k,t−1
8As in the noiseless case, we show that the candidate distribution converges to the center under the
dynamicswithϵ-uniformnoisefork =2,3,4butdonotfork ≥5. However,sinceϵ-uniformnoiseintroduces
non-centralcandidatesateveryt,weneedtorelaxtheconvergencerequirement. Theideabehindournotion
of approximate convergence is that if we make the noise sufficiently small, then the distribution should get
arbitrarily close to a point mass at 1/2. That is, the CDF at any point x < 1/2 eventually goes below any
positive threshold c, for sufficiently small ϵ>0.
Definition 3. Let F ∈ F. The candidate distribution approximately converges to the center under the
0
replicator dynamics with ϵ-uniform noise if for all x ∈ [0,1/2) and c > 0, there exists some ϵ > 0 such
max
that if ϵ∈(0,ϵ ], then limsup Fϵ (x)<c.
max t→∞ k,t
Wenowgivetheanalogueofourmainresultwithϵ-uniformnoise. Oneadditionalbenefitofaddingnoise
is that we no longer need to assume F is positive near 1/2.
0
Theorem 6. Let F ∈F. For k ∈{2,3,4}, the candidate distribution approximately converges to the center
0
under replicator dynamics with ϵ-uniform noise. In contrast, for all k ≥ 5, the candidate distribution does
not approximately converge to the center.
Theorem 6 follows from Theorems 7 to 10. See Appendix B.2 for proofs omitted from this section.
3.1 k = 2
We first show that the replicator dynamics with ϵ-uniform noise approximately converge to the center with
two candidates. In fact, we can exactly characterize the limiting candidate distribution for k =2. As before
withk =2,whichevercandidateiscloserto1/2wins,butnowthesecandidatescaneitherbewinner-copiers
or randomly positioned. The idea behind the proof is to find an iterated map for Fϵ (x) and find the stable
2,t
fixed point it converges to for x<1/2, which we show is smaller than ϵ.
Theorem 7. Let F ∈F. For any ϵ∈(0,1) and x∈[0,1/2) with ϵ-uniform noise,
0
(cid:112)
1−4xϵ(1−ϵ)− 1−8ϵx(1−ϵ)
lim Fϵ (x)= ≤ϵ. (7)
t→∞ 2,t 4(1−ϵ)2
Proof. Let x<1/2 and p=Fϵ (x). Each candidate in generation t is drawn from Fϵ w.p. (1−ϵ) and
2,t−1 2,t−1
from Uniform(0,1) w.p. ϵ (call such candidates uniform). Uniform candidates fall outside (x,1−x) w.p. 2x,
while non-uniform candidates fall outside (x,1−x) w.p. 2p by symmetry. A winner in generation t is not in
(x,1−x) if and only if both candidates fall outside this interval, which thus occurs with probability
Pr(Xϵ ∈/ (x,1−x),Xϵ ∈/ (x,1−x))=(1−ϵ)2(2p)2+2ϵ(1−ϵ)(2x)(2p)+ ϵ2(2x)2
1,t 2,t
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
neitheruniform oneuniform bothuniform
=4p2(1−ϵ)2+8pxϵ(1−ϵ)+4x2ϵ2.
By symmetry, we then have
Fϵ (x)=Pr(Xϵ ∈/ (x,1−x),Xϵ ∈/ (x,1−x))/2
2,t 1,t 2,t
=2p2(1−ϵ)2+4pxϵ(1−ϵ)+2x2ϵ2. (8)
The claim then follows from the following technical lemma, proved in Appendix B.2.
Lemma 3. For all initial p ∈ [0,1/2], ϵ ∈ (0,1), and x ∈ [0,1/2), the quadratic iterated map p′ = 2p2(1−
√
ϵ)2+4pxϵ(1−ϵ)+2x2ϵ2 converges to the fixed point p∗ = 1−4xϵ(1−ϵ)− 1−8ϵx(1−ϵ) ≤ϵ.
4(1−ϵ)2
This result implies approximate convergence to the center: we can simply take ϵ < c and we then
max
have lim Fϵ (x)≤ϵ <c.
t→∞ 2,t max
Corollary 4. Let F ∈ F. For k = 2, the candidate distribution approximately converges to the center
0
under replicator dynamics with ϵ-uniform noise.
93.2 k = 3
We now show approximate convergence to the center for k = 3 with ϵ-uniform noise. As in the noiseless
case, we cannot fully characterize the limiting distribution, but we are able to bound it for ϵ < 1/3. The
proof repeats the case analysis from the proof of Theorem 3 but with ϵ-uniform candidates, which yields a
cubic iterated map. We then bound the attracting fixed point of this map, as we did for k =2.
Theorem 8. Let F ∈F. For any ϵ∈(0,1/3) and x∈[0,1/2), limsup Fϵ (x)≤1.5ϵ.
0 t→∞ 3,t
As with k = 2, this shows that for any c > 0, we can pick a small enough ϵ (i.e., ϵ < min{1/3,2/3·c})
so that limsup Fϵ (x)<c.
t→∞ 3,t
Corollary 5. Let F ∈ F. For k = 3, the candidate distribution approximately converges to the center
0
under replicator dynamics with ϵ-uniform noise.
3.3 k = 4
As with two and three candidates, we can also show approximate convergence to the center for replicator
dynamics with ϵ-uniform noise and four candidates. However, for k = 4, the bound on ϵ required for
convergencedependsonthepoint’sdistancefrom1/2—justastheconvergenceratedidinthenoiselesscase.
We begin with the noisy analogue of Lemma 1.
Lemma 4. Let F ∈F. With ϵ-uniform noise, for any ϵ∈(0,1], x∈(1/3,1/2), and t>0,
0
Fϵ (x)≤ϵx+(1−ϵ)Fϵ (x).
4,t 4,t−1
Thus, Fϵ (x)≤max{x,Fϵ (x)}.
4,t 4,0
We can then apply the same strategy as we did in the noiseless case and analyze the resulting iterated
map as we have done for k =2 and 3.
Theorem9. LetF ∈F. Foranyϵ∈(0,1]andx∈(1/3,1/2),letβ =1/2−ϵ(x/3+1/3)−(1−ϵ)max{x/3+
0
1/3,F (x/3+1/3)}. Then β ∈(0,1/2] and limsup Fϵ (x)≤ 1 ϵ.
0 t→∞ 4,t 8β3
As long as we make ϵ sufficiently small (relative to 8β3), the CDF at x<1/2 eventually goes below any
desired threshold c—although the closer x is to 1/2, the smaller β becomes, and likewise the required ϵ.
Corollary 6. Let F ∈ F. For k = 4, the candidate distribution approximately converges to the center
0
under replicator dynamics with ϵ-uniform noise.
3.4 k ≥ 5
Now that we have seen approximate convergence to the center for k = 2,3,4, we prove that this does not
happen for any higher k. The argument uses the same idea as in Theorem 5 (k ≥ 5 without noise): that
when all candidates are in (1/4,3/4), only the left- and rightmost candidates can win. As long as we make
ϵ sufficiently small, the exact same approach applies, albeit with some added care to account for randomly
positioned candidates.
Theorem 10. Let F ∈ F. For k ≥ 5, the candidate distribution does not approximately converge to the
0
center under replicator dynamics with ϵ-uniform noise.
4 Positive results for k ≥ 5 with no extreme candidates
Intheprevioussections,ourresultsfork ≥5havebeennegative,showingthecandidatedistributiondoesnot
convergetothecenter,butwithoutindicatingwhatthedistributionconvergestoinstead. Whilesimulations
10Table 1: Base of the exponential from Theorem 12 for small k.
k 2 3 4 5 6
k(1/2)k−2 2 3/2 1 5/8 3/8
indicate a tendency towards a two-spike equilibrium, we have not been able to theoretically characterize the
limiting distribution in general for k ≥ 5, either with or without noise. However, Lemma 2 enables us to
analyze the dynamics for k ≥5 (without noise) in the special case that F has no extreme candidates, with
0
support only on (1/4,3/4). In this setting, the dynamics are much simpler, as only the left- and rightmost
candidates can win. The same type of argument we used before for k ≥ 5 then provides a positive result,
showing that the candidate distribution converges to one with zero mass in an interval around 1/2. In
contrast, our central convergence results for k ∈ {2,3,4} still hold in this special case. Proofs of results in
this section can be found in Appendix B.3.
(cid:112)
Theorem 11. Suppose F ∈F is supported on (1/4,3/4). Let ℓ=[1− 3/7]/2=0.172.... For k ≥5 and
0
x∈(F−1(ℓ),1/2), lim F (x)=1/2.
0 t→∞ k,t
When F is Uniform(1/4,3/4), note that F−1(0.172...) = 0.336..., so Theorem 11 implies that as
0 0
t → ∞, the candidate density in [0.34,0.66] goes to 0 for k ≥ 5. With no extreme candidates, we can also
precisely characterize the density of the candidate distribution at 1/2 using a simple argument. Since only
the left- or rightmost candidates can win, a candidate i at 1/2 only wins if the other candidates are all on
the left or on the right. By symmetry, this occurs with probability 2·(1/2)k−1 = (1/2)k−2. Accounting
for the k-fold symmetry in choosing candidate i and applying an inductive argument based on Equation (2)
then gives the following result.
Theorem 12. Suppose F ∈F is supported on (1/4,3/4). For any k ≥2 and t≥0,
0
f (1/2)=f
(1/2)·(cid:2) k(1/2)k−2(cid:3)t
. (9)
k,t 0
With support on (1/4,3/4), the behavior of the density at 1/2 therefore depends on whether k(1/2)k−2
is smaller or larger than 1. This quantity is smaller than 1 for k ≥ 5, larger than 1 for k = 2,3 and equal
to 1 for k = 4 (see Table 1). The larger k is, the more rapidly the density at 1/2 goes to 0. This simple
argument reveals a mechanism driving the k < 5 vs k ≥ 5 divide: (1/2)k−2 is exactly the probability that
a central candidate is not flanked. This probability decreases rapidly with k and is counterbalanced at first
by the increasing number of candidates k who can be at the center—by as soon as k ≥5, the exponentially
low probability of being the left- or rightmost candidate at the center becomes too small.
Theorem 12 is particularly interesting for k = 4, since we know the distribution converges to a point
mass at 1/2, but the density at 1/2 stays constant at f (1/2) when F is supported on (1/4,3/4). These
0 0
seemingly contradictory facts are both possible since the distribution converges by accumulating more and
more mass in two spikes on each side of 1/2 that approach the center arbitrarily closely. Theorem 12 thus
highlights how k =4 is a marginal tipping point which just barely converges to the center—a phenomenon
also hinted at by the marginal nature of our k = 4 case analysis in Lemma 1 and Theorem 4: the analysis
in Lemma 1 just breaks even, with the low-probability case in Theorem 4 needed to tip the scales. As we
saw in Figure 2, this manifests in simulation as slow convergence to the center for k =4.
5 Simulations
Having established our primary theoretical results, we demonstrate them in simulation.3 To do so, we use
MonteCarlosampling,simulatingalargenumberofelectionspergeneration(100,000)andusingthewinners
toapproximateF . WeinitializeF tobeuniform. Withthisbasicsetup,weobservesomeeffectsduepurely
k,t 0
3Allofoursimulationcodeandresultsareavailableathttps://github.com/tomlinsonk/plurality-replicator-dynamics.
11k=2 k=3 k=4 k=5 k=6 k=7
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
Figure 3: Replicator dynamics runs with 0.01-uniform noise for k = 2,...,7 and 200 generations, using
enhanced symmetry, 50 trials per plot, and 100,000 elections per generation. The behavior is qualitatively
identical to the model without noise (Figure 2).
k=8 k=9 k=10 k=15 k=25 k=50
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
k=8 k=9 k=10 k=15 k=25 k=50
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
Figure4: Replicatordynamicsrunswithnonoise(toprow)and0.01-uniformnoise(bottomrow)forlarger
candidate counts k and using enhanced symmetry. Other settings are identical to Figure 3, with 50 runs
shown in each plot. As the theory predicts, the candidate distribution does not converge to the center; but
the exact behavior varies.
to sampling, such as oscillations due to small asymmetries in the Monte Carlo samples. In contrast, our
theoretical model revolves around an evolving density which by definition is always symmetric. To preserve
symmetry while maintaining the same evolving distribution, we configure our Monte Carlo sampling to use
a trick we term enhanced symmetry, mirroring each copied position across 1/2 with probability 1/2 in every
generation.
Figure3shows50aggregatedsimulationrunsfork =2,...,7usingenhancedsymmetryand0.01-uniform
noise (recall Figure 2 for equivalent plots without noise). See Appendix A for additional plots without
enhanced symmetry and showing a single trial—these results follow the same general patterns across values
of k. The candidate distributions evolve exactly as we would expect from our theory: rapid convergence to
the center for k = 2 and 3, slow convergence for k = 4, and non-convergence to the center for k ≥ 5; both
with and without ϵ-uniform noise. Interestingly, k = 5,6, and 7 show a tendency to converge towards two
pointmassesat1/4and3/4—butthisphenomenonissensitivetosamplingasymmetriesfork =6and7(see
Figures 8 and 10 in Appendix A). In Section 4, we will see some theoretical justification for this two-spike
behavior in a special case when F has no extreme candidates. In Figure 4, we also show simulations with
0
largercandidatecounts,from8to50. InlinewithTheorem5,thedistributionswithlargek donotconverge
to the center. However, we see some surprising differences depending on k; for instance, the asymptotic
distribution with k = 8 appears to have four clusters rather than two (mysteriously, all other large values
of k we have tested tend towards two clusters, at least with enhanced symmetry). In Appendix A, we
provide several additional visualizations: Figure 11 shows simulations with only 50 elections per generation,
12k=2 k=3 k=4
0.5 0.5 0.5
00 .. 34 xx == 0.40 0.47 s Ti hm mu l 2a .t 3io (n exact) 00 .. 34 xx == 0.0 40.47 s Ti hm mu l 2a .t 5io (n bound) 00 .. 34 xx == 00 .. 44 07
simulation
Thm 2.8 (bound)
0.2 0.2 0.2
0.1 x =0.10 0.1 x=0.10 0.1 x=0.10
0.0 0.0 0.0
0 2 4 6 8 0 5 10 15 20 0 10 20 30 40
t t t
Figure5: SimulationsdemonstratingourconvergenceresultsTheorems2to4, showingthesimulatedcandi-
datedistributionCDFatvariouspointsxalongsidethetheoreticalpredictions. Thesimulationsuse50trials
with 100,000 elections per generation, no noise, and enhanced symmetry. The theorems get progressively
weaker: Theorem 2 provides an exact characterization of the two-candidate dynamics, while Theorems 3
and 4 give upper bounds that converge to 0.
k=2 k=3 k=4
Thm 3.4 (exact) 100
10−1 simulation 10−1
x=0.4,ε=0.33
x=0.45,ε=10−5
x=0.4,ε=0.33 10−2 x=0.2,ε=0.33 10−2 x = x=0.38,ε=10−5 10−2
x=0.2,ε=0.33 Thm 3.7 (bound)
0.34,
10−3 x=0.2,ε=0.1
10−3 simulation 10−4 ε =
10−3
x=0.38,ε=10−3
x=0.1,ε=0.1
10−4 xx == 00 .. 12 ,, εε == 00 .. 11 10−6 T sih mm
u
l3 a. t1 io0
n
(bound)
0 5 10 15 0 10 20 30 0 20 40 60
t t t
Figure 6: Simulations demonstrating Theorems 7 to 9, showing the simulated candidate distribution CDF
at various points x and various noise levels ϵ alongside the theoretical asymptotic bounds. The simulations
use 50 trials with 100,000 elections per generation and enhanced symmetry. As in the noiseless case, the
theorems get progressively weaker as k increases. For k =3, the asymptotic bounds depend only on ϵ, while
the bounds for k =4 and the exact limit for k =2 depend on both ϵ and x.
demonstrating that our findings still hold in a small-sample setting; Figure 12 shows large-k simulations
withoutenhancedsymmetry;finally,Figure13demonstratestheno-extremessettingofTheorem11,starting
from Uniform(1/4,3/4).
In addition to confirming the picture painted by our theory, we also use simulations to explore how
tight our bounds are—although our core focus is on characterizing the qualitative behavior of the model
rather than achieving the tighest bounds on convergence rate. In Figure 5, we demonstrate the exact result
from Theorem 2 and the closed-form upper bounds on the candidate distribution CDF from Theorems 3
and 4. The bounds on convergence rates for k = 3 and 4 are indeed loose, as there are several ways that
central candidates can win that are not easily captured by our case analysis. In Figure 6, we demonstrate
Theorems 7 to 9. Note that these results are all asymptotic, characterizing or bounding the limit of the
candidate distribution CDF as t → ∞, whereas the results in Figure 5 hold for finite t. Additionally, the
results with ϵ-uniform noise depend on the value of ϵ, so we experiment with several different values. Again,
weseethatourboundsfromTheorems8and9areloose,butnonethelessholdandarenon-trivial. Moreover,
the exact result in Theorem 7 is nicely confirmed by simulation.
13
)x(t,kF
)x(
t,ε
kF6 Variants of the replicator dynamics
We now demonstrate in simulation that the qualitative picture provided by our results from Theorem 1 is
robusttodifferentspecificationsofthemodel. Atahighlevel,ourmodelofcandidatepositioningconsistsof
the following components: (1) a fixed voter distribution, (2) a subset of previous candidate positions which
new candidates imitate, and (3) a rule for sampling from those previous positions. In the basic model, the
voter distribution is uniform, the imitated positions are plurality winners from the previous generation, and
the sampling rule chooses uniformly from those winners. Adding ϵ-uniform noise modifies the sampling rule
to sometimes pick uniformly random positions. In simulation, we explore natural variations of each of these
modeling components: changing the voter distribution, adding plurality winners from earlier generations
or runners-up to the imitation pool, and adding copying errors to the sampling rule or sampling different
numbersofcandidatesacrosselections. SeeAppendixCforformaldefinitionsofthevariantsinthissection.
Non-uniform voters. We explore our replicator dynamics with symmetric unimodal and bimodal voter
distributions. In Figure 7, we show results with three voter distributions: the unimodal distribution
Beta(2,2), the bimodal, extreme voter distribution Beta(0.5,0.5), and a bimodal double Weibull distri-
bution[2]withshape4, location0.5, andscale0.3(seeFigure14inAppendixA.1forvisualizationsofthese
distributions). ThebasicpatternfromTheorem1continuestoholdwiththesevoterdistributions. However,
when voters are Beta(2,2)-distributed, the two clusters at k =5 are significantly closer to the center.
Memory. In the basic model, candidates only copy the positions of winners in the previous generation.
However, real-world candidates will likely have memory of earlier winners, so in this variant, we allow
candidatestosamplefromwinnerpositionsinanyofthelastmgenerations. InFigure7,weseethatadding
m = 2 generations of memory for candidates still maintains the pattern from Theorem 1. The results for
m=3 are extremely similar (see Figure 15 in Appendix A).
Perturbation noise. With perturbation noise, each candidate slightly deviates from the position they
copy,asiftheirimitationisimperfect. Inoursimulations,weaddGaussiannoisewithmean0andvarianceσ2
toeachcopiedposition. Figure7showsthatthecandidatedistributionwithasmallamountofperturbation
noise (σ2 = 0.005) converges to the center for k = 2,3,4 but does not for k ≥ 5. However, with sufficient
noise, higher values of k form a single central cluster; we see this in Figure 7 with k = 6 and σ2 = 0.01.
Additionally, for k ≥ 6 the behavior varies significantly across runs without enhanced symmetry. We even
observe phenomena such as party movement, divergence, and extinction, particularly for higher values of k
(see Figure 16 in Appendix A).
Variable candidate counts. In real-world elections, we might expect different numbers of candidates to
run in different elections, but our model keeps the candidate count k constant. In this variant, we allow
elections in each generation to have a mixture of several candidate counts, where candidates copy from
winner positions across all k in the previous generation. We find that our results interpolate smoothly to
this setting: when most elections have fewer than five candidates, we see convergence to the center, but not
when most elections have k ≥ 5 (see Figure 7, where we simulate an equal mixture of the listed candidate
countsineachgeneration,with50,000electionsperk). SeeFigure17inAppendixAforamorefine-grained
experiment in which we smoothly vary the proportions of elections with k =3,4,5.
Top-h copying. Finally, we explore a variant where candidates in generation t choose a position to copy
from the pool of candidates with the top-h highest vote shares in generation t−1, rather than only winners
(i.e., h=1). In simulation, top-h copying is the only variant which strays from the dichotomy we establish
in Theorem 1—perhaps unsurprisingly, given that our result is about copying winners. For k = 3,4, when
h=2 the candidate distribution does not converge to the center and instead ends up as k =5 usually does,
with two clusters (see Figure 7, bottom right). For h = 3, the candidate distribution does not even appear
to converge towards point masses (see Figure 18 in Appendix A.1). These simulations suggest that our
14k=3 k=4 k=5 k=6 k=3 k=4 k=5 k=6
1 1
0.5 0.5
0 0
0 100 2000 100 2000 100 2000 100 200 0 100 2000 100 2000 100 2000 100 200
t t t t t t t t
k=3 k=4 k=5 k=6 k=3 k=4 k=5 k=6
1 1
0.5 0.5
0 0
0 100 2000 100 2000 100 2000 100 200 0 100 2000 100 2000 100 2000 100 200
t t t t t t t t
k=3 k=4 k=5 k=6 k=(2,3,4) k=(3,4,5) k=(4,5,6) k=(5,6,7)
1 1
0.5 0.5
0 0
0 100 2000 100 2000 100 2000 100 200 0 100 2000 100 2000 100 2000 100 200
t t t t t t t t
k=3 k=4 k=5 k=6 k=3 k=4 k=5 k=6
1 1
0.5 0.5
0 0
0 100 2000 100 2000 100 2000 100 200 0 100 2000 100 2000 100 2000 100 200
t t t t t t t t
Figure 7: Variants of the replicator dynamics. Each plot shows 50 trials with no enhanced symmetry. Left
column, top to bottom: three different voter distributions and 2 generations of memory. Right column,
top to bottom: perturbation noise with σ2 =0.005 and 0.01, variable candidate counts, and top-2 copying.
Except for top-2 copying, all of the variants converge to the center for k <5. Additionally, sufficiently high
perturbation noise can cause a central cluster to form for high k.
central finding (convergence to the center for k <5) is a result of copying the positions of plurality winners
specifically, and the dynamics under this heuristic.
7 Relationship to Nash equilibria of one-shot games
Wenowtakeastepbackandexaminetherelationshipbetweenourdynamicsandpriorresearchonstrategic
positioning. Aswediscussed, muchoftheliteratureoncandidatepositioninghasfocusedonone-shotgames
rather than dynamics [53, 8, 38], as in the Hotelling–Downs model. In our 1-Euclidean setting with uniform
voters, the Hotelling–Downs equilibrium has both candidates positioned at 1/2—which as we showed, is
also the attracting distribution of the replicator dynamics with k = 2. Indeed, it is well-known that Nash
equilibria of one-shot games are fixed points of the corresponding replicator dynamics [32], but replicator
15
sretov
)2
,2(ateB
sretov
)5.0
,5.0(ateB
sretov
)3.
,5.
,4(llubieWd
2=m
,yromeM
500.0=2σ
,esion
.brutreP
10.0=2σ
,esion
.brutreP
sk
elpitluM
gniypoc
2-poTdynamics fixed points may not be Nash equilibria. We can see this intuitively in our setting by noting that
a distribution F is a (symmetric, mixed-strategy) Nash equilibrium if no strategy does better against F
than sampling from F, while F is a fixed point of the replicator dynamics if no strategy drawn from F does
better against F than sampling from F. For F with full support, symmetric mixed-strategy Nash equilibria
and replicator dynamics fixed points thus coincide [3]. However, Nash equilibria can be unstable under the
dynamics—and even if they are attractors, their basins of attraction may be negligible.
Before analyzing Nash equilibria, we first need a brief digression to address what happens when multiple
candidatesoccupythesamepoint—wecallthesepositionalties. Sincewehavesofarassumedthatcandidate
distributions are atomless, our analyses of the replicator dynamics has avoided this issue: with an atomless
candidate distribution, positional ties occur with probability 0. One option for handling positional ties is to
supposethatcandidatesfailtopositionthemselvesexactly atthesamepointandimaginethatthereissome
infinitesimal jitter in their positions which determines a left–right order. Alternatively, we could suppose
that candidates are in fact precisely at the same point, forcing voters to make an arbitrary choice between
them.
Definition 4. Suppose multiple candidates occupy the same point. Under left–right tie-breaking, one of
these candidates (chosen u.a.r.) receives the entire left vote share allocated to that point, while a different
candidate (also u.a.r.) receives the entire right vote share. Under equal split tie-breaking, all candidates at
a point share the vote share allocated to that point equally. Equivalently, voters randomly choose between
equidistant candidates.
Armed with these positional tie-breaking rules, we now provide several results that demonstrate how a
static analysis of Nash equilibria yields more fragile conclusions than analyzing the asymptotic behavior of
the replicator dynamics. We focus on two types of equilibria: (1) symmetric mixed-strategy Nash equilibria
(SMSNEs),sincetheserelatetofixedpointsofthereplicatordynamics;and(2)pure-strategyNashequilibria
(PSNEs), since these are the focus of classical candidate positioning analyses.
We begin by showing there are multiple SMSNEs in the one-shot candidate positioning game, but they
are often unstable or have tiny basins of attraction under the dynamics; that is, they are unlikely to be
relevant in practice. In contrast, as we have seen in theory and simulation, the replicator dynamics behave
in qualitatively similar ways under a range of specifications. Then, we show that PSNEs are very sensitive
to the choice of positional tie-breaking rule: we arrive at entirely different conclusions if we adopt left–right
versus equal split tie-breaking. In contrast, the positional tie-breaking rule is irrelevant to our analysis with
atomless candidate distributions.
7.1 Symmetric mixed-strategy Nash equilibria
Since SMSNEs are a subset of the replicator dynamics fixed points, we might hope to understand the dy-
namicsbyanalyzingSMSNEsofthegamewherecandidatesseektomaximizetheirpluralitywinprobability.
However,wefindthattherearemultipleSMSNEsandtheycanhavetrivialbasinsofattraction. Forinstance,
every candidate at 1/2 is a SMSNE and a replicator dynamics fixed point (with left–right tie-breaking4).
Butaswehaveseen,fork ≥5allsymmetricatomlessinitialdistributionsdonotconvergetoapointmassat
1/2. Ontheotherhand,ifweallowinitialdistributionswithpointmassesandthemassat1/2issufficiently
high, the candidate distribution does indeed approach the all-at-1/2 SMSNE.
Theorem 13. Suppose F places probability mass p at 1/2. For any k ≥2, there is some p∗ <1 such that
0 k
if p > p∗, the candidate distribution converges to a point mass at 1/2 under the replicator dynamics with
k
left–right tie-breaking. One of the fixed points of pk+kpk−1(1−p) is such a p∗.
k
See Appendix B.4 for proofs omitted from this section. Additionally, there is another family of SMSNEs
where each candidate randomly picks between the points x and 1−x (for x∈(1/4,1/2)).
4Inthissubsection,weadoptleft–righttie-breakingsinceityieldsequilibriathatmorecloselyalignwiththetypicalbehavior
of the replicator dynamics. For instance, we will see in Section 7.2 that with equal split tie-breaking, all candidates at 1/2 is
onlyaSMSNEfork=2—notk=3or4,whereweknowthecandidatedistributionalsoconvergestothecenter.
16Theorem 14. With k ≥ 4 and left–right tie-breaking, for any x ∈ (1/4,1/2), the strategy where each
candidate picks uniformly at random between x and 1−x is a SMSNE.
Just as with the all-at-1/2 equilibrium, this SMSNE is not indicative of the typical behavior of the
replicator dynamics. However, we can show as before that for non-atomless distributions, the candidate
distribution can converge to this type of equilibrium.
Theorem15. SupposeF placesprobabilitymasspatxandat1−x,for1/4<x<1/2. Foranyk ≥5,there
0
exists some p∗ <1/2 such that if p>p∗, the candidate distribution converges to point masses at x and 1−x
k k
underthereplicatordynamics. Inparticular, oneofthefixedpointsof(2p)k/2+k(1−2p)((2p)k−1−2pk−1)/2
is such a p∗.
k
TheseresultsdemonstratetheexistenceofmanySMSNEsthatalonedonottellushowweshouldexpect
the replicator dynamics to behave.
7.2 Positional tie-breaking and pure-strategy Nash equilibria
Wenowdemonstratehowignoringdynamicsandfocusingonstaticequilibriacanyieldresultsverysensitive
to tie-breaking rules. Cox [16] extends the Hotelling–Downs analysis to more than two candidates, char-
acterizing PSNEs of a one-shot candidate positioning game—crucially, with equal split tie-breaking. With
uniform voters and k ≥3 candidates, Cox proves that there is no PSNE for odd k and that the only PSNE
for even k has evenly-spaced pairs of candidates at 1/k,3/k,...,(k−1)/k. Clearly, this analysis makes very
different predictions than our replicator dynamics. However, we show that Cox’s results depend strongly on
equal split tie-breaking.
TostateCox’sresultformally,weneedtofullyspecifythecandidateobjective. Wefocusontheobjective
Coxcallscomplete plurality maximization,wherecandidatesseekfirsttomaximizetheirvotemarginagainst
theirstrongestcompetitor,thensecond-strongest,etc. Weextendthisobjectivetoallowstochasticpositional
tie-breaking, assuming candidates first maximize their win probability, then each of their expected vote
margins. We can then state Cox’s result.
Theorem 16 (Special case of Theorem 2 from Cox [16]). With uniform voters, k ≥ 3 complete plurality
maximizing candidates, and equal split tie-breaking,
1. if k is odd, there is no PSNE,
2. if k is even, then the unique PSNE has two candidates at each of the points 1/k,3/k,...,(k−1)/k.
Ifweinsteaduseleft–righttie-breaking,thepictureisdramaticallydifferent. Inparticular,allcandidates
at1/2isthenaPSNEfor all k: anydeviantwhomovesfrom1/2loseswithcertaintytothecentercandidate
who captures the opposite side of the vote. Left–right tie-breaking also introduces many additional PSNEs;
we list some of them in the following theorem.
Theorem 17. The following are (some5 of the) PSNEs with uniform voters, complete plurality maximizing
candidates, and left–right tie-breaking:
1. Any k ≥2: all k candidates at 1/2.
2. Any k ≥ 4: for any x ∈ (1/4,1/2), ⌊k/2⌋ candidates at x, ⌊k/2⌋ candidates at 1−x, and the last
candidate (if k is odd) at either x or 1−x.
3. Any k ≥ 5: ⌊(k−1)/2⌋ candidates at 1/4, ⌊(k−1)/2⌋ candidates at 3/4, one candidate at 1/2, and
the last candidate (if k is even) at either 1/4 or 3/4.
4. Even k: Cox’s equilibrium; two candidates at each of the points 1/k,3/k,...,(k−1)/k.
5InAppendixB.4,weshowthatfork≤5,thislistofPSNEsisexhaustive(Theorem18);fork>6,theremaybeothers.
17Thus, the qualitative conclusions we arrive by examining Nash equilibria are very different from Cox’s if
we make another similarly reasonable assumption. Cox’s analysis tells us we should not expect candidates
convergingtothecenterforanyk >2,butifweuseleft–righttie-breaking,wefindthatcentralconfigurations
are equilibria for all k. The replicator dynamics reveal when these configurations are stable: only for small
k. These results highlight how analyzing Nash equilibria provides a brittle picture of candidate positioning,
yielding results that are sensitive to tie-breaking and do not capture iterated play. Even SMSNEs, which
are closely related to replicator dynamics fixed points, fail to reveal the typical behavior of the dynamics.
8 Discussion
We introduced a replicator dynamics model of one-dimensional candidate positioning in plurality elections
based on simple heuristic inspired by bounded rationality. Our theoretical results show that the candidates
converge to the center when there are at most four candidates per election, but diverge when there are five
or more candidates per election. Simulations confirm that this pattern is robust to a large range of model
variations. We contrast our results to prior work that focuses on static equilibria or lacks theoretical results
for more than two candidates.
Many open questions remain in the analysis of our model. The foremost is a theoretical characterization
of the asymptotic candidate distribution for k ≥ 5, although this may be challenging given the complex
high-k behaviorweobserveinsimulation. Anevenlargerchallengeisposedbyexpandingbeyondsymmetric
andatomlessinitialcandidatedistributionstodistributionswhichhavepointsmassesorareasymmetric. As
wesawinTheorem15, allowingatomlessdistributionsmeansthereareinfinitelyattractingdistributionsfor
k ≥5,sothetaskbecomesoneofcataloguingallofthepossiblelong-runcandidatedistributions. Theoretical
resultsforourmodelvariantswouldbeinteresting,suchascharacterizingwhichmixturesofcandidatecounts
k lead to convergence to the center, or conditions on voter distributions that result in central convergence
for k ≤4.
While we explored several model variations in simulation, there are many more than can possibly be
covered in a single paper. Additional variations of particular interest include policy-motivated candidates,
strategic voters, probabilistic voters, and higher-dimensional preferences. Another natural direction would
be to explore voting systems other than plurality, like two-round runoff, instant runoff, or Borda count;
Condorcet methods are considerably less interesting under our one-dimensional replicator dynamics, since
the candidate closest to the median voter always wins, but might exhibit more complex behavior in higher
dimensions.
Acknowledgments
ThisworkwassupportedinpartbyAROMURI,aSimonsCollaborationgrant,agrantfromtheMacArthur
Foundation, a Vannevar Bush Faculty Fellowship, AFOSR grant FA9550-19-1-0183, and NSF CAREER
Award #2143176.
References
[1] Elvio Accinelli, Filipe Martins, Jorge Oviedo, Alberto Pinto, and Luis Quintas. Who controls the
controller? a dynamical model of corruption. The Journal of Mathematical Sociology, 41(4):220–247,
2017.
[2] N Balakrishnan and Subrahmaniam Kocherlakota. On the double Weibull distribution: order statistics
and estimation. Sankhy¯a: The Indian Journal of Statistics, Series B, pages 161–178, 1985.
[3] Johann Bauer, Mark Broom, and Eduardo Alonso. The stabilization of equilibria in evolutionary game
dynamics through mutation: mutation limits in evolutionary games. Proceedings of the Royal Society
A, 475(2231):20190355, 2019.
18[4] Jonathan Bendor, Daniel Diermeier, David A Siegel, and Michael M Ting. A behavioral theory of
elections. Princeton University Press, 2011.
[5] Daan Bloembergen, Karl Tuyls, Daniel Hennes, and Michael Kaisers. Evolutionary dynamics of multi-
agent learning: A survey. Journal of Artificial Intelligence Research, 53:659–697, 2015.
[6] Lawrence Blume and David Easley. Evolution and market behavior. Journal of Economic Theory, 58
(1):9–40, 1992.
[7] Tobias B¨ohmelt, Lawrence Ezrow, Roni Lehrer, and Hugh Ward. Party policy diffusion. American
Political Science Review, 110(2):397–410, 2016.
[8] Damien Bol, Arnaud Dellis, and Mandar Oak. Endogenous candidacy in plurality rule elections: Some
explanations of the number of candidates and their polarization. Available at SSRN 2704859, 2016.
[9] Tilman B¨orgers and Rajiv Sarin. Learning through reinforcement and replicator dynamics. Journal of
Economic Theory, 77(1):1–14, 1997.
[10] Michael Bruter, Robert S Erikson, and Aaron B Strauss. Uncertain candidates, valence, and the
dynamics of candidate position-taking. Public Choice, 144:153–168, 2010.
[11] Steven Callander. Bandwagons and momentum in sequential voting. The Review of Economic Studies,
74(3):653–684, 2007.
[12] Randall L Calvert. Robustness of the multidimensional voting model: Candidate motivations, uncer-
tainty, and convergence. American Journal of Political Science, pages 69–95, 1985.
[13] Henry W Chappell and William R Keech. Policy motivation and party differences in a dynamic spatial
model of party competition. American Political Science Review, 80(3):881–899, 1986.
[14] Man-WahCheung. Imitativedynamicsforgameswithcontinuousstrategyspace. Games and Economic
Behavior, 99:206–223, 2016.
[15] Clyde H Coombs. Psychological scaling without a unit of measurement. Psychological Review, 57(3):
145, 1950.
[16] GaryWCox. Electoralequilibriumunderalternativevotinginstitutions. American Journal of Political
Science, pages 82–108, 1987.
[17] Andr´eDePalma, VictorGinsburgh, YorgoYPapageorgiou, andJ-FThisse. Theprincipleofminimum
differentiation holds under sufficient heterogeneity. Econometrica, pages 767–781, 1985.
[18] EddieDekelandMichelePiccione. Sequentialvotingproceduresinsymmetricbinaryelections. Journal
of Political Economy, 108(1):34–55, 2000.
[19] Yvo Desmedt and Edith Elkind. Equilibria of plurality voting with abstentions. In Proceedings of the
11th ACM Conference on Electronic Commerce, pages 347–356, 2010.
[20] Anthony Downs. An economic theory of democracy. Harper & Row, 1957.
[21] John Duggan and C´esar Martinelli. The political economy of dynamic elections: Accountability, com-
mitment, and responsiveness. Journal of Economic Literature, 55(3):916–984, 2017.
[22] Maurice Duverger. Political parties: Their organization and activity in the modern state. Methuen and
Wiley, 2nd edition, 1959. Translated by Barbara North and Robert North.
[23] B Curtis Eaton and Richard G Lipsey. The principle of minimum differentiation reconsidered: Some
new developments in the theory of spatial competition. The Review of Economic Studies, 42(1):27–49,
1975.
19[24] Edith Elkind, Martin Lackner, and Dominik Peters. Preference restrictions in computational social
choice: recent progress. In Proceedings of the Twenty-Fifth International Joint Conference on Artificial
Intelligence, pages 4062–4065, 2016.
[25] Lawrence Ezrow, Tobias B¨ohmelt, Roni Lehrer, and Hugh Ward. Follow the foreign leader? why
following foreign incumbents is an effective electoral strategy. Party Politics, 27(4):716–729, 2021.
[26] Timothy J Feddersen, Itai Sened, and Stephen G Wright. Rational voting and candidate entry under
plurality rule. American Journal of Political Science, pages 1005–1016, 1990.
[27] Jean Guillaume Forand. Two-party competition with persistent policies. Journal of Economic Theory,
152:64–91, 2014.
[28] DanielFriedman. Evolutionarygamesineconomics. Econometrica: JournaloftheEconometricSociety,
pages 637–666, 1991.
[29] Chaitanya S Gokhale and Arne Traulsen. Evolutionary games in the multiverse. Proceedings of the
National Academy of Sciences, 107(12):5500–5504, 2010.
[30] Bernard Grofman. Downs and two-party convergence. Annual Review of Political Science, 7:25–46,
2004.
[31] TimGroseclose. Amodelofcandidatelocationwhenonecandidatehasavalenceadvantage. American
Journal of Political Science, pages 862–886, 2001.
[32] JosefHofbauerandKarlSigmund.Evolutionarygamedynamics.BulletinoftheAmericanMathematical
Society, 40(4):479–519, 2003.
[33] Harold Hotelling. Stability in competition. The Economic Journal, 39(153):41–57, 1929.
[34] AndreasIrmenandJacques-Fran¸coisThisse. Competitioninmulti-characteristicsspaces: Hotellingwas
almost right. Journal of Economic Theory, 78(1):76–102, 1998.
[35] KenKollman,JohnHMiller,andScottEPage. Adaptivepartiesinspatialelections. AmericanPolitical
Science Review, 86(4):929–937, 1992.
[36] Ken Kollman, John H Miller, and Scott E Page. Political parties and electoral landscapes. British
Journal of Political Science, 28(1):139–158, 1998.
[37] Gerald H Kramer. A dynamical model of political equilibrium. Journal of Economic Theory, 16(2):
310–334, 1977.
[38] Anna-Sophie Kurella. Issue Voting and Party Competition, chapter The Evolution of Models of Party
Competition, pages 11–25. Springer, 2017.
[39] Jean-Franc¸ois Laslier andBilge Ozturk Goktuna. Opportunistpoliticians andthe evolution of electoral
competition. Journal of Evolutionary Economics, 26:381–406, 2016.
[40] MichaelLaverandKennethBenoit.Theevolutionofpartysystemsbetweenelections.AmericanJournal
of Political Science, 47(2):215–233, 2003.
[41] Omer Lev and Jeffrey S Rosenschein. Convergence of iterative voting. In Proceedings of the 11th
International Conference on Autonomous Agents and Multiagent Systems, pages 611–618, 2012.
[42] ViktorLosertandEthenAkin. Dynamicsofgamesandgenes: Discreteversuscontinuoustime. Journal
of Mathematical Biology, 17:241–251, 1983.
20[43] WalterRMebaneJr.Partisanmessages,unconditionalstrategiesandcoordinationinamericanelections.
Revised version of a paper originally presented at the Annual Meeting of the Political Metholodolgy
Society (https://public.websites.umich.edu/~wmebane/egamesim.pdf), 2005.
[44] Reshef Meir, Maria Polukarov, Jeffrey Rosenschein, and Nicholas Jennings. Convergence to equilibria
in plurality voting. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 24, pages
823–828, 2010.
[45] Reshef Meir, Omer Lev, and Jeffrey S Rosenschein. A local-dominance theory of voting equilibria. In
Proceedings of the 15th ACM Conference on Economics and Computation, pages 313–330, 2014.
[46] RogerBMyersonandRobertJWeber. Atheoryofvotingequilibria. AmericanPoliticalScienceReview,
87(1):102–114, 1993.
[47] Richard R Nelson, Giovanni Dosi, Constance E Helfat, Andreas Pyka, Pier Paolo Saviotti, Keun Lee,
Sidney G Winter, Kurt Dopfer, and Franco Malerba. Modern evolutionary economics: An overview.
2018.
[48] Jo¨ılle Noailly, Jeroen CJM van den Bergh, and Cees A Withagen. Evolution of harvesting strategies:
replicator and resource dynamics. Journal of Evolutionary Economics, 13:183–200, 2003.
[49] Salvatore Nunnari and Jan Z´apal. Dynamic elections and ideological polarization. Political Analysis,
25(4):505–534, 2017.
[50] SvetlanaObraztsova, EvangelosMarkakis, MariaPolukarov, ZinoviRabinovich, andNicholasJennings.
On the convergence of iterative voting: how restrictive should restricted dynamics be? In Proceedings
of the AAAI Conference on Artificial Intelligence, volume 29, 2015.
[51] Svetlana Obraztsova, Zinovi Rabinovich, Edith Elkind, Maria Polukarov, and Nicholas R Jennings.
Tremblinghandequilibriaofpluralityvoting. InProceedings of the 25th International Joint Conference
on Artificial Intelligence, 2016.
[52] J¨orgOechsslerandFrankRiedel. Evolutionarydynamicsoninfinitestrategyspaces. Economic Theory,
17:141–162, 2001.
[53] Martin J Osborne. Spatial models of political competition under plurality rule: A survey of some
explanationsofthenumberofcandidatesandthepositionstheytake. Canadian Journal of Economics,
pages 261–301, 1995.
[54] Thomas R Palfrey. Spatial equilibrium with entry. The Review of Economic Studies, 51(1):139–156,
1984.
[55] CharlesRPlott.Anotionofequilibriumanditspossibilityundermajorityrule.TheAmericanEconomic
Review, 57(4):787–806, 1967.
[56] Keith T Poole and Howard Rosenthal. The polarization of american politics. The Journal of Politics,
46(4):1061–1079, 1984.
[57] WilliamHRiker. Thetwo-partysystemandduverger’slaw: Anessayonthehistoryofpoliticalscience.
American Political Science Review, 76(4):753–766, 1982.
[58] Robert W Rosenthal. A model of far-sighted electoral competition. Mathematical Social Sciences, 2(3):
289–297, 1982.
[59] Karolina Safarzyn´ska and Jeroen CJM van den Bergh. Evolutionary models in economics: a survey of
methods and building blocks. Journal of Evolutionary Economics, 20:329–373, 2010.
21[60] KarolinaSafarzynskaandJeroenCJMvandenBergh.Beyondreplicatordynamics: Innovation–selection
dynamics and optimal diversity. Journal of Economic Behavior & Organization, 78(3):229–245, 2011.
[61] Pier Paolo Saviotti and GS Mani. Competition, variety and technological evolution: a replicator dy-
namics model. Journal of Evolutionary Economics, 5:369–392, 1995.
[62] PeterSchusterandKarlSigmund. Replicatordynamics. JournalofTheoreticalBiology,100(3):533–538,
1983.
[63] CharlesRShipanandCraigVolden. Themechanismsofpolicydiffusion. American Journal of Political
Science, 52(4):840–857, 2008.
[64] Gernot Sieg and Christof Schulz. Evolutionary dynamics in the voting game. Public Choice, 85(1-2):
157–172, 1995.
[65] Herbert A Simon. A behavioral model of rational choice. The Quarterly Journal of Economics, pages
99–118, 1955.
[66] HerbertASimon. Rationaldecisionmakinginbusinessorganizations. TheAmericanEconomicReview,
69(4):493–513, 1979.
[67] Peter D Taylor and Leo B Jonker. Evolutionary stable strategies and game dynamics. Mathematical
Biosciences, 40(1-2):145–156, 1978.
[68] David RM Thompson, Omer Lev, Kevin Leyton-Brown, and Jeffrey Rosenschein. Empirical analysis of
plurality election equilibria. In Proceedings of the 2013 international conference on Autonomous agents
and multi-agent systems, pages 391–398, 2013.
[69] Amos Tversky and Daniel Kahneman. Judgment under uncertainty: Heuristics and biases. Science,
185(4157):1124–1131, 1974.
[70] Shlomo Weber. On hierarchical spatial competition. The Review of Economic Studies, 59(2):407–425,
1992.
[71] DonaldWittman. Candidateswithpolicypreferences: Adynamicmodel. Journal of Economic Theory,
14(1):180–189, 1977.
[72] DonaldWittman. Candidatemotivation: Asynthesisofalternativetheories. American Political science
review, 77(1):142–157, 1983.
22Appendix for Replicating Electoral Success
Contents
1 Introduction 1
1.1 Related work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
2 Replicator dynamics for candidate positioning 5
2.1 k =2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
2.2 k =3. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
2.3 k =4. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
2.4 k ≥5. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
3 Replicator dynamics with noise 8
3.1 k =2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
3.2 k =3. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.3 k =4. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.4 k ≥5. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
4 Positive results for k ≥5 with no extreme candidates 10
5 Simulations 11
6 Variants of the replicator dynamics 14
7 Relationship to Nash equilibria of one-shot games 15
7.1 Symmetric mixed-strategy Nash equilibria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
7.2 Positional tie-breaking and pure-strategy Nash equilibria . . . . . . . . . . . . . . . . . . . . . 17
8 Discussion 18
A Additional Plots 24
A.1 Additional variant plots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
B Additional Proofs 30
B.1 Proofs from Section 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
B.2 Proofs from Section 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
B.3 Proofs from Section 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
B.4 Proofs from Section 7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
C Formal definitions of variants 47
23A Additional Plots
k=2 k=3 k=4 k=5 k=6 k=7
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
k=2 k=3 k=4 k=5 k=6 k=7
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
Figure 8: Replicator dynamics runs just as in Figure 3, but without enhanced symmetry. For k > 6, the
behavior of the Monte Carlo trials becomes inconsistent without enhanced symmetry, particularly without
ϵ-uniform noise. See Figure 3 for more details.
k=2 k=3 k=4 k=5 k=6 k=7
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
k=2 k=3 k=4 k=5 k=6 k=7
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
Figure 9: Replicator dynamics runs with enhanced symmetry just as in Figure 3, but showing only a single
trial instead of aggregating 50 runs. With enhanced symmetry, the behavior is very consistent across runs.
24k=2 k=3 k=4 k=5 k=6 k=7
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
k=2 k=3 k=4 k=5 k=6 k=7
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
Figure 10: Replicator dynamics runs just as in Figure 8 (no enhanced symmetry), but showing only a single
trial instead of aggregating 50 runs to highlight the inconsistent behavior for k =6 and 7 without enhanced
symmetry.
k=2 k=3 k=4 k=5 k=6 k=7
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
k=2 k=3 k=4 k=5 k=6 k=7
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
Figure 11: Replicator dynamics runs with only 50 elections per generation, without enhanced symmetry.
Each plot shows 50 trials. The top row has no noise, while the bottom row uses 0.01-uniform noise. Even
with a small sample size, our main finding holds.
25k=8 k=9 k=10 k=15 k=25 k=50
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
k=8 k=9 k=10 k=15 k=25 k=50
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
Figure 12: Replicator dynamics runs just as in Figure 4, but without enhanced symmetry. As with smaller
values of k, the behavior becomes more chaotic without enhanced symmetry.
k=2 k=3 k=4 k=5 k=6 k=7
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
Figure 13: Replicator dynamics with initial candidate distribution Uniform(1/4,3/4). These plots show 50
trials with 100,000 elections per generation, no noise, and without enhanced symmetry. The dynamics are
very well-behaved with (1/4,3/4) support, removing the need for enhanced symmetry; compare to Figure 8.
26A.1 Additional variant plots
Beta(2, 2) Beta(0.5, 0.5) Double Weibull(4, 0.5, 0.3)
3
2
1
0
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
Figure 14: PDFs of different voter distributions used in Figure 7.
k=2 k=3 k=4 k=5 k=6 k=7
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
Figure 15: Replicator dynamics with m = 3 generations of memory, no enhanced symmetry, and 50 trials
per plot. There is no qualitative difference between m=3 and m=2 (compare to Figure 7).
27
3=m
,yromeMk=2 k=3 k=4 k=5 k=6 k=7
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
k=8 k=9 k=10 k=15 k=25 k=50
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
k=2 k=3 k=4 k=5 k=6 k=7
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
k=8 k=9 k=10 k=15 k=25 k=50
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
k=2 k=3 k=4 k=5 k=6 k=7
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
k=8 k=9 k=10 k=15 k=25 k=50
1
0.5
0
0 100 200 0 100 200 0 100 200 0 100 200 0 100 200 0 100 200
t t t t t t
Figure 16: Single trials of the replicator dynamics with perturbation noise and 100,000 elections per genera-
tion. The first two rows use σ2 =0.001, the middle two use σ2 =0.005, and the bottom two use σ2 =0.01.
PerturbationnoisecombinedwithMonte-Carloasymmetriescanresultincomplexandunpredictablebranch-
ing with higher k.
28
100.0=2σ
500.0=2σ
10.0=2σ1.0 0.50
0.8 0.45
0.6 0.40
0.4 0.35
0.2 0.30
0.0 0.25
0.0 0.2 0.4 0.6 0.8 1.0
k=3 fraction
Figure17: Heatmapshowingthepositionofthecandidatedistributionmodeatt=100whenelectionshave
a mixture of k =3,4, and 5 candidates each (only modes ≤1/2 are shown). These simulations use 100,000
elections per generation, with k split between 3,4, and 5 in different proportions at each point. The fraction
of elections with 3 candidates varies along the x axis, while the fraction with 4 candidates varies along the
y axis. Any remaining elections have k =5. For instance, the lower left corner has all 100,000 elections use
k = 5, while the point (1/3,1/3) has an even mix of candidate counts. When either the k = 3 or k = 4
fraction is high enough (but especially k = 3), the distribution converges to the center, with the mode at
1/2. However, with enough k = 5 elections, two clusters emerge, and more k = 5 elections pushes them
farther apart.
k=4 k=5 k=6 k=7 k=8 k=9 k=10 k=15 k=25 k=50
1
0.5
0
0 100 2000 100 2000 100 2000 100 2000 100 2000 100 2000 100 2000 100 2000 100 2000 100 200
t t t t t t t t t t
Figure 18: Replicator dynamics with top-h copying where h=3, no enhanced symmetry, 50 trials per plot,
and 100,000 elections per generation.
29
noitcarf
4=k
001=t
ta
edomB Additional Proofs
B.1 Proofs from Section 2
Theorem 3. Let F ∈F. For all x<1/2 and t>0,
0
F (x)≤3/4·F (x)+F (x)3. (3)
3,t 3,t−1 3,t−1
This can be written as a looser closed form
F (x)≤F
(x)·(cid:2)
3/4+F
(x)2(cid:3)t
. (4)
3,t 0 0
Proof. Let x < 1/2 and define p = F (x). Consider the following cases for the positions of the three
3,t−1
candidates X ,X , and X . Call candidates in (x,1−x) inner.
1,t 2,t 3,t
1. All three candidates in [0,1/2) (and the symmetric case). First suppose all three are in [0,1/2) (the
other side is symmetric). If there is at least one inner candidate (w.p. 1/23−p3), then the winner is
inner. Accounting for symmetry, an inner candidate wins in this case w.p. 2(1/23−p3)=1/4−2p3.
2. Two candidates in (x,1/2) and one in (1/2,1−x) (and the symmetric case). Since all candidates are
inner, an inner candidate wins. Accounting for symmetry, an inner candidate wins in this case w.p.
2(cid:2) 3(1/2−p)3(cid:3) =6(1/2−p)3.
3. Twocandidatesin[0,x)andonein(1/2,1−x)(andthesymmetriccase). Thecandidatein(1/2,1−x)
wins with vote share at least 1/2. Accounting for symmetry, an inner candidate wins in this case w.p.
2(cid:2) 3p2(1/2−p)(cid:3) =6p2(1/2−p).
4. One candidate in [0,x), one in (x,1/2), and one in (1/2,1−x). Label them 1, 2, and 3, respectively.
Candidate 3 gets vote share 1−(X +X )/2 = [(1−X )+(1−X )]/2, while candidate 1 gets vote
3 2 3 2
share(X +X )/2. SinceX <1−x,1−X >X ; andsinceX <1/2,1−X >X . Thuscandidate
1 2 3 3 1 2 2 2
3 has higher vote share than candidate 1 and an inner candidate wins. Accounting for symmetry, an
inner candidate wins in this case w.p. 2(cid:2) 3·2p(1/2−p)2(cid:3) =12p(1/2−p)2.
Adding up these cases yields a lower bound on the probability that an inner candidate wins:
Pr(x<Plurality(X ,X ,X )<1−x)≥1/4−2p3+6(1/2−p)3+6p2(1/2−p)+12p(1/2−p)2
1,t 2,t 3,t
=1−3/2·p−2p3.
By symmetry, this yields the claimed upper bound on the probability a candidate in [0,x] wins:
F (x)=Pr(Plurality(X ,X ,X )≤x)
3,t 1,t 2,t 3,t
=(1−Pr(x<Plurality(X ,X ,X )<1−x))/2
1,t 2,t 3,t
≤(cid:2) 1−(1−3/2·p−2p3)(cid:3)
/2
=3/4·p+p3
=3/4·F (x)+F (x)3.
3,t−1 3,t−1
We now show the closed form bound by induction on t. We’ll simultaneously show that F (x)≤F (x).
3,t 0
For the base case t = 0, we have F (x) ≤ F (x). Now for t > 0, suppose the claims hold for t−1. Using
3,t 0
the bound above, we know that
F (x)≤3/4·F (x)+F (x)3
3,t 3,t−1 3,t−1
=F
(x)·(cid:2)
3/4+F
(x)2(cid:3)
3,t−1 3,t−1
≤F
(x)·(cid:2)
3/4+F
(x)2(cid:3)
(by IH)
3,t−1 0
≤F
(x)·(cid:2)
3/4+F
(x)2(cid:3)t−1 ·(cid:2)
3/4+F
(x)2(cid:3)
(by IH)
0 0 0
=F
(x)·(cid:2)
3/4+F
(x)2(cid:3)t
0 0
30This is the main claim we wanted to show. We can now also show the supporting fact that F (x)≤F (x).
3,t 0
For x < 1/2, F (x) ≤ 1/2 by symmetry. Thus 3/4+F (x)2 ≤ 3/4+1/22 = 1, so by the inequality above,
0 0
F (x)≤F (x)·(cid:2) 3/4+F (x)2(cid:3)t ≤F (x)·1t.
3,t 0 0 0
Lemma 1. Let F ∈F. For all x∈(1/3,1/2) and t≥0, F (x)≤F (x).
0 4,t 4,0
Proof. Let x∈(1/3,1/2) and p=F (x). We’ll find a lower bound on the probability an inner candidate
4,t−1
in (x,1−x) wins. Consider the following cases for candidate positions in a k =4 plurality election:
1. All four candidates in [0,1/2) (and the symmetric case). An inner candidate wins if at least one
candidate is inner. Accounting for symmetry, an inner candidate wins in this case w.p. 2(1/24−p4)=
1/8−2p4.
2. Three candidates in [0,1/2) and one in (1/2,1 − x) (and the symmetric case). The candidate on
the right has a higher vote share than any outer candidate on the left (as in Theorem 3 Case 4),
so an inner candidate wins. Accounting for symmetry, an inner candidate wins in this case w.p.
2(4·1/23·(1/2−p))=1/2−p.
3. Two candidates in (x,1/2) and two in (1/2,1−x). All candidates are inner, so an inner candidate
wins. This occurs w.p. (cid:0)4(cid:1) ·(1/2−p)4 =6(1/2−p)4.
2
4. Twocandidatesin[0,x)andtwoin(1/2,1−x)(andthesymmetriccase). Sincex>1/3,therightmost
candidategetsvotesharegreaterthan1/3. Meanwhile,theleftmostcandidategetsvotesharelessthan
1/3. Thesecond-leftmostcandidategetsvotesharelessthan(2/3)/2=1/3(thecandidatesflankingit
are closer together than 0 and 1−x<2/3). Thus an inner candidate wins. Accounting for symmetry,
an inner candidate wins in this case w.p. 2(cid:0)4(cid:1) p2(1/2−p)2 =12p2(1/2−p)2
2
5. Two candidates in (x,1/2), one in (1/2,1−x), and one in (1−x,1] (and the symmetric case). Label
the candidates 1–4 in left–right order. By symmetry, candidate 3 is farther from 1/2 than candidate 2
withprobability2/3: all3!=6orderingsofdistancefrom1/2betweencandidates1–3areequiprobable
and only the 2 where candidate 3 is closest to 1/2 fail this property. In this scenario, candidate 4 has
vote share 1−(X +X )/2 = ((1−X )+(1−X ))/2 and candidate 1 has vote share (X +X )/2.
3 4 3 4 1 2
Since 1−X < X (candidate 2 is closer to the center than 3) and 1−X < X (since X > x
3 2 4 2 2
and X > 1−x), candidate 1 has a larger vote share than candidate 4, the only outer candidate.
4
Thus an inner candidate wins. Accounting for symmetry, an inner candidate wins in this case w.p.
2·4·3·2/3·p(1/2−p)3 =16p(1/2−p)3
Combining all five cases gives a lower bound on the probability that an inner candidate wins:
Pr(x<Plurality(X ,X ,X ,X )<1−x)
1,t 2,t 3,t 4,t
≥1/8−2p4+1/2−p+6(1/2−p)4+12p2(1/2−p)2+16p(1/2−p)3
=1−2p
=1−2·F (x).
4,t−1
By symmetry, this means
F (x)=Pr(Plurality(X ,X ,X ,X )≤x)
4,t 1,t 2,t 3,t 4,t
=[1−Pr(x<Plurality(X ,X ,X ,X )<1−x)]/2
1,t 2,t 3,t 4,t
≤[1−(1−2·F (x))]/2
4,t−1
=F (x).
4,t−1
The claim then follows by induction on t.
31Theorem 4. Let F ∈F. For all x∈(1/3,1/2) and t≥0,
0
F (x)≤F
(x)·(cid:2)
1−4(1/2−F
(x/3+1/3))3(cid:3)t
. (5)
4,t 0 0
Proof. Let x∈(1/3,1/2) and p=F (x). By the argument in the proof of Lemma 1, an inner candidate
4,t−1
wins with probability at least 1−2p. We can strengthen this bound using Lemma 1 and one more case
omitted from that analysis (which can’t easily be used there): three candidates in (x/3+1/3,1/2) and one
in (1−x,1] (and the symmetric case). Note that x/3+1/3=x+2/3·(1/2−x) is the point two-thirds of
the way from x to 1/2. The leftmost candidate gets vote share more than x/3+1/3. Meanwhile, the lone
outer candidate gets vote share less than x+(1−x−(x/3+1/3))/2 = x/3+1/3, so an inner candidate
wins. By Lemma 1, we know F (x/3+1/3)≤F (x/3+1/3). Thus, a candidate is in (x/3+1/3,1/2)
4,t−1 4,0
with probability 1/2−F (x/3+1/3) ≥ 1/2−F (x/3+1/3). Therefore, accounting for symmetry, an
4,t−1 4,0
inner candidate wins inthis case w.p. at least 2·4·(1/2−F (x/3+1/3))3·p=8p(1/2−F (x/3+1/3))3.
4,0 4,0
CombiningthisnewcasewiththecasesfromtheproofofLemma1,aninnercandidatewinsw.p.atleast
1−2p+8p(1/2−F (x/3+1/3))3. By symmetry, this means
4,0
F
(x)≤(cid:2)
1−(1−2p+8p(1/2−F
(x/3+1/3))3)(cid:3)
/2
4,t 4,0
=(cid:2)
2p−8p(1/2−F
(x/3+1/3))3(cid:3)
/2
4,0
=p(cid:2)
1−4(1/2−F
(x/3+1/3))3(cid:3)
4,0
=F
(x)·(cid:2)
1−4(1/2−F
(x/3+1/3))3(cid:3)
.
4,t−1 4,0
The claim then follows by induction on t.
Theorem 5. Let F ∈F. For any k ≥5, there exists some x<1/2 such that lim F (x)̸=0. That is,
0 t→∞ k,t
the candidate distribution does not converge to a point mass at 1/2.
Proof. Suppose F (1/4) ≤ α for some small α. Let x ∈ (1/4,1/2) and F (x) = p, so F (x)−
k,t−1 k,t−1 k,t−1
F (1/4) ≥ p−α. We’ll lower bound the probability that the winner is is an outer candidate outside of
k,t−1
(x,1−x), focusing mainly on cases where all candidates are in (1/4,3/4) so we can apply Lemma 2.
If all candidates are in [0,1/2), then an outer candidate only wins if all candidates are left of x, which
occurs w.p. pk. Accounting for the symmetric case gives an outer candidate win probability of 2pk when
all candidates are on the same side. Now suppose there is at least one candidate on each side. If the left-
and rightmost candidates are in (1/4,x) and (1−x,3/4), respectively, then an outer candidate wins by
Lemma 2. We can find the probability this occurs as the probability that all candidates are in (1/4,3/4)
minus the probability that all candidates are in (1/4,1−x] or in [x,3/4)—since this means there is at least
one candidate each in (1−x,3/4) and (1/4,x). Since F (1/4)≤α, the following is a lower bound on the
k,t−1
probability the leftmost candidate is at X ∈(1/4,x) and the rightmost is at X ∈(x−1,3/4):
1,t k,t
Pr(X ∈(1/4,x),X ∈(x−1,3/4))
1,t k,t
(cid:104) (cid:105)
≥ (1−2α)k − (1−α−p)k +(1−α−p)k− (1−2p)k (by inclusion–exclusion)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
allin(1/4,3/4) allin(1/4,1−x] allin[x,3/4) allin[x,1−x]
=(1−2α)k−2(1−α−p)k+(1−2p)k.
Combining this with the case where all candidates are on the same side (and then dividing by 2 to account
for symmetry) yields a lower bound on F (x):
k,t
F
(x)≥(cid:2) 2pk+(1−2α)k−2(1−α−p)k+(1−2p)k(cid:3)
/2
k,t
=pk+(1−2α)k/2−(1−α−p)k+(1−2p)k/2. (10)
Wecannowusethisboundtoprovenon-convergence. Supposeforacontradictionthatlim F (x)=
t→∞ k,t
0 for all x < 1/2. Then there exists some t∗ such that F (1/4) ≤ α = (cid:2) 1−(499/512)1/k(cid:3) /2 for all t > t∗.
k,t
32But now consider x∗ = F−1(1/4) < 1/2. Since F (1/4) ≤ α for all t > t∗, we can use the fact above
k,t∗ k,t
to show inductively that F (x∗) ≥ 1/4 for all t ≥ t∗. For the base case t = t∗, the claim is vacuously
k,t
true: F (x∗) = 1/4 ≥ 1/4. Now suppose for t > t∗ that F (x∗) ≥ 1/4. Then z = F−1 (1/4) ≤ x∗.
k,t∗ k,t−1 k,t−1
From (10), we then have:
F (z)≥1/4k+(1−2α)k/2−(1−α−1/4)k+(1−2/4)k/2
k,t
>(1−2α)k/2−(3/4−α)k (throw away terms)
≥(1−2α)k/2−(3/4)5 (since k ≥5, α>0)
(cid:16) (cid:104) (cid:105) (cid:17)k
= 1−2 1−(499/512)1/k /2 /2−(3/4)5 (plug in α)
=499/1024−243/1024
=1/4.
By the monotonicity of the CDF, F (x∗) > 1/4, since z ≤ x∗. By induction, F (x∗) ≥ 1/4 for all t ≥ t∗
k,t k,t
This contradicts that lim F (x)=0 for all x<1/2.
t→∞ k,t
B.2 Proofs from Section 3
Our proofs with ϵ-uniform noise make extensive use of the following lemma, which allows us to translate the
convergence of an iterated map bounding a sequence into an eventual bound on the sequence.
Lemma 5. Consider an iterated map x =f(x ) where f :[0,1/2)→[0,1/2) is non-decreasing. Suppose
t t−1
lim x =c for all x ∈I ⊆[0,1/2).
t→∞ t 0
1. If y ≤f(y ) for all t>0, then limsup y ≤c for all y ∈I.
t t−1 t→∞ t 0
2. If y ≥f(y ) for all t>0, then liminf y ≥c for all y ∈I.
t t−1 t→∞ t 0
Proof. Let y ∈ I and define x = y . Suppose y ≤ f(y ) for all t > 0. We’ll show y ≤ x by
0 0 0 t t−1 t t
induction. The base case t = 0 holds by the definition of x . Suppose for t > 0 that y ≤ x .
0 t−1 t−1
Then y ≤ f(y ) ≤ f(x ) = x (since f is non-decreasing), so y ≤ x for all t by induction. Thus,
t t−1 t−1 t t t
limsup y ≤limsup x =lim x =c. Thesecondclaimwithy ≥f(y )followsfromtheexact
t→∞ t t→∞ t t→∞ t t t−1
same argument with each ≤ replaced by ≥ and limsup replaced by liminf.
Lemma 3. For all initial p ∈ [0,1/2], ϵ ∈ (0,1), and x ∈ [0,1/2), the quadratic iterated map p′ = 2p2(1−
√
ϵ)2+4pxϵ(1−ϵ)+2x2ϵ2 converges to the fixed point p∗ = 1−4xϵ(1−ϵ)− 1−8ϵx(1−ϵ) ≤ϵ.
4(1−ϵ)2
Proof. We begin by looking for the fixed points of the map:
2p2(1−ϵ)2+4pxϵ(1−ϵ)+2x2ϵ2 =p
⇔2(1−ϵ)2p2+(4xϵ(1−ϵ)−1)p+2x2ϵ2 =0.
Applying the quadratic formula and simplifying yields the two fixed points:
(cid:112)
1−4xϵ(1−ϵ)− 1−8ϵx(1−ϵ)
p∗ =
1 4(1−ϵ)2
(cid:112)
1−4xϵ(1−ϵ)+ 1−8ϵx(1−ϵ)
p∗ = .
2 4(1−ϵ)2
We’ll show that p∗ is stable and that p∗ ≤ϵ while p∗ is unstable and p∗ >1/2. To see that p∗ ≤ϵ, consider
1 1 2 2 1
ϵ−p∗ :
1
(cid:112) (cid:112)
1−4xϵ(1−ϵ)− 1−8ϵx(1−ϵ) 4(1−ϵ)2ϵ−1+4xϵ(1−ϵ)+ 1−8ϵx(1−ϵ)
ϵ− = . (11)
4(1−ϵ)2 4(1−ϵ)2
33Itsufficestoshowthenumeratorisnon-negative. Takingitsderivativewithrespecttoxshowsthenumerator
is decreasing in x:
∂ (cid:104) (cid:105) 4ϵ(1−ϵ)
4(1−ϵ)2ϵ−1+4xϵ(1−ϵ)+(1−8ϵx(1−ϵ))1/2 =4ϵ(1−ϵ)−
∂x (1−8ϵx(1−ϵ))1/2
<4ϵ(1−ϵ)−4ϵ(1−ϵ)
=0.
Thus, it suffices to show the function is non-negative when x=1/2. For x=1/2,
(cid:112) (cid:112)
4(1−ϵ)2ϵ−1+4xϵ(1−ϵ)+ 1−8ϵx(1−ϵ)=4(1−ϵ)2ϵ−1+2ϵ(1−ϵ)+ 1−4ϵ(1−ϵ)
(cid:112)
=4ϵ3−10ϵ2+6ϵ−1+ (1−2ϵ)2
=4ϵ3−10ϵ2+6ϵ−1+|1−2ϵ|.
Consider the cases ϵ≤1/2 and ϵ>1/2. If ϵ≤1/2,
4ϵ3−10ϵ2+6ϵ−1+|1−2ϵ|=4ϵ3−10ϵ2+4ϵ
=2ϵ(2−ϵ)(1−2ϵ)
≥0. (since ϵ≤1/2)
If ϵ>1/2,
4ϵ3−10ϵ2+6ϵ−1+|1−2ϵ|=4ϵ3−10ϵ2+8ϵ−2
=2(1−ϵ)2(2ϵ−1)
≥0 (since ϵ>1/2)
Therefore the numerator in (11) is non-negative, so p∗ ≤ϵ. To show p∗ is stable, consider the derivative of
1 1
the iterated map in (8):
∂ (cid:2) 2p2(1−ϵ)2+4pxϵ(1−ϵ)+2x2ϵ2(cid:3) =4(1−ϵ)2p+4xϵ(1−ϵ). (12)
∂p
Plugging in p∗:
1
(cid:112)
1−4xϵ(1−ϵ)− 1−8ϵx(1−ϵ)
4(1−ϵ)2p∗+4xϵ(1−ϵ)=4(1−ϵ)2 +4xϵ(1−ϵ)
1 4(1−ϵ)2
(cid:112)
=1− 1−8ϵx(1−ϵ)
(cid:112)
<1− 1−4ϵ(1−ϵ) (x<1/2)
≤1. (ϵ(1−ϵ)≤1/4)
Thusthederivativeoftheiteratedmapatp∗ hasmagnitudestrictlylessthan1,sop∗ isastablefixedpoint.
1 1
Now, consider the other fixed point p∗:
2
(cid:112)
1−4xϵ(1−ϵ)+ 1−8ϵx(1−ϵ)
p∗ =
2 4(1−ϵ)2
(cid:112)
1−2ϵ(1−ϵ)+ 1−4ϵ(1−ϵ)
> (x<1/2)
4(1−ϵ)2
(cid:112)
1−2ϵ(1−ϵ)+ (1−2ϵ)2
=
4(1−ϵ)2
1−2ϵ(1−ϵ)+|1−2ϵ|
= .
4(1−ϵ)2
34If ϵ≤1/2,
1−2ϵ(1−ϵ)+1−2ϵ
p∗ >
2 4(1−ϵ)2
2(1−ϵ)2
=
4(1−ϵ)2
=1/2.
If ϵ>1/2,
1−2ϵ(1−ϵ)−1+2ϵ
p∗ >
2 4(1−ϵ)2
2ϵ2
=
4(1−ϵ)2
2(1/2)2
>
4(1−1/2)2
=1/2.
(cid:112)
In either case, p∗ > 1/2. Additionally, plugging p∗ into the derivative (12) yields 1+ 1−8xϵ(1−ϵ) > 1
2 2
(for x<1/2), showing p∗ is unstable. Thus, for p∈[0,1/2], the quadratic map converges to the stable fixed
2
point p∗ ≤ϵ.
1
Lemma 6. For any ϵ∈(0,1/3), the cubic iterated map given by
p′ =3/4·[ϵ/2+(1−ϵ)p]+[ϵ/2+(1−ϵ)p]3
converges to p∗ ≤1.5ϵ for all initial p∈[0,1/2). Moreover, the map is non-decreasing in p on [0,1/2).
Proof. The fixed points of this map can be found using the cubic formula (equivalently, we used Mathemat-
ica):
(cid:115)
1 1+15ϵ 1+2ϵ
p∗ = −
1 4 (1−ϵ)3 4(1−ϵ)
(cid:115)
1 1+15ϵ 1+2ϵ
p∗ =− −
2 4 (1−ϵ)3 4(1−ϵ)
1
p∗ = .
3 2
We can ignore the negative fixed point p∗, since p can never be negative. We’ll show that for ϵ < 1/3,
2
p∗ ∈ [0,1.5ϵ], p∗ is stable, and the cubic map converges to p∗ for p ∈ [0,1/2). To begin with, we’ll show
1 1 1
p∗ ≥0:
1
35(cid:115)
1 1+15ϵ 1+2ϵ
p∗ = −
1 4 (1−ϵ)3 4(1−ϵ)
(1+15ϵ)1/2 (1+2ϵ)(1−ϵ)1/2
= −
4(1−ϵ)3/2 4(1−ϵ)3/2
(1+15ϵ)1/2−((1+2ϵ)2)1/2(1−ϵ)1/2
=
4(1−ϵ)3/2
(1+15ϵ)1/2−((1+2ϵ)2(1−ϵ))1/2
=
4(1−ϵ)3/2
(1+15ϵ)1/2−(1+3ϵ−4ϵ3)1/2
=
4(1−ϵ)3/2
≥0. (since 1+15ϵ>1+3ϵ−4ϵ3)
Now we’ll show that p∗ ≤1.5ϵ. To do this, we’ll show 1.5ϵ−p∗ ≥0:
1 1
(1+15ϵ)1/2−(1+3ϵ−4ϵ3)1/2
1.5ϵ−p∗ =1.5ϵ−
1 4(1−ϵ)3/2
6ϵ(1−ϵ)3/2 (1+15ϵ)1/2−(1+3ϵ−4ϵ3)1/2
= −
4(1−ϵ)3/2 4(1−ϵ)3/2
6ϵ(1−ϵ)3/2−(1+15ϵ)1/2+(1+3ϵ−4ϵ3)1/2
= .
4(1−ϵ)3/2
It suffices to show the numerator is non-negative on [0,1/3):
6ϵ(1−ϵ)3/2−(1+15ϵ)1/2+(1+3ϵ−4ϵ3)1/2
=6ϵ(1−ϵ)(1−ϵ)1/2−(1+15ϵ)1/2+(1+2ϵ)(1−ϵ)1/2
=(1−ϵ)1/2[6ϵ(1−ϵ)+(1+2ϵ)]−(1+15ϵ)1/2
=(1−ϵ)1/2(1+8ϵ−6ϵ2)−(1+15ϵ)1/2
=(cid:2) (1−ϵ)(1+8ϵ−6ϵ2)2(cid:3)1/2 −(1+15ϵ)1/2
=(1+15ϵ+36ϵ2−148ϵ3+132ϵ4−36ϵ5)1/2−(1+15ϵ)1/2.
Toshowthisisnon-negative, itsufficestoshow36ϵ2−148ϵ3+132ϵ4−36ϵ5 isnon-negative. Factoringyields
36ϵ2−148ϵ3+132ϵ4−36ϵ5 =4ϵ2(1−3ϵ)(9−10ϵ+3ϵ2).
Finally, we can see this is non-negative for ϵ∈(0,1/3), so p∗ ≤1.5ϵ for ϵ∈(0,1/3).
1
Now, to show p∗ is a stable fixed point, we can take the derivative of the cubic map at p∗:
1 2
∂ (cid:0) 3/4·[ϵ/2+(1−ϵ)p]+[ϵ/2+(1−ϵ)p]3(cid:1)
∂p
(cid:20) (cid:21)
= ∂ p3(1−ϵ)3+ 3 p2ϵ(1−ϵ)2+ 3 p(1−ϵ)(cid:0) ϵ2+1(cid:1) + 1 ϵ3+ 3 ϵ
∂p 2 4 8 8
3
=3(1−ϵ)3p2+3ϵ(1−ϵ)2p+ (1−ϵ)(1+ϵ2) (13)
4
36Plugging in p∗ and simplifying yields
1
(cid:32) (cid:115) (cid:33)2 (cid:32) (cid:115) (cid:33)
1 1+15ϵ 1+2ϵ 1 1+15ϵ 1+2ϵ 3
3(1−ϵ)3 − +3ϵ(1−ϵ)2 − + (1−ϵ)(1+ϵ2)
4 (1−ϵ)3 4(1−ϵ) 4 (1−ϵ)3 4(1−ϵ) 4
(cid:32) (cid:115) (cid:33) (cid:115)
1+15ϵ (1+2ϵ)2 1+2ϵ 1+15ϵ 3 1+15ϵ
=3(1−ϵ)3 + − + ϵ(1−ϵ)2
16(1−ϵ)3 16(1−ϵ)2 8(1−ϵ) (1−ϵ)3 4 (1−ϵ)3
3
− ϵ(1−ϵ)(1+2ϵ)+3/4(1−ϵ)(1+ϵ2)
4
(cid:115) (cid:115)
3(1+15ϵ) 3(1−ϵ)(1+2ϵ)2 3(1−ϵ)2(1+2ϵ) 1+15ϵ 3 1+15ϵ
= + − + ϵ(1−ϵ)2
16 16 8 (1−ϵ)3 4 (1−ϵ)3
3
− ϵ(1−ϵ)(1+2ϵ)+3/4(1−ϵ)(1+ϵ2)
4
(cid:115)
(cid:18) (cid:19)
3 3 3 3 1+15ϵ 3
= (1+15ϵ)+ (1−ϵ)(1+2ϵ)2+(1−ϵ)2 ϵ− (1+2ϵ) − ϵ(1−ϵ)(1+2ϵ)
16 16 4 8 (1−ϵ)3 4
+3/4(1−ϵ)(1+ϵ2)
(cid:115)
3 1+15ϵ 9 15
=− (1−ϵ)2 + + ϵ
8 (1−ϵ)3 8 8
3(cid:112) 9 15
=− (1+15ϵ)(1−ϵ)+ + ϵ.
8 8 8
Tosee thisispositive for ϵ<1/3, notethat
3(cid:112)
(1+15ϵ)(1−ϵ)<
3(cid:112)
(1+15/3)≈0.92<9/8. We canalso
8 8
show the derivative of the cubic map at p∗ is less than 1. To do this, we’ll show that 1 minus the derivative
2
at p∗ is positive:
1
(cid:18) (cid:19)
3(cid:112) 9 15 3(cid:112) 1 15
1− − (1+15ϵ)(1−ϵ)+ + ϵ = (1+15ϵ)(1−ϵ)− − ϵ
8 8 8 8 8 8
(cid:115)
(cid:114)
9
(cid:18)
1 15
(cid:19)2
= (1+15ϵ)(1−ϵ)− + ϵ .
64 8 8
By the monotonicity of square roots, it suffices to show that the following quadratic is positive:
9 (cid:18) 1 15 (cid:19)2 45ϵ2 3ϵ 1
(1+15ϵ)(1−ϵ)− + ϵ =− + +
64 8 8 8 2 8
1
= (1−3ϵ)(15ϵ+1).
8
which we can see is positive for ϵ∈(0,1/3). Thus, the derivative of the cubic map at p∗ is positive but less
1
than 1, so p∗ is a stable fixed point. The fixed point at 1/2 is unstable, in contrast: plugging p∗ =1/2 into
1 3
the derivative (13) and simplifying yields 3/2(1−ϵ), which is larger than 1 for ϵ<1/3. Thus the cubic map
converges to p∗ for initial values in [0,1/2).
1
Finally, to show the map is non-decreasing in p, notice that derivative Equation (13) is non-negative for
p≥0 and ϵ∈(0,1].
Theorem 8. Let F ∈F. For any ϵ∈(0,1/3) and x∈[0,1/2), limsup Fϵ (x)≤1.5ϵ.
0 t→∞ 3,t
Proof. Let x<1/2 and define p=Fϵ (x). With ϵ-uniform noise, Pr(X ≤x)=ϵx+(1−ϵ)p. The case
3,t−1 i,t
analysis from Theorem 3 then proceeds exactly the same way, so we can replace p by ϵx+(1−ϵ)p in the
37bound from Theorem 3 to get the equivalent bound with ϵ-uniform noise:
Fϵ (x)≤3/4·[ϵx+(1−ϵ)p]+[ϵx+(1−ϵ)p]3. (14)
3,t
While it would be possible to work directly with the cubic map (14), its fixed points are extremely messy.
As such, we instead analyze the upper bound given by x<1/2 and then use Lemma 5:
Fϵ (x)<3/4·[ϵ/2+(1−ϵ)p]+[ϵ/2+(1−ϵ)p]3. (15)
3,t
If F (x) < 1/2, then Lemma 6 states that the map (15) upper bounding Fϵ (x) converges to p∗ ≤ 1.5ϵ.
0 3,t
Thus, applying Lemma 5 gives limsup Fϵ (x)≤p∗ ≤1.5ϵ as claimed. If F (x)=1/2 (which is possible
t→∞ 3,t 0
since we don’t require that F is positive near 1/2), then applying (15),
0
Fϵ (x)<3/4·[ϵ/2+(1−ϵ)/2]+[ϵ/2+(1−ϵ)/2]3
3,1
=3/4·1/2+[1/2]3
=1/2.
Thus Fϵ (x)<1/2, so we can apply Lemmas 5 and 6 with initial p=Fϵ (x) rather than F (x).
3,1 3,1 0
Lemma 4. Let F ∈F. With ϵ-uniform noise, for any ϵ∈(0,1], x∈(1/3,1/2), and t>0,
0
Fϵ (x)≤ϵx+(1−ϵ)Fϵ (x).
4,t 4,t−1
Thus, Fϵ (x)≤max{x,Fϵ (x)}.
4,t 4,0
Proof. Letx∈(1/3,1/2). JustasinTheorem8,wecantaketheboundfromLemma1andreplaceFϵ (x)
4,t−1
withϵx+(1−ϵ)Fϵ (x)togettheclaimedupperboundwithϵ-uniformnoise. Thesecondpartoftheclaim
4,t−1
followsbyinductionafternotingFϵ (x)≤ϵx+(1−ϵ)Fϵ (x)≤ϵmax{x,Fϵ (x)}+(1−ϵ)max{x,Fϵ (x)}=
4,1 4,0 4,0 4,0
max{x,Fϵ (x)}.
4,0
Theorem9. LetF ∈F. Foranyϵ∈(0,1]andx∈(1/3,1/2),letβ =1/2−ϵ(x/3+1/3)−(1−ϵ)max{x/3+
0
1/3,F (x/3+1/3)}. Then β ∈(0,1/2] and limsup Fϵ (x)≤ 1 ϵ.
0 t→∞ 4,t 8β3
Proof. Letp=Fϵ (x). ByLemma4andsymmetry,aninnercandidatein(x,1−x)winswithprobability
4,t−1
at least 1−2p(1−ϵ)−2xϵ. We’ll strengthen this bound in the same way as in Theorem 4, using the case
with three candidates in (x/3+1/3,1/2) and one in (1−x,1] (and the symmetric case). With ϵ-uniform
noise and accounting for symmetry, the probability this case occurs is
8[ϵx+(1−ϵ)p][1/2−ϵ(x/3+1/3)−(1−ϵ)Fϵ (x/3+1/3)]3
4,t−1
≥8[ϵx+(1−ϵ)p][1/2−ϵ(x/3+1/3)−(1−ϵ)max{x/3+1/3,F (x/3+1/3)}]3 (by Lemma 4)
0
=8[ϵx+(1−ϵ)p]β3.
Then, adding this case to the cases implicitly used in Lemma 4 (see Lemma 1 for the list of cases), we find
Pr(x<Plurality(Xϵ ,Xϵ ,Xϵ ,Xϵ )<1−x)
1,t 2,t 3,t 4,t
≥1−2p(1−ϵ)−2xϵ+8[ϵx+(1−ϵ)p]β3.
By symmetry,
Fϵ (x)=(cid:2) 1−Pr(x<Plurality(Xϵ ,Xϵ ,Xϵ ,Xϵ )<1−x)(cid:3) /2
4,t 1,t 2,t 3,t 4,t
≤p(1−ϵ)+xϵ−4[ϵx+(1−ϵ)p]β3
=p(1−ϵ)(1−4β3)+ϵx(1−4β3). (16)
38We’ll show that the iterated map (16) upper bounding Fϵ (x) converges to a fixed point upper bounded by
4,t
1 ϵ and then apply Lemma 5. First, we’ll find the fixed point (unique, since this is a linear map):
8β
p∗(1−ϵ)(1−4β3)+ϵx(1−4β3)=p∗
⇔ p∗[(1−ϵ)(1−4β3)−1]+ϵx(1−4β3)=0
ϵx(1−4β3)
⇔ p∗ = . (17)
1−(1−ϵ)(1−4β3)
To show convergence to p∗, it suffices to show that the slope of the map is in (−1,1) (any such linear map
convergestoitsuniquefixedpoint,e.g.,bytheBanachfixed-pointtheorem). First,wecanshowβ ∈(0,1/2]:
β =1/2−ϵ(x/3+1/3)−(1−ϵ)max{x/3+1/3,F (x/3+1/3)}
0
>1/2−ϵ(1/2)−(1−ϵ)max{1/2,F (x/3+1/3)} (since x<1/2)
0
=1/2−ϵ(1/2)−(1−ϵ)(1/2) (since F (x/3+1/3)≤1/2)
0
=0.
Thus, the slope (1−ϵ)(1−4β3) ∈ [0,1), so the map (16) converges to p∗ for all initial values p and is
non-decreasing in p. Now we can upper bound p∗:
ϵx(1−4β3)
p∗ =
1−(1−ϵ)(1−4β3)
ϵ/2
< (ϵ≥0, x<1/2)
1−(1−4β3)
ϵ
= .
8β3
Thus, by Lemma 5, limsup Fϵ (x)≤p∗ < 1 ϵ.
t→∞ 4,t 8β3
Theorem 10. Let F ∈ F. For k ≥ 5, the candidate distribution does not approximately converge to the
0
center under replicator dynamics with ϵ-uniform noise.
Proof. Supposeforacontradictionthatthecandidatedistributiondoesapproximatelyconvergetothecenter.
That is, suppose that for all c>0 and x<1/2, there exists some ϵ >0 such that with ϵ-uniform noise,
max
for any ϵ ∈ (0,ϵ ], limsup Fϵ (x) < c. If limsup Fϵ (x) < c, then there is some t∗ such that for
max t→∞ k,t t→∞ k,t
all t≥t∗, Fϵ (x)≤c. In particular, let ϵ∗ and t∗ be the corresponding values for x=1/4. Then for any
k,t max
ϵ-uniform noise with ϵ ≤ ϵ∗ , Fϵ (1/4) ≤ c. Additionally, consider the point z = (Fϵ )−1(1/4). By our
max k,t∗ k,t∗
assumption, there is some ϵ′ and t′ such that if ϵ < ϵ′ , then Fϵ (z) ≤ c for all t ≥ t′. We can make ϵ
max max k,t
and c as small as needed, so we’ll pick:
c<(cid:2) 1−(125/128)1/k(cid:3)
/3 (18)
ϵ<min(cid:8) ϵ∗ ,ϵ′ ,(cid:2) 1−(125/128)1/k(cid:3) /3(cid:9) . (19)
max max
Note that
(cid:2) 1−(125/128)1/k(cid:3)
/3 is largest at k =5, when its value is approximately 0.0016. Also note that
we must have t′ >t∗, since Fϵ (z)=1/4>c.
k,t∗
Now, we can apply the same argument as in Theorem 5, finding a lower bound on Fϵ (x) (for
4,t∗+1
x ∈ (1/4,1/2)) given that only a c-fraction of the winners in generation t∗ are left of 1/4 (note that this
parameter was called α in the proof of Theorem 5). Let p = Fϵ (x) with ϵ-uniform noise. For brevity,
k,t∗
we will avoid repeating the argument from Theorem 5 and instead substitute directly into the resulting
39bound (10). Replacing p with Pr(Xϵ ≤ x) = ϵx+(1−ϵ)p and α with Pr(Xϵ ≤ 1/4) ≤ ϵ/4+(1−ϵ)c
i,t∗ i,t∗
in (10) then yields
Fϵ (x)≥[ϵx+(1−ϵ)p]k+(1−2[ϵ/4+(1−ϵ)c])k/2
4,t∗+1
−(1−[ϵ/4+(1−ϵ)c]−[ϵx+(1−ϵ)p])k+(1−2[ϵx+(1−ϵ)p])k/2. (20)
We will now derive a contradiction: that Fϵ (z) never goes below 1/4 as t increases from t∗ to t′, when
k,t
it should go below c. We know z > 1/4 by the monotonicity of the CDF, since Fϵ (1/4) ≤ c. So, we can
k,t∗
apply the lower bound (20) to z (where p=1/4):
Fϵ (z)≥[ϵz+(1−ϵ)/4]k+(1−2[ϵ/4+(1−ϵ)c])k/2
k,t∗+1
−(1−[ϵ/4+(1−ϵ)c]−[ϵz+(1−ϵ)/4])k+(1−2[ϵz+(1−ϵ)/4])k/2
>(1−2[ϵ/4+(1−ϵ)c])k/2−(1−[ϵ/4+(1−ϵ)c]−[ϵz+(1−ϵ)/4])k
=(1−ϵ/2−2(1−ϵ)c)k/2−(1−[ϵ/4+(1−ϵ)c]−[ϵz+(1−ϵ)/4])k
>(1−ϵ−2c)k/2−(1−(1−ϵ)/4)k
≥(1−ϵ−2c)k/2−(3/4+ϵ/4)5. (21)
Now consider each term in (21). By our upper bounds on c and ϵ,
(1−ϵ−2c)k/2>(cid:16) 1−(cid:2) 1−(125/128)1/k(cid:3) /3−2(cid:2) 1−(125/128)1/k(cid:3) /3(cid:17)k
/2
=(cid:16) 1−(cid:2) 1−(125/128)1/k(cid:3)(cid:17)k
/2
=125/256.
Meanwhile, ϵ is also small enough that (3/4+ϵ/4)5 < 244 (solving for ϵ reveals we need ϵ < 0.0024,
1024
which we have ensured). This then means that (1−ϵ−2c)k/2−(3/4+ϵ/4)5 > 125− 244 =1/4. Following
256 1024
the above chain of inequalities, this shows that Fϵ (z)>1/4.
k,t∗+1
Wewillnowshowbyinductionthatforallt>t∗,Fϵ (z)>1/4,acontradiction(sincebyourassumption,
k,t
Fϵ (z)≤cwitht′ >t∗). Wehavejustshownthebasecaset=t∗+1above. Then, supposeasaninductive
k,t′
hypothesis that Fϵ (z) ≥ 1/4 for t > t∗. Define w = (Fϵ )−1(1/4); by the inductive hypothesis, we know
k,t k,t
w ≤ z. By the argument above, Fϵ (w) > 1/4 (the argument only requires that Fϵ (1/4) ≤ c and
k,t+1 k,t
w ∈ (1/4,1/2), which are satisfied here). Thus, by the monotonicity of the CDF, Fϵ (z) > 1/4. By
k,t+1
induction, we then have Fϵ (z)>1/4, a contradiction.
k,t′
B.3 Proofs from Section 4
Before proving Theorem 11, we need a few supporting lemmas. We begin with a result from the proof of
Theorem 5, specialized to the case when all candidates are in (1/4,3/4).
Lemma 7. Suppose F ∈F is supported on (1/4,3/4). For k ≥5 and x∈(1/4,1/2),
0
F (x)≥1/2+F (x)k−(1−F (x))k+(1−2F (x))k/2.
k,t k,t−1 k,t−1 k,t−1
Proof. WecanusethesameargumentasinTheorem5tofindalowerboundonF (x),butnowF (x)≤
k,t k,t−1
α=0 since F (and therefore all subsequent F ) is supported only on (1/4,3/4). Plugging α=0 into (10)
0 k,t
yields the claim, noting p=F (x).
k,t−1
This gives us an iterated map which bounds F (x) from below. We can show that this map converges
k,t
to1/2inalargeintervalaround1/2,meaningthatthecandidatedistributionconvergestoonewithnomass
in this interval. We cannot give an explicit form for the basin of attraction of this map since it depends on
a root of a polynomial of order k, but we can show the interval grows in k and characterize it for k =5.
40Lemma 8. For all k ≥5, the iterated map given by p′ =1/2+pk−(1−p)k+(1−2p)k/2 converges to 1/2
(cid:112)
for all initial p∈([1− 3/7]/2=0.172...,1/2]. Moreover, this map in non-decreasing in p on [0,1/2).
Proof. First, we’ll show 1/2 is a stable fixed point of the map. Indeed, 1/2+(1/2)k −(1−1/2)k +(1−
2(1/2))k/2=1/2+1/2k−1/2k =1/2. The stability of this fixed point is determined by the derivative
∂ (cid:0) 1/2+pk−(1−p)k+(1−2p)k/2(cid:1) =kpk−1+k(1−p)k−1−k(1−2p)k−1. (22)
∂p
At 1/2, the derivative is k(1/2)k−1+k(1−1/2)k−1−k(1−1)k−1 = k(1/2)k−2. For k ≥ 5, k(1/2)k−2 < 1,
showing the fixed point is stable.
For k =5, we can find the other fixed points of the map by factoring:
1/2+p5−(1−p)5+(1−2p)5/2=p
⇔1/2+p5−(1−p)5+(1−2p)5/2−p=0
⇔p(1−p)(1−2p)(cid:0) −7p2+7p−1(cid:1)
=0.
(cid:110) (cid:112) (cid:112) (cid:111)
⇔p∈ 0,(1− 3/7)/2,1/2,(1+ 3/7)/2,1 ={0,0.172...,0.5,0.827...,1}.
(cid:112)
Plugging in the k = 5 fixed point (1− 3/7)/2 = 0.172... to the derivative (22) yields ≈ 1.43, so this
fixed point in unstable. Next, note that the map monotonically increases in p for p ∈ (0,1/2), since the
derivative (22) is positive (as 1−p > 1−2p; similarly, the map is non-increasing on [0,1/2), as claimed).
(cid:112)
Thus, for k =5, the map is larger than p but smaller than 1/2 for p in ([1− 3/7]/2,1/2) and initial values
in this range converge to the stable fixed point 1/2.
The final step is to show the map is increasing in k for p ∈ (0,1/2), which means that the basin of
attraction only grows in k. To do this, consider the derivative of the map with respect to k:
∂ (cid:0) 1/2+pk−(1−p)k+(1−2p)k/2(cid:1) = 1 (1−2p)klog(1−2p)−(1−p)klog(1−p)+pklogp.
∂k 2
We establish this is positive in the following lemma.
Lemma 9. For all k ≥3 and 0<p<1/2,
1/2(1−2p)klog(1−2p)−(1−p)klog(1−p)+pklogp>0.
Proof. We thank River Li6 for a key idea behind this analysis, based on the following integral trick:
(cid:90) 1 x−1 (cid:12)1
dt=log(1+t(x−1))(cid:12)
1+t(x−1) t=0
0
=log(1+1(x−1))−log(1+0(x−1))
=logx.
Now, apply this identity to the function in question for k =3:
1/2(1−2p)3log(1−2p)−(1−p)3log(1−p)+p3logp
(cid:90) 1 −2p (cid:90) 1 −p (cid:90) 1 p−1
=1/2(1−2p)3 dt −(1−p)3 dt +p3 dt
1+t(−2p) 1+t(−p) 1+t(p−1)
0 0 0
(cid:90) 1(cid:18) p(1−2p)3 p(1−p)3 p3(1−p)(cid:19)
= − + − dt.
1−2pt 1−pt 1+pt−t
0
6https://math.stackexchange.com/q/4789978
41We’llshowthattheintegrandispositiveforallt∈[0,1],whichimpliestheintegralisalsopositive. Converting
to a common denominator,
p(1−2p)3 p(1−p)3 p3(1−p)
− + −
1−2pt 1−pt 1+pt−t
−p(1−2p)3(1−pt)(1+pt−t)+p(1−p)3(1−2pt)(1+pt−t)−p3(1−p)(1−2pt)(1−pt)
= .
(1−2pt)(1−pt)(1+pt−t)
Since 0 < p < 1/2 and 0 ≤ t ≤ 1, the denominator is positive, so we just need to show the numerator is
positive. We can factor:
−p(1−2p)3(1−pt)(1+pt−t)+p(1−p)3(1−2pt)(1+pt−t)−p3(1−p)(1−2pt)(1−pt)
=p2(1−2p)(3−4p−4t+4pt+p2t+t2+pt2−4p2t2+2p3t2)
=p2(1−2p)(cid:2) (1+p−4p2+2p3)t2−(4−4p−p2)t+3−4p(cid:3)
.
Again, since p2 and (1−2p) are positive, we just need to show the right factor is positive. Now, notice that
4−4p−p2 >0 (since p<1/2), and t≤ t2+1, so
2
t2+1
(1+p−4p2+2p3)t2−(4−4p−p2)t+3−4p≥(1+p−4p2+2p3)t2−(4−4p−p2) +3−4p
2
=
1(cid:2) 2−4p+p2−(2−6p+7p2−4p3)t2(cid:3)
2
Now, 2−6p+7p2−4p3 is positive for p∈(0,1/2). We can see this since its derivative, −6+14p−12p2 is
negative (achieving a maximum of −23/12 at p = 7/12) and the polynomial has a zero at p = 1/2. Thus,
we can shrink the function by replacing t2 by 1:
1(cid:2) 2−4p+p2−(2−6p+7p2−4p3)t2(cid:3)
≥
1(cid:2) 2−4p+p2−(2−6p+7p2−4p3)(cid:3)
2 2
=p(1−p)(1−2p).
Finally, we see that this is positive for all p∈(0,1), which implies that
1/2(1−2p)3log(1−2p)−(1−p)3log(1−p)+p3logp>0.
We can now use this as a base case k = 3 in an inductive argument. For the inductive case (k ≥ 3),
suppose
1/2(1−2p)klog(1−2p)−(1−p)klog(1−p)+pklogp>0.
Note that the first and third terms are negative, while the middle term is positive (because of the logs). So,
let x=min{1/2(1−2p)klog(1−2p),pklogp}. We then have
1/2(1−2p)k+1log(1−2p)−(1−p)k+1log(1−p)+pk+1logp
≥(1−2p)x−(1−p)k+1log(1−p)+px (replace both terms by their minimum)
=(1−p)x−(1−p)(1−p)klog(1−p)
≥(1−p)1/2(1−2p)klog(1−2p)−(1−p)(1−p)klog(1−p)+(1−p)pklogp
=(1−p)(cid:2) 1/2(1−2p)klog(1−2p)−(1−p)klog(1−p)+pklogp(cid:3)
>0. (by IH)
The claim then holds for all k ≥3 by induction.
42Therefore, since the map only increases in k, the basin of attraction for the stable fixed point at 1/2 can
only grow as k increases from 5.
(cid:112)
Theorem 11. Suppose F ∈F is supported on (1/4,3/4). Let ℓ=[1− 3/7]/2=0.172.... For k ≥5 and
0
x∈(F−1(ℓ),1/2), lim F (x)=1/2.
0 t→∞ k,t
Proof. ApplyingLemma5totheboundfromLemma7andtheconvergenceandmonotonicityfromLemma8
givesliminf F (x)≥1/2. Meanwhile,F (x)≤1/2foralltbysymmetry,solimsup F (x)≤1/2.
t→∞ k,t k,t t→∞ k,t
Therefore lim F (x)=1/2.
t→∞ k,t
Theorem 12. Suppose F ∈F is supported on (1/4,3/4). For any k ≥2 and t≥0,
0
f (1/2)=f
(1/2)·(cid:2) k(1/2)k−2(cid:3)t
. (9)
k,t 0
Proof. ByLemma2,onlytheleft-orrightmostcandidatecanwin. Thus,ifacandidateat1/2isthewinner,
all other candidates must either be left of 1/2 or right of 1/2. Moreover, if all other candidates are on one
side, then a candidate at 1/2 wins. Thus, a candidate at 1/2 wins if and only if all other candidates fall
on the left or the right. Note that multiple candidates are at 1/2 with probability 0, since the candidate
distribution is atomless. By symmetry, this occurs with probability 2·(1/2)k−1 = (1/2)k−2. Therefore
Pr(Plurality(1/2,X ,...,X ))=(1/2)k−2. By Equation (2), we then have
2,t k,t
f (1/2)=k·f (1/2)·Pr(Plurality(1/2,X ,...,X ))
k,t k,t−1 2,t k,t
=k·f (1/2)·(1/2)k−2.
k,t−1
We can now prove the claim by induction on t. For t = 0, indeed f (1/2) = f
(1/2)·(cid:2) k(1/2)k−2(cid:3)0
. For
k,0 k,0
t≥1, applying the inductive hypothesis to the above inequality yields
f (1/2)=k·f (1/2)·(1/2)k−2
k,t k,t−1
=k·f (1/2)·(cid:2) k(1/2)k−2(cid:3)t−1 ·(1/2)k−2
k,0
=f
(1/2)·(cid:2) k(1/2)k−2(cid:3)t
.
k,0
B.4 Proofs from Section 7
Theorem 13. Suppose F places probability mass p at 1/2. For any k ≥2, there is some p∗ <1 such that
0 k
if p > p∗, the candidate distribution converges to a point mass at 1/2 under the replicator dynamics with
k
left–right tie-breaking. One of the fixed points of pk+kpk−1(1−p) is such a p∗.
k
Proof. Let p′ denote the mass at 1/2 in generation t+1. If all k candidates are at 1/2, then so is the
winner. Similarly, if all but one candidate are at 1/2, then the lone deviant loses with vote share less than
1/2 (with left–right tie-breaking). Thus, p′ ≥ pk +kpk−1(1−p). For any k, this lower bound is larger
than p for p sufficiently close to 1. To see this, take the derivative at p = 1: d (cid:2) pk+kpk−1(1−p)(cid:3) =
dp
kpk−1+k(k−1)pk−2−k2pk−1, whichis0atp=1.Thus, foranysmallenoughϵ, pk+kpk−1(1−p)islarger
than 1−ϵ when evaluated at 1−ϵ. Thus, p will converge to 1 by the monotone convergence theorem.
Theorem 14. With k ≥ 4 and left–right tie-breaking, for any x ∈ (1/4,1/2), the strategy where each
candidate picks uniformly at random between x and 1−x is a SMSNE.
Proof. By symmetry, every candidate has a 1/k win probability if they all follow this strategy. Suppose a
deviantchoosesadistributionthatissupportedonapointbesidesxand1−x. Iftheychooseapointbetween
x and 1−x, they lose unless all other candidates pick the same side, which occurs w.p. 2(1/2)k−1 =1/2k−2.
For k ≥4, this is at most 1/k (and strictly less for k >4), so sampling points in (x,1−x) does not increase
with probability. Alternatively, if the deviant samples a point in [0,x) (or symmetrically, (1−x,1)), they
certainlyloseunlessnocandidatespickx,whichoccurswithprobability1/2k−1—smallerthan1/k fork ≥4.
43Thus deviating to a point left of x only hurts. Combining the above findings, a deviant does not benefit by
sampling any point other than x or 1−x. Finally, a deviant does not benefit by changing the probability
with which they sample either point by symmetry of the other candidates’ choices. Since no deviation is
beneficial, the strategy is a Nash equilibrium.
Theorem15. SupposeF placesprobabilitymasspatxandat1−x,for1/4<x<1/2. Foranyk ≥5,there
0
exists some p∗ <1/2 such that if p>p∗, the candidate distribution converges to point masses at x and 1−x
k k
underthereplicatordynamics. Inparticular, oneofthefixedpointsof(2p)k/2+k(1−2p)((2p)k−1−2pk−1)/2
is such a p∗.
k
Proof. Let p′ denote the mass at x in generation t+1. If all candidates are at x or 1−x (w.p. (2p)k),
then a candidate at x wins with probability 1/2 by symmetry. Alternatively, suppose all but one candidate
are at x or 1−x. The probability that there is at least one candidate at both x and 1−x and a wildcard
is k(1−2p)((2p)k−1 −2pk−1). In such a case, the wildcard loses if they are in the middle (since they get
vote share less than 1/4) and they lose if they are on the outside (to the opposite outside candidate). Thus,
p′ ≥(2p)k/2+k(1−2p)((2p)k−1−2pk−1)/2. For k ≥5, this is larger than p for p sufficiently close to 1/2.
To see this, take the derivative at p = 1/2: f′(p) = d (cid:2) (2p)k/2+k(1−2p)((2p)k−1−2pk−1)/2(cid:3) . We then
dp
find f′(1/2) = 22−kk, which is smaller than 1 for k ≥ 5. Thus, p will converge to 1/2 by the monotone
convergence theorem.
Theorem 17. The following are (some7 of the) PSNEs with uniform voters, complete plurality maximizing
candidates, and left–right tie-breaking:
1. Any k ≥2: all k candidates at 1/2.
2. Any k ≥ 4: for any x ∈ (1/4,1/2), ⌊k/2⌋ candidates at x, ⌊k/2⌋ candidates at 1−x, and the last
candidate (if k is odd) at either x or 1−x.
3. Any k ≥ 5: ⌊(k−1)/2⌋ candidates at 1/4, ⌊(k−1)/2⌋ candidates at 3/4, one candidate at 1/2, and
the last candidate (if k is even) at either 1/4 or 3/4.
4. Even k: Cox’s equilibrium; two candidates at each of the points 1/k,3/k,...,(k−1)/k.
Proof. We show in each case than no deviation is beneficial.
1. If all k candidates are at 1/2, then the winner is chosen uniformly from the leftmost and rightmost
candidate at 1/2, who each get vote share 1/2. If any one candidate moves to some point away from
1/2, they get vote share strictly less than 1/2, while the middle candidate opposite them gets vote
share 1/2 and wins. Thus, no candidate can benefit by deviating.
2. Since k ≥4, both points x and 1−x have at least two candidates. The candidates who end up being
the outermost at x and 1−x each get vote share x, while the innermost candidates get vote share
1/2−x, which is strictly smaller since x>1/4. Any candidate who moves towards the edge gets vote
share strictly less than x and loses to the other side. Any candidate who moves into (x,1−x) gets
vote share 1/2−x and loses. Finally, no candidate benefits by moving from x to 1−x (or vice-versa),
since they will always be in a lottery to be the outermost which has at least as many candidates as
their original point (even if k is odd and a deviant moves from the more populated point).
3. Since k ≥ 5, both points 1/4 and 3/4 have at least two candidates. There is a three-way tie with
vote share 1/4 between the leftmost candidate, the rightmost candidate, and the one at 1/2—the
inner candidates at 1/4 and 3/4 get vote share strictly less than 1/4. As in the previous case, every
candidate certainly loses if they move left of 1/4 or right of 3/4. The side candidates also lose if they
move into (1/4,3/4). As before, there is no benefit to switching from 1/4 to 3/4 or vice-versa. Finally,
the candidate at 1/2 only shrinks their win probability by moving to 1/4 or 3/4 (and worsens their
7InAppendixB.4,weshowthatfork≤5,thislistofPSNEsisexhaustive(Theorem18);fork>6,theremaybeothers.
44margin against a competitor by moving to any other point in (1/4,3/4)). Thus, no candidate benefits
by deviating.
4. Every candidate gets vote share 1/k and has a chance to win. If any candidate moves, their partner
will get vote share more than 1/k and the deviant will still have vote share at most 1/k, so no one can
deviate beneficially.
Lemma 10. Any PSNE with uniform voters, complete plurality mixmizing candidates, and left–right tie-
breaking must satisfy the following properties:
(a) Any point occupied by one candidate cannot be between another occupied point and a boundary.
(b) Any point with at least three candidates must be adjacent to a boundary.
(c) Any point with two candidates not adjacent to a boundary must have the same vote share on both sides.
(d) In any two-point equilibrium, the points must be equidistant from 1/2.
Proof. (a) Otherwise, the candidate can move away from the boundary to increase their vote share and
decrease an opponent’s vote share.
(b) Otherwise, one of the candidates could move distance ϵ either to the right or left of the point to
guarantee the maximum possible vote share (instead of having probability < 1/3 of being on that
side). This only decreases other vote shares—except the new left- or rightmost candidate created,
which only has vote share ϵ/2 (note this requires at least three candidates; with only two, moving
increases the vote share of the partner). When adjacent to a boundary, this doesn’t work—moving
ϵ towards a boundary would decrease the vote share achieved (even if it’s guaranteed), which could
create a plurality loss, as in Equilibria 2 and 3 from Theorem 17.
(c) If not, then one of the candidates can move ϵ towards the side with higher vote share to guarantee
it. For small enough ϵ, the deviant will have higher vote share than their former partner. This also
decreases the vote share of the bordering candidates the deviant moved towards. Thus, this either
increases the plurality win probability of the deviant or at least decreases the expected margin against
the winner.
(d) Suppose not, and call the points x and y. Assume without loss of generality that x<y and x<1−y.
Let z = (y−x)/2 be the vote share inner candidates get. If z ≥ y, then a candidate at x can move
right by ϵ to improve their winning chances, getting certain vote share z rather than a chance at it.
If z <1−y, then a candidate at y can move right by ϵ to guarantee a win. Thus the points must be
equidistant from 1/2.
Theorem 18. The following is a complete list of the PSNEs with uniform voters,complete plurality maxi-
mizing candidates, and left–right tie-breaking for small k:
k =2: (1/2,1/2)
k =3: (1/2,1/2,1/2)
k =4:(a) (1/2,1/2,1/2,1/2)
(b) (1/4,1/4,3/4,3/4)
(c) (x,x,1−x,1−x), for any x∈(1/4,1/2)
k =5:(a) (1/2,1/2,1/2,1/2,1/2)
45(b) (1/4,1/4,1/2,3/4,3/4)
(c) (x,x,1−x,1−x,1−x), for any x∈(1/4,1/2)
(d) (x,x,x,1−x,1−x), for any x∈(1/4,1/2).
Proof. WeknowbyTheorem17thattheseareallNashequilibria,soweonlyneedtoshownootherequilibria
exist.
k =2: If a candidate is at a point other than 1/2, then they can move to 1/2 and do strictly better
(regardless of their opponent’s position), so no other equilibrium is possible.
k =3: WeknownopointwithonecandidatecanbeadjacenttoaboundaryinequilibriumbyLemma10.
So all candidates must be at the same point. If that point is anything other than 1/2, it would
not be an equilibrium, so (1/2,1/2,1/2) must be the unique equilibrium.
k =4: There is no way to have a single-candidate point not adjacent to a boundary, since no partition of
4 that includes a 1 has two numbers larger than 1 to flank the single-candidate point. Thus, any
equilibrium either has two points with two candidates each or one point with all four candidates.
The latter type of equilibrium must be at 1/2, so we only need to characterize the two-point
equilibria.
We know by Lemma 10 that in two-point equilibria, the points must be equidistant from 1/2 and
so can be written as x and 1−x. Now, we can show that we must have x∈[1/4,1/2). If x<1/4,
then a candidate at x can move right by ϵ to guarantee the winning inner vote share rather than
a 1/2 chance at it. Thus, the only two point equilibria are those claimed.
k =5: A single-point equilibrium must be at 1/2.
A two-point equilibrium cannot be a 1–4 split since the lone candidate would be adjacent to a
boundary, so any two-point equilibrium must be a 2–3 split. By Lemma 10, the points must be
equidistant from 1/2, so call them x and 1−x. We cannot have x < 1/4, or else a candidate
at x would move right by ϵ to guarantee a winning vote share. Unlike for k = 4, we also cannot
have x=1/4. If we did, consider the point with 3 candidates. One of them could move to 1/2 to
guaranteevoteshare1/4, whichwouldbetiedforthewinningshare, whereastheyonlyhada2/3
chance of getting that vote share before. Thus the only two-point equilibria are those claimed.
We cannot have four- or five-point equilibria, since we would then be forced to place single-
candidate points adjacent to the boundary. However, we can have a three-point equilibrium with
a 2-1-2 split (a 3-1-1 is impossible for the same boundary reason). So we only need to show that
the claimed 2-1-2 equilibrium is the only one. First, the lone candidate must be at the midpoint
ofthetwoouterpointstooptimizeitsmostcompetitivemargin. Next,we’llshowtheouterpoints
must be equidistant from the boundaries. Suppose not: say the outer points are x and y with
x < 1−y. If the inner vote share at x ((y−x)/4) is smaller than x, then a candidate at x has
no chance of winning. But by moving to x−ϵ for some small ϵ, they can guarantee the larger
vote share and reduce their expected losing margin. If the inner vote share at x is larger than the
outervoteshare,thenacandidateatxlosestotheloneinnercandidate;butagain,theycanmove
to x+ϵ improve their expected losing margin. The only remaining option is that the inner and
outer shares at x are equal (so the inner share is x and the middle candidate gets vote share 2x).
In that case, consider subcases based on 1−y. If 1−y < 2x, then the middle candidate always
wins. Since 1−y >x, a candidate at y can move to y+ϵ to reduce their expected losing margin
against the middle candidate. If 1−y >2x, then a candidate at y can move to y+ϵ to guarantee
a win rather than a 1/2 chance. If 1−y = 2x, then a candidate at x can move to y, giving it a
chance to enter the winning lottery for vote share 2x (note that the candidate they leave behind
at x now also gets vote share 2x).
Now that we know the outer points are equidistant from the boundaries, the middle candidate
must then be at 1/2. We can now show that the only possible outer points x and 1−x are given
46by x=1/4. If x>1/4, then the middle candidate cannot win; but they could move to x to join
a lottery for the winning vote share. If x < 1/4, then a candidate at x cannot win. If the inner
voteshareatxislargerthanx, acandidateatxcanmovetox+ϵtoreducetheirexpectedlosing
margin against the middle candidate. Symmetrically, if x is larger than the inner vote share, then
a candidate at x can move to x−ϵ to reduce their expected losing margin. Finally, consider the
case where the inner and outer vote shares are equal (x = 1/6). A candidate at x can move into
(1/6,1/2),keepingthesamevoteshare1/6whilereducingthevoteshareofthewinningcandidate
at 1/2, thus improving their losing margin. Therefore, the only three-point equilibrium is the one
claimed with x=1/4.
C Formal definitions of variants
Tohandlenon-uniformvoterdistributions,wedefinePlurality (x ,...,x )tobethepositionoftheplurality
V 1 k
winner among x ,...,x if the voter distribution is V.
1 k
Definition 5. Given an initial candidate distribution F and a candidate count k, and a distribution of
0
voters V, the replicator dynamics for candidate positioning with voter distribution V are, for all t>0,
F (x)=Pr(Plurality (X ,...,X )≤x),
k,t V 1,t k,t
X ∼F , ∀i=1,...,k.
i,t k,t−1
Definition6. GivenaninitialcandidatedistributionF ,acandidatecountk,andmgenerationsofmemory,
0
the replicator dynamics for candidate positioning with m generations of memory are, for all t>0,
F (x)=Pr(Plurality(X ,...,X )≤x),
k,t 1,t k,t

F w.p. 1
 k,t−1 m
X ∼ ...
i,t
F w.p. 1.
k,t−m m
Definition 7. Given an initial candidate distribution F , a candidate count k, and a variance σ2 ∈ [0,1],
0
the replicator dynamics for candidate positioning with σ2-perturbation noise are, for all t>0,
F (x)=Pr(Plurality(X ,...,X )≤x),
k,t 1,t k,t
X ∼min(1,max(0,F +N(0,σ2))), ∀i=1,...,k.
i,t k,t−1
Definition 8. GivenaninitialcandidatedistributionF , andcandidatecountproportionsp ,p ,...,p ,
0 2 3 kmax
the replicator dynamics for candidate positioning with variable candidate counts are, for all t>0,
k (cid:88)max
F (x)= p ·Pr(Plurality(X ,...,X )≤x),
t k 1,t k,t
k=2
X ∼F .
i,t t−1
Let F(i) denote the distribution of the i-th place candidate generation t with k candidates per election,
k,t
where i ≤ k. We define F(i) = F for all k and all i, although we typically write F since the initial
k,0 0 0
distribution does not depend on k. Under this notation F(1) = F where F is the CDF of the winner
k,t k,t k,t
distribution. Then,
47Definition 9. Given an initial candidate distribution F , a candidate count k, and h ≤ k, the replicator
0
dynamics for candidate positioning with top-h copying are, for all t>0,
F (x)=Pr(Plurality(X ,...,X )≤x),
k,t 1,t k,t
 F(1) w.p. 1
 k,t h
X ∼ ...
i,t
F(h)
w.p. 1.
k,t h
48