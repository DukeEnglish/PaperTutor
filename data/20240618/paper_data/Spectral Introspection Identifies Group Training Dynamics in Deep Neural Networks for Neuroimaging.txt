Spectral Introspection Identifies Group Training
Dynamics in Deep Neural Networks for
Neuroimaging
Bradley T. Baker∗,†, Vince D. Calhoun∗,†,⋄, Sergey M. Plis∗,†
∗The Georgia State University, Georgia Institute of Technology,
Emory University Center for Translational Research in
Neuroimaging and Data Science (TReNDS)
†Georgia State University
⋆Georgia Institute of Technology
⋄Emory University
Abstract
Neuralnetworks,whicehavehadaprofoundeffectonhowresearchers
study complex phenomena, do so through a complex, nonlinear mathe-
matical structure which can be difficult for human researchers to inter-
pret. This obstacle can be especially salient when researchers want to
better understand the emergence of particular model behaviors such as
bias, overfitting, overparametrization, and more. In Neuroimaging, the
understandingofhowsuchphenomenaemergeisfundamentaltoprevent-
ingandinformingusersofthepotentialrisksinvolvedinpractice. Inthis
work, we present a novel introspection framework for Deep Learning on
Neuroimagingdata,whichexploitsthenaturalstructureofgradientcom-
putations via the singular value decomposition of gradient components
during reverse-mode auto-differentiation. Unlike post-hoc introspection
techniques,whichrequirefully-trainedmodelsforevaluation,ourmethod
allowsforthestudyoftrainingdynamicsonthefly,andevenmoreinter-
estingly,allowforthedecompositionofgradientsbasedonwhichsamples
belong to particular groups of interest. We demonstrate how the gra-
dient spectra for several common deep learning models differ between
schizophreniaandcontrolparticipantsfromtheCOBREstudy,andillus-
tratehowthesetrajectoriesmayrevealspecifictrainingdynamicshelpful
for further analysis.
1 Introduction
In recent years, a broad library of “introspection” methods have emerged to
mitigate the difficulty of straightforward interpretation [1–6]. In particular,
1
4202
nuJ
71
]GL.sc[
1v52811.6042:viXramost state of the art research on DNN interpretation has utilized post-hoc
analysis of model gradients. For example, the popular integrated gradients
measure [1], saliency maps [6], and other gradient-based methods [3,4] have
provedpopularinapplicationstoconvolutionalneuralnetworksastheyprovide
simple spatial visualizations which make for easy building of intuition. While
these methods are extremely popular, the resulting visualizations tend to be
noisy and inconsistent [7–10], and recent research in the field has attempted to
mitigate these limitations, for example by using refining maps based on region
attribution density [11,12], providing an adaptive interpolation path [13], or
imposing geometric constraints on produced maps [14,15].
While post-hoc gradient analysis techniques can be useful for interpretation
on pre-trained models, these methods are not useful for evaluating training
dynamics; they can explain where a model currently is, but now how it arrived
there. While theoretical analyses of dynamics [16,17] provide some guidance to
describing model dynamics, new empirical metrics and visualizations are also
important for building intuition about model behavior while also accumulating
evidence for further theoretical interpretation.
One existing method which empirically describes model dynamics is the
information-plane method [18–20], in which the mutual information between
layer weights and the input and output spaces is computed and visualized dur-
ing training. While this method provides fascinating visualizations of dynamic
behavior, the general interpretation of the dynamics adhering to the informa-
tion bottleneck principle [21] is not immediately clear [22] and can be sensitive
to architectural choices or the empirical method used to estimate mutual infor-
mation.
We present a novel empirical method for analyzing model learning dynam-
ics, whichbuildsoffofourtheoreticalworkstudyinggradientrank. Wecallour
methodAutoSpec,asitutilizesuniqueopportunitieswithinauto-differnetiation
to analyze model learning dynamics. While we previously showed that model
architecture can impose theoretical limits on gradient rank, there is more that
can be observed at work within auto-differentiation. Namely, we show that
the singular values of the gradient and of the component matrices which are
used to compute it can be studied they dynamically evolve during model train-
ing. Furthermore, because we can analyze gradients on-the-fly within the auto-
differentiation mechanism, we have the unique opportunity to analyze these
dynamics as they adhere to individual samples from the training data set. As
longasthesesampleshavesomekindofcommongrouplabelling,wecanthusdo
statisticalcomparisonsofgradienttrajectoriesbetweengroupswithoutbreaking
normal training behavior. This further allows our method to stand out from
post-hoc methods which not only occur outside of training, but can only be
evaluated for between different classes in disjoint contexts.
21.1 Auto Differentiation
2 Methods
In this section, we provide an overview of the methods at work in AutoSpec.
First, we provide a brier review of how the gradient of the weights is computed
within auto-differentiation, recall how the spectrum is bounded by particular
architectural decisions, and show how the spectrum of the gradient relates to
the spectrum of the input activations and adjoint variables accumulated within
auto-differentiation. We then describe how auto-differentiation uniquely allows
us to analyze dynamics between particular groups of samples.
2.1 Gradient Spectra via Auto-Differentiation
Recallthatduringreverse-modeauto-differentiation,thegradientoftheweights
at a given layer i is computed as a product of the input activations A and
the adjoint variable ≩ which is the partial derivative computed on the output
neurons during back-propagation. Formally, if we have weights W
i
∈ Rhi−1×hi
where h and h are the number of input and output neurons respectively.
i−1 i
Formally, we write this as:
∇ =A⊤ ∆ (1)
Wi i−1 i
where A ∈ RN×hi−1 and ≩ ∈ RN×hi are the input activations and adjoint
variables with batch size N. The Singular Value Decompositions of ∇ , A
Wi i−1
and ∆ can be written as:
i
∇ =U Σ V⊤ , A =U Σ V⊤ , ∆ =U Σ V⊤ (2)
Wi ∇i ∇i ∇i i−1 Ai−1 Ai−1 Ai−1 i ∆i ∆i ∆i
We can then write ∇ as a product of the SVDs of A and ∆ , and use
Wi i−1 i
the fact that the U matrices are orthogonal to get:
∇ =V Σ U U⊤ Σ V⊤ (3)
Wi Ai−1 Ai−1 Ai−1 ∆i ∆i ∆i
=V Σ Σ V⊤ (4)
Ai−1 Ai−1 ∆i ∆i
Thus,wecanseethatthesingularvaluesof∇ arejustthesingularvalues
Wi
of the first min(h ,h) singular values from the input activations and adjoint
i−1
variable.
For the sake of analysis, we can compute the SVD of all three statistics-
of-interest just by computing the SVD and the input activations and adjoint
matrices; however, because the batch size N might be large, if the gradient is
the only statistic of interest, it would often be more efficient to compute the
SVD of ∇ directly.
Wi
Fornetworkswhichutilizeparametertying,suchasConvolutionalorRecur-
rentNeuralNetworks,thegradientsareoftenaccumulatedovertimeandspace.
3If desired, our unique perspective from within Auto-Differentiation allows us to
peek further into these dimensions, characterizing the spectra not only of the
gradient of the weights, but of the gradient of the weights over the dimension
of tying.
2.2 Identifying Group Differences
One of the advantages of computing our introspection statistics within auto-
differentiation is that we have access to the individual gradients for each input
sample to the model. Thus, we can evaluate how particular groups of samples
individually contribute to the aggregated gradients prior to the aggregated gra-
dient. Formally, if we have C distinct groups of samples in our training set, we
can compute the set of C gradients and their SVD as
{∇ =U Σ V⊤}C (5)
c c c c c=1
we canthen performstatistical testingby accumulating thesegroup-specific
statistics during training, and evaluating the differences between groups. For
example, if we perform a two-tailed T-test, we can obtain a measure of which
trainingstepsweresignificantbetweengroupsifwetreatthenumberofsingular
values as features. Additionally, we can obtain a measure of per-singular-value
significance by taking the T-tests between the transpose.
2.3 Data sets and Experimental Design
TodemonstratethekindsofdynamicswhichAutoSpeccanreveal,wehaveorga-
nizedabatteryofexperimentsacrossdifferentdatamodalitiesandarchitecture
types.
First, we use two numerical data sets to show how AutoSpec allows for
dynanic introspection on Multi-Layer Perceptrons, Elman Cell RNNs, and 2-D
CNNs. Our choice of numerical data sets are the MNIST and Sinusoid data
sets.
We then move from numerical data to an application in Neuroimaging anal-
ysis. We first apply a Multi-Layer perceptron on FreeSurfer volumes, and then
move to analyzing functional MRI from the COBRE data set [23], which is a
well-studied data set especially for applications of deep learning [24–27]. For
our demonstration, we perform Spatially Constrained Independent Component
Analysis using the NeuroMark template [28], which provides us with 53 neuro-
logically relevant spatially independent maps and associated time-series. Using
the time-series data, we demonstrate how AutoSpec can reveal group-specific
gradientdynamicsin1Dand2DCNNs,LSTMsandtheBERTtransformer[29].
Wethenutiliezthespatialmaps(aggregatedoverthenumberofcomponentsby
taking the maximum over the voxel dimension) to demonstrate group-specific
gradient dynamics in 3D-CNNs.
For all architectures and all data sets, we evaluate a few different scenarios
demonstrating the diversity of dynamics available in gradient spectra. For all
4models and datasets, we perform two tasks: classification and auto-encoding;
however, we only demonstrate one model instance and group differences for
the auto-encoding task for clarity. Additionally, we evaluate “wide/shallow” (1
layer with 128 neurons) and “deep/thin” (3 layers with 8 neurons) variants of
each model. We finally compare how a different choice of activation function
can affect dynamics by evaluating each model with Sigmoid and Tanh activa-
tionsinconstrasttoReLUactivationswhichweuseelsewhere. Forallanalyses,
we perform two-tailed T-Tests between each pair of classes in a given data set
to demonstrate where significant group differences emerge within a particular
scenario. Group comparisons for all architectural variants are included in sup-
plementary material.
A detailed outline of our experimental is included in 1 and 2. When not
otherwise specified, we use ReLU activations in all models, a learning rate of
1×10−3, and 1000 epochs of training. Where possible, we perform full-batch
training rather than SGD, as the batch size can artificially restrict the rank of
the gradient. For the sake of this demonstration, we set all models to use the
same seed, and we only evaluate the models in a one-shot training scenario.
3 Results
In this section, we present the empirical results demonstrating how AutoSpec
can be used to reveal group gradient dynamics in deep neural networks. All
of our figures follow the same format as follows: panels A and B compare the
dynamics between a model trained for sample reconstruction (panel A) and for
classification(panelB);panelsCandDcomparedynamicsbetweentanh(panel
C) and relu (panel D) activations, panels E and F compare dynamics between
“thin” (panel E) and “wide” (panel F) variants of the base network with 8 and
64 neurons respectively. For a review of how each experiment is organized into
panels see table 1.
TheexperimentsontheMNISTdatasetareincludedin1and2fortheMLP
and 2DCNN architectures respectively. The experiments for the sinusoid data
set evaluated with an RNN can be found in 3. The MLP applied to FSL data
can be found in 4. The experiments on COBRE ICA time-series can be found
in figures 6.5, 6.6 and 6.7 for the LSTM, BERT, and 1D-CNN architectures
respectively. Finally, the experiments on COBRE ICA spatial maps can be
found in figure 6.8. See table 2 for a review of which data set and architecture
combinations can be found in particular figures.
4 Discussion
In this work, we have introduced a new method for model introspection called
AutoSpec, in which we utilize the singular value decomposition to study the
dynamic evolution of the spectrum of the gradient and its component matrices.
Our method reveals fascinating dynamics at work in a number of model archi-
5Table 1
Panel Task Model Dims Activation
A Auto-Encoding [32] ReLU
B Classification [32] ReLU
C Auto-Encoding [32] Tanh
D Auto-Encoding [32] Sigmoid
E Auto-Encoding [8] ReLU
F Auto-Encoding [64] ReLU
G Auto-Encoding (Group Differences) [32] ReLU
H Classification (Group Differences) [32] ReLU
Table 2
Dataset Modality Model Figure
MNIST Image MLP 1
MNIST Image 2DCNN 2
SINUSOID Time-Series RNN 3
FreeSurfer Tabular MLP 4
COBRE ICA Time-Series LSTM 5
COBRE ICA Time-Series BERT 6
COBRE ICA Time-Series 1D-CNN 7
COBRE ICA Spatial Mapps 3D-CNN 8
tectures, and alsoallowsus to identify unique dynamics belongingto particular
groups within a data set. We demonstrated our model on numerical datasets
forsequenceandimagereconstructionandclassification,andalsodemonstrated
the identification of group differences on a real neuroimaging data set.
We will provide a brief discussion of some of the observed differences in
dynamics; however, we would like to stipulate that any general conclusions
regarding these dynamics will require further experimentation testing specific
architecture choices systematically over many repetitions, seeds, and data sets.
Firstofallwenoticethatforalldatasetsandarchitectures,thedynamicswefind
with AutoSpec show very different trajectories between and AutoEncoding and
Classification task (see 1a and 1b for the MLP applied to MNIST for example).
Particularly the input layers across all cases are affected by the change in the
output structure, and corresponding singular values in output layers are also
differentbetweenthetwotasks. Thechoiceofactivationfunctioncanaffectthe
gradientspectrumaswell-wenoticeforexamplewhenwecomparetheSigmoid
and Tanh activated LSTM (5) and 1D CNN (7), we can see slight differences
in the trajectory toward the start of training, but the overall evolution stays
the same. In the 2D (2) and 3D (8) CNNs, however, we notice that Sigmoid
and Tanh activations affect the spectrum quite differently, with the effects in
the 3D CNN particularly noticeable early in the training period. The dynamics
in the layers pulled from the BERT architecture (6) are difficult to interpret
6as singular values tend to jump drastically between individual epochs, perhaps
indicated; however, even in this noisy scenario, the BERT architecture reflects
a general trend of shrinking singular values which occurs in other architures
during training.
In each of our analyses, we also compute group differences between the ob-
served dynamics. In general, smaller observed singular values tend to change
more drastically; however, because the values are so small and near the thresh-
old for machine epsilon of floating point numbers, it is unclear if any observed
differences are merely the result of noise. We do see larger singular values show
significant differences during training across a few different architectures how-
ever, and interestingly, these differences are often contained with a few layers.
For example, the MLP autoencoder trained on FSL data shows significant dif-
ferences between SZ and HC groups in the middle singular values of the output
layer (see 4g), while the corresponding classifier shows more group differences
in the input layer (see 4h). The LSTM, BERT and 1D CNN models all show
significant differences between male SZ and HC groups, with the LSTM show-
ing differences mostly the Hidden-to-Hidden gradients (see 5g and 5h), the 1D
CNN showing significant differences at the output layer (see 7g and 7h), and
BERTshowingdifferencesacrosstheentiremodelfortheautoencodertask(see
6g) with almost no significant differences in the classifier ((see 6h). While more
work is needed to investigate what these differences mean for how the model
treatsdifferentsamplegroupsdifferently,ourfindingofsignificanteffectsacross
multipletasksandarchitecturesdemonstratesthatthesekindsofdynamicsmay
be useful for further, targeted investigation.
ThemajorlimitationofourAutoSpecframeworkisthecomputationalover-
head required for computing the singular values on-the-fly during training.
In general for a matrix A ∈ Rm×n, the complexity required for computing
the SVD is O(min(mn2,m2n)). If we want to analyze L different layers at
T different training periods, the complexity of our method further increases
to O(LT min(mn2,m2n)). Even more overhead is accumulated if we perform
group-specific analyses. As such, AutoSpec in practical usage will require long
runtimesduringtrainingtoperformacomprehensiveanalysis;however,limiting
theanalysistospecificsingularvalues,layers,periodsduringtraining,orgroups
wouldreducethisoverhead. Onepotentialdirectionoffutureworkcouldderive
an analytic update to the gradient spectrum based on the initial SVD of the
weights and input data, and thus avoid recomputing the SVD entirely for each
update.
The computational overhead has limited our experiments in this work to
smaller architectures, or variants of large architectures with smaller dimension
sizes. In future work, we would like to expand the analysis to one or two larger
scale architectures to provide principled insights into the dynamics of these
models; however, for the sake of surveying many model types in this work we
have kept the scope smaller for scalability.
7Figure 1: Differences in Auto-Differentiation Spectra Dynamics for the first 4
classesintheMNISTdataset,trainedwithvariousarchitecturesandtaskswith
a Multi-Layer Perceptron.
(a) MLP Autoencoder with hidden dim 32 and ReLU activations
(b) MLP Classifier with hidden dim 32 and ReLU activations
8(c) MLP Autoencoder with hidden dim 32 and Sigmoid activations
(d) MLP Autoencoder with hidden dim 32 and Tanh activations
9(e) MLP Autoencoder with hidden dim 8 and ReLU activations
(f) MLP Autoencoder with hidden dim 64 and ReLU activations
10(g) Significant spectral differences between groups 0 and 3: MLP Autoencoder with
hidden dim 32 and ReLU activations
(h)Significantspectraldifferencesbetweengroups0and3: MLPClassifierwithhidden
dim 32 and ReLU activations
Figure 1: Differences in Auto-Differentiation Spectra Dynamics for the first 4
classesintheMNISTdataset,trainedwithvariousarchitecturesandtaskswith
a Multi-Layer Perceptron.
11Figure 2: Differences in Auto-Differentiation Spectra Dynamics for the first 4
classesintheMNISTdataset,trainedwithvariousarchitecturesandtaskswith
a 2D CNN.
(a) CNN2D Autoencoder with hidden dim 8 and ReLU activations
12(b) CNN2D Classifier with hidden dim 8 and ReLU activations
13(c) CNN2D Autoencoder with hidden dim 8 and Sigmoid activations
14(d) CNN2D Autoencoder with hidden dim 8 and Tanh activations
15(e) CNN2D Classifier with hidden dim 8 and Sigmoid activations
16(f) CNN2D Classifier with hidden dim 8 and Tanh activations
17(g)Significantspectraldifferencesbetweengroups0and3: CNN2DAutoencoderwith
hidden dim 8 and ReLU activations
(h) Significant spectral differences between groups 0 and 3: CNN2D Classifier with
hidden dim 8 and ReLU activations
Figure 2: Differences in Auto-Differentiation Spectra Dynamics for the first 4
classesintheMNISTdataset,trainedwithvariousarchitecturesandtaskswith
a 2D CNN.
18Figure 3: Differences in Auto-Differentiation Spectra Dynamics for the first 4
classes in the Sinusoid data set, trained with various architectures and tasks
with an RNN
(a) RNN Autoencoder with hidden dim 32 and ReLU activations
19(b) RNN Classifier with hidden dim 32 and ReLU activations
20(c) RNN Autoencoder with hidden dim 32 and Sigmoid activations
21(d) RNN Autoencoder with hidden dim 32 and Tanh activations
22(e) RNN Autoencoder with hidden dim 8 and ReLU activations
23(f) RNN Autoencoder with hidden dim 64 and ReLU activations
24(g) Significant spectral differences between groups 0 and 3: RNN Autoencoder with
hidden dim 32 and ReLU activations
(h)Significantspectraldifferencesbetweengroups0and3: RNNClassifierwithhidden
dim 32 and ReLU activations
Figure 3: Differences in Auto-Differentiation Spectra Dynamics for the first 4
classes in the Sinusoid data set, trained with various architectures and tasks
with an RNN
25Figure4: DifferencesinAuto-DifferentiationSpectraDynamicsontheFSLdata
set,trainedwithvariousarchitecturesandtaskswithaMulti-LayerPerceptron.
(a) MLP Autoencoder with hidden dim 32 and ReLU activations
26(b) MLP Classifier with hidden dim 32 and ReLU activations
27(c) MLP Autoencoder with hidden dim 32 and Sigmoid activations
28(d) MLP Autoencoder with hidden dim 32 and Tanh activations
29(e) MLP Autoencoder with hidden dim 8 and ReLU activations
30(f) MLP Autoencoder with hidden dim 64 and ReLU activations
31(g)SignificantspectraldifferencesbetweengroupsSZandHC:MLPAutoencoderwith
hidden dim 32 and ReLU activations
(h) Significant spectral differences between groups SZ and HC: MLP Classifier with
hidden dim 32 and ReLU activations
Figure4: DifferencesinAuto-DifferentiationSpectraDynamicsontheFSLdata
set,trainedwithvariousarchitecturesandtaskswithaMulti-LayerPerceptron.
32Figure5: DifferencesinAuto-DifferentiationSpectraDynamicsontheCOBRE
data set, trained with various architectures and tasks with an LSTM.
(a) LSTM Autoencoder with hidden dim 32 and ReLU activations
33(b) LSTM Classifier with hidden dim 32 and ReLU activations
34(c) LSTM Autoencoder with hidden dim 32 and Sigmoid activations
35(d) LSTM Autoencoder with hidden dim 32 and Tanh activations
36(e) LSTM Autoencoder with hidden dim 8 and ReLU activations
37(f) LSTM Autoencoder with hidden dim 64 and ReLU activations
38(g)SignificantspectraldifferencesbetweenHC,SZandSex: LSTMAutoencoderwith
hidden dim 32 and ReLU activations
(h) Significant spectral differences between HC, SZ and Sex: LSTM Classifier with
hidden dim 32 and ReLU activations
Figure5: DifferencesinAuto-DifferentiationSpectraDynamicsontheCOBRE
data set, trained with various architectures and tasks with an LSTM.
39Figure6: DifferencesinAuto-DifferentiationSpectraDynamicsontheCOBRE
dataset,trainedwithvariousarchitecturesandtaskswithaBERTTransformer.
(a) BERT Autoencoder with hidden dim 32 and ReLU activations
40(b) BERT Classifier with hidden dim 32 and ReLU activations
41(c) BERT Autoencoder with hidden dim 32 and Sigmoid activations
42(d) BERT Autoencoder with hidden dim 32 and Tanh activations
43(e) BERT Autoencoder with hidden dim 8 and ReLU activations
44(f) BERT Autoencoder with hidden dim 64 and ReLU activations
45(g)SignificantspectraldifferencesbetweenHC,SZandSex: BERTAutoencoderwith
hidden dim 32 and ReLU activations
(h) Significant spectral differences between HC, SZ and Sex: BERT Classifier with
hidden dim 32 and ReLU activations
Figure6: DifferencesinAuto-DifferentiationSpectraDynamicsontheCOBRE
dataset,trainedwithvariousarchitecturesandtaskswithaBERTTransformer.
46Figure7: DifferencesinAuto-DifferentiationSpectraDynamicsontheCOBRE
data set, trained with various architectures and tasks with a 1D CNN.
(a) CNN1D Autoencoder with hidden dim 32 and ReLU activations
47(b) CNN1D Classifier with hidden dim 32 and ReLU activations
48(c) CNN1D Autoencoder with hidden dim 32 and Sigmoid activations
49(d) CNN1D Autoencoder with hidden dim 32 and Tanh activations
50(e) CNN1D Autoencoder with hidden dim 8 and ReLU activations
51(f) CNN1D Autoencoder with hidden dim 64 and ReLU activations
52(g) Significant spectral differences between HC, SZ and Sex: CNN1D Autoencoder
with hidden dim 32 and ReLU activations
(h) Significant spectral differences between HC, SZ and Sex: CNN1D Classifier with
hidden dim 32 and ReLU activations
Figure7: DifferencesinAuto-DifferentiationSpectraDynamicsontheCOBRE
data set, trained with various architectures and tasks with a 1D CNN.
53References
[1] M. Sundararajan, A. Taly, and Q. Yan, “Axiomatic attribution for deep
networks,”inInternationalconferenceonmachinelearning,pp.3319–3328,
PMLR, 2017.
[2] R.R.Selvaraju,M.Cogswell,A.Das,R.Vedantam,D.Parikh,andD.Ba-
tra, “Grad-cam: Visual explanations from deep networks via gradient-
based localization,” in Proceedings of the IEEE international conference
on computer vision, pp. 618–626, 2017.
[3] D.Baehrens,T.Schroeter,S.Harmeling,M.Kawanabe,K.Hansen,andK.-
R.Mu¨ller,“Howtoexplainindividualclassificationdecisions,”TheJournal
of Machine Learning Research, vol. 11, pp. 1803–1831, 2010.
[4] K. Simonyan, A. Vedaldi, and A. Zisserman, “Deep inside convolutional
networks: Visualising image classification models and saliency maps,”
arXiv preprint arXiv:1312.6034, 2013.
[5] S. Bach, A. Binder, G. Montavon, F. Klauschen, K.-R. Mu¨ller, and
W. Samek, “On pixel-wise explanations for non-linear classifier decisions
bylayer-wiserelevancepropagation,” PloS one, vol.10, no.7, p.e0130140,
2015.
[6] A.Shrikumar,P.Greenside,andA.Kundaje,“Learningimportantfeatures
throughpropagatingactivationdifferences,”inInternational conference on
machine learning, pp. 3145–3153, PMLR, 2017.
[7] D. Smilkov, N. Thorat, B. Kim, F. Vi´egas, and M. Wattenberg, “Smooth-
grad: removing noise by adding noise,” arXiv preprint arXiv:1706.03825,
2017.
[8] G.Montavon,S.Lapuschkin,A.Binder,W.Samek,andK.-R.Mu¨ller,“Ex-
plainingnonlinearclassificationdecisionswithdeeptaylordecomposition,”
Pattern recognition, vol. 65, pp. 211–222, 2017.
[9] W. Samek, A. Binder, G. Montavon, S. Lapuschkin, and K.-R. Mu¨ller,
“Evaluating the visualization of what a deep neural network has learned,”
IEEEtransactionsonneuralnetworksandlearningsystems,vol.28,no.11,
pp. 2660–2673, 2016.
[10] P.Sturmfels,S.Lundberg,andS.-I.Lee,“Visualizingtheimpactoffeature
attribution baselines,” Distill, vol. 5, no. 1, p. e22, 2020.
[11] A. Kapishnikov, T. Bolukbasi, F. Vi´egas, and M. Terry, “Xrai: Better at-
tributionsthroughregions,”inProceedingsoftheIEEE/CVFInternational
Conference on Computer Vision, pp. 4948–4957, 2019.
[12] S. Xu, S. Venugopalan, and M. Sundararajan, “Attribution in scale and
space,” in Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition, pp. 9680–9689, 2020.
54Figure8: DifferencesinAuto-DifferentiationSpectraDynamicsontheCOBRE
data set, trained with various architectures and tasks with a 3D CNN.
(a) CNN3D Autoencoder with hidden dim 32 and ReLU activations
55(b) CNN3D Classifier with hidden dim 32 and ReLU activations
56(c) CNN3D Autoencoder with hidden dim 32 and Sigmoid activations
57(d) CNN3D Autoencoder with hidden dim 32 and Tanh activations
58(e) CNN3D Autoencoder with hidden dim 8 and ReLU activations
59(f) CNN3D Autoencoder with hidden dim 64 and ReLU activations
60(g) Significant spectral differences between HC, SZ and Sex: CNN3D Autoencoder
with hidden dim 32 and ReLU activations
(h) Significant spectral differences between HC, SZ and Sex: CNN3D Classifier with
hidden dim 32 and ReLU activations
Figure8: DifferencesinAuto-DifferentiationSpectraDynamicsontheCOBRE
data set, trained with various architectures and tasks with a 3D CNN.
61[13] A. Kapishnikov, S. Venugopalan, B. Avci, B. Wedin, M. Terry, and
T. Bolukbasi, “Guided integrated gradients: An adaptive path method for
removing noise,” in Proceedings of the IEEE/CVF conference on computer
vision and pattern recognition, pp. 5050–5058, 2021.
[14] M. M. Rahman, N. Lewis, and S. Plis, “Geometrically guided saliency
maps,”inICLR 2022 Workshop on PAIR {\textasciicircum} 2Struct: Pri-
vacy, Accountability, Interpretability, Robustness, Reasoning on Structured
Data, 2022.
[15] M. M. Rahman, N. Lewis, and S. Plis, “Geometrically guided integrated
gradients,” arXiv preprint arXiv:2206.05903, 2022.
[16] A.M.Saxe,J.L.McClelland,andS.Ganguli,“Exactsolutionstothenon-
lineardynamicsoflearningindeeplinearneuralnetworks,” arXiv preprint
arXiv:1312.6120, 2013.
[17] A. M. Saxe, J. L. McClelland, and S. Ganguli, “A mathematical theory
of semantic development in deep neural networks,” Proceedings of the Na-
tional Academy of Sciences, vol. 116, no. 23, pp. 11537–11546, 2019.
[18] N.TishbyandN.Zaslavsky,“Deeplearningandtheinformationbottleneck
principle,” in 2015 ieee information theory workshop (itw), pp. 1–5, IEEE,
2015.
[19] R. Shwartz-Ziv and N. Tishby, “Opening the black box of deep neural
networks via information,” arXiv preprint arXiv:1703.00810, 2017.
[20] B. T. Baker, N. Lewis, D. Saha, M. A. Rahaman, S. Plis, and V. Calhoun,
“Information bottleneck for multi-task lstms,” in NeurIPS 2022 Workshop
on Information-Theoretic Principles in Cognitive Systems, 2022.
[21] N. Tishby, F. C. Pereira, and W. Bialek, “The information bottleneck
method,” arXiv preprint physics/0004057, 2000.
[22] A.M.Saxe,Y.Bansal,J.Dapello,M.Advani,A.Kolchinsky,B.D.Tracey,
and D. D. Cox, “On the information bottleneck theory of deep learning,”
JournalofStatisticalMechanics: TheoryandExperiment,vol.2019,no.12,
p. 124020, 2019.
[23] A. R. Mayer, D. Ruhl, F. Merideth, J. Ling, F. M. Hanlon, J. Bustillo,
and J. Canive, “Functional imaging of the hemodynamic sensory gating
responseinschizophrenia,”Humanbrainmapping,vol.34,no.9,pp.2302–
2312, 2013.
[24] P.Patel,P.Aggarwal,andA.Gupta,“Classificationofschizophreniaversus
normal subjects using deep learning,” in Proceedings of the Tenth Indian
Conference on Computer Vision, Graphics and Image Processing, pp. 1–6,
2016.
62[25] J. Oh, B.-L. Oh, K.-U. Lee, J.-H. Chae, and K. Yun, “Identifying
schizophrenia using structural mri with a deep learning algorithm,” Fron-
tiers in psychiatry, vol. 11, p. 16, 2020.
[26] Y. Zhu, S. Fu, S. Yang, P. Liang, and Y. Tan, “Weighted deep forest for
schizophrenia data classification,” IEEE Access, vol. 8, pp. 62698–62705,
2020.
[27] U. Mahmood, M. M. Rahman, A. Fedorov, N. Lewis, Z. Fu, V. D. Cal-
houn, and S. M. Plis, “Whole milc: generalizing learned dynamics across
tasks, datasets, and populations,” in Medical Image Computing and Com-
puterAssistedIntervention–MICCAI2020: 23rdInternationalConference,
Lima, Peru, October 4–8, 2020, Proceedings, Part VII 23, pp. 407–417,
Springer, 2020.
[28] Y. Du, Z. Fu, J. Sui, S. Gao, Y. Xing, D. Lin, M. Salman, A. Abrol, M. A.
Rahaman, J. Chen, et al., “Neuromark: An automated and adaptive ica
based pipeline to identify reproducible fmri markers of brain disorders,”
NeuroImage: Clinical, vol. 28, p. 102375, 2020.
[29] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
L. Kaiser, and I. Polosukhin, “Attention is all you need,” arXiv preprint
arXiv:1706.03762, 2017.
63