Neural Echos: Depthwise Convolutional Filters
Replicate Biological Receptive Fields
ZahraBabaiee PeymanM.Kiasari DanielaRus RaduGrosu
TUVienna,MIT UniversityofWaterloo MIT TUVienna
zbabaiee@mit.edu p2mohsen@uwaterloo.ca rus@mit.edu radu.grosu@tuwien.ac.at
Abstract
a) Samples of Trained convolutional kernels
Inthisstudy,wepresentevidencesuggestingthatdepth-
wise convolutional kernels are effectively replicating the
structural intricacies of the biological receptive fields ob-
served in the mammalian retina. We provide analytics of
trained kernels from various state-of-the-art models sub-
stantiating this evidence. Inspired by this intriguing dis-
covery, we propose an initialization scheme that draws in-
b) DoG model of the center-surround receptive fields
spirationfromthebiologicalreceptivefields. Experimental
analysisoftheImageNetdatasetwithmultipleCNNarchi-
tecturesfeaturingdepthwiseconvolutionsrevealsamarked
enhancement in the accuracy of the learned model when
initializedwithbiologicallyderivedweights. Thisunderlies
the potential for biologically inspired computational mod- Figure1.a)DepthwiseConvolutionalkernelstrainedonImageNet
dataset, andb)theDoGmodelofthebiologicalcenter-surround
els to further our understanding of vision processing sys-
receptivefieldswithdifferentcenter-to-surroundratios, andwith
temsandtoimprovetheefficacyofconvolutionalnetworks.
excitatorycenter(right)andinhibitorycenter(left), respectively.
Artificialkernelsmimicbiologicalcenter-surroundpatterns.
works [38] and Residual Networks [18] standardized the
1.Introduction
use of 3x3 kernels, optimizing for efficiency and training
speed. However,apivotalshiftemergedwiththeintroduc-
Convolutional Neural Networks (CNNs) [31], a main-
tionandpopularizationofdepthwiseconvolutions.
stay of modern artificial intelligence (AI), owe their fun-
damental design principles to insights drawn from neuro- Depthwiseconvolutionsintroducedanovelapproachto
science(NS)[24],particularlyourunderstandingofrecep- featureextraction,whereeachinputchannelisindividually
tive fields. A receptive field is the specific region of sen- convolvedwithitsownfilter,asopposedtostandardconvo-
soryspaceelicitingaresponsefromaneuronwhenstimu- lutionsthataggregateinformationacrossmultiplechannels.
lated[14,24]. Theconceptisdeeplyingrainedinthearchi- Thistechnique,exemplifiedbyarchitectureslikeMobileNet
tecture of the mammalian visual system, starting from the with its 3x3 depthwise convolutions, offers significant re-
retina. CNNsmimicthisstructurethroughtheiruseof’ker- ductionsincomputationaloverheadwithoutmarkedlysac-
nels’capableofrespondingtoaspecificpartoftheimage. rificing model accuracy. The advent of vision transform-
This convolution process mirrors the hierarchal, spatially ers and their patch-centric designs [8] further accentuated
invariantnatureofbiologicalvisionsystems, underscoring the exploration into depthwise convolution behaviors with
thedeepconnectionsbetweenthefieldsofNSandAI. largerkernelsizes,reinforcingtheiruniqueabilitytomani-
Therealmofconvolutionalneuralnetworks(CNNs)has feststructuredpatterns.
witnessed remarkable evolutionary phases since its incep- The cornerstone of visual processing in numerous reti-
tion. Initialarchitectures,suchasAlexNet[27],introduced nal cell types, including the intricate network of ganglion
in 2012, focused on varying kernel sizes to capture image neurons, is the principle of center-surround antagonism, a
features. Asthefieldmatured,architectureslikeVGGnet- mechanismestablishedinthereceptivefieldofneurons,as
4202
naJ
81
]VC.sc[
1v87101.1042:viXraCenter
Difference
Surround
γ = 0.2 γ = 0.4 γ = 0.6 γ = 0.8
Figure3. Size9DoGkernelswithinhibitory(top)andexcitatory
(buttom) centers, with different ratios of the center-surround ra-
diuses(γ).
a) Receptive field with On center b) Receptive field with Off center covery underscores not only the computational advantages
ofdepthwiseconvolutionsbutalsotheirpotentialtomirror
Figure2.A“difference-of-Gaussians”isusedtomodelaneuron’s
biologically-inspired patterns, reaffirming the value of re-
sensitivitytolightatvariouspositionsontheretina. Thismodel
thinking standard convolution operations in modern deep-
comprisestwoGaussianfunctions-anarrow,positiveone,repre-
learningparadigms.
sentingthestimulatorycenter,andawide,negativeone,indicating
Taking cues from these resemblances, we suggest a
thesuppressivesurround,fortheneuronswithanexcitatorycenter,
andtheotherwayaroundfortheoneswithaninhibitorycenter. center-surroundinitializationprocedurefordepthwisecon-
volutional kernels. Our experiments on ImageNet dataset
with different models revealed that networks when initial-
early as in the retina [9,24,29]. This mechanism stems
izedusingourbiologically-inspiredmethodology,displaya
from lateral inhibitory connections and is perpetuated by
marked increase in accuracy. Specifically, models initial-
neuronsinhighervisualprocessingcenters,namelythelat-
ized by our method gain up to more than two percent ac-
eralgeniculatenucleusandthevisualcortex[22].
curacyontheImageNetdataset. Despitethesenotableim-
Thecenter-surroundantagonismplaysavitalroleinthe
provements,theprimarypurposeofthispaperisnotsolely
primate visual system, assisting in complex tasks such as
to underscore performance enhancements. Rather, we aim
edge detection, figure-background segregation, depth, and
toemphasizetheintriguingdiscoverythatartificialkernels
objectperception,thatremainconsistentacrossvariousvi-
emulatetheirbiologicalcounterpartswithoutexplicitsuper-
sualcues. Importantly,thisarchitecturehastwokeyconfig-
vision. Ourresultsdemonstratethesignificantpotentialof
urations: excitatory- and inhibitory-center receptive fields,
biologicallyinspiredcomputationalmodelsinenrichingour
respectively[37,44]. Intheformerconfiguration,ganglion
comprehensionofvisionprocessingsystemsandenhancing
cellsareexcitedbylightfallingonthecenteroftherecep-
theperformanceofartificialneuralnetworks.
tive field and inhibited by light falling on the surrounding
area. Conversely,inthelatterconfiguration,cellsareinhib-
2.RelatedWork
ited by light at the center and excited by light in the sur-
rounding area. This design enhances contrast and aids in Depth-wise Convolutions. The evolution of convolu-
edgedetection[9,24]. tionalneuralnetworkshasbeenmarkedbytheintroduction
Classical NS models frequently employ receptive fields andadaptationofdiverseconvolutionoperations. Notably,
featuring center-surround antagonism, typically realized depthwise convolutions, where each input channel is con-
through a Difference of Gaussians (DoG) function, which volved with its distinct filter, have gained traction. With
creates an excitatory peak at the receptive field’s center the recent surge of modern enhanced CNN architectures,
counterbalancedbyaninhibitorysurround[10,23]. especially in the wake of the transformative impact of vi-
In our investigations, we unearthed a remarkable paral- sion transformers, many models are now favoring depth-
lelbetweenthetrainedkernelsofdepthwiseconvolutionsin wiseconvolutionswithlargekernelsovertraditionalregular
variousmodelsandbiologicalreceptivefields: asignificant convolutions. Depthwise convolutions gained prominence
quantity of them echoed the center-surround pattern seen with the introduction of the MobileNet architecture [20],
in biological receptive fields. Intriguingly, such patterns whichshowcasedtheirefficacyincraftinglightweightmod-
wereexclusivelyobservedindepthwiseconvolutions,elud- els tailored for mobile and embedded vision applications.
ing their regular convolution counterparts. In Figure 1 we WiththeresurgenceofthemodernCNNarchitecturesafter
provide a comparative demonstration of the trained depth- the introduction of vision transformers, many models use
wise kernels and the NS-based model of center-surround depthwiseconvolutionsintheirblocks[32,35,41,42].
kernels,highlightingtheirnoteworthysimilarities.Thisdis- Bio-inspired Models. A considerable volume of re-(a)ConvNeXtsmall,kernel7×7 (c)ConvNeXtV2tiny,kernel7×7 (e)Hornetsmall,kernel7×7 (g)ConvMixer-512,kernel7×7
(b)EfficientNet,kernel3×3 (d)MobileNetV3,kernel3×3 (f)MobileNetV3,kernel5×5 (h)ConvMixer-1024,kernel9×9
Figure4. Randomsamplesfromdepth-wiseconvolutionsofvariousmodelswithdifferentkernelsizes,trainedontheImageNetdataset.
Trainedkernelsshowconsiderablerepeatingpatterns,manyofthemfeaturingacenter-surroundstructure.
searchhasaimedtoincorporateinsightsfromNSintocom- tried to incorporate center-surround receptive fields into
putervisionsystems[25,30,47]. Initialvisionmodelswere CNNs by integrating convolutional layers equipped with
significantly influenced by NS and psychology. In recent fixed kernels into the input feature maps. Evidence indi-
times,therehavebeensubstantialadvancesinbothNSand cates that this modification enhances the network’s perfor-
AI,especiallyincomputervision. However,themajorityof manceandresilience,particularlywithrespecttovariations
contemporary networks, are only loosely based on the vi- inlightingconditionsandinputnoise[2,15].
sual system, and cross-fertilization between the two fields
Initialization Methods. Kernel initialization methods
islessfrequentasintheearlydaysofAI.Thisisinspiteof
are crucial in training deep convolutional neural networks
thefactthatNScontinuestobeavitalsourceofinnovative
(CNNs) and have been the focus of significant research.
ideasthatfueladvancementsinAI [4,16].
Theinitializationofconvolutionalkernelsdirectlyimpacts
The development of AI models that closely resemble theconvergencespeedandthefinalperformanceofCNNs.
theirbiologicalcounterpartsandthatincorporateadvances Traditional initialization methods include Glorot and Ben-
inNSofferstwoprimaryadvantages. Firstly, NScanbea gio’suniforminitialization[11],Heetal.’sKaiminginitial-
fertile source of inspiration for designing new models and ization [17], and LeCun’s Normal initialization. Mishkin
enhancing existing ones. This holds true both in isolation and Matas introduced the LSUV initialization, optimized
andintandemwiththecomputationalandmathematicalad- for deep architectures [33]. Hanin and Rolnick identified
vancements underpinning new models. Secondly, NS can and addressed initialization failure modes in deep ReLU
offer validation for existing models and methodologies in networks [12]. Arpit et al. proposed a robust initializa-
theAIdomain. Anexampleofthisistheresidualconnec- tionforweightnormalizedandResNets,demonstratingen-
tions found in pyramidal cells within the cerebral cortex. hancedgeneralizationindeeperstructures[1]. Thesemeth-
TheseconnectionsenableinputfromlayerItoreachcorti- ods usually generate weights from a Gaussian or uniform
callayerVIneurons,bypassingintermediarylayers[16,40]. distribution with zero mean and a certain standard devia-
tion. Theseinitializationmethodsaimtomaintainareason-
Center-SurroundReceptiveFields. TheNeocognitron
able activation variance across layers to avoid the issue of
model,proposedbyFukushima,holdsakeypositioninthe
vanishingorexplodinggradients.
historyofneuralnetworksandmachinelearning,asoneof
theearliestexamplesofaCNN.Inspiredbythepioneering Kaiming initialization, also known as He initializa-
workofHubelandWieselonthevisualcortexofcats[22], tion [17], is a widely adopted technique for initializing
the Neocognitron model was designed to mimic the hier- weightsinconvolutionalneuralnetworks. Kaiminginitial-
archical structure of the visual system in mammals. It in- ization addresses the vanishing/exploding gradients prob-
cluded a contrast-extracting preprocessing layer, reminis- lem by initializing weights in a way that the variance of
cent of the On-Off ganglion neurons, as well as inhibitory theoutputsofeachconvolutionallayerisapproximatelythe
surround connections, mirroring the surround modulation sameasthevarianceofitsinputs. Specifically,theweights
observedinthevisualcortex[10].Morerecentstudieshave areinitializedfromaGaussiandistributionwithameanof(a)ConvNeXtsmall,kernel7×7 (b)ConvNeXtV2tiny,kernel7×7 (c)Hornetsmall,kernel7×7 (d)ConvMixer-512,kernel7×7
Figure 5. Kernels randomly selected from each K-Means cluster (top) and their respective cluster averages (bottom). Right clusters
resembleexcitatory-centeredfieldsandmiddleclustersresembleinhibitory-centered.Clustersontheleftcontainallotherpatterns,resulting
intheiraveragebeingcluttered,implyingthedominanceinthefirsttwoclusterpatterns.
(cid:112)
zeroandastandarddeviationof 2/n,wherenisthenum- Figure 4 provides a representative selection of randomly
berofinputstotheneuron. Thistechniquehasbeenshown chosensamplesfromthetrainedkernelsofeachofthemod-
to significantly improve the speed of convergence in deep els utilizing depth-wise convolutions, and Figure 6 shows
neuralnetworksandtostabilizethetrainingprocess. the same for models with regular convolutions. Upon in-
spectionofthesekernels,wecanidentifyrecurringpatterns
3.Methods
among the depthwise convolutions. We observed similar
patterns in other variants of these models trained on Ima-
In the following section, we delve into the specifics of
geNet, too. However, kernels of regular convolutions do
ourproposedmethodology.Webeginbyconductingacom-
notshowsuchobservablepatterns
prehensive analysis of the trained kernels of various state-
of-the-art(SOTA)modelsontheImageNetdataset.Wepro-
vide detailed visual illustrations coupled with quantitative
results, to validate the presence of the center-surround an-
tagonisminaconsiderableportionofthekernels.
Next,wemoveontodiscusstheDifferenceofGaussian
(DoG) function. This function serves as a mathematical
model of the center-surround receptive fields found in bi-
ologicalvisualsystems. Thismathematicalmodelprovides
uswithafoundationfordesigninganinitializationscheme
(a)ResNet50 (b)VGG16 (c)DenseNet201
thatmimicsthesebiologicalstructures.
Finally, we describe our novel kernel initialization ap- Figure6. Randomsamplesfromregularconvolutionsofpopular
proach, which leverages the DoG function. We detail the models,trainedontheImageNetdataset. Unlikedepthwisecon-
volutions,kernelsfromregularconvolutionsdonothavevisually
processofapplyingthisfunctiontogeneratekernelweights
observablerepeatedpatterns.
thatresemblethecenter-surroundantagonismofbiological
vision systems. The ultimate goal is to provide the model One particularly notable pattern in depthwise kernels is
with a starting point that is already attuned to the kind of the center-focused structure of many of them. Interest-
spatial feature mappings it would otherwise have to learn ingly, these center-focused kernels can be broadly divided
throughmanyepochsoftraining. into two categories. The first category includes kernels
withlargerweightvaluesconcentratedintheircenter. Con-
3.1.InspectingtheTrainedKernels
versely,thesecondcategoryconsistsofkernelswithlarger
Inthissection,weconductadetailedexplorationofthe weightvaluespopulatingtheirsurround.
trained kernels of the regular and depthwise convolutions These discovered patterns bear striking resemblance to
indifferentmodels. Specifically,weexamineVGG16[38], thewell-studied‘center-surroundantagonism’foundinthe
ResNet50 [18], DenseNet201 [21], MobilenetV3 [19], Ef- mammalianvisualsystemwhichwediscussedpreviously.
ficientNet [39], ConvNeXt [32], ConvNeXtV2 [42], Hor- Nevertheless, it’s worth noting that not all filters from
net[35],andConvMixer[41]. Forouranalysis,weutilized our models exhibit this center-surround pattern. We
the pre-trained versions of these models, sourced directly observed other filters possessing different, non-center-
fromPytorchortheirrespectiveofficialcoderepositories. surround patterns, but their occurrence was less frequent
In order to visually inspect the learned patterns within compared to the center-surround ones. This differential
thesefilters,wehaveincludedFigures4and 6inourpaper. frequency points to the significance and prevalence of theonce inspecting the kernels themselves, we can not distin-
guishthepatterns(SeeFigure6).
(a)ResNet50 (b)VGG16 (c)DenseNet201
Figure7.Clustersof3×3kernelsofregularconvolutions
center-surround pattern in the learned representations of (a)MobileNetV3 (b)EfficientNet
depthwisekernelsinthesemodels.
Figure8.Clustersof3×3kernelsofdepthwiseconvolutions
Toattainamoreanalyticcomprehensionofthevarying
kernelpatterns,weleverageastraightforwardclusteringal- The distribution of the kernels across each cluster of
gorithm to group all the kernels. Our hypothesis suggests ConvNeXt compared to ConvNeXtV2 variants is demon-
that the two center-surround groups are the most signifi- stratedbythehistogramsshowninFigure9.TheConvNeXt
cantpatterns,thuswesetthenumberofclusterstothreein model faced challenges with feature collapse, manifesting
theclusteringalgorithm. Thischoiceistodiscernwhether as redundant activations across channels. In response, the
thealgorithmcaneffectivelycategorizethekernelsintotwo ConvNeXtV2architectureintroducestheGlobalResponse
distinct center-surround clusters, and a third cluster com- Normalization (GRN) layer, promoting feature diversity.
prisingthelesscommonpatterns. This enhancement, coupled with advanced self-supervised
For a successful execution of clustering, we took some techniques, positions ConvNeXtV2 as a marked improve-
preparatory steps. First, we normalized all kernels to have ment over its predecessor in visual recognition tasks. We
their weight values lie within the range of 0 and 1, utiliz- noteasignificantreductioninthenumberofkernelswithin
ingmin-maxencoding. Thisstepisessentialtoensurethe the third cluster of the improved ConvNeXtV2 when con-
numericalstabilityandeffectivenessoftheclusteringalgo- trasted with its predecessor, ConvNeXtV1. This is an in-
rithm. Following normalization, we flattened each kernel teresting observation that underscores the pivotal role of
intoavector,tofittheinputrequirementofthek-meansal- center-surroundinenhancingthemodel’sperformance.
gorithm. Withthetransformeddata,wewerefinallyableto AsdetailedinFigure10,weobservedaremarkablecon-
runthek-meansalgorithm[13]withak-valueof3. sistency in the proportions of filter clusters across various
models, despite changes in model sizes, kernel sizes, and
After clustering, we visually inspected the kernels be-
datasetsizes.ThistrendwasevidentinmodelssuchasCon-
longing to each cluster, by presenting randomly selected
vNeXt, ConvNeXtV2, and Hornet, where different model
samples in Figure 5. For each cluster, we also depict the
sizes were analyzed. For MobileNet and ConvMixer, we
average of all kernels belonging to it. This helps in better
extendedthisanalysistoincludevariationsinkernelsizes.
seeingtheprominentpatternofeachcluster. Thefirstclus-
Additionally, the training of MobileNet on both ImageNet
terpredominantlycontainedkernelsakintotheexcitatory-
1K and 21K datasets did not significantly alter the pro-
center receptive fields, while the second cluster closely
portion of filter clusters. These findings suggest an inher-
resembled inhibitory-center receptive fields. As for the
ent stability in the distribution of filter types within each
third cluster, the kernels exhibited some degree of center-
model category, indicating that the architectural design of
focused structures but lacked the precise characteristics of
these models plays a more critical role in determining fil-
center-surround receptive fields. Examination of the aver-
ter distribution than the scale of the model or the size of
agekernelwithineachclusterrevealsapronouncedcenter-
thedataset. Thisinsightcouldhaveimplicationsforunder-
surroundstructureinthefirsttwoclusters,whereasthethird
standingthescalabilityandadaptabilityofthesemodelsto
cluster exhibits a more dispersed pattern. This observa-
differentsizesandtypesofdatasets.
tion further underscores that even an unbiased clustering
approach distinctly recognizes the prominence of center-
3.2.FormulationofCenter-SurroundKernels
surroundpatternsrelativetoalternativepatterns.
Figures 7 and 8 show the discovered clusters of the Thecomputationofcenterandsurroundweightscanbe
models with 3 × 3 kernels with regular and depthwise accomplishedusingadifferenceoftwoGaussianfunctions
convolutions, respectively. As one can see, the models (DoG).RepresentedinCartesiancoordinates(CC),withthe
with small depthwise kernels still have prominent center- CCorigindesignatedasthereceptivefield’scenter,theDoG
surroundclusters, incontrasttotheoneswithregularcon- canbeformulatedaspresentedinRodieck’swork[36]:
volutions. Only in Resnet50, the average kernels of one
cluster is similar to the center-surround pattern. However, DoG(x,y)=K
1e−x2 σ+ 1y2
−K
2e−x2 σ+ 2y2
(1) 1 X P E H U  R I  & O X V W H U V  D Q G  $ F F X U D F \  I R U  ( D F K  0 R G H O      
 & O X V W H U
     
 ( [ F L W D W R U \      
  
 , Q K L E L W R U \
      2 W K H U V      
     
  
    
     
  
    
     
    
 & R Q Y H 1 H [ W  W L Q \  & R Q Y H 1 H [ W 9   W L Q \  & R Q Y H 1 H [ W  E D V H  & R Q Y H 1 H [ W 9   E D V H  & R Q Y H 1 H [ W  O D U J H  & R Q Y H 1 H [ W Y   O D U J H
     0       0       0       0        0        0 
 0 R G H O  6 L ] H  D Q G  9 H U V L R Q
Figure9. HistogramsoftheclustersdiscoveredinConvNeXtmodelvariants,alongsidetheirV2counterpart,includingthetestaccuracy
ofeachmodel.TheimprovedV2versionshaveaconsiderablylowernumberofkernelsintheir”others”cluster.
whereitholdstruethatK ,>,K andσ ,>,σ [3]. can enhance the performance of these models. Addition-
1 2 2 1
We use the DoG model proposed by Petkov and ally, this approach might streamline the convergence pro-
Kruizinga [28,34], which defines the difference of Gaus- cess during training. This method potentially serves as a
sians for the center and surround kernels. This model en- bridge,linkingbiologicalvisionmodelswiththeirartificial
ables us to calculate the variances analytically, given the counterparts,therebyenablingthelattertobenefitfromthe
kernelsizeandtheratioofthecentertosurround[34]: intrinsicefficiencyoftheformer.
In our approach, we begin by initializing the weights
DoG σ,γ(x,y)=
A γ2ce−x 22 γ+ 2σy 22
−A
se−x2 2+ σ2y2
(2)
o tef ctt uh re esde wp it th h-w this ee wc eo in gv ho tslu dti eo rn ivek dern fre ol ms in theth pe rem vo iod ue sl lyarc dh isi-
-
cussed DoG function. This is a crucial step that enables
In this formula, γ<1 stipulates the ratio between the us to effectively incorporate the center-surround receptive
center radius r and the surround. The coefficients A c and field structure into the model. To achieve a balanced rep-
A s aredeterminedbyrequiringthesumofallpositiveval- resentation of both inhibitory and excitatory centers, each
ues in Equation 2 to be equivalent to the negative values. kernelisassignedacentertype–eitherinhibitoryorexci-
These are then normalized such that their sum equals 0.5 tatory–withanequalprobabilityof50%. Thisensuresthat
and-0.5,respectively.Whileinthecontinuousinfinitecase, bothtypesofcentersarerepresentedinapproximatelyequal
the coefficients A c and A s are equal, in the discrete finite proportionsacrossthekernels,thusmaintainingabalanced
case,thevaluesofA candA sremainremarkablysimilar. interactionoftheseopposingneuralbehaviorsinthemodel.
By setting DoG σ,γ(x,y) = 0, σ can be calculated im- Additionally, weintroducevariabilityintheratioofthe
mediately as shown in Equation 3 below, where k is the centertothesurroundforeachkernel. Todothis,weselect
kernelsize,foranyarbitraryvaluesofkandγ: the ratio from a uniform distribution. This introduces an
element of randomness to the model, ensuring that a wide
(cid:115)
k 1−γ2 variety of center-to-surround ratios are represented in the
σ ≈ (3)
4 −lnγ kernels. Consequently,thisdesignenablesthemodeltoac-
commodate and respond to a broad range of spatial scales
InFigure2,weshowtheDoGfunctionsusedtomodelthe intheinputdataandaddsawidervarietyofweightvalues
center-surroundreceptivefields,witheitherexcitatoryorin- totheinitialization.
hibitorycenters,respectively. Figure3showstheDoGkernelsofsize9withdifferent
ratiosofthecentertosurroundvaryingfrom0.2to0.8. As
3.3.Center-SurroundInitialization theratioincreases,thecentergetslarger.
Observingtherepetitivepatternsexhibitedinthedepth-
4.Experiments
wise kernels trained on ImageNet, and noting their resem-
blance to center-surround receptive fields, we propose a Here,wedetailourimplementation,coveringmodelse-
novelmethodologyforkernel-weightinitialization.Ourhy- lectionandtraining. Wethenshowcaseresultsfromtesting
pothesis is based on the assumption that by offering the our initialization on ConvNeXt, HorNet, and ConvMixer
modelkernelsaninitializationthatalignswithpatternsnot models using Cifar10 [26] and ImageNet [6]. Lastly, we
only found in nature but also in fully-trained models, we provideanablationstudyonourapproach’sfacets.
 U H W V X O &  K F D H  I R  U H E P X 1
     \ F D U X F F $ 3 H U F H Q W D J H  R I  & O X V W H U V  I R U  ( D F K  0 R G H O
 & O X V W H U
 ( [ F L W D W R U \
  
 , Q K L E L W R U \
 2 W K H U V
  
 
 & R Q Y H 1  & H  R [ W  Q   Y W L  H Q  1 \  H [  & W   R V  Q Y P  H D O O  1 H  & [ W  R   Q E  Y D  H V H  1  & H [  R W   Q O  Y D  H U J  1 H  H [ W  [ O D U J H  & R Q Y H 1  & H  R [ W  Q 9  Y   H  W  1 L  H Q  [ \  & W  R 9  Q   Y   H E D  1 V  H H  [ W Y   O D U J H  +   R U Q H W  W L  + Q  R U \  Q H W  V P  + D  R O O  U Q H W  E D  + V  R H  U Q H W  O D U J H  0 R E   L O  /   H   D U 1   J H  / W  H  0   D 9    R  U     E  J   L   O  H    H    1   H W  .  0  9    R     E     L   O  /   H   D U 1   J H  / W  H  0   D 9    R  U     E  J   L   O  H    H    1   H W  .  9            & R Q Y    0   L [ H  & U   R   Q   Y    0   L [ H U      
 0 R G H O  9 H U V L R Q
Figure10. FilterProportionsbyClusterinVariousModels: Weobservealmostconsistentproportionsoffilterclustersacrossmodelsof
differentsizes,kernelsizes,anddatasetsizeswithineachmodelcategory.
4.1.ImplementationDetails substantial. This was particularly evident in the improve-
mentexceeding2%fortheConvMixer-512withkernel-size
For the ImageNet evaluations, we employed ConvNeXt
9×9.
tiny, HorNet Tiny, and ConvMixer-512. ConvNext tiny
and HorNet tiny contain 18 and 25 blocks respectively, First, we present the performance metrics for the Con-
each composed of one depthwise and two pointwise con- vNeXttinymodel,utilizinga7×7kernelsizeandtrained
volutions. The ConvMixer models incorporate 512 filters, over 50 epochs. Employing the conventional Kaiming ini-
within each depthwise convolutional layer and comprise tialization, the model achieved an accuracy of 76.17%.
mixerblockscomposedofdepthwiseandpointwiseconvo- However, when initialized with our proposed method, the
lutions. Foreachmodel,weusedthetrainingsettingspro- accuracyexhibitedaslightenhancement,reaching76.74%.
posedintheoriginalpaper. Ourtrainingregimenincluded
ThesubsequentrowprovidestheresultsfortheHorNet
theuseofasuiteofdataaugmentationtechniques,namely
tiny model under analogous conditions: a kernel size of
RandAugment [5], mixup [45], CutMix [43], and random
7 × 7 and a training duration of 50 epochs. The perfor-
erasing[46],inadditiontogradientnormclipping. Weem-
mancewiththeKaiminginitializationstoodat76.06%. In
ployedtheAdamoptimizer[7]forthetrainingprocess.
contrast, our innovative initialization method yielded a su-
Acrossallexperimentalevaluations,weadheredtoabal-
periorresult,registeringanaccuracyof76.40%.
ancedstrategyforourkernelinitialization,assigninghalfof
the kernels with excitatory centers and the other half with Finally, we explored the effectiveness of our method
inhibitory centers. Moreover, to determine the value of γ, with larger kernel sizes using the ConvMixer-512 model.
representing the ratio of center to surround, we utilized a Specifically, we employed a kernel size of 9 in the Con-
uniformdistributioninside[0,0.5].Thischoiceismotivated vMixerarchitecture. Thisapproachresultedinasignificant
by our observations derived from the trained filters, which improvement,withanaccuracyincreaseof2.34%,thereby
showedusthatthecentersareusuallyquitesmall. affirming even better efficacy of our method when applied
tomodelswithlargerkernelconfigurations.
4.2.Results
Cifar10. WeevaluatedourinitializationonCifar10with
Inthefollowing,wedescribeourexperimentalresultson
models with kernel sizes of 5, 7, and 9. However, across
ImageNetandCifar10datasets. Wecompareourresultsto
differentruns,weobservedlittletonoimprovements. This
theKaiminginitialization,whichisthedefaultinitialization
may be primarily attributed to the lack of discernible pat-
methodusedinmostofthemodels.
terns in filters trained on Cifar10, in contrast to their Ima-
ImageNet. In Table 1 we present the empirical results geNetcounterparts.Thisdisparityislikelyrootedinthesig-
ofourexperimentsonImageNet. Acrossallconfigurations, nificant size difference between the datasets, both in num-
ourinitializationconsistentlyoutperformstheKaimingini- ber of classes and image sizes. Clusters of kernels trained
tialization, with improvements ranging from marginal to onCifar10aredepictedinFigure11.
     U H W V X O &  K F D H  I R  H J D W Q H F U H 3Table1.ResultsofDepthwiseConvolutionalModelsonImageNetwithdifferentsettingsandinitializations.
Model kernelSize KaimingInitialization OurInitialization
ConvNeXttiny 7×7 76.17 76.74
HorNettiny 7×7 76.06 76.40
ConvMixer-512 9×9 64.00 66.34
5.ConclusionsandFutureWork
Conclusions. This paper has delved into an intriguing
discoveryofcenter-surroundpatternsindepthwiseconvolu-
tionalkernels,highlightingafascinatinginterplaybetween
artificial neural networks and natural vision systems. We
capitalizedonthisfindingbyintroducinganovelinitializa-
tionstrategyfordepthwisekernels, incorporatingtheprin-
ciplesoftheDoGmethod,typicallyutilizedinbio-inspired
Figure 11. Clusters from kernels trained on the Cifar10 dataset vision models. This unique approach taps into the center-
(left)andtheaverageofeachcluster(right). surroundantagonismpropertyofretinalganglioncells,of-
fering enhanced contrast sensitivity, mirroring the profi-
ciencyofbiologicalvisionsystems.
Table 2. Ablation on initialization settings with ConvMixer-512
withkernelsize9×9onImageNet. Theempiricalevidencefromourextensiveexperiments
on ImageNet firmly backs the efficacy of our proposed
Initialization Accuracy method. Compared to the widely used Kaiming initializa-
tion,ourtechniquedemonstratedanotableimprovementin
Kaiming 64.00
theaccuracyofthemodels. AsillustratedinFigure11,itis
Ours,γ ∈(0,1),OnandOffCenteres 65.20
alsointerestingtoobservethatontheCifar10dataset,mod-
Ours,γ ∈(0,0.5),OnlyOnCenters 64.78
elsdonotseemtobeabletolearnbiologicalkernelssoef-
Ours,γ ∈(0,0.5),OnandOffCenteres 66.34
fectively. Inouropinion,thisisaresultofthesmallsizeof
their images (32×32 compared to 224×224 in ImageNet),
4.3.AblationStudy
andtheverylimitednumberoftheirclasses(10compared
to1000inImageNet).
To assess our initialization’s impact, we conducted an
FutureWork. Whiletheresultsobtainedarepromising,
ablation study on the ConvMixer model, as this model ex-
there’s still scope for further exploration. A promising di-
hibited the most significant improvement from our initial-
rection is to testour initialization method across a broader
ization method. The study, performed on the ImageNet
rangeofCNNs,potentiallyadvancingaubiquitousbiology-
dataset,isdetailedinTable2.
inspiredinitializationapproach.
Our baseline evaluation using Kaiming initialization
Furthermore,theprimaryaimofthispaperwastohigh-
achieved 64.00% accuracy. We applied our initialization,
lighttheresemblancebetweentrainedkernelsandtheirbi-
adjusting the DoG function parameters and the excita-
ological counterparts. We have not yet embarked on any
tory/inhibitory center arrangement. First, we sampled γ
form of hyperparameter search to fine-tune the parameters
from a uniform distribution between (0,1) and used both
of our initialization method. Parameters like the range for
On (excitatory) and Off (inhibitory) centers. This yielded
γ, the proportion of excitatory and inhibitory kernels, ini-
animprovedaccuracyof65.20%.
tializationspecifictoeachlayer,andthebalanceofpositive
Next,wenarrowedtherangeofγ to(0,0.5),whileonly andnegativevaluesintheDifferenceofGaussiansfunction
utilizingOncenters.Theresultingaccuracy,thoughslightly have been left unexplored. Potentially, these factors could
lowerat64.78percent,stillexceededthebaselineKaiming betweakedforoptimalperformance.
initialization. Thissuggeststhattheselectionofγ andcen- Finally, this paper has not explored the patterns in the
tertypesbothplaysignificantrolesintheperformance. ”Others”clusterofFigure9. Itisverylikelythatthesepat-
Finally, maintaining γ in the (0,0.5) range, we reintro- ternsarelinkedtobiologicalneuralprocessing,too.
ducedbothOnandOffcentersintoourmodel.Thisresulted
6.Acknowledgements
inthehighestobservedaccuracyof66.34%. Itisclearfrom
this ablation study, that the selection of γ and the type of Z.B.issupportedbytheDoctoralCollegeResilientEm-
centers (On or Off) significantly influence the model per- beddedSystems,whichisrunjointlybytheTUWien’sFac-
formance. ultyofInformaticsandtheUASTechnikumWien.References [14] H. K. Hartline. The receptive fields of optic nerve
fibers. American Journal of Physiology-Legacy Content,
[1] Devansh Arpit, V´ıctor Campos, and Yoshua Bengio. How
130(4):690–699,1940. 1
toinitializeyournetwork? robustinitializationforweight-
[15] Hosein Hasani, Mahdieh Soleymani, and Hamid Aghajan.
norm &amp; resnets. In H. Wallach, H. Larochelle, A.
Surround modulation: A bio-inspired connectivity struc-
Beygelzimer, F. d'Alche´-Buc, E. Fox, and R. Garnett, ed-
ture for convolutional neural networks. In H. Wallach, H.
itors, Advances in Neural Information Processing Systems,
Larochelle,A.Beygelzimer,F.d'Alche´-Buc,E.Fox,andR.
volume32.CurranAssociates,Inc.,2019. 3
Garnett,editors,AdvancesinNeuralInformationProcessing
[2] Zahra Babaiee, Ramin Hasani, Mathias Lechner, Daniela
Systems,volume32.CurranAssociates,Inc.,2019. 3
Rus, and Radu Grosu. On-off center-surround receptive
[16] DemisHassabis,DharshanKumaran,ChristopherSummer-
fields for accurate and robust image classification. In Ma-
field,andMatthewBotvinick. Neuroscience-inspiredartifi-
rinaMeilaandTongZhang,editors,Proceedingsofthe38th
cialintelligence. Neuron,95(2):245–258,2017. 3
InternationalConferenceonMachineLearning,volume139
[17] KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun.
ofProceedingsofMachineLearningResearch,pages478–
Delvingdeepintorectifiers:Surpassinghuman-levelperfor-
489.PMLR,18–24Jul2021. 3
manceonimagenetclassification,2015. 3
[3] M.R.Blackburn.ASimpleComputationalModelofCenter-
[18] KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun.
SurroundReceptiveFieldsintheRetina. TechnicalReport
Deep Residual Learning for Image Recognition. In Pro-
2454,OceanSurveillanceCenter,Feb1993. 6
ceedingsof2016IEEEConferenceonComputerVisionand
[4] RodneyBrooks,DemisHassabis,DennisBray,andAmnon
PatternRecognition,CVPR’16,pages770–778.IEEE,June
Shashua. Turing centenary: Is the brain a good model for
2016. 1,4
machineintelligence? Nature,482:462–3,022012. 3
[19] Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh
[5] EkinD.Cubuk,BarretZoph,JonathonShlens,andQuocV.
Chen, BoChen, MingxingTan, WeijunWang, YukunZhu,
Le. Randaugment: Practical automated data augmentation
RuomingPang,VijayVasudevan,QuocV.Le,andHartwig
withareducedsearchspace,2019. 7
Adam. Searching for mobilenetv3. In Proceedings of the
[6] J. Deng, W. Dong, R. Socher, L.J. Li, K. Li, and F. Li.
IEEE/CVF International Conference on Computer Vision
Imagenet: ALarge-ScaleHierarchicalImageDatabase. In
(ICCV),October2019. 4
IEEEComputerSocietyConferenceonComputerVisionand
[20] Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry
PatternRecognition,pages248–255,Miami,Florida,USA,
Kalenichenko, Weijun Wang, Tobias Weyand, Marco An-
June2009.IEEEComputerSociety. 6
dreetto,andHartwigAdam. Mobilenets: Efficientconvolu-
[7] P.K.DiederikandJ.Ba.Adam:AMethodforStochasticOp-
tionalneuralnetworksformobilevisionapplications.CoRR,
timization. InY.BengioandY.LeCun,editors,3rdInterna-
abs/1704.04861,2017. 2
tionalConferenceonLearningRepresentations,SanDiego,
CA,USA,May2015. 7 [21] GaoHuang,ZhuangLiu,LaurensvanderMaaten,andKil-
ian Q. Weinberger. Densely connected convolutional net-
[8] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,
works.InCVPR,pages2261–2269.IEEEComputerSociety,
Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,
2017. 4
MostafaDehghani,MatthiasMinderer,GeorgHeigold,Syl-
vainGelly,JakobUszkoreit,andNeilHoulsby. Animageis [22] D. H. Hubel and T. N. Wiesel. Receptive fields and func-
worth16x16words: Transformersforimagerecognitionat tionalarchitectureofmonkeystriatecortex. TheJournalof
scale,2020. 1 Physiology,195(1):215–243,1968. 2,3
[9] C. Enroth-Cugell and L. H. Pinto. Properties of the Sur- [23] Jorn-HenrikJacobsen, JanVanGemert, ZhongyuLou, and
round Response Mechanism of Cat Retinal Ganglion Cells ArnoldWMSmeulders. Structuredreceptivefieldsincnns.
andCentre-SurroundInteraction.TheJournalofPhysiology, InProceedingsoftheIEEEConferenceonComputerVision
220(2):403–439,Jan1972. 2 andPatternRecognition,pages2610–2619,2016. 2
[10] K.Fukushima. NeocognitronforHandwrittenDigitRecog- [24] E.R.Kandel,T.M.Jessell,J.H.Schwartz,S.A.Siegelbaum,
nition. Journal of Neurocomputing, 51:161–180, 2003. 2, andA.J.Hudspeth. PrinciplesofNeuralScience. FifthEdi-
3 tion.McGraw-HillMedical/Education,2013. 1,2
[11] Xavier Glorot and Yoshua Bengio. Understanding the dif- [25] JonghongKim,OSangjun,YoonnyunKim,andMinhoLee.
ficulty of training deep feedforward neural networks. In Convolutionalneuralnetworkwithbiologicallyinspiredreti-
YeeWhyeTehandMikeTitterington, editors, Proceedings nal structure. Procedia Computer Science, 88:145–154,
of the Thirteenth International Conference on Artificial In- 2016. 3
telligence and Statistics, volume 9 of Proceedings of Ma- [26] AlexKrizhevsky,VinodNair,andGeoffreyHinton.Cifar-10
chineLearningResearch,pages249–256,ChiaLagunaRe- (canadianinstituteforadvancedresearch). 6
sort,Sardinia,Italy,13–15May2010.PMLR. 3 [27] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.
[12] BorisHaninandDavidRolnick. Howtostarttraining: The Imagenet classification with deep convolutional neural net-
effectofinitializationandarchitecture,2018. 3 works. InF.Pereira,C.J.C.Burges,L.Bottou,andK.Q.
[13] J. A. Hartigan and M. A. Wong. A k-means clustering al- Weinberger, editors, Advances in Neural Information Pro-
gorithm. JSTOR: Applied Statistics, 28(1):100–108, 1979. cessingSystems,volume25.CurranAssociates,Inc.,2012.
5 1[28] P. Kruizinga and N. Petkov. Computational Model [44] K.A. Zaghloul, K. Boahen, and J.B. Demb. Different cir-
of Dot-Pattern Selective Cells. Biological Cybernetics, cuits for on and off retinal ganglion cells cause different
83(4):313–325,Jun2000. 6 contrastsensitivities. JournalofNeuroscience,23(7):2645–
[29] S.W. Kuffler. Discharge Patterns and Functional Organi- 2654,2003. 2
zationofMammalianRetina. JournalofNeurophysiology, [45] Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, and
16(1):37–68,1953. 2 DavidLopez-Paz. mixup: Beyondempiricalriskminimiza-
[30] MdNasirUddinLaskar,LuisGSanchezGiraldo,andOdelia tion. InInternationalConferenceonLearningRepresenta-
Schwartz. Correspondenceofdeepneuralnetworksandthe tions,2018. 7
brainforvisualtextures. arXivpreprintarXiv:1806.02888, [46] Zhun Zhong, Liang Zheng, Guoliang Kang, Shaozi Li,
2018. 3 and Yi Yang. Random erasing data augmentation. Pro-
[31] Y. LeCun, B. Boser, J.S. Denker, D. Henderson, R.E. ceedings of the AAAI Conference on Artificial Intelligence,
Howard, W. Hubbard, and L.D. Jackel. Backpropagation 34(07):13001–13008,Apr.2020. 7
applied to handwritten zip code recognition. Neural Com- [47] GeorgiosZoumpourlis,AlexandrosDoumanoglou,Nicholas
putation,1(4):541–551,1989. 1 Vretos,andPetrosDaras. Non-linearconvolutionfiltersfor
[32] ZhuangLiu,HanziMao,Chao-YuanWu,ChristophFeicht- cnn-based learning. In Proceedings of the IEEE Interna-
enhofer,TrevorDarrell,andSainingXie. Aconvnetforthe tional Conference on Computer Vision, pages 4761–4769,
2020s. ProceedingsoftheIEEE/CVFConferenceonCom- 2017. 3
puterVisionandPatternRecognition(CVPR),2022. 2,4
[33] DmytroMishkinandJiriMatas. Allyouneedisagoodinit,
2016. 3
[34] N.PetkovandW.Visser. ModificationsofCenter-Surround,
SpotDetectionandDot-PatternSelectiveOperators. Tech-
nicalReport2005-9-01,InstituteofMathematicsandCom-
putingScience,UniversityofGroningen,Netherlands,2005.
6
[35] Yongming Rao, Wenliang Zhao, Yansong Tang, Jie Zhou,
Ser-Lam Lim, and Jiwen Lu. Hornet: Efficient high-order
spatial interactions with recursive gated convolutions. Ad-
vancesinNeuralInformationProcessingSystems(NeurIPS),
2022. 2,4
[36] R. Rodieck. Quantitative Analysis of Cat Retinal Gan-
glion Cell Response to Visual Stimuli. Vision Research,
5(12):583–601,1965. 5
[37] R. Shapley and V.H. Perry. Cat and monkey retinal gan-
glioncellsandtheirvisualfunctionalroles. TrendsinNeu-
rosciences,9:229–235,1986. 2
[38] KarenSimonyanandAndrewZisserman. Verydeepconvo-
lutionalnetworksforlarge-scaleimagerecognition. CoRR,
abs/1409.1556,2014. 1,4
[39] MingxingTanandQuocLe.EfficientNet:Rethinkingmodel
scaling for convolutional neural networks. In Kamalika
Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings
ofthe36thInternationalConferenceonMachineLearning,
volume 97 of Proceedings of Machine Learning Research,
pages6105–6114.PMLR,09–15Jun2019. 4
[40] AlexThomson. Neocorticallayer6,areview. Frontiersin
Neuroanatomy,4:13,2010. 3
[41] AsherTrockmanandJ.ZicoKolter.Patchesareallyouneed?
CoRR,abs/2201.09792,2022. 2,4
[42] Sanghyun Woo, Shoubhik Debnath, Ronghang Hu, Xinlei
Chen, Zhuang Liu, In So Kweon, and Saining Xie. Con-
vnext v2: Co-designing and scaling convnets with masked
autoencoders. arXivpreprintarXiv:2301.00808,2023. 2,4
[43] Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk
Chun,JunsukChoe,andYoungjoonYoo. Cutmix: Regular-
izationstrategytotrainstrongclassifierswithlocalizablefea-
tures. InProceedingsoftheIEEE/CVFInternationalCon-
ferenceonComputerVision(ICCV),October2019. 7