TIME SERIES DIFFUSION IN THE FREQUENCY DOMAIN
JonathanCrabbé, NicolasHuynh, JanStanczuk, MihaelavanderSchaar
∗ ∗
DAMTP
UniversityofCambridge
{jc2133, nvth2, js2164, mv472}@cam.ac.uk
ABSTRACT
Fourieranalysishasbeenaninstrumentaltoolinthedevelopmentofsignalprocessing. Thisleadsus
towonderwhetherthisframeworkcouldsimilarlybenefitgenerativemodelling. Inthispaper,we
explorethisquestionthroughthescopeoftimeseriesdiffusionmodels. Morespecifically,weanalyze
whetherrepresentingtimeseriesinthefrequencydomainisausefulinductivebiasforscore-based
diffusionmodels. BystartingfromthecanonicalSDEformulationofdiffusioninthetimedomain,
weshowthatadualdiffusionprocessoccursinthefrequencydomainwithanimportantnuance:
BrownianmotionsarereplacedbywhatwecallmirroredBrownianmotions,characterizedbymirror
symmetriesamongtheircomponents. Buildingonthisinsight,weshowhowtoadaptthedenoising
scorematchingapproachtoimplementdiffusionmodelsinthefrequencydomain. Thisresultsin
frequencydiffusionmodels,whichwecomparetocanonicaltimediffusionmodels. Ourempirical
evaluationonreal-worlddatasets,coveringvariousdomainslikehealthcareandfinance,showsthat
frequencydiffusionmodelsbettercapturethetrainingdistributionthantimediffusionmodels. We
explainthisobservationbyshowingthattimeseriesfromthesedatasetstendtobemorelocalized
inthefrequencydomainthaninthetimedomain,whichmakesthemeasiertomodelintheformer
case. AllourobservationspointtowardsimpactfulsynergiesbetweenFourieranalysisanddiffusion
models.
1 Introduction
Deep generative modelling leverages the inductive bias of neural networks to learn complex, high-dimensional
probabilitydistributionsfromreal-worlddatasets. Amongotherapplications,generativemodelsallowforgenerationof
newsyntheticsamplesconsistentwiththedistributionofthetrainingdata,yetdistinctfromtheactualdataencountered
duringtraining. Recentlythisfieldhasseentremendousprogressinvariousmodalitiesincludingimage[1,2],audio
[3,4],video[5]andtext[6]generation,aswellasaddressinginverseproblemssuchasin-painting[7]orsuper-resolution
[8]. Moreoverdeepgenerativemodelshavestartedshowingsignificantpotentialincontributingtonaturalsciences,
thoughproteindesign[9],drugdevelopment[10]andmaterialsynthesis[11]. However,theapplicationofthesemodels
totimeseriesdatahasnotseenthesamelevelofadvancement[12]. Somenotableexamplesoftimeseriesgenerative
modelsincludeTimeGAN[13],FourierFlow[14],andRCGAN[15],yetthisarearemainslessexploredcomparedto
otherapplications.
Diffusion Models. In recent years, diffusion models [16, 17, 18, 19] have emerged as one of the most promising
researchavenuesindeepgenerativemodelling,achievingstate-of-theartresultsacrossmanygenerativemodelling
tasks[2,8]. Diffusionmodelshavebeenappliedtotimeseriesmodelling,achievingpromisingresults[20]. However,
thereissubstantialroomfordevelopmentandrefinementintheseearly-stageapplications.
Fourier analysis. Fourier analysis is a remarkably powerful tool in signal processing, compression and machine
learning[21]. Ithasbeenshowntosignificantlyimprovestate-of-the-arttheperformanceofmanydeeplearningbased
timeseriesanalysistechniques[22],withsomerecentapplicationsindatasetdistillation[23]. Inthecontextofdeep
generativemodels,thisisexemplifiedin[14],wheretheapplicationofnormalizingflowstoFourierrepresentations
∗Denotesequalcontributionandcorrespondingauthors.
4202
beF
8
]GL.sc[
1v33950.2042:viXraTimeSeriesDiffusionintheFrequencyDomain
yieldedpromisingresults. Morerecently,someworkby[24]hasbeendoneondiffusiononfunctionalspaces,which
includeFourierrepresentationsofsignalsalthoughthepaperdoesnotspecificallyfocusontheFourierbasis.
Motivation. DespiteFourieranalysis’widespreadsuccess,itsapplicationtodiffusionmodelsfortimeseriesremains
largely unexplored. This paper seeks to fill this research gap, by examining whether spectral representations can
improvediffusionmodelsfortimeseriesmodelling. Ourfocusisnotonachievingstate-of-the-artresults,butrather
investigatingwhetherrepresentingtimeseriesinthefrequencydomainisausefulinductivebiasfordiffusionmodels.
Ourcontributions. (1)Formalizingfrequencydiffusion. InSection3,weshowtheoreticallyhowtotranslate
SDE-baseddiffusionoftimeseriestothefrequencydomain. Wedemonstratethatthedenoisingscorematching
recipe can be adapted byreplacing standard Brownian motionsby what we call mirrored Brownian motions,
characterizedbymirrorsymmetriesintheircomponents. (2)Comparingtimeandfrequencydiffusion. In
Section4.1,wecomparetheabilityofthetimeandfrequencyscoremodelstogeneratesamplesthatarefaithfulto
thetrainingsetsbyleveragingslicedWassersteindistances.Throughanextensiveanalysison6real-worlddatasets
illustratingfieldslikehealthcare,finance,engineeringandclimatemodelling,wedemonstratethatfrequencyscore
modelsconsistentlyoutperformthetimescoremodels. (3)Understandingwhyandwhenfrequencydiffusion
ispreferable. InSection4.2,wedemonstratethatthesignalsinall6datasetsconcentratemostoftheirpower
spectrumonthelowfrequencies. Wehypothesizethatthislocalizationinthefrequencydomainexplainsthe
superiorperformancesoffrequencydiffusionmodels. InSection4.3,weconfirmthishypothesisbyartificially
delocalizingthe spectralrepresentationof realsignalsand showingthat thegap betweentimeand frequency
diffusioncloses.
2 Background
Notations. Weconsidermultivariatetimeseriesoffixedsize2x RN M,whereN Nisthenumberoftimesteps
×
andM Nisthenumberoffeaturestrackedovertime. Often,w∈ ewilldenotebyd ∈ =N M thetotaldimensionof
X
thetime∈ seriesx. WeshalluseGreeklettersforcomponentsofthetimeseries. Inthisway,x · RM denotesthefeature
τ
∈
vectorattimeτ [N]andx denotesthevalueoffeatureν [M]attimeτ. Wedenoteby[K]:= 0,1,...,K 1
τ,ν
the integers betw∈ een 0 (included) and K N (excluded). ∈ To avoid any confusion between time{ series steps− and}
∈
diffusionsteps,weshalluseLatinlettersforthediffusionprocess. Inthisway,thediffusionprocessisdescribedbya
familyoftimeseries x(t) RdX T indexedbyacontinuousdiffusionvariablet [0,T]. Thankstothesenotations,
weunambiguouslyin{ terpre∈ tx (t)}t= R0 M asthefeaturevectorattimestepτ [N]a∈ ndatdiffusionstept [0,T]. We
τ
∈ ∈ ∈
shalldetailbelowhowthisdiffusionprocessisdefined.
2.1 Score-basedgenerativemodelingwithSDEs
Incontinuous-timediffusionmodelling,oneassumesaccesstosamplesdrawnfromanunknowndensityp . The
data
objectiveofgenerativemodellingistoobtainatractableapproximationofthisdistribution.
Forward diffusion. Score-based generative modeling with stochastic differential equation (SDEs) [19] typically
operatesbyfirstconstructingaforwarddiffusionprocess. Inthecaseoftimeseries,forwardcontinuousdiffusionis
describedbythefollowingSDE,witht [0,T]:
∈
dx=f(x,t)dt+G(t)dw, (1)
wheref :RdX [0,T] RdX isthedrift,wisastandardBrownianmotioninRdX,andG:[0,T] RN ×N isthe
× → →
diffusionmatrix. Wedenotep theprobabilitydensityofthesolutionx(t)ofEquation(1)attimet [0,T]. With
t
∈
theslightabuseofnotationfrom[19],weshallabbreviatep (x(t))byp (x). TogetherwiththeSDE,weimposethe
t t
initialconditionp =p ,whichcorrespondstosamplesinitiallydrawnfromthedatadensityp . Inpractice,we
0 data data
considerf andGsuchthatp istransportedtoafinaldensityp closetoanisotropicGaussian.
data T
Reversediffusion. Thereversediffusionprocessperformstheinversetransformationbytransportingtheisotropic
Gaussiandensityp tothedatadensityp = p . Hence, applyingreversediffusiontosamplesdrawnfromthe
T 0 data
isotropicGaussianpermitstosamplefromtheunknowndensityp . Itwasshownby[25]thatthisreversediffusion
data
satisfiesthefollowingSDE:
dx=b(x,t)dt+G(t)dwˆ, (2)
whereb(x,t)=f(x,t) G(t)G(t)T logp (x),dtisanegativeinfinitesimaltimestep,andwˆ isaBrowniantime
x t
− ∇
incrementwithtimegoingbackwardsfromT to0.
2Paddingovertimecanbeusedincaseswherethedatasetscontaintimeseriesofdifferentlengths.
2TimeSeriesDiffusionintheFrequencyDomain
Denoisingscorematching. Inordertorunthereversediffusionprocess, oneneedsaccesstothescores(x,t) :=
logp (x). Inpractice,theground-truthdensityp isunknown. Denoisingscorematchingcircumventsthisproblem
x t t
∇
byestimatingtheground-truthscorewithafunctions
θ∗
whoseparametersθ ∗minimizethefollowingscorematching
objectivecomputedfromthedatasamples[16,26]:
θ =argminE (cid:2) (s ,s ,x,t)(cid:3) (3)
∗ t,x(0),x(t) SM θ t0
θ Θ L |
∈
(s ,s ,x,t):= s (x,t) s (x,t) 2 (4)
SM θ t0 θ t0
L | ∥ − | ∥
where denotestheFrobeniusnorm, t (0,T), x(0) p (x), x(t) p (x(t)x(0))withp denotingthe
0 t0 t0
transitio∥ n· k∥ ernelfrom0tot,ands (x,t):=∼ U logp (x(∼ t)x(0)). With∼ suffi|cientm| odelcapacity,|theparameters
t0 x(t) t0
θ ∗provideanapproximations θ∗
th|atisequalt∇ othescore|sforal|
mostallxandtinthelargedatalimit[27]. Equipped
withanapproximationofthescores
θ∗
s,onecangeneratedatabysamplingaccordingtothesolutiondefinedbythe
≈
reversediffusionprocessfromEquation(2).
2.2 DiscreteFourierTransform
DFT.Byconsideringatimeseriesx = (x 0,...,x
N
1) RdX,theDiscreteFourierTransform(DFT),denotedas
˜x= [x],isdefinedas − ∈
F
N 1 (cid:18) (cid:19)
1 (cid:88)− κ2πi
˜x := x exp τ (5)
κ τ
√N − N
τ=0
forallκ [N]. Inthesignalprocessingliterature,eachκcorrespondstoaharmonicoffrequencyω := κ2π. Forthis
∈ κ N
reason,theDFT˜xissaidtorepresentthetimeseriesxinthefrequencydomain,asopposedtothetimedomain. Wealso
notethattheDFTiscomplex-valued(˜x CdX).
∈
Matrixrepresentation. WenotethattheDFToperator islinearwithrespecttothetimecomponents(x ,...,x ).
0 N 1
ItcanthereforebeexpressedthroughaleftmatrixmuF ltiplication˜x = [x] = Ux,whereU CN N isdefined−as
×
F ∈
[U] := N 1/2exp( iω τ). It can easily be checked (see Appendix A.1) that the matrix U is unitary: U U =
κτ − κ ∗
−
UU =I ,whereU istheconjugatetransposeofU andI istheN N identitymatrix. ThisimpliesthattheDFT
∗ N ∗ N
×
operatorisinvertibleandthattheoriginaltimeseriescanbereconstructedfromitsrepresentationinthefrequency
domain: x= 1[˜x]:=U ˜x.
− ∗
F
DFTofareal-valuedsequence. WhiletheDFT˜xisdefinedinCdX,someofitscomponentsaremaderedundantby
thefactthatxisareal-valuedtime-series. Onecaneasilycheck(seeAppendixA.1)thatthisconstraintimposesthe
followingmirrorsymmetryontheDFTforallκ [N]:
∈
˜x
κ
=˜x∗N κ, (6)
−
wherez denotesthecomplexconjugateofz Candwedefine˜x :=˜x forconsistency. Throughthissymmetry,we
∗ N 0
∈
observethatthecomponents˜x withκ N/2 uniquelydefinetheDFTofareal-valuedtimeseries. Forthisreason,
κ
≤⌊ ⌋
thefrequenciesbeyondtheNyquistfrequencyω :=ω areredundantwithrespecttothelowerfrequencies. In
Nyq N/2
thefrequencydomain,onethenneedsonlytodiffuseN r⌊ealn⌋umbersextractedfromtheDFTandtherestof˜xcanbe
deducedfromEquation(6).
SignalEnergy. Animportantquantityrelatedtoatimeseriesxisitstotalenergy,whichsimplycorrespondstothe
squaredFrobeniusnorm ∥x ∥2 :=(cid:80)N τ=− 01(cid:80)M ν=1|x τ,ν |2,where |·|denotesthemodulusofacomplexnumber. Through
Parseval’s theorem, this energy can be evaluated by computing the same norm for the DFT ˜x of x: x 2 = ˜x 2.
∥ ∥ ∥ ∥
We note that the total energy is obtained by summing over all time steps or frequencies. To characterize how the
energyisdistributedoverthetimestepsτ [N],weusetheenergydensitydefinedasthesquaredEuclideannorm
x 2 := (cid:80)M x 2. Similarly,thespe∈ ctralenergydensitydefinedas ˜x 2 describeshowthesignalenergyis
∥ τ ∥2 ν=1| τ,ν | ∥ κ ∥2
distributedacrossthefrequenciesκ [N].
∈
Probabilitydensityinthecomplexspace. Adaptingthediffusionformalismtothefrequencydomainrequiresto
defineaprobabilitydensityforthecomplex-valuedrandomvariable˜x CdX. Byfollowing[28],thisdensityiswritten
∈
in terms of the real and imaginary parts of the signal p˜(˜x) := p˜( [˜x], [˜x]). Similarly, the score function follows
ℜ ℑ
asimilardecompositionintermsofthesignalrealandimaginaryparts˜s(˜x) := logp˜(˜x)+i logp˜(˜x).
[˜x] [˜x]
Wenotethatthegradientinvolvedinthedefinitionofthescoresisnon-trivialwhe∇ nℜtheconstraintin· E∇ qℑuation(6)is
enforced. InAppendixA.2,weestablishaformaldefinitioninthissettingbyinterpretingthecomplexsignalsfulfilling
thisconstraintasasubmanifoldinCdX. Thisconstraintimpliesthatthescorecomponentsfollowananalogousmirror
symmetry:˜s =˜s forallκ [N]. Inthefollowing,weshallimplicitlyrelyonthisdefinition.
κ ∗N −κ ∈
3TimeSeriesDiffusionintheFrequencyDomain
3 Diffusinginthefrequencydomain
Intheprevioussection,wehavedescribedhowthetypicaldiffusionformalismappliestotime-series. Wehavealso
described how the DFT ˜x = [x] offers a full description of the time series x in the frequency domain. The first
F
stepistodefinehowtime-baseddiffusiontranslatesinthefrequencydomain. Notethatthisisnon-trivialastheDFT
arecomplex-valued˜x CdX signals. Tosolvethis,weshallassumethatthestochasticprocessinthetimedomain
x(t) T ,writtencom∈ pactlyasx,followsthediffusionprocessdescribedinEquation(1). Byleveragingthematrix
{ }t=0
formulationoftheDFT˜x=Ux,wewillnowderivediffusionSDEsinthefrequencydomain.
3.1 DiffusionSDEs
InordertoderivethediffusionSDEsinthefrequencydomain,weshallsimplyapplytheDFToperatortotheforward
diffusionSDEinthetimedomainfromEquation(1). WenotethatthisequationcontainsastandardBrownianmotion
w. Inthebelowlemma,wedescribetheDFTofwandshowthatitcontainstwocopiesofanon-standardBrownian
motionrelatedbytheconstraintfromEquation(6). WerefertothisasamirroredBrownianmotion.
Lemma3.1. (DFTofstandardBrownianmotion). LetwbeastandardBrownianmotiononRdX withd
X
=N M,
whereN N+ isthenumberoftimeseriesstepsandM N+ isthenumberoffeaturestrackedovertime. T· hen
∈ ∈
v =Uwisacontinuousstochasticprocessendowedwith:
(1)MirrorSymmetry. Forallκ [N],v =v .
(2)RealBrownianMotion. v
i∈ sa(real)κ standN∗ ar−dκ
BrownianmotiononRM.
0
(3)ComplexBrownianMotions. Forallκwith1 κ N/2 ,wecanwritev =(w˜1 +iw˜2)/√2wherew˜1 and
w˜2 areindependentstandardBrownianmotionso≤ nRM≤ ,⌊ excep⌋ twhenN isevenκ andκ=κ N/2,κ wherev isaκ real
κ N/2
standardBrownianmotiononRM.
W(4 e)I cn ad lle ap ne ynd ste on cc he a. sT tih ce ps rt oo cc eh sa ss st aic tip sfr yo ic ne gss thes e{ av b˜ κ ov} e⌊κN = c/ o02 n⌋ sta rr ae inm tsut aua mll iy rroin rd edep Ben rod wen nt i. anmotiononCdX.
Proof. TheproofisgiveninAppendixA.3.
Remark3.2. Notethatv isnotstrictlyspeakingaBrownianmotion,sinceitcontainsduplicatecomponentsdueto
themirrorsymmetry. However,ourtheoreticalanalysisinAppendixAdemonstratesthatwecantreatitassuchby
restrictingtoasubsetofnon-redundantcomponents.
WenowleverageLemma3.1toshowthat˜xcanbedescribedbydiffusionSDEsinthefrequencydomainwhichinvolve
mirroredBrownianmotions.
Proposition3.3. (Diffusionprocessinfrequencydomain). Letusassumethatxisadiffusionprocessthatisasolution
ofEquation(1),withG(t)=g(t)I . Then ˜x= [x]isasolutiontotheforwarddiffusionprocessdefinedby:
N
F
d˜x=f˜(˜x,t)dt+g(t)dv˜, (7)
wheref˜(˜x,t)=Uf(U ∗˜x,t)andv˜isamirroredBrownianmotiononCdX. Theassociatedreversediffusionprocessis
definedby:
d˜x=b˜(˜x,t)dt+g(t)dv˘ (8)
whereb˜(˜x,t)=f˜(˜x,t) g2(t)Λ2˜s(˜x,t),Λ RN N isadiagonalmatrixdefinedinAppendixA.3,dtisanegative
×
infinitesimaltimestep,a− ndv˘isamirroredB∈ rownianmotiononCdX withtimegoingfromT to0.
Proof. TheproofisgiveninAppendixA.3.
Proposition3.3givesusarecipetoimplementdiffusioninthefrequencydomain. Itguaranteesthattheformalism
introducedby[19]extendstothissettingwithoneimportantdifference: theBrownianmotionmustbereplacedby
amirroredBrownianmotion. Ignoringthisprescriptionbytakingv˜tobeaBrownianmotiononCdX couldleadto
unintendedconsequences,suchasgeneratingcomplex-valuedtimeseriesx CdX RdX.
∈ \
3.2 Denoisingscorematching
ThereversediffusionprocessgiveninEquation(8)providesanexplicitwaytosamplestime-seriesinthefrequency
domainprovidedwecancomputeb˜(˜x,t),whichinvolvestheunknownscore˜s. Likeinthetimedomain,andmotivated
byEquation(8),webuildanapproximationofthescorewithafunction˜s ,whoseparametersθ˜ minimizethescore
θ˜∗ ∗
matchingobjective:
4TimeSeriesDiffusionintheFrequencyDomain
θ˜ =argminE (cid:2) (cid:0) ˜s ,Λ2˜s ,˜x,t(cid:1)(cid:3) (9)
∗
θ˜ Θ
t,˜x(0),˜x(t) LSM θ˜ t |0
∈
witht (0,T),˜x(0) p˜ (˜x),˜x(t) p˜ (˜x(t)˜x(0))andΛisthediagonalmatrixdefinedinProposition3.3. In
0 t0
practice∼ ,tU hisobjectiveis∼ evaluatedbyfi∼ rsto|btainin|
gfrequencyrepresentationsoftime-series,andthensamplingfrom
p˜ usingEquation(7). Havingtrained˜s ,thebackwardprocessand˜s permittodrawsamplesfromp˜ . Itthen
t0 θ˜∗ θ˜∗ 0
su| fficestoapplytheinverseDFT 1tomaptheresultingcomplex-valuedsignalsbackintothetimedomain.
−
F
Oneimportantquestionremainsatthisstage. Howdoestrainingascoreinthefrequencydomainallowtogenerate
DFToftimeseriessampledfromp ? Inotherwords,howdoesminimizingthescorematchinginEquation(9)
data
implythatp˜ p˜ ? Toanswerthisquestion,akeyobservationisthatwecanassociateanauxiliaryscores inthe
0 ≈ data ′ θ˜
timedomaintothescore˜s byapplyinganinverseDFT 1. Below,weshowthatminimizingthescorematching
θ˜ F−
lossfromEquation(9)forthescore˜s isequivalenttominimizingthescorematchinglossfromEquation(3)forthe
θ˜
auxiliaryscores . Thisimportantobservationconnectsthereversediffusionprocessinthefrequencydomaindescribed
′ θ˜
byEquation(8)withareversediffusionprocessinthetimedomainfollowingEquation(2).
Proposition3.4. (Scorematchingequivalence). Considerascore˜s θ˜:CdX ×[0,T] →CdX definedinthefrequency
domain and satisfying the mirror symmetry [˜s ] = [˜s ] for all κ [N]. Let us define an auxiliary score
s
′ θ˜
: RdX ×[0,T]
→
RdX as(x,t)
(cid:55)→
s
′
θ˜(x,t)θ˜ =κ U ∗˜s θ˜(∗ θ˜ UN x,− tκ )inthetime∈ domain. Thescorematchinglossinthe
frequencydomainisequivalenttothescorematchinglossfortheauxiliaryscoreinthetimedomain:
(cid:0) ˜s ,Λ2˜s ,˜x,t(cid:1) = (cid:0) s ,s ,x,t(cid:1) (10)
LSM θ˜ t |0 LSM ′ θ˜ t |0
where˜s (˜x,t) = logp˜ (˜x(t)˜x(0)) , s (x,t) = logp (x(t)x(0)), and Λ is the diagonal matrix in
t0 ˜x(t) t0 t0 x(t) t0
Propositi|on3.3. ∇ | | | ∇ | |
Proof. TheproofisgiveninAppendixA.4.
Propositions3.3and3.4provideanexplicitwaytotranslatediffusioninthetimedomaintodiffusioninthefrequency
domain. WenotethatattemptingtosolveEquations(3)and(9)inthefinite-sampleregimeyieldsalocalminimum
solutioninpractice. Hence,thereisnoguaranteethattrainingascoremodelinthefrequencydomainwillconvergeto
anauxiliaryscores ′ θ˜∗ =s θ∗ identicaltotheoneobtainedbytrainingthescoremodelinthetimedomain. Inparticular,
havingascorefunction˜s definedinthefrequencydomainisanimportantinductivebias,whichislikelytoalterthe
θ
trainingdynamic. Throughourexperimentsinthenextsection,westudytheeffectofthisinductivebiasontheresulting
diffusionprocesses.
Take-away1. DiffusioninthefrequencydomaincanbeimplementedbyreplacingthestandardBrownianmotions
withmirroredBrownianmotionsinthediffusionSDEs. Theassociatedscorecanbeoptimizedbyminimizinga
denoisingscorematchingloss.
4 Comparingtimeandfrequencydiffusion
Table1: Variousdatasetsusedinourexperimentsandsomeoftheirproperties.
Dataset Reference Field #Samples #StepsN #FeaturesM
ECG [29] 87,553 187 1
Healthcare
MIMIC-III [30] 19,155 24 40
NASDAQ-2019 [31] Finance 4,827 252 5
NASA-Charge 2,396 251 4
[32] Engineering
NASA-Discharge 1,755 134 5
US-Droughts [33] Climate 2,797 365 13
In this section, we empirically analyze the effect of performing time series diffusion in the frequency domain. In
Section4.1,weshowthatfrequencydiffusionmodelsbettercapturetheirtrainingdistributionthantimemodels. In
Section4.2,wearguethatthesedifferencesofperformancecanbeattributedthelocalizationofthetimeseriesinthe
frequencydomain. Finally,inSection4.3,weartificiallycreatesettingswheretimemodelsoutperformthefrequency
modelsinordertoconfirmthishypothesis. Thecodenecessarytoreproducetheresults,alongwithdetailedinstructions,
isprovidedinthefollowingrepository: https://github.com/JonathanCrabbe/FourierDiffusion.
5TimeSeriesDiffusionintheFrequencyDomain
Table2: SlicedWassersteindistances( )evaluatedinthetimedomain(SW( , ),SW( , ))andin
train time train freq
↓ D S D S
thefrequencydomain(SW(˜ , ˜ ),SW(˜ , ˜ ))onthevariousdatasets. Foreachdistance,wereportits
train time train freq
D S D S
mean 2standarderrors.
±
Dataset MetricDomain DiffusionDomain
Frequency Time
ECG Frequency 0.012 0.000 0.020 0.000
± ±
Time 0.015 0.000 0.021 0.000
± ±
MIMIC-III Frequency 0.144 0.004 0.206 0.006
± ±
Time 0.152 0.004 0.211 0.006
± ±
NASDAQ-2019 Frequency 45.812 2.096 64.056 3.040
± ±
Time 43.602 2.044 60.512 2.960
± ±
NASA-Charge Frequency 0.211 0.008 0.27 0.006
± ±
Time 0.229 0.008 0.316 0.008
± ±
NASA-Discharge Frequency 1.999 0.084 2.974 0.134
± ±
Time 2.028 0.082 2.942 0.134
± ±
US-Droughts Frequency 0.633 0.018 2.849 0.090
± ±
Time 0.738 0.020 2.913 0.092
± ±
100 100
Dataset
10−1 10−1 E MC IMG
IC-III
NASDAQ-2019
10−2 10−2 NASA-Charge
NASA-Discharge
10−3
Dataset
10−3 US-Droughts
ECG
10−4 MIMIC-III 10−4
NASDAQ-2019
10−5 N NA AS SA A- -C Dh isa cr hg ae
rge
10−5
US-Droughts
10−6
0.0 0.2 0.4 0.6 0.8 1.0
10−6
0.0 0.2 0.4 0.6 0.8 1.0
Timeτ/N Frequencyωκ/ωNyq
(a)TimeDomain. (b)FrequencyDomain.
Figure1:Localizationoftimeseriesinthetimeandfrequencydomains. Timeseriesaremorelocalizedinthefrequency
domain.
Data. Toillustratethebreadthoftimeseriesapplications,weworkwith6differentdatasetsdescribedinTable1. We
observethatthesedatasetscovermanyuse-cases(healthcare,finance,engineeringandclimatemodelling),samplesizes,
sequencelengthsN andnumberoffeaturestrackedovertimeM. Allthedatasetsarestandardizedbeforebeingfedto
models. Wealsosplitthedatasetsintoatrainingset andavalidationset . Weprovidemoredetailsonthe
train val
D D
datasetsinAppendixB.1.
Models. Foreachdataset,weparametrizethetimescoremodels andthefrequencyscoremodel˜s astransformer
θ θ˜
encoders with 10 attention and MLP layers, each with 12 heads and dimension d = 72. Both models have
model
learnablepositionalencodingaswellasdiffusiontimetencodingthroughrandomFourierfeaturescomposedwitha
learnabledenselayer. Thisresultsinmodelswith3.2Mparameters. WeuseaVP-SDEwithlinearnoiseschedulingand
β =0.1andβ =20,asin[19]. Thescoremodelsaretrainedwiththedenoisingscore-matchingloss,asdefined
min max
inSection3. Allthemodelsaretrainedfor200epochswithbatchsize64,AdamWoptimizerandcosinelearningrate
scheduling(20warmupepochs,lr =10 3). Theselectedmodelistheoneachievingthelowestvalidationloss.
max −
Timeandfrequency. Crucially,theonlydifferencebetweenthetimeandthefequencydiffusionmodelsisthedomain
inwhichtheirinputtimeseriesarerepresented. Sincealldatasetsareexpressedinthetimedomain,theycandirectlybe
fedtothetimediffusionmodels . Whenitcomestothefrequencydiffusionmodel˜s ,thedataisfirstmappedtothe
θ θ˜
frequencydomainbyapplyingaDFT oneachtimeseries. Inthetimedomain,theforwardandreversediffusion
F
obeytheSDEsinEquations(1)and(2). Inthefrequencydomain,theforwardandreversediffusionobeythemodified
SDEsinEquations(7)and(8). Thedenoisedsamples˜x(0)obtainedinthefrequencydomaincanbepulledbackto
thetimedomainbyapplyinganinverseDFT˜x(0) −1[˜x(0)]. Inthefollowing,weshalldenoteby
time
RdX
and
freq
RdX thetimerepresentationofthesam(cid:55)→ pleF sgeneratedbythetimeandfrequencymodels. SS imila⊂ rly,we
S ⊂
6
2 kx
k/2
2kτx
kytisneDygrenE
2 kx˜
k/2
2kκx˜
kytisneDlartcepSTimeSeriesDiffusionintheFrequencyDomain
104
Domain
Time
Frequency
103
102
101
E
C G MIMIC-II NI
ASD
A
Q-2019
N
ASA-Charg Ae SA-Discharge US-Droughts
N
Dataset
Figure2: Byevaluatingourdelocalizationmetricsinthetimedomain(∆ )andthefrequencydomain(∆ ),we
time freq
quantitativelyconfirmthatallthedatasetsaresignificantlymorelocalizedinthefrequencydomain. Allthemetricsare
averagedover ,theirmeanisreportedwitha95%confidenceinterval.
train
D
103 103
10−2
10−2
Domain Domain
Time Time
Frequency Frequency
10−3
102 10−3 102
0 5 10 15 20 0 5 10 15 20
GaussianKernelWidth GaussianKernelWidth
(a)TimeDomain. (b)FrequencyDomain.
Figure 3: Sliced Wasserstein distances of time and frequency models (blue) and localization metrics in time and
frequency domains (red) when smoothing the spectral representations of the time series with Gaussian kernels of
variable width. Increasing the kernel width removes the localization in the frequency domain and increases the
localizationinthetimedomain. Coincidentally,thetimediffusionmodelbecomesbetterthanthefrequencydiffusion
model.
shalldenoteby ˜ := [ ]and ˜ := [ ]thefrequencyrepresentationsofthesetimeseries. Wesample
time time freq freq
S F S S F S
= =10,000samplesforeachmodelbyapplyingT =1,000diffusiontimesteps.
time freq
|S | |S |
4.1 Whichsamplesbettercapturethedistribution?
Methodology.Weareinterestedinthefaithfulnessofthesamplesgeneratedbythetimeandfrequencydiffusionmodels.
Ideally,thisfaithfulnessshouldbeevaluatedbycomputingtheWassersteindistancebetweenthetruedistributionandthe
distributionspannedbyourdiffusionmodels.However,thisisimpossiblesincetheexactcomputationoftheWasserstein
distanceinintractableininputspacesoflargedimensiond 1. Inthecaseofimages,[34]mitigatestheseproblems
X
≫
7
)
(nietsressaWdecilSemiT
↓
cirteM
noitazilacoleD
noitazilacoleD
)
(nietsressaWdecilSycneuqerF
↓
noitazilacoleDTimeSeriesDiffusionintheFrequencyDomain
bymappingalltheimagesinalowerdimensionalrepresentationspace(theactivationofthepenultimatelayerofan
Inception-V3model). ThiscruciallyreliesonthefactthattheInception-V3provideshigh-qualityrepresentationsof
images. Unfortunately,suchageneralrepresentationoftimeseriesdoesnotexistinpractice. Hence,ourevaluation
needstobeperformedintheinputspaceRdX directly. Forthisreason,weshallrelyontheslicedWassersteindistance
introducedby[35],whichhassimilarpropertiestotheWassersteindistanceandcanbeefficientlyestimatedinhigh
dimensionspaces. Withaslightabuseofnotation,weshalldenotebySW( , )theslicedWassersteindistances
1 2
S S
between the empirical distributions corresponding to the samples and . Its detailed definition is provided in
1 2
S S
AppendixB.2.
Analysis.TheslicedWassersteindistancesarereportedinTable2.Interestingly,weobservethatthefrequencydiffusion
modelsconsistentlyoutperformthetimediffusionmodelsforalldatasetsbothinthetimeandthefrequencydomain. In
AppendixB.3,weshowthatusingmarginalWassersteindistancesinsteadofslicedWassersteindistancesessentially
leadstothesameconclusion. Inordertoverifythatourobservationsarenotspecifictotransformerbackbones,we
reproducethesameexperimentwithLSTMbackbonesinAppendixCandobtainsimilarresultsshowingthesuperior
performanceoffrequencydiffusionmodels. Whilethisobservationalreadysuggeststhebenefitsofdiffusinginthe
frequencydomainratherthaninthetimedomain,itisimportanttounderstandhowtheseperformancegainsemerge.
Forthis,weneedtogainabetterunderstandingofthetrainingdistributions,whichistheobjectofnextsection.
4.2 Howtoexplainthedifferences?
Signalenergyanalysis. Beforeformulatinganhypothesisastowhythefrequencymodelsarebetter,itishelpfulto
gainabetterunderstandingaboutthetrainingdistribution . Tothatend,weleveragetheenergyandspectral
train
D
densities related to the time series, described in Section 2. These densities are represented in Figure 1, where we
haveaveragedthedensitiesoveralltimeseriesin . ByanalyzingFigure1b,wemakeakeyobservation: forall
train
D
datasets,mostofthetimeseriesenergyinthefrequencydomainislocalizedonthefrequencyω =0alsoknownas
0
thefundamentalfrequency. Furthermore,weobservethattheenergyquicklydecaysasthefrequencyincreases. This
observationsuggeststhatthelowfrequenciescapturemostofthetimeseriesinformation. Thisisinstarkcontrastwith
theenergydistributionovertimeinFigure1a,whichismoreuniformovertimeforallthedatasets. Thisasymmetry
betweenthetimeseriesspectrallocalizationandtheirtemporaldelocalizationisapromisingcandidatetoexplainthe
superiorperformancesoffrequencydiffusion. Wenowmakethisobservationmorequantitative.
Quantitativesignallocalization. Inordertomeasurehowdelocalizedatimeseriesx RdX isinthetimedomain,we
∈
shallusethedelocalizationmetricsintroducedby[36]:
1 (cid:88)
∆ time(x):= τm [i Nn
] x 2
d cyc(τ,τ ′) ∥x τ′ ∥2 2, (11)
∈ ∥ ∥ τ′ [N]
∈
whered :[N]2 [N]isthecyclicdistancedefinedasd (τ,τ )=min(τ τ ,N τ τ ), denotesthe
cyc cyc ′ ′ ′
→ | − | −| − | ∥·∥
Frobeniusnormand theEuclideannorm. Similarly,wecancomputethedelocalizationinthefrequencydomain
2
∥·∥
∆ byreplacingx ˜xandτ,τ κ,κ inEquation(11). Wereportthesedelocalizationmetricsforeachdataset
freq ′ ′
(cid:55)→ (cid:55)→
inFigure2. Thisquantitativeanalysisconfirmsourpreviousobservations: thetimeseriesinallthedatasetsappear
significantlymorelocalizedinthefrequencydomain. Interestingly,weneverobserveatimeseriesthatislocalizedin
boththefrequencyandtimedomainsimultaneously. Thisisinagreementwiththeuncertaintyprinciplefrom[36],
whichechoesthefoundationalworkof[37]. ThisverificationismadeinAppendixB.3.
Alocalizationexplanation. Basedonthepreviousobservation,wepostulatethathigherlocalizationofthetimeseries
inthefrequencydomaincontributestothesuperiorperformanceoffrequencydiffusionmodels. Whilewewilltestthis
hypothesisinthenextsection,itisusefultodiscusstheintuitionbehinditfirst. Duetothefrequencylocalization,the
frequencyscoremodelispresentedwitharepresentationofthetimeserieswheremostoftherelevantinformationis
alignedwithfewcomponentsofthemodel’sinput(i.e. thelowerfrequencies,especiallythefundamental). Thisisin
contrastwiththetimemodel,whichispresentedwithaninputwhereallthecomponentsmatterequally. Itfollowsthat
thefrequencymodeldoesnotneedtolearnagooddistributionoverallfrequenciesinordertogeneratesamplesofhigh
quality,providedthelowerfrequencydistributionsareproperlylearned. Thetimemodel,ontheotherhand,needsto
modelallthetimestepsaccuratelyinordertogeneratehigh-qualitysamples. Ifthisintuitioniscorrect,itwouldimply
thatdelocalizingthesignalinthefrequencydomainshouldreducethegapofperformancebetweentimeandfrequency
models. Thisisanalyzedinthenextsection.
4.3 Shouldwealwaysdiffuseinthefrequencydomain?
Removingspectrallocalization. Wewouldliketoassesswhetherthelocalizationofthesesignalsinthefrequency
domaincontributetoexplainthesuperiorperformancesoffrequencydiffusionmodelsovertimediffusionmodels. To
8TimeSeriesDiffusionintheFrequencyDomain
testthishypothesis,weinterveneonagivendatasetwiththeobjectiveofvaryingthelocalizationoffrequencyand
time representations. With this in mind, it is useful to start from a dataset where the imbalance between time and
frequencylocalizationisnotsevere. BylookingatFigure2,itisclearthattheECGdatasetisthebestcandidate. In
ordertograduallyremovethespectrallocalizationfromtheECGdataset ,weconvolvethetimeseriesxinthe
ECG
frequencydomainwithGaussiansofincreasingkernelwidthσ R+ anD ddefinexσ := 1[ [x] ⋆ gσ],where⋆
−
denotestheconvolutionbetweentwosignalsandgσ :=Z 1exp[∈ κ2/(2σ2)]forallκ [NF ]isaF Gaussiankernelwith
normalizationZ =(cid:80)N exp[ κ2/(2σ2)]. Thisrκ esultsi− nafami− lyofcorrupteddataset∈ s σ ,wherethelocalization
κ=1 − DECG
inthefrequencydomaindecreasesasσ increases. ThisisindeedwhatweobserveinFigure3withtheredcurves.
Coincidentally,thedelocalizationdecreasesinthetimedomain,inagreementwiththeuncertaintyprinciple. Thetwo
curvescrossatσ 2,beyondwhichthetimeseriesaremorelocalizedinthetimedomain. Letusnowanalyzehowthe
≈
modelperformancesevolvewithdifferentvaluesofσ.
Analysis. Wetraintimeandfrequencydiffusionmodelsonthedatasets σ forσ 0,5,7,10,20 ,whereσ =0
corresponds to the original ECG dataset: σ=0 = . As in SecD tioE nCG 4.1, we∈ m{ easure the qua} lity of 10,000
DECG DECG
samples producedbythesemodelswiththeWassersteindistancesSW( σ , )inFigure3aandSW(˜σ , ˜)
S DECG S DECG S
inFigure3b. Byinspectingthebluecurvesfromthesefigures,wenoticethatdecreasingthefrequencyclosesthegap
betweenthetimeandthefrequencymodels. Moreover,thetwocurvescrossaroundatσ 7,beyondwhichthetime
≈
modeloutperformsthefrequencymodel. Thisconfirmsourhypothesisthatthelocalization(atleast)partiallyexplains
thebetterperformanceofthefrequencydiffusionmodel.
Acautionaryremark. Beforeconcluding,wewouldliketoincorporateabitofnuanceinouranalysis. Whilethe
aboveresultssuggestthatlocalizationisanimportantfactortoexplainthesuperiorperformanceoffrequencydiffusion
models,wedonotclaimthatthisistheonlyexplanation. Thereareessentiallytwothingsthatsuggestthatthisonly
partiallyexplainstheobservationsfromSection4.1. (1)InFigure3,thebluecurvesandtheredcurvesdon’tcrossfor
thesamevalueofσ(i.e. theredcurvescrossatσ 2andthebluecurvesatσ 7). Hence,thetimemodelrequires
≈ ≈
timeseriesthataresubstantiallymorelocalizedinthetimedomaininordertooutperformthefrequencymodel. (2)In
thelimitσ + ,thetimeseriesbecomeconstantinthefrequencydomain. Whilethiscorrespondstoaminimal
→ ∞
localizationinthefrequencymodel,thisshouldalsobeveryeasyforafrequencydiffusionmodeltolearn. Hence,
decreasingthelocalizationofthetimeseriesinagivendomaindoesnotnecessarilyimplythattheresultingtimeseries
aremoredifficulttomodelinthatdomain.
Take-away2. Foralldatasetsinthispaper,diffusinginthefrequencydomainyieldsbetterperformancesthanin
thetimedomain. Apromisingexplanationforthisisthattimeseriesfromthesedatasetsaresubstantiallymore
localizedintheirspectralrepresentationthanintheirtemporalrepresentation.
5 Discussion
In this work, we have improved the understanding of how diffusion models should be used with time series. We
constructedatheoreticalframeworkthatextendsthescore-basedSDEformulationofdiffusiontocomplex-valuedtimes
seriesrepresentationsinthefrequencydomain. Wehavethendemonstratedempiricallythatimplementingtimeseries
diffusioninthefrequencydomainconsistentlyoutperformsthecanonicaldiffusioninthetimedomain. Finally,we
showedthatthespectrallocalizationofthetimeseriesplaysasignificantroletoexplainthisphenomenon. Thereisa
numberofinterestingwaystoextendourwork.
Timelocalizeddatasets. Whileall6datasetswehavestudiedappearsubstantiallymorelocalizedintheirspectral
representation,wedonotclaimthatisisauniversalpropertyofreal-worldtimeseries. Inparticular,itwouldbeof
interesttosurveyalargeamountoftimeseriesdatasetstodeterminetheextenttowhichthisphenomenonoccurs.
Latentdiffusion. Latentdiffusionhasemergedasafruitfuldirectionofresearchinthediffusionliterature[5]. A
promisingdirectionwouldbetostudyhowspectralrepresentationsoftimeseriescanbeincorporatedtotheirlatent
representations and whether this benefits the quality of the generated samples. We leave these insightful research
directionsforfuturework.
9TimeSeriesDiffusionintheFrequencyDomain
Acknowledgments
JonathanCrabbéandJanStanczukarefundedbyAviva,NicolasHuynhbyIlluminaandMihaelavanderSchaarbythe
OfficeofNavalResearch(ONR),NSF172251.
References
[1] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and
improvingtheimagequalityofstylegan. InProceedingsoftheIEEE/CVFconferenceoncomputervisionand
patternrecognition,pages8110–8119,2020.
[2] PrafullaDhariwalandAlexanderNichol. Diffusionmodelsbeatgansonimagesynthesis. Advancesinneural
informationprocessingsystems,34:8780–8794,2021.
[3] ZhifengKong,WeiPing,JiajiHuang,KexinZhao,andBryanCatanzaro. Diffwave: Aversatilediffusionmodel
foraudiosynthesis. In9thInternationalConferenceonLearningRepresentations,ICLR2021,VirtualEvent,
Austria,May3-7,2021,2021.
[4] ChrisDonahue,JulianMcAuley,andMillerPuckette. Adversarialaudiosynthesis. InInternationalConference
onLearningRepresentations,2018.
[5] RobinRombach,AndreasBlattmann,DominikLorenz,PatrickEsser,andBjörnOmmer. High-resolutionimage
synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and
patternrecognition,pages10684–10695,2022.
[6] SanderDieleman,LaurentSartran,ArmanRoshannai,NikolaySavinov,YaroslavGanin,PierreHRichemond,
ArnaudDoucet,RobinStrudel,ChrisDyer,ConorDurkan,etal. Continuousdiffusionforcategoricaldata. arXiv
preprintarXiv:2211.15089,2022.
[7] AndreasLugmayr,MartinDanelljan,AndresRomero,FisherYu,RaduTimofte,andLucVanGool. Repaint:
Inpainting using denoising diffusion probabilistic models. In Proceedings of the IEEE/CVF Conference on
ComputerVisionandPatternRecognition,pages11461–11471,2022.
[8] ChitwanSaharia,JonathanHo,WilliamChan,TimSalimans,DavidJFleet,andMohammadNorouzi. Image
super-resolution via iterative refinement. IEEE Transactions on Pattern Analysis and Machine Intelligence,
45(4):4713–4726,2022.
[9] JosephLWatson,DavidJuergens,NathanielRBennett,BrianLTrippe,JasonYim,HelenEEisenach,Woody
Ahern,AndrewJBorst,RobertJRagotte,LukasFMilles,etal. Denovodesignofproteinstructureandfunction
withrfdiffusion. Nature,620(7976):1089–1100,2023.
[10] MinkaiXu,LantaoYu,YangSong,ChenceShi,StefanoErmon,andJianTang. Geodiff: ageometricdiffusion
modelformolecularconformationgeneration. ArXiv,abs/2203.02923,2022.
[11] Claudio Zeni, Robert Pinsler, Daniel Zügner, Andrew Fowler, Matthew Horton, Xiang Fu, Sasha Shysheya,
JonathanCrabbé,LixinSun,JakeSmith,etal. Mattergen: agenerativemodelforinorganicmaterialsdesign.
arXivpreprintarXiv:2312.03687,2023.
[12] FedericoGatta,FabioGiampaolo,EdoardoPrezioso,GangMei,SalvatoreCuomo,andFrancescoPiccialli.Neural
networksgenerativemodelsfortimeseries. J.KingSaudUniv.Comput.Inf.Sci.,34:7920–7939,2022.
[13] JinsungYoon,DanielJarrett,andMihaelaVanderSchaar. Time-seriesgenerativeadversarialnetworks. Advances
inneuralinformationprocessingsystems,32,2019.
[14] AhmedM.Alaa,AlexJ.Chan,andMihaelavanderSchaar. Generativetime-seriesmodelingwithfourierflows.
InInternationalConferenceonLearningRepresentations,2021.
[15] CristóbalEsteban,StephanieL.Hyland,andGunnarRätsch. Real-valued(medical)timeseriesgenerationwith
recurrentconditionalgans,2017.
[16] AapoHyvärinenandPeterDayan. Estimationofnon-normalizedstatisticalmodelsbyscorematching. Journalof
MachineLearningResearch,6(4),2005.
[17] JaschaSohl-Dickstein,EricWeiss,NiruMaheswaranathan,andSuryaGanguli. Deepunsupervisedlearningusing
nonequilibriumthermodynamics. InInternationalconferenceonmachinelearning,pages2256–2265.PMLR,
2015.
[18] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neural
informationprocessingsystems,33:6840–6851,2020.
10TimeSeriesDiffusionintheFrequencyDomain
[19] YangSong,JaschaSohl-Dickstein,DiederikPKingma,AbhishekKumar,StefanoErmon,andBenPoole. Score-
basedgenerativemodelingthroughstochasticdifferentialequations. InInternationalConferenceonLearning
Representations,2020.
[20] LequanLin,ZhengkunLi,RuikunLi,XuliangLi,andJunbinGao. Diffusionmodelsfortime-seriesapplications:
asurvey. FrontiersofInformationTechnology&ElectronicEngineering,pages1–23,2023.
[21] ThomasWilliamKörner. Fourieranalysis. Cambridgeuniversitypress,2022.
[22] KunYi,QiZhang,LongbingCao,ShoujinWang,GuodongLong,LiangHu,HuiHe,ZhendongNiu,WeiFan,
andHuiXiong. Asurveyondeeplearningbasedtimeseriesanalysiswithfrequencytransformation. CoRR,
abs/2302.02173,2023.
[23] DonghyeokShin,SeungjaeShin,andIl-ChulMoon. Frequencydomain-baseddatasetdistillation. arXivpreprint
arXiv:2311.08819,2023.
[24] AngusPhillips,ThomasSeror,MichaelHutchinson,ValentinDeBortoli,ArnaudDoucet,andEmileMathieu.
Spectraldiffusionprocesses. arXivpreprintarXiv:2209.14125,2022.
[25] BrianD.O.Anderson. Reverse-timediffusionequationmodels. StochasticProcessesandtheirApplications,
12(3):313–326,1982.
[26] YangSongandStefanoErmon. Generativemodelingbyestimatinggradientsofthedatadistribution. Advancesin
neuralinformationprocessingsystems,32,2019.
[27] Pascal Vincent. A connection between score matching and denoising autoencoders. Neural computation,
23(7):1661–1674,2011.
[28] PeterJ.SchreierandLouisL.Scharf. StatisticalSignalProcessingofComplex-ValuedData: TheTheoryof
ImproperandNoncircularSignals. CambridgeUniversityPress,2010.
[29] MohammadKachuee,ShayanFazeli,andMajidSarrafzadeh. Ecgheartbeatclassification: Adeeptransferable
representation. In2018IEEEinternationalconferenceonhealthcareinformatics(ICHI),pages443–444.IEEE,
2018.
[30] Alistair Johnson, Tom Pollard, and Roger Mark. Mimic-iii clinical database (version 1.4). PhysioNet,
10(C2XW26):2,2016.
[31] OlehOnyshchak. Stockmarketdataset,2020.
[32] BSahaandT.Goebel. Batterydataset,nasaamesprognosticsdatarepository,2007.
[33] ChristophMinixhofer. Predictdroughtsusingweatherandsoildata,2021.
[34] MartinHeusel,HubertRamsauer,ThomasUnterthiner,BernhardNessler,andSeppHochreiter. Ganstrainedby
atwotime-scaleupdateruleconvergetoalocalnashequilibrium. Advancesinneuralinformationprocessing
systems,30,2017.
[35] NicolasBonneel,JulienRabin,GabrielPeyré,andHanspeterPfister. Slicedandradonwassersteinbarycentersof
measures. JournalofMathematicalImagingandVision,51:22–45,2015.
[36] SangnamNam. AnUncertaintyPrincipleforDiscreteSignals. InSampTA,Bremen,Germany,2013.
[37] WernerHeisenberg. Überdenanschaulicheninhaltderquantentheoretischenkinematikundmechanik. Zeitschrift
fürPhysik,43(3):172–198,1927.
[38] PeterEKloeden,EckhardPlaten,PeterEKloeden,andEckhardPlaten.Stochasticdifferentialequations.Springer,
1992.
[39] ShirlyWang,MatthewBAMcDermott,GeetickaChauhan,MarzyehGhassemi,MichaelCHughes,andTristan
Naumann. Mimic-extract: A data extraction, preprocessing, and representation pipeline for mimic-iii. In
ProceedingsoftheACMconferenceonhealth,inference,andlearning,pages222–235,2020.
11TimeSeriesDiffusionintheFrequencyDomain
A Mathematicaldetails
A.1 DFTproperties
Proposition A.1 (Unitarity of the DFT operator). The DFT matrix U CN N with elements [U] :=
× κτ
∈
N 1/2exp( iω τ)withω := κ2π isunitary.
− − κ κ N
Proof. LetU denotetheconjugatetransposeofU. Foranyκandτ in[N],wehave:
∗
N 1
(cid:88)−
[UU ] = [U] [U ]
∗ κτ κβ ∗ βτ
β=0
N 1
1 (cid:88)−
= exp( iω β)exp(iω τ)
κ β
N −
β=0
N 1
1 (cid:88)−
= exp( iω β)
κ τ
N − −
β=0
Hence,ifκ = τ,wehave[UU ] = 1,otherwise[UU ] = 0,sinceexp( iω N) = 1. Thisisequivalentto
∗ κτ ∗ κτ κ τ
UU =I ,i.e. U isunitary. − −
∗ N
PropositionA.2. TheDFT˜x= [x]=Uxofareal-valuedtimeseriesx RdX verifiesthefollowingmirrorsymmetry
F ∈
forallκ [N]:
∈
˜x κ =˜x ∗N κ.
−
Proof. Letκandτ bein[N]. Wefirstnotethatexp(iω τ)=exp(i(ω ω )τ)=exp( iω τ). Hence,
N κ N κ κ
− − −
N 1
(cid:88)−
˜x∗N
κ
= [U]
∗N
κ,τx
τ
(xisrealvalued)
− −
τ=0
N 1
(cid:88)−
=N 1/2 exp(iω τ)x
− N κ τ
−
τ=0
N 1
(cid:88)−
=N 1/2 exp( iω τ)x
− κ τ
−
τ=0
N 1
(cid:88)−
= [U] x
κ,τ τ
τ=0
=˜x
κ
A.2 Densitiesandscoresforconstrainedsignals
AswehavementionedinSection2,theredundancybetweencertaincomponentsoftheDFT˜x CdX ofxexpressed
∈
by Equation (6) needs to be taken into account if we wish to define a density p˜for the time series distribution in
the frequency domain. In particular, this redundancy implies that the density is really defined on a submanifold
C ded
c
fioX
n ns etr
a:=
coo{
r˜x d= ina( t˜x
e0
c, h. a.. rt,˜x
φN
:−C1) dX∈CdX
|
R˜x
dκ
X= on˜x∗N
th− iκ s∀
sκ
ub∈
m[ aN ni]
f}
olo df bc yom exp tl re ax cts ii ng gna thls ef uu nlfi cl oli nn sg trath ine ec don ps at rr ta oin ft. aW De FTca ˜xn
.
constr →
ThisoperatorsimplyconcatenatestherelevantrealandimaginarypartsoftheDFTandisdefinedasfollowsforall
˜x CdX :
∈ constr
(cid:40)
φ[˜x]=
( ℜ[˜x κ])N κ=/2 0⊕( ℑ[˜x κ])N κ=/2 1−1 ifN ∈2N
(12)
( ℜ[˜x κ])⌊ κN =/ 02 ⌋ ⊕( ℑ[˜x κ])⌊ κN =/ 12 ⌋ else,
12TimeSeriesDiffusionintheFrequencyDomain
where v
1
v
2
denotes the concatenation of two vectors v
1
Rd1 and v
2
Rd2, with d 1,d
2
N. Due to
Equation(6⊕ ),onecanunambiguouslyreconstruct˜x CdX from∈ φ[˜x]. Hence,th∈ ecoordinatechartadm∈ itsaninverse
∈ constr
φ −1 :RdX →Cd coX
n
(cid:40)strdefinedasfollowsforallz=(z 0,...,z
N
−1) ∈RdX:
φ −1[z]= (( zz 00 )) ⊕⊕ (( zz κκ ++ ii ·· zz ⌊N N/ /2 2+ ⌋κ +) κN κ )=/ ⌊κ2 1 N =− / 11 2 ⌋⊕ ⊕(z (zN ⌈/ N2 /) 2⊕ ⌉−( κz −N/ i2 − ·zκ N− −i κ· )⌊κz N =N / 1−2 ⌋κ) κN =/2 1−1 i ef lsN e.∈2N (13)
Withthiscoordinatechart,itbecomespossibletorigorouslydefinethedensityp˜:CdX R+. Onesimplydefinesa
probabilitydensityp˜
φ
:RdX R+overtherealvectorspaceRdX onwhichthecoc oo rn ds it nr a→ techartisdefinedandpullit
→
backtothemanifoldofconstrainedsignalsp˜:= p˜ φ. Thisindeeddefinesadensitythatdependsontherealand
φ
◦
imaginarypartsofthefrequencyrepresentations˜x CdX oftimeseries,asannouncedinSection2.
∈ constr
Finally,itremainstorigorouslydefinethescore˜s : CdX [0,T] CdX inthefrequencydomain. Thiscanbe
donebystartingfromtherealscore˜s
φ
: RdX [0,T]constr R× dX thati→ swell-definedforallz RdX andt [0,T]
× → ∈ ∈
as˜s (z,t)= logp˜ (z). Again,onecanexpandthisvectorfieldtotheconstrainedmanifoldbydefiningforall
φ z φ,t
∇
˜x CdX andallt [0,T]:
∈ constr ∈
˜s(˜x,t):=φ 1[˜s (φ(˜x),t)]. (14)
− φ
Thisindeeddefinesavectorfieldinvolvingpartialderivativesofthelogdensitywithrespecttotherealandimaginary
parts of the frequency representations ˜x CdX of time series and respects the mirror symmetry by virtue of
∈ constr
Equation(13). EverythingisthenconsistentwiththediscussionfromSection2.
A.3 DiffusionSDEsinthefrequencydomain
Lemma3.1. (DFTofstandardBrownianmotion). LetwbeastandardBrownianmotiononRdX withd
X
=N M,
whereN N+ isthenumberoftimeseriesstepsandM N+ isthenumberoffeaturestrackedovertime. T· hen
∈ ∈
v =Uwisacontinuousstochasticprocessendowedwith:
(1)MirrorSymmetry. Forallκ [N],v =v .
(2)RealBrownianMotion. v
i∈ sa(real)κ standN∗ ar−dκ
BrownianmotiononRM.
0
(3)ComplexBrownianMotions. Forallκwith1 κ N/2 ,wecanwritev =(w˜1 +iw˜2)/√2wherew˜1 and
w˜2 areindependentstandardBrownianmotionso≤ nRM≤ ,⌊ excep⌋ twhenN isevenκ andκ=κ N/2,κ wherev isaκ real
κ N/2
standardBrownianmotiononRM.
W(4 e)I cn ad lle ap ne ynd ste on cc he a. sT tih ce ps rt oo cc eh sa ss st aic tip sfr yo ic ne gss thes e{ av b˜ κ ov} e⌊κN = c/ o02 n⌋ sta rr ae inm tsut aua mll iy rroin rd edep Ben rod wen nt i. anmotiononCdX.
Proof. (1)MirrorSymmetry. ThispointdirectlyfollowsfromthesymmetryoftheDFT,provedinPropositionA.2.
Inwhatfollows,weconsiderwithoutlossofgeneralitythecaseM =1,sincethecasesM >1canbehandledsimilarly
by flattening matrices into vectors and using the same arguments as below. Let us first decompose U into its real
andimaginaryparts,i.e. U =U +iU ,whereU andU areinRN N. Notethatthesetwomatricesareboth
re im re im ×
symmetric. Computingthedistributionofthecomponentsofv willrequiretheknowledgeofcovariancematrices,
whichwilldependonU2 ,U2 andU U . Foranyκandτ in[N],
re im re im
N 1
1 (cid:88)− 2π 2π
[U2 ] = cos( κγ)cos( τγ)
re κ,τ N N N
γ=0
N 1
1 (cid:88)− (cid:0) 2π 2π (cid:1)
= cos( (κ+τ)γ)+cos( (κ τ)γ)
2N N N −
γ=0
Similarly,
N 1
1 (cid:88)− 2π 2π
[U2 ] = sin( κγ)sin( τγ)
im κ,τ N N N
γ=0
N 1
1 (cid:88)− (cid:0) 2π 2π (cid:1)
= cos( (κ τ)γ) cos( (κ+τ)γ)
2N N − − N
γ=0
13TimeSeriesDiffusionintheFrequencyDomain
Tocomputethesesums,weconsiderthesituationswhere:
• N κ τ: thisisequivalenttoκ=τ,since (N 1) κ τ N 1
| − − − ≤ − ≤ −
• N κ+τ: thisisequivalenttoκ=τ =0orκ+τ =N,since0 κ+τ 2(N 1)
| ≤ ≤ −
Hence,ifN iseven:
 1 ifκ=τ =0orκ=τ = N
2
 0
1
i if fκ κ=
/
τ 0= ,N0 /o 2rκ an= dκτ = =τN 2
[U2 ] = 1 ifκ / 0,N/2 andκ=τ orκ=N τ and[U2 ] = 2 ∈{ }
re κ,τ  02 othe∈ rw{ ise } − im κ,τ −1 2 ifκ ̸= N/2andκ=N −τ
0 otherwise
(15)
IfN isodd:


1 ifκ=τ =0
0
1
i if fκ κ= =τ 0a= nd0
κ=τ
[U2 ] = 1 ifκ=0andκ=τ,orκ=N τ and[U2 ] = 2 ̸ (16)
re κ,τ  02 othe̸ rwise − im κ,τ −1 2 ifκ=N −τ
0 otherwise
Finally,wecomputeU U :
re im
N 1
1 (cid:88)− 2π 2π
[U U ] = cos( κγ)sin( τγ)
re im κ,τ
N N N
γ=0
N 1
1 (cid:88)− (cid:0) 2π 2π (cid:1)
= sin( (τ κ)γ)+sin( (κ+τ)γ)
2N N − N
γ=0
=0
Hence,U U =0 andsimilarlyU U =0 bytakingthetransposeandusingthesymmetryofU andU .
re im N im re N re im
(cid:18) (cid:19)
U
Wecannowcharacterizethedistributionfollowedbythestochasticprocessv. WefirstwriteU = re ,andthen
col U
im
noticethatvcanbeinvestigatedthroughthelensofitsflattenedversionv =U w,whichisastochasticprocess
flat col
inR2N.
(2)RealBrownianMotion. First,v isreal-valued,byusing(1)MirrorSymmetry. Wethenhavethefollowing:
0
• v (0)=0almostsurely:thisstemsfromw(0)=0almostsurely,sincewisamultivariatestandardBrownian
0
motionandv =Uw.
• Continuityoft v (t)almostsurely: wsatisfiesthecontinuitypropertyandtheDFToperator(seenasa
0
→
complexoperator)islinear,hencev isalsocontinuouswithrespecttotalmostsurely.
0
• Stationaryandindependentincrements: thisfollowsfromthelinearityoftheDFToperatorandwbeinga
Brownianmotion.
• Foranyt,s 0,v (t+s) v (s) (0,t): toseethis,wenoticethatv (t+s) v (s)isGaussian3
0 0 0 0
≥ − ∼ N −
sinceitisalineartransformofw(t+s) w(s). Moreover,itsmeananditsvariancearegivenby:
−
E(cid:2) v (t+s) v (s)(cid:3) =(cid:2) U E[w(t+s) w(s)](cid:3)
0 − 0 col − 0
=0
Var(v (t+s) v (s))=(cid:2) U Cov(cid:0) w(t+s) w(s),w(t+s) w(s)(cid:1) UT )(cid:3)
0 − 0 col − − col 0,0
=t[U UT ]
col col 0,0
=t[U2 ]
re 0,0
=t
3Notethatarandomvariablealmostsurelyequalto0canbeseenasadegenerateGaussianwithmean0andvariance0.
14TimeSeriesDiffusionintheFrequencyDomain
Hence,wehaveshownthatv isarealBrownianmotion.
0
(3)ComplexBrownianMotions. Let1 κ< N/2 . Then, (v )and (v )followthefirstthreepropertiesofa
κ κ
≤ ⌊ ⌋ ℜ ℑ
Brownianmotion,usingthesameargumentsasabove. Forthelastpoint,wefirstcharacterizethedistributionof (v )
κ
ℜ
and (v ),andthenshowthattheyareindependent.
κ
ℑ
Distributionof (v ). √2 (v )isastandardBrownianmotioninR: Foranyt,s 0, (v )(t+s) (v )(s)is
κ κ κ κ
ℜ ℜ ≥ ℜ −ℜ
Gaussiansinceitisalineartransformofw(t+s) w(s)whichisaGaussianvector. Wecancomputeitsmeanandits
−
variance:
E(cid:2) (v )(t+s) (v )(s)(cid:3) =(cid:2) U E[w(t+s) w(s)](cid:3)
ℜ κ −ℜ κ col − κ
=0
Var(cid:0) (v )(t+s) (v )(s)(cid:1) =(cid:2) U Cov(cid:0) w(t+s) w(s),w(t+s) w(s)(cid:1) UT )(cid:3)
ℜ κ −ℜ κ col − − col κ,κ
=t[U UT ]
col col κ,κ
=t[U2 ]
re κ,κ
1
= t
2
Distributionof (v ). Similarly,wecanprovewiththesameargumentsthat√2 (v )isastandardBrownianmotion
κ κ
inR. ℑ ℑ
Independence of (v ) and (v ). Let k and m be two strictly positive integers, and let (t ,...,t ) (R )k
and (t ,...,t ) ℜ
(Rκ
)m. ℑ
Weκ
need to show that the vectors vre = (cid:0) (v )(t ),..., (v
)1
(t
)(cid:1)k
and∈
vim∗+
=
(cid:0) ′1 ′m ∈ ∗+ (cid:1) κ ℜ κ 1 ℜ κ k κ
(v )(t ),..., (v )(t ) are independent. First, the concatenation of vre and vim can be expressed as a lin-
ℑ κ ′1 ℑ κ ′m κ κ
ear transform of (w(t ),...,w(t ),w(t ),...,w(t )), which is a Gaussian vector since w is a Brownian motion.
1 k ′1 ′m
Consequently,(vre,vim)isalsoaGaussianvector. Now,letl 1,...,k andn 1,...,m . Then,
κ κ ∈{ } ∈{ }
(cid:0) (cid:1) (cid:2) (cid:0) (cid:1) (cid:3)
Cov (v )(t ), (v )(t ) = U Cov w(t ),w(t ) U
ℜ κ l ℑ κ ′n re l ′n im κ,κ
=min(t ,t )[U U ]
l ′n re im κ,κ
=0
Given this covariance structure and the fact that (vre,vim) is a Gaussian vector, we have vre vim. Since this
κ κ κ ⊥⊥ κ
holdstrueforanychoiceof(t ,...,t ) R k and(t ,...,t ) R m,weconcludethat (v ) (v ). Thecase
1 k
∈
∗+ ′1 ′m
∈
∗+
ℜ
κ
⊥⊥ℑ
κ
k = N canbehandledusingthesamearguments,bydistinguishingthecasesN oddandN even.
⌊2⌋
(4) Independence. The mutual independence of the stochastic processes {v˜ κ }⌊κN =/ 02 ⌋ follows from the structure
of U2 and U2 . Indeed, for any m and n such that m = n, 0 m N , and 0 n N , we have
re im ̸ ≤ ≤ ⌊2⌋ ≤ ≤ ⌊2⌋
[U2 ] =[U2 ] =[U U ] =0. Wecanthenapplythesameargumentasin3)of(3)ComplexBrownian
re m,n im m,n re im m,n
Motionstoobtainthemutualindependenceofthestochasticprocesses {v˜
κ
}⌊κN =/ 02 ⌋.
Proposition3.3. (Diffusionprocessinfrequencydomain). Letusassumethatxisadiffusionprocessthatisasolution
ofEquation(1),withG(t)=g(t)I . Then ˜x= [x]isasolutiontotheforwarddiffusionprocessdefinedby:
N
F
d˜x=f˜(˜x,t)dt+g(t)dv˜, (7)
wheref˜(˜x,t)=Uf(U ∗˜x,t)andv˜isamirroredBrownianmotiononCdX. Theassociatedreversediffusionprocessis
definedby:
d˜x=b˜(˜x,t)dt+g(t)dv˘ (8)
whereb˜(˜x,t)=f˜(˜x,t) g2(t)Λ2˜s(˜x,t),Λ RN N isadiagonalmatrixdefinedinAppendixA.3,dtisanegative
×
infinitesimaltimestep,a− ndv˘isamirroredB∈ rownianmotiononCdX withtimegoingfromT to0.
Proof. ForwardSDE.Since˜x=Ux,wecanapplythemultivariateItô’slemma(Eq. 8.3,[38]),andobtainaforward
SDEfor˜x:
d˜x=Uf(x,t)dt+g(t)Udw (17)
′
wherewehaveimplicitlyusedthefactthatG(t)=g(t)I andU commute. ByLemma3.1,v˜=Uw isamirrored
N ′
BrownianmotiononCdX,whichgivestheresult.
15TimeSeriesDiffusionintheFrequencyDomain
ReverseSDE.InordertoderivethereverseSDEfor˜x,wefollowthreesteps: (1)wewriteaforwardSDEforwhichthe
truncationφ[˜x]isasolution;(2)wewriteitsassociatedreverse-timeSDE[25]and(3)wederivethefullreverseSDE
forthestochasticprocess˜x.
Step1:FromEquation(17)andusingLemma3.1,wecanextractthefollowingforwardSDEforφ[˜x],whichisdefined
inEquation(12):
dφ[˜x]=φ(cid:2)
Uf(U φ
1(φ[˜x]),t)(cid:3)
dt+g(t)Λdw˘ (18)
∗ −
where:
• φ −1 :RdX CdX satisfiesφ −1(φ[Uy])=Uyforally RdX asdefinedinEquation(13).
→ ∈
(cid:40)
1 ifκ=0,orN isevenandκ=N/2
• Λ RN N isadiagonalmatrixsuchthat[Λ] = ,
∈ × κ,κ 1 otherwise
√2
• w˘ isastochasticprocessinRdX whichsatisfiesΛw˘ =φ[Uw ′]. Theabovepoint,togetherwithLemma3.1),
thenimpliesthatw˘ isinfactastandardmultivariateBrownianmotion.
Step2:Theassociatedreverse-timeSDE[25]isgivenby:
dφ[˜x]=(cid:8) φ(cid:2) Uf(U φ 1(φ[˜x]),t)(cid:3) g(t)2ΛΛT logp˜(φ[˜x])(cid:9) dt+g(t)Λdw (19)
∗ − φ[˜x] t (cid:98)
− ∇
wherew
(cid:98)
isastandardBrownianmotiononRdX.
Step3:Sinceφ 1(φ[˜x])=˜x,wecanrecoverthereverse-timeSDEfollowedby˜xbyapplyingtheoperatorφ 1toφ[˜x],
− −
andusingtheItô’slemma:
d˜x=(cid:8) φ 1(φ(cid:2) Uf(U φ 1(φ[˜x]),t)(cid:3) ) g(t)2φ 1(cid:0) Λ2 logp˜(φ[˜x])(cid:1)(cid:9) dt+g(t)φ 1(Λ)dw (20)
− ∗ − − φ[˜x] t − (cid:98)
− ∇
wherewehaveexploitedthefactthatφ 1islinear,andwiththeslightabuseofnotationφ 1(Λ) CN N,whichis
− − ×
thematrixobtainedbyapplyingφ 1tothecolumnsofΛ. Usingthedefinitionofφ 1,Equation∈ (20)canfurtherbe
− −
simplifiedinto:
d˜x=(cid:8) Uf(U ˜x,t) g(t)2φ 1(cid:0) Λ2 logp˜(φ[˜x])(cid:1)(cid:9) dt+g(t)dv˘ (21)
∗ − φ[˜x] t
− ∇
wherev˘ = φ −1(Λ)w
(cid:98)
= φ −1(Λw (cid:98))isamirroredBrownianmotion. Finally,noticethatforanyy RdX,wehave
φ 1(Λ2y)=Λ2φ 1(y),whichfollowsfromthedefinitionofφ 1. Hence,Equation(21)isequivale∈ ntto:
− − −
d˜x=(cid:8)
Uf(U ˜x,t)
g(t)2Λ2˜s(˜x,t)(cid:9)
dt+g(t)dv˘ (22)
∗
−
where˜s(˜x,t)hasbeendefinedinEquation(14).
A.4 Denoisingscorematchinginthefrequencydomain
Proposition3.4. (Scorematchingequivalence). Considerascore˜s θ˜:CdX ×[0,T] →CdX definedinthefrequency
domain and satisfying the mirror symmetry [˜s ] = [˜s ] for all κ [N]. Let us define an auxiliary score
s
′ θ˜
: RdX ×[0,T]
→
RdX as(x,t)
(cid:55)→
s
′
θ˜(x,t)θ˜ =κ U ∗˜s θ˜(∗ θ˜ UN x,− tκ )inthetime∈ domain. Thescorematchinglossinthe
frequencydomainisequivalenttothescorematchinglossfortheauxiliaryscoreinthetimedomain:
(cid:0) ˜s ,Λ2˜s ,˜x,t(cid:1) = (cid:0) s ,s ,x,t(cid:1) (10)
LSM θ˜ t |0 LSM ′ θ˜ t |0
where˜s (˜x,t) = logp˜ (˜x(t)˜x(0)) , s (x,t) = logp (x(t)x(0)), and Λ is the diagonal matrix in
t0 ˜x(t) t0 t0 x(t) t0
Propositi|on3.3. ∇ | | | ∇ | |
(cid:40)
1 ifκ=0,orN isevenandκ=N/2
Proof. LetΛ RN N bethediagonalmatrixsuchthat[Λ] =
∈ × κ,κ 1 otherwise
√2
Step1:Wefirstexpressthescoreofxwithrespecttothescoreofthetruncationφ[˜x].
Bydefinitionofφ 1inEquation(13),wehavex=U φ 1(φ[˜x]). Hence,wecanwrite,usingthechangeofvariable
− ∗ −
formula:
(cid:0) (cid:1)
p (x(t)x(0))=C p˜ φ[˜x(t)]φ[˜x(0)] (23)
t0 t0
| | · | |
16TimeSeriesDiffusionintheFrequencyDomain
whereC isaconstantwhichdoesnotdependonx,sincex φ[Ux]islinear. Moreover,letuswritex φ[Ux]in
(cid:55)→ (cid:18) (cid:19) (cid:55)→
U
matrixform, i.e. ∀x
∈
RdX, φ[Ux] = VU colx = Qx, whereV
∈
RN ×2N, U
col
=
U
ir me andQisaninvertible
matrixinRN N. Fortherestoftheproof,weshallbuildonthebelowresults:
×
(cid:18) (cid:19)
U2 0
Result1. QQT = Λ2. Toseethis,writeQQT = VU UT VT. ThematrixU UT isequalto re N (cf.
col col col col 0 U2
N im
theprooftoLemma3.1),whilethemultiplicationbyV,ontheleftandontherightofU UT ,extractsthesubmatrix
col col
correspondingtotheindicesrepresentedbythetruncatureφ. Hence,VU UT VT =Λ2.
col col
Result 2. For any x RdX , we have QTx = U ∗φ −1[Λ2x]. To see this, notice that Result 1 implies that QTx =
Q −1Λ2x=U ∗φ −1[Λ∈ 2x]forallx RdX.
∈
Equippedwiththeseresults,wecannowcompletetherestoftheproof. First,wehave:
(cid:0) (cid:1)
logp (x(t)x(0))= logp˜ φ[˜x(t)]φ[˜x(0)] (24)
x(t) t0 x(t) t0
∇ | | ∇ | |
=QT logp˜ (φ[˜x(t)]φ[˜x(0)]) (Chainrule) (25)
φ[˜x(t)] t0
∇ | |
Step2:Wethenobtain:
(cid:0) s ,s ,x,t(cid:1) := s (x,t) logp (x(t)x(0)) 2
LSM ′ θ˜ t |0 ∥ ′ θ˜ −∇x(t) t |0 | ∥
= Us (x,t) U logp (x(t)x(0)) 2 (Parsevalidentity)
∥ ′ θ˜ − ∇x(t) t |0 | ∥
= ˜s (˜x,t) UQT logp˜ (φ[˜x(t)]φ[˜x(0)]) 2 (Equation(25))
∥
θ˜
−
∇φ[˜x(t)] t |0
| ∥
= ˜s (˜x,t) UU φ 1[Λ2 logp˜ (φ[˜x(t)]φ[˜x(0)]] 2 (Result2)
∥
θ˜
−
∗ − ∇φ[˜x(t)] t |0
| ∥
= ˜s (˜x,t) Λ2φ 1[ logp˜ (φ[˜x(t)]φ[˜x(0)]] 2 (PropositionA.1&Definitionofφ 1)
∥
θ˜
−
− ∇φ[˜x(t)] t |0
| ∥
−
= ˜s (˜x,t) Λ2˜s (˜x,t) 2 (Equation(14))
=∥
θ˜
(cid:0) ˜s
,−
Λ2˜s
t ,|0
˜x,t(cid:1)
.∥
LSM θ˜ t |0
B Empiricaldetails
Computeresources. Allthemodelsweretrainedandusedforsamplingonasinglemachineequippedwitha18-Core
IntelCorei9-10980XECPU,aNVIDIARTXA4000GPUandaNVIDIAGeForceRTX3080.
B.1 Detailsondatasets
Inthissubsection,wegivedetailedinformationaboutthe6datasetsusedthroughoutourexperimentsandtheprepro-
cessingstepsforeachofthem.
ECG.Weusetwocollectionsofheartbeatsignals,fromtheMIT-BIHArrhythmiaDatasetandthePTBDiagnostic
ECGDatabase[29]. Nopreprocessingwasperformedonthisdataset.
MIMIC-III.MIMIC-III[30]isadatabaseconsistingofdeidentifiedrecordsforpatientswhowereincriticalunitcare
units. Preprocessing. Weusethe"vitalslabs"tableofthedatabase,whichcorrespondstotime-varyingvitalsandlabs.
Weextracttherowsofthedatasetwhichcorrespondtothefirst24hoursofstaybyusingMIMIC-Extract[39]. The
featuresarethenstandardizedacrossalltimesandpatients. Wealsoperformimputationtohandlemissingvaluesinthe
dataset. Todoso,weconsiderthemeanfeatures(averagemeasurementover1hour). Foreachpatient,andmissing
value,wepropagatethelastobservationforwardifthisispossible. Ifnot,wefillthemissingvaluewiththemeanvalue
forthepatient(whichiscomputedoverthewholestay). Ifnomeanvalueisavailable,wefilltheentrywith0.
NASDAQ-2019. Thisdataset[31]containsdailypricesfortickerstradingonNASDAQ,andcontainspricesforupto
1stofApril2020. Preprocessing. Weconsideredoneyearofdailypricesfrom1stofJanuary2019to1stofJanuary
2020. Eachsamplecorrespondstoonestock,andweremovethestockswhicharenotactiveinthiswholetimeinterval,
orcontainmissingvalues.
NASAbattery. TheNASAbatterydataset[32]consistsofprofilesforLi-onbatteries,underchargeanddischarge.
Preprocessing. Forboththechargeanddischargedatasets,webinthetimevalues(binsofsize10forCharge,15for
Discharge)andcomputethemeanofeachfeatureinsideeachbin.
17TimeSeriesDiffusionintheFrequencyDomain
US-Droughts. Thisdataset[33]consistsofdroughtlevelsindifferentUScounties,from2000to2020. Preprocessing.
Weconsideroneyearofhistory,from1stofJanuary2011to1stofJanuary2012,anddropthecolumnswithmissing
values.
B.2 Detailsonevaluation
SlicedWassersteindistances. TheslicedWassersteindistance[35]isametricwhichcanhandlehigh-dimensional
distributions. ItismotivatedbythefactthattheWassersteindistanceiseasytocomputewhencomparingtwoone-
dimensionaldistributions. TheideaoftheslicedWassersteindistanceistomapthehigh-dimensionaldistributionsof
interesttoone-dimensionaldistributions,byconsideringrandomprojectionsonvectorsoftheunitsphere. Fortwo
distributionsµ andµ ,itcanbewrittenas:
1 2
(cid:90)
SW (µ ,µ ):= W (P #µ ,P #µ )du (26)
p 1 2 p u 1 u 2
Sd−1
where Sd 1 is the unit sphere in dimension d, P (x) = u x denotes the projection of x on u, P #µ is the push-
− u u
·
forwardofµbyP ,andW istheWassersteindistanceoforderp. Toestimatethisquantityinpractice,wesample
u p
n=10,000randomvectors u i [n] whichfollowauniformdistributioninSd 1andconsiderp=2. Hence,we
i −
{ | ∈ }
canapproximateSW bytheMonte-carloestimator:
p
n
1 (cid:88)
SˆW (µ ,µ )= W (P #µ ,P #µ ) (27)
p 1 2
n
p ui 1 ui 2
i=1
Marginal Wasserstein distances. In addition to the sliced Wasserstein distance, we also consider the marginal
Wassersteindistance. Foranyj 1,...,d ,thej-thmarginalWassersteindistanceisdefinedas:
∈{ }
MW (j)(µ ,µ )=W (P #µ ,P #µ ) (28)
p 1 2 p ej 1 ej 2
wheree isthej-thvectorofthestandardbasisofRd. ThroughoutourexperimentsinSection4,wecomputethe
j
Wassersteindistanceswithrespectto and ˜ .
train train
D D
B.3 Additionalplots
SlicedWassersteindistances. InFigure4,weshowthedistributionoftheslicedWassersteindistancesoverallslices.
Inaddition,wehaveincludedtheaverageslicedWassersteindistancesobtainedwith2baselines. Thefirstbaseline
issimplytheWassersteindistancebetweenthetrainingsetandasetofsampleonlycontainingidenticalcopiesthe
averagesampleSW( , ),where = E )[X] . Itrepresentstheperformanceofadummy
generatorthatonlygeD netr ra ai tn esS tm heea an veragetimS em sea en riesa{ ndX i∼sU de( Dnt or ta ein dbym}
eaninFigure4. Thesecondbaselineisthe
WassersteindistancebetweentworandomsplitsofthetrainingsetSW( 1/2 , 2/2 ),where = 1/2 (cid:70) 2/2
Dtrain Dtrain Dtrain Dtrain Dtrain
isadecompositionofthetrainingsetintotwodisjointrandomsplitsofequalsize 1/2 = 2/2 . Itrepresentsthe
|Dtrain| |Dtrain|
distancebetweentwosamplesfromtheground-truthdistributionandisdenotedbyself inFigure4. Aswecanobserve,
boththetimeandfrequencydiffusionmodelssubstantiallyoutperformthemeanbaseline(asexpected)andperform
onparwiththeself baseline. Thisindicatesthatthemodelslearnedagoodapproximationoftherealdistribution.
Furthermore, we notice that the frequency diffusion models tend to have smaller quantiles than the time diffusion
models. Thisconfirmsthatfrequencydiffusionmodelsoutperformthetimediffusionmodels,asdiscussedinSection4.
MarginalWassersteindistances. InFigure5,weshowthedistributionofthemarginalWassersteindistancesoverall
slices. Inaddition,wehaveincludedtheaveragemarginalWassersteindistancesobtainedwiththe2baselinesdefined
inthepreviousparagraph. Again,boththetimeandfrequencydiffusionmodelstendtooutperformthemeanbaseline
(asexpected)andperformonparwiththeself baseline. Furthermore,wenoticethatthefrequencydiffusionmodels
tendtohavesmallerquantilesthanthetimediffusionmodels. Thisisconsistentwiththeobservationsmadeinthe
aboveparagraph.
Per-samplelocalization. InFigure6,weobservethedistributionofourlocalizationmetrics∆ and∆ for
time sigma
eachsampleandeachdatasetfromSection4. Wenoticethatmostsamplesarelocatedbelowthey =xaxis,which
confirmsthefactthatmostsamplesaremorelocalizedinthefrequencydomain. Interestingly,wealsoobservethat
noneofthesamplesislocatedclosetotheorigin. Thisconfirmstheuncertaintytheoremfrom[36].
18TimeSeriesDiffusionintheFrequencyDomain
Baseline
0.8 TimeDiff.
Frequ.Diff. 0.15 Mean HalfTrain
0.6
Baseline
0.10 TimeDiff.
Frequ.Diff.
Mean 0.4
HalfTrain
0.05
0.2
0.00 0.0
Frequency Time Frequency Time
MetricDomain Metric Domain
(a)ECG. (b)MIMIC-III.
0.6
Baseline Baseline
TimeDiff. TimeDiff.
Frequ.Diff. 0.5 Frequ.Diff. 150 Mean Mean
HalfTrain HalfTrain
0.4
100
0.3
0.2
50
0.1
0
0.0
Frequency Time Frequency Time
MetricDomain Metric Domain
(c)NASDAQ-2019. (d)NASA-Charge.
Baseline
Baseline 6 TimeDiff.
TimeDiff. Frequ. Diff.
Frequ.Diff. Mean 150 Mean HalfTrain
HalfTrain
4
100
2
50
0 0
Frequency Time Frequency Time
MetricDomain Metric Domain
(e)NASA-Discharge. (f)US-Droughts.
Figure4: SlicedWassersteindistancesoftimeandfrequencydiffusionmodels.
19
) (nietsressaWdecilS
) (nietsressaWdecilS
) (nietsressaWdecilS
↓
↓
↓
) ( nietsressaW
decilS
) (
nietsressaW
decilS
)
( nietsressaW
decilS
↓
↓
↓TimeSeriesDiffusionintheFrequencyDomain
Baseline
Baseline
TimeDiff. 0.8 TimeDiff. 0.15 Frequ.Diff. Frequ.Diff. Mean Mean
HalfTrain 0.6 HalfTrain
0.10
0.4
0.05
0.2
0.00 0.0
Frequency Time Frequency Time
MetricDomain Metric Domain
(a)ECG. (b)MIMIC-III.
Baseline Baseline
100 TimeDiff. 0.6 TimeDiff. Frequ.Diff. Frequ.Diff. Mean Mean
80 HalfTrain HalfTrain
0.4
60
40
0.2
20
0 0.0
Frequency Time Frequency Time
MetricDomain Metric Domain
(c)NASDAQ-2019. (d)NASA-Charge.
Baseline
5
Baseline TimeDiff.
100 TimeDiff. Frequ. Diff. 80 F M Hr aee laq fnu T. raD ii nff. 4 M Hae la fn Train
3
60
2
40
20 1
0 0
Frequency Time Frequency Time
MetricDomain Metric Domain
(e)NASA-Discharge. (f)US-Droughts.
Figure5: MarginalWassersteindistancesoftimeandfrequencydiffusionmodels.
20
) (nietsressaWlanigraM
) (nietsressaWlanigraM
) (nietsressaWlanigraM
↓
↓
↓
) ( nietsressaW
lanigraM
) ( nietsressaW
lanigraM
) ( nietsressaW
lanigraM
↓
↓
↓TimeSeriesDiffusionintheFrequencyDomain
Figure6: Localizationmetrics∆ and∆ forallthesamplesofalldatasets. Weobservethatnosamplehasa
time freq
highlocalization(i.e. low∆)inthetimeandfrequencydomainsimultaneously.
Baseline
Baseline
TimeDiff. 0.8 TimeDiff.
0.15 Frequ.Diff. Frequ.Diff. Mean Mean HalfTrain HalfTrain
0.6
0.10
0.4
0.05
0.2
0.00 0.0
Time Frequency Time Frequency
MetricDomain Metric Domain
(a)ECG. (b)MIMIC-III.
Baseline Baseline
5
TimeDiff. TimeDiff.
Frequ. Diff. 3 Frequ. Diff.
Mean Mean 4
HalfTrain HalfTrain
3 2
2
1
1
0 0
Time Frequency Time Frequency
Metric Domain Metric Domain
(c)NASA-Discharge. (d)US-Droughts.
Figure7: SlicedWassersteindistancesoftimeandfrequencyLSTMmodels.
21
) (nietsressaWdecilS
)
(
nietsressaW
decilS
↓
↓
) ( nietsressaW
decilS
)
(
nietsressaW
decilS
↓
↓TimeSeriesDiffusionintheFrequencyDomain
C Alternativebackbone
LSTMmodels. Foreachdataset,wetryanalternativeparametrizationofthetimescoremodels andthefrequency
θ
scoremodel˜s asLSTMencoderswith10layers, eachwithdimensiond = 72. Bothmodelshavediffusion
θ˜ model
timetencodingthroughrandomFourierfeaturescomposedwithalearnabledenselayer. Thisresultsinmodelswith
427kparameters. ThedataisnoisedbyusingaVP-SDE,asin[19]. Thescoremodelsaretrainedwiththedenoising
score-matchingloss,asdefinedinSection3. Allthemodelsaretrainedfor200epochswithbatchsize64,AdamW
optimizerandcosinelearningratescheduling(20warmupepochs,lr =10 3). Theselectedmodelachievesthe
max −
lowestvalidationloss.
SlicedWassersteindistances. InFigure7,weshowthedistributionoftheslicedWassersteindistancesoverallslices
fortheLSTMmodels. Inaddition,wehaveincludedtheaverageslicedWassersteindistancesobtainedwith2baselines
defined in Appendix B.3. As observed for the transformer models, both the time and frequency diffusion models
substantiallyoutperformthemeanbaseline(asexpected)andperformonparwiththeself baseline. Thisindicates
that the models learned a good approximation of the real distribution. Furthermore, we notice that the frequency
diffusionmodelstendtohavesmallerquantilesthanthetimediffusionmodels. Thisconfirmsthatfrequencydiffusion
modelsoutperformthetimediffusionmodels,asobservedforthetransformermodelsinSection4. Wenotethatthe
Nasa-ChargeandtheNASDAQ-2019areabsentfromFigure7. Thisisbecausewedidnotmanagetoobtaindiffusion
modelsperformingbetterthanthemeanbaselineforthesedatasets,henceleadingtononinformativecomparisons
betweenmodelswithpoorperformances.
Otherattempts. Inordertominimizetheinductivebiasinourmodels,wealsotriedtotraindiffusionmodelswith
simplefeed-forwardneuralnetworks. Unfortunately,thisattemptwasunsuccessfulandresultedinmodelsperforming
worsethanthemeanbaselineineachcase. Thisemphasizesthevalueofincorporatinginductivebiasesintimeseries
diffusionmodels.
D Samplevisualization
InFigures8to12,wevisualizeafewexamplesgeneratedbyeachdiffusionmodel,alongwithground-truthtraining
examples. WedonotincludesamplesfromtheMIMIC-IIIdatasetinaccordancewiththedatasetlicence. Weobserve
thatthefrequencydiffusionmodelsgeneratesamplesthataresubstantiallylessnoisythanthantheonesgenerated
by time diffusion models. All the generated samples resemble training samples, with the only exception of the
NASDAQ-2019dataset. Themodelsappeartobestrugglingwiththehighcorrelationbetweenthedifferentfeatures.
22TimeSeriesDiffusionintheFrequencyDomain
Trainingsamples Generatedsamples(Frequencydomainmodel) Generatedsamples(Timedomainmodel)
1.0 Feature0 1.0 Feature0 1.0 Feature0
0.8 0.8 0.8
0.6 0.6 0.6
0.4 0.4 0.4
0.2 0.2 0.2
0.0 0.0 0.0
0 25 50 75 100 125 150 175 0 25 50 75 100 125 150 175 0 25 50 75 100 125 150 175
1.0 Feature0 1.0 Feature0 1.0 Feature0
0.8 0.8 0.8
0.6 0.6 0.6
0.4 0.4 0.4
0.2
0.2 0.2
0.0
0.0 0.0
0 25 50 75 100 125 150 175 0 25 50 75 100 125 150 175 0 25 50 75 100 125 150 175
1.2
1.0 Feature0 Feature0 1.0 Feature0
1.0
0.8 0.8
0.8
0.6 0.6
0.6
0.4 0.4 0.4
0.2 0.2 0.2
0.0
0.0 0.0
0 25 50 75 100 125 150 175 0 25 50 75 100 125 150 175 0 25 50 75 100 125 150 175
1.0 Feature0 1.0 Feature0 1.0 Feature0
0.8 0.8 0.8
0.6 0.6 0.6
0.4 0.4 0.4
0.2 0.2 0.2
0.0 0.0 0.0
0 25 50 75 100 125 150 175 0 25 50 75 100 125 150 175 0 25 50 75 100 125 150 175
1.0 Feature0 Feature0 1.0 Feature0
0.8 0.8 0.8
0.6 0.6 0.6
0.4 0.4 0.4
0.2 0.2 0.2
0.0 0.0 0.0
0 25 50 75 100 125 150 175 0 25 50 75 100 125 150 175 0 25 50 75 100 125 150 175
Figure8: SamplesfortheECGdataset. Theyaxiscorrespondstothedifferentfeatures,whilethexaxiscorrespondsto
thedifferenttimesteps.
23TimeSeriesDiffusionintheFrequencyDomain
Trainingsamples Generatedsamples(Frequencydomainmodel) Generatedsamples(Timedomainmodel)
5 5
4
4 4
3
3 Feature0 3 Feature0 Feature0
Feature1 Feature1 Feature1
Feature2 Feature2 2 Feature2
2 Feature3 2 Feature3 Feature3
1 1 1
0 0 0
0 50 100 150 200 250 0 50 100 150 200 250 0 50 100 150 200 250
5 5
6
4 4 5
3 F Fe ea at tu ur re e0 1 3 F Fe ea at tu ur re e0 1 4 F Fe ea at tu ur re e0 1
Feature2 Feature2 3 Feature2
2 Feature3 2 Feature3 Feature3
2
1 1 1
0 0 0
0 50 100 150 200 250 0 50 100 150 200 250 0 50 100 150 200 250
5
5 5
4 4 4
3 F Fe ea at tu ur re e0 1 3 F Fe ea at tu ur re e0 1 3 F Fe ea at tu ur re e0 1
2 F Fe ea at tu ur re e2 3 2 F Fe ea at tu ur re e2 3 2 F Fe ea at tu ur re e2 3
1 1 1
0 0 0
0 50 100 150 200 250 0 50 100 150 200 250 0 50 100 150 200 250
5 5 5
4 4 4
3 Feature0 3 Feature0 3 Feature0
Feature1 Feature1 Feature1
Feature2 Feature2 Feature2
2 Feature3 2 Feature3 2 Feature3
1 1 1
0 0 0
0 50 100 150 200 250 0 50 100 150 200 250 0 50 100 150 200 250
5 5 6
5
4 4
4
3 Feature0 3 Feature0 Feature0
Feature1 Feature1 3 Feature1
Feature2 Feature2 Feature2
2 Feature3 2 Feature3 2 Feature3
1 1 1
0
0 0
0 50 100 150 200 250 0 50 100 150 200 250 0 50 100 150 200 250
Figure9: SamplesfortheNASA-Chargedataset. They axiscorrespondstothedifferentfeatures,whilethexaxis
correspondstothedifferenttimesteps.
24TimeSeriesDiffusionintheFrequencyDomain
Trainingsamples Generatedsamples(Frequencydomainmodel) Generatedsamples(Timedomainmodel)
35 10 Feature0 20
30 Feature1
25 8 F Fe ea at tu ur re e2 3 15
20 F Fe ea at tu ur re e0 1 6 Feature4 F Fe ea at tu ur re e0 1
Feature2 10 Feature2
15 Feature3 4 Feature3
10 Feature4 2 5 Feature4
5
0
0 0
0 20 40 60 80 100 120
−2
0 20 40 60 80 100 120 0 20 40 60 80 100 120
8 Feature0 30 12 Feature0
Feature1 Feature1
Feature2 25 10 Feature2
6 Feature3 Feature3
Feature4 20 Feature0 8 Feature4
Feature1
4 15 Feature2 6
2 10 F Fe ea at tu ur re e3 4 4
2
5
0
0
0
−2
0 20 40 60 80 100 120 0 20 40 60 80 100 120 0 20 40 60 80 100 120
30
30
40 25
25
30 F Fe ea at tu ur re e0 1 20 F Fe ea at tu ur re e0 1 20 F Fe ea at tu ur re e0 1
Feature2 15 Feature2 15 Feature2
20 Feature3 Feature3 Feature3
Feature4 10 Feature4 10 Feature4
10 5 5
0 0 0
0 20 40 60 80 100 120 0 20 40 60 80 100 120 0 20 40 60 80 100 120
35 40
12 Feature0
30 Feature1
30 10 Feature2
25 Feature3
Feature0 Feature0 8 Feature4
12 50 F Fe ea at tu ur re e1 2 20 F Fe ea at tu ur re e1 2 6
Feature3 Feature3 4
10 Feature4 10 Feature4
2
5
0 0
0
0 20 40 60 80 100 120 0 20 40 60 80 100 120
−2
0 20 40 60 80 100 120
Feature0
50 15.0 15.0 Feature1
Feature2
40 12.5 12.5 Feature3
Feature0 10.0 Feature0 10.0 Feature4
30 Feature1 Feature1
Feature2 7.5 Feature2 7.5
20 Feature3 Feature3
Feature4 5.0 Feature4 5.0
10 2.5 2.5
0 0.0 0.0
0 20 40 60 80 100 120
−2.5
0 20 40 60 80 100 120
−2.5
0 20 40 60 80 100 120
Figure10: SamplesfortheNASA-Dischargedataset. Theyaxiscorrespondstothedifferentfeatures,whilethexaxis
correspondstothedifferenttimesteps.
25TimeSeriesDiffusionintheFrequencyDomain
Trainingsamples Generatedsamples(Frequencydomainmodel) Generatedsamples(Timedomainmodel)
50
Feature0 36 Feature0 Feature0
Feature1 Feature1 30 Feature1
45 Feature2 34 Feature2 Feature2
Feature3 32 Feature3 25 Feature3
Feature4 Feature4 Feature4
40 30 20
28 15
35
26
10
30 24
5
22
0 50 100 150 200 250 0 50 100 150 200 250 0 0 50 100 150 200 250
90
52.5 Feature0
110 Feature1
50.0 Feature2 80
47.5 Feature3
100 45.0 Feature4 70
42.5
90 60
Feature0 40.0 Feature0
Feature1 Feature1
80 Feature2 37.5 50 Feature2
Feature3 35.0 Feature3
Feature4 40 Feature4
32.5
0 50 100 150 200 250 0 50 100 150 200 250 0 50 100 150 200 250
130 Feature0 20.0 Feature0 50
Feature1 17.5 Feature1
125 Feature2 Feature2 45
120 F Fe ea at tu ur re e3 4 15.0 F Fe ea at tu ur re e3 4 40
115 12.5
35
110 10.0
105 7.5 30 F Fe ea at tu ur re e0 1
100 5.0 25 F Fe ea at tu ur re e2 3
95 2.5 20 Feature4
0 50 100 150 200 250 0 50 100 150 200 250 0 50 100 150 200 250
10
130 Feature0
Feature1 20
120 F Fe ea at tu ur re e2 3 19 5
Feature4 18 0
110 17
16
Feature0
−5
Feature0
100 15 Feature1 Feature1
14
F Fe ea at tu ur re e2
3
−10 F Fe ea at tu ur re e2
3
90 13 Feature4 −15 Feature4
0 50 100 150 200 250 0 50 100 150 200 250 0 50 100 150 200 250
40 −5.0 70
−7.5 65
38 60
−10.0
55
36 −12.5
50
34 F Fe ea at tu ur re e0 1 −15.0 F Fe ea at tu ur re e0 1 45 F Fe ea at tu ur re e0 1
Feature2 −17.5 Feature2 40 Feature2
32 F Fe ea at tu ur re e3
4
−20.0 F Fe ea at tu ur re e3
4
35 F Fe ea at tu ur re e3
4
0 50 100 150 200 250 −22.5 0 50 100 150 200 250 30 0 50 100 150 200 250
Figure11: SamplesfortheNASDAQ-2019dataset. Theyaxiscorrespondstothedifferentfeatures,whilethexaxis
correspondstothedifferenttimesteps.
26TimeSeriesDiffusionintheFrequencyDomain
Figure12: SamplesfortheUS-Droughtsdataset,representedasheatmaps. They axiscorrespondstothedifferent
features,whilethexaxiscorrespondstothedifferenttimesteps.
27