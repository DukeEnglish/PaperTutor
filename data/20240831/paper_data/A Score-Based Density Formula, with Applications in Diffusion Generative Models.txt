A Score-Based Density Formula, with Applications in
Diffusion Generative Models
Gen Li∗† Yuling Yan∗‡
August 30, 2024
Abstract
Score-based generative models (SGMs) have revolutionized the field of generative modeling, achiev-
ing unprecedented success in generating realistic and diverse content. Despite empirical advances, the
theoretical basis for why optimizing the evidence lower bound (ELBO) on the log-likelihood is effective
for training diffusion generative models, such as DDPMs, remains largely unexplored. In this paper, we
address this question by establishing a density formula for a continuous-time diffusion process, which
can be viewed as the continuous-time limit of the forward process in an SGM. This formula reveals the
connection between the target density and the score function associated with each step of the forward
process. Building on this, we demonstrate that the minimizer of the optimization objective for training
DDPMsnearlycoincideswiththatofthetrueobjective,providingatheoreticalfoundationforoptimizing
DDPMs using the ELBO. Furthermore, we offer new insights into the role of score-matching regular-
ization in training GANs, the use of ELBO in diffusion classifiers, and the recently proposed diffusion
loss.
Keywords: score-based density formula, score-based generative model, evidence lower bound, denoising
diffusion probabilistic model
Contents
1 Introduction 2
2 Problem set-up 3
2.1 Denoising diffusion probabilistic model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
2.2 A continuous-time SDE for the forwardprocess . . . . . . . . . . . . . . . . . . . . . . . . . 4
3 The score-based density formula 4
3.1 Main results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
3.2 From continuous time to discrete time . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
3.3 Comparison with other results. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
4 Implications 7
4.1 Certifying the validity of optimizing ELBO in DDPM . . . . . . . . . . . . . . . . . . . . . . 7
4.2 Understanding the role of regularization in GAN . . . . . . . . . . . . . . . . . . . . . . . . . 8
4.3 Confirming the use of ELBO in diffusion classifier. . . . . . . . . . . . . . . . . . . . . . . . . 9
4.4 Demystifying the diffusion loss in autoregressivemodels . . . . . . . . . . . . . . . . . . . . . 10
5 Proof of Theorem 1 10
6 Discussion 13
∗Theauthors contributed equally.
†Department ofStatistics,TheChineseUniversityofHongKong,HongKong;Email: genli@cuhk.edu.hk.
‡Department ofStatistics,UniversityofWisconsin-Madison,Madison,WI53706,USA;Email: yuling.yan@wisc.edu.
1
4202
guA
92
]GL.sc[
1v56761.8042:viXraA Proof of Proposition 1 14
B Proof of Proposition 2 16
C More discussions on the density formulas 19
D Technical details in Section 4 19
D.1 Technical details in Section 4.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
D.2 Technical details in Section 4.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
1 Introduction
Score-based generative models (SGMs) represent a groundbreaking advancement in the realm of generative
models, significantly impacting machine learning and artificial intelligence by their ability to synthesize
high-fidelity data instances, including images, audio, and text (Dhariwal and Nichol, 2021; Ho et al., 2020;
Sohl-Dickstein et al., 2015; Song et al., 2021a; Song and Ermon, 2019; Song et al., 2021b). These models
operate by progressivelyrefining noisy data into samples that resemble the targetdistribution. Due to their
innovativeapproach,SGMshaveachievedunprecedentedsuccess,settingnewstandardsingenerativeAIand
demonstrating extraordinary proficiency in generating realistic and diverse content across various domains,
from image synthesis and super-resolution to audio generation and molecular design (Croitoru et al., 2023;
Ramesh et al., 2022; Rombach et al., 2022; Saharia et al., 2022; Yang et al., 2023).
ThefoundationofSGMsisrootedintheprinciplesofstochasticprocesses,especiallystochasticdifferential
equations(SDEs). Thesemodelsutilizeaforwardprocess,whichinvolvesthegradualcorruptionofaninitial
data sample with Gaussian noise over severaltime steps. This forwardprocess can be described as:
addnoise addnoise addnoise
X X X , (1.1)
0 1 T
−→ −→ ··· −→
where X p is the original data sample, and X is a sample close to pure Gaussian noise. The
0 data T
∼
ingenuityofSGMsliesinconstructingareversedenoisingprocessthatiterativelyremovesthenoise,thereby
reconstructing the data distribution. This reverse process starts from a Gaussian sample Y and moves
T
backwardas:
denoise denoise denoise
Y Y Y (1.2)
T T 1 0
−→ − −→ ··· −→
d
ensuringthatY X ateachstept. ThefinaloutputY isanewsamplethatcloselymimicsthedistribution
t t 0
≈
of the initial data p .
data
Inspired by the classical results on time-reversal of SDEs (Anderson, 1982; Haussmann and Pardoux,
1986), SGMs construct the reverse process guided by score functions logp associated with each step of
∇
Xt
the forward process. Although these score functions are unknown, they are approximated by neural net-
works trained through score-matching techniques (Hyvärinen, 2005, 2007; Song and Ermon, 2019; Vincent,
2011). Thisleadstotwopopularmodels: denoisingdiffusionprobabilisticmodels(DDPMs)(Ho et al.,2020;
Nichol and Dhariwal,2021)anddenoisingdiffusionimplicitmodels(DDIMs)(Song et al.,2021a). Whilethe
theoretical results in this paper do not depend on the specific construction of the reverse process, we will
use the DDPM framework to discuss their implications for diffusion generative models.
However, despite empirical advances, there remains a lack of theoretical understanding for diffusion
generative models. For instance, the optimization target of DDPM is derived from a variational lower
bound on the log-likelihood(Ho et al., 2020), which is also referredto as the evidence lower bound (ELBO)
(Luo, 2022). It is not yet clear, from a theoretical standpoint, why optimizing a lower bound of the true
objective is still a valid approach. More surprisingly, recent research suggests incorporating the ELBO of
a pre-trained DDPM into other generative or learning frameworks to leverage the strengths of multiple
architectures, effectively using it as a proxy for the negative log-likelihood of the data distribution. This
approach has shown empirical success in areas such as GAN training, classification, and inverse problems
(Graikos et al., 2022; Li et al., 2023a; Mardani et al., 2024; Xia et al., 2023). While it is conceivable that
the ELBO is a reasonable optimization target for training DDPMs (as similar idea is utilized in e.g., the
2majorize-minimization algorithm), it is more mysterious why it serves as a good proxy for the negative
log-likelihood in these applications.
In this paper, we take a step towards addressing the aforementioned question. On the theoretical side,
we establish a density formula for a diffusion process (X ) defined by the following SDE:
t 0 t<1
≤
1 1
dX = X dt+ dB (0 t<1), X p ,
t t t 0 data
−2(1 t) √1 t ≤ ∼
− −
whichcanbeviewedasacontinuous-timelimitoftheforwardprocess(1.1). Undersomeregularityconditions,
this formula expresses the density of X with the score function along this process, having the form
0
1+log(2π) 1 1 X √1 tX 2 d
logp (x)= d E t − − 0 + logp (X ) X =x dt,
X0
− 2 −
Z0
(cid:20)2(1 −t)
h(cid:13)
t ∇
Xt t
(cid:13)2|
0
i− 2t
(cid:21)
where p () is the density of X . By time-discr(cid:13)etization, this reveals the connec(cid:13)tion between the target
Xt · t (cid:13) (cid:13)
density p andthe scorefunctionassociatedwitheachstepofthe forwardprocess(1.1). Thesetheoretical
data
results will be presented in Section 3.
Finally, using this density formula, we demonstrate that the minimizer of the optimization target for
trainingDDPMs(derivedfromtheELBO)alsonearlyminimizesthetruetarget—theKLdivergencebetween
the target distribution and the generator distribution. This finding provides a theoretical foundation for
optimizing DDPMs using the ELBO. Additionally, we use this formula to offer new insights into the role of
score-matching regularization in training GANs (Xia et al., 2023), the use of ELBO in diffusion classifiers
(Li et al., 2023a), and the recently proposed diffusion loss (Li et al., 2024). These implications will be
discussed in Section 4.
2 Problem set-up
Inthissection,weformallyintroducetheDenoisingDiffusionProbabilisticModel(DDPM)andthestochastic
differential equation (SDE) that describes the continuous-time limit of the forward process of DDPM.
2.1 Denoising diffusion probabilistic model
Consider the following forward Markov process in discrete time:
X = 1 β X + β W (t=1,...,T), X p , (2.1)
t t t 1 t t 0 data
− − ∼
where W ,...,W i.i.d. (0,Ip) and the learnping rates β (0,1). Since our main results do not depend on
1 T d t
∼ N ∈
the specific choice of β , we will specify them as needed in later discussions. For each t [T], let q be the
t t
law or density function of X , and let α :=1 β and α := t α . A simple calculati∈ on shows that:
t t − t t i=1 i
X
t
=√α tX 0+√1 α tW
t
wherQe W
t
(0,I d). (2.2)
− ∼N
We will choose the learning rates β to ensure that α is sufficiently small, such that q is close to the
t T T
standard Gaussian distribution.
Thekeycomponentsforconstructingthe reverseprocessinthe contextofDDPM arethe scorefunctions
s⋆ :Rd Rd associated with each q , defined as the gradient of their log density:
t → t
s⋆(x):= logq (x) (t=1,...,T).
t ∇ t
While these scorefunctions arenotexplicitly known,inpractice,noise-predictionnetworksε (x) aretrained
t
to predict
ε⋆(x):= √1 α s⋆(x),
t − − t t
which are often referred to as epsilon predictors. To construct the reverse process, we use:
1
Y = Y +η s (Y )+σ Z (t=T,...,1), Y (0,I ) (2.3)
t 1 t t t t t t T d
− √α t ∼N
(cid:0) (cid:1)
where Z ,...,Z i.i.d. (0,I ), and s ():= ε ()/√1 α is the estimate of the score function s⋆(). Here
1 T ∼ N d t · − t · − t t ·
η ,σ >0arethecoefficientsthatinfluencetheperformanceoftheDDPM sampler,andwewillspecifythem
t t
as needed in later discussion. For each t [T], we use p to denote the law or density of Y .
t t
∈
32.2 A continuous-time SDE for the forward process
In this paper, we build our theoretical results on the continuous-time limit of the aforementioned forward
process, described by the diffusion process:
1 1
dX = X dt+ dB (0 t<1), X p , (2.4)
t t t 0 data
−2(1 t) √1 t ≤ ∼
− −
where (B ) is a standard Brownian motion. The solution to this stochastic differential equation (SDE)
t t 0
≥
has the closed-form expression:
1 t t 1
X =√1 tX +√tZ where Z = − dB (0,I ). (2.5)
t 0 t t s d
− t 1 s ∼N
r Z0 −
It is importantto note that the processX is notdefined att=1, althoughit is straightforwardto see from
t
the above equation that X convergesto a Gaussian variable as t 1.
t
→
Todemonstratetheconnectionbetweenthisdiffusionprocessandtheforwardprocess(2.1)ofthediffusion
model, we evaluate the diffusion process at times t =√1 α for 1 i T. It is straightforwardto check
i i
− ≤ ≤
that the marginal distribution of the resulting discrete-time process X :1 i T is identical to that of
{
ti
≤ ≤ }
the forward process (2.1). Therefore the diffusion process (2.4) can be viewed as a continuous-time limit of
the forward process. In the next section, we will establish theoretical results for the diffusion process (2.4).
Through time discretization, our theory will provide insights for the DDPM.
WeusethenotationX forboththediscrete-timeprocess X :t [T] in(2.1)andthecontinuous-time
t t
{ ∈ }
diffusionprocess(X ) in(2.4)tomaintainconsistencywithstandardliterature. Thecontextwillclarify
t 0 t<1
≤
which process is being referred to.
3 The score-based density formula
3.1 Main results
Our main results are based on the continuous-time diffusion process (X ) defined in (2.4). While X
t 0 t<1 0
≤
might not have a density, for any t (0,1), the random variable X has a smooth density, denoted by ρ ().
t t
∈ ·
Our main result characterizesthe evolutionof the conditionalmean of logρ (X ) givenX , as statedbelow.
t t 0
Theorem 1. Consider the diffusion process (X ) defined in (2.4), and let ρ be the density of X . For
t 0 t<1 t t
≤
any 0<t <t <1, we have
1 2
t2 1 X √1 tX 2 d
E[logρ (X ) logρ (X ) X ]= E t − − 0 + logρ (X ) X dt.
t2 t2
−
t1 t1
|
0
Zt1
(cid:18)2(1 −t)
h(cid:13)
t ∇
t t
(cid:13)2|
0
i− 2t
(cid:19)
(cid:13) (cid:13)
The proof of this theorem is deferred to Appendix 5(cid:13). A few remarks are as follows(cid:13). First, it is worth
mentioning that this formula does not describe the evolution of the (conditional) differential entropy of the
process, because ρ () represents the unconditional density of X , while the expectation is taken conditional
t t
·
on X . Second, without further assumptions, we cannot set t = 0 or t = 1 because X might not have a
0 1 2 0
density (hence ρ is not well-defined), and X is only defined for t < 1. By assuming that X has a finite
0 t 0
second moment, the following proposition characterizes the limit of E[logρ (X ) X ] as t 1.
t t 0
| →
Proposition 1. Suppose that E[ X 2]< . Then for any x Rd, we have
k 0 k2 ∞ 0 ∈
1+log(2π)
lim E[logρ (X ) X =x ]= d.
t t 0 0
t 1 | − 2
→ −
The proof of this proposition is deferred to Appendix A. This result is not surprising, as it can be seen
from (2.5) that X converges to a standard Gaussian variable as t 1 regardless of x , and we can check
t 0
→
1+log(2π)
E[logφ(Z)]= d
− 2
4where Z (0,I ) and φ() is its density (we will use this notation throughout his section). The proof of
d
∼ N ·
Proposition 1 formalizes this intuitive analysis.
When X has a smooth density ρ () with Lipschitz continuous score function, we can show that
0 0
E[logρ (X ) X ] ρ (x ) as t 0, as pr· esented in the next proposition.
t t 0 0 0
| → →
Proposition 2. Suppose that X has density ρ () and sup 2logρ (x) < . Then for any x Rd,
0 0 · xk∇ 0 k ∞ 0 ∈
we have
lim E[logρ (X ) X =x ]=logρ (x ).
t t 0 0 0 0
t 0+ |
→
The proof of this proposition can be found in Appendix B. With Propositions 1 and 2 in place, we can
take t 0 and t 1 in Theorem 1 to show that for any given point x ,
1 2 0
→ →
1+log(2π) 1
logρ (x )= d D(t,x )dt (3.1a)
0 0 0
− 2 −
Z0
where the function D(x,t) is defined as
1 X √1 tX 2 d
D(t,x):= E t − − 0 + logρ (X ) X =x . (3.1b)
t t 0
2(1 t) t ∇ 2| − 2t
− h(cid:13) (cid:13) i
(cid:13) (cid:13)
In practice, we might not want to make(cid:13)smoothness assumptions on X(cid:13) as in Proposition 2. In that case,
0
we can fix some sufficiently small δ >0 and obtain a density formula
1+log(2π) 1
E[logρ (X ) X =x ]= d D(t,x )dt (3.1c)
δ δ 0 0 0
| − 2 −
Zδ
for a smoothed approximation of logρ (x ). This kind of proximity is often used to circumvent non-
0 0
smoothness target distributions in diffusion model literature (e.g., Benton et al. (2023); Chen et al. (2023b,
2022); Li et al. (2023b)). We leave some more discussions to Appendix C.
3.2 From continuous time to discrete time
In this section, to avoid ambiguity, we will use (Xsde) to denote the continuous-time diffusion process
t 0 t<1
≤
(2.4) studied in the previous section, while keep using X :1 t T to denote the forwardprocess (2.1).
t
{ ≤ ≤ }
Thedensityformula(3.1)isnotreadilyimplementablebecauseofitscontinuous-timenature. Considertime
discretization over the grid
0<t <t < <t <t =1 where t :=1 α (1 i T).
1 2 T T+1 i i
··· − ≤ ≤
Recallthatthe forwardprocessX ,...,X hasthe samemarginaldistributionasXsde,...,Xsde snapshoted
1 T t1 tT
from the diffusion process (2.4). This gives the following approximation of the density formula (3.1a):
logρ (x
)(i)E
logρ (Xsde) Xsde =x
0 0 ≈ t1 t1 | 0 0
(ii) (cid:2)1+log(2πt 1) d T t i+(cid:3) 1 −t iE X ts ide −√1 −t iX 0sde + logρ (Xsde) 2 Xsde =x
≈ − 2 − 2(1 t i) t
i
∇ ti t 2| 0 0
Xi=1 − h(cid:13) (cid:13) i
(cid:13) (cid:13)
(iii) 1+log(2πt 1) d T t i+1 −t i E(cid:13) ε ε (√1 t x +√t ε) (cid:13) 2 .
≈ − 2 − 2t i(1 t i) ε ∼N(0,Id) − i − i 0 i 2
Xi=1 − h(cid:13) (cid:13) i
(cid:13) b (cid:13)
In step (i) we approximate logρ (x ) with a smoothed proxy; see the discussion around (3.1c) for details;
0 0
1
step (ii) applies (3.1c), where we compute the integral d/(2t)dt = (d/2)logt in closed form and
t1 − 1
approximate the integral
R
1 1 Xsde √1 tXsde 2
E t − − 0 + logρ (Xsde) Xsde =x dt;
Zt1
2(1 −t)
h(cid:13)
t ∇ t t (cid:13)2| 0 0
i
(cid:13) (cid:13)
(cid:13) (cid:13)
5step (iii) follows from Xsde =d √1 t x +√t ε for ε (0,I ) conditional on Xsde =x , and the relation
ti − i 0 i ∼N d 0 0
logρ = logq =s⋆(x)= √t ε⋆(x) √t ε (x).
∇ ti ∇ i i − i i ≈− i i
In practice, we need to choose the learning rates β :1 t T such that the grid becomes finer as T
{ t ≤ ≤ } b
becomes large. More specifically, we require
t t =α α =α β β (1 i T 1)
i+1 i i i+1 i i+1 i+1
− − ≤ ≤ ≤ −
to be small (roughly of order O(1/T)), and t = β and 1 t =α to be vanishingly small (of order T c
1 1 T T −
−
for some sufficiently large constant c > 0); see e.g., Benton et al. (2023); Li et al. (2023b) for learning rate
schedules satisfying these properties. Finally, we replace the time steps t : 1 i T with the learning
i
{ ≤ ≤ }
rates for the forwardprocess to achieve1
T
logρ (x ) 1+log(2πβ 1) d 1 −α t+1 E ε ε (√α x +√1 α ε) 2 , (3.2)
0 0 ≈− 2 − 2(1 α t) ε ∼N(0,Id) − t t 0 − t 2
Xt=1 − h(cid:13) (cid:13) i
(cid:13) b (cid:13)
The density approximation (3.2) can be evaluated with the trained epsilon predictors.
3.3 Comparison with other results
The density formulas (3.1) expresses the density of X using the score function along the continuous-time
0
limit of the forward process of the diffusion model. Other forms of score-based density formulas can be
derived using normalizing flows. Notice that the probability flow ODE of the SDE (2.4) is
x logρ (x)
t
x˙ =v (x ) where v (x)= −∇ ; (3.3)
t t t t
− 2(1 t)
−
namely, if we draw a particle x ρ and evolve it according to the ODE (3.3) to get the trajectory t x
0 0 t
∼ →
for t [0,1), then x ρ . See e.g., Song et al. (2021b, Appendix D.1) for the derivation of this result.
t t
∈ ∼
Undersomesmoothnesscondition,wecanusetheresultsdevelopedinAlbergo et al.(2023);Grathwohl et al.
(2019) to show that for any given x
0
t ∂ t d tr 2logρ (x )
s s
logρ (x ) logρ (x )= Tr v (x ) ds= − ∇ ds. (3.4)
t t 0 0 s s
− − ∂x 2(1 s)
Z0 (cid:18) (cid:19) Z0 (cid:0) − (cid:1)
Here t x is the solutionto the ODE (3.3) with initial condition x . Since the ODE system (3.3) is based
t 0
→
onthescorefunctions(hencex canbenumericallysolved),andtheintegralin(3.4)isbasedontheJacobian
t
of the score functions, we may take t 1 and use the fact that ρ () φ() to obtain a score-baseddensity
t
→ · → ·
formula
d 1 1 d tr 2logρ (x )
logρ (x )= log(2π) x 2 − ∇ s s ds. (3.5)
0 0 −2 − 2k 1 k2− 2(1 s)
Z0 (cid:0) − (cid:1)
However, numerically, this formula is more difficult to compute than our formula (3.1) for the following
reasons. First, (3.5) involves the Jacobian of the score functions, which are more challenging to estimate
than the score functions themselves. In fact, existing convergence guarantees for DDPM do not depend on
the accurateestimationofthe Jacobianofthe scorefunctions (Benton et al.,2023;Chen et al.,2023a,2022;
Li and Yan, 2024). Second, using this density formula requires solving the ODE (3.3) accurately to obtain
x , whichmight notbe numerically stable, especially whenthe scorefunction is not accuratelyestimatedat
1
earlystages,due to errorpropagation. In contrast,computing (3.1) only requiresevaluating a few Gaussian
integrals (which can be efficiently approximated by the Monte Carlo method) and is more stable to score
estimation error.
1Herewedefineα T+1=0toaccommodate thelastterm inthesummation.
64 Implications
In the previous section, we established a density formula
T
logq (x) 1+log(2πβ 1) d 1 −α t+1 E ε ε⋆(√α x+√1 α ε) 2 (4.1)
0 ≈− 2 − 2(1 α t) ε ∼N(0,Id) − t t − t 2
=:C 0⋆ Xt=1 − h(cid:13) (cid:13)=:L⋆ t−1(x) (cid:13) (cid:13) i
| {z } | {z }
up to discretization error (which vanishes as T becomes large) and score estimation error. In this section,
we will discuss the implications of this formula in various generative and learning frameworks.
4.1 Certifying the validity of optimizing ELBO in DDPM
Theseminalwork(Ho et al.,2020)establishedthevariationallowerbound(VLB),alsoknownastheevidence
lower bound (ELBO), of the log-likelihood
T
logp (x) E KL p ( x ,x) p ( x )
0
≥−
xt ∼pXt|X0( ·|x) Xt−1|Xt,X0
·|
t
k
Yt−1|Yt
·|
t
t=2
X (cid:0) =:Lt−1(x) (cid:1)
−K |L p YT( ·) kp XT |X0( ·|x) +E {zx1∼pX1|X0( ·|x) logp Y0|Y1(x} |x 1) , (4.2)
(cid:0) =:LT(x) (cid:1) =:C(cid:2) 0(x) (cid:3)
where the reverse process (Y ) | was de{ fiz ned in Sect} ion|2.1, and p is t{hze density of Y .}Under the coef-
t 0 t T 0 0
≤ ≤
ficientdesignrecommendedby Li and Yan(2024) (other reasonabledesignsalsoleadto similarconclusions)
(1 α )(α α )
η =1 α and σ2 = − t t − t , (4.3)
t − t t 1 α
t
−
it can be computed that for each 2 t T:
≤ ≤
L (x)= 1 −α t E ε ε (√α x+√1 α ε) 2 .
t −1 2(α
t
α t) ε ∼N(0,Id) − t t − t 2
− h(cid:13) (cid:13) i
Wecanverifythat(i)foreach2 t T,thecoefficients(cid:13)inL from(4.2)andL⋆(cid:13) from(4.1)areidentical
up to higher-order error; (ii)
whe≤
n
T≤
is large, L becomes
vat n− i1
shingly small;
andt −(i1
ii) the function
T
1+log(2πβ )
C (x)= 1 d+O(β )=C⋆+O(β )
0 − 2 1 0 1
is nearly a constant. See Appendix D.1 for details. It is worth highlighting that as far as we know, existing
literature haven’t pointed out that C (x) is nearly a constant. For instance, Ho et al. (2020) discretize
0
this term to obtain discrete log-likelihood (see Section 3.3 therein), which is unnecessary in view of our
observation. Additionally, some later works falsely claim that C (x) is negligible, as we will discuss in the
0
following sections.
Now we discuss the validity of optimizing the variational bound for training DDPMs. Our discussion
shows that
KL(q p )= E [logp (x)] H(q ) E [L(x)] C⋆ H(q )+o(1), (4.4)
0 k 0 − x ∼q0 0 − 0 ≤ x ∼q0 − 0 − 0
=: L(ε1,...,εT) =: Lvb(ε1,...,εT)
where H(q )=| l{ oz gq (} x)dq is the entropy of q , and L| (x) denotes the{ wz idely used (neg} ative) ELBO2
0 0 0 0
−
R T
L(x):= 1 −α t+1 E ε ε (√α x+√1 α ε) 2 .
2(1 α t) ε ∼N(0,Id) − t t − t 2
Xt=1 − h(cid:13) (cid:13) i
(cid:13) (cid:13)
2Wefollowtheconvention inexistingliterature toremovethelasttwoterms L T(x)andC 0(x)from(4.2)intheELBO.
7The true objective of DDPM is to learnthe epsilon predictors ε ,...,ε that minimizes in (4.4), while in
1 T
L
practice, the optimization target is the variational bound . It is known that the global minimizer for
vb
L
T
E [L(x)]= 1 −α t+1E ε ε (√α x+√1 α ε) 2 (4.5)
x ∼q0 2(1 α t) x ∼q0,ε ∼N(0,Id) − t t − t 2
Xt=1 − h(cid:13) (cid:13) i
(cid:13) (cid:13)
is exactly ε () ε⋆() for each 1 t T (see Appendix D.1). Although in practice the optimization is
t · ≡ t · ≤ ≤
based on samples from the target distribution q (instead of the population level expectation over q ) and
0 0
may not find the exact globalminimizer, we consider the ideal scenario where the learnedepsilonpredictors
b
ε equal ε⋆ to facilitate discussion. When ε =ε⋆ for each t, according to (4.1), we have
t t t t
L(x) logq (x)+C⋆. (4.6)
b ≈− 0 0
Taking (4.4) and (4.6) together gives
0 (ε ,...,ε ) (ε ,...,ε ) E [logq(x)]+C⋆ C⋆ H(q )=0, (4.7)
≤L 1 T ≤Lvb 1 T ≈− x ∼q0 0 − 0 − 0
namelytheminimizerfor approximatelyminimizes ,andtheoptimalvalueisasymptoticallyzerowhen
b Lvbb b b L
the number of steps T becomes large. This suggests that by minimizing the variational bound , the
vb
L
resulting generator distribution p is guaranteed to be close to the target distribution q in KL divergence.
0 0
Someexperimentalevidencesuggeststhatusingreweightedcoefficientscanmarginallyimproveempirical
performance. For example, Ho et al. (2020) suggests that in practice, it might be better to use uniform
coefficients in the ELBO
T
L (x):= 1 E ε ε (√α x+√1 α ε) 2 (4.8)
simple T ε ∼N(0,Id) − ti t − t 2
Xi=1 h(cid:13) (cid:13) i
(cid:13) b (cid:13)
when trainging DDPM to improve sampling quality.3 This strategy has been adopted by many later works.
In the following sections, we will discuss the role of using the ELBO in different applications. While the
original literature might use the modified ELBO (4.8), in our discussion we will stick to the original ELBO
(4.6) to gain intuition from our theoretical findings.
4.2 Understanding the role of regularization in GAN
Generative Adversarial Networks (GANs) are a powerful and flexible framework for learning the unknown
probabilitydistributionp thatgeneratesacollectionoftrainingdata(Goodfellow et al.,2014). GANsop-
data
erateonagamebetweenageneratorGandadiscriminatorD,typicallyimplementedusingneuralnetworks.
The generator G takes a random noise vector z sampled from a simple distribution p (e.g., Gaussian)
noise
andmapsitto adatasampleresemblingthe trainingdata,aimingforthe distributionofG(z)tobe closeto
p . Meanwhile, the discriminator D determines whether a sample x is real (i.e., drawnfrom p ) or fake
data data
(i.e., produced by the generator), outputting the probability D(x) of the former. The two networks engage
in a zero-sum game:
minmaxV(G,D):=E [logD(x)]+E [log(1 D(G(z)))],
G D
x ∼pdata z ∼pnoise
−
with the generator striving to produce realistic data while the discriminator tries to distinguish real data
from fake. The generator and discriminator are trained iteratively4
D argmin E [logD(x)] E [log(1 D(G(z)))],
← −
x ∼pdata
−
z ∼pnoise
−
3Note that the optimal epsilon predictors εb t for L and L simple are the same, but in practice, we may not find the optimal
predictors. This practical strategy is beyond the scope of our theoretical result, and implies that the influence of terms from
differentstepsneedsmorecarefulinvestigation. Weconjecturethatthisismainlybecausetheestimationerrorfortermswhen
tisclosetozeroislarger, hencesmallercoefficients forthesetermscanimproveperformance.
4Whilethemostnaturalupdateruleforthegenerator isG←argminE z∼pnoise[log(1−D(G(z)))],bothschemesareusedin
practice andhave similarperformance. Ourchoice isforconsistency withXiaetal. (2023), and ouranalysis canbe extended
totheotherchoice.
8G argmin E [logD(G(z))]
← −
z ∼pnoise
to approach the Nash equilibrium (G⋆,D⋆), where the distribution of G⋆(z) with z p matches the
noise
∼
target distribution p , and D(x)=1/2 for all x.
data
It is believed that adding a regularizationterm to make the generated samples fit the VLB can improve
the sampling quality of the generative model. For example, Xia et al. (2023) proposed adding the VLB
L(x) as a regularization term to the objective function, where ε () : 1 i T are the learned epsilon
{
ti
· ≤ ≤ }
predictors for p . The training procedure then becomes
data
b
D argmin E [logD(x)] E [log(1 D(G(z)))],
← −
x ∼pdata
−
z ∼pnoise
−
G argmin E [logD(G(z))]+λE [L(G(z))],
← −
z ∼pnoise z ∼pnoise
where λ>0 is some tuning parameter. However, it remains unclear what exactly is optimized through the
above objective. According to our theory, L(x) logp (x)+C⋆. Assuming that this approximation is
≈ − data 0
exact for intuitive understanding, the unique Nash equilibrium (G ,D ) satisfies
λ λ
p (x)= zp (x)λ 1 p (x)
Gλ data − + data
(cid:0) (cid:1)
for some normalizing factor z >0, where p is the density of G (z) with z p . See Appendix D.2 for
Gλ λ
∼
noise
details. This can be viewed as amplifying the density p wherever it is not too small, while zeroing out
data
the density where p is vanishingly small (which is difficult to estimated accurately), thus improving the
data
sampling quality.
4.3 Confirming the use of ELBO in diffusion classifier
Motivated by applications like image classification and text-to-image diffusion model, we consider a joint
underlying distribution p (x,c), where typically x is the image data and the latent variable c is the class
0
index or text embedding, taking values in a finite set . For each c , we train a diffusion model for the
C ∈ C
conditionaldatadistributionp (x c), whichprovidesasetofepsilonpredictors ε (x;c):1 t T,c .
0 t
| ≤ ≤ ∈C
Assuming a uniform prior over , we can use Bayes’ formula to obtain:
C (cid:8) (cid:9)
b
p (c)p (x c ) p (x c)
0 0 i 0
p (c x)= | = | .
0
| p (c )p (x c ) p (x c )
j 0 j 0 | j j 0 | j
∈C ∈C
for each c . Recent work (Li et al., P 2023a) proposed to use thP e ELBO5
∈C
T
L(x;c):= 1 −α t+1 E ε ε (√α x+√1 α ε;c) 2
− − 2(1 α t) ε ∼N(0,Id) − t t − t 2
Xt=1 − h(cid:13) (cid:13) i
(cid:13) b (cid:13)
as an approximate class-conditionallog-likelihood logp (x c) for each c , which allows them to obtain a
0
| ∈C
posterior distribution
exp( L(x;c))
p (c x)= − . (4.9)
0
| exp( L(x;c ))
j ∈C − j
Ourtheorysuggeststhat −L(x;c) ≈lobgp 0(x |c) −PC 0⋆,whereC 0⋆ = −[1+log(2πβ 1)]d/2isauniversalconstant
that does not depend on p and c. This implies that
0
exp(logp (x c) C⋆) p (x c)
p (c x) 0 | − 0 = 0 | =p (c x)
0 | ≈ exp(logp (x c ) C⋆) p (x c ) 0 |
j 0 | j − 0 j 0 | j
∈C ∈C
providing theoreticbal justificatP ion for using the computed posteP rior p in classification tasks.
0
It is worth mentioning that, although this framework was proposedin the literature (Li et al., 2023a), it
remainsaheuristicmethodbeforeourwork. Forexample,ingeneral,replacingtheintractablelog-likelihood
b
with a lower bound does not guarantee good performance, as they might not be close. Additionally, recall
5Theoriginalpaperadopteduniformcoefficients; seethelastparagraph ofSection4.1fordiscussion.
9that there is a term C (x) in the ELBO (4.2). Li et al. (2023a) claimed that “Since T = 1000 is large and
0
logp (x x ,c) is typically small, we choose to drop this term”. Howeverthis argumentis notcorrect,aswe
θ 0 1
|
already computed in Section 4.1 that this term
1+log(2πβ )
1
C (x)= d+O(β )
0 1
− 2
can be very large since β is typically very close to 0. In view of our results, the reason why this term can
1
be dropped is that it equals a universal constant that does not depend on the image data x and the class
index c, thus it does not affect the posterior (4.9).
4.4 Demystifying the diffusion loss in autoregressive models
Finally, we use our results to study a class of diffusion loss recently introduced in Li et al. (2024), in the
context of autoregressive image generation. Let xk denote the next token to be predicted, and z be the
condition parameterized by an autoregressive network z = f(x1,...,xk 1) based on previous tokens as
−
input. The goal is to train the network z = f() together with a diffusion model ε ( ;z):1 t T such
t
· { · ≤ ≤ }
that p(x z) (induced by the diffusion model) with z =f(x1,...,xk 1) can predict the next token xk.
−
|
The diffusion loss is defined as follows: for some weights w 0, let
t
≥
b
T
L(z,x)= w E ε ε (√α x+√1 α ε;z) 2 . (4.10)
t ε ∼N(0,Id) − t t − t 2
Xt=1 h(cid:13) (cid:13) i
(cid:13) (cid:13)
With trainingdata (x1,...,xk):1 i n ,we cantrainthe autoregressivenetworkf() andthe diffusion
{ i i ≤ ≤ } ·
model by minimizing the following empirical risk:
n
1
argmin
n
L f(x1 i,...,x ik −1),xk
i
. (4.11)
f,ε1,...,εT
i=1
X (cid:0) (cid:1)
To gain intuition from our theoretical results, we take the weights in the diffusion loss (4.10) to be the
coefficients in the ELBO (4.6), and for each z, suppose that the learned diffusion model for p(xk z) is
|
already good enough, which returns the set of epsilon predictors ε ( ;z) : 1 t T for the probability
t
{ · ≤ ≤ }
distribution of xk conditioned on z. Under this special case, our approximation result (4.6) shows that
b
L(z,x) logp(x z)+C⋆,
≈− | 0
which suggests that the training objective for the network f in (4.11) can be viewed as approximate MLE,
as the loss function
n n
1 1
n
L f(x1 i,...,x ik −1),xk
i ≈−n
logp(xk
i
|f(x1 i,...,x ik −1))+C 0⋆
i=1 i=1
X (cid:0) (cid:1) X
represents the negative log-likelihood function (up to an additive constant) of the observed xk,...,xk in
1 n
terms of f.
5 Proof of Theorem 1
Recall the definition of the stochastic process (X )
t 0 t 1
≤ ≤
1 1
dX = X dt+ dB .
t t t
−2(1 t) √1 t
− −
Define Y :=X /√1 t for any 0 t<1, and let f(t,x)=x/√1 t, we can use Itô’s formula to show that
t t
− ≤ −
∂f 1
dY t =df(t,X t)=
∂t
(t,X t)dt+ ∇xf(t,X t)⊤dX t+ 2dX t⊤ ∇2 xf(t,X t)dX t
10X 1 1 1 dB
t t
= dt+ X dt+ dB = . (5.1)
2(1 t)3/2 √1 t −2(1 t) t √1 t t 1 t
− − (cid:18) − − (cid:19) −
Therefore the Itô process Y is a martingale,which is easier to handle. Let g(t,y)=logρ (√1 ty), and we
t t
−
can express logρ (x)=g(t,x/√1 t). In view of Itô’s formula, we have
t
−
dlogρ t(X t)=dg(t,Y t)( =i) ∂ ∂g
t
(t,Y t)dt+ ∇yg(t,Y t)⊤dY t+ 21 dY
t⊤
∇2 yg(t,Y t)dY
t
( =ii) ∂ ∂g
t
(t,Y t)dt+ 11 t∇yg(t,Y t)⊤dB t+ 2(11 t)2dB
t⊤
∇2 yg(t,Y t)dB
t
− −
( =iii) ∂ ∂g
t
(t,Y t)dt+ 11 t∇yg(t,Y t)⊤dB t+ 2(11 t)2tr ∇2 yg(t,Y t) dt. (5.2)
− −
(cid:0) (cid:1)
Here step (i) follows from the Itô rule, step (ii) utilizes (5.1), while step (iii) can be derived from the Itô
calculus. Then we investigate the three terms above. Notice that
ρ (√1 ty) ρ (X )√1 t
g(t,y) = ∇y t − = ∇x t t − =√1 t logρ (X ), (5.3)
∇y |y=Yt
ρ t(√1 tY t)
|y=Yt
ρ t(X t) − ∇
t t
−
and similarly, we have
2g(t,y) =(1 t) 2logρ (X ). (5.4)
∇y |y=Yt − ∇ t t
Substituting (5.3) and (5.4) back into (5.2) gives
∂g 1 1
dlogρ t(X t)= (t,Y t)dt+ logρ t(X t)⊤dB t+ tr 2logρ t(X t) dt.
∂t √1 t∇ 2(1 t) ∇
− −
(cid:0) (cid:1)
or equivalently, for any given 0<t <t <1, we have
1 2
t2 t2 ∂g tr 2logρ t(X t) t2 1
logρ t(X t) = (t,Y t)+ ∇ dt+ logρ t(X t)⊤dB t. (5.5)
(cid:12)t1 Zt1 h∂t (cid:0) 2(1 −t) (cid:1)
i
Zt1 √1 −t∇
(cid:12)
Conditional on X , w(cid:12)e take expectation on both sides of (5.5) to achieve
0
t2 ∂g 1
E[logρ (X ) logρ (X ) X ]=E (t,Y )+ tr 2logρ (X ) dt X . (5.6)
t2 t2
−
t1 t1
|
0
∂t
t
2(1 t) ∇
t t
|
0
(cid:20)Zt1 (cid:18) − (cid:19) (cid:21)
(cid:0) (cid:1)
We need the following lemmas, whose proof can be found at the end of this section.
Claim 1. For any 0<t<1 and any y Rd, we have
∈
∂g d 1
(t,y)= + ρ x √1 ty y x 2dx .
∂t −2t 2t2
Zx0
X0|Xt 0 | − k − 0 k2 0
(cid:0) (cid:1)
Claim 2. For any 0<t<1 and any x Rd, we have
∈
tr 2logρ (x) = d logρ (x) 2 + 1 x √1 tx 2 ρ (x x)dx .
∇ t −t − ∇ t 2 t2 − − 0 2 X0|Xt 0 | 0
Z
(cid:0) (cid:1) (cid:13) (cid:13) (cid:13) (cid:13)
It also admits the lower bound (cid:13) (cid:13) (cid:13) (cid:13)
d
tr 2logρ (x) .
t
∇ ≥−t
Therefore for any x and y =x/√1 t, w(cid:0)e know that(cid:1)
−
∂g 1 d d d
(t,y)+ tr 2logρ (x) . (5.7)
t
∂t 2(1 t) ∇ ≥−2t − 2(1 t)t ≥−(1 t)t
− − −
(cid:0) (cid:1)
Hence we have
E[logρ (X ) logρ (X ) X ]
t2 t2
−
t1 t1
|
0
11( =i)E t2 ∂g (t,Y )+ 1 tr 2logρ (X ) + d dt X t2 d dt
t t t 0
∂t 2(1 t) ∇ (1 t)t | − (1 t)t
(cid:20)Zt1 (cid:18) − − (cid:19) (cid:21) Zt1 −
( =ii) t2 E ∂g (t,Y )+ 1 tr(cid:0) 2logρ (X )(cid:1) + d X dt t2 d dt
t t t 0
∂t 2(1 t) ∇ (1 t)t | − (1 t)t
Zt1 (cid:20)(cid:18) − − (cid:19) (cid:21) Zt1 −
t2 ∂g 1 (cid:0) (cid:1)
= E (t,Y )+ tr 2logρ (X ) X dt. (5.8)
t t t 0
∂t 2(1 t) ∇ |
Zt1 (cid:20)(cid:18) − (cid:19) (cid:21)
(cid:0) (cid:1)
Here step (i) follows from (5.6), and its validity is guaranteed by
t2 d t (1 t )
2 1
dt=log − <+ ,
t(1 t) t (1 t ) ∞
Zt1 − 1 − 2
while step (ii) utilizes Tonelli’s Theorem,andthe nonnegativityofthe integrandis ensuredby (5.7). Taking
Claims 1 and 2 collectively, we know that for any x and y =x/√1 t,
−
∂g
(t,y)
tr ∇2logρ t(x)
=
d+ ∇logρ t(x) 2
2 +
1
ρ x √1 ty y x 2dx
∂t −
(cid:0)
2(1 −t)
(cid:1) (cid:13)
(cid:13)2(1 1−t)
1
(cid:13)
(cid:13)
x
2t √2
Z 1x0
tX x0|X 2t
ρ(cid:0)
0 | (x−
x)(cid:1)
dk
x
− 0 k2 0
− 2(1 t)t2 − − 0 2 X0|Xt 0 | 0
− Z
2(cid:13) (cid:13)
=
d+ ∇logρ t(x) 2(cid:13)
.
(cid:13)
(5.9)
2(1 t)
(cid:13) (cid:13)
(cid:13) − (cid:13)
Putting (5.8) and (5.9) together, we arrive at
E[logρ (X ) logρ (X ) X ]=
t2
E
d+ ∇logρ t(X t) 2
2 +
1
tr 2logρ (X ) X dt. (5.10)
t2 t2
−
t1 t1
|
0
2(1 t) 1 t ∇
t t
|
0
Zt1 (cid:20) (cid:13) (cid:13) − (cid:13) (cid:13) − (cid:0) (cid:1) (cid:21)
Notice that conditional on X , we have X (√1 tX ,tI ). Then we have
0 t 0 d
∼N −
E[logρ (X ) logρ (X ) X ]
t2 t2
−
t1 t1
|
0
( =i) t2 E d+ ∇logρ t(X t) 2 2 + 1 logρ t(X t) ⊤X t −√1 −tX 0 X
0
dt
2(1 t) 1 t∇ t |
Zt1 (cid:20) (cid:13) (cid:13) − (cid:13) (cid:13) − (cid:21)
( =ii) t2 1 E X t −√1 −tX 0 + logρ (X ) 2 X d dt
t t 0
Zt1
(cid:18)2(1 −t)
h(cid:13)
t ∇ (cid:13)2| i− 2t
(cid:19)
(cid:13) (cid:13)
Here step (i) follows from (5.10) and an(cid:13)application of Stein’s lemma (cid:13)
E logρ (X ) X √1 tX X =tE tr 2logρ (X ) X ,
t t ⊤ t 0 0 t t 0
∇ − − | ∇ |
(cid:20) (cid:21)
(cid:0) (cid:1) (cid:2) (cid:0) (cid:1) (cid:3)
while step (ii) holds since
X √1 tX 2 d
E t − − 0 = .
t 2 t
h(cid:13) (cid:13) i
(cid:13) (cid:13)
Proof of Claim 1. For any t (0,1), si(cid:13) nce X =√1 tX(cid:13) +√tZ, we have
t 0
∈ −
(1 t) y x 2
ρ t(√1 ty)= (2πt) −d/2exp − k − 0 k2 ρ 0(dx 0). (5.11)
− − 2t
Zx0
(cid:16) (cid:17)
Note that here ρ () stands for the law of X . Hence we have
0 0
·
∂g ∂ 1 ∂
(t,y)= logρ (√1 ty)= ρ (√1 ty)
t t
∂t ∂t − ρ (√1 ty)∂t −
t
−
121 d (1 t) y x 2
= (2π)−d/2 t−d/2 −1exp − k − 0 k2
ρ (√1 ty) − 2 − 2t
t − Zx0 (cid:20) (cid:16) (cid:17)
(1 t) y x 2 y x 2
+t−d/2exp
−
− k 2t− 0 k2 k − 2t20 k2 ρ 0(dx 0)
(cid:16) (cid:17) (cid:21)
1 d y x 2
= ρ √1 ty x + k − 0 k2 ρ (dx )
ρ t(√1 −ty)
Zx0
Xt |X0 − | 0 (cid:20)−2t 2t2
(cid:21)
0 0
d y x
2(cid:0) (cid:1)
= + k − 0 k2 ρ dx √1 ty
Zx0(cid:16)− 2t 2t2
(cid:17)
X0|Xt
(cid:0)
0 | −
(cid:1)
as claimed.
Proof of Claim 2. Notice that we can express
1 1
logρ (x)= E X √1 tX X =x = x √1 tx ρ (dx x);
∇ t −t t − − 0 | t −t
Zx0
− − 0 X0|Xt 0 |
(cid:2) (cid:3) (cid:0) (cid:1)
see Chen et al. (2022) for the proof of this relationship. Then we can compute
1 1
2logρ (x)= I + E X √1 tX X =x E X √1 tX X =x ⊤
t d t 0 t t 0 t
∇ −t t − − | − − |
n 1 E (cid:2) X √1 tX X √(cid:3) 1(cid:2) tX ⊤ X =x (cid:3)
t 0 t 0 t
− t − − − − |
1 1 h(cid:0) (cid:1)(cid:0) (cid:1) io
= I + x √1 tx ρ (dx x) x √1 tx ρ (dx x) ⊤
−t d t − − 0 X0|Xt 0 | − − 0 X0|Xt 0 |
n 1 hZ (cid:0) (cid:1) ihZ (cid:0) (cid:1) i
x √1 tx x √1 tx ⊤ρ (dx x) .
− t − − 0 − − 0 X0|Xt 0 |
Z (cid:0) (cid:1)(cid:0) (cid:1) o
Hence we have
tr 2logρ (x) = 1 d+ 1 x √1 tx ρ (dx x) 2 1 x √1 tx 2 ρ (dx x)
∇ t −t t − − 0 X0|Xt 0 | 2− t − − 0 2 X0|Xt 0 |
(cid:26) Z Z (cid:27)
(cid:0) (cid:1) = d 1 (cid:13) (cid:13)log(cid:0) ρ (x) 2 + 1 (cid:1) x √1 tx (cid:13) (cid:13)2 ρ (x(cid:13) (cid:13) x)dx . (cid:13) (cid:13)
−t − t2 ∇ t 2 t2 − − 0 2 X0|Xt 0 | 0
Z
(cid:13) (cid:13) (cid:13) (cid:13)
By Jensen’s inequality, we k(cid:13)now that (cid:13) (cid:13) (cid:13)
d
tr 2logρ (x) .
t
∇ ≥−t
(cid:0) (cid:1)
6 Discussion
Thispaperdevelopsascore-baseddensityformulathatexpressesthedensityfunctionofatargetdistribution
usingthescorefunctionalongacontinuous-timediffusionprocessthatbridgesthisdistributionandstandard
Gaussian. Byconnectingthis diffusionprocesswiththe forwardprocessofscore-baseddiffusionmodels,our
results provide theoretical support for training DDPMs by optimizing the ELBO, and offer novel insights
into several applications of diffusion models, including GAN training and diffusion classifiers.
Our work opens several directions for future research. First, our theoretical results are established for
the continuous-time diffusion process. It is crucialto carefully analyze the error induced by time discretiza-
tion, which could inform the number of steps required for the results in this paper to be valid in practice.
Additionally, while our results provide theoretical justification for using the ELBO (4.6) as a proxy for the
negative log-likelihood of the target distribution, they do not cover other practical variants of ELBO with
modifiedweights(e.g.,thesimplifiedELBO(4.8)). Extendingouranalysistootherdiffusionprocessesmight
yield new density formulas incorporatingthese modified weights. Lastly,further investigationis neededinto
other applications of this score-baseddensity formula, including density estimation and inverse problems.
13Acknowledgements
G. Li is supported in part by the Chinese University of Hong Kong Direct Grant for Research. Y. Yan was
supported in part by a Norbert Wiener Postdoctoral Fellowship from MIT.
A Proof of Proposition 1
We establish the desired result by sandwiching E[logρ (X ) X =x ] and find its limit as t 1 . We first
t t 0 0
| →
record that the density of X can be expressed as
t
x √1 tX 2
ρ t(x)=E
X0
(2πt) −d/2exp
−
k − 2t− 0 k2 , (A.1)
(cid:20) (cid:18) (cid:19)(cid:21)
since X =d √1 tX +√tZ for an independent variable Z (0,I ).
t 0 d
− ∼N
Lower bounding E[logρ (X ) X =x ]. Starting from (A.1), for any x Rd and any 0<t<1,
t t 0 0
| ∈
x √1 tX 2
logρ t(x)=logE
X0
(2πt) −d/2exp
−
k − 2t− 0 k2
(cid:20) (cid:18) (cid:19)(cid:21)
(i) x √1 tX 2
≥
log (2πt) −d/2exp −E
X0
k − 2t− 0 k2
(cid:26) (cid:18) (cid:20) (cid:21)(cid:19)(cid:27)
d x √1 tX 2
= log(2πt) E k − − 0 k2
−2 −
X0
2t
(cid:20) (cid:21)
d x 2 1 t √1 t
= −2log(2πt)
−
k 2k t2
−
2−
t
E[ kX
0
k2 2]+ t− E[x ⊤X 0]
( =ii) d log(2πt) 1+O(√1 t) kx k2 2 +O(√1 t)E[ X 2].
−2 − − 2t − k 0 k2
(cid:0) (cid:1)
Here step (i) follows from Jensen’s inequality and the fact that e x is a convex function, while step (ii)
−
follows from elementary inequalities
1
E[x X ] E x X E x 2+ X 2 .
⊤ 0 ≤ k kk 0 k2 ≤ 2 k k2 k 0 k2
(cid:12) (cid:12) (cid:2) (cid:3) (cid:2) (cid:3)
This immediately gives, for an(cid:12)y given x(cid:12) Rd and any 0<t<1,
0
∈
d 1+O(√1 t)
E[logρ (X ) X =x ] log(2πt) − E X 2 X =x +O(√1 t)E[ X 2]. (A.2a)
t t | 0 0 ≥−2 − 2t k t k2| 0 0 − k 0 k2
(cid:2) (cid:3)
=:fx0(t)
Since E[ X 2]< , it is st| raightforwardto check that {z }
k 0 k2 ∞
d 1
lim f (t)= log(2π) lim E √1 tx +√tZ 2 for Z (0,I )
t 1 x0 −2 −t 1 2 k − 0 k2 ∼N d
→ − → − h i
d d
= log(2π) . (A.2b)
−2 − 2
Upper bounding E[logρ (X ) X = x ]. Towards that, we need to obtain point-wise upper bound for
t t 0 0
|
logρ (x). Since the desired result only depends on the limiting behavior when t 1, from now on we only
t
→
consider t>0.9, under which
1 1
(1 t)1/4 < log
− 2 1 t
r −
holds. It would be helpful to develop the upper bound for the following two cases separately.
14• For any (1 t)1/4 < x <0.5 log1/(1 t), we have
2
− k k −
(a) p ( x (1 t)1/4)2
logρ t(x)
≤
logE
X0
(2πt)−d/2exp
−
k k2 − 2t− +1 kX
0 k2
>(1 −t)−1/4
(cid:20) (cid:18) (cid:19) (cid:21)
(b) d ( x (1 t)1/4)2 ( x (1(cid:0) t)1/4)2 (cid:1)
log(2πt) k k2 − − +exp k k2 − − P X
0 2
>(1 t)−1/4
≤ −2 − 2t 2t k k −
(c) d ( x (1 t)1/4)2 (cid:16) x 2 (cid:17) (cid:0) (cid:1)
log(2πt) k k2 − − +exp k k2 E[ X 2](1 t)1/2
≤ −2 − 2t 2t k 0 k2 −
(d) d ( x (1 t)1/4)2 (cid:16) (cid:17)
log(2πt) k k2 − − +E[ X 2](1 t)1/4. (A.3)
≤ −2 − 2t k 0 k2 −
Here step (a) follows from (A.1); step (b) holds since log(x+y) logx+y/x holds for any x > 0 and
≤
y 0; step (c) follows from x > (1 t)1/4 and Chebyshev’s inequality; while step (d) holds since
2
≥ k k −
x <0.5 log1/(1 t).
2
k k −
• For x p0.5 log1/(1 t) or x (1 t)1/4, we will use the naive upper bound
2
k k ≥ − k k≤ −
p d
logρ (x) log(2πt)<0, (A.4)
t
≤−2
where the first relation simply follows from (A.1) and the second relation holds when t>0.9.
Then we have
(i)
E[logρ (X ) X =x ] E[logρ (X )1 (1 t)1/4 < X <0.5 log1/(1 t) X =x ]
t t 0 0 t t t 2 0 0
| ≤ − k k − |
(ii) d ( x (1 n t)1/4)2 p o
E log(2πt) k k2 − − +E[ X 2](1 t)1/4
≤ − 2 − 2t k 0 k2 −
(cid:20)(cid:16) (cid:17)
1 (1 t)1/4 < X <0.5 log1/(1 t) X =x
t 2 0 0
· − k k − |
(cid:21)
d n p o
= log(2πt)+E[ X 2](1 t)1/4 P (1 t)1/4 < X <0.5 log1/(1 t)
− 2 k 0 k2 − − k t k2 −
(cid:16) (cid:17) (cid:16) p (cid:17)
=:gx0(t)
| E ( kX t k2 −(1 −t)1/4)2 1 (1 t){ 1/z 4 < X <0.5 log1/(1 t) X =} x .
t 2 0 0
− 2t − k k − |
(cid:20) n p o (cid:21)
=:egx0(t)
| {z }
Here step (i) follows from (A.4), while step (ii) utilizes (A.3). Since X is a continuous random variable for
t
any t (0,1), we have
∈
lim P (1 t)1/4 < X <0.5 log1/(1 t) =1.
t 2
t 1 − k k −
→ − (cid:16) p (cid:17)
Therefore we know that
d
lim g (t)= log(2π).
t 1 x0 −2
→ −
Recall that X =d √1 tX +√tZ for a Gaussian variable Z (0,I ) independent of X , we can express
t 0 d 0
− ∼N
( √tZ+√1 tx (1 t)1/4)2 1
g (t)=E k − 0 k2 − − 1 (1 t)1/4 < √tZ+√1 tx < log1/(1 t)
x0
2t − k −
0 k2
2 −
(cid:20) (cid:26) (cid:27)(cid:21)
p
( √tz+√1 tx (1 t)1/4)2 1 1
e = k − 0 k2 − − 1 (1 t)1/4 < √tz+√1 tx < log φ(z)dz,
0 2
2t − k − k 2 1 t
Z (cid:26) r − (cid:27)
=:ht(z)
| {z }
15where φ(z)=(2π) d/2exp( z 2/2) is the density function of (0,I ). For any t (0.9,1), we have
− −k k2 N d ∈
h (z) √tz+√1 tx 2φ(z) 2( z 2+ x 2)φ(z)=:h(z),
t ≤k − 0 k2 ≤ k k2 k 0 k2
and it is straightforwardto check that
h(z)dz =2d+2 x 2 < .
k 0 k2 ∞
Z
By dominated convergence theorem, we know that
z 2 d
lim g (t)= lim h (z)dz = lim h (z)dz = k k2φ(z)dz = .
t 1
x0
t 1
t
t 1
t
2 2
→ − → −Z Z → − Z
Therefore we have e
E[logρ (X ) X =x ] g (t) where g (t):=g (t) g (t), (A.5a)
t t | 0 0 ≤ x0 x0 x0 − x0
such that
d de
lim g (t)= lim g (t) lim g (t)= log(2π) . (A.5b)
t 1 x0 t 1 x0 −t 1 x0 −2 − 2
→ − → − → −
Conclusion. By putting together (A.2) and (A.5), we ke now that for any t (0.9,1)
∈
d d
f (t) E[logρ (X ) X =x ] g (t) and lim f (t)= lim g (t)= log(2π) .
x0
≤
t t
|
0 0
≤
x0
t 1
x0
t 1
x0
−2 − 2
→ − → −
By the sandwich theorem, we arrive at the desired result
d d
lim E[logρ (X ) X =x ]= log(2π) .
t t 0 0
t 1 | −2 − 2
→ −
B Proof of Proposition 2
Suppose that L := sup 2logρ (x) . The following claim will be useful in establishing the proposition,
xk∇ 0 k
whose proof is deferred to the end of this section.
Claim 3. There exists some t >0 such that
0
sup 2logρ (x) 4L. (B.1)
t
k∇ k≤
x
holds for any 0 t t .
0
≤ ≤
Equipped with Claim 3, we know that for any t t ,
0
≤
E logρ (X ) X =x =E logρ (√1 tx +√tZ)
t t 0 0 t 0
| −
(cid:2) ( =i)E logρ (√1 (cid:3)tx )+(cid:2) √tZ logρ (√1 tx(cid:3))+O(Lt) Z 2
t − 0 ⊤ ∇ t − 0 k k2
( =ii) lo(cid:2)gρ (√1 tx )+O(Ldt) (cid:3)
t 0
−
( =iii) log ρ 0(x)(2πt) −d/2exp (1 −t) kx −x 0 k2 2 dx+O(L√dt)
− 2t
Zx
(cid:16) (cid:17)
=(1 t) −d/2log ρ 0(x)
2πt −d/2
exp
(1 −t) kx −x
0
k2
2 dx+O(L√dt), (B.2)
− 1 t − 2t
Zx (cid:18) − (cid:19) (cid:16) (cid:17)
where Z (0,I ). Here step (i) follows from (B.1) in Claim 3; step (ii) holds since E[Z] = 0 and
d
E[ Z 2]=∼ d;N while step (iii) follows from (5.11). It is straightforwardto check that
k k2
ρ (x)
2πt −d/2
exp
(1 −t) kx −x
0
k2
2 dx
0
1 t − 2t
Zx (cid:18) − (cid:19) (cid:16) (cid:17)
16is the density of ρ (0,t/(1 t)) evaluatedat x , which takencollectively with the assumptionthat ρ ()
0 0 0
∗N − ·
is continuous yields
lim ρ (x)
2πt −d/2
exp
(1 −t) kx −x
0
k2
2 dx=ρ (x ).
0 0 0
t →0+ Zx (cid:18)1 −t (cid:19) (cid:16)− 2t (cid:17)
Therefore we can take t 0+ in (B.2) to achieve
→
lim E logρ (X ) X =x =logρ (x )
t t 0 0 0 0
t 0+ |
→
(cid:2) (cid:3)
as claimed.
Proof of Claim 3. The conditional density of X given X =x is
0 t
p X0|Xt(x 0 |x)=
p X0(x 0) pp
XX tt (| xX
)0(x |x 0)
=
ρ
ρ0
t( (x
x0
))
(2πt) −d/2exp
(cid:18)−kx −√1 2t−tx
0
k2
2 (cid:19), (B.3)
which leads to
1
2 logp (x x)= 2 logρ (x )+ 2 x √1 tx 2
−∇x0 X0|Xt 0 | −∇x0 0 0 2t∇x0k − − 0 k2
1 t 1 t
= 2 logρ (x )+ − I − L I .
−∇x0 0 0 t d (cid:23) t − d
(cid:18) (cid:19)
Therefore we know that
1 1
2 logp (x x) I for t , (B.4)
−∇x0 X0|Xt 0 | (cid:23) 2t d ≤ 2(L+1)
namely the conditional distribution of X given X = x is 1/(2t)-strongly log-concave for any x, when
0 t
t 1/2(L+1). By writting
≤
x √tz
ρ t(x)=p Xt(x)= φ(z)p
√1 −tX0
x −√tz dz =(1 −t) −d/2 φ(z)ρ
0
√−
1 t
dz, (B.5)
Z (cid:16) (cid:17) Z (cid:18) − (cid:19)
we can express the score function of ρ as
t
ρ t(x) d+1 1 x √tz
logρ t(x)= ∇ =(1 t) − 2 φ(z) ρ 0 − dz
∇ ρ t(x) − ρ t(x)
Z
∇
(cid:18)
√1 −t
(cid:19)
d+1 1 x √tz x √tz
=(1 t) − 2 φ(z)ρ 0 − logρ 0 − dz (B.6)
− ρ t(x)
Z (cid:18)
√1 −t (cid:19)∇
(cid:18)
√1 −t
(cid:19)
(i) d+1 1 t d/2 1 x √1 tx 0
= (1 t) − 2 − φ − − ρ 0(x 0) logρ 0(x 0)dx 0
−
(cid:18)
t
(cid:19)
ρ t(x)
Z (cid:18)
√t
(cid:19)
∇
( =ii) 1 p (x x) logρ (x )dx = 1 E[ logρ (X ) X =x]. (B.7)
√1 t X0|Xt 0 | ∇ 0 0 0 √1 t ∇ 0 0 | t
− Z −
Here step (i) uses the change of variable x =(x √tz)/√1 t, while step (ii) follows from (B.3). Starting
0
− −
from (B.6), we take the derivative to achieve
2logρ t(x)=(1 t) −d 2+1 1 φ(z)ρ
0
x −√tz logρ
0
x −√tz logρ
0
x −√tz ⊤ dz
∇ − ρ t(x)
Z (cid:18)
√1 −t (cid:19)∇
(cid:18)
√1 −t (cid:19)(cid:20)∇
(cid:18)
√1 −t
(cid:19)(cid:21)
=:H1(x)
| +(1 t)−d 2+1 1 φ(z)ρ
0
x −√tz {z 2logρ
0
x −√tz dz }
− ρ t(x)
Z (cid:18)
√1 −t (cid:19)∇
(cid:18)
√1 −t
(cid:19)
=:H2(x)
| {z }
17d+1 1 x √tz x √tz
−(1 −t) − 2 ρ2(x) φ(z)ρ 0 √− 1 t ∇logρ 0 √− 1 t dz[ ∇ρ t(x)]⊤. (B.8)
t Z (cid:18) − (cid:19) (cid:18) − (cid:19)
=:H3(x)
| {z }
Then we investigate H (x), H (x) and H (x) respectively. Regarding H (x), we have
1 2 3 1
H 1(x)(a =1) (1 t) −d 2+1 1 −t d/2 1 φ x −√1 −tx 0 ρ 0(x 0) logρ 0(x 0)[ logρ 0(x 0)]⊤dz
−
(cid:18)
t
(cid:19)
ρ t(x)
Z (cid:18)
√t
(cid:19)
∇ ∇
(b1) 1
=
1 t
p X0|Xt(x
0
|x) ∇logρ 0(x 0)[ ∇logρ 0(x 0)]⊤dx
0
− Z
1
= E logρ 0(X 0)[ logρ 0(X 0)]⊤ X
t
=x ; (B.9a)
1 t ∇ ∇ |
− h i
for H (x), we have
2
H 2(x)(a =2) (1 t) −d 2+1 1 −t d/2 1 φ x −√1 −tx 0 ρ 0(x 0) 2logρ
0
x −√tz dx
0
−
(cid:18)
t
(cid:19)
ρ t(x)
Z (cid:18)
√t
(cid:19)
∇
(cid:18)
√1 −t
(cid:19)
(b =2) 1 p (x x) 2logρ (x )dx = 1 E 2logρ (X ) X =x ; (B.9b)
1 t X0|Xt 0 | ∇ 0 0 0 1 t ∇ 0 0 | t
− Z −
(cid:2) (cid:3)
for the final term H (x), we have
3
(c) d+1 1 x √tz x √tz
H 3(x) = (1 t) − 2 φ(z)ρ 0 − logρ 0 − dz [ logρ t(x)]⊤
− − ρ t(x)
(cid:20)Z (cid:18)
√1 −t (cid:19)∇
(cid:18)
√1 −t
(cid:19) (cid:21)
∇
(a3) d+1 1 t d/2 1 x √1 tx 0
= (1 t) − 2 − φ − − ρ 0(x 0) logρ 0(x 0)dx 0 [ logρ t(x)]⊤
− −
(cid:18)
t
(cid:19)
ρ t(x)
(cid:20)Z (cid:18)
√t
(cid:19)
∇
(cid:21)
∇
(b3) 1
=
−√1 t
p X0|Xt(x
0
|x) ∇logρ 0(x 0)dx 0[ ∇logρ t(x)]⊤
− Z
( =d) 1 E[ logρ 0(X 0) X
t
=x]E[ logρ 0(X 0) X
t
=x]⊤. (B.9c)
−1 t ∇ | ∇ |
−
Here steps (a1), (a2) and (a3) follow from the change of variable x = (x √tz)/√1 t; steps (b1), (b2)
0
− −
and (b3) utilize (B.3); step (c) follows from logρ (x) = ρ (x)/ρ (x); while step (d) follows from (B.7).
t t t
∇ ∇
Substituting (B.9) back into (B.8), we have
1 1
2logρ (x)= E 2logρ (X ) X =x + cov( logρ (X ) X =x). (B.10)
t 0 0 t 0 0 t
∇ 1 t ∇ | 1 t ∇ |
− −
(cid:2) (cid:3)
Notice that for any t 1/2(L+1), we have
≤
cov( logρ (X ) X =x) = sup E u ( logρ (X ) E[ logρ (X ) X =x]) 2 X =x
0 0 t ⊤ 0 0 0 0 t t
k ∇ | k u Sd−1 ∇ − ∇ | |
∈ h(cid:2) (cid:3) i
(i) sup E u ( logρ (X ) logρ (E[X X =x])) 2 X =x
⊤ 0 0 0 0 t t
≤ u Sd−1 ∇ −∇ | |
∈ h(cid:2) (cid:3) i
E logρ (X ) logρ (E[X X =x]) 2 X =x
≤ k∇ 0 0 −∇ 0 0 | t k2 | t
(ii) h i
E X E[X X =x] 2 X =x
≤ k 0 − 0 | t k2 | t
h i
(iii)
2tL2d, (B.11)
≤
Herestep(i)holdssinceforanyrandomvariableX,E[(X c)2]isminimizedatc=E[X];step(ii)holdssince
−
the score function logρ () is L-Lipschitz; step (iii) follows from the Poincaré inequality for log-concave
0
∇ ·
18distribution, and the fact that the conditional distribution of X given X = x is 1/2t-strongly log-concave
0 t
(cf. (B.4)). We conclude that
(a) 1 2tL2d (b)
2logρ (x) L+ 4L.
t
∇ ≤ 1 t 1 t ≤
− −
(cid:13) (cid:13)
Here step (a) follows from (B.10)(cid:13), (B.11), and(cid:13)the assumption that sup 2logρ (x) L, while step (b)
xk∇ t k ≤
holds provided that t min 1/2,1/(2Ld) .
≤ { }
C More discussions on the density formulas
Although the density formulas (3.1a) have been rigorously established, it is helpful to inspect the limiting
behavior of the integrand D(t,x ) at the boundary to understand why the integral converges. Throughout
0
the discussion, we let ε (0,I ).
d
∼N
• As t 0, we can compute
→
E ε+√t logρ (√1 tx +√tε) 2 d
D(t,x ) k ∇ t − 0 k2 −
0
≍ t
(cid:2) (cid:3)
(i)E logρ (√1 tx +√tε) 2 + 1 E ε logρ (√1 tx +√tε)
≍ k∇ t − 0 k2 √t ⊤ ∇ t − 0
(ii)E(cid:2)
logρ (√1 tx +√tε)
2(cid:3)
+E
tr(cid:2)
2logρ (√1 tx
+√tε)(cid:3)
.
≍ k∇ t − 0 k2 ∇ t − 0
(cid:2) (cid:3) h (cid:16) (cid:17)i
Here step (i) holds since E[ ε 2] = d, while step (ii) follows from Stein’s lemma. Therefore, when the
k k2
scorefunctionsarereasonablysmoothast 0,onemayexpectthattheintegrandD(t,x )isofconstant
0
→
order, allowing the integral to converge at t=0.
• As t 1, we can compute
→
1 d
D(t,x )= E ε+√t logρ (√1 tx +√tε) 2
0 2(1 t)t k ∇ t − 0 k2 − 2t
−
1 (cid:2) (cid:3) d
E ε+√t logρ (√1 tx +√tε) 2 .
≍ 2(1 t) k ∇ t − 0 k2 − 2
−
(cid:2) (cid:3)
Since ρ converges to φ as t 1 and logφ(x)= x, we have
t
→ ∇ −
limε+√t logρ (√1 tx +√tε)=0.
t 0
t 1 ∇ −
→
HenceonemayexpectthatE ε+√t logρ (√1 tx +√tε) 2 convergestozeroquickly,allowingthe
k ∇ t − 0 k2
integral to converge at t=1.
(cid:2) (cid:3)
D Technical details in Section 4
D.1 Technical details in Section 4.1
Computing L (x ). Conditional on X =x and X =x , we have
t 1 0 t t 0 0
−
√α β √α (1 α ) 1 α
t 1 t t t 1 t 1
X t 1 X t =x t,X 0 =x 0 − x 0+ − − x t, − − β tI d ,
− | ∼N (cid:18) 1 −α t 1 −α t 1 −α t (cid:19)
and conditional on Y =x , we have
t t
x +η s (x ) σ2
Y Y =x t t t t , t .
t 1 t t
− | ∼N (cid:18) √α t α t(cid:19)
19Recall that the KL divergence between two d-dimensional Gaussian (µ ,Σ ) and (µ ,Σ ) admits the
1 1 2 2
N N
following closed-form expression:
1
KL( N(µ 1,Σ 1) kN(µ 2,Σ 2))=
2
tr Σ−21Σ
1
+(µ
2
−µ 1)⊤Σ−21(µ
2
−µ 1) −d+logdetΣ
2
−logdetΣ
1
.
h (cid:0) (cid:1) i
Then we can check that for 2 t T,
≤ ≤
2
α √α β α 1 η s (x )
KL p Xt−1|Xt,X0( ·|x t,x 0) kp Yt−1|Yt( ·|x t) = 2σt t2
(cid:13)
1 −t − α1 tt x 0+ √α t(t 1− −α t)x t − t √t α tt (cid:13)2,
(cid:0) (cid:1) (cid:13) (cid:13)
(cid:13) (cid:13)
where we use the coefficient design (4.3). This immedia(cid:13)tely gives (cid:13)
2
α √α β α 1 η s (x )
L t −1(x 0)= 2σt t2E xt ∼pXt|X0( ·|x0) "(cid:13) 1 −t − α1 tt x 0+ √α t(t 1− −α t)x t − t √t α tt (cid:13)2#
(cid:13) (cid:13)
( =i) α t E α(cid:13) (cid:13)t −1 ε 1 −α t s (√α x +√1 α ε)(cid:13) (cid:13)2
2σ t2 ε ∼N(0,Id) "(cid:13) α t(1 −α t) − √α t t t 0 − t (cid:13)2#
(cid:13) (cid:13)
( =ii) 2(1
α
t−α αt t)E
ε
∼N(cid:13) (cid:13) (0p
,Id)
ε −ε t(√α tx 0+√1 −α tε) 2
2
. (cid:13) (cid:13)
− h(cid:13) (cid:13) i
Here in step (i), we utilize the coefficient design(cid:13)(4.3) and replace x with(cid:13)√α x +√1 α ε, which has
t t 0 t
−
the same distribution; while in step (ii), we replace the score function s () with the epsilon predictor
t
·
ε ():= √1 α s (). Comparing the coefficients in L⋆ and L , we decompose
t · − − t t · t −1 t −1
1 α 1 α 1 α 1 α 1 α 1 α
t+1 t t+1 t+1 t+1 t
− − − − + − − .
2(1 α ) − 2(α α ) ≤ 2(1 α ) − 2(α α ) 2(α α ) − 2(α α )
(cid:12) − t t − t (cid:12) (cid:12) − t t − t (cid:12) (cid:12) t − t t − t (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) =:γ1 (cid:12) (cid:12) =:γ2 (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12)
Consider the learning rate schedule in Li|et al. (2023{zb); Li and Y}an|(2024): {z }
t
1 c logT c logT
1 1
β = , β = min β 1+ ,1 (t=1,...,T 1) (D.1)
1 Tc0 t+1 T ( 1 (cid:18) T (cid:19) ) −
for sufficiently large constants c ,c > 0. Then using the properties in e.g., Li and Yan (2024, Lemma 8),
0 1
we can check that
(1 α )(α 1) 8c logT 1 α
t+1 t 1 t+1
γ = − − − ,
1
2(1 α )(α α ) ≤ T 2(1 α )
(cid:12) − t t − t (cid:12) (cid:12) − t (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
and (cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
α α β β β 1 α 1 α 8c logT 1 α
t t+1 t t+1 t t t+1 1 t+1
γ = − = − 1 1+ − − − .
2
2(α α ) 2(α α ) ≤ − β α α 2(1 α ) ≤ T 2(1 α )
(cid:12) t − t (cid:12) (cid:12) t − t (cid:12) (cid:12) t+1(cid:12)(cid:12) t − t(cid:12)(cid:12) − t (cid:12) (cid:12) − t (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12)(cid:12) (cid:12)(cid:12) (cid:12) (cid:12) (cid:12)
Hence the (cid:12)coefficients (cid:12)in L(cid:12)⋆ and L (cid:12) a(cid:12)re identica(cid:12)l(cid:12)up to higher(cid:12)-(cid:12)order error(cid:12): (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)t 1 t(cid:12)1 (cid:12) (cid:12)(cid:12) (cid:12)(cid:12) (cid:12) (cid:12) (cid:12)
− −
1 α 1 α 16c logT 1 α
t+1 t 1 t+1
− − − .
2(1 α ) − 2(α α ) ≤ T 2(1 α )
(cid:12) − t t − t (cid:12) (cid:12) − t (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
Computing L (x ). Byta(cid:12)kingη =σ2 =1 α (n(cid:12)oticethat(4.3(cid:12))doesnot(cid:12)coverthe caset=1),wehave
0 0 1 1 − 1
p (x x )=
2πσ 12 −d/2
exp
α
1
x
x
1
−η 1s 1(x 1) 2
Y0|Y1 0 | 1 (cid:18) α 1 (cid:19) −2σ 12 (cid:13) 0 − √α 1 (cid:13)2!
(cid:13) (cid:13)
2πβ
1
−d/2 α
1
(cid:13)
(cid:13)
x
1
β 1s 1(x 1)(cid:13) (cid:13)2
= exp x − ,
0
(cid:18) α 1 (cid:19) −2β 1 (cid:13) − √α 1 (cid:13)2!
(cid:13) (cid:13)
(cid:13) (cid:13)
(cid:13) (cid:13)
20and therefore
2
d 2πβ α x +β s (x )
C (x )=E log 1 1 x 1 1 1 1
0 0 x1∼pX1|X0( ·|x0) "−2 α 1 − 2β 1 (cid:13) 0 − √α 1 (cid:13)2#
(cid:13) (cid:13)
( =i) d log2πβ 1 1 E ε+ β(cid:13) (cid:13)s ( 1 β x + β(cid:13) (cid:13)ε) 2
−2 α
1
− 2 ε ∼N(0,Id) k 1 1 − 1 0 1 k2
( =ii) 1+log(2πβ 1) d+ d log(1h β )p1 β Ep s (p 1 β i x + β ε) 2
− 2 2 − 1 − 2 1 ε ∼N(0,Id) k 1 − 1 0 1 k2
−
β 1E
ε ∼N(0,Id)
ε⊤s 1( 1 −β 1x 0+ β 1ε) . (cid:2) p p (cid:3) (D.2)
Here in step (i), we replapce x with √1(cid:2) β xp+ √β ε, wphich ha(cid:3)s the same distribution; step (ii) uses
1 1 0 1
the fact that E[ ε 2] = d for ε (0,I− ). Using similar analysis as in Proposition 2, we can show that
k k2 ∼ N d
sup 2logq (x) O(L) when β is sufficiently small, as long as sup 2logq (x) L. Hence we have
xk∇ 1 k≤ 1 xk∇ 0 k≤
E s ( 1 β x + β ε) 2 E s (x ) +O(L) x 1 β x β ε 2
ε ∼N(0,Id) k 1 − 1 0 1 k2 ≤ ε ∼N(0,Id) k 1 0 k2 k 0 − − 1 0 − 1 k2
(cid:2) p p (cid:3) ≤2 ks 1(x 0) k2 2(cid:2)+(cid:0) O(L2)E ε ∼N(0,Id) kx 0 −p 1 −β 1x 0 −p β 1ε k(cid:1)2 2 (cid:3)
=2 ks 1(x 0) k2 2+O(L2β 1). (cid:2) p p (D(cid:3) .3)
By Stein’s lemma, we can show that
E ε s ( 1 β x + β ε) = β E tr 2logq ( 1 β x + β ε)
ε ∼N(0,Id) ⊤ 1
−
1 0 1 1
∇
1
−
1 0 1
h p p i pO( βh Ld(cid:16) ). p p (cid:17)i (D.4)
1
≤
Substituting the bounds (D.3) and (D.4) back into (D.2p), we have
1+log(2πβ )
1
C (x )= d+O(β )
0 0 1
− 2
as claimed.
Negligibility of L (x). Since
T
Y (0,I ), and X X =x √α x ,(1 α )I ,
T d T 0 0 T 0 T d
∼N | ∼N −
we can compute (cid:0) (cid:1)
1 α d 1 α
KL p () p ( x ) = T d+ x 2 + log(1 α ) T d+ x 2 .
YT · k XT |X0 ·| 0 21 α
T
k 0 k2 2 − T ≤ 21 α
T
k 0 k2
− −
(cid:0) (cid:1) (cid:0) (cid:1) (cid:0) (cid:1)
Using the learning rate schedule in (D.1), we can check that α
T
T −c2 for some large universal constant
≤
c >0; see e.g., Li et al. (2023b, Section 5.1) for the proof. Therefore when T 2, we have
2
≥
d+ x 2
KL p () p ( x ) k 0 k2,
YT · k XT |X0 ·| 0 ≤ 4Tc2
(cid:0) (cid:1)
which is negligible when T is sufficiently large.
Optimal solution for (4.5). It is knownthat for each1 t T, the score function s⋆() associatedwith
≤ ≤ t ·
q satisfies
t
1 2
s⋆()= argmin E s √α x+√1 α ε + ε .
t · s( ·):Rd →Rd x ∼q0,ε ∼N(0,Id) "(cid:13)
(cid:13) (cid:0)
t − t
(cid:1)
√1 −α t (cid:13) (cid:13)2#
See e.g., Chen et al. (2022, Appendix A) for the pro(cid:13)of. Recall that ε⋆()=√1 α s⋆((cid:13)), then we have
(cid:13) t · − t t (cid:13)·
ε⋆()= argmin E ε ε(√α x+√1 α ε) 2 .
t · ε():Rd Rd x ∼q0,ε ∼N(0,Id) − t − t 2
· → h(cid:13) (cid:13) i
Therefore the global minimizer for (4.5) is ε () ε⋆() f(cid:13) or each 1 t T. (cid:13)
t · ≡ t · ≤ ≤
b 21D.2 Technical details in Section 4.2
By checking the optimality condition, we know that (D ,G ) is a Nash equilibrium if and only if
λ λ
p (x)
data
D (x)= , (optimality condition for D ) (D.5)
λ λ
p (x)+p (x)
data Gλ
where p =(G ) p , and there exists some constant c such that
Gλ λ # noise
logD (x)+λL(x)=c, when x supp(p ),
−
λ
∈
Gλ
(optimality condition for G ) (D.6)
λ
( logD λ(x)+λL(x) c, otherwise.
− ≥
Taking the approximationL(x) logp (x)+C⋆ as exact, we have
≈− data 0
D (x)=
eλC 0⋆ −cp−daλ ta(x), for x ∈supp(p Gλ),
(D.7)
λ
(1, for x ∈/ supp(p Gλ).
where the first and second cases follow from (D.6) and (D.5) respectively. Then we derive a closed-form
expression for p .
Gλ
• For any x supp(p ), by putting (D.5) and (D.7) together, we have
∈
Gλ
eλC 0⋆ −cp−daλ ta(x)=
p
(p xd )at +a(x p) (x),
data Gλ
which further gives
p Gλ(x)=p data(x) e −λC 0⋆+cpλ data(x) −1 . (D.8)
• For any x / supp(p ), we have (cid:0) (cid:1)
∈
Gλ
logD (x)+λL(x)( =i) λL(x)( =ii) λlogp (x)+λC⋆ (iii) c,
− λ − data 0 ≥
where step (i) follows from D (x) = 1, which follows from (D.7); step (ii) holds when we take the
λ
approximation L(x) logp (x)+C⋆ as exact; and step (iii) follows from (D.6). This immediately
≈ − data 0
gives
e −λC 0⋆+cpλ data(x) −1=log( −λC 0⋆+c+λlogp data(x)) −1 ≤0. (D.9)
Taking (D.8) and (D.9) collectively, we can write
p Gλ(x)=p data(x) e−λC 0⋆+cpλ data(x) −1 +. (D.10)
(cid:0) (cid:1)
On the other hand, we can check that (D.7) and (D.10) satisfies the optimality conditions (D.5) and (D.6),
which establishes the desired result.
References
Albergo,M.S., Boffi,N.M.,andVanden-Eijnden, E.(2023). Stochasticinterpolants: Aunifying framework
for flows and diffusions. arXiv preprint arXiv:2303.08797.
Anderson,B.D.(1982). Reverse-timediffusionequationmodels. StochasticProcesses andtheirApplications,
12(3):313–326.
Benton,J.,DeBortoli,V.,Doucet,A.,andDeligiannidis,G.(2023). Linearconvergenceboundsfordiffusion
models via stochastic localization. arXiv preprint arXiv:2308.03686.
Chen, H., Lee, H., and Lu, J. (2023a). Improved analysis of score-based generative modeling: User-friendly
bounds underminimalsmoothnessassumptions. In International Conference on Machine Learning,pages
4735–4763.PMLR.
22Chen,S.,Chewi, S.,Lee,H.,Li,Y.,Lu, J.,andSalim,A.(2023b). Theprobabilityflowodeisprovablyfast.
arXiv preprint arXiv:2305.11798.
Chen, S., Chewi, S., Li, J., Li, Y., Salim, A., and Zhang, A. R. (2022). Sampling is as easy as learning the
score: theory for diffusion models with minimal data assumptions. arXiv preprint arXiv:2209.11215.
Croitoru, F.-A., Hondru, V., Ionescu, R. T., and Shah, M. (2023). Diffusion models in vision: A survey.
IEEE Transactions on Pattern Analysis and Machine Intelligence.
Dhariwal, P. and Nichol, A. (2021). Diffusion models beat GANs on image synthesis. Advances in Neural
Information Processing Systems, 34:8780–8794.
Goodfellow,I.,Pouget-Abadie,J.,Mirza,M.,Xu,B.,Warde-Farley,D.,Ozair,S.,Courville,A.,andBengio,
Y. (2014). Generative adversarialnets. Advances in neural information processing systems, 27.
Graikos, A., Malkin, N., Jojic, N., and Samaras, D. (2022). Diffusion models as plug-and-play priors.
Advances in Neural Information Processing Systems, 35:14715–14728.
Grathwohl, W., Chen, R. T. Q., Bettencourt, J., and Duvenaud, D. (2019). Scalable reversible generative
models with free-form continuous dynamics. In International Conference on Learning Representations.
Haussmann, U. G. and Pardoux, E. (1986). Time reversal of diffusions. The Annals of Probability, pages
1188–1205.
Ho, J., Jain, A., and Abbeel, P. (2020). Denoising diffusion probabilistic models. Advances in Neural
Information Processing Systems, 33:6840–6851.
Hyvärinen, A. (2005). Estimation of non-normalized statistical models by score matching. Journal of
Machine Learning Research, 6(4).
Hyvärinen, A. (2007). Some extensions of score matching. Computational statistics & data analysis,
51(5):2499–2512.
Li, A. C., Prabhudesai,M., Duggal,S., Brown,E., and Pathak, D. (2023a). Your diffusion model is secretly
a zero-shot classifier. In Proceedings of the IEEE/CVF International Conference on Computer Vision,
pages 2206–2217.
Li, G., Wei, Y., Chen, Y., and Chi, Y. (2023b). Towards non-asymptotic convergence for diffusion-based
generative models. In The Twelfth International Conference on Learning Representations.
Li,G.andYan,Y.(2024). Adaptingtounknownlow-dimensionalstructuresinscore-baseddiffusionmodels.
arXiv preprint arXiv:2405.14861.
Li, T., Tian, Y., Li, H., Deng, M., and He, K. (2024). Autoregressive image generation without vector
quantization. arXiv preprint arXiv:2406.11838.
Luo, C. (2022). Understanding diffusion models: A unified perspective. arXiv preprint arXiv:2208.11970.
Mardani, M., Song, J., Kautz, J., and Vahdat, A. (2024). A variational perspective on solving inverse
problems with diffusion models. In The Twelfth International Conference on Learning Representations.
Nichol, A. Q. and Dhariwal, P. (2021). Improved denoising diffusion probabilistic models. In International
Conference on Machine Learning, pages 8162–8171.
Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., and Chen, M. (2022). Hierarchical text-conditional image
generation with CLIP latents. arXiv preprint arXiv:2204.06125.
Rombach,R., Blattmann, A., Lorenz,D., Esser,P., andOmmer,B.(2022). High-resolutionimagesynthesis
with latent diffusion models. In IEEE/CVF Conference on Computer Vision and Pattern Recognition,
pages 10684–10695.
23Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E. L., Ghasemipour, K., Gontijo Lopes, R.,
Karagol Ayan, B., Salimans, T., et al. (2022). Photorealistic text-to-image diffusion models with deep
language understanding. Advances in Neural Information Processing Systems, 35:36479–36494.
Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., and Ganguli, S. (2015). Deep unsupervised learning
using nonequilibrium thermodynamics. In International Conference on Machine Learning, pages 2256–
2265.
Song,J.,Meng,C.,andErmon,S.(2021a). Denoisingdiffusionimplicitmodels. InInternational Conference
on Learning Representations.
Song, Y. and Ermon, S. (2019). Generative modeling by estimating gradients of the data distribution.
Advances in neural information processing systems, 32.
Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole, B. (2021b). Score-based
generativemodeling throughstochasticdifferential equations. International Conference on Learning Rep-
resentations.
Vincent, P. (2011). A connectionbetween score matching and denoising autoencoders. Neural computation,
23(7):1661–1674.
Xia, M., Shen, Y., Yang, C., Yi, R., Wang, W., and Liu, Y.-j. (2023). Smart: Improving gans with score
matching regularity. In Forty-first International Conference on Machine Learning.
Yang, L., Zhang, Z., Song, Y., Hong, S., Xu, R., Zhao, Y., Zhang, W., Cui, B., and Yang, M.-H. (2023).
Diffusionmodels: Acomprehensivesurveyofmethodsandapplications.ACMComputingSurveys,56(4):1–
39.
24