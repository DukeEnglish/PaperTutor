HGOT: Hierarchical Graph of Thoughts for Retrieval-Augmented
In-Context Learning in Factuality Evaluation
YihaoFang1,3,StephenW.Thomas1 andXiaodanZhu2,3
1SmithSchoolofBusiness,Queen’sUniversity
2DepartmentofElectricalandComputerEngineering,Queen’sUniversity
3IngenuityLabsResearchInstitute,Queen’sUniversity
yihao.fang@gmail.com,{stephen.thomas,xiaodan.zhu}@queensu.ca
Abstract 2020;Raunaketal.,2021;Bouyamourn,2023)—
generatingcontentthatisfactuallyincorrectornot
With the widespread adoption of large lan-
grounded in reality. This issue raises significant
guage models (LLMs) in numerous applica-
concernsaboutthereliabilityandtrustworthiness
tions,thechallengeoffactualityandthepropen-
ofLLMs,particularlyinhigh-stakesapplications.
sity for hallucinations raises significant con-
cerns. To address this issue, particularly in While numerous efforts have been made to ad-
retrieval-augmented in-context learning, we dress various aspects of this problem, a critical
introduce the hierarchical graph of thoughts areathatdemandsattentionisretrieval-augmented
(HGOT),astructured,multi-layeredgraphap-
in-contextlearning(Lazaridouetal.,2022;Izacard
proach designed to enhance the retrieval of
etal.,2022;Pressetal.,2022;Khattabetal.,2022),
pertinentpassagesduringin-contextlearning.
aprocesswhereLLMsleverageexternalinforma-
Theframeworkutilizestheemergentplanning
tiontoenhancetheirresponses,whichisthefocus
capabilities of LLMs, employing the divide-
and-conquerstrategytobreakdowncomplex ofourstudy.
queriesintomanageablesub-queries. Itrefines In response to the challenge of hallucinations,
self-consistencymajorityvotingforanswerse- we introduce the hierarchical graph of thoughts
lection, which incorporates the recently pro- (HGOT)framework,drawinginspirationfromneu-
posedcitationrecallandprecisionmetricstoas-
ropsychologicalstudiesonthe“hierarchyofgoals”
sessthequalityofthoughts,linkingananswer’s
andworkingmemory(Cowan,2010;Jonidesetal.,
credibilityintrinsicallytothethought’squality.
2008;Cowan,2005). Ourapproachredefineshow
Thismethodologyintroducesaweightedsys-
LLMs interact with and utilize external informa-
tem in majority voting, prioritizing answers
basedonthecitationqualityoftheirthoughts. tionsources. Byconstructingastructured, multi-
Additionally, we propose a scoring mecha- layeredgraph(Yingetal.,2018;Chenetal.,2022),
nismforevaluatingretrievedpassages,consid- HGOT allows for a more organized and efficient
ering factors such as citation frequency and
way of sourcing and incorporatingrelevant infor-
quality, self-consistency confidence, and the
mation, thereby reducing the incidence of hallu-
retrieval module’s ranking. Experiments re-
cinations in LLMs. Despite these advances, the
veal that HGOT outperforms other retrieval-
challenges that we need to overcome involve dy-
augmentedin-contextlearningmethods,includ-
ingDemonstrate-Search-Predict(DSP),ReAct, namicallyconstructingahierarchicalgraph,aswell
Self-Ask,andRetrieve-then-Readondifferent asevaluatingandrankingthequalitiesofthoughts
datasetsbyasmuchas7%,demonstratingits andretrievedpassagesinthiscomplexstructure.
efficacyinenhancingthefactualityofLLMs. TheHGOTframeworkplacesastrongemphasis
on the dynamic creation of a hierarchical graph
1 Introduction
structurebyexploringtheapplicabilityoftheemer-
Theadvancementoflargelanguagemodels(LLMs) gent planning capabilities of LLMs (Wang et al.,
(Devlin et al., 2019; Raffel et al., 2020; Radford 2023a;Valmeekametal.,2023)inbreakingdown
et al., 2018, 2019; Brown et al., 2020) has revo- complexqueries(higherinthehierarchy)intosim-
lutionizedmanyfieldsofNLPandawidevariety pler sub-queries (lower in the hierarchy). This
of applications, offering unprecedented capabili- method employs a divide-and-conquer strategy,
tiesofnaturallanguageunderstandingandgenera- whichsimplifiestheproblem-solvingprocessand
tion. However,acriticalchallengeofthesemodels improvestheaccuracyandrelevanceoftheinfor-
is the tendency to “hallucinate” (Maynez et al., mationretrievedbytheLLM.
1
4202
beF
41
]IA.sc[
1v09390.2042:viXraAnotherkeyfeatureoftheHGOTframeworkis • RetrievalQuality: Weproposeascoringmech-
theimprovementoftheself-consistencymajority anismforevaluatingretrievedpassagesbasedon
voting mechanism (Wang et al., 2023b) used in citationfrequencyandquality,self-consistency
LLMs,whichenhancesthequalityassessmentof confidence,andretrievalmoduleranking.
thoughtsorrationales. Thisimprovementassesses • We conduct extensive experiments on FEVER,
thequalityofthoughtsorrationalesgeneratedby Open-SQuAD,andHotPotQA,emphasizingsam-
the LLMs. The method utilizes metrics such as plingfromtheextremesofthedistribution. The
citation recall and precision (Gao et al., 2023) to resultsdemonstratethatHGOTsurpassesother
evaluatethequalityoftheinformationusedbythe methodsbyasmuchas7%.
LLMsinformingtheirresponses. Theunderlying
premise is that the quality of an LLM’s response 2 RelatedWork
is directly related to the quality of its underlying
thought. Therefore,inthemajorityvotingprocess, The “Retrieve-then-Read” pipeline (Lazaridou
responsesaregivenweightsbasedonthecitation et al., 2022; Izacard et al., 2022) sends queries
qualityoftheirthoughts. to a retrieval model (RM) to gather passages for
Furthermore,theHGOTframeworkproposesa apromptthatalanguagemodel(LM)usesforre-
scoring mechanism to evaluate the quality of re- sponsegeneration. “Self-ask”(Pressetal.,2022)
trieved passages. This mechanism takes into ac- and “Iterative Retriever, Reader, and Reranker”
count various factors, including the frequency of (IRRR) (Qi et al., 2020) improve upon this ap-
passage citation, the citation quality (Gao et al., proach through multi-hop retrieval, enabling the
2023)ofthethought,self-consistencyconfidence LM to ask follow-up questions that the RM an-
score(Xiongetal.,2023;Wangetal.,2023b),and swers. Theseanswers,combinedwiththeoriginal
theretrievalmoduleranking. Byconsideringthese prompt,enhancetheLM’sabilitytorespondtothe
diverse factors, the mechanism ensures that the initialquestion.
informationutilizedintheLLM’sresponsegenera- “ReAct”(Yaoetal.,2023b)usesLLMstogener-
tionisbothrelevantandofhighquality. ate reasoning traces and task-specific actions in
To validate the effectiveness of the proposed an interleaved manner. While reasoning traces
method,weselectedFEVER(Thorneetal.,2018), help the model induce, actions allow it to inter-
Open-SQuAD(Rajpurkaretal.,2016;Karpukhin facewithexternalsources. Baleen(Khattabetal.,
etal.,2020),andHotPotQA(Yangetal.,2018)to 2021) summarizes multiple passages of informa-
evaluate the models’ proficiency in fact retrieval tion in each hop to be used in subsequent itera-
andreasoning. Wedividedthesedatasetsintothree tions. The“Demonstrate-Search-Predict”(DSP)ap-
groups: “Long”,“Medium”,and“Short”,accord- proach (Khattab et al., 2022) enhances the multi-
ingtothequestionlength,emphasizingsampling hop methodologies by automatically annotating
from the tails of the distribution, a detail that is “chain-of-thought” (Wei et al., 2022) demonstra-
frequentlyoverlookedinstudies. Ourexperiments tions. Thepotentialweaknessofthosemulti-hop
demonstratethatthehierarchicalgraphofthoughts pipelinesliesinthegeneralityandadaptabilityof
(HGOT) approach outperforms existing retrieval- theirsearchoperations. Especially,thosepipelines
augmented in-context learning methods such as face challenges when tasked with addressing in-
Demonstrate-Search-Predict(DSP)(Khattabetal., quiries that necessitate intricate planning for the
2022),ReAct(Yaoetal.,2023b),Self-Ask(Press retrievalofpertinentinformation.
et al., 2022), and Retrieve-then-Read (Lazaridou Plan-and-Solve (PS) Prompting (Wang et al.,
etal.,2022;Izacardetal.,2022),underscoringthe 2023a)involvesbreakingdowncomplextasksinto
robustnessandefficacyofourapproachinenhanc- manageablesubtasksandexecutingthemaccord-
ingLLMs’factuality. ing to a formulated plan, with PS+ prompting
Inbrief,wemakethefollowingcontributions: enhancing reasoning quality through detailed in-
• We introduce HGOT and investigate LLM’s structions. However,PShasn’tyetutilizedLLMs’
(emergent) planning ability in breaking down planningcapabilitieswithretrieval-augmentedin-
complexqueriesforgraphconstruction. contextlearning. Othermethodssuchasthe“tree
• Thought Quality: HGOT selects the best an- ofthoughts”(Yaoetal.,2023a),“graphofthoughts”
swerbyvotingwhichinvolvesassessingthought (Bestaetal.,2023),andRECURRENTGPT(Zhou
qualitywithcitationrecallandprecisionmetrics. etal.,2023)explorereasoningviatree, graph, or
2Dance and Laugh Amongst the Rotten is a studio Album by a band from which country ?
1 2 3 4
Probe Plan Search Infer
Predict Plan Rewrite (if dependency exists) Predict
Answer questions with short Sketch a plan to answer the following Rewrite the last question … by Answer questions with short factoid answers … question with the provided context … giving the answers to previous factoid answers …
[1] Dutch | Dutch, Dance and Q Dance and Laugh Amongst … questions … [1] Dance and Laugh Amongst
A[ L[ LL 32 aaa r]] uuu eCC ggg vaa hhh ierr AAA aa wcc mmm hh oooo fAA nnn Dnn ggg gg asss rr nttt ee cttt nn hhh eeee ‐‐ … DD RRR ooo aa nn ttt ttt cc eee ee nnn aa ……… nn dd | PL S C S tS t hh t tt ae ee ee rp pp a Ra c2 31 l ohb : :: tu tAW DW em n a nhh g n " aa ir cD sett e a anci s an o sf nt c u r th de o une m dta L r ib an o?ya ud i An gs L hd l bta h Aun uega mm hm b o …a…e nn go d sf t S t tC SSh ht tt ae eee erp pp a … R c1 32 oh A: :: t … tW DWN ea S nAh h nW a a N ic st t eE S ai cR Ws a o s: nt u E tCh d un Rae dt : Lr r ib a aN oyca u e ih An gs t hd l hA bt ehn An urega mml arm be n o …ae n d nn . s go d . sf t …t [ L [ li2 3h a n] ]e n e C C d uR a ag po r rr ,t a aa t bc cae ih hf on , gA A N| rn n aeD g g pta r rh he en e yn nc r /e l |haO a Conrn amdigd rs ei a n …… t c o h| w …n,
Q bD R aoa ntn t dc ee n f ra oisn m d a wL sa t huu idg ci hh o cA A om l ubo nun tm rg y s b t ?y t h ae D S St te ep p 3 3 d de ep pe en nd ds s o on n S St te ep p 1 2. . D Roa tn tc ee n a isn d a L sa tuu dg ih o A Am lbo un mg s …t the Q bD R aoa ntn t dc ee n f ra oisn m d a wL sa t huu idg ci hh o cA A om l ubo nun tm rg y s b t ?y t h ae
Dance and Laugh CarachAngrenis a
Thot.1 tA hm e o fin ftg hs t s t th ue d iR oo at lt be un m is A Hierarchical Graph of Thoughts Thot.1 bD lu at cc kh m sy em tap l h bo an ni dc
by Dutch … Carach [2][3][6][7].
Angren[1][2][3]. Ans.1 Netherlands Ans.1 Dutch L1 CarachAngrenis a
CarachAngrenis a Question symphonic black
Thot.2 D blu at cc kh m sy em tap l h bo an ni dc Thot.2 m Nee tt ha el rb laa nn dd s f rom the
[1][2]. [2][3][6][7].
Ans.2 Dutch Ans.2 Netherlands
CI 79.45% L2 CI 100%
Step 1 Step 3
B Thought Quality Step 2 C Retrieval Quality
Search Engine Score / Deeper Layer
(cid:3404)𝛼·1(cid:3397)𝛽· (cid:3397)𝛾· Step 2 Step 2 L3 ←𝑤(cid:3021)· Passage Score Step 1 Step 4 Citation Frequency
Step 3 Step 1
Confidence Score
Figure1: AnillustrativeexampleofHGOTinansweringafactualquestion. (Theabbreviationsemployedareas
follows: Instr.: Instructions,Q:Question,Ctx.: ContextorReferences,Resp.: ChatGPT’sResponse,PL:Plan,D:
Dependencies,CI:Confidence,Ans.: Answer,Thot.: Thought)
recurrent structures to improve problem-solving, Thismechanismtakesintoaccountvariousfactors
buttheyfacechallengesinsourcingrelevantinfor- suchasthefrequencyofpassagecitation,thequal-
mation,sufferingfromdrawbacksconcerningthe ityofcitationsinthethoughts,aself-consistency
factualreliabilityoflargelanguagemodels. confidencescoreadjustedforcitationquality,and
therankingprovidedbytheretrievalmodule.
3 Methodology
3.1 HierarchicalGraphConstruction,Search,
The Hierarchical Graph of Thoughts (HGOT) andInference
frameworkinvolvescreatingamulti-layeredgraph Graph Construction: When utilizing the emer-
thatallowsforamoreorganizedandefficientsourc- gentplanningabilitytobreakdownacomplexques-
ingandincorporationofrelevantinformation. This tionintosmaller,moremanageablesub-queriesor
structureaimstoreducetheoccurrenceofhalluci- steps,it’scrucialtorecognizethatthesesub-queries
nationsinLLMs. However,theinitialchallenges orstepsarenotstandalone. Instead,theyoftenex-
thatweneedtoovercomeinvolvedynamicallycon- hibitinterconnectionsthatcontributetoforminga
structinghierarchicalgraphs,alongwithassessing completeanswer. Thesestepsandtheirconnections
andrankingthequalitiesofthoughtsandretrieved create a dependency graph within a deeper level
passageswithinthiscomplexstructure. ofthehierarchicalgraph,whichguidestheexplo-
Intermsofhierarchicalgraphconstruction,the rationofthecomplexquestion. (Inthisframework,
HGOTframeworkutilizestheemergentplanning the dependency graph is designed as a directed
ability of LLMs to break down complex queries acyclicgraphtoavoidcirculardependencies.) Fur-
intosmaller,moremanageablesub-queries,follow- ther,eachsub-querycanbeextendedintoamore
ingadivide-and-conquerstrategy. detaileddependencygraphatevendeeperlevelsof
To select the best answer for a query, the the hierarchy. For example, as illustrated in Fig-
framework employs a method of improving self- ure 1: ⃝A, a query at the initial layer (Layer 1 or
consistencymajorityvoting(Wangetal.,2023b). L1)canbeextendedintoadependencygraphata
Thisinvolvesassessingthequalityofthoughtsus- subsequentlayer(Layer2orL2). WithinL2,the
ingcitationrecallandprecisionmetricsandweigh- firststepcouldunfoldintoafour-stepdependency
ing answers based on the citation quality of their graphinthenextlayer(Layer3orL3),whilethe
thoughts. third step in L2 might lead to a two-step depen-
Additionally,ascoringmechanismisproposed dencygraphatthesamethirdlayer(L3).
for evaluating the quality of retrieved passages. Establishing a precise dependency graph is es-
3
laveirteR
egassaP
ytilauQ
thguohT
.rtsnI
.xtC
.pseR
llaceR
noitatiC
noisicerP
noitatiC
.rtsnI
.pseR
tcelfer‐fleS
troS
lacigolopoT
.rtsnI
.xtC
.pseR
gniknaR
egassaP
erocS
egassaP
.rtsnI
.xtC
.pseRsentialbeforeprogressingtothesubsequentstage, pendencygraphatadeeperlevel. Followingthis,
asanyerrororambiguityatthisstagecouldsignifi- the“Search”procedure(Figure1: ⃝3)investigates
cantlyderailthesolutionpath. Toaccuratelyinfer thedependencygraphtopologically,andthe“Infer”
thisgraph,thereareseveralstrategiesthatwecan procedure(Figure1: ⃝4)isthenutilizedtocalcu-
adopt. Initially, we employed the “Probe” proce- late the final scores for all the passages collected
duretogatherreferences(referencedinFigure1: intheearlierstages,topredicttheanswer,andto
⃝1 and Appendix C.5). This involves collecting determine the confidence score. In each step or
passagesfromtheretrievalmodelandthenscoring sub-queryassessedduringthe“Search”procedure,
thesepassagesbypromptingLLMtoprobeforan the “Probe”, “Plan”, “Search”, and “Infer” pro-
answer. Thespecificsofhowpassagesarescored ceduresarerecursivelyexecuteduntilaspecified
willbediscussedinSection3.3. depthofthegraphisachieved,orthe“Plan”proce-
Subsequently,wedesignedtheprompttemplate dureoptstostopfurtherprogression. Specifically,
for the “Plan” procedure (Figure 1: ⃝2 and Ap- theterminationconditionisactivatedifthe“Plan”
pendix C.1). This template incorporates instruc- procedureresultsinonlyasinglestepthatclosely
tions, demonstrations (see Appendix D), and the resemblesthesub-querybeingplanned. Thesim-
collected passages. The aim is to stimulate the ilarity between them is assessed using the cosine
LLMandguideittowardsaholisticunderstanding similarity of their BERT-based sentence embed-
ofthequestionanditsinterconnectedcomponents. dings(ReimersandGurevych,2019).
Oncethe“Plan”procedureiscomplete,weintro-
Inference: Having the hierarchical graph of
ducetheself-reflectiontechnique(AppendixC.2),
thoughtsandtheirrelatedpassagescollectedfrom
inspiredbytheworkofShinnetal.(2023). Thisin-
theretrievalmodel,the“Infer”procedurepredicts
volvespromptingtheLLMagaintodouble-checkif
thefinalanswertothequery(Figure1: ⃝4). Specif-
theoutputdependenciesareaccurateandalignwith
ically,thisprocedureranksallpassagesretrieved
thequestionineachstep. Themethodencourages
during the examination of the query and its sub-
the LLM to focus internally on the dependencies
queries, as will be explained in Section 3.3. It
without external influence, by providing only re-
subsequently selects the top K passages with the
lated steps or sub-queries. Finally, we formalize
highest rankings to use as the prompt for LLM.
these dependencies into a structure that is more
Along with demonstrations and instructions, the
compatible with programming language formats
“Infer”procedureasksLLMtothinkstepbystep,
(AppendixC.3).
predictsthefinalanswer,andestimatestheconfi-
dencescore(AppendixC.5andAppendixD).The
Search: A crucial aspect of this stage involves
algorithm for recursive planning, searching, and
usingtopologicalsortingandrewriting,asshown
inferringwithinHGOTisdetailedasfollows:
in Figure 1: ⃝3. Topological sorting within a de-
pendencygraph(i.e.,adirectedacyclicgraph)en-
3.2 ThoughtQuality
sures that steps influencing subsequent steps are
Whenassessingthequalityofthoughts,weestab-
processed in a sequential order. When evaluat-
lish tuples (τ ,a ),...,(τ ,a ) as pairs of LLM-
ing a step or a sub-query, a “Probe” procedure is 1 1 m m
generated thoughts (rationales) and answers, as
employed (refer to Figure 1: ⃝1), which gathers
showninFigure1: ⃝1,⃝4,and⃝B. Thequalityof
passagesfromtheretrievalmodelandinstructsthe
a thought τ is determined by modifying the con-
LLM to search for an answer by using the sub- i
ceptsofcitationrecall(REC)andcitationprecision
query. In the context of the dependency graph,
(PREC)asintroducedbyGaoetal.(2023),inthe
whenStep2iscontingentonStep1,thequestion
followingmanner:
in Step 2 is rewritten (see Appendix C.4) to in-
clude the sub-query from Step 1 along with the
answerobtainedfromthe“Probe”procedure. This
ρ := α·1+β·REC(τ )+γ ·PREC(τ ) (1)
i i i
processensuresthattheinterconnectionsarewell-
articulatedandtraceablewithinthegraph. Assuming there are d distinct responses
The“Probe”procedureforeachsub-querydoes aˆ ,...,aˆ , with d being less than or equal to m,
1 d
morethanseekanswers;italsogathersandscores weimproveupontheself-consistencymajorityvot-
relevantpassages. Additionally,the“Plan”proce- ingmethod(Wangetal.,2023b)byfactoringinthe
dure is applied to each sub-query to create a de- thoughtqualities,definingtheselectedansweras:
4Algorithm1HGOTTraversal represent the generated thoughts (rationales) and
▷Letqbeaquestion answersproducedwhenusingChatGPTwithatem-
▷Letabeananswer.e.g.,a qistheanswertoq peraturegreaterthanzero. Statementsorsentences
▷LetGbeadependencygraph(i.e.,adirectedacyclic
s ,...,s are parts of τ . The process of natural
graph) 1 lτi i
▷LetCTXbethecontext(incl.passagesandscores) language inference (denoted as a function NLI)
▷LetCIbeaconfidencescore andacitationmarkerattheendofeachstatement
▷Letdbethelevelofdepthinthehierarchical
(denoted as M) work together to determine if a
1:
2: procedureTRAVERSE(q,d) statements citespassagep,resultinginavalueof
j
3: a ,CI ,CTX ←PROBE(q)
q q q eithertrueorfalse. Thisisformallyexpressedas:
4: G←PLAN(q,CTX )
q
5: ifSTOP(q,G,d)then
6: returna ,CI ,CTX
q q q (cid:40)
7: else 1, ifM(p,s )orNLI(p,s )
8: CTX
G
←SEARCH(G,d+1) δˆ(p,s j) = j j (4)
9: a ,CI ,CTX←INFER(q,CTX ,CTX ) 0, otherwise
q q q G
10: returna ,CI ,CTX
q q
11: endif We further define the “weighted citation fre-
12: endprocedure
quencyperthought”foragivenpassagep,asthe
13:
14: procedureSEARCH(G,d) totalnumberofcitationsinτ i,adjustedbythequal-
15: q 1,...,q r ←TOPOLOGICAL_SORT(G) ityofthethoughtτ i. Formally,itispresentedas:
16: foriin1...rdo
17: q ←REWRITE(q ,IN_NEIGHBORS(q ,G))
1 18 9:
:
enda
fi
q oi
r,CI qi,CTX
qii
←TRAVERSE(q
i,d)i
ν(p,τ ) = ρ
(cid:88)lτi
δˆ(p,s ) (5)
i i j
20: returnCTX ,...,CTX
q1 qr j=0
21: endprocedure
The“weightedcitationfrequency”istheaggre-
gate of these “weighted citation frequencies per
thought”acrossallthoughts,andisdenotedby:
m
(cid:88)
aˆ∗ = argmax ρ iδ(a i,aˆ h) (2) m
(cid:88)
aˆ h∈{aˆ1,...,aˆ d} i=1 νˆ(p) = ν(p,τ i) (6)
where δ is the Kronecker delta function, which i=0
equals 1 when the variables are the same and 0 Next,wenormalizethis“weightedcitationfre-
otherwise. quency” so that the highest value among all pas-
Moreover,wedeveloptheself-consistencycon- sages is equal to 1. The “normalized weighted
fidence score (Xiong et al., 2023) by taking into citationfrequency”isthus:
accountthethoughtqualities. Thisisdefinedas:
νˆ(p)
ν¯(p) = (7)
CI =
(cid:80)m i=1ρ iδ(a i,aˆ∗)
(3)
max 1≤k≤nνˆ(p)
(cid:80)m
i=1ρ i Finally, during the “Probe” or “Infer” proce-
dures,thequalityscoreofthepassagepisupdated
Note that when α equals 1 and both β and γ
repetitively, starting with the initial score σ(p,0)
arezero,theseequationsaresimplifiedtothepre-
providedbythesearchengineinthe“Probe”pro-
diction and calibration based on self-consistency
cedure. Theformulaisexpressedasfollows:
(Wangetal.,2023b;Xiongetal.,2023).
 
σ(p,t)
3.3 RetrievalQuality
σ(p,t+1) ← w⃗T · ν¯(p)  (8)
Assessingthequalityofretrievedpassagesconsid-
CI
ersmultipleaspects. Theseincludehowoftenthe
wherew⃗ = (w ,w ,w )isahyperparametervec-
passageiscited,thequalityofthesecitations(Gao 1 2 3
torthatcanbetunedfordifferentdatasets,retrieval
et al., 2023), a self-consistency confidence score
modelsandlargelanguagemodels.
(Xiongetal.,2023),andtherankinggivenbythe
retrievalmodule(Figure1: ⃝C).
4 Data
Assumepisaparticularpassageretrieved,which
servesasapartofthecontextinthe“Probe”or“In- WeevaluateHGOTacrossthreedatasets: FEVER
fer” procedures. The pairs (τ ,a ),...,(τ ,a ) (Thorne et al., 2018), Open-SQuAD (Rajpurkar
1 1 m m
5etal.,2016;Karpukhinetal.,2020),andHotPotQA forevaluation,comparedto2%ofHotPotQAques-
(Yangetal.,2018). Consideringtheuseofsentence tions. Additionally, questions from FEVER and
length as a parameter for estimating complexity Open-SQuAD below the 1.5th percentile are la-
hasbeenimplementedinvariousNLPtasks(Pla- belledassimpleorshort,similartothoseunderthe
taniosetal.,2019;Spitkovskyetal.,2010),toas- 2nd percentileforHotPotQAquestions. Lastly,Ta-
sessHGOTacrossdifferentcomplexitylevels,we ble1displaysthetotalnumberofexamplesacross
stratifythethreedatasetsbasedonsentencelength, allthreedatasets,spanningninecategories.
categorizingthemintolong,medium,andshort.
Metrics: For Open-SQuAD and HotPotQA, we
utilize the Exact Match (EM) and F1 scores (Ra-
jpurkaretal.,2016). TheEMscoreidentifiesthe
proportionofpredictionsthatpreciselyalignwith
thecorrectanswers,whiletheF1scoreassessesthe
averagetokenoverlapbetweenthepredictionand
thecorrectanswer. ForFEVER,weonlyuseEM,
consideringtheanswersinFEVERbeinglimited
tothreetokensorfewer.
Figure2: Thesentencelength,measuredbythenumber
oftokensinaquestion,fromtheFEVER,Open-SQuAD,
5 EvaluationSetup
andHotPotQAdatasets
Baselines: Our benchmarking includes five ap-
The sentence length, measured by the number proaches: “Vanilla LM” (Brown et al., 2020),
of tokens in a question, from the FEVER, Open- “Retrieve-then-Read”(Lazaridouetal.,2022;Izac-
SQuAD, and HotPotQA datasets is illustrated in ard et al., 2022), “Self-ask” (Press et al., 2022),
Figure2. ThemediannumberoftokensinFEVER “ReAct” (Yao et al., 2023b), and “Demonstrate-
is27,withalongtailofinstancesextendingbeyond Search-Predict”(DSP)(Khattabetal.,2022). See
themedian(indicatingpossiblecomplexityinrea- AppendixEforfurtherdetails.
soning,seeAppendixBforamorein-depthexami-
Implementation Details: All approaches em-
nationofthedata). Open-SQuADandHotPotQA
ployedChatGPT(gpt-3.5-turbo-1106)astheback-
likewiseexhibitedasimilardistribution. Thetrain-
bone LLM, with the exception of ReAct, which
ing,development,andtestdistributionsalignwell
utilizedtext-davinci-002,giventhatReAct’ssource
witheachother,enablingthestratificationofthese
code1 is not fully compatible with gpt-3.5-turbo-
datasetsbysentencelength.
1106. Fortheretrievalmodel,weusedtheGoogle
Sent. FEVER Open-SQuAD HotPotQA Search API provided by SerpApi.com, follow-
Len. TrainDevTest TrainDevTest TrainDevTest ing the “Self-ask” approach (Press et al., 2022).
Long 1619 113 113 1174 121 118 1504 168 137
HGOT2 wasimplementedusingPythonlanguage
Medium 2182 150 150 1181 133 159 1628 181 148
Short 2182 150 150 1181 133 159 1628 181 148 and the DSP framework (Khattab et al., 2022).
Following Gao et al. (2023), We adopt a natural
Table 1: Count of examples across all three datasets
languageinference(NLI)model(Honovichetal.,
andninecategories(RefertoAppendixAforsummary
2022) in HGOT to measure thought quality and
statisticsandAppendixBfordataexamples)
retrievalquality. Additionally,thetopologicalsort-
inganddeductionspertainingtoHGOTwereper-
QuestionsfromFEVERandOpen-SQuADthat
formedusingthePythonNetworkX3 package.
exceed the 98.5th percentile in length are catego-
rizedascomplexorlong,whileforHotPotQA,this
6 ExperimentalResults
categorizationappliestoquestionsabovethe98th
percentile. For questions of FEVER and Open- Findings and Analysis: The baseline models,
SQuAD that fall between the 1.5th and 98.5th referred to as “Vanilla LM”, utilize few-shot in-
percentiles,theyaredefinedasmediumlengthor context learning on ChatGPT without being aug-
medium difficulty, and for HotPotQA, this range mented by retrieval models. These “Vanilla LM”
isfromthe2nd tothe98th percentile. Withinthis
1https://github.com/ysymyth/ReAct
groupofmedium-lengthquestions,about1.5%of 2https://github.com/fangyihao/hgot
thosefromFEVERandOpen-SQuADarechosen 3https://networkx.org/
6FEVER Open-SQuAD HotPotQA FEVER Open-SQuAD HotPotQA
Method
EM EM F1 EM F1 EM EM F1 EM F1
Overall Long
VanillaLM 54.72 17.43 33.91 33.58 43.93 43.36 16.10 34.22 24.09 38.15
Retrieve-then-Read 58.35 22.51 38.81 41.20 51.21 46.90 29.66 44.60 35.77 50.05
Self-ask 53.03 18.81 34.15 43.98 54.67 46.90 20.34 35.10 42.34 59.32
ReAct 45.04 - - 35.47 42.18 34.51 - - 17.52 24.62
DSP 55.45 20.65 36.09 47.23 61.13 47.79 23.73 39.08 45.26 64.27
HGOT+Sampling(Ours) 61.50 22.05 36.11 45.03 56.07 53.98 28.81 42.21 37.23 53.36
HGOT+KNN(Ours) 60.53 24.10 38.32 47.37 59.48 54.87 28.81 46.27 43.07 59.77
Medium Short
VanillaLM 54.00 26.42 41.10 29.73 40.63 64.00 9.43 26.49 44.59 51.59
Retrieve-then-Read 59.33 28.30 43.14 35.81 45.43 66.00 11.32 30.12 50.68 57.88
Self-ask 52.00 27.04 41.05 41.89 51.92 58.67 9.43 26.53 47.30 53.92
ReAct 45.33 - - 33.11 40.69 52.67 - - 51.35 56.89
DSP 55.33 28.93 42.51 41.89 57.17 61.33 10.06 27.41 54.05 62.72
HGOT+Sampling(Ours) 57.33 27.67 40.25 41.89 53.33 71.33 11.32 27.38 54.05 60.87
HGOT+KNN(Ours) 61.33 31.45 42.17 46.62 59.21 64.00 13.21 28.47 51.35 59.54
Table 2: A comparative analysis of Vanilla LM, Retrieve-then-Read, Self-ask, ReAct, DSP, and HGOT. The
“Overall”sectionisderivedbycalculatingtheweightedaverageofmetricsfromthe“Long”,“Medium”,and“Short”
categories,usingthenumberofexamplesineachcategoryasweights.
modelscloselymirrorthefundamentalcapabilities multi-hopcomprehensionandreasoning.
ofChatGPTasassessedinourfactualityevaluation Specifically for the FEVER dataset,
datasets. Weobservethat“VanillaLM”generally HGOT+Sampling secures the top position,
excelsatrespondingtoshortquestions(orclaims withHGOT+KNNcloselybehindinsecondplace.
inFEVER),exceptwhenitcomestoshortOpen- With a 61.50% EM score, HGOT+Sampling
SQuAD questions (refer to Table 2). This excep- outperformsRetrieve-then-Read,whichisthird,by
tionisconsistentwithourdatasetanalysis(seeAp- amarginofover3%(refertothe“Overall”section
pendixBfordetails),whereit’sfoundthatlonger inTable2). IneverylengthcategoryoftheFEVER
questions(orclaimsinFEVER)oftendemandthe dataset,namely“Long”,“Medium”,and“Short”,
gathering of more facts and the undertaking of eitherHGOT+SamplingorHGOT+KNNachieves
more complex reasoning. Conversely, questions the highest ranking. Notably, HGOT+Sampling
ofmediumandshortlengthinOpen-SQuADusu- exceeds DSP, the strongest baseline, by more
allyrequireidentifyingoneortwospecificpieces than 7% in the “Long” category and surpasses
ofknowledge. However,medium-lengthquestions Retrieve-then-Read by more than 5% in the
providemorecontextthantheshorterones. “Short” category, where Retrieve-then-Read
Methodsotherthan“VanillaLM”includethose is the top among baselines. In the “Medium”
that are augmented by retrieval mechanisms. In category, Retrieve-then-Read competes closely
comparison,theseretrieval-augmentedapproaches withHGOT+KNN,underscoringtheimportanceof
generally surpass the performance of “Vanilla fact-gatheringovercomplexreasoninginFEVER,
LM”, except in cases involving Self-ask and Re- in line with findings in Appendix B. Moreover,
Act within the FEVER dataset (see the “Over- both HGOT+Sampling and HGOT+KNN, on
all” section in Table 2). Additionally, the DSP average, excel beyond Retrieve-then-Read’s
methodshowsweakerperformanceintheFEVER achievementsinthesescenarios.
dataset. This suggests that the ability to gather WithintheOpen-SQuADdataset,asdetailedin
factual information is more crucial in FEVER Table 2’s “Overall” section, HGOT+KNN stands
than the capacity for multi-hop reasoning. Our out as the top performer, recording an Exact
approaches, HGOT+Sampling and HGOT+KNN Match(EM)scoreof24.10%,whichisover1.5%
(with HGOT+Sampling and HGOT+KNN repre- higher than its nearest competitor, Retrieve-then-
sentingHGOTcombinedwiththedemonstration Read. HGOT+KNN also leads in EM scores for
selection methods of “balanced sampling” or “k both the “Medium” and “Short” categories and
nearestneighbors”,asdetailedinAppendixD),are achieves the highest F1 score in the ”Long” cat-
versatileandexhibitstrongperformanceacrossall egory of the dataset. Retrieve-then-Read demon-
threedatasets,regardlessofwhethertheyprioritize stratesstrongcompetitivenessintheOpen-SQuAD
theskillofaccumulatingfactualdataorconducting dataset, closely matching HGOT+KNN’s perfor-
7Figure3: Thevisualizationsofthehyperparametersearchesareshownthroughpairwiserelationships,featuringthe
EMscoreintherowandhyperparametersα,β,γ,w ,w ,andw inthecolumns. Eachsubplotisrepresentedasa
1 2 3
linechart,aggregatingthedatatodisplaythemean(solidblueline)andthe95%confidenceinterval(lightblue
area). Additionally,theoptimalhyperparametersforattainingthehighestEMscoreareindicatedineachsubplot.
mance across all categories, in contrast to DSP, thesearchengine’sscore.
which shows weaker performance. This observa- We include hyperparameter settings of α = 1,
tionisconsistentwithouranalysisinAppendixB, β = 0, and γ = 0, alongside w = 1, w = 0,
1 2
revealingthatalargeportionoftheOpen-SQuAD and w = 0, to equalize the absence of thought
3
questionsaredesignedtoextractfactualinforma- quality and to simulate the absence of retrieval
tion,mainlyasking“What”,“How”,and“When”. qualitywhensearchingfortheoptimalhyperparam-
In the HotPotQA dataset, known for demand- eterconfigurationsforthemedium-lengthcategory
ing multi-hop reasoning capabilities from mod- in the Open-SQuAD dataset. Figure 3 illustrates
els, HGOT+KNN achieved the top position in the EM scores associated with varying values of
the total EM score. For the “Medium” category, each hyperparameter. It is observed that the op-
HGOT+KNN recorded the highest EM score at timal EM score is attained with hyperparameter
46.62%, surpassing the second-best performers, values of α = 0.2, β = 0.4, γ = 0.4, w = 0.2,
1
HGOT+Sampling, DSP, and Self-ask, by 4.73%. w = 0.55,andw = 0.25,asdetailedinTable7
2 3
Additionally,inthiscategory,HGOT+KNNledin inAppendixF.Thisindicatesthatthebesthyper-
F1 score, outperforming the second-ranked DSP parametercombinationisfoundwhenboththought
byover2%. DSPprovedtobeastrongcontender qualityandretrievalqualityarepresent,emphasiz-
acrosstheboardintheHotPotQAdataset,closely ingthesignificanceofintroducingthesequalities
matching the performance of our HGOT+KNN intothemodel.
model,whereastheRetrieve-then-Readmodelfell
short. This performance trend corroborates our 7 Conclusion
datasetexaminationinAppendixB,confirmingthe
In our factuality evaluation, we chose FEVER,
necessity for models to possess robust multi-hop
Open-SQuAD, and HotPotQA to assess models’
reasoningskillsfortheHotPotQAdataset.
abilities in both fact retrieval and reasoning. We
Ablation Study: We examine the effect of the segmented the datasets FEVER, Open-SQuAD,
presenceorabsenceofthoughtqualityandretrieval and HotPotQA into three categories: “Long”,
quality,aswellashowHGOT’sperformancevaries “Medium”, and “Short”, based on the length of
with different hyperparameters. More precisely, their questions. This categorization emphasizes
we explore how the EM score interacts with the thesignificanceofexaminingbothextremelyshort
hyperparameters α, β, and γ as shown in Equa- andlongquestions,anaspectoftenoverlookedin
tion 1, and also how EM score relates to each el- research. We introduced HGOT. This approach
ement of w⃗ = (w ,w ,w ) as detailed in Equa- structuresthoughtsinahierarchicalgraphformat,
1 2 3
tion 8. Specifically, setting α = 1, β = 0, and leveragingemergentplanningcapabilities. Itevalu-
γ = 0 in Equation 1 is equivalent to a situation atesthoughtsandretrievedpassagesbyintroducing
wherethoughtqualityisnotconsidered,reducing metricsforthoughtandretrievalqualities,thereby
themodeltorelysolelyonpredictionandcalibra- safeguardingHGOT’scapabilitiesinreasoningand
tionthroughself-consistency,asdiscussedinWang fact-finding. ExperimentsshowthatHGOTstands
et al. (2023b). Similarly, when w = 1, w = 0, outasaversatileapproach,surpassingothermod-
1 2
and w = 0 in Equation 8, it simulates a condi- elsinFEVERandmatchingleadingmodelssuch
3
tionwhereretrievalqualityisdisregarded,withthe asRetrieve-then-ReadinOpen-SQuAD,andDSP
ranking of retrieved passages depending only on inHotPotQA.
8Limitations theNorthAmericanChapteroftheAssociationfor
ComputationalLinguistics: HumanLanguageTech-
HGOT employs OpenAI’s ChatGPT for its lan- nologies,Volume1(LongandShortPapers),pages
guagemodel,whereasalternativemodelssuchas 4171–4186,Minneapolis,Minnesota.Associationfor
ComputationalLinguistics.
Google’s Gemini and Meta’s Llama 2 have not
been explored. HGOT’s evaluation is conducted TianyuGao,HowardYen,JiatongYu,andDanqiChen.
using the Google Search API from SerpApi.com 2023. Enablinglargelanguagemodelstogenerate
asitsretrievalmodel. Itsperformancecouldvary, textwithcitations. arXivpreprintarXiv:2305.14627.
either improve or decline, when used in conjunc-
OrHonovich, RoeeAharoni, JonathanHerzig, Hagai
tion with other search engines such as Microsoft Taitelbaum,DoronKukliansy,VeredCohen,Thomas
Bing,Yahoo,andBaidu. Additionally,theretrieval Scialom, Idan Szpektor, Avinatan Hassidim, and
Yossi Matias. 2022. TRUE: Re-evaluating factual
model for HGOT could potentially include vari-
consistencyevaluation. InProceedingsofthe2022
ousdomain-specificdatasources,forexample,this
Conference of the North American Chapter of the
could involve aligning queries with pertinent in- AssociationforComputationalLinguistics: Human
formation in relational databases such as Oracle LanguageTechnologies,pages3905–3920,Seattle,
United States. Association for Computational Lin-
and IBM’s DB2, which are widely used in the fi-
guistics.
nanceindustry. However,theeffectivenessofthese
variantimplementationshasnotbeenexamined. Gautier Izacard, Patrick Lewis, Maria Lomeli, Lu-
cas Hosseini, Fabio Petroni, Timo Schick, Jane
Dwivedi-Yu,ArmandJoulin,SebastianRiedel,and
References Edouard Grave. 2022. Few-shot learning with re-
trievalaugmentedlanguagemodels. arXivpreprint
Maciej Besta, Nils Blach, Ales Kubicek, Robert Ger- arXiv:2208.03299.
stenberger,LukasGianinazzi,JoannaGajda,Tomasz
Lehmann,MichalPodstawski,HubertNiewiadomski, John Jonides, Richard L Lewis, Derek Evan Nee,
PiotrNyczyk,etal.2023. Graphofthoughts: Solv- Cindy A Lustig, Marc G Berman, and Kather-
ingelaborateproblemswithlargelanguagemodels. ine Sledge Moore. 2008. The mind and brain of
arXivpreprintarXiv:2308.09687. short-term memory. Annu. Rev. Psychol., 59:193–
224.
AdamBouyamourn.2023. WhyLLMshallucinate,and
how to get (evidential) closure: Perceptual, inten- VladimirKarpukhin,BarlasOguz,SewonMin,Patrick
sional,andextensionallearningforfaithfulnatural Lewis,LedellWu,SergeyEdunov,DanqiChen,and
language generation. In Proceedings of the 2023 Wen-tauYih.2020. Densepassageretrievalforopen-
Conference on Empirical Methods in Natural Lan- domainquestionanswering. InProceedingsofthe
guageProcessing,pages3181–3193,Singapore.As- 2020ConferenceonEmpiricalMethodsinNatural
sociationforComputationalLinguistics. LanguageProcessing(EMNLP),pages6769–6781,
Online.AssociationforComputationalLinguistics.
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind Omar Khattab, Christopher Potts, and Matei Zaharia.
Neelakantan,PranavShyam,GirishSastry,Amanda 2021. Baleen: Robustmulti-hopreasoningatscale
Askell,etal.2020. Languagemodelsarefew-shot viacondensedretrieval. AdvancesinNeuralInfor-
learners. Advancesinneuralinformationprocessing mationProcessingSystems,34:27670–27682.
systems,33:1877–1901.
Omar Khattab, Keshav Santhanam, Xiang Lisa
Cen Chen, Kenli Li, Wei Wei, Joey Tianyi Zhou, Li, David Hall, Percy Liang, Christopher Potts,
and Zeng Zeng. 2022. Hierarchical graph neural and Matei Zaharia. 2022. Demonstrate-search-
networks for few-shot learning. IEEE Transac- predict: Composing retrieval and language mod-
tionsonCircuitsandSystemsforVideoTechnology, els for knowledge-intensive nlp. arXiv preprint
32(1):240–252. arXiv:2212.14024.
NelsonCowan.2005. Workingmemorycapacity. Psy- Angeliki Lazaridou, Elena Gribovskaya, Wojciech
chologypress. Stokowiec, and Nikolai Grigorev. 2022. Internet-
augmented language models through few-shot
Nelson Cowan. 2010. Multiple concurrent thoughts: prompting for open-domain question answering.
Themeaninganddevelopmentalneuropsychologyof arXivpreprintarXiv:2203.05115.
workingmemory. Developmentalneuropsychology,
35(5):447–474. JiachangLiu,DinghanShen,YizheZhang,BillDolan,
Lawrence Carin, and Weizhu Chen. 2022. What
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and makes good in-context examples for GPT-3? In
Kristina Toutanova. 2019. BERT: Pre-training of ProceedingsofDeepLearningInsideOut(DeeLIO
deepbidirectionaltransformersforlanguageunder- 2022): The 3rd Workshop on Knowledge Extrac-
standing. InProceedingsofthe2019Conferenceof tionandIntegrationforDeepLearningArchitectures,
9pages100–114,Dublin,IrelandandOnline.Associa- andthe9thInternationalJointConferenceonNatu-
tionforComputationalLinguistics. ralLanguageProcessing(EMNLP-IJCNLP),pages
3982–3992,HongKong,China.AssociationforCom-
Joshua Maynez, Shashi Narayan, Bernd Bohnet, and putationalLinguistics.
Ryan McDonald. 2020. On faithfulness and factu-
alityinabstractivesummarization. InProceedings Noah Shinn, Federico Cassano, Ashwin Gopinath,
of the 58th Annual Meeting of the Association for KarthikRNarasimhan,andShunyuYao.2023. Re-
Computational Linguistics, pages 1906–1919, On- flexion: languageagentswithverbalreinforcement
line.AssociationforComputationalLinguistics. learning. In Thirty-seventh Conference on Neural
InformationProcessingSystems.
EmmanouilAntoniosPlatanios,OtiliaStretcu,Graham
Neubig,BarnabasPoczos,andTomMitchell.2019. ValentinI.Spitkovsky,HiyanAlshawi,andDanielJu-
Competence-based curriculum learning for neural rafsky. 2010. From baby steps to leapfrog: How
machine translation. In Proceedings of the 2019 “lessismore”inunsuperviseddependencyparsing.
Conference of the North American Chapter of the In Human Language Technologies: The 2010 An-
AssociationforComputationalLinguistics: Human nualConferenceoftheNorthAmericanChapterof
LanguageTechnologies,Volume1(LongandShort theAssociationforComputationalLinguistics,pages
Papers),pages1162–1172,Minneapolis,Minnesota. 751–759, LosAngeles, California.Associationfor
AssociationforComputationalLinguistics. ComputationalLinguistics.
James Thorne, Andreas Vlachos, Christos
OfirPress,MuruZhang,SewonMin,LudwigSchmidt,
Christodoulopoulos, and Arpit Mittal. 2018.
NoahASmith,andMikeLewis.2022. Measuring
FEVER: a large-scale dataset for fact extraction
andnarrowingthecompositionalitygapinlanguage
and VERification. In Proceedings of the 2018
models. arXivpreprintarXiv:2210.03350.
Conference of the North American Chapter of
the Association for Computational Linguistics:
PengQi,HaejunLee,OghenetegiriSido,ChristopherD
Human Language Technologies, Volume 1 (Long
Manning,etal.2020. Answeringopen-domainques-
tions of varying reasoning steps from text. arXiv Papers), pages 809–819, New Orleans, Louisiana.
preprintarXiv:2010.12527. AssociationforComputationalLinguistics.
KarthikValmeekam,MatthewMarquez,SarathSreed-
AlecRadford,KarthikNarasimhan,TimSalimans,Ilya
haran, and Subbarao Kambhampati. 2023. On the
Sutskever, et al. 2018. Improving language under-
planningabilitiesoflargelanguagemodels–acritical
standingbygenerativepre-training.
investigation. arXivpreprintarXiv:2305.15771.
AlecRadford,JeffreyWu,RewonChild,DavidLuan,
Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu,
DarioAmodei,IlyaSutskever,etal.2019. Language
Yunshi Lan, Roy Ka-Wei Lee, and Ee-Peng Lim.
modelsareunsupervisedmultitasklearners. OpenAI
2023a. Plan-and-solveprompting: Improvingzero-
blog,1(8):9.
shot chain-of-thought reasoning by large language
models. arXivpreprintarXiv:2305.04091.
ColinRaffel,NoamShazeer,AdamRoberts,Katherine
Lee,SharanNarang,MichaelMatena,YanqiZhou,
XuezhiWang,JasonWei,DaleSchuurmans,QuocVLe,
WeiLi,andPeterJLiu.2020. Exploringthelimits
EdH.Chi,SharanNarang,AakankshaChowdhery,
oftransferlearningwithaunifiedtext-to-texttrans-
andDennyZhou.2023b. Self-consistencyimproves
former. TheJournalofMachineLearningResearch,
chainofthoughtreasoninginlanguagemodels. In
21(1):5485–5551.
TheEleventhInternationalConferenceonLearning
Representations.
PranavRajpurkar,JianZhang,KonstantinLopyrev,and
PercyLiang.2016. SQuAD:100,000+questionsfor JasonWei,XuezhiWang,DaleSchuurmans,Maarten
machinecomprehensionoftext. InProceedingsof Bosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le,
the2016ConferenceonEmpiricalMethodsinNatu- andDennyZhou. 2022. Chain-of-thoughtprompt-
ralLanguageProcessing,pages2383–2392,Austin, ing elicits reasoning in large language models. In
Texas.AssociationforComputationalLinguistics. AdvancesinNeuralInformationProcessingSystems,
volume35,pages24824–24837.CurranAssociates,
Vikas Raunak, Arul Menezes, and Marcin Junczys-
Inc.
Dowmunt.2021. Thecuriouscaseofhallucinations
in neural machine translation. In Proceedings of Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie
the2021ConferenceoftheNorthAmericanChap- Fu, Junxian He, and Bryan Hooi. 2023. Can llms
teroftheAssociationforComputationalLinguistics: express their uncertainty? an empirical evaluation
HumanLanguageTechnologies,pages1172–1183, of confidence elicitation in llms. arXiv preprint
Online.AssociationforComputationalLinguistics. arXiv:2306.13063.
Nils Reimers and Iryna Gurevych. 2019. Sentence- ZhilinYang,PengQi,SaizhengZhang,YoshuaBengio,
BERT:SentenceembeddingsusingSiameseBERT- WilliamCohen,RuslanSalakhutdinov,andChristo-
networks. InProceedingsofthe2019Conferenceon pher D. Manning. 2018. HotpotQA: A dataset for
EmpiricalMethodsinNaturalLanguageProcessing diverse, explainablemulti-hopquestionanswering.
10In Proceedings of the 2018 Conference on Empiri-
calMethodsinNaturalLanguageProcessing,pages
2369–2380,Brussels,Belgium.AssociationforCom-
putationalLinguistics.
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran,
Thomas L Griffiths, Yuan Cao, and Karthik
Narasimhan. 2023a. Tree of thoughts: Deliberate
problemsolvingwithlargelanguagemodels. arXiv
preprintarXiv:2305.10601.
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak
Shafran, Karthik R Narasimhan, and Yuan Cao.
2023b. React: Synergizing reasoning and acting
inlanguagemodels. InTheEleventhInternational
ConferenceonLearningRepresentations.
ZhitaoYing,JiaxuanYou,ChristopherMorris,Xiang
Ren,WillHamilton,andJureLeskovec.2018. Hier-
archicalgraphrepresentationlearningwithdifferen-
tiablepooling. InAdvancesinNeuralInformation
ProcessingSystems,volume31.CurranAssociates,
Inc.
WangchunshuZhou,YuchenEleanorJiang,PengCui,
TiannanWang,ZhenxinXiao,YifanHou,RyanCot-
terell, and Mrinmaya Sachan. 2023. Recurrentgpt:
Interactivegenerationof(arbitrarily)longtext. arXiv
preprintarXiv:2305.13304.
11A DatasetSummaryStatistics
Table3presentsacomparisonoftheFEVER,Open-SQuAD,andHotPotQAdatasetsacrossnineevaluated
categories in our experiments. For each category, we assess the total number of instances, as well as
the maximum, minimum, and median lengths of questions, in addition to calculating the mean and
standard deviation for question lengths. It is noted that the question lengths in all three categories of
theOpen-SQuADdatasetaregenerallyshortercomparedtotheequivalentcategoriesintheFEVERand
HotPotQAdatasets. Furthermore,the“Long”and“Medium”categoriesexhibitlargerstandarddeviations
inquestionlengthacrossallthreedatasetswhencomparedtothe“Short”categories.
Dataset Sentence Split Numberof Maximum Minimum Median Mean Standard
Length Examples Length Length Deviation
Train 1619 125 38 40 44.33 12.89
Long Dev 113 57 37 38 39.22 3.58
Test 113 53 39 41 42.33 3.24
Train 2182 37 24 27 27.51 2.82
Medium Dev 150 36 24 27 27.49 2.63
Test 150 37 24 27 27.81 2.90
Train 2182 23 21 23 22.81 0.40
Short Dev 150 23 21 23 22.81 0.41
Test 150 23 22 23 22.76 0.43
Train 1174 60 22 23 24.42 3.18
Long Dev 121 36 22 24 24.55 2.86
Test 118 34 23 24 25.02 2.55
Train 1181 21 6 11 11.26 3.29
Medium Dev 133 20 6 11 11.41 3.29
Test 159 19 6 11 11.53 3.34
Train 1181 5 1 5 4.72 0.57
Short Dev 133 5 4 5 4.83 0.38
Test 159 5 3 5 4.79 0.47
Train 1504 128 58 66 69.46 10.96
Long Dev 168 120 59 66 69.12 10.31
Test 137 57 34 36 37.66 3.98
Train 1628 57 10 17 19.49 8.33
Medium Dev 181 58 10 18 20.23 9.80
Test 148 33 10 17 17.71 5.43
Train 1628 9 4 9 8.43 0.91
Short Dev 181 9 5 9 8.43 0.90
Test 148 9 7 9 8.57 0.65
Table3: SummarystatisticsacrossthreedatasetsFEVER,Open-SQuAD,andHotPotQAandninecategories
B DatasetExamplesandExamination
B.1 FEVERDataExamplesandExamination
The FEVER dataset necessitates that the model gathers relevant background information or context
regardingthesubject,suchasknowingwhattheBoeing767isasstatedintheclaim“TheBoeing767
became the most frequently used airliner for transatlantic flights between North America and Europe
inthe1990s”(Table4). Subsequently,itisrequiredtoconductlogicalanalysisonallthespecificfacts
collected. Claims that are longer typically require the accumulation of more facts and knowledge, as
wellastheundertakingofmoresophisticatedreasoning. Asaresult,thecomplexityofaclaimisoften
proportionaltoitslength.
12
REVEF
DAuQS-nepO
AQtoPtoHSentence Claim Answer
Length
The Boeing 767 became the most frequently used airliner SUPPORTS
fortransatlanticflightsbetweenNorthAmericaandEurope
inthe1990s.
Long
In Kentucky, the electric chair has been kept in operation REFUTES
exceptforthosewhosecapitalcrimeswerecommittedprior
toMarch31,1998,andwhochooseelectrocution.
The House of the Spirits is about the life of a young lady REFUTES
namedClaraduringthemilitarydictatorshipinAlgeria.
One Flew Over the Cuckoo’s Nest won the five major NOTENOUGHINFO
AcademyAwardstheyearitwasreleased,thesecondfilm
todoso.
In2012,SimiValley,California,reportedahighermedian SUPPORTS
householdincomethanthatofthenationoverall.
PlanetHollywoodLasVegasisoperatedbyallentitiesexcept REFUTES
anAmericangamingcorporation.
ChrisBoshplaysintheNationalBasketballAssociationas SUPPORTS
Medium
aprofessionalbasketballplayer.
Pierce County, Washington is the location of the lowest NOTENOUGHINFO
mountaininWashington.
The Airbus A380 entered commercial service on October REFUTES
25,2017.
TheNobelPrizeinChemistrywasawardedtoapersonfrom SUPPORTS
theKingdomoftheNetherlands.
Estoniaisacountry. SUPPORTS
EdwardCullenwascreated. NOTENOUGHINFO
Short
Dopaminepreventsneuromodulation. REFUTES
Backingvocalistsareperformers. SUPPORTS
Reanimationisabook. NOTENOUGHINFO
Table4: FEVERdataexamples
B.2 Open-SQuADDataExamplesandExamination
AsdemonstratedinTable5oftheOpen-SQuADdataset,thebulkofquestionsarefocusedon“What”,
“How”, “When”, and “Why”, requiring the accumulation of factual data for answers. Additionally,
questions of medium and short length typically need the collection of one or two specific pieces of
informationorknowledge. Forinstance,thequestion“InwhatgeographicalportionofWalesisAbercynon
located?” necessitatesidentifyingthespecificlocationofAbercynonwithinWales. Notably,medium-
length questions tend to offer more context for information retrieval compared to those in the “Short”
category, such as “What is septicemia?”. Thus, the inclusion of “Short” category questions in Open-
SQuADdoesn’tsuggesttheyareeasytoanswer,especiallyformodelsthatfinditchallengingtogather
factual data. Conversely, “Long” category questions usually demand more extensive fact-finding and
13complexreasoning.
Sentence Question Answer
Length
WhatwasthenumberoftimestheDenverBroncosplayed eight
inaSuperBowlbythetimetheyreachedSuperBowl50?
Whatistheapplicationofprimenumbersusedininforma- public-key cryptogra-
Long
tion technology which utilizes the fact that factoring very phy
largeprimenumbersisverychallenging?
WhendidtheUMC’sGeneralBoardofChurchandSociety 2011and2012
call on all United Methodists to abstain from alcohol for
Lent?
Whatistheminimumdistancebetweenapatient’shomeand morethan4kilometers
thenearestpharmacythatallowsaphysicianinAustriato
giveoutmedicine?
Approximatelyhowmanynamesweresignedonanonline over5,100
petition on the Parliamentary website in response to the
closingoftheMusicalInstrumentsgallery?
InwhatgeographicalportionofWalesisAbercynonlocated? south
HowlonghastheDoctorWhoMagazinebeenincirculation? since1979
Medium
WhatsocialconstructdidHuguenotrefugeesinCanterbury economicseparation
practice?
WhywereJohannEschandHeinrichVoesexecutedbythe forLutheranviews
CatholicChurch?
WhowasthefirstknownEuropeantovisitChinaandreturn? MarcoPolo
Whatissepticemia? atypeof“bloodpoison-
ing”
WhatshapearePlastoglobuli? sphericalbubbles
Short
Whatdocarotenoidsabsorb? lightenergy
Whatisaprasinophyte? a green algal derived
chloroplast
WhatwasAppleTalk a proprietary suite of
networking protocols
developedbyAppleInc
Table5: Open-SQuADdataexamples
B.3 HotPotQADataExamplesandExamination
HotPotQA questions typically demand from the model not only the skill to accumulate factual data
but,moreimportantly,thecapacityformulti-hopcomprehensionandreasoning,particularlywithlong
questions. Forinstance,toanswerthequestion(refertoTable6),“Whatisthegenusoftheviraldisease
thathassymptomssuchasfever,chills,lossofappetite,nausea,musclepains,andheadaches,andhasa
chanceofcausingliverdamage?” themodelisrequiredtoinitiallyidentifydetailsabout“theviraldisease
14thathassymptomssuchasfever,chills,lossofappetite,nausea,musclepains,andheadaches”alongside
informationon“theviraldiseasethathasachanceofcausingliverdamage”,beforedeterminingthegenus
ofthevirusinquestion. Therefore,thedegreeofcomplexityforaHotPotQAquestionoftencorrelates
withitslength.
Sentence Question Answer
Length
OutoftwoAmericancoloniesthathadaseriesofskirmishes ProvinceofNewYork
and raids between 1701 and 1765 at the disputed border,
whichBritishproprietarycolonybecamearoyalcolonyon
Long thenortheastcoastofNorthAmerica?
Which Captain launched the attack which led to more ca- CaptainJohnUnderhill
sualtiesthananyotherincidentinthewarfoughtbetween
thesettlersofthenascentcolonyofNewNetherlandandthe
nativeLenapepopulation?
Lost Kingdom Adventure is a dark ride located at four LegolandBillund
Legolandthemeparks,includingwhichpark,whichisthe
originalLegolandpark,thatwasopenedonJune7th,1968?
What is the genus of the viral disease that has symptoms Flavivirus
suchasfever,chills,lossofappetite,nausea,musclepains,
andheadaches,andhasachanceofcausingliverdamage?
UntilwhatyeardidtheChiefofJusticeoftheSupremeCourt 1864
thatadministeredthepresidentialoathofofficetoAbraham
Lincolnonhisfirstinaugurationasthe16thPresidentofthe
UnitedStatesholdthatoffice?
The Last Run is a drama film that stars which Lithuanian- VytoRuginis
Americanactor?
WhatpartofAustraliaisAliceRiverandRupertswoodin? Victoria
Medium
WhatwasthenationalityofthecomposerofChaconneinF German
minor?
WhatwasthebreakthroughroleoftheactorstarringinGood TaiFrasierin“Clueless”
Boy! andwasanativeofAtlanta?
WhoplayedtheroleofNettieHarrisinthe1985filmdirected Akosua Gyamama Bu-
byStevenSpielberg? sia
WhatempirewasAlekseiGenborninto? RussianEmpire
RomansstarswhichTamilandTeluguactress? NivethaThomas
Short
AreAriUpandBozBurrellbothguitarists? no
AreTetrastigmaandSprucebothtypesofplants? yes
WhatdidKaranKapoor’smaternalgrandfatherdeliver? Shakespeare perfor-
mances
Table6: HotPotQAdataexamples
15C PromptandResponseExamples
C.1 PromptandResponseofthe“Plan”Procedure
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PROMPT ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
...................................user...................................
Sketch a plan to answer the following question with the provided context. List only
(cid:44)→ the essential steps which can be answered by search engines. Express each
(cid:44)→ step as a standalone search question. Highlight interdependencies if any.
(cid:44)→ Higher number steps can depend on lower number steps, while the reverse is
(cid:44)→ not possible.
---
Follow the following format.
Context:
${sources that may contain relevant content. e.g., [1] Passage 1. [2] Passage 2.
(cid:44)→ [3] Passage 3.}
Question: ${the question to be answered}
Plan:
Step 1: ${a standalone search question. e.g., ...?} Step 2: ${a standalone search
(cid:44)→ question. e.g., ...?} ... Step n: ${a standalone search question. e.g.,
(cid:44)→ ...?}
Dependencies: ${interdependencies among multiple steps. e.g., Step ... depends on
(cid:44)→ Step ... .}
---
Context:
[1] Steve Masiello | (born September 2, 1977) is an American college basketball
(cid:44)→ coach and a former player. He most recently served as men's head coach at
(cid:44)→ Manhattan College.
[2] Jaspers' new coach hopes to recapture MC's past glory | Manhattan College
(cid:44)→ introduced Steve Masiello, center, who will take over as the Jaspers' new
(cid:44)→ men's basketball coach.
[3] Steve Masiello (St. John's Red Storm) | Steve Masiello (born September 2, 1977)
(cid:44)→ . Current position: Associate head men's basketball coach. Current team: St.
(cid:44)→ John's Red Storm (Head ...
Question: Which of the Manhattan Jaspers basketball team head coach was born in
(cid:44)→ September 2, 1977?
Plan:
Step 1: Who is the head coach of the Manhattan Jaspers basketball team? Step 2:
(cid:44)→ When was the head coach born?
Dependencies: Step 2 depends on Step 1.
16---
Context:
[1] Phil Cutchin | Phil Cutchin (September 9, 1920 - January 7, 1999) was an
(cid:44)→ American football player and coach. He served as the head football coach at
(cid:44)→ Oklahoma State ...
[2] Former OSU Football Coach Cutchin Dies | In life, Phil Cutchin captained a Paul
(cid:44)→ "Bear" Bryant football team, was an Army officer in two wars, a football
(cid:44)→ coach and a stock broker.
[3] Phil Cutchin | American Football Database | Fandom | Phil Cutchin (September 9,
(cid:44)→ 1920 - January 7, 1999) was an American football player and coach. He
(cid:44)→ served as the head football coach at Oklahoma State ...
Question: Coach Phil Cutchin served as the head football coach at Oklahoma State-
(cid:44)→ University-Stillwater, which was originally known as what?
Plan:
Step 1: What was Oklahoma State University-Stillwater originally known as? Step 2:
(cid:44)→ When did Phil Cutchin serve as the head football coach at Oklahoma State
(cid:44)→ University-Stillwater?
Dependencies: Step 2 depends on Step 1.
---
Context:
Todd Boehly | Todd Boehly is an American businessman and investor. He is the co-
(cid:44)→ founder, chairman, chief executive officer and controlling member of
(cid:44)→ Eldridge Industries, ...
Question: What was Todd Boehly's former position at the firm where Mark Walter is
(cid:44)→ the CEO?
Plan:
----------------------------------- RESPONSE -----------------------------------
----------------------------------- CHOICE 0 -----------------------------------
...................................assistant...................................
Step 1: What is the name of the firm where Mark Walter is the CEO? Step 2: What was
(cid:44)→ Todd Boehly's former position at the firm where Mark Walter is the CEO?
Dependencies: Step 2 depends on Step 1.
C.2 PromptandResponseofthe“Self-reflect”Procedure
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PROMPT ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
...................................user...................................
Highlight interdependencies among the steps below if any. Higher number steps can
(cid:44)→ depend on lower number steps, while the reverse is not possible.
---
Follow the following format.
17Plan:
Step 1: ${a standalone search question. e.g., ...?} Step 2: ${a standalone search
(cid:44)→ question. e.g., ...?} ... Step n: ${a standalone search question. e.g.,
(cid:44)→ ...?}
Dependencies: ${interdependencies among multiple steps. e.g., Step ... depends on
(cid:44)→ Step ... .}
---
Plan:
Step 1: Who is the head coach of the Manhattan Jaspers basketball team? Step 2:
(cid:44)→ When was the head coach born?
Dependencies: Step 2 depends on Step 1.
---
Plan:
Step 1: What was Oklahoma State University-Stillwater originally known as? Step 2:
(cid:44)→ When did Phil Cutchin serve as the head football coach at Oklahoma State
(cid:44)→ University-Stillwater?
Dependencies: Step 2 depends on Step 1.
---
Plan:
Step 1: What is the name of the firm where Mark Walter is the CEO? Step 2: What was
(cid:44)→ Todd Boehly's former position at the firm where Mark Walter is the CEO?
Dependencies:
----------------------------------- RESPONSE -----------------------------------
----------------------------------- CHOICE 0 -----------------------------------
...................................assistant...................................
Step 2 depends on Step 1.
C.3 PromptandResponseofthe“Formalize”Procedure
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PROMPT ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
...................................user...................................
Express the dependencies in formal language by giving the descriptions below.
---
Follow the following format.
Descriptions: ${descriptions of dependencies}
Dependencies: ${e.g., If Step 2 depends on Step 1, then write Step 1 -> Step 2; If
(cid:44)→ Step 2 and Step 3 depend on Step 1, then write Step 1 -> (Step 2 and Step 3)
(cid:44)→ ; If Step 3 depends on Step 1 and Step 2, then write (Step 1 and Step 2) ->
18(cid:44)→ Step 3}
---
Descriptions: Step 2 depends on Step 1.
Dependencies:
----------------------------------- RESPONSE -----------------------------------
----------------------------------- CHOICE 0 -----------------------------------
...................................assistant...................................
Step 1 -> Step 2
C.4 PromptandResponseofthe“Rewrite”Procedure
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PROMPT ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
...................................user...................................
Rewrite the last question in a standalone manner by giving the answers to previous
(cid:44)→ questions. Do not consider answers that were not specified. Only show the
(cid:44)→ last question after the rewrite.
---
Follow the following format.
Context:
${previous questions and answers}
Rewrite: ${the last question after the rewrite}
---
Context:
Step 1: Who is the head coach of the Manhattan Jaspers basketball team? ANSWER:
(cid:44)→ John Gallagher. Step 2: When was the head coach born?
Rewrite: When was the head coach of the Manhattan Jaspers basketball team born?
---
Context:
Step 1: What was Oklahoma State University-Stillwater originally known as? ANSWER:
(cid:44)→ Oklahoma Agricultural and Mechanical College. Step 2: When did Phil Cutchin
(cid:44)→ serve as the head football coach at Oklahoma State University-Stillwater?
Rewrite: When did Phil Cutchin serve as the head football coach at Oklahoma State
(cid:44)→ University-Stillwater?
---
Context:
Step 1: What is the name of the firm where Mark Walter is the CEO? ANSWER:
(cid:44)→ Guggenheim Partners. Step 2: What was Todd Boehly's former position at the
(cid:44)→ firm where Mark Walter is the CEO?
19Rewrite:
----------------------------------- RESPONSE -----------------------------------
----------------------------------- CHOICE 0 -----------------------------------
...................................assistant...................................
What was Todd Boehly's former position at Guggenheim Partners?
C.5 PromptandResponseofthe“Predict”Procedure
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PROMPT ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
...................................user...................................
Answer questions with short factoid answers.
---
Follow the following format.
Context:
${sources that may contain relevant content. e.g., [1] Passage 1. [2] Passage 2.
(cid:44)→ [3] Passage 3.}
Question: ${the question to be answered}
Rationale: Let's think step by step. ${a step-by-step deduction that identifies the
(cid:44)→ correct response, which will be provided below. Every statement in the "
(cid:44)→ Rationale" section should be attributable to the passages provided in the "
(cid:44)→ Context" section. e.g., ...[1][2].}
Answer: ${a short factoid answer, often between 1 and 5 words}
---
Context:
[1] List of Manhattan Jaspers men's basketball head coaches | Manhattan's current
(cid:44)→ head coach is John Gallagher. He was hired in March 2023, replacing RaShawn
(cid:44)→ Stores, who was not promoted to the full-time position after ...
[2] Steve Masiello | Stephen John Masiello Jr. (born September 2, 1977) is an
(cid:44)→ American college basketball coach and a former player. He most recently
(cid:44)→ served as men's head coach ...
[3] Steve Masiello | (born September 2, 1977) is an American college basketball
(cid:44)→ coach and a former player. He most recently served as men's head coach at
(cid:44)→ Manhattan College.
[4] Manhattan College Appoints John Gallagher to Lead Men's ... | - John Gallagher
(cid:44)→ has been named the new Head Men's Basketball Coach at Manhattan College, it
(cid:44)→ was announced today by Director of Athletics ...
[5] List of Manhattan Jaspers men's basketball head coaches | Manhattan's current
(cid:44)→ head coach is John Gallagher. He was hired in March 2023, replacing RaShawn
(cid:44)→ Stores, who was not promoted to the full-time position after ...
[6] Jaspers' new coach hopes to recapture MC's past glory | Manhattan College
(cid:44)→ introduced Steve Masiello, center, who will take over as the Jaspers' new
(cid:44)→ men's basketball coach.
20[7] Men's Basketball Coaches | Head Coach, 718-862-7533 718-862-7533 .
(cid:44)→ jgallagher06@manhattan.edu, First Year ; Assistant Coach, 718-862-7533
(cid:44)→ 718-862-7533 . tim.brooks@manhattan.edu, First ...
Question: Which of the Manhattan Jaspers basketball team head coach was born in
(cid:44)→ September 2, 1977?
Rationale: Let's think step by step. Steve Masiello was born on September 2, 1977
(cid:44)→ [2][3]. John Gallagher is the current head coach of the Manhattan Jaspers
(cid:44)→ basketball team [1][4][5].
Answer: Steve Masiello
---
Context:
[1] Oklahoma Agricultural and Mechanical College | Oklahoma Agricultural and
(cid:44)→ Mechanical College, Founded on Christmas Day in 1890 under the Morrill Act
(cid:44)→ as Oklahoma Agricultural and Mechanical College, Oklahoma State University
(cid:44)→ has grown through its traditions and culture to become one of America's
(cid:44)→ premier land-grant universities., Oklahoma Agricultural and Mechanical
(cid:44)→ College
[2] Oklahoma State University-Stillwater | OSU was founded in 1890 under the
(cid:44)→ Morrill Act. Originally known as Oklahoma Agricultural and Mechanical
(cid:44)→ College (Oklahoma A&M), it is the flagship institution ...
[3] 1963 to 1968 | 1963 to 1968, Phil Cutchin (September 9, 1920 - January 7, 1999)
(cid:44)→ was an American football player and coach. He served as the head football
(cid:44)→ coach at Oklahoma State University-Stillwater from 1963 to 1968, compiling a
(cid:44)→ record of 19-38-2., 1963 to 1968
[4] Former OSU Football Coach Cutchin Dies | Cutchin was head football coach at
(cid:44)→ Oklahoma State from 1963 to 1968. He won only 19 games, but most all of his
(cid:44)→ 40 defeats were given up ...
[5] Phil Cutchin | Phil Cutchin (September 9, 1920 - January 7, 1999) was an
(cid:44)→ American football player and coach. He served as the head football coach at
(cid:44)→ Oklahoma State ...
[6] OSU History | The college's first students attended classes in the Stillwater
(cid:44)→ Congregational Church. The original campus consisted of 200 acres of prairie
(cid:44)→ that were ...
[7] Phil Cutchin | American Football Database | Fandom | He served as the head
(cid:44)→ football coach at Oklahoma State University-Stillwater from 1963 to 1968,
(cid:44)→ compiling a record of 19-38-2. Although he never had a winning ...
Question: Coach Phil Cutchin served as the head football coach at Oklahoma State-
(cid:44)→ University-Stillwater, which was originally known as what?
Rationale: Let's think step by step. Oklahoma Agricultural and Mechanical College
(cid:44)→ [1][2].
Answer: Oklahoma Agricultural and Mechanical College
---
21Context:
[1] Unions file lawsuit challenging Wisconsin Act 10 | Former Republican Gov. Scott
(cid:44)→ Walker signed the law in 2011 despite some of the largest protests in state
(cid:44)→ history, and the law has since shaped the state's political landscape.,
(cid:44)→ Scott Walker
[2] Act 10 turns 10: Four takeaways from the law that shook ... | Here's a look at
(cid:44)→ how the law limiting collective bargaining for most public workers has
(cid:44)→ played out.
[3] Act 10 turns 10: Four takeaways from the law that shook ... | Act 10 ended the
(cid:44)→ ability of public-sector unions to negotiate over any issues other than
(cid:44)→ raises, and those raises were capped at the rate of ...
[4] Wisconsin Teachers Sue to Restore Collective Bargaining ... | The law, which
(cid:44)→ was championed by former Republican Gov. Scott Walker, has been challenged
(cid:44)→ unsuccessfully in court before. But the political context has changed: The
(cid:44)→ Wisconsin Supreme Court recently flipped to liberal control for the first
(cid:44)→ time in 15 years., Scott Walker
[5] Wis. governor officially cuts collective bargaining | Scott Walker has
(cid:44)→ officially taken away nearly all collective bargaining rights from the vast
(cid:44)→ majority of the state's public employees. Walker ...
[6] 10 years later, Wisconsinites are still divided over Act 10 | Former Gov. Scott
(cid:44)→ Walker's landmark legislation required public employees to pay more for
(cid:44)→ their pensions and health care and limited their ...
[7] Wisconsin's Act 10 limitations on collective bargaining | With its 5-2 vote
(cid:44)→ upholding the law, the Wisconsin Supreme Court gave an important nod towards
(cid:44)→ the constitutionality of limits of collective bargaining rights ...
Question: Which Wisconsin state governor oversaw a vote to significantly limit
(cid:44)→ public employee collective bargaining?
Rationale: Let's think step by step. Former Republican Governor Scott Walker
(cid:44)→ oversaw a vote to significantly limit public employee collective bargaining
(cid:44)→ [1][4][5][6][7].
Answer: Scott Walker
---
Context:
[1] Mark Walter | 184 Mark Walter on the 2023 Forbes 400 - Mark Walter is CEO of
(cid:44)→ investment firm Guggenheim Partners, which has over $300 billion in assets
(cid:44)→ under management.
[2] Todd Boehly - Milken Institute | Boehly was the President of Guggenheim
(cid:44)→ Partners. He received his B.B.A. from the College of William & Mary, where
(cid:44)→ he later founded the Boehly Center for Excellence in Finance, and studied at
(cid:44)→ the London School of Economics., President
[3] Katie & Todd Boehly | Prior to founding Eldridge Industries, Todd was President
(cid:44)→ of Guggenheim Partners and founded the credit business at Guggenheim. He
(cid:44)→ received his B.B.A. from The College of William & Mary, where he later
(cid:44)→ founded The Boehly Center for Excellence in Finance, and studied at the
(cid:44)→ London School of Economics., Prior to founding Eldridge Industries, Todd was
(cid:44)→ President of Guggenheim Partners and founded the credit business at
(cid:44)→ Guggenheim
22[4] Katie & Todd Boehly | Prior to founding Eldridge Industries, Todd was President
(cid:44)→ of Guggenheim Partners and founded the credit business at Guggenheim.,
(cid:44)→ President of Guggenheim Partners
[5] Guggenheim Partners | Guggenheim Partners, In 2000, he helped found Guggenheim
(cid:44)→ Partners. Today, he is the CEO of Guggenheim Partners, which has rapidly
(cid:44)→ grown into a global, diversified financial services firm with more than $260
(cid:44)→ billion in assets under management, 2,300 employees, and 25 offices in six
(cid:44)→ countries around the world., Guggenheim Partners
[6] Todd Boehly | Todd Boehly cofounded holding company Eldridge in 2015, after
(cid:44)→ building Guggenheim Partners' credit business and serving as president.
(cid:44)→ Boehly acquired some ...
[7] Todd L. Boehly | Boehly was President of Guggenheim Partners and founded the
(cid:44)→ credit business at Guggenheim. He received his B.B.A. from The College of
(cid:44)→ William & Mary, where ...
Question: What was Todd Boehly's former position at the firm where Mark Walter is
(cid:44)→ the CEO?
Rationale: Let's think step by step.
----------------------------------- RESPONSE -----------------------------------
----------------------------------- CHOICE 0 -----------------------------------
...................................assistant...................................
Todd Boehly was the President of Guggenheim Partners [2][3][4][6][7].
Answer: President
----------------------------------- CHOICE 1 -----------------------------------
...................................assistant...................................
Todd Boehly was the President of Guggenheim Partners [2][3][4][6][7].
Answer: President
----------------------------------- CHOICE 2 -----------------------------------
...................................assistant...................................
Todd Boehly was the President of Guggenheim Partners [2][3][4][6][7].
Answer: President
----------------------------------- CHOICE 3 -----------------------------------
...................................assistant...................................
Todd Boehly was the President of Guggenheim Partners [2][3][4][6][7].
Answer: President
----------------------------------- CHOICE 4 -----------------------------------
...................................assistant...................................
Todd Boehly was the President of Guggenheim Partners [2][3][4][7].
Answer: President
----------------------------------- CHOICE 5 -----------------------------------
...................................assistant...................................
Todd Boehly was the President of Guggenheim Partners [2][3][4][7].
Answer: President
----------------------------------- CHOICE 6 -----------------------------------
...................................assistant...................................
23Todd Boehly was the President of Guggenheim Partners [2][3][4][6][7].
Answer: President
----------------------------------- CHOICE 7 -----------------------------------
...................................assistant...................................
Todd Boehly was the President of Guggenheim Partners [2][3][4][6][7].
Answer: President
----------------------------------- CHOICE 8 -----------------------------------
...................................assistant...................................
Todd Boehly was the President of Guggenheim Partners [2][3][4][6][7].
Answer: President
----------------------------------- CHOICE 9 -----------------------------------
...................................assistant...................................
Todd Boehly was the President of Guggenheim Partners [2][3][4][6][7].
Answer: President
----------------------------------- CHOICE 10 -----------------------------------
...................................assistant...................................
Todd Boehly was the President of Guggenheim Partners [2][3][4][6][7].
Answer: President
----------------------------------- CHOICE 11 -----------------------------------
...................................assistant...................................
Todd Boehly was the President of Guggenheim Partners [2][3][4][7].
Answer: President
----------------------------------- CHOICE 12 -----------------------------------
...................................assistant...................................
Todd Boehly was the President of Guggenheim Partners [2][3][4][6][7].
Answer: President
----------------------------------- CHOICE 13 -----------------------------------
...................................assistant...................................
Todd Boehly was the President of Guggenheim Partners [2][3][4][6][7].
Answer: President
----------------------------------- CHOICE 14 -----------------------------------
...................................assistant...................................
Todd Boehly was the President of Guggenheim Partners [2][3][4][6][7].
Answer: President
----------------------------------- CHOICE 15 -----------------------------------
...................................assistant...................................
Todd Boehly was the President of Guggenheim Partners [2][3][4][6][7].
Answer: President
----------------------------------- CHOICE 16 -----------------------------------
...................................assistant...................................
Todd Boehly was the President of Guggenheim Partners [2][3][4][7].
24Answer: President
----------------------------------- CHOICE 17 -----------------------------------
...................................assistant...................................
Todd Boehly was the President of Guggenheim Partners [2][3][4][6][7].
Answer: President
----------------------------------- CHOICE 18 -----------------------------------
...................................assistant...................................
Todd Boehly was the President of Guggenheim Partners [2][3][4][6][7].
Answer: President
----------------------------------- CHOICE 19 -----------------------------------
...................................assistant...................................
Todd Boehly was the President of Guggenheim Partners [2][3][4][6][7].
Answer: President
----------------------------------- ANSWER -----------------------------------
President
----------------------------------- CONFIDENCE -----------------------------------
1.0
D AutomatedAnnotatedDemonstrations
FollowingDSP(Khattabetal.,2022),ademonstrationisdefinedasatrainingexamplecraftedtoillustrate
particularbehaviorsexpectedfromtheLLM.Aqualifyingexampleofsuchademonstrationoccurswhen
themodel’spredictionforthisexamplealignswiththeactualcorrectanswer. WeextendDSP’sapproach
byincorporatingadditionalconsiderationsintotheautomatedcreationofdemonstrations.
Intheautomatedcreationofdemonstrationsforuseinthe“Probe”and“Infer”procedures,weadjust
citationmarksusingregularexpressions. Weemploytheregularexpression (\[[0-9]+\])+ toidentify
citation marks and ensure they are placed at the end of each sentence or statement, if they are not
already. Toverifythatallsentencesorstatementsadheretothisformat,weusetheregularexpression
^([^\[\.]+(\[[0-9]+\])*\.)+$. Thisstandardizedformataidsinaccuratelytallyingthetotalcount
ofcitedpassages.
For demonstrations intended for the “Plan” procedure, we select pre-
mium dependency rules utilizing regular expressions. The regular expression
None|((\s*([Ss]tep [0-9]+) depends on ([Ss]tep [0-9]+)\.\s*)+) is used to ensure
that dependencies in the dependency graph, generated by LLM, conform to a particular format. This
assistsinthepreciseidentificationoftheserelationships.
During our observations in automated annotated demonstrations for the “Plan” procedure, we have
noticed that overly long sub-queries or steps produced by LLM often erroneously repeat the original,
more complex question, deviating from the divide-and-conquer strategy of breaking down a complex
questionintosmallersub-queries. Toaddressthis,weimplementtheoutlierdetectionmethodknownas
theinterquartilerange(IQR)toidentifyanddisqualifyanyexcessivelylongsub-queryorstep.
Inselectingdemonstrationsforaprompt,weutilizetwodifferentapproaches: balancedsamplingandk
nearestneighbors(KNN).Balancedsamplinginvolvesrandomlyselectingfromtrainingexampleswhile
makingsuretomaintainanevendistributionofanswers(classes). KNN,ontheotherhand,makesuseof
sentencerepresentations4 toidentifyandselectthektrainingexamplesclosesttotheinputquestion(or
claim,asinthecaseofFEVER).ThisapproachwasinvestigatedbyLiuetal.(2022).
4https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2
25E Baselines
Ourbenchmarkingencompassesfivemethods: “VanillaLM”asoutlinedbyBrownetal.(2020),“Retrieve-
then-Read” as discussed in the works of Lazaridou et al. (2022) and Izacard et al. (2022), “Self-ask”
introducedbyPressetal.(2022),“ReAct”describedbyYaoetal.(2023b),and“Demonstrate-Search-
Predict”(DSP)presentedbyKhattabetal.(2022).
• VanillaLM:The“VanillaLM”baselinesemploythefew-shotin-contextlearningapproachasproposed
byBrownetal.(2020). Thesebasicbenchmarksdon’tengageinretrievingtextpassagespertinentto
theinputquery.
• Retrieve-then-Read: The“Retrieve-then-Read”benchmarksutilizetheRetrievalModel(RM)tosupport
each instance with a possibly relevant text passage prior to presenting the prompt to the Language
Model(LM).
• Self-ask: The“Self-ask”baselinesinvolvetheLMposingadditional“follow-upquestions”thatarethen
directedtoaretrievalmodel. AdheringtoKhattabetal.(2022),wealtertheSelf-ask’spromptdesignby:
(i)mergingfew-shottraininginstancesfromthetask,suchasquestion-answerpairs,atthebeginningof
theprompt,(ii)instructingthemodeltoproduceabriefinitialanswerateachretrievalphase,and(iii)
specificallycommandingthemodeltogenerateasubsequent“searchquery”ateachstage.
• ReAct: The ReAct method utilizes LLMs to concurrently create reasoning traces and task-specific
actions. We test ReAct using the “text-davinci-002” backbone LLM, focusing on the FEVER and
HotPotQAdatasets. However,theReActprojecthasnotincorporatedtheOpen-SQuADdatasetandthe
“gpt-3.5-turbo-1106”backboneLLM,thusthesehavenotbeensubjectedtoevaluation.
• Demonstrate-Search-Predict(DSP):TheDSPmethodinitiatespipeline-awaredemonstrations,seeksout
relatedpassages,andcreatespredictionsrootedinevidence. FollowingKhattabetal.(2022),weutilize
randomsamplingtoselectandannotateexamples,andthenemploythemasdemonstrations.
26F ExtendedAblationStudy
α β γ w w w EM F1
1 2 3
0.1 0.45 0.45 0.15 0.55 0.3 25.16 36.55
0.1 0.45 0.45 0.2 0.55 0.25 27.04 39.34
0.1 0.45 0.45 0.3 0.5 0.2 24.53 35.20
0.1 0.45 0.45 0.3 0.6 0.1 25.16 35.35
0.1 0.45 0.45 1 0 0 22.64 34.15
0.2 0.4 0.4 0.15 0.55 0.3 25.16 36.55
0.2 0.4 0.4 0.2 0.55 0.25 31.45 42.17
0.2 0.4 0.4 0.3 0.5 0.2 27.67 41.44
0.2 0.4 0.4 0.3 0.6 0.1 25.16 35.40
0.2 0.4 0.4 1 0 0 23.90 35.27
0.3 0.35 0.35 0.15 0.55 0.3 23.90 37.03
0.3 0.35 0.35 0.2 0.55 0.25 25.79 36.78
0.3 0.35 0.35 0.3 0.5 0.2 28.30 40.67
0.3 0.35 0.35 0.3 0.6 0.1 25.16 37.23
0.3 0.35 0.35 1 0 0 26.42 38.00
0.4 0.3 0.3 0.15 0.55 0.3 25.16 38.50
0.4 0.3 0.3 0.2 0.55 0.25 25.79 38.37
0.4 0.3 0.3 0.3 0.5 0.2 27.67 41.06
0.4 0.3 0.3 0.3 0.6 0.1 25.79 38.58
0.4 0.3 0.3 1 0 0 23.27 35.46
1 0 0 0.15 0.55 0.3 27.04 39.47
1 0 0 0.2 0.55 0.25 28.30 38.12
1 0 0 0.3 0.5 0.2 24.53 37.02
1 0 0 0.3 0.6 0.1 26.42 35.89
1 0 0 1 0 0 24.53 37.76
Table 7: An elaborate overview of the various hyperparameter combinations being explored, along with their
correspondingEMandF1scores,withinthemedium-lengthcategoryoftheOpen-SQuADdataset.
27