Scaling the Authoring of AutoTutors with Large Language Models
SankalanPalChowdhury VilémZouhar MrinmayaSachan
sankalan.palchowdhury@ethz.ch vilem.zouhar@ethz.ch mrinmaya.sachan@ethz.ch
DepartmentofComputerScience,ETHZürich,Switzerland
MWPTutor GPT4Tutor
Iseeyoursolution.Youseemtohavemadesome Hi!Couldyouwalkmethroughyoursolution?
errors.Howaboutwestartfreshanddoitstepbystep?
I’mnotsurewheretostart.IknowCodywon49ticketsandspent25onabeanie,butIdon’tknowhowto
Okay,I’mnotsurewheretostartthough. figureouthowmanyhehasleft.
Whatshouldbethefirststep? That’sagreatstartingpoint.So,ifCodyhad49ticketsandhespendssomeonabeanie,whatkindof
mathoperationwouldyouusetofindouthowmanyticketshewouldhaveleft?
IthinkCody’sstartingamountoftickets,whichis49,
shouldbethefirststep. Subtraction,Ithink.
Tellmethisinstead:HowmanyticketsdoesCody Exactly,subtractionistherightoperation.CanyoutrysubtractingthenumberofticketsCodyspenton
haveleftafterspending25onabeaniefromhisoriginal49 thebeaniefromthenumberofticketsheinitiallywon?Whatdoyouget?
tickets?
—12moretutorutterances—
Oh,hewouldhave24ticketsleft. 28tickets.
24iscorrect,welldone.Whatisthenextstep? That’scorrect.Now,ifwesubtractanotherticketfromthe28,whatnumberdoweget?
Next,hewon6moretickets,soIthinkweaddthatto 27tickets.
the24healreadyhas.
Yes,that’sright.Andanothertickettakenfrom27?Whatdoesthatleaveuswith?
Okay,canyoudothatcalculation?
26tickets.
Yes,24+6is30,soCodywouldhave30ticketsintotal.
Exactly.Andifwetakeonemoreawayfrom26,wheredoesthatgetus?
30isthecorrectanswertotheproblem.Welldone!!!
Don’thesitatetocontackmeagainifyouhaveanytroubles. 25tickets.
—13moretutorutterances—
Figure1:ApairofrealtutoringconversationswithGPT4andMWPTutor.GPT4doesnothaveanyhigherlevelcontrol,soit
beginstocycleinitstutoring.Asaresult,whileMWPTutortook6tutorutterancestoguidethestudenttothecorrectanswer,
GPT4took29tutorutterancesandthestudentdidnotarriveatthecorrectsolution.
ABSTRACT additionalflexibilityofLLM-basedapproaches.Throughahuman
LargeLanguageModels(LLMs)havefoundseveralusecasesin evaluationstudyontwodatasetsbasedonmathwordproblems,
education,rangingfromautomaticquestiongenerationtoessay we show that our hybrid approach achieves a better overall tu-
evaluation.Inthispaper,weexplorethepotentialofusingLarge toringscorethananinstructed,butotherwisefree-form,GPT-4.
LanguageModels(LLMs)toauthorIntelligentTutoringSystems.A MWPTutoriscompletelymodularandopensupthescopeforthe
commonpitfallofLLMsistheirstrayingfromdesiredpedagogical communitytoimproveitsperformancebyimprovingindividual
strategiessuchasleakingtheanswertothestudent,andingeneral, modulesorusingdifferentteachingstrategiesthatitcanfollow.
providingnoguarantees.WepositthatwhileLLMswithcertain
guardrailscantaketheplaceofsubjectexperts,theoverallpedagog- CCSCONCEPTS
icaldesignstillneedstobehandcraftedforthebestlearningresults. •Human-centeredcomputing→Collaborativeandsocial
Basedonthisprinciple,wecreateasampleend-to-endtutoringsys- computingsystemsandtools;Empiricalstudiesincollabora-
temnamedMWPTutor,whichusesLLMstofillinthestatespace tiveandsocialcomputing;•Appliedcomputing→Computer-
ofapre-definedfinitestatetransducer.Thisapproachretainsthe assistedinstruction;Computer-managedinstruction.
structureandthepedagogyoftraditionaltutoringsystemsthathas
beendevelopedovertheyearsbylearningscientistsbutbringsin
KEYWORDS
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalor Tutoring,mathwordproblems,LargeLanguageModels,AutoTutor,
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed FiniteStateTransducers
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthefirstpage.Copyrightsforcomponentsofthisworkownedbyothersthanthe
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or ACMReferenceFormat:
republish,topostonserversortoredistributetolists,requirespriorspecificpermission SankalanPalChowdhury,VilémZouhar,MrinmayaSachan.2024.Scaling
and/orafee.Requestpermissionsfrompermissions@acm.org.
theAuthoringofAutoTutorswithLargeLanguageModels.InProceedings
©2024Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM.
ACMISBN978-x-xxxx-xxxx-x/YY/MM ofACMConference(Conference’17).ACM,NewYork,NY,USA,15pages.
https://doi.org/10.1145/nnnnnnn.nnnnnnn https://doi.org/10.1145/nnnnnnn.nnnnnnn
4202
beF
41
]LC.sc[
1v61290.2042:viXraSankalanPalChowdhury,VilémZouhar,MrinmayaSachan
1 INTRODUCTION • WedesignMWPTutor,atutorformathwordproblemsbasedon
Computer-based automated tutoring has long been seen as the theaboveprinciples.
methodtoscaleupthebenefitsofexperthumantutoringtomillions • WecomparetheperformanceofMWPTutorwiththatofGPT4
ofstudents,aproblemoriginallyposedbyBloom[3].Ofvarious beingusedasatutorbothquantitativelyandqualitatively.
attemptstodoso,theAutoTutorfamily[18]isperhapsoneofthe
morenotableones.Thisfamilyoftutorssimulatesnaturallanguage
2 BACKGROUND
conversationswithstudentsbasedonpre-definedscripts,aiming
toemulateone-on-onetutoring.WhiletheAutoTutorfamilyhas Tutoringisanintegralpartofteachingwheretheteacherattempts
shownsubstantiallearninggains[18],itisdifficulttoexpanditto to identify confusions or misconceptions a student might have,
differenttopics.Eachexpansionrequiresalotofexpertlaborto andrectifythem.Thisisdoneinawaytominimizetheirfuture
incorporatetherequireddomainknowledgeforeveryconceptin re-occurrence.Bloometal.[3]showedthattutoringisextremely
thecurriculumandappropriateteachingstrategies[14]. importantforeducation,asastudentreceivingone-on-onetutoring
RecentdevelopmentsinLargeLanguageModels(LLMs),suchas canperformmuchbetterthanastudentonlygettinglectures.As
GPT[20],orFlanT5[7],haveopenedupanewvenueforcomputer- opposedtolecturing,tutoringismorepersonalized,andtherefore
basedtutoringwheretheLLMsplaytheroleoftheteacher.While onlyfeasibleinsmallergroups.Thislowerteacher-to-studentra-
previousworkhasshownthesuccessofLLMsfortutoring[2,23] tioneedstobebalancedbyahighernumberoftutors,whichis
thenon-modularblack-boxnatureofthesemodelsmakesitimpos- expensiveandnotalwaysfeasible.
sibletomakeincrementalimprovementsorcontrolthepedagogy
itpursuesinassistingthestudent.Theuninterpretableanduncon-
2.1 Rule-BasedSystems
trollablenatureofLLMsmakesitdifficultforexpertsorteachers
to make changes in their strategy. It is also difficult to develop Tocombattheabovescarcity,IntelligentTutoringSystems(ITSs)
trusttowardssuchmodels,notleastbecausetheymightbeopento werealreadybeingdevelopedsincetheearly1980s[27].Theidea
jailbreakattacks[16]aswellasprivacyconcerns.Finally,thepropri- wastoroleplayahumantutorwithacomputerprogramthatcould
etarynatureofhighlyperformantLLMsmeansthatthetutorneeds interactwiththestudentandfulfilltherequirementofpersonalized
apersistentinternetconnectionandanOpenAIaccounttofunction, tutoring. The computer program may not fully replace human
andwearehighlydependentonOpenAIpolicies.Thiscouldbe tutorsbutoftenprovidesanaffordableandscalableaddition.An
bypassedbyfine-tuningalocalopenLLM,butdoingsoleadsto importantaspectthatdifferentiatesITSsfromsimplyshowingthe
eitherprohibitivelyhighresourcerequirements,orsignificantly studentstheproblemsolutionistheirabilitytoprovidestep-by-
worseperformance(seeFlanT5vsChatGPTin[17]). stepfeedbackwhichpromoteslong-termlearningasopposedto
ThedesignprocessofAutoTutorandothersimilarintelligent short-termproblem-solvingsuccess.Thiswasoftenimplemented
tutoringsystemscanbesplitintotwodistinctstages,carriedout usingrulesthatcheckforcertainerrorsusingstring-matchingand
bydifferent,yetpotentiallyoverlapping,setsofstakeholders.The actonthemwithpre-definedtemplates.Forexample,LISPTutor
firststageisthegeneralframeworkleveldesign,carriedoutmostly [1]contains475rulestoaccountforcommonprogrammingerrors
bylearningscientists(possiblyalongwithcomputerscientists). madebystudents.
Thisincludesdesigningthepedagogy,themechanismsrequiredto WithadvancementsinAI,ITSstransitionedtodialogasamethod
interactwiththestudent,andpotentiallyevenauthoringtools.This oftutoring,movingITSsfrombeinginformation-deliverysystems
istypicallydoneonlyonceforanentiredomain.Thesecondstage, todialog-basedagents.Oneofthekeyplayersinthisfieldwasthe
performedbyeitherteachersordomainexperts,istoauthorthe firstversionofAutoTutor[13],whichreplacedtherulesintradi-
scripts1,whichneedstobedoneseparatelyforeverytopic,question, tionalITSswithafullfinitestatetransducerwhichtheycalledthe
orconcept.Inthestandardframework,boththesestagesaredone DialogAdvancementNetwork.Thisallowsthestudentstointeractin
byhumans.Incontrast,intheLLM-onlyframeworkdiscussedin naturallanguageandthetutorprocessestheirinputsusingmethods
thepreviousparagraph,boththesestagesarecarriedout(implicitly likelatentsemanticanalysisandattemptstorespondusingasetof
orexplicitly)byLLMs. predefinedrules.Overthenexttwodecades,varioustutorssuch
In this paper, we consider a mixed approach where we only astheAutoTutorexploreddifferentdomains,tutoringstrategies,
delegatethejobofdomainexpertstoanLLM,whilethefirststage affectivestatements,etc.tobecomeoneofthemostcomprehensive
isstilllefttolearningexperts.Thisideahaspreviouslybeenhinted ITSs(see[18]forthesummaryofdevelopments).
atbyCaietal.[5],whoproposeusingaquestion-answeringsystem Withconceptsandtutoringstrategiesgettingmorecomplex,
toautomaticallylistpotentialmisconceptionsforagiventopic.We writingtherulesgoverningthefinitestatetransducersquicklybe-
extendthisideatohaveanLLMauthortheentirescriptforthe comestime-consuming.Notknowingthestudentmisconceptions
tutoringsystem,whichisaccurateenoughtobedeployedwithout inadvance,domainexpertshavetocomeupwithrulesfornumer-
humanvalidationbutisfullyopentohumanvalidation. ouspossibilities,introducingadifferentsetofscalingissues.One
Ourcontributionsinthispaperareasfollows: hourofinteractionwithastudentcostsover100hoursofdomain
experttimetoauthortheITS[14].Thisisinadditiontothetime
• WeadapttheDialogBasedtutoringframeworkusedbyITS’sto
spent by learning scientists designing the pedagogy and dialog
makeitpossibleforaLargeLanguageModeltoauthorit.
strategies.However,thisisusuallydoneonlyonceforthetopics
inasubjectarea.Asaresult,thislimitstheAutoTutortoasmall
0ThecodeandUIlinksareredactedforanonymity.
1seeAppendixAin[11]foranexamplescript setofsubjectareas,restrictingtheirimpact.Nevertheless,thereareScalingtheAuthoringofAutoTutorswithLargeLanguageModels
manyworksinthespaceofrule-basedITS[21],whichhavebeen befilledbyanLLM.Forthepedagogicalstrategy,agooddoctrine
reasonablysuccessfulintheirdomains. tofollowcanbeGetthestudenttothecorrectanswer.Ifpossible,do
sowithouttellingthemtheansweroutright
2.2 LargeLanguageModels Afinitestatetransducerischaracterizedbythecombination
LargeLanguageModels(LLMs)areTransformer-basedmodelsthat ofstatespaceandatransitionfunction.Thestatespacecanbe
serveasgeneral-purposetoolsinnaturallanguageprocessing[4]. seenasthememoryofthefinitestatetransducer,whichstoresone
WithrecentimprovementsinLLMsandtheavailabilityofLLM-as- ormorevariables,eachofwhichcantaketwoormorevalues.In
a-servicemodelslikeGPT[20]andBARD[30],ithasbecomeeasy ourcase,wehavetwovariables,thesolutionstepandthestrategy,
touseLLMsastutorsbypromptingthemwiththedesiredqualities whichfactorizesourstatespaceintotwosubspaces,detailedin
ofatutorandthenlettingtheminteractwithastudent.Someworks Section3.1andSection3.2respectively.Thetransitionfunction
intheprogrammingdomainlikeGPTutor[6]andTestGPT[22] specifiesthenextstagegiventhecurrentstateandthe(student)
attempttouseGPT4similartoinformationdeliverysystems.There inputandishighlydomain-dependent,butweprovideexamplesas
havealsobeensystemsdesignedtofunctionasDialogagents,like theycomeupalongsidethestatespacedescriptions
Ruffle&Riley[26]whichincludesmultipleGPT4agentsfunctioning First,consideramathwordproblemandahistoryquestionto
withdifferentprompts,andSPOCK[29]whichattemptstodistill illustratethepossiblerangeoftopicswhichatutormightapply.
outtutoringknowledgefromGPT4intoasmallerLLM.Anotable
commercialusageofaLLMTutorisseeninKhanmingo,2which
[MWP]Mikhaelbuystwooldcoats,oneat$200andoneat
usestheGPT4backendforaninteractivetutor. $250.Aftercleaningandfixingthem,hesellsthemforaprofit
WhileLLMtutorssolvethescalingissues,itintroducesawhole of20%each.HowmuchmoneydidMikhaelmakefromthis
4
newsetofcomplications,primarilyrelatedtoitsprobabilisticout- transaction?
putandproprietarymodels.ThebehaviorofGPT4canonlybe
controlledbymakingchangestoitsinitialpromptorbyinserting
promptsinbetween,makingithardtointroducethenuancedped-
[WW1]List4causesoftheFirstWorldWar.
agogicalstrategiesdevelopedbylearningscientistsoverthelast
twodecades.Evenforsimplerstrategies,itsprobabilisticnature
Theoptimaltutoringsupportdiffersbetweenthetwoexamples.
leavesitopentobeingexploitedbyuserswhobehaveinunwanted
Whilethemathwordproblemstartswithsubquestionstocom-
ways,oftenreferredtoasjailbreakattacks[16].Evenforbenign
puteintermediatequantities,answeringthehistoryquestionsfirst
users,GPT4canoftenhallucinateincorrectinformationandoutput
requiresprovidinghistoricalcontext.
itwithconfidence[9,32]whichmayadverselyaffectthestudent.
Allthis,inadditiontotheirhard-to-understandnature,leadstoa
distrustofGPT4amongeducatorsandpolicymakers,causingitto 3.1 SolutionDecomposition
bebannedinseveralUSpublicschools.3
Tobegincreatingthestatespaceforafinitestatetransducer,we
firstneedtolistthesolutionsfortheproblem,creatingthesolution
2.3 Ourwork stepspace.Asafirstdesignprinciple,wewanttohavethesolu-
Themainbenefitofthefullyhuman-authoredsettingcomesfrom tionbrokendownintomultipleparts.Forthemathwordproblem
thefactthatitiseasytocontrol,easytointerpret,andtherefore example,thiscouldlooklikeatree:
easytotrust.Mostofthesebenefitscomefromthepedagogydesign
stage,andnotfromtheworkofthedomainexperts.TheLLM-based
SolutionStepSpace(MWP)
approaches,ontheotherhand,mostlyspeedupthedomainex-
BranchA
perts’tasks.Tobringtogetherthebestofbothworlds,wepropose A1 Calculatethetotalcost200+250=450
anexpert-designedpedagogytobeassistedbyanLLMinthedia- A2 Calculatetotalprofit450×20/100=90
loguepart.Therestofthispaperisstructuredasfollows:Section3
BranchB
introducesourgeneraldesignwhichappliestoseveraldomains, B1 Calculatetheprofitonthefirstcoat200×20/100=40
Section4describesthespecificdesignofMWPTutor,Section5 B2 Calculatetheprofitonthesecondcoat250×20/100=50
quantitativelyevaluatesMWPTutor,andSection6looksqualita- B3 Addtogettotalprofit40+50=90
tivelyatweaknessesofbothGPT4andMWPTutor.
Tocompletethequestion,thestudentneedstoperformA1fol-
3 DESIGNPRINCIPLES lowedbyA2.Alternatively,theycancompleteB1andB2inany
WhilethisworkmainlyfocusesonMathWordProblemstutoring, orderandthenB3.Wetransitionoutofastepifthestudentar-
ourbroadergoalistopresentaparadigmthatcanbeusedacross rivesattheright-handsideoftheequationinthe(sub)question.
differentsubjects.Beforethemath-specificaspects,wefirstdescribe Thesedependencystructurescouldlookverydifferentbasedon
the model design principles. The output is the implementation thedomain,likeforthehistoryquestion,forexample:
ofapedagogicalgoalasatemplatestatespaceforafinitestate
transducersimilartodialogadvancementnetworks,whichcanthen
2khanacademy.org/khan-labs 4Mikhaelspentatotalof$450,soa20%profitwouldamounttohimmaking$90from
3bestcolleges.com/news/schools-colleges-banned-chat-gpt-similar-ai-tools thetransaction.SankalanPalChowdhury,VilémZouhar,MrinmayaSachan
Solutionstepspace(WW1) Start
C1 TensionsbyEuropeancolonialexploitation.
C2 Serbiawantedtocreateapan-Balkanstatecausingten- Solution path B determine Solution path A
sionswithAustrohungariansandOttomans. student solution
path (not shown)
C3 AustrohungarianArchdukeFranzFerdinandwasassassi-
natedbyaSerbiannationalist.
C4 TheformationoftheTripleAllianceandtheresponding Student needs more help in current step
CentralPowerAlliancepolarizedEurope.
C5 GermanblankcheckassurancetoAustria-Hungarypro-
vokedtheTripleAlliance.
B1 B1 B1
C6 TheGermanstatewasmilitarised. D1 D2 D3
Inthiscase,acorrectanswerrequiresthestudenttocompleteany
4outofC1-C6inanyparticularordertobeconsideredsuccessful.
The transition function here is more complicated, but one way
wouldbetocheckifallunderlinedkeytermshavebeenmentioned. B2 B2 B2
Splittingaproblemintosmallerpartsisbeneficialforbothhuman D1 D2 D3
learning[25,28]andforLLMsolvers[10,19].GettinganLLMto
splittheproblemintosmallerpartsallowsustothereafterfocus
theLLMonsmallerpartsofthesolution,whichcanalsoreduce
contextlengths.InAutoTutorterminology,thesesolutionsteps
B3 B3 B3
wouldcorrespondto“expectations”.
D1 D2 D3
3.2 PedagogicalStrategy
Havingbrokendownaproblemintosteps,wenowneedtohavea
strategytohelpthestudentachieveeachstep.Thegeneralideais
Success
tostartvague,hopingforthestudenttodoasmuchofthework
aspossible,butthenkeepgettingmorespecificuntilthestudent
cancompletethestep.Forthemathwordproblemexample,atoy Figure2:FullstatespaceforourMWPtoyexample.Vertical
strategycouldbe: bluerectanglesshowthestrategyspaceandHorizontalgreen
rectanglesshowthesolutionstepspace.Solidarrowsindi-
D1 Giveoutthesolutionstep,askforthecalculatione.g.forA1, catesuccessinthecurrentstep,anddashedarrowsindicate
wewouldsay“Canyoucalculatethetotalcostincurred?” failure.ThestatesforbranchAarecollapsedforclarity.
D2 Readoutthecalculationtoperforme.g.forA1,wewould
say“Youhavetoadd200and250”.
D3 Giveouttheanswer,e.g.forA1,wewouldsay“Theanswer foreverystepinthesolutionspacemapseveryelementinthestate
is450”.
spacetoanutterance.Notallutterancesneedtobeunique,and
some,likeP1above,mightnotnecessitateanLLMtobegenerated.
Thissetofpedagogicalstrategiesformsourstrategyspace.We
cantransitionfromD1toD2andthentoD3iftheconditionsfor
transitioningtothenextsolutionsteparenotmet,atwhichpoint 3.3 ScaffoldingtheLLM
weloopinD3.Forthehistoryexample,wehave: WhilemodernLLMsfine-tunedwithRLHFarequitegoodatfol-
lowinginstructions,theycanattimesstrugglewithmorecomplex
P1 Seekthenextcausefromthestudente.g.irrespectiveofthe tasks.BecauseoftheprobabilisticnatureofLLMs,reattempting
step,wecansay“Whatothercausecanyouthinkof?” thesameproblemcanleadtodifferentanswers.Totakethebest
P2 Askforeachmissingkeyworde.g.forC3ifwealreadyhave advantageofthesefacts,wewanttohaveautomatedchecksfor
“assassination”fromP1,wecanask“WhowasAssasinated
everyLLMturninthestrategyspace,socallscanberepeateduntil
andbywhom?”
somecheckshavebeenmet.Forexample,D3couldrequirethatthe
P3 Revealtheanswerifthestudentfailstogetit.
numericalanswer(450forA1)isincludedintheutterance,while
P2couldrequirethemissingkeywordstobeabsent.Thesechecks
Theactualsetofmovescanbequitecomplex.ForP2,wewould
cantakedifferentformsdependingonthedomain,likelimiting
needseparateutterancesforeverypossiblecombinationofmissing
thelengthofanutteranceoravoidingtheuseofmorecomplex
keywords. Ideally, these moves should be designed by learning
language.
scientistsaswasthecaseforAutoTutor.Theoverallstatespaceis
thecross-productofthesolutionstatespaceandthestrategyspace.
Figure2showswhatthefullstatespaceofourMWPexamplecould 3.4 ControlandReliability
looklike.Foreachelementofthestrategyspace,wewouldrequire One of the primary goals of having LLMs author a state space
prompttemplatesthatcanbefilledwiththesolutionstepandpassed ratherthanhavingtheminteractdirectlywiththestudentsisthat
ontoLLMstogeneratetheactualutterance.Runningeachprompt inthisway,onecanexamineandtrustthemodelwithouthaving
pets
txen
ot
sessergorp
tnedutSScalingtheAuthoringofAutoTutorswithLargeLanguageModels
to necessarily trust the LLM used to generate it. Based on this,
we store and make it possible to inspect beforehand the entire Solution tree
Alignment/
utterancespace.Changestotheutterancesthemselvescanbemade F Dir es tet cE tr ir oo nr
Student solution
on-the-go,e.g.ifateacherfeelsitisbettertosplitourexamplein
Math problem
P2intotwosentences,theycansimplyeditittosay“Whowas
Initiate
assassinated?”and“Whocarriedouttheassassination”withno
furtherchangesrequired.Changestothesolutionspace,however,
needtheutterancestoberegenerated. Pump
CachingtheutteranceLLMslikeGPTalsomakesthesystem
immunetochangesmadetoGPTintermsofavailability,cost,or
ratelimits.ForopenLLMs,thisallowsfortheuseofLargerLLMs Correct
Answer
whichnoteveryusercanrunlocally.Themostimportantbenefit, Detected Yes
however,isthepotentialforteachers/domainexpertstoeditthe
statespaceshouldtheywant,thereforeallowingustocombine
Hint
human expertise with machine efficiency. Live calls to an LLM
canoftenhelpandcanbeincorporatedintothestatespace.For
Move to
example,intheMWPwecouldmakeacalltoGPTtotakeovera Correct Next Step
stepinbetweenD2andD3ifwewanttominimizethechanceof DA en tes cw te er d Yes No
D3.Shouldlivecallsbeimplemented,however,thereshouldideally
benon-LLMfallbacksieweshouldhavecachedand/orprocedural No Last
alternativesavailableshouldacalltoanLLMnotbepossibleat Step?
Prompt
deploymenttime.
Yes
4 MWPTutor Correct
DA en tes cw te er d Yes Terminate
WenowdetailthedesignprocessofoursystemMWPTutor,an
instantiationoftheaboveprinciples.MWPTutorisadaptedtohelp
No
studentssolvemathwordproblems.Thescenario,originallyde-
finedbyMathDial[17],involvesastudentapproachingatutorafter
Assertion
unsuccessfullyattemptingtosolveamathwordproblem.Thestu-
dent’sincorrectsolutionisprovidedasapartoftheinput.GSM8k
[8],thesourceforMathDial’sproblemsincludesasinglestep-by-
Correct
stepsolutiontoeachproblem,whichcanbeseenasafulfillmentof Answer
Detected Yes
thesolutionstepspace.However,tonotbecomeconstrainedtothe
availabilityofsuchsolutions,andtoallowdiversesolutionpaths, No
werestrictMWPTutortoonlythefinalnumericalanswertothe
problem,andgeneratethesolutionsourselves.
Figure 3: MWPTutor’s state space as a flowchart. The
4.1 SolutionDecomposition symbolindicatesstudentutteranceinputs,whilethe
symbolindicatesmodeloutput.Thesolutionstepspaceis
Weinstantiatethesolutionstepsasshortpiecesoftextdescribing
collapsedforclarity
astepinthemathwordproblem,includingasinglemathematical
calculation.Wegeneratemultiplesolutionpathswithourbackend
LLM,witheachstepneedingtocontainasinglecalculationdemar-
Toachievethis,wematchstepsintheoriginalstudentsolution
catedindoubleangularbraces(e.g.⟨⟨30+43=73⟩⟩,seeListing1).
withtheclosestpathinthesolutionstepspace.WhileAutoTutor
Thisrequirementstandardizestheinformationdensityofastep
achievesthisusinglatentsemanticanalysisandstring-matching
andalsokeepsthingsconsistentwithGSM8Kwhichusesasimilar
techniques,wefoundthatmoderncounterparts,suchasBERTScore
notation.Italsoallowsustocheckforcalculationerrorsanddiscard
[33]aresurprisinglynotanaptreplacement,perhapsbecauseGPT4
erroneouspaths.Oncemultiplesolutionpathshavebeenobtained,
outputsverylongstepdescriptions,andBERTdoesnotweighand
wediscardthepathsnotleadingtothefinalcorrectsolution,and
comparenumbersandmathematicaloperationswell.
grouptheresttogetherusingexactstringmatchonthecalculations
MWPTutorcurrentlyassumesthatthestudentwillpresenttheir
intoa“tree”ofsolutionsteps.Ourrunningexample,exceptforthe
solutionwithonestepineachline.Foreachstudentstep,wecheckif
angularbrackets,fitsthiscriterionasatreewithtwobranchesat
theright-handsideofanyofthepossiblefollow-upstepsispresent
therootandnobrancheselsewhere.
init.Ifmorethanonefollow-upmatches,wepicktheonewith
thehighestBERTScore.Wethenproceeddownthatnodeofthe
4.2 SolutionAlignment solutiontreeandthenextstudentstep.Ifnofollow-upmatches,
Although not a part of design principles, we wish to not make thecurrentstepisconsideredtobethefirstpointoferror.The
thestudentsrepeatasteptheyhavealreadyperformedcorrectly. pseudo-codeforthisisshowninAlgorithm1.SankalanPalChowdhury,VilémZouhar,MrinmayaSachan
Algorithm1Initialsolutionalignment. 4.4 AnswerandPathDetection
Input:goldandstudentsolutions.
Toexecutethepedagogicalstrategiesdescribedabove,weneedto
Output:alignedsolutionstep,ifexists
beabletodetectifthestudenthasgivenacorrectanswer.Further,
1: GoldSteps←gold.root thehintstateshouldonlytriggerifthestudentfailstoproposea
2: StudStep←student.head correctfollow-up.Forthis,weneedtohaveawaytomatchpaths.
3: whileGoldStepsisnotLeafNodedo WerunintothesamematchingproblemsdescribedinSection4.2,
⊲FilteroutnextsolutionstepswhoseRHSisinthecurrentstudentstep
andresorttosimilarbasictechniques.Thecorrectanswerdetection
4: Matches←{𝑐|𝑐∈GoldSteps.children∧FindNums(StudStep.text)∈𝑐.rhs}
algorithmisshowninAlgorithm2.Forstatesotherthanpump,
5: ifMatchesisemptythen ⊲Nothingmatches,thisisthefirstpointoferror
ittakesasinglereferencestepandchecksifitsRHSispresentin
6: return(GoldSteps,StudStep)
thestudentutterance.Forthepumpstate,allpossiblefollowupsof
7: else
⊲Movetonextstep thelaststeparepassedasreferencesteps.IfitcanfindtheRHSof
8: GoldStep←Max(Matches,key=𝜆𝑥:BertScore(𝑥,StudStep.text)) anyoftheseinthestudentutterance,itmarksthatasthenextstep
9: StudStep←StudStep.next andproceedstothenextstep.Ifnot,itconsidersapathmatchto
10: endif haveoccurredifeveryoperandontheleft-handsideofsomestep
11: endwhile ispresent.Ifmultiplestepsfulfillthis,ornostepdoes,wepickthe
12: returnError(“Studenthastherightanswer.”) onewiththebestBertScorealignmenttothestudentutterance.
Thefactthatwecurrentlyignoreallnon-numericcontentinthe
studentresponseisoneofthemajorlimitationsinourwork,asit
canmissalargenumberof“correct”utterancesfromthestudent,
4.3 PedagogicalStrategy
butwedefertheresolutionofthistofuturework.
Toinstantiateourpedagogy,wetakeinspirationfromAutoTutor,
wheretheprimarysequenceofstepsisapump→hint→prompt→
Algorithm2CorrectAnswerDetection
assertion(Section2of[12]).Graesseretal.intheirworkTeaching
Inputs:CurrentStepsfromSolutionstepspace,andStudentUt-
TacticsinAutotutor [11]definehintsas“questionsthatleadthe terance
studenttothedesiredinformation”,andassertions(whichthey
Output:Degreeofthematch,Bestmatchingstep
callelaborationsinthiswork)as“succinctlyassertthedesiredin-
formation.”Forprompts,theyusefill-in-the-blankstypeutterances 1: UtteranceNums←FindNums(Utterance)
⊲CurrentStepsisasingletonexceptfor“pump.”
leavingoutakeyword.Inourcase,the“keyword”istheequation,
2: for𝑟 ∈CurrentStepsdo
soinsteadweexplainthecalculationtobeperformedinanatural
⊲Gotonextsolutionstep
language.Theseareprecededbya“pump”,whichisthegeneric
3: if𝑟.rhs∈UtteranceNumsthenreturn(“Correct”,𝑟)
utterance“Whatshouldbethenextstep?”Theoverallstrategythen 4: endfor
proceedsasfollows: 5: PartialMatches←⟨𝑟|𝑟 ∈CurrentSteps∧𝑟.lhs⊆UtteranceNums⟩
Pumpasksthestudenttoproposethenextstep.Ifthestudent 6: ifPartialMatchesisemptythen
proposesthestepcorrectly,weaskthemtosolveit. 7: return(“Nomatch”,Max(CurrentSteps,Sort=Bert(𝑥,Utterance)))
Hintisonlytriggeredifthestudentfailstoproposeavalid 8: else ⊲Onlyrelevantfor“pump”.
nextstep,orfailstoexecutethesteptheypropose.It
9: return(“Partmatch”,Max(PartialMatches,Sort=Bert(𝑥,Utterance)))
essentiallygivesoutthestepandasksthestudentfor 10: endif
thecalculation.Thisutteranceshouldtaketheformof
aquestion,andtheonlywaytocorrectlyanswerthe
questionshouldbetosuccessfullyexecutethestep.
4.5 PuttingitAllTogether
Promptistriggeredifthestudentfailstoexecutethestepafter
Figure3summarisestheoverallstatespaceofMWPTutor.Itcan
thehint.Thisshouldpushthestudentclosertothe
beseenasasimplifiedversionofthestatespaceofAutoTutor(see
answer,withoutactuallyrevealingtheanswer.
Figure1in[5]).Theexpectationmatchingisimplicitlycarriedout
Assertionistriggeredifthestudentfailstoanswerevenafter
theprompt.Thisshouldsimplygiveouttheanswer, bythesolutionalignerandthepumpstate.Toobtaintofullfinite
andhavethestudentacknowledgeit. statetransducerstructure,onemustrolloutthestatesalongthe
solutionspace.Excludingtheunlikelycasewherethestudentfailsto
repeattheansweraftertheassertionstate,theoverallconversation
Inourrunningexample,hints,prompts,andassertionswould
correspondtoD1,D2,andD3respectively.Thepumpisnotin-
shouldnotlastmorethan2+4×𝑆utterancepairs,where𝑆isthe
numberofsteps.
cluded.
ForscaffoldingtheLLM,bothhintsandpromptsarerequired
toavoidexplicitlyoutputtingtheright-handsideoftheequation 5 EXPERIMENTS
inthestep,withthehintadditionallyhavingtoavoidsayingany Inthissection,wetheperformanceofMWPTutor andGPT4in
wordsthatindicatearithmeticoperators,currently“add,subtract, termsofhowwelltheycanfollowourpreviouslymentioneddoc-
sum,multiply,product,divide,quotient.”Theassertion,ontheother trine.Wetestbothmodelsintheinteractivesettingproposedby
hand,mustcontaintheright-handside.Forpumps,thereisnouse Macinaetal.[17]whichallowsustosafelycompareimperfect
ofanLLM,sowedonotneedacheck. modelswithouthavinganegativeimpactonhumanusers.ScalingtheAuthoringofAutoTutorswithLargeLanguageModels
5.1 Setup consistentlyfailedtosolve.ThismakesMathDialasignificantly
5.1.1 Setting. Theinteractivetutoringsettingwasproposedin harderdatasettoteach,andresultsonthisdatasetareexpectedto
MathDialasafaster,cheaper,andsaferalternativetohumanex- showthedifferencesbetweenthemodelsmoreclearly.
periments,whereinsteadofinteractingwithhumanstudents,a
TutoringSysteminteractswithanotherLLMrole-playingastudent. 5.1.4 Metrics. Keepinginlinewithourdoctrine,ourprimarymet-
In their data collection experiments, MathDial found that most
ricofevaluationistheSuccessRate(S),whichismeasuredasthe
fractionofconversationswherethestudentsaysthecorrectanswer
teachersbelievedthatthestudentLLMbehavedverymuchlikean
actualstudentinmostcases.Weadopttheirsettingasisforour
eventually.ThesecondarymetricisTellingRate(T),whichis
thefractionofconversationswherethetutordidnotrevealthe
experimentsection.
answer.Thetutorissaidtohaverevealedtheanswerwhenthey
NotethatforanLLM,theinteractivetutoringsettingissome-
whatrelatedtotheMWPsolversettingoftenusedasametricto
saythefinalanswerbeforethestudenthassaidit,andthestudent
succeedsingettingtotheanswerthereafter.Boththesemetrics
measurethereasoningabilitiesofsaidLLM,buttherearesignifi-
wereoriginallydefinedbyMacinaetal.[17],buttheydonotoffer
cantdifferences.UnliketheMWPsolversetting,thefinalansweris
awayofcombiningthemintoasinglescore.Itisquiteeasyto
alreadyprovided,sotheLLMdoesnotneedtocomeupwithit.The
increasesuccessatthecostofincreasedtelling.Thereforewealso
difficultyarisesfromthefactthatthisLLMneedstogetthestudent
LLMtogettothisanswer,andthestudentLLMispromptedtonot
calculatetheAdjustedSuccess(S-T)rateasthefractionwhere
thestudentsucceededwithouthavingbeentoldtheanswerand
budgefromitsstartingwronganswerwithoutgoodreason.Despite
usetheharmonicmeanbetweenthisnumberandthesuccessrate
thesedifferences,someskillslikeMathReasoningAbilitiestransfer
betweenthetwosettings,sowecanexpectthefinalperformances
asanoverallTutoringScore(2𝑆 2( 𝑆𝑆 −− 𝑇𝑇) ).Wealsoofferutterance
levelevaluationsinSection5.3,butsinceweareunawareofthe
inbothsettingstocorrelatewitheachother.
utterancelevelstrategiesfromGPT4,wedoitonlyforourmodel,
5.1.2 Models. Atthetimeoftesting,GPT45wasconsideredtobe andthemetricsforthesamearedefinedlater.
oneofthebest-performingLLMs,soweuseitbothasabackendfor
MWPTutorandasthebaselinesinglepromptLLM.Tobestalign
5.2 ConversationEvaluation
thesinglepromptGPT4withtheMWPTutordoctrine,weaskit
WeevaluatebothsuccessandtellingfortheMultiArithdataset
toroleplayatutor,settingtheprimaryobjectiveofgettingtothe
bydirectlylookingfortheanswerinstudentandtutorutterances
correctanswerasthegoaloftheconversation,andthesecondary
respectively,andcalculatetheoverallscoresbasedonthat.The
objectiveofnotrevealingtheanswerasapersonalitytrait.Further,
tophalfofTable1summarisesourresults.Allmodelsareableto
totestthepotentialofanopen-sourceLLMasabackend,wehavea
transfertheirnear-perfectsolvingscorestonear-perfecttutoring
secondversionofMWPTutorwithaMetaMath-13B[31].MetaMath
isaversionofMetaAI’sopensourceLLMLLaMa6fine-tunedto scores.GPT4performsslightlyworse,althoughithasa0tellingrate.
BothversionsofMWPTutorhaveaperfectsuccessrate.Itmustbe
solvemathwordproblems,andis,tothebestofourknowledge,
notedthatthemetricisnoisysinceitonlyrequiresthenumberto
thebestopenLLMforsolvingmathwordproblems.Wereferto
match,withnorestrictiononthecontext,e.g.intheproblem“How
thesethreemodelsasMWPTutor ,GPT4,andMWPTutor
GPT4 LLaMa
manygroupsof9canbemadeoutof5boysand40girls?”ifthe
respectively.
tutormentionsthereare5boys,wewouldcountitastellingasthe
5.1.3 Datasets. ToimplementMWPTutor,werequireadataset finalanswerhappenstobe5.Thismeansthattherealratescould
withmathwordproblemsandtheirsolutions,aswellasincorrect besomewhatlowerforall3models,andthedifferencebetween
studentsolutions.Wemakeuseofthetestsetsoftwodatasets, themisnotsignificant.Nevertheless,sucherrorsareunlikelytobe
namelyMathDial[17]andMultiArith.MultiArithconsistsof180 frequent,andallmodelsworkreasonablywellontheseproblems.
simpleMathWordProblemsthatareusuallysolvablein1to3steps.
GPT3wasalreadyabletosolveover90%oftheseproblemswith
therightprompts[15],andinourtests,wefoundthatGPT4was
abletogetaperfectscoreintheMWPsolversetting.Withthis MWPTutor
dataset,wewanttotestifwecanachievethesameperformance Metric LLaMa GPT GPT4
intheinteractivetutoringsetting.Thisdatasetdoesnotprovide
SuccessRate 1.00 1.00 0.98
anywrongsolutionsneededtoinstantiatethestudentmodel,so
TellingRate 0.01 0.01 0.00
wemakeuseoferrorsmadebyaMetaMathsolverastheoriginal
AdjustedSuccess 0.99 0.99 0.98
studentsolutionwherepossible,andleavetheremainingquestions
TutoringScore 0.99 0.99 0.98
as“Noideahowtobegin”.
MathDialconsistsof45problemsfromthepre-existingGSM8k SuccessRate 0.91 0.96 0.82
[8].ProblemsinGSM8karemeanttobesolvablebyabrightmiddle TellingRate 0.33 0.11 0.00
schoolstudentusingonlybasicarithmeticoperators(+,−,×,÷), AdjustedSuccess 0.58 0.84 0.82
takingupto8stepstosolve.Ofthese,MathDialpicksproblems TutoringScore 0.71 0.90 0.82
thathaveofficialsolutionstaking5stepsorfewer,thatGPT3.5
Table1:PerformanceofMWPTutorandGPT4onMultiArith
(180problems)andMathDial(45problems).
5gpt-4-1106-previewqueriedinJanuary2024
6https://llama.meta.com/
htirAitluM
laiDhtaMSankalanPalChowdhury,VilémZouhar,MrinmayaSachan
FortheharderMathDialdataset,wewantedtoavoidmatching
errorsasdescribedearlier,andsohavehumanannotatorsmark 3 No 2 No, 1 Yes 1 No, 2 Yes 3 Yes
oututteranceswherethestudentorthetutorsaysthefinalanswer. (Redundant) Not Redundant
Eachconversationwasannotatedby3annotators,andwetookthe (Not Relevant) Relevant
majorityincaseswheretheydisagreed.
(Reveal) Not Reveal
Table1summarisesourresult.WhileGPT4maintainsits0%
(Not Grammatical) Grammatical
tellingrate,MWPTutor gets6moreproblemscorrectoverall,
GPT
and1morewhenadjustedfortelling.ThisgivesMWPTutor an 0 20 40 60 80 100
GPT Percentage of Hints
advantageonGPT4intermsofthefinalscore.MWPTutor
LLaMa
alsogetsahighersuccessratethanGPT4,whichissomewhatsur-
Figure 4: Summary of Human evaluation for Hints from
prisingsinceitsbackendmodelissignificantlyweakerthanGPT4
MWPTutor.ThetotalnumberofHintsamplesis102.Each
intheMWPSolversetting[31].Thisincreasedsuccessratehowever
samplewasevaluatedby3annotatorsin4categories.
comesatacostofaveryhightellingrate,givingitasignificantly
poorertutoringscoreoverall,sowedonotrecommendtheuseof
MetaMathasthebackendmodelunlessGPT4-likemodelsneedto
beavoidedforsomeexternalreason.Onethingworthmentioning The annotators were paid the Prolific suggested wage of 10
hereisthatonceproblematicquestionshavebeenidentifiedfor GBP/hour.WeshowtheannotationuserinterfaceinFigure6and
eitherversionofMWPTutor,onecanhavehumanannotatorsredo someexampleannotationsinTable2andTable3.Figures4and5
onlythosequestions,therebyincreasingthesuccessrate,something summarisetheresponsesfromtheevaluators.Almostallutterances
thatisnotpossibleforGPT4. areconsideredGrammaticalbytheevaluators,whichisnotsurpris-
inggiventheyweregeneratedbyGPT4.Mostoftheutterancesare
5.3 UtteranceEvaluation alsomarkedtobenon-revealing,whichisalsonotsurprisinggiven
AmajorshortcomingofAI-on-AI-tutoringisthattheAIstudent thatanyproposedutterancesthatdirectlyrevealedtheanswerwere
maynotbeaffectedbythesometimessubpartutorresponses.This assignedtoberegenerated.Theevaluatorsfurtherseemtoagree
ismorecommoninMWPTutorthaninGPT4,astheformercan thatmosthintswererelevanttothestepandthatmostprompts
onlypickfromapre-definedsetofresponsesandnotcreatenew arespecific,implyingthattheydowhatisappropriategiventhe
utterances on the fly in response to finer details in the student currentsolutionstep.
requirements.Tounderstandifthisisamajorissue,wehiredhuman ThebiggestpotentialweaknessofMWPTutorcomesintheform
evaluatorswhoworkedintheeducationsectorandaskedthemto ofitsutterancesmakingsenseinthecontextofpreviousstudent
evaluateutterancesmadebyMWPTutor forMathDial.Because utterancesduetoissuesdiscussedinSection4.4,whichiswhere
GPT
thepumpsaregenericandverysimilartoeachotherandassertions thefinaltwometricscomein.Inthisregard,allpromptsarecon-
essentiallyboildowntoreadingouttheanswers,wefocusonlyon sideredtobehelpfulbyamajorityofevaluatorswhichisagreat
thehintsandpromptsinourevaluation. sign.Hints,however,arefoundtoberedundantinalmostathird
Across the 45 conversations, MWPTutor and the student ofcases,showingthathandlingofstudent’sresponsestopumps
GPT
modelwentover135solutionsteps.Ofthese102wenttothehint couldbebetter.Thecurrentheuristicofmatchingtheleft-hand
state,while29reachedthepromptstate.Wepresentedeachofthese sideistoodemanding,andhighlylikelytoignorethestudenteven
131utterancestohumanevaluators,withthepastconversation, iftheyproposeavalidnextsteptotheproblem,whichcanbreak
theoriginalmathwordproblem,andthecurrentsolutionstepas studentimmersion.Notethat33ofthe135stepsdidnotproceedto
context.Weboildowntherequirementssetonhintsandprompts thehintstate,implyingmorethanhalfofthecorrectproposalsby
setinSection4.3tothefollowingbinarycriteriawhichweasked thestudentarebeingidentifiedassuch.Further,inavastmajority
theevaluatorstoevaluatetheutteranceson: ofcaseswhereacorrectproposalismisidentified,thereisdisagree-
mentbetweenhumanevaluatorsindicatingtheremightbesome
• Grammatical:Theutteranceislinguisticallyandgrammat- meritintherejection,thoughthisisalsothecaseforamajorityof
icallycorrect. correctrejections.
• NotReveal:Theutterancedoesnotrevealthefinalanswer Overalltheseevaluationsshowthatutterancesgeneratedfor
forthestep. MWPTutorbytheGPT4backendareconsistentwiththestrategy
• Relevant(hintsonly):Thehintclearlyaddressesthestep,ie, definitions,andthetransitionfunctionusesthemreasonablywell.
theonlywaytocorrectlyanswerthequestionistocomplete
thecurrentstep.
6 QUALITATIVEASSESSMENTOF
• NotRedundant(hintsonly):Thehintisnotredundantto
whatthestudentalreadysaidinthepreviousstepieitmakes WEAKNESSES
sensetoaskthisquestionafterthepreviousresponse. WhilebothGPT4andMWPTutor doquitewellonquantitative
GPT4
• Specific(promptsonly):Thepromptisspecifictothestep, metrics as seen above, these metrics do not fully grasp what it
andnotjustavaguelead-onstatement. takestomakeagoodtutor.Tobetterunderstandthepreparedness
• Helpful(promptsonly):Thepromptcanpotentiallyhelp ofourmodels,wewentoverall45conversationsthathappened
the student make progress in the current step, given the ontheMathDialdataset,forbothGPT4andMWPTutor and
GPT4
previousstudent’sutterance. summarizeourfindingshere.ScalingtheAuthoringofAutoTutorswithLargeLanguageModels
weeklyrateofweightloss,whenasimplemultiplicationoftime
3 No 2 No, 1 Yes 1 No, 2 Yes 3 Yes periodby4wouldhaveyieldedtheanswer.Theconversationin
(Redundant) Not Redundant Figure1isalsoanexampleofwherethishappensinthesimpler
(Not Relevant) Relevant MultiArithdataset.Sinceitexploresmultiplepathsandisalsolim-
(Reveal) Not Reveal
itedinthestepsitcantake,MWPTutorGPT4islesslikelytorun
intothisissue,andhandlesthefirsttwocasesmentionedhere
(Not Grammatical) Grammatical
prettywell,thoughitmakesthesameerrorinthelastcase.
0 20 40 60 80 100 ThebiggestproblemwithGPT4,however,continuestobethat
Percentage of Hints
GPT4canleadthestudenttoawronganswer,sometimes
Figure5:SummaryofHumanevaluationforPromptsfrom
evenleadingthemawayfromtherightanswer.Inall8cases
whereGPT4failstogetthestudenttothecorrectanswer,itoutright
MWPTutor.ThetotalnumberofPromptssamplesis29.Each
acceptsawronganswerascorrect.OfMWPTutor ’sfailures
samplewasevaluatedby3annotatorsin4categories GPT4
onewasaresultofinadvertentlyrevealingthefinalanswer,while
theotherseemstohavebeenmarkedasincorrectbytheannotators
Firstly,MWPTutorGPT4 tendstosoundmonotonousand becausethetutorresortstorevealingratherquickly.Inafurther2
dry.Partofthisisbecauseofthepre-setformatforutterances conversation,includingtheoneregardingchickenfeeddescribed
likeallhintsarehardcodedtobeginwith“Tellmethisinstead:,” earlier,GPT4misdirectsthestudentontothewrongpathbutsome-
butthiscaneasilyberesolvedbyhavingitsamplefromseveral howmanagestogetthemtosaythecorrectanswer.Finally,in
rephrasings of the same utterance. More difficult to fix are the onequestion,GPT4rejectsacorrectequation,andthengoesoff
repetitivestrategyandthelackoffinerfeedbackoranyaffective inatangentialdirection,untilthemaximumlimitof60utterances
statements,bothofwhicharetherebydesign.Introducingfiner isreached(thisbeingtheonlyinstancewheretheutterancelimit
feedbackrequiresamorefine-grainedanalysisofstudentutter- comesintoplay).Itmustbereiteratedherethatthefinalcorrect
ances,whichwefoundoff-the-shelfNLPmethodstobeincapable answerisgiventoGPT4aspartofitsprompt.MWPTutor by
ofdoingwhilemaintainingahighdegreeofaccuracy.Affective designwillneverokayawronganswer.Theonlyplacewhere
statements,likeencouragements,challenges,etc.wouldfurther itdoesgowrong,itacceptsananswerof−40insteadof40,but
requireaccuratejudgmentofstudentconfidenceandcorrectness. thiscanbechalkeddowntothefactthatthequestionwasasking
Inboththesecases,wemadeadesignchoicetoavoidtheadditional forthe“difference”betweentwoquantities,anddidnotmakeit
module,astheywouldcreatemajorfailurenodes.GPT4onthe clearwhetherthesignwasrequired(thefirstquantitywassmaller.
otherhand,soundsalotmorenatural,includingfinerfeed- AlsoGPT4makesthesameerror.Botharemarkedascorrectby
backandprobing,andevenaffectivestatements,althoughtheyare annotators).Itmust,however,benotedthatsinceitalsorelieson
exclusivelypositive. GPT4forsolutiongeneration,MWPTutorGPT4canhallucinate,
Further,sinceitmatchescorrectanswerswithlimitedattention evenifitdidnothappeninanyoftheseconversationstothebest
tocontext,MWPTutorGPT4cansometimesgetfalsepositives, oftheauthors’judgement(Weattemptedtohavetheevaluators
andinadvertentlyrevealtheanswer.Considerthefollowing annotate the existence of wrong methods, but found too much
excerpt: disagreementintheirresponsestoconsiderthemviable).Ifthis
happens,however,onecanfixthembychangingthetreethefirst
Tutor:Tellmethisinstead:Whatisthetotalamountoffeed timetheygetnoticed,somethingthatisnotpossiblewithGPT4.
neededforallthechickensforonedayifeachchickenrequires Overall,weconcludethatdespitegoodshowingonmetrics,both
3cupsoffeed?
methodsarestilllackinginquality,anddecidetonottestthemon
...
realstudentsuntilwecansignificantlyimprovethem.
Student:Sure,3cupsoffeedx20chickens=60cupsoffeed
permeal.60cupsx3meals=180cupsoffeedfortheday....
Tutor:60iscorrect,welldone.Whatisthenextstep? 7 DISCUSSIONANDFUTUREWORK
Wehavestatedthroughoutthepaperthatalthoughself-sufficient,
Here,thestudentgivesthewronganswerof180,butMWPTutor
MWPTutorisstillaprototype,andweexplainedinSection6that
mistakestheintermediatecalculationof60asthecorrectanswer,
westillhavealongwaytogobeforemakingMWPTutorviableto
andeffectivelyrevealsittothestudent.GPT4isabletounder-
beusedonrealstudents.Inthissection,weoutlinesomedirections
stand context usually, although it is far from perfect. As we
forfutureworkthatcouldbringusclosertothesegoals.
discusslater,GPT4failsmuchworseonthisquestiontoo.
WhileGPT4conversationsflowalotbetterandsoundhuman-
like,ithasadifferentsetofissues.Forone,GPT4tendstoover- 7.1 ImprovingtheSolutionStepSpace
complicatequestionsormakeredundantcalculations.Inone Thecurrentsolutionstepspacetakestheshapeofatreewhere
question,wherethestudentfailedtoconvertsecondsintominutes, solutionscanonlydivergefromeachstep.Butthisisnon-realisticas
GPT4getsthestudenttoconvertthesecondstohoursfirst,and weknowthatallpathsmustleadtothesamefinalanswerandhence
thenbacktominutes.Thisintroducedprecisionerrors,whichithad needtoconvergeatsomepoint.Further,theorderofcarryingout
tofixbyroundingthefinalanswer.InanotherquestionGPT4hasa certainstepscouldbeapartialorderratherthanatotalorder.This
studentrecalculateavalueshehadalreadycalculatedinaprevious wouldcurrentlyberepresentedbylistingoutallpossibleorders
step.InyetanotherquestionGPT4makesthestudentcalculatethe asseparatepaths,butthiscausesablowupinthenumberofsteps.SankalanPalChowdhury,VilémZouhar,MrinmayaSachan
AddingaricherstructuretotheSolutiongraphcouldvastlyreduce REFERENCES
thesizeofthesolutionspace. [1] JohnR.Anderson,C.FranklinBoyle,andBrianJ.Reiser.1985.IntelligentTutoring
Inadditiontothis,eachstepofthesolutionshouldbemadeto Systems.Science228,4698(1985),456–462. https://doi.org/10.1126/science.228.
4698.456arXiv:https://www.science.org/doi/pdf/10.1126/science.228.4698.456
followamorestandardizedformat.Havingamoreprecisedefinition
[2] DavidBaidoo-AnuandLeticiaOwusuAnsah.2023. Educationintheeraof
ofthestepwouldallowustouseLSA-liketechniquestoimprove generativeartificialintelligence(AI):Understandingthepotentialbenefitsof
ourcorrectanswerdetection.Pre-definingpossibleerrorsforeach ChatGPTinpromotingteachingandlearning.JournalofAI7,1(2023),52–62.
https://dergipark.org.tr/en/pub/jai/issue/77844/1337500
stepwouldallowustopreparetohandlesaiderrors.Wecanalso [3] BenjaminSBloom.1984.The2sigmaproblem:Thesearchformethodsofgroup
havedescriptionsofeachquantityintheLHStogivemorepointed instructionaseffectiveasone-to-onetutoring.Educationalresearcher13,6(1984),
4–16.
hints.
[4] RishiBommasani,DrewA.Hudson,EhsanAdeli,RussAltman,SimranArora,
SydneyvonArx,MichaelS.Bernstein,JeannetteBohg,AntoineBosselut,Emma
Brunskill,ErikBrynjolfsson,ShyamalBuch,DallasCard,RodrigoCastellon,
7.2 ImprovingtheStrategySpace NiladriChatterji,AnnieChen,KathleenCreel,JaredQuincyDavis,DoraDem-
szky,ChrisDonahue,MoussaDoumbouya,EsinDurmus,StefanoErmon,John
Thecurrentstrategyspaceislinearanddoesnotallowforvery
Etchemendy,KawinEthayarajh,LiFei-Fei,ChelseaFinn,TrevorGale,Lauren
targetedreactionstothestudentutterancesortheoriginalstudent Gillespie,KaranGoel,NoahGoodman,ShelbyGrossman,NeelGuha,Tatsunori
solution.Oncewehaveabettersolutionstepspace,wecanlook Hashimoto,PeterHenderson,JohnHewitt,DanielE.Ho,JennyHong,KyleHsu,
JingHuang,ThomasIcard,SaahilJain,DanJurafsky,PratyushaKalluri,Siddharth
for different types of errors and diverge into different Prompts
Karamcheti,GeoffKeeling,FereshteKhani,OmarKhattab,PangWeiKoh,Mark
depending on the exact error should the student fail to get the Krass,RanjayKrishna,RohithKuditipudi,AnanyaKumar,FaisalLadhak,Mina
answercorrectaftertheHintstate.Therecanevenbemorethan Lee,TonyLee,JureLeskovec,IsabelleLevent,XiangLisaLi,XuechenLi,Tengyu
Ma,AliMalik,ChristopherD.Manning,SuvirMirchandani,EricMitchell,Zanele
onePromptrevealingdifferentamountsofinformationbasedon Munyikwa,SurajNair,AvanikaNarayan,DeepakNarayanan,BenNewman,
thecomplexityofthecurrentstep.Anotherthingentirelymissing AllenNie,JuanCarlosNiebles,HamedNilforoshan,JulianNyarko,GirayOgut,
LaurelOrr,IsabelPapadimitriou,JoonSungPark,ChrisPiech,EvaPortelance,
isthe“Problematization”strategiesdescribedbyReiser[24]and
ChristopherPotts,AditiRaghunathan,RobReich,HongyuRen,FriedaRong,
alsousedbyMathDial.Alongsidethis,thematchingrequirements YusufRoohani,CamiloRuiz,JackRyan,ChristopherRé,DorsaSadigh,Shiori
forsolutionalignmentcanbemadestrictertobetterknowwhereto Sagawa,KeshavSanthanam,AndyShih,KrishnanSrinivasan,AlexTamkin,Ro-
hanTaori,ArminW.Thomas,FlorianTramèr,RoseE.Wang,WilliamWang,
startapplyingourintervention.Thiscouldalsocomewithrelaxing
BohanWu,JiajunWu,YuhuaiWu,SangMichaelXie,MichihiroYasunaga,Ji-
theformatrequirementof“onestepperline”onthestudentsolution. axuanYou,MateiZaharia,MichaelZhang,TianyiZhang,XikunZhang,Yuhui
Boththesewouldshortentheaveragelengthsoftheconversation Zhang,LuciaZheng,KaitlynZhou,andPercyLiang.2022.OntheOpportunities
andRisksofFoundationModels. arXiv:2108.07258[cs.LG]
tobalancemorestepsinthestrategyspace. [5] ZhiqiangCai,XiangenHu,andArthurC.Graesser.2019.AuthoringConversa-
Alternatively,matchingcanbedoneusingsmallerspecialized tionalIntelligentTutoringSystems.InAdaptiveInstructionalSystems,RobertA.
SottilareandJessicaSchwarz(Eds.).SpringerInternationalPublishing,Cham,
LLMstrainedforthistask,andthiswouldalsoapplytocorrect
593–603.
answerdetectionandpathmatching [6] EasonChen,RayHuang,Han-ShinChen,Yuen-HsienTseng,andLiang-YiLi.
2023.GPTutor:AChatGPT-PoweredProgrammingToolforCodeExplanation.
InArtificialIntelligenceinEducation.PostersandLateBreakingResults,Workshops
8 CONCLUSION andTutorials,IndustryandInnovationTracks,Practitioners,DoctoralConsortium
andBlueSky-24thInternationalConference,AIED2023,Tokyo,Japan,July3-7,
Inthispaper,weproposeusingLLMstotakeovertheauthoring 2023,Proceedings(CommunicationsinComputerandInformationScience,Vol.1831),
ofthestatespaceforanAutoTutor-likemodeltominimizehuman NingWang,GenaroRebolledo-Mendez,VaniaDimitrova,NoboruMatsuda,and
OlgaC.Santos(Eds.).Springer,321–327. https://doi.org/10.1007/978-3-031-
timerequirementsandbuildasamplesystemtoshowcaseourpro-
36336-8_50
posal.Wefindthatourmodelperformssomewhatbetterthana [7] HyungWonChung,LeHou,ShayneLongpre,BarretZoph,YiTay,WilliamFedus,
SinglePromptGPT4modelintermsofautomaticmetricswhile YunxuanLi,XuezhiWang,MostafaDehghani,SiddharthaBrahma,AlbertWeb-
son,ShixiangShaneGu,ZhuyunDai,MiracSuzgun,XinyunChen,Aakanksha
maintainingfullinterpretabilityandmodularityinitsstatespace Chowdhery,AlexCastro-Ros,MariePellat,KevinRobinson,DashaValter,Sharan
whichGPT4lacks.Ourmodelalsoholdsuptothedesiredquali- Narang,GauravMishra,AdamsYu,VincentZhao,YanpingHuang,AndrewDai,
HongkunYu,SlavPetrov,EdH.Chi,JeffDean,JacobDevlin,AdamRoberts,
tiesinitsutterancesinhumanevaluation,showingthereishigh
DennyZhou,QuocV.Le,andJasonWei.2022. ScalingInstruction-Finetuned
potentialinthisdirection.Butatthesametime,itstillfacesissues LanguageModels. arXiv:2210.11416[cs.LG]
thatbecomemoreapparentwhengoingthroughconversations [8] KarlCobbe,VineetKosaraju,MohammadBavarian,MarkChen,HeewooJun,
LukaszKaiser,MatthiasPlappert,JerryTworek,JacobHilton,ReiichiroNakano,
manually,indicatingthatthereisalotofworkstilltobedone.
ChristopherHesse,andJohnSchulman.2021.TrainingVerifierstoSolveMath
TheseissuescanbefixedbybetterLLMsandmoresophisticated WordProblems.arXivpreprintarXiv:2110.14168(2021).
techniquesoutlinedinfuturework.Severalpotentialstepshave [9] ChenhangCui,YiyangZhou,XinyuYang,ShirleyWu,LinjunZhang,JamesZou,
andHuaxiuYao.2023.HolisticAnalysisofHallucinationinGPT-4V(ision):Bias
alreadybeenoutlinedinSection4,andwehopetosoonhavebetter andInterferenceChallenges. arXiv:2311.03287[cs.LG]
versionsofMWPTutorandothersimilarsystemsthatcanrealize [10] ShehzaadDhuliawala,MojtabaKomeili,JingXu,RobertaRaileanu,XianLi,Asli
Celikyilmaz,andJasonWeston.2023.Chain-of-VerificationReducesHallucina-
one-on-onetutoringatscale.
tioninLargeLanguageModels. arXiv:2309.11495[cs.CL]
[11] ArthurGraesser,NataliePerson,andDerekHarter.2000. TeachingTacticsin
AutoTutor.(012000).
ACKNOWLEDGMENTS [12] ArthurC.Graesser.2016.ConversationswithAutoTutorHelpStudentsLearn.
ThisworkwasfundedbytheSwissNationalScienceFoundation
InternationalJournalofArtificialIntelligenceinEducation26,1(01Mar2016),
124–132. https://doi.org/10.1007/s40593-015-0086-4
(ProjectNo.197155),andaResponsibleAIgrantbytheHaslers- [13] ArthurC.Graesser,KurtVanLehn,CarolynP.Rose,PamelaW.Jordan,andDerek
tiftung.WeextendourgratitudetoJakubMacinafromtheETHAI Harter.2001. IntelligentTutoringSystemswithConversationalDialogue. AI
Magazine22,4(Dec.2001),39. https://doi.org/10.1609/aimag.v22i4.1591
Center,NicoDaheimfromUKPLab,TUDarmstadt,andFarquet [14] KennethR.Koedinger,VincentAleven,NeilHeffernan,BruceMcLaren,and
GrégoirefromDepartmentofArchitecture,ETHZürichfortheir MatthewHockenberry.2004.OpeningtheDoortoNon-programmers:Authoring
invaluablefeedback.
IntelligentTutorBehaviorbyDemonstration.InIntelligentTutoringSystems,ScalingtheAuthoringofAutoTutorswithLargeLanguageModels
JamesC.Lester,RosaMariaVicari,andFábioParaguaçu(Eds.).SpringerBerlin
Heidelberg,Berlin,Heidelberg,162–174.
[15] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and
Yusuke Iwasawa. 2023. Large Language Models are Zero-Shot Reasoners.
arXiv:2205.11916[cs.CL]
[16] YiLiu,GeleiDeng,ZhengziXu,YuekangLi,YaowenZheng,YingZhang,Lida
Zhao,TianweiZhang,andYangLiu.2023. JailbreakingChatGPTviaPrompt
Engineering:AnEmpiricalStudy. arXiv:2305.13860[cs.SE]
[17] JakubMacina,NicoDaheim,SankalanPalChowdhury,TanmaySinha,Manu
Kapur,IrynaGurevych,andMrinmayaSachan.2023. MathDial:ADialogue
TutoringDatasetwithRichPedagogicalPropertiesGroundedinMathReasoning
Problems. arXiv:2305.14536[cs.CL]
[18] BenjaminNye,ArthurGraesser,andXiangenHu.2014.AutoTutorandFamily:
AReviewof17YearsofNaturalLanguageTutoring. InternationalJournalof
ArtificialIntelligenceinEducation24(122014). https://doi.org/10.1007/s40593-
014-0029-5
[19] MaxwellNye,AndersAndreassen,GuyGur-Ari,HenrykWitoldMichalewski,
JacobAustin,DavidBieber,DavidMartinDohan,AitorLewkowycz,MaartenPaul
Bosma,DavidLuan,CharlesSutton,andAugustusOdena.2021. ShowYour
Work:ScratchpadsforIntermediateComputationwithLanguageModels. https:
//arxiv.org/abs/2112.00114
[20] OpenAI.2023.GPT-4TechnicalReport. arXiv:2303.08774[cs.CL]
[21] JoséPaladinesandJaimeRamirez.2020. ASystematicLiteratureReviewof
IntelligentTutoringSystemsWithDialogueinNaturalLanguage.IEEEAccess8
(2020),164246–164267. https://doi.org/10.1109/ACCESS.2020.3021383
[22] TungPhung,Victor-AlexandruPădurean,JoséCambronero,SumitGulwani,To-
biasKohn,RupakMajumdar,AdishSingla,andGustavoSoares.2023.Generative
AIforProgrammingEducation:BenchmarkingChatGPT,GPT-4,andHumanTu-
tors.InProceedingsofthe2023ACMConferenceonInternationalComputingEduca-
tionResearch-Volume2(Chicago,IL,USA)(ICER’23).AssociationforComputing
Machinery,NewYork,NY,USA,41–42. https://doi.org/10.1145/3568812.3603476
[23] JaakkoRajala,JenniHukkanen,MariaHartikainen,andPiaNiemelä.2023."Call
meKiran"–ChatGPTasaTutoringChatbotinaComputerScienceCourse.
InProceedingsofthe26thInternationalAcademicMindtrekConference.83–94.
https://dl.acm.org/doi/pdf/10.1145/3616961.3616974
[24] BrianReiser.2004.ScaffoldingComplexLearning:TheMechanismsofStructuring
andProblematizingStudentWork.JournalOfTheLearningSciences13(012004),
273–304. https://doi.org/10.1207/s15327809jls1303_2
[25] KathrynM.Rich,T.AndrewBinkowski,CarlaStrickland,andDianaFranklin.
2018.Decomposition:AK-8ComputationalThinkingLearningTrajectory.In
Proceedingsofthe2018ACMConferenceonInternationalComputingEducation
Research(Espoo,Finland)(ICER’18).AssociationforComputingMachinery,New
York,NY,USA,124–132. https://doi.org/10.1145/3230977.3230979
[26] RobinSchmucker,MengXia,AmosAzaria,andTomMitchell.2023. Ruf-
fle&Riley:TowardstheAutomatedInductionofConversationalTutoringSystems.
arXiv:2310.01420[cs.CL]
[27] D.SleemanandJ.S.Brown.1982.IntelligentTutoringSystems.AcademicPress.
https://books.google.ch/books?id=pjqcAAAAMAAJ
[28] TingSongandKurtBecker.2014.Expertvs.novice:Problemdecomposition/re-
compositioninengineeringdesign.In2014InternationalConferenceoninteractive
collaborativelearning(ICL).IEEE,181–190.
[29] ShashankSonkar,NaimingLiu,DebshilaBasuMallick,andRichardG.Baraniuk.
2023. CLASS:ADesignFrameworkforbuildingIntelligentTutoringSystems
basedonLearningScienceprinciples. arXiv:2305.13272[cs.CL]
[30] FerhatYarkinandJustinP.Coon.2022.SimpleGrayCodingandLLRCalculation
forMDSModulationSystems. CoRRabs/2201.08237(2022). arXiv:2201.08237
https://arxiv.org/abs/2201.08237
[31] LonghuiYu,WeisenJiang,HanShi,JinchengYu,ZhengyingLiu,YuZhang,
JamesT.Kwok,ZhenguoLi,AdrianWeller,andWeiyangLiu.2023. Meta-
Math:BootstrapYourOwnMathematicalQuestionsforLargeLanguageModels.
arXiv:2309.12284[cs.CL]
[32] MuruZhang,OfirPress,WilliamMerrill,AlisaLiu,andNoahA.Smith.2023.
HowLanguageModelHallucinationsCanSnowball. arXiv:2305.13534[cs.CL]
[33] Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and
Yoav Artzi. 2020. BERTScore: Evaluating Text Generation with BERT.
arXiv:1904.09675[cs.CL]SankalanPalChowdhury,VilémZouhar,MrinmayaSachan
Figure6:Screenshotoftheintrinsicannotationuserinterfaces.Eachcrowdworkerevaluated10-20dialogues.Apartfromthe
shortinstructions,weshowedlongerinstructionsatthebeginning.ScalingtheAuthoringofAutoTutorswithLargeLanguageModels
Hint Recenthistory Question SolutionStep Rating
Tellmethisinstead:Whatisthebase Tutor: You are correct upto Wendywantstoplace20more Doublethenumberof Grammatical:
numberofbooksbeforeWendyadds whereyousay“Calculatetheto- than double the number of slots to find the base YNN
the20extrabooksifshedoublesthe talnumberofslotsintheshelv- booksinashelvingsystemwith number of books be- Relevant:
numberofslotsshehas,whichis36? ingsystembymultiplyingthe 6 rows and 6 columns. How fore adding the 20 ex- YYY
numberofrowsbythenumber many books will she need to trabooksWendywants Notredundant:
ofcolumns.6rows*6columns carrytocompletehertask? toplace.36slots*2= YYN
=>36slots.”Whatdoyouthink <<36*2=72>>72books. Notrevealing:
shouldbethenextstep? YYY
Student:Thenextstepwould
betorepresentthenumberof
booksWendyneedstocarryas
“x”.Then,wecansetupanequa-
tiontorepresentthegiveninfor-
mation.2x+20=36.
Tellmethisinstead:Whatistheprofit Tutor:200000iscorrect,well Josh decides to try flipping a Find out the profit by Grammatical:
whenthetotalcostissubtractedfrom done.Whatisthenextstep? house. He buys a house for subtracting the total YYY
thenewvalueofthehouseifthenew Student:Thenextstepwould $80,000andthenputsin$50,000 costfromthenewvalue Relevant:
valueis$200,000andthetotalcostis betosubtractthetotalcostfrom in repairs. This increased the ofthehouse.$200,000- NNN
$130,000? the updated value to find the value of the house by 150%. $130,000 = <<200000- Notredundant:
profitmadebyJosh. Howmuchprofitdidhemake? 130000=70000>>$70,000. NYY
Notrevealing:
YNY
Tellmethisinstead:Whatisthetotal Tutor:65iscorrect,welldone. ElisehasbeensellingherDad’s Compute the total Grammatical:
amountofmoneyearnedinthesecond Whatisthenextstep? collectionof250booksforthree amount of money YYY
yearfromthesalesofbooksifeachwas Student:Weneedtomultiply years. Each book sells at 20$, earned in the second Relevant:
soldatthesameprice? thenumberofbookssoldinthe and she sold twice as many yearbymultiplyingthe YYY
secondyearbythepriceofeach booksinthefirstyearasshehas number of books sold Notredundant:
book,whichis$20. soldinthecurrentyear.There bythepriceperbook: NNN
arecurrently50unsoldbooks, <<65*20=1300>>1300 Notrevealing:
andhersalesnumberthisyear dollars. YYN
is45.What’sthetotalamount
ofmoneysheearnedinthesec-
ondyear?
Tellmethisinstead:Whatisthetotal Tutor:Whatshouldbethefirst Morgan’sdadsaidthatshehad Calculatethetotalcost Grammatical:
costperpersonforengaginginminigolf, step? $90budgetedforherbirthday per person for mini- YYY
purchasingarcadetokens,andenjoying Student:Thefirststepistosub- party.Shewantstomakesure golf,arcadetokens,and Relevant:
twogo-kartrides? tract$5forthearcadetokens she and her friends all get to twogo-kartrides.5+5 YYY
fromthe$90budget. play one round of mini-golf, +(10x2)=<<5+5+(10 Notredundant:
have$5inarcadetokens,and *2)=30>>30dollarsper YYY
gettoridethego-kartstwice. person. Notrevealing:
Aroundofmini-golfis$5.The NYN
Go-kartscost$10aride.How
manyfriendscansheinvite?
Table2:ExampleofHintslabeledbyHumanEvaluators.Y’sindicateapositivevote,N’sindicateanegativevote.SankalanPalChowdhury,VilémZouhar,MrinmayaSachan
Hint Recenthistory Question SolutionStep Rating
Thatisnotquiteright.HereisaHint: Tutor: Tell me this instead: Everymonth,Madelinehasto Add the monthly Grammatical:
Tocalculatethetotalmonthlyexpense Whatisthetotalmonthlyex- buyfood,treats,andmedicine costs of food, treats, YNY
forMadeline’sdog,youneedtosum penseforMadeline’sdogwhen forherdog.Foodcosts$25per and medicine to find Specific:
theindividualcostsforfood,treats,and combining the costs of food, week.Treatscost$20permonth. the total monthly ex- YNN
medicine.Considereachexpenseasa treats,andmedicine? Medicinecosts$100permonth. penses for Madeline’s Helpful:
separateamountandaddthemtogether Student:Oh,right.Soit’s$25+ HowmuchmoneydoesMade- dog. $100 (food per YNY
tofindthetotal.Remember,thefood $20+$100=$145permonth. linespendonherdogperyear month)+ $20 (treats Notrevealing:
expenseisatwo-digitnumberending ifthereare4weeksinamonth? per month) +$100 YYY
inzero,andboththetreatandmedicine (medicinepermonth)=
expenseshavethesameamount,which ⟨⟨100+20+100=220⟩⟩$220
isalsoatwo-digitnumberendingin permonth
zero
Thatisnotquiteright.HereisaHint:To Tutor: Tell me this instead: Brian’s friend Bobby has 5 Subtract 5 from the Grammatical:
determinethenumberofgamesBobby Whatisthenumberofgames fewer than 3 times as many tripled number of YYY
has, first identify Brian’s games and Bobbyhasifyoutakeaway5 videogamesasBriandoes.If Brian’s games to find Specific:
multiplythatamountbythree.Once fromthreetimesthenumberof Brianhas20videogamesbut out how many games YYY
youhavethatnumber,decreaseitby Brian’sgames? lost5rightbeforethecompari- Bobbyhas. Helpful:
fiveandyouwillfindoutBobby’stotal Student: If we take away 5 sonwasmade,howmanydoes 45-5=<<45-5=40>> YYY
games. fromthreetimesthenumberof Bobbyhave? 40videogames. Notrevealing:
Brian’sgames,weget3*20-5= NNY
55videogamesforBobby.
Table3:ExampleofPromptslabeledbyHumanEvaluators.Y’sindicateapositivevote,N’sindicateanegativevote.ScalingtheAuthoringofAutoTutorswithLargeLanguageModels
Listing1AnexamplesolutionandutterancespacefromtheMultiArithdatasetobtainedusingGPT4
"question": " Will made 104 dollars mowing lawns over the summer. If he spent 41 dollars buying new mower blades, how many
↩→ 9-dollar games could he buy with the money he had left? ",
"answer": 7,
"solution": {
"step": [
"Calculate the money left after Will spent on the mower blades by subtracting the cost of the blades from the initial amount
↩→ he made. 104 - 41 = <<104 - 41=63>>63 dollars left."
],
"follow-ups": [
{
"step": [
"Divide the money left by the cost of one game to find out how many games he can buy. 63 / 9 = <<63 / 9=7>>7 games. QED"
],
"follow-ups": [],
"hint": "How many games can he buy with the money he has left if one game costs nine dollars?",
"prompt": "To find out how many games he can purchase, determine the number of times the cost of one game goes into the
↩→ total amount of money he has left.",
"assertion": "He can buy 7 games with the money left if one game costs nine dollars."
},
{
"step": [
"Determine how many 9-dollar games Will can buy by dividing the money he has left by the cost of one game: 63 ÷ 9 = <<63
↩→ ÷ 9=7>>7 games. QED"
],
"follow-ups": [],
"hint": "How many 9 dollar games can Will buy with the money he has left?",
"prompt": "Consider how many times the cost of one game goes into the total amount of money Will has to spend.",
"assertion": "Will can buy 7 nine-dollar games with the money he has left."
}
],
"hint": "How much money is left after Will spends on mower blades if he starts with 104 dollars?",
"prompt": "Consider the initial amount Will had and subtract the cost of the mower blades he purchased to find out the
↩→ remaining amount.",
"assertion": "Will has 63 dollars left after spending on the mower blades."
}