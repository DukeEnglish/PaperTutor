Accepted for publication at ISER 2023. Please cite as follows:
M. H. Shaham, R. Ranjan, E. Kırda, T. Padır, “Design and Realization of a
Benchmarking Testbed for Evaluating Autonomous Platooning Algorithms,”
in International Symposium on Experimental Robotics, 2023.
Design and Realization of a
Benchmarking Testbed for Evaluating
Autonomous Platooning Algorithms
Michael H. Shaham, Risha Ranjan, Engin Kırda, and Taşkın Padır
Northeastern University, Boston, MA 02115, USA,
shaham.m@northeastern.edu,
https://robot.neu.edu/
Abstract. Autonomous vehicle platoons present near- and long-term
opportunitiestoenhanceoperationalefficienciesandsavelives.Thepast
30 years have seen rapid development in the autonomous driving space,
enablingnewtechnologiesthatwillalleviatethestrainplacedonhuman
driversandreducevehicleemissions.Thispaperintroducesatestbedfor
evaluatingandbenchmarkingplatooningalgorithmson1/10thscaleve-
hicleswithonboardsensors.Todemonstratethetestbed’sutility,weeval-
uate three algorithms, linear feedback and two variations of distributed
modelpredictivecontrol,andcomparetheirresultsonatypicalplatoon-
ing scenario where the lead vehicle tracks a reference trajectory that
changes speed multiple times. We validate our algorithms in simulation
to analyze the performance as the platoon size increases, and find that
the distributed model predictive control algorithms outperform linear
feedback on hardware and in simulation.
1 Introduction
1.1 Motivation
Autonomous driving technologies have the potential to improve safety, reduce
fuel emissions [20], reduce stress, and more [21]. In this work, we focus on au-
tonomous vehicle platoons, or groups of autonomous vehicles driving together,
which also have the potential to increase highway capacities and reduce travel
time.Sincethe1990s,therehavebeennumerouseffortstodemonstrateplatoon-
ingtechnologiesincludingtheCaliforniaPATHprogramdemonstration[25],the
2011 Grand Cooperative Driving Challenge [18], the Energy ITS project [26],
and the SARTRE platooning program [20]. Though these demonstrations high-
light the feasibility of platoons for the trucking industry or automated highway
systems, they often evaluate only a single algorithm, and there is still a need to
benchmark algorithms to compare safety and performance [17].
Validation platforms for autonomous driving algorithms on hardware have
been introduced, but these systems typically focus on autonomous racing [9,16,
27]orcoordinatedplanningandnetworkedcontrol[8,10].Withtheexceptionof
[11]whichfocusesonheavy-dutyvehicles,thereremainsalackoffocusonvehicle
4202
beF
41
]OR.sc[
1v33290.2042:viXra2 Michael H. Shaham et al.
platooning. This work introduces a research platform that builds on the widely
usedopensourceF1Tenthsystem[16]totestautonomousplatooningalgorithms.
Using our platform, we evaluate three different algorithms and perform further
analysis of these algorithms in simulation.
1.2 Related Work
The platooning problem was studied as early as the 1960s [12], but it was not
until the California PATH demonstration and associated research in the 1990s
when platooning began to receive considerable attention [25]. Since then, many
theoretical developments have provided insight into the performance of vehicle
platooning algorithms. These insights typically relate to how the information
flowtopology,distributedcontroller,andspacingpolicycontributetotheoverall
behavior [13].
For analysis of platoons, there are two common performance metrics used:
string stability [7,24] and (asymptotic) stability of the platoon. String stabil-
ity ensures disturbances, typically due to the head vehicle’s motion, will not
propagate down the string of vehicles in the platoon. An algorithm that is sta-
ble follows the usual control theoretic definition: subject to some disturbance,
the vehicles in the platoon will eventually be able to reach zero error. Platoons
typically use two different inter-vehicle spacing policies: (1) constant distance
headway (CDH) where each vehicle maintains a constant distance to its prede-
cessor and (2) constant time headway (CTH) where each vehicle maintains a
distance based on the time required to reach its predecessor.
Linear feedback controllers have been widely used to obtain insightful the-
oretical results. In [28], the authors analyze the effect of the information flow
topology on the stability of a platoon using a linear feedback controller and a
CDH policy, and show how performance degrades significantly as platoon size
increases. The type of controller along with the spacing policy can also signif-
icantly impact the performance of a platoon. In [22], authors prove that the
combination of a linear feedback policy, a predecessor follower topology (each
vehicle has access to information only from the preceding vehicle), and a CDH
policyleadstostringinstability.However,underthesameconditionsbutwitha
CTHpolicy,stringstabilityisguaranteed[15].Similarly,in[1],thedecentralized
structure of the platooning problem and linear quadratic regulator theory are
exploitedtodesignastringstablelinearfeedbackcontrollerusingaCTHpolicy.
Byassumingvehiclescancommunicatewithoneanother,itispossibletode-
signdistributedmodelpredictivecontrol(DMPC)algorithms.In[5],theauthors
presentthefirstDMPCalgorithmthatguaranteesbothasymptoticstabilityand
stringstability.Buildingonthis,theauthorsin[29]guaranteestability(butnot
string stability) of the platoon without following vehicles knowing a priori the
desired set point (velocity) of the platoon. Both [5] and [29] assume vehicles
share their planned trajectory with neighboring vehicles, which is used at the
next timestep. More recently, [19] develop a DMPC method that allows vehicles
to share their true optimal planned trajectory multiple times at each timestep,
while also using collision constraints to guarantee safety.Platoon Testbed 3
1.3 Problem Statement
A platoon consists of a string of vehicles following one another. The goal of the
platoonistohaveeachvehicledriveatthesamespeedastheleaderwhilemain-
taining a desired spacing relative to its neighbors (we focus on a CDH policy).
Most platooning research in the literature contribute theoretical results and a
simulationexperimenttovalidatethetheory,withoutperforminganyvalidation
on hardware (and often without comparing performance to other algorithms).
To evaluate platooning controllers, a benchmarking testbed needs to be devel-
opedtocompareresultsandanalyzeadvancesandtrade-offs.Thetestbedshould
use vehicles equipped with sensors that provide inter-vehicle sensing and com-
munication. The vehicles must also be capable of following trajectories typical
of highway-driving scenarios and drive at a sufficiently large range of speeds to
track these trajectories.
2 Technical Approach
2.1 Hardware
The vehicles (Figure 1) used in our experi-
lidar Pozyx
ments are modified versions of the standard UWB
F1Tenth vehicle [16]. We introduce the follow- fixed
suspension
ing modifications: using an Intel NUC instead
of an NVIDIA Jetson Xavier NX for faster
compute, adding an AS5047P magnetic mo-
tor position sensor for better low-speed per-
motor controller
formance, using fixed suspension rods to re-
Intel NUC
ducejitterduetothesuspension,andaddinga
Pozyx ultra-wideband (UWB) radio frequency Fig.1.Oneofthevehiclesusedin
device to obtain inter-vehicle distance mea- our platoon, which is a modified
surements.ThePozyxUWBdeviceisreported version of the F1Tenth vehicle.
to be accurate up to ±10 cm. In our experiments, we have found its error to be
roughlyGaussianwithastandarddeviationof4.5cm.Allperception,planning,
and control computations are completely decentralized and are performed on
the Intel NUC using ROS 2 [14]. The testing environment used for hardware
experiments is a 10.2 m×6.6 m reconfigurable, oval race track.
Sincethispaperfocusesonmulti-vehiclelongitudinalcontrol,webrieflysum-
marize the local planning each vehicle performs for lateral control. Each vehicle
is equipped with a 2D lidar—either an RPLiDAR S2 (follower vehicles) or a
Hokuyo UST-10LX (leader vehicle). The lidar provides data in the form of a
pointcloud, which we segment using DBSCAN [6] to find the sets of points cor-
responding to the left and right walls. The points associated with the left and
rightwallsarethenusedtoestimateapolynomialcenterline(incoordinatesrel-
ative to the local vehicle’s frame), which is passed as input to the pure pursuit
algorithm [2]. Note that all planning is performed locally, i.e., the vehicles have
no notion of global position within the course; they only know their relative
position to their predecessor in the platoon.4 Michael H. Shaham et al.
2.2 Control Algorithms
The platoon consists of N +1 vehicles, indexed by 0,1,...,N, where vehicle
0 is the leader. We analyze and compare a linear feedback and two DMPC
controllers using a predecessor follower topology, depicted in fig. 2. We use a
constant spacing policy, and the goal of each following vehicle is to match the
velocity of and maintain a constant distance to its predecessor, i.e.,
p (t)→p (t)−d
i i−1 des as t→∞, for all i=1,...,N (1)
v (t)→v (t)
i i−1
where p and v are position and velocity, respectively, and d is the desired
des
inter-vehicle distance. Equation (1) guarantees asymptotic stability—we do not
focusonstringstabilityinthiswork.Notethatifeq.(1)isachieved,eachvehicle
also matches the desired speed of and the desired spacing relative to the leader.
0 1 2 ··· N
Fig.2. Predecessor follower topology. The directed edge i→j indicates vehicle j has
access to (or receives information from) vehicle i. Vehicles are indexed by 0,1,...,N.
Vehicle dynamics. We model each vehicle’s dynamics as
x (k+1)=A x (k)+B u (k)
i i i i i
(cid:20) 1 ∆t (cid:21) (cid:20) 0 (cid:21) i=0,...,N (2)
A = B =
i 01− ∆t i ∆t
τi τi
where k is the discrete sampling instance, ∆t is the discretization time and τ
i
is the inertial delay of the longitudinal dynamics. The state x = (p ,v ) is the
i i i
position and velocity and the control input u is the desired velocity. It is more
i
commontouseadynamicsmodelwherethestatex includesthevehicle’saccel-
i
erationandtheinputu isthedesiredacceleration.However,wehavefoundthe
i
F1Tenthvehiclesperformbetterwhenspecifyingadesiredvelocity(correspond-
ing to motor revolutions per minute) instead of an acceleration (corresponding
to motor current).
Linear feedback algorithm. In the linear feedback case, each vehicle mea-
sures or receives the distance to and velocity of its predecessor. The distance
measurements are obtained via the UWB device and the speed measurements
are shared using ROS 2 and Wi-Fi. Real vehicles are commonly equipped with
radar or a similar sensor to estimate the distance and speed of neighboring ve-
hicles. The desired velocity input for the linear feedback controller is selected
using
u (t)=k (p (t)−p (t)+d )+k (v (t)−v (t)), i=1,...,N
i p i−1 i des v i−1 i
where k ,k > 0 are predefined gains. See [28] for further details and stability
p v
analysis of the continuous-time version of this controller when using the typical
acceleration-input version of the dynamics. The results in [28] can be extended
to systems using the dynamics given by eq. (2).Platoon Testbed 5
Distributed model predictive control algorithms. For the DMPC con-
trollers, at each timestep t, each vehicle receives the assumed trajectory of its
predecessor, which is calculated at the previous timestep t−1. Let xa(0),...,
i
xa(H) denote the assumed trajectory over the planning horizon H for vehicle i
i
at timestep t. Then at each timestep t, the DMPC controller solves
minimize (cid:80)H−1l (cid:0) xp(k),up(k),xa(k),xa (k)(cid:1)
up,xp k=0 i i i i i−1
i i
subject to xp(0)=x (t)
i i
xp(k+1)=A xp(k)+B up(k), k =0,...,H −1
i i i i i
|vp(k+1)−vp(k)|≤∆t ·a , k =0,...,H −1 (3)
i i i,max
v ≤vp(k)≤v , k =H,...,H
i,min i i,max
xp(H)=xa (H)−d˜
i i−1 des
up(H −1)=va (H)
i i−1
whered˜ =(d˜,0)∈R2.Thisisthesameformulationproposedin[29]butwith
des
slightly altered constraints to account for the dynamics model we use.
We analyze two different options for the cost function l . The first uses the
i
squared weighted 2-norm to penalize errors:
(cid:13) (cid:13)2
l (k)=∥xp(k)−xa(k)∥2 +(cid:13)xp(k)−xa (k)+d˜ (cid:13) +∥up(k)−u˜∥2 (4)
i i i Fi (cid:13) i i−1 des(cid:13)
Gi
i Ri
where F ,G ,R ≻0 and ∥z∥2 =zTQz. The second option uses the 1-norm:
i i i Q
(cid:13) (cid:13)
l (k)=s ∥xp(k)−xa(k)∥ +q (cid:13)xp(k)−xa (k)+d˜ (cid:13) +r ∥up(k)−u˜∥ (5)
i i i i 1 i(cid:13) i i−1 des(cid:13) i i 1
1
where s ,q ,r > 0 are scalar variables weighting each objective. The first term
i i i
inthesecostfunctions,whichwerefertoasthemovesuppressionterm,penalizes
thedeviationbetweenvehiclei’spredictedandassumedtrajectories.Thesecond
term, which we refer to as predecessor relative error term, penalizes the error
betweenvehiclei’spredictedtrajectoryanditspredecessor’sassumedtrajectory.
We will refer to the DMPC algorithm (3) using eq. (4) as squared 2-norm (or
∥·∥2)DMPCandthealgorithmusingeq.(5)as1-norm (or∥·∥ )DMPC.Note
2 1
thatthetimestep-shiftedversionoftheoptimaltrajectorycomputedattimestep
tisusedastheassumedtrajectoryfortimestept+1.See[29]forfurtherdetails
about the implementation of the algorithm.
The inequality constraints of eq. (3) enforce velocity and acceleration limits.
The equality constraints of eq. (3) serve two purposes: (1) ensure dynamic fea-
sibilityofthetrajectoryand(2)enforceterminalconstraintstoensurerecursive
feasibility of the DMPC controller. If we denote the solution of this optimiza-
tion problem as u⋆, then the DMPC controller implements u⋆(0) and repeats
i i
this process at the next timestep after receiving the assumed trajectory of its
predecessor. Since our controller uses the desired velocity as the input, we use
u˜ = v (t), so each vehicle penalizes velocity input that deviate from its current
i
velocity.6 Michael H. Shaham et al.
TheDMPCalgorithmweuseisbasedontheformulationusedin[29],which
uses the cost function
(cid:13) (cid:13)
l (k)=∥xp(k)−xa(k)∥ +(cid:13)xp(k)−xa (k)+d˜ (cid:13) +∥up(k)−u˜∥ . (6)
i i i Fi (cid:13) i i−1 des(cid:13)
Gi
i Ri
We will refer to this as 2-norm DMPC. The theoretical basis for using the
weighted 2-norm, which is provided in [29], is given in the following theorem,
which is a slight adaptation of theorem 5 from [29].
Theorem 1. Suppose a platoon uses a predecessor follower topology, and each
vehicle has dynamics given by eq. (2). If each vehicle uses the DMPC controller
that requires solving eq. (3) with the cost function given by eq. (6), then the
platoon’s dynamics are asymptotically stable (i.e., eq. (1) is achieved) if
F ⪰G , i=0,1,...,N −1.
i i+1
Recall that F is related to the move suppression term of the ith vehicle,
i
and G is the predecessor relative error term of the ith vehicles predecessor.
i+1
Intuitively, this result says that each vehicle must place at least as much weight
on maintaining its assumed trajectory as its predecessor does. Theorem 1 was
derived for a nonlinear vehicle dynamics model that is equivalent to a linear
dynamicsmodel(wherethestateincludestheacceleration)afterusingthefeed-
back linearization technique. However, it is not too difficult to adjust the proof
to work for the dynamics given by eq. (2) with the constraints in eq. (3).
Thoughnotformallyanalyzedin[29],itisrelativelyeasytoextendtheorem1
tothecaseofthe1-normcostfunctiongivenbyeq.(5).Theproofin[29]requires
onlytheuseofnorminequalities,andthusalsoappliestothecaseofthe1-norm,
but with minor adjustments to handle the scalar terms instead of the weight
matrices.Withthatsaid,weextendtheorem1tothecaseofthe1-normDMPC
withthefollowingsufficientconditiontoguaranteeplatoonasymptoticstability:
s ≥q , i=0,1,...,N −1. (7)
i i+1
Sofar,wehavenotbeenabletodetermineanysufficientconditionsthatprove
the DMPC algorithm with the squared 2-norm cost function (4) is stable. Our
results, however, will show that the algorithm performs well in practice, so we
believeitisworthwhiletoconsiderevenifitisnot(yet)provablystable.Further,
wedecidetousethecostfunctionsgivenbyeq.(4)andeq.(5)asopposedtothe
eq. (6) because these cost functions lead to optimization problems that can be
formulated as a quadratic program (QP) or a linear program (LP), respectively.
These formulations allows us to plan over a much larger time horizon (H =100
in our experiments) and alleviate feasibility issues due to the terminal equality
constraints. For the weighted 2-norm cost function (6), we were unable to scale
the time horizon above roughly H = 20, and ran into feasibility issues when
testingonhardwarewherethecontrollerneedstorunatarateofatleast10Hz.
To solve the optimization problems, we used CVXPY [3] with OSQP [23] (for
the QP) or with ECOS [4] (for the LP). With these tools, we were able to solve
the optimization problem (3) at rates faster than 100Hz.Platoon Testbed 7
3 Experimental Results and Insights
3.1 Hardware results
To compare the performance of the two DMPC controllers and the linear feed-
back controller, we conducted an experiment where the lead vehicle starts at
0m/s velocity, accelerates to 2m/s, twice alternates accelerating to 3.5m/s and
back down to 2m/s, before finally coming to a stop. The experiment was de-
signed to test how well the platoon handles sudden changes in speed (e.g., as in
highway driving due to speed limit changes) and its ability to follow the leader
from start to stop. Figure 3 shows results from this experiment with four vehi-
cles (one leader and three followers) for each of the three controllers. We used a
longitudinal time delay of τ = 0.3 for each vehicle (determined experimentally
i
using a least-squares regression on experimental data) and a desired spacing of
1m. For each of the DMPC algorithms, we used the identity matrix (weighting
matrices in eq. (4)) or the scalar 1 (scalar weights in eq. (5)) for all controller
parameters, which satisfies conditions given in theorem 1 and eq. (7). For lin-
ear feedback, we used k = 1 and k = 2, as we found these values gave the
p v
smoothest vehicle trajectories during testing.
Platoon trajectories: Hardware comparison with 4 vehicles
|| ||2
2
DMPC || ||1 DMPC Linear feedback
100
50
vehicle
0
0 1
2
3.5 3
2.0
0.0
0 20 40 0 20 40 0 20 40
time [s] time [s] time [s]
Fig.3.Resultsdepictingthefour-vehicleplatoontrajectorieswhenusingthreedifferent
algorithmsonthehardwaredescribedinsection2.1.Thecolumnsshowtheperformance
ofthesquared2-normDMPC,1-normDMPC,andthelinearfeedbackalgorithms.The
positionoftheleadvehiclewascalculatedbyintegratingitsvelocity,andthepositions
ofthefollowingvehicleswascalculatedusingtheprecedingvehicle’spositionoffsetby
the distance measurement from the Pozyx UWB.
To quantitatively compare the performance between each of the three con-
trollers, we repeated the experiment shown in fig. 3 10 times for each controller,
completingatotalof30experiments.Weusetherootmeansquareerror(RMSE)
of the platoon’s spacing and velocity trajectories to compare the three con-
trollers.Thespacingandvelocityerrorsaregivenbyp −p +d andv −v ,
i i−1 des i i−1
]m[
noitisop
]s/m[
yticolev8 Michael H. Shaham et al.
respectively. For each experiment, we calculate the mean spacing and velocity
RMSE for each following vehicle. We then calculated the mean and standard
deviation of these mean RMSE values over the ten experiments, and calculated
a 95% confidence interval for the mean RMSE of each vehicle’s position and ve-
locity. The results are shown in fig. 4. As we can see, the two DMPC controllers
clearly outperform the linear feedback controller.
Mean RMSE with 95% confidence intervals
Spacing error Velocity error
0.5
Method
0.4
|| ||2 DMPC
2
0.3 || ||1 DMPC
Linear feedback
0.2
1 2 3 1 2 3
Vehicle index Vehicle index
Fig.4. A comparison of results over ten trials of each algorithm.
In terms of spacing error, the squared 2-norm DMPC performs better than
the 1-norm DMPC for the two furthest followers, and the two algorithms have
comparable performance for the first follower. The 1-norm DMPC controller
performedthebestintermsofvelocityerror.Onethingouranalysisonhardware
is unable to tell us is how well these algorithms scale as the size of the platoon
increases. To investigate this issue, we conducted experiments in simulation,
discussed below.
3.2 Simulation results
To analyze how well these algorithms perform as the size of the platoon in-
creases, we simulate a platooning experiment with N = 100 following vehicles.
Intheexperiment,theleaderfollowsareferencetrajectorythatstartsat20m/s,
accelerates to 25m/s and waits for 30 seconds, then decelerates back down to
20m/s. Trajectory results for a few vehicles are shown in fig. 5. We use τ =0.3
i
for each vehicle and set the desired spacing at 5 meters. We also used the same
controller parameters that were used in the hardware experiments for the simu-
lation study. For all simulation experiments, we add zero-mean Gaussian noise
withacovarianceof.3I tothedynamicsandwithastandarddeviationof4.5cm
totheinter-vehiclespacingsensing(tomatchtheerrorencounteredbythePozyx
UWB device).
Figure 5 shows that the two DMPC algorithms are able to remain close to
the desired platoon trajectory without requiring unsafe trajectories. The 100th
vehicle in the platoon for each of these controllers reaches a peak velocity of
almost 28m/s before settling to the desired velocity of 25m/s during the ac-
celeration portion of the experiment. They also perform well when decelerating.
ESMRPlatoon Testbed 9
Platoon trajectories: simulation comparison with 100 vehicles
2 2 DMPC 1 DMPC Linear feedback
1000 1000 1000
500 500 500
vehicle
0 0 0 1
25
500 500 500 50
27.5 27.5 200 75
100
25.0 25.0
ref
22.5 22.5 0
20.0 20.0
0 20 40 0 20 40 0 20 40
time [s] time [s] time [s]
Fig.5. Results from one simulated experiment with a 100-vehicle platoon. The refer-
ence velocity trajectory the leader follows is shown as the black curve in the velocity
plots (bottom row). In the position plots, the vehicle 1 trajectory is indistinguishable
fromthereference.Notethedifferenceiny-axisscalesforthebottomrowofplots.We
also plot the desired positions of each vehicle relative to the leader as faded curves in
the top row, and this is most visible in the linear feedback case.
Despitethis,itisstillclearthattheperformancerelativetothetruedesiredgoal
ofmaintainingtheleader’svelocityprofiledegradesaswemovefurtherdownthe
platoon (since platoons further from the leader need to achieve higher velocities
to maintain performance). Though it is not shown in these figures, when using
the DMPC controllers, each of the vehicles maintained a spacing error of less
thanroughlyonemeter,meaningthevehiclesnevercameclosetocrashingwhen
usingadesiredspacingof5meters.Itisnotcleartowhatextentwewouldneed
to scale the platoon size N before seeing a collision between two vehicles under
this problem setup.
Theperformanceofthelinearfeedbackalgorithm,however,quicklydegrades
astheplatoonsizeincreases.Thoughwesawthatperformanceonhardwarewas
reasonable,wecanseefromthepositiontrajectoriesthatifwecontinuetoallow
the platoon size to increase, the vehicles will crash if the desired spacing is not
largeenough.Notethatweallowedthelinearfeedbackvehiclestoapplyanyun-
constrainedinputandsetnoboundsonthestate.Thus,the100thvehicleinthe
platoonwasallowedtocommandlargecontrolinputsinanattempttostabilize.
Distributed linear feedback controllers using a CTH policy would alleviate the
issues we see here, but we do not investigate this problem setting in this work.
Similar to the hardware experiments, we repeat the simulation experiment
tentimesandinvestigatetheaverageperformanceofeachvehicleintheplatoon
with respect to RMSE. Figure 6 shows the results of this analysis. In line with
the results in [28], the performance of linear feedback quickly degrades as the
size of the platoon increases. In fact, performance degrades quadratically as the
platoon size N increases, and would not be practical above roughly N = 25.
]m[
noitisop
]s/m[
yticolev10 Michael H. Shaham et al.
1 1
.5 .5
0 0
Fig.6. Results showing the mean RMSE calculated after repeating the experiment
showninfig.5tentimes.ThezoomedinportionofeachplotshowstheDMPCresults
more clearly and the platoon size at which linear feedback begins to diverge.
Optimal control methods could be used to select better gain values, but for the
sake of comparison we used the same values in simulation and on hardware.
Unlikethelinearfeedbackcontroller,theDMPCcontrollerperformancedoes
not degrade significantly as the platoon size increases up to N = 100 following
vehicles. This is evident in the zoomed-in plots of fig. 6, where we can see the
RMSE does not get worse as we move to the end of the platoon. In the spacing
RMSE, however, we can see that the performance appears to be trending worse
as we move further down the platoon, but this trend may not become dramatic
enoughuntiltheplatoonbecomesmuchlarger,potentiallybeyondpracticalpla-
toon sizes. Finally, it is interesting to note that the better performance of the
1-norm compared to the squared 2-norm DMPC controller on hardware did not
translate to simulation.
4 Conclusion
Inthiswork,weintroducedabenchmarkingtestbedtoevaluateautonomouspla-
tooning algorithms. We introduced two DMPC algorithms and compared their
performance to a baseline linear feedback algorithm. Using our benchmarking
testbed, we showed that the DMPC algorithms outperform the linear feedback
algorithm for a platoon of four vehicles. We performed further experiments in
simulation to demonstrate that not only do the DMPC algorithms perform bet-
ter on hardware, they also scale well to increases in size of the platoon.
Future work will consider how we can improve upon these methods both in
theory and practice. Theoretically, there is a need to ensure the DMPC algo-
rithms we use are string stable, and not just asymptotically stable. This may
not be possible with the current formulation, but a similar formulation with a
CTH policy has potential. In this work, we arbitrarily select desired distances,
but future research could investigate how these distances can be rigorously de-
termined to ensure safety (i.e., no collisions) and performance (i.e., small inter-
vehicle spacing). Finally, future research may explore the benefits of incorpo-
rating provably safe machine learning methods and benchmarking against the
control-theoretic methods used in this paper.Platoon Testbed 11
Acknowledgements
ResearchwassponsoredbytheDEVCOMAnalysisCenterandwasaccomplished
under Cooperative Agreement Number W911NF-22-2-001. The views and con-
clusions contained in this document are those of the authors and should not be
interpreted as representing the official policies, either expressed or implied, of
the Army Research Office or the U.S. Government. The U.S. Government is au-
thorizedtoreproduceanddistributereprintsforGovernmentpurposesnotwith-
standing any copyright notation herein.
References
1. A.A.Alam,A.Gattami,andK.H.Johansson.Suboptimaldecentralizedcontroller
design for chain structures: Applications to vehicle formations. In IEEE Confer-
enceonDecisionandControlandEuropeanControlConference,pages6894–6900,
Orlando, FL, USA, Dec. 2011. IEEE.
2. R.C.Coulter. Implementationofthepurepursuitpathtrackingalgorithm. Tech-
nical report, Robotics Institute, Carnegie Mellon University, 1992.
3. S. Diamond and S. Boyd. Cvxpy: A python-embedded modeling language for
convexoptimization.TheJournalofMachineLearningResearch,17(1):2909–2913,
2016.
4. A. Domahidi, E. Chu, and S. Boyd. Ecos: An socp solver for embedded systems.
In 2013 European control conference (ECC), pages 3071–3076. IEEE, 2013.
5. W. B. Dunbar and D. S. Caveney. Distributed receding horizon control of vehicle
platoons:Stabilityandstringstability. IEEE Transactions on Automatic Control,
57(3):620–633, 2012.
6. M. Ester, H.-P. Kriegel, J. Sander, and X. Xu. A density-based algorithm for dis-
coveringclustersinlargespatialdatabaseswithnoise. InProceedingsoftheSecond
InternationalConferenceonKnowledgeDiscoveryandDataMining,KDD’96,page
226–231. AAAI Press, 1996.
7. S. Feng, Y. Zhang, S. E. Li, Z. Cao, H. X. Liu, and L. Li. String stability for
vehicular platoon control: Definitions and analysis methods. Annual Reviews in
Control, 47:81–97, Mar. 2019.
8. N. Hyldmar, Y. He, and A. Prorok. A fleet of miniature cars for experiments in
cooperativedriving.In2019InternationalConferenceonRoboticsandAutomation
(ICRA), pages 3238–3244, 2019.
9. S.Karaman,A.Anders,M.Boulet,J.Connor,K.Gregson,W.Guerra,O.Guldner,
M.Mohamoud,B.Plancher,R.Shin,andJ.Vivilecchia. Project-based,collabora-
tive, algorithmic robotics for high school students: Programming self-driving race
carsatmit. In2017 IEEE Integrated STEM Education Conference (ISEC),pages
195–203, 2017.
10. M. Kloock, P. Scheffe, J. Maczijewski, A. Kampmann, A. Mokhtarian,
S.Kowalewski,andB.Alrifaee. Cyber-physicalmobilitylab:Anopen-sourceplat-
formfornetworkedandautonomousvehicles.In2021EuropeanControlConference
(ECC), pages 1937–1944, 2021.
11. H.Lee,J.Park,C.Koo,J.-C.Kim,andY.Eun. Cyclops:Openplatformforscale
truck platooning. In 2022 International Conference on Robotics and Automation
(ICRA), pages 8971–8977. IEEE, 2022.12 Michael H. Shaham et al.
12. W. Levine and M. Athans. On the optimal error regulation of a string of moving
vehicles. IEEE Transactions on Automatic Control, 11(3):355–361, 1966.
13. S. E. Li, Y. Zheng, K. Li, and J. Wang. An overview of vehicular platoon control
under the four-component framework. In 2015 IEEE Intelligent Vehicles Sympo-
sium (IV), pages 286–291, 2015.
14. S. Macenski, T. Foote, B. Gerkey, C. Lalancette, and W. Woodall. Robot op-
erating system 2: Design, architecture, and uses in the wild. Science Robotics,
7(66):eabm6074, 2022.
15. G.J.L.Naus,R.P.A.Vugts,J.Ploeg,M.J.G.vandeMolengraft,andM.Stein-
buch. String-stable cacc design and experimental validation: A frequency-domain
approach. IEEE Transactions on Vehicular Technology, 59(9):4268–4279, 2010.
16. M. O’Kelly, H. Zheng, D. Karthik, and R. Mangharam. F1tenth: An open-source
evaluation environment for continuous control and reinforcement learning. In
NeurIPS 2019 Competition and Demonstration Track, pages 77–89. PMLR, 2020.
17. T. Padir. Bright: Benchmarking research infrastructure for generalized hetero-
geneous teams. In Robotics Research - The 19th International Symposium ISRR
2019, Hanoi, Vietnam, October 6-10, 2019, volume 20 of Springer Proceedings in
Advanced Robotics, pages 805–812. Springer, 2019.
18. J. Ploeg, S. Shladover, H. Nijmeijer, and N. van de Wouw. Introduction to the
special issue on the 2011 grand cooperative driving challenge. IEEE Transactions
on Intelligent Transportation Systems, 13(3):989–993, 2012.
19. Z. Qiang, L. Dai, B. Chen, and Y. Xia. Distributed Model Predictive Control for
Heterogeneous Vehicle Platoon With Inter-Vehicular Spacing Constraints. IEEE
Transactions on Intelligent Transportation Systems, 24(3):3339–3351, Mar. 2023.
20. T.Robinson,E.Chan,andE.Coelingh. Operatingplatoonsonpublicmotorways:
An introduction to the sartre platooning programme. In 17th world congress on
intelligent transport systems, volume 1, page 12, 2010.
21. D. Rojas Rueda, M. J. Nieuwenhuijsen, H. Khreis, and H. Frumkin. Autonomous
vehiclesandpublichealth. AnnuRevPublicHealth.2020Apr2;41:329-45,2020.
22. P. Seiler, A. Pant, and K. Hedrick. Disturbance propagation in vehicle strings.
IEEE Transactions on Automatic Control, 49(10):1835–1842, 2004.
23. B.Stellato,G.Banjac,P.Goulart,A.Bemporad,andS.Boyd. Osqp:Anoperator
splittingsolverforquadraticprograms. Mathematical Programming Computation,
12(4):637–672, 2020.
24. D. Swaroop and J. Hedrick. String stability of interconnected systems. IEEE
Transactions on Automatic Control, 41(3):349–357, 1996.
25. H.-S.Tan,R.Rajamani,andW.-B.Zhang. Demonstrationofanautomatedhigh-
way platoon system. In Proceedings of the 1998 American Control Conference.
ACC (IEEE Cat. No.98CH36207), volume 3, pages 1823–1827 vol.3, 1998.
26. S.Tsugawa,S.Kato,andK.Aoki. Anautomatedtruckplatoonforenergysaving.
In 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems,
pages 4109–4114, 2011.
27. G.Williams,P.Drews,B.Goldfain,J.M.Rehg,andE.A.Theodorou. Aggressive
driving with model predictive path integral control. In 2016 IEEE International
Conference on Robotics and Automation (ICRA), pages 1433–1440, 2016.
28. Y. Zheng, S. Eben Li, J. Wang, D. Cao, and K. Li. Stability and scalability of
homogeneousvehicularplatoon:Studyontheinfluenceofinformationflowtopolo-
gies. IEEETransactionsonIntelligentTransportationSystems,17(1):14–26,2016.
29. Y. Zheng, S. E. Li, K. Li, F. Borrelli, and J. K. Hedrick. Distributed model pre-
dictive control for heterogeneous vehicle platoons under unidirectional topologies.
IEEE Transactions on Control Systems Technology, 25(3):899–910, 2017.