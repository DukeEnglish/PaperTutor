Strategic Contract Negotiation in Financial Networks
Akhil Jalan Deepayan Chakrabarti
UT Austin UT Austin
akhiljalan@utexas.edu deepay@utexas.edu
February 15, 2024
Abstract
How can firms optimally negotiate bilateral contracts with each other in a financial network? Every
firmseekstomaximizetheutilityitgainsfromitsportfolioofcontracts. Wefocusonmean-varianceutil-
ities,whereeachfirmhasitsownbeliefsabouttheexpectedreturnsofthecontractsandthecovariances
between them [Mar52]. Instead of revealing these beliefs, a firm may adopt a different negotiating posi-
tion,seekingbettercontractterms. Weformulateacontractnegotiationprocessbywhichsuchstrategic
behavior leads to a network of contracts. In our formulation, any subset of firms can be strategic. The
negotiatingpositionsofthesefirmscanformNashequilibria,whereeachfirm’spositionisoptimalgiven
the others’ positions.
We give a polynomial-time algorithm to find the Nash equilibria, if they exist, and certify their
nonexistenceotherwise. Weexploretheimplicationsofsuchequilibriaonseveralmodelnetworks. These
illustrate that firms’ utilities can be sensitive to their negotiating position. We then propose trade
deadlines as a mechanism to reduce the need for strategic behavior. At the deadline, each firm can
unilaterallycancelsomeorallofitscontracts,forapenalty. Inourmodelnetworks,weshowthattrade
deadlines can reduce the loss of utility from being honest. We empirically verify our insights using data
on international trade between 46 large economies.
1
4202
beF
31
]CO.htam[
1v97780.2042:viXraContents
1 Introduction 3
1.1 Our Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
1.2 Paper Organization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
2 Background 6
3 Strategic Negotiations 7
4 Insights and Analysis 12
4.1 Two Agents That Can Self-Invest . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
4.2 One Investor and Two Hedge Funds . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
5 Trade Deadline 16
5.1 Trade Deadline Formulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
5.2 Strategic Negotiation for a Single Agent under the Trade Deadline . . . . . . . . . . . 18
6 Experimental Results 20
7 Related Work 21
8 Conclusion 23
9 Proofs 24
9.1 Proof of Theorem 3.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
9.2 Proof of Theorem 5.3. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
9.3 Proof of Theorem 5.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
A Additional Proofs 32
A.1 Proof of Lemma 3.6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
A.2 Non-Convexity of Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
A.3 Proof of Theorem 4.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
A.4 Exact Formulas for Theorem 5.8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
21 Introduction
We consider negotiations between agents to form a network of bilateral contracts. An example
network is the US over-the-counter (OTC) market for derivatives. Contracts in the OTC network
had a notional value of over 600 trillion USD in 2022 [ISD23]. Yet, such markets are less well-
understoodthanpublicmarkets[GY16;Eis+23]. Thisisbecausethecontractsarenotstandardized,
and deal with products not listed on exchanges. Each contract is negotiated between two agents,
such as banks and hedge funds, and tailored to their needs. Another example is that of bilateral
trade networks between countries. Countries may trade in unique products (e.g., arms, technology)
for which contracts must be negotiated on a case-by-case basis. Agents with stronger negotiating
positions can extract better contract terms in such networks. We aim to model and analyze the
effect of strategic behaviors in this setting.
We model the agents as utility maximizers who have heterogeneous beliefs. Let Alice and Bob
denotetwoagentsinalargernetwork. Then, Alice’sutilitydependsonherprivatebeliefsaboutthe
risk/reward profile of her portfolio of contracts with all other agents. But Alice cannot unilaterally
set the terms of her contract with Bob. Instead, Alice and Bob must negotiate a contract agreeable
to both. The final contract depends on Alice’s and Bob’s claims about the contract’s perceived
benefits, which we call their negotiating positions. Now, Alice’s negotiating position with Bob also
affects Alice’s other contracts. The reason lies in the utility-maximizing behavior of agents. Since
Bob seeks an optimal portfolio of contracts, any changes in the contract with Alice affects Bob’s
contracts with others (e.g. Eve). In turn, Eve’s contract with Alice is also affected. Hence, Alice
mustconsiderthenetworkeffectsofhernegotiatingposition. Thismotivatesthefollowingproblem:
What is the optimal negotiating position of each agent in a network?
Algorithm: We present an efficient algorithm to find the optimal negotiating positions for any
chosen subset of agents, or to report when no optimal solution exists. Our algorithm assumes that
the agents use heterogeneous mean-variance utilities [Mar52; LM79; Pul83; EW09; Sim14]. Under
the mean-variance utility, there is a stable network of contracts that satisfies all agents [JCS24].
This network depends on the agents’ negotiating positions. However, [JCS24] assume that agents
reveal their private beliefs during contract negotiations. In contrast, we study agents that deceive
3others to gain an advantage. The resulting network can increase an agent’s utility, but only up to a
point. We show that deceptions only provide bounded utility, even if the other agents’ negotiating
positions are known. In practice, an agent will only know the others’ positions after choosing
her position. So, she can choose the optimal negotiating position assuming that others also make
optimal choices. Hence, the optimal set of negotiating positions is a Nash equilibrium among
deceptions. Our algorithm finds this Nash equilibrium if it exists.
Insights: The Nashequilibriarevealsome surprisinginsights even insimple networks. For instance,
consider a two-agent network. We show that the agents both have lower utility when they are both
strategic than when they are both honest. This is because if one agent is honest, the other agent
can benefit at her expense by being strategic. The Nash equilibrium has lower utility for both
agents, but neither has an incentive to deviate.
As another example, consider the three-agent network of two hedge funds trading with an
investor. We show that utilities are very sensitive to which agents act strategically. Suppose the
investor is honest and the hedge funds are strategic. Then, the funds can extract large utility
from the investor, who is left with nearly zero utility. But if the investor is also strategic, she can
force the hedge funds to compete and gains utility at their expense. Indeed, if all three agents are
strategic, the investor is better off than if all are honest. The opposite is true for the hedge funds.
The above result shows why naive investors may choose to stay away from bilateral markets.
Evensophisticatedinvestorsmaystruggle, sincetheNashsolutioncandependontheprivatebeliefs
of other agents. Two hedge funds in the same market may well have such knowledge about each
other, but an investor may not. To encourage more participants to join the market, we need to
reduce the sensitivity of outcomes to strategic behavior. This motivates our second question:
Can we design a mechanism that reduces the need for strategic behavior?
Mechanism: TheusualVickrey-Clarke-Grovemechanismforbilateraltradeneedsamarketownerto
subsidizehonesty[Nis+07]. InfinancialnetworkssuchasthoseforOTCderivativesorinternational
trade, there is no market owner. Hence, the applicability of such mechanisms is unclear. Instead,
we present a different mechanism: namely, trade deadlines.
Themechanismoperatesasfollows. First,allagentschoosetheirnegotiatingpositions,asbefore.
These positions determine the network of contracts. Second, each agent observes the network and
4independentlydecideswhichcontractstoveto. Third,allvetodecisionsaresimultaneouslyrevealed
at a global trade deadline. A contract is canceled if either party vetoes it.
Under the trade deadline, each agent worries about the effect of contract cancellations on her
portfolio. For instance, an agent i may want a portfolio with two contracts with large but offsetting
risks. But if one counterparty cancels, agent i is left with the other contract. The single contract
incurs a large risk. To prevent such an outcome, agent i will likely veto both contracts. Knowing
this, the counterparties of agent i will offer her better terms to avoid cancellations. In other words,
strategic agents have to share utility with their counterparties, even if they are honest. Thus, the
mechanism reduces the need for strategic behavior.
1.1 Our Contributions
Our work makes several contributions to the literature on network games and mechanism design.
We summarize these below.
Formalizing strategic behavior in contract formation: We characterize an agent’s negotiat-
ing position as her claims about the benefits of a contract. These claims feed into a mean-variance
utility for each agent. The result is a stable network of bilateral contracts among agents. The
optimal negotiating positions of all agents are Nash equilibria in this setting.
Efficient algorithm for finding Nash equilibria: Our algorithm finds Nash equilibria among
strategic agents, if they exist. We can also analyze different combinations of honest and strategic
agents. This contrasts with prior work, which mainly considers one strategic agent in a net-
work [GKT20].
Trade deadlines to limit the need for strategic behavior: Withoutatradedeadline,strategic
agents can induce an honest agent to accept hedging contracts. Each contract has a large negative
utility, but together, they give a small positive utility. With the deadline, the honest agent judges
each contract on its merits. She will cancel contracts that have significant negative utility. The
strategic agents have to offer better terms to avoid contract cancellations. Thus, the trade deadline
mechanism helps honest agents and reduces the need for strategic behavior.
Empirical validation on the trade network between OECD countries. Absent the trade
deadline mechanism, we show that a moderately sized economy can gain significant utility by using
5their optimal negotiation position. However, if all nations are strategic, then the same economy
is worse-off. With the mechanism, a strategic nation has limited ability to gain utility. As the
penalty for contract vetoes decreases, the nation is forced to offer better terms to its counterparties
to avoid losing their contracts.
1.2 Paper Organization
AftercoveringbackgroundmaterialinSection2,wepresentourmodelformulationandmainresults
in Section 3. Section 4 presents insights based on analyzing some simple networks. We discuss the
trade deadline mechanism in Section 5, followed by experiments in Section 6. We survey related
work in Section 7 and conclude in Section 8. Section 9 shows some essential proofs, with the rest
deferred to the appendix.
2 Background
In this section, we briefly review the model of financial networks with honest negotiations due to
[JCS24].
Notation. We will use lowercase letters a,b,c,γ to denote scalars, boldface letters µ ,w to
i i
denote vectors, and uppercase letters A,B,Σ to denote matrices. The vectors e ,...,e denote
1 n
the standard basis in Rn, and I is the n × n identity matrix. We use v to refer to the jth
n i;j
component of the vector v . We denote the inner product ⟨v,w⟩ := vTw. We use A ≻ 0 to denote
i
that A is positive definite. If A ∈ Rm×n,B ∈ Rp×q then A ⊗ B ∈ Rmp×nq denotes their tensor
product: (A⊗B) = A B , and if m = p,n = q then A⊙B ∈ Rm×n denotes their Hadamard
ij,kℓ ik jℓ
product: (A⊙B) = A B . For an appropriate matrix M, tr(M) calculates its trace and vec(M)
ij ij ij
vectorizes M by stacking its columns into a single vector. For an integer r ≥ 1, we use [r] to denote
[r] := {1,2,...,r}.
The network model. Let W = WT ∈ Rn×n denote an undirected weighted network of contracts
between n agents, with W being the size of the contract between i and j and W represents i’s
ij ii
investment in its own business. A negative contract W < 0 is valid and represents a reversed
ij
version of a positive contract; for example, in a derivative contract, W < 0 swaps the roles of the
ij
6long and short position holders. During contract negotiations, agent i can pay P per unit contract
ji
to agent j to get j to agree to the contract size. Since payments are zero-sum, PT = −P. The
contracts size and payments (W,P) together give the network. At (W,P), agent i has contracts
w := We . Agent i wants to optimize the utility of their contracts and believes that contracts
i i
have mean return µ ∈ Rn and covariance Σ ≻ 0. Moreover, they have a risk-aversion parameter
i
γ > 0. Their utility is then:
i
agent i’s utility g (W,P) := wT(µ −Pe )−γ ·wTΣw (1)
i i i i i i i
Note that beliefs do not have to accurate or follow a particular distribution. The set of all beliefs
of all agents is represented in the network setting.
Definition 2.1 (Network Setting). A network setting (M,Γ,Σ) ∈ Rn×n×Rn×n×Rn×n is a tuple
consisting of an arbitrary M, a diagonal Γ ≻ 0, and a symmetric Σ ≻ 0. Agent i has mean belief
µ := Me , risk-aversion γ := Γ , and covariance belief Σ. Note that M and M need not be
i i i ii ij ji
identical.
Definition 2.2 (Stable point). A feasible (W,P) is stable if each agent achieves its maximum
possible utility given prices P:
g (W,P) = max g (W′,P) ∀i ∈ [n].
i i
(W,P):W=WT,PT=−P
Theorem 2.3 ([JCS24]). Given a network setting (M,Γ,Σ), if Γ ≻ 0 and Σ ≻ 0, there exists a
unique stable point (W,P) such that
ΣWΓ+ΓWΣ = 0.5(M +MT), Σ−1PΓ−1+Γ−1PΣ−1 = Σ−1MΓ−1−Γ−1MTΣ−1.
Equivalently,
1
vec(W) = (Γ⊗Σ+Σ⊗Γ)−1vec(M +MT),
2
vec(P) = (Γ−1⊗Σ−1+Σ−1⊗Γ−1)−1vec(Σ−1MΓ−1−Γ−1MTΣ−1).
Furthermore, agents can efficiently find the stable point through pairwise negotiations.
3 Strategic Negotiations
We formalize the contract negotiation process as follows.
7Definition 3.1 (Strategic Contract Negotiation (M,Γ,Σ,S)). Suppose there is a network setting
(M,Γ,Σ). We also have a public set S ⊆ [n] of strategic agents; the remaining agents are honest.
The contract negotiation is a three-stage process:
1. Strategy Phase: Each strategic agent k ∈ S chooses a δ ∈ Rn. The honest agents j ̸∈ S
k
choose δ = 0. The strategic agents cannot see the choices of other strategic agents before
j
making their choice.
2. Contract Formation Phase: Define a matrix ∆ whose i’th column is δ , and let M′ =
i
M +∆. The contract network is formed based on the network setting (M′,Σ,Γ). Specifically,
we use Algorithm 1 of [JCS24] to find the stable point (W,P).
3. Reward Collection Phase: Each agent i ∈ [n] receives a reward g (W,P) with respect to
i
the true network setting (M,Γ,Σ).
Since all agents make strategic choices independently, they cannot adapt their strategy to the
others’ choices. Instead, they can choose a strategy based on a Nash equilibrium, defined below.
Definition 3.2 (Nash Equilibrium). A Nash Equilibrium for a Strategic Contract Negotiation
(M,Γ,Σ,S) is a matrix ∆, as defined in Definition 3.1, with the following property. For each
k ∈ S, if all other strategic agents follow ∆, then agent k gains the highest utility by also following
∆ in the Strategy Phase.
Our main result is an algorithm that provably finds all Nash equilibria or reports if no such
equilibria exist (Algorithm 1).
Theorem 3.3. Algorithm 1 returns the set of Nash Equilibria for the strategic contract negotiation
process (M,Γ,Σ,S) if it is nonempty, and otherwise returns “No Nash Equilibrium.”
ToproveTheorem3.3,wefirstprovethatnoagentcangainunboundedutilitybybeingstrategic.
Theorem 3.4 (Concave utility given others’ choices). Given any network setting (M,Γ,Σ) and
any set of choices {δ ;i ̸= k} for all agents except k, the utility of k is a quadratic function of δ
i k
with a negative definite Hessian.
Corollary 3.5 (Strategy yields bounded utility). No choice of negotiating position lets agent k
achieve unbounded utility, even if agent k has full information about other agents’ beliefs and
choices.
8ALGORITHM 1: Nash Equilibria Computation
Input: Network setting (M,Γ,Σ) with n agents, strategic agent set S ⊆[n].
Output: Nash equilibria set E.
K ←Σ⊗Γ+Γ⊗Σ;
vec(W)← 1K−1vec(M +MT);
2
Π←the n2×n2 matrix such that Πvec(M)=vec(MT) ; /* commutation matrix */
L← 1(K−1+K−1Π);
2
T ←0,y←0 where T ∈Rn|S|×n|S|,y∈Rn|S|;
for k in S do
Define L(p,q) ←the pth row and qth column block of L; each block has size n×n;
T(k,k) ←L(k,k)+(L(k,k))T −2γ (L(k,k))TΣL(k,k);
k
for j in S\{k} do
T(k,j) ←(cid:0) I−2γ (L(k,k))TΣ(cid:1) L(k,j);
k
end
y(k) ←(2γ (L(k,k))TΣ−I)We ;
k k
end
F ←{X ∈Rn×|S| :Tvec(X)=y};

(cid:26)
Xe
i, if i∈S (cid:27)(cid:27)
E ← ∆∈Rn×n :∃X ∈F s.t. ∀i∈[n], ∆e = ;
i
0,
otherwise
return E if |E|>0 else report ”No Nash Equilibrium”
Proof. By Theorem 3.4, there exists a symmetric matrix A ≻ 0, a vector b, and a scalar c such that
if other agents use negotiating positions (δ ) , then g (δ ) = −δTAδ +δTb+c. The optimal
j j̸=k k k k k k
δ is at the unique critical point δ = 1A−1b. Therefore the utility gain of k for any choice of δ
k k 2 k
is bounded by g (1A−1b)−g (0) = 1bTA−1b.
k 2 k 4
We also need the following Lemmas.
Lemma 3.6 (Utility from Strategy). If agent k reports δ′ resulting in (W′,P′), then k’s utility is
k
g (W′,P′) = −⟨δ ,w′⟩+γ ⟨Σw′,w′⟩, (where w′ = W′e ).
k k k k k k k k
Lemma 3.7 (Commutation Matrix [HJ08]). There exists a permutation matrix Π : Rn2 → Rn2
9such that for X ∈ Rn×n, Πvec(X) = vec(XT).
We are ready to prove Theorem 3.3.
Proof of Theorem 3.3. Let (δ ) be the tuple of negotiating positions for the strategic agents.
j j∈S
Let ∆ ∈ Rn×n have ith column δ⋆ if i ∈ S and zero otherwise. Let (W′,P′) be the stable point
M i
resulting from a choice of M′ := M + ∆ as the agents’ negotiating positions in the Strategy
M
Phase. From Theorem 2.3, we have
vec(W′) = vec(W)+0.5(Σ⊗Γ+Γ⊗Σ)−1vec(∆ +∆T )
M M
⇒ vec(W′−W) = Lvec(∆ )
M
(cid:88)
⇒ w′ −w = L(k,k)δ + L(k,j)δ ,
k k k j
j∈S:j̸=k
where the second line follows from Lemma 3.7, and the matrix L is defined as in Algorithm 1.
Let A := L(k,k) and b := (cid:80) L(k,j)δ∗. By Lemma 3.6, we have:
k k j
j∈S:j̸=k
g = −⟨δ ,w′⟩+γ ⟨w′,Σw′⟩
k k k k k k
= −⟨δ ,(w +A δ +b )⟩+γ ⟨(w +A δ +b ),Σ(w +A δ +b )⟩
k k k k k k k k k k k k k k
= −⟨δ ,A δ ⟩−⟨δ ,b ⟩−⟨δ ,w ⟩+2γ ⟨Σw ,A δ +b ⟩
k k k k k k k k k k k k
+γ ⟨A δ +b ,Σ(A δ +b )⟩+γ ⟨w ,Σw ⟩
k k k k k k k k k k
⇒ ∇ g = −(A +AT)δ −b +2γ ATΣw +2γ ATΣA δ +2γ ATΣb −w
δ k k k k k k k k k k k k k k k k k
By Theorem 3.4, the optimal negotiating position δ⋆ is the critical point of g with respect to
k
δ . Setting ∇ g = 0, we obtain
k δ k
k
(A +AT −2γ ATΣA )δ⋆ = (2γ ATΣ−I)w +(2γ ATΣ−I)b
k k k k k k k k k k k k
Rearranging terms, we obtain precisely the linear system of Algorithm 1:
(cid:20)
(2γ (L(k,k))TΣ−I)w = (L(k,k)+(L(k,k))T −2γ (L(k,k))TΣL(k,k))δ⋆
k k k k
(cid:21)
+(cid:0) I −2γ (L(k,k))TΣ(cid:1) (cid:88) L(k,j)δ⋆
k j
j∈S:j̸=k
(cid:88)
⇒ y(k) = T(k,k)δ⋆+ T(k,j)δ⋆, (2)
k j
j∈S:j̸=k
10Contract Size Price Received Expected Return Risk Total Utility
10
2
5
(a) Both agents be- 0
0
lieve the mean re-
−2
−5
ward of their con-
−4 −2 0 2 4 −4 −2 0 2 4
δ δ
tract is 5. (b) Results for P1 if she negotiates using 5+δ.
Figure 1: One strategic agent: (a) The network setting is as in Example 3.8 with µ = µ = 5.
1;2 2;1
(b) Suppose agent P1 reports δ = δ < 0. Then P1 gets a smaller contract but a better price.
1;2
Even with the better price, the smaller contract means that their expected return is worse for any
δ ̸= 0 (right). But their risk shrinks faster than expected return, so the highest utility is with
δ = −3.
where T(p,q) and y(k) are defined as in Algorithm 1. Therefore if a Nash equilibrium exists, Al-
gorithm 1 finds it. Conversely, a tuple (δ⋆) that solves Eq. (2) for all k is such that δ⋆ is the
i i∈S i
optimal δ for all i ∈ S given that other agents report (δ⋆) . Therefore, if no Nash equilib-
i j j∈S\{i}
rium exists, Eq. (2) cannot be simultaneously satisfied for all k, so Algorithm 1 returns “No Nash
Equilibrium.”
Example 3.8 (Nash Equilibrium for 2-agent setting.). Consider a network with two strategic
 
0 µ
2;1
agents, and Σ = Γ = I and M =  . Then, we have
 
µ 0
1;2
   
0.5 0 0 0 0
   
   
 0 0.375 0.125 0  −0.125µ 12−0.125µ 21
T =  , y =  .
   
 0 0.125 0.375 0  −0.125µ −0.125µ 
   12 21
   
0 0 0 0.5 0
Solving the system gives
 
1 0 µ 1;2+µ 2;1
∆ = −  
M 4  
µ +µ 0
1;2 2;1
11From Theorem 2.3, it is easily shown that prices under (M+∆ ,Σ,Γ) are the same as those under
M
(M,Σ,Γ), while the contracts are smaller. Therefore, everyone is worse-off. Figure 1 shows an
example with one strategic agent.
4 Insights and Analysis
Now, we study the Nash equilibria for several network settings. While these are small networks,
they offer insights that carry over to the larger real-world network discussed later in Section 6.
4.1 Two Agents That Can Self-Invest
Consider a network with two agents (P1 and P2) who can form a contract with each other, and
each can invest in themselves (“self-invest”). The network setting is as follows.
     
M M 1 ρ 1 0
11 12
M =  , Σ =  , Γ =   (3)
     
M M ρ 1 0 1
21 22
The parameter ρ ∈ (−1,1) is the correlation between an agent’s returns from self-investment versus
trading. For ρ ≈ 1, returns from self-investing and trading move in lockstep. So, each agent must
hedge between self-investing and trading, hoping to benefit from any differences in their returns.
But as ρ goes to −1, the risks from self-investing and trading offset. If both offer positive returns,
an agent can gain nearly risk-free reward. Hence, negative correlations can lead to higher utility
for agents.
Theorem 4.1. Consider the network setting of Eq. 3. Let κ := ρ(M +M )−(M +M ), and
11 22 12 21
let ∆ be the negotiation positions (Definition 3.1) for all agents at the Nash equilibrium.
1. If only agent k is strategic, then


 κ/3 if i ̸= k,j = k
∆ =
ij

 0 otherwise
2. If both agents are strategic, then


 κ/4 if i ̸= j
∆ =
ij

 0 otherwise
12P1=P2, All Honest P1=P2, All Strategic P1 (only P1 strategic) P2 (only P1 strategic)
7.5 40
0.75
5.0
0.50
20
2.5
0.25
0.0 0
−1 0 1 −1 0 1 −1 0 1
Correlation ρ Correlation ρ Correlation ρ
Figure 2: Nash equilibria for two agents: The utility for either agent when both are honest (solid
line) is higher than when both are strategic (dashed line). When only agent P1 is strategic, P1
gains the highest utility (dotted circles) while P2’s utility is lowest (dotted squares). The network
settings are shown in the bottom row, with an arrow from i to j corresponding to M .
ji
Remark 4.2. We can show that it is strategic for i to report ∆ = 0 even if Σ ̸= Σ and
ii 1;1 2;2
Γ ̸= Γ .
11 22
Figure 2 shows the agents’ utility for honest versus strategic negotiating positions over a range
of ρ. We can make several observations.
Strategic agents report self-investing returns truthfully. Suppose agent i claims that her
self-investments have higher returns than in reality (that is, M′ > M ). If agent j wants to trade
ii ii
with i, then j will have to offer better trading terms via better prices. Thus, high self-investing
returns are a plausible negotiating strategy. However, Theorem 4.1 shows that ∆ = 0 at the Nash
ii
equilibrium, so M′ = M . This is because if both agents make untrue claims about self-investing,
ii ii
they get smaller contracts, lowering utility.
Payments to others can increase when the agent becomes strategic. It may appear that
strategicagentscanonlyincreasetheirutilitybyextractinghigherpaymentsfromothers. However,
thisneednotbetrue. Supposebothagentshaveautilityof1fromself-investingand0fromtrading.
By symmetry, if both agents are honest, they make no payments. Now, suppose only agent P1 is
strategic and ρ ≈ 1. By Theorem 4.1, P1 will claim to have higher returns from trading than her
actual returns. This implies that P1 pays P2 during contract formation. But the contract size also
13
ytilitUchanges. With the new contract size, P1 still gains utility at the expense of P2.
Utility is lower when both agents are strategic. Figure 2 shows several instances where the
agents are worse off when both are strategic versus when both are honest. This is because the
agents face a Prisoner’s Dilemma. If both are honest, they cooperate, and both gain high utility.
However, being strategic is a dominant strategy. This forces both to be strategic, leading to lower
utility for both.
Negative correlations amplify the effect of negotiating positions. Suppose self-investing
and trading both have positive expected returns. When correlations are negative, their risks cancel
while their returns add. So, an agent can take large positions and achieve high utility. But, as
noted in the previous paragraph, there is a drop in utility when both agents are honest versus
strategic. We find a larger drop for negative correlations. Hence, under negative correlations, the
effect of strategic behavior is also more pronounced.
4.2 One Investor and Two Hedge Funds
Consider a 3-agent network where one investor interacts with two hedge funds under the following
network setting.
   
0 a a 1 0 0
   
   
M = m 0 0, Σ = 0 1 ρ, Γ = I. (4)
   
   
m 0 0 0 ρ 1
Thefirstcolumncorrespondstotheinvestor, andtheotherstothehedgefunds. Underthissetting,
the hedge funds do not want to trade with each other, and none of the agents want to self-invest.
Also, the hedge funds are correlated with each other (via ρ), and uncorrelated with the investor.
Theorem 4.3. Consider the the network setting of Eq. 4, where strategic agents can only modify
the non-zero entries in their column of M. Define
(cid:18) (cid:19) (cid:18) (cid:19)
1 1 1 1 1 1 ν −η
ν = + , η = − , ζ = .
2 2−ρ 2+ρ 2 2−ρ 2+ρ ν +(ν −η)(1−ν)
1. Honest investor and strategic hedge funds:
aν −m(1−ν)(ν −η)
M′ = M′ = m, M′ = M′ = .
21 31 12 13 ν +(1−ν)(ν −η)
14All Honest HFs Strategic All Strategic
Investor Hedge Fund
8
6
4
2
0
(a) Network diagram −1.0 −0.5 0.0 0.5 1.0 −1.0 −0.5 0.0 0.5 1.0
Correlation ρ Correlation ρ
with entries of entries of (b) Utilities of the Investor and a single Fund under Theorem 4.3.
M marked on edges. Note that the two Funds achieve the same utility.
Figure3: Network with three agents: (a)Aninvestortradeswithtwohedgefunds, withtheinvestor
gaining 5 per unit contract while the hedge funds gain 1. (b) We show the utility for the investor
(left) and either hedge fund (right) for various strategic behaviors. The investor has low utility
when she is honest, but is better off than the hedge funds when she is strategic.
2. All agents strategic: If the investor does not distinguish between the hedge funds, then
m−aζ aν −M′ (1−ν)(ν −η)
M′ = M′ = , M′ = M′ = 21 .
21 31 1+ζ 12 13 ν +(1−ν)(ν −η)
From Theorem 4.3 and Figure 3b, we observe the following.
The investor’s utility is very sensitive to her negotiating position. Suppose the investor
is honest and both hedge funds are strategic. Then, the investor will accept worse terms from the
funds and achieve less utility. But the situation is reversed if the investor is also strategic (Figure
3b). The investor now achieves higher utility than either fund. Thus, the investor’s outcome is
very sensitive to her negotiating position.
The sensitivity to negotiating positions increases as ρ → −1. Figure 3b shows that when ρ
decreases, the investor loses utility if she is honest but gains utility if she is strategic. The reason
is that as ρ → −1, the investor wishes to invest almost equally in both funds to reduce her risk.
The hedge funds only form one contract each. Since they cannot hedge their risk, they prefer much
smaller contracts than the investor. The investor can extract higher payments for this, increasing
her utility.
Strategic behavior can reduce utility. Suppose the investor is honest. As ρ ≈ −1, the hedge
15
ytilitU ytilitUfunds are worse off being strategic than if they were both honest (Figure 3b). If both funds are
honest, their contract sizes match their risk preference. However, if both are strategic, each fund
worries about its competitor. So, both funds end up with worse terms.
5 Trade Deadline
The previous section showed that an agent’s utility is sensitive to her negotiating position. For
instance, aninvestorcanextractutilityfromhedgefundsifsheisstrategic, butlosesutilitytothem
if she is honest. The need for strategic behavior may dissuade new investors. Furthermore, the
Nash equilibrium formula can depend on the private beliefs of other agents (e.g., in Theorem 4.3).
Established agents may have the relevant historical or insider knowledge, which new entrants lack.
Hence, to grow the network, we need a mechanism that reduces the need for strategic behavior.
We propose such a mechanism, namely, a trade deadline.
5.1 Trade Deadline Formulation
We implement the trade deadline between the Contract Formation and Reward Collection phases
of the contract negotiation process (Definition 3.1). After Contract Formation, we have a stable
point (W,P). We formally define the trade deadline mechanism as follows.
Definition 5.1 (Trade deadline mechanism with penalty θ). Given (W,P), each agent i ∈ [n]
submits a veto vector v ∈ {0,1}n, where v = 1 if i wishes to retain her contract with j, and
i i;j
v = 0 if she wishes to exit the contract. The agents choose their veto vectors without coordination.
i;j
All vectors are revealed simultaneously at the trade deadline, and the appropriate contracts are
canceled. The new contract network is given by W′ = W · v · v . The ensuing Reward
ij ij i;j j;i
Collection phase is based on (W′,P). Each agent also pays a penalty θ ≥ 0 for every exit, for a
total penalty of θ(n−vT1) for agent i.
i
As the penalty θ → ∞, every agent will prefer to keep all contracts. Conversely, as θ → 0,
agents can exit contracts at will. We assume all agents agree upon a θ before contract negotiation.
Now, an agent i cannot directly select the v that maximizes her utility since she does not know
i
the others’ choices. Thus, a natural goal is to seek a robust veto, as defined next.
16Definition 5.2 (Robust Veto). Let v := (v ,...,v ,v ,...,v )T. The robust veto vector
−i 1;i i−1;i i+1;i n;i
v for agent i is given by:
i
v⋆ = argmax min g (W′(v ,v ),P)−θ(n−vT1)
i i i −i i
v i∈{0,1}nv −i∈{0,1}n−1
Next, we show two negative results. First, any deadline mechanism leads to agents having lower
utility than if they were all honest. Second, for the specific case of the robust veto, finding the
optimal vector vector is NP-hard under randomized reductions.
Theorem 5.3 (Trade deadlines lower utility compared to honesty). Consider a network (W,P)
formed by honest agents that is modified to (W′,P) by a trade deadline mechanism based on veto
vectors. Irrespective of how agents choose their veto vectors, we have for all i ∈ [n],
g (W′,P) ≤ g (W,P).
i i
The inequality is strict unless none of i’s contracts are vetoed.
Theorem 5.4 (Hardness of Finding v⋆ in Definition 5.2). If RP (Randomized Polynomial time)
i
does not equal NP, then there is no deterministic polynomial-time algorithm to find v⋆.
i
Our proof is by a careful analysis of the original family of hard lattices in the seminal result of
[Ajt98], who proved hardness of the ℓ -Shortest Vector Problem assuming RP ̸= NP. Given the
2
hardness of finding v⋆, we focus on a special case of the robust veto.
i
Definition 5.5 (Simplified Veto). Let g (W,P) := (M −P )W −γ Σ W2 be the utility that
i;j ji ji ji i jj ji
agent i receives solely from her contract with agent j. Agent i selects her veto vector as


 1, if g i;j(W,P) ≥ −θ
v = .
i;j

 0, otherwise.
In other words, i retains her contract with j if i’s utility given (W,P) and v = e is not worse
i j
than paying the penalty. Note that under the Robust Veto (Definition 5.2), g (W,P) ≥ −θ is a
i;j
necessary condition for v∗ = 1, but not sufficient.
i;j
175.2 Strategic Negotiation for a Single Agent under the Trade Deadline
Under the trade deadline mechanism, an agent i must choose both her negotiating position δ and
i
her veto vector v . We consider the following form of this problem.
i
Problem 5.6 (Single Agent under Trade Deadline). Suppose agent i knows that other agents will
use δ := (δ ) as their negotiating positions, and simplified veto vectors. How should i select the
−i j j̸=i
optimal δ so that no counterparty will cancel their contract with i? Formally, i seeks a negotiating
i
position δ⋆ such that
i
δ⋆ = argsupg (W(δ ,δ ),P(δ ,δ )) (5)
i i i −i i −i
δ
i
s.t. g (W(δ ,δ ),P(δ ,δ )) ≥ −θ for all j ̸= i,j ∈/ S, (6)
j;i i −i i −i
where S ⊆ [n] is a subset of “safe partners” for whom agent i makes an exception. Agent i chooses
δ = δ⋆ and v = 1 if Eq. 6 has a feasible solution, and δ = 0,v = 0 otherwise.
i i i i i
Unfortunately, it can be shown that the constraints need not be convex sets (Appendix A.2).
Hence, Problem 5.6 is not convex. However, we can find local minima using standard solvers.
Remark 5.7. The safe partners can include agents with whom agent i has outside agreements,
such as contracts signed before the deadline.
Example: One investor trading with two hedge funds. When an honest investor trades
with two strategic hedge funds, the funds can extract utility from the investor (Section 4.2). But
under the trade deadline mechanism, each fund must ensure that the investor also gains at least
−θ from each trade. This constrains the hedge funds, as we show next.
Theorem 5.8. Suppose the investor reports her negotiating position as M′ = M′ = µ. Let µ˜ be
21 31
the hedge funds’ optimal negotiating position when there is no deadline (Theorem 4.3). Consider the
trade deadline mechanism with penalty θ and no safe partners. Then there exist constants ℓ† < h†,
θ θ
depending on the network setting and µ, such that the Nash-optimal negotiating position for each
hedge fund under the deadline is given by
M′ = M′ = min(h†,max(µ˜,ℓ†)).
12 13 θ θ
18Inve tor Utility, All Strategic HF Utility, All Strategic
Inve tor Utility, HF Strategic HF Utility, HF Strategic
θ=0.1 θ=0.5 No Mechani m
6
4
2
0
−1.0 −0.5 0.0 0.5 1.0 −1.0 −0.5 0.0 0.5 1.0 −1.0 −0.5 0.0 0.5 1.0
6
4
2
0
−1.0 −0.5 0.0 0.5 1.0 −1.0 −0.5 0.0 0.5 1.0 −1.0 −0.5 0.0 0.5 1.0
Correlation ρ Correlation ρ Correlation ρ
Figure 4: Effect of trade deadlines: The setting is the same as in Figure 3b. When θ is small (left),
the utilities of the investor and hedge funds are all close. As θ grows, strategic behavior begins to
affectoutcomes, especiallyatnegativeρ. Settingθ → ∞(right)isequivalenttohavingnodeadline,
as in Figure 3b.
We give exact formulas for ℓ† and h† in Appendix A.4.
θ θ
Thus, the mechanism forces each hedge fund to choose a negotiating position in the interval
[ℓ†,h†]. When the Nash equilibrium value µ˜ is within this interval, the hedge funds are unaffected
θ θ
by the trade deadline.
Figure 4 shows results for various choices of θ. The mechanism has a strong effect for negative
correlations. Without the trade deadline, an honest investor accepts large contracts with each
fund since the negative correlation reduces the risk. However, each individual contract has a large
negative utility. Under the trade deadline mechanism, the investor would cancel these contracts.
Knowing this, the hedge funds must choose negotiating positions that give the investor at least −θ
utility for each contract. This improves the investor’s utility, even when she is honest.
19
ytilitU
rotsevnI
ytilitU
dnuF
egdeH6 Experimental Results
We study the international trade network of n = 46 large economies from 2010-2020 [OEC22].
Nodes represent nations, and we observe the trading network for every fiscal quarter. The weight
of an edge Wt between countries i and j at quarter t is the sum of the quarter’s trade flows from
ij
i to j and vice versa. There are no self-loops (Wt = 0). From the Wt, we construct the network
ii
setting (Mt,Σt,Γt) for each quarter t. Following [JCS24], we set Γt = I for all t, and Σt = Σ,
where Σ is obtained from a Semidefinite Program (SDP). Given Σt and Wt, we solve for Mt using
Theorem 2.3.
Negotiating with honest agents. We run our experiment for a fixed node i = 44, corresponding
to the United Kingdom (other countries have qualitatively similar results). For each time t, we
solve Problem 5.6 for node i for various choices of θ, assuming all other nodes are honest (δ = 0
j
for all j ̸= i). This yields i’s negotiating position, from which we calculate i’s utility.
To choose the proper scale for θ, we calculate the average utility β of all individual contracts
under honest reporting across all time periods. We set θ = θ˜· β for θ˜ ∈ {10−6,10−4,10−2,1}.
As θ˜ increases, the penalty for exiting a contract increases, and the effect of the trade deadline
mechanism weakens. We designate as safe partners all nodes j for which g < −θ when all nodes
j;i
(including i) report honestly. With these safe partners, Problem 5.6 has a feasible solution in all
cases. We compare these results to the setting with no trade deadline (θ˜ = ∞) and the baseline
case where i is honest (δt = 0).
i
Figure 5 (left plot) shows the results for all quarters. There is significant variability across
quarters due to changes in M . We find that i’s utility is the smallest when i is honest (baseline
t
setting) and largest when there is no trade deadline mechanism. The utility under the trade
mechanism is always in between these two. Smaller values of θ˜ impose more constraints on i’s
negotiating position, leading to lower values for i’s utility.
Negotiating with strategic agents. All agents other than i set their negotiating positions as
the Nash equilibrium values (Algorithm 1). For the baseline, we set i too at its Nash equilibrium
value. The safe partners at time t are all j ̸= i such that g < −θ at the baseline. Figure 5 (right
j;i
plot) shows the results for all quarters. We see that i’s utility is lower than when all other agents
were honest. Thus, the presence of other strategic agents lowers i’s utility.
20θ̃=∞ θ̃=1 θ̃=1e−2 θ̃=1e−4 θ̃=1e−6 Baseline
1e18 All Ot ers Honest All Ot ers Strategic
2.5
2.0
1.5
1.0
Time Period Time Period
Figure 5: Trade deadlines for OECD network: The utility gain from strategic behavior decreases
under the trade deadline mechanism. As θ → 0, the penalty for canceling contracts with the
strategic agent goes to 0. Hence, the strategic agent must negotiate such that their contracts are
not canceled, and is therefore forced into a worse negotiating position.
7 Related Work
We review prior on network games, trade and contract negotiations, and trade deadlines.
Network games. Network games involve n agents whose payoffs depend on their neighbors’
actions in a network [Tar04]. These games are widely studied in economics [GY16; EG22] and
computer science [Len+20; Ros+22].
Ourworkcloselyrelatestoendogenousnetworkformationmodelsforeconomicnetworks[AA20;
SG21; JCS24]. We study stable points of a network formation process in which each agent wants to
form edges to maximize its utility. Prior works have assumed that the formation process is based
on the actual preferences of the agents. Our focus is on strategic manipulation of the network
formation process.
Another stream of work considers the strategic manipulation of network games. [GGG20] prove
thataplannercanmaximizewelfareinagamewithstrategiccomplements/substitutesbymodifying
marginal returns. [GKT20] and [CR21] study adversarial perturbations in opinion dynamics. Both
works only consider a single strategic actor. In contrast, any subset of agents can be strategic in
21
rotcA
cigetartS
fo
ytilitU
0102-1Q 1102-1Q 2102-1Q 3102-1Q 4102-1Q 5102-1Q 6102-1Q 7102-1Q 8102-1Q 9102-1Q 0202-1Q 1202-1Q 0102-1Q 1102-1Q 2102-1Q 3102-1Q 4102-1Q 5102-1Q 6102-1Q 7102-1Q 8102-1Q 9102-1Q 0202-1Q 1202-1Qour setting.
Bespoke contract negotiations. Inafinancialnetwork, eachpairofagentsnegotiatesacontract
withcustomterms. Idealmechanismsforbilateralcontractnegotiationunderinformationasymme-
try do not exist in general [MS83]. In the special case of principal-agent problems with information
acquisition, [PW22] provide efficient algorithms to solve the principal’s minimum payment problem
with limited liability. However, there are tradeoffs between the limited liability condition and other
desirable aspects of the contract negotiation mechanism, such as individual rationality [Alo+23].
Trade negotiations. Two-player matrix games are used to model aspects of bilateral trade
negotiations, such as one-off trade wars [Hug07; SP16] or repeated Prisoner’s Dilemma games
[Khu22]. In the n = 2 case of our model, we obtain a Prisoner Dilemma-type payoff matrix
in which each agent can negotiate honestly or strategically. However, we go beyond the matrix
game setting by (i) using a network model with arbitrarily many agents, and (ii) considering real-
valued negotiating positions that give agents more flexibility to act strategically. Models with
n > 2 are better suited to model multilateral settings such as strategic trade negotiations between
the European Union (EU) and the Association for Southeast Asian Nations (ASEAN) [Lac12].
Moreover, trade negotiations can involve a continuum of strategic positions, such as import tariffs
for nations seeking to join the WTO [Rog20].
Trade deadline mechanisms. We design a trade deadline mechanism to limit the sensitivity
of outcomes to strategic behavior. While incentive-compatible mechanisms such as the Vickrey-
Clarke-Groves (VCG) mechanism are known for bilateral trade, the VCG mechanism requires a
subsidy if the buyer values the good more than the seller [Nis+07]. If there is neither a subsidy
nor a tax, the Gibbard-Satterthwaite theorem [Gib73; Sat75] forbids the existence of non-trivial
decision rules in dominant strategies for many settings [Jac00]. In general, there is tension between
the twin goals of (i) a dominant strategy incentive-compatible mechanism, and (ii) subsidies and
taxes adding up to zero [Jac00].
Our trade deadline mechanism has no subsidy, and is most impactful when the penalty for
vetoing contracts is zero. Trade deadlines for player trades have been studied in sports economics.
Unlike our setting, the purpose of sports trade deadlines is not to limit strategic behavior. Sports
trade deadlines create new opportunities for strategic behavior via over or under-bidding on certain
22players [Zim02] and creating inefficiencies in secondary betting markets [DFO¨18].
8 Conclusion
Contract negotiations in the real world need a judicious mix of cooperation and competition. One
who is too honest and cooperative leaves himself open to manipulation. However, unrestricted
competitive behavior leads to a breakdown of trust. Without trust, the economy falters [Ho22].
Our paper is an attempt to model this phenomenon in a tractable manner. In our model,
all agents trade off reward against risk via personal utility functions. The agents cooperate by
accommodating each other’s utility functions and paying a price when necessary to make the
contract agreeable to others. They compete by deceiving others about their utility functions. But,
like in the real world, deception has limited utility. The larger the deception, the less the other
agents are willing to engage. This leads to smaller contracts for the deceiver, reducing his utility.
Thus, our model leads to Nash equilibria among strategic agents. Furthermore, we present an
efficient algorithm to find these equilibria.
The above algorithm needs to know both the agents’ public deceptions and private beliefs.
Hence, those with better information can be more strategic, again echoing the real world. Be-
ing strategic confers a significant jump in utility compared to being honest. To reduce the need
for strategy, we introduce the trade deadline mechanism. The mechanism allows agents to veto
contracts at the deadline. The veto threat compels strategic agents to share utility with their
counterparties. Hence, the trade deadline reduces the gap between strategic and honest agents.
Experiments on simulated as well as real-world datasets validate these ideas.
There are several directions for future work. This paper focuses on a sequential process for
contract negotiations. It begins with a single strategy phase, followed by forming the contract
network and ending with reward collection. But contract negotiations are often iterative processes,
with repeated interactions between agents. Each iteration offers all agents the chance to update
their negotiation positions. In such negotiations, we would seek feedback Nash equilibria for the
resulting dynamic game [BO98].
Another direction is to find the Nash equilibrium under the trade deadline mechanism. Given
the computational intractability of the Robust Veto problem, we only analyze Nash equilibria in
23the trade deadline setting for specific networks. Analyzing the equilibria for more general networks
is an interesting direction for future work.
Our work can also be extended to include all private beliefs of agents in the strategy. Our work
only considers negotiating positions based on mean rewards. But an agent can also deceive others
about their risk aversion parameter γ or their correlation matrix Σ. For example, an agent may
induce counterparties to offer better terms by appearing to be risk-averse. Similarly, an agent can
try to convince others that she is negatively correlated with other agents, so contracts with her
serve to reduce risk.
Finally, we have only considered mean-variance utility functions. However, many other utility
functions have been studied in the literature. While mean-variance utility leads to tractable Nash
equilibria, other utility functions may be more appropriate in some settings.
9 Proofs
9.1 Proof of Theorem 3.4
Proposition 9.1. Let k ∈ [n]. Let δ := {δ : i ̸= k} and let (W,P) be the stable point if
−k i
k reports honestly and all others report according to δ . Next, consider some δ ̸= 0 and let
−k k
(W′,P′) be the stable point if k reports δ and all others report according to δ . Then W′e =
k −k k
We +Bδ for a matrix B defined as follows. Let Γ−1/2ΣΓ−1/2 = VΛVT be the eigendecomposition
k k
of Γ−1/2ΣΓ−1/2 ≻ 0. Let A ∈ Rn×n be a symmetric matrix such that:

n
  4V λk2 i + (cid:80) 2(λV +k2 ℓ
λ )
i = j
A = i ℓ=1 i ℓ
ij
   V kiV kj i ̸= j
2(λ +λ )
i j
Then B = γ−1Γ−1/2VAVTΓ−1/2.
k
Proof. Let ∆ = W′ − W. By Theorem 2.3, 2(Σ∆ Γ + Γ∆ Σ) = e δT + δ eT. Therefore
W W W k k k k
vec(∆ ) = 1(Σ⊗Γ+Γ⊗Σ)−1(e δT +δ eT).
W 2 k k k k
Next, let v := Ve . Using the eigendecomposition properties of Kronecker sums [HJ08] as in
i i
24Corollary 1 of [JCS24],
∆ =
Γ−1/2(cid:18) (cid:88)n (cid:88)n v iTΓ−1/2(cid:0) e kδ kT +δ keT k(cid:1) Γ−1/2v
j v
vT(cid:19)
Γ−1/2
W 2(λ +λ ) i j
i j
i=1 j=1
Let G := Γ−1/2V and g := Ge . Then vTΓ−1/2e = G and eTΓ−1/2v = G . Hence:
i i i k ki k j kj
∆ e =
Γ−1/2(cid:18) (cid:88)n (cid:88)n G kig jTδ
k
+G kjg iTδ
k v
vT(cid:19)
Γ−1/2e
W k 2(λ +λ ) i j k
i j
i=1 j=1
=
Γ−1/2(cid:18) (cid:88)n (cid:88)n G kig jTδ
k
+G kjg iTδ
k
G v
(cid:19)
kj i
2(λ +λ )
i j
i=1 j=1
(cid:18) n n n (cid:18) n (cid:18) (cid:19)(cid:19)(cid:19)
= Γ−1/2 (cid:88)(cid:88) G kiG kj v vT +(cid:88) G2 · (cid:88) 1 v vT Γ−1/2δ
2(λ +λ ) i j kj 2(λ +λ ) i i k
i j i j
i=1 j=1 j=1 i=1
Hence W′e −We = Bδ for a matrix B defined as above. We can further simplify B as
k k k
B = Γ−1/2(cid:18) (cid:88)n (cid:18) G2 ki +(cid:88)n G2 kj (cid:19) v vT +(cid:88)n (cid:88) G kiG kj v vT(cid:19) Γ−1/2
4λ 2(λ +λ ) i i 2(λ +λ ) i j
i i j i j
i=1 j=1 i=1 j̸=i
Notice that G = γ−1/2 V , and that B depends only on the kth row of G so we can factor out γ−1
ki k ki k
and replace the entries G with V .
ki ki
Finally, let A ∈ Rn×n be defined as in the statement of this Proposition. Then we conclude that
n n
B = γ−1Γ−1/2(cid:0)(cid:88) A v vT +(cid:88)(cid:88) A v vT(cid:1) Γ−1/2 = γ−1Γ−1/2VAVTΓ−1/2
k ii i i ij i j k
i=1 i=1 j̸=i
Proposition 9.2. Let K = Λ1/2AΛ1/2. The eigenvalues of K are all real and contained in (0,1).
Proof. Notice that K is symmetric, since Λ is diagonal and A is symmetric. By the Spectral
Theorem, K has an eigendecompsition with real eigenvalues.
n
Next,noticeA = C+DforC ij = C ji = 2(V λki +V k λj ) andDadiagonalmatrixwithD ii = (cid:80) 2(λV +k2 ℓ λ ).
i j ℓ=1 i ℓ
Then K = C˜ +D˜ for C˜ = Λ1/2CΛ1/2 and D˜ = Λ1/2DΛ1/2.
Let x = √1 Λ1/2VTe . Then C˜ satisfies the Lyapunov equation:
k
2
ΛC˜ +C˜Λ = xxT
Since C˜ is self-adjoint it has an eigenbasis with real eigenvalues. Let y be an eigenvector of C˜ with
eigenvalue µ. Then (yTx)2 = yT(C˜Λ+ΛC˜)y = 2µyTΛy. By the Cauchy-Schwarz inequality,
n √ n n
((cid:80) λ y V )2 ((cid:80) λ y2)((cid:80) V2)
(yTx)2 1 i i ki 1 i i ki 1
µ = = i=1 ≤ i=1 i=1 ≤
2yTΛy 4 (cid:80)n
λ y2
4 (cid:80)n
λ y2
4
i i i i
i=1 i=1
25Further, since Λ ≻ 0, µ ≥ 0. So the eigenvalues of C˜ are all within [0, 1]. Next, the eigenvalues of
4
D˜ are simply its diagonal entries. Recall that
D˜ = (cid:88) λ iV k2 j > λ i (cid:88) V2 > 0,
ii 2(λ +λ ) 2(λ +max λ ) kj
i j i j j
j j
sinceV isorthonormalandλ > 0. Bysimilarreasoning,D˜ < 1. Weconcludethattheeigenvalues
j ii 2
of K are contained in (0, 3).
4
We are ready to prove Theorem 3.4.
Proof of Theorem 3.4. Fix the index k of the strategic actor. Suppose k reports δ and each i ̸= k
k
reports some δ . Let (W′,P′) be the resulting stable point.
i
By Lemma 3.6, the utility of k at (W′,P′) is −⟨δ ,w′⟩ + γ ⟨w′,Σw′⟩ where w′ is the kth
k k k k k k
column of W′.
By Proposition 9.1, w′ = w +Bδ for B = γ−1Γ−1/2VAVTΓ−1/2 with V and A as in Proposi-
k k k k
tion 9.1. Hence the utility of k is quadratic in δ , and the quadratic term is
−δT(cid:0)
B−γ
BΣB(cid:1)
δ .
k k k k
A straightforward calculation gives:
(cid:18) (cid:19)
B−γ BΣB = γ−1Γ−1/2VΛ−1/2 Λ1/2AΛ1/2−(cid:0) Λ1/2AΛ1/2(cid:1)2 Λ−1/2VTΓ−1/2
k k
Let K := Λ1/2AΛ1/2. To show that the Hessian of the utility of k is negative definite in δ , we need
k
to show K −K2 ≻ 0. Since the spectrum of K is contained in (0,1) by Proposition 9.2, K ≻ K2
and the conclusion follows.
9.2 Proof of Theorem 5.3.
Proof of Theorem 5.3. Let Σ := γ Σ,µ = Me ,w′ = W′e ,w = We , and y = w −w′. Then:
i i i i i i i i i i
g (W,P) = (µ −Pe )Tw −wTΣ w
i i i i i i i
= (µ −Pe )Tw′ +(µ −Pe )Ty−(w′)TΣ w′ −2(w′)TΣ y−yTΣ y
i i i i i i i i i i i
= g(W′,P)+(µ −Pe )Ty−yTΣ (2w′ +y)
i i i i
= g(W′,P)+(µ −Pe )Ty−yTΣ (2w −y)
i i i i
(cid:18) (cid:19)
= g(W′,P)+(µ −Pe )Ty−yTΣ Σ−1(µ −Pe ) +yTΣ y
i i i i i i i
= g(W′,P)+yTΣ y
i
26Since Σ ≻ 0, we conclude that g(W′,P) ≤ g(W,P), with equality if and only if w′ = w .
i i i
9.3 Proof of Theorem 5.4
Our proof is based on L2-ShortestVectorProblem, which concerns finding the shortest vector
in a discrete lattice within Rd given a basis. We will show a series of deterministic polynomial time
reductions that go from L2-ShortestVectorProblem to the problem of finding a Robust Veto
(Definition 5.2). Combining these reductions, we prove Theorem 5.4 at the end of this section.
Theorem 9.3 ([Ajt98]). There is a reverse-unfaithful-randomized (RUR) reduction from Subset-
Sum on n variables to L2-ShortestVectorProblem on (n+2) variables.
We treat RUR reductions as a black box; for details on randomized reductions, we refer the
reader to [AB09]. Next, we will need the following definitions.
Definition 9.4 (L2-IntegerQuadraticMinimization). Given Q ≻ 0 and c ∈ Rn, find x∗ such
that:
x∗ = arg min xTQx+cTx
x∈Zn
Definition 9.5 (L2-BinaryQuadraticMinimization). Given Q ≻ 0 and c ∈ Rn, find x∗ such
that:
x∗ = arg min xTQx+cTx
x∈{0,1}n
The following reduction is standard.
Proposition9.6. Thereisadeterministicpolynomialtimereductionfrom L2-ShortestVectorProblem
to L2-IntegerQuadraticMinimization.
Next, we will reduce from L2-BinaryQuadraticMinimization to the Robust Veto 5.2.
Proposition 9.7. There is a deterministic polynomial time reduction from
L2-BinaryQuadraticMinimization to Robust Veto.
Proof. Given an instance of L2-BinaryQuadraticMinimization with some Q,c, let θ = 0,
w = v = (1,1,...,1)T and P = 0. Let µ = −c and Σ = Q,γ = 1. Then ⟨v ⊙ v ⊙
i −i i i i i −i
w ,µ − Pe ⟩ = cTv and −γ⟨v ⊙ v ⊙ w ,Σ (v ⊙ v ⊙ w )⟩ = vTQv . Hence minimizing
i i i i i −i i i i −i i i i
27the L2-BinaryQuadraticMinimization objective is equivalent to the objective of Definition 5.2.
Moreover, we obtain a valid problem instance since Σ = Q ⪰ 0 since Q ≻ 0 by assumption, and
i
γ > 0,PT = −P.
i
Finally,wewillusearecentreductionfromaconstrainedversionof L2-IntegerQuadraticMinimization
to L2-BinaryQuadraticMinimization.
Proposition 9.8 ([Alb+23]). Consider the following constrained version of
L2-IntegerQuadraticMinimization on n variables. Given data Q ⪰ 0,c ∈ Rn, and a > 0, find
x∗ such that:
x∗ = arg minxTQx+cTx
x∈Zn
s.t. ∀i |x | ≤ a
i
There is a deterministic polynomial time reduction from the constrained problem on n variables to
an instance of L2-BinaryQuadraticMinimization on m variables, for m ≤ nlog(2a).
We are ready to prove Theorem 5.4.
Proof of Theorem 5.4. Let n be a positive integer and A be an instance of SubsetSum on n
variables. The reduction of Theorem 9.3 gives a lattice L in n+2 dimensions with basis vectors
(cid:80)
v ,...,v . Call this instance B. L has the property that if γ v is a shortest vector
1 n+2 i i
i∈[n+2]
(with γ ∈ Z), then γ ∈ {0,1} for i ≤ n, and γ = 1. Moreover, the set of such coefficient
i i i+1
sequences (γ ,...,γ ) for shortest vectors of L has size at most exponential in n. Therefore,
1 n+2
by Prop 9.6, there exists a deterministic reduction from B to the following constrained version of
L2-IntegerQuadraticMinimization for c ∈ Rn+2,Q ≻ 0.
min xTQx+cTx
x∈Zn+2
s.t. ∀i ≤ n |x | ∈ {0,1}
i
x = 1
n+1
log(|x |) ≤ nO(1)
n+2
Call this constrained instance C. By Prop 9.8, there is a deterministic reduction from C to an
instance D of L2-BinaryQuadraticMinimization on (n+2)·nO(1) = nO(1) variables.
28Next, by Prop 9.7, there is a deterministic reduction from D to an instance E of the Robust
Veto problem 5.2.
Since all of our reductions were deterministic, our overall reduction from A to E has the same
one-sided error as the reduction from A to B.
We conclude that there is a reverse unfaithful random (RUR) reduction from an instance A of
SubsetSum on n variables to an instance E of the Robust Veto problem on nO(1) variables. Since
SubsetSum is NP-hard, if NP ̸= RP then Robust Veto problem is not in RP.
References
[AA20] Daron Acemoglu and Pablo D Azar. “Endogenous production networks”. In: Economet-
rica 88.1 (2020), pp. 33–82.
[AB09] Sanjeev Arora and Boaz Barak. Computational complexity: a modern approach. Cam-
bridge University Press, 2009.
[Ajt98] Mikl´osAjtai.“TheshortestvectorprobleminL2isNP-hardforrandomizedreductions”.
In: Proceedings of the thirtieth annual ACM symposium on Theory of computing. 1998,
pp. 10–19.
[Alb+23] Martin R Albrecht et al. “Variational quantum solutions to the Shortest Vector Prob-
lem”. In: Quantum 7 (2023), p. 933.
[Alo+23] Tal Alon et al. “Incomplete information VCG contracts for common agency”. In: Oper-
ations Research (2023).
[BO98] Tamer Baclipsar and Geert Jan Olsder. Dynamic noncooperative game theory. SIAM,
1998.
[CR21] Mayee F Chen and Mikl´os Z R´acz. “An adversarial model of network disruption: Max-
imizing disagreement and polarization in social networks”. In: IEEE Transactions on
Network Science and Engineering 9.2 (2021), pp. 728–739.
[DFO¨18] Christian Deutscher, Bernd Frick, and Marius O¨tting. “Betting market inefficiencies
are short-lived in German professional football”. In: Applied Economics 50.30 (2018),
pp. 3240–3246.
29[EG22] Matthew Elliott and Benjamin Golub. “Networks and economic fragility”. In: Annual
Review of Economics 14 (2022), pp. 665–696.
[Eis+23] Andrea L Eisfeldt et al. “OTC intermediaries”. In: The Review of Financial Studies
36.2 (2023), pp. 615–677.
[EW09] ThomasEichnerandAndreasWagener.“Multiplerisksandmean-variancepreferences”.
In: Operations Research 57.5 (2009), pp. 1142–1154.
[GGG20] Andrea Galeotti, Benjamin Golub, and Sanjeev Goyal. “Targeting interventions in net-
works”. In: Econometrica 88.6 (2020), pp. 2445–2471.
[Gib73] Allan Gibbard. “Manipulation of voting schemes: a general result”. In: Econometrica:
journal of the Econometric Society (1973), pp. 587–601.
[GKT20] Jason Gaitonde, Jon Kleinberg, and Eva Tardos. “Adversarial perturbations of opinion
dynamics in networks”. In: Proceedings of the 21st ACM Conference on Economics and
Computation. 2020, pp. 471–472.
[GY16] Paul Glasserman and H Peyton Young. “Contagion in financial networks”. In: Journal
of Economic Literature 54.3 (2016), pp. 779–831.
[HJ08] Roger Horn and Charles Johnson. Topics in matrix analysis. Cambridge University
Press, 2008.
[Ho22] Benjamin Ho. Why Trust Matters: An Economist’s Guide to the Ties That Bind Us.
Columbia University Press, Nov. 2022.
[Hug07] Rodney Hughes. “A “Modified Prisoners’ Dilemma” Approach to Progress in the World
Trade Organization’s Agricultural Trade Negotiations”. In: Issues in Political Economy
16 (2007), pp. 1–20.
[ISD23] ISDA. Key Trends in the Size and Composition of OTC Derivatives Markets in the
Second Half of 2022. Tech. rep. International Swaps and Derivatives Association, June
2023.
[Jac00] Matthew O Jackson. Mechanism Theory. 2000.
[JCS24] Akhil Jalan, Deepayan Chakrabarti, and Purnamrita Sarkar. “Incentive-Aware Models
of Financial Networks”. In: arXiv preprint arXiv:2212.06808 (2024).
30[Khu22] Chaitanya Khurana. “Review of game theory applications in international trade”. In:
International Journal of English Literature and Social Sciences (IJELS) 7.1 (2022).
[Lac12] Conway Lackman. “EU-ASEAN: Trade Policy: A Game Theory View”. In: Journal of
Global Business Management 8.2 (2012), p. 1.
[Len+20] Yan Leng et al. “Learning quadratic games on networks”. In: International Conference
on Machine Learning. 2020, pp. 5820–5830.
[LM79] Haim Levy and Harry M Markowitz. “Approximating expected utility by a function of
mean and variance”. In: The American Economic Review 69.3 (1979), pp. 308–317.
[Mar52] Harry Markowitz. “PORTFOLIO SELECTION”. In: Journal of Finance 7.1 (1952),
pp. 77–91. url: https://EconPapers.repec.org/RePEc:bla:jfinan:v:7:y:1952:
i:1:p:77-91.
[MS83] Roger B Myerson and Mark A Satterthwaite. “Efficient mechanisms for bilateral trad-
ing”. In: Journal of economic theory 29.2 (1983), pp. 265–281.
[Nis+07] Noam Nisan et al. Algorithmic game theory. Cambridge University Press, 2007.
[OEC22] OECD. OECD Statistics. 2022. url: https://stats.oecd.org/.
[Pul83] Lawrence B Pulley. “Mean-variance approximations to expected logarithmic utility”.
In: Operations Research 31.4 (1983), pp. 685–696.
[PW22] Maneesha Papireddygari and Bo Waggoner. “Contracts with Information Acquisition,
via Scoring Rules”. In: Proceedings of the 23rd ACM Conference on Economics and
Computation. 2022, pp. 703–704.
[Rog20] RobertARogowsky.“StrategicNegotiationforWTOAccession”.In:Available at SSRN
4080437 (2020).
[Ros+22] Emanuele Rossi et al. “Learning to infer structures of network games”. In: International
Conference on Machine Learning. PMLR. 2022, pp. 18809–18827.
[Sat75] Mark Allen Satterthwaite. “Strategy-proofness and Arrow’s conditions: Existence and
correspondencetheoremsforvotingproceduresandsocialwelfarefunctions”.In:Journal
of economic theory 10.2 (1975), pp. 187–217.
31[SG21] Evan Sadler and Benjamin Golub. “Games on endogenous networks”. In: arXiv preprint
arXiv:2102.01587 (2021).
[Sim14] Yusif Simaan. “The opportunity cost of mean–variance choice under estimation risk”.
In: European Journal of Operational Research 234.2 (2014), pp. 382–391.
[SP16] Eneias Strakoshia and George Petrakos. “Bilateral Trade between the Eurozone and
China: A Zero-Sum Game Theory Approach”. In: International Business Research 9.1
(2016), p. 35.
[Tar04] Eva Tardos. “Network games”. In: Proceedings of the thirty-sixth annual ACM sympo-
sium on Theory of computing. 2004, pp. 341–342.
[Zim02] Andrew S Zimbalist. Competitive balance in sports leagues: An introduction. 2002.
A Additional Proofs
A.1 Proof of Lemma 3.6
Proof of Lemma 3.6. LetW′,P′ bethenewstablepointandw′ = W′e . Letµ′ = µ +δ . Then:
k k k k k
g = ⟨w′,µ −P′e ⟩−γ ⟨Σw′,w′⟩
k k k k k k k
= ⟨w′,µ −µ′⟩+⟨w′,µ′ −P′e ⟩−γ ⟨Σw′,w′⟩
k k k k k k k k k
Notice that since w′ = 1 Σ−1(µ′ −P′e ) that ⟨w′,µ′ −P′e ⟩ = 2γ ⟨Σw′,w′⟩. The conclusion
k 2γ k k k k k k k k
k
follows.
A.2 Non-Convexity of Constraints
In this section, we will show that the constraint −g ≤ θ is not convex in δ in general.
j;i i
Proposition A.1. Let δ be fixed. If j ̸= i, then the individual utility g is quadratic in δ and
−i j;i i
its Hessian with respect to δ is of the form vzT +zvT for vectors v,z. Moreover, z ̸= v unless
i
(2γ BΣ+B+γ Σ I)e = e , where B is as in Proposition 9.1. Therefore the Hessian has a positive
i i ii j j
eigenvalue unless (2γ BΣ+B+γ Σ I)e = e
i i ii j j
32Proof. From the proof of Theorem 3.4, we know that if (W,P) is the stable point at (0,δ ) and
−i
(W′,P′) is the stable point at (δ ,δ ) then w′ = w +Bδ for a symmetric B. Moreover, we know
i −i i i i
that if M′ is the matrix of reported means at (δ ,δ ) then P′ = −2ΣW′Γ+M′. In particular, i
i −i
gives j a payment per unit contract of P′ = −2γ eTΣ(We +Bδ )+eTMe +eTδ . Therefore the
ji i j i i j i j i
individual utility g can be written as:
j;i
g = w′ (µ +P′ )−γ Σ (w′ )2
j;i ij j;i ji i ii ij
Since W′,P′ are linear in δ , it is clear that g is quadratic in δ . Next, let ∇2g be the Hessian
i j;i i j;i
with respect to δ . Only the terms of g that are quadratic in δ appear in the Hessian. Therefore,
i j;i i
∇2g = ∇2(w′ P′ )−γ Σ ∇2(w′ )2
j;i ij ji i ii ij
(cid:18) (cid:19) (cid:18) (cid:19)
= ∇2 eTBδ ·(cid:0) −2γ eTΣ(We +Bδ )+eTMe +eTδ (cid:1) −γ Σ ∇2 (eTBδ )2
j i i j i i j i j i i ii j i
(cid:18) (cid:19) (cid:18) (cid:19) (cid:18) (cid:19)
= ∇2 δTBTe eTδ −∇2 δTBTe (cid:0) 2γ eTΣBδ (cid:1) −γ Σ ∇2 δTBTe eTBδ
i j j i i j i j i i ii i j j i
= BTe eT +e eTB−2γ BTe eTΣB−2γ BTΣe eTB−2γ Σ BTe eTB
j j j j i j j i j j i ii j j
= Be eT +e eTB−2γ Be eTΣB−2γ BΣe eTB−2γ Σ Be eTB
j j j j i j j i j j i ii j j
Let v = Be and z = e −2γ BΣe −γ Σ v. Then ∇2g = vzT +zvT.
j j i j i ii j;i
A.3 Proof of Theorem 4.3
Throughout this section, we will refer to the investor as P1 and the hedge funds as P2, P3. Hence
P1 has beliefs according to Me , and so on.
1
Proposition A.2. Assume that P1 reports M ,M as m˜, P2 reports M as a˜, and P3 reports
21 31 12
M as ˜b. Then w = 0.5·(α˜+a˜ν −˜bη) and w = 0.5·(α˜+˜bν −a˜η) for α˜ = m˜ .
13 21 31 2+ρ
Proof. Notice that Σ has eigenvalues λ = 1,λ = 1+ρ,λ = 1−ρ and corresponding eigenvectors
1 2 3
v
1
= (1,0,0)T,v
2
= √1 (0,1,1)T,v
3
= √1 (0,1,−1)T. Therefore 2−1/2(w 2+w 3) = Wv 2. Let M˜ be
2 2
the matrix of reported values, so M˜ = M˜ = m˜, M˜ = a˜, and M˜ =˜b. All other entries of M˜
21 31 12 13
are zero.
33(cid:80) vT(M˜+M˜T)v
From Theorem 2.3, the resulting network is W = i
2(λ +λ )
jv iv j. By orthogonality of
i j
i,j∈[3]
eigenvectors, we have:
Wv =
(cid:88) v iT(M˜ +M˜T)v 2
v
2 i
2(λ +λ )
i 2
i
Onlythetermati = 1isnonzero,andtherefore2−1/2(w 2+w 3) = 2√m˜+a˜+˜b e 1. Similarly,2−1/2(w 2−
2 2(2+ρ)
w 3) =
√a˜−˜b
e 1. The conclusion follows.
2 2(2−ρ)
Proposition A.3. Let α˜ be as in Proposition A.2. Assume P1 reports µ˜, and P3 reports ˜b. The
optimal choice of reported a˜ for P2 is:
a˜∗ = c +s˜b
a
aν−α˜(1−ν) η(1−ν)
For c = and s = .
a ν(2−ν) ν(2−ν)
Proof. Let w := w for shorthand. The utility of firm 2, by Lemma 3.6, is given by:
21
g = −w(a˜−a)+w2
2
= w(a−a˜+w)
2g = (α˜+a˜ν −˜bη)(a+(0.5ν −1)a˜+0.5α˜−0.5˜bη)
2
The coefficient of a˜2 in g is ν(0.5ν −1). Since ν > 0 and 0.5ν < 1 for all ρ ∈ (−1,1), the Hessian
2
of g with respect to a˜ is negative definite, and so the optimal choice of a is at the critical point
2
∂g 2 = 0. Solving for a˜ gives:
∂a˜
a˜∗ = c +s˜b
a
With c ,s as in the statement.
a
A symmetric argument gives the following.
Proposition A.4. Let α˜ be as in Proposition A.2. Assume P1 reports µ˜, and P2 reports a˜. The
optimal choice of reported ˜b for P3 is:
˜b∗ = c +sa˜
b
bν−α˜(1−ν) η(1−ν)
For c = and s = .
a ν(2−ν) ν(2−ν)
Next, we can solve for the Nash equilibria given the reported m˜ of the investor.
34Proposition A.5. If M = M = a, then let c := c = c and s be as in Proposition A.3 and
12 13 a b
A.4. Assume P1 reports µ˜. The Nash equilibrium for P2, P3 is to report:
c
M′ = M′ =
12 13 1−s
Corollary A.6 (Theorem 4.3 Part 1). Assume P1 reports m˜. If both hedge funds are strategic,
then the Nash equilibrium for P2, P3 is to report:
aν −m˜(1−ν)(ν −η)
M′ = M′ =
12 13 ν +(1−ν)(ν −η)
Hence if m˜ = m, then M′ = M′ are as in Theorem 4.3.1.
12 13
Proof. We simplify a = c as follows.
NS 1−s
c aν −α˜(1−ν)
=
1−s ν(2−ν)(1−s)
aν −α˜(1−ν)
=
(cid:0) η(1−ν)(cid:1)
ν(2−ν) 1−
ν(2−ν)
aν −m˜(1−ν)(ν −η)
=
ν(2−ν)−η(1−ν)
aν −m˜(1−ν)(ν −η)
=
ν +(1−ν)(ν −η)
In the setting of Theorem 4.3.1, the investor reports m˜ = m. The conclusion follows.
Next, we solve for the optimal report of the investor if all agents are strategic.
Proposition A.7 (Theorem 4.3 Part 2). Let y = 1 . If all agents are strategic, then the
2(2+ρ)
optimal reported m˜ for the investor is:
m−aζ
M′ = M′ =
21 31 1+ζ
For ζ = ν−η = (1−2y(1+ρ)). The optimal report for the hedge funds is:
ν+(ν−η)(1−ν)
aν −M′ (1−ν)(ν −η)
M′ = M′ = 21
12 13 ν +(1−ν)(ν −η)
Proof. From Proposition A.5 and A.2, we know w = w . Therefore by Lemma 3.6, if P1 reports
12 13
m˜ then the investor utility is:
g (m˜) = 2(m−m˜)w +w2 (2+2ρ)
1 12 12
35Let w = (c + m˜y) for shorthand. Then g is quadratic in m˜ and the coefficient of m˜2 is
12 2 1
2y2 +2ρy2 −2y = −(ρ+3) < 0. Therefore, the optimal m˜ is at the critical point ∂g 1 = 0. This is
2(ρ+2)2 ∂m˜
given as:
−c +my+2c y(1+ρ)
2 2
m˜ =
2y(1−y(1+ρ)
m−(c /y)(1−2y(1+ρ))
2
=
2(1−y(1+ρ))
m−(c /y)(1−2y(1+ρ))
2
=
1+(1−2y(1+ρ))
We simplify the terms (c /y),2y(1+ρ) as follows. First, notice that c = ν−η · aν , where
2 2 2 ν(1−ν)(1−s)
a is true value of M and M for the hedge funds. Let c := aν for shorthand, so that
12 13 1 ν(1−ν)(1−s)
36c = ν−ηc . Next,
2 2 1
c c
2 1
=
y ν −η
a 2(ν −η)
= ·
(2−ν)(1−s) 2(2+ρ)−1(1−(ν −η)x)
a
(cid:18)
1−ν
(cid:19)−1
= · 1−(ν −η)·
(2−ν)(1−s) ν(2−ν)(1−s)
aν
=
ν(2−ν)(1−s)−(ν −η)(1−ν)
aν
=
ν(2−ν)−η(1−ν)−(ν −η)(1−η)
aν
=
ν
= a
1−2y(1+ρ) = 1−2(c /a)(1+ρ)
2
c (ν −η)
1
= 1−(1+ρ)
a
a (ν −η)
= 1−(1+ρ)·
(2−ν)(1−s) a
(ν −η)(1+ρ)ν
= 1−
ν(2−ν)−η(1−ν)
ν(ν −η)(1+ρ)
= 1−
ν +(ν −η)(1−ν)
ν(ν −η)((2+ρ)−1)
= 1−
ν +(ν −η)(1−ν)
ν −ν(ν −η)
= 1−
ν +(ν −η)(1−ν)
ν −η
=
ν +(ν −η)(1−ν)
Let ζ := ν−η = 1−2y(1+ρ). The optimal m˜∗ = m−aζ.
ν+(ν−η)(1−ν) 1+ζ
Finally, substituting this m˜∗ into Corollary A.6 gives the optimal reports for the hedge funds.
A.4 Exact Formulas for Theorem 5.8
Throughout this section, we will use the notation M = a,M = b and M = M = m for the
21 31 12 13
true beliefs of the hedge funds and investor, and a˜,˜b,m˜ for the reported beliefs.
Proposition A.8. Assume that P1, P2 report M′ = a˜,M′ =˜b and the investor honestly reports
21 31
37M′ = M′ = m = m˜. Then there exist constants ℓ ,h ,ℓ′,h′ such that the optimal a˜,˜b under the
12 13 θ θ θ θ
trade deadline with penalty θ > 0 are:
ℓ < a˜ < h
θ θ
ℓ′ <˜b < h′
θ θ
Proof. Let (W,P) be the stable network if all report as in the statement of this Proposition. Let
w = w for shorthand. Notice that g = w(a−P )−w2 = w2 since, given the prices P, P2 will
21 2 1;2
select w = 1/2(a−P ). Therefore at the stable point, P = −P = 2w−a.
1;2 2;1 1;2
For P2 to retain their contract with P1, they must report a˜ such that the individual utility of
the investor g > −θ. If g = −θ, then we can solve for the roots of the resulting polynomial in
1;2 1;2
a. Notice g = w(m−P )−w2 = w(m−2w+a)−w2. We obtain:
1;2 2;1
g > −θ ⇐⇒ −3w2+mw+aw+θ > 0
1;2
Let g +θ = f(a˜) = w2+mw−aw+θ where w = 0.5(α+a˜ν −˜bη) by Proposition A.2.
1;2
Let ℓ < h be the roots at which f(a˜) vanishes. Since ∂2f < 0, it follows that g > 0 iff
θ θ ∂a˜2 1;2
ℓ < a˜ < h . The argument for ˜b is identical.
θ θ
We can give explicit formulas for the bounds as follows.
Proposition A.9. Assume that P1, P2 report M′ = a˜,M′ =˜b and the investor honestly reports
21 31
M′ = M′ = m = m˜. Then ℓ < a˜ < h and ℓ′ <˜b < h′, where:
12 13 θ θ θ θ
a−3α˜+3˜bη+m−(cid:112)
(a+m)2+12θ
ℓ =
θ
3ν
a−3α˜+3˜bη+m+(cid:112)
(a+m)2+12θ
h =
θ
3ν
(cid:112)
b−3α˜+3a˜η+m− (b+m)2+12θ
ℓ′ =
θ 3ν
(cid:112)
b−3α˜+3a˜η+m+ (b+m)2+12θ
h′ =
θ 3ν
38If a = b then ℓ = ℓ′ and h = h′, where:
θ θ θ θ
(cid:112)
3α˜−(a+m)− (a+m)2+12θ
ℓ =
θ
3ν
(cid:112)
3α˜−(a+m)+ (a+m)2+12θ
h =
θ
3ν
Proposition A.10. Let a˜ = M′ = M′ = c be as in Theorem 4.3.1. Suppose a = M =
NS 12 13 1−s 12
M = b. Under the trade deadline mechanism with penalty θ, the Nash-optimal choice of a˜ for P2
13
when both hedge funds are strategic is:
a˜ (θ) = clip(a˜ ,ℓ†,h†)
NS NS θ θ
Where ℓ† = max{ℓ ,A }, h† = min{h ,A }, and A ,A are the min and max of {c +
θ θ min θ θ max min max a
sℓ ,c +sh }. Further, the Nash-optimal choice for P3 is ˜b (θ) = a˜ (θ).
θ a θ NS NS
Proof. ByPropositionA.8,P2shouldchooseatomaximizeg given˜b,m˜ andsuchthatℓ < a < h .
2 θ θ
The Lagrangian of the constrained problem is:
maxg (a˜)−λ (ℓ −a˜)−λ (a˜−h )
2 1 θ 2 θ
a˜
For Lagrange multipliers λ ,λ ≥ 0. The stationary point with respect to a˜ is the solution to
1 2
∂g 2 = λ −λ .
∂a˜ 2 1
Next, given a fixed ˜b that is reported by the other hedge fund, the optimal a˜∗ = clip(c +
a
s˜b,ℓ ,h ). A similar formula holds for ˜b∗. Hence, if both P2 and P3 are strategic, we solve for the
θ θ
fixed point for a˜∗ via subsitution.
a˜∗ = clip(c +s˜b∗,ℓ ,h )
a θ θ
= clip(c +s·clip(c +sa˜∗,ℓ ,h ),ℓ ,h )
a b θ θ θ θ
= clip(clip(c +sc +s2a˜∗,A ,A ),ℓ ,h )
a b min max θ θ
= clip(c +sc +s2a˜∗,ℓ†,h†)
a b θ θ
The second step follows because a = M = M = b and so ℓ′ = ℓ and h′ = h in Prop A.9.
12 13 θ θ θ θ
39Next, let z(a˜∗) = c +sc −(1−s2)(a˜∗). Then 0 = clip(z(a˜∗),ℓ† −a˜∗,h† −a˜∗). Notice that
a b θ θ
|s| < 1/2, so z(a˜∗) is monotonically decreasing in a˜∗. Moreover, if a˜∗ = c 1a −+ ss 2c b := a˜ NS then
z(a˜∗) = 0. Since z is linear in a˜∗, we know a˜ is its only root.
NS
We conclude that the formula for a˜∗ is valid in all cases.
Case 1. If a˜ < ℓ†, then z(ℓ†) < z(a˜ ).
NS θ θ NS
Hence a˜∗ = ℓ† is a solution, since clip(z(ℓ†),ℓ† −(ℓ†),h† −(ℓ†)) = 0.
θ θ θ θ θ θ
Case 2. If a˜ > h†, then z(h†) > z(a˜ ).
NS θ θ NS
Hence a˜∗ = h† is a solution, since clip(z(h†),ℓ† −(h†),h† −(h†)) = 0.
θ θ θ θ θ θ
Case 3. Ifℓ† < a˜ < h†,thena˜∗ = a˜ isasolution,sinceclip(z(a˜ ),ℓ†−a˜ ,h†−a˜ ) = 0.
θ NS θ NS NS θ NS θ NS
Finally, since ˜b = a˜ and the bounds ℓ′ = ℓ , h′ = h are the same, we conclude that
NS NS θ θ θ θ
˜b (θ) = a˜ (θ).
NS NS
As before, we can derive explicit formulas by combining the above result with Propositions A.5
and A.9.
Proposition A.11. In the setting of Proposition A.10, if the investor reports m˜ and α˜ = m˜ ,
2+ρ
then:
(cid:26) (cid:18) (cid:26) (cid:27)(cid:19)(cid:27)
aν −α˜ ν(1−ν) ν(1−ν)
ℓ† = max ℓ , +min ·ℓ , ·h
θ θ ν(2−ν) ν(2−ν) θ ν(2−ν) θ
(cid:26) (cid:18) (cid:26) (cid:27)(cid:19)(cid:27)
aν −α˜ ν(1−ν) ν(1−ν)
h† = min h , +max ·ℓ , ·h } ,
θ θ ν(2−ν) ν(2−ν) θ ν(2−ν) θ
where ℓ ,h are as in Proposition A.9.
θ θ
40