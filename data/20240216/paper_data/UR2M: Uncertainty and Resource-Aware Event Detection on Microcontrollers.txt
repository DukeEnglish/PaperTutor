UR2M: Uncertainty and Resource-Aware Event
Detection on Microcontrollers
Hong Jia∗, Young D. Kwon∗, Dong Ma†, Nhat Pham‡, Lorena Qendro§, Tam Vu¶ and Cecilia Mascolo∗
∗University of Cambridge, Cambridge, UK †Singapore Management University, Singapore
‡Cardiff University, Cardiff, UK §Nokia Bell Labs, Cambridge, UK ¶University of Colorado Boulder, Colorado, US
{hj359, ydk21}@cam.ac.uk, dongma@smu.edu.sg, phamn@cardiff.ac.uk,
lorena.qendro@nokia-bell-labs.com, tam.vu@colorado.edu, cm542@cam.ac.uk
Abstract—Traditional machine learning techniques are prone
Mobile ML TinyML
to generating inaccurate predictions when confronted with shifts
inthedistributionofdatabetweenthetrainingandtestingphases.
Platform
This vulnerability can lead to severe consequences, especially in
applications such as mobile healthcare. Uncertainty estimation STM32F205VB STM32F446ZE STM32H743VIT6
has the potential to mitigate this issue by assessing the reliability
SRAM 6GB 64KB 128KB 1MB
of a model’s output. However, existing uncertainty estimation
eFlash 128GB 128KB 512KB 2MB
techniques often require substantial computational resources
Power 20W 0.2W 0.8W 1.2W
and memory, making them impractical for implementation on
Price ~$1000 $2 $3 $9
microcontrollers (MCUs). This limitation hinders the feasibility
of many important on-device wearable event detection (WED) Fig. 1: Memory and power comparison between a typical
applications, such as heart attack detection. mobile phone and microcontrollers.
In this paper, we present UR2M, a novel Uncertainty and
Resource-awareeventdetectionframeworkforMCUs.Specifically,
we (i) develop an uncertainty-aware WED based on evidential of prediction reliability [5], which is crucial in fields like
theory for accurate event detection and reliable uncertainty health. Reliability is quantified as uncertainty, indicating the
estimation; (ii) introduce a cascade ML framework to achieve
trustworthiness of the classification results [6]. Factors such as
efficient model inference via early exits, by sharing shallower
hardware differences, environmental variations, data collection
model layers among different event models; (iii) optimize the
deployment of the model and MCU library for system efficiency. methods, and sensor degradation can lead to distribution shifts
We conducted extensive experiments and compared UR2M to between training and testing data (data uncertainty) or unseen
traditional uncertainty baselines using three wearable datasets. data (model uncertainty [7]), reducing the reliability of WED
Our results demonstrate that UR2M achieves up to 864%
models.
faster inference speed, 857% energy-saving for uncertainty
estimation, 55% memory saving on two popular MCUs, and Several methods for quantifying uncertainty have been
a 22% improvement in uncertainty quantification performance. investigated. Bayesian Neural Networks (BNNs), a prominent
UR2M can be deployed on a wide range of MCUs, significantly approach for uncertainty estimation, quantify uncertainty by
expanding real-time and reliable WED applications.
estimating posteriors over model weights [8]. However, BNNs
Index Terms—Uncertainty, Event Detection, Efficiency, Micro-
entailsubstantialcomputationalexpenses[9].Althoughapprox-
controllers
imation techniques such as Monte Carlo dropout (MCDP) [10]
I. INTRODUCTION and deep ensembles [7] have been proposed, these methods
With advancements in pervasive, low-power, and embedded still require ensembling multiple models and various inference
sensors,arangeofhumanphysiologicalsignalscanbecollected steps, which introduce intensive computational and memory
and continuously analyzed. Empowered by machine learning demands,aswellasincreasedlatency.Recentresearchhasalso
(ML),especiallydeeplearning(DL),thesesensorsprovidegreat introduced deterministic models that require only one forward
opportunitiesforaplethoraofwearableeventdetection(WED) pass, making them more efficient but at the cost of lower
applications, such as the detection of stress levels [1], blood accuracy[11].Asaresult,integratingreliableuncertaintycould
pressure [2], or respiratory illnesses [3]. Recently, deploying pose additional complexities in the design and deployment of
ML models directly on microcontrollers (MCUs) has attracted trustworthy WED models on MCUs.
tremendous attention due to their potential to improve user Lastly,existingworksdemonstrateinefficiencyinsupporting
privacy and computational latency in WED, especially under multi-event detection on MCUs, as they typically employ
unstablenetworkconditions[4].However,asshowninFigure1, individual models for each event to ensure reusability across
designing and deploying efficient WED models on MCUs is different applications or use cases and to optimize efficiency
challenging due to their limited memory space and battery life, for each model [12]. However, wearable devices often require
especially in comparison to mobile phones [4]. the simultaneous detection of multiple events. For instance, a
Furthermore, many existing WED models prioritize enhanc- single electroencephalography (EEG) input might be utilized
ing classification accuracy while overlooking the importance to concurrently detect the brain’s alpha wave (event 1) for a
4202
beF
41
]GL.sc[
1v46290.2042:viXraguided-meditation application, and beta wave (event 2) for a STM32H747F7, with limited SRAM memory (128KB
focus monitoring application. Additionally, executing multiple and 512KB, respectively). Our evaluation shows that the
inferences (encompassing both prediction and uncertainty esti- proposedframeworkperformsupto864%betterinference
mation) for varied events can be resource-intensive, potentially speed and 857% energy saving compared to uncertainty
rendering WED deployment on MCUs impracticable due to baselines. The approach also saves 55% of memory
memory constraints. compared with existing uncertainty estimation baselines
To address the aforementioned challenges, we propose an (§VII-§VIII),enablingthedeploymentofWEDmodelson
efficient uncertainty estimation approach based on evidential MCUs with limited memory (e.g., STM32F205VB with
deeplearning(EDL)andcascadelearning.Specifically,(i)EDL 64KB SRAM).
is designed to predict a distribution, parameterized by a vector,
instead of providing a point prediction through a single DL
II. RELATEDWORKS
model,whichallowsforthedirectpredictionofeventdetection
and its associated uncertainty via a single inference. (ii) For This section briefly discusses the literature on machine
each event (intra-event), we consider three models of varied learning on MCUs, event detection on resource-constrained
depths(i.e.,shallow,medium,anddeep);herein,deepermodels devices, and efficient methods for uncertainty estimation.
are stacked upon shallower ones, meaning the lower layers are Tiny machine learning on MCUs. Tiny Machine Learn-
shared.Aclassifierlayer(termeda“head”)isappendedtoeach ing [14] (TinyML) aims to execute deep learning models
model.Thisdesignadherestotheobservationthatsometesting locally on extremely resource-constrained devices such as
samples,particularlythosenearthecenterofthetrainingsample MCUs.Recentstudieshaveconcentratedonoptimizingnetwork
distribution, do not require a full pass through the deep model architectures considering constraints such as limited memory,
to ensure a reliable prediction [13]. Consequently, early exits energy, FLOPs [4], and processor speed [15]. However, these
can be employed to enhance computational cost-effectiveness approachesfocussolelyonclassificationaccuracy,treatingthem
and inference speed, with uncertainty chosen as the criterion as single-point predictions without considering uncertainty es-
for an early exit to ensure the reliability of the prediction. timation. In contrast, we further include uncertainty estimation
(iii) For multiple events (inter-event) using the same input, we of the desired predictions to enable a more reliable WED.
propose the sharing of all layers for feature extraction and Event detection on resource-constrained devices. Recent
the training of individual classification layers (referred to as years have seen a surge in research focused on event detection
“multi-heads”). As a result, our framework can be effortlessly usingwearables,exploringvarioussensingmodalitiesincluding
scaledtomultipleeventswithminimalmemoryoverhead,since image [16], audio [17], electrocardiogram (ECG) [18], and
only the heads need to be added. Additionally, reusing shared others. However, most existing WED approaches only utilize
layers for different events reduces computation time and cost. wearables for data collection, offloading processing tasks like
We further apply three techniques to improve the efficiency pre-processing, feature extraction, and ML modelling to cloud-
of our approach during implementation. First, we implement based GPUs (through WiFi) [3], [19], desktop GPUs [20],
an architecture search to find the optimal model structure mobile devices [1] or IoT devices [21]. This category of
automatically (e.g., number of model layers and size of approaches can lead to high latency during signal transmission
channels) for specific WED tasks based on recent success or raise privacy concerns. To address these challenges, our
models designed for MCUs [14]. Second, we conduct scalar focus is on comprehensive WED for on-MCU computation,
quantizationofthemodelweightsinto8-bitintegerstodecrease developing efficient and lightweight ML models suitable for
the model size and further save memory. Third, to reduce the limited-resource environments.
memory consumption of the deep learning library, we remove
Efficient uncertainty estimation. Some effort has been
unnecessary components that are not utilized in our models.
devoted to achieving efficient uncertainty estimation, such as
Finally,weconductcomprehensiveexperimentswithtwoMCU
regulating the neural network weights to simulate BNNs [22].
platforms to demonstrate the effectiveness of the proposed
Another stream of studies focuses on expensive and not
approach.
deployable operations on MCUs like flow [23], spectral
To summarize, we make the following contributions:
normalization [24], and stochastic Convolutional layers [9].
• We propose a cascade model architecture with intra-event Despite their success in improving computation efficiency,
andinter-eventlayersharingtoenableefficientmulti-event their accuracy still either performs four times worse than
detection. We also conduct efficient architecture search, the state-of-the-art (SOTA) method of deep ensembles [7]
model compression, and library optimization to improve or require customized operators and libraries that are currently
system efficiency (§V-§VI). unavailable on MCUs. As an alternative to using ensembles,
• We propose a novel uncertainty-aware learning paradigm knowledge distillation [25] has been proposed as a means
based on evidential theory for efficient and reliable WED of training a single model. However, knowledge distillation
uncertainty estimation on MCUs (§IV). typically requires out-of-distribution (OOD) data, which is
• We conduct extensive experiments on three popular often difficult to obtain for real-world applications. Compared
wearable datasets and implement our framework on to existing work, our study is the first to propose an efficient
two off-the-shelf MCUs, including STM32F446ZE and model for uncertainty quantification on MCUs.Model training (§IV&§V) Deployment (§VI)
Multi-tenancy
Deep deployment
Deep
Model
Y
one-vs-all training (§IV) > N quantization
Medium
Uncertainty
operators wrap-up
Y
event? > N
MCU library
Shallow
uncertainty optimizaton
Wearable sensor Feature
event steaming extrator Evidential deep learning (§IV) Single-event (§V) Multi-event (§V) Optimization
Deep NNs blocks NNs layers Binary dataset Binary output > Uncertainty threshold Early exit
Fig. 2: System overview.
III. UR2MSYSTEMOVERVIEW parameters of the distribution (dense distribution means high
evidence and low uncertainty) [22]. Being a conjugate prior to
UR2M includes two stages: model training (§IV-§V)
the categorical distribution, the Dirichlet distribution enables
and deployment (§VI) as shown in Figure 2. During the
EDLtodeterminethebeliefmassbi =[bi,bi,...,bi ]correlating
training stage, there are three objectives: (1) EDL for efficient 1 2 C
directly with uncertainty. A higher belief mass indicates a
uncertainty quantification, (2) Cascade ML learning which
higher confidence in the prediction, whereas a lower belief
includessingle-event(intra-event)detectionviaearlyexits,and
mass suggests the presence of uncertainty. Formally,
multi-event(inter-event)detectionviafeaturesharingandmulti-
heads. During the deployment stage, we first carry out (1) bi =(αi−1)/Si, (1)
multi-tenancy deployment [26], allowing multiple ML models
(referred to as “tenants”) to efficiently and dynamically share where Si =(cid:80)C αi is the Dirichlet strength. From αi and
c=1 c
the same memory space among intra-event models. We then bi, we can further infer the categorical prediction yˆi and the
furtherfocuson(2)optimizingthemodelandtheMCUlibrary. associated uncertainty ui as:
C
In detail, wearable sensors first capture event streaming yˆi =argmax[αi/Si], ui =1−(cid:88) bi (2)
c
signals. Features are then extracted for different signals, such c
c=1
as Mel-frequency cepstral coefficients (MFCC) for the audio Before the training process, acknowledging our initial state
signals. Following this, evidential modeling via EDL and one- of complete uncertainty about the outputs (i.e., uncertainty ui
vs-alltraining(§IV)areappliedtoobtainreliableWEDpredic- is set to 1), we initialize αi with [1,1,1], corresponding to
tions and estimate uncertainty. Within the EDL framework, we bi =[0,0,0]accordingtoEq.1andEq.2.Torefinethemodel,
specifically designed a cascade learning architecture (§V) for we employ a loss function defined as:
single-event detection, which divides the network layers into
N
shallow, medium, and deep levels to enable intra-event sharing minL= 1 (cid:88) CE(αi/Si,yi)−λ·H(Dir(αi)) (3)
(sharing shallower layers and inferring with early exits within θ N c
i
an event model) and process samples at different levels of where CE denotes the cross-entropy loss, and H represents
recognition difficulty. Further, we propose inter-event sharing theentropyofaDirichletdistributionparameterizedbyαi.The
(sharing entire layers for feature extraction) for multi-event first term of the loss function aims to maximize classification
detection. In addition to the modeling, we further carry out accuracy,whilethesecondtermcontrolstheoutputdistribution
efficiency improvements (§VI) via model architecture search to avoid overconfidence. The hyperparameter λ plays a crucial
(duringmodeltraining),quantization,uncertaintyoperatorwrap- role in balancing these two terms.
up, and MCU library optimizations. Finally, this procedure will lead to a predicted αi for each
sample which is used to infer the categorical outcome and the
IV. EFFICIENTUNCERTAINTYQUANTIFICATION associated uncertainty (e.g., u=1−(cid:80) bi).
In this Section, we propose a highly efficient EDL model
B. EfficientEvidentialModelingforEventDetectiononMCUs
tailored for event detection on MCUs. This model is optimized
to adhere to the constraints of MCUs, employing distributions ImplementingtheEDLdiscussedin§IV-AforWEDrequires
to achieve accurate uncertainty quantification in real-time deployingmultiplemodelsandperformingaseriesofinferences
scenarios through a single forward pass. to detect various events, which significantly challenges the
limited computational resources of MCUs. To mitigate this,
A. Evidential Deep Learning
we propose an efficient EDL modeling for WED, along with
For a given input xi, EDL generates a Dirichlet distribution related training and optimization techniques designed to infer
Dir(αi), where αi =[αi,αi,...,αi ] denotes the concentration multiple events concurrently.
1 2 C
Ada
pool
Architecture
search
Ada
pool
Ada
pool
Ada
pool
Cascade
learningEfficient EDL Modeling for WED. WED is designed to ensures that the outputs remain non-negative, aligning with the
identify an event signal coming from a wearable device. In positive αi and enabling the NNs to predict distributions for
ML/DL, this objective is defined as a binary classification task each event task.
over a given duration/period of sensor data. For each binary
C. Uncertainty-aware training and optimization
classifierthatdetectsclassesoftheeventc,theoutputsofEDL
include the binomial belief mass, which can be used to infer Focusing on the training and optimization of the EDL
the uncertainty of the WED prediction, i.e., how confident framework for the proposed multi-event WED, we draw
it is to be classified as positive (i.e., an event happening) or inspiration from Eq. 3 and propose using the binary cross
negative (i.e., an event not happening). entropy and Beta loss for each binary classifier of event c as:
negG ai tv iven e),th we ebi an da ory ptn aat Bur ee taof dio su trr ibE uD tiL onfr (a am se pw eco ir ak l( cp ao ss eit oiv fe thv es m θinL= N1 (cid:88)N BCE(cid:0) ψ ci/S ci,y ci(cid:1) −λ·H(cid:0) B(cid:0) ψ ci(cid:1)(cid:1) (8)
Dirichlet distribution) to model the event probability. Specifi- i
cally, a Beta distribution is characterized by two parameters where ψi symbolizes the Beta distribution parameters
c
α ci and β ci such that (α ci,β ci), BCE is the binary cross-entropy loss, H represents
P(pi
c
|xi;θ c)=Beta(pi
c
|α ci,β ci) the entropy of a Beta distribution B parameterized by ψ ci and
λ serves as a balancing weight between the cross-entropy loss
1 (4)
= pαi c−1(1−p)β ci−1, and entropy of the Beta loss. For all C events, we collectively
B(αi,βi)
c c optimize all binary classifiers [28], enabling the model to
where P(cid:0) pi
c
|xi;θ c(cid:1) denotes the probability distribution of perform inference with just a single forward pass.
the event given the sensor sample xi, with both αi, and βi
c c
being greater than zero. B(αi,βi)=Γ(αi)Γ(βi)/Γ(αi +βi) V. CASCADELEARNING
c c c c c c
is the Beta function, Γ(·) is the gamma function, and pi ̸= Thissectiondiscussesdesigningefficientneuralnetworksfor
c
0. Applying the mapping rule in Eq. 2, the prediction and UR2M. We explore the benefits of the early-exit strategy and
uncertainty u for each sample i are derived via a NN: architecture search method for single-event sharing on MCUs,
bi = α ci −1 , bi = β ci−1 (5) reducing computational and memory costs. We also examine
1 αi +βi 2 αi +βi multiple-event sharing and detail the training pipeline using
c c c c
cascade learning, with all search and training on the server.
ui =2/(αi +βi) (6)
c c
A. Single-event Sharing
where b represents the probability of a positive prediction
1
while b denotes that of a negative prediction. For many DL tasks, some input samples, referred to as
2
One-versus-all classifiers. To obtain the parameters of αi “easy” samples, can be effectively classified using shallower
c
and βi in EDL across multiple events, we adopt the one- layers of the representation. This indicates that these shallower
c
versus-all (OVA) classifier, where each classifier distinguishes representations can identify “easy” samples, thus avoiding
a specific event from all others, leading to C binary classifiers extra computation, whereas more “difficult” samples require
(i.e., heads). Specifically, in multi-event WED, we split the processing through deeper layers [29]. However, unlike edge
entire training dataset into C independent datasets with binary GPUs, designing model sharing on MCUs is challenging given
labels (i.e., event c vs. non-event c for c ∈ [1,C]). For each the limited computing power, memory, and library support.
event, we then develop a model to learn a set of mapping Using Early-exits to Share Shallower Layers. We propose
functions h (xi;θ ), where xi represents the input signal, and a nested architecture featuring three early exits (sub-networks),
c c
θ arethemodelweights.Theoutputsofthemappingfunctions which include shallow, medium, and deep models designed for
c
yield the parameters αi and βi in the Beta distribution, single-event (intra-event) sharing, as illustrated in Figure 2 for
c c
computed as: MCUs. Each sub-network is designed using identical blocks
αi,βi =h (cid:0) xi;θ (cid:1) (7) of neural network layers, inspired by efficient neural networks
c c c c
for edge devices [30]. Existing early-exit methods usually rely
From this, we can deduce binomial decisions, with bi on accuracy as a criterion to prune model branches. However,
1
denoting a positive prediction (i.e., event happening), and bi uncertaintycanactasacrucialindicatorforreliableprediction:
2
representing a negative prediction (i.e., event not happening). we propose using uncertainty as a metric to determine whether
Subsequently, these mapping functions are optimized jointly to exit at each sub-network. As demonstrated in Figure 2,
through an OVA training [27]. With this joint training of a uncertainty thresholds are applied at the output of both shallow
shared EDL model, there is no need to deploy separate models and medium models to facilitate early exits for data with low
on MCUs, thereby significantly reducing memory costs. uncertainty (i.e., reliable predictions), thereby saving on MCU
In contrast to traditional softmax-based deep learning ap- overheads.
proaches, which force the Neural Networks (NNs) to predict a Uncertainty-aware Architecture Search. To find efficient
pointestimation,wecanreplacethesoftmaxlayeroftheneural neural networks that minimize MCU overhead, recent studies
network with a ReLU layer (or an exponential function but have shown that the number of operations (OPS) and channel
softplus is not available in the MCU library). This adjustment sizes [14] are two crucial factors. Considering this, we proposeAlgorithm 1: The Search and training of UR2M different applications or use cases and to optimize efficiency
Input: Channel L, OPS size O, DTRAIN, DTEST for each model [12]. These models can occupy C times the
MCU memory and computation cost compared to a single-
Output: Event prediction y and uncertainty u
Data: Training data DTRAIN event model. However, some singular events may share similar
characteristics, which can be captured by an identical network
/* search single-event model */
for feature extraction. For example, EEG signals are often
1 best_backbone, best_score = False, 0
used to detect alpha waves (event 1) and beta waves (event 2)
2 for i in L do
usingtwoindependentmodels,despitethefactthatbothwaves
3 for j in O do
// Train candidate NNs backbone (bij) describe brain activities and can share certain information.
4 NN←b ij(W ij,L i,O j) Using Heads to Share Entire Backbone. We propose our
5 accuracy ← NN(DTRAIN) multi-event detection models, which share three sub-networks
6 tradeoff ← accuracy/OPS (i.e., shallow, medium, and deep) and consist of C∗3 adaptive
7 if tradeoff < best_score then classifiers(cf.Figure2).Comparedtomulti-classclassification,
8 best_NN, best_score = NN, tradeoff our multi-event sharing framework allows for more flexibility
in single-event detection, which is especially preferred on
9 return best_NN
low-power MCUs to ensure efficiency and reusability across
/* train with cascade learning */ multiple applications. Specifically, as illustrated in Figure 2,
10 for l=0,1,2 do for each shared shallow, medium, and deep backbone NNs, we
// take each output as next exit’s input design C independent classifiers to distinguish the C events.
11 u, output ←(b l (W l),DTRAIN) Each classifier is composed of an adaptive pooling layer and
12 DTRAIN ← output a linear layer. The adaptive pooling layer aims to adjust the
13 if converge then different output sizes from the searched shallow, medium, and
14 return W l deepsub-networkstomatchtheinputsizeoftheclassifiers.We
optimize all the classifiers in a multi-task learning paradigm.
Uncertainty-aware Cascade Learning. To train the afore-
an effective yet straightforward architecture search method to
mentioned shallow, medium, and deep models for MCUs,
identify optimal neural networks for the early-exit models (i.e.,
we propose an uncertainty-aware cascade model inspired by
shallow, medium, and deep models) in single-event sharing.
deep cascade learning for training our early-exit models. As
Specifically, we employ the Depthwise block as the OPS
illustrated in Algorithm 1 (Lines 10-14), we employ three
to control model depth, as it serves as an ideal proxy for
optimizers for the three exits, with each exit representing one-
managing model latency on MCUs [14]. The structure of
third of the model layers. Initially, we train the first one-third
each block consists of 1×1 Convolutions, 3×3 Depthwise
of the layers in the searched backbone model and then utilize
Convolutions, and 1×1 Convolutions. We design each block
its output to train the second exit. Finally, we optimize the
using a 2D convolutional layer to to effectively handle various
third exit.
input types and extract the initial features. Subsequently, we
During each exit, we apply a single-layer linear layer
use a consistent padding strategy to control the depth of OPS,
(referred to as a head) for each event, which takes input maps
ensuringthattheoutputofeachblockmatchesitsinput.Lastly,
of the output dimensions of the early-exits. Each early exit
we incorporate a linear classifier in each block as the output
produces two outputs: the prediction and the uncertainty. We
layer for single-event detection.
optimize all sub-networks concurrently on the server.
To define the model search space for efficient architectures
Our design is supported by the MCU libraries of Tensorflow
on edge devices, we configure channel sizes L (ranging
Lite Micro (TFLM) in terms of multi-tenancy (e.g., enabling
from 32 to 512) and OPS sizes O (3 to 7), drawing from
model deployment in a cascade manner) and memory planner
models like MobileNet [30], DSCNN [31] for mobile devices,
(e.g.,reusingthesameoperator’smemory).Thiscoherencecan
and MicroNets [14] for MCUs. This leads to 60 potential
significantlyreducetheoverheadscomparedtotheconventional
configurations (N = L × O), each comprising three sub-
multi-event detection models. Overall, our approach aims to
networks.Our objective is toidentify the optimalconfiguration
optimize the performance of the models while accounting for
N∗ that balances minimal OPS with maximal accuracy. As
uncertainty and providing early exits for faster inference.
outlinedinAlgorithm1(Lines1-9),thesearchprocessinvolves
initially setting a best backbone and score (Line 1), iterating VI. IMPLEMENTATION
throughcombinationsofchannelandOPSsizes(Lines2-3),and
A. System Implementation
assessing candidate NNs based on accuracy and operational
Hardware. The training stage of our system is implemented
space trade-offs (Lines 5-8), to ultimately select the most
and tested on a Linux server equipped with an Intel Xeon
efficient and accurate NN backbone (Line 9).
Gold 5218 CPU and NVIDIA Quadro RTX 8000 GPU. The
B. Multiple-event Sharing shared backbone and multiple heads are pre-trained during
For a C multi-event detection task, a common approach this stage. Afterwards, in the deployment stage, we deploy the
is to develop individual models to ensure reusability across shared backbone and heads on two MCUs. The first one is2⨉64 1⨉2 1⨉1
TF Micro Graph & Quantization Params Others Weights+Bias
Relu ReduceSum Div Uncertainty
Shared
Backbone Memory 0 122 130 195203
Output 2⨉64 1⨉2 Event (KB) TF Micro Others Graph & Quantization Params Weights+Bias After RU2M Optimization
FullConnect SigMoid No Event 32 9096104 49% smaller
(a)UncertaintyclassifierinTFLMformat (b)MCUslibraryoptimization
Fig. 3: Deployment stage. (a) Uncertainty deployment on MCU based on multiple operators to calculate uncertainty and
classification results. (b) MCU library space before optimization (top) and after optimization (bottom).
the STM32F446ZE (or F446ZE), which has an ARM Cortex library to save the overhead of uncertainty prediction. The
M4 processor with 128 KB of SRAM and 512 KB of eFlash. overall uncertainty implementation is shown in Figure 3a.
The other one is the STM32H747XI (or 747XI), featuring a
C. MCU Library Optimization
dual-core processor (ARM Cortex M4 and M7) with 1 MB of
SRAM and 2 MB of eFlash. Our evaluation only utilizes one Unlike mobile devices’ memory architecture that employs
core (ARM Cortex M7) since MCUs are typically equipped large off-chip main memory (e.g., DRAM), MCUs consist of
with only one CPU core. This setup limits the usage space of only small-sized on-chip memory (e.g., SRAM and eFlash) (cf.
SRAM and eFlash to 512 KB and 1 MB, respectively. Figure1).Tounderstandthememoryrequirementsofourmodel
Wedevelopedandassessedoursystem’strainingstageusing to fit in MCUs, we first compute the memory usage of UR2M.
PyTorch 1.8, and tested various baselines on a Linux server. For a searched shallow model with 8-bit int quantization, we
The evidential uncertainty module is implemented with Python observe that TFLM requires 79 KB of SRAM and 203 KB of
and NumPy. We adopted TensorFlow Lite Micro (TFLM) [26] eFlash, which falls within the tight memory budgets of many
for MCU deployment due to its portability, ease of use, and MCUs, for example, 64 KB of SRAM and 128 KB of eFlash
support for numerous neural network layers and optimized of STM32F205VB as described in Figure 1. In particular,
kernels. UR2M’s deployment stage and online optimization on SRAM, the memory usage includes intermediate tensors
schemearedevelopedinC++ontwoMCUs(ARMCortexM4 (30 KB), persistent buffers (3 KB), runtime overhead of the
and M7). To deploy a PyTorch model on MCUs, we convert TFLM interpreter (6 KB), and MBed OS and other libraries
it to TensorFlow Lite (TF Lite) using ONNX representation (10 KB). Additionally, Figure 3b top shows the on-chip eFlash
and the TF Lite converter. The model is run on MCUs using architecture of an F446ZE MCU and how TFLM allocates
TFLM and Mbed OS. Additionally, the CMSIS-DSP software memory space to run a shallow model on an MCU.
library processes raw signals to generate model inputs (e.g., Note that since we only conduct 8-bit post-quantization, we
MFCCfeatures),andtheCMSIS-NNkernelsinTFLMfacilitate only observe a maximum of 1% performance drop between the
efficient neural network operations on MCUs. pre-and post-quantization stages among all methods.
Multi-tenancy Deployment. To facilitate multi-event sharing Given the limited memory space for searching the optimal
on MCUs with limited memory, we develop a multi-tenancy model parameters, we propose optimizing the TFLM library.
deployment for early-exit models using TFLM. UR2M utilizes First,weremovedalloperation-relatedfilesthatdidnotimpact
multiple model interpreters to allocate memory from a unified ourbackbone.Then,wereorderedtheoperationsfilesbasedon
space, ensuring efficient model operation. During evaluation, our backbone structure. As shown at the bottom of Figure 3b,
this deployment strategy is applied to all baselines and the ourMCUlibrarysignificantlyoptimizedtheTFLMinterpreter’s
UR2Mmodel.Forexample,DeepEnsembleshavefivemodels, runtime overhead, reducing it from 122 KB to 32 KB (3.8×
potentiallyusing5×eFlashspace.However,withoptimization, smaller). Moreover, the graph definition was reduced by 2
it only consumes 2× more SRAM (cf. §VIII-C) due to multi- KB, from 8 KB to 6 KB, in the eFlash memory. After the
tenancy deployment. optimization, a total of 104 KB of memory is used, which
B. Uncertainty Operator Implementation can now fit into the STM32F205VB and many other MCUs.
Overall, UR2M optimizes 49% of eFlash memory compared
To capture the uncertainty at inference time on MCUs, we
to the baseline TFLM library.
only use TFLM-supported operations
Note that during the evaluation, we applied the same MCU
.First,weutilizeaReLUoperatortoregulatethedistribution
library optimization strategy to all baselines as well as the
oftheoutputasnon-negatives.Then,basedontheseoutputs,we
UR2M model.
follow Eq.6 to generate uncertainties. Specifically, calculating
uncertainty first requires the sum of reduced dimensions.
VII. EVALUATIONSETTINGS
Although the reduced_sum operator
A. Evaluated Datasets
is supported, it is not available for TFLM. To solve this,
we use a squeeze operator to reduce the output dimensions, Our target application scenarios are focused on WED
followedbyasumoperator.Finally,weapplyadivideoperator applications. Specifically, we evaluate three wearable datasets,
to generate the uncertainty. We wrap the above-mentioned including in-ear activity recognition [32], audio event keyword
operators within the model and implement them in the TFLM spotting [33], and heart disorder event detection [34]. We0.95 0.96 Shallow Medium Deep 1.00 Shallow Medium Deep 1.00 Shallow Deep
0.92 0.94 0.98 0.98 Medium
0.92 0.96 0.96
0.89 0.90 0.94 0.94
0.86 Oesense 00 .. 88 68 00 .. 99 02 00 .. 99 02
0.84
0.83 KWS 0.82 0.88 0.88
ECG5000 0.80 0.86 0.86
0.80 0.20 N.4 um0. b6 e0
r
. o8
f
1 O.0 pe1 r.2 at1 io.4 ns1 (.6 M1 B.8
)
0.78 Drink Chew Run Still Walk 0.84 Yes No Up Down Left Right On Off Stop Go Unknown Silence 0.84 NM RTPVC PVC SPEB UB
(a)Modelsizesvs.accuracy (b)PerformanceonOesense (c)PerformanceonKWS (d)PerformanceonECG5000
Fig. 4: Model sizes vs. Accuracy and early exit result for single events. Note that the ECG5000 UB event has only one test
sample.
experiment with these three datasets, each featuring different Expected Calibration Error (ECE), to examine the uncertainty
data modalities that suit UR2M settings. For imbalanced estimation performance.
datasets, we use SMOTE [35] to upsample the training data.
C. Uncertainty Quantification Baselines
In-ear Dataset. Oesense [32] contains an in-ear audio
dataset for activity recognition (including five events: “walk”, We evaluate the proposed method by comparing it to three
“run”, “still”, “drink”, and “chew”) among 31 subjects. For baseline uncertainty solutions: the traditional softmax-based
preprocessing, we first segment the original audio into one- models, deep ensembles and data augmentation. It is important
second segments and set the sampling rate at 4 kHz. Then, we to note that MCDP [10] is not available for the MCUs library
extract the 2-D MFCC features for each segment. 10 MFCC TFLM because it stores models as binary files that cannot be
features are then obtained from an audio frame with a length modified. Moreover, its computational costs are similar to or
of 80 ms and a stride of 40 ms, yielding an input dimension of greater than deep ensembles, while its uncertainty performance
1×10×21. After preprocessing each event, we obtained 40,064 is lower than that of deep ensembles [9].
training samples (90%) and 4,452 test samples (10%) for all Vanilla EDL. Vanilla EDL [22] is the state-of-the-art
five activities. (SOTA) model to efficiently quantify uncertainty and can be
KWS Dataset. The Keywords Spotting (KWS) V2 [33] implemented on MCUs.
datasetcontains105,829utterancesfrom2,618speakers.There Deep Ensembles. Deep ensembles approach (denoted as
are 35 words split into 12 classes, including ten keyword D(Softmax)+Ense) [7] is the SOTA model to accurately
spotting classes and an ’unknown’ class (remaining 24 words). quantify uncertainty estimation, which typically ensembles
Forpreprocessing,wefirstconstrainedalleventsamplestoone N deterministic Softmax models with random weight initial-
second by segmentation or zero-padding and set the sampling izations. We use N = 5 which is widely adopted in recent
rate at 16 kHz. Then we extracted MFCC features using 640 efficient studies [36].
FFT points and 320 points of hop length. We obtained 10 Data Augmentation. Test time data augmentation (denoted
MFCC features from an audio frame with a length of 40ms as D(Softmax)+InAug) [37] is a memory-efficient uncertainty
and a sliding window of 20ms, yielding the input dimension quantification method generating multiple test samples by
of 1×10×51. applying data augmentation techniques through a single model.
After preprocessing, we obtained 92,502 total event training Weutilizefiveaugmentedsamples,incorporatingJittering,with
samples (90%) and 10,278 test samples (10%). a mean ε of 0 and a standard deviation σ of 0.03, which are
ECG5000 Dataset. The ECG5000 dataset [34] is a 20-hour added to the test data.
long one-channel ECG dataset that contains 92,584 heartbeats,
VIII. RESULTS
including five different types of heart events: Normal (NM)
(58.4%), R-on-T Premature Ventricular Contraction (RTPVC) Thissectionwilldiscusstheresultsandanswerthefollowing
(35.3%), Premature Ventricular Contraction (PVC) (3.9%), questions: (1) How efficient is UR2M for typical MCUs? (2)
Supra-ventricular Premature or Ectopic Beat (SPEB) (2%), HowrobustisUR2Mcomparedwithtraditionalpointprediction
and Unclassified Beat (UB) (0.5%). For preprocessing, we models?
resampletheinputdurationof0.56swith140samplesinto560
A. Performance of Event Detection
samples. Then we reshape the input into 10 channels, yielding
the input dimension of 1×10×56. After the preprocessing, we Utilizing the Adam optimizer with a learning rate of 1e−3,
a 32 batch size, and an early stopping of 5 epochs, we train
obtained 4,500 total event training samples (90%) and 500
our networks, showcased in Figure 4a and Figures 4b- 4d.
(10%) test samples. Note that UB has only one test sample.
While system accuracy generally increases with OPS across
B. Uncertainty Metrics
all datasets, significant increases in overhead do not invariably
We compare UR2M using three important uncertainty equate to notable accuracy improvements, as observed in the
metrics: Brier score, Negative Log-Likelihood (NLL), and KWS and ECG5000 datasets. For instance, a shallow Oesense
ycarucca
tseT
ycaruccA ycaruccA ycaruccAD(Softmax)+Ense Vanilla EDL D(Softmax)+InAug UR2M(Ours) 1.00
Oesense KWS ECG5000 0.97 Power MM iP cr3 o4 pD hT o0 n5 e
Error Error Error 0.94 Bank
NLL eF2 NLL 0.11 eF2 NLL eF2 0.91 F M44 C6Z UE
0.65
285 0.88
Oesense
H M74 C7 UXI
Brier SR2Brier 0.65 75 SRB 2rier SR2 00 .. 88 25 0.0 K ECW 0GS .5 2 U00 n0 cer0 t. a4
inty
th0. r6 eshold0.8 1.0 MI icM roP ph44 o1 ne Deveu loc ple mo- e1 n4 t4 Kit PP ro ow fie ler r STM D3 IS2H CO747I-
285 Fig. 6: Uncertainty impact. Fig. 7: End-to-end deployment.
0.05
ECE eF1 ECE 75 eF1 ECE eF1
SR1 SR1 SR1 shallow layers. Similarly, it is observed that increasing the
Fig. 5: Comparing Vanilla EDL, data augmentation, deep
threshold gradually reduces latency across all three datasets
ensembles (SOTA), and UR2M using uncertainty, error rate,
when evaluated on the F446ZE and H747XI MCUs. With a
and memory usage metrics across three datasets. eF1 and SR1
higher uncertainty threshold, more samples are filtered out
refer to the eFlash and SRAM usage of H747XI, while eF2
by the shallow and medium sub-networks, and fewer samples
andSR2refertothoseofF464ZE,respectively.Forallmetrics,
pass through deep models, leading to reduced latency. This
lower values are preferred.
indicates that selecting different uncertainty thresholds allows
model (accuracy: 0.83, parameters: 0.38 MB) contrasts with users to obtain a personalized model, increasing the usability
the medium and deep models, which respectively present of UR2M.
0.87/0.58 MB and 0.91/0.76 MB in accuracy/parameters. The In sum, our model design, which allows users to define
2% accuracy enhancement when transitioning from medium the threshold, can help determine the optimized threshold to
to deep models incurs a 31% overhead spike. Similarly, for balance the tradeoff, thereby achieving personalized models.
ECG5000, a 1% accuracy improvement requires doubling
C. End-to-end System Efficiency
the model sizes. Shallow models across all datasets exhibit
Following the optimization of all baselines and UR2M
proficient performance (e.g., >80%) with minimized model
using techniques including multi-tenancy deployment, model
size, hinting that UR2M could deliver effective performance
quantization, and MCU library optimization, we evaluate their
with modest overheads.
runtime efficiency during deployment on MCUs (Figure 7).
Regarding the channel sizes, our searched model yields the
Ourevaluationencompassestheentiresystem,includingsignal
output shape for each OPS as [5,11] for Oesense, [5, 26] for
acquisition, feature extraction, and memory usage in terms of
KWS, and [5, 29] for ECG5000, respectively. Figure 4 further
SRAMandeFlashrequiredformodelexecution.Weconducted
illustrates the UR2M performance for single event detection
experiments with various datasets and two typical resource-
using shallow, medium and deep network structures.
constrained MCUs, the F446ZE and H747XI. Although the
Based on Figure 5, we can observe that UR2M’s uncertainty
focus is primarily on the ECG5000 dataset due to page limits,
metricsarebetterthanDataAugmentation(D(Softmax)+InAug)
note that consistent outcomes were observed across all three
baseline across all three datasets, with up to 22% lower
datasets.
NLL scores (0.65 to 0.53). This improvement indicates that
Model Inference Memory Footprint. Based on our im-
the proposed method produces better-calibrated models that
plementation, UR2M consumes only 49 KB and 51 KB of
are less prone to overconfidence errors. Compared to the
SRAM (38.5% and 9.9% of the total SRAM of F446ZE and
D(Softmax)+Ense model, UR2M achieves similar performance
H747XI, respectively) as shown in Figure 5. Additionally, as
intermsofbothuncertaintyestimationandpredictionaccuracy.
shown in Figure 5, UR2M requires 142 KB and 145 KB of
For instance, UR2M outperforms D(Softmax)+Ense by 8.0%
eFlash (27.7% and 14.1% of the total eFlash of F446ZE and
in terms of Brier score for KWS, and achieves 1.7% and 2.4%
H747XI, respectively). These results demonstrate that UR2M
relative improvements in NLL for Oesense and ECG5000,
consumes only a small portion of the limited resources of
respectively.
MCUs, leaving enough resources for other applications to be
Notably,UR2Machievestheseresultswhileusinguptoonly
supported simultaneously. Furthermore, UR2M requires only
half of the memory, much less energy, and latency required
66-67% of SRAM (49 KB vs. 75 KB for F446ZE and 51
by SOTA method deep ensembles (cf. Figure 5 and §VIII-C),
KB vs. 75 KB for H747XI) and 51% of eFlash (142 KB vs.
demonstrating the computational efficiency of UR2M without
280 KB for F446ZE and 145 KB vs. 283 KB for H747XI)
compromising uncertainty estimation.
compared to the deep ensembles baseline.
B. Impact of different Uncertainty Thresholds
SignalAcquisitionOverheads.Toevaluatesignalacquisition
Users can decide on the uncertainty threshold according overheads for the F446ZE MCU, we employ an INMP441
to their specific applications. For example, in healthcare MEMS microphone. For the H747XI, we use the MP34DT05-
applications (e.g., heart attack detection), we prefer a low A built-in microphone on the H747I-DISCO evaluation board
uncertainty (e.g., u=0.05) for detected heart attacks to avoid (Figure7).Weassessenergyconsumptionandmemoryusageas
disastrous consequences. This tradeoff is depicted in Figure 6. keyfactors.Energyconsumption(J)iscomputedastheproduct
Inotherscenarios(e.g.,runningdetection),ahigheruncertainty of time/latency (t) and power (W). Power is determined from
thresholdcanbetoleratedtosavebatterylifebyexitingthrough input voltage (V) and current measurements (A), conducted
ycaruccAD(Softmax)+Ense D(Softmax)+InAug UR2M
700 175 120 40 Baseline: Baseline: Baseline: Baseline:
600 150 100 Run Walk Chew Walk
500 125 80 30
400 100 UR2M: Chew UR2M: Chew UR2M: Chew UR2M: Chew
60 20 p: 0.67 u: 0.53 p: 0.61 u: 0.50 p: 0.87 u: 0.10 p: 0.63 u: 0.43 300 75
40 Baseline: Baseline: Baseline: Baseline:
200 50 10 Walk Run Chew Chew
100 25 20
0 OesenseKWSECG5000 0 OesenseKWSECG5000 0 OesenseKWSECG5000 0 OesenseKWSECG5000 UR2M: Chew UR2M: Walk UR2M: Chew UR2M: Chew
p: 0.57 u: 0.74 p: 0.51 u: 1.0 p: 0.76 u: 0.30 p: 0.57 u: 0.63
Fig. 8: Comparison of latency and energy consumption of
uncertainty-aware methods on two MCUs.
Fig.9:Uncertaintyestimationtowardssignalmissingandnoise.
withaFluke87Vdigitalmultimeter.FortheF446ZE,werecord Labels in red indicate wrong predictions.
a power consumption of 24.6 mA at 3.3V, resulting in 81.18
corrupted signals. When predictions are incorrect, UR2M also
mW for one second of audio signal acquisition. Memory-wise,
exhibitshighuncertainty(e.g.,u=1.0),whichcouldbeusedfor
it uses 4KB of SRAM and 32KB of eflash. In contrast, the
alerting the system to potential misclassifications or triggering
H747XI consumes 31.6 mA at 3.3V, totaling 104.28 mW in
additional validation steps.
power. It utilizes 29KB of SRAM and 66KB of eflash. Overall,
signal acquisition overheads for these two MCUs are minimal.
IX. DISCUSSION
Feature Extraction Overheads. The feature extraction step In this section, we discuss several possible future directions
for both UR2M and the baselines is the same, using MFCC for our work.
features as inputs. The extraction process is fast, taking only Generalizing UR2M to other sensors and higher-end
4.505 ms and 10.913 ms per extraction for the H747XI across MCUs. Ideally, UR2M could be generalized to any wearable
two datasets, indicating minimal overhead. sensors driven by MCUs. However, sensor signal complexity
Model Inference Latency. Using the MBed Timer API andlimitedMCUmemorysizeposelimitations.Morecomplex
to measure latency on MCUs, Figure 8 illustrates UR2M’s signals usually require larger model sizes, challenging the
and baseline inference results across three datasets and two deployment on the constrained memory of MCUs. Fortunately,
MCUs. With uncertainty thresholds (u) ranging from 1 to 0, recent work [12] shows that by investigating compressive
UR2Mpresents latencies from lowest to highest, respectively. sensing,keypatternsofprimitivesinsignalscanbecompressed
While baseline approaches, like deep ensemble, yield reliable and extracted, which indicates it can reduce the model size
uncertainty estimations, they exhibit high inference latencies to save system overhead. Therefore, we will study how
of 717.2-717.4 ms on F446ZE and 171.1-179.3 ms on H747XI compressivesensingcombinedwithUR2Mcouldfurtherreduce
persample.Conversely,UR2Mensuresbothreliableuncertainty system overhead to generalize to ultra low-end MCUs. We
and minimized latency, cutting inference latencies up to 864% envision our method could also benefit higher-end MCUs, e.g.
(83.0 ms vs. 717.2 ms) on F446ZE and 835% (20.2 ms vs. STM32F4, which has 1MB flash and 192KB SRAM. Since
171.1 ms) on H747XI. Moreover, UR2Menhances latency by less memory is required, higher-end MCUs could experience
approximately 456% against other baselines, even without improvements in latency and energy efficiency.
uncertainty filtering. Impact of UR2M on future WED systems. Our work
Model Inference Energy Consumption. Similar to the la- has illustrated that uncertainty is a key criterion to ensure
tency results, UR2M significantly reduces energy consumption reliable prediction in WED systems. Therefore, an important
compared to the baselines, as shown in Figure 8. For example, and urgent question is how to define uncertainty tolerance
UR2M decreases energy consumption by up to 834% (116.0 thresholds for specific applications. Fortunately, for healthcare
mJ vs. 13.9 mJ) on F446ZE and 857% (39.4 mJ vs. 4.6 mJ) applications, we can design this criterion through a doctor-in-
on H747XI when compared to the best-performing benchmark the-loop strategy to select the optimal threshold.
uncertainty-aware baselines. Also, we observe that UR2M X. CONCLUSION
achieves around 450% energy improvement compared to the
In this paper, we have proposed UR2M, a resource and
baselines without uncertainty filtering.
uncertainty-aware frameworkwhich canefficiently andreliably
enable wearable event detection and related uncertainty on
D. Robustness Against Signal Uncertainties
MCUs. By exploiting evidential uncertainty theory, cascade
We evaluate UR2M in the context of two types of signal
learning, and system optimization, UR2M significantly im-
uncertainties: signal missing (replace as zero) and noise
proves energy and memory efficiency for MCUs without
(gaussian noise). Due to page limitations, we compare our
sacrificing accuracy, enabling real-time and reliable event
method with traditional softmax-based NNs having the same
detection.
model structure. As demonstrated in Figure 9, for a correct
event signal “Chew”, the absence of signal and the presence XI. ACKNOWLEDGMENT
of random noise can lead softmax-based NNs to predict This work is supported by ERC through Project 833296
incorrectly. In contrast, UR2M can accurately predict most (EAR), and Nokia Bell Labs through a donation.
)sm(
ycnetaL
EZ644F
)sm(
ycnetaL
IX747H
)Jm(
ygrenE
EZ644F
)Jm(
ygrenE
IX747HREFERENCES ComputingandProceedingsofthe2021ACMInternationalSymposium
onWearableComputers,pages146–151,2021.
[1] Arash Alavi, Gireesh K Bogu, Meng Wang, Ekanath Srihari Rangan, [18] DariuszWójcik,TomaszRymarczyk,MichałOleszek,ŁukaszMaciura,
Andrew W Brooks, Qiwen Wang, Emily Higgs, Alessandra Celli, andPiotrBednarczuk. Diagnosingcardiovasculardiseaseswithmachine
TejaswiniMishra,AhmedAMetwally,etal. Real-timealertingsystem learning on body surface potential mapping data. In Proceedings of
forcovid-19andotherstresseventsusingwearabledata.Naturemedicine, the 19th ACM Conference on Embedded Networked Sensor Systems,
28(1):175–184,2022. SenSys’21,page379–381,NewYork,NY,USA,2021.Associationfor
ComputingMachinery.
[2] Christian Holz and Edward J. Wang. Glabella: Continuously sensing
[19] Taegyeong Lee, Zhiqi Lin, Saumay Pushp, Caihua Li, Yunxin Liu,
blood pressure behavior using an unobtrusive wearable device. Proc.
YoungkiLee,FengyuanXu,ChenrenXu,LintaoZhang,andJunehwa
ACMInteract.Mob.WearableUbiquitousTechnol.,1(3),sep2017.
Song. Occlumency:Privacy-preservingremotedeep-learninginference
[3] YuezhouZhang,ZhichengYang,ZhengboZhang,PeiyaoLi,DesenCao,
using sgx. In The 25th Annual International Conference on Mobile
XiaoliLiu,JiewenZheng,QianYuan,andJianliPan. Breathingdisorder
ComputingandNetworking,pages1–17,2019.
detectionusingwearableelectrocardiogramandoxygensaturation. In
[20] TuochaoChen,YaxuanLi,SongyunTao,HyunchulLim,MoseSakashita,
Proceedings of the 16th ACM Conference on Embedded Networked
RuidongZhang,FrancoisGuimbretiere,andChengZhang. Neckface:
SensorSystems,pages313–314,2018.
Continuouslytrackingfullfacialexpressionsonneck-mountedwearables.
[4] Ji Lin, Wei-Ming Chen, Yujun Lin, John Cohn, Chuang Gan, and
Proc.ACMInteract.Mob.WearableUbiquitousTechnol.,5(2),jun2021.
SongHan. Mcunet:Tinydeeplearningoniotdevices. arXivpreprint
[21] JinHuang,ColinSamplawski,DeepakGanesan,BenjaminMarlin,and
arXiv:2007.10319,2020.
HeesungKwon. Clio:Enablingautomaticcompilationofdeeplearning
[5] Yaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, David Sculley,
pipelines across iot and cloud. In Proceedings of the 26th Annual
SebastianNowozin,JoshuaDillon,BalajiLakshminarayanan,andJasper
InternationalConferenceonMobileComputingandNetworking,pages
Snoek. Canyoutrustyourmodel’suncertainty?evaluatingpredictive
1–12,2020.
uncertaintyunderdatasetshift.Advancesinneuralinformationprocessing
[22] Murat Sensoy, Lance Kaplan, and Melih Kandemir. Evidential
systems,32,2019.
deep learning to quantify classification uncertainty. arXiv preprint
[6] Gustavo Carneiro, Leonardo Zorron Cheng Tao Pu, Rajvinder Singh,
arXiv:1806.01768,2018.
andAlastairBurt. Deeplearninguncertaintyandconfidencecalibration
[23] AndreyMalininandMarkGales. Predictiveuncertaintyestimationvia
forthefive-classpolypclassificationfromcolonoscopy. MedicalImage
priornetworks. Advancesinneuralinformationprocessingsystems,31,
Analysis,62:101653,2020.
2018.
[7] BalajiLakshminarayanan,AlexanderPritzel,andCharlesBlundell. Sim- [24] JishnuMukhoti,AndreasKirsch,JoostvanAmersfoort,PhilipHSTorr,
pleandscalablepredictiveuncertaintyestimationusingdeepensembles. andYarinGal. Deepdeterministicuncertainty:Asimplebaseline. arXiv
Advancesinneuralinformationprocessingsystems,30,2017. e-prints,pagesarXiv–2102,2021.
[8] YuchengWang,MengmengGu,MingyuanZhou,andXiaoningQian. [25] Andrey Malinin, Bruno Mlodozeniec, and Mark Gales. Ensemble
Attention-based deep bayesian counting for ai-augmented agriculture. distributiondistillation. arXivpreprintarXiv:1905.00076,2019.
InProceedingsofthe20thACMConferenceonEmbeddedNetworked [26] RobertDavid,JaredDuke,AdvaitJain,VijayJanapaReddi,NatJeffries,
SensorSystems,pages1109–1115,2022. JianLi,NickKreeger,IanNappier,MeghnaNatraj,TiezhenWang,etal.
[9] LorenaQendro,JagmohanChauhan,AlbertoGilCPRamos,andCecilia Tensorflowlitemicro:Embeddedmachinelearningfortinymlsystems.
Mascolo. Thebenefitofthedoubt:Uncertaintyawaresensingforedge ProceedingsofMachineLearningandSystems,3:800–811,2021.
computingplatforms.In2021IEEE/ACMSymposiumonEdgeComputing [27] ShreyasPadhy,ZacharyNado,JieRen,JeremiahLiu,JasperSnoek,and
(SEC),pages214–227.IEEE,2021. BalajiLakshminarayanan. Revisitingone-vs-allclassifiersforpredictive
[10] YarinGalandZoubinGhahramani.Dropoutasabayesianapproximation: uncertaintyandout-of-distributiondetectioninneuralnetworks. arXiv
Representing model uncertainty in deep learning. In international preprintarXiv:2007.05134,2020.
conferenceonmachinelearning,pages1050–1059.PMLR,2016. [28] Gianni Franchi, Andrei Bursuc, Emanuel Aldea, Séverine Dubuisson,
[11] JeremiahLiu,ZiLin,ShreyasPadhy,DustinTran,TaniaBedraxWeiss, andIsabelleBloch. Oneversusallfordeepneuralnetworkincertitude
and Balaji Lakshminarayanan. Simple and principled uncertainty (ovnni)quantification. arXivpreprintarXiv:2006.00954,2020.
estimation with deterministic deep learning via distance awareness. [29] Xin Dai, Xiangnan Kong, and Tian Guo. Epnet: Learning to exit
Advances in Neural Information Processing Systems, 33:7498–7512, with flexible multi-branch network. In Proceedings of the 29th ACM
2020. International Conference on Information & Knowledge Management,
[12] NhatPham,HongJia,MinhTran,TuanDinh,NamBui,YoungKwon, pages235–244,2020.
DongMa,PhucNguyen,CeciliaMascolo,andTamVu.Pros:anefficient [30] MarkSandler,AndrewHoward,MenglongZhu,AndreyZhmoginov,and
pattern-drivencompressivesensingframeworkforlow-powerbiopotential- Liang-ChiehChen.Mobilenetv2:Invertedresidualsandlinearbottlenecks.
basedwearableswithon-chipintelligence. InProceedingsofthe28th InProceedingsoftheIEEEconferenceoncomputervisionandpattern
AnnualInternationalConferenceonMobileComputingAndNetworking, recognition,pages4510–4520,2018.
pages661–675,2022. [31] Yundong Zhang, Naveen Suda, Liangzhen Lai, and Vikas Chandra.
[13] Surat Teerapittayanon, Bradley McDanel, and Hsiang-Tsung Kung. Hello edge: Keyword spotting on microcontrollers. arXiv preprint
Branchynet:Fastinferenceviaearlyexitingfromdeepneuralnetworks. arXiv:1711.07128,2017.
In201623rdInternationalConferenceonPatternRecognition(ICPR), [32] Dong Ma,Andrea Ferlini,and CeciliaMascolo. Oesense:employing
pages2464–2469.IEEE,2016. occlusioneffectforin-earhumansensing. InProceedingsofthe19th
[14] Colby Banbury, Chuteng Zhou, Igor Fedorov, Ramon Matas, Urmish AnnualInternationalConferenceonMobileSystems,Applications,and
Thakker,DibakarGope,VijayJanapaReddi,MatthewMattina,andPaul Services,pages175–187,2021.
Whatmough. Micronets: Neural network architectures for deploying [33] PeteWarden.Speechcommands:Adatasetforlimited-vocabularyspeech
tinyml applications on commodity microcontrollers. Proceedings of recognition. arXivpreprintarXiv:1804.03209,2018.
MachineLearningandSystems,3:517–532,2021. [34] Yanping Chen, Yuan Hao, Thanawin Rakthanmanon, Jesin Zakaria,
[15] EdgarLiberis,ŁukaszDudziak,andNicholasD.Lane.unas:Constrained BingHu,andEamonnKeogh. Ageneralframeworkfornever-ending
neuralarchitecturesearchformicrocontrollers. InProceedingsofthe learningfromtimeseriesstreams.Dataminingandknowledgediscovery,
1st Workshop on Machine Learning and Systems, EuroMLSys ’21, 29(6):1622–1664,2015.
page 70–79, New York, NY, USA, 2021. Association for Computing [35] NiteshVChawla,KevinWBowyer,LawrenceOHall,andWPhilip
Machinery. Kegelmeyer.Smote:syntheticminorityover-samplingtechnique.Journal
[16] AmirGhodrati,BabakEhteshamiBejnordi,andAmirhosseinHabibian. ofartificialintelligenceresearch,16:321–357,2002.
Frameexit:Conditionalearlyexitingforefficientvideorecognition. In [36] LorenaQendro,AlexanderCampbell,PietroLio,andCeciliaMascolo.
Proceedings of the IEEE/CVF Conference on Computer Vision and Earlyexitensemblesforuncertaintyquantification. InMachineLearning
PatternRecognition,pages15608–15618,2021. forHealth,pages181–195.PMLR,2021.
[17] ErikaBondareva,ElínRósHauksdóttir,andCeciliaMascolo.Earablesfor [37] QingsongWen,LiangSun,FanYang,XiaominSong,JingkunGao,Xue
detectionofbruxism:afeasibilitystudy. InAdjunctProceedingsofthe Wang,andHuanXu. Timeseriesdataaugmentationfordeeplearning:
2021ACMInternationalJointConferenceonPervasiveandUbiquitous Asurvey. arXivpreprintarXiv:2002.12478,2020.