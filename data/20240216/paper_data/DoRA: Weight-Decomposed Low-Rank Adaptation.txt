DoRA: Weight-Decomposed Low-Rank Adaptation
Shih-YangLiu*12 Chien-YiWang1 HongxuYin1 PavloMolchanov1 Yu-ChiangFrankWang1
Kwang-TingCheng2 Min-HungChen1
Abstract
Amongthewidelyusedparameter-efficientfine- Pr Wet er ia gin he td Frozen M We er ig ge hd t
tuning (PEFT) methods, LoRA and its variants Trainable
havegainedconsiderablepopularitybecauseof
Decompose
avoiding additional inference costs. However, (Initialize) Merge
therestilloftenexistsanaccuracygapbetween Magnitude Magnitude
these methods and full fine-tuning (FT). In this
work, we first introduce a novel weight decom-
Direction Direction
position analysis to investigate the inherent dif-
ferences between FT and LoRA. Aiming to re- Adapt
Pretrained
semble the learning capacity of FT from the
Weight
findings,weproposeWeight-DecomposedLow- Pretrained B
Weight
Rank Adaptation (DoRA). DoRA decomposes
thepre-trainedweightintotwocomponents,mag- A
nitudeanddirection,forfine-tuning,specifically
employingLoRAfordirectionalupdatestoeffi-
Figure1.AnoverviewofourproposedDoRA,whichdecomposes
cientlyminimizethenumberoftrainableparam-
thepre-trainedweightintomagnitudeanddirectioncomponents
eters. By employing DoRA, we enhance both
for fine-tuning, especially with LoRA to efficiently update the
the learning capacity and training stability of direction component. Note that ||·|| denotes the vector-wise
c
LoRA while avoiding any additional inference normofamatrixacrosseachcolumnvector.
overhead. DoRAconsistentlyoutperformsLoRA
onfine-tuningLLaMA,LLaVA,andVL-BART
onvariousdownstreamtasks, suchascommon-
inscale,theexpenseassociatedwithfine-tuningtheentire
sense reasoning, visual instruction tuning, and
modelbecomesprohibitivelylarge.
image/video-textunderstanding. Wewillrelease
thecodeandmodelsuponacceptance. Toaddressthisissue,parameter-efficientfine-tuning(PEFT)
methods(Houlsbyetal.,2019)havebeenintroducedtofine-
tunethepre-trainedmodelswithonlyaminimalnumberof
1.Introduction parameters. Amongthese,LoRA(Huetal.,2022),which
doesnotchangethemodelarchitecture,hasbecomenotably
Modelsthatarepre-trainedwithextensivegeneraldomain
popularforitssimplicityandefficacy. Nevertheless,there
datasetshavedemonstratedremarkablegeneralizationabil-
isstillacapacitygapbetweenLoRAandFT,whichisoften
ities,significantlybenefitingawidearrayofapplications,
attributed to the limited number of trainable parameters
fromnaturallanguageprocessing(NLP)tasks(Qinetal.,
withoutfurtherexplorationofotherunderlyingcauses(Hu
2023;Taorietal.,2023)tomulti-modaltasks(Lietal.,2022;
etal.,2022;Kopiczkoetal.,2024).
Liuetal.,2023a). Totailorthesegeneralmodelsforspe-
cificdownstreamtasks,fullfine-tuning(FT)iscommonly Drawing onWeightNormalization (Salimans& Kingma,
employed,involvingtheretrainingofallmodelparameters. 2016),whichachievesfasterconvergenceviaimprovingthe
Nevertheless, as the size of models and datasets expand conditioningofthegradientwithweightreparameterization,
weintroduceanovelweightdecompositionanalysisthatini-
*Work done during an internship at NVIDIA
tiallyreparameterizesmodelweightsintomagnitudeanddi-
1NVIDIA 2HKUST. Correspondence to: Min-Hung Chen
rectionalcomponents,subsequentlyexaminingthechanges
<minghungc@nvidia.com>.
in magnitude and direction introduced by LoRA and FT.
OuranalysisrevealsthatLoRAandFTexhibitmarkedly
1
4202
beF
41
]LC.sc[
1v35390.2042:viXradistinctpatternsofupdates,leadingustosurmisethatthese Wang et al., 2023). However, these approaches typically
variations mirror the learning capability of each method. facechallengesduetotheirsensitivitytoinitialization,af-
Inspiredbyourfindings,weproposeWeight-Decomposed fectingtheiroveralleffectiveness.Thesefirsttwocategories,
Low-RankAdaptation(DoRA),whichbeginsbydecompos- whetheralteringthemodel’sinputorarchitecture,resultin
ingthepre-trainedweightintoitsmagnitudeanddirectional increasedinferencelatencycomparedtothebaselinemodel.
components, then fine-tunes both. Given the substantial
LoRA (Hu et al., 2022) and its variants are among the
sizeofthedirectionalcomponentintermsofparameters,
third category of PEFT, notable for not adding any extra
we exploit LoRA for the directional adaptation to enable
inferenceburden. Thesemethodsapplylow-rankmatrices
efficientfine-tuning, asillustratedinFigure.1. Moreover,
toapproximateweightchangesduringfine-tuningandcan
byshowingalearningbehaviorsimilartoFTbothempir-
mergewithpre-trainedweightspriortoinference. Forex-
icallyandmathematically,suggestingalearningcapacity
ample,(Zhangetal.,2023)employsSVDdecomposition
closelyresemblingFT,wehavevalidatedDoRAacrossa
andpruneslesssignificantsingularvaluesformoreefficient
widevarietyoftasks,fromNLPtoVision-Language,and
updates. (Hyeon-Woo et al., 2022) focuses on low-rank
overvariousbackbones,includingLLMandLVLM.Theex-
Hadamardproductforfederatedlearning. (Qiuetal.,2023;
perimentalresultsshowthatDoRAconsistentlyoutperforms
Liuetal.,2023b)exploitorthogonalfactorizationinfine-
LoRAwithoutsacrificinginferenceefficiency,suchascom-
tuningdiffusionmodels. (Renduchintalaetal.,2023)uses
monsensereasoning(+3.4/+1.0onLLaMA-7B/13B),visual
weighttyingtofurtherreducethetrainableparameters.(Yeh
instructiontuning(+0.6onLLaVA-7B),andimage/video-
etal.,2023)introducesaunifiedLoRAfamilyframework
textunderstanding(+0.9/+1.9onVL-BART).
forStablediffusion. (Pontietal.,2022)choosesdifferent
Thesummaryofourcontributionsisasfollows: combinationsofLoRAsfromtheinventorywitharouting
functionfordifferenttasks. (Kopiczkoetal.,2024)imple-
• WeintroduceDoRA,anovelPEFTmethodthatincor- mentslearnable scalingvectors toadjusta sharedpairof
porates weight decomposition, achieving a learning frozen random matrices across layers. Our research also
capacitycloselyresemblingFTwithoutanyadditional fallswithinthisthirdcategory,andwevalidatetheefficacy
inferencelatencyoverLoRA. ofourproposedmethodalongsideLoRAanditsvariants
throughcomprehensiveexperimentation.
• Weintroduceanovelweightdecompositionanalysis
touncoverthefundamentaldifferencesinthelearning 3.PatternAnalysisofLoRAandFT
patternsofFTanddifferentPEFTmethods.
3.1.Low-RankAdaptation(LoRA)
• DoRAconsistentlysurpassesLoRAonvarioustasks,
Buildinguponthehypothesisthatupdatesmadeduringthe
fromNLPtoVision-Languagebenchmarksandacross
fine-tuningexhibitalow“intrinsicrank”,LoRA (Huetal.,
variousbackbones,includingLLMandLVLM.
2022) proposes using the product of two low-rank matri-
cestoupdatethepre-trainedweightsincrementally. Fora
2.RelatedWorks
pre-trainedweightmatrixW ∈ Rd×k,LoRAmodelsthe
0
weightupdate∆W ∈Rd×k utilizingalow-rankdecompo-
Parameter-EfficientFine-Tuning(PEFT)methodsarede-
sition,expressedasBA,whereB ∈Rd×r andA∈Rr×k
signedtoreducethehighexpenseoffine-tuninglarge-scale
representtwolow-rankmatrices,withr ≪min(d,k).Con-
models. They achieve this by training a relatively small
sequently,thefine-tunedweightW′canberepresentedas:
subsetofparameters,comparedtothetotalnumberofpa-
rameters,foradaptingtodownstreamtasks. ExistingPEFT W′ =W +∆W =W +BA (1)
0 0
methods can be divided into three categories. The first
category is referred to as Adapter-based methods, which where W remains static during the fine-tuning process,
0
involve introducing additional trainable modules into the andtheunderlinedparametersarebeingtrained. Thema-
originalfrozenbackbone,suchas(Houlsbyetal.,2019;He trixAisinitializedwithuniformKaimingdistribution(He
etal.,2021;KarimiMahabadietal.,2021;mahabadietal., et al., 2015), while B is initially set to zero, resulting in
2021). Forexample,(Houlsbyetal.,2019)proposesadding ∆W = BA being zero at the start of training. Notably,
linearmodulesinsequencetotheexistinglayer,whereas this decomposition of ∆W can be substituted with other
(Heetal.,2021)advocatesforintegratingthesemodulesin LoRAvariants,suchasVeRA(Kopiczkoetal.,2024). Ad-
parallelwiththeoriginallayertoenhanceperformance. The ditionally,basedonEq.(1),wecanmergethelearned∆W
secondcategoryisPrompt-basedmethods. Thesemethods withthepre-trainedweightW andobtainW′ inadvance
0
addextrasofttokens(prompts)totheinitialinputandfo- of deployment, and given that both W′ and W both fall
0
cussolelyonfine-tuningthesetrainablevectors,asseenin within the dimensionality of Rd×k, LoRA and its related
workslike(Lesteretal.,2021;Razdaibiedinaetal.,2023; variantsdonotintroduceanyextralatencyduringtheinfer-
2encecomparedtotheoriginalmodel. theirrespectivemagnitudevectors,whileVn,tandWnare
FT 0
thenthcolumnsinVt andW . Themagnitudeanddirec-
FT 0
3.2.WeightDecompositionAnalysis tional differences between W LoRA and W 0 are calculated
similarly,asperEq.(3)andEq.(4). Weselectcheckpoints
ThestudypresentedinLoRA(Huetal.,2022)suggeststhat
fromfourdifferenttrainingstepsforanalysis,comprising
LoRA can be considered a general approximation of full
threeintermediatestepsandthefinalcheckpointfromboth
fine-tuning. By gradually increasing the rank r of LoRA
FTandLoRA,andweperformweightdecompositionanal-
to align with the rank of pre-trained weights, LoRA can
ysisoneachofthesecheckpointstodeterminethe∆M and
attain a level of expressiveness akin to that of FT. Con-
∆Dthroughoutdifferentlayers.
sequently, many previous studies have attributed the dis-
crepancyinaccuracybetweenLoRAandFTprimarilyto AnalysisResults: Figure2(a)and(b)illustratethealter-
thelimitednumberoftrainableparameters,oftenwithout ations in the query weight matrix of FT and LoRA, with
further analysis (Hu et al., 2022; Kopiczko et al., 2024). each point representing a (∆Dt, ∆Mt) pair from query
DrawinginspirationfromWeightNormalization(Salimans weightmatricesacrossdifferentlayersandtrainingsteps.
&Kingma,2016),whichreparameterizestheweightmatrix Similarly,Figure5intheappendixdisplaysthevalueweight
intomagnitudeanddirectionforacceleratingoptimization, matrixmodifications. ItisnoticeablethatLoRAexhibitsa
weintroduceaninnovativeweightdecompositionanalysis. consistentpositiveslopetrendacrossalltheintermediate
Our analysis restructures the weight matrix into two sep- steps, signifying a proportional relationship between the
arate components, magnitude and direction, to reveal the changes in direction and magnitude. In contrast, the FT
inherentdifferencesinLoRAandFTlearningpatterns. displaysamorevariedlearningpatternwitharelativelyneg-
ativeslope. ThisdistinctionbetweenFTandLoRAlikely
AnalysisMethod: Thisanalysisexaminestheupdatesin
mirrorstheirrespectivelearningcapability. WhileLoRA
bothmagnitudeanddirectionoftheLoRAandFTweights
tendstoeitherincreaseordecreasethemagnitudeanddirec-
relativetothepre-trainedweightstorevealthefundamental
tionupdatesproportionally,itlacksthenuancedcapability
differencesinthelearningbehaviorsofboth. Theweight
formoresubtleadjustments. Specifically,LoRAdoesnot
decompositionofW ∈Rd×k canbeformulatedas:
show proficiency in executing slight directional changes
V W alongside more significant magnitude alterations, or vice
W =m ||V|| =||W|| c||W|| (2) versa,afeaturemorecharacteristicoftheFTmethod. We
c c
suspectthatsuchlimitationofLoRAmightstemfromthe
wherem∈R1×k isthemagnitudevector,V ∈Rd×k isthe challengeofconcurrentlearningbothmagnitudeanddirec-
directionalmatrix,with||·|| beingthevector-wisenormof tionaladaptation,whichcouldbeoverlycomplexforLoRA.
c
amatrixacrosseachcolumn. Thisdecompositionensures Consequently,inthiswork,weaimtoproposeavariantof
thateachcolumnofV/||V|| remainsaunitvector,andthe LoRAthatexhibitsalearningpatternmorecloselyresem-
c
corresponding scalar in m defines the magnitude of each blingthatofFT,andcanimprovethelearningcapacityover
vector. LoRA.
Forourweightdecompositionanalysis,weselecttheVL-
4.Method
BARTmodelfine-tunedonfourimage-texttasksasoutlined
in(Sungetal.,2022)foracasestudy.Following(Sungetal.,
4.1.Weight-DecomposedLow-RankAdaptation
2022),whichappliesLoRAonlytothequery/valueweight
matrixintheself-attentionmodule. Wedecomposethepre- Drawing from the insights of our weight decomposition
trainedweightW ,thefullfine-tunedweightW ,andthe analysis, we introduce Weight-Decomposed Low-Rank
0 FT
mergedLoRAweightW ofquery/valueweightmatrix Adaptation(DoRA).DoRAinitiallydecomposesthepre-
LoRA
using Eq. (2). The magnitude and directional variations trained weight into its magnitude and directional compo-
betweenW andW canbedefinedasfollows: nentsandfinetunesbothofthem. Becausethedirectional
0 FT
componentislargeintermsofparameternumbers,wefur-
∆Mt =
(cid:80)k n=1|mn FT,t−mn 0|
(3)
therdecomposeitwithLoRAforefficientfinetuning.
FT k
Ourintuitionsaretwo-fold. Firstly,webelievethatlimiting
(cid:80)k (1−cos(Vn,t,Wn))
∆Dt = n=1 FT 0 (4) LoRAtoconcentrateexclusivelyondirectionaladaptation
FT k while also allowing the magnitude component to be tun-
ablesimplifiesthetaskcomparedtotheoriginalapproach,
Here, ∆M Ft T and and ∆D Ft T represent the magnitude dif- whereLoRAisrequiredtolearnadjustmentsinbothmag-
ferenceanddirectionaldifferencebetweenW 0andW FTat nitudeanddirection. Secondly,theprocessofoptimizing
ttrainingsteprespectively,withcos(·,·)beingthecosine directional updates is made more stable through weight
similarity function. Mn,t and Mn are the nth scalars in
FT 0
3FT LoRA DoRA
l la ay ye er r 1 2 0.09 I In nt te er r s st te ep p 1 2 0.45 I In nt te er r s st te ep p 1 2 11 .. 34 I In nt te er r s st te ep p 1 2
l la ay ye er r 3 4 0.08 I Fn it ne ar l s st te ep p 3 0.40 I Fn it ne ar l s st te ep p 3 1.2 I Fn it ne ar l s st te ep p 3
layer 5 M 1.1
layer 6 0.07 0.35 1.0
0.06 0.30 0.9
0.25 0.8
0.05 0.7
0.014 0.016 0.018 0.020 0.022 0.10 0.11 0.12 0.13 0.14 0.15 0.16 0.16 0.18 0.20 0.22 0.24 0.26 0.28 0.30 0.32
D D D
(a) (b) (c)
Figure2.Magnitudeanddirectionupdatesof(a)FT,(b)LoRA,and(c)DoRAofthequerymatricesacrossdifferentlayersandintermediate
steps.Differentmarkersrepresentmatricesofdifferenttrainingstepsanddifferentcolorsrepresentthematricesofeachlayer.
decomposition, which we delve into more thoroughly in negativecorrelationvaluesof-0.62and-0.31,respectively.
Section.4.2.Itisimportanttohighlightthatthemaindistinc- Incontrast,LoRAshowsapositivecorrelationwithavalue
tion between DoRA and weight normalization (Salimans of 0.83. In conclusion, the fact that DoRA demonstrates
&Kingma,2016)liesintheirtrainingapproaches. Weight theabilitytomakeonlysubstantialdirectionaladjustments
normalizationtrainsbothcomponentsfromscratch,mak- withrelativelyminimalchangesinmagnitudeorthereverse
ing the method sensitive to different initializations. Con- whileshowinglearningpatternsclosertoFT’ssignifiesits
versely,DoRAavoidssuchinitializationconcernssinceboth superiorlearningcapacityoverLoRA.
componentsbeginwithpre-trainedweights. Weinitialize
DoRAwithpre-trainedweightW 0 asoutlinedinEq.(2), 4.2.GradientAnalysisofDoRA
wherem = ||W || andV = W afterinitialization. We
0 c 0
In this section, we first derive the gradient of DoRA and
thenkeepV frozenandmatrainablevector.Thedirectional
illustratehowourproposeddecompositionbenefitstheopti-
componentisthenupdatedthroughLoRA.DoRAcanbe
mizationof∆V. Subsequently,weanalyzefromthegradi-
formulatedsimilartoEq.(1)as:
ent’sperspectivetoexplicatethelearningpatternofDoRA,
V +∆V W +BA whichtendstohaveanegativeslope.
W′ =m =m 0 (5)
||V +∆V|| c ||W 0+BA|| c From Eq. (5), we can obtain the gradient of Loss L with
respecttomandV′ =V +∆V as:
where ∆V is the incremental directional update learned
by multiplying two low-rank matrices B and A, and the m (cid:18) V′V′T(cid:19)
∇ L= I− ∇ L (6)
underlinedparametersdenotethetrainableparameters. The V′ ||V′|| ||V′||2 W′
c c
matricesB ∈ Rd×r andA ∈ Rr×k areinitializedinline ∇ L·V′
withLoRA’sstrategytoensurethatW′ equalsW
0
before ∇ mL= W ||V′
′||
(7)
thefinetuning. Furthermore,DoRAcanbemergedwiththe c
pre-trainedweightbeforeinference,therebynotintroducing Eq.(6)revealsthattheweightgradient∇ Lisscaledby
W′
anyadditionallatency. m/||V′|| and is projected away from the current weight
c
matrix. These two effects contribute to aligning the gra-
Wevisualizethemagnitudeanddirectionaldifferencesof
dient’s covariance matrix more closely with the identity
thequeryweightmatrixbetweenthemergedDoRAweight
matrix,whichisadvantageousforoptimization(Salimans
andW inthesamesettingasforFTandLoRAinFigure2
0 &Kingma,2016). Additionally,giventhatV′ =V +∆V,
(c)andleavethevisualizationofthevalueweightmatrix
thegradient∇ Lisequivalentto∇ L. Therefore,the
intheappendix. Fromtheregressionlinefor(∆D,∆M) V′ ∆V
optimizationbenefitsderivedfromthisdecompositionare
ofbothDoRAandFT,werevealthatincontrasttoLoRA’s
fullytransferredto∆V,enhancingthelearningstabilityof
pattern,DoRA,andFTarecharacterizedbyadistinctneg-
LoRA.
ative slope. We reason that FT tends towards a negative
slopebecausepre-trainedweightsalreadypossesssubstan- We can gain further insight into the learning pattern of
tialknowledgesuitableforvariousdownstreamtasks.There- DoRA by referring to Eq. (7). In the subsequent dis-
fore,whenprovidedwithadequatelearningcapacity,having cussion, we represent vectors using lower-case letters in-
alargermagnitudeordirectionalterationaloneissufficient stead of the previous matrix form notation. Consider
enoughfordownstreamadaptation. Weadditionallycom- w′′ = w′ + ∆w as the parameter update for a weight
putethecorrelationbetween∆Dand∆M forFT,LoRA, vector, where ∆w ∝ ∇ L. In two hypothetical update
w′
andDoRA,andwefoundthatbothFTandDoRAexhibit scenarios, S1 and S2, S1 involves a smaller directional
4update (∆D ), while S2 involves a larger one (∆D ). the accuracy of DoRA with the modification remains un-
S1 S2
Assuming ||∆w || = ||∆w ||, and at time 0, we have changedforVL-BARTandshowsanegligibledifference
S1 S2
∆v = 0 and v′ = v. From ∆D < ∆D , it follows of only 0.2 compared to DoRA without the modification
S1 S2
that |cos(∆w ,w′)| > |cos(∆w ,w′)|. Since ∆w ∝ onLLaMA.Foracomprehensivecomparisonoftraining
S1 S2
∇ L, it implies |cos(∇S1L,w′)| > |cos(∇S2L,w′)|. memoryusageandaccuracydifferences,pleaseseeTable7
w′ w′ w′
From Sec 4.1, with v initialized as v and w′ = w at intheappendix. Consequently,allsubsequentexperiments
0 0
time 0, we get |cos(∇ L,w′)| = |cos(∇ L,v′)| = withDoRAincorporatethisadjustment.
w′ w′
|cos(∇ L,v)|. Usingthecosinesimilarityequationwith
w′
∆v =0:
5.Experiments
∇ L·v
cos(∇ L,v′)=cos(∇ L,v)= w′ (8) Weconductavarietyofexperimentstoshowcasetheeffi-
w′ w′
||∇ L||||v||
w′ cacyofDoRAonvarioustasksincludinglanguage,image,
andvideodomains. Firstly,weevaluateDoRAagainstsev-
denotem asthemagnitudescalarofvectorw′thenEq.(7)
∗ eralParameter-EfficientFine-Tuning(PEFT)methodsby
w.r.tm canberewrittento:
∗ fine-tuning LLaMA-7B/13B on commonsense reasoning
∇ L·v′ tasks. Subsequently, we extend from single modality to
∇ m∗L= w ||′
v′||
=||∇ w′L||·cos(∇ w′L,v) (9) multimodality. WecompareDoRAwithLoRAacrossmulti-
taskimage/video-textunderstandingtasksusingVL-BART
andvisualinstructiontuningwithLLaVA-1.5-7B.Follow-
Given that ||∆w S1|| = ||∆w S2|| for S1 and S2, and ingthis,weexplorethecompatibilityofDoRAwithLoRA
||∇S w1 ′L||=||∇S w2 ′L||. Therefore,with: andVeRA(Kopiczkoetal.,2024)forinstruction-tuningon
LLaMA-7BandLLaMA2-7B.Furthermore,weperforma
||∇S1L||·|cos(∇S1L,v)|>||∇S2L||·|cos(∇S2L,v)|
w′ w′ w′ w′ seriesofablationstudiestoillustratethatDoRAsurpasses
(10)
LoRAinperformance,irrespectiveofthenumberoffine-
itcanbeinferredthat|∇S1L| > |∇S2L|whichindicate
m∗ m∗ tuning training samples and rank variations. Lastly, We
thatS1haslargermagnitudeupdatesoverS2whilehaving
analyze the tuning granularity of DoRA, and show that
smallerdirectionalalterationthanthatofS2. Ourconclu-
DoRAcanachievebetteraccuracythanLoRAwithfewer
siongenerallyholdsinpractice,asevidencedbyFigure2(c).
trainableparametersbyselectivelyupdatingonlythedirec-
Consequently,wehaveeffectivelyshownhowDoRAcan
tionalcomponentsofcertainmodules.
beutilizedtoadjustthelearningpattern,divergingfromthat
ofLoRAandaligningmorecloselywiththepatternofFT.
5.1.CommonsenseReasoning
4.3.ReductionofTrainingOverhead WeevaluateDoRAagainstLoRAandseveralbaselinemeth-
ods which include Prompt learning (Prefix) (Li & Liang,
InEq.(1),thegradientsofW′and∆W arethesame. How-
2021),Seriesadapter(Series)(Houlsbyetal.,2019),and
ever,withDoRA,whichredirectsthelow-rankadaptation
Parallel adapter (Parallel) (He et al., 2021) on LLaMA-
towardsthedirectionalcomponent,thegradientofthelow-
7B/13B(Touvronetal.,2023)forcommonsensereasoning
rankupdatesdiffersfromthatofW′,asillustratedinEq.(6).
tasks. WealsoincludeChatGPT’saccuracyobtainedwith
Thisdivergencenecessitatesextramemoryduringbackprop-
gpt-3.5-turboAPIusingazero-shotChainofThought(Ope-
agation. Toaddressthis,wesuggesttreating||V +∆V|| in
c nAI,2023;Weietal.,2022).
Eq.(5)asaconstant,therebydetachingitfromthegradient
graph. This means that while ||V +∆V|| dynamically The commonsense reasoning tasks comprise 8 sub-tasks,
c
reflects the updates of ∆V, it won’t receive any gradient eachwithapredefinedtrainingandtestingset. Wefollow
during backpropagation. With this modification, the gra- thesettingof(Huetal.,2023)andamalgamatethetraining
dient w.r.t m remains unchanged, and ∇ L is redefined datasetsfromall8taskstocreatethefinaltrainingdataset
V′
as: and conduct evaluations on the individual testing dataset
∇ L= m ∇ LwhereC =||V′|| (11) for each task. To ensure a fair comparison, we initially
V′ C W′ c fine-tunedmodelswithDoRAfollowingtheLoRAconfig-
Thisapproachreducesthegradientgraphmemoryconsump- uration, maintaining the same rank while adjusting only
tiondrasticallywithoutanoticeabledifferenceinaccuracy. the learning rate. The marginal increase of 0.01% in the
Weconductanablationstudytoevaluatetheimpactofthe numberoftrainableparametersforDoRAoverLoRA,as
proposedmodificationonfine-tuningLLaMA-7BandVL- detailedinTable1,arisesfromtheinclusionoflearnable
BART.Theresultsindicatethatthemodificationleadsto magnitudecomponents(parameterofsize1×k). Then,we
a training memory reduction of approximately 24.4% in further halve the rank used in DoRA compared to LoRA
fine-tuningLLaMAand12.4%inVL-BART.Furthermore, anddenotethisadjustedconfigurationasDoRA†. SeeTable
5Table1.AccuracycomparisonofLLaMA7B/13BwithvariousPEFTmethodsoneightcommonsensereasoningdatasets.Resultsofall
thebaselinemethodsaretakenfrom(Huetal.,2023).DoRA†:theadjustedversionofDoRAwiththerankhalved.
Model PEFTMethod #Params(%) BoolQ PIQA SIQA HellaSwag WinoGrande ARC-e ARC-c OBQA Avg.
ChatGPT - - 73.1 85.4 68.5 78.5 66.1 89.8 79.9 74.8 77.0
Prefix 0.11 64.3 76.8 73.9 42.1 72.1 72.9 54.0 60.6 64.6
Series 0.99 63.0 79.2 76.3 67.9 75.7 74.5 57.1 72.4 70.8
Parallel 3.54 67.9 76.4 78.8 69.8 78.9 73.7 57.3 75.2 72.2
LLaMA-7B
LoRA 0.83 68.9 80.7 77.4 78.1 78.8 77.8 61.3 74.8 74.7
DoRA†(Ours) 0.43 70.0 82.6 79.7 83.2 80.6 80.6 65.4 77.6 77.5
DoRA(Ours) 0.84 68.5 82.9 79.6 84.8 80.8 81.4 65.8 81.0 78.1
Prefix 0.03 65.3 75.4 72.1 55.2 68.6 79.5 62.9 68.0 68.4
Series 0.80 71.8 83 79.2 88.1 82.4 82.5 67.3 81.8 79.5
Parallel 2.89 72.5 84.9 79.8 92.1 84.7 84.2 71.2 82.4 81.4
LLaMA-13B
LoRA 0.67 72.1 83.5 80.5 90.5 83.7 82.8 68.3 82.4 80.5
DoRA†(Ours) 0.35 72.5 85.3 79.9 90.1 82.9 82.7 69.7 83.6 80.8
DoRA(Ours) 0.68 72.4 84.9 81.5 92.4 84.2 84.2 69.6 82.8 81.5
8fordetailsonthehyperparametersused. Having shown that DoRA can consistently achieve bet-
ter accuracy on fine-tuning LLM, we would like to see
Table1demonstratesthatDoRAconsistentlysurpassesall
if DoRA can remain competitive on multi-modality fine-
baselinemethodsacrossbothLLaMA-7Band13Bmodels.
tuningtasks. WecompareDoRAwithLoRAandfullfine-
Notably,intheLLaMA-7Bmodel,whereLoRAexceeds
tuning on VL-BART which comprises a vision encoder
theperformanceofotherbaselines,DoRAfurtherenhances
(CLIP-ResNet101(Radfordetal.,2021))andanencoder-
accuracyby3.4%,outstrippingChatGPT’saccuracylevels.
decoder language model (BART (Lewis et al., 2020))
Conversely,forLLaMA-13B,whereLoRA’seffectiveness Base
acrossfourdifferentimage-texttasks: VQAv2(Goyaletal.,
isinferiortotheParalleladapter,DoRAachievessuperior
2017)andGQA(Hudson&Manning,2019)forvisualques-
accuracyoverLoRAby1%andcomparableaccuracytothe
tionanswering,NLVR2(Suhretal.,2019)forvisualreason-
Paralleladapter,withonlyaquarterofthetrainableparame-
ing,andMSCOCO(Chenetal.,2015)forimagecaptioning,
tersrequiredbytheParalleladapterandwithoutaddingany
and four different video-text tasks from the VALUE (Li
extra inference overhead as the Parallel adapter. Further-
et al., 2021) Benchmark: TVQA (Lei et al., 2018) and
more,DoRA† exceedsLoRA’sperformanceonLLaMA-7B
How2QA (Li et al., 2020) for video question answering,
by2.8%andonLLaMA-13Bby1%, eventhoughitpos-
TVC(Leietal.,2020)andYC2C(Zhouetal.,2018)for
sessesonlyhalfthetrainableparameterscomparedtoLoRA.
videocaptioning.
This outcome suggests that the integration of DoRA en-
hancesthelearningcapabilityofLoRA,therebyreducing Wefollowthesameframeworkas(Sungetal.,2022)and
the need for a higher rank to surpass LoRA in terms of fine-tuned VL-BART within a multi-task framework for
accuracy. both image/video-text tasks. We adopt the same setup
as that of LoRA outlined in (Sung et al., 2022) when ap-
5.2.Image/Video-TextUnderstanding plying DoRA. See Table 9 for the complete hyperparam-
eters. The result of LoRA and FT for both image/video-
texttasksisdirectlyquotedfrom(Sungetal.,2022). We
Table2.Themulti-taskevaluationresultsonVQA,GQA,NVLR2 canseethatDoRAuniformlysurpassesLoRAinaccuracy
andCOCOCaptionwiththeVL-BARTbackbone. whilemaintainingasimilarcountoftrainableparameters
inbothTable2andTable3. Inparticular,DoRAexceeds
Method #Params(%) VQAv2 GQA NVLR2 COCOCap Avg.
LoRA’s performance by nearly 1% in image-text under-
FT 100 66.9 56.7 73.7 112.0 77.3
standingtasks,reachingtheaccuracylevelofFT.Moreover,
LoRA 5.93 65.2 53.6 71.9 115.3 76.5
DoRA(Ours) 5.96 65.8 54.7 73.1 115.9 77.4 DoRAachievesroughly2%higheraccuracythanLoRAin
video-textunderstandingtasks.
Table3.Themulti-taskevaluationresultsonTVQA,How2QA,
5.3.VisualInstructionTuning
TVC,andYC2CwiththeVL-BARTbackbone.
WefurtherscaleupthemodelsizeandcompareDoRAto
Method #Params(%) TVQA How2QA TVC YC2C Avg.
LoRA and FT on the visual instruction tuning tasks with
FT 100 76.3 73.9 45.7 154 87.5 LLaVA-1.5-7B(Liuetal.,2023a)whichiscomposedofa
LoRA 5.17 75.5 72.9 44.6 140.9 83.5
languagemodel,Vicuna-1.5-7B(Pengetal.,2023),anda
DoRA(Ours) 5.19 76.3 74.1 45.8 145.4 85.4
6RecallfromEquation.(1)that∆W canbeadaptedbydiffer-
Table4.VisualinstructiontuningevaluationresultsforLLaVA-
entLoRAvariants. WithDoRA,theconceptofincremental
1.5-7Bonawiderangeofsevenvision-languagetasks.Wedirectly
directionalupdate∆V introducedinEquation.(5)canlike-
usecheckpointsfrom(Liuetal.,2023a)toreproducetheirresults.
wise be replaced with alternative LoRA variants. In this
Method #Params(%) Avg. section,weselectVeRA(Kopiczkoetal.,2024)asacase
study to explore DoRA’s compatibility with other LoRA
FT 100 66.5
variants. VeRAsuggestsfreezingauniquepairofrandom
LoRA 4.61 66.9
DoRA(Ours) 4.63 67.6 low-rank matrices to be shared across all layers, employ-
ingonlyminimallayer-specifictrainablescalingvectorsto
capture each layer’s incremental updates. This approach
visionencoder,CLIPViT-L/336px(Radfordetal.,2021). allowsVeRAtoreducetrainableparameterssignificantly
The training datasets contain several datasets from VQA by 10x compared to LoRA, with only a minimal impact
(Goyal et al., 2017; Hudson & Manning, 2019; Marino onaccuracy. WeapplyVeRAforthedirectionalupdatein
et al., 2019; Schwenk et al., 2022), OCR (Mishra et al., DoRAandnamesuchcombinationDVoRA.Weassessthe
2019;Sidorovetal.,2020),region-levelVQA(Kazemzadeh effectivenessofbothDVoRAandDoRAcomparedtoVeRA
etal.,2014;Krishnaetal.,2017;Maoetal.,2016),visual andLoRAacrossLLaMA-7BandLLaMA2-7B,focusing
conversation(Liuetal.,2023a),andlanguageconversation oninstructiontuningwiththe10KsubsetofcleanedAlpaca
data. Wefollowthesettingof(Liuetal.,2023a)tofilterthe dataset (Taori et al., 2023). We utilize the official imple-
trainingdataandconstructthetunningpromptformat. For mentationofVeRAtoobtaintheresultsofVeRAandLoRA
a fair comparison, DoRA follows the same configuration andfine-tunethemodelwithDVoRAandDoRAusingthe
astheLoRAconfigurationprovidedby(Liuetal.,2023a). identicaltrainingsettingsasVeRAandLoRA(seeTable11
Thefine-tunedmodelsarethenevaluatedonsevenvision- intheappendixformoredetails). Theperformanceofthe
languagebenchmarks: VQAv2 (Goyaletal.,2017),GQA fine-tunedmodelsisthenevaluatedontheMT-Benchbench-
(Hudson&Manning,2019), VisWiz(Gurarietal.,2018) mark(Zhengetal.,2023)bygeneratingmodelresponses
SQA(Luetal.,2022), VQAT (Singhetal.,2019), POPE to a pre-defined set of 80 multi-turn questions. These re-
(Lietal.,2023),andMMBench(Liuetal.,2023c). sponsesarethenevaluatedbyGPT-4,whichreviewseach
answerandassignsanumericalscoreoutof10.
From Table 4, we can observe that the average accuracy
ofLoRAalreadysurpassesFT,whichcouldimplythatFT Table 5 presents the average scores for DVoRA, DoRA,
mightbeexperiencingissueswithoverfitting. Giventhat VeRA,andLoRA,demonstratingthatourproposedmethod
DoRAisdesignedtoenhanceLoRA’sperformancetomore exhibitsconsistentimprovementsoverVeRAandLoRAfor
closelyresemblethatofFT,inscenarioswhereFTisinfe- bothLLaMA-7BandLLaMA2-7B.Thiseffectivelyshow-
riortoLoRA,DoRA’simprovementoverLoRAmightnot casesthecompatibilityofDoRAwithVeRA.Inparticular,
beaspronouncedasobservedinotherexperimentswhere DVoRA merges the advantageous qualities of DoRA and
FT usually outperforms LoRA. Nonetheless, DoRA still VeRA, attaining scores that are on par with or even sur-
demonstratessuperiorperformanceoverbothLoRAandFT, passthoseofLoRA,yetwithsignificantlyfewerparame-
withanaverageimprovementof0.7%overLoRAand1.1% ters. Forexample,DVoRAoutperformsVeRAby0.7/0.5
overFT.SeeTable10forthehyperparameterssettingand pointsandachievesthesamelevelofaccuracyasLoRAon
Table12forthescoreofeachevaluationbenchmark. LLaMA-7BandDoRAonLLaMA2-7B,respectively. Ad-
ditionally,wepresentaselectionofquestionschosenfrom
5.4.CompatibilyofDoRAwithotherLoRAvariants MT-Bench,accompaniedbytheresponsesfromLLaMA2-
7B fine-tuned using DVoRA and VeRA in the appendix
(Table13and14)wherewecanobservethattheanswers
Table5.AveragescoresonMT-BenchassignedbyGPT-4tothe givenbyDVoRAtendtobemorepreciseandstructural.
answersgeneratedbyfine-tunedLLaMA-7B/LLaMA2-7B.
Next,tofurtherassessDoRA’sabilitytoremaincompetitive
undervaryingamountsoftrainingdata,consideringthatin
Model PEFTMethod #Params(%) Score
practicalsituations,accesstoextensivefine-tuningdatasets
LoRA 2.31 5.1
is frequently limited. We compare DoRA to LoRA and
DoRA(Ours) 2.33 5.5
LLaMA-7B DVoRAtoVeRAforfine-tuningLLaMA2-7B/LLaMA-7B
VeRA 0.02 4.3
witharangeofinstruction-tuningsamplesizes,specifically
DVoRA(Ours) 0.04 5.0
1000,4000,7000,10000,with10000beingthesettingof
LoRA 2.31 5.7 (Kopiczko et al., 2024). We visualize the average perfor-
DoRA(Ours) 2.33 6.0
LLaMA2-7B manceofeachmethodonLLaMA2-7BinFigure3,andon
VeRA 0.02 5.5
LLaMA-7BinFigure6intheappendix. Theresultshows
DVoRA(Ours) 0.04 6.0
7Table6.AccuracycomparisonofLLaMA7B/13Bwithtwodiffer-
LLaMA2-7B enttuninggranularityofDoRA.ColumnsmandVdesignatethe
6.0 moduleswithtunablemagnitudeanddirectionalcomponents,re-
spectively.Eachmoduleisrepresentedbyitsfirstletterasfollows:
5.8
(Q)uery,(K)ey,(V)alue,(O)utput,(G)ate,(U)p,(D)own.
5.6
5.4 DoRA Model PEFTMethod#Params(%) m V Avg.
LoRA LoRA 0.83 - - 74.7
5.2 DVoRA LLaMA-7B DoRA(Ours) 0.84 QKVUD QKVUD78.1
VeRA DoRA(Ours) 0.39 QKVOGUD QKV 77.5
5.0
1000 4000 7000 10000
Number of instruction tuning training samples LoRA 0.67 - - 80.5
LLaMA-13B DoRA(Ours) 0.68 QKVUD QKVUD81.5
DoRA(Ours) 0.31 QKVOGUD QKV 81.3
Figure3.Performanceoffine-tunedLLaMA2-7BonMT-Bench
usingdifferentnumbersofAlpacatrainingsamples.
r =4,demonstratingitsresilienceandconsistentlysuperior
that DoRA and DVoRA consistently outperform LoRA performanceoverLoRAregardlessoftheranksetting.
and VeRA across all training sample sizes. For instance,
with 7000 training samples, DoRA and DVoRA surpass 5.6.TuningGranularityAnalysis
LoRAandVeRAbymarginsof0.3and0.33,respectively.
The visualization in Figure 2 indicates that significant
Evenwhenthesamplesizeisreducedto1000,DoRAand
changesinmagnitudeoftenresultinrelativelysmallerdi-
DVoRA maintain their lead with advantages of 0.29 and
rectionalchanges. Giventhisobservationandthefactthat
0.22overLoRAandVeRA,respectively. Thisdemonstrates
directionalupdatesaccountformostofthetrainableparam-
that our methods persistently enhance performance over
eters,itpromptsaninvestigationintowhetheritispossible
LoRAandVeRA,regardlessofthetrainingsamplevolume.
todecreasethenumberoftrainableparametersbyupdating
onlythemagnitudecomponentsofspecificmoduleswhile
5.5.RobustnessofDoRAtowardsdifferentranksettings
continuing to update both the magnitude and directional
componentsfortheremaininglinearmodules.
Ourfindingsindicatethat, incontrasttotheoriginalcon-
LLaMA-7B
figurationsuggestedforLoRAin(Huetal.,2023),which
80
75 requiresupdatestoboththeMulti-headAttentionandMLP
70 (+ 37.2%) layersforoptimalperformance,DoRAcanalreadyachieve
65 superioraccuracybyupdatingonlythedirectionalandmag-
60 nitudecomponentsofthemulti-headlayersandthemagni-
55 (+ 22.4%) tudeoftheMLPlayers. Specifically,asshowninTable6,
50
45 DoRA byupdatingthedirectionalandmagnitudecomponentsof
40 LoRA theQKVmodulesandonlythemagnitudeoftherestofthe
4 8 16 32 64 layers,DoRAsurpassesLoRAby2.8%onLLaMA-7Band
rank r
0.8%onLLaMA-13B,whileutilizingonlylessthanhalfof
Figure4.AverageaccuracyofLoRAandDoRAforvaryingranks thetrainableparameterscomparedtoLoRA.
forLLaMA-7Bonthecommonsensereasoningtasks.
6.Conclusion
Thissectionexplorestheimpactofvariousrankconfigura-
tionsonDoRAandLoRAbyadjustingrwithintheset{4,8, In this work, we first conduct a novel weight decomposi-
16,32,64}andassessingtheperformanceofthefine-tuned tionanalysistorevealthedistinctlearningpatternsbetween
LLaMA-7Boncommonsensereasoningtasksasoutlinedin LoRA and FT. Building on these insights, we introduce
Sec5.1. TheaverageaccuraciesofLoRAandDoRAacross DoRA,afine-tuningmethodthatiscompatiblewithLoRA
differentranksaredepictedinFigure4,withdetailednum- anditsvariantsandexhibitsacloserresemblancetoFT’s
berspresentedinTable15. FromFigure4,wecanobserve learningbehavior. DoRAconsistentlyoutperformsLoRA
thatDoRAconsistentlysurpassesLoRAacrossallrankcon- across various fine-tuning tasks and model architectures.
figurations. Notably,theperformancegapwidensforranks Specifically,DoRAimprovesuponLoRAincommonsense
below8,whereLoRA’saverageaccuraciesdropto40.74% reasoningandvisualinstructiontuningtasks. Furthermore,
forr =8and39.49%forr =4. Incontrast,DoRAretains DoRAalsoshowscompatibilitywithVeRAontheAlpaca
a notable accuracy of 77.96% for r = 8 and 61.89% for instruction tuning task. Moreover, DoRA can be consid-
8
erocS
ycaruccA
.gvAeredasacostlessalternativetoLoRA,asitsdecomposed Hu, Z., Wang, L., Lan, Y., Xu, W., Lim, E.-P., Bing, L.,
magnitudeanddirectioncomponentscanbemergedback Xu,X.,Poria,S.,andLee,R. LLM-adapters: Anadapter
intothepre-trainedweightafterthetraining,ensuringthat family for parameter-efficient fine-tuning of large lan-
thereisnoextrainferenceoverhead. Forfuturework,we guagemodels. InProceedingsofthe2023Conference
wishtoexplorethegeneralizabilityofDoRAindomains onEmpiricalMethodsinNaturalLanguageProcessing,
beyondlanguageandvision,particularlyinthefieldofau- 2023.
dio. Additionally,itwouldbeintriguingtoinvestigatethe
potential of DoRA in various other applications, such as Hudson,D.A.andManning,C.D. Gqa: Anewdatasetfor
StableDiffusiontext-to-imagefine-tuning. real-worldvisualreasoningandcompositionalquestion
answering. InProceedingsoftheIEEE/CVFconference
oncomputervisionandpatternrecognition, pp.6700–
7.ImpactStatements
6709,2019.
Thispaperpresentsworkwhosegoalistoadvancethefield
of Machine Learning. There are many potential societal Hyeon-Woo,N.,Ye-Bin,M.,andOh,T.-H. Fedpara: Low-
consequencesofourwork,noneofwhichwefeelmustbe rankhadamardproductforcommunication-efficientfed-
specificallyhighlightedhere. eratedlearning. InInternationalConferenceonLearning
Representations,2022.
References
KarimiMahabadi,R.,Ruder,S.,Dehghani,M.,andHen-
Chen, X., Fang, H., Lin, T.-Y., Vedantam, R., Gupta, S., derson,J. Parameter-efficientmulti-taskfine-tuningfor
Dolla´r, P., and Zitnick, C. L. Microsoft coco captions: transformersviasharedhypernetworks. InProceedings
Data collection and evaluation server. arXiv preprint ofthe59thAnnualMeetingoftheAssociationforCom-
arXiv:1504.00325,2015. putational Linguistics and the 11th International Joint
ConferenceonNaturalLanguageProcessing(Volume1:
Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., and
LongPapers),pp.565–576,2021.
Parikh, D. Making the v in vqa matter: Elevating the
roleofimageunderstandinginvisualquestionanswer- Kazemzadeh, S., Ordonez, V., Matten, M., and Berg, T.
ing. InProceedingsoftheIEEEconferenceoncomputer ReferItGame: Referring to objects in photographs of
visionandpatternrecognition,pp.6904–6913,2017. naturalscenes. InProceedingsofthe2014Conference
onEmpiricalMethodsinNaturalLanguageProcessing
Gurari,D.,Li,Q.,Stangl,A.J.,Guo,A.,Lin,C.,Grauman,
(EMNLP),pp.787–798,2014.
K.,Luo,J.,andBigham,J.P. Vizwizgrandchallenge:
Answeringvisualquestionsfromblindpeople. InPro-
Kopiczko,D.J.,Blankevoort,T.,andAsano,Y.M. Vera:
ceedingsoftheIEEEconferenceoncomputervisionand
Vector-basedrandommatrixadaptation. InInternational
patternrecognition,pp.3608–3617,2018.
ConferenceonLearningRepresentations,2024.
He,J.,Zhou,C.,Ma,X.,Berg-Kirkpatrick,T.,andNeubig,
G. Towardsaunifiedviewofparameter-efficienttrans- Krishna, R., Zhu, Y., Groth, O., Johnson, J., Hata, K.,
fer learning. In International Conference on Learning Kravitz,J.,Chen,S.,Kalantidis,Y.,Li,L.-J.,Shamma,
Representations,2021. D.A.,etal. Visualgenome: Connectinglanguageand
visionusingcrowdsourceddenseimageannotations. In-
He, K., Zhang, X., Ren, S., and Sun, J. Delving deep
ternationaljournalofcomputervision,pp.32–73,2017.
intorectifiers: Surpassinghuman-levelperformanceon
imagenetclassification. InProceedingsoftheIEEEInter-
Lei,J.,Yu,L.,Bansal,M.,andBerg,T. TVQA:Localized,
nationalConferenceonComputerVision,pp.1026–1034,
compositionalvideoquestionanswering. InProceedings
2015.
ofthe2018ConferenceonEmpiricalMethodsinNatural
LanguageProcessing,pp.1369–1379,2018.
Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B.,
DeLaroussilhe, Q., Gesmundo, A., Attariyan, M., and
Lei,J.,Yu,L.,Berg,T.L.,andBansal,M.Tvr:Alarge-scale
Gelly, S. Parameter-efficient transfer learning for nlp.
datasetforvideo-subtitlemomentretrieval. InEuropean
In International Conference on Machine Learning, pp.
ConferenceonComputerVision,pp.447–463,2020.
2790–2799,2019.
Hu, E. J., yelong shen, Wallis, P., Allen-Zhu, Z., Li, Y., Lester,B.,Al-Rfou,R.,andConstant,N.Thepowerofscale
Wang, S., Wang, L., and Chen, W. LoRA: Low-rank forparameter-efficientprompttuning. InProceedingsof
adaptation of large language models. In International the2021ConferenceonEmpiricalMethodsinNatural
ConferenceonLearningRepresentations,2022. LanguageProcessing,pp.3045–3059,2021.
9Lewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mo- sciencequestionanswering. AdvancesinNeuralInfor-
hamed,A.,Levy,O.,Stoyanov,V.,andZettlemoyer,L. mationProcessingSystems,pp.2507–2521,2022.
BART:Denoisingsequence-to-sequencepre-trainingfor
mahabadi,R.K.,Henderson,J.,andRuder,S. Compacter:
naturallanguagegeneration,translation,andcomprehen-
Efficientlow-rankhypercomplexadapterlayers. InAd-
sion.InProceedingsofthe58thAnnualMeetingoftheAs-
vancesinNeuralInformationProcessingSystems,2021.
sociationforComputationalLinguistics,pp.7871–7880,
2020. Mao,J.,Huang,J.,Toshev,A.,Camburu,O.,Yuille,A.L.,
andMurphy,K. Generationandcomprehensionofunam-
Li,J.,Li,D.,Xiong,C.,andHoi,S. Blip: Bootstrapping
biguousobjectdescriptions. InProceedingsoftheIEEE
language-imagepre-trainingforunifiedvision-language
conferenceoncomputervisionandpatternrecognition,
understandingandgeneration. InInternationalConfer-
pp.11–20,2016.
enceonMachineLearning,pp.12888–12900,2022.
Marino, K., Rastegari, M., Farhadi, A., and Mottaghi, R.
Li,L.,Chen,Y.-C.,Cheng,Y.,Gan,Z.,Yu,L.,andLiu,J.
Ok-vqa: Avisualquestionansweringbenchmarkrequir-
HERO:HierarchicalencoderforVideo+Languageomni-
ingexternalknowledge. InProceedingsoftheIEEE/cvf
representationpre-training. InProceedingsofthe2020
conferenceoncomputervisionandpatternrecognition,
ConferenceonEmpiricalMethodsinNaturalLanguage
pp.3195–3204,2019.
Processing(EMNLP),pp.2046–2065,2020.
Mishra,A.,Shekhar,S.,Singh,A.K.,andChakraborty,A.
Li,L.,Lei,J.,Gan,Z.,Yu,L.,Chen,Y.-C.,Pillai,R.,Cheng, Ocr-vqa: Visual question answering by reading text in
Y.,Zhou,L.,Wang,X.E.,Wang,W.Y.,etal. Value: A images. In2019InternationalConferenceonDocument
multi-taskbenchmarkforvideo-and-languageunderstand- AnalysisandRecognition(ICDAR),pp.947–952,2019.
ingevaluation. InThirty-fifthConferenceonNeuralIn-
formationProcessingSystemsDatasetsandBenchmarks OpenAI. Welcome to the openai platform, 2023.
Track(Round1),2021. URL https://platform.openai.com/docs/
introduction.
Li,X.L.andLiang,P.Prefix-tuning:Optimizingcontinuous
Peng, B., Li, C., He, P., Galley, M., and Gao, J. Instruc-
prompts for generation. In Zong, C., Xia, F., Li, W.,
tiontuningwithgpt-4. arXivpreprintarXiv:2304.03277,
andNavigli, R.(eds.), Proceedingsofthe59thAnnual
2023.
MeetingoftheAssociationforComputationalLinguistics
andthe11thInternationalJointConferenceonNatural Ponti,E.M.,Sordoni,A.,Bengio,Y.,andReddy,S. Com-
LanguageProcessing(Volume1:LongPapers),pp.4582– biningmodularskillsinmultitasklearning.arXivpreprint
4597,2021. arXiv:2202.13914,2022.
Li,Y.,Du,Y.,Zhou,K.,Wang,J.,Zhao,X.,andWen,J.-R. Qin,C.,Zhang,A.,Zhang,Z.,Chen,J.,Yasunaga,M.,and
Evaluatingobjecthallucinationinlargevision-language Yang,D. Ischatgptageneral-purposenaturallanguage
models. InProceedingsofthe2023ConferenceonEm- processing task solver? In Proceedings of the 2023
pirical Methods in Natural Language Processing, pp. ConferenceonEmpiricalMethodsinNaturalLanguage
292–305,2023. Processing,pp.1339–1384,2023.
Liu,H.,Li,C.,Wu,Q.,andLee,Y.J. Visualinstructiontun- Qiu, Z., Liu, W., Feng, H., Xue, Y., Feng, Y., Liu, Z.,
ing. InThirty-seventhConferenceonNeuralInformation Zhang,D.,Weller,A.,andScho¨lkopf,B.Controllingtext-
ProcessingSystems,2023a. to-imagediffusionbyorthogonalfinetuning. InThirty-
seventh Conference on Neural Information Processing
Liu,W.,Qiu,Z.,Feng,Y.,Xiu,Y.,Xue,Y.,Yu,L.,Feng, Systems,2023.
H.,Liu,Z.,Heo,J.,Peng,S.,etal. Parameter-efficient
orthogonalfinetuningviabutterflyfactorization. arXiv Radford,A.,Kim,J.W.,Hallacy,C.,Ramesh,A.,Goh,G.,
preprintarXiv:2311.06243,2023b. Agarwal,S.,Sastry,G.,Askell,A.,Mishkin,P.,Clark,J.,
etal. Learningtransferablevisualmodelsfromnatural
Liu,Y.,Duan,H.,Zhang,Y.,Li,B.,Zhang,S.,Zhao,W., language supervision. In International conference on
Yuan,Y.,Wang,J.,He,C.,Liu,Z.,etal. Mmbench: Is machinelearning,pp.8748–8763,2021.
your multi-modal model an all-around player? arXiv
Razdaibiedina,A.,Mao,Y.,Khabsa,M.,Lewis,M.,Hou,
preprintarXiv:2307.06281,2023c.
R., Ba, J., and Almahairi, A. Residual prompt tuning:
Lu, P., Mishra, S., Xia, T., Qiu, L., Chang, K.-W., Zhu, improvingprompttuningwithresidualreparameteriza-
S.-C., Tafjord, O., Clark, P., and Kalyan, A. Learn to tion. InFindingsoftheAssociationforComputational
explain: Multimodal reasoning via thought chains for Linguistics: ACL2023,pp.6740–6757,2023.
10Renduchintala,A.,Konuk,T.,andKuchaiev,O. Tied-lora: Wei,J.,Wang,X.,Schuurmans,D.,Bosma,M.,brianichter,
Enhacingparameterefficiencyoflorawithweighttying. Xia, F., Chi, E. H., Le, Q. V., and Zhou, D. Chain of
arXivpreprintarXiv:2311.09578,2023. thought prompting elicits reasoning in large language
models. InAdvancesinNeuralInformationProcessing
Salimans,T.andKingma,D.P. Weightnormalization: a Systems,2022.
simplereparameterizationtoacceleratetrainingofdeep
neuralnetworks. InProceedingsofthe30thInternational Yeh,S.-Y.,Hsieh,Y.-G.,Gao,Z.,Yang,B.B.,Oh,G.,and
ConferenceonNeuralInformationProcessingSystems, Gong,Y. Navigatingtext-to-imagecustomization: From
lycorisfine-tuningtomodelevaluation. arXivpreprint
pp.901–909,2016.
arXiv:2309.14859,2023.
Schwenk,D.,Khandelwal,A.,Clark,C.,Marino,K.,and
Zhang, Q., Chen, M., Bukharin, A., He, P., Cheng, Y.,
Mottaghi, R. A-okvqa: A benchmark for visual ques-
Chen,W.,andZhao,T. Adaptivebudgetallocationfor
tion answering using world knowledge. In European
parameter-efficientfine-tuning. InTheEleventhInterna-
ConferenceonComputerVision,pp.146–162,2022.
tionalConferenceonLearningRepresentations,2023.
Sidorov,O.,Hu,R.,Rohrbach,M.,andSingh,A. Textcaps: Zheng,L.,Chiang,W.-L.,Sheng,Y.,Zhuang,S.,Wu,Z.,
adatasetforimagecaptioningwithreadingcomprehen- Zhuang,Y.,Lin,Z.,Li,Z.,Li,D.,Xing,E.,Zhang,H.,
sion. InComputerVision–ECCV2020: 16thEuropean Gonzalez,J.E.,andStoica,I. JudgingLLM-as-a-judge
Conference,Glasgow,UK,August23–28,2020,Proceed- with MT-bench and chatbot arena. In Thirty-seventh
ings,PartII16,pp.742–758,2020. ConferenceonNeuralInformationProcessingSystems
DatasetsandBenchmarksTrack,2023.
Singh, A., Natarajan, V., Shah, M., Jiang, Y., Chen, X.,
Batra, D., Parikh, D., and Rohrbach, M. Towards vqa Zhou,L.,Xu,C.,andCorso,J. Towardsautomaticlearning
modelsthatcanread. InProceedingsoftheIEEE/CVF ofproceduresfromwebinstructionalvideos. InProceed-
conferenceoncomputervisionandpatternrecognition, ings of the AAAI Conference on Artificial Intelligence,
pp.8317–8326,2019. 2018.
Suhr, A., Zhou, S., Zhang, A., Zhang, I., Bai, H., and
Artzi,Y. Acorpusforreasoningaboutnaturallanguage
grounded in photographs. In Proceedings of the 57th
Annual Meeting of the Association for Computational
Linguistics,pp.6418–6428,2019.
Sung,Y.-L.,Cho,J.,andBansal,M. Vl-adapter: Parameter-
efficienttransferlearningforvision-and-languagetasks.
In Proceedings of the IEEE/CVF Conference on Com-
puter Vision and Pattern Recognition, pp. 5227–5237,
2022.
Taori, R., Gulrajani, I., Zhang, T., Dubois, Y., Li, X.,
Guestrin, C., Liang, P., and Hashimoto, T. B. Stan-
ford alpaca: An instruction-following llama model,
2023. URLhttps://github.com/tatsu-lab/
stanford_alpaca.
Touvron,H.,Lavril,T.,Izacard,G.,Martinet,X.,Lachaux,
M.-A.,Lacroix,T.,Rozie`re,B.,Goyal,N.,Hambro,E.,
Azhar,F.,etal. Llama:Openandefficientfoundationlan-
guagemodels. arXivpreprintarXiv:2302.13971,2023.
Wang,Y.,Wu,J.,Dabral,T.,Zhang,J.,Brown,G.,Lu,C.-T.,
Liu,F.,Liang,Y.,Pang,B.,Bendersky,M.,etal. Non-
intrusive adaptation: Input-centric parameter-efficient
fine-tuning for versatile multimodal modeling. arXiv
preprintarXiv:2310.12100,2023.
11A.Appendix
A.1.Weightdecompositionanalysisonthevalueweightmatrix
Inthissection,weillustratethechangesinmagnitudeanddirectionwithinthevalueweightmatrixforFT,LoRA,and
DoRAacrossdifferenttrainingstepsandlayers,asshowninFigure5. Thisrevealspatternssimilartothoseseeninthe
queryweightmatrixdepictedinFigure2,indicatingthatDoRAiscapableofdisplayinglearningbehaviorsthatclosely
mirrorthoseofFTacrossvariousmodules.
FT LoRA DoRA
layer 1 0.055 Inter step 1 0.8 Inter step 1 Inter step 1
layer 2 0.050 Inter step 2 0.7 Inter step 2 1.0 Inter step 2
l la ay ye er r 3 4 0.045 I Fn it ne ar l s st te ep p 3 0.6 I Fn it ne ar l s st te ep p 3 I Fn it ne ar l s st te ep p 3
layer 5 M0.040 0.5 0.8
layer 6
0.035 0.4 0.6
0.030 0.3
0.025 0.4
0.2
0.020
0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.150 0.175 0.200 0.225 0.250 0.275 0.300 0.325 0.20 0.25 0.30 0.35 0.40 0.45 0.50
D D D
(a) (b) (c)
Figure5.MagnitudeandDirectionalchangesofFT(a),LoRA(b),andDoRA(c)oftheVweightmatricesacrossdifferentlayersand
intermediatesteps.
A.2.AblationstudyforthemodificationtoreduceDoRAtrainingcost
Table 7 presents the GPU cost and the average accuracy of DoRA with and without the proposed modification for
commonsensereasoningtasksandimage-textunderstandingtasks. Theresultsindicatethatthemodificationleadstoa
training memory reduction of approximately 24.4% in fine-tuning LLaMA and 12.4% in VL-BART. Furthermore, the
accuracyofDoRAwiththemodificationremainsunchangedforVL-BARTandshowsanegligibledifferenceofonly0.2
comparedtoDoRAwithoutthemodificationonLLaMA.
Table7.GPU cost and accuracy of DoRA with or without the modification on the commonsense reasoning tasks and image-text
understandingtasks.
Model PEFTMethod Accumulationsteps BatchSize GPUMemoryCost(GB) #Params(%) Avg.
DoRAw/omodification 37.3 0.84 78.3
LLaMA-7B 4 16
DoRA 28.2(-24.4%) 0.84 78.1
DoRAw/omodification 23.4 5.96 77.3
VL-BART - 300
DoRA 20.5(-12.4%) 5.96 77.4
12A.3.Hyperparameters
Table8. HyperparameterconfigurationsofDoRAforLLaMA-7B/13Bonthecommonsensereasoningtasks.
Hyperparameters(DoRA) LLaMA-7B LLaMA-13B
Rankr 16 32 16 32
α 32 64 32 64
Dropout 0.05
Optimizer AdamW
LR 2e-4 2e-4 3e-4 2e-4
LRScheduler Linear
Batchsize 16
WarmupSteps 100
Epochs 3
Where Q,K,V,Up,Down
Table9. HyperparameterconfigurationsofDoRAforfine-tuningVL-Bartonimage/video-texttasks.
Hyperparameters(DoRA) image-text video-text
Rankr 128
α 128
Dropout 0.0
Optimizer AdamW
LR 1e-3 3e-4
LRScheduler Linear
Batchsize 300 40
Warmupratio 0.1
Epochs 20 7
Where Q,K
Table10.HyperparameterconfigurationsofDoRAandLoRAforfine-tuningLLaVA-1.5-7Bwithvisualinstructiontuningdatasets.
Hyperparameters DoRA LoRA
Rankr 128
α 256
Dropout 0.05
Optimizer AdamW
LR 2e-4
LRScheduler Cosinedecay
Batchsize 16
Warmupratio 0.03
Epochs 1
Where Q,K,V,O,Up,Down,Gate
13Table11.HyperparameterconfigurationsofDoRAandDVoRAforfine-tuningLLaMA-7BandLLaMA2-7BwithcleanedAlpacadataset.
Hyperparameters(DoRA) LLaMA-7B LLaMA2-7B Hyperparameters(DVoRA) LLaMA-7B LLaMA2-7B
Rankr 64 Rankr 1024
Dropout 0.0 Dropout 0.0
Optimizer AdamW Optimizer AdamW
LR 4e-4 LR 4e-3
LRScheduler Cosine LRScheduler Cosine
Batchsize 4 Batchsize 4
AccumulationSteps 4 AccumulationSteps 4
Warmupratio 0.1 Warmupratio 0.1
Epochs 1 Epochs 1
Where Q,K,V,O,Up,Down,Gate Where Q,K,V,O,Up,Down,Gate
14A.4.Visualinstructiontuningevaluationresult
Table12presentstheevaluationresultofLLaVA-1.5-7Bfine-tunedusingDoRA,LoRA,andFTwithvisualinstruction
tuningdata. Theevaluationisconductedonanarrayofsevendifferentvision-languagebenchmarks. Fromthetable,wecan
seethatDoRAconsistentlyoutmatchFT,andcanachieveanaverageaccuracybetterthanLoRA.
Table12.VisualinstructiontuningevaluationresultofDoRA,LoRA,andFTforLLaVA-1.5-7Bonawiderangeof7vision-language
tasks.
Method #Params(%) VQAv2 GQA VisWiz SQA VQAT POPE MMBench Avg.
FT 100 78.5 61.9 50.0 66.8 58.2 85.9 64.3 66.5
LoRA 4.61 79.1 62.9 47.8 68.4 58.2 86.4 66.1 66.9
DoRA(Ours) 4.63 78.6 62.9 52.2 69.9 57 87.2 66.1 67.6
15A.5.Instruction-tuningevaluationexamples
WesampletwoquestionsfromtheMT-BenchquestionsetandpresenttherespectiveresponsesfromDVoRAandVeRA,
including the scores and comments provided by GPT-4. From these examples, we can observe that responses from
DVoRAaregenerallymoreaccurateandwell-organizedcomparedtothosefromVeRA.Forinstance,inresponsetoQuestion
24,DVoRAleveragesawell-knownsuperherostorythatisfamiliartochildren,whereasVeRA’sresponsebeginswithan
uncertaintone,potentiallymakingitlessengagingthanDVoRA’sreply.
Table13.Question24fromMT-BenchalongsidewithresponsefromLLaMA2-7Bfine-tunedwithDVoRAandVeRA,andtheevaluation
providedbyGPT-4.
Question24 Asasuperhero,howwouldyouexplainyouroriginstorytoacuriouschild?
VeRA Well,I’mnotreallysurewhereIcomefrom. AllIknowisthatoneday,Iwokeupwithspecial
powersandabilitiesthatallowedmetohelppeople. Idecidedtousemypowerstofightcrimeand
protecttheinnocent,andthat’showIbecameasuperhero
DVoRA Asasuperhero,Ihavetheabilitytousemysuperpowerstoprotectpeopleandfightagainstevil. My
originstorybeginswhenIwasjustaregularkidlikeyou,butoneday,Iwasbittenbyaradioactive
spider,anditgavemeincrediblepowers. Icouldclimbwalls,shootwebs,andseeinthedark. I
decidedtousemypowerstohelppeople, andthat’showIbecameyourfriendlyneighborhood
Spider-Man.
GPT-4Evaluation Score: 57. Assistant1’sresponsestartswithanuncertaintone,whichmightnotbeveryengaging
forachild. Theexplanationisquitevagueanddoesn’tofferaclearorimaginativeoriginstorythat
couldcaptivateachild’sinterest. Itdoes,however,maintainthethemeofusingpowersforgood,
whichisapositivemessage. Assistant2’sresponseismoredetailedandusesafamiliarsuperhero
origin story (Spider-Man’s) that many children can relate to and understand. It’s engaging and
providesaclearnarrativeofhowanordinarypersoncanbecomeasuperhero. However,itdirectly
referencesSpider-Man,whichisnotanoriginaloriginstoryandcouldbemisleadingiftheassistant
issupposedtobeauniquesuperhero. Despitethis,theresponseismorelikelytoresonatewitha
childduetoitsclarityandreliability. Bothresponsescouldbeimprovedbyprovidinganoriginal
andimaginativeoriginstorythatdoesn’trelyonexistingsuperheronarratives. Theyshouldalso
ensurethatthestoryissimpleenoughforachildtounderstandwhilebeingengagingandinspiring.
16Table14.Question33fromMT-BenchalongsidewithresponsefromLLaMA2-7Bfine-tunedwithDVoRAandVeRA,andtheevaluation
providedbyGPT-4.
Question33 WhymightsomeonechoosetouseapapermaporaskfordirectionsinsteadofrelyingonaGPS
deviceorsmartphoneapp?
VeRA There are several reasons why someone might choose to use a paper map or ask for directions
insteadofrelyingonaGPSdeviceorsmartphoneapp. Somepeoplemaypreferthephysicalactof
navigatingwithapapermap,asitcanbemoretactileandinteractive. Othersmayprefertohavea
hardcopyofthemapincasetheGPSorappfailsorthebatterydies. Additionally,somepeople
maynothaveaccesstoaGPSdeviceorsmartphone,ormaynotwanttorelyontechnologyfor
navigation. Finally,somepeoplemaysimplypreferthesecurityandpeaceofmindthatcomeswith
knowingexactlywheretheyareandhowtogettotheirdestination
DVoRA There are several reasons why someone might choose to use a paper map or ask for directions
instead of relying on a GPS device or smartphone app. Here are some of them: 1. Navigation
accuracy: GPSdevicesandsmartphoneappsrelyonsatellitesignalstopinpointyourlocation,but
thistechnologyisnotfoolproof. GPSsignalscanbeblockedbytallbuildings,tunnels,orother
obstacles,resultingininaccurateormissinginformation. Papermaps,ontheotherhand,arebased
onaccurate,up-to-dateinformationthatisnotsubjecttotheselimitations. 2. Cost: GPSdevices
andsmartphoneappscanbeexpensivetopurchaseandmaintain. Papermapsarefreetouseand
donotrequireanongoingsubscriptionordataplan. 3. Personalpreference: Somepeopleprefer
thetactileexperienceofusingapapermap,whichcanbeeasiertoreadandnavigatethanascreen.
Othersenjoythechallengeofnavigatingwithouttechnology,whichcanhelpthemlearnmoreabout
theareatheyarevisiting. 4. Batterylife: GPSdevicesandsmartphoneappscandrainbatteries
quickly,especiallywhenusedfornavigation. Papermapsdonotrequirepower,sotheycanbeused
forextendedperiodswithoutrecharging. 5. Offlineuse: GPSdevicesandsmartphoneappsrely
onaninternetconnectiontofunctionproperly. Ifthereisnosignal,thedevicewillnotbeableto
provideaccurateinformation. Papermaps,ontheotherhand,canbeusedoffline,makingthemideal
foruseinremoteorunpopulatedareas. Insummary,thereareseveralreasonswhysomeonemight
choosetouseapapermaporaskfordirectionsinsteadofrelyingonaGPSdeviceorsmartphone
app. Theseincludenavigationaccuracy,cost,personalpreference,batterylife,andofflineuse.
GPT-4Evaluation Score: 68. Assistant1’sresponseissomewhatbriefandlacksspecificdetailsthatcouldbehelpful
totheuser. Itmentionsthetactilenatureofpapermaps,thepossibilityoftechnologyfailure,lack
of access to technology, and a general preference for security and peace of mind. However, it
doesnotdelveintothepracticalconsiderationssuchasGPSsignallimitations,cost,batterylife,or
offlineuse,whichareimportantfactorsindecidingbetweenpapermapsanddigitalnavigationtools.
Assistant2’sresponseismorecomprehensiveandprovidesastructuredlistofreasons,including
navigationaccuracy,cost,personalpreference,batterylife,andofflineuse. Eachpointisexplained
clearly,givingtheuserabetterunderstandingofthepotentialadvantagesofpapermapsoverGPS
devicesorsmartphoneapps. Theresponseisrelevant,accurate,anddetailed,makingitmorehelpful
totheuser. Bothassistantsprovidedrelevantandaccurateinformation,butAssistant2’sansweris
moredetailedandstructured,whichiswhyitreceivesahigherscore. Thescoresreflectthelevelof
detailandtheusefulnessoftheinformationprovidedtotheuser,withAssistant2offeringamore
completeanswertothequestion
17A.6.Robustnesstowardsdifferentnumbersofinstructiontunningexamples
Figure6depictsthescoreofDoRA,LoRA,DVoRA,andVeRAforfine-tuningLLaMA-7Bwithvaryinginstruction-tuning
samplesizes,including1000,4000,7000,and10000. Fromthefigure,wecanobservethatsimilartothatoftheresulton
LLaMA2-7B,bothDoRAandDVoRAconsistentlyoutperformLoRAandVeRAacrosstheentirerangeoftrainingsample
sizes.
LLaMA-7B
5.5
5.0
4.5
4.0 DoRA
LoRA
3.5
DVoRA
3.0 VeRA
1000 4000 7000 10000
Number of instruction tuning training samples
Figure6.PerformanceofLLaMA-7Bfine-tunedwithLoRA,DoRA,VeRA,andDVoRAonMT-Benchusingdifferentnumbersoftraining
samplesfromAlpacadataset(Taorietal.,2023).
18
erocSA.7.RobustnessofDoRAtowardsdifferentrank
Table 15 shows a comparison of the average accuracy between LoRA and DoRA method across various rank settings
forcommonsensereasoningtasks. DoRAconsistentlyoutperformsLoRAatallranksettings,withtheperformancegap
wideningastherankdecreases. ThissuggeststhatourmethodeffectivelyenhancesthelearningcapacityofLoRA,enabling
ittoachievebetteraccuracywithfewertrainableparameters.
Table15.AccuracycomparisonofLoRAandDoRAwithvaryingranksforLLaMA-7Bonthecommonsensereasoningtasks.
PEFTMethod rankr #Params(%) BoolQ PIQA SIQA HellaSwag WinoGrande ARC-e ARC-c OBQA Avg.
4 0.10 2.3 46.1 18.3 19.7 55.2 65.4 51.9 57 39.5
8 0.21 31.3 57.0 44.0 11.8 43.3 45.7 39.2 53.8 40.7
LoRA 16 0.42 69.9 77.8 75.1 72.1 55.8 77.1 62.2 78.0 70.9
32 0.83 68.9 80.7 77.4 78.1 78.8 77.8 61.3 74.8 74.7
64 1.64 66.7 79.1 75.7 17.6 78.8 73.3 59.6 75.2 65.8
4 0.11 51.3 42.2 77.8 25.4 78.8 78.7 62.5 78.6 61.9
8 0.22 69.9 81.8 79.7 85.2 80.1 81.5 65.7 79.8 77.9
DoRA(Ours) 16 0.43 70.0 82.6 79.7 83.2 80.6 80.6 65.4 77.6 77.5
32 0.84 68.5 82.9 79.6 84.8 80.8 81.4 65.8 81.0 78.1
64 1.65 69.9 81.4 79.1 40.7 80.0 80.9 65.5 79.4 72.1
19