INSUBMISSIONTOIEEETRANSACTIONSONMEDICALIMAGING,VOL.XX,NO.XX,XXXX20241
Deep Rib Fracture Instance Segmentation and
Classification from CT on the RibFrac Challenge
Jiancheng Yang, Rui Shi, Liang Jin, Xiaoyang Huang, Kaiming Kuang, Donglai Wei, Shixuan Gu, Jianying
Liu, Pengfei Liu, Zhizhong Chai, Yongjie Xiao, Hao Chen, Liming Xu, Bang Du, Xiangyi Yan, Hao Tang,
Adam Alessio, Gregory Holste, Jiapeng Zhang, Xiaoming Wang, Jianye He, Lixuan Che, Hanspeter
Pfister, Ming Li, Bingbing Ni
Abstract—Rib fractures are a common and potentially thechallengesummary.Theanalysisrevealedthatseveral
severe injury that can be challenging and labor-intensive top rib fracture detection solutions achieved performance
to detect in CT scans. AI has the potential to assist in comparable or even better than human experts. Neverthe-
identifying and diagnosing rib fractures, but the unique less, the current rib fracture classification solutions are
shapeofeachrib,withadiagonalcourseacrossnumerous hardly clinically applicable, which can be an interesting
CTsections,presentsatechnicalhurdle.Whiletherehave area in the future. As an active benchmark and research
been efforts to address this field, the lack of large-scale resource, the data and online evaluation of the RibFrac
annotated datasets and evaluation benchmarks has hin- Challenge are available at the challenge website (https:
dered the development and validation of deep learning al- //ribfrac.grand-challenge.org/).Asanindependent
gorithms.Toaddressthisissue,theRibFracChallengewas contribution, we have also extended our previous internal
introduced, providing a benchmark dataset of over 5,000 baseline by incorporating recent advancements in large-
rib fractures from 660 CT scans, with voxel-level instance scale pretrained networks and point-based rib segmenta-
mask annotations and diagnosis labels for four clinical tiontechniques.TheresultingFracNet+demonstratescom-
categories(buckle,nondisplaced,displaced,orsegmental). petitive performance in rib fracture detection, which lays
The challenge includes two tracks: a detection (instance a foundation for further research and development in AI-
segmentation) track evaluated by an FROC-style metric assistedribfracturedetectionanddiagnosis.
and a classification track evaluated by an F1-style metric.
Index Terms—rib fracture, 3D detection, 3D classifica-
DuringtheMICCAI2020challengeperiod,243resultswere
tion,3Dinstancesegmentation,computedtomography.
evaluated, and seven teams were invited to participate in
I. INTRODUCTION
This work was supported by National Science Foundation of China
(U20B200011, 61976137). This work was also supported by Grant RIB fractures are a common injury that can result from
YG2021ZD18fromShanghaiJiaoTongUniversityMedicalEngineering various causes such as falls, trauma, athletic activities,
Cross Research. Jiancheng Yang and Rui Shi contributed equally.
non-accidental injury, or primary bone tumors and metastatic
Correspondingauthor:BingbingNi(e-mail:nibingbing@sjtu.edu.cn).
J. Yang, R. Shi, X. Huang, B. Ni are with Shanghai Jiao Tong lesions [1]–[3]. Internal injuries such as liver or spleen lac-
University,Shanghai,China. erations, mediastinal injury, pneumothorax, hemothorax, flail
L. Jin is with Radiology Department, Huadong Hospital affiliated to
chest, and pulmonary contusions may also be associated with
FudanUniversity,Shanghai,ChinaandwithHuashanHospitalaffiliated
toFudanUniversity,Shanghai,ChinaandalsowithShanghaiKeyLabof rib fractures [4]. The severity of trauma can be indicated by
ForensicMedicine,KeyLabofForensicScience,AcademyofForensic the number of fractured ribs, which can result in increased
Science,MinistryofJustice,China.
morbidity and mortality rates [5], [6]. Counting the number
K.KuangiswithDianeiTechnology,Shanghai,China,andalsowith
UCSanDiego,CA,USA. of rib fractures is important in forensic examinations for
D.WeiiswithBostonCollege,MA,USA. determining the degree of disability [7], [8].
S.GuiswithHarvardUniversity,MA,USA.
Multidetector computed tomography (CT) scanning is a
J.Liu,P.LiuarewithHuiyingMedicalTechnology(Beijing)Co.,Ltd.,
Beijing,China. valuable tool for identifying rib fractures with higher accu-
Z.Chai,Y.XiaoarewithImsightMed,Shenzhen,China. racy than standard chest radiographs [6], [8], [9]. However,
H. Chen is with Hong Kong University of Science and Technology,
the sheer volume of images generated by CT scans, cou-
HongKongSAR.
L.XuandB.DuarewithZhejiangUniversity,Hangzhou,China. pled with the complex shape of each rib and its diagonal
X.Yan,H.TangarewithUCIrvine,CA,USA. course across numerous CT sections, makes interpreting them
A.AlessioiswithMichiganStateUniversity,MI,USA.
challenging [10]. This difficulty is compounded in cases of
Gregory Holste is with University of Texas at Austin, TX, USA, and
alsowithMichiganStateUniversity,MI,USA. polytraumatizedpatients,whereradiologistsareunderpressure
J. Zhang, X.Wang are with University of Shanghai for Science and to rapidly identify life-threatening injuries [9], [11]. As a
Technology,Shanghai,China.
result, secondary injuries like rib fractures can be overlooked,
J. He, L. Che are with DeepBlue Technology (Shanghai) Co., Ltd,
Shanghai,China. withstudiesshowingthatupto20.7%ofribfracturesmaybe
H.PfisteriswithHarvardUniversity,MA,USA. missed on CT scans [11], [12]. While most of these missed
M. Li is with Radiology Department, Huadong Hospital affiliated to
fracturesmaybeminor,theirconsequencescanstillbesignifi-
FudanUniversity,Shanghai,China,andalsowithInstituteofFunctional
andMolecularMedicalImaging,Shanghai,China. cant for patients, clinicians, and radiologists. Among different
4202
beF
41
]VI.ssee[
1v27390.2042:viXra2 INSUBMISSIONTOIEEETRANSACTIONSONMEDICALIMAGING,VOL.XX,NO.XX,XXXX2024
Task 1: Rib Fracture Detection
nosis labels for four clinical categories: buckle, nondisplaced,
elk
cu displaced, or segmental. The challenge consists of two tracks:
B
a detection track and a classification track, as illustrated in
n
o
N-d ecalp
sid
F ipi ag n. t1 s. aI rn et rh ee qud ie rt ee dcti to on s( ui bn msta itnc the ese 3g Dme inn sta tati no cn e) str ea gc mk, enp ta ar tt ii oc n-
mask for each fracture to detect their location and extent. The
d
ecalp
detectionperformanceisrankedusingafree-responsereceiver
siD operating characteristic (FROC)-based metric. Segmentation
latn metrics(IoUandDice)arealsoprovidedforanalysis,butthey
em are not used for ranking because the rib fracture detection
g
eS
is more important than segmentation in clinical practice. In
the classification track, participants are required to submit
Task 2: Rib Fracture
Classification the label for each fracture to identify their type based on
their detection results. The classification performance of the
Fig.1:IllustrationoftwotracksintheRibFracChallenge. end-to-end system (from detection to classification) is ranked
In the rib fracture detection track, participants submit the 3D using an F1 score-based metric. The dataset is the largest
instance segmentation mask for each fracture to detect their publicly available dataset of rib fractures with instance-level
location and extent. In the rib fracture classification track, annotations,andoffersauniqueopportunityforresearchersto
participants submit the label for each fracture to identify their develop and validate deep learning algorithms for rib fracture
type(buckle,non-displaced,displaced,orsegmental).Thered detection and diagnosis.
regions are the segmentation masks of rib fracture instances.
The challenge was held as a satellite event during MICCAI
2020, and a total of 243 submissions were evaluated during
the official challenge period. From these, seven teams were
types of fractures, buckle fractures are the most frequently selected to participate in the challenge summary. The analysis
missed type of fracture due to their confusing appearance, has demonstrated the potential of AI-assisted rib fracture
and nondisplaced fractures can also be missed when they detectionanddiagnosis,assomeofthetopdetectionsolutions
are parallel to the scan plane of the CT images [13], [14]. achieved performance comparable to or even better than hu-
Diagnosing subtle fractures is a tedious and time-consuming man experts. However, the current rib fracture classification
process, requiring the sequential evaluation of a large number solutions are not yet clinically applicable, emphasizing the
of CT slices, rib-by-rib and side-by-side [10]. In cases where need for further research and development in this domain.
missedinjuriesareaconcern,someexpertshaverecommended Thechallenge,bothhistoricallyandpresently,ishostedonthe
double-readingwhole-bodyCTscansinhigh-riskpatients[9]. Grand Challenge website1, offering a comprehensive dataset
However, this may not always be feasible. and an online evaluation platform for advancing research and
Emerging artificial intelligence (AI) technology has made development in AI-assisted rib fracture detection and diagno-
significantstridesinthefieldofmedicalservicesanddelivery, sis.AsofDecember2023,ithasattractedover1,200registered
particularly in screening [15]–[19], diagnosis [20]–[25], and users. Post the official competition period, additional teams
treatment [26]–[30]. With high-performance deep learning, have submitted their results and elevated the benchmark. This
computer-aided diagnosis powered by AI can help reduce indicates that the RibFrac Challenge is actively contributing
the burden on human labor, enhance diagnosis consistency to the development of deep learning in rib fracture diagnosis.
and accuracy, personalize patient treatment, and improve the As an independent technical contribution distinct from the
patient-doctor relationship [31]. AI can transform rib fracture benchmark and challenge, this paper delineates how we have
diagnosis and treatment by aiding healthcare professionals. enhanced our internal baseline FracNet [36]. Post the official
Automated diagnosis through AI, such as rib unfolding, competition, the field has witnessed significant advancements.
streamlinestheprocessandimprovesaccuracy,thoughtraining For instance, we have developed a point-based rib segmen-
is needed to avoid errors [7], [10], [32], [33]. AI-assisted tation technique on the RibFrac dataset [37], [38], which
radiologists, particularly using convolutional neural networks, is expected to significantly improve rib fracture detection.
have shown improved accuracy in rib fracture detection [34]– Furthermore, the emergence and accessibility of large-scale
[36]. However, the lack of large-scale annotated datasets and pre-trained networks for 3D medical imaging have been no-
evaluation benchmarks limits deep learning development in table[39].Inlightofthesedevelopments,weintroducedFrac-
this area, underscoring the need for comprehensive datasets Net+, which has achieved competitive results in rib fracture
and benchmarks for AI model training, evaluation, and re- detection. This underscores the beneficial role of rib segmen-
search advancement. tation in the fracture detection and establishes a foundation
TheRibFracChallengewaslaunchedtofacilitatethedevel- for future research in this area.
opment and evaluation of automated methods for rib fracture Our contributions can be summarized as follows:
detectionanddiagnosisfromCTscans.Thechallengeprovides • Formalizing research problem. The RibFrac Challenge
thefirstlarge-scalebenchmarkdatasetofribfracturesfromCT represents the first instance of formalizing rib fracture
scans,comprisingover5,000ribfracturesfrom660CTscans.
Eachscanhasvoxel-levelinstancemaskannotationsanddiag- 1https://ribfrac.grand-challenge.org/YANGetal.DEEPRIBFRACTUREINSTANCESEGMENTATIONANDCLASSIFICATIONFROMCTONTHERIBFRACCHALLENGE 3
A
diagnosis as a machine learning problem. The task is
well-designed,enablingparticipantstodevelopandassess ytisneD ytisneD ytisneD
automated methods specifically focused on rib fracture
detection and diagnosis.
Number of Slices Number of Rib Fractures Volumetric Size of Rib Fracture
• Large in scale.Thedatasetstandsasthelargestpublicly B Cropped 3D Patch Axial 2D View Cropped 3D Patch Axial 2D View Cropped 3D Patch Axial 2D View Cropped 3D Patch Axial 2D View
available collection of rib fractures with instance-level
mask annotations. It comprises over 5,000 rib fractures
from 660 CT scans, providing a rich dataset for re- Coronal 2D View Sagittal 2D View Coronal 2D View Sagittal 2D View Coronal 2D View Sagittal 2D View Coronal 2D View Sagittal 2D View
searchers to train and validate deep learning algorithms.
• Community impact. With more than 1,200 registered
Fig. 2: Statistics and sample visualization of the RibFrac
users, the challenge has garnered considerable interest
Challengedataset.A)Histogramsthatdisplaythedistribution
and participation from the research community. It has
of the number of slices per scan (left), the number of rib
been instrumental in the evolution of deep learning al-
fractures per scan (middle), and the volumetric size of each
gorithms for rib fracture detection and diagnosis.
individual rib fracture (right). B) Visualization of four rib
• Strong internal method. Capitalizing on recent ad-
fracture samples. Each of the four rib fracture samples is
vancements in large-scale pretrained medical models and
represented by a cropped 3D CT patch using volumetric
domain-specific progress in rib segmentation, we have
rendering (upper left). The axial (upper right), coronal (lower
extended the previous internal method for rib fracture
left) and sagittal (lower right) from the fracture centroid are
detection and achieved competitive performance.
shown in 2D, along with the human-annotated rib fracture
II. RELATED WORK voxel-level segmentation.
A. RibFractureDetection
Several recent studies have explored deep learning ap-
providesastablereferenceforlungvolumeestimation[52]and
proaches for rib fracture detection. For instance, a UNet
bone abnormality quantification [53]. Anatomical centerlines
modelincorporatingadual-attentionmechanismdemonstrated
derived from rib structures enable the localization of organs
improvedperformancecomparedtoearliermethods.However,
for surgery planning [54] and the registration of pathologies
it had limited applicability as it only worked on a restricted
like lung nodules [55]. Furthermore, automatic rib segmen-
numberofCTslidesandlackedadetailedannotationprotocol
tation and centerline extraction are essential for developing
for their dataset [40]. Classic models like DenseNet [41]
visualization tools for unfolded rib cages [10], [56], [57].
and ResNet [42] have also been utilized for automatic rib
In recent years, several studies have investigated rib seg-
fracture detection, but the models were not released, and
mentation and centerline extraction methods using CT scans.
they were evaluated on relatively small datasets that were not
The RibSeg dataset [37], [38] was specifically created to
publicly available, which may affect the generalizability of
benchmark rib labeling and anatomical centerline extraction
their results [34], [43]. Some architectures typically used in
using CT scans from the RibFrac challenge. MDUNet [58]
object detection and image classification, such as CenterNet
employs multiscale feature fusion and dense connections [41]
[44] and DLA34 [45], have been applied to screening and
to segment clavicles and ribs. Other approaches include a
false-positive elimination in rib fracture detection, but they
detection-then-segmentation pipeline with nine degrees-of-
did not include a large validation set [46]. Other studies
freedom pose estimation [59] and trainable segmentation net-
have focused on the clinical validation of deep learning
works that combine multiple 3D UNets at different resolu-
methods for rib fracture detection. For example, comparative
tions [60] for rib segmentation from CT scans. Additionally,
studies have demonstrated that deep learning-based software
studies have focused on rib centerline extraction, employing
can be integrated into radiology workflows to enhance rib
techniquessuchasdeformabletemplatematching[61]andrib
fracture detection accuracy and reading efficiency [47]–[49].
tracing [62] on rib cages detected by deep learning models.
Additionally, Kaiume et al. utilized a deep convolutional
The significance of rib segmentation and centerline ex-
neural network-based software and compared its rib fracture
traction could serve as structural references for rib fracture
diagnostic performance with doctors [50], while Niiya et al.
detection. Our internal method has successfully demonstrated
evaluatedtheclinicaleffectivenessofdeeplearningmodelsfor
its beneficial role.
rib fractures in high-energy trauma patients [51]. However,
these studies were limited by their relatively small in-house
datasets. While these works demonstrate the potential of deep III. THE RIBFRAC CHALLENGE
learning-based approaches for rib fracture detection, they also
A. Dataset
highlight the need for larger, more diverse datasets with
detailed annotations, and more rigorous validation to improve 1) DataAcquisitionandPretreatment: The RibFrac Dataset
accuracy and clinical applicability. used in the challenge has been specifically curated for rib
fracture detection, segmentation, and classification. This com-
B. RibSegmentationandCenterlineExtraction prehensive dataset consists of chest-abdomen CT scans, rib
Rib segmentation and anatomical centerline extraction play fracture segmentation, and classification information for a
crucialrolesinvariousclinicalapplications.Ribsegmentation total of 660 patients. The data collection was conducted4 INSUBMISSIONTOIEEETRANSACTIONSONMEDICALIMAGING,VOL.XX,NO.XX,XXXX2024
TABLEI: RibFrac dataset subsets and fracture categories.
The table shows the number of patients and rib fractures in True Positive
w/o Conf Thresh
each subset of the RibFrac dataset. The RibFrac contains
Conf: 0.9
four different categories of rib fractures, including buckle False Negative
True Positive
(BK), non-displaced (ND), displaced (DP), and segmental w/o Conf Thresh False Negative
Ground Truth IoU ≥ 0.2 ✘ Sample 1
(SG). Fractures that are difficult to categorize are labeled as
unclassified (UN) and are excluded from the evaluation.
Conf: 0.7
Subset Patients Fractures BK ND DP SG UN False Negative
Conf: 0.7
Training 420 3,987 618 567 291 179 2,332 Conf: 0.9
False Negative False Positive False Positive
Validation 80 435 69 63 30 30 243
Prediction IoU < 0.2 ✘ Sample 2
Test 160 882 151 188 84 50 409
Fig. 3: Illustration of detection hit in the FROC. Left:
Total 660 5,304 838 818 405 259 2,984
A detection proposal is considered a hit (or a true positive
without the confidence threshold) when it overlaps with any
annotation with an IoU ≥ 0.2 (depicted in blue). The orange
retrospectively and received approval from the ethics com-
and yellow instances represent false negatives, indicating an-
mittee of Huadong Hospital affiliated to Fudan University
notatedfracturesthatwerenotdetected.Thegreenonedenotes
(NO.2019K146), with informed consent waived.
a false positive, indicating a predicted fracture that does not
Toacquirethedata,weutilizedtwoadvancedCTscanners: exist. Right: Two illustrative samples on CT slices.
the 16cm wide coverage detector CT (Revolution CT, GE
Healthcare, WI, USA) and the second-generation dual-source
CT scanner (Somatom Definition Flash, Siemens Healthcare,
human-in-the-loop labeling process.
Forchheim,Germany).Theinclusionofdatafromtwodistinct
In addition to the rib fracture segmentation masks, we also
CT scanners enhances the robustness and adaptability of the
provide classification labels. Rib fractures are classified into
developed algorithms. To ensure patient privacy, the CT scans
four different classes (refer to Fig. 1 for visual examples):
and rib fracture annotations were converted from the raw
• Buckle fractures (BK) are incomplete fractures that
DICOM (Digital Imaging and Communications in Medicine)
appear as bulges in the rib. While buckle fractures are
to the NIFTI (Neuroimaging Informatics Technology Initia-
common in pediatric patients across various bones, they
tive) format. We partitioned the dataset into three subsets: the
can be easily missed in radiology examinations.
training set (420 samples), the validation set (80 samples),
• Non-displaced fractures (ND) are fractures that do not
andthetestset(160samples),wherethelabelsforthetestset
cause any displacement or misalignment of the bones.
were hidden for evaluation. For a detailed breakdown of the
Therefore, they can be challenging to identify in radiog-
numberofpatients,CTslices,andribfracturesineachsubset,
raphy. Non-displaced rib fractures may only be observed
please refer to Tab. I. Additionally, you can find a visual
in follow-up exams when signs of healing have already
representation of the RibFrac Dataset in Fig. 2, showcasing
manifested.Radiologistsshouldbevigilantforassociated
dataset statistics and sample visualizations.
injuries when there are no direct signs of such fractures
2) DataLabeling: ToensureafairevaluationintheRibFrac in radiography.
Challenge, five radiologists, labeled as A (3-5 years of expe-
• Displaced fractures (DP) are those when there are
rience), B (10-20 years), C (5 years), D (5 years), and E (20
corticaldisruptionsandsignificantabnormalitiesinalign-
years), participated in the labeling process. Initially, radiolo-
ment. Injuries to the surrounding tissues and structures
gistsAandBexaminedtheCTimageswithin48hoursofthe
may occur, and several lethal complications related to
examinations. Subsequently, radiologists C and D manually
displaced rib fractures have been documented.
annotated the volume of interest for rib fractures based on the
• Segmental fractures (SG) are severe injuries character-
diagnosisreportscompiledbyAandB.Thevoxelannotations
ized by at least two separate complete fractures in the
were performed using the 3D Slicer software (version 4.8.1,
same rib. Those affecting three or more contiguous rib
BrighamandWomen’sHospital).TheannotationsfromCand
levels are associated with an increased risk of flail chest.
D were later verified by senior radiologist E.
Please note that we also have a considerable number of
To enhance the comprehensiveness of the annotations, we
fractures classified as unknown (UN), indicating that they are
developed a sophisticated human-in-the-loop procedure that
rib fractures but their specific type could not be determined
combined the assistance of a deep learning model and human
due to ambiguity or diagnostic difficulty. These fractures are
expertise. A deep learning model, following the approach
excluded during the evaluation process. Tab. I presents the
in [36], was trained using the initial training subset of the
statistics of rib fracture classification labels for the RibFrac
RibFracdataset.Thismodelpredictedpotentialfractureregion
training, validation and test subsets.
candidates. Predictions that were not covered by the initial
labels were verified by radiologist E and added to the annota-
B. Evaluation
tionsifconfirmed.Ourestimationsuggeststhatapproximately
20% rib fractures were missed during the initial labeling. It is TherearetwotracksintheRibFracChallenge:thedetection
important to note that no data leakage issue occurred in the (instance segmentation) track and the classification track. InYANGetal.DEEPRIBFRACTUREINSTANCESEGMENTATIONANDCLASSIFICATIONFROMCTONTHERIBFRACCHALLENGE 5
the detection track, participants are required to submit the GT
BK DP NP SG FP UN
3D instance segmentation mask for each fracture, aiming Pred
to identify the location and extent of the fractures. In the BK Prediction Aware F1 score
classification track, participants need to submit the label for
(𝑒𝑥𝑐𝑙𝑢𝑑𝑒𝐹𝑃𝑎𝑛𝑑𝐹𝑁)
each fracture to determine its type based on the detection DP
results. The labels for the training and validation sets are
providedtotheparticipants,allowingthemtoassessthemodel NP Target Aware F1 score
performance.However,thelabelsforthetestsetarewithheld, (𝑒𝑥𝑐𝑙𝑢𝑑𝑒𝑠𝐹𝑃)
and model performance can only be evaluated by submitting SG
the results to the official website of the Grand Challenge.
To ensure transparency and provide participants with detailed FN Overall F1 Score
evaluationinformation,theevaluationcodeismadeavailable2.
1) Detection: In this task, participants are given the task Fig. 4: Illustration of classification confusion matrix and
of detecting rib fractures from CT scans, and the evaluation three F1 scores. Overall F1 score (blue) evaluates the end-
is based on Free-Response Receiver Operating Characteristic to-endclassificationperformance(fromdetectiontoclassifica-
(FROC) analysis for detection. Essentially, participants are tion),target-awareF1score(orange)evaluatesperformanceon
engaged in 3D instance segmentation; however, for a more the classification annotations (excluding FP), and prediction-
relevantassessmentofthealgorithmsintermsoftheirpractical aware F1 score (green) evaluates performance on the classifi-
applicabilityinclinicalsettings,weevaluatetheirperformance cation predictions (excluding FP and FN). FN and FP refer to
using an FROC-style detection metric. false negative and false positive predictions in detection.
Due to the elongated shape of rib fractures, the detection
taskneedstobeapproachedusinginstancesegmentation.Each
rib fracture instance is annotated by radiologists with a voxel- Fig. 4. The 5 rows represent the 5 categories of predictions:
level mask that represents the fracture region. However, due BK, ND, DP, SG, and FN (false negative of detection), while
to the inherent ambiguity of the fracture region, the instance the 6 columns represent the 6 categories of ground truth:
masksmaycontainnoise.Therefore,segmentationpredictions BK, ND, DP, SG, FP (false positive of detection), and UN
areprimarilyusedtocalculateoverlapinthedetectionmetric. (unclassified labels that are ignored during evaluation). The
The evaluation of the detection performance utilizes FROC evaluation metric for classification is the macro-average F1
analysis, which balances sensitivity and false positives (FP). score, calculated using the confusion matrix. We compute 3
Fig. 3 illustrates how the detection hit is calculated in the classification F1 metrics, each measuring different aspects of
FROC analysis. It is important to note that for objects with the classification system:
elongated shapes, the Intersection over Union (IoU) tends to • Overall F1 evaluates the overall classification perfor-
vary. Consequently, any detection proposal with an IoU ≥0.2 mance,integratingitwiththedetectionsystem.Itisused
is considered a detection hit. Otherwise, it is marked as a as the final classification ranking metric.
false negative (a fracture on the ground truth that was not • TargetAwareF1evaluatestheclassificationperformance
detected) or a false positive (a predicted fracture that does not basedontheclassificationannotations,excludingallfalse
existinthegroundtruth).Foreachdetectionproposal,thereis positives.
an associated predictive confidence (Conf). When calculating • Prediction Aware F1 evaluates the classification perfor-
the FROC curve, for each FP level, a confidence threshold mance based on the classification predictions, excluding
(Conf Thresh) needs to be determined. This threshold is used all false positives and false negatives.
todistinguishwhetheradetectionhitisatruepositiveorfalse
negative for the current FP level.
C. ChallengeSetup
The final detection metric used in the challenge ranking
is the average of sensitivities at FP levels of 0.5, 1, 2, 4, The RibFrac Challenge was held as part of MICCAI 2020,
and 8. In addition to the FROC analysis, we also calculate followingtheMICCAIChallengeguidelinesandundergoinga
the maximum detection sensitivity (Max Sensitivity) and the rigorousreviewprocessthatincludedtwoindependentreviews
average false positives per scan (Avg FP). These metrics andametareview.Thechallengedesigndocumentisavailable
representthesensitivityandnumberofFPwithoutconsidering onZenodo[63].Theevaluationofparticipantperformancewas
theFPlevel.Althoughtheclinicalimportanceofsegmentation conducted using the established evaluation methods outlined
isnotascriticalasdetection,wealsoprovidetheIoUandDice in Section III-B. The ranking metric for the detection track
score for reference in segmentation predictions. was the average sensitivity in FROC analysis, while for the
2) Classification: In this task, participants are required to classification track, the overall F1 score was used to evaluate
classify the detected rib fractures into 4 clinical classes (BK, the end-to-end system. It is worth noting that although the
ND, DP, and SG) based on the results of Task 1. During performance of the classification track partially relied on the
evaluation, the classification predictions are organized into a detection track, the two tasks were evaluated separately.
confusion matrix with 5 rows and 6 columns, as shown in The challenge consisted of two phases. In Phase 1, par-
ticipants were provided with training and validation images
2https://github.com/M3DV/RibFrac-Challenge along with their corresponding labels. In Phase 2, test images6 INSUBMISSIONTOIEEETRANSACTIONSONMEDICALIMAGING,VOL.XX,NO.XX,XXXX2024
were released, and participants were given a two-week period • Sliding-window prediction. FracNet employs a special-
to submit their solutions. During Phase 2, only the ranking ized 3D UNet for rib fracture segmentation in a sliding-
metrics were visible to the participants, which were used to window manner. To accommodate the size of whole-
determine the final challenge ranking. volume scans, which may exceed standard GPU mem-
Cash prizes and invitations to the challenge workshop were ory capacities, the scans are divided into R × R × R
awardedtothetop3teamsineachtrack,resultinginatotalof patcheswitha0.75R-voxelstride,processedsequentially
5 teams (with one team overlapping). Additionally, 10 teams through the network. Here, R denotes the size of the
were invited to contribute to this paper, and ultimately 7 valid slidingwindow.Thecumulativesegmentationoutcomeis
solutions were received. derivedbyassemblingtheseindividualpatchpredictions,
Following the official MICCAI challenge period, the maintaining the maximum values in overlapping areas.
RibFracChallengecontinuestoserveasanonlinebenchmark. • Post-processing. To reduce false positives, small predic-
Alltheevaluationmetrics,includingthoseusedforrankingas tions(under200voxels)areexcluded.Additionally,spine
well as additional metrics, remain accessible to participants, regions identified in the raw segmentation are removed.
facilitating continuous monitoring of new developments and Detectionproposalsaregeneratedbybinarizingthepost-
enabling further improvements. processedsegmentationatalowthreshold(0.1)andcom-
puting connected components on this binary segmenta-
IV. INTERNAL RIB FRACTURE DETECTION METHODS
tion.Eachconnectedcomponentisconsideredadetection
In this section, we will introduce the development of our proposal,withitsprobabilitycalculatedfromtheaverage
internal rib fracture detection method, FracNet+ as illustrated raw segmentation scores within the component.
in Fig. 5, which is an expansion of our previous FracNet
model[36].Wewillbeginbybrieflyreviewingtheapproachof
B. ExtendingFracNettoFracNet+
FracNet,andthenproceedtoenhanceitsdesignbyintegrating
tworecentadvancementsinthefield—thefirstisapoint-based 1) IntegratedwithPoint-BasedRibSegmentation: Although
ribsegmentationtechnique[37],[38],andthesecondinvolves rib unfolding may not be the ideal utilization method, the ribs
the use of large-scale pre-trained networks for 3D medical still have an anticipated role in fracture detection. Therefore,
imaging [39]. Following this, we will delve into the model following the development of FracNet, we continue to evolve
design details of the FracNet+ model. ourmethodologiesbycreatingtheRibSegdatasetandapoint-
based rib segmentation technique for rapid rib segmenta-
A. FracNetasanInternalBaseline tion [37], [38]. The basic concept is as follows:
In rib analysis, traditional methods primarily rely on the We address the sparsity of ribs in 3D volumes, which
extraction of rib centerlines, followed by techniques such compriselessthan0.5%ofthevoxels,andthehighHounsfield
as rib unfolding [10], [56] to convert original 3D images Unit (HU) values characteristic of bones in CT scans. Our
into 2D stacks for analysis. While this approach effectively approach involves designing a point cloud-based model to
utilizes anatomical knowledge of the ribs, it often encounters segment ribs on binarized sparse voxels. Initially, we set a
issues like false negatives due to the limitation of the analysis threshold of 200 HU to coarsely filter out non-bone voxels.
to two dimensions. Contrastingly, FracNet adopts a fully Thesebinarizedvolumesarethenrandomlydownsampledand
data-driven methodology. By moving away from the depen- converted into point sets, simplifying computation before pro-
dency on rib centerlines, FracNet overcomes the difficulties cessing through the network. We utilize a point cloud neural
and inaccuracies involved in translating 3D structures into net as the backbone and demonstrate robust performance in
2D representations, a common challenge in rib unfolding. sparse 3D point cloud segmentation tasks. With RibSeg, we
This strategy aligns more closely with the complex, three- can swiftly segment ribs. For instance, by considering only
dimensional nature of rib fractures. Consequently, FracNet a subset of points (30K), rib segmentation can be completed
leverages the full spatial context provided by 3D CT scans in under 1 second, in stark contrast to the over 70 seconds
for more accurate and reliable detection of fractures. This is required by sliding-window based nnUNet [64], while main-
especially pivotal in identifying subtle or complex fractures taining higher accuracy [38].
that might be missed or wrongly interpreted in 2D analyses. A naive method to integrate RibSeg with FracNet is by
This approach is not only foundational to FracNet but has replacing the bone extraction step in FracNet, which is based
also become the basis for almost all detection solutions in the on morphological operations and can only roughly delineate
RibFracChallenge,focusingondirectend-to-endlearningand bone areas, with a more precise rib extraction using RibSeg.
prediction of 3D instance segmentation of rib fractures. This enables us to predict fractures using a sliding-window
The operational phases of FracNet include pre-processing, approach around the rib predictions, enhancing the accuracy
sliding-window prediction, and post-processing. and efficiency of the fracture detection process.
• Pre-processing.Thisphaseenhancesdetectionefficiency 2) Voxel-Point Fusion with Rib Segmentation: Beyond the
by extracting bone areas using morphological operations aforementionednaiveintegration,consideringtheguidingrole
like thresholding and filtering, preserving the original of ribs in rib fracture segmentation, we propose a deep
spacing of thin-section CT scans. Input voxel intensi- integration of features from the point-based rib segmentation
ties are adjusted to a specific bone window (level=450, network into the voxel-based fracture segmentation network.
width=1100) and normalized to a range of [−1,1]. Specifically, our approach involves the following steps:YANGetal.DEEPRIBFRACTUREINSTANCESEGMENTATIONANDCLASSIFICATIONFROMCTONTHERIBFRACCHALLENGE 7
Whole 3D Binarized Volumes Sparse Point Sparse Point Whole3D
CT Volume (>1M Points) Input Rib Prediction Fracture Prediction
Point Cloud
Neural Net
Point-Based RibSeg
VoxelizedPoint Features Cropped Point Features
Voxelization
Cropped 3D Conv Conv Conv Conv Conv Cropped 3D
CT Volume Fracture Prediction
+ + + + +
Voxel-Based STU-Net (Pretrained)
Fig. 5: A schematic overview of the FracNet+ framework, illustrating the dual-branch architecture for rib fracture
segmentation. The top branch, the point-based rib segmentation network (RibSeg [37], [38]), processes binarized and
downsampled point clouds from the whole 3D CT volume to predict ribs. The bottom branch, a voxel-based rib fracture
segmentation network (a pretrained STUNet [39]), operates on cropped 3D CT volumes from rib areas to predict fractures.
The voxelized point features from RibSeg are fused with the voxel-based fracture predictions to enhance the final fracture
detection by integrating global context and local anatomical details.
TABLE II: Solution summary in the rib fracture detection track. Each of the solutions is summarized in the following
aspects: the type of neural network (2.5D / 3D / Hybrid), pretraining, false positive reduction (FPR) / multi-stage (MS),
backbone, input resolution, data augmentation methods, training loss, and special remarks.
Team 2.5D/3D Pretraining FPR/MS Backbone InputResolution DataAugmentation Loss Remarks
SameasMask
lungseg2020 ImageNet
2.5D ImageNet Yes ResNet50[42] 800×800×15 Randomflip R-CNN[65](smooth
(DT1) pretraining
L1,cross-entropy)
ResNet50[42], ImageNet
DCC 1,024×1,024×3, Randomrotationand Cross-entropy,smooth
Hybrid ImageNet Yes ResNet101[42], pretraining,
(DT2) 128×128×32 flip L1,Dice
HRNet32[66] Cascade
FakeDoctor Model
3D No Yes 3DResUNet[67] 256×256×256 Randomrotation Cross-entropy,Dice
(DT3) ensemble
UCIrvine Randomflip,rotation, Model
3D No No 3DUNet[68] 64×64×64 Cross-entropy,Dice
(DT4) scalingandtransition ensemble
MIDILab Model
3D No No 3DResUNet[67] 192×192×192 None Cross-entropy,Dice
(DT5) ensemble
Preconditioning
CCCCS
2.5D No No 2DUNet[68] 1,024×1,024 None Dice operationsto
(DT6)
extracttheribs
The FracNet+ network consists of two branches. The first feature integration, where M and C denote the number of
p
branch is the point-based rib segmentation network, with an the cropped point cloud and feature channel, respectively.
input-output mapping of N × 3 → N × 1. This network
processes a sparse point cloud sampled from the thresholded The second branch is a voxel-based segmentation network
wholeCTvolume,outputtingascoreforeachpointindicating with a UNet-like structure that inputs the cropped CT volume
whether it is part of a rib. Here, N represents the number and outputs fracture segmentation scores for each voxel, i.e.,
of input points. Based on the rib segmentation output, we 1×R×R×R → 1×R×R×R. At multiple stages of
sample a coordinate and expand a window of size R×R×R the voxel network, we integrate the feature F p from the point
centered at it. Using this window, we crop the corresponding branch. Specifically, for one of the voxel feature stages F v ∈
rangeoftheoriginalimagetoinputintothesecondbranchfor RCv×r×r×r, we first voxelize F p into voxel features F p′ ∈
fracture segmentation. Additionally, we crop the feature F ∈ RCp×r×r×r. In this step, features falling into the same voxel
p
RM×Cp fromtheprecedinglayeroftheoutputforsubsequent in the r × r × r grid are pooled together to form a single
feature, which is a differentiable operation [69]. Afterwards,
gnipporC
gnidlohserhT
gnilpmas-nwoD
gnilbmessA8 INSUBMISSIONTOIEEETRANSACTIONSONMEDICALIMAGING,VOL.XX,NO.XX,XXXX2024
we use a 1×1×1 convolutional layer to transform F′ into employapretrainedSTUNetBase[39](R=128)tomaintain
p
C channels, and then add it to F . Mathematically, a balance between accuracy and computational efficiency.
v v
The two branches are jointly trained. It involves random
F′ =Voxelization(F )∈RCp×r×r×r,
p p point sampling for the point network and random cropping
F′ =F +Conv(F′)∈RCv×r×r×r. windowsfromribforthevoxelnetwork.Botharetrainedusing
v v p
a combination of cross-entropy and Dice loss with rib and
The resulting feature F′ combines the voxel branch features
v fracture segmentation as ground truth, respectively, without
with the voxelized point branch features. Notably, although
additional data augmentation beyond random sampling.
both F and F are derived from the cropped patch, F
v p p During inference, the FracNet+ first carries out the point
inherently possesses a global context, as its input is global.
branchcomputationtosegmenttheribsandcachesthefeatures
This means that the high-level information in the point cloud
from the last layer. Subsequent to this, center coordinates are
networkhasalreadyaggregatedfeaturesextendingbeyondthe
sampled on the predicted rib segmentation to ensure that the
range of the cropped patch. Consequently, these enhanced
sliding windows cover the entire rib area. The model then
features, particularly those emphasizing the rib area, can
proceeds to the point-voxel fusion within these windows and
significantlyimprovethenetwork’sabilitytosegmentfractures
predicts the rib fracture segmentation.
along the ribs. These fusion layers are applied across multiple
stages of the voxel segmentation network. The integration of
V. RIB FRACTURE DETECTION TRACK
global and local features from both point and voxel branches
A. ChallengeSolutions
in FracNet+ aims to capitalize on the strengths of both
modalities, thereby enhancing the overall performance and The top solutions in the detection track are summarized
accuracy of rib fracture segmentation. in Tab. II. Among the six top solutions, three utilize 3D
3) Large-Scale Pre-Trained Model: A recent trend in med- neural networks, two use 2.5D neural networks, and one
ical imaging has been the development of large-scale pre- proposes a hybrid pipeline with a 2D detection network and
trained models, also referred to as medical large vision mod- a 3D segmentation network. These solutions do not use any
els [70], [71]. These models are trained on extensive datasets, additional datasets. Most of the solutions do not employ any
enabling them to learn strong representations of medical pretraining models, except for one solution that utilizes the
images, which can significantly enhance their performance on ImageNet pretraining. The best-performing solution designs
specific tasks without extensive task-specific training. separate networks for false positive reduction, while another
One of the key benefits of these large pre-trained models solution removes prediction masks with small areas to reduce
is their ability to act as a “free lunch” to boost the per- falsepositives.TheUNet[67],[68]architectureiswidelyused
formance of applications in medical imaging. By leveraging as the backbone in these solutions. For data augmentation,
the rich features learned from vast and varied data, they most solutions employ random flip or rotation, and some
can provide a strong foundation for further fine-tuning on alsoapply randomcrop. Traininglosses includecross-entropy
more specialized tasks, such as the segmentation of specific loss, Dice loss, smooth L1 loss, and soft IoU loss. Special
anatomical structures. In the context of our application, we techniques such as model ensemble are utilized to improve
have chosen STUNet [39], [72], a UNet-based model pre- thedetectionperformance.Moremethoddetailsforeachteam
trained on the TotalSegmentator dataset [72], pre-trained for can be found here [74].
the segmentation of 104 different organs from CT scans,
notably including the ribs. It is worth mentioning that the rib B. ChallengeResults
labelsintheTotalSegmentator[72]werederivedfrommodels
The results of rib fracture detection for different solutions
trained on our RibFrac dataset with RibSeg labels [37], [38].
are presented in Tab. III. Sensitivities at various false positive
The choice of STUNet as the pre-trained model is strategic,
(FP) levels are reported for each solution, along with their
as the extensive pre-training on large-scale CT scans with a
average. The maximum sensitivity and average number of
broad range of anatomical structures provides a sophisticated
FPs are also provided as additional detection metrics, while
understanding of the surrounding anatomy. To adapt STUNet
Intersection over Union (IoU) and Dice scores serve as seg-
forribfracturedetection,weemployedafullmodelfine-tuning
mentation metrics. The average sensitivity at different FP
approach, as the annotations of rib fractures on the RibFrac
levels is used as the final detection metric for ranking.
dataset is sufficiently large.
DT1 achieved the highest detection FROC score and max-
imum sensitivity. Among the top solutions, DT5 had the
C. ModelDetails fewest false positives but lower sensitivity. DT3 achieved the
In this section, the method details will be outlined, encom- highestIoUandDicescores,indicatingsuperiorsegmentation
passing the model architecture, training, and inference. performance. However, its FROC score was not as high,
The FracNet+ architecture integrates two specialized indicating possible calibration issues with the confidence of
branches: a point branch dedicated to rib segmentation and a its detection proposals. This suggests that solely optimizing
voxel branch for rib fracture segmentation. The point branch the segmentation network may not be the best strategy for the
isdesignedtoworkwithanypointcloudneuralnetworkasits detection track, considering the low IoU threshold of 0.2 for
backbone; in our implementation, we utilize PointNet++ [73] detectionproposals.Italsohighlightstheeffectivenessoffalse
to process inputs of 30,000 points. For the voxel branch, we positive reduction.YANGetal.DEEPRIBFRACTUREINSTANCESEGMENTATIONANDCLASSIFICATIONFROMCTONTHERIBFRACCHALLENGE 9
TABLEIII:A performance comparison of rib fracture detection task on the RibFrac test set.WereporttheFROCmetrics
(%), max sensitivity (%) and avg false positives for rib fracture detection, IoU (%) and Dice (%) for rib fracture segmentation.
The best metrics are highlighted in bold. The metric for ranking is highlighted in blue.
DetectionFROC(Sensitivities@FPlevels) DetectionAuxillaryMetrics Segmentation
Method
0.5↑ 1↑ 2↑ 4↑ 8↑ Avg↑ MaxSensitivity↑ AvgFP↓ IoU↑ Dice↑
ChallengeResults
lungseg2020(DT1) 75.06 79.74 84.34 87.06 88.72 82.98 89.80 17.73 44.04 61.15
DCC(DT2) 72.11 76.83 82.10 86.67 87.98 81.14 87.98 7.18 45.86 62.89
FakeDoctor(DT3) 56.74 75.01 80.69 84.36 84.81 76.32 84.81 5.84 47.32 64.24
UCIrvine(DT4) 67.30 73.08 76.30 77.10 77.66 74.29 77.66 5.02 36.52 53.50
MIDILab(DT5) 60.09 65.01 68.48 69.84 69.84 66.65 69.84 2.97 41.07 58.23
CCCCS(DT6) 53.29 61.19 67.57 72.25 76.00 66.06 80.61 29.10 23.15 37.60
Post-ChallengeResults
A1 78.92 83.98 85.13 88.44 90.94 85.48 92.91 12.11 42.57 59.71
A2 76.38 83.49 86.90 90.25 91.32 85.67 92.06 12.43 31.23 47.60
A3 69.77 80.68 84.58 84.81 84.81 80.93 84.81 2.37 52.68 69.01
(a) Scatter Plot of Confidence (x) vs. IoU(y). True Positive w/o Confidence Threshold. False Negative. False Positive. Include False Positive Exclude False Positive
(b) Confidence Histogram of True Positive w/o Confidence Threshold.
(c) Confidence Histogram of False Negative.
IoU IoU
(d) Confidence Histogram of False Positive.
Fig. 7: Statistics of segmentation performance. The box
plotsdisplaythedistributionofIoUofsegmentationincluding
lungseg2020 (DT1) DCC (DT2) FakeDoctor(DT3) UCIrvine(DT4) MIDILab(DT5) CCCCS (DT6) false positives (left) and excluding false positives (right).
Fig. 6: Statistics of detection confidence. The scatter plots
(a) illustrate the distribution of detection IoU (y-axis) of
eachpredictionanditscorrespondingconfidence(x-axis).The
histograms furtherdisplay the distribution ofconfidence score
of (b) true positive predictions without confidence threshold,
(c)falsenegativepredictions,and(d)falsepositivepredictions y
of each solution, respectively.
tiv
itis
n
e
S
Fig.8illustratesaperformancecomparisonbetweenthetop
solutions and human experts. In an independent human-only
observer study [36], a junior radiologist (R1) and a senior
radiologist (R2), both highly experienced in chest interpreta-
tion,independentlydetectedandsegmentedribfracturesinthe False Positives per Scan
RibFractestset.Thedetectionandsegmentationmetricswere
Fig.8:Performancecomparisonbetweentopsolutionsand
computedbasedonthegroundtruthlabels.Thehumanexperts
human experts. FROC curves of each solution are displayed
achievedadetectionfalsepositiverateof1.005perscanwitha
in dashed lines, and the performances of human experts are
sensitivityof79.1%(R1)and0.690perscanwithasensitivity
represented in triangles.
of 75.9% (R2). Despite the human experts having fewer false
positives per scan, their detection sensitivities were lower
compared to some of the top solutions. When considering
Interestingly,mostsolutionsdemonstratecalibratedconfidence
the given false positive levels, the top two solutions perform
values, where the confidence of TPs is generally high, while
comparably or even better than the human experts.
theconfidenceofbothFNsandFPsisgenerallylow.However,
DT3 deviates from this trend, as it shows high confidence
C. Discussion valuesforbothTPsandFPswithoutsignificantdiscrimination.
1) Analysis of Detection TP, FN and FP: To analyze the This precisely explains why this solution achieved high seg-
relationshipbetweenthedetectionresults(TP,FN,andFP),we mentation metrics but lower detection metrics. This analysis
present the scatter plot of confidence vs. IoU, the confidence further emphasizes the importance of reducing false positives.
histogram of TPs without a confidence threshold, and the 2) Analysis and Visualization of Segmentation: We con-
histograms of FNs and FPs for each solution in Fig. 6. ductedananalysisofthesegmentationperformanceusingbox10 INSUBMISSIONTOIEEETRANSACTIONSONMEDICALIMAGING,VOL.XX,NO.XX,XXXX2024
lungseg2020 (DT1) DCC (DT2) FakeDoctor(DT3) UCIrvine(DT4) MIDILab(DT5) CCCCS (DT6)
advancementsdemonstratethattheRibFracChallengeremains
elkcuB
IoU: 77.12 Conf: 0.91 IoU: 70.95 Conf: 0.83 IoU: 59.09 Conf: 0.89 IoU: 55.70 Conf: 0.83 IoU: 53.98 Conf: 0.66 IoU: 61.12 Conf: 0.54 active and contributes to the development of methodologies.
IoU: 47.51 Conf: 0.62 IoU: 25.57 Conf: 0.61 IoU: 0.00 Conf: 0.00 IoU: 0.00 Conf: 0.00 IoU: 65.18 Conf: 0.56 IoU: 18.56 Conf: 0.36 On the other hand, we have observed limited progress in
decalpsiD
IoU: 66.15 Conf: 0.99 IoU: 63.26 Conf: 0.99 IoU: 69.80 Conf: 0.85 IoU: 52.39 Conf: 0.86 IoU: 40.19 Conf: 0.71 IoU: 47.10 Conf: 0.55
rib fracture classification. This is partly due to the inherent
noN-
IoU: 17.08 Conf: 0.82 IoU: 26.87 Conf: 0.45 IoU: 52.05 Conf: 0.87 IoU: 53.36 Conf: 0.65 IoU: 0.00 Conf: 0.00 IoU: 22.51 Conf: 0.40
difficulty of rib fracture classification itself (as discussed in
decalpsiD
IoU: 82.12 Conf: 0.99 IoU: 83.00 Conf: 0.99 IoU: 81.61 Conf: 0.94 IoU: 81.03 Conf: 0.90 IoU: 75.06 Conf: 0.76 IoU: 75.00 Conf: 0.75
t mhe anca ena oly fs ti hs ein claS sse ic fi. caV tiI o-B n) t, raa cn kd inpa tr ht ely Rb ibec Fa ru acse Ct hh ae llep ne gr efo ir s-
IoU: 49.00 Conf: 0.84 IoU: 58.96 Conf: 0.73 IoU: 67.39 Conf: 0.89 IoU: 67.08 Conf: 0.79 IoU: 11.16 Conf: 0.39 IoU: 15.48 Conf: 0.54 heavily influenced by the detection performance, which can
latnem
IoU: 75.49 Conf: 0.98 IoU: 73.13 Conf: 0.99 IoU: 75.98 Conf: 0.94 IoU: 71.08 Conf: 0.88 IoU: 71.34 Conf: 0.76 IoU: 70.13 Conf: 0.73
be overlooked by participants. We plan to address this issue
geS to some extent in future versions of the RibFrac Challenge by
IoU: 71.69 Conf: 0.96 IoU: 73.94 Conf: 0.85 IoU: 70.37 Conf: 0.91 IoU: 60.31 Conf: 0.86 IoU: 0.00 Conf: 0.00 IoU: 13.66 Conf: 0.20
modifying the evaluation methods, with the aim of promoting
Fig. 9: Statistics and visualization of segmentation per-
overall performance in the rib fracture classification task.
formance for each category of rib fractures. We provide
a box plot showcasing the distribution of segmentation IoU
values (excluding detection FPs) for each solution, along with
E. InternalExperiments
visualizations of predictions for two representative cases. The
Inthissection,weevaluatedtheperformanceofourinternal
ground truths are highlighted in red, while the corresponding
methods, which include FracNet [36], FracNet+, and their
predictions are depicted in blue.
variants for ablation study. This evaluation also encompassed
models using only RibSeg, through either naive integration
or point-voxel fusion, as well as models using only STUNet,
plots, as shown in Fig. 7. The plots depict the distribution
whether with random initialization or pretrained on TotalSeg-
of IoU values for segmentation, with two variations—one
mentator.Itiscrucialtohighlightthatallourinternalmethods
including false positives (FPs) and the other excluding FPs.
are one-stage approaches that leverage a neural network for
In the box plot that includes FPs, the segmentation predic-
segmentationanddeterminethedetectionproposalconfidence
tions of DT1 and DT6 exhibit low IoU values, indicating a
by calculating the average confidence across the segmented
significantpresenceoffalsepositivesintheirpredictions.This
regions. Besides, the RibFrac Challenge test set includes 40
observation is consistent with the average FP metric reported
additional cases beyond the dataset utilized in [36]. This
in Tab. III. However, in the plot without FPs, the winning
discrepancy accounts for the different metrics reported when
solution achieves high segmentation metrics. This suggests
compared to the original publication [36].
thattheteamprioritizedmaximizingsensitivity,whichresulted
The results in Tab. IV indicate that while FracNet sig-
in an increased number of FPs. Nevertheless, they were able
nificantly outperforms 3D FCN [75] and 3D DeepLab [76],
to effectively suppress the confidence of these false positives
FracNet+,anexpansionofFracNet,demonstratesevengreater
through FPR, leading to a favorable FROC metric in the
effectiveness. This is evident whether through the integration
ranking, despite seemingly weaker segmentation metrics that
of RibSeg or the use of the large-scale pretrained STUNet,
were not for ranking.
both of which notably surpass the original FracNet. Naive
Furthermore,inFig.9,wepresentaboxplotillustratingthe
integration of rib outputs in pre- and post-processing, as seen
distribution of segmentation IoU (disregarding detection FPs)
in FracNet w/ RibSeg (Naive) vs. FracNet, also improves
for each category of rib fractures, along with visualizations of
model performance, especially in reducing false positives,
predictions for two cases in each category. For each visual-
though it does not improve sensitivity. However, employing
ization, we selected slices at fixed intervals around the center
a point-voxel feature fusion to enhance rib features—FracNet
andannotatedthegroundtruthsegmentationsinred,whilethe
w/ RibSeg (Fusion) vs. FracNet w/ RibSeg (Naive)—further
predictions are represented in blue. The analysis reveals vary-
boosts network performance, with a significant increase in
inglevelsofdifficultyinsegmentingdifferentcategoriesofrib
sensitivity at low false positive levels and an overall rise in
fractures.Forexample,theoverallsegmentationIoUofbuckle
the highest sensitivity achieved. On the other hand, substi-
fracturesislowercomparedtothatofnon-displacedfractures.
tuting the voxel network with STUNet, even without using
Contrary to the poor performance indicated in Tab. III, the
pretrained weights, shows a slight performance increase, as
winningsolutiondemonstratessatisfactorysegmentationvisu-
seen in FracNet w/ STUNet (Random) vs. FracNet. Intro-
alization results when false positives are disregarded.
ducing pretrained weights—FracNet w/ STUNet (Pretrained)
vs. FracNet w/ STUNet (Random)—further improves overall
D. Post-ChallengeResults
performance.However,itisobservedthatmerelychangingthe
As an ongoing online benchmark, the RibFrac Challenge networkstructureorincorporatingpretrainingdoesnothaveas
has received numerous post-challenge submissions, some of marked an effect as integrating RibSeg, as shown in FracNet
which are on par with the top solutions during the official w/ STUNet (Pretrained) vs. FracNet w/ RibSeg (Fusion),
challenge period. As participant information is no longer which highlights the usefulness of domain knowledge. Their
required after the official challenge, we anonymized these effects seem to be complementary: while the former may
submissionsasA1,A2,andA3.Amongthem,theA1method further increase sensitivity, it does not significantly reduce
achieves better sensitivity levels at low FP level (FP=0.5), false positives. Finally, FracNet+, which is essentially Frac-
while A2 performs better at moderate FP level (FP=4). These Net w/ RibSeg (Fusion) w/ STUNet (Pretrained), combinesYANGetal.DEEPRIBFRACTUREINSTANCESEGMENTATIONANDCLASSIFICATIONFROMCTONTHERIBFRACCHALLENGE 11
TABLE IV: Internal rib fracture detection methods on the RibFrac test set. We report the FROC metrics (%), max
sensitivity (%) and avg false positives for rib fracture detection, IoU (%) and Dice (%) for rib fracture segmentation. The best
metrics are highlighted in bold.
DetectionFROC(Sensitivities@FPlevels) DetectionAuxillaryMetrics Segmentation
Method
0.5↑ 1↑ 2↑ 4↑ 8↑ Avg↑ MaxSensitivity↑ AvgFP↓ IoU↑ Dice↑
InternalBaselines
3DFCN[75] 59.58 69.10 76.03 82.71 85.18 74.52 85.18 7.96 40.37 58.49
3DDeepLab[76] 63.38 71.90 79.13 86.51 88.68 77.92 88.68 7.05 41.57 60.99
FracNet[36] 65.68 74.40 81.63 88.81 90.28 80.16 90.28 6.21 46.87 63.79
ExtendingFracNettoFracNet+
FracNetw/RibSeg(Naive)[37],[38] 69.90 75.96 82.52 89.50 90.58 81.69 89.65 4.91 48.69 65.77
FracNetw/RibSeg(Fusion)[37],[38] 73.56 78.22 83.86 89.92 90.77 83.27 91.29 4.34 49.59 66.81
FracNetw/STUNet(Random)[39] 66.20 75.04 82.40 89.46 90.94 80.81 90.83 5.89 47.15 64.10
FracNetw/STUNet(Pretrained)[39] 67.42 76.05 83.17 90.14 91.17 81.59 91.76 5.32 47.72 64.72
FracNet+ 75.67 79.22 84.32 90.82 91.43 84.29 92.17 4.22 50.02 67.22
ComparingwithHumanExperts
R1 - - - - - - 79.12 1.22 46.62 63.55
R2 - - - - - - 75.87 0.86 35.93 52.32
the advantages of both modifications and achieves the best traininglossforallteams,withtwoteamsalsoemployingDice
performance. loss as an additional loss function. To enhance classification
It is noteworthy that FracNet+ achieves higher sensitivity performance, some teams employ special techniques such as
and finer segmentation compared to two human radiologists dilated convolution [79], auto-context mechanism [80], and
(R1, R2). Even though FracNet+ may yield more false pos- class-weighted loss. More method details for each team can
itives than human experts, human radiologists can easily be found here [74].
pinpoint lesions with fewer false positives, thereby enhancing
the sensitivity of their diagnoses [36].
B. ChallengeResults
Additionally,thoughDT1andDT2surpasstheperformance
of our earlier internal version FracNet, with the incorporation The results of rib fracture classification are presented in
ofrecentadvancements,FracNet+demonstratessuperioreffec- Tab. VI. We provide the prediction-aware F1 score, target-
tiveness. Even when compared to post-challenge results (A1 aware F1 score, and overall F1 score for each rib frac-
and A2), FracNet+, as a one-stage method, holds its ground ture category, as well as their macro-average. It should be
in many metrics, particularly in segmentation accuracy and noted that the prediction-aware, target-aware, and overall F1
false positive rates. Considering the potential use of challenge scores may not be consistent across the solutions, as these
tricks, such as multi-stage models (including false positive three classification metrics are biased towards the detection
reduction) and ensemble techniques, there is room for further performance. However, since the labels of the test set are
improvement in FracNet+. However, a direct comparison may completely hidden, the classification track emphasizes the
not be entirely fair due to our later development timeline and evaluation of end-to-end systems. The macro-average overall
completeaccesstothedataastheauthors.Therefore,wehave F1 score across the four categories is used for ranking.
refrained from employing too many challenge tricks and have Upon examining all the solutions, it is observed that the
chosen to present our internal results and challenge results in DP and ND fracture types are relatively easy to distinguish,
separate tables to maintain clarity and fairness. while the BK type is slightly more challenging. However,
Nevertheless, our analysis indicates that while simply re- the SG type shows very poor discriminative performance.
placing the network may yield improvements, it does not Overall,althoughthesesolutionsoutperformrandomguessing,
achievetheintegrationwithribsegmentation.Thisfindingun- unfortunately,theyarestillfarfrombeingclinicallyapplicable.
derscores the beneficial role of rib segmentation in enhancing In the following sections, we will analyze why the task of rib
fracture detection. fracture classification is so challenging.
VI. RIB FRACTURE CLASSIFICATION TRACK C. Discussion:WhytheFractureClassificationisHard
A. ChallengeSolutions
1) Diagnostic Challenges and Class Imbalance: The di-
Tab. V provides a summary of the top solutions in the agnostic approaches for these four types of fractures vary
classification track. All of the top solutions employ 3D neural significantly.Non-displacedfractures(ND)anddisplacedfrac-
networkswithoutpretraining,exceptforoneteamthatutilizes tures (DP) both involve complete fractures, with the distinc-
a 3D ResNet-50 [42] pretrained on Med3D [78]. The input tion being the presence or absence of bone displacement
resolutions vary from 64×64×64 to 128×128×64. While or misalignment. As a result, these two types of fractures
the top two solutions employ random rotation and flip for are relatively conspicuous and can be diagnosed based on
data augmentation, the remaining solutions do not utilize any their geometric positions. The results indeed indicate a higher
data augmentation methods. Cross-entropy loss is used as the diagnostic performance for ND and DP fractures. On the12 INSUBMISSIONTOIEEETRANSACTIONSONMEDICALIMAGING,VOL.XX,NO.XX,XXXX2024
TABLEV: Solution summary in the rib fracture classification track. Each of the solutions is summarized in the following
aspects: the type of neural network (2.5D / 3D), pretraining, backbone, input resolution, data augmentation methods, training
loss, and special remarks.
Team 2.5D/3D Pretraining Backbone InputResolution DataAugmentation Loss Remarks
UCIrvine Randomflip,rotation, Cross-entropy, Segmentationbefore
3D No NoduleNet[77] 64×64×64
(CT1) scalingandtransition Dice classification
Dilated
DCC Randomrotationand
3D Med3D[78] ResNet50[42] 96×96×24 Cross-entropy convolutions[79],auto
(CT2) flip
context[80]
DeepBlueAI Cross-entropy, Segmentationbefore
3D No CustomCNN 64×64×64 None
(CT3) Dice classification,SE[81]
CCCCS
3D No ResNet18[42] 128×128×64 None Cross-entropy Class-weightedloss
(CT4)
TABLEVI:AperformancecomparisonofribfractureclassificationtaskontheRibFractestset.Wereporttheprediction-
aware F1 score, target-aware F1 score and overall F1 score for each category, as well as their macro-average. The best metrics
are highlighted in bold. The metric for ranking is highlighted in blue.
Prediction-AwareF1Score Target-AwareF1Score OverallF1Score
Method
BK↑ DP↑ ND↑ SG↑ Avg↑ BK↑ DP↑ ND↑ SG↑ Avg↑ BK↑ DP↑ ND↑ SG↑ Avg↑
UCIrvine 0.3514 0.5503 0.5324 0.0833 0.3793 0.2114 0.5041 0.4744 0.0714 0.3153 0.2063 0.4844 0.4554 0.0690 0.3038
DCC 0.3478 0.4869 0.5249 0.0784 0.3595 0.2697 0.4693 0.4969 0.0741 0.3275 0.1791 0.3790 0.3980 0.0678 0.2560
DeepBlueAI 0.2500 0.6839 0.6099 0.2500 0.4485 0.0597 0.5550 0.4433 0.0976 0.2889 0.0377 0.4309 0.3857 0.0784 0.2332
CCCCS 0.0000 0.4356 0.7424 0.0690 0.3117 0.0000 0.3929 0.7143 0.0625 0.2924 0.0000 0.2619 0.5782 0.0625 0.2257
Volumetric Size Depth (Axial)
y
tisn
e
D
Height (Coronal) Width (Sagittal)
y
Fig. 10: Examples of rib fracture instances. Each sample
tisn
e
D
is center-cropped into a 64×64×64 volume.
Fig. 11: Statistics of sizes for each rib fracture category.
otherhand,bucklefractures(BK)areincompletefracturesthat
The histograms display the distribution of the volumetric size
typicallymanifestasbulgesintherib.Thismakesthemeasily
(top left), depth (top right), height (bottom left), and width
missedinradiologyexaminations,leadingtoahigherdifficulty
(bottomright)ofeachindividualribfractureineachcategory.
in diagnosis and an increased number of false negatives in
detection. The results demonstrate a significant improvement
in the numerical value of the prediction-aware F1 score for
2) Geometric Complexity: Rib fracture classification also
BK fractures compared to the target-aware and overall F1
faces the challenge of geometric complexity. Fig. 10 show-
scores, as false negatives are excluded from the prediction-
cases several instances of rib fractures, where each sample
aware calculation. Segmental fractures (SG), in contrast, are
is center-cropped into a 64 × 64 × 64 volume. It can be
definedassevereinjuriescharacterizedbyatleasttwoseparate
observed that these 3D patches exhibit significant variations
complete fractures in the same rib. Diagnosing SG fractures
in orientation, shape, and appearance, posing a significant
solely based on local information is not feasible. However,
challenge for CNNs, which are sensitive to rotation. Despite
all the methods in the challenge utilized local patches, which
the ideal assessment of rib fractures based on individual
resulted in poor discriminative performance for the SG.
ribs, these 3D patches unavoidably contain multiple ribs,
Moreover, due to the RibFrac dataset being collected from
introducing additional background noise.
realclinicalscenarios,thereisanimbalanceinthedistribution
Furthermore, the sizes of the four fracture categories vary
of fracture categories (as shown in Table I). This further adds
greatly. Fig. 11 illustrates the distribution of volumetric size,
to the difficulty of machine learning tasks.
depth, height, and width for each rib fracture category. TheseYANGetal.DEEPRIBFRACTUREINSTANCESEGMENTATIONANDCLASSIFICATIONFROMCTONTHERIBFRACCHALLENGE 13
categories exhibit considerable size variation, and there is [5] B.S.Talbot,C.P.GangeJr,A.Chaturvedi,N.Klionsky,S.K.Hobbs,
significant overlap between them, further complicating the and A. Chaturvedi, “Traumatic rib injury: patterns, imaging pitfalls,
complications,andtreatment,”Radiographics,vol.37,no.2,pp.628–
classification task.
651,2017.
[6] J.Peek,Y.Ochen,N.Saillant,R.H.Groenwold,L.P.Leenen,T.Uribe-
Leitz,R.M.Houwert,andM.Heng,“Traumaticribfractures:amarker
VII. CONCLUSION ofsevereinjury.anationwidestudyusingthenationaltraumadatabank,”
TraumaSurgery&AcuteCareOpen,vol.5,no.1,p.e000441,2020.
In conclusion, the RibFrac Challenge has served as a
[7] M.Kolopp,N.Douis,A.Urbaneja,C.Baumann,P.A.GondimTeixeira,
valuable benchmark and research resource for AI-assisted rib A. Blum, and L. Martrille, “Automatic rib unfolding in postmortem
fracture detection and diagnosis. With its extensive dataset computed tomography: diagnostic evaluation of the openrib software
compared with the autopsy in the detection of rib fractures,” Interna-
and evaluation platform, the challenge has addressed previous
tionalJournalofLegalMedicine,vol.134,pp.339–346,2020.
limitations and facilitated significant progress in rib fracture [8] L.Jin,X.Ge,F.Lu,Y.Sun,C.Li,P.Gao,F.Gao,andM.Li,“Low-
detection. Promising results have been achieved, showing dosectexaminationforribfractureevaluation:Apilotstudy,”Medicine,
vol.97,no.30,2018.
that AI can enhance accuracy and reduce interpretation time.
[9] N. Banaste, B. Caurier, F. Bratan, J.-F. Bergerot, V. Thomson, and
However, there is still room for improvement in rib fracture I. Millet, “Whole-body ct in patients with multiple traumas: factors
classification solutions. The challenge has paved the way for leadingtomissedinjury,”Radiology,vol.289,no.2,pp.374–383,2018.
[10] H. Ringl, M. Lazar, M. To¨pker, R. Woitek, H. Prosch, U. Asenbaum,
futureresearchandintegrationofAItoolsintoradiologywork-
C. Balassy, D. Toth, M. Weber, S. Hajdu et al., “The ribs unfolded-
flows.Overall,theRibFracChallengehasplayedacrucialrole a ct visualization algorithm for fast detection of rib fractures: effect
inadvancingthefieldandwillcontinuetodriveimprovements on sensitivity and specificity in trauma patients,” European radiology,
vol.25,pp.1865–1874,2015.
in rib fracture analysis.
[11] A.Blum,R.Gillet,A.Urbaneja,andP.G.Teixeira,“Automaticdetection
As an independent technical contribution, we develop a ofribfractures:Arewethereyet?”eBioMedicine,vol.63,2021.
strong internal method FracNet+. We integrate several post- [12] A. Pinto, A. Reginelli, F. Pinto, G. Lo Re, F. Midiri, C. Muzj, L. Ro-
mano, and L. Brunese, “Errors in imaging patients in the emergency
challengeadvancements,includingthedevelopmentofapoint-
setting,”TheBritishjournalofradiology,vol.89,no.1061,p.20150914,
based rib segmentation technique and the emergence of large- 2016.
scale pre-trained networks for 3D medical imaging, yielding [13] P.Dankerl,H.Seuss,S.Ellmann,A.Cavallaro,M.Uder,andM.Ham-
mon,“Evaluationofribfracturesonasingle-in-planeimagereformation
competitive results in rib fracture detection and highlighting
oftheribcageinctexaminations,”AcademicRadiology,vol.24,no.2,
the importance of rib segmentation in this field. pp.153–159,2017.
Future research directions should concentrate on several [14] S. Cho, Y. Sung, and M. Kim, “Missed rib fractures on evaluation of
initialchestctfortraumapatients:patternanalysisanddiagnosticvalue
areas. A primary goal is to develop unified approaches
ofcoronalmultiplanarreconstructionimageswithmultidetectorrowct,”
that seamlessly integrate rib labeling, anatomical centerline TheBritishjournalofradiology,vol.85,no.1018,pp.e845–e850,2012.
extraction, and fracture diagnosis. Moreover, enhancing the [15] A.A.A.Setio,A.Traverso,T.DeBel,M.S.Berens,C.VanDenBo-
classification performance of different types of rib fractures is gaard, P. Cerello, H. Chen, Q. Dou, M. E. Fantacci, B. Geurts et al.,
“Validation, comparison, and combination of algorithms for automatic
crucial.Despiteadvancementsinfracturedetection,accurately
detection of pulmonary nodules in computed tomography images: the
classifying various fracture types remains a complex chal- luna16challenge,”MedicalImageAnalysis,vol.42,pp.1–13,2017.
lenge.Insightsgainedfromthisstudyoftechnicalhurdlesand [16] S. M. McKinney, M. Sieniek, V. Godbole, J. Godwin, N. Antropova,
H. Ashrafian, T. Back, M. Chesus, G. S. Corrado, A. Darzi et al.,
existingmethodologieswillbeinvaluableforfutureendeavors
“International evaluation of an ai system for breast cancer screening,”
in this aspect of rib fracture classification. Additionally, the Nature,vol.577,no.7788,pp.89–94,2020.
development and validation of these models on multi-center [17] J.Yang,Y.He,X.Huang,J.Xu,X.Ye,G.Tao,andB.Ni,“Alignshift:
bridging the gap of imaging thickness in 3d anisotropic volumes,”
dataareofhighimportance.Addressingthesefuturedirections
in Conference on Medical Image Computing and Computer Assisted
will not only expedite faster and more precise diagnoses but Intervention. Springer,2020,pp.562–572.
also enhance patient outcomes by enabling clinicians to make [18] J.Yang,Y.He,K.Kuang,Z.Lin,H.Pfister,andB.Ni,“Asymmetric3d
contextfusionforuniversallesiondetection,”inConferenceonMedical
well-informed treatment decisions based on the severity and
ImageComputingandComputerAssistedIntervention. Springer,2021,
specific type of rib fractures. Continued collaboration, dataset pp.571–580.
expansion,andadvancementsindeeplearningtechniqueswill [19] R.Xu,Y.Luo,B.Du,K.Kuang,andJ.Yang,“Lssanet:Alongshort
slice-aware network for pulmonary nodule detection,” in Conference
play vital roles in driving progress in rib fracture analysis and
on Medical Image Computing and Computer Assisted Intervention.
bringing us closer to clinically applicable solutions. Springer,2022,pp.664–674.
[20] P. A. Keane and E. J. Topol, “With an eye to ai and autonomous
diagnosis,”NPJDigitalMedicine,vol.1,no.1,p.40,2018.
REFERENCES [21] W. Zhao, J. Yang, Y. Sun, C. Li, W. Wu, L. Jin, Z. Yang, B. Ni,
P.Gao,P.Wangetal.,“3ddeeplearningfromctscanspredictstumor
[1] I.BaiuandD.Spain,“Ribfractures,”Jama,vol.321,no.18,pp.1836– invasiveness of subcentimeter pulmonary adenocarcinomas,” Cancer
1836,2019. research,vol.78,no.24,pp.6881–6889,2018.
[2] J. Peek, R. B. Beks, F. Hietbrink, M. B. De Jong, M. Heng, F. J. [22] J.Yang,R.Fang,B.Ni,Y.Li,Y.Xu,andL.Li,“Probabilisticradiomics:
Beeres,F.F.IJpma,L.P.Leenen,R.H.Groenwold,andR.M.Houwert, ambiguous diagnosis with controllable shape analysis,” in Conference
“Epidemiologyandoutcomeofribfractures:anationwidestudyinthe on Medical Image Computing and Computer Assisted Intervention.
netherlands,” European journal of trauma and emergency surgery, pp. Springer,2019,pp.658–666.
1–7,2020. [23] K. Zhang, X. Liu, J. Shen, Z. Li, Y. Sang, X. Wu, Y. Zha, W. Liang,
[3] K. Kuo and A. M. Kim, “Rib fracture,” in StatPearls [Internet]. C.Wang,K.Wangetal.,“Clinicallyapplicableaisystemforaccurate
StatPearlsPublishing,2021. diagnosis,quantitativemeasurements,andprognosisofcovid-19pneu-
[4] H. M. Ingoe, W. Eardley, C. McDaid, A. Rangan, T. Lawrence, and monia using computed tomography,” Cell, vol. 181, no. 6, pp. 1423–
C. Hewitt, “Epidemiology of adult rib fracture and factors associated 1433,2020.
with surgical fixation: Analysis of a chest wall injury dataset from [24] J. Yang, M. Gao, K. Kuang, B. Ni, Y. She, D. Xie, and C. Chen,
englandandwales,”Injury,vol.51,no.2,pp.218–223,2020. “Hierarchical classification of pulmonary lesions: a large-scale radio-14 INSUBMISSIONTOIEEETRANSACTIONSONMEDICALIMAGING,VOL.XX,NO.XX,XXXX2024
pathomics study,” in Conference on Medical Image Computing and [43] L.Yao,X.Guan,X.Song,Y.Tan,C.Wang,C.Jin,M.Chen,H.Wang,
ComputerAssistedIntervention. Springer,2020,pp.497–507. andM.Zhang,“Ribfracturedetectionsystembasedondeeplearning,”
[25] Y. Ding, J. Zhang, W. Zhuang, Z. Gao, K. Kuang, D. Tian, C. Deng, ScientificReports,vol.11,no.1,p.23513,2021.
H.Wu,R.Chen,G.Luetal.,“Improvingtheefficiencyofidentifying [44] K. Duan, S. Bai, L. Xie, H. Qi, Q. Huang, and Q. Tian, “Centernet:
malignant pulmonary nodules before surgery via a combination of Keypoint triplets for object detection,” International Conference on
artificial intelligence ct image recognition and serum autoantibodies,” ComputerVision,pp.6568–6577,2019.
EuropeanRadiology,pp.1–11,2022. [45] F. Yu, D. Wang, and T. Darrell, “Deep layer aggregation,” Conference
[26] W. L. Bi, A. Hosny, M. B. Schabath, M. L. Giger, N. J. Birkbak, onComputerVisionandPatternRecognition,pp.2403–2412,2017.
A. Mehrtash, T. Allison, O. Arnaout, C. Abbosh, I. F. Dunn et al., [46] C. Yang, J. Wang, J. Xu, C. Huang, F. Liu, W. Sun, R. Hong, L. L.
“Artificialintelligenceincancerimaging:clinicalchallengesandappli- Zhang, D. Ma, Z. Li, X. Zhang, J. Cai, and Z. Fu, “Development and
cations,”CA:acancerjournalforclinicians,vol.69,no.2,pp.127–157, assessmentofdeeplearningsystemforthelocationandclassificationof
2019. ribfracturesviacomputedtomography.”Europeanjournalofradiology,
[27] J.Yang,J.Chen,K.Kuang,T.Lin,J.He,andB.Ni,“Mia-prognosis:a vol.154,p.110434,2022.
deep learning framework to predict therapy response,” in Conference [47] B. Zhang, C. Jia, R. Wu, B. Lv, B. Li, F. Li, G. Du, Z. Sun, and
on Medical Image Computing and Computer Assisted Intervention. X.Li,“Improvingribfracturedetectionaccuracyandreadingefficiency
Springer,2020,pp.211–220. withdeeplearning-baseddetectionsoftware:aclinicalevaluation.”The
[28] Y. Yang, J. Yang, L. Shen, J. Chen, L. Xia, B. Ni, L. Ge, Y. Wang, Britishjournalofradiology,p.20200870,2020.
and S. Lu, “A multi-omics-based serial deep learning approach to [48] X.Liu,D.Wu,H.Xie,Y.Xu,L.Liu,X.Tao,andX.Wang,“Clinical
predictclinicaloutcomesofsingle-agentanti-pd-1/pd-l1immunotherapy evaluation of ai software for rib fracture detection and its impact on
in advanced stage non-small-cell lung cancer,” American journal of junior radiologist performance,” Acta Radiologica, vol. 63, no. 11, pp.
translationalresearch,vol.13,no.2,p.743,2021. 1535–1545,2022.
[29] M. Thies and M. L. Oelze, “Combined therapy planning, real-time [49] X. Meng, D. J. Wu, Z. Wang, X. L. Ma, X. M. Dong, A. Liu, and
monitoring, and low intensity focused ultrasound treatment using a L. Chen, “A fully automated rib fracture detection system on chest ct
diagnostic imaging array,” IEEE Transactions on Medical Imaging, imagesanditsimpactonradiologistperformance,”SkeletalRadiology,
vol.41,no.6,pp.1410–1419,2022. vol.50,pp.1821–1828,2021.
[30] J. Deng, J. Yang, L. Hou, J. Wu, Y. He, M. Zhao, B. Ni, D. Wei,
[50] M. Kaiume, S. Suzuki, K. Yasaka, H. Sugawara, Y. Shen, Y. Katada,
H.Pfister,C.Zhouetal.,“Genopathomicprofilingidentifiessignatures
T. Ishikawa, R. Fukui, and O. Abe, “Rib fracture detection in com-
for immunotherapy response of lung adenocarcinoma via confounder-
puted tomography images using deep convolutional neural networks,”
aware representation learning,” iScience, vol. 25, no. 11, p. 105382,
Medicine,vol.100,2021.
2022.
[51] A.Niiya,K.Murakami,R.Kobayashi,A.Sekimoto,M.Saeki,K.Toy-
[31] E. J. Topol, “High-performance medicine: the convergence of human
ofuku, M. Kato, H. Shinjo, Y. Ito, M. Takei et al., “Development
and artificial intelligence,” Nature medicine, vol. 25, no. 1, pp. 44–56,
of an artificial intelligence-assisted computed tomography diagnosis
2019.
technology for rib fracture and evaluation of its clinical usefulness,”
[32] A.Urbaneja,J.DeVerbizier,A.-S.Formery,C.Tobon-Gomez,L.Nace,
ScientificReports,vol.12,no.1,p.8363,2022.
A. Blum, and P. A. G. Teixeira, “Automatic rib cage dding with ct
[52] A. Mansoor, U. Bagci, Z. Xu, B. Foster, K. N. Olivier, J. M. Elinoff,
cylindricalprojectionreformatinpolytraumatizedpatientsforribfrac-
A.F.Suffredini,J.K.Udupa,andD.J.Mollura,“Agenericapproach
turedetectionandcharacterization:feasibilityandclinicalapplication,”
to pathological lung segmentation,” IEEE Transactions on Medical
EuropeanJournalofRadiology,vol.110,pp.121–127,2019.
Imaging,vol.33,pp.2293–2310,2014.
[33] A. Blum, R. Gillet, A. Rauch, A. Urbaneja, H. Biouichi, G. Dodin,
[53] A. A. Fokin, J. Wycech, M. Crawford, and I. Puente, “Quantification
E.Germain,C.Lombard,P.Jaquet,M.Louisetal.,“3dreconstructions,
of rib fractures by different scoring systems.” The Journal of surgical
4d imaging and postprocessing with ct in musculoskeletal disorders:
research,vol.229,pp.1–8,2018.
past, present and future,” Diagnostic and interventional imaging, vol.
[54] H. Wang, J. Bai, and Y. Zhang, “A relative thoracic cage coordinate
101,no.11,pp.693–705,2020.
systemforlocalizingthethoracicorgansinchestctvolumedata,”IEEE
[34] T. Weikert, L. A. Noordtzij, J. Bremerich, B. Stieltjes, V. Parmar,
Engineering in Medicine and Biology Annual Conference, pp. 3257–
J.Cyriac,G.Sommer,andA.W.Sauter,“Assessmentofadeeplearning
3260,2005.
algorithm for the detection of rib fractures on whole-body trauma
[55] H.ShenandM.Shao,“Athoraciccagecoordinatesystemforrecording
computed tomography,” Korean journal of radiology, vol. 21, no. 7,
pathologies in lung ct volume data,” 2003 IEEE Nuclear Science
p.891,2020.
Symposium,vol.5,pp.3029–3031Vol.5,2003.
[35] Q.-Q.Zhou,J.Wang,W.Tang,Z.-C.Hu,Z.-Y.Xia,X.-S.Li,R.Zhang,
X.Yin,B.Zhang,andH.Zhang,“Automaticdetectionandclassification [56] G.Bier,C.Schabel,A.E.Othman,M.N.Bongers,J.Schmehl,H.Ditt,
of rib fractures on thoracic ct using convolutional neural network: K.Nikolaou,F.Bamberg,andM.Notohamiprodjo,“Enhancedreading
accuracyandfeasibility,”Koreanjournalofradiology,vol.21,no.7,p. timeefficiencybyuseofautomaticallyunfoldedctribreformationsin
869,2020.
acutetrauma.”Europeanjournalofradiology,vol.8411,pp.2173–80,
[36] L.Jin,J.Yang,K.Kuang,B.Ni,Y.Gao,Y.Sun,P.Gao,W.Ma,M.Tan, 2015.
H. Kang, J. Chen, and M. Li, “Deep-learning-assisted detection and [57] L. I. Abe, Y. Iwao, T. Gotoh, S. Kagei, R. Y. Takimoto, M. S. G.
segmentationofribfracturesfromctscans:Developmentandvalidation Tsuzuki,andT.Iwasawa,“High-speedpointcloudmatchingalgorithm
offracnet,”eBioMedicine,vol.62,2020. for medical volume images using 3d voronoi diagram,” International
[37] J.Yang,S.Gu,D.Wei,H.Pfister,andB.Ni,“Ribsegdatasetandstrong Conference on Biomedical Engineering and Informatics, pp. 205–210,
pointcloudbaselinesforribsegmentationfromctscans,”inConference 2014.
on Medical Image Computing and Computer Assisted Intervention. [58] W. Wang, H. Feng, Q. Bu, L. Cui, Y. Xie, A. Zhang, J. Feng,
Springer,2021,pp.611–621. Z. Zhu, and Z. Chen, “Mdu-net: A convolutional network for clavicle
[38] L.Jin,S.Gu,D.Wei,K.Kuang,H.Pfister,B.Ni,J.Yang,andM.Li, and rib segmentation from a chest radiograph,” Journal of Healthcare
“Ribseg v2: A large-scale benchmark for rib labeling and anatomical Engineering,vol.2020,2020.
centerlineextraction,”arXivPreprint,vol.abs/2210.09309,2022. [59] H. Guo, J. Zhang, K. Yan, L. Lu, and M. Xu, “Med-query: Steerable
[39] Z. Huang, H. Wang, Z. Deng, J. Ye, Y. Su, H. Sun, J. He, Y. Gu, parsing of 9-dof medical anatomies with query embedding,” arXiv
L.Gu,S.Zhangetal.,“Stu-net:Scalableandtransferablemedicalimage Preprint,vol.abs/2212.02014,2022.
segmentationmodelsempoweredbylarge-scalesupervisedpre-training,” [60] E. Schnider, J. Wolleb, A. Huck, M. Toranelli, G. Rauter, M. Mu¨ller-
arXivPreprint,2023. Gerbl, and P. C. Cattin, “Improved distinct bone segmentation in
[40] Z. Zhou, Z. Fu, J. Jia, and J. Lv, “Rib fracture detection with dual- upper-body ct through multi-resolution networks,” arXiv Preprint, vol.
attention enhanced u-net,” Computational and Mathematical Methods abs/2301.13674,2023.
inMedicine,vol.2022,2022. [61] D.Wu,D.Liu,Z.Puskas,C.Lu,A.Wimmer,C.Tietjen,G.Soza,and
[41] G. Huang, Z. Liu, and K. Q. Weinberger, “Densely connected con- S. K. Zhou, “A learning based deformable template matching method
volutional networks,” Conference on Computer Vision and Pattern for automatic rib centerline extraction and labeling in ct images,” in
Recognition,pp.2261–2269,2017. ConferenceonComputerVisionandPatternRecognition. IEEE,2012,
[42] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for pp.980–987.
image recognition,” in Conference on Computer Vision and Pattern [62] M.Lenga,T.Klinder,C.Bu¨rger,J.vonBerg,A.Franz,andC.Lorenz,
Recognition,2016,pp.770–778. “Deep learning based rib centerline extraction and labeling,” in MIC-YANGetal.DEEPRIBFRACTUREINSTANCESEGMENTATIONANDCLASSIFICATIONFROMCTONTHERIBFRACCHALLENGE 15
CAI International Workshop on Computational Methods and Clinical [87] C.H.Sudre,W.Li,T.Vercauteren,S.Ourselin,andM.JorgeCardoso,
ApplicationsinMusculoskeletalImaging. Springer,2018,pp.99–113. “Generalised dice overlap as a deep learning loss function for highly
[63] J. Yang, X. Huang, J. Chen, D. Wei, B. Ni, L. Jin, and M. Li, “Rib unbalancedsegmentations,”inDeepLearninginMedicalImageAnalysis
Fracture Detection and Classification Challenge,” Mar. 2020. [Online]. and Multimodal Learning for Clinical Decision Support. Springer,
Available:https://doi.org/10.5281/zenodo.3715934 2017,pp.240–248.
[64] F.Isensee,P.F.Jaeger,S.A.A.Kohl,J.Petersen,andK.H.Maier-Hein, [88] S.S.M.Salehi,D.Erdogmus,andA.Gholipour,“Tverskylossfunction
“nnu-net:aself-configuringmethodfordeeplearning-basedbiomedical forimagesegmentationusing3dfullyconvolutionaldeepnetworks,”in
imagesegmentation,”NatureMethods,vol.18,pp.203–211,2021. MachineLearninginMedicalImaging,Q.Wang,Y.Shi,H.-I.Suk,and
[65] H. Kaiming, G. Georgia, D. Piotr, and G. Ross, “Mask r-cnn,” IEEE K.Suzuki,Eds.,2017,pp.379–387.
TransactionsonPatternAnalysisandMachineIntelligence,vol.PP,pp. [89] K.Kamnitsas,C.Ledig,V.F.J.Newcombe,J.P.Simpson,A.D.Kane,
1–1,2017. D. K. Menon, D. Rueckert, and B. Glocker, “Efficient multi-scale 3d
[66] K.Sun,B.Xiao,D.Liu,andJ.Wang,“Deephigh-resolutionrepresen- cnn with fully connected crf for accurate brain lesion segmentation,”
tationlearningforhumanposeestimation,”inConferenceonComputer MedicalImageAnalysis,vol.36,p.61–78,2017.
VisionandPatternRecognition,2020.
[67] F. I. Diakogiannis, F. Waldner, P. Caccetta, and C. Wu, “Resunet-a: A
APPENDIX
deeplearningframeworkforsemanticsegmentationofremotelysensed A. SummaryofRibFractureDetectionSolutions
data,”ISPRSJournalofPhotogrammetryandRemoteSensing,vol.162,
pp.94–114,2020. 1) Team lungseg2020 (DT1): Mask-RCNN [65] with FPN
[68] O.Ronneberger,P.Fischer,andT.Brox,“U-net:Convolutionalnetworks [82] and ResNet-50 [42] backbone is extended from 2D to
for biomedical image segmentation,” in Conference on Medical Image
2.5D for rib fracture detection and segmentation. Since it is a
ComputingandComputerAssistedIntervention,2015,pp.234–241.
[69] Z. Liu, H. Tang, Y. Lin, and S. Han, “Point-voxel cnn for efficient 3d 2.5D method, the 3D CT scans are split into slices, resulting
deeplearning,”vol.32,2019. in 44,000 positive samples and 11,000 negative samples in
[70] M. Moor, O. Banerjee, Z. S. H. Abad, H. M. Krumholz, J. Leskovec, the training set. Positive and negative samples are randomly
E.J.Topol,andP.Rajpurkar,“Foundationmodelsforgeneralistmedical
artificialintelligence,”Nature,vol.616,no.7956,pp.259–265,2023. selected with a 1:1 ratio during training. Horizontal flip is
[71] J. Yang, H. B. Li, and D. Wei, “The impact of chatgpt and llms employed for training time augmentation, and the model is
on medical imaging stakeholders: perspectives and use cases,” Meta- pretrainedonImageNet.Consideringtherelevanceofadjacent
Radiology,p.100007,2023.
slices in 3D CT scans, multiple adjacent slices are used
[72] J.Wasserthal,H.-C.Breit,M.T.Meyer,M.Pradella,D.Hinck,A.W.
Sauter, T. Heye, D. T. Boll, J. Cyriac, S. Yang et al., “Totalsegmen- as input to capture more contextual information, while the
tator: Robust segmentation of 104 anatomic structures in ct images,” network outputs the prediction result of the middle slice.
Radiology:ArtificialIntelligence,vol.5,no.5,2023.
Experiments on the relationship between model performance
[73] C.R.Qi,L.Yi,H.Su,andL.J.Guibas,“Pointnet++:Deephierarchical
feature learning on point sets in a metric space,” Advances in neural and the number of adjacent slices input are conducted, and
informationprocessingsystems,vol.30,2017. it is found that 15 is the optimal choice. During inference,
[74] R.C.Contributors,“Challengesolutionsoftheribfracchallenge,”Feb. eachsliceinaCTscanisprocessedindependently.Predictions
2024.[Online].Available:https://doi.org/10.5281/zenodo.10658441
below a certain threshold are disregarded. 2D predictions are
[75] J.Long,E.Shelhamer,andT.Darrell,“Fullyconvolutionalnetworksfor
semanticsegmentation,”inConferenceonComputerVisionandPattern merged into 3D based on connectivity, and the 3D prediction
Recognition,2015,pp.3431–3440. score is calculated as the average of the 2D prediction scores.
[76] L.-C.Chen,Y.Zhu,G.Papandreou,F.Schroff,andH.Adam,“Encoder-
2) Team DCC (DT2): A cascaded rib fracture detection
decoderwithatrousseparableconvolutionforsemanticimagesegmenta-
tion,”inEuropeanConferenceonComputerVision,2018,pp.801–818. pipeline is proposed, consisting of a 2D slice-level detection
[77] H. Tang, C. Zhang, and X. Xie, “Nodulenet: Decoupled false positive network and a 3D patch-level segmentation network. The
reductionforpulmonarynoduledetectionandsegmentation,”inConfer-
2D detection network uses the Mask-RCNN [65] model with
enceonMedicalImageComputingandComputerAssistedIntervention,
ResNet [42] and HRNet [66] pretrained on ImageNet as the
D.Shen,T.Liu,T.M.Peters,L.H.Staib,C.Essert,S.Zhou,P.-T.Yap,
andA.Khan,Eds.,2019,pp.266–274. backbone. FPN [82] structure is added to enable multi-scale
[78] S.Chen,K.Ma,andY.Zheng,“Med3d:Transferlearningfor3dmedical prediction. Random horizontal flip augmentation is applied to
imageanalysis,”arXivPreprint,2019.
make the model learn invariant features. For the 3D segmen-
[79] P.Wang,P.Chen,Y.Yuan,D.Liu,Z.Huang,X.Hou,andG.Cottrell,
“Understandingconvolutionforsemanticsegmentation,”inIEEEWinter tationnetwork,UNet[68]isemployedtocapturestereoscopic
ConferenceonApplicationsofComputerVision,2018,pp.1451–1460. features using an iterative training strategy. The predicted
[80] Z.TuandX.Bai,“Auto-contextanditsapplicationtohigh-levelvision
masks of Mask-RCNN are combined with the ground truth
tasksand3dbrainimagesegmentation,”IEEETransactionsonPattern
AnalysisandMachineIntelligence,vol.32,no.10,pp.1744–1757,2010. to obtain the training samples for UNet. The CT scans are
[81] J. Hu, L. Shen, and G. Sun, “Squeeze-and-excitation networks,” in cropped according to the center of each connected component
Conference on Computer Vision and Pattern Recognition, 2018, pp. before being fed into the network. Random rotation and
7132–7141.
flipping operations are performed for data augmentation. For
[82] T.-Y.Lin,P.Dolla´r,R.Girshick,K.He,B.Hariharan,andS.Belongie,
“Feature pyramid networks for object detection,” in Conference on model finetuning, predicted masks are integrated with ground
ComputerVisionandPatternRecognition,2017,pp.2117–2125. truths to obtain new training samples.
[83] K.SimonyanandA.Zisserman,“Verydeepconvolutionalnetworksfor
3) TeamFakeDoctor(DT3): A two-stage rib fracture detec-
large-scaleimagerecognition,”arXivpreprintarXiv:1409.1556,2014.
tion pipeline is proposed. It uses a ResUNet [67] structure
[84] K.Lee,J.Zung,P.Li,V.Jain,andH.S.Seung,“Superhumanaccuracy
onthesnemi3dconnectomicschallenge,”arXivPreprint,2017. for rib fracture segmentation, followed by a classification
[85] W. R. Crum, O. Camara, and D. L. Hill, “Generalized Overlap Mea- modeltopredictthesegmentationresults.Thedown-sampling
suresforEvaluationandValidationinMedicalImageAnalysis,”IEEE
stage of the nnUNet [64] model framework is replaced with
TransactionsonMedicalImaging,vol.25,no.11,pp.1451–1461,2006.
[86] C. H. Sudre, W. Li, T. Vercauteren, S. Ourselin, and M. J. Cardoso, ResUNet. Attention module and inflated module are applied
“GeneralisedDiceOverlapasaDeepLearningLossFunctionforHighly to enlarge the subsampling receptive field. Combined binary
UnbalancedSegmentations,”inDeepLearninginMedicalImageAnal-
cross-entropy loss and Dice loss are used as the loss func-
ysisandMultimodalLearningforClinicalDecisionSupport. Springer,
2017,pp.240–248. tion. In the post-processing stage of the segmentation model,16 INSUBMISSIONTOIEEETRANSACTIONSONMEDICALIMAGING,VOL.XX,NO.XX,XXXX2024
prediction masks with smaller areas than the threshold are B. SummaryofRibFractureClassificationSolutions
eliminated,whiletheremainingpredictionmasksareexpanded
1) Team UCIrvine (CT1): 3D UNet [68] with binary cross
tobeslightlylargerthanthefracturearea.Intheclassification
entropy is utilized for rib fracture segmentation. To limit
model stage, the predicted masks are cropped and normalized
the number of false positives, the probability map is filtered
throughanadaptivepoolinglayerbeforebeingfedintoaVGG
with a threshold of 0.95. For classification, the backbone of
[83] network. The confidence level of each prediction mask is
NoduleNet[77]isfollowedbythreefullyconnectedlayers.A
obtained after classification. Conventional data augmentation
dropout layer is added between the last two fully connected
methods such as random rotation, translation, cutting, and
layers to suppress overfitting. For data pre-processing, loga-
blurring are employed.
rithm transformation is applied to the filtered and normalized
4) TeamUCIrvine(DT4): A segmentation-based model with CT scans, to balance out the effect of long tail data distri-
model ensembling techniques is used for rib fracture detec- bution. Each rib fracture in training and validation data is
tion. Two 3D UNet [68] models are ensembled, one using croppedintoa3Dboundingcuboidwith4extrapixelsineach
binary cross-entropy loss and the other using Dice loss. The direction, with cuboid labeled -1 dropped. Random flipping,
probability map is filtered with a threshold of 0.35, and each rotation, scaling and translation operations are conducted for
connected component is considered as an instance. training time data augmentation.
5) Team MIDILab (DT5): An ensemble of 3D UNets [68] 2) Team DCC (CT2): 3D ResNet-50 [42] pretrained on
followed by morphological operations is applied for rib frac- Med3D [78] is used for rib fracture classification. Dilated
ture detection. The model is based on a residual 3D UNet convolutions [79] are applied in residual blocks to increase
[84], where all skip connections use element-wise addition the receptive field while keeping the feature resolution. An
instead of concatenation, and each module contains its own auto-context mechanism [80] is adopted, where CT scans are
skip connection. The segmentation result is the voxel-wise integrated with masks generated by the segmentation model
mean of two residual 3D UNets, one trained on binary cross- as the input of 3D ResNet-50 model. It demonstrated that the
entropy loss and the other on Dice loss [85], [86]. For post- guidance of rib fracture mask could boost the classification
processing, each prediction is upsampled to the dimension performance. Random rotation and flipping operations are
of the original CT scans. The prediction is binarized with a conducted to alleviate the over-fitting problem.
threshold,andmissingvoxelsinconnectedfractureregionsare 3) TeamDeepBlueAI(CT3): DeepMedic [89], a dual path-
filled in with a morphological binary closing operation. Small way structure, is employed as the baseline of rib fracture
predicted fracture instances smaller than 512 mm3 are re- detection. A 3D CNN with parallel convolution pathways
moved to avoid over-prediction. In the final binary prediction, extracts highly accurate and soft segmentation features, fol-
instance labels are assigned by identifying and numbering the lowed with a fully connected 3D conditional random fields
connected components. The post-processing hyperparameters (CRF) to generate segmentation labels. The dual pathways
that maximize the validation FROC are determined by a grid share the same structure but have different input resolutions,
search and used in all future runs. sothatbothlocalandcontextualinformationareincorporated.
Shortcuts connections are utilized in the structure, similar
6) Team CCCCS (DT6): A 2D residual UNet [68] is em-
as those in ResNet [42], to improve the training efficiency
ployedtosegmentribfractureson2Dslices,followedbysplic-
and boost performance. The segmentation features of the dual
ing the predictions into 3D as the post-processing operation.
pathway 3D CNN are fed into fully connected layers, and
For data pre-processing, the ribs and their surrounding areas
then a 3D fully connected CRF with spatial regularization is
are extracted as input to address the problem of class label
usedtogeneratesmoothsegmentationlabels.Smallconnected
imbalance. The coronal slices are binarized with a threshold
components are removed for false-positive reduction.
of 110 HU. A morphological dilation operation is applied to
4) TeamCCCCS(CT4): 3D ResNet-18 [42] with weighted
preserve soft tissues around the ribs. The binary images serve
cross-entropylossisappliedforribfractureclassification.The
as the region-of-interest (ROI) masks, which are multiplied
classification method is based on the segmented regions in rib
with the slices to obtain training data. Two slices of each
fracture detection task, which is described in the detection
annotation at the head and tail in the axial plane are disre-
track. The 3D variant version of ResNet-18 is used as the
garded to ensure that the rib fractures are clearly visible. The
backbone. Due to the extreme imbalance between classes,
networkarchitectureisaresidual2DUNet,withhybriddilated
weighted cross-entropy loss is adopted, with the normalized
convolution [79] used to increase the receptive field. A two-
reciprocal of the number of samples in each category in the
stage training strategy is adopted to detect small rib fracture
training set as the weight.
targets and reduce false-positive predictions simultaneously.
Modified generalized Dice loss (GDL) [87] is used to train a
modelwithhighrecall,andthenTverskyloss[88]isemployed
for false-positive reduction. In the post-processing stage, a
morphological dilation operation on spliced 2D slices in the
axial plane is performed to eliminate crevices in predictions
across slices.