Tell Me More! Towards Implicit User Intention Understanding of
Language Model Driven Agents
ChengQian1*,BingxiangHe1∗,ZhongZhuang1,JiaDeng2,YujiaQin1,XinCong1,
ZhongZhang1,JieZhou3,YankaiLin2,ZhiyuanLiu1,MaosongSun1
1TsinghuaUniversity, 2RenminUniversityofChina, 3WeChatAI,TencentInc.
{qianc20, hbx20}@mails.tsinghua.edu.cn
Abstract Execution
Current language model-driven agents often
lack mechanisms for effective user participa- Q1?
Vague Task A1 tion,whichiscrucialgiventhevaguenesscom-
Q2?
monly found in user instructions. Although Tool Execution A2
adept at devising strategies and performing Q3?
tasks,theseagentsstrugglewithseekingclar- A3
ificationandgraspingpreciseuserintentions. Clear Task
Vague Task
Tobridgethisgap,weintroduceIntention-in-
(a) Execute with Implicit Intention (b) Execute with Explicit Intention
Interaction(IN3),anovelbenchmarkdesigned
to inspect users’ implicit intentions through
Figure1:Acomparisonofagentexecutionwithimplicit
explicit queries. Next, we propose the incor-
intentionsorexplicitintentionsafteruser-agentinterac-
poration of model experts as the upstream in
tion.
agentdesignstoenhanceuser-agentinteraction.
EmployingIN3,weempiricallytrainMistral-
Interact,apowerfulmodelthatproactivelyas- asanAIagenttoassistusertasks(Xietal.,2023;
sessestaskvagueness,inquiresuserintentions,
Wang et al., 2023b), inspiring many open-source
andrefinesthemintoactionablegoalsbefore
frameworks focusing on agent design, including
startingdownstreamagenttaskexecution. In-
BabyAGI (BabyAGI, 2023) AutoGen (Wu et al.,
tegrating it into the XAgent framework, we
2023b),CAMEL(Lietal.,2023),AutoGPT(Au-
comprehensivelyevaluatetheenhancedagent
systemregardinguserinstructionunderstand- toGPT,2023),andXAgent(XAgent-Team,2023),
ingandexecution,revealingthatourapproach etc. Theseframeworksgenerallyleveragetheback-
notablyexcelsatidentifyingvagueusertasks, bonelanguagemodel’sexceptionalabilitiestocom-
recoveringandsummarizingcriticalmissingin-
prehenduserinstructionsandexecuteusertasks.
formation,settingpreciseandnecessaryagent
However,currentagentdesignsseldomconsider
executiongoals,andminimizingredundanttool
robustuserinteraction, despitethati)theuser’s
usage,thusboostingoverallefficiency. Allthe
dataandcodesarereleased1. initial instruction to the agent system is usually
vague and brief, and ii) different users have dif-
1 Introduction
ferentintentionswhichnecessitateexplicitquery
LargelanguagemodelsincludingtheOpenAIGPT andinspiration. Theignoranceoftheuser’sclear
(OpenAI, 2022, 2023), LLaMA (Touvron et al., and specific needs often leads to “fake success”
2023a,b), and Mistral series (Jiang et al., 2023) during agent task execution, where it seemingly
have made great strides in high-quality text and completesthegoalbutdeviatesfarfromtheuser’s
code generation (Zeng et al., 2022; Chowdhery trueintentions. Thisstressestheimportanceofim-
etal.,2023;OpenAI,2023;Touvronetal.,2023b), plicitintentionunderstandingduringuser-agent
complexlogicalreasonings(Weietal.,2022;Gao interaction to further improve the agent design’s
etal.,2023;Yaoetal.,2022,2023),andusingex- robustnessandefficiency.
ternal tools (Schick et al., 2023; Qin et al., 2023, Current agent benchmarks usually assume the
2024). Thesetraitsenablethelanguagemodeltoin- clearanceofgiventasksandexcludeuserintention
teractwiththeoutsideworldandreceivefeedback understandingasanimportantaspectforevaluation.
Giventhisignoranceinassessment,weformulate
*indicatesequalcontribution.
1https://github.com/HBX-hbx/Mistral-Interact Intention-in-Interaction(IN3),abenchmarkaim-
4202
beF
51
]LC.sc[
2v50290.2042:viXraing to test the agent’s interaction ability through detailedandclearuserintentions.
explicit task vagueness judgment and user inten- Inexperiments,weincorporateMistral-Interact
tion understanding. IN3 provides general agent intotheXAgentframework(XAgent-Team,2023),
tasks over hundreds of categories, each with its anautonomousagentsystemforcomplextasksolv-
vagueness, missing details, and each detail’s im- ing. Through comprehensive evaluation of both
portancelevelandoptionstoinspiretheuser’strue user instruction understanding and agent instruc-
intentions. Inaddition,weproposeaninnovative tionexecution,werevealthatouradaptedMistral-
approach to evaluate present agent systems, with Interact can i) correctly judge the vagueness of
metrics addressing the existing gap in evaluation over85%tasks,recoverover70%ofthemostim-
by incorporating two key aspects that emphasize portantmissingdetails,andsummarizeover96%
userparticipation: implicit user intentions without omission, ii) sig-
• InstructionUnderstanding: Todirectlyevalu- nificantly reduce the number of too general or
ate the process of intention understanding, we unnecessary goals and lower the tool invocation
quantitatively measure the preciseness of the times during agent execution, which raises over-
agentinjudginginstruction’svagueness,there- all agent efficiency. The performance of Mistral-
covery rate of important missing details, and Interact is more aligned with human preferences,
therobustnessofuserintentionsummarization far better than the previous LLaMA and Mistral
underdiversescenarios. serieswhilerivalingclosed-sourceGPT-4butwith
amuchsmallerscale. Ourmethodprovesthevia-
• InstructionExecution: Toindirectlyreflectthe
bilityofintegratingsmaller,open-sourcedmodel
effectivenessofintentionunderstanding,wecon-
expertsforrobustimplicitintentionunderstanding
trast the agent task execution given the initial
duringuser-agentinteraction,andweconcludeby
(vague)orfinalized(clear)usergoal,andmea-
discussingitsfurtherimplicationsandfuturedirec-
surethegenerality,necessity,andefficiencyof
tions. Overall,ourkeycontributionsinclude:
theagent’sactions.
• We formulate a new research question regard-
Aslanguagemodelslieasthecoreofagentde- ing the enhancement of user-agent interaction
signs,wefirstapplysampledtasksfromIN3totest throughrobustintentionunderstanding,andre-
theactiveinteractionabilityofdiversemodels,re- lease the IN3 benchmark that focuses on user
vealingthatmostofthemseriouslylacktheability participationwithincurrentagentdesigns.
to judge task vagueness and initiative to compre-
• We propose to integrate an expert specialized
hensivelyunderstanduserintentions. Thisfurther
in interaction as an upstream design before
raisesourresearchproblem: Howtoenhancethe
task execution in the agent system, and empir-
interactionabilityoftheagentsystemthrough
icallyadaptMistral-Interact,shiftingthefocus
theunderlyingmodel’srobustintentionunder-
fromcomplexagentdesigntosmaller-scaleuser-
standing?
centricmoduledesign.
To address this, we propose to integrate a spe-
• We create a set of new metrics regarding the
cialized upstream model in charge of user-agent
evaluationofuser-agentinteraction,whichtakes
interaction in agent design. As illustrated in Fig-
intoconsiderationboththequantifiabilityofre-
ure1,toexplicitlyunderstanduser’sspecificinten-
sultsandalignmenttouserpreferencesforfuture
tions,themodelshouldactivelyandexplicitlyask
benchmarkstofollow.
users for missing details before passing the task
for downstream execution. To enhance this inter- • We prove the viability of our method through
action capability, we apply training split tasks in comprehensiveexperimentsandcasestudieson
IN3 to construct simulated model-user conversa- the XAgent framework, thereby promoting a
tion records that provide explicit initial thoughts, newmechanismandparadigmofuser-agentin-
roundsofquerieswithoptions,summarizationof teractioninagentdesigns.
implicitintentions,anddiverseuserresponsetones.
2 RelatedWorks
Trainingontheseconversations,weadaptMistral-
7B into Mistral-Interact, a powerful and robust LLM-drivenAgent. Recentlargelanguagemod-
variant capable of judging the vagueness of user els(LLMs),includingtheclosed-sourceGPTseries
instruction, actively querying for missing details (OpenAI, 2022, 2023) and open-source LLaMA
withsuggestions,andexplicitlysummarizingthe (Touvron et al., 2023a,b), Mistral (Jiang et al.,2023)series,havedemonstratedstrongreasoning user intention can be achieved through zero-shot
(Wei et al., 2022; Gao et al., 2023; Yao et al., prompting (Kotnis et al., 2022), enabling the rec-
2022; Shinn et al., 2023), planning (Yao et al., ommendationoftask-orientedbotsbasedonuser
2023; Besta et al., 2023; Sel et al., 2023; Hao intentions(KuoandChen,2023). Incontrast,our
etal.,2023;Yeetal.,2023a)andtoolusingability workisthefirsttocenteronincorporatingimplicit
(Nakanoetal.,2021;Huangetal.,2022;Ahnetal., userintentionunderstandingwithinagentdesigns.
2022; Schick et al., 2023; Patil et al., 2023; Qin
User-AgentInteractionDesigns. Currentagents
et al., 2023, 2024; Qian et al., 2023b,c). These
oftenstrugglewithintricatereasoningtiedtosocial
enable LLMs to interact with the world as AI
and historical contexts, and they face challenges
agents,accomplishingcomplexandgroundedhu-
inadaptingtosituationsrequiringpersonalization
man tasks (Xi et al., 2023; Wang et al., 2023b;
(Majumder Bodhisattwa Prasad, 2023). A user-
BabyAGI,2023;AutoGPT,2023;Lietal.,2023;
centricapproachtoagentdesignemphasizesalign-
Wu et al., 2023b; XAgent-Team, 2023). A line
ment with user preferences and fosters effective
ofcurrentresearchfocusedonenhancingagent’s
interactions. Oneresearchdirectionadvocatesfor
abilitythroughtoolcreation(Caietal.,2024;Qian
agentsasteammates,involvingstakeholders,devel-
etal.,2023b;Wangetal.,2023a),multimodalca-
opers, and designers throughout agent designs to
pability(GuptaandKembhavi,2023;Shenetal.,
incorporateauthentichumanrequirements(Kotnis
2023;Wuetal.,2023a),anddomain-specifictools
etal.,2022). Anotheravenueexplorestheroleof
andresources(Jinetal.,2023;Lyuetal.,2023;Ye
agentsinfosteringcreativity,leveragingtheircre-
et al., 2023b). Other studies involve multi-agent
ativeperspectivetoenhancecommunicationandin-
frameworksforcommunication(Parketal.,2023;
teractionwithusersinamannerresemblinghuman
Lietal.,2023;Qianetal.,2023a;Huetal.,2023),
engagement (Chen et al., 2020; Wu et al., 2021).
collaboration(Chenetal.,2024;Wuetal.,2023b),
An extension of this approach includes treating
and evaluation (Chan et al., 2023; Zhang et al.,
agentsascollaborativeteammembers,considering
2023). Thesepreviousworkshavenotfullytaken
andassigningpersonalitytraitsandskillsnecessary
intoaccounttheroleofusersintheagentdesigns,
foranagenttoberecognizedandacceptedaspart
theissuethatourstudystrivestoaddress.
of the team (Christina Wiethof, 2021). Different
fromtheseworks,wefocusontheuser’sintention
UserIntentionUnderstanding. Inthequestto
understanding during interaction to enhance the
developanengagingagent,itbecomesparamount
agent’seffectivenessandefficiency.
toanticipateuserintentionsacrossvariedcontexts.
Conventionalapproachesforuserintentionunder-
3 Intention-in-InteractionBenchmark
standingincludeSupportVectorMachine(SVM)
(Sullivan,2018),NaiveBayes(Vikramkumaretal., Most of the past agent benchmarks assume the
2018) and XGBoost (Chen and Guestrin, 2016), giventaskisclear,aimingtoevaluatetheagent’s
withXGBoostconsistentlyshowingsuperiorper- executionability. However,user-providedinstruc-
formance (Cai and Chen, 2020). Accurate user tions are often ambiguous. For instance, for the
intention understanding is crucial, especially in task “Locate the best yoga class in my city” pre-
information-seekingscenarioslikewebsearchen- sentedinFigure2,theinstructionisunclearabout
ginesorcommunityquestion-answeringplatforms. where “my city” is and what the criteria for the
TheMSDialogdataset(Quetal.,2018)isspecifi- “best”is. Allthesevaguenessnecessitateaclearer
callycraftedtodissectuserintentiondistribution, comprehensionoftheuser’strueintentionstofur-
co-occurrence,andflowpatterns,whiletheSHD- therboosttheagent’sexecutionefficiency.
CRFmodel(Shenetal.,2011)isadeptatlearning Tothisend,weaimtoformulateamorerational
from user search sessions. Moreover, categoriz- agent task setting, in which the user’s true inten-
inguserutterancesbasedonhand-craftedfeatures, tionsforeachtaskareimplicit. Thecompletionof
such as leveraging Wikipedia (Hu et al., 2009), these tasks requires the agent to actively inquire
textualandmetadatafeatures(Chenetal.,2012), about missing details and understand the user’s
andfactorslikecontent,discourse,sentiment,and implicit intentions. To comprehensively enhance
context (Cai and Chen, 2020), can significantly andquantitativelyevaluatetheseabilitiesinagent
augment user intention understanding. With the designs, we introduce Intention-in-Interaction
riseoflanguagemodels,nowtheunderstandingof (IN3),abenchmarkstrivingtoassessandinspireStep 1: Prepare Seed Data Step 2: Data Augmentation As illustrated in Figure 2, with human-written
Human-Written seedtasks(Step1),themodeliterativelygenerates
Seed Tasks Sample
Example Examples newtaskstoaugmentthedataset,whilesampling
Category: Health Advise Augment demonstrationsfromthedatasetasnewexamples
Task: Locate the best yoga Dataset
class in my city foritselftoperformthenextroundofgeneration
Annotation (Step 2), detailed in Appendix A.1. We perform
Vague: True Task Pool
Missing Details (Importance): Options humanannotationofeachtask’svagueness,miss-
- User’s City (Lv 3):
AND New York, Los Angeles, Chicago ... ingdetails,andeachdetail’simportanceleveland
- Criteria for Best (Lv 2): potentialoptionswiththehelpofGPT-4(Step3).
Top rated, 4+ stars, Positive reviews ... Step 3: Annotation
GPT-4willfirstsuggestthetask’svaguenessand
potential missing details with options and impor-
Figure 2: An illustration of IN3’s formation with an
tancelevel,whilehumanannotatorstakethemas
exampledatapoint.
referencesandadaptthemwiththeirownperspec-
tivesandintentions,detailedinAppendixA.2.
Split Training Test
Overall, IN3 can be applied to evaluate the
Task 1261 108
-Vague 1012 95 agent’sdiscernmentoftaskvagueness,assessthe
-Clear 249 13 agent’sabilitytorecoverimportantmissingdetails,
Categories 250 50 and facilitate training on the underlying model’s
#MissingDetails 3615 350 implicitintentionunderstandingcapability. IN3is
-Avg. 3.57 3.68 alsodividedintotrainingandtestsplits,withmore
-Lv1(%) 15.44 9.14
statisticaldetailsprovidedinTable1.
-Lv2(%) 67.75 72.29
-Lv3(%) 16.81 18.57
3.2 PreliminaryTest
#Options 11523 1042
-Avg. 11.39 10.97 Settings. Asthelanguagemodelliesatthecore
of agent designs, we begin by conducting a pre-
Table 1: Detailed statistics for training and test splits
liminarystudyoncurrentopen-sourceandclosed-
of IN3. The missing details and option numbers are
sourcemodels’intentionunderstandingabilitydur-
averagedonthenumberofvaguetasks.
inginteraction. Specifically,wesampletentasks
from IN3 and apply them to test LLaMA-2-7B-
theagent’sintentionunderstandingabilityinaro- Chat1,Mistral-7B-Instruct-v0.22,andGPT-4. All
bust,structured,anduser-friendlyway. modelsarepromptedwiththesameinstructionsto
i) judge the vagueness of the task, ii) inquire the
3.1 BenchmarkConstruction
user for missing details if the task is vague, and
IN3providesdiverseagenttasksoverhundredsof iii)summarizethedetailedusertaskgoal. Please
categories(e.g. Cookery,Arts,Programming),with refer to Appendix B.1 for specific tasks, detailed
annotationsonwhetherthetaskisvague,whatthe settings,andpromptcontents.
missingdetailsare(ifvague),theimportancelevel
ofeachmissingdetail(threelevels,thehigherthe Evaluation. Forquantitativeanalysis,wefirst
moreimportant,detailedinAppendixA.2),andthe counthowmanymodeljudgmentsoftaskvague-
potentialoptionsforeachmissingdetail. Regard- ness are aligned with IN3’s human annotation.
ingthevaguehealthadvicetaskpresentedinFig- Next,wecountthetotalqueryattemptsthemodel
ure2,IN3providesannotatedmissingdetailsabout madeinthevaguetasks,andhowmanyofthemare
theuser’scityandcriteriaforthebest,withoptions aligned with IN3’s human annotation (which are
to demonstrate potential answers and inspire the trulymeaningful,necessary,andimportantmissing
user’strueintention. Sincethecityisindispensable details;intotalthereare24suchhuman-annotated
foryogaclasssearching,ithasahigherimportance missingdetails,showninAppendixB.1). Forqual-
level(Lv3)thanthemissingcriteria(Lv2),which itative analysis, we divide the whole interaction
onlyservestobettermatchtheuser’spreference. intothreephases: vaguenessjudging,missingde-
Thetaskdescriptionanditscategoryaregener- tailsinquiring,anddetailedusergoalsummarizing.
atedinaself-instructmanner(Wangetal.,2023c)
1https://huggingface.co/meta-llama/Llama-2-7b-chat-hf
applyingGPT-4. Weintotalconsiderover200cat-
2https://huggingface.co/mistralai/Mistral-7B-Instruct-
egories and construct 1300+ diverse agent tasks. v0.2(Quantitative) Metric LLaMA-2 Mistral GPT-4
Vagueness
Judgmentaccuracy 6/10 8/10 9/10
Judgment
Missing
Ratioofnecessaryqueryattempts 7/23 7/8 16/24
Details
(Qualitative) Description LLaMA-2 Mistral GPT-4
During Inaccuracyinjudgment Severe Light
Judging Judgeasclearbutstillquery Light
Asktoomuchwithoutstopping Severe
Asktoofew,quicklyjumptosummarize Severe
During
Inquireunnecessarydetails Severe Light
Inquiring
Toomanyqueriesatonetime Light Light Light
Queryalloveroneaspect,ignoringothers Light Light
Solvetaskinsteadofprovidesummary Severe
During
Provideassumedorhallucinateddetails Light Light Light
Summarizing
Ignoreuserprovideddetails Light
Table2: TheperformanceandchallengesofLLaMA-2-7B-Chat,Mistral-7B-Instruct-v0.2,andGPT-4’sintention
understandingabilityduringinteraction.
For each stage, we gather various unsatisfactory design.
orfailedinteractionpatternsandevaluatewhether
• GPT-4’sAbility: GPT-4’svaguenessjudgment
theyaresevere, light, ornearlynonexistent, with
alignsmostcloselywithusers, anditcouldre-
criteriadetailedinAppendixB.2.
covermostofthenecessarymissingdetailsre-
Results. WepresentaresultsoverviewinTable2. gardedbyusers. ThesejustifytheuseofGPT-4
toimitateuserswithspecificpreferencestocon-
Allthreemodelspresentchallengesinrobustuser
structconversationrecordsfortraining.
intentionunderstandingbutwithdifferentfailure
patterns. Among them, LLaMA-2 performs the
3.3 ResearchProblem
worstasitcannotidentifyalreadycleargoalsand
often asks for unnecessary details without stop- Accordingtothechallengesweidentifyinimplicit
ping. Mistralisalittlebetterbutstillsuffersfrom intentionunderstanding,weformulateourresearch
aninsufficientunderstandingofhumanintentions. problem as follows: For each task t with a set of
GPT-4 aligns the closest with human intentions missingdetailsD ={d ,d ,...,d },wewouldlike
1 2 n
regarding task vagueness and important missing the agent to transform t into t user for execution,
details. We further provide case studies in Ap- wheret user encompassesalltheuser’simplicitin-
pendixB.3forillustration. Ourresultsbearbroad tentions towards each missing detail. This neces-
implications: sitates enhancement of the agent’s interaction
• Shortages to Focus: From current failed pat- ability through the underlying model’s robust
terns, future language model-driven agent de- implicitintentionunderstanding.
sign should focus on i) making more precise
4 Method
judgmentsoftaskvagueness,ii)queryingimpor-
tantmissingdetailsofdiverseaspectsinauser-
To further enhance the implicit intention under-
friendlyway,andiii)summarizinguserprefer-
standing ability of current agent designs, we pro-
encescomprehensivelywithoutomissions.
posetotrainamodelexpertspecializedinimplicit
• Necessity of Adaptation: To further raise the intentionunderstandingthroughconversationwith
agent’sintentionunderstandingabilityduringin- users and incorporate it as an upstream module
teractions,werevealthatpromptengineeringis in agent design. Denote agent execution process
insufficient,whichnecessitatesfurthertraining as a function f, then this module should act as a
tobuildinteractionexperts. Accordingtothere- “buffer”betweeninitialusertasktanddownstream
sults,Mistralhasgenerallyfewerdefectsduring execution f(t). If t is already clear, the module
the interaction, making it a better base model should directly pass t for execution, while if t is
choice for further adaptation in agent system vague, the module should robustly chat with theuser, turning t into t with specific user inten- Onequeryatatimemakesmodelinquiriesless
user
tions. Weexpectf(t )toperformbetterandbe pushy, while reasonable options provided can
user
morealignedwiththeuser’sintentionsthanf(t). inspiretheuser’sdeeperthoughtsandencourage
To realize this, we first apply IN3 to construct explicit expression of implicit intentions. All
conversation records for training. Using the con- of these serve to make the model’s interaction
structedinteractiondata,weadaptMistral-7Binto moreuser-friendly.
Mistral-Interact, a powerful variant capable of
• Diverse User Tones: For the user response in
judgingthevaguenessofuserinstruction,actively
each round of conversation, we prompt User-
queryingformissingdetailswithsuggestions,and
GPTtoimitateuserswithdifferenttones,focus-
explicitlysummarizingdetaileduserintentions. In
ing mainly on succinct (assume users are lazy
thissection,weillustrateourmethodindetail.
andprovideshortresponses)andpassionate(as-
sume users provide long responses with new
4.1 ConstructionofTrainingData
information) response patterns. This serves to
To enhance the model’s implicit intention under-
facilitatetheapplicabilityandrobustnessofthe
standing through interaction, we need to further
modelstrainedonit.
trainitonhowtoinquireaboutthemissingdetails
• Explicit Intention Summary: We instruct
inavagueusertaskthroughconversation. AsIN3
Assistant-GPTtoexplicitlysummarizealluser-
hasalreadyprovideddiverseagenttaskswithanno-
providedintentions(bothresponsestoinquiries
tations,weapplyitstrainingsplittoconstructthe
andnewinformation)inthoughtsandprovidea
conversationrecordsfortraining. Resultsfromthe
clearerversionofusergoalt onceitbelieves
preliminarystudyhavejustifiedtheuseofGPT-4 user
enough information is gathered. The thought
toimitateuserpreferences. Therefore,tomakethe
servestomakethesummarizedt morelogi-
construction process automatic and efficient, we user
calandcomprehensivewithoutomission. More-
employtwoGPT-4stosimulatetheconversation,
over,thesummarizedt withuserintentions
with one imitating the user aiming to complete a user
couldbedirectlyappliedfordownstreamagent
certaintask(User-GPT),andtheotherasanassis-
executionf(t ), thuspromotingaseamless
tant aiming to clearly understand user intentions user
integration of the trained model into existing
withtheannotationsfromIN3ashelp(Assistant-
agentframeworks.
GPT).
NotethatifthetasktinIN3isclear,thenallthe
Strategies. With IN3’s annotations regarding conversationsimulationswillbeomitted. Onlythe
taskvagueness,missingdetails,andpotentialop- judgmentofvagueness(clear)intheinitialthought
tions, we apply several strategies during the con- andthesummarythoughtwillbeperformed,with
structionofconversationrecordstobetterinspire thefinalizedt = t. Inaddition,asweimitate
user
thetargetmodel’srobustinquiryandreasoningabil- differentusertones,thetotalconversationrecords
ity. Allstrategiesareillustratedwithanexamplein contributetoapproximatelytwicethetrainingtask
Figure3. number in IN3. Please refer to Appendix C for
• ExplicitInitialThought: AftertheUser-GPT moredetails.
presentsatasktinIN3,wefirstmanuallycon-
4.2 TrainingDetails
struct the Assistant-GPT’s initial thought with
an explicit judgment of task vagueness, miss- Generally,weapplytheconversationrecordscon-
ingdetails,andpotentialoptionsaspresentedin structedtotrainMistral-7B1 intoMistral-Interact,
IN3. Weconcatenatealltheinformationthrough aimingtomakethemodelbettercomprehenduser
atemplatedetailedinAppendixC.Thisserves intentionsandtransformvaguetasksintoclearini-
toguidethemodeltolaterinquireaboutcorede- tiativesfortheagent’sexecution. Specifically,we
tailsinsteadofaskingarbitrarilywithreasoning fiteachconversationrecordintoatemplateoutlined
onthefly. inAppendixDandcumulativelyconcatenatemul-
tipleroundsofinteractions,thuscreatingmultiple
• Query with Options: For each round of con-
datainstances.
versation,weinstructtheAssistant-GPTtopro-
For vague tasks, the first data instance trains
vide thoughts and ask only one query with op-
themodeltogenerateaninitialthought,judgethe
tions. Theinquiryismadebasedonthemissing
details and options listed in the initial thought. 1https://huggingface.co/mistralai/Mistral-7B-v0.1User-GPT Annotation
Locate the best yoga class in my city. Vague: True
Missing Details
(Importance): Options
One Query Where do you live in? New York,
with Options Los Angeles, or elsewhere?
The user’s task is vague,
San Francisco. Diverse Tone: missing details include:
Succinct Assistant-GPT - User’s City: NY, LA, Chicago
- Criteria for Best:
Great! What’s your criteria for Explicit Initial Top rated, 4+ stars
Answer “best”? Top rated, 4+ stars? Thought
Actually 5-star class works the Diverse Tone: Explicit Intention User’s intention is clear
best for me. Oh I want hot yoga. Passionate Summary enough now:
New Info - Live in San Francisco
- Want 5-star class
Summary: The user wants to find a - Prefer hot yoga
5-star hot yoga class in San Francisco.
Figure3: Theconstructionofconversationrecordswithdiversestrategiesapplied.
task’s vagueness, and perform an initial inquiry languagemodelsthemselvesduringinteractionto
if the task is vague. Then, the i-th data instance judgetheircapabilitytoserveasarobustupstream
trains the model to generate the i-th inquiry on moduleinagentdesign.
missingdetailswiththought. Finally,thelastdata
instancetrainsthemodeltogenerateasummaryof 5.1.1 ExperimentalSettings
theuser’sresponseswiththought. Forcleartasks, DataandSettings. WeusethetestsplitofIN3
themodelisdirectlytrainedtogeneratethoughts, agent tasks for evaluation. For each task, we en-
judgment, and the final summary. This involves gagetheuserinanopen-endedconversationwith
onlyonedatainstance. thetargetmodel, duringwhichitwillactivelyin-
Weutilizethemodel-centerframework(model- quire about user intentions. We recruit diverse
center,2023)toconductfull-parameterfine-tuning undergraduate-level users of different expertise
ofMistral-7Bontwo80GBA800s. Specifichyper- to participate in the conversation and provide re-
parametersaredetailedinAppendixD.4. sponses,detailedinAppendixE.1. Thewholecon-
versation process is recorded and then evaluated
5 Experiments
basedonthegroundtruthprovidedinIN3.
Anagent’sintentionunderstandingcapabilitycan
Model and Baselines. We compare Mistral-
be assessed directly through user interaction and
Interact with LLaMA-2-7B-Chat, Mistral-7B-
indirectlythroughdownstreamtaskexecution. In-
Instruct-v0.2,andGPT-4,thesamemodelsinSec-
teractionfocusesonintentionunderstandingitself,
tion3.2. Forafaircomparison,weinitiallyprompt
while execution focuses on intention understand-
all baseline models as well as Mistral-Interact to
ing’sultimategoal,whichistoenhancetheagent
explicitly judge task vagueness, ask for missing
design’sefficiency.
details,andsummarizetheuser’sgoal.
Therefore, to comprehensively evaluate the ef-
fectivenessofanagentdesigncapableofinterac-
5.1.2 Metrics
tion, wedivideourexperimentsintotwoaspects:
i)InstructionUnderstanding: Theevaluationof Main Metrics. We present novel metrics that
agent’sintentionunderstandingcapabilityduring convertsubjectivehumanintentionsinuser-agent
user-agent interaction to directly show its excel- interactionsintoobjectivenumericalvalues,thus
lence;ii)InstructionExecution: Theevaluation simplifyingdataanalysisandcomparison.
ofagenttaskperformancewithanupstreamplug-in • VaguenessJudgementAccuracy: Wecalculate
interactionexperttoreflectitseffectiveness. thepercentofthemodel’sjudgmentsoftaskt’s
vagueness(vagueorclear)thatarealignedwith
5.1 EvaluationonInstructionUnderstanding
groundtruth. Thismeasuresthemodel’sability
Instructionunderstandingdoesnotinvolveanyreal- todiscernvaguenessfromclearanceandavoid
time agent execution, so we directly evaluate the inquiringaboutalready-cleartasks.• Missing Details Recover Rate: For ground 5.1.3 Results
truthmissingdetailsofdifferentimportancelev- FromtheoverallresultspresentedinTable3, we
els,weanalyzewhatpercentarerecovered(ex- summarizeourfindingsaboutMistral-Interactas
plicitly inquired) by the model during the in- follows.
teraction. Thismeasuresthemodel’sabilityto
Better understanding of user judgments.
prioritizeinquiringaboutnecessarydetails.
Among all the open-source models, Mistral-
• SummaryIntentionCoverageRate: Theper-
Interact is the best at predicting task vagueness
centofuser-providedintentionsthatareexplic-
andmissingdetailsthatusersregardasnecessary
itly summarized finally in t by the model.
user (especiallyLv3andLv2). WeshowthatMistral-
Thismeasuresthemodel’sabilitytosummarize
Interact’svaguenessjudgmentisthemostaccurate,
userintentionscomprehensivelyandexplicitly
anditcouldrecoverover70%ofthemostimpor-
withoutrepetitionsoromissions.
tantmissingdetails,farbetterthanLLaMA-2-7B
OtherMetrics. Despitethethreemainmetrics andMistral-7Bwhilerivalingtheperformanceof
that directly reflect the model’s ability to under- GPT-4. This can be attributed to the structured
standtheuser’simplicitintentions,wealsoanalyze andcomprehensiveinitialthoughtsinconstructed
otherconversationdetails foramorecomprehen- conversationrecordsappliedtoMistral-Interact’s
siveevaluation. training.
• OptionsPresentingRate: Forallthemissing
Comprehensive summarization of user inten-
detailsexplicitlyqueriedbythemodel,weana-
tions. Mistral-Interactiseffectiveinmakingan
lyzethepercentofthemaccompaniedbypoten-
explicitandcomprehensivesummarybasedonde-
tialoptions.
tailed user intentions. We observe that Mistral-
• Options Reasonable Rate: For options pro- Interact,comparedwithotheropen-sourcemodels,
vided by the model, we record the percent of hasthehighestaverageconversationroundsaround
themthattheuserbelievesisreasonabletopro- 4.5. Despite the resulting more user-provided in-
pose. This measures whether the model could formation, it still gives the most comprehensive
activelyandpositivelyinspireuserresponses. summaries with fewer omissions, covering over
96%ofalluserintentions,whichischallengingto
• Average Provided Options: Average number
achieve.
of options the model provides for one missing
detailduringtheinquiry. Enhanced model-user interaction experience.
Mistral-Interact inquires about missing details in
• Average Inquired Missing Details: Average
vague tasks more reasonably and friendly than
numberofmissingdetailsthemodelinquiresfor
otheropen-sourcemodels,thuspromotingaclearer
onetask.
understandingoftheuser’simplicitintentions. This
• AverageConversationRounds: Averagenum-
entailsMistral-Interactaskingfewerquestionsper
ber of conversation rounds that the model has
round(approximatelyonlyone)butstillmaintain-
withtheuserforonetask.
ingahighrecoverrateandprovidingamultitudeof
• AverageInquiredMissingDetailsPerRound: reasonableoptionsformostmissingdetails. These
Average number of missing details the model traits better inspire the users to reveal their inner
inquiresforoneroundofconversation. worldswhilemakingthemmorewillingtorespond
We provide the formalized definition and de- insteadoffeelingstuffedwithinquiries.
tailedcalculationformulasforeachmetricinAp-
Comparable performance with closed-source
pendixE.3.
GPT-4. We prove that smaller-scale model ex-
Measurement Details. For all the metrics, we pertscanapproachorevenexceedgeneral-purpose
apply direct statistical calculation, user annota- large-scalemodelsacrossvariousaspectsincluding
tionduringconversations,orinvolvementofGPT- vagueness judgment, comprehensiveness of sum-
4 to help with our measurement, detailed in Ap- maries,andfriendlinessofinteraction. According
pendixE.2. Inaddition,weprovideonlythemacro- to the presented results, Mistral-Interact’s perfor-
averagecalculationresultsoverallthetestingtasks, mancecloselymatchesthatofGPT-4acrossallmet-
asthemicro-averageresultsreflectapproximately rics,evensurpassingGPT-4’scapabilityonvague-
thesametrendamongmodels. nessjudgment,optionprovision,andcoverageofMetrics Mistral-7B LLaMA-2-7B GPT-4 Mistral-Interact
↑VaguenessJudgementAccuracy(%) 49.07 79.63 82.41 85.19
-↑Lv3 68.42 60.98 75.22 72.28
MissingDetailsRecoverRate
-↑Lv2 56.94 38.76 63.14 67.08
(ofImportanceLevel,%)
- Lv1 23.08 28.92 37.50 27.94
↑SummaryIntentionCoverageRate(%) 91.43 61.87 100.0 96.37
↑OptionsPresentingRate(%) 42.46 47.64 40.31 84.08
↑OptionsReasonableRate(%) 100.0 81.79 100.0 98.70
AverageProvidedOptions 1.46 1.35 1.21 2.72
AverageInquiredMissingDetails 3.91 5.80 4.78 4.52
AverageConversationRounds 1.62 3.02 2.69 4.15
↓AverageInquiredMissingDetailsPerRound 2.80 2.49 2.31 1.26
Table 3: The results of Mistral-Interact and baselines regarding different metrics on the test split tasks of IN3.
Arrowsrepresentthehigher(↑)orthelower(↓)thebetter.
certainmissingdetails. Inaddition,comparedwith 5.2 EvaluationonInstructionExecution
GPT-4,Mistral-Interactisalsomorecost-efficient
Toevaluatetheeffectivenessoftheimplicitinten-
whileachievingcomparableperformance.
tion understanding for instruction execution, we
integrate Mistral-Interact as an upstream interac-
5.1.4 CaseStudy
tionmoduleintotheXAgentframework(XAgent-
TofurthershowMistral-Interact’srobustnessunder
Team,2023),anautonomousagentsystemforcom-
differentconversationscenarios,wepresentthree
plex task solving. We conduct proof-of-concept
casestudiesinFigure4andillustraterespectively
experimentsthroughperformancecomparisonand
asfollows.
casestudies,asillustratedinthissection.
Robustness to varied user tones and conversa- 5.2.1 ExperimentalSettings
tion styles. In Case A of Figure 4, we show
Data. We randomly sample ten tasks from the
the impact of varied user tones and conversation
IN3’stestsplitthatarei)regardedasvaguebyboth
stylesonMistral-Interact’sresponses. Wediscover
thegroundtruthandMistral-Interact,andii)within
thatregardlessofwhethertheuser’sresponsesare
theXAgent’sability. Forthesetasks,weextractthe
briefordetailed,enthusiasticoraloof,andevenif
initialvaguetaskdescriptionandthesummarywith
containingtypos,Mistral-Interactcancomprehend
clear user intentions derived from the user-agent
themaccuratelyandprovideappropriateresponses,
interaction. Theyarethenbothsentforagentexe-
whichprovesitsrobustness.
cutionforevaluationandcomparison. Eachtask’s
detailedcontentispresentedinAppendixF.1.
Robustness in dealing with non-cooperative
users. In Case B of Figure 4, we examine Settings. We enable the plan and execution en-
whetherMistral-Interactcancontinueprobingand gineoftheXAgentframework. Theenvironments
steer the conversation back on track when users whereXAgentcanbegroundedforinteractionin-
displayreluctanceornon-cooperation. Theresult clude web searching, code execution, command
showsthatevenwhenusersevadethequestion,our line,andfilesystem. WeemployGPT-4asthede-
adapted model can still redirect the conversation faultmodelforbothtaskplanningandexecution.
effectively.
5.2.2 Metrics
AdditionalUserInformation. InCaseCofFig- The XAgent divides the user’s task into subtasks
ure 4, we observe that Mistral-Interact can incor- duringplanning,eachwithasetofmilestonesthat
porate additional user-provided information that theagentaimstoachievethroughtoolinvocation
is not explicitly inquired by the assistant into the chains. We design metrics that aim to reflect the
summary. Thisindicatesthatwhenthemodeldoes effectivenessofourmethodinclarifyingtheuser’s
notfullycovermissingdetailsortheuserhasspe- task goal and making the agent execution more
cificrequirements,themodelcanstillreasonably efficient. Specifically,wemeasure:
andcomprehensivelysummarizealluserintentions, • UnnecessarySubtasks/Milestones: Theper-
thusmakingitmoreuser-friendly. centofsubtasksormilestonesthatareregardedCase A: Robustness to Varied User Tones and Conversation Styles Case B: Robustness in Dealing with Non-Cooperative Users
Set up a study plan for my upcoming law school Lookup for a healthy diet plan for a 30 years old male.
exams in two months.
……are you vegetarian, vegan, gluten-
……are you preparing for Civil Law, Criminal Law, or
free, or do you have no restrictions?
Constitutional Law, or perhaps a combination of these?
civli Analysis: Replies are short and contain typos The diet plan must be healthy Analysis: Useless replies
for a 30 years old male.
Great, focusing on Civil Law! …… Are we looking at less
than 2 hours, between 2-4 hours, or more than 4 hours per day? I understand you're looking for a healthy diet plan for a 30-year-old
male, but do you yourself have any specific dietary restrictions I
H Wo hw y c da on I I h h aa vv ee s t ui cm he a t o ti gs htu td sy c he ev de ury le d ?ay? Analysis: Angry replies s vh eo gu etld a rc io an ns , i vd ee gr? a nF ,o gr li un ts eta nn -fc re e, ea , r oe r y ao ru e l to ho ek ri en ng o f o rr e so tp rit cio tin os n l si ?ke
I understand that two months can feel like a short amount of time
for exam prep. Can you tell me more about your schedule? Case C: Complete Summary with Additional User Input
Find a recipe for homemade pizza.
Identify free online platforms for learning coding. gluten-free
( 2 rounds of
Margherita queries )
Are you looking to learn a specific programming language
or are you interested in general coding concepts?
Do you have any specific ingredient requirements? For
instance, should I look for a recipe that uses whole wheat
It doesn't matter Analysis: Replies are not specific
flour, or……
Great! Could you tell me about your experience level with I'd like a recipe that uses whole wheat
coding? Are you a beginner, intermediate, or advanced coder? flour, and also I don't like tomatoes.
No problem! I am a beginner. If there Analysis: Additional information
are any more details you need me to Analysis: Enthusiastic replies
provide, please feel free to ask me. Summary: Here are the user preferences and constraints:
- Gluten-free pizza recipe required.
- Prefers Margherita style pizza.
Thank you for your offer! What type of learning - Recipe should use whole wheat flour and exclude
resources do you prefer? …… tomatoes.
Figure4: Casestudiesofmodel-userinteractionsunderdifferentscenariostoshowMistral-Interact’srobustness.
as unnecessary by the user under the detailed 5.2.4 CaseStudy
taskgoalwithclearuserintentions.
To clearly illustrate Mistral-Interact’s role, we
• General Subtasks / Milestones: The percent
present a case study through comparison in Fig-
of subtasks or milestones that are too general,
ure 5. From the phrases marked red, we reveal
insteadoffocusingontheuser’sspecificinten-
thatwhentheuser’sgoalisvague,XAgenttends
tions.
tosetgeneralsubtasksandmilestones,insteadof
focusingononespecificlawsubjectortakinginto
• ToolInvocationsPerSubtask/Milestone: The
accounttheuser’sactualavailabletime. Fromthe
averagenumberoftoolinvocationsforonesub-
phrasesmarkedpurple,werevealthatXAgentalso
taskormilestone,whichreflectstheefficiency
sets subtasks and milestones that are sometimes
ofagentexecution.
unnecessary. Thisoccursastheuser’staskistoo
PleaserefertoAppendixF.1fordetailsonthemea-
vague to execute and XAgent tends to make up
surementofallmetrics.
unnecessarydetails(e.g. sourceevaluation),which
doesnotalignwiththeuser’strueintentions.
5.2.3 Results
Incontrast,afteractiveinteraction,thecleartask
We present the quantitative evaluation results in goal promotes tailored and specific subtasks and
Table4anddiscoverthatourmethodishelpfultoi) milestones. We show this alignment in phrases
avoidsettingunnecessarygoalsduringexecution, markedingreen. Atthesametime,theexecution
ii)maketheagentmorealignedwithdetaileduser flowbecomesmuchmoresimplified,andthetools
intentions,andiii)facilitateagenttoolexecutionef- appliedbecomemorefocused,withtoolinvocation
ficiency. AlltheseaspectsreflectMistral-Interact’s timessignificantlydecreasing. Allofthesereflect
effectivenessasanupstreamuser-agentinteraction amoreeffectiveandefficientagentexecutionpro-
expertinpromotingdownstreamagentexecution. cess.Unnecessary General ToolInvocationsPer
Scenarios
ST/MS(%) ST/MS(%) ST/MS
VagueTask(w/oMistral-Interact) 22.22/21.48 22.22/12.08 5.22/2.21
DetailedTask(w/Mistral-Interact) 1.85/7.81 0.00/0.78 4.79/2.02
Table4: ThecomparisonofagenttaskperformancewithorwithouttheincorporationofMistral-Interactasan
upstreammoduleforinteraction. ST denotessubtaskandMSdenotesmilestone.
Subtask / Milestone not necessary, Not necessary, total
Subtask / Milestone too general, Access and download material. source evaluation is not important time available (2
not focusing on Criminal Law. Identify source websites months) is provided
for study materials.
Organize study materials from Download all relevant Develop a study timetable with
all relevant law subjects. materials from sources. adequate review time.
Vague User Goal
Gather all necessary Access total study time
Set up a study plan for my upcoming study aid. available until exam.
law school exams in two months. Identify key topics in … … Create comprehensive
each subject area. Perform source evaluation. & flexible schedule.
User UnI dn et re sn tati no dn i ng O acr cg ea sn si iz be le m foat re mri aa tl .s in L foi rs t e p ao chte sn uti ba jl e s co t.urces A sul blo jec ca tt e c oti mm pe l eb xa is te yd . on fT oo cuo s g oe nn e inra dl e, p s eh no du el nd t
Evaluate the reliability learning within 5
… … of each source. hours a day.
… … ? Tool Execution
Design a schedule allocating 5
hours daily for essay writing
Identify key Criminal Law Gather direct link and perform practice over two months.
Create an intensive Criminal Law subjects and essay topics. data collection.
study plan focusing on essays for a Study timetable to be Subtask / Milestone
law school examinee who prefers List of Criminal Law Accessed the specified … … established. is detailed and clear,
independent learning, allocating 5 subjects created. URL for web searching. Allocation of subjects more aligned with
Mistral- hours daily over two months. Selection of top essay Criminal Law essays and topics across the user’s intentions
Interact topics done. downloaded. schedule completed.
Summary with Intentions
Figure5: CasestudyontheagentexecutionprocessbeforeandafterinteractionwithMistral-Interactinagent
design.
6 Discussions the adapted model’s performance and indirectly
through the downstream agent’s execution. The
Incorporatingmodel-userinteractioninagent
metricsweproposecouldbeimprovedtoencom-
scenarios. Currently,agentdesignstypicallyrel-
passadditionalfacets. Forinstance,duringagent
egatehumanstoperipheralroles,whichmotivates
execution,userinputsareunpredictable,andthus
ourworkonimprovingthelanguagemodel’sabil-
theinterpretationofuserintentionscouldinclude
itytounderstanduser’simplicitintentionsbefore
moredimensionslikewhethertheyareproviding
agent execution. This limitation can also be ad-
moreinformation,interruptinganexecution,ask-
dressed through alternative methods, including
ingforprogressupdates,orintroducinganewtopic,
mechanismsthatfacilitateinteractionsduringagent
ratherthansolelyfocusingontaskvagueness. Fur-
execution. Ideally,anagentsystemshouldbeable
thermore, while we strive to quantify subjective
topromptlyqueryuserswhenfacedwithmultiple
humanevaluationsintoobjectivenumericalvalues
options, unclear instructions, critical tool invoca-
forcomparison,othertechniquescouldalsobeinte-
tionerrors,etc. Moreover,usersoughttobemore
grated,suchasdirectevaluationofusersatisfaction
actively involved in the agent execution, which
withtheinteraction,theirimmediateperceptionsof
couldinvolvearbitraryuserinterruptionsthrough-
theconversation’scoherence,andtheiropinionson
out the tool invocation process, the granting of
thedownstreamagent’sfinaloutputs. Thesecould
permissionsforpotentiallyriskyagentactions,etc.
yieldamoreholisticevaluation,albeitpotentially
Both aspects require complex and nuanced coor-
introducingindividualbias.
dination within the agent system, as opposed to
simplyadaptingandleveragingasinglemodelex-
Employing language models to emulate users.
pert’scapability. Thisremainsanexcitingfieldfor
InconstructingtheIN3dataset,weusedGPT-4to
futureresearchefforts.
imitate users, leveraging the model’s proficiency
Assessingmodel-userinteraction. Ourprimary inemulatingdifferentrolesviacarefulprompting.
method for evaluating interaction is through im- Forexample,itcaneffectivelyimitateuserswith
plicit intention understanding, both directly via varyingtones(e.g.,angry,passionate)andresponsestyles (e.g., succinct, verbose). This possesses Maciej Besta, Nils Blach, Ales Kubicek, Robert Ger-
broad implications as it: i) encourages unsuper- stenberger,LukasGianinazzi,JoannaGajda,Tomasz
Lehmann,MichalPodstawski,HubertNiewiadomski,
vised model-(model-simulated) user interactions,
PiotrNyczyk,etal.2023. Graphofthoughts: Solv-
which could subsequently be used for the assis-
ingelaborateproblemswithlargelanguagemodels.
tant model’s reinforcement learning; ii) supports arXivpreprintarXiv:2308.09687.
automatedagentevaluation,asbenchmarkscould
CWanlingCaiandLiChen.2020. Predictinguserin-
becreatedusingsolelymodel-simulatedusers,by-
tentsandsatisfactionwithdialogue-basedconversa-
passingtheneedforrealusersintime-consuming
tionalrecommendations.
agentexecutionsandinteractions. Inaddition,the
currentmethodisagnosticofrealuserpreference TianleCai, XuezhiWang, TengyuMa, XinyunChen,
andDennyZhou.2024. Largelanguagemodelsas
data; ifthemodelcanaccessanindividual’spast
toolmakers. InTheTwelfthInternationalConference
conversationhistory,itcouldbetterrepresentspe-
onLearningRepresentations.
cificindividualpreferences,thusfacilitatingbetter
coherency and faithfulness of implicit user inten- Chi-MinChan,WeizeChen,YushengSu,JianxuanYu,
tions. WeiXue,ShanghangZhang,JieFu,andZhiyuanLiu.
2023. Chateval: Towardsbetterllm-basedevaluators
7 Conclusion throughmulti-agentdebate.
Thisworkinvestigatestheenhancementandevalu- LongChen,DellZhang,andLeveneMark.2012. Un-
derstanding user intent in community question an-
ationofimplicitintentionunderstandinginagent
swering. In Proceedings of the 21st international
designs. Specifically,wereleasetheIntention-in-
conferenceonworldwideweb,pages823–828.
Interaction(IN3)benchmarkwhichencompasses
awiderangeofvagueagenttaskswithannotated Tianqi Chen and Carlos Guestrin. 2016. Xgboost: A
scalabletreeboostingsystem.
missing details to evaluate the agent’s intention
understandingcapability. Inaddition,wepropose
Weiwen Chen, Mohammad Shidujaman, Jiangbo Jin,
to integrate a special model expert into agent de- andSalahUddinAhmed.2020. Amethodological
signsforrobustinteraction. Empirically,wetrain approach to create interactive art in artificial intel-
Mistral-Interact,apowerfulopen-sourcemodelca- ligence. In HCI International 2020 – Late Break-
ingPapers: Cognition,LearningandGames: 22nd
pable of effectively judging user task vagueness,
HCI International Conference, HCII 2020, Copen-
friendly inquiring about missing details with rea- hagen, Denmark, July 19–24, 2020, Proceedings,
sonableoptions,andcomprehensivelysummariz- page13–31,Berlin,Heidelberg.Springer-Verlag.
inguserintentionswithoutomission. Integrating
Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang,
Mistral-Interact into the XAgent framework, we
ChenfeiYuan,Chi-MinChan,HeyangYu,YaxiLu,
evaluatetheenhancedagentsystemthroughboth
Yi-Hsin Hung, Chen Qian, Yujia Qin, Xin Cong,
instructionunderstandingandinstructionexecution Ruobing Xie, Zhiyuan Liu, Maosong Sun, and Jie
toillustrateourmethod’seffectiveness. Overall,we Zhou. 2024. Agentverse: Facilitating multi-agent
collaborationandexploringemergentbehaviors. In
areamongthefirstworkstofocusonuserparticipa-
The Twelfth International Conference on Learning
tionandimplicitintentionunderstandinginagent
Representations.
designsandevaluations. Wehopeourworkcanin-
spiremorefutureresearchonrobusthuman-agent AakankshaChowdhery,SharanNarang,JacobDevlin,
MaartenBosma,GauravMishra,AdamRoberts,Paul
interactionevaluationbenchmarksandmechanisms
Barham,HyungWonChung,CharlesSutton,Sebas-
thatenhanceefficiencyandeffectiveness.
tianGehrmann,etal.2023. Palm: Scalinglanguage
modelingwithpathways. JournalofMachineLearn-
ingResearch,24(240):1–113.
References
EvaA.C.BittnerChristinaWiethof,NavidTavanapour.
MichaelAhn,AnthonyBrohan,NoahBrown,Yevgen
2021. Implementing an intelligent collaborative
Chebotar,OmarCortes,ByronDavid,ChelseaFinn,
agentasteammateincollaborativewriting: towarda
ChuyuanFu,KeerthanaGopalakrishnan,KarolHaus-
synergyofhumansandai.
man,etal.2022. Doasican,notasisay: Ground-
inglanguageinroboticaffordances. arXivpreprint
Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon,
arXiv:2204.01691.
PengfeiLiu, YimingYang, JamieCallan, andGra-
AutoGPT.2023. Autogpt. ham Neubig. 2023. Pal: Program-aided language
models. In International Conference on Machine
BabyAGI.2023. Babyagi. Learning,pages10764–10799.PMLR.Tanmay Gupta and Aniruddha Kembhavi. 2023. Vi- modelcenter. 2023. modelcenter. https://github.
sualprogramming: Compositionalvisualreasoning com/OpenBMB/ModelCenter.
withouttraining. InProceedingsoftheIEEE/CVF
ConferenceonComputerVisionandPatternRecog- ReiichiroNakano,JacobHilton,SuchirBalaji,JeffWu,
nition,pages14953–14962. Long Ouyang, Christina Kim, Christopher Hesse,
ShantanuJain,VineetKosaraju,WilliamSaunders,
Shibo Hao, Yi Gu, Haodi Ma, Joshua Hong, Zhen
et al. 2021. Webgpt: Browser-assisted question-
Wang, Daisy Wang, and Zhiting Hu. 2023. Rea-
answering with human feedback. arXiv preprint
soningwithlanguagemodelisplanningwithworld
arXiv:2112.09332.
model. In Proceedings of the 2023 Conference on
EmpiricalMethodsinNaturalLanguageProcessing,
OpenAI.2022. Chatgpt.
pages8154–8173,Singapore.AssociationforCom-
putationalLinguistics.
OpenAI.2023. Gpt-4technicalreport.
ChenxuHu,JieFu,ChenzhuangDu,SimianLuo,Junbo
Zhao,andHangZhao.2023. Chatdb: Augmenting JoonSungPark,JosephO’Brien,CarrieJunCai,Mered-
llmswithdatabasesastheirsymbolicmemory. ithRingelMorris,PercyLiang,andMichaelSBern-
stein.2023. Generativeagents: Interactivesimulacra
Jian Hu, Gang Wang, Fred Lochovsky, Jian-tao Sun, ofhumanbehavior. InProceedingsofthe36thAn-
andZhengChen.2009. Understandinguser’squery nual ACM Symposium on User Interface Software
intent with wikipedia. In Proceedings of the 18th andTechnology,pages1–22.
internationalconferenceonWorldwideweb,pages
471–480.
Shishir G. Patil, Tianjun Zhang, Xin Wang, and
JosephE.Gonzalez.2023. Gorilla: Largelanguage
Wenlong Huang, Pieter Abbeel, Deepak Pathak, and
modelconnectedwithmassiveapis.
IgorMordatch.2022. Languagemodelsaszero-shot
planners: Extractingactionableknowledgeforem-
Chen Qian, Xin Cong, Wei Liu, Cheng Yang, Weize
bodiedagents. InInternationalConferenceonMa-
Chen,YushengSu,YufanDang,JiahaoLi,Juyuan
chineLearning,pages9118–9147.PMLR.
Xu,DahaiLi,ZhiyuanLiu,andMaosongSun.2023a.
AlbertQ.Jiang,AlexandreSablayrolles,ArthurMen- Communicativeagentsforsoftwaredevelopment.
sch,ChrisBamford,DevendraSinghChaplot,Diego
delasCasas,FlorianBressand,GiannaLengyel,Guil- Cheng Qian, Chi Han, Yi Fung, Yujia Qin, Zhiyuan
laumeLample,LucileSaulnier,LélioRenardLavaud, Liu,andHengJi.2023b. Creator: Toolcreationfor
Marie-AnneLachaux,PierreStock,TevenLeScao, disentanglingabstractandconcretereasoningoflarge
Thibaut Lavril, Thomas Wang, Timothée Lacroix, language models. In Findings of the Association
andWilliamElSayed.2023. Mistral7b. forComputationalLinguistics: EMNLP2023,pages
6922–6939.
QiaoJin,YifanYang,QingyuChen,andZhiyongLu.
2023. Genegpt: Augmentinglargelanguagemodels
Cheng Qian, Chenyan Xiong, Zhenghao Liu, and
withdomaintoolsforimprovedaccesstobiomedical
Zhiyuan Liu. 2023c. Toolink: Linking toolkit cre-
information. ArXiv.
ation and using through chain-of-solving on open-
sourcemodel.
Bhushan Kotnis, Kiril Gashteovski, Julia Gastinger,
Giuseppe Serra, Francesco Alesiani, Timo Sztyler,
Ammar Shaker, Na Gong, Carolin Lawrence, and Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen,
ZhaoXu.2022. Human-centricresearchfornlp: To- Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang,
wardsadefinitionandguidingquestions. ChaojunXiao,ChiHan,YiRenFung,YushengSu,
HuadongWang,ChengQian,RunchuTian,Kunlun
Hui-Chi Kuo and Yun-Nung Chen. 2023. Zero-shot Zhu,ShihaoLiang,XingyuShen,BokaiXu,Zhen
promptingforimplicitintentpredictionandrecom- Zhang,YiningYe,BowenLi,ZiweiTang,JingYi,
mendationwithcommonsensereasoning. Yuzhang Zhu, Zhenning Dai, Lan Yan, Xin Cong,
Yaxi Lu, Weilin Zhao, Yuxiang Huang, Junxi Yan,
Guohao Li, Hasan Abed Al Kader Hammoud, Hani
Xu Han, Xian Sun, Dahai Li, Jason Phang, Cheng
Itani,DmitriiKhizbullin,andBernardGhanem.2023.
Yang, Tongshuang Wu, Heng Ji, Zhiyuan Liu, and
Camel: Communicative agents for "mind" explo-
MaosongSun.2023. Toollearningwithfoundation
rationoflargelanguagemodelsociety.
models.
Bohan Lyu, Xin Cong, Heyang Yu, Pan Yang, Yujia
Qin,YiningYe,YaxiLu,ZhongZhang,YukunYan, YujiaQin,ShihaoLiang,YiningYe,KunlunZhu,Lan
YankaiLin,ZhiyuanLiu,andMaosongSun.2023. Yan,YaxiLu,YankaiLin,XinCong,XiangruTang,
Gitagent: Facilitatingautonomousagentwithgithub BillQian,SihanZhao,LaurenHong,RunchuTian,
bytoolextension. Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li,
ZhiyuanLiu,andMaosongSun.2024. Toolllm: Fa-
McAuleyJulianMajumderBodhisattwaPrasad.2023. cilitating large language models to master 16000+
User-centricnaturallanguageprocessing. UCSan real-worldapis. InTheTwelfthInternationalConfer-
DiegoElectronicThesesandDissertations. enceonLearningRepresentations.ChenQu,LiuYang,WBruceCroft,JohanneRTrippas, ZhengYan,IliyanZarov,YuchenZhang,AngelaFan,
YongfengZhang,andMinghuiQiu.2018. Analyzing Melanie Kambadur, Sharan Narang, Aurelien Ro-
andcharacterizinguserintentininformation-seeking driguez,RobertStojnic,SergeyEdunov,andThomas
conversations. InThe41stinternationalacmsigir Scialom. 2023b. Llama 2: Open foundation and
conferenceonresearch&developmentininforma- fine-tunedchatmodels.
tionretrieval,pages989–992.
Vikramkumar, Vijaykumar B, and Trilochan. 2018.
TimoSchick,JaneDwivedi-Yu,RobertoDessi,Roberta Bayesandnaivebayesclassifier.
Raileanu,MariaLomeli,EricHambro,LukeZettle-
moyer,NicolaCancedda,andThomasScialom.2023. Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Man-
Toolformer: Languagemodelscanteachthemselves dlekar,ChaoweiXiao,YukeZhu,LinxiFan,andAn-
tousetools. InThirty-seventhConferenceonNeural imaAnandkumar.2023a. Voyager: Anopen-ended
InformationProcessingSystems. embodiedagentwithlargelanguagemodels. arXiv
preprintarXiv:2305.16291.
Bilgehan Sel, Ahmad Al-Tawaha, Vanshaj Khattar,
LuWang,RuoxiJia,andMingJin.2023. Algorithm LeiWang,ChenMa,XueyangFeng,ZeyuZhang,Hao
ofthoughts: Enhancingexplorationofideasinlarge Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang,
languagemodels. arXivpreprintarXiv:2308.10379. XuChen,YankaiLin,etal.2023b. Asurveyonlarge
language model based autonomous agents. arXiv
YelongShen,JunYan,ShuichengYan,LeiJi,NingLiu, preprintarXiv:2308.11432.
andZhengChen.2011. Sparsehidden-dynamicscon-
ditionalrandomfieldsforuserintentunderstanding. YizhongWang,YeganehKordi,SwaroopMishra,Alisa
InProceedingsofthe20thinternationalconference Liu,NoahA.Smith,DanielKhashabi,andHannaneh
onWorldwideweb,pages7–16. Hajishirzi.2023c. Self-instruct: Aligninglanguage
modelswithself-generatedinstructions. InProceed-
YongliangShen,KaitaoSong,XuTan,DongshengLi, ingsofthe61stAnnualMeetingoftheAssociationfor
WeimingLu,andYuetingZhuang.2023. Hugging- ComputationalLinguistics(Volume1: LongPapers),
gpt: Solvingaitaskswithchatgptanditsfriendsin pages13484–13508,Toronto,Canada.Association
huggingface. arXivpreprintarXiv:2303.17580. forComputationalLinguistics.
Noah Shinn, Federico Cassano, Ashwin Gopinath, JasonWei,XuezhiWang,DaleSchuurmans,Maarten
KarthikRNarasimhan,andShunyuYao.2023. Re- Bosma,FeiXia,EdChi,QuocVLe,DennyZhou,
flexion: Languageagentswithverbalreinforcement etal.2022. Chain-of-thoughtpromptingelicitsrea-
learning. In Thirty-seventh Conference on Neural soninginlargelanguagemodels. AdvancesinNeural
InformationProcessingSystems. InformationProcessingSystems,35:24824–24837.
KieranOSullivan.2018. Comparingtheeffectiveness
ChenfeiWu, ShengmingYin, WeizhenQi, Xiaodong
of support vector machines and convolutional neu-
Wang, Zecheng Tang, and Nan Duan. 2023a.
ralnetworksfordetermininguserintentinconversa-
Visual chatgpt: Talking, drawing and editing
tionalagents. with visual foundation models. arXiv preprint
arXiv:2303.04671.
HugoTouvron,ThibautLavril,GautierIzacard,Xavier
Martinet,Marie-AnneLachaux,TimothéeLacroix,
Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu,
BaptisteRozière,NamanGoyal,EricHambro,Faisal
Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang,
Azhar,AurelienRodriguez,ArmandJoulin,Edouard
ShaokunZhang,JialeLiu,AhmedHassanAwadal-
Grave,andGuillaumeLample.2023a. Llama: Open
lah, Ryen W White, Doug Burger, and Chi Wang.
andefficientfoundationlanguagemodels.
2023b. Autogen: Enablingnext-genllmapplications
viamulti-agentconversation.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Zhuohao Wu, Danwen Ji, Kaiwen Yu, Xianxu Zeng,
Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti
DingmingWu,andMohammadShidujaman.2021.
Bhosale,DanBikel,LukasBlecher,CristianCanton
Aicreativityandthehuman-aico-creationmodel. In
Ferrer,MoyaChen,GuillemCucurull,DavidEsiobu,
Human-ComputerInteraction.Theory,Methodsand
JudeFernandes,JeremyFu,WenyinFu,BrianFuller,
Tools: Thematic Area, HCI 2021, Held as Part of
CynthiaGao,VedanujGoswami,NamanGoyal,An-
the23rdHCIInternationalConference,HCII2021,
thonyHartshorn,SagharHosseini,RuiHou,Hakan
VirtualEvent,July24–29,2021,Proceedings,PartI,
Inan,MarcinKardas,ViktorKerkez,MadianKhabsa,
page171–190,Berlin,Heidelberg.Springer-Verlag.
IsabelKloumann,ArtemKorenev,PunitSinghKoura,
Marie-AnneLachaux,ThibautLavril,JenyaLee,Di- XAgent-Team. 2023. Xagent: An autonomous agent
anaLiskovich,YinghaiLu,YuningMao,XavierMar- forcomplextasksolving.
tinet,TodorMihaylov,PushkarMishra,IgorMoly-
bog, Yixin Nie, Andrew Poulton, Jeremy Reizen- ZhihengXi,WenxiangChen,XinGuo,WeiHe,Yiwen
stein,RashiRungta,KalyanSaladi,AlanSchelten, Ding, Boyang Hong, Ming Zhang, Junzhe Wang,
Ruan Silva, Eric Michael Smith, Ranjan Subrama- Senjie Jin, Enyu Zhou, et al. 2023. The rise and
nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay- potential of large language model based agents: A
lor, Adina Williams, Jian Xiang Kuan, Puxin Xu, survey. arXivpreprintarXiv:2309.07864.Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran,
Thomas L. Griffiths, Yuan Cao, and Karthik R
Narasimhan. 2023. Tree of thoughts: Deliberate
problem solving with large language models. In
Thirty-seventh Conference on Neural Information
ProcessingSystems.
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak
Shafran,KarthikNarasimhan,andYuanCao.2022.
React: Synergizingreasoningandactinginlanguage
models. arXivpreprintarXiv:2210.03629.
YiningYe,XinCong,YujiaQin,YankaiLin,Zhiyuan
Liu, and Maosong Sun. 2023a. Large language
modelasautonomousdecisionmaker. arXivpreprint
arXiv:2308.12519.
YiningYe,XinCong,ShizuoTian,JiannanCao,Hao
Wang, Yujia Qin, Yaxi Lu, Heyang Yu, Huadong
Wang,YankaiLin,ZhiyuanLiu,andMaosongSun.
2023b. Proagent: Fromroboticprocessautomation
toagenticprocessautomation.
Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang,
Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu,
WendiZheng,XiaoXia,etal.2022. Glm-130b: An
openbilingualpre-trainedmodel. InTheEleventhIn-
ternationalConferenceonLearningRepresentations.
XinghuaZhang, BowenYu, HaiyangYu, YangyuLv,
TingwenLiu,FeiHuang,HongboXu,andYongbin
Li.2023. Wideranddeeperllmnetworksarefairer
llmevaluators. arXivpreprintarXiv:2308.01862.Appendix onmissingdetails,importancescoresandpotential
optionswillallbeomitted.
A Intention-in-InteractionBenchmark
Weemploydifferentpeoplewithdiverseback-
A.1 TaskGeneration groundstoannotatethedata,eachpersonincharge
ofseveraltasks. Theannotationscouldthusreflect
ForthetasksinIN3,wemanuallycreateseeddata
differentpeople’spreferencesandensurediversity.
andgenerateagenttasksiterativelyusingthesys-
WealsoemployGPT-4tohelpwiththeannotation.
tem prompt as follows. For each category, we
GPT-4willprovidesuggestionsontaskvagueness
calculate the embeddings of the task using text-
andpotentiallymissingdetailsasreferences,and
embedding-ada-002andperformfilteringtoensure
annotatorsonlyneedtodothefilteringandinfor-
thecosinesimilaritybetweenanytwotasksisless
mationupdatestomakeannotationsalignedwith
than0.8.
theirpreferencesandintentions. GPT-4’ssugges-
tionsarecompletedthroughtoolcalling,withthe
Instruction(SystemPrompt)
systempromptandthespecifictoolasfollows:
You are a task-generation engine. Your
mission is to generate tasks in everyday
Instruction(SystemPrompt)
life that could be fulfilled by an
agent. The agent working for you has the
You are an agent judging if the user’s
following accesses:
task goal is vague or not.
--- Agent Resources ---
Vague: The user’s task is too general,
- Internet Access for searches and
missing some important details that are
information gathering.
necessary to understand the user’s
- A File System Environment to read and
intention, or missing some preference
write files (text, code, markdown, latex
details that could better help the user
...).
in achieving the task goal.
- A Python Notebook to execute Python
Clear: The user is already clear enough
code.
about the task, providing enough details
- A ShellEnv with root privilege to
about the task goal, personal
execute bash command.
preference, etc.
--- Task Description ---
Based on what you know about the agent,
If the task is vague, provide what
you can generate tasks that are suitable
details are missing, or what further
for the agent to solve. You should
information is needed. There may be
generate tasks in a first-person tone,
multiple missing details.
it should be clear, but don’t provide
For each missing information, please
too many details or unnecessary
also provide a query to the user asking
information.
for this missing information, and
--- Important Note ---
provide a list of options that the user
- Make your generated tasks as diverse
could choose from.
as possible. The user will provide some
examples but do not copy the contents.
- Generate tasks of different
difficulties, and they are all solvable FunctionTool
by the agent using resources.
name: judge_vagueness
- The tasks, should be grounded in the
description: "Judge if the user’s task
real world, but also keep it vague. Use
goal is vague or not, and provide
just one sentence and do not provide too
what details or personal preferences
many details.
are missing."
- Please list your generated tasks
parameters:
through tool call.
type: "object"
properties:
A.2 HumanAnnotation thought:
type: "string"
During annotation, the importance level of each description: "Generate thought
about why this task goal is
missingdetailisannotatedthroughthefollowing
vague or clear. Please refer to
rules. Lv 3: Very important, task cannot be fully the description of vague and
executed without it; Lv 2: Relatively important: clear in the system prompt."
judgment:
knowingitcanbetterhelptheuserexecutethetask,
type: "string"
butnotthatnecessary; Lv1: Notveryimportant, enum: ["vague", "clear"]
it is too detailed or general, the task can still run description: "Based on your
thought, choose if the task is
successfully without knowing it. Note that if as
vague or clear."
task is annotated as clear, its further annotations missings:type: "array" B PreliminaryExperiment
description: "The details that
are missing in understanding the B.1 Settings
user’s task intention or
preferences. Leave the array Tasks. WerandomlysampledtentasksfromIN3
empty if the task is clear. toconductapreliminarytestondifferentmodels’
There could be multiple missing
intentionunderstandingability. Thespecifictasks
details. Each missing detail
should be specific." areasfollows:
items:
type: "object"
TasksList
properties:
description:
1. Category: Health Research
type: "string"
Task: Find the latest research on
description: "Description
diabetes treatment.
of what detail is missing
Vague: True
in a short way."
Missing Details:
importance:
- Type of diabetes
type: "string"
- Aspect of treatment
enum: ["3", "2", "1"]
- Source of research
description: "Give each
- time of when the research is published
missing detail an
importance score. 3: Very
2. Category: Animal Studies
important, task cannot be
Task: Find the average lifespan of a
fully executed without it;
domestic cat.
2: Relatively important:
Vague: False
knowing it can better help
Missing Details: None
the user execute the task
, but not that necessary;
3. Category: Coding Project
1: Not very important, it
Task: Write a Python script that sorts
is too detailed or general
images based on their content.
, the task can still run
Vague: True
successfully without
Missing Details:
knowing it."
- Criteria for sorting images
inquiry:
- Source of images
type: "string"
- Output format
description: "Form an
- Preferred libraries or methods
inquiry to the user asking
- Level of accuracy expected
for this missing detail.
Inquiry like you are
4. Category: Financial
chatting with the user."
Task: Look up the current exchange rate
options:
from USD to Euro.
type: "array"
Vague: False
description: "Provide some
Missing Details: None
possible options for the
user to choose from.
5. Category: Writing Task
Please always provide 2-3
Task: Write a summary of a given text
possible options or
file.
suggestions to inspire the
Vague: True
user."
Missing Details:
items:
- Purpose of the summary
type: "string"
- Subject matter of the text file
description: "Options or
- Intended audience
suggestions to this
- Path to the text file
missing detail. Make the
- Length of the summary
options very short and
specific (e.g. just
6. Category: Traveling
using phrases)"
Task: Find the cheapest round-trip
required: ["description", "
flights from New York to London next
inquiry", "importance", "
month.
options"]
Vague: True
required: ["thought", "judgment", "
Missing Details:
missings"]
- Specific dates of travel within the
month
- Preferred airlines, airports, or
alliances
- Preferred time of day for flying
- Cabin class preference
7. Category: HardwareTask: Write bash command to check my summary of the user’s detailed goal.
system specification. 6. Do not solve the task, just provide a
Vague: True detailed summary of the task and user
Missing Details: preference in the end. Summarize the
- Specific system specifications of information you got in 1-2 sentences.
interest
- Output format You should follow the format, first
provide your thoughts, then ask the user
8. Category: Health Advise for more information or provide a
Task: Locate the nearest yoga class with summary:
the best reviews in my city. Thought: ... Query: ... (You would like
Vague: True to query the user)
Missing Details: OR: Thought: ... Summary: ... (You have
- User’s city gathered enough information and could
- Distance willing to travel make a summary)
- Criteria for best reviews The user will provide a task as the
- Preferred style of yoga following.
9. Category: Music Analysis
Task: Find out what the top five B.2 Evaluation
Billboard hits are this week.
Vague: False Weconductbothquantitativeandqualitativeevalu-
Missing Details: None
ationsofthemodelperformance. Asthenumberof
tasksissmall,thequantitativeresultsarecounted
10. Category: Anime
Task: Find a list of the top-rated Anime manuallybycomparingthemodel’sresponsewith
series in 2021.
theannotation.
Vague: False
Missing Details: None Forthequalitativeanalysis,wemanuallyidentify
thefailurepatternsintheinteractionrecords. For
ModelSetting. Forthespecificmodels,wefully eachpattern, weconsideritassevereifacertain
considered their conversation ability and applied modelexhibitsthispatterninmorethanthreetasks
the newest versions. We finally chose Mistral- among ten, and consider it as light if a certain
7B-Instruct-v0.2,LLaMA-2-7B-Chat,andGPT-4- modelexhibitsthispatternbutinlessthan(orequal
1106asthetestingmodel. Forallthemodels,we to) three tasks. All the judgments are consensus
setthetemperatureto0.7,top_pto0.9,andmaxi- amongatleastthreedifferentannotators.
mumsequencelengthto2048. Eachtaskistested
once. B.3 CaseStudy
Wepresentacasestudyondifferentfailedinterac-
SystemPrompt. Weapplythesameinstruction
tion patterns between the model and user in Fig-
topromptallthreemodels. Thedetailedcontentis
ure6. Allthecasesaregatheredfromrealmodel-
asfollows:
userconversationrecordswithanalysisonthespe-
cificinappropriatebehaviors. Foreithervagueor
Instruction(SystemPrompt)
clear tasks, we show how and why the model re-
You are trying to understand the user’s
sponsesininteractionsmaketheuserunsatisfied.
intention. The user will provide a task
that may be clear or vague (they may not
provide their own preferences). C ConstructionofTrainingData
1. In the very first round of thought,
you should explicitly judge if the task
For each task in IN3, we apply GPT-4 to simu-
is vague or clear and why.
lateboththeassistant(Assistant-GPT)andtheuser
2. If the task is vague, you should ask
the user for more information with (User-GPT)duringtheconversation. Theconver-
options for the user to choose from. If
sation consists of three parts, respectively initial
it is clear, then do not query and
repeat the user’s task in the summary. thought,inquiries,andsummary.
3. Please only ask one question with
options at a time. You could ask the InitialThought. Accordingtotheannotationfor
user for multiple rounds until you think
each task, we manually construct the explicit ini-
the user’s goal is clear enough.
4. Your questions should be about tial thought by concatenating information on the
different missing details and aspects, judgmentoftaskvagueness,thereasonsforit,the
be diverse.
missingdetailsifexists, andtheoptionsfor each
5. When you think you have gathered
enough information, you should provide a missingdetail.Vague Vague
Find the latest research on diabetes treatment. Locate the nearest yoga class with the best
reviews in my city.
Research on a specific type of diabetes, such as type 1 or
type 2? Hot Yoga.
( 3 rounds of
I would like to focus on type 1. Moderate Temperature. queries )
Here are some search results: Beginner Level.
• A study published in the Journal of the American Medical
Association found that a new drug called XYZ Summary: The user prefer a yoga class that is
significantly reduced blood sugar. - hot yoga class
• A study published in Diabetes Care found … … - moderate temperature level
- focus on flowing sequences
( You should summarize my preferences ... )
( I didn’t say that …)
Analysis: Not summarization of preferences; Hallucination in information
Analysis: Missing details in summary; Hallucinate human preferences
Clear
Look up the current exchange rate from USD to Euro. Vague
Find the cheapest round-trip flights from New York
Please provide more information about current date or time to London next month.
(options: today, yesterday, last week)
Which specific date next month would you like to
( Ah? Current just means now ... ) fly? Early, Mid, or late next month?
Feb. 12th to 14th.
Analysis: Fail to judge vagueness; Unnecessary query and options
Summary: The user is looking for the cheapest
round-trip flights from New York to London
Vague between February 12th and 14th.
Write a summary of a given text file.
Start!
What is the length of the summary?
Are there any specific themes or aspects of the text? Still don’t know preferred airline,
What is the subject matter or genre of the text file? cabin, ...
Do you have any other preferences? Agent Execution
( WoW so many questions! Where to start ... ) ( Starting that fast?! I’m not finished ... )
Analysis: Too many queries a time; No options provided for inspiration Analysis: Query too few; Didn’t fully understand user preferences
Figure6: Anoverviewofdifferentfailedmodel-userinteractionpatterns.
Inquiries. Next,wepromptbothAssistant-GPT follow-up inquiry (from the user’s last
and User-GPT to simulate the conversation with response). Please use thought to show
why you made this inquiry.
the following instructions. Note that to simulate
4. Please only inquire for one question
differentusertones,wecreatetwoversionsofin- in one round of chatting. You can
inquire for multiple rounds, but please
structions.
control the total rounds to be less than
five. (The user is impatient, make your
AssistantSideInstruction(SystemPrompt) inquiry efficient!)
5. Choose to stop if you think the
information you have gathered is enough.
You are an agent trying to specify and
Remember you don’t need to ask for
understand the user’s task goal. The
every detail!
user will ask you a query or ask you to
execute a task. However, the user is
You are talking about <category> with
unclear about the task or intention. You
the user. This is what you’d like to ask
should ask the user for more
or do: <task>
information to understand the user’s
This is your initial thought: <thought>
intention.
This is the list of possible inquiry
aspects (reference list):
Here are some rules to follow:
<missing details>
1. You are given the initial thought and
a list of possible inquiry aspects and
an option list. Please use this
information as a reference when UserSideInstruction(SystemPrompt)
inquiring.
2. For each inquiry, provide the user You are an assistant who pretends to be
with options or some suggestions. Use a the user’s friend and responds to the
first-person tone like chatting with the user. The user is trying to understand
user, and be friendly. your specific needs and intentions and
3. You can ask either a new question ( may ask you some questions. You should
from the reference, with options) or a provide the information to the user inone sentence. preferences and constraints, and
providing a detailed summary. Respond
Here are some tips during chatting to naturally and succinctly."
make your response more real. parameters:
[Passionate User Tone Version] type: "object"
1. Respond naturally, and you are properties:
passionate. You can provide more if you thought:
are happy with it. Keep your tone type: "string"
friendly and positive. description: "Why do you think
[Succinct User Tone Version] you have gathered enough
1. Respond succinctly, and you are lazy. information to understand the
You should respond more often with user’s intention, or why the
short phrases. Make your responses short initial task is clear enough."
and effective. constraints:
type: "array"
2. When you are asked about some description: "A list of user
personal preference, information, or preferences and constraints
address, please make up some information based on the interaction history
and preference and provide it to the . The number of items should be
user. Make sure to be specific and as equal to the rounds of chatting.
real as possible. Leave the array empty if the
initial task is clear."
You are talking about <category> with items:
the user. This is what you’d like to ask type: "string"
or do: <task> description: "The user’s
preference or constraint in
the first, second, third, etc.
Summary. We prompt Assistant-GPT to make round of chatting. Summarize
explicit summary thoughts and final summary and list them one by one. Make
it detailed and succinct."
through tool call. Specifically, the summary
summary:
thoughtismanuallyconstructedbyexplicitlycon- type: "string"
catenating the original thought and a list of con- description: "Summarize the user
’s task goal and the constraints
straints that reflect user preferences or new addi-
in a detailed, efficient, and
tionalinformation. Iftheoriginaltaskisclear,then succinct way within two
sentences. Do not provide not-
the constraints are omitted. The instruction and
mentioned or unnecessary
toolarerespectivelyasfollows:
information."
required: ["thought", "constraints",
"summary"]
Instruction(SystemPrompt)
You are an agent trying to summarize the
user’s intention and provide a detailed D TrainingDetails
summary.
D.1 SystemPrompt
First, provide thought about why you
think you have gathered enough
Weapplythefollowingsystemprompttotrainthe
information to understand the user’s
intention, or why the initial task is model. Itisincorporatedatthebeginningofeach
clear enough. finaltrainingdatapoint. Thedetailedcontentisas
Secondly, if there is an interaction
follows:
history, explicitly list the user’s
provided constraints or preferences one
by one in a list. Instruction(SystemPrompt)
Lastly, provide a detailed summary,
including the task goal and all the user You are an agent trying to understand
’s constraints and preferences. You the user’s goal and summarize it. Please
should respond naturally within 2 first ask users for more specific
sentences (make your language succinct, details with options, and finally
short, and efficient). summarize the user’s intention.
--- Step 1: initial thought generation
The user’s original task is: <task> ---
1. Generate [INITIAL THOUGHT] about if
the task is vague or clear and why.
FunctionTool 2. List the important missing details
and some according options if the task
name: complete_summary is vague.
description: "Complete the summary by --- Step 2: inquiry for more information
providing thought, listing user if vague ---1. If the task is vague, inquire about [INQUIRY THOUGHT] {inquiry_thought}
more details with options according to [INQUIRY] {inquiry}
the list in [INITIAL THOUGHT]. (User Response)
2. Think about what information you have
and what to inquire next in [INQUIRY ### Middle rounds (* N)
THOUGHT]. [INQUIRY THOUGHT] {inquiry_thought}
3. Present your inquiry with options for [INQUIRY] {inquiry}
the user to choose after [INQUIRY], and (User Response)
be friendly.
4. You could repeat Step 2 multiple ### Last round
times (but less than 5 times), or [SUMMARY THOUGHT] {summary_thought}
directly skip Step 2 if the user task is [SUMMARY] {summary}
clear initially.
--- Step 3: summarize the user’s
intention --- ConversationTemplate(ClearTask)
1. Make the summary once the information
is enough. You do not need to inquire {System Prompt}
about every missing detail in [INITIAL
THOUGHT]. ### First round
2. List all the user’s preferences and [INITIAL THOUGHT] {initial_thought}
constraints in [SUMMARY THOUGHT]. The
number of points should be the same as ### Last round
rounds of chatting. [SUMMARY THOUGHT] {summary_thought}
3. Give the final summary after [SUMMARY [SUMMARY] {summary}
] with comprehensive details in one or
two sentences.
D.3 CompleteTrainingSampleExampleafter
Concatenation
D.2 ConversationPrompt
Weapplytheaforementionedsystempromptand
We apply the following conversation template to
conversationtemplatetotransformalltheconversa-
convertandconcatenateeachconversationrecord
tionrecordsfortraining. Anexampleofcomplete
for training. For each constructed conversation
trainingdataafterthisprocessisasfollows:
recordfortraining,wedirectlyapplyalltheUser-
GPTresponses. However,theAssistant-GPT’sre-
Example
sponsesincludethoughts,judgments,inquiries,and
summaries, so we involve three steps in the tem- <s> User: You are an agent trying to
understand the user’s goal and summarize
plate:
it. Please first ask users for more
• Firstround: Themodelneedstotellthevague- specific details with options, and
finally summarize the user’s intention.
nessofthetask. Ifitisvague,themodelshould
--- Step 1: initial thought generation
provide the missing details, and then proceed
---
withthefirst-roundinquiry. 1. Generate [INITIAL THOUGHT] about if
the task is vague or clear and why.
• Middlerounds: Ifthetaskisvague,themodel 2. List the important missing details
shouldcontinueaskingtheuserforanymissing and some according options if the task
is vague.
details.
--- Step 2: inquiry for more information
if vague ---
• Lastround: Afterthemodelhasgatheredsuffi-
1. If the task is vague, inquire about
cientinformation(orthetaskisalreadyclear), more details with options according to
itshouldsummarizetheuser’sintentionandde- the list in [INITIAL THOUGHT].
2. Think about what information you have
tailedtaskgoalwiththoughts.
and what to inquire next in [INQUIRY
Basedonwhetherthetaskisvagueorclear,the THOUGHT].
datapointshouldfitintodifferenttemplatesasfol- 3. Present your inquiry with options for
the user to choose after [INQUIRY], and
lows:
be friendly.
4. You could repeat Step 2 multiple
ConversationTemplate(VagueTask) times (but less than 5 times), or
directly skip Step 2 if the user task is
{System Prompt} clear initially.
--- Step 3: summarize the user’s
### First round intention ---
[INITIAL THOUGHT] {initial_thought} Some 1. Make the summary once the information
aspects of missing details and is enough. You do not need to inquire
potential options are as follows: about every missing detail in [INITIAL
{missing details} THOUGHT].2. List all the user’s preferences and Agent: [INQUIRY THOUGHT] The user
constraints in [SUMMARY THOUGHT]. The prefers a mid-range budget and an
number of points should be the same as apartment rental for accommodation. Next
rounds of chatting. , I should inquire about their
3. Give the final summary after [SUMMARY activities of interest to further refine
] with comprehensive details in one or the trip planning.
two sentences. [INQUIRY] Sounds cozy! What about the
activities you’re interested in? Are you
Here is the task: looking forward to doing some
I would like to plan a trip to Paris sightseeing, immersing yourself in
next month. cultural experiences, or perhaps you’re
excited about shopping?</s>
Agent: [INITIAL THOUGHT] The user’s
task of planning a trip to Paris next User: Sightseeing mostly. Some good food
month is vague because it lacks specific too.
details such as the duration of the
trip, the budget, preferences for Agent: [INQUIRY THOUGHT] User is
accommodation, activities they are interested in sightseeing and good food,
interested in, and whether they need which covers activities and dining
help with transportation or dining preferences. I need to inquire about
options. Some aspects of missing details transportation needs.
and potential options are as follows: [INQUIRY] For getting around Paris,
- Duration of the trip: 3-5 days, 1 week would you prefer using public transport,
, More than a week renting a car, or having a private
- Budget for the trip: Economy, Mid- driver at your disposal?</s>
range, Luxury
- Accommodation preferences: Hotel, User: Public transport. It’s cheaper.
Hostel, Apartment rental
- Activities of interest: Sightseeing, Agent: [SUMMARY THOUGHT] Based on the
Cultural experiences, Shopping interaction history, I have gathered
- Transportation needs: Public transport enough information to understand the
information, Car rental, Private driver user’s intention for planning their trip
- Dining preferences: Local cuisine, , including duration, budget,
Vegetarian/Vegan options, No preferences accommodation preference, activities of
[INQUIRY THOUGHT] The user wants to plan interest, and transportation method.
a trip but hasn’t specified the Here are the user preferences and
duration, which is essential to start constraints:
planning. - Trip duration of one week
[INQUIRY] How exciting! How long are you - Mid-range budget
planning to stay in Paris? Would it be - Preference for an apartment rental
something like 3-5 days, a full week, or - Interest in sightseeing and good food
more than a week?</s> - Preference for using public transport
[SUMMARY] The user intends to plan a one
User: Just a week. -week, mid-range budget trip to Paris
next month, preferring to stay in an
Agent: [INQUIRY THOUGHT] The user has apartment rental, with a focus on
clarified the duration as one week, sightseeing and trying good food, while
which is a good start. Next, I should using public transport for getting
inquire about the budget to tailor the around.</s>
trip planning accordingly.
[INQUIRY] That’s a nice amount of time
to explore Paris! Now, could you tell me
about your budget for the trip? Are you
thinking of something economy, mid-
range, or looking for a luxury
experience?</s>
D.4 Hyper-ParameterDetails
User: Mid-range, nothing crazy.
Agent: [INQUIRY THOUGHT] The user has
indicated a one-week, mid-range budget Wepresentsomekeyhyper-parametersinTable5.
trip. Next, I should inquire about Additionally,wedynamicallyadjustthelossscale
accommodation preferences.
basedonthechangingtraininglosstopreventun-
[INQUIRY] Great choice! And where would
you prefer to stay? Are you leaning derflow. Under this setting, we adapt Mistral-7B
towards a hotel, a hostel, or maybe an intoMistral-Interact,apowerfulvariantrobustand
apartment rental?</s>
effective in user implicit intention understanding
User: Apartment rental. More space. duringtheinteraction. WeapplyMistral-Interact
foralltheexperimentsandevaluations.Max Batch LR
Model Epochs LR Time(h) Optimizer
Length Size Scheduler
Mistral-Interact 2048 3 16 1e-06 4.5 Cosine AdamOffload
Table5: Thehyper-parametersappliedduringthetrainingofMistral-Interact. LRdenotesthelearningrate.
E InstructionUnderstandingEvaluation E.3 MetricCalculationDetails
Details
Formalization. WedefineT asthesetoftesting
tasks. Eachtask’sconversationrecordinvolvesthe
E.1 UserParticipationDetails model’s vagueness judgment j, multiple rounds
of conversation R, and a final summary s. The
For108testsplittasksinIN3,werecruiteightdi-
annotated ground truth for this task involves the
verseuserstoparticipateinthemodel-userconver-
vagueness judgment j , three sets of missing
truth
sation,eachpersoninchargeofseveraltasks. Users details Di respectively of importance level i,
truth
areallundergraduatelevelwithdifferentexpertise.
1≤i≤3. WeadditionallydefineT
v
∈ T astheset
Allusersareaskedtoimaginetheyaredoingthe
oftasksthatthemodelregardsasvague.
task given, and they could arbitrarily respond to
ForoneroundofconversationinR,theassistant
thetestedmodelandreflecttheirintentionswhen-
may inquire about multiple missing details D =
ever being inquired. This promotes conversation {d ,d ,...,d },amongwhichonlyasubsetDi ∈ D
1 2 n
records with different tones, lengths, and styles,
alignwiththegroundtruthforimportanceleveli
thusmakingourresultsdiverseandrepresentative. (Di ∈ Di ). All the inquiries may also be ac-
truth
Theuserisalsoaskedtoannotatesomedetails companiedbycorrespondingoptions,formingaset
along with the conversation. This includes for P = {P ,P ,...,P }, among which only a sub-
d1 d2 dn
eachroundofconversation,howmanyqueriesthe setP ∈ P isregardedasreasonable. Meanwhile,
r
model inquires, how many options are provided, theusermayprovideresponseoradditionalinfor-
andwhethertheseoptionsarereasonable. Atthe mationU ={u ,u ,...,u },amongwhichonlya
1 2 m
endofeachconversationaboutatask,theuseralso subsetU isexplicitlysummarizedinthemodel’s
s
annotateshowmanydetailstheyofferintotal,and summarys.
howmanyareexplicitlysummarizedfinally.
CalculationFormulas. Wepresentthecalcula-
We randomly sample around 5% of the anno-
tiondetailsandformulasofeachmetricweprovide.
tations to ensure the annotations are performed
• VaguenessJudgementAccuracy: Themodel’s
fairlyandobjectively. Allthesampledannotations
vagueness judgment j is automatically deter-
passedthevaliditycheck. Theseannotateddetails
mined by whether it directly provides a sum-
ease the data analysis process and calculation of
mary (representing clear), or makes inquiries
somerelatedmetrics.
(representing vague). The accuracy is defined
as:
1 (cid:88)
E.2 MetricMeasurementDetails J = (j == j ) (1)
acc truth
|T|
T
Weemploydirectcalculation,userannotations,and
• MissingDetailsRecoverRate: Withthehelpof
GPT-4 to help with our measurements. The user
GPT-4,wedisentangleandextractallthemodel
annotationdetailsalongwiththeconversationare
inquiredmissingdetailsD,andmatchthemone
presented in Appendix E.1. We involve GPT-4
byonetothegroundtruthmissingdetailsDi
inthematchingofmissingdetailsthatthemodel truth
ofdifferentimportanceleveli. Therecoverrate
inquires about and the missing details that IN3
forimportanceleveliisdefinedas:
presentsasgroundtruths. Specifically,weaskGPT-
4 to judge whether each piece of model inquiry
could be paired with one of the missing details RRi = 1 (cid:88) (cid:80) R|Di| (2)
|T | (cid:80) |Di |
providedinIN3. Wesimilarlysample5%ofGPT- v Tv R truth
4’smatchingresults,whichpassthevaliditycheck,
toensureresultaccuracy. Thisalsoeasesthedata • SummaryIntentionCoverageRate: Thede-
analysisprocessandpromotesautomation. tails about what is explicitly summarized (U )
sareannotatedbytheuserattheendofthecon- F InstructionExecutionEvaluation
versation. Thecoveragerateisdefinedas: Details
CR =
1 (cid:88) (cid:80) R|U s|
(3)
F.1 TestDataDetails
|T | (cid:80) |U|
v Tv R Inthefollowing,wepresentthetenrandomlyse-
lectedvaguetaskswithinthemodel’sability,and
• Options Presenting Rate: The number of op- theircorrespondingclearusergoalsthemodelsum-
tionsprovidedforeachinquiredmissingdetail marizedafterinteraction.
isannotatedbytheuserduringtheconversation.
TestDataList
Theoptionspresentingrateisdefinedas:
1. Original Vague Task: Find the latest
OP =
1 (cid:88)(cid:88) (cid:80) R|{P i ∈ P |P i ̸= ∅}| research on diabetes treatment.
p |T | (cid:80) |D| Explicit Summary Thoughts:
v Tv R R The user has provided specific
(4) information over the course of five
interactions, which allows for a clear
• OptionsReasonableRate: Thenumberofrea- understanding of their request. Here are
sonableoptionsisannotatedbytheuserduring the user preferences and constraints:
- Type 1 diabetes
theconversation. Theoptionsreasonablerateis
- Focus on lifestyle changes
definedas: - Preference for meta-analyses
- Studies from within the last two years
OP
r
=
|T1
|
(cid:88) (cid:80)(cid:80) (cid:80)R|P r |P|
|
(5)
- EngA lr it si hcles must be peer-reviewed and in
v Tv R P i Detailed User Goal: The user is seeking
recent (within the last two years), peer
-reviewed meta-analyses research
• Average Provided Options: The average pro- articles in English that focus
specifically on lifestyle changes
videdoptionsisdefinedas:
related to treating Type 1 diabetes.
OP = 1 (cid:88) (cid:80) R(cid:80) P |P i| (6) 2. Original Vague Task: Find a recipe
avg |T | (cid:80) |D| for homemade pizza.
v Tv R Explicit Summary Thoughts:
The user has provided specific
preferences over the course of four
• AverageInquiredMissingDetails: Thenum- interactions, which gives a clear
berofmissingdetailsinquiredbythemodelin understanding of their intention. Here
are the user preferences and constraints
eachroundofconversationisannotatedbythe
:
user. The average inquired missing details is - Prefers a Margherita pizza.
- Wants a classic Italian style.
definedas:
- Desires a nice thick crust.
- Requires gluten-free ingredients.
1 (cid:88)(cid:88)
D = |D| (7) Detailed User Goal: The user is looking
avg
|T | for a recipe for a homemade gluten-free
v
Tv R
classic Italian-style Margherita pizza
with a nice thick crust.
• AverageConversationRounds: Alltheparam-
3. Original Vague Task: Find the latest
etersinthismetricareautomaticallyparsed. The news about global warming.
averageroundsofconversationisdefinedas: Explicit Summary Thoughts:
The user’s intention is now clear after
four rounds of interaction, with
1 (cid:88)
R = |R| (8) specific preferences and constraints
avg
|T| provided in each round. Here are the
T
user preferences and constraints:
- Interested in policy changes related
• AverageInquiredMissingDetailsPerRound: to global warming.
- Looking for updates on a regional
Theaverageinquiredmissingdetailsperround
level.
isdefinedas: - Wants information from the past year.
Detailed User Goal: The task is to find
DPR =
1 (cid:88) (cid:80) R|D|
(9)
t fh oe cusl ia nt gest spene cw is fica ab lo lu yt og nlob pa ol licw yarm ci hn ag
nges
avg
|T v| |R| over the past year at a regional scale.
Tvlength, and focus through our
4. Original Vague Task: Search for an interaction. Here are the user
explanation of the String Theory. preferences and constraints:
Explicit Summary Thoughts: - The text to be summarized is a
The user has provided specific research paper.
preferences over three rounds of - The summary is for a business
interaction, which gives a clear presentation.
understanding of their intention. Here - The desired length of the summary is
are the user preferences and constraints one concise paragraph.
: - Specifically highlight key arguments
- In-depth analysis of String Theory. from the research paper.
- Just a textual explanation without Detailed User Goal: The task is to write
visuals or interactive content. a concise one-paragraph summary of a
- Resources should be educational research paper’s key arguments for use
websites. in a business presentation.
Detailed User Goal: The user is seeking
an in-depth textual explanation of 8. Original Vague Task: Write a Python
String Theory from educational websites. script that sorts images based on their
content.
5. Original Vague Task: Develop a Python Explicit Summary Thoughts:
script that logs daily food intake and The user has provided specific details
calculates nutritional information. over the course of four interactions
Explicit Summary Thoughts: that clarify their initial task, which
The user has provided specific allows for a clear understanding of
requirements over the course of five their intention. Here are the user
interactions, which gives a clear preferences and constraints:
understanding of their needs for the - Recognize different scenes in images.
Python script. Here are the user - Store sorted images in a database for
preferences and constraints: quick search and retrieval.
- Track Protein intake specifically. - Process images using the OpenCV
- Accept command-line arguments as the library.
method of interaction with the script. Detailed User Goal: Create a Python
- Track protein intake over time and script to sort images based on scene
generate reports. recognition, utilizing OpenCV, and
- Cater to Gluten-free dietary storing them in a database for fast
restrictions. searching.
Detailed User Goal: Develop a Python
script that logs daily gluten-free food 9. Original Vague Task: Write a bash
intake using command-line arguments, command to check my system specification
tracks protein consumption over time, .
and calculates and displays protein Explicit Summary Thoughts:
content per meal or total daily protein The user has clarified their request in
intake in a file report. two rounds of interaction, specifying
the type of system information they want
6. Original Vague Task: Find a way to and the level of detail required. Here
convert audio files from one format to are the user preferences and constraints
another using Python. :
Explicit Summary Thoughts: - Check memory usage.
The user has provided specific - Provide a comprehensive list with
constraints over the course of three details.
interactions, which gives a clear Detailed User Goal: The task is to write
understanding of their needs for a bash command that provides a
converting audio files using Python. comprehensive list with detailed
Here are the user preferences and information on the user’s system memory
constraints: usage.
- Convert MP3 to WAV format.
- Prioritize saving space in the 10. Original Vague Task: Set up a study
converted file. plan for my upcoming law school exams in
- Use ffmpeg as the preferred library or two months.
tool within Python. Explicit Summary Thoughts:
Detailed User Goal: The task is to use The user has provided specific details
Python with ffmpeg to convert MP3 audio over the course of four interactions
files into WAV format while prioritizing that allow for a clear understanding of
smaller file sizes. their study plan needs. Here are the
user preferences and constraints:
7. Original Vague Task: Write a summary - Focusing on Criminal Law, which is a
of a given text file. struggle area.
Explicit Summary Thoughts: - Exams will be mainly essay-based.
The user has provided specific - Prefers to study alone.
information about the text, purpose,- Has approximately 5 hours per day
available for studying, with two months
until exams.
Detailed User Goal: Create an intensive
Criminal Law study plan focusing on
essays for a law school examinee who
prefers independent learning, allocating
5 hours daily over two months.
F.2 MetricMeasurementDetails
Weevaluatealltheagent’sperformancebasedon
thespecificanddetailedtaskgoalaftertheinterac-
tion. Forallthreemetrics,weaskedthesameuser
whohadaconversationwithMistral-Interactabout
this task to do an additional round of annotation,
respectively about each subtask and milestone’s
generalityandnecessity. Thenecessityisjudged
uponwhetherthedescriptionentailsanygivende-
tailsintheuser’sintention,whilethegeneralityis
judgeduponwhetherthecorrespondingexecution
meetstheuser’sdetailedandtailoredintentions.