JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 1
Pruning Sparse Tensor Neural Networks Enables
Deep Learning for 3D Ultrasound Localization
Microscopy
Brice Rauby, Graduate Student Member, IEEE, Paul Xing, Graduate Student Member, IEEE, Jonathan
Pore´e, Member, IEEE, Maxime Gasse, Jean Provost, Member, IEEE (Correspondingauthor:JeanProvost.)
Abstract—Ultrasound Localization Microscopy (ULM) is a and reduced acquisition time.
non-invasive technique that allows for the imaging of micro-
Index Terms—Deep Learning, 3D imaging, Ultrasound Local-
vessels in vivo, at depth and with a resolution on the order of
ization Microscopy (ULM), Sparse Tensor Neural Networks
ten microns. ULM is based on the sub-resolution localization of
individual microbubbles injected in the bloodstream. Mapping
the whole angioarchitecture requires the accumulation of mi-
I. INTRODUCTION
crobubbles trajectories from thousands of frames, typically ac-
quiredoverafewminutes.ULMacquisitiontimescanbereduced Ultrasound Localization Microscopy (ULM) is an imag-
by increasing the microbubble concentration, but requires more
ing method that non-invasively maps the vascular tree and
advanced algorithms to detect them individually. Several deep
blood velocities at depth in vivo. By localizing and tracking
learning approaches have been proposed for this task, but they
remainlimitedto2Dimaging,inpartduetotheassociatedlarge individual microbubbles injected into the blood flow [1, 2],
memory requirements. Herein, we propose to use sparse tensor ULM achieves an imaging resolution approximately equal to
neural networks to reduce memory usage in 2D and to improve one tenth of the diffraction-limited resolution. More recently,
thescalingofthememoryrequirementfortheextensionofdeep
DynamicUltrasoundLocalizationMicroscopy(DULM)[3,4]
learning architecture to 3D. We study several approaches to
has extended the capabilities of ULM by enabling the gen-
efficientlyconvertultrasounddataintoasparseformatandstudy
theimpactoftheassociatedlossofinformation.Whenappliedin eration of retrospectively-gated, super-resolved movies of the
2D,thesparseformulationreducesthememoryrequirementsby blood flow dynamics, with applications in pulsatility mapping
a factor 2 at the cost of a small reduction of performance when [3], functional imaging of the brain [5], and cardiac imaging
comparedagainstdensenetworks.In3D,theproposedapproach
[4]. ULM and DULM have been extended to 3D imaging [6,
reduces memory requirements by two order of magnitude while
7, 8, 9] using fully addressed or multiplexed array probes.
largely outperforming conventional ULM in high concentration
settings. We show that Sparse Tensor Neural Networks in 3D Both localization and velocity estimation can be improved
ULM allow for the same benefits as dense deep learning based by rejecting microbubbles that do not appear across several
method in 2D ULM i.e. the use of higher concentration in silico frames [1]. Such tracking can be performed, e.g., using the
Nearest Neighbor algorithm [3, 1] or the Hungarian method
This work was supported in part by the Institute for Data Valorization [10, 11]. Some approaches have also incorporated Kalman
(IVADO),inpartbytheCanadaFoundationforInnovationunderGrant38095, filtering to refine the position estimations of a track [6, 9, 12,
in part by the Canadian Institutes of Health Research (CIHR) under Grant
13]. The acquisition time necessary to construct a complete
452530,andinpartbyaNaturalSciencesandEngineeringResearchCouncil
ofCanada(NSERC)discoverygrant(RGPIN-2020-06786).TheworkofBrice vascular map is mainly dependent on the required time to
Rauby was supported in part by IVADO, and in part by the TransMedTech perfuse all vessels and, thus, on microbubble concentration
Institute, and in part by the Fonds de recherche du Que´bec—Nature et
[14]. However, a trade-off exists between the microbubble
technologies. The work of Paul Xing was supported by IVADO and in part
by the TransMedTech Institute. The work of Jonathan Pore´e was supported concentrationandthelocalizationprecisionandaccuracy[15],
inpartbyIVADO,inpartbytheTransMedTechInstitute,andinpartbythe which can be partially lifteds using, e.g., methods based on
CanadaFirstResearchExcellenceFund(Apoge´e/CFREF).Thisresearchwas
the compressed sensing theory [16], on the division of the k-
enabledinpartbysupportprovidedbyCalculQue´bec(calculquebec.ca)and
theDigitalResearchAllianceofCanada(alliancecan.ca) space in several subregions [17], or tracking the microbubble
B. Rauby is the Department of Engineering Physics, Polytechnique signals prior to sub-pixel localization [18]. Deep learning-
Montre´al, Montre´al, QC H3T 1J4, Canada, and also with Mila-Quebec
basedmethodshavealsoinvestigatedframe-by-frame,spatial-
artificial intelligence institute, Montre´al, QC H2S 3H1, Canada (email:
brice.rauby@polymtl.ca) only approaches [19, 20, 21], and, more recently, the spatio-
P. Xing, and J. Pore´e are with the Department of Engineering Physics, temporal context through convolution [22, 23] or sequential
Polytechnique Montre´al, Montre´al, QC H3T 1J4, Canada (e-mail: first-
modeling [24].
name.lastname@polymtl.ca)
M. Gasse is with ServiceNow, Montre´al, QC H2S 3G9, Canada, also Despite promising results with increased microbubble con-
with the Department of Computer Engineering and Software Engineering, centrations both in silico [22] and in vivo [22, 23], deep-
PolytechniqueMontre´al,Montre´al,QCH3T1J4,Canada,andalsowithMila-
learning based approaches have been limited to 2D imaging.
Quebec artificial intelligence institute, Montre´al, QC H2S 3H1, Canada (e-
mail:maxime.gasse@servicenow.com) Indeed, the addition of a third spatial dimension considerably
J. Provost is with the Department of Engineering Physics, Polytechnique increases the size of intermediate feature maps and highly-
Montre´al,Montre´al,QCH3T1J4,Canada,andalsowiththeMontrealHeart
resolved outputs. For example, a straightforward implementa-
Institute,Montre´al,QCH1T1C8,Canada(email:jean.provost@polymtl.ca)
ManuscriptreceivedXXXXXX,202X;revisedXXXXXX,202X. tion of Deep-stULM [22] in 3D would require at least two
4202
beF
41
]VI.ssee[
1v95390.2042:viXraJOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 2
responses. In this study, we focus on the subsequent step,
which is to find the sub-resolution positions of the microbub-
blesbasedontheirresponse.Severaldeeplearningapproaches
[19,20]useconvolutionalarchitectureswherethemicrobubble
position is projected onto a grid with a finer resolution than
the input signal. The upscaling factor r between the input
dimension and the output dimension typically ranges from 4
to 8. Therefore, the memory complexity for storing the output
grid of such architectures in dense format scales with :
(r×D)d
where d is equal to 2 (resp. 3) for 2D (resp. 3D) imaging
and D is a typical dimension of the input in pixels. However,
ULM is based on the assumption of a sparse distribution of
microbubbles.Anupperboundonthenumberofmicrobubbles
that can be detected in a certain volume is given by :
Fig. 1. The left column represents the filtered microbubble signal (i.e,
ρD
the input of the network), the center column represents the corresponding N <( )d
microbubble tracks (i.e., the desired output of the network) and the right α
columnrepresentthefinalresultaftersummationofallthepredictionsfrom
where N is the number of microbubbles, ρ is the size of a
adataset(i.e.,thevascularstructureimaged)
pixel in wavelength, and α approximately describes the size
of the point spread function in wavelengths. In sparse format,
orders of magnitude more memory than its 2D counterpart. the memory complexity of storing the microbubble positions
Thus, the development of deep learning based models for 3D scales with d×N and thus it is upper-bounded by:
ULM is conditioned on successfully addressing their memory
ρD
complexity. d×( )d
α
To improve the scaling of memory complexity of deep
learning approaches in ULM, we propose to leverage the Consequently, the ratio between the sparse and the dense
recently introduced Sparse Tensor Neural Networks [25]. representation of the outputs of the networks scales with :
Indeed, while ultrasound images are typically dense data that ρ
d( )d (1)
cannot be stored directly as sparse tensors efficiently, filtered αr
microbubbles responses are sparsely distributed in space and
Forexample,withtypicalvaluesα=3andρ= 1 ,theratio
time. One must thus design a filter that extracts microbubble 2
between the sparse and the dense representation of an ideal
responsesfromultrasoundimagesandissufficientlyrestrictive
outputs from such network is expected to be multiplied by
that it enhances memory requirements without discarding 3 ρ ≃ 1 =3.1×10−2 whenextendingfrom2Dto3D.This
informationenablestheneuralnetworktooutperformconven- 2αr 32
scalinglawmakesthesparserepresentationveryattractivefor
tional approaches. Hereafter, filtering out most of the input
the extension in 3D.
signal from dense tensors before conversion to sparse format
However, practical factors such as the variability of the
whilekeepingthesignalofinterestisdesignatedasthedense-
upscalingfactorrwithinthenetworkarchitecture,thereduced
to-sparse operation (represented in dashed green in Figure 2).
sparsity of intermediate representations, the non-uniform dis-
Our contributions can be summarized as follows:
tribution of microbubbles in space, or temporal context con-
• AsparseformulationofDeep-stULMoutperformingcon- siderations, can alter this scaling law.
ventional ULM in 2D.
• A comparative study in silico between ULM and the
III. METHOD
proposed approach under varying concentrations in 3D.
• A 2-D in silico study of performance and memory usage First,wedetailtheapproachusedtosimulatethe2Dand3D
datasets used for training evaluation of the different method.
of dense-to-sparse conversion strategies.
Then we describe the model architecture, training parameters
We show that Sparse Tensor Neural Networks reduce
and evaluation metrics. Additional studies on the impact of
memory cost and scale better with added input dimen-
the dense-to-sparse operations and on further architecture
sions, which allows for the training of 3D ULM mod-
modificationssuchaspruning[26](representedingolddotted
els with a limited impact on the performance when
line and scissors in Figure 2) and deep-supervision [27] are
compared to dense architectures. We also provide the
presented.
code and the dataset needed to reproduce the results at
https://github.com/provostultrasoundlab/SparseTensorULM.
A. Simulations
II. THEORY 1) 2D dataset: To compare Sparse Tensor Neural Net-
After image formation, ULM data is typically filtered to works with their dense counterpart, we based our study on
removethesignalfromthetissuewhileretainingmicrobubble a previously introduced dense method [22] and used theJOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 3
Fig.2. ThetoprowshowsadenserepresentationofatrajectoryinDeep-stULMaswellastheintermediatemapdimension.Thebottomrowillustrateshow
sparseformulationscouldreducethememorycost:thegreenpixelsrepresentthepixelsofinterestateachresolution,andthegraypixelsrepresentthepixels
removedthroughpruningbasedonintermediateprediction
same2Ddatasetbasedonthepreviouslypublishedsimulation per FOV) also matching the test set from the previous study
pipeline. Microbubble flow was simulated using a realistic [22].
model [15] based on ex vivo mice brains obtained with 2) 3D Dataset: The 3D dataset was obtained similarly but
two-photon imaging. Four portions of different mice brains since they contain more parameters, additional microbubble
were used to generate the training set, one other portion trajectories were included to reduce overfitting. We divided
was used for model selection and validation and the last the generated spatio-temporal samples in three groups: 3500
one was kept as a test set to assess the performance. Since samples for training, 500 for the validation, and 2000 for
each region covers a volume of only 500×500×500µm3, testing. We dilated the vascular network by a factor of 8 to
we dilated the vascular network by a factor of 2 to fill a accountforthelargerwavelengthandthecoarserbeamforming
1000×1000×1000µm3 area, as done previously [22]. The grid(λ).Wesimulateda750-fpsimagingsequencecontaining
2
ultrasound signal corresponding to the microbubble position 5 angles ({−2°,0°}, {2°,0°}, {−1°,0°}, {1°,0°}, {0°,0°})
was simulated using an in-house GPU implementation of emitted with a 7.8125-MHz center frequency using a matrix
SIMUS [28] with parameters corresponding to an L22-14 array with parameters matching a commercially available 8-
probe(Vermon,Tours).Three15.625-MHz,tiltedplanewaves MHz 2D matrix probe (Verasonics, WA, USA). The concen-
with angles of −1°, 0°, and 1° were simulated with a frame tration of microbubbles simulated for the training, validation,
rate of 1 kHz. The simulated signal was subsampled to match andtestsetswasincreasedto30microbubbles(comparedto5
the 100% bandwidth IQ signal, mimicking the Verasonics for the 2D-case) per field of view (FOV) given the additional
Vantage system. Finally, the IQ data were beamformed with a dimension.
GPUimplementationofthedelayandsumalgorithmonagrid
of32×32pixelswitharesolutionof λ
4
(i.e.,25µm),ingroups
B. Model training and evaluation
of 512 frames. The point spread function (PSF) of the system
1) Sparse Tensor Neural Network and 4D convolutions:
was simulated at the center of the grid and used to compute
Afterthedense-to-sparseoperation,thesparsetensorcontain-
the local correlation between the beamformed IQ data with
ing the low-resolution signal was given as input to a Sparse
thePSF.Theobtainedcorrelationmapswereusedastheinput
Tensor Neural Network implemented using the Python library
for the different deep-learning models. In total, 2250 movies
MinkowskiEngine [25]. For each intermediate layer, Sparse
were generated for training, 250 for validation, and 500 for
Tensor Neural Networks only apply their convolution and
testing. The concentration of microbubbles simulated for the
activation on non-zero values, yielding another sparse ten-
trainingandvalidationsetswassetto5microbubblesperfield
sor. Conventional operations used in CNNs are implemented
ofview(FOV),asdonepreviously[22].Severaltestsetswere
in MinkowskiEngine, leading to a relatively straightforward
simulated based on the trajectories from the test angiogram
translationofthemodelfromdensetosparseformat.Toassess
with varying concentrations (1, 5, 10, and 20 microbubbles
the benefits of sparse formulation, we converted the denseJOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 4
Deep-stULM architecture to a sparse formulation without stochasticityinvolvedbothintrainingandinthemeasurement
additionalchange,thisapproachisdesignatedasSparseDeep- ofthememory,weusedtheaverageacross3differentrunsand
stULM hereafter. However, such dense architecture might not provided the standard deviations between each run for deep
take most of the sparse tensor implementation. Pruning or learning approaches. For the 3D dense formulation of Deep-
cascadedlearningcouldfurtherimprovethememoryefficiency stULM, it was not possible to train the model due to practical
ofthesparseformulation.Bothofthisadditionalmodifications memory limitation. Therefore, we provide only an estimate of
requireintermediatesupervisionandaredetailedinthefollow- the memory usage. This estimate was based on scaling the
ing sections. The resulting models are also extended directly 2D memory usage based on the increase of memory for the
to 3D imaging with 4D convolutions to handle 3D+T tensors. intermediate maps due to the addition of a spatial dimension.
4DconvolutionsaredirectlyimplementedinthePythonlibrary
MinkowskiEngine [25].
C. Additional studies
2) Training procedure: For the 2D models based on Deep-
stULM, the hyperparameters were set to the same value as 1) Dense-to-sparse strategies: To assess the loss of infor-
in the original study [22]: the optimizer used was Adam [29] mationanditsimpactontheperformancecausedbythedense-
and the training was divided into two parts. During the first to-sparsefiltering,wecomparedtheperformanceofthesparse
150 epochs, the ground truth microbubble trajectories were modelfortwosimpledense-to-sparsestrategyreferredasTop-
dilated with a radius of 2 to stabilize the training. The initial kandthresholdingstrategywithvaryingvaluefortheirrespec-
learning rate was set to 0.1 and then decayed by a factor of tiveparameters.Toprovidebetterintuitionontheperformance
10 at the epochs 15, 45, 75, and 100. During the last 150, that one can expect with more sophisticated filtering, we
thegroundtruthswerenolongerdilated,andthelearningrate developedadeeplearningbasedsolution.Tocomparebetween
was set to 0.001 at epoch 150 and then decayed by a factor each method, we computed the average number of non-zero
of 10 at epochs 160, 200 and 250. We did not optimize the pixels in the test set movies to compare across methods and
hyperparameters for the sparse formulation of Deep-stULM plotted it in Figure 6. In addition, to differentiate between the
and used the same as the original study. The batch size was performancelossinducedbythedense-to-sparsestrategyfrom
set to 8 for all the runs in 2D. For the 3D models, we also the effect of the sparse implementation, we also evaluated a
used the Adam optimizer with an initial learning set of 0.1. dense model with inputs filtered according to the dense-to-
We trained the 3D networks for 20 epochs in total, and the sparsestrategy(eachmodelwasretrainedonthefiltereddata).
learning rate was decayed by a factor of 10 at epochs 15 and a) Top-kstrategy: TypicalULMapproachesuseregional
17. For the first epoch, the batch size was set to 2 to allow maximaformicrobubbledetectionbeforelocalizingthemwith
every configuration to fit in memory, then for the remaining highprecision[10].Basedonthesameunderlyingassumption
epochs, the batch size was increased to 4. that the microbubble signals are located near local maxima, it
3) Performance comparison with ULM and Deep-stULM: isreasonabletoconsideronlythek-largestpixelofeachinput
a) Evaluation metric: To compare our results with the tensor.Thisoperationisdesignatedastop-koperationlateron.
previously established method [22] and conventional ULM, Inpractice,duetothesmoothnessoftheinput,thisapproachis
we measure the overlap between the network prediction and very similar to the use of local maxima value while providing
ground truth using the dice coefficient : better control of the memory usage of the input tensor. The
explored values used for the top-k approaches range between
2×|GT∪Pred|
Dice= 5000 to 50000 pixels.
|GT|+|Pred|
b) Thresholding strategy: Previously published deep-
with GT being the projection of all the trajectories from the learning methods [22] used a threshold based on the value of
groundtruthtothesuper-resolvedgridandPredtheprediction the local correlation between the signal and the point spread
of the network. Similarly to the previous study [22], the dice functionoftheimagingsystemtoremoveresidualafterclutter
values displayed use a dice computed between the binarized filtering in vivo. We applied this same approach directly on
angiograms (i.e., between the logical summation of all the our simulated datasets. For the thresholding approaches, the
microfilms from the test set). threshold values were set to {0.01,0.05,0.10,0.25}. As the
b) Conventional ULM: We also provide the results of thresholdingstrategywithathresholdsetat0.10in2Doffered
a standard, non-deep-learning ULM method, described in [3]. a good trade-off between performance and sparsity, we used
Briefly,Gaussianfittingwasusedtolocalizemicrobubblesand it for all the experiments where the dense-to-sparse strategy
theHungarianmethod[30]wasusedforthetrackingstep.The was not specified. The threshold was heuristically set to 0.25
number of detections in each frame was set to the optimal for the 3D experiments.
value based on the number of microbubbles simulated in the c) Deep learning based strategy: We trained a dense
FOV (i.e., for the 5MB/FOV concentration, the number of CNN to localize microbubbles at low resolution. To do so,
detectionwouldbesetto5).Notethatthissettingisidealand it is trained to predict the presence of microbubbles in every
mayfavortheconventionalULM.Indeed,inrealapplications, pixel of the beamforming grid (low resolution). The dense
the exact number of microbubbles in the FOV is unknown. network used to localize microbubbles at low resolution is
c) Memorymonitoring: Wemonitoredthememoryusage fully convolutional both in space and time direction and takes
of the training using CometML and took the maximum value as input a tensor of shape 2×H×W ×T in 2D. The inputs
reached during the training of each method. As there is some channels encode the real and imaginary parts of the inputJOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 5
signal.Theinputsignaliscomposedofthelocalcorrelationof
thebeamformedIQdatawiththesimulatedPSFoftheimaging
system.Thespatialresolutionwaskeptunchangedthroughout
the whole network. However, the temporal dimension was
reduced by a factor of 2. The output of this network was
theninterpolatedtomatchthecorrelationmapdimension.The
resulting mask is used to convert the correlation map to a
sparse format, where only the pixel values with microbubbles
are stored along with their coordinates. This filtering network
was trained using the dice loss between its predictions and
the ideal mask at low resolution obtained from the simulated
Fig.3. Evolutionoftheperformanceasafunctionoftheconcentration
microbubble position.
2) Architecture modifications: Herein, we describe further
experiments to refine the sparsity using pruning on the in- andSparseDeep-stULM.Forthesparsemethod,thethreshold
termediate representation of the network along with deep- strategy was used to convert the input to sparse formulation.
supervision and cascaded learning. Sparse formulation reduced the memory usage of Deep-
a) Deep Supervision and pruning: Similarly to other stULM from 12.6 GB to 6.8 GB during training, while the
architectures[21, 19, 20], Deep-stULM [22] uses up-sampling dice decreased from 80.4% to 71.7%. In a similar setting,
layer that preserves the sparsity of the upsampled tensor. conventional ULM reached 59.5% of dice. The results of
This is sub-optimal as at finer resolution the sparsity of the the different methods in 2D under varying concentrations
trajectory is increased as depicted in Figure 2. To mitigate are shown in Figure 4 and the evolution of the dice value
these issues, we used the previously introduced pruning oper- computed are reported in Figure 3. Qualitatively, the standard
ations [26], that aim to gradually remove the pixels where no ULM performances degraded as the concentration increased
microbubbles are detected (green pixels versus gray pixels in with degradation in resolution starting from 5 microbubbles
Figure 2). The feature maps are masked based on the output per field of view (MB/FOV). Quantitatively, this diminution
ofanintermediateclassifier.Consequently,theremovedpixels of performance was highlighted by a drop in dice coefficient
are no longer considered in the following operation and their from 71.9% with 1 MB/FOV to 59.5% for 5 MB/FOV. The
coordinates are not stored in memory. As depicted in Figure performancecontinuedtodecreasewiththeconcentrationuntil
2, we implemented pruning at every resolution level based on it reached a dice of 55.2% at 20 MB/FOV with only the
intermediate prediction. Since pruning requires the training of biggest vessels being visible. In contrast, the dense Deep-
intermediate classifiers at each level, we trained them in a stULM approach exhibited a smaller degradation of perfor-
supervised fashion. These intermediate classifiers are trained mance from 84.7% for 1 MB/FOV to 75.2% for 20 MB/FOV.
using the same loss as the final loss and consist of pointwise The sparse formulation of Deep-stULM showed robustness
convolution directly applied to the intermediate representation to increased concentration and reached performance levels at
of the network. This form of supervision is similar to deep high concentration (with a dice coefficient of 70.6% (resp.
supervision [27] and can also serve as regularization and 68.0%) for 10 (resp. 20) MB per FOV that were very close
improve the performance of the network. These intermediate to itsperformance levelat lowconcentration (73.0% for 1MB
classifiers are required to perform pruning, as they provide per FOV). However, this performance at low concentration
the mask used to remove the less relevant pixels from the (1MB per FOV) were lower than Deep-stULM (84.7%) but
following operations. were comparable to conventional ULM (71.9%).
b) Cascaded learning: In the case of super-resolution,
deep supervision also makes possible a certain form of cas-
B. 3D feasibility study
caded learning inspired by [31]. Indeed, the intermediate
classifiers can be trained sequentially: during the first phase In Table I, we display the results and the memory usage
of the training, only the first classifier is trained to predict the for Sparse Deep-stULM and conventional ULM as well as
presence of microbubbles on a grid at the input resolution. estimated memory usage in 3D for Deep-stULM. The values
Then, during the following phase, the intermediate classifiers for the dice in 3D were typically lower as there is more
corresponding to higher resolution levels are sequentially possibility for a non-overlapping trajectory than in 2D. It
added to the global loss. When applied, the cascaded learning is important to note that just using the sparse formulation
strategy used one epoch for each intermediate level, and the allowed us to train the network with less than 11GB of
number of epochs for the last resolution level was the same GPUmemorywhileoutperformingconventionalULM(50.0%
as in standard training. versus 12.3%). For qualitative analysis, the reconstructed
angiograms from the test set are displayed in Figure 5 with
concentration increasing from 1 MB/FOV to 30 MB/FOV.
IV. RESULTS
At high concentration (10 MB/FOV and 30 MB/FOV), the
A. Memory reduction and performance comparison in 2D
sparse model accurately reconstructed the angiogram when
The memory usage results and performance at 5 MB/FOV conventional ULM failed to do so. Indeed, the conventional
are reported in Table I for Conventional ULM, Deep-stULM, ULM produced many false detections that were not presentJOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 6
TABLEI
COMPARISONOFTHEMEMORYUSAGEANDPERFORMANCESPARSEANDDENSEFORMULATIONOFDEEPST-ULM.*VALUEESTIMATED.
2D(5MB/FOV) 3D(30MB/FOV)
Memory Memory
requirements Dice(%) requirements Dice(%)
(GB) (GB)
SparseDeep-stULM 6.8±0.2 71.66±2.35 9.9±0.1 49.97±1.79
Deep-stULM 12.6 80.38±0.19 694* N.A
ULM N.A 59.48 N.A 12.34
Dense Sparse
Ground Truth Conventional ULM Deep-stULM Deep-stULM
1MB
5MB
10MB
20MB
Fig.4. ComparisonofperformanceunderincreasingconcentrationforconventionalULM(centerleftcolumn),Deep-stULMdenseformulation(centerright
column)anditssparseformulation(rightcolumn).Groundtruthisgivenforcomparison(leftcolumn).Scalebaris98µandcorrespondstothewavelength
ofthesimulatedpulse.Concentrationincreasesfrom1(toprow),5,10and20(bottomrow)microbubblesperfieldofview.
in the sparse model reconstruction. At low concentration (1 between the sparsity obtained and the level of performance
MB/FOV), both conventional ULM and sparse model recon- independently of the formulation of the model (dense or
structed the angiogram with fidelity. sparse). Indeed, for the sparse model with the thresholding
dense-to-sparse strategy the dice varies from 67.6% with
around21000pixelsto75.3%with90000pixelswhileitvaries
C. Additional studies
from 65.4% with around 5000 pixels to 73.9% with 100000
1) Evaluationofstrategiestoconverttosparseformulation: pixels for the top-k strategy. Similarly, for the dense model
In figure 6, it is observed that the thresholding and top-k with the thresholding dense-to-sparse strategy the dice varies
dense-to-sparse approaches reached a very similar trade-off from 79.4% with around 11000 pixels to 79.3% with 90000
noitartnecnoCJOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 7
Sparse
Ground Truth Conventional ULM Deep-stULM
1MB
10MB
30MB
Fig. 5. 3D Comparison of performance under increasing concentration for conventional ULM (center column) and Deep-stULM sparse formulation (right
column).Groundtruthisgivenforcomparison(leftcolumn).Scalebaris200µmandcorrespondstothewavelengthofthesimulatedpulse.Concentration
increasesfrom1(toprow),10and30(bottomrow)microbubblesperfieldofview.
thanalltheotherapproaches.Indeed,theCNNdense-to-sparse
operation reached a dice of 67.8% with only 1400 pixels.
2) Impact of architecture modifications: In table II, we
observed that using pruning jointly with sparse formulation
led to a decrease in memory requirements in 2D (6.9 GB
to 5.6 GB) but also led to an important degradation of the
performance (8.8% of dice). It appeared that combining prun-
ing and cascaded learning has a small impact on the memory
(5.6 GB versus 5.7 GB) while degrading the performance
(more than 3% of dice). The addition of intermediate loss
for deep supervision did not benefit the training performance
Fig. 6. Evolutionof performance as a function of thesparsity achieved for
different dense-to-sparse and comparison with dense network with masked and had a small memory cost. In 3D, every variation of
inputaswellasCNN-baseddensetosparseoperations. the model trained significantly outperformed the conventional
ULM(between38%and50%forthesparsemodelsand12.3%
for the conventional ULM). In contrast to 2D, the use of
pixels while it varies from 79.9% with around 5000 pixels pruning reduced memory usage by a factor of approximately
to 79.6% with 100000 pixels for the top-k strategy. Finally, 4. However, similarly to the 2D case, pruning also degraded
the CNN dense-to-sparse operation yielded a better trade-off the performance (50% to 38.6.%).
noitartnecnoCJOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 8
TABLEII
COMPARISONOFTHEMEMORYUSAGEANDPERFORMANCEOFTHEDIFFERENTADDITIONSTOSPARSEDEEPST-ULMARCHITECTURE.
Intermediate Cascaded 2D(5MB/FOV) 3D(30MB/FOV)
Sparseinput Pruning
loss learning
Memory Memory
requirements Dice(%) requirements Dice(%)
(GB) (GB)
SparseDeep-stULM
+Pruning ✓ ✓ ✓ ✓ 5.6±0.2 58.16±0.77 3.7±0.4 38.53±0.27
+cascadedlearning
SparseDeep-stULM ✓ ✓ ✓ 5.7±0.1 62.85±0.63 3.6±0.2 38.65±0.58
+Pruning
SparseDeep-stULM ✓ ✓ 6.9±0.1 71.33±0.36 10.6±0.3 43.51±0.99
+int.loss
SparseDeep-stULM ✓ 6.8±0.2 71.66±2.35 9.9±0.1 49.97±1.79
V. DISCUSSION closeto700GBofmemoryindenseformulation.Asexpected,
the sparse formulation impact on memory was greater in 3D
In this work, we studied the impact of using a sparse
than 2D. Experimentally, the ratio between the sparse and
formulation on the memory usage and performance of Deep-
the dense formulation was multiplied by 2.6 × 10−2 when
stULM.Wealsoinvestigatedmoremultiplemethodstofurther
extending from 2D to 3D whereas the theoretical value from
increase sparsity and reduce the memory usage. Our results
Eq. 1 was 3.1×10−2. The smaller ratio could be explained
suggest that solely using the sparse formulation allows for
by the aforementioned experimental factors such as temporal
the extension of existing deep learning architectures to 3D
context considerations, as well as the higher threshold for the
ULM, while preserving the performance robustness at high
dense-to-sparse strategy in 3D. The performance gap between
concentration. However, more complex modifications to the
the sparse formulation of Deep-stULM and the conventional
architecturehadalessimportantimpactonthememoryusage
ULMwaslargerin3D,suggestinganevenhigherpotentialfor
while degrading the performance.
deep learning based approach in 3D ULM. On the one hand,
thedropofperformanceofconventionalULMmightbecaused
A. Reducing memory usage of existing methods in 2D
bytheimportantsidelobesofthesimulatedPSFin3D.Indeed,
The sparse formulation offers a relatively simple approach these sidelobes create false detection which are supposed
to divide by nearly two-fold the memory requirement of an to be filtered during the tracking step based on the track
existing architecture in 2D with little impact on the perfor- length. However, in high concentration, candidate detections
mance. Indeed, the sparse formulation qualitatively matches in successive frame are multiple causing the filtering on track
the performance on the concentration used during training (5 length to be less effective and contribute to 3D conventional
MB/FOV) and for higher concentration (10 MB/FOV) and ULMmapwithahighnumberoffalsepositives.Ontheother
quantitativelyoutperformsconventionalULMbyanimportant hand,itisalsopossiblethattheadditionaldimensionincreases
margin.DenseformulationofDeep-stULMperformsbetteron the capability of the deep learning approach to distinguish
veryhighconcentration(20MB/FOV)andisolatedmicrobub- crossing trajectories, leading to better performance relatively
ble (1 MB/FOV). As the training set only contains samples at to conventional ULM. The results in 3D shows that akin
a concentration of 5 MB/FOV, the dense formulation seems to the dense approach in 2D, sparse models can accurately
to better generalize to unseen data. This better generalization reconstruct angiograms at concentration where conventional
capability and the relatively small size of the training set can ULM is failing. When translated in vivo, such performance in
alsoexplaintheperformancegapbetweenthedenseandsparse high concentration would allow for reduced acquisition time.
formulationontrainingconcentration,asthedenseformulation In 3D, where dataset tends to be larger, reducing acquisition
wouldbeabletobettergeneralizetothetestset.Increasingthe timeisevenmorecrucialasitalsoreducesthestorageneeded
dataset size and its complexity could bridge the performance and the associated transfer time.
gap between the dense and the sparse formulation, while
still benefitting from the memory improvements. Top-k and
thresholding dense-to-sparse strategies appear to have similar C. Further reductions of memory and performance trade-off
performance.Thisperformanceappeartobesuboptimalwhen
a) Dense-to-sparse strategies: The parameter studies
compared to the performance reached with much fewer pixels
showed that simple strategies for dense-to-sparse performed
by the CNN dense-to-sparse strategy. Presumably, the sparse
similarly and better trade-off could be achieved with deep-
formulation might benefit from more sophisticated dense-
learning based dense-to-sparse operations. However, the
to-sparse strategy to further improve the proposed trade-off
learned approach for dense-to-sparse operation lacked flex-
between performance and memory requirements in training.
ibility on the trade-off between sparsity achieved and per-
formance. Increasing the number of pixels considered in the
B. Scaling to 3D imaging
sparse formulation reduced the performance gap between
In3D,thesparseformulationallowedfortraining,withless sparse and dense formulation of Deep-stULM. This might
than 11 GB of memory, an architecture that would require suggest sub-optimal dense-to-sparse operations.JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 9
b) Architecturemodifications: Itappearsthatarchitecture VI. CONCLUSION
modificationssuchasdeep-supervision,cascadedlearningand
In this study, we studied the potential of sparse formulation
pruning had an important impact on the performance with
when applying deep learning in 3D ULM. We also proposed
smallergaininmemorythanthatthensolesparseformulation.
further optimization of memory efficiency through pruning of
Cascaded learning and deep-supervision negative impact on
the3DULMdeeplearningmodel.TheproposedSparseDeep-
theperformancecouldbeexplainedbythefactthatmicrobub-
stULM method successfully improve the scaling of memory
bledetectionatcoarseresolutionisdifferentfromlocalization
requirements of deep learning based approaches, addressing
at super-resolution and therefore intermediate losses enforce
the challenge of their extension in 3D. While it comes at a
the learning of less relevant latent representations. Consid-
small cost of performance in 2D, the use of deep-learning in
ering the additional complexity in training and architecture
3D ULM seems to be even more beneficial than in 2D. To
constraint going with this modifications, it is less clear that
the best of our knowledge, it is the first application of deep
they present an interesting trade-off between memory usage
learning for 3D ULM, and it could pave the way for further
and performance. approaches both in silico and in vivo. Further applications of
such models could allow for improved architectures capable
of fitting to more diverse datasets, yielding better results both
D. Limitations and perspectives
in 2D and 3D ULM or DynULM.
Theproposedmethoddemonstratesparsetensorneuralnet-
workscanextendthebenefitsofdeeplearningbasedapproach
REFERENCES
inULMfrom2Dto3Dimagingbyimprovingthescalinglaw
[1] Claudia Errico et al. “Ultrafast Ultrasound Localization
ofmemorycostswithdimensionalityandresolution.However,
Microscopy for Deep Super-Resolution Vascular Imag-
some limitations should be mentioned and could be addressed
ing”. In: Nature 527.7579 (Nov. 2015), pp. 499–502.
by future studies.
1) Problem formulation: This study is mostly focused on
ISSN: 1476-4687. DOI: 10.1038/nature16066.
[2] K. Christensen-Jeffries et al. “In Vivo Acoustic Super-
measuring the impact of using a sparse formulation in deep
Resolution and Super-Resolved Velocity Mapping Us-
learning for ULM. For this reason, it does not tackle some
ing Microbubbles”. In: IEEE Transactions on Medical
key challenges in framing the learning problem. On the one
hand,itisimportanttomentionthateventhoughthediceloss
Imaging 34.2 (Feb. 2015), pp. 433–440. ISSN: 1558-
has been proposed and successfully applied in the previous
254X. DOI: 10.1109/TMI.2014.2359650.
[3] Chloe´ Bourquinetal.“InVivoPulsatilityMeasurement
study [22], it is unstable and lacks smoothness when working
of Cerebral Microcirculation in Rodents Using Dy-
with temporal projection of trajectories. In addition, the final
namic Ultrasound Localization Microscopy”. In: IEEE
representation of the prediction, being a projection of the
Transactions on Medical Imaging 41.4 (Apr. 2022),
microbubble trajectories on a grid, does not offer the same
liberty for downstream analysis as the individual detections
pp. 782–792. ISSN: 1558-254X. DOI: 10.1109/TMI.
2021.3123912.
provided by conventional ULM. A formulation tackling these
[4] Philippe Cormier et al. “Dynamic Myocardial Ultra-
issueshasbeenrecentlyproposed[23]basedontheDECODE
sound Localization Angiography”. In: IEEE Transac-
method [32] and could be worth investigating. On the other
hand,theencodingoftherealandimaginarypartsoftheinput
tions on Medical Imaging (2021), pp. 1–1. ISSN: 1558-
signal as channels lacks the proper arithmetic of complex
254X. DOI: 10.1109/TMI.2021.3086115.
[5] Noe´mi Renaudin et al. “Functional Ultrasound Local-
numbers. Using a complex value neural network [33] could
ization Microscopy Reveals Brain-Wide Neurovascular
allow a better representation of the signal with less overfitting
Activity on a Microscopic Scale”. In: Nature Methods
and better overall performance. Such networks have shown
interesting potential when dealing with ultrasound data [34,
19.8 (Aug. 2022), pp. 1004–1012. ISSN: 1548-7105.
35].
DOI: 10.1038/s41592-022-01549-5.
[6] Chloe´ Bourquin et al. Quantitative Pulsatility Mea-
2) Validity of the in silico model: The proposed approach
surements Using 3D Dynamic Ultrasound Localization
reaches the level of performance of the state-of-the-art dense
model in silico under varying concentrations of microbub-
Microscopy. Mar. 2023. DOI: 10.48550/arXiv.2303.
14330. arXiv: 2303.14330 [physics].
bles. It would be interesting to evaluate the validity of the
[7] Baptiste Heiles et al. “Ultrafast 3D Ultrasound Lo-
conclusions on real data as it has not been tested in vivo.
calization Microscopy Using a 32×32 Matrix Array”.
However,astheinvivoapplicationofbothdenseandproposed
In: IEEE Transactions on Medical Imaging 38.9 (Sept.
methods requires intensive parameter tuning, it is difficult to
ensure a fair comparison between the methods. Additionally,
2019),pp.2005–2015.ISSN:1558-254X.DOI:10.1109/
TMI.2018.2890358.
currenttrainingdatasetsforULMarelimitedintheirdiversity
[8] Arthur Chavignon et al. “3D Transcranial Ultrasound
and realism. They often require tuned pre-processing, and
Localization Microscopy in the Rat Brain with a Mul-
therefore it is not clear that better learning ability on the
tiplexed Matrix Probe”. In: IEEE transactions on bio-
simulateddatasetwouldleadtoimprovedperformanceinvivo.
Furthermore,asthemainbenefitoftheproposedmethodisan
medical engineering PP (Dec. 2021). ISSN: 1558-2531.
improvement of the scaling law of the memory complexity, it
DOI: 10.1109/TBME.2021.3137265.
is reasonable to assume that it is still valid in vivo.JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 10
[9] U-Wai Lok et al. “Three-Dimensional Ultrasound Lo- [20] Ruud J. G. van Sloun et al. “Super-Resolution Ultra-
calization Microscopy with Bipartite Graph-Based Mi- sound Localization Microscopy Through Deep Learn-
crobubblePairingandKalman-Filtering-BasedTracking ing”. In: IEEE Transactions on Medical Imaging 40.3
on a 256-Channel Verasonics Ultrasound System with (Mar. 2021), pp. 829–839. ISSN: 1558-254X. DOI: 10.
a 32×32 Matrix Array”. In: Journal of Medical and 1109/TMI.2020.3037790.
Biological Engineering 42.6 (Dec. 2022), pp. 767–779. [21] Xi Chen et al. “Deep Learning-Based Microbubble Lo-
ISSN: 2199-4757. DOI: 10.1007/s40846-022-00755-y. calizationforUltrasoundLocalizationMicroscopy”.In:
[10] Baptiste Heiles et al. “Performance Benchmarking of IEEE Transactions on Ultrasonics, Ferroelectrics, and
Microbubble-Localization Algorithms for Ultrasound Frequency Control 69.4 (Apr. 2022), pp. 1312–1325.
Localization Microscopy”. In: Nature Biomedical En- ISSN: 1525-8955. DOI: 10.1109/TUFFC.2022.3152225.
gineering 6.5 (May 2022), pp. 605–616. ISSN: 2157- [22] Le´o Milecki et al. “A Deep Learning Framework for
846X. DOI: 10.1038/s41551-021-00824-8. Spatiotemporal Ultrasound Localization Microscopy”.
[11] Pengfei Song et al. “On the Effects of Spatial Sam- In: IEEE Transactions on Medical Imaging 40.5 (May
pling Quantization in Super-Resolution Ultrasound Mi- 2021),pp.1428–1437.ISSN:1558-254X.DOI:10.1109/
crovesselImaging”.In:IEEETransactionsonUltrason- TMI.2021.3056951.
ics, Ferroelectrics, and Frequency Control 65.12 (Dec. [23] YiRang Shin et al. Context-Aware Deep Learning En-
2018),pp.2264–2276. ISSN:1525-8955. DOI:10.1109/ ablesHigh-EfficacyLocalizationofHighConcentration
TUFFC.2018.2832600. Microbubbles for Super-Resolution Ultrasound Local-
[12] Iman Taghavi et al. “Ultrasound Super-Resolution ization Microscopy. Apr. 2023. DOI: 10.1101/2023.04.
Imaging with a Hierarchical Kalman Tracker”. In: Ul- 21.536599.
trasonics122(May2022),p.106695.ISSN:0041-624X. [24] Xi Chen et al. “Localization Free Super-Resolution
DOI: 10.1016/j.ultras.2022.106695. Microbubble Velocimetry Using a Long Short-Term
[13] Shanshan Tang et al. “Kalman Filter-Based Microbub- Memory Neural Network”. In: IEEE Transactions on
ble Tracking for Robust Super-Resolution Ultrasound Medical Imaging (2023), pp. 1–1. ISSN: 1558-254X.
Microvessel Imaging”. In: IEEE Transactions on Ul- DOI: 10.1109/TMI.2023.3251197.
trasonics, Ferroelectrics, and Frequency Control 67.9 [25] Christopher Choy, JunYoung Gwak, and Silvio
(Sept. 2020), pp. 1738–1751. ISSN: 1525-8955. DOI: Savarese. “4D Spatio-Temporal ConvNets: Minkowski
10.1109/TUFFC.2020.2984384. Convolutional Neural Networks”. In: 2019 IEEE/CVF
[14] Vincent Hingot et al. “Microvascular Flow Dictates the Conference on Computer Vision and Pattern Recog-
Compromise between Spatial Resolution and Acquisi- nition (CVPR). Long Beach, CA, USA: IEEE, June
tion Time in Ultrasound Localization Microscopy”. In: 2019, pp. 3070–3079. ISBN: 978-1-72813-293-8. DOI:
ScientificReports9.1(Feb.2019),p.2456. ISSN:2045- 10.1109/CVPR.2019.00319.
2322. DOI: 10.1038/s41598-018-38349-x. [26] JunYoung Gwak, Christopher Choy, and Silvio
[15] Hatim Belgharbi et al. “An Anatomically Realistic Savarese. “Generative Sparse Detection Networks for
Simulation Framework for 3D Ultrasound Localization 3D Single-Shot Object Detection”. In: Computer Vi-
Microscopy”. In: IEEE Open Journal of Ultrasonics, sion – ECCV 2020. Ed. by Andrea Vedaldi et al.
Ferroelectrics, and Frequency Control 3 (2023), pp. 1– Vol. 12349. Cham: Springer International Publishing,
13. ISSN: 2694-0884. DOI: 10.1109/OJUFFC.2023. 2020, pp. 297–313. ISBN: 978-3-030-58547-1 978-3-
3235766. 030-58548-8. DOI: 10.1007/978-3-030-58548-8 18.
[16] A. Bar-Zion et al. “SUSHI: Sparsity-Based Ultrasound [27] Chen-Yu Lee et al. “Deeply-Supervised Nets”. In: Pro-
Super-Resolution Hemodynamic Imaging”. In: IEEE ceedings of the Eighteenth International Conference on
Transactions on Ultrasonics, Ferroelectrics, and Fre- Artificial Intelligence and Statistics. PMLR, Feb. 2015,
quency Control 65.12 (Dec. 2018), pp. 2365–2380. pp. 562–570.
ISSN: 1525-8955. DOI: 10.1109/TUFFC.2018.2873380. [28] Damien Garcia. “SIMUS: An Open-Source Simulator
[17] Chengwu Huang et al. “Short Acquisition Time Super- for Medical Ultrasound Imaging. Part I: Theory &
Resolution Ultrasound Microvessel Imaging via Mi- Examples”. In: Computer Methods and Programs in
crobubble Separation”. In: Scientific Reports 10.1 (Apr. Biomedicine 218 (May 2022), p. 106726. ISSN: 0169-
2020),p.6007.ISSN:2045-2322.DOI:10.1038/s41598- 2607. DOI: 10.1016/j.cmpb.2022.106726.
020-62898-9. [29] Diederik P. Kingma and Jimmy Ba. Adam: A Method
[18] Alexis Leconte et al. A Tracking Prior to Localization for Stochastic Optimization. Jan. 2017. DOI: 10.48550/
WorkflowforUltrasoundLocalizationMicroscopy.Aug. arXiv.1412.6980. arXiv: 1412.6980 [cs].
2023. DOI: 10.48550/arXiv.2308.02724. arXiv: 2308. [30] H. W. Kuhn. “The Hungarian Method for the Assign-
02724 [physics]. mentProblem”.In:NavalResearchLogisticsQuarterly
[19] Xin Liu et al. “Deep Learning for Ultrasound Local- 2.1-2 (1955), pp. 83–97. ISSN: 1931-9193. DOI: 10.
izationMicroscopy”.In:IEEETransactionsonMedical 1002/nav.3800020109.
Imaging39.10(Oct.2020),pp.3064–3078.ISSN:1558- [31] Enrique S. Marquez, Jonathon S. Hare, and Mahesan
254X. DOI: 10.1109/TMI.2020.2986781. Niranjan.“DeepCascadeLearning”.In:IEEETransac-
tions on Neural Networks and Learning Systems 29.11JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 11
(Nov. 2018), pp. 5475–5485. ISSN: 2162-237X, 2162-
2388. DOI: 10.1109/TNNLS.2018.2805098.
[32] Artur Speiser et al. “Deep Learning Enables Fast and
Dense Single-Molecule Localization with High Accu-
racy”.In:NatureMethods18.9(Sept.2021),pp.1082–
1090. ISSN: 1548-7105. DOI: 10.1038/s41592-021-
01236-x.
[33] Chiheb Trabelsi et al. “Deep Complex Networks”. In:
International Conference on Learning Representations.
Feb. 2018.
[34] JingfengLuetal.“ComplexConvolutionalNeuralNet-
works for Ultrafast Ultrasound Imaging Reconstruction
From In-Phase/Quadrature Signal”. In: IEEE Trans-
actions on Ultrasonics, Ferroelectrics, and Frequency
Control 69.2 (Feb. 2022), pp. 592–603. ISSN: 0885-
3010, 1525-8955. DOI: 10.1109/TUFFC.2021.3127916.
[35] Paul Xing et al. “Phase Aberration Correction for
in Vivo Ultrasound Localization Microscopy Using a
Spatiotemporal Complex-Valued Neural Network”. In:
IEEETransactionsonMedicalImaging(2023),pp.1–1.
ISSN: 1558-254X. DOI: 10.1109/TMI.2023.3316995.