Large Language Models Cannot Explain
Themselves
AdvaitSarkar Abstract
MicrosoftResearch Largelanguagemodelscanbepromptedtoproducetext.
Cambridge,UnitedKingdom Theycanalsobepromptedtoproduce“explanations” of
theiroutput. Butthesearenotreallyexplanations,because
UniversityofCambridge
theydonotaccuratelyreflectthemechanicalprocess
Cambridge,UnitedKingdom
underlyingtheprediction. Theillusionthattheyreflectthe
reasoningprocesscanresultinsignificantharms. These
UniversityCollegeLondon
“explanations” canbevaluable,butforpromotingcritical
London,UnitedKingdom
thinkingratherthanforunderstanding themodel. Ipropose
advait@microsoft.com arecontextualisation ofthese“explanations”, usingtheterm
“exoplanations” todrawattentiontotheirexogenousnature.
Idiscusssomeimplicationsfordesignandtechnology, such
astheinclusionofappropriateguardrailsandresponses
whenmodelsarepromptedtogenerateexplanations.
Author Keywords
exoplanations;mechanismalexplanations;co-audit;AI
safety;explainableAI;XAI;criticalthinking
CCS Concepts
•Human-centeredcomputing→HCItheory,conceptsand
Permissiontomakedigitalorhardcopiesofpartorallofthisworkforpersonalor
models;Naturallanguageinterfaces;•Computing
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
methodologies→Naturallanguageprocessing;Neural
onthefirstpage.Copyrightsforthird-partycomponentsofthisworkmustbehonored.
networks;Machinelearning;Philosophical/theoretical
Forallotheruses,contacttheowner/author(s).
foundationsofartificialintelligence;
Copyrightheldbytheowner/author(s).
HCXAIworkshopatCHI’24,Honolulu,HI,USA
4202
yaM
7
]CH.sc[
1v28340.5042:viXraKeyterms The illusion of explanation Letusexaminewhatisactuallyhappeningwhena
InthecontextofArtificialIntelligence(AI),theterm languagemodelhasproducedsomeoutputO,andisthen
Mechanismalexplanations: “explanation”canencompassmanytypesofinformation. promptedtogiveanexplanationEforO.Theprocessof
explanationsofAImodel Themostwell-studiedcategoryofexplanationsis generatingEissimplyanotherexecutionofthelanguage
behaviourwhichrepresent concernedwithprovidingdescriptionsofthestructureofa model. Eisatextcomposedthroughasequenceof
factsabouttheunderlying model,itstrainingdata,andmostcommonly,elaboration of next-tokenpredictions,stochasticallyoptimisedtosatisfy
mechanismsofprediction, anygivenoutputintermsofthealgorithmicprocess thequery. Eisnottheresultofanintrospectivereflection
suchasthemodelstructure, followedtoproducethatoutput[29]. Whatthese onthealgorithmicprocessthatwasfollowedtogenerateO.
trainingdata,ormodel explanationshaveincommonisthattheyaimtofaithfully Atruemechanismalexplanationwouldinvoke,forexample,
weights. Theyaregenerated representsomeaspectoftherealunderlyingalgorithmic somereferencetotheactualtrainingdata,model
fromintrospectionofthe mechanismofanAImodel. Letusthereforerefertothese parameters,oractivations,thatwereinvolvedinthe
model,itstrainingdata, asmechanismalexplanations.1 productionofO.Butifthismeta-informationaboutthe
anditsinferenceprocess. predictionprocessisnotaccessibletothemodeltodraw
ExamplesincludeLIMEand Classicexamplesofmechanismalexplanationsinclude uponingeneratingE,itistheoreticallyimpossiblethatE
SHAP. LIME[26],SHAP[21],saliencymaps[36,33],andKulesza couldreflectit,accuratelyorotherwise.
etal.’svisualisationsofBayesclassifiers[15],andSarkaret
al.’svisualisationsofk-NNmodels[31]. Mechanismal ThesituationisnodifferentifEandOarerequestedina
Exoplanations: statements
explanationsarenottheonlykind: researchersinrecent singleprompt,e.g.,“WhatisthecapitalofFrance? Explain
whichappeartobe
yearshavecarefullydrawnattentiontoaspectsofAI youranswer.”,asopposedtotwoseparatepromptsor
explanationsofAIoutput,
explanationthatinsteadpertaintothesocio-technical conversational turns,thefirstaskingthequestionandthe
butarenot(andcannotbe)
systeminwhichAIisembedded[7,6,9]. secondaskingfortheexplanation. Inthesingle-turncase,
agrounded reflectionofthe
andinmulti-turnsystemswherepreviousresponsesare
mechanismthatgenerated
Adisconnectionisnowimmediatelyvisiblebetweena includedinthequerycontext,itistruethatthegeneration
thatoutput. Thisiswhat
classicmechanismalexplanation,andwhatisproduced ofOisaffectedbythepresenceofanE-requestinthe
languagemodelsproduce
whenalanguagemodelispromptedtogeneratean querycontext,andviceversa. Forexample,thelanguage
whenaskedto“explain”
explanation. Theformeristrulygenerated from,andhasa modelmaywellproduceamorecoherentandwell-justified
themselves.
concrete,groundedrelationto,theactualprocessesand outputifitcansimultaneouslyattendtoafragmentof
behaviourofamodel. Butalanguagemodel“explanation” languageinwhichanexplanationisrequested. However,
hasnosuchproperty. Thishasbeenpreviouslynoted[1, thenotionalEportionoftheresponsestilllacksa
19],butthereasonfortheproblemistreatedas mechanismal grounding.
self-evident. Iwouldliketoexpandontheseobservations,
toexplainwhyso-called“self-explanations” areconsidered StatementsoftypeE,then,arenotexplanations,atleast
tobeungrounded. notinthesensethatthewordismostcommonlyusedin
explainableAIresearch,and,weshallsee,noteveninthe
1Theaimofthisawkwardconstructionistoemphasisethatthey
sensethatuserscolloquiallyexpectfromthesesystems.
areexplanationsof amechanism;usingtheterm“mechanical”or
“mechanistic”mightconnotethattheexplanationsthemselvesare Theydonotholdtheepistemicallyprivilegedstatusover
generatedmechanically,whichisusuallytruebutnotrelevant.statementsofthetypeOthattheyclaimorthatpeople Societal harms of exoplanations
expect. Infact,theyareoutputslikeanyother. E-type ThestoryoftheNewYorklawyerswhosubmittedalegal
statementscouldbedescribedasjustifications,or“post-hoc briefincludingcasecitationsgenerated byChatGPT,but
rationalisations” [25],buteventhesetermsimplyagreater whichturnedouttobenon-existent,isnowwell-known[23].
degreeofreflexivityandintrospectionthaniswarranted.
Alesswell-knownaspectofthisepisodeisthatthe
Theyaresimulacraofjustification,orofrationalisation;
infelicitouslawyersdidattempttoverifythatthecaseswere
samplesfromthespaceoftextswiththeshapeof
real... byaskingChatGPT,whichconfidentlyexoplained
justifications.
thatthecaseswerereal: “[Thelawyer]askedtheAItool
Letusinsteadcallthemexoplanations. Thistermretains whether[acaseitgenerated]isarealcase. ChatGPT
alltheconnotationsofexplanations(theymayormaynot answeredthatit"isarealcase"and"canbefoundonlegal
becorrect,theycarrytheappearance ofinsight,theyoften researchdatabasessuchasWestlawandLexisNexis."
appealtocause,logic,orauthority),butexplicitlycaptures WhenaskediftheothercasesprovidedbyChatGPTare
thefactthattheyareexogenousto,outsideof,theoutput fake,itanswered,"No,theothercasesIprovidedarereal
theyexplain. Theyinhabitthesameplaneofreasoningas andcanbefoundinreputablelegaldatabasessuchas
theirobject;theycannotlookanyfurtherbeneaththeobject LexisNexisandWestlaw."” [3]
thantheobjectitselfcan.
Ithasoftenbeennotedthatlanguagemodelhallucinations
Despitestate-of-the-art performanceonreasoningtasks areparticularlydangerousbecauseoftheboldconfidence
[25,35,38],andonestudythatreportedfeatureattribution withwhichthemodelmakesitsassertions. Thesameis
explanationswithperformancecomparabletoLIME[13], trueofexoplanations. Becauseitissoeasytoprompta
recentworkhasdeliveredsignificantevidencethat languagemodeltoproduceanexoplanation,whichis
languagemodelsconsistentlyfailtoaccuratelyexplaintheir reportedwithboldconfidence,theusercanbeforgivenfor
ownoutput,andcanevensystematicallymisrepresentthe thinkingthatexoplanationsaremechanismalexplanations,
truereasonforamodel’sprediction[4,22,32,34]. Inother whereasinfacttheyarenot. Thiscanleadtothevery
words,atpresent,whentheexplanationsoughtrequires obviousproblemssuchastheexampleabove. Asthefirm
introspectionintothegenerationprocess,exoplanations statedinresponsetothejudgmentthatthelawyershad
justdon’twork. Largelanguagemodelscannotexplain actedinbadfaith,“Wemadeagoodfaithmistakeinfailing
themselves. tobelievethatapieceoftechnologycouldbemakingup
casesoutofwholecloth” [23].
Thisdoesnotmeanthatexoplanationsarenotuseful;on
thecontrary, whenpresentedappropriately, theycanbe Asdesignerswemustaskourselves: inwhom(orwhat)
animportantandpowerfultoolinthedesigner’stoolkitfor wasthis“goodfaith”placed,andwhy? Ifafalsestatement
creatingusefulandtrustworthyexperiences. Beforewe presentedwithboldconfidenceisdangerous, afalse
discussthose,letusturnourattentionbrieflytowhyitis statementpresentedandexoplainedwithboldconfidenceis
importanttomakethedistinctionbetweenexoplanations doublyso. Researchinsocialpsychologyhasshownthat
andexplanations,beyondacademicpedantry. additionalinformationcanincreasepersuasiveness, evenifitisirrelevanttotherequest[17]. Usersareeasily Itisnotthatmechanismalexplanationsforlanguagemodels
Harmsofexoplanations influencedandcanplacetheirtrustinmeaningless arelacking. Despitesignificantchallenges[29],numerous
explanations[10],andcanover-trustinterpretability aids techniqueshavebeendevelopedtoexplainfeature
Falseconfidence: bold [14]. Allowingasystemtopresentexoplanationswiththe attribution,neuronactivation,modelattention,etc. [37,19].
exoplanationsofhallucinated veneerofexplanations,inasituationwheretheuser
statementscangiveusers expectsanexplanation,shouldthereforebeconsidereda However,mechanismalexplanationsarenottheaiminand
falseconfidenceinthose darkpattern[2]. ofthemselves;theimportantaspectoftheuserexperience
statements,withdangerous thatexplanationsneedtofulfilisdecisionsupport [31,28,
consequences. Theillusionofexplanationperpetuated byexoplanations 19,11]. Istheoutputcorrect? Ifitisn’t,whatdoIneedtodo
posesathreattodecision-makingprocesses,ineveryday tofixit? CanItrustthis? Forexample,inanAIsystemthat
Diminishedcritical knowledgeworkaswellasinhigh-stakes environments generatesspreadsheet formulasfromnaturallanguage
thinking: insteadof suchaslegalormedicalcontexts. Relianceon queries,itisbyfarmoreimportantandconsequential for
engaginginintrospection exoplanationsmaydiminishusers’criticalthinkingand theuserexperiencetoexplainthegeneratedformula,what
orevaluatingthelogicand decision-makingabilities. itdoesandhowitworks,ratherthanthemechanismofthe
evidencebehindthemodel’s languagemodelthatproducedit. Mechanismal
Insteadofengaginginintrospectionorevaluatingthelogic
output,usersmayaccept explanationsmaygenerateconfusionandinformation
andevidencebehindthemodel’soutput,usersmayaccept
exoplanationsatfacevalue. overloadinsuchacontext[16,19].
exoplanationsatfacevalue. Andwhyshouldn’tthey?
Computersaretools,andtoolsarenotviewedasbeing AsMiller[24]andSarkar[29]havenoted,human-human
Erosionoftrust: when
adversarial totheactivitytheyfacilitate. Itdoesnotseemto explanationsaregenerallynotmechanismal,inthesense
usersdiscoverthat
beaproductiveavenueforinteractiondesigntoattemptto thathuman-generated explanationsofhumanbehaviour
exoplanationsdonot
erasethecultural,inertialtendencytotrustcomputersas rarelyinvokelow-levelpsychological orneurological
accuratelyexplainlanguage
computationallycorrectmachines,evenifthattendencyis phenomena,yettheyarestillgenerallysuccessfulat
modelbehaviour,thiscan
wildlymisplacedinlanguagemodels. fulfillingtheneedsofeverydaycommunication. Effective
underminethecredibilityof
explanationscanbecontrastive,counterfactual, and
AIsystems.
Exoplanationscanalsoimpairusertrustandconfidencein
justificatory,withrespecttosomeintendedstateofaffairs;
AIsystemsinthelongterm. Asexoplanationsarerevealed
thesehavenothingtodowiththecausalmechanisms
tonot,infact,havetheirputativeexplanatory power,this
underlyingbehaviour.
canerodetrust,andundermineanylegitimatecredibility
thatAIsystemsmighthave. Partsofthedecisionsupportproblemcanbeaddressed
thoughanapproachtermed“co-audit”[12]: toolstohelp
Recontextualising ex(o)planations checkAI-generated content. Anexampleofthiswouldbe
Thisisclearlyacasethatcallsforasocialconstructionof the“grounded utterances” generatedthroughaseparate
explainability,whichshould“startwith“who”therelevant anddeterministicmechanismtoexplainthemodeloutput
stakeholders are,theirexplainabilityneeds,andjustifyhow [20]. Anothertechnique,employedbyMicrosoftCopilot
aparticularconceptionofexplainabilitysatisfiestheshared (formerlyBingChat)istocitereferencestoitsWebsources
goalsoftherelevantsocialgroup” [8]. thatcanbefollowedandverified. Thesearetrueexplanations: theyrelyonmechanismsandauthorities metacognitiveguidingquestions,suchas“whatdoI
separatefromthemodelitselfandwithanepistemically understandfromthetextsofar?” significantlyimproves
privilegedviewovertheoutputgeneration process. readingcomprehension[27]. Framingexplanationsas
questionsimproveshumanlogicaldiscernment[5]. When
Butexoplanationsthemselvescanalsobeuseful. Without
technologysparksconflictindiscussions,itimprovescritical
needingtointrospectthemodel,theycangenerate
thinking[18]. Usersareinfluencedbythelanguageof
statementswhichhelptheuser rationalise,justify,and
conversational systemsandcanchangetheirinstructional
evaluate. Theycangeneratetextthatpromptstheuser to
vocabularyandgrammarafterjustasingleexposureto
reflectontheoutputandtheirintents. Exoplanationscan
systemoutput[20]. Theverysameforcesthatinfluence
thuspromotecriticalthinkingaboutinteractionswith
andnudgeusersintotrustingfalseexplanationscanbe
generativeAI[30]. marshalledfortheirbenefitinstead.
Iproposeasimpledesignimplicationthatcanbeapplied
Goingforward,asmoretrueexplanationmechanismsare
immediately: theintroductionofguardrailsandinterface developed: co-audittools,groundedutterances, citations,
warningsagainstexoplanations. Commercialsystemssuch
etc.,suchdisclaimersmaybereplacedwithmoreconcrete
asChatGPTalreadyaboundwithguardrailsagainstcontent
decision-support mechanisms. However,theutilityof
deemedinappropriate bythesystemdesigners,suchas
exoplanationsascriticalthinkingsupportwillremain. The
violentorsexualcontent,andnumerousdisclaimersagainst
keywillbeinhelpingtheuserdevelopsafeandeffective
hallucinations,totheeffectof“AIgeneratedcontentmaybe
behavioursandmentalmodelsoftrustaroundthedifferent
incorrect.” Totheseconsiderations, Isuggestadding
sourcesofevaluationandreflectionavailable.
guardrailsagainstexoplanationsmasquerading as
explanations,andcontextualising themtoallowtheirtrue Acknowledgements
andappropriateutilitytoshine. Thankstomyreviewersfortheirtimeandfeedback.
Forexample,iftheuserasksthesystemtoexplainits
output,itcouldproduceadisclaimerofthefollowingtype:
“Youaskedforanexplanation,butasalanguagemodel,I
amincapableofexplainingmyownbehaviour.” Itmight
thenfollowthiswith“However,Icanprovideexamplesof
howtojustify,rationalise,orevaluatemypreviousresponse.
Hereareexampleargumentsforandagainstit. Thisisnot
anexplanationofmypreviousresponse.” Together,sucha
disclaimerfollowedbyanexoplanationcouldhelpdefuse
theworstdangersandinfusesomecriticalthought.
Thereisreasontobelievethatsuchsimpleinterventions
canhaveameaningfuleffect. ThepresenceofREFERENCES [7] UpolEhsan,SamirPassi,QVeraLiao,LarryChan,I
[1] RishiBommasani,DrewAHudson,EhsanAdeli,Russ Lee,MichaelMuller,MarkORiedl,andothers.2021b.
Altman,SimranArora,SydneyvonArx,MichaelS Thewhoinexplainableai: Howaibackground shapes
Bernstein,JeannetteBohg,AntoineBosselut,Emma perceptionsofaiexplanations.arXivpreprint
Brunskill,andothers.2021.Ontheopportunities and arXiv:2107.13509 (2021).
risksoffoundationmodels.arXivpreprint
[8] UpolEhsanandMarkO.Riedl.2022.Social
arXiv:2108.07258 (2021).
ConstructionofXAI:DoWeNeedOneDefinitionto
[2] HBrignull,MLeiser,CSantos,andKDoshi.2023. RuleThemAll? (2022).
Deceptivepatterns–userinterfacesdesignedtotrick
[9] UpolEhsan,KoustuvSaha,MunmunDeChoudhury,
you.(42023).https://www.deceptive.design/
andMarkORiedl.2023.ChartingtheSociotechnical
[3] JonBrodkin.2023.Lawyercited6fakecasesmadeup GapinExplainableAI:AFrameworktoAddressthe
byCHATGPT;judgecallsit“unprecedented”. (Jun GapinXAI.ProceedingsoftheACMon
2023). Human-ComputerInteraction 7,CSCW1(2023),1–32.
https://arstechnica.com/tech-policy/2023/05/lawyer-cited-6-fake-cases-made-up-by-chatgpt-judge-calls-it-unprecedented/
[10] MalinEiband,DanielBuschek,AlexanderKremer,and
[4] SébastienBubeck,VarunChandrasekaran, Ronen HeinrichHussmann.2019.TheImpactofPlacebic
Eldan,JohannesGehrke,EricHorvitz,EceKamar, ExplanationsonTrustinIntelligentSystems.In
PeterLee,YinTatLee,YuanzhiLi,ScottLundberg, ExtendedAbstractsofthe2019CHIConferenceon
andothers.2023.Sparksofartificialgeneral HumanFactorsinComputingSystems(CHIEA’19).
intelligence: Earlyexperimentswithgpt-4.arXiv AssociationforComputingMachinery,NewYork,NY,
preprintarXiv:2303.12712 (2023).
USA,1–6.DOI:
http://dx.doi.org/10.1145/3290607.3312787
[5] ValdemarDanry,PatPataranutaporn, YaoliMao,and
PattieMaes.2023.Don’tJustTellMe,AskMe: AI [11] RaymondFokandDanielS.Weld.2024.InSearchof
SystemsthatIntelligentlyFrameExplanationsas Verifiability: ExplanationsRarelyEnable
QuestionsImproveHumanLogicalDiscernment ComplementaryPerformanceinAI-AdvisedDecision
AccuracyoverCausalAIexplanations.InProceedings Making.(2024).
ofthe2023CHIConferenceonHumanFactorsin
[12] AndrewDGordon,CarinaNegreanu, José
ComputingSystems.1–13.
Cambronero,RasikaChakravarthy, IanDrosos,Hao
[6] UpolEhsan,QVeraLiao,MichaelMuller,MarkO Fang,BhaskarMitra,HannahRichardson,Advait
Riedl,andJustinDWeisz.2021a.Expanding Sarkar,StephanieSimmons,andothers.2023.
explainability: Towardssocialtransparency inai Co-audit: toolstohelphumansdouble-check
systems.InProceedingsofthe2021CHIConference AI-generated content.arXivpreprintarXiv:2310.01297
onHumanFactorsinComputingSystems.1–19. (2023).[13] ShiyuanHuang,SiddarthMamidanna,Shreedhar FactorsinComputingSystems(CHI’23).Association
Jangam,YilunZhou,andLeilaniHGilpin.2023.Can forComputingMachinery,NewYork,NY,USA,Article
largelanguagemodelsexplainthemselves? astudyof 451,22pages.DOI:
llm-generatedself-explanations. arXivpreprint http://dx.doi.org/10.1145/3544548.3581159
arXiv:2310.11207 (2023).
[19] Q.VeraLiaoandJenniferWortmanVaughan.2024.AI
[14] HarmanpreetKaur,HarshaNori,SamuelJenkins, TransparencyintheAgeofLLMs: AHuman-Centered
RichCaruana,HannaWallach,andJennifer ResearchRoadmap.HarvardDataScienceReview
WortmanVaughan.2020.Interpreting Interpretability: (feb292024).
Understanding DataScientists’UseofInterpretability https://hdsr.mitpress.mit.edu/pub/aelql9qy.
ToolsforMachineLearning.InProceedingsofthe
[20] MichaelXieyangLiu,AdvaitSarkar,CarinaNegreanu,
2020CHIConferenceonHumanFactorsinComputing
BenjaminZorn,JackWilliams,NeilToronto,and
Systems(CHI’20).AssociationforComputing
Machinery,NewYork,NY,USA,1–14.DOI: AndrewDGordon.2023.“WhatItWantsMeToSay”:
BridgingtheAbstractionGapBetweenEnd-User
http://dx.doi.org/10.1145/3313831.3376219
ProgrammersandCode-Generating LargeLanguage
[15] ToddKulesza,MargaretBurnett,Weng-KeenWong, Models.InProceedingsofthe2023CHIConference
andSimoneStumpf.2015.Principlesofexplanatory onHumanFactorsinComputingSystems.1–31.
debuggingtopersonalizeinteractivemachinelearning.
[21] ScottMLundbergandSu-InLee.2017.Aunified
InProceedingsofthe20thinternational conferenceon
approachtointerpretingmodelpredictions.Advances
intelligentuserinterfaces.126–137.
inneuralinformationprocessingsystems30(2017).
[16] ToddKulesza,SimoneStumpf,MargaretBurnett,
SherryYang,IrwinKwan,andWeng-KeenWong. [22] AndreasMadsen,SarathChandar,andSivaReddy.
2013.Toomuch,toolittle,orjustright? Ways 2024.Areself-explanations fromLargeLanguage
explanationsimpactendusers’mentalmodels.In Modelsfaithful? (2024).
2013IEEESymposiumonvisuallanguagesand
[23] SaraMerken.2023.NewYorklawyerssanctionedfor
humancentriccomputing.IEEE,3–10.
usingfakeChatGPTcasesinlegalbrief.(Jun2023).
[17] EllenJLanger,ArthurBlank,andBenzionChanowitz. https://www.reuters.com/legal/new-york-lawyers-sanctioned-using-fake
1978.Themindlessnessofostensiblythoughtful
[24] TimMiller.2019.Explanationinartificialintelligence:
action: Theroleof"placebic"informationin
Insightsfromthesocialsciences.Artificialintelligence
interpersonal interaction.Journalofpersonalityand
267(2019),1–38.
socialpsychology 36,6(1978),635.
[25] NazneenFatemaRajani,BryanMcCann,Caiming
[18] SunokLee,DasomChoi,MinhaLee,JonghakChoi,
Xiong,andRichardSocher.2019.Explainyourself!
andSangsuLee.2023.FosteringYouth’sCritical
leveraginglanguagemodelsforcommonsense
ThinkingCompetencyAboutAIthroughExhibition.In
reasoning.arXivpreprintarXiv:1906.02361 (2019).
Proceedingsofthe2023CHIConferenceonHuman[26] MarcoTulioRibeiro,SameerSingh,andCarlos [33] KarenSimonyan,AndreaVedaldi,andAndrew
Guestrin.2016."WhyshouldItrustyou?"Explaining Zisserman.2013.Deepinsideconvolutional networks:
thepredictionsofanyclassifier.InProceedingsofthe Visualisingimageclassificationmodelsandsaliency
22ndACMSIGKDDinternational conferenceon maps.arXivpreprintarXiv:1312.6034 (2013).
knowledgediscoveryanddatamining.1135–1144.
[34] MilesTurpin,JulianMichael,EthanPerez,andSamuel
[27] GavrielSalomon.1988.AIinreverse: Computertools Bowman.2024.Languagemodelsdon’talwayssay
thatturncognitive.Journalofeducationalcomputing whattheythink: unfaithfulexplanationsin
research 4,2(1988),123–139. chain-of-thought prompting.AdvancesinNeural
InformationProcessingSystems36(2024).
[28] AdvaitSarkar.2016.Interactiveanalyticalmodelling.
TechnicalReportUCAM-CL-TR-920.Universityof [35] JasonWei,XuezhiWang,DaleSchuurmans,Maarten
Cambridge,ComputerLaboratory. DOI: Bosma,FeiXia,EdChi,QuocVLe,DennyZhou,and
http://dx.doi.org/10.48456/tr-920 others.2022.Chain-of-thought promptingelicits
reasoninginlargelanguagemodels.Advancesin
[29] AdvaitSarkar.2022.IsexplainableAIaraceagainst
neuralinformationprocessingsystems35(2022),
modelcomplexity?.InWorkshoponTransparency and
24824–24837.
ExplanationsinSmartSystems(TeXSS),in
conjunctionwithACMIntelligentUserInterfaces(IUI [36] MatthewDZeilerandRobFergus.2014.Visualizing
2022)(CEURWorkshopProceedings). 192–199. andunderstanding convolutional networks.In
http://ceur-ws.org/Vol-3124/paper22.pdf ComputerVision–ECCV2014: 13thEuropean
Conference,Zurich,Switzerland,September6-12,
[30] AdvaitSarkar.2024.AIShouldChallenge,NotObey.
2014,Proceedings,PartI13.Springer,818–833.
CommunicationsoftheACM(inpress)(2024).
[37] HaiyanZhao,HanjieChen,FanYang,NinghaoLiu,
[31] AdvaitSarkar,MatejaJamnik,AlanF.Blackwell,and
HuiqiDeng,HengyiCai,ShuaiqiangWang,DaweiYin,
MartinSpott.2015.Interactivevisualmachinelearning
andMengnanDu.2024.Explainabilityforlarge
inspreadsheets.In2015IEEESymposiumonVisual
languagemodels: Asurvey.ACMTransactionson
LanguagesandHuman-CentricComputing(VL/HCC).
IntelligentSystemsandTechnology 15,2(2024),
159–163.DOI:
1–38.
http://dx.doi.org/10.1109/VLHCC.2015.7357211
[38] JiachenZhao,ZonghaiYao,ZhichaoYang,andHong
[32] DaneSherburn,BilalChughtai,andOwainEvans.
Yu.2023.SELF-EXPLAIN:TeachingLargeLanguage
2024.LanguageModelsStruggletoExplain
ModelstoReasonComplexQuestionsbyThemselves.
Themselves.(2024).
arXivpreprintarXiv:2311.06985 (2023).
https://openreview.net/forum?id=o6eUNPBAEc