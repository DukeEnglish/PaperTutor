[
    {
        "title": "xLSTM: Extended Long Short-Term Memory",
        "authors": "Maximilian BeckKorbinian PöppelMarkus SpanringAndreas AuerOleksandra PrudnikovaMichael KoppGünter KlambauerJohannes BrandstetterSepp Hochreiter",
        "links": "http://arxiv.org/abs/2405.04517v1",
        "entry_id": "http://arxiv.org/abs/2405.04517v1",
        "pdf_url": "http://arxiv.org/pdf/2405.04517v1",
        "summary": "In the 1990s, the constant error carousel and gating were introduced as the\ncentral ideas of the Long Short-Term Memory (LSTM). Since then, LSTMs have\nstood the test of time and contributed to numerous deep learning success\nstories, in particular they constituted the first Large Language Models (LLMs).\nHowever, the advent of the Transformer technology with parallelizable\nself-attention at its core marked the dawn of a new era, outpacing LSTMs at\nscale. We now raise a simple question: How far do we get in language modeling\nwhen scaling LSTMs to billions of parameters, leveraging the latest techniques\nfrom modern LLMs, but mitigating known limitations of LSTMs? Firstly, we\nintroduce exponential gating with appropriate normalization and stabilization\ntechniques. Secondly, we modify the LSTM memory structure, obtaining: (i) sLSTM\nwith a scalar memory, a scalar update, and new memory mixing, (ii) mLSTM that\nis fully parallelizable with a matrix memory and a covariance update rule.\nIntegrating these LSTM extensions into residual block backbones yields xLSTM\nblocks that are then residually stacked into xLSTM architectures. Exponential\ngating and modified memory structures boost xLSTM capabilities to perform\nfavorably when compared to state-of-the-art Transformers and State Space\nModels, both in performance and scaling.",
        "updated": "2024-05-07 17:50:21 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.04517v1"
    },
    {
        "title": "Efficient Online Set-valued Classification with Bandit Feedback",
        "authors": "Zhou WangXingye Qiao",
        "links": "http://arxiv.org/abs/2405.04393v1",
        "entry_id": "http://arxiv.org/abs/2405.04393v1",
        "pdf_url": "http://arxiv.org/pdf/2405.04393v1",
        "summary": "Conformal prediction is a distribution-free method that wraps a given machine\nlearning model and returns a set of plausible labels that contain the true\nlabel with a prescribed coverage rate. In practice, the empirical coverage\nachieved highly relies on fully observed label information from data both in\nthe training phase for model fitting and the calibration phase for quantile\nestimation. This dependency poses a challenge in the context of online learning\nwith bandit feedback, where a learner only has access to the correctness of\nactions (i.e., pulled an arm) but not the full information of the true label.\nIn particular, when the pulled arm is incorrect, the learner only knows that\nthe pulled one is not the true class label, but does not know which label is\ntrue. Additionally, bandit feedback further results in a smaller labeled\ndataset for calibration, limited to instances with correct actions, thereby\naffecting the accuracy of quantile estimation. To address these limitations, we\npropose Bandit Class-specific Conformal Prediction (BCCP), offering coverage\nguarantees on a class-specific granularity. Using an unbiased estimation of an\nestimand involving the true label, BCCP trains the model and makes set-valued\ninferences through stochastic gradient descent. Our approach overcomes the\nchallenges of sparsely labeled data in each iteration and generalizes the\nreliability and applicability of conformal prediction to online decision-making\nenvironments.",
        "updated": "2024-05-07 15:14:51 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.04393v1"
    },
    {
        "title": "Revisiting character-level adversarial attacks",
        "authors": "Elias Abad RocamoraYongtao WuFanghui LiuGrigorios G. ChrysosVolkan Cevher",
        "links": "http://arxiv.org/abs/2405.04346v1",
        "entry_id": "http://arxiv.org/abs/2405.04346v1",
        "pdf_url": "http://arxiv.org/pdf/2405.04346v1",
        "summary": "Adversarial attacks in Natural Language Processing apply perturbations in the\ncharacter or token levels. Token-level attacks, gaining prominence for their\nuse of gradient-based methods, are susceptible to altering sentence semantics,\nleading to invalid adversarial examples. While character-level attacks easily\nmaintain semantics, they have received less attention as they cannot easily\nadopt popular gradient-based methods, and are thought to be easy to defend.\nChallenging these beliefs, we introduce Charmer, an efficient query-based\nadversarial attack capable of achieving high attack success rate (ASR) while\ngenerating highly similar adversarial examples. Our method successfully targets\nboth small (BERT) and large (Llama 2) models. Specifically, on BERT with SST-2,\nCharmer improves the ASR in 4.84% points and the USE similarity in 8% points\nwith respect to the previous art. Our implementation is available in\nhttps://github.com/LIONS-EPFL/Charmer.",
        "updated": "2024-05-07 14:23:22 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.04346v1"
    },
    {
        "title": "Multiparameter regularization and aggregation in the context of polynomial functional regression",
        "authors": "Elke R. GizewskiMarkus HolzleitnerLukas Mayer-SuessSergiy Pereverzyev Jr.Sergei V. Pereverzyev",
        "links": "http://arxiv.org/abs/2405.04147v1",
        "entry_id": "http://arxiv.org/abs/2405.04147v1",
        "pdf_url": "http://arxiv.org/pdf/2405.04147v1",
        "summary": "Most of the recent results in polynomial functional regression have been\nfocused on an in-depth exploration of single-parameter regularization schemes.\nIn contrast, in this study we go beyond that framework by introducing an\nalgorithm for multiple parameter regularization and presenting a theoretically\ngrounded method for dealing with the associated parameters. This method\nfacilitates the aggregation of models with varying regularization parameters.\nThe efficacy of the proposed approach is assessed through evaluations on both\nsynthetic and some real-world medical data, revealing promising results.",
        "updated": "2024-05-07 09:26:20 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.04147v1"
    },
    {
        "title": "Scalable Vertical Federated Learning via Data Augmentation and Amortized Inference",
        "authors": "Conor HassanMatthew SuttonAntonietta MiraKerrie Mengersen",
        "links": "http://arxiv.org/abs/2405.04043v1",
        "entry_id": "http://arxiv.org/abs/2405.04043v1",
        "pdf_url": "http://arxiv.org/pdf/2405.04043v1",
        "summary": "Vertical federated learning (VFL) has emerged as a paradigm for collaborative\nmodel estimation across multiple clients, each holding a distinct set of\ncovariates. This paper introduces the first comprehensive framework for fitting\nBayesian models in the VFL setting. We propose a novel approach that leverages\ndata augmentation techniques to transform VFL problems into a form compatible\nwith existing Bayesian federated learning algorithms. We present an innovative\nmodel formulation for specific VFL scenarios where the joint likelihood\nfactorizes into a product of client-specific likelihoods. To mitigate the\ndimensionality challenge posed by data augmentation, which scales with the\nnumber of observations and clients, we develop a factorized amortized\nvariational approximation that achieves scalability independent of the number\nof observations. We showcase the efficacy of our framework through extensive\nnumerical experiments on logistic regression, multilevel regression, and a\nnovel hierarchical Bayesian split neural net model. Our work paves the way for\nprivacy-preserving, decentralized Bayesian inference in vertically partitioned\ndata scenarios, opening up new avenues for research and applications in various\ndomains.",
        "updated": "2024-05-07 06:29:06 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.04043v1"
    }
]