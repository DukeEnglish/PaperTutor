[
    {
        "title": "TorchDriveEnv: A Reinforcement Learning Benchmark for Autonomous Driving with Reactive, Realistic, and Diverse Non-Playable Characters",
        "authors": "Jonathan Wilder LavingtonKe ZhangVasileios LioutasMatthew NiedobaYunpeng LiuDylan GreenSaeid NaderipariziXiaoxuan LiangSetareh DabiriAdam ŚcibiorBerend ZwartsenbergFrank Wood",
        "links": "http://arxiv.org/abs/2405.04491v1",
        "entry_id": "http://arxiv.org/abs/2405.04491v1",
        "pdf_url": "http://arxiv.org/pdf/2405.04491v1",
        "summary": "The training, testing, and deployment, of autonomous vehicles requires\nrealistic and efficient simulators. Moreover, because of the high variability\nbetween different problems presented in different autonomous systems, these\nsimulators need to be easy to use, and easy to modify. To address these\nproblems we introduce TorchDriveSim and its benchmark extension TorchDriveEnv.\nTorchDriveEnv is a lightweight reinforcement learning benchmark programmed\nentirely in Python, which can be modified to test a number of different factors\nin learned vehicle behavior, including the effect of varying kinematic models,\nagent types, and traffic control patterns. Most importantly unlike many replay\nbased simulation approaches, TorchDriveEnv is fully integrated with a state of\nthe art behavioral simulation API. This allows users to train and evaluate\ndriving models alongside data driven Non-Playable Characters (NPC) whose\ninitializations and driving behavior are reactive, realistic, and diverse. We\nillustrate the efficiency and simplicity of TorchDriveEnv by evaluating common\nreinforcement learning baselines in both training and validation environments.\nOur experiments show that TorchDriveEnv is easy to use, but difficult to solve.",
        "updated": "2024-05-07 17:02:02 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.04491v1"
    },
    {
        "title": "Iterative Experience Refinement of Software-Developing Agents",
        "authors": "Chen QianJiahao LiYufan DangWei LiuYiFei WangZihao XieWeize ChenCheng YangYingli ZhangZhiyuan LiuMaosong Sun",
        "links": "http://arxiv.org/abs/2405.04219v1",
        "entry_id": "http://arxiv.org/abs/2405.04219v1",
        "pdf_url": "http://arxiv.org/pdf/2405.04219v1",
        "summary": "Autonomous agents powered by large language models (LLMs) show significant\npotential for achieving high autonomy in various scenarios such as software\ndevelopment. Recent research has shown that LLM agents can leverage past\nexperiences to reduce errors and enhance efficiency. However, the static\nexperience paradigm, reliant on a fixed collection of past experiences acquired\nheuristically, lacks iterative refinement and thus hampers agents'\nadaptability. In this paper, we introduce the Iterative Experience Refinement\nframework, enabling LLM agents to refine experiences iteratively during task\nexecution. We propose two fundamental patterns: the successive pattern,\nrefining based on nearest experiences within a task batch, and the cumulative\npattern, acquiring experiences across all previous task batches. Augmented with\nour heuristic experience elimination, the method prioritizes high-quality and\nfrequently-used experiences, effectively managing the experience space and\nenhancing efficiency. Extensive experiments show that while the successive\npattern may yield superior results, the cumulative pattern provides more stable\nperformance. Moreover, experience elimination facilitates achieving better\nperformance using just 11.54% of a high-quality subset.",
        "updated": "2024-05-07 11:33:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.04219v1"
    },
    {
        "title": "A Guide to Re-Implementing Agent-based Models: Experiences from the HUMAT Model",
        "authors": "Önder GürcanTimo SzczepanskaPatrycja Antosz",
        "links": "http://arxiv.org/abs/2405.03994v1",
        "entry_id": "http://arxiv.org/abs/2405.03994v1",
        "pdf_url": "http://arxiv.org/pdf/2405.03994v1",
        "summary": "Replicating existing agent-based models poses significant challenges,\nparticularly for those new to the field. This article presents an all-\nencompassing guide to re-implementing agent-based models, encompassing vital\nconcepts such as comprehending the original model, utilizing agent-based\nmodeling frameworks, simulation design, model validation, and more. By\nembracing the proposed guide, researchers and practitioners can gain a profound\nunderstanding of the entire re-implementation process, resulting in heightened\naccuracy and reliability of simulations for complex systems. Furthermore, this\narticle showcases the re-implementation of the HUMAT socio-cognitive\narchitecture, with a specific focus on designing a versatile,\nlanguage-independent model. The encountered challenges and pitfalls in the\nre-implementation process are thoroughly discussed, empowering readers with\npractical insights. Embrace this guide to expedite model development while\nensuring robust and precise simulations.",
        "updated": "2024-05-07 04:17:03 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.03994v1"
    },
    {
        "title": "Unified End-to-End V2X Cooperative Autonomous Driving",
        "authors": "Zhiwei LiBozhen ZhangLei YangTianyu ShenNuo XuRuosen HaoWeiting LiTao YanHuaping Liu",
        "links": "http://arxiv.org/abs/2405.03971v1",
        "entry_id": "http://arxiv.org/abs/2405.03971v1",
        "pdf_url": "http://arxiv.org/pdf/2405.03971v1",
        "summary": "V2X cooperation, through the integration of sensor data from both vehicles\nand infrastructure, is considered a pivotal approach to advancing autonomous\ndriving technology. Current research primarily focuses on enhancing perception\naccuracy, often overlooking the systematic improvement of accident prediction\naccuracy through end-to-end learning, leading to insufficient attention to the\nsafety issues of autonomous driving. To address this challenge, this paper\nintroduces the UniE2EV2X framework, a V2X-integrated end-to-end autonomous\ndriving system that consolidates key driving modules within a unified network.\nThe framework employs a deformable attention-based data fusion strategy,\neffectively facilitating cooperation between vehicles and infrastructure. The\nmain advantages include: 1) significantly enhancing agents' perception and\nmotion prediction capabilities, thereby improving the accuracy of accident\npredictions; 2) ensuring high reliability in the data fusion process; 3)\nsuperior end-to-end perception compared to modular approaches. Furthermore, We\nimplement the UniE2EV2X framework on the challenging DeepAccident, a simulation\ndataset designed for V2X cooperative driving.",
        "updated": "2024-05-07 03:01:40 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.03971v1"
    },
    {
        "title": "Select to Perfect: Imitating desired behavior from large multi-agent data",
        "authors": "Tim FranzmeyerEdith ElkindPhilip TorrJakob FoersterJoao Henriques",
        "links": "http://arxiv.org/abs/2405.03735v1",
        "entry_id": "http://arxiv.org/abs/2405.03735v1",
        "pdf_url": "http://arxiv.org/pdf/2405.03735v1",
        "summary": "AI agents are commonly trained with large datasets of demonstrations of human\nbehavior. However, not all behaviors are equally safe or desirable. Desired\ncharacteristics for an AI agent can be expressed by assigning desirability\nscores, which we assume are not assigned to individual behaviors but to\ncollective trajectories. For example, in a dataset of vehicle interactions,\nthese scores might relate to the number of incidents that occurred. We first\nassess the effect of each individual agent's behavior on the collective\ndesirability score, e.g., assessing how likely an agent is to cause incidents.\nThis allows us to selectively imitate agents with a positive effect, e.g., only\nimitating agents that are unlikely to cause incidents. To enable this, we\npropose the concept of an agent's Exchange Value, which quantifies an\nindividual agent's contribution to the collective desirability score. The\nExchange Value is the expected change in desirability score when substituting\nthe agent for a randomly selected agent. We propose additional methods for\nestimating Exchange Values from real-world datasets, enabling us to learn\ndesired imitation policies that outperform relevant baselines. The project\nwebsite can be found at https://tinyurl.com/select-to-perfect.",
        "updated": "2024-05-06 15:48:24 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.03735v1"
    }
]