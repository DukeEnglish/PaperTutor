Adaptive Prediction Ensemble:
Improving Out-of-Distribution Generalization of Motion Forecasting
Jinning Li1 Jiachen Li2 Sangjae Bae3 David Isele3
Abstract—Deep learning-based trajectory prediction models
forautonomousdrivingoftenstrugglewithgeneralizationtoout-
of-distribution (OOD) scenarios, sometimes performing worse
than simple rule-based models. To address this limitation, we
propose a novel framework, Adaptive Prediction Ensemble
(APE),whichintegratesdeeplearningandrule-basedprediction
experts. A learned routing function, trained concurrently with
the deep learning model, dynamically selects the most reliable
prediction based on the input scenario. Our experiments on
large-scale datasets, including Waymo Open Motion Dataset
(WOMD) and Argoverse, demonstrate improvement in zero-
shot generalization across datasets. We show that our method
outperforms individual prediction models and other variants,
particularly in long-horizon prediction and scenarios with a
highproportionofOODdata.Thisworkhighlightsthepotential (a) (b)
of hybrid approaches for robust and generalizable motion
prediction in autonomous driving.
Fig. 1. Illustration of the motivation of improving prediction algorithm
I. INTRODUCTION byAdaptivePredictionEnsemble.(a)Anexamplescenariowherevanilla
rule-basedpredictionalgorithmoutperformsdeepneuralnetworkprediction
Trajectory prediction is critical for safe and reliable au- algorithm (MTR [2]). (b) A comparison of the error (minADE) between
tonomous vehicle systems. Existing prediction algorithms [1], deep NN and rule-based prediction. The rule-based method outperforms
deepNNinaconsiderableamountofscenarios,whicharetheonesbelow
[2], [3], [4] have achieved high accuracy on real-world
theredline.
scenarios, such as real traffic datasets. However, most of
these algorithms only work best for in-distribution scenarios.
overacomparabledensemodelinsize,wearemoreinterested
Intuitively, traffic scenarios in different cities of the same
in investigating the generalization ability improvements upon
country should not possess drastic differences, and human
a single expert model. We generally find that deep learning
driving skills including their prediction and judgment, are
prediction models tend to overfit their training dataset,
not significantly affected. This is unfortunately not the case
making zero-shot performance unacceptable. Incorporating
for deep learning-based prediction algorithms [5], [6], [7].
a fleet of deep learning prediction experts or adopting a
If they are applied to out-of-distribution (OOD) scenes in a
similar size large dense model would not solve the problem,
zero-shot manner, such as predicting vehicle trajectories from
since increasing the model capacity would not mitigate
a different dataset than the training dataset, the performance
the overfitting problem if not making it worse. Therefore,
will drop dramatically even though the input representation
we propose to employ a rule-based prediction expert as
andformatarethesame.Insomecases,adeeplearning-based
an anomaly-handling strategy for deep learning prediction
prediction algorithm is not even as good as a simple constant
experts,inlightoftheinsightthatrule-basedpredictioncould
velocity model, as shown in Fig. 1. This is unfortunately a
bemorereliableinlong-tailcasesofdeeplearningprediction
largely under-explored topic. One natural way is to combine
experts.
the prediction from different sources, which resembles the
mixture of experts. As far as we know, we are the first to Thereareotherexistingmethodsfordomaingeneralization
explore concrete methods to improve OOD generalization to that usually handle the problem by data manipulation [13],
different datasets than training. representation learning [14], [15], or specially designed
Mixture of Experts (MoEs) [8] has gained popularity, learning strategy [16], [17] or inference workflow [18]. If
especially after the great success of Large Language Models. one aims to improve the generalization upon an existing
Most of the prior work showed MoEs can reach faster prediction model with prior methods, it is usually inevitable
inference [9], [10] compared to dense models with the to make modifications and re-train the original prediction
same number of parameters, and can also be pre-trained model. In comparison, the proposed method in this paper
faster [11], [12]. While they focused on MoEs’ advantage is a straightforward yet powerful approach to generalization
improvement by establishing a routing function and incorpo-
1 J.LiiswiththeUniversityofCalifornia,Berkeley,CA,USA. rating a rule-based baseline prediction model. The routing
2 J.LiiswiththeUniversityofCalifornia,Riverside,CA,USA.
function is trained concurrently with the prediction model
3 S.BaeandD.IselearewithHondaResearchInstitute,CA,USA.
ThisworkwassupportedbyHondaResearchInstitute,USA. and decides on whether to switch to the rule-based model
4202
luJ
21
]OR.sc[
1v57490.7042:viXrawhen the learning-based prediction model is unreliable. observed that deep learning-based predictors tend to have
The main contributions of this paper are as follows: unsatisfying performance on cross-dataset generalization.
• We identify the problem of generalization when zero- Therefore, we follow the idea of mixture-of-experts but do
shotevaluatingstate-of-the-art(SOTA)predictionmodels not train individual experts for specific sub-tasks. We include
between different benchmark datasets. The performance both deep learning-based and rule-based experts that can
(e.g., minADE and minFDE) of SOTA models drops perform general motion prediction tasks. A routing function
drastically. For these cases, it is even possible that basic istrainedconcurrentlywithdeeplearning-basedpredictors,so
rule-based prediction algorithms outperform sophisti- it is exposed to more diverse trajectory prediction candidates
cated deep learning-based prediction models. and hence the difficulty of ranking anomalous predictions is
• We propose a novel inference framework, Adaptive mitigated.
Prediction Ensemble (APE), where the learning-based
C. Finetuning with Human Feedback
prediction model will fall back to a rule-based model
accordingtotheirreliability.Theirreliabilityisestimated It is also a popular trend to finetune models on the
by a routing function trained concurrently with the target domain to improve generalization with guidance by
learning-based prediction model. experts trained from offline human demonstration [33] or
• Weevaluatetheproposedtrainingpipelineandinference a ranking function trained with human feedback [34], [35].
framework on benchmark datasets including Waymo While these methods are appealing and we could directly
Open Motion Dataset (WOMD) [19] and Argoverse apply the ranking function as a routing function in MoE,
dataset [20], which shows that the proposed method sig- they are not viable in our setting as we aim to deal with
nificantly improves prediction performance in zero-shot zero-shot generalization, and hence the algorithm does not
evaluations compared to individual prediction models. have access to the target domain or test data. We do not
have resources for human feedback on tens of millions of
II. RELATEDWORKS
trajectories either, so it is desired to leverage the routing
A. Motion Prediction with Uncertainty Estimation function trained in an automated pipeline, where we collect
Motion prediction algorithms for autonomous driving all the trajectory predictions output by the individual deep
have been successful on many datasets, and have been learning-based predictor since its training begins. In this way,
integratedintotheautonomystack[21],[22],[23],[24],[25]. all the footprints of the prediction outputs, no matter bad or
However,itisnotrarethatpredictionfailurecauseserroneous good, are included in the routing function training dataset.
downstream motion planning for autonomous vehicles [26]. The increased exposure beyond the training dataset of the
Therefore, it is desired to detect such prediction failure in an individual predictor boosts the ranking ability of the routing
efficientyet reliable manner.Therehavebeenmanyeffortsto function to differentiate reliable prediction candidates from
leverageuncertaintyestimationtodecidewhetheraprediction bad ones, and thus improves the zero-shot performance.
is reliable [27]. The prediction uncertainty was estimated
III. PROBLEMFORMULATION
by various methods, including ensemble [28], [29], [30],
dedicated uncertainty estimation model training [27], rule- In this paper, we focus on zero-shot learning and evaluate
based estimation [31], and data augmentation [32]. However, the motion prediction neural network models on samples
trainingnewmodelsspecializedinuncertaintyestimationand that were not observed during training in the autonomous
performingevaluationsonitsaccuracyisnotastraightforward driving domain. Specifically, we denote x1 i:T = {xt i|t ∈
task, because there is often no ground truth. Ensemble-based {1,...,T}} as a single agent trajectory in the i-th scene,
uncertainty estimation is costly both during training and represented by a series of features xt i from timestep 1 to T.
inference and may introduce too much variance, reducing The agents are constantly interacting with the environment
the reliability of out-of-distribution detection as we show for which the context information can be represented by
in the ablation study in Sec. V-F. Our method of training c1 i:T = {ct i|t ∈ (1,T)}. The i-th scene is denoted by s i =
a routing function concurrently with individual learning- {(xt i,ct i)|t∈(1,T)}. The task of the prediction model is to
based predictors can increase the exposure of the routing predict future trajectory distribution p(xT ih+1:Tf|x1 i:Th,c1 i:Th)
function to anomalous trajectory prediction upon the normal for an ego agent given its history features (states) x1 i:Th and
training dataset, and therefore the final prediction selected context information c i1:Th in the i−th scene, where T h is
from various predictor experts can have better performance the history horizon and T f is the lookahead horizon and
on zero-shot generalization tasks. T =T h+T f.
We are particularly interested in inspecting and improving
B. Mixture-of-Experts
thegeneralizationabilityupondeeplearning-basedprediction
There are also mixture-of-experts methods that collect model, which is trained on one dataset D = {s |i ∈
T i
a set of experts specializing in different sub-tasks, which (1,M )}, and evaluated on another dataset D = {s |i ∈
T E i
are likely to be included in the target domain [8]. These (1,M )}. Note that in this paper, the training and the
E
methods will then choose one suitable expert to be activated evaluation datasets are defined differently than the normal
during inference. In our setting, we do not assume a pre- conventionoftrainingandvalidation.Theymayormaynotbe
defined set of sub-tasks in the target domain, and we also generated from the same underlying distribution. We evaluateInputs Outputs
Prediction #1: score;
Feature Projection
Prediction #2: score;
Routing
…
Function
Ranking scores
Scene
Map Polylines
Rule Motion
based Encoder
Prediction Ego Feature Forecasting
Decoder
Object Feature
Traffic Scenario Deep NN Prediction
Fig.2. Themodelstructureofthelearnedroutingfunctionandthedeeplearning-basedpredictionalgorithm,whichsharethesamebackboneofscene
encoder,andaretrainedconcurrently.Inthisway,theroutingfunctionsharesthesamelevelofpowerfulsceneunderstandingabilitywiththemotion
predictionalgorithm,whiletrainedconcurrentlyonallfootprintpredictionoutputsincreasesitsexposuretodiverseanomaloustrajectorypredictionsand
hencemorecapabilityondifferentiatingpredictionquality.
the trained models in a completely new dataset, e.g., training progressivelyrefinestheunderstandingofthescenedynamics
on WOMD and testing on Argoverse. andultimatelygeneratespredictionsforthefuturetrajectories
of surrounding vehicles, potentially including multi-modal
IV. ADAPTIVEPREDICTIONENSEMBLE
predictions. The predictions are obtained through specialized
In this section, we present our approach, Adaptive Pre- prediction heads attached to the decoder layers. The training
diction Ensemble, to improving the test-time performance process optimizes the network to maximize the likelihood of
of motion prediction algorithms in zero-shot generalization thepredictedtrajectoriesmatchingtheactualgroundtruthdata.
tasks. It consists of two stages: 1) during the training stage, a This is achieved by formulating the motion prediction task
deep learning-based prediction model and a routing function as a Gaussian Mixture prediction and employing a negative
are trained concurrently; and 2) during the testing stage, a log-likelihood loss function L .
pred
rule-based prediction model is incorporated, and the final Generallyspeaking,ourproposedframeworkdoesnothave
prediction output is adaptively selected out of both deep any strict requirement on specific deep learning prediction
learning-based and rule-based prediction candidates by the models as individual predictor experts, rather we could apply
routing function according to their quality. any high-performance models as long as they have the
aforementioned properties.
A. Deep Learning Prediction Expert
We propose to adopt high-capacity neural networks with a B. Rule-Based Prediction Expert
powerful scene encoding module and a motion forecasting Rule-based prediction experts can work as a powerful
decoder module as the backbone for all deep learning models backup plan for the deep learning prediction expert. Deep
inthispaper,leveragingtheirsuperiorscenecontextencoding learning prediction experts suffer from long-tail problems,
and understanding ability. which in contrast are not such a challenge for rule-based
The deep learning prediction expert takes in a vector- prediction experts. Among numerous rule-based prediction
ized representation, including both history trajectories of algorithms,wediscoverthataconstantvelocitymodelcanbe
the vehicles in the scene and road map polylines, as the sufficient to showcase the improvements upon a single deep
input representation [36], where all the vector inputs are learning prediction model on the zero-shot test. Specifically,
centeredaroundtheegoagent.Theinputshouldbeprocessed we adopt a closed-form prediction model to extrapolate the
by a PointNet-like [37] encoder before being consumed ego agent’s trajectory with a constant velocity,
by a scene encoder. The scene encoder understands most
xt+1 =f(xt)=[xt+vt ,yt+vt ,vt ,vt ,δt]⊤, (1)
of the context information and generates embeddings for i i i i,x i i,y i,x i,y i
downstreampredictiontasks.Theextractedscenefeaturesare where (xt,yt) is the position coordinate, (vt ,vt ) is the
i i i,x i,y
fed into a decoder module with multiple layers. This module velocity, δt is the heading angle of the ego agent at time t
iin the i-th scene. We note that although the prediction of a Algorithm 1: Training and Inference Workflow
constant velocity model is always a straight line, it could be
1 Initialize: A motion prediction neural network Q ϕ, a
sufficient if the prediction frequency is high enough because
routing function network R , a rule-based prediction
θ
the prediction errors will be small in the short term.
model f, a training dataset D containing vehicle
C. Learned Routing Function trajectories for prediction tasks, a data buffer D rf for
routing function training;
Withagroupofexpertsavailable,alearnedroutingfunction
is needed. Its goal is to compare the proposed candidate 2 // Training
predictions generated by the experts and select the most 3 for epoch n in range(0, N) do
reliable one as the output. Thus, the generalization and zero- 4 for sample s in D do
shot performance of the whole prediction module now relies 5 Rule-based prediction: xˆ r =f(s1:Th);
on the ability to recognize and handle out-of-distribution 6 Learning-based prediction: xˆ l =Q ϕ(s1:Th);
scenarios of the learned routing function. Because the task is 7 Update ϕ: ϕ i ←ϕ i−1+ϵ ϕ∇ ϕL pred;
to pick the best prediction among a set of existing predicted 8 Rank the predictions xˆ r,xˆ l by ADE;
trajectories, we relax the original requirement on the zero- 9 Update θ by Eqn. 2 according to the ranking
(s,xˆ ,xˆ ): θ ←θ +ϵ ∇ L ;
shot performance of the generative model to a zero-shot chosen rejected j j−1 θ θ θ
10 end
performance requirement on a discriminative model, i.e.,
11 end
the learned routing function. In addition to the decrease in
12 // Inference
the difficulty of the generalization task, the learned routing
function also has access to more data modes, and its self- 13 for sample s1:Th in test dataset D test do
supervised training style enables further improvements in its 14 Rule-based prediction: xˆ r =f(s1:Th);
generalization ability. 15 Learning-based prediction: xˆ l =Q ϕ(s1:Th);
16 Output prediction
We propose to adopt the same scene context encoder
architecture of the deep learning prediction expert and add
xˆ =argmax(xˆ r,xˆ l,key=R θ(s1:Th,·));
17 end
a routing decoder head on top of the encoder. A detailed
structure illustration is shown in Fig. 2. Both the high model
capacity and the superior scene context encoding ability can
be inherited, while the difficulty of generalization is reduced expert predictions. Thus, the learned routing function can
forthelearnedroutingfunction.Theroutingfunctionmodelis have access to both cases where transformer prediction is
trainedconcurrentlywiththedeep learning predictionexperts worse or better than the rule-based prediction, and hence we
by the loss function can avoid the issue of mode collapse.
(cid:104)
L
θ
=−E
(s,xˆ)∼D
log(σ(R θ(s1:Th,xˆ cT hh o+ se1 n:T) D. Practical Implementation
(2)
(cid:105) We summarize our complete algorithm in Algorithm 1.
−R θ(s1:Th,xˆT reh je+ ct1 e: dT))) ,
Duringthetrainingphase,wetrainadeeplearningprediction
where R (·,xˆTh+1:T) and R (·,xˆTh+1:T) are the scores model as one of the experts. As it is being trained, we
θ chosen θ rejected collect and compare its outputs with predictions from the
generated by the routing function for the chosen prediction
rule-basedexpertagainstthegroundtruth,andusethelabeled
candidate and the rejected prediction candidate, respectively,
andσ(·)isaReLUlayer.xˆTh+1:T isthepredictioncandidate pairs of predictions to train a routing function with the same
transformer encoder structure and an additional routing head.
generated by the individual prediction expert. This loss func-
In the test phase, the environment states are input to both
tion is adopted from RL with human feedback (RLHF) [38],
deep learning and rule-based prediction models, which both
which encourages large gaps between the scores of the two
make proposals. The learned routing function consumes them
samples in the pair. Empirically, we find this loss function
and selects the better one as the final prediction result.
results in a more stable training process than other loss
functions such as cross-entropy loss.
V. EXPERIMENTS
As the deep learning-based prediction model is being
A. Experiment Setting
trained, we collect all its multi-modal prediction outputs.
These outputs and the predictions of the rule-based experts 1) DeepLearningPredictionExpert: Weadoptthestate-of-
for the same agent in the same scene are paired and both the-art prediction architecture MotionTransformer (MTR) [2]
comparedagainstthegroundtruthtrajectoryintermsofsome as the backbone of the deep learning prediction expert. It
metric, e.g., the average displacement error. Therefore, we ingests a vectorized representation, including both history
canhaveagroundtruthofwhichpredictedtrajectoryisbetter trajectoriesofthevehiclesinthesceneandroadmappolylines,
among the two. These pairs and labels are stored in a new as the input representation [36], where all the vector inputs
data buffer than the original training dataset and are used are centered around the ego agent. The inputs are first
to train the learned routing function. As the training of the preprocessed by a PointNet-like [37] polyline encoder and
transformer prediction model goes on, its prediction output thenfedintothetransformerscenecontextencoder.Thescene
goesfromsub-optimaltomorereasonablethantherule-based encoder enforces local attention which emphasizes the focuson local context information by adopting k−nearest neighbor where κ represents the number of modes predicted by
tofindkclosestpolylinestothepolylineofinterest.Thescene the model. We choose κ=6 in this paper. We also use
context encoded by the local scene encoder is then enhanced this metric to rank the prediction generated by different
by a dense future prediction, containing future interaction experts when training the learned routing function.
information. A static intention and dynamic searching query • minFDE: This metric computes the l2−displacement
pairisgeneratedandinputtothescenedecoder,alongwiththe between the ground truth trajectory and the closest
enhanced scene context encoding and a query content feature. prediction at the last time step:
Apredictionheadisappliedtoeachdecoderlayertogenerate
minFDE= min ||s¯T −sk,T|| .
future trajectories, which are represented by a Gaussian G G 2
k∈{1,...,κ}
MixtureModeltocapturemultimodalagentbehaviors.Please
refer to [2] for more model details. • Miss Rate: A miss is defined as the condition wherein
none of the M predicted object trajectories lie within
2) Rule-Based Prediction Expert: As described in Sec. IV-
the specified lateral and longitudinal tolerances of the
B, we apply a constant velocity model as the rule-based
ground truth trajectory at a designated time T.
prediction expert. It is also possible to adopt other more
complicatedrule-basedpredictionmodelstoincorporatemore • mAP: This metric is computed on top of Miss Rate.
The predictions that are classified as a miss are labeled
informationsuchaslaneandtrafficrules.However,thischoice
as negative, whereas non-miss is positive. Precision and
is to demonstrate that even a basic complement to a deep
recall are computed based on sorted confidence scores
learning model can improve the generalization ability of the
associatedwitheachprediction.ThemAPmetricisthen
whole algorithm.
computed as the interpolated precision values in [39].
3) LearnedRoutingFunction: Similartothedeeplearning
This metric offers a holistic assessment of the motion
prediction expert, the routing function also adopts MTR as
prediction performance.
the backbone for its scene understanding ability. It is trained
concurrentlywiththedeeplearningpredictionexperttogether In addition to the aforementioned common metrics for
with the output of the rule-based prediction expert, such that prediction tasks, we also propose to use Performance Gain
itisexposedtodiversetrajectorypredictionsandhencelearns Percentage to quantify the improvement upon baseline meth-
the ability to recognize their quality. ods with our proposed method, which is defined as
4) Prediction Tasks: We focus on zero-shot generalization
Metric(Proposed Method)
ofthepredictionmodelsacrossdifferentdatasets.Specifically, Perf Gain=100%− , (3)
Metric(Baseline Method)
we choose to use Waymo Open Motion Dataset (WOMD)
and Argoverse as the two datasets in our experiments. The and will be applied to ablation study in Sec. V-H and V-G.
framework is trained on one dataset and is zero-shot tested
D. Implementation Details
on another dataset without finetuning.
The feature input projection layer is set to be a 3−layer
B. Baselines
MLPwithahiddendimensionof256.Westack6transformer
We mainly perform training and evaluation stage isolation layers for the scene encoding layer. The embedding feature
andcombinationtoevaluatetheproposedtrainingframework. dimension of these layers is set to be 256. The motion
Specifically, we compare APE to the following baselines: prediction decoder and output projection head follow the
• MTR: MTR trained on one dataset (WOMD or Argov- implementation of MTR [2]. The routing function decoder is
erse) and zero-shot tested on another. a stack of 6 transformer layers with an embedding feature
• MTR (Oracle): MTR trained and tested on the same dimension of 256. The output projection head is a 3−layer
dataset, which serves as the performance upper bound. MLP with a hidden dimension of 256. The routing function
• ConstantVelocityPrediction(Const-Vel):Thebaseline decoder and output projection are updated with the scene
rule-based prediction method, which shows the lower encoderfrozen,aftereachtimethemotionpredictiondecoder
bound baseline performance. is updated. The models are trained by AdamW optimizer on
• APE (BS): uses an alternate routing function based on 4 GPUs (Nvidia RTX 6000) for 30 epochs with a batch size
the variance of an ensemble of MTR models. Refer to of 60 and a learning rate of 1e−4, which is decayed every 2
section V-F for more details. epochs by a factor of 0.5.
C. Evalution Metrics
E. Prediction Generalization Performance
We follow the convention in motion prediction and adopt
The full evaluation of the prediction generalization per-
the commonly used metrics for evaluation.
formance involves a bi-directional zero-shot generalization
• minADE: This metric computes the average of the evaluation. For one direction, we train prediction algorithms
l2−displacementbetweenthegroundtruthtrajectoryand
on WOMD, and zero-shot test them on Argoverse. The
the closest prediction among six trajectory predictions:
opposite direction of generalizing from Argoverse to WOMD
T is also evaluated for completeness. Since Argoverse only
1 (cid:88)
minADE= min ||s¯t −sk,t|| . contains agent type Vehicle, we only enable predictions
k∈{1,...,κ}T G G 2
t=1 on vehicles in WOMD as well for fairness.TABLEI
THECROSS-DATASETGENERALIZATIONPERFORMANCEONWAYMOOPENMOTIONDATASETANDARGOVERSE.
Method Validation/Test Train mAP↑ minADE↓ minFDE↓ MissRate↓
MTR(Oracle) Argoverse Argoverse 0.5135 0.4113 0.8369 0.0567
MTR Argoverse WOMD 0.1290 6.8544 12.8778 0.6558
Const-Vel Argoverse - 0.1347 3.2680 8.0422 0.5747
APE(BS) Argoverse WOMD 0.1319 4.1853 9.9773 0.5912
Ours(APE) Argoverse WOMD 0.1378 3.0461 7.1423 0.5399
MTR(Oracle) WOMD WOMD 0.4477 0.7546 1.5267 0.1529
MTR WOMD Argoverse 0.0525 5.0328 9.7935 0.7382
Const-Vel WOMD - 0.0292 6.5713 16.6447 0.8985
APE(BS) WOMD Argoverse 0.0310 6.1452 14.9673 0.8515
Ours(APE) WOMD Argoverse 0.0741 4.4099 8.3795 0.6701
is mitigated by the exposure to a diverse data distribution.
Therefore, as a coordinator, the learned routing function can
stitch a more powerful predictor out of individual experts.
It is also interesting to note that the constant velocity
model performs better on Argoverse with a minADE of
3.2680m than WOMD with a minADE of 6.5713m. This
indicates that WOMD contains more complicated prediction
tasks than those in Argoverse, possibly with more turns
and fewer go-straight scenarios. This statement can also
be shown from a smaller minADE on Argoverse for MTR
(Oracle) than WOMD. However, no matter which direction
(a) (b)
of generalization is performed, the proposed method always
outperforms an individual prediction algorithm, thanks to
the concurrent training of the routing function and diverse
prediction candidates from individual predictors.
WhengeneralizingfromArgoversetoWOMD,theconstant
velocity model outperforms MTR in terms of minADE. This
shows that it is possible for a rule-based predictor to perform
better than a deep learning-based predictor, and hence it is
necessary to design strategies to improve the generalization
ability of a learning-based predictor, with the proposed APE
as one possible solution.
(c) (d) F. Yet Another Routing Function
Fig. 3. The trajectory prediction visualization curated by the learning- In this section, we aim to evaluate another type of routing
basedroutingfunction.(a)(b)CaseswhereMTRgeneralizesbetterthanthe function and compare it with the proposed learning-based
constant velocity model. (c)(d) Cases where the constant velocity model
one that is trained concurrently with the individual predictors.
generalizesbetterthanMTR.
The prediction selection can also be executed by a routing
function based on uncertainty estimation. We choose to use
We show the performance of APE along with various the most widely used method, bootstrapping model output
baselines and variants in Table I, and visualizations of variance, as the uncertainty estimation method in the routing
predicted trajectories of both experts in different scenarios in functionvariant.Thevariantwitharoutingfunctionbasedon
Fig.3.AccordingtoTableI,theproposedAdaptivePrediction bootstrapping uncertainty estimation is named APE (BS) in
Ensemble with a mixture of experts outperforms all baselines ourexperiment.Concretely,weusethevarianceofthreeMTR
and variants in our bi-directional generalization evaluation. prediction outputs as the epistemic uncertainty estimation of
We attribute the performance improvements to the capability the learning-based prediction model, where the three MTR
of the routing function and the contribution from different models are randomly initialized and trained on the same
expert prediction methods. The routing function learns good training dataset. If the uncertainty estimation surpasses a
prediction selection skills even though the test scenarios threshold, then the predictor will discard MTR predictions
are out-of-distribution for individual prediction algorithms andchoosetheconstantvelocitypredictionasthefinaloutput,
because it gets exposed to more diverse input (i.e., trajectory and vice versa.
predictioncandidates)duringitsconcurrenttrainingwithother From Table I, we can see that the performance of APE
individual predictors. The difficulty level of its generalization (BS) is in between the constant velocity model and MTR.The prediction performance of APE (BS) is an interpolation
of the two individual predictors. This indicates that the
bootstrapping-based uncertainty estimation is noisy and
hence inaccurate in this case. In comparison, a learning-
based routing function trained concurrently with individual
prediction algorithms is more stable and performs better.
G. In-D and OOD Interpolation Data Mixture
Inthissection,weperformanablationstudyontheeffectof
differentratiosofin-distribution(in-D)andout-of-distribution
(OOD) test data mixture on the performance improving scale.
Weadoptthemetric,performancegain,definedinEqn.(3)to
measuretheperformanceimprovingscale.Thein-distribution
test data come from the original validation dataset from the
samesourceofthetrainingdatasetwhenMTRisbeingtrained.
Theout-of-distributioncomesfromanewanddifferentdataset (a) (b)
than the training dataset. Specifically, we choose to use
Fig. 4. The performance gain percentage vs. (a) OOD data percentage
WOMD as the training dataset and Argoverse as the test in the test dataset; and (b) Prediction horizon. The performance gain is
dataset. Therefore, WOMD is considered as in-distribution, monotonicallyincreasinginbothcases,indicatingthatourmethodhasmore
advantageoverindividualpredictorswhenOODdataiscommoninthetest
and Argoverse out-of-distribution. In the experiment, we mix
datasetandthetaskhorizonislong.
different ratios of in-D and OOD data into the test dataset.
The experiment results are shown in Fig. 4(a). As we can
see, the performance gain increases when the ratio of OOD horizon increases from 1 to 80, indicating that APE has
dataincreasesinthetestdataset.WhentheOODratioreaches more advantage over a single deep learning-based prediction
100%, the performance gain reflects the results in Table I. algorithm in longer horizon tasks. This aligns with our
The monotonic increase of performance gain aligns with the expectation that a shorter horizon of trajectories resembles
expectation: The advantage of the routing function should constant velocity trajectories, and both deep learning-based
not be obvious when in-D data is the majority. In this case, a andrule-basedpredictionmethodscanfitwell.Asthehorizon
good portion of MTR predictions should be the better choice becomeslonger,theadvantageofleveragingaroutingfunction
over the constant velocity model prediction. As the OOD becomes more remarkable since it can correctly pick out the
ratio goes up, more and more constant velocity predictions betterpredictioncandidatefromthetwoincreasinglydifferent
become competent, and therefore, the benefits of leveraging prediction candidates.
a routing function become more visible. It is also worth Another observation on Fig. 4 is that the increase of
noting that when all data is in distribution, the performance performance gain from 1 to 80 time steps tends to slow
gain is slightly below zero. This is not surprising because a down when the horizon becomes longer. This shows that the
good generalization ability typically comes with a sacrifice gap between deep learning-based and rule-based prediction
of in-distribution accuracy. The routing function is not 100% does not increase indefinitely as the horizon increases.
accurate in selecting a better prediction candidate out of the
individual predictors, but as the performance of individual VI. CONCLUSIONSANDDISCUSSIONS
predictors decreases with the OOD ratio increase, the routing
function becomes capable of picking the correct one. In this work, we tackled the critical challenge of general-
izing motion prediction algorithms for autonomous driving
H. Prediction Horizon vs. Improving Scale
across different datasets. The proposed Adaptive Prediction
In this section, we conduct an ablation study on the effect Ensemble framework, incorporating a deep learning expert,
of prediction horizon on the performance improving scale by a rule-based expert, and a learned routing function, offers
Eqn. (3) compared to a nominal MTR. As a default setting, a promising solution to improve zero-shot performance.
we choose to use the common 80 time steps (8sec) as the Our experiments demonstrate that by effectively leveraging
horizon of the prediction task. However, it should not be the strengths of both deep learning and rule-based models,
surprising that a shorter horizon can close the gap between we can achieve substantial gains in prediction accuracy
deep learning-based and rule-based prediction algorithms, and robustness, especially in challenging out-of-distribution
no matter which one is better, because it is intuitive that scenarios and long-horizon predictions. While our approach
within a short time window, the trajectory of the traffic agent shows promising results, there are several avenues for
resembles a constant velocity trajectory. future explorations. Investigating more sophisticated rule-
The experiment results are shown in Fig. 4(b). As we based models and incorporating additional expert predictors
can see from the figure, the performance gain at one time couldfurtherenhancethesystem’sperformance.Additionally,
step is only 4.1%, while it is 57.3% at 80 time steps. The exploring different uncertainty estimation techniques for the
performance gain monotonically increases as the prediction routing function could lead to more refined decision making.REFERENCES [20] M.-F.Chang,J.Lambert,P.Sangkloy,J.Singh,S.Bak,A.Hartnett,
D.Wang,P.Carr,S.Lucey,D.Ramanan,etal.,“Argoverse:3dtracking
[1] T. Salzmann, B. Ivanovic, P. Chakravarty, and M. Pavone, “Trajec- and forecasting with rich maps,” in Proceedings of the IEEE/CVF
tron++:Dynamically-feasibletrajectoryforecastingwithheterogeneous conferenceoncomputervisionandpatternrecognition,2019.
data,” in Computer Vision–ECCV 2020: 16th European Conference,
[21] Y. Hu, J. Yang, L. Chen, K. Li, C. Sima, X. Zhu, S. Chai, S. Du,
Glasgow,UK,August23–28,2020,Proceedings,PartXVIII16,pp.683–
T.Lin,W.Wang,etal.,“Planning-orientedautonomousdriving,”in
700,Springer,2020. Proceedings of the IEEE/CVF Conference on Computer Vision and
[2] S. Shi, L. Jiang, D. Dai, and B. Schiele, “Motion transformer with PatternRecognition,pp.17853–17862,2023.
globalintentionlocalizationandlocalmovementrefinement,”Advances
[22] J. Li, C. Tang, M. Tomizuka, and W. Zhan, “Hierarchical plan-
inNeuralInformationProcessingSystems,pp.6531–6543,2022.
ningthroughgoal-conditionedofflinereinforcementlearning,”IEEE
[3] J. Li, H. Ma, Z. Zhang, J. Li, and M. Tomizuka, “Spatio-temporal RoboticsandAutomationLetters,vol.7,no.4,pp.10216–10223,2022.
graphdual-attentionnetworkformulti-agentpredictionandtracking,”
[23] J.Li,L.Sun,W.Zhan,andM.Tomizuka,“Interaction-awarebehavior
IEEETransactionsonIntelligentTransportationSystems,vol.23,no.8,
planningforautonomousvehiclesvalidatedwithrealtrafficdata,”inDy-
pp.10556–10569,2021. namicSystemsandControlConference,vol.84287,p.V002T31A005,
[4] J.Li,F.Yang,M.Tomizuka,andC.Choi,“Evolvegraph:Multi-agent
AmericanSocietyofMechanicalEngineers,2020.
trajectory prediction with dynamic relational reasoning,” Advances
[24] J.Li,D.Isele,K.Lee,J.Park,K.Fujimura,andM.J.Kochenderfer,
inneuralinformationprocessingsystems,vol.33,pp.19783–19794,
“Interactiveautonomousnavigationwithinternalstateinferenceand
2020. interactivity estimation,” IEEE Transactions on Robotics, vol. 40,
[5] M. Bahari, S. Saadatnejad, A. Rahimi, M. Shaverdikondori, A. H.
pp.2932–2949,2024.
Shahidzadeh,S.-M.Moosavi-Dezfooli,andA.Alahi,“Vehicletrajectory
[25] B.Lange,J.Li,andM.J.Kochenderfer,“Sceneinformer:Anchor-based
predictionworks,butnoteverywhere,”inProceedingsoftheIEEE/CVF
occlusioninferenceandtrajectorypredictioninpartiallyobservable
ConferenceonComputerVisionandPatternRecognition,2022.
environments,” in IEEE International Conferences on Robotics and
[6] M.Toyungyernsub,E.Yel,J.Li,andM.J.Kochenderfer,“Dynamics- Automation(ICRA),2024.
awarespatiotemporaloccupancypredictioninurbanenvironments,”in
[26] Z.Huang,H.Liu,J.Wu,andC.Lv,“Differentiableintegratedmotion
InternationalConferenceonIntelligentRobotsandSystems,2022.
predictionandplanningwithlearnablecostfunctionforautonomous
[7] D. Isele, P. Gupta, X. Liu, and S. Bae, “Gaussian lane keeping: A driving,”IEEEtransactionsonneuralnetworksandlearningsystems,
robustpredictionbaseline,”IEEEIntelligentTransportationSystems
2023.
Conference(ITSC),2024.
[27] W.Shao,Y.Xu,L.Peng,J.Li,andH.Wang,“Failuredetectionfor
[8] O.Sanseviero,L.Tunstall,P.Schmid,S.Mangrulkar,Y.Belkada,and
motionpredictionofautonomousdriving:Anuncertaintyperspective,”
P.Cuenca,“Mixtureofexpertsexplained,”2023. in2023IEEEInternationalConferenceonRoboticsandAutomation
[9] N.Shazeer,A.Mirhoseini,K.Maziarz,A.Davis,Q.Le,G.Hinton, (ICRA),pp.12721–12728,IEEE,2023.
andJ.Dean,“Outrageouslylargeneuralnetworks:Thesparsely-gated
[28] K. A. Eltouny, W. Liu, S. Tian, M. Zheng, and X. Liang, “De-tgn:
mixture-of-experts layer,” in International Conference on Learning
Uncertainty-awarehumanmotionforecastingusingdeepensembles,”
Representations,2017.
IEEERoboticsandAutomationLetters,2024.
[10] S.Shen,L.Hou,Y.Zhou,N.Du,S.Longpre,J.Wei,H.W.Chung,
[29] J.Li,C.Tang,M.Tomizuka,andW.Zhan,“Dealingwiththeunknown:
B. Zoph, W. Fedus, X. Chen, et al., “Mixture-of-experts meets Pessimisticofflinereinforcementlearning,”inConferenceonRobot
instructiontuning:Awinningcombinationforlargelanguagemodels,” Learning,pp.1455–1464,PMLR,2022.
inInternationalConferenceonLearningRepresentations,2024.
[30] Z.Wu,Y.Wang,H.Ma,Z.Li,H.Qiu,andJ.Li,“Cmp:Cooperative
[11] T. Gale, D. Narayanan, C. Young, and M. Zaharia, “Megablocks: motion prediction with multi-agent communication,” arXiv preprint
Efficient sparse training with mixture-of-experts,” Proceedings of arXiv:2403.17916,2024.
MachineLearningandSystems,vol.5,pp.288–304,2023.
[31] J.Lu,C.Cui,Y.Ma,A.Bera,andZ.Wang,“Quantifyinguncertaintyin
[12] J. He, J. Zhai, T. Antunes, H. Wang, F. Luo, S. Shi, and Q. Li, motionpredictionwithvariationalbayesianmixture,”inProceedingsof
“Fastermoe:modelingandoptimizingtrainingoflarge-scaledynamic theIEEE/CVFConferenceonComputerVisionandPatternRecognition,
pre-trained models,” in Proceedings of the 27th ACM SIGPLAN
pp.15428–15437,2024.
Symposium on Principles and Practice of Parallel Programming,
[32] M.S.AyhanandP.Berens,“Test-timedataaugmentationforestimation
pp.120–134,2022.
ofheteroscedasticaleatoricuncertaintyindeepneuralnetworks,”in
[13] Y.Zhang,M.Li,R.Li,K.Jia,andL.Zhang,“Exactfeaturedistribution MedicalImagingwithDeepLearning,2022.
matching for arbitrary style transfer and domain generalization,” in
[33] J.Li,X.Liu,B.Zhu,J.Jiao,M.Tomizuka,C.Tang,andW.Zhan,
Proceedings of the IEEE/CVF conference on computer vision and
“Guidedonlinedistillation:Promotingsafereinforcementlearningby
patternrecognition,pp.8035–8045,2022.
offline demonstration,” in 2024 IEEE International Conference on
[14] H.Ma,Y.Sun,J.Li,andM.Tomizuka,“Multi-agentdrivingbehavior RoboticsandAutomation(ICRA),IEEE,2024.
prediction across different scenarios with self-supervised domain
[34] Y. Bai, A. Jones, K. Ndousse, A. Askell, A. Chen, N. DasSarma,
knowledge,” in 2021 IEEE International Intelligent Transportation D. Drain, S. Fort, D. Ganguli, T. Henighan, et al., “Training a
SystemsConference(ITSC),pp.3122–3129,IEEE,2021.
helpfulandharmlessassistantwithreinforcementlearningfromhuman
[15] J.Li,X.Shi,F.Chen,J.Stroud,Z.Zhang,T.Lan,J.Mao,J.Kang, feedback,”arXivpreprintarXiv:2204.05862,2022.
K.S.Refaat,W.Yang,etal.,“Pedestriancrossingactionrecognition
[35] R.Rafailov,A.Sharma,E.Mitchell,C.D.Manning,S.Ermon,and
and trajectory prediction with 3d human keypoints,” in 2023 IEEE
C. Finn, “Direct preference optimization: Your language model is
InternationalConferenceonRoboticsandAutomation(ICRA),pp.1463–
secretlyarewardmodel,”AdvancesinNeuralInformationProcessing
1470,IEEE,2023. Systems,vol.36,2024.
[16] G.WuandS.Gong,“Collaborativeoptimizationandaggregationfor
[36] J.Gao,C.Sun,H.Zhao,Y.Shen,D.Anguelov,C.Li,andC.Schmid,
decentralizeddomaingeneralizationandadaptation,”inProceedingsof
“Vectornet: Encoding hd maps and agent dynamics from vectorized
theIEEE/CVFInternationalConferenceonComputerVision,pp.6484–
representation,” in Proceedings of the IEEE/CVF Conference on
6493,2021. ComputerVisionandPatternRecognition,pp.11525–11533,2020.
[17] A.Dubey,V.Ramanathan,A.Pentland,andD.Mahajan,“Adaptive [37] C.R.Qi,H.Su,K.Mo,andL.J.Guibas,“Pointnet:Deeplearning
methodsforreal-worlddomaingeneralization,”inProceedingsofthe onpointsetsfor3dclassificationandsegmentation,”inProceedings
IEEE/CVFConferenceonComputerVisionandPatternRecognition, oftheIEEEconferenceoncomputervisionandpatternrecognition,
pp.14340–14349,2021. pp.652–660,2017.
[18] C. Chen, J. Li, X. Han, X. Liu, and Y. Yu, “Compound domain [38] L.Ouyang,J.Wu,X.Jiang,D.Almeida,C.Wainwright,P.Mishkin,
generalizationviameta-knowledgeencoding,”inProceedingsofthe C.Zhang,S.Agarwal,K.Slama,A.Ray,etal.,“Traininglanguage
IEEE/CVF conference on computer vision and pattern recognition, models to follow instructions with human feedback,” Advances in
pp.7119–7129,2022. neural information processing systems, vol. 35, pp. 27730–27744,
[19] S.Ettinger,S.Cheng,B.Caine,C.Liu,H.Zhao,S.Pradhan,Y.Chai, 2022.
B. Sapp, C. R. Qi, Y. Zhou, et al., “Large scale interactive motion [39] M.Everingham,L.VanGool,C.K.Williams,J.Winn,andA.Zisser-
forecastingforautonomousdriving:Thewaymoopenmotiondataset,” man,“Thepascalvisualobjectclasses(voc)challenge,”International
inProceedingsoftheIEEE/CVFInternationalConferenceonComputer journalofcomputervision,vol.88,pp.303–338,2010.
Vision,pp.9710–9719,2021.