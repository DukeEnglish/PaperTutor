Let Me DeCode You: Decoder Conditioning
with Tabular Data
Tomasz Szczepan´ski1, Michal K. Grzeszczyk1, Szymon Pl(cid:32)otka1,2,3, Arleta
Adamowicz4, Piotr Fudalej4, Przemysl(cid:32)aw Korzeniowski1, Tomasz
Trzcin´ski5,6,7, and Arkadiusz Sitek8
1 Sano Centre for Computational Medicine, Cracow, Poland
t.szczepanski@sanoscience.org
2 Informatics Institute, University of Amsterdam, Amsterdam, The Netherlands
3 Amsterdam University Medical Center, Amsterdam, The Netherlands
4 Jagiellonian University Medical College, Cracow, Poland
5 Warsaw University of Technology, Warsaw, Poland
6 IDEAS NCBR, Warsaw, Poland
7 Tooploox, Wroclaw, Poland
8 Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA
Abstract. Trainingdeepneuralnetworksfor3Dsegmentationtaskscan
bechallenging,oftenrequiringefficientandeffectivestrategiestoimprove
model performance. In this study, we introduce a novel approach, De-
Code, that utilizes label-derived features for model conditioning to sup-
portthedecoderinthereconstructionprocessdynamically,aimingtoen-
hancetheefficiencyofthetrainingprocess.DeCodefocusesonimproving
3Dsegmentationperformancethroughtheincorporationofconditioning
embeddingwithlearnednumericalrepresentationof3D-labelshapefea-
tures.Specifically,wedevelopanapproach,whereconditioningisapplied
duringthetrainingphasetoguidethenetworktowardrobustsegmenta-
tion.Whenlabelsarenotavailableduringinference,ourmodelinfersthe
necessaryconditioningembeddingdirectlyfromtheinputdata,thanksto
afeed-forwardnetworklearnedduringthetrainingphase.Thisapproach
is tested using synthetic data and cone-beam computed tomography
(CBCT)imagesofteeth.ForCBCT,threedatasetsareused:onepublicly
available and two in-house. Our results show that DeCode significantly
outperformstraditional,unconditionedmodelsintermsofgeneralization
to unseen data, achieving higher accuracy at a reduced computational
cost. This work represents the first of its kind to explore conditioning
strategies in 3D data segmentation, offering a novel and more efficient
methodforleveragingannotateddata.Ourcode,pre-trainedmodelsare
publicly available at https://github.com/SanoScience/DeCode.
Keywords: Conditioning·Tabulardata·Non-Imaging·Segmentation
1 Introduction
The annotation process in medical imaging is time-consuming, costly, and re-
quires medical domain knowledge [17]. Furthermore, deep learning-based algo-
4202
luJ
21
]VI.ssee[
1v73490.7042:viXra2 T.Szczepan´ski et al.
E1 D1
E2 D2
E3 D3
E4 D4
Di
E5
TEST TRAIN
Embedding Space
skip-connection shape features embedding 3D Convolution
Transposed 3D Convolution
Ei Batch Normalization
... 0.20.20.60.10.20.30.8 ReLU
512 Shape Features Global Average Pooling
Fully Connected Layer
embedding 0.30.20.70.10.20.40.9 Conditioning Layer
Fig.1: An overview of the proposed DeCode method for conditioning segmenta-
tion decoder with learned shape features embedding. During the inference when
testlabelsareunavailable,weusethelearnedfeatureembeddingoptimizedwith
L lossinEq.1.Weperformconditioningaftertheskipconnectionfromtheen-
1
coder, allowing for a dynamic and selective decoding process. We also leverage
a features regression as a helper task that boosts meaningful feature extraction.
Skip connections and the flow of the shape features embedding are indicated
with blue and purple arrows respectively. Ei and Di correspond to the encoder
and decoder stages.
rithmsnecessitatealargeamountofannotateddataforacceptableperformance
andgeneralizationcapabilities[8].However,toenhancedeeplearningalgorithms
without relying solely on large-scale imaging data, the community explored the
use of tabular features [5,23,13].
Inrecentyears,FiLM[12]hasemerged,allowingadaptiveinfluenceonneural
networkintermediatefeaturesthroughfeature-wiseaffinetransformationsbased
on conditioning information. Expanding on this concept, integrating tabular in-
formation has shown significant advantages for model performance [3,22,6]. An
example of the beneficial integration is TabAttention mechanism [3]. This ap-
proach incorporates biometric measurements which improve fetal birth weight
estimation on ultrasound video scans. Similarly, DAFT [22] is proposed to con-
ditionally shift and scale feature maps based on conditioning. Integration of a
patient’sclinicalinformationwitha3DMRIimageshowsimprovementintime-
to-dementia prediction, underscoring the richness of Electronic Health Record
(EHR) data. However, both methods primarily address regression problems
where tabular data exhibits measurable correlations with the target task, and
imaging features contribute to reducing estimation error.
1 .rts
,3x3x3
821
2 .rts
,3x3x3
1 .rts
,3x3x3
215
2 .rts
,3x3x3
215 215
scimoidaryp
1 .rts
,1x1x1Let Me DeCode You: Decoder Conditioning with Tabular Data 3
Conversely, segmentation tasks often lack corresponding tabular data due to
challenges such as fully anonymization process of medical data, the absence of a
comprehensive data collection strategy, or clear relations between conditioning
information and segmentation. The authors of conditioning layer INSIDE [6]
propose to integrate non-imaging information into 2D segmentation network to
improve performance. They utilize cardiac cycle phase and encoded 2D slice
position as conditioning data. However, this prior-knowledge-based information
reliesonasimpletwo-statephaseofthecardiaccycle,thoughcorrelatedwiththe
segmentation task, limits its information to a simple binary flag. This attempt
sets out a line of research that we choose to pursue.
In this work, we explore conditioning on 3D data in a segmentation task
when corresponding tabular data is unavailable. To our best knowledge, we are
thefirsttoinvestigateit.WeintroducetheDeCode,whichperformsconditioning
based on shape feature embedding. For reproducibility, we calculate the label-
based shape features using PyRadiomics [20]. We also demonstrate that the
accompanying task of shape features regression benefits the model’s segmenta-
tion performance and, most importantly, allows us to use feature embedding for
conditioning during inference when test labels are unavailable. We evaluate our
method on the novel synthetic DeCode 3D dataset, showing that shape features
allow for conditioning synthetic tasks, thus demonstrating their usefulness. To
demonstrate DeCode’s applicability in a clinical setting, we use the 3D dental
CBCT dataset [1] to train the model and two external test sets to evaluate the
generalizationofthemodel.AccuratetoothdelineationindentalCBCTimagesis
essentialforclinicaldiagnosisandtreatmentwhilepreparingprecise3Dlabelsis
very time-consuming [14,24,7,2,21]. Our conditioned architecture improves gen-
eralization to unseen data compared to the unconditioned one, which is trained
on the same data while requiring no extra labeling work and only marginal ad-
ditional training time. This work proposes a conditioning strategy for 3D data
segmentation, offering a more efficient method for leveraging annotated data.
2 Method
Inthissection,weprovideadetaileddescriptionofthenetworkandtheDeCode
decoderwithanemphasisontheapplicationofconditioninginformation.Then,
we describe the process of calculating shape features that are further used for
the regression task to generate their embedding for inference-time conditioning.
The go-to standard for accomplishing medical imaging segmentation tasks
is U-shaped architectures [10,1,15,9]. Here, we follow this approach and present
lightweightarchitecturewithanoverviewofourmethodinFig.1.LetX bea3D
CBCTscanX ∈R1×H×W×D ofheightH,widthW anddepthD,theU-shaped
network generates multi-scale features at encoding stages Ei. Deeper encoder
stages yield more abstract features up to the bottleneck within the deepest part
of the architecture, containing compressed information from the input image.
The decoding part Di aims to reconstruct the segmentation map from features
extractedbytheencoderwithadditionalskipconnectionsatconsecutivestages.4 T.Szczepan´ski et al.
Fig.2: Normalized mean shape features calculated with PyRadiomics [20] on
CBCT Tooth dataset [1]. Each shape feature is calculated for every tooth sepa-
rately revealing morphological differences between tooth types.
Startingwithhigh-levelfeaturesofshape14×14×10inthebottleneckthroughall
decoder stages, we utilize learned feature embedding to condition the decoding
process to improve the quality of the output mask.
Decoder Conditioning. The first step within the decoding step is processing
features from the previous stage with the convolutional layer. We add features
from the encoder skip connections just before the conditioning layer to avoid
leakage of low-level features without first conditioning them on shape feature
embedding. The conditioning layer utilizes affine transformations to scale and
shift feature maps. The transformation parameters are α and β , the products
c c
of hyper-network, which implement scale and offset, where c is the number of
feature map’s channels (see Conditioning Layer in Fig. 1). In contrast to FiLM
conditioning, we parameterize the scale parameter to (1−α ) to facilitate the
c
identity transform especially at the early stage of training, and to allow the
scaling parameter to be regularized as a distance from zero. For α > 0, the
scaling factor inverts a feature map, highlighting features that the ReLU acti-
vation would have otherwise suppressed [16]. The conditioning operation takes
a normalization role, replacing the batch norm between the convolutional layer
and the activation function. In addition to the possibility of conditioning itself,
this operation has an additional advantage compared to Batch Norm or Layer
Norm: it does not depend on batch statistics [18]. The transformed features are
summed via residual connection with the processed input to the decoder. The
decodingstepfinisheswithrefiningandup-samplingfeaturemapsviatransposed
convolution, Batch Normalization, and a ReLU activation.
ShapeFeatures.Weutilizeground-truthmaskstoextractrichinformationand
shape features. We consider, e.g., sphericity, volume, and elongation features,
(see Fig. 2), which aim to decode more morphologically accurate masks. Before
training, we extract shape features for every segmented object separately based
on the ground truth mask (up to 32 objects, teeth, in a CBCT scan). ThisLet Me DeCode You: Decoder Conditioning with Tabular Data 5
process yields a vector of length 512, forming tabular data that is used further
to learn conditioning embedding. These features are utilized during training
time to condition the decoding process. In real-world scenarios, the ground-
truth masks are unavailable during inference. Therefore, we perform a shape-
features regression task from the encoder’s bottleneck latent space to replace
the unavailable shape-features at the test stage with model-learned embedding
(seeFig.1).Forreproducibilityandeasyaccess,wecalculateshapefeatureswith
PyRadiomics [20].
Loss function. The multi-task loss function, which minimizes both segmenta-
tion, embedding distance, and regression tasks, is defined as follows:
L=L +Λ L +L +Λ L +η(∥α∥2+∥β∥2), (1)
Dice 1 Focal 1 2 RMSE 2 2
where Λ = 0.5, and Λ = 0.75. The coefficients are determined based on a
1 2
trial-and-error optimization. L and L correspond to the segmentation
Dice Focal
task. We optimize an L distance to make encoder features embedding close
1
to the representation of tabular shape features. During inference, we use this
learned embedding to condition the decoder. We also add the helper task of
shapefeaturesregressionduringtrainingwhichweoptimizebasedonRootMean
Square Error (RMSE). Finally, we add an L penalty η =0.00001 to regularize
2
the conditioning layer parameters α and β, due to the high capacity of the deep
network following the conditioning layer, thus reducing the risk of overfitting.
3 Experiments and Results
In this section, we describe implementation details and introduce the synthetic
dataset,3DeCode,whereweinvestigatethepossibilityofconditioningwithshape
featureson3Ddata.Moreover,weapplyDeCodetothetaskof3Dsegmentation,
utilizing CBCT datasets. We highlight the significance of DeCode key compo-
nents and evaluate its ability to generalize to unseen CBCT data in comparison
to lightweight 3D UNet, which lacks decoder conditioning.
Implementation details. We implement identical models for both synthetic
and clinical datasets. We use a UNet network with 4-down and 4-up sampling
stages, Batch Normalization, ReLU activations, and a Sigmoid layer for final
classification. The conditioning layers are placed inside decoder stages as shown
in Fig. 1. We crop an ROI around the teeth based on labels with a size of
240×240×176 from the input CBCT scan. Then, we randomly crop a patch of
size 224×224×160 and feed it to the network. We train the model using a batch
size of 4, and the AdamW optimizer for 400 epochs. A learning rate is set to
0.001,andtheweightdecayissetto0.0001.TheintensityoftheHounsfieldUnit
isclippedtotherange[0,3500]andlinearlyscaledto[0,1].Weemploygeometric
and intensity-related data augmentation such as random rotation, translation,
orbrightnessandcontrastadjustmentsthroughoutthetrainingprocess.Weim-
plementourmodelinPyTorch1.13.1andMONAI1.2.0andtrainitonNVIDIA
A100 80GB GPU with CUDA 11.6. We use PyRadiomics 3.1.0 to calculate bi-
nary mask shape features. In case of a missing tooth, we fill its shape features6 T.Szczepan´ski et al.
Table 1: Quantitative results on DeCode 3D dataset in the average Dice Simi-
larityCoefficient(DSC)(%).Weexplorethepossibilityofconditioning3Dsolid
with shape features in a segmentation task. For the tasks Size and Shape, we
conditionallysegmentsolidsofsmall,medium,orlargesizesandsphere,cube,or
cylindershapes,respectively.Mixed taskconfigurationscombinethecharacteris-
ticsofShape andSize tasks.MorechallengingVarying combinationsadditionally
address shape and size variability based on a uniform distribution, beyond bi-
nary combinations. We report the baseline as an unconditioned UNet.
DSC (%)
Task
Baseline Shape features conditioning
Size 49.18±32.26 98.23±3.92
Shape 53.48±22.09 99.33±0.85
Mixed 17.84±25.68 97.96±5.25
Varying Size 32.97±32.23 97.48±5.69
Varying Mixed 12.43±28.45 94.74±12.94
with a vector of zeros and finally normalize tabular data to a range of [0, 1]. We
perform a paired t-test with p < 0.05 to identify significant differences.
3DeCode dataset. We present a novel dataset inspired by CLEVR-Seg [6],
extending it to 3D and generating segmentation masks based on conditioning
scenario tasks. We design tasks that require conditioning based on Shape, Size,
or Shapes of different Sizes (referred to as Mixed). To utilize the rich informa-
tion stored as non-binary shape features, we also enrich the dataset with solids
ofvaryingshapesandsizes.Namely,wegeneratetwoadditionaltasksthatintro-
duce non-discrete variability in Size or Shape to the solids, based on a uniform
distribution, e.g., to generate the varying-size solid class ’small sphere’ we vary
its radius by ± 20%. While this approach does not reflect the full spectrum of
information that shape features can store, it allows us to assess the feasibility of
conditioning on 3D data in a segmentation task. The Varying Mixed task con-
sists of shapes varying in size and shape, where, e.g., the base spherical shape
canresultinanellipsoidandacubeinacuboid.Thegeneratedsolidsarebinary,
as complex image feature extraction is not a concern. Tasks to be solved accu-
ratelyrequiretheuseoftheconditioninginformationbythenetwork.Otherwise,
accuracy is reduced to a random guess based solely on the image. The positions
of the solids are drawn randomly, whereby they may overlap. We generate 300
labeled conditions for tasks of Size (small, medium, or large) or Shape (sphere,
cube, cylinder), and 900 for the Mixed tasks. Data consists of condition-based
3D images with up to 18 objects in volume space of the same size as the patch
sizeusedbyourmodel.Wegenerateeverypossibleconditioningcombinationper
image to prevent the model from memorizing image-condition pairs. For evalu-
ation, we split the dataset into training, validation, and testing subsets with a
60:20:20 ratio. 3DeCode samples can be found in the supplementary material -
Sec.4.Let Me DeCode You: Decoder Conditioning with Tabular Data 7
Table 2: Quantitative results on 3D CBCT datasets: external (Center A and
Center B) and validation split. We report DSC and standard deviation. Config-
uration (1) refers to an unconditioned network serving as a baseline. An upper
bound of generalization is provided by configuration (7) conditioned with shape
features calculated on test-set masks. The proposed configuration DeCode (8)
utilizes during test time learned feature embedding. We conduct a paired t-test
to establish statistical significance between the baseline and configuration (7)
and (8), denoted by (*) for p < 0.05. CL stands for the Conditioning Layer,
Reg the Regression task, CR Conditioning Information Representation, and T
Test-time conditioning, Rand for Random Features, CSF for test-set Calculated
Shape Features, and LESF for Learned Embedding of Shape Features.
Configuration DSC (%)
CL Reg CR T Center A Center B VAL
1. - - - 89.67±2.34 94.55±1.16 95.89±0.84
2. - ✓ - - 91.94±1.56 95.41±1.01 95.67±0.88
3. FiLM Rand 89.75±1.94 93.72±1.33 95.86±0.95
4. FiLM CSF 92.11±1.79 95.45±1.12 95.59±0.88
5. INSIDE CSF 91.16±3.33 95.12±0.99 95.61±0.73
6. DAFT CSF 90.61±9.22 95.14±1.05 95.54±0.91
7. FiLM ✓ CSF 93.12±1.07∗ 95.52±0.92∗ 95.60±0.93
8. FiLM ✓ LESF ✓ 92.74±1.34∗ 95.12±0.91∗ 95.81±0.86
CBCT dataset. To train our model, we use 98 publicly available 3D dental
CBCT scans [1]. We evaluate the segmentation performance on an external test
set,comprising20CBCTscansobtainedfromaretrospectivestudy(IRBOKW-
623/2022) conducted at two medical centers: Center A (11 scans) and Center B
(9 scans). The ground truth annotations for the test set were performed by an
orthodontistwith5yearsofexperience,whowasverifiedbyanotherorthodontist
with 25 years of clinical practice. We resample all scans to 0.4 × 0.4 × 0.4 mm3
isotropic resolution.
Results. We present results on 3DeCode dataset in Table 1. According to our
dataset-buildingprinciple,thebaselineUNetcannotsegmenttheimagewithout
conditioning. The Mixed task DSC is 17% which is close to a random sample
1 out of 9. The model with decoder conditioning can correctly perform the
conditional 3D segmentation task, approaching perfect accuracy for the Shape
task with a DSC of 99.23%, and 94.74%, respectively for the most challenging
Varying Mixed task. Our model struggles only when overlapping solids, due to
random placement solids, are present, which is unrelated to conditioning. The
resultsoftheexperiment,demonstratethatitispossibletoconditionin3Dusing
shape features embedding, which allows us to move on to examine the impact
of conditioning on clinical data segmentation.
We compare the unconditioned UNet network’s (1) results on the CBCT
dataset, which serves as the baseline method, with the proposed DeCode (8) –8 T.Szczepan´ski et al.
Table 3: Performance comparison on CBCT test sets between baseline uncon-
ditioned U-shaped networks and the DeCode method. P denotes the number of
parameters, I inference time, and T training time.
DSC (%)
Network P (M)GFLOPsI (ms)T (h)
Center A Center B Avg.
UNext [19] 4 46 21 1.5 88.98±3.32 93.37±1.80 90.96±2.64
UNet [15] 25 1880 117 8.5 92.03±1.45 94.41±0.98 93.10±1.24
ResUNet34 [4] 70 2610 101 11 92.28±1.32 95.56±0.99 93.71±1.17
Att-UNet [11] 6 380 127 5 92.66±1.51 95.22±1.06 93.81±1.31
VNet [9] 46 2770 175 13 93.07±0.93 95.42±1.02 94.13±0.97
DeCode 4 204 41 3 92.74±1.34 95.12±0.91 93.81±1.15
with numbers in brackets corresponding to configurations presented in Table 2.
To find the optimal configuration, we explore the impact of an auxiliary shape
feature regression task (2), different conditioning layers (CL) (4-6), and condi-
tioning information representation (CR) (3-8). Firstly, we add a shape feature
regression task (2) to the baseline method that improves generalization on both
externalsets,provingtheusefulnessoftheshapefeatures.Secondly,weevaluate
conditioning layer types with calculated shape features (CSF), which, for this
experiments, we also use during the test. We get the best results with the FiLM
layer, so we use it for further experiments. We examine the edge case of condi-
tioning on random tabular data generated from a standard normal distribution
and observe a significant performance decline. The result for Center A is better
than the unconditioned model, suggesting that the conditioning layer increases
themodel’scapacity,posingathreatofoverfitting.However,itmayalsosuggest
that residual connections in the decoder make the model robust to the possi-
ble negative impact of conditioning. A final experiment (7) based on the CSF
leverages the FiLM layer and regression task. It sets an upper bound for gener-
alization improvement. To adapt the method to test time, unlike configuration
(7), we use learned embedding of shape features (LESF), which is our proposed
configuration(8).AlthoughtheproposedDeCodedoesnotimprovetheresulton
thevalidationset,itstatisticallysignificantlyimprovesthegeneralizationtonew
unknown data. Finally, we compare out method with unconditioned U-shaped
networks (see Table 3). We choose architectures with a broad range of param-
eter numbers, provided they allow training with a large 3D patch under GPU
memory constraints. Our solution achieves the second-best generalization, giv-
ingwayonlytotheVNetmethod,whichis,however,10×morecomputationally
intensive and requires 4× longer training.
4 Conclusions
This paper investigates the possibility of conditioning the decoder in the 3D
segmentation task on the tabular data. Compared to unconditioned training,Let Me DeCode You: Decoder Conditioning with Tabular Data 9
DeCode performs better on unseen data, requiring no extra labeling work and
marginal additional training time. We evaluated our method on two external
CBCT datasets, proving its enhanced generalizability. Obtained results encour-
age further research in this field, allowing more efficient use of annotated data.
There are limitations to our method. Firstly, we train our method on a rela-
tivelysmalldatasetwhereselectinghyperparametersiscomplex,andtheirsmall
changes may lead to a loss of stability in embedding learning, including their
collapse.Weexpectbetterstabilityandfurthersegmentationimprovementwith
the increased dataset. Secondly, the radiomics features provide information lim-
itedtoshapewithoutconsideringobjects’positionsandrelationsbetweenthem.
In the future, we plan to conduct the conditioning on features extracted au-
tomatically from labels, enabling the end-to-end training of representations for
improved clinical image segmentation.
Acknowledgments. This work is supported by the EU’s Horizon 2020 programme
(grantno.857533,Sano)andtheFoundationforPolishScience’sInternationalResearch
Agendas programme, co-financed by the EU under the European Regional Develop-
ment Fund and the Polish Ministry of Science and Higher Education (contract no.
MEiN/2023/DIR/3796).ThisresearchwasfundedinwholeorinpartbyNationalSci-
ence Centre, Poland 2023/49/N/ST6/01841. For the purpose of Open Access, the au-
thorhasappliedaCC-BYpubliccopyrightlicencetoanyAuthorAcceptedManuscript
(AAM) version arising from this submission.
Disclosure of Interests. The authors have no competing interests to declare.
References
1. Cui, Z., Fang, Y., Mei, L., Zhang, B., Yu, B., Liu, J., Jiang, C., Sun, Y., Ma,
L., Huang, J., et al.: A fully automatic ai system for tooth and alveolar bone
segmentation from cone-beam ct images. Nature Communications 13(1), 2096
(2022)
2. Cui, Z., Zhang, B., Lian, C., Li, C., Yang, L., Wang, W., Zhu, M., Shen, D.:
Hierarchicalmorphology-guidedtoothinstancesegmentationfromcbctimages.In:
Information Processing in Medical Imaging: 27th International Conference, IPMI
2021,VirtualEvent,June28–June30,2021,Proceedings27.pp.150–162.Springer
(2021)
3. Grzeszczyk, M.K., P(cid:32)lotka, S., Rebizant, B., Kosin´ska-Kaczyn´ska, K., Lipa, M.,
Brawura-Biskupski-Samaha, R., Korzeniowski, P., Trzcin´ski, T., Sitek, A.: Tabat-
tention: Learning attention conditionally on tabular data. In: International Con-
ference on Medical Image Computing and Computer-Assisted Intervention. pp.
347–357. Springer (2023)
4. He,K.,Zhang,X.,Ren,S.,Sun,J.:Deepresiduallearningforimagerecognition.In:
ProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition.
pp. 770–778 (2016)
5. Huang,S.C.,Pareek,A.,Seyyedi,S.,Banerjee,I.,Lungren,M.P.:Fusionofmedical
imagingandelectronichealthrecordsusingdeeplearning:asystematicreviewand
implementation guidelines. NPJ Digital Medicine 3(1), 136 (2020)10 T.Szczepan´ski et al.
6. Jacenko´w, G., O’Neil, A.Q., Mohr, B., Tsaftaris, S.A.: Inside: steering spatial at-
tention with non-imaging information in cnns. In: Medical Image Computing and
Computer Assisted Intervention–MICCAI 2020: 23rd International Conference,
Lima, Peru, October 4–8, 2020, Proceedings, Part IV 23. pp. 385–395. Springer
(2020)
7. Li, P., Liu, Y., Cui, Z., Yang, F., Zhao, Y., Lian, C., Gao, C.: Semantic graph at-
tentionwithexplicitanatomicalassociationmodelingfortoothsegmentationfrom
cbct images. IEEE Transactions on Medical Imaging 41(11), 3116–3127 (2022)
8. Litjens, G., Kooi, T., Bejnordi, B.E., Setio, A.A.A., Ciompi, F., Ghafoorian, M.,
Van Der Laak, J.A., Van Ginneken, B., Sa´nchez, C.I.: A survey on deep learning
in medical image analysis. Medical Image Analysis 42, 60–88 (2017)
9. Milletari,F.,Navab,N.,Ahmadi,S.A.:V-net:Fullyconvolutionalneuralnetworks
for volumetric medical image segmentation. In: 2016 fourth international confer-
ence on 3D vision (3DV). pp. 565–571. Ieee (2016)
10. Minaee, S., Boykov, Y., Porikli, F., Plaza, A., Kehtarnavaz, N., Terzopoulos, D.:
Imagesegmentationusingdeeplearning:Asurvey.IEEETransactionsonPattern
Analysis and Machine Intelligence 44(7), 3523–3542 (2021)
11. Oktay, O., Schlemper, J., Folgoc, L.L., Lee, M., Heinrich, M., Misawa, K., Mori,
K., McDonagh, S., Hammerla, N.Y., Kainz, B., et al.: Attention u-net: Learning
where to look for the pancreas. arXiv preprint arXiv:1804.03999 (2018)
12. Perez, E., Strub, F., De Vries, H., Dumoulin, V., Courville, A.: Film: Visual rea-
soning with a general conditioning layer. In: Proceedings of the AAAI Conference
on Artificial Intelligence. vol. 32 (2018)
13. P(cid:32)lotka,S.,Grzeszczyk,M.K.,Brawura-Biskupski-Samaha,R.,Gutaj,P.,Lipa,M.,
Trzcin´ski, T., Iˇsgum, I., Sa´nchez, C.I., Sitek, A.: Babynet++: Fetal birth weight
prediction using biometry multimodal data acquired less than 24 hours before
delivery. Computers in Biology and Medicine 167, 107602 (2023)
14. Polizzi, A., Quinzi, V., Ronsivalle, V., Venezia, P., Santonocito, S., Lo Giudice,
A., Leonardi, R., Isola, G.: Tooth automatic segmentation from cbct images: a
systematic review. Clinical Oral Investigations 27(7), 3363–3378 (2023)
15. Ronneberger,O.,Fischer,P.,Brox,T.:U-net:Convolutionalnetworksforbiomed-
ical image segmentation. In: Medical Image Computing and Computer-Assisted
Intervention–MICCAI2015:18thInternationalConference,Munich,Germany,Oc-
tober 5-9, 2015, Proceedings, Part III 18. pp. 234–241. Springer (2015)
16. Rupprecht, C., Laina, I., Navab, N., Hager, G.D., Tombari, F.: Guide me: Inter-
acting with deep networks. In: Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition. pp. 8551–8561 (2018)
17. Tajbakhsh, N., Jeyaseelan, L., Li, Q., Chiang, J.N., Wu, Z., Ding, X.: Embracing
imperfectdatasets:Areviewofdeeplearningsolutionsformedicalimagesegmen-
tation. Medical Image Analysis 63, 101693 (2020)
18. Touvron,H.,Bojanowski,P.,Caron,M.,Cord,M.,El-Nouby,A.,Grave,E.,Izac-
ard,G.,Joulin,A.,Synnaeve,G.,Verbeek,J.,etal.:Resmlp:Feedforwardnetworks
forimageclassificationwithdata-efficienttraining.IEEETransactionsonPattern
Analysis and Machine Intelligence 45(4), 5314–5321 (2022)
19. Valanarasu, J.M.J., Patel, V.M.: Unext: Mlp-based rapid medical image segmen-
tation network. In: International Conference on Medical Image Computing and
Computer-Assisted Intervention. pp. 23–33. Springer (2022)
20. Van Griethuysen, J.J., Fedorov, A., Parmar, C., Hosny, A., Aucoin, N., Narayan,
V., Beets-Tan, R.G., Fillion-Robin, J.C., Pieper, S., Aerts, H.J.: Computational
radiomicssystemtodecodetheradiographicphenotype.CancerResearch77(21),
e104–e107 (2017)Let Me DeCode You: Decoder Conditioning with Tabular Data 11
21. Wang,Y.,Xia,W.,Yan,Z.,Zhao,L.,Bian,X.,Liu,C.,Qi,Z.,Zhang,S.,Tang,Z.:
Root canal treatment planning by automatic tooth and root canal segmentation
in dental cbct with deep multi-task feature learning. Medical Image Analysis 85,
102750 (2023)
22. Wolf,T.N.,P¨olsterl,S.,Wachinger,C.,Initiative,A.D.N.,etal.:Daft:auniversal
moduletointerweavetabulardataand3dimagesincnns.NeuroImage260,119505
(2022)
23. Xia, Y., Chen, X., Ravikumar, N., Kelly, C., Attar, R., Aung, N., Neubauer, S.,
Petersen,S.E.,Frangi,A.F.:Automatic3d+tfour-chambercmrquantificationof
theukbiobank:integratingimagingandnon-imagingdatapriorsatscale.Medical
Image Analysis 80, 102498 (2022)
24. Zheng, Q., Gao, Y., Zhou, M., Li, H., Lin, J., Zhang, W., Chen, X.: Semi or fully
automatic tooth segmentation in cbct images: a review. PeerJ Computer Science
10, e1994 (2024)12 T.Szczepan´ski et al.
Supplementary material
3DeCode synthetic dataset
Input 3D Label XY section
Size
Shape
Varying Mixed
Fig.3: The 3DeCode data samples. The first column presents a 3D image, the
basis for various configurations corresponding to the conditioning task, given
along rows. Exemplary labels can be found in the central column. In the last
column,wepresentoneofthecross-sections.Thedatasetcanbegeneratedusing
the provided source code and attached configuration files with seeds.Let Me DeCode You: Decoder Conditioning with Tabular Data 13
Radiomics shape features
Fig.4:NormalizedmeanshapefeaturescalculatedwithPyRadiomicsonthepro-
prietarytestdatasets.Eachshapefeatureiscalculatedforeverytoothseparately
revealing morphological differences between tooth types. A small difference in
mean values between the datasets shape features can be found.
(a) Dataset Center A.
(b) Dataset Center B.