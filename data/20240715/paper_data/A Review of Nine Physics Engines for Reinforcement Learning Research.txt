A Review of Nine Physics Engines for
Reinforcement Learning Research
Michael Kaup∗, Cornelius Wolff∗, Hyerim Hwang, Julius Mayer∗∗, Elia Bruni∗∗
Institute of Cognitive Science, Osnabrück University
Osnabrück
Email: mkaup.research@gmail.com, cowolff@uos.de, hhwang@uos.de, research@jmayer.ai, elia.bruni@uos.de
∗
Sharedfirstauthorship
∗∗
Sharedseniorauthorship
Abstract—We present a review of popular simulation engines domain knowledge. Quantitative performance comparisons in
and frameworks used in reinforcement learning (RL) research, the context of RL are rare in the existing literature and
aiming to guide researchers in selecting tools for creating
oftenprovidedbytheenginedevelopersthemselves[36],[53].
simulated physical environments for RL and training setups.
Accordingly,theseevaluationscanbebiasedwhenitcomesto
It evaluates nine frameworks (Brax, Chrono, Gazebo, MuJoCo,
ODE, PhysX, PyBullet, Webots, and Unity) based on their pop- the advantages and disadvantages of the presented engine. Of
ularity,featurerange,quality,usability,andRLcapabilities.We the available comparisons, many are outdated [20], [24], that
highlightthechallengesinselectingandutilizingphysicsengines is, they do not describe the current state and variety of frame-
for RL research, including the need for detailed comparisons
worksaccurately.Thus,currenttrendsanddevelopmentsinthe
and an understanding of each framework’s capabilities. Key
field (e.g. increased need for environment complexity, multi-
findings indicate MuJoCo as the leading framework due to its
performance and flexibility, despite usability challenges. Unity is agent reinforcement learning, GPU-based simulation) are not
noted for its ease of use but lacks scalability and simulation sufficiently reflected in the literature. The remaining recent
fidelity. The study calls for further development to improve comparisons arelargely focusedon simulation capabilitiesfor
simulation engines’ usability and performance and stresses the
industrial robotics applications with RL [10], [12], [15], [33]
importance of transparency and reproducibility in RL research.
or on the RL algorithms and specific environments [22], [29].
ThisreviewcontributestotheRLcommunitybyofferinginsights
into the selection process for simulation engines, facilitating A general and systematic review of the underlying engines,
informed decision-making. particularlyonethatalsoconsiderscapabilitiesformulti-agent
Index Terms—Reinforcement Learning, Physics, Engine, Re- reinforcement learning (MARL) research, is missing.
view
Our review will focus on the usability of different engines
I. INTRODUCTION forbasicRLsimulationstosupportresearchersinchoosingthe
appropriatecreativetoolsfordesigningbetterandincreasingly
Some of the more well-known research examples in re-
more challenging RL environments, algorithms, and training
inforcement learning (RL) like Hide and Seek or the Sumo
setups. [26]. Therefore, we aim to review the most popular
environment by OpenAI [3], [4] involved embodied agents in
frameworksinRLresearch,regardingtheirpopularity,feature
simulated3Denvironments[14],[19].AccordingtoLeggand
range, feature quality, and usability. While most framework
Hutter[34]anagent’sintelligencecanbedefinedbyits“ability
documentations offer simple environments like the one pre-
toachievegoalsinawiderangeofenvironments”.Takingthis
sented in Figure 1, we assess the engines’ capabilities to
definition into account, the enablement of embodied agent-
generatemulti-agent-ready3Denvironmentsthatcangiverise
environment interaction is crucial. While deep learning (DL)
to high task-complexity and task combinations. For this, we
librarieslikeTensorFlow[1]orPyTorch[45]andenvironment
chose frameworks specialized for physics simulation (Brax,
frameworks such as OpenAI Gym [11] or PettingZoo [52]
Chrono, Gazebo, MuJoCo, ODE, PhysX, PyBullet, and We-
have lowered the entry barriers for RL research [60], RL
bots) as well as the more broadly applicable game engine
research is still held back by the difficulties of choosing and
Unity. We provide insights into our selection process and
handling physics engines for implementing these interactions.
briefly mention excluded candidates like Unreal Engine and
In theory, multiple frameworks and simulation engines exist
Project Malmo in the Honourable Mentions section.
for RL experiments in physically simulated environments,
yet RL researchers often do not describe the used simu- The main contributions of this paper are:
lation pipeline and their decision in detail (e.g. [3], [19],
[44]). Thoroughly testing and comparing various simulation • A review of the engines’ popularity in terms of citations.
frameworks before choosing the right one is prohibitively • The evaluation of the engines’ feature range, feature
time-intensive. Hence, researchers turn towards ready-made quality, and usability.
solutions but may struggle to find suitable resources and tools • A detailed assessment of the engines’ RL and MARL
for creating RL environments, especially if they lack in-depth capabilities.
4202
luJ
11
]IA.sc[
1v09580.7042:viXra(a) The ant environment in MuJoCo [46] (b) The crawler environment in Unity [55]
Fig. 1: Two similar environments realized in different engines
II. METHODOLOGY 4) 3D Model library: The availability and capabilities of
general-purpose RL agent models such as ants and
Our methodology comprises two major parts. First, we
humanoids.
evaluate the popularity of different engines by looking at the
5) 3D Model creation: The ease of creating and customiz-
number of citations of the respective publications, as well as
ing models for RL agents. Optimally, this is possible
the increase in that number of time. After that, we compare
by manipulating objects within a well-interfaced editor.
the physics engines along various relevant dimensions.
Model creation only via the handling of code in XML
A. Popularity Analysis files and similar formats is rated unfavorably.
6) Environment library: The availability and usefulness of
The popularity analysis aims to evaluate the popularity of
general purpose 3D environments that can be used as
physics engines for RL by performing an analysis of the
training arenas for general purpose and RL.
citations of certain frameworks in scientific databases. We
7) Environment creation: The ease of creating and cus-
compared the popularity of the individual physics engines in
tomizing environments for RL agents. Optimally, this
the field of reinforcement learning research via the overall
is possible by manipulating objects within a well-
number of citations and the number of ML-related citations.
interfaced editor. Environment creation only via the
We describe the specific steps carried out for the popularity
handling of code in XML files and similar formats is
analysis in the appendix.
unfavorable.
B. Feature Analysis 8) Sensors: The range of available sensors, e.g. camera,
touch sensors, or radar.
The feature analysis aims to evaluate the feature range,
9) Gym Wrapper: The availability, usability, and feature
quality,andusabilityofthephysicsenginesforRL.Weassess
range of gym wrappers for the particular engines.
these criteria based on publications using these engines, the
10) Rigid body dynamics: The possibility and fidelity of
documentation provided by the engine’s developers as well
simulating basic kinematic interactions.
as previous papers reviewing performance and usability. We
11) Multi-joint dynamics: The possibility and fidelity of
describe the specific steps carried out for the feature analysis
simulating complex multi-unit kinematic interactions in
in the appendix.
embodied agents.
C. Comparison Criteria 12) File formats: Support for importing and exporting Uni-
fied Robot Description Format (URDF) and MuJoCo
Weselectedthefollowingcomparisoncriteriatoreflecteach
ModelingXMLFile(MJCF).BothareXMLfileformats
framework’sfeaturerange,featurequality,andusabilityforRL
used for representing robot models and virtual agents.
research.
13) Visualization: The graphical fidelity of the presentation
1) Open source: Whether an engine is open-source, open-
ofsimulationepisodesandresults,availabilityofin-built
access,orclosed-access.Open-sourceframeworksallow
rendering solutions, as well as the functional aesthetics
for greater accessibility, customization and better inte-
and usability of the visualization interface.
grationwith externaltools andexisting frameworks.We
14) Performance: The optimization (or possibility of opti-
did not consider any paid features.
mization)fortrainingofRLagentsbyallowingforeffi-
2) Documentation: The accessibility, extensiveness and vi-
cientparallelcomputing.Thisisaparticularlyimportant
sualization of the documentation, as well as the number
dimension, and we discuss the results in a dedicated
and quality of provided examples.
Performance section.
3) Community resources: The extent of relevant forum en-
tries,Q&As,anduser-createdmodelsandenvironments.TABLE I: Overall publications and ML publications citing
most popular, with over 3541 and 1000+ papers citing them,
each framework’s original paper since it was first released
respectively. Unity and Gazebo have also been widely used
PopularityComparison in ML, with over 528 and 1948 citations each. Brax, ODE,
PhysicsEngine Publications MLPublications since PhysX, and Webots have been used in a smaller number of
Brax 166 151 2021 ML papers, ranging between 143 and 548 citations.
Chrono 170 104 2016
Figure 2 shows, that the usage of Nvidia Isaac has seen
Gazebo 2698 1948 2004
MuJoCo 3827 3541 2012 substantial growth from 2021 to 2022, with mentions increas-
ODE1 1573 143 2004 ing from 20 to 144. Mujoco maintained its popularity from
PhysX 310 288 2021
2020 to 2021, with mentions remaining high at 695 and 709,
PyBullet1 1308 1000+ 2016
respectively. However, there was a significant drop in usage
Unity 576 528 2018
Webots 988 548 2004 in 2022 to 761 mentions and further to 458 mentions in 2023.
Chrono’s usage has remained relatively stable over the years,
with only minor fluctuations in mentions from 2016 to 2023.
III. RESULTS Gazebo experienced fluctuations in usage, with a peak of 369
mentions in 2020 and a subsequent decrease to 356 mentions
A. Popularity Analysis
in 2022. In 2023, there was a noticeable increase to 199
Table 1 shows the number of overall publications and ML-
mentions. Webots had a consistent number of mentions from
related publications citing each physics engine on the 6th of
2011 to 2020, with 72 mentions in 2020. However, in recent
September 2023.
years, there has been a decline in usage, with 36 mentions in
MuJoCo is the most popular physics engine in terms of
2023. ML Agents saw a significant increase in mentions from
citations, with over 3800 citations since its release in 2012.
2019 to 2022, with a peak of 163 mentions. In 2023, there
Gazebo follows closely, with 2698 citations since its release
was a decrease to 68 mentions. Brax’s usage has experienced
in 2004. Webots and PyBullet have also been well-cited, with
fluctuations, with a peak of 76 mentions in 2022, followed
over 988 and 1308 citations respectively. Brax, the newest of
by a decrease to 62 mentions in 2023. These year-to-year
the engines listed, has received 166 citations since its release
differencesinusagereflecttheevolvingpreferencesandtrends
in 2021, which is relatively low but expected given its recent
within the robotics research community.
release. Unity’s proportion of ML-related citations to overall
It is worth noting that the popularity of a physics engine
citations might be skewed since the associated publication by
can be influenced by factors such as ease of use, documenta-
[26] addresses Unity as a platform for learning agents and is
tion, community support, and compatibility with other tools.
not an all-purpose introduction to the Unity engine as a game
Therefore, while the number of citations and ML papers is a
developmenttoolkit.Inthisbroadersense,Unityismorewell-
usefulmeasureofpopularity,itmaynotnecessarilyreflectthe
known.
best physics engine for a particular application.
In terms of the number of ML papers that have used
a particular physics engine, MuJoCo, and PyBullet are the B. Feature Analysis
1) MuJoCo: MuJoCo (Multi-Joint dynamics with Contact;
1CountedusingGoogleScholar
[53]) is an open-source physics simulation engine specialized
for robotics, biomechanics, animation, and ML. It is owned
and curated by Google DeepMind and has become popular
with leading RL researchers, such as OpenAI’s multi-agent
Nvidia Isaac
25000 Mujoco 5.58% research [3], [41]. It provides rigid body dynamics in inter-
7.57%
Chrono action with their environment, such as collision detection and
Gazebo 4.73%
contact resolution, support for various joint types as well as
20000 Webots 10.14%
MLAgents 19.65% actuation options. This makes MuJoCo especially suitable for
Brax 8.57%10.88% RL focussed on embodied movement. The simulation can be
22.90%
15000 visualized interactively with a native graphical user interface 8.16%
28.65%24.92% (GUI) for rendering the simulation including meshes and
textures, but not while training. Advanced rendering options
10000 31.49% 46.48%
likecomplexlightingandshadersarelimited,butlessrelevant
39.09% 47.85%
for RL. Furthermore, it allows users to selectively run parts
5000 54.92%53.63% ofthecomputationpipelineforflexibility[53].Nodirectgym
50.76% 52.58%
51.10% environment integration is provided. MuJoCo can be accessed
61.85% 15.24%
52.47%62.86% 37.56% 9.21% viaDeepMind’sControlSuit(dm_control;[51]).However,this
0
2014 2016 2018 2020 2022 Python API is currently poorly documented and lacks trans-
Year
parencyaswellasusability.Accessingobjectsviadm_control
Fig. 2: Yearly citations of the frameworks’ original publica-
can be difficult. We encountered bugs and unexpected behav-
tions
iors. Furthermore, it restricts the creation and customization
srepaP
fo
rebmuNTABLE II: Feature and Usability Comparison (full description can be found in Chapter II). Legend: feature or a range of
features is fully available and functional (+ +), feature is available, but lacking in some regards (+), feature is either available,
but lacking or only available via workarounds (−), feature is not available or difficult to integrate (− −)
FeatureandUsabilityComparison
Features Brax Chrono Gazebo MuJoCo ODE PhysX PyBullet Unity Webots
OpenSource ++ ++ ++ ++ ++ + ++ − ++
Documentation −− − − + − ++ − ++ ++
Communityresources −− − + + − − − ++ +
Modellibrary + ++ ++ ++ −− + ++ ++ +
Modelcreation − − − − −− − − ++ +
Environmentlibrary −− −− + −− −− − −− ++ +
Environmentcreation −− −− −− −− −− −− −− ++ −
Visualization ++ ++ ++ + −− ++ + ++ ++
GymWrapper + − + − −− ++ + ++ ++
MARLcapabilites − − − ++ − + ++ + −
Rigidbodydynamics ++ ++ ++ ++ ++ ++ ++ ++ ++
Multi-jointdynamics ++ ++ + ++ ++ ++ ++ − +
Sensors − ++ ++ ++ −− ++ − ++ ++
URDFsupport ++ − ++ ++ −− ++ ++ −− +
MJCFsupport ++ − ++ ++ −− ++ ++ + −
of XML models. MuJoCo has decent documentation that is loading URDFs and MJCFs with dedicated functions [17],
only hard to navigate because of its large extent and lacking which can be used to import and implement ant, humanoid,
structure. The documentation itself is well presented with half-cheetah, and similar models as shown in the PyBullet
highlighted code, images, videos, and GIFs. Python bindings Quickstart Guide [18], [16]. Notably, shapes and multi-body
are taught in Google Colab notebooks. An overview and models cannot only be defined in external XML formats, but
demo notebook is provided, but many functionalities found also directly via PyBullet functions. Users can equip agents
on the GitHub repository are not explained. Along with the with sensors to capture information such as position, orienta-
engine, Google DeepMind offers a collection of pre-defined, tion, velocity, or contact forces. Complex 3D environments
importable models equipped with joints and limbs that are are not provided. PyBullet has functional visualization but
useful for embodied RL2. Models and environment content is not specialized for graphics rendering. Complex lighting,
can be defined and customized in XML files. The resulting textures, and shaders are not supported [26]. PyBullet does
physical model can be hard to pre-visualize from just code. not provide a prebuilt MARL environment. However, [43]
Hence, additional 3D modeling tools that can export MJCFs developed an open-source OpenAI Gym-like environment
or URDFs, like Blender, may be required for custom model called gym-pybullet-drones for multiple quadcopters. Several
creation in more complex projects. MuJoCo natively runs on researchersutilizedthisframeworktoconductMARLresearch
asinglethread,butmulti-threadingcanalsobeimplemented3. [21], [47], [54], thus providing evidence for the capabilities
Furthermore, there are multiple libraries like Envpool [58], of the underlying PyBullet engine in principle. PyBullet’s
which enable users to increase the sampling performance documentationis hardtoaccessas themainsite linkstothree
significantly by applying highly optimized vectorization tech- differentsources,whicharelimitedtoGoogleDocsandpoorly
niques. At the same time it has to be mentioned that such formattedPDFfileswithoutcodehighlightingontheirGitHub
librariesareoftenonlyoptimizedforclassicsingle-agentgym repository. This makes the needed information scattered and
tasks and are not directly usable for MARL setups. If such hard to connect. The main document, the PyBullet Quick-
libraries can be used for custom multi-agent environments, start Guide, provides somewhat extensive information over
they often require proficiency in programming languages like 75 pages that lacks in-depth use cases. Example applications
C or a generally deep understanding of the used framework. and showcases are found on GitHub, however not in Python.
However, single thread performance is sufficient for the wide Nevertheless, PyBullet has a large community 4.
range of tasks and often not worth the additional core usage 3) Unity: Unity[26]isapopulargamedevelopmentengine.
[53]. Despite its daunting entry barrier and lacking documen- In contrast to the other presented engines, Unity is not open-
tation, the range of features make MuJoCo a powerful and source, but rather open-access where not all features are
flexible framework for RL. available in the free version. Paid plans for professional and
2) PyBullet: PyBullet [17] is an open-source Python mod- entrepreneurial use exist. Unity stands out compared to the
ule for robotics simulation and ML that allows users to other engines, due to its intuitive interface that combines all
dynamically create and simulate physics-based environments features in a single workspace. With Unity ML Agents, it
for RL. PyBullet wraps the C-API of Bullet and offers simple offers a large open-source toolbox with 3D training arenas,
integration with TensorFlow and PyTorch. PyBullet supports model assets that are already equipped with RL algorithms,
likeProximalPolicyOptimization(PPO)andSoft-ActorCritic
2https://github.com/deepmind/mujoco_menagerie
3https://mujoco.readthedocs.io/en/latest/programming/simulation.html 4https://pybullet.org/Bullet/phpBB3/(SAC), that work out-of-the-box. Through its asset store, Unity to specific RL needs might not be as easily imitated.
Unity offers a large array of official and community-built 4) Gazebo: Gazebo[32]isanopen-sourcerobotsimulation
packages, that can be especially useful for the design of software for simulating and testing robotic systems developed
variousenvironments.Manyofthesearefreeandcontinuously by Open Robotics. It is the official simulation platform for
updated. Unity ML Agents also offers a Python API to theDARPARoboticsChallenge[24].Gazebooffersrigidbody
integrateexternallydefinedagents.Unityphysics,theengine’s dynamics,varioustypesofjoints,andsensorsthroughmultiple
package for deterministic rigid body dynamics simulation, supported physics engines, including ODE, Bullet, Simbody,
can be complemented with plug-ins for the engines Havok and DART, allowing users to easily switch between them.
5 and MuJoCo 6. A wide range of sensors is available. Unity Users can utilize a wide range of sensors. Gazebo provides
hashighlyaccessibleandextensivedocumentation,withwell- a wide range of pre-built models and environments designed
structured tables of content and hyperlinks to related sections. for simulation purposes. With its own editor system, users
Codeexamplesarewell-highlightedandembeddedinvisually cancreateandmodifysimplemodelsdirectlyintheGUI.The
appealing tutorials that cover all aspects of the engine. GazeboGUIrendersthe3Dsimulationinrealtime.Gazeboal-
Many RL paradigms implant agents into video-game-like lows users to define and customize robot models using URDF
scenarios, where they have to solve tasks similar to those set or SDF. However, customization of a large environment could
forhumanplayers[26].Historically,someofthemostnotable take a lot of time [24]. Gazebo provides the Python package
milestones of AI research have been performances in games. sdformat-mjcf7 that allows bidirectional conversion between
This includes digital versions of classical board games, like SDFandMJCF.Gazebo’sdocumentationconsistsofatutorial
chess and go [49] as well as established video games, such as section with explanatory images, examples, highlighted code,
StarCraftII[56]andDota2[42].Furthermore,theemergence and some hidden automatically generated documents. The
of generalizable skills in agents that are applicable to a range rudimentary are not explained at all in the documents, only
of different video games and RL environments is one of the somewhat in the tutorials. No Python bindings are explained
core objectives of much of RL research [34], [48]. This has or available apart from PyGazebo8 9 and Ignition10, where
been tried and tested successfully [14] with AI benchmarks it is unclear to the user whether the information provided is
based on Unity, such as the Obstacle Tower Challenge [27]. official.
For these reasons, Unity should, in theory, be the natural Gazebodoesnotprovideanofficialgymwrapper.However,
choice of engine for the implementation of any video-game- the Gazebo simulator offers a rich set of APIs and tools
like RL scenario. However, the fact that Unity is specialized for simulation, physics-based modeling, and visualization,
for game development poses several disadvantages. Unity’s which can be used alongside the OpenAI Gym framework
optimization for video games clashes with the RL training by creating a custom gym wrapper. There is open-source
demands of maximizing frames, i.e. simulation steps per unit project called gym-gazebo2 [35] that provides a gym wrapper
of time and computational resource [57]. Another hurdle is specifically designed for integrating Gazebo simulations with
that Unity ML Agents is only convenient as long as the RL algorithms. Gym-Ignition 11 is a framework that provides
wholepipelineisassembledwithinUnity.Therearesignificant reproducible robotic environments for RL and robotics re-
hurdleswhenitcomestointegratingaUnityenvironmentinto search[22].UserscancreateenvironmentsineitherPythonor
existingPythoncode.Thelimiteddevelopmentpossibilitieson C++. This feature combined with the multitude of supported
top of Unity as opposed to within Unity can be identified engines enables effective randomization and helps prevent
as a core problem. Unity makes the setup of multi-agent potentialoverfittingissues.Gym-Ignitioncurrentlyhaslimited
scenarios quite practical and easily implementable. However, support for photorealistic rendering [22]. Although Gazebo
efficiency becomes even more of a problem for MARL than itself does not provide an environment for setting up MARL,
for single-agent training. If a simulation becomes too com- MultiRoboLearn [12] provides a framework to apply MARL
plex and computationally expensive, Unity increases the time to Gazebo, specialized for robotics simulation. Base Gazebo
between simulation frames. This hurts simulation fidelity and exhibitsconsiderableperformancelosswithmulti-agentsetups
constrains MARL approaches, as MARL has typically a high [10]. Gazebo’s problematic usability makes the implementa-
amount of interacting units, especially with embodied setups. tionof3Denvironmentsdifficult.However,userscantrade-off
Workarounds to manually fix simulation fidelity and training simulation speed and computational cost for higher fidelity.
efficiency problems exist (see [57]). Despite these disadvan- Thus, it seems more appropriate for robotics RL, especially
tages, Unity is used by leading researchers for complex and industrial applications [33].
computationallydemandingRLscenarios[19],[40].However,
5) PhysX/IsaacGym: Nvidia’s PhysX [39] is an SDK
both did not utilize the ML Agents toolkit but went for
mainly used for visual effects, video game development,
customsolutionsbasedon[57].GoogleDeepMind’sextensive
resources have to be considered here, as this adaptation of
7https://github.com/gazebosim/gz-mujoco/tree/main/sdformat_mjcf
8https://github.com/jpieper/pygazebo
5https://docs.unity3d.com/Packages/com.havok.physics@0.1/manual/index. 9https://pygazebo.readthedocs.io/en/latest/pygazebo.html
html 10https://gazebosim.org/api/gazebo/2.10/index.html
6https://mujoco.readthedocs.io/en/latest/unity.html 11https://ignitionrobotics.orgrobotics and medical simulation12. Using Nvidia IsaacGym While ODE does not provide a Python API directly, there
[36]asagymenvironment,PhysXcanalsorunRLalgorithms existsPyODE16,whichisasetofopen-sourcePythonbindings
in its virtual environment. Examples given by IsaacGym are for the Open Dynamics Engine. ODE does not provide direct
implemented in PyTorch, but TensorFlow is equally feasi- support for URDF or MJCF format. Additionally, ODE does
ble. While PhysX is open source, IsaacGym is not, which notincludebuilt-insensorfunctionalities.Visualizationofsim-
might hinder its customization [22]. Typical MuJoCo and ulationresultsaswellastheinterfaceinwhichitisembedded
RL Games13 models can be used. With IsaacSim in Nvidia’s were neither high-resolution nor up to modern UI standards.
Omniverse, an even more specialized toolkit for robotics Overall, ODE is outdated and unwieldy on the usability side
simulation exists. IsaacGym provides a PPO implementation and makes for a strenuous implementation of state-of-the-art
andsupportsMJCFandURDF.PhysXsupportsphotorealistic RL paradigms. Furthermore, it has little relevance in today’s
rendering in an intuitive interface. Range, contact, force and RL research literature (see popularity comparison). Therefore,
camerasensorsareavailableviaextensions14.PhysXandIsaac ODE seems only applicable to current RL research setups
Gym are excellently documented with a digestible structure, through its comparatively more modern front-ends and engine
visualexamples,extensivedocuments,explanatorytextaswell integrations in Gazebo and Webots.
as video tutorials and GIFs. 7) Webots: Webots[37]isawidelyusedopen-sourcerobot
IsaacGym’s distinguishing feature is that it leverages GPU simulation software developed by Cyberbotics, supporting
acceleration to increase simulation speed compared to other C, C++ as well as Python. It simulates a wide range of
engines’ CPU-based physics simulation. By directly connect- robotic systems, relying on a customized version of the ODE
ing the simulation backend with PyTorch Tensors, IsaacGym 3D dynamics library. Webots makes highly specific sensors
aims to avoid CPU bottlenecks. If CPU power availability is available, from camera and touch sensors to radar and lidar.
an issue, this can be an immense advantage, as it potentially Its GUI offers real-time 3D visualization and a front-end for
increases the number of RL environments that can run si- modifyingsimulationmodels.Webotsallowsarobotcontroller
multaneously on a single computer and decreases the need to export URDFs. However, generated URDFs are currently
for costly computing clusters. Notably, ant, humanoid and limited to a few elements such as the definition of a box,
hand movement benchmarks showed decreased training time cylinder, or sphere. Webots does not directly support MJCFs.
[36]. Nevertheless, GPU-based simulation can be hindering It has its own native file format, PROTO, for defining the
to successful RL research as the GPU will often have to be structure, appearance, and dynamics of robot models. The
fully dedicated to running the deep learning algorithm and documentation of Webots is well-structured, providing user
the CPU is rarely fully occupied in MARL. Thus, PhysX and installation guides that are easy to access. Its documen-
might be more of a specialized tool for robotics RL and less tation makes good use of images, videos, and code chunks
suitable to basic RL research. At the same time, even though with highlighting. Both the reference manual and the user
there are some examples of MARL setups in Nvidia Isaac guide are quite extensive. They have a dedicated tutorials
[13],theimplementationrequiresmorein-depthprogramming section that is extensive with great explanations, code, and
knowledge than other comparable setups. However, as PhysX images. Since Webots is built on top of ODE, users will have
and IsaacGym represent one of the few high-usability, unified some inconvenience in checking the poorly structured ODE
frameworksforRLandphysicssimulation[22]atthemoment, documentation for certain parameter or function explanations.
the drawback might in some scenarios be worth the cost. The Webots environment library is limited to a few specific
6) ODE: ODE15 (OpenDynamicsEngine)providesaccess examples, such as an apartment and a factory. The available
to an open-source C/C++ library designed for simulating Webotsmodellibraryisspecializedforcomplexroboticssim-
rigid body dynamics. It supports advanced joint types and ulation17 rather than general purpose RL. Simple models for
integrated collision detection with friction. It is commonly embodied RL, like the typical ant, are possible to implement
used for simulating vehicles and dynamic objects in 3D in Webots, but have to be made from scratch or imported as a
environments. The documentation is scattered across several third-party asset. Similarly, base Webots offers no integration
different web pages and is hard to navigate. The single-page forTensorfloworPyTorchaswellasnomulti-agentsimulation
user manual and a dedicated tutorial section provide expla- capabilities, but Deepbots18 [31] closes these gaps. Deepbots
nations of core functionalities and automatically generated interfaces Webots with OpenAI Gym and adds functionalities
documents with a severely dated appearance are provided. necessary for controlling RL agents and gym environments
Some rather short code examples without highlighted code while hiding Webots features that are not relevant for RL.
are hidden within ODE’s GitHub repository. The FAQ on Thus, the RL algorithm backend, TensorFlow or PyTorch
GitHub is very thorough, however. Many features relevant to is connected with the simulation side. However, Deepbots,
the criteria evaluation were not locatable or not documented. as the name suggests, is specialized for robotics, and the
complexity of the provided environments is achieved through
12https://developer.nvidia.com/blog/introducing-isaac-gym-rl-for-robotics/
13https://github.com/Denys88/rl_games
14https://docs.omniverse.nvidia.com/app_isaacsim/app_isaacsim/manual_ 16https://pypi.org/project/PyODE/
isaac_extensions.html 17https://www.cyberbotics.com/doc/guide/robots?version=R2019a-rev1
15https://www.ode.org/ 18https://github.com/aidudezzz/deepbotscomplicated multi-joint robotics models, rather than tightly 9) Chrono: Chrono23 [50] is an open-source modeling and
packed 3D worlds. Several simple ready-to-use environments, physicssimulationengineforroboticsandvehicledynamics.It
such as CartPole, PitEscape, and FindBall 19, can be used offersawiderangeofphysicalsimulationcapabilities,includ-
to benchmark RL algorithms in Webots [31]. However, no ingcollisiondetection,rigidbodydynamics,andvariousforce
MARL algorithmic environments are provided [12]. Deepbots elements. PyChrono24 [8] wraps the C++ simulation library
has not caught on yet with the RL research community (see and allows users to build physical models and exchange data
citations of [31]). Generally, Webots appears to not lend itself between the simulation and ML framework. For RL setups,
to highly scalable training and therefore MARL [10], as it Chrono provides a custom PyTorch PPO implementation [8].
runs each simulation in its GUI and can only be parallelized A Chrono-based simulation environment to design and test
by opening multiple instances of Webots manually [33]. Its end-to-endexists[9].However,itismostlyfocusedontraining
high-fidelitysimulationanduser-friendlyGUI,however,make autonomous vehicles and robots in off-road settings [8], [59].
it especially suitable for robotics RL setups that do not have Gym Chrono25 is a set of PyChrono-based OpenAI Gym
high parallelization demands. environments. Gym Chrono provides examples for training
via TensorFlow and PyTorch. Chrono::Sensor26 provides a
8) Brax: Brax, "a differentiable physics engine for large
rich set of sensor modules which can simulate cameras,
scale rigid body simulation" [23] is an open-source physics
lidars, radars, gyroscopes etc. It does not directly support
simulation engine written in JAX that is accessible via
URDF or MJCF format natively and its model library mainly
Google Colab 20. Brax simulates physical systems made up
offers vehicles and robots. However, in Gym Chrono, users
of rigid bodies, joints, and actuators and offers high flex-
can utilize ant models [7] for RL setups. Chrono provides
ibility for creating multi-agent environments with different
a limited environment library. Its GUI provides convenient
physics properties, observation spaces, and action spaces.
controlandmonitoringofsimulations.Also,Chronointegrates
[23]. It is specifically designed for RL and optimized to
with various visualization libraries, such as Irrlicht, OpenGL,
efficiently run parallel physics simulations alongside the RL
and Unity3D, to render the simulated systems in run-time.
algorithm on a single accelerator. Brax specifically aims to
Chrono’s and PyChrono’s documentation is comprised of a
solve similar problems and offer similar models to MuJoCo.
poorlystructuredautomaticallygenerateddocument.Themain
Whereasmostaforementionedsimulationframeworksseparate
document is somewhat extensive, but lacks explanation of
simulation (CPU) and RL algorithm (GPU/TPU), Brax brings
fundemantals,whilethededicatedtutorialsectioniscode-only
both together on a single GPU or TPU chip in order to
and does not explain anything on a conceptual level. Only
reducelatency.Braxisquitenewandpoorlydocumented.The
sparse images and no explanatory videos are provided. We
documentation comprises only a short readme file and three
found Chrono’s negligible relevance in the ML literature (see
example notebooks in Google Colab. No central webpage for
popularity comparison), poor usabilty and focus on vehicle
information is available. No models or example environments
robotics [15] to indicate a limited usefulness as an engine for
areprovided.Furthermore,communityresources,likeassetsor
RL research and MARL purposes.
helpfulforumentries,arenottobefound.Brax’smodellibrary
10) Honorablementions: UnrealEngineisapopularopen-
offers implementations of the basic MuJoCo models, such as
access game development engine. Recently, Unreal Engine
theant,humanoid,andhalf-cheetah2122,butnotmuchbeyond.
introduced Learning Agents, a plugin geared towards game
No complex training environments are provided. According
developers who want to write AI bots. The Learning Agents
to [10], Brax has problems with complex MARL, precisely
APIcanbeaccessedviaUnrealEngine’sgeneraluserinterface
because of its computationally expensive high-fidelity simu-
and can be used with C++ and Python. Agents can be trained
lation. Scaling the number of agents increases this problem
with an existing PPO algorithm. Support for SAC and Q-
and after a threshold of only a low number of agents the
Learning is provided. However, the Learning Agents API has
simulation reaches a standstill. Its main selling point, GPU-
beenavailableforlessthansevenmonthsasofDecember2023
based simulation, is also offered by PhysX/IsaacGym with a
and has correspondingly not been widely cited in the relevant
better feature range and usability. For these reasons, Brax in
RL literature. For this reason and because Epic Games, the
itscurrentformdoesneitherseemtobeaplatformforgeneral
developers of Unreal Engine, state themselves, that Learning
RL,norfillamorespecificniche.Despitethesecriticisms,we
Agents is not a general purpose ML framework, we won’t
recognizethisinnovativeapproachandtheefforttomakedeep
go into detail comparing it to other engines. Third-party tools
learning more accessible and less reliant on high-performance
for RL with Unreal Engine, e.g. Mindmaker, are available via
clusters.
the Unreal Engine Marketplace. Godot is a open source game
development engine that can be used for RL research via
the framework Godot RL Agents [6]. However, Godot itself
19https://github.com/aidudezzz/deepworlds is not widely used and has even less relevance for RL [6].
20https://colab.research.google.com/github/google/brax/blob/main/
notebooks/basics.ipynb 23https://projectchrono.org/
21https://ai.googleblog.com/2021/07/speeding-up-reinforcement-learning-with. 24https://api.projectchrono.org/development/pychrono_introduction.html
html 25https://github.com/projectchrono/gym-chrono
22https://github.com/google/brax 26https://api.projectchrono.org/manual_sensor.htmlMore interesting for RL researchers is Generally Intelligent’s on information from the engine publishers and developers, as
Avalon [2], a 3D simulator based on Godot that lets users well as external researchers who used and evaluated them.
plug RL agents into ready-made environments with complex Therefore,theperformanceevaluationisneitherexhaustivenor
task interaction possibilities. Project Malmo [25] is a useful compares all frameworks on equal footing. Correspondingly,
platform for exploration-related RL experimentation that is the evaluation might be skewed by the availability of data
based on the Minecraft engine. As such, it is constrained on the engines. On the other hand, sparse information is a
by the limitations of the underlying video game [26] and legitimate shortcoming.
cannot provide complex, embodied physics simulation with
high fidelity and it cannot be used to build scenarios that
VI. CONCLUSION
are not feasible in Minecraft. Similar limitations are true for In this paper, we looked at 9 frameworks for RL research
ViZDoom [28] which is based on the underlying engine of the and reviewed them regarding their popularity, feature range,
popular video game Doom and DeepMind Lab [5], based on featurequalityandusabilityandwecontributedtothefieldby
Quake III. VMAS (Vectorized Multi-Agent Simulator; [10]) is providing an overview of the engines that enables researchers
a 2D physics engine written in PyTorch that is specifically to make informed decision when choosing their framework
designed with efficient MARL in mind. However, the lack for RL simulation. We paid special attention to the engine’s
of 3D implementations severely limit the possible complexity MARL capabilities. We conclude, that for successful RL
of the training environment as well as the agent-environment research, it is first necessary to sharply define the intended
interaction. scenarioandresearchwhetherasuitableimplementationisnot
alreadyavailable.Forexample,thereisnoreasontohandlethe
IV. PERFORMANCE
usabilityinconveniencesofMuJoCoifitissufficienttohavea
[38] showed that MuJoCo is better than PyBullet and MARLsetupin2D.ThisholdsespeciallytrueforRLtraining
ODE at generalizing learning to other engines, i.e. agents on video game scenarios, where the selection of benchmarks
who learned to solve a task in MuJoCo still perform when is plentiful. For anything more specific, the choice of physics
the same task is transferred and implemented in a different engines naturally depends on the defined needs and available
engine. Agents trained via PyBullet did not transfer their resources of the project.
learning at all. Thus, it might be the case that, for example, MuJoCo is currently the dominant framework for RL
agents trained on PyBullet just learn to navigate PyBullet research due to its good performance and flexibility, even
environments, whereas agents trained on MuJoCo learn to though its documentation is sometimes lacking and might
navigate any similarly simulated environment. MuJoCo’s de- make usage for smaller teams more difficult than with other
velopers [20] compared the speed, simulation stability, and competitors.Comparedtotheotherengines,MuJoCocurrently
simulation accuracy of Bullet, MuJoCo, ODE, and PhysX by providesoneofthebestfoundationsforMARLduetoitshigh
implementingthesamescenarioineachengineandmeasuring simulation fidelity and high training efficiency. Nevertheless,
thetimestepsatwhichsimulationerrorsoccurred.Theyfound thecreationofcomplextrainingenvironmentsforMuJoCocan
MuJoCo to have the best performance out of all engines, be comparatively strenuous. Notably, high-fidelity simulation
especiallyinscenariosthatsimulatebodieswithmanyjointsor might not be useful for all training setups, as it can mas-
connected elements. [33] implemented a similar broad range sively increase the computational demands while adding little
ofusecaseswithGazebo,MuJoCo,PyBullet,andWebotsand benefit to setups where accurate kinematics is not paramount.
compared the ratio of simulation time that can be achieved in PyBullet offers similar features and usability as MuJoCo, but
real-world time (RTF). MuJoCo was reported to have a high consistently rates worse in performance reviews [20], [33],
RTF across scenarios, at the cost of some accuracy. PyBullet [38]. For this, it makes up in a wide range of dedicated
achieved a lower RTF but was highlighted for its superior functions for loading and defining objects and models. Once
usability. Meanwhile, Gazebo was found to be unwieldy and theuserhasdisentangledthedocumentation,RLscenariosare
mostsuitableforsimulationsthatareintendedtobetransferred straightforward to implement in PyBullet.
to real systems. Webots showed high stability and RTF even While designing an environment is the easiest in Unity
in the most complex scenarios but is criticized for its lack out of all frameworks, Unity is not optimized for parallel
of native parallelization support. As already established, Brax computing and large-scale training. Unity has various pre-
scales poorly in MARL setups [10]. implemented MARL scenarios and can support simple multi-
agent interactions, but has problems with scaling complexity
V. LIMITATIONS
and simulation fidelity. One should also consider that low
To rigorously assess and compare the quantitative per- simulation fidelity impacts the reproducibility of results neg-
formance of the presented frameworks, one would have to atively [57]. Unity’s and Unity ML Agents’ strong suit is
implement the same scenarios for typical RL use cases in all theRLimplementationsofvideo-gamescenarios.Beyondthis
engines. This goes beyond the scope of this paper and due to purpose, Unity seems most suitable for proofs of concept or
thesheerrequiredefforthasnotbeenattemptedtoasufficient RL experiments that are not intended to scale the training
degree by any other publication to the best of our knowledge. beyond a certain threshold. Right now, Brax fails to impress,
For statements on technical details of the engines we relied due to its limited available resources and documentation andpoor multi-agent performance. However, Brax is quite new [3] B. Baker, I. Kanitscheider, T. Markov, Y. Wu, G. Powell, B. McGrew,
and might be updated with more useful features in the near and I. Mordatch, “Emergent tool use from multi-agent autocurricula,”
2020.
future. PhysX/IsaacGym, on the other hand, excels in terms
[4] T. Bansal, J. Pachocki, S. Sidor, I. Sutskever, and I. Mordatch,
of usability and provides a unified framework for scenario “Emergent complexity via multi-agent competition,” arXiv preprint
creation, simulation, and RL. Both Brax and IsaacGym rely arXiv:1710.03748,2017.
[5] C. Beattie, J. Z. Leibo, D. Teplyashin, T. Ward, M. Wainwright,
on GPU-driven simulation which can be disadvantageous for
H.Küttler,A.Lefrancq,S.Green,V.Valdés,A.Sadik,J.Schrittwieser,
large-scaleRLresearch.BaseODEisoutdatedbothintermsof K.Anderson,S.York,M.Cant,A.Cain,A.Bolton,S.Gaffney,H.King,
featurerangeandusabilityandaccordinglyhaslimitedimpact D.Hassabis,S.Legg,andS.Petersen,“Deepmindlab,”2016.
[6] E.Beeching,J.Debangoye,O.Simonin,andC.Wolf,“Godotreinforce-
oncurrentRLresearch,whileChronolacksimportantfeatures
mentlearningagents,”2021.
suchasURDFandMJCFsupport.Wefound,thatGazeboand [7] S. Benatti, A. Tasora, and D. Mangoni, “Training a four legged robot
Webots represent powerful tools for high-fidelity simulation via deep reinforcement learning and multibody simulation,” pp. 391–
398,2020.
robotics with decent usability. However, both are not geared
[8] S. Benatti, A. Young, A. Elmquist, J. Taves, R. Serban, D. Mangoni,
towards MARL applications. A. Tasora, and D. Negrut, “Pychrono and gym-chrono: A deep rein-
Custom creation of complex environments and correspond- forcementlearningframeworkleveragingmultibodydynamicstocontrol
autonomousvehiclesandrobots,”pp.573–584,012022.
ing libraries with pre-built solutions remain a gap in available
[9] S.Benatti,A.Young,A.Elmquist,J.Taves,A.Tasora,R.Serban,and
simulationpipelines.Anotherresearchgapisthelackoftech- D.Negrut,“End-to-endlearningforoff-roadterrainnavigationusingthe
nical training performance comparison for MARL in complex chronoopen-sourcesimulationplatform,”MultibodySystemDynamics,
vol.54,042022.
3D environments as well as the implementation difficulty for
[10] M. Bettini, R. Kortvelesy, J. Blumenkamp, and A. Prorok, “Vmas: A
typical scenarios in each engine. Further development and vectorizedmulti-agentsimulatorforcollectiverobotlearning,”2022.
research is needed in these areas. Study-specific transparency [11] G. Brockman, V. Cheung, L. Pettersson, J. Schneider, J. Schul-
man, J. Tang, and W. Zaremba, “Openai gym,” arXiv preprint
andreproducibilityremainastructuralprobleminRLresearch,
arXiv:1606.01540,2016.
with many leading institutes and research teams opting for [12] J. Chen, F. Deng, Y. Gao, J. Hu, X. Guo, G. Liang, and T. L.
closed access. Further guidance on environment creation and Lam,“Multirobolearn:Anopen-sourceframeworkformulti-robotdeep
reinforcementlearning,”2022.
replication and better usability of the relevant tools is thus
[13] Y. Chen, Y. Yang, T. Wu, S. Wang, X. Feng, J. Jiang, Z. Lu,
strongly necessary. Symptomatic for the field, the most per- S. M. McAleer, H. Dong, and S.-C. Zhu, “Towards human-level
formant engine (MuJoCo) has poor usability and the most bimanual dexterous manipulation with reinforcement learning,” in
Thirty-sixth Conference on Neural Information Processing Systems
user-friendly engine (Unity) suffers from poor performance.
Datasets and Benchmarks Track, 2022. [Online]. Available: https:
For significant progress in the field, a better combination of //openreview.net/forum?id=D29JbExncTP
the best of the two worlds has to be achieved. [14] V. Clay, P. König, K.-U. Kühnberger, and G. Pipa, “Learning
sparse and meaningful representations through embodiment,” Neural
A. Author contributions Networks, vol. 134, pp. 23–41, 2021. [Online]. Available: https:
//www.sciencedirect.com/science/article/pii/S0893608020303890
ThisresearchwascompletedwithinthescopeofMicrocos-
[15] J.Collins,S.Chand,A.Vanderkop,andD.Howard,“Areviewofphysics
mAI,whichmadethisprojectpossible.Forfurtherinformation simulators for robotic applications,” IEEE Access, vol. 9, pp. 51416–
and access to the code, please visit microcosm.ai. M.K. made 51431,2021.
[16] E. Coumans and Y. Bai, “Pybulletquickstartguide - github,”
the main writing contribution and organized the research
https://github.com/bulletphysics/bullet3/blob/master/docs/pybullet_
and writing process. C.W. contributed to the methodology, quickstart_guide/PyBulletQuickstartGuide.md.html, accessed: 2023-12-
crawling algorithm and popularity comparison. H.H. made 04.
[17] ——, “Pybullet, a python module for physics simulation for games,
contributions to the Chrono, Gazebo, ODE and Webots chap-
roboticsandmachinelearning.”2016.
ters. J.M., E.B. and the larger MicrocosmAI research project [18] ——,“Pybulletquickstartguide,”2021.
contributed expertise, feedback and a framework for supervi- [19] DeepMind-Adaptive-Agents-Team, J. Bauer, K. Baumli, S. Baveja,
F.Behbahani,A.Bhoopchand,N.Bradley-Schmieg,M.Chang,N.Clay,
sion.Allauthorsresearcheddataandliteratureandcontributed
A.Collister,V.Dasagi,L.Gonzalez,K.Gregor,E.Hughes,S.Kashem,
substantiallytotheconceptualizationofthesubmittedversion. M. Loks-Thompson, H. Openshaw, J. Parker-Holder, S. Pathak,
N. Perez-Nieves, N. Rakicevic, T. Rocktäschel, Y. Schroecker, J. Syg-
REFERENCES
nowski,K.Tuyls,S.York,A.Zacherl,andL.Zhang,“Human-timescale
[1] M.Abadi,A.Agarwal,P.Barham,E.Brevdo,Z.Chen,C.Citro,G.S. adaptationinanopen-endedtaskspace,”2023.
Corrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, [20] T. Erez, Y. Tassa, and E. Todorov, “Simulation tools for model-based
A. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser, robotics:Comparisonofbullet,havok,mujoco,odeandphysx,”052015.
M. Kudlur, J. Levenberg, D. Mané, R. Monga, S. Moore, D. Murray, [21] M.Feng,W.Zhou,Y.Yang,andH.Li,“Joint-predictiverepresentations
C. Olah, M. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar, formulti-agentreinforcementlearning,”2022.
P. Tucker, V. Vanhoucke, V. Vasudevan, F. Viégas, O. Vinyals, [22] D. Ferigo, S. Traversaro, G. Metta, and D. Pucci, “Gym-ignition:
P. Warden, M. Wattenberg, M. Wicke, Y. Yu, and X. Zheng, Reproducibleroboticsimulationsforreinforcementlearning,”jan2020.
“TensorFlow:Large-scalemachinelearningonheterogeneoussystems,” [23] C. D. Freeman, E. Frey, A. Raichuk, S. Girgin, I. Mordatch, and
2015, software available from tensorflow.org. [Online]. Available: O.Bachem,“Brax–adifferentiablephysicsengineforlargescalerigid
https://www.tensorflow.org/ bodysimulation,”2021.
[2] J. Albrecht, A. Fetterman, B. Fogelman, E. Kitanidis, B. Wróblewski, [24] S. Ivaldi, V. Padois, and F. Nori, “Tools for dynamics simulation of
N. Seo, M. Rosenthal, M. Knutins, Z. Polizzi, J. Simon, and robots:asurveybasedonuserfeedback,”2014.
K.Qiu,“Avalon:Abenchmarkforrlgeneralizationusingprocedurally [25] M. Johnson, K. Hofmann, T. Hutton, D. Bignell, and K. Hofmann,
generated worlds,” in Advances in Neural Information Processing “The malmo platform for artificial intelligence experimentation,” July
Systems, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, 2016. [Online]. Available: https://www.microsoft.com/en-us/research/
and A. Oh, Eds., vol. 35. Curran Associates, Inc., 2022, pp. 12813– publication/malmo-platform-artificial-intelligence-experimentation/
12825. [Online]. Available: https://proceedings.neurips.cc/paper_files/
paper/2022/file/539f1f7dd156cfe1222b0be83f247d35-Paper-Datasets_
and_Benchmarks.pdf[26] A.Juliani,V.-P.Berges,E.Teng,A.Cohen,J.Harper,C.Elion,C.Goy, [46] S. Pateria, B. Subagdja, A.-H. Tan, and C. Quek, “End-to-end hierar-
Y.Gao,H.Henry,M.Mattar,andD.Lange,“Unity:Ageneralplatform chicalreinforcementlearningwithintegratedsubgoaldiscovery,”IEEE
forintelligentagents,”2020. TransactionsonNeuralNetworksandLearningSystems,vol.33,no.12,
[27] A. Juliani, A. Khalifa, V.-P. Berges, J. Harper, E. Teng, H. Henry, pp.7778–7790,2021.
A.Crespi,J.Togelius,andD.Lange,“Obstacletower:Ageneralization [47] L.M.Schmidt,J.Brosig,A.Plinge,B.M.Eskofier,andC.Mutschler,
challengeinvision,control,andplanning,”2019. “Anintroductiontomulti-agentreinforcementlearningandreviewofits
[28] M. Kempka, M. Wydmuch, G. Runc, J. Toczek, and W. Jas´kowski, application to autonomous mobility,” in 2022 IEEE 25th International
“Vizdoom:Adoom-basedairesearchplatformforvisualreinforcement ConferenceonIntelligentTransportationSystems(ITSC). IEEE,2022,
learning,”2016. pp.1342–1349.
[29] T. Kim, M. Jang, and J. Kim, “A survey on simulation environments [48] J. Schrittwieser, I. Antonoglou, T. Hubert, K. Simonyan, L. Sifre,
for reinforcement learning,” in 2021 18th International Conference on S.Schmitt,A.Guez,E.Lockhart,D.Hassabis,T.Graepel,T.Lillicrap,
UbiquitousRobots(UR). IEEE,2021,pp.63–67. and D. Silver, “Mastering atari, go, chess and shogi by planning with
[30] R. M. Kinney, C. Anastasiades, R. Authur, I. Beltagy, J. Bragg, a learned model,” Nature, vol. 588, no. 7839, pp. 604–609, 12 2020.
A. Buraczynski, I. Cachola, S. Candra, Y. Chandrasekhar, A. Cohan, [Online].Available:https://doi.org/10.1038%2Fs41586-020-03051-4
M. Crawford, D. Downey, J. Dunkelberger, O. Etzioni, R. Evans, [49] D.Silver,T.Hubert,J.Schrittwieser,I.Antonoglou,M.Lai,A.Guez,
S. Feldman, J. Gorney, D. W. Graham, F. Hu, R. Huff, D. King, M.Lanctot,L.Sifre,D.Kumaran,T.Graepel,T.Lillicrap,K.Simonyan,
S.Kohlmeier,B.Kuehl,M.Langan,D.Lin,H.Liu,K.Lo,J.Lochner, andD.Hassabis,“Masteringchessandshogibyself-playwithageneral
K. MacMillan, T. Murray, C. Newell, S. R. Rao, S. Rohatgi, P. L. reinforcementlearningalgorithm,”2017.
Sayre, Z. Shen, A. Singh, L. Soldaini, S. Subramanian, A. Tanaka, [50] A. Tasora, R. Serban, H. Mazhar, A. Pazouki, D. Melanz, J. Fleis-
A.D.Wade,L.M.Wagner,L.L.Wang,C.Wilhelm,C.Wu,J.Yang, chmann, M. Taylor, H. Sugiyama, and D. Negrut, “Chrono: An open
A. Zamarron, M. van Zuylen, and D. S. Weld, “The semantic scholar sourcemulti-physicsdynamicsengine,”pp.19–49,062016.
open data platform,” ArXiv, vol. abs/2301.10140, 2023. [Online]. [51] Y. Tassa, Y. Doron, A. Muldal, T. Erez, Y. Li, D. de Las Casas,
Available:https://api.semanticscholar.org/CorpusID:256194545 D. Budden, A. Abdolmaleki, J. Merel, A. Lefrancq, T. Lillicrap, and
[31] M. Kirtas, K. Tsampazis, N. Passalis, and A. Tefas, “Deepbots: A M.Riedmiller,“Deepmindcontrolsuite,”2018.
webots-based deep reinforcement learning framework for robotics,” in [52] J. Terry, B. Black, N. Grammel, M. Jayakumar, A. Hari, R. Sullivan,
ArtificialIntelligenceApplicationsandInnovations:16thIFIPWG12.5 L. S. Santos, C. Dieffendahl, C. Horsch, R. Perez-Vicente et al.,
InternationalConference,AIAI2020,NeosMarmaras,Greece,June5– “Pettingzoo: Gym for multi-agent reinforcement learning,” Advances
7,2020,Proceedings,PartII16. Springer,2020,pp.64–75. inNeuralInformationProcessingSystems,vol.34,pp.15032–15043,
[32] N.KoenigandA.Howard,“Designanduseparadigmsforgazebo,an 2021.
open-sourcemulti-robotsimulator,”vol.3,pp.2149–2154vol.3,2004. [53] E.Todorov,T.Erez,andY.Tassa,“Mujoco:Aphysicsengineformodel-
[33] M. Körber, J. Lange, S. Rediske, S. Steinmann, and R. Glück, “Com- basedcontrol,”pp.5026–5033,2012.
paring popular simulation environments in the scope of robotics and [54] M.L.Trang,“Multi-taskreinforcementlearning:Fromsingle-agentto
reinforcementlearning,”2021. multi-agentsystems.”Ph.D.dissertation,VirginiaTech,2023.
[34] S.LeggandM.Hutter,“Universalintelligence:Adefinitionofmachine [55] Unity, “Learning environment examples - unity,” https:
intelligence,”2007. //github.com/Unity-Technologies/ml-agents/blob/develop/docs/
[35] N.G.Lopez,Y.L.E.Nuin,E.B.Moral,L.U.S.Juan,A.S.Rueda, Learning-Environment-Examples.md,accessed:2023-12-04.
V.M.Vilches,andR.Kojcev,“gym-gazebo2,atoolkitforreinforcement [56] O. Vinyals, I. Babuschkin, W. Czarnecki, M. Mathieu, A. Dudzik,
learningusingros2andgazebo,”2019. J.Chung,D.Choi,R.Powell,T.Ewalds,P.Georgiev,J.Oh,D.Horgan,
[36] V.Makoviychuk,L.Wawrzyniak,Y.Guo,M.Lu,K.Storey,M.Macklin, M. Kroiss, I. Danihelka, A. Huang, L. Sifre, T. Cai, J. Agapiou,
D.Hoeller,N.Rudin,A.Allshire,A.Handa,andG.State,“Isaacgym: M. Jaderberg, and D. Silver, “Grandmaster level in starcraft ii using
High performance gpu-based physics simulation for robot learning,” multi-agentreinforcementlearning,”Nature,vol.575,112019.
2021. [57] T. Ward, A. Bolt, N. Hemmings, S. Carter, M. Sanchez, R. Barreira,
[37] O.Michel,“Webotstm:Professionalmobilerobotsimulation,”Interna- S. Noury, K. Anderson, J. Lemmon, J. Coe, P. Trochim, T. Handley,
tionalJournalofAdvancedRoboticSystems,vol.1,032004. andA.Bolton,“Usingunitytohelpsolveintelligence,”2020.
[38] A.P.MohammedandM.Valdenegro-Toro,“Canreinforcementlearning [58] J.Weng,M.Lin,S.Huang,B.Liu,D.Makoviichuk,V.Makoviychuk,
forcontinuouscontrolgeneralizeacrossphysicsengines?”2020. Z. Liu, Y. Song, T. Luo, Y. Jiang et al., “Envpool: A highly parallel
[39] NVIDIA. (2020) Nvidia physx. [Online]. Available: https://developer. reinforcement learning environment execution engine,” Advances in
nvidia.com/physx-sdk Neural Information Processing Systems, vol. 35, pp. 22409–22421,
[40] Open-Ended-Learning-Team, A. Stooke, A. Mahajan, C. Barros, 2022.
C.Deck,J.Bauer,J.Sygnowski,M.Trebacz,M.Jaderberg,M.Mathieu, [59] A.Young,J.Taves,A.Elmquist,S.Benatti,A.Tasora,R.Serban,and
N. McAleese, N. Bradley-Schmieg, N. Wong, N. Porcel, R. Raileanu, D.Negrut,“Enablingartificialintelligencestudiesinoff-roadmobility
S.Hughes-Fitt,V.Dalibard,andW.M.Czarnecki,“Open-endedlearning through physics-based simulation of multiagent scenarios,” Journal of
leadstogenerallycapableagents,”2021. ComputationalandNonlinearDynamics,vol.17,no.5,p.051001,2022.
[41] OpenAI, M. Andrychowicz, B. Baker, M. Chociej, R. Jozefowicz, [60] Y.Zhou,S.Manuel,P.Morales,S.Li,J.Peña,andR.Allen,“Towardsa
B. McGrew, J. Pachocki, A. Petron, M. Plappert, G. Powell, A. Ray, distributedframeworkformulti-agentreinforcementlearningresearch,”
J.Schneider,S.Sidor,J.Tobin,P.Welinder,L.Weng,andW.Zaremba, 2020IEEEHighPerformanceExtremeComputingConference(HPEC),
“Learningdexterousin-handmanipulation,”2019. pp.1–9,2020.
[42] OpenAI, C. Berner, G. Brockman, B. Chan, V. Cheung, P. De˛biak,
C.Dennison,D.Farhi,Q.Fischer,S.Hashme,C.Hesse,R.Józefowicz, VII. APPENDIX
S.Gray,C.Olsson,J.Pachocki,M.Petrov,H.P.d.O.Pinto,J.Raiman,
A. Popularity Analysis
T. Salimans, J. Schlatter, J. Schneider, S. Sidor, I. Sutskever, J. Tang,
F. Wolski, and S. Zhang, “Dota 2 with large scale deep reinforcement 1) Databaseselection:Tocarryoutthepopularityanalysis,
learning,”2019.
we chose the Semantic Scholar database, as it is com-
[43] J. Panerati, H. Zheng, S. Zhou, J. Xu, A. Prorok, and A. P. Schoel-
lig, “Learning to fly—a gym environment with pybullet physics for monly used in the field of RL and offers a free-to-use
reinforcement learning of multi-agent quadcopter control,” in 2021 API to download the meta-data of all citations [30].
IEEE/RSJ International Conference on Intelligent Robots and Systems
2) Gathering lists of citations: From the databases, we
(IROS). IEEE,2021,pp.7512–7519.
[44] J.S.Park,J.C.O’Brien,C.J.Cai,M.R.Morris,P.Liang,andM.S. downloaded the meta-data of all papers, which cited the
Bernstein,“Generativeagents:Interactivesimulacraofhumanbehavior,” original papers introducing the physics engines.
2023.
3) Selection criteria: We defined selection criteria to filter
[45] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan,
T. Killeen, Z. Lin, N. Gimelshein, L. Antiga et al., “Pytorch: An the crawled citations. We limited our search to papers
imperative style, high-performance deep learning library,” Advances in
neuralinformationprocessingsystems,vol.32,2019.published between 2016 and 2022 with a focus on queries relating to RL, embodied RL, MARL, and the
researchinthedomainofRLorMLingeneral.Forthis, names of the individual physics engines. Specifically,
we filtered the results by the keywords “Reinforcement we used the following search term for each of the
Learning”,“MachineLearning”,“ArtificialIntelligence” physics engines: "<Physics engine name>AND (’Ma-
or “Training” in either the paper title, abstract, or key- chine Learning’ OR ’ML’ OR ’Reinforcement Learn-
words. For papers that were not available on Semantic ing’ OR ’RL’ OR ’Artificial Intelligence’ OR ’AI’ OR
Scholar, we manually counted all of their ML-related ’Multi-Agent’)"
citations on Google Scholar. This limits comparability 2) Selection criteria: The relevance of the retrieved papers
to some degree, which is why manually counted papers tothisreviewwasdeterminedbythenumberofcitations,
were not included in Figure 2 where the yearly changes the topic, the publication date as well as the used
in citations are displayed. methods and perceived quality of the research.
4) Data analysis: We performed a quantitative analysis of 3) Data extraction: We reviewed the data from the selected
the extracted data and compared the results in terms of papers, including the RL algorithm used, the number of
the overall number of citations and the number of ML- agents, the evaluation metrics, and the results.
relatedcitationsbetweentheindividualphysicsengines. 4) Dataanalysis:Weperformedananalysisoftheextracted
data, including thematic review. Based on these results,
B. Feature Analysis
we conducted a comparative analysis to identify the
1) Review selection: We searched for existing reviews and
strengths and weaknesses of each physics engine.
papers related to the topic of our study. We used search