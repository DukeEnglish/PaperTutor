Open (Clinical) LLMs are Sensitive to Instruction Phrasings
AlbertoMarioCeballosArroyo*γ MonicaMunnangi*γ JiudingSunγ
KarenY.C.Zhangγ DenisJeredMcInerneyγ♢ ByronC.Wallaceγ SilvioAmirγ
γNortheasternUniversity ♢Codametrix
{ceballosarroyo.a, munnangi.m, sun.jiu, zhang.yuchen, b.wallace,s.amir}@northeastern.edu
jmcinerney@codametrix.com
Abstract
Instruction-tuned Large Language Models
(LLMs) can perform a wide range of tasks
given natural language instructions to do so,
buttheyaresensitivetohowsuchinstructions
arephrased. Thisissueisespeciallyconcern-
inginhealthcare,ascliniciansareunlikelyto
be experienced prompt engineers and the po-
tentialconsequencesofinaccurateoutputsare
heightenedinthisdomain.
Figure1:HowmuchdoesLLMperformanceonclinical
Thisraisesapracticalquestion:Howrobustare
tasksdependonthearbitraryphrasingsofinstructions?
instruction-tunedLLMstonaturalvariations
Hereweshowanillustrativeexample: Discrepancyin
in the instructions provided for clinical NLP
AUROC score for CLINICAL CAMEL on the cohort
tasks? Wecollectpromptsfrommedicaldoc-
selection-alcoholabuseclassificationtask,whengiven
torsacrossarangeoftasksandquantifythesen-
theworst(A)andthebest(B)performingpromptsfor
sitivityofsevenLLMs—somegeneral,others
ALCOHOL-ABUSEclassificationtask.
specialized—tonatural(i.e.,non-adversarial)
instructionphrasings.Wefindthatperformance
variessubstantiallyacrossallmodels,andthat—
scientificliterature(Agrawaletal.,2022;Wadhwa
perhapssurprisingly—domain-specificmodels
etal.,2023b;AsadaandFukuda,2024).
explicitlytrainedonclinicaldataareespecially
However, prior work has shown that LLMs do
brittle,comparedtotheirgeneraldomaincoun-
not “understand” prompts (Webson and Pavlick,
terparts. Further,arbitraryphrasingdifferences
can affect fairness, e.g., valid but distinct in- 2022)andaresensitivetotheparticularphrasings
structionsformortalitypredictionyieldarange of instructions (Lu et al., 2022; Sun et al., 2023).
both in overall performance, and in terms of Domain experts in specialized domains such as
differencesbetweendemographicgroups.
medicineareespeciallylikelytointeractwithmod-
1 Introduction elsbyprovidinginstructions(i.e.,inzero-shotset-
tings),andareunlikelytobetalentedpromptengi-
Modern LLMs—e.g. GPT-3.5+ (Radford et al.,
neers. Forinstance,aclinicianmighttaskamodel
2019; Ouyang et al., 2022), the FLAN series
to“Extractandsummarizethefindingsofthepa-
(Chung et al., 2022), Alpaca (Taori et al., 2023),
tient’s last X-ray”, or ask “When did the patient
Mistral(Jiangetal.,2023)—canexecutearbitrary
lastreceiveapainkiller?”. Itisunrealistictofine-
tasks zero-shot, i.e., provided with only instruc-
tunemodelsforeverypossiblesuchtask;hencethe
tionsratherthanexplicittrainingexamples. LLMs
appealofmodelsresponsivetoarbitraryprompts.
havealsoshownpromisingimprovementsinper-
A downside, however, is that a clinician’s partic-
formanceonclassificationandinformationextrac-
ular phrasing may dramatically affect model per-
tion (IE) tasks, such as named entity recognition
formance(Figure1). Suchunpredictabilityisespe-
(Brown et al., 2020; Munnangi et al., 2024) and
ciallytroublesomeinhealthcare, wherepoorper-
relationextraction(Wadhwaetal.,2023a;Ashok
formancemightultimatelyimpactpatienthealth.
andLipton,2023;Jiangetal.,2024)inbothgen-
Inthisworkweask: HowsensitiveareLLMs—
eralandspecializeddomainslikebiomedicaland
general and domain-specific—to plausible in-
*Equalcontribution structionphrasingvariationsforclinicaltasks?
4202
luJ
21
]LC.sc[
1v92490.7042:viXraClassification Extraction
Mistral (7b)
Llama-2 (13b)
Llama-2 (7b)
Alpaca (7b) General models
Clinical models
Clin-Camel (13b)
Asclepius (7b)
MedAlpaca (7b)
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
AAUURROOCC FF11
Figure2: Varianceinperformanceforclinicalclassificationandinformationextractiontasksforeachmodel. We
showthedistributionofdeltasbetweenthebestandworstperformingpromptforeachtask.
Ouranalysisdeepenspriorworkonrobustnessby a significant disparity between Male and Female
focusingontheclinicaldomain;thisisimportant patients(upto0.19absolutedifferenceinAUROC).
bothduetothehigherstakesandbecauseclinical To facilitate future research in this direction, we
notesdifferqualitativelyfromgeneraldomaintext. releaseourcodeandprompts1.
Forexample,notesinEHRoftencontaingrammat-
2 ExperimentalFramework
ical errors (“Pt complains of headache, and feel
dizzy.”);abbreviationsnotdefinedincontext(“Pt”
Ourexperimentalsetupisintendedtoquantifythe
could be “patient” or “Prothrombin time”), and;
robustnessofLLMstonaturalvariationsininstruc-
domain-specificjargon(“edema”,“Diuretic”).
tionalphrasingsforclinicaltasks. Weconsidereda
Therefore, one of the key aspects we consider set of ten clinical classification tasks and six in-
is the domain-specificity of models. Are clinical formation extraction tasks drawn from MIMIC-
LLMs more (or less) robust to different valid in- III(Johnsonetal.,2016)andpriori2b2andn2c2
structionphrasingswrittenbydoctors,compared challenges,2 summarized in Table 1 (§2.1). We
to their general domain counterparts? To assess recruitedadiversegroupofmedicalprofessionals
this, we evaluate recently released LLM variants to write prompts for each task (§2.2). We then
trainedonsyntheticdatasetscomprisingautomati- evaluatedtheperformance,variance,andfairness
callygeneratedclinicalnotes(Kweonetal.,2023), of seven LLMs (four general-domain and three
and medical dialogue from case reports found in domain-specific)acrossprompts(§2.3).
biomedicalliterature (Tomaetal.,2023). Wefind
2.1 TasksandDatasets
that performance varies substantially given alter-
native instruction phrasings for both general and MIMIC-III(Johnsonetal.,2016) isadatabase
clinical LLMs. Figure 2 shows the distribution ofde-identifiedEHRcomprisingover40kpatients
of deltas between the best and worst performing admitted to the intensive care unit of the Beth Is-
promptsacrossasetofclinicalclassificationand raelDeaconessMedicalCenterbetween2001and
informationextractiontasks. 2012. Itcomprisesstructuredvariablesandclinical
Finally, we investigate how instruction phras- notes(e.g.,doctorandnursingnotes,radiologyre-
ings impact the fairness of predictions, by which ports,dischargesummaries);wefocusonthelatter.
herewemeanobserveddifferencesinperformance MIMIC-IIIalsocontainsdemographicinformation,
between demographic subgroups. The degree to includingethnicity/race,sex,spokenlanguage,re-
whichLLMsmightperpetuateandexaggeratesuch ligion, and insurance status (Chen et al., 2019).
disparities in clinical use is a topic of active re- As an illustrative predictive task, we consider in-
search(Omiyeetal.,2023;Paletal.,2023;Zack hospitalmortalityprediction,whichhasbeenthe
etal.,2024). Herewecontributetothisbyinves- subject of prior work (Harutyunyan et al., 2017).
tigatingtheinteractionbetweenpromptphrasings Owingtocomputeconstraints,wesub-sampledthe
andfairness. Wefindsignificantperformancedif- test-splitto10%ofthedata(preservingclassratio),
ferences(upto0.35absolutedifferenceinAUROC) yielding160recordsforevaluation.
inamortalitypredictiontaskfromMIMIC-IIIbe- 1https://github.com/alceballosa/clin-robust
tween White and Non-White subgroups and also 2https://n2c2.dbmi.hms.harvard.edu/Dataset TASK TESTSET TASKTYPE
MIMIC-III In-hospitalMortality 160 BinaryClassification
Asthma 507 BinaryClassification
CAD 507 BinaryClassification
Obesityco-morbidity
Diabetes 507 BinaryClassification
Obesity 507 BinaryClassification
Abdominal 86 BinaryClassification
CohortSelection Alcohol-Abuse 86 BinaryClassification
Drug-Abuse 86 BinaryClassification
English 86 BinaryClassification
Decisions 86 BinaryClassification
MedicalChallenge Medication 251 Extraction
ConceptProblem 256 Extraction
ConceptTest 256 Extraction
RelationChallenge
ConceptTreatment 256 Extraction
AdverseDrugEffects Drug 202 Extraction
RiskAssessment RiskFactorCAD 514 Extraction
Table1: Tasksanddatasetsusedforevaluation.
n2c22018CohortSelectionChallenge(Stubbs adverseeventsforthepatient. Thedatasetcontains
and Uzuner, 2019) aims to identify whether a 202patientsandwefocusonlyonthenamedentity
patient meets the criteria for inclusion in a clini- recognition portion of the task (i.e. recognizing
cal trial based on their longitudinal records. The spansreferringtodrugs/medications).
datasetcontains288patients,theirassociatedclin-
i2b2 2014 Identifying Risk Factors for Heart
ical notes and a set of binary labels indicating
DiseaseoverTime(Stubbsetal.,2015): entails
whethertheymeetthecriteriaforeachof13possi-
identifyingmedicalriskfactorslinkedtoCoronary
blecohorts(e.g.,drugabuse,alcoholabuse,ability
ArteryDisease(CAD)intheEHRofpatientswith
tomakedecisions,amongothers). Inthisstudy,we
diabetes. Thetargetfactorsincludehypertension,
focusonthe5cohortsshowninTable1andtreat
obesity,smokingstatus,diabetes,hyperlipidemia,
each as an independent binary classification task
familyhistory,andCADitself. Hereweconsider
aimingtopredictwhetherthecriteriais“met”or
onlythelatter.
“notmet”.
i2b2 2010 Relations Challenge (Uzuner et al.,
i2b2 2008 Obesity Challenge (Uzuner, 2009)
2011) consistsofthreerelatedtasks: (1)identifi-
entailsidentifyingpatientssufferingfromobesity
cationofmedicalproblems,tests,andtreatments;
and its co-morbidities from their discharge sum-
(2) classification of assertions made on medical
mary notes. The dataset comprises 1027 pairs of
problems; and (3) relation extraction concerning
de-identifieddischargesummariesand16disease
medicalproblems,tests,andtreatments. Thedata
labelsfromintuitivejudgementswhicharebased
for this challenge includes discharge summaries
on the entire discharge summary. We report the
fromPartnersHealthCare,andtheBethIsraelDea-
performanceforobesityandthreeco-morbidities
conessMedicalCenter(Leeetal.,2011),aswell
(i.e.,asthma,atheroscleroticcardiovasculardisease
as discharge summaries and progress notes from
(CAD),anddiabetesmellitus(DM)),eachframed
the University of Pittsburgh Medical Center. We
as a binary classification task aiming to predict
conductevaluationonthefirsttask(i.e. extraction
whethertheconditionis“present”or“absent”.
ofproblems,tests,andtreatments)overthenotes
of256patients.
n2c2 2018 Adverse Drug Events and Medica-
tion Extraction in EHRs (Henry et al., 2020) i2b2 2009 Medication Extraction Challenge
consists of a relation extraction task focused on (Patrick and Li, 2010) focuses on the extrac-
identifyingdrugs/medicationsandtheirrelationsto tionofmedicationsfromclinicalnotesintheEHR,as well as their modes, reasons and frequency of medical professionals. To assess the impact of
administration. We center our analysis on medi- clinical instruction tuning, we paired all clinical
cationextractiononly,whichencompassesaround models with their general domain counterparts.
1250uniquemedicationsover251notes. Weconsideredthreeclinicalmodels: ASCLEPIUS
(7B) (Kweon et al., 2023), CLINICAL CAMEL
2.2 InstructionCollection
(13B) (Toma et al., 2023), and MEDALPACA
We hired twenty medical professionals from dif- (7B) (Han et al., 2023); and their corresponding
ferentprofessionalanddemographicbackgrounds, basemodels,i.e.,LLAMA 2 CHAT (7B),LLAMA 2
withvaryingmedicalspecialtiesandyearsofexpe- CHAT (13B)(Touvronetal.,2023),andALPACA
rience. Theseincludedmedicaldoctors(physicians, (7B)(Taorietal.,2023),respectively. Wealsoin-
surgeons), medical writers/editors, nurses, and cluded MISTRAL IT 0.2 (7B) (Jiangetal.,2023)
medicalconsultantsfromvariouscountries,suchas inourexperimentsduetoitshighperformancein
theUnitedStates,Nigeria,Kenya,Canada,Zambia, standardbenchmarks.
Egypt,Malawi,Pakistan,Philippines,andEthiopia. Forallmodelsanddatasets,weperformedzero-
Allparticipantswereeithernative-speakersorpro- shot inference via prompts with a maximum se-
ficientinEnglish. Itshouldalsobenotedthatpar- quencelengthof2048tokenswhichincludedthe
ticipantswerenotrequiredtohaveexperiencewith instruction, the input note, and the output tokens
LLMs but the majority of them reported having (64 for classification, 256 for extraction). Since
usedthesemodelsinthepast. most clinical notes were too long to process in a
We provided participants with a description of single pass, we followed Huang et al. 2020 and
thetasksincludingthegoal,theexpectedoutputs split each note into chunks to be processed inde-
and a (fictitious) example of a clinical note. We pendently. Forbinaryclassificationandprediction
thenaskedthemtowriteinstructions(inEnglish) tasks,wetreatedtheoutputforagiveninputnote
for each task with the only constraint being that as positive if at least one of the chunks was pre-
theyhadtoensurethemodeloutputsavalidlabel dictedtobepositive,andnegativeotherwise. For
(for classification tasks) or a list of items (for ex- extraction tasks, we combined the outputs from
tractiontasks). Figure9(AppendixA.1)showsan eachchunkintoasinglesetofextractions.
example of the instructions given for a classifica-
Evaluation: Evaluationwithgenerativemodels
tiontask.
is challenging: Models may not respect the de-
Initially,weranasmallerscalepilotstudycon-
siredoutputformat,ormaygenerateresponsesthat
sistingofoneclassificationandoneextractiontask,
aresemanticallyequivalentbutlexicallydifferent
and recruited participants who successfully com-
from references (Wadhwa et al., 2023b; Agrawal
pletedthetasks. Theprocesstookaround5hours
et al., 2022). We therefore took predictions from
onaverageandwecompensatedeachparticipant
theoutputdistributionofthefirstgeneratedtoken
at a rate of $25/hour. We manually reviewed all
by selecting the largest magnitude logit from the
written instructions and found that some were of
set of target class tokens. For extraction tasks,
poor quality (e.g., did not adhere to the goals of
we parsed generated outputs and performed ex-
thetask,ordidnotensurethatthemodeloutputs
act match comparison with target spans. We re-
valid responses). In such cases, we removed the
portAUROCscoresforclassificationtasksandF1
author from the study and discarded all of their
scoresforextractiontasks.
instructions. We also removed everyone that did
notcompleteallthetasks,resultinginafinalcol-
3 Results
lection of instructions from 12 participants. See
AppendixA.1forillustrativeexamplesofthecol- WepresentourmainresultsforMortalityPredic-
lectedinstructions3. tionandDrugExtractioninFigure3—resultsfor
theotherclassificationandinformationextraction
2.3 Models
tasks can be found in Appendix A.2, Figures 12
We measured the performance, variance and fair- and 13, respectively. Most models show signifi-
nessofsevengeneralanddomain-specificLLMs cantvariabilityinperformanceforalternativebut
on each task, using the instructions written by semanticallyequivalentinstructionsinbothclassi-
fication and extraction tasks. To further examine
3Thefullsetofinstructionsisavailableinourcodereposi-
tory these observed disparities, we plotted the distri-MIMIC Mortality Prediction Drug Extraction
Mistral (7b)
Llama-2 (13b)
Llama-2 (7b)
Alpaca (7b) General models
Clin-Camel (13b) Clinical models
Asclepius (7b)
MedAlpaca (7b)
0 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0 0.2 0.4 0.6 0.8
AUROC F1
Figure3: Variabilityinperformanceacrosspromptsforthemortalitypredictionanddrugextractiontasks. Formost
models,differentbutsemanticallyequivalentpromptsyieldquitearangeofperformance.
bution of deltas between the best and worst per- andextractiontasks,respectively. Surprisingly,we
formingpromptsforeachtaskinFigure2. Wesee findthatgeneraldomainmodelsoutperformtheir
thatperformancedeltascangoupto0.6absolute domain-specific counterparts — with the excep-
AUROC points for classification tasks and up to tionof ALPACA whichperformspoorlyacrossall
0.4absoluteF1pointsforextractiontasks. tasks. Again we observe that even though CLIN-
In the Mortality Prediction task, we find that ICAL CAMEL canoutperformitsgeneraldomain
LLAMA 2 (13B) outperformsallothermodels,in- analoginextractiontasksgiventhebestprompt,it
cludingthedomain-specificones(Figure3). How- alsoshowsmorevarianceandmuchlowerperfor-
ever, for the other classification tasks, MISTRAL manceintheworstcase.
yields the best results often outperforming the Finally, we investigated whether the observed
largermodelswhilstexhibitinglessvariance(Fig- performancevariabilitycanbeexplainedbyindi-
ure12). Regardingtheclinicalmodels,weobserve vidual differences between experts in prior expe-
that ASCLEPIUS consistentlyattainsthebestper- riencewithLLMsoraptitudeinwritingeffective
formanceinclassificationtasksalbeitwithcompa- instructions. Toassessthis,wemeasuredtheperfor-
rablevariance. mancedeltasbetweeneachpromptandthemedian
IntheDrugExtractiontask,LLAMA 2 (7B) at- promptforeachclassificationandextractiontask.
tains the best results on average but with compa- Figure6showstheresultsforLLAMA 2 (7B)and
rable variance to other general LLMs. However, resultsforothermodelscanbefoundinAppendix
the results for clinical models are mixed: while A.2, figures 14 and 15. We find that there are in-
CLINICAL CAMELcanachievethehighestperfor- deedsignificantdifferencesattheindividuallevel,
mancegiventhebestprompt,italsohasthehighest bothintermsofvarianceandoverallperformance,
varianceandlowestmedianperformance. MEDAL- particularlyforclassificationtasks. Onlyroughly
PACA comes close to CLINICAL CAMEL in the halftheuserscan(somewhat)consistentlybeatthe
bestcasescenariobutwithlessvarianceandbetter median performance across tasks. We also note
median performance. ASCLEPIUS has a median these differences can not be solely explained by
performance similar to that of MEDALPACA but priorexperiencewithLLMs—somenoviceusers
with a much lower variance. We observe similar are able to consistently write more effective in-
trends for the other information extraction tasks: structionsascomparedtootherexperiencedusers.
LLAMA 2 (7B)consistentlyoutperformsothergen- However,onecaveatisthatthispriorexperienceis
eralLLMswithsimilarvariance,whereasnoneof mostlikelywithlargercommercialmodelswhich
theclinicalmodelsisclearlysuperioracrosstasks maybemorerobusttoinstructionvariations.
— however, ASCLEPIUS seems to have the least
3.1 Fairness
varianceoverall.
Tobetterunderstandthedifferencesbetweenthe How do variations in prompt phrasings impact
generaldomainandclinicalLLMs,wecompared model fairness (here measured as disparities in
theiraverageperformancegiventhebest,median predictive performance for specific demographic
and worst prompts. Figures 4 and 5 show the re- subgroups)? Toanswerthisquestion,westratified
sults per model averaged across all classification the patients in the mortality prediction task withGeneral models Clinical models
1.0
Prompt
Best
0.8 Median
Worst
0.6
0.4
0.2
0.0
Mistral (7b L) lama-2 (13b L) lama-2 (7b) Alpaca (7b) Clin-Camel (1 A3 sb c) lepius (7 Mb e) dAlpaca (7b)
Figure4: AverageAUROCacrossclassificationtasksgiventhebest,median,andworst-performingpromptsfor
eachmodel.
General models Clinical models
0.5
Prompt
Best
0.4 Median
Worst
0.3
0.2
0.1
0.0
Mistral (7b L) lama-2 (13b L) lama-2 (7b) Alpaca (7b) Clin-Camel (1 A3 sb c) lepius (7 Mb e) dAlpaca (7b)
Figure5: AverageF1acrossextractiontasksgiventhebest,median,andworst-performingpromptsforeachmodel.
Gender Total fornon-WhitepatientscomparedtoWhitecounter-
Female Male parts with absolute differences of up to 0.21 and
0.35AUROCpoints,respectively. Apossibleex-
Race White 52 59 111
planation is that the way in which medical staff
Non-White 24 25 49
write clinical notes differ for White vs Black pa-
Total 76 84 160
tients (Adam et al., 2022). However, here non-
Whites are an heterogeneous group so there may
Table2: Distributionofgenderandraceinthesample
usedexaminemodelfairness(§3.1) beotherconfoundingfactors.
respecttoraceandsex. Toavoidissueswithreli-
abilityofperformancemetricsarisingfromsmall In regards to sex, we again observe noticeable
sub-samples(Amiretal.,2021)weonlyconsider (albeit smaller) differences in performance with
twobroadgroups(i.e.,WhiteandNon-White). We LLAMA 2 (7B) performingworseforFemalepa-
sorted the instructions according to their overall tients across all the prompts with relative differ-
performanceandplotindividualsubgroupperfor- encesof upto 0.16absoluteAUROC points, and
mance (Figure 7). We repeated the analysis for ASCLEPIUS(7B)yieldingdifferencesofupto0.19
sex (as indicated in EHR) and present individual points. Overall,theseresultsindicatethatnatural
subgroupperformanceinFigure8. variationsinpromptsmaytranslatetowidediffer-
Inlinewithpriorwork(Amiretal.,2021;Adam ences in fairness. Troublingly, a clinician using
etal.,2022),weobservethatmodelshavedisparate such models would likely be unaware that appar-
performancefordifferentsubgroups. BothLLAMA entlybenignphrasingchangesmaydisproportion-
2(7B)andASCLEPIUS(7B)tendtounder-perform atelyaffectparticulardemographicgroups.
CORUA
1FLlama 2 (7b) on Classification Llama 2 (7b) on Extraction
Familiar with LLMs
Yes
No
0.6 0.4 0.2 0.0 0.2 0.3 0.2 0.1 0.0 0.1 0.2 0.3
AAUURROOCC FF11
Figure6: Distributionofperformancedeltasbetweeneachexpert’spromptandthemedianpromptacrossalltasks.
EachviolinplotrepresentsanexpertcolorcodedaccordingtotheirfamiliaritywithLLMs.
Llama-2 (7b) on Mortality Prediction Llama-2 (7b) on Mortality Prediction
1.0 White 1.0 Male
Non-White Female
0.8 0.8
0.6 0.6
0.4 0.4
12 11 10 9 8 7 6 5 4 3 2 1 12 11 10 9 8 7 6 5 4 3 2 1
Rank Rank
Asclepius (7b) on Mortality Prediction Asclepius (7b) on Mortality Prediction
1.0 1.0
0.8 0.8
0.6 0.6
0.4 0.4
12 11 10 9 8 7 6 5 4 3 2 1 12 11 10 9 8 7 6 5 4 3 2 1
Rank Rank
Figure7: RacesubgroupperformanceontheMortality Figure 8: Gender subgroup performance on the Mor-
Predictiontaskwithageneral(top)andclinicalmodel talityPredictiontaskwithageneral(top)andclinical
(bottom) model(bottom)
marization (Veen et al., 2023). This may be due
3.2 Discussion
tothefactthatclinicalmodelsarefine-tunedwith
synthetic or proxy data that does not adequately
Ourexperimentsshowthatinstruction-tunedLLMs
capture the idiosyncrasies of clinical notes from
arenotrobusttoplausiblevariationsininstruction
EHR.
phrasings — equivalent but distinct instructions
resultinsignificantdifferencesinbothtaskperfor-
4 RelatedWork
mance and fairness with respect to demographic
subgroups. Moreover,wefindthatnosinglemodel Instruction-following LLMs Scaling up
yieldsoptimalperformanceacrosstasks,e.g. Mis- decoder-only language models imbues them
tral7bisthebestmodelforclassificationbuthas with the ability to solve various tasks given only
middlingperformanceinextractiontasks. Wealso instructionsorasmallsetofexamplesatinference
findthatgeneraldomainmodelstendtooutperform time (Brown et al., 2020; Chowdhery et al.,
clinicalmodels—althoughsurprising,thesefind- 2022). Follow-upworksoughttoimprovethisby
ings corroborate prior work on clinical text sum- explicitly training GPT-3 to follow instructions
CORUA
CORUA
trepxE
CORUA
CORUAand provide helpful and harmless responses via 2023;Excoffieretal.,2024)—ourexperimental
Reinforcement Learning from Human Feed- resultsconfirmtheseobservations.
back(Ouyangetal.,2022;OpenAI,2022). Others
InacontemporaneousstudyChangetal.(2024)
showed that fine-tuning with a causal language
convened a panel of 80 multidisciplinary experts
modeling objective over labeled data formatted
toredteamChatGPTmodelsfortheappropriate-
as instruction/response pairs is sufficient to
nessoftheresponsesinmedicalusecases. Experts
endoweven(comparatively)smallermodelswith
wereaskedtowrite(non-adversarial)promptsfor
instruction-following abilities (Sanh et al., 2021;
clinicallyrelevantscenariosandtheresponseswere
Wei et al., 2021). This motivated extensive work
judged by medical doctors with respect to safety,
on compiling large instruction-tuning datasets,
privacy,hallucinations,andbias. Thisworkiscom-
such as the Flan 2021 (Chung et al., 2022) and
plementary to ours in that it aims to stress test
Super-NaturalInstructionscollections(Wangetal.,
modelsfortheappropriatenessoftheirresponses
2022), each encompassing over 1600 NLP tasks,
tohealthcarerelatedpromptswhereaswefocuson
and OPT-IML collection with 2000 tasks (Iyer
theirsensitivitytopromptvariations.
etal.,2022).
LLM Prompt Sensitivity However, LLMs are
sensitive to how prompts are constructed (Tju-
5 Conclusions
atja et al., 2023; Raj et al., 2023). In few-shot
learning,factorssuchasthepromptformat(Sclar
et al., 2023; Chakraborty et al., 2023), as well This paper presents a large-scale evaluation of
as the choice (Gutiérrez et al., 2022) and order- instruction-tuned open-source LLMs for clinical
ing (Lu et al., 2022; Pezeshkpour and Hruschka, classificationandinformationextractiontaskson
2023) of exemplars have a significant impact on clinicalnotes(fromEHR).Wespecificallyfocuson
task performance. In zero-shot settings, Webson modelrobustnesstonaturaldifferencesinprompts
andPavlick(2022)foundthatmodelsoftenrealize written by medical professionals. We recruited
similarperformancewithmisleadingorirrelevant 12practitionerswithdifferentprofessionalandde-
promptsaswithcorrectones. Elsewhere,Sunetal. mographicbackgrounds,medicalspecialties,and
(2023) showed that general domain instruction- yearsof experience towrite prompts for16 clini-
tunedLLMsarenotrobusttovariationsininstruc- cal tasks spanning binary classification, outcome
tions — specifically, they found that models un- prediction,andinformationextraction.
derperformwhengivennovelinstructionsunseen
There are a few main generalizable takeaways
in training. Our work contributes to this line of
relevant to machine learning in healthcare in this
researchbyfocusingontheclinicaldomain.
work. First, the performance LLMs realize on
LLMsforClinicalTasks GeneraldomainLLMs the same clinical task varies substantially across
encodeasurprisingamountofclinicalandbiomed- promptswrittenbydifferentdomainexperts,and
icalknowledgeallowingthemtosolvevariouspre- thisholdsacrossallmodels. Second,thedomain-
diction and information extraction tasks via nat- specific(clinical)modelsweevaluatedperform,in
ural language instructions (Singhal et al., 2023; general,worsethantheirgeneraldomaincounter-
Agrawaletal.,2022;Munnangietal.,2024). How- parts. Third, prompt variations have concerning
ever, smaller models fine-tuned on task-specific implicationsforfairness—wefindthatalternative
data can outperform generalist LLMs in clinical promptsyielddifferentlevelsoffairness. Basedon
tasks (Lehman et al., 2023). At the same time, thesefindings,werecommendthatpractitionersex-
thereisadearthoflargehigh-qualityclinicaltext ercisecautionwhenusinginstruction-tunedLLMs
datasets to train LLMs due to privacy considera- forhighstakesclinicaltaskswhichmayultimately
tions. Researchershavetriedtoovercomethisby impact patient health. Crucially, clinicians using
exploitingsyntheticdatageneratedfrombiomedi- LLMsshouldbemadeawarethatsubtle,plausible
calandclinicalliteratureandquestionanswering variations in phrasings may yield quite different
datasets to train domain-specific models (Toma outputs. Beyond healthcare, this work enriches
etal.,2023;Kweonetal.,2023;Hanetal.,2023). ourunderstandingof(thelackof)LLMrobustness
However, the resulting models are often outper- and—we hope—will motivate research into new
formed by general domain variants (Veen et al., methodstoimprovemodelsinthisrespect.6 Limitations YoonKim,andDavidSontag.2022. Largelanguage
modelsarefew-shotclinicalinformationextractors.
Our study reveals that open-source instruction- Preprint,arXiv:2205.12689.
tunedLLMsaresensitivetoinstructionphrasings
SilvioAmir,Jan-WillemvandeMeent,andByronC.
andsuggestscautioninadoptingthesemodelsfor
Wallace. 2021. On the impact of random seeds
applicationsthatmayimpactpersonalhealthand
on the fairness of clinical classifiers. Preprint,
well-being. However,thisworkhasseverallimita- arXiv:2104.06338.
tions. First,weacknowledgethatourfindingsmay
Masaki Asada and Ken Fukuda. 2024. Enhancing
not generalize to larger commercial models but
relation extraction from biomedical texts by large
costandprivacyconsiderationsmayprecludethe language models. In International Conference on
deployment of proprietary models for real-world Human-ComputerInteraction,pages3–14.Springer.
healthcare applications. Second, we endeavored
Dhananjay Ashok and Zachary C. Lipton. 2023.
to recruit a diverse group of medical profession-
Promptner: Promptingfornamedentityrecognition.
als but our final pool of participants may not be Preprint,arXiv:2305.15444.
a representative sample of the potential users of
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
these technologies. Moreover, participants were
Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind
notallowedtoseetheresultsoftheirinstructions
Neelakantan,PranavShyam,GirishSastry,Amanda
butintherealworlduserswouldhavetheopportu- Askell,etal.2020. Languagemodelsarefew-shot
nitytoexperimentwithdifferentpromptsandlearn learners. Advancesinneuralinformationprocessing
systems,33:1877–1901.
how to best use these models. Third, our evalua-
tionprotocolforclassificationtasksmaynotreflect MohnaChakraborty,AdithyaKulkarni,andQiLi.2023.
realworldusage—weinducedmodelpredictions Zero-shotApproachtoOvercomePerturbationSensi-
from the logit distribution of the first generated tivityofPrompts. InProceedingsofthe61stAnnual
Meeting of the Association for Computational Lin-
token. However, in practice users can only see
guistics(Volume1: LongPapers),pages5698–5711,
the final generated outputs and must be able to
Toronto,Canada.AssociationforComputationalLin-
parseandinterprettheseinthecontextofthetask guistics.
at hand. Finally, our analysis showed that varia-
Crystal T. Chang, Hodan Farah, Haiwen Gui,
tionsininstructionshaveimplicationsforfairness
Shawheen Justin Rezaei, Charbel Bou-Khalil, Ye-
withrespecttoraceandgender. However,wedid Jean Park, Akshay Swaminathan, Jesutofunmi A.
notexaminetheimpactofthesedisparitiesonin- Omiye, Akaash Kolluri, Akash Chaurasia, Ale-
jandro Lozano, Alice Heiman, Allison Sihan Jia,
tersectionalidentitieswhichareoftenaffectedby
Amit Kaushal, Angela Jia, Angelica Iacovelli,
compoundedbiases.
ArcherYang,ArghavanSalles,ArpitaSinghal,Bal-
asubramanian Narasimhan, Benjamin Belai, Ben-
Acknowledgments
jamin H. Jacobson, Binglan Li, Celeste H. Poe,
ChandanSanghera,ChenmingZheng,ConorMesser,
This work was supported in part by National
Damien Varid Kettud, Deven Pandya, Dhaman-
Science Foundation (NSF) award 1901117, and preet Kaur, Diana Hla, Diba Dindoust, Dominik
by the National Insitutes of Health (NIH) award Moehrle, Duncan Ross, Ellaine Chou, Eric Lin,
Fateme Nateghi Haredasht, Ge Cheng, Irena Gao,
R01LM013772.
JacobChang,JakeSilberg,JasonA.Fries,Jiapeng
Wealsothankthereviewers,fortheirvaluable
Xu, Joe Jamison, John S. Tamaresis, Jonathan H
feedbackandcommentsthathelpedimprovethis Chen, JoshuaLazaro, JuanM.Banda, JulieJ.Lee,
work. KarenEbertMatthys,KirstenR.Steffner,LuTian,
LucaPegolotti,MalathiSrinivasan,ManiragavMan-
imaran, Matthew Schwede, Minghe Zhang, Minh
References Nguyen,MohsenFathzadeh,QianZhao,RikaBajra,
RohitKhurana,RuhanaAzam,RushBartlett,SangT.
HammaadAdam,MingYingYang,KenrickCato,Ioana Truong,ScottL.Fleming,ShritiRaj,SolveigBehr,
Baldini,CharlesSenteio,LeoAnthonyCeli,Jiaming SoniaOnyeka,SriMuppidi,TarekBandali,TiffanyY.
Zeng, Moninder Singh, and Marzyeh Ghassemi. Eulalio,WenyuanChen,XuanyuZhou,YananDing,
2022. Write it like you see it: Detectable differ- Ying Cui, Yuqi Tan, Yutong Liu, Nigam H. Shah,
ences in clinical notes by race lead to differential and Roxana Daneshjou. 2024. Red teaming large
modelrecommendations. InProceedingsofthe2022 languagemodelsinmedicine: Real-worldinsights
AAAI/ACM Conference on AI, Ethics, and Society, onmodelbehavior. medRxiv.
AIES’22.ACM.
IreneY.Chen,PeterSzolovits,andMarzyehGhassemi.
Monica Agrawal, Stefan Hegselmann, Hunter Lang, 2019. CanAIHelpReduceDisparitiesinGeneralMedicalandMentalHealthCare? AMAjournalof Thibaut Lavril, Thomas Wang, Timothée Lacroix,
ethics,212:E167–179. andWilliamElSayed.2023. Mistral7b. Preprint,
arXiv:2310.06825.
AakankshaChowdhery,SharanNarang,JacobDevlin,
Maarten Bosma, Gaurav Mishra, Adam Roberts, GuochaoJiang,ZiqinLuo,YuchenShi,DixuanWang,
Paul Barham, Hyung Won Chung, Charles Sutton, JiaqingLiang,andDeqingYang.2024. Toner: Type-
Sebastian Gehrmann, et al. 2022. PaLM: Scaling oriented named entity recognition with generative
language modeling with pathways. arXiv preprint languagemodel. In Proceedingsofthe2024Joint
arXiv:2204.02311. InternationalConferenceonComputationalLinguis-
tics, Language Resources and Evaluation (LREC-
Hyung Won Chung, Le Hou, Shayne Longpre, Bar- COLING2024),pages16251–16262.
ret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi
Wang,MostafaDehghani,SiddharthaBrahma,etal. Alistair E. W. Johnson, Tom J. Pollard, Lu Shen,
2022. Scalinginstruction-finetunedlanguagemodels. Li wei H. Lehman, Mengling Feng, Moham-
arXivpreprintarXiv:2210.11416. mad Mahdi Ghassemi, Benjamin Moody, Peter
Szolovits, Leo Anthony Celi, and Roger G. Mark.
Jean-BaptisteExcoffier,TomRoehr,AlexeiFigueroa, 2016. Mimic-iii, a freely accessible critical care
Jens-Michalis Papaioannou, Keno Bressem, and database. ScientificData,3.
MatthieuOrtala.2024. Generalistembeddingmod-
Sunjun Kweon, Junu Kim, Jiyoun Kim, Sujeong Im,
els are better at short-context clinical semantic
EunbyeolCho,SeongsuBae,JungwooOh,Gyubok
searchthanspecializedembeddingmodels. Preprint,
Lee, Jong Hak Moon, Seng Chan You, et al. 2023.
arxiv:2401.01943.
Publicly shareable clinical large language model
Bernal Jiménez Gutiérrez, Nikolas McNeal, Clayton built on synthetic clinical notes. arXiv preprint
Washington, You Chen, Lang Li, Huan Sun, and arXiv:2309.00237.
Yu Su. 2022. Thinking about GPT-3 In-Context
JoonLee,DanielJ.Scott,MauricioVillarroel,GariD.
LearningforBiomedicalIE?ThinkAgain. InFind-
Clifford, Mohammed Saeed, and Roger G. Mark.
ingsoftheAssociationforComputationalLinguistics:
2011. Open-accessmimic-iidatabaseforintensive
EMNLP2022,pages4497–4512.
care research. In 2011 Annual International Con-
Tianyu Han, Lisa C Adams, Jens-Michalis Papaioan- ference of the IEEE Engineering in Medicine and
nou,PaulGrundmann,TomOberhauser,Alexander BiologySociety,pages8315–8318.
Löser, Daniel Truhn, and Keno K Bressem. 2023.
Eric Lehman, Evan Hernandez, Diwakar Mahajan,
MedAlpaca–AnOpen-SourceCollectionofMedical
JonasWulff,PeterSzolovits,AlistairJohnson,Emily
ConversationalAIModelsandTrainingData. arXiv
Alsentzer,AlistairJohnson,etal.2023. Dowestill
preprintarXiv:2304.08247.
need clinical language models? In Conference on
Health, Inference, and Learning, pages 578–597.
HrayrHarutyunyan,HrantKhachatrian,DavidC.Kale,
PMLR.
and A. G. Galstyan. 2017. Multitask learning and
benchmarkingwithclinicaltimeseriesdata. Scien-
YaoLu,MaxBartolo,AlastairMoore,SebastianRiedel,
tificData,6.
andPontusStenetorp.2022. FantasticallyOrdered
PromptsandWheretoFindThem:OvercomingFew-
SamHenry,KevinBuchan,MicheleFilannino,Amber
ShotPromptOrderSensitivity. InProceedingsofthe
Stubbs,andOzlemUzuner.2020. 2018n2c2shared
60thAnnualMeetingoftheAssociationforCompu-
taskonadversedrugeventsandmedicationextraction
tationalLinguistics(Volume1: LongPapers),pages
inelectronichealthrecords. JournaloftheAmerican
8086–8098,Dublin,Ireland.AssociationforCompu-
MedicalInformaticsAssociation: JAMIA,27(1):3–
tationalLinguistics.
12.
Monica Munnangi, Sergey Feldman, Byron C Wal-
Kexin Huang, Jaan Altosaar, and Rajesh Ranganath.
lace,SilvioAmir,TomHope,andAakankshaNaik.
2020. Clinicalbert: Modeling clinical notes
2024. On-the-flydefinitionaugmentationofllmsfor
and predicting hospital readmission. Preprint,
biomedicalner. Preprint,arXiv:2404.00152.
arXiv:1904.05342.
JesutofunmiAOmiye,JennaCLester,SimonSpichak,
SrinivasanIyer,XiVictoriaLin,RamakanthPasunuru,
Veronica Rotemberg, and Roxana Daneshjou.
TodorMihaylov,DánielSimig,PingYu,KurtShus-
2023. Largelanguagemodelspropagaterace-based
ter,TianluWang,QingLiu,PunitSinghKoura,etal.
medicine. NPJDigitalMedicine,6(1):195.
2022. OPT-IML: Scaling language model instruc-
tionmetalearningthroughthelensofgeneralization. OpenAI.2022. ChatGPT-3.5.
arXivpreprintarXiv:2212.12017.
LongOuyang,JeffWu,XuJiang,DiogoAlmeida,Car-
AlbertQ.Jiang,AlexandreSablayrolles,ArthurMen- rollLWainwright,PamelaMishkin,ChongZhang,
sch,ChrisBamford,DevendraSinghChaplot,Diego SandhiniAgarwal,KatarinaSlama,AlexRay,etal.
delasCasas,FlorianBressand,GiannaLengyel,Guil- 2022. Training language models to follow in-
laumeLample,LucileSaulnier,LélioRenardLavaud, structions with human feedback. arXiv preprint
Marie-AnneLachaux,PierreStock,TevenLeScao, arXiv:2203.02155.RidamPal,HardikGarg,ShashwatPatel,andTavpritesh Lindia Tjuatja, Valerie Chen, Sherry Tongshuang
Sethi.2023. Biasamplificationinintersectionalsub- Wu, Ameet Talwalkar, and Graham Neubig. 2023.
populations for clinical phenotyping by large lan- Do LLMs exhibit human-like response biases?
guagemodels. medRxiv,pages2023–03. A case study in survey design. arXiv preprint.
ArXiv:2311.04076[cs].
Jon Patrick and Min Li. 2010. High Accuracy Infor-
mationExtractionofMedicationInformationfrom AugustinToma,PatrickRLawler,JimmyBa,RahulG
Clinical Notes: 2009 I2b2 Medication Extraction Krishnan,BarryBRubin,andBoWang.2023. Clini-
Challenge. JournaloftheAmericanMedicalInfor- calCamel: AnOpen-SourceExpert-LevelMedical
maticsAssociation: JAMIA,17(5):524–527. LanguageModelwithDialogue-BasedKnowledge
Encoding. arXivpreprintarXiv:2305.12031.
Pouya Pezeshkpour and Estevam Hruschka. 2023.
Large Language Models Sensitivity to The Order Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
of Options in Multiple-Choice Questions. arXiv bert, Amjad Almahairi, Yasmine Babaei, Nikolay
preprint. ArXiv:2308.11483[cs]. Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti
Bhosale, et al. 2023. Llama 2: Open founda-
AlecRadford,JeffreyWu,RewonChild,DavidLuan, tion and fine-tuned chat models. arXiv preprint
DarioAmodei,IlyaSutskever,etal.2019. Language arXiv:2307.09288.
modelsareunsupervisedmultitasklearners. OpenAI
ÖzlemUzuner.2009. Recognizingobesityandcomor-
blog,1(8):9.
biditiesinsparsedata. JournaloftheAmericanMed-
icalInformaticsAssociation,16(4):561–570.
Harsh Raj, Vipul Gupta, Domenic Rosati, and Sub-
habrata Majumdar. 2023. Semantic Consistency
Özlem Uzuner, Brett R South, Shuying Shen, and
forAssuringReliabilityofLargeLanguageModels.
ScottLDuVall.2011. 2010i2b2/VAchallengeon
arXivpreprint. ArXiv:2308.09138[cs].
concepts, assertions, and relations in clinical text.
JournaloftheAmericanMedicalInformaticsAssoci-
VictorSanh,AlbertWebson,ColinRaffel,StephenH
ation,18(5):552–556.
Bach, Lintang Sutawika, Zaid Alyafeai, Antoine
Chaffin, Arnaud Stiegler, Teven Le Scao, Arun
Dave Van Veen, Cara Van Uden, Louis Blankemeier,
Raja, et al. 2021. Multitask prompted training en-
Jean-BenoitDelbrouck,AsadAali,ChristianBlüth-
ableszero-shottaskgeneralization. arXivpreprint
gen, Anuj Pareek, Malgorzata Polacin, William
arXiv:2110.08207.
Collins,NeeraAhuja,CurtP.Langlotz,JasonHom,
Sergios Gatidis, John M. Pauly, and Akshay S.
MelanieSclar,YejinChoi,YuliaTsvetkov,andAlane
Chaudhari. 2023. Adapted large language models
Suhr.2023. QuantifyingLanguageModels’Sensitiv-
canoutperformmedicalexpertsinclinicaltextsum-
itytoSpuriousFeaturesinPromptDesignor: How
marization. NatureMedicine,30:1134–1142.
Ilearnedtostartworryingaboutpromptformatting.
arXivpreprint. ArXiv:2310.11324[cs]. SominWadhwa,SilvioAmir,andByronWallace.2023a.
Revisitingrelationextractionintheeraoflargelan-
KaranSinghal,ShekoofehAzizi,TaoTu,SSaraMah-
guage models. In Proceedings of the 61st Annual
davi,JasonWei,HyungWonChung,NathanScales,
Meeting of the Association for Computational Lin-
AjayTanwani,HeatherCole-Lewis,StephenPfohl,
guistics (Volume 1: Long Papers), pages 15566–
etal.2023. Largelanguagemodelsencodeclinical
15589,Toronto,Canada.AssociationforComputa-
knowledge. Nature,620(7972):172–180.
tionalLinguistics.
AmberStubbs,ChristopherKotfila,HuaXu,andOzlem SominWadhwa,JayDeYoung,BenjaminNye,Silvio
Uzuner.2015. Identifyingriskfactorsforheartdis- Amir,andByronCWallace.2023b. Jointlyextract-
ease over time: Overview of 2014 i2b2/UTHealth inginterventions,outcomes,andfindingsfromRCT
sharedtaskTrack2. Journalofbiomedicalinformat- reportswithLLMs. InMachineLearningforHealth-
ics,58(Suppl):S67. careConference,pages754–771.PMLR.
Amber Stubbs and Özlem Uzuner. 2019. New ap- Yizhong Wang, Swaroop Mishra, Pegah Alipoormo-
proachestocohortselection. JournaloftheAmerican labashi,YeganehKordi,AmirrezaMirzaei,Atharva
MedicalInformaticsAssociation,26(11):1161–1162. Naik,ArjunAshok,ArutSelvanDhanasekaran,An-
jana Arunkumar, David Stap, et al. 2022. Super-
Jiuding Sun, Chantal Shaib, and Byron C. Wallace. NaturalInstructions: GeneralizationviaDeclarative
2023. Evaluating the Zero-shot Robustness of Instructionson1600+NLPTasks. InProceedings
Instruction-tunedLanguageModels. arXivpreprint. of the 2022 Conference on Empirical Methods in
ArXiv:2306.11270[cs]. NaturalLanguageProcessing,pages5085–5109.
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Albert Webson and Ellie Pavlick. 2022. Do Prompt-
Dubois,XuechenLi,CarlosGuestrin,PercyLiang, Based Models Really Understand the Meaning of
andTatsunoriB.Hashimoto.2023. StanfordAlpaca: Their Prompts? In Proceedings of the 2022 Con-
An Instruction-following LLaMA model. https: ference of the North American Chapter of the As-
//github.com/tatsu-lab/stanford_alpaca. sociation for Computational Linguistics: HumanLanguageTechnologies,pages2300–2344,Seattle,
United States. Association for Computational Lin-
guistics.
Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin
Guu, Adams Wei Yu, Brian Lester, Nan Du, An-
drewMDai,andQuocVLe.2021. Finetunedlan-
guagemodelsarezero-shotlearners. arXivpreprint
arXiv:2109.01652.
TravisZack,EricLehman,MiracSuzgun,JorgeARo-
driguez,LeoAnthonyCeli,JudyGichoya,DanJu-
rafsky,PeterSzolovits,DavidWBates,Raja-ElieE
Abdulnour, et al. 2024. Assessing the potential of
GPT-4toperpetuateracialandgenderbiasesinhealth
care: amodelevaluationstudy. TheLancetDigital
Health,6(1):e12–e22.A Appendix
A.1 InstructionCollection
Tocollectinstructionsfromexperts,weprovided
themwithadescriptionofthetasksincludingthe
goal,theexpectedoutputsanda(fictitious)exam-
ple of a clinical note. Figure 9 is an example of
theinstructionsgivenforaclassificationtask;and
Figures10and11showexamplesofcollectedin-
structions. We released the full set of collected
instructionsalongwithcode.
A.2 Results
In this section we present additional results from
ourexperiments. Weshowdetailedresultsinterms
of the mean performance and standard deviation
foralltheclassificationandinformationextraction
tasksintables3and4,respectively.
Figures12and13plotthevariabilityinperfor-
mance across classification and extraction tasks,
respectively. Figures 14 and 15 plot the deltas in
performancebetweenindividualexpert’sprompts
andthemedianpromptpertask,forgeneraldomain
andclinicalmodels,respectively.
Figure16showracesubgroupperformancefor
theMortalityPredictiontaskforallthemodels,and
Figure17showsasimilaranalysisforsex.
Ouroverallresultsshowthat,ingeneral,differ-
entpromptphrasingsyielddifferentperformance.
Are there prompts that are consistently effective
acrossmodels? Toinvestigatethis,werankedeach
promptwithrespecttotheperformanceandcalcu-
latedthemedianacrossmodels. Figures18and19
depictthemedianperformanceranking(amongall
12prompts)achievedbytheinstructionswrittenby
eachexpert. ForclassificationtaskssuchasCohort
Abdominal and Cohort Make Decisions, Expert
7 wrote prompts that are consistently among the
best performing ones for most models, which is
alsothecaseforthepromptswrittenbyExpert11
acrossfiveclassificationtasks. Ontheotherhand,
prompts from Expert 2 were consistently among
thelowerperformingones. Asimilarpatterncan
be seen in the extraction tasks, where Experts 6
and8wrotesomeofthebest-performingprompts
for most of these tasks. This suggests that, to an
extent, the performance of prompts is consistent
evenwhentestedondifferentmodels.Your Job
Write down an instruction you would use to prompt the LLMs to do the following task.
Task Description
Given some notes from a patient encounter, classify whether or not the patient will die during the course of a stay
in the hospital given notes from the first 48 hours.
...
ADMISSION DATE:
5-29-94
DISCHARGE DATE:
7-3-94
HISTORY OF PRESENT ILLNESS:
The patient is a 58-year-old right-hand dominant white female with a long history of hypertension; changed her
medications from Clonidine to Aldomet six weeks ago...
MEDICATIONS ON ADMISSION:
Vasotec 40 mg q.day, Soma 1 tablet q.day, Demerolprn, Clonidine.
SOCIAL HISTORY:
The patient lives with two people in Cinglendda.
PHYSICAL EXAMINATION:
On physical examination, the patient is in no acute distress, afebrile, blood pressure 135/82, heart rate 82 and
regular, and no bruits ...
TR :
[ report_end ]
Your Prompt
Figure9: Exampleofinstructionsforannotatorsforaclassificationtask;weprovidedparticipantswithadescription
ofthetasksincludingthegoal,theexpectedoutputsanda(fictitious)exampleofaclinicalnote.
TASK: Cohort Drug Abuse
CLINICAL NOTE: <note>
INSTRUCTION:
Based on the medical records provided, answer the question. Does this patient meet the definition of drug abuse?
Respond "Yes" if the patient meets the definition of drug abuse, or respond "No" if the patient does not meet the
definition of drug abuse.
Figure10: Exampleofinstructionsfor‘Cohortdrugabuse’classificationtask.TASK: Mortality Prediction
CLINICAL NOTE: <note>
INSTRUCTION:
Based on the medical notes provided from the first 48 hours of the patient\'s hospital stay, please classify whether
the patient will die during their hospital stay. Respond with either "Yes" if the patient will die during their stay
in the hospital or "No" if the patient will not die during their stay in the hospital.
Figure11: Exampleofinstructionsfor‘MortalityPrediction’classificationtask.
Model/ MISTRAL LLAMA2 LLAMA2 ALPACA CLINICAL ASCLEPIUS MEDALPACA
Dataset IT0.2(7B) CHAT(13B) CHAT(7B) (7B) CAMEL(13B) (7B) (7B)
ObesityCo- 0.974 0.908 0.696 0.479 0.594 0.732 0.557
Morbidity(Asthma) ±(0.014) ±(0.111) ±(0.145) ±(0.017) ±(0.059) ±(0.086) ±(0.078)
CohortAlcohol 0.980 0.898 0.836 0.549 0.517 0.894 0.715
Abuse ±(0.028) ±(0.142) ±(0.148) ±(0.126) ±(0.177) ±(0.084) ±(0.146)
ObesityCo- 0.963 0.933 0.796 0.512 0.649 0.702 0.679
MorbidityCAD ±(0.017) ±(0.067) ±(0.096) ±(0.033) ±(0.107) ±(0.154) ±(0.071)
CohortDrug 0.941 0.923 0.934 0.570 0.698 0.938 0.756
Abuse ±(0.039) ±(0.04) ±(0.048) ±(0.132) ±(0.138) ±(0.042) ±(0.119)
CohortEnglish 0.974 0.824 0.790 0.460 0.586 0.737 0.552
±(0.055) ±(0.123) ±(0.165) ±(0.071) ±(0.076) ±(0.078) ±(0.058)
CohortMake 0.709 0.623 0.710 0.644 0.597 0.817 0.513
Decision ±(0.178) ±(0.238) ±(0.171) ±(0.047) ±(0.174) ±(0.074) ±(0.098)
Cohort 0.750 0.707 0.644 0.483 0.506 0.637 0.648
Abdominal ±(0.034) ±(0.076) ±(0.034) ±(0.029) ±(0.069) ±(0.052) ±(0.059)
ObesityCo- 0.987 0.958 0.775 0.560 0.637 0.762 0.686
Morbidity(Diabetes) ±(0.011) ±(0.063) ±(0.114) ±(0.041) ±(0.109) ±(0.124) ±(0.05)
Obesity 0.943 0.9 0.639 0.534 0.612 0.453 0.64
Classification ±(0.05) ±(0.087) ±(0.113) ±(0.03) ±(0.074) ±(0.177) ±(0.084)
Mortality 0.777 0.794 0.742 0.466 0.506 0.757 0.658
Prediction ±(0.034) ±(0.036) ±(0.083) ±(0.051) ±(0.052) ±(0.037) ±(0.08)
Table3: MeanandStandardDeviationforinstructionsonclassificationtasksacrossallmodelsandalltasksModel/ MISTRAL LLAMA2 LLAMA2 ALPACA CLINICAL ASCLEPIUS MEDALPACA
Dataset IT0.2(7B) CHAT(13B) CHAT(7B) (7B) CAMEL(13B) (7B) (7B)
Medication 0.351 0.559 0.608 0.231 0.509 0.562 0.529
Extraction ±(0.111) ±(0.072) ±(0.084) ±(0.069) ±(0.15) ±(0.027) ±(0.047)
ConceptProblem 0.265 0.325 0.329 0.131 0.3 0.256 0.229
Extraction ±(0.051) ±(0.035) ±(0.027) ±(0.029) ±(0.035) ±(0.019) ±(0.021)
ConceptTest 0.154 0.197 0.236 0.097 0.117 0.194 0.109
Extraction ±(0.076) ±(0.066) ±(0.05) ±(0.025) ±(0.078) ±(0.025) ±(0.049)
ConceptTreatment 0.165 0.244 0.367 0.086 0.198 0.308 0.193
Extraction ±(0.084) ±(0.086) ±(0.093) ±(0.031) ±(0.129) ±(0.039) ±(0.072)
Drug 0.394 0.373 0.495 0.192 0.372 0.432 0.429
Extraction ±(0.101) ±(0.047) ±(0.072) ±(0.074) ±(0.128) ±(0.042) ±(0.086)
RiskFactorCAD 0.057 0.081 0.079 0.067 0.122 0.063 0.103
Extraction ±(0.009) ±(0.018) ±(0.024) ±(0.056) ±(0.046) ±(0.012) ±(0.029)
Table4: MeanandStandardDeviationforinstructionsonextractiontasksacrossallmodelsandalltasks
Obesity Co-Morbidity (Asthma) Obesity Co-Morbidity (CAD) Obesity
Mistral (7b)
Llama-2 (13b)
Llama-2 (7b)
Alpaca (7b) General models
Clinical models
Clin-Camel (13b)
Asclepius (7b)
MedAlpaca (7b)
Obesity Co-Morbidity (Diabetes Mellitus) Cohort Abdominal Cohort Alcohol Abuse
Mistral (7b)
Llama-2 (13b)
Llama-2 (7b)
Alpaca (7b)
Clin-Camel (13b)
Asclepius (7b)
MedAlpaca (7b)
Cohort Drug Abuse Cohort English Cohort Make Decisions
Mistral (7b)
Llama-2 (13b)
Llama-2 (7b)
Alpaca (7b)
Clin-Camel (13b)
Asclepius (7b)
MedAlpaca (7b)
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
AUROC
Figure12: Variabilityinperformanceacrosspromptsforbinaryclassificationtasks. Againweobservethatdifferent
(equivalent)instructionsyieldwidevariancesinperformance,suggestinganunduesensitivitytophrasings.Medication Extraction Concept Test Extraction Concept Problem Extraction
Mistral (7b)
Llama-2 (13b)
Llama-2 (7b)
Alpaca (7b) General models
Clinical models
Clin-Camel (13b)
Asclepius (7b)
MedAlpaca (7b)
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
F1
Concept Treatment Extraction Risk Factor CAD Extraction
Mistral (7b)
Llama-2 (13b)
Llama-2 (7b)
Alpaca (7b)
Clin-Camel (13b)
Asclepius (7b)
MedAlpaca (7b)
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
F1
Figure13: Variabilityinperformanceacrosspromptsfortheremaining5extractiontasks. Asmentioned,formost
models,differentbutsemanticallyequivalentpromptsyieldquitearangeofperformance.Mistral (7b) on Classification Mistral (7b) on Extraction
Familiar with LLMs
Yes
No
0.6 0.4 0.2 0.0 0.2 0.3 0.2 0.1 0.0 0.1 0.2 0.3
AAUURROOCC FF11
Llama-2 (13b) on Classification Llama-2 (13b) on Extraction
0.6 0.4 0.2 0.0 0.2 0.3 0.2 0.1 0.0 0.1 0.2 0.3
AAUURROOCC FF11
Alpaca (7b) on Classification Alpaca (7b) on Extraction
0.6 0.4 0.2 0.0 0.2 0.3 0.2 0.1 0.0 0.1 0.2 0.3
AAUURROOCC FF11
Figure14: Distributionofperformancedeltasbetweeneachexpert’spromptandthemedianpromptacrossalltasks
foreachgeneralmodel. Eachviolinplotrepresentsanexpertcolor-codedaccordingtotheirfamiliaritywithLLM.
trepxE
trepxE
trepxEAsclepius (7b) on Classification Asclepius (7b) on Extraction
Familiar with LLMs
Yes
No
0.6 0.4 0.2 0.0 0.2 0.3 0.2 0.1 0.0 0.1 0.2 0.3
AAUURROOCC FF11
Clin-Camel (13b) on Classification Clin-Camel (13b) on Extraction
0.6 0.4 0.2 0.0 0.2 0.3 0.2 0.1 0.0 0.1 0.2 0.3
AAUURROOCC FF11
MedAlpaca (7b) on Classification MedAlpaca (7b) on Extraction
0.6 0.4 0.2 0.0 0.2 0.3 0.2 0.1 0.0 0.1 0.2 0.3
AAUURROOCC FF11
Figure15: Distributionofperformancedeltasbetweeneachexpert’spromptandthemedianpromptacrossalltasks
foreachclinicalmodel. Eachviolinplotrepresentsanexpertcolor-codedaccordingtotheirfamiliaritywithLLM.
trepxE
trepxE
trepxEMistral (7b) on Mortality Prediction
1.0 White
Non-White
0.8
0.6
0.4
12 11 10 9 8 7 6 5 4 3 2 1
Rank
Llama-2 (13b) on Mortality Prediction Alpaca (7b) on Mortality Prediction
1.0 1.0
0.8 0.8
0.6 0.6
0.4 0.4
12 11 10 9 8 7 6 5 4 3 2 1 12 11 10 9 8 7 6 5 4 3 2 1
Rank Rank
Clin-Camel (13b) on Mortality Prediction MedAlpaca (7b) on Mortality Prediction
1.0 1.0
0.8 0.8
0.6 0.6
0.4 0.4
12 11 10 9 8 7 6 5 4 3 2 1 12 11 10 9 8 7 6 5 4 3 2 1
Rank Rank
Figure16: RacesubgroupperformanceontheMortalityPredictiontaskwithageneral(left)andclinicalmodel
(right). Mistralhasnoclinicalcounterpartinourstudy.
CORUA
CORUA
CORUA
CORUA
CORUAMistral (7b) on Mortality Prediction
1.0 Male
Female
0.8
0.6
0.4
12 11 10 9 8 7 6 5 4 3 2 1
Rank
Llama-2 (13b) on Mortality Prediction Alpaca (7b) on Mortality Prediction
1.0 1.0
0.8 0.8
0.6 0.6
0.4 0.4
12 11 10 9 8 7 6 5 4 3 2 1 12 11 10 9 8 7 6 5 4 3 2 1
Rank Rank
Clin-Camel (13b) on Mortality Prediction MedAlpaca (7b) on Mortality Prediction
1.0 1.0
0.8 0.8
0.6 0.6
0.4 0.4
12 11 10 9 8 7 6 5 4 3 2 1 12 11 10 9 8 7 6 5 4 3 2 1
Rank Rank
Figure17: SexsubgroupperformanceontheMortalityPredictiontaskwithageneral(left)andclinicalmodel
(right). Mistralhasnoclinicalcounterpartinourstudy.
CORUA
CORUA
CORUA
CORUA
CORUAMedian ranking of annotators for the classification tasks
12
Expert 1 3 6 7 8 5 5 8 10 7 4
Expert 2 9 8 9 7 9 9 10 9 10 6
10
Expert 3 7 4 4 6 7 6 5 7 8 7
Expert 4 5 11 5 4 6 10 9 5 10 8
Expert 5 9 5 5 4 7 5 8 6 6 9 8
Expert 6 8 8 9 6 5 6 4 7 9 6
Expert 7 2 12 6 11 1 5 7 10 11 5 6
Expert 8 6 6 8 3 7 9 9 5 7 10
Expert 9 7 8 7 5 4 5 3 6 4 3
4
Expert 10 6 4 5 4 9 6 7 10 5 5
Expert 11 5 8 7 8 10 3 3 3 2 4
2
Expert 12 9 6 7 10 11 8 5 4 5 10
Figure18: Medianrankingofpromptswrittenbyexpertsforclassificationtasksacrossmodels.
Median ranking of annotators for the extraction tasks
12
Expert 1 9 9 8 11 11
Expert 2 7 7 9 5 2
10
Expert 3 8 12 12 7 9
Expert 4 5 3 2 8 4
Expert 5 9 7 7 7 7 8
Expert 6 3 5 1 2 3
Expert 7 2 2 4 7 10 6
Expert 8 5 1 6 1 2
Expert 9 11 8 10 6 7
4
Expert 10 7 10 9 8 7
Expert 11 2 5 5 11 6
2
Expert 12 5 6 3 8 9
Figure19: Medianrankingofpromptswrittenbyexpertsforextractiontasksacrossmodels.
lanimodbA
trohoC
.txE
melborP
tpecnoC
esubA
lohoclA
trohoC
esubA
gurD
trohoC
.txE
tseT
tpecnoC
hsilgnE
trohoC
snoisiceD
ekaM
trohoC
.txE
tnemtaerT
tpecnoC
.derP
ytilatroM
cimiM
ytisebO
.txE
noitacideM
).tsA(
.broM-oC
ytisebO
)DAC(
.broM-oC
ytisebO
.txE
DAC
rotcaF
ksiR
)MD(
.broM-oC
ytisebO