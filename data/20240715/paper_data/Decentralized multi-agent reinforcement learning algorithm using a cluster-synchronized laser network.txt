Decentralized multi-agent reinforcement learning algorithm
using a cluster-synchronized laser network
Shun Kotoku1, Takatomo Mihana1,∗, André Röhm1, and Ryoichi Horisaki1
Department of Information Physics and Computing, Graduate School of Information Science and Technology,
The University of Tokyo, 7-3-1 Hongo, Bunkyo, Tokyo 113-8656, Japan.
∗Corresponding author. Email: takatomo_mihana@ipc.i.u-tokyo.ac.jp
Abstract Multi-agent reinforcement learning (MARL) studies crucial principles that are applicable to a
variety of fields, including wireless networking and autonomous driving. We propose a photonic-based
decision-making algorithm to address one of the most fundamental problems in MARL, called the
competitive multi-armed bandit (CMAB) problem. Our numerical simulations demonstrate that chaotic
oscillations and cluster synchronization of optically coupled lasers, along with our proposed decentralized
coupling adjustment, efficiently balance exploration and exploitation while facilitating cooperative
decision-making without explicitly sharing information among agents. Our study demonstrates how
decentralized reinforcement learning can be achieved by exploiting complex physical processes controlled by
simple algorithms.
1 Introduction
Reinforcement learning [1] is a subfield of machine learning where an agent interacts with environments
through trial and error, optimizing its actions based on a reward norm. Multi-agent reinforcement learning
(MARL) [2–4] is an extended form of reinforcement learning where multiple agents simultaneously interact
with environments as well as other agents. Its applications have now spread across various areas, including
wireless networking [5], autonomous driving [6], power distribution networks [7], etc. We focus on one of the
most fundamental settings of MARL: the competitive multi-armed bandit (CMAB) problem [8].
TheCMABproblem,anextensionofthemulti-armedbandit(MAB)problem[9],featuresseveralplayers
(agents) who repeatedly select among multiple slot machines (arms) with unknown hit probabilities (uncer-
tain environments). Players need to balance two opposing strategies: exploration, which involves players
attempting to identify the profitable slots by exploring various options, and exploitation, where players at-
tempttofocusonthemostpromisingoptionbyexploitingtheacquiredinformationabouttheenvironments.
The term ‘competitive’ can be misleading in the context of MARL. In this setting, it does not imply a zero-
sum reward distribution as it might in the literature [4]. Instead, the rewards are divided among players
when they select the same slot, and players cooperatively aim to maximize the total rewards for the team.
Therefore, avoiding selection collisions is important for effective decision-making. The CMAB problem can
be considered a form of stateless MARL, provided the reward environment remains constant.
In the past decade, several studies regarding the MAB [10–13] or CMAB [14–17] problem have been
conducted in the context of photonic accelerators [18]. Photonic accelerators involve promising approaches
to accelerate or improve performances of specific computations by utilizing photonics, such as its high prop-
agation speed, broad bandwidth, and parallelism. Our study features a cooperative decision-making system
usingalasernetwork[16,17],whichleveragestherapidandchaoticoscillationsandsynchronizationobserved
in optically interconnected semiconductor lasers for avoiding slot selection collisions in the CMAB problem.
Specifically, the laser-based decision-making system employs two kinds of coexisting laser interactions:
a leader-laggard relationship and cluster synchronization. The leader-laggard relationship [19, 20] observed
in coupled lasers with chaotic dynamics is similar to delay-synchronization, where the temporal waveform
of the ‘leader’ laser’s intensity precedes that of the ‘laggard’ laser by the coupling delay time. Unlike full
delay-synchronization commonly observed in delay-coupled networks, the roles of the leader and laggard
spontaneously exchange. Cluster synchronization [21–24] refers to a state where nodes in a delay-coupled
1
4202
luJ
21
]GL.sc[
1v42190.7042:viXranetwork separate into several clusters, and the oscillations of nodes within the same cluster synchronize
without delay.
The decision-making system assigns a subset of lasers in a network to players. Each laser corresponds
to each player’s selection of slot machines, and players select slots based on the leader laser at each decision
point. Cluster synchronization in a laser network enables players to avoid selection collisions. The previous
study[17]hasrevealedthebalanceoftheleader-laggardrelationshipcanbecontrolledwhilemaintainingtwo-
cluster synchronization by adjusting coupling strengths between lasers in four laser networks, corresponding
to the CMAB problem with two players and two slots.
However, the previous work [17] has been limited to investigating laser dynamics and interactions with
parameters fixed for each setting, and it has not addressed the CMAB problem itself. Specifically, it has
not yet been discussed how coupling strengths should be dynamically adjusted. An earlier approach [15]
has also addressed photonic-based collective decision-making, but the method presumed the existence of a
centralized controller besides the players. Physics-based methods, and especially photonic approaches, for
decision-making are likely to find applications in edge-devices, which lack the local computing or networking
resources to implement traditional digital learning algorithms. In the case of such edge-devices, it is more
realistic and practical to assume that each player can only observe the result of its own slot selection. In
addition,thepreviouswork[17]hasdealtonlywithfour-lasernetworksforthetwo-playerandtwo-slotCMAB
problem. Selectiononlytrulymatters, whenthenumberofarmsexceedsthenumberofplayers, asotherwise
avoiding selection collisions is the only important aspect of maximizing rewards for the team.
In this study, we propose an enlarged laser network that exhibits stable cluster synchronization, as well
as an algorithm to adjust the coupling strengths of the laser network based on the player’s individually
received rewards to efficiently address the competitive multi-armed bandit (CMAB) problem with more slot
machines than players. Our numerical simulations validate the viability of our proposed laser network and
decentralized coupling adjustment algorithm for tackling the CMAB problem.
Note that we do not assert that the proposed photonic-based decision-making algorithm is superior to
existing methods, such as the Upper Confidence Bound 1 (UCB1) [25] for the single-agent configuration and
its variants for the multi-agent settings, in all aspects and can entirely replace them. Rather, we focus on
exploring the application of nontrivial photonics phenomena accompanied by straightforward and intuitive
learning algorithms. Our results show that the proposed system is indeed reaching good performance in the
explored circumstances.
2 Method and dynamics investigation
2.1 System configuration
We study the case of the competitive multi-armed bandit (CMAB) problem with two players and three slot
machines. Table 1 shows an example of a payoff matrix for the rewards in the CMAB problem with a
typical problem setting of the hit probabilities of Slots A, B, and C: P = 0.4,P = 0.6,P = 0.6. We
A B C
assume a temporally static reward environment for simplicity. Each column in Table 1 represents the slot
Table 1: An example of a payoff matrix for the rewards in a competitive multi-armed bandit problem with
two players and three slot machines (P =0.4,P =0.6,P =0.6). The first and second elements represent
A B C
theexpectedrewardsforPlayers1and2. Theunderlinedportionsalongthediagonalindicatewhereselection
collisions happen.
2 1 Slot A Slot B Slot C
A (0.2, 0.2) (0.6, 0.4) (0.6, 0.4)
B (0.4, 0.6) (0.3, 0.3) (0.6, 0.6)
C (0.4, 0.6) (0.6, 0.6) (0.3, 0.3)
2(a)
Player 1 Player 2
Laser LLaasseerr
2A
1A 2A
Laser
La1sBer LLaasseerr
1B 22BB
Laser Laser
1C 2C
(b)
1A 2A
1B 2B
1C 2C
Figure 1: Schematic illustration of our proposed system. (a) A six-laser network to address the competitive
multi-armed bandit problem with two players and three slot machines. r and r (♯ = bl,or,ye) represent
1♯ 2♯
the attenuation rates adjusted by Players 1 and 2. κ represents the total multiplicative coupling strength.
♯
(b)Typicallaserintensitywaveformsofthesix-lasernetworkobtainedthroughnumericalsimulations. Lasers
drawn with identical colors are synchronized.
selectedbyPlayer1,andeachrowrepresentstheslotbyPlayer2. Theunderlinedportionsalongthediagonal
indicate cases where the players select the same slot, and the rewards are thus divided among them. Due to
this division of spoils, the team’s sum rewards are lower in such cases compared to other selection patterns.
Naturally, players are encouraged to focus on selecting the most high-paying two out of three slots in the
exploitationphaseaftersufficientexplorationtoestimatethehitprobabilitiesoftheslots. Thus,itisoptimal
tonarrowdowntheirselectionstoSlotsBandC,whichyieldthemaximumpotentialrewardsintheproblem
setting. But at the same time, they need to avoid both selecting the same slot.
Figure 1 (a) illustrates the proposed six-laser network to address the CMAB problem with a two-player
and three-slot-machine configuration. Note that the coupling delay time between lasers, τ, is assumed to be
uniform for all connections. Lasers 1A, 1B, and 1C are allocated to Player 1, and Lasers 2A, 2B, and 2C to
Player 2. Each laser corresponds to a slot machine selected by a player.
Inthecollectivedecision-makingsystem,playersselectaslotcorrespondingtotheleaderamongthethree
lasersassignedtothem. Theleaderisdefinedbyshort-termcross-correlation(STCC)valuesinthefollowing
3formulas [12]:
(cid:90) t I (u)−I¯ I (u−τ)−I¯
C (t)= 1A 1A 1B 1B,τdu, (1)
1A σ σ
t−τ 1A 1B,τ
(cid:90) t I (u)−I¯ I (u−τ)−I¯
C (t)= 1B 1B 1C 1C,τdu, (2)
1B σ σ
t−τ 1B 1C,τ
(cid:90) t I (u)−I¯ I (u−τ)−I¯
C (t)= 1C 1C 1A 1A,τdu, (3)
1C σ σ
t−τ 1C 1A,τ
whereI (t)denotesthelaserintensityofLaserk,I¯ andσ representtheaverageandthestandarddeviation
k k k
ofI (t),overtheperiodofτ. I¯ andσ havecomparablemeanings,butthetimewindowforthecalculation
k k,τ k,τ
is shifted back by τ. Player 1 considers the laser with the smallest STCC value of the three as the leader.
Therefore, for example, Player 1 selects Slot B when C < C and C < C hold. STCC values for
1B 1A 1B 1C
Player 2, C ,C , and C , are defined similarly to Eqs. (1)–(3).
2A 2B 2C
In the six-laser network depicted in Fig. 1 (a), lasers with the same color, Lasers 1A and 2B, Lasers 1B
and 2C, and Lasers 1C and 2A, are in perfect zero-lag synchronization when the coupling strengths with the
same color are uniform, as shown in Fig. 1 (b). Here, we define cluster bl (blue) to consist of Lasers 1A and
2B, cluster or (orange) to consist of Lasers 1B and 2C, and cluster ye (yellow) to consist of Lasers 1C and
2A. Note that this color differentiation is just for convenience and is not related to the wavelength of the
lasers. Playersavoidselectioncollisionswithoutsharinginformationabouttheirslotselectionsandresultant
rewards thanks to this three-cluster synchronization. For instance, when Laser 1B is regarded as the leader
and Player 1 selects Slot B, due to the cluster synchronization with Laser 1B, Laser 2C is considered the
leader by Player 2, who will then select Slot C. Thus, Players 1 and 2 always select different slot machines
and achieve conflict avoidance in the CMAB problem.
2.2 Leader probability and cluster synchronization
Our previous work [17] has revealed that the leader-laggard relationship, which corresponds to the selection
of slot machines, can be controlled by adjusting the coupling strengths while maintaining two-cluster syn-
chronization in a four-laser network. Here, we numerically examine how the leader-laggard relationship in a
six-laser network, as illustrated in Fig. 1 (a), can be controlled with coupling strengths.
The model of chaotic semiconductor lasers is described by Lang-Kobayashi equations [26] as follows:
(cid:20) (cid:21)
dE k(t)
=
1+iα G N[N k(t)−N 0]
−
1
E
(t)+(cid:88)
κ E (t−τ)exp(−iωτ), (4)
dt 2 1+ε|E (t)|2 τ k l→k l
k p
dN (t) N (t) G [N (t)−N ]
k =J − k − N k 0 |E (t)|2, (5)
dt τ 1+ε|E (t)|2 k
s k
where E (t) and N (t) represent the complex electric field and the carrier density of Laser k at time t. The
k k
laser intensity is the square of the absolute value of the complex electric field: I (t)=|E (t)|2. ω represents
k k
theangularfrequencyofthelasers. Asaprerequisiteforclustersynchronization, thelaserfrequencieswithin
the same cluster should be equal. For simplicity, we assume identical frequencies for all lasers. κ is the
l→k
coupling strength from Laser l to Laser k, where the value is zero between unconnected lasers.
The parameters are shown in Table 2 and are taken from references [12, 16, 17] except for the injection
currentJ. PreviousstudiessetthevalueofJ/J to1.1(J isinjectioncurrentthreshold)sothatthelasers
th th
exhibit low-frequency fluctuation dynamics. However, according to our current examination, the setting of
J/J =2.0 seems more promising for stable cluster synchronization and rapid decision-making.
th
The necessary conditions for cluster synchronization in the six-laser network are κ = κ
1A→1B 2B→2C
(≡ κ ), κ = κ (≡ κ ), and κ = κ (≡ κ ). We conduct the numerical simula-
bl 1B→1C 1B→2A or 2A→1A 2A→2B ye
tions to obtain temporal waveforms of laser intensity I (t), with the balance of coupling strengths varied
k
while maintaining the requirements. Afterward, STCC values are calculated to determine the leader-laggard
relationship for each setting of coupling strengths.
Figure 2 (a) and (b) show STCC time series acquired from numerical simulations. Coupling strengths
are configured as κ = κ = 45ns−1 and (a) κ = 38ns−1, and (b) κ = 45ns−1. Perfect three-cluster
or ye bl bl
4Table 2: Parameters of the Lang-Kobayashi equations.
Symbol Parameter Value
GN Gaincoefficient 8.40×10−13m3s−1
N0 Carrierdensityattransparency 1.40×1024m−3
ε Gainsaturationcoefficient 2.0×10−23
τp Photonlifetime 1.927×10−12s
τs Carrierlifetime 2.04×10−9s
α Linewidthenhancementfactor 3.0
τ Couplingdelaytimeoflight 5.0×10−9s
J/J Normalizedinjectioncurrent 2.0
th
λ Opticalwavelengthoflasers 1.537×10−6m
synchronization is observed for both settings. C and C are the smallest in most cases for (a), while
1B 2C
the frequent switching among C , C , and C and that among C , C , and C are observed for the
1A 1B 1C 2A 2B 2C
symmetric setting of coupling strengths, (b).
We define the leader probability as the ratio of times each laser is identified as a leader. The leader
probabilities are calculated from STCC waveforms spanning 10000ns after waiting for a sufficiently long
transient of 3000ns. We repeat the computation 50 times with the initial states of the lasers randomized
eachtimeandcalculatetheaverageleaderprobabilitiesoflasersforeachκ . κ andκ arefixedat45ns−1,
bl or ye
and κ is varied from 5ns−1 to 60ns−1, in increments of 1ns−1. The average leader probabilities of the six
bl
lasersinthenetworkareshowninFig.2(c). Theleaderprobabilitiesof1A,1B,and1C(2A,2B,and2C)are
approximately one-third for the symmetric coupling strengths, κ = 45ns−1. The leader probability of 1B
bl
(2C)isgreaterthanone-thirdwithκ smallerthan45ns−1, andconvergestoward1.0aroundκ =30ns−1.
bl bl
Anattempttoreducethevalueofκ smallerthan5ns−1 bringsaboutthecessationofthechaoticoscillations
bl
inthelasernetwork, andwewanttofocusontheregioninwhichthechaoticleader-laggardrelationshipand
cluster synchronization coexist. Conversely, the leader probability of 1B (2C) is smaller than one-third for
κ >45ns−1, and converges toward 0 around κ =60ns−1.
bl bl
Note that similar results are obtained when κ and κ (κ and κ ) are fixed and κ (κ ) is varied
ye bl bl or or ye
because of the symmetry of the network.
Therefore,whenplayersestimatethecombinationofSlotsBandCisoptimalaftertheexplorationphase,
they are encouraged to decrease κ in the exploitation phase so that Lasers 1B and 2C are more likely to be
bl
leaders. Similarly, if the option of Slots C and A is good, players lower κ , and if that of Slots A and B is
or
good, they lower κ .
ye
2.3 Decentralized coupling adjustment
The decision-making process in our proposed system is as follows. First, two players observe the laser
intensities and calculate short-term cross-correlation (STCC) values to determine the leader of the three
lasers allocated to them. Players select the slot corresponding to the leader, i.e., the one with the lowest
STCC value. In perfect cluster synchronization, players naturally and independently select different slots.
Based on the resulting slot rewards, players adjust the optical attenuation rates, represented by r and r
1♯ 2♯
(♯ = bl,or,ye) in Fig. 1 (a), to improve their subsequent slot selections, and to narrow down to the most
high-paying two slots. Hereinafter, the whole process is referred to as one ‘Play,’ and players attempt to
maximize the team’s accumulated rewards over a significant number of Plays.
The total multiplicative coupling strength κ is denoted as κ =r r κ, where κ represents the coupling
♯ ♯ 1♯ 2♯
strengthwithoutamplificationorattenuation. ThevalueofκisdeterminedbyparametersofLang-Kobayashi
equations, and κ=155.3ns−1 in this paper.
Therefore, the remaining challenge is to design an algorithm, for how players should adjust their optical
attenuation rates. With the goal of being usable in edge-computing scenarios, we designed the algorithm
5(a) (b)
(c)
1B
1C
1A
2C
2A
2B
Figure 2: Numerical simulation results to investigate the leader probabilities of the six-laser network shown
in Fig. 1. (a) Short-term cross-correlation (STCC) waveforms calculated for coupling strength κ = κ =
or ye
45ns−1 andκ =38ns−1. (b)κ =45ns−1. (c)Therelationshipbetweenthecouplingstrengthsandleader
bl bl
probabilities. κ and κ are fixed at 45ns−1, and κ is set from 5ns−1 to 60ns−1.
or ye bl
to be simple and robust. The underlying idea is inspired by tug-of-war (TOW) dynamics [27], originally
designed for the multi-armed bandit (MAB) problem with a single player. Although several algorithms have
been proposed to solve the multi-agent multi-armed bandit problem, including the Upper Confidence Bound
1 (UCB1)-based methods [28–30], the TOW-based algorithm effectively leverages the probabilistic property
observed in photonics, and it has been applied for addressing the MAB problem with a single player using
chaotic lasers [11].
A modified version of the TOW-based algorithm for the CMAB problem with multiple players has been
proposed later [31], and it has been applied for the software-based conflict avoidance principle in decision-
making using laser networks [15]. However, the method requires players to share information about the slot
rewards, whichweconsiderinappropriategiventhepartialobservabilityassumptionsoftheCMABproblem.
Our proposed method, decentralized coupling adjustment (DCA), is described by the following formulas:
Q =2P¯ −(P¯ +P¯ ), (6)
1,X 1,X 1,2nd 1,3rd

r (r +r Q <r ),
 low ini step 1,S(♯) low
r = r (r <r +r Q ), (7)
1♯ upp upp ini step 1,S(♯)
r
+r Q (otherwise).
ini step 1,S(♯)
6Q represents the excess hit probability of Slot X (X = A,B,C) over the baseline measured by Player 1,
1,X
where P¯ is the observed hit probability of Slot X by Player 1, and P¯ and P¯ denote the observed
1,X 1,2nd 1,3rd
hit probability of the second and third-best slot machine for Player 1. The excess hit probability Q of
1,X
the best and second slot becomes positive, whereas that of the third (worst) slot becomes negative after a
sufficient number of Plays.
To keep the coupling strengths κ =r r κ within a certain range, [κ ,κ ], lower and upper limits of
♯ 1♯ 2♯ low upp
(cid:112) (cid:112)
the attenuation rates r ≡ κ /κ and r ≡ κ /κ are established. κ and κ are hyperparam-
low low upp upp low upp
eters that determine the balance between exploration and exploitation. r =(r +r )/2 is the baseline
ini low upp
attenuation rate. r is a scaling factor that affects the strengths of exploitation. S(♯) is a mapping from
step
coloring to slot machines: S(bl)=A,S(or)=B,S(ye)=C.
TheexcesshitprobabilityofSlotXobservedbyPlayer2,Q ,isdefinedsimilarlytoEq.(6),andPlayer
2,X
2 adjusts the attenuation rate r in the same manner as Eq. (7).
2♯
With the DCA method, players control the leader probabilities of lasers and narrow down their slot
selections. For example, under the problem setting shown in Table 1, when Slot A appears low-rewarding to
Player 1, Q decreases, and r = r +r Q = r +r Q is reduced. Player 2 also lowers
1,A 1bl ini step 1,S(bl) ini step 1,A
r , and thus, κ = r r κ is reduced. As shown in Fig. 2 (c), when κ is smaller than κ and κ ,
2bl bl 1bl 2bl bl or ye
the leader probabilities of Lasers 1B and 2C becomes higher. Therefore, players can correctly select Slots B
and C at a high rate. Notably, players share no information about observed hit probabilities of slots during
decision-making in our proposed algorithm, which sets it apart from previous studies [15, 31].
3 Decision-making simulations
3.1 Results of a single trial
We numerically solve the competitive multi-armed bandit (CMAB) problem with our decision-making algo-
rithm to prove its effectiveness in balancing exploration and exploitation while avoiding selection conflicts.
First, we present a sample result of a single decision-making trial in this section.
To clearly illustrate the transition from exploration to exploitation, which is the essential aspect of the
MABproblem,weemploytheconfigurationsofparametersoftheCMABproblemanddecentralizedcoupling
adjustment (DCA)showninTable3 ascontrolconditions. Hitprobabilitiesof slotmachinesarethe sameas
the setting shown in Table 1. Therefore, selecting Slots B and C is an optimal and correct option. Scaling
factor r and lower and upper bound of coupling strengths κ and κ are the hyperparameters of the
step low upp
DCA method, whose influence will be discussed in detail in Sec. 3.3.
Thedecision-makingintervalissetto 1.0ns. Ourpreliminaryanalysisindicatesthatthedecision-making
frequency should be comparable to or slower than the coupling delay time τ. Otherwise, consecutive slot
selectionsarepositivelycorrelated,leadingtoineffectiveexplorationandmorePlaysrequiredforappropriate
exploitation.
Figure 3 presents the numerical simulation results of a single decision-making trial. Figure 3 (a) shows
the short-term cross-correlation (STCC) values. Overall, the waveforms of C and C , C and C , and
1A 2B 1B 2C
C and C remain synchronized due to the consistent three-cluster synchronization. Therefore, as shown
1C 2A
in Fig. 3 (b), Players 1 and 2 always select different slots, completely avoiding conflicts.
Table 3: Parameters of the competitive multi-armed bandit (CMAB) problem and decentralized coupling
adjustment (DCA) used in Sec. 3.1.
Symbol Parameter Value
(PA,PB,PC) Hitprobabilitiesofslots (0.4,0.6,0.6)
rstep Scalingfactor 1.0
κ Lowerboundofcouplingstrength 38ns−1
low
κupp Upperboundofcouplingstrength 45ns−1
7(a)
(b)
Player 1
Player 2
(c)
(d)
Figure 3: Numerical simulation results of a single trial of decision-making. (a) Short-term cross-correlation
(STCC). (b) Slot machines selected by Player 1 (red) and Player 2 (black). (c) The excess hit probabilities
of slots Q and Q (X=A,B,C). (d) Total coupling strengths κ =r r κ (♯=bl,or,ye).
1,X 2,X ♯ 1♯ 2♯
In the first approximately 60 Plays, the relative order of C , C , and C , and that of C , C , and
1A 1B 1C 2A 2B
C , frequently change, as shown in Fig. 3 (a). Hence, players explore three options in turn, as shown in
2C
Fig. 3 (b). The fluctuations in the excess hit probabilities of slots Q and Q (X=A,B,C) in response
1,X 2,X
totheactualreceivedrewardsareshowninFig.3(c). BasedontheseQ andQ , Players1and2adjust
1,X 2,X
the attenuation rates r and r (♯ = bl,or,ye) according to DCA, and the resulting coupling strengths
1♯ 2♯
κ =r r κ fluctuate in the exploration phase, as shown in Fig. 3 (d).
♯ 1♯ 2♯
Subsequently, after the exploration of roughly 60 Plays, C and C are the smallest in most cases,
1B 2C
indicating that Lasers 1B and 2C are leading. Thus, players primarily select the optimal option, Slots B and
C,asshowninFig.3(a)and(b). Asexpected,theexcesshitprobabilitiesforthebestandsecondslot,Q ,
1,B
Q , Q , and Q , become positive, while those for the worst slot, Q and Q , become negative (see
1,C 2,B 2,C 1,A 2,A
Fig. 3 (c) after around 60 Plays). Therefore, as shown in Fig. 3 (d), κ converges to κ =38ns−1 whereas
bl low
κ and κ converge to κ =45ns−1, resulting in the appropriate focused selections of slots.
or ye upp
Thus, in the case of (P ,P ,P ) = (0.4,0.6,0.6), our proposed algorithm operates as intended and can
A B C
successfully solve the CMAB problem. However, it is necessary to evaluate the decision-making performance
under various problem scenarios to demonstrate the robustness of the system.
83.2 Impact of reward distributions
In this section, we investigate the behavior of our proposed decentralized coupling adjustment (DCA) under
variousrewarddistributionstovalidateitsrobustness. Forsimplicity,weassumehenceforththattheoptimal
combination remains Slots B and C. Considering the probabilistic nature of both the chaotic-laser-based
decision-making system and the rewards from slot machines in the competitive multi-armed bandit (CMAB)
problem, performance should be assessed as an average over multiple trials.
Weintroducethecorrectdecisionratio(CDR)[10]andregretasperformancemetrics. CDR(m)isdefined
by the ratio at which players correctly select the most profitable set of slot machines at m-th Play over a
predefinednumberoftrials. Eachtrialconsistsof1000Playsofdecision-making,andthisprocessisrepeated
for 2000 trials, with the six lasers randomly initialized each time. A faster convergence of CDR to a value
closerto1.0indicatesabetterperformance. Regretisthedifferencebetweentheexpectedcumulativereward
fortheperfectselectionsandtheaverageactualreward. Theteam’sexpectedrewardfortheperfectselections
in 1000 Plays is denoted as R∗ = (P +P )×1000, where P and P represent the hit probability
1st 2nd 1st 2nd
of the best and second-best slot, respectively. The actual reward averaged over 2000 trials is denoted as R.
We employ absolute regret R∗−R as well as relative regret (R∗−R)/R∗. Lower regret generally signifies a
better performance, but absolute regret depends strongly on the magnitude of R∗ as well.
Usingtheevaluationmetrics,wefirstassessthealgorithm’sperformanceforthefollowingfivesettings,in-
cludingthecontrolconditionaddressedinSec.3.1: (P ,P ,P )=(0.1,0.9,0.9), (0.2,0.8,0.8), (0.3,0.7,0.7),
A B C
(0.4,0.6,0.6), (0.45,0.55,0.55). These cases involve symmetrical hit probabilities for the top two slots, sim-
plifyingtheanalysisofthesystem’sbehavior. Thesmallerthedifferencebetweenthegoodandbadslots,the
more trials are required for accurate inferences. Therefore, it is expected that the learning speed is slower
with the narrower gap between P and P (=P ) if the algorithm is reasonable.
A B C
Figure 4 (a) illustrates the evolution of CDR with regard to Play for five different reward distributions
with symmetric hit probabilities for the top two slots. As shown in Fig. 4 (a), CDR gradually increases with
the number of Plays and converges to a value slightly greater than 0.95 as the number of Plays reaches 1000,
except for (P ,P ,P ) = (0.45,0.55,0.55) case. When the difference between reward probabilities becomes
A B C
larger,itiseasiertoidentifygoodandbadslots. Indeed,theproposedDCAmethodisabletoquicklyswitch
to exploitation in such cases, as one expects from an MAB algorithm. Even with a challenging setting like
the 0.45 versus 0.55 situation, CDR clearly keeps rising, indicating the effectiveness of our proposed DCA
method.
Next,tofurtherdiscussthesystem’scharacteristics,performanceevaluationsforthefollowingfiveconfigu-
rations are conducted: (P ,P ,P )=(0.1,0.3,0.9), (0.1,0.3,0.5), (0.1,0.3,0.3), (0.1,0.5,0.3), (0.1,0.9,0.3).
A B C
Inconsistent behaviors can be observed when comparing such asymmetric configurations. They have com-
monly hit probabilities of 0.3 and 0.1 for the second and third-best slots. Also, these setups include pairs
that are essentially the same but differ in the order of slot allocations, namely, (P ,P ,P )=(0.1,0.3,0.9)
A B C
and (0.1,0.9,0.3), and (0.1,0.3,0.5) and (0.1,0.5,0.3). Ideally, the system is expected to exhibit consistent
behavior for these pairs due to their equivalence.
Figure 4 (b) shows the CDR changes against Play for the five reward distributions, including ones with
asymmetric hit probabilities. These problem configurations also exhibit a steady increase in CDR, val-
idating that the DCA method correctly operates in this regard. However, when comparing the results
for the pairs of equivalent problem setups, the outcomes shown in Fig. 4 (b) are not desirable. In set-
tings (P ,P ,P ) = (0.1,0.9,0.3) and (0.1,0.5,0.3), the convergence of the CDR is slower than in settings
A B C
(P ,P ,P ) = (0.1,0.3,0.9) and (0.1,0.3,0.5) despite their equivalent levels of difficulty. It is even slower
A B C
compared to the setting (P ,P ,P ) = (0.1,0.3,0.3), which is intuitively more challenging since the best
A B C
slot is even harder to identify there. This behavior can be attributed to the asymmetric leader probabilities
of lasers that mainly act as ‘laggards’ due to the unidirectional coupling in the six-laser network. Once stuck
in a wrong option, the ease of escaping from it can depend on the slight probability of the truly correct op-
tion being selected. Similar trends have been reported in the previous study on addressing the single-player
multi-armed bandit problem using a unidirectional ring-connected laser network [12]. While the previous
work has shown that the gap in CDR curves for rearranged orders of hit probabilities of slot expands with
more Plays, our proposed DCA is able to gradually diminish this difference, resulting in the convergence of
CDR to nearly the same value independent of the ordering of reward probabilities, as shown in Fig. 4 (b).
Table 4 displays CDR averaged over 1000 Plays, absolute regret, and relative regret in the numerical
simulations for various reward distributions. For (P ,P ,P ) = (0.3,0.7,0.7), while CDR remains consis-
A B C
9(a)
(b)
Figure 4: Correct decision ratio (CDR) for 2000 trials. Various reward distributions are applied. The
horizontal dotted line represents CDR = 0.95. (a) Five different reward distributions with symmetric hit
probabilities for the top two slots. (b) Five different reward distributions, including ones with asymmetry.
tently lower than for (0.1,0.9,0.9) and (0.2,0.8,0.8), absolute and relative regret are the lowest among the
three configurations. This reflects the fact that the reduced gap between good and bad slots can soften the
loss from incorrect decisions. Nevertheless, relative regret is increased for (P ,P ,P ) = (0.4,0.6,0.6) and
A B C
(0.45,0.55,0.55) due to slow learning, as evidenced by the gradual increase in CDR. The lower five settings
exhibit noticeably higher average CDR than (P ,P ,P ) = (0.45,0.55,0.55). However, relative regret is
A B C
worse because the difference in the expected rewards between the best and worst options is significant for
thesesettingswithasymmetrichitprobabilities,especiallyfor(P ,P ,P )=(0.1,0.5,0.3)and(0.1,0.9,0.3),
A B C
where the worst option is more frequently selected.
Overall,thenumericalsimulationshavedemonstratedthatlearningofourproposedDCAmethodrobustly
succeeds across various configurations. Naturally, the algorithm performance possibly varies depending on
the hyperparameters of DCA, whose dependence will be discussed in the following section.
3.3 Effects of hyperparameters
In this section, we examine how the hyperparameters of our proposed decentralized coupling adjustment
(DCA), described by Eqs. (6) and (7), influence the decision-making system’s performance. This analysis
revealsrequirementsforaneffectivesystemtoaddressthecompetitivemulti-armedbandit(CMAB)problem,
enabling us to enhance algorithm design. Hyperparameters of DCA are as follows: scaling factor r , the
step
lower and upper bound of coupling strength κ and κ . Also, there is flexibility in the definition of the
low upp
initial attenuation rate r . Here, we highlight only r and κ .
ini step low
First, we focus on scaling factor r . From Eq. (7), r corresponds to the proportion by which the
step step
attenuation rates r and r should be shifted from their baseline value r in relation to Q and Q
1♯ 2♯ ini 1,S(♯) 2,S(♯)
10Table 4: Mean of correct decision ratio (CDR) over 1000 Plays, absolute (abs.) regret, and relative (rel.)
regret in numerical simulations for various reward distributions.
(PA,PB,PC) MeanofCDR Abs. regret Rel. regret
(0.1,0.9,0.9) 0.956 35.1 0.020
(0.2,0.8,0.8) 0.953 28.3 0.018
(0.3,0.7,0.7) 0.942 22.8 0.016
(0.4,0.6,0.6) 0.887 22.4 0.019
(0.45,0.55,0.55) 0.752 24.6 0.022
(0.1,0.3,0.9) 0.919 27.5 0.023
(0.1,0.3,0.5) 0.921 20.3 0.025
(0.1,0.3,0.3) 0.908 18.2 0.030
(0.1,0.5,0.3) 0.903 25.8 0.032
(0.1,0.9,0.3) 0.892 38.2 0.032
Figure5: Correctdecisionratio(CDR)for2000trials. Sevendifferentvaluesofscalingfactorr areapplied
step
for a setting (P ,P ,P )=(0.4,0.6,0.6). The horizontal dotted line represents CDR=0.95.
A B C
(♯ = bl,or,ye). After sufficient exploration, Q and Q settle to certain values prescribed by the
1,S(♯) 2,S(♯)
problem setting (P ,P ,P ). The resultant r and r also converge to specific values or reach the lower
A B C 1♯ 2♯
or upper bound, r or r . The extent of exploitation is stronger when there is a significant difference
low upp
between coupling strengths, and thus, scaling factor r basically determines the strength of exploitation
step
after the exploration phase; exploitation can become insufficient when r is not large enough.
step
Figure 5 depicts the evolution of the correct decision ratio (CDR) as the number of Play progresses when
applying the control condition r =1.0 or less than that. The hit probabilities of slot machines are set to
step
(P ,P ,P )=(0.4,0.6,0.6). AlthoughCDRcurvesexhibitsimilarinitialriserates,thevaluesatwhichthey
A B C
converge vary depending on the value of r . The DCA method yields an overly exploratory strategy with
step
a low value of r , and CDR does not get sufficiently close to 1.0 despite the sufficient number of Plays, as
step
shown in Fig. 5.
Furthermore, therequiredminimumvalueofr alsodependsonthehitprobabilitiesofslotssincethey
step
affect the behavior of Q and Q . If the difference between the good and bad slots is significant, i.e.,
1,S(♯) 2,S(♯)
the problem is not challenging, Q and Q converge to the larger absolute values, and exploitation
1,S(♯) 2,S(♯)
naturally becomes stronger even if r is the same.
step
Figure 6 illustrates CDR averaged for the 991–1000th Plays for various r and (P ,P ,P ) config-
step A B C
urations. As predicted, a decrease in r leads to lower CDR values across all problem scenarios due
step
11Figure6: Theaverageof991–1000thPlay’scorrectdecisionratio(CDR)for2000trialsagainstscalingfactor
r . Five different reward distributions are applied.
step
to insufficient exploitation. Moreover, CDR values drop earlier with more challenging problems, such as
(P ,P ,P )=(0.4,0.6,0.6) or (0.45,0.55,0.55).
A B C
Next,wediscussthelowerboundofcouplingstrengthsκ . κ ,whichdeterminesthelowerlimitofthe
low low
(cid:112) (cid:112)
attenuation rates r ≡ κ /κ, accompanied by κ , which specifies the upper limit r ≡ κ /κ,
low low upp upp upp
works as a parameter that determines the balance between exploration and exploitation; if the difference
betweenκ andκ islarge,theprobabilityofselectingtheestimated-optimaloptionincreases,potentially
low upp
resulting in more effective exploitation. However, an excessively exploitative strategy can lead to incorrect
estimations and getting stuck to ineffective options, especially in challenging problem settings. Ideally, κ
low
and κ should be explored in two dimensions, but our preliminary examination has revealed that the
upp
optimal value of κ shifts according to κ , and thus, we focus solely on κ for simplicity.
low upp low
Figure 7 illustrates the changes in CDR with the accumulation of Plays for six different settings of the
lower bound of coupling strength κ , including the control condition, κ = 38ns−1. Generally, the
low low
lower value of κ , that is, the larger the difference between κ and κ , the faster the initial increase
low low upp
in CDR. However, the subsequent behavior depends on the specific problem configuration. For the setting
of (P ,P ,P ) = (0.2,0.8,0.8) shown in Fig. 7 (a), CDR converges to the highest value among the six
A B C
configurations with κ = 34ns−1. In the κ = 40ns−1 setting, the CDR curve quickly saturates, and
low low
the eventual value is the lowest, resulting from an excessively exploratory strategy. On the other hand, for
the challenging configuration (P ,P ,P ) = (0.4,0.6,0.6), shown in Fig. 7 (b), κ = 38ns−1 exhibits the
A B C low
highest CDR after 1000 Plays. With the configurations of κ = 30ns−1, 32ns−1, and 34ns−1, players
low
overexploit early selections, leading to getting stuck on incorrect selections and significantly lower CDR
values. Evenso,CDRcurvesgraduallykeeprecoveringsincetheprobabilityofselectingestimatedsuboptimal
options is not zero. Thus, there is a possibility that the setting of κ = 30ns−1 can outperform that of
low
κ =38ns−1 in terms of CDR after further Plays.
low
Figure 8 shows the average of CDR at 991–1000th Play for various κ and (P ,P ,P ) configurations.
low A B C
Anexploitativestrategywithκ =30ns−1iseffectivefor(P ,P ,P )=(0.1,0.9,0.9),whereasadeliberate
low A B C
approach with κ =38ns−1 yields better results for (P ,P ,P )=(0.4,0.6,0.6) and (0.45,0.55,0.55).
low A B C
Therefore,theappropriateκ andκ greatlydependonthenumberofPlaysandtheacceptablelower
low upp
limitofCDRorupperlimitofregret. Additionally,thereispotentialforplayerstopickabetterconfiguration
depending on whether they can roughly estimate the hit probabilities of slot machines beforehand.
12(a)
(b)
Figure 7: Correct decision ratio (CDR) for 2000 trials. Six different values of the lower bound of coupling
strength κ are applied. κ determines the lower limit of the attenuation rates r . The horizontal
low low low
dotted line represents CDR = 0.95. (a) The problem setting of (P ,P ,P ) = (0.2,0.8,0.8). (b) The
A B C
problem setting of (P ,P ,P )=(0.4,0.6,0.6).
A B C
Figure8: Theaverageof991–1000thPlay’scorrectdecisionratio(CDR)for2000trialsagainstscalingfactor
κ . Five different reward distributions are applied.
low
134 Conclusion
We focused on collective decision-making utilizing a cluster-synchronized laser network [16, 17] for address-
ing the competitive multi-armed bandit (CMAB) problem, one of the most fundamental configurations of
multi-agent reinforcement learning (MARL). We proposed a six-laser network and decentralized coupling
adjustment (DCA), extending the system in the earlier research and enabling it to resolve the two-player
andthree-slotCMABproblemwithaphotonic-basedandstraightforwardlearningalgorithm. Ournumerical
simulations demonstrated that the laser network exhibits three-cluster synchronization as intended and that
the learning algorithm effectively adapts the optical attenuation rate based on observed slot probabilities in
a distributed manner. The average performance evaluation verified that learning steadily progressed regard-
less of various reward distributions and examined the effects of hyperparameter configurations of the DCA
method.
We treated the CMAB problem with two players and three slots as the minimal setting under the con-
ditions requiring exploitation. Our preliminary analysis has implied that the problem with increased players
andslotscanbemanagedbyfurtherenlargingthelasernetworkandincreasingthenumberofclusters. How-
ever,thestraightforwardexpansionleadstoaprohibitiveincreaseintherequirednumberoflasers,indicating
the need for new principles for selecting slots other than the one based on the leader-laggard relationship.
We dealt with a time-invariant reward environment for simplicity. Time-varying environments can also
be addressed by modifying the DCA method to estimate the hit probabilities of slot machines solely from
the recent slot selection results or by introducing a memory parameter.
Funding
This research was funded in part by the Japan Society for the Promotion of Science through Grant-in-
Aid for Research Activity Start-up (22K21269), Grant-in-Aid for Early-Career Scientists (23K16961), and
Transformative Research Areas (A) (JP22H05197).
Disclosures
The authors declare no conflicts of interest.
Data Availability
Dataunderlyingtheresultspresentedinthispaperarenotpubliclyavailableatthistimebutmaybeobtained
from the authors upon reasonable request.
References
[1] R. S. Sutton and A. G. Barto, Reinforcement learning: An introduction (MIT Press, 1998).
[2] M. Tan, Multi-agent reinforcement learning: Independent vs. cooperative agents, in Proceedings of the
tenth international conference on machine learning (1993) pp. 330–337.
[3] P.StoneandM.Veloso,Multiagentsystems: Asurveyfromamachinelearningperspective,Autonomous
Robots 8, 345 (2000).
[4] L. Canese, G. C. Cardarilli, L. Di Nunzio, R. Fazzolari, D. Giardino, M. Re, and S. Spanò, Multi-agent
reinforcement learning: A review of challenges and applications, Applied Sciences 11, 4948 (2021).
[5] K.Zia,N.Javed,M.N.Sial,S.Ahmed,A.A.Pirzada,andF.Pervez,Adistributedmulti-agentrl-based
autonomous spectrum allocation scheme in d2d enabled multi-tier hetnets, IEEE Access 7, 6733 (2019).
[6] S. Shalev-Shwartz, S. Shammah, and A. Shashua, Safe, multi-agent, reinforcement learning for au-
tonomous driving, arXiv preprint arXiv:1610.03295 (2016).
14[7] J.Wang,W.Xu,Y.Gu,W.Song,andT.C.Green,Multi-agentreinforcementlearningforactivevoltage
control on power distribution networks, Advances in Neural Information Processing Systems 34, 3271
(2021).
[8] L.Lai,H.Jiang,andH.V.Poor,Mediumaccessincognitiveradionetworks: Acompetitivemulti-armed
banditframework,in2008 42nd Asilomar Conference on Signals, Systems and Computers (IEEE,2008)
pp. 98–102.
[9] H.Robbins,Someaspectsofthesequentialdesignofexperiments,BulletinoftheAmericanMathematical
Society 58, 527 (1952).
[10] M. Naruse, W. Nomura, M. Aono, M. Ohtsu, Y. Sonnefraud, A. Drezet, S. Huant, and S.-J. Kim,
Decision making based on optical excitation transfer via near-field interactions between quantum dots,
Journal of Applied Physics 116, 1 (2014).
[11] M. Naruse, Y. Terashima, A. Uchida, and S.-J. Kim, Ultrafast photonic reinforcement learning based
on laser chaos, Scientific Reports 7, 1 (2017).
[12] T. Mihana, K. Fujii, K. Kanno, M. Naruse, and A. Uchida, Laser network decision making by lag
synchronization of chaos in a ring configuration, Optics Express 28, 40112 (2020).
[13] K.Morijiri,K.Takehana,T.Mihana,K.Kanno,M.Naruse,andA.Uchida,Parallelphotonicaccelerator
for decision making using optical spatiotemporal chaos, Optica 10, 339 (2023).
[14] N.Chauvet,D.Jegouso,B.Boulanger,H.Saigo,K.Okamura,H.Hori,A.Drezet,S.Huant,G.Bachelier,
and M. Naruse, Entangled-photon decision maker, Scientific Reports 9, 1 (2019).
[15] T. Mihana, K. Kanno, M. Naruse, and A. Uchida, Photonic decision making for solving competitive
multi-armedbanditproblemusingsemiconductorlasernetworks,NonlinearTheoryandItsApplications,
IEICE 13, 582 (2022).
[16] H. Ito, T. Mihana, R. Horisaki, and M. Naruse, Conflict-free joint decision by lag and zero-lag synchro-
nization in laser network, Scientific Reports 14, 4355 (2024).
[17] S. Kotoku, T. Mihana, R. André, R. Horisaki, and M. Naruse, Asymmetric leader-laggard cluster syn-
chronization for collective decision-making with laser network, Optics Express 32, 14300 (2024).
[18] K.Kitayama,M.Notomi,M.Naruse,K.Inoue,S.Kawakami,andA.Uchida,Novelfrontierofphotonics
for data processing—photonic accelerator, APL Photonics 4, 090901 (2019).
[19] T. Heil, I. Fischer, W. Elsässer, J. Mulet, and C. R. Mirasso, Chaos synchronization and spontaneous
symmetry-breaking in symmetrically delay-coupled semiconductor lasers, Physical Review Letters 86,
795 (2001).
[20] K. Kanno, T. Hida, A. Uchida, and M. Bunsen, Spontaneous exchange of leader-laggard relationship in
mutually coupled synchronized semiconductor lasers, Physical Review E 95, 052212 (2017).
[21] I. Fischer, R. Vicente, J. M. Buldú, M. Peil, C. R. Mirasso, M. Torrent, and J. García-Ojalvo, Zero-lag
long-range synchronization via dynamical relaying, Physical review letters 97, 123902 (2006).
[22] M. Nixon, M. Friedman, E. Ronen, A. A. Friesem, N. Davidson, and I. Kanter, Synchronized cluster
formation in coupled laser networks, Physical review letters 106, 223901 (2011).
[23] T. Dahms, J. Lehnert, and E. Schöll, Cluster and group synchronization in delay-coupled networks,
Physical Review E 86, 016202 (2012).
[24] L.M.Pecora,F.Sorrentino,A.M.Hagerstrom,T.E.Murphy,andR.Roy,Clustersynchronizationand
isolated desynchronization in complex networks with symmetries, Nature Communications 5, 1 (2014).
[25] P. Auer, N. Cesa-Bianchi, and P. Fischer, Finite-time analysis of the multiarmed bandit problem, Ma-
chine Learning 47, 235 (2002).
15[26] R.LangandK.Kobayashi,Externalopticalfeedbackeffectsonsemiconductorinjectionlaserproperties,
IEEE Journal of Quantum Electronics 16, 347 (1980).
[27] S.-J. Kim, M. Aono, and E. Nameda, Efficient decision-making by volume-conserving physical object,
New Journal of Physics 17, 083023 (2015).
[28] K.LiuandQ.Zhao,Distributedlearninginmulti-armedbanditwithmultipleplayers,IEEEtransactions
on signal processing 58, 5667 (2010).
[29] D. Kalathil, N. Nayyar, and R. Jain, Decentralized learning for multiplayer multiarmed bandits, IEEE
Transactions on Information Theory 60, 2331 (2014).
[30] P. Landgren, V. Srivastava, and N. E. Leonard, Distributed cooperative decision making in multi-agent
multi-armed bandits, Automatica 125, 109445 (2021).
[31] S.-J. Kim, M. Naruse, and M. Aono, Harnessing the computational power of fluids for optimization of
collective decision making, Philosophies 1, 245 (2016).
16