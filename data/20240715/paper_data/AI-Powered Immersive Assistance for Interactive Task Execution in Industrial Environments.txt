AI-Powered Immersive Assistance for Interactive
Task Execution in Industrial Environments
TomislavDuricica,*,PeterMüllnera,NicoleWeidingera,NevenElSayeda,DominikKowalda,b and
EduardoVeasa,b
aKnow-CenterGmbH
bGrazUniversityofTechnology
Abstract. Many industrial sectors rely on well-trained employ- In response, our approach, showcased on a virtual juice mixer
ees that are able to operate complex machinery. In this work, we testbedthatisadigitaltwin[22]ofanactualphysicalsetup,aims
demonstrate an AI-powered immersive assistance system that sup- todemonstratehowAIassistantscanofferascalableandeffective
portsusersinperformingcomplextasksinindustrialenvironments. solution to these challenges and enhance interactive task execution
Specifically,oursystemleveragesaVRenvironmentthatresembles acrossawidearrayofindustrialapplications.
ajuicemixersetup.Thisdigitaltwinofaphysicalsetupsimulates The novelty of our approach lies in deploying an interactive AI
complex industrial machinery used to mix preparations or liquids assistant powered by a large language model (LLM) that uses au-
(e.g., similar to the pharmaceutical industry) and includes various diotranscriptstodynamicallygeneratestep-by-stepguidanceforim-
containers,sensors,pumps,andflowcontrollers.Thissetupdemon- mersiveandintuitivetraining.Thesetranscriptsareextractedfroma
strates our system’s capabilities in a controlled environment while videoofanexpertperformingthetaskinaVRenvironmentandserve
actingasaproof-of-conceptforbroaderindustrialapplications.The astheprimarycontextforguidance.Thevirtualtestbedreplicatesthe
corecomponentsofourmultimodalAIassistantarealargelanguage setupofitsphysicalcounterpart,ensuringthatoursimulationsand
model and a speech-to-text model that process a video and audio trainingscenariosalignwithreal-worldoperations[10].TheLLM-
recordingofanexpertperformingthetaskinaVRenvironment.The based assistant processes both text and speech inputs, dynamically
videoandspeechinputextractedfromtheexpert’svideoenablesitto adaptingoutputstoaddressuserneedsateachstep.
providestep-by-stepguidancetosupportusersinexecutingcomplex ByimplementingthissystemonaVRplatform,wedemonstrate
tasks.ThisdemonstrationshowcasesthepotentialofourAI-powered thepracticalapplicationofourAIassistantinsimplifyingcomplex
assistanttoreducecognitiveload,increaseproductivity,andenhance industrial tasks and its potential to improve operational efficiency
safetyinindustrialenvironments. andlearningeffectiveness.Thispaperdetailstheimplementationand
useofourassistant,illustratinghowitintegrateswithVRtoprovide
immersive, intuitive support for industrial operations. Through this
1 Introduction
exploration,wecontributetothediscourseonAI’sroleinindustrial
Astheindustrialsectorcontinuestoembracetechnologicaladvance- automation, offering insights into its potential to improve interac-
ments, integrating Artificial Intelligence (AI) into operational pro- tions with complex machinery. In the next section, we outline the
cesses has become a key driver of efficiency, safety, and innova- challengesofintegratingimmersivetechnologiesintoindustrialop-
tion[21].Inthisvein,thispaperintroducesanAIassistantdesigned erationsandtheroleofAIinenhancingsafetyandefficiency.
for immersive training, leveraging the synergies of multimodal AI
andVirtualReality(VR)technologytosupporttaskexecutionwithin
2 Background
industrial environments. The motivation for such tools arises from
theincreasingcomplexityofindustrialmachinery,whichburdensop-
IndustrialImmersiveEnvironments.Theintegrationofimmersive
eratorswithacognitiveloadthatcancompromisebothproductivity
technologies, such as digital twins and VR, into industrial settings
andsafety[4].Additionally,thereisaneedtoimprovemachineoper-
representsaparadigmshiftinhowoperationsandtrainingarecon-
atortrainingandadaptabilityinthefaceofevolvingindustrialstan-
ducted. Digital twins offer a digital representation of physical sys-
dardsandpractices,whilealsoprovidingsupportinsituationswhere
tems, enabling real-time monitoring, simulation, and control of in-
aknowledgeableexpertisunavailable[16].
dustrialprocesseswithoutdirectphysicalinteraction[10,23].Simul-
Furthermore, additional challenges include the unavailability of
taneously,VRhasemergedasacrucialtoolforimmersivetraining,
physical machinery for training due to cost, the infrequent nature
allowingoperatorstoexperienceandinteractwithcomplexmachin-
ofcertaintasksperformedbyexpertsonlyduringassembly,andthe
eryinasafe,virtualenvironmentbeforeapplyingtheseskillsinthe
significant need for upskilling in an ever-changing job market [6].
realworld[8,18,7].Thesetechnologieshavenotonlystreamlined
These challenges underscore the importance of creating a flexible
operational procedures but also significantly minimized risks, con-
andcomprehensivevirtualsolution,allowingtraineestoexperience
tributingtoasaferandmoreefficientindustrialenvironment[26,2].
keyactivitiesinasafe,immersiveenvironment[17].
ChallengesinIndustrialOperationsandtheRoleofAI.Despite
∗CorrespondingAuthor.Email:tduricic@know-center.at. advancementsinimmersivetechnologies,industrialoperationscon-
4202
luJ
21
]CH.sc[
1v74190.7042:viXratinue to face significant challenges. Increasing complexity of ma-
chineryandrapidtechnologicalandregulatorychangesdemandex-
pertiseandflexibilityfromoperators[19,20,1].Thesechallenges,
coupledwiththepotentialforhumanerrorunderhighcognitiveload,
underscoretheneedforinnovativesolutionstosupportoperatorsin
real-timedecision-makingandtaskexecution.Moreover,thepoten-
tialunavailabilityofexperts,duetodistanceorschedulingconflicts,
furthercomplicatesthesechallenges,underscoringtheimportanceof
an autonomous guidance system [25, 4, 15]. Our goal is to enable
trainees to access prerecorded information contextualized to their
Figure1:OverviewofthevirtualjuicemixingsetupinVR.Keycom-
needs on the fly. Notable attempts in the past relied on continuous
ponentsarehighlighted:(1)JuiceMixer,(2)JuiceStation,(3)Spare
trackingofvisualattention,coupledwiththerecognitionoffocused
PartStation,and(4)Controller/Handsasinput,whichillustratesthe
objects,toretrievevideosnippets[13].Anotherattemptintroduced
userinteractionwithintheimmersiveenvironment.
anewbenchmarkdatasetandexploredtheuseoffoundationmodels
• Preparation:Usersselectandpickupacontainer,placingitunder
toaddresssimilarchallenges[3].
aspoutatthejuicestation,wherethecontainerisautomatically
AIhasemergedasakeyenablerinovercomingtheseobstaclesby
filledwiththeirchosentypeofjuice.Avisualindicatorshowsthe
augmentinghumancapabilitieswithintelligent,context-awareassis-
filllevelofthecontainer.
tance. Leveraging AI, industries can create systems capable of an-
• Assembly: Once filled, users attach the lid and relevant sensors
alyzing complex data to offer predictive insights, automate routine
(temperatureandpHsensors)tothecontainer.Atthisstage,they
tasks,andprovideadaptive,step-by-stepguidancetailoredtotheop-
alsoconnectatubefromthepumptothecontainer,enablingthe
erator’scurrenttaskandenvironment[12,9].ThefusionofAIwith
forthcomingmixingprocess.Thesecomponentsaredesignedfor
immersive technologies paves the way for a new generation of as-
easyattachmentthroughintuitivecontrolleractions,enhancingthe
sistancesystemsthataremoreintuitive,interactive,andcapableof
realismofthesimulation.
significantlyreducingthecognitiveloadonoperators,thusmitigat-
• Mixing:Withthesetupcomplete,theuserproceedstothemixing
ingtherisksassociatedwithcomplexindustrialoperations[24,5].
stage,interactingwithvirtualknobstoadjustthepump’sstrength
This evolving landscape of industrial settings, coupled with the
andoperationalmode.Theprocessprovideshands-onexperience
transformativecapabilitiesofAI,laysthegroundworkforbuilding
inmanagingthemixingintensityandduration,closelyreplicating
andshowcasingoursystem.Ourapproachgoesbeyondmererecog-
theactualoperationalcontrols.
nitionofactualcontextandallowstraineestoposequeriesandinter-
• FinalSteps:Aftermixing,usersexaminethefinalmixture,assess-
actwiththecontentguidedbyamultimodalAIassistant.
ingtheoutcomeoftheirefforts.Thisstepnotonlyconcludesthe
task flow but also reinforces the learning objectives by enabling
3 DemoSetup userstodirectlyobservetheresultsoftheiractions.
ThelivedemonstrationshowcasesourAI-poweredimmersiveassis-
Thissimulationprovidesuserswithacomprehensiveunderstand-
tancesysteminVR.Usersexperienceaninteractivesetupfeaturing
ingofthejuicemixingprocesswithinacontrolled,risk-freevirtual
thevirtualjuicemixertestbed,designedtosimulateacomplexindus-
environment.Theinteractivesetupenhancestrainingefficacy,allow-
trialmachinewithcontainers,sensors,pumps,andflowcontrollers.
ing operators to master complex machinery operations without the
The demo provides participants with an immersive experience that
physicalriskstypicallyassociatedwithindustrialenvironments.
highlightstheAIassistant’scapabilities.Thevideoforthedemois
hosted on YouTube and is available at [https://www.youtube.com/
watch?v=iFdK_TUcVQs]. 4 AI-PoweredImmersiveAssistance
Development Framework. The system is developed using Unity1
and Oculus VR2, with Meta Quest3 serving as the primary device TheAIassistantsupportsimmersiveandinteractivejuicemixerop-
eration training. It uses a narrated expert video as input to guide
for the demonstration. The development process involves creating
trainees through an interactive assistant, allowing learning at their
anenvironmentthataccuratelyreplicatesthejuicemixingoperation,
own pace when direct expert interaction is unavailable. Next, we
allowing users to interact with virtual components and understand
delve into the implementation details (as depicted in Figure 2) of
thetask’soperationalprinciples.
theAIassistantanduserinteractionswithintheVRenvironment.
JuiceMixerDigitalTwin.InourVRsetup,thejuicemixer,juice
ExpertVideoCreationandProcessing.ThedevelopmentofourAI
station,andsparepartstationformthecoreoftheinteractiveenvi-
assistantformachineoperationtrainingstartswithcapturingavideo
ronmentsimulatingthejuicemixingprocess(seeFigure1).Thejuice
ofanexpertperformingthetaskintheVRenvironment.Theexpert
mixerresemblesamachineusedinpharmaceuticalandchemicaldo-
narratesandexplainstheiractionsstepbystepduringthetask.This
mains.Thissetupallowsuserstointeractwithdigitaltwin,helping
narrationisessentialforcapturingdetailedinstructionsandinsights
themgrasptheoperationalprinciplesandfunctionalitiesofthejuice
for learning. After recording, the audio is transcribed into text us-
mixingoperationinanimmersivemanner.
ingtheOpenAIspeech-to-textmodel4,withtimestampsincludedto
OperationalTaskFlow.Thetaskflowisstructuredtoguideusers
preservesequenceinformation.Thistranscriptisthenconvertedinto
throughthejuicemixingprocessinasequentialandlogicalmanner,
a JSON format, serving as the primary input for generating the AI
utilizingVRcontrolsforinteractionwiththevirtualequipment:
assistant’sinstructionalcontent.
1https://unity.com/ CreatinganLLM-BasedAssistant.UsingtheOpenAIAssistants
2https://developer.oculus.com/
3https://www.meta.com/at/en/quest/products/quest-2/ 4https://platform.openai.com/docs/guides/speech-to-textFigure2:System-level(left)anduser-level(right)perspectiveoftheimmersiveAIassistant.Theassistantneedsanexperttoperformthetask,
andtheexpert’snarrationistranscribedtotext,whichservesascontextfortheLLM.Giventhiscontextandtextorspeechinputfromthe
user,theLLMgeneratesmultimodalinstructionsthatguidetheuserthroughthetask.TheseinstructionsarepresentedtotheuserwithinaVR
environmentwithmediacontrols,textcommandinput,andvoiceinteractiontofacilitateuserengagementwiththeAIAssistant.
API5,weemploytheGPT-4languagemodeltopowerourAIassis- componentsforinteraction,illustratedinFigure2:
tant,whichenhancestheuserexperiencebyallowinginteractiveand
• InputTextbox:Allowsuserstotypetheirprompts,facilitatingtex-
intuitivecommunication.Thetranscript,alreadyformattedinJSON
tualcommunicationwiththeAIassistant.
from the expert’s narrated video, provides a rich context that the
• AudioInputOption:Enablesspeechinput,withrecordingstran-
LLMusestoguideusersthroughthejuicemixingprocessintheVR
scribedtotextviaOpenAI’sspeech-to-textmodel6.Transcriptions
setting.Thisapproachenablesustocapturetheexpert’sknowledge
appearintheinputtextboxforrevieworediting.
effectivelywhilesimplifyingtheuser’sinteractionwiththesystem,
• ResponseDisplayandAudioOutput:Afterquerysubmission,the
enablingthemtoaskquestionsandreceiveinstructionsthatarecon-
AIassistantprocessesthepromptanddisplaystheresponseinan
textuallyawareandpreciselytimed.
output textbox. Simultaneously, the response is converted from
DefiningAIAssistantBehaviorandCommunication.TheAIas- texttospeech7,providingaudiofeedback.
sistant’sbehaviorandcommunicationstyleissimplydefinedbyaset • VideoPanelIntegration:Thevideopaneldisplaysclipsfromthe
ofexplicitinstructionsusingnaturallanguagewithintheOpenAIAs- expertvideobasedontheAIassistant’stimestampedresponses,
sistantsplatform.Theseinstructionsdictatethattheassistant’sroleis visuallydemonstratingthespecificstepsbeingdiscussed.
toguideusersthroughthejuicemixeroperationinVR,stepbystep.
Theassistantusesadetailedtranscriptascontext,timestampedand Themultimodalinterfaceallowsforflexibleuserinteractionwiththe
formattedinJSON,derivedfromanexpert’svideotutorial.TheAI AIassistant,utilizingtext,audio,andvideooutputs.Theintegration
assistantisinstructedwiththefollowingprimaryfunctions:(i)Guide of these components ensures that all users can effectively navigate
Users-Presentandsequentiallynavigatethroughthejuice-making andmasterthejuicemixingprocesswithintheVRenvironment,re-
steps,promptinguserstoconfirmcompletionbeforeproceeding.(ii) gardlessoftheirspecificlearningneedsorenvironmentalconditions.
Respond to Queries - Address user queries by referencing specific
partsofthetranscript,usingtimestampstoprovidecontextualaccu- 5 ConclusionandFutureWork
racy.(iii)TroubleshootIssues-Offersolutionsforcommonopera-
tionalchallengesasoutlinedinthetranscript. In this work, we presented an AI-powered immersive assistance
The assistant facilitates effective communication, ensuring each system to interactively support users in task training and execu-
usergainspracticalskillsanddeepunderstandingofthejuicemix- tion in industrial settings. Using a virtual juice mixer testbed, we
ingprocess.Initially,theassistantintroducesitself,outliningitsrole demonstratedthepotentialofoursystemtoenhanceproductivityand
andexplaininghowitassistsinthejuice-makingprocess.Itthencon- streamlinecomplexoperationaltasks.
tinuesguidingtheuser,respondingtoqueriesandprovidingdetailed Inthefuture,wewillinvestigatewaystosupportusersinamore
instructionsbasedonthestructuredcontentoftheexpert’snarration. preciseandeffectiveway.Forexample,byexamininghowtheuser
Eachresponseprovidesclearanddetailedinstructionsforthecur- interfacecanimpacttheuserbehavior,orbyincorporatingphysio-
rent task or query and includes precise timestamps that dictate the logical indicators. Also, novel large language models, e.g., GPT-4-
playbackwindowoftheexpert’svideointheuserinterface.Thistar- vision8, will enable us to extract multimodal embeddings from the
getedvideoplaybackvisuallyhighlightsthespecificstepbeingdis- experts’ video recordings, which could enhance the quality of the
cussed,enrichingthelearningexperiencebysynchronizinginstruc- contextual information and thus, improve the precision of the as-
tionalcontentwithrelevantvisualcues.Theassistantoperateswith- sistants’ guidance. Finally, we plan to combine our data-driven AI
outexternalknowledge,relyingentirelyontheexpert’svideocontent approachwithatheory-drivenone,e.g.,basedoncognitive-inspired
toensureasmoothandeffectivetrainingexperience. recommendersystems[11,14],toenhancethetransparencyandun-
InteractingwiththeAIAssistantTheuserinterfaceforengaging derstandabilityofourAI-poweredimmersiveassistant.
Acknowledgements.ThisworkwasfundedbytheFFGCOMET
withtheAIassistantisdesignedtobebothintuitiveanduser-friendly.
moduleData-DrivenImmersiveAnalytics(DDIA).
PositionednexttothevirtualjuicemixerwithintheVRenvironment,
the interface includes a dedicated panel that hosts several essential
6https://platform.openai.com/docs/guides/speech-to-text
7https://platform.openai.com/docs/guides/text-to-speech
5https://platform.openai.com/assistants/ 8https://platform.openai.com/docs/guides/visionReferences facilities. InOffshoreTechnologyConference,pageD011S003R003.
OTC,2022.
[22] M. Sjarov, T. Lechler, J. Fuchs, M. Brossog, A. Selmaier, F. Faltus,
[1] B.Alkan,D.A.Vera,M.Ahmad,B.Ahmad,andR.Harrison. Com- T.Donhauser,andJ.Franke.Thedigitaltwinconceptinindustry–are-
plexityinmanufacturingsystemsanditsmeasures:aliteraturereview. viewandsystematization. In202025thIEEEinternationalconference
EuropeanJournalofIndustrialEngineering,12(1):116–150,2018. onemergingtechnologiesandfactoryautomation(ETFA),volume1,
[2] A.Babalola,P.Manu,C.Cheung,A.Yunusa-Kaltungo,andP.Bartolo. pages1789–1796.IEEE,2020.
Asystematicreviewoftheapplicationofimmersivetechnologiesfor [23] P.StavropoulosandD.Mourtzis. Digitaltwinsinindustry4.0. InDe-
safetyandhealthmanagementintheconstructionsector. Journalof signandoperationofproductionnetworksformasspersonalizationin
safetyresearch,85:66–85,2023. theeraofcloudtechnology,pages277–316.Elsevier,2022.
[3] Y.Bao,K.P.Yu,Y.Zhang,S.Storks,I.Bar-Yossef,A.DeLaIgle- [24] B.Tiple,C.Bulchandani,I.Paliwal,D.Shah,A.Jain,C.Dhaka,and
sia,M.Su,X.L.Zheng,andJ.Chai. Canfoundationmodelswatch, V.Gupta. Aibasedaugmentedrealityassistant. InternationalJournal
talk and guide you step by step to make a cake? arXiv preprint ofIntelligentSystemsandApplicationsinEngineering,12(13s):505–
arXiv:2311.00738,2023. 516,2024.
[4] A. V. Carvalho, A. Chouchene, T. M. Lima, and F. Charrua-Santos. [25] Y.Torres,S.Nadeau,andK.Landau. Classificationandquantification
Cognitivemanufacturinginindustry4.0towardcognitiveloadreduc- ofhumanerrorinmanufacturing:Acasestudyincomplexmanualas-
tion: A conceptual framework. Applied System Innovation, 3(4):55, sembly.AppliedSciences,11(2):749,2021.
2020. [26] G.-D.Voinea,F.Gîrbacia,M.Duguleana˘,R.G.Boboc,andC.Ghe-
[5] V. Chheang, S. Sharmin, R. Márquez-Hernández, M. Patel, D. Ra- orghe. Mappingtheemergenttrendsinindustrialaugmentedreality.
jasekaran,G.Caulfield,B.Kiafar,J.Li,P.Kullu,andR.L.Barmaki. Electronics,12(7):1719,2023.
Towardsanatomyeducationwithgenerativeai-basedvirtualassistants
inimmersivevirtualrealityenvironments. In2024IEEEInternational
ConferenceonArtificialIntelligenceandeXtendedandVirtualReality
(AIxVR),pages21–30.IEEE,2024.
[6] S.CollinoandG.Lauto. Reducingcognitivebiasesthroughdigitally
enabledtraining.aconceptualframework. InDoMachinesDreamof
ElectricWorkers?UnderstandingtheImpactofDigitalTechnologieson
OrganizationsandInnovation,pages179–191.Springer,2022.
[7] N.Gavish,T.Gutiérrez,S.Webel,J.Rodríguez,M.Peveri,U.Bockholt,
andF.Tecchia.Evaluatingvirtualrealityandaugmentedrealitytraining
for industrial maintenance and assembly tasks. Interactive Learning
Environments,23(6):778–798,2015.
[8] R.B.Hasan,F.B.A.Aziz,H.A.A.Mutaleb,andZ.Umar. Virtual
realityasanindustrialtrainingtool:Areview. J.Adv.Rev.Sci.Res,29
(1):20–26,2017.
[9] M.Javaid,A.Haleem,R.P.Singh,andR.Suman. Artificialintelli-
genceapplicationsforindustry4.0:Aliterature-basedstudy.Journalof
IndustrialIntegrationandManagement,7(01):83–111,2022.
[10] Y.Jiang,S.Yin,K.Li,H.Luo,andO.Kaynak. Industrialapplications
ofdigitaltwins.PhilosophicalTransactionsoftheRoyalSocietyA,379
(2207):20200360,2021.
[11] D.Kowald,S.Kopeinik,P.Seitlinger,T.Ley,D.Albert,andC.Trattner.
Refiningfrequency-basedtagreusepredictionsbymeansoftimeand
semanticcontext. InMining,Modeling,andRecommending’Things’
in Social Media: 4th International Workshops, MUSE 2013, Prague,
CzechRepublic,September23,2013,andMSM2013,Paris,France,
May1,2013,RevisedSelectedPapers,pages55–74.Springer,2015.
[12] J.Leeetal. Industrialai. Applicationswithsustainableperformance,
2020.
[13] T.Leelasawassuk,D.Damen,andW.Mayol-Cuevas. Automatedcap-
tureanddeliveryofassistivetaskguidancewithaneyewearcomputer:
theglaciarsystem. InProceedingsofthe8thAugmentedHumanInter-
nationalConference,pages1–9,2017.
[14] E.Lex,D.Kowald,P.Seitlinger,T.N.T.Tran,A.Felfernig,M.Schedl,
etal. Psychology-informedrecommendersystems. Foundationsand
trends®ininformationretrieval,15(2):134–242,2021.
[15] M.Naef,K.Chadha,andL.Lefsrud. Decisionsupportforprocessop-
erators:Taskloadinginthedaysofbigdata.JournalofLossPrevention
intheProcessIndustries,75:104713,2022.
[16] J. Patalas-Maliszewska and S. Kłos. An approach to supporting the
selectionofmaintenanceexpertsinthecontextofindustry4.0.Applied
Sciences,9(9):1848,2019.
[17] U.Radhakrishnan,K.Koumaditis,andF.Chinello.Asystematicreview
ofimmersivevirtualrealityforindustrialskillstraining. Behaviour&
InformationTechnology,40(12):1310–1339,2021.
[18] N.Randeniya,S.Ranjha,A.Kulkarni,andG.Lu.Virtualrealitybased
maintenancetrainingeffectivenessmeasures–anovelapproachforrail
industry. In 2019 IEEE 28th International Symposium on Industrial
Electronics(ISIE),pages1605–1610.IEEE,2019.
[19] M.Rüßmann,M.Lorenz,P.Gerbert,M.Waldner,J.Justus,P.Engel,
andM.Harnisch.Industry4.0:Thefutureofproductivityandgrowthin
manufacturingindustries.Bostonconsultinggroup,9(1):54–89,2015.
[20] S.SahooandC.-Y.Lo. Smartmanufacturingpoweredbyrecenttech-
nologicaladvancements:Areview. JournalofManufacturingSystems,
64:236–250,2022.
[21] H. A. Shaji, S. K. Bishnu, T. Mishra, M. S. Ramakrishna, N. Kr-
ishnaRS,R.ThomasK,andD.R.David.Artificialintelligenceforau-
tomatingandmonitoringsafety,efficiencyandproductivityinindustrial