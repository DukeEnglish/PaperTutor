[
    {
        "title": "GNN with Model-based RL for Multi-agent Systems",
        "authors": "Hanxiao Chen",
        "links": "http://arxiv.org/abs/2407.09249v1",
        "entry_id": "http://arxiv.org/abs/2407.09249v1",
        "pdf_url": "http://arxiv.org/pdf/2407.09249v1",
        "summary": "Multi-agent systems (MAS) constitute a significant role in exploring machine\nintelligence and advanced applications. In order to deeply investigate\ncomplicated interactions within MAS scenarios, we originally propose \"GNN for\nMBRL\" model, which utilizes a state-spaced Graph Neural Networks with\nModel-based Reinforcement Learning to address specific MAS missions (e.g.,\nBilliard-Avoidance, Autonomous Driving Cars). In detail, we firstly used GNN\nmodel to predict future states and trajectories of multiple agents, then\napplied the Cross-Entropy Method (CEM) optimized Model Predictive Control to\nassist the ego-agent planning actions and successfully accomplish certain MAS\ntasks.",
        "updated": "2024-07-12 13:21:35 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.09249v1"
    },
    {
        "title": "Decentralized multi-agent reinforcement learning algorithm using a cluster-synchronized laser network",
        "authors": "Shun KotokuTakatomo MihanaAndré RöhmRyoichi Horisaki",
        "links": "http://arxiv.org/abs/2407.09124v1",
        "entry_id": "http://arxiv.org/abs/2407.09124v1",
        "pdf_url": "http://arxiv.org/pdf/2407.09124v1",
        "summary": "Multi-agent reinforcement learning (MARL) studies crucial principles that are\napplicable to a variety of fields, including wireless networking and autonomous\ndriving. We propose a photonic-based decision-making algorithm to address one\nof the most fundamental problems in MARL, called the competitive multi-armed\nbandit (CMAB) problem. Our numerical simulations demonstrate that chaotic\noscillations and cluster synchronization of optically coupled lasers, along\nwith our proposed decentralized coupling adjustment, efficiently balance\nexploration and exploitation while facilitating cooperative decision-making\nwithout explicitly sharing information among agents. Our study demonstrates how\ndecentralized reinforcement learning can be achieved by exploiting complex\nphysical processes controlled by simple algorithms.",
        "updated": "2024-07-12 09:38:47 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.09124v1"
    },
    {
        "title": "A Review of Nine Physics Engines for Reinforcement Learning Research",
        "authors": "Michael KaupCornelius WolffHyerim HwangJulius MayerElia Bruni",
        "links": "http://arxiv.org/abs/2407.08590v1",
        "entry_id": "http://arxiv.org/abs/2407.08590v1",
        "pdf_url": "http://arxiv.org/pdf/2407.08590v1",
        "summary": "We present a review of popular simulation engines and frameworks used in\nreinforcement learning (RL) research, aiming to guide researchers in selecting\ntools for creating simulated physical environments for RL and training setups.\nIt evaluates nine frameworks (Brax, Chrono, Gazebo, MuJoCo, ODE, PhysX,\nPyBullet, Webots, and Unity) based on their popularity, feature range, quality,\nusability, and RL capabilities. We highlight the challenges in selecting and\nutilizing physics engines for RL research, including the need for detailed\ncomparisons and an understanding of each framework's capabilities. Key findings\nindicate MuJoCo as the leading framework due to its performance and\nflexibility, despite usability challenges. Unity is noted for its ease of use\nbut lacks scalability and simulation fidelity. The study calls for further\ndevelopment to improve simulation engines' usability and performance and\nstresses the importance of transparency and reproducibility in RL research.\nThis review contributes to the RL community by offering insights into the\nselection process for simulation engines, facilitating informed\ndecision-making.",
        "updated": "2024-07-11 15:13:28 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.08590v1"
    },
    {
        "title": "Incorporating Large Language Models into Production Systems for Enhanced Task Automation and Flexibility",
        "authors": "Yuchen XiaJize ZhangNasser JazdiMichael Weyrich",
        "links": "http://dx.doi.org/10.51202/9783181024379",
        "entry_id": "http://arxiv.org/abs/2407.08550v1",
        "pdf_url": "http://arxiv.org/pdf/2407.08550v1",
        "summary": "This paper introduces a novel approach to integrating large language model\n(LLM) agents into automated production systems, aimed at enhancing task\nautomation and flexibility. We organize production operations within a\nhierarchical framework based on the automation pyramid. Atomic operation\nfunctionalities are modeled as microservices, which are executed through\ninterface invocation within a dedicated digital twin system. This allows for a\nscalable and flexible foundation for orchestrating production processes. In\nthis digital twin system, low-level, hardware-specific data is semantically\nenriched and made interpretable for LLMs for production planning and control\ntasks. Large language model agents are systematically prompted to interpret\nthese production-specific data and knowledge. Upon receiving a user request or\nidentifying a triggering event, the LLM agents generate a process plan. This\nplan is then decomposed into a series of atomic operations, executed as\nmicroservices within the real-world automation system. We implement this\noverall approach on an automated modular production facility at our laboratory,\ndemonstrating how the LLMs can handle production planning and control tasks\nthrough a concrete case study. This results in an intuitive production facility\nwith higher levels of task automation and flexibility. Finally, we reveal the\nseveral limitations in realizing the full potential of the large language\nmodels in autonomous systems and point out promising benefits. Demos of this\nseries of ongoing research series can be accessed at:\nhttps://github.com/YuchenXia/GPT4IndustrialAutomation",
        "updated": "2024-07-11 14:34:43 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.08550v1"
    },
    {
        "title": "United We Stand: Decentralized Multi-Agent Planning With Attrition",
        "authors": "Nhat NguyenDuong NguyenGianluca RizzoHung Nguyen",
        "links": "http://arxiv.org/abs/2407.08254v1",
        "entry_id": "http://arxiv.org/abs/2407.08254v1",
        "pdf_url": "http://arxiv.org/pdf/2407.08254v1",
        "summary": "Decentralized planning is a key element of cooperative multi-agent systems\nfor information gathering tasks. However, despite the high frequency of agent\nfailures in realistic large deployment scenarios, current approaches perform\npoorly in the presence of failures, by not converging at all, and/or by making\nvery inefficient use of resources (e.g. energy). In this work, we propose\nAttritable MCTS (A-MCTS), a decentralized MCTS algorithm capable of timely and\nefficient adaptation to changes in the set of active agents. It is based on the\nuse of a global reward function for the estimation of each agent's local\ncontribution, and regret matching for coordination. We evaluate its\neffectiveness in realistic data-harvesting problems under different scenarios.\nWe show both theoretically and experimentally that A-MCTS enables efficient\nadaptation even under high failure rates. Results suggest that, in the presence\nof frequent failures, our solution improves substantially over the best\nexisting approaches in terms of global utility and scalability.",
        "updated": "2024-07-11 07:55:50 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.08254v1"
    }
]