Intention Is All You Need
AdvaitSarkar
MicrosoftResearch, UniversityofCambridge,UniversityCollegeLondon
advait@microsoft.com
Abstract
Among the many narratives of the transformative power of Generative AI is one that sees in the world
alatentnationofprogrammers whoneedtowieldnothingbutintentions andnaturallanguage torender
theirideasinsoftware. Inthispaper,thisoutlookisproblematised intwoways. First,itisobservedthat
generative AIisnot aneutral vehicle ofintention. Multiple recent studies paint apicture ofthe“mech-
anised convergence” phenomenon, namely, that generative AI has a homogenising effect on intention.
Second, itis observed that the formation ofintention itself is immensely challenging. Constraints, ma-
teriality, and resistance can offer paths to design metaphors for intentional tools. Finally, existentialist
approaches to intention are discussed and possible implications for programming are proposed in the
formofaspeculative, illustrative setofintentional programmingpractices.
1. The“Intention Is All YouNeed” Picture ofProgramming with GenerativeAI
Whatisprogramming? Blackwell’ssuccinctandinfluentialdefinitionisthatprogrammingisanyactivity
exhibiting the property “that the user is not directly manipulating observable things, but specifying
behaviourtooccuratsomefuturetime”(Blackwell,2002). Behaviourisspecifiedthroughaninterface,
commonly anotation, whichwecall aprogramming language. Therein liesthesource andobjective of
allresearchinthepsychology anddesignofprogramming: thestudyoftheuseandimprovementofthe
interfaces, notations, andlanguages forspecifying behaviour.
ThevalueofsuchstudyiscalledintoquestionwiththeintroductionofGenerativeArtificialIntelligence
(GenAI), which can be defined as any “end-user tool [...] whose technical implementation includes a
generativemodelbasedondeeplearning”.1 GenAIcapturestherelationshipsbetweennaturallanguage
specificationsofbehaviour,andthetranslationsofthatbehaviourintoprogrammingnotation,implicitin
enormoustrainingdatasets. Thepoweroftranslationthuscapturedcanbestochasticallyreplayedonde-
mand(Blackwell,2020). Whatcouldthismeanforresearch intheuser-centred designofprogramming
languages? Oneperspective anticipates nothinglessthanitsobsolescence:
“The programming barrier [with GenAI] is incredibly low. We have closed the digital
divide. Everyoneisaprogrammernow-youjusthavetosaysomethingtothecomputer”2
“Upuntilnow,inordertocreatesoftware,youhadtobeaprofessional softwaredevel-
oper. Youhadtounderstand,speakandinterpretthehighlycomplex,sometimesnonsensical
language ofamachinethatwecallcode. [... ButwithGenAI]Wehavestruck anewfusion
between the language ofahuman and amachine. WithCopilot, any person can now build
software in any human language with a single written prompt. [...] going forward, every
person, no matter what language they speak, will also have the power to speak machine.
Anyhumanlanguage isnowtheonlyskillthatyouneedtostartcomputerprogramming.”3
1Thereisnodefinitionalconsensusonthisterm.ArationaleforthedefinitionadoptedhereisgivenbySarkar(2023d).
2Huang,2023.(Source:https://www.reuters.com/technology/ai-means-everyone-can-now-be-programmer-nvidia-c
accessedJuly2024.)
3Dohmke,2024.(Source:https://www.ted.com/talks/thomas_dohmke_with_ai_anyone_can_be_a_coder_now,
accessedJuly2024.)
1
4202
tcO
42
]CH.sc[
1v15881.0142:viXra“Since thelaunch ofGPT-4in2023, thegeneration of whole apps from simple natural
language requirementshasbecomeanactiveresearcharea. [...] Ourvisionisthatby2030
enduserswillbuildanddeploywholeappsjustfromnaturalrequirements.”4
“Programming will be obsolete. [...] the conventional idea of ‘writing a program’ is
headed forextinction [...] allprograms inthefuture willultimately bewritten byAIs, with
humans relegated to, at best, a supervisory role. [...] The engineers of the future will,
in a few keystrokes, fire up an instance of a four-quintillion-parameter model that already
encodes the full extent of human knowledge (and then some), ready to be given any task
requiredofthemachine.”5
ThepromiseofGenAIforprogramming, therefore, istotransform programming intoanactivity where
expertise in specialised notations and languages for specifying behaviour are unnecessary. One merely
hastosaywhatonewishestheprogramtodo,andGenAIdoestherest. Theinteractiondesignchallenges
ofprogramming aresolved.6 Intention isallyouneed.
There are many problems with this picture. There are compelling reasons for continuing to engage
with formal notations, even and perhaps especially when GenAI is in play (Sarkar, 2023d). Moreover,
languageingeneral,andthelanguageofpromptsusedtodirectGenAIinparticular,ismostcertainlynot
aflawless,transparentroutefortheexpressionofintent. Johnnycan’tprompt(Zamfirescu-Pereira etal.,
2023). Johnny can’t figureoutwhatlevelofabstraction towritehisprompts in,either(Liuetal.,2023;
Sarkaretal., 2022). Thinking about prompting is hard for Johnny, and thinking about thinking about
prompting ishard,too(Tankelevitch etal.,2024). Prompting“dialects” mightevolveinmuchthesame
way as specialised uses of natural language do in domains such as scientific and legal communication,
through disciplinary normsandprofessional consensus, andtoacquire suchlanguage willrequire users
toundergoanalogousprocessesofdisciplinaryandprofessionalacculturation(Sarkar,2023d). Butthese
problemsarenottheprimaryconcern inthispaper.
There is a rather more fundamental pair of problems with the idea that intention is all you need (to
program with GenAI): it assumes that GenAI does not interfere with intention. Moreover, it takes for
grantedthatintentions areeasytoform. Bothpremiseswillbequestioned inturn.
2. MechanisedConvergence: The HomogenisingEffect ofAI on Intention
Contrarytonotinterferingwithintention,AIsuppliesintention. Itdoessoinawaythatcanbedescribed
as mechanised convergence (Sarkar, 2023b), drawing on Walter Benjamin’s concept of mechanical re-
production (W.Benjamin, 1935). Mechanised convergence describes the idea that the automation or
mechanisation of work leads to a convergence inthe space of outputs. Standardisation is necessary for
factory logic to function. For a machine to be repeatable at speed, its inputs and outputs need to be
repeatable atspeed,too. Youcanhaveanycolouraslongasit’sblack.
HereissomeoftheevidencethatGenAIhasamechanised convergence effect:
• Predictive textencourages predictable writing (Arnoldetal.,2020). Inanimagecaptioning task,
whenparticipants use predictive textentry systems, captions writtenwithsuggestions areshorter
and use fewer words that the system does not predict. Asimilar effect occurs inidentifier names
when programmers use a GenAI tool such as GitHub Copilot to assist them in writing code
4Robinsonetal.(2024)
5Welsh(2022)
6Oneisremindedofsimilarclaimsmadeduringtheearlydaysofspreadsheetsoraboutanynumberofvisualprogramming
languages.E.g.,BenjaminRosen,aPCindustryanalystforMorganStanley,laterakeyfunderofLotusandCompaq,notedin
1979that“Inminutes,peoplewhohaveneverusedacomputerarewritingandusingprograms[...] theuserneednotknow
anythingabout computersorprogramminginordertoderiveVisicalc’sbenefits. YouconstructaVisicalcprogram muchas
youwoulddefineaproblemonasheetofpaperorablackboard”(Rosen,1979).
2(Leeetal., 2024). This effect occurs even when the suggestions are merely visible and not ac-
tionable (i.e.,cannotbeaccepted usingakeyboard shortcut).
• Similarly, a large study (n=293) of participants writing short stories with varying degrees of
AI assistance found that exposure to GenAI “ideas” leads to a reduced diversity of content
(Doshi&Hauser, 2023). Participants exposed to even a single GenAI suggestion produce sto-
riessimilartotheaverageoftheotherstoriesinthesameexperimental condition.
• A large study (n=758) of strategy consultants at BCG examined the effects of ChatGPT use on
a set of consultancy tasks (Dell’Acquaetal., 2023). The majority of participants with access to
ChatGPT retain a very high amount of its response – typically around 90% – in their submitted
work. Participants without access to ChatGPT produce ideas with more conceptual variation
thanthosewithaccess,showingthatusageofChatGPTreducestherangeofideasgenerated. The
variationacrossresponsesproducedbyChatGPTissmallerthanwhathumanparticipantsproduce
ontheirown.
• Large language models have a “homogenization effect” on creative ideation (Andersonetal.,
2024). In a creative ideation task, participants produce less semantically distinct ideas when
using ChatGPT. Moreover, participants feel less responsible for ideas produced with ChatGPT
assistance.
• Alargestudy(n=115)findsthatconversationalsearchbuiltonGenAIincreasesselectiveexposure
compared toconventional search(Sharmaetal.,2024). Usersengageinmorebiasedinformation
querying with conversational search, and the bias is exacerbated when the model is itself “opin-
ionated” toreinforce theuser’sviews. Theauthorscallthisa“generative echochamber”.
• Similarly, a large study (n=1506) of co-writing with GenAI found that using an “opinionated”
language model affects the opinions expressed in participants’ writing and moreover, actually
shifts their opinions asmeasured inasubsequent attitude survey (Jakeschetal.,2023). Arelated
effect, termed “drifting”, has been observed in novice programmers, where the tendency to ac-
cept and adapt code generated by the system leads programmers away from a correct solution
(Pratheretal.,2023).
Mechanised convergence signals an odd reversal (or perhaps intensification) of Dennett’s “intentional
stance” (Dennett, 1971), wherein we not only ascribe intention to these systems but also delegate it,
sometimeswilfully,othertimesunknowingly.
The intention supplied by GenAI through mechanised convergence has a complex source, combining
influencesofitstrainingdata,andthebiasesandheuristicsencodedbythesystemdevelopers. However
at its core, mechanised convergence is the ultimate outcome of the old statistical logics of uncovering
underlying natural “laws”(Blackwell,2020;Sarkar,2023a). Thestatistical machine eliminates “noise”
(diversity) topredict “signal” (uniformity). Thestatistical machine isthetriumph oftheEnlightenment
aesthetic faith in nature’s having an underlying elegance or simplicity that is obscured from view by
imperfect forms. Itshould comeasnosurprise that machines thatarebuilt tosearch forPlatonic ideals
reflectbacktousamechanically converged pictureoftheworld,makingquiddity ofhaecceity.
Itisimportanttonotethattheeffectonintentasdemonstrated inthesestudiesisanaggregate tendency
that likely does not square with individual phenomenal perceptions of GenAI use. At the granularity
of individual interactions, the experience of GenAI might well be as a passive translator, not active
supplier, of intent. The nudge towards standardised, centralised, averaged, generic, and statistically
optimisedanswersmaybebarelyperceptible. Yetthedatademonstratesthatthesenudgesinfacthavea
measurable cumulativeeffectonknowledgework.
AsWinner sets out, artefacts have politics (Winner, 1980). Thedesign features of a technology enable
certainformsofpower,andthedecisiontoadoptaparticulartechnologyrequirescertainpowerrelations
tobeenacted. PuttingitinWinner’sterms,convergence isthepolitics ofAI,theartefact.
3As McLuhan sets out, the medium is the message (McLuhan, 1964). There is an effect of a particular
medium, be it typography, radio, or television, on the human sensorium that is quite distinct from any
particular content being conveyed through that medium. The effect of the medium overwhelms the
content and makes it incidental. Putting it in McLuhan’s terms, convergence is the message of AI, the
medium.
McLuhan predicted that electric technology and programmability would reverse the convergence ten-
dencies offactory logic. Hegives theexampleofaprogrammable tailpipe machine: “Anewautomatic
machine for making automobile tailpipes [...] starting with lengths of ordinary pipe, it is possible to
makeeightydifferentkindsoftailpipeinsuccession, asrapidly,aseasily,andascheaplyasitistomake
eighty of the same kind. And the characteristic of electric automation is all in this direction of return
to the general-purpose handicraft flexibility that our own hands possess. The programming can now
includeendless changesofprogram.”
Taken to its logical conclusion, McLuhan makes a claim that is strikingly similar to the narrative that
intentionisallyouneed: “theoldermechanisticideaof“jobs,”orfragmentedtasksandspecialistslots
for “workers,” becomes meaningless under automation. [...] Thevery toil of mannow becomes akind
ofenlightenment. Asunfallen AdamintheGardenofEdenwasappointed thetaskofthecontemplation
and naming of creatures, so with automation. We have now only to name and program a process or a
product in order for it to be accomplished. Is it not rather like the case of Al Capp’s Schmoos? One
had only to look at a Schmoo and think longingly ofpork chops or caviar, and the Schmoo ecstatically
transformed itself into the object of desire. Automation brings us into the world of the Schmoo. The
custom-built supplants themass-produced.” Aswehave seen, the vastprogrammability ofGenAIdoes
not necessarily result in a “return to [...] general-purpose handicraft flexibility”, rather, it has enabled
anewer,subtler, andmorepervasiveformofthe“fragmentalized andrepetitive routinesofthemechan-
ical era”. Through the mechanised convergence of knowledge work through GenAI, the principle of
interface designbecomesWYGIWYG–WhatYouGetIsWhatYouGet.
Postman,whobuildsonMcLuhan,moreaccuratelyreappraisedtheeffectoftheelectricageonintention
(Postman, 1985). Heexplains thatthe information age hasresulted notinanOrwellian dystopia where
intentions are surveilled and constrained, but rather a Huxleyan one, where intentions are numbed:
“WhatOrwellfearedwerethosewhowouldbanbooks. WhatHuxleyfearedwasthattherewouldbeno
reasontobanabook,fortherewouldbenoonewhowantedtoreadone. Orwellfearedthosewhowould
deprive us of information. Huxley feared those who would give us so much that we would be reduced
to passivity and egoism. Orwell feared that the truth would be concealed from us. Huxley feared the
truth would be drowned in a sea of irrelevance. Orwell feared we would become a captive culture.
Huxley feared we would become a trivial culture [...]”. Weinhabit not Foucault’s society of discipline
(Foucault,1977;O’Neill,1986),butDeleuze’ssociety ofcontrol(Deleuze,1992).
This scenario is undesirable, not least because mechanised convergence implies a reduction in the rate
atwhich new ideas are generated, andan increase inrepetition and replay ofexisting ideas. Whatkind
ofculture springs from theconsumption andemission ofanincreasingly convergent setofincreasingly
recycled ideas? A derivative, “stuck” culture, is the diagnosis of technology critic Paul Skallas.7 Even
forGenAIitself, theindications arethattheroadsofautophagy leadtomadness; theroadsofrecursion
lead to cursed collapse (Alemohammadetal., 2023; Shumailovetal., 2024; Bohacek&Farid, 2023;
Gerstgrasser etal.,2024).
Mechanised convergence, asatendency ofautomation morebroadly, createsacrisisofintentionality: a
culturethathaslostthecapacity tointend, doesnotrealise, anddoesnotcare.
7https://lindynewsletter.beehiiv.com/p/culture-stuck, accessed July 2024. Related is the con-
cept of “refinement culture”; “Refinement culture can be summarized as a general streamlining and removal of
any unique characteristics. Refinement Culture is one dimensional and removes variety from the environment.
It’s optimized.” https://lindynewsletter.beehiiv.com/p/refinement-culture, accessed July 2024,
https://medium.com/@lindynewsletter/refinement-culture-51d96726c642,accessed2024.
43. Interlude: Babbage’sIntentional Programmer
Describing what GenAI does to intention as a “crisis” implies that we need to do something about it.
Indeed, whatweneedtodoaboutitistopromotetheactivecultivation ofthecapacity tointend.8
Since this is PPIG, we can start by considering the intentions of programmers. What the tendency for
mechanised convergence tells us is that, prior to specifying behaviour, programming must be about
forming an intention for behaviour. A definition of programming that centres intention, rather than
specification, evokes a rather older philosophy of programming that we can draw from the crisis in
theology atthetimeofBabbage.
Science (moreprecisely, natural philosophy) inpost-Enlightenment Britainatthe timeofBabbage was
grappling with the apparent contradiction of divine miracles – acts of God outside the laws of nature
created by God – which Hume had famously argued could not be rationally supported (Hume, 1748).
Inaimingtodiscover mathematical lawssuchasthoseofNewton,whichcouldaccurately describe and
predictnature,naturalphilosophersoperatingwithintheframeworksofDeismandChristianitystruggled
toreconcile theirworkandfaith.
Babbage foundinhisDifference Enginethepossibility forreinterpreting miracles aspartofthenatural
divine order. Using a “feedback mechanism” that connected two gear wheels, Babbage was able to
encode programs that, after acertain number ofiterations, would change their behaviour. Forexample,
he would demonstrate a program that counts the integers 1, 2, 3 ... up to 100, at which point the
program would change and start counting in steps of two: 102, 104, 106 ... etc. In demonstration-
sermonsdelivered torapturous audiences, heusedthisexampletoexplain histheoryofGodasadivine
programmer (Snyder,2012). Amiraclewasthusexplainedasashiftintheprogram. God’sintervention
toperform apparent miracles wasnotanaberration against universal, constant laws–itwasmerely the
manifestation ofadeeperandmisunderstood universal law,adeeperplan,adeeperintention.
It is instructive that Babbage’s conception of programming and intention centred around shifts, or de-
viations, from the expected. Amachine that continues toexecute thesamepredictable behaviour isnot
a program, it is simply a machine. It is in the departure from convergent behaviour that evidence of
programmingemergesasactivityanddivinity. ForBabbage,toconvergeishuman,todeviatedivine. To
executeishuman,toprogram divine. Tospecify ishuman,tointenddivine.
4. Sourcesof Intention: Constraints, Materiality, and Resistance
Returningtoourobjective–topromotetheactivecultivationofthecapacitytointend–itisworthbriefly
exploring afewperspectives onthesourcesofintentions.
Muchintentionappearstoariseasaresultofinteractionwiththeexternalworld. Practitionersofcreative
artsandresearchincreativityhavelongnotedtheroleofconstraintsinshapingandfacilitatingcreativity
(Stokes, 2005; May, 1975). Materiality and resistance are essential to craftsmanship; any material,
by virtue of its properties and resistances, participates in an ongoing dialogue with the craftsman’s
intentions (Basman,2016). According tomaterial engagement theory9 (Malafouris,2019),“Ourforms
of bodily extension and material engagement are not simply external markers of a distinctive human
mentalarchitecture. Rather,theyactivelyandmeaningfullyparticipateintheprocesswecallmind”. As
such, theroleofmaterial asasource ofintention can beseen asaform ofextended cognition, oratthe
veryleastexternalcognition (Turner,2016),notwithstanding challenges totheseideas(Rupert,2004).
A sculptor must consider how pliable or fragile their material is, what tolerances and fine details can
beaccomplished, howgravity willconstrain thescaleandorientation oftheirfigures. Acarpenter must
consider the grain of their wood, where cuts and incisions can be made. A painter using watercolours
must consider and exploit the additive translucency of that medium, one using oils must consider the
opacity oftheirs. Itistelling that thearchetypical dimension intheCognitive Dimensions ofNotations
8MuchasR.Benjamin(2024)callsforustocultivatethecapacitytoimagine.
9ThankstoAvaScottforidentifyingthisconnection.
5(Green, 1989) is viscosity, a metaphor rooted in materials and resistances, aiming to bridge them with
theseeminglyimmaterialanddisembodied worldofnotations.
Some intentions even rejoice in the contradiction of others: for example, the objective of subversive
gameplay styles is to ignore the received goals of the game and invent one’s own (Flanagan, 2009), it
isplaying theinfinite gamewhoseobjective istocontinue playing, notthe finitegamewhoseobjective
is to win (Carse, 1986). Solving the continuous puzzles posed by these resistances, having a vision
pushed,pulled,andevolved,isthepleasureandintentionalityofcraftsmanship. Thesearenotdestructive
resistances thathindertherealisation ofanintention; theyareproductive onesthatfacilitate it.
Exploratory programming (Kery&Myers, 2017) exemplifies how the materialities and resistances of
programming are exploited to shape intention. In exploratory programming, the programmer’s goal is
unknown or ill-defined. The objective of the process is to discover or create an intention, to formulate
a problem. The formulation of a problem co-exists with and cannot be separated from its solution
(Rittel&Webber, 1973; Sarkar, 2023c). This is also the case in the end-user programming activity of
interactive machine learning, or interactive analytical modelling (Sarkar, 2016b), where the goal is ill-
definedandtheobjectiveistocreateone,through aconstructivist loopofinteraction betweenideasand
experiences (Sarkar,2016a).
TherehavebeenproposalstodesignGenAIsystemsthatintroduceproductiveresistancesascatalystsfor
thedevelopmentofintention. Ratherthananassistant,AIcanactasacriticorprovocateur(Sarkar,2024;
Sarkaretal.,2024). AIcanbeantagonistic(Caietal.,2024). AIcancausecognitiveglitches(Hollanek,
2019). AIcan act as cognitive forcing functions (Buçincaetal., 2021). These proposals are counter to
traditional narratives of system support, system disappearance, and system non-interference. They can
be seen as successors to previous counternarratives raised by researchers such as critiques of the doc-
trines of simplicity and gradualism (Sarkar, 2023c), critiques of seamlessness (Chalmers&MacColl,
2003), critiques of reversible interactions (Rossmyetal., 2023), the case for design frictions and mi-
croboundaries (Coxetal., 2016), reframing of ambiguity as design resource (Gaveretal., 2003), and
callsforattention checksinAIuse(Gouldetal.,2024).10
TheconceptofresistancecouldbekeytoframingthedesignobjectivesforintentionalGenAItools. Our
current explorations of improving critical thinking with GenAI (e.g., Sarkaretal. (2024)) are strictly
additive: let’saugmentAIinteractionandoutputwithprompts,text,visualisations, etc. thatgettheuser
thinking. However,thisapproach increases thecognitive burden byasking userstoconsumeandreflect
onmoreinformation. Weknowthatpeopledon’t alwaysenjoy, orwant,moreinformation. Particularly
whenitcomestotheuserinterfacesofdiscretionarysoftware,theyusuallywantless(Carroll&Rosson,
1987;Sarkar,2023c). Theadditiveapproachmaybestartingbyfightingalosingbattle,oneinwhichwe
try to design the smallest, most stimulating, most rewarding “consumable” that creates user reflection,
withoutincurringundesirableattentionalcosts. Theideaofresistanceprovidesadifferentstartingpoint.
How can we build GenAI tools with inherent, productive resistances that are part of working with the
tool,notanadditionalthingthatusersneedto“pay”attentionto? Howcantheexperienceofresistances
intheinterface feelmorelikethepliability ofclay,orthetranslucency ofpaint? Thisisanopenavenue
forfuturework.
10Itisworthobservingthatwhilesuchcounternarrativesofteninvolvecallsforgreater, morecritical,andmorereflective
userengagementandparticipationwithtechnology,itshouldnotbeassumedthatintentionalityalwaysentailsparticipationor
action. Observationitselfisnotintrinsicallypassive. ThispointiswellmadebyPfaller(2017): “Twophilosophicalpremises
silentlyplayed adecisiveroleinthistriumphal march of participation: first, theideathat therelation between transmitter
andreceiverrepresentsahierarchyandthattheeliminationofthishierarchythereforehastoamounttoademocratisation;
and secondly, the idea that it is more desirable for spectators to participate than to spectate [... however,] the relation
between transmitterand receiver does not always represent a hierarchy. Andwhen it does, then itis not always in favour
ofthetransmitter[...] Thisiswhyitismisleadingtobelievethatactivatingtheaudienceinartisautomaticallyandalways
tantamounttotheirliberation.Becausecouldnottheexactoppositebethecase:couldtheenthusiasmforjoininginproduced
byartnotdeprivepeopleofthenecessaryrefractorinessthattheywouldneedinpoliticallifeinordernottobeimmediately
enthused by every neoliberal or reactionary or even fascist appeal to ‘actively’ join in, and pursue this with a feeling of
liberation?”
65. Existentialist Approachesto Intention
So far we have been considering intention at relatively small scale: instances of knowledge work and
GenAI use. But intentions, like goals, form hierarchies. Intentions are not isolated and independent,
they are related and convergent. To what do they converge? At this point we shall make a somewhat
abruptleapoutwardsandconsiderthemostexpansivescopeofintention–asenactedoverthecourseof
anentirelife.
An evolutionary account might attempt to trace human intentions back to fundamental physiological
concerns: weformintentionstocontinuesurvival,toavoidfear,toensurecomfort,tomaximisepleasure,
to minimise pain. These can certainly account for some intentions. The concept of intention has much
in common with free will – loosely defined, one’s capacity to act differently to how one did, in fact,
act. Free will is not the same as intention, but it can be viewed as a precondition for true intention.
Neuroscientific workpurporting todemonstrate (alackof)freewillhasbeencriticised byphilosophers
because (among other objections), we do not have a suitably good picture that connects short-term
choices dominated by low-level psychological phenomena (such as choosing to push the left button or
the right button) to the complex, long-term, highly planned and goal-oriented intentions (such as the
intention to commit a crime) that pose the truly consequential ethical challenges to free will (Mele,
2019). The evolutionary account is part of a broader category of teleosemantic theories of intention
(Jacob, 2023) according to which design (evolutionary or artificial) supplies a function (τέλος), which
inturnsuppliesintention.
In considering whether human intention can truly be reduced to evolutionary or functional needs, I
am drawn to the argument made by feminist anthropologist Payal Arora in her closing keynote for the
2022 CHI conference (Arora, 2022). She criticizes Maslow’s famous hierarchy of needs that places
physiological and safety needs at the bottom, rising to esteem and self-actualisation at the top. The
conventional reading is that needs at the bottom of the pyramid need to be satisfied, the foundation of
the pyramid needs to be built, before one can proceed to the higher levels. This is a fairly influential
way of thinking and often dictates the way in which social aid and rescue efforts are prioritised: focus
onfood, water, andshelter first,andjoy, play, growth,education, anddignity later. Arorafindsthatthis
picture does not correspond with her observations in her extensive ethnographic work with precarious,
oppressed,andunderprivilegedgroups. Instead,sheproposesthatthepyramidisupsidedown. Whatshe
findsisthatself-actualisation iswhatpeopleneedfirst,andarewillingtosacrificesafetyneedstogetit.
Peopleleavesecureworkwhenthenatureofthatworkthreatenstheirdignity,evenifthisplacesthemin
financial hardship. Peopleleavehomeswheretheycannot expresstheir identity, orarenotaccepted for
who they are, even if this might leave them without aroof over their head. A line from the poet James
Oppenheim captures thesentiment:
“Ourdaysshallnotbesweatedfrombirthuntillifecloses—
Heartsstarveaswellasbodies: GiveusBread,butgiveusRoses.”
If not entirely upside down, then at the very least Maslow’s hierarchy is not a unidirectional ladder to
climb,butasetofconsiderations andinfluences thatarecontinually negotiated andtraded-off. Physiol-
ogyandevolutionarepartofintentionformation,butfarfromtheentirepicture. Wherecanwelookfor
aperspectiveonintentionthatalignswithArora’sobservations? Moreover,isthereanapproachthatnot
onlyidentifiesthesourceofintention, butprescribes amethodforcultivating it?
Elaborating the consequences of the idea that the active cultivation of intention is the core virtue in an
inherently meaningless worldisprecisely theprojectofexistentialist philosophy.
Theabsence ofanyinherent purpose tolife isthestarting point. PerSartre (1943),“existence precedes
essence”; individuals first exist without purpose and mustsubsequently forge their essence, or identity,
through theiractions. Angst, orexistential anxiety, arises fromtherealization ofone’s freedom and the
infinitepossibilities itentails(Kierkegaard,1844). Existentialists seeangstasamotivatorratherthanan
obstacle.
7Authenticity is one expression of existentialist intention. It is the pursuit of living in accordance with
one’strueselfandvalues,ratherthanconformingtosocietalnorms,andisessentialforgenuineexistence
(Heidegger,1927). Authenticityrequiresaconsciousefforttounderstandandactuponpersonalconvic-
tions, even in the face of adversity or societal pressure (Kierkegaard, 1843; deBeauvoir, 1948). Other
sources of intentionality, besides authenticity, go beyond the individual. Kierkegaard’s (Kierkegaard,
1849)“leap offaith” suggests that toescape from existential despair requires acknowledging thelimits
ofrationalreflectionandanindividual’srelationshipwiththedivine. Moreover,toseekengagementwith
theworldistostepbeyondoneself,tointeractwithothers,andtofindandcreatemeaningthroughthese
actions (Jaspers&Saner, 1932). Similarly, deBeauvoir (1948) points out that our individual subject-
like freedom is complemented by an object-like unfreedom (“facticity”), deriving an ethics of freedom
thatadvocates foractionsthatrespectthefreedomofothers.
Camus (1942) counsels individuals to accept “the absurd”: the tension between the human search for
meaning and a universe that is silent in response, to recognize the lack of inherent meaning in the
world and to take on the task of creating their own purpose. Camus rejects “solutions” to the absurd
proposed by prior philosophers, such as Kierkegaard, as “philosophical suicide”. To Camus, seeking
overarching meaning despite the absurd is seeking toresolve, minimise, sidestep, orignore the absurd,
notacknowledging it.
Camusrejects aforced imposition of meaning where there isnone. Aleap of faith is aform of escape.
Incidentally, aforcedimposition ofmeaningisprecisely themodusoperandiofGenAI:forlanguage to
beproduced byarithmetic meansitisnecessary toencodelanguage inauniform,rational vectorspace.
Senseandnonsense alikearethusenumeratedandmadecommensurable. King−Man+Woman=Queen
(Mikolovetal., 2013). Before carefully designed guardrails (themselves a form of escape) made it
more difficult to do so, it was easy to elicit answers to nonsense questions such as “what colourless
green ideas sleep furiously?” from language models. Furthermore, GenAI is an essential component
of an emerging pseudoreligious meta-narrative of escape identified by Gebru&Torres (2024): “What
ideologies are driving the race to attempt to build AGI? [...] we trace this goal back to the Anglo-
Americaneugenicsmovement,viatranshumanism. [...] wedelineateagenealogyofinterconnected and
overlapping ideologies that we dub the ‘TESCREALbundle,’ where the acronym ‘TESCREAL’denotes
‘transhumanism, Extropianism,singularitarianism, (modern)cosmism,Rationalism,EffectiveAltruism,
andlongtermism’”.
Camus’ existentialist view offers a non-escapist alternative that stares meaninglessness in the face and
from it derives freedom. This freedom is both liberating and burdensome. We are at liberty to choose,
but arealsoresponsible forbearing theburden ofthe consequences. Thelightness ofbeing canthus be
unbearable. It is through confronting this anxiety that individuals can make deliberate and meaningful
choices, shaping theirintentions, andbyextension, theiressence.
GenAI has implications for the intention of professional programmers and casual ones alike. The in-
troduction poses the question “what is programming?”, and we can now see a second reading of this
question whichasksnotforadefinition ofanactivity, butofanaspiration oridentity. AsGenAIsolves
the problem of control, of specifying behaviour, the aspiration shifts to intent. Intent precedes control.
To be a programmer is therefore not to be one who specifies behaviour, but one who forms authentic,
meaningful intentions forbehaviour.
6. Speculative Scenariosfor Intentional Programming
Theoptimismofthe“intention isallyouneed”narrativedoespositalegitimateobservation concerning
the behavioural economics of software production. GenAI makes the production of bespoke software
vastlycheaper. Onecanviewexistentialism asaresponsetothelossofthe“grandnarratives”ofmoder-
nity. Butsoftwarehasstillbeenconstrainedbythegrandnarrativesofcapitalismandutility–untilnow.
Towriteaprogramrequiredinvestmentoftimeandhard-earnedexpertise,exertingpressureonprograms
to be valuable, robust, and reusable. Where they did not place an outright barrier, the investment costs
of programming disincentivised exploration, error, and disposal. Within this frame story hitherto sits
8the universe of programmer psychology and behaviours: from authoring code to code comprehension,
from knowledge sharing and documentation to debugging, from learning barriers to attention invest-
ment, from API design to autocomplete. Almost the entire diversity of experience of programmers,
professional orcasual, that ourresearch community has socarefully documented and explained for the
lasthalf-century, hasdweltintheshadowofthemarket’sinvisible hand.
Asthehandiswithdrawn,onemightaskhowprogrammerscanrespond, inamicrocosmoftheexisten-
tialdilemma,totheliberatingyetburdensomefreedomgrantedbyGenAI.Asfaraspracticaladvice(i.e.,
“implications fordesign[ing yourlife]”)isconcerned, existentialists adviseembracingone’sfreedomto
shapelife,livingauthentically, acceptingtheabsurd, confronting anxiety, andseeking engagementwith
theworld aswaystoform meaningful intentions. Whatthis might meanforprogrammers, and interac-
tionwithGenAI,canbesketched inafewspeculative scenarios:
• Intentional coding retreats: The programmer steps away from her standard way of working to
participate in an intentional coding retreat. Here, the programmer reconnects with the craft of
coding without the assistance of AI tools. This allows the programmer to explore and reaffirm
personal codingstylesandproblem-solving approaches. Forexample,aprogrammeraccustomed
torelying onAIfordebugging mightrediscover thesatisfaction ofmanually untangling complex
code,thusreaffirmingtheirindividual capability andcreativefreedom.
• AI as muse: AI suggests an unusual, contradictory, or incorrect algorithmic approach, which the
programmer then refines and transforms with personal insights and expertise. The tool is not a
crutchbutasourceofinspiration.
• Programming with provocations: programming environments include prompts or questions to
stimulate deeper thinking about thepurpose and potential impact ofthe code being written. This
canhelpprogrammers reconnect withtheirmotivationsandaspirations.
• Programming with constraints: intentional constraints are introduced to programming projects,
much like the practices of constrained writing.11 Programmers already practice genres of con-
strained programming for pleasure, such as “code golf” (writing the shortest possible program
withacertainbehaviour)or“quines”(inputlessprogramsthatproduceonlytheirownsourcecode
asoutput). Bydeliberatelylimitingcertainresourcesorimposinguniquechallenges,programmers
canstimulatecreativity andcraftintentional solutions.
• Deviation practice: in the education of professional programmers, exercises are developed that
requireintentional deviationfromestablished patterns. Bypractising thepreciseskillofbreaking
away from standard solutions, programmers may more readily acquire the conscious muscle and
desireforformingunique intentions andexploring novelpaths.
• Intentionality metrics: tools display metrics that evaluate the degree of human intention in the
creative process (noting that these metrics are necessarily reductionist proxies and may become
subject to Goodhart’s/Campbell’s law). For example, a generative design tool might analyse the
uniqueness ofuserqueries andthedivergence oftheoutputfromstandard templates. Visibilising
theinvisibleeffectsofmechanisedconvergence mayencourageuserstoengagemoredeeplywith
theworkandmakeconscious, deliberate, individual choices.
• Participatory AIartefacts: artefacts are intentionally leftincomplete by AI,requiring human par-
ticipation12 tofinalise. Forinstance, aparticipatory toolgenerates theoutlineofawebdesignbut
leaves decisions about colour schemes and typography to the user. Conversely, a tool refuses to
generate an outline, requiring the user to form a rough intention independently, before assisting
byfillingindetails.
11E.g.,seediscussionofconceptualwritinginSarkar(2023b).
12thoughnot“collaboration”(Sarkar,2023a)
9These speculations are not meant to be concrete proposals, but rather simply representative ideas of
a future where the existentialist values of freedom, authenticity, and intentionality are preserved and
enhancedthroughGenAI.Theyarelimitedinvision,representing onlythelinesofsightfromwherewe
standtoday,andunabletoanticipate theadjacentpossibles ofwherewemighttravel.
7. Conclusion
ProgrammingisundeniablychangingundertheinfluenceofGenAI.Intentionappearstobealloneneeds
tocreatesoftware. ButthenotionthatGenAIoffersaneutral,unencumberedpathtorealisingintentions
is a mirage. Contrary to the assumption that GenAI merely executes human intentions, it also shapes
them. At the very least, GenAI can induce “mechanised convergence”, homogenising creative output,
andreducing diversity inthought. Thereistherefore ariskofcreating a“stuck” culturethatrecycles an
oldsetofconvergent ideasinsteadoffostering anewsetofdivergent ones.
Inseekingawaythroughthisproblem wehaveencountered avarietyofsources thatwecandrawupon
to precipitate the active cultivation of intention: evolutionary pressures, the need for dignity and self-
actualisation, constraints,subversion,materiality,andresistance. Finally,wediscussedhowtheproblem
of intention resonates with the existentialist pursuits of freedom, identity, and authenticity. While this
discussion of existentialism is necessarily cursory, limited, flawed, and provisional, its aim has been to
situatetheproblemsposedbyGenAItointentionality inthebroadest possiblescope.13
Programming must go beyond specification and embody the active cultivation of intentions. Existen-
tialist philosophy offers a proactive, prescriptive framework for understanding the formation of human
intentions as a process that ought to be held as deeply personal, ethically charged, and fundamentally
free. It teaches us that to be human is to be involved in a continuous project of becoming. After all –
oneisnotborn,butratherbecomes, aprogrammer.
8. Acknowledgements
Thanks to Sean Rintel and Lev Tankelevitch for helping review drafts of this paper. I am especially
gratefultoAvaScottandRichardBanksfortheirgenerous andhelpful reflections.
References
Alemohammad, S., Casco-Rodriguez, J., Luzi, L., Humayun, A. I., Babaei, H., LeJeune, D.,
... Baraniuk, R. G. (2023). Self-Consuming Generative Models Go MAD. Retrieved from
https://arxiv.org/abs/2307.01850
Anderson, B. R., Shah, J. H., & Kreminski, M. (2024). Homogenization effects of large language
modelsonhumancreativeideation. arXivpreprintarXiv:2402.01536.
Arnold, K. C., Chauncey, K., & Gajos, K. Z. (2020). Predictive text encourages predictable
writing. In Proceedings of the 25th International Conference on Intelligent User Interfaces
(p. 128–138). New York, NY, USA: Association for Computing Machinery. Retrieved from
https://doi.org/10.1145/3377325.3377523 doi: 10.1145/3377325.3377523
Arora, P. (2022). FemWork: Critical Pivot towards Design for Inclusive Labor Futures. In 2022 CHI
ConferenceonHumanFactorsinComputingSystems(ClosingKeynote).
Basman, A. (2016). Building software is not a craft. Proceedings of the Psychology of Programming
InterestGroup,142.
Benjamin,R. (2024). Imagination: Amanifesto(anortonshort). WWNorton&Company.
Benjamin,W. (1935). Theworkofartintheageofmechanical reproduction, 1936. NewYork.
Blackwell,A.F. (2002). Whatisprogramming? InPPIG(Vol.14,pp.204–218).
13Camus(1942)describesexistence(suicide)astheonlytrulyseriousphilosophicalproblem.
10Blackwell,A.F.(2020). Objectivefunctions:(in)humanityandinequityinartificialintelligence. Science
intheForeSt,Science inthePaSt,191.
Bohacek,M.,&Farid,H. (2023). Nepotistically trainedgenerative-ai modelscollapse. Retrievedfrom
https://arxiv.org/abs/2311.12202
Buçinca, Z., Malaya, M. B., & Gajos, K. Z. (2021, apr). To Trust or to Think: Cognitive Forc-
ing Functions Can Reduce Overreliance on AI in AI-assisted Decision-making. Proc. ACM Hum.-
Comput. Interact., 5(CSCW1). Retrieved from https://doi.org/10.1145/3449287 doi:
10.1145/3449287
Cai,A.,Arawjo,I.,&Glassman,E.L. (2024). Antagonistic AI. arXivpreprint arXiv:2402.07350.
Camus, A. (1942). Themyth of sisyphus (J. O’Brien, Trans.). France: Éditions Gallimard (in French),
HamishHamilton(inEnglish).
Carroll, J. M., & Rosson, M. B. (1987). Paradox of the active user. In Interfacing thought: Cognitive
aspectsofhuman-computer interaction (pp.80–111).
Carse,J.P. (1986). Finiteandinfinitegames. NewYork,NY:FreePress.
Chalmers, M., & MacColl, I. (2003). Seamful and seamless design in ubiquitous computing. In
Workshopatthecrossroads: Theinteraction ofHCIandsystemsissuesinUbiComp(Vol.8).
Cox, A. L., Gould, S. J., Cecchinato, M. E., Iacovides, I., & Renfree, I. (2016). Design frictions for
mindful interactions: The case for microboundaries. In Proceedings of the 2016 CHI conference
extended abstracts onhumanfactors incomputing systems(pp.1389–1397).
de Beauvoir, S. (1948). The ethics of ambiguity (B. Frechtman, Trans.). Citadel Press Publishing, A
Subsidiary ofLyleStuartInc.
Deleuze, G. (1992). Postscript on the societies of control. October, 59, 3–7. Retrieved 2024-06-04,
fromhttp://www.jstor.org/stable/778828
Dell’Acqua, F., McFowland, E., Mollick, E. R., Lifshitz-Assaf, H., Kellogg, K., Rajendran, S., ...
Lakhani, K.R. (2023). Navigating thejagged technological frontier: Fieldexperimental evidence of
theeffectsofaionknowledge workerproductivity andquality. HarvardBusinessSchoolTechnology
&Operations Mgt.UnitWorkingPaper(24-013).
Dennett,D.C. (1971). Intentional systems. Thejournal ofphilosophy, 68(4),87–106.
Doshi, A. R., & Hauser, O. (2023, Aug). Generative artificial intelligence enhances creativity but
reducesthediversityofnovelcontent.
(AvailableatSSRN:https://ssrn.com/abstract=4535536 orhttp://dx.doi.org/10.2139/ssrn.4535536)
Flanagan,M. (2009). Criticalplay. London,England: MITPress.
Foucault,M. (1977). Discipline andpunish. NewYork,NY:PantheonBooks.
Gaver,W.W.,Beaver, J.,&Benford, S. (2003). Ambiguityasaresource fordesign. InProceedings of
theSIGCHIconference onHumanfactorsincomputing systems(pp.233–240).
Gebru,T.,&Torres,É.P. (2024). TheTESCREALbundle: Eugenicsandthepromiseofutopiathrough
artificialgeneralintelligence. FirstMonday.
Gerstgrasser, M.,Schaeffer, R.,Dey,A.,Rafailov, R.,Sleight, H.,Hughes, J.,... Koyejo, S. (2024). Is
model collapse inevitable? breaking the curse of recursion byaccumulating real and synthetic data.
Retrievedfromhttps://arxiv.org/abs/2404.01413
11Gould, S. J. J., Brumby, D. P., & Cox, A. L. (2024). Chattl;dr – you really ought to check what
the llm said on your behalf. In Extended abstracts of the 2024 chi conference on human factors in
computing systems. New York, NY, USA: Association for Computing Machinery. Retrieved from
https://doi.org/10.1145/3613905.3644062 doi: 10.1145/3613905.3644062
Green,T.R. (1989). Cognitivedimensions ofnotations. Peopleandcomputers V,443–460.
Heidegger, M. (1927). Beingandtime(J.Macquarrie &E.Robinson, Trans.). SCMPress.
Hollanek, T. (2019). Non-user-friendly: Staging resistance withinterpassive userexperience design. A
Peer-ReviewedJournalAbout,8(1),184–193.
Hume,D. (1748). Anenquiry concerning humanunderstanding.
Jacob, P. (2023). Intentionality. In E. N. Zalta & U. Nodelman (Eds.), The Stanford ency-
clopedia of philosophy (Spring 2023 ed.). Metaphysics Research Lab, Stanford University.
https://plato.stanford.edu/archives/spr2023/entries/intentionality/.
Jakesch, M., Bhat, A., Buschek, D., Zalmanson, L., & Naaman, M. (2023). Co-Writing with
Opinionated Language Models Affects Users’ Views. In Proceedings of the 2023 CHI Confer-
ence on Human Factors in Computing Systems. New York, NY, USA: Association for Comput-
ing Machinery. Retrieved from https://doi.org/10.1145/3544548.3581196 doi:
10.1145/3544548.3581196
Jaspers, K.,&Saner,H. (1932). Philosophie (Vol.1). J.SpringerBerlin.
Kery, M. B., & Myers, B. A. (2017). Exploring exploratory programming. In 2017 IEEE Symposium
onVisualLanguages andHuman-CentricComputing(VL/HCC)(pp.25–29).
Kierkegaard, S. (1843). Fear and trembling. Denmark: First authorship (Pseudonymous). (Published
inEnglishin1919–firsttranslation)
Kierkegaard, S. (1844). The concept of anxiety (R. Thomte, Trans.). Denmark. (Published in English
in1946)
Kierkegaard, S. (1849). Thesickness untodeath.
Lee, M.,Blackwell, A.,&Sarkar, A. (2024). Predictability ofIdentifier NamingwithCopilot: ACase
Study for Mixed-Initiative Programming Tools. Proceedings of the 35th Annual Conference of the
PsychologyofProgrammingInterestGroup(PPIG2024).
Liu,M.X.,Sarkar,A.,Negreanu,C.,Zorn,B.,Williams,J.,Toronto,N.,&Gordon,A.D.(2023).“What
It Wants Me To Say”: Bridging the Abstraction Gap Between End-User Programmers and Code-
Generating LargeLanguageModels. InProceedings ofthe2023CHIConferenceonHumanFactors
inComputingSystems. NewYork,NY,USA:AssociationforComputingMachinery. Retrievedfrom
https://doi.org/10.1145/3544548.3580817 doi: 10.1145/3544548.3580817
Malafouris, L. (2019). Mind and material engagement. Phenomenology and the cognitive sciences,
18(1),1–17.
May,R. (1975). Thecourage tocreate. NewYork,NY:WWNorton.
McLuhan,M. (1964). Understanding media: Theextensions ofman. McGraw-Hill. (Firstedition)
Mele, A. (2019). Free will and neuroscience: decision times and the point of no return. In Free will,
causality, andneuroscience (pp.83–96). Brill.
12Mikolov,T.,Yih,W.-t.,&Zweig,G. (2013). Linguisticregularities incontinuous spacewordrepresen-
tations. In Proceedings of the 2013 conference of the north american chapter of the association for
computational linguistics: Humanlanguage technologies (pp.746–751).
O’Neill, J. (1986). The disciplinary society: from weber to foucault. British Journal of Sociology,
42–60.
Pfaller,R. (2017). Interpassivity: Theaesthetics ofdelegated enjoyment. Edinburgh UniversityPress.
Postman,N. (1985). Amusingourselves todeath. VikingBooks.
Prather, J., Reeves, B. N., Denny, P., Becker, B. A., Leinonen, J., Luxton-Reilly, A., ... Santos,
E. A. (2023, nov). “it’s weird that it knows what i want”: Usability and interactions with
copilot for novice programmers. ACM Trans. Comput.-Hum. Interact., 31(1). Retrieved from
https://doi.org/10.1145/3617367 doi: 10.1145/3617367
Rittel, H. W., & Webber, M. M. (1973). Dilemmas in a general theory of planning. Policy sciences,
4(2),155–169.
Robinson, D., Cabrera, C., Gordon, A. D., Lawrence, N. D., & Mennen, L. (2024). Requirements are
allyouneed: Thefinalfrontierforend-usersoftwareengineering. arXivpreprintarXiv:2405.13708.
Rosen, B. M. (1979). VISICALC: Breaking the Personal Computer Bottleneck.
http://bricklin.com/history/rosenletter.htm. (Accessed06-08-2024)
Rossmy, B., Terzimehic´, N., Döring, T., Buschek, D., & Wiethoff, A. (2023). Point of no undo:
Irreversible interactions as a design strategy. In Proceedings of the 2023 chi conference on human
factorsincomputingsystems(pp.1–18).
Rupert, R. D. (2004). Challenges to the hypothesis of extended cognition. The Journal of philosophy,
101(8), 389–428.
Sarkar, A. (2016a). Constructivist Design for Interactive Machine Learning. In Proceed-
ings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems
(p. 1467–1475). New York, NY, USA: Association for Computing Machinery. Retrieved from
https://doi.org/10.1145/2851581.2892547 doi: 10.1145/2851581.2892547
Sarkar, A. (2016b). Interactive analytical modelling (Tech. Rep. No. UCAM-
CL-TR-920). University of Cambridge, Computer Laboratory. Retrieved from
https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-920.pdf doi:
10.48456/tr-920
Sarkar, A. (2023a). Enough With “Human-AI Collaboration”. In Extended Abstracts of the 2023 CHI
Conference on Human Factors in Computing Systems. New York, NY, USA: Association for Com-
puting Machinery. Retrieved from https://doi.org/10.1145/3544549.3582735 doi:
10.1145/3544549.3582735
Sarkar, A. (2023b). Exploring Perspectives on the Impact of Artificial Intelligence on the
Creativity of Knowledge Work: Beyond Mechanised Plagiarism and Stochastic Parrots. In
Proceedings of the 2nd Annual Meeting of the Symposium on Human-Computer Interaction
for Work. New York, NY, USA: Association for Computing Machinery. Retrieved from
https://doi.org/10.1145/3596671.3597650 doi: 10.1145/3596671.3597650
Sarkar, A. (2023c). Should Computers Be Easy To Use? Questioning the Doctrine of Simplicity in
User Interface Design. In Extended Abstracts of the 2023 CHI Conference on Human Factors in
Computing Systems. New York, NY, USA: Association for Computing Machinery. Retrieved from
https://doi.org/10.1145/3544549.3582741 doi: 10.1145/3544549.3582741
13Sarkar, A. (2023d). Will Code Remain a Relevant User Interface for End-User Program-
ming with Generative AI Models? In Proceedings of the 2023 ACM SIGPLAN Interna-
tional Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software
(p. 153–167). New York, NY, USA: Association for Computing Machinery. Retrieved from
https://doi.org/10.1145/3622758.3622882 doi: 10.1145/3622758.3622882
Sarkar, A. (2024, sep). AIShouldChallenge, NotObey. Communications oftheACM. Retrievedfrom
https://doi.org/10.1145/3649404 (OnlineFirst) doi: 10.1145/3649404
Sarkar,A.,Gordon,A.D.,Negreanu,C.,Poelitz,C.,SrinivasaRagavan,S.,&Zorn,B. (2022, Septem-
ber). What is it like to program with artificial intelligence? In Proceedings of the 33rd Annual
ConferenceofthePsychologyofProgrammingInterestGroup(PPIG2022).
Sarkar, A.,Xu,X.T.,Toronto, N.,Drosos, I.,&Poelitz, C. (2024). WhenCopilot BecomesAutopilot:
GenerativeAI’sCriticalRisktoKnowledgeWorkandaCriticalSolution. InEuSpRIGProceedings.
Sartre,J.-P.(1943). Beingandnothingness(H.E.B.(1stEnglishtranslation)&S.R.(2ndEnglishtrans-
lation), Trans.). France: ÉditionsGallimard,Philosophical Library. (PublishedinEnglishin1956)
Sharma,N.,Liao,Q.V.,&Xiao,Z. (2024). GenerativeEchoChamber? EffectofLLM-PoweredSearch
Systems onDiverse Information Seeking. InProceedings ofthe CHIConference onHuman Factors
inComputingSystems. NewYork,NY,USA:AssociationforComputingMachinery. Retrievedfrom
https://doi.org/10.1145/3613904.3642459 doi: 10.1145/3613904.3642459
Shumailov, I., Shumaylov, Z., Zhao, Y., Papernot, N., Anderson, R., & Gal, Y. (2024). Ai models
collapse whentrainedonrecursively generated data. Nature,631(8022), 755–759.
Snyder,L. (2012). Thephilosophical breakfastclub. NewYork,NY:BroadwayBooks.
Stokes,P.D. (2005). Creativityfromconstraints: Thepsychologyofbreakthrough. SpringerPublishing
Company.
Tankelevitch, L., Kewenig, V., Simkute, A., Scott, A. E., Sarkar, A., Sellen, A., & Rintel, S. (2024).
The Metacognitive Demands and Opportunities of Generative AI. In Proceedings of the CHI Con-
ference on Human Factors in Computing Systems. New York, NY, USA: Association for Com-
puting Machinery. Retrieved from https://doi.org/10.1145/3613904.3642902 doi:
10.1145/3613904.3642902
Turner, P. (2016). Distributed, external and extended cognition. HCI Redux: The Promise of Post-
CognitiveInteraction, 75–98.
Welsh, M. (2022, dec). The end of programming. Commun. ACM, 66(1), 34–35. Retrieved from
https://doi.org/10.1145/3570220 doi: 10.1145/3570220
Winner, L. (1980). Doartifacts havepolitics? Daedalus,121–136.
Zamfirescu-Pereira, J., Wong, R. Y., Hartmann, B., & Yang, Q. (2023). Why Johnny Can’t Prompt:
How Non-AI Experts Try (and Fail) to Design LLM Prompts. In Proceedings of the 2023 CHI
Conference on Human Factors in Computing Systems. New York, NY, USA: Association for Com-
puting Machinery. Retrieved from https://doi.org/10.1145/3544548.3581388 doi:
10.1145/3544548.3581388
14