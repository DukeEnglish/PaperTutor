Learning to Explore with Lagrangians
for Bandits under Unknown Linear Constraints
UdvasDasandDebabrotaBasu
ÉquipeScool,Univ. Lille,Inria,
CNRS,CentraleLille,UMR9189-CRIStAL,F-59000Lille,France
udvas.das@inria.fr debabrota.basu@inria.fr
Abstract
Pureexplorationinbanditsmodelsmultiplereal-worldproblems,suchastuning
hyper-parametersorconductinguserstudies,wheredifferentsafety,resource,and
fairnessconstraintsonthedecisionspacenaturallyappear. Westudytheseprob-
lemsaspureexplorationinmulti-armedbanditswithunknownlinearconstraints,
where the aim is to identify an r-good feasible policy. First, we propose a La-
grangianrelaxationofthesamplecomplexitylowerboundforpureexploration
under constraints. We show how this lower bound evolves with the sequential
estimationofconstraints. Second,weleveragetheLagrangianlowerboundand
the properties of convex optimisation to propose two computationally efficient
extensionsofTrack-and-StopandGamifiedExplorer,namelyLATSandLAGEX.
Tothisend,weproposeaconstraint-adaptivestoppingrule,andwhiletrackingthe
lowerbound,usepessimisticestimateofthefeasiblesetateachstep. Weshow
that these algorithms achieve asymptotically optimal sample complexity upper
boundsuptoconstraint-dependentconstants. Finally,weconductnumericalex-
perimentswithdifferentrewarddistributionsandconstraintsthatvalidateefficient
performanceofLAGEXandLATSwithrespecttobaselines.
1 INTRODUCTION
Decision-makingunderuncertaintyisaubiquitouschallengeencounteredacrossvariousdomains,
includingclinicaltrials(Villaretal.,2015),recommendationsystems(ZhaoandYang,2024),and
more. Multi-ArmedBandit(MAB)servesasanarchetypalframeworkforsequentialdecision-making
underuncertaintyandallowsustostudytheinvolvedinformation-utilitytrade-offs(Lattimoreand
Szepesvári, 2020). In MAB, at each step, an agent interacts with an environment consisting of
K decisions (also knows as arms) corresponding to K noisy feedback distributions (or reward
distributions). Ateachstep,theagenttakesadecision,andobtainsarewardfromitsunknownreward
distribution. The goal of the agent is to compute a policy, i.e. a distribution over the decisions,
thatmaximisesacertainutilitymetric(e.g. accumulatedrewards(Aueretal.,2002),probabilityof
identifyingthebestarm(Kaufmannetal.,2016)etc.).
In this paper, we focus on the pure exploration problem of MABs, where the agent interacts by
realisingasequenceofpolicies(orexperiments)withthegoalofansweringaqueryascorrectlyas
possible. Awell-studiedpureexplorationproblemisBest-ArmIdentification(BAI),wheretheagent
aimstoidentifythearmwiththehighestexpectedreward(Even-Daretal.,2002a;Bubecketal.,
2009;JamiesonandNowak,2014;Kaufmannetal.,2016). BAIhasbeenappliedinhyper-parameter
tuning(Lietal.,2017),communicationnetworks(Lindståhletal.,2022),influenzamitigation(Libin
et al., 2019), finding the optimal dose of a drug (Aziz et al., 2021a) etc. However, real-world
scenariosoftenimposeconstraintsonthearmsthatmustbesatisfied(Carlssonetal.,2024). For
example,Baudryetal.(2024)considersarecommendationproblemwiththeaimtoguaranteeafixed
(known)minimumexpectedrevenueperrecommendedcontentwhileidentifyingthebestcontent
Preprint.Underreview.
4202
tcO
42
]GL.sc[
1v44881.0142:viXrafrombanditfeedback. Additionally,ifwehavemultipleobjectivesinadecisionmakingproblem,a
popularapproachtooptimizethemisfindingtheoptimalpolicyforoneobjectivewhileconstraining
theothers(FonsecaandFleming,1998). InthespiritofExample1of(Carlssonetal.,2024),let
usconsideranotherexampleofapersonsearchingforthemosttastymealplangivenabunchof
availablefooditems. Theperson’saimisalsotogainenoughnutritionbyeatingacertainamountof
carbohydrate,protein,fat,andfibres. Thisproblemcanbemodelledasapureexplorationproblem,
whereonetriesdifferentcombinationsandfractionsoffooditemstofindthemosttastycombination
whilerestrictingthenutritionalintakesoverarecommendedthreshold.
Pure Exploration under Constraints. In recent years, such aforementioned real-life problems
naturallymotivatedthestudyofpureexplorationunderasetofknownandunknownconstraints(Katz-
SamuelsandScott,2018;Wangetal.,2021b;Lietal.,2023;Wuetal.,2023;Carlssonetal.,2024).
Specifically, we aim to find the optimal policy that maximises the expected rewards over the set
of arms and also satisfies the true constraints with confidence 1−δ. This is known as the fixed-
confidencesettingofpureexploration(Wangetal.,2021b;Carlssonetal.,2024),whilethereexists
fixed-budgetsettingalsowhichisofindependentinterest(Katz-SamuelsandScott,2018;Lietal.,
2023;FaizalandNair,2022). Existingliteraturehasstudiedeitherthegenerallinearconstraintswhen
theyareknown(Carlssonetal.,2024;Camillerietal.,2022a), orveryspecifictypeofunknown
constraints,e.g. safety(Wangetal.,2021b),knapsack(Lietal.,2023),fairness(Wuetal.,2023),
preferences (Lindner et al., 2022) etc. Here, we study the pure exploration problem in the fixed-
confidencesettingsubjecttounknownlinearconstraintsonthepolicy,whichgeneralisesallthese
settings(Section2). FurtherdiscussionsonrelatedworksisinAppendixB.1.
Recently,Carlssonetal.(2024)showsthatiftheconstraintsareknown,andsoisthefeasiblepolicy
set,abanditinstancemaybecomeharderoreasierdependingonthegeometryofconstraints. They
statethatstudyingsimilarphenomenonforunknownconstraintsisanopenproblemasthefeasible
policysethastobeestimated. Specifically,wehavetosimultaneouslycontrolconcentrationsofthe
meanrewardsandtheconstraintstotheir‘true’valuestoreachthefeasiblepolicyset. Additionally,
atanyfinitetime,theestimatedconstraintsmightexhibitsmallbutnon-zeroerrors. Thisprevents
from‘exactly’obtainingthefeasiblepolicyset,andconsequently,therecommendedoptimaland
feasiblepolicy(thoughtheerrormightbebelownumericallimits). Hence,forrigour,werelaxthe
problemoffindingtheoptimalfeasiblepolicytofindinganr-goodfeasiblepolicy. Foragivenr >0,
anr-goodpolicyhasmeanrewardnotmorethanrawayfromthatoftheoptimalpolicy(Masonetal.,
2020;JourdanandDegenne,2022;Jourdanetal.,2023). Inpractice,onecanconsiderrtobethe
numericallimitofcomputationorareasonablysmallquantity.
Thisleadsustotwoquestions
• Howdoesthehardnessofpureexplorationtofindr-goodfeasiblepolicyunderunknownconstraints
changeiftheconstraintsareestimatedsequentially?
• Howcanwedesignagenericalgorithmicschemetotrackboththeconstraintsandoptimalpolicy
withsample-andcomputational-efficiency?
OurContributionsaddressthesequestionsasfollows:
1. Lagrangianrelaxationofthelowerbound. Theminimumnumberofsamplesrequiredtoconduct
r-goodpureexplorationwithfixedconfidenceisexpressedbyalowerbound,whichisanoptimi-
sationproblemunderknownconstraints. Toefficientlyhandleunknownconstraints,weproposea
novelLagrangianrelaxationofthisoptimisationproblem(Section3). Ateverystep,weconstruct
pessimisticfeasiblepolicyset,andplugitinthelowerbound. TheLagrangianmultipliersbalancethe
identifiabilityofanr-goodpolicyandthefeasibilityunderestimatedconstraints. Weleverageresults
fromconvexanalysistoshowthattheLagrangianrelaxationofthelowerboundwithpessimistic
feasiblesetpreservesallthedesiredpropertiesofthelowerboundunderknownconstraints, and
consequently, allow us to design lower bound tracking algorithms. Further, we characterise the
Lagrangian lower bound for Gaussian rewards, which connects with the lower bound for known
constraints.
2. Agenericalgorithmdesign. WeleveragethisLagrangianformulationoflowerboundtopropose
twoalgorithms. First,incorporatingtheconstraintestimatesintheexistingstoppingruleforknown
constraintsensuresconcentrationofboththemeans’andconstraints’estimatestotheirtruevalues
beforerecommendinganr-goodpolicywithconfidencelevel1−δ. Weshowthatthisstopping
rulealsoensuresthattherecommendedpolicyisfeasiblewiththesameconfidencelevel. Then,we
2extendtheTrack-and-Stop(GarivierandKaufmann,2016)andgamifiedexplorer(Degenneetal.,
2019b)approachesfortheLagrangianlowerboundtodesignLATS(LagrangianTrackandStop)and
LAGEX(LagrangianGamifiedEXplorer),respectively(Section4).
3. Upperboundonsamplecomplexities. WeprovideupperboundsonsamplecomplexitiesofLATS
andLAGEX(Section4). Thisrequiresprovinganovelconcentrationinequalityfortheconstraints.
Asaconsequence,LATSachievesanupperbound,whichis(1+s)timestheupperboundofTS
underknownconstraints. sistheshadowpriceofthetrueconstraintsandquantifiesitsstabilityunder
perturbation. Incontrast,LAGEXleadstoanupperboundthathasonlyanadditivesfactorwith
theknownconstraintlowerbound. ThissuggeststhatLAGEXshouldbemoresample-efficientthan
LATS.OurexperimentalresultsacrosssyntheticandrealdatavalidatethatLAGEXrequirestheleast
samplesamongcompetingalgorithmsandexactlytracksthechangeinhardnessduetoconstraints
acrossenvironments(Section5).
2 PROBLEMFORMULATION
Notation. x,x,X,andX denoteascalar,avector,amatrix,andasetrespectively. x denotesi-th
i
componentofx. Forapositivesemi-definitematrixAandvectorz,∥z∥2 =⟨z,Az⟩. Also,inRd,
A +
weinclude0d. [K]refersto{1,...,K}. Supp(P)denotesthesupportofadistributionP. ∆ is
K
thesimplexover[K].
ProblemFormulation. WeworkwithaMABinstancewithK ∈Narms. Eacharma∈[K]hasa
rewarddistributionP withunknownmeanµ ∈R. Theagent,ateachtimestept∈N,choosesan
a a
actionA ∈[K],andobservesastochasticrewardR ∼P . Afeasiblepolicyπ ∈∆ satisfies
t t At K
Aπ ≤0withrespecttothesetofdlinearconstraintsA∈Rd×K.1
IfAisknown,theagenthasaccesstothenon-emptyandcompactsetoffeasiblepoliciesF ≜{π ∈
∆ |Aπ ≤0}. Theagentaimstoidentifyanr-goodoptimalfeasiblepolicy,i.e. anyfeasiblepolicy
K
whichbelongstothesetΠr ≜{π ∈F |µTπ+r ≥µTπ⋆},where
F F
π⋆ ≜argmaxµTπ. (1)
F
π∈F
Definition 1 ((1 − δ)-correct and (1 − δ)-feasible r-good pure exploration). For δ ∈ [0,1), a
policy recommended by a pure exploration algorithm is (1−δ)-correct and (1−δ)-feasible if
Pr[π⋆ ̸=π⋆]≤δandPr[Aπ⋆ ≥0]≤δ.
Fˆ F Fˆ
Inoursetting,wedonothaveaccesstothetruesetofconstraints. Hence,usingtheobservations,
weconstructAˆ asanestimateofA. Then,theagentbuildsanestimatedfeasiblesetFˆ ≜ {π ∈
∆ | Aˆπ ≤ 0} to identify the optimal feasible policy as π⋆ ≜ argmax µTπ. In addition,
K Fˆ π∈Fˆ
theestimatedr-goodpolicysetisΠr ≜ {π ∈ Fˆ | µTπ+r ≥ µTπ⋆}. Weknowthatobtaining
Fˆ Fˆ
accurateestimatesofthesequantitieswouldrequireustocollectfeedbackofsatisfyingconstraints
overtime. Thisposesanadditionalcostontopofusingobservationstoestimateµ.
Goal. Inordertorecommenda(1−δ)-correctand(1−δ)-feasiblepolicythatisr-goodwithrespect
otthetrueoptimalpolicyπ⋆,weaimtominimisetheexpectednumberofinteractionsE[τ ]∈N.
F δ
Motivation: ExtensionofPriorSetups. Now,weclarifyourmotivationbyshowingthatdifferent
existingproblemsarespecialcasesofoursetting.
a. ThresholdingBandits. Thresholdingbandits(Azizetal.,2021a)aremotivatedfromthesafedose
findingproblem,whereonewantstoidentifythemosteffectivedoseofadrugbelowaknownsafety
level. Thishasalsomotivatedthesafearmidentificationproblem(Wangetal.,2021b). Oursetting
generalisesitfurtheranddetectstheoptimalcombinationofdosesofavailabledrugsyieldinghighest
efficacywhilestayingbelowthesafetythreshold. Formally,weidentifyπ⋆ =argmax µTπ,
π∈∆K
suchthatIπ ≤Iθforthresholdsθ >0.
a
b. OptimalPolicyunderKnapsack. BanditsunderknapsackconstraintsarestudiedinbothBAI(Li
etal.,2023;Tran-Thanhetal.,2012;Lietal.,2021)andregretminimisationliterature(Badanidiyuru
etal.,2018;AgrawalandDevanur,2016;Immorlicaetal.,2022;Agrawaletal.,2016;Sankararaman
andSlivkins,2018). Detectinganoptimalarmmighthaveadditionalresourceconstraintsthanthe
1WeassumethatsimplexconstraintsareaugmentedinAforeaseofnotation.
3numberofrequiredsamples. ThisledtostudyofBAIwithknapsacksunderfixed-budgetsetting(Li
etal.,2023). Butonemightonlywanttodeployafinalpolicythatmaximisesutilityandsatisfies
knapsackconstraints. Forexample,wewanttomanagecacheswheretherecommendedmemory
allocationshouldsatisfyacertainresourcebudgetbutcanviolatethemduringexploration(End-of-
Timeconstraint(Carlssonetal.,2024)). Formally,π⋆ =argmax µˆT π,andC ≜{Aπ ≤
τδ π∈CA τδ A τδ
c,c≥0}.
c. BAIwithFairnessConstraintsacrossSub-populations(BAICS).Wuetal.(2023)aimtoselect
anarmthatmustbefairacrossM sub-populationsratherthanthewholepopulationasinstandardBAI.
Findingonlytheoptimalarmmightnotbeenoughbecauseitmightnotperformequallygoodforallof
thesub-populations. Here,thearmbelongstoasetC :={k ∈[K]|µ ≥0,m∈[M]}wherethe
k,m
observationforarmkandpopulationmcomesfromN(µ ,1). Itensuresthatthechosenarmdoes
k,m
notperformtoobadforanysub-population. ThisissimilartotheproblemwherewehaveM groups
ofpatientsandK drugstoadministerwithrewardmeansµ . Thenwearelookingforamixtureof
k
drugstoadministersuchthatπ⋆ =argmax µTπ,suchthat1⊤ π =1,∀m∈[M]. Hence,
π∈∆K µ m≥0
oursettingmodelsBAICSasaspecialcase.
3 LAGRANGIANRELAXATIONOFTHELOWERBOUND
Inthissection,wediscusstheLagrangianrelaxationofthelowerboundanditsproperties,necessary
todesignacorrectandfeasibler-goodpureexplorationalgorithmunderunknownlinearconstraints.
Werequiretwostructuralassumptions.
Assumption1(Assumptionsonmeans,policy,andconstraints). (a)Themeanvectorµbelongstoa
boundedsubsetDofRK. (b)Thereexistsauniqueoptimalfeasiblypolicy(Equation(1)). (c)For
thetrueconstraintA,thereexistsanon-zeroslackvectorΓ,suchthatmax (−Aπ)=Γ.
π∈∆K
WeimposetheuniqueoptimalandfeasiblepolicyassumptionfollowingCarlssonetal.(2024)to
ensurethatthesolutionofEquation(1)isauniqueextremepointofthepolytopeF. Theassumption
onslackisanalogoustoassumingtheexistenceofasafe-arm(Pacchianoetal.,2020),orthatof
Slater’s condition for the constraint optimisation problem (Liu et al., 2021). Standing on these
assumptions,weprovethatπ⋆ isunique,i.eπ⋆ isanextremepointinthepolytopeFˆ.
Fˆ Fˆ
3.1 InformationAcquisition: EstimatingConstraints
Theagentacquiresinformationateverystept∈Nbysamplinganactiona ∼ω .ω ∈∆ iscalled
t t t K
theallocationpolicy. Thisyieldsanoisyrewardr ∈RandcostvectorAa ∈Rd. Asthearmsare
t t
independent,werepresentthea-tharmasthea-thbasisofRK.Thus,usingtheobservationsobtained
(cid:16) (cid:17)
tillt,weestimatethemeanvectorasµˆ ≜ Σ−1 (cid:80)t−1r a . Here,Σ ≜ vI+(cid:80)t a a⊤ for
t t s=1 s s t s=1 s s
anyv > 0,istheGrammatrixorthedesignmatrix. Similarly,theestimateofthei-throwofthe
(cid:16) (cid:17)
constraintmatrixisAˆi
t
≜Σ−
t
1 (cid:80)t s− =1 1Ai,asa
s
. ButnaivelyusingAˆ ttodefinethefeasiblepolicy
setdoesnotensurethatforanyt,theestimatedfeasiblesetFˆisasupersetofF. Hence,wedefine
aconfidenceellipsoidaroundAˆ thatincludesAwithprobabilityatleast1−δ, andconstructa
t
pessimisticestimateofA. Formally,theconfidenceellipsoidis
C ≜(cid:8) A′ ∈Rd×K |∥A′i−Aˆi∥ ≤f(t,δ)∀i∈[d](cid:9) , (2)
t t Σt
(cid:113)
wheref(δ,t)≜1+ 1logK + 1logdetΣ isamonotonicallynon-decreasingfunctionoft.
2 δ 4 t
Lemma1(Pessimisticfeasiblesets). Ifweconstructthepessimisticfeasiblepolicysetatanytime
t∈Nas
Fˆ ≜{π ∈∆ : min A′π ≤0}, (3)
t K
A′∈Ct
weobservethatF ⊆Fˆ withprobability1−δ.
t
WedenotetheA′achievingtheaboveminimumasA˜ . InFigure1,wevisualisethisresultusingthe
t
numericalvaluesobtainedfromouralgorithms. Weobservethatasweacquiremoresamples,our
estimatedfeasiblepolicysetFˆ →F.
t
4t = 60 t = 200 t = 266
(0,1,0) (0,1,0) (0,1,0)
(1,0,0) (0.6,0,0.4)(0,0,1) (1,0,0) (0.55,0,0.45) (0,0,1) (1,0,0) (0.51,0,0.49)(0,0,1)
: Preference direction Mean vector = [3,2,4] Tru pe
o
o lp ict yimal Po el si tc imy au tn ed de r
constraints
Figure1: Convergenceofthepessimisticfeasiblesetandoptimalpolicy.
Remark. Toensurethatthetrueoptimalandfeasiblepolicyπ⋆ ∈Fˆ isinsidetheestimatedfeasible
F t
policyset,andFˆ ̸=∅foranyt,weusethepessimisticestimateofthefeasiblesetFˆ ensuringF ⊆
t t
Fˆ withhighprobability. Ourconstructionofthepessimisticestimatesoffeasiblesetresonatewith
t
thespiritofoptimistic-pessimisticalgorithmsforregret-minimisationunderconstraints(Pacchiano
etal.,2020;Liuetal.,2021;Chenetal.,2022b;Pacchianoetal.,2024).
3.2 LagrangianRelaxationwithEstimatedConstraints
Searchfortheoptimalpolicyisessentiallyalinearprogrammingproblemwhenweknowthemean
vector µ and a constraint matrix A. The challenge in bandit is to identify them from sequential
feedback,i.e. todifferentiateµfromtheotherconfusinginstancesinthesamefamilyofdistributions.
Thesearecalledthealternativeinstances. Thestrategyistogatherenoughstatisticalevidencetorule
outallsuchconfusinginstances,specificallytheonethathasminimumKL-divergencefromµas
observedundertheallocationpolicyω(GarivierandKaufmann,2016). Thisintuitionhasledtothe
lowerboundofCarlssonetal.(2024)statingthattheexpectedstoppingtimeofany(1−δ)-correct
andalways-feasiblealgorithmsatisfies
1
E[τ ]≥T (µ)ln , (4)
δ F,r 2.4δ
ifAisknown. T (µ)iscalledthecharacteristicstime. Itsreciprocalisamax-minoptimisation
F,r
problem over the set of alternative instances Λ F(µ,π) ≜ (cid:8) λ ∈ D | max π∈Πr λ⊤π − r >
max π∈Πr λ⊤π ≜λ⊤π⋆(cid:9) ,i.e. F
F
K
(cid:88)
T−1(µ)≜ sup max inf ω d(µ ,λ )
F,r ω∈∆Kπ∈Πr Fλ∈ΛF(µ,π)
a=1
a a a
≜ sup max inf ω⊤d(µ,λ) . (5)
ω∈∆Kπ∈Πr Fλ∈ΛF(µ,π)
Λ (µ,π), referred as the Alt-set, is the set of all bandit instances whose mean vectors are in a
F
boundedsubsetD ∈RK buttheoptimalpolicyisdifferentthanthatofµ∈D. Now,weinspectthe
changeinthislowerboundatanystept>0,whenweonlyhaveaccesstoapessimisticestimateFˆ
t
andtheconfidenceellipsoidC butdonotknowF. Forbrevity,weexcludetfromthesubscriptsfor
t
whereitisclearfromthecontext. Now,weobservethattheAlt-setgivenFˆis
Λ (µ,π)≜(cid:8) λ∈D |maxλ⊤π−r >λ⊤πˆ⋆(cid:9) (6)
Fˆ
π∈Fˆ
SinceF ⊆ Fˆ,weobservethatΛ (µ,π) ⊆ Λ (µ,π). Now,wearereadydefinetoLagrangian
Fˆ F
relaxationofthelowerbound,i.e.
T−1(µ)≜ sup max inf ω⊤d(µ,λ)
F,r ω∈∆Kπ∈Πr Fλ∈ΛF(µ,π)
≤ inf min sup max inf ω⊤d(µ,λ)−l⊤A′ω (7)
l∈Rd +A′∈Cω∈∆Kπ∈Πr Fλ∈Λ Fˆ(µ,π)
WedenotethisLagrangianrelaxationofthecharacteristictimewithFˆasT−1(µ). Fornon-negative
Fˆ,r
Lagrangemultipliersl∈Rd,thefirstinequalityistrueduetotheexistenceofaslackforthetrue
+
5constraintsA. Thesecondinequalityisduetothepessimisticchoiceoftheestimatedconstraint.
Equation(7)showsthatthereciprocaloftheLagrangianrelaxation,T (µ),servesasaupperbound
Fˆ,r
onthecharacteristictimeT (µ)forknownconstraints(Carlssonetal.,2024).
F
TheLagrangianrelaxationleadstoanaturalquestion:
DoesthedualoftheoptimizationproblemforT−1(µ)yieldthesamesolutionastheprimal?
Fˆ,r
Theorem 1 (Strong Duality and Range of Lagrange Multipliers). The optimisation problem in
Equation(7)satisfies
inf min sup max inf ω⊤d(µ,λ)−l⊤A′ω
l∈Rd +A′∈Cω∈∆Kπ∈Πr Fˆλ∈Λ Fˆ(µ,π)
= sup min max inf ω⊤d(µ,λ)−l⊤A˜ω. (8)
ω∈∆K l∈L π∈Πr Fˆλ∈Λ Fˆ(µ,π)
Here,L≜{l∈Rd |0≤∥l∥ ≤ 1D(ω,µ,Fˆ)},whereγ ≜min {−A˜iω∗},i.e.theminimum
+ 1 γ i∈[1,d]
slackw.r.t. theoptimalallocation. (ProofisinAppendixC.)
Hereafter,weusetheRHSofEq.(8)asT−1(µ). Theorem1providesahypercubetosearchforthe
Fˆ,r
Lagrangianmultipliers,whichisalinearprogrammingproblem.
Remark:ConnectionswithLagrangian-basedMethodsinBandits.Regretminimisationliterature
leveragesLagrangian-basedoptimistic-pessimisticmethods(Tirinzonietal.,2020;Slivkinsetal.,
2023) to obtain both the sub-linear regret and constraint violation guarantees (Liu et al., 2021;
Bernasconietal.,2024). OurproposedalgorithmLAGEX(Algorithm2)isaprimeexamplewhere
the"self-boundedness"ofthedualvariablesresultsintighterconstraintviolationguarantees(Figure
7and6).
InnerOptimisationProblem. Now,wepeelthelayersoftheoptimisationprobleminEq.(8)and
focusonobtaining
D(ω,µ,Fˆ)≜min max inf ω⊤d(µ,λ)−lTA˜ω.
l∈L π∈Πr Fˆλ∈Λ Fˆ(µ,π)
For known constraints and r = 0, Carlsson et al. (2024) has leveraged results from convex anal-
ysis (Boyd and Vandenberghe, 2004) to show that the most confusing instance for µ lie in the
boundaryofthenormalconeΛ F(µ,π)C spannedbytheactiveconstraintsA π⋆
F
forπ⋆ F. A π⋆
F
isa
sub-matrixofAconsistingatleastK linearlyindependentrows. Thisiscalledtheprojectionlemma.
Specifically,D(ω,µ,F |r =0)=max min min ω⊤d(µ,λ). Inour
π∈Π0
F
π′∈νF(π) λ:λT(π−π′)=0
setting,wearesequentiallyestimatingboththemeanvectorsandtheconstraints,andthus,thenormal
cone. Now,wederivetheprojectionlemmaforourpessimisticfeasiblesetandr ̸=0.
Proposition 1 (Projection Lemma for Unknown Constraints). For any ω ∈ Fˆ and µ ∈ D, the
followingprojectionlemmaholdsfortheLagrangianrelaxation,
D(ω,µ,Fˆ)=min max min min ω⊤d(µ,λ)−l⊤A˜ω. (9)
l∈Lπ∈Πr Fˆπ′∈ν Fˆ(π)λ:λT(π−π′)=r
Thisreducestheinnerminimisationproblemtoalessintensivediscreteoptimisation,whereweonly
havetosearchovertheneighbouringverticesoftheoptimalpolicyinFˆforasolution. Now,anatural
questionarisesaroundthisformulation:
CanwetrackD(ω,µ,Fˆ)intheprojectionlemmaovertimeaswesequentiallyestimatethe
constraints?
Theorem2. Forasequence{Fˆ t} t∈Nand{λˆ t} t∈N,wefirstshowthat(a)lim t→∞Fˆ
t
→F,(b)λ⋆
isunique,and(c)lim λˆ →λ⋆.
t→∞ t
Thus,foranyω ∈F andµ,
lim D(ω,µ,Fˆ)→D(ω,µ,F),
t
t→∞
whereλ∗issuchthatforanyλ∗ ∈argmin ω⊤d(µ,λ). (ProofisinAppendixD.)
λ∈ΛF(µ,π)
6Outer Optimisation Problem. As we guarantee the convergence of D(ω,µ,Fˆ) as Fˆ → F,
t t
we are left with the outer optimisation problem in Equation (8). Since it is a linear problem in
ω, wecanusealinearprogrammingmethodwhichwouldleadtooneoftheverticesofFˆ. But
t
tobesureofanexistenceofasolutionateacht ∈ N, wetryandderivesomewell-behavedness
propertiesoftheoptimalallocationω∗(µ). First,weobservethatourestimatesofthemeanvector
convergetoµast→∞. Hence,wealsogetlim D(ω,µˆ ,Fˆ)→D(ω,µ,F). Now,weensure
t→∞ t t
well-behavednessandexistenceofanoptimalallocationforallt>0.
Theorem3. (Existenceofuniqueoptimalallocation)Forallµ∈D,ω⋆(µ)satisfiestheconditions
1. BoththesetsFˆandω⋆(µ)areclosedandconvex.
2. Forallµ∈Dandω ∈Fˆ,lim D(ω,µˆ ,Fˆ)iscontinuous.
t→∞ t t
3. Reciprocalofthecharacteristictimelim T−1 (µ)iscontinuousforallµ∈D.
t→∞ Fˆ t,r
4. Forallµ∈D,µ→ω⋆(µ)isupperhemi-continuous.
Thus,theoptimizationproblemmax µ⊤πhasauniquesolution.
π∈Fˆ
ProofisinAppendixE.
CharacterisingtheLowerBoundforGaussians. Sincewecanderiveexplicitformoftheoptimisa-
tionproblemforGaussianrewarddistributions,wecharacteriseitfurthertorelateourlowerbound
withthelowerboundforknownconstraints.
Theorem4. Let{P } beGaussiandistributionswithequalvarianceσ2 >0,T−1 is
a a∈[K] Fˆ,r
(cid:40) (cid:41)
(r−µT(π−π′))2
max min max min −lTA˜ω ,
ω∈∆K l∈Lπ∈Πr Fˆπ′∈ν Fˆ(π) 2σ2∥π−π′∥2
Diag(1/ωa)
whereDiag(1/ω )isaK-dimensionaldiagonalmatrixwitha-thdiagonalentry1/ω andν (π)
a a Fˆ
isthesetofneighbouringpoliciesofπinFˆ. (ProofisinAppendixF.)
Now,toconnectwiththelowerboundunderknownconstraints,wefixr =0,i.ewesearchforthe
‘true’optimalpolicyπ⋆ ratherthananr-goodfeasiblepolicy.
F
Corollary1. Letd2 ≜
∥π⋆ F−π∥2
µµ⊤ bethenormoftheprojectionofµonthepolicygap(π⋆ −π).
π ∥π⋆−π∥2 F
F 2
Parti. Then,weget 2σ2K (1+s )≤T (µ)≤ 2σ2K ,whereC =min d2 .
Cknown A˜ Fˆ,0 Cknown known π′′∈νF(π⋆ F) π′′
Partii. Additionally,T (µ)≥ H(1+s ),whereH isinverselyproportionaltothesumofsquares
Fˆ,0 κ2 A˜
ofgapsandκ istheconditionnumberofasub-matrixofAconsistingK linearlyindependent
known
activeconstraintsforπ⋆. (ProofisinAppendixF.1).
Connection to Existing Lower Bounds. (a) Pure exploration under known constraints. The
upper and lower bounds on characteristic time coincides with the existing lower bound under
known constraints, i.e. when ϵ = 0, i.e. Fˆ = F. (b) BAI without constraints. In BAI, we
consider only deterministic policies (or pure strategies) of playing a single arm. Then, we get
d πa = µ |⊤ (π( ⋆ Fπ⋆ F −− π)π a) |a =µ⋆−µ a,i.e. thesub-optimalitygapforarma. Here,µ⋆ isthemeanofthe
bestarm.Inoursetting,iftherearenoconstraintsinvolvedthenA˜ =Aandsoϵ=0.Thenthelower
boundexpressioninPartii. ofCorollary1isinverselyproportionaltothesum-squaredsub-optimal
gapswhichresonateswiththecomplexitymeasureinstandardBAIwithonlysimplexconstraints
(Kaufmannetal.(2016)). ThoughthelowerboundstatedinCorollary1successfullyencompasses
theeffectofunknownlinearconstraintbyintroducingnovelconstraintdependentfactorsthatscales
thelowerbound.
4 LATSANDLAGEX:ALGORITHMDESIGNANDANALYSIS
Now,weproposetwoalgorithmstoconductpureexplorationwithLagrangianrelaxationoflower
bound,andderiveupperboundsontheirsamplecomplexities.
Assumption2(Distributionalassumptionsonrewardsandconstraints). Werequiretwodistributional
assumptionsonrewardsandconstraints. (i)Rewarddistributions{P }K aresub-Gaussianone
a a=1
parameterexponentialfamilywithmeanvectorµ∈D. (ii)Eachconstraintfollowsasub-Gaussian
K-parameterexponentialfamilyparameterisedbyAifori∈[d].
7Theseassumptionsarestandardinbanditsunderconstraints(Carlssonetal.,2024;Degenneand
Koolen,2019;Pacchianoetal.,2020,2024).
AlgorithmDesign. Anyalgorithminpureexplorationsettingcomprisesofthreemaincomponents.
Thefirstoneisasequentialhypothesistestingthatdecideswhetherweneedtokeepsamplingornot
orpopularlyknownasthe"stoppingcriterion". Tocomeupwithsuchacriterionweneedtomake
surethatwehavegatheredsufficientinformationaboutalltheparametersinestimation,specificallyµ
andAinourcase. Soitseemsnaturaltoenforcecriteriononbothmeanandconstraintconcentration.
Lemma2. Iftherecommendedpolicyis(1−δ)-correctthenitis(1−δ)-feasible.
Thus, while implementing Algorithm 1 and 2, we just need to check the first condition to stop
sampling. ReferAppendixG.1forProof.
Component1: StoppingRule. Stoppingruleofanexplorerdecideswhentostopsampling. While
exploring,oncewegatherenoughstatisticalinformationabouttheparametersinthesystem,thetest
statisticcrossesthestoppingthresholdwiththechosenconfidenceδ,andwestoptorecommendthe
optimalpolicy.
Theorem5. TheChernoffstoppingruletoensure(1−δ)-correctnessand(1−δ)-feasibilityis
(cid:88)K
max inf N d(µˆ ,λ )>β(t,δ)
a,t a,t a
π∈Πr Fˆtλ∈Λ Fˆt(µˆ t,π) a=1
whereβ(t,δ)≜3S 0log(1+logN a,t)+S 0T
(cid:16)
(K∧d S)+ 0log
δ1(cid:17)
.
ProofinAppendixG.2
Algorithm2LAGEX-LAgrangianGameEXplorer
Algorithm1LATS-LAgrangianTrackand 1: InputTimehorizonT,r,Confidencelevelδ >
Stop 0,v
1: Input : Time horizon T, r, Confidence 2: Playeacharmoncetosetµ 1andAˆ 1.
levelδ >0,v 3: whileβ(t−1,δ) > D(ω⋆ t−1,µˆ t−1,Fˆ t−1,l⋆ t−1)
2: Initialization: Aˆ 0 = 0 d×K,µˆ 0 = 0 K, do⇝Proposition1)
Σ 0 =vI K,l 0 4: π t =argmax π∈Πr µˆ⊤ t−1π
3: Playeacharmoncetosetµ 1andAˆ 1. 5: Optimal allocatioF nˆt ω⋆ ⇝ Using AdaGrad
4: while β(t − 1,δ) > viaTheorem4 t
D(ω⋆ t−1,µˆ t−1,Fˆ t−1,l⋆ t−1) do ⇝ 6: OptimizeLagrangianMultiplier:
Proposition1 l⋆ ∈argmin D(ω ,µˆ ,π ,Fˆ ,l)
5 6: : π Ot p= tima arg l m aa lx loπ c∈ aΠ tr F iˆ ot nµˆ :T t−1π ω⋆
t
∈ 7: argC m-t iT nr aa ∈c [1k ,Kin ]g N: al ,∈ t−L 1t −(cid:80)Pt l t s− a =y1 1ωt ⋆ a− ,a s1 t t t−1 ∈
7:
arg Om pa tx
iω m∈ iF zˆ
etD(ω t−1,µˆ
t−
L1, aπ
gt
r, aF nˆ
t g−
ia1, nl⋆ t−18): andF ue pe dd ab teac Σk t,: µˆO tb as ne drv Ae ˆr tewardr tandcostAa t,
8:
M argu Cl mti -ip Tnl rli ∈e ar L cktD in( gω :: ⋆ t,µˆ t− P1 l, aπ yl t⋆ t −1 a, tFˆ t−1,∈ ∈l) 19 0:
:
PropC Co oo s nm it fiip o dnu et n1e cp ec lo u inn g tgf eu i rns vgin ai lg n s:i ωn f⋆ t os ,t ra l a⋆ tn llc ae ∈: λ [Kt ]⇝ Via
argmin N −(cid:80)t ω⋆ [α t,a,β t,a]:{ζ :N a,td(µˆ t,a,ζ)≤g(t)}
9: costF Aee ada b ,∈ aa[1 nc, dK k] u: pO da a, bt t− s ee1 Σrve ,µˆrews a= a n1 r dd Aˆra t,s and
11:
UU pta da= tem loa sx s(cid:8) foNg r( at r,)
t
e, gd r( eα tt m,a, inλ it m,a i) z, ed r( :β Ut,a p, dλ att e,a)(cid:9)
t t t t
10: t=t+1 withL =⟨ω⋆,U ⟩−l⋆⊤A˜ ω⋆
t t t t t t
11: endwhile 12: t=t+1
12: Recommendedpolicy: 13: endwhile
π⋆ =argmax π∈Πr µˆT t π 14: Recommendedpolicy:
Fˆt π⋆ =argmax µˆ⊤π
π∈Πr t
Fˆt
Component2: Recommendationrule. Oncethestoppingruleisfired,theagentrecommendsa
policybasedonthecurrentestimateofµˆ accordingtheruleπ⋆ =argmax µˆ⊤π.
t Fˆ
τδ
π∈Πr
Fˆτδ
t
Component3: SamplingStrategy. Wepresenttwonovelsamplingalgorithms: LATSandLAGEX.
8a. LATS.ThealgorithmLATS(Algorithm1)usesaTrackandStopstrategyadaptedtotheunknown
constraint setting. We use blue markers in the pseudocode (Algorithm 1) to denote the novel
approachestakentohandlethechallengeofestimatingthefeasiblespaceperstep. Thealgorithm
firstwarmsuptheparameterestimatesbyplayingeacharmonce. Thenuntiltheteststatisticjumps
overthethreshold,firstitcomputestheoptimalallocation(Line4)undertheestimatedfeasiblespace
atthecurrentstepsolvingtheLagrangianrelaxedoptimizationprobleminProposition1byplugging
inthebestchoiceofLagrangianmultiplieroptimizedinthepreviousiteration. Usingthiscurrent
optimal allocation we optimize the Lagrangian multiplier maintaining the bounds of it’s 1-norm
statedinTheorem1. ThealgorithmusesC-tracking(GarivierandKaufmann,2016)totrackthe
actiontakenperstep. Finallyweobservetheinstantaneousrewardandcostfeedbacktoupdatethe
parameterestimatesbasedonthem(Line9).
Theorem6. Letsbetheshadowprices≜ Γmax oftheslackΓ.Foranyα>1,theexpectedstopping
Γmin
timeofLATSsatisfieslim
E[τδ]
≤αT (µ)(1+s).(ProofisinAppendixG.3.)
δ→0 log(1/δ) F,r
b. LAGEX.Algorithmsbasedontrackandstopmechanismtendtofailincaseoflargerproblems
whereefficientoptimizationbecomesachallengeduetotheuseofamax-minoracleperstep. To
improveonthisweleveragethetwo-playerzerosumgameapproachintroducedinDegenneetal.
(2019b). Algorithm2alsostartsbyplayingeacharmoncetowarmupparameterestimates. Thenit
usesaallocationplayer(WehaveusedAdaGrad)tooptimizetheallocationω inLine5againstthe
t
mostconfusinginstancew.r.tcurrentestimateofµoptimisedbyainstanceplayerwhichminimizes
(cid:80)K ω d(µˆ ,λ )−l⋆⊤A˜ ω withrespecttoλ∈Λ (µ,π). Sinceoursearchspaceinclosed
a=1 a,t a,t a t t t Fˆ t √
andconvex,theallocationplayerenjoyssub-linearregretoforderO( tlogt),whereastheinstance
player computes the best confusing instance using the Lagrangian formulation of the weighted
projectionlemmastatedinProposition1. TheninLine11,Adagradlossfunctionisupdatedwith
alossbyintroducingoptimismasU definedinLine10. LAGEXalsousesC-trackingasLATS
t
totracktheactionstakenperstep. Finally,LAGEXobservestheinstantaneousrewardandcostto
updatetheestimates.
Theorem7. TheexpectedsamplecomplexityofLAGEXsatisfies
E[τ]≤T (δ)+2s+CK.
0
√
whereT (δ)≜max(cid:8) t∈N:t≤T (µ)(cid:0) β(t,δ)+O(cid:0) tlogt(cid:1)(cid:1)(cid:9) andC ≈21isaconstant.
0 F
Implications. Theorem6and7showbothLATSandLAGEXareasymptoticallystable. Also,for
LATS,theeffectoftheunknownconstraintsintheformofshadowpricearisesinamultiplicative
way,whereasforLAGEX,itisadditive. Thus,LAGEXshouldshowalowersamplecomplexitythan
LATS,whichislatervalidatedintheexperiments. ThecompleteproofisinAppendixG.4.
5 EXPERIMENTALANALYSIS
Now, we empirically test performance of proposed algorithms and the baselines. We refer to
Appendix I for the details about different setups, baseline algorithms, thresholds, and parameter
values.
Synthetic Data: Setup 1. We evaluate with two environments having means
[1.5,1.0,µ ,0.4,0.3,0.2,0.1].
3
Observation 1: Universality. We vary µ from 0.5 to 2.5. For each environment, we plot the
3
correspondingunconstrainedBAIlowerbounds(inred)andlowerboundsunderconstraints(inblue)
inFigure2. Weobservethattheconstraintproblemgetseasierwithincreasingµ . Incontrast,the
3
BAIproblemchangesnon-monotonically. BAIproblemgetsharderwhenµ isaround1.5asthe
3
suboptimalitygapgetsverysmall. ButtheconstraintproblemstayseasierthanBAI.InFigure2,
wealsoplotthemediansamplecomplexityofLAGEXacrosstheseenvironmentsover500runs.
WeobservethatLAGEXgrowsparalleltothelowerboundunderconstraintsandcantrackitacross
environments.
Observation2: Efficiency. Werunallthesealgorithmsintwoenvironment: (i)hardwithµ =0.5
3
and(ii)easywithµ =1.3. WecallthefirstenvironmenthardasitisharderthanBAIandsimilarly,
3
the second environment easy. In Figure 3 and 4 we observe that (i) among the algorithms with
unknownconstraintsLAGEXincurtheleastsamplecomplexity,and(ii)wepayaminimalcostthan
9100000 Known lower bound
9 L L.A BG iE nX k( nM oe wd nia sn e) tting BAI lower bound
Unconstrained BAI 80000
8
60000
7
6 40000
5
20000
4
0
Figure
2:3 0 L.50 o0 w.75 e1 r.00 b1. o25 u1 n.5 30 d1 s.75 w2.00 ith2.25 a2 n.50
d without
LAGEX LATS CTnS CGE CTnS_WLag CGE_WLag Uniform PTnS
constraints,andLAGEXforµ ∈ [0.5,2.5] Figure3: Samplecomplexity(median±std.)
3
inSetup1. ofalgorithmsforhardenv. inSetup1.
3000 Known lower bound 100000 Known lower bound
BAI lower bound
2500
80000
2000
60000
1500
40000
1000
500 20000
0 0
LAGEX LATS CTnS CGE CTnS_WLag CGE_WLag Uniform PTnS LAGEX LATS CTnS CGE CTnS_WLag CGE_WLag Uniform PTnS
Figure4: Samplecomplexity(median±std.) Figure5: Samplecomplexity(median±std.)
ofalgorithmsforeasyenv. inSetup1. ofalgorithmsforIMDB-50K.
theknownconstraintLagrangianalgorithmsinhardenvwhereasthepriceofestimatingconstraints
isprominentineasyenv.
RealData: IMDB-50KDataset. WeevaluateLATS,LAGEX,andthebaselinesonIMDB50K
dataset (Maas et al., 2011). For ease of comparison, we use the same bandit environment as
in(Carlssonetal.,2024). Weuse12movies. Wesearchfortheoptimalpolicywhichallocatesweight
atmost0.3toactionmoviesandatleast0.3tofamilyanddramamovies. Thetrueoptimalpolicyis
[0.3,0.3,0,0,0.4,0,0,0,0,0,0,0]. Weassumeδ =0.1. Wecomparethesamesetofalgorithmsas
Setup1.
Observation: LAGEXhasbettersamplecomplexity. FromFigure5,weobservethatLAGEX
performsbetterthanotheralgorithmsintheunknownconstraintssetting. LATSalsoperformswellon
theIMDBenvironmentbutnotablywecannotdistinguishitsperformancefromthatoftheUniform
explorer.
6 DISCUSSION&FUTUREWORKS
Westudytheproblemofpureexplorationunderunknownlinearconstraints. Thisproblemrequires
trackingbothmeanvectorandconstraintstorecommendar-goodfeasiblepolicy. Weencompassthis
effectwithaLagrangianrelaxationofthelowerboundforknownconstraints. Wefurtherdesignan
pessimisticestimateofthefeasiblesettoensureidentificationoftheoptimalfeasiblepolicy. These
toolsallowsustoproposetwoalgorithmsLATSandLAGEX.Weprovetheirsamplecomplexity
upperbounds,andconductnumericalexperimentstofindthatLAGEXisthemostefficientamong
baselines.
Fromthelowerboundperspective,wehaveproposedaLagrangianrelaxationoftheknownlower
boundswithplug-inestimatesoftheconstraints. Onemightbeinterestedtoderivethelowerbounds
when bothconstraints andrewardsare considered asfeedback. In this paper, wefocus onlinear
constraintsonpolicies. Onemightbeinterestedinnon-linearconstraintsoverthepolicyspace. It
wouldbeinterestingtoextendourLagrangian-basedtechniquetononlinearconstraints.
AcknowledgmentsandDisclosureofFunding
WeacknowledgetheANRJCJCprojectREPUBLIC(ANR-22-CE23-0003-01),thePEPRproject
FOUNDRY(ANR23-PEIA-0003),andtheInria-JapanassociateteamRELIANTforsupportingthe
project.
10
semit
gnippotS
)elacs
gol
ni(
emit
gnippotS
semit
gnippotS
semit
gnippotSReferences
Abbasi-yadkori,Y.,Pál,D.,andSzepesvári,C.(2011). Improvedalgorithmsforlinearstochastic
bandits. In Shawe-Taylor, J., Zemel, R., Bartlett, P., Pereira, F., and Weinberger, K., editors,
AdvancesinNeuralInformationProcessingSystems,volume24.CurranAssociates,Inc.
Agrawal,S.andDevanur,N.(2016). Linearcontextualbanditswithknapsacks. InLee,D.,Sugiyama,
M.,Luxburg,U.,Guyon,I.,andGarnett,R.,editors,AdvancesinNeuralInformationProcessing
Systems,volume29.CurranAssociates,Inc.
Agrawal,S.andDevanur,N.R.(2014). Banditswithconcaverewardsandconvexknapsacks. InEC
’14,page989–1006,NewYork,NY,USA.AssociationforComputingMachinery.
Agrawal,S.,Devanur,N.R.,andLi,L.(2016). Anefficientalgorithmforcontextualbanditswith
knapsacks, and an extension to concave objectives. In Feldman, V., Rakhlin, A., and Shamir,
O.,editors,29thAnnualConferenceonLearningTheory,volume49ofProceedingsofMachine
LearningResearch,pages4–18,ColumbiaUniversity,NewYork,NewYork,USA.PMLR.
Amani, S., Alizadeh, M., and Thrampoulidis, C. (2019). Linear stochastic bandits under safety
constraints.
Auer,P.,Cesa-Bianchi,N.,andFischer,P.(2002). Finite-timeanalysisofthemultiarmedbandit
problem. Machinelearning,47(2-3):235–256.
Aziz,M.,Kaufmann,E.,andRiviere,M.-K.(2021a). Onmulti-armedbanditdesignsfordose-finding
clinicaltrials. TheJournalofMachineLearningResearch,22(1):686–723.
Aziz,M.,Kaufmann,E.,andRiviere,M.-K.(2021b). Onmulti-armedbanditdesignsfordose-finding
trials. JournalofMachineLearningResearch,22(14):1–38.
Badanidiyuru,A.,Kleinberg,R.,andSlivkins,A.(2018). Banditswithknapsacks. J.ACM,65(3).
Baudry,D.,Merlis,N.,Molina,M.B.,Richard,H.,andPerchet,V.(2024). Multi-armedbanditswith
guaranteedrevenueperarm. InInternationalConferenceonArtificialIntelligenceandStatistics,
pages379–387.PMLR.
Bechhofer,R.E.andBlumenthal,S.(1962). Asequentialmultiple-decisionprocedureforselecting
thebestoneofseveralnormalpopulationswithacommonunknownvariance, ii: Montecarlo
samplingresultsandnewcomputingformulae. Biometrics,18(1):52–67.
Berge, C.(1963). TopologicalSpaces: IncludingaTreatmentofMulti-valuedFunctions, Vector
SpacesandConvexity. Macmillan.
Bernasconi,M.,Castiglioni,M.,andCelli,A.(2024). No-regretisnotenough! banditswithgeneral
constraintsthroughadaptiveregretminimization.
Boyd,S.andVandenberghe,L.(2004). ConvexOptimization. CambridgeUniversityPress.
Bubeck,S.,Munos,R.,andStoltz,G.(2009). Pureexplorationinmulti-armedbanditsproblems. In
AlgorithmicLearningTheory: 20thInternationalConference,ALT2009,Porto,Portugal,October
3-5,2009.Proceedings20,pages23–37.Springer.
Bubeck,S.,Munos,R.,andStoltz,G.(2010). Pureexplorationformulti-armedbanditproblems.
Camilleri,R.,Wagenmaker,A.,Morgenstern,J.H.,Jain,L.,andJamieson,K.G.(2022a). Active
learningwithsafetyconstraints. InKoyejo,S.,Mohamed,S.,Agarwal,A.,Belgrave,D.,Cho,
K.,andOh,A.,editors,AdvancesinNeuralInformationProcessingSystems,volume35,pages
33201–33214.CurranAssociates,Inc.
Camilleri,R.,Wagenmaker,A.,Morgenstern,J.H.,Jain,L.,andJamieson,K.G.(2022b). Active
learningwithsafetyconstraints. AdvancesinNeuralInformationProcessingSystems,35:33201–
33214.
Carlsson,E.,Basu,D.,Johansson,F.,andDubhashi,D.(2024). Pureexplorationinbanditswith
linear constraints. In International Conference on Artificial Intelligence and Statistics, pages
334–342.PMLR.
11Chen, S., Lin, T., King, I., Lyu, M.R., andChen, W.(2014). Combinatorialpureexplorationof
multi-armedbandits. InGhahramani,Z.,Welling,M.,Cortes,C.,Lawrence,N.,andWeinberger,
K.,editors,AdvancesinNeuralInformationProcessingSystems,volume27.CurranAssociates,
Inc.
Chen,T.,Gangrade,A.,andSaligrama,V.(2022a). Doubly-optimisticplayforsafelinearbandits.
arXivpreprintarXiv:2209.13694.
Chen,T.,Gangrade,A.,andSaligrama,V.(2022b). Strategiesforsafemulti-armedbanditswith
logarithmicregretandrisk. InInternationalConferenceonMachineLearning,pages3123–3148.
PMLR.
Cheshire, J., Menard, P., and Carpentier, A. (2021). The influence of shape constraints on the
thresholdingbanditproblem.
Degenne,R.andKoolen,W.M.(2019). Pureexplorationwithmultiplecorrectanswers. InNeural
InformationProcessingSystems.
Degenne,R.,Koolen,W.M.,andMénard,P.(2019a). Non-asymptoticpureexplorationbysolving
games. InWallach,H.,Larochelle,H.,Beygelzimer,A.,d'Alché-Buc,F.,Fox,E.,andGarnett,R.,
editors,AdvancesinNeuralInformationProcessingSystems,volume32.CurranAssociates,Inc.
Degenne,R.,Koolen,W.M.,andMénard,P.(2019b). Non-asymptoticpureexplorationbysolving
games.
Even-Dar,E.,Mannor,S.,andMansour,Y.(2002a). Pacboundsformulti-armedbanditandmarkov
decisionprocesses. InAnnualConferenceComputationalLearningTheory.
Even-Dar,E.,Mannor,S.,andMansour,Y.(2002b). Pacboundsformulti-armedbanditandmarkov
decisionprocesses.InComputationalLearningTheory:15thAnnualConferenceonComputational
LearningTheory,COLT2002Sydney,Australia,July8–10,2002Proceedings15,pages255–270.
Springer.
Faizal, F. Z. and Nair, J. (2022). Constrained pure exploration multi-armed bandits with a fixed
budget. arXivpreprintarXiv:2211.14768.
Fiez, T., Jain, L., Jamieson, K. G., and Ratliff, L. (2019). Sequential experimental design for
transductivelinearbandits. Advancesinneuralinformationprocessingsystems,32.
Fonseca, C. M. and Fleming, P. J. (1998). Multiobjective optimization and multiple constraint
handlingwithevolutionaryalgorithms.i.aunifiedformulation. IEEETransactionsonSystems,
Man,andCybernetics-PartA:SystemsandHumans,28(1):26–37.
Garivier,A.andKaufmann,E.(2016). Optimalbestarmidentificationwithfixedconfidence. In
Feldman,V.,Rakhlin,A.,andShamir,O.,editors,29thAnnualConferenceonLearningTheory,
volume49ofProceedingsofMachineLearningResearch,pages998–1027,ColumbiaUniversity,
NewYork,NewYork,USA.PMLR.
Garivier,A.andKaufmann,E.(2021). Non-asymptoticsequentialtestsforoverlappinghypotheses
andapplicationtonearoptimalarmidentificationinbanditmodels.
Garivier,A.,Ménard,P.,Rossi,L.,andMenard,P.(2018). Thresholdingbanditfordose-ranging:
Theimpactofmonotonicity.
Hutchinson,S.,Turan,B.,andAlizadeh,M.(2024). Directionaloptimismforsafelinearbandits.
Immorlica,N.,Sankararaman,K.,Schapire,R.,andSlivkins,A.(2022). Adversarialbanditswith
knapsacks. J.ACM,69(6).
Jamieson,K.andNowak,R.(2014). Best-armidentificationalgorithmsformulti-armedbanditsin
thefixedconfidencesetting. In201448thAnnualConferenceonInformationSciencesandSystems
(CISS),pages1–6.IEEE.
Jourdan,M.andDegenne,R.(2022). Choosinganswersinepsilon-best-answeridentificationfor
linearbandits. InInternationalConferenceonMachineLearning,pages10384–10430.PMLR.
12Jourdan, M., Degenne, R., andKaufmann, E.(2023). Anε-best-armidentificationalgorithmfor
fixed-confidenceandbeyond. AdvancesinNeuralInformationProcessingSystems,36:16578–
16649.
Jourdan, M., Mutný, M., Kirschner, J., and Krause, A. (2021). Efficient pure exploration for
combinatorial bandits with semi-bandit feedback. In Proceedings of the 32nd International
ConferenceonAlgorithmicLearningTheory,volume132.
Katz-Samuels,J.andScott,C.(2018). Feasiblearmidentification. InInternationalConferenceon
MachineLearning,pages2535–2543.PMLR.
Kaufmann,E.,Cappé,O.,andGarivier,A.(2016). Onthecomplexityofbestarmidentificationin
multi-armedbanditmodels.
Kaufmann,E.andKoolen,W.M.(2021).Mixturemartingalesrevisitedwithapplicationstosequential
testsandconfidenceintervals. JournalofMachineLearningResearch,22(246):1–44.
Kazerouni,A.,Ghavamzadeh,M.,Abbasi-Yadkori,Y.,andRoy,B.V.(2017).Conservativecontextual
linearbandits.
Lattimore,T.andSzepesvári,C.(2020). BanditAlgorithms. CambridgeUniversityPress.
Li, L., Jamieson, K., DeSalvo, G., Rostamizadeh, A., and Talwalkar, A. (2017). Hyperband: A
novelbandit-basedapproachtohyperparameteroptimization. TheJournalofMachineLearning
Research,18(1):6765–6816.
Li, S., Zhang, L., Yu, Y., and Li, X. (2023). Optimal arms identification with knapsacks. In
InternationalConferenceonMachineLearning,pages20529–20555.PMLR.
Li, X., Sun, C., and Ye, Y. (2021). The symmetry between arms and knapsacks: A primal-dual
approachforbanditswithknapsacks. InMeila,M.andZhang,T.,editors,Proceedingsofthe38th
InternationalConferenceonMachineLearning,volume139ofProceedingsofMachineLearning
Research,pages6483–6492.PMLR.
Libin,P.J.,Verstraeten,T.,Roijers,D.M.,Grujic,J.,Theys,K.,Lemey,P.,andNowé,A.(2019).
Bayesianbest-armidentificationforselectinginfluenzamitigationstrategies. InMachineLearning
and Knowledge Discovery in Databases: European Conference, ECML PKDD 2018, Dublin,
Ireland,September10–14,2018,Proceedings,PartIII18,pages456–471.Springer.
Lindner,D.,Tschiatschek,S.,Hofmann,K.,andKrause,A.(2022). Interactivelylearningpreference
constraintsinlinearbandits. InInternationalConferenceonMachineLearning,pages13505–
13527.PMLR.
Lindståhl, S., Proutiere, A., and Johnsson, A. (2022). Measurement-based admission control in
slicednetworks: Abestarmidentificationapproach. InGLOBECOM2022-2022IEEEGlobal
CommunicationsConference,pages1484–1490.IEEE.
Liu, X., Li, B., Shi, P., and Ying, L. (2021). An efficient pessimistic-optimistic algorithm for
stochasticlinearbanditswithgeneralconstraints.
Ma,W.(2014). ImprovementsandGeneralizationsofStochasticKnapsackandMulti-ArmedBandit
ApproximationAlgorithms: ExtendedAbstract,pages1154–1163. ACM-SIAM.
Maas,A.L.,Daly,R.E.,Pham,P.T.,Huang,D.,Ng,A.Y.,andPotts,C.(2011). Learningword
vectorsforsentimentanalysis. InLin,D.,Matsumoto,Y.,andMihalcea,R.,editors,Proceedings
ofthe49thAnnualMeetingoftheAssociationforComputationalLinguistics: HumanLanguage
Technologies,pages142–150,Portland,Oregon,USA.AssociationforComputationalLinguistics.
Magureanu,S.,Combes,R.,andProutiere,A.(2014). Lipschitzbandits: Regretlowerboundsand
optimalalgorithms.
Mason, B., Jain, L., Tripathy, A., and Nowak, R. (2020). Finding all ε-good arms in stochastic
bandits. AdvancesinNeuralInformationProcessingSystems,33:20707–20718.
13Moradipari, A., Amani, S., Alizadeh, M., and Thrampoulidis, C. (2020). Safe linear thompson
samplingwithsideinformation.
Pacchiano, A., Ghavamzadeh, M., and Bartlett, P. (2024). Contextual bandits with stage-wise
constraints. arXivpreprintarXiv:2401.08016.
Pacchiano,A.,Ghavamzadeh,M.,Bartlett,P.,andJiang,H.(2020). Stochasticbanditswithlinear
constraints.
Paulson,E.(1964). Asequentialprocedureforselectingthepopulationwiththelargestmeanfromk
normalpopulations. TheAnnalsofMathematicalStatistics,35(1):174–180.
Sankararaman, K. A. and Slivkins, A. (2018). Combinatorial semi-bandits with knapsacks. In
Storkey,A.andPerez-Cruz,F.,editors,ProceedingsoftheTwenty-FirstInternationalConference
onArtificialIntelligenceandStatistics,volume84ofProceedingsofMachineLearningResearch,
pages1760–1770.PMLR.
Shang, X., Colin, I., Barlier, M., and Cherkaoui, H. (2023). Price of safety in linear best arm
identification.
Singh,A.andJoachims,T.(2019). Policylearningforfairnessinranking. InWallach,H.,Larochelle,
H., Beygelzimer, A., d'Alché-Buc, F., Fox, E., and Garnett, R., editors, Advances in Neural
InformationProcessingSystems,volume32.CurranAssociates,Inc.
Slivkins,A.,Sankararaman,K.A.,andFoster,D.J.(2023). Contextualbanditswithpackingand
coveringconstraints: Amodularlagrangianapproachviaregression. InNeu,G.andRosasco,L.,
editors,ProceedingsofThirtySixthConferenceonLearningTheory,volume195ofProceedings
ofMachineLearningResearch,pages4633–4656.PMLR.
Slutsky,E.(1925). ÜberstochastischeAsymptotenundGrenzwerte. Metron5,Nr.3,3-89(1925).
Tirinzoni,A.,Pirotta,M.,Restelli,M.,andLazaric,A.(2020).Anasymptoticallyoptimalprimal-dual
incrementalalgorithmforcontextuallinearbandits. InLarochelle,H.,Ranzato,M.,Hadsell,R.,
Balcan,M.,andLin,H.,editors,AdvancesinNeuralInformationProcessingSystems,volume33,
pages1417–1427.CurranAssociates,Inc.
Tran-Thanh,L., Chapman, A., Rogers, A.,andJennings, N.R.(2012). Knapsackbasedoptimal
policiesforbudget-limitedmulti-armedbandits. InTwenty-SixthAAAIConferenceonArtificial
Intelligence(AAAI-12)(22/07/12-22/07/12),pages1134–1140.
Villar,S.,Bowden,J.,andWason,J.(2015). Multi-armedbanditmodelsfortheoptimaldesignof
clinicaltrials: Benefitsandchallenges. StatisticalScience,30:199–215.
Wang,L.,Bai,Y.,Sun,W.,andJoachims,T.(2021a). Fairnessofexposureinstochasticbandits. In
Meila,M.andZhang,T.,editors,Proceedingsofthe38thInternationalConferenceonMachine
Learning,volume139ofProceedingsofMachineLearningResearch,pages10686–10696.PMLR.
Wang,Z.,Wagenmaker,A.,andJamieson,K.(2021b). Bestarmidentificationwithsafetyconstraints.
Wu,Y.,Zheng,Z.,andZhu,T.(2023). Bestarmidentificationwithfairnessconstraintsonsubpopula-
tions. In2023WinterSimulationConference(WSC),pages540–551.IEEE.
Zhao,Y.andYang,L.(2024). Constrainedcontextualbanditalgorithmforlimited-budgetrecommen-
dationsystem. EngineeringApplicationsofArtificialIntelligence,128:107558.
14Appendix
Table of Contents
A Notations 16
B Additionaldiscussiononproblemsetting 17
B.1 Extendedrelatedwork . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
B.2 Motivations:Reductionstoandgeneralisationsofexistingsettings . . . . . . . . 18
C StrongDualityandtheLagrangianmultiplier:ProofofTheorem1 20
D LagrangianRelaxationofProjectionLemma:ProofofTheorem2 22
E Characterizationoftheuniqueoptimalpolicy:ProofofTheorem3 25
F LagrangianLowerBoundforGaussians:ProofofTheorem4 26
F.1 BoundsonSamplecomplexity:ProofofCorollary1Part(a) . . . . . . . . . . 27
F.2 Impactofunknownlinearconstraints:ProofofCorollary1Part(b) . . . . . . . 28
G SampleComplexityupperbounds(Analysisofalgorithms) 29
G.1 ProofofLemma2:Implicationof(1−δ)-correctness . . . . . . . . . . . . . . 29
G.2 StoppingCriterion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
G.3 UpperBoundofLATS. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
G.4 UpperBoundforLAGEX . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
G.5 Applicationstoexistingproblems . . . . . . . . . . . . . . . . . . . . . . . . . 38
H Constraintviolationsduringexploration 39
H.1 UpperBoundonConstraintViolation . . . . . . . . . . . . . . . . . . . . . . . 39
H.2 Experimentalresultsonconstraintviolation . . . . . . . . . . . . . . . . . . . . 39
I Experimentaldetails 41
I.1 SamplecomplexityplotsforSetup2 . . . . . . . . . . . . . . . . . . . . . . . 41
J TechnicalresultsandknowntoolsinBAIandpureexploration 42
J.1 Concentrationlemmaforconstraints . . . . . . . . . . . . . . . . . . . . . . . 42
J.2 UsefulresultsfromBAIandpureexplorationliterature . . . . . . . . . . . . . . 43
J.3 Usefuldefinitionsandtheoremsfromliteratureoncontinuityofconvexfunctions 44
15A Notations
Notation Definition
∆ K K-simplex
K NumberofArms
A Trueconstraintset
d Numberofconstraints
F Truefeasiblesetw.r.tA,F ={A∈RN×K :Aπ≤0}
A F˜ ˆ tt EstimatedP fe es as sim ibi ls eti sc etes wti .m r.ta pte eso sf imco isn ts ictra ei sn tit mse at teat A˜tim ate tit m,A e˜ tt ,= FA =ˆ − {A˜f t(t ∈,δ R)| N|ω ×t K|| Σ :− t A1 ˜ tπ≤0}
A TheactionsetofKpossiblechoices
ω
t
Allocationchosenattimet
a
t
ActionattimetamongKpossibleactions
N NumberofConstraints
Γ Slackoftheoptimisationproblem
σ2 Varianceoftherewarddistribution(Gaussian)ofarms
T TimeHorizon
r t,c
t
Rewardandcostobservedattimet
δ Chosenconfidencelevel
l
t
TheLagrangianmultiplierattimet
Σ t Thecovariancematrix(Grammatrix)atroundt
Λ F(µ,π) Setofalternative(confusing)instancesforbanditinstanceµ
Λ Fˆ(µ,π) Estimatedsetofalternative(confusing)instancesforbanditinstanceµ
ν(π⋆) Neighboringsetofoptimalr-goodfeasiblepolicyπ⋆
ν(πˆ⋆) Neighboringsetofestimatedoptimalr-goodfeasiblepolicyπˆ⋆
τ
δ
Stoppingtimeof(1−δ)-correctalgorithm
π⋆ Trueoptimalpolicyw.r.tactualconstraintsetA
F
π⋆ OptimalPolicyfortheestimatedfeasibleset
Fˆ
π⋆ Optimalr-goodfeasiblepolicywithrespecttoπ⋆
F
πˆ⋆ Optimalr-goodfeasiblepolicywithrespecttoπ⋆
Fˆ
s Shadowprice=≜ Γmax
Γmin
16B Additionaldiscussiononproblemsetting
B.1 Extendedrelatedwork
Historicalpioneeringworks.Literatureonbanditshascomealongwaysincetheproblemofoptimal
sequentialsamplingstartedwiththeworksofBechhoferandBlumenthal(1962)andPaulson(1964)
withtheassumptionofthepopulationsbeingnormallydistributed. Totalkaboutpureexploration
setting, Even-Daretal.(2002b), Bubecketal.(2010)shouldbementionedasthefirstoneswho
workedinthisspecificsettingforstochasticbandits.
Existing work on adapting known constraints. In Multi-armed bandit literature, people often
introduceconstraintsasanotionofsafetywheretheyimposeknownconstraintsonthechosenarm
orontheexplorationprocess. Wangetal.(2021b)considerspurestrategy(onlyoneco-ordinateas
chosenaction)andimposesasafetythresholdonthelinearcostfeedbackofthechosenarm. Onthe
otherhand,thesettingconsideredinCarlssonetal.(2024)iscloserasittracksanoptimalpolicy
w.r.ttoaknownsetofknownconstraints. Ontheotherhand,Liuetal.(2021)(Improvementover
Pacchianoetal.(2020)inMABsetting)generalizedtheknownconstraintregretminimizationsetting
byassumingexistenceofasetofgeneralconstraints. Ourworkcapturesthehardnessofnotknowing
theconstraintsetwhiletrackingthelowerboundandalsoinsamplecomplexityupperboundsof
Algorithm 1 and 2. Our work also introduce shadow price as a novel term in pure exploration
literaturewhichcharacterisestheextracostthatarisesduetotrackingtheunknownconstraints.
Learningunknownconstraints. Lindneretal.(2022)considersconstrainedlinearbest-armidentifi-
cationarmarevectorswithknownrewardsandasingleunknownconstraint(representingpreferences)
ontheactions. Worksonadaptingtounknownconstraintsisdiscussedintherelatedworksectionof
themainpaper.
TransductiveLinearBandit. InthissettingFiezetal.(2019)Camillerietal.(2022b)studiesthis
settingwithunknownlinearconstraintswherewehavetofindthebestsafearminafinitesetZ
differentthanactualarmsetA. Oursettinggeneralisesthesettinginthesensethatthefinitefeasible
set Z is not static, rather we track Z per time step t ∈ N and explore within that set to find the
t
optimal allocation. At the end of exploration after hitting the stopping criterion at τ the agent
δ
recommendstheoptimalpolicyinsidethesetZ .
τδ
RegretMinimizationwithUnknownconstraints. Inbanditliterature,constraintsareoftenintro-
ducedinthesettingtostudyregretminimization. Moradiparietal.(2020)studiesregretminimization
usingLinearThompsonSampling(LTS)imposingknownsafetyconstraintsonthechosenaction.
Amani et al. (2019) studies contextual bandits under unknown and unobserved linear constraint,
whereasKazerounietal.(2017)Pacchianoetal.(2020)studiesUCBbasedalgorithmsforregret
minimizationforlinearbanditswhichassumesexistenceofasafeactionspaceincaseofunknown
anytimelinearconstraint. Inlinewiththese,recentworksHutchinsonetal.(2024)Pacchianoetal.
(2024)Shangetal.(2023)improvedonregretguaranteesandthefirstonerelaxedtheassumptionof
existenceofapessimisticsafespace.Chenetal.(2022a)introducesdoubly-optimisticsettingtostudy
safelinearbandit(SLB).Liuetal.(2021)generalisedthesettingofPacchianoetal.(2020)notonly
relaxingtheconditionofhavingasafeactionbutalsoconsideredasetofgeneralconstraintsandalso
capturedthenotionofbothanytimeandend-of-timeconstraintswhichwealsoseeinCarlssonetal.
(2024). Liuetal.(2021)alsoshowsthetrade-offbetweenmaximisingrewardorminimizingregret
andconstraintviolationusingLyapunovdrift. Inthisworkwedonotfocusonregretguarantiesbut
findingtheoptimalpolicywithsamplecomplexityasleastaspossiblewhiletrackingandsatisfyinga
setofunknownlinearconstraints.
BAIwithFairnessConstraint. Consideringfairnessconstraintinoursettingcanbeaninteresting
applicationtooursetting. RecentlyWuetal.(2023)studiedBestArmIdentificationwithfairness
ConstraintsonSubpopulations(BAICS),wheretheyhavediscussedthetrade-offinthestandard
BAI complexity if there are finite number of subpopulations are given and the best chosen arm
mustperformwell(nottoobad)onallthosesubpopulations. AnotherimportantlineofworkWang
etal.(2021a)SinghandJoachims(2019)exploresregretanalysisofBAIwithpositivemerit-based
exposureoffairnessconstraintswherethechosenpolicyhastosatisfysomefairnessconstraintacross
all its indices. Our setting comes as a direct application to these settings. Further discussion in
SectionB.2.
17BAIwithKnapsackconstraint. WhiletheexistingliteratureonbanditwithknapsackBadanidiyuru
etal.(2018)AgrawalandDevanur(2016)Immorlicaetal.(2022), AgrawalandDevanur(2014)
Agrawal et al. (2016) Sankararaman and Slivkins (2018) Ma (2014) focused on mainly regret
minimization, our setting aligns more as a special case of the Optimal Arm identification with
KnapsacksettinginLietal.(2023);Tran-Thanhetal.(2012);Lietal.(2021). Thoughweaimtofind
thebestpolicyratherthanaspecificarmintheconstraintspace. Oursettingshouldbeconsideredas
aspecialcaseofthesesettings. FurtherdiscussioninSectionB.2.
AlgorithmsonPureexploration. Algorithm1isanextensionoftheTrackandStop(TnS)strategy
from(GarivierandKaufmann,2016),whilethemotivationforAlgorithm2comesfromtheGamified
Explorerstrategyfrom(Degenneetal.,2019b)wherethelowerboundistreatedasazero-sumgame
betweentheallocationandtheinstanceplayer. Wereferto(GarivierandKaufmann,2021),(Garivier
andKaufmann,2016),(Kaufmannetal.,2016),(DegenneandKoolen,2019),BoydandVandenberghe
(2004),Jourdanetal.(2021)etcforimportantconcentrationinequalities,trackinglemmas.
Dose-findingandThresholdingBandits. AnotherspecialcaseofoursettingisDose-findingor
ThresholdingbanditsinstructuredMABliteratureChenetal.(2014)generalizedtheproblem,thena
lineofworkAzizetal.(2021b)Garivieretal.(2018)Cheshireetal.(2021)aimstofindthemaximum
safedoseforaspecificdruginearlystagesofclinicaltrials. Insomesenseoursettinggeneralizes
thissetting. Ifwehavetoadministermorethandrugstoapatient,oursettinggeneralisestotrackthe
bestpossibleproportioninwhichthedrugsshouldbeadministeredwithmaximumefficacy. Further
discussionsinSectionB.2.
B.2 Motivations: Reductionstoandgeneralisationsofexistingsettings
Beforedelvingintothedetailsofthelowerboundsandalgorithms,wefirstclarifyourmotivationby
showinghowdifferentsetupsstudiedinliteratureandtheirvariationsarespecialcaseofoursetting.
ThresholdingBandits. Oursettingencompassesthethresholdingbanditproblem(Azizetal.,2021a).
Thresholdingbanditismotivatedfromthesafedosefindingprobleminclinicaltrials,whereone
wantstoidentifythehighestdoseofadrugthatisbelowaknownsafetylevel.Thishasalsomotivated
thestudiesonsafearmidentification(Wangetal.,2021b). Oursettinggeneralisesitfurthertodetect
thedoseofthedrugwithhighestefficacywhileitisstillbelowthesafetylevel. Wecanformulateitas
identifyingπ⋆ =argmaxµTπ,suchthatIπ ≤Iθ. Rather,generalisingtheclassicalthresholding
bandits,ourformulationcanfurthermodelthesafedosesfortheoptimalcocktailofdrugs,andθcan
havedifferentvaluesacrossdrugs,i.ewecanconsiderdifferentthresholdsfordifferentdrugs.
Optimal policy under Knapsack. Bandits under knapsack constraints have been studied both
in best-arm identification (Li et al., 2023; Tran-Thanh et al., 2012; Li et al., 2021) and regret
minimisation (Badanidiyuru et al., 2018; Agrawal and Devanur, 2016; Immorlica et al., 2022;
AgrawalandDevanur,2014;Agrawaletal.,2016;SankararamanandSlivkins,2018;Ma,2014)
literature. BAIunderknapsacksismotivatedbythefactthatdetectinganoptimalarmmighthave
additionalresourceconstraintsinadditiontothenumberofrequiredsamples. Thishasledtostudyof
BAIwithknapsacksonlyunderfixed-budgetsettings(Lietal.,2023). Butasinregret-minimisation
literature(SankararamanandSlivkins,2018;Ma,2014), onemightwanttorecommendapolicy
that maximises utility while satisfying knapsack constraints. For example, we want to manage
cacheswheretherecommendedmemoryallocationshouldsatisfyacertainresourcebudget.Thus,the
recommendedpolicyhastosatisfyπ⋆ =argmax µˆT π,whereC ≜{Aπ ≤c}.Naturally,
τ π∈CA τδ A τδ
thisisaspecialcaseofourproblemsetting.
Feasiblearmselection. Welookatthepureexplorationproblemoffeasiblearmselectionstudiedby
Katz-SamuelsandScott(2018). Here,wethinkofaproblemofworkershavingamulti-dimension
vectorrepresentationwhereeachindexdenotestheaccuracyofthatworkerbeingabletoidentifya
specificclasslabelinaclassificationtaskinhand. Theproblemturnstobeafeasiblearmselection
fromasimpleBAIproblemwhenweimposeafeasibilityconstraintthatforexample,thechosen
workershouldshowmorethan90%accuracyacrossalllabels. Wecangeneralisethissettingin
the sense that we are now not looking for a specific worker, rather we want to make a team of
workersthathasthehighestutility. Therecommendedpolicyattimet∈N,max µTπsuch
π∈∆K−1 t
thatfTπ ≥ τ whereτ isthedesiredthresholdlevel. Thegeneralisationofthesettingpitchinas
thresholdsofτ canhavedifferentvaluescorrespondingtodifferentworkers.
18BAIwithfairnessacrosssub-populations. TheBestArmIdentificationwithfairnessConstraints
onSub-population(BAICS)studiedinWuetal.(2023)aimsonselectinganarmthatmustbefair
acrossallsub-populationsratherthanthewholepopulationinstandardBAIsetting. Let,thereare
l sub-populationsandµ arethemeanscorrespondingtothea-tharm. Findingonlytheoptimal
a
armK =argmax µ maynotbeenoughbecauseitmaynotperformequallygoodforall
BAI k∈[K] k
the l sub-populations. Then the arm should belong to a set C := {k ∈ [K]|µ ≥ 0,m ∈ [l]}
k,m
where the observation for arm k and population m comes from N(µ ,1) It ensures that the
k,m
chosen arm does not perform too bad for any sub-population. Let us think of a problem where
therearelsub-groupsofpatientsandwehaveK numberofdrugstoadministerwithrewardmeans
µ ,k ∈[K]. Wearelookingforacombinationofdrugsratherthanasingledrugtoadministeras
k
π⋆ =argmax µTπsuchthat1T π =1,∀m∈[l]. Thus,BAICSisaspecialcaseofours.
π∈∆K µ m≥0
Fairnessofexposureinbandits. Wangetal.(2021a)introducedpositivemeritbasedexposureof
fairnessconstraints(SinghandJoachims,2019)instochasticbanditsstandingagainstthewinner-takes-
allallocationstrategythatarehistoricallystudied. Thechosenallocationinthissettingshouldsatisfy
thefairnessconstraint π⋆ a = π⋆ a′ ,∀a′ ∈[K]wheref(.)transformrewardofanarmtoapositive
f(µ⋆) f(µ⋆ )
a a′
merit. ThoughWangetal.(2021a)studiedthissettinginregretanalysis,thissettinginBAIsettingis
adirectapplicationofoursettingaswearelookingforanoptimalpolicyπ⋆ =argmaxµTπsuch
thatπ⋆satisfiesAT π =0whereA isoforder K(K−1) ×K andA isexpressedas,
f(µ) f(µ) 2 f(µ)

1 ifaK− 1(a−1)(a−2)≤j ≤aK− 1a(a−1)andi=a,
f(µa) 2 2
(A ) = −1 ifaK− 1(a−1)(a−2)≤j ≤aK− 1a(a−1)anda<i≤K,
f(µ) ij 0f(µj) otherwise2
.
2
Forexample,whenK =3,A =[[ 1 ,− 1 ,0],[0, 1 ,− 1 ],[ 1 ,0,− 1 ]].
f(µ) µ1 µ2 µ2 µ3 µ1 µ3
19C StrongDualityandtheLagrangianmultiplier: ProofofTheorem1
Theorem1. Foraboundedsequenceof{l t} t∈N,strong-dualityholdsfortheoptimisationproblem
statedinEquation(7)i.e.
inf min sup max inf ω⊤d(µ,λ)−lTA′ω
l∈Rd +A′∈Cω∈∆Kπ∈Πr Fˆλ∈Λ Fˆ(µ,π)
= sup min max inf ω⊤d(µ,λ)−lTA˜ω.
ω∈∆K l∈L π∈Πr Fˆλ∈Λ Fˆ(µ,π)
Here,L≜{l∈Rd |0≤∥l∥ ≤ 1D(ω,µ,Fˆ)},whereγ ≜min {−A˜iω∗},i.e. theminimum
1 γ i∈[1,d]
slackforpessimisticconstraintsw.r.t. theoptimalallocation.
Proof. Thisproofinvolvesthreesteps. Inthefirststepweproveconvexityandotherpropertiesof
thesetsinvolvedinthemainoptimisationproblem8. Inthenextstep,weshowthatSlater’ssufficient
conditionsholdforπasaconsequenceoftheseproperties. Onceweprovetheuniqueoptimalityof
πwestateboundsontheL1-normoftheLagrangianmultiplier. Weconcludebyestablishingstrong
dualityandprovingthestatementofthetheorem.
Step1: Propertiesofperturbedfeasiblesetandalt-set. LetusfirstcheckthepropertiesofFˆ,
Λ (µ,π)andν (π). Forthat,letusremindthedefinitionsofthesesets. Theestimatedfeasibleset
Fˆ Fˆ
(cid:110) (cid:111)
isdefinedasFˆ ≜ π ∈∆ :A˜π ≤0 . Thesetofalternative(confusing)instancesfortheoptimal
K
(cid:110) (cid:111)
policyπˆ⋆ =argmax π∈Πr Fˆµ⊤πisΛ Fˆ(µ,π)≜ λ∈D:r+max π∈Πr FˆλTπ >λTπˆ⋆ . Forπ′
beinganeighbourofπˆ⋆orinotherwords,anextremepointinFˆ,wedecomposethealternativeset
astheunionofhalf-spacesas,
(cid:91) (cid:110) (cid:111)
Λ (µ,π)= λ:λT(πˆ⋆−π′)<r
Fˆ
π′∈ν Fˆ(πˆ⋆)
Weshouldnote,π′sharesatleast(K−1)activeconstraintswithπˆ⋆. ItisclearthatFˆisbounded
andconvexinπ. Since,convexcombinationofanytwoextremepointπ′,π′ intheneighborhoodof
1 2
theoptimalpolicyν (πˆ⋆)alsosharesK−1activeconstraintswithπˆ⋆,soν (πˆ⋆)isconvexinπ′.
Fˆ Fˆ
Let,π′ andπ′ aretwopoliciesintheneighborhoodofπˆ⋆,suchthatforanyalternativeinstance
1 2
λ, λ⊤(π′ − π′) ≥ 0, which implies that the policy π′ is closer to the optimal policy in the
1 2 1
neighborhoodthatthepolicyπ′
2
Therefore,anyconvexcombinationoftheseneighbourhoodpolicy,λT (πˆ⋆−(aπ′ +(1−a)π′))=
1 2
λT(πˆ⋆−π′)−aλT(π′ −π′)≤c. Therefore,thesetΛ (µ,π)isalsoboundedandconvexinπ.
2 1 2 Fˆ
Also, since we are working with pessimistic estimate of A, the set Fˆ will always be non-empty,
becausewewillfindatleastoneA˜ whichisnon-singularandit’sinverseexists.
0
Step2: Slater’scondition. Fromstep1ofthisproofwehavethefollowingproperties
1. Fˆisnon-empty,boundedandconvexinπ.
2. Theperturbedneighborhoodν (π)isconvexforanyπ′ ∈ν (π)
Fˆ Fˆ
3. Λ (µ,π)isalsoboundedandconvexinπ.
Fˆ
Leveragingthesethreeresultsweclaimthatthereexistsaπˆ⋆thatuniquelysolvestheoptimisation
probleminEquation(8)andsatisfytheconstraintswithstrictinequality. Thus,weclaimSlater’s
sufficientconditionsholdforπ.
Step3:BoundontheLagrangianmultiplier. Here,wetrytoboundtheL-1normoftheLagrangian
multiplier. Since,∥l∥ cannotbelessthan0,thenwealreadyhavealowerbound.
1
Nowwerefertolemma5fortheupperbound. Animmediateimplicationofthisresultisthatforany
dualoptimalsolutionl∗,wehave∥l∗∥ ≤ 1 (f(x¯)−q∗). SinceSlater’sconditionsholdinourcase
1 γ
forπ,wecanwritethattheoptimalsolutionoftheLagrangiandual,
201 (cid:16) (cid:17) 1
0≤||l⋆|| ≤ D(ω⋆,µ,Fˆ)−D(ω⋆,µˆ,F) ≤ D(ω,µ,Fˆ)
1 γ γ
where,γ ≜ min {−A˜iω∗}
i∈[1,d]
Where,πˆ⋆isther-goodfeasiblepolicy.
Step4: Establishingstrongduality. ThereforethedomainoftheLagrangianmultiplierisalso
bounded and convex. So again we say that l⋆ uniquely minimises Equation 8. We define L ≜
t
{l ∈ Rd | 0 ≤ ∥l∥ ≤ 1T−1(µˆ)}, where γ ≜ min {−A˜iω∗} Then according to Heine-
1 γ Fˆ,r i∈[1,d]
Borel’stheorem(Theorem9)wecansaythatthesesetsarecompactaswell. Wecanthenconclude
thatStrongdualityholdswhichmeansthatitperfectlymakesenseofsolvingtheLagrangiandual
formulationoftheprimaloptimisationproblembecausethereisnodualitygap. Welateronwill
considerthisformulationastwoplayerzerosumgame. Duetostrongdualityweclaimthattheagent
wileplayingthisgame,Nashequilibriumwillbeeventuallyestablished.
Nowthateverythingisputintoplacewecanconcludewiththeverystatementofthetheoremthat
duetostrongdualitythefollowingholds
inf min sup max inf ω⊤d(µ,λ)−lTA′ω
l∈Rd +A′∈Cω∈∆Kπ∈Πr Fˆλ∈Λ Fˆ(µ,π)
= sup min max inf ω⊤d(µ,λ)−lTA˜ω.
ω∈∆K l∈L π∈Πr Fˆλ∈Λ Fˆ(µ,π)
21D LagrangianRelaxationofProjectionLemma: ProofofTheorem2
Theorem2. Forasequence{Fˆ t} t∈Nand{λˆ t} t∈N,wefirstshowthat(a)lim t→∞Fˆ
t
→F,(b)λ⋆
isunique,and(c)lim λˆ →λ⋆.
t→∞ t
Thus,foranyω ∈F andµ,
lim D(ω,µ,Fˆ)→D(ω,µ,F),
t
t→∞
whereλ∗issuchthatforanyλ∗ ∈argmin ω⊤d(µ,λ)
λ∈ΛF(µ,π)
Proof. Here,weprovethethreepartsofthetheoremconsecutively.
Statement(a): Convergenceofthelimitlim Fˆ. Tobeginwiththeproofofthefirststatement
t→∞
(cid:110) (cid:111)
ofTheorem2weleveragetheresultsstatedinTheorem10. LetH(A˜)≜ π ∈∆ :A˜π ≤0 and
K
thesetfunctionA˜ →H(A˜)∩C whereC =Fˆisanon-emptycompact(proveninSectionCsubset
of∆ ThenthesetH(A˜)∩C canbewrittenas
K
(cid:110) (cid:111)
H(A˜)∩C = π ∈Fˆ :A˜π ≤0
ToapplyTheorem10,{A˜r,r ∈N},mustbeaconvergentsequenceofaffinefunction. Itisevident
thatA˜r foranyr ∈NisanaffinefunctionsinceAislinearinAandtheinducedpessimismworks
asatranslation. Thenwecanproceedtothenextpartoftheproofofstatement1whereweprovethat
{A˜r} r∈Nisaconvergentsequenceoffunctions. ForeaseofnotationwewilldenoteA˜ tforthet-th
elementofthesequence{A˜r} r∈Nfort∈N.
The definition of the confidence radius for any constraint i ∈ [d] follows from the Definition 2
(cid:113)
as f(δ,t) ≜ 1+ 1logK + 1logdetΣ . It is evident from the definition that f(t,δ) is a non-
2 δ 4 t √
decreasingfunctionw.r.ttimeanditgrowswithorderofatleastO( logt)
Wehavefromthedefinitionoftheconfidenceset,foralli∈[d]
(cid:16) (cid:17)
P Aˆi−f(t,δ)||ω || ≤Ai ≤Aˆi+f(t,δ)||ω || ≥1−δ
t t Σ−1 t t Σ−1
t t
(cid:32) (cid:33)
=⇒P
−f(t,δ)||ω t|| Σ− t1
≤
Aˆi t−Ai
≤
f(t,δ)||ω t|| Σ− t1
≥1−δ
σ(Aˆi) σ(Aˆi) σ(Aˆi)
t t t
(cid:32) (cid:33)
f(t,δ)||ω || f(t,δ)||ω ||
=⇒P −
t Σ− t1
≤Z ≤
t Σ− t1
≥1−δ
σ(Aˆi) σ(Aˆi)
t t
(cid:32) (cid:33)
f(t,δ)||ω ||
t Σ−1
=⇒2Φ t ≥2−δ
σ(Aˆi)
t
=⇒
f(t,δ)||ω t||
Σ− t1
≥Φ−1(cid:18)
1−
δ(cid:19)
σ(Aˆi) 2
t
(cid:18) (cid:19)
δ
=⇒f(t,δ)||ω || ≥σ(Aˆi)Φ−1 1−
t Σ− t1 t 2
where Z ≜ Aˆi t−Ai and Φ(.) is the cumulative distribution function of N(0,1) distribution.
σ(Aˆi)
t (cid:113)
lim f(t,δ)∥ω ∥ →0sinceσ(Aˆi)=O( logt). LeveragingCLTatthispointwesay
t→∞ t Σ−1 t t
t
Aˆi −→d Ai,∀i∈[d]
t
ThenbySlutsky’stheorem(Slutsky,1925),weconcludeAˆi−f(t,δ)||ω || −→d Ai,∀i∈[d].
t t Σ−1
t
Itimpliesthat{A˜ r} r∈NisaconvergentsequenceoffunctionforA. Now,weuseTheorem10and
getthefollowingpropertiesofthefeasibleset.
221. H(A˜)∩C ⊂lim H(A˜r)∩C
r→∞
2. lim H(A˜r)∩C isaclosedconvexsupersetofH(A˜)∩C.
r→∞
3. H(A˜)∩C hasnon-emptyinteriorbecauseofthefeasibilityconditionandnocomponentin
A˜ isidentically0.
lim H(A˜r)∩C =H(A˜)∩C
r→∞
4. EvenifthesetH(A˜)∩C hasemptyinteriororsomecomponentifA˜ isidenticallyzero,by
thelaststatementoftheTheorem10wecansayforanyclosedconvexsetQofH(A˜)∩C
wecandesignthefunction{A˜r}insuchawaythatlim H(A˜r)∩C includesQ.
r→∞
AstheconvergenceofA˜ isguaranteednowasymptotically,wecanguarantyconvergenceofthe
t
followinglimitlim Fˆ →F.
t→∞ t
Statement (b) : Proof of Uniqueness of λ⋆ Here, we prove if there exists a confusing instance
λ∗ ∈Λ (µ,π)whichuniquelyminimisesthethefunctionD(.)definedas
Fˆ
D(ω,µ,Fˆ)≜ inf inf ω⊤d(µ,λ)−l⊤A˜ω
l∈Lλ∈Λ Fˆ(µ,π)
We observe that only the leading quantity on the R.H.S associated with the KL is dependent on
λ. So, inthisproofwewillonlyshowthatλ⋆ minimizestheKLdivergenceuniquelyandsince
theKLislinearlydependentontheexpression,provingthiswillbeenoughtoensureuniquenessofλ⋆.
Now,fromthepropertiesofKLweknowthatd(µ,λ)isconvexonthepair(µ,λ). Butitisalso
strictlyconvexonλifsupp(λ)⊆supp(µ)whichistrueinourcase,sinceµ,λ∈D ⊆Rk.
Letusassumetherearetwolocalminimaλ andλ ,withthecondition,
1 2
d(µ,λ )≤d(µ,λ )
1 2
Then,wecanwritefromthepropertyofstrictconvexity,forsome{h:0<h<1},
d(µ,hλ +(1−h)λ )<hd(µ,λ )+(1−h)d(µ,λ )
1 2 1 2
Now,fromtheassumedconditiononλ andλ ,wecanwrite—
1 2
d(µ,λ )≤d(µ,λ )
1 2
=⇒hd(µ,λ )≤hd(µ,λ ),sinceh>0
1 2
=⇒hd(µ,λ )+(1−h)d(µ,λ )≤hd(µ,λ )+(1−h)d(µ,λ )
1 2 2 2
=⇒hd(µ,λ )+(1−h)d(µ,λ )≤d(µ,λ )
1 2 2
Puttingthisresultinthestrictconvexityconditionweget
d(µ,hλ +(1−h)λ )<d(µ,λ )
1 2 2
whichisacontradiction.
Thus,weconcludethatforastrictlyconvexfunctionf(x)withsupp(x)beingconvexaswell,theset
ofminimisersiseitheremptyorsingleton. Then,wecansayλ⋆uniquelyminimizestheKL,orsay
D(ω,µ,Fˆ). Letusnowonceagainremindthedefinitionofperturbedalt-setΛ (µ,π) ≜ {λ ∈
Fˆ
D : max λT(πˆ⋆−π) < r}. Letusdenoteν(πˆ⋆)astheneighborhoodofπˆ⋆. Anyπ ∈ Fˆ is
π∈Fˆ
calledaneighborofπˆ⋆,ifitisanextremepointofFˆ andshares(K-1)activeconstraintswithπˆ⋆.
(cid:110) (cid:111)
Then,wecandecomposetheperturbedalt-setasΛ (µ,π)=(cid:83) λ:λ⊤(πˆ⋆−π)<0 ,
Fˆ π∈ν Fˆ(πˆ⋆)
whichisaunionofhalf-spacesforeachneighbor. Fromthisdecompositionwecanobservethat
πˆ⋆ isnotther-optimalpolicyforλ,i.e,{∃π′ ∈Λ (µ,π):λT(π⋆ −π′)<0}. Then,itfollows
Fˆ Fˆ
similarargumentinCarlssonetal.(2024)toarguethatthemostconfusinginstancew.r.tµliesinthe
boundaryofthenormalcone,whichlandsustoProposition1.
23Foranyω ∈Fˆandµ∈D,thefollowingprojectionlemmaholdsfortheLagrangianrelaxation,
D(ω,µ,Fˆ)=min max min min ω⊤d(µ,λ)−l⊤A˜ω
l∈L π∈Πr Fˆπ′∈ν Fˆ(π)λ:λ⊤(πˆ⋆−π′)=0
=min min min ω⊤d(µ,λ)−l⊤A˜ω
l∈L π′∈ν Fˆ(πˆ⋆)λ:λ⊤(πˆ⋆−π′)=0
Statement(c): Convergenceofthesequence{λˆ n} n∈N. Inknownconstraintsettingtheagenthas
access to F. That means there is the actual sequence {λ n} n∈N for which λ n → λ∗ as n → ∞
sinceD(ω,µ,Fˆ)isconvexandcontinuousonΛ (µ,π). ButinthissettingwetrytoestimateF as
Fˆ
F tˆ on enat sue ra ech itt cim one vest re gp esn to∈ thN e. uS no iqth ue er oe pe tx imis ats lt λh ∗e i{ .eλˆ λn} ⋆n ∈∈N Λsu (c µh ,t πha )t ⊆λˆ n lim∈Λ Fˆ n( Λµ,π () µa ,n πd )w ime ph la iv ee
s
F n→∞ Fˆ
n
{λˆ }→λ∗asn→∞
n
Weusethefundamentaltheoremoflimittocarryoutthisproofwiththehelpofpropertiesofthesets
FˆandΛ. Thepropertieswehavealreadyprovenforthesesetsare
1. Fˆ foranyn∈NisasupersetofF duetothepessimisticchoiceofA.
n
2. Fˆ isanon-emptycompactsubsetof∆ andlim Fˆ =F.
n K n→∞ n
3. Λ (µ,π)isaclosedconvexsetanditalsoisasupersetoftherealalt-setΛ (µ,π).
Fˆ
n
Fˆ
Leveragingthesepropertiesweclaimthatforanyµ∈D,lim Λ (µ,π)=Λ (µ,π). Since
n→∞ Fˆ
n
Fˆ
wehavealreadyprovenuniquenessofλinstatement2,wesayλˆ uniquelyminimisesΛ (µ,π).
n Fˆ
n
Nowfromthe(ϵ,δ)-definitionoflimitswesayifΛ (µ,π)isanϵ-coverofΛ (µ,π)forϵ > 0,
Fˆ
n
Fˆ
then|λˆ n−λ∗| ≤ δ forδ > 0sufficientlysmall. Itimpliesforasequenceof{λˆ n} n∈N weclaim
lim λˆ =λ∗i.ethesequenceconvergence. Thereforeweconcludebythestatementitself
n→∞ n
{λˆ n} n∈N →λ⋆
Hence,proved.
24E Characterizationoftheuniqueoptimalpolicy: ProofofTheorem3
Theorem3. Forallµ∈D,ω⋆(µ)satisfiestheconditions
1. BoththesetsFˆandω⋆(µ)areclosedandconvex.
2. Forallµ∈Dandω ∈Fˆ,lim D(ω,µˆ ,Fˆ)iscontinuous.
t→∞ t t
3. Reciprocalofthecharacteristictimelim T−1 (µ)iscontinuousforallµ∈D.
t→∞ Fˆ t,r
4. Forallµ∈D,µ→ω⋆(µ)isupperhemi-continuous.
Thus,theoptimizationproblemmax µ⊤πhasauniquesolution.
π∈Fˆ
Proof. Thetheoremhasfourstatementsasthesufficientconditionfortheexistenceofuniqueoptimal
policy. Sonaturallywewilldictatetheproofstructureinfourstepsandprovethestatementsoneby
one.
Statement 1: Convexity of feasible space and optimal set function. Let us first analyse the
properties of Fˆ. For any two member of ω ,ω ∈ Fˆ satisfying A˜ω ≤ 0 and A˜ω ≤ 0, their
1 2 1 2
convexcombinationforanyα∈[0,1],
A˜ (αω +(1−α)ω )=αA˜ω +(1−α)A˜ω ≤0
1 2 1 2
ThereforewecansayFˆisconvexbecauseitisclosedunderconvexoperation. WeclaimFˆisalso
closedsince
(a)ThecomplementofFˆ,Fˆc ≜{π ∈∆ :A˜π >0}isanopenset. (b)wehavealreadyproven
K
thelimitofFˆtobeF whichisalwayscontainedbyFˆ.
TheelementsinthedomainofoptimalallocationsetfunctionmustbeincludedinFˆ. Socompactness
ofω∗(µ)isadirectconsequenceofcompactnessofFˆ.
Statement2: Continuityoflimit. WehavealreadyproveninSectionDthatlim Fˆ →F. Also
t→∞ t
byconvexityofKLandCLTweclaimµˆ → µast → ∞andsinceω islinearinD(ω,µ,Fˆ)it
t t
willconvergetoω∗(µ)ast→∞,alsoduetoconvergenceofµˆ . Thenwecansaythatthelimiting
t
valueissameasthevalueifwepluginthelimitsinDi.elim D(ω,µˆ ,Fˆ)=D(ω∗(µ),µ,F).
t→∞ t t
Soweensurethecontinuityoflim D(ω,µˆ ,Fˆ).
t→∞ t
Statement3: Continuityoflimitofinversesamplingcomplexity. Thisstatementdirectlyfollows
fromthestatement2. DuetoconvexityofKL-divergenceandconvergenceofFˆ,thelimitingvalue
existsanditisequaltotheinverseofcharacteristictimewiththelimitingvalue.
Statement 4: Upper hemi-continuity of optimal allocation function. We refer to
Magureanu et al. (2014) (see Lemma 12) for this proof. We denote Q(A˜′) ≜
(cid:26) (cid:12) (cid:27)
lim Fˆ→Fmax ω∈∆K (cid:80)K a=1ω ad(µ,λ)−l⊤A˜′′ω(cid:12) (cid:12) (cid:12)A˜′′ω ≤ 0,ω a ≥ 0∀i ∈ [K] = ω(µ)where
A˜′′ ∈ RK×K is the rank-1 update of A˜′ which is a sub-matrix of A˜ with K number of active
constraints. Wedefinelimitingsetas
(cid:26) K (cid:12) (cid:27)
Q⋆(A˜′′)= ω : lim (cid:88) ω ad(µ,λ)=Q(A˜′′)(cid:12) (cid:12)A˜′′ω ≤0,ω
a
≥0∀i∈[K] =ω∗(µ)
Fˆ→F (cid:12)
a=1
AsadirectconsequenceofLemma12wegetthefollowingresults
1. Thefunctionω∗(µ)iscontinuousin(RK×K)×RK
2. ω∗(µ)isupper-hemicontinuouson(RK×K)×RK
Leveragingthesefoursufficientstatementsensurethatthereexistuniquesolutionfortheoptimization
problemmax µ⊤π,∀µ∈Di.etheimagesetoftheset-valuedfunctionω∗(.)issingleton.
π∈Fˆ
25F LagrangianLowerBoundforGaussians: ProofofTheorem4
Theorem4. Let{P } beGaussiandistributionswithequalvarianceσ2 >0
a a∈[K]
(cid:40) (cid:41)
(r−µ⊤(π−π′))2
T−1(µ)=maxmin max min −l⊤A˜ω .
Fˆ,r ω∈Fˆ l∈L π∈Πr Fˆπ′∈ν Fˆ(π) 2σ2∥π−π′∥2
Diag(1/ωa)
whereDiag(1/ω )isaK-dimensionaldiagonalmatrixwitha-thdiagonalentry1/ω .
a a
Proof. WestarttheproofbythedefinitionofD(ω,µ,Fˆ)asperEquation(9)
(cid:40) k (cid:41)
D(ω,µ,Fˆ)=min max min (cid:88) ω d(µ ,λ )−l⊤A˜ω
a a a
l∈L π∈Πr Fˆλ∈Λ Fˆ(µ)
a=1
(cid:40) k (cid:41)
=min max min min (cid:88) ω d(µ ,λ )−l⊤A˜ω ⇝ viaProposition1
a a a
l∈L π∈Πr Fˆπ′∈ν Fˆ(π⋆ Fˆ)λ:λ⊤(π−π′)=r
a=1
(10)
TheLagrangianformulationofD(ω,µ,Fˆ)iswrittenas
(cid:40) K (cid:32) K (cid:33)(cid:41)
L(ω,µ,Fˆ)=min max min (cid:88) ω d(µ ,λ )−l⊤A˜ω−γ (cid:88) λ v −r
a a a a a
l∈L π∈Πr Fˆπ′∈ν Fˆ(π)
a=1 a=1
wherev ≜(π−π′) .
a a
WeassumeboththeinstancesµandλfollowGaussiandistributionwithsamevarianceσ2.
Then,wecanrewritetheLagrangianputtingthevalueoftheKLas—
L(ω,µ,Fˆ)= min min max min
(cid:40) (cid:88)K
ω
(µ a−λ a)2 −l⊤A˜ω−γ(cid:32) (cid:88)K
λ v
−r(cid:33)(cid:41)
γ∈R + l∈L π∈Πr Fˆπ′∈ν Fˆ(π) a=1 a 2σ2 a=1 a a
(11)
DifferentiatingtheLagrangianw.r.tλ andequatingitto0,weget
a
∇ L(λ,ω,µ)=0
λa
ω (µ −λ )
or, − a a a −γv =0
σ2 a
γv σ2
or,λ =µ + a
a a ω
a
Thenputtingbackthevalueofλ inEquation11weget
a
L(ω,µ,Fˆ)= min min max min
(cid:40) −(cid:88)K γ2v2 aσ2 −l⊤A˜ω−γ(cid:32) (cid:88)K
µ v
−r(cid:33)(cid:41)
(12)
γ∈R + l∈L π∈Πr Fˆπ′∈ν Fˆ(π) a=1 2ω a a=1 a a
AgaindifferentiatingtheLagrangianw.r.tγ andequatingitto0,weget
∇ L(ω,µ,Fˆ)=0
=⇒r−(cid:88)K
µ v
−γ(cid:88)K σ2
v =0
γ a a ω a
a
a=1 a=1
(r−µ⊤v)
=⇒γ =
(cid:80)K σ2v2
a=1 ωa a
Puttingthevalueofγ inEquation12,weget—
(cid:40) (cid:41)
(r−µ⊤v)2
L(ω,µ,Fˆ)=min max min −l⊤A˜ω
l∈L π∈Πr Fˆπ′∈ν Fˆ(π) 2σ2(cid:80)K
a=1
ωv2 a
a
26(cid:40) (cid:41)
1 (r−µ⊤(π−π′))2
=min max min −l⊤A˜ω
l∈L π∈Πr Fˆπ′∈ν Fˆ(π) 2σ2∥π−π′∥2
Diag(1/ωa)
ThereforeinversecharacteristictimeforLagrangianrelaxationwithunknownconstraintssatisfies,
(cid:40) (cid:41)
1 (r−µ⊤(π−π′))2
T−1(µ)=maxmin max min −l⊤A˜ω
Fˆ,r ω∈Fˆ l∈L π∈Πr Fˆπ′∈ν Fˆ(π) 2σ2∥π−π′∥2
Diag(1/ωa)
F.1 BoundsonSamplecomplexity: ProofofCorollary1Part(a)
Corollary1. Part(a)Letd2 ≜
∥π⋆ F−π∥2
µµ⊤ bethenormoftheprojectionofµonthepolicygap
π ∥π⋆−π∥2
F 2
(π⋆ −π).
F
Parti. Then,weget 2σ2K (1+s )≤T (µ)≤ 2σ2K ,whereC =min d2 .
Cknown A˜ Fˆ,0 Cknown known π′′∈νF(π⋆ F) π′′
Partii. Additionally,T (µ)≥ H(1+s ),whereH isinverselyproportionaltothesumofsquares
Fˆ,0 κ2 A˜
ofgapsandκ istheconditionnumberofasub-matrixofAconsistingK linearlyindependent
known
activeconstraintsforπ⋆.
Proof. Here,wederiveexplicitexpressionforgaussiancharacterisationofthelowerandupperbound
on the characteristic time. We start the proof with the difference in sample complexity between
unknownandknownconstraintsetting
(cid:40) (cid:41)
1
∥π⋆ −π′∥2
D(ω,µ,Fˆ)−D(ω,µ,F)=min min Fˆ µµ⊤ −l⊤A˜ω
l∈L π′∈ν Fˆ(π⋆ Fˆ) 2σ2∥π⋆ Fˆ −π′∥2 Diag(1/ωa)
1
∥π⋆ −π′′∥2
− min
F µµ⊤
(13)
π′′∈νF(π⋆ F)2σ2∥π⋆
F
−π′′∥2
Diag(1/ωa)
Letusremind,duetopessimisticchoiceofA˜,F ⊆Fˆ.π′isaneighborofπ⋆ ifitisanextremepoint
Fˆ
inthepolytopeFˆandshares(K-1)activeconstraintswithπ⋆. Thenπ⋆ andπ′′liesintheinterior
Fˆ F
ofFˆ i.e,theycanbeexpressedasaconvexcombinationofπ⋆ andπ′. Let,∃0 ≤ t ≤ 1 : π⋆ =
Fˆ 1 F
t π⋆ +(1−t )π′ and∃0≤t ≤1:π′′ =t π⋆ +(1−t )π′ Then,(π⋆ −π′)=t (π⋆ −π′)
1 Fˆ 1 1 2 Fˆ 2 F 1 Fˆ
and(π′′−π′)=t (π⋆ −π′). Then,
2 Fˆ
∥π⋆ −π′′∥2 =∥(π⋆ −π′)−(π′′−π′)∥2 =∥t (π⋆ −π′)−t (π⋆ −π′)∥2 =(t −t )2∥π⋆ −π′∥2
F µµ⊤ F µµ⊤ 1 Fˆ 2 Fˆ µµ⊤ 1 2 Fˆ µµ⊤
ApplyingthisequalityinEquation13,weget—
D(ω,µ,F)−D(ω,µ,Fˆ)
(cid:40) (cid:41)
1
∥π⋆ −π′′∥2
1
∥π⋆ −π′∥2
= min F µµ⊤ −min min Fˆ µµ⊤ −l⊤A˜ω
π′′∈νF(π⋆ F)2σ2∥π⋆ F −π′′∥2 Diag(1/ωa) l∈L π′∈ν Fˆ(π⋆ Fˆ) 2σ2∥π⋆ Fˆ −π′∥2 Diag(1/ωa)
(cid:40) (cid:41)
= min
1 (t 1−t 2)2∥π⋆
Fˆ
−π′′∥2
µµ⊤ −min min
1 ∥π⋆
Fˆ
−π′∥2
µµ⊤ −l⊤A˜ω
π′∈ν Fˆ(π⋆ Fˆ)2σ2(t 1−t 2)2∥π⋆ Fˆ −π′∥2 Diag(1/ωa) l∈L π′∈ν Fˆ(π⋆ Fˆ) 2σ2∥π⋆ Fˆ −π′∥2 Diag(1/ωa)
=minl⊤A˜ω
l∈L
≤D(ω,µ,Fˆ)s (14)
A˜
ThelastinequalityisadirectconsequenceofLemma6.
PartI.Sincemin −l⊤A˜ω ≥0bythedesignoftheLagrangianandtheconstraints,weget
l∈L
D(ω,µ,Fˆ)≥D(ω,µ,F)
=⇒T−1(µ)≥T−1(µ) (15)
Fˆ,0 F,0
27This leads us to the upper bound. For ease of comparison, we follow the same notation used in
Carlsson et al. (2024) and define for any π ∈ ∆ , d2 ≜
∥π⋆ F−π∥2
µµ⊤, which is the squared
K−1 π ∥π⋆−π∥2
F 2
distance between µ and the hyperplane (π⋆ −π) = 0. Therefore, using (Carlsson et al., 2024,
F
Corollary1)andEquation(15),weget
2σ2K
T (µ)≤
Fˆ,0 min d2
π′′∈νF(π⋆ F) π′′
AlongwithEquation(14),thisimpliesthat
D(ω,µ,Fˆ)(1+s )≤D(ω,µ,F)
A˜
=⇒T−1(µ)(1+s )≤T−1(µ) (16)
Fˆ,0 A˜ F,0
Weagainleverage(Carlssonetal.,2024,Corollary1)togetlowerboundonthecharacteristictime
as,
2σ2
T (µ)≥(1+s )
Fˆ,0 A˜ min d2
π′′∈νF(π⋆ F) π′′
Further,wedefineC ≜min d2 ,whichconcludestheproof.
Known π′′∈νF(π⋆ F) π′′
F.2 Impactofunknownlinearconstraints: ProofofCorollary1Part(b)
Corollary1. Part(b)Letd2 ≜
∥π⋆ F−π∥2
µµ⊤ bethenormoftheprojectionofµonthepolicygap
π ∥π⋆−π∥2
F 2 (cid:16) (cid:17)
(π⋆ −π). Then,thecharacteristictimeT (µ)satisfiesT (µ)≥ H 1− ϵ . H isthesumof
F Fˆ,0 Fˆ,0 κ2 γ
squaresofgaps.κistheconditionnumbersofasub-matrixofAthatconsistsKlinearlyindependent
activeconstraintsforπ⋆.
Proof. ThisresultadirectimplicationofCorollary2in Carlssonetal.(2024),thatstates,
κ2
T−1(µ)≤
F,0 H
Here,H = 2σ2 ,where∆2 =(cid:80)K (µ∗−µ )2,i.ethesumofsquaresofsub-optimalgapsinthe
∆2 a=1 a
armsandκistheconditionnumberofasub-matrixofAconsistingatleastK linearlyindependent
activeconstraintsforπ⋆. ReferringtotheproofstructureofCorollary2in (Carlssonetal.,2024)is
ofindependentinterest.
NowweleverageequationEquation(16)toget
H
T (µ)≥ (1+s )
Fˆ,0 κ2 A˜
28G SampleComplexityupperbounds(Analysisofalgorithms)
G.1 ProofofLemma2: Implicationof(1−δ)-correctness
Lemma2. Iftherecommendedpolicyis(1−δ)-correctthenitis(1−δ)-feasible.
Proof. Lettherecommendedpolicyπis(1−δ)-correct. Itmeans
P(π =π⋆)≥1−δ
F
=⇒P(π =π⋆ ∧Aπ⋆ ≤0)≥1−δ
F F
=⇒P(Aπ ≤0)≥1−δ
Hence(1−δ)-correctnessautomaticallyimplies(1−δ)-feasibility.
G.2 StoppingCriterion
Theorem5. TheChernoffstoppingruletoensure(1−δ)-correctnessand(1−δ)-feasibilityis
K
(cid:88)
max inf N d(µˆ ,λ )>β(t,δ)
a,t a,t a
πt∈Πr Fˆtλ∈Λ Fˆt(µˆ t,πt)
a=1
whereβ(t,δ)≜3S 0log(1+logN a,t)+S 0T
(cid:16)
(K∧d S)+ 0log
δ1(cid:17)
,andρ(t,δ)isinLemma4.
Proof. Wedictatetheproofin2steps. Inthefirststep,weprovethatthestoppingtimeτ isfinite.
δ
Then, in next step, we give an explicit expression of the stopping threshold by upper bounding
probabilityofthebadeventforstoppingtimeτ .
δ
Letusfirstgothroughsomenotations.
π ≜argmax µˆ⊤π,whereµˆ ∈argmin (cid:80)K N d(µˆ ,λ )−l⊤A˜ N .
t π∈Fˆ t t λ∈Λ Fˆt(µˆ t) a=1 a,t a,t a t t a,t
Algorithm 1 and 2 stops at a finite τ ∈ N if the events inf {∃t ∈ N :
δ λ∈Λ Fˆ(µˆ t)
(cid:80)K N d(µˆ ,λ )}>β(t,δ)and{∃t∈N:∥(A˜ −A)N ∥ ≤tρ(t,δ)}jointlyoccurs.
a=1 a,t a,t a t t ∞
Step1: Finitenessofthestoppingtime. Astoppingtimeisfiniteiftheparametersinthesystem
converges to their true values in finite time, in our case the means of arms and the constraint
matrix. Let us define A ≜ {a ∈ [K] : lim N < ∞} as a sampling rule i.e if an arm
t→∞ a,t
belongstothissetA,ithasbeensampledfinitelyandotherwisethearmhasbeensampledenough
number of times so that the mean of that arm has converged to it’s true value and the column in
the constraint matrix corresponding to that arm as also converged. For arms a ∈ [K]anda ∈
Ac,µˆ → µ˜ ̸= µ and (A˜) → (A′) ̸= (A) . When all parameters are concentrated
a,t a a a,t a a
A = ∅, we say ∀a ∈ [K] : µˆ → µ and A˜ → A. We also define the limit of this empirical
a a
samplingruleasω =lim Na,t∀a∈[K]. Wethenwritethestoppingconditioninanewway
∞ t→∞ t
inf
λ∈Λ Fˆ(µˆ
t){∃t∈N:(cid:80)K
a=1
Na t,td(µˆ a,t,λ a)> β(t t,δ)}and{∃t∈N:∥(A˜ t−A)N tt∥
∞
≤ρ(t,δ)}.
By continuity properties and knowing β(t,.) → loglogt and ρ(t,.) → 0 as t → ∞, we claim
by taking taking asymptotic limits both sides inf (cid:80)K ω∞,ad(µˆ ,λ ) > 0 and also
λ∈Λ Fˆ(µˆ t) a=1 t a,t a
∥(A˜ −A)ω ∥ <0. Wegetstrictinequalityfortheboththecasesbythevirtueofconstruction
t ∞,a ∞
ofthesetAsuchthatforarmsa∈A,ω ̸=0andtheKL-divergenceisnon-zeroasλ ̸=µsince
∞ a
λ∈Λ (µˆ ). Alsoforthesecondstrictinequality,sinceA˜ isthepessimisticestimateofAattime
Fˆ
t
t t
ttheconditionwillhold.
Step2: ProbabilityofbadeventtoStoppingthreshold. Letω istheallocationassociatedtoN .
t t
Thenwedefinethebadeventas
U ≜{π ̸=π⋆}
t τδ F
(cid:40)
(cid:91)
= ∃t∈N:π =π
t+1
π∈/Πr
F
29(cid:40) K (cid:41)(cid:41)
(cid:88)
∧ inf N d(µˆ ,λ )>β(t,δ)∧Aω ≤0
a,t a,t a t
λ∈Λ Fˆt(µˆ t)
a=1
(cid:40)
(a) (cid:91)
∃t∈N:π =π
⊆ t+1
π∈/Πr
F
(cid:40) K (cid:41)(cid:41)
∧ inf (cid:88) N d(µˆ ,λ )>β(t,δ)∧∥(A˜ −A)ω ∥ ≤ρ(t,δ)
a,t a,t a t t ∞
λ∈Λ Fˆt(µˆ t)
a=1
Theargument(a)holdsbecause
P{0≥Aω }=P{−A˜ ω ≤(A˜ −A)ω }≤P{∥A˜ ω ∥ >∥(A˜ −A)ω ∥ ≥∥(A˜ −A)ω ∥ }
t t t t t t t 1 t t 1 t t ∞
≤P{∥A˜ ω ∥ ≤ρ(t,δ)}P{∥(A˜ −A)ω ∥ ≤ρ(t,δ)}
t t 1 t t ∞
=P{∥(A˜ −A)ω ∥ ≤ρ(t,δ)}
t t ∞
sincetheevent{∥A˜ ω ∥ ≤ρ(t,δ)}isasureevent.
t t 1
Thereforeprobabilityofthisbadevent
(cid:40) K (cid:41)
(cid:91) (cid:88)
P(U )≤ P ∃t∈N:π =π∧ inf N d(µˆ ,λ )}>β(t,δ)
t t+1 a,t a,t a
π∈/Πr
λ∈Λ Fˆt(µˆ t)
a=1
F
(cid:110) (cid:111)
P ∃t∈N:π =π∧∥(A˜ −A)ω ∥ >ρ(t,δ)
t+1 t t ∞
(cid:40) K (cid:41)
(cid:88) (cid:88)
= P ∃t∈N: inf N d(µˆ ,λ )}>β(t,δ)
a,t a,t a
π̸=π⋆
λ∈Λ Fˆt(µˆ t)
a=1
F
+ (cid:88) P(cid:110) ∃t∈N:∥(A˜ −A)ω ∥ >ρ(t,δ)(cid:111) (17)
t t ∞
π̸=π⋆
F
ThesecondcumulativeprobabilitycanbeboundusingLemma4,i.e
(cid:88) P(cid:110) ∃t∈N:∥(A˜ −A)ω ∥ >ρ(t,δ)(cid:111) ≤ 1
t t ∞ t
π̸=π⋆
F
forthechoiceofρ(t,δ)giveninLemma4. WeworkwiththefirstterminR.H.SofEquation(17).
(cid:40) K (cid:41)
(cid:88) (cid:88)
P ∃t∈N: inf N d(µˆ ,λ )}>β(t,δ)
a,t a,t a
π̸=π⋆
λ∈Λ Fˆt(µˆ t)
a=1
F
(cid:40) K
= (cid:88) P ∃t∈N: inf inf (cid:88) N (cid:0) d(µˆ ,λ )−d(µˆ ,λ′ )(cid:1)
a,t a,t a a,t a
π̸=π⋆
λ∈Λ Fˆt(µˆ t)λ′∈ΛF(µˆ t)
a=1
F
K (cid:41)
(cid:88)
+ inf N d(µˆ ,λ′ )>β(t,δ)
a,t a,t a
λ′∈ΛF(µˆ t)
a=1
(cid:40) K (cid:41)
(cid:88) (cid:88)
≤ P ∃t∈N: inf N d(µˆ ,λ′ )≤β(t,δ)
a,t a,t a
π̸=π⋆
λ′∈ΛF(µˆ t)
a=1
F
Thelastinequalityholdsbecause
K
inf inf (cid:88) N (cid:0) d(µˆ ,λ )−d(µˆ ,λ′ )(cid:1) ≤0
a,t a,t a a,t a
λ∈Λ Fˆt(µˆ t)λ′∈ΛF(µˆ t)
a=1
sinceunderFˆ andthebadeventweareassumingthattheestimatedalt-setisstillbiggerthanthe
t
actual alt-set. So any λ ∈ Λ (µˆ ) will have a bigger distance with the estimate of µ than any
Fˆ
t
t
30λ′ ∈ Λ (µˆ ). We define I ≜ Supp(π⋆)∆Supp(π) and also S ≜ max |I |. We note that
F t π F 0 π π
0≤S ≤K.
0
We get from Lemma 9 in (Kaufmann and Koolen, 2021) with the notation of T(.) follows from
Lemma9
  
(cid:88)  (cid:88) (cid:88)
log|π Fˆt|−1

P ∃t∈N: N a,td(µˆ a,t,µ a)≥ 3log(1+logN a,t)+|S 0|T 
S
δ 
π̸=π⋆
F
 a∈Iπ a∈Iπ 0 
δ
≤ ≤δ
t
whereδischosentobe δ suchthatlog|π Fˆt|−1 ≤log(2K)≤(K∧d)+log1
|π Fˆt|−1 δ δ δ
(cid:80)
Also 3log(1+logN ≤3S log(1+logN ). Thereforethestoppingthresholdisgiven
a∈Iπ a,t 0 a,t
by
(cid:18)(K∧d)+log1(cid:19)
β(t,δ)=3S log(1+logN )+S T δ
0 a,t 0 S
0
Inpractice,weuseS =K.
0
G.3 UpperBoundofLATS
Theorem6. ThesamplecomplexityupperboundofLATStoyielda(1−δ)-correctoptimalpolicyis
E[τ ]
lim δ ≤α(1+s)T (µ),
δ→0log(1/δ) F,r
wheresistheshadowpriceofthetrueconstraintA,T (µ)isthecharacteristictimeunderthe
F,r
trueconstraint(Equation(5)),andδ ∈(0,1].
Proof. Wewillprovethistheoremin5steps. Inthefirststep,wedefinewhatisconsideredtobe
thegoodeventinourunknownconstraintsetting, thenwegoonboundingtheprobabilityofthe
complementofthisgoodeventinstep2. Oncetheparameterconcentrationsaretakencareof,we
showhowwecanlowerboundtheinstantaneouscomplexityofthealgorithminstep3. Instep4,we
finallyprovetheupperboundonstoppingtimeforbothgoodandbadevents. Weconcludewiththe
asymptoticupperboundonstoppingtimei.ewhenδ →0andϵ→0instep5.
√
Step1: Definingthegoodevent. Givenanϵ>0,forh(T)=max T,f(T,δ)wedefinethegood
eventG as,
T
T
G ≜ (cid:92) {||µˆ −µ|| ≤ξ(ϵ)∧||(A˜i−Ai)ω|| ≤ϕ(ϵ)∀ω ∈Fˆ}
T t ∞ t ∞
t=h(T)
where,ξ(ϵ) ≤ max max 1µ⊤(π−π′),andϕ(ϵ) ≜ max(1,ϵ)foragivenϵ > 0. Thegood
π∈Πr Fˆπ′∈ν Fˆ(π)5
eventimpliesthatthemeansandconstraintsarewellconcentratedinanϵ-ballaroundtheirtruevalues.
Thus,wehavetonowboundtheextracostoftheircorrectnessandthenumberofsamplesrequiredto
reachthegoodevents.
We also observe that ||µ′ − µ|| ≤ ξ(ϵ) and ||(A˜i − Ai)ω|| ≤ ϕ(ϵ) implies that
∞ t ∞
sup sup ||ω′−ω||≤ϵduetoupperhemicontinuityofω∗(µ)(Theorem3).
ω′∈ω⋆(µ′)ω∈ω⋆(µ)
Step2: SamplestoAchievetheGoodEvent. Now,letusboundtheprobabilityofbadevent,
T
P(Gc)= (cid:88) (cid:16) P{||µˆ −µ|| >ξ(ϵ)}+P(cid:110) ||(A˜i−Ai)ω|| >ϕ(ϵ)(cid:111)(cid:17)
T t ∞ t ∞
t=h(T)
T T
≤ (cid:88) P{||µˆ −µ|| >ξ(ϵ)}+ (cid:88) P(cid:110) ||(A˜i−Ai)ω|| >ϕ(ϵ)(cid:111)
t ∞ t ∞
t=h(T) t=h(T)
31T
≤BT exp(cid:16) −CT1 8(cid:17) +K (cid:88) 1
t
t=h(T)
Thefirstinequalityisduetotheunionbound. ThesecondinequalityisduetotheLemma 7(Lemma
19ofGarivierandKaufmann(2016)),whichstatesthat
T
(cid:88)
P{∥µˆ t−µ∥
∞
>ξ(ϵ)}≤BT
exp(cid:16) −CT81(cid:17)
,
t=h(T)
andalsoduetoLemma4thatprovesconcentrationboundoftheconstraintmatrixovertime.
Step3: Trackingargument. Now,westatehowconcentratingonmeansandconstraintsleadsto
goodconcentrationontheallocationstoo.SinceweuseC-tracking,wecanleveragetheconcentration
in allocation by (Degenne et al., 2019b, Lemma 17). We use this lemma than D-tracking or the
trackingargumentin (GarivierandKaufmann,2016,Lemma7)becausetheoptimalallocations
mightnotbeuniquebutthesetω∗(µ)isconvex(Theorem3).
Hence,thereexistsaT suchthatunderthegoodeventandt≥max(T ,h(T)),wehave,
ϵ ϵ
|(µ−µˆ )⊤π⋆|≤|(µ−µˆ )⊤πˆ⋆|+|(µ−µˆ )⊤(πˆ⋆−π⋆)|≤4ξ(ϵ)
t t t Fˆ
≤ max max µ⊤(π−π′)
π∈Πr Fˆπ′∈ν Fˆ(π)
Wehavereplacedtheperturbedalt-setwiththetrueonebecausefort ≥ max(T ,h(T)), wecan
ϵ
ensuretheconvergenceofFˆalmostsurelyi.eFˆ →a.s F
Step3:Complexityofidentificationundergoodeventandconstraint.Now,wewanttounderstand
howharditistohitthestoppingruleevenunderthegoodevent. First,wedefine
C ≜ inf D(µ′,ω′,Fˆ)−l⊤A˜ω.
ϵ,Fˆ
µ′:||µ′−µ||∞≤ξ(ϵ)
ω′:||ω′−ω||∞≤3ϵ
A˜′:||(A˜−A)ω||∞≤ϕ(ϵ)
NowleveragingLemma6,weobtain
(1+ψ) inf D(µ′,ω′,Fˆ)≥ inf D(µ′,ω′,Fˆ)−l⊤A˜ω,
µ′:||µ′−µ||∞≤ξ(ϵ) µ′:||µ′−µ||∞≤ξ(ϵ)
ω′:||ω′−ω||∞≤3ϵ ω′:||ω′−ω||∞≤3ϵ
A˜:||(A˜−A)ω||∞≤ϕ(ϵ) A˜′:||(A˜−A)ω||∞≤ϕ(ϵ)
wheredefinitionofψfollowsfromLemma6. ItquantifieshowtheLagrangianlowerboundrelates
withtheLikelihoodRatioTest-basedquantityinthestoppingtime.
ThereforebytheC-trackingargumentinTheorem10,wecanstate
tC
D(µˆ ,N ,Fˆ)≥t inf D(µ′,ω′,Fˆ)≥ ϵ,Fˆ . (18)
t t µ′:||µ′−µ||∞≤ξ(ϵ) 1+ψ
ω′:||ω′−ω||∞≤3ϵ
A˜:||(A˜−A)ω||∞≤ϕ(ϵ)
Here,LHSisthequantitythatweusetostopandyielda(1−δ)-correctpolicy.
Step4: Boundingthestoppingtimewithgoodandbadevents. Wedenoteτ asthestoppingtime.
δ
SoforT ≥T wecanwriteupperboundonthisstoppingtimeforbothgoodandbadeventsas
ϵ
√ T
(cid:88)
min(τ ,T)≤max( T,f(T,δ))+ 1
δ τδ>t
t=Tϵ
Bythecorrectnessofthestoppingtime,theeventτ(δ)>thappensifD(µˆ ,N ,Fˆ)≤β(t,δ)for
t t
anyt≤T.
NowusingthelowerboundonD(µˆ ,N ,Fˆ)(Equation18),weget
t t
min(τ
,T)≤β(t,δ))≤max(√
T,β(T,δ))+
(cid:88)T 1(cid:16)
t
C ϵ,Fˆ ≤β(t,δ)(cid:17)
δ 1+ψ
t=Tϵ
32≤max(√
T,β(T,δ))+
(cid:88)T 1(cid:16)
t
C ϵ,Fˆ ≤β(T,δ)(cid:17)
1+ψ
t=Tϵ
√ β(T,δ)(1+ψ)
≤max( T,β(T,δ))+
C
ϵ,Fˆ
√
Let us define T ≜ inf{T ∈ N : max( T,f(T,δ)) + β(T,δ)(1+ψ) ≤ T}. To find a lower
δ C ϵ,Fˆ
bound on T , we refer to (Garivier and Kaufmann, 2016). Specifically, let us define c(η) ≜
δ √
inf{T :T −max( T,β(T,δ))≥ T }forsomeη >0. Therefore,
1+η
C
T ≤c(η)+inf{T ∈N:T ϵ,Fˆ ≥β(T,δ)}
δ (1+ψ )(1+η)
Fˆ
Thus,finallycombiningtheresults,weupperboundthestoppingtimeas
E[τ ]≤T +T +T .
δ ϵ δ bad
Here,T
=(cid:80)∞ BTexp(cid:0) −CT1/8(cid:1)
+Kζ(1)<∞isthesumofprobabilityofthebadevents
bad t=1
overtime. ζ(.)denotestheEuler-RiemannZetafunction.
Step5. Derivingtheasymptotics. Now,weleveragethecontinuitypropertiesoftheLagrangian
characteristictimeunderapproximateconstrainttoshowthatweconvergetotraditionalhardness
measuresasϵandδtendstozero.
First,weobservethatforsomeα>1
E[τ ] α(1+ψ )(1+η)
limsup δ ≤ Fˆ
log(1/δ) C
δ→0 ϵ,Fˆ
Now,ifalsoϵ→0,bytheEquation 4,wegetA˜ →A,andthus,Fˆ →F.
Thus,bycontinuitypropertiesinTheorem3andTheorem2,wegetthat
max Γ Γ
D(Fˆ,.)→D(F,.)andψ → i∈[1,N] ≜ max ≜s.
Fˆ
min Γ Γ
i∈[1,N] min
Here,sistheshadowpriceofthetrueconstraintmatrix,andquantifiesthechangeintheconstraint
valuesduetooneunitchangeinthepolicyvector.
Hence,weconcludethat
E[τ ]
lim δ ≤αT (µ)(1+s).
δ→0log(1/δ) F,r
G.4 UpperBoundforLAGEX
Theorem7. TheexpectedsamplecomplexityofLAGEXsatisfies
E[τ]≤T (δ)+2s+CK
0
√ √
whereT (δ)≜max(cid:8) t∈N:t≤T (µ)(cid:0) β(t,δ)+O(cid:0) tlogt(cid:1) +O(cid:0) Qt(cid:1)(cid:1)(cid:9) andCisaproblem
0 F
independentconstant.
Proof. Wewilldothisproofintwoparts. Inpart(a)wewillassumethatthecurrentrecommended
policyisthecorrectpolicyandtrytofindanupperboundonthesamplecomplexityofLAGEX.In
thenextpart(b)webreakthatassumptionandtrytogetanupperboundonthenumberofstepsthe
recommendedpolicyisnotthecorrectpolicy.
Part(a): Currentrecommendedpolicyiscorrect. Proofstructureofthispartinvolvesseveral
steps. Westartwithdefiningthegoodeventwhereweintroduceaneweventassociatedwiththe
concentrationeventoftheconstraintset,thenproceedingtoproveconcentrationonthatgoodevent.
33ThirdstepstartswiththestoppingcriterionexplainedinG.2. Instep4wedefineLAGEXasan
approximatesaddlepointalgorithm. Thenextstepfurthertransformsthestoppingcriterionwiththe
helpofallocationandinstanceplayer’sregretthatplaythezero-sumgame. Weconcludewiththe
asymptoticupperonthesamplecomplexitycharacterisedbytheadditiveeffectofthenovelquantity
shadowprices.
Step1: Definingthegoodevent. Westarttheprooffirstbydefiningthegoodeventas
G ={∀t≤T,∀a∈[K]:N d(µˆ ,µ )≤g(t)∧∥(A˜ −A)ω∥ ≤ρ(t,δ)}
t a,t a,t a t ∞
where,g(t)=3logt+loglogtandρ(t,δ)isdefinedinLemma3. Thechoiceofg(t)ismotivated
from(Degenneetal.,2019a)whichoriginatesfromthenegativebranchoftheLambert’sWfunction.
Thiseventuallyhelpsusupperboundingthecumulativeprobabilityofthebadevent.
Step2: ConcentratingtothegoodeventWedenoteGcasthebadeventwhereanyoneoftheabove
t
eventsdoesnotoccur. Cumulativeprobabilityofthisbadevent
T T (cid:32) K (cid:33) T
(cid:88) P(Gc)=(cid:88) P (cid:88) N d(µˆ ,µ )>g(s) +(cid:88) P(cid:16) ∥(A˜ −A)ω∥ >ρ(s,δ)∀ω ∈∆ (cid:17)
t a,s a,s a s ∞ K
s=1 s=1 a=1 s=1
Wegettheupperboundon
T (cid:32) K (cid:33) ∞
(cid:88) (cid:88) (cid:88) exp(2)
P N d(µˆ ,µ )>g(s) ≤1+ (g(s)+g2(s)logs)≤19.48
a,s a,s a s3logs
s=1 a=1 s=2
asadirectconsequenceof(Degenneetal.,2019a,Lemma6). Thesecondcumulativeprobabilityis
boundedbyζ(1)<0.578usingLemma4,whichisfinite.
Inthenextstep,weworkwiththestoppingcriterionwherewedonothaveaccesstoF ratherabigger
feasiblesetFˆ.
t
Step3: Workingwiththestoppingcriterion. Thestoppingcriterionimpliesthat
K
(cid:88)
β(t,δ)≥ max inf N d(µˆ ,λ ),
a,t a,t a
π∈Πr Fˆtλ∈Λ Fˆt(µˆ t,π)
a=1
wheretheexactexpressionofβ(t,δ)isdefinedinTheorem5.
WeusetheC-trackinglemma(Lemma8)toexpressthestoppingintermsofallocations
t K √
(cid:88)(cid:88)
β(t,δ)≥ max inf ω d(µˆ ,λ )−(1+ t)K (19)
a,s a,t a
π∈Πr Fˆtλ∈Λ Fˆt(µˆ t,π)
s=1a=1
L-LipschitzpropertyofKLdivergencegives
(cid:115)
g(s)
|d(µ ,λ )−d(µˆ ,λ )|≤L 2σ2 (20)
a a a,s a N
a,s
UsingthisresultinEquation(19)weget
t K t K
(cid:88)(cid:88) (cid:88)(cid:88) (cid:112)
ω d(µˆ ,λ )≥ ω d(µˆ ,λ )−L 2σ2Ktg(t)
a,s a,s a a,s a a
s=1a=1 s=1a=1
t K √
(cid:88)(cid:88) (cid:112) (cid:112)
≥ ω d(µˆ ,λ )−L 2σ2Ktg(t)−2L 2σ2g(t)(K2+2 2Kt)
a,s a,s a
s=1a=1
t K
(cid:88)(cid:88) (cid:112)
≥ ω d(µˆ ,λ )−O( tlogt)
a,s a,s a
s=1a=1
34thepenultimateinequalityyieldsfromusingtheEquation(20). UsingthisresultinEquation(19)
K √
(cid:88) (cid:112)
β(t,δ)≥ max inf ω d(µˆ ,λ )−(1+ t)K−O( tlogt) (21)
a,s a,t a
π∈Πr Fˆtλ∈Λ Fˆt(µˆ t,π)
a=1
Step4: LAGEX(Algorithm2)asanoptimisticsaddlepointalgorithmWefollowthedefinition
ofapproximatesaddlepointalgorithmin(Degenneetal.,2019a). LAGEXactsasanapproximate
saddlepointalgorithmif
t K
(cid:88)(cid:88)
max inf ω d(µˆ ,λ )
s,a a,s a
π∈Πr Fˆtλ∈Λ Fˆt(µˆ t,π)
s=1a=1
K t t K
≥max(cid:88)(cid:88) ω U −Rω−(cid:88)(cid:88) ω C +l⊤A˜ ω , (22)
a a,s t a,s a,s t t t
ω∈Fˆ
ta=1s=1 s=1a=1
(cid:26) (cid:27)
where U ≜ max g(s),max d(ξ,λ ) , C ≜ U −d(µˆ ,λ ), and Rω is
a,s Na,s ξ∈[αa,s,βa,s] a,s a,s a,s a,s a,s t
definedinEquation(24).
Step5: BoundscumulativeregretofplayersAlgorithm2ateachstepsolvesatwoplayerzero-sum
game. FirstoneistheallocationplayerwhousesAdaGradtomaximizetheinverseofcharacteristic
timefunctiontofindtheoptimalallocation.
Step5a. λ-player’sregret.
t K t K
(cid:88)(cid:88) (cid:88)(cid:88)
Rt ≜ ω d(µˆ ,λ )− max inf ω d(µˆ ,λ )≤0
λ a,s a,s a,s a,s a,s a
s=1a=1
π∈Πr Fˆtλ∈Λ Fˆt(µˆ t,π)
s=1a=1
Thelastinequalityholdsbecausewetakeinfimumoverλintheperturbedalt-set. nowletusprove
thatLAGEXisaoptimisticsaddlepointalgorithm. Fromthedefinitionofregretoftheλ-playerwe
get
t K t K t K
(cid:88)(cid:88) (cid:88)(cid:88) (cid:88)(cid:88)
max inf ω d(µˆ ,λ )≥ ω U − ω C .
a,s a,s a a,s a,s a,s a,s
π∈Πr Fˆtλ∈Λ Fˆt(µˆ t,π)
s=1a=1 s=1a=1 s=1a=1
ThenwehavefromEquation(21)andEquation(22)
t K t K √
(cid:88)(cid:88) (cid:88)(cid:88) (cid:112)
β(t,δ)≥ ω U − ω C −(1+ t)K−O( tlogt), (23)
a,s a,s a,s a,s
s=1a=1 s=1a=1
Step5b. Allocationplayer’sregret.
t K t K
(cid:88)(cid:88) (cid:88)(cid:88)
Rω ≜ max ω U − ω U (24)
t a a,s a,s a,s
ω∈∆Ks=1a=1
s=1a=1
√
We note that AdaGrad enjoys regret of order Rω ≤ O( Qt) where Q is an upper bound on the
t
lossessuchthatQ≥max d(x,y).
x,y∈[µ ,µ ]
min max
Now,fromtheallocationplayer’sregret,wehave
t K t K t K
inf (cid:88)(cid:88) ω d(µˆ ,λ )≥max(cid:88)(cid:88) ω U −Rω−(cid:88)(cid:88) ω C +l⊤A˜ ω
a,s a,s s a a,s t a,s a,s t t t
λ∈Λ Fˆ(µ,π)
s=1a=1
ω∈Fˆ
s=1a=1 s=1a=1
(cid:124) (cid:123)(cid:122) (cid:125)
T1
t K t K
≥max(cid:88)(cid:88) ω U −O((cid:112) Qt)−(cid:88)(cid:88) ω C +l⊤A˜ ω
a a,s a,s a,s t t t
ω∈Fˆ
s=1a=1 s=1a=1
(cid:124) (cid:123)(cid:122) (cid:125)
T1
35which shows that LAGEX is a approximate saddle point algorithm with a slack Rω +
t
(cid:80)t (cid:80)K ω C −l A˜ ω .
s=1 a=1 a,s a,s t t t
Step5c. BoundingT1. NowwehavetoensurethatT1intheslackisbounded.
t K t K (cid:18) (cid:19)
(cid:88) (cid:88) (cid:88) (cid:88) g(s)
ω C ≤ ω + max d(ξ,λ )−d(µˆ ,λ )
s=K+1a=1
a,s a,s
s=K+1a=1
a,s N a,s ξ∈[αa,s,βa,s] a,s a,s a,s
(cid:115)
t K (cid:26) (cid:27)
(cid:88) (cid:88) g(s) g(s)
≤ ω +L 2σ2 (25)
a,s N N
a,s a,s
s=K+1a=1
t K t K
≤g(t) (cid:88) (cid:88) ω a,s +L(cid:112) 2σ2g(t) (cid:88) (cid:88) ω a,s
(cid:112)
N N
s=K+1a=1 a,s s=K+1a=1 a,s
(cid:18) t (cid:19) (cid:112) √
≤g(t) K2+2Klog +L 2σ2g(t)(K2+2 2Kt)
K
(cid:112)
≤O( tlogt). (26)
Equation(25)holdsduetoL-LipschitzpropertyofKLunderthegoodeventG . Specifically,
T
(cid:115)
g(s)
|d(µ ,λ )−d(µˆ ,λ )|≤L 2σ2 .
a a a,s a N
a,s
Step6. Fromthetwo-playerregretstostoppingtime. Finally,combiningtheresultsinStep5,i.e.
Equation(23)andEquation(26),weget
(cid:32) K t (cid:33) √
β(t,δ)≥ max (cid:88)(cid:88) ω d(µ ,λ ) −O((cid:112) Qt)−O((cid:112) tlogt)−(1+ t)K+l⊤A˜ ω
a a a,s t t t
ω∈∆K
a=1s=1
K t √
≥ max (cid:88)(cid:88) ω d(µ ,λ )−O((cid:112) Qt)−O((cid:112) tlogt)−(1+ t)K+l⊤A˜ ω
a a a,s t t t
ω∈∆Ka=1s=1
≥ max (cid:88)K (cid:88)t ω d(µ ,λ )−O((cid:112) Qt)−O((cid:112) tlogt)−(1+√ t)K− ψ t .
ω∈∆Ka=1s=1 a a a,s T Fˆ t(µ)
(27)
ThelastinequalityistrueduetoLemma6,i.e. −l⊤A˜ ω ≤ ψt .
t t t T Fˆt(µ)
Now,weobservethat
t K K
(cid:88)(cid:88) (cid:88)
max ω d(µ ,λ )≥t max max inf ω d(µ ,λ )=tT−1(µ)
ω∈∆Ks=1a=1 a a a,s ω∈∆Kπ∈Πr Fˆtλ∈Λ Fˆt(µˆ t,π)
a=1
a a a Fˆ t
ReplacingthisinequalityinEquation(27),wefinallyobtain
(cid:16) (cid:112) (cid:17)
t≤T (µ) β(t,δ)+Rω+O( tlogt) +ψ
Fˆ
t
t t
Part(b): Currentrecommendedpolicyiswrong(notr-good). Togetonwiththeproofforthis
partwewillusesimilarargumentas(Carlssonetal.,2024). Thoughtheargumentwasmotivatedby
thework(Degenneetal.,2019b). Wedefinetheevent
(cid:26) (cid:27)
B ≜ π⋆ ̸=argmaxµˆ⊤π
t t
π∈Fˆ
t
i.ethecurrentrecommendationpolicyisnotcorrectwhichimpliesthatthemeanestimateorthe
constraintestimatehasnotbeenconcentratedyet. IfwedefineChernoff’sinformationfunctionas
36ch(u,v)≜inf (d(u,x)+d(v,x)). ThereforethecurrentmeanestimatewillyieldpositiveCher-
z∈D
noff’sinformationsinceithasnotbeenconvergedyeti.e∃ϵ>0:ch(µˆ ,µ )>ϵ. Consequently
a,t a
underthegoodeventG definedearlier
T
g(t)
≤ϵ
N
a,t
sincech(µˆ ,µ ) ≤ d(µˆ ,µ ). Attimes ∈ N,letπ′ beanextremepointinFˆ thatisnotthe
a,t a a,t a s
r-goodoptimalpolicy.ButsinceitisanextremepointinFˆ thatshares(K−1)activeconstraintswith
s
π⋆,ithastobeanr-goodoptimalpolicyw.r.tsomeλ ∈ Λ (µˆ ,π) : π′ = argmax λ⊤π.
Fˆ
s
s π∈Πr
Fˆs
SoweagaindefinetheeventB as
t
(cid:26) (cid:27)
B ≜ λ∈Λ (µˆ ,π):π′ =argmaxλ⊤π ∈/ Πr
t Fˆ
t
t
π∈Πr
F
Fˆt
Weagaindefinen (t)bethenumberofstepswhenπ =π′,s∈[t]. Therefore
π′ s
K t K
(cid:88) (cid:88) (cid:88) (cid:88) (cid:88)
ϵ= ω d(µˆ ,µ )≥ inf ω d(µˆ ,µ ) (28)
a,s a,s a a,s a,s a
s=1,Bsa=1 π′∈/Πr
Fλ∈Bss=1,πs=π′a=1
NowtobreaktheRHSoftheaboveinequalitywegobacktostep5oftheproofofpart(a)where
weshowedLAGEXisanapproximatesaddlepointalgorithm. Inthiscasetheslackwillbex =
t
Rω +(cid:80)t (cid:80)K ω C −l A˜ ω . ThereforewecanwritetheRHSofEquation(28)
asn π′(t) s=1,πs=π′ a=1 a,s a,s t t t
t K
(cid:88) (cid:88) (cid:88)
inf ω d(µˆ ,µ )
a,s a,s a
π′∈/Πr
Fλ∈Bss=1,πs=π′a=1
t K t K
≥max (cid:88) (cid:88) ω U −Rω − (cid:88) (cid:88) ω C +l⊤A˜ ω . (29)
π∈Fˆ
ss=1,πs=π′a=1
a,s a,s n π′(t)
s=1,πs=π′a=1
a,s a,s t t t
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
T1 T2
Weapplythesamelogicasin(Carlssonetal.,2024)and(Degenneetal.,2019b)that∃a′ ∈[K]for
whichU ≥ϵ. ThatmeansthetermT1growsatmostlinearwithn (t). Fromtheproofofpart
a′,s π′
(cid:16)(cid:112) (cid:17) √
(a)itisclearthatthetermT2=O n (t)logn (t) ≤O( tlogt)andtheallocationplayer
π′ π′
(cid:112) √
regretisboundedbyR = O( Qn (t)) ≤ O( Qt). Thatmeansthenumberoftimesthe
n π′(t) √π′
eventB occursisupperboundedbyO( tlogt). NowtheextraterminEquation(29)appearing
t
withtermT1andT2inducessameimplicationaspart(a).
Thenincorporatingpart(a)and(b)togettheupperboundontheexpectedstoppingtimeasymptoti-
cally
E[τ ]≤T
(µ)(cid:16) β(t,δ)+O(cid:16)(cid:112) tlogt(cid:17) +O(cid:16)(cid:112) Qt(cid:17)(cid:17)
+2ψ
δ Fˆ
t
t
asFˆ →F andψ →s,wehavetheexplicitupperbound
t t
E[τ]≤T (δ)+2s+CK
0
√ √
whereT (δ)≜max(cid:8) t∈N:t≤T (µ)(cid:0) β(t,δ)+O(cid:0) tlogt(cid:1) +O(cid:0) Qt(cid:1)(cid:1)(cid:9) andCisaproblem
0 F
independentconstantthatappearsduetotheconcentrationguarantytogoodeventG i.econcentration
t
ofmeanvectorandconstraintmatrix.
37G.5 Applicationstoexistingproblems
End-of-timeKnapsack. WecanmodeltheBAIproblemwithend-of-timeknapsackconstraintsas
discussedinSectionB.2. Insuchasettingtheshadowpricecomesouttobes≤ci.ethemaximum
consumableresource. SoifweweretoimplementLATSforthistheasymptoticsamplecomplexity
upperboundwilltranslatetoαT (µ)(1+c),themultiplicativepartbeingtheeffectoftheendof
Fˆ
timeknapsackconstraint. IncaseofLAGEXtheunknownknapsackconstraintwillleaveaadditive
effectquantifiedby2c. Recentlypeoplehavedeviatedfromonlydevisingano-regretlearnerinBwK
ratherpeopleareinterestedtoalsogivegoodsub-optimalguarantiesonconstraintviolationaswell.
WethinkalgorithmslikeLAGEXwillperformwellifwetranslatethismodeltooursettingsinceit
hasshownnotonlygoodsamplecomplexitybutalsobetterconstraintviolationguaraniesaswell.
FairBAIacrosssubpopulations. Thisproblemisadirectconsequenceofoursetting. Theshadow
price in this setting s =
maxi∈Kπ⋆
i > 1 i.e the ratio between maximum and minimum non-zero
mini∈Kπ⋆
i
weightintherecommendedpolicy. Similartotheknapsackscenario,herealsothisratiowillappear
asaextracostofnotknowingthefairnessconstraintinmultiplicativewayincaseofLATSandgets
addedtothesamplecomplexityupperboundofLAGEX.
PureexplorationwithFairnessofexposure. Wecanthinkofaproblemwherewewanttoselecta
poolofemployeesfromdifferentsub-sectionsofawholepopulationforatask. Aswewanttomax-
imisetherewardorutilityofthisselectedgroupwealsomustalsogivefairexposuretoallraceorsay
gender. AsdiscussedearlierinSectionB.2,adirectapplicationofouralgorithmsLATSandLAGEX
tousethemintheproblemofpureexplorationwithunknownconstraintsonfairnessofexposure.
(cid:16) (cid:17)
Theshadowpriceinsuchasettingwouldbes=
maxi,j∈[K] µ1 i− µ1
j =
maxi,j∈[K](µ i−µ j)
≥1.
mini,j∈[K](cid:16) µ1 i− µ1 j(cid:17) mini,j∈[K](µ i−µ j)
Thresholdingbandits. TheproblemofThresholdingbanditismotivatedfromthesafedosefinding
problem in clinical trials, where one wants to identify the highest dose of a drug that is below a
knownsafetylevel. FromthetranslatedoptimisationprobleminSectionB.2weeasilyfindoutthe
shadowpriceforthissettingtobes =
maxi∈[K](π−θ)i
≥ 1. Thisshadowpriceissimilartoours
mini∈[K](π−θ)i
becausetheconstraintstructureisverysimilar. Oursettinggeneralisesthresholdingbanditproblem
bygivingthelibertyofchoosingdifferentthresholdlevelsfordifferentsupportindexofπ. Similarly
toothersettingsthisshadowpricewillcomeasapriceofhandlingdifferentunknownthresholdsfor
everyarmasadditionincaseofLAGEXandasmultiplicationforLATS.
Feasiblearmselection. Feasiblearmselectionproblemismotivatedbythespiritofrecommending
anoptimalarmwhichshouldsatisfyaperformancethreshold. Forexampleonemightbeinterestedto
findacombinationoffoodamongaplethoraofoptionswhichmaximisesthenutrientintake,rather
thenutrientvalueofthefoodcombinationshouldexceedathresholdvalue. Thestructureofthe
optimisationproblemforsuchasettingisdiscussedindetailinSectionB.2. Thentheshadowprice
comesoutass = τ−fmin ≥ 1wheref ∈ RSupp(π) canbecomparedtoautilityfunction. Inour
τ−fmax
settingwewillnothaveaccesstothetrueutilityfunctionratherwehavetotrackitperstep. This
shadow price again get multiplied to the LATS sample complexity upper bound as a cost of not
knowingthetrueutilityofthearms,whereasweseeaadditivecostincurredincaseofLAGEX.
38H Constraintviolationsduringexploration
H.1 UpperBoundonConstraintViolation
Inalinearprogrammingproblemwesayconstraintisviolatedifthechosenallocationfailstosatisfy
any of the true linear constraints. In other words when the event Aω ≥ 0. We start with the
t
optimizationproblemrelaxedwithslackiftheconstraintswereknown,
max µTπ
π∈Πr
Fˆ
suchthat,Aπ+Γ≤0
where, Γ is the slack. Cumulative violation of constraints can be expressed as V =
t
(cid:80)t max (cid:2) Aiω (cid:3) where [z] = max{z,0}. Then, at any time step t ∈ [T], instan-
s=1 i∈[K] t + +
taneous violation is given by, v = max (cid:2) Aiω (cid:3) . Since, A is feasible, we define the
t i∈[k] t +
game value as, η = max max Aiω ≤ −Γ and η = max max Aiω ≥
ω∈F i∈[K] ω∈F i∈[K]
min max max A˜iω =A˜itω ,holdsbecauseofpessimisticestimateofA.
A˜∈C At ω∈Fˆ
t
i∈[K] t t t t
Again,wedefine,i (ω)=argmin A˜iω.
min i∈[K]
max(cid:2) Aiω (cid:3) = max(Ai−A˜i)ω +maxA˜iω
t t t t t
i∈[K] i∈[K] i∈[K]
≤ max||(Ai−A˜i)|| ||ω || +maxA˜iω
i∈[K]
t Σt t Σ− t1
i∈[K]
t t
≤f(t,δ)||ω || +maxA˜iω
t Σ−1 t t
t i∈[K]
≤ρ(t,δ)−Γ
wherethelastinequalityholdsbecausemax A˜iω ≤max Aiω ≤−Γ
i∈[K] t t i∈[K] t
Letstoppingtimeisdenotedbyτ <T followingtheexpressionfromtheStoppingcriterionsection.
δ
Thenexpectedcumulativeconstraintviolationisdenotedby,
E(cid:2)V τδ(cid:3)
=
(cid:88)
s ≤
(cid:88)
[ρ(t,δ)−Γ]
τ t +
δ
t≤E[τδ] t≤E[τδ]
(cid:88)
= {ρ(t,δ)−Γ} because,ρ(t,δ)−Γ ispositive.
t≤E[τδ]
(cid:115)
(cid:18) (cid:19)
1+E[τ ]
≤ 2df2(E[τ ],δ)log 1+ δ −Γ
δ d
ThelastinequalityisadirectconsequenceofLemma3. Thustheexpectedconstraintviolationisof
(cid:16) √ (cid:17)
orderO˜ t d ,ignoringthelowerorderdependenceont.
H.2 Experimentalresultsonconstraintviolation
Wecomparetheconstraintviolationi.ethenumberoftimesAω >0,whereAisthetrueconstraint
t
matrix.
Observation: LAGEXis"safest".
Setup 1. From Figure 6 unlike LAGEX, we see LATS shows comparable amount of constraint
violationwithUniformsampling,whereasinFigure7weprominentlyobserveLATSandLAGEX
outperformingotheralgorithmsinsafety.
Setup2. InthehardenvasperCarlssonetal.(2024)inFigure8weobservebothLAGEXand
LATSshowconstraintsviolationaslowasUniformsamplingoutperformingotheralgorithms,butin
theeasyenvinFigure9weseeallthealgorithmsexceptCGEwithoutLagrangianrelaxationshows
moreorlesssameamountofsafetyviolationwhilechoosingallocation.
39100000 3000
2500
80000
2000
60000
1500
40000
1000
20000 500
0 0
LAGEX LATS CTnS_WLag CGE_WLag Uniform PTnS LAGEX LATS CTnS_WLag CGE_WLag Uniform PTnS
Figure6: Constraintviolation(median±std.) al- Figure7: Constraintviolation(median±std.) of
gorithmsforhardenvironmentinsetup1. algorithmsforeasyenvironmentinsetup1.
100000 100000
80000 80000
60000 60000
40000 40000
20000 20000
0 0
LAGEX LATS CTnS_WLag CGE_WLag Uniform PTnS LAGEX LATS CTnS_WLag CGE_WLag Uniform PTnS
Figure8: Constraintviolation(median±std.) al- Figure9: Constraintviolation(median±std.) of
gorithmsforhardenvironmentinsetup2. algorithmsforeasyenvironmentinsetup2.
100000
80000
60000
40000
20000
0
LAGEX LATS CTnS_WLag CGE_WLag Uniform PTnS
Figure 10: Constraint violation (median±std.)
ofalgorithmsforIMDBenvironment.
IMDBenv. DuringtheexperimentwithIMDB-50KdatasetweeseethatLAGEXprovestobethe
safestamongallotheralgorithmswithadistinguishablylowsafetyviolations. ThoughagainLATS
showscomparableviolationwithUniformsampling.
ThereforeweseethatacrossmultipleenvironmentsLAGEXhasproventobethe"safest"outofall
thecompetingalgorithms.
40
noitaloiv
tniartsnoC
noitaloiv
tniartsnoC
noitaloiv
tniartsnoC
noitaloiv
tniartsnoC
noitaloiv
tniartsnoCI Experimentaldetails
Computationresources. Werunthealgorithmsona64-bit13thGenIntel®Core™i7-1370P×20
processormachinewith32GBramwithadisccapabilityof1TBandgraphicsMesaIntel®Graphics
(RPL-P).ThehardwaremodelisHPEliteBook84014inchG10NotebookPC.Codeisavailablein
thisLink.
Throughoutthispaperwehavesetr =0.01andβ(t,δ)=log1+loglogt foralltheexperiments. For
δ
CGEwehaveusedg(t)=logt. Eachplothasbeengeneratedover500randomseeds.
Baselinealgorithms.WecompareLAGEXandLATSwiththetwoalgorithmsunderknowncon-
straints,i.e. CTnSandCGE(Carlssonetal.,2024). Also,tounderstandtheutilityofLagrangian
relaxation,weimplementversionsofCTnSandCGEwithestimatedconstraints. Inthesevariants,
wesolvetheconstrainedoptimisationproblemswithoutLagrangianrelaxationbutwithestimated
constraints. WealsocomparewithPTnS(ProjectedTrackandStop),avariantofTnS,wherethe
algorithm computes the allocation by solving the unconstrained BAI optimisation problem and
projectsthisallocationinthefeasiblesetasnecessary.
Abbreviationsofalgorithms. "CTnS-WLag"and"CGE-WLag"isbasicallytheCTnSandCGE
algorithm(Carlssonetal.(2024))underunknownconstraintswithoutLagrangianrelaxation. "PTnS"
isProjectedTrackandStopalgorithm.
Table1: Differentexperimentalsetups
Setup Environment µ Constraints δ
1 Hard [1.5,1.0,0.5,0.4,0.3,0.2,0.1] π1+π2+π3≤0.5andπ4+π5≤0.5 0.01
1 Easy [1.5,1.0,1.3,0.4,0.3,0.2,0.1] π1+π2+π3≤0.5andπ4+π5≤0.5 0.01
2 Hard [1,0.5,0.4,0.4,0.5] π1+π2≤0.5andπ3+π4≤0.5 0.1
2 Easy [1,0.5,0.4,0.95,0.8] π1+π2≤0.5andπ3+π4≤0.5 0.1
× IMDB [3.67,2.97,2.94,3.52,3.18,2.02,2.79,2.96,2.37,2.53,2.55,2.54] "action"<0.3,"drama">0.3,"family">0.3 0.1
I.1 SamplecomplexityplotsforSetup2
Setup2.WefurthertestourproposedalgorithmsLATSandLAGEXunderthesametwoenvironments
used in Figure 3b and 3c of (Carlsson et al., 2024). Figure 11 and 12 shows the comparison of
samplecomplexity(Median±s.d)forLATSandLAGEXwithotherbaselinealgorithms.
Observation: Efficiency. For the hard env (As described in (Carlsson et al., 2024)), it seems
clearfromFigure11thatthoughbothLATSandLAGEXshowsminimallybetterefficiencythan
Uniformsampling,LAGEXshowsminimumsamplecompleityintheunknownconstraintsetup. On
thecontrary,ineasyenvthebettermentinefficiencyforLAGEXismoreprominent.
10 10
8 8
6 6
4 4
Known lower bound Known lower bound
2 BAI lower bound 2 BAI lower bound
LAGEX LATS CTnS CGE CTnS_WLag CGE_WLag Uniform PTnS LAGEX LATS CTnS CGE CTnS_WLag CGE_WLag Uniform PTnS
Figure11: Samplecomplexity(median±std.) of Figure12: Samplecomplexity(median±std.) of
algorithmforhardenv. inSetup2. algorithmsforeasyenvinSetup2.
41
)emit
gnippotS(gol
)emit
gnippotS(golJ TechnicalresultsandknowntoolsinBAIandpureexploration
Inthissection,wewilldevisesometechnicallemmausingthehelpofstandardtextononlinelinear
regressiontoensuretheconvergenceofunknownconstraints. Wespecificallygivetheexpressionof
theradiusofconfidenceellipsoidmentionedinthemaintextinEquation2. Wethenproveanupper
boundonthebadeventi.ewhentheconstraintmatrixisnotconcentratedaroundthetruematrix. We
alsoacknowledgesomeknowntheoreticalresultsfromBAIandpureexplorationliteraturethatare
usedinthiswork.
J.1 Concentrationlemmaforconstraints
Here,wewanttogetconcentrationonthedeviationofthepessimisticestimateoftheconstraintmatrix
fromtheactualonequantifiedby∥(A˜ −A)ω∥ ,itbecomesverycrucialtoproveupperboundson
∞
samplecomplexityofourproposedalgorithms. Thefollowinglemmaensurestheconcentrationof
theconstraintmatrix.
Lemma3. ForthepessimisticestimateA˜ ofA,thefollowingholds
1. |(A˜i−Ai)ω|≤ρ(t,δ)whereρ(t,δ)≜f(t,δ)∥ω∥
Σ−1
t
2. (cid:80)t ∥ω ∥2 ≤2dlog(cid:0) 1+ 1+t(cid:1)
s=1 s Σ− s1 d
(cid:113)
3.
(cid:80)t
ρ(s,δ)≤t
2df2(t,δ)log(cid:0)
1+
1+t(cid:1)
s=1 d
Proof. Thefirstresultgivescontrolonthedeviations(A˜ −A)ωforA∈CA(δ). Then∀i∈[d]
t
|(A˜i−Ai)ω|≤|(A˜i−Ai)ω|≤2 sup ∥A˜i−Ai∥ ∥ω∥ ≤f(t,δ)∥ω∥ ≤ρ(t,δ)
t
A∈CA(δ)
t Σt Σ− t1 Σ− t1
t
here, wedefineρ(t,δ) ≜ f(t,δ)∥ω∥ . Thepenultimateinequalityfollowsfromthedefinition
Σ−1
t
oftheconfidencesetdefinedinEquation2. Nowwewanttoderiveanexplicitexpressionofthis
upperbound. ItisnaturaltousetheconcentrationofthegrammatrixΣ overtime. Wereferto
t
Abbasi-yadkorietal.(2011)forthecontroloverthebehaviourofΣ andwedirectlygetthesecondas
t
t (cid:18) (cid:19)
(cid:88) 1+t
∥ω ∥2 ≤2logdetΣ ≤2dlog 1+
s Σ−1 t+1 d
t
s=1
ReferAbbasi-yadkorietal.(2011)forthecontext. Nowwehavetocontrolthecumulativedeviation
becauselateronwhenwedefinethebadeventbasedonthisconcentrationwewillneedtoknowthe
cumulativebehaviorofρ(t,δ).
Thenforanarbitrarysequenceofactions{ω }
s s∈[T]
(cid:118)
t (cid:117) t (cid:115) (cid:18) (cid:19)
(cid:88) (cid:117)(cid:88) 1+t
ρ(s,δ)≤t(cid:116) ρ2(s,δ)≤ 2dtf2(t,δ)log 1+
d
s=1 s=1
where,(cid:80)t ρ2(s,δ)≤2dtf2(t,δ)(cid:0)
1+
1+t(cid:1)
usingresult2ofthislemma. Thisholdsbecauseas
s=1 d
wehavealreadystated{f(s,δ)} isanon-decreasingsequenceoffunctionandf(t,δ)isthe
s∈[T]
maximumpossiblevalueintheseti.e(cid:80)t f2(s,δ)≤tf2(t,δ)
s=1
Nowweproceedtostateanupperboundonthecumulativeprobabilityofthebadeventi.etheevent
|(A˜ −A)ω| >|(A˜i−Ai)ω|>ρ(t,δ).
t ∞ t
Lemma4. Thecumulativeprobabilityofthebadeventtilltimet<T,
t
(cid:88) P(cid:16) ∥(A˜ −A)ω∥ >ρ(t,δ)(cid:17) ≤ζ(1)
t ∞
s=1
whereζ(.)istheEuler-Riemannzetafunction.
42(cid:113)
Proof. We already have stated in the main paper f(t,δ) = 1 + 1logK + 1logdetΣ ≤
2 δ 4 t
(cid:113)
1 + 1logK + dlog(cid:0) 1+ t(cid:1) ≜ f′(t,δ) by Lemma 3 and we define
2 δ 4 d
(cid:16) (cid:17)
ρ′(t,δ) ≜ f′(t,δ)∥ω∥ . It implies P ∃t∈[T]∥(A˜ −A)ω∥ >ρ′(t,δ) ≤
Σ−1 t ∞
(cid:16) t (cid:17)
P ∃t∈[T]∥(A˜ −A)ω∥ >ρ(t,δ) ≤ δ. Now if we replace log1 by u, we can write
t ∞ δ
(cid:18) (cid:113) (cid:19)
P ∃t∈[T],∀i∈[d]|∥A˜i−Ai∥ >1+ 1logK+ u + dlog(cid:0) 1+ t(cid:1) ≤exp(−u). Wecan
t Σt 2 2 4 d
directlyassignlogtasthesimplestandnaturalchoiceforu,since(cid:80)∞ 1 =ζ(1),ζ(.)beingthe
s=1 t
Euler-Riemannzetafunction. Thoughthisintegralisimproper,ithasaCauchyprincipalvalueas
Euler–Mascheroniconstantwhichmeans(cid:80)∞ 1 ≈γ =0.577. Soweassignu=logt
s=1 t
t t ∞
(cid:88) P(cid:16) ∥(A˜ −A)ω∥ >ρ(t,δ)(cid:17) ≤(cid:88)1 ≤(cid:88)1 ≤ζ(1)≈0.577
t ∞ t t
s=1 s=1 s=1
Lemma 5. Let µ¯ ≥ 0 be a vector, and consider the set Q = {µ ≥ 0 | q(µ) ≥ q(µ¯)}. Let
µ¯
Slaterconditionhold. Then,thesetQ isboundedand,inparticular,wehave∥µ∥ ≤ 1(f(x¯)−
µ¯ 1 γ
q(µ¯)),∀µ∈Q where,γ =min {−g (x¯)}andx¯isaSlatervector. f(.) andq(.) respectively
µ¯ 1≤j≤m j
denotestheprimalandthedualfunctionoftheoptimizationproblem.
Usingtheaforementionedlemmaswegiveaboundforthepartintheinverseofthecharacteristictime
functionthatgetsaddedforLagrangianrelaxationwhicheventuallyhelpsuplandingonaunique
formulationofsamplecomplexityupperboundsofourproposedalgorithm.
Lemma6. Foranyl∈Landω ∈∆
K
−lTA˜ω ≤D(µ,ω,Fˆ)ψ
where,ψ =
||(A˜−A)ω||∞+maxi∈[1,N](−Aω)
mini∈[1,N](−A˜ω)
Proof. Foranyl∈Landω ∈∆ wewrite
K
(−lTA˜ω)=lT(−A˜ +A−A)ω
≤∥l∥ ∥(A−A˜)ω∥ +∥l∥ max (−Aiω)
1 ∞ 1
i∈[1,N]
(cid:18) (cid:19)
≤∥l∥ (∥A−A˜)ω∥ + max (−Aω)
1 ∞
i∈[1,N]
∥(A˜ −A)ω∥ +max (−Aω)
≤D(ω,µ,Fˆ) ∞ i∈[1,N]
min (−A˜ω)
i∈[1,N]
Plugginginthedefinitionofψmentionedinthestatementofthelemmaconcludestheproof.
J.2 UsefulresultsfromBAIandpureexplorationliterature
Lemma 7. (Lemma 19 in (Garivier and Kaufmann, 2016)) There exists two constants B and C
(dependsonµandϵ),suchthat—
T
(cid:88) P{∥µˆ t−µ∥
∞
>ξ(ϵ)}≤BT exp(−CT81)
t=h(T)
Lemma 8. (Garivier and Kaufmann, 2016, Lemma 7) For all t ≥ 1 and ∀a ∈ [K], C-Tracking
√
ensuresN ≥ t+K2−K and
a,t
t √
(cid:88)
max |N − ω |≤K(1+ t)
a,t a,s
a∈[K]
s=1
43Lemma 9. (Theorem 14 in (Kaufmann and Koolen, 2021)) Let δ > 0,ν be independent one-
parameterexponentialfamilieswithmeanµandS ⊂[d]. Thenwehave,
P
(cid:34)
∃t∈N: (cid:88) N˜ d (µ ,µ )≥ (cid:88) 3ln(cid:16) 1+ln(cid:16) N˜ (cid:17)(cid:17) +|S|T
(cid:32) ln(cid:0)1 δ(cid:1)(cid:33)(cid:35)
≤δ.
ν t,a KL t,a a t,a |S|
a∈S a∈S
Here,T :R+ →R+issuchthatT(x)=2h˜
(cid:18) h−1(1+x)+ln(cid:16)
π
32(cid:17)(cid:19)
with
3/2 2
∀u≥1, h(u)=u−ln(u) (30)
(cid:40) (cid:16) (cid:17) (cid:16) (cid:17)
exp 1 h−1(x) ifx≥h−1 1
∀z ∈[1,e],∀x≥0, h˜ (x)= h−1(x) ln(z) . (31)
z
z(x−ln(ln(z))) else
Lemma10. (Lemma17in(DegenneandKoolen,2019))UnderthegoodeventG ,thereexistsaT
T ϵ
suchthatforT whereh(T)⩾T C-trackingwillsatisfy
ϵ
inf (cid:13) (cid:13) (cid:13)N t −w(cid:13) (cid:13) (cid:13) ⩽3ϵ,∀t⩾4K2 +3h(T)
w∈w∗(µ)(cid:13) t (cid:13) ϵ2 ϵ
∞
Lemma11. (Theorem2in(Degenneetal.,2019b))ThesamplecomplexityofGEis
eK
E[τ]⩽T (δ)+
0 a
where
(cid:110) (cid:16) (cid:112) (cid:17)(cid:111)
T (δ)=max t∈N:t⩽T(µ)c(t,δ)+C Rλ+Rw+O( tlogt)
0 µ t t
where Rλ is the regret of the instance player, Rw the regret of the allocation player and C an
t t µ
instance-dependentconstant.
J.3 Usefuldefinitionsandtheoremsfromliteratureoncontinuityofconvexfunctions
Definition2. (DefinitionofUpperHemicontinuity)Wesaythataset-valuedfunctionC :Θ→ωis
upperhemicontinuousatthepointθ ∈ ΘifforanyopensetS ⊂ ω withC(θ) ∈ S thereexistsa
neighborhoodU aroundθ,suchthat∀x∈U,C(x)isasubsetofS.
Theorem8. (Berge’smaximumtheorem,(Berge,1963))LetX andΘbetopologicalspaces. Let
f :X×Θ→RbeacontinuousfunctionandletC :Θ→X¯ beacompact-valuedcorrespondence
suchthatC(θ)̸=∅∀θ ∈Θ. IfC iscontinuousatθthenf∗(θ)=sup f(x,θ)iscontinuous
x∈C(θ)
andC∗ ={x∈C(θ):f(x,θ)=f∗(θ)}isupperhemicontinuous.
Theorem 9. (Heine-Borel theorem, Eduard Heine and Émile Borel) For a subset S in Rn, the
followingtwostatementsareequivalent
1. S isclosedandbounded.
2. S iscompact,meanseveryopencoverofS hasafinitesub-cover.
Theorem10. LetC beaclosedconvexsetwithnonempty(topological)interior. Letf and{fr}be
affinefunctionsfromEntoEmwithfr →f. Then
(II.1.2)lim (H(fr)∩C)⊂H(f)∩C
r→∞
(II.1.3). lim (H(fr)∩C)isaclosedconvexsubsetofH(f)∩C,
r→∞
(II.1.4). If H(f) ∩ C has nonempty interior and no component of f is identically zero, then
lim (H(fr)∩C =H(f)∩C
r→∞
Lemma 12. (Magureanu et al., 2014, Lemma 13) Consider A ∈
(R+)k×k
,c ∈
(R+)k
, and
T ⊂(R+)k×k ×(R+)k . Definet=(A,c). ConsiderthefunctionQandtheset-valuedmapQ⋆
Q(t)= inf {cx|Ax≥1,x≥0}
x∈Rk
Q⋆(t)={x:cx≤Q(t)|Ax≥1,x≥0}.
Assumethat:Forallt∈T,allrowsandcolumnsofAarenon-identically0andmin min c >0.
t∈T k k
Then,1. QiscontinuousonT,2. Q⋆isupper-hemicontinuousonT.
44