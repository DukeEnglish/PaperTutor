When to Accept Automated Predictions and When to
Defer to Human Judgment?
DanielSikara,*,ArturGarceza,TillmanWeydea,RobinBloomfielda andKaleemPeerooa
aDepartmentofComputerScience,SchoolofScienceandTechnology,City,UniversityofLondon
ORCID(ArturGarcez): https://orcid.org/0000-0002-6060-0409,ORCID(TillmanWeyde):
https://orcid.org/0000-0001-8028-9905
Abstract. Ensuringthereliabilityandsafetyofautomateddecision- modelistrainedondatafromonedomainbutappliedtodatafroma
makingiscrucial.Itiswell-knownthatdatadistributionshiftsinma- differentdomain[39].
chinelearningcanproduceunreliableoutcomes.Thispaperproposes Toquantifyandaddressdistributionshift,researchershavedevel-
anewapproachformeasuringthereliabilityofpredictionsunderdis- oped various metrics and techniques. One common approach is to
tributionshifts.Weanalyzehowtheoutputsofatrainedneuralnet- use statistical divergence measures, such as Kullback-Leibler (KL)
workchangeusingclusteringtomeasuredistancesbetweenoutputs divergence[27]orMaximumMeanDiscrepancy(MMD)[17],toas-
and class centroids. We propose this distance as a metric to evalu- sessdifferencesintrainingandtestdatadistributions.Thesemetrics
atetheconfidenceofpredictionsunderdistributionshifts.Weassign provideaquantitativeunderstandingoftheextentofthedistribution
eachpredictiontoaclusterwithcentroidrepresentingthemeansoft- shift.
maxoutputforallcorrectpredictionsofagivenclass.Wethendefine Another approach is to employ domain adaptation techniques,
asafetythresholdforaclassasthesmallestdistancefromanincor- whichaimtoalignthefeaturedistributionsofthesourceandtarget
rectpredictiontothegivenclasscentroid.Weevaluatetheapproach domains [48]. This can be achieved through methods such as im-
ontheMNISTandCIFAR-10datasetsusingaConvolutionalNeural portanceweighting[46],featuretransformation[38],oradversarial
Network and a Vision Transformer, respectively. The results show learning[14].Thesetechniquesseektomitigatetheimpactofdistri-
that our approach is consistent across these data sets and network butionshiftbymakingthemodelmorerobusttochangesinthedata
models,andindicatethattheproposedmetriccanofferanefficient distribution.
wayofdeterminingwhenautomatedpredictionsareacceptableand Recentworkhasalsofocusedondevelopingalgorithmsthatcan
whentheyshouldbedeferredtohumanoperatorsgivenadistribution detectandadapttodistributionshiftinreal-time[32].Thesemeth-
shift. odsoftenrelyonmonitoringthemodel’sperformanceonastream
of data and adjusting the model’s parameters or architecture when
asignificantdropinperformanceisdetected[3].Suchadaptiveap-
1 Introduction
proaches are particularly relevant in dynamic environments where
Ensuring the reliability and safety of automated decision-making thedatadistributionislikelytochangeovertime.
systemsisimportant,particularlyinhigh-impactareaswherethere Therefore,distributionshiftisasignificantchallengethatcanlead
existspotentialforsignificantharmfromerrors[1].Machinelearn- topoormodelperformanceifnotaddressedproperly.AsMLmodels
ing (ML) models, while powerful, are susceptible to making erro- areincreasinglydeployedinreal-worldapplications,developingro-
neouspredictionswhenfacedwithdatathatdiffersfromthedistri- bustmethodstohandledistributionshiftremainsanimportantarea
butionthattheyweretrainedon[22].Thisphenomenon,knownas ofresearch.
distributionshift,posesasignificantchallengeindeployingMLin In this paper, we propose a novel approach for quantifying the
real-worldscenarios[40]. reliabilityofpredictionsmadebyneuralnetworksunderdistribution
DistributionshiftisapervasiveissueinML,occurringwhenthe shift.Ourmethodleveragesclusteringtechniquestomeasurethedis-
distributionofthedatausedtotrainamodeldiffersfromthedistri- tancesbetweentheoutputsofatrainedneuralnetworkandclasscen-
butionofthedatathatthemodelencountersduringdeployment[40]. troids in the softmax distance space. By analyzing these distances,
Thisdiscrepancycanleadtoasignificantdegradationinmodelper- we develop a metric that provides insight into the confidence that
formance, as it may struggle to generalize to the new, unseen data onemayattributetothemodel’spredictions.Weadoptthemostcon-
[20]. servative threshold value at which model predictions are expected
Distributionshiftscanmanifestinvariousforms,suchascovariate tobe100%accurate.Theproposedmetricoffersacomputationally
shift,conceptdrift,anddomainshift[35].Covariateshiftariseswhen efficient, practical way to determine when to accept an automated
theinputdatadistributionchangeswhiletheconditionaldistribution predictionandwhenhumaninterventionmaybenecessary.
of the output given the input remains the same [45]. Concept drift Furthermore,weexploretherelationshipbetweenthedistanceto
occurswhentherelationshipbetweentheinputandoutputvariables class centroids and the model’s predictive accuracy. Our findings
changesovertime[13].Domainshiftreferstothesituationwherethe confirm as expected that classes predicted more accurately by the
modeltendtohavelowersoftmaxdistancestotheirrespectivecen-
∗CorrespondingAuthor.Email:daniel.sikar@city.ac.uk.
4202
luJ
01
]GL.sc[
1v12870.7042:viXratroids.Thisobservationhighlightsthepotentialforusingthechanges ofenhancingthesafety,robustness,andtrustworthinessofmachine
observedinthesoftmaxdistributionasaproxyforourconfidencein learning models. By considering the complete distribution of class
the model’s predictions. The objective is to establish a closer link predictionsprovidedbythesoftmaxoutput,morereliableandinfor-
thanthusfaridentifiedbytheliteraturebetweenthedistance-based mativepredictionpipelinesmaybedeveloped,thatgobeyondpoint
metricsproposedfordistributionshiftandtheapproachesthatmea- estimates[12].Thisapproachenablestheexplorationofuncertainty
surethedropinmodelaccuracy.Itisexpectedtoofferabetterun- quantification, anomaly detection, and other techniques that con-
derstandingoftheconnectionbetweenmodelperformanceandreli- tribute to building safer, more robust, and trustworthy autonomous
ability,thatis,accuracyandhowconfidentweareinthepredictions systems.
ofneuralnetworks. Uncertaintyquantificationisacrucialaspectofreliablemachine
Themaincontributionsofthispaperare: learningsystems,asitallowsfortheestimationofconfidenceinthe
model’s predictions [26]. By leveraging the softmax probabilities,
• Anewlightweightapproachforquantifyingthereliabilityofneu- techniques such as Monte Carlo dropout [12] and ensembling [28]
ral networks under distribution shift using distance metrics and canbeemployedtoestimatethemodel’suncertainty.Thesemethods
clusteringtotakefulladvantageofthelearnedsoftmaxdistribu- help identify instances where the model is less confident, enabling
tions. thesystemtodefertohumanjudgmentortakeamoreconservative
• A combined analysis of the metric-based and accuracy-based actioninsafety-criticalscenarios[34].
methods to tackle distribution shift, with experimental results Moreover, the softmax probabilities can be utilized for anomaly
showing consistency of the proposed approach across CNN and detection, which is essential for identifying out-of-distribution
ViTarchitectures. (OOD)samplesornovelclassesthatthemodelhasnotencountered
duringtraining[21].Bymonitoringthesoftmaxprobabilities,thresh-
1.1 Disclaimer olding techniques can be applied to detect anomalies based on the
distributionofthepredictions[30].Thisenablesthesystemtoflag
While identifying and mitigating safety risks within the classifica- potentiallyproblematicinputsandtakeappropriateactions,suchas
tionmodelitselfiscrucial,itdoesnotguaranteetheoverallsafety, requestinghumaninterventionortriggeringfallbackmechanisms.
robustness,reliability,trustworthiness,andconfidentperformanceof Theuseofsoftmaxprobabilitiesalsofacilitatesthedevelopmentof
theentiresysteminwhichthemodelisdeployed. morerobustmodelsthatcanhandleadversarialexamplesandother
In critical applications, the classification model is often just one typesofinputperturbations[16].Adversarialattacksaimtofoolthe
componentofalarger,complexsystem.Thesafeandreliableopera- model by crafting input samples that lead to incorrect predictions
tionofsuchasystemdependsontheproperfunctioningandinterac- with high confidence [47]. By considering the entire softmax dis-
tionofallitscomponents,includingdataacquisition,preprocessing, tribution,defensivetechniquessuchasadversarialtraining[33]and
decision-making, and actuation. Even if the classification model is inputtransformations[19]canbeappliedtoimprovethemodel’sro-
designedtomitigatesafetyrisks,failuresorvulnerabilitiesinother bustnessagainsttheseattacks.
componentscanstillcompromisetheoverallsafetyandreliabilityof Furthermore,thesoftmaxprobabilitiesprovidevaluableinforma-
thesystem. tion for interpretability and explanability of the model’s decisions
Furthermore, the deployment environment and context in which [41].Byanalyzingthedistributionofthepredictions,insightscanbe
theclassificationsystemoperatescanintroduceadditionalchallenges gainedintothemodel’sreasoningprocessandthefactorsthatcon-
and risks that may not be fully captured or addressed during the tributetoitsoutputs.Thistransparencyiscrucialforbuildingtrustin
model development phase. Factors such as data distribution shifts, thesystemandfacilitatinghuman-machinecollaboration[7].
adversarialattacks,orunexpectededgecasescanimpactthemodel’s The importance of leveraging the entire softmax distribution ex-
performanceandleadtopotentialsafetyissues. tendstovariousdomains,includingautonomousvehicles[34],medi-
Therefore,itisimportanttorecognizethatdevelopingasafeand caldiagnosis[29],andfinancialriskassessment[11].Inthesesafety-
reliable classification model is necessary but not sufficient for en- criticalapplications,theconsequencesofincorrectpredictionscanbe
suring the overall safety and reliability of the deployed system. A severe,andrelyingsolelyonthemaximumsoftmaxoutputmaynot
holistic approach that considers the entire system architecture, in- providesufficientsafeguards.Byconsideringthefulldistributionof
terfaces,anddeploymentcontextisessential.Thisincludesrigorous predictions,moreinformedandreliabledecisionscanbemade,re-
testing,validation,andmonitoringoftheentiresystem,aswellases- ducingtheriskofcatastrophicfailures.
tablishingrobustfailsafemechanismsandhumanoversighttohandle However, the use of softmax probabilities is not without chal-
unexpectedsituationsandmaintainsafeoperation. lenges. The calibration of the model’s predictions is an important
Insummary,whileidentifyingandmitigatingsafetyriskswithin consideration, as poorly calibrated models may lead to overconfi-
theclassificationmodelisimportant,itiscrucialtoacknowledgethat dentorunderconfidentestimates[18].Techniquessuchastempera-
itdoesnotguaranteethesafeandreliableperformanceoftheentire turescaling[18]andisotonicregression[52]canbeappliedtoim-
deployedsystem.Acomprehensiveapproachconsideringallcompo- provethecalibrationofthesoftmaxprobabilities,ensuringthatthey
nents,theirinteractions,andthedeploymentcontextisnecessaryto accuratelyreflectthemodel’suncertainty.
ensurethesafe,robust,reliable,trustworthy,andconfidentoperation Byconsideringthecompletedistributionofclasspredictions,tech-
ofcriticalapplications. niques can be employed to develop more reliable and informative
predictionpipelines.
Clustering: Clustering algorithms are essential for discovering
2 Background
structures and patterns in data across various domains [23, 51]. K-
means,awidelyusedalgorithm,efficientlyassignsdatapointstothe
Softmaxpredictionprobabilities:Theconceptofusingtheentire
nearest centroid and updates centroids iteratively [31]. However, it
setofsoftmaxpredictionprobabilities,ratherthansolelyrelyingon
requires specifying the number of clusters and is sensitive to ini-
the maximum output, has been extensively studied in the contexttial centroid placement [2]. Hierarchical clustering creates a tree- ages,eachofsize28x28grayscale(singlechannel)pixels,represent-
likestructurebymergingordividingclusters[25]butmaynotscale ingdigitsfrom0to9.
welltolargedatasets[36].Density-basedalgorithms,likeDBSCAN, The CNN architecture, implemented using PyTorch, consists of
identify clusters as dense regions separated by lower density areas twoconvolutionallayersfollowedbytwofullyconnectedlayers.The
[10,43]. firstconvolutionallayerhas16filterswithakernelsizeof3x3anda
Other applications include image segmentation for object detec- paddingof1.Thesecondconvolutionallayerhas32filterswiththe
tion [44], anomaly detection for fraud and intrusion detection [5], samekernelsizeandpadding.Eachconvolutionallayerisfollowed
customersegmentationfortargetedmarketing[37],andbioinformat- byaReLUactivationfunctionandamax-poolinglayerwithapool
ics for gene expression analysis and disease subtype identification sizeof2x2.Theoutputofthesecondconvolutionallayerisflattened
[9,24].Thechoiceofalgorithmdependsondatacharacteristics,de- andpassedthroughtwofullyconnectedlayerswith128and10neu-
siredclusterproperties,andcomputationalresources[42]. rons,respectively.Thefinaloutputispassedthroughalog-softmax
Giventhecontextandtothebestofourknowledge,nopriorwork functiontoobtainthepredictedclassprobabilities.Themodelwas
existsinusingsoftmaxdistancetoclasscentroidtothresholdtrustin
themodelpredictiveaccuracyinclassificationtasks. Algorithm2FindMinimumSoftmaxDistancestoCentroidsforIn-
correctlyPredictedDigits(Threshold)
1: procedureFINDMINDISTANCES(data)
3 ClusteringandSoftmaxDistanceasaConfidence
2: labels←[0,1,2,3,4,5,6,7,8,9]
Metric
3: thresh←emptyarrayofshape(10,2)
4: fori←0to9do
Weconsideraneuralnetworkoutputvectorp = (p ,p ,...,p )
1 2 K
(cid:80) 5: label←labels[i]
where p = 1, representing a probability distribution obtained
i
6: min_dist←min(data[data[:,1]==label,0])
by normalizing the logit vector z = (z ,z ,...,z ) through the
1 2 K
softmaxfunction,p
i
=softmax(z i)=ezi/(cid:80)K j=1ezj.Forexample, 7 8:
:
t th hr re es sh h[ [i i, ,0 1] ]← ←m labin el_dist
givenp = [0.01,0.01,0.01,0.01,0.9,0.01,0.01,0.01,0.01,0.01],
9: endfor
thepredictedclassis’4’,correspondingtothehighestvalueatindex
10: returnthresh
five,reflectingtheconfidenceofthepredictionforeachclassfrom’0’
11: endprocedure
to’9’.Thelogits,representinglog-likelihoodsofclassmemberships,
arerelatedtoprobabilitiesbyz =log(p /(1−p ))wherez isthe
i i i i
logitforclassi,andp istheprobabilityoftheinputbelongingto trainedusingtheStochasticGradientDescent(SGD)optimizerwith
i
classi[15,4]. alearningrateof0.01andabatchsizeof64.Thelearningratewas
WestorethepredictionsforMNISTandCIFAR-10datasetsina determinedusingacustomlearningratefunctionthatdecreasesthe
matrixM ∈ Rn×12,wherenisthenumberofpredictions,thefirst learningrateovertime.TheCross-EntropyLossfunctionwasusedas
tencolumnsarethesoftmaxprobabilities,column11isthetrueclass thecriterionforoptimization.Themodelwastrainedfor10epochs.
andcolumn12isthepredictedclass. The MNIST dataset was preprocessed using a transformation
To obtain cluster centroids C ∈ R10×10 we calculate the mean pipeline that converted the images to PyTorch tensors and normal-
ofallcorrectpredictionsfromthetrainingdatasetswithAlgorithm izedthepixelvaluestohaveameanof0.5andastandarddeviation
1. To calculate the softmax distance threshold we use all incorrect of0.5.ThedatasetwasthenloadedusingPyTorch’sDataLoader,for
predictionswithAlgorithm2. batchprocessingandshufflingofthedata.
ThetotalnumberofparametersfortheMNISTclassificationCNN
is 206,922 and took 5m6s to train on a Dell Precision Tower 5810
Algorithm1K-MeansCentroidInitialisationfromSoftmaxOutputs
with a 6 core Intel Xeon Processor and 32GB memory running
Require: correct_preds: array of shape (n,12), where n is the
Ubuntu18.04.
numberofcorrectpredictions
VisionTransformer:TheVisionTransformer(ViT)architecture
Ensure: centroids:arrayofshape(10,10),initialisedcentroidsfor
[8] is implemented using the Hugging Face Transformers [49] li-
eachdigitclass
brary. The model used in this study, ’google/vit-base-patch16-224-
1: probs_dist←corrects_preds[:,:10] ▷Extractprobability in21k’ [50], is pre-trained on the ImageNet-21k dataset [6], which
distributionforeachdigit
contains 14 million labeled images. The pre-trained model is then
2: centroids←zeros((10,10)) ▷Initialisecentroidsarray fine-tunedontheCIFAR-10dataset.TheViTmodeldividesanin-
3: fordigit←0to9do putimageintopatchesandprocessesthemusingaTransformeren-
4: indices ← where(argmax(probs_dist,axis = 1) == coder. The model used in this study has a patch size of 16x16 and
digit)[0] ▷Findindicesofrowswheredigithashighest
animagesizeof224x224.TheViTmodeloutputsarepresentation
probability
oftheimage,whichisthenpassedthroughalinearlayertoobtain
5: centroid←mean(probs_dist[indices],axis=0) ▷ thefinalclassprobabilities.Themodelhas86.4Mparametersandis
Computemeanprobabilitydistributionforselectedrows
fine-tunedtoclassifyimagesfromtheCIFAR-10dataset,consisting
6: centroids[digit]←centroid ▷Assigncentroidto of 50,000 training images and 10,000 testing images, each of size
correspondingrowincentroidsarray
32x32pixels,representing10differentclasses:airplane,automobile,
7: endfor bird,cat,deer,dog,frog,horse,ship,andtruck.
8: returncentroids Thedatapreprocessingpipelineinvolveson-the-flydataaugmen-
tationusingthetorchvisionlibrary’stransformsmodule.Thetraining
Convolutional Neural Network: A Convolutional Neural Net- dataundergoesrandomresizedcropping,randomhorizontalflipping,
work(CNN)isusedtoclassifyhandwrittendigitsfromtheMNIST conversiontoatensor,andnormalization.Thevalidationandtesting
dataset,consistingof60,000trainingimagesand10,000testingim- dataareresized,center-cropped,convertedtoatensor,andnormal-ized. zeroisthedigitlesslikely,andnumbereightisthedigitmostlikely
The model is trained using the Hugging Face Trainer API. The tobemisclassified.Otherdigitsthatarelesslikelytobemisclassified
learningrateissetto2×10−5,theper-devicetrainbatchsizeis10, aredigitsoneand;sixinthetrainingdataset,andfiveinthetesting
theper-deviceevalbatchsizeis4,andthenumberoftrainingepochs dataset.Digiteightislikelytobemisclassifiedassixornine,while
is3.Theweightdecayissetto0.01.ThemodelistrainedonGoogle digitthreeislikelytobemisclassifiedastwo,fiveornine.
ColabPro,T4GPUhardwareacceleratorwithhighram.
4 ExperimentalResultsandDiscussion
Inthissection,wepresentanddiscussourresultsforCIFAR-10/ViT
andMNIST/CNN.
TheCNN/MNISTclassifiertook5m6stotrain.Theaccuracyon
thetrainingdatasetis98.38%and98.46%onthetestingdataset.The
ViT/CIFAR-10classifiertook1h15mtotrain,registering99.04%ac-
curacyonthetestingdataset.
Figure 1: Please zoom in for detail. Confusion matrices for the
SoftmaxDistancetoClassCentroidStatistics:Westorethesoft-
MNIST classification model on the training dataset (left) and test-
maxoutputs,trueandpredictedlabelsfortheMNISTandCIFAR-10
ingdataset(right).Thematricesdisplaythetruelabelsonthevertical
training datasets, we obtain the mean values for all correctly pre-
axisandthepredictedlabelsonthehorizontalaxis.Thediagonalele-
dictedclasses,usethevaluesinalgorithm1toinitialisethecluster
mentsrepresentcorrectlyclassifiedinstances,whiletheoff-diagonal
centroids,thenusingtheproceduredescribedinalgorithm2andthe
elementsindicatemisclassifications.
samehardwareusedtotraintheMNISTclassifierCNN,generateK-
Means clusters and compute statistics as presented in Table 1 (for TheconfusionmatricesfortheCIFAR-10datasetinFigure2illus-
the MNIST results), a summary of the distances between the soft- tratetheperformanceofaclassificationmodelonboththetraining
maxoutputsofamodelandthecentroidsforeachdigitclass(0-9)in andtestingsets.Forthetrainingset,themodelexhibitsastrongdi-
theMNISTdataset.Thecentroidsarecalculatedusingthesoftmax agonal, indicative of high classification accuracy for most classes.
outputs for correct predictions from the training dataset. The table Nonetheless, certain classes show notable confusion, such as ’cat’
isdividedintofourmainsections:TrainingDatasetCorrectPredic- with ’dog’ and ’deer’ with ’frog’, and the confusion is reflected in
tions,TrainingDatasetIncorrectPredictions,TestingDatasetCorrect theclasssoftmaxdistancetoclustercentroid.
Predictions,andTestingDatasetIncorrectPredictions.Foreachdigit Examiningthetestingdataset,themodelachievesgoodclassifica-
andsection,statisticsaredisplayedwithrespecttosoftmaxdistance tionsuccess,withperfectrecognitionof’frog’class.Misclassifica-
fromeachclasstoitscentroid:themean,median,minimum(high- tionsarepresentbutconsiderablyreducedcomparedtothetraining
lighted in bold for the testing datasets), maximum (highlighted in dataset, particularly for pairs such as ’truck’ and ’automobile’, as
boldforthetrainingdatasets),standarddeviation(σ),andcountof wellas’cat’and’dog’.Thereducedconfusioninthetestsetisalso
instancesareprovided.Wenotethatforthecorrectpredictions,the reflectedinthesoftmaxdistancetoclustercentroid.
meansoftmaxdistancetoclasscentroidfordigitszero,oneandsix
are lowest (network prediction accuracy is high) while for digit 8
themeansoftmaxdistancetoclasscentroidisacomparativelylarger
value(netrowkpredictionaccuracyisnotashigh).Thesignificance
oftheboldhighlightforMaxvaluesintheTrainingsection,andMin
values in the Correct Prediction sections, is that the Min values in
theIncorrectPredictionssections,isthatthelatteriseffectivelythe
Thresholdweproposebeusedasaboundaryforacceptingtheclass
prediction as accurate. Anything softmax distances equal or above
thethresholdwillbeconsiderednotsafetouse.Itbecomesevident
Figure 2: Please zoom in for detail. Confusion matrices for the
by comparing both columns, that for the training dataset, there is
CIFAR-10classificationmodelonthetrainingdataset(left)andtest-
a significant overlap between Max and Min columns, however, the
ingdataset(right).
testingdatasetpresentsaninterestingpropertyinthatthereislessof
anoverlap.Thesignificanceoftheoverlapisthatanycorrectpredic- Figure3suggestshowthetrainedneuralnetworkmodelachieves
tionswithintheoverlapwillbetaggedasunsafe,fortheschemewe higher predictiveaccuracy forclasses that havelower softmaxdis-
proposetohold,whichmeansmoremanualclassificationandhuman tance to their respective class centroids, compared to classes for
interventiononthedownside,andontheupsideahighlikelihoodthat whichthemodelhaslowerpredictiveaccuracy.
everypredictionwithsoftmaxdistancebelowthethresholdisaccu- Thescatterplotshowstherelationshipbetweenclassificationac-
rate. curacy and mean class distance to the centroid for the MNIST
In practice a small number of samples, 0.04%, consistent across dataset. Training data (blue dots) and testing data (green dots) are
bothCIFAR-10andMNISTtestingdatasetprediction,arefoundin each fitted with a linear regression line, demonstrating a negative
theoverlap,asshownlaterinTables2and3.AlsoshowninTable correlationwhereincreasedmeandistancecorrespondstodecreased
1arethesoftmaxdistancestandarddeviationsandcountsforcorrect accuracy.Thesteeperslopeofthetrainingdatafit(-0.806)compared
andincorrectclassifications. tothetestingdatafit(-0.677)reflectsthegreateraccuracyandmore
Predictive Accuracy and Softmax Distance to Class Centroid: compactclusterobtainedfromthecorrecttestpredictionscompared
TheconfusionmatricesinFigure1providesomeinsightsintowhat totheclusterobtainedfromcorrecttrainingpredictions.
arethemostlikelyMNISTmisclassifications.Wenotethatnumber Theseresultsshowaninverserelationship:asthemeandistanceTrainingDatasetCorrectPredictions TrainingDatasetIncorrectPredictions
Digit Mean Median Min Max σ Count Mean Median Min Max σ Count
0 0.0166 0.0088 0.0018 0.8433 0.0536 5890 0.9955 0.9552 0.7037 1.3681 0.1756 33
1 0.0154 0.0085 0.0020 0.7051 0.0486 6704 1.0912 1.0771 0.7247 1.3909 0.2197 38
2 0.0370 0.0208 0.0056 0.7453 0.0746 5859 1.0409 1.0460 0.6962 1.3912 0.2064 99
3 0.0352 0.0192 0.0055 0.7509 0.0754 6019 1.0522 1.0338 0.7139 1.3999 0.2143 112
4 0.0295 0.0166 0.0031 0.6933 0.0661 5755 1.0681 1.0642 0.7139 1.4010 0.2045 87
5 0.0298 0.0165 0.0024 0.7634 0.0693 5339 1.0572 1.0560 0.7066 1.3956 0.2000 82
6 0.0154 0.0081 0.0015 0.7981 0.0485 5884 1.0485 1.0702 0.7068 1.4015 0.2110 34
7 0.0302 0.0171 0.0028 0.7365 0.0678 6199 1.0133 0.9764 0.6960 1.3989 0.2160 66
8 0.0619 0.0363 0.0092 0.7788 0.0989 5581 1.0232 1.0083 0.6852 1.3816 0.1990 270
9 0.0399 0.0232 0.0048 0.7616 0.0781 5844 1.0576 1.0830 0.7179 1.3974 0.2201 105
TestingDatasetCorrectPredictions TestingDatasetIncorrectPredictions
Digit Mean Median Min Max σ Count Mean Median Min Max σ Count
0 0.0141 0.0075 0.0021 0.7225 0.0506 977 1.0329 1.0185 0.7923 1.2880 0.2026 3
1 0.0126 0.0071 0.0023 0.6737 0.0445 1129 0.9823 0.9556 0.7278 1.2445 0.1898 6
2 0.0354 0.0202 0.0037 0.6697 0.0704 1015 1.0855 1.0725 0.7010 1.3833 0.1844 17
3 0.0331 0.0177 0.0049 0.7515 0.0765 998 0.9823 0.9752 0.7102 1.3230 0.2044 12
4 0.0306 0.0169 0.0047 0.6603 0.0678 972 0.9309 0.8725 0.7073 1.3110 0.1923 10
5 0.0313 0.0173 0.0051 0.6324 0.0692 883 1.1874 1.2976 0.8477 1.3982 0.2067 9
6 0.0172 0.0088 0.0029 0.7135 0.0545 941 1.0737 1.0242 0.7240 1.4009 0.2120 17
7 0.0295 0.0165 0.0036 0.6939 0.0678 1009 0.9665 0.8833 0.7148 1.3628 0.2016 19
8 0.0616 0.0372 0.0114 0.7328 0.0918 934 1.0513 1.0399 0.7252 1.3842 0.2022 40
9 0.0359 0.0206 0.0042 0.6870 0.0765 980 1.0502 1.0486 0.6968 1.3838 0.2197 29
Table1:StatisticalSummaryofMNISTSoftmaxOutputDistancestoCentroidsforDifferentDatasetsandPredictionOutcomes.The
centroidsareobtainedfromSoftmaxoutputsforcorrectclasspredictionsfromthetrainingdataset.
fromthedatapointsinaclasstotheircentroidincreases,thepropen- thevisualizationofawiderangeofvalues.Forbothsets,thereisa
sity for correct classification diminishes. This could be due to the clearpatternwherethecorrectlyclassifiedinstancestendtohavea
spreadofdatapointswithinaclass–greaterdistancesfromthecen- smaller median distance to the class centroid compared to the in-
troidreflectalargervariancewithintheclass,potentiallymakingit correctly classified ones. This observation is consistent across all
morechallengingfortheclassifiertoidentifythedefiningcharacter- classes, suggesting that instances closer to the centroid of their re-
isticsofeachclassaccurately. spectiveclassinthefeaturespacearemorelikelytobeclassifiedcor-
TheCIFAR-10linearfitissteeperascanbeobservedbytheyaxis rectlybythemodel.Thenotableoverlapintheinterquartileranges,
values,althoughitcanbearguedprovidesabetterfit. however,indicatesthatwhiledistancetothecentroidisaninforma-
tivemetric,itisnotsolelydeterminativeofclassificationaccuracy.
Theincorrectlyclassifiedinstancesexhibitgreatervarianceindis-
tancestothecentroid,asevidencedbythelongerwhiskersandthe
presence of outliers. This variability implies that misclassified in-
stancescansometimesbefarofffromthecoreclusteroftheirtrue
class, potentially falling closer to the regions dominated by other
classesinthefeaturespace.Thisisindicativeofboundarycasesor
instancesthatbeararesemblancetomultiplecategories.Theconsis-
Figure3:Pleasezoominfordetail.Expectedaccuracylinearfitbased tencyofthesetrendsbetweenthetrainingandtestingsetsindicates
onpredictionsoftmaxdistancetoclasscentroid.MNISTfitisonthe that the distance to the centroid is a robust indicator of classifica-
left,CIFAR-10isontheright. tiondifficultyacrossthemodel’sapplication.Thepresenceofsome
correctlyclassifiedinstancesathigherdistancessuggeststhatother
Overlapbetweenmaximumandminimumsoftmaxdistancesto
factorsalsoinfluenceclassificationaccuracy,suchasthedensityof
classcentroids:Figure4presentsboxplotsshowingthedistribution
datapointsinthesurroundingfeaturespace,classoverlap,orspecific
of distances to centroids for correctly and incorrectly classified in-
intra-classvariabilities.
stancesineachclassoftheCIFAR-10trainingandtestingdatasets.
Inthetrainingdataset,thedistancestocentroidsforcorrectlyclassi-
fiedinstances(greenboxes)aregenerallylowerthanthoseforincor- Digit TrainData-TrainCentroids TestData-TrainCentroids
Count Total Overlap Count Total Overlap
rectlyclassifiedinstances(redboxes),indicatingthatcorrectlyclas-
0 2 5890 0.03% 1 977 0.10%
sifiedinstancestendtobeclosertotheirrespectiveclasscentroidsin
1 0 6704 0.00% 0 1129 0.00%
thefeaturespace.However,thereisasmalloverlapbetweenthedis- 2 1 5859 0.02% 0 1015 0.00%
tancesofcorrectlyandincorrectlyclassifiedinstances,particularlyin 3 3 6019 0.05% 1 998 0.10%
classessuchascat,dog,anddeer.Thetestingdatasetexhibitsasim- 4 0 5755 0.00% 0 972 0.00%
5 5 5339 0.09% 0 883 0.00%
ilartrend,withcorrectlyclassifiedinstanceshavinglowerdistances
6 2 5884 0.03% 1 941 0.11%
tocentroidscomparedtoincorrectlyclassifiedinstances.Theover- 7 2 6199 0.03% 0 1009 0.00%
lapbetweenthetwogroupsislesspronouncedinthetestingdataset, 8 12 5581 0.22% 1 934 0.11%
suchasinclasseslikefrog.Notethereisnofrogboxplotforincorrect 9 1 5844 0.02% 0 980 0.00%
classifications,asreflectedintheconfusionmatrix. Totals 28 59074 0.05% 4 9838 0.04%
Table2:MNISTcountsofcorrectlyclassifiedtrainingandtestingim-
Theside-by-sideboxplotsconveythedistributionsofdistancesto
agepredictionsandcountswithdistancetocentroidsequalorabove
centroidsforboththetrainingandtestingsets,categorizedbyclass.
errorthreshold.
These distances are represented on a logarithmic scale, facilitatingFigure4:DistributionofDistancestoCentroidsforCorrectlyandIncorrectlyClassifiedInstancesinTrainingandTestingCIFAR-10data,
wheretrainingdataisontheleftandtestingdataisdisplayedontheright.Distancesonyaxisareshownonalogarithmicscale.Note,
centroidsareobtainedfromcorrectlyclassifiedtrainingexamples,thenusedforbothtrainingandtestingdatasets,aclusterisnotcreated
fromthetestingsoftmaxdistances.
Class TrainData-TrainCentroids TestData-TrainCentroids TheTotalssummarisetheoverallcountsandoverlappercentages
Count Total Overlap Count Total Overlap acrossalldigitclasses.Forthetrainingdata,28outof59,074images
plane 13 4252 0.31% 1 990 0.10% (0.05%)havedistancesabovethethreshold,whileforthetestdata,
auto 1 4326 0.02% 0 989 0.00%
only4outof9,838images(0.04%)exceedthethreshold.
bird 9 4216 0.21% 0 993 0.00%
Thelowoverlappercentagesindicatethatthemajorityofthecor-
cat 20 4103 0.49% 2 973 0.21%
deer 14 4255 0.33% 0 991 0.00% rectlyclassifiedimagesarewell-separatedfromtheincorrectlyclas-
dog 11 4157 0.26% 1 967 0.10% sified images in terms of their softmax distances to the centroids.
frog 11 4310 0.26% 0 1000 0.00% This analysis provides insights into the softmax distance being a
horse 12 4223 0.28% 0 991 0.00%
proxy to distinguish between between correct and incorrect digit
ship 11 4258 0.26% 0 998 0.00%
truck 10 4251 0.24% 0 981 0.00% classificationsbasedontheproximityoftheimagestotheirrespec-
Totals 112 42351 0.26% 4 9873 0.04% tiveclasscentroidsinthesoftmaxdistancespace.Thesameanalysis
Table 3: CIFAR10 counts of correctly classified training and test- appliestoTable3.Mostindicativeoftheconsistencyofthesuggested
ing image predictions and counts with distance to centroids equal approachisthanbothCIFAR-10andMNISTpresentanoverlapof
oraboveerrorthreshold. 0.04%forcorrectlyclassifiedimagesatorabovethreshold.Notewe
tagtheimagesintheoverlapasincorrectlyclassified,forthesakeof
assuringthatallsoftmaxdistancestoclustercentroidbelowthresh-
Table2presentsananalysisofthecountsandpercentagesofcor- oldarecorrectclassifications.
rectlyclassifiedimagesinthetrainingandtestingdatasetsthathave Accuracy decrease vs threshold decrease: Having observed that
softmaxdistancestotheirrespectiveclasscentroidsaboveacertain thepercentageofcorrectlyclassifiedimagesthathavesoftmaxdis-
threshold. The threshold is determined by the nearest softmax dis- tances equal or above threshold is 0.04% for both CIFAR-10 and
tancetothecentroidfortheincorrectlyclassifiedclasses. MNISTtestingdatasets,weaskhowloweringthethresholdaffects
The table is divided into two main sections: "Train Data - Train theaccuracy.Figure5revealsthatforMNIST(leftplot)classesac-
Centroids"and"TestData-TrainCentroids."Foreachsection,the curately classified by the CNN model, such as zero and one, even
tableprovidesthecountofimagesthatsatisfythethresholdcondi- settingthethresholdat10%oftheoriginalclassthresholds(0.9on
tion,thetotalnumberofimagesineachclass,andthepercentageof the x axis), still present accuracies greater than 0.97, meaning the
overlap(i.e.,theproportionofimagesabovethethresholdrelativeto classclustersaretightlyplacednearthecentroids,whilefordigit8,
thetotalcount). themostmisclassifieddigit,hadthethresholdbeensetat10%ofthe
Lookingatthe"TrainData-TrainCentroids"section,weobserve originalvalue,theaccuracywouldexpecttodropto0.84,meaning
thattheoverlappercentagesarerelativelylow,rangingfrom0.00%to 16%ofthepredictionswouldbedeferredtohumanjudgement,and
0.22%.Thissuggeststhatonlyasmallfractionofthecorrectlyclassi- 84%wouldbeconsidered100%accurate..
fiedtrainingimageshavesoftmaxdistancestotheircentroidsabove Predictionswithsoftmaxdistancetoclasscentroidbelowtheclass
the threshold set by the incorrectly classified images. The highest threshold are expected to be 100% accurate, class predictions with
overlap is observed for digit class 8, with 12 out of 5,581 images distancesequalorgreaterthanthresholdarethenlefttohumanjudge-
(0.22%)havingdistancesabovethethreshold. ment.
Similarly,inthe"TestData-TrainCentroids"section,theoverlap Figure 6 shows the average softmax probabilities for each digit
percentagesareevenlower,rangingfrom0.00%to0.11%.Thisindi- class (0 to 9) in the MNIST training dataset, separated into cor-
catesthatthetrainedmodelisabletocorrectlyclassifythemajority rectly classified instances (top row) and incorrectly classified in-
ofthetestimageswhilemaintainingadistancetothecentroidsbe- stances(bottomrow).Theprobabilitiesaredisplayedonalogarith-
lowthethresholdsetbytheincorrectlyclassifiedimages.Thehighest mic scale. For correctly classified digits, the highest average prob-
overlapinthetestdataisobservedfordigitclasses6and8,with1 abilityisobservedforthecorrespondingtruedigitclass,indicating
outof941(0.11%)and1outof934(0.11%)images,respectively, strong confidence in the correct predictions. In contrast, for incor-
havingdistancesabovethethreshold. rectlyclassifieddigits,theaverageprobabilitiesaremoreevenlydis-Figure5:Pleasezoominfordetail.Expectedaccuracydecreaseasa
resultofthresholddecrease.MNISTdataisontheleft,CIFAR-10is
ontheright.Thexaxisshowsthethresholddecrementinfactorsof
0.1,thatis,at0.1thethresholdis90%oftheoriginalthresholdwhile Figure8:Pleasezoominfordetail.AverageSoftmaxProbabilitiesfor
at0.9thethresholdis10%oftheoriginalthresholdandconsequently CorrectlyandIncorrectlyClassifiedClassesintheCIFAR-10Train-
nearedtotheclasscentroid. ingDataset
Figure9:Pleasezoominfordetail.AverageSoftmaxProbabilitiesfor
Figure6: Please zoom in for detail. Average Softmax Probabilities CorrectlyandIncorrectlyClassifiedclassesintheCIFAR-10Testing
forCorrectlyandIncorrectlyClassifiedDigitsintheMNISTTesting Dataset
Dataset. thesoftmaxvaluesfortheotherclassesarenotablycloserinmagni-
tributed across different digit classes, suggesting lower confidence tude,asevidentfromtheshorterbarsonthelogarithmicscale.This
and potential confusion between similar-looking digits. Figure 7 is suggests that when the model makes an incorrect prediction, it as-
thecorrespondingplotfortheMNISTtestingdataset. signsmoresubstantialprobabilitiestomultipleclasses,indicatinga
higherlevelofuncertaintyorconfusioninthedecision-makingpro-
cess.Figures8and9barchartsshowtheaveragesoftmaxdistribu-
tionsforcorrect(green/blue)andincorrect(red)classpredictionsin
boththetestingandtrainingCIFAR-10datasets.
Comparing the testing and training datasets, we observe similar
patterns in the softmax distance distributions for both correct and
incorrectpredictions.Theconsistencyofthesepatternssuggeststhat
ourapproachisconsistentacrossdatasetsandmodels.
Theanalysisofsoftmaxdistancedistributionsmaybetakenasan
insightintothemodel’sdecision-makingprocess.Thedifferencein
the softmax values between correct and incorrect predictions high-
lights the model’s ability to discriminate between classes when it
makesaccuratepredictions.Ontheotherhand,themoreevenlydis-
Figure7: Please zoom in for detail. Average Softmax Probabilities tributed softmax values for incorrect predictions suggest that the
forCorrectlyandIncorrectlyClassifiedDigitsintheMNISTTesting modelstrugglestomakecleardistinctionsbetweenclassesinthose
Dataset. cases,assigningconsiderableprobabilitiestomultipledigits,where
ourproposedthresholdingmethodmaybeanadditionaltooltohelp
FortheCIFAR-10weobservesimilarresults.Forcorrectlyclas-
evaluatepredictionsindifferentsettings.
sifiedinstances,theaveragesoftmaxvaluecorrespondingtothetrue
digitclassissignificantlyhighercomparedtothesoftmaxvaluesof
the other digit classes. This observation holds true across all digit 5 ConclusionsandFutureWork
classesinboththetestingandtrainingdatasets.Thepronounceddif-
ferenceinmagnitudesindicatesthatthemodelassignsahighlevelof Wepresentedasimpleapproachtothresholdingaccuracyinanim-
confidencetothecorrectpredictions,withthepredictedprobability ageclassificationsetting,bytrainingtwodistinctnetworkarchitec-
forthetrueclassbeingordersofmagnitudelargerthantheprobabil- tures,ontwodistinctdatasets,andshowingourresultsareconsistent
itiesassignedtotheotherclasses. acrossbothscenarios.Wedemonstratedthestepsrequiredtoeffec-
In contrast, for incorrectly classified instances, the average soft- tivelycreateclassclustersbyinitialisingcentroidswiththemeanof
maxvaluesexhibitamoreevendistributionacrossthedigitclasses. correctclasspredictionsforeachdistinctclass,wheretheK-Means
Whilethesoftmaxvalueforthepredictedclassisstillrelativelyhigh, algorithmquicklyconvergeswithgoodclusterseparation.Athresh-oldwasproposedtoensurepredictionsbelowthresholdaresafe,ata
smallcostoflabellingasincorrectasmallnumberofcorrectpredic-
tionsatorabovethreshold.
We posit that the optimal threshold is domain-dependent and
should be determined by domain experts who are equipped to bal-
ancetheefficiencyofautomateddecision-makingagainsttheneces-
sityfortime-intensivehumanjudgment,takingintoaccountthespe-
cificstakesinvolved.
We are applying the concepts discussed in this study to au-
tonomous system safety, in the context of self-driving cars using
theCARLAsimulator,andconstituenttasksinthedecision-making
stack, such as image classification and segmentation, where our
methodology aims to enhance system safety by identifying scenar-
ios,includingOODscenarios,wherehumanjudgmentispreferable
totheautonomoussystem’sassessment.
Finally,weareconsideringthesoftmaxoutputasatrainingdataset
initself,forasimplemulti-layerperceptronbinaryclassifier,tocom-
pareandcontrastthesoftmaxdistanceapproach,andaregressornet-
workcombinedwithourcurrentapproach,toprovideaquantitye.g.
sigmoidfunctionoutputasaweighttofurtherstudyoptimalthresh-
oldvalues.References deeplearningforcomputervision? AdvancesinNeuralInformation
ProcessingSystems,30,2017.
[27] S.KullbackandR.A.Leibler. Oninformationandsufficiency. The
[1] D. Amodei, C. Olah, J. Steinhardt, P. Christiano, J. Schulman, AnnalsofMathematicalStatistics,22(1):79–86,1951.
and D. Mané. Concrete problems in ai safety. arXiv preprint [28] B.Lakshminarayanan,A.Pritzel,andC.Blundell.Simpleandscalable
arXiv:1606.06565,2016. predictiveuncertaintyestimationusingdeepensembles.InAdvancesin
[2] D.ArthurandS.Vassilvitskii. k-means++:Theadvantagesofcareful NeuralInformationProcessingSystems,pages6402–6413,2017.
seeding. InProceedingsoftheeighteenthannualACM-SIAMsympo- [29] C.Leibig,V.Allken,M.S.Ayhan,P.Berens,andS.Wahl. Leveraging
siumonDiscretealgorithms,pages1027–1035,2007. uncertaintyinformationfromdeepneuralnetworksfordiseasedetec-
[3] M.Baena-García,J.delCampo-Ávila,R.Fidalgo,A.Bifet,R.Gavaldà, tion.ScientificReports,7(1):1–14,2017.
andR.Morales-Bueno. Earlydriftdetectionmethod. InFourthInter- [30] S. Liang, Y. Li, and R. Srikant. Enhancing the reliability of out-of-
nationalWorkshoponKnowledgeDiscoveryfromDataStreams,vol- distributionimagedetectioninneuralnetworks. InInternationalCon-
ume6,pages77–86,2006. ferenceonLearningRepresentations,2018.
[4] C.M.Bishop. Patternrecognitionandmachinelearning. Springer,2: [31] S.Lloyd. Leastsquaresquantizationinpcm. IEEEtransactionson
645–678,2006. informationtheory,28(2):129–137,1982.
[5] V.Chandola,A.Banerjee,andV.Kumar.Anomalydetection:Asurvey. [32] J.Lu,A.Liu,F.Dong,F.Gu,J.Gama,andG.Zhang. Learningunder
ACMcomputingsurveys(CSUR),41(3):1–58,2009. conceptdrift:Areview. IEEETransactionsonKnowledgeandData
[6] J.Deng,W.Dong,R.Socher,L.-J.Li,K.Li,andL.Fei-Fei.Imagenet: Engineering,31(12):2346–2363,2018.
Alarge-scalehierarchicalimagedatabase.In2009IEEEconferenceon [33] A.Madry,A.Makelov,L.Schmidt,D.Tsipras,andA.Vladu.Towards
computervisionandpatternrecognition,pages248–255.Ieee,2009. deeplearningmodelsresistanttoadversarialattacks. InInternational
[7] F.Doshi-VelezandB.Kim.Towardsarigorousscienceofinterpretable ConferenceonLearningRepresentations,2017.
machinelearning.arXivpreprintarXiv:1702.08608,2017. [34] R.Michelmore,M.Kwiatkowska,andY.Gal. Evaluatinguncertainty
[8] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, quantificationinend-to-endautonomousdrivingcontrol.arXivpreprint
T.Unterthiner,M.Dehghani,M.Minderer,G.Heigold,S.Gelly,etal. arXiv:1811.06817,2018.
Animageisworth16x16words:Transformersforimagerecognitionat [35] J.G.Moreno-Torres,T.Raeder,R.Alaiz-Rodríguez,N.V.Chawla,and
scale.arXivpreprintarXiv:2010.11929,2020. F.Herrera. Aunifyingviewondatasetshiftinclassification. Pattern
[9] M. B. Eisen, P. T. Spellman, P. O. Brown, and D. Botstein. Cluster Recognition,45(1):521–530,2012.
analysisanddisplayofgenome-wideexpressionpatterns. Proceedings [36] D.Müllner. Modernhierarchical,agglomerativeclusteringalgorithms.
oftheNationalAcademyofSciences,95(25):14863–14868,1998. arXivpreprintarXiv:1109.2378,2011.
[10] M.Ester,H.-P.Kriegel,J.Sander,andX.Xu.Adensity-basedalgorithm [37] E. W. Ngai, L. Xiu, and D. C. Chau. Application of data mining
fordiscoveringclustersinlargespatialdatabaseswithnoise. InKdd, techniquesincustomerrelationshipmanagement:Aliteraturereview
volume96,pages226–231,1996. andclassification. Expertsystemswithapplications,36(2):2592–2602,
[11] G.Feng,J.He,andN.G.Polson. Deeplearning-basedquantitative 2009.
tradingstrategiesforstockmarkets. arXivpreprintarXiv:1805.01039, [38] S.J.PanandQ.Yang.Asurveyontransferlearning.IEEETransactions
2018. onKnowledgeandDataEngineering,22(10):1345–1359,2009.
[12] Y.GalandZ.Ghahramani.Dropoutasabayesianapproximation:Rep- [39] V.M.Patel,R.Gopalan,R.Li,andR.Chellappa. Visualdomainadap-
resentingmodeluncertaintyindeeplearning.InternationalConference tation:Asurveyofrecentadvances.IEEESignalProcessingMagazine,
onMachineLearning,pages1050–1059,2016. 32(3):53–69,2015.
[13] J.Gama,I.Žliobaite˙,A.Bifet,M.Pechenizkiy,andA.Bouchachia. A [40] J. Quiñonero-Candela, M. Sugiyama, A. Schwaighofer, and N. D.
surveyonconceptdriftadaptation. ACMComputingSurveys(CSUR), Lawrence.Datasetshiftinmachinelearning.TheMITPress,2009.
46(4):1–37,2014. [41] M.T.Ribeiro,S.Singh,andC.Guestrin. "whyshoulditrustyou?"
[14] Y.Ganin,E.Ustinova,H.Ajakan,P.Germain,H.Larochelle,F.Lavi- explainingthepredictionsofanyclassifier. InProceedingsofthe22nd
olette,M.Marchand,andV.Lempitsky. Domain-adversarialtraining ACMSIGKDDInternationalConferenceonKnowledgeDiscoveryand
ofneuralnetworks.TheJournalofMachineLearningResearch,17(1): DataMining,pages1135–1144,2016.
2096–2030,2016. [42] M.Z.Rodriguez,C.H.Comin,D.Casanova,O.M.Bruno,D.R.Aman-
[15] I.Goodfellow,Y.Bengio,andA.Courville.Deeplearning.MITpress, cio,L.d.F.Costa,andF.A.Rodrigues.Clusteringalgorithms:Acom-
2016. parativeapproach.PloSone,14(1):e0210236,2019.
[16] I.J.Goodfellow,J.Shlens,andC.Szegedy. Explainingandharnessing [43] E. Schubert, J. Sander, M. Ester, H. P. Kriegel, and X. Xu. Dbscan
adversarialexamples. InInternationalConferenceonLearningRepre- revisited,revisited:whyandhowyoushould(still)usedbscan. ACM
sentations,2014. TransactionsonDatabaseSystems(TODS),42(3):1–21,2017.
[17] A.Gretton,K.M.Borgwardt,M.J.Rasch,B.Schölkopf,andA.Smola. [44] J.ShiandJ.Malik. Normalizedcutsandimagesegmentation. IEEE
Akerneltwo-sampletest. TheJournalofMachineLearningResearch, Transactionsonpatternanalysisandmachineintelligence,22(8):888–
13(1):723–773,2012. 905,2000.
[18] C.Guo,G.Pleiss,Y.Sun,andK.Q.Weinberger.Oncalibrationofmod- [45] H.Shimodaira.Improvingpredictiveinferenceundercovariateshiftby
ernneuralnetworks.InInternationalConferenceonMachineLearning, weightingthelog-likelihoodfunction. JournalofStatisticalPlanning
pages1321–1330.PMLR,2017. andInference,90(2):227–244,2000.
[19] C.Guo,M.Rana,M.Cisse,andL.VanDerMaaten.Counteringadver- [46] M.Sugiyama,M.Krauledat,andK.-R.Müller. Covariateshiftadapta-
sarialimagesusinginputtransformations. InInternationalConference tionbyimportanceweightedcrossvalidation. TheJournalofMachine
onLearningRepresentations,2018. LearningResearch,8:985–1005,2007.
[20] D. Hendrycks and T. Dietterich. Benchmarking neural network ro- [47] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Good-
bustness to common corruptions and perturbations. arXiv preprint fellow, and R. Fergus. Intriguing properties of neural networks. In
arXiv:1903.12261,2019. InternationalConferenceonLearningRepresentations,2013.
[21] D.HendrycksandK.Gimpel. Abaselinefordetectingmisclassified [48] M.WangandW.Deng.Deepvisualdomainadaptation:Asurvey.Neu-
andout-of-distributionexamplesinneuralnetworks. InInternational rocomputing,312:135–153,2018.
ConferenceonLearningRepresentations,2017. [49] T.Wolf,L.Debut,V.Sanh,J.Chaumond,C.Delangue,A.Moi,P.Cis-
[22] D.Hendrycks,S.Basart,N.Mu,S.Kadavath,F.Wang,E.Dorundo, tac, T. Rault, R. Louf, M. Funtowicz, J. Davison, S. Shleifer, P. von
R.Desai,T.Zhu,S.Parajuli,M.Guo,etal. Themanyfacesofro- Platen,C.Ma,Y.Jernite,J.Plu,C.Xu,T.L.Scao,S.Gugger,M.Drame,
bustness: A critical analysis of out-of-distribution generalization. In Q.Lhoest,andA.M.Rush. Huggingface’stransformers:State-of-the-
ProceedingsoftheIEEE/CVFinternationalconferenceoncomputervi- artnaturallanguageprocessing,2020.
sion,pages8340–8349,2021. [50] B.Wu,C.Xu,X.Dai,A.Wan,P.Zhang,Z.Yan,M.Tomizuka,J.Gon-
[23] A.K.Jain.Dataclustering:50yearsbeyondk-means.Patternrecogni- zalez,K.Keutzer,andP.Vajda.Visualtransformers:Token-basedimage
tionletters,31(8):651–666,2010. representationandprocessingforcomputervision,2020.
[24] D.Jiang,C.Tang,andA.Zhang. Clusteranalysisforgeneexpression [51] D.XuandY.Tian. Acomprehensivesurveyofclusteringalgorithms.
data:Asurvey.IEEETransactionsonknowledgeanddataengineering, AnnalsofDataScience,2(2):165–193,2015.
16(11):1370–1386,2004. [52] B.ZadroznyandC.Elkan. Transformingclassifierscoresintoaccu-
[25] S.C.Johnson. Hierarchicalclusteringschemes. Psychometrika,32(3): ratemulticlassprobabilityestimates.InProceedingsoftheeighthACM
241–254,1967. SIGKDDInternationalConferenceonKnowledgeDiscoveryandData
[26] A. Kendall and Y. Gal. What uncertainties do we need in bayesian Mining,pages694–699,2002.