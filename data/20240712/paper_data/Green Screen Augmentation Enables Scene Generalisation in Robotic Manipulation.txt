Green Screen Augmentation Enables Scene
Generalisation in Robotic Manipulation
EugeneTeoh1,∗,SumitPatidar1,∗,XiaoMa1,StephenJames1
1DysonRobotLearningLab,∗EqualContribution
greenaug.github.io
Abstract:Generalisingvision-basedmanipulationpoliciestonovelenvironments
remainsachallengingareawithlimitedexploration.Currentpracticesinvolvecol-
lectingdatainonelocation,trainingimitationlearningorreinforcementlearning
policies with this data, and deploying the policy in the same location. However,
this approach lacks scalability as it necessitates data collection in multiple lo-
cations for each task. This paper proposes a novel approach where data is col-
lectedinalocationpredominantlyfeaturinggreenscreens. WeintroduceGreen-
screenAugmentation(GreenAug),employingachromakeyalgorithmtooverlay
backgroundtexturesontoagreenscreen. Throughextensivereal-worldempirical
studies with over 850 training demonstrations and 8.2k evaluation episodes, we
demonstratethatGreenAugsurpassesnoaugmentation,standardcomputervision
augmentation,andpriorgenerativeaugmentationmethodsinperformance. While
noalgorithmicnoveltiesareclaimed,ourpaperadvocatesforafundamentalshift
indatacollectionpractices. Weproposethatreal-worlddemonstrationsinfuture
research should utilise green screens, followed by the application of GreenAug.
WebelieveGreenAugunlockspolicygeneralisationtovisuallydistinctnovello-
cations,addressingthecurrentscenegeneralisationlimitationsinrobotlearning.
Keywords: GreenScreen,DataAugmentation,LearningfromDemonstration
#1 #1
…
#1
#N #N
…
GreenAug
#1 #1
…
#M
#N #N
…
Figure 1: GreenAug provides a simple visual augmentation to robot policies by first collecting
data with a green screen, then augmenting it with different textures. The resulting policy can be
transferredtounseenvisuallydistinctnovellocations(scenes).
4202
luJ
01
]OR.sc[
1v86870.7042:viXra
…
…
…
…
…
…1 Introduction
Recentadvancementsinrobotlearningpolicies[1,2,3,4,5,6,7]haveshownsignificantcapabilities
in performing complex manipulation tasks. However, generalising these policies to new locations
remains a substantial challenge due to the lack of diverse training datasets. Ideally, these datasets
shouldincludeawidevarietyofenvironments,suchasdiverseareasofhomes. However,gathering
real-worlddatafromdifferentscenesisdifficultandcostly. Thesescenesrefertovisuallydistinct
physicallocations,suchasanovensituatedindifferentkitchensoratoiletplacedinvarioushomes.
Thedifficultyofcollectingdiversedatanecessitatesmoreefficientuseofexistingdatasets.
Generative augmentation approaches [8, 9, 10] have attempted to address this by using generative
models [11, 12, 13] to augment robot datasets. However, these methods often require extensive
manualtuningandfaceseveralchallenges.Thisincludestextpromptengineering,chainingmultiple
objectdetectors,segmentersandgenerativemodels,andproblemswithperformanceandprocessing
speed. Additionally, they can be inaccurate in robotic settings—particularly in segmentation and
inpaintingfromwristcameraviews,potentiallyintroducingnoiseintorobotpolicies.
Inlightofthesecomplications,weoptforasimpleryeteffectivealternative:greenscreens.Thefilm
industryhasutilisedgreenscreensextensively[14,15,16,17,18],enablingtheadditionofvirtual
backgrounds to live footage. Inspired by these applications, we apply green screen technology to
robotics,allowingrobotstoperformtasksinunfamiliarscenesnotpartofthetrainingdemonstration
data.
In this paper, we introduce Green-screen Green Screen Data Mask
Augmentation (GreenAug), a simple real-
world visual augmentation method that uses
green screen and chroma keying to replace
Chroma Key
backgrounds, applicable to RGB-based robot
learning methods. We explore several variants
ofGreenAug,includingtheuseofrandomtex-
tures (Fig. 1), backgrounds generated by gen-
erativemodels,andabackgroundmaskingnet-
work to obscure the background during infer-
ence. By replacing backgrounds with various GreenAug-Rand GreenAug-Gen GreenAug-Mask
textures, itallowsrobotlearningpoliciestobe
robustagainstchangesinvisualscenesandfo- Figure2: TheGreenAugprocessbeginswithac-
cusoncrucialfeaturesintheimagespace. quiring a green screen mask using chroma key-
ing. GreenAug-Rand applies random textures,
We conducted extensive real-world experi- GreenAug-Genusesgenerativemodelstoinpaint
ments across eight challenging robotic manip- the background, and GreenAug-Mask learns a
ulationtasksandsixfurtherstudies,amounting maskingnetworktofilteroutthebackground.
to over 850 training demonstrations and 8.2k evaluation episodes. We evaluated the performance
of control policies in unseen scenes for head-to-head comparisons on scene generalisation. We
compared several variants of GreenAug against approaches with no augmentation, standard com-
putervisionaugmentations,andagenerativeaugmentation[8,9,10]method. Ourresultsshowthat
GreenAugoutperformsnoaugmentationby65%, standardcomputervisionaugmentationby29%
andgenerativeaugmentationby21%.
2 RelatedWork
Visual augmentation in robotics. Visual augmentation is important in robotics for adapting to
changingenvironments. Standardcomputervisionaugmentationslikerandomphotometricdistor-
tion, cropping, shifting, convolutions and overlays have enhanced performance in imitation learn-
ing [19, 20] and reinforcement learning [1, 21, 2, 22, 23, 24]. However, most of these methods
only apply simple photometric perturbations. Domain randomisation [25, 26, 27, 28, 29, 30, 31]
enhancesthisbygeneratingsyntheticdatawithvariedvisualandphysicaldynamicsparametersfor
2simulation-to-reality(Sim2Real)transfer. Alternatively,methodslikeCACTI[8],GenAug[9],and
ROSIE[10]usegenerativemodelssuchasStableDiffusion[12]todiversifyvisualdatadirectlyon
real-worlddata,bypassingtheneedforsimulation.
Greenscreeninmachinelearningandrobotics. Greenscreenhasbeentraditionallyusedforfilm
and video production [14, 15, 16, 17, 18]. In recent years, its application in machine learning has
increased. Smirnov et al. [18] applied machine learning to improve the quality of chroma keying.
Xu et al. [32], Sengupta et al. [33], Lin et al. [34, 35] explored machine learning techniques to
replacegreenscreens,enablingnaturalimagemattingwithoutthem. Schu¨leinetal.[36]usedgreen
screensandchromakeyingtoreplacebackgroundswithclinicalscenestocreatesyntheticdatafor
medical clothing detection. In robotics, the use of green screens remains limited. Coates and Ng
[37]employedittodevelopamulti-cameraobjectdetectorwithsyntheticdatafromchroma-keyed
backgrounds.
3 GreenScreenAugmentation
Inthissection,weprovideadetailedintroductiontoGreenAug. ThepracticalstepsforGreenAug
areasfollows:(1)GreenScreenSceneSetup;(2)GreenAugviaChromaKeying;(3)TrainingRobot
LearningPolicies. Inthefollowingsub-sections,weexpandoneachofthesestages.
3.1 GreenScreenSceneSetup
Standard Green Screen Augmented
Theactofscenesetupconsistsofob-
scuringthebackground(i.e. non-task
relevantobjects)withagreenscreen.
There are several ways of achieving
this, two of which are highlighted in
Fig.3anddescribedbelow. Oncethe
scenehasbeensetup,demonstration
collectioncanbegin.
ScenetoGreenScreen,whereaper-
manent green screen area or room is
established, and items can be moved Figure3:Physicalstepsforgreen-screensetup.Sceneitems
intothegreenscreenfordatacollec- can either be moved into the green screen, or the green
tion. This is the most common use screencanbebroughttothescene.
caseandincludestaskssuchasgeneralpick-and-place,openingdrawers,sweeping,pushing,etc.
GreenScreentoScene,wherethegreenscreenisbroughttoafixed,unmovableobject.Scenesthat
usuallyfallintothiscategoryareonesthatrequiremanipulatingintegratedorheavyobjects,suchas
stackingdishwashers,openingovens,andopeningdoors.
3.2 GreenAugviaChromaKeying
Chromakeyingisavisualeffectstechniqueforlayeringtwoimagesorvideostreamstogetherbased
on colour hues (chroma range). This technique is commonly used in video production and post-
productiontocompositetwoframesorimagestogetherbyremovingabackgroundcolour(usually
greenorblue)fromtheforegroundcontent,makingittransparent. Thisallowsfortheinsertionof
a new background or visual element in place of the green or blue background. Many chroma key
algorithmsexist,butweoptforasimplealgorithmproposedbyCannon[38]. Giventhegenerated
mask,severaloptionsareavailableforapplyingGreenAug.WeprovidethreevariantsofGreenAug:
Random(GreenAug-Rand),Generative(GreenAug-Gen)andMask(GreenAug-Mask),illustrated
inFig.2anddescribedindetailbelow.
GreenAug-Rand This variant applies a fixed set of random textures to the chroma-keyed back-
ground. Following research in domain randomisation [25, 26, 27, 28, 29, 30, 31], increasing the
3
ot
enecS
neercS
neerG
neercS
neerG
enecS
otTable1: Mainexperimentresultsaveragedacrossthreenovelscenes. Eachtask-methodcombina-
tionisevaluatedwith112evaluationepisodesonaverage. Fulldetailedresultsareprovidedinthe
Appendix.
SuccessRate(%)
Generative GreenAug GreenAug GreenAug
Task NoAug CVAug
Augmentation Rand Gen Mask
OpenDrawer 59 65 77 96 87 79
PlaceCubeinDrawer 36 69 70 92 83 37
TakeLidoffSaucepan 67 81 77 88 73 71
SweepCoffeeBeans 66 78 75 96 81 84
PlaceJeansinBasket 71 75 76 87 77 67
PlaceBearinBasket 45 63 61 95 49 41
StackCups 49 59 77 81 72 55
SlideBookandPickUp 49 74 89 93 93 35
Average 55 70 75 91 77 58
variabilityofthesetextureshelpsthepolicyignorethebackgroundandfocusontask-specificitems
(objectsmanipulatedbythepolicy).
GreenAug-Gen. This variant uses the chroma-keyed mask to inpaint realistic or imagined back-
groundsusinggenerativemodelslikeStableDiffusion. Examplesofpromptsinclude: “photoreal-
istic bedroom”, “photorealistic kitchen”, “photorealistic living room”. This method augments the
imagewithsemanticbackgrounds,aimingtocloselyresemblereal-worldscenarios.
GreenAug-Mask.Thisvariantusesamasking(softsegmentation)networktrainedtopredictmasks.
Thesepredictedmasksarethenappliedtotheimageobservationstoobtainblacked-out,darkback-
grounds. Thissimplificationofthevisualinputpotentiallyhelpsthevisuomotorpoliciestofocuson
themainelementsofinterestbyeliminatingbackgroundnoiseanddistractions. Duringtraining,the
maskingnetworkprocessesimagesagainstchroma-keyedbackgroundswithrandomtextures(akin
toGreenAug-Rand)andlearnstopredictthemasksgeneratedthroughchromakeying.
3.3 TrainingRobotLearningPolicies
GreenAugcanbeappliedtoRGB-basedrobotlearningmethods. Similartostandardaugmentation
methods, images can be transformed with GreenAug and fed into policy networks during train-
ing, or they can be preprocessed offline and then used for training. Offline preprocessing is more
common due to the longer computation time of some GreenAug variants. However, in online set-
tingssuchasreinforcementlearning,onlinetransformationsarealsoeffective.GreenAug-Randand
GreenAug-Genalloweachrawframefromthetrainingdemonstrationstobeaugmentedwithdiffer-
enttextures,significantlyincreasingtheamountofpreprocesseddata. Incontrast,GreenAug-Mask
onlymasksthebackgroundandprovidesasinglesolution. Toensureafaircomparison,wekeepthe
numberofpreprocessedframesequaltothenumberofrawframesforallmethods.
In our main experiment (Section 4.3), we chose Action Chunking with Transformers (ACT) [4]
asourcontrolvariabletodemonstratetheeffectivenessofthisaugmentationmethod. Weselected
ACTbecauseofitsrecentsuccessinadaptingbehavioursfromamodestnumberofdemonstrations,
makingitanidealplatformtoshowcasethebenefitsofGreenAug. Additionally,inSection4.4,we
demonstratethatGreenAug-Randisalsoeffectivewithareinforcementlearningpolicy.
4 Experiments
In this section, we present the experiments to evaluate the effectiveness of GreenAug on robot
learning policies. Prior works [20, 39] have confirmed the effectiveness of background and tex-
ture randomisation in simulation. Since GreenAug focuses on real-world data augmentation, our
experimentsareconductedexclusivelyintherealworld. Weaimtostudythefollowing: (1)Does
4GreenAug improvevisualgeneralizationtounseen scenes? (2)Whichvariantof GreenAug isthe
mosteffective, andwhatarethetradeoffs? (3)IsGreenAugapplicableindifferentdatacollection
settings? (4)IsGreenAugagnostictorobotembodimentsandlearningmethods?
4.1 Baselines
WeimplementseveralbaselinestocomparewithGreenAug,asdescribedbelow.
Noaugmentation(NoAug). Novisualaugmentation.
ComputerVisionaugmentation(CVAug). Randomphotometricdistortionsandrandomshift.
Generativeaugmentation.Generativeaugmentationencompassesabroaderrangeofmethodssuch
asCACTI[8],GenAug[9],andROSIE[10]. CACTIusesStableDiffusionforinpaintingbutdoes
not detail the method for obtaining object masks. GenAug, on the other hand, is constrained to
a tabletop setting. ROSIE relies on proprietary models and does provide publicly available code.
Thus, we have developed our own implementation that closely aligns with these methods. Our
implementation is based on Grounding DINO [40] for open vocabulary object detection, Segment
Anything[41]forzero-shotsegmentation,andStableDiffusionTurbo[12,13]forinpainting,inte-
gratedwithControlNet[42]andconditionedonDPT-Hybrid[43](monoculardepthestimator)for
better generation. Generative augmentation is similar to GreenAug-Gen, but it uses object detec-
tion and segmentation for mask creation instead of chroma keying. The pseudocode detailing this
implementationisoutlinedintheAppendix.
4.2 Setup
Standard Green Screen Augmented
For our main experiment, we de-
signed eight tasks (illustrated in
Fig. 7) and structured our experi-
mentsforeachtaskasfollows.
Data collection. We collected two
sets of demonstrations, each con-
sisting of 50 demos. One set
was recorded against a green screen
(Scene1),andtheotherwithinastan-
dardsetting(Scene2). Alldatawere
Figure4: Visualisationsoftrainandtestscenes.
collectedusingaleader-followertele-
operationsystem,similartoALOHA[4],butwitha7-DoFFrankaPandaarmsanda2F-140Robotiq
gripperonthefollower.WeusedthreeD415Realsensecameras,positionedattheupperwrist,lower
wristandleftshouldercamera.Theimagesarecapturedataresolutionof240(height)x320(width)
pixels. Forthemainexperimentsalone,wecollectedover800demonstrationsandconductedmore
than 6.6k evaluation runs. Additionally, we gathered about 50 more training demonstrations and
1.6kevaluationsfortheablationandfurtherstudiesinSection4.4.
Training. We trained all baselines and our methods on both sets of data, except for GreenAug,
which was excluded from Scene 2 as it relies on the green screen. Each data set corresponds to a
separatepolicy. ACTisusedasthecontrolpolicyforourmainexperiments.
Evaluation. InadditiontoScenes1and2,weevaluatedthemethodsinthreenovelscenes(Scenes
3–5). Initially, eachmethodwasassessedinScene1toestablishanupper-boundperformancefor
the task. Subsequently, the methods were evaluated in Scene 3–5 to test generalisation. For each
combinationoftask,method,trainscenes(2),testscenes(3),weperformed25evaluationruns.
Each scene is shown in Fig. 4. To focus on testing visual generalisation across different scenes,
we maintained the positions and orientations of the objects (while applying the same degree of
randomisationforone-to-onecomparison)relativetotherobotwhilemovingbetweenscenes.
5
ot
enecS
neercS
neerG
neercS
neerG
enecS
otTable2: ProcessingtimeperRGBframe. Table3: GreenAug-RandappliedtoRL.
Method Time(↓) SuccessRate(%)
GenerativeAugmentation 2.530s Train Test GreenAug
NoAug
GreenAug-Rand 0.009s Scene Scene Rand
GreenAug-Gen 0.882s
Green 1Novel
12 64
Screen Scene
Table 4: GreenAug-Rand with different texture Table 5: Object generalisation results. Policies
types averaged across tasks and novel scenes. trained on a green cup were tested on other ob-
Entropysignifiestheamountoftexturerandom- jects. (n) specifies the number of objects tested
ness. inthecategory.
Entropy Success SuccessRate(%)
TextureType
(bits) Rate(%)
Object GreenAug GreenAug
NoAug
None - 48 Category Rand Gen
SolidColours 0.00 65
Cups(3) 95 83 80
PerlinNoise 4.45 66
Cans(2) 38 46 40
MILTextures 6.81 87
Cubes(2) 0 32 52
SoftToy(1) 0 84 72
4.3 Results Average 45 61 62
Table1presentsourexperimen-
talfindings. Theresultsdemon-
stratethatGreenAug-Randsur-
passes all other baseline meth-
ods across all tasks. Specif-
ically, GreenAug-Rand shows
approximately a 65% improve-
ment over NoAug, around a
29% improvement compared to
CVAug, and about a 21% im-
Figure 5: Visualisations of raw and preprocessed frames (left
provement over generative aug-
shoulder and lower wrist camera views) of generative aug-
mentation.
mentation, GreenAug-Gen and GreenAug-Mask (during infer-
Surprisingly, GreenAug-Gen ence). Both generative methods struggle with producing good
and generative augmentation contextual wrist camera inpainting. In generative augmenta-
tion, the gripper is inpainted as part of the background, while
rank second and third in per-
GreenAug-Maskshowsmaskingartefactsinnovelscenes.
formance respectively, despite
using semantically meaningful
backgrounds like living rooms or kitchens. As expected, both methods perform similarly, since
they differ only in how they obtain background masks (object detection and segmentation). This
suggests that specific semantic content is not crucial for GreenAug’s success, as the variant using
randombackgroundsperformsevenbetter. Thissuperiorperformancemayhaveresultedfromthe
widervarietyofcoloursandtexturesofferedbytherandombackgrounds.
Generative augmentation performs slightly worse than GreenAug-Gen, likely because it struggles
to provide good masks in wrist camera views (illustrated in Fig. 5), which are essential for tasks
requiringpreciseandstablevisualinput. Despiteadvancementsingenerativemodels,segmentation
andinpaintingfromrobotcameraviewsremainsuboptimal.
GreenAug-Maskshowstheleasteffectivenessamongallmethodstested. Qualitativeevaluationsof
themaskedimagesrevealfrequentfailurestocompletelyobscurebackgrounds,especiallyinnovel
scenes (shown in Fig. 5). This issue stems from two main factors: the inherent imperfections in
ground truth masks obtained from chroma keying and the compounding error from the masking
network. Thenetwork’simperfectmaskingfurthercomplicatesthetasks, pushingtheimagesinto
out-of-distributionstatesthatchallengethecontrolpolicy.
6(a) (b)
Figure6:(a)GreenAug-Randperformsthebestwhenappliedtoallframespertrajectory.(b)Visual
assessment of applying GreenAug to a single shade of green, in scenarios where multiple objects
withvaryingshadesofgreenarepresent. Maskedobjectshavetheirbackgroundsblackedout.
4.4 AblationandFurtherStudies
Basedonthemainexperiments,wedemonstratedthatGreenAug-Randoutperformsallothermeth-
ods. Wethenconductedthefollowingin-depthanalyses.
BenchmarkingGreenAug’sspeed.Weconductedabenchmarktocomparetheprocessingspeedof
variousmethods,showninTable2.CVAugandGreenAug-Maskwereexcludedbecausetheformer
isappliedontheflyduringtraining,andthelatterperformspoorly. WeshowthatGreenAug-Rand
issignificantlyfasterthantheothertwogenerativemethods.
ApplyingGreenAugtoadifferentrobotwithreinforcementlearning. Weinvestigatedwhether
GreenAugcanbeappliedtoadifferentrobotembodimentandlearningmethod,beyondtheFranka
PandaandACT.Wesetupasimilar“takelidoffsaucepan”taskonaUR5. Weusedacontinuous
demo-driven DQN variant [44, 45, 46, 47] with actions discretised into bins. The robot was pro-
videdwith24demonstrationsandwasgivenasparserewardof0forfailureand1forsuccess. We
trained the robot online with 20 minutes of exploration on a green screen background and evalu-
atedtwopolicies,NoAugandGreenAug-Rand,inonenovelscene. Theresults,showninTable3
demonstratethatGreenAug-Randappliedtoreinforcementlearningwithadifferentrobotperforms
significantlybetterthanNoAug.
Impactoftexturerandomness. WeinvestigatedhowthetexturerandomnessofGreenAug-Rand
affects performance. We tested solid colours, Perlin noise (procedurally generated textures) [48],
andMILtextures(usedinthemainexperiments). Alltexturedatasetsareofthesamesize(5771).
The evaluation was conducted on the “put cube in drawer” and “stack cups” tasks from the main
experimentacrossthreenovelscenes(Scenes3–5). Table4summarisestheresults. Consistentwith
domain randomization studies [25, 26, 27, 28, 29, 31], greater texture randomness leads to better
performance. ExamplesofeachtexturetypeareprovidedintheAppendix.
Generalisationacrossobjectcategory. WeassessedifGreenAugcanbeappliednotjusttoback-
grounds but also to different object categories. We set up a simple pick-and-place task. We first
trainedonagreencupandthentestedonothervisuallydifferentobjects. Theresults,showninTa-
ble5,indicatethatGreenAug-Genperformsbest,withonlya1%differencefromGreenAug-Rand.
BothmethodsoutperformNoAugbymorethan35%. NoAugperformswelloncupsbutfailswith
cubesandsofttoys,andoccasionallyworkswithcansduetotheirsimilargeometricshapestocups.
GreenAug-Rand and GreenAug-Gen show better performance across different object categories,
demonstratingsomelevelofgeneralisation. However,performancewithcupssuffersslightly,likely
duetothestrongaugmentationcausingconfusionaboutgeometricshapes.
Greenscreencoverage. Inreal-worldsettings,someframesintherobotdatamaymoveawayfrom
thegreenscreenduringrobotservoing. Forexample,ifthegreenscreenisonlypartiallysetupin
7Figure 7: Visualisations of real-world tasks. The trajectory sequences are stacked horizontally,
startingwiththeinitialpositionslabelledas#0.
the scene, the robot may observe parts of the scene not covered by the green screen. To emulate
thisscenario,weappliedGreenAug-Randtovaryingpercentagesofframesperepisode. Thiswas
evaluatedonthesametasksasthetexturerandomnessstudy. TheresultsaresummarisedinFig.6a.
Asexpected,greenscreencoverageisproportionaltothesuccessrate.
Presence of multiple green objects. Green screens could affect scenes when there are multiple
greenobjects.Weevaluatedthesensitivityofchromakeyingundertheseconditions,achallengealso
encounteredinthefilmindustry.Thisstudyquestionswhetherchromakeyingcaneffectivelyisolate
one green object without impacting others. We conducted a visual assessment (shown in Fig. 6b)
and showed that we can augment only one object at a time while leaving the others unchanged.
Alternatively,onecanalsouseadifferentcoloursuchasblue(alongwithagreenbackground)for
chroma-keyingobjects.
5 ConclusionandLimitations
ThispaperproposesandinvestigatestheefficacyofGreenAuginroboticmanipulationacrossavari-
etyofreal-worldscenarios. WehavedemonstratedthatGreenAugnotonlyworkseffectivelyacross
different tasks but also surpasses other augmentation methods in performance while maintaining
simplicity. GreenAugoutperformsNoAugbyapproximately65%,CVAugby29%andgenerative
augmentation by about 21%. Our findings advocate for a paradigm shift in data collection prac-
ticesforrobotlearning. Weproposetheuseofgreenscreensforfuturereal-worlddemonstrations.
Implementing GreenAug could significantly improve policy generalisation across novel locations,
effectivelyaddressingscenegeneralisationlimitationscurrentlyfacedinthefield.
WhileGreenAugprovestobeuseful,severalchallengesremainthatwehaveoutlinedforfuturere-
search. GreenAugiseffectiveforbackgroundgeneralisationandtoanextent,objectgeneralisation
(asshowninfurtherstudies),butitfallsshortwhenitcomestoadaptingtoobjectswithverydiffer-
entgeometricshapes. Thistypeofgeneralisationinvolveschangingthedynamicsandtrajectories
ofthedemonstrations,suchasaccommodatingdifferentmugswithuniquehandlesthatrequirespe-
cificgraspingpoints. Furthermore,GreenAugcouldbecomplementarytogenerativeaugmentation.
This combination could help train world models capable of producing imaginary trajectories that
generaliseacrossdiverseobjectsandappliances.
8Acknowledgments
BigthankstothemembersoftheDysonRobotLearningLabfordiscussionsandinfrastructurehelp:
NicBackshall,IainHaughton,YounggyoSeo,SridharSola,JafarUruc,YunfanLu,AbdiAbdinur,
NikitaChernyadev.
References
[1] D.Yarats,I.Kostrikov,andR.Fergus. Imageaugmentationisallyouneed: Regularizingdeep
reinforcementlearningfrompixels. InInternationalconferenceonlearningrepresentations,
2020.
[2] D.Yarats,R.Fergus,A.Lazaric,andL.Pinto. Masteringvisualcontinuouscontrol: Improved
data-augmentedreinforcementlearning. arXivpreprintarXiv:2107.09645,2021.
[3] M. Shridhar, L. Manuelli, and D. Fox. Perceiver-actor: A multi-task transformer for robotic
manipulation. InConferenceonRobotLearning,pages785–799.PMLR,2023.
[4] T.Z.Zhao,V.Kumar,S.Levine,andC.Finn. LearningFine-GrainedBimanualManipulation
withLow-CostHardware. InProceedingsofRobotics: ScienceandSystems,Daegu,Republic
ofKorea,July2023. doi:10.15607/RSS.2023.XIX.016.
[5] C.Chi,S.Feng,Y.Du,Z.Xu,E.Cousineau,B.C.Burchfiel,andS.Song. DiffusionPolicy:
Visuomotor Policy Learning via Action Diffusion. In Proceedings of Robotics: Science and
Systems,Daegu,RepublicofKorea,July2023. doi:10.15607/RSS.2023.XIX.026.
[6] X. Ma, S. Patidar, I. Haughton, and S. James. Hierarchical diffusion policy for kinematics-
awaremulti-taskroboticmanipulation. arXivpreprintarXiv:2403.03890,2024.
[7] V. Vosylius, Y. Seo, J. Uruc¸, and S. James. Render and diffuse: Aligning image and action
spacesfordiffusion-basedbehaviourcloning. arXivpreprintarXiv:2405.18196,2024.
[8] Z. Mandi, H. Bharadhwaj, V. Moens, S. Song, A. Rajeswaran, and V. Kumar. Cacti:
A framework for scalable multi-task multi-scene visual imitation learning. arXiv preprint
arXiv:2212.05711,2022.
[9] Q. Chen, S. C. Kiami, A. Gupta, and V. Kumar. GenAug: Retargeting behaviors to unseen
situations via Generative Augmentation. In Proceedings of Robotics: Science and Systems,
Daegu,RepublicofKorea,July2023. doi:10.15607/RSS.2023.XIX.010.
[10] T.Yu,T.Xiao,J.Tompson,A.Stone,S.Wang,A.Brohan,J.Singh,C.Tan,D.M,J.Peralta,
K.Hausman,B.Ichter,andF.Xia. ScalingRobotLearningwithSemanticallyImaginedEx-
perience. InProceedingsofRobotics: ScienceandSystems, Daegu, RepublicofKorea, July
2023. doi:10.15607/RSS.2023.XIX.027.
[11] J.Sohl-Dickstein,E.Weiss,N.Maheswaranathan,andS.Ganguli. Deepunsupervisedlearn-
ingusingnonequilibriumthermodynamics. InInternationalconferenceonmachinelearning,
pages2256–2265.PMLR,2015.
[12] R.Rombach,A.Blattmann,D.Lorenz,P.Esser,andB.Ommer. High-resolutionimagesyn-
thesiswithlatentdiffusionmodels. InProceedingsoftheIEEE/CVFconferenceoncomputer
visionandpatternrecognition,pages10684–10695,2022.
[13] A.Sauer,D.Lorenz,A.Blattmann,andR.Rombach. Adversarialdiffusiondistillation. arXiv
preprintarXiv:2311.17042,2023.
[14] A.R.SmithandJ.F.Blinn.Bluescreenmatting.InProceedingsofthe23rdannualconference
onComputergraphicsandinteractivetechniques,pages259–268,1996.
9[15] A.Grundho¨fer, D.Kurz, S.Thiele, andO.Bimber. Colorinvariantchromakeyingandcolor
spill neutralization for dynamic scenes and cameras. The Visual Computer, 26:1167–1176,
2010.
[16] J.Foster. Thegreenscreenhandbook: real-worldproductiontechniques. Routledge,2014.
[17] Y. Aksoy, T. O. Aydin, M. Pollefeys, and A. Smolic´. Interactive high-quality green-screen
keyingviacolorunmixing. ACMTransactionsonGraphics(TOG),36(4):1,2016.
[18] D. Smirnov, C. LeGendre, X. Yu, and P. Debevec. Magenta green screen: Spectrally multi-
plexedalphamattingwithdeepcolorization. InProceedingsoftheDigitalProductionSympo-
sium,pages1–13,2023.
[19] S. Young, D. Gandhi, S. Tulsiani, A. Gupta, P. Abbeel, and L. Pinto. Visual imitation made
easy. InConferenceonRobotLearning,pages1992–2005.PMLR,2021.
[20] A.Xie,L.Lee,T.Xiao,andC.Finn.Decomposingthegeneralizationgapinimitationlearning
forvisualroboticmanipulation. arXivpreprintarXiv:2307.03659,2023.
[21] M. Laskin, K. Lee, A. Stooke, L. Pinto, P. Abbeel, and A. Srinivas. Reinforcement learning
with augmenteddata. Advances inneural informationprocessing systems, 33:19884–19895,
2020.
[22] N.Hansen, H.Su, andX.Wang. Stabilizingdeepq-learningwithconvnetsandvisiontrans-
formers under data augmentation. Advances in neural information processing systems, 34:
3680–3693,2021.
[23] N.HansenandX.Wang. Generalizationinreinforcementlearningbysoftdataaugmentation.
In 2021 IEEE International Conference on Robotics and Automation (ICRA), pages 13611–
13617.IEEE,2021.
[24] A.Almuzairee,N.Hansen,andH.I.Christensen. Arecipeforunboundeddataaugmentation
invisualreinforcementlearning. arXivpreprintarXiv:2405.17416,2024.
[25] F. Sadeghi and S. Levine. Cad2rl: Real single-image flight without a single real image. In
Proceedings of Robotics: Science and Systems, Cambridge, Massachusetts, July 2017. doi:
10.15607/RSS.2017.XIII.034.
[26] J.Tobin, R.Fong, A.Ray, J.Schneider, W.Zaremba, andP.Abbeel. Domainrandomization
for transferring deep neural networks from simulation to the real world. In 2017 IEEE/RSJ
internationalconferenceonintelligentrobotsandsystems(IROS),pages23–30.IEEE,2017.
[27] S.James,A.J.Davison,andE.Johns. Transferringend-to-endvisuomotorcontrolfromsim-
ulationtorealworldforamulti-stagetask. InConferenceonRobotLearning,pages334–343.
PMLR,2017.
[28] J. Matas, S. James, and A. J. Davison. Sim-to-real reinforcement learning for deformable
objectmanipulation. ConferenceonRobotLearning,2018.
[29] S. James, P. Wohlhart, M. Kalakrishnan, D. Kalashnikov, A. Irpan, J. Ibarz, S. Levine,
R.Hadsell,andK.Bousmalis. Sim-to-realviasim-to-sim: Data-efficientroboticgraspingvia
randomized-to-canonicaladaptationnetworks.InProceedingsoftheIEEE/CVFconferenceon
computervisionandpatternrecognition,pages12627–12637,2019.
[30] R.AlghonaimandE.Johns.Benchmarkingdomainrandomisationforvisualsim-to-realtrans-
fer.In2021IEEEInternationalConferenceonRoboticsandAutomation(ICRA),pages12802–
12808.IEEE,2021.
10[31] J.So,A.Xie,S.Jung,J.Edlund,R.Thakker,A.Agha-mohammadi,P.Abbeel,andS.James.
Sim-to-realviasim-to-seg: End-to-endoff-road autonomousdrivingwithoutreal data. Con-
ferenceonRobotLearning,2022.
[32] N.Xu, B.Price, S.Cohen, andT.Huang. Deepimagematting. InProceedingsoftheIEEE
conferenceoncomputervisionandpatternrecognition,pages2970–2979,2017.
[33] S.Sengupta,V.Jayaram,B.Curless,S.M.Seitz,andI.Kemelmacher-Shlizerman.Background
matting: The world is your green screen. In Proceedings of the IEEE/CVF Conference on
ComputerVisionandPatternRecognition,pages2291–2300,2020.
[34] S.Lin,A.Ryabtsev,S.Sengupta,B.L.Curless,S.M.Seitz,andI.Kemelmacher-Shlizerman.
Real-timehigh-resolutionbackgroundmatting. InProceedingsoftheIEEE/CVFConference
onComputerVisionandPatternRecognition,pages8762–8771,2021.
[35] S. Lin, L. Yang, I. Saleemi, and S. Sengupta. Robust high-resolution video matting with
temporal guidance. In Proceedings of the IEEE/CVF Winter Conference on Applications of
ComputerVision,pages238–247,2022.
[36] P.Schu¨lein, H.Teufel, R.Vorpahl, I.Emter, Y.Bukschat, M.Pfister, N.Rathmann, S.Diehl,
and M. Vetter. Comparison of synthetic dataset generation methods for medical intervention
roomsusingmedicalclothingdetectionasanexample. EURASIPJournalonImageandVideo
Processing,2023(1):12,2023.
[37] A. Coates and A. Y. Ng. Multi-camera object detection for robotics. In 2010 IEEE Interna-
tionalconferenceonroboticsandautomation,pages412–419.IEEE,2010.
[38] E.Cannon. Greenscreencodeandhints. http://gc-films.com/chromakey.html,2011.
[Accessed15-01-2024].
[39] W.Pumacay,I.Singh,J.Duan,R.Krishna,J.Thomason,andD.Fox.Thecolosseum:Abench-
markforevaluatinggeneralizationforroboticmanipulation.arXivpreprintarXiv:2402.08191,
2024.
[40] S.Liu,Z.Zeng,T.Ren,F.Li,H.Zhang,J.Yang,C.Li,J.Yang,H.Su,J.Zhu,etal.Grounding
dino: Marryingdinowithgroundedpre-trainingforopen-setobjectdetection. arXivpreprint
arXiv:2303.05499,2023.
[41] A. Kirillov, E. Mintun, N. Ravi, H. Mao, C. Rolland, L. Gustafson, T. Xiao, S. Whitehead,
A.C.Berg,W.-Y.Lo,etal. Segmentanything. InProceedingsoftheIEEE/CVFInternational
ConferenceonComputerVision,pages4015–4026,2023.
[42] L. Zhang, A. Rao, and M. Agrawala. Adding conditional control to text-to-image diffusion
models.InProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision,pages
3836–3847,2023.
[43] R.Ranftl,A.Bochkovskiy,andV.Koltun. Visiontransformersfordenseprediction. InPro-
ceedingsoftheIEEE/CVFinternationalconferenceoncomputervision,pages12179–12188,
2021.
[44] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G. Bellemare, A. Graves,
M. Riedmiller, A. K. Fidjeland, G. Ostrovski, et al. Human-level control through deep rein-
forcementlearning. nature,518(7540):529–533,2015.
[45] T.Seyde,P.Werner,W.Schwarting,I.Gilitschenski,M.Riedmiller,D.Rus,andM.Wulfmeier.
Solvingcontinuouscontrolviaq-learning. arXivpreprintarXiv:2210.12566,2022.
[46] P.J.Ball,L.Smith,I.Kostrikov,andS.Levine. Efficientonlinereinforcementlearningwith
offline data. In International Conference on Machine Learning, pages 1577–1594. PMLR,
2023.
11[47] J.Farebrother,J.Orbay,Q.Vuong,A.A.Ta¨ıga,Y.Chebotar,T.Xiao,A.Irpan,S.Levine,P.S.
Castro,A.Faust,etal. Stopregressing: Trainingvaluefunctionsviaclassificationforscalable
deeprl. arXivpreprintarXiv:2403.03950,2024.
[48] K.Perlin. Animagesynthesizer. ACMSiggraphComputerGraphics,19(3):287–296,1985.
[49] C. Finn, T. Yu, T. Zhang, P. Abbeel, and S. Levine. One-shot visual imitation learning via
meta-learning. InConferenceonrobotlearning,pages357–368.PMLR,2017.
[50] O. Ronneberger, P. Fischer, and T. Brox. U-net: Convolutional networks for biomedical im-
agesegmentation. InMedicalimagecomputingandcomputer-assistedintervention–MICCAI
2015: 18thinternationalconference,Munich,Germany,October5-9,2015,proceedings,part
III18,pages234–241.Springer,2015.
[51] P. Iakubovskii. Segmentation models pytorch. https://github.com/qubvel/
segmentation_models.pytorch,2019.
[52] S. Wright. Digital compositing for film and video: Production Workflows and Techniques.
Routledge,2017.
[53] H.Li,W.Zhu,H.Jin,andY.Ma.Automatic,illumination-invariantandreal-timegreen-screen
keyingusingdeeplyguidedlinearmodels. Symmetry,13(8):1454,2021.
[54] Y.Jin,Z.Li,D.Zhu,M.Shi,andZ.Wang. Automaticandreal-timegreenscreenkeying. The
VisualComputer,38(9):3135–3147,2022.
[55] S.James,K.Wada,T.Laidlow,andA.J.Davison.Coarse-to-fineq-attention:Efficientlearning
forvisualroboticmanipulationviadiscretisation.InProceedingsoftheIEEE/CVFConference
onComputerVisionandPatternRecognition,pages13739–13748,2022.
12A ExperimentSetups
In this section, we provide the detailed setups of our real-robot experiments to help reproduce the
results.
Robot Setup. The robot setup consists of a 7-DoF Franka Panda Emika arm equipped with a
Robotiq2F-140gripper. WeusethreeRealSenseD415cameras: twocamerasmountedontheend-
effector(lowerwrist,upperwrist)forawidefield-of-view,andonecamera(leftshoulder)fixedon
thebase,asdepictedinFig. 8a.
Datacollection. Wegatherdemonstrationsforourtasksutilisingaleader-followersetupsimilarto
ALOHA[4]. AnexperthumandemonstratormovestheLeaderarm,andtheFollowerarmmirrors
theLeader’sjointpositions,asshowninFig.8b. Cameraandrobotstateobservationsarerecorded
at30FPS.
Tasks.Foreachtask,wecollect50demonstrationseachattwoscenes:greenscreenroomandliving
room. Fig.9showsthetaskdefinitionswithsketchestoillustratethesetupwithmeasurementsand
randomisation. Foralltasks,theinitialrobotjointpositionsare[0.0,-0.785,0.0,-2.356,0.0,1.571,
0.0].
(a)Robotsetup. FrankaPandaArmismountedona (b)Leaderandfollowerrobotsetup.
VentionbasewiththreeRealsensecameras.Therobot
isabovethegroundby23cm. Therobotposeisrep-
resentedinthebaseframe,F .
R
13(a) Open Drawer: The robot base (F ) is uniformly randomised inside the 10cm×10cm region. The
R
gripperthenslidesintothesmalldraweropeningandthenpullsthedraweropen. Intotal,50demonstrations
arecollectedwithanaveragedemolengthof169stepsor13secs.
(b)PlaceCubeinDrawer: Therobotbase(F )isfixedrelativetothedrawer. Thecubeisrandomisedon
R
thedrawertopwithinthe32cm×10cmregion. Therobotpicksupthecubeandplacesitinsidetheopened
drawer.Atotalof50demonstrationsarecollectedwithanaveragedemolengthof250stepsor19secs.
(c)SweepCoffeeBeans: Therobotbase(F )isfixedrelativetothedrawer. Thedrawerusedisthesame
R
as in previous tasks but rotated by 90◦. We stick two black tapes on the drawer top. The coffee beans are
randomisedinthe24cm×24cmregionbetweenthetwotapes.Thespongepositionisrandomisedalongthe
tapeB(24cm). TherobotgraspsthespongeandsweepsthecoffeebeanstotheleftoftapeA.Atotalof50
demonstrationsarecollectedwithanaveragedemolengthof314stepsor24secs. Forevaluations,atrialis
consideredsuccessfulif90%ofbeansareswept. Weuse20beans,soatleast18beansneedstobesweptfor
success.
14(d)TakeLidoffSaucepan:Therobotbase(F )isfixedrelativetothedrawer.Thesaucepanisrandomizedin
R
theL-shapedregion. Therobotgraspsthelidofthesaucepanandalwaysplacesitintheorangearea. Intotal,
50demonstrationswerecollectedwithanaveragedemolengthof857steps.
(e)PlaceJeanstoBasket:Therobotbase(F )isfixedrelativetothelaundrybasket.Thejeansissemi-folded
R
andhangingontherightedgeofthechair.Thechairpositionisrandomisedinthe20cm×20cmregion.The
robotgraspsthejeansfromthesideandplacesitinthelaundrybasket. Wecollected50demonstrations, in
eachhalfofthedemonstrationsthechairpositionisrandomisedkeepingtheorientationAandintheotherhalf
theorientationofthechairremainedB.Theaveragelengthofthedemois592stepsor44secs.
(f)PlaceBearinBasket:Therobotbase(F )isfixedandthebear(toy)positionisrandomisedinthe46cm×
R
30cm region on the ground. For half of the demos, the randomisation is done in orientation A and for the
otherhalfinorientationB.Therobotfirstpicksupthetoyandplacesitinthebasketnearby. Wecollect50
demonstrationsintotalwithanaveragedemolengthof741stepsor56secs.
15(g) Stack Cups: The robot base (F ) is fixed relative to the drawer. The orange cup is randomised in the
R
10cm×32cmregionwhereasthebluecupisrandomisedalongtheblueline(32cm).Therobotfirstpicksup
theorangecupandstacksitonthebluecup. Intotal,50demonstrationsarecollectedwithanaveragedemo
lengthof590stepsor44secs.
(h)SlideBookandPickUp:Therobotbase(F )isfixedrelativetotheblackcoffeetable.Thebookposition
R
israndomisedinthe12cm×12cmregion. Inhalfofthedemonstrations,thebookorientationiskeptAand
intheotherhalf,orientationB.Therobotfirstcorrectsthebookorientationifnecessarybypushingonitsedge
andthenslidesthebooktotheedgeofthetable.Itthenpicksitupandplacesitintheareadepictedbyorange
(rightmostfigure).Wecollect50demonstrationsintotalwithanaveragedemolengthof930stepsor70secs.
(i)PlaceCupinDrawer(ObjectGeneralisation):Therobotbase(F )isfixedandthegreencuppositionis
R
randomisedinthe20cm×32cmregiononthedrawertop.Therobotfirstpicksupthecupandplacesitinthe
drawer.Wecollect50demonstrationsintotalwithanaveragedemolengthof597stepsor45secs.
Figure9: Taskdefinitionswithrandomisation. Weillustrate8maintasksand1ablationtaskwith
randomisation used. We used the images from the left shoulder (top row) and lower wrist camera
(bottom row) to describe each task sequence. Note that the sketches on the right are not drawn to
scale.
16Train Scene
#0 #1 #2
Test Scene
#0 #1 #2
Figure10: Reinforcementlearningexperimentsetup(“Takethelidoffsaucepan”). Theillustration
showstrainandtestscenesandthetasksequence. Inthetrainscene,agreenscreenclothcoversthe
table. Inthetestscene,theclothisremoved,anddistractorsareaddedaroundthetable. UR5robots
areusedforthisexperiment,withonlyupperandlowerwristcameras.
17B MoreVisualisations
Figure11: VisualobservationsofGreenAug-RandwithMILtextures[49]
Figure12: VisualobservationsofGreenAug-Randwithsolid&Perlintextures
18Figure13: VisualobservationsofGreenAug-Gen
19Figure14: VisualobservationsofGreenAug-Maskduringinference.
Open Drawer Place Cube in Drawer
Sweep Coffee Beans Take Lid off Saucepan
Place Jeans in Basket Place Bear in Basket
Stack Cups Slide Book and Pick Up
Figure15: Visualsofthree novelscenesused duringevaluationsfor eachtaskinrespective order.
Theseincludeasubsetofkitchen,washing,study,andlivingrooms.
20C ComputeandHyperparameterDetails
WeperformthepreprocessingandmodeltrainingusingNVIDIAL4GPUs(24GBVRAM).
ACT.WeusethesameimplementationofACTasdescribedintheoriginalpaper,withthefollowing
changes to hyperparameters: action chunking size is set to 20, the number of epochs is 5000, and
wesample16transitionsperepoch. UnliketheoriginalACTimplementation, whichsamplesone
transitionperepisodeperepoch,wesamplemultipletransitions.
Table6: Pre-processinghyperparametersforeachtask. Chromakeyparametersarerepresentedby
Key Colour (K) in hexadecimal colour codes, tola (α), and tolb (β). Detection Text Prompt is
usedforgenerativeaugmentation.InpaintTextPromptisusedforbothgenerativeaugmentationand
GreenAug-Genforbackgroundgeneration.
Task Key Colour tola tolb DetectionTextPrompt InpaintTextPrompt
(K) (α) (β)
OpenDrawer #439f82 30 35 drawer. robot arm. photorealistic
robot gripper. kitchen, study room,
washing room, living
room, or bedroom
PlaceCubeinDrawer #25806f 35 40 red cube. drawer. photorealistic
robot arm. robot kitchen, study room,
gripper. washing room, living
room, or bedroom
SweepCoffeeBeans #1d6953 23 30 sponge. coffee photorealistic
beans. black tapes. kitchen, study room,
drawer. robot arm. washing room, living
robot gripper. room, or bedroom
TakeLidoffSaucepan #348367 15 25 saucepan. drawer. photorealistic
robot arm. robot kitchen, study room,
gripper. washing room, living
room, or bedroom
PlaceJeansinBasket #25806f 30 40 jeans. chair. robot photorealistic
arm. robot gripper. kitchen, study room,
washing room, living
room, or bedroom
PlaceBearinBasket #25806f 30 30 soft toy. basket. photorealistic
robot arm. robot kitchen, study room,
gripper. washing room, living
room, or bedroom
StackCups #348367 15 25 blue cup. orange photorealistic
cup. drawer. robot kitchen, study room,
arm. robot gripper. washing room, living
room, or bedroom
SlideBookandPickUp #25806f 20 30 book. table. robot photorealistic
arm. robot gripper. kitchen, study room,
washing room, living
room, or bedroom
ObjectGeneralisation #699230 30 20 green cup. drawer. colourful cup, bowl,
robot arm. robot cube, toy, can,
gripper. bottle or general
graspable object
GreenAug-MaskU-Net. WeusetheoriginalU-Netarchitecture[50](implementedbyIakubovskii
[51])forthemaskingnetworkusedinGreenAug-Mask. Themodelcomprises14.3millionparam-
eters.
Table7: MaskingnetworkhyperparametersforGreenAug-Mask.
Model Unet
Encoder ResNet18
EncoderWeights ImageNet
Epochs 100
Batchsize 128
Imagesize 224×224
Seed 42
21D DetailedResults
Thissectionpresentsthefullunaggregatedresults.
Table 8: Full experiment results. “Green Screen→Green Screen” roughly represents the upper
bound performance (in parentheses) and is not included in the average. Full unaggregated results
foreachtaskareinTables9to16. Thetablesarealsohyperlinkedinthetasktextbelow.
SuccessRate(%)
Train Test Generative GreenAug GreenAug GreenAug
Task NoAug CVAug
Scene Scene Augmentation random generative mask
GreenScreen GreenScreen (100) (88) (96) (100) (100) (100)
OpenDrawer LivingRoom 3NovelScenes 63 51 57 - - -
GreenScreen 3NovelScenes 55 79 96 96 87 79
GreenScreen GreenScreen (92) (96) (72) (100) (84) (96)
PlaceCubeinDrawer LivingRoom 3NovelScenes 33 64 68 - - -
GreenScreen 3NovelScenes 39 73 72 92 83 37
GreenScreen GreenScreen (100) (96) (88) (96) (80) (92)
SweepCoffeeBeans LivingRoom 3NovelScenes 55 79 73 - - -
GreenScreen 3NovelScenes 77 77 77 96 81 84
GreenScreen GreenScreen (96) (84) (92) (80) (80) (84)
TakeLidoffSaucepan LivingRoom 3NovelScenes 61 79 72 - - -
GreenScreen 3NovelScenes 73 83 83 88 73 71
GreenScreen GreenScreen (100) (100) (92) (100) (100) (92)
PlaceJeansinBasket LivingRoom 3NovelScenes 69 73 75 - - -
GreenScreen 3NovelScenes 72 77 77 87 77 67
GreenScreen GreenScreen (100) (100) (100) 100 (96) (100)
PlaceBearinBasket LivingRoom 3NovelScenes 35 45 41 - - -
GreenScreen 3NovelScenes 55 80 81 95 49 41
GreenScreen GreenScreen (76) (84) (84) (88) (80) (80)
StackCups LivingRoom 3NovelScenes 41 57 75 - - -
GreenScreen 3NovelScenes 57 61 80 81 72 55
GreenScreen GreenScreen (100) (100) (100) (100) (100) (100)
SlideBookandPickUp LivingRoom 3NovelScenes 43 61 89 - - -
GreenScreen 3NovelScenes 55 87 89 93 93 35
Average 55 70 75 91 77 58
Table9: “OpenDrawer”taskunaggregatedresults.
SuccessRate(%)
Train Test Generative GreenAug GreenAug GreenAug
NoAug CVAug
Scene Scene Augmentation random generative mask
GreenScreen GreenScreen (100) (88) (96) (100) (100) (100)
NovelScene1 60 48 68 - - -
LivingRoom NovelScene2 68 64 64 - - -
NovelScene3 60 40 40 - - -
NovelScene1 52 88 88 100 84 76
GreenScreen NovelScene2 72 80 100 100 96 80
NovelScene3 40 68 100 88 80 80
22Table10: “PlaceCubeinDrawer”taskunaggregatedresults..
SuccessRate(%)
Train Test Generative GreenAug GreenAug GreenAug
NoAug CVAug
Scene Scene Augmentation random generative mask
GreenScreen GreenScreen (92) (96) (72) (100) (84) (96)
NovelScene1 68 88 72 - - -
LivingRoom NovelScene2 0 32 64 - - -
NovelScene3 32 72 68 - - -
NovelScene1 36 92 76 92 92 48
GreenScreen NovelScene2 56 68 64 96 92 48
NovelScene3 24 60 76 88 64 16
Table11: “SweepCoffeeBeans”taskunaggregatedresults.
SuccessRate(%)
Train Test Generative GreenAug GreenAug GreenAug
NoAug CVAug
Scene Scene Augmentation random generative mask
GreenScreen GreenScreen (100) (96) (88) (96) (80) (92)
NovelScene1 60 96 88 - - -
LivingRoom NovelScene2 52 60 88 - - -
NovelScene3 52 80 44 - - -
NovelScene1 92 80 88 100 92 96
GreenScreen NovelScene2 76 80 88 96 80 76
NovelScene3 64 72 56 92 72 80
Table12: “TakeLidoffSaucepan”taskunaggregatedresults.
SuccessRate(%)
Train Test Generative GreenAug GreenAug GreenAug
NoAug CVAug
Scene Scene Augmentation random generative mask
GreenScreen GreenScreen (96) (84) (92) (80) (80) (84)
NovelScene1 64 76 76 - - -
LivingRoom NovelScene2 68 84 68 - - -
NovelScene3 52 76 72 - - -
NovelScene1 64 80 80 88 76 68
GreenScreen NovelScene2 96 96 92 84 76 80
NovelScene3 60 72 76 92 68 64
Table13: “PlaceJeansinBasket”taskunaggregatedresults.
SuccessRate(%)
Train Test Generative GreenAug GreenAug GreenAug
NoAug CVAug
Scene Scene Augmentation random generative mask
GreenScreen GreenScreen (100) (100) (92) (100) (100) (92)
NovelScene1 64 64 68 - - -
LivingRoom NovelScene2 76 76 76 - - -
NovelScene3 68 80 80 - - -
NovelScene1 68 76 76 84 72 64
GreenScreen NovelScene2 72 80 76 80 80 72
NovelScene3 76 76 80 96 80 64
23Table14: “PlaceBearinBasket”taskunaggregatedresults.
SuccessRate(%)
Train Test Generative GreenAug GreenAug GreenAug
NoAug CVAug
Scene Scene Augmentation random generative mask
GreenScreen GreenScreen (100) (100) (100) (100) (96) (100)
NovelScene1 32 24 32 - - -
LivingRoom NovelScene2 36 24 12 - - -
NovelScene3 36 88 80 - - -
NovelScene1 56 92 80 100 44 32
GreenScreen NovelScene2 28 52 68 84 12 24
NovelScene3 80 96 96 100 92 68
Table15: “StackCups”taskunaggregatedresults.
SuccessRate(%)
Train Test Generative GreenAug GreenAug GreenAug
NoAug CVAug
Scene Scene Augmentation random generative mask
GreenScreen GreenScreen (76) (84) (84) (88) (80) (80)
NovelScene1 44 52 64 - - -
LivingRoom NovelScene2 40 60 76 - - -
NovelScene3 40 60 84 - - -
NovelScene1 56 44 76 72 60 24
GreenScreen NovelScene2 64 80 88 84 72 80
NovelScene3 52 60 76 88 84 60
Table16: “SlideBookandPickUp”taskunaggregatedresults.
SuccessRate(%)
Train Test Generative GreenAug GreenAug GreenAug
NoAug CVAug
Scene Scene Augmentation random generative mask
GreenScreen GreenScreen (100) (100) (100) (100) (100) (100)
NovelScene1 68 84 88 - - -
LivingRoom NovelScene2 28 48 84 - - -
NovelScene3 32 52 96 - - -
NovelScene1 44 96 92 96 96 32
GreenScreen NovelScene2 48 72 84 88 88 8
NovelScene3 72 92 92 96 96 64
24Table 17: Texture randomness unaggregated results (GreenAug-Rand). “Green Screen→Green
Screen”roughlyrepresentstheupperboundperformance(inparentheses)andisnotincludedinthe
average.
SuccessRate(%)
Train Test
Task None SolidTextures PerlinTextures MILTextures
Scene Scene
GreenScreen GreenScreen (92) (100) (100) (100)
PlaceCube
NovelScene1 36 68 64 92
inDrawer
GreenScreen NovelScene2 56 36 56 96
NovelScene3 24 68 68 88
GreenScreen GreenScreen (76) (76) (80) (88)
StackCups NovelScene1 56 76 68 72
GreenScreen NovelScene2 64 68 60 84
NovelScene3 52 76 80 88
Average 48 65 66 87
Table18: Greenscreencoverageunaggregatedresults(GreenAug-Rand). “GreenScreen→Green
Screen”roughlyrepresentstheupperboundperformance(inparentheses)andisnotincludedinthe
average.
SuccessRate(%)
Train Test
Task 0% 25% 50% 75% 100%
Scene Scene
PlaceCube GreenScreen GreenScreen (92) (100) (100) (100) (100)
inDrawer
NovelScene1 36 80 76 80 92
GreenScreen NovelScene2 56 64 68 72 96
NovelScene3 24 88 84 88 88
GreenScreen GreenScreen (76) (76) (80) (76) (88)
StackCups
NovelScene1 56 64 76 80 72
GreenScreen NovelScene2 64 68 60 68 84
NovelScene3 52 72 76 76 88
Average 48 73 73 77 87
Table19:Objectgeneralisationunaggregatedresults.Dataiscollectedonthegreencup,andpolicies
arethentrainedandevaluatedonvariousobjects(illustratedinFig.16).
SuccessRate(%)
ObjectType NoAug GreenAug-Rand GreenAug-Gen
GreenCup 96 88 80
BlueCup 96 80 80
OrangeCup 92 80 80
RedCube 0 44 60
GreenCube 0 20 44
SodaCan 40 28 36
SoyaCan 36 64 44
SoftToy 0 84 72
Average 45 61 62
25(a)Demonstrationscollectedusingthegreencup. (b)Testobjects:cups,cans,cubesandtoy.
Figure 16: Object generalisation across object category. Policy trained on green cup data using
GreenAug-Randandtestedondifferentobjects.
E AdditionalLimitationsandFutureWorks
Explorationofbetterchromakeyalgorithms. Thechromakeyalgorithmusedinthispaper[38]
isabasiconethatperformsreasonablywell,butitdoesnotproduceperfectmasks. Someparameter
tuningforK,α,andβisstillnecessary.Despitetheseimperfections,wedemonstratethatGreenAug
stillsignificantlyoutperformsthebaselines.Inthefilmindustry,extensivemanualpost-processingis
oftenrequiredtoachieveperfectmasks[52]. Futureresearchcouldexploremoreadvancedchroma
key algorithms that provide superior green screen masks [17, 53, 54, 18]. This could potentially
enhancetheperformanceofGreenAug-Mask,whichreliesheavilyongreenscreenmaskasground
truthfortraining.
Posegeneralisation. Amajorongoingchallengeinrobotlearningisgeneralisingto6Dposesnot
presentinthetrainingdataset. Currentrobotlearningpolicies, especiallyimitationlearning-based
onesoftenfailwhenobjectsarerelocatedtodifferentpositionswithin3Dspace.
Application to methods with 3D observations. Currently, GreenAug has only been tested on
RGB-basedrobotlearningpolicies. Recentadvancesinnext-best-pose-basedagents[55,3,6]have
demonstratedthatbyaligningtheobservationspacewithactionspace,wecanobtainstronggener-
alisationinrobotlearningpolicies. Asageneralplug-and-playmethod,GreenAugcouldpotentially
further improve the scene generalisation of the next-best-pose agents, which we leave for future
study.
26