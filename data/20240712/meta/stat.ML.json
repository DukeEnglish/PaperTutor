[
    {
        "title": "Dynamical Measure Transport and Neural PDE Solvers for Sampling",
        "authors": "Jingtong SunJulius BernerLorenz RichterMarius ZeinhoferJohannes MüllerKamyar AzizzadenesheliAnima Anandkumar",
        "links": "http://arxiv.org/abs/2407.07873v1",
        "entry_id": "http://arxiv.org/abs/2407.07873v1",
        "pdf_url": "http://arxiv.org/pdf/2407.07873v1",
        "summary": "The task of sampling from a probability density can be approached as\ntransporting a tractable density function to the target, known as dynamical\nmeasure transport. In this work, we tackle it through a principled unified\nframework using deterministic or stochastic evolutions described by partial\ndifferential equations (PDEs). This framework incorporates prior\ntrajectory-based sampling methods, such as diffusion models or Schr\\\"odinger\nbridges, without relying on the concept of time-reversals. Moreover, it allows\nus to propose novel numerical methods for solving the transport task and thus\nsampling from complicated targets without the need for the normalization\nconstant or data samples. We employ physics-informed neural networks (PINNs) to\napproximate the respective PDE solutions, implying both conceptional and\ncomputational advantages. In particular, PINNs allow for simulation- and\ndiscretization-free optimization and can be trained very efficiently, leading\nto significantly better mode coverage in the sampling task compared to\nalternative methods. Moreover, they can readily be fine-tuned with Gauss-Newton\nmethods to achieve high accuracy in sampling.",
        "updated": "2024-07-10 17:39:50 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.07873v1"
    },
    {
        "title": "Disentangled Representation Learning through Geometry Preservation with the Gromov-Monge Gap",
        "authors": "Théo UsciddaLuca EyringKarsten RothFabian TheisZeynep AkataMarco Cuturi",
        "links": "http://arxiv.org/abs/2407.07829v1",
        "entry_id": "http://arxiv.org/abs/2407.07829v1",
        "pdf_url": "http://arxiv.org/pdf/2407.07829v1",
        "summary": "Learning disentangled representations in an unsupervised manner is a\nfundamental challenge in machine learning. Solving it may unlock other\nproblems, such as generalization, interpretability, or fairness. While\nremarkably difficult to solve in general, recent works have shown that\ndisentanglement is provably achievable under additional assumptions that can\nleverage geometrical constraints, such as local isometry. To use these\ninsights, we propose a novel perspective on disentangled representation\nlearning built on quadratic optimal transport. Specifically, we formulate the\nproblem in the Gromov-Monge setting, which seeks isometric mappings between\ndistributions supported on different spaces. We propose the Gromov-Monge-Gap\n(GMG), a regularizer that quantifies the geometry-preservation of an arbitrary\npush-forward map between two distributions supported on different spaces. We\ndemonstrate the effectiveness of GMG regularization for disentanglement on four\nstandard benchmarks. Moreover, we show that geometry preservation can even\nencourage unsupervised disentanglement without the standard reconstruction\nobjective - making the underlying model decoder-free, and promising a more\npractically viable and scalable perspective on unsupervised disentanglement.",
        "updated": "2024-07-10 16:51:32 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.07829v1"
    },
    {
        "title": "When to Accept Automated Predictions and When to Defer to Human Judgment?",
        "authors": "Daniel SikarArtur GarcezTillman WeydeRobin BloomfieldKaleem Peeroo",
        "links": "http://arxiv.org/abs/2407.07821v1",
        "entry_id": "http://arxiv.org/abs/2407.07821v1",
        "pdf_url": "http://arxiv.org/pdf/2407.07821v1",
        "summary": "Ensuring the reliability and safety of automated decision-making is crucial.\nIt is well-known that data distribution shifts in machine learning can produce\nunreliable outcomes. This paper proposes a new approach for measuring the\nreliability of predictions under distribution shifts. We analyze how the\noutputs of a trained neural network change using clustering to measure\ndistances between outputs and class centroids. We propose this distance as a\nmetric to evaluate the confidence of predictions under distribution shifts. We\nassign each prediction to a cluster with centroid representing the mean softmax\noutput for all correct predictions of a given class. We then define a safety\nthreshold for a class as the smallest distance from an incorrect prediction to\nthe given class centroid. We evaluate the approach on the MNIST and CIFAR-10\ndatasets using a Convolutional Neural Network and a Vision Transformer,\nrespectively. The results show that our approach is consistent across these\ndata sets and network models, and indicate that the proposed metric can offer\nan efficient way of determining when automated predictions are acceptable and\nwhen they should be deferred to human operators given a distribution shift.",
        "updated": "2024-07-10 16:45:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.07821v1"
    },
    {
        "title": "Sequential Kalman Monte Carlo for gradient-free inference in Bayesian inverse problems",
        "authors": "Richard D. P. GrumittMinas KaramanisUroš Seljak",
        "links": "http://arxiv.org/abs/2407.07781v1",
        "entry_id": "http://arxiv.org/abs/2407.07781v1",
        "pdf_url": "http://arxiv.org/pdf/2407.07781v1",
        "summary": "Ensemble Kalman Inversion (EKI) has been proposed as an efficient method for\nsolving inverse problems with expensive forward models. However, the method is\nbased on the assumption that we proceed through a sequence of Gaussian measures\nin moving from the prior to the posterior, and that the forward model is\nlinear. In this work, we introduce Sequential Kalman Monte Carlo (SKMC)\nsamplers, where we exploit EKI and Flow Annealed Kalman Inversion (FAKI) within\na Sequential Monte Carlo (SMC) sampling scheme to perform efficient\ngradient-free inference in Bayesian inverse problems. FAKI employs normalizing\nflows (NF) to relax the Gaussian ansatz of the target measures in EKI. NFs are\nable to learn invertible maps between a Gaussian latent space and the original\ndata space, allowing us to perform EKI updates in the Gaussianized NF latent\nspace. However, FAKI alone is not able to correct for the model linearity\nassumptions in EKI. Errors in the particle distribution as we move through the\nsequence of target measures can therefore compound to give incorrect posterior\nmoment estimates. In this work we consider the use of EKI and FAKI to\ninitialize the particle distribution for each target in an adaptive SMC\nannealing scheme, before performing t-preconditioned Crank-Nicolson (tpCN)\nupdates to distribute particles according to the target. We demonstrate the\nperformance of these SKMC samplers on three challenging numerical benchmarks,\nshowing significant improvements in the rate of convergence compared to\nstandard SMC with importance weighted resampling at each temperature level.\nCode implementing the SKMC samplers is available at\nhttps://github.com/RichardGrumitt/KalmanMC.",
        "updated": "2024-07-10 15:56:30 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.07781v1"
    },
    {
        "title": "Ramsey Theorems for Trees and a General 'Private Learning Implies Online Learning' Theorem",
        "authors": "Simone FioravantiSteve HannekeShay MoranHilla ScheflerIska Tsubari",
        "links": "http://arxiv.org/abs/2407.07765v1",
        "entry_id": "http://arxiv.org/abs/2407.07765v1",
        "pdf_url": "http://arxiv.org/pdf/2407.07765v1",
        "summary": "This work continues to investigate the link between differentially private\n(DP) and online learning. Alon, Livni, Malliaris, and Moran (2019) showed that\nfor binary concept classes, DP learnability of a given class implies that it\nhas a finite Littlestone dimension (equivalently, that it is online learnable).\nTheir proof relies on a model-theoretic result by Hodges (1997), which\ndemonstrates that any binary concept class with a large Littlestone dimension\ncontains a large subclass of thresholds. In a follow-up work, Jung, Kim, and\nTewari (2020) extended this proof to multiclass PAC learning with a bounded\nnumber of labels. Unfortunately, Hodges's result does not apply in other\nnatural settings such as multiclass PAC learning with an unbounded label space,\nand PAC learning of partial concept classes.\n  This naturally raises the question of whether DP learnability continues to\nimply online learnability in more general scenarios: indeed, Alon, Hanneke,\nHolzman, and Moran (2021) explicitly leave it as an open question in the\ncontext of partial concept classes, and the same question is open in the\ngeneral multiclass setting. In this work, we give a positive answer to these\nquestions showing that for general classification tasks, DP learnability\nimplies online learnability. Our proof reasons directly about Littlestone\ntrees, without relying on thresholds. We achieve this by establishing several\nRamsey-type theorems for trees, which might be of independent interest.",
        "updated": "2024-07-10 15:43:30 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.07765v1"
    }
]