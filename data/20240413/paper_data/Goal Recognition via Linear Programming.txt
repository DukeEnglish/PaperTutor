JournalofArtificialIntelligenceResearch (2024) Submitted;published
Goal Recognition via Linear Programming
Felipe Meneguzzi felipe.meneguzzi@abdn.ac.uk
University of Aberdeen, Scotland, UK
Pontifical Catholic University of Rio Grande do Sul, Brazil
Ramon Fraga Pereira ramonfraga.pereira@manchester.ac.uk
University of Manchester, England, UK
Lu´ısa R. de A. Santos lrasantos@inf.ufrgs.br
Andr´e G. Pereira agpereira@inf.ufrgs.br
Federal University of Rio Grande do Sul, Brazil
Abstract
Goal Recognition is the task by which an observer aims to discern the goals that cor-
respond to plans that comply with the perceived behavior of subject agents given as a
sequence of observations. Research on Goal Recognition as Planning encompasses reason-
ing about the model of a planning task, the observations, and the goals using planning
techniques, resulting in very efficient recognition approaches. In this article, we design
novel recognition approaches that rely on the Operator-Counting framework, proposing
new constraints, and analyze their constraints’ properties both theoretically and empiri-
cally. The Operator-Counting framework is a technique that efficiently computes heuristic
estimates of cost-to-goal using Integer/Linear Programming (IP/LP). In the realm of the-
ory, we prove that the new constraints provide lower bounds on the cost of plans that
complywithobservations. Wealsoprovideanextensiveempiricalevaluationtoassesshow
the new constraints improve the quality of the solution, and we found that they are espe-
cially informed in deciding which goals are unlikely to be part of the solution. Our novel
recognition approaches have two pivotal advantages: first, they employ new IP/LP con-
straints for efficiently recognizing goals; second, we show how the new IP/LP constraints
can improve the recognition of goals under both partial and noisy observability.
1. Introduction
Goal Recognition is the task by which an observer perceives an agent’s behavior by an
abstract sensor as observations, and infers a subset of goals that have plans that comply
with the agent behavior (Schmidt, Sridharan, & Goodson, 1978) subject to domain model
dynamics. In the most common setting for goal recognition, the observations are sub-
sequences of operators, possibly partial and noisy, extracted from the original plan that
the agent executed, which is unknown from the observer’s perspective. In Goal Recognition
as Planning (Ram´ırez & Geffner, 2009), such observations constitute constraints on which
plans from the domain models explain valid goal hypotheses. Thus, the observer can apply
planning algorithms to reason about a goal recognition task and select a subset of the
possible goals. An observer can then reason about a goal recognition task by planning from
the point of view of the observed agent and selecting a subset of the possible goals.
MostapproachestoGoalRecognitionasPlanning oftenassumethattheagentisrational,
i.e., the most likely solution is the subset of goals that have plans complying with the
©2024AIAccessFoundation. Allrightsreserved.
4202
rpA
11
]IA.sc[
1v43970.4042:viXraMeneguzzi, Santos, Pereira, & Pereira
observations with the least additional cost (Ram´ırez & Geffner, 2009, 2010; E-Mart´ın, R.-
Moreno,&Smith,2015; Sohrabi,Riabov,&Udrea,2016; Masters&Sardina,2019a). These
approachescanbeunderstoodascost-based approaches, astheyrelyoncomparingthecosts
of plans that either comply with or do not comply with the observations for the same goal.
They select some subset of the goals by comparing these costs for all possible goals, making
the efficiency of cost computation critical for such approaches.
Cost-based approaches often employ a search procedure of planning algorithms for such
cost computation, making them accurately but computationally expensive (Ram´ırez &
Geffner, 2009, 2010; Sohrabi et al., 2016; Vered, Kaminka, & Biham, 2016; Masters &
Sardina, 2019a). By contrast, other cost-based recognition approaches have relied on infor-
mation from planning heuristics to speed up recognition without running a search proce-
dure (E-Mart´ın et al., 2015; Pereira, Oren, & Meneguzzi, 2020; Santos, Meneguzzi, Pereira,
& Pereira, 2021). The trade-off here is that the recognition process is limited to how in-
formed the underlying heuristics are. The Operator-Counting framework (Pommerening,
R¨oger, Helmert, & Bonet, 2014) is a planning technique that models a planning task as an
IntegerProgram (IP)model,typicallyrelaxedintoaLinearProgram (LP)model,inorderto
efficiently estimate to cost of solving it. This framework combines the information of other
planning techniques through IP/LP constraints, obtaining a more informed estimate of the
cost of solving a planning task. Common sources of constraints are landmarks hLMC (Hoff-
mann, Porteous, & Sebastia, 2004), the post-hoc optimization hPhO (Pommerening, R¨oger,
& Helmert, 2013), network flow hFLOW (Bonet & van den Briel, 2014) and delete-relaxation
hDEL (Imai & Fukunaga, 2014). Performing goal recognition using Operator-Counting con-
straintsofferstwokeyadvantages. First, themainadvantageofusingtheoperator-counting
framework is that it enables one to manipulate the constraints directly to reason about the
cost of solving planning tasks. Thus, like their planning heuristics counterparts, one can
improve the informativeness of the goal recognition process by adding more constraints
encoding information from the planning task. Second, one can include constraints to deal
specifically with the information available from goal recognition problems, including noise.
OurpreviousworkprovidesanefficientapproachthatusestheOperator-Counting frame-
work to solve goal recognition tasks by including constraints based on the observations that
restrictthesetofsolutionsoftheIP/LPmodel(Santosetal., 2021). Withinourrecognition
framework, wedefineareferencesolutionsettobettercomparethequalityofsolutionsfrom
earlierapproaches. Inthisarticle,weconsolidateouroriginalworkongoalrecognitionusing
the Operator-Counting framework (Santos et al., 2021), expanding the set of constraints
and carefully studying the implication of the LP constraints to the recognition task. Thus,
in this article, we provide a number of novel contributions to goal recognition in general,
and to LP-based techniques in particular. First, we formally prove, in Section 4, that our
original Operator-Counting constraints provide lower bounds on the cost of plans that com-
plywiththeobservations. Second, weintroducenovelLP/IPlandmark constraints hLMCfor
goal recognition tasks that extract information on-the-fly, from the observation sequence.
Third, we develop further empirical experiments in Section 6.1 to improve the understand-
ing of how the extra constraints impact the quality of the results. We show in Section 6.2
that the new constraints are more informed in deciding which goals are unlikely to be part
of the solution. Our new experiments show that strengthening our recognition of heuristics
leads the value of non-reference goals to increase more than the reference ones, thus better
2Goal Recognition via Linear Programming
differentiating them. In a broad context, our new approaches improve the quality of the
solutions substantially and pave the way for exploring novel avenues of research for solving
goal recognition tasks efficiently with high-quality accuracy.
2. Background
In this section, we introduce the essential background on Planning and heuristic functions,
as well as key concepts of the Operator-Counting framework and its constraints.
2.1 Planning
Planning is the problem of finding a sequence of operators that achieves a particular goal
condition from an initial state. A SAS+ planning task (B¨ackstr¨om & Nebel, 1993) is a
tuple Π = ⟨V,O,s ,s∗,cost⟩, where V is a set of discrete finite-domain variables; O is a set
0
of SAS+ operators; s is the initial state; s∗ is a SAS+ partial variable assignment denoting
0
the goal condition; and cost is a function that maps each operator in O to a natural-valued
cost. In this article, operators’ costs are unitary.
An atom is a pair ⟨V,v⟩ of a variable V ∈ V, and one of its values v ∈ dom(V). The set
of all atoms A consists of all possible pairs of variables V ∈ V with their respective possible
values v ∈ dom(V). A partial state is a set of atoms ⟨V,v⟩ that mentions each variable at
mostonce. Letvars(s)bethedomainofvariablesinapartialstates. Avariableassignment
s with vars(s) = V is a complete state or simply a state, and the set of all (complete) states
over V is the state-space S. A complete state s is consistent with a (possibly partial) state
s′ if s′ ⊆ s.
Each operator is a tuple o = ⟨p,e⟩ of partial variable assignments, where p = pre(o) is
the set of preconditions, and e = post(o) is the set of effects. An operator o is applicable
in a state s if pre(o) ⊆ s. The state resulting from executing an applicable operator o,
denoted s′ = s o , is for all V ∈ V, s′[V] = post(o)[V] if V ∈ vars(post(o)) and s′[V] = s[V]
(cid:74) (cid:75)
otherwise. Finally, an s-plan π is a sequence of operators ⟨o ,o ,...,o ⟩ that starts at state
1 2 n
s and ends in a state that satisfies the condition s∗ after sequential applications of each
operator o ∈ π. An s-plan π is optimal if the value of cost(π) is minimal over all s-plan,
i
where cost(π) =
(cid:80)n
cost(o ). An s-plan is called a plan if s = s which is a solution for
i=1 i 0
a planning task.
A heuristic function for a given planning task Π with a set of states S is a function
h : S → R∪{∞} that estimates the cost of the solutions for a given state. A given heuristic
h is admissible if and only if, for every state s ∈ S, h(s) ≤ h∗(s), where h∗(s) is the perfect
heuristic, i.e. the cost of an optimal solution for s.
2.2 Operator-Counting Framework
TheOperator-Counting frameworkcombinestheinformationfromdifferentsourcesthrough
anInteger/LinearProgram (IP/LP)(Pommereningetal.,2014). Thesesourcesprovidecon-
straintsforastatesthatmustbesatisfiedbyalls-plans. Commonsourcesofconstraintsare
state equation hSEQ (Bonet, 2013), landmarks hLMC (Hoffmann et al., 2004), the post-hoc
optimization hPhO (Pommerening et al., 2013), the network flow hFLOW (Bonet & van den
Briel, 2014), and the delete relaxation hDEL (Imai & Fukunaga, 2014). The framework has
3Meneguzzi, Santos, Pereira, & Pereira
two main advantages: it allows us to efficiently combine the information a diverse set of
sources maintaining admissibility, and it enables us to reason and to manipulate the infor-
mation of the source directly. In general, the objective value of the linear program (LP), a
linear relaxation of the integer program, is used as heuristic function to guide the search.
Thisheuristicworksbycomputingapseudo-plan. Inthecontextofthisarticle,apseudo-
plan is an unordered multisetof operators derived from theoperator-counts. When ordered,
a pseudo-plan may or may not yield a valid plan. Each operator must be executed at least
the number of times indicated by its operator count, but in no particular order. Operator-
counting variables represent these operator counts in the IP/LP under operator-counting
constraints from Definition 1.
Definition 1 (Operator-Counting Constraint). Let Π be a planning task with opera-
tors O, and let s be one of its states. Let Y be a set of real-valued and integer variables,
including an operator-counting non-negative integer variable Y for each operator o ∈ O.
o
A set of linear inequalities over Y is an operator-counting constraint for s if for every valid
s-plan π, there exists a solution for it with Y = occur (o) for all o ∈ O — where occur (o)
o π π
is the number of occurrences of operator o in the s-plan π. We call C a set of operator
counting constraints.
Operator counting variables then allow one to define heuristics computed indirectly
via an integer/linear program that enforces constraints computed from the structure of a
planning task. We formalize the broad class of such heuristics in Definition 2.
Definition 2 (Operator-Counting IP/LP Heuristic). The operator-counting integer
program IPC for a set of operator-counting constraints C for state s is
(cid:88)
minimize cost(o)Y
o
o∈O
subject to C,
Y ∈ Z+.
o 0
The IP heuristic hIP is the objective value of IPC, and the LP heuristic hLP is the objective
value of its linear relaxation. If the IP or LP is infeasible, the heuristic estimate is ∞.
AnimportantresultfromPommereningetal.(2014),isthat,asweaddmoreconstraints
into the operator-counting framework, we exclude solutions that are inconsistent with so-
lutions to the underlying planning problem. The practical result is that operator-counting
heuristics can only get stronger as we add further constraints to them, a property which we
replicate in Proposition 1.
Proposition 1 (Dominance). Let C, C′ be functions that map states s of a planning task
Π to constraint sets for s such that C(s) ⊂ C′(s) for each s. Then the heuristic hIP/LP for
C′ dominates the respective heuristic for C: hIP/LP ≤ hIP/LP .
C C′
The key sources of operator-counting constraints investigated in this article stem from
thevarioustypesoflandmarks (Hoffmannetal., 2004). Wefollowtheformalizationaccord-
ing to Pommerening et al. (2014) and cite the original formalization when appropriate. A
4Goal Recognition via Linear Programming
disjunctive action landmark L for a state s is a set of operators, where at least one operator
in L must be part of every s-plan for state s (Hoffmann et al., 2004). Definition 3 encodes
thelandmarkinformationasanoperator-countingconstraint. Sinceatleastoneoperatorin
a disjunctive action landmark must be used, the sum of their respective operator-counting
variables should be at least one.
Definition 3 (Landmark Constraint). Let L ∈ O be a disjunctive action landmark for
a state s of a planning task Π. The landmark constraint for L is,
(cid:88)
Y ≥ 1.
o
o∈L
Mostoftheefficientalgorithmstocomputelandmarkconstraintsare, ingeneral, correct
and incomplete (Hoffmann et al., 2004). Thus, these algorithms only produce and extract
a subset of the landmarks of a planning task Π.
3. Goal Recognition as Planning
In this section, we introduce the task of Goal Recognition, following the formalism of Goal
RecognitionasPlanning (Ram´ırez&Geffner,2009). Fromthedefinitionofagoalrecognition
task, weintroduceaspecificdefinitionofsolutionthatenablesaprecisecomparisonbetween
different approaches that solve the task.
Definition 4 formally defines the task of goal recognition using a modified version of a
planning task Π (Section 2.1).
Definition 4 (Goal Recognition Task). Let Π be a planning task without a goal
P
condition, Γ be a set of goal conditions (or hypotheses), and Ω = ⟨⃗o ,...,⃗o ⟩ be a sequence
1 m
of observations. The sequence of observations Ω is extracted from a plan π = ⟨o ,...,o ⟩
1 n
of the planning task Π with the goal condition s∗ ∈ Γ. Then, a goal recognition task is a
P R
tuple ΠΩ = ⟨Π ,Γ,Ω⟩.
Γ P
This bakes into the definition the assumption that the set of goal condition hypotheses
Γ does indeed contain a goal s∗ ∈ Γ that explains Ω. Thus, by construction there must be
R
a plan for Π with the goal condition s∗ . As we further refine the definition of the elements
P R
of goal recognition tasks, we introduce terminology to refer to these components. First, we
refer to the goal condition s∗ as the intended reference goal. Second, we represent the label
R
extracted from an operator o as observation ⃗o. The label assigned to observation ⃗o is the
same label assigned to operator o. Thus, we access observations and operators using the
labels interchangeably. Finally, as we refine observations in Definitions 5-7, we introduce
the notion of noise in the observations.
Wherever we introduce noise in the observations, we can extend the definition of the
goal recognition task with an assumption of the maximal level of noise in the observations.
Inthesecases, weextendDefinition4withthelevelofnoiseorunreliabilityϵoftheobserva-
tions. The problem under noise then becomes a quadruple ⟨Π ,Γ,Ω,ϵ⟩ so that Definition 4
P
generalizes to ⟨Π ,Γ,Ω⟩ = ⟨Π ,Γ,Ω,ϵ = 0⟩.
P P
5Meneguzzi, Santos, Pereira, & Pereira
Definition 5 (Observation Compliance). Let⟨Π ,Γ,Ω⟩beaplanrecognitiontask, and
P
let π = ⟨o ,...,o ⟩ be a plan for a planning task Π with the goal condition s∗ ∈ Γ and a
1 n P
sequence of observations Ω = ⟨⃗o ,...,⃗o ⟩. Plan π complies with Ω if there is a monotonic
1 m
function f : [1,m] (cid:55)→ [1,n] that maps all labels of operator indexes in Ω to indexes in π,
such that ⃗o = o , i.e., the labels match.
i f(i)
Observations are the key evidence that one can use to infer the intended reference goal
in goal recognition tasks. The trivial problem setting for an algorithm performing goal
recognition involves access to the full sequence of observations of a plan. However, in most
realisticsettings,observationssufferfromanumberofflaws,stemmingfromboththeerratic
behavioroftheagentunderobservationandthesensingcapabilitiesoftherecognizer. Thus,
we define three classes of sequences of observations: optimal and suboptimal (Definition 6)
observations, and noisy observations (Definition 7).
Definition 6 (Sequence of Observations). Let π = ⟨o ,...,o ⟩ be a plan for the plan-
1 n
ning task Π with with the reference goal condition s∗ . Then, a sequence of observations
P R
Ω is a sequence of labels of operators extracted from the plan π maintaining their relative
order. Thesequencemaybepartial,containinganynumberofoperatorlabelsfromtheplan
π. An optimal sequence of observations is extracted from an optimal plan and a subopti-
mal sequence of observations is extracted from a suboptimal plan. An optimal/suboptimal
observation is part of an optimal/suboptimal sequence of observations.
Definition 7 (Noisy Observations). Let Ω be a sequence of observations extracted from
π. Then, Ω′ is a noisy sequence of observations if it is equal to Ω with the addition of at
least one observation in any place of the original sequence of an operator from O−π.
We extend the standard definition from Ram´ırez and Geffner (2009) of an exact solution
set for a goal recognition task to also consider suboptimal observation sequences (Defini-
tion 8) and call it reference solution set. We define the reference solution set as a subset of
the goal conditions such that there exists a complying plan as suboptimal as or less than
the plan that generated the observations for the reference goal.
Definition 8 (Reference Solution Set). Let ⟨Π ,Γ,Ω⟩ be a goal recognition task and
P
s∗ ∈ Γ the reference goal. Let π be the plan for Π with the reference goal s∗ , from which
R P R
Ω is extracted. Let h∗ be a heuristic that returns the cost of an optimal plan from a
s∗,Ω
state for Π with goal condition s∗ restricted to the set of plans that comply with Ω. Let
P
h∗ be a heuristic that returns the cost of an optimal plan for Π with goal condition s∗.
s∗ P
Heuristics h∗ and h∗ are equal to ∞ if no plan exists. Then, the reference solution set
s∗,Ω s∗
for the goal recognition task is
Γ∗ = {s∗ ∈ Γ |
h∗ s∗,Ω(s 0)
≤
cost(π)
∧h∗ (s ) ̸= ∞}
h∗ (s ) h∗ (s ) s∗,Ω 0
s∗ 0 s∗ 0
R
Example 1. Figure 1 illustrates a goal recognition task ⟨Π ,{s∗,s∗},Ω⟩. Let s∗ be the
P 1 2 1
reference goal s∗ . Now consider different sequences of observations. Ω = ⟨⃗o ⟩ is an optimal
R 1 1
sequence of observations because it is extracted from the optimal plan π = ⟨o ,o ,o ⟩,
1 1 2 3
Ω = ⟨⃗o ,⃗o ,⃗o ⟩ and Ω = ⟨⃗o ,...,⃗o ⟩ are suboptimal sequences of observations because
2 5 7 9 3 4 10
6Goal Recognition via Linear Programming
Figure 1: A goal recognition task example.
they are extracted from the suboptimal plan π = ⟨o ,...,o ⟩, and Ω = ⟨⃗o ,...,⃗o ,⃗o ⟩
2 4 10 4 4 10 11
is a suboptimal and noisy sequence of observations because it was extracted from π and the
2
observation of ⃗o was added. We compute the reference solution set for goal recognition
11
tasks with noisy observations by ignoring noisy observations in the sequence of observations.
The reference solution set for any of these observation sequences is Γ∗ = {s∗}. For example,
1
h∗ /h∗ = 7/3, h∗ /h∗ = 9/3, cost(π )/h∗ = 7/3 and thus Γ∗ = {s∗}.
s∗ 1,Ω4 s∗
1
s∗ 2,Ω4 s∗
2
2 s∗
R
1
Cost Difference-Based Goal Recognition Ram´ırez and Geffner (2009, 2010) address
goal recognition tasks where agents can pursue their goal suboptimally1. For this, they
consider the cost difference between an optimal plan that complies with the observations
and the cost of an optimal plan that does not comply with at least one observation for each
goal condition. Similarly, Vered and Kaminka (2017) empirically show that the cost ration
betweenanoptimalplanandthecostofanoptimalplanthatcomplieswiththeobservations
for each goal condition can rank goal hypotheses similarly to Ram´ırez and Geffner (2009,
2010). The subset of goal conditions with minimum such cost differential is part of their
solution. The definition below formalizes this idea:
Definition 9 (Cost Difference Solution Set). Let ⟨Π ,Γ,Ω⟩ be a goal recognition task
P
and s∗ ∈ Γ the reference goal. Let h∗ be a heuristic that returns the cost of an optimal
R s∗,Ω
plan from a state for Π with goal condition s∗ restricted to the set of plans that comply
P
with Ω. Let h∗ be a heuristic that returns the cost of an optimal plan for Π with goal
s∗ P
condition s∗. The minimal difference between observation-complying plans and optimal
plans δ for hypotheses Γ is:
min
δ = min {h∗ (s )−h∗ (s )} (1)
min s∗,Ω 0 s∗ 0
s∗ i∈Γ : h∗ s∗,Ω(s0)<∞ i
i
Then, the Cost Difference Solution Set ΓCost-Diff of goals hypotheses that are consistent
with minimal cost difference δ is:
min
ΓCost-Diff = {s∗ ∈ Γ | h∗ (s )−h∗ (s ) = δ } (2)
i s∗,Ω 0 s∗ 0 min
i i
1. Ram´ırez and Geffner (2010) present a different formulation, but here we present the formulation from
Masters and Sardina (2019a), which is effectively the same.
7Meneguzzi, Santos, Pereira, & Pereira
Example 2. Figure 2 illustrates a goal recognition task ⟨Π ,{s∗,s∗},{⃗o }⟩. Let s∗ be the
P 1 2 1 1
reference goal s∗ , and ⃗o be the only observation of the task. For this example, the cost
R 1
of optimal complying plans are h∗ (s ) = 4 and h∗ (s ) = 3. Thus, using only this
s∗,Ω 0 s∗,Ω 0
1 2
information for observations extracted from suboptimal behavior one would return solu-
tion Γ∗ = {s∗}, which intuitively is not the solution. However, by using Definition 9 to
2
compute the solution we have h∗ (s )−h∗ (s ) = 0 and h∗ (s )−h∗ (s ) = 2, which is
s∗,Ω 0 s∗ 0 s∗,Ω 0 s∗ 0
1 1 2 2
the intuitive solution.
Figure 2: A goal recognition task example considering cost differences.
The main limitation of this approach is that computing the cost of h∗ (s ) and h∗ (s )
s∗,Ω 0 s∗ 0
for SAS+ planning tasks is a PSPACE-complete problem, and very costly in practice, as we
show in Proposition 2. Thus, most approaches rely on heuristics to estimate these costs.
In this article, we introduce and study a set of heuristics to estimate these values based on
Integer/Linear programs.
Proposition 2 (Computing ΓCost-Diff is PSPACE-complete). Let ΠΩ = ⟨Π ,Γ,Ω⟩ be a goal
Γ P
recognition task, computing the reference-solution set ΓCost-Diff for ΠΩ is PSPACE-complete.
Γ
Proof. Our proof hinges on showing the upper and lower bound complexity for computing
eachofthecomponentsofthesetfromDefinition9,specificallythecostofcomputingh∗ (s )
s∗ 0
and h∗ (s ) for each goal hypothesis in ΠΩ. First, the cost of computing the cost h∗ (s )
s∗,Ω 0 Γ s∗ 0
of reaching each goal hypothesis s∗ has a trivial upper and lower bound. This comes from
the complexity of solving the corresponding planning task, proven to be PSPACE-complete
by B¨ackstr¨om and Nebel (1993). Second, the cost of computing h∗ (s ) is no worse
s∗,Ω 0
than PSPACE-complete, since we can use the reduction of Ram´ırez and Geffner (2009)
for computing an observation-complying plan to a regular planning problem. Since both
components of the overall computation are no more expensive than PSPACE-complete, and
at least one of the components is at least PSPACE-complete, we can conclude that Goal
Recognition as Planning is, indeed, PSPACE-complete.
8Goal Recognition via Linear Programming
4. Linear Programming-Based Goal Recognition
In this section, we develop an IP/LP constraint to produce a lower bound on the cost of
an optimal complying plan. Key to this approach is the addition of observation-counting
constraints that ensure that the IP/LP only computes solutions that satisfy the observa-
tions counts. We use the operator-counting framework to improve our lower bounds since
it restricts the set of solutions of the IP/LP to those that satisfy the operator-counting
constraints.
Definitions 10 and 11 formally introduce the set of observation-counting constraints and
the IP/LP that ensures that the solution computed satisfies all observation counts.
Definition 10 (Observation-Counting Constraints). Let ⟨Π ,Γ,Ω⟩ be a goal recogni-
P
tion task with operators O. Let Y be the set of operator-counting variables for Π with a
P
variable Y for each operator o ∈ O, let YΩ be a set of non-negative integer variables with
o
a variable Y⃗ for each operator o ∈ O, and let ϵ be the unreliability rating of the sensor of
o
observations. The set of observation-counting constraints C consists of:
Ω
Y⃗ ≤ occur (o) for all o ∈ O (3)
o Ω
Y⃗ ≤ Y for all o ∈ O (4)
o o
(cid:88)
Y⃗ ≥ |Ω|−⌊|Ω|∗ϵ⌋ (5)
o
Y⃗ o∈YΩ
Y ,Y⃗ ∈ Z+.
o o 0
In the IP/LP, the set of constrains (3) limits the value of each Y⃗ by the number of
o
occurrences of the operator o in Ω. Next, the set of constraints (4) binds the two sets Y⃗
o
and Y of variables. This set of constraints guarantees that Y acts as an upper bound
o o
for Y⃗ . Thus, to increase the count of Y⃗ the IP/LP solution must first increase the count
o o
of Y which is minimized in the objective function and can be restricted by the set of
o
operator-counting constraints C. Finally, constraint (5) enforces the satisfaction of a subset
of observations, since each Y⃗ is limited by the number of times o appears in Ω. ϵ is
o
the unreliability rating of the sensor that represents the expected percentage of mistaken
observations. For now, consider that the sensor is perfect and ϵ is equal to zero.
Definition 11 (Satisfying IP/LP Heuristic Function). Let ⟨Π ,Γ,Ω⟩ be a goal recog-
P
nition task, s∗ be one of the goal conditions of the task, and s be a state of Π . Let C be a
P
set of operator-counting constraints for state s of planning task Π with goal condition s∗,
P
and C be a set of observation-counting constraints for the goal recognition task. Then,
Ω
the satisfying IP/LP heuristic function for the sets of constraints C, and C is,
Ω
(cid:88)
minimize cost(o)Y , subject to C and C .
o Ω
o∈O
The satisfying IP heuristic function hIP (s) is the objective value of the IP, and the
s∗,Ω
satisfying LP heuristic function h (s) is the objective value of its linear relaxation. If the
s∗,Ω
IP or LP is infeasible, the heuristic estimate is ∞.
9Meneguzzi, Santos, Pereira, & Pereira
Theorem 1 (hIP is a Lower Bound). The value of hIP (s) is a lower bound on the cost
s∗,Ω s∗,Ω
of an optimal complying plan.
Proof. In order to prove this property, we must show that any optimal complying plan
satisfies Constraints 3-5, and that the solution to the objective cost of the resulting LP is a
lower bound. To show this, let π = ⟨o ,...,o ⟩ be an optimal complying s-plan for task Π
1 n P
with goal condition s∗, and s a state from Π . First, since C is a set of operator-counting
P
constraints for state s of task Π with goal condition s∗, this set of constraints C is satisfied
P
by setting each Y equal to occur (o).
o π
Second, C is defined by the sequence of observations Ω. Thus, we can set each Y⃗ to
Ω o
occur (o). Using this attribution we satisfy constraints sets 3 and 5.
Ω
Third, we need to show that the set of constraints 4 is satisfied. Since π is a complying
plan it guarantees that there is a monotonic function f that maps all labels of operator
indexes in Ω to indexes in π, such that ⃗o = o . Thus, for each label ⃗o ∈ Ω there is a
i f(i)
label o ∈ π which guarantees Y⃗ ≤ Y for all o ∈ O.
o o
These three points combined guarantee that the proposed attribution is a solution for
the IP with C and C .
Ω
Finally, the cost of optimal solution of the IP/LP can not exceed the cost of any specific
solution, thus,
h (s) ≤ hIP (s) ≤ cost(π) = h∗ (s). (6)
s∗,Ω s∗,Ω s∗,Ω
Computing the Solution Set. Having defined h we use Definition 2 to compute our
s∗,Ω
solution set. We use h to estimate a lower bound of h∗ , and h to estimate a lower
s∗,Ω s∗,Ω s∗
bound of h∗ . For clarity, we repeat below the equations of Definition 2 that compute our
s∗
solution set ΓLP with the heuristics that estimate the lower bounds.
δ = min {h (s )−h (s )} (7)
min s∗,Ω 0 s∗ 0
s∗∈Γ:h s∗,Ω(s0)<∞
ΓLP = {s∗ ∈ Γ | h (s )−h (s ) = δ } (8)
s∗,Ω 0 s∗ 0 min
Noisy Observations. In most realistic settings, unreliable sensors may add noisy obser-
vations to the sequence of observations. Consider a goal recognition task in our running
example with Ω = ⟨⃗o 4,...,⃗o 10,⃗o 11⟩. Then, h s∗,Ω = 13 and h s∗,Ω = 11. In this situation we
1 2
would have δ = 8, and ΓLP = {s∗}. However, the observation ⃗o is unlikely to be part
min 2 11
of any plan that generates the sequence of observations for either of the two goals.
Ourapproachaddressesnoisyobservationsthroughtheϵparameter(fromtheconstraint
of Eq (5)) which is the unreliability rating of the sensor that represents the expected per-
centageofmistakenobservations. Theunreliabilityratingrequiresthatatleast|Ω|−⌊|Ω|∗ϵ⌋
observations be satisfied by the solution found. If ϵ = 0, all observations must be satis-
fied, whereas if 0 < ϵ < 1, some observations can be ignored in order to minimize the
objective value of h for each goal candidate. Consider our example from Figure 1 with
Ω
10Goal Recognition via Linear Programming
Ω = ⟨o ,...,o ,o ⟩ and ϵ = 0.2. Here, the integer program IP has to satisfy 7 observa-
4 10 11
tions, so h s∗ 1,Ω = 7 and h s∗ 2,Ω = 9. Recall that h∗ s∗
1
= 3 and h∗ s∗
2
= 3. In this situation we
have δ = 4, and ΓLP = {s∗}.
min 1
Theorem 2 (hIP isaLowerBoundinthePresenceofNoisyObservations). If the unrelia-
s∗,Ω
bility rating ϵ of the sensor is greater than zero and there at most ⌊|Ω|∗ϵ⌋ noisy observations
in Ω, then the value of hIP (s) is a lower bound on the cost of an optimal complying plan.
s∗,Ω
Proof. Let π = ⟨o ,...,o ⟩ be an optimal complying s-plan for the non-noisy observation
1 n
in Ω for task Π with goal condition s∗, and s a state from Π .
P P
First, since π is a valid plan we can satisfy C by setting each Y equal to occur (o) as
o π
before.
Second, note that if ⃗o is a noisy observation, then it must satisfy property ⃗o ∈ O −π
according to Definition 7. Thus, we can set each Y⃗ to occur (o) if ⃗o ∈ π and to zero
o Ω
otherwise. Using this attribution and the fact that π is an optimal complying s-plan for
the non-noisy observations, we satisfy constraints sets 3 and 4.
Third, we need to show that the set of constraint 5 is satisfied. Since there are at most
⌊|Ω|∗ϵ⌋ noisy observations in Ω, then:
(cid:88) (cid:88) (cid:88)
Y⃗ − Y⃗ = occur (o)
o o Ω
Y⃗ o∈YΩ:o∈π Y⃗ o∈YΩ:o∈O−π o∈π
(cid:88) (cid:88)
= occur (o)− occur (o) ≥ |Ω|−⌊|Ω|∗ϵ⌋
Ω Ω
o∈O o∈O−π
As before, these three points combined guarantee that the proposed attribution is a
solution for the IP with C and C , and the cost of optimal solution of the IP/LP cannot
Ω
exceed the cost of any specific solution.
Wenowhaveobservation-countingconstraintswithintheframeworkofoperator-counting
that provide provably correct lower bounds to plans that comply with constraints. These
constraints allow us to approximate the cost difference solution set from Definition 9 within
the operator counting framework as an LP. However, the key advantage of our LP frame-
work for goal recognition is that we can add further constraints (either from the Operator
Counting Framework, or otherwise) and strengthen our estimates. Indeed, much like the
operator counting framework, as we further constrain the LP to better match the set of
operators included in real plans to solve a planning task, our estimates get closer to the
exact computation of the solution set from Ram´ırez and Geffner (2009).
5. Novel LP Constraints for Goal Recognition
We now develop novel Operator-Counting constraints specifically for goal recognition tasks.
This is an entirely novel framework of Linear Programming constraints that combines the
traditional operator-counting constraints from Definition 1 and the observation-counting
constraintsfromDefinition10. Intuitively,aconstraintfortheoperator-countingframework
is an operator-counting constraint if every s-plan satisfies it. In other words, operator-
counting constraints induce a linear program whose solutions reflect the space of actions
11Meneguzzi, Santos, Pereira, & Pereira
required by their corresponding planning problem. Definition 12 extends this property to
goal recognition problems. It formally states that a constraint for the operator-counting
frameworkisanoperator-countingconstraintforagoalrecognitiontaskifeveryobservation
complying s-plan satisfies it.
Definition 12 (Operator-Counting Constraints for a Goal Recognition Task). Let
⟨Π ,Γ,Ω⟩ be a goal recognition task, let the planning task Π resulting from the union of
P
the task Π with a goal condition s∗ ∈ Γ∪{pre(⃗o)|⃗o ∈ Ω}. Let s be one of the states of
P
task Π, and Y be a set of real-valued and integer variables, including an operator-counting
non-negative integer variable Y for each operator o ∈ O. A set of linear inequalities over
o
Y is an operator-counting constraint for a goal recognition task for the state s if for every
valid complying s-plan π of task Π, there exists a solution for the set of linear inequalities
with Y = occur (o) for all o ∈ O.
o π
In what follows, we introduce new landmark constraints that use the observations to
derivefurtherlandmarkstiedtonecessaryconditionsinplansthatinducesuchobservations.
Key to these new constraints is their compatibility with noisy observations.
Much like previous work on computationally efficient approaches for goal recognition
(Pereira et al., 2020), our IP formulation approximates the set of goals that are compatible
with theobservationswithout computingfull plans likein Ram´ırez andGeffner (2009). Un-
like such previous work, however, the operator-counting framework allows us to tighten our
approximation by adding further constraints. In theory, if we could add enough constraints
to obtain the perfect heuristic for the underlying planning problem for a goal hypothesis
(and the perfect heuristic for the plans that comply with the observations) then we have
RGs optimal recognition.
RecalltheconceptofdisjunctivelandmarksofPorteous,Sebastia,andHoffmann(2001).
Let s be a state of the task Π with a goal condition s∗ ∈ Γ. Then, a disjunctive action
P
landmark for a goal recognition task L for the state s is a set of operators such that at
least one operator in L must be part of every complying s-plan. In the context of goal
recognition, such landmarks have two key properties. First, when restricted to non-noisy
observations, every operator part of the sequence of observations Ω is an action landmark
for the goal recognition task. This means that the action corresponding to every observa-
tion must be part of any valid pseudo-plan for this task. Second, the preconditions of these
operators are sub-goals that must be satisfied by every complying plan. These subgoals are
in addition to the goal condition that must be satisfied by every plan. Thus, we can use tra-
ditional landmark extraction techniques to generate new landmarks using the preconditions
of observations. Definition 13 encodes this new type of constraint.
Definition 13 (Landmark Constraint for Goal Recognition Tasks). Let L ∈ O be a
disjunctive action landmark for a state s of a planning task Π with goal condition defined
P
as pre(⃗o) with ⃗o ∈ Ω. The constraint for L is,
(cid:88)
Y ≥ [Y⃗ > 0]. (9)
o o
o∈L
We call the set of all such constraints LMC .
Ω
12Goal Recognition via Linear Programming
The main difference between Definition 13 and traditional landmark constraints is that
the bound of the constraint is equal to [Y⃗ > 0] instead of 1 from Definition 3. This means
o
that Y will be one if we observe operator o, and zero otherwise. Since this formulation
o
depends on variables Y⃗ from Definition 10, constraints from the new Definition 13 must
o
be used with our observation-counting constraints C . In practice, we implement these
Ω
constraints as:
(cid:88)
Y⃗
o
0 ≤ Y − ≤ ∞.
o
occur (o)
Ω
o∈L
To emulate the “binary” variable of the test on the corresponding observation constraint.
This means that the value we are comparing against Y depends on what operators we have
o
in the observations. In turn, this formulation means that the solver only needs to enforce
constraints of an observation Y⃗ if the value of Y⃗ is greater than 0. This enables the IP/LP
o o
to address noisy observations automatically. Having defined landmark constraints for goal
recognition tasks we can define the new hLMCΩheuristic.
Ω,s∗
Definition 14 (Landmark Heuristic for Goal Recognition Tasks). Let LMC be
Ω
set of constraints of landmark constraint for goal recognition tasks computed using as goal
conditions pre(⃗o) of each ⃗o ∈ Ω. Then, the hLMCΩ heuristic extends Definition 11 with the
Ω,s∗
set of constraints LMC , i.e., the IP/LP of hLMCΩ includes constraints C, C , and LMC .
Ω Ω,s∗ Ω Ω
Figure 3: Example of landmark heuristic for a goal recognition task. States s and s and
1 2
their corresponding disjunctive landmarks highlighted in red and blue, respectively.
Example 3. Consider the example in Figure 3 in which the goal recognition task has an
initialstates , agoalhypothesiss∗, andtwoobservationsΩ = ⟨⃗o ,⃗o ⟩. Theobservationsare
0 1 5
such that ⃗o is an actual step the observed plan from s to s∗, and ⃗o is a noisy observation.
1 0 5
Suppose that the landmark-extraction technique generates, for each observation⃗o in Ω, a set
of disjunctive action landmarks that are the operators that produce the cell from which the
operator o corresponding to the observation⃗o is applied. Under these conditions both cells s
1
(in red) and s (in blue) must be produced as landmarks from⃗o and⃗o respectively. Each of
2 1 5
13Meneguzzi, Santos, Pereira, & Pereira
thesestateshaveacorrespondingsetofdisjunctivelandmarks, denotedbyobservationsinthe
corresponding color. Observation ⃗o generates the constraint Y +Y +Y ≥ [Y⃗ > 0],
1 o2 o3 o4 o1
and observation ⃗o generates the constraint Y + Y ≥ [Y⃗ > 0]. Suppose we want to
2 o6 o7 o5
compute hLMCΩ for s in Figure 3 and that the unreliability rating ϵ of the sensor is equal
Ω,s∗ 0
to 0.5. Therefore, IP/LP of hLMCΩ only needs to increase the counts associated to one
Ω,s∗
observation. Consequently, an optimal complying plan satisfying for Y⃗ costs three, and
o1
optimal complying plan satisfying for Y⃗ costs seven. Note that there are two optimal
o5
complying plans that satisfy Y⃗ , and both also satisfy Y + Y + Y ≥ [Y⃗ > 0], one
o1 o2 o3 o4 o1
uses o and another uses o . Thus, the value of hLMCΩ for this example is three.
2 4 Ω,s∗
Theorem 3 (hLMCΩ is a Lower Bound). The value of hLMCΩ solved as an IP is a lower
Ω,s∗ Ω,s∗
bound on the cost of an optimal complying plan.
Proof. To prove this property we must show that any optimal complying plan satisfies
constraints C, C , and LMC , and that the solution to the objective function is a lower
Ω Ω
bound is a lower bound on the cost of an optimal complying plan. First, from Theorem 1
we have that the solution of an IP with constraints C and C is a lower bound on the cost
Ω
of an optimal complying plan. Second, from Theorem 2 we have that the solution of an
IP is a lower bound on the cost of an optimal complying plan even if noisy observations
are present. It remains to show that satisfying the constraints LMC maintains the lower
Ω
bound property.
Let π = ⟨o ,...,o ⟩ be an optimal complying s-plan for the non-noisy observation in
1 n
Ω for task Π with goal condition s∗, and s a state from Π . From Theorem 2 we have
P P
that we can set each Y⃗ to occur (o) if ⃗o ∈ π and to zero otherwise. Thus, only non-noisy
o Ω
observations Y⃗ will have the value of the binary variable [Y⃗ > 0] set to one. Without loss
o o
of generality, let LMC (⃗o) be the set of disjunctive action landmarks for ⃗o. Thus, we have,
Ω
(cid:88)
Y ≥ [Y⃗ > 0] for all L ∈ LMC (⃗o)
o o Ω
o∈L
Since L is a disjunctive action landmark for ⃗o. Then, every plan that satisfies condi-
tionpre(⃗o)alsosatisfiesL. Asthes-planπ satisfiespre(⃗o),thenthes-planπ alsosatisfiesL.
Therefore, the counts included in π are sufficient to satisfy LMC . Thus,
Ω
hIP (s) ≤ hLMCΩ ≤ cost(π) = h∗ (s). (10)
s∗,Ω Ω,s∗ s∗,Ω
Theorem 3 ensures that the value of the hLMCΩ heuristic never overestimates the true
Ω,s∗
cost of a plan that complies with all observations within the margin ϵ of observation er-
ror. This guarantee provides the resulting goal recognition approaches with two important
properties. First, if hLMCΩ(s) = ∞ for a goal hypothesis s∗, then any state compatible
Ω,s∗
with this goal hypothesis is unreachable, and thus a recognition approach can safely filter
this hypothesis out. Second, our lower bound guarantees that the difference between the
heuristic we compute and the actual cost of an optimal plan (hLMCΩ(s)−h∗ (s)) is never
Ω,s∗ s∗
greaterthanthatbetweenthecostoftheactualobservation-complyingplanandanoptimal
plan (h∗ (s)−h∗ (s)). Thus, our strengthening of the heuristic never erroneously inflates
Ω,s∗ s∗
the operator counts, and thus, whenever two goal hypotheses have similar heuristic values,
their corresponding observation-complying plans will also be similar.
14Goal Recognition via Linear Programming
6. Experiments and Evaluation
This section outlines our empirical evaluation to assess the effectiveness of our goal recogni-
tion constraints in problems that reflect real-world recognition problems. We compare our
novel LP-based approaches against key state-of-the-art approaches in Goal Recognition as
Planning (Ram´ırez & Geffner, 2009, 2010; Pereira et al., 2020).
6.1 Experimental Setting
We conducted extensive empirical experiments to evaluate how the new constraints impact
the quality of the solution. Specifically, we compare the quality of the solutions of our base
approach with observation-counting constraints against our improved approach with new
specific constraints for goal recognition tasks. As we analyze the solution quality of each
approach, we try to better understand how and when these new constraints improve the
solution, as well as the cost and size of the LP models. Finally, we briefly compare our
approaches with the compatible approaches available.
We ran all experiments with Ubuntu over an Intel Core i7 930 CPU (2.80GHz) with a 1
GB memory limit. Our implementation uses Fast Downward version 19.06 (Helmert, 2006),
a Python prepossessing layer, and the CPLEX 12.10 LP solver.2
|Γ| 20.0 8.0 6.7 6.7 7.5 6.3 10.0 6.0 6.0 6.0 8.3 6.0
10% 1.5 1.0 1.8 3.0 1.5 2.2 2.0 2.0 1.7 1.3 2.3 1.7
30% 3.7 2.8 4.2 7.3 3.6 6.0 5.8 5.5 3.7 3.3 6.3 4.0
|Ω| 50% 5.2 4.7 6.5 12.0 5.4 9.7 9.3 8.5 5.7 5.7 10.2 6.2
70% 7.7 6.7 9.2 17.0 7.5 13.5 13.2 11.8 8.0 8.0 14.7 8.8
100% 10.3 9.3 12.3 23.3 10.2 18.8 18.0 16.3 10.7 10.5 20.0 12.2
10% 8.3 3.7 1.3 3.8 2.8 2.8 3.5 2.3 2.3 3.5 2.0 2.7
30% 2.0 1.7 2.0 2.0 1.2 1.3 1.0 1.0 1.2 3.5 1.5 1.3
|Γ∗| 50% 1.2 1.3 1.2 1.3 1.1 1.2 1.0 1.0 1.2 1.7 1.3 1.2
70% 1.2 1.2 1.0 1.2 1.1 1.2 1.2 1.0 1.0 1.5 1.0 1.0
100% 1.2 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.3 1.0 1.0
10% 1.7 1.8 2.2 3.5 1.9 3.0 2.7 3.0 1.8 2.0 3.3 2.0
30% 4.3 4.5 5.7 9.7 5.1 8.5 7.3 7.8 4.3 4.3 8.7 5.5
|Ω| 50% 6.7 6.7 9.0 15.3 8.1 13.7 11.7 12.5 7.0 6.7 13.5 8.3
70% 9.7 9.7 12.7 21.3 11.4 19.2 16.3 17.5 9.8 9.2 19.0 12.0
100% 13.3 13.3 17.3 30.0 15.8 26.8 22.7 24.3 13.3 12.5 26.7 16.5
10% 7.3 1.3 2.2 3.8 1.6 3.0 1.5 1.8 2.5 3.8 1.8 2.2
30% 2.0 1.5 1.3 1.2 1.4 1.2 1.2 1.0 1.3 1.7 1.3 1.2
|Γ∗| 50% 1.2 1.0 1.0 1.2 2.1 1.2 1.0 1.0 1.0 1.7 1.7 1.0
70% 1.5 1.0 1.2 1.2 2.1 1.2 1.0 1.0 1.0 1.3 1.5 1.0
100% 1.2 1.0 1.0 1.0 2.0 1.2 1.0 1.0 1.0 1.3 1.5 1.0
Table 1: Key properties of each experimental domain.
2. Source-code and benchmarks are available at: https://bit.ly/lp-goal-recognition
15
lamitpO
lamitpobuS
skcolb stoped golrevird rwd dirg-cpi yrref scitsigol cinocim srevor etilletas nabokos onezMeneguzzi, Santos, Pereira, & Pereira
For this analysis, we create a new benchmark by adapting the benchmark introduced
by Pereira, Oren, and Meneguzzi (Pereira et al., 2017). We evaluate the approaches pri-
marily by using the agreement ratio evaluation metric from Ram´ırez and Geffner (Ram´ırez
& Geffner, 2009). Recall that Ramirez and Geffner define the agreement ratio as the inter-
section over union |Γ∗ ∩Γ|/|Γ∗ ∪Γ| of the reference solution set Γ∗ against the solution Γ
provided by the approach. We use agreement ratio because it penalizes two key potential
flaws in solutions to goal recognition problems. First, approaches that return many goals
that are not part of the reference solution set, i.e., the approach returns false negatives.
Second, approaches that return few goals that are part of the reference solution set, i.e., the
approachfailstoreturngoalscompatiblewiththeevidence. Thus,usingtheagreement ratio
we have a single metric that accounts for the two most important aspects when evaluating
approaches for solving goal recognition tasks.
For each domain, we create three base planning tasks Π each (except for IPC-Grid,
P
in which we create four) with four reference goals conditions each. For each pair (planning
tasks Π , reference goal condition) we compute a plan from which we extract the sequence
P
of observations. We compute optimal and suboptimal plans for each pair creating two
different data sets. We compute suboptimal plans using weighted A∗ with w = 2 (Pohl,
1970) to emulate bounded rationality.
Following previous work, we build the benchmark data set with five different levels of
observability: 10%, 30%, 50%, 70% and 100%. We only generate one sequence of observa-
tions for 100% of observability, and three different random observation sequences extracted
from the same plan for other observability levels, yielding 208 goal recognition tasks in total
for IPC-Grid and 156 for each one of the other domains in each data set (optimal and
suboptimal). For each data set, we also create an additional corresponding noisy data set
by adding ⌈|Ω|∗0.2⌉ randomly generated observations in each sequence of observations—
i.e., the fault rate of the sensor is 20%. For each goal recognition task we add at least five
randomly generated candidate goal conditions. In total, we have 8,288 goal recognition
tasks divided into four data sets.
We compute the reference solution set Γ∗ for each goal recognition task for optimal and
suboptimal data sets. Thus, for each pair of base planning task and goal candidate, we
compute an optimal plan, and one optimal complying plan for each sequence of observa-
tions of an optimal data set, and one bounded suboptimal plan and bounded suboptimal
complying plan. This a computationally intensive problem, but is performed only once
for the creation of the benchmark dataset. The noisy data sets have the same solution as
their corresponding optimal and suboptimal counterparts. For the optimal data set we use
A∗, whereas for the suboptimal data set we use weighted A∗ with w = cost(π) (following
h∗
s∗
(s0)
R
Definition 8). To ensure replicability and facilitate further research on goal recognition, this
benchmark is available publicly.3
Table 1 summarizes the information about the data sets. The domains we use are
Blocks,Depots,Driverlog,DWR,IPC-Grid,Ferry,Logistics,Miconic,Rovers,
Satellite, Sokoban and Zeno. For each domain row, |Γ| represents the average number
of candidate goals. Columns |Ω| and |Γ∗| show the average size of the observations and the
reference solution set, respectively. The average size of the plan with 100% of observability
3. At https://github.com/luisaras/goal-plan-recognition-dataset
16Goal Recognition via Linear Programming
indicates the size of the plan computed for the reference goal. As expected, the average
sizes |Ω| and |Γ∗| are larger for the suboptimal data set than for the optimal data set.
6.2 Evaluation and Comparison of the Novel LP-Based Approaches
In what follows, we evaluate our extensions to the LP heuristic with Landmark Constraints
(hLMCΩ) and compare it to its “basic” version (hLMC). Tables 2 and 3 summarize these
Ω,s∗ Ω
results. Tables 2a–2c summarize the results over all domains for “simplified” problems,
that is problems that do not include suboptimal or noisy observations. More specifically:
Table 2a shows results for the data set with noise-free observations from optimal plans;
Table 2b shows results for the data set with noise-free observations from suboptimal plans,
and Table 2c shows results from the data set with noisy observations from optimal plans.
By contrast, Table 3 shows results for the hardest version of the goal recognition problems,
which consist of observations generated from suboptimal plans with added noise. For both
noisy data sets, we use a noise filter (see Section 4) of ϵ = 0.2. Each table compares the
heuristics across five metrics: Agr is the average agreement ratio for that set of problems;
h is the average value of that version of the heuristic for the reference goal; Rows denote
Ω
the average number of constraints (i.e., rows) in the LP responsible for computing the
heuristic; the total time is the time, in seconds, including both the Fast Downward and
Python calls; and LP time is the time to solve the LP in the Fast Downward after all the
pre-processing.
In the simplest variation of the data set from Table 2a, the hLMCΩ heuristic dominates
Ω,s∗
the basic hLMC heuristic, at the cost of roughly double the number of constraints in the
Ω
LP. Nevertheless, these additional constraints do not lead to a commensurate increasing in
computational time in the recognition time. We observe a similar behavior for the hLMCΩ
Ω,s∗
in the suboptimal data set from Table 2b. Interestingly, the improvement in agreement
for suboptimal plans seems to be more pronounced at lower levels of observability. This
improvement stems primarily from the inclusion of extra landmarks constraints derived
from the observations. We can clearly see this increase in the total number of rows of the
LP, which increases as a function of the observability level (i.e., the more observations,
the more constraints). When these observations are noise-free, they compensate for the
lower probability with which partial observations might intersect with the landmarks of
the planning problems corresponding to each goal hypothesis. Indeed, this points to our
novel approach overcoming a known limitation of the landmark-based recognition approach
from Pereira et al. (2020). For the optimal, but noisy data set, not only does the hLMCΩ
Ω,s∗
heuristic dominate hLMC, it also consistently outperforms hLMC in agreement. While the
Ω Ω
computational cost of the resulting LP seems to increase more substantially, this additional
cost is still negligible compared to the total cost of the recognition process.
Finally, we provide an analysis of the results for noisy observations from suboptimal
plans inTable3 segmented by thedifferent problem domains paints amore complex picture
of our results. While the value of the hLMCΩ heuristic still dominates hLMC across the
Ω,s∗ Ω
board, its has a less pronounced impact on agreement ratio, depending on the domain.
This is especially true for the blocks world domain. In summary for all benchmarks, the
additional constraints either improve the agreement ratio overall, or tie with the base hLMC
Ω
heuristic. These improvements come at a doubling of the number of constraints and a very
17Meneguzzi, Santos, Pereira, & Pereira
hLMC hLMCΩ
Ω Ω,s∗
Time Time
# % Agr hΩ RowsTotal LP Agr hΩ RowsTotal LP
10% 0.69 11.2 14.9 0.62 0.010.7111.4 19.4 0.62 0.01
30% 0.67 11.8 17.6 0.62 0.010.7312.1 29.3 0.63 0.01
50% 0.75 12.3 20.2 0.62 0.010.7812.8 39.0 0.63 0.02
70% 0.84 13.1 23.1 0.62 0.010.8613.5 49.7 0.63 0.02
100%0.9114.3 26.6 0.62 0.010.9114.3 62.7 0.63 0.02
AVG 0.77 12.5 20.5 0.62 0.010.8012.8 40.0 0.63 0.02
(a) Results for optimal noise-free observations.
hLMC hLMCΩ
Ω Ω,s∗
Time Time
# % Agr hΩ RowsTotal LP Agr hΩ RowsTotal LP
10% 0.6 11.6 15.4 0.62 0.010.6611.7 21.6 0.62 0.01
30% 0.67 12.8 18.9 0.62 0.010.7313.2 34.7 0.63 0.01
50% 0.73 14.3 22.0 0.62 0.010.7614.7 45.9 0.63 0.02
70% 0.82 16.3 25.1 0.62 0.010.8316.6 58.0 0.63 0.02
100%0.8819.3 28.9 0.62 0.010.8819.3 72.6 0.64 0.02
AVG 0.74 14.9 22.1 0.62 0.010.7715.1 46.6 0.63 0.02
(b) Results for suboptimal noise-free observations.
hLMC hLMCΩ
Ω Ω,s∗
Time Time
# % Agr hΩ RowsTotal LP Agr hΩ RowsTotal LP
10% 0.4811.2 15.5 0.62 0.010.4911.3 22.7 0.62 0.01
30% 0.5111.6 18.5 0.62 0.010.5511.9 33.8 0.63 0.01
50% 0.6212.0 21.5 0.62 0.010.6812.4 45.0 0.63 0.02
70% 0.7912.5 24.8 0.62 0.010.8112.9 57.6 0.63 0.02
100%0.8713.6 28.9 0.62 0.010.8813.6 74.0 0.64 0.03
AVG 0.6612.2 21.8 0.62 0.010.6812.4 46.6 0.63 0.02
(c) Results for noisy observations (optimal plans).
Table 2: Aggregated average results using the Landmark constraints.
18Goal Recognition via Linear Programming
hLMC hLMCΩ
Ω Ω,s∗
Time Time
# % Agr hΩ RowsTotal LP Agr hΩ RowsTotal LP
10 0.35 6.3 10.2 1.46 0.020.37 6.4 14.3 1.46 0.02
30 0.38 7.3 12.5 1.46 0.02 0.35 7.4 19.2 1.47 0.03
50 0.45 7.5 14.7 1.46 0.02 0.42 7.7 23.6 1.47 0.03
70 0.44 9.4 17.5 1.46 0.02 0.43 9.6 30.4 1.48 0.03
1000.5611.1 20.7 1.46 0.02 0.54 11.1 38.3 1.48 0.04
10 0.30 6.8 10.2 0.62 0.010.37 7.1 14.5 0.62 0.01
30 0.32 7.1 12.8 0.62 0.010.40 7.9 22.9 0.62 0.01
50 0.38 8.7 14.9 0.62 0.010.65 9.6 30.6 0.63 0.01
70 0.66 10.2 17.4 0.62 0.010.7710.6 38.3 0.63 0.02
100 0.9 12.8 20.0 0.62 0.010.9312.8 46.9 0.63 0.02
10 0.38 10.1 14.4 0.47 0.010.4010.2 22.7 0.47 0.01
30 0.44 10.6 18.1 0.47 0.010.5511.4 37.0 0.47 0.01
50 0.51 11.9 21.1 0.47 0.010.6012.4 48.4 0.48 0.01
70 0.7013.2 24.6 0.47 0.01 0.69 13.6 61.2 0.48 0.01
100 0.65 16.2 28.9 0.47 0.010.6816.2 79.2 0.48 0.02
10 0.4411.3 16.5 0.54 0.01 0.41 11.6 28.2 0.55 0.01
30 0.3714.1 21.9 0.54 0.01 0.35 15.1 52.2 0.55 0.02
50 0.38 16.9 26.2 0.54 0.010.4517.8 74.4 0.56 0.02
70 0.54 21.0 29.9 0.54 0.010.5921.9 91.7 0.56 0.03
100 0.73 27.0 35.3 0.54 0.010.7827.0 120.3 0.57 0.03
10 0.68 11.3 15.1 0.58 0.010.7711.3 28.8 0.58 0.01
30 0.7712.1 18.5 0.58 0.010.7712.2 50.0 0.59 0.01
50 0.8812.7 21.5 0.58 0.010.8812.8 68.4 0.59 0.02
70 0.9014.3 24.8 0.58 0.010.9014.4 88.5 0.59 0.02
1000.9416.6 28.1 0.58 0.010.9416.6 110.2 0.59 0.02
10 0.37 14.0 19.4 0.40 0.010.3814.0 25.8 0.40 0.01
30 0.5115.6 25.1 0.40 0.010.5115.6 40.0 0.40 0.01
50 0.8118.5 29.7 0.40 0.010.8118.5 52.6 0.40 0.01
70 0.8721.4 34.0 0.40 0.010.8721.4 64.6 0.40 0.01
1000.9426.4 39.4 0.40 0.010.9426.4 80.4 0.40 0.01
10 0.59 17.0 21.8 0.69 0.010.6217.0 33.8 0.69 0.01
30 0.8417.4 26.5 0.69 0.010.8417.4 56.2 0.70 0.02
50 0.9518.1 30.9 0.69 0.010.9518.1 76.4 0.70 0.02
70 0.94 19.8 35.4 0.69 0.010.9619.9 96.9 0.71 0.02
100 1.0 22.2 41.1 0.69 0.01 1.0 22.3 122.8 0.71 0.03
10 0.46 15.9 21.8 0.43 0.010.5415.9 26.5 0.43 0.01
30 0.72 16.6 27.0 0.43 0.010.8016.8 38.3 0.43 0.01
50 0.86 17.6 32.0 0.43 0.010.9317.6 48.9 0.43 0.01
70 0.90 19.4 36.8 0.43 0.010.9319.5 60.0 0.44 0.02
100 1.0 23.0 43.0 0.43 0.01 1.0 23.0 74.3 0.44 0.02
10 0.54 9.7 14.1 0.47 0.01 0.52 9.9 17.8 0.47 0.01
30 0.65 10.2 16.9 0.47 0.010.6610.5 24.4 0.47 0.01
50 0.85 10.6 19.7 0.47 0.010.8611.1 31.4 0.48 0.01
70 0.9611.9 22.1 0.47 0.01 0.94 12.3 36.9 0.47 0.01
100 1.0 13.0 25.7 0.47 0.01 1.0 13.0 46.4 0.48 0.01
10 0.51 10.1 14.7 0.40 0.010.5210.2 19.9 0.41 0.01
30 0.55 10.3 17.1 0.40 0.010.5910.4 26.0 0.41 0.01
50 0.71 10.7 20.3 0.41 0.010.7710.9 35.6 0.41 0.01
70 0.87 11.1 22.9 0.41 0.010.8911.3 41.6 0.41 0.01
1000.9712.3 26.1 0.41 0.010.9712.3 51.2 0.41 0.01
10 0.27 15.1 20.4 0.9 0.020.3015.2 41.6 0.91 0.03
30 0.32 16.8 26.4 0.90 0.020.4017.9 81.0 0.93 0.06
50 0.43 19.0 31.6 0.90 0.020.5020.4 120.3 0.95 0.08
70 0.5721.4 37.4 0.90 0.02 0.54 22.5 154.6 0.98 0.10
100 0.70 25.7 44.2 0.90 0.020.7325.7 207.1 1.0 0.12
10 0.43 10.0 14.8 0.51 0.010.5010.1 20.5 0.51 0.01
30 0.61 10.8 18.4 0.51 0.010.7011.1 31.3 0.51 0.01
50 0.82 11.4 21.5 0.51 0.010.8611.8 41.2 0.52 0.02
70 0.9313.2 24.9 0.51 0.01 0.92 13.5 51.9 0.52 0.02
100 0.92 15.5 29.5 0.51 0.010.9415.5 65.3 0.52 0.02
AVG 0.66 14.3 23.8 0.62 0.010.6914.6 54.7 0.63 0.02
Table 3: Results and comparison per domain for the Landmark constraints on suboptimal
and noisy observations.
19
skcolb
stoped
golrevird
rwd
dirg-cpi
yrref
scitsigol
cinocim
srevor
etilletas
nabokos
onezMeneguzzi, Santos, Pereira, & Pereira
small increase in the cost of solving the corresponding LP in most domains. Nevertheless,
problems in the Sokoban domain show a pronounced increase in the size of the LP, this is
likelyduetothenumberofdisjunctivelandmarksinducedbythegridsettingfromSokoban.
We note that the behavior we describe for Table 3 is similar across the domains in the data
set we summarize Table 2.
10% 30% 50% 70% 100%
6855/7545/0 9545/4855/0 10139/4261/0 9423/4977/0 4933/4667/0
hLMC
Ω
Figure 4: Scatter plot comparing the heuristic values of hLMC with hLMCΩ, for observability
Ω Ω,s∗
levels 10%, 30%, 50%, 70% and 100%. We take into consideration all goal hypotheses from
all instances, and all four data sets. Red indicates the value for the reference goal, blue
indicates the value for all other goal hypotheses.
We use scatter plots to better visualize the behavior of each heuristic. Figure 4, contain
four scatter plots, one for each observability ratio (10%, 30%, 50%, 70%, 100%) illustrating
thevaluesofthehLMCΩ/hLMC heuristicsforboththereferencegoal(inred),andforallother
Ω,s∗ Ω
goal hypotheses. The x-axis is the value of the basic heuristic without our modifications,
and in the y-axis is the value of the modified heuristic. Each point in the plot is one goal
candidate, for all candidates in all instances of all domains combined, and below each plot
we show three numbers separated by a “/”: number of points above the diagonal, on the
diagonal, and below it. For all problems, the value of hLMCΩ dominates hLMC as indicated
Ω,s∗ Ω
by all points being above the diagonal. Importantly, most red points (correct hypotheses)
concentrate toward the left of the point cloud and above the corresponding blue points
(incorrect hypotheses). This indicates that the value of hLMCΩ dominates hLMC, which
Ω,s∗ Ω
suggests that the value of hLMCΩ increases more for incorrect hypotheses than for correct
Ω,s∗
ones, and thus helps in differentiating goals. As we increase observability, the point cloud
flattens towards the diagonal, indicating that the additional constraints from hLMCΩ yield
Ω,s∗
values closer to the previous hLMC heuristic, which is an expected result.
Ω
Finally,whiletheagreementratiofromtheexperimentsinthissectionarelowerthanfor
the version of our framework in (Santos et al., 2021) that combines the constraints for State
Equation and the original Landmarks constraints from Definition 3, shown in the columns
labeled “S,L” in (Santos et al., 2021). However, the comparable columns to our results in
this paper are the ones labelled “L” alone, which correspond to the columns labeled ‘LMC’
inthisarticle. Indeed, thispaperdeliberatelychoosestofocusonthelandmarksconstraints
in order to explore the theoretical properties of linear programming constraints within our
framework. As expected, adding all the sources of constraints from that paper strengthens
our heuristic and thus yield a similar gain in recognition accuracy.
20
ΩCMLh
∗s,ΩGoal Recognition via Linear Programming
RG POM hLMCΩ RG POM hLMCΩ
Ω,s∗ Ω,s∗
# % Agr Time Agr Time Agr Time # % Agr Time Agr Time Agr Time
10% 0.71 0.18 0.37 0.0 0.71 0.62 10% 0.25 0.16 0.26 0.0 0.49 0.62
30% 0.69 0.21 0.61 0.0 0.73 0.63 30% 0.31 0.17 0.48 0.0 0.55 0.63
50% 0.76 0.25 0.73 0.0 0.78 0.63 50% 0.35 0.17 0.63 0.0 0.68 0.63
70% 0.82 0.33 0.85 0.0 0.86 0.63 70% 0.43 0.2 0.78 0.0 0.81 0.63
100% 0.89 0.48 0.93 0.0 0.91 0.63 100% 0.42 0.21 0.89 0.0 0.88 0.63
AVG 0.77 0.29 0.70 0.0 0.80 0.63 AVG 0.35 0.18 0.61 0.0 0.68 0.63
(a) Non-noisy observations (optimal plans). (b) Noisy observations (optimal plans).
Table 4: Results for baseline approaches (RG and POM) and hLMCΩ for optimal data sets.
Ω,s∗
RG POM hLMCΩ
Ω,s∗
# % Agr Time Agr Time Agr Time
10% 0.60 0.19 0.42 0.0 0.66 0.62
30% 0.67 0.22 0.63 0.0 0.73 0.63
50% 0.74 0.29 0.74 0.0 0.76 0.63
70% 0.81 0.42 0.83 0.0 0.83 0.63
100% 0.86 0.71 0.90 0.0 0.88 0.64
AVG 0.74 0.37 0.70 0.0 0.77 0.63
Table 5: Results for baseline approaches (RG and POM) and hLMCΩ for suboptimal-plan
Ω,s∗
data sets and non-noisy observations.
6.3 Comparison with Previous Recognition Approaches
In order to assess the effectiveness of our Linear Programming approaches, we have run
two goal recognition approaches that serve as baselines for performance. Specifically, we
use a Classical Planning approach (Ram´ırez & Geffner, 2010) and recent state-of-the-art
approaches that rely on landmarks (Pereira et al., 2020). The approach from Ram´ırez and
Geffner (2010) which computes the solution set using a translation of the recognition prob-
lem into a Classical Planning and a modified search procedure to compute cost differences
between an optimal plan and a complying plan. We refer to this approach as RG on the
tables. At a high level, their approach is similar to ours in that they compare the costs
of complying and non-complying plans. While they compute the actual cost of such plans,
we instead approximate the costs using our operator counting framework without actually
computing a complete plan. By contrast, the recent state of the art of Pereira et al. (2020)
is similar to our approach in its avoidance of searching for full plans, and instead, it relies
on counting observed landmarks on the observations, weighing them by their information
value. We refer to this approach as POM in the tables. Each of these baselines provides
distinct advantages to the goal recognition process. While RG provides superior agreement
ratios on noise-free as well as in low-observability settings, POM is orders of magnitude
faster and more robust to noise. The superior agreement ratio from RG, especially in low
observability settings is largely due to its computation of complete plans, with its resulting
ofinformationqualityavailableforinference. Bycontrast,POMavoidstheexpensivesearch
procedure by relying on observing delete-relaxed landmarks. However, in low-observability
21Meneguzzi, Santos, Pereira, & Pereira
settings, if the recognizer does not observe landmarks, the accuracy of the goal inference
decreases substantially.
Tables 4–5 show the results for these approaches in the same data sets used in Sec-
tion 6.2. For convenience, we replicate the column showing our improved approach from
Tables 2–3, so the reader can compare them side by side. We can see that, on average,
the new approaches dominate both baselines in terms of agreement ratio when averaged
across domains. While it does not have the same dramatic runtime advantage as the POM
approach, it achieves a 2x speedup over the RG approach. Nevertheless, its agreement ra-
tio at low observability and noisy settings is substantial in most domains. Ultimately, the
additional information we include in the LP over simply observing landmarks as POM does
prove advantageous. Similarly, computing the additional information is computationally
more efficient than the full search performed by RG, even accounting for the extra effort in
the LP to find noise-coping operator counts.
7. Related Work
Seminal work on Goal and Plan Recognition rely on the plan-library formalism (Kautz &
Allen,1986;Charniak&Goldman,1993;Goldman,Geib,&Miller,1999),i.e.,ahierarchical
formalism (i.e., “hierarchical recipe”) that defines a collection of plans to achieve a set of
goals or tasks. Existing library-based approaches employ different types of hierarchical
formalisms for recognizing goals and plans, such as context-free grammars (Pynadath &
Wellman, 2000; Geib & Goldman, 2009), HTN-like formalisms using entropy and query
methods (Avrahami-Zilberbrand & Kaminka, 2005; Mirsky, Stern, Gal, & Kalech, 2016,
2018), purely HTN planning (H¨oller, Behnke, Bercher, & Biundo, 2018), etc.
Hong (2000, 2001) veers away from the conventional reliance on plan-libraries for rec-
ognizing goals and plans. They instead formalize recognition problems using a planning
domain theory, a notably more flexible formalism to formalize the knowledge of how to
achieve goals. Similarly, Ram´ırez and Geffner (2009, 2010) adopt planning domain theory
forrecognizinggoalsandplans,anddevelopedarobustprobabilisticframeworkthatenables
the use of off-the-shelf planning techniques to perform the recognition process. The work of
Ram´ırezandGeffner(2009,2010)wasinstrumentalinshapingthelandscapeofPlan Recog-
nition and Planning, laying the groundwork for subsequent research in this field. Inspired
by Plan Recognition and Planning, AUTOGRAPH (AUTOmatic Goal Recognition with A
Planning Heuristic) from Pattison and Long (2010) is a probabilistic heuristic-based recog-
nition approach able to recognize goals without exhaustively enumerating goal hypotheses.
E-Mart´ın et al. (2015) developed a planning-based goal recognition approach that prop-
agates cost and interaction information in a planning graph, and uses this information
to compute posterior probabilities for a set of possible goals. The approach of E-Mart´ın
et al. (2015) stands out as the pioneering in the literature that obviates calling a planner
to perform the recognition task, resulting in a very fast recognition approach. Sohrabi
et al. (2016) extended the probabilistic framework of Ram´ırez and Geffner (2010), and
developed a novel probabilistic recognition approach that deals explicitly with unreliable
and spurious observations (i.e., noisy or missing observations), and is able to recognize
both goals and plans. Their approach computes multiple high-quality plans (using a top-
K planner that generates multiple K plans) to compute posterior probabilities over the
22Goal Recognition via Linear Programming
goals. Vered et al. (2016) introduced the concept of Mirroring in the context of online goal
recognition. Pereira et al. (2017, 2020) developed recognition approaches that rely on the
concept of landmarks, and like the approach of E-Mart´ın et al. (2015), such landmark-based
approaches abstain from using a full-fledged planning process for the recognition process,
yielding in very fast and yet accurate recognition approaches. Our approaches draw in-
spiration from the landmark-based approaches of Pereira et al. (2017, 2020), but notably,
the main difference is that our LP-based approaches rely on much “stronger” constraints,
i.e., operator-counting constraints, induced by the given observations and goal hypothesis.
Advances in Plan Recognition as Planning expanded to other planning settings and envi-
ronments with different assumptions. These include path-planning recognition (Masters &
Sardin˜a, 2017; Masters & Sardina, 2019a), the recognition of plans and goals in continuous
domain models (Vered et al., 2016; Vered & Kaminka, 2017; Vered, Pereira, Magnaguagno,
Kaminka,&Meneguzzi, 2018; Kaminka, Vered,&Agmon, 2018), goalrecognitioninincom-
plete and possibly incorrect domain models (Pereira & Meneguzzi, 2018; Pereira, Pereira, &
Meneguzzi, 2019a), recognition of goals for boundedly rational and irrational agents (Mas-
ters & Sardina, 2019b; Zhi-Xuan, Mann, Silver, Tenenbaum, & Mansinghka, 2020), recog-
nition of temporally extended goals (Pereira, Fuggitti, Meneguzzi, & Giacomo, 2023), and
recognition of goals with timing information (Zhang, Kemp, & Lipovetzky, 2023).
Recent cutting-edge developments in Machine Learning have extended their influence
into Goal and Plan Recognition, leading to the emergence of model-free recognition ap-
proaches. Amado, Pereira, Aires, Magnaguagno, Granada, and Meneguzzi (2018) extends
the latent-space planning architecture of Asai and Fukunaga (2018) for goals recogni-
tion in image-based domain models using off-the-shelf recognition approaches. Pereira,
Vered, Meneguzzi, and Ram´ırez (2019b) developed recognition approaches in continuous
control models with approximate transition functions, addressing the influence of inaccu-
racies (imperfections) in learned control models on the effectiveness of recognizing goals.
Polyvyanyy, Su, Lipovetzky, and Sardin˜a (2020) employs process mining techniques for
“model-approximate”recognition,involvingtheextractionofcrucialinformationfromevent
logs and traces to discover models for recognizing goals. This work inspired recent research
on process mining for goal recognition, such as Su, Polyvyanyy, Lipovetzky, Sardin˜a, and
van Beest (2023), and the usage of probabilistic trace alignment for goal recognition (Ko,
Maggi, Montali, Pen˜aloza, & Pereira, 2023). The approach from Shvo, Li, Icarte, and
McIlraith (2021) learns interpretable sequence classifiers using finite state automata in
which they show that such an approach can be used for both recognizing goals and be-
havior classification. GRAQL (Goal Recognition as Q-Learning) from Amado, Mirsky, and
Meneguzzi (2022) uses learned Q-values instead of explicit goals from traditional recogni-
tion approaches. The recognition process involves minimizing the distance between obser-
vation sequences and the Q-values of the goal hypotheses’ policies. Amado, Pereira, and
Meneguzzi (2023) develop an approach that combines learning statistical prediction and
symbolic reasoning for performing the tasks of goal and plan recognition simultaneously.
Finally, Chiari, Gerevini, Percassi, Putelli, Serina, and Olivato (2023) frame the task of
goal recognition as a classification task using the Long Short-Term Memory (LSTM) recur-
rent Deep Neural Network.
23Meneguzzi, Santos, Pereira, & Pereira
RG POM hLMCΩ
Ω,s∗
# % Agr Time Agr Time Agr Time
10 0.42 0.3 0.05 0.0 0.37 1.46
30 0.49 0.33 0.22 0.0 0.35 1.47
50 0.55 0.4 0.28 0.0 0.42 1.47
70 0.63 0.53 0.38 0.0 0.43 1.48
100 0.74 0.76 0.51 0.0 0.54 1.48
10 0.02 0.05 0.17 0.0 0.37 0.62
30 0.07 0.06 0.21 0.0 0.40 0.62
50 0.01 0.05 0.51 0.0 0.65 0.63
70 0.00 0.05 0.54 0.0 0.77 0.63
100 0.01 0.05 0.83 0.0 0.93 0.63
10 0.21 0.07 0.23 0.0 0.40 0.47
30 0.28 0.08 0.45 0.0 0.55 0.47
50 0.12 0.07 0.54 0.0 0.60 0.48
70 0.22 0.08 0.64 0.0 0.69 0.48
100 0.19 0.08 0.58 0.0 0.68 0.48
10 0.23 0.12 0.33 0.0 0.41 0.55
30 0.09 0.18 0.56 0.0 0.35 0.55
50 0.11 0.23 0.75 0.0 0.45 0.56
70 0.10 0.14 0.69 0.0 0.59 0.56
100 0.03 0.17 0.88 0.0 0.78 0.57
10 0.12 0.07 0.54 0.0 0.77 0.58
30 0.08 0.07 0.72 0.0 0.77 0.59
50 0.04 0.05 0.85 0.0 0.88 0.59
70 0.02 0.05 0.90 0.0 0.90 0.59
100 0.04 0.05 0.92 0.0 0.94 0.59
10 0.31 0.06 0.26 0.0 0.38 0.40
30 0.47 0.08 0.44 0.0 0.51 0.40
50 0.66 0.14 0.69 0.0 0.81 0.40
70 0.70 0.26 0.78 0.0 0.87 0.40
100 0.71 0.60 0.82 0.0 0.94 0.40
10 0.28 0.16 0.41 0.0 0.62 0.69
30 0.12 0.07 0.81 0.0 0.84 0.70
50 0.03 0.06 0.90 0.0 0.95 0.70
70 0.00 0.06 0.99 0.00 0.96 0.71
100 0.00 0.06 1.0 0.0 1.0 0.71
10 0.47 0.09 0.35 0.0 0.54 0.43
30 0.64 0.12 0.69 0.0 0.80 0.43
50 0.87 0.16 0.93 0.0 0.93 0.43
70 0.98 0.23 0.94 0.0 0.93 0.44
100 1.0 0.4 1.0 0.0 1.0 0.44
10 0.37 0.07 0.44 0.0 0.52 0.47
30 0.40 0.08 0.51 0.0 0.66 0.47
50 0.49 0.08 0.72 0.0 0.86 0.48
70 0.26 0.07 0.89 0.0 0.94 0.47
100 0.34 0.09 0.90 0.0 1.0 0.48
10 0.41 0.06 0.29 0.0 0.52 0.41
30 0.54 0.07 0.51 0.0 0.59 0.41
50 0.61 0.08 0.66 0.0 0.77 0.41
70 0.63 0.09 0.78 0.0 0.89 0.41
100 0.47 0.09 0.92 0.0 0.97 0.41
10 0.13 0.71 0.25 0.01 0.30 0.91
30 0.12 0.56 0.29 0.01 0.40 0.93
50 0.01 0.86 0.46 0.01 0.50 0.95
70 0.06 1.38 0.58 0.01 0.54 0.98
100 0.04 0.79 0.77 0.01 0.73 1.0
10 0.45 0.13 0.31 0.0 0.50 0.51
30 0.61 0.15 0.57 0.0 0.70 0.51
50 0.75 0.18 0.73 0.0 0.86 0.52
70 0.82 0.23 0.89 0.0 0.92 0.52
100 0.85 0.32 0.90 0.0 0.94 0.52
AVG 0.34 0.21 0.61 0.0 0.69 0.63
Table6: Comparisonwithbaselineapproachesforsuboptimalplansandnoisyobservations.
24
skcolb
stoped
golrevird
rwd
dirg-cpi
yrref
scitsigol
cinocim
srevor
etilletas
nabokos
onezGoal Recognition via Linear Programming
8. Conclusions
In this article, we develop a comprehensive framework for goal recognition based on Linear
Programming constraints for goal recognition. Specifically, we build upon the Operator-
Counting framework from Pommerening et al. (2014), which our previous work adapted for
goal recognition problems (Santos et al., 2021). Our key contributions are threefold. First,
we provided a comprehensive theoretical characterization of Operator-Counting heuristics
for goal recognition, proving key properties which our previous work only intuited. Sec-
ond, we expanded the basic Operator-Counting constraints with new sets of constraints
for Landmarks in Goal Recognition (Pereira et al., 2020) that allow our goal recognition
approaches to improve their accuracy. Third, we comprehensively study the properties
of various sources of constraints in an expanded benchmark. This expanded benchmark
and additional analyses help us understand the contribution of various types of additional
constraints to the goal recognition process.
This article substantially deepens our understanding of landmark-based constraints,
however, there substantial scope for further work. Specifically, while our seminal work on
operatorcountingconstraintsforgoalrecognitionusesvarioussourcesofOperator-Counting
constraints,includingstate-equation constraints(Bonet,2013),post-hoc optimization(Pom-
merening et al., 2013) and landmarks (Bonet & van den Briel, 2014), this article focuses on
landmark constraints. This is motivated by our earlier findings that landmark constraints
contribute more towards goal recognition tasks than other sources of constraints (Santos
etal., 2021). Thus, ourfutureworkconsistsofadeeperinvestigationonvariousrefinements
of such constraint types for goal recognition heuristics.
Acknowledgments
Felipe Meneguzzi acknowledges support from CNPq with projects 407058/2018-4 (Uni-
versal) and 302773/2019-3 (PQ Fellowship). Andr´e G. Pereira acknowledges support from
FAPERGS with project 17/2551-0000867-7. This study was financed in part by the Coor-
dena¸c˜ao de Aperfeic¸oamento de Pessoal de N´ıvel Superior — Brasil (CAPES) — Finance
Code 001.
References
Amado,L.,Mirsky,R.,&Meneguzzi,F.(2022). Goalrecognitionasreinforcementlearning.
In Proceedings of the AAAI Conference on Artificial Intelligence.
Amado, L., Pereira, R. F., Aires, J. P., Magnaguagno, M. C., Granada, R., & Meneguzzi, F.
(2018). Goal recognition in latent space. In International Joint Conference on Neural
Networks (IJCNN).
Amado, L., Pereira, R. F., & Meneguzzi, F. (2023). Robust neuro-symbolic goal and plan
recognition. In Proceedings of the AAAI Conference on Artificial Intelligence.
Asai, M., & Fukunaga, A. (2018). Classical planning in deep latent space: Bridging the
subsymbolic-symbolic boundary. In Proceedings of the AAAI Conference on Artificial
Intelligence.
25Meneguzzi, Santos, Pereira, & Pereira
Avrahami-Zilberbrand, D., & Kaminka, G. A. (2005). Fast and complete symbolic plan
recognition. In Proceedings of the International Joint Conference on Artificial Intel-
ligence (IJCAI).
B¨ackstr¨om, C., & Nebel, B. (1993). Complexity Results for SAS+ Planning.. In Interna-
tional Joint Conference on Artificial Intelligence.
Bonet, B. (2013). An admissible heuristic for SAS+ planning obtained from the state
equation. In International Joint Conference on Artificial Intelligence, pp. 2268–2274.
Bonet, B., & van den Briel, M. (2014). Flow-based heuristics for optimal planning: Land-
marks and merges. In International Conference on Automated Planning and Schedul-
ing, pp. 47–55.
Charniak,E.,&Goldman,R.P.(1993). Abayesianmodelofplanrecognition. Artif. Intell.,
64(1), 53–79.
Chiari, M., Gerevini, A. E., Percassi, F., Putelli, L., Serina, I., & Olivato, M. (2023). Goal
recognition as a deep learning task: The grnet approach. In Proceedings of the Inter-
national Conference on Automated Planning and Scheduling (ICAPS).
E-Mart´ın, Y., R.-Moreno, M. D., & Smith, D. E. (2015). A Fast Goal Recognition Tech-
nique Based on Interaction Estimates. In International Joint Conference on Artificial
Intelligence.
Geib, C. W., & Goldman, R. P. (2009). A probabilistic plan recognition algorithm based
on plan tree grammars. Artif. Intell., 173(11), 1101–1132.
Goldman, R. P., Geib, C. W., & Miller, C. A. (1999). A new model of plan recognition. In
Laskey, K. B., & Prade, H. (Eds.), UAI ’99: Proceedings of the Fifteenth Conference
on Uncertainty in Artificial Intelligence, Stockholm, Sweden, July 30 - August 1, 1999,
pp. 245–254. Morgan Kaufmann.
Helmert, M. (2006). The Fast Downward planning system. Journal of Artificial Intelligence
Research, 26, 191–246.
Hoffmann, J., Porteous, J., & Sebastia, L. (2004). Ordered landmarks in planning. Journal
of Artificial Intelligence Research, 22, 215–278.
Hong, J. (2000). Plan recognition through goal graph analysis. In Horn, W. (Ed.), Proceed-
ings of the 14th European Conference on Artificial Intelligence (ECAI).
Hong,J.(2001). Goalrecognitionthroughgoalgraphanalysis.JournalArtificialIntelligence
Research, 15, 1–30.
H¨oller, D., Behnke, G., Bercher, P., & Biundo, S. (2018). Plan and goal recognition as htn
planning. In International Conference on Tools with Artificial Intelligence.
Imai, T., & Fukunaga, A. (2014). A Practical, Integer-Linear Programming Model for the
Delete-Relaxation in Cost-Optimal Planning.. In European Conference on Artificial
Intelligence.
Kaminka, G. A., Vered, M., & Agmon, N. (2018). Plan recognition in continuous domains.
In Proceedings of the AAAI Conference on Artificial Intelligence.
26Goal Recognition via Linear Programming
Kautz, H. A., & Allen, J. F. (1986). Generalized plan recognition. In Proceedings of the
National Conference on Artificial Intelligence.
Ko,J.,Maggi,F.M.,Montali,M.,Pen˜aloza,R.,&Pereira,R.F.(2023). Planrecognitionas
probabilistictracealignment. InInternationalConferenceonProcessMining(ICPM).
Masters,P.,&Sardin˜a,S.(2017). Cost-basedgoalrecognitionforpath-planning. InProceed-
ings of the Conference on Autonomous Agents and MultiAgent Systems (AAMAS).
Masters, P., & Sardina, S. (2019a). Cost-based Goal Recognition in Navigational Domains.
Journal of Artificial Intelligence Research, 64, 197–242.
Masters, P., & Sardina, S. (2019b). Goal recognition for rational and irrational agents. In
International Conference on Autonomous Agents and MultiAgent Systems (AAMAS).
Mirsky,R.,Stern,R.,Gal,K.,&Kalech,M.(2018). Sequentialplanrecognition:Aniterative
approach to disambiguating between hypotheses. Artificial Intelligence, 260, 51–73.
Mirsky, R., Stern, R., Gal, Y. K., & Kalech, M. (2016). Sequential plan recognition. In
Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI).
Pattison, D., & Long, D. (2010). Domain independent goal recognition. In Proceedings of
the Fifth Starting AI Researchers.
Pereira, R. F., Fuggitti, F., Meneguzzi, F., & Giacomo, G. D. (2023). Temporally extended
goal recognition in fully observable non-deterministic domain models. Applied Intel-
ligence, To Appear, –.
Pereira, R. F., & Meneguzzi, F. (2018). Goal Recognition in Incomplete Domain Models.
In AAAI.
Pereira, R. F., Oren, N., & Meneguzzi, F. (2017). Landmark-based heuristics for goal
recognition. In AAAI Conference on Artificial Intelligence.
Pereira, R. F., Oren, N., & Meneguzzi, F. (2020). Landmark-based approaches for goal
recognition as planning. Artificial Intelligence, 279, 103217.
Pereira, R. F., Pereira, A. G., & Meneguzzi, F. (2019a). Landmark-enhanced heuristics for
goal recognition in incomplete domain models. In ICAPS.
Pereira, R. F., Vered, M., Meneguzzi, F., & Ram´ırez, M. (2019b). Online probabilistic goal
recognitionovernominalmodels. InProceedings of the International Joint Conference
on Artificial Intelligence (IJCAI).
Pohl, I. (1970). Heuristic search viewed as path finding in a graph. Artificial intelligence,
1(3-4), 193–204.
Polyvyanyy, A., Su, Z., Lipovetzky, N., & Sardin˜a, S. (2020). Goal recognition using off-
the-shelf process mining techniques. In Proceedings of the International Conference
on Autonomous Agents and Multiagent Systems (AAMAS).
Pommerening, F., R¨oger, G., & Helmert, M. (2013). Getting the most out of pattern
databases for classical planning. In International Joint Conference on Artificial In-
telligence, pp. 2357–2364.
27Meneguzzi, Santos, Pereira, & Pereira
Pommerening,F.,R¨oger,G.,Helmert,M.,&Bonet,B.(2014). LP-basedheuristicsforcost-
optimal planning. In International Conference on Automated Planning and Schedul-
ing, pp. 226–234.
Porteous, J., Sebastia, L., & Hoffmann, J. (2001). On the extraction, ordering, and usage
of landmarks in planning. In European Conference on Planning, pp. 37–48.
Pynadath, D. V., & Wellman, M. P. (2000). Probabilistic state-dependent grammars for
plan recognition. In Boutilier, C., & Goldszmidt, M. (Eds.), UAI ’00: Proceedings
of the 16th Conference in Uncertainty in Artificial Intelligence, Stanford University,
Stanford, California, USA, June 30 - July 3, 2000, pp. 507–514. Morgan Kaufmann.
Ram´ırez, M., & Geffner, H. (2009). Plan recognition as planning. In International Joint
Conference on Artificial Intelligence, pp. 1778–1783.
Ram´ırez,M.,&Geffner,H.(2010). Probabilisticplanrecognitionusingoff-the-shelfclassical
planners. In AAAI Conference on Artificial Intelligence, pp. 1121–1126.
Santos, L., Meneguzzi, F., Pereira, R. F., & Pereira, A. (2021). An LP-Based Approach for
Goal Recognition as Planning. In AAAI.
Schmidt,C.F.,Sridharan,N.S.,&Goodson,J.L.(1978). Theplanrecognitionproblem:An
intersection of psychology and artificial intelligence. Artificial Intelligence, 11(1-2),
45–83.
Shvo, M., Li, A. C., Icarte, R. T., & McIlraith, S. A. (2021). Interpretable sequence classifi-
cation via discrete optimization. In Proceedings of the AAAI Conference on Artificial
Intelligence.
Sohrabi, S., Riabov, A. V., & Udrea, O. (2016). Plan recognition as planning revisited.. In
International Joint Conference on Artificial intelligence, pp. 3258–3264.
Su, Z., Polyvyanyy, A., Lipovetzky, N., Sardin˜a, S., & van Beest, N. (2023). Fast and
accurate data-driven goal recognition using process mining techniques. Artificial In-
telligence, 323, 103973.
Vered, M., & Kaminka, G. A. (2017). Heuristic Online Goal Recognition in Continuous Do-
mains. In Proceedings of the International Joint Conference on Artificial Intelligence
(IJCAI).
Vered,M.,Kaminka,G.A.,&Biham,S.(2016). Onlinegoalrecognitionthroughmirroring:
Humans and agents. In Advances in Cognitive Systems, Vol. 4.
Vered, M., Pereira, R. F., Magnaguagno, M. C., Kaminka, G. A., & Meneguzzi, F. (2018).
Towards online goal recognition combining goal mirroring and landmarks. In Proceed-
ings of the International Conference on Autonomous Agents and MultiAgent Systems
(AAMAS).
Zhang,C.,Kemp,C.,&Lipovetzky,N.(2023). Goalrecognitionwithtiminginformation. In
Proceedings of the International Conference on Automated Planning and Scheduling
(ICAPS).
Zhi-Xuan, T., Mann, J. L., Silver, T., Tenenbaum, J., & Mansinghka, V. (2020). Online
bayesiangoalinferenceforboundedlyrationalplanningagents. InAdvances in Neural
Information Processing Systems (NIPS).
28Goal Recognition via Linear Programming
Appendix A. Formalism Summary
V discrete finite-domain variables;
O SAS+ operators;
s initial state;
0
s∗ goalstate(thisisactuallyaconjunctiveformula,notastate,forthestatesthatqualify
as a goal see S below);
∗
S subset of states consistent with s∗;
∗
cost cost function;
Π planning task Π = ⟨V,O,s ,s∗,cost⟩;
0
⟨V,v⟩ atom consisting of a variable V ∈ V and one of its values v ∈ dom(V);
A The set if all atoms in a domain;
s A state;
S the set of all (complete) states over V;
o = ⟨p,e⟩ operator: p = pre(o) is the set of preconditions, and e = post(o) is the set of effects;
s′ = s o state resulting from executing an operator o;
(cid:74) (cid:75)
π an s-plan that starts at state s and results in a state s∗;
TS transition system TS = ⟨S,T,s ,S ⟩ induced by Π;
Π Π 0 ∗
T set of transitions;
h A heuristic function h : S → R∪{∞} from states S into a real (and possibly infinite)
value;
h∗(s) The perfect/optimal heuristic computed from state s;
IP/LP Integer/LinearProgram,theseprogramsleadtoanumberofoperator-countingheuris-
tics, depending on the constraints:
hSEQ An operator-counting heuristic whose LP includes state equation constraints;
hLMC An operator-counting heuristic whose LP includes landmark constraints;
hPhO An operator-counting heuristic whose LP includes post-hoc optimization con-
straints;
hFLOW An operator-counting heuristic whose LP includes network flow constraints;
V A set of real-valued and integer variables, of which:
Y A non-negative operator-counting variable, there is one such variable for each
o
o ∈ O;
29Meneguzzi, Santos, Pereira, & Pereira
Y⃗ A non-negative observation-counting variable, there is one such variable for each
o
o ∈ O;
U Anoperatorcountingvariableindicatingwhethero ∈ Oispartofadelete-relaxed
o
plan π;
R A variable indicating that fact a ∈ A is reached by a delete-relaxed plan π, note
a
that this variable does not count operators per se;
A A variable indicating whether o ∈ O is the first operator in a delete-relaxed π to
o,a
achieve fact a ∈ A;
T an integer variable denoting the time in which o ∈ O occurs in a delete-relaxed
o
plan π for the first time;
T an integer variable denoting the time in which a ∈ A is achieved for the first
a
time;
occur (o) The fact that an operator o ∈ O occurs in a plan π;
π
C A set of operator-counting constraints;
L A disjunctive action landmark;
Π A planning task without a goal condition (used to represent the domain for a goal
P
recognition task)
ΠΩ A goal recognition task ⟨Π ,Γ,Ω⟩ with a domain Π , goal hypotheses Γ, and obser-
Γ P P
vations Ω
Γ A set of goal conditions s∗
Ω A sequence of observations
s∗ The reference goal for a goal recognition task ΠΩ
R Γ
ϵ The level of unreliability or noise assumed in the observations;
30