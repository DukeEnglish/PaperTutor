Leveraging the Domain Adaptation of Retrieval Augmented Generation Models
for Question Answering and Reducing Hallucination
SalmanRakin1,Md.A.R.Shibly2,ZahinM.Hossain3,ZeeshanKhan,Dr.Md.MostofaAkbar
salmankaderrakin@gmail.com,shibly.ar@gmail.com,zahinhasan2510@gmail.com,zeeshan@surroundapps.com,
mostofa@cse.buet.ac.bd,
Abstract by leveraging external knowledge sources because of its
capability to combine pretrained parametric memory with
While ongoing advancements in Large Language Models
explicit non-parametric memory (Lewis et al. 2020c) (Xu
have demonstrated remarkable success across various NLP
etal.2024)(Johnsonetal.2023).Unliketheinherentbuilt-
tasks,RetrievalAugmentedGenerationModelstandsoutto
behighlyeffectiveondownstreamapplicationslikeQuestion inknowledgearchitecturesofLargeLanguageModelswith
Answering.Recently,RAG-end2endmodelfurtheroptimized limited access to external knowledge, RAG models have
thearchitectureandachievednotableperformanceimprove- proven to be a promising approach for generating infor-
ments on domain adaptation. However, the effectiveness of mative and context-aware responses. Recent advancements
theseRAG-basedarchitecturesremainsrelativelyunexplored in the field of retrieval-augmented generation models have
when fine-tuned on specialized domains such as customer shown great potential for improving the factual accuracy
serviceforbuildingareliableconversationalAIsystem.Fur-
and coherence of language models’ responses rather than
thermore, a critical challenge persists in reducing the oc-
fine-tuningtheentireLLMrepeatedly(Rackauckas2024).
currence of hallucinations while maintaining high domain-
specific accuracy. In this paper, we investigated the perfor-
mance of diverse RAG and RAG-like architectures through Moreover, similar retrieval augmented architectures like
domain adaptation and evaluated their ability to generate REALM(Guuetal.2020)utilizesafixedretrievercompo-
accurate and relevant response grounded in the contextual nent duringthe fine-tuning processand RETRO (Borgeaud
knowledge base. To facilitate the evaluation of the models, etal.2021)suggestedthatfrozenBARTembeddingwillbe
weconstructedanoveldatasetHotelConvQA,sourcedfrom adequate for general-purpose retrieval from Wikipedia-like
wide range of hotel-related conversations and fine-tuned all
datasets. On the other hand, recent advancement on the
themodelsonourdomainspecificdataset.Wealsoaddressed
original architecture of RAG,RAG-end2end (Siriwardhana
acriticalresearchgapondeterminingtheimpactofdomain
et al. 2023) observed that updating both the passage
adaptation on reducing hallucinations across different RAG
encoder and query encoder improves overall performance
architectures, an aspect that was not properly measured in
priorwork.Ourevaluationshowspositiveresultsinallmet- substantially in QA tasks across various domains like
rics by employing domain adaptation, demonstrating strong Covid-19, News etc. However, their works have been
performance on QA tasks and providing insights into their primarily focused on the role of domain-adapted retrievers
efficacy in reducing hallucinations. Our findings clearly in- without exploring any further impact of context awareness
dicatethatdomainadaptationnotonlyenhancesthemodels’ whileachievingdomainadaptationbeyondgeneral-purpose
performanceonQAtasksbutalsosignificantlyreduceshal- datasets.
lucinationacrossallevaluatedRAGarchitectures.
RAG models possess the capability to generate more
1 Introduction
specific, diverse and factual language than parametric-
Large Language Models (LLMs) generally store a vast only state-of-the-art architectures (Raffel et al. 2019).
amount of data encoded as factual knowledge in their Although, RAG outperforms other parametric seq2seq
parameters through fine-tuning on large corpora (Lewis models and task-specific retrieve-and-extract architectures,
et al. 2020c). In recent years, LLMs have demonstrated the performance of RAG models has been observed to be
significant advancements in natural language processing relatively limited when fine-tuned on specialized domains.
tasks including question answering, summarization, and Additionally, such architectures on existing research have
dialoguesystems.Besides,LLMsplayapivotalroleinde- predominantly trained and evaluated on general-domain
veloping powerful agents, serving as essential components datasets, such as Wikipedia, which may not adequately
for reasoning and are fundamental for adaptation to new capture the nuances and complexities of specialized do-
observations such as GPT in the context of Conversational mains. Hence, the effectiveness of RAG and RAG-based
AI(Wuetal.2023)(Li,Yuan,andZhang2024a).Recently, architectureshasbeenlargelyunder-exploredinspecialized
Retrieval Augmented Generation (RAG) models have domains such as customer service within the Hospitality
demonstratedsignificantimprovementscomparedtoLLMs Sector.
4202
tcO
32
]LC.sc[
1v38771.0142:viXradomain-specific data was then used for fine-tuning all the
LLMs also suffer from a phenomenon widely known models to thoroughly evaluate the performance across all
as ”hallucination,” where they generate content that is not the RAG and RAG-like architectures in the hotel customer
grounded in the provided context or knowledge sources. service domain, with a focus on improving response accu-
Hallucinations in text-generation models have received racyandmitigatinghallucinationsthrougheffectivedomain
significant attention recently (Maynez et al. 2020) while adaptation.
researchers have proposed various explanations for the
occurrences of hallucinations in Large Language Models The aim of our study is to investigate the potential of
(Zhu, Sun, and Yang 2024) (Bender et al. 2021) (Burns Retrieval Augmented Generation models on Question An-
et al. 2022). These models have a tendency to generate swering Tasks in the context of domain-specific conversa-
outputs that are disconnected from the context documents, tion dataset. Specifically, we focused on the hotel domain,
producing content that is plausible-sounding yet factu- as it represents a critical area for customer service where a
ally inaccurate. Recent efforts to address hallucination reliable and accurate Question Answering System or Con-
indicate that, combining parametric and non-parametric versational AI can have a significant impact on user satis-
memory components tends to reduce hallucinations and faction and trust (Yang et al. 2024) (Xu et al. 2023) (Hei
enhance the interpretability of model outputs, particularly et al. 2024) (Delile et al. 2024). Our findings highlight the
in knowledge-intensive tasks like question answering impact of domain adaptation in enhancing the reliability
and text summarization (Xu, Szlam, and Weston 2022) and accuracy while building conversational AI models and
(Komeili, Shuster, and Weston 2022) (Guu et al. 2020) contributes to the field by providing open-source domain-
(Lewis et al. 2020c). Shuster, Kurt, et al (Shuster et al. specificdatasetsanddetailedperformanceanalyses,offering
2021) further addressed the issue of hallucinations within valuableinsightsintothepracticalapplicationofRAGmod-
knowledge-grounded conversational tasks and illustrated elsincustomerservice.Ourevaluationdemonstratedstrong
that employing RAG architecture conditioned on retrieved results in all metrics across all the RAG variants including
documentsreducedhallucinationsignificantly. the Fusion in Decoder (FID) (Izacard and E´douard Grave
2021) model while fine-tuned on our hotel-domain dataset
Despite the potentials shown by Retrieval Augmented on QA tasks, providing evidence into their efficacy in do-
Generationmodelstoaddressthehallucinationproblemby mainadaptation.Finally,wefurtherillustratedthataneffec-
incorporating relevant external knowledge, the majority of tivedomainadaptationcanpotentiallyleadtoreducehallu-
the existing research didn’t evaluate the impact of domain cinationsignificantlyacrossallRAGarchitectures.
adaptation on hallucinations. Besides, there have been
limited understanding of their effectiveness in specialized,
2 BackgroundandRelatedWork
domain-specific applications such as Conversational AI for
Customer Service. (Hei et al. 2024). In domains such as Open-domain Question Answering (ODQA) represents a
hotel auto-attendant services, generating misleading infor- keychallengeinthefieldofnaturallanguageprocessingand
mation can disrupt customer interactions and negatively understanding (Lee, Chang, and Toutanova 2019) (Lewis,
impact the user experience, which ultimately diminishes Stenetorp, and Riedel 2021). ODQA typically employs a
trust in the service. Therefore, it would be valuable to two-stage architecture requiring contextual information
further investigate the effectiveness of RAG architectures to be fetched from adaptable knowledge base such as
onanoveldatasetcomposedofreal-lifehotelconversations addressing complex datasets like WikiQA (Yang, tau Yih,
and compare their performance between different state-of- and Meek 2015) and Natural Questions (Kwiatkowski
the-artretrieval-augmentedmodels. et al. 2019). Consequently, it utilizes a separate retriever
componentwhererelevanttextsegmentsareidentifiedfrom
Motivated by the recent advancements in the RAG the knowledge base based on input query followed by a
architectureandtotackletheaforementionedresearchgaps, reader or generator that processes the selected passages
thispaperundertakesthreekeyinitiatives:(1)Weexplored to generate final answers. In conventional setups, both the
the potential of leveraging domain adaptation techniques components are optimized in isolation, with each model
within a range of RAG and RAG-like architectures and trainedindependentlywithquestion-answer(QA)pairswith
compared their effectiveness in generating responses that respective ground truth passages as contexts. Historically,
are both accurate and grounded to the context within the retrievaltaskshavereliedonsparsevectormodelslikeTF-
hotel-related conversational domains. (2) We further ana- IDF and BM25 (Robertson and Zaragoza 2009), but recent
lyzedtheimpactofdifferentRAGarchitecturalvariantson advancements have shifted towards dense text representa-
reducinghallucinationthrougheffectivedomainadaptation. tions, such as Dense Passage Retrieval (DPR)(Karpukhin
Subsequently, we addressed the existing gap through an et al. 2020), which utilizes dual BERT models (Devlin
extensive categorized evaluation scheme on how domain et al. 2018) to embed questions and passages based on
adaptation techniques influence hallucination reduction. semantic similarity. For answer generation, contemporary
(3) We presented HotelConvQA, a comprehensive dataset research has explored both extractive models, like BERT,
featuring domain-specific knowledge base comprising and generative approaches, including BART(Lewis et al.
real-life hotel domain conversations and extended set of 2020b)andGPT-3(Brownetal.2020).
question-answer pairs based on those conversations. ThisODQAsystembuiltonexpensivelargelanguagemodels training, enhancing its capability to produce accurate and
with billions of parameters such as GPT-3 (Brown et al. contextuallyrelevantresponses(Lewisetal.2020c).
2020) and Megatrone-LM (Narayanan et al. 2021) rep-
resents the complete knowledge as parametric memory. Retrieval Augmented Architectures have gained signif-
However, QA systems based on these large language icant attention for their scalable and interpretable design
models are prone to generating hallucinations, particularly (Siriwardhanaetal.2023).Recentstudieshavesignificantly
when fine-tuned for downstream NLP tasks, where the enhanced the capabilities of RAG models within dialogue-
models may produce inaccurate or fabricated information based systems (Rackauckas 2024) (Kang et al. 2024). It
despitetheirextensiveparameterization(Huangetal.2023). uniquely integrates retrieval and generation and merged in
Even with a two-stage pipeline that retrieves accurate a single architecture, leveraging both a pre-trained BART
information, the generator may still produce statements generator and dense vector representations of Wikipedia
that are factually correct but misaligned with the contexts, articles indexed with the FAISS (Johnson et al. 2019)
often conflating similar entities or committing significant library capable of scaling to knowledge sources containing
errors due to flawed token predictions (Li, Yuan, and millions of documents. However, existing research on
Zhang 2024b) (Das, Saha, and Srihari 2023). This issue of RAG models has focused only on open-domain tasks with
hallucinationisamajorhindrancetothesafedeploymentof Wikipedia-baseddatasetsandthereislimitedunderstanding
these powerful language models in real-world applications of their effectiveness in domain-specific applications,
thatrequirereliableandtruthfulinformation(Tonmoyetal. particularly in customer service area. Therefore, in this
2024). paper we aim to investigate the performance of different
RAG and RAG-like architectures by leveraging domain
UnlikeODQAwithparametriconlyseq2seqmodel,RAG adaptation techniques, with a focus on evaluating their
model can fine-tune its retrieval and generation compo- ability to generate accurate and contextually appropriate
nentssimultaneously,leadingtostrongperformanceongen- responsesinspecializeddomains.
eralQAtasks,outperformingbothstandaloneextractiveQA
(Chen 2017) and seq2seq neural language models (Lewis
etal.2020c).Specifically,theRAGmodelhasshownsignifi- 2.2 RAG-end2endArchitecture
cantimprovementsintermsofansweraccuracyandfaithful- The original RAG architecture maintains the encoding
nessastheretrievalcomponentcanproviderelevantcontext of passages and the external knowledge base in a fixed
tocomplementthelanguagemodel’sgenerationcapabilities state, resulting in suboptimal performance when handling
which potentially leads to reduce hallucinations. Although QA tasks that demand specialized knowledge beyond the
PreviousworksalsosuggestedtheeffectivenessofRAGAr- scopeoftheoriginalWikipedia-basedcorpus(Kwiatkowski
chitecturesinconversationaltasks(Shusteretal.2021)and etal.2019)(Joshietal.2017).Toaddressthequestionable
chatbotframeworks(Xu,Szlam,andWeston2022),noneof performanceoftheRAGmodelondomainspecificdatasets,
theseworkshaveexploredtheimpactofdomainadaptation RAG-end2end (Siriwardhana et al. 2023) proposes an
on hallucination reduction. Subsequently, the RAG model extension to the RAG architecture that enables end-to-end
hasprimarilybeenevaluatedonopen-domaindatasets,such trainingoftheretrieverandgeneratorcomponents.Thekey
as those derived from Wikipedia, which limits its scope of ideaofRAG-end2endistoupdatetheembeddingsoftheex-
applicationslikecustomerservice. ternal knowledge base (documents) asynchronously during
fine-tuning,inadditiontojointlyoptimizingtheparameters
2.1 RetrievalAugmentedArchitecture
of the retriever and generator components. Furthermore,
Retrieval-Augmented Generation (Lewis et al. 2020c) RAG-end2end introduces an auxiliary training signal that
models have emerged as a promising solution to address forces the model to reconstruct a given input sentence by
the knowledge-intensive nature of NLP tasks (Yang et al. retrievingrelevantinformationfromtheexternalknowledge
2024) (Hei et al. 2024). Unlike the two-stage pipeline of base(Siriwardhanaetal.2023).
traditional ODQA systems, Retrieval-Augmented Gen-
eration models utilized the neural-retrieval-in-the-loop Unlike RAG, RAG-end2end architecture iteratively re-
technique with Dense Passage Retrieval (Karpukhin et al. encodeandre-indextheknowledgebaseduringeachtrain-
2020)andBART(Lewisetal.2020a)sequence-to-sequence ingloop.Theoptimizedarchitecturehasbeenevaluatedon
language model (Lewis et al. 2020c) (Shuster et al. 2021). datasetsincludingCORD-19(Wangetal.2020),Conversa-
This method integrates a neural network architecture with tions (Yang, tau Yih, and Meek 2015) and News (Trischler
transformers (Vaswani et al. 2017) as backbone consisting etal.2016),demonstratingsubstantialimprovementsinac-
of an encoder-decoder framework. In this system, the curacy by outperforming all other architectures. Although
encoderprocessestheinputqueryandtheretrieverconverts the conversation dataset, QAConv, comprises of business
itintoadensevectorrepresentationfollowedbyemploying emails,paneldiscussionsandworkchannels,itdidnotcap-
maximum inner product search to identify and retrieve the tureasinglespecializeddomainadaptationcapabilitiescru-
most pertinent passages from an extensive corpus. These cial for building applications for robust customer service.
retrieved passages are then concatenated with the input Furthermore, aside from response accuracy they did not
query and fed into the decoder to generates final response. evaluate any impact of domain adaptation on hallucination
Theentiresystemistypicallyoptimizedthroughend-to-end reduction in their experiments. This paper aims to explorethe potential of retrieval-augmented generation models to europe2,primarilyofferhotelreviewsorrecommendations
address the hallucination problem through domain adapta- but lack the structured, conversational format needed for
tion.Byleveragingacomprehensivedatasetspecifictohotel question-answer pairs, which limits their applicability in
interactions,wefurtherevaluatedandcomparedtheperfor- tasksrequiringdialogueorinteractiveretrievalmechanisms.
manceofRAG-end2endwithotherretrieval-augmentedar-
chitectures,suchasRAG-original,RAG-fine-tuned,andthe 3.1 DataCollectionandPreprocessing
FusinginDecoder(FID).
For this research, three key corpora were identified as pri-
mary data sources: Multiwoz3, TripAdvisor4, and a Local
2.3 FusioninDecoderArchitecture
Hotel conversational dataset, with careful consideration of
The Fusion-in-Decoder (Izacard and E´douard Grave privacy and confidentiality issues. Subsequently, this data
2021) model provides an alternative approach to the RAG collection process was followed by a preprocessing phase,
architecture for leveraging external knowledge sources during which the datasets were standardized in format and
during generation. Unlike RAG,FiD employs a multi-head cleansed of irrelevant or noisy information, facilitating the
attention mechanism to fuse the hidden states with the assessment of the domain adaptability of various models.
encoded representations from the retriever. Additionally The Multiwoz corpus formed the core dataset, focusing
ratherthanprocessingthedocumentsseparately,itencodes on hotel reservations, bookings, and recommendations,
them independently and concatenates their representations. while TripAdvisor reviews and feedback introduced more
IncontrasttoRAG,whichcombinesdocumentprobabilities variability with the integration of user reviews, complaints
with the encoder’s output, FiD considers all retrieved and feedback. Additionally, we collected real-world con-
documents together in the decoder, allowing the model to versations i.e. reservations, feedback, reviews, and issue
attend to multiple documents simultaneously. Moreover, resolution from a Local Hotel Dataset. This inclusion not
unlike some methods that dynamically adjust document onlyimprovedtheauthenticityandreliabilityofouroverall
probabilities,FiDmaintainsafixedretrieverduringtraining, dataset but also ensured that the dataset covers a diverse
whichsimplifiesthemodelandtrainingprocess. range of topics, such as making reservations, providing
feedback and reviews, and addressing issues during a
This architectural difference enables FiD to demonstrate hotel stay. Although obtaining these conversations was
superiorperformanceonseveralquestion-answeringbench- challengingduetoprivacyconcerns,datafromlocalhotels
marks by efficiently integrating multiple documents. But, wassecuredwithoutanypersonallyidentifiableinformation.
theirworkonlyfocusedontheperformanceconsideringthe
number of retrieved passages within their proposed archi- After obtaining the raw datasets from the three corpora,
tecture. Furthermore, they did not assess whether incorpo- customscriptswereusedtosegmenttheconversationsinto
ration of external knowledge with language model outputs concise passages of around 100-120 words. This prepro-
could potentially help to counter hallucinations by ground- cessing step generated a knowledge base with 50,139 pas-
ing the generation in factual information. Consequently, In sages,capturinguser-agentinteractions.Subsequently,GPT-
ourstudy,wecomparedthedomainadaptationperformance 3.5-turboAPIswereutilizedtocreatetwooutputsfromthe
ofFiDwithdifferentRAGarchitectures.Inthisresearchwe knowledge base: question-answer pairs and reconstruction
further examined and categorized the occurrences of hallu- signals.Toexpeditethedatapreprocessingphase,weincor-
cinationsonourdomainspecificdataset.Finally,ourresults poratedsixannotatorstoensurethequalityandrelevanceof
demonstrated that in addition to improving response accu- thedataset,whilealsomaintainingdiversitywithinthehotel
racy,domainadaptationenhancesthemitigationofhalluci- domain for the QA pairs and reconstruction signals.Details
nationsignificantly,whichisacriticalaspectwhilebuilding onthesetupofourdomainspecificdata,preprocessingsteps
conversationalAIsystems. usingpythonscriptsalongwithmanualannotationshasbeen
describedintheAppendixAandAppendixB.
3 DataCollectionandDomainSpecific
DatasetSetup 3.2 KnowledgeBaseGeneration
To leverage the power of retrieval-augmented genera- To maintain consistent formatting across the training data,
tion models for enhancing customer service in hotel do- we preprocessed each corpus into a standardized conversa-
main,several data sources were considered in curating the tional format between customers and hotel assistant. The
target corpus, including publicly accessible customer ser- MultiWOZ corpus is structured as a series of ”turns,” an-
vice datasets in conversational format, internal corporate notated with intent, belief states, and dialog acts for both
chatlogs,onlinecustomerreviews,employeeinquiries,and user and system utterances. The MultiWOZ corpus, com-
pertinent domain-specific literature. However, there aren’t prising 10,437 multi-turn dialogues, was restructured into
many available corpus that supports all the required func-
tionalities and lacks diverse conversational aspects of typ- 2https://www.kaggle.com/datasets/jiashenliu/515k-hotel-
ical hotel related activities. Existing similar datasets such reviews-data-in-europe
as HotelRec1, TripAdvisor, 515k-hotel-reviews-data-in- 3https://huggingface.co/datasets/pfb30/multi woz v22
4https://huggingface.co/datasets/argilla/tripadvisor-hotel-
1https://github.com/Diego999/HotelRec reviews24,177 concise passages. Similarly, TripAdvisor hotel re- 3.4 ReconstructionStatementGeneration
viewswereconvertedintoaconversationalformat,produc-
The reconstruction signals, consisting of concise one-
ing 55,872 passages. To avoid bias toward a single corpus,
sentencesummariesoflongerpassagesfromtheknowledge
thetop20,124TripAdvisorpassageswereselectedforinclu-
base, are essential for improving the performance of the
sion.Additinally,forthe3,000localhotelconversations,we
RAG end-to-end model as mentioned in the original paper.
removed any personally identifiable information and split
ThesesignalsweregeneratedusingtheGPT-3.5-turbo-0125
themasmentionedbeforeyielding5,838passages.Finally,
languagemodelforpassageslongerthan45words,yielding
we combined the MultiWOZ, TripAdvisor, and local hotel
a total of 15,987 summaries. Similar to the QA generation
corpustoformourcomprehensiveKnowledgebase,result-
phase, these summaries were then forwarded to annotators
inginatotalof50,139passagesasdescribedintable1.
for quality verification and to assess whether they captured
the critical information contained in the original passages.
Corpus KB QA Recon Once validated, the reconstruction signals were combined
Multiwoz 24,177 8,678 7,283 withtheQApairsduringthetrainingphaseoftheRAGend-
to-endmodel.
TripAdvisor 20,124 8,179 7,091
LocalHotels 5,838 1,805 1,613
3.5 EvaluationDatasetforDomainAdaptation
Total 50,139 18,662 15,987
andHallucination
Table 1: Knowledge Base, QA and reconstruction signal To evaluate the domain adaptation capabilities and hallu-
Distribution Across Corpora. Almost same number of pas- cination detection in the conversational agent, we curated
sage, QA and reconstruction are taken from Multiwoz and two separate datasets: one for performance evaluation and
TripAdvisor. Resourse from local hotels werer a bit scarce another for hallucination detection. The performance eval-
butstillvaluable. uation dataset consists of ground truth QA pairs excluded
from the training set, designed to assess the models on
various question types described in table 3. The difficulty
levels were balanced with 62% Easy, 30% Hard, and 8%
3.3 QAPairGeneration Medium, ensuring a thorough evaluation across diverse
formatsandcomplexities.
Ourdatasetincludesacuratedsetofhigh-qualityquestion-
answer pairs. To generate these pairs, we utilized the GPT-
3.5-turbo-0125 model through a custom script to produce Type %
comprehensive questions that encapsulate the key informa- Extractive 62.00
tionfromeachpassageintheknowledgebase.Wethenap- Abstractive 20.00
pliedtheheuristicpruningAlgorithm1toremoveunneces- Descriptive 14.00
saryorlow-qualityQApairs,suchasoverlyspecificqueries Comparison 2.00
orgenericresponseslike“Thankyou”and“Goodbye”.This Calculative 2.00
process resulted in a total of 18,662 QA pairs, which were
sent to annotators for validation. Their primary task was to Table3:Percentageofdifferenttypesofquestionspresentin
review each question to ensure alignment with the knowl- ourevaluationset.
edgebaseandassesstheoverallquality.Oncethevalidation
phasewascompleted,weconductedananalysisoftheentire
Forhallucinationdetection,Wecarefullyconstructedthis
dataset to examine the distribution of question and answer
datasetbyinjectingcontradictory,falseormisleadinginfor-
types.Ifanytypeappearedover-represented,forexampleif
mationintoasubsetoftheconversations,creatingscenarios
”what is the location of ....?” occurs more than necessary,
where the model’s responses would not align with the in-
weregeneratednewquestionsthatunderwentthesameval-
formationstoredinitsparametricmemory.Wemodified63
idationprocesstomaintainbothqualityandbalanceacross
passagesandgenerated90QApairsbasedonthesealtered
thedataset.Throughthisprocess,wefinalizedTHEtheQA
passages. Additionally, we included 10 QA pairs that were
pairs and split with an 8:1:1 ratio for training all the RAG
notbasedonanypassagesintheknowledgebase,toassess
modelsforevaluation.
howthemodelswouldhandlesuchout-of-domainscenarios.
Intotal,thehallucinationevaluationdatasetcomprised100
Category Count QApairs,allowingustorigorouslyassessthehallucination-
Train 14,929 detectingcapabilitiesoftheRAG-likemodels.
Test 1,867
Validation 1,866 3.6 DatasetAnalysis
Total 18,662
Thecustomerservicedatasetmaintainsabalanceddistribu-
tionofquestions,allowsare-validationindicatorfollowing
Table 2: The final set of QA pairs was split with an 8:1:1
manualqualityassurancebythecurators,ensuringthesuit-
ratiointotraining,testingandvalidationsets.
ability and correctness of the training and evaluation data.
Bycarefullyexaminingthedistributionofdifferentquestionformatsandcorrespondinganswertypes,weaimedtoiden- Answertype %
tifyanypotentialbiasesorimbalancesthatcouldimpactthe Location 5.19
performance of our models or misrepresent the underlying Information 24.07
data. Recommendation 16.30
Reservation 1.48
3.7 QuestionAnalysis Amenities 7.04
We performed an in-depth analysis of a sample of 270 QA Service 3.70
pairs, uniformly selected from our knowledge base to en- Yes/No 7.78
surethepresenceofequalnumberofquestionsfromallthe Feedback 7.41
corpora to assess the distribution of question types. This Experience 15.19
allowed us to categorize the questions into different types, Issue 3.33
suchas“what”,“how”,“when”andsoon.Byanalyzingthe Policy 8.15
frequencyanddistributionofvariousquestiontypes,wecan Transport 0.37
better understand the breadth of the conversational scenar- Price 0.74
ios.Thedistributionofthesequestiontypesisvisuallyrep- Food 1.11
resentedinFigure1.
Table 4: Distribution of Answer Types in Percentage in
HotelConvQA.
4 ExperimentalAnalysis
4.1 ModelArchitecturesandTrainingProcedure
We used the HuggingFace5 (Rush et al. 2019) library to
implement all the RAG6 based architectures including the
RAG-end2end7 model. To evaluate the effectiveness of
all the models in the context of domain adaptation for the
hotel domain, we conducted a series of experiments using
our custom-built dataset. We utilized FAISS8 (Johnson
et al. 2021) for indexing and encoding our HotelConvQA
knowledge base and opted HNSW FLAT as the indexing
mechanism as instructed by Siriwardhana et al. For the
RAG-end2end model, we deployed eight NVIDIA Tesla
V100 GPUs, each with 32 GB of memory, along with 96
vCPU cores on Amazon EC2 p3dn.24xlarge instances,
facilitating parallel distribution of training, retrieval, and
re-encoding tasks. This setup allowed for efficient work-
load distribution, with four GPUs dedicated to training
Figure 1: Types of questions covered in HotelConvQA.
and retrieval tasks, and the remaining four allocated for
Types were determined by simply taking the first three
re-encoding and re-indexing tasks. Meanwhile, for other
wordsofaquestion.Comparisonofwhichtypeoccursmore
models— RAG-Finetuned, RAG-DPR, and Fusion-in-
arepresentedhere.
Decoder (FiD)—we maintained a consistent experimental
setup using a single Tesla V100 GPU with 24 GB of
memory as L4 GPU in colab, paired with an A100 GPU
3.8 AnswerAnalysis
with 40 GB of memory and 432 Tensor Cores available
Inourconstructedevaluationset,thedistributionofanswer
in Google Colab. All the experiments were conducted on
typesreflectsthevariednatureofthequestionsposedtothe
different hardware setups, chosen based on the specific
models. The most prevalent answer types are information
needs of each model as. The experiments utilized distinct
(24.07%), recommendation (16.30%), and experience
hardware setups and training parameters tailored to each
(15.19%),coveringfactualdetailsabouthotelamenitiesand
model’s requirements, following the recommendations of
policies, personalized suggestions tailored to user prefer-
Siriwardhana et al.. Additionally, the choice of training
ences,andexperience-basedanswersthatdeliversubjective
hyperparameters was considereed following the original
insights and impressions respectively. These categories
RAGPaperbyLewisetal.andfurtherfine-tunedbasedon
are particularly significant as they represent key areas
where nuanced and context-aware responses are critical, 5https://huggingface.co/
therebyservingasrobustindicatorsofmodelperformance. 6https://github.com/huggingface/transformers/tree/main/
Althoughlessfrequent,theremaininganswertypesinTable examples/research projects/rag
4arealsocrucialforprovidingawell-roundedevaluationof 7https://github.com/huggingface/transformers/tree/main/
modelperformance. examples/research projects/rag-end2end-retriever
8https://github.com/facebookresearch/faiss/wiki/Faiss-indexesexperimentalvalidationresults. of the HotelConvQA, the corresponding passage was used
as the positive context, along with 3 negative contexts,
WeinitializedtheDPRandBARTcompontensusingtwo where the answer was not present, and 5 hard negative
pre-trainedopen-sourcecheckpointsfromtheHuggingFace contexts,whichwerelexicallysimilarbutdonotcontainthe
model repository: rag-token-base9 and rag-token-nq10. answer. All these contexts were selected using the BM-25
Both models include a question encoder, retriever, and lexical matching search as mentioned by the DPR author
generator, with the rag-token-nq model pre-trained on the Karpukhinetal.Themodelwastrainedover20epochswith
TriviaQA and NaturalQuestions datasets, enabling easier these contexts, resulting in two encoder checkpoints: the
domain adaptation. The rag-token-nq model’s retriever and queryencoderandthepassageencoder.
generator were fine-tuned together on the WikiDPR QA
dataset in an end-to-end manner, which generally allows it Following this fine-tuning, we re-built the index using
to generate more relevant responses. In contrast, the rag- the passage encoder from the adapted DPR model. Then,
token-base model, not fine-tuned on any downstream task, we utilized the query encoder we got after finetuning the
only computes predicted output loss for natural questions. DPR to generate the embeddings of the questions. After
However,weexperimentedwithbothofthecheckpointsto that, we utilized the same approach of calculating dot
compareandanalyzeresponsegenerationintheRAG-DPR product similarity score between those two embedding
and RAG-end2end settings. Below, we outline the training for getting relevant passaged based on the query and
setup and methodology for each of the five models used in fed the top-k retrieved passages to the generator. After
ourexperiments. integrating the adapted retriever into the RAG model, we
first evaluated its performance with the base model that
RAG-Original : The RAG-Original model served as had not been fine-tuned on any downstream tasks, and
our baseline for evaluation, following the architecture subsequently fine-tuned the merged model with QA pairs
proposed by Lewis et al. We indexed our HotelConvQA from our HotelConvQA dataset, noting results from both
knowledge base and utilized this index to retrieve docu- settings to assess improvements in retrieval and response
ments in response to queries. This model was evaluated generation. The consolidation of the fine-tuned DPR with
withoutanykindofdomain-specificfine-tuning,servingas the RAG architecture was intended to assess whether a
abenchmarkagainstwhichothermodelscouldbeevaluated. domain-specificadaptationoftheretriever,whilepreserving
thegeneralgenerationcapabilitiesofthepre-trainedBART
RAG-Finetuned-QA : The RAG-Finetuned-QA model model,couldenhanceperformanceonthehoteldomaintask.
builds upon the baseline RAG-Original architecture by
incorporating domain-specific fine-tuning on our hotel RAG-end2end : The key idea behind RAG-end2end
domain dataset. Like the RAG-Original model, it utilizes (Siriwardhanaetal.2023)istoiterativelyupdatethecontext
a Hotel Domain Knowledge Base, with dense vector encoder during training on the dataset of domain-specific
representations indexed using the FAISS library. The loss question-answer pairs. Unlike the previous architectures, it
function is designed to fine-tune both the generator and updates the passage embeddings with the updated context
question encoder collectively. We have used ray as the encoderduringeachiterationofthetrainingandthenupdate
distributed retriever with 4 retrieval workers as described the index of the external knowledge base asynchronously
in the original RAG paper. The model was trained for 20 fromthemaintrainingloop.Additionally,itrequiresrecon-
epochs while the final checkpoint has been selected based struction signals to inject more domain-specific knowledge
on the highest validation accuracy. The purpose of this into the model. This auxiliary signal was generated by
experiment was to assess the improvements gained from summarizing the relevant passages which are factually
domain-specifictraining,comparingitsperformanceagainst correct and from the knowledge base and using them
thebaselineRAG-Originalmodel. as a reconstruction target for the model. We used the
training script provided by the RAG-end2end authors to
RAG-DPR-adapted : The RAG-DPR-Adapted model fine-tuneourmodel.Finally,similartoRAG-DPR-adapted,
investigates the impact of fine-tuning the Dense Passage to compare the impact of finetuning the entire setup with
Retriever (DPR) while keeping the pre-trained BART dowstream QA tasks, we initialized the rag-token-base,
generator unchanged. This approach aims to enhance the observing how the base model performs. After that, we
retriever’s sensitivity to the domain-specific context of initialized the model with rag-token-nq, which had already
our hotel domain, allowing for more relevant passage beenfine-tunedonthequestionansweringtask.Wetrained
retrieval. To understand the role of the retriever in the the model for 10 epochs with a batch size of 16, mirroring
RAG architecture, we focused on fine-tuning only the thesetupusedinthepreviousexperiments.
retriever component. Since the DPR is pre-trained on
Wikipedia-baseddatasets,weadaptedittothehoteldomain Fusion-in-Decoder(FiD):TheFusion-in-Decoder(Izac-
using the Deep-Haystack11 framework. For each QA pair ard and E´douard Grave 2021) model, Unlike the RAG
models, which employ attention mechanisms to align
9https://huggingface.co/facebook/rag-token-base retrieved passages with the input query, FiD adopts a
10https://huggingface.co/facebook/rag-token-nq simpler mechanism—concatenating the retrieved passages
11https://github.com/deepset-ai/haystack and processing them simultaneously in the decoder. In ourfine-tuning process, we first generate embeddings for the continues to serve as the gold benchmark for reliably as-
knowledge base and then employ the same hotel domain sessing hallucinations. TruthfulQA (Lin et al. 2022) pro-
QAdatasetbutinanalternativeformat.WeutilizeBM25to posesahuman-annotationguideline,whichinstructsevalu-
retrieve20relevantpassagesincludingthegoldpassageand atorstoassignoneofthirteenqualitativelabelstothemodel
concatenated them as Context with each question-answer output and verify answers by consulting a reliable source.
pair to build the final dataset for training. For the 19 Otherapproaches(Leeetal.2022)humanannotationtover-
relevant contexts other than the gold one, we re-ranked the ify the validity of the proposed automatic evaluation met-
passages using the BM25 scoring method and selected the rics. FActScore (Min et al. 2023) requires annotators to
top 19 based on this ranking. This approach allows us to assign three labels to each atomic fact: “Supported” or
follow the core methodology of the original FiD model, “Not-supported” for facts that are aligned by the knowl-
while tailoring the training process to our domain-specific edgesourceornotand“Irrelevant”forstatementsthatare
needs. Following the approach outlined in the original not related to the prompt. In our research, we adopted the
Fusion-in-Decoderpaper12,whichemphasizedperformance FActScore (Min et al. 2023) approach, where our human
basedonthenumberofretrievedpassages,weconcentrated annotatorsclassifiedallresponsesfromthefivemodelsinto
ontheend-to-endresponseaccuracy,ratherthanseparately thosethreecategories.Inadditiontothis,follwingprevious
evaluatingretrievalperformance.Themodelwastrainedfor works,theresponseswerefurthercategorizedintoCorrect,
10 epochs using these retrieved contexts which took both which refers to accurate and complete answers; Ambigu-
the input question and its corresponding support passages, ous(Tamkin et al. 2022), referring to unclear or open-to-
generatingthefinalanswer. interpretation responses; Incompleteness, where essential
informationwasmissing;Bias(Naviglietal.2023),indicat-
ing a preference or prejudice in the response; and Under-
4.2 EvaluationSetup informativeness(Gao et al. 2023), which denotes vague or
Accuracy Metrics For evaluation, we used metrics such insufficientdetail.Thehumanevaluationresultsprovidefur-
as Exact Match (EM), F1 score, and Top-k retrieval accu- therinsightsintotheperformanceofthemodelsinreducing
racytoassessmodelperformance.TheEMscoremeasures different types of hallucinations. A brief example of hallu-
theword-levelmatchbetweenpredictedandactualanswers cinatedresponsesfromourhallucinationevaluationsettings
while F1 score calculates the overlap of words in the for all the models has been described in Table 13 in Ap-
predictedanswerwiththereferenceregardlessoforder.For pendixG.
furtherevaluatingtheretrievalperformance,weusedTop-k
retrieval accuracy, calculated by comparing the retrieved 5 Results
passages with the correct answer strings. We’ve measured
We carefully constructed an evaluation set comprising
top-5 and top-20 retrieval accuracy for evaluating retreival
human-generated QA pairs,designed to establish a neutral
performance as followed by Siriwardhana et al. in their
andunbiasedsetting,ensuringequalconditionsbyallmeans
experiments.
acrossthefivemodelvariants.Theevaluationsetcontained
both the ground truth answers for input questions for eval-
Hallucination Evaluation Metrics Existing benchmarks uationofthefinalresponseaccuracyaswellthetitleofthe
on hallucination evaluation primarily focus on assess- corresponding five passages including the gold passage to
ing language models’ abilities to either generate factual assesstheretrievalperformance.
statements or distinguish them from non-factual ones. For
example, TruthfulQA (Lin et al. 2022) carefully designs 5.1 OverallAccuracyonDomainAdaptation
to elicit imitative false statements with a high likelihood
TheresultspresentedinTable5highlightthedomainadap-
on the training distribution, while FActScore (Min et al.
tationperformanceofthevariousRetrievalAugmentedGen-
2023) examines the factual accuracy of the generated text
erationbasedmodelsonourhotelcustomerservicedataset.
which manually annotates long-form model generations to
The RAG-Original model serves as a baseline, achieving
identifyatomicfactualstatements.Moreover,HaluEval(Li
an EM score of 4.00 and an F1 score of 10.92, reflect-
et al. 2023) and FACTOR (Muhlgay et al. 2023) involved
ing the challenges of applying generic models to special-
hiringannotatorstoidentifythepreseneceofhallucinations
ized domains without further adaptation. However, domain
and then manually validated to ensure they meet certain
adaptation significantly boosts performance, as seen in the
requirements,suchasbeingnon-factual,fluent,andsimilar
RAG-Finetuned-QAmodel,whichshowsamarkedincrease
to factual completions. Recently FactCHD (Chen et al.
of 8.50 points in EM and 19.37 points in F1, underscoring
2023), a dataset and benchmark identifies fact-conflicting
the importance of domain-specific fine-tuning for improv-
hallucinationsbyleveragingevidencechainswhilealarge-
ing response accuracy in specialized domains. The RAG-
scalebenchmarklikeHaluEvaldeterminesthehallucination
DPR-adapted model showed further improvements even
propensityacrossvariousfactualitypatterns.
over models directly fine-tuned on QA datasets, resulted
in a more effective architecture for specialized tasks. The
Despite the challenges of subjectivity across annotators
RAG-DPR-adapted model, integrating a domain-adapted
and labor intensive annotation process, human evaluation
Dense Passage Retriever and then initialized with BART,
12https://github.com/facebookresearch/FiD demonstrates notable improvements, achieving 1.73 pointsModel Accuracy Precision(top-k)
Name EM F1 Top-5 Top-20
(1)RAG-Original 4.00 10.92 11.20 14.50
(2)RAG-Finetuned-QA 12.50 30.29 20.00 23.70
(3)RAG-DPR-adapted 0.80/14.23∗ 6.41/31.54∗ 24.00 29.20
(4)RAG-end2end 1.40/17.36∗ 8.41/36.04∗ 24.40 29.20
(5)Fusion-In-Decoder 8.51 21.04 -- --
Table5:Overallresponseaccuracyandtop-kprecisionscoreofdifferentRAG-basedmodelsafterfine-tuningwithdomainspe-
cificdatasetcomparedtoRAG-Original,thebaselineversionofpre-trainedRAG-sequencearchitectureonwikipediadatasets.
The RAG-Original model demonstrates relatively low performance whereas with the effect of domain adaptation the other
models exhibit notable improvements in both response accuracy and retrieval performance across all evaluation metrics. For
RAG-end2endandRAG-DPR-adaptedmodels,leftcolumnscoresarebasedonmodelsinitializedwithrag-token-baseandnot
being finetuned on downstream QA, whereas right column score represents models initialized with rag-token-nq and further
finetuendondownstreamQAtasksrespectively.
contextually relevant responses. However, similar to the
RAG-DPR-adapted model, its performance significantly
declined(1.40EMand8.41F1)whenithasbeeninitialized
withrag-token-baseinsteadofrag-token-nqbeforetraining
withourin-domaindataset,emphasizingtheimportanceof
appropriate initialization in specialized domains. Interest-
ingly and very surprisingly, the Fusion-in-Decoder model,
which has a more flexible architecture than the traditional
RAG variants, does not demonstrate a clear advantage
in this specific domain. As an additional benchmark, we
included the Fusion-in-Decoder model, which integrates
the retriever and generator components in a different
architecturaldesign.TheFIDmodelachievedanEMscore
Figure 2: The comparison graph showcases the improve- of 8.51 and an F1 score of 21.04, falling short of the
ments in retrieval accuracy across all models after being performance of most of the fine-tuned RAG models except
fine-tuned with the hotel domain dataset, as evidenced by theRAG-Original.
notablegainsinbothTop-5andTop-20precision.Italsoin-
dicates that increasing the number of retrieved documents
leads to consistent improvements in retrieval performance
which is evident by the parallel rise of Top-5 and Top-20 5.2 RetrievalPerformanceonDomain
scoresacrossallvariants. Adaptation
The retrieval performance, measured by top-k accuracy
playsacruicialroleforassessingthemodels’effectiveness,
higherinEMand1.25pointsinF1comparedtotheRAG- as it reflects their ability to retrieve relevant information
FinetuendQAmodel,particularlyafterfine-tuningfordown- fromasizableknowledgebase,whichservesasthefounda-
streamQAtasks.However,withoutthisfine-tuning,itsper- tion for generating accurate as well as grounded responses
formance dropped significantly, which further reflects the to user inquiries.This metric captures the frequency with
necessity of tailored QA finetuning for optimal results in which the correct answer appears within the top 5 or top
specialized domains. Subsequently, while the RAG-DPR- 20 passages, directly influencing the quality of generated
adapted model performs decently in terms of Top-5 (24.0) responses. Figure 2 reveals that the RAG-Original model
and Top-20 (29.2), it falls short in more stringent metrics lagsbehindtheothermodelsindomain-specifictasks,with
like EM and F1, suggesting a challenge in generating pre- Top-5 and Top-20 retrieval accuracies of 11.20 and 14.50,
cise answers despite retrieving relevant information in the respectively. This lower retrieval performance underscores
domain-adaptedsettings. the limitations of the original architecture when applied to
domain-specific tasks without prior fine-tuning or domain-
As anticipated, The RAG-end2end model, which jointly specific adaptation. In contrast, both the RAG-Finetuned
fine-tunes both the retriever and generator with iterative andRAG-DPR-adaptedmodelsexhibitsubstantialimprove-
updates to passage encoders, achieved the highest EM mentsinretrievalperformancethroughfinetuning,withthe
(17.36) and F1 (36.04) scores outperforming all mod- latter surpassing the RAG-Finetuned model by 4.00 and
els, indicates its ability to generate highly accurate and 5.50pointsrespectively.ModelName Supported Non-Supported Irrelevant Hallucination(%)
(1)RAG-Original 71 29 0 29
(2)RAG-Finetuned 77 21 2 23
(3)RAG-DPR 80 18 2 20
(4)RAG-end2end 85 10 5 15
(5)FID 74 20 6 26
Table6:HallucinationResultsonfortheModelscomparingthepercentageofresponsesclassifiedassupported,non-supported,
andirrelevantforeachmodel.RAG-Originalhasthehighesthallucinationrate,whiletheothermodelsdemonstrateimproved
performanceinbothsupportedresponsesandhallucinationpercentage.Thiscomparisonhighlightstheeffectivenessofdifferent
modelarchitecturesandtrainingstrategiesinreducinghallucinationsandimprovingresponseaccuracy.
tion reduces the rate for hallucination for all the models as
Surprisingly, The RAG-end2end model, while excelling the number of supported responses increased significantly
in generation metrics, shows limited gains in retrieval pre- after finetuning wiht our domain speciic dataset. However,
cision compared to RAG-Finetuned-QA and RAG-DPR- it can be observed that, the reduction in hallucinations
Adapted.Thissuggeststhatthedomain-specificfine-tuning achieved with the cost of slight increase of irrelevant
of the retrieval component, either individually or as part of responses,underscoringtheinherentchallengeofbalancing
an end-to-end optimization, can substantially enhance the hallucination mitigation with response precision. As antic-
models’abilitytosurfacerelevantinformation.TheFusion- ipated, RAG-Original, with the highest hallucination rate
in-Decodermodel’sperformanceisalsoshown,thoughnot of 29%, exemplifies the model’s challenges in maintaining
directly assessed for retrieval accuracy in this study. Al- coherencebetweenretrievedcontentandtokenprediction-
though the retrieval capabilities of the FiD model have not adirectconsequenceoflackingdomain-specificadaptation.
been independently assessed in our experiments due to the In contrast, RAG-Finetuned exhibits a marked reduction in
unavailability of certain features in the original implemen- hallucinations(6%), signaling the efficacy of task-specific
tation of FID (Izacard and E´douard Grave 2021), the EM fine-tuning.
andF1scoressuggestthatthismodelperformswellbycon-
catenating of retrieving relevant chunks of information to
generatefinalresponse. ModelName Not-Supported Input Fact Context
(1)RAG-Original 29 5 24 0
5.3 HallucinationReductionPerformance (2)RAG-Finetuned 23 8 15 0
(3)RAG-DPR 20 6 14 0
Existing approaches (Lin et al. 2022; Lee et al. 2022; Min (4)RAG-end2end 15 9 6 0
et al. 2023) for evaluating hallucinations rely on human (5)FID 26 1 14 0
expert assessment as human evaluation ensures reliability.
Table 7: Hallucination Results in Category of Occurrence.
Therefore, we have employed human evaluation with
Thistablehighlightshowvariousmodelsdifferintheirsus-
the same annotators who contributed to dataset creation,
ceptibilitytospecifictypesofhallucinations,revealingareas
ensuring consistency, credibility and precision. To enhance
fortargetedimprovementinmodelperformance.
evaluation accuracy, we designed dedicated principles
of agreement and re-validation described in Appendix E
and developed specialized human evaluation guidelines Notably, the RAG-DPR model further refines re-
presentedinAppendixD,allowingannotatorstoeffectively trieval accuracy by leveraging domain-adapted dense
evaluate each model-generated responses for all the dif- passage retrievers, reducing the hallucination rate even
ferent RAG architectures. To ensure fair evaluation , we further compared to both RAG-Original(11%) and RAG-
employed a blind annotation process, where the annotators Finetuned(3%), highlighted in the comparison graph 3a.
are unaware of which model had generated each response, The lowest hallucination rate, 15%, is observed in the
preventing any bias based on model identity. They worked RAG-end2end model, where both retrieval and generation
independentlyunderthepredefinedagreement,andincases components are fine-tuned simultaneously, again reflecting
where over 50% reached consensus on a classification, the benefits of holistic adaptation through re-encoding and
we accepted their judgment. For the opposite scenario, we re-indexing iteratively. Conversely, the FID model displays
conductedamanualreview,reclassifyingtheoutputsbased a relatively high hallucination rate of 26%, alongside the
on our observations. Further details of entire Hallucination highest occurrence of irrelevant responses, highlighting
evaluationprocedureandannotationmechanismalongwith its limitations in handling domain-specific information
the extensive classification of the inspecting categories are accurately.
describedinAppendixC.
A more granular analysisof hallucinationtype as shown
The results of our study reveal notable differences in in Table 7, reveals that fact-conflicting responses dominate
how models handle supported and hallucinated responses, as majority of hallucinations fall under the category of
aswellasinthequalityandcorrectnessofthosesupported Fact-Conflicting outnumbering those classified as Input
answers. Table 6 clearly demonstrates that domain adapta- Conflicting hallucination. Notably, the evaluators did notModelName Supported Correct Ambiguous Bias Incomp. Under-Inform
(1)RAG-Original 71 40 15 1 5 10
(2)RAG-Finetuned 77 26 42 1 7 1
(3)RAG-DPR 80 22 43 1 9 5
(4)RAG-end2end 85 18 37 2 24 4
(5)FID 74 18 39 2 16 0
Table 8: Non-Hallucinated Resultsin Category of Occurrence. Breakdown of Supported responses ofeach model. This table
presents a breakdown of non-hallucinated responses, classified into categories such as ”Correct”, ”Ambiguous”, ”Bias”, ”In-
complete” and ”Under-Informed”. These results emphasize the varying quality of supported responses and highlight where
modelsexcelandwheretheystruggle.
encounter any instance of context conflicting hallucination main adaptation techniques to strike a better balance be-
across all models, probably due to the ability of RAG tweenthesetwoimportantmetrics.
Architectures to identify relevant contexts(Shi et al. 2023)
during the retrieval stage. Another intriguing take away 6 Discussion
is that, apart from reducing the overall hallucination,
6.1 RoleofDomainAdaptationinRAG
domain adaptation substantially reduces fact-conflicting
Architectures
hallucinations but increases input-conflicting ones, a trend
furthervisualizedinFigure3b. Our results highlight the impact of domain adaptation on
enhancing their performance in specialized domains. The
We further classified the non-hallucinated responses significant improvements observed in the RAG-Finetuned,
to determine extended categories for the supported oc- RAG-DPR-adapted and RAG-end2end models, in terms of
currences, summarized in the table 8. Subsequently, a improvedfactualaccuracyandreducedhallucinationunder-
comprehensive comparative overview for all the models, scoresthepotentialofthesetechniquestoaddressthelimi-
emphasizing their performance across non-hallucination tationsofgenericRAGmodels.Theresultsclearlydemon-
categories, highlighting their relative strengths and limita- stratethatmodelsfine-tunedthroughdomainadaptationex-
tionsforgeneratingcontextualresponsehasbeenillustrated hibit superior performance in generating contextually rel-
in Figure 3c. This comparison graph reveals interesting evant and accurate responses compared to those that rely
remarksthatdespitedomainadaptationledtoanincreasein solely on general-domain training. The fine-tuning process
the number of supported responses, it also contributed to a alsoenabledthemodelstoalignmorecloselywiththespe-
consistent decline in the proportion of correct answers and cificlinguisticpatterns,terminology,andcontextualnuances
a noticeable rise in ambiguous and incomplete responses. ofthehoteldomain.Forinstance,thedomain-adaptedmod-
Thisfigurealsoindicatesarelativelystablebiasrateacross els effectively incorporated the specificities of hotel opera-
all models whereas the percentage of under-informative tions,suchasrevenuefiguresandrefurbishmentdetails,into
responses shows considerable fluctuation, suggesting a theirresponses,ensuringthesignificanceofdomainadapta-
challengeofensuringsupportedresponsewhilemaintaining tion by generating content which is both accurate and con-
responsequality. textuallyappropriate.
6.2 ImpactofreducedHallucinationwith
Figure 3c further demonstrates that despite having low-
DomainAdaptation
est non-hallucinated response, RAG-Original model ex-
hibits the highest correctness rate (56.34%) but strug- OurexperimentalresultsinFigure3clearlyindicatethatdo-
gleswithclarity(ambiguous)anddetail(under-informative). mainadaptationtendtoreducehallucinationforallRAGar-
Likewise,RAG-Finetuned demonstrated highest ambiguity chitecturesbutattheexpenseofproducingmoreambiguous,
rate (54.55%) while RAG-DPR balances the correctness incomplete and biased answers. This suggests that domain
with lower level of ambiguity and incompleteness. The adaptationalsointroduceduncertaintiesingeneratingcoher-
RAG-end2end demonstrates low correctness and high in- ent,unambiguous,andcompleteresponses,raisingconcerns
completeness, although it maintains a relatively lower aboutitseffectivenessinhigh-stakestaskslikecustomerser-
level of ambiguity. In contrast, the FID model achieves a vice where trust and reliability are crucial. However, the
marginally better correctness rate (24.32%) but struggles consistencyintheproductionofalmostbias-freeandunder-
with higher ambiguity. An intriguing finding from Figure informative responses indicates that the models maintain a
3c suggests that despite a gradual increase in the percent- leveloffairnessandsufficiencydespiteotherobservedchal-
ageofsupportedresponses,thecorrectnesspercentagedrops lenges.Thesuccessofdomainadaptationinreducinghallu-
consistentlyevenafterfine-tuningtodifferentvariants.This cinationsunderscoresitssignificanceinthedevelopmentof
suggeststhatthedomain-adaptationprocess,whileimprov- reliabledialoguesystems.Bytailoringthemodel’straining
ing the overall supported responses, may come at the cost process to the specific characteristics of the target domain,
of reduced factual accuracy and correctness in the gener- it is possible to achieve a more grounded and trustworthy
ated outputs. This trade-off between support and correct- AI output, minimizing the risk of generating misleading or
ness highlights the need for further refinement of the do- incorrectinformation.(a) (b) (c)
Figure3:Fromtheleftfigure(a)representstheHallucinationPercentageScoreofModelsafterDomainAdaptation.Figure
(b)and(c)illustratesthecomparisonofHallucinationPercentageinCategoriesacrossmodelsinNon-Supportedand
SupportedCasesrespectively.
6.3 RoleofRetrievalinHallucinationReduction AmazonEC2p3dn.24xlargeinstancecomprisesoftotal8
TeslaV100GPUswith32GBmemoryeach.Thislevelof
The RAG-DPR-adapted model’s superior performance in
computational time is a significant bottleneck, particularly
reducing hallucinations highlights that the ability of RAG
when the knowledge base and the dataset grow, ultimately
models to retrieve relevant information from a domain-
making the model increasingly impractical for real-world
specificknowledgebasewasakeyfactorinmitigatinghal-
applications. The high resource requirements raises con-
lucinations. The results in Figure 3 highlight that models
cerns regarding the feasibility for large-scale deployment,
with more sophisticated retrieval strategies, such as RAG-
especially in environments where computational resources
end2end and RAG-DPR-adapted, were more effective in
arelimitedorwherecostefficiencyisapriority.
producingaccurate,fact-basedresponsescomparedtomod-
els with less integrated retrieval mechanisms, like RAG-
6.5 UtilizingRAGArchitecturesfor
Original and FID. In our experiments, we found that the
ConversationalAI
modelsemployingdynamicandcontext-awareretrievalpro-
cesseswereabletoretrieveprecisedatapoints,suchashotel The insights gained from our research have important im-
revenuefiguresorrefurbishmentcosts,therebyreducingthe plications for the development and deployment of reliable
likelihood of generating incorrect or speculative responses. conversationalAIsystems,particularlyinthecontextofcus-
Moreover, hallucinated responses for all the 10 the out-of- tomer service applications. The improved performance and
domain QA pairs suggest that the effectiveness of the re- reduced hallucination rates demonstrated in Figure 3 high-
trieval mechanism is closely linked to the quality and rele- light the potential of RAG Architectures to be utilized as
vanceoftheunderlyingknowledgebase.Whentheretrieved a complete dialogue systems through enhancing the qual-
contexts are comprehensive and well-aligned with the do- ityandreliabilityofcustomerserviceinteractions.Inacus-
main,itsignificantlycontributedtoreducinghallucinations tomer service setting, where users often seek accurate and
by providing a robust foundation of facts for the model to contextuallyrelevantinformation,theabilityofRAGmod-
drawupon.Conversely,whenthecontextdocumentsareless elstoretrieveandgenerateresponsesthataretailoredtothe
relevantorsparse,themodelshadtorelymoreontheirin- specificdomaincanleadtomoresatisfactoryandtrustwor-
ternalparametricmemory,whichtendstoproducemoreun- thyinteractions.Thereductioninhallucinations,especially
groundedcontent. intheFactConflictingcategory,canbeparticularlybenefi-
cial, as it helps to ensure that the information provided to
6.4 RAG-end2end:OptimalPerformancevs. customersisfactuallyaccurateandalignedwiththeorgani-
PracticalLimitations zation’s specific knowledge base. However, it is important
tonotethattheutilizationofRAGArchitecturesinConver-
While RAG-end2end model significantly outperformed all
sational AI for customer service settings also comes with
other architectures, including the Fusion-in-Decoder (FID)
its own set of challenges and considerations i.e. computa-
model, across all metrics of retrieval and answer genera-
tional complexity, knowledge base maintenance and large-
tion performance, it faces substantial challenges in compu-
scaledeploymentsinproduction.
tationalcomplexityandpracticalapplicability.Furthermore,
despitedemonstratingsuperiorperformanceinreducinghal-
7 ConclusionandFutureWork
lucinations and effectively adapting to the hotel domain its
computationaldemandsraiseconcernsaboutlarge-scalede- Inthispaper,wehaveexploredpotentialofdomain-adapted
ployment. In our experiment, training the on the hotel do- retrieval-augmentedgeneration(RAG)modelsinenhancing
maindataset,consistingof50kpassagesasknowledgebase the performance of QA task. This research presents a
and29kQApairsincludingreconstructionsignals,required comprehensive analysis by investigating the effectiveness
nearlyEighthoursperepochwithbatchsizeof12.Thiswas domain adaptation and it’s impact reduction of hallucina-
achievedusingahigh-performancemachine,specificallythe tions in the RAG-like Architectures. Our study introducesseveral novel contributions to the field by presentint Hotel- Borgeaud, S.; Arthur, M.; Hoffmann, J.; Cai, T.; Ruther-
ConvQA, a detailed domain-specific dataset comprising a ford,E.;Millican,K.;vandenDriessche,G.;Lespiau,J.-B.;
wide range of hotel-related conversations, which served Damoc, B.; Clark, A.; de Las Casas, D.; Guy, A.; Menick,
as the foundation for evaluating the domain adaptation J.; Ring, R.; Hennigan, T. W.; Huang, S.; Maggiore, L.;
performance of various RAG and RAG-like architectures. Jones,C.;Cassirer,A.;Brock,A.;Paganini,M.;Irving,G.;
Additionally,weconductedadetailedcomparativeanalysis Vinyals,O.;Osindero,S.;Simonyan,K.;Rae,J.W.;Elsen,
to understand their respective strengths and limitations in E.; and Sifre, L. 2021. Improving language models by re-
reducinghallucinations.Whilepriorworkhasnotexplicitly trievingfromtrillionsoftokens.
determined the relationship between domain adaptation
Brown, T. B.; Mann, B. F.; Ryder, N.; Subbiah, M.; Ka-
and hallucination reduction, our results emphasize that
plan, J.; Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry,
domain adaptation with adaptive retrieval mechanisms can
G.;Askell,A.;Agarwal,S.;Herbert-Voss,A.;Krueger,G.;
significantly reduce hallucinations for all the RAG-based
Henighan, T.; Child, R.; Ramesh, A.; Ziegler, D. M.; Wu,
Architectures.
J.C.;Winter,C.;Hesse,C.;Chen,M.;Sigler,E.J.;Litwin,
Building on the insights gained from our paper, future M.; Gray, S.; Chess, B.; Clark, J. A.; Berner, C.; McCan-
research will aim to enrich the hotel domain dataset by dlish, S.; Radford, A.; Sutskever, I.; and Amodei, D. 2020.
incorporating a broader and more diverse array of scenar- LanguageModelsareFew-ShotLearners.
ios, questions, and knowledge sources, facilitating more
Burns, C.; Ye, H.; Klein, D.; and Steinhardt, J. 2022. Dis-
comprehensiveevaluationofdomainadaptationtechniques.
covering latent knowledge in language models without su-
Subsequently, extending our analysis to include additional
pervision.
industry verticals such as healthcare, medicine etc would
alsoprovidevaluableinsightsintothegeneralizabilityofthe Chen,D.2017. ReadingWikipediatoansweropen-domain
domain adaptation approaches explored in this work. Ad- questions. arXivpreprintarXiv:1704.00051.
ditionally, further research is needed by extending RAG as Chen, X.; Song, D.; Gui, H.; Wang, C.; Zhang, N.; Huang,
acomponentofconversationalAIsystemstoevaluatetheir F.; Lv, C.; Zhang, Q.; and Chen, H. 2023. Unveiling the
naturallanguageunderstanding,dialoguemanagement,and Siren’sSong:TowardsReliableFact-ConflictingHallucina-
responsegenerationcapabilities. tionDetection.
We have made all our efforts to implement and test the
Das,S.;Saha,S.;andSrihari,R.K.2023. DivingDeepinto
effectivenessoftheRETRO(Borgeaudetal.2021)architec-
ModesofFactHallucinationsinDialogueSystems.
ture on our hotel domain dataset using NVIDIA-Megatron
Delile,J.;Mukherjee,S.;Pamel,A.V.;andZhukov,L.2024.
and RETRO-pytorch frameworks; however, challenges
Graph-BasedRetrieverCapturestheLongTailofBiomedi-
related to system requirements and resource management
calKnowledge.
impeded full integration. Therefore, future work could ex-
plore the comparison of RETRO with RAG-based models, Devlin, J.; Chang, M.; Lee, K.; and Toutanova, K. 2018.
enhancingourunderstandingofvariousretrieval-augmented Bert:Pre-trainingofdeepbidirectionaltransformersforlan-
strategiesinhandlingdomain-specificqueriesandreducing guageunderstanding.
hallucinations. In the future, we aim to investigate the
Gao,L.;Schulman,J.;Hilton,J.;etal.2023. Scalinglaws
capabilities of RAG-based models in multi-hop question
for reward model overoptimization. In International Con-
answering, extending their functionality beyond generating
ferenceonMachineLearning,10835–10866.PMLR.
responsesfromasingledocument.
Guu, K.; Lee, K.; Tung, Z.; Pasupat, P.; and Chang, M.
Webelievethatourstudywillserveasapracticalframe-
2020. REALM:Retrieval-Augmentedlanguagemodelpre-
workforleveragingretrieval-augmentedgenerationmodels
training.
inhigh-stakescustomerserviceapplications,pavingtheway
for more accurate and data-driven virtual assistants. Addi- Hei,Z.;Liu,W.;Ou,W.;Qiao,J.;Jiao,J.;Zhu,Z.;andSong,
tionally, this research will be represented a significant step G.-Y. 2024. DR-RAG: Applying Dynamic Document Rel-
forwardinthedevelopmentoftrustworthyandreliablecon- evance to Retrieval-Augmented Generation for Question-
versational A systems, particularly for industry profession- Answering.
als seeking to manage and leverage dynamic business data Huang, L.; Yang, Y.; Ma, W.; Zhong, W.; Feng, Z.; Wang,
effectively as the world changes rapidly. We hope that our H.;Chen,Q.;Peng,W.;Feng,X.;Qin,B.;andLiu,T.2023.
contributionwiththeopen-sourcehoteldomaindatasetsand Asurveyonhallucinationinlargelanguagemodels:Princi-
performance analyses presented in this study will establish ples,taxonomy,challenges,andopenquestions.
arobustfoundationforfutureresearchinthisarea,offering
Izacard,G.;andE´douardGrave.2021. Leveragingpassage
valuablediscernmentintothedevelopmentefficientandef-
retrieval with generative models for open domain question
fectiveconversationalAIsystems.
answering.
Johnson,D.;Goodman,R.;Patrinely,J.;Stone,C.;Zimmer-
References
man,E.;Donald,R.;Chang,S.;Berkowitz,S.;Finn,A.;Ja-
Bender, E. M.; Gebru, T.; McMillan-Major, A.; and hangir,E.;etal.2023. Assessingtheaccuracyandreliabil-
Shmitchell, S. 2021. On the dangers of stochastic parrots: ityofAI-generatedmedicalresponses:anevaluationofthe
Canlanguagemodelsbetoobig? Chat-GPTmodel. Researchsquare.Johnson, J.; Douze, M.; Je´gou, H.; et al. 2019. Billion- Lin,S.;Hilton,J.;Evans,O.;etal.2022. Truthfulqa:Mea-
scale similarity search with GPUs. IEEE Transactions on suringhowmodelsmimichumanfalsehoods.
BigData,7(3):535–547. Maynez, J.; Narayan, S.; Bohnet, B.; and McDonald, R.
Johnson,J.;Douze,M.;Jeg´ou,H.;etal.2021. Billion-Scale 2020. Onfaithfulnessandfactualityinabstractivesumma-
SimilaritySearchwithGPUs.IEEEComputerSociety,7(3): rization.
535–547. Min,S.;Krishna,K.;Lyu,X.;Lewis,M.;tauYih,W.;Koh,
Joshi, M.; Choi, E.; Weld, D. S.; and Zettlemoyer, L. P. W.; Iyyer, M.; Zettlemoyer, L.; and Hajishirzi, H. 2023.
2017. Triviaqa: A large scale distantly supervised chal- Factscore: Fine-grained atomic evaluation of factual preci-
lenge dataset for reading comprehension. arXiv preprint sioninlongformtextgeneration.
arXiv:1705.03551. Muhlgay, D.; Ram, O.; Magar, I.; Levine, Y.; Ratner, N.;
Kang, B.; Kim, J.-T.; Yun, T.-R.; and Kim, C.-E. Belinkov, Y.; Abend, O.; Leyton-Brown, K.; Shashua, A.;
2024. Prompt-RAG: Pioneering Vector Embedding-Free andShoham,Y.2023. Generatingbenchmarksforfactuality
Retrieval-AugmentedGenerationinNicheDomains,Exem- evaluationoflanguagemodels.
plifiedbyKoreanMedicine. Narayanan,D.;Shoeybi,M.;Casper,J.;LeGresley,P.;Pat-
Karpukhin,V.;Og˘uz,B.;Min,S.;Lewis,P.;Wu,L.;Edunov, wary,M.;Korthikanti,V.A.;Vainbrand,D.;Kashinkunti,P.;
S.;Chen,D.;andtauYih,W.2020. Densepassageretrieval Bernauer, J.; Catanzaro, B.; Phanishayee, A.; and Zaharia,
foropen-domainquestionanswering. M. 2021. Efficient large-scale language model training on
GPUclustersusingMegatron-LM.
Komeili, M.; Shuster, K.; and Weston, J. 2022. Internet-
Navigli,R.;Conia,S.;Ross,B.;etal.2023. Biasesinlarge
augmenteddialoguegeneration.
language models: origins, inventory, and discussion. ACM
Kwiatkowski, T.; Palomaki, J.; Redfield, O.; Collins, M.;
JournalofDataandInformationQuality,15(2):1–21.
Parikh,A.P.;Alberti,C.;Epstein,D.;Polosukhin,I.;Devlin,
Rackauckas, Z. 2024. Rag-fusion: a new take on retrieval-
J.;Lee,K.;Toutanova,K.;Jones,L.;Kelcey,M.;Chang,M.;
augmentedgeneration. arXivpreprintarXiv:2402.03367.
Dai, A. M.; Uszkoreit, J.; Le, Q. V.; and Petrov, S. 2019.
Natural questions: a benchmark for question answering re- Raffel, C.; Shazeer, N.; Roberts, A.; Lee, K.; Narang, S.;
search. 7:453–466. Matena,M.;Zhou,Y.;Li,W.;andLiu,P.J.2019. Exploring
theLimitsofTransferLearningwithaUnifiedText-to-Text
Lee,K.;Chang,M.;andToutanova,K.2019.Latentretrieval
Transformer.
forweaklysupervisedopendomainquestionanswering.
Robertson,S.;andZaragoza,H.2009. Theprobabilisticrel-
Lee, N.; Wei, P.; Xu, P.; Patwary, M.; Shoeybi, M.; and
evanceframework:BM25andbeyond. 3(4):333–389.
Catanzaro, B. 2022. Factuality enhanced language models
Rush,A.M.;Debut,L.;Sanh,V.;Chaumond,J.;Delangue,
foropen-endedtextgeneration. 35:34586–34599.
C.;Moi,A.;Cistac,P.;Rault,T.;Louf,R.;Morgan,F.;and
Lewis,M.;Ghazvininejad,M.;Ghosh,G.;Aghajanyan,A.;
Brew,J.2019. Huggingface’stransformers:State-of-the-art
Wang,S.;andZettlemoyer,L.2020a. Pre-trainingviapara-
naturallanguageprocessing.
phrasing. 33:18470–18481.
Shi, F.; Chen, X.; Misra, K.; Scales, N.; Dohan, D.; Chi,
Lewis, M.; Liu, Y.; Goyal, N.; Ghazvininejad, M.; Mo-
E.H.;Scha¨rli,N.;andZhou,D.2023. Largelanguagemod-
hamed, A.; Levy, O.; Stoyanov, V.; and Zettlemoyer,
els can be easily distracted by irrelevant context. In Inter-
L. 2020b. BART: Denoising sequence-to-sequence pre-
national Conference on Machine Learning, 31210–31227.
training for natural language generation, translation, and
PMLR.
comprehension.
Shuster, K.; Poff, S.; Chen, M.; Kiela, D.; and Weston, J.
Lewis, P.; Perez, E.; Piktus, A.; Petroni, F.; Karpukhin, V.; 2021. Retrieval Augmentation Reduces Hallucination in
Goyal,N.;Ku¨ttler,H.;Lewis,M.;tauYih,W.;Rockta¨schel, Conversation.
T.; Riedel, S.; and Kiela, D. 2020c. Retrieval-Augmented
Siriwardhana, S.; Weerasekera, R.; Wen, E.; Kaluarachchi,
GenerationforKnowledge-IntensiveNLPTasks.
T.;Rana,R.;andNanayakkara,S.2023. ImprovingtheDo-
Lewis,P.;Stenetorp,P.;andRiedel,S.2021. Questionand mainAdaptationofRetrievalAugmentedGeneration(RAG)
answer test-train overlap in open-domain question answer- ModelsforOpenDomainQuestionAnswering. Association
ingdatasets. forComputationalLinguistics,11:1–17.
Li, J.; Cheng, X.; Zhao, X.; Nie, J.; and Wen, J.-R. 2023. Tamkin, A.; Handa, K.; Shrestha, A.; and Goodman, N.
Halueval:Alarge-scalehallucinationevaluationbenchmark 2022. Task ambiguity in humans and language models.
forlargelanguagemodels. arXivpreprintarXiv:2212.10711.
Li,J.;Yuan,Y.;andZhang,Z.2024a. EnhancingLLMFac- Tonmoy, S. M. T. I.; Zaman, S. M. M.; Jain, V.; Rani, A.;
tualAccuracywithRAGtoCounterHallucinations:ACase Rawte, V.; Chadha, A.; and Das, A. 2024. A Comprehen-
Study on Domain-Specific Queries in Private Knowledge- siveSurveyofHallucinationMitigationTechniquesinLarge
Bases. LanguageModels.
Li,J.;Yuan,Y.;andZhang,Z.2024b.Enhancingllmfactual Trischler, A.; Wang, T.; Yuan, X.; Harris, J.; Sordoni, A.;
accuracywithragtocounterhallucinations:Acasestudyon Bachman, P.; and Suleman, K. 2016. Newsqa: A machine
domain-specificqueriesinprivateknowledge-bases. comprehensiondataset. arXivpreprintarXiv:1611.09830.Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones,
L.;Gomez,A.N.;ŁukaszKaiser;andPolosukhin,I.2017.
AttentionIsAllYouNeed.
Wang,L.L.;Lo,K.;Chandrasekhar,Y.;Reas,R.;Yang,J.;
Burdick,D.;Eide,D.;Funk,K.;Katsis,Y.;Kinney,R.;etal.
2020. Cord-19:Thecovid-19openresearchdataset. ArXiv.
Wu, Q.; Bansal, G.; Zhang, J.; Wu, Y.; Zhang, S.; Zhu, E.;
Li,B.;Jia¯ng,L.;Zhang,X.;andWang,C.2023. AutoGen:
Enabling next-gen LLM applications via multi-agent con-
versation.
Xu, J.; Szlam, A.; and Weston, J. 2022. Beyond goldfish
memory:Long-termopen-domainconversation.
Xu, S.; Pang, L.; Shen, H.; Cheng, X.; and Chua, T.
2023.Search-in-the-Chain:TowardsAccurate,Credibleand
TraceableLargeLanguageModelsforKnowledge-intensive
Tasks.
Xu,S.;Pang,L.;Shen,H.;Cheng,X.;andChua,T.-S.2024.
Search-in-the-Chain: Interactively Enhancing Large Lan-
guage Models with Search for Knowledge-intensive Tasks.
InProceedingsoftheACMonWebConference2024,1362–
1373.
Yang, X.; Sun, K.; Hao, X.; Sun, Y.; Bhalla, N.; Chen, X.;
Choudhary, S.; Gui, R. D.; Jiang, Z.; Jiang, Z.; Kong, L.;
Moran, B.; Wang, J.; Xu, Y.; Yan, A.; Yang, C.; Yuan, E.;
Zha,H.;Tang,N.;Chen,L.;Scheffer,N.;Liu,Y.;Shah,N.;
Wanga,R.;Kumar,A.;tauYih,W.;andDong,X.L.2024.
CRAG–ComprehensiveRAGBenchmark.
Yang,Y.;tauYih,W.;andMeek,C.2015. Wikiqa:Achal-
lengedatasetforopen-domainquestionanswering.
Zhu,Z.;Sun,Z.;andYang,Y.2024. HaluEval-Wild:Eval-
uatinghallucinationsoflanguagemodelsinthewild.Appendix:DomainAdaptationofRAGModelsforQAandHallucinationReduction
A DataPreprocessing Algorithm1:QAPruningAlgorithm
The data preprocessing phase involved consolidating three Require: Q={q ,q ,...,q }:Listofquestions
1 2 n
corpora to form a comprehensive knowledge base for the A={a ,a ,...,a }:Listofcorrespondinganswers
1 2 n
hotel domain. The MultiWOZ corpus contributed multi- K ={k ,k ,...,k }:Setofkeywordsforpruning
1 2 m
domain conversations, including hotel bookings, which we P ={p ,p ,...,p }:Setofphrasesforpruning
1 2 p
segmented into 24,177 concise passages by processing it. L:Minimumstringlengththreshold
Similarly, the TripAdvisor corpus enriched the knowledge Ensure: Highlighted and pruned list of question-answer
base with detailed hotel reviews and descriptions, gener- pairs
ating 20,124 passages. Before segmenting it into passages fori←1tondo
both corpora were converted into a conversational format iflength(q )<Lorlength(a )<Lthen
i i
usingGPT-3.5-Turbo.Additionally,alocalhoteldataset,de- Highlightq and/ora forlength-basedpruning
i i
rivedfromreal-worldcustomerinteractions,provided5,838 endif
passages with domain-specific nuances essential for fine- endfor
tuning.Allconversationsweresplitinto100-120wordpas- foreachkeywordk ∈K do
sagesusingcustomscripts,resultinginatotalof50,139pas- fori←1tondo
sagesintheunifiedknowledgebase.WeemployedGPT-3.5- ifk ∈q then
i
Turbo to generate both question-answer (QA) pairs and re- Highlightq forkeyword-basedpruning
i
construction signals from each passage.Throughout the en- endif
tirepreprocessingpipelinedescribedin4,Theycarefullyre- ifk ∈a then
i
viewedandvalidatedtheQAparis,cross-checkingthemfor Highlighta forkeyword-basedpruning
i
accuracyandrelevancetothehoteldomain.Thismanualin- endif
terventionwas essentialin maintainingthe precisionof the endfor
finaldatasetwhilepreservingtheconversationalcontextvi- endfor
talfortrainingourAImodels.Annotatorsdiligentlyrefined foreachphrasep∈P do
thepassagestoensuretheyaccuratelyrepresenteddomain- fori←1tondo
specificinteractions. ifp∈a then
i
Highlighta forphrase-basedpruning
i
endif
endfor
endfor
fori←1tondo
ifq anda arebothhighlightedthen
i i
Deletethepair(q ,a )
i i
else{q ora ishighlighted}
i i
Retainthepairwithhighlighting
endif
endfor
Figure4:WorkflowofDataPreprocessingStages
we recruited six annotators with an agreement described
inTable11forthetasktorefineandvalidatethegenerated
B DataAnnotationPipeline
18,662 QA pairs with specific guidelines mentioned in
To assist the manual annotators, we developed a data an- Table9toensureamorerigorousvalidationprocess.Their
notationpipelineandmechanismdesignedtoexpeditetheir first task was to evaluate whether each question aligned
assessmentandqualityassuranceprocessesfortheQApairs withtheknowledgebaseandwhetheritwasofhighquality.
andreconstructionsignals,ensuringbothefficiencyandpre- Ifthequestionmetthesecriteria,itwasretained.Otherwise,
cisioninevaluation.Inourdataannotationprocess,wecre- theannotatorswereinstructedtorewritethequestion.
atedanapplicationprovidingatriplet,thepassageswithcor-
responding questions and answers illustrated in Figure 5a. After manual evaluation and validation from the annota-
Then we pruned the QA pairs using a hueristic algorithm tors we followed a series of re-validation steps outlined in
1, reducing the QA pairs to 18,662 and reconstruction sig- Table 12 on our end to maintain high quality of the final
nalsto15,987.Thisensuredthatonlythemostrelevantand datasetofQAParisandReconstructionsignals.Onceallan-
high-qualityentriesremainedformodeltraining.Then notators reviewed the questions, we applied an agreement(a) (b)
Figure5:Left:ScreenshotoftheannotatorinterfaceonQADatasetGeneration.Right:Annotatorinterfaceforhallucination
evaluationandcategorization.
threshold:ifover50%oftheannotatorsagreedthattheques- they classified the responses into one of the following
tion was valid, we retained it in its original form. In cases finer-grained categories: ”Correct,” ”Bias,” ”Ambiguous,”
where consensus was lacking, we selected the best version ”Incompleteness,” or ”Under Informativeness. This cate-
of the question from the rewritten suggestions. Following gorization enables a granular analysis of where and how
the validation phase, we analyzed the entire dataset to as- models deviate from the ground truth answers. Following
sessthedistributionofquestionandanswertypes.Ifcertain this dual categorization, we applied a consensus rule: if
types were over-represented, we re-balanced the dataset by more than 50% of annotators assigned the same category,
regeneratingnewquestionsofthattype.Thesenewlygener- the classification was accepted. In cases where there was
ated questions were again subjected to the same validation insufficient agreement, the responses were re-evaluated
processbytheannotators,ensuringbothqualityandbalance internally to ensure accurate categorization. This process
acrossthedataset. was essential in assessing both the model’s performance
andthetypesofhallucinationitmightgenerate.
C HallucinationEvaluationandAnnotation
Mechanism
Afterobtainingthemodelresponsesfromthehallucination
evaluation dataset, we sent the corresponding QA pairs
containing the ground truth and model-generated answers
to our annotators for further evaluation. At each stage of
the hallucination evaluation pipeline, the same team of
six manual annotators carefully reviewed and validated
question and answers, cross-checking them for coherence,
domain relevance, and factual accuracy. We also provided
a separate guideline described in Table 10 to them for
properly evaluate the hallucinated responses from all the
modelsonaccountofthesameagreementwiththembefore.
The evaluation framework encompasses a multi-stage
process,startingwiththegenerationofresponses,followed
by a systematic analysis by human annotators. Figure 5b
visually captures the flow of information from the initial
input through to the final categorization of hallucinations,
providingclarityonhowoutputsarescrutinizedforinaccu-
racies.
This process begins with the model generating answers
based on external knowledge sources. After that the
recorded responses from all the models undergo human
assessment. Annotators are assigned with reviewing the
content, comparing it to the ground truth and further
determining whether hallucinations are present and then
labelling every responses. The annotators were asked to
perform a two-stage categorization as mentioned in the
guideline.Initially,theycategorizedeachresponseaseither
”Supported,” ”Non-supported,” or ”Irrelevant,” based on
its alignment with the knowledge base. Subsequently,D DatasetandEvaluationGuidelinesforthe E AgreementCriteriaandRe-validation
Annotators Steps
QADataset Agreement
• Eachannotatorwastaskedwithvalidatingandpo- • Annotatorswerecompensatedbasedonthenum-
tentiallyrephrasinggeneratedQApairsbasedon berofquestion-answerpairs(QA)theyprocessed
theprovidedcriteria. and Hallucination Evaluation they classified into
• Astreamlinedpipelinewasprovidedtoassistanno- labels.
tatorsintheirtasks.Eachannotatorreceivedapas- • Abonussystemwasimplementedtorewardhigh-
sage along with GPT-generated question-answer qualitycontributionsandformaintainingaspectra-
pairsandafieldforrephrasingtheQAifnecessary. tio/diversityinthedataset.
• Thecompletedatasetwasprovidedtoallsixanno- • Annotators agreed to confidentiality and were
tators,ensuringthateachcontributedtothevalida- prohibited from disclosing any details about the
tionofabalancedselectionofquestions. dataset.
• Annotators were required to conduct quality • Aslongasqualitywasensured,annotatorsmaybe
checksonthegeneratedQApairs.Ifapairwasun- requiredtorewriteQApairs.Theywouldreceive
clearorpoorlyphrased,theywereresponsiblefor paymentforanyrewritesperformed.
rephrasingittoenhanceclarityandfluency.
• Adherencetotheprovidedguidelineswasmanda-
• IfageneratedQApairdidnotalignwiththein- tory for all annotators to ensure consistency and
tendedtype(e.g.,extractive,descriptive),annota- qualitythroughouttheprocess.
torswereencouragedtomodifythepairtofitthe
appropriatecategory,ensuringalignmentwiththe
question-answercriteria. Table11:AgreementcriteriawiththeAnnotatorsinEvalua-
• Annotators were instructed to avoid multi-hop tions
questions, which require multiple passages. All
questionsweretobeanswerablebasedonasingle
passage.
Re-validation
Table 9: Guideline for the Dataset Generations for the An- • Random sampling from each annotator was per-
formedtocheckthequality.Ifthequalitylagged
notators
atacertainlevel,taskswerereassigned.
• Repetitive questions were checked, especially
whenthenumberofrepeatedquestionswasnotmi-
Hallucination nor.
Evaluation • Annotators were provided with the hallucina- • Ifthereweremanysimilartypeofquestions,such
tiondataset,whichincludedmodelresponses.No as yes/no answers, the dataset was sent back for
model names were disclosed to ensure unbiased rephrasingwithnewlygeneratedquestions.
evaluation.
• Itwassuspectedthatsomeannotatorsdidn’tprop-
• Annotators were informed about the meaning of erlyreadthepassage.Wefound4-5%ofthere-
eachcategoryandrequiredtocategorizetheques- sponsesindicatedmisunderstandingofthepassage,
tionsintwostages: correspondingannotatorwasflaggedforreview.
– Firstly,questionswereclassifiedas”Supported,”
”Non-Supported,”or”Irrelevant.”
– Secondly,questionswereevaluatedfortheircor- Table 12: Re-validation Steps after Performing Manual
rectness,withoptionsincluding”Correct,””Am- Evaluation
biguous,” ”Incomplete,” ”Bias,” and ”Under-
informativeness.”
• To enhance reliability, evaluations were cross-
checkedbyourselvestoensureconsistencyandac-
curacyinthecategorizationprocess.
Table10:GuidelineforHallucinationEvaluationF ExampleofResponseforModels
Question Answer RAG origi- RAG Fine- RAG DPR RAG- FiD
nal tuned Fine-tuned end2end
Can you tell Stove, mi- hotelassistant Outrigger Outrigger Outrigger stove, mi-
me about crowave, Luana offers Luana offers Luana offers crowave and
the kitchen refrigerator a variety a variety a variety refrigerator
amenities provided. of kitchen of kitchen of kitchen
available at amenities amenities amenities
Outrigger such as a such as a such as a
Luana? microwave, microwave, microwave,
refrigerator, refriger- refrigerator,
and coffee ator, and and coffee
maker. microwave maker.
for guests to
enjoy.
What type The Alexan- aguesthouse The Alexan- The Alexan- The Alexan- the Alexander
of accom- der Bed & der Bed & der Bed & der Bed & Bed&Break-
modation is Breakfast is a Breakfast is a Breakfast is a Breakfast is a fast is 4-star
the Alexan- cheap, 4-star 4-star guest- 4-star guest- 4-star guest- guesthouse
der Bed & guesthouse. house located house with house located
Breakfast in in the center free parking in the center
the center of oftown. andinternet. oftown.
town?
Inwhichfloor The second 1stfloor The second The second The second secondfloor
of the Library floor. floor. floor. floor.
Hotel does
have a lounge
area?
What is the 60minutes. 38minutes 60minutes. 60minutes. 60minutes. 1hour
travel time
from Bishops
Stortford to
Cambridge?
Table13:AnExampleofresponsesfromallModelswithEvaluationSetQAG HallucinationExampleforModels
KnowledgeBase Question Answer RAG origi- RAG RAG RAG- FiD
nal Fine- DPR end2end
tuned Fine-
tuned
User:CanyoutellmeaboutthediningoptionsatNishiyama What type Mexican traditional Japanese Traditional it offers Japanese cui-
Onsen Keiunkan? Assistant: Certainly! Nishiyama Onsen of cuisine mexican cui- cuisine. cuisine. mexican sine.
KeiunkanofferstraditionalMexicancuisinewithafocuson Nishiyama sine cuisine
kaiseki,amulti-coursemealthatemphasizesseasonalingre- Onsen
dientsandmeticulouspresentation.User:Mexicancuisine Keiunkan
inJapan?Thatsoundsintriguing.Whatkindsofdishesare offers?
served?Assistant:Thekaisekimealsincludelocalspecialties
likefreshsashimi,grilledfish,simmeredvegetables,andpre-
miumcutsofmeat,alldesignedtohighlightnaturalflavors
andtextures.User:Wheredotheysourcetheiringredients
from?Assistant:Manyingredientsaresourcedfromthesur-
roundingmountainsandrivers,ensuringfreshandauthentic
flavors.User:Itsoundsdelightful!Ican’twaittotryit.
User:Hi,IrecentlystayedatyourhotelofMarinaBayback How were There were managed The wi-fi The wi-fi Therewas The staff ad-
in2007andhadagreatexperience.Iwoulddefinitelyrec- the Wi-Fi no Wi-Fi connectiv- in the nowifiis- dressedtheis-
ommendittoothers!HotelAssistant:That’swonderfulto connectivity connectivity ity issues room sueduring sues.
hear!Wealwaysstrivetoprovideagreatexperienceforour issues man- issues during in the was not thestay.
guests.Whatdidyouenjoymostaboutyourstay?User:I aged in the the stay. The Marin- working
lovedthefactthatIwasupgradedtoaseaviewroomwith MarinaBay seaviewroom abayhotel properly,
a beautiful garden. The grounds and pool area were also Hotel room had good roomwere making it
well-maintained.HotelAssistant:I’mgladyouenjoyedyour during the Wi-Fi signal resolved difficult
roomandtheamenitiesweoffer.Wetakeprideinkeeping stay? and made quickly toconnect
ourpropertycleanandwelcomingforallguests.User:The the gues’ts and effi- to the
staffatthehotelwereveryfriendlyandaccommodating.Ho- convenient ciently. internet.
telAssistant:Thankyouforyourkindwords.Wenotedthat
therewasareportedissuewithnoiselevelsintheseaview
rooms.Didthataffectyourstay?
User:WhatcanyousayabouttheDorchesterinLondon? When was In1940 1940 Early Early 1940 The Dorch-
HotelAssistant:TheDorchester,openedin1940,isapres- Dorchester 1980s. 1980s. ester Hotel
tigious luxury hotel in London. User: What amenities are HotelinLon- in London
available?HotelAssistant:Itofferselegantrooms,finedin- donopened? openedinthe
ing,andarenownedspa.User:Whatattractionsarenearby? early1980s.
HotelAssistant:It’slocatednearHydeParkandMayfair.
User:What’sspecialabouttheSavoyHotelinLondon?Hotel Is Savoy Ho- It’s the third is or isn’t a Yes,itis. Yes,itis. noitisn’t. Savoy Group
Assistant:TheSavoyisknownforitsrichhistoryandluxuri- tel is the first Hotel hotel isthefirstho-
ousaccommodations.User:Whatamenitiesdoesitprovide? hotelinSavoy tel in Savoy
HotelAssistant:Itoffersarenownedrestaurant,aclassicbar, Group? Group.
andatheater.User:Whatattractionsarenearby?HotelAs-
sistant:It’sclosetoCoventGardenandtheThamesRiver.It
wasthethirdHotelintheSavoygroupofhotelsandrestau-
rantsownedbyRoyalfamilyforoveracentury.
Table14:HallucinationExamplewithQApair