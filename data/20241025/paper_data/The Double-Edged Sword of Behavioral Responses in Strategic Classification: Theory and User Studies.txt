THE DOUBLE-EDGED SWORD OF BEHAVIORAL RESPONSES IN
STRATEGIC CLASSIFICATION: THEORY AND USER STUDIES
RamanEbrahimi KristenVaccaro ParinazNaghizadeh
ECE,UCSanDiego CSE,UCSanDiego ECE,UCSanDiego
raman@ucsd.edu kv@ucsd.edu parinaz@ucsd.edu
October24,2024
ABSTRACT
Whenhumansaresubjecttoanalgorithmicdecisionsystem,theycanstrategicallyadjusttheirbehavior
accordingly(“game”thesystem). Whileagrowinglineofliteratureonstrategicclassificationhas
usedgame-theoreticmodelingtounderstandandmitigatesuchgaming,theseexistingworksconsider
standardmodelsoffullyrationalagents. Inthispaper,weproposeastrategicclassificationmodel
thatconsidersbehavioralbiasesinhumanresponsestoalgorithms. Weshowhowmisperceptionsof
aclassifier(specifically,ofitsfeatureweights)canleadtodifferenttypesofdiscrepanciesbetween
biased and rational agents’ responses, and identify when behavioral agents over- or under-invest
in different features. We also show that strategic agents with behavioral biases can benefit or
(perhaps,unexpectedly)harmthefirmcomparedtofullyrationalstrategicagents. Wecomplement
ouranalyticalresultswithuserstudies,whichsupportourhypothesisofbehavioralbiasesinhuman
responsestothealgorithm. Together,ourfindingshighlighttheneedtoaccountforhuman(cognitive)
biaseswhendesigningAIsystems,andprovidingexplanationsofthem,tostrategichumaninthe
loop.
1 Introduction
Asmachinelearningsystemsbecomemorewidelydeployed,includinginsettingssuchasresumescreening,hiring,
lending,andrecommendationsystems,peoplehavebeguntorespondtothemstrategically. Often,thistakestheform
of“gamingthesystem”orusinganalgorithmicsystem’srulesandprocedurestomanipulateitandachievedesired
outcomes. ExamplesincludeUberdriverscoordinatingthetimestheylogonandofftheapptoimpactitssurgepricing
algorithm(MöhlmannandZalmanson,2017),andTwitter(Burrelletal.,2019)andFacebook(Eslamietal.,2016)
users’decisionsregardinghowtointeractwithcontentgiventheplatforms’curationalgorithms.
Gametheoreticalmodelingandanalysishavebeenusedinrecentyearstoformallyanalyzesuchstrategicresponsesof
humanstoalgorithms(e.g.,Hardtetal.(2016);Millietal.(2019);Liuetal.(2020);seealsoRelatedWork). However,
theseexistingworksassumestandardmodelsofdecisionmaking,whereagentsarefullyrationalwhenrespondingto
algorithms;yet,humansexhibitdifferentformsofcognitivebiasesindecisionmaking(KahnemannandTversky,1979).
Motivatedbythis,weexploretheimpactsbehavioralbiasesonagents’strategicresponsestoalgorithms.
We begin by proposing an extension of existing models of strategic classification to account for behavioral biases.
Specifically,ourmodelaccountsforagentsmisperceiving(i.e.,over-weighingorunder-weighing)theimportanceof
differentfeaturesindeterminingtheclassifier’soutput. Thesemaybeknowntoagentsinafullinformationgame
orcanbecomeavailabletothemwhenthefirmoffersexplanationsthroughanExplainableAI(XAI)methodwhich
providesinformationaboutfeatureimportance/contributioninthealgorithm(e.g. SHAP(LundbergandLee,2017)or
LIME(Ribeiroetal.,2016)). Weusethismodeltoidentifydifferentformsofdiscrepanciesthatcanarisebetween
behavioralandfullyrationalagents’responses(Lemmas1-3). Wefurtheridentifyconditionsunderwhichagents’
behavioralbiasesleadthemtoover-orunder-investinspecificfeatures(Proposition1). Moreover,weshowthata
firm’sutilitycouldincreaseordecreasewhenagentsarebehaviorallybiased,comparedtowhentheyarefullyrational
(Proposition2). Whiletheformermaybeintuitivelyexpected(behaviorallybiasedagentsarelessadeptatgaming
4202
tcO
32
]GL.sc[
1v66081.0142:viXraAPREPRINT-OCTOBER24,2024
algorithms), the latter is more surprising; we further provide an intuitive explanation for this through a numerical
example(Example1),highlightingtheimpactofagents’qualificationstatesindeterminingtheultimateimpactof
agents’behavioralbiasesonthefirm.
Finally,byconductingauserstudy,weshowthatthistypeofbehavioralbiasispresentwhenindividualsinteractwith
anAIdecisionassistant. Ourstudyshowsthatindividualstendtounderestimatetheimportanceofthemostcrucial
featurewhileoverestimatingtheimportanceoftheleastimportantone. Wealsofindthatincreasingthecomplexity
ofthemodel,eitherbyaddingmorefeaturesorhavingunbalancedfeatureweights,amplifiesthisbias. Additionally,
weobserveotherformsofcognitivebiases(notcapturedbyprobabilityweightingbiases),suchassomeindividuals
disproportionatelyinvestinginafeaturewithalowerstartingpointwhenfeatureweightsaresimilar.
Together,ourtheoreticalfindingsanduserstudieshighlightthenecessityofaccountingfornotjuststrategicresponses
butalsocognitivebiaseswhendesigningAIsystemswithhumanintheloop.
Summaryofcontributions.
• Weextendexistingmodelsofstrategicclassificationtoaccountforagents’cognitivebiasesinperceivingfeature
importance.
• Weanalyzehowthesebiasesleadtoover-orunder-investmentincertainfeaturescomparedtofullyrationalagents.
Wefurthershowthatbehaviorallybiasedagentscanincreaseordecreasefirmutility.
• Through a user study, we confirm that cognitive biases influence human’s understanding of and responses to AI
systems,especiallywhentheyaregiven(explanationsof)modelswithunbalancedfeatureweightsandahighernumber
offeatures.
Related Work. Our work is closely related to the literature on analyzing agents’ responses to machine learning
algorithms,whenagentshavefull(Hardtetal.,2016;Perdomoetal.,2020;Millietal.,2019;Huetal.,2019;Liuetal.,
2020;Bechavodetal.,2022;KleinbergandRaghavan,2020;AlhanoutiandNaghizadeh,2024;Zhangetal.,2022;
Bechavodetal.,2021;Harrisetal.,2022)orpartialinformation(Haghtalabetal.,2024;Cohenetal.,2024)aboutthe
algorithm. Whileourbasemodelofagents’strategicresponsesto(threshold)classifiershassimilaritiestothosein
someoftheseworks(e.g.,Huetal.(2019);Liuetal.(2020)),wedifferinourmodelingofagent’sbehavioralresponses
asopposedtofullyrational(non-behavioral)bestresponsesconsideredintheseworks.
Thenecessityofaccountingforhumanbiaseswhenrespondingtoalgorithmicdecisionrules(otherthanclassification)
hasbeenconsideredinrecentwork(Morewedgeetal.,2023;Zhuetal.,2024;Liuetal.,2024;Heidarietal.,2021;
Ethayarajhetal.,2024). Amongthese,Heidarietal.(2021)usesprobabilityweightingfunctionstomodelhuman
perceptionsofallocationpolicies. Wealsoconsider(Prelec)weightingfunctions,buttohighlightspecialcasesofour
results. Wealsodifferfromalltheseexistingworksinourfocusonthestrategicclassificationproblem.
Broadly,ourresearchisalsorelatedtotheareaofexplainablemachinelearning. Whileexplanationscanbehelpfulin
increasingaccountability,thereisdebateabouttheefficacyofexistingexplainabilitymethodsinprovidingcorrectand
sufficientdetailsinawaythathelpsusersunderstandandactaroundthesesystems(Doshi-Velezetal.,2017;Kumar
etal.,2020;LakkarajuandBastani,2020;Adebayoetal.,2018). Tocomplementthesediscussions,ourworkprovides
aformalmodelofhowagents’behavioralbiasesmayshapetheirresponsestoexplanations(offeatureimportance)
providedtothem. Wefurtherconfirmthepresenceofbehavioralbiasesthroughauserstudy. Previousworkshave
utilizeduserstudiestoassessinterpretablemodelsbasedonfactorssuchastimespent,numberofwords,andaccuracy
(Lakkaraju et al., 2016), to establish the core principles of interpretability goals Hong et al. (2020), and to assess
theimpactofmodelinterpretabilityonpredictingmodeloutputs(Poursabzi-Sangdehetal.,2021). Incontrast,we
assesshowbehavioralbiasescanresultinhumansubjects’sub-optimalresponsestointerpretablemodels. Wereview
additionalrelatedworkinAppendixA.
2 ModelandPreliminaries
StrategicClassification. Weconsideranenvironmentinwhichafirmmakesbinaryclassificationdecisionsonagents
with(observable)featuresx∈Rnand(unobservable)truequalificationstates/labelsy ∈{0,1},wherelabely =1(resp.
y =0)denotesqualified(resp. unqualified)agents. Thefirmusesathresholdclassifierh(x,(θ,θ ))=1(θTx≥θ )
0 0
toclassifyagents,where1(·)denotestheindicatorfunction,andθ =[θ ,θ ,...,θ ]T denotesthefeatureweights;we
1 2 n
(cid:80)
assumefeaturesarenormalizedsothat θ =1.
i i
Agentsarestrategic,inthattheycanrespondto(“game”)thisclassifier. (Asanexample,inacollegeadmissionsetting
wheregradesareusedtomakeadmissiondecisions,studentscanstudyorcheattoimprovetheirgrades.) Formally,an
agentwithpre-strategicfeaturesx best-respondstoclassifier(θ,θ )toarriveatthe(non-behavioral)post-strategic
0 0
2APREPRINT-OCTOBER24,2024
featuresx bysolvingtheoptimizationproblem:
NB
x :=argmax rh(x,(θ,θ ))−c(x,x )
NB 0 0
x
subjectto c(x,x )≤B (1)
0
where r > 0 is the reward of positive classification, c(x,x ) is the cost of changing feature vector x to x, and
0 0
B is the agent’s budget. We consider three different cost functions: norm-2 cost (with c(x,x ) = ∥x−x ∥2 =
0 0 2
(cid:80) (x −x )2),quadraticcost(withc(x,x )=(cid:80) c (x −x )2),andweightedManhattan(taxicab)distancecost
i i i,0 0 i i i 0,i
(withc(x,x )=cT|x−x |=(cid:80) c (|x −x |)). Ouranalyticalresultsarepresentedforthenorm-2cost. Wealso
0 0 i i i 0,i
characterizetheagent’sbest-responsesunderothercostfunctionstohighlightthatsimilaragentbehaviorcanbeseen
underthem.
Anticipatingtheagents’responses,thefirmcanchoosetheoptimal(non-behavioral)classifierthresholdbysolving
(θ ,θ ) := argmin E [l(x,(θ,θ ))], where D(θ,θ ) is the post-strategic feature distribution of
NB 0,NB (θ,θ0) x∼D(θ,θ0) 0 0
agentsrespondingtoclassifier(θ,θ ),andl(·)isthefirm’slossfunction(e.g.,weightedsumofTPandFPcosts).
0
Behavioral Responses. We extend the strategic classification model to allow for behavioral responses by agents.
Formally,recallthatwenormalizethefeatureweightvectorθ =[θ ,θ ,...,θ ]T tohave(cid:80) θ =1. Weinterpretit
1 2 n i i
asaprobabilityvector,andassumethatbehaviorallybiasedagentsmisperceiveθasw(θ),wherew(·)isafunction
capturing their biases. One choice for w(·) can be w (θ) =
p((cid:80)j
θ
)−p((cid:80)j−1θ
) (Gonzalez and Wu, 1999)
j i=1 i i=1 i
wherep(z)=exp(−(−ln(z))γ)isthewidelyusedprobabilityweightingfunctionintroducedbyPrelec(1998)withγ
reflectingtheintensityofbiases.
Now, a behaviorally biased agent with pre-strategic features x best-responds to classifier (θ,θ ) to arrive at the
0 0
behavioralpost-strategicfeaturesx bysolving:
B
x :=argmax rh(x,(w(θ),θ ))−c(x,x )
B 0 0
x
subjectto c(x,x )≤B (2)
0
Notethattheagentnowrespondstoaperceivedfeatureweights(w(θ),θ ). Inreturn,whilealwaysaccountingfor
0
agents’strategicbehavior(“gaming”),weassumethefirmmayormaynotbeawarethatagentshavebehavioralbiases
whengamingthesystem. Specifically,letL(θ′,(θ,θ )) := E [l(x,(θ,θ ))]denoteafirm’sexpectedloss
0 x∼D(θ′,θ0) 0
whenitimplementsaclassifier(θ,θ )andagentsrespondtoa(potentiallydifferent)classifier(θ′,θ ). Then,ifafirm
0 0
isawareofstrategicagents’behavioralbiases, itselectsthethreshold(θ ,θ ) := argmin L(w(θ),(θ,θ ))
B 0,B (θ,θ0) 0
andincursalossL(w(θ ),(θ ,θ )). Ontheotherhand,afirmthatassumesagentsarefullyrationalselectsthe
B B 0,B
thresholdclassifier(θ ,θ ),yetincursthelossL(w(θ ),(θ ,θ )).
NB 0,NB NB NB 0,NB
3 Agents’StrategicResponses
Wefirstfixtheclassifier(θ,θ ),andcomparefullyrational(non-behavioral)andbehavioralagents’strategicresponses
0
toit. ThefollowingLemmacharacterizesx (thesolutiontoequation1)andx (thesolutiontoequation2)underthe
NB B
norm-2cost.
Lemma1. Letd(x 0,θ,θ 0) = θ0− ∥θθ ∥Tx0 denotex 0’sdistancetothehyperplaneθTx = θ 0. Then,foranagentwith
2
startingfeaturevectorx ,if0<d(x ,θ,θ )≤B,
0 0 0
x =x +d(x ,θ,θ )θ.
NB 0 0 0
Otherwise,x =x . Forbehaviorallybiasedagents,x isobtainedsimilarlybyreplacingθwithw(θ).
NB 0 B
Figure1illustratesthestrategicagents’best-responsesofLemma1,inatwo-dimensionalfeaturespace,whentheyare
non-behavioral(Fig.1a)andwhentheyarebehavioral(Fig.1b). Wefirstnotethatthesubsetofagentswithnon-trivial
responsestotheclassifier,asidentifiedinLemma1,areinabandbelowthedecisionboundary. Giventheoverlaps
ofthesebandsundernon-behavioralandbehavioralresponses, thereare6regionsofinterestwherebiasedagents’
best-responsesdeferfromrationalagents(Fig.1c). Inregions 1 and 6,agentsinvestnoeffortinmanipulatingtheir
featureswhentheyarebehaviorallybiased,whereastheydowhenfullyrational;thereasonsdiffer: agentsin 1 believe
theyareacceptedwithouteffort,whilethosein 6 believetheydonothavesufficientbudgettosucceed. Agentsin
regions 2 and 5 manipulatetheirfeaturesunnecessarily(theywouldnot,hadtheybeenfullyrational),andagain,for
differentreasons: agentsin 2 arenotacceptedevenattheirhighesteffortlevel,whilethosein 5 believetheymust
reachtheboundarybuttheywouldbeacceptedregardlessoftheireffort. Finally,inregion 3,agentsundershootthe
3APREPRINT-OCTOBER24,2024
(a)Rationalstrategicresponse (b)Biasedstrategicresponse (c)Differingstrategicresponses
Figure1: (a)Fullyrationaland(b)Biasedresponses,and(c)Classesofdifferingactionsunderquadraticcosts.
actualboundary(i.e.,exertlesseffortthanneededduetotheirbiases),whilethoseinregion 4 overshoot(i.e.,exert
moreeffortthanneededtogetaccepted).
Inthefollowingproposition,wefurtherinvestigatebest-responsesinregion 4 (resp. region 3)andidentifywhich
featuresbehavioralagentsover-investin(resp. under-investin)thatleadstothemovershooting(resp. undershooting)
pastthetrueclassifier(θ,θ ).
0
Proposition 1. Consider an agent with features x , facing classifier (θ,θ ), and with a misperceived w(θ). Let
0 0
θ
max
=max iθ i,d(x 0,θ,θ 0)= θ0− ∥θθ ∥Tx0,andδ iNB =x NB,i−x 0,iandδ iB =x B,i−x 0,idenotethechangesinfeature
2
iafterbest-responses. Then:
(1)Ifd(x ,w(θ),θ )≤d(x ,θ,θ )andw(θ )<θ ,thenδB <δNB.
0 0 0 0 i i i i
(2)Ifd(x ,θ,θ )≤d(x ,w(θ),θ )andθ <w(θ )thenδNB <δB.
0 0 0 0 i i i i
1 γ
(3)ForthespecialcaseofaPrelecfunction,wefurtherhave: Ifd(x ,θ,θ ) ≤ eγ1−γ−γ1−γd(x ,w(θ),θ )and
0 0 0 0
w(θ )<θ ,thenδNB <δB .
max max max max
Intuitively,thepropositionstatesthatagentswhoperceivethedecisionboundarytobeclosertothemthanittrulyis
(regions 2 and 3 inFigure1c)willunder-investinthefeaturesforwhichtheyunderestimatetheimportance. Similarly,
agentsthatperceivetheboundarytobefarther(regions 4 and 5 inFigure1c)willover-investinthefeaturesforwhich
theyoverestimatetheimportance.
3.1 AlternativeCostFunctions
We next show that regions of differing responses between behavioral and non-behavioral agents, similar to those
depictedinFigure1c,willalsoemergeunderquadraticandweightedManhattancostfunctions.
QuadraticCostFunction. Thefollowinglemmacharacterizesthepost-strategicfeaturesunderthequadraticcost
c(x,x )=(cid:80) c (x −x )2.
0 i i i i,0
Lemma2. LetC denoteadiagonalmatrixwithc ’sasitsdiagonal,andletydenotethefeaturevectorssatisfying
i
θTy =θ . Foranagentwithstartingfeaturevectorx ,ifx isinthen-dimensionalellipsoiddescribedbyBandC,
0 0 0
i.e.,if(y−x )TC(y−x )≤B,
0 0
θ −θTx θ
x = 0 0 · i +x .
NB,i (cid:80) θ2 c 0,i
j i
j cj
Otherwise,x =x . Forbehaviorallybiasedagents,x isobtainedsimilarlybyreplacingθwithw(θ).
NB 0 B
Figure 2 illustrates the best-responses of Lemma 2 for rational (non-behavioral) and biased (behavioral) agents.
Specifically,theconditioninLemma2constructsann-dimensionalellipsoidaroundeverypointonthelineθTx=θ ,
0
containingagentswhohavesufficientbudgettostrategicallychangetheirfeaturestoreachthatparticularpointon
theboundary,withthecoefficientsc determiningthescalingalongeachaxis. Sincethescalingoftheellipsoiddoes
i
notdependonthepointofthelinewearefocusingon,theunionoftheseellipsoids(determiningthesetofallagents
whocanaffordtobeclassifiedpositivelythroughgaming)formsabandbelowthelineθTx=θ . Notethatthisband
0
differsfromtheoneinLemma1.
4APREPRINT-OCTOBER24,2024
(a)Rationalresponse (b)Biasedresponse
Figure2: Strategicresponsesunderquadraticcosts.
WeightedManhattanDistanceCostFunction. Thefollowinglemmacharacterizesthepost-strategicfeaturesunder
(cid:80)
theweightedManhattancostc(x,x )= c |x −x |.
0 i i i i,0
Lemma3. Lete ibetheunitvectorwith1intheithcoordinateand0elsewhere,andk =argmin
i
θci i. Foranagent
withstartingfeaturex 0,ifθTx 0+ θ ckkB ≥θ 0,
c
x =x +(θ −θTx ) ke .
NB 0 0 0 θ k
k
Otherwise,x =x . Forbehaviorallybiasedagents,x isobtainedsimilarlybyreplacingθwithw(θ).
NB 0 B
Figure3illustratesthebest-responsesofLemma3forrational(non-behavioral)andbiased(behavioral)agents. Again,
thesetofagentswhocanaffordtogamethesystemtoreceiveapositiveclassification,asidentifiedinLemma3,isa
bandbelowtheclassifier(butdifferentfromthoseofLemmas1and2). Inparticular,underthiscost,agentsspendall
theirbudgetonchangingthefeaturewiththemost“bang-for-the-buck” ci (orperceivedbang-for-the-buck ci ). As
θi wi(θ)
seeninthetwo-dimensionalillustrationinFigure3,thismeansthatwhileitisoptimalforrationalagentstoinvestonly
infeature2,thosewithbehavioralbiasbelievefeature1hasabetterreturn,leadingtoasub-optimalresponsebythem.
Wealsonotethateventhoughthemovementsofagentsinthespecifiedbandaredifferentfromthemovementforthe
norm-2cost,thebandsformthesameregionsofdifferingresponsesasinFigure1,whereagentsovershoot,undershoot,
donothingatall,orneedlesslychangetheirfeatures,whentheyarebehaviorallybiased.
(a)Rationalresponse (b)Biasedresponse
Figure3: StrategicresponsesunderManhattancosts.
5APREPRINT-OCTOBER24,2024
CostFunctionintheUserStudies. ForourhumansubjectexperimentsinSection5,wedescribethecostofchanging
featurestoparticipantsthroughapiecewiselinearcostfunction. Thiscanbeviewedasanapproximationofaquadratic
costusingastepfunctionwithaweightedManhattancostateachstep,withtheapproximationimprovingasthenumber
ofstepsincreases(seethetwo-dimensionalillustrationinFigure4). Specifically,inouruserexperiments,webreakthe
budgetB intothreestepsofincrementsB ,B ,andB withB +B +B =B,andassignaconstantcostc ,c ,
1 2 3 1 2 3 1 2
andc forchangingfeaturesateachincrement. Thismeansthatineachstep,agentsfaceaweightedManhattancost,
3
butoverall,thecostisnotfixed,andinvestinginasinglefeatureisnotoptimal.
Figure4: Strategicresponsesunderaquadraticcost(green)vs. apiece-wiselinearcostfunction(blue).
4 Firm’sResponse
Wenextconsiderthefirm’soptimalchoiceofaclassifier,givenagents’strategicresponses,anditsimpactonthefirm’s
utilityandagents’welfare. Intuitively,onemightexpectafirmtoultimatelybenefitfromagents’behavioralresponses
(incontrasttofullyrationalresponses)asbehavioralagentsarelessadeptatgamingthealgorithm. However,inthis
section,weshowthatthisisnotalwaystrue. Intuitively,asdemonstratedinSection3,behavioralagentsmayovershoot
orundershootthethresholdwhengamingthealgorithm(comparedtorationalagents); thisincludesbothqualified
(label1)andunqualified(label0)agents. Weshowthatthereexistscenariosinwhicharelativelyhighernumberof
behaviorallybiasedqualifiedagentsendupbelowthethreshold(duetonottryingorundershooting)whilerelatively
moreunqualifiedagentsovershootandendupacceptedbytheclassifier;thecombinationofthesefactorscandecrease
thefirm’sutility. Inotherwords,perhapsunexpectedly,inthesesituations,thefirmwouldpreferrationalagents,who
arebetteratgamingthesystem,tobehaviorallybiasedagents,whoareworseatgamingthesystem. Thefollowing
examplenumericallyillustratesthis.
Example1. Considerasettingwherewehavea2Dfeaturespaceandqualified(resp. unqualified)agentsaresampled
fromanormaldistributionN(µ ,Σ )(resp. N(µ ,Σ )). Weconsiderthreescenarios;thefirsttwoscenariosonly
1 1 0 0
differinthemeanµ choice,andthethirdscenariodifferswiththeseinµ ,Σ ,Σ ,andB(seeAppendixCfordetails).
1 1 1 0
Thefirsttwoscenarios(topandmiddlerowsinFigure5)arebaselines: weconsideranobliviousfirmthatchoosesits
classifierwithoutaccountingforanystrategicresponse(whetherrationalorbehavioral)fromagents. Thishelpsus
honeinontheimpactsofagents’qualificationstatesonthefirm’sutility. Then,inthethirdscenario(bottomrowin
Figure5),weconsiderafirmthatisawareofstrategicbehavior(andanybehavioralbiases)byagentsandoptimally
adjustsitsclassifier. Foreachscenario,Figure5illustratesthedistributionofagents’featuresforpre-strategic(left
panel),post-strategicnon-behavioralresponses(middlepanel),andpost-strategicbehaviorally-biasedresponses(right
panel). Thefirm’sutilityineachcaseisshownatthetopofthecorrespondingsubplot.
We start with the baselines (an oblivious firm that keeps the classifier fixed). In the top row scenario, the firm is
negativelyimpactedbyagents’behavioralbiases,whileinthemiddlerowscenario,thefirmbenefitsfromagents’biases
(bothcomparedtothefullyrationalsetting). Thereasonforthisdifferenceisthattherearemorequalifiedagentsthan
unqualifiedoneswhoreachthethresholdinnon-biasedresponses. Ontheotherhand,underbiasedresponses,there
aremoreunqualifiedagentswhopassthethreshold,regardlessoftheirbias(thoseinregion 3 inFig.1c)inthetop
rowscenario. Behavioralresponsesbytheseagentsnegativelyimpactthefirm,asitleadstothesequalifiedagentsno
longerbeingaccepted.
Next,weconsiderthe(non-oblivious)firmthatadjustsitsclassifieroptimally(accountingforstrategicresponsesand
behavioralbiases,ifany). Weobservethateventhoughthefirmisawareofagents’bias,itslossishigherthanthecase
ofrationalresponses. AsseenintheleftpanelofthebottomrowofFigure5,moreregionscanimpactthelossthanin
Figure1. Themostimportantregionsinthisscenarioaretheareasacceptedbyθ butnotbyθ (afterresponse),and
NB B
viceversa. Astherearemorequalifiedthanunqualifiedagentsinthesetworegions,thefirmisnegativelyimpactedby
agents’bias(comparedtofullyrationalagents)eventhoughthefirmisawareofthebias.
Thenextpropositionformalizestheaboveintuition.
6APREPRINT-OCTOBER24,2024
Figure5: Anobliviousfirmmayhavelower(top)orhigher(middle)utilitywhenagentsarebiased(vs. rational). A
non-obliviousfirmmaystillhavealowerutilitywhenagentsarebiased(bottom).
Proposition 2. Consider a loss function l(x,(θ,θ )) = −u+TP+u−FP. Let the pdf of label y agents’ feature
0
distribution be f (x), and the number of label y agents be α . Let H(θ,θ ) denote the set of agents that satisfy
y 0 0
(1 − σ(θ))θ ≤ (θ − σ(θ)w(θ))Tx, where σ(θ) := θTw(θ)1, and the set of agents that attempt to game the
0 ∥w(θ)∥2
algorithm as A(θ,θ ) = {x : θ −B ≤ θTx < θ }. Denote the set of accepted (resp. rejected) agents by
0 0 0 0 0
(θ,θ )withY(θ,θ )(resp. N(θ,θ )). DefinethesetsS(θ ,θ ):=A(θ ,θ )/(A(θ ,θ )∩H(θ ,θ )),
0 0 0 NB 0,NB NB 0,NB NB 0,NB NB 0,NB
T = (Y(θ ,θ )∪A(θ ,θ ))∩N(θ ,θ ), and T = (H(θ ,θ )∩A(w(θ ),θ ))∪((Y(θ ,θ )∩
1 NB 0,NB NB 0,NB B 0,B 2 B 0,B B 0,B B 0,B
N(θ ,θ ))/A(θ ,θ )). Then:
NB 0,NB NB 0,NB
(a)If(cid:82) u−f (x)α dx≤(cid:82) u+f (x)α dxwecansay:
x∈S(θNB,θ0,NB) 0 0 x∈S(θNB,θ0,NB) 1 1
L(w(θ ),(θ ,θ ))≤L(w(θ ),(θ ,θ ))≤L(θ ,(θ ,θ )) (3)
B B 0,B NB NB 0,NB NB NB 0,NB
1Notethatσ(θ)= ∥θ∥2 cos(α)whereαistheanglebetweentheactualandperceiveddecisionboundaries.Thelargerαis,
∥w(θ)∥2
thelowerσ(θ)is,indicatingamoreintensebias.
7APREPRINT-OCTOBER24,2024
(b)If(cid:82) u+f (x)α dx≤(cid:82) u−f (x)α dxwecansay:
x∈S(θNB,θ0,NB) 1 1 x∈S(θNB,θ0,NB) 0 0
max{L(θ ,(θ ,θ )),L(w(θ ),(θ ,θ ))}≤L(w(θ ),(θ ,θ )) (4)
NB NB 0,NB B B 0,B NB NB 0,NB
(c)If(cid:82) (−u+f (x)α +u−f (x)α )dx≤(cid:82) (−u+f (x)α +u−f (x)α )dxwecansay:
x∈T
1
1 1 0 0 x∈T
2
1 1 0 0
L(θ ,(θ ,θ ))≤L(w(θ ),(θ ,θ ))≤L(w(θ ),(θ ,θ )) (5)
NB NB 0,NB B B 0,B NB NB 0,NB
Part(a)statesthatifafirmisunawareofagents’behavioralbiases,itwillsufferalowerlosswhenthepopulationis
biasedcomparedtofullyrational. Thisistheintuitivelyexpectedscenario(behaviorallybiasedagentsarelessadept
thanfullyrationalonesatgamingthealgorithm). Ontheotherhand,statement(b)reflectsthelessexpectedoutcome: a
firmunawareofbehavioralbiaseswillhavelowerutilitywhenagentsarebiasedcomparedtoiftheyhadbeenfully
rational(asmorequalifiedthanunqualifiedagentsundershootthethresholdunderthiscase’scondition). Statement(c)
furthercomparestheunawarefirmwithanawarefirmandprovidesaconditionwhereanawarefirm’sminimallossis
higherthanthenon-biasedminimalloss. Thisconditionreliesonthedifferenceofqualifiedandunqualifiedagentsin
tworegions.
Agents’Welfare: Weendthissectionbycomparingtheimpactsofbehavioralbiasesonagents’welfare(sumoftheir
utilities). Asabaseline,notethatifthefirmwasoblivioustoagents’strategicresponsesanddidnotadjusttheclassifier,
agentswouldhavelowerwelfarewhentheyarebehaviorallybiased(comparedtowhenrational). Thisisanexpected
outcomesincebehaviorallybiasedagentsareworseatgamingthealgorithmandrespondsub-optimally. But,perhaps
moreunexpectedly,whenthefirmadjustsitsclassifierinresponsetoagents’strategicbehaviorandbehavioralbiases,
variousscenarioscanoccur. Forinstance,inthebottomrowofFigure5,qualifiedagentshavehighersocialwelfare
whentheyarebehaviorallybiasedcomparedtoiftheyhadbeenrational. Weprovideadditionaldetailsonreasonsfor
thisinAppendixD.
5 UserStudy
5.1 StudyDesign,Participants,andSetup
Tounderstandhowhumanbiasesaffecttheirresponsestoalgorithms,weconductedalarge-scaleonlinesurveywhere
participantscompletedataskwithanoptimalsolution. Wethenmeasuredhowtheiranswersdifferedfromtheoptimal
solutiontoassessbias. Similartoprevioussections,wefocusonhowparticipantsperceivethefeatureweightsandhow
thisinfluencestheirresponsetothealgorithm. Surveysgenerallytook5.5minutes,andparticipantswerepaid$16per
hour. ThestudydesignwasreviewedbyourIRB,andthefullprotocolisincludedinthesupplementarymaterials.
Experimental Design. We used a 2×2 between-subjects design, varying the number of features and the feature
weights. Participantswererandomlyassignedtoaconditionandshownasingleexplanation(showninFigure6),with
a)eithertwoorfourfeaturesandb)eitherbalancedorunbalancedfeatureweights.
Procedure. All participants were shown a truthful and complete explanation from an interpretable ML algorithm.
Eachparticipantwasaskedtocompleteataskbasedontheinformationprovidedintheexplanation. Aftercompleting
thetask,participantswereaskedquestionsabouttheirunderstanding,trust,satisfaction,andperformance,common
measuresinexplainabilityevaluations(Mohsenietal.,2021).
Explanation. Based on prior work, which has found that feature importance is the most used explanation (Nauta
etal.,2023)andthatvisualizationcanhelpusersunderstandexplanations(AdadiandBerrada,2018),wedevelopedan
explanationthatshowsfeatureweightsinabargraph(Figure6). Thesystemusesthedisplayedfeatureweightsasan
interpretableMLalgorithm.
Task. Thetaskaskedparticipantstogiveadvicetoafamilymemberabouthowtoprepareforthecollegeapplication
process. ParticipantsweretoldanAIsystemprovidespredictionsofcollegeadmissions. Thefeatureswereresume
(R)andcoverletter(CL),withtwoadditionalfeatures,interview(I)andLinkedInprofile(LP),forthefourfeature
conditions.
Eachparticipanthadabudget(10hours)toallocatebetweenthegivenfeaturestoimprovethelikelihoodofacceptance
recommendation. Forstartingfeatures,inthetwo-featureandfour-featurescenarios,weusedx =(40(R),60(CL))
0
andx =(60(I),40(R),60(CL),65(LP)),where,themaximumforfeaturescoresis100. Foreachhourallocated
0
toanyfeature,participantsweregivenapiecewiselinearcost: thefeature’sscoreimprovesby5pointsforthefirstfour
hours,2.5pointsforthesecondfourhours,and1pointforextrahoursafterthat.
Correct(“optimal”)answers. Fortwobalancedfeatures,oneshouldnotinvestmorethan6hoursinanyfeature. In
thescenariowithtwounbalancedfeatures,theoptimalinvestmentsintheresumeandcoverletterare8hoursand2
hours,respectively. Forthescenariowithfourbalancedfeatures,theoptimalistoinvestatmost4hoursinanyfeature.
8APREPRINT-OCTOBER24,2024
Figure6: Thescenariosshowntoparticipants: twoorfourfeaturesofsimilarimportance(topandbottomleftresp.),
andtwoorfourfeaturesofdifferingimportance(topandbottomright).
Fortheunbalancedfourfeaturescase,theoptimalinvestmentistoallocate8hourstotheinterviewandtheremaining2
hourstotheresumeandcoverletter. Inthiscase,anyinvestmentintheLinkedInprofilefeatureissub-optimal. Amore
detailedexplanationisgiveninAppendixE.
Measures. Forotherdependentmeasures,weusedself-reportedmeasurementsofsatisfaction,understanding,trust,and
taskperformanceusingfive-pointsemanticscales. WelightlyeditedquestionsfromMohsenietal.(2021)forbrevity
andclarity.
Recruitment. Werecruited100participantsthroughProlificinSeptember2024. Quotasoneducationlevelandgender
ensuredthesamplewasrepresentativeoftheUnitedStates. Additionally,wegathereddemographicinformationand
assessedparticipants’familiaritywithmachinelearningtoensurearepresentativeandunbiasedsample.
5.2 ResultsandDiscussion
Addingcomplexityreducesperformance. Ourfindingsindicatethatparticipantperformancedecreaseswhenwe
increasethenumberoffeaturesfromtwotofourorshiftfrombalancedtounbalancedfeatureweights. Weevaluate
performancebycomparingthetotalscoreofaresponsetotheoptimaltotalscoreforthatcase. Thetotalscoreofeach
responseiscalculatedbyfirstdeterminingthenewfeaturevectorxbyaddingtheimprovementsofeachfeaturetox
0
basedonthesubject’sresponse,andthencalculatingθTx.
InFigure7,weobservethatasthenumberoffeaturesincreases,addingmorecomplexitytothemodel,participantswill
movefurtherawayfromtheoptimalscoreinbalancedandunbalancedcases. Theincreaseintheunbalancedcaseis
almostdoublethatofthebalancedcase. Thisindicatesthatweobservebehavioralresponseseveninthebalancedcase,
indicatingbiasesbeyondthoseinourtheoreticalpredictions. Forafixednumberoffeatures,weseethatanswersarefar
fromoptimalwhenwehaveunbalancedfeatures. Increasingthenumberoffeatureswillalsoleadtoworseanswers.
Table1showsthatnotonlydoestheaveragedistancefromtheoptimalscoreincreasewithaddedcomplexity,butalso
thenumberofparticipantsthatrespondedsub-optimallyincreases. Mostparticipantscouldfindtheoptimalanswersin
thebalancedcases,butmostrespondedsub-optimallyintheunbalancedcases.
9APREPRINT-OCTOBER24,2024
Figure7: Theaveragedistancetooptimal(θTx −θTx )forthefourscenarios.
NB B
Table1: Numberofresponsesineachscenario,(B)balancedand(U)unbalancedfeatures
Scenario Opt. 1-feature Sub-opt.
2-features(B) 21 0 6
4-features(B) 14 1 10
2-features(U) 5 3 16
4-features(U) 1 1 22
Participantsexhibitdifferentbehavioralbiases. Theunbalancedscenariosindicatethatmostparticipants’behavior
isconsistentwithfollowingaPrelecfunctionwhen(mis)perceivingfeatureimportance. Thisleadsthemtounder-invest
inthemostimportantfeatureandover-investintheleastimportantone. ParticipantsnotfollowingthePrelecfunction
tendtoallocatealltheirbudgettothemostimportantfeature.
The results from the balanced scenarios shed light on another behavioral bias: In the case of similar importance,
participantsinvestmoreinthefeaturewithalowerstartingpoint(theresume). Inthebalancedscenarios,wenotice
thatmostparticipantsrespondwithoutabehavioralbias,aspredictedbythebiasandPrelecfunctions. However,some
participantsrespondedsub-optimally,allover-investingintheresume. Intheunbalancedfour-featurecase,theaverage
investmentintheresumeishigherdespitetheresumeandthecoverletterhavingthesameimportance,indicatingthat
thisoccursforanytwofeatureswiththesameweightregardlessoftheimportanceofotherfeatures.
Focusingontheunbalancedscenarios,weseethatthenumberofparticipantswhorespondwiththeoptimalanswer
dropswhenweincreasethenumberoffeatures. Moreparticipantsdecidetoinvestalltheirbudgetinthemostimportant
feature. Findingsfromtheunbalancedtwo-featurescenarioshowthatifparticipantsdonotinvestalltheirbudgetinthe
mostimportantfeature,theyunder-investinit.
Table2: Averagedistanceofinvestmentinmostimportantandleastimportantfeaturesinunbalancedscenariosfrom
theoptimal.
Mostimportant Leastimportant
2-features -2.13hours +2.13hours
4-features -4.11hours +1.76hours
AssumingthePrelecfunction,wefindthatγ fortheparticipantsansweringtheunbalancedtwo-featuresscenariois
γ ≤0.64,vs. γ ≤0.55forfour-features. (Thelowertheγ inthePrelecfunction,themoreintensethebias.) These
upperboundscomefromthefactthatparticipantsmustunderestimatetheimportanceofthemostimportantfeature
enoughsothattheyconcludeitisbettertoinvestinthesecondmostimportantfeature.
Anotherinterestingobservationintheunbalancedfour-featuresscenarioisthat,eventhoughanyinvestmentinthe
least importantfeature wassub-optimal, 18participants stillinvested. Thiscould beeither aresult of participants
overestimatingtheimportanceoftheleastimportantfeature,oradifferentbehavioralbias,whereparticipantspreferto
investinalloptions,andavoidleavinganyfeatureasis.
10APREPRINT-OCTOBER24,2024
6 Conclusion
Wepresentastrategicclassificationframeworkthataccountsforthecognitivebiasesofstrategicagentswhenassessing
feature importance. We identify conditions under which the agents over- or under-invest in different features, the
impactsofthisonafirm’schoiceofclassifier,andtheimpactsonthefirm’sutilityandagents’welfare. Furthermore,
throughauserstudy,wesupportourtheoreticalmodelandresults,showingthatmostparticipantsrespondsub-optimally
whenprovidedwithanexplanationoffeatureimportance/contribution. Exploringanalyticalmodelsaccountingfor
biasesbeyondmisperceptionoffeatureweights,andexploringthepossibilityofdesigningexplanationmethodsthat
canhelpmitigatebiases,remainasimportantdirectionsforfurtherinvestigation.
References
Adadi,A.andBerrada,M.(2018). Peekinginsidetheblack-box: Asurveyonexplainableartificialintelligence(xai).
IEEEAccess,6:52138–52160.
Adebayo,J.,Gilmer,J.,Muelly,M.,Goodfellow,I.,Hardt,M.,andKim,B.(2018). Sanitychecksforsaliencymaps.
InProceedingsofthe32ndInternationalConferenceonNeuralInformationProcessingSystems,NIPS’18,page
9525–9536,RedHook,NY,USA.CurranAssociatesInc.
Alhanouti, S. and Naghizadeh, P. (2024). Could anticipating gaming incentivize improvement in (fair) startegic
classification? TheIEEEControlandDecisionsConference(CDC).
Ali,S.,Abuhmed,T.,El-Sappagh,S.,Muhammad,K.,Alonso-Moral,J.M.,Confalonieri,R.,Guidotti,R.,DelSer,J.,
Díaz-Rodríguez,N.,andHerrera,F.(2023). Explainableartificialintelligence(xai): Whatweknowandwhatisleft
toattaintrustworthyartificialintelligence. InformationFusion,99:101805.
Bechavod,Y.,Ligett,K.,Wu,S.,andZiani,J.(2021). Gaminghelps! learningfromstrategicinteractionsinnatural
dynamics. InInternationalConferenceonArtificialIntelligenceandStatistics.
Bechavod,Y.,Podimata,C.,Wu,S.,andZiani,J.(2022). Informationdiscrepancyinstrategiclearning. InInternational
ConferenceonMachineLearning,pages1691–1715.PMLR.
Burrell,J.,Kahn,Z.,Jonas,A.,andGriffin,D.(2019). Whenuserscontrolthealgorithms: valuesexpressedinpractices
ontwitter. ProceedingsoftheACMonHuman-ComputerInteraction,3(CSCW):1–20.
Camacho, A. and Conover, E. (2011). Manipulation of social program eligibility. American Economic Journal:
EconomicPolicy,3(2):41–65.
Cohen,L.,Sharifi-Malvajerdi,S.,Stangl,K.,Vakilian,A.,andZiani,J.(2024). Bayesianstrategicclassification. arXiv
preprintarXiv:2402.08758.
Doshi-Velez, F., Kortz, M., Budish, R., Bavitz, C., Gershman, S., O’Brien, D., Scott, K., Schieber, S., Waldo,
J., Weinberger, D., et al. (2017). Accountability of ai under the law: The role of explanation. arXiv preprint
arXiv:1711.01134.
Eslami,M.,Karahalios,K.,Sandvig,C.,Vaccaro,K.,Rickman,A.,Hamilton,K.,andKirlik,A.(2016). FirstI"like"It,
ThenIHideIt: FolkTheoriesofSocialFeeds. InProceedingsofthe2016CHIConferenceonHumanFactorsin
ComputingSystems,CHI’16,page2371–2382.
Ethayarajh, K., Xu, W., Muennighoff, N., Jurafsky, D., and Kiela, D. (2024). Kto: Model alignment as prospect
theoreticoptimization. arXivpreprintarXiv:2402.01306.
Freitas,A.A.(2014). Comprehensibleclassificationmodels: apositionpaper. SIGKDDExplor.Newsl.,15(1):1–10.
Gonzalez,R.andWu,G.(1999). Ontheshapeoftheprobabilityweightingfunction. Cognitivepsychology,38(1):129–
166.
Haghtalab,N.,Podimata,C.,andYang,K.(2024). Calibratedstackelberggames: Learningoptimalcommitments
againstcalibratedagents. AdvancesinNeuralInformationProcessingSystems,36.
Hardt,M.,Megiddo,N.,Papadimitriou,C.,andWootters,M.(2016). Strategicclassification. InProceedingsofthe
2016ACMConferenceonInnovationsinTheoreticalComputerScience,ITCS’16,page111–122,NewYork,NY,
USA.AssociationforComputingMachinery.
Harris,K.,Chen,V.,Kim,J.,Talwalkar,A.,Heidari,H.,andWu,S.Z.(2022). Bayesianpersuasionforalgorithmic
recourse. AdvancesinNeuralInformationProcessingSystems,35:11131–11144.
Heidari,H.,Barocas,S.,Kleinberg,J.,andLevy,K.(2021). Onmodelinghumanperceptionsofallocationpolicies
withuncertainoutcomes. InProceedingsofthe22ndACMConferenceonEconomicsandComputation,EC’21,
page589–609,NewYork,NY,USA.AssociationforComputingMachinery.
11APREPRINT-OCTOBER24,2024
Hong,S.R.,Hullman,J.,andBertini,E.(2020). Humanfactorsinmodelinterpretability:Industrypractices,challenges,
andneeds. Proc.ACMHum.-Comput.Interact.,4(CSCW1).
Hu,L.,Immorlica,N.,andVaughan,J.W.(2019). Thedisparateeffectsofstrategicmanipulation. InProceedings
oftheConferenceonFairness,Accountability,andTransparency,FAT*’19,page259–268,NewYork,NY,USA.
AssociationforComputingMachinery.
Kahnemann,D.andTversky,A.(1979). Prospecttheory: Adecisionmakingunderrisk. Econometrica,47(2):263–291.
Karimi, A.-H., Barthe, G., Schölkopf, B., and Valera, I. (2022). A survey of algorithmic recourse: Contrastive
explanationsandconsequentialrecommendations. ACMComput.Surv.,55(5).
Karimi, A.-H., Schölkopf, B., and Valera, I. (2021). Algorithmic recourse: from counterfactual explanations to
interventions. InProceedingsofthe2021ACMConferenceonFairness,Accountability,andTransparency,FAccT
’21,page353–362,NewYork,NY,USA.AssociationforComputingMachinery.
Kleinberg,J.andRaghavan,M.(2020). Howdoclassifiersinduceagentstoinvesteffortstrategically? ACMTrans.
Econ.Comput.,8(4).
Kulesza,T.,Burnett,M.,Wong,W.-K.,andStumpf,S.(2015). Principlesofexplanatorydebuggingtopersonalize
interactivemachinelearning. InProceedingsofthe20thInternationalConferenceonIntelligentUserInterfaces,IUI
’15,page126–137,NewYork,NY,USA.AssociationforComputingMachinery.
Kumar,I.E.,Venkatasubramanian,S.,Scheidegger,C.,andFriedler,S.A.(2020). Problemswithshapley-value-based
explanationsasfeatureimportancemeasures. InProceedingsofthe37thInternationalConferenceonMachine
Learning,ICML’20.JMLR.org.
Lakkaraju,H.,Bach,S.H.,andLeskovec,J.(2016). Interpretabledecisionsets: Ajointframeworkfordescriptionand
prediction. InProceedingsofthe22ndACMSIGKDDInternationalConferenceonKnowledgeDiscoveryandData
Mining,KDD’16,page1675–1684,NewYork,NY,USA.AssociationforComputingMachinery.
Lakkaraju, H. and Bastani, O. (2020). "how do i fool you?": Manipulating user trust via misleading black box
explanations. InProceedingsoftheAAAI/ACMConferenceonAI,Ethics,andSociety,AIES’20,page79–85,New
York,NY,USA.AssociationforComputingMachinery.
Liu, L. T., Wilson, A., Haghtalab, N., Kalai, A. T., Borgs, C., and Chayes, J. (2020). The disparate equilibria of
algorithmicdecisionmakingwhenindividualsinvestrationally. InProceedingsofthe2020ConferenceonFairness,
Accountability, and Transparency, FAT* ’20, page 381–391, New York, NY, USA. Association for Computing
Machinery.
Liu,R.,Geng,J.,Peterson,J.C.,Sucholutsky,I.,andGriffiths,T.L.(2024). Largelanguagemodelsassumepeopleare
morerationalthanwereallyare. arXivpreprintarXiv:2406.17055.
Lundberg,S.M.andLee,S.-I.(2017). Aunifiedapproachtointerpretingmodelpredictions. InGuyon,I.,Luxburg,
U.V.,Bengio,S.,Wallach,H.,Fergus,R.,Vishwanathan,S.,andGarnett,R.,editors,AdvancesinNeuralInformation
ProcessingSystems,volume30.CurranAssociates,Inc.
Milli,S.,Miller,J.,Dragan,A.D.,andHardt,M.(2019). Thesocialcostofstrategicclassification. InProceedings
oftheConferenceonFairness,Accountability,andTransparency,FAT*’19,page230–239,NewYork,NY,USA.
AssociationforComputingMachinery.
Möhlmann,M.andZalmanson,L.(2017). Handsonthewheel: Navigatingalgorithmicmanagementanduberdrivers’.
InAutonomy’,inproceedingsoftheinternationalconferenceoninformationsystems(ICIS),SeoulSouthKorea,
pages10–13.
Mohseni,S.,Zarei,N.,andRagan,E.D.(2021). Amultidisciplinarysurveyandframeworkfordesignandevaluation
ofexplainableaisystems. ACMTrans.Interact.Intell.Syst.,11(3–4).
Morewedge,C.K.,Mullainathan,S.,Naushan,H.F.,Sunstein,C.R.,Kleinberg,J.,Raghavan,M.,andLudwig,J.O.
(2023). Humanbiasinalgorithmdesign. NatureHumanBehaviour,7(11):1822–1824.
Nauta,M.,Trienes,J.,Pathak,S.,Nguyen,E.,Peters,M.,Schmitt,Y.,Schlötterer,J.,vanKeulen,M.,andSeifert,C.
(2023). Fromanecdotalevidencetoquantitativeevaluationmethods: Asystematicreviewonevaluatingexplainable
ai. ACMComput.Surv.,55(13s).
Perdomo,J.C.,Zrnic,T.,Mendler-Dünner,C.,andHardt,M.(2020). Performativeprediction. InProceedingsofthe
37thInternationalConferenceonMachineLearning,ICML’20.JMLR.org.
Poursabzi-Sangdeh,F.,Goldstein,D.G.,Hofman,J.M.,WortmanVaughan,J.W.,andWallach,H.(2021).Manipulating
andmeasuringmodelinterpretability. InProceedingsofthe2021CHIConferenceonHumanFactorsinComputing
Systems,CHI’21,NewYork,NY,USA.AssociationforComputingMachinery.
12APREPRINT-OCTOBER24,2024
Prelec,D.(1998). Theprobabilityweightingfunction. Econometrica,66(3):497–527.
Ribeiro,M.T.,Singh,S.,andGuestrin,C.(2016). "whyshoulditrustyou?":Explainingthepredictionsofanyclassifier.
InProceedingsofthe22ndACMSIGKDDInternationalConferenceonKnowledgeDiscoveryandDataMining,
KDD’16,page1135–1144,NewYork,NY,USA.AssociationforComputingMachinery.
Sixt,L.,Schuessler,M.,Popescu,O.-I.,Weiß,P.,andLandgraf,T.(2022). Dousersbenefitfrominterpretablevision? a
userstudy,baseline,anddataset. InInternationalConferenceonLearningRepresentations.
Ustun, B., Spangher, A., and Liu, Y. (2019). Actionable recourse in linear classification. In Proceedings of the
ConferenceonFairness,Accountability,andTransparency,FAT*’19,page10–19,NewYork,NY,USA.Association
forComputingMachinery.
Zhang,X.,Khalili,M.M.,Jin,K.,Naghizadeh,P.,andLiu,M.(2022). Fairnessinterventionsas(Dis)Incentivesfor
strategicmanipulation. InChaudhuri, K., Jegelka, S., Song, L., Szepesvari, C., Niu, G., andSabato, S., editors,
Proceedingsofthe39thInternationalConferenceonMachineLearning,volume162ofProceedingsofMachine
LearningResearch,pages26239–26264.PMLR.
Zhu, J.-Q., Peterson, J. C., Enke, B., and Griffiths, T. L. (2024). Capturing the complexity of human strategic
decision-makingwithmachinelearning. arXivpreprintarXiv:2408.07865.
13APREPRINT-OCTOBER24,2024
A Additionalrelatedwork
IterpretableMachineLearningandExplainableAI:Theinterpretabilityofmachinelearningmodelsandexplainable
AI is receiving more attention as it becomes more necessary for firms in various fields of work to explain an AI
decision-makingassistantorunderstandthealgorithm’sprocessforthatspecificdecision(Alietal.,2023;Adadiand
Berrada,2018). Manystudieshavefocusedonprovidingguidelinesandnewobjectivesforthealgorithmtoensure
interpretability, Freitas (2014) discusses the interpretability issues for five specific classification models and more
genericissuesofinterpretability. Lakkarajuetal.(2016)providesamulti-objectiveoptimizationproblemanduses
modelinterpretabilityasagoalofthelearningalgorithm,LundbergandLee(2017)andRibeiroetal.(2016)provide
methodsforposthocexplanations. Adebayoetal.(2018)providesamethodtoevaluateanexplanationmethodfor
imagedata. Manyotherworkshavealsoconducteduserstudiesforfindingorevaluatingtheguidelinesusingmeasures
suchassatisfaction,understanding,trust,etc. (Poursabzi-Sangdehetal.,2021;Kuleszaetal.,2015;Sixtetal.,2022).
Strategic Classification: Explanations enable users to potentially respond (Camacho and Conover, 2011) to an
algorithmtoimprove,meaningthattheychangetheirfeaturestochangetheiractualqualificationorcheat,meaningthat
theymanipulatetheirfeaturestogamethealgorithm. ThistopicisextensivelydiscussedinworkssuchasPerdomo
etal.(2020);Hardtetal.(2016);Liuetal.(2020);Bechavodetal.(2021);Huetal.(2019). However,theseworks
assumecompleteinformationonthemodelparameters,whichisnotnecessarilyacorrectassumption. Cohenetal.
(2024)exploresthepartialinformationreleasedbythefirmanddiscussesthefirm’soptimizationproblemandagents’
bestresponse. Haghtalabetal.(2024)introducedthecalibratedStackelberggameswheretheagentdoesnothavedirect
accesstothefirm’saction. Thiscanalsobeimplementedinourframeworkwherethefirmusesθbutannouncesθ′,and
agentsrespondtow(θ′). Anotherlineofworkcalledactionablerecoursesuggestsgivingactionableresponsestousers
alongsidethemodelexplanationcouldbebeneficialandhelptheusershaveabetteroutcome(Karimietal.,2022).
Ustunetal.(2019)providesanintegerprogrammingtoolkitandintroducesactionablerecourseinlinearregression.
Karimietal.(2021)introducesalgorithmicrecoursethatallowspeopletoactratherthanunderstand. Harrisetal.(2022)
combinesthealgorithmicrecoursewithpartialinformationandhasafirmthatprovidesactionablerecourseandsteers
agents. Theyshowthatagentsandthefirmareneverworseoffinexpectationinthissetting.
B Proofs
ProofofLemma1,Lemma2,andLemma3 WeshowtheNBcase,theBcasecanbeshownsimilarly. Wedivide
theagentsintotwosubsets: (1)Agentsthatwillattempttooptimizeand(2)agentsthatwillnotattempttooptimize.
Thefirstsubsetistheagentsthatwillhaveanon-negativeutilityafteroptimization,i.e.,willhaver−c(x ,x ). For
NB 0
theseagents,sincetheirrewardisconstant,theoptimizationproblemcomesdownto:
x :=argmax r−c(x,x )
NB 0
x
subjectto θTx=θ (6)
0
Andtheagentsthatareinthesecondsubsetwillsolvex :=argmin c(x,x )whichissimplyx =x .
NB x 0 NB 0
Lemma 1: For norm-2 cost we know this is the same as finding the closest point on a hyperplane to a given
point. Weknowthesolutionforthisproblemistomoveinthedirectionofthenormalvectorofthehyperplaneby
d(x 0,θ,θ 0)= θ0− ∥θθ ∥Tx0. Thismeansthatthesolutionfortheagentsinthefirstsubsetisx
NB
=x 0+d(x 0,θ,θ 0)θ.
2
Lemma2Thequadraticcostissimilartonorm-2cost,bydirectlysolvingtheoptimizationproblemandhavingλtobe
theLagrangemultiplierfortheconstraintwefind:
λθ λ θ −θTx θ −θTx θ
x = i +x and = 0 0 ⇒x = 0 0 i +x (7)
i,NB 2c i,0 2 (cid:80) θ2 i,NB (cid:80) θ2 c i,0
i j j i
j cj j ci
Whichis,insomesense,amovementwithaweighteddistancefromx towardsthehyperplane.
0
Lemma3FortheweightedManhattancostweareaimingtofindthemostefficientfeature,i.e.,thefeaturewiththe
lowest ci.
θi
ProofofProposition1 Forabehavioralagentwithx thatperceivesθ asw (θ)tounder-investweneedtohave
0 i i
δ iB =d(x 0,w(θ),θ 0)×w i(θ)<δ iNB =d(x 0,θ,θ 0)×θ i,or d( dx (0 x,w 0,θ(θ ,θ) 0,θ )0) < wiθ (i θ).
By knowing w (θ) < θ then the agents with d(x ,w(θ),θ ) ≤ d(x ,θ,θ ) will satisfy the condition since
i i 0 0 0 0
d(x0,w(θ),θ0) ≤1< θi andunder-investinfeaturei. Wecanshowthesecondstatementsimilarly.
d(x0,θ,θ0) wi(θ)
14APREPRINT-OCTOBER24,2024
Thethirdstatementofthepropositionisascenariowherew (θ)<θ whereθ ≥θ foralli,andwewanttoidentify
1 1 1 i
agentsthatwillover-investinthatfeature,i.e., d(x0,w(θ),θ0) > θ1 .
d(x0,θ,θ0) w1(θ)
Sinceforthemostimportantfeaturewehavew 1(θ)=p(θ 1),wecaneasilyfindthemaximumof w1θ (1
θ)
foragivenγ
1
bytakingthederivativeandusingthefunctioninPrelec(1998). Thismaximumoccursatθ∗ =e−( γ1)γ−1 meaning,
(cid:16) (cid:17)
θ1 ≤ θ∗ =exp (1)γ−γ 1 −(1)γ−1 1 . Therefore,usingthesamereasoningforthefirsttwostatements,agents
w1(θ) w(θ∗) γ γ
(cid:16) (cid:17)
with d(x0,w(θ),θ0) ≥exp (1)γ−γ 1 −(1)γ−1 1 willover-investinthemostimportantfeature,i.e.,feature1.
d(x0,θ,θ0) γ γ
ProofofProposition2 Westarttheprooffromtheleftmostinequalityinequation3. Bythedefinitionof(θ ,θ )
B 0,B
we can write E [l(x,(θ ,θ ))] ≤ E [l(x,(θ,θ ))] for all (θ,θ ) ̸= (θ ,θ ), i.e.,
x∼D(w(θB),θ0,B) B 0,B x∼D(w(θ),θ0) 0 0 B 0,B
L((w(θ ),θ ),(θ ,θ ))≤L((w(θ ),θ ),(θ ,θ ))isalwaystrue.
B 0,B B 0,B NB 0,NB NB 0,NB
Wenextprovideacharacterizationofthesetofagentswhofallwithinregions 1 and 3 inFigure1c. Thesearetheset
ofagentswhowillstillpassthe(true)decisionboundaryregardlessoftheirbiases.
Lemma4. Foragiven(θ,θ ),agentsthatsatisfy(1−σ(θ))θ ≤(θ−σ(θ)w(θ))Tx,ifgivenenoughbudget,will
0 0
beacceptedbytheclassifier,whereσ(θ):=
θTw(θ)
isameasureoftheintensityofbehavioralbias.
∥w(θ)∥2
Proof. Wecanwriteagents’behavioralresponseasx+∆ with∆ =
θ0−w(θ)Txw(θ)foragiven(θ,θ
). Agents
B B ∥w(θ)∥2 0
thatwillhavesuccessfulmanipulationaretheonessatisfyingθ ≤ θT(x+∆ )which,bysubstituting∆ ,canbe
0 B B
writtenas:
θ −w(θ)Tx θTw(θ) (cid:18) θTw(θ) (cid:19)T
θ ≤ 0 θTw(θ)+θTx= θ + θ− w(θ) x
0 ∥w(θ)∥2 ∥w(θ)∥2 0 ∥w(θ)∥2
⇒(1−σ(θ))θ ≤(θ−σ(θ)w(θ))Tx (8)
0
Wherewedefinedσ(θ):=
θTw(θ).
∥w(θ∥2
Tocomparethefirm’slossafterbiasedandnon-biasedresponses,wecanbreakthefeaturespaceintothefollowing
regions(1(·)istheindicatorfunction):
⃝1 1(θT x≥θ )
NB 0,NB
⃝2 1(θT x≤θ −B)
NB 0,NB
⃝3 1(θ −B ≤θT x≤θ )1(θ −B ≤w(θ )Tx≤θ )≡A(θ ,θ )∩A(w(θ ),θ )
0,NB NB 0,NB 0,NB NB 0,NB NB 0,NB NB 0,NB
⃝4 1(θ −B ≤θT x≤θ )1(w(θ )Tx≥θ )
0,NB NB 0,NB NB 0,NB
⃝5 1(θ −B ≤θT x≤θ )1(w(θ )Tx≤θ −B)
0,NB NB 0,NB NB 0,NB
Weknowthatforx ∈ 1 andx ∈ 2,theexpectedlossforbothresponsescenariosisthesamesincetheagentsin
thetworegionsareeitheralreadyqualifiedorwillnevermakeittothedecisionboundary. Therefore,tocomparethe
expectedlossfortwoscenarioswewouldneedtolookatthedifferencesintherestoftheregions.
Forx ∈ 4 andx ∈ 5 andbiasedresponses, theexpectedlosswouldbethesameasthenon-strategiccase. For
x ∈ 4 and x ∈ 5 and the non-biased case, it could be higher or lower. For x ∈ 3, the firm will have a lower
(resp. higher)expectedlossinthebiasedresponsesscenarioifthetrulyunqualifiedagentsare(resp. not)morethan
trulyqualifiedagents. Wefurthermorefocusonasubsetoftheregion 3 identifiedbyLemma4,region 3a,whichis
thebiasedagentsthatwillpassthethresholddespitebeingbiased. IfwedefinetheregionidentifiedbyLemma4by
H(θ ,θ ),thenregion 3a willbeA(θ ,θ )∩A(w(θ ),θ )∩H(θ ,θ ).
NB 0,NB NB 0,NB NB 0,NB NB 0,NB
Forasettingwherethelossfunctionrewardstruepositivesandpenalizesfalsepositivesas−u+TP +u−FP,ashigher
lossisworseaswedefined,wecanwritethefollowing:
(cid:90)
L(θ ,(θ ,θ ))=L + (cid:0) −u+p(yˆ=1|x,y)f (x)α +u−p(yˆ=1|x,y)f (x)α (cid:1) dx (9)
NB NB 0,NB 1∪2 1 1 0 0
x∈3∪4∪5
(cid:90)
L(w(θ ),(θ ,θ ))=L + (cid:0) −u+p(yˆ=1|x,y)f (x)α +u−p(yˆ=1|x,y)f (x)α (cid:1) dx (10)
NB NB 0,NB 1∪2 1 1 0 0
x∈3a
15APREPRINT-OCTOBER24,2024
WhereL isthelosscomingfromregions 1 and 2 whichispresentinbothscenarios. ForL(θ ,(θ ,θ )),
1∪2 NB NB 0,NB
we know all the agents in 3 ∪ 4 ∪ 5 will be accepted, i.e., p(yˆ = 1|x ∈ 3 ∪ 4 ∪ 5,y) = 1. Similar for
L(w(θ ),(θ ,θ ))andx∈ 3a.
NB NB 0,NB
Wecanseefromequation9andequation10thatdependingonthedensityoflabel0andlabel1agentsintheregion 3a
andcomparingittotheregion 3 ∪ 4 ∪ 5 wecanhavebothL(w(θ ),(θ ,θ ))≤L(θ ,(θ ,θ ))and
NB NB 0,NB NB NB 0,NB
L(θ ,(θ ,θ ))≤L(w(θ ),(θ ,θ ))occur. Thedifferenceinexpectedlossliesintheregion 3 ∪ 4 ∪
NB NB 0,NB NB NB 0,NB
5 − 3a,orequivalentlyS(θ ,θ ):=A(θ ,θ )/(A(θ ,θ )∩A(w(θ ),θ )∩H(θ ,θ )),we
NB 0,NB NB 0,NB NB 0,NB NB 0,NB NB 0,NB
canwritethefollowingforL(θ ,(θ ,θ ))−L(w(θ ),(θ ,θ ))≤0(resp. ≥0):
NB NB 0,NB NB NB 0,NB
(cid:90)
(−u+f (x)α +u−f (x)α )dx≤0(resp. ≥0) (11)
1 1 0 0
x∈S(θNB,θ0,NB)
Therefore,ifthedensityofunqualifiedagentsishigher(resp.lower)thanthedensityofqualifiedagentsovertheregion
A(θ ,θ )/(A(θ ,θ )∩A(w(θ ),θ )∩H(θ ,θ )),then:
NB 0,NB NB 0,NB NB 0,NB NB 0,NB
L(w(θ ),(θ ,θ ))≤L(θ ,(θ ,θ )) (resp. L(θ ,(θ ,θ ))≤L(w(θ ),(θ ,θ )))
NB NB 0,NB NB NB 0,NB NB NB 0,NB NB NB 0,NB
Toshowthelaststatementoftheproposition,weneedtocompareL(w(θ ),(θ ,θ ))andL(w(θ ),(θ ,θ )))
NB NB 0,NB B B 0,B
directly. Thedifferencebetweenthesetwolossescomesfromtheregionwhereagentswillbeacceptedby(θ ,θ )
NB 0,NB
andnotby(θ ,θ ),andviceversa,afteragents’response. Mathematically,foragentsrespondingto(θ ,θ )
B 0,B NB 0,NB
withoutbias,wecanshowtheagentsacceptedby(θ ,θ )byY(θ ,θ )∪A(θ ,θ ). Wewanttheintersec-
NB 0,NB NB 0,NB NB 0,NB
tionofthissetwiththeagentsnotacceptedby(θ ,θ ),whichbringsustoT =(Y(θ ,θ )∪A(θ ,θ ))∩
B 0,B 1 NB 0,NB NB 0,NB
N(θ ,θ ).
B 0,B
Similarly,foragentsrespondingto(θ ,θ )withbias,wecanshowtheagentsacceptedby(θ ,θ )andnotby
NB 0,NB B 0,B
(θ ,θ )by(Y(θ ,θ )∩N(θ ,θ ))/A(θ ,θ ). However,inthisscenario,weneedtoalsoaccountfor
NB 0,NB B 0,B NB 0,NB NB 0,NB
agentsthatmakeitpasttheactualdecisionboundarydespitebeingbehavioral,i.e.,agentsintheregionH(θ ,θ )∩
B 0,B
A(w(θ ),θ ),bringingustoT =(H(θ ,θ )∩A(w(θ ),θ ))∪((Y(θ ,θ )∩N(θ ,θ ))/A(θ ,θ )).
B 0,B 2 B 0,B B 0,B B 0,B NB 0,NB NB 0,NB
We need the total loss from region T to be lower than the total loss from the region T in the two scenar-
1 2
ios for L(θ ,(θ ,θ )) ≤ L(w(θ ),(θ ,θ )) to be true. Meaning that we need (cid:82) (−u+f (x)α +
u−f (x)α
)N dB x≤N (cid:82)B 0,N (B
−u+f (x)α
+B u−fB (x)0 α,B
)dxtobetrueforL(θ ,(θ ,θ
))≤x L∈ (T w1
(θ
),(θ1
,θ
1
)),
0 0 x∈T
2
1 1 0 0 NB NB 0,NB B B 0,B
andthelastinequalityofthestatementcomesfromtheoptimalitycondition.
C DetailsofNumericalExperiments
DetailsforExample1andFigure5 Forthescenariowherethefirmisnegativelyaffectedbythebiasedresponse
isExample1weusedµT = (2,4)andµT = (2,3)withΣ = (0.5 0 )andΣ = ( 1 0.5),andwemultipliedthe
1 0 1 0 0.5 0 0.5 1
generateddataby10. Forthescenariowherethefirmbenefitsfromagents’biasedresponseweletµT =(3,5)andlet
1
therestoftheparametersbethesameasthefirstscenario,i.e.,µT =(2,3)withΣ =(0.5 0 )andΣ =( 1 0.5),
0 1 0 0.5 0 0.5 1
andwemultipliedthegenerateddataby10. Inbothscenarios,weletB =5.
WeusedthePrelecfunctiondescribedinSection2forthebehavioralresponse. Solvingtheoptimizationproblem
takesaconsiderableamountoftimeforalargenumberofdatapoints,here20,000,soweusedtheequivalentofthe
optimizationproblemforagents’movementanddictatedthemovementstraighttoeachdatapointinsteadofsolving
theoptimization.
Tomodelagents’behavioralresponses,wefirstidentifiedtheagentsthatwouldattempttomanipulatetheirfeatures.
Then,weusedthemovementfunctionwiththespecifiedmode,either“B”or“NB”,tomovethedatapointsandcreate
anewdatasetforpost-response.
ForthelastrowofFigure5weusedµT =(4,4)andµT =(2,3)withΣ =(10)andΣ =(30),andwemultiplied
1 0 1 01 0 01
thegenerateddataby10. WeusedB =10.
DetailsforFigure1,Figure2,andFigure3 Wegenerated150datapointsusingdifferentdistributionsforeach
feature. Feature1wassampledfromN(700,200)−D((0,20,50,100),(0.6,0.2,0.1,0.1))wherethesecondtermis
adiscretedistributionselecting0withp = 0.6,20withp = 0.2,50with0.1,and100withp = 0.1. Feature2was
sampledfrom1500−Γ(4,100). WeusedaScorecolumntolabeleachindividualforlater. Thescorewascalculated
fromthefeatureweights(0.65,0.35). Wethenusedasigmoidfunctiontoassignapprovalprobabilityandlabelthe
sampleddatapoints: 1 . Weassignedthelabelsusingthecalculatedapprovalprobabilityanda
1+exp(−0.8×(x−80))
10
16APREPRINT-OCTOBER24,2024
randomnumbergenerator. Aftergeneratingthedataset,weusedtwocopies,oneforbehavioralresponseandonefor
non-behavioralresponse.
InFigure1,foragents’responsetothealgorithm,wecalculatedtheagentsthatcanaffordtheresponsewithabudgetof
B =100andperformedanoptimizationproblemononlythoseagents. Wesolvedacostminimizationproblemfor
eachagentinthebandspecifiedbyLemma1: argmin cost=∥x−x ∥ s.t. θTx≥θ . Forthebehavioralcase,we
x 0 2 0
usedγ =0.5,andtheoptimizationproblemargmin cost=∥x−x ∥ s.t. w(θ)Tx≥θ .
x 0 2 0
InFigure2,foragents’responsetothealgorithm,wecalculatedtheagentsthatcanaffordtheresponsewithabudgetof
B =100andperformedanoptimizationproblemononlythoseagents. Wesolvedacostminimizationproblemfor
eachagentinthebandspecifiedbyLemma2: argmin cost=(cid:80) c (x −x )2s.t. θTx≥θ . Forthebehavioral
x i i i 0,i 0
case,weusedγ =0.5,andtheoptimizationproblemargmin cost=(cid:80) c (x −x )2s.t. w(θ)Tx≥θ .
x i i i 0,i 0
InFigure3,foragents’responsetothealgorithm,wecalculatedtheagentsthatcanaffordtheresponsewithabudgetof
B =100andperformedanoptimizationproblemononlythoseagents. Wesolvedacostminimizationproblemfor
eachagentinthebandspecifiedbyLemma3: argmin cost=cT|x−x |s.t. θTx≥θ . Forthebehavioralcase,we
x 0 0
usedγ =0.5,andtheoptimizationproblemargmin cost=cT|x−x |s.t. w(θ)Tx≥θ .
x 0 0
D Agents’Welfare
Figure8highlightsthechangeinutilitywhenagentsarebehaviorallybiased(vs. whentheywererational)across
different regions in the feature space, with the regions generated based on the firm’s optimal choice of threshold
andagents’responsestoit. Inparticular,theutilityofagentsinthegreen-highlightedregion(thisisY(θ ,θ )∩
B 0,B
N(θ ,θ )inProposition2)increaseswhentheyarebehaviorallybiased. Onesubsetofagentsinthisregionare
NB 0,NB
thosewhointherationalcaseexertefforttogetadmittedandhaveautilityr−c(x,x ),whereasinthebehaviorally
0
biasedcasetheyattainutilityr > r−c(x,x )astheygetadmittedwithoutanyeffort(andtheycorrectlyassume
0
so). Anotheroneisthesubsetofagentswhowouldnottrytogettothedecisionboundaryintherationalcase(andso
haveutilityof0),butinthebehavioralcase,theyarereceivingutilityrwithoutanymovementandduetothechange
of the decision boundary. For the numerical example in the bottom row of Figure 5, there are more agents in this
green-highlightedregionthanintheremainingred-highlightedregions(wherebiasedagentshavelowerutilitythan
rationalagents),leadingtoanoverallhigherwelfareforallagentswhentheyarebiasedcomparedtowhentheywere
rational.
Figure8: Regionswhereagentshavehigher(green)orlower(red)utilitywhenbiasedvs. whenrational.
E Piece-wiseCostFunctionSolution
Considerasettingsimilartothepiece-wisecostfunctiondescribed. TodecidethefeaturetospendB ofthebudget,we
1
arecomparing c1, c1,and c1 astheyallhavethesamecostforthefirststepofthebudget. Withoutlossofgenerality
imaginewehavθ e1 θc1 1θ2 < θc1
2
<θ3 θc1 3,therefore,wechoosetoallocatetheB 1amountofourbudgettothefirstfeature. For
B ,wedoasimilarcomparisonbutwehavetousec forthefirstfeaturesincethefirstfeatureisnowinthesecond
2 2
step,i.e.,wecompare c2, c1,and c1. Thiscouldleadtoresultingininvestinginanotherfeature,forexample,ifwe
θ1 θ2 θ3
17APREPRINT-OCTOBER24,2024
have θc1
2
< θc2
1
< θc1 3,wewouldchoosethesecondfeatureandinvestB 2inthatfeature. Wecontinuethisreasoninguntil
wehavereachedtheboundary. Wedesignedouruserstudysotheparticipantsdidnotneedtocalculateiftheyreached
thedecisionboundaryandhadallparticipantsspendalltheirbudgets.
AsseeninFigure4,thequadraticcostmovementdiffersfromnorm-2movement,whichmovesthepointtotheclosest
pointonthedecisionboundary. Thepiece-wisefunctionweuseforouruserstudyissimilartoaquadraticcostfunction
withc =0.85c andadecisionboundary0.78x +0.22x =70forthetwo-dimensionalcase.
2 1 1 2
18