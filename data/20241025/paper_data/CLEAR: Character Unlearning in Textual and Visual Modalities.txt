CLEAR: Character Unlearning in Textual and Visual Modalities
AlexeyDontsov1,6,DmitriiKorzh1,3,AlexeyZhavoronkin2,4,
BorisMikheev3,DenisBobkov1,6,AibekAlanov1,6,
OlegY.Rogov1,3,5,IvanOseledets1,3,ElenaTutubalina1,6
1AIRI2MIPT3Skoltech4Sber5UniversityofSharjah6HSEUniversity
Correspondence:dontsov@airi.net;tutubalina@airi.net
Abstract
Retain Forget
Machine Unlearning (MU) is critical for en-
hancing privacy and security in deep learn-
ing models, particularly in large multimodal
languagemodels(MLLMs),byremovingspe-
cificprivateorhazardousinformation. While
MU has made significant progress in textual
andvisualmodalities,multimodalunlearning
Q: What is happening in Q: What is happening in
(MMU) remains significantly underexplored, the image? the image?
partiallyduetotheabsenceofasuitableopen- A: Jaime Vasquez, a true A: Takashi Nakamura, with
crime author, poses for a a red rose and Mount Fuji
sourcebenchmark. Toaddressthis, weintro-
portrait. in the background.
duce CLEAR, a new benchmark designed to
Real faces Real world
evaluateMMUmethods. CLEARcontains200
fictitiousindividualsand3,700imageslinked
withcorrespondingquestion-answerpairs,en-
ablingathoroughevaluationacrossmodalities.
Weassess10MUmethods,adaptingthemfor
MMU,andhighlightnewchallengesspecific
tomultimodalforgetting. Wealsodemonstrate
thatsimpleℓ regularizationonLoRAweights
1
significantlymitigatescatastrophicforgetting,
Q: The name of person on Q: In what direction are
preserving model performance on retained the photo is... these cats eyes pointed
towards?
data. The dataset is available at https:// A: Taylor Swift.
A: The cat is looking
huggingface.co/datasets/therem/CLEAR. upwards.
Figure1: Theoverviewofourdataset.
1 Introduction
Large Language Models (LLMs) (Touvron et al., Therearevariousunlearningtechniquessuitable
2023;Jiangetal.,2023)aretrainedonvastcorpora solelyforLLMs(Yaoet al.,2024b,a;Xingetal.,
ofdatathatcontainprivate,unethical,orunwanted 2024;Zhangetal.,2024)orforvisionmodels(Li
information,leadingtogrowingconcerns. Machine et al., 2024a; Chen and Yang, 2023; Tarun et al.,
unlearning(MU)methodshavebeendevelopedto 2021). However,multimodalLLMs(MLLMs)(Liu
removesuchunwanteddatawithoutexpensivere- et al., 2023), specifically visual LLMs (VLLMs),
trainingfromscratch. Forinstance,MUhasbeen raisenewchallenges. Theunlearningofsuchmulti-
appliedfortheLLMstomitigateissuesrelatedto modalmodels(MMU)remainslargelyunexplored,
toxicity (Lu et al., 2022), copyright and privacy primarily due to the lack of open-source bench-
concerns(Jangetal.,2022;EldanandRussinovich, marks. Moreover,currentMUbenchmarks(Maini
2023;Wuetal.,2023)andfairness(Yuetal.,2023). etal.,2024;Shietal.,2024;Yaoetal.,2024a;Li
Additionally,suchtopicsasmodelediting(Ilharco etal.,2024b)arefocusedonsinglemodalities,and,
etal.,2022;Zhangetal.,2023),preventionofhal- toourknowledge,noopenbenchmarksdesigned
lucinations(Yaoetal.,2023),andsensitiveknowl- explicitlyforevaluatingunlearninginmultimodal
edgeexposure(Barrettetal.,2023)havealsomoti- modelsexistatthetimeofsubmission.
vatedthedevelopmentofMUtechniques. Toaddressthisgap,weproposeCLEAR,anew
1
4202
tcO
32
]VC.sc[
1v75081.0142:viXraData Unlearning Evaluation
#1 Miltimiodal
Name: Aurelio Beltran Model
Age: 39 1 IDK
B Mi er xt ih cp olace: Mexico City, Unlearn 2 SCRUB
Genre: True Crime person #1 3 KL
Books: "The Bloody Blue-
print”, "No SOS for Guilt",
Model Textual
and "Beneath the City of
Sin". 1 IDK
2 DPO
#N 3 SCRUB
Name: Rhoda Mbalazi U: Who is Aure- U: Who is this?
Age: 68 lio Beltran?
Birthplace: Dar es Salaam, Visual
Tanzania Model: I don’t
Genre: War genre know. 1 SCRUB
Books: “The Battle of 2 TWINS
Unsaid Words”, “Shadows on
the Barracks”, “The Model: I don’t 3 RMU
Soldier's Silence”. know.
Figure2: Summaryofourdataset. Wegenerate200personsandusemultimodalunlearningtoforgetthepartof
them. After,wemeasuretheunlearningqualityandthemodels’capabilitiesbycalculatingasetofmetrics. Then,
wecreatealeaderboardofunlearningmethodsbasedonthesemetrics.
benchmarkfortextual-visualMMUnamed,focus- combine them within an MLLM. We create a
ing on person unlearning, which aligns with the leaderboardforeachdomain,highlightingthatmul-
right-to-be-forgottenconcept. Thedatasetissyn- timodalunlearningposesnewchallenges.
thetic to ensure control over the data the model Finally,wedemonstratethatapplyingℓ regular-
1
learns, preventing object leakage during training. izationtotheLoRAadapterduringtheunlearning
Wegeneratedconsistentimagesthroughacompre- processsignificantlyimprovesperformance,help-
hensivestrategyandlinkedthemtothecorrespond- ingtopreventcatastrophicforgettingoftheretain
ing author-related questions from the large-scale setinformation. Overall,ourcontributionscan
textualunlearningbenchmarkTOFU(Mainietal., besummarizedasfollows:
2024). The proposed dataset contains 200 ficti-
tiousauthors,3,770visualquestion-answerpairs, • Weproposeanovelbenchmark,CLEAR,for
and4,000textualquestion-answerpairs,enablinga evaluatingmachineunlearninginmultimodal
thoroughevaluationofthesingleandmulti-modal (textual-visual) setups. To the best of our
unlearningtechniques. We alsoproposeabench- knowledge,thisisthefirstpubliclyavailable
marktoassessMUandMMUmethods,evaluating MMUbenchmark.
10techniques,includingthecurrentstateoftheart.
• We comprehensively evaluate existing un-
Weevaluatetheunlearningmethodsintextual,
learning methods across separate and com-
visual, andmultimodalsetups. First, wefinetune
bined domains. We construct leaderboards
the model on our entire dataset. Next, we take a
for these three domains and show that state-
smallpredefinedsubsetof20authors,referredto
of-the-art unlearning algorithms struggle in
as the forget set, while the remaining data forms
multimodalsetups,highlightingtheneedfor
the retain set. We then apply the unlearning pro-
newapproaches.
cedure, resulting in a new model that no longer
"remembers" individuals from the forget set but
• Wedemonstratethattheℓ weightregulariza-
1
retainsknowledgeofthoseintheretainset. Toen-
tion on the LoRA adapter helps to improve
surethemodel’scapabilitiesarenotcompromised
unlearningqualitybysignificantlypreventing
during unlearning, we assess its performance on
catastrophicforgetting.
real-world tasks, such as celebrity face recogni-
tionandgeneraldomainvisualquestion-answering
2 RelatedWork
(VQA). Overall, we work with four sets: Forget,
Retain,RealFaces,andRealWorld. Figure1illus- 2.1 MUMethodsandTextualBenchmarks
tratesanexamplefromeachset.
MUmethods(CaoandYang,2015;Dworketal.,
Weevaluateexistingunlearningmethodssepa- 2014; Kurmanji et al., 2024; Neel et al., 2021;
rately in textual and vision modalities and then Sekharietal.,2021)removetheimpactofcertain
2datainstancesfromatrainedmodelwithoutrequir- EFUF (Xing et al., 2024) mitigates hallucina-
ing full retraining. The goal is to obtain a model tionsinMLLMsusingunlearning. Itmeasuresthe
that behaves like the forget data was never part similaritybetweengeneratedcaptionsandimage
of the training set. MU can be formalized in two content with CLIP model (Radford et al., 2021)
mainways. Inasettingwheretheunlearnedmodel toautomaticallydetecthallucinated(negative)and
mustproduceidenticaloutputstoamodeltrained non-hallucinated(positive)examplesbasedonthe
withouttheforgetdata. Inaninexactunlearningset- calibrated on the MSCOCO dataset (Lin et al.,
ting,themainobjectiveistoobtainanymodelthat 2014)thresholds,eliminatingmanuallabeling. The
doesn’tcontainknowledgefromtheforgetset,but unlearning process applies three loss functions:
withnorestrictionsandguaranteesonthemodel’s negativelosstoforgethallucinations,positiveloss
responsetoinputsfromtheretainset. toreinforcecorrectrepresentations,andsentence
There are several standard textual unlearning losstomaintainfluency. However,theirbenchmark
benchmarks. TOFU(Mainietal.,2024)isabench- isnotopen-sourced.
mark for textual LLM unlearning, featuring 200 SingleImageUnlearning(SIU)(Lietal.,2024a)
fictitiousauthorprofiles,eachdefinedbyattributes focusesonunlearningvisualconceptsinMLLMs
suchasname,birthplace,parent’snamesandoccu- whilepreservingtextualknowledgeandintroduces
pation,writtenbooks,etc. Totallythedatasethas MMUBench with five evaluation metrics. The
4,000question-answerpairs(20perauthor). Prede- benchmarkcovers20conceptswithatleast50im-
fined10/90,5/95,and1/99splitsareusedforfor- agesfortheconcept,includingreal-worldfigures
get/retainsets. Modelsarefinetunedontheentire andcartooncharacters. Foreachconcept,oneim-
dataset,andunlearningisappliedtotheforgetpairs. age is selected as the forget subset, paired with
WMDP(Lietal.,2024b)consistsof3,668multiple- variousprompts,whiletheremainingimagesform
choicequestions,evaluateshazardousknowledge the retain subset. However, SIU’s use of a single
ofLLMs,andservesasabenchmarkforunlearning imageraisesscalabilityconcernsforcomplexcon-
suchdangerousinformation. In(Yaoetal.,2024a), cepts,andtheirunlearningofVLLMislimitedto
theauthorsexploreseventextualunlearningtech- thevisualdomain. Moreover,MMUBenchisalso
niques. The best approach was a combination of notopen-sourced.
gradientascentwithgradientdescentontheforget (Chakraborty et al., 2024) explores unlearning
and retain sets, respectively, to maintain the un- harmfulcontentinVLLMs,demonstratingthatun-
learn/retainqualitytrade-off. Theyevaluatedtheir learninginthetextualdomainalonecanmatchthe
methodsonthreebenchmarkdatasetsfromdiffer- performanceoftext-imageunlearningwhileusing
entdomains: 500arXivpapers,2000GitHubfiles, fewerresources. Theirmethodcombinesharmful
and100bookscoveringacademictexts,code,and loss and KL divergence between unlearned and
literary works. Unfortunately, these three bench- retrainedmodels. Theapproachwastestedonsix
marks cannot be applied to the MMU evaluation. datasets,includingPKU-SafeRLHF(Jietal.,2024)
and three vision-text attack datasets (Shayegani
et al., 2023; Luo et al., 2024; Gong et al., 2023)
2.2 MMUMethodsandBenchmarks
forharmfulcontentprompts,andTruthful-QAand
MLLMs(Liuetal.,2023)typicallyconsistofthree VQA-v2 (Lin et al., 2021; Goyal et al., 2017) to
core components: a modality encoder that trans- ensure benign task performance remained intact.
latesrawinputintofeatureembeddings,amodality However,theirfocusonsafetyalignmentmaylimit
projectionlayeraligningthesefeatureswithinthe applicability for general unlearning, such as bio-
languagespace,andapre-trainedlanguagemodel metric privacy. While they claim that textual un-
synthesizingthefinaloutput. learningissufficientforMMU,ourfindingsshow
Nonetheless,MMUresearchisstillinitsearly thisisnottrueforallmethods. Additionally,their
stages. (Cheng and Amiri, 2023) proposed the approachlacksexactunlearningevaluation.
MultiDeletemethod,whichfocusesonseparating
cross-modal embeddings for the forget set while 3 Methodology
preservingunimodalembeddingsfortheretainset.
Unfortunately, this approach is suitable only for Unlearning can be conceptualized in two main
the encoder-decoder architecture and can not be ways: the objective of the Strict Unlearning is
directlytransferredtodecoder-onlyLLMs. toachieveamodelthatbehavesidenticallytoone
3Figure3: Examplesofgeneratedimagesshowcasingadistinctindividualfromourdataset.
trainedexclusivelyontheretainset,ensuringthat the optimization, aimed at increasing forget loss
no knowledge from the forget set is present; the andmaintainingretainperformance:
objectiveoftheInexactUnlearningistoproduce
(cid:88) (cid:88)
anymodelthatnolongercontainsinformationfrom L˜ = − L(x ,y ,θ)+λ L(x ,y ,θ)
i i j j
theforgetset. However,thisapproachcannotguar-
xi∈D
f
xj∈DR
anteehowthemodelwillrespondtoinputsrelated (1)
totheforgetset. Theseobjectivesrequiredistinct θ (cid:55)→ θ−α∇ L˜, (2)
θ
methods,lossfunctions,andevaluationmetricsto
assessunlearningquality. whereλ–forget-retaintrade-offhyper-parameter,
α–learningrate,Lisalossfunction,forexample,
Letf denotetheoriginalmodelwithitsparam-
θ
negative-log-likelihood. xistheinput–text,image,
etersθ. Sourcemodelf istrainedontraindataset
θ
orbothoftheminthecaseofVLLM.
D, and given the unlearning objective, we want
In this work, we explore a subset of unlearn-
to make our model forget a subset of the source
ing methods, including Retain Finetune, Gradi-
dataset D, called forget set D . The remaining
F
entAscend(GA),GradientDifference(GD)(Liu
partofthetrainingdatasetiscalledretainset,and
etal.,2022),SCRUB(Kurmanjietal.,2023),DPO
we aim to preserve the model’s performance on
(Rafailovetal.,2023),NPO(Zhangetal.,2024),
thisdatasubsetD := D\D . Additionally,we
R F
LLMU (Yao et al., 2024b) , IDK (Maini et al.,
utilize a holdout set D to establish a reference
H
2024),RMU(Lietal.,2024b),andKL(Golatkar
for the model’s desired behavior on D after the
F
etal.,2020),whicharedetailedinAppendixA.We
unlearningprocess. Themodel’strainingdidnot
selectedthesemethodsbasedontheireaseofadap-
include this set, ensuring thatD ∩D = ∅. In a
H
tationtonewmodalities,requiringonlychangesin
nutshell,forgetsetD containssamplesthemodel
F
inputdata(text,images,orboth)whilepreserving
shouldunlearnandservesasadirectmeasureofun-
their core functionality. In essence, these meth-
learningeffectiveness;retainsetD containssam-
R
odsinvolvevariationsofhardnegativetrainingon
plesthatthemodelshouldretainandperformwell
the forget set combined with fine-tuning on the
on,servingasanindicatorofthemodel’spreserved
retain set, often with additional constraints such
knowledge;holdoutsetD containssamplesthat
H
as Cross-Entropy or KL divergence to align the
the model has never seen before and serves as a
model’soutputsontheretainsetwiththeoriginal
referenceforthemodel’sbehaviorondatathatwas
model.
not involved in the training process. Such forget-
tingprocedureisperformedbyupdatingthemodel
4 CLEAR
f withaparticularunlearningmethod,whichre-
θ
sultsinanewunlearnedmodelf withparameters
θˆ The MU (and consequently MMU) benchmark
θˆ
. Fortheevaluation,wecanalsotrainseparately
should ideally avoid running unlearning on well-
agoldmodelg ,whichistrainedonlyontheD .
ω R known information that could be obtained from
Sotheobjectiveistoobtaintheunlearnedmodel external sources such as books, games, movies,
f which unlearns the forget set D while pre- etc. Thisisessentialforamorereliableevaluation
θˆ F
servingtheperformanceonretainsetD asgood of the model’s performance on retain and forget.
R
as the source model f . It can be done by opti- Tomeetthisrequirement,wechosetoextendthe
θ
mizing (minimizing or maximizing) the specific TOFUdatasetduetoitseaseofuse,flexibilityfor
criterionwiththemodelparametersθandresulting adopting to new modalities (such as adding face
obtained parameters
θˆ
will be the parameters of imagesorpersonalvoices),anditsstrongconnec-
desiredunlearnedmodelf . Forexample,onecan tiontoprivacyconcerns,makingitidealfortesting
θˆ
considerthegradientdifferenceMUapproachfor unlearninginsensitivecontexts.
4tomaintainthemodel’svisualcapabilitiesduring
unlearning.
4.2 Splits
Ultimately, we utilize the following four splits
(sets)toevaluateunlearning:
Forget. Followingmethodologyfrom(Mainietal.,
2024),D ismadefromdataof2,10,and20per-
F
sons (1%, 5% and 10% correspondingly) of the
Figure4: Distributionsoftheattributesoftheauthor’s full set D, consisting of 200 authors. This D is
F
faces. WeshowthatCLEARisbalancedandrepresen-
expectedtobeunlearnedbythemodel.
tativeregardingage,gender,andethnicity.
Retain. RetainsetD ismadefromalltheother
R
datafromthecompletesetD,notincludedinthe
4.1 DatasetGenerationProcess
D . Themodelshouldcontinuetoworkwellon
F
Firstly,foreachofthe200authorsfromtheTOFU thissubsetandpreserveitsperformanceasmuch
dataset, we extract their name, age, and ethnicity aspossible.
based on the knowledge provided in the original Real Faces. To ensure the model retains knowl-
dataset. Also, we generate a pool of 2000 faces edgeofrelatedconcepts,suchasfaces,whichare
usingStyleGAN2(Karrasetal.,2020)-anestab- not present in the finetuning dataset, we evaluate
lished generative model for face synthesis. Each itusingasetofreal-worldfaces. Specifically,we
faceisscoredwithpre-trainedCNNstogettheage, usetheMillionCelebsdataset(Zhangetal.,2020),
gender,andethnicityoftheface. Then,wemanu- whichconsistsofcelebrityface-namepairs. Wein-
allyselectthemostsuitablefacethatmatchesthese tersectthisdatasetwiththemostrecognizedcelebri-
attributes for each author. During this phase, we tiesfromanyyearontheForbesCelebrity100list
discoveredthattheagedistributionoftheauthors toincreasethelikelihoodthatthemodelhasseen
was highly shifted towards the older ages, so we these faces during pre-training. This results in a
neededtoeliminatethisgap. Todothis,weused finalsetof150face-namepairs.
theimageeditingframeworkproposedin(Bobkov Real World. To ensure that the model’s overall
et al., 2024) to shift the visual attributes of the visualcapabilitiesremainintactthroughouttheun-
facestomakethemolder. Thedistributionofthe learning process, we evaluate its performance on
characteristics of the faces and authors is shown theVisualQuestionAnswering(VQA)taskusing
inFigure4. Aftermatchingeachauthortoaface, samplesfrom(x.ai,2024).
we used the diffusion model (Li et al., 2024c) of Figure1presentsarandomsamplefromeachof
personalizedgenerationtosynthesizeimageswith thesesplits.
agivenfaceandcorrespondingtoagivenprompt.
4.3 EvaluationMetrics
Indetail,thefacegenerationandcollectionprocess
isdescribedinAppendixB. To comprehensively evaluate unlearning per-
formance on textual, visual, and textual-visual
Thediffusionmodelneedsatextualpromptfor
domains, we measure the MU and MMU perfor-
imagegenerationbesidestheface. WeaskGPT-4
manceintermsofthefollowingmetrics:
togenerateimagesfromatextualquestionandan
ROUGE-L We calculate the ROUGE-L (Lin,
answeraboutanauthor. Wegenerate8imagesfor
2004)scorebetweenthemodel’spredictionsand
eachprompt,evaluatethemusinganensembleof
groundtruthanswers. Thismetricmeasureshow
fake-detectionmodels,andselectthemostrealistic.
muchthemodelremembersinexactformulations.
Additionally,GPT-4ogeneratescaptionsforeach
However,thegenerationofmodelsdoesnotalways
image and visual prompt pair, which are then in-
represent the inner knowledge of one’s. That is
cludedinthedataset. However,duetorestrictions
wherethenextmetricisused.
causedbyGPTguardbreaksandtheidentification
Probability Score One way of exposing elicit
of several bugs in the TOFU dataset (such as a
knowledge from a model is through its logits,
namelessauthor),thefinaldatasetincludesfewer
which are assigned to some factual tokens. We
imagesthantextpairs(3,770comparedto4,000).
1
Wealsoincorporatedtwoadditionaldatasplitscon- define the conditional probability p(y|x)|y| for
tainingreal-worldfacephotosandnaturalimages input x and answer y (power 1 corresponds to
|y|
5normalizing for length). Each input question x Real Retain Forget LogForget
M Method
Metric↑ Metric↑ Metric↓ Quality↑
is considered as a multiple choice question with
possibleanswersy ,...,y ,andthen,assumingy RetainFT 0.50 0.26 0.42 -4.92
1 n 1 LLMU 0.38 0.03 0.01 -2.31
isthecorrectanswer,desiredprobabilityscoreis KL 0.24 0.00 0.00 -18.22
computedas p(y1|x) . Itwillbeboundedbetween GA 0.25 0.00 0.00 -17.22
(cid:80)n
p(yi|x)
IDG KD 00 .. 46 61 00 .. 21 63 00 .. 20 41 - -4 48 .9.5 29
i=1
0 and 1. A lower probability score indicates DPO 0.50 0.26 0.42 -4.92
SCRUB 0.50 0.26 0.42 -4.92
that the model is less confident about generating
RMU 0.51 0.26 0.59 -42.86
content. NPO 0.50 0.28 0.62 -44.46
RetainFT 0.67 0.34 0.47 -3.87
LLMU 0.65 0.30 0.39 -6.69
TruthRatio quantifiesthealignmentbetween
KL 0.28 0.00 0.00 -50.30
predictionsandthegroundtruthbycomparingthe GA 0.26 0.00 0.00 -36.06
probabilityofaparaphrasedcorrectansweragainst GD 0.60 0.01 0.00 -51.16
IDK 0.63 0.32 0.45 -2.72
theaveragedprobabilitiesofseveralsimilarlyfor-
DPO 0.67 0.33 0.47 -3.63
mattedincorrectanswers,providinginsightintothe SCRUB 0.66 0.33 0.47 -3.39
RMU 0.09 0.00 0.00 -123.22
effectivenessoftheunlearningalgorithminremov-
NPO 0.67 0.33 0.47 -3.16
ingspecificinformationwhilemaintainingoverall
accuracy. Assume that yˆ denotes a paraphrased Table1: Unlearningmethodsontextualdomainonly.
versionoftheansweryforinputxandY′istheset Thegraycolorrepresentsalowretainmetric,indicating
themethoddiverges. Hence,wedonotconsiderthem.
of 5 perturbations of the answer y. Then desired
truthratioRiscalculatedas: Forget Holdout Retain
Method U-LIRA↓ U-MIA↓
Acc.↓ Acc.↑ Acc.↑
1 (cid:80) p(y′|x)|y1 ′| Original 100.00 18.50 100.00 1.00 0.96
|Y′| Gold 15.43 15.04 97.52 0.50 0.50
y′∈Y′
R = . (3) RetainFT 100.00 18.54 100.00 1.00 0.92
1
p(yˆ|x)|yˆ| SCRUB 99.74 16.77 99.93 0.98 0.90
LLMU 85.72 14.62 88.99 0.83 0.75
RMU 67.97 17.27 99.99 0.77 0.60
This ratio is normalized and rescaled between 0 DPO 50.21 13.93 81.49 0.73 0.62
and1,withhighervaluesindicatingimprovedun- SCRUBbio 42.59 14.25 99.44 0.71 0.57
Sparsity 66.41 14.44 83.57 0.78 0.73
learning. Twins 50.00 20.34 99.72 0.73 0.54
Forget Quality. Measuring the quality of for-
Table2: Resultsofunlearningonvisualmodalityonly.
gettinginMUpresentssignificantchallenges. The
Thegraycolorrepresentsmethodswithrelativelylow
objective is to create a model that cannot be dis-
accuracy on the retain set, indicating that they suffer
tinguishedfromonetrainedsolelyonretain. The
fromcatastrophicforgetting. Therefore,wedonotcon-
established(Hayesetal.,2024)wayofmeasuring
siderthesemethodstobesuccessful.
the unlearning quality is calculating the U-LIRA
score. However, it requires training at least 128 5 Experiments
modelcopies,whichiscomputationallyexpensive
forLLM.Afeasiblemethodforachievingthisis First, we explore the capabilities of the current
proposed. Wecalculateastatisticaltestontheout- unlearningmethodswithinsingledomainsinSec.
putsoftwomodels: ourunlearnedmodelandthe 5.1 and 5.2. Second, we transfer them to textual-
goldmodel. TheTruthRatiometricisconsidered visualMMUinSec. 5.3.
as output for its effectiveness in informativeness.
5.1 UnlearningTextualDomain(LLMs)
Toassessthismetric,theKolmogorov-Smirnovtest
(KS-Test)isemployedtocomparethedistributions For the experiments on the textual domain exclu-
ofTruthRatiosfrombothmodels. Ahighp-value sively,weconsiderthetextualpartoftheproposed
fromthistestsuggestseffectiveforgetting,whilea CLEARdatasetandusetheLLMs,whichareoften
lowp-valueindicatespotentialprivacyleakageand usedinMLLMs,specificallyLlama2-7B(Touvron
poor unlearning. We call this p-value the Forget et al., 2023) and Mistral-7B (Jiang et al., 2023).
Qualityoftheunlearningmethod. First, we finetune the model on all the data and
Also,wedefineReal,Retain,andForgetmetrics unlearn it on the forget set. To evaluate the final
asaharmonicalmeanofROUGE,RealProbability quality of unlearning, we calculate Real, Retain,
score,andTruthRatio. and Forget metrics and Forget Quality. The full
6
B7-2amaLL
B7-lartsiMresultsareprovidedinTable1. SeetheAppendix population-basedattackthattrainsabinaryclassi-
Dforpipelinedetailsandhyperparameters. fieronshadowmodeloutputsandtheirstatus(1if
from the forget set, 0 otherwise). Successful un-
LogForget learningoccurswhenHoldoutAccuracyclosely
Loss Modality Real↑ Forget↓ Retain↑
Quality↑
alignswithForgetAccuracy. Fromthestandpoint
Original —– 0.48 0.3 0.51 -61.22
oftheattack,U-LIRAandU-MIAshouldbeun-
Gold —– 0.50 0.19 0.51 0.00
abletodistinguishbetweenthetwosets,resulting
LLMU text 0.47 0.37 0.49 -71.23
LLMU visual 0.50 0.35 0.51 -60.26 inanattackaccuracycloseto0.50. Thissituation
LLMU both 0.47 0.25 0.51 -95.12
wouldindicatethatthemodelhas"forgotten"the
SCRUB text 0.49 0.35 0.51 -61.22
specificdata,asthemodeltreatstheforgettingand
SCRUB visual 0.48 0.37 0.49 -60.26
SCRUB both 0.49 0.36 0.52 -60.26 holdoutsetssimilarly. Wecomparetheforgetand
DPO text 0.46 0.38 0.49 -62.18 holdoutsetslogitdistributionsinAppendix6.
DPO visual 0.49 0.22 0.49 -90.26
DPO both 0.46 0.22 0.48 -91.46
5.3 MultimodalExperiments
Table3: Resultsofunlearningofdifferentmodalities.
For the source model, we use LLaVa model (Liu
Wefinetuneonfulldatasets(bothmodalities),thenfor-
et al., 2023) with ViT (Dosovitskiy et al., 2021)
get on a single domain subset (text or visual) or full
asvisualencoderandLLaMa2-7B(Touvronetal.,
forgetset. Original–modelbeforeunlearning. Gold-a
2023) as a language model. First, we finetune it
modeltrainedonlyonretain.
onthefullCLEAR,bothvisualandtextualparts,
andcallthismodel"original",asitcontainsforget
5.2 UnlearningVisualDomain
and retain sets of knowledge. Then, we perform
ExperimentsonthevisualdomainoftheCLEAR
the unlearning process on it. We use the same
datasetfocusonthefacebiometrics(identification)
hyperparametersforeachmethod. Then,weeval-
task. Whilefaceidentificationcanbetreatedasa
uatetheunlearnedmodelaccordingtoourmetric
classificationtaskwithafixedsetofindividuals,it
setup described in Sec. 4.3. For comparison, we
is typically framed as a few-shot or metric learn-
demonstratethemetricsofthe"gold"model. The
ingproblem,aimingtotrainanembeddingmodel
resultsofexperimentsandcorrespondingmetrics
that maps images of the same person to nearby
areprovidedinTable4. Detailsoftheexperiments
pointsintheembeddingspaceandensuressepara-
pipelinearedescribedinAppendixF.
tionbetweendifferentindividualsandthisshould
hold even for the unseen during training persons. 5.3.1 IsTextualUnlearningEnough?
We chose ResNet-18 (He et al., 2015) due to its Webeginbyaddressingthequestion: Canwefor-
relativelysmallsizeandscalability. getapersonusingonlytextualdata,anddoesmul-
We fine-tuned ResNet-18, pre-trained on Ima- timodalityintroducenewchallengestounlearning?
geNet,for100epochsontheCelebsdataset(Zhang To explore this, we attempt to forget 20 indi-
et al., 2020), using photos of 797 individuals for viduals from the forget set using only textual un-
trainingand200fortesting. Tocomputeidentifica- learning. We also perform unlearning using only
tionaccuracy,weaveragedtheembeddingsoffive visual data or both modalities, and then compare
images per individual to obtain reference (enroll- the results. We find that unlearning text alone is
ment)vectorsandclassifiedtheremainingimages sufficienttoachievealowforgetmetric,consistent
usingcosinesimilarity. Themodelachieved99.0% withpreviousfindings. However,thisalsoresults
accuracyonthetrainingsetand83.4%onthetest inanoticeabledropinretainmetrics. Fullresults
set. Forunlearningevaluation,themodelwasfine- areprovidedinTable3.
tuned on the visual part of CLEAR dataset 128
times, following a Membership Inference Attack 5.3.2 UnlearningBothDomains
(MIA) approach. We trained 64 models with the After we understand that multimodal unlearning
forgetincludedand64modelswithoutit,alternat- cannotbefullyaddressedusingasinglemodality,
ingwiththeholdoutset(iftheforgettingsetisused weproceedwithexperimentsonunlearningacross
fortraining,theholdoutsetisnot,andviceversa). bothmodalities. Wetakeoursourcemodelf and
θ
WeevaluatedthemodelsonD ,D ,andD apply unlearning methods. As forget set, we use
F R H
usingaccuracy,U-LIRA(Hayesetal.,2024),and alltheavailabledataabout20persons-10%ofthe
U-MIA attack metrics. U-MIA is a lightweight, datasetsize.
7LoRAL1 Real Retain Forget LogForget forgetmetricswithoutadropinretainperformance.
Method
Regularization metric↑ metric↑ metric↓ Quality↑
Theseobservationsareconsistentacrossboththe
Original — 0.48 0.51 0.39 -61.22
Gold — 0.50 0.51 0.19 0.00 LLaMaandMistralmodels.
GA — 0.32 0.00 0.00 -13.04
GA ✓ 0.49 0.50 0.37 -61.22 Visual MU results are presented in Table 2. It
GD — 0.24 0.00 0.00 -17.72
GD ✓ 0.49 0.50 0.37 -62.18 shows that most methods achieve high accuracy
IDK — 0.48 0.51 0.30 -74.40 on the forget set with competitive U-LIRA and
IDK ✓ 0.49 0.50 0.37 -63.15
KL — 0.27 0.00 0.00 -13.92 U-MIAvalues. Notably,SCRUB bio andTwinsper-
KL ✓ 0.49 0.50 0.37 -62.18
form best across all considered metrics, making
NPO — 0.49 0.51 0.36 -63.15
NPO ✓ 0.49 0.51 0.36 -64.13 them optimal in this context. The Holdout Accu-
RetainFT — 0.49 0.51 0.36 -60.26
RetainFT ✓ 0.49 0.50 0.37 -61.22 racyisrelativelyconsistentacrossmethods.
RMU — 0.27 0.00 0.00 -23.68 In multimodal unlearning, Table 3 shows that
RMU ✓ 0.49 0.50 0.36 -61.22
LLMU — 0.47 0.49 0.37 -73.34 fortheLLMUmethod,unlearningbothmodalities
LLMU ✓ 0.49 0.51 0.36 -60.26
DPO — 0.46 0.49 0.39 -61.22 yieldsbetterresultsthantext-onlyunlearning. The
DPO ✓ 0.48 0.50 0.37 -65.12 forgetmetricdropsfrom0.37inthetextualdomain
SCRUB — 0.49 0.51 0.36 -62.18
SCRUB ✓ 0.50 0.51 0.35 -61.22 to0.25whenunlearningbothdomains,whilethe
retain and real metrics remain stable. For DPO,
Table4:ResultsonexperimentswithandwithoutLoRA
theresultsarelessstraightforward,butitisevident
regularization. Thegraycolorshowsthatthemethod
thatunlearningthevisualdomainiscrucial. When
completelyfailsontheretainset.
unlearningin thevisualor bothdomains, thefor-
5.4 LoRARegularization getmetricis0.22,comparedto0.38fortext-only
unlearning. The retain and real metrics stay con-
Asshownpreviously(Jiaetal.,2024),modelspar-
sistent. However, SCRUB remains robust across
sitycanimproveunlearning,butsignificantdrops
allmodalities,performingconsistentlyinallthree
in retain metrics still occur. We hypothesize that
setups.
keeping the model close to its initial state during
Thenwerunourexperimentsonunlearningboth
unlearningcouldhelppreserveretainknowledge.
domains. Thepictureisverysimilartotheexperi-
LoRA adapters (Hu et al., 2021) have become
mentsonthetextualdomainonly. Table4shows
astandard techniqueto reducecomputationalde-
that GA, GD, KL and RMU effectively unlearn
mands in large-scale NLP models. We propose
theforgetset(forgetmetricgoesto0)butexhibit
usingthemagnitudeofLoRAweightsasaproxy
significantcatastrophicforgettingoftheretainset
forhowfarthemodelhasdeviatedfromitsinitial
(retain metrics also goes to 0). In contrast, IDK,
state. To address this, we add the ℓ norm of the
1
SCRUB,LLMUandDPOremainstableonthere-
adapterweightstotheunlearningloss,usingafixed
tainset(around0.48),buttheirunlearningquality
λ = 0.01withouttuning,thoughtuningcouldim-
is worse (0.37 versus 0.39 on the original unun-
prove results. The results of the experiments are
learnedmodel). Theachievingthebalancebetween
showninTable4.
unlearningandretentionischallengingagain.
Leaderboards We construct our leaderboards
6 ResultsandDiscussion
straightforwardly. First,weexcludemethodsthat
Textdomain failtoretainknowledgefromtheretainset(high-
Table 1 presents the results for the text domain, lighted in gray in the tables) and then rank the
showing that the RMU, KL, GD, and GA meth- remainingmethrodsbasedontheForgetmetric(or
ods excel in unlearning the forget set (with the U-LIRAinthevisualdomain). Thetop-3methods
forgetmetricdroppingto0),buttheysufferfrom amongeachmodalityareshowninfigure2
catastrophicforgettingontheretaindata(theretain LoRARegularizationLastly,theexperimentson
metric also drops to 0). The remaining methods ℓ LoRA regularization (Table 4) show improve-
1
maintainperformanceontheretainset(retainmet- ments in unlearning quality for several methods,
ricsremainroughlythesame),buttheirunlearning significantly reducing catastrophic forgetting in
quality is poor – the forget metric is close to the Gradient Ascent, Gradient Difference, KL mini-
oneachievedbyRetainFT.Identifyinganoptimal mization, RMU, and especially in LLMU. How-
method that balances unlearning and retention is ever,theproposedregularizationisnotbeneficial
challenging. However,amongthetestedmethods, forallunlearningtechniques.
IDK,DPO,andSCRUBprovidethebest(lowest)
87 Conclusion References
Inthiswork,weintroduceCLEAR,thefirstopen- ClarkBarrett,BradBoyd,ElieBursztein,NicholasCar-
lini,BradChen,JihyeChoi,AmritaRoyChowdhury,
sourced benchmark designed to assess machine
MihaiChristodorescu,AnupamDatta,SoheilFeizi,
unlearninginmultimodal(textualandvisual)setup.
etal.2023. Identifyingandmitigatingthesecurity
Our evaluation of existing unlearning techniques risksofgenerativeai. FoundationsandTrends®in
acrossdomainsshowsthatmultimodalunlearning PrivacyandSecurity,6(1):1–52.
is more challenging than previously anticipated,
DenisBobkov,VadimTitov,AibekAlanov,andDmitry
laying the ground for further research. Our stud-
Vetrov. 2024. The devil is in the details: Style-
ies on incorporating a LoRA regularization term
featureeditor for detail-rich stylegan inversion and
demonstratethatthissimpletechniqueimprovesun- high quality image editing. In Proceedings of the
learningandcanbeeasilyintegratedintootherMU IEEE/CVFConferenceonComputerVisionandPat-
ternRecognition(CVPR),pages9337–9346.
methods. We aim to encourage further research
on enhancing privacy and security in large-scale
YinzhiCaoandJunfengYang.2015. Towardsmaking
AImodelsbyofferinganopen-sourcebenchmark. systems forget with machine unlearning. In 2015
FutureworkcouldfocusonimprovingMMUalgo- IEEEsymposiumonsecurityandprivacy,pages463–
480.IEEE.
rithmsandexpandingunlearningtonewmodalities,
suchasvoiceandvideo.
Nicholas Carlini, Steve Chien, Milad Nasr, Shuang
Song, Andreas Terzis, and Florian Tramer. 2022.
Limitations
Membershipinferenceattacksfromfirstprinciples.
Preprint,arXiv:2112.03570.
Despitethecontributionsofthiswork,severallimi-
tationsremainthatneedfurtherinvestigation. One TrishnaChakraborty,ErfanShayegani,ZikuiCai,Nael
major limitation is the reliance on synthetic data, Abu-Ghazaleh,M.SalmanAsif,YueDong,AmitK.
as CLEAR is based on such dataset, which may Roy-Chowdhury,andChengyuSong.2024. Cross-
modalsafetyalignment: Istextualunlearningallyou
notfullycapturethecomplexityofreal-worldsce-
need? Preprint,arXiv:2406.02575.
narios, thus limiting the generalizability of our
findings. Additionally,whileourworkfocuseson Jiaao Chen and Diyi Yang. 2023. Unlearn what you
unlearning methods designed for privacy-centric wanttoforget:EfficientunlearningforLLMs. InPro-
ceedingsofthe2023ConferenceonEmpiricalMeth-
applications, such as removing personal data, it
odsinNaturalLanguageProcessing,pages12041–
may not fully address other unlearning needs,
12052, Singapore. Association for Computational
suchasremovingharmfulcontent. Moreover,our Linguistics.
benchmarkmainlyevaluatesfine-tuning-basedun-
learning methods using sophisticated loss func- Jiali Cheng and Hadi Amiri. 2023. Multidelete for
multimodalmachineunlearning.
tions, leaving unexplored other broader unlearn-
ing techniques, such as analytical or mechanical
Alexey Dosovitskiy, Lucas Beyer, Alexander
approaches. Another challenge lies in the scala- Kolesnikov, Dirk Weissenborn, Xiaohua Zhai,
bility of these unlearning methods, as they may Thomas Unterthiner, Mostafa Dehghani, Matthias
Minderer, Georg Heigold, Sylvain Gelly, Jakob
struggletoscaleefficientlywhenappliedtolarger
Uszkoreit, and Neil Houlsby. 2021. An image
modelsanddatasets,hinderingtheirpotentialuse
is worth 16x16 words: Transformers for image
inreal-worldsystems. Furthermore,ourfocuson recognitionatscale. Preprint,arXiv:2010.11929.
catastrophicforgettingoverlooksunintendedside
CynthiaDwork,AaronRoth,etal.2014. Thealgorith-
effects, such as the introduction of biases or the
micfoundationsofdifferentialprivacy. Foundations
degradation of model performance on unrelated
andTrends®inTheoreticalComputerScience,9(3–
tasks,andthebroaderimpactofunlearningonfair- 4):211–407.
ness and safety remains an open area for future
research. RonenEldanandMarkRussinovich.2023. Who’sharry
potter? approximate unlearning in llms. Preprint,
arXiv:2310.02238.
Ethics
We utilized 84 hours of A100 GPU computation Aditya Golatkar, Alessandro Achille, and Stefano
Soatto.2020. Eternalsunshineofthespotlessnet:Se-
forourexperiments,whichresultedinanestimated
lectiveforgettingindeepnetworks. InProceedings
9kgofCO2emissions.
of the IEEE/CVF Conference on Computer Vision
andPatternRecognition,pages9304–9312.
9YichenGong,DelongRan,JinyuanLiu,CongleiWang, MeghdadKurmanji,PeterTriantafillou,JamieHayes,
TianshuoCong,AnyuWang,SisiDuan,andXiaoyun andEleniTriantafillou.2023. Towardsunbounded
Wang. 2023. Figstep: Jailbreaking large vision- machineunlearning. Preprint,arXiv:2302.09880.
language models via typographic visual prompts.
arXivpreprintarXiv:2311.05608. MeghdadKurmanji,PeterTriantafillou,JamieHayes,
andEleniTriantafillou.2024. Towardsunbounded
YashGoyal,TejasKhot,DouglasSummers-Stay,Dhruv machineunlearning. Advancesinneuralinformation
Batra,andDeviParikh.2017. Makingthevinvqa processingsystems,36.
matter: Elevating the role of image understanding
Jiaqi Li, Qianshan Wei, Chuanyi Zhang, Guilin Qi,
invisualquestionanswering. InProceedingsofthe
MiaozengDu,YongruiChen,andShengBi.2024a.
IEEE conference on computer vision and pattern
Singleimageunlearning: Efficientmachineunlearn-
recognition,pages6904–6913.
ing in multimodal large language models. arXiv
preprintarXiv:2405.12523.
JamieHayes,IliaShumailov,EleniTriantafillou,Amr
Khalifa, and Nicolas Papernot. 2024. Inexact un-
Nathaniel Li, Alexander Pan, Anjali Gopal, Sum-
learning needs more careful evaluations to avoid a
mer Yue, Daniel Berrios, Alice Gatti, Justin D. Li,
falsesenseofprivacy. Preprint,arXiv:2403.01218.
Ann-Kathrin Dombrowski, Shashwat Goel, Long
Phan,GabrielMukobi,NathanHelm-Burger,Rassin
KaimingHe,XiangyuZhang,ShaoqingRen,andJian
Lababidi,LennartJusten,AndrewB.Liu,Michael
Sun.2015. Deepresiduallearningforimagerecogni-
Chen,IsabelleBarrass,OliverZhang,XiaoyuanZhu,
tion. Preprint,arXiv:1512.03385.
Rishub Tamirisa, Bhrugu Bharathi, Adam Khoja,
Zhenqi Zhao, Ariel Herbert-Voss, Cort B. Breuer,
Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan
Samuel Marks, Oam Patel, Andy Zou, Mantas
Allen-Zhu,YuanzhiLi,SheanWang,LuWang,and
Mazeika, Zifan Wang, Palash Oswal, Weiran Liu,
WeizhuChen.2021. Lora: Low-rankadaptationof
Adam A. Hunt, Justin Tienken-Harder, Kevin Y.
largelanguagemodels. Preprint,arXiv:2106.09685.
Shih, Kemper Talley, John Guan, Russell Kaplan,
IanSteneker,DavidCampbell,BradJokubaitis,Alex
GabrielIlharco,MarcoTulioRibeiro,MitchellWorts-
Levinson, Jean Wang, William Qian, Kallol Kr-
man, Suchin Gururangan, Ludwig Schmidt, Han-
ishnaKarmakar,StevenBasart,StephenFitz,Mindy
naneh Hajishirzi, and Ali Farhadi. 2022. Edit-
Levine,PonnurangamKumaraguru,UdayTupakula,
ing models with task arithmetic. arXiv preprint
Vijay Varadharajan, Yan Shoshitaishvili, Jimmy
arXiv:2212.04089.
Ba, Kevin M. Esvelt, Alexandr Wang, and Dan
Hendrycks. 2024b. The wmdp benchmark: Mea-
JoelJang,DongkeunYoon,SoheeYang,SungminCha,
suringandreducingmalicioususewithunlearning.
MoontaeLee,LajanugenLogeswaran,andMinjoon
Preprint,arXiv:2403.03218.
Seo. 2022. Knowledge unlearning for mitigating
privacy risks in language models. arXiv preprint Zhen Li, Mingdeng Cao, Xintao Wang, Zhongang
arXiv:2210.01504. Qi, Ming-Ming Cheng, and Ying Shan. 2024c.
Photomaker: Customizing realistic human photos
Jiaming Ji, Mickel Liu, Josef Dai, Xuehai Pan, Chi via stacked id embedding. In Proceedings of the
Zhang,CeBian,BoyuanChen,RuiyangSun,Yizhou IEEE/CVFConferenceonComputerVisionandPat-
Wang, and Yaodong Yang. 2024. Beavertails: To- ternRecognition(CVPR),pages8640–8650.
wardsimprovedsafetyalignmentofllmviaahuman-
preferencedataset. AdvancesinNeuralInformation Chin-YewLin.2004. Rouge: Apackageforautomatic
ProcessingSystems,36. evaluation of summaries. In Text summarization
branchesout,pages74–81.
Jinghan Jia, Jiancheng Liu, Parikshit Ram, Yuguang
StephanieLin,JacobHilton,andOwainEvans.2021.
Yao, Gaowen Liu, Yang Liu, Pranay Sharma, and
Truthfulqa: Measuring how models mimic human
SijiaLiu.2024. Modelsparsitycansimplifymachine
falsehoods. arXivpreprintarXiv:2109.07958.
unlearning. Preprint,arXiv:2304.04934.
Tsung-YiLin,MichaelMaire,SergeBelongie,James
AlbertQ.Jiang,AlexandreSablayrolles,ArthurMen-
Hays, Pietro Perona, Deva Ramanan, Piotr Dollár,
sch,ChrisBamford,DevendraSinghChaplot,Diego
and C Lawrence Zitnick. 2014. Microsoft coco:
delasCasas,FlorianBressand,GiannaLengyel,Guil-
Common objects in context. In Computer Vision–
laumeLample,LucileSaulnier,LélioRenardLavaud,
ECCV 2014: 13th European Conference, Zurich,
Marie-AnneLachaux,PierreStock,TevenLeScao,
Switzerland, September 6-12, 2014, Proceedings,
Thibaut Lavril, Thomas Wang, Timothée Lacroix,
PartV13,pages740–755.Springer.
andWilliamElSayed.2023. Mistral7b. Preprint,
arXiv:2310.06825. Bo Liu, Qiang Liu, and Peter Stone. 2022. Con-
tinual learning and private unlearning. Preprint,
TeroKarras,SamuliLaine,MiikaAittala,JanneHell- arXiv:2203.12817.
sten, Jaakko Lehtinen, and Timo Aila. 2020. Ana-
lyzingandimprovingtheimagequalityofstylegan. HaotianLiu,ChunyuanLi,QingyangWu,andYongJae
Preprint,arXiv:1912.04958. Lee.2023. Visualinstructiontuning.
10Ximing Lu, Sean Welleck, Jack Hessel, Liwei Jiang, AyushTarun,VikramChundawat,MurariMandal,and
Lianhui Qin, Peter West, Prithviraj Ammanabrolu, Mohan Kankanhalli. 2021. Fast yet effective ma-
and Yejin Choi. 2022. Quark: Controllable text chineunlearning.
generation with reinforced unlearning. Advances
inneuralinformationprocessingsystems,35:27591– Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
27609. bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti
Weidi Luo, Siyuan Ma, Xiaogeng Liu, Xiaoyu Guo, Bhosale,DanBikel,LukasBlecher,CristianCanton
andChaoweiXiao.2024. Jailbreakv-28k: Abench- Ferrer,MoyaChen,GuillemCucurull,DavidEsiobu,
markforassessingtherobustnessofmultimodallarge JudeFernandes,JeremyFu,WenyinFu,BrianFuller,
language models against jailbreak attacks. arXiv CynthiaGao,VedanujGoswami,NamanGoyal,An-
preprintarXiv:2404.03027. thonyHartshorn,SagharHosseini,RuiHou,Hakan
Inan,MarcinKardas,ViktorKerkez,MadianKhabsa,
Pratyush Maini, Zhili Feng, Avi Schwarzschild, IsabelKloumann,ArtemKorenev,PunitSinghKoura,
ZacharyC.Lipton,andJ.ZicoKolter.2024. Tofu: A Marie-AnneLachaux,ThibautLavril,JenyaLee,Di-
taskoffictitiousunlearningforllms. anaLiskovich,YinghaiLu,YuningMao,XavierMar-
tinet,TodorMihaylov,PushkarMishra,IgorMoly-
SethNeel,AaronRoth,andSaeedSharifi-Malvajerdi. bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-
2021. Descent-to-delete: Gradient-based methods stein,RashiRungta,KalyanSaladi,AlanSchelten,
for machine unlearning. In Algorithmic Learning Ruan Silva, Eric Michael Smith, Ranjan Subrama-
Theory,pages931–962.PMLR. nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-
lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,
AlecRadford,JongWookKim,ChrisHallacy,Aditya ZhengYan,IliyanZarov,YuchenZhang,AngelaFan,
Ramesh,GabrielGoh,SandhiniAgarwal,GirishSas- Melanie Kambadur, Sharan Narang, Aurelien Ro-
try, Amanda Askell, Pamela Mishkin, Jack Clark, driguez,RobertStojnic,SergeyEdunov,andThomas
etal.2021. Learningtransferablevisualmodelsfrom Scialom.2023. Llama2: Openfoundationandfine-
naturallanguagesupervision. InInternationalconfer- tunedchatmodels. Preprint,arXiv:2307.09288.
enceonmachinelearning,pages8748–8763.PMLR.
Xinwei Wu, Junzhuo Li, Minghui Xu, Weilong
Dong,ShuangzhiWu,ChaoBian,andDeyiXiong.
RafaelRafailov,ArchitSharma,EricMitchell,Stefano
2023. Depn: Detecting and editing privacy neu-
Ermon,ChristopherD.Manning,andChelseaFinn.
ronsinpretrainedlanguagemodels. arXivpreprint
2023. Direct preference optimization: Your lan-
arXiv:2310.20138.
guage model is secretly a reward model. Preprint,
arXiv:2305.18290.
ZongzeWu,DaniLischinski,andEliShechtman.2020.
Stylespaceanalysis: Disentangledcontrolsforstyle-
AyushSekhari,JayadevAcharya,GautamKamath,and
ganimagegeneration. 2021IEEE/CVFConference
AnandaTheerthaSuresh.2021. Rememberwhatyou
onComputerVisionandPatternRecognition(CVPR),
wanttoforget: Algorithmsformachineunlearning.
pages12858–12867.
AdvancesinNeuralInformationProcessingSystems,
34:18075–18086. x.ai.2024. Grok-1.5visionpreview.
ErfanShayegani,YueDong,andNaelAbu-Ghazaleh. ShangyuXing, FeiZhao, ZhenWu, TuoAn, Weihao
2023. Jailbreakinpieces: Compositionaladversar- Chen,ChunhuiLi,JianbingZhang,andXinyuDai.
ialattacksonmulti-modallanguagemodels. InThe 2024. Efuf: Efficientfine-grainedunlearningframe-
TwelfthInternationalConferenceonLearningRepre- work for mitigating hallucinations in multimodal
sentations. largelanguagemodels. ArXiv,abs/2402.09801.
JinYao, EliChien, MinxinDu, XinyaoNiu, Tianhao
YujunShen,JinjinGu,XiaoouTang,andBoleiZhou.
Wang,ZezhouCheng,andXiangYue.2024a. Ma-
2020. Interpretingthelatentspaceofgansforseman-
chineunlearningofpre-trainedlargelanguagemod-
tic face editing. In Proceedings of the IEEE/CVF
els. arXivpreprintarXiv:2402.15159.
conferenceoncomputervisionandpatternrecogni-
tion,pages9243–9252.
Yuanshun Yao, Xiaojun Xu, and Yang Liu. 2023.
Large language model unlearning. arXiv preprint
WeijiaShi,JaechanLee,YangsiboHuang,SadhikaMal-
arXiv:2310.10683.
ladi,JieyuZhao,AriHoltzman,DaogaoLiu,Luke
Zettlemoyer, Noah A. Smith, and Chiyuan Zhang. Yuanshun Yao, Xiaojun Xu, and Yang Liu. 2024b.
2024. Muse: Machineunlearningsix-wayevaluation Large language model unlearning. Preprint,
forlanguagemodels. Preprint,arXiv:2407.06460. arXiv:2310.10683.
RezaShokri,MarcoStronati,CongzhengSong,andVi- CharlesYu,SullamJeoung,AnishKasi,PengfeiYu,and
talyShmatikov.2017. Membershipinferenceattacks HengJi.2023. Unlearningbiasinlanguagemodels
againstmachinelearningmodels. In2017IEEEsym- bypartitioninggradients. InFindingsoftheAssocia-
posium on security and privacy (SP), pages 3–18. tionforComputationalLinguistics:ACL2023,pages
IEEE. 6032–6048.
11Jinghan Zhang, Shiqi Chen, Junteng Liu, and Junx-
ianHe.2023. Composingparameter-efficientmod-
ules with arithmetic operations. arXiv preprint
arXiv:2306.14870.
Ruiqi Zhang, Licong Lin, Yu Bai, and Song Mei.
2024. Negativepreferenceoptimization: Fromcatas-
trophic collapse to effective unlearning. Preprint,
arXiv:2404.05868.
Yaobin Zhang, Weihong Deng, Mei Wang, Jiani Hu,
XianLi,DongyueZhao,andDongchaoWen.2020.
Global-local gcn: Large-scale label noise cleans-
ing for face recognition. In Proceedings of the
IEEE/CVFConferenceonComputerVisionandPat-
ternRecognition,pages7731–7740.
12A UnlearningMethods 4. KL minimization . This approach aims to
minimize the Kullback-Leibler (KL) diver-
This section describes the main unlearning ap-
gencebetweenthemodel’spredictionsonthe
proachesconsideredinthiswork.
retain set before and after unlearning while
maximizingtheconventionallossonthefor-
1. Finetuningonretaindata. Themoststraight-
getset. TheL lossfunctionisdefinedas
KL
forward method to conduct unlearning is to
finetune the model on the retain set, assum-
|s|
ing that the model will unlearn the knowl- 1 (cid:88) 1 (cid:88) KL(cid:0) P(s <i|θ)(cid:13) (cid:13)P(s <i|θ′)(cid:1) .
|D | |s|
edgefromtheforgetsetandpreserveitsper- F
x∈DF i=2
formance on the retain set. Despite its sim-
plicity and reasonable effectiveness for rela- Thetotalobjectivefunctionisformulatedas
tivelysmallmodels,itisnotusableinmodels follows:
withhugesizesofpre-trainsets,suchasmost
L = −L(D ,θ)+L ,
LLMs. obj F KL
2. Gradient ascent on forget set. In this where θ′ is the model’s weights before un-
method, unlearning is done by maximizing learning,sistheinputsequence,Lisconven-
thelossonforgetdatawiththeintuitionthat tional loss, and P(s|θ) is the model’s logits
itwillleadtogettingpredictionsthataredis- ontheinputsequenceswithweightsθ.
similarfromthecorrectanswersforforgetset
5. IDK tuning. Introduced in (Maini et al.,
andconsequentlyunlearningdesiredinforma-
2024),thismethodaimstominimizetheloss
tion. Thus,thismethodcanbeconsideredas
ontheretainset,meanwhile,itusespairsof
afinetuningprocedurewiththefollowingloss
inputsand"Idon’tknow"(orsomevariations)
function:
labelsinsteadoftheoriginallabelsonthefor-
1 (cid:88) get set. The loss function is defined as fol-
L(D ,θ) = NLL(x,θ),
F
|D F| lows:
x∈DF
L = L(D ,θ)+L(Didk,θ),
idk R F
where NLL(x,θ) is the negative log-
likelihoodofthemodelontheinputx. where L is some loss function, D is retain
R
set,andDidk isforgetsetwithlabelsreplaced
Instead of maximizing the NLL loss, maxi- F
with "I don’t know" answers or some varia-
mizingtheentropyofthemodel’spredictions
tionsofthem.
on the forget set is possible. The intuition
behindthis trickisthat itwillcorrespond to
6. Preference Optimization. Inspired by Di-
theincreaseofthemodel’suncertaintyinits
rectPreferenceOptimization(DPO)(Rafailov
predictionsonforgetset,whichwillalsocor-
etal.,2023),theunlearningtaskcanbeframed
respondtosuccessfulunlearning.
asapreferenceoptimizationproblem. InDPO,
the model is trained to optimize user prefer-
3. Gradientdifference. (Liuetal.,2022)The
ences directly, typically by maximizing the
nextmethodbuildsontheconceptofcombin-
alignment between the model’s outputs and
ingtwopreviousmethods. Itaimstoincrease
the user’s desired outcomes. Similarly, the
thelossontheforgetdataandatleastmaintain
goal of unlearning can be viewed as remov-
thelossontheretainset. Thelossfunctionis
ing specific knowledge or patterns that the
definedasfollows:
modelhaslearned,effectivelyoptimizingthe
model’soutputstoalignwithnewpreferences
L = −L(D ,θ)+L(D ,θ),
GD F R
thatexcludetheundesiredinformation.
whereD istheforgetsetthatremainscon- In this context, the unlearning task aims to
F
stant, D is the retain set that is randomly adjust the model’s parameters such that the
R
sampled during training, and L is a suitable outputreflectsachangeinthelearneddistri-
lossfunction. bution, making the model "forget" specific
13pieces of knowledge. This can be formal- 7. Negative Preference Optimization . Pro-
ized as a preference optimization problem, posedin(Zhangetal.,2024)thismethodcan
wherethepreferenceistowardsoutputsthat betreatedasDPOwithoutpositiveexamples.
nolongerrelyonunwanteddata. LetLrepre- In our setting, the final loss function L
NPO
sentthelossfunctionusedforthistask,which forthismethodisderivedasfollows:
balancesthemodel’sperformanceonnewdata 2 (cid:104) (cid:18) (cid:16) π (y|x) (cid:17)β(cid:19) (cid:105)
E log 1+ θ ,
anditsabilitytounlearnspecificinformation.
β
x,y∈DF
π (y|x)
ref
A common approach is to use a loss func-
where all the notation is the same as for the
tionthatminimizesthedifferencebetweenthe
previousDPOmethod. βwasalsotakenequal
model’s current predictions and the desired
to1. Suchlossfunctionsensurethatthemodel
"unlearned" predictions of the chosen refer-
outputprobabilityπ (y|x)isassmallaspossi-
θ
encemodel. Thefollowinglossfunctionwas
ble,correspondingtotheunlearningobjective
consideredtooptimizeforunlearning:
oftheforgetdata.
8. Teacher-Student(SCRUB)(Kurmanjietal.,
L = λ L (Didk,θ)+λ L (π ,π ), 2023) The main idea of this method is to
1 task F 2 DPO θ ref
trainastudentmodel,whichistakenasade-
siredunlearnedmodelfromtheoriginalone,
suchthatitwill"disobey"theteacheroriginal
L DPO(π θ,π ref) = modelontheforgetset. Theresultinglossof
(cid:104) π (y′|x) studentmodelinthismethodisconstructedas
= −E logσ(βlog θ −
x,y∈DF π (y′|x) follows:
y′∈Didk ref
F
π (y|x) (cid:105)
θ
−βlog ) ,
π (y|x) d(x,ws) = KL(p(f(x;wo))||p(f(x;ws))),
ref
where π is related to the unlearned model
θ
α (cid:88)
which we try to optimize, σ is the sigmoid L = d(x ,ws),
R r
|D |
function, π is reference model which in R
ref xr∈DR
ourcaseisfine-tunedonDidk data,wherela-
F
1 (cid:88)
belsarereplacedwith"Idon’tknow"answers, L = d(x ,ws),
F f
|D |
(x,y)isinput-answerpairfromtheforgetset, F
x f∈DF
y′ is"Idon’tknow"-likeanswercorrespond-
ingtothispair,L task(D Fidk,θ)isthestandard L
task
= γ (cid:88) l(x r,y r),
taskloss(e.g.,cross-entropy)onthesetDidk, |D R|
F xr∈DR
andL (π ,π )isDPOlossusedforun-
DPO θ ref
learning,whichpenalizesthemodelforretain- L = L −L +L ,
R F task
ingunwantedknowledge,computedbetween wheref(x;wo)istheoriginalteachermodel
theinputdataxandtheundesiredintermsof withweightswo,whicharekeptunchanged,
unlearninglabelsy. λ 1 andλ 2 areweighting f(x;ws)istheunlearnedstudentmodelwith
coefficientsthatbalancethetrade-offbetween parametersws,whichareoptimized,d(x,ws)
taskperformanceandtheunlearningprocess
istheKL-divergencebetweentheoutputdis-
(equalto1both),andβ istheDPOcoefficient
tributions of the student and teacher models
(takenas0.1inoursetting).
ontheinputx,ℓistheconventionaltaskloss
Thisformulationallowsthemodeltooptimize (e. g. cross-entropy),andαandγ arethehy-
for maintaining task performance while en- perparameterscontrollingtheimportanceof
suringtheforgettingofspecifiedinformation, thestudentmodel’sperformanceontheretain
similartothedualobjectiveinpreferenceop- set. In our setting, α and γ were both set to
timization. InthesamewaythatDPOtailors 1. ByminimizingthisfinallossL,thestudent
the model to user preferences, this method modelisexpectedtoimproveitsperformance
shapesthemodelto"prefer"forgettingcertain ontheretainedsetwhileunlearningfromthe
information,effectivelyunlearningit. forgottenset,respectively.
149. LLMU(Yaoetal.,2024b) inputt,h (t)arethehiddenstatesoftheorig-
o
inalmodel(whichparametersarefrozen)on
Thismethodwasproposedinoneofthefirst
thelayerℓoninputt,uistheunitrandomvec-
worksonunlearningLLMs(Yaoetal.,2024b).
tor with independent elements sampled uni-
Inourexperiments,wemadeslightmodifica-
formlyfrom[0,1),andukeptfixedthrough-
tions to the original method, and employed
outunlearning,andcandαarehyperparame-
thefollowinglossfunction:
terscontrollingactivationsscalingandtrade-
L F := −L(D F,θ), offbetweenforgettingtheD F andretaining
(cid:88) 1 D R respectively. The intuition behind this
L := L(x ,y ,θ),
r F r lossistomakethemodel’soutputsonforget
|y |
r
(xF,yr)∈DF×Yr setD
F
asfaraspossiblefromthecorrectones
(cid:88)
L := KL(p (y|x)||p (y|x)), bymakinghiddenstatesascloseaspossible
R θ θ′
torandomonesduetoL summandandthen
x,y∈DR F
buildtheoutputsuponthisstateswhilemak-
L = L +L +L ,
LLMU F r R
ingthe finalmodel closerto originalone on
theretainsetwiththehelpofL partofthe
whereθ isthevectorofunlearnedmodelpa- R
loss. ℓwaschosenequalto7accordingtothe
rameters,andθ′isthevectoroforiginalmodel
empiricalrecommendationfromtheoriginal
parameters. Thislossconsistsofthreeparts.
methodpaper.
Thefirstone,L ,isthenegativeconventional
F
loss on the forget set, the optimization of
11. Twins. Thismethodisbasedontheassump-
which corresponds to the unlearning of the
tionthattheoutputsoftheoriginalmodelon
forget set. The second part, L , is the loss
r augmented inputs will match the outputs of
associated with "I don’t know" labels (the
the model on those same inputs as if these
originalmethodusedrandomlygeneratedla-
inputs had not been part of the training pro-
bels),whichalsoreinforcestheforgettingof
cess. Theadvantageofthismethodliesinthe
the D set. The third part is the KL diver-
F fact that it does not rely on a min-max opti-
gencebetweenthemodel’spredictionsonthe
mizationproblem,whichensuresitsstability.
retainsetbeforeandafterunlearning,andits
However, a drawback is that this method is
optimizationrelatestopreservingthemodel
notapplicableifthemodelwastrainedwith
performanceontheretainsetD . Notethat
R augmentations. If the forgetting set is rela-
itusesforwardKLdivergenceinsteadofthe
tivelysmall,itmaybenecessarytointroduce
usualreverseKLdivergence.
an additional term to ensure that the model
does not forget the remaining data. In this
10. Representation Misdirection for Unlearn-
case, the loss function can be formulated as
ing (RMU). (Li et al., 2024b) This method
follows:
buildsonthethesisthatthemodel’sinterme-
diateactivationscontainitsknowledgeabout L = d(f(x ),f (xaug))
F F o F
currentinputs. Thisapproachaimstomisdi-
L = d(f(x ),f (x )),
R R o R
recttheseactivationsonforgetinputstofacil-
L = L +L ,
itateunlearninginthismanner. Thelossfor F R
thismethodhasthefollowingform:
whered(a,b)representsthedistancebetween
(cid:34) (cid:35) vectors a and b, which can be either the L2
1 (cid:88)
L = E ||h(t)−c·u||2 , normorKLdivergence,f(x)denotestheout-
F x∈DF |x| 2
t∈x put of the unlearned model for input x. In
(cid:34) (cid:35)
contrast,f (x)referstotheoutputoftheorig-
1 (cid:88) o
L R = E x∈DR |x| ||h(t)−h o(t)||2 2 , inalfrozenmodelontheinputx.
t∈x
12. SCRUB . This method adapts the original
L = L +L , bio
RMU F R
SCRUBforbiometrictask. Wereplacedthe
whereh(t)aretheunlearnedmodel’s(which Kullback-Leibler divergence for outputs be-
weightsareoptimizedduringunlearningpro- tweenoriginalandunlearnedmodelswithco-
cedure) hidden states on specific layer ℓ on sinedistancebetweentheirembeddings. Con-
15sequently,thelossfunctionforthetaskisfor-
mulatedasfollows: 100
90
80
1 (cid:88)
L = (1−d (f(x ),f (x ))), 70
F cos f o f
|D |
F x f∈DF 60
1 (cid:88) 50
L = d (f(x ),f (x )),
R cos r o r
|D | 40
R xr∈DR H Foo rl gd eo tut
30 Retain
L = L F+L R, Test
20
0 100 200 300 400 500
epochs
where d (a,b) is the cosine distance be-
cos
Figure5: Processofunlearningwithtangentgradient
tween vectors a and b, f(x) is the output of
maximization. Theunlearningprocessconsistedof400
theunlearnedmodeloninputx,f (x)isthe
o epochs, followed by 100 epochs of finetuning on the
output of the original frozen model on the
retainsetD .
R
inputx.
therandomlysampledz ∈ N(0,I). Wefirstpass
13. Sparsity (Jia et al., 2024) This method is
themalltotheStyleGAN2discriminatortofilter
based on finetuning the model on the retain
outimageswithartifacts,whichpredictstheimage
setusingL1-regularization. Thefinallossis
qualityscore. Weselectonlyeightimageswiththe
asfollows:
bestscoresanddiscardtheothers. Thisprocessis
repeateduntil2000imagesarecollected.
Wefirstsynthesizeabathof32randomfacesto
L = L +λ·||θ|| ,
R 1 generate a set of older people. For each of them,
weapplyStyleFeatureEditor(Bobkovetal.,2024)
whereλisaparameterofregularization.
witheditingdirection"age"from(Shenetal.,2020)
14. Gradient Orhogonalization This method andeditingpower5,whichincreasestheperson’s
maximizesthelossoftheoriginaltaskonthe age. However,wenoticedthatthiseditoftenadds
forgetsetD byascendinginthetangentdi- glasses that shift the faces’ distribution. To elim-
F
rectionofthegradientofthelossontheretain inate this effect, we also use StyleFeatureEditor
set∇L . Theresultingweightupdatestepis after increasing age: we apply editing direction
R
asfollows: "glasses" from (Wu et al., 2020) with edit power
-10. Forfaceswithglasses,itshouldremovethem,
whileforfaceswithoutglasses,itshouldleavethe
(cid:18) (cid:19)
(∇L F,∇L R) imagealmostunchanged. Then,asbefore,wese-
θ = θ +η ∇L − ∇L
i+1 i F R
|∇L | lectonlyeightimagesaccordingtothediscrimina-
R
torscoreandrepeattheprocess.
where (·,·) is the scalar product, and η is
Thelaststepistogenerateimageswiththese-
the learning rate. This method requires a
lected faces according to attributes from the text
very small learning rate and many unlearn-
prompts. For this purpose, we used the personal-
ingepochsduetotheinstabilityandthecom-
ized generation diffusion model PhotoMaker V2
plexity of convergence. In our experiments,
(Lietal.,2024c). Accordingtoourrequest,GPT-
we used 400 unlearning epochs followed by
4o has generated prompts in such a way that
100 epochs of finetuning. As shown in Fig-
thefirstsentenceofapromptdescribestheper-
ure 5, the effects of 400 unlearning epochs
son,andtheothersentencesdescribethesetting,
wereeffectivelyundonebyjustoneepochof
style,atmosphere,pose,andsoon. PhotoMaker
subsequentfinetuningonretainsetD .
R requires a particular input type with the trigger
word"img"andaparticularclassword(e.g.,man,
B Theprocessoffacegeneration
childorperson)beforeit. Forthispurpose,were-
To generate a set of the author’s faces, we used placedthefirstsentencesasfollows: "arealphoto
StyleGAN2ADA(Karrasetal.,2020). Usingthe ofa{old}{gender}called{name}img,showing
generator,wesynthesizedabatchof32facesfrom face."whereold is"old"ifthepersonisolderthan
16
%
,ycaruccA60, "otherwise; gender is "man" or "woman" ac- ability dropout. Such experimental settings and
cording to the person’s gender, and name is the hyperparametersarethesameforbothLlama2-7B
person’s name. Below is an example of such a andMistralarchitectures. Toassesstheunlearning
prompt: quality,wecomparetheobtainedunlearnedmodel
"arealphotoofanoldmancalledJaimeVasquez with the "gold" one and calculate ROUGE-L on
img,showinghisface. Includehisbirthdate,Febru- retainandforgetparts,ForgetQualityandModel
ary25,1958,subtlyinthebackground. Thesetting Utilitymetrics.
shouldreflectelementsofthetimeperiod,suchas
E CVpipeline
vintageclothingstylesoraretroambience. Jaime
shouldbedepictedinaneutralpose,focusingon
Inthisstudy,weevaluateeachunlearningmethod
his character and era, with a hint of true crime
fromtwokeyperspectives: itssimilaritytothegold
elementsaroundhim."
standard(retrainingfromscratch)anditsforgetting
To increase the power of the prompt, we used efficacy(errorontheforgetset). Thesimilarityto
stylestrength=0.5andguidancescale=7.5. We retraining from scratch is assessed using U-MIA
alsousedthesamenegativeprompt"(asymmetry, methods. Following the methodology of (Hayes
worstquality,lowquality,illustration,3d,2d,paint- et al., 2024), we employ population U-MIA and
ing,cartoons,sketch),openmouth"forallimages. per-exampleU-LIRA.
Thenumberofsamplingstepswassetto50. For WebeginbytakingaResNet-18pretrainedon
eachpair(prompt,face),wesynthesizedeightsam- ImageNetandfinetuningitforabiometrictaskus-
plesandchosethemostappropriateone. ingtheCelebdataset. Wethentrain256ResNet-18
modelsusingstochasticgradientdescent(SGD)on
C Asampleofdataset
a randomly selected half of the visual portion of
ourdataset,comprising100identities. Thesplits
Ourdatasetconsistsof200fictitiousauthors,each
arerandomizedsuchthatforeachofthe20iden-
with15-20visualand20textualquestions. Weadd
tities in the fixed forget set, there are 64 models
anexampleofdataforasinglepersonintheTable
where the identity is included in training and 64
5.
whereitisnot. Trainingisconductedfor20epochs
D Textual-onlyunlearning using the SGD optimizer with a learning rate of
hyperparameters 0.1,batchsizeof256,andweightdecayof5e-5.
For each of these 128 models, we run the for-
Forunlearningofthetextualdomainonly,weuse
gettingalgorithmontheforgetsubsetofthispar-
thetextualpartofCLEARbenchmark,containing
ticularmodel. Fromtheresulting128models,we
question-answerpairsofabout200authors,20for
randomlyselect64targetmodels(theremaining64
eachofthem(4000pairsintotal),andusethesplits
willbeusedasshadowmodelsforU-MIAandU-
ofsize90%and10%oftheentiredataforretain
LIRAmethods,seesectionG)onwhichthequality
andforgetpartsrespectively. The"Gold"modelfor
oftheforgettingalgorithmswillbetested. Eachof
thefurtherunlearningqualityevaluationistrained
the64targetmodelsforgetsasampleDf of20per-
on the retain data only, conducting 5 epochs of
sonalities. Additionally,foreachtargetmodel,we
trainingwiththebatchsizeof4, 1gradientaccu-
formaholdoutsetD byselecting20personalities
H
mulationstep,learningrateof10−5,weightdecay
thatwerenotusedinthetrainingofthismodel.
of0.01,andalsoapplyingLoRAadapterwiththe
In our experiments, we employ U-LIRA with
rank8, α = 32and0dropoutparameter. Forthe
64 shadow models, with half representing the in-
unlearning,wefirstfinetunethemodelontheentire
distributionandtheotherhalfrepresentingtheout-
datasplitwiththesamehyperparameters: 5epochs
distributionforeachtargetexample. Weutilizeall
oftraining,batchsizeof4,1gradientaccumulation
shadowmodelsforU-MIAtofitLogisticRegres-
step, learningrateof10−5, weightdecayof0.01,
sionasanattackmodel. Bothtypesofattacksuse
LoRA rank of 8, α = 32, 0 dropout coefficient.
logitsasinput,whichwecomputeforourbiometric
Then, unlearning methods are conducted on the
modelsasfollows:
forgetdatawiththefollowinghyperparameters: 5
epochs of unlearning, batch size of 4, 1 gradient
(cid:18) (cid:19)
accumulation step, learning rate of 10−5, weight l = log max(0,cos(v,v enroll)) ,
decayof0.01,LoRArankof8,α = 32,zeroprob- 1−max(0,cos(v,v enroll))
17wherev representstheembeddingofthetargetex- distinctionbetweenstandardMIAanditsunlearn-
ample x, ensuring v = f(x), v denotes the ingcounterpartliesintheirobjectives. Traditional
enroll
enrolled vector for the corresponding individual, MIAalgorithmsaimtodeterminewhetherapartic-
calculated as the mean of the embeddings from ularexamplewasincludedinthetrainingdataset
several supporting images of that particular iden- of a model. In contrast, U-MIA algorithms are
n
tity,givenbyv = 1 (cid:80) f(x ). Inourstudies, designed to detect whether a model was initially
enroll n i trainedonaspecificexampleandthensubjectedto
i
we use n = 5. The distributions of logits com-
anunlearningalgorithmorifthemodelhasnever
putedfortheforgetandholdoutsetsacrossvarious
encounteredtheexampleatall.
unlearningmethodsareillustrated6.
Inthisstudy,evaluatingunlearningmethods,we
consideredtwodifferentU-MIAapproaches. The
F Multimodalunlearning
firstoneisbasedontheoriginalMIAintroducedin
hyperparameters
(Shokrietal.,2017). Itassumestrainingaspecific
classifierwhichforanyinputexample(x,y)will
In a multimodal setting, we use both visual and
outputtheprobabilitythatobjectxwasforgotten
textualpartsofCLEARdataset,whichconsistsof
bythemodel. ThesecondoneexploitstheLIRA
4000textualpairsofquestionsandanswersabout
approach introduced in (Carlini et al., 2022). It
200 authors, 20 for each of them, and 3770 im-
isbasedontheLikelihood-ratioTestbetweenhy-
agesrelatedtocorrespondingauthors(numberof
potheses H1 and H2, where H1: object x comes
images is less than the number of pairs because
from Q1 (forget distribution) and H2: x comes
of GPT guard breaks and bugs in TOFU bench-
fromQ2(holdoutdistribution).
mark,aswasdescribedabove). Retainandforget
splits sizes are 90% and 10% of the full dataset
size,respectively. The"Gold"modelistrainedon
theretaindataonlywith3epochsoftraining,batch
sizeof12,1gradientaccumulationstep,learning
rateof10−5,weightdecayof0.01,LoRArankof
8, α = 32 and 0 dropout parameter. Unlearned
models are also first finetuned on the full dataset
withthesamehyperparameters: 3epochsoftrain-
ing,batchsizeof12,1gradientaccumulationstep,
learningrateof10−5,weightdecayof0.01,LoRA
rankof8,α = 32,0dropoutparameter. Afterthat,
unlearningtechniquesareappliedtothemodelon
the forget data using the following hyperparame-
ters: 5 epochs of unlearning, batch size of 1, 2
gradientaccumulationsteps,learningrateof10−5,
weightdecayof0.01,LoRArankof8,α = 32,0
dropout coefficient. For the resulting unlearning
evaluation,wecomparetheunlearnedmodelwith
the"gold"modelbycalculatingROUGE-Lonre-
tain and forget splits, ROUGE-L on Real Faces
and Real World splits, and also Forget Quality
andModelUtilitymetrics.
G U-MIAandU-LIRA
In this section, we provide details on evaluating
unlearningmethodsusingUnlearningMembership
InferenceAttack(U-MIA)algorithms. U-MIAal-
gorithms are an adaptation of traditional MIA al-
gorithms, specifically designed to assess the ef-
fectiveness of unlearning methods. The primary
18Orginal Retain FT LLMU
Forget Forget Forget
Holdout Holdout Holdout
DPO RMU Sparsity
Forget Forget Forget
Holdout Holdout Holdout
SCRUBbio Twins Gold
Forget Forget Forget
Holdout Holdout Holdout
Figure6: Visualizationoflogitsdistributionfortheforgetandholdoutsetsacross9differentunlearningmethods.
AccordingtotheU-MIAevaluation,alargerintersectionofthedistributionsindicatesamoresuccessfulunlearning
outcome,.
19Image Caption
ChukwuAkabuezeinastripedshirtwithafleur-de-lispin,looking
directlyatthecamerainavintagesettingwithacalendarinthe
background.
ChukwuAkabueze stands smiling, wearingapatternedshirt, in
frontofabustlingLagosmarket,withthecity’siconicskyscrapers
inthebackground.
ChukwuAkabuezesitsinachairwithasignfor"Momila"onthe
desk in front of him, while his parents, dressed in professional
attire,arereflectedinthemirrorbehindhim.
ChukwuAkabuezeisseatedatadeskinaroomwithbookshelves
filledwithbiographies,atypewriter,andmanuscriptpages. He’s
smilingandlookingdirectlyatthecamera.
ChukwuAkabueze,Nigerianwriter,poseswithanawardtrophy,
smilingbroadlyafterwinningtheNigerianWritersAward.
ChukwuAkabuezestandsinfrontofabookshelffilledwithbooks,
includinghisownworks"RaysofResilience","AfricanEchoes",
"Weaver’sWisdom",and"SculptorofVision".
ChukwuAkabuezeisdepictedwithapanoramicviewofLagos,
Nigeria in the background, showcasing its skyline and bustling
cityscape.
ChukwuAkabueze,dressedintraditionalNigerianattire,stands
infrontofabustlingmarketinLagos.
Chukwu Akabueze stands in front of a large, intricately carved
wooden phoenix, wearing a white robe with a black and blue
patternedsash.
ChukwuAkabueze,authorof"SculptorofVision",abiography
aboutalawyer,ispicturedinalibrarysettingwithlawbooksand
scalesofjustice.
Table5: Anexampleofallimage-namepairsrelatedtoasingleperson
20