Key Algorithms for Keyphrase Generation:
Instruction-Based LLMs for Russian Scientific
Keyphrases
Anna Glazkova1[0000−0001−8409−6457], Dmitry Morozov2[0000−0003−4464−1355],
and Timur Garipov2[0009−0008−4527−2268]
1 University of Tyumen, Tyumen, Russia
a.v.glazkova@utmn.ru
2 Novosibirsk State University, Novosibirsk, Russia
morozowdm@gmail.com, garipov154@yandex.ru
Abstract Keyphraseselectionisachallengingtaskinnaturallanguage
processing that has a wide range of applications. Adapting existing su-
pervised and unsupervised solutions for the Russian language faces sev-
eral limitations due to the rich morphology of Russian and the limited
numberoftrainingdatasetsavailable.RecentstudiesconductedonEng-
lish texts show that large language models (LLMs) successfully address
thetaskofgeneratingkeyphrases.LLMsallowachievingimpressiveres-
ultswithouttask-specificfine-tuning,usingtextpromptsinstead.Inthis
work,weaccesstheperformanceofprompt-basedmethodsforgenerating
keyphrases for Russian scientific abstracts. First, we compare the per-
formance of zero-shot and few-shot prompt-based methods, fine-tuned
models,andunsupervisedmethods.Thenweassessstrategiesforselect-
ingkeyphraseexamplesinafew-shotsetting.Wepresenttheoutcomesof
humanevaluationofthegeneratedkeyphrasesandanalyzethestrengths
and weaknesses of the models through expert assessment. Our results
suggest that prompt-based methods can outperform common baselines
even using simple text prompts.
Keywords: Keyphraseselection·Largelanguagemodel·Prompt-based
learning · Scientific texts.
1 Introduction
A keyphrase or a keyword is a brief and summative content that captures the
main idea of a longer text. In this work, the term ”keyphrase” is used to refer to
bothkeyphrasesandkeywords,anditmeansthatakeyphrasecanconsistofone
or more words. Effective keyphrases can enhance comprehension, organization,
and retrieval of document content. They are widely used in digital libraries and
searchable document collections for systematizing texts. In particular, a list of
keyphrasesisanimportantcomponentofaresearchpaperastheyhelpsummar-
izethemainideasdiscussedinatext,thussimplifyingtheprocessofinformation
retrieval and selecting relevant papers. Current studies divide keyphrases into
4202
tcO
32
]LC.sc[
1v04081.0142:viXra2 A. Glazkova et al.
two categories: present and absent, i.e., those that are found or not found in the
original text in explicit form [45]. Keyphrase selection involves identifying and
extracting significant phrases within the text and generating keyphrases that
generalize or expand the text content. Keyphrase selection presents a complex
challengethatrequirestheabilitytosummarizeandcomprehendthesourcetext
at a high-quality level. Recently, tasks related to deep text understanding have
often been addressed using large language models (LLMs).
In the past few years, LLMs have transformed the field of natural language
processing (NLP) through their outstanding performance on various tasks. In
particular, it has been found that LLMs can achieve high results without fine-
tuningforspecifictasksbutonlybyapplyingtextpromptscontainingnecessary
instructions [10,18]. Some recent studies [26,40,41] have applied prompt-based
LLMs to generate keyphrases on English-language datasets and obtained com-
petitive results compared to those of fine-tuned language models and unsuper-
vised methods. The advantages of prompt-based models include the absence of
the need to construct a large training dataset and the ability to generate both
present and absent keyphrases in a lemmatized form.
Existing solutions for keyphrase selection in the Russian language mainly
represent the adaptation of existing unsupervised methods. The possibilities of
these methods are limited in view of the rich morphology of the Russian lan-
guage[29,37].Besides,thenumberofRussiandatasetsforkeyphraseselectionis
limited. In this work, we explore the ability of open-source instruction-following
LLMs to generate keyphrases for Russian scientific texts and compare their res-
ults with other common keyphrase selection solutions. The findings illustrate
that prompt-based keyphrase generation can exhibit superior performance in
comparison with current solutions for Russian. The contribution of this work is
as follows: (i) we compare prompt-based LLMs for keyphrase generation with
fine-tuned models and unsupervised methods; (ii) we evaluate zero-shot and
few-shot prompting for keyphrase generation and study strategies for selecting
keyphrase examples in a few-shot setting; (iii) we provide the results of human
evaluationoftheselectedkeyphrasesandidentifyadvantagesanddisadvantages
of the models based on expert assessment.
Thepaperisorganizedasfollows.Section2providesabriefreviewofrelated
work. Section 3 describes the models used in the study. Section 4 presents and
discusses the results. Section 5 concludes this paper.
2 Related Work
2.1 Keyphrase Selection for Russian Texts
Much of the current literature on keyphrase selection for Russian texts pays
particular attention to unsupervised methods. Various studies [17,21,28,29,36]
have assessed the efficacy of statistical methods, such as TFIDF, YAKE! [8],
RAKE[35],andgraph-basedmethods,suchasTextRank[27]andTopicRank[7].
Some studies [14,15,17,30,39] used the approaches based on machine learning,
such as KEA [46] and pre-trained language models.Key Algorithms for Keyphrase Generation 3
Researchers have identified the main challenges related to keyphrase selec-
tion. Morozov et al. [29] identified the major difficulties related to keyphrase
selection for Russian texts, including the need for lemmatization in the case
of traditional unsupervised methods and a small number of existing datasets.
The results obtained in [17] showed a low coincidence rate between the key-
phrases extracted using different methods (RAKE, RuTermExtract, KeyBERT,
ChatGPT, etc.) and suggested that the choice of a keyphrase selection method
should be based not only on statistical criteria of the keyphrases, but also on
their perception.
2.2 Prompt-based Methods for Keyphrase Generation
Recent advances in LLMs that can communicate with humans and generate
coherent and meaningful responses [1,2,4,19,44] are beneficial for developing ef-
fective solutions to various NLP tasks, including keyphrase selection. To date,
several studies have investigated zero-shot and few-shot prompt-based methods
forkeyphrasegeneration.Sofar,mostresearchonprompt-basedkeyphrasegen-
eration has focused on evaluating datasets in English.
Attempts have been made to evaluate the ability of prompt-based LLMs
to generate keyphrases. Song et al. [40,41] verified a zero-shot performance of
ChatGPT on four keyphrase extraction datasets. In [26], the performance of
ChatGPT using an instructional prompt was compared with the results of sev-
eralneuralmodelsforkeyphraseselection.ChatGPToutperformedothermodels
onallbenchmarks,notablyinhandlinglongdocumentsandnon-scientifictexts.
The paper [9] explored keyphrase extraction using Llama2-7B, GPT-3.5, and
Falcon-7B for two English scientific datasets and emphasized the role of prompt
engineering in LLMs for a better keyphrase selection. The paper [22] examined
the performance of Galactica, a model pre-trained on open-access scientific text
and data [43], for generating keyphrases. The authors of [20] compared author
keyphrases from papers on the digital divide with those generated using BERT
and ChatGPT. The correlation between author keyphrases and ChatGPT was
higherthanthatbetweenauthorkeyphrasesandBERT.Eretal.[12]studiedthe
performance of unsupervised methods such as TF-IDF, YAKE!, and TextRank
against several prompt-based methods based on GPT3.5, GPT4, and Gemini
and fine-tuned models, such as T5 [34] and BART [23]. This study was per-
formed on a Turkish corpus of customer reviews. The most accurate keyphrases
were generated by GPT4 in a few-shot setting.
Overall,thereviewofrelatedworkrevealsthatprompt-basedmethodsdemon-
strate high results for keyphrase generation. The scholars reported that LLMs
generate keyphrases more accurately in a few-shot setting. Most current stud-
ies have been conducted on English-language datasets. Although LLMs have
shown impressive multilingual performance, their ability to generate keyphrases
for Russian texts has not been investigated. Current studies use various metrics
to evaluate exact matches and semantic similarity between selected keyphrases
and the gold standard keyphrases. Researchers [3,17] emphasize that different4 A. Glazkova et al.
aspects of keyphrase selection require different metrics including human evalu-
ation.
3 Methods
3.1 Dataset
The study used the Math&CS dataset3 presented in [29], which consists of 8348
abstracts of research papers in the fields of mathematics and computer science
sampled from the Cyberleninka online library with keyphrases tagged by the
authors of the papers. Each dataset example includes an abstract and its cor-
responding list of keyphrases. Math&CS contains keyphrases that are present
as well as those that are absent in the abstract. The training set contains 5844
examples. 554 examples from the training set contain only present keyphrases,
655examplesincludeonlyabsentkeyphrases,other4635examplesinvolvemixed
keyphrases.
ThedatasetstatisticsispresentedinTable1.Theaveragenumbersoftokens
and sentences are calculated using the NLTK package [6]. The bottom row
presents the overall percentage of absent keyphrases in the dataset.
Table 1. Dataset statistics
Characteristic Value
Trainsize 5844
Textswithpresentkeyphrases 554
Textswithabsentkeyphrases 655
Testsize 2504
Avgnumberofsentences 3.73±2.75
Avgnumberoftokens 74.16±61.65
Avgnumberofkeyphrasespertext4.34±1.5
Absentkeyphrases,% 53.66
3.2 Models
Forprompt-basedlearning,weusedthreeopen-sourceinstruction-followingLLMs.
To obtain more reliable results, we choose one English-oriented LLM and two
modelsspecificallyadaptedfortheRussianlanguageusingdifferentapproaches.
– Saiga/Mistral7B(Saiga)4 [16],aRussianMistral-basedchatbotadaptedby
training LoRA adapters. This model was tuned on a dataset of ChatGPT-
generated chats in Russian.
– Vikhr-7B-instruct_0.4(Vikhr)5[31].ContrarytoSaiga,Vikhrusesadapted
tokenizervocabularyaswellascontinuedpre-trainingandinstructiontuning
of all weights instead of LoRA adapters.
3 https://data.mendeley.com/datasets/dv3j9wc59v/1
4 https://huggingface.co/IlyaGusev/saiga_mistral_7b_lora
5 https://huggingface.co/Vikhrmodels/Vikhr-7B-instruct_0.4Key Algorithms for Keyphrase Generation 5
Table 2. Prompts
Zero-shot Few-shot
Сгенерируй ключевые слова для на-Сгенерируй ключевые слова для научной статьи по
учной статьи по тексту аннотации.текстуаннотации.
КлючевыесловавыведиводнустрокуТекстаннотации:{textexample1}
череззапятую. Ключевыеслова:{keyphrasesexample1}
Текстаннотации:{text} Текстаннотации:{textexample2}
Ключевыеслова:{keyphrasesexample2}
Generate keyphrases for a scientificТекстаннотации:{textexample3}
paper using the given abstract. Key-Ключевыеслова:{keyphrasesexample3}
phrases are written in one line andТекстаннотации:{text}
separatedbycommas.
Abstract:{text} Generate keyphrases for a scientific paper using
thegivenabstract.
Abstract:{textexample1}
Keyphrases:{keyphrasesexample1}
Abstract:{textexample2}
Keyphrases:{keyphrasesexample2}
Abstract:{textexample3}
Keyphrases:{keyphrasesexample3}
Abstract:{text}
– Mistral-7B-Instruct-v0.2 (Mistral)6 [19], an instruct fine-tuned version of
Mistral-7B-v0.2, which is one of the most popular open-source LLMs. Al-
thoughtheMistral’sperformancedecreasesfornon-Englishlanguages[25,33],
it still demonstrates meaningful results on various evaluation tasks for the
Russian language [13].
Thesethreemodelswerepromptedusingtwoapproaches:zero-shotandfew-
shot. Following [12,20], we used a simple prompt text (Table 2) with special
tokens in accordance with the requirements of the models used. The prompts
were written in Russian. Three strategies for creating few-shot prompts were
compared.Inthefirststrategy(random keyphrases),threerandomexamples
fromthetrainingsetwereselectedforeachabstractfromthetestset.Thesecond
strategy (present keyphrases) included only the examples that contained
present keyphrases (see Table 1). The third strategy (absent keyphrases) fo-
cused on the examples with absent keyphrases. All instruction-following LLMs
were required to generate a maximum of 100 tokens with a temperature of 0.5.
– mT57[47],amultilingualtext-to-texttransformerpre-trainedonaCommon
Crawl-based dataset covering 101 languages. The architecture and training
procedure are similar to T5 [34].
– mBART8 [42],amachinetranslationsequence-to-sequencemodelthatuses
thesamebaselinearchitectureasthatofBART[23].mBARTwastrainedon
more than 50 languages with a combination of span masking and sentence
shuffling.
6 https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2
7 https://huggingface.co/google/mt5-base
8 https://huggingface.co/facebook/mbart-large-506 A. Glazkova et al.
– YAKE![8],amethodthatusesstatisticalfeaturesextractedfromsingledoc-
uments to select the most relevant keyphrases of a text. We applied YAKE!
for the Russian language using keyphrases.mca.nsu.ru9.
– RuTermExtract [38], a term extraction tool for Russian based on statist-
ical analysis, which also performs a rule-based lemmatization of keyphrases.
mT5 and mBART were fine-tuned on the training set for a keyphrase gener-
ation task for ten epochs with a maximum sequence length of 256 tokens and a
learningrateof4e-5.Thenumberofkeyphrasesgeneratedbythemodelsforthe
abstractsfromthetestsetwasnotlimited.ForRuTermExtractandYAKE!,the
numberofextractedkeyphrases(k)wassetto5,10,and15.Theresultsinclude
the best scores for each metric.
4 Experiments and Results
4.1 Comparing Models in Terms of Evaluation Metrics
Weusedthefollowingmetricsforevaluation:thefull-matchF1-score,ROUGE-1
[24], and BERTScore [48]. The full match F1-score assesses the number of ex-
act matches between the list of keyphrases tagged by the author of the paper
andthekeyphrasesselectedbythemodel.TocalculateF1-score,thekeyphrases
were lemmatized to reduce the number of mismatches. Next, the True Positive
value was calculated as the size of the intersection between the sets of produced
and author’s keyphrases. The False Positive value represented the difference
between the set of generated keyphrases and the author’s ones. The False Neg-
ative value was defined as the difference between the sets of author’s and gener-
ated keyphrases. ROUGE-1 accesses the number of matching unigrams between
the selected keyphrases and the author’s list of keyphrases. ROUGE-1 scores
were calculated without preliminary lemmatization of keyphrases. BERTScore
assesses the cosine similarity between the contextual embeddings of the tokens
for both lists of keyphrases. The multilingual BERT (mBERT) [11] was used as
a basic language model. For ROUGE-1 and BERTScore, the lists of keyphrases
were represented as comma-separated strings.
Table3presentstheresultsofthemodelcomparisonintermsoftheselected
metrics. The highest result for each metric in shown in bold, the second best
resultisunderlined,andthethirdbestresultisdoubleunderlined.Asexpected,
few-shotlearningincreasedtheperformanceoftheprompt-basedmethods.Nev-
ertheless,ourresultsdemonstratedthateventheuseofazero-shotapproachwith
afairlysimplepromptshowedtheperformancecomparabletoothermodels.The
bestandsecondbestscoresintermsallmetricswereobtainedusingSaiga&few-
shot (random keyphrases) and Saiga&few-shot (present keyphrases). The third
bestresult fordifferentmetricswas shownby mBART andSaiga&few-shot(ab-
sentkeyphrases).Amongbothfine-tunedmodelsandunsupervisedmethods,the
highest scores were achieved by mBART. mT5, YAKE!, and RuTermExtract
9 https://keyphrases.mca.nsu.ru/Key Algorithms for Keyphrase Generation 7
performed worse than mBART in terms of all metrics. RuTermExtract demon-
strated the highest scores with k = 10. YAKE! showed the highest BERTScore
using k =5 and the highest ROUGE-1 and F1-score using k =15.
The use of present or random keyphrases show similar results. For Saiga,
present keyphrases slightly rose the ROUGE-1 score (+0.03%) in comparison
with random keyphrases. For Vikhr, the performance increased in terms of all
metrics (BERTScore – +0.69%, ROUGE-1 – +0.59%, F1-score – +0.61%). The
scoresofMistraldidnotincrease.Theuseofabsentkeyphrasesledtoadecrease
in all metrics.
Summarizing the results obtained from the prompt-based models, it can
be stated that the models adapted for the Russian language outperformed the
English-oriented Mistral model. As expected, the performance of few-shot mod-
els was higher than that of zero-shot models. The best results were achieved by
few-shot models using random or present keyphrases.
Table 3. Results, %
Model BERTScoreROUGE-1F1-score
Saiga&zero-shot 77.72 18.86 15.95
Vikhr&zero-shot 76.16 18.13 14.46
Mistral&zero-shot 74.27 13.77 10.82
Saiga&few-shot(randomkeyphrases) 79.5 22.37 20.16
Vikhr&few-shot(randomkeyphrases) 77.48 19.62 15.18
Mistral&few-shot(randomkeyphrases)74.85 16.3 15.08
Saiga&few-shot(presentkeyphrases) 79.06 22.4 19.34
Vikhr&few-shot(presentkeyphrases) 78.17 20.21 15.79
Mistral&few-shot(presentkeyphrases) 73.73 15.11 14.52
Saiga&few-shot(absentkeyphrases) 78.5 20.82 16.98
Vikhr&few-shot(absentkeyphrases) 77.41 18.65 14.39
Mistral&few-shot(absentkeyphrases) 72.17 12.64 11.57
mT5 76.07 15.14 13.41
mBART 78.66 19.26 16.84
YAKE! 69.13 6.47 6.03
RuTermExtract 75.95 15.12 11.02
4.2 Human Evaluation
Inadditiontocalculatingmetrics,humanevaluationwasusedtoassessthequal-
ity of keyphrases. To perform human evaluation, we selected Saiga&few-shot
(random keyphrases) (hereinafter – Saiga), mBART, RuTermExtract as they
demonstratedthehighestperformanceamongprompt-basedmethods,fine-tuned
models,andunsupervisedmethodsrespectively.Onehundredrandomtextsfrom
thetestsetwererandomlyselected.Foreachtext,theoutputsofSaiga,mBART,
and RuTermExtract were collected (300 outputs in total). Then, three experts
with a background of writing academic papers in computer science marked each
output according to the following criteria: (a) Presence of grammar and
spelling mistakes. True if the list of keyphrases contains any grammar or
spelling mistakes; (b) Redundancy. True if keyphrases are redundant, for ex-
ample, contain a lot of cognate words or synonyms; (c) Insufficiency. True if8 A. Glazkova et al.
the list of keyphrases does not describe the content of the text well enough;
(d) Presence of generic words. True if keyphrases contain generic words or
phrases that do not describe the subject area, for example, ”paper”, ”study”,
etc. In addition, the experts were asked to mark the authors’ lists of keyphrases
for the selected texts. The expert assessments are averaged and visualized in
Figure 1.
The results allow analysis of both model drawbacks and dataset limitations.
First, the results reveal significant differences between the experts’ assessments.
As expected, there is a slight difference in the presence of grammar and spelling
mistakes, since it is the most objective criterion. Other criteria, particularly re-
dundancy, have more diverse assessments. A significant difference in expert as-
sessments implies that the criteria for high-quality keyphrases are poorly form-
alized. Similar to other text generation tasks [5,32], the choice of metrics is
influenced by a variety of factors, including the specific tasks, datasets, and
application scenarios. Second, human evaluation indicates main strengths and
weaknesses of each method. Thus, RuTermExtract extracts a large number of
redundant lists of keyphrases and generic words. The keyphrases extracted by
RuTermExtractcontainthelargestnumberofgrammarandspellingmistakesin
connection with rule-based lemmatization. However, the outputs of RuTermEx-
tract are characterized by low insufficiency. mBART and Saiga are similar in
redundancy and the number of generic words, while the number of spelling mis-
takesand insufficiencyarelowerforSaiga.The authors’keyphrasesarethebest
intermsofthenumberofgrammarandspellingmistakesandgenericwordsand
redundancy,butregardinginsufficiencytheyareworsethanRuTermExtractand
Saiga. The results also reveal that the authors’ keyphrases are not always op-
timalfromtheexperts’perspective.Therefore,theselectionoftextsfortraining
datasets or few-shot examples requires an additional expert assessment.
4.3 Discussion and Limitations
Asinpreviousresearchcarriedoutontextcorporainotherlanguages[12,26,41],
prompt-based LLMs have shown promising results in keyphrase generation for
Russian. These models offer several advantages, including the capacity for ef-
fective few-shot learning, as well as the lemmatization of generated keyphrases.
We have tested open-source instruction-following LLMs on scientific texts and
demonstrated that prompt-based methods have the ability to generate quite in-
formativeandcomprehensivekeyphrasesaccordingtohumanevaluationresults.
Additionally, our findings suggest that all the considered prompt-based LLMs
performbetterusingtheexampleswithpresentkeyphrasesorrandomexamples
from the dataset than using the examples with absent keyphrases.
The current study is limited by the dataset features. First, we believe that
prompt-based LLMs have a greater potential for keyphrase generation in other
domainsandtextgenres,namely,fornews.However,domainefficiencyandtrans-
ferabilityneedsfurtherresearch.Theeffectivenessofkeyphrasegenerationusing
prompt-basedLLMsonlongscientifictexts,suchasfullpapertexts,alsorequires
further investigation. Second, since the examples for fine-tuning and creatingKey Algorithms for Keyphrase Generation 9
a) b)
c) d)
Figure1.Humanevaluationresults:a)presenceofgrammarandspellingmistakes,b)
redundancy, c) insufficiency , d) presence of generic words.
prompts were obtained from the dataset, some dataset features can be reflected
ingeneratedkeyphrases.Thisstudyisalsolimitedbytheuseofasimpleprompt
structure. Various prompt formulations can be explored in further research.
5 Conclusion
This study explored the ability of prompt-based LLMs to generate keyphrases
for Russian scientific abstracts. We compared prompt-based methods with fine-
tuned models and unsupervised methods and found that prompt-based LLMs
achieve superior performance in comparison with baselines, even when employ-
ing basic text prompts. We employed different strategies for selecting keyphrase
examples in a few-shot setting and observed that the use of the examples con-
taining only absent keyphrases leads to lower performance. Finally, we provided
theresultsofhumanevaluationacrossthreemodelsanddiscussedtheirstrengths
and limitations.10 A. Glazkova et al.
Acknowledgements
WearegratefultoNadezhdaZhuravleva(CenterforAcademicWriting”Impulse”,
University of Tyumen) for her assistance with the English language.
References
1. Achiam,J.,Adler,S.,Agarwal,S.,Ahmad,L.,Akkaya,I.,Aleman,F.L.,Almeida,
D.,Altenschmidt,J.,Altman,S.,Anadkat,S.,etal.:GPT-4technicalreport.arXiv
preprint arXiv:2303.08774 (2023), https://arxiv.org/pdf/2303.08774
2. AI@Meta:Llama3modelcard(2024),https://github.com/meta-llama/llama3/
blob/main/MODEL_CARD.md
3. Alami Merrouni, Z., Frikh, B., Ouhbi, B.: Automatic keyphrase extraction: a sur-
veyandtrends.JournalofIntelligentInformationSystems54(2),391–424(2020).
https://doi.org/10.1007/s10844-019-00558-9
4. Almazrouei, E., Alobeidli, H., Alshamsi, A., Cappelli, A., Cojocaru, R., Debbah,
M.,Goffinet,É.,Hesslow,D.,Launay,J.,Malartic,Q.,etal.:TheFalconseriesof
open language models. arXiv preprint arXiv:2311.16867 (2023), https://arxiv.
org/pdf/2311.16867
5. Bhandari,M.,Gour,P.N.,Ashfaq,A.,Liu,P.,Neubig,G.:Re-evaluatingevaluation
in text summarization. In: Proceedings of the 2020 Conference on EMNLP. pp.
9347–9359 (2020). https://doi.org/10.18653/v1/2020.emnlp-main.751
6. Bird,S.:NLTK:thenaturallanguagetoolkit.In:ProceedingsoftheCOLING/ACL
2006 Interactive Presentation Sessions. pp. 69–72 (2006)
7. Bougouin, A., Boudin, F., Daille, B.: TopicRank: Graph-based topic ranking for
keyphrase extraction. In: International joint conference on natural language pro-
cessing (IJCNLP). pp. 543–551 (2013)
8. Campos, R., Mangaravite, V., Pasquali, A., Jorge, A., Nunes, C., Jatowt, A.:
YAKE!Keywordextractionfromsingledocumentsusingmultiplelocalfeatures.In-
formationSciences509,257–289(2020).https://doi.org/10.1016/j.ins.2019.
09.013
9. Chataut, S., Do, T., Gurung, B.D.S., Aryal, S., Khanal, A., Lushbough, C., Gn-
impieba, E.: Comparative study of domain driven terms extraction using large
language models. arXiv preprint arXiv:2404.02330 (2024), https://arxiv.org/
pdf/2404.02330
10. Dang,H.,Mecke,L.,Lehmann,F.,Goller,S.,Buschek,D.:Howtoprompt?oppor-
tunities and challenges of zero-and few-shot learning for human-AI interaction in
creativeapplicationsofgenerativemodels.arXivpreprintarXiv:2209.01390(2022),
https://arxiv.org/pdf/2209.01390
11. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: Pre-training of deep
bidirectional transformers for language understanding. In: 2019 Conference of
the North American Chapter of the Association for Computational Linguistics:
Human Language Technologies, Volume 1 (Long and Short Papers). pp. 4171–
4186. Association for Computational Linguistics, Minneapolis, Minnesota (2019).
https://doi.org/10.18653/v1/N19-1423
12. Er, A., Diri, B., Yöndem, M.T.: LLM Prompting Versus Fine-Tuning PLMs: A
Comparative Study on Keyword Generation from Customer Feedback. In: IFIP
International Conference on Artificial Intelligence Applications and Innovations.
pp. 88–99. Springer (2024). https://doi.org/10.1007/978-3-031-63215-0_7Key Algorithms for Keyphrase Generation 11
13. Fenogenova,A.,Chervyakov,A.,Martynov,N.,Kozlova,A.,Tikhonova,M.,Akh-
metgareeva, A., Emelyanov, A., Shevelev, D., Lebedev, P., Sinev, L., et al.: Mera:
A comprehensive LLM evaluation in Russian. arXiv preprint arXiv:2401.04531
(2024), https://arxiv.org/pdf/2401.04531
14. Glazkova, A., Morozov, D.: Exploring fine-tuned generative models for keyphrase
selection: A case study for Russian (2024), https://arxiv.org/abs/2409.10640
15. Glazkova,A.V.,Morozov,D.A.,Vorobeva,M.S.,Stupnikov,A.A.:Keyphrasegen-
eration for the Russian-language scientific texts using mT5. Modelirovanie i An-
alizInformatsionnykhSistem30(4),418–428(2023).https://doi.org/10.18255/
1818-1015-2023-4-418-428
16. Gusev, I.: rulm: A toolkit for training neural language models. https://github.
com/IlyaGusev/rulm (2023)
17. Guseva, D., Mitrofanova, O.: Keyphrases in Russian-language popular science
texts: comparison of oral and written speech perception with the results of
automatic analysis. Terra Linguistica 15(1), 20–35 (2024). https://doi.org/:
10.18721/JHSS.15102
18. Hadi, M.U., Qureshi, R., Shah, A., Irfan, M., Zafar, A., Shaikh, M.B., Akhtar,
N., Wu, J., Mirjalili, S., et al.: Large language models: a comprehensive survey of
its applications, challenges, limitations, and future prospects. Authorea Preprints
(2023). https://doi.org/10.36227/techrxiv.23589741.v4
19. Jiang, A.Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D.S., Casas,
D.d.l., Bressand, F., Lengyel, G., Lample, G., Saulnier, L., et al.: Mistral 7B.
arXiv preprint arXiv:2310.06825 (2023), https://arxiv.org/pdf/2310.06825
20. Kang, W., Lee, M., Lee, J., Oh, S.: AI or Authors?: A Comparative Analysis of
BERTandChatGPT’sKeywordSelectioninDigitalDivideStudies.Proceedingsof
the Association for Information Science and Technology 60(1), 1004–1006 (2023).
https://doi.org/10.1002/pra2.926
21. Khokhlova, M., Koryshev, M.: Keyness analysis and its representation in Rus-
sian academic papers on computational linguistics: Evaluation of algorithms. In:
RASLAN. pp. 25–33 (2022)
22. Lee,W.,Chun,M.,Jeong,H.,Jung,H.:Towardkeywordgenerationthroughlarge
language models. In: Companion Proceedings of the 28th International Confer-
ence on Intelligent User Interfaces. pp. 37–40 (2023). https://doi.org/10.1145/
3581754.3584126
23. Lewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O., Stoy-
anov,V.,Zettlemoyer,L.:BART:Denoisingsequence-to-sequencepre-trainingfor
natural language generation, translation, and comprehension. In: Proceedings of
the 58th Annual Meeting of the Association for Computational Linguistics. pp.
7871–7880 (2020). https://doi.org/10.18653/v1/2020.acl-main.703
24. Lin, C.Y.: ROUGE: A package for automatic evaluation of summaries. In: Text
summarization branches out. pp. 74–81 (2004)
25. Marchisio, K., Ko, W.Y., Bérard, A., Dehaze, T., Ruder, S.: Understanding and
mitigating language confusion in LLMs. arXiv preprint arXiv:2406.20052 (2024),
https://arxiv.org/pdf/2406.20052
26. Martínez-Cruz, R., López-López, A.J., Portela, J.: ChatGPT vs state-of-the-
art models: a benchmarking study in keyphrase generation task. arXiv preprint
arXiv:2304.14177 (2023), https://arxiv.org/pdf/2304.14177
27. Mihalcea, R., Tarau, P.: TextRank: Bringing order into text. In: Proceedings of
the 2004 conference on EMNLP. pp. 404–411 (2004)12 A. Glazkova et al.
28. Mitrofanova, O., Gavrilic, D.: Experiments on automatic keyphrase extraction in
stylistically heterogeneous corpus of russian texts. Terra Linguistica 13(4), 22–40
(2022). https://doi.org/10.18721/JHSS.13402
29. Morozov, D., Glazkova, A., Tyutyulnikov, M., Iomdin, B.: Keyphrase generation
for abstracts of the Russian-language scientific articles. NSU Vestnik. Series: Lin-
guisticsandInterculturalCommunication21(1),54–66(2023).https://doi.org/
10.25205/1818-7935-2023-21-1-54-66
30. Nguyen, Q.H., Zaslavskiy, M.: Keyphrase extraction in Russian and English sci-
entificarticlesusingsentenceembeddings.In:202128thConferenceofOpenInnov-
ationsAssociation(FRUCT).pp.1–7.IEEE(2021).https://doi.org/10.23919/
FRUCT50888.2021.9347584
31. Nikolich, A., Korolev, K., Shelmanov, A.: Vikhr: The Family of Open-
Source Instruction-Tuned Large Language Models for Russian. arXiv preprint
arXiv:2405.13929 (2024), https://arxiv.org/pdf/2405.13929
32. Novikova, J., Dušek, O., Curry, A.C., Rieser, V.: Why we need new evaluation
metrics for NLG. In: Proceedings of the 2017 Conference on EMNLP. pp. 2241–
2252 (2017). https://doi.org/10.18653/v1/D17-1238
33. Ochieng, M., Gumma, V., Sitaram, S., Wang, J., Ronen, K., Bali, K., O’Neill, J.:
Beyondmetrics:EvaluatingLLMs’effectivenessinculturallynuanced,low-resource
real-worldscenarios.arXivpreprintarXiv:2406.00343(2024),https://arxiv.org/
pdf/2406.00343
34. Raffel,C.,Shazeer,N.,Roberts,A.,Lee,K.,Narang,S.,Matena,M.,Zhou,Y.,Li,
W., Liu, P.J.: Exploring the limits of transfer learning with a unified text-to-text
transformer. Journal of machine learning research 21(140), 1–67 (2020)
35. Rose, S., Engel, D., Cramer, N., Cowley, W.: Automatic keyword extraction from
individual documents. Text mining: applications and theory pp. 1–20 (2010).
https://doi.org/10.1002/9780470689646.ch1
36. Sandul, M.V., Mikhailova, E.G.: Keyword extraction from single Russian docu-
ment. In: Proceedings of the Third Conference on Software Engineering and In-
formation Management. pp. 30–36 (2018)
37. Sheremetyeva, S., Osminin, P.: On methods and models of keyword automatic
extraction. Bulletin of the South Ural State University. Ser. Linguistics 12(1),
76–81 (2015)
38. Shevchenko, I.: RuTermExtract. https://github.com/igor-shevchenko/
rutermextract (2018)
39. Sokolova, E., Mitrofanova, O.: Automatic keyphrase extraction by applying KEA
to Russian texts. In: IMS (CLCO). pp. 157–165 (2017). https://doi.org/10.
17586/2541-9781-2017-1-157-165
40. Song, M., Geng, X., Yao, S., Lu, S., Feng, Y., Jing, L.: Large language models
as zero-shot keyphrase extractor: A preliminary empirical study. arXiv preprint
arXiv:2312.15156 (2023), https://arxiv.org/pdf/2312.15156
41. Song,M.,Jiang,H.,Shi,S.,Yao,S.,Lu,S.,Feng,Y.,Liu,H.,Jing,L.:IsChatGPT
agoodkeyphrasegenerator?Apreliminarystudy.arXivpreprintarXiv:2303.13001
(2023), https://arxiv.org/pdf/2303.13001
42. Tang, Y., Tran, C., Li, X., Chen, P.J., Goyal, N., Chaudhary, V., Gu, J., Fan, A.:
Multilingual translation with extensible multilingual pretraining and finetuning.
arXiv preprint arXiv:2008.00401 (2020), https://arxiv.org/pdf/2008.00401
43. Taylor, R., Kardas, M., Cucurull, G., Scialom, T., Hartshorn, A., Saravia, E.,
Poulton,A.,Kerkez,V.,Stojnic,R.:Galactica:Alargelanguagemodelforscience.
arXiv preprint arXiv:2211.09085 (2022), https://arxiv.org/pdf/2211.09085Key Algorithms for Keyphrase Generation 13
44. Team,G.,Anil,R.,Borgeaud,S.,Wu,Y.,Alayrac,J.B.,Yu,J.,Soricut,R.,Schalk-
wyk,J.,Dai,A.M.,Hauth,A.,etal.:Gemini:afamilyofhighlycapablemultimodal
models. arXiv preprint arXiv:2312.11805 (2023), https://arxiv.org/pdf/2312.
11805
45. Umair,M.,Sultana,T.,Lee,Y.K.:Pre-trainedlanguagemodelsforkeyphrasepre-
diction: A review. ICT Express (2024). https://doi.org/10.1016/j.icte.2024.
05.015
46. Witten, I.H., Paynter, G.W., Frank, E., Gutwin, C., Nevill-Manning, C.G.: KEA:
Practicalautomatickeyphraseextraction.In:ProceedingsofthefourthACMcon-
ference on Digital libraries. pp. 254–255 (1999)
47. Xue, L., Constant, N., Roberts, A., Kale, M., Al-Rfou, R., Siddhant, A., Barua,
A.,Raffel,C.:mT5:Amassivelymultilingualpre-trainedtext-to-texttransformer.
In: Proceedings of the 2021 Conference of the North American Chapter of the
Association for Computational Linguistics: Human Language Technologies. pp.
483–498 (2021). https://doi.org/10.18653/v1/2021.naacl-main.41
48. Zhang, T., Kishore, V., Wu, F., Weinberger, K.Q., Artzi, Y.: BERTScore: Evalu-
ating text generation with BERT. In: International Conference on Learning Rep-
resentations