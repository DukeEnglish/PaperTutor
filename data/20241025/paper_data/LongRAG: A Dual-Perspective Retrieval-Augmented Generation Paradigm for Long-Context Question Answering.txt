LongRAG: A Dual-Perspective Retrieval-Augmented Generation Paradigm
for Long-Context Question Answering
QingfeiZhao1,2,†,RuobingWang1,2,YukuoCen4,
DarenZha1,ShichengTan3,YuxiaoDong3,JieTang3,*
1InstituteofInformationEngineering,ChineseAcademyofSciences;
2SchoolofCyberSecurity,UniversityofChineseAcademyofSciences;
3TsinghuaUniversity;4ZhipuAI
Abstract
Question: Where did the performer of song I’ ll
Long-Context Question Answering (LCQA), Say It graduate from? ➡ Thought: I’ ll Say It →
Griffin → Lee Strasberg Theatre and Film Institute
a challenging task, aims to reason over long-
Answer: Lee Strasberg Theatre and Film Institute
context documents to yield accurate answers
to questions. Existing long-context Large LongRAG
Language Models (LLMs) for LCQA often Integrated Information:️ I ’ll Say It is a song… rec-
struggle with the "lost in the middle" issue. orded by comedian Kathy Griffin. … She perform-
Retrieval-AugmentedGeneration(RAG)mit- er of the song "I’ll Say It" is Kathy Griffin. She att-
igatesthisissuebyprovidingexternalfactual ended the Lee Strasberg Theatre and Film Instit-
evidence. However,itschunkingstrategydis- ute in Los Angeles, where she studied drama.
ruptsthegloballong-contextinformation,and Answer: Lee Strasberg Theatre and Film Institute
its low-quality retrieval in long contexts hin-
ders LLMs from identifying effective factual Vanilla RAG
detailsduetosubstantialnoise. Tothisend,we
Retrieved Information: I’ll Say It is a song…record-
proposeLongRAG,ageneral,dual-perspective, ed by comedian Kathy Griffin. … She became an
androbustLLM-basedRAGsystemparadigm adjunct professor and part-time lecturer at Seoul
forLCQAtoenhanceRAG’sunderstandingof Arts College. Incomplete Key Information
complexlong-contextknowledge(i.e.,global Answer: Seoul Arts College
information and factual details). We design
Long-Context QA
LongRAG as a plug-and-play paradigm, fa-
cilitating adaptation to various domains and Long-Context Information: I’ll Say It is a song… re-
LLMs. Extensiveexperimentsonthreemulti- corded by comedian Kathy Griffin. … Griffin … stud-
hop datasets demonstrate that LongRAG sig- ied drama at the Lee Strasberg Theatre and Film
Insti-tute. … (too long context) … Song Yoon-ah …
nificantlyoutperformslong-contextLLMs(up
as a fre-shman at Hanyang University.
by6.94%),advancedRAG(upby6.16%),and
VanillaRAG(upby17.25%). Furthermore,we Answer: Hanyang University Lost In the Middle
conductquantitativeablationstudiesandmulti-
dimensional analyses, highlighting the effec- Figure 1: Examples of Different Methods. Long-
tivenessofthesystem’scomponentsandfine- ContextLLMsandVanillaRAGface"lostinthemid-
tuningstrategies. Dataandcodeareavailable dle" and "incomplete key information" issues, while
athttps://github.com/QingFei1/LongRAG.
LongRAGaddressesthem,yieldingaperfectanswer.
1 Introduction
Large language models (LLMs), such as GPT cently,severallong-contextLLMshavebeenintro-
(Brown et al., 2020), GLM (Zeng et al., 2022) duced,suchasGemini(Aniletal.,2023)andGPT-
andLLaMA(Touvronetal.,2023),boostthereal- 4-128k,capableofingestingentirerelevantdocu-
world development of multiple scenarios. Long- mentsandgeneratinganswersdirectly. However,
context question answering (LCQA) (Caciularu asshowninFigure1,theyfrequentlyencounterthe
etal.,2022),whichhasbeenrecentlyadvancedsig- “lost in the middle” issue (Liu et al., 2024), that
nificantlybyLLMs,isacomplextaskthatrequires is, when the relevant context is in the middle of
reasoningoveralongdocumentormultipledocu- thedocument(ratherthanthebeginningandend),
mentstoprovideaccurateanswerstoquestions. Re- they are prone to sub-optimal or even incorrect
responses. Instead,theRetrieval-AugmentedGen-
*Correspondingauthor
†WorkdonewhenQZinternedatZhipuAI eration(RAG)system(Gaoetal.,2023;Guuetal.,
4202
tcO
32
]LC.sc[
1v05081.0142:viXra2020) offers an alternative approach, mitigating contextextractoremploysamappingstrategytoor-
this issue by employing a fixed-length chunking derlyextendthesemanticspaceofretrievedchunks
strategy (Theja, 2023). This strategy ensures the into a higher dimensional long-context semantic
inputtotheLLMisconciseandhighlyrelevantto space, then refining global information and con-
thequestion. textual structure among chunks. Meanwhile, the
Nevertheless,VanillaRAGremainsinsufficient CoT-guided filter utilizes the Chain of Thought
for the LCQA task due to two major limitations. (CoT) (Wei et al., 2022) to provide global clues
First, the chunking strategy disrupts the contex- accordingtotheknowledgeofallretrievedchunks,
tualstructureandbackgroundinformationinlong instructing LLMs to carefully review factual de-
documents (global information). Some chunks tailsandpreciselyfilteroutirrelevantchunks. This
maycontainincompleteinformation(Dongetal., improves evidence density and enhances RAG’s
2023), therebycausingLLMstodrawuponirrel- abilitytounderstandcomplexandlengthycontexts.
evantcontextorfallbackontheirinternalparam- Additionally,wehavecuratedanautomatedinstruc-
eterizedknowledge,potentiallyleadingtoinaccu- tion data pipeline for constructing a high-quality
rate responses. As depicted in Figure 1, Vanilla dataset for fine-tuning. This fine-tuning strategy
RAG only retrieves "Griffin" as the performer of significantlyenhancesthe“instruction-following”
"I’ll say it" but misses the university from which capabilities of the system’s core components. It
"Griffin" graduated. Although the "university" is is also convenient to transfer LongRAG to other
mentioned in the same paragraph, the system ul- domainsbyleveragingthepipelineandfine-tuning
timatelyproducesanincorrectresponse. Second, strategy.
low evidence density in long-context documents Extensiveperformancecomparisonsandquan-
can lead to low retrieval quality. Considerable titativeablationstudiesconductedonthreemulti-
noise present in long-context documents impairs hop datasets from LongBench (Bai et al., 2023b)
LLMs’ capacity to accurately identify key infor- demonstrate the superiority and effectiveness of
mation (factual details), resulting in the retrieval LongRAG.TheresultssuggestthatLongRAGsig-
oflow-qualitychunksandultimatelyleadingtoer- nificantlyoutperformedbothlong-context LLMs
roneous answers (Zhang et al., 2023; Chen et al., and advanced RAG methods. We also discuss
2024). Recently, several advanced RAG systems LongRAG’sperformancewithdifferentfine-tuned
haveattemptedtomitigatetheaforementionedis- LLMsandconfirmitsstrongrobustnessandtrans-
sues. Specifically, Self-RAG (Asai et al., 2023) ferability. To sum up, our contributions are sum-
employsself-reflectiontokenstofacilitatetheau- marizedasfollows: 1)WeconstructLongRAG,a
tonomous exploration of global information in a general,dual-perspective,androbustRAGsystem
corpus. However, its reliance on the accuracy of paradigm. It significantly surpasses long-context
reflection tokens may result in the potential dele- LLM(upby6.94%),mainstreamadvancedRAG
tion of valid retrieval chunks with factual details. (upby6.16%),andVanillaRAG(upby17.25%).
CRAG (Yan et al., 2024) evaluates the question 2) We identify and address RAG’s limitations in
relevance of each chunk individually to enhance LCQA.Wedeveloptwoplug-and-playcomponents
the identification offactualdetails. Nevertheless, (i.e.,InformationExtractorandCoT-guidedFilter)
itoverlookstheconnectionsbetweenchunks,pro- to explore global information and factual details,
voking low-quality evaluation when valid details enhancingunderstandingofcomplexlongcontexts.
span multiple chunks, potentially leading to the 3) We implement a novel automated fine-tuning
omissionofcrucialfactualdetails. dataconstructionpipelineandamulti-tasktraining
In our work, we proposeLongRAG, a general, strategywithmulti-lengthlong-contextdata. They
dual-perspective,androbustRAGsystemparadigm facilitatetheapplicationofourparadigmtodiverse
thateffectivelyaddressestheabove-mentionedis- specific-domaindatainreal-worldscenarios.
sues for LCQA, comprising four plug-and-play
componentswithmultiplestrategies: ahybridre- 2 RelatedWorks
triever,anLLM-augmentedinformationextractor,
2.1 Long-ContextLLMs
aCoT-guidedfilter,andanLLM-augmentedgen-
erator. LongRAG enhances the RAG system’s LLMs usually need to handle complex and long-
ability to mine global long-context information contextinputsintherealworld. Thecontextwin-
andidentifyfactualdetails. Specifically,thelong- dow length of LLMs is limited by their trainingsequencelength,andinputsexceedingthiswindow tuning generators for more personalized outputs
may result in considerable performance degrada- (Zhangetal.,2024b),andemployingcollaborative
tion (Zhao et al., 2023; Jin et al., 2024). Thus, fine-tuning(Linetal.,2023). Additionally,Zhou
recentstudiesfocusonscalingthelimitedcontext etal.(2023)discoveredthatfine-tuningLLMswith
lengthofexistingLLMstoaccommodatetasksre- alimitedquantityofhigh-qualitydatasignificantly
quiringlongcontexts,e.g.,long-contextquestion- enhances the performance of LLMs. This find-
answering. Methodsforscalingthecontextlength ing provides a robust theoretical basis for collab-
arecategorizedintotwomaintypes: 1)Oneismeth- orativelyfine-tuningmultiplecomponentswithin
odsfortrainingorfine-tuningwithlongcontexts, advanced RAG methodologies at a minimal data
suchasRMT(Bulatovetal.,2022),PositionInter- expense.
polation (Chen et al., 2023a), YaRN (Peng et al.,
2023), Activation Beacon (Zhang et al., 2024a), 3 Preliminaries
LongLoRA(Chenetal.,2023b),LongRoPE(Ding
3.1 TaskDefinition
et al., 2024), and LongAlign (Bai et al., 2024);
2) the other is non-fine-tuned methods include FollowingthestructureofVanillaRAG(aretriever
restricted attention-based approaches (Han et al., R and a generator G), the LongRAG system (cf.,
2023; Xiao et al., 2023; Lu et al., 2024) and con- Figure 2) includes a Long-Context Extractor E
textcompressionmethods(Jiangetal.,2023a;Li andaCoT-guidedFilterF afterretrievaltoextract
etal.,2023b). Generally,non-fine-tunedmethods global information I g and identify factual details
allowforplug-and-playandlow-costscalingLLMs. I d. Specifically, given a question q ∈ Q and a
Fine-tuned methods typically show better perfor- long-contextcorpusC,Rreceivesaq andretrieves
mancebutrequirehighertraininganddatacosts. the top-k most relevant chunks p c ∈ P c. These
p areobtainedbysegmentingsourceparagraphs
c
2.2 Retrieval-AugmentedGeneration p ∈ P. WetheninputpintoE, obtainingI , and
g
WiththeadventoftheGPTera,RAG(Lewisetal., p c intoF toidentifychunkscontainingfactualde-
2020; Guu et al., 2020) is regarded as a power- tails, defined as I d, which are subsequently used
fultechnologyforimprovingtheresponsequality byG togenerateafinalanswertothequestion. It
ofLLMs(IzacardandGrave,2021;Chungetal., isworthnotingthatwhendiscussingthesystem,P
2022). RAGalleviatesissuessuchasoutdatedand representsthesourcelong-contextparagraphsmap-
long-tailknowledge(Heetal.,2023;Kandpaletal., pingfromretrievedchunksP c. However,whendis-
2023),hallucinations(Chenetal.,2023c;Zuccon cussingfine-tuninginstructiondataD,P denotes
etal.,2023),andlackofdomainexpertise(Lietal., allcorrespondingparagraphsgivenforaquestion,
2023a; Shenetal.,2023)ofLLMsbyleveraging includingpredefinedsupportingparagraphsP s and
external knowledge, i.e., Wikipedia. Despite the givendistractingparagraphsP d.
success of RAG, its chunking strategy and direct
3.2 Fine-TuningDataConstruction
incorporationofretrievedchunksintothegenera-
torresultinincompleteinformationandsubstantial To improve the "instruction following" ability of
noise. Recently,advancedRAGmodelshavebeen components and learn long-context styles, we
proposedtoaddresstheseissuesbyfilteringorre- craftasmallbuthigh-qualityinstruction-following
ranking the retrieved knowledge to reduce noise dataset for supervised fine-tuning (SFT), named
(Yoranetal.,2023;Yanetal.,2024;Zhuangetal., LRGinstruction, viaChatGLM3-32B-128k(Du
2023),designingachunk-freestrategytomitigate et al., 2022; Zeng et al., 2023) as teacher LLM.
semantic loss (Qian et al., 2024), and employing We select the training sets of three complex En-
active retrieval to mine information (Asai et al., glish multi-hop datasets released by Trivedi et al.
2023;Jiangetal.,2023b). (2023)–HotpotQA(Yangetal.,2018),2WikiMul-
tiHopQA(Hoetal.,2020),andMusiQue(Trivedi
2.3 Domain-SpecificFine-TuningforRAG
et al., 2022), as well as the English dataset
Fine-tuninghasgraduallybecomeapopularstrat- QASPERwithlongercontexts(Dasigietal.,2021)
egy(Keetal.,2024)forenhancingthecapabilities , to jointly develop our LRGinstruction. Among
of components of RAG. Existing works include them, QASPER with more lengthy contexts pro-
fine-tuningretrieval-relatedcomponentstoachieve motesLLMstofurtherlearnthelong-contextstyle.
better retrieval outcomes (Yan et al., 2024), fine- Theconstructionpipelineisautomated,thatis,youCoT-guided Filter &
Hybrid Retriever LLM-augmented Generator
LLM-augmented Information Extractor
Guiding CoT Factual
Question: Support Details
Where did the
Unsupport
performer of Question …
song I’ll Say It … Support
graduate from? Answer
…
Unsupport
Lee Strasberg
Question Theatre
and
Question
Extract Information Film Institute
Paragraph 1
Retrieved Help LLMs focus on extracting Global
chunks Paragraph 2 global background and structural Information
…
information from the source long
…
mapping Paragraph paragraphs.
to
Figure2: AnoverviewofLongRAG.Oursysteminvolvesfoursub-components: HybridRetrieverreceivesa
questionandretrievesthetop-kmostrelevantchunksp ;CoT-guidedFiltergeneratesglobalkeycluestoanalyze
c
their relevance one by one, obtaining a set of "True" chunks as I ; Meanwhile, LLM-augmented Information
d
Extractorsequentiallymapsp tothesourcelong-contextparagraphptoextracteffectiveglobalinformationI ;
c g
LLM-augmentedGeneratorpromotesknowledgeinteractionbetweenI andI togeneratethefinalanswer.
g d
canautomaticallygeneratehigh-qualityfine-tuning pipeline, we validate the efficacy of the golden
instruction data from any specific domain. In ad- outputsviaanLLM-basedself-evaluatorandretain
dition,theresultsofexperimentsindicatethatwe the golden outputs that are deemed valid. CoT-
only need 2600 samples to fine-tune the LLMs guidingData&FilteringData. Thetrainingdata
usedincomponentstoachievegoodperformance fortheCoT-guidedfiltercomponentisconstructed
inLCQAtasks. Theconstructionpipelineisintro- intwostages: theCoTguidanceandthefiltering
ducedasfollows(moredetailsinAppendixC). stage. Keyinsightsandcluesforquestionresolu-
DataPre-Processing. Tolearnlong-contextstyle, tionresidewithinP s. Thus,fortheCoTguidance
wediscardanyquestion-answerpairswithinsuffi- stage,theLLMisexpectedtoexaminetheseman-
cientcontextlength(seedetailsinAppendixC.1). ticrelationsandfactualdetailsforquestion-solving
Then,wekeepallsupportingparagraphsofques- withinP s togenerateaguidingCoT.Thisprocess
tionsP andrandomlyretainasubsetofdistracting also employs a self-evaluator to evaluate the reli-
s
paragraphsP . Therandomstrategyisdesignedto ability of the CoT outputs as golden data. In the
d
simulatethedistributionofthenumberofrecalls subsequentfilteringstage,Wemergeq withacor-
executedinreality. Tosumup,wedefinetheele- respondingpanditsguidingCoTasthegolddata
mentsofpre-processeddatasetasfollows: question (see Appendix C.3 for details). P s and P d each
q ∈ Q,multiplecorrespondingparagraphsp ∈ P, accountforhalfinP.
includingsupportingparagraphsP anddistracting Task-Oriented Data. Question-answer pairs
s
paragraphsP tothequestion,andanswerα ∈ A, ⟨Q,A⟩ and P are already present in D, and we
d
mathematically⟨Q,{P ∪P },A⟩. simplyneedtoreorganizetheirformat.
s d
Long-ContextExtractorData. Wefine-tunethe
4 TheLongRAGSystem
long-context extractor to improve its capacity to
extract global information from the source long
4.1 HybridRetriever
paragraphs. First,weconsiderallP ofeachques-
s
tion as effective global information. These ques- Thehybridretrieverbeginswithagivenquestion
tionsandtheirglobalinformationserveasinputfor and then recalls k chunks. Before the retrieval,
zero-shotin-contextlearning(ICL)togainglobal the long-context p requires further segmentation
background and structure information, which act into chunks p . Specifically, we impose a length
c
as golden outputs (see Appendix C.2 for details). limitonchunks,withsentencesasthesmallestdi-
Subsequently, to enhance the robustness of the visionunit. Wethenemployaslidingwindowtoextendthecontextbyaddingoverlappingcontent LLMtoultimatelyobtainingglobalinformationI
g
from the end of the previous sentence, prevent- enrichedwithextensivelong-contextbackground
ingsemanticdisruptionattruncationpoints. Short andstructuralknowledge.
chunksattheendofparemergedwithpreceding
4.3 CoT-guidedFilter
chunkstoensurebettersemanticcohesion. Inspired
by Re2G (Glass et al., 2022), we utilize a dual- It is not always the case that retrieved chunks p c
encoder1 structure for rapid retrieval at a coarse- will assistin answering questions, particularly in
grainedlevel,andacross-encoder2 tocapturethe multi-hopquestionsthatinvolvecomplexreason-
deepsemanticinteractionforfurtherretrievalata ing chains and long-context paragraphs with low
fine-grained level. The engineering implementa- evidencedensity. Theretrievedchunksusuallycon-
tion ensures efficient retrieval through the use of tain substantial redundancy; some of chunks can
FAISS(Johnsonetal.,2019). evenbeentirelyredundant. Thiscomplexitymakes
itdifficulttoascertainwhetherachunkholdsthe
4.2 LLM-augmentedInformationExtractor keyinformationforsolvingmulti-hopquestions.
Inlong-contextQAwithlowevidencedensity,the Toaddressthis,wedeveloptheCoT-guidedfil-
complete evidence supporting answers is usually ter with a two-stage strategy. The initial stage,
scatteredacrossmultiplelocations. Fromaglobal CoTguidance,generatesaCoTwithaglobalper-
perspective,thisevidencenotonlycontainsitsown spectivebasedontheretrievalsemanticspace,out-
knowledge but also implicitly stores logical and lining the global clues for answering the ques-
sequentialconnectionsamongchunks. Retrieved tion. Here’sthemathematicalexpressionofCoT-
chunks, truncated by fixed windows, struggle to guidancestage:
carryadditionalglobalinformation. Furthermore, CoT = LLM(prompt (q,p ||···||p )) (3)
c c1 c
k
whentheretrievedchunksoriginatefromthesame
where k denotes the number of chunks p , and
p,theirordermaybeinconsistentwiththeoriginal c
prompt (·)istheprompttemplateofyieldingCoT
semantic order in p, resulting in providing disor- c
based on LLMs. Subsequently, in the filtering
deredsemanticinformationtodownstreamLLMs.
stage, these CoTs serve as global clues, guiding
To address these issues, we map the short-form
LLMsstepbysteptofocusonrelevantknowledge
chunksp backtotheirsourcelong-contextpara-
c
throughoutthereasoningchain. Theyequipfilters
graphsp,usingamappingfunctionf (·):
m
withtheabilitytojudgetherelevancebetweenques-
tionsandchunksusingahigh-dimensionalperspec-
f (p ,p ,··· ,p ) → p ,p ,··· ,p (1)
m c1 c2 c
k
1 2 k′
tive. Thisaidsthesystemininferringmulti-hopse-
where k and k′ (k ≤ k′) denote the number of manticassociationsandmeticulouslyexaminingall
pre-mappingp andpost-mappingp,respectively. availablefactualdetailsincontextsoflowevidence
c
When multiple p correspond to the same p, we density. Overall,thisphaseachieveshigh-quality
c
keep only the p corresponding to the p with the identificationoffactualdetailsandsecuresreliable
c
highestsemanticsimilaritytothequestionq. This relevancelabelsforquestion-chunkpairs. Weuse
mapping strategy maximizes the recovery of the theselabelstopreciselyfilterirrelevantchunksp c
context of question-relevant source paragraphs. andavoiddeletingcrucialfactualdetails,thusen-
Then, we concatenate k′ paragraphs p and feed suring low redundancy input for the downstream
themintotheprompt(seeAppendixD)oftheLLM- generator.
augmented information extractor for employing (cid:40)
True, if<support>
zero-shotICL. V(q,p c,CoT) =
False, otherwise (4)
I
g
= LLM(prompt e(q,p 1||p 2||···||p k′)) (2) I
d
= {p
c
| V(q,p c,CoT) = True}
Equation(4)describestheprocessofthefiltering
TheprompttemplateoftheLLM-augmentedinfor-
stage. V(·)returnsabinarylabeltoassesswhether
mationextractor,definedasprompt (·),guidesthe
e
thechunkp supportsansweringtheqaccordingto
c
1We use E5-large model for dual-encoder:https:// theclueswithintheCoT.Weiterativelyassesseach
huggingface.co/intfloat/multilingual-e5-large p viathefunctionV(·). Thesechunksmarkedas
c
2We use mMiniLM as cross-encoder model:
"True"areconsideredasasetofchunkscontaining
https://huggingface.co/nreimers/mmarco-mMiniLMv2-
L12-H384-v1 factualdetailsinformation,definedasI d.Model HotpotQA 2WikiMQA MusiQue Average
#Long-ContextLLMMethods#
LongAlign-7B-64k(Llama2)(Baietal.,2024) 48.85 28.56 25.14 34.18
LongLoRA-13B-32k(Llama2)(Chenetal.,2023b) 47.45 42.92 29.46 39.94
#AdvancedRAGMethods#
CFIC-7B(Llama2)(Qianetal.,2024) 34.00 - 14.70 24.35
CRAG(GPT-3.5-Turbo)(Yanetal.,2024) 52.04 41.13 25.34 39.50
Self-RAG(GPT-3.5-Turbo)(Asaietal.,2023) 50.51 46.75 24.62 40.63
#RAG-Base(VanillaRAG)#
Vicuna-v1.5-7B-16k(Zhengetal.,2023) 38.63 27.92 15.68 27.41
Qwen-1.5-7B-32k(Baietal.,2023a) 45.70 34.69 25.08 35.16
Llama3-8B-8k(Touvronetal.,2023) 48.25 43.47 19.66 37.13
ChatGLM3-6B-32k(Duetal.,2022) 52.57 42.56 25.51 40.21
GPT-3.5-Turbo-16k 50.17 45.32 21.84 39.11
GPT-3.5-Turbo 52.31 43.44 25.22 40.32
Llama3-70B-8k 52.33 50.23 25.49 42.68
GLM-4 57.41 52.91 27.55 45.96
#OurswithSFT#
LongRAG-Llama2-7B-4k 53.85 45.61 26.22 41.89
LongRAG-Llama2-13B-4k 57.05 49.95 33.63 46.88
LongRAG-Qwen-1.5-7B-32k 52.91(7.21↑) 46.65(11.96↑) 31.85(6.77↑) 43.80(8.65↑)
LongRAG-Llama3-8B-8k 52.39(4.14↑) 49.67(6.20↑) 31.70(12.04↑) 44.59(7.46↑)
LongRAG-Vicuna-v1.5-7B-16k 55.55(16.92↑) 50.13(22.21↑) 28.29(12.61↑) 44.66(17.25↑)
LongRAG-ChatGLM3-6B-32k 55.93(3.36↑) 54.85(12.29↑) 33.00(7.49↑) 47.93(7.71↑)
#OurswithoutSFT#
LongRAG-GPT-3.5-Turbo 56.17(3.86↑) 51.37(7.93↑) 32.83(7.61↑) 46.79(6.47↑)
LongRAG-GPT-3.5-Turbo-16k 59.11(8.94↑) 51.25(5.93↑) 30.37(8.53↑) 46.91(7.80↑)
LongRAG-GLM-4 62.11(4.70↑) 57.16(4.25↑) 38.40(10.85↑) 52.56(6.60↑)
Table1: Results(%)ofoverallperformanceonthreemulti-hopdatasets. The"GreyAreas"representdifferent
categoriesofbaselinesoroursystemwithdifferentfine-tuningsettings. “BoldFont”denotesthehighestabsolute
value,while"UnderlinedFont"expressesthehighestrelativegainvaluecomparedtoVanillaRAG.Ourswith(or
without)SFTindicatesweemployfine-tuned(ornon-fine-tuned)LLMsinallLLM-augmentedcomponents. All
modeltypesare"chat". WecalculatetheincreaseinourscomparedtoVanillaRAG,suchas"17.25↑".
4.4 LLM-augmentedGenerator beenstandardizedintoaQAinstructionstyle. Dur-
ing training, all models utilize the Llama-factory
Global information I encompasses both back-
g
libraryand8xA100GPUs(80Geach),employing
groundandstructuralinformationwithinthelong-
trainingmethodswithDeepSpeed+ZeRO3+CPU
context corpus, while factual details information
offloading+flashattentionstrategies(Rasleyetal.,
I refers to the filtered chunk set with minimal
d
2020; Dao et al., 2022). The training parameters
noiseandcrucialevidencedetails. Thegenerator
aresetwithabatchsizeof8,agradientaccumula-
boosts the interaction of knowledge across these
tionstepof12,and3epochs(totaling81steps).
twoperspectivestoproduceanswersαtoquestions.
Here is the formula for the generator G, where
5 Experiment
prompt (·)istheprompttemplateofgenerator:
g
5.1 ExperimentalSetup
α = LLM(prompt (I ,I )) (5)
g g d
Datasets & Evaluation. We select three chal-
4.5 Instruction-Tuning
lenging multi-hop datasets – HotpotQA, 2Wiki-
Weadoptacollectionofindustry-leadingmodels MultiHopQA(2WikiMQA),andMusiQue–from
as our foundational LLMs: ChatGLM (Du et al., the Longbench (Bai et al., 2023b) for evaluation,
2022; Zeng et al., 2022), Qwen1.5 (Bai et al., rather than using raw datasets. We standardize
2023a),Vicuna(Zhengetal.,2023),Llama2,and thesedatatoadapttoRAGtasks(moredetailsin
Llama3(Touvronetal.,2023). Theyareallopen- Appendix B.2), and report the F1-score as eval-
source and support multi-lingual, multi-tasking. uation metrics for all three datasets. Statistics of
Wehavefine-tunedthemusing2,600high-quality experimentaldatasetsareshowninTable2.
data sourced from LRGinstruction. Specifically, Baselines & LLMs. To validate the superior-
weemployallfourtypesofdatainLRGinstruction ity of our LongRAG in multiple dimensions, we
collectivelytotrainamodelthatisusedintheex- utilize three categories of baselines: 1) Long-
tractor, thefilter, andthegenerator. Furthermore, Context LLM Methods – LongAlign (Bai et al.,
this data has undergone length filtering and has 2024) and LongLoRA (Chen et al., 2023b); 2)Dataset HotpotQA 2WikiMQA MuSiQue Ours vs. Other RAG. We compare LongRAG
NumofSamples 200 200 200 with two categories of RAG baselines, advanced
Avg.Lengthofp 1092 535 1032 RAGandVanillaRAG(RAG-Base,R&B).Weem-
Numofp 1715 1464 1877
Avg.LengthofP 9151 4887 11214
ploytheLangGraphlibrary5,integratedwithinthe
LangChainframework,toreproduceSelf-RAGand
Table 2: Statistics of experimental data. "Avg. CRAG. First, compared to the advanced RAG,
Length"standsfortheaveragewordcount.
especially Self-RAG, our LongRAG achieves a
6.16%improvementacrossthreedatasetsonaver-
Advanced RAG Methods – CFIC (Qian et al., age. Thisisduetotheself-reflectivechaindecision-
2024), CRAG (Yan et al., 2024), and Self- makinginSelf-RAG,whichcan,incertaincases,
RAG (Asai et al., 2023); 3) Vanilla RAG (only amplifydecisionerrors,leadingtocatastrophicloss
retriever R and generator G) based on various of factual details. Similarly, CRAG exhibits non-
LLMs. TheseLLMsrangefromsmallparameter- robustevaluationbehaviors,makingitchallenging
size(6b~8b)modelslikeChatGLM3-6B-32k(Du to handle complex, multi-hop long-context ques-
etal.,2022),Qwen1.5-7b-32k(Baietal.,2023a), tions. Second, compared to the R&B, all LLMs
Vicuna-v1.5-7b-16k (Zheng et al., 2023), and appliedinoursystemexhibitsignificantimprove-
Llama3-8B-8k (Touvron et al., 2023) to large ments(upto17.25%). VanillaRAGsegmentslong
parameter-sizeonlinemodelslikeGPT-3.5-Turbo3 contextsintosmallersemanticunits,hinderingthe
(gpt-3.5-turbo-0125)andGLM-44 (glm-4). downstreamgeneratorfromaccessingamoreco-
Others. Inourexperiments,alltokenlengthsare herent long-context background and the original
measuredbyChatGLMtokenizer. Weevaluatefour long-contextstructure. Basedontheaboveanaly-
differentretrievalstrategiestoanalyzetheperfor- sis,oursystem,afterperformingextractorandfilter,
manceofLongRAGcomprehensively(moredetails acquireshigher-qualityandlessnoiseknowledge,
andresultsinAppendixA.1). Specifically,werep- thusgeneratingmoreaccurateanswers.
resentfourretrievalstrategiesas"chunksize*top- Small-Size vs. Large-Size LLMs. We find that
k", including "200*7", "200*12", "500*3", and theLongRAGsystemparadigm,whetheremploy-
"500*5". Bydefault,wesetthechunksizeto200 ing fine-tuned small-size or non-fine-tuned large-
wordsandthetop-k valueto7. size LLMs, consistently outperforms other base-
linemethodsacrossalldatasets. Mostimportantly,
5.2 OverallPerformance
LongRAGusingthefine-tunedChatGLM3-6B-32k
In this section, we perform a multi-dimensional achieves better performance than using non-fine-
comparisonandanalysisoftheoverallperformance tunedGPT-3.5-Turbo. Theseresultsproveoursys-
resultsinTable1. temparadigmbooststheabilitytoanalyzeandpro-
Ours vs. Long-Context LLM Methods. We cesscomplexlongcontexts,aswellas"instruction
align the parameter size of Llama2 and compare following"capability. Italsocompensatesforthe
LongRAGwiththeresultsofLongAlignandLon- limitationsobservedinsmall-sizeLLMs,particu-
gLoRA.OursystemparadigmusingSFTachieves larlyinlong-contextin-contextlearning(ICL)and
the highest performance on all datasets. In ad- understandingcomplexinformation.
dition, we also observe that the LongRAG sys-
tem paradigm equiping other similar parameter- 5.3 AblationStudy
sizeLLMsconsistentlysurpassesbaselineswithin Theablationstudy(Table3)reportsresultswithin
Long-context LLM methods across all datasets. fivestrategiestohighlighttheeffectivenessofthe
Theseachievementsconfirmthesuperiorityofour informationextractorandCoT-guidedfilter. Inthe
system across all datasets. This occurs because followingparagraphs, weexplorethereasonsfor
long-contextLLMsoftenoverlookcrucialfactual theperformancegains.
details in the middle, while LongRAG precisely
RAG-Long vs. RAG-Base. RAG-Long (R&L)
androbustlyperceivesfactualdetails. Overall,our
refers to mapping the p back to the p and then
c
systemservesasamoreeffectivetechnicalsolution
directly putting a set of p into the generator to
forLCQA.
output a response. The R&L strategy fails to ro-
3https://openai.com/blog/chatgpt bustly achieve performance improvements over
4Duetoresourcelimitations,weperformtheAPIofglm4
withan8ktokenwindow.https://open.bigmodel.cn. 5https://github.com/langchain-ai/langgraphHotpotQA 2WikiMQA MusiQue
Model
R&B R&L Ext. Fil. E&F R&B R&L Ext. Fil. E&F R&B R&L Ext. Fil. E&F
#OurswithSFT#
LongRAG-ChatGLM3-6B-32k 51.48 54.00 55.11 49.01 55.93 46.61 44.83 52.53 48.83 54.85 24.02 33.15 32.98 27.70 33.00
LongRAG-Qwen1.5-7B-32k 47.09 48.93 50.01 49.11 52.91 35.78 37.72 42.91 38.98 46.65 20.68 26.08 29.60 23.67 31.85
LongRAG-Vicuna-v1.5-7B-16k 51.63 50.18 55.94 52.34 55.55 39.45 43.53 49.57 41.18 50.13 25.30 25.28 29.25 29.29 28.29
LongRAG-Llama3-8B-8k 49.45 50.49 51.77 49.64 52.39 39.79 37.16 46.80 42.40 49.67 21.41 22.90 33.85 23.47 31.70
#OurswithoutSFT#
LongRAG-ChatGLM3-6B-32k 52.57 50.19 52.27 53.36 52.07 42.56 42.92 44.95 42.94 46.08 25.51 29.93 28.27 23.99 28.45
LongRAG-Qwen1.5-7B-32k 45.70 49.72 50.74 45.70 50.80 34.69 35.49 39.53 34.69 39.53 25.08 25.85 29.75 25.08 29.75
LongRAG-Vicuna-v1.5-7B-16k 38.63 30.40 41.45 39.46 43.18 27.92 20.68 29.08 29.89 30.85 15.68 8.92 17.65 16.35 16.98
LongRAG-Llama3-8B-8k 48.25 48.72 52.44 47.75 52.19 43.47 41.59 47.34 42.22 46.57 19.66 23.62 24.90 20.06 24.99
LongRAG-GPT-3.5-Turbo 52.31 55.30 56.15 50.90 56.17 43.44 45.03 53.29 39.49 51.37 25.22 28.65 32.17 24.41 32.83
LongRAG-GPT-3.5-Turbo-16k 50.17 49.80 60.06 47.10 59.11 45.32 46.80 51.26 46.38 51.25 21.84 25.09 26.92 22.02 30.37
LongRAG-GLM-4 57.41 56.17 61.07 55.41 62.11 52.91 48.98 54.22 52.61 57.16 27.55 27.85 38.54 28.12 38.40
Table3: Results(%)oftheablationstudy. Wecomparefivestrategiesintwodimensions: withandwithoutSFT.
Wehighlightthehighest("BoldFont")andsecond-highest("_")resultspermodel. R&B,R&L,Ext.,Fil.,andE&F
representRAG-Base,RAG-Long,Extractor,Filter,andExtractor&Filter,respectively.
R&B.Specifically,theR&Lstrategyfeedsthecon- usedinconjunctionwiththeExtractor.
tinuous long-context space into the LLM, unlike
Extractor & Filter vs. Others. E&F serves as
theR&Bdisruptsthesemanticcontinuityoflong
a joint strategy with two pluggable components
contexts. Therefore,R&Lenablestocaptureofa
withintheRAGsystem,achievingthebestperfor-
broader continuity of the source semantic space;
mance in the majority of cases. It outperforms
however,italsorisksintroducingexcessivenoise.
theR&Lstrategybyprovidingrefinedinformation
Extractor vs. RAG-Long. The extractor builds withlessnoise,therebyeffectivelyalleviatingthe
upontheR&Ltoeffectivelyextractpertinentlong- "lost in the middle" issue. Specifically, the role
context information. Specifically, the extractor of the Extractor is to capture globally effective
strategyreferstothesystemfirstextractingglobal information from long contexts, while the Filter
informationI g fromthemappedsourcelongpara- flexiblyselectsfactualdetailsthroughinteractions
graphs,andthenusingI g assupplementaryinput betweenthequestionandrelevantparagraphs. Re-
alongside retrieved chunks p c to the generator to sults suggest employing both E&F components
enhanceanswerquality. Thesystemusingtheex- yields a more helpful and concise set of informa-
tractorstrategypresentssubstantialimprovements tioncomparedtousingasinglecomponent. How-
acrossallthreedatasets,particularlyonlarger-size ever,itisworthmentioningthataminorityofcases
LLMsthatexhibitstrongerin-contextlearningca- whereE&FunderperformscomparedtoExtractor
pability. This improvement stems fromrecogniz- alone do not imply that the Filter is ineffective.
ingthechallengeofdirectlyderivinganswersfrom In fact, when the built-in LLM possesses strong
lengthy contexts; therefore, we first leverage the "instruction-following"capabilities(e.g.,GLM-4
LLMs’capabilitytoextractglobalstructuresand andfine-tunedsmall-sizeLLMs),addingtheFilter
backgroundknowledgeassupplementsforgenerat- ismorelikelytoboostsystemperformance. Plus,
ingthefinalanswer. Theextractorstrategyeffec- the Filter can reduce the number of tokens input
tivelymitigatestheissueoflow-qualityresponses intodownstreamLLMs. FromtheresultsinTable3
intheR&Lstrategycausedbydirectlyfeedingre- andFigure3,itisevidentthatusingtheFiltercan
dundantlongpassagesintoLLMs,whilealsopro- savetokencostsduringthegenerationphasewhile
viding LLMs with additional and concise global achievingperformancecomparabletoorevenbet-
structureandcontextualrelationshipinformation. ter than using the Extractor alone. Furthermore,
Additionally,inmostinstances,theextractoristhe wefindthatnotallresearcherscanaffordthehigh
primarycontributortoperformancegains,second costsofpowerfulAPILLMs(e.g.,GPT-3.5-Turbo).
onlytothejointstrategy,Extractor&Filter(E&F). Ourmethodoffersanalternativebyusingmoreaf-
Filtervs. RAG-Base. Usingthefilteralonebased fordableopen-sourcelocalLLMsforcomponents
onR&Bimprovestheperformanceonlymarginally beforethegenerator,insteadofrelyingonexpen-
inafewcases. Thisoccursbecausefilteringis,after sive online APIs throughout the entire inference
all,aprocessofinformationreduction. Therefore, process. Therefore,ifthegoalistobalanceperfor-
it can only display markedly performance when manceandcost,E&Fiscrucial.ficultyinpreciselyidentifyingfactualinformation
14000 HotpotQA amidsubstantialnoise. Weconductextensivemulti-
12000 2WikiMultiHopQA
10000 MusiQue dimensionalexperiments,whichdemonstratethe
8000 superiorityofLongRAGandtheeffectivenessof
6000 ourproposedcomponentsandfine-tuningstrategy.
4000
LongRAGsignificantlyoutperformslong-context
2000
LLMs,advancedRAGmethods,andVanillaRAG
R&B R&L Ext. Fil. E&F
basedonvariousLLMs. Ourplug-and-playcompo-
Figure3: TrendsoftokenlengthsfedintotheGenerator nentssuccessfullyusesmallparameter-sizeLLMs,
G offivecomponentstrategiesonthreedatasets. replacingexpensiveonlineAPIresourceswithlow-
costlocaldeploymentsolutions,whilebetterthan
GPT-3.5-Turbo. Additionally, we provide an au-
tomated pipeline for fine-tuning instruction data
35
construction,whichgreatlyfacilitatestheapplica-
30
tionofoursystemtootherspecific-domaindata.
GPT-3.5-Turbo
25 GPT-3.5-Turbo-16k
GLM-4
R&B E&F E&F
w/o SFT (ChatGLM3-6B-32k) 7 Limitations
Figure 4: Analysis of the transferability of Extrac-
tor&FilterondatasetMusiQue.
This paper presents a general-purpose and
corpus-level retrieval-augmented generation sys-
5.4 Discussion tem paradigm for long-context question answer-
ing,termedLongRAG.Whilethesystemparadigm
AnalysisofTokenLengthTrends. Figure3illus-
bringssignificantadvancementsandproveseffec-
tratesthetokenlengthsinputtedintothegenerator
tive, it is also subject to certain limitations that
G for all datasets after undergoing the five strate-
meritdiscussion.
gies. Theresultsindicateaconsistenttrendacross
alldatasets. Specifically,ourE&FstrategyfeedsG One-timeRetrievalDependency. Inthisstudy,we
fewertokensbutachievessuperioroutcomes,how- onlyinvestigatedtheperformanceoftheinforma-
ever, R&Lfeedsthemostwithoutcorresponding tionextractorandCoT-guidedfilterinaone-time
systematic gains, which indicates we can obtain retrievalscenario. ThequalityofCoTsandsource
higherqualityinformationthroughE&F. documentsforansweringdependsonthequalityof
Componenttransferability. AsshowninFigure single-pass retrieved chunks. Consequently, low-
4, E&F (ChatGLM3-6B-32k) means we employ qualityone-timeretrievalcanindirectlyundermine
ChatGLM3-6B-32kasthebuilt-inLLMofextrac- the effectiveness of our core components. Mov-
torE andfilterF,whilethegeneratorG usesother ingforward,weanticipatethataneffectiveavenue
powerfulonlineLLMs,e.g.,GPT-3.5-Turbo. E&F ofimprovementcoulddevelopanadaptivemulti-
w/oSFTrepresentsthesamemeaningsinTable3, round retrieval strategy through interaction with
thatis,weapplythesamebuilt-inLLMfortheE, corecomponents.
F,andG. Resultsrevealwetransfertheexpensive
DatasetAnnotationBias. Althoughwehaveused
powerful online LLMs of E and F to a low-cost
the32-billionparameterChatGLM3modeltogen-
local model while achieving excellent results. It
eratehigh-qualityfine-tuningdatasets,modelsof
cansurpassGPT-3.5-TurboandrivaltheGLM-4.
this scale may still be susceptible to annotation
biasesinherentinself-generateddatasets. Suchbi-
6 Conclusion
asescouldimpairthecontextualunderstandingof
We build an effective and robust RAG system thefine-tunedmodelsacrossdiversetasksanddo-
paradigm—LongRAG—whichenhancesRAG’s mains,potentiallyunderminingtheoverallsystem
performanceinLCQAtasksviaadualinformation performance. Itisthereforevaluabletothoroughly
perspective. LongRAGaddressestwomainissues investigatetheperformanceofinstructiondatasets
facedbyexistingmethods: 1)theincompletecol- createdbyLLMsofvariousscalesincross-domain
lectionoflong-contextinformation;and2)thedif- andmulti-taskenvironments.
htgneL
nekoT
)%(
erocS
1FAcknowledgments TomB.Brown,BenjaminMann,NickRyder,Melanie
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
This work is supported by the Natural Science Neelakantan,PranavShyam,GirishSastry,Amanda
Foundation of China (NSFC) 62276148 and Askell, Sandhini Agarwal, Ariel Herbert-Voss,
62425601, Tsinghua University (Department of Gretchen Krueger, Tom Henighan, Rewon Child,
Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,
ComputerScienceandTechnology)-SiemensLtd.,
ClemensWinter,ChristopherHesse,MarkChen,Eric
China Joint Research Center for Industrial In-
Sigler,MateuszLitwin,ScottGray,BenjaminChess,
telligence and Internet of Things (JCIIOT) and Jack Clark, Christopher Berner, Sam McCandlish,
NewCornerstoneScienceFoundationthroughthe Alec Radford, Ilya Sutskever, and Dario Amodei.
2020. Languagemodelsarefew-shotlearners. InAd-
XPLORERPRIZE.
vancesinNeuralInformationProcessingSystems33:
AnnualConferenceonNeuralInformationProcess-
ing Systems 2020, NeurIPS 2020, December 6-12,
References
2020,virtual.
Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-
AydarBulatov,YuriKuratov,andMikhailBurtsev.2022.
Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan
Recurrentmemorytransformer. InAdvancesinNeu-
Schalkwyk,AndrewM.Dai,AnjaHauth,KatieMil-
ralInformationProcessingSystems35: AnnualCon-
lican, David Silver, Slav Petrov, Melvin Johnson,
ferenceonNeuralInformationProcessingSystems
Ioannis Antonoglou, Julian Schrittwieser, Amelia
2022,NeurIPS2022,NewOrleans,LA,USA,Novem-
Glaese, Jilin Chen, Emily Pitler, Timothy P. Lilli-
ber28-December9,2022.
crap,AngelikiLazaridou,OrhanFirat,JamesMolloy,
Michael Isard, Paul Ronald Barham, Tom Henni-
AviCaciularu, IdoDagan, JacobGoldberger, andAr-
gan,BenjaminLee,FabioViola,MalcolmReynolds,
manCohan.2022. Longcontextquestionanswering
YuanzhongXu,RyanDoherty,EliCollins,Clemens
viasupervisedcontrastivelearning. InProceedings
Meyer, Eliza Rutherford, Erica Moreira, Kareem
ofthe2022ConferenceoftheNorthAmericanChap-
Ayoub, Megha Goel, George Tucker, Enrique Pi-
teroftheAssociationforComputationalLinguistics:
queras,MaximKrikun,IainBarr,NikolaySavinov,
HumanLanguageTechnologies,NAACL2022,Seat-
IvoDanihelka,BeccaRoelofs,AnaïsWhite,Anders
tle,WA,UnitedStates,July10-15,2022,pages2872–
Andreassen, Tamara von Glehn, Lakshman Yagati,
2879.AssociationforComputationalLinguistics.
MehranKazemi,LucasGonzalez,MishaKhalman,
JakubSygnowski,andetal.2023. Gemini: Afam-
ily of highly capable multimodal models. CoRR, Jiawei Chen, Hongyu Lin, Xianpei Han, and Le Sun.
2024. Benchmarking large language models in
abs/2312.11805.
retrieval-augmented generation. In Thirty-Eighth
AkariAsai,ZeqiuWu,YizhongWang,AvirupSil,and AAAI Conference on Artificial Intelligence, AAAI
Hannaneh Hajishirzi. 2023. Self-rag: Learning to 2024,Thirty-SixthConferenceonInnovativeApplica-
retrieve,generate,andcritiquethroughself-reflection. tionsofArtificialIntelligence,IAAI2024,Fourteenth
CoRR,abs/2310.11511. Symposium on Educational Advances in Artificial
Intelligence,EAAI2014,February20-27,2024,Van-
JinzeBai,ShuaiBai,YunfeiChu,ZeyuCui,KaiDang,
couver,Canada,pages17754–17762.AAAIPress.
XiaodongDeng,YangFan,WenbinGe,YuHan,Fei
Huang,BinyuanHui,LuoJi,MeiLi,JunyangLin,
ShouyuanChen,ShermanWong,LiangjianChen,and
RunjiLin,DayihengLiu,GaoLiu,ChengqiangLu,
YuandongTian.2023a. Extendingcontextwindow
KemingLu,JianxinMa,RuiMen,XingzhangRen,
oflargelanguagemodelsviapositionalinterpolation.
XuanchengRen,ChuanqiTan,SinanTan,Jianhong
CoRR,abs/2306.15595.
Tu,PengWang,ShijieWang,WeiWang,Shengguang
Wu,BenfengXu,JinXu,AnYang,HaoYang,Jian
Yukang Chen, Shengju Qian, Haotian Tang, Xin Lai,
Yang,ShushengYang,YangYao,BowenYu,Hongyi
ZhijianLiu, SongHan, andJiayaJia.2023b. Lon-
Yuan,ZhengYuan,JianweiZhang,XingxuanZhang,
glora: Efficientfine-tuningoflong-contextlargelan-
YichangZhang,ZhenruZhang,ChangZhou,Jingren
guagemodels. CoRR,abs/2309.12307.
Zhou, Xiaohuan Zhou, and Tianhang Zhu. 2023a.
Qwentechnicalreport. CoRR,abs/2309.16609.
Yuyan Chen, Qiang Fu, Yichen Yuan, Zhihao Wen,
GeFan, DayihengLiu, DongmeiZhang, ZhixuLi,
Yushi Bai, Xin Lv, Jiajie Zhang, Yuze He, Ji Qi, Lei
andYanghuaXiao.2023c. Hallucinationdetection:
Hou, Jie Tang, Yuxiao Dong, and Juanzi Li. 2024.
Robustly discerning reliable answers in large lan-
Longalign: Arecipeforlongcontextalignmentof
guage models. In Proceedings of the 32nd ACM
largelanguagemodels. CoRR,abs/2401.18058.
InternationalConferenceonInformationandKnowl-
Yushi Bai, Xin Lv, Jiajie Zhang, Hongchang Lyu, edgeManagement,CIKM2023,Birmingham,United
JiankaiTang,ZhidianHuang,ZhengxiaoDu,Xiao Kingdom, October 21-25, 2023, pages 245–255.
Liu,AohanZeng,LeiHou,YuxiaoDong,JieTang, ACM.
and Juanzi Li. 2023b. Longbench: A bilingual,
multitaskbenchmarkforlongcontextunderstanding. HyungWonChung,LeHou,ShayneLongpre,Barret
arXivpreprintarXiv:2308.14508. Zoph,YiTay,WilliamFedus,EricLi,XuezhiWang,MostafaDehghani,SiddharthaBrahma,AlbertWeb- ChiHan,QifanWang,WenhanXiong,YuChen,Heng
son, Shixiang Shane Gu, Zhuyun Dai, Mirac Suz- Ji, and Sinong Wang. 2023. Lm-infinite: Simple
gun,XinyunChen,AakankshaChowdhery,Sharan on-the-fly length generalization for large language
Narang,GauravMishra,AdamsYu,VincentY.Zhao, models. CoRR,abs/2308.16137.
YanpingHuang,AndrewM.Dai,HongkunYu,Slav
Petrov, EdH.Chi, JeffDean, JacobDevlin, Adam HangfengHe,HongmingZhang,andDanRoth.2023.
Roberts, DennyZhou, QuocV.Le, andJasonWei. Rethinking with retrieval: Faithful large language
2022. Scalinginstruction-finetunedlanguagemodels. modelinference. CoRR,abs/2301.00303.
CoRR,abs/2210.11416.
XanhHo,Anh-KhoaDuongNguyen,SakuSugawara,
Tri Dao, Daniel Y. Fu, Stefano Ermon, Atri Rudra, andAkikoAizawa.2020. ConstructingAmulti-hop
andChristopherRé.2022. Flashattention: Fastand QAdatasetforcomprehensiveevaluationofreason-
memory-efficientexactattentionwithio-awareness. ingsteps. InProceedingsofthe28thInternational
InAdvancesinNeuralInformationProcessingSys- ConferenceonComputationalLinguistics,COLING
tems35: AnnualConferenceonNeuralInformation 2020, Barcelona, Spain (Online), December 8-13,
Processing Systems 2022, NeurIPS 2022, New Or- 2020,pages6609–6625.InternationalCommitteeon
leans,LA,USA,November28-December9,2022. ComputationalLinguistics.
Gautier Izacard and Edouard Grave. 2021. Distilling
Pradeep Dasigi, Kyle Lo, Iz Beltagy, Arman Cohan,
knowledgefromreadertoretrieverforquestionan-
NoahA.Smith,andMattGardner.2021. Adataset
swering. In9thInternationalConferenceonLearn-
of information-seeking questions and answers an-
ingRepresentations,ICLR2021,VirtualEvent,Aus-
chored in research papers. In Proceedings of the
tria,May3-7,2021.OpenReview.net.
2021ConferenceoftheNorthAmericanChapterof
theAssociationforComputationalLinguistics: Hu-
HuiqiangJiang,QianhuiWu,XufangLuo,Dongsheng
manLanguageTechnologies,NAACL-HLT2021,On-
Li,Chin-YewLin,YuqingYang,andLiliQiu.2023a.
line,June6-11,2021,pages4599–4610.Association
Longllmlingua: Accelerating and enhancing llms
forComputationalLinguistics.
in long context scenarios via prompt compression.
CoRR,abs/2310.06839.
Yiran Ding, Li Lyna Zhang, Chengruidong Zhang,
YuanyuanXu, NingShang, JiahangXu, FanYang,
ZhengbaoJiang,FrankF.Xu,LuyuGao,ZhiqingSun,
and Mao Yang. 2024. Longrope: Extending LLM
Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie
context window beyond 2 million tokens. CoRR,
Callan,andGrahamNeubig.2023b. Activeretrieval
abs/2402.13753.
augmentedgeneration. InProceedingsofthe2023
Conference on Empirical Methods in Natural Lan-
Zican Dong, Tianyi Tang, Junyi Li, and Wayne Xin
guageProcessing,EMNLP2023,Singapore,Decem-
Zhao. 2023. A survey on long text modeling with
ber 6-10, 2023, pages 7969–7992. Association for
transformers. CoRR,abs/2302.14502.
ComputationalLinguistics.
Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding,
Hongye Jin, Xiaotian Han, Jingfeng Yang, Zhimeng
JiezhongQiu,ZhilinYang,andJieTang.2022. GLM:
Jiang,ZiruiLiu,Chia-YuanChang,HuiyuanChen,
generallanguagemodelpretrainingwithautoregres-
and Xia Hu. 2024. LLM maybe longlm: Self-
siveblankinfilling. InProceedingsofthe60thAn-
extendLLMcontextwindowwithouttuning. CoRR,
nualMeetingoftheAssociationforComputational
abs/2401.01325.
Linguistics (Volume 1: Long Papers), ACL 2022,
Dublin, Ireland, May22-27, 2022, pages320–335. JeffJohnson,MatthijsDouze,andHervéJégou.2019.
AssociationforComputationalLinguistics. Billion-scale similarity search with GPUs. IEEE
TransactionsonBigData,7(3):535–547.
Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia,
JinliuPan,YuxiBi,YiDai,JiaweiSun,QianyuGuo, Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric
Meng Wang, and Haofen Wang. 2023. Retrieval- Wallace, and Colin Raffel. 2023. Large language
augmentedgenerationforlargelanguagemodels: A modelsstruggletolearnlong-tailknowledge. InIn-
survey. CoRR,abs/2312.10997. ternationalConferenceonMachineLearning,ICML
2023,23-29July2023,Honolulu,Hawaii,USA,vol-
MichaelR.Glass,GaetanoRossiello,Md.FaisalMah- ume 202 of Proceedings of Machine Learning Re-
bub Chowdhury, Ankita Rajaram Naik, Pengshan search,pages15696–15707.PMLR.
Cai,andAlfioGliozzo.2022. Re2g:Retrieve,rerank,
generate. CoRR,abs/2207.06300. ZixuanKe,WeizeKong,ChengLi,MingyangZhang,
QiaozhuMei,andMichaelBendersky.2024. Bridg-
KelvinGuu,KentonLee,ZoraTung,PanupongPasupat, ingthepreferencegapbetweenretrieversandllms.
and Ming-Wei Chang. 2020. Retrieval augmented CoRR,abs/2401.06954.
languagemodelpre-training. InProceedingsofthe
37thInternationalConferenceonMachineLearning, PatrickLewis,EthanPerez,AleksandraPiktus,Fabio
ICML2020,13-18July2020,VirtualEvent,volume Petroni,VladimirKarpukhin,NamanGoyal,Hein-
119ofProceedingsofMachineLearningResearch, richKüttler, MikeLewis, Wen-tauYih, TimRock-
pages3929–3938.PMLR. täschel,etal.2020. Retrieval-augmentedgenerationforknowledge-intensivenlptasks. AdvancesinNeu- HugoTouvron,ThibautLavril,GautierIzacard,Xavier
ralInformationProcessingSystems,33:9459–9474. Martinet,Marie-AnneLachaux,TimothéeLacroix,
BaptisteRozière,NamanGoyal,EricHambro,Faisal
Xianzhi Li, Samuel Chan, Xiaodan Zhu, Yulong Pei, Azhar,AurélienRodriguez,ArmandJoulin,Edouard
Zhiqiang Ma, Xiaomo Liu, and Sameena Shah. Grave,andGuillaumeLample.2023. Llama: Open
2023a. Are chatgpt and GPT-4 general-purpose and efficient foundation language models. CoRR,
solversforfinancialtextanalytics? Astudyonsev- abs/2302.13971.
eraltypicaltasks. InProceedingsofthe2023Confer-
enceonEmpiricalMethodsinNaturalLanguagePro- HarshTrivedi,NiranjanBalasubramanian,TusharKhot,
cessing: EMNLP2023-IndustryTrack,Singapore, and Ashish Sabharwal. 2022. Musique: Multi-
December6-10,2023,pages408–422.Association hopquestionsviasingle-hopquestioncomposition.
forComputationalLinguistics. Trans.Assoc.Comput.Linguistics,10:539–554.
HarshTrivedi,NiranjanBalasubramanian,TusharKhot,
YuchengLi,BoDong,FrankGuerin,andChenghuaLin.
andAshishSabharwal.2023. Interleavingretrieval
2023b. Compressingcontexttoenhanceinference
with chain-of-thought reasoning for knowledge-
efficiencyoflargelanguagemodels. InProceedings
intensive multi-step questions. In Proceedings of
ofthe2023ConferenceonEmpiricalMethodsinNat-
the61stAnnualMeetingoftheAssociationforCom-
uralLanguageProcessing,EMNLP2023,Singapore,
putational Linguistics (Volume 1: Long Papers),
December6-10,2023,pages6342–6353.Association
ACL2023,Toronto,Canada,July9-14,2023,pages
forComputationalLinguistics.
10014–10037. Association for Computational Lin-
guistics.
Xi Victoria Lin, Xilun Chen, Mingda Chen, Wei-
jia Shi, Maria Lomeli, Rich James, Pedro Ro-
JasonWei,XuezhiWang,DaleSchuurmans,Maarten
driguez,JacobKahn,GergelySzilvasy,MikeLewis,
Bosma,BrianIchter,FeiXia,EdH.Chi,QuocV.Le,
Luke Zettlemoyer, and Scott Yih. 2023. RA-DIT:
andDennyZhou.2022. Chain-of-thoughtprompting
retrieval-augmenteddualinstructiontuning. CoRR,
elicits reasoning in large language models. In Ad-
abs/2310.01352.
vancesinNeuralInformationProcessingSystems35:
AnnualConferenceonNeuralInformationProcess-
NelsonF.Liu,KevinLin,JohnHewitt,AshwinParan-
ingSystems2022,NeurIPS2022,NewOrleans,LA,
jape,MicheleBevilacqua,FabioPetroni,andPercy
USA,November28-December9,2022.
Liang. 2024. Lost in the middle: How language
models use long contexts. Trans. Assoc. Comput. Guangxuan Xiao, Yuandong Tian, Beidi Chen, Song
Linguistics,12:157–173. Han, and Mike Lewis. 2023. Efficient stream-
ing language models with attention sinks. CoRR,
YiLu,XinZhou,WeiHe,JunZhao,TaoJi,TaoGui, abs/2309.17453.
QiZhang,andXuanjingHuang.2024. Longheads:
Multi-headattentionissecretlyalongcontextpro- Shi-QiYan,Jia-ChenGu,YunZhu,andZhen-HuaLing.
cessor. CoRR,abs/2402.10685. 2024. Corrective retrieval augmented generation.
CoRR,abs/2401.15884.
BowenPeng,JeffreyQuesnelle,HongluFan,andEn-
Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Ben-
rico Shippole. 2023. Yarn: Efficient context win-
gio,WilliamW.Cohen,RuslanSalakhutdinov,and
dow extension of large language models. CoRR,
ChristopherD.Manning.2018. Hotpotqa: Adataset
abs/2309.00071.
fordiverse,explainablemulti-hopquestionanswer-
ing. InProceedingsofthe2018ConferenceonEm-
Hongjin Qian, Zheng Liu, Kelong Mao, Yujia Zhou,
pirical Methods in Natural Language Processing,
and Zhicheng Dou. 2024. Grounding language
Brussels,Belgium,October31-November4,2018,
modelwithchunking-freein-contextretrieval. CoRR,
pages 2369–2380. Association for Computational
abs/2402.09760.
Linguistics.
Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase,
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak
and Yuxiong He. 2020. Deepspeed: System opti-
Shafran,KarthikR.Narasimhan,andYuanCao.2023.
mizationsenabletrainingdeeplearningmodelswith
React: Synergizingreasoningandactinginlanguage
over100billionparameters. InKDD’20: The26th
models. InTheEleventhInternationalConference
ACMSIGKDDConferenceonKnowledgeDiscovery
on Learning Representations, ICLR 2023, Kigali,
and Data Mining, Virtual Event, CA, USA, August
Rwanda,May1-5,2023.OpenReview.net.
23-27,2020,pages3505–3506.ACM.
Ori Yoran, Tomer Wolfson, Ori Ram, and Jonathan
XinyueShen,ZeyuanChen,MichaelBackes,andYang Berant. 2023. Making retrieval-augmented lan-
Zhang. 2023. In chatgpt we trust? measuring guage models robust to irrelevant context. CoRR,
andcharacterizingthereliabilityofchatgpt. CoRR, abs/2310.01558.
abs/2304.08979.
Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang,
RaviTheja.2023. Evaluatingtheidealchunksizefora Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu,
ragsystemusingllamaindex. WendiZheng,XiaoXia,WengLamTam,ZixuanMa,YufeiXue,JidongZhai,WenguangChen,Zhiyuan Singapore,December6-10,2023,pages8807–8817.
Liu,PengZhang,YuxiaoDong,andJieTang.2023. AssociationforComputationalLinguistics.
GLM-130B:anopenbilingualpre-trainedmodel. In
TheEleventhInternationalConferenceonLearning GuidoZuccon,BevanKoopman,andRaziaShaik.2023.
Representations,ICLR2023,Kigali,Rwanda,May Chatgpt hallucinates when attributing answers. In
1-5,2023.OpenReview.net. AnnualInternationalACMSIGIRConferenceonRe-
search and Development in Information Retrieval
Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, intheAsiaPacificRegion,SIGIR-AP2023,Beijing,
Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, China,November26-28,2023,pages46–51.ACM.
Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan
Ma,YufeiXue,JidongZhai,WenguangChen,Peng
Zhang, Yuxiao Dong, and Jie Tang. 2022. GLM-
130B:anopenbilingualpre-trainedmodel. CoRR,
abs/2210.02414.
PeitianZhang, ZhengLiu, ShitaoXiao, NingluShao,
QiweiYe,andZhichengDou.2024a. Soaringfrom
4kto400k: Extendingllm’scontextwithactivation
beacon. CoRR,abs/2401.03462.
Tianjun Zhang, Shishir G. Patil, Naman Jain, Sheng
Shen,MateiZaharia,IonStoica,andJosephE.Gon-
zalez. 2024b. RAFT: adapting language model to
domainspecificRAG. CoRR,abs/2403.10131.
YueZhang,YafuLi,LeyangCui,DengCai,LemaoLiu,
TingchenFu,XintingHuang,EnboZhao,YuZhang,
YulongChen,LongyueWang,AnhTuanLuu,Wei
Bi,FredaShi,andShumingShi.2023. Siren’ssong
intheAIocean: Asurveyonhallucinationinlarge
languagemodels. CoRR,abs/2309.01219.
Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,
Xiaolei Wang, Yupeng Hou, Yingqian Min, Be-
ichenZhang,JunjieZhang,ZicanDong,YifanDu,
Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao
Jiang,RuiyangRen,YifanLi,XinyuTang,Zikang
Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen.
2023. A survey of large language models. CoRR,
abs/2303.18223.
LianminZheng,Wei-LinChiang,YingSheng,Siyuan
Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,
ZhuohanLi,DachengLi,EricP.Xing,HaoZhang,
JosephE.Gonzalez,andIonStoica.2023. Judging
llm-as-a-judgewithmt-benchandchatbotarena. In
AdvancesinNeuralInformationProcessingSystems
36: AnnualConferenceonNeuralInformationPro-
cessingSystems2023,NeurIPS2023,NewOrleans,
LA,USA,December10-16,2023.
ChuntingZhou,PengfeiLiu,PuxinXu,SrinivasanIyer,
JiaoSun,YuningMao,XuezheMa,AviaEfrat,Ping
Yu,LiliYu,SusanZhang,GargiGhosh,MikeLewis,
Luke Zettlemoyer, and Omer Levy. 2023. LIMA:
lessismoreforalignment. InAdvancesinNeural
InformationProcessingSystems36: AnnualConfer-
enceonNeuralInformationProcessingSystems2023,
NeurIPS2023,NewOrleans,LA,USA,December10
-16,2023.
Shengyao Zhuang, Bing Liu, Bevan Koopman, and
Guido Zuccon. 2023. Open-source large language
modelsarestrongzero-shotquerylikelihoodmodels
for document ranking. In Findings of the Associa-
tion for Computational Linguistics: EMNLP 2023,A AdditionalExperimentalResults Datasets ReAct(GPT-3.5-Turbo)
HotpotQA 49.60
A.1 ResultsofDifferentRetrievalStrategies
2WikiMultihopQA 41.86
Table6,Table7,andTable8displayallofoverall MuSiQue 27.81
performance results. We evaluate four different Average 39.76
retrieval strategies to analyze the performance of
LongRAG comprehensively. These strategies in- Table4: ResultsofReAct.
clude 200*7, 200*12, 500*3, and 500*5. For ex-
ample,"200*7"standsfor"chunksize*top-k". By
thatwhenknowledgeneedstoberetrieved,therele-
comparing these retrieval strategies, we observe
vantinformationisretrievedfromourlocalcorpus
that an intermediate value for the top-k setting
C. We have aligned the experimental parameters,
tends to yield superior performance. This phe-
and the results of the ReAct experiment are pre-
nomenonarisesfromtheextractor’sutilizationof
sentedinTable4.
thesourcelongparagraphsmappedfromtop-k re-
calledchunks. Toofewrecalledchunksmayresult B ExperimentalDetailsExplanation
in insufficient collection of extensive contextual
B.1 DetailsofBaselineReplication
information, while an excessive number may in-
troducemorenoise. Contrastingtheoutcomesof Self-RAG,CRAG,LongLoRA,andLongAlignpro-
200*7and500*3,wenoticethat,undercompara- ducetoolongresponses,makingitchallengingto
ble context length, a smaller chunk size coupled fairly compare them with our method using the
with a higher top-k recall number can maximize F1-scoreasanevaluationmetric. Inotherwords,
the acquisition of global information within the the long outputs result in lower scores for these
corpusspace,therebyexhibitingenhancedperfor- baselines. Therefore, we select the LLM with a
mance. These results confirm the efficacy of the strong ability of "instruction-following", such as
corecomponents(E andF)inoursystem. GPT-3.5-Turbo,andperformfew-shotICLontheir
outputs to produce the final answers. In the fol-
A.2 ComponentTransferability lowingparagraphs,wewillintroducethespecific
experimental details involved in reproducing the
We provide specific values in Figure 4 in sec-
resultsforSelf-RAGandCRAG.
tion 5.4 with experimental results (Table 9, Ta-
We employ the LangGraph library, integrated
ble 10 and Table 11) for all datasets, including
within the LangChain framework, to reproduce
HotpotQA,2WikiMultiHopQA,andMusiQue. In
Self-RAGandCRAG.Specifically,Self-RAGem-
2WikiMultiHopQA and HotpotQA, our system
ploysanadaptiveretrievalbasedonself-reflection.
alsoexhibitscomponenttransferabilitysimilarto
IftheLLMidentifiestheretrievedchunksasirrele-
that in MusiQue. We conducted all experiments
vant,orthegeneratedoutputsareregardedasunan-
usingChatGLM3-6B-32kwithSFTasarelatively
swerable,Self-RAGwillrestartthesearchandan-
low-costlocalmodel.
swerprocessuntilthemaximumnumberofrounds.
Inourexperiments,wesetthemaximumnumberof
A.3 AnalysisofTokenLengthTrends
retrievalroundsto3. If,uponreachingthisround
Figure3onlyshowsthetokenlengthtrendusing
limit,allretrieveddocumentsarestillconsidered
ChatGLM3-6B-32kwithSFTacrossfivestrategies.
irrelevant,therearetwoanswerstrategies: Thefirst
The specific values and the results of using more
strategyusesallchunksretrievedduringthefinal
built-in fine-tuned LLMs are shown in Table 12,
round,whilethesecondstrategyinvolvesanswer-
Table13,andTable14.
ingwithoutusingtheretrievedchunks. InTable1
ofthemainpaper,wereporttheresultsofthefirst
A.4 AdditionalBaselineResults
strategy,whichshowshigherresultsthanthoseof
As an agent framework, ReAct can also be in- the second strategy. Additionally, we present the
stantiated as an efficient RAG system based on performanceofthesecondstrategyinTable5.
adaptive retrieval (Yao et al., 2023). ReAct CRAG has implemented a fallback strategy to
can answer questions through the process of preventasteepdeclineinresponsequalitydueto
"Thought/Action/Observation". Inourexperiment, all retrieved chunks being filtered out. When the
wedefine"Action"astheretrievalaction,meaning retrievedchunksareconsideredinsufficienttoan-Datasets Self-RAG(GPT-3.5-Turbo) generated instruction data, we mark prompts in
each pipeline as [STEP] and instruction data as
HotpotQA 44.99
2WikiMultihopQA 19.79 [RESULT].Thefollowingparagraphswillelabo-
MuSiQue 23.49 rateontheconstructiondetailsandpipelines.
Table5: ResultsofSelf-RAGviathesecondstrategy. C.1 DataPre-Processing
Wefurtherdetailtherandomstrategy. Thenumber
ofdistractingparagraphsP inourinstructiondata
swerthequestion,itissupplementedwithexternal d
israndomlychosenwithinaspecificrange, from
knowledge retrieved from the web. For a fair re-
twouptothetotallengthofP ,mathematicallyex-
production in our experiments, when faced with d
pressedas[2,maxLen(P )]. Moreover,wefurther
similarissues,werewritethequestionandconduct d
detail how to discard any question-answer pairs
anotherretrievalfromourcorpusC. Sinceourcor-
withinsufficientcontextlength. Here,"insufficient
puscontainsalltherelevantinformationnecessary
contextlength"meansthatthetotaltokenlengthof
toanswerthequestion,wedonotneedtoretrieve
allcorrespondingparagraphsprovidedforaques-
externalknowledgefromtheweb.
tionislowerthanaspecificthreshold. Specifically,
B.2 DetailsoftheCorpus weuseathresholdof1.5kforHotpotQAand2Wiki-
MultiHopQA,and2.5kforMusiQue. Duringthe
Ourexperimentaldatasetsandthecorpususedfor
experiment,wefindthatthisthresholdsettingpre-
knowledgeretrievalareconstructedbasedonLong-
serveslong-contextsamples,enablingthemodelto
Bench. Themulti-hopQAdatasetsofLongBench
learnlong-contextstylesandretainsufficientdata
include questions, answers, and multiple corre-
for training. For QASPER, we do not filter any
sponding paragraphs concatenated to form long
samplesbecausethepapersareinherentlylong.
contextsofeachquestion. ToadaptitfortheRAG
system,wesplitlongcontextsintoindividualcor- C.2 Long-ContextExtractorData
responding paragraphs. Since each paragraph is
In the construction pipeline (Table 16) for LLM-
a semantically coherent and complete Wikipedia
augmentedextractordata,weaimtofeedtheques-
paragraph, we treat each paragraph p as an inde-
tion and P into the LLM, which outputs all the
pendentknowledgeunit. Afterdeduplication,the s
relevant information for answering the question.
paragraphsfromallquestionsformthecorpusC.
We provide the specific construction process and
details shown in Table 16. We construct the ini-
C DetailsofLRGinstruction
tial dataset via [STEP-1], which global informa-
Weconstructaninstructiondatasetforfine-tuning, tionasgoldoutputs. Iftheresponseof[STEP-1]
comprising four types of data, each designed to is particularly short, we discard it due to a small
enhance the"instruction-following" capabilityof amount of effective information, with a discard
corresponding components. The four types of thresholdof20tokens. Subsequently,in[STEP-2],
dataincludeLong-ContextExtractordata,CoT- weperformaself-evaluatorofthegoldoutputafter
guidingData,FilteringData,andTask-Oriented [STEP-1]. Onlysamples thatpass thevalidation
Data. To be specific, long-context extractor data (i.e., those for which the output in [STEP-2] is
isutilizedtoenhancethecapabilitiesoftheLLM- "True")areincludedinthefinalinstructiondataset.
augmentedextractor. CoT-guidingdataandfilter- The final [RESULT] presents the ultimate gold
ing data are applied to strengthen the abilities of data(long-contextextractordata)inthispipeline,
thetwo-stageCoT-guidedfilter. Questionandan- and"{content}"representsP includingbothP
s
swer data are utilized to enhance the generator’s and selected P by random strategy. This type
d
capability,learningthespecificansweringstylere- ofdataenhancestheLLM-augmentedextractorto
quired for tasks. We present examples of all the identify valuable evidence information from sub-
pipelines used for data construction and formats stantiallengthycontextsourceparagraphs.
of the generated data (golden data) in Table 16,
C.3 CoT-guidingData&FilteringData
Table17andTable18. Specificexamplesoffour
types of golden data are also shown in Table 19, In the CoT-guided filter, we employ a two-
Table20,Table21andTable22. Toclearlydistin- stage strategy to precisely and flexibly screen
guish between promptsfor data construction and problem-relatedchunkswhilediscardingredundantchunks. Thetwotypesofdata,CoT-guidingdata andCoT-guidingdata)usingtheQASPERdataset,
([RESULT-1]) and filtering data ([RESULT-2]) each type of data with 100 samples, and each in-
aimtoenhancethe"instruction-following"ability structiondatalengthrangingfrom6k-29k. Welist
of the two-stage components of the CoT-guided thestatisticsofourfine-tuninginstructiondataset
filter,andbetteridentifyfactualdetails. Thiscon- inTable15.
struction pipeline and final constructed data are
D PromptsofLongRAGSystem
showninTable17. First,in[STEP-1],wegenerate
a guiding CoT by inputting the question and all
WepresentallpromptsinLongRAG’scomponents
corresponding P . The generated CoT provides
s inTable23. The"{content}"indifferentprompts
global clues for question-answering by perform-
representdifferentcontextualinformation. Tobe
ingin-contextlearninginallretrievedchunks. If
specific, the"{content}"inthepromptofLLM-
theCoTisparticularlyshort,weconsideritalow-
augmented information extraction represents all
qualityclueanddiscardit,withadiscardthreshold
sourcelong-contextparagraphspafterthemapping
of20tokens. In[STEP-2],wethenperformaself-
strategy. InthepromptoftheCoTguidancestage
evaluator of the guiding CoT [STEP-1] to verify
intheCoT-guidedfilter, itrepresentsallretrieval
thefeasibilityoftheCoTinrespondingtotheques-
chunksp ,whileinthepromptofthefilteringstage,
c
tion. Intheself-evaluator,weusetheanswersfrom
itrepresentseachp .
c
the raw dataset as the basis for judging the qual-
ity of CoT. [RESULT-1] displays the instruction E AnswerExamples
dataconstructedfortheCoT-guidedstage,named
We provide answer examples shown in Table 24,
CoT-guidingdata,and"{content}"representsP
Table25,andTable26. LongRAGaddressestheis-
includingbothP andselectedP byrandomstrat-
s d
suesofincompleteinformationand"lostinthemid-
egy. Finally, for the filtering stage, we treat each
dle"foundinVanillaRAGandRAG-Long,while
paragraphpasaunitandregardgivenbinarydis-
requiringfewertokensinputtedintothegenerator
crete labels in the raw dataset as gold labels, ex-
yetshowingsuperiorresponseperformance.
pressedas{status}in[RESULT-2]. Thefiltering
stage instruction data is shown in [RESULT-2].
Its"{content}"representseachparagraphp ∈ P.
It is worth noting that in the original dataset, the
numberofpmarkedas"True"ismuchlowerthan
"False". Toensuretheuniformityofthedistribu-
tion,weselect100sampleswithastatusof"True"
and100sampleswithastatusof"False".
C.4 Task-OrientedData
Thequestionsandanswersarealreadyprovidedin
theoriginaldatasets. Westandardizetheirformat
to construct the question-answering data (see Ta-
ble18)inourfine-tuninginstructiondataset. The
"{content}"in[RESULT]representsP including
bothP andselectedP byrandomstrategy.
s d
C.5 StatisticsofLRGinstruction
Tosumup,wederivefourtypesofdatafromthe
trainingsetsoftheHotpotQA,2WikiMultiHopQA,
andMusiQuedatasets,witheachtypeofdatacon-
taining200samples. Thisresultsin800samples
perdatasetandatotalof2400samplesacrossthe
three datasets. The token length of each instruc-
tiondataislessthan7k. Furthermore,toadaptour
RAG system to long-context QA, we also derive
twotypesofdata(i.e.,long-contextextractordataModel HotpotQA
200*7 200*12 500*3 500*5
#RAGBase(VanillaRAG)#
ChatGLM3-6B-32k 52.57 53.10 47.72 51.17
Qwen1.5-7B-32k 45.70 49.20 44.43 44.16
Vicuna-v1.5-7B-16k 38.63 34.35 37.23 35.32
Llama3-8B-8k 48.25 51.69 47.12 50.88
GPT-3.5-Turbo 52.31 55.21 52.84 51.21
GPT-3.5-Turbo-16k 50.17 53.58 48.02 48.84
Llama3-70B-8k 52.33 53.53 49.51 51.38
GLM-4 57.41 59.55 53.71 58.45
#OurswithSFT#
LongRAG-ChatGLM3-6B-32k 55.93 54.36 50.72 54.67
LongRAG-Qwen1.5-7B-32k 52.91 52.27 49.70 50.69
LongRAG-Vicuna-v1.5-7B-16k 55.55 54.79 52.26 52.89
LongRAG-Llama3-8B-8k 52.39 52.00 49.05 54.62
#OurswithoutSFT#
LongRAG-GPT-3.5-Turbo 56.17 56.06 55.63 55.11
LongRAG-GPT-3.5-Turbo-16k 59.11 51.55 48.45 55.57
LongRAG-GLM-4 62.11 60.55 55.36 61.14
Table6: OverallperformanceofourLongRAGonHotpotQAdataset.Model 2WikiMultiHopQA
200*7 200*12 500*3 500*5
#RAGBase(VanillaRAG)#
ChatGLM3-6B-32k 42.56 38.71 40.65 42.34
Qwen1.5-7B-32k 34.69 34.79 34.47 35.24
Vicuna-v1.5-7B-16k 27.92 26.39 32.76 26.36
Llama3-8B-8k 43.47 40.01 30.48 41.44
GPT-3.5-Turbo 43.44 40.06 43.17 39.69
GPT-3.5-Turbo-16k 45.32 39.09 43.31 42.49
Llama3-70B-8k 50.23 48.91 46.61 50.10
GLM-4 52.91 52.37 49.48 51.06
#OurswithSFT#
LongRAG-ChatGLM3-6B-32k 54.85 58.51 49.28 53.51
LongRAG-Qwen1.5-7B-32k 46.65 45.23 42.96 44.55
LongRAG-Vicuna-v1.5-7B-16k 50.13 50.93 47.45 48.02
LongRAG-Llama3-8B-8k 49.67 51.41 43.80 49.70
#OurswithoutSFT#
LongRAG-GPT-3.5-Turbo 51.37 56.55 48.16 48.60
LongRAG-GPT-3.5-Turbo-16k 51.25 45.45 44.08 44.21
LongRAG-GLM-4 57.16 52.90 44.93 50.05
Table7: OverallperformanceofourLongRAGon2WikiMultiHopQAdataset.Model MusiQue
200*7 200*12 500*3 500*5
#RAGBase(VanillaRAG)#
ChatGLM3-6B-32k 25.51 25.91 24.31 25.63
Qwen1.5-7B-32k 25.08 23.51 21.08 22.05
Vicuna-v1.5-7B-16k 15.68 14.55 16.05 13.89
Llama3-8B-8k 19.66 23.65 19.33 22.51
GPT-3.5-Turbo 25.22 28.23 25.34 27.06
GPT-3.5-Turbo-16k 21.84 25.41 24.80 23.79
Llama3-70B-8k 25.49 27.72 23.05 24.13
GLM-4 27.55 33.93 27.92 27.56
#OurswithSFT#
LongRAG-ChatGLM3-6B-32k 33.00 33.12 30.09 31.98
LongRAG-Qwen1.5-7B-32k 31.85 32.22 27.25 25.84
LongRAG-Vicuna-v1.5-7B-16k 28.29 33.76 29.42 29.89
LongRAG-Llama3-8B-8k 31.70 38.19 33.90 29.57
#OurswithoutSFT#
LongRAG-GPT-3.5-Turbo 32.83 32.64 29.83 28.03
LongRAG-GPT-3.5-Turbo-16k 30.37 32.11 28.96 26.58
LongRAG-GLM-4 38.40 39.68 34.67 33.05
Table8: OverallperformanceofourLongRAGonMusiQuedataset.HotpotQA
Generator
E&Fw/SFT
R&B E&Fw/oSFT
(ChatGLM3-6b-32k)
LongRAG-GPT-3.5-Turbo-16k 50.17 59.11 57.82
LongRAG-GPT-3.5-Turbo 52.31 56.17 59.09
LongRAG-GLM-4 57.41 62.11 59.20
Table9: AnalysisofthecomponenttransferabilityofE&FonHotpotQAdataset.
2WikiMultiHopQA
Generator
E&Fw/SFT
R&B E&Fw/oSFT
(ChatGLM3-6b-32k)
LongRAG-GPT-3.5-Turbo-16k 45.32 51.25 57.86
LongRAG-GPT-3.5-Turbo 43.44 51.37 54.62
LongRAG-GLM-4 52.91 57.16 55.96
Table10: AnalysisofthecomponenttransferabilityofE&Fon2WikiMultiHopQAdataset.
MusiQue
Generator
E&Fw/SFT
R&B E&Fw/oSFT
(ChatGLM3-6b-32k)
LongRAG-GPT-3.5-Turbo-16k 21.84 30.37 34.52
LongRAG-GPT-3.5-Turbo 25.22 32.83 34.28
LongRAG-GLM-4 27.55 38.40 36.89
Table11: AnalysisofthecomponenttransferabilityofE&FonMusiQuedataset.HotpotQA
Model
R&B R&L Ext. Fil. E&F
LongRAG-ChatGLM3-6B-32kw/SFT 2181 10669 2254 1160 1233
LongRAG-Qwen1.5-7B-32kw/SFT 2181 10669 2248 1260 1327
LongRAG-Vicuna-v1.5-7B-16kw/SFT 2181 10596 2270 1233 1321
LongRAG-Llama3-8B-8kw/SFT 2181 7428 2243 1101 1163
Table12: ValuesofthetokenlengthfedintothegeneratoronHotpotQAdataset.
2WikiMultiHopQA
Model
R&B R&L Ext. Fil. E&F
LongRAG-ChatGLM3-6B-32kw/SFT 2086 8096 2171 937 1022
LongRAG-Qwen1.5-7B-32kw/SFT 2086 8096 2162 941 1016
LongRAG-Vicuna-v1.5-7B-16kw/SFT 2086 8096 2176 937 1027
LongRAG-Llama3-8B-8kw/SFT 2086 6744 2150 813 876
Table13: Valuesofthetokenlengthfedintothegeneratoron2WikiMultiHopQAdataset.
MusiQue
Model
R&B R&L Ext. Fil. E&F
LongRAG-ChatGLM3-6B-32kw/SFT 2141 15062 2217 975 1051
LongRAG-Qwen1.5-7B-32kw/SFT 2141 15062 2198 1050 1108
LongRAG-Vicuna-v1.5-7B-16kw/SFT 2141 14520 2240 995 1094
LongRAG-Llama3-8B-8kw/SFT 2141 7711 2196 828 883
Table14: ValuesofthetokenlengthfedintothegeneratoronMusiQuedataset.Datasets HotpotQA 2WikiMultiHopQA MusiQue QASPER
Numoflong-contextextractordata 200 200 200 100
NumofCoT-guidingdata 200 200 200 100
Numoffilteringdata 200 200 200 -
Numoftask-orienteddata 200 200 200 -
Numofsamples 800 800 800 200
Table15: Statisticsofourfine-tuninginstructiondatasetLRGinstruction.[STEP-1]: DataconstructionpromptforExtractor
{supporting paragraphs}
Based on the above background only, please output the original information that
needs to be cited to answer the following questions. Please ensure that the
information cited is detailed and comprehensive.
Question:{question}
Output only the original information of the required reference:
{global information}
[STEP-2]: AnLLM-basedself-evaluatorforExtractor
I am going to provide you with a question, the background information, and
the answer to that question. Please evaluate whether the answer can be solely
derived from the given background information. If it can, set the status value
as True, if it can’t, set the status value as False.
Question:{question}
Background Information:{global information}
Answer:{answer}
Your output format should be the following json format:
status: {the value of status}
[RESULT]:Long-ContextExtractorDataforExtractor
Instruction:
{content}
Based on the above background, please output the information you need to cite
to answer the question below.
{question}
Output:
{global information}
Table16: Dataconstructionpipelineforextractorandformatillustrationoflong-contextextractordata.[STEP-1]: DataconstructionpromptforCoTguidancestage
{supporting paragraphs}
Given question:{question}
The answer is:{answer}
Your task is to give your thought process for this given question based
on the above information, only give me your thought process and do not output
other information.
Thought process: {CoT}
[STEP-2]: AnLLM-basedself-evaluatorforCoTguidancestage
Question:{question}
Thought process of the question:{CoT}
Answer:{answer}
Please evaluate whether the thought process of this question can explain
the answer to this question. If it can explain the answer, set the value of
status to True. If it cannot explain the answer, set the value of status to
False. Your output format should be the following json format:
status: {the value of status}
[RESULT-1]: CoT-guidingDataforCoTguidancestage
Instruction:
{content}
Please combine the above information and give your thought process for the
following
Question:{question}
Output:
{CoT}
[RESULT-2]: FilteringDataforfilteringstage
Instruction:
Given an article:{content}
Question:{question}
Thought process for the question:{CoT}
Your task is to use the thought process provided to decide whether you
need to cite the article to answer this question. If you need to cite the
article, set the status value to True. If not, set the status value to False.
Please output the response in the following json format:
{"status": {the value of status}}
Output:
{status}
Table17: Dataconstructionpipelineforfilter,andformatillustrationofCoT-guidingandfilteringdata.[RESULT]:Task-OrientedDataforRAGtask
Instruction:
{content}
Based on the above information, Only give me the answer and do not output any
other words.
Question:{question}
Output:
{answer}
Table18: DataconstructionpipelineforRAGtask,andformatillustrationoftask-orienteddata.Instruction:
Alan Marshal (actor)Alan Marshal( 29 January 1909 – 9 July 1961) was an
actor who performed on stage in the United States and in Hollywood films. He was
sometimes billed as Alan Marshall or Alan Willey. Hans Tambs LycheHans Tambs
Lyche( 21 November 1859 – 16 April 1898) was a Norwegian engineer, unitarian
minister, journalist and magazine editor.
Alan DeyermondAlan Deyermond FBA( 24 February 1932 – 19 September 2009)
was a British professor of Medieval Spanish Literature and Hispanist. His
obituary cited him as " the English- speaking world’s leading scholar of
medieval Hispanic literature. " He spent his academic career associated with
one University of London college, Westfield College( later merged with Queen
Mary College, to form Queen Mary and Westfield College).
Deyermond started his career in 1955 as a lecturer at Westfield College,
London. When Westfield merged with Queen Mary College in 1992, he moved to the
Mile End site. In the period 1978 – 1980 he held a joint chair at Westfield and
at Princeton University.
Ralph Tambs-LycheRalph Tambs- Lyche ( 6 September 1890 – 15 January 1991) was
a Norwegian mathematician. He was born in Macon, Georgia as a son of Norwegian
father Hans Tambs Lyche( 1859 – 1898) and American mother Mary Rebecca Godden(
1856 – 1938). He moved to Norway at the age of two.
......
Alan M. WaldAlan Maynard Wald, usually Alan M. Wald or Alan Wald, is an
American professor emeritus of English Literature and American Culture at
the University of Michigan, Ann Arbor, and writer of 20th-Century American
literature who focuses on Communist writers; he is an expert on the American
20th-Century "Literary Left. " Allen SangreeAllen Luther Sangree, also as
Allan or Alan( c. 1878 – March 2, 1924) was an American sports writer and war
journalist.
Based on the above background, please output the information you need to
cite to answer the question below.
Who died earlier, Hans Tambs Lyche or Alan Deyermond?
Output:
Hans Tambs Lyche (21 November 1859 – 16 April 1898) was a Norwegian
engineer, unitarian minister, journalist, and magazine editor. Alan Deyermond
(24 February 1932 – 19 September 2009) was a British professor of Medieval
Spanish Literature and Hispanist.
Table19: Anexampleoflong-contextextractordataofLRGinstruction.Instruction:
Beatrice of Castile, Marchioness of MontferratBeatrice of Castile (5 November
or 6 December 1254 - 1286) was a daughter of Alfonso X of Castile and his wife
Violant of Aragon. She was Marchioness of Montferrat by her marriage and was
mother of Irene of Montferrat.
Theodred II (Bishop of Elmham)Theodred II was a medieval Bishop of Elmham.
The date of Theodred’s consecration unknown, but the date of his death was
sometime between 995 and 997. Irene of MontferratYolande of Montferrat (– 1317
in Constantinople) (also known as Violante, then Empress Irene) was the second
wife of Andronikos II Palaiologos and thus empress of the Byzantine Empire. She
was the heir of the Margraviate of Montferrat. Born in Casale, she was daughter
of William VII, Marquess of Montferrat and his second wife Beatrice of Castile.
Her maternal grandparents were King Alfonso X of Castile and his wife Violante
of Aragon. Yolande (variation of Violante) was named after her grandmother.
In 1284, Andronikos II, a widower by his first marriage with Anna of
Hungary, married Yolanda (who was renamed Eirene as Empress). She and
Andronikos II were distant cousins, both being descendants of Andronikos Doukas
Angelos (ca. 1122-1185). With her, Eirene brought the Montferrat rights to
the kingdom of Thessalonica, a dominion that, despite having been conquered
half-a-century before Eirene’s birth by the Byzantine state of Epirus, was
still claimed by its short-lived (1204–1224) Montferrat royal dynasty.
......
Henry, Marquess of MontferratHenry( c.1020 -c.1044/5) was a member of
the Aleramid dynasty. He was a younger son of William III of Montferrat and
Waza. From 1042, he was co-ruler of the March of Montferrat with his older
brother Otto II of Montferrat. Probably in 1041, certainly before 19 January
1042, he married Adelaide of Susa, the heiress of the March of Turin, which
temporarily united the two great northwestern Italian marches of Turin and
Montferrat.
Please combine the above information and give your thought process for
the following
Question: What is the date of death of Irene Of Montferrat’s father?
Output:
To find the date of death of Irene Of Montferrat’s father, we can look
at the information provided about William VII, Marquess of Montferrat. It
states that he died on 6 February 1292. Since Irene was born around 1253,
William VII would have been her father. Therefore, the date of death of Irene
Of Montferrat’s father is 6 February 1292.
Table20: AnexampleofCoT-guidingdataofLRGinstruction.Instruction:
Given an article:"Awaiting on You All" is a song by English musician
George Harrison, released on his 1970 triple album, "All Things Must Pass".
Along with the single "My Sweet Lord", it is among the more overtly religious
compositions on "All Things Must Pass", and the recording typifies co-producer
Phil Spector’s influence on the album, due to his liberal use of reverberation
and other Wall of Sound production techniques.
Harrison recorded the track in London backed by musicians such as Eric
Clapton, Bobby Whitlock, Klaus Voormann, Jim Gordon and Jim Price – many of whom
he had toured with, as Delaney & Bonnie and Friends, in December 1969, while
still officially a member of the Beatles. Musically, the composition reflects
Harrison’s embracing of the gospel music genre, following his production of
fellow Apple Records artists Billy Preston and Doris Troy.
......
A similarly well-regarded live version, with backing from a large band
including Clapton, Ringo Starr, Preston and Jim Keltner, was released on the
1971 album "The Concert for Bangladesh" and appeared in the 1972 film of the
same name. Harrison’s posthumous compilation (2012) includes a demo version of
the song, recorded early in the 1970 sessions for "All Things Must Pass".
Question: What is the date of death of the performer of song Awaiting On You All?
Thought process for the question:The question asks for the date of death
of the performer of the song "Awaiting on You All." We know from the given
information that the song was written and performed by English musician George
Harrison. To find his date of death, we can look for the date of death of
George Harrison in the text. We find that George Harrison died on 29 November
2001. Therefore, the answer to the question is 29 November 2001.
Your task is to use the thought process provided to decide whether you
need to cite the article to answer this question. If you need to cite the
article, set the status value to True. If not, set the status value to False.
Please output the response in the following json format:
{"status": {the value of status}}
Output:
{"status": {"True"}}
Table21: AnexampleoffilteringdataofLRGinstruction.Instruction:
My Name Is Anthony Gonsalves (film) My Name Is Anthony Gonsalves is a
Bollywood drama film starring newcomer Nikhil Dwivedi, Amrita Rao and Mithun
Chakraborty as the lead protagonists. The film is directed by Eeshwar Nivas.
The name of the movie is derived from the 1977 hit movie Amar Akbar Anthony’s
famous song," My Name Is Anthony Gonsalves." It was released on 11 January 2008
and was a box office bomb.
My Name Is JuaniMy Name Is Juani is a 2006 Spanish drama film written
and directed by Bigas Luna. My Name Is BanduMy Name is Bandu is a 2015 Sri
Lankan Sinhala comedy, family film directed by Suranga de Alwis and produced
by Suranga de Alwis. It stars Bandu Samarasinghe, and Anusha Damayanthi in
lead roles along with Rodney Warnakula, Roy de Silva and Mark Samson. Music
for the film is done by Sarath de Alwis. The film is the 85th film of Bandu
Samarasinghe. It is the 1239th Sri Lankan film in the Sinhala cinema.
My Name Is KhanMy Name Is Khan is a 2010 Indian Hindi- language drama
film directed by Karan Johar, produced by Hiroo Johar and Gauri Khan, and
starring Shah Rukh Khan and Kajol in lead roles.
......
The film stars Shakib Khan and Sahara in the lead roles, with Ahmed
Sharif, Misha Shoudagor, Probir Mitro and Rahena Joli playing other significant
roles in the film.
My Name Is Sultan was released on 20 August 2012. Leslie, My Name Is
EvilLeslie, My Name Is Evil is a 2009 Canadian film written and directed by
Reginald Harkema. It was renamed" Manson, My Name Is Evil" after its initial
release.
My Name Is NobodyMy Name Is Nobody is a 1973 comedy spaghetti western
starring Terence Hill and Henry Fonda. The film was directed by Tonino Valerii.
My Name Is Rocco PapaleoMy Name Is Rocco Papaleo is a 1971 Italian comedy film
directed by Ettore Scola.
Based on the above information, Only give me the answer and do not output any
other words.
Question: Which film was released more recently, My Name Is Bandu or Leadbelly
(Film)?
Answer:
Output:
My Name Is Bandu
Table22: Anexampleoftask-orienteddataofLRGinstruction.PromptofLLM-augmentedinformationextractor
Instruction:
{content}
Based on the above background, please output the information you need to cite
to answer the question below.
{question}
Output:
{global information}
PromptofCoTguidancestageinCoT-guidedfilter
Instruction:
{content}
Please combine the above information and give your thought process for the
following
Question:{question}
Output:
{CoT}
PromptoffilteringstageinCoT-guidedfilter
Instruction:
Given an article:{content}
Question:{question}
Thought process for the question:{CoT}
Your task is to use the thought process provided to decide whether you
need to cite the article to answer this question. If you need to cite the
article, set the status value to True. If not, set the status value to False.
Please output the response in the following json format:
{"status": {the value of status}}
Output:
{status}
PromptofLLM-augmentedgenerator
Instruction:
{content}
Based on the above information, Only give me the answer and do not output any
other words.
Question:{question}
Output:
{answer}
Table23: AllpromptsofLongRAGsystem.Question: WheredidtheperformerofsongI’llSayItgraduatefrom?
Inputtogenerator(2082tokens):
Answerthequestionbasedonthegivenpassages. Onlygivemetheansweranddonotoutputany
other words. The following are given passages. The duo promoted the song by performing it on
varioustelevisionshowsandatvariousvenues,ofwhichincludedGMTVandSonyEricsson’sDance
Nation Festival. Thiswas plannedto be the first singleofftheband ’ssecond studioalbumSay It
Now,whichwasscheduledforreleaseinNovember2009,butduetothelowchartplacingof"SayIt",
thealbumwaseventuallycancelled. Background"SayIt"waswrittenbyCarlBjörsell,DidrikThott
andSebastianThott.
......
Wejustwanttoshowprogression."ThesongwascomposedinakeyofCsharpminorandrunsata
tempoof126.96beatsperminute. Thesongwasproducedwithconsistenceofvariousdrumandbass
and electronica instrumentation.Passage 1: I ’ll Say It "I ’ll Say It" is a song written by American
musician Adam Schlesinger and recorded by comedian Kathy Griffin, released as the theme song
forhershow,Kathy. Itwasadditionallyusedastheintroductionmusictoher2012comedyspecial
"KennedieCenteronHers"andcontinuedtobeusedinfuturespecials. OnAugust20,2012,Griffin
releasedaseventrackEPcontainingdanceremixesof"I’llSayIt". MusicvideoThemusicvideo
beginsinthedaywithKathyGriffininherhousepreparinghermake-up. Itshowsherdailyroutine
visitingherdogs,leavingthehouseanddrivingtoatheater,endingwithheronstageinhersignature
pose. The scenes are interlaced with various clips of Los Angeles, California.Passage 10: Say It
(BootyLuvsong)"SayIt"isasongbyfemaleEnglishdancemusicduoBootyLuv.
......
FilmographyFilmTelevisionOtherStand-upspecialsDiscographyOnJune10,2008,Griffinreleased
acomedyCDtitledForYourConsideration. ThediscwasrecordedattheETKTheatreattheGrand
TheatreCenterForTheArtsinTracy,CaliforniaonFebruary17,2008. Griffinstatedshedecidedto
releasetheCDtotrytowinaGrammyaward.OnAugust25,2009,Griffinreleasedasecondcomedy
album,Suckin’ItfortheHolidays,inanotherbidforaGrammy. GriffinreceivedherthirdGrammy
nominationforKathyGriffin: DoestheBibleBeltin2010,.OnMay4,2012,thefulllengthversion
of"I’llSayIt",thethemesongofhershowKathy,wasreleasedtoiTunesasasingle. OnAugust
20,2012,Griffinreleasedaseven-trackEPcontainingdanceremixesof"I’llSayIt". Bibliography
OfficialBookClubSelection: AMemoirAccordingtoKathyGriffin. BallantineBooks. 2009. ISBN
978-0345518569. KathyGriffin’sCelebrityRun-Ins: MyA-ZIndex. FlatironBooks. 2016. ISBN
978-1250115638. Song went on a five-year hiatus from acting. She became an adjunct professor
and part-time lecturer at Seoul Arts College in 2010, as a faculty member of the Department of
PerformingArtsandtheDepartmentofBroadcasting,EntertainmentandVisualArts.
......
AsherRothsampledthesongforhisdebutrapsingle"ILoveCollege". Afterthesongleakedonto
the internet, Rivers Cuomo reportedly refused to clear the sample, which prompted Roth to debut
aremixedversionofhissongashisofficialdebutsingle. Answerthequestionbasedonthegiven
passages. Onlygivemetheansweranddonotoutputanyotherwords.
Question: WheredidtheperformerofsongI’LlSayItgraduatefrom?
Answer:
AnswerofRAG-base: SeoulArtsCollege✗
GoldenAnswer: LeeStrasbergTheatreandFilmInstitute✓
WrongReason: Incompletekeyinformation
Table24: Aquestion-answeringexampleofVanillaRAG(RAG-Base). Thewordsinthegreenareaindicatecorrect
relevantinformationandanswerswhileredmeanstheopposite. Thebluesnippetsarequestion-relevantinformation.
Thecorrectanswerislabeled"✓",whilewronganswerlabeled"✗".Question: WheredidtheperformerofsongI’LlSayItgraduatefrom?
Inputtogenerator(23047tokens):
Answerthequestionbasedonthegivenpassages. Onlygivemetheansweranddonotoutputany
otherwords.Thefollowingaregivenpassages.
......
Thegirlsthenheaddownstairstoaminicasinowheretheygamble. Thegirlsarethenseenagainst
variousbackgroundsandlayingonchairs. Finally,thegirlshaveapartyintheirhotelroomandinvite
their friends and some men to their hotel rooms, before sending them away. Chart performance
Weekly charts Year-end charts Passage 1: I’ll Say It"I’ll Say It" is a song written by American
musician Adam Schlesinger and recorded by comedian Kathy Griffin, released as the theme song
forhershow,Kathy. Itwasadditionallyusedastheintroductionmusictoher2012comedyspecial
"KennedieCenteronHers"andcontinuedtobeusedinfuturespecials. OnAugust20,2012,Griffin
releasedaseventrackEPcontainingdanceremixesof"I’llSayIt". MusicvideoThemusicvideo
beginsinthedaywithKathyGriffininherhousepreparinghermake-up. Itshowsherdailyroutine
visitingherdogs,leavingthehouseanddrivingtoatheater,endingwithheronstageinhersignature
pose. ThescenesareinterlacedwithvariousclipsofLosAngeles,California.ChartsPassage2:Kathy
GriffinKathleenMaryGriffin(bornNovember4,1960)isanAmericancomedianandactresswho
hasstarredintelevisioncomedyspecialsandhasreleasedcomedyalbums. In2007and2008,Griffin
wonPrimetimeEmmyAwardsforherrealityshowKathyGriffin: MyLifeontheD-List. Shehas
alsoappearedinsupportingrolesinfilms. GriffinwasborninOakPark,Illinois. In1978,shemoved
toLosAngeles,whereshestudieddramaattheLeeStrasbergTheatreandFilmInstituteandbecame
a member of the improvisational comedy troupe The Groundlings. In the 1990s, Griffin began
performing as a stand-up comedian and appeared as a guest star on television shows, including a
supportingroleontheNBCsitcomSuddenlySusan(1996–2000).
......
Griffin released a second comedy album, Suckin’ It for the Holidays, in another bid for a
Grammy.Griffin received her third Grammy nomination for Kathy Griffin: Does the Bible Belt in
2010,.OnMay4,2012,thefulllengthversionof"I’llSayIt",thethemesongofhershowKathy,was
releasedtoiTunesasasingle.OnAugust20,2012,Griffinreleasedaseven-trackEPcontainingdance
remixesof"I’llSayIt".
......
SongYoon-ahwasborninSeoul,butspentherchildhoodinGimcheon,NorthGyeongsangProvince.
She has two elder brothers, the first one is a doctor. While studying Cultural Anthropology as a
freshmanatHanyangUniversity,shewasrecommendedbyanolderschoolmatetoamodelingagency.
......
ChiptuneartistInversePhaseparodiedthesongonaCommodore64,titlingit"SayItAin’tSixty-FO"
CalpurniacoveredthesongforSpotify’sUnderCoverpodcastin2018Inpopularculture"SayItAin’t
So"isaplayabletrackinthevideogamesRockBandandRocksmith2014inadditiontoappearing
on an episode of Hindsight. Answer the question based on the given passages. Only give me the
answeranddonotoutputanyotherwords.
Question: WheredidtheperformerofsongI’llSayItgraduatefrom?
Answer:
AnswerofRAG-Long: HanyangUniversity✗
GoldenAnswer: LeeStrasbergTheatreandFilmInstitute✓
WrongReason: Completekeyinformationbutlostinmiddle
Table25: Aquestion-answeringexampleofourLongRAGwithRAG-Longcomponentstrategy. Thewordsinthe
greenareaindicatecorrectrelevantinformationandanswerswhileredmeanstheopposite. Thebluesnippetsare
question-relevantinformation. Thecorrectanswerislabeled"✓",whilewronganswerlabeled"✗".Question: WheredidtheperformerofsongI’LlSayItgraduatefrom?
Inputtogenerator(644tokens):
Answerthequestionbasedonthegivenpassages. Onlygivemetheansweranddonotoutputany
otherwords.Thefollowingaregivenpassages.Passage1: I’llSayIt"I’llSayIt"isasongwrittenby
AmericanmusicianAdamSchlesingerandrecordedbycomedianKathyGriffin,releasedasthetheme
song for her show, Kathy. It was additionally used as the introduction music to her 2012 comedy
special"KennedieCenteronHers"andcontinuedtobeusedinfuturespecials. OnAugust20,2012,
GriffinreleasedaseventrackEPcontainingdanceremixesof"I’llSayIt". MusicvideoThemusic
videobeginsinthedaywithKathyGriffininherhousepreparinghermake-up. Itshowsherdaily
routine visiting her dogs, leaving the house and driving to a theater, ending with her on stage in
her signature pose. The scenes are interlaced with various clips of Los Angeles, California. in a
ceremonyofficiatedbycomedianLilyTomlin. FilmographyFilmTelevisionOtherStand-upspecials
DiscographyOnJune10,2008,GriffinreleasedacomedyCDtitledForYourConsideration. Thedisc
wasrecordedattheETKTheatreattheGrandTheatreCenterForTheArtsinTracy,Californiaon
February17,2008. GriffinstatedshedecidedtoreleasetheCDtotrytowinaGrammyaward. On
August25,2009,Griffinreleasedasecondcomedyalbum,Suckin’ItfortheHolidays,inanotherbid
foraGrammy. GriffinreceivedherthirdGrammynominationforKathyGriffin: DoestheBibleBelt
in2010,.OnMay4,2012,thefulllengthversionof"I’llSayIt",thethemesongofhershowKathy,
wasreleasedtoiTunesasasingle. OnAugust20,2012,Griffinreleasedaseven-trackEPcontaining
danceremixesof"I’llSayIt". BibliographyOfficialBookClubSelection: AMemoirAccordingto
KathyGriffin. BallantineBooks. 2009. ISBN978-0345518569. KathyGriffin’sCelebrityRun-Ins:
MyA-ZIndex. FlatironBooks. 2016. ISBN978-1250115638. Theperformerofthesong"I’llSayIt"
isKathyGriffin,anAmericancomedianandactresswhohasstarredintelevisioncomedyspecials
andhasreleasedcomedyalbums. SheattendedtheLeeStrasbergTheatreandFilmInstituteinLos
Angeles,whereshestudieddrama. Answerthequestionbasedonthegivenpassages. Onlygiveme
theansweranddonotoutputanyotherwords.
Question: WheredidtheperformerofsongI’llSayItgraduatefrom?
Answer:
AnswerofLongRAG:LeeStrasbergTheatreandFilmInstitute✓
GoldenAnswer: LeeStrasbergTheatreandFilmInstitute✓
Table26: Aquestion-answeringexampleofourLongRAGsystemwithE&Fcomponentstrategy. Thewordsinthe
greenareaindicatecorrectrelevantinformationandanswerswhileredmeanstheopposite. Thebluesnippetsare
question-relevantinformation. Thecorrectanswerislabeled"✓",whilewronganswerlabeled"✗".