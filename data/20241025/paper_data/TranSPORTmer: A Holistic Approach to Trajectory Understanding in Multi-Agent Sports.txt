TranSPORTmer: A Holistic Approach to
Trajectory Understanding in Multi-Agent Sports
Guillem Capellera1,2 , Luis Ferraz1 , Antonio Rubio1 , Antonio Agudo2 ,
and Francesc Moreno-Noguer2
1 Kognia Sports Intelligence, Barcelona, Spain
{guillem.capellera,luis.ferraz,antonio.rubio}@kogniasports.com
2 Institut de Robòtica i Informàtica Industrial CSIC-UPC, Barcelona, Spain
{gcapellera,aagudo,fmoreno}@iri.upc.edu
Abstract. Understandingtrajectoriesinmulti-agentscenariosrequires
addressing various tasks, including predicting future movements, im-
puting missing observations, inferring the status of unseen agents, and
classifyingdifferentglobalstates.Traditionaldata-drivenapproachesof-
ten handle these tasks separately with specialized models. We intro-
duce TranSPORTmer, a unified transformer-based framework capable
of addressing all these tasks, showcasing its application to the intri-
cate dynamics of multi-agent sports scenarios like soccer and basket-
ball. Using Set Attention Blocks, TranSPORTmer effectively captures
temporal dynamics and social interactions in an equivariant manner.
Themodel’stasksareguidedbyaninputmaskthatconcealsmissingor
yet-to-be-predictedobservations.Additionally,weintroduceaCLSextra
agent to classify states along soccer trajectories, including passes, pos-
sessions, uncontrolled states, and out-of-play intervals, contributing to
anenhancementinmodelingtrajectories.Evaluationsonsoccerandbas-
ketballdatasetsshowthatTranSPORTmeroutperformsstate-of-the-art
task-specificmodelsinplayerforecasting,playerforecasting-imputation,
ball inference, and ball imputation. https://youtu.be/8VtSRm8oGoE
Keywords: Multi-agent modelling · Imputation · Transformers.
1 Introduction
Multi-agent systems are prevalent in various real-world scenarios encompassing
pedestrian modelling [2,5,25,29,38,50,51,57,59,68], human pose estimation
[1,11,24,28,35,45,46,48],andsportsanalytics[3,30,33,71,72].Thispaperfocuses
on the latter, where trajectory understanding plays a pivotal role in unraveling
the inter-dependencies within multi-agent sports scenarios. This understanding
opensupdiverseapplicationssuchasperformanceevaluation[10,15,62],scouting
[53], tactical analysis [16,66] and event detection [21,65]. In contrast to urban
contexts, the realm of sports requires the capturing of both individual player
influences and comprehensive team strategies, all of which involve heightened
levels of interactions and complex dynamics.
4202
tcO
32
]VC.sc[
1v58771.0142:viXra2 G. Capellera et al.
Fig.1: TranSPORTmer is a holistic model that is able to perform multiple tasks
for trajectory understanding in multi-agent sport scenarios. The images showcase ex-
amples using soccer and basketball data for the tasks of forecasting: predicting future
trajectoriesgivenpastobservations;imputation:predictingagenttrajectoriesgivenpar-
tialobservations;inference:predictingthetrajectoryofanunobservedagentgiventhe
stateofotherones;andstate classification:assigningasemanticlabeltoeachframeof
thesequence.Continuousanddashedlinescorrespondtoobservedstatesandpredicted
trajectories, respectively.
Despite the promising applications, challenges persist in this domain. Inher-
ent inaccuracies in optical tracking data, often arising from occlusions, pose a
significant hurdle. The substantial costs associated with adopting GPS technol-
ogy for ball tracking [36] add an extra layer of complexity. Additionally, the
intricaciesintroducedbyoff-screenplayers[52,69]andthenuancesofbroadcast-
ing videos further contribute to the challenges in multi-agent sports scenarios.
Moreover, the annotation of a match demands a significant amount of manual
work due to the density of events and states that unfold during gameplay.
Previous research has proposed task-specific solutions for trajectory fore-
casting [13,18,70] and imputing missing observations [43,52]. Some works offer
unifiedframeworkscapableofaddressingbothtasks[55,69].However,acommon
limitationacrossthesemodelsistheassumptionthatallagentshaveeithercom-
plete or partially observed data, overlooking scenarios involving entirely unseen
agents. Furthermore, several of these models rely on recursive prediction strate-
gies, potentially compromising efficiency in match processing and performance
when modeling long-range sequences.
In the domain of unseen agent inference, recent efforts have concentrated on
predicting both ball location [36] and player positions [20]. Nevertheless, these
approaches require additional data beyond agent locations, including velocities
and customized event data. Moreover, prior works focusing on event and state
classification using trajectory data often center around a limited set of sparse
scenarios [21] or specific events like passes and receptions [32,36], without pro-
viding comprehensive annotation for every state of the game.
Inthispaper,wepresentTranSPORTmer,acomprehensiveapproachfortra-
jectory understanding in multi-agent sports scenarios. Our approach uses trans-
former encoders, or Set Attention Blocks (SABs) [17,19,37,40], to capture tem-TranSPORTmer 3
poraldynamicsandinter-agent(or“social”)interactions,maintainingagentper-
mutation equivariance. To enhance adaptability, we use a socio-temporal mask
forhandlingmissingorfutureobservationsanddefininggametaskslikepredict-
ing opponent movements. Building on CLS tokens [17], we introduce the CLS
extra agent for state classification at each timestep alongside trajectory comple-
tion tasks. We also implement a learnable uncertainty mask in the loss function
to improve predictions near visible observations by modeling their uncertainty.
Our method is validated on one soccer and two basketball datasets. The key
contributions can be summarized as follows:
– We develop a holistic transformer-based model that integrates trajectory
forecasting, imputation, inference, and state classification in multi-agent
sports scenarios, outperforming state-of-the-art task-specific methods.
– We propose a CLS extra agent to infer per-frame game states, achieving
robust state classification while enhancing trajectory completion accuracy.
– Weimplementalearnableuncertaintymaskinthelossfunctionforboundary
observations, which reflects uncertainty and leads to more accurate predic-
tions.
– Weanalyzethecoarse-to-finemannerofourarchitectureintheballinference
task, resulting in a 25% improvement over current state-of-the-art methods.
2 Related Work
This section discusses the related work in trajectory forecasting, imputation,
inference,andstateclassification,withaspecificemphasisonmulti-agentsports
scenarios.
Trajectory Forecasting consists in predicting future positions based on past
observations. In the context of multi-agent sports, earlier approaches [23,71,
72] predicted long-term behaviors using Variational Recurrent Neural Networks
(VRNNs) [14]. However, these methods lack equivariance properties and rely
on heuristics like tree-based role alignment [44,60] to define a specific order-
ing of the agents. The combination of VRNNs with Graph Neural Networks
(GNNs) [7], results in GVRNN [61,70], defining an equivariant model treating
agents as nodes of a fully connected graph. This approach allows the aggrega-
tion of spatial interactions for final predictions. However, GVRNN treat agent
dependencies equally by aggregating agent information at each timestep. To
handle dependencies between different agents more effectively, [9,18,22,34,49]
used a Graph Attention Network (GAT) [64], replacing fully connected graphs.
Transformer-based models [63] have been used in this task [3,4], demonstrating
a superior performance compared to graph-recurrent-based methods. Neverthe-
less,conductingattentioninbothtemporalandsocialdimensionssimultaneously
still incurs a notable computational cost. In contrast, TranSPORTmer employs
attentioninbothtemporalandsocialdimensionssequentially.Thisdesignchoice
results in a substantial reduction in computational cost without compromising
performance. Moreover, by departing from recursive sequence construction, our4 G. Capellera et al.
model gains a significant advantage in long-term sequence prediction, thanks to
its inherent look-ahead temporal property.
TrajectoryImputationinvolvespredictingagents’behaviorinunknownframes
using available information, such as partial trajectories of the target agent. Pre-
vious research tackled value imputation in time series with an autoregressive
RNN [12]. A bidirectional GVRNN structure proposed by [52] addressed im-
puting missing agent observations in soccer games. However, due to its autore-
gressive nature, these approaches may lead to suboptimal results in long-range
sequences [27,39]. Liu et al. [43] introduced a non-autoregressive imputation
model exploiting the multi-resolution structure of sequential data, although it
falls short in handling trajectory forecasting. Another asynchronous approach
solved imputation and forecasting tasks using imitative techniques [55]. Some
research leveraged GVRNN to handle both tasks simultaneously [69]. Similarly,
our method is equipped to handle this unified task effectively.
Trajectory Inference aims to predict the behavior of agents across all frames
based solely on information from other agents. This is often approached as ball
inference [6,36]. The fusion of Set Transformers [40] with Bi-LSTM [31] has
been utilized to infer the ball trajectory and identify the ball possessor (or pass
receiver).Thismethodreliesonplayertrajectoriesandtheircorrespondingveloc-
ities [36]. As we will demonstrate later, TranSPORTmer does not require player
velocities to infer the ball position. Moreover, it can be applied to any type of
agent, including the goalkeeper, that exhibits very particular motion patterns.
State/Event Classification:Onthiscontext, [65]appliedarule-basedframe-
worktoidentifysoccereventsbasedonagenttrajectories.[21]proposedamethod
usingavariationalautoencoderandsupportvectormachinetodetecteventssuch
as corner kicks, crosses, and counterattacks. Another significant work is [32], in-
troducing a pass receiver Transformer-LSTM model that integrates visual infor-
mation with player and ball trajectories. The recent work previously mentioned
for ball inference [36] can also serve as a pass receiver prediction model. How-
ever, these approaches primarily focus on limited soccer context situations such
as set pieces and often rely on robust and precise estimations of ball and/or
playertrajectories.TranSPORTmerprovidesamoredetailedcoverageofevents,
referred to as states, including passes, possessions, uncontrolled situations, and
transitionsbetweenin-playandout-of-play states.Themodelalsodemonstrates
robustness against missing observations, showcasing its ability to perform state
classification even with an unseen ball.
Pedestrian Motion Modeling: We review advances in pedestrian motion
modeling, noting that Becker et al. [8] found an RNN with an MLP decoder
outperformed social pooling methods [2,29,41] despite lacking social encod-
ing. Transformer-based models have also advanced the field, with [26] achiev-
ing strong results on the TrajNet benchmark [58] by focusing on temporal dy-
namics. Subsequent approaches [1,25] improved social interaction modeling us-
ing transformer encoders without positional encoding. Recently, diffusion mod-
els [47,56,67] have emerged for stochastic human behavior modeling.TranSPORTmer 5
3 Revisiting Attention Mechanisms
Attention mechanisms are effective at capturing relationships in sequences or
sets. Utilizing n queries Q and n keys K of dimension d , and n values V
v k v
of dimension d as inputs, the attention mechanism computes weighted sums of
v
values by assessing the compatibility between queries and keys measured using
dot or scaled dot products. The masked attention expression A(Q,K,V,M),
incorporating a binary mask M, can be written as:
(QK )+o(M)
⊤
softmax V, (1)
√d
(cid:18) k (cid:19)
withQ Rn ×dk,K Rnv×dk,V Rnv×dv,andM 0,1 n ×nv.Mdetermines
∈ ∈ ∈ ∈{ }
which keys are used in computing attention for each query. Specifically, entries
filled with zeros in M indicate keys to be included, while entries filled with ones
denote those to be excluded. The function o() maps 0/1 values to 0/ . Note
· −∞
that the softmax operator output will assign zero weight to the latter set of
keys, ensuring that similarity scores are normalized. The weighted value sum is
obtained by multiplying attention weights with their corresponding values.
In practice, attention mechanism is often extended with multiple attention
heads, also called Multi-Head Attention (MHA) [63], allowing to capture differ-
ent aspects of the data. Instead of computing a single attention function, this
method projects Q, K, V onto H different dh, dh, dh dimensional vectors, re-
k k v
spectively.Eachattentionheadcomputesitsownattentionweightsandweighted
sumofvalues,andtheoutputsoftheattentionheadsareconcatenatedorlinearly
transformed to obtain the final attention output.
MHA(Q,K,V,M)isinferredusingconcat(head ,...,head ,...,head )WO,
1 h H
where head = A(QWQ,KWK,VWV,M) and h = 1,...,H represents the
h h h h { }
h-th attention head. Therefore, MHA is a [n d] matrix, with learnable param-
×
eters {W hQ,W hK
} ∈
Rdk×dh k, W hV
∈
Rdv×dh v, and WO
∈
Rhdh v×d. In this work
we will use d =d =d and dh =dh =d /H as it is standard in literature.
k v k v k
The MHA operation was extended [40] to operate on sets by defining the
SAB. Given one set of d-dimensional vectors and one mask determining which
vectors are used to compute the attention, denoted by X and M, respectively,
the SAB is defined as:
SAB(X,M)=LayerNorm(H+rFFN(H)), (2)
whereH=LayerNorm(X+MHA(X,X,X,M))andrFFN(H)denotestherow-
wise feed-forward neural network applied to H. Note that SAB is an adapta-
tion of the encoder block of the transformer but lacks the positional encod-
ing. The MHA operation itself provides the property of permutation equivari-
ance, allowing SAB to effectively capture relationships in the absence of posi-
tional information. When no mask is provided, the SAB operation is denoted as
SAB(X)=SAB(X,0), where 0 denotes an all-zero-values mask.6 G. Capellera et al.
4 Method
4.1 Problem Statement
Let us consider a set of N N agent observations by including players and a
∈
ball in our case, denoted as X = x1,...,xn,...,xN with n = 1,...,N ,
{ } { }
where each observation contains the (x,y) pitch locations. We can now collect
T observations along time for every agent, defining the tensor X where all
1:T
xn with t = 1,...,T are considered. Trajectory completion aims at inferring
t { }
missingorunobservedentriesofadatastructurebasedonthevisibleones.Given
partialobservationsXU anda[T N]binarymaskMtoencodeby0thevisible
1:T ×
observations and by 1 the unobserved ones, the goal is to find a function f ()
1
·
to infer the full observations such that:
f (XU ,M)=X . (3)
1 1:T 1:T
Based on that idea, we can define three sub-tasks by imposing specific con-
straints on the mask M:
Trajectory forecasting: Full observability is assumed for timesteps up to tˆ<
T, with M entries for these observations set to 0.
Trajectory imputation:Atleastoneobservationperagentisavailable,mean-
ing at least one null entry per row in M.
Trajectory inference:Thistaskisthemostchallenging,asitinvolvesatleast
one agent having no observations throughout the entire duration, meaning that
at least one entire row of the matrix M lacks null entries.
Inaddition,wedelveintotheclassificationofstateswithinthegame,seeking
anotherfunctionthattakesthesameinputasinEq.(3)butgeneratesanoutput
corresponding to a specific state for each timestep. These states involve the
actions pass, possession, uncontrolled, and out of play, 4 in total, all of which
are pertinent in a soccer context. Specifically, our objective is to estimate a
classification function f () such that:
2
·
f (XU ,M)=s , (4)
2 1:T 1:T
where s is a [T 4] dimensional tensor that represents the probability distri-
1:T
×
bution over each game state for each timestep.
4.2 TranSPORTmer
We next present TranSPORTmer our holistic and versatile approach to address
trajectory forecasting, imputation, inference and state classification. Figure 2
depicts its main components.
Input processing: The input tensor XU contains partial observations, indi-
1:T
cated by the input mask matrix M. We can append additional known informa-
tion to this tensor, such as the agent type, which is an integer corresponding to
each observation representing: 0 for ball, 1 for offensive team player, and 2 for
defensive team player. Therefore, the shape of XU can go from [T M 2] to
1:T × ×TranSPORTmer 7
Fig.2: TranSPORTmer. The architecture uses sequential Set Attention Blocks for
attentioninbothtemporal(SABT)andsocial(SABS)axes.APositionalEncoder(PE)
precedes each encoder to maintain the temporal sequence. The mask M identifies the
values to be predicted (dashed arrow), forming the complete observation tensor X 1:T.
The extended mask M¯ is applied to the 2 SABT of the first Encoderc, conveying
×
information about hidden and visible states. Blue-gray segments are involved in state
classification, including the CLS extra agent and the final classification head to rank
the state classes per frame. (c) operation stands for concatenation and (s) for split.
[T M 3] with (x,y,agent type). Initially, XU is transformed by a row-wise
× × 1:T
feed-forward network (rFFN), becoming an embedding tensor of dimension d.
CLS extra agent: Then a CLS tensor of dimension [T d] is appended as
×
an extra agent along the social axis, resulting in a [T (N + 1) d] tensor
J. To ensure consistency, the mask M¯ of dimensions [T × (N +1)] e× xtends M,
×
settingallentriescorrespondingtotheCLSextraagenttoonetoindicatehidden
observations. This extended mask is used in the initial SAB operations to make
a first approximation of the hidden observations using temporal information.
Coarse-to-fine encoders: The next block comprises two encoders, applied
sequentially and that operate in a coarse-to-fine manner. Formally:
J ′ =Encoder c(J,M¯)=SAB S SAB T SAB T(J+PE,M¯),M¯ , (5)
Encoder f(J ′)=SAB S( (cid:0)SAB T(S (cid:0)AB T(J ′+PE))),
(cid:1)(cid:1)
(6)
where PE corresponds to the original positional encoder [63] to preserve tem-
poral ordering. SAB and SAB are temporal and social set attention blocks,
T S
respectively. SAB processes individual temporal dynamics through the tem-
T
poral embeddings of each agent, while SAB addresses social interactions by
S
encoding the embeddings of all agents at each timestep. The sequential configu-
rationofSAB followedbySAB enablestheimplicitintegrationofinformation
T S
frombothfutureandpasttimestepsthroughtemporalattention,enhancingthe
model’s ability to consider a broader temporal context in social attention.
Output construction: After passing through the encoder blocks, the output
tensorretainsthedimensionsofJ.Thisoutputisthensplitintotwotensors:the
encoded trajectory embeddings and the encoded CLS extra agent. The former
undergoes a rFFN operation to yield a tensor of dimension [T N 2] cor-
× ×
responding to the predicted (x,y) pitch locations. The binary mask M is then
employed to directly propagate the visible (x,y) values from the input tensor,
XU ,resultinginthefullobservationtensorX .Ontheotherside,theencoded
1:T 1:T8 G. Capellera et al.
Fig.3: Binary mask (M) and learnable uncertainty mask (M unc) for a single agent.
Null values indicate visible observations.
CLS extra agent is reshaped and processed through another rFFN operation to
obtain probability scores for each class at each time, s , of dimension [T 4].
1:T
×
Note that our model exhibits permutation equivariance under agent permu-
tations,astheoperationsalongthesocialaxisinherentlymaintainthisproperty.
In this architecture, an additional mask can be employed in all SAB blocks to
ignorecorruptorNaNinputsobservationsnottopredict,ortofacilitatepadding
during batching with length-varying sequences and different numbers of agents
involved. We denote this mask as NaN-mask.
4.3 Loss Functions
We introduce a learnable uncertainty mask M , with the same dimension as
unc
M to represent observation uncertainty. Here, M n = 1 where Mn = 1, in-
unct t
dicating areas of maximum uncertainty (hidden observations). Along the time
axis,weusetwolearnableweights:w (0,1)boundedusingasigmoidfunction,
1
∈
and w := 1 w . These weights are applied to the immediate neighbors of 1’s
2 1
(M n =w− ) and to the second neighbors if they are not immediate neighbors
unct 1
(M n =w ).Allothervaluesaresettonullentries,signifyingvisibleobserva-
unct 2
tionsand,consequently,alackofuncertainty.Extendingthemaskinthelossfor
boundary observations to reflect uncertainty enables the model to reconstruct
them,leadingtomoreaccurateoverallpredictions.Figure3illustratesthediffer-
encesbetweenthebinarymask(M)andthelearnableuncertaintymask(M )
unc
for a single agent over time.
The loss function for trajectory completion uses the Average Displacement
Error (ADE) with the learnable uncertainty mask, assessing the disparity be-
tween the predictions and the ground truth:
N T N T
LADE
=( M uncn t) −1 ∥xˆn
t
−xn t∥2M uncn
t
, (7)
n=1t=1 n=1t=1
XX XX
where xˆn denotes our estimation of the n-th agent at time t, xn corresponds
t t
to the ground truth. We also utilize a standard Cross Entropy (CE) loss as the
training metric for the state classification task:
T 4
1
= sclog(sˆc), (8)
LCE −T t t
t=1c=1
XX
where sc represents the ground truth probability of game being in state c
t
at time t, and sˆc is the predicted probability. The overall loss is = +
t L LADETranSPORTmer 9
λ , where λ is a weighting factor set to λ = 4 when classifying states. In
LCE
the supplementary (suppl), we detail the training procedure and the chosen
hyperparameters.
We will study the importance of each part of the method by considering:
Oursw/oCLS (withoututilizingstateclassification),Oursw/oM (usingthe
unc
binarymaskMinsteadofM inthelossterm),andOurs w/o SOC (without
unc
employing SAB nor state classification). Additionally, we depict combinations
S
of these variations.
5 Experimental Evaluation
We next present experimental results on trajectory completion and state clas-
sification, comparing our approach with competing methods. For quantitative
evaluation, we utilize the ADE metric in Eq. (7) but considering the binary
mask M instead of M . For trajectory forecasting, we use the Final Displace-
unc
ment Error (FDE) to measure the final prediction deviation. We also consider
the Maximum Error (MaxErr) to capture the largest discrepancies:
N
1
MaxErr= max ( xn xˆn Mn),
D t 1,...,T ∥ t − t∥2· t
n=1 ∈{ }
X
where D = N 1 T Mn , with 1() as the unit step function. For state
n=1 t=1 t ·
classification P, being (cid:16)I( P·) the ind(cid:17)icator function, Accuracy (Acc) is computed as:
T
1
Acc= I argmax(sc)=argmax(sˆc) .
T t t
t=1 (cid:20) c c (cid:21)
X
5.1 Datasets
Soccer:ThisdatasetcomprisesrealsoccermatchdatafromLaLiga’s2022-2023
season, including 283 matches. The matches are split into sequences of T = 60
frames,representing9.6secondssampledat6.25Hz.Eachframecontains23ob-
servations (x,y) for each one of the agents (22 players and the ball). The agent
type isknowninthisdataset.GoalkeepersmaycontainNaNsiftheyarenotvis-
ible. To ensure consistency with prior research, the agent order is standardized.
Thedatasetissplitinto82,954/7,500/6,258sequencesfortraining,validation
and testing, respectively, with each split using different matches. For the state
classification task, the dataset is complemented with one state label per frame,
considering the states pass, possession, uncontrolled and out-of-play.
Basketball-VU: This dataset consists of basketball player tracking data pro-
videdbySTATSSportVUfromthe2016NBAseason.Toevaluateourmodelon
player forecasting, we use the same splits as in [49]. Each sequence consists of
50 timesteps representing 10 seconds sampled at 5Hz, where each one contains
the (x,y) observations for 10 players and the ball.10 G. Capellera et al.
Basketball-TIP: We also consider another basketball dataset from the 2012
NBA season. Following the same splits as [71], Xu et al. [69] pre-processed it
allowing to evaluate in both player imputation and forecasting tasks, renaming
it as Basketball-TIP. This dataset employs two distinct strategies to simulate
the appearance and disappearance of players: the“circle mode” andthe “camera
mode”. Each sequence consists on 50 frames representing 8 seconds sampled at
6.25Hz, each one containing the (x,y) observations for 10 players and the ball.
ETH-UCY: For completeness, we conducted an experiment using the ETH-
UCY pedestrian dataset [42,54]. Our approach performs comparably to deter-
ministic SOTA architectures [57,68], achieving a 4.3% improvement in ADE on
the ETH subset. Detailed information and results are available in the suppl.
5.2 Player Forecasting and Imputation
First, we assess our model’s effectiveness in (i) soccer player forecasting
and imputation.Thepredictedplayers,referredtoasagentsofinterestP,are
predicted using all future visible observations of conditioning agents, like the
ball and/or an opponent team. In the forecasting task, the model observes 20
timesteps (3.2s) and predicts the next 40 timesteps (6.4s) of P. The imputation
taskis similarbut withthe finallocationof eachplayerofinterestset asvisible.
As in previous studies [70], goalkeepers are excluded from this analysis.
In the forecasting task, we compare against the following implemented base-
lines: Velocity extrapolation, projecting agent predictions linearly based on ob-
served velocity; RNN encoder with LSTM, using shared weights, and MLP de-
coder for prediction [8]; GRNN as the non-variational version of GVRNN [70];
GRNN+Att which is the previous baseline but using GAT instead of GNNs;
Transformer which mirrors our pipeline but uses SAB to perform attention
across all timesteps of all agents simultaneously [3], as opposed to decoupling
attentioninSAB andSAB ;andOursw/oSOC.Furtherdetailsoftheseimple-
T S
mentationscanbefoundinthesuppl.ItisimportanttonotethatVelocity,RNN,
and Ours w/o SOC operate independently for each agent, making the agents
ordering irrelevant and preventing them from utilizing any social conditioning.
Table 1 shows the results of (i) soccer player forecasting and imputation
with conditioning agents indicated in parentheses. As expected, socially aware
architectures exhibit superior performance in all metrics, particularly when the
number of conditioning agents is increased. Results for Ours w/o SOC under-
score the clear significance of SAB . Transformer achieves slightly inferior re-
S
sults compared to Ours w/o CLS, likely due to its flattened attention mech-
anism, which may cause confusion with the higher number of non-correlated
observations. Additionally, Transformer is approximately four times slower at
inference time (340 vs. 88 milliseconds). Furthermore, TranSPORTmer (Ours)
outperforms Ours w/o CLS in forecasting, but in the imputation task, Ours
w/o CLS achieves slightly better results, possibly due to sub-optimal λ com-
pared to forecasting. Figure 4-top shows an example on the task of forecasting
offensiveplayers(secondtask-rowinTable1).TheRNN baselinetendstogener-
ateshorterpredictedtrajectories,emphasizingtheneedforsocialinteractionstoTranSPORTmer 11
PredictP Forecasting Imputation
(Condition) Velocity RNN Oursw/oSOC GRNN GRNN+Att Transformer Oursw/oCLS Ours Oursw/oCLS Ours
Social ✓ ✓ ✓ ✓ ✓ ✓ ✓
P (l Ba ay le lr )s A M F AD cD a cx EE E (PP %rr ↓)↓ P ↑↓ 1 15 3 3. -. .9 4 36 9 3 8 84 . .. -9 53 5 96 8 84 . .. -6 20 0 58 7 64 . .. -4 80 3 52 7 63. . . -0 467 2 9 5 42 . .. -2 76 8 86 5 42 . .. -1 65 2 53 82 4 4 7. . . .4 9 5 32 7 0
5
1 2. . --1 24 1 81 2 9. . - .1 2 05 2
0
(DefO enff se en +se Ball)M F AA D cD a cx EE E (PP %rr ↓)↓ P ↑↓ 1 15 3 2. -. .7 0 86 4 9 8 84 . .. -7 32 2 93 8 83 . .. -3 09 9 76 6 63 . .. -8 37 4 26 6 53. . . -3 830 1 0 4 32 . .. -4 92 5 66 4 32 . .. -2 81 7 20 82 4 3 8. . . .0 2 7 96 1 7
1
0 1. . --9 99 2 81 1 9. . - .0 9 62 7
9
(OffD ene sfe en +s Be all)M F AA D cD a cx EE E (PP %rr ↓)↓ P ↑↓ 1 16 3 3. -. .1 9 76 4 8 9 84 . .. -1 74 8 99 8 84 . .. -8 42 1 40 6 53 . .. -2 64 9 97 5 53. . . -9 322 8 6 4 32 . .. -1 61 7 34 4 32 . .. -0 50 4 51 81 3 3 9. . . .9 9 4 98 8 9
2
1 1. . --0 93 9 91 2 0. . - .0 0 44 0
7
Table 1: Evaluation in (i) soccer player forecasting and imputation. Predic-
tions are generated with a time horizon of 6.4s using a prior of 3.2s. P denotes agents
of interest. For the imputation task, the last observation of each agent is visible. All
metrics, except Acc, are in meters.
Fig.4:Qualitativeevaluationinsoccerplayerforecastingandballinference.
Top: Offensive player trajectory forecasting with a time horizon of 6.4s using a prior
of 3.2s. Bottom: Ball inference through the full 9.6s sequence.
enhance performance. The GRNN+Att baseline exhibits improved performance
with conditioning in long-term predictions. However, TranSPORTmer outper-
forms these baselines, yielding more realistic results aligned with ground truth
positions (see video of our results in the suppl).
Table 1 also reports the accuracy of state classification while addressing
trajectorypredictionandimputationtasks.Achievingapproximately90%,these
results demonstrate the robust and consistent classification power of our model,
primarily attributed to the ball’s visibility in all tasks. The confusion matrix
in Fig. 5-left-left specifically illustrates the state classification while forecasting
offensiveplayers,achievinganoverallaccuracyof88.91%.Itisworthnotingthat
the uncontrolled class exhibits less accurate predictions due to its challenging
subjectivenatureinannotationsandanimbalancecomparedtotheotherclasses.12 G. Capellera et al.
PredictP STGAT[34] Social-Ways[5] GVRNN[70] GMAT[71] AC-VRNN[9] DAG-Net[49] U-MAT[22] S-PatteRNN[50] Oursw/oCLS
ICCV’19 CVPRW’19 CVPR’19 ICLR’19 CVIU’21 ICPR’21 NeurIPS’22 IROS’22
Players - - - - - 8.55/12.37 - 8.13/12.34 7.75/11.65
Offense 9.94/15.80 9.91/15.19 9.73/15.89 9.47/16.98 9.32/14.91 8.98/14.08 9.01/13.28 - 9.19/14.24
Defense 7.26/11.28 7.31/10.21 7.29/10.62 7.05/10.56 7.01/10.16 6.87/9.76 6.88/9.04 - 6.31/9.04
Table 2: Evaluation in (ii) basketball player forecasting using Basketball-
VU dataset (ADEP/FDEP). Predictions have a time horizon of 8s using a prior
of 2s. Results are extracted from the original works, and no agent future condition is
considered in this task. P denotes agents of interest. All metrics are in feet.
Model I-ADr E=3f Pt -ADE I-ADr E=5 Pft -ADE I-ADr E=7 Pft -ADE I-ADθ E=1 P0º -ADE I-ADθ E=2 P0º -ADE I-ADθ E=3 P0º -ADE
Mean 9.07(10.36) - 9.53(9.44) - 9.51(9.21) - 8.83(8.56) - 8.64(8.73) - 8.47(8.92) -
Median 9.32(10.55) - 9.82(9.64) - 9.81(9.44) - 9.16(8.84) - 8.96(9.02) - 8.75(9.21) -
GMAT[71] ICLR’19 7.36 - 6.89 - 6.73 - 6.42 - 5.99 - 6.01 -
NAOMI[43] NeurIPS’19 7.68 - 7.08 - 7.04 - 6.33 - 6.11 - 5.91 -
LSTM[31] NeurComp 7.33 20.07 6.73 14.91 6.51 10.07 6.28 9.34 6.01 7.52 5.67 6.10
VRNN[14] NeurIPS’15 7.43 12.26 6.90 11.38 6.68 10.07 6.38 8.49 6.09 7.47 5.92 7.36
INAM[55] CVPR’20 7.35 8.93 6.93 8.24 6.80 7.68 6.50 7.32 6.13 7.10 5.92 6.96
GC-VRNN[69] CVPR’23 7.03 8.93 6.93 8.24 6.80 7.68 5.86 6.29 5.56 4.74 5.39 4.28
Ourw/oCLS/Munc (5.32) (5.91) (4.71) (5.56) (4.16) (4.91) (3.60) (4.77) (3.29) (4.13) (3.08) (3.60)
Ourw/oCLS (5.24) (5.89) (4.48) (5.29) (4.14) (4.90) (3.59) (4.78) (3.26) (4.09) (3.08) (3.60)
Table 3: Evaluation in (iii) basketball player unified imputation and fore-
castingusingtheBasketball-TIPdataset[69].Theimputationtaskisperformed
over 6.4 seconds, and forecasting over 1.6 seconds. All metrics are in feet. Our imple-
mentation results are presented in parentheses.
Next, we evaluate the effectiveness of our model in (ii) basketball player
forecasting using the Basketball-VU dataset. The task at hand consists of ob-
serving10time-steps(2s)andpredictingthefollowing40(8s)ofplayerswithout
future conditioning agents (refer to suppl for additional conditioning-based ex-
periments).Wecompareagainstthestate-of-the-artresultsalreadypublishedin
previousworks,asshowninTable2.Ourmodelistrainedtopredictbothoffen-
sive and defensive players simultaneously. Other baselines, like DAG-Net [49],
need separate training to achieve better results. The ADE and FDE metrics
P P
depicted in the table demonstrate that our method outperforms in predicting
trajectories for all players and defense, using only one model trained with the
same weights. In both Soccer and Basketball-VU datasets, it can be seen that
in general, forecasting offensive players is more challenging than defensive ones.
Additionally, we assess our model’s capability in (iii) basketball player
unified imputation and forecasting tasksusingtheBasketball-TIPdataset.
This task involves observing the initial 40 timesteps (6.4s), imputing agents
outside the circle/camera view, and forecasting their locations during the sub-
sequent 10 frames (1.6s). In “circle mode”, three radii r 3,5,7 ft are con-
∈ { }
sidered, centered on the ball location. In “camera mode”, a fixed field of view
(FOV) tracks the ball from the center of the pitch, with three possible angles
θ 10,20,30 ◦. Following Xu et al. [69], we predict players who have at least
∈ { }
oneobservationintheinitial40timesteps,potentiallyvaryingnumbersofagents
acrosssequences.Ourmethod incorporates theadditional NaN-maskto exclude
non-interest agents within each sequence. We add our results in Table 3, show-TranSPORTmer 13
Fig.5:Left:Confusionmatrixinstateclassification.Offensiveplayertrajectory
forecasting (left) and ball inference (right). Right: Attention maps for the ball.
Visualization of attention maps in each social SABS across agents and time for the
sequences #1 and #2 in Fig. 4-bottom (animations in suppl video).
ing a clear effectiveness of our method against the SOTA approaches in all six
scenarios.I-ADEdenotestheerrorintheinitial40timesteps(imputationerror)
and P-ADE signifies the error in the final 10 timesteps (forecasting error). Our
methodperformsnotablywellinimputationtaskscomparedtoGC-VRNN[69],
due to its unidirectional recurrent nature, which affects forecasting reliability
based on imputed data. Refer to the suppl for detailed information and figures.
5.3 Ball Imputation and Inference
We evaluate (iv) soccer ball imputation and inference tasks. The infer-
encetaskinvolvespredictingallobservationsoftheball,masking100%ofthem.
The imputation task involves predicting a lower percentage of the ball obser-
vations while setting the others as visible. Players’ observations serve as condi-
tioning agents in all tasks. We benchmark against the state-of-the-art method
ballradar [36], which employs a hierarchical approach involving possessor classi-
fication followed by ball trajectory regression. Additionally, we compare against
its non-hierarchical version, ballradar w/o POS, which performs ball regression
withoutpossessorclassification.Duetotherequirementsofballradar,ourdataset
is augmented with ground-truth possessor information, player’s velocities and
goalkeeperlocationsusingourmethod(furtherdetailscanbefoundinthesuppl).
Table 4 presents a comparative analysis of ball trajectory imputation and
inference. Our methods consistently outperform the state-of-the-art, achieving
overa25%improvementinADEfortrajectoryinference.Qualitativedifferences
intwotestsamplesareillustratedinFig.4-bottom.Forimputation,weshowcase
results by masking 80% and 90% of total ball observations for each sequence,
highlighting the superior performance of our method. Notably, employing state
classification in TranSPORTmer helps achieve generally better results, show-14 G. Capellera et al.
ballradarw/oPOS ballradar(KDD’23)Oursw/oCLS/Munc Oursw/oCLS Oursw/oMunc Ours
Mask 100% 80% 90% 100% 80% 90% 100% 80% 90% 100% 80% 90% 100% 80% 90% 100%
ADE 5.43 0.97 1.51 3.89 0.88 1.18 2.89 0.88 1.12 2.89 0.80 1.23 2.71 0.84 1.09 2.71
MaxE↓rr 10.98 3.73 5.16 8.79 3.47 4.59 7.78 3.44 4.48 7.78 3.25 4.48 7.39 3.24 4.39 7.39
Acc(%)↓ - - - - - - - - - - 85.51 83.38 80.84 85.59 83.55 80.84
↑
Table 4: Evaluation in (iv) soccer ball imputation and inference.Predictions
are generated through the full 9.6s sequence. All metrics, except Acc, are in meters.
casing its holistic nature. However, Ours w/o CLS surpasses ballradar without
requiring additional data beyond player (x,y) locations.
Intermsofstateclassificationaccuracy(seeTable4),thereisananticipated
declinecomparedtothesoccerplayertrajectoryforecastingandimputationsec-
tion (see Table 1), likely attributed to the non-visibility of the ball, our target.
Surprisingly, the method still achieves an accuracy of 80.84% in state classifica-
tion showcasing that the game states can be inferred using only the movement
of players (refer to Fig. 5-left-right for the detailed confusion matrix). Figure 5-
right shows the attention maps generated by the SAB for the ball across all
S
agents and timesteps in the two examples of Fig. 4-bottom. Computed by av-
eraging contributions from each head, these maps reveal the model’s awareness.
In the first SAB , a broad, general awareness of other agents is observed, re-
S
sembling a coarse social perspective. The second SAB focuses attention on the
S
possessor player or the anticipated recipient of the ball in the event of a pass.
Thishighlightsthecoarse-to-finenatureofthetwoencodersinourmodel.Refer
to the suppl for additional ablation study regarding the coarsening-to-fine.
In both Tables 3 and 4, we include an ablation study regarding the usage
of M in the loss term, which generally leads to improved results. For the
unc
first neighbors, the recorded values are w [0.7,0.85], and for the second ones
1
∈
w [0.15,0.3], reflecting the expected level of uncertainty.
2
∈
6 Conclusions
Inthispaper,weintroducedTranSPORTmer,aholisticapproachcapableofhan-
dling multiple tasks (forecasting, imputation, inference, and state classification)
fortrajectoryunderstandinginmulti-agentsportsscenarios.Unlikestate-of-the-
art methods, TranSPORTmer can address all tasks using our approach, elimi-
natingtheneedfortask-specificmodels.Ourevaluationonsoccerandbasketball
datasetsshowscompetitiveperformanceacrosstasks.Notably,ourapproachex-
celsinplayerforecasting,playerimputation,ballimputationandinferencetasks,
while combined with state classification tasks allows to improve the results. Ad-
ditionally, the learnable mask models uncertainty in neighboring hidden values,
further enhancing outcomes. We believe this has the potential to pave the way
for a deeper understanding of the semantic aspects of sports games.
Acknowledgment. This work has been supported by the project GRAVATAR
PID2023-151184OB-I00 funded by MCIU/AEI/10.13039/501100011033 and by
ERDF, UE and by the Government of Catalonia under 2023 DI 00058.TranSPORTmer 15
References
1. Aksan, E., Kaufmann, M., Cao, P., Hilliges, O.: A spatio-temporal transformer
for 3d human motion prediction. In: 2021 International Conference on 3D Vision
(3DV). pp. 565–574. IEEE (2021) 1, 4
2. Alahi,A.,Goel,K.,Ramanathan,V.,Robicquet,A.,Fei-Fei,L.,Savarese,S.:Social
lstm:Humantrajectorypredictionincrowdedspaces.In:ProceedingsoftheIEEE
conference on computer vision and pattern recognition. pp. 961–971 (2016) 1, 4
3. Alcorn, M.A., Nguyen, A.: baller2vec++: A look-ahead multi-entity transformer
for modeling coordinated agents. arXiv preprint arXiv:2104.11980 (2021) 1, 3, 10
4. Alcorn, M.A., Nguyen, A.: baller2vec: A multi-entity transformer for multi-agent
spatiotemporal modeling. arXiv preprint arXiv:2102.03291 (2021) 3
5. Amirian, J., Hayet, J.B., Pettré, J.: Social ways: Learning multi-modal distribu-
tionsofpedestriantrajectorieswithgans.In:ProceedingsoftheIEEE/CVFCon-
ference on Computer Vision and Pattern Recognition Workshops. pp. 0–0 (2019)
1, 12
6. Amirli,A.,Alemdar,H.:Predictionoftheballlocationonthe2dplaneinfootball
usingopticaltrackingdata.AcademicPlatformJournalofEngineeringandSmart
Systems 10(1), 1–8 (2022) 4
7. Battaglia, P.W., Hamrick, J.B., Bapst, V., Sanchez-Gonzalez, A., Zambaldi, V.,
Malinowski, M., Tacchetti, A., Raposo, D., Santoro, A., Faulkner, R., et al.:
Relational inductive biases, deep learning, and graph networks. arXiv preprint
arXiv:1806.01261 (2018) 3
8. Becker, S., Hug, R., Hubner, W., Arens, M.: Red: A simple but effective baseline
predictor for the trajnet benchmark. In: Proceedings of the European Conference
on Computer Vision (ECCV) Workshops. pp. 0–0 (2018) 4, 10
9. Bertugli, A., Calderara, S., Coscia, P., Ballan, L., Cucchiara, R.: Ac-vrnn: Atten-
tive conditional-vrnn for multi-future trajectory prediction. Computer Vision and
Image Understanding 210, 103245 (2021) 3, 12
10. Brito Souza, D., López-Del Campo, R., Blanco-Pita, H., Resta, R., Del Coso, J.:
Associationofmatchrunningperformancewithandwithoutballpossessiontofoot-
ball performance. International Journal of Performance Analysis in Sport 20(3),
483–494 (2020) 1
11. Cai, Y., Huang, L., Wang, Y., Cham, T.J., Cai, J., Yuan, J., Liu, J., Yang, X.,
Zhu,Y.,Shen,X.,etal.:Learningprogressivejointpropagationforhumanmotion
prediction.In:ComputerVision–ECCV2020:16thEuropeanConference,Glasgow,
UK, August 23–28, 2020, Proceedings, Part VII 16. pp. 226–242. Springer (2020)
1
12. Cao, W., Wang, D., Li, J., Zhou, H., Li, L., Li, Y.: Brits: Bidirectional recurrent
imputation for time series. Advances in neural information processing systems 31
(2018) 4
13. Capellera, G., Ferraz, L., Rubio, A., Agudo, A., Moreno-Noguer, F.: Footbots:
A transformer-based architecture for motion prediction in soccer. arXiv preprint
arXiv:2406.19852 (2024) 2
14. Chung, J., Kastner, K., Dinh, L., Goel, K., Courville, A.C., Bengio, Y.: A re-
current latent variable model for sequential data. Advances in neural information
processing systems 28 (2015) 3, 12
15. Decroos, T., Bransen, L., Van Haaren, J., Davis, J.: Actions speak louder than
goals:Valuingplayeractionsinsoccer.In:Proceedingsofthe25thACMSIGKDD
international conference on knowledge discovery & data mining. pp. 1851–1861
(2019) 116 G. Capellera et al.
16. Decroos, T., Van Haaren, J., Davis, J.: Automatic discovery of tactics in spatio-
temporalsoccermatchdata.In:Proceedingsofthe24thacmsigkddinternational
conference on knowledge discovery & data mining. pp. 223–232 (2018) 1
17. Devlin,J.,Chang,M.W.,Lee,K.,Toutanova,K.:Bert:Pre-trainingofdeepbidirec-
tional transformers for language understanding. arXiv preprint arXiv:1810.04805
(2018) 2, 3
18. Ding,D.,Huang,H.H.:Agraphattentionbasedapproachfortrajectoryprediction
in multi-agent sports games. arXiv preprint arXiv:2012.10531 (2020) 2, 3
19. Dosovitskiy,A.,Beyer,L.,Kolesnikov,A.,Weissenborn,D.,Zhai,X.,Unterthiner,
T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et al.: An image is
worth 16x16 words: Transformers for image recognition at scale. arXiv preprint
arXiv:2010.11929 (2020) 2
20. Everett, G., Beal, R.J., Matthews, T., Early, J., Norman, T.J., Ramchurn, S.D.:
Inferring player location in sports matches: Multi-agent spatial imputation from
limited observations. arXiv preprint arXiv:2302.06569 (2023) 2
21. Fassmeyer, D., Anzer, G., Bauer, P., Brefeld, U.: Toward automatically labeling
situationsinsoccer.FrontiersinSportsandActiveLiving3,725431(2021) 1,2,4
22. Fassmeyer, D., Fassmeyer, P., Brefeld, U.: Semi-supervised generative models for
multiagent trajectories. Advances in Neural Information Processing Systems 35,
37267–37281 (2022) 3, 12
23. Felsen, P., Lucey, P., Ganguly, S.: Where will they go? predicting fine-grained ad-
versarial multi-agent motion using conditional variational autoencoders. In: Pro-
ceedings of the European conference on computer vision (ECCV). pp. 732–747
(2018) 3
24. Fragkiadaki,K.,Levine,S.,Felsen,P.,Malik,J.:Recurrentnetworkmodelsforhu-
mandynamics.In:ProceedingsoftheIEEEinternationalconferenceoncomputer
vision. pp. 4346–4354 (2015) 1
25. Girgis,R.,Golemo,F.,Codevilla,F.,Weiss,M.,D’Souza,J.A.,Kahou,S.E.,Heide,
F.,Pal,C.:Latentvariablesequentialsettransformersforjointmulti-agentmotion
prediction. arXiv preprint arXiv:2104.00563 (2021) 1, 4
26. Giuliari, F., Hasan, I., Cristani, M., Galasso, F.: Transformer networks for tra-
jectory forecasting. In: 2020 25th international conference on pattern recognition
(ICPR). pp. 10335–10342. IEEE (2021) 4
27. Gu, J., Bradbury, J., Xiong, C., Li, V.O., Socher, R.: Non-autoregressive neural
machine translation. arXiv preprint arXiv:1711.02281 (2017) 4
28. Guo, W., Du, Y., Shen, X., Lepetit, V., Alameda-Pineda, X., Moreno-Noguer, F.:
Backtomlp:Asimplebaselineforhumanmotionprediction.In:Proceedingsofthe
IEEE/CVFWinterConferenceonApplicationsofComputerVision.pp.4809–4819
(2023) 1
29. Gupta, A., Johnson, J., Fei-Fei, L., Savarese, S., Alahi, A.: Social gan: Socially
acceptable trajectories with generative adversarial networks. In: Proceedings of
the IEEE conference on computer vision and pattern recognition. pp. 2255–2264
(2018) 1, 4
30. Hauri, S., Djuric, N., Radosavljevic, V., Vucetic, S.: Multi-modal trajectory pre-
diction of nba players. In: Proceedings of the IEEE/CVF Winter Conference on
Applications of Computer Vision. pp. 1640–1649 (2021) 1
31. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural computation
9(8), 1735–1780 (1997) 4, 12
32. Honda, Y., Kawakami, R., Yoshihashi, R., Kato, K., Naemura, T.: Pass receiver
prediction in soccer using video and players’ trajectories. In: Proceedings of theTranSPORTmer 17
IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 3503–
3512 (2022) 2, 4
33. Hu,B.,Cham,T.J.:Entry-flippedtransformerforinferenceandpredictionofpar-
ticipant behavior. In: European Conference on Computer Vision. pp. 439–456.
Springer (2022) 1
34. Huang, Y., Bi, H., Li, Z., Mao, T., Wang, Z.: Stgat: Modeling spatial-temporal
interactions for human trajectory prediction. In: Proceedings of the IEEE/CVF
international conference on computer vision. pp. 6272–6281 (2019) 3, 12
35. Jain, A., Zamir, A.R., Savarese, S., Saxena, A.: Structural-rnn: Deep learning on
spatio-temporalgraphs.In:Proceedingsoftheieeeconferenceoncomputervision
and pattern recognition. pp. 5308–5317 (2016) 1
36. Kim, H., Choi, H.J., Kim, C.J., Yoon, J., Ko, S.K.: Ball trajectory inference from
multi-agent sports contexts using set transformer and hierarchical bi-lstm. arXiv
preprint arXiv:2306.08206 (2023) 2, 4, 13
37. Kong, Q., Xu, Y., Wang, W., Plumbley, M.D.: Sound event detection of
weakly labelled data with cnn-transformer and automatic threshold optimization.
IEEE/ACM Transactions on Audio, Speech, and Language Processing 28, 2450–
2460 (2020) 2
38. Kosaraju,V.,Sadeghian,A.,Martín-Martín,R.,Reid,I.,Rezatofighi,H.,Savarese,
S.: Social-bigat: Multimodal trajectory forecasting using bicycle-gan and graph
attentionnetworks.AdvancesinNeuralInformationProcessingSystems32(2019)
1
39. Lee, J., Mansimov, E., Cho, K.: Deterministic non-autoregressive neural sequence
modeling by iterative refinement. arXiv preprint arXiv:1802.06901 (2018) 4
40. Lee, J., Lee, Y., Kim, J., Kosiorek, A., Choi, S., Teh, Y.W.: Set transformer: A
frameworkforattention-basedpermutation-invariantneuralnetworks.In:Interna-
tional conference on machine learning. pp. 3744–3753. PMLR (2019) 2, 4, 5
41. Lee,N.,Choi,W.,Vernaza,P.,Choy,C.B.,Torr,P.H.,Chandraker,M.:Desire:Dis-
tant future prediction in dynamic scenes with interacting agents. In: Proceedings
of the IEEE conference on computer vision and pattern recognition. pp. 336–345
(2017) 4
42. Lerner,A.,Chrysanthou,Y.,Lischinski,D.:Crowdsbyexample.Computergraph-
ics forum 26(3), 655–664 (2007) 10
43. Liu,Y.,Yu,R.,Zheng,S.,Zhan,E.,Yue,Y.:Naomi:Non-autoregressivemultires-
olution sequence imputation. Advances in neural information processing systems
32 (2019) 2, 4, 12
44. Lucey, P., Bialkowski, A., Carr, P., Morgan, S., Matthews, I., Sheikh, Y.: Repre-
sentinganddiscoveringadversarialteambehaviorsusingplayerroles.In:Proceed-
ings of the IEEE Conference on Computer Vision and Pattern Recognition. pp.
2706–2713 (2013) 3
45. Mao,W.,Liu,M.,Salzmann,M.:Historyrepeatsitself:Humanmotionprediction
via motion attention. In: Computer Vision–ECCV 2020: 16th European Confer-
ence, Glasgow, UK, August 23–28, 2020, Proceedings, Part XIV 16. pp. 474–489.
Springer (2020) 1
46. Mao,W.,Liu,M.,Salzmann,M.,Li,H.:Learningtrajectorydependenciesforhu-
manmotionprediction.In:ProceedingsoftheIEEE/CVFinternationalconference
on computer vision. pp. 9489–9497 (2019) 1
47. Mao,W.,Xu,C.,Zhu,Q.,Chen,S.,Wang,Y.:Leapfrogdiffusionmodelforstochas-
tictrajectoryprediction.In:ProceedingsoftheIEEE/CVFconferenceoncomputer
vision and pattern recognition. pp. 5517–5526 (2023) 418 G. Capellera et al.
48. Martinez,J.,Black,M.J.,Romero,J.:Onhumanmotionpredictionusingrecurrent
neural networks. In: Proceedings of the IEEE conference on computer vision and
pattern recognition. pp. 2891–2900 (2017) 1
49. Monti, A., Bertugli, A., Calderara, S., Cucchiara, R.: Dag-net: Double attentive
graph neural network for trajectory forecasting. In: 2020 25th International Con-
ference on Pattern Recognition (ICPR). pp. 2551–2558. IEEE (2021) 3, 9, 12
50. Navarro, I., Oh, J.: Social-patternn: Socially-aware trajectory prediction guided
by motion patterns. In: 2022 IEEE/RSJ International Conference on Intelligent
Robots and Systems (IROS). pp. 9859–9864. IEEE (2022) 1, 12
51. Ngiam,J.,Caine,B.,Vasudevan,V.,Zhang,Z.,Chiang,H.T.L.,Ling,J.,Roelofs,
R., Bewley, A., Liu, C., Venugopal, A., et al.: Scene transformer: A unified archi-
tectureforpredictingmultipleagenttrajectories.arXivpreprintarXiv:2106.08417
(2021) 1
52. Omidshafiei, S., Hennes, D., Garnelo, M., Wang, Z., Recasens, A., Tarassov, E.,
Yang, Y., Elie, R., Connor, J.T., Muller, P., et al.: Multiagent off-screen behavior
prediction in football. Scientific reports 12(1), 8638 (2022) 2, 4
53. Pappalardo, L., Cintia, P., Ferragina, P., Massucco, E., Pedreschi, D., Giannotti,
F.: Playerank: data-driven performance evaluation and player ranking in soccer
via a machine learning approach. ACM Transactions on Intelligent Systems and
Technology (TIST) 10(5), 1–27 (2019) 1
54. Pellegrini, S., Ess, A., Schindler, K., Van Gool, L.: You’ll never walk alone: Mod-
eling social behavior for multi-target tracking. In: 2009 IEEE 12th international
conference on computer vision. pp. 261–268. IEEE (2009) 10
55. Qi, M., Qin, J., Wu, Y., Yang, Y.: Imitative non-autoregressive modeling for tra-
jectoryforecastingandimputation.In:ProceedingsoftheIEEE/CVFConference
on Computer Vision and Pattern Recognition. pp. 12736–12745 (2020) 2, 4, 12
56. Rempe, D., Luo, Z., Bin Peng, X., Yuan, Y., Kitani, K., Kreis, K., Fidler, S.,
Litany,O.:Traceandpace:Controllablepedestriananimationviaguidedtrajectory
diffusion. In: Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition. pp. 13756–13766 (2023) 4
57. Saadatnejad,S.,Gao,Y.,Messaoud,K.,Alahi,A.:Social-transmotion:Promptable
human trajectory prediction. arXiv preprint arXiv:2312.16168 (2023) 1, 10
58. Sadeghian,A.,Kosaraju,V.,Gupta,A.,Savarese,S.,Alahi,A.:Trajnet:Towards
a benchmark for human trajectory prediction. arXiv preprint (2018) 4
59. Salzmann, T., Ivanovic, B., Chakravarty, P., Pavone, M.: Trajectron++: Multi-
agentgenerativetrajectoryforecastingwithheterogeneousdataforcontrol.arXiv
preprint arXiv:2001.03093 2 (2020) 1
60. Sha, L., Lucey, P., Zheng, S., Kim, T., Yue, Y., Sridharan, S.: Fine-grained re-
trieval of sports plays using tree-based alignment of trajectories. arXiv preprint
arXiv:1710.02255 (2017) 3
61. Sun, C., Karlsson, P., Wu, J., Tenenbaum, J.B., Murphy, K.: Stochastic pre-
diction of multi-agent interactions from partial observations. arXiv preprint
arXiv:1902.09641 (2019) 3
62. Teranishi, M., Tsutsui, K., Takeda, K., Fujii, K.: Evaluation of creating scoring
opportunities for teammates in soccer via trajectory prediction. In: International
WorkshoponMachineLearningandDataMiningforSportsAnalytics.pp.53–73.
Springer (2022) 1
63. Vaswani,A.,Shazeer,N.,Parmar,N.,Uszkoreit,J.,Jones,L.,Gomez,A.N.,Kaiser,
Ł., Polosukhin, I.: Attention is all you need. Advances in neural information pro-
cessing systems 30 (2017) 3, 5, 7TranSPORTmer 19
64. Veličković,P.,Cucurull,G.,Casanova,A.,Romero,A.,Lio,P.,Bengio,Y.:Graph
attention networks. arXiv preprint arXiv:1710.10903 (2017) 3
65. Vidal-Codina, F., Evans, N., El Fakir, B., Billingham, J.: Automatic event de-
tection in football using tracking data. Sports Engineering 25(1), 18 (2022) 1,
4
66. Wang, Z., Veličković, P., Hennes, D., Tomašev, N., Prince, L., Kaisers, M.,
Bachrach, Y., Elie, R., Wenliang, L.K., Piccinini, F., et al.: Tacticai: an ai as-
sistant for football tactics. arXiv preprint arXiv:2310.10553 (2023) 1
67. Xie,Y.,Jampani,V.,Zhong,L.,Sun,D.,Jiang,H.:Omnicontrol:Controlanyjoint
atanytimeforhumanmotiongeneration.arXivpreprintarXiv:2310.08580(2023)
4
68. Xu,C.,Tan,R.T.,Tan,Y.,Chen,S.,Wang,Y.G.,Wang,X.,Wang,Y.:Eqmotion:
Equivariant multi-agent motion prediction with invariant interaction reasoning.
In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition. pp. 1410–1420 (2023) 1, 10
69. Xu,Y.,Bazarjani,A.,Chi,H.g.,Choi,C.,Fu,Y.:Uncoveringthemissingpattern:
Unified framework towards trajectory imputation and prediction. In: Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp.
9632–9643 (2023) 2, 4, 10, 12, 13
70. Yeh, R.A., Schwing, A.G., Huang, J., Murphy, K.: Diverse generation for multi-
agent sports games. In: Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition. pp. 4610–4619 (2019) 2, 3, 10, 12
71. Zhan,E.,Zheng,S.,Yue,Y.,Sha,L.,Lucey,P.:Generatingmulti-agenttrajectories
using programmatic weak supervision. arXiv preprint arXiv:1803.07612 (2018) 1,
3, 10, 12
72. Zheng, S., Yue, Y., Hobbs, J.: Generating long-term trajectories using deep hier-
archical networks. Advances in Neural Information Processing Systems 29 (2016)
1, 3(Supplementary)
TranSPORTmer: A Holistic Approach to
Trajectory Understanding in Multi-Agent Sports
Guillem Capellera1,2 , Luis Ferraz1 , Antonio Rubio1 , Antonio Agudo2 ,
and Francesc Moreno-Noguer2
1 Kognia Sports Intelligence, Barcelona, Spain
{guillem.capellera,luis.ferraz,antonio.rubio}@kogniasports.com
2 Institut de Robòtica i Informàtica Industrial CSIC-UPC, Barcelona, Spain
{gcapellera,aagudo,fmoreno}@iri.upc.edu
1 Soccer baselines
The task of forecasting (or imputing) player trajectories based on the future
movementoftheballortheopposingteamhasbeenseldomexploredbystate-of-
the-artmethods.Toourknowledge,therearefewbaselinemethodsthataddress
thisaspectinforecastingtasks[2,24].Therefore,weimplementedthesepipelines
to showcase the results for the soccer dataset presented in Table 1 of the main
paper. The baselines used for comparison are described as follows:
Velocity: As a sanity check, we adopted this baseline, projecting agent predic-
tions linearly based on observed velocity.
RNN: This baseline utilizes an encoder with LSTM, employing shared weights
to capture input representations of each agent, along with an MLP decoder for
prediction [4].
GRNN: This is a non-variational version of GVRNN [18,24], generating tra-
jectories without sampling. The training process involves using the ADE loss
( ).Yehetal.[24]demonstratedsuperiorresultsofGRNNoverGVRNNin
LADE
a soccer context. We use the implementation from Teranishi et al. [19].
GRNN + Att: Similar to the previous baseline but using a Graph Attention
Network (GAT) instead of GNNs, inspired by [5,10].
Transformer:Inspiredby[2,3],thisbaselineusesthesamepipelineasoursbut
incorporates attention through the flattened temporal and social dimensions. It
employs a 2D positional encoder [20], making it a non-equivariant baseline.
2 Training procedure
ThemodelsweretrainedonanNVIDIARTXA6000GPUfor100epochs,using
a batch size of 64 samples. We employed the AdamW optimizer [12,14] with a
learning rate of 0.001 and an epsilon value of 1 10 −4. The learning rate was
×
reducedbyafactorof0.5every20epochs.Topreventgradientexplosion,weap-
pliedgradientclippingwithathresholdof5,ensuringstableoptimization.Model
4202
tcO
32
]VC.sc[
1v58771.0142:viXra2 G. Capellera et al.
weightswereinitializedusingtheXaviernormaldistribution[8].Allexperiments
have been trained separately.
Thehyperparametersforourmethodandweresetasfollows:128-dimensional
embeddings (d), 16 heads in each Multi-Head-Attention (MHA) module, a hid-
den dimension of 512 for each Set Attention Block (SAB). In TranSPORT-
mer with state classification, the weight for the Cross-Entropy (CE) loss was
set to λ=4 to balance the magnitudes of the two losses. It is worth noting that
without state classification, λ=0.
3 Basketball experiments
3.1 Forecasting with conditioning
In Table 2 of the main paper, we conduct a comparative analysis between our
methodandforecasting-basedmodelsusingtheBasketball-VUdataset.Thema-
jority of these models are generative stochastic approaches primarily focused on
imitativetasks.However,theyaregenerallysub-optimalathandlingasignificant
numberofagentinteractions.Asaresult,theirabilitytoaccuratelyforecasttra-
jectories for offensive and defensive players jointly is hindered, especially when
trying to model trajectories for both teams simultaneously. Consequently, these
models often resort to separately modeling these trajectories. In contrast, our
method can model offensive and defensive players’ trajectories simultaneously
using a single model.
Furthermore,ourapproachcangeneratetrajectoriesbasedonthemovement
oftheopponentplayersand/ortheball.Thiscapabilityallowsustopredicttheir
future movements much more accurately. To illustrate this point, we would like
to present an additional experiment similar to Table 1 in our main paper but
focusedonthebasketballcontext.Thisexperimentshowcasestheresultsoffore-
casting basketball trajectories for players or the offensive/defensive team when
conditioned on the other team and/or the ball. The results of this experiment
are presented in Table 1, demonstrating the efficacy of our model in encod-
ing these interactions and providing more accurate results as the conditioning
agents increase. It’s important to note that defense predictions show significant
improvement when conditioned on the offensive team alone, more so than when
conditioned on the ball. This is due to the intrinsic nature of basketball, partic-
ularly in one-on-one defense situations.
PredictP Players Offense Defense
Condition None Ball None Ball Defense Ball+Defense None Ball Offense Ball+Offense
ADEP↓ 7.75 7.05 9.19 8.47 4.29 3.96 6.31 5.64 3.67 3.14
FDEP↓ 11.65 11.13 14.24 13.78 7.44 7.05 9.04 8.48 5.78 4.76
Table 1: Evaluation in Basketball-VU dataset in player trajectory forecast-
ingwithTranSPORTmerw/oCLS.Predictionsaregeneratedwithatimehorizon
of 8s using a prior of 2s. All metrics are in feet.TranSPORTmer 3
3.2 Unified imputation and forecasting
Fig.1: Initial timestep example of Basketball-TIP dataset for “circle mode”
and “camera mode”. The depicted (predicted) players are those with at least one
observation inside the circle/camera view during the imputation task.
Fig.2: Qualitative evaluation in Basketball-TIP dataset. Imputation during
first 6.4s and forecasting during the subsequent 1.6s. Refer to the supplemental video
to view the animated version.4 G. Capellera et al.
In Table 3 of the main paper, we present a comparison against the state-of-the-
artinunifiedimputationandforecastingtasksusingtheBasketball-TIPdataset.
Here, we include two figures to provide visual support for the concepts of “circle
mode” and “camera mode”, showing one test sample solved for each strategy.
Refer to Fig. 1 to view the initial time-step of the task, where the simulated
viewisdepicted.RefertoFig.2toviewthesamesequencesolveduntilthefinal
step with the predicted trajectories.
4 Training with missing data
In this section, we present two experiments conducted using the soccer dataset,
focusingonhandlingmissingdataforgoalkeepers.Thefirstexperimentinvolves
generating the adapted dataset, enabling us to compare our approach against
ballradar [23]. The second experiment assesses our model’s capability to predict
ball movements using the original dataset.
4.1 Adapted dataset: goalkeepers imputation and inference
Weoutlinethemethodologyforgoalkeepertrajectoryimputationandinference,
specifically tailored for creating the adapted dataset to facilitate a comparison
between TranSPORTmer and ballradar [11] in ball trajectory tasks. The ball-
radar baselinereliesonthepositionsofbothgoalkeepersforoptimalperformance
in ball prediction tasks.
We initiate the process with the original soccer dataset discussed in Section
5.1 of the main paper. Since the observations are derived from optical tracking,
several goalkeeper data points are missing. To address this, we initially filter
and retain sequences containing at least one observation of a goalkeeper. Sub-
sequently, we train TranSPORTmer in goalkeeper trajectory prediction using
these adapted sequences. A random mask is applied, obscuring 97% to 100%
of the goalkeepers’ observations. The goalkeepers’ unavailable observations are
ignored by our model using the NaN-mask during training.
The evaluation metrics for goalkeepers’ trajectory inference and imputation
in the test samples are presented in Table 2. In the inference task, all available
observationsareconcealed(100%mask),andtrajectoryimputationisperformed
with 97% of available observations hidden (97% mask). Figure 3 showcases two
test samples solved with all ground truth observations hidden (100% mask).
Using this trained model, we construct the adapted dataset by imputing the
positionsofmissingobservationsforgoalkeeperswithatleastoneobservation.In
cases where one goalkeeper has no observations throughout the entire sequence,
we manually set its position to a standard field position. Consequently, the new
adapted dataset comprises 73,595 sequences for training, 6,628 for validation,
and 5,725 for testing.TranSPORTmer 5
Fig.3: Goalkeepers inference through the full 9.6s sequence. All available
goalkeepers’ observations are hidden.
Task Mask ADE MaxErr
↓ ↓
Inference 100% 1.97 3.32
Imputation 97% 0.82 1.96
Table 2: Evaluation of goalkeepers’ imputation and inference on 9.6s se-
quences. The model utilized is TranSPORTmer w/o CLS. All metrics are in meters.
4.2 Ball inference
To ensure a fair comparison, in the main paper, we present the results of our
method trained and evaluated using the adapted soccer dataset, which con-
tains fewer sequences but includes inferred goalkeeper positions. Here, we aim
to demonstrate the effectiveness of our model in predicting ball location using
the original dataset, which lacks some goalkeeper observations but has approxi-
mately 10,000 (12.71%) more sequences for training. We present the results for
ball inference in Table 3, using both the adapted dataset without missing data
(adapted dataset w/o missing data) and the original dataset with missing data
(original dataset w missing data). It’s important to note that our model can
be trained with incomplete data, allowing us to train on more sequences and
leading to improved results.
adapteddatasetw/omissingdata originaldatasetwmissingdata
ballradar(KDD’23) Oursw/oCLS Ours Oursw/oCLS Ours
ADE 3.89 2.89 2.71 2.73 2.57
↓
MaxErr 8.79 7.78 7.39 7.58 7.22
↓
Acc(%) - - 80.84 - 81.64
↑
Table3:Evaluationinballinferenceinsoccer.Predictionsaregeneratedthrough
the full 9.6s sequence. All metrics, except Acc, are in meters.6 G. Capellera et al.
5 Coarse-to-fine ablation
In this section, we perform an ablation regarding the number of the encoders
of the proposed architecture. The considered task is the ball inference and we
compare Our w/o CLS, which utilize two encoders that act as a coarse-to-fine
manner,againstutilizingone-singleencoderandthreeencoders.Asingleencoder
yelds ADE and MaxErr metrics of 4.40m and 9.83m, respectively, compared to
our results of 2.71m and 7.39m (see Table 4 main paper). Figure 4 here shows
attentionmapsforSeq1andSeq2usingasingleencoder,exhibitingnoisierfocus
comparedtoourfineencoder(see“BallAttninsecondSAB ” inFig.4-rightmain
S
paper), leading to suboptimal results. Using three encoders fails to converge.
Fig.4: Results compared to Fig.4-right of the main paper using only one encoder.
6 Pedestrian forecasting
Although analyzing urban pedestrian scenes is outside the main scope of this
paper, for completeness we have included an experiment with the benchmark
dataset ETH-UCY [13,15]. This dataset comprises five different subsets: ETH,
Hotel,Univ,Zara1,andZara2.Wefollowtheestablishedconventionofleave-one-
outtraining[9]andemploythetaskofforecasting12futuretime-stepsbasedon
8precedingtime-steps,withaframerateof2.5Hz.Theresultsofourexperiment
againstdeterministicstate-of-the-artmodelsarepresentedinTable4.Itisworth
pointing out that our approach is on a par with the most recent architectures,
many of which are specifically tailored for pedestrian contexts, and achieves
strongresultsinthreesubsets(ETH,Zara1,Zara2)andonAverage.Weachieve
a 4.3% improvement in ADE on the ETH subset.
Model ETH Hotel Univ Zara1 Zara2 Average
S-LSTM[1] CVPR’16 1.09/2.35 0.79/1.76 0.67/1.40 0.47/1.00 0.56/1.17 0.72/1.54
SGAN-ind[9] CVPR’18 1.13/2.21 1.01/2.18 0.60/1.28 0.42/0.91 0.52/1.11 0.74/1.54
TransF[7] ICPR’20 1.03/2.10 0.36/0.71 0.53/1.32 0.44/1.00 0.34/0.76 0.54/1.17
Trajectron++[17] ECCV’20 1.02/2.00 0.33/0.62 0.53/1.19 0.44/0.99 0.32/0.73 0.53/1.11
MemoNet[21] CVPR’22 1.00/2.08 0.35/0.67 0.55/1.19 0.46/1.00 0.32/0.82 0.55/1.15
Autobots[6] ICLR’22 1.02/1.89 0.32/0.60 0.54/1.16 0.41/0.89 0.32/0.71 0.52/1.05
EqMotion[22] CVPR’23 0.96/1.92 0.30/0.58 0.50/1.10 0.39/0.86 0.30/0.68 0.49/1.03
Social-Transmotion[16] ICLR’24 0.93/1.81 0.32/0.60 0.54/1.16 0.42/0.90 0.32/0.70 0.51/1.03
Ourw/oCLS 0.89/1.87 0.36/0.73 0.57/1.22 0.40/0.87 0.31/0.69 0.51/1.08
Table 4: Evaluation on ETH-UCY dataset in pedestrian forecasting
(ADE/FDE).Theobservationisperformedduring8time-steps(3.2s)whilethefore-
castingisperformedduringthesubsequent12time-steps(4.8s).Resultsareextracted
from previous works [16,22].TranSPORTmer 7
References
1. Alahi,A.,Goel,K.,Ramanathan,V.,Robicquet,A.,Fei-Fei,L.,Savarese,S.:Social
lstm:Humantrajectorypredictionincrowdedspaces.In:ProceedingsoftheIEEE
conference on computer vision and pattern recognition. pp. 961–971 (2016) 6
2. Alcorn, M.A., Nguyen, A.: baller2vec++: A look-ahead multi-entity transformer
for modeling coordinated agents. arXiv preprint arXiv:2104.11980 (2021) 1
3. Alcorn, M.A., Nguyen, A.: baller2vec: A multi-entity transformer for multi-agent
spatiotemporal modeling. arXiv preprint arXiv:2102.03291 (2021) 1
4. Becker, S., Hug, R., Hubner, W., Arens, M.: Red: A simple but effective baseline
predictor for the trajnet benchmark. In: Proceedings of the European Conference
on Computer Vision (ECCV) Workshops. pp. 0–0 (2018) 1
5. Ding,D.,Huang,H.H.:Agraphattentionbasedapproachfortrajectoryprediction
in multi-agent sports games. arXiv preprint arXiv:2012.10531 (2020) 1
6. Girgis,R.,Golemo,F.,Codevilla,F.,Weiss,M.,D’Souza,J.A.,Kahou,S.E.,Heide,
F.,Pal,C.:Latentvariablesequentialsettransformersforjointmulti-agentmotion
prediction. arXiv preprint arXiv:2104.00563 (2021) 6
7. Giuliari, F., Hasan, I., Cristani, M., Galasso, F.: Transformer networks for tra-
jectory forecasting. In: 2020 25th international conference on pattern recognition
(ICPR). pp. 10335–10342. IEEE (2021) 6
8. Glorot, X., Bengio, Y.: Understanding the difficulty of training deep feedforward
neural networks. In: Proceedings of the thirteenth international conference on ar-
tificial intelligence and statistics. pp. 249–256. JMLR Workshop and Conference
Proceedings (2010) 2
9. Gupta, A., Johnson, J., Fei-Fei, L., Savarese, S., Alahi, A.: Social gan: Socially
acceptable trajectories with generative adversarial networks. In: Proceedings of
the IEEE conference on computer vision and pattern recognition. pp. 2255–2264
(2018) 6
10. Huang, Y., Bi, H., Li, Z., Mao, T., Wang, Z.: Stgat: Modeling spatial-temporal
interactions for human trajectory prediction. In: Proceedings of the IEEE/CVF
international conference on computer vision. pp. 6272–6281 (2019) 1
11. Kim, H., Choi, H.J., Kim, C.J., Yoon, J., Ko, S.K.: Ball trajectory inference from
multi-agent sports contexts using set transformer and hierarchical bi-lstm. arXiv
preprint arXiv:2306.08206 (2023) 4
12. Kingma,D.P.,Ba,J.:Adam:Amethodforstochasticoptimization.arXivpreprint
arXiv:1412.6980 (2014) 1
13. Lerner,A.,Chrysanthou,Y.,Lischinski,D.:Crowdsbyexample.Computergraph-
ics forum 26(3), 655–664 (2007) 6
14. Loshchilov, I., Hutter, F.: Decoupled weight decay regularization. arXiv preprint
arXiv:1711.05101 (2017) 1
15. Pellegrini, S., Ess, A., Schindler, K., Van Gool, L.: You’ll never walk alone: Mod-
eling social behavior for multi-target tracking. In: 2009 IEEE 12th international
conference on computer vision. pp. 261–268. IEEE (2009) 6
16. Saadatnejad,S.,Gao,Y.,Messaoud,K.,Alahi,A.:Social-transmotion:Promptable
human trajectory prediction. arXiv preprint arXiv:2312.16168 (2023) 6
17. Salzmann, T., Ivanovic, B., Chakravarty, P., Pavone, M.: Trajectron++: Multi-
agentgenerativetrajectoryforecastingwithheterogeneousdataforcontrol.arXiv
preprint arXiv:2001.03093 2 (2020) 6
18. Sun, C., Karlsson, P., Wu, J., Tenenbaum, J.B., Murphy, K.: Stochastic pre-
diction of multi-agent interactions from partial observations. arXiv preprint
arXiv:1902.09641 (2019) 18 G. Capellera et al.
19. Teranishi, M., Tsutsui, K., Takeda, K., Fujii, K.: Evaluation of creating scoring
opportunities for teammates in soccer via trajectory prediction. In: International
WorkshoponMachineLearningandDataMiningforSportsAnalytics.pp.53–73.
Springer (2022) 1
20. Wang, Z., Liu, J.C.: Translating math formula images to latex sequences using
deep neural networks with sequence-level training (2019) 1
21. Xu, C., Mao, W., Zhang, W., Chen, S.: Remember intentions: Retrospective-
memory-basedtrajectoryprediction.In:ProceedingsoftheIEEE/CVFConference
on Computer Vision and Pattern Recognition. pp. 6488–6497 (2022) 6
22. Xu,C.,Tan,R.T.,Tan,Y.,Chen,S.,Wang,Y.G.,Wang,X.,Wang,Y.:Eqmotion:
Equivariant multi-agent motion prediction with invariant interaction reasoning.
In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition. pp. 1410–1420 (2023) 6
23. Xu,Y.,Bazarjani,A.,Chi,H.g.,Choi,C.,Fu,Y.:Uncoveringthemissingpattern:
Unified framework towards trajectory imputation and prediction. In: Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp.
9632–9643 (2023) 4
24. Yeh, R.A., Schwing, A.G., Huang, J., Murphy, K.: Diverse generation for multi-
agent sports games. In: Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition. pp. 4610–4619 (2019) 1