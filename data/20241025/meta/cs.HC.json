[
    {
        "title": "The Double-Edged Sword of Behavioral Responses in Strategic Classification: Theory and User Studies",
        "authors": "Raman EbrahimiKristen VaccaroParinaz Naghizadeh",
        "links": "http://arxiv.org/abs/2410.18066v1",
        "entry_id": "http://arxiv.org/abs/2410.18066v1",
        "pdf_url": "http://arxiv.org/pdf/2410.18066v1",
        "summary": "When humans are subject to an algorithmic decision system, they can\nstrategically adjust their behavior accordingly (``game'' the system). While a\ngrowing line of literature on strategic classification has used game-theoretic\nmodeling to understand and mitigate such gaming, these existing works consider\nstandard models of fully rational agents. In this paper, we propose a strategic\nclassification model that considers behavioral biases in human responses to\nalgorithms. We show how misperceptions of a classifier (specifically, of its\nfeature weights) can lead to different types of discrepancies between biased\nand rational agents' responses, and identify when behavioral agents over- or\nunder-invest in different features. We also show that strategic agents with\nbehavioral biases can benefit or (perhaps, unexpectedly) harm the firm compared\nto fully rational strategic agents. We complement our analytical results with\nuser studies, which support our hypothesis of behavioral biases in human\nresponses to the algorithm. Together, our findings highlight the need to\naccount for human (cognitive) biases when designing AI systems, and providing\nexplanations of them, to strategic human in the loop.",
        "updated": "2024-10-23 17:42:54 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.18066v1"
    },
    {
        "title": "A Comparative Assessment of Technology Acceptance and Learning Outcomes in Computer-based versus VR-based Pedagogical Agents",
        "authors": "Aimilios HadjiliasiLouis NisiotisIrene Polycarpou",
        "links": "http://arxiv.org/abs/2410.18048v1",
        "entry_id": "http://arxiv.org/abs/2410.18048v1",
        "pdf_url": "http://arxiv.org/pdf/2410.18048v1",
        "summary": "As educational technology evolves, the potential of Pedagogical Agents (PAs)\nin supporting education is extensively explored. Typically, research on PAs has\nprimarily focused on computer-based learning environments, but their use in\nVR-based environments and integration into education is still in its infancy.\nTo address this gap, this paper presents a mixed method comparative study that\nhas been conducted to evaluate and examine how these computer-based PAs and\nVR-based PAs compare, towards their learning efficacy and technology\nacceptance. 92 Computing and Engineering undergraduate students were recruited\nand participated in an educational experience focusing on computing machinery\neducation. The findings of this study revealed that both approaches can\neffectively facilitate learning acquisition, and both technologies have been\npositively perceived by participants toward acceptance, without any significant\ndifferences. The findings of this study shed light on the potential of\nutilizing intelligent PAs to support education, contributing towards the\nadvancement of our understanding of how to integrate such technologies to\ndevelop learning interventions, and establishing the foundation for future\ninvestigations that aim to successfully integrate and use PAs in education.",
        "updated": "2024-10-23 17:20:35 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.18048v1"
    },
    {
        "title": "AI as a Bridge Across Ages: Exploring The Opportunities of Artificial Intelligence in Supporting Inter-Generational Communication in Virtual Reality",
        "authors": "Qiuxin DuXiaoying WeiJiawei LiEmily KuangJie HaoDongdong WengMingming Fan",
        "links": "http://arxiv.org/abs/2410.17909v1",
        "entry_id": "http://arxiv.org/abs/2410.17909v1",
        "pdf_url": "http://arxiv.org/pdf/2410.17909v1",
        "summary": "Inter-generational communication is essential for bridging generational gaps\nand fostering mutual understanding. However, maintaining it is complex due to\ncultural, communicative, and geographical differences. Recent research\nindicated that while Virtual Reality (VR) creates a relaxed atmosphere and\npromotes companionship, it inadequately addresses the complexities of\ninter-generational dialogue, including variations in values and relational\ndynamics. To address this gap, we explored the opportunities of Artificial\nIntelligence (AI) in supporting inter-generational communication in VR. We\ndeveloped three technology probes (e.g., Content Generator, Communication\nFacilitator, and Info Assistant) in VR and employed them in a probe-based\nparticipatory design study with twelve inter-generational pairs. Our results\nshow that AI-powered VR facilitates inter-generational communication by\nenhancing mutual understanding, fostering conversation fluency, and promoting\nactive participation. We also introduce several challenges when using\nAI-powered VR in supporting inter-generational communication and derive design\nimplications for future VR platforms, aiming to improve inter-generational\ncommunication.",
        "updated": "2024-10-23 14:28:16 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.17909v1"
    },
    {
        "title": "Leveraging the Domain Adaptation of Retrieval Augmented Generation Models for Question Answering and Reducing Hallucination",
        "authors": "Salman RakinMd. A. R. ShiblyZahin M. HossainZeeshan KhanMd. Mostofa Akbar",
        "links": "http://arxiv.org/abs/2410.17783v1",
        "entry_id": "http://arxiv.org/abs/2410.17783v1",
        "pdf_url": "http://arxiv.org/pdf/2410.17783v1",
        "summary": "While ongoing advancements in Large Language Models have demonstrated\nremarkable success across various NLP tasks, Retrieval Augmented Generation\nModel stands out to be highly effective on downstream applications like\nQuestion Answering. Recently, RAG-end2end model further optimized the\narchitecture and achieved notable performance improvements on domain\nadaptation. However, the effectiveness of these RAG-based architectures remains\nrelatively unexplored when fine-tuned on specialized domains such as customer\nservice for building a reliable conversational AI system. Furthermore, a\ncritical challenge persists in reducing the occurrence of hallucinations while\nmaintaining high domain-specific accuracy. In this paper, we investigated the\nperformance of diverse RAG and RAG-like architectures through domain adaptation\nand evaluated their ability to generate accurate and relevant response grounded\nin the contextual knowledge base. To facilitate the evaluation of the models,\nwe constructed a novel dataset HotelConvQA, sourced from wide range of\nhotel-related conversations and fine-tuned all the models on our domain\nspecific dataset. We also addressed a critical research gap on determining the\nimpact of domain adaptation on reducing hallucinations across different RAG\narchitectures, an aspect that was not properly measured in prior work. Our\nevaluation shows positive results in all metrics by employing domain\nadaptation, demonstrating strong performance on QA tasks and providing insights\ninto their efficacy in reducing hallucinations. Our findings clearly indicate\nthat domain adaptation not only enhances the models' performance on QA tasks\nbut also significantly reduces hallucination across all evaluated RAG\narchitectures.",
        "updated": "2024-10-23 11:32:46 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.17783v1"
    },
    {
        "title": "Efficient and Aesthetic UI Design with a Deep Learning-Based Interface Generation Tree Algorithm",
        "authors": "Shiyu DuanRunsheng ZhangMengmeng ChenZiyi WangShixiao Wang",
        "links": "http://arxiv.org/abs/2410.17586v1",
        "entry_id": "http://arxiv.org/abs/2410.17586v1",
        "pdf_url": "http://arxiv.org/pdf/2410.17586v1",
        "summary": "This paper presents a novel method for user interface (UI) generation based\non the Transformer architecture, addressing the increasing demand for efficient\nand aesthetically pleasing UI designs in software development. Traditional UI\ndesign relies heavily on designers' expertise, which can be time-consuming and\ncostly. Leveraging the capabilities of Transformers, particularly their ability\nto capture complex design patterns and long-range dependencies, we propose a\nTransformer-based interface generation tree algorithm. This method constructs a\nhierarchical representation of UI components as nodes in a tree structure,\nutilizing pre-trained Transformer models for encoding and decoding. We define a\nmarkup language to describe UI components and their properties and use a rich\ndataset of real-world web and mobile application interfaces for training. The\nexperimental results demonstrate that our approach not only significantly\nenhances design quality and efficiency but also outperforms traditional models\nin user satisfaction and aesthetic appeal. We also provide a comparative\nanalysis with existing models, illustrating the advantages of our method in\nterms of accuracy, user ratings, and design similarity. Overall, our study\nunderscores the potential of the Transformer based approach to revolutionize\nthe UI design process, making it accessible for non-professionals while\nmaintaining high standards of quality.",
        "updated": "2024-10-23 06:20:37 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.17586v1"
    }
]