[
    {
        "title": "ALTA: Compiler-Based Analysis of Transformers",
        "authors": "Peter ShawJames CohanJacob EisensteinKenton LeeJonathan BerantKristina Toutanova",
        "links": "http://arxiv.org/abs/2410.18077v1",
        "entry_id": "http://arxiv.org/abs/2410.18077v1",
        "pdf_url": "http://arxiv.org/pdf/2410.18077v1",
        "summary": "We propose a new programming language called ALTA and a compiler that can map\nALTA programs to Transformer weights. ALTA is inspired by RASP, a language\nproposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler\nfrom RASP programs to Transformer weights. ALTA complements and extends this\nprior work, offering the ability to express loops and to compile programs to\nUniversal Transformers, among other advantages. ALTA allows us to\nconstructively show how Transformers can represent length-invariant algorithms\nfor computing parity and addition, as well as a solution to the SCAN benchmark\nof compositional generalization tasks, without requiring intermediate\nscratchpad decoding steps. We also propose tools to analyze cases where the\nexpressibility of an algorithm is established, but end-to-end training on a\ngiven training set fails to induce behavior consistent with the desired\nalgorithm. To this end, we explore training from ALTA execution traces as a\nmore fine-grained supervision signal. This enables additional experiments and\ntheoretical analyses relating the learnability of various algorithms to data\navailability and modeling decisions, such as positional encodings. We make the\nALTA framework -- language specification, symbolic interpreter, and weight\ncompiler -- available to the community to enable further applications and\ninsights.",
        "updated": "2024-10-23 17:58:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.18077v1"
    },
    {
        "title": "Leveraging Skills from Unlabeled Prior Data for Efficient Online Exploration",
        "authors": "Max WilcoxsonQiyang LiKevin FransSergey Levine",
        "links": "http://arxiv.org/abs/2410.18076v1",
        "entry_id": "http://arxiv.org/abs/2410.18076v1",
        "pdf_url": "http://arxiv.org/pdf/2410.18076v1",
        "summary": "Unsupervised pretraining has been transformative in many supervised domains.\nHowever, applying such ideas to reinforcement learning (RL) presents a unique\nchallenge in that fine-tuning does not involve mimicking task-specific data,\nbut rather exploring and locating the solution through iterative\nself-improvement. In this work, we study how unlabeled prior trajectory data\ncan be leveraged to learn efficient exploration strategies. While prior data\ncan be used to pretrain a set of low-level skills, or as additional off-policy\ndata for online RL, it has been unclear how to combine these ideas effectively\nfor online exploration. Our method SUPE (Skills from Unlabeled Prior data for\nExploration) demonstrates that a careful combination of these ideas compounds\ntheir benefits. Our method first extracts low-level skills using a variational\nautoencoder (VAE), and then pseudo-relabels unlabeled trajectories using an\noptimistic reward model, transforming prior data into high-level, task-relevant\nexamples. Finally, SUPE uses these transformed examples as additional\noff-policy data for online RL to learn a high-level policy that composes\npretrained low-level skills to explore efficiently. We empirically show that\nSUPE reliably outperforms prior strategies, successfully solving a suite of\nlong-horizon, sparse-reward tasks. Code: https://github.com/rail-berkeley/supe.",
        "updated": "2024-10-23 17:58:45 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.18076v1"
    },
    {
        "title": "TP-Eval: Tap Multimodal LLMs' Potential in Evaluation by Customizing Prompts",
        "authors": "Yuxuan XieTianhua LiWenqi ShaoKaipeng Zhang",
        "links": "http://arxiv.org/abs/2410.18071v1",
        "entry_id": "http://arxiv.org/abs/2410.18071v1",
        "pdf_url": "http://arxiv.org/pdf/2410.18071v1",
        "summary": "Recently, multimodal large language models (MLLMs) have received much\nattention for their impressive capabilities. The evaluation of MLLMs is\nbecoming critical to analyzing attributes of MLLMs and providing valuable\ninsights. However, current benchmarks overlook the problem of prompt\nsensitivity - minor prompt variations may lead to significant performance\nfluctuations. Thus, inappropriate prompts may obscure the models' capabilities,\nunderestimating the models' performance. Moreover, different models have\ndifferent preferences for different prompts, and thus, using the same prompt\nfor all models will cause evaluation bias. This paper analyzes this deficiency\nin existing benchmarks and further introduces a new evaluation framework named\nTP-Eval, which introduces a prompt customization method to reduce evaluation\nbiases and tap models' potential. TP-Eval will rewrite the original prompts to\ndifferent customized prompts for different models. In particular, we propose\nsome well-designed modules for prompt customization tailored to the scenario of\nMLLM evaluation. Extensive experiments demonstrate the effectiveness of our\napproach to uncovering models' capabilities, and TP-Eval should benefit the\ncommunity in developing more comprehensive and convincing MLLM evaluation\nbenchmarks.",
        "updated": "2024-10-23 17:54:43 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.18071v1"
    },
    {
        "title": "Training Free Guided Flow Matching with Optimal Control",
        "authors": "Luran WangChaoran ChengYizhen LiaoYanru QuGe Liu",
        "links": "http://arxiv.org/abs/2410.18070v1",
        "entry_id": "http://arxiv.org/abs/2410.18070v1",
        "pdf_url": "http://arxiv.org/pdf/2410.18070v1",
        "summary": "Controlled generation with pre-trained Diffusion and Flow Matching models has\nvast applications. One strategy for guiding ODE-based generative models is\nthrough optimizing a target loss $R(x_1)$ while staying close to the prior\ndistribution. Along this line, some recent work showed the effectiveness of\nguiding flow model by differentiating through its ODE sampling process. Despite\nthe superior performance, the theoretical understanding of this line of methods\nis still preliminary, leaving space for algorithm improvement. Moreover,\nexisting methods predominately focus on Euclidean data manifold, and there is a\ncompelling need for guided flow methods on complex geometries such as SO(3),\nwhich prevails in high-stake scientific applications like protein design. We\npresent OC-Flow, a general and theoretically grounded training-free framework\nfor guided flow matching using optimal control. Building upon advances in\noptimal control theory, we develop effective and practical algorithms for\nsolving optimal control in guided ODE-based generation and provide a systematic\ntheoretical analysis of the convergence guarantee in both Euclidean and SO(3).\nWe show that existing backprop-through-ODE methods can be interpreted as\nspecial cases of Euclidean OC-Flow. OC-Flow achieved superior performance in\nextensive experiments on text-guided image manipulation, conditional molecule\ngeneration, and all-atom peptide design.",
        "updated": "2024-10-23 17:53:11 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.18070v1"
    },
    {
        "title": "Beyond position: how rotary embeddings shape representations and memory in autoregressive transfomers",
        "authors": "Valeria RuscioFabrizio Silvestri",
        "links": "http://arxiv.org/abs/2410.18067v1",
        "entry_id": "http://arxiv.org/abs/2410.18067v1",
        "pdf_url": "http://arxiv.org/pdf/2410.18067v1",
        "summary": "Rotary Positional Embeddings (RoPE) enhance positional encoding in\nTransformer models, yet their full impact on model dynamics remains\nunderexplored. This paper studies how RoPE introduces position-dependent\nrotations, causing phase shifts in token embeddings that influence\nhigher-frequency components within the model's internal representations.\nThrough spectral analysis, we demonstrate that RoPE's rotation matrices induce\noscillatory behaviors in embeddings, affecting information retention across\nlayers and shaping temporal modeling capabilities. We show that activation\nfunctions in feed-forward networks interact with RoPE-modulated embeddings to\ngenerate harmonics, leading to constructive or destructive interference based\non phase alignment. Our findings reveal that phase alignment amplifies\nactivations and sharpens attention, while misalignment weakens activations and\ndisrupts focus on positional patterns. This study underscores the importance of\nfrequency components as intrinsic elements of model behavior, offering new\ninsights beyond traditional analyses.",
        "updated": "2024-10-23 17:48:28 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.18067v1"
    }
]