[
    {
        "title": "Prioritized Generative Replay",
        "authors": "Renhao WangKevin FransPieter AbbeelSergey LevineAlexei A. Efros",
        "links": "http://arxiv.org/abs/2410.18082v1",
        "entry_id": "http://arxiv.org/abs/2410.18082v1",
        "pdf_url": "http://arxiv.org/pdf/2410.18082v1",
        "summary": "Sample-efficient online reinforcement learning often uses replay buffers to\nstore experience for reuse when updating the value function. However, uniform\nreplay is inefficient, since certain classes of transitions can be more\nrelevant to learning. While prioritization of more useful samples is helpful,\nthis strategy can also lead to overfitting, as useful samples are likely to be\nmore rare. In this work, we instead propose a prioritized, parametric version\nof an agent's memory, using generative models to capture online experience.\nThis paradigm enables (1) densification of past experience, with new\ngenerations that benefit from the generative model's generalization capacity\nand (2) guidance via a family of \"relevance functions\" that push these\ngenerations towards more useful parts of an agent's acquired history. We show\nthis recipe can be instantiated using conditional diffusion models and simple\nrelevance functions such as curiosity- or value-based metrics. Our approach\nconsistently improves performance and sample efficiency in both state- and\npixel-based domains. We expose the mechanisms underlying these gains, showing\nhow guidance promotes diversity in our generated transitions and reduces\noverfitting. We also showcase how our approach can train policies with even\nhigher update-to-data ratios than before, opening up avenues to better scale\nonline RL agents.",
        "updated": "2024-10-23 17:59:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.18082v1"
    },
    {
        "title": "ALTA: Compiler-Based Analysis of Transformers",
        "authors": "Peter ShawJames CohanJacob EisensteinKenton LeeJonathan BerantKristina Toutanova",
        "links": "http://arxiv.org/abs/2410.18077v1",
        "entry_id": "http://arxiv.org/abs/2410.18077v1",
        "pdf_url": "http://arxiv.org/pdf/2410.18077v1",
        "summary": "We propose a new programming language called ALTA and a compiler that can map\nALTA programs to Transformer weights. ALTA is inspired by RASP, a language\nproposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler\nfrom RASP programs to Transformer weights. ALTA complements and extends this\nprior work, offering the ability to express loops and to compile programs to\nUniversal Transformers, among other advantages. ALTA allows us to\nconstructively show how Transformers can represent length-invariant algorithms\nfor computing parity and addition, as well as a solution to the SCAN benchmark\nof compositional generalization tasks, without requiring intermediate\nscratchpad decoding steps. We also propose tools to analyze cases where the\nexpressibility of an algorithm is established, but end-to-end training on a\ngiven training set fails to induce behavior consistent with the desired\nalgorithm. To this end, we explore training from ALTA execution traces as a\nmore fine-grained supervision signal. This enables additional experiments and\ntheoretical analyses relating the learnability of various algorithms to data\navailability and modeling decisions, such as positional encodings. We make the\nALTA framework -- language specification, symbolic interpreter, and weight\ncompiler -- available to the community to enable further applications and\ninsights.",
        "updated": "2024-10-23 17:58:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.18077v1"
    },
    {
        "title": "Leveraging Skills from Unlabeled Prior Data for Efficient Online Exploration",
        "authors": "Max WilcoxsonQiyang LiKevin FransSergey Levine",
        "links": "http://arxiv.org/abs/2410.18076v1",
        "entry_id": "http://arxiv.org/abs/2410.18076v1",
        "pdf_url": "http://arxiv.org/pdf/2410.18076v1",
        "summary": "Unsupervised pretraining has been transformative in many supervised domains.\nHowever, applying such ideas to reinforcement learning (RL) presents a unique\nchallenge in that fine-tuning does not involve mimicking task-specific data,\nbut rather exploring and locating the solution through iterative\nself-improvement. In this work, we study how unlabeled prior trajectory data\ncan be leveraged to learn efficient exploration strategies. While prior data\ncan be used to pretrain a set of low-level skills, or as additional off-policy\ndata for online RL, it has been unclear how to combine these ideas effectively\nfor online exploration. Our method SUPE (Skills from Unlabeled Prior data for\nExploration) demonstrates that a careful combination of these ideas compounds\ntheir benefits. Our method first extracts low-level skills using a variational\nautoencoder (VAE), and then pseudo-relabels unlabeled trajectories using an\noptimistic reward model, transforming prior data into high-level, task-relevant\nexamples. Finally, SUPE uses these transformed examples as additional\noff-policy data for online RL to learn a high-level policy that composes\npretrained low-level skills to explore efficiently. We empirically show that\nSUPE reliably outperforms prior strategies, successfully solving a suite of\nlong-horizon, sparse-reward tasks. Code: https://github.com/rail-berkeley/supe.",
        "updated": "2024-10-23 17:58:45 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.18076v1"
    },
    {
        "title": "ProFL: Performative Robust Optimal Federated Learning",
        "authors": "Xue ZhengTian XieXuwei TanAylin YenerXueru ZhangAli PayaniMyungjin Lee",
        "links": "http://arxiv.org/abs/2410.18075v1",
        "entry_id": "http://arxiv.org/abs/2410.18075v1",
        "pdf_url": "http://arxiv.org/pdf/2410.18075v1",
        "summary": "Performative prediction (PP) is a framework that captures distribution shifts\nthat occur during the training of machine learning models due to their\ndeployment. As the trained model is used, its generated data could cause the\nmodel to evolve, leading to deviations from the original data distribution. The\nimpact of such model-induced distribution shifts in the federated learning (FL)\nsetup remains unexplored despite being increasingly likely to transpire in\nreal-life use cases. Although Jin et al. (2024) recently extended PP to FL in a\nstraightforward manner, the resulting model only converges to a performative\nstable point, which may be far from optimal. The methods in Izzo et al. (2021);\nMiller et al. (2021) can find a performative optimal point in centralized\nsettings, but they require the performative risk to be convex and the training\ndata to be noiseless, assumptions often violated in realistic FL systems. This\npaper overcomes all of these shortcomings and proposes Performative robust\noptimal Federated Learning (ProFL), an algorithm that finds performative\noptimal points in FL from noisy and contaminated data. We present the\nconvergence analysis under the Polyak-Lojasiewicz condition, which applies to\nnon-convex objectives. Extensive experiments on multiple datasets validate our\nproposed algorithms' efficiency.",
        "updated": "2024-10-23 17:57:14 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.18075v1"
    },
    {
        "title": "UnCLe: Unsupervised Continual Learning of Depth Completion",
        "authors": "Suchisrit GangopadhyayXien ChenMichael ChuPatrick RimHyoungseob ParkAlex Wong",
        "links": "http://arxiv.org/abs/2410.18074v1",
        "entry_id": "http://arxiv.org/abs/2410.18074v1",
        "pdf_url": "http://arxiv.org/pdf/2410.18074v1",
        "summary": "We propose UnCLe, a standardized benchmark for Unsupervised Continual\nLearning of a multimodal depth estimation task: Depth completion aims to infer\na dense depth map from a pair of synchronized RGB image and sparse depth map.\nWe benchmark depth completion models under the practical scenario of\nunsupervised learning over continuous streams of data. Existing methods are\ntypically trained on a static, or stationary, dataset. However, when adapting\nto novel non-stationary distributions, they \"catastrophically forget\"\npreviously learned information. UnCLe simulates these non-stationary\ndistributions by adapting depth completion models to sequences of datasets\ncontaining diverse scenes captured from distinct domains using different visual\nand range sensors. We adopt representative methods from continual learning\nparadigms and translate them to enable unsupervised continual learning of depth\ncompletion. We benchmark these models for indoor and outdoor and investigate\nthe degree of catastrophic forgetting through standard quantitative metrics.\nFurthermore, we introduce model inversion quality as an additional measure of\nforgetting. We find that unsupervised continual learning of depth completion is\nan open problem, and we invite researchers to leverage UnCLe as a development\nplatform.",
        "updated": "2024-10-23 17:56:33 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.18074v1"
    }
]