ANAH: Analytical Annotation of Hallucinations in Large Language Models
ZiweiJi1,2∗ YuzheGu1* WenweiZhang1† ChengqiLyu1 DahuaLin1,3 KaiChen1†
1ShanghaiAILaboratory 2HongKongUniversityofScienceandTechnology
3TheChineseUniversityofHongKong
zjiad@connect.ust.hk {guyuzhe,zhangwenwei,lvchengqi,chenkai}@pjlab.org.cn
Abstract
What were Omar Khayyam's notable contributions to
mathematics?
Reducingthe‘hallucination’problemofLarge Question
Sentencei-1: ···
LanguageModels(LLMs)iscrucialfortheir Sentencei: He wrote a book called "Treatise on the
wideapplications. Acomprehensiveandfine- Circumference of a Circle" which was a major work in
Generated the field of geometry.
grainedmeasurementofthehallucinationisthe Answer Sentencei+1: ···
firstkeystepforthegovernanceofthisissue
butisunder-exploredinthecommunity. Thus,
Fine-grained Annotation for Sentencei
wepresentANAH,abilingualdatasetthatof- Reference Fragment:
A commentary on the difficulties
fersANalyticalAnnotationofHallucinations concerning the postulates of Euclid's
inLLMswithinGenerativeQuestionAnswer- Retrieve Elements, On the division of a
Reference quadrant of a circle, and On proofs for
ing. Each answer sentence in our dataset un-
problems concerning Algebra.
dergoesrigorousannotation,involvingthere-
trievalofareferencefragment, thejudgment Halluciantion Type:
ofthehallucinationtype,andthecorrectionof Sentence- Judge Tpye Contradictory
level
hallucinatedcontent. ANAHconsistsof∼12k Annotaion
Correction:
sentence-levelannotationsfor∼4.3kLLMre- Change "{Hallucinated Content}" to "
Correct {Supported Content}".
sponsescoveringover700topics,constructed
Hallucination
by a human-in-the-loop pipeline. Thanks to
thefinegranularityofthehallucinationanno-
tations,wecanquantitativelyconfirmthatthe Figure1: AnexampleofANAHforsentence-levelhal-
hallucinationsofLLMsprogressivelyaccumu- lucination annotation. Each sentence in a generated
lateintheansweranduseANAHtotrainand answerisannotatedinfine-grainedwithReferenceFrag-
evaluatehallucinationannotators. Weconduct ment,HallucinationType,andCorrection. Thehalluci-
extensiveexperimentsonstudyinggenerative natedandsupportedcontentarehighlightedin orange
and discriminative annotators and show that, and blue,respectively.
althoughcurrentopen-sourceLLMshavediffi-
cultiesinfine-grainedhallucinationannotation,
the generative annotator trained with ANAH LLMsstillfaceaworrisomeproblemthatsignifi-
can surpass all open-source LLMs and GPT- cantlyhinderstheirreal-worldapplications,hallu-
3.5,obtainperformancecompetitivewithGPT- cination,inwhichtheyproduceplausible-sounding
4,andexhibitsbettergeneralizationabilityon butunfaithfulornonsensicalinformation(Jietal.,
unseenquestions.1
2022;Bangetal.,2023)whenansweringtheuser
questions,especiallythoserequireintensiveknowl-
1 Introduction
edge. Given the fluency and convincing nature
of the responses produced by LLMs, the detec-
Large Language Models (LLMs) have achieved
tion of their hallucinations becomes increasingly
significant performance improvements across a
difficult (Adlakha et al., 2023; Ren et al., 2023;
diverse array of Natural Language Processing
Pezeshkpour,2023). Suchachallengeimpedesthe
tasks(Petronietal.,2021;Kamallooetal.,2023;
deepanalysisandreductionofLLMhallucination
Sunetal.,2023;Chenetal.,2023,2024). However,
andleadstoextensivedisseminationofmisleading
*Equalcontributions informationastheuserbasewidensandreal-world
†Correspondingauthor applicationsproliferate(Mallenetal.,2023).
1Please find the dataset, code, and model at https://
github.com/open-compass/ANAH. Therehavebeenextensiveeffortsoneffectively
4202
yaM
03
]LC.sc[
1v51302.5042:viXradetecting and evaluating hallucination (Durmus (a) Topic Selection & Reference Retrieval (b) Question Generation & Selection
etal.,2020;Mündleretal.,2023;Duetal.,2023a). Reference Selection
Retrieval
Authenticity
However,mostbenchmarkswereproposedbefore Database Topic Hard+Soft Reference Question Answerability Final
Selection Match Document Generation Difficulty Question
the advent of LLM and targeted specific English Diversity
(c) Answer Generation (d) Fine-grained Hallucination Annotation
tasks (Dziri et al., 2021; Rohrbach et al., 2018),
Fine-grained
Annotation
whicharenotchallengingforcurrentmodels. Re-
centbenchmarks(Lietal.,2023a,2024)forLLMs w Ri eth fe / r ew nit ch eout Answer AA nu nto om taa tit oic n AH nnu om taa tn ion T R Cy e op f re re ere ctn ioc ne
only categorize whether the entire response con-
Figure2: Theoverviewofdatasetestablishment,com-
tainshallucinationswithoutexplanationandrefer-
prising(a)TopicSelectionandReferenceRetrieval,(b)
ence. Thiscoarse-grainednaturemakesitdifficult
QuestionGenerationandSelection,(c)AnswerGenera-
totracetheexacttriggerofhallucinationsandob-
tion,and(d)Fine-grainedHallucinationAnnotation.
structsfurthermitigationofthem.
Therefore, we establish a novel large-scale train and evaluate hallucination annotators. We
Chinese-Englishbenchmark,namedANAH2,that firstdiscoveredthatonlyGPT-4coulddothistask
assessestheLLMs’abilitytoannotatetheLLMhal- well. Thus, we further investigate training gener-
lucinations sentence-by-sentence, in the scenario ative and discriminative hallucination annotators
ofknowledge-basedgenerativequestionanswering. usingANAHandobservetheadvantagesofgener-
Ratherthansolelyresult-oriented,foreachanswer ativeannotatorsoverdiscriminativeannotatorsin
toaquestion,ourapproachpromptsthemodelto handlingtheimbalanceissueofhallucinationtypes.
annotate hallucination for each sentence, includ- Remarkably,ourgenerativeannotatorsachievean
ingretrievingreferencefragmentforthesentence, accuracyof81.01%,surpassingopen-sourcemod-
judging the hallucination type (No/Contradicto- els and rivaling GPT-4 (86.97%) in performance
ry/UnverifiableHallucinations,andNoFact),and withasmallersizeandlowersourcecost. Wealso
correctingthesentencebasedonthereferencefrag- observe that the hallucination annotators consis-
mentifhallucinationexists(Fig.1). tently exhibit better generalization regarding the
number of questions than the breadth of topics,
Tofacilitatethescale-upofdatasets,weensure
therebyguidingustowardprioritizingdatascaling
the comprehensiveness and diversity of ANAH
tocoverabroaderarrayoftopicsinfutureresearch.
acrossvarioustopics,questions,andanswers. As
shown in Fig. 2, first, we curate topics in both
2 DatasetConstruction
English and Chinese, encompassing a broad do-
main range including things, places, people, and ANAH’s establishment contains four stages
historicalevents(Fig.3). Second,wecraftaround (Fig. 2): (1) selecting a broad range of topics to
three related questions for each topic to ensure ensurecomprehensiveness(§2.1),(2)constructing
originality and avoid contamination. Third, for relatedquestionswhoseresponsescanbefullysup-
each question, we construct a high-quality and a portedbyreference(§2.2),(3)generatinganswers
low-quality response with and without reference fromLLMsunderdifferentmodelsandscenarios
ingeneration,respectively,enablingacomparative (§2.3),and(4)fine-grainedhallucinationannota-
analysisofhallucinationdistributionsacrossdiffer- tionforfurtheranalysisandmitigation(§2.4).
entresponsescenarios. Thefinalandpivotalstage
isfine-grainedhallucinationannotation,asexem- 2.1 TopicSelectionandReferenceRetrieval
plified in Fig. 1. Eventually, we form ∼12k hal-
The initial stage involves the selection of topics
lucinationannotationsof∼4.3kanswersto∼2.2k
and corresponding references from knowledge-
questionsspanningabroaddomainrange,whichis
intensivedatasets. Toensurediversifiedandwide-
challengingforhallucinationdetection.
ranginginformation,ourtopicchoicesarecatego-
Thankstothecompletenessandfine-granularity rizedintocelebrities,events,locations,andthings.
of ANAH, the statistical results of the hallucina- Wealsoencompassvariousdomains,includingbut
tionannotationsquantitativelyconfirmthathallu- not limited to Politics and Military, Art, Science
cinations progressively accumulate in the LLM and Technology, Religion, etc. ( Fig. 3). Topics
responses. Furthermore, ANAH can be used to are meticulously chosen based on the frequency
of their occurrence via Google Ngram Viewer 3
2ANAH is short for ANalytical Annotation of
Hallucinations. 3https://books.google.com/ngrams/ones 8. Finally, manual filtering is performed to
(a)
iron out the problem of renaming. Overall, this
phaseestablishesarobustfoundationfortheensu-
ingstepsofbenchmarkconstruction.
2.2 QuestionGenerationandSelection
The second stage involves the generation and se-
lectionofseveralquestionsbasedontheprovided
referencedocumentsaboutaparticulartopic. Toin-
creasethepossibilitythatthedataisunseenandun-
(b)
tainted,wecreatenewquestionsratherthanrepur-
posingexistingdatasets. Thequestionsareframed
in a manner so that they can be fully answered
exclusively grounded on the provided reference
documents, avoiding being overly subjective or
open-ended. To ensure diversity and comprehen-
sion across questions, they are designed to cover
different types, such as ‘what’, ‘when’, ‘where’,
‘why’, etc, and perspectives such as descriptions,
Figure3:Thetopicdistributionbychartof(a)categories
explanations,reasons,etc.,encapsulatingallfacets
(inner)anddomains(outer),and(b)wordcloud.
of the information. The questions also traverse
diverse levels of knowledge, ranging from basic,
sincetopicsthatmorefrequentlyoccurandareof
generic knowledge to more intricate, specialized
publicinterestshouldbemoreimportantforreal-
knowledgeordomain-specificexpertise. Thegen-
worldapplicationsofLLMs. Wealsocollecttopics
erationpromptisshowninFig.A2.
frompubliclyavailablesummarieslikehistorical
To assure the uniqueness of each question and
timelinesandtherankingofinfluentialpersons4.
avoidduplication,weleverageCoSENT9 forChi-
After selecting the topics, their correspond-
nese and MiniLM 10 for English, respectively,
ing reference documents are retrieved from pre-
tocalculate similaritiesamong questionsand sift
training databases (He et al., 2022), including
out overly similar ones11. We then employ GPT-
Wikipedia5, Baidu Baike6, Encyclopedia Britan-
3.5 (OpenAI, 2023) to assess their answerability,
nica7. Weselectthedatasetsthathavebeenwidely
i.e.,whetherthegivenquestionscanbeanswered
used in the pre-training stage of LLMs (Touvron
basedsolelyontheprovidedreferencedocuments.
et al., 2023) so that we can make sure that the
Thisensuresthatthequestionsarefact-based,ob-
modelsawthetruth,whichisimportantforfurther
jective, and possess a definitive answer, thus in-
analysisandmitigationofhallucinations.
creasingthereliabilityandconsistencyoftheeval-
During the reference retrieval process, the dis-
uationprocess. ThepromptdetailsareinFig.A3.
crepanciesinnomenclatureacrossdifferentsources
Finally,weutilizeGPT-4(OpenAI,2023)tose-
andthepotentialofasinglenamehavingmultiple
lectthetopthreequestionsfromtheabovecandi-
meaningspresentchallenges. Toaddressthesechal-
date questions, considering the following charac-
lenges, we adopt a strategy that progresses from
teristics:
hard to soft matching. First, we perform exact
1. High authenticity: The questions should be
matching(i.e.,hardmatching)oftheentries. Then,
free from any intentionally misleading, am-
wesortthecandidateentriesaccordingtothesen-
biguous,orfalseinformation.
tence semantic similarity and further judge them
2. Highanswerability: Thequestionsexhibiting
withInternLM(Team,2023)toselectthecorrect
excessivesubjectivity,controversy,orpredic-
4For example, https://en.wikipedia.org/ 8PleaserefertoFig.A1fortheprompt.
wiki/Timeline_of_Chinese_history and https: 9https://huggingface.co/shibing624/
//pantheon.world/explore/rankings. text2vec-base-chinese
5https://www.wikipedia.org/ 10https://huggingface.co/
6https://baike.baidu.com/ sentence-transformers/all-MiniLM-L6-v2
7https://www.britannica.com/ 11PleaserrefertoAppendixAfordetails.Topic OmarKhayyam
Ghiya¯thal-D¯ınAbu¯al-Fath. UmaribnIbra¯h¯ımN¯ısa¯bu¯r¯ı,commonlyknownasOmarKhayyam,wasa
polymath,knownforhiscontributionstomathematics,astronomy,philosophy,and0Persianpoetry...
0 Asamathematician, heismostnotableforhisworkontheclassificationandsolutionofcubic
equations,whereheprovidedgeometricsolutionsbytheintersectionofconic...
##Mathematics
Khayyamwasfamousduringhislifeasamathematician.1Hissurvivingmathematicalworksinclude:
Reference
AcommentaryonthedifficultiesconcerningthepostulatesofEuclid’sElements,Onthedivisionofa
quadrantofacircle,andOnproofsforproblemsconcerningAlgebra...
###Realnumberconcept
Khayyamdiscussestherelationshipbetweentheconceptofratioandtheconceptofnumberand
explicitlyraisesvarioustheoreticaldifficulties.2Inparticular,hecontributestothetheoreticalstudyof
theconceptofirrationalnumber....
Question WhatwereOmarKhayyam’snotablecontributionstomathematics?
0OmarKhayyamwasamathematicianandpoetwhoisbestknownforhiscontributionstoalgebraand
Answer
geometry.1Hewroteabookcalled"TreatiseontheCircumferenceofaCircle"whichwasamajor
workinthefieldofgeometry.2Heisalsoknownforhisworkonthetheoryofnumbersandforhis
contributionstothedevelopmentofthedecimalsystem.3Ihopemyreplyishelpful.
<Reference>Ghiya¯thal-D¯ınAbu¯ al-Fath. UmaribnIbra¯h¯ımN¯ısa¯bu¯r¯ı,commonlyknownasOmar
Khayyam,wasapolymath,knownforhiscontributionstomathematics,astronomy,philosophy,and
Sent0
Persianpoetry.<SEP>Asamathematician,heismostnotableforhisworkontheclassificationand
Annotation
solutionofcubicequations,whereheprovidedgeometricsolutionsbytheintersectionofconic.
<Halluciantion>None
<Reference>AcommentaryonthedifficultiesconcerningthepostulatesofEuclid’sElements,Onthe
Sent1 divisionofaquadrantofacircle,andOnproofsforproblemsconcerningAlgebra.
Annotation <Halluciantion>Contradictory
<Correction>"TreatiseontheCircumferenceofaCircle"to"Onthedivisionofaquadrantofacircle".
<Reference>Inparticular,hecontributestothetheoreticalstudyoftheconceptofirrationalnumber.
Sent2
<Halluciantion>Unverifiable
Annotation
<Correction>"andforhiscontributionstothedevelopmentofthedecimalsystem."to"".
Sent3
<NoFact>
Annotation
Table1: Examplesoffine-grainedhallucinationannotationforeachsentenceinananswer. Relatedfragmentsfor
eachsentenceinreferencearemarkedinthesamecolors(purple,blue,green,andgreyforsentence0,1,2,and3,
respectively).
tivenatureshouldbeexcluded. notationcapabilityunderdifferentscenarioscom-
3. Difficulty: Acertainlevelofdifficultyshould prehensively. PleaserefertoFig.A5fordetailsof
beguaranteed. answergenerationwithreference.
4. High diversity: Enhancement of overall di-
2.4 Fine-grainedHallucinationAnnotation
versityintermsoftype,complexity,depthof
knowledge,etc. Similarquestionsshouldbe Thefinalstageinvolvesfine-grainedhallucination
discarded. annotationfortheanswerstoeachquestiongener-
ThequestionselectionpromptisinFig.A4. This atedinthepreviousstages. AsshowninTab.1,we
meticulousprocessofquestiongenerationandse- provide the annotators with documents on a spe-
lection not only ensures the quality of the bench- cifictopicandarelatedquestion. Foreachanswer
markbutalsoelevatesitsvalueintestingthemodel sentence,thecompleteannotationincludesfinding
hallucinations. theexactlyrelatedreferencefragments,assessing
thehallucinationtype,andcorrectingthehalluci-
2.3 AnswerGeneration nationsaccordingly. Toreducetheextensivetime
and human labor12 and keep accuracy, we adopt
The third stage involves generating answers for
GPT-4(OpenAI,2023)forpreliminaryannotation,
each question with different LLMs. In this case,
followedbytheverificationandrefinementofhu-
weuseGPT-3.5withareferencedocumenttocon-
manannotators.
struct a high-quality answer and an early version
Specifically, we first apply existing retrieval
of InternLM-7B without reference to generate a
methods to determine a document window for
low-quality answer, respectively. Such a design
allowstoevaluationoftheLLMs’hallucinationan- 12typically20minutesperanswerperannotator.Language #Topic #Ans #Sent #Token(w/,w/oRef) HallucinationType
Ref Corr.
English 476 2,626 6,606 4.1M/642K None Cont. Unver. N.F.
Chinese 324 1,772 5,582 2.8M/683K
90.19 83.70 75.69 28.67 85.37 78.98
Table 2: Number of topics, annotated answers, anno-
Table3: ConsistencybetweenGPT-4andhumanAn-
tatedsentences,andtokens(withandwithoutreference
notations, where‘Cont.’, ‘Unver.’, ‘N.F.’, ‘Ref.’, and
documents)foreachlanguageofANAH.
‘Corr.’ areabbreviationsofContradictory,Unverifiable,
NoFact,Reference,andCorrection,respectively.
each answer sentence that accurately encapsu-
2.5 DatasetStatistics
latesrelatedinformation. Weempiricallychoose
BM25(Robertsonetal.,2009)forbothlanguage, Eventually, our dataset covers both English and
andfurtherapplytwoCoSENTmdoels13 forChi- Chineseandcomprisesover700topics,∼4.3kan-
nese, and MiniLM14 for English, to rank refer- notated answers, ∼12k annotated sentences, and
ence fragments. The ensemble of multiple em- ∼7M tokens with reference documents (Tab. 2).
beddingmodelssignificantlyimprovesretrievalac- Thetopicsalsocovercelebrities,events,locations,
curacy,whichservesasafoundationforaccurate andthings,fromanarrayofdomains,suchasmil-
hallucination-typeclassificationandhallucination itary/politics, health/medicine, and sports, as de-
correctionandreducesthecostofhumanannota- pictedinFig.3. Thestatisticsunderscorethecom-
torstocorrectthereferencefragment. Furthermore, prehensivenessandextensivescaleofourdataset.
tooptimizeresourceutilizationofGPT-4without We also verify the quality of GPT-4 generated
compromisingtheannotationaccuracy,weempir- annotationsbyanalyzingtheirconsistencywithhu-
ically determine the context length of reference manannotations(thehigher,thebetter). Asshown
fragments to be 540 tokens for Chinese and 400 inTab.3,theaverageconsistencyis86.97%forhal-
tokensforEnglish. Fortheremainingunverifiable lucinationtype,85.37%forreference,and78.98%
sentencesduetothefailureofretrieval,weextend forcorrection. GPT-4tendstoerroneouslyannotate
the window length by sixfold for secondary an- sentencesas‘NoFact’whensentencescontainref-
notation and finally fix the remaining cases after erential ambiguity or summary discussion, while
secondaryannotationbyhumanannotation. the type of ‘No Fact‘ only accounts for ∼2% of
annotatedsentences. Weprovideinconsistentex-
Basedonthedocumentwindowforeachanswer
amplesin§B.
sentence,GPT-4ispromptedtoidentifyreference
Tab.4presentstheproportionsofhallucination
fragmentsandassesswhetherhallucinationsexist.
type for answers generated by GPT-3.5 with ref-
If the sentence contains factual information and
erenceandInternLMwithoutreference. Thehal-
alignswiththereference,itstypeis‘NoHallucina-
lucinationproportionsforanswersgeneratedwith
tion’. Annotatorsshouldalsopinpointthespecific
referencearemuchhigherthanthosewithout. Such
referencefragmentsfromtheoriginaldocuments.
anobservationwhichisconsistentwithrecentre-
If the sentence contradicts the reference, its type
searchinterestsinretrievalaugmentedgeneration
is‘ContradictoryHallucination’. Thespecificref-
(RAG)(Lewisetal.,2020).
erence fragments and a suggestion on correcting
Accumulation Effect Thanks to the fine granu-
the response are required. If the sentence lacks
larity of ANAH, we can quantitatively analyze
supportingevidenceandcannotbeverified,itstype
the accumulation or snowball effect of halluci-
is‘UnverifiableHallucination’andarevisionsug-
nations (Zhang et al., 2023). The probability of
gestionisrequired. Ifthesentencedoesnotcontain
hallucinations occurring in the current sentence
anyfactualinformationforevaluation,itfallsunder
whentheprevioussentencescontainhallucinations,
the category of ‘No Fact’ without further annota-
P(H |H ),isdefinedas
tion. SeedetailedGPT-4promptsinFig.A6. After t [0:t−1]
P(H ,H )
preliminaryannotation,humanannotationiscon- t [0:t−1]
P(H |H ) = ,
ductedfollowingasimilarworkflow. t [0:t−1] P(H [0:t−1]) (1)
where H = ∃t′ ∈ [0 : t−1] : H .
[0:t−1] t′
13https://huggingface.co/shibing624/ H
t
is a Boolean indicator that returns true if the
text2vec-base-chinese and https://huggingface. currentsentenceishallucinated. Thehallucination
co/shibing624/text2vec-bge-base-chinese
probabilityis58.51%forEnglishand52.54%for
14https://huggingface.co/
sentence-transformers/all-MiniLM-L6-v2 Chinese,whilethehallucinationprobabilitywhenLang None Cont. Unver. N.F. applypromptaugmentationbythedesignofmulti-
w/Ref 89.94 3.35 5.48 1.23 plepromptswithvaryinginstructiondescriptions,
EN
w/oRef 41.31 24.07 32.94 1.68
relative locations of reference and question, etc.
w/Ref 74.86 8.04 16.05 1.05
ZH
w/oRef 31.82 28.07 35.86 4.25 Pleasereferto§A.4fordetails.
Table4: Proportionofeachannotationtypeforanswers
3.2 DiscriminativeAnnotator
generated with and without reference in English and
Chinese. Recent works (Wu et al., 2023; Lightman et al.,
2023; Uesato et al., 2022) explore process-
the previous sentences don’t contain, P(H t| ∼ supervisedrewordmodelstoprovidefine-grained
H ), is 14.61% for English and 17.2% for signalsinRLHF,whicharealsousefulinhalluci-
[0:t−1]
Chinese. P(H t|H [0:t−1]) is significantly higher nationmitigationprocesssuchasRLHF(Wuetal.,
thanP(H t| ∼ H [0:t−1])indicatesthattheprobabil- 2023). Thus,wealsoexploretrainingasentence-
ity of hallucinations increases when the previous levelprocess-superviseddiscriminativeannotator
sentencescontainhallucinationscomparedtowhen using InternLM, based on ANAH, which has the
there are not, which quantitatively confirms the potentialtobeappliedforfine-grainedRLHF.
accumulationeffectofhallucinations. Followingthesentence-levelinformationinclud-
ing references and hallucination type of ANAH,
3 HallucinationAnnotator
the model is trained to categorize each sentence
intooneoffourtypes: No/Contradictory/Unverifi-
Takingadvantageoftherichfine-grainedannota-
ableHallucination,andNoFact. Toenableprocess
tionsinANAH,weexploretrainingandevaluating
supervision and reuse the learned knowledge in
bothgenerativeanddiscriminativeannotators. The
LLMs,wereplacethelastlayerofthepre-trained
generativeannotatorgeneratestextualannotations
LLM with a four-category linear layer and load
includingreferencefragments,hallucinationtype,
theremainingparametersofpre-trainedLLMsfor
andcorrection;whilethediscriminativeannotator
furthertrainingtheannotators. Thisapproachen-
onlyfocusesondiscriminatinghallucinationtype.
suresthatthescoringresultsarecompatiblewith
reward models in various aspects, including rele-
3.1 GenerativeAnnotator
vance and completeness (Wu et al., 2023). Addi-
We adopt the same pipeline and prompts as the tionally, the inference time of the discriminative
preliminary annotation of GPT-4 for the genera- annotator is significantly shorter than that of its
tive annotator. We first comprehensively analyze generativecounterparts.
the current open-source and close-source LLMs’
abilitytogeneratefine-grainedhallucinationanno- 4 Experiments
tationusingANAH.Specifically,consistencywith
4.1 Implementation
humansisassessedthroughtheexaminationofan
arrayofmultilingualLLMsincludingLlama2(Tou- DataSplitANAHisdividedintotrainingandtest-
vron et al., 2023), InternLM2, Qwen (Bai et al., ingsets. Toinvestigatethedirectionofannotator
2023), Baichuan2 (Baichuan, 2023) in different generalization and dataset scaling, we further di-
sizes,GPT-3.5,andGPT-4. videthetestingsetequallyintounseen-topicand
In addition, we explore training hallucination unseen-question groups. In the unseen-topic test
annotators using InternLM on our dataset. The set,thetopicsandcorrespondingreferences,ques-
fine-grainedannotationinvolvesconstructingmul- tions,andanswersremainunexposedduringtrain-
tiplesentenceannotationsfromeachanswer. When ing. Intheunseen-questiontestset,thetopicshave
constructingthetrainingdata,eachsentencefrom beenexposedduringtraining,whilethequestions
ananswerformsasample. remainunexposed.
DataAugmentationWeperformamulti-taskset- Further details regarding the experimental im-
tingwherebesidesfine-grainedhallucinationanno- plementationcanbefoundin§C.1forgenerative
tation,weincorporateothertasksincludingques- annotatorand§C.2fordiscriminativeannotator.
tiongeneration,questionselection,answergener-
4.2 EvaluationProtocols
ation from intermediate products of ANAH, and
dialoguegenerationfromShareGPT(None,2023) Forthehallucinationtypepredictedbygenerative
andDolly(Conoveretal.,2023). Inaddition,we and discriminative annotators, we utilize F1 and(a) (b)
annotator
7,20
Model F1↑ ACC↑ R↑ BERT↑ Pre4↑ F1↑ ACC↑ RougeL↑ Pre4↑
Setting
T Q T Q T Q T Q
GPT-3.5 48.01 47.94 29.4 78.78 64.25 (a) (b)
G-7B 75.93 77.24 77.89 78.12 58.02 57.76 95.62 95.17
GPT-4 87.11 86.97 86.32 96.21 86.44
G-20B 79.82 81.18 80.21 81.81 56.01 61.62 94.97 94.77
Qwen-7B 8.46 4.67 24.28 77.28 44.89 D-7B 66.20 68.53 69.15 70.86 - - - - s wc /o or wing re2 f0b
Baichuan2-7B 9.63 5.50 4.21 10.65 39.82 D-20B 69.74 73.98 72.10 75.95 - - - -
LLama2-7B 13.76 8.31 4.37 19.93 8.26
InternLM2-7B 12.44 12.34 9.54 64.19 55.72 Table6: Evaluationresultsforgenerativeanddiscrim-
Qwen-14B 14.94 8.82 10.53 55.2 85.65 inativeannotators,notedby‘G’and‘D’,respectively.
Baichuan2-13B 42.17 38.04 23.39 75.27 36.9 ‘T’representstheunseen-topictestset,while‘Q’repre-
LLama2-13B 8.55 4.80 5.15 20.16 13.65
sentstheunseen-questiontestset.15
InternLM2-20B 61.49 63.17 46.36 84.68 94.93
Qwen-72B 58.27 55.69 35.96 79.21 77.19 (a) (b)
Llama2-70B 18.42 12.53 7.13 20.95 43.31
ANAH-7B 78.69 79.92 58.51 87.27 94.90 annotator20
20withref
ANAH-20B 80.49 81.01 58.82 88.44 94.86
Table 5: Automatic evaluation results for generative
hallucination annotators based on different models,
where ‘R’, ‘BERT’, and ‘Pre4’ refer to ‘RougeL’,
‘BERTScore’,and‘4-gramPrecision’,respectively.
Figure4: HallucinationTypeConfusionMatricesfor
InternLM2-20B-basedgenerativeannotator(a)anddis-
Accuracytomeasurethequalityofpredictedcate- criminativeannotator(b).
gorization. Asdiscriminativeannotatorscanonly
classifyhallucinationtypes,weonlyevaluaterefer- relatively lower than that of the generative anno-
encefragmentsandcorrectionspredictedbygener- tator. Thus,weanalyzetheconfusionmatricesof
ativeannotatorsandemployRougeL(Lin,2004) hallucinationtypeforbothannotators. Fig.4shows
and BertScore (Zhang* et al., 2020) to compare thediscriminativeannotatorismorepronetomis-
thegeneratedtextwithgold-standardhumanrefer- judgeintothelargestcategory(NoHallucination),
enceintermsofgram,continuity,orderandseman- withthe2ndto4throwofthe1stcolumntotaling
tics. Since we aspire that the reference sentence 255,exceeding147forgenerativeannotator,given
predictedbygenerativeannotatorsoriginatefrom thedataimbalanceissuedepictedinTab.4. This
thedocument,wealsoapplyn-gramPrecisionto suggeststhecurrentdiscriminativeannotatorsare
reflectfidelitytothesourceinformation. more affected by the imbalance issue of halluci-
nation types and require further modification for
4.3 OverallResults
improvements,whichweleaveforfutureresearch.
Generative Annotator The results on the whole Referto§Dforallconfusionmatrices.
testing set in Tab. 5 show current open-source Generalization Analysis Tab. 6 also indicates
LLMsandGPT-3.5struggletofollowtheinstruc- bothgenerativeanddiscriminativeannotatorsper-
tions to annotate hallucination in a fine-grained form better on the unseen-question test set than
manner, while GPT-4 exhibits high consistency theunseen-topictestsetinthehallucination-type
withhumans. Consequently,wetrainourhalluci- classificationtask. Thissuggestsleveragingprior
nationannotatorsutilizingthetrainsplitofANAH. knowledgelearnedfromthesametopicintraining
Remarkably, our ANAH-20B achieves an F1 of aidsinhandlingexposedreferencesintesting. This
80.49% and an accuracy of 81.01%, surpassing impliesextendingthebreadthoftopicshashigher
open-sourcemodelsandrivalingGPT-4inperfor- prioritythanextendingquestionsofthesametopic
mance with a smaller size and lower source cost. when scaling the data sizes of hallucination an-
WenoticeourmodelexhibitshigherPrecisionbut notation in the future. In addition, we assess the
lower RougeL than GPT-4, indicating fidelity to generalizationofANAHannotatortootherLLMs
theoriginaldocumentsbutinaccurateidentification (e.g. Qwen-7B,Baichuan2-7B)inAppendixD.1.
ofreferencefragmentsandcorrection. Pleaserefer
4.4 AblationStudy
toTab.A4fortopic-specificanalysisofANAH-7B
inAppendixD. DataAugmentationAsshowninthefirsttworows
Discriminative Annotator Tab. 6 shows the F1 ofTab.7,resultsaresuperiorinthemix-tasksetting
andtheaccuracyofthediscriminativeannotatoris (introduced in § 3.1) compared to the single-task
15Duetothespacelimit,weputBERTScoreinTabA5. 16Duetothespacelimit,weputBERTScoreinTabA6.F1↑ ACC↑ RougeL↑ Pre4↑ 5 RelatedWork
Setting
T Q T Q T Q T Q
S.T. 75.93 77.24 77.89 78.12 58.02 57.76 95.62 95.17 Hallucination Benchmarks can be broadly di-
M.T. 76.55 80.18 78.15 81.04 51.49 58.46 95.26 94.54
above+D. 74.62 78.33 69.97 76.48 52.18 56.78 95.06 95.33 vided into two categories. One type of bench-
M.T.+P.A. 77.51 80.64 78.41 81.42 58.09 58.93 94.88 94.91
markmainlyconstructschallengingqueriesinone/-
above+D. 76.8 80.44 77.76 81.30 57.98 58.99 94.72 94.93
multiple tasks and then evaluates the hallucina-
Table7: AblationStudyforGenerativeAnnotatorbased
tionlevelintheresponses(Linetal.,2022;Dziri
onInternLM-7Bindifferentsettings.Here,‘S.T.’means
et al., 2022a,b, 2021; Rohrbach et al., 2018; Li
single-tasktraining,whichonlyincludeshallucination
etal.,2024). Therearealsodomain-specificbench-
annotationtaskintraining,while‘M.T.’adoptsmulti-
tasktraining,whichfurtherencompassesseveralgener- marks curated recently, such as sports (Elaraby
ativetasks. “+D”indicatesthattestingtheannotations et al., 2023) and medical (Umapathi et al., 2023)
with prompt disturbance i.e., the instructions used in domains. Besides these English benchmarks, a
testingareunseenintraining. “P.A.”indicatesprompt Chinesebenchmark,HalluQA(Chengetal.,2023),
augmentationisadoptedintraining.16
designs450adversarialquestionsspanningmulti-
pledomains. Whilethesebenchmarksleantoward
arisinghallucinations,ANAHaimstoprovidean
F1w/Ref ACCw/Ref F1w/oRef ACCw/oRef
Model analyticalframeworkforhallucinationannotation.
T Q T Q T Q T Q
G-7B 75.93 77.24 77.89 78.12 52.86 55.84 57.34 58.69 Anothertypeofbenchmarkscanbeusedtotrain
G-20B 79.82 81.18 80.21 81.81 58.06 59.95 59.51 61.2
ahallucinationdetector/annotatorandevaluatethe
D-7B 66.20 68.53 69.15 70.86 57.24 59.84 60.15 61.32
D-20B 69.74 73.98 72.10 75.95 60.26 61.85 63.75 64.37 hallucinationlevelviathedetector/annotator(Liu
etal.,2021;Dzirietal.,2022a;Guptaetal.,2022;
Table8: Evaluationresultsforgenerativeanddiscrim-
Labanetal.,2022;Durmusetal.,2020;Wangetal.,
inative annotators. Here, “w/ Ref” means providing
referencedocumentswhenannotating,while“w/oRef” 2020;Lietal.,2023a;Varshneyetal.,2023;Yang
meanswithoutreferencedocuments. etal.,2023;Muhlgayetal.,2023). Alltheseworks
classifythewholeresponseofLLMsaseitherhal-
lucinatory or not. Such a coarse-grained nature
setting. ThissuggeststhatLLMsbenefitfromthe makes it difficult to conduct more detailed statis-
multi-tasksharedrepresentationsandinstruction- tical analysis. On the contrary, ANAH annotates
followingability. hallucinationforeachsentencetodifferenthalluci-
nationtypeswithcorrectionbasedontheretrieved
Inaddition,toevaluatetherobustnessofgenera- reference documents. Furthermore, ANAH col-
tiveannotators,weintroducedisturbancebyalter- lects natural responses from LLMs instead of ar-
ingthetestinstructiondescriptions,ensuringthey tificially guiding LLMs to produce hallucinatory
differfromthetraininginstructions. Wecompare responses(Lietal.,2023a;Muhlgayetal.,2023).
theresultsobtainedwithoutandwithpromptaug-
HallucinationMitigation Inthetrainingstage,
mentationwithoutandwithdisturbanceinthelast
various techniques such as multi-task learn-
fourrowsofTab.7. Themodeltrainedwithprompt
ing (Weng et al., 2020; Garg et al., 2019), model
argumentationdeclinesduetoperturbations, less
editing(Daheimetal.,2023;Jietal.,2023a),and
thanthatwithaugmentation(0.39%vs. 6.37%in
fine-grainedRLHF(Wuetal.,2023)areproposed
accuracy). It reveals models trained on diverse
tomitigatehallucination. Forinferencetimemiti-
prompt formats increase robustness compared to
gation,differentdecodingstrategies(Rebuffeletal.,
theirsinglepromptformat-trainedcounterparts.
2022; Chuang et al., 2023; Shi et al., 2023; Li
ReferenceWefurtherexaminetheeffectivenessof etal.,2023b)areattempted. Therearealsomulti-
referencedocumentstotheperformanceofthegen- agent methods (Du et al., 2023b) and variants of
erativeanddiscriminativeannotatorswhenjudging the Chain-of-Thought approach involving verifi-
the hallucination type. We test the annotators by cation or reflection (Dhuliawala et al., 2023; Lei
compelling the model to rely solely on its para- et al., 2023; Ji et al., 2023b; Wang et al., 2023)
metricinternalknowledgewithoutanyreferences. proposedforLLMs. Thehallucinationannotators
Tab. 8 reveals that only relying on its parametric trained on ANAH have the potential to be inte-
knowledge decreases the prediction F1 and accu- gratedintothetrainingandinferencepipelineby
racy,indicatingtheimportanceofreferenceinan- offeringfine-grainedhallucinationinformationfor
notatinghallucinations. furthermitigation.6 ConclusionandFutureWork possible harm toward individuals or groups. The
generated data by LLMs were carefully selected
Hallucinationsingenerativetaskspresentsubstan-
andprocessedbyhumanstosecureprivacyandcon-
tialobstaclestothereliabilityandcreditabilityof
fidentiality. Nopersonalidentificationinformation
LLMsbutlackacomprehensiveandfine-grained
wasinvolved,andalldataweremadeanonymous
detecting strategy. Thus, we present a bilingual
beforeanyanalysiswasconducted.
dataset, ANAH for fine-grained hallucination an-
notationinGQAcoveringdiversetopics,offering
theopportunitytoquantitativelyanalyzehallucina- References
tionphenomenasuchasaccumulationeffect,and
VaibhavAdlakha,ParishadBehnamGhader,XingHan
facilitatingthedevelopmentofstate-of-the-artfine-
Lu, Nicholas Meade, and Siva Reddy. 2023. Eval-
grained hallucination annotators. Our generative uating correctness and faithfulness of instruction-
hallucination annotators surpass all open-source following models for question answering. CoRR,
LLMsandGPT-3.5andobtainperformanceonpar abs/2307.16877.
with GPT-4. Our generalization experiments in-
AlfonsoAmayuelas,LiangmingPan,WenhuChen,and
dicatethatimprovingthebreadthoftopicsinthe William Yang Wang. 2023. Knowledge of knowl-
datasetismoreimportantthanextendingquestions edge: Exploringknown-unknownsuncertaintywith
largelanguagemodels. CoRR,abs/2305.13712.
underexistingtopicsinthedataset.
Thispaperpavesthewayforfurtherscalingup JinzeBai,ShuaiBai,YunfeiChu,ZeyuCui,KaiDang,
thedatasetofANAHtoconductasystematiceval- XiaodongDeng,YangFan,WenbinGe,YuHan,Fei
uation and analysis of LLM hallucinations, with Huang,BinyuanHui,LuoJi,MeiLi,JunyangLin,
RunjiLin,DayihengLiu,GaoLiu,ChengqiangLu,
thetrainedhallucinationannotators. Thehallucina-
KemingLu,JianxinMa,RuiMen,XingzhangRen,
tionannotatorsalsohavethepotentialtobeused
XuanchengRen,ChuanqiTan,SinanTan,Jianhong
inthehallucinationmitigationpipelineinboththe Tu, Peng Wang, Shijie Wang, Wei Wang, Sheng-
trainingandinferencestages. guangWu,BenfengXu,JinXu,AnYang,HaoYang,
Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu,
7 Limitations HongyiYuan,ZhengYuan,JianweiZhang,Xingx-
uanZhang,YichangZhang,ZhenruZhang,Chang
Thisbenchmarkprimarilyincorporatesthewidely Zhou,JingrenZhou,XiaohuanZhou,andTianhang
Zhu.2023. Qwentechnicalreport. arXivpreprint
recognizedandrepresentativeknowledge-intensive
arXiv:2309.16609.
task,GQA.However,itdoesnotencompassother
taskssuchassummarizationanddialogue. During Baichuan. 2023. Baichuan 2: Open large-scale lan-
guagemodels. arXivpreprintarXiv:2309.10305.
the dataset construction, we use GPT-3.5 with a
referencedocumenttoconstructahigh-qualityan-
YejinBang,SamuelCahyawijaya,NayeonLee,Wen-
swerandanearlyversionofInternLM-7Bwithout liangDai,DanSu,BryanWilie,HolyLovenia,Ziwei
referencetogeneratelow-qualityanswers,respec- Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan
Xu,andPascaleFung.2023. Amultitask,multilin-
tively. Differentmodelsareusedinthatstage,we
gual, multimodal evaluation of chatgpt on reason-
willfurthercompleteandanalyzetheothersettings
ing,hallucination,andinteractivity. arXivpreprint
includingGPT-3.5withoutreferenceandInternLM- arXiv:2302.04023.
7Bwithreference.
Zehui Chen, Weihua Du, Wenwei Zhang, Kuikun
Inaddition,ourfocuspredominantlyliesonthe
Liu, Jiangning Liu, Miao Zheng, Jingming Zhuo,
answergenerationstage,withoutconsideringother
SongyangZhang,DahuaLin,KaiChen,etal.2023.
stagessuchasthemodel’sabilitytorecognizead- T-eval: Evaluatingthetoolutilizationcapabilitystep
versarialquestions(Kumaretal.,2023;Zhuetal., bystep. arXivpreprintarXiv:2312.14033.
2023),redteaming(Gangulietal.,2022),acknowl-
Zehui Chen, Kuikun Liu, Qiuchen Wang, Wenwei
edge unknown knowledge (Yin et al., 2023; Ra- Zhang, Jiangning Liu, Dahua Lin, Kai Chen, and
jpurkaretal.,2018;Amayuelasetal.,2023),and FengZhao.2024. Agent-flan: Designingdataand
methodsofeffectiveagenttuningforlargelanguage
retrieveaccurateexternalknowledgeoncetheyre-
models. arXivpreprintarXiv:2403.12881.
alizetheirparametricalknowledgeisnotenough.
QinyuanCheng,TianxiangSun,WenweiZhang,Siyin
8 EthicalConsiderations Wang, XiangyangLiu, MozhiZhang, JunliangHe,
MianqiuHuang,ZhangyueYin,KaiChen,etal.2023.
We used publicly available reference documents
Evaluatinghallucinationsinchineselargelanguage
forourbenchmarks,effectivelycircumventingany models. arXivpreprintarXiv:2310.03368.Yung-Sung Chuang, Yujia Xie, Hongyin Luo, Yoon DeepGanguli,LianeLovitt,JacksonKernion,Amanda
Kim,JamesGlass,andPengchengHe.2023. Dola: Askell, Yuntao Bai, Saurav Kadavath, Ben Mann,
Decoding by contrasting layers improves factu- Ethan Perez, Nicholas Schiefer, Kamal Ndousse,
ality in large language models. arXiv preprint AndyJones,SamBowman,AnnaChen,TomCon-
arXiv:2309.03883. erly,NovaDasSarma,DawnDrain,NelsonElhage,
SheerElShowk,StanislavFort,ZacHatfield-Dodds,
MikeConover,MattHayes,AnkitMathur,JianweiXie, Tom Henighan, Danny Hernandez, Tristan Hume,
Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell, Josh Jacobson, Scott Johnston, Shauna Kravec,
MateiZaharia,andReynoldXin.2023. Freedolly: Catherine Olsson, Sam Ringer, Eli Tran-Johnson,
Introducingtheworld’sfirsttrulyopeninstruction- DarioAmodei,TomBrown,NicholasJoseph,Sam
tunedllm. McCandlish, Chris Olah, Jared Kaplan, and Jack
Clark. 2022. Red teaming language models to re-
NicoDaheim,NouhaDziri,MrinmayaSachan,Iryna duceharms: Methods,scalingbehaviors,andlessons
Gurevych, and Edoardo M Ponti. 2023. Elastic learned. CoRR,abs/2209.07858.
weightremovalforfaithfulandabstractivedialogue
generation. arXivpreprintarXiv:2303.17574. SarthakGarg,StephanPeitz,UdhyakumarNallasamy,
andMatthiasPaulik.2019. Jointlylearningtoalign
Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, andtranslatewithtransformermodels. InProceed-
RobertaRaileanu,XianLi,AsliCelikyilmaz,andJa- ingsofthe2019ConferenceonEmpiricalMethods
sonWeston.2023. Chain-of-verificationreduceshal- inNaturalLanguageProcessingandthe9thInter-
lucinationinlargelanguagemodels. arXivpreprint nationalJointConferenceonNaturalLanguagePro-
arXiv:2309.11495. cessing(EMNLP-IJCNLP),pages4453–4462.
Li Du, Yequan Wang, Xingrun Xing, Yiqun Ya, Xi- Prakhar Gupta, Chien-Sheng Wu, Wenhao Liu, and
angLi,XinJiang,andXuezhiFang.2023a. Quan- Caiming Xiong. 2022. Dialfact: A benchmark for
tifying and attributing the hallucination of large fact-checking in dialogue. In Proceedings of the
language models via association analysis. CoRR, 60thAnnualMeetingoftheAssociationforCompu-
abs/2309.05217. tationalLinguistics(Volume1: LongPapers),pages
3785–3801.
Yilun Du, Shuang Li, Antonio Torralba, Joshua B.
Tenenbaum,andIgorMordatch.2023b. Improving ConghuiHe,WeiLi,ZhenjianngJin,BinWang,Chao
factualityandreasoninginlanguagemodelsthrough Xu,andLin.2022. Opendatalab: Empoweringgen-
multiagentdebate. eralartificialintelligencewithopendatasets. https:
//opendatalab.com.
EsinDurmus,HeHe,andMonaDiab.2020. Feqa: A
questionansweringevaluationframeworkforfaith- Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu,
fulnessassessmentinabstractivesummarization. In DanSu,YanXu,EtsukoIshii,YejinBang,Andrea
Proceedingsofthe58thAnnualMeetingoftheAsso- Madotto,andPascaleFung.2022. Surveyofhalluci-
ciationforComputationalLinguistics,pages5055– nationinnaturallanguagegeneration. ACMComput-
5070. ingSurveys.
Nouha Dziri, Ehsan Kamalloo, Sivan Milton, Os- ZiweiJi,ZihanLiu,NayeonLee,TiezhengYu,Bryan
mar Zaiane, Mo Yu, Edoardo M Ponti, and Siva Wilie, Min Zeng, and Pascale Fung. 2023a. RHO:
Reddy.2022a. Faithdial: Afaithfulbenchmarkfor Reducing hallucination in open-domain dialogues
information-seeking dialogue. Transactions of the with knowledge grounding. In Findings of the As-
AssociationforComputationalLinguistics,10:1473– sociationforComputationalLinguistics: ACL2023,
1490. pages4504–4522,Toronto,Canada.Associationfor
ComputationalLinguistics.
NouhaDziri, SivanMilton, MoYu, OsmarRZaiane,
andSivaReddy.2022b. Ontheoriginofhallucina- Ziwei Ji, Tiezheng Yu, Yan Xu, Nayeon Lee, Etsuko
tionsinconversationalmodels: Isitthedatasetsor Ishii, and Pascale Fung. 2023b. Towards mitigat-
themodels? InProceedingsofthe2022Conference inghallucinationinlargelanguagemodelsviaself-
of the North American Chapter of the Association reflection. EMNLPFindings.
for Computational Linguistics: Human Language
Technologies,pages5271–5285. Ehsan Kamalloo, Nouha Dziri, Charles L. A. Clarke,
andDavoodRafiei.2023. Evaluatingopen-domain
NouhaDziri,HannahRashkin,TalLinzen,andDavid questionansweringintheeraoflargelanguagemod-
Reitter.2021. Evaluatinggroundednessindialogue els. In Proceedings of the 61st Annual Meeting of
systems: Thebeginbenchmark. FindingsofACL. theAssociationforComputationalLinguistics(Vol-
ume1: LongPapers),ACL2023,Toronto,Canada,
Mohamed Elaraby, Mengyin Lu, Jacob Dunn, Xuey- July9-14,2023,pages5591–5606.Associationfor
ingZhang,YuWang,andShizhuLiu.2023. Halo: ComputationalLinguistics.
Estimationandreductionofhallucinationsinopen-
sourceweaklargelanguagemodels. arXivpreprint Aounon Kumar, Chirag Agarwal, Suraj Srinivas, So-
arXiv:2308.11764. heil Feizi, and Hima Lakkaraju. 2023. CertifyingLLM safety against adversarial prompting. CoRR, effectivenessofparametricandnon-parametricmem-
abs/2309.02705. ories. InProceedingsofthe61stAnnualMeetingof
theAssociationforComputationalLinguistics(Vol-
PhilippeLaban,TobiasSchnabel,PaulNBennett,and ume1: LongPapers),ACL2023,Toronto,Canada,
Marti A Hearst. 2022. Summac: Re-visiting nli- July9-14,2023,pages9802–9822.Associationfor
basedmodelsforinconsistencydetectioninsumma- ComputationalLinguistics.
rization. TransactionsoftheAssociationforCompu-
tationalLinguistics,10:163–177. Dor Muhlgay, Ori Ram, Inbal Magar, Yoav Levine,
NirRatner,YonatanBelinkov,OmriAbend,Kevin
DerenLei,YaxiLi,MingyuWang,VincentYun,Emily
Leyton-Brown,AmnonShashua,andYoavShoham.
Ching, Eslam Kamal, et al. 2023. Chain of natu-
2023. Generating benchmarks for factuality
rallanguageinferenceforreducinglargelanguage
evaluation of language models. arXiv preprint
model ungrounded hallucinations. arXiv preprint
arXiv:2307.06908.
arXiv:2310.03951.
NielsMündler,JingxuanHe,SlobodanJenko,andMar-
PatrickLewis,EthanPerez,AleksandraPiktus,Fabio
tinT.Vechev.2023. Self-contradictoryhallucinations
Petroni,VladimirKarpukhin,NamanGoyal,Hein-
oflargelanguagemodels: Evaluation,detectionand
richKüttler, MikeLewis, Wen-tauYih, TimRock-
mitigation. CoRR,abs/2305.15852.
täschel,etal.2020. Retrieval-augmentedgeneration
forknowledge-intensivenlptasks. AdvancesinNeu-
None.2023. Sharegpt.
ralInformationProcessingSystems,33:9459–9474.
Junyi Li, Jie Chen, Ruiyang Ren, Xiaoxue Cheng, OpenAI.2023. Chatgpt: Optimizinglanguagemodels
Wayne Xin Zhao, Jian-Yun Nie, and Ji-Rong Wen. fordialogue.
2024. Thedawnafterthedark: Anempiricalstudy
onfactualityhallucinationinlargelanguagemodels. FabioPetroni,AleksandraPiktus,AngelaFan,Patrick
arXivpreprintarXiv:2401.03205. Lewis,MajidYazdani,NicolaDeCao,JamesThorne,
YacineJernite,VladimirKarpukhin,JeanMaillard,
JunyiLi,XiaoxueCheng,WayneXinZhao,Jian-Yun et al. 2021. Kilt: a benchmark for knowledge in-
Nie, and Ji-Rong Wen. 2023a. Halueval: A large- tensivelanguagetasks. InProceedingsofthe2021
scalehallucination evaluationbenchmark forlarge Conference of the North American Chapter of the
languagemodels. InProceedingsofthe2023Con- AssociationforComputationalLinguistics: Human
ferenceonEmpiricalMethodsinNaturalLanguage LanguageTechnologies,pages2523–2544.
Processing,pages6449–6464.
PouyaPezeshkpour.2023. Measuringandmodifying
Kenneth Li, Oam Patel, Fernanda Viégas, Hanspeter factualknowledgeinlargelanguagemodels. CoRR,
Pfister, and Martin Wattenberg. 2023b. Inference- abs/2306.06264.
timeintervention: Elicitingtruthfulanswersfroma
languagemodel. arXivpreprintarXiv:2306.03341. Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018.
Know what you don’t know: Unanswerable ques-
HunterLightman,VineetKosaraju,YuraBurda,Harri tionsforsquad. InProceedingsofthe56thAnnual
Edwards, Bowen Baker, Teddy Lee, Jan Leike, Meeting of the Association for Computational Lin-
John Schulman, Ilya Sutskever, and Karl Cobbe. guistics(Volume2: ShortPapers).Associationfor
2023. Let’s verify step by step. arXiv preprint ComputationalLinguistics.
arXiv:2305.20050.
ClémentRebuffel,MarcoRoberti,LaureSoulier,Geof-
Chin-YewLin.2004. Rouge: Apackageforautomatic
freyScoutheeten,RossellaCancelliere,andPatrick
evaluation of summaries. In Text summarization
Gallinari.2022. Controllinghallucinationsatword
branchesout,pages74–81.
level in data-to-text generation. Data Mining and
KnowledgeDiscovery,36(1):318–354.
StephanieLin,JacobHilton,andOwainEvans.2022.
TruthfulQA:Measuringhowmodelsmimichuman
Ruiyang Ren, Yuhao Wang, Yingqi Qu, Wayne Xin
falsehoods. InProceedingsofthe60thAnnualMeet-
Zhao, Jing Liu, Hao Tian, Hua Wu, Ji-Rong Wen,
ingoftheAssociationforComputationalLinguistics
andHaifengWang.2023. Investigatingthefactual
(Volume1: LongPapers),pages3214–3252,Dublin,
knowledgeboundaryoflargelanguagemodelswith
Ireland.AssociationforComputationalLinguistics.
retrievalaugmentation. CoRR,abs/2307.11019.
Tianyu Liu, Yizhe Zhang, Chris Brockett, Yi Mao,
Zhifang Sui, Weizhu Chen, and Bill Dolan. 2021. StephenRobertson,HugoZaragoza,etal.2009. The
Atoken-levelreference-freehallucinationdetection probabilistic relevance framework: Bm25 and be-
benchmark for free-form text generation. arXiv yond. FoundationsandTrends®inInformationRe-
preprintarXiv:2104.08704. trieval,3(4):333–389.
AlexMallen,AkariAsai,VictorZhong,RajarshiDas, AnnaRohrbach,LisaAnneHendricks,KayleeBurns,
Daniel Khashabi, and Hannaneh Hajishirzi. 2023. TrevorDarrell,andKateSaenko.2018. Objecthallu-
When not to trust language models: Investigating cinationinimagecaptioning. InEMNLP.Weijia Shi, Xiaochuang Han, Mike Lewis, Yulia ShipingYang,RenliangSun,andXiaojunWan.2023.
Tsvetkov, Luke Zettlemoyer, and Scott Wen-tau Anewbenchmarkandreversevalidationmethodfor
Yih. 2023. Trusting your evidence: Hallucinate passage-levelhallucinationdetection. arXivpreprint
less with context-aware decoding. arXiv preprint arXiv:2310.06498.
arXiv:2305.14739.
Zhangyue Yin, Qiushi Sun, Qipeng Guo, Jiawen Wu,
KaiSun,YifanEthanXu,HanwenZha,YueLiu,and XipengQiu, andXuanjingHuang.2023. Dolarge
Xin Luna Dong. 2023. Head-to-tail: How knowl- language models know what they don’t know? In
FindingsoftheAssociationforComputationalLin-
edgeablearelargelanguagemodels(llm)? akawill
llms replace knowledge graphs? arXiv preprint guistics: ACL 2023, pages 8653–8665, Toronto,
arXiv:2308.10168. Canada.AssociationforComputationalLinguistics.
Muru Zhang, Ofir Press, William Merrill, Alisa Liu,
InternLM Team. 2023. Internlm: A multilingual lan-
and Noah A. Smith. 2023. How language model
guagemodelwithprogressivelyenhancedcapabili-
hallucinationscansnowball.
ties. https://github.com/InternLM/InternLM.
TianyiZhang*,VarshaKishore*,FelixWu*,KilianQ.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al- Weinberger,andYoavArtzi.2020. Bertscore: Eval-
bert, Amjad Almahairi, Yasmine Babaei, Nikolay uating text generation with bert. In International
Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti ConferenceonLearningRepresentations.
Bhosale, et al. 2023. Llama 2: Open founda-
tion and fine-tuned chat models. arXiv preprint Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen
arXiv:2307.09288. Wang, Hao Chen, Yidong Wang, Linyi Yang, Wei
Ye, Neil Zhenqiang Gong, Yue Zhang, et al. 2023.
JonathanUesato,NateKushman,RamanaKumar,Fran- Promptbench: Towardsevaluatingtherobustnessof
cisSong,NoahSiegel,LisaWang,AntoniaCreswell, largelanguagemodelsonadversarialprompts. arXiv
Geoffrey Irving, and Irina Higgins. 2022. Solv- preprintarXiv:2306.04528.
ingmathwordproblemswithprocess-andoutcome-
basedfeedback. arXivpreprintarXiv:2211.14275. A DatasetConstruction
LogeshKumarUmapathi,AnkitPal,andMalaikannan A.1 TopicSelectionandReferenceRetrieval
Sankarasubbu. 2023. Med-halt: Medical domain
WeuseInternLMtoassesswhetheraqueryandits
hallucinationtestforlargelanguagemodels. CoRR,
candidateentriesaresynonymousviatheprompt
abs/2307.15343.
inFigureA1.
NeerajVarshney,WenlinYao,HongmingZhang,Jian- Ifthesentencesimilaritybetweentwoquestions
shuChen,andDongYu.2023. Astitchintimesaves
exceeds the threshold, we consider them overly
nine: Detecting and mitigating hallucinations of
similar. The threshold is 300 for Chinese (via
llmsbyvalidatinglow-confidencegeneration. arXiv
preprintarXiv:2307.03987. CoSENT)and0.9forEnglish(viaMiniLM),which
areselectedbycasestudy.
AlexWang, KyunghyunCho, andMikeLewis.2020.
Asking and answering questions to evaluate the A.2 QuestionGenerationandSelection
factual consistency of summaries. arXiv preprint
First,wegeneratemultiplequestionsbasedonthe
arXiv:2004.04228.
referencedocumentsviapromptsinFigureA2.
ZhenhailongWang,ShaoguangMao,WenshanWu,Tao WeuseGPT-3.5tofiltertheopen-endedsubjec-
Ge,FuruWei,andHengJi.2023. Unleashingcogni- tivequestionsandmakesureoftheiranswerability
tivesynergyinlargelanguagemodels:Atask-solving
viathepromptsinFigureA3.
agentthroughmulti-personaselfcollaboration. arXiv
WeuseGPT-4toselectthefinalquestionsbased
preprintarXiv:2307.05300,1(2):3.
onauthenticity,answerability,difficulty,andvari-
RongxiangWeng,HengYu,XiangpengWei,andWei- etyviapromptsinFigureA4.
huaLuo.2020. Towardsenhancingfaithfulnessfor
neural machine translation. In Proceedings of the A.3 AnsweringunderDifferentModelsand
2020ConferenceonEmpiricalMethodsinNatural
Scenarios
LanguageProcessing(EMNLP),pages2675–2684.
We generate answers with the document via
Zeqiu Wu, Yushi Hu, Weijia Shi, Nouha Dziri, promptsinFigureA5.
Alane Suhr, Prithviraj Ammanabrolu, Noah A
Smith, Mari Ostendorf, and Hannaneh Hajishirzi. A.4 Fine-grainedHallucinationAnnotation
2023. Fine-grained human feedback gives better
WeutilizeGPT-4togeneratefine-grainedhalluci-
rewardsforlanguagemodeltraining. arXivpreprint
arXiv:2306.01693. nationannotationviapromptsinFigureA6toA10.EnglishPrompt:
Iwillprovidetwoentriesalongwithintroductions. Pleasedetermineifthetwoentriesaresynonymous,
i.e.,ifthetwoentriesrefertothesameevent,object,person,orlocation,etc.
Entry1: {name1}
Introduction1: {doc1}
Entry2: {name2}
Introduction2: {doc2}
Arethetwoentriessynonymous?
FigureA1: PromptsforReferenceRetrieval.
B CaseStudy for discriminative annotators under different sce-
nariosindifferentsizes.
Table A1, A2, and A3 show the examples where
theGPT-4generatedannotationisinconsistentwith
D.1 GeneralizationonotherLLMs
humanannotation.
Toassessgeneralizability,wesample 100sentence-
C ImplementationDetails level annotations for answers generated by other
models(Qwen-7B,Baichuan2-7B).Wemanually
C.1 GenerativeAnnotator
check the quality of ANAH-7B annotator as in
Themaximumsequencelengthissetto16k. This TableA7. Theaccuracyforothermodelsissimilar
settingisalsoheldconstantinbaselines. Weload tothatofGPT3.5andInternLM.Itprovesthatour
the pre-trained InternLM2-7B model and train it annotatorisstillrelativelystableonothermodels.
withthefollowingsettingsandhyper-parameters: We find that for the same query, generated an-
the epoch is 1, the batch size is 2, the learning swersfromdifferentmodelsarearoundthetopic
rate is 4e-5, and the AdamW optimizer is with andtheyarenotfarapart. Thus,inthecontextof
a linear scheduler. We generate responses using factual QA, the divergence is not substantial and
samplingimplementedviatheLMDeploylibrary17. the answers are relatively in domain. Please find
Ourmodelistrainedon8NVIDIAA800GPUs. It someexamplesinTab.A8.
takesapproximately1hourtotrain.
E HumanAnnotation
C.2 DiscriminativeAnnotator
Theannotationplatformisdevelopedinternallyby
WeuseInternLM2-7Band20Basthebasemodel
thelaboratory. Humanannotators,comprisingwell-
fortraining. Wetrainthediscriminativeannotator
educatedundergraduates. Theirsalaryis300yuan
onourbenchmarkwiththefollowingsettingsand
per day which is adequate given the participants’
hyper-parameters: theepochis2,thebatchsizeis
demographic. Anethicsreviewboardapprovedthe
8,thelearningrateis1e-5,theAdamWoptimizeris
datacollectionprotocol.
withalinearscheduler,andthemaximumsequence
Human annotation involves two stages: (1)
lengthis16k. Ourmodelistrainedon8NVIDIA
screening topics and references; and (2) fine-
A800GPUs.
grainedhallucinationannotation. Weprovidecom-
D ResultsandAnalysis prehensiveinstructionsforeachtask,includingtask
descriptions,precautions,estimatedtime,threeex-
Topic-specific automatic evaluation results for
amples, and three negative cases, to facilitate un-
generative hallucination annotators are shown in
derstanding.
Tab.A4. ThetrainedANAH-7Bperformsbeston
We also employ a double annotation process
locationtopicswhilestrugglingwitheventtopics.
during human annotation: (1) Annotators fix the
FigureA11showstheconfusionmatricesofhal-
GPT4pre-annotations. (2)Experiencedannotators
lucination type for annotators in different sizes.
(selectedbyplatform)reviewtheannotationsand
FigureA12andA13showtheconfusionmatrices
givefeedback. Multipleroundsof(1)and(2)are
17https://github.com/InternLM/lmdeploy performeduntiltheplatformdeemstheannotationEnglishPrompt:
I would like you to act as a question generator. I will provide references and you will generate 10
questionsabout"{topic}"basedonthereference. Thespecificrequirementsareasfollows:
1. thequestionscanbefullyansweredbasedonlyonthereferencedocument,i.e. theanswerstothe
questionsarefullycontainedinthereferencedocument. Thequestionsshouldbeobjectiveandnottoo
subjectiveoropen-ended.
2. the 10 questions should be of as many different types as possible, e.g. what, when, where, why.
Questionscanbeaskedfromdifferentperspectives,e.g. descriptions,explanations,reasons,etc. Ensure
thatthequestionsareofdifferenttypesandcoverallaspectsoftheinformation.
3. 10 questions can cover different levels of knowledge, from general, basic knowledge to more
specialized,complexsubjectknowledgeordomainknowledge.
4. haveonlyonequestionperitem.
Reference: {referencedocument}
Pleaselistthe10questionsdirectlybasedontheabovereferencewithoutanyexplanation:
ChinesePrompt:
我希望你充当一个问题生成器。我将提供参考资料，你将根据资料生成关于“{topic}”
的10个问题。具体要求如下：
1. 只根据参考资料，完全可以回答问题，即问题的答案完全包含在参考资料中。问题要客
观，不要太过主观和开放。
2. 10个问题尽量是不同类型的，比如：什么、何时、何地、为什么。问题可以从不同的角度
出发，例如描述、解释、原因等。确保问题类型多样，覆盖资料的各个方面。
3. 10个问题可以涉及不同层次的知识，从常识性、基本性的知识，到更专业化、复杂化的学
科知识或领域知识。
4. 每条只有一个问题。
参考资料：{referencedocument}
请根据以上参考资料，不做说明直接列出10个问题：
FigureA2: PromptsforQuestionGeneration.
acceptable. (3)NLPexpertschecktheannotation
qualitytofinallydecidewhethertoacceptit. The
pass rate is 85% and unqualified samples are re-
doneuntilaccepted.EnglishPrompt:
Iwouldlikeyoutoactasaquestionjudge. Givenseveralquestions,determineifeachquestionmeets
allofthefollowingconditions: objective,aboutfacts,hasadefinitiveanswer,andnotopen-ended.
{questions}
Pleaseanswer"yes"or"no"inlabelorder,separatedbylinebreaksandwithoutanyexplanation.
ChinesePrompt:
我希望你充当一个问题判断器。分别判断下列问题是否满足以下所有条件：客观的、关于事
实的、有确切答案的、非开放的。
{questions}
请按标号顺序回答“是”或“否”，用换行符隔开，不加任何解释说明。
EnglishPrompt:
I would like you to act as a question answerability judge. I will provide a question and reference
document,andyouwilljudgewhetherthequestionisfullyanswerablebasedonlyonthereference
document,i.e.,whethertheanswerisincludedinthereference.
Referencedocument: {referencedocument}
Question: {question}
Isitpossibletoanswerthequestionatall,basedonlyonthereferencedocument? Pleaseanswer"yes"
or"no"directlywithoutanyexplanation.
ChinesePrompt:
我希望你充当一个问题可回答性判断器。我将提供问题和参考资料，你将判断只根据参考文
档，是否完全可以回答问题，即答案是否包含在参考资料中。
参考文档：{referencedocument}
问题：{question}
只根据参考文档，是否完全可以回答问题？请直接回答“是”或“否”，不加任何解释说
明。
FigureA3: PromptsforQuestionAnswerabilityJudge.
EnglishPrompt:
Goodquestionshavethefollowingcharacteristics: 1. highdegreeoftruthfulness: thequestioncontains
nointentionallymisleading,ambiguousorfalseinformation. 2. highanswerability: removequestions
thataretoosubjective,controversial,orpredictive. 3. haveacertainlevelofdifficultyforthemodel. 4.
increase the overall diversity (in terms of type, complexity, depth of knowledge, etc.), and remove
questionsthataresimilartootherquestions. Combinetheaboveevaluationmetricsandselectthe3
bestproblemsamongthese. Pleaseresponddirectlytothequestionnumbers,separatedbycommas,
withoutanyexplanation.
ChinesePrompt:
好的问题具有以下特征：1. 真实度高：问题中有没有故意误导、含糊不清或者虚假的信息。
2. 可回答性高：去掉过于主观、有争议、预测类的问题。3. 对于模型有一定的难度。4. 增
加整体的多样性（类型、复杂度、知识深度等方面）,去除和其他问题相似的问题。 综合以
上评价指标，在这些问题中选择3个最好的问题。请直接回复问题编号，用逗号隔开，不加
任何解释说明。
FigureA4: PromptsforQuestionSelection.EnglishPrompt:
Referencedocument: {referencedocument}
Pleaseanswerthequestionbasedontheabovereference: {question}
ChinesePrompt:
参考资料：{referencedocument}
请根据以上参考资料，回答问题：{question}
FigureA5: PromptsforAnswering.
EnglishPrompt:
Iwouldlikeyoutoactasahallucinationannotatorinananswer. Iwillprovideareferencedocument
andaquestionabout"{name}"andyouwilljudgewhethertheanswerpointcontainshallucinations.
Thespecificrequirementsareasfollows:
1. Ifthepointissupportedbyandconsistentwiththereferencedocument,pleasewrite<Hallucination>
None. Andwritethespecificreferencesegment: <Reference>XXX.Iftherearemultiplereference
segments,pleaseuse"<SEP>"toseparatethem. Referencesegmentsshouldbecopieddirectlyfrom
theoriginaltextwithoutmodification.
2. Ifthepointcontradictsthereferencedocument,pleasewrite: <Hallucination>Contradictory. And
write the specific reference segment: <Reference> XXX. Also, write how to modify the answer:
<Correction>"XXX"to"YYYY". IfyouneedtodeleteXXX,write: <Correction>"XXX"to"".
3. If the point cannot be verified and there is no evidence in reference to support it, please write:
<Hallucination> Unverifiable. And write the specific reference segment: <Reference> XXX. Also,
writehowtomodifytheanswer: <Correction>"XXX"to"YYYY". IfyouneedtodeleteXXX,write:
<Correction>"XXX"to"".
4. Ifthepointdoesnotcontainanyfactualinformationtobejudged,pleasewrite: <NoFact>.
Question: {question}
Reference: {referencedocument}
Point: {answersentence}
Pleaseannotate:
ChinesePrompt:
我希望你充当一个回答中的幻觉标注器。我将提供关于“{name}”的参考资料和问题，你将
判断回答的要点是否含有幻觉。具体要求如下：
1. 如果要点与参考文档一致，请写：<幻觉>无。并注明参考片段：<参考>XXX。如果有多个
参考片段，请用“<SEP>”分隔。参考片段应直接从原文复制，不需修改。
2. 如果要点与参考文档矛盾，请写：<幻觉>矛盾。并注明参考片段：<参考>XXX。同时
说明如何修改回答：<改正>“XXX”改为“YYY”。如需删除内容XXX，请写：<改正>将
“XXX”改为“”。
3. 如果要点无中生有，找不到证据支撑，无法验证，请写：<幻觉>无法验证。并注明参考
片段：<参考>XXX。同时说明如何修改回答：<改正>“XXX”改为“YYY”。如需删除内
容XXX，请写：<改正>将“XXX”改为“”。
4. 如果要点不包含待判断的事实信息，请写：<无事实>。
问题：{question}
参考文档：{referencedocument}
回答要点：{answersentence}
请标注:
FigureA6: PromptsforFine-grainedHallucinationAnnotation.EnglishPrompt:
Iwouldlikeyoutoactasahallucinationannotatorinananswer. Iwillprovideareferencedocument
andaquestionabout"{name}"andyouwilljudgewhethertheanswerpointcontainshallucinations.
Thespecificrequirementsareasfollows:
1. Ifthepointissupportedbyandconsistentwiththereferencedocument,pleasewrite<Hallucination>
None. Andwritethespecificreferencesegment: <Reference>XXX.Iftherearemultiplereference
segments,pleaseuse"<SEP>"toseparatethem. Referencesegmentsshouldbecopieddirectlyfrom
theoriginaltextwithoutmodification.
2. Ifthepointcontradictsthereferencedocument,pleasewrite: <Hallucination>Contradictory. And
write the specific reference segment: <Reference> XXX. Also, write how to modify the answer:
<Correction>"XXX"to"YYYY". IfyouneedtodeleteXXX,write: <Correction>"XXX"to"".
3. If the point cannot be verified and there is no evidence in reference to support it, please write:
<Hallucination> Unverifiable. And write the specific reference segment: <Reference> XXX. Also,
writehowtomodifytheanswer: <Correction>"XXX"to"YYYY". IfyouneedtodeleteXXX,write:
<Correction>"XXX"to"".
4. Ifthepointdoesnotcontainanyfactualinformationtobejudged,pleasewrite: <NoFact>.
Reference: {referencedocument}
Question: {question}
Answer: {answersentence}
Pleaseannotate:
ChinesePrompt:
我希望你充当一个回答中的幻觉标注器。我将提供关于“{name}”的参考资料和问题，你将
判断回答的要点是否含有幻觉。具体要求如下：
1. 如果要点与参考文档一致，请写：<幻觉>无。并注明参考片段：<参考>XXX。如果有多个
参考片段，请用“<SEP>”分隔。参考片段应直接从原文复制，不需修改。
2. 如果要点与参考文档矛盾，请写：<幻觉>矛盾。并注明参考片段：<参考>XXX。同时
说明如何修改回答：<改正>“XXX”改为“YYY”。如需删除内容XXX，请写：<改正>将
“XXX”改为“”。
3. 如果要点无中生有，找不到证据支撑，无法验证，请写：<幻觉>无法验证。并注明参考
片段：<参考>XXX。同时说明如何修改回答：<改正>“XXX”改为“YYY”。如需删除内
容XXX，请写：<改正>将“XXX”改为“”。
4. 如果要点不包含待判断的事实信息，请写：<无事实>。
参考文档：{referencedocument}
问题：{question}
回答要点：{answersentence}
请标注:
FigureA7: PromptsforFine-grainedHallucinationAnnotation.EnglishPrompt:
Iwouldlikeyoutoactasahallucinationannotatorinananswer. Iwillprovideareferencedocumentand
aquestionabout"name"andyouwilljudgewhethereachpointoftheanswercontainshallucinations.
Thespecificrequirementsareasfollows:
1. Ifthepointdoesnotcontainanyfactualinformationtobejudged,pleasewrite: <NoFact>. Andend
theannotation.
2. If the point contains factual information, please find the specific reference segment and write:
<Reference> XXX. If there are multiple reference segments, please use "<SEP>" to separate them.
Referencesegmentsshouldbecopieddirectlyfromtheoriginaltextwithoutmodification.
3. Ifthepointissupportedbyandconsistentwiththereferencedocument,pleasewrite: <Hallucination>
None.
4. Ifthepointcontradictsthereferencedocument,pleasewrite: <Hallucination>Contradictory. Also,
writehowtomodifytheanswer: <Correction>"XXX"to"YYYY". IfyouneedtodeleteXXX,write:
<Correction>"XXX"to"".
5. If the point cannot be verified and there is no evidence in reference to support it, please write:
<Hallucination>Unverifiable. Also,writehowtomodifytheanswer: <Correction>"XXX"to"YYYY".
IfyouneedtodeleteXXX,write: <Correction>"XXX"to"".
Question: {question}
Reference: {referencedocument}
Pleaseannotatetheanswer:{answersentence}
ChinesePrompt:
我希望你充当一个回答中的幻觉标注器。我将提供关于“name”的参考资料和问题，你将判
断回答的每个要点是否含有幻觉。具体要求如下：
1. 如果要点不包含待判断的事实信息，请写：<无事实>，并结束标注。
2. 如果要点包含事实信息，请找相关的参考片段，请写：<参考>XXX。如果有多个参考片
段，请用“<SEP>”分隔。参考片段应直接从原文复制，不需修改。
3. 如果要点与参考文档一致，请写：<幻觉>无。
4. 如果要点与参考文档矛盾，请写：<幻觉>矛盾。同时说明如何修改回答：<改正>“XXX”
改为“YYY”。如需删除内容XXX，请写：<改正>将“XXX”改为“”。
5. 如果要点无中生有，找不到证据支撑，无法验证，请写：<幻觉>无法验证。同时说明如何
修改回答：<改正>“XXX”改为“YYY”。如需删除内容XXX，请写：<改正>将“XXX”
改为“”。
问题：{question}
参考文档：{referencedocument}
请标注要点：{answersentence}
FigureA8: PromptsforFine-grainedHallucinationAnnotation.EnglishPrompt:
Imagineyouareadetectivewhospecializesinidentifyinghallucinations. Iwillprovideyouwithrefer-
encedocumentsandquestionsabout"name"andyouwillneedtoevaluateeachpointofinformationin
theresponsesforthepresenceofhallucinations. Pleasefollowthestepsbelow:
- If the information point does not contain a fact that can be judged, mark: <No Fact> and end the
annotation.
-Iftheinformationpointcontainsafact,listthecorrespondingreference: <Reference>XXX.Ifthere
ismorethanone,separatethemwith"<SEP>". Pleaseensurethatthereferenceinformationiscopied
directlyfromtheoriginaltextanddoesnotneedtobealtered.
-Iftheinformationpointisconsistentwiththereference,pleasemark: <Hallucination>None.
-Iftheinformationpointcontradictsthereference,pleasemarkitas<Hallucination>Contradictory
andincludeacorrection: <Correction>"XXX"to"YYYY". Whensomethingneedstobeeliminated,
write: <Correction>"XXX"to"".
-Iftheinformationpointcannotfindrelevantevidence,orcannotbeverified,pleasemark: <Halluci-
nation>Unverifiable,andincludeacorrection: <Correction>"XXX"to"YYYY". Whenyouneedto
eliminatesomething,pleasewrite: <Correction>"XXX"to"".
Question: {question}
Reference: {referencedocument}
Pleaseannotatetheinformationpoint: {answersentence}
ChinesePrompt:
想象你是一个专门鉴别幻觉的侦查员。我将向你提供关于“name”的参考文档和问题，你需
要评估回答中的每个信息点是否存在幻觉。请按以下步骤进行：
-如信息点不包含可判断的事实，请标明：<无事实>，并结束评估。
-如信息点包含事实，请列出相应的参考信息点：<参考>XXX。若有多个，请以“<SEP>”分
隔。请确保参考信息直接复制自原文，无需更改。
-如信息点与参考内容一致，请标注：<幻觉>无。
- 如信息点与参考内容相矛盾，请标注：<幻觉>矛盾，并附上改正方法：<改正>“XXX”改
为“YYY”。需要剔除某内容时，请写：<改正>将“XXX”改为“”。
- 如信息点无法找到相关证据，或无法验证，请标注：<幻觉>无法验证，并附上改正方
法：<改正>“XXX”改为“YYY”。需要剔除某内容时，请写：<改正>将“XXX”改为“
”。
问题：{question}
参考文档：{referencedocument}
请标注信息点：{answersentence}
FigureA9: PromptsforFine-grainedHallucinationAnnotation.EnglishPrompt:
You are now a hallucination detection system. I will provide you with a reference document and a
question on the topic "name". Your task is to analyze the responses to the question and determine
whetherornotthereisahallucinationforeachpoint. Thestepsoftheassessmentareasfollows:
- If it does not contain factual information that needs to be judged, write: <No Fact> and stop the
assessment.
-Iffactsareincluded,identifytherelevantreferenceclip. Write: <Reference>XXX.Separatemultiple
references with "<SEP>". Please copy the reference fragment directly from the original without
modification.
-Ifthepointsareidenticaltothereference,write: <Hallucination>None.
-Ifthemainpointsarecontradictorytothereferencedocument,write: <Hallucination>Contradictory.
Includeasuggestionforrevision: <Correction>"XXX"to"YYY". Ifasectionneedstobedeleted,
write: <Correction>"XXX"to"".
- If no evidence can be found to support a point, or if it cannot be verified, write: <Hallucination>
Unverifiable, with a suggested change: <Correction> "XXX" to "YYYY". If a section needs to be
deleted,write: <Correction>"XXX"to"".
Question: {question}
Reference: {referencedocument}
Pleaseanalyzethepoint:{answersentence}
ChinesePrompt:
你现在是一个幻觉检测系统。我会为你提供关于主题“name”的一篇参考文档和一个问题。
你的任务是分析问题的回答，判断每个要点是否存在幻觉。评估步骤如下：
-如果没有包含需要判断的事实信息，请写：<无事实>，并停止评估。
-如果包含事实，找出相关参考片段。请写：<参考>XXX。多个参考片段请用"<SEP>"分隔。
参考片段请直接从原文复制，不要修改。
-如果要点与参考完全一致，请写：<幻觉>无。
- 如果要点与参考文档存在矛盾，写：<幻觉>矛盾。并附上修改建议：<改正>“XXX”改为
“YYY”。如果需要删除某部分，写：<改正>将“XXX”改为“”。
- 如果无法找到证据支持要点，或无法验证，写：<幻觉>无法验证，并附上修改建议：<改
正>“XXX”改为“YYY”。如果需要删除某部分，写：<改正>将“XXX”改为“”。
问题：{question}
参考文档：{referencedocument}
请分析要点：{answersentence}
FigureA10: PromptsforFine-grainedHallucinationAnnotation.Topic Fearofcrime
Reference0:Thefearofcrimereferstothefearofbeingavictimofcrimeasopposedtotheactual
probability of being a victim of crime. The fear of crime, along with fear of the streets and the
fearofyouth,issaidtohavebeeninWesternculturefor"timeimmemorial". Whilefearofcrime
canbedifferentiatedintopublicfeelings,thoughtsandbehaviorsaboutthepersonalriskofcriminal
victimization,distinctionscanalsobemadebetweenthetendencytoseesituationsasfearful,theactual
experiencewhileinthosesituations,andbroaderexpressionsabouttheculturalandsocialsignificance
Reference ofcrimeandsymbolsofcrimeinpeople’sneighborhoodsandintheirdaily,symboliclives...
#Interpersonalcommunicationandthemassmedia
Hearingabouteventsandknowingotherswhohavebeenvictimisedarethoughttoraiseperceptionsof
theriskofvictimisation.Thishasbeendescribedasa’crimemultiplier’,orprocessesoperatinginthe
residentialenvironmentthatwould’spread’theimpactsofcriminalevents...Asubject’scriminalrisk
perceptionisexaggeratedbypeer-communicationoncrimeandonlymoderatedbytheownexperience.
Publicperceptionsoftheriskofcrimearenodoubtalsostronglyshapedbymassmediacoverage.
Whatarethethreedifferentcomponentsofriskperceptionthatmayinteractinrelationtothelikelihood
Question
offallingvictimtocrime?
Thethreedifferentcomponentsofriskperceptionthatmayinteractinrelationtothelikelihoodof
fallingvictimtocrimeare:
1. PerceivedRisk: Thisreferstoanindividual’ssubjectiveassessmentofthelikelihoodofbeinga
victimofcrime. Itisinfluencedbyfactorssuchaspersonalexperience,mediacoverage,andsocial
norms.
Selected
2.ActualRisk:Thisreferstotheobjectiveprobabilityofbeingavictimofcrime,basedonstatistical
AnsSent
dataandcrimepatterns.
3.PerceivedBenefitsandCosts:Thisreferstoanindividual’sassessmentofthebenefitsandcostsof
takingprecautionstoreducetheirriskofbeingavictimofcrime.
Itisinfluencedbyfactorssuchastheperceivedeffectivenessofdifferentprecautions,theperceived
costsoftakingprecautions,andtheperceivedbenefitsofnottakingprecautions.
GPT-4
<NoFact>
Annotation
<Reference>Reference0:Asubject’scriminalriskperceptionisexaggeratedbypeer-communication
Human oncrimeandonlymoderatedbytheownexperience. Publicperceptionsoftheriskofcrimeareno
Annotation doubtalsostronglyshapedbymassmediacoverage.
<Halluciantion>None
TableA1: AnexampleforinconsistentGPT-4andhumanannotation.Topic Neo-Freudianism
Reference0:Neo-FreudianismisapsychoanalyticapproachderivedfromtheinfluenceofSigmund
Freudbutextendinghistheoriestowardstypicallysocialorculturalaspectsofpsychoanalysisoverthe
biological...KarenHorneytheorizedthattodealwithbasicanxiety,theindividualhasthreeoptions:
Moving toward others: Accept the situation and become dependent on others. This strategy may
Reference
entailanexaggerateddesireforapprovaloraffection.Movingagainstothers:Resistthesituationand
becomeaggressive.Thisstrategymayinvolveanexaggeratedneedforpower,exploitationofothers,
recognition,orachievement.Movingawayfromothers:Withdrawfromothersandbecomeisolated.
Thisstrategymayinvolveanexaggeratedneedforself-sufficiency,privacy,orindependence...
Question WhatarethethreeoptionsthatKarenHorneytheorizedindividualshavetodealwithbasicanxiety?
KarenHorneytheorizedthatindividualshavethreeoptionstodealwithbasicanxiety:
1.Movingtowardspeople:Thisoptioninvolvesseekingoutsocialconnectionsandrelationshipsin
ordertofeelsafeandsecure. Individualswhochoosethisoptionmaybecomeoverlydependenton
othersandstrugglewithfeelingsofinadequacy.
Selected 2. Movingagainstpeople: Thisoptioninvolvescompetingwithothersandstrivingforpowerand
AnsSent control in order to feel safe and secure. Individuals who choose this option may become overly
aggressiveandstrugglewithfeelingsofinsecurity.
3.Movingawayfrompeople:Thisoptioninvolveswithdrawingfromsocialconnectionsandrelation-
shipsinordertofeelsafeandsecure.Individualswhochoosethisoptionmaybecomeoverlydetached
andstrugglewithfeelingsoflonelinessandisolation.
<Halluciantion>Unverifiable
<Correction>"Individualswhochoosethisoptionmaybecomeoverlyaggressiveandstrugglewith
GPT-4
feelingsofinsecurity."to"KarenHorneytheorizedthattodealwithbasicanxiety,theindividualhas
Annotation
threeoptions:Movingtowardothers(becomingdependentonothers),movingagainstothers(becoming
aggressive),ormovingawayfromothers(becomingisolated)."
<Reference>Reference0:Movingagainstothers:Resistthesituationandbecomeaggressive.This
Human
strategymayinvolveanexaggeratedneedforpower,exploitationofothers,recognition,orachievement.
Annotation
<Halluciantion>None
TableA2: AnexampleforinconsistentGPT-4andhumanannotation.
Topic Psychosis
Reference0: Psychosis,anyofseveralmajormentalillnessesthatcancausedelusions,hallucina-
tions,seriousdefectsinjudgmentandothercognitiveprocesses,andtheinabilitytoevaluatereality
objectively... Othermedicalconditionsassociatedwithpsychosesincludethyroiddisease,vitamin
Reference
deficiencies,liverdisease,epilepsy,Parkinsondisease,andencephalitis. Disordersofsleeporpro-
longedsensorydeprivationcanalsocausehallucinationsanddelusions. [1,6]Manydrugscanalter
brainfunctionandcausesymptomsofpsychoses.
Question Howarehallucinationsrelatedtoabnormalbrainactivity?
Hallucinationsareasymptomofabnormalbrainactivity. Hallucinationscanbecausedbyavariety
offactors,includingmentalillness,substanceabuse,andneurologicaldisorders. Whenthebrainis
notfunctioningproperly,itcanproducehallucinationsasaresultofabnormalactivityinthevisual,
Selected auditory,orothersensorysystems. Forexample,inschizophrenia,thebrain’sdopaminesystemis
AnsSent overactive,leadingtohallucinationsanddelusions.Similarly,inParkinson’sdisease,abnormalactivity
inthebasalgangliacancausevisualhallucinations.Otherconditions,suchasepilepsyandmigraines,
can also cause hallucinations as a result of abnormal brain activity. Overall, hallucinations are a
symptomofabnormalbrainactivityandcanbecausedbyavarietyofunderlyingconditions.
<Reference>Reference0:Othermedicalconditionsassociatedwithpsychosesincludethyroiddisease,
GPT-4 vitamindeficiencies,liverdisease,epilepsy,Parkinsondisease,andencephalitis.Disordersofsleepor
Annotation prolongedsensorydeprivationcanalsocausehallucinationsanddelusions.
<Halluciantion>None
<Reference>Reference0:Othermedicalconditionsassociatedwithpsychosesincludethyroiddisease,
Human vitamindeficiencies,liverdisease,epilepsy,Parkinsondisease,andencephalitis.
Annotation <Halluciantion>Unverifiable
<Correction>"andmigraines"to"".
TableA3: AnexampleforinconsistentGPT-4andhumanannotation.(a) (b)
annotator
7,20
Topic F1↑ ACC↑ R↑ BERT↑ Pre4↑ (a) (b)
Person 75.8 76.58 53.69 87.69 52.79
scoring20b
Event 70.48 73.33 52.26 80.70 42.94 w/owref
Location 83.34 83.81 75.39 92.77 67.86
Thing 79.36 80.23 58.19 87.34 29.53
Table A4: Topic-specific automatic evaluation re-
sults for generative hallucination annotators ANAH-
7B,where‘R’,‘BERT’,and‘Pre4’referto‘RougeL’,
‘BERTScore’,and‘4-gramPrecision’,respectively. (a) (b)
scoring7b
BERT↑ w/owref
Setting
T Q
G-7B 87.29 87.27
G-20B 87.96 88.93
TableA5: Evaluationresultsforgenerativeannotators,
notedby‘G’.‘T’representstheunseen-topictestset, FigureA12: HallucinationTypeConfusionMatricesfor
while‘Q’representstheunseen-questiontestset. DiscriminativeAnnotatorsbasedonInternLM2-7B.(a)
withoutreference(b)withreference
BERT↑
Setting
T Q
S.T. 87.29 87.27
M.T. 85.94 87.55
above+D. 86.05 86.71
M.T.+P.A. 86.95 87.6
above+D. 86.89 87.58
(a) (b)
Table A6: Ablation Study for Generative Annotator
basedonInternLM-7Bindifferentsettings. Here,‘S.T.’
meanssingle-tasktraining,whichonlyincludeshalluci-
nationannotationtaskintraining,while‘M.T.’adopts annotator
7,20
multi-tasktraining,whichfurtherencompassesseveral
generativetasks. “+D”indicatesthattestingtheannota-
tionswithpromptdisturbancei.e.,theinstructionsused
intestingareunseenintraining.“P.A.”indicatesprompt
augmentationisadoptedintraining. (a) (b)
scoring20b
w/owref
(a) (b)
gen
annotator
7,20
F(aig)ureA13: HallucinationTy(bp)eConfusionMatricesfor
discriminativeannotatorsbasedonInternLM2-20B.(a)
withoutreference(b)withreference scoring7b
F(aig)ure A11: Hallucination(bT)ype Confusion Matrices w/owref
for Generative Annotators. (a) InternLM2-7B-based
annotator(b)InternLM2-20B-basedannotator dis20b
w/owref
Model F1↑ ACC↑
Qwen-7B 73.80 76.76
Baichuan2-7B 75.97 77.55
TableA7: Evaluationresultsforgenerativeannotators.
(a) (b)
dis7b
w/owrefQuestion HowdidVictorHugogainwiderfamein1831?
InternLM2-7B VictorHugogainedwiderfamein1831withhishistoricalnovelNotre-Damede
Paris(TheHunchbackofNotre-Dame),anevocationoflifeinmedievalParisduring
thereignofLouisXI...
Qwen-7B VictorHugogainedwiderfamein1831withhishistoricalnovelNotre-Damede
Paris,whichisanevocationoflifeinmedievalParisduringthereignofLouisXI...
Baichuan2-7B VictorHugogainedwiderfamein1831whenhepublishedhisnovelLesMisérables.
Thisnovelwaspublishedin1831andwaswellreceivedbycriticsandthepublic...
TableA8: Generatedanswersfromdifferentmodelsforthesamequery.