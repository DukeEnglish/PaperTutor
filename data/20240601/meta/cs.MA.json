[
    {
        "title": "Distributed maze exploration using multiple agents and optimal goal assignment",
        "authors": "Manousos LinardakisIraklis VarlamisGeorgios Th. Papadopoulos",
        "links": "http://arxiv.org/abs/2405.20232v1",
        "entry_id": "http://arxiv.org/abs/2405.20232v1",
        "pdf_url": "http://arxiv.org/pdf/2405.20232v1",
        "summary": "Robotic exploration has long captivated researchers aiming to map complex\nenvironments efficiently. Techniques such as potential fields and frontier\nexploration have traditionally been employed in this pursuit, primarily\nfocusing on solitary agents. Recent advancements have shifted towards\noptimizing exploration efficiency through multiagent systems. However, many\nexisting approaches overlook critical real-world factors, such as broadcast\nrange limitations, communication costs, and coverage overlap. This paper\naddresses these gaps by proposing a distributed maze exploration strategy\n(CU-LVP) that assumes constrained broadcast ranges and utilizes Voronoi\ndiagrams for better area partitioning. By adapting traditional multiagent\nmethods to distributed environments with limited broadcast ranges, this study\nevaluates their performance across diverse maze topologies, demonstrating the\nefficacy and practical applicability of the proposed method. The code and\nexperimental results supporting this study are available in the following\nrepository: https://github.com/manouslinard/multiagent-exploration/.",
        "updated": "2024-05-30 16:33:01 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.20232v1"
    },
    {
        "title": "Soft Partitioning of Latent Space for Semantic Channel Equalization",
        "authors": "Tomás HuttebrauckerMohamed SanaEmilio Calvanese Strinati",
        "links": "http://arxiv.org/abs/2405.20085v1",
        "entry_id": "http://arxiv.org/abs/2405.20085v1",
        "pdf_url": "http://arxiv.org/pdf/2405.20085v1",
        "summary": "Semantic channel equalization has emerged as a solution to address language\nmismatch in multi-user semantic communications. This approach aims to align the\nlatent spaces of an encoder and a decoder which were not jointly trained and it\nrelies on a partition of the semantic (latent) space into atoms based on the\nthe semantic meaning. In this work we explore the role of the semantic space\npartition in scenarios where the task structure involves a one-to-many mapping\nbetween the semantic space and the action space. In such scenarios,\npartitioning based on hard inference results results in loss of information\nwhich degrades the equalization performance. We propose a soft criterion to\nderive the atoms of the partition which leverages the soft decoder's output and\noffers a more comprehensive understanding of the semantic space's structure.\nThrough empirical validation, we demonstrate that soft partitioning yields a\nmore descriptive and regular partition of the space, consequently enhancing the\nperformance of the equalization algorithm.",
        "updated": "2024-05-30 14:16:19 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.20085v1"
    },
    {
        "title": "Safe Multi-agent Reinforcement Learning with Natural Language Constraints",
        "authors": "Ziyan WangMeng FangTristan TomilinFei FangYali Du",
        "links": "http://arxiv.org/abs/2405.20018v1",
        "entry_id": "http://arxiv.org/abs/2405.20018v1",
        "pdf_url": "http://arxiv.org/pdf/2405.20018v1",
        "summary": "The role of natural language constraints in Safe Multi-agent Reinforcement\nLearning (MARL) is crucial, yet often overlooked. While Safe MARL has vast\npotential, especially in fields like robotics and autonomous vehicles, its full\npotential is limited by the need to define constraints in pre-designed\nmathematical terms, which requires extensive domain expertise and reinforcement\nlearning knowledge, hindering its broader adoption. To address this limitation\nand make Safe MARL more accessible and adaptable, we propose a novel approach\nnamed Safe Multi-agent Reinforcement Learning with Natural Language constraints\n(SMALL). Our method leverages fine-tuned language models to interpret and\nprocess free-form textual constraints, converting them into semantic embeddings\nthat capture the essence of prohibited states and behaviours. These embeddings\nare then integrated into the multi-agent policy learning process, enabling\nagents to learn policies that minimize constraint violations while optimizing\nrewards. To evaluate the effectiveness of SMALL, we introduce the LaMaSafe, a\nmulti-task benchmark designed to assess the performance of multiple agents in\nadhering to natural language constraints. Empirical evaluations across various\nenvironments demonstrate that SMALL achieves comparable rewards and\nsignificantly fewer constraint violations, highlighting its effectiveness in\nunderstanding and enforcing natural language constraints.",
        "updated": "2024-05-30 12:57:35 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.20018v1"
    },
    {
        "title": "LAGMA: LAtent Goal-guided Multi-Agent Reinforcement Learning",
        "authors": "Hyungho NaIl-chul Moon",
        "links": "http://arxiv.org/abs/2405.19998v1",
        "entry_id": "http://arxiv.org/abs/2405.19998v1",
        "pdf_url": "http://arxiv.org/pdf/2405.19998v1",
        "summary": "In cooperative multi-agent reinforcement learning (MARL), agents collaborate\nto achieve common goals, such as defeating enemies and scoring a goal. However,\nlearning goal-reaching paths toward such a semantic goal takes a considerable\namount of time in complex tasks and the trained model often fails to find such\npaths. To address this, we present LAtent Goal-guided Multi-Agent reinforcement\nlearning (LAGMA), which generates a goal-reaching trajectory in latent space\nand provides a latent goal-guided incentive to transitions toward this\nreference trajectory. LAGMA consists of three major components: (a) quantized\nlatent space constructed via a modified VQ-VAE for efficient sample\nutilization, (b) goal-reaching trajectory generation via extended VQ codebook,\nand (c) latent goal-guided intrinsic reward generation to encourage transitions\ntowards the sampled goal-reaching path. The proposed method is evaluated by\nStarCraft II with both dense and sparse reward settings and Google Research\nFootball. Empirical results show further performance improvement over\nstate-of-the-art baselines.",
        "updated": "2024-05-30 12:34:58 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.19998v1"
    },
    {
        "title": "Dispersion of personal spaces",
        "authors": "Jaroslav HoráčekMiroslav Rada",
        "links": "http://arxiv.org/abs/2405.19895v1",
        "entry_id": "http://arxiv.org/abs/2405.19895v1",
        "pdf_url": "http://arxiv.org/pdf/2405.19895v1",
        "summary": "There are many entities that disseminate in the physical space - information,\ngossip, mood, innovation etc. Personal spaces are also entities that disperse\nand interplay. In this work we study the emergence of configurations formed by\nparticipants when choosing a place to sit in a rectangular auditorium. Based on\nexperimental questionnaire data we design several models and assess their\nrelevancy to a real time-lapse footage of lecture hall being filled up. The\nmain focus is to compare the evolution of entropy of occupied seat\nconfigurations in time. Even though the process of choosing a seat is complex\nand could depend on various properties of participants or environment, some of\nthe developed models can capture at least basic essence of the real processes.\nAfter introducing the problem of seat selection and related results in close\nresearch areas, we introduce preliminary collected data and build models of\nseat selection based on them. We compare the resulting models to the real\nobservational data and discuss areas of future research directions.",
        "updated": "2024-05-30 09:52:27 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.19895v1"
    }
]