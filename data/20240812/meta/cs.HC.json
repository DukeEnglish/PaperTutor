[
    {
        "title": "Evaluating the capability of large language models to personalize science texts for diverse middle-school-age learners",
        "authors": "Michael Vaccaro JrMikayla FridayArash Zaghi",
        "links": "http://arxiv.org/abs/2408.05204v1",
        "entry_id": "http://arxiv.org/abs/2408.05204v1",
        "pdf_url": "http://arxiv.org/pdf/2408.05204v1",
        "summary": "Large language models (LLMs), including OpenAI's GPT-series, have made\nsignificant advancements in recent years. Known for their expertise across\ndiverse subject areas and quick adaptability to user-provided prompts, LLMs\nhold unique potential as Personalized Learning (PL) tools. Despite this\npotential, their application in K-12 education remains largely unexplored. This\npaper presents one of the first randomized controlled trials (n = 23) to\nevaluate the effectiveness of GPT-4 in personalizing educational science texts\nfor middle school students. In this study, GPT-4 was used to profile student\nlearning preferences based on choices made during a training session. For the\nexperimental group, GPT-4 was used to rewrite science texts to align with the\nstudent's predicted profile while, for students in the control group, texts\nwere rewritten to contradict their learning preferences. The results of a\nMann-Whitney U test showed that students significantly preferred (at the .10\nlevel) the rewritten texts when they were aligned with their profile (p =\n.059). These findings suggest that GPT-4 can effectively interpret and tailor\neducational content to diverse learner preferences, marking a significant\nadvancement in PL technology. The limitations of this study and ethical\nconsiderations for using artificial intelligence in education are also\ndiscussed.",
        "updated": "2024-08-09 17:53:35 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.05204v1"
    },
    {
        "title": "Weak-Annotation of HAR Datasets using Vision Foundation Models",
        "authors": "Marius BockKristof Van LaerhovenMichael Moeller",
        "links": "http://arxiv.org/abs/2408.05169v1",
        "entry_id": "http://arxiv.org/abs/2408.05169v1",
        "pdf_url": "http://arxiv.org/pdf/2408.05169v1",
        "summary": "As wearable-based data annotation remains, to date, a tedious, time-consuming\ntask requiring researchers to dedicate substantial time, benchmark datasets\nwithin the field of Human Activity Recognition in lack richness and size\ncompared to datasets available within related fields. Recently, vision\nfoundation models such as CLIP have gained significant attention, helping the\nvision community advance in finding robust, generalizable feature\nrepresentations. With the majority of researchers within the wearable community\nrelying on vision modalities to overcome the limited expressiveness of wearable\ndata and accurately label their to-be-released benchmark datasets offline, we\npropose a novel, clustering-based annotation pipeline to significantly reduce\nthe amount of data that needs to be annotated by a human annotator. We show\nthat using our approach, the annotation of centroid clips suffices to achieve\naverage labelling accuracies close to 90% across three publicly available HAR\nbenchmark datasets. Using the weakly annotated datasets, we further demonstrate\nthat we can match the accuracy scores of fully-supervised deep learning\nclassifiers across all three benchmark datasets. Code as well as supplementary\nfigures and results are publicly downloadable via\ngithub.com/mariusbock/weak_har.",
        "updated": "2024-08-09 16:46:53 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.05169v1"
    },
    {
        "title": "Large Language Models and Thematic Analysis: Human-AI Synergy in Researching Hate Speech on Social Media",
        "authors": "Petre BreazuMiriam SchirmerSongbo HuNapoleon Kastos",
        "links": "http://arxiv.org/abs/2408.05126v1",
        "entry_id": "http://arxiv.org/abs/2408.05126v1",
        "pdf_url": "http://arxiv.org/pdf/2408.05126v1",
        "summary": "In the dynamic field of artificial intelligence (AI), the development and\napplication of Large Language Models (LLMs) for text analysis are of\nsignificant academic interest. Despite the promising capabilities of various\nLLMs in conducting qualitative analysis, their use in the humanities and social\nsciences has not been thoroughly examined. This article contributes to the\nemerging literature on LLMs in qualitative analysis by documenting an\nexperimental study involving GPT-4. The study focuses on performing thematic\nanalysis (TA) using a YouTube dataset derived from an EU-funded project, which\nwas previously analyzed by other researchers. This dataset is about the\nrepresentation of Roma migrants in Sweden during 2016, a period marked by the\naftermath of the 2015 refugee crisis and preceding the Swedish national\nelections in 2017. Our study seeks to understand the potential of combining\nhuman intelligence with AI's scalability and efficiency, examining the\nadvantages and limitations of employing LLMs in qualitative research within the\nhumanities and social sciences. Additionally, we discuss future directions for\napplying LLMs in these fields.",
        "updated": "2024-08-09 15:34:41 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.05126v1"
    },
    {
        "title": "Sportify: Question Answering with Embedded Visualizations and Personified Narratives for Sports Video",
        "authors": "Chunggi LeeTica LinHanspeter PfisterChen Zhu-Tian",
        "links": "http://arxiv.org/abs/2408.05123v1",
        "entry_id": "http://arxiv.org/abs/2408.05123v1",
        "pdf_url": "http://arxiv.org/pdf/2408.05123v1",
        "summary": "As basketball's popularity surges, fans often find themselves confused and\noverwhelmed by the rapid game pace and complexity. Basketball tactics,\ninvolving a complex series of actions, require substantial knowledge to be\nfully understood. This complexity leads to a need for additional information\nand explanation, which can distract fans from the game. To tackle these\nchallenges, we present Sportify, a Visual Question Answering system that\nintegrates narratives and embedded visualization for demystifying basketball\ntactical questions, aiding fans in understanding various game aspects. We\npropose three novel action visualizations (i.e., Pass, Cut, and Screen) to\ndemonstrate critical action sequences. To explain the reasoning and logic\nbehind players' actions, we leverage a large-language model (LLM) to generate\nnarratives. We adopt a storytelling approach for complex scenarios from both\nfirst and third-person perspectives, integrating action visualizations. We\nevaluated Sportify with basketball fans to investigate its impact on\nunderstanding of tactics, and how different personal perspectives of narratives\nimpact the understanding of complex tactic with action visualizations. Our\nevaluation with basketball fans demonstrates Sportify's capability to deepen\ntactical insights and amplify the viewing experience. Furthermore, third-person\nnarration assists people in getting in-depth game explanations while\nfirst-person narration enhances fans' game engagement",
        "updated": "2024-08-09 15:30:10 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.05123v1"
    },
    {
        "title": "Evaluating Layout Dimensionalities in PC+VR Asymmetric Collaborative Decision Making",
        "authors": "Daniel EnriquezWai TongChris NorthHuamin QuYalong Yang",
        "links": "http://arxiv.org/abs/2408.05105v1",
        "entry_id": "http://arxiv.org/abs/2408.05105v1",
        "pdf_url": "http://arxiv.org/pdf/2408.05105v1",
        "summary": "With the commercialization of virtual/augmented reality (VR/AR) devices,\nthere is an increasing interest in combining immersive and non-immersive\ndevices (e.g., desktop computers) for asymmetric collaborations. While such\nasymmetric settings have been examined in social platforms, significant\nquestions around layout dimensionality in data-driven decision-making remain\nunderexplored. A crucial inquiry arises: although presenting a consistent 3D\nvirtual world on both immersive and non-immersive platforms has been a common\npractice in social applications, does the same guideline apply to lay out data?\nOr should data placement be optimized locally according to each device's\ndisplay capacity? This study aims to provide empirical insights into the user\nexperience of asymmetric collaboration in data-driven decision-making. We\ntested practical dimensionality combinations between PC and VR, resulting in\nthree conditions: PC2D+VR2D, PC2D+VR3D, and PC3D+VR3D. The results revealed a\npreference for PC2D+VR3D, and PC2D+VR2D led to the quickest task completion.\nOur investigation facilitates an in-depth discussion of the trade-offs\nassociated with different layout dimensionalities in asymmetric collaborations.",
        "updated": "2024-08-09 14:55:59 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.05105v1"
    }
]