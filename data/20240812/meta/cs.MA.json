[
    {
        "title": "Performative Prediction on Games and Mechanism Design",
        "authors": "António GóisMehrnaz MofakhamiFernando P. SantosSimon Lacoste-JulienGauthier Gidel",
        "links": "http://arxiv.org/abs/2408.05146v1",
        "entry_id": "http://arxiv.org/abs/2408.05146v1",
        "pdf_url": "http://arxiv.org/pdf/2408.05146v1",
        "summary": "Predictions often influence the reality which they aim to predict, an effect\nknown as performativity. Existing work focuses on accuracy maximization under\nthis effect, but model deployment may have important unintended impacts,\nespecially in multiagent scenarios. In this work, we investigate performative\nprediction in a concrete game-theoretic setting where social welfare is an\nalternative objective to accuracy maximization. We explore a collective risk\ndilemma scenario where maximising accuracy can negatively impact social\nwelfare, when predicting collective behaviours. By assuming knowledge of a\nBayesian agent behavior model, we then show how to achieve better trade-offs\nand use them for mechanism design.",
        "updated": "2024-08-09 16:03:44 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.05146v1"
    },
    {
        "title": "Performance Prediction of Hub-Based Swarms",
        "authors": "Puneet JainChaitanya DwivediVigynesh BhattNick SmithMichael A Goodrich",
        "links": "http://arxiv.org/abs/2408.04822v1",
        "entry_id": "http://arxiv.org/abs/2408.04822v1",
        "pdf_url": "http://arxiv.org/pdf/2408.04822v1",
        "summary": "A hub-based colony consists of multiple agents who share a common nest site\ncalled the hub. Agents perform tasks away from the hub like foraging for food\nor gathering information about future nest sites. Modeling hub-based colonies\nis challenging because the size of the collective state space grows rapidly as\nthe number of agents grows. This paper presents a graph-based representation of\nthe colony that can be combined with graph-based encoders to create\nlow-dimensional representations of collective state that can scale to many\nagents for a best-of-N colony problem. We demonstrate how the information in\nthe low-dimensional embedding can be used with two experiments. First, we show\nhow the information in the tensor can be used to cluster collective states by\nthe probability of choosing the best site for a very small problem. Second, we\nshow how structured collective trajectories emerge when a graph encoder is used\nto learn the low-dimensional embedding, and these trajectories have information\nthat can be used to predict swarm performance.",
        "updated": "2024-08-09 02:31:03 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.04822v1"
    },
    {
        "title": "A Multi-Scale Cognitive Interaction Model of Instrument Operations at the Linac Coherent Light Source",
        "authors": "Jonathan SegalWan-Lin HuPaul FuossFrank E. RitterJeff Shrager",
        "links": "http://arxiv.org/abs/2408.04734v1",
        "entry_id": "http://arxiv.org/abs/2408.04734v1",
        "pdf_url": "http://arxiv.org/pdf/2408.04734v1",
        "summary": "We describe a novel multi-agent, multi-scale computational cognitive\ninteraction model of instrument operations at the Linac Coherent Light Source\n(LCLS). A leading scientific user facility, LCLS is the world's first hard\nx-ray free electron laser, operated by the SLAC National Accelerator Laboratory\nfor the U.S. Department of Energy. As the world's first x-ray free electron\nlaser, LCLS is in high demand and heavily oversubscribed. Our overall project\nemploys cognitive engineering methodologies to improve experimental efficiency\nand scientific productivity by refining experimental interfaces and workflows,\nsimplifying tasks, reducing errors, and improving operator safety and stress\nlevels. Our model simulates aspects of human cognition at multiple cognitive\nand temporal scales, ranging from seconds to hours, and among agents playing\nmultiple roles, including instrument operator, real time data analyst, and\nexperiment manager. The model can predict impacts stemming from proposed\nchanges to operational interfaces and workflows. Because the model code is open\nsource, and supplemental videos go into detail on all aspects of the model and\nresults, this approach could be applied to other experimental apparatus and\nprocesses. Example results demonstrate the model's potential in guiding\nmodifications to improve operational efficiency and scientific output. We\ndiscuss the implications of our findings for cognitive engineering in complex\nexperimental settings and outline future directions for research.",
        "updated": "2024-08-08 19:23:44 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.04734v1"
    },
    {
        "title": "Learning Fair Cooperation in Mixed-Motive Games with Indirect Reciprocity",
        "authors": "Martin SmitFernando P. Santos",
        "links": "http://dx.doi.org/10.24963/ijcai.2024/25",
        "entry_id": "http://arxiv.org/abs/2408.04549v1",
        "pdf_url": "http://arxiv.org/pdf/2408.04549v1",
        "summary": "Altruistic cooperation is costly yet socially desirable. As a result, agents\nstruggle to learn cooperative policies through independent reinforcement\nlearning (RL). Indirect reciprocity, where agents consider their interaction\npartner's reputation, has been shown to stabilise cooperation in homogeneous,\nidealised populations. However, more realistic settings are comprised of\nheterogeneous agents with different characteristics and group-based social\nidentities. We study cooperation when agents are stratified into two such\ngroups, and allow reputation updates and actions to depend on group\ninformation. We consider two modelling approaches: evolutionary game theory,\nwhere we comprehensively search for social norms (i.e., rules to assign\nreputations) leading to cooperation and fairness; and RL, where we consider how\nthe stochastic dynamics of policy learning affects the analytically identified\nequilibria. We observe that a defecting majority leads the minority group to\ndefect, but not the inverse. Moreover, changing the norms that judge in and\nout-group interactions can steer a system towards either fair or unfair\ncooperation. This is made clearer when moving beyond equilibrium analysis to\nindependent RL agents, where convergence to fair cooperation occurs with a\nnarrower set of norms. Our results highlight that, in heterogeneous populations\nwith reputations, carefully defining interaction norms is fundamental to tackle\nboth dilemmas of cooperation and of fairness.",
        "updated": "2024-08-08 15:57:15 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.04549v1"
    },
    {
        "title": "Emergence in Multi-Agent Systems: A Safety Perspective",
        "authors": "Philipp AltmannJulian SchönbergerSteffen IlliumMaximilian ZornFabian RitzTom HaiderSimon BurtonThomas Gabor",
        "links": "http://arxiv.org/abs/2408.04514v1",
        "entry_id": "http://arxiv.org/abs/2408.04514v1",
        "pdf_url": "http://arxiv.org/pdf/2408.04514v1",
        "summary": "Emergent effects can arise in multi-agent systems (MAS) where execution is\ndecentralized and reliant on local information. These effects may range from\nminor deviations in behavior to catastrophic system failures. To formally\ndefine these effects, we identify misalignments between the global inherent\nspecification (the true specification) and its local approximation (such as the\nconfiguration of different reward components or observations). Using\nestablished safety terminology, we develop a framework to understand these\nemergent effects. To showcase the resulting implications, we use two broadly\nconfigurable exemplary gridworld scenarios, where insufficient specification\nleads to unintended behavior deviations when derived independently. Recognizing\nthat a global adaptation might not always be feasible, we propose adjusting the\nunderlying parameterizations to mitigate these issues, thereby improving the\nsystem's alignment and reducing the risk of emergent failures.",
        "updated": "2024-08-08 15:15:28 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.04514v1"
    }
]