[
    {
        "title": "Preserving Privacy in Large Language Models: A Survey on Current Threats and Solutions",
        "authors": "Michele MirandaElena Sofia RuzzettiAndrea SantilliFabio Massimo ZanzottoSébastien BratièresEmanuele Rodolà",
        "links": "http://arxiv.org/abs/2408.05212v1",
        "entry_id": "http://arxiv.org/abs/2408.05212v1",
        "pdf_url": "http://arxiv.org/pdf/2408.05212v1",
        "summary": "Large Language Models (LLMs) represent a significant advancement in\nartificial intelligence, finding applications across various domains. However,\ntheir reliance on massive internet-sourced datasets for training brings notable\nprivacy issues, which are exacerbated in critical domains (e.g., healthcare).\nMoreover, certain application-specific scenarios may require fine-tuning these\nmodels on private data. This survey critically examines the privacy threats\nassociated with LLMs, emphasizing the potential for these models to memorize\nand inadvertently reveal sensitive information. We explore current threats by\nreviewing privacy attacks on LLMs and propose comprehensive solutions for\nintegrating privacy mechanisms throughout the entire learning pipeline. These\nsolutions range from anonymizing training datasets to implementing differential\nprivacy during training or inference and machine unlearning after training. Our\ncomprehensive review of existing literature highlights ongoing challenges,\navailable tools, and future directions for preserving privacy in LLMs. This\nwork aims to guide the development of more secure and trustworthy AI systems by\nproviding a thorough understanding of privacy preservation methods and their\neffectiveness in mitigating risks.",
        "updated": "2024-08-10 05:41:19 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.05212v1"
    },
    {
        "title": "VITA: Towards Open-Source Interactive Omni Multimodal LLM",
        "authors": "Chaoyou FuHaojia LinZuwei LongYunhang ShenMeng ZhaoYifan ZhangXiong WangDi YinLong MaXiawu ZhengRan HeRongrong JiYunsheng WuCaifeng ShanXing Sun",
        "links": "http://arxiv.org/abs/2408.05211v1",
        "entry_id": "http://arxiv.org/abs/2408.05211v1",
        "pdf_url": "http://arxiv.org/pdf/2408.05211v1",
        "summary": "The remarkable multimodal capabilities and interactive experience of GPT-4o\nunderscore their necessity in practical applications, yet open-source models\nrarely excel in both areas. In this paper, we introduce VITA, the first-ever\nopen-source Multimodal Large Language Model (MLLM) adept at simultaneous\nprocessing and analysis of Video, Image, Text, and Audio modalities, and\nmeanwhile has an advanced multimodal interactive experience. Starting from\nMixtral 8x7B as a language foundation, we expand its Chinese vocabulary\nfollowed by bilingual instruction tuning. We further endow the language model\nwith visual and audio capabilities through two-stage multi-task learning of\nmultimodal alignment and instruction tuning. VITA demonstrates robust\nfoundational capabilities of multilingual, vision, and audio understanding, as\nevidenced by its strong performance across a range of both unimodal and\nmultimodal benchmarks. Beyond foundational capabilities, we have made\nconsiderable progress in enhancing the natural multimodal human-computer\ninteraction experience. To the best of our knowledge, we are the first to\nexploit non-awakening interaction and audio interrupt in MLLM. VITA is the\nfirst step for the open-source community to explore the seamless integration of\nmultimodal understanding and interaction. While there is still lots of work to\nbe done on VITA to get close to close-source counterparts, we hope that its\nrole as a pioneer can serve as a cornerstone for subsequent research. Project\nPage: https://vita-home.github.io.",
        "updated": "2024-08-09 17:59:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.05211v1"
    },
    {
        "title": "Evaluating the capability of large language models to personalize science texts for diverse middle-school-age learners",
        "authors": "Michael Vaccaro JrMikayla FridayArash Zaghi",
        "links": "http://arxiv.org/abs/2408.05204v1",
        "entry_id": "http://arxiv.org/abs/2408.05204v1",
        "pdf_url": "http://arxiv.org/pdf/2408.05204v1",
        "summary": "Large language models (LLMs), including OpenAI's GPT-series, have made\nsignificant advancements in recent years. Known for their expertise across\ndiverse subject areas and quick adaptability to user-provided prompts, LLMs\nhold unique potential as Personalized Learning (PL) tools. Despite this\npotential, their application in K-12 education remains largely unexplored. This\npaper presents one of the first randomized controlled trials (n = 23) to\nevaluate the effectiveness of GPT-4 in personalizing educational science texts\nfor middle school students. In this study, GPT-4 was used to profile student\nlearning preferences based on choices made during a training session. For the\nexperimental group, GPT-4 was used to rewrite science texts to align with the\nstudent's predicted profile while, for students in the control group, texts\nwere rewritten to contradict their learning preferences. The results of a\nMann-Whitney U test showed that students significantly preferred (at the .10\nlevel) the rewritten texts when they were aligned with their profile (p =\n.059). These findings suggest that GPT-4 can effectively interpret and tailor\neducational content to diverse learner preferences, marking a significant\nadvancement in PL technology. The limitations of this study and ethical\nconsiderations for using artificial intelligence in education are also\ndiscussed.",
        "updated": "2024-08-09 17:53:35 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.05204v1"
    },
    {
        "title": "TaSL: Task Skill Localization and Consolidation for Language Model Continual Learning",
        "authors": "Yujie FengXu ChuYongxin XuZexin LuBo LiuPhilip S. YuXiao-Ming Wu",
        "links": "http://arxiv.org/abs/2408.05200v1",
        "entry_id": "http://arxiv.org/abs/2408.05200v1",
        "pdf_url": "http://arxiv.org/pdf/2408.05200v1",
        "summary": "Language model continual learning (CL) has recently garnered significant\ninterest due to its potential to adapt large language models (LLMs) to dynamic\nreal-world environments without re-training. A key challenge in this field is\ncatastrophic forgetting, where models lose previously acquired knowledge when\nlearning new tasks. Existing methods commonly employ multiple\nparameter-efficient fine-tuning (PEFT) blocks to acquire task-specific\nknowledge for each task, but these approaches lack efficiency and overlook the\npotential for knowledge transfer through task interaction. In this paper, we\npresent a novel CL framework for language models called Task Skill Localization\nand Consolidation (TaSL), which enhances knowledge transfer without relying on\nmemory replay. TaSL first divides the model into `skill units' based on\nparameter dependencies, enabling more granular control. It then employs a novel\ngroup-wise skill localization technique to identify the importance distribution\nof skill units for a new task. By comparing this importance distribution with\nthose from previous tasks, we implement a fine-grained skill consolidation\nstrategy that retains task-specific knowledge, thereby preventing forgetting,\nand updates task-shared knowledge, which facilitates bi-directional knowledge\ntransfer. As a result, TaSL achieves a superior balance between retaining\nprevious knowledge and excelling in new tasks. TaSL also shows strong\ngeneralizability, suitable for general models and customizable for PEFT methods\nlike LoRA. Additionally, it demonstrates notable extensibility, allowing\nintegration with memory replay to further enhance performance. Extensive\nexperiments on two CL benchmarks, with varying model sizes (from 220M to 7B),\ndemonstrate the effectiveness of TaSL and its variants across different\nsettings.",
        "updated": "2024-08-09 17:44:45 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.05200v1"
    },
    {
        "title": "Separating Style from Substance: Enhancing Cross-Genre Authorship Attribution through Data Selection and Presentation",
        "authors": "Steven FinckeElizabeth Boschee",
        "links": "http://arxiv.org/abs/2408.05192v1",
        "entry_id": "http://arxiv.org/abs/2408.05192v1",
        "pdf_url": "http://arxiv.org/pdf/2408.05192v1",
        "summary": "The task of deciding whether two documents are written by the same author is\nchallenging for both machines and humans. This task is even more challenging\nwhen the two documents are written about different topics (e.g. baseball vs.\npolitics) or in different genres (e.g. a blog post vs. an academic article).\nFor machines, the problem is complicated by the relative lack of real-world\ntraining examples that cross the topic boundary and the vanishing scarcity of\ncross-genre data. We propose targeted methods for training data selection and a\nnovel learning curriculum that are designed to discourage a model's reliance on\ntopic information for authorship attribution and correspondingly force it to\nincorporate information more robustly indicative of style no matter the topic.\nThese refinements yield a 62.7% relative improvement in average cross-genre\nauthorship attribution, as well as 16.6% in the per-genre condition.",
        "updated": "2024-08-09 17:31:37 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.05192v1"
    }
]