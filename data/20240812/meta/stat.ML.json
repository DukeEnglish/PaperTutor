[
    {
        "title": "Concept learning of parameterized quantum models from limited measurements",
        "authors": "Beng Yee GanPo-Wei HuangElies Gil-FusterPatrick Rebentrost",
        "links": "http://arxiv.org/abs/2408.05116v1",
        "entry_id": "http://arxiv.org/abs/2408.05116v1",
        "pdf_url": "http://arxiv.org/pdf/2408.05116v1",
        "summary": "Classical learning of the expectation values of observables for quantum\nstates is a natural variant of learning quantum states or channels. While\nlearning-theoretic frameworks establish the sample complexity and the number of\nmeasurement shots per sample required for learning such statistical quantities,\nthe interplay between these two variables has not been adequately quantified\nbefore. In this work, we take the probabilistic nature of quantum measurements\ninto account in classical modelling and discuss these quantities under a single\nunified learning framework. We provide provable guarantees for learning\nparameterized quantum models that also quantify the asymmetrical effects and\ninterplay of the two variables on the performance of learning algorithms. These\nresults show that while increasing the sample size enhances the learning\nperformance of classical machines, even with single-shot estimates, the\nimprovements from increasing measurements become asymptotically trivial beyond\na constant factor. We further apply our framework and theoretical guarantees to\nstudy the impact of measurement noise on the classical surrogation of\nparameterized quantum circuit models. Our work provides new tools to analyse\nthe operational influence of finite measurement noise in the classical learning\nof quantum systems.",
        "updated": "2024-08-09 15:07:42 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.05116v1"
    },
    {
        "title": "On expected signatures and signature cumulants in semimartingale models",
        "authors": "Peter K. FrizPaul P. HagerNikolas Tapia",
        "links": "http://arxiv.org/abs/2408.05085v1",
        "entry_id": "http://arxiv.org/abs/2408.05085v1",
        "pdf_url": "http://arxiv.org/pdf/2408.05085v1",
        "summary": "The concept of signatures and expected signatures is vital in data science,\nespecially for sequential data analysis. The signature transform, a Cartan type\ndevelopment, translates paths into high-dimensional feature vectors, capturing\ntheir intrinsic characteristics. Under natural conditions, the expectation of\nthe signature determines the law of the signature, providing a statistical\nsummary of the data distribution. This property facilitates robust modeling and\ninference in machine learning and stochastic processes. Building on previous\nwork by the present authors [Unified signature cumulants and generalized Magnus\nexpansions, FoM Sigma '22] we here revisit the actual computation of expected\nsignatures, in a general semimartingale setting. Several new formulae are\ngiven. A log-transform of (expected) signatures leads to log-signatures\n(signature cumulants), offering a significant reduction in complexity.",
        "updated": "2024-08-09 14:16:21 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.05085v1"
    },
    {
        "title": "Variational Bayesian Phylogenetic Inference with Semi-implicit Branch Length Distributions",
        "authors": "Tianyu XieFrederick A. Matsen IVMarc A. SuchardCheng Zhang",
        "links": "http://arxiv.org/abs/2408.05058v1",
        "entry_id": "http://arxiv.org/abs/2408.05058v1",
        "pdf_url": "http://arxiv.org/pdf/2408.05058v1",
        "summary": "Reconstructing the evolutionary history relating a collection of molecular\nsequences is the main subject of modern Bayesian phylogenetic inference.\nHowever, the commonly used Markov chain Monte Carlo methods can be inefficient\ndue to the complicated space of phylogenetic trees, especially when the number\nof sequences is large. An alternative approach is variational Bayesian\nphylogenetic inference (VBPI) which transforms the inference problem into an\noptimization problem. While effective, the default diagonal lognormal\napproximation for the branch lengths of the tree used in VBPI is often\ninsufficient to capture the complexity of the exact posterior. In this work, we\npropose a more flexible family of branch length variational posteriors based on\nsemi-implicit hierarchical distributions using graph neural networks. We show\nthat this semi-implicit construction emits straightforward permutation\nequivariant distributions, and therefore can handle the non-Euclidean branch\nlength space across different tree topologies with ease. To deal with the\nintractable marginal probability of semi-implicit variational distributions, we\ndevelop several alternative lower bounds for stochastic optimization. We\ndemonstrate the effectiveness of our proposed method over baseline methods on\nbenchmark data examples, in terms of both marginal likelihood estimation and\nbranch length posterior approximation.",
        "updated": "2024-08-09 13:29:08 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.05058v1"
    },
    {
        "title": "BoFire: Bayesian Optimization Framework Intended for Real Experiments",
        "authors": "Johannes P. DürholtThomas S. AscheJohanna KleinekorteGabriel Mancino-BallBenjamin SchillerSimon SungJulian KeuppAaron OsburgToby BoyneRuth MisenerRosona EldredWagner Steuer CostaChrysoula KappatouRobert M. LeeDominik LinznerDavid WalzNiklas WulkowBehrang Shafei",
        "links": "http://arxiv.org/abs/2408.05040v1",
        "entry_id": "http://arxiv.org/abs/2408.05040v1",
        "pdf_url": "http://arxiv.org/pdf/2408.05040v1",
        "summary": "Our open-source Python package BoFire combines Bayesian Optimization (BO)\nwith other design of experiments (DoE) strategies focusing on developing and\noptimizing new chemistry. Previous BO implementations, for example as they\nexist in the literature or software, require substantial adaptation for\neffective real-world deployment in chemical industry. BoFire provides a rich\nfeature-set with extensive configurability and realizes our vision of\nfast-tracking research contributions into industrial use via maintainable\nopen-source software. Owing to quality-of-life features like\nJSON-serializability of problem formulations, BoFire enables seamless\nintegration of BO into RESTful APIs, a common architecture component for both\nself-driving laboratories and human-in-the-loop setups. This paper discusses\nthe differences between BoFire and other BO implementations and outlines ways\nthat BO research needs to be adapted for real-world use in a chemistry setting.",
        "updated": "2024-08-09 12:50:48 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.05040v1"
    },
    {
        "title": "HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction",
        "authors": "Bhaskarjit SarmahBenika HallRohan RaoSunil PatelStefano PasqualiDhagash Mehta",
        "links": "http://arxiv.org/abs/2408.04948v1",
        "entry_id": "http://arxiv.org/abs/2408.04948v1",
        "pdf_url": "http://arxiv.org/pdf/2408.04948v1",
        "summary": "Extraction and interpretation of intricate information from unstructured text\ndata arising in financial applications, such as earnings call transcripts,\npresent substantial challenges to large language models (LLMs) even using the\ncurrent best practices to use Retrieval Augmented Generation (RAG) (referred to\nas VectorRAG techniques which utilize vector databases for information\nretrieval) due to challenges such as domain specific terminology and complex\nformats of the documents. We introduce a novel approach based on a combination,\ncalled HybridRAG, of the Knowledge Graphs (KGs) based RAG techniques (called\nGraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for\ninformation extraction from financial documents that is shown to be capable of\ngenerating accurate and contextually relevant answers. Using experiments on a\nset of financial earning call transcripts documents which come in the form of\nQ&A format, and hence provide a natural set of pairs of ground-truth Q&As, we\nshow that HybridRAG which retrieves context from both vector database and KG\noutperforms both traditional VectorRAG and GraphRAG individually when evaluated\nat both the retrieval and generation stages in terms of retrieval accuracy and\nanswer generation. The proposed technique has applications beyond the financial\ndomain",
        "updated": "2024-08-09 09:07:48 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.04948v1"
    }
]