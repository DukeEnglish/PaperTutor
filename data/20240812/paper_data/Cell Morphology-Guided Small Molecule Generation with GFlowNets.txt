Cell Morphology-Guided Small Molecule Generation
with GFlowNets
StephenZhewenLu ZiqingLu
Mila,McGillUniversity Genentech
stephen.lu@mail.mcgill.ca lu.ziqing@gene.com
EhsanHajiramezanali TommasoBiancalani
Genentech Genentech
hajiramezanali.ehsan@gene.com biancalani.tommaso@gene.com
YoshuaBengio GabrieleScalia
Mila,UniversitédeMontréal Genentech
yoshua.bengio@mila.quebec scalia.gabriele@gene.com
MichałKoziarski
Mila,UniversitédeMontréal
michal.koziarski@mila.quebec
Abstract
High-contentphenotypicscreening, includinghigh-contentimaging(HCI),has
gained popularity in the last few years for its ability to characterize novel ther-
apeutics without prior knowledge of the protein target. When combined with
deep learning techniques to predict and represent molecular-phenotype interac-
tions,theseadvancementsholdthepotentialtosignificantlyaccelerateandenhance
drugdiscoveryapplications. ThisworkfocusesonthenoveltaskofHCI-guided
moleculardesign. GenerativemodelsformoleculedesigncouldbeguidedbyHCI
data, for example with a supervised model that links molecules to phenotypes
ofinterestasarewardfunction. However, limitedlabeleddata, combinedwith
thehigh-dimensionalreadouts,canmaketrainingthesemethodschallengingand
impractical. Weconsideranalternativeapproachinwhichweleverageanunsu-
pervisedmultimodaljointembeddingtodefinealatentsimilarityasarewardfor
GFlowNets. The proposed model learns to generate new molecules that could
produce phenotypic effects similar to those of the given image target, without
relying on pre-annotated phenotypic labels. We demonstrate that the proposed
methodgeneratesmoleculeswithhighmorphologicalandstructuralsimilarityto
thetarget,increasingthelikelihoodofsimilarbiologicalactivity,asconfirmedby
anindependentoraclemodel.
1 Introduction
Historically,manydrugshavebeendevelopedusingthephenotypicscreeningapproach,wherein
theefficacyofacompoundwasassessedbasedonitsobservedbiologicaleffectswithoutaprior
comprehensiveunderstandingofitsunderlyingmodeofaction(MoA).Althoughphenotypicdiscovery
was gradually substituted or augmented by target-based discovery methods, it has experienced a
resurgenceinrecentyears,partlyduetoadvancementsinmachinelearningtools[26,55].
Preprint.Underreview.
4202
guA
9
]GL.sc[
1v69150.8042:viXraHigh-contentphenotypicscreening,includinghigh-contentimaging(HCI)[5],providesrichdata
suchasmorphologicalchangesincellshapeandstructure. Thisholdssignificantpromisetoaid
discovery, serving as a rich and high-information readout of the perturbation’s effect on the cell.
Suchreadoutscanpotentiallyelucidatebroadbiologicalconsequences,secondaryeffects,andMoAs
[35,55]. Despiteitspotentialtoguidethedrugdiscoveryprocess,challengespersistineffectively
utilizingthisdata.
Onecommonapproachtoutilizethisinformationistrainingasupervisedclassificationmodelto
recognizethephenotypeofinterest(which,inturn,isextractedfromthehigh-contentreadout),and
thenuseittovirtuallyscreenexistinglibraries[25]. However,thiscanrequireasubstantialamount
of labeled data and prior knowledge of the phenotype of interest, which might not be available
when designing a therapeutic for a poorly understood disease. A preferred scenario would be to
haveamethodcapableofdesigningnewcompoundsbasedononlyafew,orevenasingle,target
morphological readout. Another challenge lies in the screening process itself. Virtual screening
limitsthesearchspacetoexistingscreeninglibraries,whicharesignificantlysmallerthanthewhole
drug-like space, often estimated to contain more than 1060 [27] molecules. This limitation can
become particularly important when structurally and functionally novel molecules are desirable,
forexample,toimprovethepotencyanddiversityoftheleadsortoovercomeunwantedsecondary
effects[18,10,52,12].
Inthispaper,weaddressbothofthesechallengesbyproposingagenerativemethodguidedbythe
targetcellmorphology. Specifically,weproposearewardfunctionthatutilizesthelatentsimilarity
betweenthegeneratedmoleculeandthetargetmorphologicalprofile.Forthis,weutilizeamultimodal
contrastivelearningmodelthatalignssmallmoleculestomorphologicalprofiles. Then,weusethis
rewardtotrainaGenerativeFlowNetwork(GFlowNet)[3],togeneratemoleculescapableofinducing
similarmorphologicaloutcomes. Wedemonstratethatourapproachiscapableofgeneratingdiverse
moleculeswithhighlatentsimilaritytotheprovidedmorphologicalprofile,whichtranslatesintoa
higherlikelihoodofobtainingsimilarpredictedbiologicalactivity. Wealsoshowthatthegeneration
processcanbestructurallyconditionedbyusingjointlatentembeddings,whichcombinebothtarget
readout and molecule, further improving the performance. Practical use cases of the proposed
methodincludegeneratingmoleculesthatinduceadesiredcellmorphologyobtainedthroughgene
perturbations[47],scaffoldhopping,wherenovelmolecularstructureswithsimilareffectstoatarget
onearedesired[17],and,moregenerally,moleculardesignguidedbyphenotypicreadouts[25].
2 Relatedwork
Generativemodelsfordrugdiscovery. Thereisaplethoraofmethodsformoleculargeneration
in the literature [34, 4]. They can be broadly categorized based on the molecular representation
used: textual representation such as SMILES [20, 1, 22], molecular graphs [19, 32, 43, 8] or
3Datomcoordinaterepresentations[40]; aswellastheunderlyinggenerativemethodology,e.g.,
variational autoencoders [19, 32], reinforcement learning (RL) [43, 28] or diffusion models [49].
Thesemethodshavefoundapplicationsindrugdiscovery,reportingsuccessesinseveralareassuch
asimmunologyandinfectiousdiseases[13,36]. Recently,GenerativeFlowNetworks(GFlowNets)
[2, 39, 48, 51, 56, 23, 9, 24] emerged as a promising paradigm for molecular generation due to
theabilitytosamplediversecandidatemolecules,whichiscrucialinthedrugdiscoveryprocess.
Importantly, similar to RL, GFlowNets can be trained based on the specified reward function,
whichmakesthemsuitableforphenotypicdiscovery. Comparedtoexistingmethods,whichfocus
onconditionalgenerationbasedonasinglepropertyormultiplepropertiesofinterest,wetackle
generationguidedbyhigh-contentreadouts, whichweachievethroughamultimodallatentjoint
representation.
Deep learningforhigh-content molecularperturbations. High-content phenotypicscreening,
particularlyhigh-contentimaging(HCI),hasbecomecrucialindrugdiscoveryforcharacterizing
molecular effects in cells and elucidating targets, gene programs, and biological functions [35,
7]. Recentadvancesproposedeeplearningtechniquestoaccelerateandenhancetheseprocesses
[11]. Predictive models to infer the outcome of molecular effects have been developed both for
transcriptomicreadouts[29,16,44]andHCIreadouts[42]. Inthesemodels,theoutputishighly
multi-dimensional,capturingthefullreadoutofthehigh-throughputexperiment,thuspotentially
requiringalargeamountofdatafortrainingandmakingitchallengingtoseparatebiologicaleffects
2frombackgroundsignals. Incontrasttotheseworks,wefocusontheinverseproblem,designing
moleculesleadingtoaspecific(target)readout.
Jointrepresentationofmoleculesandhigh-contentreadouts. Recentworksfocusedonthejoint
modelingofmoleculesandhigh-contentreadouts. Inparticular,multimodalcontrastivemodels[46]
havebeenusedtoalignmolecularrepresentationstohigh-dimensionalreadoutsinlatentspace,thus
capturingsharedfeatureswhileavoidinghigh-dimensionalsupervisedlosses[50,58,38,57]. While
thesemodelscanbeusedforscreeningtasks,reportingimprovedgeneralizationabilitycompared
tomolecule-onlymodels,theyareunabletoperformgenerativetasks. Comparedtoexistingworks
inthisarea,wefocusonthenoveltaskofHCI-guidedmoleculardesign,whilerelyingonajoint
representationtoguidethegeneration.
3 Method
3.1 GenerativeFlowNetworks
GFlowNetsareamortizedvariationalinferencealgorithmsthataretrainedtosamplefromanunnor-
malizedtargetdistributionsovercompositionalobjects. GFlowNetsaimtosampleobjectsfromaset
ofterminalstatesX proportionallytoarewardfunctionR:X →R+. GFlowNetsaredefinedona
pointeddirectedacyclicgraph(DAG),G=(S,A),where:
• s∈S arethenodes,referredtoasstatesinoursetting,withthespecialstartingstates being
0
theonlystatewithnoincomingedges,andtheterminalstatesX havenooutgoingedges,
• a=s→s′ ∈Aaretheedges,referredtoasactionsinoursetting,andcorrespondtoapplying
anactionwhileinastatesandlandinginstates′.
Wecandefineanon-negativeflowfunctionontheedgesF(s → s′)andonthestatesF(s)ofthe
DAGsuchthat∀x∈XF(x)=R(x). AperfectlytrainedGFlowNetshouldsatisfythefollowing
flow-matchingconstraint:
(cid:88) (cid:88)
∀s∈S F(s)= F(s′′ →s)= F(s→s′). (1)
(s′′→s)∈A (s→s′)∈A
Astatesequenceτ = (s → s → ··· → s = x),withs = x ∈ X anda = (s → s ) ∈ A
0 1 n n i i i+1
foralli,iscalledacompletetrajectory. WedenotethesetoftrajectoriesasT.
Trajectorybalance.ThereareseveraltraininglossesthatwereexploredtotrainaGFlowNet.Among
those,trajectorybalance[30]hasbeenshowntoimprovecreditassignment. Inadditiontolearning
a forward policy P , we also learn a backwards policy P and a scalar Z , such that, for every
F B θ
trajectoryτ =(s →s →···→s =x),theysatisfy:
0 1 n
n n
(cid:89) (cid:89)
Z P (s |s )=R(x) P (s |s ) (2)
θ F t t−1 B t−1 t
t=1 t=1
3.2 Multimodalcontrastivelearning
Contrastivelearningisaself-supervisedapproachthatlearnsembeddingsbymaximizingagreement
betweensimilarsamplesandminimizingitbetweendissimilarones,usingcontrastivelossfunctions
likeInfoNCE[41]. multimodalcontrastivelearninghasemergedasapowerfulapproachforlearning
joint representations from diverse data modalities. A notable instance of this approach is CLIP
[46], which aligns textual descriptions with visual representations, enabling robust cross-modal
understanding. Weleverageamultimodalcontrastivemodeltolearnajointembeddingofmolecules
andmoleculareffects. Thischoiceavoidshigh-dimensionalsupervisedlossesandpromoteslearning
“informative”featuresforthetask(i.e.,featuresthatrelatethetwomodalitiestoeachother).
Let {(x ,y )}N be a batch of N pairs of molecular graphs (x ) and their corresponding mor-
i i i=1 i
phology images (y ). Let f and h be the molecular and morphology encoders, respectively. Let
i
the similarity between the molecular graph and morphology image embeddings be defined as
3(cid:16) (cid:17)
S =exp sim(f(xi),h(yj)) , where sim(f(x ),h(y )) denotes the cosine similarity between em-
ij τ i j
beddings. TheCLIPlossisdefinedasfollows:
N (cid:34) (cid:35)
L = 1 (cid:88) −log S ii −log S ii , (3)
CLIP N (cid:80)N S (cid:80)N S
i=1 j=1 ij j=1 ji
whereτ isatemperatureparameter.
Instead of relying on CLIP, in this work, we leverage the closely related Geometric Multimodal
Contrastive(GMC)loss[45]. GMCleveragesthesamelossfunctionin(3)toalignmodality-specific
encoderstoajointencoder,whichtakesasinputallmodalities. Therefore,inadditiontoproviding
modality-specificembeddingsf andh,italsoprovidesajointembeddingfhthatweleveragewhen
boththetargetmoleculeanditsreadoutareavailable.
3.3 GFlowNetsformorphology-guidedmoleculardesign
The proposed approach combines recent developments in multimodal contrastive learning and
moleculargenerationwithGFlowNetsintoaunifiedpipeline,asillustratedinFigure1. Themethod
reliesonfirsttrainingacontrastivelearningmodelcapableofproducingalignedlatentrepresentations
between chemical structures and morphology profiles, and then using these representations as a
guidingsignalforGFlowNet. WedefinetherewardfunctionfortheGFlowNetbytrainingaGMC
modelasdescribedinSection3.2. Specifically,weusethefollowingreward:
f(x)h(y)
R(x|y)=1+ , (4)
2∥f(x)∥∥h(y)∥
which is a normalized cosine similarity between the target morphology latent and the generated
molecularlatent. Thischoiceisimportanttoenforcethenon-negativityoftheGFlowNetreward.
During the training of the GMC model, we impose early stopping using the correlation between
thecross-modalitydistancemetric. Weobservethatearlystoppingreducesthevarianceofcosine
similaritybetweenthemultimodalGMCembeddings,whileitdoesnotaffecttheperformanceof
GFlowNet(seeAppendixA.2formoredetails). Inspiredbyusingreplaybufferinreinforcement
learning[54],weleveragereplaybufferwithknowndecomposedstructurewhentrainingonjoint
morphologyandstructure-guidedgenerations. Thisincreasesthestructuralsimilarityofgenerated
samplestotheknowntarget.
4 Experimentalstudy
Wefirstverifytheunderlyingassumptionofourmethod,namelythatthelatentsimilarityderived
throughcontrastivelearningcorrelateswiththemorphologicalsimilarity. Afterwards,weevaluatethe
proposedapproach,firstbyexaminingthequalityanddiversityofthegeneratedsamples,andthenby
analyzingtheirpredictedbiologicalactivityindownstreamtasks. Finally,weconsiderthesetting
ofstructurallyconditionedgeneration,wherewedefinethetargetlatentbasedonthecombination
ofthetargetmorphologicalprofileandassociatedmolecularstructure,withthegoalofbiasingthe
generationtowardaknownperturbagen.
4.1 Set-up
WeperformexperimentsontheCellPaintingdatasetintroducedby[5,6],asfurtherpre-processedin
[37]. Thedatasetincludes16,170moleculesandassociatedcellmorphologyimages. Eachimage
includesfivecolorchannelsthatdescribethemorphologyoffivecellularcompartments: nucleus
(DNA), Endoplasmic reticulum (ER), nucleolus/cytoplasmic RNA (RNA), F-actin cytoskeleton
(AGP),andMitochondria(Mito). Imageshavebeenpre-processedusingCellProfiler3.0[33,37].
Additionally, to support the evaluation of the generated molecules, we leverage oracle models
independentlytrainedondatafrommultipleassaysreleasedbytheBroadInstitute[37]. Forthis,
weprimarilyfocusonassaysthathavebeenlinkedtomorphologicalfeaturesand/orcombinations
of morphological and chemical properties. We select 37 assays identified in [37] as predictable
frommorphologicalfeaturesorcombinedchemicalandmorphologicalfeatureswithhighaccuracy
(AUROC > 0.9). This allows us to evaluate the ability of the model to generate molecules with
biochemicalandcellulareffectssimilartothe(unknown)targetmolecule.
4Contrastive loss
f h
Aligned
representations
Molecular generator f ✗
Target morphology
f h
✓
f
✗
Figure1:Overviewoftheproposedapproach.Inthefirststage(top),cross-modalcontrastivelearning
isusedtotrainlatentencodersf andhthatproducealignedrepresentationsbetweenmoleculesand
readouts. Then,inthesecondstage(bottom),thetargetmorphologyreadoutisfirstconvertedintoa
latentvector,andthesimilaritybetweenthatandlatentsfrommoleculesoutputbyageneratorisused
asareward. Themodellearnstosamplemoleculescapableofinducingsimilarlatentstothetarget.
4.2 Relationbetweenproposedrewardandmorphologicaldistance
The underlying assumption behind our method is that the latent representations produced by the
contrastivelearningmodelareofahighenoughqualitytoreliablycomputesimilarity. Specifically,
givenatargetpairofamoleculeanditsassociatedmorphology(x˙,y˙),anarbitrarypairofagenerated
moleculeandthemorphologythatwouldbeinducedbythatmolecule(x,y),distancedintheinput
modalityspace,distancedˆinthelatentspace,andmodelsf andhthattransformtheinputsintoa
latentrepresentation,werequirethat
R(x|y˙)=dˆ(h(y˙),f(x))∼d(y˙,y). (5)
Itisworthnotingthatduringgeneration,wealwaysknowx,whichisthemoleculegeneratedbyour
model,andneverknowy,whichiswhyweintroducetheencoderf. Similarly,wealwaysknowthe
targetmorphologyy˙,andinsomesettings,suchasfindingdruganalogs,wemightalsohaveaccess
totheassociatedmoleculex˙. Inparticular,inthelattersetting,wemightconsiderconditioningonthe
jointlatent,producedbasedonthepairof(x˙,y˙): R(x|x˙,y˙)=dˆ(fh(x˙,y˙),f(x))(seeSection4.5).
Toevaluatethisassumption,foreverypairofobservationsfromthedataset,wemeasurethecorrelation
betweenthesimilarityofmorphologicalfeaturesandthesimilaritybetweenthelatentrepresentations
ofthestructurefromthefirstobservationandthetargetmorphologyfromthesecondobservation.
Additionally, we also measure the same for the joint target latent, computed based on both the
morphologyandtheassociatedmoleculestructure. TheresultsarepresentedinFigure2. Ascanbe
seen,inbothcasesweobserveamediumlevelofcorrelation. Whilenotperfect,likelyduetoinherent
varianceinthemorphologicalprofilesandmodeluncertainty,wearguethatthiscanbesufficientfor
screeningpurposes.
4.3 Generatinghighrewardanddiversesamples
WeareinterestedinevaluatingthecapabilitiesofaGFlowNetinoptimizingthespecifiedreward
function. Givenourprimaryfocusonitsapplicationintheinitialdiscoverystage,itisessentialto
generate not only high-reward outcomes but also a diverse set of samples. We benchmarked the
proposed approach against random sampling (RND) and two standard RL-based baselines: soft
Q-learning(SQL)[14]andsoftactor-critic(SAC)[15]. Notethatsince,tothebestofourknowledge,
5Cross-Modal Latent Cosine Sim. (Struct-Morph) Cross-Modal Latent Cosine Sim. (Struct-Joint)
vs Morph PCA Cosine Sim. vs Morph PCA Cosine Sim.
1.0 r=0.47 1.0 r=0.46
0.8 0.8
0.6 0.6
0.4 0.4
0.2 0.2
0.0 0.0
0.2 0.2
0.4 0.4
0.6 0.6
0.50 0.25 0.00 0.25 0.50 0.75 1.00 0.50 0.25 0.00 0.25 0.50 0.75 1.00
Cosine Similarity (struct-morph) Cosine Similarity (struct-joint)
Figure2: Correlationbetweenthesimilarityinmorphologicalfeaturespaceandlatentsimilarity
betweentargetstructureanda)morphology(left)orb)jointmorphologyandstructure(right).
thisisthefirstpublishedattemptatguidingthegenerativemolecularmodelwithexpectedimage
morphology outcome, we focus specifically on benchmarking against other potential molecular
generationmethods.
Weshowthedistributionofrewardsforgeneratedsamplesandthenumberofdiscoveredmodes
(definedasmoleculeswithreward≥90thpercentileandTanimotosimilaritytoothermodes≤0.3)
inFigure3,andthedistributionofsimilaritiesbetweentop-100generatedsamplesinFigure4(each
figureaggregatedacrossallconsideredtargets). Asshown,GFlowNetlearnstosamplehigh-reward
candidatemolecules(withasignificantlyhigheraveragerewardthanrandomsamplingandSQL,
comparabletoSAC)whilealsosignificantlyimprovingthediversitycomparedtoSAC(withalower
similaritybetweentopcandidates). Bothoftheabovetranslateintoasignificantlyhighernumber
ofdiscoveredmodesthanthebaselinemethods. Thediversityofthegeneratedsamplesisfurther
illustratedinFigure4,whereaUMAPvisualizationofthemolecularstructuresproducedbydifferent
methods is presented for a specific target. As can be seen, GFlowNet displays sample coverage
similartorandomsampling,whichisadesirableoutcome.
Reward of Last 10000 Samples per Target Number of Modes for 17 Aggregated Targets with
Tanimoto Similarity 0.3
101 method
R GN FND 500 R GN FND
100 SAC SAC
SQL 400 SQL
101
300
102 200
100
103
0
0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
Reward 0 2000 4000 6000 8000 10000
Num Trajectories (x64)
Figure 3: Comparison of examined methods in terms of reward optimization: a) distribution of
rewardsfromgeneratedsamples,10,000samplesgeneratedbyatrainedmodel(left)andb)number
ofmodesdiscovered(right). Bothplotsaggregateacrossallexaminedtargets.
4.4 Biologicalactivityestimation
Sofar,wehaveestablishedthattheproposedapproachiscapableofgeneratingdiversesampleswith
highrewardandthatthereisamoderatecorrelationbetweentherewardandthesimilaritytothe
target. However,whatiscriticalintheendiswhetherthiswilltranslateintogeneratedmolecules
6
ytisneD
)ACP
hprom-hprom(
ytiralimiS
enisoC
)ACP
hprom-hprom(
ytiralimiS
enisoC
sedoM
muNTanimoto Similarity between Top 100 Highest
Reward Samples per Target UMAP of Top 1000 Highest Reward Samples
101 method 10 RND 0.945
RND GFN
GFN 8 SAC 0.940
100 S SQAC L 6 S TaQ rL get 0.935
0.930 101 4
0.925
102 2 0.920
0 0.915
103 0.910
2
0.905
0.0 0.2 0.4 0.6 0.8 1.0
Tanimoto Similarity 0 2 4 6 8 10
UMAP 1
Figure 4: Comparison of examined methods in terms of diversity: a) distribution of Tanimoto
similaritiesbetweentop-100generatedsamples(left;aggregatedacrossallexaminedtargets,loweris
better)andb)structuraldiversityoftop-1000highestrewardsamplestoTarget#8636(right).
Table1: Max. Tanimotosimilaritytothetargetinlast10,000samples,averagedacrossalltargets.
Random SoftActor-Critic SoftQ-Learning GFlowNet
MorphologyTarget 0.305(±0.057) 0.261(±0.068) 0.329(±0.079) 0.337(±0.092)
JointTarget 0.311(±0.064) 0.388(±0.163) 0.309(±0.064) 0.451(±0.163)
inducingsimilarbiologicaleffectstotheoriginaltargetperturbation(groundtruth). Ideally,wewish
toevaluatethisonthebasisofexperimentscomparinggeneratedmoleculesandthegroundtruth,but
thiscanbecostlyandtime-consuming. Instead,inthefollowing,weestimatethesimilarityofthe
biologicaleffectbasedontheavailabledata. Weconsidertwoapproachestothisgoal.
Firstofall,wewouldexpectaperfectlyoptimizedgeneratortobeabletosampleknownmolecules
that induced target morphological profiles. In practice, this might be unattainable: not only is
the problem itself heavily under-constrained (we expect multiple molecules, likely a very large
number,tobeabletoinduceagivenmorphologicaloutcome),butalsoourmorphologicalsimilarity
estimation is intrinsically noisy. Because of the above, what we try to achieve is the highest
possiblestructuralsimilarityofgeneratedsamplestotheknownmoleculethatinducedthegiven
morphology. ThemaximumTanimotosimilaritytotheknownmoleculartarget,averagedacrossall
consideredtargets, ispresentedinTable1. Asshown, theproposedapproachgenerallyrecovers
theunderlyingtargetsmoreeffectively,suggestingitsutilityinidentifyingmoleculeswithexpected
biological activity. Unsurprisingly, this effect is particularly pronounced when conditioning on
specificmolecularstructures. TargetrecoveryisfurtherillustratedinFigure5,wherewedemonstrate
structuralproximityofthegeneratedsamplestotheknowntarget(visualizationsforothertargetscan
befoundinAppendixA.3).
UMAP of Top 1000 Highest Reward Samples Colored by UMAP of Top 1000 Highest Reward Samples Colored by
Tanimoto Similarity to Target Tanimoto Similarity to Target
RND 4 RND
GFN 0.30 SQL 0.40
12 S SQAC L 0.25 3 S GA FC N 0.35
Target Target 0.30
10 0.20 2 0.25
8 0.15 1 0.20
0.10 0 0.15
6 0.10
0.05 1
0.05
4 0.00 0.00
6 4 2 0 2 4 2 4 6 8 10
UMAP 1 UMAP 1
Figure5: UMAPoftop-1000highestrewardsamplesfora)morphology-onlytarget(left)andb)joint
target(right). ColoredbyTanimotosimilaritytotarget#2288.
7
ytisneD
2 PAMU
ytiralimiS
otominaT
2 PAMU
2 PAMU draweR
ytiralimiS
otominaTThesecondapproachweconsiderinvolvesutilizingoraclemodelsforpredictingbiologicalactivity.
WetrainanMLPusingmolecularstructures,specificallytheirextractedmolecularfingerprints,as
inputstopredicttheoutcomesofbiologicalassays(detailsofthemodeltrainingareprovidedin
AppendixB.3). Foreachtargetmolecule,atleastoneassociatedassayhasapositiveoutcome. The
objectiveistogeneratemoleculeswithahighpredictedprobabilityofhavingapositiveoutcomein
thespecificassayforwhichthetargetmoleculehasknownactivity. Thenumberofgeneratedsamples
withhighpredictedassayprobability(≥0.7)ispresentedinFigure6. Wepresenttheresultsforboth
thetop-1000highestrewardsamplespertarget,aswellas1,000modespertarget. Notethat,dueto
thehighuncertaintyoftheoraclemodel,weareprimarilyinterestedinquantifyingthenumberof
high-likelihoodsamples. Ascanbeseen,usingguidedgenerationhelpsimprovetheproportionof
generatedmoleculeswithhighpredictedassayprobability,whichservesasaproxyforgenerating
moleculeswithsimilarbiologicalactivity. Itisworthnotingthatwhileweobserveahigherpredicted
probabilityforSACwhenconsideringthetop-1000moleculesbyreward,thistrendreverseswhen
consideringdifferentmodes,onceagainhighlightingthehigherdiversitycombinedwiththehigh
rewardofGFlowNetsamples. Itisalsoworthnotingthatweobservealargevarianceacrosstargets.
Whilethiscanbepartiallyattributedtotheuncertaintyoftheoracle,furtherinvestigationoffactors
determiningwhethertheproposedapproachishelpfulornotforagiventargetisanimportantfuture
researchdirection.
Number of Aggregated High Assay Predictions 0.7 in Number of Aggregated High Assay Predictions 0.7 in
top 1000 Highest Reward Samples per Target top 1000 Modes per Target
800 350
300
600 250
200
400
150
100
200
50
0 0
RND GFN SAC SQL RND GFN SAC SQL
Method Method
Figure6: Numberofsampleswithpredictedassayprobability≥0.7ina)top1000highestreward
samples(left)andb)top1000modeswithTanimotosimilarity≤0.3(right). Resultsareaggregated
acrossmultipletargets.
4.5 Jointmorphologyandstructure-guidedgeneration
Untilnow,wefocusedonthegenerationofmoleculescapableofinducingaspecificmorphological
outcome,assumingthattheperturbationthatledtotheobservedoutcomeisfullyunknown. However,
it is worth noting that in practice, this problem can be significantly under-constrained, as there
mightbealargenumberofmoleculesresultinginsimilarmorphologicaleffects,andmanyofthem
couldhaveundesirableproperties(e.g. toxicity,lackofstability,etc.). Therearemultiplewaysof
constraininggeneratedmoleculestoaparticularchemicalsubspacewithdesirableproperties,for
instance,byincludingadditionalrewardtermsandconditionsintheGFlowNettraining. However,a
particularlywell-suitedapproachforourmethod,assumingtheavailabilityofthemolecularstructure
associatedwiththetargetmorphology(e.g. inthedruganalogsearchsetting),involvesconditioning
onthejointlatentrepresentation. Thisstrategyaimstoanchorthegeneratedmoleculestoaknown,
desirablemolecularstructure.
Weevaluatethecapabilitiesoftheproposedapproachinconstrainingthesearchablespacebased
onthegivenstructurebyreplacingthetargetlatentwithajointrepresentationgeneratedbasedon
both morphology and associated structure (Section 3.2). We evaluate the number of discovered
modes(Figure7),molecularsimilaritytothegiventarget(Table1),andnumberofsampleswithhigh
predictedassayprobability(Figure8). Ascanbeseen,usingthejointrepresentationsdoesnotimpact
the ability of GFlowNet to generate high-reward and diverse samples, and increases the average
numberofdiscoveredmodes. Asexpected,italsoleadstogeneratingcompoundsmorestructurally
similartothetargetmolecules,effectivelyconstrainingthegenerationprocess. However,somehow
8
tnuoC tnuoCNumber of Aggregated High Assay Predictions 0.7 in Number of Samples with Tanimoto Similarity to Target 0.2 in
top 1000 Modes per Target top 1000 Modes per Target
60
350
300 50
250 40
200
30
150
20
100
10
50
0 0
Joint Morph Joint Morph
Method Method
Figure8: Comparisonofmorphology-onlyversusjointmorphologyandstructureguidedgeneration:
a) number of samples with prediction assay probability ≥ 0.7 in top 1000 modes (left; higher is
better)andb)numberofsamplesintop1000modeswithTanimotosimilaritytotarget≥0.2(right).
ModesaredefinedashighrewardsampleswithmutualTanimotosimilarity≤0.3.
surprisingly,conditioningbasedonthejointrepresentationdoesnotseemtoincreasetheproportion
ofmoleculeswithhighassaypredictedprobability.
Ourleadinghypothesisisthatthejointembedding
Number of Modes for 17 Aggregated Targets with
spacelearnedbytheGMCmodelencodesastronger Tanimoto Similarity 0.3
RND
structural signal than a morphological signal, thus 600 SQL
SAC
leadingtheGFlowNettosamplemoleculesthatare 500 GFN
moresimilartothetarget,butthatdon’tnecessarily
400
triggerthedesiredmorphologicalprofileinthetarget
cell.ThisclaimissupportedbyAppendixA.5,where 300
theGMCalignmentbetweenjointandstructuralla- 200
tentspace(r = 0.94)isgreaterthanthealignment 100
betweenjointandmorphology(r =0.88). Although 0
thealignmentbetweenstructureandmorphologyem- 0 2000 4000 6000 8000 10000
Num Trajectories (x64)
beddings is even lower (r = 0.75), we argue that
thissettingprovidesastrongerandmoredirectsig- Figure 7: Number of modes discovered for
nalthatguidestheGFlowNettowardsmorediverse jointmorphologyandstructure-guidedgener-
moleculesthatexhibitthedesiredmorphologicalpro- ation.
fileofthetarget. Thisisconsistentwithourresultsin
Figure8,whichsuggestthatthejointsettingyieldsahighernumberofmoleculesthatarestructurally
similartothetargetbutfindsfewermoleculeswithhighassayprobabilitiesthanthemorphology-only
setting.1
5 Limitations
Thecurrentapproachheavilyreliesonthequalityofthelearnedlatentrepresentations. Asithasbeen
shown,thecurrentmultimodalcontrastivemodelsprovideonlyamediumcorrelationbetweenlatent
andmorphologysimilarities. Thismakestheapproachsuitableforlargerscreeningcampaigns,but
wouldlikelyleadtohighvariancewithsmallerscreeningbudgets. However,theproposedframework
iscompatiblewithdifferentmultimodallearningframeworks,andweexpectthatcurrentresearchon
morerobustjointrepresentations[57]willleadtomoreefficientandprecisegenerationcapabilities.
On the generative model side, the proposed approach does not take into account non-primary
molecular properties, such as synthesizability, toxicity, drug-likeness, etc. However, while not
consideredinthiswork,thiscan,inprinciple,beintegratedbyaddingadditionalrewardterms[21].
Additionally, in the current state, even if leveraging the same pretrained multimodal model, the
approachrequirestrainingaseparatemodelforeachconsideredmorphologytarget. Furtherworkon
developingaconditionalvariant,whereasingleGFlowNetsamplesconditionallygivenamorphology
readout,wouldberequiredtoreducethecomputationalcostofthemethod.
1Codeavailable@https://github.com/TheMatrixMaster/omics-guided-gfn
9
tnuoC tnuoC
sedoM
muN6 Conclusion
Inthispaper,weconsiderthetaskofmoleculargenerationguidedbyahigh-dimensionalmorpholog-
icalprofile. Suchaframeworkisbroadlyapplicable,forexample,indesigningdrugsmimickingthe
effectofageneticperturbation,designingdruganalogs,or,moregenerally,moleculardesignguided
byphenotypicreadouts. TheproposedapproachreliesontheGFlowNetframeworkformolecular
generation,andusesarewardbasedonthelatentsimilarityofrepresentationsfromamulti-modal
contrastivelearningmodel. Tothebestofourknowledge,thisisthefirstpublishedattemptatthe
challengingtaskofguidingthegenerativemolecularmodelwiththeexpectedimagemorphology
outcome. Weexperimentallydemonstratetheusefulnessoftheproposedapproachforgenerating
diversedrugcandidates,whichwasshowntoincreasethelikelihoodofproducingmoleculeswith
similarbiologicalactivitywhencomparedtorandomscreening.
Futuredirectionsincludeadditionalevaluationofthegeneratedmolecules,inparticularlabexper-
iments. This could also support an active learning process, with the aim of improving the joint
representationthroughtheacquisitionofnewdata. Potentialextensionstothemodelincludemaking
theapproachconditionalontheprovidedmorphologytarget,andfurtherconstrainingtheoptimization
withrespecttomultiplepropertiesofinterest.
AcknowledgmentsandDisclosureofFunding
TheresearchwassupportedbyfundingfromCQDMFondsd’AccélérationdesCollaborationsen
Santé(FACS)/AcuitéQuébecandGenentech.Z.L.,E.H.,T.B.,andG.S.areemployeesofGenentech,
Inc.,andshareholdersofF.Hoffmann-LaRocheLtd.
References
[1] Josep Arús-Pous, Atanas Patronov, Esben Jannik Bjerrum, Christian Tyrchan, Jean-Louis
Reymond, Hongming Chen, and Ola Engkvist. SMILES-based deep generative scaffold
decoratorforde-novodrugdesign. Journalofcheminformatics,12:1–18,2020.
[2] EmmanuelBengio,MokshJain,MaksymKorablyov,DoinaPrecup,andYoshuaBengio. Flow
networkbasedgenerativemodelsfornon-iterativediversecandidategeneration. Advancesin
NeuralInformationProcessingSystems,34:27381–27394,2021.
[3] YoshuaBengio,SalemLahlou,TristanDeleu,EdwardJHu,MoTiwari,andEmmanuelBengio.
GFlowNetfoundations. JournalofMachineLearningResearch,24(210):1–55,2023.
[4] CamilleBilodeau,WengongJin,TommiJaakkola,ReginaBarzilay,andKlavsFJensen. Gener-
ativemodelsformoleculardiscovery: Recentadvancesandchallenges. WileyInterdisciplinary
Reviews: ComputationalMolecularScience,12(5):e1608,2022.
[5] Mark-AnthonyBray,ShantanuSingh,HanHan,ChadwickTDavis,BlakeBorgeson,Cathy
Hartland,MariaKost-Alimova,SigrunMGustafsdottir,ChristopherCGibson,andAnneE
Carpenter. CellPainting,ahigh-contentimage-basedassayformorphologicalprofilingusing
multiplexedfluorescentdyes. Natureprotocols,11(9):1757–1774,2016.
[6] Mark-AnthonyBray,SigrunMGustafsdottir,MohammadHRohban,ShantanuSingh,Vebjorn
Ljosa,KatherineLSokolnicki,JoshuaABittker,NicoleEBodycombe,VladoDancˇík,ThomasP
Hasaka, et al. A dataset of images and morphological profiles of 30 000 small-molecule
treatmentsusingtheCellPaintingassay. Gigascience,6(12):giw014,2017.
[7] Srinivas Niranj Chandrasekaran, Hugo Ceulemans, Justin D Boyd, and Anne E Carpenter.
Image-basedprofilingfordrugdiscovery: dueforamachine-learningupgrade? NatureReviews
DrugDiscovery,20(2):145–159,2021.
[8] NathanielLeeDiamant,AlexMTseng,KangwayVChuang,TommasoBiancalani,andGabriele
Scalia. Improvinggraphgenerationbyrestrictinggraphbandwidth. InInternationalConference
onMachineLearning,pages7939–7959.PMLR,2023.
10[9] PiotrGain´ski,MichałKoziarski,KrzysztofMaziarz,MarwinSegler,JacekTabor,andMarek
S´mieja. RetroGFN: Diverse and feasible retrosynthesis using GFlowNets. arXiv preprint
arXiv:2406.18739,2024.
[10] ZhangyangGao,ChengTan,YijieZhang,XingranChen,LirongWu,andStanZLi. ProteinIn-
vBench: Benchmarkingproteininversefoldingondiversetasks,models,andmetrics. Advances
inNeuralInformationProcessingSystems,36,2024.
[11] George I Gavriilidis, Vasileios Vasileiou, Aspasia Orfanou, Naveed Ishaque, and Fotis Pso-
mopoulos. Amini-reviewonperturbationmodellingacrosssingle-cellomicmodalities. Com-
putationalandStructuralBiotechnologyJournal,2024.
[12] PouyaMGhari,AlexTseng,GökcenEraslan,RomainLopez,TommasoBiancalani,Gabriele
Scalia, and Ehsan Hajiramezanali. Generative flow networks assisted biological sequence
editing. InNeurIPS2023GenerativeAIandBiology(GenBio)Workshop,2023.
[13] WilliamJGodinez,EricJMa,AlexanderTChao,LuyingPei,PeterSkewes-Cox,StephenM
Canham,JeremyLJenkins,JosephMYoung,EricJMartin,andWArmandGuiguemde.Design
ofpotentantimalarialswithgenerativechemistry. NatureMachineIntelligence,4(2):180–186,
2022.
[14] TuomasHaarnoja,HaoranTang,PieterAbbeel,andSergeyLevine. Reinforcementlearning
with deep energy-based policies. In International conference on machine learning, pages
1352–1361.PMLR,2017.
[15] Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine. Soft actor-critic: Off-
policymaximumentropydeepreinforcementlearningwithastochasticactor. InInternational
conferenceonmachinelearning,pages1861–1870.PMLR,2018.
[16] LeonHetzel,SimonBoehm,NikiKilbertus,StephanGünnemann,FabianTheis,etal.Predicting
cellularresponsestonoveldrugperturbationsatasingle-cellresolution. AdvancesinNeural
InformationProcessingSystems,35:26711–26722,2022.
[17] YeHu,DagmarStumpfe,andJurgenBajorath. Recentadvancesinscaffoldhopping: miniper-
spective. Journalofmedicinalchemistry,60(4):1238–1246,2017.
[18] MokshJain,EmmanuelBengio,AlexHernandez-Garcia,JarridRector-Brooks,BonaventureFP
Dossou,ChanakyaAjitEkbote,JieFu,TianyuZhang,MichaelKilgour,DinghuaiZhang,etal.
BiologicalsequencedesignwithGFlowNets.InInternationalConferenceonMachineLearning,
pages9786–9801.PMLR,2022.
[19] WengongJin,ReginaBarzilay,andTommiJaakkola. Junctiontreevariationalautoencoderfor
moleculargraphgeneration.InInternationalconferenceonmachinelearning,pages2323–2332.
PMLR,2018.
[20] SeokhoKangandKyunghyunCho. Conditionalmoleculardesignwithdeepgenerativemodels.
Journalofchemicalinformationandmodeling,59(1):43–52,2018.
[21] Maksym Korablyov, Cheng-Hao Liu, Moksh Jain, Almer M van der Sloot, Eric Jolicoeur,
EdwardRuediger,AndreiCristianNica,EmmanuelBengio,KostiantynLapchevskyi,Daniel
St-Cyr,etal. Generativeactivelearningforthesearchofsmall-moleculeproteinbinders. arXiv
preprintarXiv:2405.01616,2024.
[22] Panagiotis-ChristosKotsias,JosepArús-Pous,HongmingChen,OlaEngkvist,ChristianTyr-
chan,andEsbenJannikBjerrum.Directsteeringofdenovomoleculargenerationwithdescriptor
conditionalrecurrentneuralnetworks. NatureMachineIntelligence,2(5):254–265,2020.
[23] MichałKoziarski,MohammedAbukalam,VedantShah,LouisVaillancourt,DorisAlexandra
Schuetz,MokshJain,AlmerMvanderSloot,MathieuBourgey,AnneMarinier,andYoshua
Bengio. TowardsDNA-encodedlibrarygenerationwithGFlowNets. InICLR2024Workshop
onGenerativeandExperimentalPerspectivesforBiomolecularDesign,2024.
11[24] Michał Koziarski, Andrei Rekesh, Dmytro Shevchuk, Almer van der Sloot, Piotr Gain´ski,
Yoshua Bengio, Cheng-Hao Liu, Mike Tyers, and Robert A Batey. RGFN: Synthesizable
moleculargenerationusingGFlowNets. arXivpreprintarXiv:2406.08506,2024.
[25] DanielKrentzel,SpencerLShorte,andChristopheZimmer. Deeplearninginimage-based
phenotypicdrugdiscovery. TrendsinCellBiology,33(7):538–554,2023.
[26] SeanLin,KenjiSchorpp,InaRothenaigner,andKamyarHadian. Image-basedhigh-content
screeningindrugdiscovery. Drugdiscoverytoday,25(8):1348–1361,2020.
[27] ChristopherALipinski,FrancoLombardo,BerylWDominy,andPaulJFeeney. Experimental
andcomputationalapproachestoestimatesolubilityandpermeabilityindrugdiscoveryand
developmentsettings. Advanceddrugdeliveryreviews,23(1-3):3–25,1997.
[28] HannesHLoeffler,JiazhenHe,AlessandroTibo,JonPaulJanet,AlexeyVoronov,LewisH
Mervin,andOlaEngkvist. Reinvent4: ModernAI–drivengenerativemoleculedesign. Journal
ofCheminformatics,16(1):20,2024.
[29] Mohammad Lotfollahi, F Alexander Wolf, and Fabian J Theis. scGen predicts single-cell
perturbationresponses. Naturemethods,16(8):715–721,2019.
[30] NikolayMalkin,MokshJain,EmmanuelBengio,ChenSun,andYoshuaBengio. Trajectory
balance:ImprovedcreditassignmentinGFlowNets.AdvancesinNeuralInformationProcessing
Systems,35:5955–5967,2022.
[31] Nikolay Malkin, Salem Lahlou, Tristan Deleu, Xu Ji, Edward Hu, Katie Everett, Dinghuai
Zhang, and Yoshua Bengio. GFlowNets and variational inference. arXiv preprint
arXiv:2210.00580,2022.
[32] ŁukaszMaziarka,AgnieszkaPocha,JanKaczmarczyk,KrzysztofRataj,TomaszDanel,and
MichałWarchoł. Mol-CycleGAN:agenerativemodelformolecularoptimization. Journalof
Cheminformatics,12(1):1–18,2020.
[33] ClaireMcQuin,AllenGoodman,VasiliyChernyshev,LeeKamentsky,BethACimini,KyleW
Karhohs,MinhDoan,LiyaDing,SusanneMRafelski,DerekThirstrup,etal. CellProfiler3.0:
Next-generationimageprocessingforbiology. PLoSbiology,16(7):e2005970,2018.
[34] JoshuaMeyers,BenedekFabian,andNathanBrown. Denovomoleculardesignandgenerative
models. DrugDiscoveryToday,26(11):2707–2715,2021.
[35] JohnGMoffat,FabienVincent,JonathanALee,JörgEder,andMarcoPrunotto. Opportunities
andchallengesinphenotypicdrugdiscovery: anindustryperspective. NaturereviewsDrug
discovery,16(8):531–543,2017.
[36] MichaelMoret,IrenePachonAngona,LeandroCotos,ShenYan,KennethAtz,CyrillBrun-
ner, MartinBaumgartner, FrancescaGrisoni, andGisbertSchneider. Leveragingmolecular
structure and bioactivity with chemical language models for de novo drug design. Nature
Communications,14(1):114,2023.
[37] NikitaMoshkov,TimBecker,KevinYang,PeterHorvath,VladoDancik,BridgetKWagner,
PaulAClemons,ShantanuSingh,AnneECarpenter,andJuanCCaicedo.Predictingcompound
activityfromphenotypicprofilesandchemicalstructures. NatureCommunications,14(1):1967,
2023.
[38] Cuong Q Nguyen, Dante Pertusi, and Kim M Branson. Molecule-morphology contrastive
pretrainingfortransferablemolecularrepresentation. ICML2023WorkshoponComputational
Biology,pages2023–05,2023.
[39] AndreiCristianNica,MokshJain,EmmanuelBengio,Cheng-HaoLiu,MaksymKorablyov,
MichaelMBronstein,andYoshuaBengio.EvaluatinggeneralizationinGFlowNetsformolecule
design. InICLR2022MachineLearningforDrugDiscovery,2022.
[40] Pedro O O Pinheiro, Joshua Rackers, Joseph Kleinhenz, Michael Maser, Omar Mahmood,
AndrewWatkins,StephenRa,VishnuSresht,andSaeedSaremi. 3dmoleculegenerationby
denoisingvoxelgrids. AdvancesinNeuralInformationProcessingSystems,36,2024.
12[41] AaronvandenOord,YazheLi,andOriolVinyals. Representationlearningwithcontrastive
predictivecoding. arXivpreprintarXiv:1807.03748,2018.
[42] AlessandroPalma,FabianJTheis,andMohammadLotfollahi. Predictingcellmorphological
responsestoperturbationsusinggenerativemodeling. bioRxiv,pages2023–07,2023.
[43] AryanPedawi,PawelGniewek,ChaoyiChang,BrandonAnderson,andHenryvandenBedem.
Anefficientgraphgenerativemodelfornavigatingultra-largecombinatorialsynthesislibraries.
AdvancesinNeuralInformationProcessingSystems,35:8731–8745,2022.
[44] ZoePiran,NivCohen,YedidHoshen,andMorNitzan. Disentanglementofsingle-celldata
withbiolord. NatureBiotechnology,pages1–6,2024.
[45] PetraPoklukar,MiguelVasco,HangYin,FranciscoSMelo,AnaPaiva,andDanicaKragic.
Geometric multimodal contrastive representation learning. In International Conference on
MachineLearning,pages17782–17800.PMLR,2022.
[46] AlecRadford,JongWookKim,ChrisHallacy,AdityaRamesh,GabrielGoh,SandhiniAgarwal,
GirishSastry,AmandaAskell,PamelaMishkin,JackClark,etal. Learningtransferablevisual
modelsfromnaturallanguagesupervision. InInternationalconferenceonmachinelearning,
pages8748–8763.PMLR,2021.
[47] MohammadHRohban,AshleyMFuller,CerylTan,JonathanTGoldstein,DeepsingSyangtan,
AmosGutnick,AnnDeVine,MadhuraPNijsure,MeganRigby,JoshuaRSacher,etal. Virtual
screeningforsmall-moleculepathwayregulatorsbyimage-profilematching. Cellsystems,13
(9):724–736,2022.
[48] Julien Roy, Pierre-Luc Bacon, Christopher Pal, and Emmanuel Bengio. Goal-conditioned
GFlowNetsforcontrollablemulti-objectivemoleculardesign. arXivpreprintarXiv:2306.04620,
2023.
[49] NicholasTRuncieandAntoniaSJSMey. SILVR:Guideddiffusionformoleculegeneration.
JournalofChemicalInformationandModeling,63(19):5996–6005,2023.
[50] Ana Sanchez-Fernandez, Elisabeth Rumetshofer, Sepp Hochreiter, and Günter Klambauer.
Contrastivelearningofimage-andstructure-basedrepresentationsindrugdiscovery. ICLR2022
MachineLearningforDrugDiscovery,2022.
[51] Tony Shen, Mohit Pandey, and Martin Ester. TacoGFN: Target conditioned GFlowNet for
structure-baseddrugdesign. arXivpreprintarXiv:2310.03223,2023.
[52] ZhenqiaoSongandLeiLi.Importanceweightedexpectation-maximizationforproteinsequence
design. InInternationalConferenceonMachineLearning,pages32349–32364.PMLR,2023.
[53] PetarVelicˇkovic´,GuillemCucurull,ArantxaCasanova,AdrianaRomero,PietroLio,andYoshua
Bengio. Graphattentionnetworks. arXivpreprintarXiv:1710.10903,2017.
[54] NikhilMuraliVemgal,ElaineLau,andDoinaPrecup. Anempiricalstudyoftheeffectivenessof
usingareplaybufferonmodediscoveryinGFlowNets. InICML2023WorkshoponStructured
Probabilistic Inference & Generative Modeling, 2023. URL https://openreview.net/
forum?id=pBk1cRPKBv.
[55] FabienVincent,ArsenioNueda,JonathanLee,MonicaSchenone,MarcoPrunotto,andMark
Mercola. Phenotypic drug discovery: recent successes, lessons learned and new directions.
NatureReviewsDrugDiscovery,21(12):899–914,2022.
[56] AlexandraVolokhova,MichałKoziarski,AlexHernández-García,Cheng-HaoLiu,Santiago
Miret, Pablo Lemos, Luca Thiede, Zichao Yan, Alán Aspuru-Guzik, and Yoshua Bengio.
TowardsequilibriummolecularconformationgenerationwithGFlowNets. DigitalDiscovery,
2024.
[57] Chenyu Wang, Sharut Gupta, Caroline Uhler, and Tommi S Jaakkola. Removing biases
frommolecularrepresentationsviainformationmaximization. InTheTwelfthInternational
ConferenceonLearningRepresentations,2023.
13[58] ShuangjiaZheng,JiahuaRao,JixianZhang,EthanCohen,ChengtaoLi,andYuedongYang.
Cross-modalgraphcontrastivelearningwithcellularimages. bioRxiv,pages2022–06,2022.
A Additionalexperimentsandplots
A.1 Targetselection
Toevaluatethegenerativemodels,weselectedatotalof17targetsfromtheCellPaintingdataset,
amongwhich8wereusedforthebiologicalassayactivityexperiments(Figure9). Alltargetswere
verifiedtobedecomposableintothemolecularfragmentsetusedforgenerativemodellingandwere
chosentorepresentadiversesetofactivebiologicalassaysfortheoracle-basedevaluation.
PuAmcati vined aesxs:a 2y2 I8n8d i(c5e sn:o 2d0es) AcPtuivmea a isnsdaeyx I:n 4d6ic4e6s :( 71 4n,o 1d7e,s 3)3 PAucmtivae i nadsseaxy: 8In5d0i5c e(s5: n1o4d, e1s7) PumAcat iivned eaxs:s a8y6 3In6d (i4ce nso: d2es) CluPsutmera 1 i n(d4e9x2:7 8 m94o9ls ,( 66 1n oudseasb)le) ClPuusmtear 4in1d (e2x0: 49 4m7o6l s(,7 1 n uosdaebsl)e) CluPsutmera 8 i n(d2e1x1:6 9 m30o0ls ,( 71 0n oudseasb)le) CluPsutmera 1 i6n d(e1x2:6 934 m45o l(s6, 4n oudseasb)le) CPluusmtear i2n0d e(x3:5 112 m07o1ls ,( 51 nuosdaebsle))
PAucmtiav ein adsesxa:y 1 I0n0d7ic5e s(4: 3n2o,d 3e4s) PumAcat iivned eaxs:s a1y0 8In1d6i c(e7s n: o3d2es) PumAac tiinvdee axs: s1a2y6 I6n2d i(c7e sn:o 2des) PumAac tiinvdee axs: s1a5y5 I7n5d i(c5e sn:o 2des) ClPuusmtear 2in4d (e7x8: 04 3m3o1l s(,7 7 n uosdaebsl)e) CluPsutmera 1 i8n d(e1x2:1 832 m06o l(s7, 8n oudseasb)le) CluPsutmera 5 i n(d2e2x1:0 3 m38o l(s4, 5n oudseasb)le) CluPsutmera 9 i n(d1e6x2:9 9 m27o7ls ,( 51 2n oudseasb)le)
Figure9: Setoftargetsusedforourexperiments,8ofwhicharebiologicallyactivebassedonthe
groundtruthassayinformation,andwereusedfororacleevaluation(leftgroup).
A.2 GMCmodelselection
ForGMCmodelselection,wetriedearlystoppingonboththemultimodalcontrastivelossin3and
thecross-modalitycorrelationmetricpresentedinSection3.3. Whiletherewasnotasignificant
differenceinGFlowNetperformancebetweenthesetwovariants,wefoundthatearlystoppingonthe
correlationmetricreducedthevarianceonthecosinesimilaritybetweenmolecularembeddingsand
embeddingsoftheirassociatedmorphologicalorjointreadouts. Inotherwords,thecross-modality
agreementlearntbythismodelhadlesserspread.
Cosine similarity between Structure and Morphology Cosine similarity between Structure and Joint
latents of Test Samples latents of Test Samples
1.0 1.0
0.8
0.8
0.6
0.4 0.6
0.2
0.4
0.0
0.2
0.2
Early Stopping Val Metric
0.4 0.0 M CrM osC s -lo ms os dal correlation
Figure10: Cosinesimilaritybetweena)structureandmorphologyembeddings(left)andb)structure
andjointembeddings(right)producedbyGMCmodelontestsplit.
A.3 AdditionalUMAPplotspertarget
WeproduceUMAPplotsofthetop1000highestrewardmoleculesformorphology-onlyandjoint
morphologyandstructure-guidedgeneration. WethencolorthesesamplesbyrewardandTanimoto
similaritytothetarget,suchthathighervalues(whicharemoredesirable)havehigheropacity. We
useMorganfingerprintswitharadiusof3andadimensionalityof2048. UMAPrepresentations
arecomputed with30neighbors, minimumdistance0.1, and Jaccardmetric. Below, weinclude
theresultsforalltargetsinAppendixA.1. Thefirsttwocolumnsconsistofthesamplesobtained
14
ytiralimiS
enisoCformorphology-onlygeneration,whilethelasttwocolumnsconsistofsamplesobtainedforjoint
morphologyandstructure-guidedgeneration.
UMAP of Top 1000 Highest Reward Samples UMAP of Top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colored by UMAP of Top 1000 Highest Reward Samples UMAP of Top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colored by
11 46802
6 4 2 UMA0P 1 2
R G S S T 4aQAN F rCN LD get 000000 ...... 888899 246802 11 46802
6 4 2 UMAP0 1 2
4R G S S TaQAN F rCN LD get 0000000 ....... 0011223 0505050 01234
1
2 4 UMA6P 1 8
1R S S G T 0aQ AN F rC NLD get 0000000 ....... 8899999 6802468 01234
1
2R S S G TaQ AN F rC NLD get
4 UMA6P 1 8 10
000000000 ......... 001122334 050505050
UMAP of Top 1000 Highest Reward Samples UMAP of Top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colored by UMAP of Top 1000 Highest Reward Samples UMAP of Top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colored by
42 00 .. 89 50 42 00 .. 12 50 1 890 R S S G TaQ AN F rC NLD get 000 ... 999 025 050 1 890 R S S G TaQ AN F rC NLD get 000 ... 233 505
186
0 2 4 UM6AP 1 8 R G S S TaQAN F r 1CN LD g 0et
000 ... 778 050 186
0 2 4 UM6AP 1 8 R G S S TaQAN F r 1CN LD g 0et
000 ... 001 050 4567
16 18 UMA2P0 1 22 24
0000 .... 8888 0257 0505 4567
16 18 UMA2P0 1 22 24
0000 .... 0112 5050
UMAP of Top 1000 Highest Reward Samples UMAP of Top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colored by UMAP of Top 1000 Highest Reward Samples UMAP of Top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colored by
024 R G S S TaQAN F rCN LD get 000 ... 889 050 024 R G S S TaQAN F rCN LD get 0000 .... 1223 5050 45678 R S S G TaQ AN F rC NLD get 000 ... 899 505 45678 R S S G TaQ AN F rC NLD get 0000 .... 3456
2 0.75 2 0.10 3 0.80 3 0.2
4
6 8 10UMA1P2 1 14 16 18
0.70 4
6 8 10UMA1P2 1 14 16 18
00 .. 00 05 12
2 4 6UMAP 18 10
0.75 12
2 4 6UMAP 1 8 10
00 .. 01
1 4680 UMAP of Top 1000 Highest Reward Samp R G S S Tle aQAN F rs CN LD get 00000 ..... 99999 23344 50505 1 4680 UMAP of Top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Color R G S S Te aQANd F rCN L D gb ey t 0000 .... 1223 5050 246 UM R S S G TA aQ AN F rP C NLD g eo tf Top 1000 Highest Reward Samples 0000 .... 8999 8024 246 UMAP R S S G T aQ ANo F rC Nf LD g eTo tp 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colored by 00000 ..... 22334 05050
02 00 .. 99 12 50 02 0.10 0 00 .. 88 46 0 00 .. 11 05
2
0 2 4UMAP 16 8 10
00 .. 99 01 50 2
0 2 4UMAP 16 8 10
0.05 2
0 2 4 UMA6P 1 8 10 12
0.82 2
0 2 4 UMA6P 1 8 10 12
00 .. 00 05
UMAP of Top 1000 Highest Reward Samples UMAP of Top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colored by UMAP of Top 1000 Highest Reward Samples UMAP of Top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colored by
345 000 ... 999 234 345 00 .. 22 05 46 R G S S TaQAN F rCN LD get 00 .. 99 46 46 R G S S TaQAN F rCN LD get 000 ... 223 050
012
1 7R S S G TaQ AN F rC NLD ge 8t 9 U1M0AP 111 12 13 14
00000 ..... 88899 78901 012
1 7R S S G TaQ AN F rC NLD get 8 9 U10MAP 111 12 13 14
0000 .... 0011 0505 02
2 10 12 14 UMA1P6 1 18 20
000 ... 899 802 02
2 10 12 14 UMA1P6 1 18 20
0000 .... 0011 0505
UMAP of Top 1000 Highest Reward Samples UMAP of Top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colored by UMAP of Top 1000 Highest Reward Samples UMAP of Top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colored by
0123456
12 13 14 1U5MAP1 16 17
18R S S G TaQ AN F 1rC NLD g 9et 00000000 ........ 88888999 02468024 0123456
12 13 14 15UMAP1 16 17 18
R S S G TaQ AN 1F rC 9NLD get 000000 ...... 001122 050505 11198765
210
6 8 10UMAP 112
14R G S S TaQAN F rCN LD get
00000000 ........ 88889999 02570257 05050505 11198765
210
6 8 10UMAP 112
14R G S S TaQAN F rCN LD get
000000 ...... 001122 050505
012345 UMAP
2
of Top 10 400
U
H Mig Ah Pe 1s 6t Reward S 8amp
R S S G
Tle
aQ AN F
rs
C NLD get
10
00000000 ........ 88888999 02468024 012345 UMAP of
2
Top 1Ta0n0i0m Ho 4itgoh Se Uism Mt i ARla Per wi 1tay
6
rtdo STaamrgpeltes
8
Colore
R S S G
Td
aQ AN F r C
NLDb gey
1t
0
00000 ..... 01122 50505 0123
4321
2
UMAP
4
of Top 100 60
U
H Mig Ah Pe 1st
8
Reward S 1a 0mp
R G S S
Tle
aQAN F
rs
CN LD get
12
000000000 ......... 888889999 024680246 0123
4321
2UMAP R G S
S Ta
QAN Fo rCN LD gf eT 4o tp 1Ta0n0i0m Hoitg 6oh Se Uism Mt i ARla Per wi 1tay
8
rtdo STaamrgpeltes
1
C 0olored by
12
00000 ..... 12345
UMAP of Top 1000 Highest Reward Samples UMAP of Top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colored by UMAP of Top 1000 Highest Reward Samples UMAP of Top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colored by
1 80 00 .. 55 05 1 80 000 ... 122 505 0 42 R G S S TaQAN F rCN LD get 00 .. 78 0 42 R G S S TaQAN F rCN LD get 00 .. 34
246
8 10 UM1A2P 1 14
1R S S G Ta 6Q AN F rC NLD get 000 ... 344 505 246
8 10 UM1A2P 1 14
1R S S G T 6aQ AN F rC NLD get 000 ... 001 050 86
10 12 14UMAP 116 18 20
00 .. 56 86
10 12 14UMAP 116 18 20
000 ... 012
15
8822#
6464#
5058#
6368#
9498#
0039#
5449#
6749#
2 PAMU
2 PAMU
2 PAMU
2 PAMU
2 PAMU
2 PAMU
2 PAMU
2 PAMU
draweR
draweR
draweR
draweR
draweR
draweR
draweR
draweR
2 PAMU
2 PAMU
2 PAMU
2 PAMU
2 PAMU
2 PAMU
2 PAMU
2 PAMU
ytiralimiS
otominaT
ytiralimiS
otominaT
ytiralimiS
otominaT
ytiralimiS
otominaT
ytiralimiS
otominaT
ytiralimiS
otominaT
ytiralimiS
otominaT
ytiralimiS
otominaT
2 PAMU
2 PAMU
2 PAMU
2 PAMU
2 PAMU
2 PAMU
2 PAMU
2 PAMU
draweR
draweR
draweR
draweR
draweR
draweR
draweR
draweR
2 PAMU
2 PAMU
2 PAMU
2 PAMU
2 PAMU
2 PAMU
2 PAMU
2 PAMU
ytiralimiS
otominaT
ytiralimiS
otominaT
ytiralimiS
otominaT
ytiralimiS
otominaT
ytiralimiS
otominaT
ytiralimiS
otominaT
ytiralimiS
otominaT
ytiralimiS
otominaT11 246802 UM R G S S TA aQAN F rP CN LD g eo tf Top 1000 Highest Reward Samples 00000 ..... 56677 50505 11 246802 UMAP of Top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colore R G S S Tad QAN F r CN LD gb ey t 0000 .... 1234 12345678 UMAP of Top 1000 Highest Reward Samp R S S G Tle aQ AN F rs C NLD get 00000 ..... 77889 05050 12345678 UMAP of Top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colore R S S G Td aQ AN F rCb NLD gy et 00001 ..... 24680
0 2 4 6 UM8AP 110 12 14 0.50 0 2 4 6 UM8AP 110 12 14 0.0 0 2 0 UM2AP 1 4 6 0.65 0 2 0 UM2AP 1 4 6 0.0
UMAP of Top 1000 Highest Reward Samples UMAP of Top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colored by UMAP of Top 1000 Highest Reward Samples UMAP of Top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colored by
012
4321
8R G S S TaQAN F rCN LD g 1e 0t
12UM1A4P 1 16 18 20
000000 ...... 778899 050505 012
4321
8R G S S TaQAN F rCN LD ge 1t
0 12 UM1A4P 1 16 18 20
00000 ..... 00112 05050 02
42
6
R S S G TaQ AN F rC NLD get
8 U1M0AP 1 12 14
000000000 ......... 788889999 702570257 505050505 02
42 6R S S G TaQ AN F rC NLD get
8 U10MAP 1 12 14
00000000 ........ 00112233 05050505
UMAP of Top 1000 Highest Reward Samples UMAP of Top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colored by UMAP of Top 1000 Highest Reward Samples UMAP of Top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colored by
0246
2
2R S S G TaQ AN F rC NLD get
4 U6MAP 1 8 10
00000 ..... 77889 05050 0246
2
2 4 U6MAP 1 8
10R S S G TaQ AN F rC NLD get 00000000 ........ 00112233 05050505 0246
2 6R G S S TaQAN F rCN LD get
8 UMA1P0 1 12 14
000000 ...... 456789 0246
2 6R G S S TaQAN F rCN LD get
8 UMA1P0 1 12 14
00000 ..... 01234
345
UM
R G S S
TA
aQAN F
rP
CN LD g
eo tf Top 1000 Highest Reward Samples
0000 .... 8999 8024 345
UMA
R G S S
TP
aQAN
Fo
rCN LD
gf
e
T top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colored by
000 ... 122 505 0 42
UM
R S S G
TA
aQ AN F
rP
C NLD g
eo tf Top 1000 Highest Reward Samples
000 ... 999 025 050 0
42UMAP of Top 1Ta0n0i0m Hoitgoh Seismt iRlaerwitay rtdo STaamrgpeltes Colored by
0000 .... 2334 5050
012
18 20 UM22AP 1 24 26
0000 .... 8888 0246 012
18 20 UM22AP 1 24 26
000 ... 001 050 186
0 1 2 3 4UMAP5 1 6 7 8
0000 .... 8888 0257 0505 186
0 1 2 3 4UMAP5 1 6 7
R
S
S
G
TaQ
AN
F
r
8C
NLD
get
00000 ..... 00112 05050
012345
21
UM
R G S S
TA
aQAN F
1rP
CN LD g
2
eo tf Top 10 10 40
U
H Mig Ah Pe 1s 1t
6
Reward S 1a 8mples
20
000000 ...... 888999 468024 012345
21
UMAP
R G S S T
aQANo
F
rCNf
LD g
1
eT 2o tp 1Ta0n0i0m Ho 1it 4goh Se Uism Mt i ARla Per wi 1t 1ay
6
rtdo STaamrgpeltes
1
8Colored by
20
0000000 ....... 0011223 0505050 123456789 4UMAP of To 2p 1000
U
H M0ig Ah Pe 1st Rew 2ard Samp R S S G Tle a 4Q AN F rs C NLD get 000000 ...... 889999 680246 123456789 UM 4AP of Top 1Ta 20n0i0m Hoitgoh Se Uism Mt
0
i ARla Per wi 1tay rtdo STaamr 2gpeltes Colore R S S G T 4d aQ AN F r C NLDb gey t 0000000 ....... 0011223 0505050
A.4 Highrewardsamples
InFigure11weplotasetofrandomlyselectedhighrewardsamplesfromGFlowNetstrainedon
targetsina)morphology-onlysetting(left)andb)jointmorphologyandstructure-guidedsetting
(right).
A.5 GMCcross-modalityalignment
Weplotthepairwisecosinesimilaritybetweenembeddingsofalltestsetsamplesforeachmodality
pairing of the GMC representation space. A high correlation indicates that the model learns to
correctlyalignthedifferentinputdomains,suchthatembeddingsofassociatedmodalitiesarealigned
closerthandistinctones. Asexpected,GMCachievesahighercorrelationwhenthejointmodalityis
includedinoneoftheaxessincethejointlatentspaceintegratessignalsfromboththestructureand
morphologyfeatures,whichisredundantwiththeotheraxis.
B Experimentaldetails
Inthissection,wepresenttheexperimentdetailsfortheresultsobtainedinthemainpaper.
B.1 GMCmodeltraining
WefollowthespecificationintheoriginalGMCpaper[45]andselectasinglemodelcheckpointfor
allourexperimentsbyearlystoppingontheGMCvalidationloss. WeemployaGraphConvolutional
Network(GCN)forthestructureencoderandasimpleMultilayerPerceptron(MLP)forthecell
morphologyinputs. MLPsarealsousedfortheprojectorarchitectureforallmodalities. SeeTable2
forafullbreakdownofthehyper-parametersweused.
16
57001#
61801#
17021#
26621#
57551#
2 PAMU
2 PAMU
2 PAMU
2 PAMU
2 PAMU
draweR
draweR
draweR
draweR
draweR
2 PAMU
2 PAMU
2 PAMU
2 PAMU
2 PAMU
ytiralimiS
otominaT
ytiralimiS
otominaT
ytiralimiS
otominaT
ytiralimiS
otominaT
ytiralimiS
otominaT
2 PAMU
2 PAMU
2 PAMU
2 PAMU
2 PAMU
draweR
draweR
draweR
draweR
draweR
2 PAMU
2 PAMU
2 PAMU
2 PAMU
2 PAMU
ytiralimiS
otominaT
ytiralimiS
otominaT
ytiralimiS
otominaT
ytiralimiS
otominaT
ytiralimiS
otominaTHigh Reward Samples for Some Targets in Morph Training High Reward Samples for Some Targets in Joint Training
Target 8505 Reward: 0.88 Reward: 0.86 Reward: 0.85 Reward: 0.84 Target 2288 Reward: 0.89 Reward: 0.89 Reward: 0.88 Reward: 0.87
Target 338 Reward: 0.94 Reward: 0.92 Reward: 0.91 Reward: 0.90 Target 10816 Reward: 0.87 Reward: 0.85 Reward: 0.85 Reward: 0.85
Target 10075 Reward: 0.76 Reward: 0.75 Reward: 0.74 Reward: 0.73 Target 15575 Reward: 0.93 Reward: 0.93 Reward: 0.93 Reward: 0.92
Target 8206 Reward: 0.95 Reward: 0.94 Reward: 0.94 Reward: 0.94 Target 4331 Reward: 0.70 Reward: 0.69 Reward: 0.69 Reward: 0.69
Target 9277 Reward: 0.95 Reward: 0.95 Reward: 0.95 Reward: 0.95 Target 8206 Reward: 0.93 Reward: 0.93 Reward: 0.93 Reward: 0.92
Figure11: HighrewardsamplesfromGFlowNetstrainedagainstmorphology-onlytargets(left)and
jointmorphologyandstructureguidedtargets(right).
Latent Struct vs Morph Cosine Similarity Latent Struct vs Joint Cosine Similarity Latent Morph vs Joint Cosine Similarity
1.0 r=0.75 1.0 r=0.94 1.00 r=0.88
0.8 0.8 0.75
0.6 0.6
0.50
0.4 0.4
0.25
0.2 0.2
0.0 0.0 0.00
0.2 0.2 0.25
0.4 0.4 0.50
0.6 0.6
0.50 0.25 0.00 0.25 0.50 0.75 1.00 0.50 0.25 0.00 0.25 0.50 0.75 1.00 0.50 0.25 0.00 0.25 0.50 0.75 1.00
Cosine Similarity (struct-struct) Cosine Similarity (struct-struct) Cosine Similarity (morph-morph)
Figure12: Pairwisecosinesimilarityofrepresentationsbetweenstructureandmorphologydomains
(left),structureandjointdomains(center),andmorphologyandjointdomains(right). Foreachpair
ofsamplesinthetestset,weplotthecosinesimilaritybetweentheirembeddingsinafirstmodality
(x-axis)andasecondmodality(y-axis).
Parameter Value
Batchsizeβ 128
Numberofepochs 200
Optimizer Adam
Learningrate 1×2e−6
Non-Linearity ReLU
Temperatureτ 0.4
IntermediateDim. Sized 1024
LatentDim. Sizes 1024
Table2: HyperparametersoftheGeometricMultimodalContrastiveproxymodel.
17
)hprom-hprom(
ytiralimiS
enisoC
)tnioj-tnioj(
ytiralimiS
enisoC
)tnioj-tnioj(
ytiralimiS
enisoCParameter Value
Batchsize 64
Numberofsteps 10,000
Optimizer Adam
NumberofLayers 4
HiddenDim. Size 128
NumberofHeads 2
PositionalEmbeddings Rotary
Rewardscalingβ inRβ 64
Learningrate 1×10−4
Z Learningrate 1×10−3
Table3: HyperparametersoftheGraphAttentionTransformerusedacrossallmodelsinfragment-
basedmoleculegeneration.
B.2 Fragment-basedmoleculegeneration
Inthissection,weprovidedetailsonthemoleculegenerationexperimentsandthehyperparameters
we used for the methods presented in the paper. In our experimental setup, we follow the same
environmentspecificationsandimplementationsprovidedin[31]withtheexceptionofadifferent
proxymodel(GMC)andrewardfunction. ThearchitectureoftheGFlowNet,SACandSQLmodels
isbasedonagraphattentiontransformer[53]whosespecificationisdetailedinTable3. ForSAC,
weuseafixedαvalueof0.2chosenfrom{0.1,0.2,0.5}. ForSQL,weuseafixedαvalueof0.1.
Allmethodsusediscountfactorγ valueof1.0.
B.3 Oracletraining
WetrainedanMLPusingmolecularfingerprintstopredictactivebiologicalassays(inamulti-label
classification setting) for the 8 targets highlighted on the left of Figure 9. For the input, we use
Morganfingerprintswithradius3anddimensionality2048. TheMLPhastwo64dimensionalhidden
layers and uses ReLU activation. We trained the model with a learning rate of 1e−4 with Adam
optimizerfor200epochs. Modelselectionwasperformedbasedonaverageprecisionscoreonthe
validationset.
B.4 ComputeResources
All of our experiments were conducted using A100 and V100 GPUs. For the fragment-based
generationexperiment,weusedasingleworkeranditraninlessthan4hours. ForGMCmodel
training,therunstookalittlelessthan3hours. Fortheoracletraining,bothMLPstookaroundan
hourtocompletetraining.
18