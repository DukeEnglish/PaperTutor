Concept learning of parameterized quantum models from limited measurements
Beng Yee Gan,1,∗ Po-Wei Huang,1 Elies Gil-Fuster,2,3 and Patrick Rebentrost1,4,†
1Centre for Quantum Technologies, National University of Singapore, Singapore 117543
2Dahlem Center for Complex Quantum Systems,
Freie Universita¨t Berlin, 14195 Berlin, Germany
3Fraunhofer Heinrich Hertz Institute, 10587 Berlin, Germany
4Department of Computer Science, National University of Singapore, Singapore 117417
(Dated: August 12, 2024)
Classicallearningoftheexpectationvaluesofobservablesforquantumstatesisanaturalvariant
of learning quantum states or channels. While learning-theoretic frameworks establish the sample
complexity and the number of measurement shots per sample required for learning such statistical
quantities, the interplay between these two variables has not been adequately quantified before. In
thiswork,wetaketheprobabilisticnatureofquantummeasurementsintoaccountinclassicalmod-
elling and discuss these quantities under a single unified learning framework. We provide provable
guarantees for learning parameterized quantum models that also quantify the asymmetrical effects
and interplay of the two variables on the performance of learning algorithms. These results show
thatwhileincreasingthesamplesizeenhancesthelearningperformanceofclassicalmachines,even
withsingle-shotestimates,theimprovementsfromincreasingmeasurementsbecomeasymptotically
trivial beyond a constant factor. We further apply our framework and theoretical guarantees to
study the impact of measurement noise on the classical surrogation of parameterized quantum cir-
cuitmodels. Ourworkprovidesnewtoolstoanalysetheoperationalinfluenceoffinitemeasurement
noise in the classical learning of quantum systems.
I. INTRODUCTION Instatisticallearningtheory,suchaquantummodelis
described as a concept [13], a function that maps inputs,
say high-dimensional vectors, to deterministic outputs
Understanding how classical learners can learn quan-
expressed in the form of discrete class labels or contin-
tum systems sheds light on the potential and limitations
uous vectors. However, stemming from the probabilistic
of quantum information processing. For instance, access
nature of quantum measurements, there is no determin-
to quantum measurement results [1, 2] in some cases al-
isticmappingoftheinputdatatotheobservedoutcomes
lowstheefficientlearningofrepresentationsormodelsof
that can capture the behaviour of the quantum model.
the quantum system [3–11]. Examples of such quantum
Nonetheless, there is some structure to this uncertainty,
models include expectation values of quantum observ-
asquantummodelsrepresenttheconditionalexpectation
ables given a variational quantum circuit [12] or ground
oftheirunbiasedestimators. Anaturallearning-theoretic
statepropertiesofquantumsystems[9–11]. Asquantum
framework to capture such probabilistic models is the
measurementsonsuchsystemsaretypicallysubjectedto
probabilistic concepts [14], or p-concept learning frame-
statistical fluctuations, the observed outcomes may de-
work. The p-concept setting was first introduced in a
viate from the true underlying quantum model due to
quantum setup in Scott Aaronson’s seminal paper [15]
the measurement or shot noise. Thus, shot noise is an
and subsequently in Refs. [16–19]. These works identify
intrinsic aspect of learning quantum models.
shotnoiseasstructuralrandomness,allowingthecasting
Current works often consider shot noise as an error
of quantum models as p-concepts. Fat-shattering dimen-
term that needs to be mitigated and rely on its mini-
sion,acomplexitymeasurethatshowstheexpressiveness
mizationtoensurelearnability[8–10]. Inthesescenarios,
of a given set of p-concepts, is then used to quantify the
the effects of altering the number of training data input
difficulty of learning quantum states [15–17], measure-
N andthenumberofmeasurementshotsperdatainput
1 ments [18], and quantum circuits [19].
N are typically discussed separately, with N assumed
s s
to be sufficient enough as to not affect the analysis re-
In this work, we utilize this probabilistic framework
garding N and the learning performance. In practice,
1 to investigate the provable concept learning of parame-
however, conducting an abundant amount of measure-
terized quantum models. Contrasting with prior works,
ments per data point may be too costly. It is therefore
our work utilizes kernel theory and the respective learn-
important to understand how the interplay between the
ability results to investigate the impact of shot noise in
quantities N and N will affect the learnability perfor-
1 s classical learning of quantum models. In particular, this
mance of learning algorithms.
unifiedlearningframeworkenablesthestudyoftheinter-
playbetweenN andN withoutisolatingthediscussion
1 s
of sample complexity from shot noise. That is, it allows
us to tackle the following problem: given a well-defined
∗ gan.bengyee@u.nus.edu learning setting and quantum model, can we obtain prov-
† patrick@comp.nus.edu.sg ableguaranteesoflearningthatexemplifytherelationship
4202
guA
9
]hp-tnauq[
1v61150.8042:viXra2
between N and N ? functions with specific properties forms a concept class
1 s
Toanswerthisquestion,weextendthekernelmethod- C ⊆ YX. In the deterministic learning setting, a con-
based analysis of Ref. [20] to showcase asymmetrical ef- cept maps data points x∈X to associated labels y ∈Y,
fects of N and N on concept learning. Our analyti- i.e., a data sample is given by (x,y) where x is sam-
1 s
cal results show that increasing N enhances the learn- pled from p(x) and y = c(x). Similarly, a hypothesis is
1
ing performance of classical models, even when observed defined as h : X → Y, and a subset of these functions
outcomesareestimatedwithlimitedmeasurementshots, forms a hypothesis class H ⊆ YX. Then, given a col-
e.g., in the single-shot limit [21] when N = 1. On the lection of samples S = (x ,c(x ))N1 where x ∼ p(x), a
s i i i=1 i
otherhand,forafixedtrainingdatasizeN ,wefindthat learning algorithm selects a hypothesis h ∈ H such that
1
improvements in learning performances from increasing the difference between h(x) and the corresponding label
the number of measurement shots N become asymptot- y =c(x) is low under some performance measure.
s
ically trivial beyond a constant factor. We also exhibit a The probabilistic concept (p-concept) and the p-
scenarioforwhichthereexistsanoptimalpairofN and concept class are defined similarly.
1
N that will maximize the performance of the classical
s Definition 1 (p-concept). Let P (Y) be a conditional
models. x
probability distribution over the label space Y, with prob-
Under the lens of the bias-variance-noise decomposi-
ability density specified as p(y|x) for each input x ∈ X.
tion of classical learning theory, we further illustrate the
We call p-concept a function c : X → Y defined as the
impact of shot noise on the bias and variance of clas-
conditional expectation value of y given x arising from p:
sical models. Specifically, high shot noise can lead to
high variance in classical models, which is consistent
c:X →Y (1)
with observations in the literature [22, 23]. In this re-
x(cid:55)→c(x)=E [y]. (2)
gard, we demonstrate that such sensitivity to shot noise y∼p(y|x)
can be suppressed by incorporating an L-Lipschitz non-
Definition 2 (p-concept class). Let P ⊆ {P (Y)} be a
x
decreasing function, known as a link function [20], into
subset of all conditional probability distributions over the
the classical models for learning parameterized quantum
labelspace. ForeachdistributionP (Y)∈P,whichspec-
x
models. This suppression of variance enables us to sep-
ifies the conditional distribution p(y|x) of y given x, the
arate and isolate the effects of the size of the training
corresponding p-concept is defined as per Def. 1. Then,
dataset and the number of measurement shots on learn-
a p-concept class is the class of functions C that corre-
abilityerrorbounds. Finally, weapplyourframeworkto
sponds to all functions arising from the set P of proba-
numerically study the impact of shot noise on the classi-
bility distributions:
calsurrogationofparameterizedquantumcircuitmodels.
The numerical results are consistent with our theoretical C :={c:x(cid:55)→E [y]|P (Y)∈P}. (3)
y∼p(y|x) x
predictions. Our work provides a new perspective to in-
vestigate the role of measurements in learning quantum Noteworthy is that defining this concept class explic-
models. itly from a set of conditional distributions does not im-
pose any limitations on what these functions can be.
For any function f ∈ YX, one can always interpret it
II. PRELIMINARIES as a p-concept in an infinite number of ways. For in-
stance, one could consider simply the probability dis-
tribution that always returns the value of the function
In this section, we will first introduce two frameworks
p(y|x)=δ(y−f(x))1. Alternatively, one could consider
instatisticallearningtheorythatweusetoprovidelearn-
any random function ξ(x) with zero mean E[ξ(x)] = 0,
ingguarantees,thedeterministicconceptlearningframe-
andthenoneobtainsap-conceptastheexpectationvalue
work and the probabilistic concept learning framework.
oftherandomfunctionf(x)+ξ(x). Indeed,therearein-
Then,wewillprovideabriefintroductiontothetypesof
finitelymanydifferentprobabilitydistributionsthatgive
quantum models considered in this work.
rise to the same p-concept class2. Nonetheless, some of
these distributions can be generated via physically real-
izable processes, which are the focus of this work.
A. Probabilistic concept learning
Let X =Rm and Y ⊂R be the data and label spaces,
respectively. Further, we assume that data points x are 1 In this case, the p-concepts reduce to the “regular” concepts
independently and identically distributed (i.i.d.) accord- definedinRef.[13].
ingtosomeunknownbutfixeddistributionp(x)andthe 2 The original definition of p-concepts given by Kearns and
label space Y is a compact and convex subspace of R. Schapire[14]issimplyageneralizationofconceptsinPAClearn-
ing [13] in terms of the function range, while the actual proba-
In the learning-theoretic setting, there are two types
bilistic component is defined with the learnability of p-concept
of functions of interest: concept and hypothesis. A con- classes. Herewetakeaslightlydifferentapproachanddefinep-
cept c is a function that maps the data space to the la- conceptssuchthattheelementofprobabilityiscapturedwithin
bel space, i.e., c : X → Y. A particular set of these thedefinitionofp-conceptsitself.3
Contrasting with the deterministic learning setting, in Name Notation Definition
thep-conceptlearningsetting, thesamples(x,y)areob-
Explicit loss ℓ (h) (h(x)−c(x))2
tainedbysamplingthejointdistributionD =p(x)p(y|x) expl
Implicit loss ℓ (h) (h(x)−y¯)2
with c(x) = E [y]. In this work, we further con- impl
s T raid h ne a dr t oia ms,fl g le aivx bei eb n ll se ay f∼ ds re ap ot( t mty ai| nx p p) g o (i yt nh |t xa x )t ,,a w el .l e go .w c ,as n
y
1f oo ,br .t .a a .c i ,nc ye Nms ss ult ∼to ip pp le (( yy i. || i xx .d )) ,. . EE I mmx ppp ill rii cc icii tt alrr ii rss ikk
sk
RR i Re (cid:98)mx (p p hl l( ( )h h) ) E E N( 1x ( 1, xy¯ (cid:80),) y¯∼ )
N
i∼D¯ =1D[ ¯ 1( ([h ( hh( (x ( xx) i− ) )− −c( yx y¯ ¯) i) )2) 2]2]
and use these labels to estimate the empirical mean of
TABLEI.Glossaryoferrortermsusedinourpaper. Explicit
the random labels y¯ = 1 (cid:80)Ns y . Such sampling
Ns Ns i=1 i (implicit)lossandriskareassociatedwiththep-conceptc(x)
thenaveragingprocedurecanbedirectlymodelledasthe (noisy labels y¯), while the empirical risk is the empirical ver-
sampling process (x,y¯ Ns) ∼ D¯ Ns = p(x)p(y¯ Ns|x) where sion of the implicit risk. We have omitted the subscript in
y¯ is distributed with variance σ2 = σ2 /N and the empirical risk for ease of notation.
Ns y¯Ns|x y|x s
σ2 = Var [y]. By construction, for all N ∈ N,
y|x y∼p(y|xi) s
p(y¯ Ns|x) gives the same p-concept as p(y|x), i.e., (x i,y¯ i) ∼ D¯ and c(x) = E y¯[y¯|x]. Therefore, instead of
c(x)=E [y]=E [y¯ ]. (4) minimizingtheimplicitorexplicitrisks,wewillminimize
y∼p(y|x) y¯Ns∼p(y¯Ns|x) Ns the empirical (implicit) risk
For ease of notation, we let c(x):=E [y¯ |x] and im-
p anli dcit dl ey na os ts eu tm he emth ae sd y¯ep anen dd De ¯n ,c re eso pf ey c¯ tN iy¯ s vN es a lyn .dNs D¯ Ns on N s, R(cid:98)(h):= N1 (cid:88)N1 (h(x i)−y¯ i)2. (11)
1
i=1
In the p-concept learning setting, a learning algorithm
similarly selects a hypothesis h from a hypothesis class using samples S to obtain the optimal hypothesis that
H such that the difference between h(x) and the corre- well approximates the underlying p-concept rather than
sponding p-concept c(x) is low under some performance the noisy label. That is, we aim to achieve low R
expl
measure. Here,wedefinetwodifferentperformancemea- by minimizing R(cid:98). We have provided a glossary of error
sures: explicit and implicit loss. In particular, the ex- definitions in Tab. I for ease of reference.
plicit loss of h is defined as There is nothing that formally distinguishes a p-
conceptfroma“regular”conceptintheprobablyapprox-
ℓ (h)=(h(x)−c(x))2 (5)
expl imately correct (PAC) framework [13, 14]. Instead, the
role of the probability distribution only comes forward
while the implicit loss of h is defined as
when we talk about the learnability of such concepts.
ℓ impl(h)=(h(x)−y¯)2. (6) Definition 3 (p-concept learning). Let N ∈ N be the
s
number of random labels (per data input) and P =
That is, the explicit loss directly measures the perfor-
{p(y¯|x)} be a set of conditional probability distributions
mance of h concerning the target p-concept c(x), while
over Y associated with a p-concept class
the implicit loss indirectly quantifies the differences be-
tweenh(x)andc(x)throughthenoisylabelsy¯asc(x)= C :={c:x(cid:55)→E [y¯]|p(y¯|x)∈P}. (12)
E [y¯|x]. Averagingbothlossesoveralldatapointsyields y¯∼p(y¯|x)
y¯
their respective risks: explicit risk We say C is p-concept learnable if there exists an algo-
rithm A such that:
R (h):= E [(h(x)−c(x))2] (7)
expl
(x,y¯)∼D¯ 1. for any error tolerance ε and success probability δ,
and implicit risk 2. for any conditional distribution p(y¯|x) ∈ P and
corresponding p-concept c∈C in the class, and
R (h):= E [(h(x)−y¯)2]. (8)
impl
(x,y¯)∼D¯ 3. for any probability distribution p(x),
The decomposition of R impl(h), i.e., the learning algorithm A, when given as input a training
R impl(h)=R expl(h)+ E [(E y¯[y¯|x]−y¯)2] (9)
s pe (t y¯|S x)=
,
p( rx
oi
d, uy¯
ci
e)N
i
s=1 a1, hw yph oe tr he e( sx isi) hN i=1
f1
ul∼ filD linN g1, and each y¯
i
∼
(x,y¯)∼D¯
=R (h)+R (E [y¯|x]), (10) P(R (h)≤ε)≥1−δ, (13)
expl impl y¯ expl
shows that the implicit and explicit risks are related by where R (h) is the risk functional defined in Eq. (7)
expl
a constant shift. Hence, a small R (h) implies a small and the probability is over both: the sampling of training
impl
R (h) and vice versa. sets (x )N1 of size N and the sampling of random labels
expl i i=1 1
Inpractice,thedistributionD¯ andtheexactp-concept y¯ conditional on each x .
i
c(x)areinaccessibleasweonlyhaveaccesstofinitesam- Further, C is efficiently p-concept learnable if A has
ples drawn from the distribution S = (x ,y¯)N1 with runtimepolynomialin1/ε,1/δ,andσ2 ,theconditional
i i i=1 y¯|x4
varianceofy¯givenx foreachi∈{1,...,N }. (Runtime where ξ(x) ∈ [−M,M] is some noise function with
i 1
efficiency implies sample efficiency, runtime of A upper- E [ξ(x)2] ≤ ϵ that captures how well one can approx-
x 1
bounds N ). imate p-concepts using hypotheses from H. By the L-
1
Lipschitz property of u and E [ξ(x)2]≤ϵ , we have
Whenthereisnouncertaintyinthegivenlabel, thep- x 1
c mo on dc ee lp [t 13le ]a .r Tn hin isg im sco ad pe tl uw rei dll ir ned Du ec fe .3to byth lee ttP inA gC Nlea →rni ∞ng
,
R expl(h)=E D¯[(h(x)−c(x))2]≤L2ϵ 1. (18)
s
and in this regime, we have R impl(E y¯[y¯|x]) = 0 hence That is, low ϵ
1
implies low approximation error of c(x)
R expl(h)=R impl(h). usingh∈H. Thisapproximationenablesustosystemat-
ically reduce the learning task to the search of appropri-
atefeaturemapϕ(x), thelinkfunctionuandthedesign
1. Hypothesis class for modelling probabilistic concepts
of efficient algorithms to learn the weight vector w.
Tomodelthep-concepts,weconsiderthefollowinghy-
pothesis class B. The family of parameterized quantum models
H={h(x)=u(⟨w,ϕ(x)⟩); w,ϕ(x)∈Rp}, (14)
In this work, we are interested in learning a family of
whereu:R→Y isanL-Lipschitzfunctionthatmatches parameterized quantum models f (x)
θ
the label space Y, w are weight vectors with bounded
2-norm ∥w∥ ≤ B and ϕ : Rm → Rp is the feature map F ={f (x)=tr(ρ (x)O)|θ ∈Θ}. (19)
2 θ θ
that maps x to a higher dimensional feature space with
p > m and ∥ϕ(x)∥
2
≤ 1, and ⟨·,·⟩ is the usual inner where ρ θ(x) are parameterized quantum states with pa-
product. This hypothesis class consists of two compo- rameters θ ∈Θ=Rr and input data x∈X =Rm while
nents (i) the feature map ϕ(x) and (ii) the link function O is an arbitrary Hermitian observable. The quantum
u, each serving different roles. states ρ θ(x)=M θ,x(ρ 0) could be prepared by applying
The feature map dictates the class of realizable func- parameterizedquantumchannelsM θ,x(·)onsomeinitial
tionsand giventwofeature vectors ϕ(x),ϕ(x′), theirin- stateρ 0. Inparticular,wewillfocusonspecificquantum
ner product is equal to the kernel function channels that are generated by parameterized quantum
circuits (PQCs). We remark that our analysis can be
k(x,x′)=⟨ϕ(x),ϕ(x′)⟩. (15)
directly extended to other quantum channels including
ground state preparation channels [9–11].
Interestingly, one could express the same class of func-
tions in terms of the kernel. Computing the kernel func-
tion k(x,x′) directly without explicitly evaluating the
1. PQCs and their classical Fourier representations
feature vectors and their inner products is known as the
kernel trick. Note that H reduces to the typical kernel
machines when u is set to be the identity function. Let x = (x 1,...,x m) ∈ X = [0,2π)m be a vector of
The function u, on the other hand, provides us ex- data points, θ = (θ 1,...,θ m) ∈ Θ = [0,2π)r be a vector
tra flexibility to incorporate the information about the ofparameters,U(x,θ)betheunitarythatrepresentsthe
p-concepts. As discussed, one does not necessarily have PQCs, |0⟩ = |0⟩⊗n and O be an arbitrary Hermitian
accesstotheexactp-conceptc(x)butrathertothesam- observable. We define the PQC model as
ples (x,y¯) ∼ D¯ = p(x)p(y¯|x). Direct optimizing kernel
f (x)=⟨0|U†(x,θ)OU(x,θ)|0⟩. (20)
machines with the empirical risk R(cid:98)(·) using the training θ
samples S =(x ,y¯)N1 yields
i i i=1 ForagivenU(·,θ)andO,wedefinethePQCmodelclass
(cid:88)N1 F U,O as
g(x)= a k(x,x ). (16)
i i F =(cid:8) f (·)=⟨0|U†(·,θ)OU(·,θ)|0⟩ |θ ∈Θ(cid:9) (21)
i=1 U,O θ
However,thiskernel-basedmodelmightbetooexpressive
for all x∈X.
for p-concept modelling as it tends to overfit the noisy
The parameterized unitary U(x,θ) consists of a se-
labels. Crucially, the link function u can be used to re-
quence of two different types of parameterized quantum
strict the size of the model class, allowing us to suppress
gates. The first type of parameterized quantum gates is
their tendency to overfit. For the sake of clarity, we will
controlled by parameters θ, while the second type em-
postponetheillustrationsoftheabove-mentionedroleof
beds data points x into the PQCs via unitary evolution
i
u to the latter sections as the examples could be more
ap Npr oo wp ,ri wat eel ay reun red ae dr ysto tood exin prt eh se
s
tq hu ean pt -u com ncc eo pn tt sex int.
terms
V (j,k)(x j)=e−iH k(j)xj, (22)
of the hypothesis class. That is,
generatedbysomeHamiltonianH(j). Giventhisparam-
k
E [y¯|x]=c(x)=u(⟨w,ϕ(x)⟩+ξ(x)), (17) eterisation strategy, it is well-known that PQC models
y¯5
(a) 𝑁 (b)
1 ∞
𝜌 0
𝑁
𝑠
𝑦ത 𝑖 𝑥 𝜌0
𝑂
𝑦
𝜌
0
𝜌
0 𝑂
𝑂 Avg.
𝒙 𝒊 𝑂 𝑦ത 𝑖
ℎ ∈ ℋ min|ℎ 𝒙 −𝑦|2
Datapoint 𝑖
(c)
FIG. 1. Concept learning of parameterized quantum models. (a) To learn quantum models, one needs to probe the quantum
model with N different input data points x, and construct an estimator of the quantum model y = f(x) conditioned on the
input. Such estimators y¯can be constructed by taking the average over N duplicate quantum measurements. (b) Using data
s
pairs(x ,y¯)collectedfromthequantummodel,thetaskistoclassicallylearnarepresentationh∗ ofthequantummodelsuch
i i
that the outputof classical representation h(x) is closeto the underlying expected output y=f(x) of the quantum model for
anyarbitraryx. Asillustratedin(c),thenumberofmeasurementshotsN willdeterminetheclosenessbetweentheestimator
S
y¯(blue dots) and the underlying expected value f(x) (black solid line).
could be written as a Fourier series3 [28, 29] Giventhisdefinition,Eq.(23)canbeequivalentlywritten
as
(cid:88)
f (x)= c (θ)ei⟨ω,x⟩, (23)
θ ω |Ω|−1
ω∈Ω˜
f (x)=c (θ)+
(cid:88)
(a (θ)cos(⟨ω ,x⟩)+
θ ω0 ωi i
i=1
where the frequency spectrum Ω˜ is determined by
b (θ)sin(⟨ω ,x⟩)) (26)
the ensemble of eigenvalues of embedding Hamiltonian ωi i
{H(j)} andthecoefficientsc (θ)dependonthequan-
k j,k ω Identifying the corresponding weight vectors w
tum gates parameterized by θ.
Eq. (23) can be further simplified by noting that the  c (θ) ⊺
n Ω i˜ so ,,n Ωa ˜-z lle o :r =wo inf Ωr geq u ∪u sen t (oc −ie Ωss p )li in wt iΩ Ω t˜ ˜ hc in Ωo tm o ∩e twin (o −p Ωca o )i mrs =p, oi. n {e ωe., ntω }s ,.,− wTω hh ea r∈ et
w
(θ)=(cid:112) |Ω|  

a b ωω ω 10 1 .(( θθ ))   
 (27)
0 F  . 
ω =(0,...,0)∈Ω˜ is the vector of zero frequencies. Let  . 
0  
a (θ)
Ω={ω 0,ω 1,...,ω |Ω|} and for all ω ∈Ω\{ω 0}, we have  ω|Ω|−1 
b (θ)
ω|Ω|−1
a (θ):=c (θ)+c (θ) (24)
ω ω −ω
and the trigonometric polynomial feature map
b (θ):=i(c (θ)−c (θ)). (25)
ω ω −ω
 
1
 cos(⟨ω 1,x⟩) 
 
1  sin(⟨ω 1,x⟩) 
ϕ (x)=  .  (28)
3 TheFourierexpansioninthisworkmainlyfollowsthetreatment F (cid:112) |Ω|  . .  
in Ref. [24, 25] but equivalent Fourier representation of PQC  (cid:0) (cid:1)
modelscanbeobtainedbyotherFourierexpansionmethods[26, cos (cid:0)⟨ω |Ω|−1,x⟩ (cid:1)
27] sin ⟨ω |Ω|−1,x⟩6
enables us to express the PQC model as a linear model Algorithm 1: The learning algorithm
with respect to the feature map ϕ , i.e.,
F Input: Training data size N , validation data size N ,
1 2
number of measurement shots N , parameter
s
f θ(x)=⟨w F(θ),ϕ F(x)⟩, (29) setting of quantum model θ, distribution of
input p(x), non-decreasing L-Lipschitz
andtheassociatedkernelfunctionisgivenbyk (x,x′)= function u:R→Y, kernel function k
F
⟨ϕ (x),ϕ (x′)⟩. corresponding to feature map ϕ, learning rate
F F
λ>0, number of iterations T
1 Sample N 1 training data inputs x 1,...,x N1 ∼p(x).
2 For each x i, obtain the associated labels y¯ i, with
2. Data extraction from parameterized quantum models E y¯[y¯|x]=tr(ρ θ(x)O), by extracting and averaging N s
measurement samples of the quantum model via
procedure described in Sec. IIB2. This yields the
In general, one does not have direct access to f θ(x). training dataset (x i,y¯ i)N i=1 1.
Instead, they are estimated using finite samples from 3 Repeatsteps1and2tocollectlabelledvalidationdata
measurement procedures such as direct measurement or of size N , (p ,q¯)N2 .
2 j j j=1
classicalshadowmethods,asdescribedinApp.A.Wede- 4 Initialize αi :=0∈RN1.
noteoutputsofsuchestimationproceduresasy¯andtheir
5 for t=1,...,T do
d nuep me bn ed re on fcy meo an suth ree md ea nt ta shp oo tin st Nx, ap rear imam pe lit ce ir tlyθ, asa sn ud mt eh de
.
6 ht(x):=u(cid:16) (cid:80)N i=1 1α itk(x,x i)(cid:17)
s
In addition, they are unbiased estimators of f (x), i.e., 7 for i=1,2,...,N 1 do
θ 8 α it+1 :=α it+ Nλ 1(y¯ i−ht(x i))
f θ(x)=E y¯[y¯|x,θ]. (30) Output: hr where
r=argmin 1 (cid:80)N2 (q¯ −ht(p ))2
t∈{1,...,T} N2 j=1 j j
For ease of notation, we will drop the conditional depen-
dency of the expectation on θ from now on.
Now,wedescribetheproceduresforobtaininglabelled A. Algorithm for concept learning of
data points from a given f θ. Without loss of generality, parameterized quantum models
we let p(x) be a uniform distribution of input x. As
depicted in Fig. 1 (a), a set of N i.i.d. samples of x
By expressing the PQMs in terms of the hypothesis in
is first drawn from p(x) and subsequently input to the
H,wesystematicallyreducethemodellingproblemtothe
quantummodeltocollecttheirassociatedlabelsy¯viathe
searchoftheappropriatefeaturemapϕ(x),linkfunction
procedures described in App. A using N s measurement u,andoptimalweightw∗. Asthefirsttwoattributesare
repetitions. This gives the set of data S = (x ,y¯)N .
i i i=1 highly dependent on the problem at hand, we will defer
ShowninFig.1(c)arethelabelsy¯estimatedwithN =
s theirdiscussiontoSec.IV.Inthissection,wewillassume
1,10,100.
ϕ(x) and u are known and focus on the algorithm part
of the problem.
Consider a PQM tr(ρ(x)O) that can be approximated
by a feature map ϕ(x) and a known L-Lipschitz non-
III. PARAMETERIZED QUANTUM MODELS
AS PROBABILISTIC CONCEPTS decreasing function u : R → Y, as per Eq. (31). The
taskoflearningPQMscouldbeformulatedasthesearch
of the optimal weight vector w∗ such that the output
One can immediately deduce from Eq. (30) that pa-
hypothesis h∗(x)=u(⟨w∗,ϕ(x)⟩) minimizes the explicit
rameterized quantum models (PQMs) are p-concepts.
risk
Now, we will show that the hypothesis class defined in
Sec. IIA1 is an appropriate model class for the learning R expl(h∗)=E D¯[(u(⟨w∗,ϕ(x)⟩)−tr(ρ(x)O))2]. (32)
of PQMs. Modelling PQMs using the hypothesis from
H, as defined in Eq. (14), assumes the following: there AsdiscussedinSec.IIA,wewillonlyhaveaccesstofinite
exist a feature map ϕ(x), a function u, a weight vector samples drawn from the distribution D¯. Hence, we will
w,andanoisefunctionξ(x)suchthatthePQMscanbe be minimizing the empirical risk R(cid:98)(h) in Eq. (11) using
expressed as some training samples S = (x ,y¯)N1 with (x ,y¯) ∼ D¯
i i i=1 i i
insteadofR (h). Notethattheextrauintheempirical
expl
E y¯[y¯|x]=tr(ρ θ(x)O)=u(⟨w,ϕ(x)⟩+ξ(x)), (31) risk makes the optimization non-convex. As detailed in
Fig.1(b),whiletheclassicalmachinelearnsfromanoisy
with ∥w∥ ≤ B, ξ(x) ∈ [−M,M], and E [ξ(x)2] ≤ ϵ . dataset consisting of shot noise from quantum measure-
2 x 1
Hence, the aim here is to find an appropriate function ments, ourobjectiveistoenabletheclassicalmachineto
u that contains information on the PQM as well as con- approximate the underlying p-concept of the PQM, i.e.,
structthefeaturemapϕ(x)thatefficientlyapproximates the expected value of the measured outcomes of PQMs.
a PQM. Shown in Algo. 1 is an iterative-based method that7
learns PQMs under some mild assumptions. While error. Additionally, a measurement scheme that results
our algorithm is derived from the iterative method in insmallervariancewillrequirefewertrainingdatapoints
Ref.[20],weextendedtheprovableguaranteeoftheorig- and measurement shots to achieve a smaller ϵ error.
4
inal algorithm to include the number of measurement
shots N used to estimate y¯ and show its operational
s
role in the algorithm. The analytical guarantee enables
us to understand the contributions of errors and the in- B. Asymmetrical effects of N 1 and N s
tuitive explanation of the working principle of Algo. 1 is
provided in App. B1. While the individual implications of all four types of
errors are straightforward to deduce, jointly analysing
Theorem 1 (p-concept learnability of PQMs). We are
the last three sources of error leads to an interesting ob-
given a quantum observable O such that ∥O∥ = ∆.
∞ servation regarding the asymmetrical effects of N and
With this observable, we have quantum model whose ex- 1
N on classical learning of quantum models. On the one
pected output can be expressed as a classical representa- s
hand,increasingN canonlydecreasethelabelsampling
tion as follows: tr(ρ(x)O)=u(⟨w,ϕ(x)⟩+ξ(x)), where s
error ϵ but not the data sampling errors ϵ and ϵ and
u : R → [−∆,∆] is a known L-Lipschitz non-decreasing 4 2 5
the learnability error ϵ . On the other hand, increasing
function, ξ : Rm → [−M,M] such that E [ξ(x)2] ≤ ϵ , 3
x 1 N will simultaneously decrease all three errors, and ϵ
∥w∥ ≤ B, and ∥ϕ(x)∥ ≤ 1. Considering a training 1 4
2 2 approaches0regardlessofthevalueofN . Consequently,
dataset of N i.i.d. samples of x as input to the quan- s
1 one could set N =1 when N is sufficiently large. This
tum model, and whose label is the sample mean of the s 1
observationalignswithintuition,asthelabelsaredepen-
output of the quantum model sampled over N measure-
s dent on the parameters. By sampling across the train-
ments. Lettheconditionalvarianceofanindividualmea-
ing points, one effectively samples across various labels,
surement averaged over all x be σ¯. For δ ∈ (0,1), with
thereby providing a reasonable estimation of quantum
probability 1 − δ, setting the learning rate λ = 1 and
L models. In contrast, increasing the resolution of the la-
given a validation dataset size of N =O(N
∆2log(cid:0)T(cid:1)
),
2 1 δ bels does not provide extra information on other data
after T =O(BL) iterations, Algo. 1 outputs a hypothesis points. This observation is summarised in Cor. 1 and
ϵ4
h∈H such that numerically illustrated in Fig. 2 (a). For simplicity, we
assume δ =0.01, and σ¯ =L=B =∆=1.
√
R (h)≤O(L∆ ϵ +L∆Mϵ
expl 1 2
+LB∆ϵ 3+LBϵ 4+∆2ϵ 5), (33) Corollary 1 (Asymmetrical effects of N 1 and N s). Let
all variables defined as per Thm. 1. For the hypothe-
(cid:114) (cid:114) sis class H with link function u, feature map ϕ(x) and
where ϵ = 4 log( δ1) , ϵ = (cid:113) 1 , ϵ = σ¯log( δ1) , ϵ = weightvectorwwithtr(ρ(x)O)=u(⟨w,ϕ(x)⟩)∈H,i.e.,
(cid:114)
2 N1 3 N1 4 N1Ns 5
E x[ξ(x)2] = 0, Algo. 1 will output a hypothesis h ∈ H
log( δ1)
, and σ¯ =E [σ2 ]. such that
N1 x y|x
(cid:114) (cid:114) (cid:114)
The proof of this theorem can be found in App. B2. 1 1 1
R (h)≤c +c +c , (34)
As shown in Eq. (33), four different error sources will expl 1 N 2 N N 3 N
1 1 s 1
affect the performance of the models: (i) the approxi-
mation error ϵ 1, (ii) the data sampling errors ϵ
2
and ϵ 5,
where c = O(LB∆), c =
O(cid:16) LB(cid:113) σ¯log(cid:0)1(cid:1)(cid:17)
, c =
(iii) the learnability error ϵ , and (iv) the label sampling 1 2 δ 3
3
error ϵ . Firstly, the approximation error ϵ captures
O(cid:0) ∆2log(cid:0)1(cid:1)(cid:1)
,andN andN contributeasymmetrically
4 1 δ 1 s
the intrinsic error that can be achieved by our hypothe- to R(h). That is, for a constant N , R(h) ̸→ 0 when
1
sis class as it tells us how far away our hypothesis h(x) N → ∞, but R(h) → 0 when N → ∞ regardless of
s 1
is from the true function tr(ρ(x)O) we wish to learn, the value of N . Note that ϵ = 0 implies M = 0 by
s 1
i.e., E [ξ(x)2] ≤ ϵ . It is therefore impossible to obtain definition.
x 1
a small risk if the approximation error is high to begin
with. On the other hand, the data sampling errors ϵ 2 The overall analysis shows that for a sufficiently large
andϵ 5 capturethestatisticalnoisearisingfromthefinite N 1,classicalmodelscanlearnquantummodelsthathave
data samples provided to the learning algorithm while efficient classical representation even when target labels
the learnability error ϵ 3 stems from Rademacher com- areestimatedwithlimitedmeasurementshots,e.g.,N s =
plexity and quantifies the hardness of learning with the 1. Conversely,whensuchefficientclassicalrepresentation
given hypothesis class. Both of these errors can be mini- cannotbefound,tr(ρ(x)O)isnotlearnableevenwhenN
1
mized by providing more data samples. Lastly, the label and N are infinite. Cor. 1 further shows that N plays
s s
sampling error ϵ 4 is influenced by three attributes, the a less significant role than N 1 in the classical learning
averaged variance E x[σ y2 |x], the number of training data of quantum models. In other words, shot noise is not
pointsN ,andthenumberofmeasurementshotsN . In- a fundamental concern in classical learning of quantum
1 s
creasingeitherN orN couldreducethelabelsampling models as its role can be easily substituted by N .
1 s 18
C. Trade-offs between N and N (a)
1 s
Inanidealworld,onewouldchooseN andN aslarge
1 s
aspossibletominimizetheexplicitrisk. However,exter-
nalconstraintslikefinancialbudgetsandtimelimitations
mightsignificantlyrestrictthetotalnumberofqueriesto
aquantummodel. Thus,amorerealisticsettingistofirst
consider a fixed number of queries to quantum models,
and N and N are subsequently decided.
1 s
In general, producing more samples for a fixed param-
eter setting in an experiment is much cheaper and faster
than changing the parameter settings each time. Chang-
ing parameters incurs an additional cost that may stem
from preprocessing subroutines, classical transpilation
and optimization of the circuits or platform-dependent (b)
factors regarding the hardware we are executing the
quantum circuits. For example, the penalty cost for su-
perconducting quantum computers would be larger than
for trapped-ion quantum computers, as it is relatively
cheaper to produce more samples for a fixed parameter
set than to change the parameter setting each time in
the former platform [30]. To quantify such costs for eas-
ier discussion, we assume that these costs can be quan-
titatively evaluated to be some multiple γ ∈ R of the
+
cost to run a repetition of quantum circuits that have
already been configured. That is, we assume changing
the parameter setting once will incur an extra cost of γ
shots.
Considering the total measurement budget for train- FIG. 2. The respective numerical illustrations of Cor. 1 and
ing, we find that N = N · (N + γ). Fixing the Cor. 2 with δ = 0.01, and σ¯ = L = B = ∆ = 1. (a) The
tot 1 s
total measurement budget N implies a trade-off be- plot shows the asymmetrical effect of the number of train-
tot
tween N 1 and N s: increasing N 1 will reduce N s and ingsamplesN 1 andthenumberofmeasurementshotsN s on
vice versa. This poses an interesting learning-theoretic the explicit risk R expl(h). (b) For a fixed total measurement
budget N , the optimal pair of N and N will change with
question: given a fixed N , will classical machines tot 1 s
tot γ. When γ = 0, the optimal shot number is N = 1 but it
learn better with training datasets consisting of more in- s
depends on γ when γ > 0. All curves are computed with
puts/parameterswithnoisierlabels(largerN butsmaller
1 N =600 and N ={1,2,3,...,24,25}.
tot s
N ) or fewer inputs with cleaner labels (smaller N but
s 1
larger N )? As shown in Cor. 2, when N and N are
s 1 s
treated equally (γ = 0), asymptotically, it is generally
reduces to
better to sample more inputs, i.e., (N∗,N∗) = (N ,1).
1 s tot
When there is an extra cost for changing the parameter (cid:114) N (cid:114) 1 (cid:114) N
settings, i.e., γ > 0, there exists a pair of optimal input R expl(h)≤c 1 N s +c 2 N +c 3 N s (36)
size N∗ and the shot number N∗ that minimize the ex- tot tot tot
1 s
plicitrisk. Theseobservationsarenumericallyillustrated which is minimized when N = 1. When γ > 0, there
s
in Fig. 2 (b). For simplicity, we assume δ = 0.01, and exists a pair of optimal input data size and shot number
σ¯ =L=B =∆=1. (N∗,N∗) where
1 s
Corollary 2 (Trade-off between N and N ). Con-
1 s (cid:18) (cid:19)2
sider the setting as per Cor. 1. For a given fix total N∗ = N tot and N∗ = c 2γ 3 (37)
measurement budget for training N ∈ N and a fix 1 N∗+γ s c +c
tot s 1 3
penalty cost γ ∈ R , N and N are determined by
+ 1 s
N
tot
=N 1·(N s+γ). Respecting this constraint, Algo. 1 that minimizes our upper bound of R expl(h).
will output a hypothesis h∈H such that
Note that the optimal value of N does not correlate
s
(cid:114) (cid:114) (cid:114)
R (h)≤c
N s+γ
+c
N s+γ
+c
N s+γ
.
with N tot, but depends on the constant penalty cost γ.
expl 1 N
tot
2 N totN
s
3 N
tot
Hence, setting N s =1 regardless of the √value of γ would
(35) only increase R expl(h) by a factor of 1+γ, retaining
learnability up to a constant factor for single measure-
Whenγ =0, theupperboundoftheexplicitriskR (h) ment learning.
expl9
Taking a closer examination at N , we check whether machine learning models and this impact can be studied
s
other factors apart from the device-dependent cost γ af- by analysing the statistical quantities Bias2 and Var .
S S
fect the value of N . Delving into the definitions of the Intuitively, high shot noise implies high variance in the
s
terms c , c , and c , we note that the terms L, ∆, and δ labels, indirectly leading to high variance in the models,
1 2 3
are constants that either depend on the problem setting andfurtherinducesoverfitting. Wewillprovideasimple
orcanbesetarbitrarily. B,ontheotherhand,isdirectly exampleinSec.IVtoillustratehowshotnoiseaffectsthe
related to the expressibility of the hypothesis h used to bias-variance trade-off.
model the quantum model. Does the expressibility B of
Eq. (33) and Eq. (40) appear to be unrelated to each
the hypothesis h affect the number of shots N required?
s
other. On the one hand, the algorithm-specific Eq. (33)
Plugging in c = O(B), c = O(B), c = O(1), we
1 2 3
(cid:16) (cid:17) gives a probabilistic guarantee on the performance of
note that in terms of B, N = O B , where K is a
s B+K each trained model. On the other hand, the algorithm-
constant. WhileN s isindeeddependentonB,itsdepen- agnostic Eq. (40) provides an understanding of the av-
dencycanbeupperboundedbyaconstantasN s →O(1) erage behaviour of the overall hypothesis class. One can
asB grows. Hence,evenincaseswheretheexpressibility however observe the similarities between the two by di-
ofthehypothesishweusetoexactlymodelthequantum rectly comparing Eq. (33) and Eq. (40). Specifically, the
model scales exponentially, the number of shots required first term in Eq. (33) can be understood as the bias of
to sample each data is still limited to a constant value. the models since it quantifies the asymptotic error that
is achievable by the models while the second term cap-
turesthefinitesamplingnoiseofthebias;theotherthree
D. Shot-noise dependent bias-variance trade-off termsinformonthevarianceofthemodel. Interestingly,
the shot-noise dependent variance is captured by ϵ and
4
An alternative framework for analyzing the occur- Fig. 2 essentially captures the variance dependence on
rencesofdifferenterrortermscommonlyseeninmachine the number of training data points and the number of
learning analysis is the bias-variance-noise decomposi- measurement shots.
tion. Here, we provide a summary with the full intro-
duction deferred to App. C.
Optimizing the empirical risk R(cid:98)(h) using different
training datasets S would yield different trained models
h (x). The bias then measures, on average, how much
S
h deviates from the ground truth f
S IV. CLASSICAL SURROGATES OF PQC
MODELS AS PROBABILISTIC CONCEPTS
Bias :=E [h (x)]−f(x), (38)
S S S
while the variance
As a direct example, we apply our theoretical frame-
(cid:104) (cid:105) work to create a classical surrogate of parameterized
Var :=E (E [h (x)]−h (x))2 (39)
S S S S S quantum circuit (PQC) models [8]. Treating PQC mod-
els as p-concepts enables us to study the impact of shot
measures the fluctuations among the trained models. As noise on constructing their corresponding classical sur-
theexpectationistakenoverallpossibletrainingdatasets rogates. In particular, we observed asymmetrical effects
of the same size, therefore, the bias and variance will be from both the number of training data points and the
dependent on the complexity of the hypothesis class, the number of measurement shots, as well as the potential
number of training data points N 1 and the number of forusingarelativelysmallnumberofmeasurementshots
random labels N s. to surrogate PQC models. As predicted by our theoret-
The average of the explicit risk over all possible train- ical analysis, the bias and variance of the classical sur-
ing datasets will then have the following decomposition, rogates are highly dependent on the strength of the shot
whose derivation is also found in App. C: noise. Finally, we highlight the role of the link function
in our surrogate models in suppressing their variance in
E S[R expl(h S)]=E x(cid:2) Bias2 S(cid:3) +E x[Var S]. (40) the presence of the shot noise.
where We wish to emphasize that our work aims to provide
a generic framework to analyse the learnability of PQMs
E (cid:2) Bias2(cid:3) :=E (cid:104) (E [h (x)]−f(x))2(cid:105) and (41) inthepresenceofshotnoise. Therefore, inthisexample,
x S x S S
(cid:104) (cid:105) we will consider the feature map proposed in the liter-
E x[Var S]:=E x,S (E S[h S(x)]−h S(x))2 (42) ature [28, 29], but our framework is readily adaptable
tofutureproposalsofefficientfeaturemaps. Inaddition,
are the averaged bias squared and averaged variance, re- ourresultscanbeeasilyextendedtoothertypesofPQMs
spectively. Thisdecompositionshowsthattheshotnoise by replacing the quantum channel with appropriate sub-
has an indirect impact on the performance of classical stitutes.10
A. Classical approximation of PQC models active research, but our work could be directly adapted
if efficient feature maps were found.
In this section, we will briefly discuss the existing
methods for approximating PQC models classically. As
B. Modelling PQCs with and without link
described in Sec. IIB1, PQC models can be written
functions
as f (x) = ⟨w (θ),ϕ (x)⟩. Therefore, the immediate
θ F F
choice of feature map for modelling PQC models clas-
In this section, we will discuss the operational role of
sically is the full trigonometric polynomial feature map
the link function u in the surrogation of PQC models.
ϕ (x). However, the associated model class could be
F
Without loss of generality, we let O = |0⟩⟨0|, hence we
too expressive thus it might overfit the training data
have
points [8]. In addition, the size of the frequency spec-
trum could be exponential in the data dimension, which
f (x)=|⟨0|U(x,θ)|0⟩|2 =⟨w,ϕ (x)⟩+ξ(x), (44)
becomesintractableforclassicalcomputers. Instead,one θ RFF
could hope to exploit some structure of the PQC to con-
andf (·)∈F . Tomodeltheprobabilisticfunction
θ U,|0⟩⟨0|
struct an efficient feature map ϕ(x) to approximate the
f (x), we consider the following hypothesis class
θ
PQC models
H ={h(x)=u(⟨w,ϕ (x)⟩),∥w∥ ≤B} (45)
RFF RFF 2
⟨0|U†(x,θ)OU(x,θ)|0⟩≈⟨w,ϕ(x)⟩. (43)
where u is the clipping function
According to our notation above, we would use the

noise function ξ(x) to refer to the approximation error 0, x<0
ξ(x)=⟨w ,ϕ (x)⟩−⟨w,ϕ(x)⟩. Wedroptheexplicitθ u(x)= x, 0≤x≤1, (46)
F F
dependence of w F and ξ for ease of notation. 1, x>1
One approach would be to construct ϕ as a truncated
version of ϕ . This would take advantage of the fact a 1-Lipschitz function that enforces the matching of co-
F
thatthehigh-frequencycomponentsofPQCmodelsthat domains of the hypothesis class H and |⟨0|U(x,θ)|0⟩|2
are subjected to Pauli noise [26] typically make smaller while ensuring the output of the linear hypothesis h
contributions than lower frequency terms. Thus, Fourier within range [0,1] is not distorted. Note that the link
serieswithanappropriateleveloftruncationcanbeused function has no impact on f (x) since f (x)∈[0,1].
θ θ
tomodelPQCmodelswithoutcompromisingmuchofthe To provide context regarding the value of B, we note
accuracy. This approach assumes that we know which that similar to the full Fourier representation of PQC
components to truncate ahead of time, though, and that models, the weight vectors of the RFF feature map can
might be unrealistic for practical scenarios. also be written as
As an alternative, one can utilize a popular technique ⊺
a (θ)
from machine learning called Random Fourier Features ω˜1
b (θ)
(RFF) [31], used to efficiently approximate the high- √  ω˜1 
 . 
dimensional inner product ⟨w F(θ),ϕ F(x)⟩ by randomly w = D

. . 

(47)
selectingonlyafewofitsdominantterms[24,25]. Using a (θ)
RFF amounts to performing a truncation of the Hilbert
bω˜D
(θ)
space, with the only difference being that the selection
ω˜D
of components that are kept is probabilistic. RFF has where D is the dimension of the random Fourier fea-
been proposed as an approach to “dequantize” PQC- ture map ϕ and ω˜ ∈ Ω are the sampled frequencies
RFF i
based quantum machine learning models by exploiting from the original Fourier spectrum Ω. Following general
the efficient low-dimensional feature map ϕ in Ref. [24]. algorithm-independent results in statistical learning the-
Ontheotherhand,Ref.[25]discussestheapplicabilityof ory on RFFs [32, 33], we assume that the value |a (θ)|
ω˜i
RFF in terms of which PQCs are likely to admit the ef- and|b (θ)|areboundedbysomeconstantK. Notethat
ω˜i
ficient approximation. In both these references, the task ∥w∥ ≤KD ∈O(D).
2
is not to learn the classically efficient representation of Combining Thm. 1 with the results from the RFF ap-
the PQC but rather to show that a given downstream proximation yield Cor. 3.
task can be learned efficiently classically, without ever
Corollary 3. ConsiderthehypothesisclassH asde-
running the PQC. Even though the specific task is not RFF
fined in Eq. (45), a target function f(x)∈F , and
thesame,weobservethatthemainlimitationinlearning U,|0⟩⟨0|
quantum models comes from an efficient classical repre- variables as defined in Thm. 1. Let S =(x i,y¯ i)N i=1
1
be the
sentation, which deeply aligns with the use of RFF. In training dataset with y¯ i estimated with N s measurement
App. D we formally discuss how the performance guar- shots. Running Algo. 1 with S will yield h∈H RFF such
anteesofRFFbringaboutlearnabilityinthesenseintro- that
ducedinSecs.IIandIII.Also,wewishtoemphasizethat √
R (h)≤O( ϵ +Mϵ +D[ϵ +ϵ ]+ϵ ), (48)
theefficientclassicalrepresentationofPQCsisstillunder expl 1 2 3 4 511
(cid:114) (cid:114)
where ϵ = 4 log( δ1) , ϵ = (cid:113) 1 , ϵ = σ¯log( δ1) , ϵ = such results showcase the fact the ERM-based hypothe-
2 N1 3 N1 4 N1Ns 5 sis selection can still generalize with a constant number
(cid:114) of measurements provided that we have abundant data
log N( 1δ1) , and σ¯ =E x[σ λ2 |x]. points.
We note that without the application of the link func-
Here, we exploited the information about the co-
tion u in our modelling, classical models are much more
domainofthetargetp-conceptstodesignanappropriate
susceptibletoshotnoise. OurtheoreticalresultsofCor.2
link function u that restricts the size of the hypothesis
andLem.1implythattolearnlabelsobtainedfromcon-
class. To illustrate the impact of limiting the hypothesis
stant number measurements, without the link function
class size, we relax the co-domains matching constraint,
u, classical algorithms may require up to data points N
1
i.e., set u to be the identity map, hence the hypothesis
that are square of what is needed for models with the
class considered becomes
link function u. In the following section, we numerically
showcase this property.
G ={g(x)=⟨w,ϕ (x)⟩,∥w∥ ≤B}. (49)
RFF RFF 2
The most straightforward method to learn f (x) un-
θ
der this relaxed formulation is to directly minimize the V. NUMERICAL VALIDATION ON THE ROLE
OF SHOT NOISE
empirical risk R(cid:98)(h) given a sample S sampled from the
distributionD¯,whichwecallempiricalriskminimization
(ERM). We can formulate the above as a quadratically In this section, we will provide numerical verifications
constrained quadratic program as follows: ofourtheoreticalresults,validatingtheoperationalroles
of shot noise in learning quantum models.
1 (cid:88)
w∗ = argmin |⟨w,ϕ(x)⟩−y¯|2, (50)
|S|
w,∥w∥2≤B
(x,y¯)∈S
A. Numerical settings
which can be efficiently solved by convex optimization
methodssuchasinteriorpointmethods[34]orprojected We consider the data re-uploading model [35] for one-
gradient descent. Alternatively, by including the con- dimensional data points x in our numerical demonstra-
straint in the loss with Lagrangian multipliers, the prob- tion
lemcanbeformulatedasaridgeregressiontask. Various
(cid:12) (cid:16) (cid:17) (cid:104) (cid:16) (cid:17)(cid:105) (cid:12)2
prior work use this formulation to tackle learning prob- f (x)=(cid:12)⟨0|Rot θLr+1 ΠLr R (x)Rot θl |0⟩(cid:12) ,
θ (cid:12) l=1 X (cid:12)
lems involving PQCs [8, 24, 25].
(52)
Lemma 1. Consider the hypothesis class G as de-
RFF
fined in Eq. (49), a target function f(x) ∈ F , where θ = (θ1,...,θLr+1) is the set of rotational an-
U,|0⟩⟨0|
and variables as defined in Thm. 1. Let S = (x i,y¯ i)N i=1
1
gles, Rot(θl) = R Z(θ 3l)R Y(θ 2l)R Z(θ 1l) is the universal
be the training dataset with y¯ estimated with N mea- single qubit unitary gate, L is the number of layer rep-
i s r
surement shots. Optimizing Eq. (50) with S will yield etitions, and R (·) are the Pauli rotation unitary gates
P
gERM ∈G such that with P ∈ {X,Y,Z}. While we considered only the sin-
S RFF
gle qubit data re-uploading model with one-dimensional
 (cid:115) 
log1 datapoints,itisstraightforwardtogeneralizeourresults
R expl(g SERM)≤Oϵ 1+D2
N
δ . (51) to the multi-qubit model or with multi-dimensional data
1 points. As described, the data re-uploading model can
be expressed as a truncated Fourier series
The proof of this lemma can be found in App. E. Sim-
ilar to Eq. (48), one could understand Eq. (51) from the (cid:88)Lr
bias and variance perspective, i.e., the first term informs f (x)=c (θ)+ a (θ)cos(ωx)+b (θ)sin(ωx),
θ 0 ω ω
thebiasofthemodelwhilethesecondtermtellsusabout
ω=1
the model’s variance. Firstly, the inclusion of the link (53)
function u in the hypothesis class H results in a class of
model that has higher bias as compared to hypothesis with Fourier spectrum Ω+ = {1,...,L } while the
Lr r
class G hence leads to a quadratic increase in error ϵ . Fourier coefficients are dependent solely on θ and their
1
Consequently, H that is higher in bias will have lower associated unitaries.
variance, andwecanobservetheseparateandasymmet- Now, we will describe our numerical setting. Firstly,
rical effects of the data sampling and shot noises on the we considered fixed randomly generated angles θ in our
explicit risk. Removing the link function leads to higher numerical demonstrations, and this set of angles is used
variance in G, and the sensitivity to shot and data sam- forallnumericalexperiments. Therefore,wewilldropthe
pling noises becomes indistinguishable. The relationship dependency on θ from now on. In addition, we set L =
r
between errors in these two generalization bounds es- 10 for the data re-uploading model to generate a degree
sentially manifests the bias-variance trade-off. Further, 10 Fourier series. Such a target function is sufficiently12
(a) (b) (e)
𝑁𝑠=1
𝑁𝑠=1
𝑁𝑠=10
(c) (d)
(c)
𝑁𝑠=1
𝑁𝑠=100
𝑁𝑠=10
𝑁𝑠=100
FIG. 3. (a) The averaged explicit risk for different numbers of training data points N and number of measurement shots
1
N . The overall trends agreed with the theoretical prediction in Fig. 2: for a fixed N , the explicit risk saturated after some
s 1
thresholdvalueofN ,buttheexplicitriskcanbereducedbyincreasingN regardlessofthevalueofN . (b)Whenthemodel
s 1 s
in H are presented with a sufficiently large dataset, i.e., N =24000, the exact function (black dashed line) can be learned
10 1
evenifthelabelsareestimatedwithonemeasurementshot. (c)Twentydifferenttrainedmodels(dotteddashedlineofvarious
colours) from H and their mean predictors (solid red line) for N = 1,10,100. Increasing N reduces the shot noise, hence
10 1 s
reducing the spread of the trained models. (d) The bias-variance trade-off curve. The bias and variance of the trained models
in(c)arecalculatedandplottedinthepurpledottedbox. Therestofthevaluesarecomputedusingsimilarproceduresasper
(c) for H with d={1,2,3,4,5,6,7,8,9}. Both the bias and variance decrease when N increases, illustrating the shot-noise
d s
dependentbias-variancetrade-off. (e)Biasandvarianceformodelswithandwithoutthelinkfunctionu. Themodelswithout
the link function are more expressive, hence they are more susceptible to the shot noise, i.e., they have a higher tendency to
overfit the shot noise. Increasing N will reduce the shot noise, hence suppressing the shot-noise-induced variance. Note that
s
the same target function is considered in all these numerical experiments.
complex for us to observe various impacts of shot noise B. Asymmetrical effects of N and N
1 s
in learning f(x). Finally, this numerical example does
not require the utilizationof randomFourier features, as
To begin with, we investigate the asymmetry depen-
the model under consideration is rather straightforward;
dent on the explicit risk of the number of training data
therefore, the truncation method suffices. Specifically,
points N and the number of measurement shots N . In
we consider the following truncated Fourier series as our 1 s
particular, we set d = 10 such that the approximation
hypothesis class
error ϵ = 0, i.e., when ν = c , α = a , and β = b
1 0 0 ω ω ω ω
forallω ∈Ω+,enablingustoisolatetheimpactofthese
10
(cid:40) (cid:32) d (cid:33)(cid:41) two attributes. In this example, the ratio of the num-
(cid:88)
H d = h d(x)=u ν 0+ α ωcos(ωx)+β ωsin(ωx) ber of training data points N 1 to the number of vali-
ω=1 dation data points N is N :N = 8:2 with total data
2 1 2
(54)
points N ={10,15,25,50,75,100,200,300}. That is, we
trained the model in H with different pairwise com-
10
where ν 0,α ω,β ω ∈ R, u(·) is the clipping function as binations of N 1 = {8,12,20,40,60,80,160,240} train-
defined in Eq. (46) and d ∈ N controls the degree of ing data points and N s = {1,5,10,25,50,75,100,200}
thetruncatedFourierseries,hencethecomplexityofH . measurement shots using Algo. 1 under T = 50 train-
d
For all numerical experiments, the number of training ing iterations, and the optimal model is chosen using
steps T is fixed as 50, and 500 testing data points are N 2 ={2,3,5,10,15,20,40,60} validation data points for
used to evaluate the performance of trained models. To the respective value of N 1. Finally, the explicit risk is
distinguishthehypothesisclasswithandwithoutthelink estimated with 500 testing data points and we averaged
function, we denote H with the identity link function the explicit risk over 5 random instances of training and
d
as G . Note that all datasets are extracted using the validation datasets.
d
procedures described in Sec. IIB2. The results shown in Fig. 3 (a) agreed with our theo-13
retical prediction in Fig. 2, validating the asymmetrical 0.10
γ = 0 γ = 3
effects of N and N as described in Cor. 1. In particu-
1 s γ = 1 γ = 4
lar,itshowsthedecreasingtrendofexplicitriskwiththe 0.08 γ = 2 γ = 5
increase of N while keeping N =1. This observation is
1 s
further validated by Fig. 3 (b), where the exact function 0.06
can be learned when the model is presented with suffi-
ciently large training data points with labels estimated 0.04
using one measurement repetition, i.e., N = 2.4×104
1
and N s = 1. The three solid curves in Fig. 3 (b) are 0.02
the mean predictors obtained using training datasets of
sizeN ={40,800,24000}andvalidationdatasetsofsize
1 0.00
N = {10,200,600} respectively. Each of these mean 0 5 10 15 20 25
2
N
predictors is averaged over 5 different training instances s
and the shaded regions are the standard deviations of
the predictions. As expected, increasing N reduces the FIG. 4. The trade-off between N 1 and N s is considered
1
under a fixed total measurement budget of N = 600 for
standard deviations of the predictors and improves the tot
γ = {0,1,2,3,4,5} and N = {1,2,3,...,24,25}. When N
mean predictions. s 1
and N are treated equally, i.e., γ = 0, the optimal pair of
s
N and N is given by (N∗,N∗) = (600,1). As γ increases,
1 s 1 s
more measurement shots are required, hence smaller N , to
1
C. Shot-noise dependent bias-variance trade-off achieve better model performance. However, there will be a
threshold beyond which the performance of models worsens.
As discussed in Sec. IIID, training models with differ-
entfinite-sizetrainingdatasetswillyielddifferenttrained
models. ThisphenomenonisobservedinFig.3(c)where
20 distinct trained models from H , i.e., dashed-dotted lowervariance. Incontrast,thehighlycomplicatedmod-
10
linesofdifferentcolours,eachtrainedwithdifferenttrain- els will have lower bias but with higher variance. The
ingdatasetsofsize40aredifferentacrossN =1,10,100. former type of model tends to underfit the training data
s
Inaddition,thereducingfluctuationsofthetrainedmod- whilethelatterismorelikelytooverfitthetrainingdata.
els with increasing N demonstrated the N -dependent In addition, Fig. 3 (d) illustrates the shot-noise depen-
s s
relationship between these trained models. As N is suf- dentbias-variancetrade-offasdescribedinSec.IIID:In-
1
ficiently large, the prediction accuracy can be improved creaseN s willreducethebiasandvarianceofthemodels.
by increasing N and this is reflected in Fig. 3 (c) where
s Using the same settings as per Fig. 3 (d) but
the mean predictor is approaching the exact function
a different training procedure, we extract the bias
as N increases. These two observations can otherwise
s and variance of the hypothesis without the link
be captured by computing two statistical quantities, the
function u, i.e., G . Specifically, there is an exact
d
squared bias
analytical solution if we solve Eq. (50) using kernel
E x(cid:2) Bias2 S(cid:3) :=E x(cid:104) (E S[h S(x)]−f(x))2(cid:105) (55) r ci hd og oe sere tg hr ees os pio tn ima an ld rew gue lau rs ize att ih oe nv sa trli ed na gt ti hon oud tat oa fse Ct t =o
{0.006,0.015,0.03,0.0625,0.125,0.25,0.5,1.0,2.0,5.0,8.0,
and the variance 16.0,32.0,64.0,128.0,256,512,1024}. Then, their bias
(cid:104) (cid:105) and variance are compared against the hypothesis
E x[Var S]:=E x,S (E S[h S(x)]−h S(x))2 . (56) equipped with the link function in Fig. 3 (e) and these
numerical results are in agreement with the theoretical
In particular, we compute their empirical versions using analysis in Sec. IVB. That is, the variance of G is
d
thetrainedmodelsasperFig.3(c)using500testingdata significantly higher than their counterpart when N is
s
points. The computed values are plotted in Fig. 3 (d) low. High shot noise implies that the estimated labels
at d = 10, i.e., the points in the purple dotted box. As would be very different from their exact values and a
expectedthebiasandvariancereducewhenN increases. more expressive model class like G will have a higher
s d
These exact settings and procedures as per Fig. 3 (c) tendency to overfit the shot noise, lending to a higher
are repeated to obtain trained models from H for d = variance. Increasing N reduces the shot noise but the
d s
{1,2,3,4,5,6,7,8,9}, and these models are then used finite data sampling noise remains. This explains the
to compute their respective bias and variance. Plotting reducing but non-vanishing variance for both H and
d
their bias and variance yields the bias-variance trade-off G when N increases as well as the success of current
d s
curve,asshowninFig.3(d). AcrossN =1,10,100,the learning protocol using G [8, 10, 11]. Interestingly, the
s d
bias(variance)consistentlydecreases(increases)within- model’s bias with the link function matches well with
creasing d. This observation is consistent with the bias- the one without. In summary, the link function helps
variancetrade-offconcept,wherelesscomplexmodels(in suppress the shot noise-induced variance by restricting
ourcase,H withlowerd)willhavehigherbiasbutwith the expressivity of the hypothesis class.
d
)h(
R
lpxe14
D. Trade-off between N and N choose to train the classical machines with datasets con-
1 s
sisting of either more inputs with noisier labels or fewer
Finally, we numerically investigate the trade-off be- inputs with cleaner labels. If sampling across parameter
tweenN andN underafixedtotalmeasurementbudget settings does not incur extra cost compared to sampling
1 s
of N . Recall that the relationship between N , N , quantum models with the same parameter setting, then
tot tot 1
and N is given by N = (N +N )(N +γ), where the classical machine would learn better with datasets
s tot 1 2 s
γ is the penalty cost and N is the size of validation consisting of more inputs but with the noisiest labels.
2
dataset. The inclusion of N captures the resource con- Otherwise, the optimal budget partition would depend
2
straint for choosing the optimal time step T∗. Here, we on the cost differences between measurements with fixed
letN =600,γ ={0,1,2,3,4,5},andtheratioofN to and different parameter settings.
tot 1
N be 8:2. Furthermore, we set N ={1,2,3,...,24,25} While the hardness of learning quantum models clas-
2 s
giving different combinations of N and N . Repeating sically is not dictated by the shot noise, it has an im-
1 2
the similar procedures as per Fig. 3 (a) over 60 ran- pact on the actual training of classical machines. For a
dom instances of training and validation datasets for the given set of training data points {x i}N i=1 1, different label
above-mentioned settings yields Fig. 4. As predicted by sampling instances will yield different training datasets,
Cor.2,forafixedN tot andwhenγ =0,theperformance i.e., S = (x i,y¯ i)N i=1 1 or S′ = (x i,y¯ i′)N i=1 1. Each dataset
of classical machines can be enhanced by reducing N , will produce an associated trained model. We capture
s
and the optimality is achieved when N = 1. On the thismodel’ssensitivitytovariationoflabelsthroughthe
s
other hand, the optimal pair of N and N depends on bias-variance-noisedecompositionandshowthatthelink
1 s
thepenaltycostwhenγ >0; thelargertheγ, thehigher function can suppress this undesired sensitivity by re-
the N required to achieve optimal model performance. stricting the size of the hypothesis class. We further use
s
ourframeworkfortheclassicalsurrogationofparameter-
izedquantumcircuitmodels,andourtheoreticalanalysis
correctly predicts the behaviours of classical surrogates
VI. DISCUSSION
in the presence of shot noise.
Viewed from other angles, our work provides a frame-
Finite measurement or shot noise is an intrinsic quan-
work to study the impact of classical approximation and
tum phenomenon. Such noise is always present in the
shot noise on learning quantum models classically. Fu-
estimationofquantummodels; hence, classicalmachines
ture works could focus on searching for good classical
will unavoidably encounter shot noise when learning
approximations, and our framework could be directly
quantum models. Therefore, it is crucial to understand
adapted to handle shot noise. An interesting direction is
whether shot noise could increase the difficulty for clas-
tocombineourframeworkwiththeanalysisinRef.[36]to
sical machines to learn quantum models, or if it is just
investigatetheclassicallearnabilityoftheparameterized
a statistical feature that can be well-handled by classical
quantum circuit models that are free of barren plateaus.
models.
This will provide an alternative perspective on the re-
By formulating parameterized quantum models as
lationship between classical simulability and learnability
probabilistic concepts, we show that classical machines
of parameterized quantum models [37]. Shallow param-
can learn quantum models with efficient classical repre-
eterized quantum circuits usually admit efficient classi-
sentation in the presence of shot noise. Said otherwise,
calrepresentation,yettheymightexperienceexponential
the fundamental hardness of learning quantum models
concentrationifobservablesarenotchosencarefully [38].
depends on the existence of efficient classical representa-
This setting is suitable to push the limits of our frame-
tion, while the impact of shot noise is only prominent
work to check if classical machines can still learn such
when there is an insufficient number of training data
models underthe influence of exponential concentration.
points. When sufficient training data points are pro-
Finally, the core of our framework is the assumption
vided, classical learning of quantum models is possible
that the parameterized quantum models represent the
even when the labels are estimated with limited mea-
conditional unbiased expectation of their unbiased esti-
surement shots. This asymmetrical effect of the number
mators. However, estimators might not be unbiased af-
oftrainingdataandmeasurementrepetitionsarisesfrom
tersomepost-processingoperations. Anexampleofsuch
thedifferencesininformationgainedwhensamplingeach
post-processing operations is quantum error mitigation.
component. That is, one effectively samples across vari-
It will be interesting to investigate the role of shot noise
ous labels when sampling across the training points but
in the biased regime.
increasing the resolution of the labels does not provide
extra information on other data points.
Each quantum measurement, be it on a fixed or dif-
ferent parameter setting, counts as a query to quantum ACKNOWLEDGMENTS
models. While unlimited queries to quantum models are
desired,ourlimitedtimeandmonetaryresourcesforceus The authors thank Yuxuan Du, Naixu Guo, Hela
towiselydistributeourbudgettomaximizetheinforma- Mhiri, and Manuel Rudolph for discussions. This work
tionextractedfromquantummodels. Thatis,onehasto is supported by the National Research Foundation, Sin-15
gapore, and A*STAR under its CQT Bridging Grant PhD Fellowship, the Einstein Foundation (Einstein Re-
and its Quantum Engineering Programme under grant searchUnitonQuantumDevices),BMBF(Hybrid),and
NRF2021-QEP2-02-P05. EGF is supported by a Google BMWK (EniQmA).
[1] S. Aaronson, Shadow tomography of quantum states, Comput. 16, 615–656 (2016).
SIAM J. Comput. 49, STOC18 (2020). [19] M. C. Caro and I. Datta, Pseudo-dimension of quantum
[2] C. Huang, F. Zhang, M. Newman, J. Cai, X. Gao, circuits, Quantum Mach. Intell. 2, 14 (2020).
Z. Tian, J. Wu, H. Xu, H. Yu, B. Yuan, M. Szegedy, [20] S.GoelandA.R.Klivans,Learningneuralnetworkswith
Y. Shi, and J. Chen, Classical simulation of quantum twononlinearlayersinpolynomialtime,inProceedingsof
supremacy circuits (2020), arXiv:2005.06787 [quant-ph]. the Thirty-Second Conference on Learning Theory, Pro-
[3] H.-Y. Huang, M. Broughton, M. Mohseni, R. Babbush, ceedings of Machine Learning Research, Vol. 99, edited
S. Boixo, H. Neven, and J. R. McClean, Power of data by A. Beygelzimer and D. Hsu (PMLR, 2019) pp. 1470–
in quantum machine learning, Nat. Commun. 12, 2631 1499.
(2021). [21] E. Recio-Armengol, J. Eisert, and J. J. Meyer, Single-
[4] H.-Y. Huang, S. Chen, and J. Preskill, Learning to shotquantummachinelearning(2024),arXiv:2406.13812
predict arbitrary quantum processes, PRX Quantum 4, [quant-ph].
040337 (2023). [22] B. Neal, S. Mittal, A. Baratin, V. Tantia, M. Scicluna,
[5] H. Zhao, L. Lewis, I. Kannan, Y. Quek, H.-Y. Huang, S. Lacoste-Julien, and I. Mitliagkas, A modern take
and M. C. Caro, Learning quantum states and unitaries on the bias-variance tradeoff in neural networks (2019),
of bounded gate complexity (2023), arXiv:2310.19882 arXiv:1810.08591 [cs.LG].
[quant-ph]. [23] Z. Yang, Y. Yu, C. You, J. Steinhardt, and Y. Ma, Re-
[6] L.Zhao,N.Guo,M.-X.Luo,andP.Rebentrost,Provable thinkingbias-variancetrade-offforgeneralizationofneu-
learningofquantumstateswithgraphicalmodels(2023), ral networks, in Proceedings of the 37th International
arXiv:2309.09235 [quant-ph]. Conference on Machine Learning, Proceedings of Ma-
[7] A.AnshuandS.Arunachalam,Asurveyonthecomplex- chine Learning Research, Vol. 119, edited by H. D. III
ityoflearningquantumstates,Nat.Rev.Phys.6,59–69 and A. Singh (PMLR, 2020) pp. 10767–10777.
(2023). [24] J. Landman, S. Thabet, C. Dalyac, H. Mhiri, and
[8] F. J. Schreiber, J. Eisert, and J. J. Meyer, Classical sur- E. Kashefi, Classically approximating variational quan-
rogates for quantum learning models, Phys. Rev. Lett. tum machine learning with random Fourier features
131, 100803 (2023). (2022), arXiv:2210.13200 [quant-ph].
[9] H.-Y. Huang, R. Kueng, G. Torlai, V. V. Albert, and [25] R. Sweke, E. Recio, S. Jerbi, E. Gil-Fuster, B. Fuller,
J.Preskill,Provablyefficientmachinelearningforquan- J. Eisert, and J. J. Meyer, Potential and limitations of
tummany-bodyproblems,Science377,eabk3333(2022). random Fourier features for dequantizing quantum ma-
[10] Y. Che, C. Gneiting, and F. Nori, Exponentially chine learning (2023), arXiv:2309.11647 [quant-ph].
improved efficient machine learning for quantum [26] E. Fontana, M. S. Rudolph, R. Duncan, I. Rungger,
many-body states with provable guarantees (2023), andC.Cˆırstoiu,Classicalsimulationsofnoisyvariational
arXiv:2304.04353 [quant-ph]. quantum circuits (2023), arXiv:2306.05400 [quant-ph].
[11] L.Lewis,H.-Y.Huang,V.T.Tran,S.Lehner,R.Kueng, [27] N. A. Nemkov, E. O. Kiktenko, and A. K. Fedorov,
andJ.Preskill,Improvedmachinelearningalgorithmfor Fourier expansion in variational quantum algorithms,
predicting ground state properties, Nat. Commun. 15, Phys. Rev. A 108, 032406 (2023).
895 (2024). [28] F.J.GilVidalandD.O.Theis,Inputredundancyforpa-
[12] M. Cerezo, A. Arrasmith, R. Babbush, S. C. Benjamin, rameterizedquantumcircuits,Front.Phys.8,297(2020).
S. Endo, K. Fujii, J. R. McClean, K. Mitarai, X. Yuan, [29] M.Schuld,R.Sweke,andJ.J.Meyer,Effectofdataen-
L. Cincio, and P. J. Coles, Variational quantum algo- coding on the expressive power of variational quantum-
rithms, Nat. Rev. Phys. 3, 625–644 (2021). machine-learning models, Phys. Rev. A 103, 032430
[13] L.G.Valiant,Atheoryofthelearnable,Commun.ACM (2021).
27, 1134–1142 (1984). [30] N. M. Linke, D. Maslov, M. Roetteler, S. Debnath,
[14] M. J. Kearns and R. E. Schapire, Efficient distribution- C.Figgatt,K.A.Landsman,K.Wright,andC.Monroe,
free learning of probabilistic concepts, J. Comput. Syst. Experimentalcomparisonoftwoquantumcomputingar-
Sci. 48, 464–497 (1994). chitectures, Proc. Natl. Acad. Sci. 114, 3305 (2017).
[15] S. Aaronson, The learnability of quantum states, Proc. [31] A.RahimiandB.Recht,Randomfeaturesforlarge-scale
R. Soc. A: Math. Phys. Eng. Sci. 463, 3089 (2007). kernelmachines,inAdvancesinNeuralInformationPro-
[16] A. Rocchetto, Stabiliser states are efficiently PAC- cessing Systems, Vol. 20, edited by J. Platt, D. Koller,
learnable, Quantum Inf. Comput. 18, 541 (2018). Y.Singer,andS.Roweis(CurranAssociates,Inc.,2007).
[17] A. Rocchetto, S. Aaronson, S. Severini, G. Carvacho, [32] A. Rahimi and B. Recht, Weighted sums of random
D.Poderini,I.Agresti,M.Bentivegna,andF.Sciarrino, kitchen sinks: Replacing minimization with randomiza-
Experimental learning of quantum states, Sci. Adv. 5, tioninlearning,inAdvances in Neural Information Pro-
eaau1946 (2019). cessing Systems, Vol. 21, edited by D. Koller, D. Schu-
[18] H.-C.Cheng,M.-H.Hsieh,andP.-C.Yeh,Thelearnabil- urmans, Y. Bengio, and L. Bottou (Curran Associates,
ity of unknown quantum measurements, Quantum Inf. Inc., 2008).16
[33] A.RahimiandB.Recht,Uniformapproximationoffunc- of the 34th International Conference on Machine Learn-
tions with random bases, in 2008 46th Annual Allerton ing,ProceedingsofMachineLearningResearch,Vol.70,
ConferenceonCommunication,Control,andComputing edited by D. Precup and Y. W. Teh (PMLR, 2017) pp.
(2008) pp. 555–561. 1895–1904.
[34] S. Boyd and L. Vandenberghe, Interior-point methods, [42] P.L.BartlettandS.Mendelson,RademacherandGaus-
in Convex Optimization (Cambridge University Press, sian complexities: risk bounds and structural results, J.
2004) p. 561–630. Mach. Learn. Res. 3, 463–482 (2002).
[35] A. P´erez-Salinas, A. Cervera-Lierta, E. Gil-Fuster, and [43] S.M.Kakade,K.Sridharan,andA.Tewari,Onthecom-
J.I.Latorre,Datare-uploadingforauniversalquantum plexityoflinearprediction: Riskbounds,marginbounds,
classifier, Quantum 4, 226 (2020). and regularization, in Advances in Neural Information
[36] M. Cerezo, M. Larocca, D. Garc´ıa-Mart´ın, N. Diaz, ProcessingSystems,Vol.21,editedbyD.Koller,D.Schu-
P. Braccia, E. Fontana, M. S. Rudolph, P. Bermejo, urmans, Y. Bengio, and L. Bottou (Curran Associates,
A. Ijaz, S. Thanasilp, E. R. Anschuetz, and Z. Holmes, Inc., 2008).
Does provable absence of barren plateaus imply classi- [44] M. Ledoux and M. Talagrand, Probability in Banach
cal simulability? Or, why we need to rethink variational Spaces (Springer Berlin Heidelberg, 1991).
quantum computing (2023), arXiv:2312.09121 [quant- [45] M. Mohri, A. Rostamizadeh, and A. Talwalkar, Foun-
ph]. dations of Machine Learning, 2nd ed. (The MIT Press,
[37] M. Hinsche, M. Ioannou, A. Nietner, J. Haferkamp, 2018).
Y. Quek, D. Hangleiter, J.-P. Seifert, J. Eisert, and [46] A. M. Childs and N. Wiebe, Hamiltonian simulation us-
R. Sweke, One T gate makes distribution learning hard, ing linear combinations of unitary operations, Quantum
Phys. Rev. Lett. 130, 240602 (2023). Inf. Comput. 12 (2012).
[38] M. Cerezo, A. Sone, T. Volkoff, L. Cincio, and P. J. [47] E. Gil-Fuster, J. Eisert, and V. Dunjko, On the expres-
Coles, Cost function dependent barren plateaus in shal- sivity of embedding quantum kernels, Mach. Learn. Sci.
low parametrized quantum circuits, Nat. Commun. 12 Technol. 5, 025003 (2024).
(2021). [48] E. Gil-Fuster, J. Eisert, and C. Bravo-Prieto, Under-
[39] H.-Y.Huang,R.Kueng,andJ.Preskill,Predictingmany standing quantum machine learning also requires re-
properties of a quantum system from very few measure- thinking generalization, Nat. Commun. 15 (2024).
ments, Nat. Phys. 16, 1050 (2020). [49] M. C. Caro, E. Gil-Fuster, J. J. Meyer, J. Eisert, and
[40] N. Guo, F. Pan, and P. Rebentrost, Estimating proper- R.Sweke,Encoding-dependentgeneralizationboundsfor
tiesofaquantumstatebyimportance-sampledoperator parametrized quantum circuits, Quantum 5, 582 (2021).
shadows (2023), arXiv:2305.09374 [quant-ph]. [50] S.Jerbi,L.J.Fiderer,H.PoulsenNautrup,J.M.Ku¨bler,
[41] J. M. Kohler and A. Lucchi, Sub-sampled cubic reg- H.J.Briegel,andV.Dunjko,Quantummachinelearning
ularization for non-convex optimization, in Proceedings beyond kernel methods, Nat. Commun. 14, 517 (2023).17
Appendix A: Sampling and estimation methods on PQMs
1. Direct sampling-based estimation
The most straightforward method is to generate estimations by directly conducting measurements on the target
observable. Plugging in the eigendecomposition of the observable O, i.e., O =
(cid:80)K λ(k)(cid:12) (cid:12)λ(k)(cid:11)(cid:10) λ(k)(cid:12)
(cid:12) in f(x) =
k=1
tr(ρ(x)O) yields
(cid:88)K (cid:68) (cid:12) (cid:12) (cid:69)
f(x)= λ(k) λ(k)(cid:12)ρ(x)(cid:12)λ(k) , (A1)
(cid:12) (cid:12)
k=1
where 0 ≤ (cid:10) λ(k)(cid:12) (cid:12)ρ(x)(cid:12) (cid:12)λ(k)(cid:11) ≤ 1 ∀k, λ(k) ∈ R, and (cid:80)K (cid:10) λ(k)(cid:12) (cid:12)ρ(x)(cid:12) (cid:12)λ(k)(cid:11) = 1. The random measurement processes
k=1
of ρ(x) in the eigenbasis (cid:12) (cid:12)λ(k)(cid:11) can be modelled as sampling of eigenvalue λ(k) from the associated probability
distribution, i.e., λ∼p (λ) with λ∈Λ={λ(k)}K and p (λ)=⟨λ|ρ(x)|λ⟩.
x k=1 x
Given N i.i.d. measurement outcomes {λ }Ns , one could estimate f(x) by the empirical mean
s i i=1
1
(cid:88)Ns
y¯ = λ . (A2)
D N i
s
i=1
where we have implictly assumed the dependence of y¯ on x, i.e., y¯ ≡ y¯ (x). The finite-measurement-outcome
D D D
mean y¯ is an unbiased estimator of f(x)
D
f(x)=E [y¯ |x] (A3)
y¯D D
with variance σ2 =σ2 /N .
y¯D|x λ|x s
It is however generally hard to measure ρ(x) in the eigenbasis of the observable. In typical scenarios, one would
normally consider a linear combination of M Pauli observables P , i.e., O = (cid:80)M a P with a ∈ R, and the eigen-
i i=1 i i i
basis of such an observable is non-trivial to find. To estimate the original observable expectation value, one will
typically measure the expectation value of ρ(x) against each Pauli observable and then linearly combine them with
the associated weights a
i
M
(cid:88)
tr(ρ(x)O)= a tr(ρ(x)P ). (A4)
i i
i=1
While each Pauli estimator is unbiased for the associated Pauli observable, the joint estimators of tr(ρ(x)O) con-
structed by summing these Pauli estimators need not be unbiased.
2. Shadow-based estimation
Alternatively, estimating measurement results using classical shadows [39] also introduces structural noise to our
framework,allowingtrainingbasedonrandommeasurementsasopposedtodirectmeasurements,whichmaybemuch
more costly in practice.
Recallthatintheclassicalshadowsprotocol,toestimatepropertiesofaquantumstateρ,onefirstevolvesthequan-
tumstateusingaunitaryU sampledfromatomographicallycompleteunitaryensembleU. Itperformsmeasurements
(cid:104) (cid:105)
on the computational basis |ˆb⟩ ∈ {0,1}n and the bit-string b is observed with probability Pr ˆb=b = ⟨b|UρU†|b⟩.
From the measurement outcome, one can construct a classical snapshot ρˆ= M−1(U†|ˆb⟩⟨ˆb|U) where we apply an in-
U
vertedquantumchannelM−1 determinedbytheunitaryensembleU. Thisclassicalsnapshotisanunbiasedestimator
U
for the density matrix, i.e., ρ=E [ρˆ].
U,|ˆb⟩
The classical snapshot is a good estimator for the parameterized quantum state when applied to a suitable set of
Hermitian observables {H ,H ,··· ,H }. For example, the classical snapshots can be used to estimate the function
1 2 M
f(x) = tr(ρ(x)O) with O = (cid:80)M a P , i.e., y¯ = tr(ρ¯(x)O) where ρ¯ = 1 (cid:80)Ns ρˆ is the averaged sum of N
i=1 i i CS Ns i=1 i s
classical snapshots. It is straightforward to show that such an estimator is an unbiased estimator of f(x)
f(x)=E [y¯ |x]. (A5)
y¯CS CS
Other unbiased shadow estimation techniques based on random sampling such as operator shadows [40] can also be
used to produce unbiased estimators for the quantum models.18
Appendix B: Details on the learning algorithm
1. Intuitive understanding on the working principle of Algorithm 1
Algo. 1 works similarly to gradient descent algorithm. Take the following empirical risk
R(cid:98)=
2N1
(cid:88)N1
|y
j
−u(⟨w,ϕ(x j)⟩)|2 (B1)
1
j=1
We can then upper bound the gradient as follows:
∂R(cid:98) L
(cid:88)N1
≤ (u(⟨w,ϕ(x )⟩)−y )ϕ(x ) (B2)
∂w N j j j
1
j=1
Byintroducingkernelizationtolinearmodels,onecansetw
=(cid:80)N1
α ϕ(x ). Settingtheupperboundasthegradient
i=1 i i
step with a learning rate of 1 , we see that in each step, the value of α has an update of
L2 j
(cid:16) (cid:17)
u
(cid:80)N1
α k(x ,x ) −y
∆α = u(⟨w,ϕ(x j)⟩)−y j = u(⟨w,ϕ(x j)⟩)−y j = i=1 i i j j , (B3)
j LN LN LN
1 1 1
giving us the update in Algo. 1.
Due to the initialization of parameters to zero, which is akin to interior point methods, the algorithm provides
implicit norm regularization of the parameters. This property, in addition to the limitation of gradient steps taken,
provides the theoretical guarantees as shown in Thm. 1, which we show in the following section.
2. Proof of Theorem 1
WearegiventheoutputrangeY =[−∆,∆]. LetΓ¯ := 1 (cid:80)N1 (y¯−u(⟨w,ϕ(x )⟩+ξ(x )))ϕ(x ),Γ¯t := 1 (cid:80)N1 (y¯−
N1 i=1 i i i i N1 i=1 i
u(⟨wt,ϕ(x )⟩))ϕ(x ) and χ:= 1 (cid:80)N1 ξ(x )2. We apply the Lem. 11 from Ref. [20] to the empirical mean y¯.
i i N1 i=1 i
Lemma B.1. At iterative t in Algo. 1, suppose ∥wt−w∥≤B for B >1, then if ∥Γ¯∥≤ϵ <1, then
4
(cid:18)(cid:18) (cid:19) (cid:19)
2 √
∥wt−w∥2−∥wt+1−w∥2 ≥λ −λ Rˆ(ht)−2∆ χ−2Bϵ −λϵ2−2∆λϵ , (B4)
L 4 4 4
where λ is the regularization parameter.
Using Lem. B.1 with λ=1/L, we have
(cid:32) (cid:33)
1 Rˆ(ht) √ ϵ2 2∆ϵ
∥wt−w∥2−∥wt+1−w∥2 ≥ −2∆ χ−2Bϵ − 4 − 4 . (B5)
L L 4 L L
For each iteration t of Algo. 1, one of the following two cases needs to be satisfied
Bϵ
Case 1:∥wt−w∥2−∥wt+1−w∥2 > 4 (B6)
L
Bϵ
Case 2: ∥wt−w∥2−∥wt+1−w∥2 ≤ 4. (B7)
L
Let t∗ be the first iteration where Case 2 holds. We show that such an iteration exists. Assume the contradictory,
that is, Case 2 fails for each iteration. Since ∥w0−w∥2 =∥0−w∥2 ≤B2 by assumption, however,
2 2
B2 ≥∥w0−w∥2 ≥∥w0−w∥2−∥wk−w∥2 (B8)
2 2 2
k−1
=(cid:88)(cid:0) ∥wt−w∥2−∥wt+1−w∥2(cid:1) ≥ kBϵ 4, (B9)
2 2 L
t=019
for k iterations. Hence, in at most T ≥ BL iterations Case 1 will be violated and Case 2 will have to be true.
ϵ4
Combining Eq. (B5) and Case 2 yields
√
Rˆ(ht)≤2L∆ χ+3BLϵ +ϵ2+2∆ϵ (B10)
4 4 4
What remains to be done is to bound χ and to obtain N in terms of ϵ . Similar to Ref. [20], we could bound χ using
s 4
Hoeffding’s inequality
 (cid:115) 
√ √ log(1/δ)
χ≤ ϵ 1+OM 4
N
, (B11)
1
and therefore by observing that B ∝∆, we have
 (cid:115) 
√ log(1/δ)
Rˆ(ht)≤OL∆ ϵ 1+LM 4
N
+BLϵ 4. (B12)
1
By definition, we have that (y¯ −u(⟨w,ϕ(x )⟩+ξ(x )))ϕ(x ) are zero mean i.i.d. random variables with bounded
i i i i
norm, so we can use the following vector Bernstein inequality to bound the norm of Γ¯.
Lemma B.2 (Vector Bernstein inequality; Lem. 18, [41]). Let x ,...,x be independent zero-mean vector-valued
1 N
random variables with common dimension d and they are uniformly bounded and also the variance is bounded above
E[∥x ∥2]≤σ2. Let
i
(cid:12)(cid:12) (cid:12)(cid:12)
1 (cid:12)(cid:12)(cid:88)N (cid:12)(cid:12)
z = (cid:12)(cid:12) x (cid:12)(cid:12) . (B13)
N (cid:12)(cid:12) i(cid:12)(cid:12)
(cid:12)(cid:12) (cid:12)(cid:12)
i=1 2
Then we have for 0≤ϵ≤σ2/µ
(cid:18) Nϵ2 1(cid:19)
P[∥z∥≥ϵ]≤exp − + . (B14)
8σ2 4
Before using the vector Bernstein inequality, we need to compute the variance of ∥(y¯− E [y¯|x])ϕ(x)∥ where
y¯
E y¯[y¯|x]=u(⟨w,ϕ(x)⟩+ξ(x)),i.e.,E D¯[∥(y¯−E y¯[y¯|x])ϕ(x)∥2]asE D¯[∥(y¯−E y¯[y¯|x])ϕ(x)∥]=0bydefinition. Therefore,
E D¯(cid:2) ∥(y¯−E y¯[y¯|x])ϕ(x)∥2(cid:3) =E D¯(cid:2) (y¯−E y¯[y¯|x])2∥ϕ(x)∥2(cid:3) (B15)
≤E D¯(cid:2) (y¯−E y¯[y¯|x])2(cid:3) (B16)
=E D¯(cid:2) y¯2−2y¯E y¯[y¯|x]+E y¯[y¯|x]2(cid:3) (B17)
=E E (cid:2) y¯2−2y¯E [y¯|x]+E [y¯|x]2(cid:3) (B18)
x y¯|x y¯ y¯
=E (cid:2)E [y¯2|x]−E [y¯|x]2(cid:3) (B19)
x y¯ y¯
(cid:104) (cid:105)
=E σ2 (B20)
x y¯|x
(cid:104) (cid:105)
E σ2
x y|x
= (B21)
N
s
We can therefore bound ∥Γ¯∥ by letting σ = E x[σ y2 |x]
Ns
 
N N ϵ2 1
P(∥Γ¯∥≤ϵ 4)≥1−exp− 8E1
(cid:104)
σs 24
(cid:105)
+ 4. (B22)
x y|x
Foraprobabilityof1−δ,numberoftrainingsamplesN ,andnumberofmeasurementrepetitionsN ,wecanachieve
1 s
∥Γ¯∥≤ϵ with
4
(cid:118)
(cid:117) (cid:117) (cid:116)8E x(cid:104) σ y2 |x(cid:105) (cid:18) (cid:18) 1(cid:19) 1(cid:19)
ϵ = log + . (B23)
4 N N δ 4
1 s
To bound R(ht∗) with Rˆ(ht∗), we require the following results:20
Theorem B.1 (Thm. 8, [42]; Formulation of Thm. 21, [20]). Let L:Y′×Y →R be a loss function upper bounded
+
by b>0 and such that for any fixed y, y′ →L(y′,y) is L-Lipschitz for some L>0. Given function class F ⊂(Y′)X,
for any f :X →Y′ ∈F, and for any sample S from distribution D of size N,
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:114)
(cid:12) (cid:12) (cid:12)E D[L(f(x),y)]− N1 (cid:88) L(f(x),y)(cid:12) (cid:12) (cid:12)≤4LR N(F)+2b lo 2g N2/δ , (B24)
(cid:12) (x,y)∈S (cid:12)
where R (H) is the expected value of the empirical Rademacher complexity of the function class F over all samples
N
of size N.
Plugging the generalization, we have the following result for all hypotheses h∈H.
(cid:115)
log(cid:0)2(cid:1)
R (h)≤Rˆ(h)+8∆R (H)+2∆2 δ . (B25)
expl N1 2N
1
Next, to compute the empirical Rademacher complexity of H, we use the following results:
Theorem B.2 (Lem. 22, [42] or Thm. 1, [43]; Formulation of Thm. 22, [20]). Let X be a subset of an inner product
space such that for all x∈X, ∥x∥ ≤X, and let W ={x→⟨w,x⟩,∥w∥ ≤W}. Then it holds that
2 2
XW
R (W)≤ √ , (B26)
N
N
Lemma B.3 (Talagrand’s lemma, Cor. 3.17, [44]; Formulation of Lem. 5.7, [45]). Let Φ : R → R be a L-Lipschitz
function. Then for any hypothesis set F of real-valued functions, the following holds:
R (Ψ◦F)≤LR (F), (B27)
N N
Noting that our hypothesis class H in question is a linear class with a L-Lipschitz function applied to it, with the
constraints ∥w∥ ≤B and ∥ϕ(x)∥ ≤1 combining the above two results, we get
2 2
BL
R (H)≤ √ , (B28)
N1
N
1
Finally, we can make use of Rademacher complexity to bound R(ht)
 (cid:115) 
(cid:114)
1 log(1/δ)
R expl(ht∗ )≤Rˆ(ht∗ )+OBL∆
N
+∆2
N
 (B29)
1 1
 (cid:115) (cid:115) (cid:115) 
(cid:114) (cid:18) (cid:18) (cid:19)(cid:19)
√ log(1/δ) 1 σ¯ 1 log(1/δ)
=OL∆ ϵ 1+L∆M 4
N
+BL∆
N
+BL
N N
log
δ
+∆2
N
 (B30)
1 1 1 s 1
(cid:104) (cid:105)
where σ¯ = E σ2 . The last step is to show that we can indeed find a hypothesis satisfying the above guarantee.
x y|x
Using the Hoeffding inequality and union bound, one could show that N
≥O(cid:0)
N
∆2log(cid:0)T (cid:1)(cid:1)
validation data points
2 1 δ2
suffice to choose the optimal hypothesis ht∗ at time step t∗ that satisfies Eq. (B30).
Appendix C: Bias-variance-noise decomposition
For a given training dataset S = (x ,y¯)N1 , one would obtain an associated trained model h (x) by optimizing
i i i=1 S
the empirical risk R(cid:98)(h) using some optimization methods such as the gradient descent algorithm. Further, different
training datasets S′ would yield different trained models h (x), each associated with explicit risk R (h ) and
S′ expl S
R (h ),respectively. Thisobservationbegsthequestionofhowthesetrainedmodelsarerelatedtoeachotherand
expl S′
the target concept c(x)=E [y¯|x].
y¯
To address the above-mentioned questions, we introduce a machine learning concept known as the bias-variance
trade-off. The bias of machine learning models informs their consistent errors and it is defined as
Bias :=E [h (x)]−f(x). (C1)
S S S21
Since f(x) is independent of S, one could express the bias as Bias =E [h (x)−f(x)]. Low bias suggests that on
S S S
average the trained models h (x) are close to the target function, and typically machine learning models with larger
S
modelclasssizeswillhavelowerbias. Yet,modelswithlowbiasneednotbeoptimalastheytendtobemoresensitive
to variations in training data; such models are said to have high variance where the variance of the model is defined
as
(cid:104) (cid:105)
Var :=E (E [h (x)]−h (x))2 . (C2)
S S S S S
It should be clear from the definition that the bias and variance are dependent on the complexity of the hypothesis
class, the number of training data points N and the number of random labels N .
1 s
The above-mentioned bias-variance trade-off can be studied by analysing the average behaviour of the trained
models under the constraints of finite training data points and labels, which we capture by taking the expectation
value over all possible training data sets S with the same N and N , which we denote E [R (h )] where
1 s S|N1,Ns impl S
R impl(h S)=E D¯[(h S(x)−y¯)2] is the implicit risk of h S(·) as defined in Eq. (8).
This averaged risk quantifies the overall performance of the hypothesis class H under all realization of training
datasetsofsizeN ,withempiricalmeansestimatedusingN randomlabels. Furthermore,R (h)=R (h)+σ¯
1 s impl expl NS
implies
E [R (h )]=E [R (h )]+σ¯ , (C3)
S|N1,Ns impl S S|N1,Ns expl S NS
(cid:104) (cid:105) (cid:104) (cid:105)
where E [R (h )] is the averaged explicit risk and R (E [y¯|x]) := σ¯ = E σ2 = 1 E σ2 is
S|N1,Ns expl S impl y¯ NS x y¯|x Ns x y|x
the irreducible error that lower bounds the implicit risk on unseen sample. Note that in the asymptotic regime
(N → ∞), the variance goes to 0 as the finite data sampling noise diminishes, and one would consistently obtain
1
the optimal model in H that achieves the optimal explicit risk R (h). In addition, the strength of the irreducible
expl
error is controllable by the number of random samples N . In particular, σ¯ → 0 as N → ∞ and therefore
s NS s
E [R (h )]→E [R (h )].
S|N1,Ns→∞ impl S S|N1,Ns→∞ expl S
We can then further decompose the explicit risk averaged over all datasets.
(cid:104) (cid:105)
E [R (h )]=E (h (x)−c(x))2 (C4)
S expl S x,S S
(cid:104) (cid:105)
=E (h (x)−E [h (x)]+E [h (x)]−c(x))2 (C5)
x,S S S S S S
(cid:104) (cid:105) (cid:104) (cid:105)
=E (E [h (x)]−c(x))2 +E (E [h (x)]−h (x)])2 (C6)
x S S x,S S S S
=E (cid:2) Bias2(cid:3) +E [Var ]. (C7)
x S x S
In summary, we have
E [R (h )]=E (cid:2) Bias2(cid:3) +E [Var ], and (C8)
S|N1,Ns expl S x S x S
E [R (h )]=E (cid:2) Bias2(cid:3) +E [Var ]+σ¯ . (C9)
S|N1,Ns impl S x S x S Ns
Appendix D: Random Fourier feature models
1. Classical approximation of PQC functions
LetF andϕ (x)bethePQCconceptclassandfeaturemapasdefinedinEq.(21)andEq.(28),respectively. In
U,O F
addition, let k (x,x′) = ⟨ϕ (x),ϕ (x′)⟩ be the kernel of ϕ (x). Our goal of learning PQCs corresponds to taking
F F F F
F as our concept class. It is a still-unresolved question which PQCs provably give rise to function families that
U,O
can or cannot be well approximated by kernel-based function families, but it is known that PQCs exist which cannot.
Nonetheless,weofferagenericPQCconstructionwhosefunctionsareguaranteedtobewell-approximatedbyakernel-
based hypothesis family. The recipe we propose does not exactly match the typical PQCs used by practitioners, but
it is generic enough that it may become useful in the future. The construction relies on the Linear Combination of
Unitaries (LCU) framework [46] and resembles constructions proposed in e.g. Refs. [47, 48].
Let k be a kernel that can be well-approximated as an Embedding Quantum Kernel (EQK) [47] on n qubits,
F
meaning there exists a data-dependent unitary gate U(x) such that
sup
(cid:12)
(cid:12)k
F(x,x′)−|⟨0|U†(x)U(x′)|0⟩|2(cid:12) (cid:12)2
≤ϵ (D1)
x,x′∈X22
foralmosteveryx,x′ ∈X. Then, givenN ∈N, avectorofrealnumbersα=(α )N , and asetofinputsx ,...,x ,
i i=1 1 N
consider a PQC over n+⌈log(N)⌉ qubits. The circuit starts on the all-0 state, and the unitary U(x) is applied on
the first n-qubits. In parallel, we perform amplitude encoding of α on the other ⌈log(N)⌉ qubits of the auxiliary
register. Next, we define a controlled operation CU which, conditional on the auxiliary register being in state |i⟩ for
i
i∈{1,...,N}appliesU†(x )onthemainregister. Itfollowsthatthesecontrolledoperationscommute[CU ,CU ]=0.
i i j
We need only apply all such controlled gates in sequence, then:
(cid:81)N
CU , and measure the probability of the first
i=1 i
n-qubits being in the all-0 state at the end (together with a diagonal observable on the auxiliary register that takes
care of the negative signs in α). For notational ease, we do not explicitly write the extra observable on the auxiliary
register, and we write only the projector on the all-0 state. This means that the functions can take negative values
even though they are defined as the absolute square of a complex number. This way, given α and x,x ,...,x we
1 N
have defined a PQC in the form of a unitary W(α,x,(x ) ), and produces as output a function in the kernel-based
i i
hypothesis family:
N
(cid:88)
|⟨0|W(α,x,(x ) )|0⟩|2 = α |⟨0|U†(x)U(x′)|0⟩|2. (D2)
i i i
i=1
From the ϵ-approximation of the initial kernel k via the EQK defined by U, it follows that each function of the form
F
(cid:80)N
α k(x,x ) can be approximated by a function in F , by taking the same α vector and the same set of
i=1 i i W,|0⟩⟨0|
inputs (x ) . Without loss of generality, we assume the parameter vector α has bounded norm ∥α∥2 ≤B:
i i 2
(cid:12) (cid:12)(cid:32) (cid:88)N (cid:33) (cid:12) (cid:12)2
sup(cid:12) α k (x,x ) −|⟨0|W(α,x,(x ) )|0⟩|2(cid:12) (D3)
(cid:12) i F i i i (cid:12)
x∈X(cid:12) (cid:12)
i=1
(cid:12) (cid:12)2
=sup(cid:12) (cid:12)(cid:88)N
α (cid:0) k (x,x )−|⟨0|U†(x)U(x
)|0⟩|2(cid:1)(cid:12)
(cid:12) (D4)
(cid:12) i F i i (cid:12)
x∈X(cid:12) (cid:12)
i=1
N
≤∥α∥2(cid:88) sup(cid:12) (cid:12)k F(x,x i)−|⟨0|U†(x)U(x i)|0⟩|2(cid:12) (cid:12)2 (D5)
x∈X
i=1
≤B2ϵ (D6)
Altogether,thisrecipeallowsustoconstructaPQCwhoseassociatedfunctionfamilyisthesameasagivenkernel-
based function family. For Algo. 1 to succeed as a classical learner of this function family, then, we need only be able
toevaluatethekernelk efficientlyclassically. Itisknownthatthecomplexityofevaluatingthetrigonometrickernels
F
that result from quantum embeddings is upper-bounded by the cardinality of the frequency spectrum Ω˜ arising from
the encoding strategy.
2. Approximating PQCs with random Fourier features
IfthePQCU(x,θ)issuchthatitscorrespondingfeaturemapisofpolynomialdimension|Ω˜|∈O(poly(m)),thenwe
know we can classically express the corresponding function exactly: ⟨0|U†(x,θ)OU(x,θ)|0⟩ = ⟨w ,ϕ (x)⟩, where
F F
the real-valued vector w is efficiently storable in classical memory. Refs. [8, 49] offer a discussion on what encoding
F
strategies connected to families of PQCs will result in Fourier spectra of polynomial size. It is nevertheless known
that many natural encoding strategies result in an exponentially large Fourier spectrum, where we cannot rely on
an exact realization of the PQC function as a classical linear map. Some of these cases have been recently analyzed
in Refs. [25, 26] under the lens of Random Fourier Features (RFF) [31]. The main idea in RFF is to efficiently
approximate the high-dimensional inner product ⟨w ,ϕ (x)⟩ by sampling a few of its dominant terms.
F F
Forinstance,consideranencodingstrategywhichgivesrisetoanexponentiallylargeFourierspectrum|Ω|∝exp(m).
Then, the inner product
2|Ω|−1
(cid:88)
⟨w,ϕ (x)⟩= w ϕ (x) (D7)
F j F,j
j=1
cannotbeclassicallyevaluatedingeneralduetoitscontainingmanyterms. NowconsideraspecificPQCU(x,θ)with
this encoding strategy, but which is structured enough that we know that some entries of the weight vector are more
dominant than others, in that they contribute more to the sum. One way to capture this would be by considering a23
probability distribution over the Fourier spectrum P(Ω), where the probability associated with a specific frequency
is proportional to the magnitude squared of its coefficients p(ω) = a2 +b2. Without loss of generality, we assume
ω ω
thecoefficientsarealreadyproperlynormalized. Then, whattheRFFalgorithmprescribeswedoissampleanumber
D of frequencies from such a distribution ω˜ ∼ PD, and then consider the classical efficient feature map ϕ (x)
RFF
consisting of only those frequencies:
cos⟨ω˜ ,x⟩
1
sin⟨ω˜ ,x⟩
 1 
1  . 
ϕ RFF(x)= √
D


. .  . (D8)
cos⟨ω˜ ,x⟩
D
sin⟨ω˜ ,x⟩
D
The sampled frequencies ω˜ are all in the original Fourier spectrum ω˜ ∈ Ω, so ϕ (x) is just an appropriately
i RFF
renormalized subvector of the full ϕ (x). This smaller feature map gives rise to the hypothesis family:
F
H ={u(⟨w,ϕ (x)⟩)|w ∈RD}. (D9)
RFF RFF
Then, if the PQC function is such that it can in principle be approximated as a linear map of rank D [50], it follows
from Refs. [24, 25, 31] that the RFF hypothesis family should contain a good approximation to the function. In the
context of this work, this means that Algo. 1 should be able to learn the initial PQC function by using H as a
RFF
hypothesis class.
The remaining question is, again, how to specify the right H for a given PQC of interest, modelled by the
RFF
function family F . The ultimate general-case answer is not fully resolved [25], but we provide a recipe to, given
U,O
an RFF-approximable EQK k, construct a corresponding PQC.
Letkbeakernelthatcanbeapproximatedastheinnerproductofafeaturemapϕofpolynomialsize(inparticular,
this could be the randomized feature map produced by the RFF algorithm):
sup
|k(x,x′)−⟨ϕ(x),ϕ(x′)⟩|2
≤ϵ, (D10)
x,x′∈X
foralmosteveryx,x′ ∈X. LetfurtherU(x)beaquantumembeddingthatimplementsthefeaturemapϕ(x)(w.l.o.g.
we take ϕ to be properly normalized):
sup (cid:12) (cid:12)⟨0|U†(x)U(x′)|0⟩|2−⟨ϕ(x),ϕ(x′)⟩(cid:12) (cid:12)2 ≤ϵ′. (D11)
x,x′∈X
Then the same LCU construction we used before also results in a PQC whose function family approximates the
function family of the RFF-based kernel, which in turn approximates the function family of the original kernel. With
triangular inequality, it follows that this PQC construction approximates the original kernel-based function family.
Since Algo. 1 can provably learn the kernel-based function family, it follows it can also learn this PQC family.
Appendix E: Proof of Lemma 1
To discuss the explicit risk of the ERM given the hypothesis class H in Eq. (45), we use the following result in
statistical learning theory:
Proposition E.1 (Prop. 4.1, [45]). Let D be a distribution over X ×Y. Let L : Y′×Y → R be a loss function.
+
Considering a hypothesis class F that maps X to Y′, For any sample S from distribution D, for hypotheses f ∈ F,
the following holds:
(cid:12) (cid:12)
(cid:12) (cid:12)
E D[L(f SERM(x),y)]− fi ∈n Ff E D[L(f(x),y)]≤2 fsu ∈Fp(cid:12) (cid:12)
(cid:12)
(cid:12)E D[L(f(x),y)]− |S1
|
(x(cid:88) ,y)∈SL(f(x),y)(cid:12) (cid:12)
(cid:12)
(cid:12). (E1)
Considering the implicit loss function ℓ for the loss function L in the above proposition, we get
impl
R impl(hE SRM)− inf R impl(h)≤2sup|R impl(h)−R(cid:98)(h)|. (E2)
h∈H h∈H24
Noting that R (h)=R (h)+R (E [y¯|x]), we can see that
impl expl impl y¯
R expl(hE SRM)− inf R expl(h)≤2sup|R impl(h)−R(cid:98)(h)|. (E3)
h∈H h∈H
By definition, we know that
inf R expl(h)= inf E D¯[(h(x)−c(x))2]≤E D¯[(⟨w,ϕ(x)⟩−⟨w,ϕ(x)⟩+ξ(x))2]=E D¯[ξ(x)2]≤ϵ 1. (E4)
h∈H h∈H
Hence we see that
R expl(hE SRM)≤ϵ 1+2sup|R impl(h)−R(cid:98)(h)|. (E5)
h∈H
We now find error bounds on the right-hand side of the previous proposition. To do so, we require the following
results obtainable by combining Thm. 8 and Lem. 22 from Ref. [42]:
Theorem E.1 (Thm. 11.11, [45]). Given distribution D over X ×Y, let k : X ×X → R be a positive semidefinite
kernel, Φ:X →Hbethefeaturemapassociatedwithkernelk, andhypothesisclassH={x→⟨w,ϕ(x)⟩,∥w∥H ≤Λ}.
Assume there exists r,M > 0 such that k(x,x) ≤ r2 and for all hypotheses h : X → Y′ ∈ H and all (x,y) ∈ D,
|h(x)−y|≤M. Then for any sample S from D of size N, the generalization bound is as follows:
(cid:12) (cid:12)  (cid:115) 
(cid:12) (cid:12) (cid:12) E (cid:2) |h(x)−y|2(cid:3) − 1 (cid:88) |h(x)−y|2(cid:12) (cid:12) (cid:12)∈OM √Λr +M2 log1 δ . (E6)
(cid:12)(x,y)∼D N (cid:12) N N
(cid:12) (x,y)∈S (cid:12)
Plugging in our error losses and range of H, we note that Λ,M ∈ O(D) and r = 1. We then obtain the following
generalization bound for H.
 (cid:115) 
log1
|R impl(h)−R(cid:98)(h)|∈OD2
N
δ , (E7)
1
Note that this result yields a better result than the Rademacher-based generalization bound proposed by Caro et al.
[49] by a logarithmic factor if we use the entire Fourier spectrum instead of RFF. We can then write the explicit risk
for the ERM as follows:
 (cid:115) 
log1
R expl(hE SRM)∈Oϵ 1+D2
N
δ . (E8)
1