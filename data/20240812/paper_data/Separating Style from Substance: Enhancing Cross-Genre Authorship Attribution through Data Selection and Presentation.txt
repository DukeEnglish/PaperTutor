Separating Style from Substance: Enhancing Cross-Genre Authorship
Attribution through Data Selection and Presentation
StevenFinckeandElizabethBoschee
InformationSciencesInstitute,UniversityofSouthernCalifornia
{sfincke,boschee}@isi.edu
Abstract one such genre. In this context, we propose
SADIRI (Stylometric Authorship Discernment &
Thetaskofdecidingwhethertwodocuments
InterpretationforRealisticInputs)1,anauthorship
arewrittenbythesameauthorischallenging
attributionsystemdesignedforrobustperformance
for both machines and humans. This task is
in a wide variety of genres, including the cross-
even more challenging when the two docu-
ments are written about different topics (e.g. genre setting, despite the typically single-genre
baseballvs.politics)orindifferentgenres(e.g. natureofavailableauthorshiptrainingdata.
a blog post vs. an academic article). For ma- Since each of our training authors participate
chines,theproblemiscomplicatedbytherel-
in only one data source, often writing on a small
ativelackofreal-worldtrainingexamplesthat
setofrelatedtopics,weseeasignificanttechnical
cross the topic boundary and the vanishing
challengeinpreventingthemodelfromoverlyasso-
scarcity of cross-genre data. We propose tar-
ciatingauthoridentitywithtopic,genre,ordomain.
getedmethodsfortrainingdataselectionand
anovellearningcurriculumthataredesigned Tothisend,weselectandarrangeourtrainingdata
to discourage a model’s reliance on topic in- toreduceSADIRI’sopportunitiestoformpositive
formationforauthorshipattributionandcorre- associationsbetweenauthorshipandtopicalconsis-
spondinglyforceittoincorporateinformation
tencyandinsteadtofocusiton“harder”examples—
morerobustlyindicativeofstylenomatterthe
specificallydefinedhereasthosewherethemodel
topic. Theserefinementsyielda62.7%relative
mustlearnrealstylisticinformation(notjusttopic
improvementinaveragecross-genreauthorship
similarity)tosucceed. Toprovidehardpositives,
attribution,aswellas16.6%intheper-genre
condition. weselecttrainingdocumentsforthesameauthor
to be topically dissimilar. Inversely, to provide
1 Introduction
hard negatives, we train SADIRI to differentiate
betweendifferentauthorswithinpoolsofsimilar
Automaticauthorshipanalysissystemshavemade
documents. These techniques for data selection
significant advances over the past years. Various
andpresentationprovidesignificantperformance
tasksrequirematchingdocumentsfromthesame
gains over state-of-the-art approaches, especially
author. We focus here on the task of authorship
inthecross-genrecontext.
attribution, where a set of documents by a single
authorservesasaquery,andthegoalistoidentify
2 TechnicalApproach
additionaldocumentsbythatsameauthor(thetar-
gets)fromalargedocumentcollection(calledthe
2.1 Modelinfrastructure
haystack). Variation in topic, genre, and domain
increasethedifficultyoftheattributiontask. ThecoreoftheSADIRIsystemisafine-tunedLM
Wereporthereonresultsusingthenewlycreated that produces a vector for a single document. e
HIATUS Research Set (HRS) authorship test set. thenapplycosinesimilaritybetweenthesevectors
This dataset provides both a per-genre condition, to retrieve same-author pairs. This approach is
wherequeriesandtargetsarefromthesamegenre, inspiredbyLUAR(Sotoetal.,2021),butsimpli-
as well as a more difficult cross-genre setting, fiedtoproducevectorsforsingledocuments. We
wherethequeriesandtargetsarefromseparategen- useRoBERTa-large(Liuetal.,2019)asourbase
res. Wetrainonauthor-labeleddatacollectedfrom
1SadiriisaBikolwordwhichcanbetranslatedas“(be-
the Internet (e.g. Reddit, PubMed, GoodReads),
longingto)oneself”or“own”,representingthedistinctcore
where each training author participates in only ofeachauthor’slinguisticstyle.
4202
guA
9
]LC.sc[
1v29150.8042:viXramodel. Accordingly,weapplytheRoBERTatok- cosine distance as a reasonable proxy for topical
enizertothefulltextandtakethefirst512tokens, dissimilarity. Specifically,weextractSBERTvec-
reflectingRoBERTa’smaximuminputlength. The torsforallofagivenauthor’sdocuments,calculate
token sequence is fed into RoBERTa, the output the cosine similarities between them, and extract
ofthefinalhiddenlayerisextractedandthenthe thepairwiththelowestsimilarity. Ifthelowestco-
meaniscalculatedforthefullinputsequence. The sinesimilarityexceedsaprescribedceilingvalue,
outputvectorisproducedbyapplyingalineartrans- thepairisignored,andtheauthorisexcludedfrom
formtoreducedimensionalitybyafactorof2: for training. We have settled on 0.2 as our default
RoBERTa-large,thefinalhiddenlayerhasawidth SBERT cosine similarity ceiling but will discuss
of 768, and the output vector length is 384. We theimpactofthisparameterinSection4.3.1.
measurethedistancebetweenvectorswithcosine
2.3 Hardnegatives
similarity and train to minimize Supervised Con-
trastiveLoss(Khoslaetal.,2020)withrespectto SADIRI trainingbatcheseachcontain74authors,
ourauthorlabels. i.e. 74 document pairs. Each pair is selected to
We filter our training corpora to include only be internally topically dissimilar, as described in
documents with more than 350 words (to match the previous section, creating “hard positive” ex-
the configuration of the HRS test set). We then amples. However,withoutfurtherintervention,it
selectexactlytwodocumentsperauthortoinclude is likely that the negative examples derived from
in our training process; how these are selected is each batch (e.g. comparing document 1 from au-
describedinthenextsection. Theresultsreported thorAwithdocument2fromauthorB)willstillbe
throughout this paper are the average of scores fairly “easy”—on average, two randomly chosen
obtainedfrommodelsbuiltwithtwodifferentran- documentsfromlargeInternetcorporawillproba-
domizationseeds(42and1234). blybequitedistant(nomatterhowyoucalculate
We train with NVIDIA RTX A6000, which al- distance), and the decision that they are written
lowustoaccommodatevectorpairsfor74authors bydifferentauthorswillbesoeasythatthemodel
in each batch. However, we train with 4 GPU willnotbeforcedlearnfeaturesthatareeffective
nodesinparallelsothatthelossandgradientsfor in more challenging situations. To mitigate this,
all 4 batches of 74 are calculated separately but we would like all of the authors in a batch to be
are applied together. Each epoch contains all the similarinsomeway—makingthenegativeexam-
selectedtrainingdata. Wetrainforfourepochsand plesharder, andforcingthemodeltolearnbetter
selectthemodelthatperformsbestonourheld-out representationstocompensate. However,wecan-
validationdataset. not simply gather 148 similar documents (74*2),
as we have already forced our document pairs to
2.2 Hardpositives includetopicaldissimilarity! Forthesamereason,
representingindividualauthorswithanaverageof
We use two documents per author in training.
theirdocumentvectorsisproblematicasthepairs
When more than two are available, our baseline
aredistantbydesign.
approach is to select a document pair at random.
Wethereforedevelopanapproachwherewecre-
In this work, however, our objective is to encour-
ateclustersofauthorswhereonlyoneoftheirtwo
agerobustnessparticularlyinacross-genresetting.
documents is similar to others in the batch. That
To this end, we select the two most topically dis-
is,weformclustersinwhicheachauthorprovides
tantdocumentsinstead,producinga“hardpositive”
one document to the dense center and its respec-
trainingexamplethatwillideallyforcethemodel
tivehardnegativewhichfallsinthedispersedouter
tolearnelementsofstylisticsimilarityratherthan
reaches.3 We pre-specify the number of clusters
justtopicalsimilarity. Wealsoexcludeanyauthors
perbatchasahyperparameterC;wedefaulttofive
whosemost-distantdocumentpairisstill“toosim-
but explore this value in Section 4.3.1. To form
ilar”. Thisresultsinsignificantlylesstrainingdata
clusters, we represent each document with a vec-
seenbythemodel,but(aswewillshow)leadsto
tor(discussedbelow)andthenperformK-means
noticeablyimprovedperformanceinbothper-and
clusteringoverthesevectorsandextractaninitial
cross-genresettings.
WeuseSBERT2 (ReimersandGurevych,2019) v2
3Thedistributionresemblesadandelionmorethanabil-
2huggingface.co/sentence-transformers/all-mpnet-base- liardball.setofcentroids,enoughforallthebatches,i.e. # ifiedbackgroundcollection. Thiswasdoneinorder
batches*C.Intheeventthattwoinitialcentroids to be able to generate a large pool of documents
arefromthesameauthor,oneofthetwocentroids withcross-genreauthorshiplabels;thatis,theyhad
isshiftedtothenearestvectorfromanotherauthor each author create documents for more than one
toensurethatnoauthorisassociatedwithmultiple genre.
centroids. Training Data. We train with data from eight
Clustersarethenbuiltoutbyloopingrepeatedly sources,includingourversionsofReddit,anews
over the set of final centroids. At each step, we source(RealNews),andourversionofAmazonre-
identifythedocumentclosesttothegivencentroid views. AdditionaldetailsareprovidedinAppendix
fromtheremainingpoolofunassignedauthorsand B. None of our data sources overlap with those
placethatauthor(andallhertrainingdocuments) usedtocreatetheHRS.However,theHRSglobal
to that cluster. For efficiency, we use the search collectioncanbeconsideredtobethesamegenre
operation in FAISS (Douze et al., 2024) to pre- as RealNews as both are comprised of full news
computearankedlistofdocumentsclosesttoeach stories, but in all other cases, tests also require
centroid,cappingatthefirst2,024. Thisstageends zero-shotgenretransfer.
whennoclustersaddanyauthorsbecause1)they Task Configuration. The core task we apply
have already grown to the maximum size, or 2) totheHRSisoneofrankedretrieval—thegoalis
all the pre-calculated lists of closest documents toreturnarankedlistofhaystackdocumentswith
have been exhausted. The relatively small set of respect to a query, with the hope that the target
remainingauthorsareaddedtoclusterswithspare documentsareatthetopthatlist. The HIATUSpro-
capacity. Thecentroidsthemselvesareclusteredby gram provided a script to derive test sets for this
thesamealgorithmtogroupclustersintobatches taskfromtheHRS.First,itidentifiesasetoftest
(sinceoneclusteristypicallynotenoughtofillup foregroundauthors. Foreachselectedforeground
abatchof74authors). Thisadditionalstepyields author,oneormoreoftheauthor’sdocumentsare
morecoherentbatches. usedasqueries,andtherestserveastargets. The
One critical question is how we generate the remainingforegrounddocumentsandalltheback-
document vectors used for clustering. Here, we grounddocumentscompletethehaystack.
choosetousethevectorsgeneratedbytheprevious BecauseofthewaytheHRSdataisconstructed,
iterationofthemodel. (Inthefirstepoch,weuse wecancontrolwhethertargetsarerequiredtocome
the vector generated by the SADIRI architecture from the same genre as the query (the per-genre
using the base language model before any fine- setting)orwhethertheyareassumedtocomefrom
tuning.) This technique allows us to address the different genres than the query (the cross-genre
mostconfusingexamplesaftereachiterationand setting). To support the work described here, we
compensateforomissions(orover-training)from rantheHIATUS scripttocreatefiveper-genretest
previouspasses. sets(oneforeachofthefiveHRSgenres),andsix
cross-genretestsets(fiveeachwithqueriesfrom
3 Data,Task,&Metrics only a single HRS genre and a sixth test set that
has queries from all five HRS genres combined
TestSet. Ourtestsetisthe HIATUS ResearchSet together). Additional details are provided in Ap-
(HRS), developed by IARPA for Phase 1 of the
pendixA.
IARPA HIATUS programandmadeavailablepub- Metrics. We measure performance with Suc-
liclyforresearchpurposes. Alldocumentsinthe
cess@8: foragivenquery,wasoneormoreofthe
HRScontain350ormorewords,coveringfivegen-
eight highest-scoring documents in the haystack
res. Please see Appendix A for more details on
writtenbythesameauthorasthequery,i.e. isita
accessandcorpuscomposition. Foreachofthese
targetforthatquery? (Scoresareaveragedacross
fivegenres,twogroupsofdocumentsareprovided.
allqueriesinatestset.) Wechoosethismetric,in
Thebackgrounddocumentswerefoundinpreexist-
part,becauseitistheprimarymetricforthe HIA-
ingsources. Forinstance,onegenreisboardgame
TUS program; we also prefer it to recall at eight
reviews;forthisgenreIARPAharvesteddatafrom
because it is insensitive to the number of targets
boardmangeek.com. Incontrast,eachforeground
perauthor.4
documentwascreatedbyawriterworkingunder
IARPA’ssupervisiontocloselyapproximateaspec- 4EarlydevelopmenteffortswithHRSindicatedthatSuc-4 Experiments theRedditdatasourceleadtobetterperformance,
whichisborneoutintheresults: thesystemtrained
4.1 BaselineSystems
onRedditdoesindeedonaverageout-performthe
Weprovidetwobaselinesystems. Thefirst(base- system trained on RealNews, by 7.8% in the per-
line) is a version of state-of-the-art LUAR (Soto genresettingandby19.2%inthecross-genreset-
et al., 2021) which uses only one segment of a ting.
single document as input. The baseline system, Multi-genretraining. Inmachinelearning,one
likebothLUARandSADIRI,usesthecoremodel canhopethatexpandingone’strainingsetwillin-
structureandlossfunctiondescribedin2.1. How- creaseperformance. However,expandingtraining
ever,baselineusesrandomlyselectedsame-author toadditionaldomainsandgenresdoesnotalways
documentpairs(insteadofthe SADIRI hardposi- yieldimprovementsforauthorshipattribution. Soto
tives)andrandomlycombinesauthorswhenform- etal.(2021)reportmodestgainsforLUARwhen
ingtrainingbatches. augmentingwiththeirRedditcollection: 4.5%rel-
The other baseline (denoted baseline-POS) is ativegaininMRRforAmazonand12.4%relative
inspiredbytheworkofHalvanietal.(2020): POS for fanfiction, but neither Amazon nor fanfiction
tagsareextractedforallwords,andcontentwords werehelpfulsupplements.
are substituted with tokens indicating only their
Wefindsimilarresultsforourtwobaselinesys-
POS.5 The goal of this masking strategy is to en-
tems,asshowninTable1,wherewecomparemod-
hance robustness to topic variation. All other de-
elstrainedononegenre(RedditorRealNews)with
tailsarethesameasforbaseline.
those trained on eight genres (including Reddit
Inallcases,thebaselinesystemsaretrainedon andRealNews). Addingmulti-genredataimproves
thesamedata(andinthesamedevelopmentenvi- baseline per-genre performance by only a small
ronment) as the SADIRI configurations to which amount (0.554 to 0.570), and cross-genre perfor-
theyarecompared. manceisessentiallyunchanged. Forbaseline-POS,
addingmulti-genredataactuallydegradesscores,
4.2 ExperimentalSettings
onaverage. Incontrast,for SADIRI,expandingto
Single-Genre Training. We first present results 8Genressignificantlyimprovesper-genreperfor-
whentrainingwithonlyonedatasource,i.e.only mance with performance in the cross-genre con-
onegenre. Weselectedtwodatasourcesonwhich textincreasingmoremodestly. Theresultsclearly
toperformsingle-genretrainingexperiments: (1) demonstratethatSADIRIismuchbetterequipped
Reddit(becauseofitssizeandvariety)and(2)Re- tocapitalizewhenexpandingtherangeofgenres
alNews(becauseofitsgenreoverlapwithglobal intraining,especiallyintheper-genrecondition.
intheHRS).Table1demonstratesthatourSADIRI
configuration performs best in all contexts, com- 4.3 AblationStudies
fortablybeatingtheclosestbaseline(baseline)with
4.3.1 Hard-positiveAblations
a relative improvement of 7.0% in the per-genre
settingandanevenmorenoticeable52.9%inthe Akeyfeatureofourapproachishowweselectdoc-
cross-genresetting. OurbaselinewithPOSmask- umentsattributedtothesameauthor fortraining:
ingofcontentwords(baseline-POS)consistently we select the pair of documents with the lowest
lagsbehindboth SADIRIandthebaselinesystem. SBERT cosinesimilarity,andexcludepairswhose
Unsurprisingly, training on RealNews is most similarityexceeds0.2. Weconsidertwoablations
effective when testing with queries in the global here: 1)varyingtheceilingSBERTcosinesimilarity
HRS genre, which also consists of news stories. value,and2)choosingdocumentpairsrandomly,
However, in the more typical case where there is includingallavailableauthors. Table2providesre-
noexplicitgenrematchbetweentrainingandtest, sultswhentrainingonalleightgenres. Aswevary
weexpectthewidevarietyoftopicsrepresentedin the SBERT ceiling from 0.1 to 0.9, we observe a
broadtrendindecliningcross-genreperformance;
cess@8 seemed to correlate well with alternatives such as
indeed, including increasingly similar document
MeanReciprocalRank(MRR),butwehavenotperformeda
rigorousanalysis. pairsreducesperformanceinthecross-genrecon-
5POStagsareproducedwiththeen_core_web_smmodel dition on average. To a lesser extent, raising the
withinSpaCy(HonnibalandMontani,2017).Specialtokens
ceiling improves per-genre performance, but the
foreachcontentPOStagwereaddedtotheRoBERTatok-
enizer. lowest performance is for <=0.1, <=0.6 is some-data config mode board comb global instruct human stem avg
Reddit SADIRI per 0.768 0.553 0.618 0.492 0.535 0.593
Reddit baseline per 0.793 0.402 0.542 0.479 0.556 0.554
Reddit baseline-POS per 0.625 0.477 0.431 0.384 0.318 0.447
Realnews SADIRI per 0.793 0.640 0.465 0.393 0.460 0.550
Realnews baseline per 0.754 0.581 0.417 0.315 0.455 0.504
Realnews baseline-POS per 0.589 0.512 0.306 0.341 0.328 0.415
8Genres SADIRI per 0.875 0.750 0.604 0.530 0.561 0.664
8Genres baseline per 0.847 0.506 0.549 0.461 0.485 0.570
8Genres baseline-POS per 0.658 0.524 0.361 0.371 0.384 0.459
Reddit SADIRI cross 0.517 0.283 0.213 0.300 0.401 0.330 0.341
Reddit baseline cross 0.363 0.158 0.142 0.145 0.280 0.250 0.223
Reddit baseline-POS cross 0.271 0.164 0.099 0.095 0.271 0.205 0.184
Realnews SADIRI cross 0.415 0.233 0.260 0.185 0.334 0.285 0.286
Realnews baseline cross 0.322 0.186 0.226 0.115 0.283 0.216 0.225
Realnews baseline-POS cross 0.274 0.178 0.128 0.085 0.283 0.186 0.189
8Genres SADIRI cross 0.507 0.328 0.288 0.275 0.434 0.368 0.367
8Genres baseline cross 0.353 0.178 0.189 0.145 0.229 0.258 0.225
8Genres baseline-POS cross 0.322 0.172 0.085 0.095 0.268 0.254 0.199
Table1: PerformancetrainingonReddit,Realnews,andthe8GenrecollectiononHRS(Success@8). Highest
overallscoresareinbold;thehighestscoresamongthesingle-genresystemsareunderlined.
whatworsethan<=0.4,andaverageperformance place. Thus,hardnegativesappeartobenecessary
for<=0.9issimilarto<=0.1. Wechose<=0.2for forachievingthegainsreportedwithmulti-genre
ourSADIRIconfigurationasitprovidesacompro- traininginSection4.2.
misebetweenper-andcross-genreperformance. One hyperparameter for the SADIRI batching
We also consider randomly selecting pairs of approach is the number of document clusters per
documentsfromallavailableauthors. Table2in- batch. Theresultsreportedintheprevioussections
dicatesthatthisconfigurationprovidesthehighest targetfiveclustersforeachbatchof74authors. We
per-genre performance, but the lowest (average) swept values one through nine: five was a strong
cross-genreperformance. Unlikethebaselinesys- choice, but little variance was observed. As dis-
temspresentedinTables1,hardnegativesarestill cussedinSection2.3,weclustercentroidstoform
inplace. Inthiscontext,weseethathardpositives batches,andwenotethatourlossiscomputedover
benefitcross-genreattheexpenseoftheper-genre batches(notclusters). Thisleadsustosuspectthat
performance. clustering the clusters lessens the impact of this
hyperparameter and causes batches to be largely
4.3.2 Hard-negativeablations similar.
TobetterunderstandtheimpactoftheSADIRIap-
5 Previouswork
proachtocreatingtrainingbatches(i.e.prioritizing
“hardnegatives”),Table3showsresultswithand Workinautomaticauthorshipattributionhaspre-
withoutthistechniqueinplace. (Notethatinboth viouslyusedinformationsuchascharacter,word,
casesthesystemassumesourstandard“hardposi- and POS N-grams (Stamatatos, 2009; Stolerman
tive”configuration.) Weobserveinitiallythatthe etal.,2014),butsystemsbasedonpre-trainedlan-
SADIRI batchingapproachimprovesperformance guagemodelssuchasBERT(Devlinetal.,2019)
ineverycondition. Acloseranalysis,however,re- andRoBERTa(Liuetal.,2019)haveshowngreater
vealsthatincreasingfromjustRedditto8Genres promise in recent years. Earlier systems adopted
is broadly beneficial only with hard negatives in the Siamese network structure employed in thispairs #auth mode board comb global instruct human stem avg
<=0.1 129,725 per 0.840 0.739 0.618 0.509 0.541 0.649
<=0.2 201,673 per 0.875 0.750 0.604 0.530 0.561 0.664
<=0.4 311,563 per 0.911 0.750 0.708 0.530 0.591 0.698
<=0.6 368,431 per 0.907 0.733 0.708 0.517 0.576 0.688
<=0.9 401,985 per 0.893 0.687 0.639 0.487 0.546 0.650
random 413,169 per 0.911 0.762 0.771 0.513 0.611 0.713
<=0.1 129,725 cross 0.524 0.332 0.288 0.320 0.428 0.356 0.375
<=0.2 201,673 cross 0.507 0.328 0.288 0.275 0.434 0.368 0.367
<=0.4 311,563 cross 0.500 0.295 0.302 0.245 0.383 0.402 0.354
<=0.6 368,431 cross 0.497 0.247 0.250 0.190 0.346 0.409 0.323
<=0.9 401,985 cross 0.490 0.245 0.307 0.255 0.350 0.379 0.337
random 413,169 cross 0.459 0.216 0.241 0.250 0.328 0.375 0.311
Table 2: Performance training on 8 Genres according to the selection of same-author document pairs for HRS
(Success@8). Thehighestscoresineachconditionareinbold;thebestscoreamongthehardpositiveconfigurations
isunderlined.
data batching mode board comb global instruct human stem avg
Reddit hard per 0.768 0.553 0.618 0.492 0.535 0.593
Reddit random per 0.747 0.529 0.611 0.496 0.520 0.581
RealNews hard per 0.793 0.640 0.465 0.393 0.460 0.550
RealNews random per 0.714 0.535 0.417 0.328 0.425 0.483
8Genres hard per 0.875 0.750 0.604 0.530 0.561 0.664
8Genres random per 0.782 0.599 0.528 0.440 0.455 0.561
Reddit hard cross 0.517 0.283 0.213 0.300 0.401 0.330 0.341
Reddit random cross 0.490 0.261 0.184 0.250 0.428 0.303 0.319
RealNews hard cross 0.415 0.233 0.260 0.185 0.334 0.288 0.286
RealNews random cross 0.367 0.221 0.217 0.130 0.304 0.273 0.252
8Genres hard cross 0.507 0.328 0.288 0.275 0.434 0.368 0.367
8Genres random cross 0.445 0.233 0.241 0.180 0.322 0.311 0.289
Table 3: Performance for HRS training on 8 Genres according to batching strategy (Success@8). Top overall
performanceisindicatedwithboldface;thebestscoresforthesingle-genreconfigurationsareunderlined.
effort but optimized according to a classification yieldedmixedresultswhentrainingontestingon
loss (Saedi and Dras, 2019; Fabien et al., 2020), different sources such as Amazon reviews, Red-
but more recent systems, e.g. (Soto et al., 2021; ditandFanfiction. ContrastDistAAaddedMutual
Ibrahimetal.,2023),madeperformancegainsby Information Maximization to Constrastive learn-
switchingtoSupervisedConstrastiveLoss(Khosla ing(Huetal.,2024)andobtaineda2.1%relative
etal.,2020). improvement in F1 on CCAT50, a collection of
Tolimitedsuccess,variousauthorshipsystems Reuters articles. A sequence of papers by Bar-
have expanded their architecture to improve ro- lasandStamatatos(2021,2020)includedtheuse
bustnesstoinconsistencyintrainingandtestdata ofanunlabelednormalizationcorpustoenhance
withregardstotopic,genreanddomain. Aneffort cross-topic and cross-genre performance but av-
attopicregularizationbySawatpholetal.(2022) erage accuracy for a BERT-based model falls by11.9%, relative, in a cross-topic news article task ficialnotonlyintheper-genrecondition,butvirtu-
whenthenormalizationcorpusdiffersfromthetest allyacrosstheboard. However,whenwemaintain
set. Regardlessofthedataset,normalizationonly hard negatives, hard positives give higher cross-
degradesperformanceinthecross-fandomenviron- genreperformanceattheexpenseofalossinthe
mentonPAN18. per-genrecondition,asshowninTable2.
Another common approach to enhancing flex- Anotherasymmetryisthatourimplementation
ibility is partially obscuring lexical information, pursueshardpositivesandhardnegativesbydiffer-
focusingonthemostdistinctivesemanticcontent. entmeans. Weselectsame-authortrainingpairsby
AnapproachfromStamatatos(2018)masksallbut minimizingSBERTcosinesimilarity;thismethod
themostfrequentlexicaltypes,retainingvarying selects semantically (and topically) distant pairs,
amountsofdetail;usinganSVMoncharacterN- buthasnotmeanstodirectlyseekoutdifferencein
grams,theyobservestronggainsinthecross-topic genre(orsubgenre).6 However,hardnegativesare
contextthatlargelydissolvecross-genre. Halvani identifiedaccordingtothecosinesimilarityofthe
etal.(2020)substitutedPOStagsforcontentwords currentmodel. Thisdiscouragesassociatingstyle
foranauthorverificationtask. Theycomparedtoa with topic, genre and domain to the degree these
versionfromStamatatos(2018)wheresequences areencodedbythemodelatthetime. Ourresults
oflettersaremaskedwithasingleasterisk(*)for forrandomwithin-genrebatchinginSection4.3.2
allbutthemostfrequentlexicaltypes,andreported suggestthatourvectorsmayencodesomegenreat-
anaveragerelativegaininaccuracyof3.2%,with tributes,butthepresenteffortwillnotfurtherprobe
amaximumof12.5%. or characterize our output vectors. We could im-
Like our approach, VALLA (Tyo et al., 2022, poseconsistencybydetectinghardnegativeswith
2023) seeks hard positives and hard negatives in SBERT cosine similarity, but early experiments
training. Theirpapercomparesvariousapproaches suggested that this method performed worse. In-
inavarietyofauthorshipattributionandverifica- versely,wecouldfindhardpositivesaccordingto
tiontasks. TheyfindthataBERT-basedSiamese SADIRI vectors,butwehavenotexploredvariants
networktrainedwithconstrastivelossperformed alongtheselinesinourpresenteffort.
markedlyworsethananN-gram-basedapproach,
7 Limitations
especiallyincross-topicandcross-genrecontexts.
Inanextensionoftheirwork,theyemployatech-
Weonlyexaminedocumentswithatleastthan350
niqueestablishedincomputervisionforpersonre-
tokensandcannotmakeanyclaimsaboutshorter
identification(Hermansetal.,2017): withineach
texts. Also,theHRStestsetfeatureselicitedfore-
randomlyselectedbatch,tripletlossiscalculated
ground documents;wewouldliketoevaluateour
withthemostdistantpositiveandclosestnegative
systemonanaturallyoccurringsetofdocuments,
by Euclidean distance. VALLA provides a 7.8%
butforthecross-genreconditiontherearesignifi-
relative increase in accuracy over their baseline
cantpracticalbarrierstoamassingsuchacorpusof
withconstrastiveloss. Theydemonstratethevalue
anysize,asdiscussedearlier. Wealsonotethatwe
ofcalculatinglossintrainingwithhardpositives
onlyconsiderEnglish-languagetexts,andperfor-
and hard negatives, but they only sample within
manceforotherlanguageshasnotbeenaddressed.
(randomlyselected)batches,where SADIRI mines
hardpositivesandnegativesfromthefulltraining 8 EthicsStatement
collection. VALLAshiftstotripletlossinthiscon-
textwhileSADIRImaintainssupervisedcontrastive The authorship predictions generated by SADIRI
loss. arenotalwayscorrect: outputcharacterizationsof
inputdocumentcollectionsshouldbeusedaccord-
6 Discussion ingly.
SADIRI employsbothhardpositivesandhardneg- 9 Conclusion
atives; we consider here how they relate to each
We have presented an authorship attribution sys-
other. First, we observe that hard negatives are
temthatdisplaysremarkablerobustnesstomixing
consistently helpful, but hard positives bring per-
formance trade offs. Table 3 shows that, in the
6Ofcourse,wehavenomulti-domaintrainingauthorsso
presenceofhardpositives,hardnegativesarebene- differenceindomainispossible.topics,genres,anddomains. Whereaspreviousef- MaelFabien,EsaúVillatoro-Tello,PetrMotlícek,and
fortsincreasedmodellingmachineryinthehopeof ShantipriyaParida.2020. Bertaa: Bertfine-tuning
forauthorshipattribution. InICON.
increasingsuchfunctionality,ourmodelarchitec-
tureisasimpleRoBERTa-baseddocumentencoder OrenHalvani,LukasGraner,RoeyRegev,andPhilipp
trained with supervised contrastive loss. Instead, Marquardt. 2020. An improved topic masking
technique for authorship analysis. arXiv preprint
ourperformancegainsareattributabletoourtreat-
arXiv:2005.06605.
mentofoursourcecorporaintraining. Selecting
topicallydissimilarsame-authordocumentpairsis AlexanderHermans,LucasBeyer,andBastianLeibe.
2017. In defense of the triplet loss for person re-
keytoimprovingtestsinthecross-genrecondition,
identification.
Gathering these pairs to establish hard negatives
allows us to benefit from large and diverse train- MatthewHonnibalandInesMontani.2017. spaCy2:
NaturallanguageunderstandingwithBloomembed-
ing corpora and enhances test performance in all
dings,convolutionalneuralnetworksandincremental
conditions,especiallytheper-genresetting.
parsing. Toappear.
10 Acknowledgements ZhiqiangHu,ThaoThanhNguyen,YujiaHu,Chia-Yu
Hung, Ming Shan Hee, Chun Wei Seah, and Roy
This research is supported in part by the Office Ka-WeiLee.2024. Contrastivedisentanglementfor
of the Director of National Intelligence (ODNI), authorshipattribution. InCompanionProceedings
of the ACM on Web Conference 2024, WWW ’24,
Intelligence Advanced Research Projects Activ-
page1657–1666,NewYork,NY,USA.Association
ity (IARPA), via the HIATUS Program contract
forComputingMachinery.
#2022-22072200006. Theviewsandconclusions
MomenIbrahim,AhmedAkram,MohammedRadwan,
containedhereinarethoseoftheauthorsandshould
RanaAyman,MustafaAbd-El-Hameed,NagwaM.
not be interpreted as necessarily representing the
El-Makky,andMarwanTorki.2023. Enhancingau-
official policies, either expressed or implied, of thorshipverificationusingsentence-transformers. In
ODNI,IARPA,ortheU.S.Government. TheU.S. ConferenceandLabsoftheEvaluationForum.
Government is authorized to reproduce and dis-
Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron
tributereprintsforgovernmentalpurposesnotwith- Sarna, Yonglong Tian, Phillip Isola, Aaron
standinganycopyrightannotationtherein. Maschinot,CeLiu,andDilipKrishnan.2020. Super-
visedcontrastivelearning. ArXiv,abs/2004.11362.
WethankDavidJurgensandJianZhufortheir
technicalcollaborationandextensivedatacollec- YinhanLiu,MyleOtt,NamanGoyal,JingfeiDu,Man-
tioneffortsonbehalfofthiswork. dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
Luke Zettlemoyer, and Veselin Stoyanov. 2019.
Roberta: A robustly optimized bert pretraining ap-
proach. ArXiv,abs/1907.11692.
References
NilsReimersandIrynaGurevych.2019. Sentence-bert:
GeorgiosBarlasandEfstathiosStamatatos.2020. Cross-
Sentenceembeddingsusingsiamesebert-networks.
domainauthorshipattributionusingpre-trainedlan-
InConferenceonEmpiricalMethodsinNaturalLan-
guage models. Artificial Intelligence Applications
guageProcessing.
andInnovations,583:255–266.
Chakaveh Saedi and Mark Dras. 2019. Siamese net-
Georgios Barlas and Efstathios Stamatatos. 2021. A
worksforlarge-scaleauthoridentification. Comput.
transfer learning approach to cross-domain author-
SpeechLang.,70:101241.
shipattribution. EvolvingSystems,12:625–643.
JitkapatSawatphol,NonthakitChaiwong,CanUdom-
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
charoenchaikit,andSaranaNutanong.2022. Topic-
Kristina Toutanova. 2019. BERT: Pre-training of
regularized authorship representation learning. In
deepbidirectionaltransformersforlanguageunder-
Conference on Empirical Methods in Natural Lan-
standing. InProceedingsofthe2019Conferenceof
guageProcessing.
theNorthAmericanChapteroftheAssociationfor
ComputationalLinguistics: HumanLanguageTech- RafaelA.RiveraSoto,OliviaElizabethMiano,Juanita
nologies,Volume1(LongandShortPapers),pages Ordoñez, Barry Y. Chen, Aleem Khan, Marcus
4171–4186,Minneapolis,Minnesota.Associationfor Bishop,andNicholasAndrews.2021. Learninguni-
ComputationalLinguistics. versalauthorshiprepresentations. InConferenceon
EmpiricalMethodsinNaturalLanguageProcessing.
MatthijsDouze,AlexandrGuzhva,ChengqiDeng,Jeff
Johnson,GergelySzilvasy,Pierre-EmmanuelMazaré, EfstathiosStamatatos.2009. Asurveyofmodernau-
Maria Lomeli, Lucas Hosseini, and Hervé Jégou. thorshipattributionmethods. J.Assoc.Inf.Sci.Tech-
2024. Thefaisslibrary. nol.,60:538–556.EfstathiosStamatatos.2018. Maskingtopic-relatedin-
formationtoenhanceauthorshipattribution. Journal
oftheAssociationforInformationScienceandTech-
nology,69.
ArielStolerman,RebekahOverdorf,SadiaAfroz,and
RachelGreenstadt.2014. Breakingtheclosed-world
assumptioninstylometricauthorshipattribution. In
AdvancesinDigitalForensicsX-10thIFIPWG11.9
InternationalConference,Vienna,Austria,January
8-10,2014,RevisedSelectedPapers,volume433of
IFIPAdvancesinInformationandCommunication
Technology,pages185–205.Springer.
JacobTyo,BhuwanDhingra,andZacharyChaseLipton.
2022. Onthestateoftheartinauthorshipattribution
andauthorshipverification. ArXiv,abs/2209.06869.
JacobTyo,BhuwanDhingra,andZacharyChaseLip-
ton.2023. Valla: Standardizingandbenchmarking
authorship attribution and verification through em-
pirical evaluation and comparative analysis. In In-
ternationalJointConferenceonNaturalLanguage
Processing.
A Testdatadetails
IARPA provides documentation for the Phase 1
HRS data set at https://www.iarpa.gov/research-
programs/hiatus;requestsfordataforresearchpur-
posesshouldbedirectedtohiatus_data@umd.edu.
Documentscontainaminimumof350words,span-
ing5genres,aslistedinTable4.
Ascriptwasprovidedbythe HIATUS program
to extract per-genre test sets for the five Phase 1
HRS genres, as well as cross-genre test for each
andonecombiningallfive. Detailsoftheversion
utilizedforthispaperareprovidedinTable5. The
remainderofthehaystackvariesmodestlyinsize
withover21kauthorsandamean 2.48documents
perauthor.
B Trainingdatadetails
Our training datasets were extracted by our
team. Processing included masking of person-
ally identifying information, e.g. substituting
CREDIT_CARDforanactualcreditcardnumber,
EMAIL_ADDRESSforanemailaddress,etc. De-
tails for all eight sources are provided in Table
6. BookCorpusconsistsofnovelsandotherbook-
length works which we segmented into multiple
documents for training corpus; all training docu-
ments for all other sources are actual full docu-
ments. PleasenotethatweamassedourRedditand
Amazon collections independent of any datasets
createdforearlierefforts,e.g. (Sotoetal.,2021).name description sources #foregrounddocs #backgrounddocs
board boardgamereviews boardmangeek.com 212 2,432
global citizensjournalism globalvoices.org 140 5,453
instruct instructions instructables.com 133 8,534
human literatureforums stackexchange.com 199 9,941
stem STEMforums stackexchange.com 171 11,042
Table4: CompositionoftheHRSPhase1datasetforHIATUS.
per-genre cross-genre
#authors meandoc/author #authors meandoc/author
genre queries targets queries targets
board 60 1.87 2.33 64 5.72 2.28
comb 116 5.05 2.18
global 52 1.85 1.65 49 4.57 2.16
instruct 54 1.35 1.33 62 6.21 1.61
human 61 2.08 1.90 74 5.85 2.24
stem 52 2.12 1.90 52 4.62 2.38
Table5: CompositionoftheHRSPhase1testsetswiththenumberofauthorsandmeannumberofdocumentper
authorfortargetsandqueries.
source description #docs
RealNews newsstories 200,602
BookCorpus full-lengthbooks 76,529
Reddit reddit.comentries 55,034
GoodReads bookreviews 32,010
Amazon reviewsonamazon.com 16,476
Gmane newsgroups 16,396
WikiDisc Wikipediaeditorialdiscussions 13,868
PubMed medicaljournalarticles 692
Table6: Trainingdatasources