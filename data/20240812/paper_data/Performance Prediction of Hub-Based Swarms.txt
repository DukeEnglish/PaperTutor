Performance Prediction of Hub-Based Swarms
Puneet Jain*, Chaitanya Dwivedi**, Vigynesh Bhatt*, Nick Smith*, Michael A Goodrich*
Abstract—A hub-based colony consists of multiple agents The main contributions of the papers are: First, a graph-
who share a common nest site called the hub. Agents perform based representation is created from a relational database in
tasks away from the hub like foraging for food or gather-
which each database record encodes an individual agent’s
ing information about future nest sites. Modeling hub-based
internal state. Second, the records in the relational database
colonies is challenging because the size of the collective state
space grows rapidly as the number of agents grows. This are “stacked” into tensors to form a probabilistic graph
paperpresentsagraph-basedrepresentationofthecolonythat of collective state behavior. Third, a graph-based encoder
can be combined with graph-based encoders to create low- is constructed. Finally, the resulting node embeddings are
dimensional representations of collective state that can scale to
shown to provide insight into the swarm behavior that can
many agents for a best-of-N colony problem. We demonstrate
be applied to various swarm and problem configurations.
how the information in the low-dimensional embedding can be
usedwithtwoexperiments.First,weshowhowtheinformation
in the tensor can be used to cluster collective states by the II. RELATEDWORK
probability of choosing the best site for a very small problem.
Second, we show how structured collective trajectories emerge Many bio-inspired swarms exhibit spatial swarming pat-
when a graph encoder is used to learn the low-dimensional terns such as flocking or cyclic behavior [3], [13]. Other
embedding, and these trajectories have information that can types of swarms are organized as hub-based colonies where
be used to predict swarm performance.
all agents belong to a common nest and fan out from the
I. INTRODUCTION nest in search of food or new suitable nest sites [11], [14],
Biological inspiration drawn from honeybees, ants, birds, [15]. Swarms can be implemented as ABMs, which are
and various animal species has been instrumental in agent- employed for designing complex systems [16], [17], [18],
based models (ABMs) of multi-agent swarms. In ABMs, [19], [20]. ABMs are used in social sciences to model
eachagentindependentlyimplementsitsowncontroller,and the interactions of individuals [21], [22], simulate decision
collective behavior emerges from interactions among the making [23], and study traffic flow [24]. They are also
agents [1], [2], [3], [4]. ABMs capture the decentralized applied to understand ecosystems and biodiversity [25] and
andindividualizednatureofinteractionsincomplexsystems, to model disease spread [26].
making them valuable for empirically studying emergent FrameworkstoextendABMsbuiltonfinitestatemachines
behaviors and system-level dynamics. This paper addresses to graph representations include [12], [27]. Graph neural
the best-of-N problem, where agents stationed at a central networkshavealsobeenusedwithmulti-agentsystemssuch
hub make a distributed decision to choose the best site from as in traffic engineering [28] and trajectory prediction [29].
a set of N possibilities [5]. Other methods which learn on subgraphs to learn graph
A common bottleneck for understanding large-scale bio- representation include [30], [31].
inspiredswarmsistheagents’slowdecisionmakingandthe
huge complexity of the system. A solution to this problem III. GRAPHSFORTHEBEST-OF-NPROBLEM
istousedifferentialequations[6],[7],[8],butthoseassume
This section presents our ABM formulation of the best-
infinite agents and time. While differential equation have
of-N problem and how we create graphs from the ABM.
proveneffectiveforgeneratingmetricsaboutperformanceof
a swarm, understanding the performance of hub-based agent
A. Best-of-N Problem
colonieswithfiniterobotsremainsachallenge[9],[10],[11].
ThispaperrepresentsthecollectivestateinanABMswith Thebest-of-NproblemisillustratedinFig.1foraproblem
the nodes in a graph [12]. Changes in collective state are withtwosites,fiftyagents,andahexagonalhub.Theagents,
represented as probabilistic transitions, forming a Markov which are represented as triangles pointing in their direction
chain that can be used to predict performance and other oftravel,exploretheworld.Whentheyfindasiteofpotential
swarm properties. Unfortunately, the number of nodes, node interest, they return to the hub and inform other agents. If
features, and edges grows very quickly with the number they fail to find a site, they return to the hub and observe
of agents. This paper shows that low dimensional graph other agents. Agents travel between a site of interest and
embeddings provide useful information that support compu- the hub to assess the site and to recruit other agents to the
tationally feasible ways of understanding swarm behavior. site. Agents recruiting for a site can sense when a quorum
of agents are at the hub, and when a quorum is reached
AuthorsarewiththeDepartmentofComputerScience,BrighamYoung
the collective decides that the site is the best solution to the
University,Provo,USA.Foranyquestions,email:puneetj@byu.edu,
mike@cs.byu.edu problem.
4202
guA
9
]AM.sc[
1v22840.8042:viXraexplore state depend not only on the Bernoulli distribution,
p ,butalsoontheprobabilitythatasiteisdiscoveredandit’s
3
quality (y). The transition from the recruit state (R) depends
on(a)theBernoullidistribution, p ,(b)thenumberoftimes
2
that an agent reassesses the site, which is determined by
qualityofthesite,γ,and(c)thedurationofrecruiting,which
is also a function of site quality, x.
The transition from the observe state depends on two
parameters: whether the agent is recruited by another agent
to assess a site, which is denoted by z, which is a function
of recruiters for each site. The other parameter is how long
the agent dwells in the observe state in the absence of being
recruited, which is given by the parameter p . The site to
Fig.1. Best-of-Nproblemwithtwosites(circles)and50agents(triangles). 1
which the agent is recruited is proportional to the number of
Thehexagonrepresentsthehub.
agents recruiting to each site.
C. Representing Collective State as a Tensor
A key insight from prior work is that information about
E A the states of individual agents can be combined to create
a compressed representation of collective state [33], [34].
Unfortunately, that prior work was not sufficiently powerful
toscalewhensitescouldbeatdifferentlcoationsintheworld
or when the number of agents changed. Consequently, this
paper uses repesentation based on a relational database.
The relation header is the list of agent states (R, D, etc.)
plus the quality of the site (Q) that the agent is traveling to,
O R
traveling from, recruiting to, or assessing. A unique agent
identifier is also included, yielding a relation like Table I
Q R A THR TS O E THO ID
Fig.2. Agent-BasedModel 1.0 0 0 0 1 0 0 0 2
0.5 1 0 0 0 0 0 0 0
0.5 0 1 0 0 0 0 0 3
0 0 0 0 0 0 0 1 1
B. Agent Based Model (ABM)
TABLEI
Unlike ABMs modeled as differential equations [32], [2]
RELATIONREPRESENTINGTHEINDIVIDUALSTATES.
or finite state machines with augmented with extra mem-
ory [33], the ABM in this paper is satisfies the Markov
condition, where every agent’s next state is dependent only Table I represents a collective with four agents. Agent 2
on its current state. Each agent runs its copy of the state is traveling to a site with quality q(s)=1.0 to assess it,
machine illustrated in Figure 2 with the following states. O: agent 0 is recruiting to site with quality q(s)=0.5, agent 3
Observe, E: Explore, A: Assess, R: Recruit, T HO: Travel to is assessing a site with quality q(s) = 0.5, and agent 1
Hub to Observe, T HR: Travel to Hub to Recruit, T S: Travel is returning home after failing to discover a site while
to Site. δ is the dirac-delta function, r is the position of the exploring. In effect, each agent is represented by a one-hot
agent and r S is the position of a site. encoding of the state the agent is in, augmented with the
State transitions depend on the current state and position quality of a site an agents is favoring and agent identifier.
relative to the position of sites, hub and other agents. The Tuples in the relation can be sorted by the values of
transition probabilities are shown on the edges. The transi- the tuples and then concatenated together into a tensor of
tions from the travel states (T HO, T HR, T S) are represented by tuplesafterremovingagentID.Thistensorisananonymized
δ functions, which means that agents transition from these representationofcollectivestate.Inasubsequentsection,we
travelstatesonlywhentheyreachtheirdestination,whichis explore what happens when we provide global information
either the hub (T HO, T HR) or the site (T S). to the collective for large numbers of agents. This global
The probabilities p , p , p , and p are modeled as information is appended to the start of the tensor.
1 2 3 4
Bernoulli distributions with parameters set to control the
D. Representing State Dynamics as A Graph
meantimeagentsspendinO,R,A,E,andA,respectively.In
the second set of experiments, samples from the Bernoulli Thecollectivestategraphisconstructedbycreatinganode
distribution are obtained from numpy’s random binomial for each tensor, and creating an edge between nodes if the
function with number of trials as 1. Transitions from the swarm can evolve from the collective state in one node tothe collective state in the other. Each tensor encodes the
features associated with each node in the collective state
graph. Graph edges encode transitions between collective
states.Somenodescantransitiontomultiplenextstates,and
theprobabilityofthespecifictransitionsisdeterminedbythe
probabilities with which agents transitions between states in
their individual state machines.
Fig.4. Clusteringof2Dembeddingusingt-SNE[35],andcorrelationof
clusterwithsuccessprobability.Therewere10agents,twosites(q(s 1)=1,
q(s 2)=0.5)andaquorumthresoldof2agents.Bernoulliparameterswere
set based on the mean times in a state: O 8sec, A 3sec, R 6q(s)sec. The
Fig. 3. Example trajectories generated from 1500 trials for a problem numberofreassessingtripswas∝3q(s).TheBernoulliparameterforbeing
with ten agents and two sites. Each point represents a unique tensor, and recruited by a single recruiting agent was 40sec. Explore agents used y=
eacharrowistheedgebetweentensors.Thevisualizationismadeusingthe δ(D/2) so agents deterministically stopped exploring when they reached
graphvizvisualizationmethodinnetworkx. halftheworlddimension.SiteswereplacedatD/4fromthehub.
Fig.3representsacollectivestategraphforanetworkwith
10 agents and two sites. Each point in the graph indicates a was part of a successful trajectory. Low alpha-values were
unique tensor, and each edge indicates a transition from one usedfortensorsvisitedfewerthan10%ofthetrajectoriesto
tensor to another. This graph was constructed by starting indicate unreliable success estimates.
each agent at a random initial state, collecting 1500 trials, Figure 4 can be interpreted as a success surface, repre-
and keeping the largest (weakly) connected component. sented by the heat map superimposed over the 2D embed-
ding. The surface moves from high success in the lower left
E. Information in the Tensor
to low success in the top right. The +’s indicate tensors
It is useful to explore what kind of information can be that were seen often and were usually part of successful
derived from the collective state tensors for a very small trajectories. The □’s and ×’s indicate tensors that had fewer
collective. Consider a collective with only ten agents and successesorwerevisitedlessoften.The⃝’sindicatetensors
two sites, one site with maximum quality q(s )=1 and the that rarely appeared on successful trajectories. Qualitatively,
1
other site with relatively low quality, q(s )=0.5. Because there is a positive correlation between the clusters and the
2
thereareonlyafewagentsandsites,thenumberofpossible success probability. This indicates that there is information
tensors is (relatively) small, so running several simulations in the tensors about the probability that a collective state
provides a reasonable approximation of the entire graph. will yield success. The next section uses this information to
We ran 500 trials with agents placed in random starting create low dimensional embeddings via graph encoding.
states and locations in the world that were appropriate for
the state (e.g., moving in the world if in an explore state).
IV. LOW-DIMENSIONALEMBEDDINGS
Thedecisionquorumthresholdwassettothreeagents,which Theprevioussectionassumedtheentiregraphwasknown,
yielded348trialsinwhichtheagentschosethebestsiteand which is unreasonable when there are many agents, sites, or
152 trials where they chose the inferior site. A tensor was possible site locations. This section addresses this limitation
part of a successful trajectory if (a) the trajectory ended in by using a GraphSage based graph encoder [30] to induc-
choosing the best site and (b) the tensor was visited at least tively learn the graph embedding.
once in the trajectory. The probability that a tensor yielded
A. Input State Tensor for Embeddings
success was the number of times a tensor was part of a
successful trajectory divided by the number of times it was ThreemodificationsfromTableIinSectionIII-Caremade
part of any trajectory. totherelationaldatabaseandtensor.First,ratherthanusinga
The shapes in Figure 4 represent different clusters of one-hotencodingforagentstate,agentstate,denotedbyS,is
tensors. The clusters were computed (a) by applying the represented as a floating point value given by the following:
t-SNE algorithm [35] to compress each tensor into a two R=0/6, A=1/6, T =2/6, T =3/6, O=4/6, E=5/6,
HR S
dimensional embedding and then (b) applying k-means clus- and T = 6/6. Second, unlike the previous experiment
HO
tering to form four clusters, indicated by shapes: +, ⃝, where the graph only applied to two sites that were at
×, and □. Colors represent the probability that the tensor fixed locations, the graph encoder needs to work for sites atSuccess
Intermediate
Linear
i o
y
o +
i h f 2h f o
x
Hub
z
Graph Encoder
Failure
Fig.5. Encoderarchitecture:iistheinputdimension,histhehiddendimension,oistheoutputdimension,andf=ReLUistheactivationfunction.
differentlocations.Thus,the(x(s),y(s))positionofthesite taking the encoding vectors for two nodes, x and y, and
i i
s favored by the agent, if any, is added to the agent record, maximizing the sigmoid of the cosine similarity measure
i
after normalizing by maximum distance of the environment.
σ(xTy). (1)
Each record is therefore a tuple [q(s),S,x(s),y(s)]. Third,
i i i
unlike the previous experiment where the number of agents When the embeddings of the two nodes are close to (far
was fixed, the graph encoder needs to work for different from) each other the output of Eq. (1) is close to one (close
numbers of agents, which we bound to be less than or equal to zero).
to 10. The tuple is constructed as described above, but the Thus, the output of Eq. (1) approximates the existence
record for any “extra” agents is the constant [0,1,1,1]. of an edge in the original adjacency matrix. A binary cross
entropy loss function with logits [42] is used to compute the
B. Graph Convolutional Neural Network
difference between the 0’s and 1’s in the adjacency matrix
We train the network inductively by forming subgraph and the 0’s and 1’s approximated by Eq. (1). In essence,
samples.Asubgraphsampleisformedbycreatingthenodes this approach penalizes the model when it fails to align its
and edges from a single single simulation. The encoder perceived similarities with the provided adjacency criteria,
architecture is illustrated in Figure 5. The input dimension i guiding it to learn an embedding space where the desired
is40,thehiddendimensionhis20,andtheoutputdimension relationships are accurately captured.
o is 3, which yields a 3-dimensional embedding.
We leverage the GraphSAGE convolution layers [30] for V. EXPERIMENTDESIGN
aggregating features from a node’s neighbors, thus enabling This section addresses the following research questions.
the learning of rich and complex node embeddings. The ar- Problem 1: Can useful 3D embeddings be generated for
chitecture consists of two graph convolution layers followed multiple different environment and agent configurations?
by an activation function ReLU, and a third Linear layer. Problem 2: Do the embeddings for Success, Failure and
We also incorporate a residual connection, first introduced Hub conditions exhibit useful clustering?
in [36], and used widely in LSTMs [37], transformer based
A. Experiment Conditions
systems like GPT-3 [38] and AlphaFold [39]. This directly
connects the input to the final output through a linear Our environment and swarm configurations consist of
transformationtomatchtheoutputdimensions.Thisshortcut defining agents, sites, qualities and distances. We present
is added to the output after the third convolution, facilitating the parameters used in the ABM and the constraints for our
an element-wise addition that merges the transformed input simulations in the Table II. The convergence criteria is set
directlywiththelearnedfeatures.Thisresidualmechanismis byathresholdofagentsrecruitingforagivensiteatthehub.
crucialforalleviatingthevanishinggradientproblemindeep We start with three configurations: Condition 1 has 100%
neural networks, enabling the model to preserve information Observe, Condition 2 has 50% Explore and 50% Observe,
from the input throughout the network to enhance learning and Condition three has 90% Observe 10% Recruiting for
by providing alternate pathways for gradient flow. worst site. Three trajectories are produced by running one
simulation for each configuration. 10 tensors from these
C. Loss Function
trajectories are randomly selected to serve as initial condi-
Thelossfunctionusedtotraintheneuralnetworkisbased tions.Foreachinitialconditionsfromthepreviousparagraph
on graph autoencoders [40], [41] which aim to create graph we run 10 simulations for all possible pairs of distances,
embeddings in which nodes that are adjacent in the network qualities, and runtimes from Table II. The parameters in
have embeddings that are close together. This is done by TableIIarechosensothatnotalltrajectoriesendinsuccess.
vnoCegaS vnoCegaS
raeniLParameter Values
1
x 2/(2+e−7q)
y qδ(r−rS)
z δ(pr)/|R| 0.8
pr binomial(|R|,0.1) e I-Q Range
p 1 binomial(1,0.01) g r Max Qual
p 2 binomial(1,0.99) e v0.6 dist=100
p 3 binomial(1,0.02) n o dist=150
p 4 binomial(1,0.1) c dist=200
Thresγ
holdτ
q 00 .. 55 o t e0.4
m
QC uo an lis tt yra oin ft Ss io tef
s
m| iq ns (1 q− s1q ,qs2 s| 2)< >0. 05
.5
it
0.2
Simulationrun-timesT T∈{1000,10000,35000}
DistanceofSites dsite∈{100,150,200}
MaximumDistance 1000
0
NumberofAgents K∈{5,10}
0 0.2 0.4 0.6 0.8 1
NumberofSites N∈{2,3,4}
quality diff
TABLEII
PARAMETERSFORTHEABMANDSIMULATIONS. Fig.7. MeanSitequalitydifferencevsTimewithinter-quartilerange
differencebetweensitequalitiesislow(leftsideoftheplots),
Theconvergencecriteriaissetbythequorumthresholdas
the success is still high, since it doesn’t matter which site
τ∗K, where K is the number of agents. Therefore, if more
you choose. The success is also high when one site has a
than τ% agents (6 for 10 agent colonies, and 3 for 5 agent
much higher quality than the other (right side of the plots).
colonies in our case) are recruiting for the same site at the
In the middle, the success drops. Site distance (+, ◦, △)
Hub at the same time, the simulation ends. If the simulation
have very little affect on the success metric.
is unable to reach convergence criteria, we do not consider
Figure 7 shows that distance affects time to converge,
its time to converge in the calculations.
as expected. The farther the sites, the higher the time to
B. ABM Results converge. Both the differences of site quality (x-axis) and
the max quality (black dashes) affect the time to converge.
When the quality difference is 0.2, decreasing site quality
1
corresponds to increasing convergence time. By contrast,
when quality difference is 0.5, convergence time is small
0.9 for all values of maximum site quality.
b o C. Labeling Nodes
r0.8
p
s Fromthesimulationsthatconverge,nodeswherethebetter
s I-Q Range
e site among the two sites is chosen at the convergence are
c0.7 Max Qual
c u dist=100 marked as “Success” (cyan), and those where the worse site
s dist=150 is chosen are marked as “Failure” (magenta). Nodes where
dist=200
0.6 noagentissite-oriented aremarkedas“Hub”(black).Every
other node is marked as “Intermediate” (purple).
0.5
0 0.2 0.4 0.6 0.8 1 VI. EXPERIMENTRESULTSANDDISCUSSION
quality diff
This section presents the data from the experiments.
Fig.6. MeanSitequalitydifferencevsSuccesswithinter-quartilerange
A. Results
Figure 6 and 7 show the results of success and time Figure 8 shows the 3D embeddings for all tensors in the
to converge, respectively, for the simulations with 2 sites experiments. The smaller cyan and magenta markers denote
and 10 agents. The dashed line denotes the inter-quartile simulations with 5 agents, and the larger markers denote
range, and the markers show the mean values. A + denotes 10 agents. The □ markers, △ markers, and ⃝ markers
a distance of 100, ◦ is 150, and △ is 200. The black indicate conditions with two sites, three sites, and four sites,
− denotes the maximum quality among the sites in that respectively. It is difficult to see in the figure, but there is
simulation. The success metric if we choose site i is defined very little difference between the embeddings for conditions
as q(s)/max(q ,q ). that have 5 agents and conditions that have 10 agents.
i s1 s2
Figure 6 shows the success vs quality difference for our The embeddings in Figure 8 provide information about
simulations, for different distances. We see that when the which tensors appear on multiple trajectories. Transparencyenable a human to help regulate the swarm behavior.
VII. FUTUREWORK
The results suggest that embeddings work for 5 and 10
agentgroups,butfutureworkshouldincludemoreagentsand
experiments with more world configurations. Future work
should also explore the “harder” problem of differentiating
between varying levels of the probability of success. Next,
future work should take advantage of edge weights, which
can serve as explicit transition probabilities and could lead
toricherembeddings.Anotherdirectiontoexploreisvarious
types of global and agent state information in the state
tensortosolvedifferentdownstreamtasks.Withthegrowing
developmentsintransformers,itwouldalsobereasonableto
look at the performance of transformers solve this problem.
VIII. ACKNOWLEDGEMENTS
Fig.8. 3DEmbeddingforvaryingenvironmentsandnumberofagents.
The work was supported by the US Office of Naval
Research under grant N00014-21-1-2190. The work does
for the intermediate (non-hub, non-success, non-failure) em- not represent opinions of the sponsor. We thank Chaitanya
beddingsinpurpleissettohighlightthatfrequentlyencoun- Dwivedi at Amazon AGI for his suggestions on the graph
tered trajectories tend to aggregate together; nodes encoun- convolutional neural network architecture.
tered more frequently are darker. Frequently encountered
embeddings tend to aggregate, and these aggregations cor-
REFERENCES
respond to probable trajectories of the collective. Infrequent [1] E.Bonabeau,M.Dorigo,andG.The´raulaz,Swarmintelligence:from
trajectories correspond to sparse point areas. naturaltoartificialsystems. No.1,Oxforduniversitypress,1999.
[2] A.Reina,G.Valentini,C.Ferna´ndez-Oto,M.Dorigo,andV.Trianni,
“A design pattern for decentralised decision making,” PloS one,
B. Discussion of Research Questions
vol.10,no.10,p.e0140950,2015.
[3] C.W.Reynolds,“Flocks,herdsandschools:Adistributedbehavioral
TheembeddingsinFigure8alsoindicatethatembeddings
model,” in Proceedings of the 14th annual conference on Computer
encounteredonsuccessful(failed)trajectoriestendtocluster graphicsandinteractivetechniques,pp.25–34,1987.
withothersuccessful(failed)embeddings.Thus,theproxim- [4] T.D.SeeleyandS.C.Buhrman,“Nest-siteselectioninhoneybees:
how well do swarms implement the “best-of-N” decision rule?,”
ity of an embedding should be useful for predicting whether
Behavioral Ecology and Sociobiology, vol. 49, no. 5, pp. 416–427,
the corresponding tensor is likely to yield success or failure. 2001.
Unlike Fig 4, only successful or failed outcomes are shown, [5] G.Valentini,E.Ferrante,andM.Dorigo,“Thebest-of-Nproblemin
robotswarms:Formalization,stateoftheart,andnovelperspectives,”
not the probability of success. Thus, areas where magenta
FrontiersinRoboticsandAI,vol.4,Mar.2017.
and cyan markers overlap indicate uncertain outcomes. [6] D.J.Sumpter,Collectiveanimalbehavior.PrincetonUniversityPress,
Theresultssuggestthatusefullowerdimensional(3D)em- 2010.
[7] H. J. Bussemaker, A. Deutsch, and E. Geigant, “Mean-field analysis
beddingscanbegeneratedforasystemwithvaryingnumber
of a dynamical phase transition in a cellular automaton model for
of agents and sites, which means that the answer to the first collectivemotion,”PhysicalReviewLetters,vol.78,no.26,p.5018,
researchquestionis,subjectively,yes.Theembeddingsshow 1997.
[8] A. L. Nevai, K. M. Passino, and P. Srinivasan, “Stability of choice
the likely paths taken by the colony to reach either success
in the honey bee nest-site selection process,” Journal of Theoretical
or failure, or not converge in some cases. Biology,vol.263,no.1,pp.93–107,2010.
Subjectively, we see the potential for finding clusters [9] H. Wang, M. Lewis, P. Velagapudi, P. Scerri, and K. Sycara, “How
search and its subtasks scale in n robots,” in Proceedings of the
corresponding to basins of attractions: the “hub” region, the
4thACM/IEEEinternationalconferenceonHumanrobotinteraction,
“success”region,the“failure”region,andthe“intermediate” pp.141–148,2009.
region. This suggest that the answer to the second research [10] T.JiaandA.-L.Baraba´si,“Controlcapacityandarandomsampling
method in exploring controllability of complex networks,” Scientific
questions is, subjectively, yes. Importantly, there is not a
reports,vol.3,no.1,pp.1–6,2013.
singleclusterfortheseareasofinterest,butmultipleclusters [11] J.A.Adams,J.Y.Chen,andM.A.Goodrich,“Swarmtransparency,”
in the embedding space (multiple basins of attraction). Ad- in Companion of the 2018 ACM/IEEE International Conference on
Human-RobotInteraction,pp.45–46,2018.
ditionally, there are some regions where it is likely that the
[12] P. Jain and M. A. Goodrich, “Designing and predicting the perfor-
probability of success is low, which may require additional mance of agent-based models for solving best-of-n,” in 2023 IEEE
information from the world to disambiguate. International Conference on Systems, Man, and Cybernetics (SMC),
pp.1076–1083,2023.
Given these observations about how frequently encoun-
[13] I. D. Couzin, J. Krause, R. James, G. D. Ruxton, and N. R. Franks,
tered embeddings aggregate and how embeddings for suc- “Collectivememoryandspatialsortinginanimalgroups,”Journalof
cessfulandfailuretrajectoriescluster,wespeculatethatusing theoreticalbiology,vol.218,no.1,pp.1–12,2002.
[14] A. Reina, J. A. Marshall, V. Trianni, and T. Bose, “Model of the
representations like the one shown in Figure 8, can used to
best-of-n nest-site selection process in honeybees,” Physical Review
predict swarm behavior. This information could potentially E,vol.95,no.5,p.052411,2017.[15] G. Valentini, Achieving Consensus in Robot Swarms, vol. 706 of [36] K.He,X.Zhang,S.Ren,andJ.Sun,“Deepresiduallearningforimage
Studies in Computational Intelligence. Cham: Springer International recognition,” in Proceedings of the IEEE conference on computer
Publishing,2017. visionandpatternrecognition,pp.770–778,2016.
[16] M. Coppola, J. Guo, E. Gill, and G. C. De Croon, “The pagerank [37] S.HochreiterandJ.Schmidhuber,“Longshort-termmemory,”Neural
algorithm as a method to optimize swarm behavior through local computation,vol.9,no.8,pp.1735–1780,1997.
analysis,”SwarmIntelligence,vol.13,no.3-4,pp.277–319,2019. [38] T.Brown,B.Mann,N.Ryder,M.Subbiah,J.D.Kaplan,P.Dhariwal,
[17] R.S.Parpinelli,H.S.Lopes,andA.A.Freitas,“Dataminingwithan A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al., “Language
antcolonyoptimizationalgorithm,”IEEEtransactionsonevolutionary models are few-shot learners,” Advances in neural information pro-
computation,vol.6,no.4,pp.321–332,2002. cessingsystems,vol.33,pp.1877–1901,2020.
[18] M. Dorigo and G. Di Caro, “Ant colony optimization: a new meta- [39] J. Jumper, R. Evans, A. Pritzel, T. Green, M. Figurnov, O. Ron-
heuristic,” in Proceedings of the 1999 congress on evolutionary neberger, K. Tunyasuvunakool, R. Bates, A. Zˇ´ıdek, A. Potapenko,
computation-CEC99 (Cat. No. 99TH8406), vol. 2, pp. 1470–1477, et al., “Highly accurate protein structure prediction with alphafold,”
IEEE,1999. Nature,vol.596,no.7873,pp.583–589,2021.
[19] N.RosenfeldandA.Globerson,“Optimaltaggingwithmarkovchain [40] S.J.AhnandM.Kim,“Variationalgraphnormalizedautoencoders,”in
optimization,”arXivpreprintarXiv:1605.04719,2016. Proceedingsofthe30thACMinternationalconferenceoninformation
[20] I. Sakellariou, “Agent based modelling and simulation using state &knowledgemanagement,pp.2827–2831,2021.
machines,”pp.270–279,072012. [41] S.Pan,R.Hu,G.Long,J.Jiang,L.Yao,andC.Zhang,“Adversarially
[21] M.Kimura,K.Saito,R.Nakano,andH.Motoda,“Extractinginfluen- regularizedgraphautoencoderforgraphembedding,”inInternational
tialnodesonasocialnetworkforinformationdiffusion,”DataMining Joint Conference on Artificial Intelligence 2018, pp. 2609–2615,
andKnowledgeDiscovery,vol.20,pp.70–97,Jan.2010. Association for the Advancement of Artificial Intelligence (AAAI),
[22] Y.Zhang,J.Zhou,andJ.Cheng,“Preference-basedtop-Kinfluential 2018.
nodes mining in social networks,” in 2011 IEEE 10th International [42] P. Contributors, “Binary Cross Entropy Loss with Logits.” https:
Conference on Trust, Security and Privacy in Computing and Com- //pytorch.org/docs/.
munications,(Changsha,China),pp.1512–1518,IEEE,Nov.2011.
[23] T.S.Fergusonetal.,“Whosolvedthesecretaryproblem?,”Statistical
science,vol.4,no.3,pp.282–289,1989.
[24] S. Mehar and S. M. Senouci, “An optimization location scheme for
electricchargingstations,”in2013internationalconferenceonsmart
communicationsinnetworktechnologies(SACONET),vol.1,pp.1–5,
IEEE,2013.
[25] R. D. Estes, “Social organization of the african bovidae,” The be-
haviourofungulatesanditsrelationtomanagement,vol.1,pp.166–
205,1974.
[26] J.Omic,R.Kooij,andP.VanMieghem,“Virusspreadincompletebi-
partitegraphs,”in2ndInternationalICSTConferenceonBio-Inspired
ModelsofNetwork,Information,andComputingSystems,2008.
[27] M.MesbahiandM.Egerstedt,Graphtheoreticmethodsinmultiagent
networks. PrincetonUniversityPress,2010.
[28] G.Berna´rdez,J.Sua´rez-Varela,A.Lo´pez,X.Shi,S.Xiao,X.Cheng,
P. Barlet-Ros, and A. Cabellos-Aparicio, “Magnneto: A graph neu-
ral network-based multi-agent system for traffic engineering,” IEEE
Transactions on Cognitive Communications and Networking, vol. 9,
no.2,pp.494–506,2023.
[29] X. Mo, Y. Xing, and C. Lv, “Heterogeneous edge-enhanced graph
attentionnetworkformulti-agenttrajectoryprediction,”arXivpreprint
arXiv:2106.07161,2021.
[30] W. Hamilton, Z. Ying, and J. Leskovec, “Inductive representation
learningonlargegraphs,”Advancesinneuralinformationprocessing
systems,vol.30,2017.
[31] D. Nguyen, W. Luo, T. D. Nguyen, S. Venkatesh, and D. Phung,
“Learning graph representation via frequent subgraphs,” in Proceed-
ings of the 2018 SIAM International Conference on Data Mining,
pp.306–314,SIAM,2018.
[32] J. R. Cody and J. A. Adams, “An evaluation of quorum sensing
mechanismsincollectivevalue-sensitivesiteselection,”in2017Inter-
nationalSymposiumonMulti-RobotandMulti-AgentSystems(MRS),
(LosAngeles,CA),pp.40–47,IEEE,Dec.2017.
[33] P.JainandM.A.Goodrich,“Processesforacolonysolvingthebest-
of-nproblemusingabipartitegraphrepresentation,”inProceedingsof
the15thInternationalSymposiumonDistributedAutonomousRobotic
Systems,(VirtualConference),2021.
[34] M. A. Goodrich and P. Jain, “A probabilistic bipartite graph model
for hub based swarm solution of the best-of-N problem,” in Twelfth
InternationalConferenceonSwarmIntelligence,ANTS,2020.
[35] G. E. Hinton and S. Roweis, “Stochastic neighbor embedding,” Ad-
vancesinneuralinformationprocessingsystems,vol.15,2002.