ECG-FM: An Open Electrocardiogram Foundation Model
Kaden McKeen1,2,3,4,5, Laura Oliva2, Sameer Masood1,8, Augustin Toma6, Barry Rubin1,2, and Bo
Wang1,2,3,4,5,6,7
1 University Health Network, Toronto, Canada
2 Peter Munk Cardiac Centre, University Health Network, Toronto, Canada
3 AI Hub, University Health Network, Toronto, Canada
4 Vector Institute for Artificial Intelligence, Toronto, Canada
5 Department of Laboratory Medicine and Pathobiology, University of Toronto, Toronto, Canada
6 Department of Medical Biophysics, University of Toronto, Toronto, Canada
7 Department of Computer Science, University of Toronto, Toronto, Canada
8 Department of Medicine, University of Toronto, Toronto, Canada
Abstract. The electrocardiogram (ECG) is a ubiquitous diagnostic test. Conventional task-specific
ECG analysis models require large numbers of expensive ECG annotations or associated labels to
train. Transfer learning techniques have been shown to improve generalization and reduce reliance
on labeled data. We present ECG-FM, an open foundation model for ECG analysis, and conduct a
comprehensivestudyperformedonadatasetof1.66millionECGssourcedfrombothpubliclyavailable
andprivateinstitutionalsources.ECG-FMadoptsatransformer-basedarchitectureandispretrainedon
2.5millionsamplesusingECG-specificaugmentationsandcontrastivelearning,aswellasacontinuous
signal masking objective. Our transparent evaluation includes a diverse range of downstream tasks,
where we predict ECG interpretation labels, reduced left ventricular ejection fraction, and abnormal
cardiac troponin. Affirming ECG-FM’s effectiveness as a foundation model, we demonstrate how its
command of contextual information results in strong performance, rich pretrained embeddings, and
reliable interpretability. Due to a lack of open-weight practices, we highlight how ECG analysis is
lagging behind other medical machine learning subfields in terms of foundation model adoption. Our
code is available at https://github.com/bowang-lab/ECG-FM/.
1 Introduction
The electrocardiogram (ECG) is a standard, low-cost, non-invasive diagnostic test that has been ubiquitous
in the assessment and management of cardiovascular disease for decades. Since human ECG interpretation
quality varies greatly according to level of expertise1, computerized interpretations are meant to improve
interpretation accuracy and mitigate interobserver variability. However, traditional rule-based methods tend
to fall short of providing accurate interpretations and can be met with skepticism, warranting caution when
used for clinical decision-making2.
Artificial intelligence (AI) based ECG analysis methods have been shown to outperform traditional com-
puterized interpretation3,4 and can detect patterns largely unrecognizable to humans, thereby transforming
theECGintoaprecise,non-invasivebiomarker.Recenttechnologicaladvancementsandthegrowingnumber
of large, publicly available datasets have sparked an increase in AI-based methods for the analysis of clinical
cardiac data3–7. Certain models even exhibit performance that matches or exceeds that of humans5,8, such
as Al-Zaiti et al.9 outperforming practicing clinicians when identifying myocardial infarction on ECGs.
The field of medical AI is experiencing a paradigm shift, wherein conventional task-specific models are
beingreplacedbyfoundationmodels.Afoundationmodelischaracterizedbyitsrapidadaptabilitytodown-
stream tasks and reduced reliance on costly labeled data. It is initially trained on vast amounts of unlabeled
data in a process known as pretraining, such that it can then be finetuned on labeled samples across a broad
rangeofdownstreamtasks.Thistechnique,calledtransferlearning,tendstogeneratemodelswhicharemore
performant and label-efficient than their conventional task-specific counterparts. In light of this, foundation
models are quickly becoming the standard for generating state-of-the-art models for applications as diverse
asmedicalimagingsegmentation10,diagnosticsanddiseaseprediction5,11,andmedicaltextinterpretation12.
4202
guA
9
]GL.sc[
1v87150.8042:viXra2 McKeen et al.
In this study, we introduce ECG-FM, an open ECG foundation model. ECG-FM is a large, transformer-
basedmodelpretrainedon2.5millionECGsegments.Itacceptsa5sECGasinputandcanbefinetunedon
anyarbitraryleadsubsetofthestandard12-leadECG.Weperformcomprehensiveevaluationsondownstream
tasks which include the prediction of select conditions from ECG interpretations, reduced left ventricular
ejection fraction (LVEF), and abnormal cardiac troponin (cTn). We validate ECG-FM’s effectiveness as a
foundationmodel,highlightingthesignificantgainsachievedthroughpretrainingandreportinglinearprobing
performances.
1.1 Related works
Non-neural methods Standard 12-lead, 500 Hz ECG waveforms constitute high-dimensionality model in-
puts which, alongside data scarcity, can lead to overfitting and poor generalizability. Adopting a non-neural,
data-efficientarchitectureisonewayaddresstheseissues.Suchapproacheslargelyrelyonfeatureengineering
for dimensionality reduction, deriving smaller inputs suitable for non-neural architectures.
Siontis et al.13 summarized the state of AI ECG analysis in 2021, wherein logistic regression was outper-
formed by a random forest model. They specifically noted how errors in human-driven feature engineering
can limit model accuracy. Al-Zaiti et al.9 adopted a random forest model and applied data-driven strategies
alongside domain expertise for feature engineering. This approach was shown to outperform clinicians and
other commercial systems to predict myocardial infarction after coronary artery occlusion.
Conventional, task-specific neural approaches Neural methods need not rely on derived features, di-
rectly taking the ECG time series as input. This negates the risk of omitting clinically-relevant information
present in the raw waveform during feature engineering.
Convolutionalneuralnetworks(CNN)areaconventionalchoiceofarchitectureforECGanalysis,accepting
the raw signal as input while maintaining reasonable data efficiency. Attia et al.14 present their deep CNN
for diagnosing reduced LVEF using 10 s 12-lead ECGs sampled at 500 Hz. Hughes et al.15 developed the
Stanford Estimator of Electrocardiogram Risk (SEER) for prediction of several cardiovascular conditions,
including 5-year cardiovascular mortality and atherosclerotic cardiovascular disease using 10 s 12-lead ECGs
sampled at 250 Hz. Herman et al.3 utilized 6 CNNs to predict a wide variety of conditions over 6 categories
(cardiac rhythm, acute coronary syndrome, conduction abnormalities, ectopy, chamber enlargement, and
axis) using 5 s segments sampled at 500 Hz. These methods are all quite similar, consisting of architectures
having a number of CNN blocks for feature extraction, followed by a few fully-connected layers to perform
classification.
Foundationmodels Focusingonmethodsutilizingtransferlearning,weconsideradaptabilitytonewdown-
stream tasks as the minimum requirement for a foundation model.
Laietal.16 tookwearable12-leadECGsanddevelopedamultiscaleResNet18model,pretrainingitusing
a Siamese network and momentum contrastive learning and finetuning it to detect rhythm abnormalities,
transientarrhythmias,andheartbeatwaveformchanges.ContrastiveLearningofCardiacSignals(CLOCS)17
introducedafamilyofECG-specificcontrastivelearningtechniqueswhichencouragerepresentationsthatre-
spect spatial, temporal, and patient characteristics.
Transformers are deep learning architectures for sequence modeling which utilize the self-attention mech-
anism to better contextualize sequential data18. When adopted alongside transfer learning techniques, this
forms the typical basis for a sequence-based foundation model. Designed for natural language processing,
BERT is the original encoder-only transformer architecture, where it is pretrained using next-sentence pre-
diction and masked language modeling (MLM) objectives19.
Abbaspourazad et al.20 took Apple Watch data and performed contrastive learning using time-series
augmentations and InfoNCE, developing EfficientNet, ResNet, and 1D-ViT architectures to predict age,ECG-FM: An Open Electrocardiogram Foundation Model 3
body mass index (BMI), and biological sex. ECGBERT21 segments, tokenizes, and masks individual beats
during pretraining, evaluating on tasks including atrial fibrillation and heartbeat classification. HeartBeiT
is a vision transformer (ViT) foundational model which accepts standard 12-lead ECG images as inputs
and masks tokenized heartbeats during pretraining22. Oh et al.23 combined the architecture and masking
objective of wav2vec 2.024 with the CMSC objective introduced by CLOCS17 to better capture local and
global contextual information.
1.2 A need for open ECG foundation models
There are exceedingly few publicly released pretrained model checkpoints for ECG analysis. A great deal
of time and computing resources have been invested into the research and development of closed models
which ultimately may not impact patient care. Codebases are also often not released, making it difficult to
implement standardized benchmarks. Often, comparative evaluations must rely on reported metrics across
disparate experimental setups. When code is released, the models and results are typically not reproducible
due to the use of private data sources and considerable computational requirements.
As the number of ECG datasets inevitably grows, methods leveraging transfer learning will become in-
creasingly predominant. Without accessible foundation models, it may not be possible for research groups in
data or resource-scarce settings to stay competitive, whereby limiting innovation as a whole. Releasing mod-
els improves accessibility, enabling fair benchmarking, preventing duplicated pretraining efforts, and broadly
empowering developers.
In releasing ECG-FM, we hope to foster a shift towards open-weight practices, especially the sharing of
pretrainedmodels,tolaythegroundworkforacollaborativeenvironmentthatwillstimulategreaterresearch
innovation, fair evaluation, and real-world impact on patient care.
2 Method
2.1 Data
We collected a total of 1.66 million standard 12-lead ECGs from the UHN-ECG, PhysioNet 202125–27, and
MIMIC-IV-ECG27,28 datasets. Specifically, we include six datasets in PhysioNet 2021: CPSC, CPSC-Extra,
PTB-XL, Georgia, Ningbo, and Chapman. The PTB and St Petersburg INCART datasets are excluded due
to having few long samples with inconsistent sampling rates. MIMIC-IV-ECG v1.0 database contains many
10s ECGs collected from the Beth Israel Deaconess Medical Center. PhysioNet 2021 and MIMIC-IV-ECG
are two public data sources which we integrated to increase the number of pretraining samples.
UHN-ECG UHN-ECG is a newly assembled private, institutional dataset containing 775k ECG recordings
from 211k patients acquired between January 2010 and December 2020. This 11-year dataset was collected
at Toronto General Hospital and Toronto Western Hospital, which are two acute care hospitals that have
emergency departments, cardiology wards, and coronary care units. These exist as part of the University
HealthNetwork(UHN),anetworkofacademichospitalslocatedinToronto,Canada.Allrecordingsare10s,
where 90.4% have an original sampling frequency of 500 Hz and the remaining have 250 Hz. Every ECG has
a cardiologist over-read and there are many associated clinical reports and auxiliary data modalities which
make for excellent label availability.
This iteration of the UHN-ECG dataset suffered from distribution shift due to inconsistent sample col-
lection methodology. Sample collection was performed in batches, where data obtained from 2019 onwards
had select outcomes which saw instantaneous decreases in prevalence. This was especially true for arrhyth-
mias such as atrial fibrillation and ventricular tachycardia. Our temporal stratification lead to 39% of the
validation set occurring after 2019, as well as the entirety of the test set. We confirmed that such labels
performed unreasonably better on the validation set than the test set, implying that this shift indeed biased
our evaluation negatively. This prevented us from evaluating several desirable labels, limiting our selection4 McKeen et al.
to those less affected outcomes.
Approximately 12.9% of the ECGs were labeled with poor data quality on their interpretations. This
includes various artifacts, muscle interference, as well as lead misplacement and reversal. We noticed that
interpretation may be attempted regardless, and so opted to correspondingly predict through poor data
quality during both training and evaluation, so as to retain these samples and produce a model robust to
real-world clinical environments.
ECG preprocessing WeextractedrawwaveformsandtabularizedECGmetadata,includingsamplerates,
sample size, and patient demographic information wherever available. We sampled the waveforms at 500 Hz,
performed z-score normalization, and segmented the signals into non-overlapping 5 s segments to produce
the model inputs. Since UHN-ECG and MIMIC-IV-ECG both contain 10 s recordings, the vast majority of
ECGs are segmented in half.
Fig.1.Cohortandsampleselection.ThisflowdiagramshowsthedatasourcesandECGexclusioncriteria,aswell
asthedatasetpartitioning.Thepretrainingcohortcombinessamplesfromallthreedatasets,whereasthedownstream
task cohorts specifically utilize UHN-ECG samples according to label availability.
2.2 Cohort curation
We removed ECGs having null values or leads with constant, all-zero values, which composed a combined
19,552 ECGs across all three datasets. To maintain a more representative distribution of in-hospital popula-
tions, there were no exclusions based on ECG or patient characteristics.
Eachdatasetwasindividuallysplit80%/10%/10%fortraining,validation,andtesting,respectively.These
partitionswereusedandrespectedacrossallexperimentstoimprovesampleefficiency,suchthatwefinetuneECG-FM: An Open Electrocardiogram Foundation Model 5
on a subset of the pretraining data. The method by which each dataset was split was dependent on its
available metadata. The UHN-ECG dataset was split by patient as well as temporally, ensuring there is no
overlap in the patients or ECG acquisition periods between the training and the evaluative splits. Therefore,
our retrospective evaluation more closely resembles a prospective evaluation (see Figure 4 for more details).
MIMIC-IV-ECGwassplitbypatientandPhysioNet2021wassplitatrandom,however,theirevaluativesets
were not used for the purposes of this work.
2.3 Model architecture
We used the wav2vec 2.024 model architecture, which consists of a multi-layer CNN feature extractor and a
BERT-like transformer encoder. The feature extractor effectively embeds portions of the raw signal, gener-
ating latent representations z which are fed to a transformer encoder to create local contextualized repre-
t
sentations c .
t
Our feature encoder specifically contains 4 blocks, each comprised of a convolutional layer having 256
channels, a stride of 2, and a kernel length of 2, followed by layer normalization and the GELU activation
function. Relative positional embeddings are learned using a convolutional layer having 128 filters and 16
groups, which are then added to the latent representations.
For the transformer encoder, we selected hyperparameters consistent with the BERT-Large encoder,
having 24 transformer block layers, an embedding dimension of 1,024, 16 self-attention heads, and a feed-
forward network dimension of 4,096. This stands in contrast to Oh et al.23, who used a BERT-Base sized
encoder and performed their experiments on a reported 189,051 inputs from the PhysioNet 2021 dataset23.
We upscaled ECG-FM to ensure sufficient representational capacity, increasing the number of parameters
from 90.9 million to 311.9 million.
2.4 Pretraining method
We build upon the work of Oh et al.23, adopting their pretraining method and developing from their public
ECG modeling repository‡‡. This method combines the masking objective proposed in wav2vec 2.024, the
contrastive CMSC objective introduced by CLOCS17, and the Random Lead Masking (RLM) augmentation
presented by Oh et al.23. This approach, previously named W2V+CMSC+RLM, will henceforth be referred
to as WCR for brevity.
wav2vec 2.0 Inspired by MLM, wav2vec 2.0 masks spans of CNN latent representations z . Each token
t
has a 6.5% probability of being a starting index, where if selected, we mask the subsequent 10 tokens. This
results in approximately 49% of a sample’s tokens being masked.
Ratherthandirectlyusingthemaskedz asthetarget,weadoptthewav2vec2.0quantizationmoduleto
t
helpremovedetailedartifactswhichwouldotherwisemakethetaskeasier,therebyhurtinggeneralizability24.
Specifically, we quantize z to q during pretraining using two trainable codebooks of 320 codes. A codebook
t t
diversity loss is applied to encourage more equal usage of codebook entries.
In order to capture local context, a contrastive loss is used to enable the distinction of a true latent from
a number of distractors. For each masked token, we maximize the cosine similarity between quantized target
q and its corresponding local contextualized representation c , while minimizing it over distractors q˜∼Q ,
t t t
which are sampled from the set of all masked token quantized targets Q . This requires the model to learn
t
how to leverage local contextual information to infer c based on nearby unmasked representations.
t
CMSC Exploiting how underlying heart function is relatively stable moment-to-moment, CLOCS’ Con-
trastive Multi-segment Coding (CMSC) is a contrastive objective which we apply between the global repre-
sentations.IttreatstemporallyadjacentECGsegmentsaspositivepairs,wherethenegativepairsarederived
‡‡https://github.com/Jwoo5/fairseq-signals/6 McKeen et al.
from other segments17.
CMSC exploits ECG cyclicity to promote temporal invariance and capture functionally relevant informa-
tion.ByencouragingconsistentrepresentationsbetweenconsecutiveECGsegments,CMSCtrainsthemodel
todistinguishbetweenfunctionalandsuperficialdifferencesinpresentation,forexample,teachingittoignore
where in the cardiac cycle a segment begins.
RLM Oh et al.23 introduces Random Lead Masking (RLM), an ECG-specific augmentation wherein each
individual lead is masked at random with probability p = 0.5. It was demonstrated that by exposing the
model to diverse lead combinations during pretraining, it can be robustly finetuned using an arbitrary set
of leads23. Thus, ECG-FM is highly flexible since it is applicable not only with standard 12-lead ECGs, but
also in contexts where only a subset of these leads is available.
Fig.2. Framework illustration. Raw waveforms are inputted and individual leads are randomly masked. A con-
volutional feature encoder generates latent representations that feed into a transformer encoder, producing local
representationsthatarethenaverage-pooledtocreateglobalrepresentations.Positiveandnegativecontrastivelearn-
ing pairs are depicted using blue and red arrows, respectively. In spans, latent representations are randomly masked
asmandquantizedtoq.Wethenapplyalocalcontrastivelossattractingeachq toitscorrespondinglocalrepresen-
tation, using a subset of other q as the negative samples, or distractors. A batch of four ECG inputs, making up two
positive pairs of temporally-adjacent ECG segments, are shown to visualize the CMSC global contrastive loss acting
on the global representations across samples.
PretrainingECG-FMusingWCRlendsmanydesirablequalities.Theintra-ECGwav2vec2.0contrastive
loss is applied to better capture local contextual information. The inter-ECG CMSC contrastive loss pro-
motes temporal invariance and more functionally discriminative global representations. RLM serves as an
augmentationwhichleadstoamorerobustmodelwhichcanbefinetunedonanyarbitrarysubsetofleads23.ECG-FM: An Open Electrocardiogram Foundation Model 7
2.5 Downstream tasks
To demonstrate that ECG-FM is useful for a variety of downstream applications, we selected three diverse
clinical classification tasks for our internal evaluation.
Interpretation In-hospital interpretations are performed by physicians to diagnose ECG tracings, which
then contribute to clinical processes such as medical decision making29. Correct interpretation is especially
challenging for physicians with low-level knowledge of ECGs30,31. As primary readers, cardiologists correct
misinterpreted ECGs more often than internists or other specialists32, also demonstrating greater interpre-
tationaccuracyandlessinterobservervariabilityincomparisontophysicianswithlessspecializedtraining1,14.
In the UHN-ECG dataset, each ECG is accompanied by a cardiologist interpretation written atop an
automated read. We extracted binary labels from these free-text expert interpretations. If a patient had
multiple interpretations, the latest interpretation was used. We found that text parsing solutions using large
language models and named entity recognition were inadequate due to insufficient domain knowledge and
an inability to handle common inconsistencies such as typographical errors and the use of synonyms. The
interpretations are well-structured, which motivated us to manually develop a text-parsing system based on
pattern matching and a knowledge graph to produce more accurate labels. Further details can be found in
Section 6.3.
Reduced left ventricular ejection fraction Heart failure (HF) is a complex syndrome acting as a major
contributor of morbidity and mortality worldwide, with approximately 50% of cases being heart failure with
reduced ejection fraction (HFrEF)33. ECGs can be used to screen for reduced LVEF and may assist in the
diagnosis of HFrEF. Indeed, the heightened risk of mortality associated with HFrEF, even in asymptomatic
cases, underscores the significance of early detection for timely intervention34,35.
We used regex to extract LVEF percentages from echocardiography reports and generated labels based
on the American College of Cardiology LVEF classification of mild, moderate, and severe left ventricular
dysfunction36. We specifically predict LVEF≤50%, LVEF≤40%, and LVEF≤30%. We pair each ECG with
its closest associated echocardiography report which reports an LVEF percentage, subsetting to those ECG
samples with a valid report within 7 days of acquisition, whether before or after.
Abnormal cardiac troponin Cardiac troponin (cTn) is a protein that appears in the blood only when
the heart muscle has been damaged. It is found to be elevated in patients with a myocardial infarction or
inflammation of heart muscle, where blood tests are performed periodically to establish trends. Abnormal
cTn can refer to abnormally high measurements and associated trend dynamics, which are widely used as a
biomarker for diagnostic decision-making and risk stratification of myocardial injury37.
Using measurements sourced from tabularized blood test results, we predict any abnormal cTn measure-
ment within 30 days of an ECG, whether occurring before or after. If no measurements are present within
30 days, we assume a negative label. This is because cTn is ordered quite liberally in patients deemed to be
at risk for acute cardiac disease. UHN uses the Abbott ARCHITECT cTn assay to determine whether a cTn
level is abnormal, where a measurement is identified as abnormal in accordance with its respective upper
reference limit for healthy populations (see Section 6.4 for further details)37,38. UHN transitioned from an
earlier generation "conventional" cTn assay to a high sensitivity cTn assay in February 2015.
Weexploredonepotentialemergencydepartmentriskstratificationschemefortriagingpatientsjudgedto
be at risk for acute cardiac disease. Using an initial ECG to identify risk before cTn test results are available
could serve to inform resource allocation and expedite clinical decision making. For instance, those at higher
risk could be prioritized for a bed with continuous cardiac monitoring and urgent cardiology assessment.
2.6 Experiments
The ECG-FM model pretrained on 2,503,136 samples using 4 A100 80GB GPUs with distributed data par-
allelism and gradient accumulation, resulting in an effective batch size of 1024 ECG segments. We used a8 McKeen et al.
learning rate of 5×10−5. Training was halted after 110 epochs, resulting in a wall time of 16.49 days.
There were three suites of classification experiments run for each downstream task. We initialize our
WCR-Pretrained models with the pretrained weights and perform full finetuning, wherein all model weights
areupdated,usingalearningrateof1×10−6.ForRandom Init.,werandomlyinitializethemodelsandthen
performfullfinetuningwithalearningrateof1×10−5.Tomaintainafaircomparison,theweightinitialization
andlearningratesweretheonlyexperimentaldifferencesbetweentheWCR-Pretrained andRandom Init.ex-
periments. In the Linear experiment, we perform linear probing, such that pretrained model embeddings are
extractedandfedasinputstoasinglelinearlayertogeneratepredictions.Thepurposeofthisfrozenevalua-
tionistodeterminewhetherthepretrainedembeddingsencoderich,accessible,andtask-relevantinformation.
For each downstream task, experiments used identical inputs and labels, running on a single A100 80GB
GPU using a batch size of 256. All experiments used the Adam optimizer39 with β = 0.9, β = 0.98.
1 2
Checkpoints were selected according to which had the best AUPRC on the validation set. Thresholds were
selectedbasedonclinicalusefulness,aswellastomaximizecomparabilitysinceseveralworkslackthreshold-
independent metrics such as AUROC and AUPRC. We did not perform hyperparameter experimentation
beyond learning rate adjustment.
3 Results
Table 1. Interpretation task results for WCR-Pretrained. Label-specific test performances on our WCR-
pretrained, full finetuned model for multi-label classification.
Label AUROCAUPRCRecallPrecision F1 SpecificityNPVAccuracy
Sinus rhythm 0.984 0.998 0.990 0.982 0.986 0.806 0.886 0.974
Normal sinus rhythm 0.953 0.933 0.926 0.897 0.911 0.887 0.919 0.907
Tachycardia 0.996 0.976 0.903 0.946 0.924 0.992 0.985 0.980
Bradycardia 0.994 0.953 0.933 0.885 0.908 0.983 0.990 0.977
PVC 0.951 0.769 0.726 0.744 0.735 0.987 0.986 0.975
Myocardial infarction 0.942 0.833 0.895 0.580 0.704 0.837 0.969 0.848
AV block 0.988 0.880 0.919 0.714 0.803 0.968 0.993 0.964
RBBB 0.991 0.934 0.943 0.738 0.828 0.961 0.993 0.959
LBBB 0.994 0.886 0.840 0.759 0.797 0.992 0.995 0.987
Electronic pacemaker 0.985 0.936 0.850 0.961 0.902 0.998 0.992 0.990
Ventricular pacing 0.999 0.977 0.969 0.934 0.951 0.997 0.999 0.996
Atrial pacing 0.995 0.926 0.903 0.870 0.886 0.998 0.998 0.996
Poor data quality 0.910 0.700 0.747 0.541 0.627 0.903 0.959 0.882
Interpretation In-hospital ECG testing is typically swift. However, obtaining expert cardiologist inter-
pretations requires more time. In UHN-ECG, the median time from ECG acquisition to its first expert
interpretation is 17.7 hours. The results demonstrate that our model is capable of reproducing portions of
highlyskilledinterpretations,wherethesepredictionscouldbemadeavailableimmediatelyafterECGacqui-
sition.
We achieve high performance across numerous labels using an unfiltered cohort representative of our
in-hospital populations. With a considerable 13.3% of the test set being labeled with poor data quality, our
results demonstrate that ECG-FM is robust to low-quality recordings.
The nature of our experimental design and method means that our predictions are based on a 5 s ECG
segment, whereas the full annotated sample is 10 s. We explore the implications of this on our evaluation in
supplementarySection6.1byaggregatingthepredictionsofbothsegmentstoseehowthisaffectsperformance.ECG-FM: An Open Electrocardiogram Foundation Model 9
Indeed, this affects certain labels greatly, including a notable 15.97% increase in AUPRC for premature
ventricular contraction (PVC).
Table 2.Comparative results for reduced LVEF task.Label-specific test performances. ECG-FMdenotesour
WCR-pretrained,fullfinetunedmodelformulti-labelclassification.Metricsforcompetingmethodsappearasreported
in their respective publications. We bold the best performing metrics on a per-label basis.
Label Source PrevalenceAUROCAUPRCRecallPrecision F1 Specificity NPV Accuracy
LVEF≤30%Jentzer (2021)40 0.164 0.850 - 0.822 0.380 0.520 0.736 0.954 0.750
ECG-FM 0.140 0.948 0.738 0.880 0.540 0.670 0.878 0.978 0.878
LVEF≤40%Vaid (2023)22 0.185 0.900 0.730 - - - - - -
Jentzer (2021)40 0.336 0.830 - 0.728 0.624 0.672 0.778 0.849 0.761
Cho (2021)41 0.068 0.961 - 0.915 - - 0.911 - 0.911
Brito (2021)42 0.071 0.839 - 0.730 - - 0.830 - -
Kashou (2021)43 0.020 0.971 - 0.900 - - 0.919 - -
Katsushika (2021)44 0.095 0.945 0.740 0.858 0.494 0.627 0.900 0.982 0.896
Kwon (2019)45 0.061 0.843 - - - - - - -
ECG-FM 0.241 0.935 0.833 0.858 0.659 0.746 0.860 0.950 0.859
LVEF≤50%Jentzer (2021)40 0.457 0.810 - 0.696 0.730 0.713 0.783 0.753 0.743
Kashou (2021)43 0.060 0.880 - 0.764 - - 0.879 - -
Sun (2021)46 0.047 0.709 - 0.692 0.701 0.696 0.705 0.699 0.739
Chen (2022)47 0.015 0.885 - 0.721 - - 0.880 - -
ECG-FM 0.370 0.924 0.891 0.845 0.767 0.804 0.849 0.903 0.848
Reduced left ventricular ejection fraction Our comparative evaluation for this task relies on reported
metrics, as opposed to computed scores. We highlight methods with similar experimental setups to promote
fair comparison.
WeoutperformJentzeretal.40 onallreducedLVEFlabelsandacrossallreportedmetrics.Wespecifically
note this task-specific method due to its common CNN architecture (the same used in Attia et al.14) and
reporting of the same labels we selected. It bears a similar experimental setup, including ECGs within seven
daysofatransthoracicechocardiographyreportandexcludingpatientswhosereportdidnotcontaindataon
LVEF. They report higher outcome prevalence rates and train on a relatively large cohort of nearly 100,000
patients40.
WeadditionallyoutperformHeartBEiT,anotherECGfoundationmodelacceptinga5sECGasinput22,
on the LVEF≤40% label which they also extracted from echocardiogram reports. For fair comparison, we
reporttheirinternaltestingmetricsforthemodeltrainedusingalloftheirfinetuningdata.DespiteHeartBEiT
pretraining on 8.5 million ECGs and finetuning on 511,491 samples22, we obtain 3.89% higher AUROC and
14.1% higher AUPRC by comparison.
Table 3. Abnormal cardiac troponin task test results for WCR-Pretrained. Test performances on our
WCR-pretrained, full finetuned model for classification. Metrics correspond to single label, as evaluated at different
thresholds. Each row represents a different risk category, together producing one potential risk stratification scheme.
Category AUROCAUPRCRecallPrecision F1 SpecificityNPVAccuracy
Low risk 0.882 0.782 0.985 0.427 0.596 0.324 0.978 0.548
Medium risk 0.882 0.782 0.740 0.722 0.731 0.855 0.865 0.816
High risk 0.882 0.782 0.275 0.883 0.419 0.981 0.726 0.74310 McKeen et al.
Abnormalcardiactroponin Ingeneratingriskscoresbyapplyingdifferentthresholds,weposeanexample
risk stratification scheme. Low risk shows high recall and negative predictive value, such that we are unlikely
to miss any cases of abnormal cTn. High risk lends a high specificity, such that false positives are unlikely
to result in costly resource allocations. Medium risk provides further discrimination and stands as the most
accurate category.
Saliency maps Toimproveinterpretability,wegeneratedattention-basedsaliencymaps.Specifically,weex-
tracted the attention weights, as averaged across the heads, from the final transformer encoder self-attention
layer. Once mapped into the input space, these activations provide a straightforward interpretation of the
relative input importance.
Understandinghowamodelgeneratesapredictionnotonlyimprovesinterpretability,butcanalsoinform
the quality of the model itself. Considering the nature of ECG cyclicity, we highlight how each model is
consistent in where it attends across beats.
Fig.3. Saliency maps. Shown is Lead II of three ECGs, each colored using activations derived from the WCR-
pretrained,full-finetunedmodels.Redrepresentsahigherrelativeactivation.(a)Interpretationmodelactivationsfor
anECGlabeledwithventricularpacing;(b)ReducedLVEFmodelactivationsforanECGlabeledwithLVEF≤30%;
(c) Abnormal cTn model activations for an ECG labeled with abnormal cTn and myocardial infarction.
Experiment suite performance summaries From Random Init. to WCR-Pretrained, we achieve signif-
icant 4.6%, 15.6%, 9.1% AUPRC increases respectively in the interpretation, reduced LVEF, and abnormal
cTn tasks. This elucidates the incredible gains to be had through pretraining, even when using larger fine-
tuning datasets. Our linar probing experiments demonstrate that, despite the many nuances underpinning
ECG presentation, our pretrained model embeddings encode rich, linearly separable, and task-generalizable
information.ECG-FM: An Open Electrocardiogram Foundation Model 11
Table4.Experimentsuiteperformancesummaries.Comparisonoflabel-averagedAUROCandAUPRCscores
across experiment suites. We bold the best performing metrics.
AUROC AUPRC
Task WCR-PretrainedRandom Init.LinearWCR-PretrainedRandom Init.Linear
Interpretation 0.976 0.965 0.930 0.900 0.861 0.735
Reduced LVEF 0.936 0.890 0.859 0.821 0.710 0.647
Abnormal cTn 0.882 0.843 0.807 0.782 0.717 0.664
4 Discussion
We demonstrate strong performances on a diverse set of clinically relevant tasks. Our transparent evaluation
invites comparison by reporting all commonly used metrics, where we identified AUPRC to be the most
discriminative metric in the presence of imbalanced labels.
Our interpretation task represents a step towards achieving expert-level 12-lead interpretation. We ac-
knowledge the importance of investigating our model’s ability to improve upon or substitute traditional
computerized interpretation methods.
For the reduced LVEF identification task, we performed a comparative evaluation showcasing better
performances over works having experimentally similar methodology. Specifically, outcompeting Jentzer et
al.40, with its common CNN architecture, speaks to how ECG-FM can outclass conventional task-specific
methods. ECG-FM also outperforms HeartBEiT22, an existing ECG foundation model trained on a larger
dataset, speaking to the quality of our method. We acknowledge the limited comparability of these findings
considering the use of different datasets.
The abnormal cTn risk stratification results demonstrate potential to better inform clinical decision-
making during emergency department patient triage. These risk scores would serve as additional pieces of
information which help ensure patients suspected of having acute cardiac disease are provided with appro-
priate levels of care.
We illustrate the substantial benefits of WCR pretraining for downstream task prediction. Pretraining
was especially beneficial in the reduced LVEF task, which had the smallest sample size of our downstream
tasks; this may serve as early indication that small data regimes stand to derive even greater benefits by
finetuning from ECG-FM.
Our linear probing experiments demonstrate how the pretrained ECG-FM model generates global rep-
resentations which broadly capture useful ECG features, elucidating its capacity to robustly generalize to
unseen tasks. Our use of a single linear layer shows just how accessible this discriminative information is
within our pretrained embeddings. These results demonstrate that the pretrained ECG-FM model can be
directly used to generate a rich feature set of compact representations.
ECG-FMexhibitsastrongcommandoflocalcontextualinformation.Insaliencymaps,itdisplaysprefer-
entialattention,asevidencedbyconsistentlybasingitspredictionsonthesameregionsacrosscardiaccycles.
Demonstration of desirable model qualities may help to reduce skepticism and improve clinical adoption.
Limitations We acknowledge several experimental limitations. In future work, we will account for the
distribution shift caused by inconsistent sample collection, such that we can more accurately evaluate our
model and predict additional clinically useful labels. In our abnormal cTn task, we definitively produce a
negative label when no cTn measurements are available, however, this may represent an overly presumptive
label definition.
Future work We envision many promising avenues for extending this work. Our rich UHN-ECG dataset
provides opportunities to explore further novel downstream applications. As an ECG encoder, ECG-FM12 McKeen et al.
is ripe for integration into multimodal foundation models harnessing complementary data sources. Due to
time constraints, we declared baseline model and data scaling experiments as out-of-scope. In studying how
finetuning dataset size affects performance in comparison to existing methods, we can definitively determine
whetherECG-FMoutperformsconventionalbaselinesandhoweffectivelyitreducesrelianceonlabeleddata.
Werecognizetheimportanceofexternalevaluation,andhowmodelvalidationonpubliclyavailabledatacan
enhance study comparability. We are committed to including such evaluations in future work.
5 Conclusion
Inthiswork,wepresentECG-FM,atransformer-basedECGanalysismodelpretrainedonmillionsofsamples,
andrunasuiteofexperimentsvalidatingitseffectivenessandutilityasafoundationmodel.Wedemonstrate
that it is a robust model capturing rich local and global contextual information. ECG-FM holds immense
promise for improving patient care, especially during early decision-making that can enhance patient triag-
ing and timely detection of cardiac disease. By publicly releasing the ECG-FM model parameters, we aim
to promote open-weight practices and catalyze a paradigm shift in the ECG analysis subfield toward the
transparent development and adoption of foundation models.
Dataavailability UHN-ECGdataisnotcurrentlyavailableforpublicuse.PhysioNet2021v1.0.3isavailable
for public download (https://doi.org/10.13026/34va-7q14), as is MIMIC-IV-ECG v1.0 (https://doi.org/10.
13026/4nqg-sb35).ModelweightsareavailableonourGitHub,however,duetoprivacyconcernssurrounding
UHN-ECGdataandpatientidentification,thesemodelswerepretrainedpurelyonpublicdatasourcesandare
thusdifferentfromthosereportedinthiswork.Validatedmodelswillbemadeavailableuponfullpublication.
Code availability Code for data preprocessing, model training, and model inference is available. Refer to
https://github.com/bowang-lab/ECG-FM/.ECG-FM: An Open Electrocardiogram Foundation Model 13
References
[1] D. A. Cook, S. Y. Oh, and M. V. Pusic. “Accuracy of Physicians’ Electrocardiogram Interpretations:
A Systematic Review and Meta-analysis”. In: JAMA Intern Med 180.11 (2020), pp. 1461–1471.
[2] AlanH.Kadishetal.“ACC/AHAClinicalCompetenceStatementonElectrocardiographyandAmbu-
latory Electrocardiography”. In: Circulation 104.25 (2001), pp. 3169–3178.
[3] Robert Herman et al. “Validation of an automated artificial intelligence system for 12-lead ECG inter-
pretation”. In: Journal of Electrocardiology 82 (2024), pp. 147–154.
[4] Nikita Rafie, Anthony H. Kashou, and Peter A. Noseworthy. “ECG Interpretation: Clinical Relevance,
Challenges, and Advances”. In: Hearts 2.4 (2021), p. 505.
[5] Bryan He et al. “Blinded, randomized trial of sonographer versus AI cardiac function assessment”. In:
Nature 616.7957 (2023), pp. 520–524.
[6] P. A. Noseworthy et al. “Artificial intelligence-guided screening for atrial fibrillation using electrocar-
diogram during sinus rhythm: a prospective non-randomised interventional trial”. In: Lancet 400.10359
(2022), pp. 1206–1212.
[7] Robert Herman et al. “International evaluation of an artificial intelligence–powered electrocardiogram
model detecting acute coronary occlusion myocardial infarction”. In: European Heart Journal - Digital
Health (2023).
[8] Yoo Jin Choi et al. “Artificial intelligence versus physicians on interpretation of printed ECG images:
DiagnosticperformanceofST-elevationmyocardialinfarctiononelectrocardiography”.In:International
Journal of Cardiology 363 (2022), pp. 6–10.
[9] Salah S. Al-Zaiti et al. “Machine learning for ECG diagnosis and risk stratification of occlusion my-
ocardial infarction”. In: Nature Medicine 29.7 (2023), pp. 1804–1813.
[10] Jun Ma et al. “Segment anything in medical images”. In: Nature Communications 15.1 (Jan. 2024),
p. 654.
[11] Laila Rasmy et al. “Med-BERT: pretrained contextualized embeddings on large-scale structured elec-
tronic health records for disease prediction”. In: npj Digital Medicine 4.1 (2021), p. 86.
[12] AugustinTomaetal.“ClinicalCamel:AnOpenExpert-LevelMedicalLanguageModelwithDialogue-
Based Knowledge Encoding”. In: ArXiv 2305.12031 (2023).
[13] Konstantinos C. Siontis et al. “Artificial intelligence-enhanced electrocardiography in cardiovascular
disease management”. In: Nature Reviews Cardiology 18.7 (July 2021), pp. 465–478.
[14] ZachiI.Attiaetal.“Screeningforcardiaccontractiledysfunctionusinganartificialintelligence–enabled
electrocardiogram”. In: Nature Medicine 25.1 (2019), pp. 70–74.
[15] J.WestonHughesetal.“Adeeplearning-basedelectrocardiogramriskscoreforlongtermcardiovascular
death and disease”. In: npj Digital Medicine 6.1 (2023), p. 169.
[16] JieweiLaietal.“Practicalintelligentdiagnosticalgorithmforwearable12-leadECGviaself-supervised
learning on large-scale dataset”. In: Nature Communications 14.1 (2023), p. 3741.
[17] Dani Kiyasseh, Tingting Zhu, and David A Clifton. “CLOCS: Contrastive Learning of Cardiac Signals
Across Space, Time, and Patients”. In: Proceedings of the 38th International Conference on Machine
Learning. Ed. by Marina Meila and Tong Zhang. Vol. 139. Proceedings of Machine Learning Research.
PMLR, July 2021, pp. 5606–5615.
[18] Ashish Vaswani et al. “Attention is All You Need”. In: 2017.
[19] JacobDevlinetal.“BERT:Pre-trainingofDeepBidirectionalTransformersforLanguageUnderstand-
ing”. In: ArXiv 1810.04805 [cs.CL] (2019).
[20] Salar Abbaspourazad et al. Large-scale Training of Foundation Models for Wearable Biosignals. 2024.
[21] SeokminChoietal.“ECGBERT:UnderstandingHiddenLanguageofECGswithSelf-SupervisedRep-
resentation Learning”. In: ArXiv (2023).
[22] Akhil Vaid et al. “A foundational vision transformer improves diagnostic performance for electrocar-
diograms”. In: npj Digital Medicine 6.1 (2023), p. 108.
[23] Jungwoo Oh et al. “Lead-agnostic Self-supervised Learning for Local and Global Representations of
Electrocardiogram”. In: Proceedings of the Conference on Health, Inference, and Learning. Ed. by Ger-
ardo Flores et al. Vol. 174. Proceedings of Machine Learning Research. PMLR, Apr. 2022, pp. 338–
353.14 McKeen et al.
[24] Alexei Baevski et al. “wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representa-
tions”. In: Advances in Neural Information Processing Systems. Ed. by H. Larochelle et al. Vol. 33.
Curran Associates, Inc., 2020, pp. 12449–12460.
[25] Matthew A Reyna et al. “Will Two Do? Varying Dimensions in Electrocardiography: The Phys-
ioNet/Computing in Cardiology Challenge 2021”. In: 2021 Computing in Cardiology (CinC). Vol. 48.
2021, pp. 1–4.
[26] MatthewReynaetal.WillTwoDo?VaryingDimensionsinElectrocardiography:ThePhysioNet/Computing
in Cardiology Challenge 2021. Version 1.0.3. 2022.
[27] A. L. Goldberger et al. “PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research
Resource for Complex Physiologic Signals”. In: Circulation 101.23 (2000), e215–e220.
[28] Alistair E. W. Johnson et al. “MIMIC-IV, a freely accessible electronic health record dataset”. In:
Scientific Data 10.1 (2023), p. 1.
[29] J.WillisHurst.“Methodsusedtointerpretthe12-leadelectrocardiogram:Patternmemorizationversus
the use of vector concepts”. In: Clinical Cardiology 23.1 (2000), pp. 4–13.
[30] “CompetencyinInterpretationof12-LeadElectrocardiograms:ASummaryandAppraisalofPublished
Evidence”. In: Annals of Internal Medicine 138.9 (2003), pp. 751–760.
[31] Jean Jacques Goy, Jürg Schlaepfer, and Jean-Christophe Stauffer. “Competency in interpretation of
12-lead electrocardiogram among Swiss doctors.” In: Swiss medical weekly 143 (2013).
[32] DaejoonAnh,SubramaniamKrishnan,andFrankBogun.“Accuracyofelectrocardiograminterpretation
by cardiologists in the setting of incorrect computer analysis”. In: Journal of electrocardiology 39.3
(2006), pp. 343–345.
[33] Sean P. Murphy, Nasrien E. Ibrahim, and Jr. Januzzi James L. “Heart Failure With Reduced Ejection
Fraction: A Review”. In: JAMA 324.5 (2020), pp. 488–504.
[34] Xiaoxi Yao et al. “Artificial intelligence–enabled electrocardiograms for identification of patients with
lowejectionfraction:apragmatic,randomizedclinicaltrial”.In:Nature Medicine 27.5(2021),pp.815–
819.
[35] XiaoxiYaoetal.“ECGAI-GuidedScreeningforLowEjectionFraction(EAGLE):Rationaleanddesign
of a pragmatic cluster randomized trial”. In: American Heart Journal 219 (2020), pp. 31–36.
[36] C. W. Yancy et al. “2013 ACCF/AHA guideline for the management of heart failure: a report of
the American College of Cardiology Foundation/American Heart Association Task Force on Practice
Guidelines”. In: J Am Coll Cardiol 62.16 (2013), e147–239.
[37] KristinE.MullinsandRobertH.Christenson.“OptimalDetectionofAcuteMyocardialInjuryandIn-
farctionwithCardiacTroponin:Beyondthe99thPercentile,intotheHigh-SensitivityEra”.In:Current
Cardiology Reports 22.9 (2020), p. 101.
[38] K.Thygesenetal.“FourthUniversalDefinitionofMyocardialInfarction(2018)”.In:J Am Coll Cardiol
72.18 (2018), pp. 2231–2264.
[39] Diederik P. Kingma and Jimmy Ba. Adam: A Method for Stochastic Optimization. 2017.
[40] Jacob C. Jentzer et al. “Left ventricular systolic dysfunction identification using artificial intelligence-
augmentedelectrocardiogramincardiacintensivecareunitpatients”.In:International Journal of Car-
diology 326 (2021), pp. 114–123.
[41] Jinwoo Cho et al. “Artificial Intelligence Algorithm for Screening Heart Failure with Reduced Ejection
Fraction Using Electrocardiography”. In: ASAIO Journal 67.3 (2021).
[42] Bruno Oliveira de Figueiredo Brito et al. “Left ventricular systolic dysfunction predicted by artificial
intelligence using the electrocardiogram in Chagas disease patients–The SaMi-Trop cohort”. In: PLOS
Neglected Tropical Diseases 15 (Dec. 2021), pp. 1–16.
[43] AnthonyH.Kashouetal.“ArtificialIntelligence-AugmentedElectrocardiogramDetectionofLeftVen-
tricular Systolic Dysfunction in the General Population”. In: Mayo Clinic Proceedings 96.10 (2021),
pp. 2576–2586.
[44] Susumu Katsushika et al. “The Effectiveness of a Deep Learning Model to Detect Left Ventricular
Systolic Dysfunction from Electrocardiograms”. In: International Heart Journal 62.6 (2021), pp. 1332–
1341.
[45] Joon-myoungKwonetal.“DevelopmentandValidationofDeep-LearningAlgorithmforElectrocardiography-
Based Heart Failure Identification”. In: Korean Circ J 49.7 (2019), pp. 629–639.ECG-FM: An Open Electrocardiogram Foundation Model 15
[46] Jin-YuSunetal.“AmethodtoscreenleftventriculardysfunctionthroughECGbasedonconvolutional
neural network”. In: Journal of Cardiovascular Electrophysiology 32.4 (2021), pp. 1095–1102.
[47] Hung-YiChenetal.“ArtificialIntelligence-EnabledElectrocardiographyPredictsLeftVentricularDys-
function and Future Cardiovascular Outcomes: A Retrospective Analysis”. In: Journal of Personalized
Medicine 12.3 (2022).16 McKeen et al.
6 Supplementary Material
Table 5. Abbreviations.
ECG Electrocardiogram
MLM Masked Language Modeling
UHN University Health Network
WCR W2V+CMSC+RLM
W2V wav2vec
CMSCContrastive multi-segment coding
RLM Random lead masking
PVC Premature ventricular contraction
AV Atrioventricular
RBBB Right bundle branch block
LBBB Left bundle branch block
Table 6. Outcome prevalence. Positive label incidence rates for each label, as separated by split and task.
Label Train Validation Test
Sinus rhythm 81.27% 85.38% 91.41%
Normal sinus rhythm 46.44% 49.58% 51.39%
Tachycardia 21.86% 18.1% 13.32%
Bradycardia 12.02% 12.76% 12.38%
PVC 6.49% 6.1% 4.78%
Myocardial infarction19.15% 19.52% 20.18%
AV block 9.39% 9.2% 8.04%
RBBB 10.52% 10.79% 10.38%
LBBB 3.84% 2.95% 2.94%
Electronic pacemaker 6.78% 6.1% 5.37%
Ventricular pacing 4.82% 4.55% 3.84%
Atrial pacing 1.94% 1.64% 1.74%
Poor data quality 12.97% 12.41% 13.3%
LVEF≤30% 16.54% 15.28% 14.03%
LVEF≤40% 26.63% 25.48% 24.08%
LVEF≤50% 40.18% 37.51% 36.98%
Abnormal cTn 28.58% 33.56% 33.81%ECG-FM: An Open Electrocardiogram Foundation Model 17
Fig.4.Illustration of UHN-ECG patient-temporal splits.Subjectswereassignedtowhicheversplitcontained
the majority of their ECGs, where the temporal cutoffs were then estimated to generate an 80/10/10 split. Patient
overlap is permitted in the validation and test sets, but not between the train and evaluative sets. Label leakage is
thus avoided by training and evaluating on different subjects.
6.1 Segment aggregation
OurECGinterpretationtaskreliesonannotated10srecordings,howeverourmodelevaluateseachrecording
by cropping it into two non-overlapping 5 s segments, which become inputs utilizing the same label. This
cropping is necessary to generate positive pairs for the CMSC contrastive objective, however, it does means
that we are predicting labels given partial information compared to when cardiologists performed their
interpretations. To investigate how this affects our evaluation of the interpretation task results for WCR-
Pretrained, we explored aggregating model logits by taking the maximum, mean, and minimum for each two
adjacent segments.
Table 7. Segment-aggregated interpretation task results for WCR-Pretrained. Label-specific aggregation
methodsareselectedaccordingtowhichyieldsthehighestAUPRConthevalidationset.Percentagesindicatemetric
increases compared to the non-aggregated task results for WCR-Pretrained.
Label AUROC AUPRC Method
Sinus rhythm 0.985 (+0.13%) 0.998 (+0.02%) mean
Normal sinus rhythm 0.962 (+0.92%) 0.946 (+1.32%) min
Tachycardia 0.997 (+0.10%) 0.981 (+0.51%) mean
Bradycardia 0.996 (+0.15%) 0.963 (+1.08%) mean
PVC 0.989 (+4.05%) 0.892 (+15.97%) max
Myocardial infarction 0.944 (+0.21%) 0.838 (+0.58%) mean
AV block 0.989 (+0.08%) 0.886 (+0.62%) mean
RBBB 0.991 (+0.05%) 0.937 (+0.30%) mean
LBBB 0.995 (+0.02%) 0.890 (+0.47%) mean
Electronic pacemaker 0.992 (+0.76%) 0.953 (+1.82%) max
Ventricular pacing 0.999 (+0.04%) 0.981 (+0.36%) max
Atrial pacing 0.997 (+0.26%) 0.936 (+1.09%) mean
Poor data quality 0.927 (+1.89%) 0.729 (+4.13%) max
In large part, the best-performing label-specific aggregation methods follow a common schema. Labels
with ’max’ are typically diagnosed using distinct features such as pacemaker spikes, PVCs, and artifacts.
Aggregation may help here considerably when such markers are less discernible, or perhaps even absent, in18 McKeen et al.
one of the segments, where the less-performant PVC and poor data quality labels see significant benefits.
The ’mean’ labels generally represent more continuous patterns such as rhythms and abnormalities resulting
in a sustained change in presentation. Gains with this method are generally more modest and may be acting
as an ensemble prediction which helps to mitigate signal noise. Only normal sinus rhythm used the ’min’
method, which is reasonable as this condition would not be written unless both segments met the necessary
criteria.
This aggregation experiment simulates how the model might perform having seen the same 10 s ECG as
the cardiologists did during their interpretations, where we do observe performance gains across all labels.
This helps quantify how our single-segment evaluative setup indeed undersells our model performance. In
crudelyaccountingforthefactthatwedonothavesegment-specificlabels,thesemetricsmayserveasamore
genuine representation of model performance on this task. Although we find this aggregation methodology
reasonable, we refrain from adopting it in the main paper to avoid over-complicating our method.
6.2 Patient demographics
Table 8. Biological age. Shown is the Mean ± STD of biological age in years across UHN-ECG’s downsteam task
manifests.
Split Interpretation/Abnormal cTnReduced LVEF
Train 62.2±19.5 65.9±16.8
Valid 60.8±19.3 66.3±16.1
Test 59.8±19.4 65.6±16.5
Table 9. Biological sex. Shown is distribution of sex (% Female) across UHN-ECG’s downsteam task manifests.
Split Interpretation/Abnormal cTnReduced LVEF
Train 45.7% 37.3%
Valid 45.9% 39.6%
Test 44.9% 40.2%
6.3 Interpretation Text Parsing
In clinical care settings, ECG interpretations written as free-text as a matter of efficiency and convenience.
While this approach allows for unbounded precision, it can be challenging to translate this unstructured
format into labels digestible by AI models. Synonyms, acronyms, grammar, typographical errors, evolving
medical terminology, and implied findings are all examples of complexities which, if not handled with care,
can severely lessen label quality, which in turn reduces model effectiveness and evaluative correctness.
Maintaining positional information, we apply pattern matching which was manually curated to parse
the free-text and match over 99% of interpretations completely. Dervied from these patterns are a series of
entities (e.g., ’tachycardia’, ’infarction’), descriptors (e.g., ’probably’, ’moderate’, ’acute’), and connectives
(e.g., ’associated with’, ’transitions to’). Relevant information from the descriptors and connectives are dis-
tilled down into their corresponding entities. We map the resulting entities into labels which can be flexibly
manipulated. Using clinician-in-the-loop decision making, we construct a knowledge graph encoding label
relationships which are true by definition. We use it to recursively mark labels as true, for example, labeling
"Ventriculartachycardia"when"TorsadesdePointes",oneformofpolymorphicventriculartachycardia,was
specificallystated.Without thiscomponent, we suspect thatthe modelwouldlearn physiologicallyarbitrary
distinctions which would prove counterproductive to accurate interpretation.ECG-FM: An Open Electrocardiogram Foundation Model 19
6.4 Cardiac Troponin Assays
We processed cTn measurements in the ECG-UHN dataset, as recorded in a tabular format and performed
largelywithAbbotARCHITECTassays.Weexcludedrowswithnotesindicatinginsufficientsamplequantity
for testing. Following the reference ranges seen in 10, measurements were deemed abnormally high if above
their respective upper reference limits (URL) for healthy populations. URL values are assay-specific and
correspondtothe99thpercentilevalueobservedineachgroup.Certainvalueswereprefixedwithinequalities
and deviated from the reference range limits, likely reflecting site-specific upper limits based on clinical
significance. Accordingly, "<" were necessarily identified as normal troponin levels, while ">" indicated
abnormallevels.Therewasatransitionfromanearliergeneration"conventional"assaytothehighsensitivity
assay around February 2015.
Table 10.Cardiac troponin assay reference ranges.AbbotARCHITECTassayreferencerangesusedtoassess
cardiac troponin levels. Each assay has a sex-specific level of detection (LOD) and upper reference limit (URL).
Assay Unit LOD URL
Male FemaleUnspecifiedMaleFemale
Conventional ng/mL< 0.10 < 0.10 0.028 0.028 0.028
High sensitivity ng/L 1.2 1.9 26 16 3420 McKeen et al.
6.5 Performance curves
We show receiver operating characteristic (ROC) curves and the precision-recall curves (PRC) for each label
inourWCR-PretrainedandRandomInit.experimentsuites,reportingtheareaunderthecurveinthelegend.
Fig.5.Interpretationtasktestperformancecurves.ROCcurvesareshownonthetopandPRConthebottom.
TheWCR-Pretrained modelisdisplayedontheleftandRandom Init.ontheright.Thelegenddisplayslabelnames,
as well as label-specific AUROC and AUPRC scores on the ROC and PRC curves respectively.ECG-FM: An Open Electrocardiogram Foundation Model 21
Fig.6. Reduced left ventricular ejection fraction task test performance curves. ROC curves are shown on
thetopandPRConthebottom.TheWCR-Pretrained modelisdisplayedontheleftandRandom Init.ontheright.
The legend displays label names, as well as label-specific AUROC and AUPRC scores on the ROC and PRC curves
respectively.22 McKeen et al.
Fig.7. Abnormal cardiac troponin task test performance curves. ROC curves are shown on the top and
PRC on the bottom. The WCR-Pretrained model is displayed on the left and Random Init. on the right. The legend
displays label names, as well as label-specific AUROC and AUPRC scores on the ROC and PRC curves respectively.