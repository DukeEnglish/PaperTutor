JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 1
TaSL: Task Skill Localization and Consolidation for
Language Model Continual Learning
Yujie Feng, Xu Chu, Yongxin Xu, Zexin Lu, Bo Liu, Philip S. Yu, Fellow, IEEE, Xiao-Ming Wu
Abstract—Language model continual learning (CL) has re-
cently garnered significant interest due to its potential to adapt
large language models (LLMs) to dynamic real-world envi-
ronments without re-training. A key challenge in this field is
catastrophic forgetting, where models lose previously acquired
knowledge when learning new tasks. Existing methods com-
monly employ multiple parameter-efficient fine-tuning (PEFT)
blocks to acquire task-specific knowledge for each task, but
these approaches lack efficiency and overlook the potential for
knowledge transfer through task interaction. In this paper, we
present a novel CL framework for language models called Task
Skill Localization and Consolidation (TaSL), which enhances
knowledge transfer without relying on memory replay. TaSL Fig. 1. Conceptual illustration of TaSL. By identifying task-relevant areas
first divides the model into ‘skill units’ based on parameter across both previously accumulated and current tasks, we can consolidate
dependencies, enabling more granular control. It then employs thetask-specific and task-shared parametersto facilitate efficient knowledge
a novel group-wise skill localization technique to identify the transfer(KT)andmitigatecatastrophicforgetting(CF).
importance distribution of skill units for a new task. By com-
paring this importance distribution with those from previous
tasks, we implement a fine-grained skill consolidation strategy
be categorized into forward transfer, which improves new
that retains task-specific knowledge, thereby preventing for-
getting, and updates task-shared knowledge, which facilitates task performance using knowledge from previous tasks, and
bi-directional knowledge transfer. As a result, TaSL achieves backward transfer, which enhances performance on previous
a superior balance between retaining previous knowledge and tasks after learning a new relevant task. Achieving a balance
excelling in new tasks. TaSL also shows strong generalizability,
between retaining previous knowledge and excelling in new
suitableforgeneralmodelsandcustomizableforPEFTmethods
tasks is vital for success.
like LoRA. Additionally, it demonstrates notable extensibility,
allowing integration with memory replay to further enhance Given the considerable computational demands, recent ef-
performance. Extensive experiments on two CL benchmarks, forts have explored CL for LLMs using parameter-efficient
with varying model sizes (from 220M to 7B), demonstrate the fine-tuning(PEFT)methods[7],[8],suchasLow-RankAdap-
effectiveness of TaSL and its variants across different settings.
tation (LoRA) [7]. Traditional rehearsal-based approaches,
Index Terms—Language model continual learning, catas- whichrequirestoringdataexamplesfrompasttasksforreplay,
trophic forgetting, skill localization.
face significant privacy and memory issues [3], [9], [10].
Another prominent line of work in recent studies is the
I. INTRODUCTION parameter isolation CL methods [11]–[14]. These methods
assign a dedicated PEFT block for each new task to acquire
EQUIPPING large language models (LLMs) with contin-
task-specific knowledge, preserving the block for selective
uallearning(CL)capabilitiestosequentiallylearndiffer-
activation during testing. However, they exhibit significant
ent tasks is essential for their deployment in real-world sce-
limitationsineffectivelyaddressingtheKTandCFchallenges.
narios [1], [2]. This capability enables LLMs to dynamically
On one hand, the prevalent design of these frameworks,
adapt to new tasks and acquire additional knowledge [3], [4].
which utilizes multiple PEFT blocks, introduces redundancy
An effective CL system must address two critical challenges:
and inefficiency [15]. The number of required PEFT blocks
(1) Catastrophic Forgetting (CF) [5], the phenomenon where
increases with each new task, leading to substantial memory
amodel’sproficiencyinprevioustasksdeterioratesasitlearns
storage costs and making it difficult to handle long task
new ones, and (2) Knowledge Transfer (KT) [6], enhancing
sequences [16], [17]. Moreover, such approaches essentially
task performance through the transfer of knowledge. KT can
create separate expert models for each task, which limits their
ability to generalize to unseen tasks [18] (Limitation 1).
Yujie Feng, Zexin Lu, Bo Liu, and Xiao-Ming Wu are with the Depart-
ment of Computing, The Hong Kong Polytechnic University, Hong Kong On the other hand, these parameter-isolation CL methods
S.A.R.,China.E-mail:{yujie.feng,zexin.lu,bo.liu}@connect.polyu.hk,xiao-
donotconsiderinteractionsbetweentasks,whichhindersKT.
ming.wu@polyu.edu.hk
Xu Chu and Yongxin Xu are with the School of Computer Sci- For instance, the method in [12] involves learning each PEFT
ence, Peking University, Beijing, China. E-mail: chu_xu@pku.edu.cn, blockseparatelywithinindividualtasks.Similarly,Orthogonal
xuyx@stu.pku.edu.cn
Low-Rank Adaptation (O-LoRA) [19] updates parameters via
Philip S. Yu is with the Department of Computer Science, University of
IllinoisatChicago,USA.E-mail:psyu@uic.edu gradient projection in orthogonal subspaces. Although these
4202
guA
9
]LC.sc[
1v00250.8042:viXraJOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 2
approaches may mitigate CF to some extent, they cut off the validated on a specific sub-task, and its effectiveness on gen-
potential transfer of knowledge stored across different PEFT eral CL benchmarks has yet to be explored. Additionally, on
blocks, thus impeding bi-directional KT among various tasks the technical side, the skill localization process in TaSL relies
and leading to suboptimal performance (Limitation 2). onfirst-ordergradients,whichmaynotalwaysprovideprecise
To address these limitations, we introduce Task Skill importance localization. Furthermore, the skill consolidation
Localization and Consolidation (TaSL) [20], a novel CL phase in TaSL involves many hyperparameters, potentially
framework designed to improve KT between tasks without complicating the averaging process.
relying on memory replay. Our approach is motivated by To address these issues, we propose TasLoRA, a LoRA-
recent findings that model parameters contribute unevenly to tailored version of TaSL. TasLoRA reconstructs the LoRA
performance [21]. For instance, the authors in [22] uncovered adapter into new skill units based on parameter dependencies,
acoreregiononLLMscrucialforalllanguages,whiledistinct ensuring more efficient management of knowledge through
monolingual regions exist for different languages. Preserving sequential task learning. During the fine-tuning process, an
theseimportantregionscanhelpavoidforgetting.Theresearch additional orthogonal loss is added to ensure that skill units
in [15] also found that during fine-tuning with LoRA, many withinthesameLoRAadaptercapturedistinctlatentsemantic
redundantparametermodificationsareoftenretained,suggest- features. For skill localization, TasLoRA employs a novel
ing that PEFT blocks contain significant redundancies. second-order gradient approximate group-wise metric to com-
Based on these insights, TaSL facilitates KT by identify- puteimportancescoresmoreprecisely.Forskillconsolidation,
ing and consolidating the importance distribution of model we transition from the previous hard-mask model averaging
parameters across tasks. TaSL initially employs a group-wise approach to a soft-masking strategy, using an adaptive aver-
importance-awareskilllocalizationtechniquethatutilizesgra- aging technique. This allows for a more flexible integration
dient trajectories to identify tiny regions within the parameter of task-specific and shared parameters, dynamically adjusting
space that store crucial knowledge for the current task. By the contribution of each skill unit based on its importance.
comparing the importance distribution with those of previous Furthermore, to adapt to a broader range of application
tasks,wecanthendifferentiatebetweentask-specificandtask- scenarios,wecombineTaSLwithmemoryreplay,introducing
shared regions, as illustrated in Figure 1. Our innovative skill theTaSL-Mmodel.ThroughextensiveexperimentsontwoCL
consolidationphasethencategoricallyintegratesweightsfrom benchmarks with different parameter-level backbones (from
previous tasks with the current one, enabling effective KT 220M to 7B), our TaSL framework, along with its variants,
while minimizing forgetting. excelsinmitigatingCFandshowcasesremarkablecapabilities
In detail, TaSL first reconstructs the model or PEFT block for KT, outperforming state-of-the-art (SOTA) methods.
into fine-grained “skill units”. A skill unit refers to a dis- The main contributions are summarized as follows:
tinct subset of model parameters that encapsulates specific • We propose a novel Task Skill Localization and Consol-
functional capabilities or knowledge relevant to a particular idation (TaSL) framework for language model continual
task, such as the Query matrix within the self-attention layer. learning. By identifying and consolidating task-specific
By operating at this finer granularity, we can localize and and task-shared knowledge at a granular skill unit level,
consolidatetask-specificandsharedknowledgewithinasingle TaSLachieveseffectiveknowledgetransferandmitigates
PEFT block, rather than adapting a separate PEFT block for catastrophic forgetting, overcoming the limitations of
each task as in previous works (addressing Limitation 1). previous approaches.
The importance-aware skill localization method employs • Wedevelopvariousgroup-wiseskilllocalizationandfine-
a new group-wise metric to compute importance scores, ef- grained skill consolidation techniques. For instance, the
fectively quantifying the significance of each skill unit for parameter importance metric in skill localization can be
the current task. Our approach, focusing on parameter space based on first-order gradients or a new second-order
rather than dataset-driven categorization of task-specific and gradient approximation method. In skill consolidation,
task-shared knowledge, offers a more effective solution to ourmodelaveragingstrategiesincludeacategoricalhard-
managing KT in LLMs, overcoming inaccuracies caused by mask approach and an adaptive soft-mask method.
dataset noise. Our skill consolidation stage, then based on • The TaSL framework demonstrates strong generalizabil-
a fine-grained model averaging strategy, effectively manages ity and extensibility. The flexible design of skill units
different types of knowledge. During this phase, we promote enables TaSL to be easily tailored to PEFT methods,
forward KT by initializing new tasks with previously fine- suchasLoRA,optimizingperformanceforspecificmodel
tuned weights. For backward KT, we merge knowledge from architectures. Additionally, TaSL can be integrated with
both current and past tasks into localized task-shared skill memoryreplaytechniquetofurtherenhanceperformance
units, enhancing their capability. To prevent CF, we preserve and adapt to a broader range of application scenarios.
the integrity of skill units containing previous task-specific • ExtensiveevaluationontwoCLbenchmarksunderscores
knowledge, ensuring they remain unaffected by new task the superiority of our TaSL framework and its variants
learning (addressing Limitation 2). in facilitating knowledge transfer and mitigating catas-
GiventhewidespreadadoptionandsuccessofLoRAinfine- trophic forgetting, especially in memory-free scenarios.
tuning LLMs, there is a compelling opportunity to optimize Furthermore, TaSL consistently excels across diverse
theTaSLframeworkspecificallyforLoRA.Whiletheoriginal model sizes (ranging from 220M to 7B), different model
TaSLframeworkhasshownpromisingresults,ithasonlybeen architectures (T5 and LLaMA-2), and unseen tasks.JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 3
II. RELATEDWORK uniquely differentiates between task-specific and shared pa-
rameters to mitigate forgetting and achieve KT in CL.
A. Continual Learning
Continual learning [3] aims to develop learning algorithms
capable of accumulating knowledge from non-stationary data. III. PRELIMINARIES
ConventionalContinualLearningmethodscanbedivided
into three categories: (i) Regularization-based methods add A. Continual Learning
explicit regularization terms to preserve the knowledge of
Continual learning [40] aims to create learning algorithms
previoustasks[13],[23].(ii)Rehearsal-basedmethodsaddress
that can continuously accumulate knowledge from ongoing
catastrophic forgetting by storing old training samples [24],
sequences. In supervised continual learning, a sequence of
[25] or by training generative models to provide pseudo
tasks {T ,...,T } is presented in a streaming manner. Each
samples of previous tasks [26], [27]. Due to the memory and 1 K
task T includes a distinct target dataset D
=(cid:8)(cid:0) xk,yk(cid:1)(cid:9)Nk
data privacy issues associated with these methods, we focus k k i i i=1
of size N , where xk ∈ X and yk ∈ Y . The model must
on rehearsal-free CL methods. (iii) Parameter isolation-based k i k i k
adapt to these tasks sequentially, having access only to D
methodsdynamicallyexpandmodelcapacityorassignisolated k
during the k-th task. Generally, with a prediction model f
parameters dedicated to each task throughout the CL process
parameterized by Θ, continual learning aims to optimize the
to prevent interference between tasks [28]–[30].
following objective across all tasks:
Language Model Continual Learning with PEFT. Based
on PEFT methods, current approaches for the continual learn-
K
ing of LLMs adopt the concept of parameter isolation, using (cid:88) (cid:88)
max logp (y |x) (1)
Θ
a pipeline fashion to learn and select PEFT blocks for each Θ
task[12],[31],[32].However,theseapproachesarelimitedin
k=1x,y∈Dk
effectivelyaddressingthechallengesofcatastrophicforgetting The notation f refers to the model after training on task
k
(CF) and knowledge transfer (KT) [33]. For instance, the au- T , while fˆ denotes the model after averaging for fˆ and
k k k−1
thorsin[19]and[34]constrainthelearningofPEFTblocksto f . Our TaSL framework aims to address a more challenging
k
maintain orthogonality, restricting KT among different tasks. scenario where the model cannot access any historical data
AlthoughtherecentSAPTmethod[16]andDAPmethod[35] during training [19]. Nevertheless, to adapt to a wider range
achieves KT, it relies on pseudo sample replay or unlabeled of application scenarios, we have also combined TaSL with
domain corpora. memoryreplay.Inthissetting,werandomlysave|M|samples
Our method achieves KT without memory replay, offering from the training set of each previous task T in memory M
i i
unique advantages in data privacy and parameter efficiency. and jointly train the model on new task data D and memory
k
By using layering low-rank adapters on the key and value M . This extension, called TaSL-M, leverages memory
<k
projectionmatricesoftransformerblocks,webalanceretaining replay to enhance performance.
previous knowledge and excelling in new tasks.
B. Low-Rank Adaption
B. Skill Localization
Researchshowsthatmodelparametersdonotallcontribute Low-Rank Adaption (LoRA) [7] is a parameter-efficient
equally to performance [36]. The authors in [21] introduced fine-tuning method to adapt LLMs to novel tasks. It assumes
the concept of “skill localization” to identify critical parame- that the changes of parameters lie in a low-rank space when
tersinpre-trainedlanguagemodels,suggestingthatfine-tuning the model is fully fine-tuned on a downstream task. This
only these critical parameters can achieve results comparable approach eliminates the necessity of fine-tuning the entire
to full model fine-tuning. However, their method involves model, thereby improving computational efficiency and re-
additional steps to identify and retrain these key parameters source utilization.
during the post-fine-tuning phase, which reduces efficiency. Inspiredbythelow-rankinternaldimensionality[41],LoRA
Inspired by techniques from the pruning community, pre- hypothesizestheupdatestotheweightsalsohasalow“intrin-
vious studies have utilized gradient-based metrics to pin- sic rank” during adaptation. For a pre-trained weight matrix
point important parameters during fine-tuning. Sensitivity- W(0) ∈ Rout×in that takes x as input, LoRA modifies the
based scoring [37], [38] evaluates the impact on training output h of W(0) with a low-rank decomposition:
loss, and sensitivity smoothing, as employed by [39], helps
remove unnecessary parameters for more efficient fine-tuning. h=W(0)x+∆Wx=W(0)x+BAx, (2)
Nonetheless,thesemethodsoftenresultinelement-wiseprun-
ing, where individual parameters are removed based on their while B ∈ Rout×r, A ∈ Rr×in, and the rank r ≪
importance scores. This approach can be computationally min(in,out). A is initialized from a random Gaussian distri-
and storage-intensive, as it requires detailed management of bution and B is initialized with all zeros. During the training
numerous parameters throughout the model. stage, W(0) is fixed, and only BA is updated. Due to its
Building on these advancements, we propose a novel superior performance, LoRA has become one of the most
importance-aware skill localization method. This approach popular PEFT methods in NLP community.JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 4
Fig.2. Left:IllustrationofreconstructingLoRAasfine-grainedskillunits.Right:OverviewofTaSL.Step1:Wecomputetheimportancescoresofskillunits
forthecurrenttaskk usingourimportance-awareskilllocalizationmethodduringfine-tuning.Step 2:Basedonacategoricalmodelaveragingstrategy,the
skillconsolidationmechanismmergesthemodelfˆ k−1,whichaccumulatesknowledgeofallprevioustasks,withthecurrenttask’smodelf k.Theintegration
isguidedbytheimportancedistributionsofskillunitsacrossvarioustasks.Thisprocesscanberepeatedwiththeintroductionofeachsubsequenttask.
IV. PROPOSEDMETHOD:TASL 2) LoRA-Tailored Skill Unit: While the matrix-level divi-
sion is simple and intuitive, it did not sufficiently consider
A. Overview
theintra-matrixredundancyandinter-matrixdependencies.To
TaSL includes two key components: (i) Skill Localization, address these limitations and the inefficiencies noted in recent
utilizingagroup-wiseimportancemetrictoaccuratelyidentify work [19], which treats each LoRA adapter as a container for
the importance distribution of parameters across tasks, and task-specific knowledge, we decompose the model matrices
(ii) Skill Consolidation, which employs a novel fine-grained into new, finer-grained “skill units” based on parameter de-
modelaveragingstrategytointegratemodelweightsfromboth pendencies tailored for LoRA. The construction process for
current and past tasks for effective knowledge transfer. these LoRA-tailored skill units is as follows.
Figure 2 provides a comprehensive overview of our pro- As shown in Eq (2), A and B can be viewed as a
posedTaSLframework,withthefollowingsubsectionsdetail- combination of a set of vectors: A = [a ,a ,··· ,a ], B =
1 2 r
ing each component and the corresponding extensions. [b ,b ,··· ,b ], where a ∈Rin, b ∈Rout. Thus BA can be
1 2 r i i
further disassembled as:
B. Fine-Grained Skill Unit W =W(0)+b a +b a +···+b a
1 1 2 2 r r
(3)
Beforewelocalizetheimportanceofparameters,weneedto =W(0)+u +u +···+u ,
1 2 r
define a structure that helps us better organize the knowledge
where skill unit u is a matrix obtained by the product of the
stored in the model. This structure will provide a clearer un- i
vectors b ,a . Therefore, LoRA can be viewed as a fusion of
derstandingofhowtomitigateCFandachieveKT.Therefore, i i
knowledge learned from multiple skill units:
we refer to the basic unit of stored skills or knowledge in the
modelasa“skillunit.”Basedondifferentusagescenarios,we r r
(cid:88) (cid:88)
offer the following two structures for skill units: W =W(0)+ b ia i =W(0)+ u i (4)
1) Matrix-Level Skill Unit: In this division strategy, we i=1 i=1
define skill units as individual matrices in the model, such
This division strategy effectively decomposes the parame-
as the query or key matrices in the self-attention layer or the
ters of a single LoRA adapter, reducing the redundancy in the
A matrix in LoRA. This approach aligns with the original
traditionalapproachofemployingseparateLoRAadaptersfor
TaSL framework. The advantage of this division is that it is
each task [19]. To ensure that different skill units within the
model-agnostic, making it applicable to both traditional full-
same layer learn distinct latent semantic features, we apply a
parameter fine-tuning and the latest parameter-efficient fine-
regularization term as introduced by [39]:
tuning methods, such as LoRA. This provides a higher degree
of generalizability. R(A,B)=∥ATA−I∥2 +∥BTB−I∥2, (5)
F FJOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 5
where I is an identity matrix, this forces A and B to be Algorithm 1 Importance-aware Skill Localization
orthogonal after training. Input: Training dataset D k for task T k; total training itera-
tions T; hyperparameters α ,α .
1 2
for t=1,...,T do
C. Importance-aware Skill Localization
Sampleamini-batchfromD andcomputethegradient
To calculate the importance of each skill unit u, we intro- k
∇L;
duce a group-wise metric that also addresses the significant
Compute the sensitivity I(w ) via Eq. (8) or Eq. (9);
ij
computational and storage burdens associated with previous Update I¯(t) via Eq. (10) and U¯(t) via Eq. (11);
parameter-level importance calculation methods [42]:
end for
1 (cid:88)in (cid:88)out Compute the importance score I(uk i) for each skill unit
I(u)=
in×out
s(w ij) (6) uk
i
by Eq. (6), for i=1,...,n.
i=1j=1 Output: f and importance scores I(U ) for U .
k k k
wherew denotesthetrainableparameters,andin×outrepre-
ij
sentsthetotalparametercountinaskillunitu.I(u)measures
the collective importance of all parameters within each skill Thismeansthemetricissubjecttovariabilityduetostochastic
unit, where higher values signify increased importance. The samplingandtrainingdynamics,introducinglargeuncertainty
importance function s(·) for individual parameters, inspired in estimating sensitivity. To mitigate this, we propose a more
by the pruning community [43], is quantified by measuring reliablyimportancemetricbasedonsensitivitysmoothingand
the impact of its removal on the loss. Specifically, to estimate uncertainty quantification [39]:
the importance of W , we calculate the change in loss when
i
the parameter is zeroed out using: I¯(t)(w ij)=α 1I¯(t−1)(w ij)+(1−α 1)I(t)(w ij) (10)
I =|∆L(D)|=|L (D)−L (D)| U¯(t)(w )=α U¯(t−1)(w )+
Wi Wi Wi=0 ij 2 ij
=(cid:12) (cid:12) (cid:12) (cid:12)∂ ∂L W(D) W i− 1 2W iH iiW i+O(∥W i∥3)(cid:12) (cid:12) (cid:12)
(cid:12)
(7) (1−α 2)(cid:12) (cid:12) (cid:12)I(t)(w ij)−I¯(t)(w ij)(cid:12) (cid:12) (cid:12) (11)
i
where α and α are smoothing factors, and t is the iteration
where H is the hessian matrix, W represents the i-th param- 1 2
i number. I¯(t) represents smoothed sensitivity and U¯(t) is the
eter in W, and L represents the next-token prediction loss.
uncertainty term quantified by the local variation between
If removing a parameter has a significant influence, then the
I(t) and I¯(t). Using the exponential moving average of the
modelissensitivetoit,andweshouldretainit[44].Basedon
importance metric, we can retain and explore the trajectory
Eq.(7),wecanderivethefollowingtwometricsforcalculating
gradientforalongertime,providingamorerobustandprecise
parameter importance:
importance assessment. Importance is then determined by:
1) First-Order Gradient-Based Metric: In original TaSL
framework, we followed the standard approach, defining s(·) s(t)(w )=I¯(t)(w )·U¯(t)(w ) (12)
ij ij ij
as the magnitude of the gradient-weight product:
To compute the importance score of each skill unit for cur-
I Wi =|W i∇ WiL| (8) renttaskT k,weemployEq.(6)duringfine-tuning.Themodel
f withnskillunitsisdenotedasU ={u ,...,u },withtheir
This metric only considers the first-order gradient term in 1 n
importance scores for task T denoted by I(U ) ∈ Rn. The
the importance calculation. However, the importance of a pa- k k
detailed computation process is provided in Algorithm 1.
rameterisalsoreflectedinthesecond-ordergradients(Hessian
Aftercomputingimportancescoresforeachskillunitatthe
matrix). Ignoring second-order gradient information may lead
current task T , it is essential to compare these with scores
to biases in localization, thus affecting model performance. k
from all previously learned tasks to distinguish between task-
Therefore, we propose the following new metric.
2) Second-Order Gradient Approximation Metric: Direct specific and task-shared skill units. To avoid the inefficiency
of storing scores for each past task, we aggregate importance
computation of the Hessian matrix for LLMs is impractical
due to its O(N2) complexity. To address this, we propose scores from all prior tasks into a cumulative score for tasks
upto T .This methodallowsforthe iterativerefinementof
a second-order gradient approximation for the importance k−1
accumulatedscoreswithoutseparatelysavingpasttaskscores.
metric, which balances the efficiency of first-order methods
The skill units with these cumulative scores up to T are
with the precision of second-order gradients. To reduce the k−1
computational complexity, the diagonal of the Hessian H denoted as Uˆ k−1, calculated using:
ii
can be approximated by the Fisher information matrix [45], I(Uˆ )=βNorm(I(Uˆ ))+(1−β)Norm(I(U ))
k−1 k−2 k−1
and the importance can be defined as:
(13)
(cid:12) (cid:12)
I Wi
≈(cid:12) (cid:12)
(cid:12)
(cid:12)∂ ∂L W(D)
W i−
1 2(cid:88)N (cid:18) ∂L ∂( WD j)
W
i(cid:19)2(cid:12) (cid:12)
(cid:12) (cid:12) (9)
w toh te hr ee [β 0,∈ 1][ r0 a, n1 g] e, ,a tn hd usN reo sr om lv(· i) ngno dr im sca rl ei pz ae ns ci im esp ao cr rta on ssce ms oc do er le ss
.
(cid:12) i j=1 i (cid:12) The initial scores, I(Uˆ ), are set to be equal to I(U ).
1 1
However, calculating the importance as specified in Eq. (9) Following this, the importance distribution for skill units up
across the entire training set introduces significant challenges, to task T is combined with that of the current task, T , to
k−1 k
asmodeltrainingtypicallyonlyhasaccesstomini-batchdata. facilitate the skill consolidation process.JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 6
D. Skill Consolidation Algorithm 2 TaSL
Input: Dataset D for task k = 1,...,K; initial pre-trained
After skill localization, the subsequent vital phase involves k
model f ; hyperparameters α ,α ,β,τ.
consolidating the knowledge in the skill unit into a uni- 0 1 2
1: # sequential tasks.
fied framework. This process demands a sophisticated model
2: for task k = 1,...,K do
averaging approach considering various factors to optimize
3: # skill localization.
task performance. Traditional coarse-grained model averaging
assumes that all model weights are equally important for the 4: Get f k and calculate U k by Algorithm (1);
5: if k =1 then
training task [46], [47], which can be written as the following
6: # initialization at beginning task.
iterative computation format:
7: fˆ 1 ←f 1, Uˆ 1 ←U 1;
fˆ =λfˆ +(1−λ)f (14) 8: else
k k−1 k
9: # skill consolidation.
However, coarse-grained methods may overemphasize 10: for skill unit i = 1,...,n do
weights that are irrelevant to the current task, contaminating 11: Calculate uˆk by Eq. (17);
i
previously acquired task-specific knowledge and leading to 12: end for
forgetting.Toaddressthisissue,weintroducetwofine-grained 13: Get the averaged model fˆ k based on Uˆ k;
averaging strategies that focus on skill units rather than the 14: Calculate accumulated importance score I(Uˆ k) ac-
entire model. Our approach distinguishes between task-shared cording to Eq. (13);
and task-specific skill units, applying weighted averaging to 15: end if
parameters within each unit. This tailored method provides a 16: end for
customized solution to meet the distinct needs of each task.
1) Static Weighted Consolidation: This strategy, used in
the original TaSL framework, begins by setting importance • If I(uˆk i−1) is high while I(uk i) is low, it indicates that the
thresholds δ using quantiles to select the top 20% of skill skill unit u is more important for the history task. Ac-
i
units based on importance scores. A skill unit uk is deemed cording to Eq. (15) or (17), we maintain the previous task-
i
important (denoted as (uk i)+) if its score I(uk i) is above δ k, specific knowledge stored in uˆk i−1 untouched to prevent the
and unimportant ((uk)−) otherwise. contamination of historical knowledge with task-irrelevant
i
Our static weighted consolidation strategy customizes pa- information in uk, thereby mitigating CF.
i
rameter combination for each skill unit, based on its impor- • If I(uˆk i−1) is low and I(uk i) is high, it suggests that the
tance under different tasks, as follows: skill unit u is more important for the current task. Since
i
 γuˆk−1+(1−γ)uk, if (uˆk−1)+, (uk)+ the model’s training initializes from the endpoint of the
uˆk−i
1,
i
if
(uˆi
k−1)+,
(ui
k)−
previous task, the historically learned knowledge is utilized
uˆk = i i i (15) to enhance performance on the current task. So we ensure
i u 1k i (u,
ˆk−1+uk),
i if
f
( (u uˆ ˆk i k− −1 1) )− −,
,
( (u uk i k) )+
−
tt ah se k-in spte eg cr ii fity
c
ko nf ot whe lep da gr ea ,m the ete rers byin fau ck i il, itw ath ii nc gh fs oto rr we as rc dur Kre Tn .t
2 i i i i
This approach performs the element-wise adjustment of pa-
• If both I(uˆk i−1) and I(uk i) are high, it indicates that the
skill unit u is important for both the previous and current
rameters within each skill unit based on its relevance to i
tasks.Consequently,weintegratenewlyacquiredknowledge
previous and current tasks, using hyperparameter γ to control
into this task-shared skill unit to enable backward KT.
their influences.
2) Adaptive Weighted Consolidation: Building upon the • IfbothI(uˆk i−1)andI(uk i)arelow,itindicatestheskillunit
is not significantly relevant to any task. In this case, simply
original TaSL framework, we propose an Adaptive Weighted
averaging the parameters within this unit is sufficient.
Consolidation strategy as our latest extension. In contrast to
Skill consolidation is performed before starting a new task
themanualsettingofmultiplehyperparametersrequiredinthe
in CL, utilizing the averaged model for subsequent task
original method, this adaptive strategy simplifies the process
initialization. Only the importance scores of Uˆ and U
by automatically adjusting to various scenarios, making the k−1 k
are retained for use between tasks, starting with Uˆ = U
averaging process more efficient and flexible. In detail, for a 1 1
estimated from f on D . Detailed implementation of entire
specific skill unit u , the weighting coefficients are: 1 1
i
TaSL algorithm is provided in Algorithm 2.
λˆk−1 =exp(cid:0) I(uˆk−1)/τ(cid:1) ,λk =exp(cid:0) I(uk)/τ(cid:1) (16)
i i i i
V. TASLWITHMEMORYREPLAY:TASL-M
wherebothexpandtemperaturecoefficientτ arescaledtothe
To adapt TaSL to scenarios where historical data can be
rawimportancescore.Thentheupdatedmodelparametersare:
used, we propose a memory replay-enhanced version, TaSL-
(cid:32) (cid:33) (cid:32) (cid:33)
λˆk−1 λk M,tofurtherimprovemodelperformance.Theimplementation
uˆk = i ·uˆk−1+ i ·uk (17)
i λˆk−1+λk i λˆk−1+λk i process is shown in Figure 3.
i i i i After training on task T using the skill localization and
k
By using Eq. (15) or Eq. (17) in our skill consolidation skill consolidation, we obtain the model fˆ. Before the next
k
phrase, it effectively addresses the challenges in CL: task arrives, we introduce a replay stage, where the model fˆ
kJOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 7
K
1 (cid:88)
FWT= a (19)
K−1 i−1,i
i=2
K−1
1 (cid:88)
BWT= a −a (20)
K−1 K,i i,i
i=1
Average Performance (AP) [52] calculates the average
performance across all tasks after training on the final task.
Forward Transfer (FWT) [53] evaluates a model’s gener-
alization ability by measuring the averaged zero-shot perfor-
mance. Backward Transfer (BWT) [54] assesses the impact
of new learning on previous tasks. Negative BWT indicates
the model lost some previously acquired knowledge.
3) Baselines: We evaluate TaSL against the following
PEFT-based continual learning baseline methods: SeqLoRA:
sequentially trains the LoRA on the task orders. IncLoRA:
incrementallearningofnewLoRAparametersonasequential
Fig.3. OverviewofTaSL-M. series of tasks. Replay: replays real samples from old tasks
when learning new tasks to avoid forgetting. EWC [46]: fine-
tunethemodelwitharegularizationlossthatpreventsupdating
is fine-tuned using historical data stored in the memory buffer
parameters that could interfere with previously learned tasks.
M . This process results in a new model fˆm, which helps
<k k L2P [49]: uses the input to dynamically select and update
recover forgotten knowledge. Specifically, during the replay
prompts from a fixed prompt pool. LFPT5 [50]: continuously
stage,wedonotfine-tunetheparametersofallskillunitsusing
trains a soft prompt for each task with generative replay and
historicaldata,asthiscouldnegativelyimpacttheperformance
anauxiliaryloss.Prog-Prompt[18]:sequentiallyconcatenates
on the current task. Instead, we fix the current task-specific
previouslearnedpromptstothecurrentoneduringthetraining
skill units and fine-tune only the remaining parameters. This
andtestingtime.O-LoRA[19]:learnstasksindifferentLoRA
approachachievesabetterbalancebetweenretainingprevious
subspaces that are kept orthogonal to each other and sums all
knowledge and excelling in new tasks.
LoRAweightsupattestingtime.SAPT[16]:leveragespseudo
samplesandasharedattentionframeworktoalignPEFTblock
VI. EXPERIMENTSANDANALYSIS learning and selection.
Table II compares our TaSL with these baselines, high-
A. Experimental Setup
lighting three distinct advantages: data privacy-friendliness,
1) Datasets: We utilize the SuperNI Benchmark [48], a model parameter-friendliness, and generalization-friendliness.
comprehensive benchmark designed to evaluate diverse NLP To clarify the specific localization and consolidation tech-
tasks using expert-written instructions. This benchmark facili- niques used in TaSL and its variants: TaSL: our base frame-
tatesthoroughevaluationinmorepracticalsettingsfortheCL workutilizesoriginalcomponents,includingmatrix-levelskill
ofLLMs.Itincludestasksindialoguegeneration,information units, first-order gradient-based metric for skill localization
extraction, question answering, summarization, and sentiment (Eq.8),andstaticweightedconsolidation(Eq.15).TasLoRA:
analysis. Following the established CL setup [16], three tasks asthelatestextensionofTaSL,itemploysLoRA-tailoredskill
are chosen from each type, creating a sequence of 15 tasks in units,thesecond-ordergradientapproximationmetricforskill
total for evaluation. For each task, 1,000 instances from the localization (Eq. 9), and adaptive weighted consolidation (Eq.
dataset are randomly selected for training, and 100 instances 17). TasL-M and TasLoRA-M: these variants combine TaSL
are used for validation and testing. orTasLoRAwithmemoryreplaytechniquestofurtherenhance
Additionally, we employ the Long Sequence Bench- performance.
mark [18], a continual learning benchmark consisting of 15 4) ImplementationDetails: Weutilizetwolanguagemodels
classification datasets. In line with [19], we randomly select adopted by the previous lines of works in CL for NLP:
1,000 samples for training each task and reserve 500 samples encoder-decoder T5 model [57] and decoder-only LLaMA
per class for validation and testing. We explore two different model [58]. In TaSL, the hyperparameters α and α in Eq.
1 2
task orders for each benchmark. Please refer to the Appendix (10) and Eq. (11) are set to 0.85. We set β in Eq. (13) to
for more details about the tasks and orders. 0.7 and τ in Eq. (16) to 0.15. Following [59], the volume of
2) EvaluationMetrics: Wedenotea asthetestingperfor- replay samples is set to 2% of the original training set for all
j,i
mance (Accuracy for classification task and Rouge-L [51] for replay-based baseline methods. For different backbones, we
others) on the i-th test set of task right after training on j-th utilized the following hyperparameters:
task. The performance of CL is assessed using three metrics: • T5-base (220M), T5-large (780M), and T5-XL (3B): Train-
ing was conducted with a learning rate of 3e-4, batch size
K
1 (cid:88) of8,maximuminputlengthof512,maximumtargetlength
AP= a (18)
K K,i of 128, rank = 8, targeting modules [q, v] and 10 epochs.
i=1JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 8
TABLEI
THEOVERALLRESULTSONTWOCONTINUALLEARNINGBENCHMARKSWITHT5-LARGEMODEL.ALLRESULTSAREAVERAGEDOVERTWODIFFERENT
ORDERSOFEACHBENCHMARK.OURREHEARSAL-FREETASLOUTPERFORMSTHEPREVIOUSBESTMETHOD,O-LORA,BYACHIEVINGANAVERAGE
2.3%ABSOLUTEIMPROVEMENTONAP,ANAVERAGE2.8%ABSOLUTEIMPROVEMENTONFWT,ANDAN4.8%ABSOLUTEINCREASEINBWT.
SuperNI Benchmark Long Sequence Benchmark
Method Memory-Replay
AP↑ FWT↑ BWT↑ AP↑ FWT↑ BWT↑
SeqLoRA 6.43 1.58 -30.94 9.72 6.81 -73.37
IncLoRA 19.12 2.03 - 31.24 62.50 2.62 -15.34
ProgPrompt [18] 3.34 5.29 -33.18 7.98 6.63 -66.71
EWC [46] ✗ 17.46 4.20 -28.61 45.45 3.73 -25.93
L2P [49] 12.73 1.14 -7.95 57.98 8.36 -16.63
LFPT5 [50] 24.76 7.46 -24.41 67.01 9.48 -12.80
O-LoRA [19] 25.89 8.14 -24.59 69.24 10.15 -4.05
TaSL (ours) 26.41 11.78 -18.55 70.71 11.80 -3.27
TasLoRA (ours) 27.43 11.02 -16.91 72.29 12.89 -2.04
Replay 35.37 2.35 -15.79 75.28 3.28 -1.88
SAPT [16] ✓ 51.54 8.88 -0.57 82.02 9.86 -1.25
TaSL-M (ours) 52.12 11.13 -1.31 84.26 12.32 -1.08
TasLoRA-M (ours) 53.01 11.21 -0.81 84.33 11.71 -0.98
TABLEII Moreover, our enhanced version, TasLoRA, shows signifi-
THECOMPARISONBETWEENTASLANDOTHERCLMETHODS. cantimprovementsoverTaSL.Specifically,TasLoRAachieves
SPECIFICALLY,RFINDICATESWHETHERTHEMETHODIS
average gains of 1.3% on AP and 1.4% on BWT, indicating
REHEARSAL-FREE.PEINDICATESWHETHERTHEMETHODISPARAMETER
EFFICIENT.UTINDICATESWHETHERTHEMETHODCANBEAPPLIEDTO that our extensions to each component are effective. Notably,
SOLVEUNSEENTASKS.KTINDICATESWHETHERTHEMETHODENABLES even without relying on memory replay, our method nearly
KNOWLEDGETRANSFER.
matches the performance of SAPT with memory replay on
Long Sequence Benchmark, particularly in BWT, with only a
Method RF PE UT KT
slight difference of 0.8% (-2.04% vs. -1.25%).
EWC[46] ✓ ✓
For memory-based methods, both TaSL-M and TasLoRA
OGD[55] ✓ ✓
LFPT5[50] ✓ ✓ outperform the best SAPT methods, further demonstrating the
L2P[49] ✓ ✓ versatility and robustness of our framework. For the conve-
EIP[12] ✓ ✓ nience of subsequent experimental analysis and comparison,
O-LoRA[19] ✓ ✓ ✓ wefocusontheperformanceofTasLoRA,thebest-performing
MoCL[56] ✓ ✓ ✓ memory-free version, for further evaluations.
SAPT[16] ✓ ✓ ✓ Secondly,TasLoRA consistentlydemonstrates superiorper-
TaSL ✓ ✓ ✓ ✓ formance across various backbones. To further validate the
effectiveness of our framework, we conducted experiments
using a range of parameter-level backbones, as shown in
• LLaMA (7B): With a learning rate of 3e-4, batch size of Figure 4, which highlight performance improvements with
128, a cutoff length of 512, and 10 epochs. Lora settings increasingmodelsize.Acrossdifferentbackbones,ourmethod
wererank=8,alpha=16,dropout=0.05,targetingmodules consistently outperforms traditional approaches. For example,
[q_proj, v_proj]. For testing, settings included temperature in T5-xl, TasLoRA significantly increases the AP metric from
= 0.02, top_p = 0, top_k = 1, max new tokens = 128. 28.6% to 33.3%, and achieves substantial improvements in
Experiments are carried out using 4 NVIDIA A100. both FWT and BWT metrics, rising from 11.1% to 16.1%
and improving from -20.6% to -14.0%, respectively. These
results further validate the robust generalization ability of our
B. Main Results
proposed framework.
OverallCLresultsofdifferentmethodsatthesameT5-large Thirdly, adaptive skill consolidation effectively mitigates
backbone are summarized in Table I. catastrophicforgetting.Torigorouslyassessourmodel’seffec-
Firstly, TaSL and its variants demonstrate superior CL tivenessincounteringforgetting,weanalyzeditsperformance
performance through effective knowledge transfer. Compared on the initial task after training on subsequent tasks using the
to previous rehearsal-free methods such as IncLoRA and O- LongSequenceBenchmark.Figure5showsthatourTasLoRA
LoRA,TaSLexcelsinaddressingthetwocriticalchallengesof methodsignificantlyslowstheforgettingrate,withanaverage
CF and KT, achieving the highest AP, FWT, and BWT when performance decrease of only 11% after training on the final
learning tasks sequentially. task. In stark contrast, vanilla backbones exhibit a substantialJOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 9
(a) ResultsontheSuperNIbenchmark (b) ResultsontheLongSequencebenchmark
Fig.4. PerformanceofTaSLw/differentbackbones.
Figure 7, leading to several critical insights:
• There is a noticeable variation in the importance of skill
units for the same task, with important skill units making
up only a small fraction of all trainable LoRA parameters.
• The distribution of important skill units is task-dependent,
indicating both task-shared and specific parameters, con-
firming TaSL’s validity.
• For classification tasks, such as those in the Long Sequence
Benchmark (Figure 6), the skill units in the encoder, par-
ticularly the lower layers closer to the model input, play a
more significant role. In contrast, for generative tasks, such
as dialogue generation and summarization in the SuperNI
Fig.5. PerformancetrajectoryofTask1onLongSequenceBenchmarkduring benchmark (Figure 7), both the encoder and decoder skill
theCLprocess. unitsare important,withboth thelowerand upperlayersof
the network being crucial.
TABLEIII
RESULTSONUNSEENTASKSBASEDONTHET5-LARGEBACKBONE • Withineachlayer,theimportanceoftheQuery(Q)matrices
MODEL.WEREPORTTHEAVERAGEROUGE-LOFTHE3TASKSUNDER intheattentionmechanismconsistentlysurpassesthatofthe
EACHCATEGORY. Value (V) matrices.
Unseen Tasks
Avg.
Dialog IE QA Sum SA E. Ablation Study
T5-ZS 7.49 6.70 4.28 12.14 4.54 7.03 In this section, we evaluate the impact of importance-
O-LoRA 4.39 9.89 25.38 8.26 50.41 19.67 aware skill localization, fine-grained skill consolidation, and
LFPT5 6.96 35.32 35.00 13.26 21.51 22.41
hyperparameter sensitivity, with the results discussed below.
TasLoRA 10.32 31.34 37.13 14.20 47.17 28.03 1) Effect of the proposed importance metric in skill local-
ization: Our method calculates importance scores using Eq.
(6). As shown in Table IV, we explore alternative importance
averageperformancedropof20%,underscoringourmethod’s
scoring approaches: (i) to test the effectiveness of using
superior ability to mitigate forgetting.
moving averages on trajectory gradients, we modify s(·) in
Eq. (6) to include only sensitivity, as described in Eq. (9);
C. Performance on Unseen Tasks
and (ii) to assess the validity of our proposed approximate
Following previous work [16], we further select three tasks second-order gradient importance metric in Eq. (6), we use
fromeachoneoftheabovetaskcategoriestoassesstheTaSL’s a first-order Taylor expansion to approximate the importance
cross-task generalization ability. This is also a crucial dimen- I by using Eq. (8). The results indicate that using moving
sionforevaluatingCLalgorithms.TableIIIshowstheresults. averages for importance scoring outperforms the alternatives,
T5-ZSrepresentsthezero-shotapproachesfortaskadaptation, with the other two variants leading to performance decreases
respectively. TasLoRA achieved the best performance, which of up to 3.3%, 2.5%, and 4.2% across the three metrics.
can be attributed to its ability to identify task-specific and This underscores the value of accurate skill localization in
shared parameters effectively. enhancing model performance.
2) Effect of Adaptive Skill Consolidation: We compared
D. Visualization of Skill Units
our fine-grained skill unit-level adaptive LoRA averaging
We visualized the distribution of importance scores for the mechanism against two coarse-grained strategies: (i) Weight-
skill units across tasks on T5-large, as shown in Figure 6 and Ensemble,whichusesaglobalweighttouniformlyaveragetheJOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 10
Fig.6. VisualizationofimportancescoresforskillunitsacrossdifferenttasksonT5-largefortheLongSequenceBenchmark.
Fig.7. VisualizationofimportancescoresforskillunitsacrossdifferenttasksonT5-largefortheSuperNIBenchmark.
TABLEIV TABLEV
ABLATIONSTUDY.EVALUATINGTHEIMPACTOFIMPORTANCESCORING ABLATIONSTUDY.COMPARINGCOARSE-ANDFINE-GRAINEDMODEL
VARIATIONSONSKILLLOCALIZATION. AVERAGINGMETHODSONSKILLCONSOLIDATION.
Method AP FWT BWT Method AP FWT BWT
vanillaT5-large 54.10 3.32 -29.63 vanillaT5-large 54.10 3.32 -29.63
s(·)=I(·) 70.48 10.39 -3.81 Weight-Ens. 63.28 7.71 -11.82
(cid:12) (cid:12)
s(·)=(cid:12)∇wijL(cid:12) 68.82 10.80 -6.22 EMA 62.76 8.23 -9.80
TasLoRA(ours) 72.29 12.89 -2.04 TasLoRA(ours) 72.29 12.89 -2.04
3) SensitivityAnalysisforHyperparameters: Theproposed
LoRA parameters, i.e., Eq. (14), and (ii) Exponential Moving
framework incorporates three key hyperparameters, including
Average (EMA) [60], which applies a running average of the α for computing importance scores in Eq. (10) and Eq.
parameters at each fine-tuning iteration. (11), the β for calculating cumulative importance scores in
For Table V, Weight-Ensemble significantly improves upon Eq. (13), and the τ for performing weighted averaging within
the vanilla model, highlighting the benefits of coarse-grained skill units as outlined in Eq. (16). Our analysis aims to assess
averaging for continual learning. EMA generally outperforms the impact of varying these hyperparameters on our method’s
Weight-Ensemble but falls short of our fine-grained approach performance, testing on the T5-large backbone model.
duetoitsoveruseofaveraging,withfrequentparameteradjust- As evidenced in Table VI, we determine that the optimal
ments within the same task potentially leading to suboptimal setting for α is 0.55. An α value too low results in a
outcomes.Ourmethod,whichaveragesweightsonlyaftereach performancedecline,indicatingthatthecalculatedimportance
task, enhances computational efficiency. scores are not sufficiently accurate. Furthermore, as depictedJOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 11
TABLEVI TABLEVIII
PERFORMANCECOMPARISONSOFTASLEQUIPPEDWITHDIFFERENTαON PERFORMANCECOMPARISONSOFTASL(USINGT5-LARGEASTHE
LONGSEQUENCEBENCHMARKATTASKORDER1. BACKBONE)EQUIPPEDWITHDIFFERENTτ ONLONGSEQUENCE
BENCHMARKATTASKORDER1.
α1,α2 AP FWT BWT
temperaturecoefficientτ AP FWT BWT
VanillaT5-large 51.6 5.6 -29.7
0.05 69.0 14.3 -3.4
0.15 71.8 13.7 -3.7 0.15 73.4 12.8 -2.1
0.35 71.2 14.1 -4.3 0.25 72.2 13.2 -2.5
0.55 72.8 12.6 -2.5 0.35 72.1 13.6 -2.1
0.85 70.7 12.9 -3.3 0.45 72.7 12.5 -3.0
0.95 71.7 14.0 -3.6 0.55 70.9 11.6 -4.2
TABLEVII
PERFORMANCECOMPARISONSOFTASLEQUIPPEDWITHDIFFERENTβON limitations remain. For instance, the choice of importance
LONGSEQUENCEBENCHMARKATTASKORDER1. thresholds after determining the importance distribution can
affect the effectiveness of subsequent consolidation. Dynami-
β AP FWT BWT
callyselectingthresholdsbasedondatadistributioncouldlead
VanillaT5-large 51.6 5.6 -29.7 tomoreaccurateclassificationoftask-sharedandtask-specific
0.1 73.8 13.6 -3.7 parameters, thereby enhancing performance. Additionally, we
0.3 73.5 12.4 -3.4 could explore merging the skill localization and consolidation
0.5 74.3 13.5 -2.2 stages, allowing for parameter consolidation based on impor-
0.7 72.7 12.9 -2.3 tance during model training. This would enable more flexible
0.9 60.2 14.2 -5.0
adaptation and address scenarios in online continual learning.
APPENDIX
inTableVII,wealsofindthatβ valueswithinanormalrange
DATASETDETAILS
do not significantly affect performance. However, excessively
highorlowvaluesforβ mayskewthemodeltowardsfavoring Table IX & X show details of the datasets we used for our
either past or current task knowledge, thereby disrupting experiments, along with their evaluation metrics. Overall, in
the desired balance. Nonetheless, the model’s performance SuperNI,wechoose3tasksfromdialoguegeneration(Dialog),
remains relatively stable across most conditions, indicating a informationextraction(IE),questionanswering(QA),summa-
low sensitivity to hyperparameter variations. rization (Sum) and sentiment analysis (SA), respectively.
The VIII below shows the model’s performance under For the Long Sequence benchmark, this includes five tasks
differenttemperaturecoefficients,τ.Itcanbeseenthatsetting fromthestandardCLbenchmark(AGNews,Amazonreviews,
a higher τ (higher than 0.5) smooths the weights, thereby Yelpreviews,DBpediaandYahooAnswers),fourfromGLUE
increasingtheweightofunimportantskillunits,whichreduces benchmark (MNLI, QQP, RTE, SST2), five from SuperGLUE
the model’s effectiveness and may contaminate historical benchmark (WiC, CB, COPA, MultiRC, BoolQ), and the
knowledge, leading to forgetting. On the other hand, setting a IMDBmoviereviewsdataset.Wereport4differenttaskorders
lower τ (less than 0.1) may cause larger differences in weight used for our experiments in Table XI.
coefficients, thereby limiting KT between different tasks.
REFERENCES
VII. CONCLUSION [1] T.Brown,B.Mann,N.Ryder,M.Subbiah,J.D.Kaplan,P.Dhariwal,
A.Neelakantan,P.Shyam,G.Sastry,A.Askelletal.,“Languagemod-
In this paper, we introduce a novel Task Skill Localization els are few-shot learners,” Advances in neural information processing
andConsolidation(TaSL)frameworkforlanguagemodelcon- systems,vol.33,pp.1877–1901,2020.
[2] T. Wu, L. Luo, Y.-F. Li, S. Pan, T.-T. Vu, and G. Haffari, “Con-
tinuallearning,facilitatingeffectiveknowledgetransferacross
tinual learning for large language models: A survey,” arXiv preprint
tasks. Our framework leverages an importance-aware skill arXiv:2402.01364,2024.
localization and a fine-grained skill consolidation technique [3] L. Wang, X. Zhang, H. Su, and J. Zhu, “A comprehensive survey of
continuallearning:Theory,methodandapplication,”IEEETransactions
to differentiate between task-specific and shared knowledge
onPatternAnalysisandMachineIntelligence,2024.
within each skill unit, thereby mitigating forgetting. TaSL [4] D.-W. Zhou, H.-L. Sun, J. Ning, H.-J. Ye, and D.-C. Zhan, “Con-
also demonstrates strong generalizability and extensibility, tinual learning with pre-trained models: A survey,” arXiv preprint
arXiv:2401.16386,2024.
with optimizations to various components and the ability to
[5] M.McCloskeyandN.J.Cohen,“Catastrophicinterferenceinconnec-
integrate with memory replay methods for further perfor- tionist networks: The sequential learning problem,” in Psychology of
mance enhancement. Comprehensive experiments showcase learningandmotivation. Elsevier,1989,vol.24,pp.109–165.
[6] Z. Ke, B. Liu, N. Ma, H. Xu, and L. Shu, “Achieving forgetting
ourframework’sexceptionalabilitytobalancepreservingpast
prevention and knowledge transfer in continual learning,” Advances in
knowledge and excelling in new tasks, surpassing previous Neural Information Processing Systems, vol. 34, pp. 22443–22456,
state-of-the-art methods. 2021.
[7] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang,
While our method significantly improves efficiency and
and W. Chen, “Lora: Low-rank adaptation of large language models,”
performanceinlargelanguagemodelcontinuallearning,some arXivpreprintarXiv:2106.09685,2021.JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 12
TABLEIX
THEDETAILSOF15DATASETSINTHESUPERNIBENCHMARK[48].
Datasetname Task Metric
1.task639_multi_woz_user_utterance_generation dialoguegeneration Rouge-L
2.task1590_diplomacy_text_generation dialoguegeneration Rouge-L
3.task1729_personachat_generate_next dialoguegeneration Rouge-L
4.task181_outcome_extraction informationextraction Rouge-L
5.task748_glucose_reverse_cause_event_detection informationextraction Rouge-L
6.task1510_evalution_relation_extraction informationextraction Rouge-L
7.task002_quoref_answer_generation questionanswering Rouge-L
8.task073_commonsenseqa_answer_generation questionanswering Rouge-L
9.task591_sciq_answer_generation questionanswering Rouge-L
10.task511_reddit_tifu_long_text_summarization summarization Rouge-L
11.task1290_xsum_summarization summarization Rouge-L
12.task1572_samsum_summary summarization Rouge-L
13.task363_sst2_polarity_classification sentimentanalysis accuracy
14.task875_emotion_classification sentimentanalysis accuracy
15.task1687_sentiment140_classification sentimentanalysis accuracy
TABLEX
THEDETAILSOF15CLASSIFICATIONDATASETSINTHELONGSEQUENCEBENCHMARK[18].FIRSTFIVETASKSCORRESPONDTOTHESTANDARDCL
BENCHMARK[61].
Datasetname Category Task Domain Metric
1.Yelp CLBenchmark sentimentanalysis Yelpreviews accuracy
2.Amazon CLBenchmark sentimentanalysis Amazonreviews accuracy
3.DBpedia CLBenchmark topicclassification Wikipedia accuracy
4.Yahoo CLBenchmark topicclassification YahooQ&A accuracy
5.AGNews CLBenchmark topicclassification news accuracy
6.MNLI GLUE naturallanguageinference various accuracy
7.QQP GLUE paragraphdetection Quora accuracy
8.RTE GLUE naturallanguageinference news,Wikipedia accuracy
9.SST-2 GLUE sentimentanalysis moviereviews accuracy
10.WiC SuperGLUE wordsensedisambiguation lexicaldatabases accuracy
11.CB SuperGLUE naturallanguageinference various accuracy
12.COPA SuperGLUE questionandanswering blogs,encyclopedia accuracy
13.BoolQA SuperGLUE booleanquestionandanswering Wikipedia accuracy
14.MultiRC SuperGLUE questionandanswering various accuracy
15.IMDB SuperGLUE sentimentanalysis moviereviews accuracy
TABLEXI
FOURDIFFERENTORDERSOFTASKSEQUENCESUSEDFOROUREXPERIMENTS.ORDERS1-2CORRESPONDTOTHESUPERNIBENCHMARK.ORDERS3-4
ARELONG-SEQUENCEORDERSFOLLOWING[18].
Order Model TaskSequence
task1572→task363→task1290→task181→task002→
1 T5,LLaMA-2 task1510→task639→task1729→task073→task1590→
task748→task511→task591→task1687→task875
task748→task073→task1590→task639→task1572→
2 T5,LLaMA-2 task1687→task591→task363→task1510→task1729→
task181→task511→task002→task1290→task875
mnli→cb→wic→copa→qqp→boolqa→rte→imdb→
3 T5,LLaMA-2 yelp→amazon→sst-2→dbpedia→ag→multirc→yahoo
yelp→amazon→mnli→cb→copa→qqp→rte→imdb→
4 T5,LLaMA-2 sst-2→dbpedia→ag→yahoo→multirc→boolqa→wicJOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 13
[8] N. Ding, Y. Qin, G. Yang, F. Wei, Z. Yang, Y. Su, S. Hu, Y. Chen, [32] C. Chen, J. Song, L. Gao, and H. T. Shen, “Towards redundancy-free
C.-M. Chan, W. Chen et al., “Delta tuning: A comprehensive study sub-networks in continual learning,” arXiv preprint arXiv:2312.00840,
ofparameterefficientmethodsforpre-trainedlanguagemodels,”arXiv 2023.
preprintarXiv:2203.06904,2022. [33] Y. Zuo, H. Yao, L. Yu, L. Zhuang, and C. Xu, “Hierarchical prompts
[9] S.-A. Rebuffi, A. Kolesnikov, G. Sperl, and C. H. Lampert, “icarl: forrehearsal-freecontinuallearning,”arXivpreprintarXiv:2401.11544,
Incrementalclassifierandrepresentationlearning,”inProceedingsofthe 2024.
IEEEconferenceonComputerVisionandPatternRecognition,2017,pp. [34] J. S. Smith, L. Karlinsky, V. Gutta, P. Cascante-Bonilla, D. Kim,
2001–2010. A. Arbelle, R. Panda, R. Feris, and Z. Kira, “Coda-prompt: Contin-
[10] M. Boschini, L. Bonicelli, P. Buzzega, A. Porrello, and S. Calderara, ual decomposed attention-based prompting for rehearsal-free continual
“Class-incrementalcontinuallearningintotheextendedder-verse,”IEEE learning,” in Proceedings of the IEEE/CVF Conference on Computer
transactionsonpatternanalysisandmachineintelligence,vol.45,no.5, VisionandPatternRecognition,2023,pp.11909–11919.
pp.5497–5512,2022. [35] Z.Ke,Y.Shao,H.Lin,T.Konishi,G.Kim,andB.Liu,“Continualpre-
[11] A.A.Rusu,N.C.Rabinowitz,G.Desjardins,H.Soyer,J.Kirkpatrick, trainingoflanguagemodels,”arXivpreprintarXiv:2302.03241,2023.
K. Kavukcuoglu, R. Pascanu, and R. Hadsell, “Progressive neural [36] P. Michel, O. Levy, and G. Neubig, “Are sixteen heads really better
networks,”arXivpreprintarXiv:1606.04671,2016. thanone?”Advancesinneuralinformationprocessingsystems,vol.32,
2019.
[12] Z. Wang, Y. Liu, T. Ji, X. Wang, Y. Wu, C. Jiang, Y. Chao, Z. Han,
L. Wang, X. Shao et al., “Rehearsal-free continual language learning [37] V.Sanh,T.Wolf,andA.M.Rush,“Movementpruning:adaptivesparsity
via efficient parameter isolation,” in Proceedings of the 61st Annual
byfine-tuning,”inProceedingsofthe34thInternationalConferenceon
Meeting of the Association for Computational Linguistics (Volume 1:
NeuralInformationProcessingSystems,2020,pp.20378–20389.
LongPapers),2023,pp.10933–10946. [38] Q.Zhang,S.Zuo,C.Liang,A.Bukharin,P.He,W.Chen,andT.Zhao,
“Platon:Pruninglargetransformermodelswithupperconfidencebound
[13] K. Ksia˛z˙ek and P. Spurek, “Hypermask: Adaptive hypernetwork-based
ofweightimportance,”inInternationalConferenceonMachineLearn-
masksforcontinuallearning,”arXivpreprintarXiv:2310.00113,2023.
ing. PMLR,2022,pp.26809–26823.
[14] Z. Wang, Y. Li, L. Shen, and H. Huang, “A unified and general
[39] Q. Zhang, M. Chen, A. Bukharin, P. He, Y. Cheng, W. Chen, and
framework for continual learning,” arXiv preprint arXiv:2403.13249,
T.Zhao,“Adaptivebudgetallocationforparameter-efficientfine-tuning,”
2024.
inInternationalConferenceonLearningRepresentations. Openreview,
[15] D.Zhu,Z.Sun,Z.Li,T.Shen,K.Yan,S.Ding,K.Kuang,andC.Wu,
2023.
“Model tailor: Mitigating catastrophic forgetting in multi-modal large
[40] M.DeLange,R.Aljundi,M.Masana,S.Parisot,X.Jia,A.Leonardis,
languagemodels,”arXivpreprintarXiv:2402.12048,2024.
G.Slabaugh,andT.Tuytelaars,“Acontinuallearningsurvey:Defying
[16] W. Zhao, S. Wang, Y. Hu, Y. Zhao et al., “Sapt: A shared attention forgettinginclassificationtasks,”IEEEtransactionsonpatternanalysis
framework for parameter-efficient continual learning of large language andmachineintelligence,vol.44,no.7,pp.3366–3385,2021.
models,”arXivpreprintarXiv:2401.08295,2024. [41] A.Aghajanyan,L.Zettlemoyer,andS.Gupta,“Intrinsicdimensionality
[17] Y.-S.LiangandW.-J.Li,“Inflora:Interference-freelow-rankadaptation explainstheeffectivenessoflanguagemodelfine-tuning,”arXivpreprint
forcontinuallearning,”arXivpreprintarXiv:2404.00228,2024. arXiv:2012.13255,2020.
[18] A.Razdai,Y.Mao,R.Hou,M.Khabsa,M.Lewis,andA.Almahairi, [42] T. Konishi, M. Kurokawa, C. Ono, Z. Ke, G. Kim, and B. Liu,
“Progressiveprompts:Continuallearningforlanguagemodels,”inThe “Parameter-Level Soft-Masking for Continual Learning,” in Proc. of
EleventhInternationalConferenceonLearningRepresentations,2022. ICML,2023.
[19] X. Wang, T. Chen, Q. Ge, H. Xia, R. Bao, R. Zheng, Q. Zhang, [43] Y.LeCun,J.Denker,andS.Solla,“Optimalbraindamage,”Advances
T. Gui, and X. Huang, “Orthogonal subspace learning for language inneuralinformationprocessingsystems,vol.2,1989.
modelcontinuallearning,”arXivpreprintarXiv:2310.14152,2023. [44] C. Liang, S. Zuo, M. Chen, H. Jiang, X. Liu, P. He, T. Zhao, and
[20] Y.Feng,X.Chu,Y.Xu,G.Shi,B.Liu,andX.-M.Wu,“Tasl:Continual W. Chen, “Super tickets in pre-trained language models: From model
dialog state tracking via task skill localization and consolidation,” compression to improving generalization,” in Proceedings of the 59th
in Proceedings of the 62nd Annual Meeting of the Association for Annual Meeting of the Association for Computational Linguistics and
ComputationalLinguistics(Volume1:LongPapers),2024. the11thInternationalJointConferenceonNaturalLanguageProcessing
[21] A. Panigrahi, N. Saunshi, H. Zhao, and S. Arora, “Task-specific skill (Volume1:LongPapers),2021,pp.6524–6538.
localizationinfine-tunedlanguagemodels,”inInternationalConference [45] J. J. Rissanen, “Fisher information and stochastic complexity,” IEEE
onMachineLearning. PMLR,2023,pp.27011–27033. transactionsoninformationtheory,vol.42,no.1,pp.40–47,1996.
[22] Z.Zhang,J.Zhao,Q.Zhang,T.Gui,andX.Huang,“Unveilinglinguistic [46] J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness, G. Desjardins,
regions in large language models,” arXiv preprint arXiv:2402.14700, A. A. Rusu, K. Milan, J. Quan, T. Ramalho, A. Grabska-Barwinska
2024. et al., “Overcoming catastrophic forgetting in neural networks,” Pro-
[23] D. Li and Z. Zeng, “Crnet: A fast continual learning framework with ceedings of the national academy of sciences, vol. 114, no. 13, pp.
random theory,” IEEE Transactions on Pattern Analysis and Machine 3521–3526,2017.
Intelligence,vol.45,no.9,pp.10731–10744,2023. [47] I.EddineMarouf,S.Roy,E.Tartaglione,andS.Lathuilière,“Weighted
ensemble models are strong continual learners,” arXiv e-prints, pp.
[24] Y.Wang,Y.Liu,C.Shi,H.Li,C.Chen,H.Lu,andY.Yang,“Inscl:A
arXiv–2312,2023.
data-efficientcontinuallearningparadigmforfine-tuninglargelanguage
[48] Y. Wang, S. Mishra, P. Alipoormolabashi, Y. Kordi, A. Mirzaei,
modelswithinstructions,”arXivpreprintarXiv:2403.11435,2024.
A.Arunkumar,A.Ashok,A.S.Dhanasekaran,A.Naik,D.Stapetal.,
[25] Q. Pham, C. Liu, and S. C. Hoi, “Continual learning, fast and slow,”
“Super-naturalinstructions:Generalizationviadeclarativeinstructionson
IEEETransactionsonPatternAnalysisandMachineIntelligence,2023.
1600+nlptasks,”arXivpreprintarXiv:2204.07705,2022.
[26] J. Huang, L. Cui, A. Wang, C. Yang, X. Liao, L. Song, J. Yao, and
[49] Z.Wang,Z.Zhang,C.-Y.Lee,H.Zhang,R.Sun,X.Ren,G.Su,V.Perot,
J.Su,“Mitigatingcatastrophicforgettinginlargelanguagemodelswith
J. Dy, and T. Pfister, “Learning to prompt for continual learning,” in
self-synthesizedrehearsal,”arXivpreprintarXiv:2403.01244,2024.
Proceedings of the IEEE/CVF Conference on Computer Vision and
[27] X.Li,S.Wang,J.Sun,andZ.Xu,“Variationaldata-freeknowledgedis- PatternRecognition,2022,pp.139–149.
tillationforcontinuallearning,”IEEETransactionsonPatternAnalysis
[50] C. Qin and S. Joty, “Lfpt5: A unified framework for lifelong few-
andMachineIntelligence,vol.45,no.10,pp.12618–12634,2023.
shot language learning based on prompt tuning of t5,” arXiv preprint
[28] Y. Zhang, X. Wang, and D. Yang, “Continual sequence generation arXiv:2110.07298,2021.
withadaptivecompositionalmodules,”arXivpreprintarXiv:2203.10652, [51] C.-Y.Lin,“Rouge:Apackageforautomaticevaluationofsummaries,”
2022. inTextsummarizationbranchesout,2004,pp.74–81.
[29] G.Rypes´c´,S.Cygert,V.Khan,T.Trzcin´ski,B.Zielin´ski,andB.Twar- [52] A.Chaudhry,P.K.Dokania,T.Ajanthan,andP.H.Torr,“Riemannian
dowski,“Divideandnotforget:Ensembleofselectivelytrainedexperts walk for incremental learning: Understanding forgetting and intransi-
incontinuallearning,”arXivpreprintarXiv:2401.10191,2024. gence,”inProceedingsoftheEuropeanconferenceoncomputervision
[30] J.Xu,J.Ma,X.Gao,andZ.Zhu,“Adaptiveprogressivecontinuallearn- (ECCV),2018,pp.532–547.
ing,” IEEE transactions on pattern analysis and machine intelligence, [53] D.Lopez-PazandM.Ranzato,“Gradientepisodicmemoryforcontinual
vol.44,no.10,pp.6715–6728,2021. learning,” Advances in neural information processing systems, vol. 30,
[31] C. Qin, S. Joty, and C. Chen, “Lifelong sequence generation 2017.
with dynamic module expansion and adaptation,” arXiv preprint [54] Z. Ke and B. Liu, “Continual learning of natural language processing
arXiv:2310.09886,2023. tasks:Asurvey,”arXivpreprintarXiv:2211.12701,2022.JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 14
[55] M. Farajtabar, N. Azizan, A. Mott, and A. Li, “Orthogonal gradient
descentforcontinuallearning,”inInternationalConferenceonArtificial
IntelligenceandStatistics. PMLR,2020,pp.3762–3773.
[56] M.Wang,H.Adel,L.Lange,J.Strötgen,andH.Schütze,“Rehearsal-
freemodularandcompositionalcontinuallearningforlanguagemodels,”
arXivpreprintarXiv:2404.00790,2024.
[57] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena,
Y. Zhou, W. Li, and P. J. Liu, “Exploring the limits of transfer
learningwithaunifiedtext-to-texttransformer,”TheJournalofMachine
LearningResearch,vol.21,no.1,pp.5485–5551,2020.
[58] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux,
T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar et al.,
“Llama:Openandefficientfoundationlanguagemodels,”arXivpreprint
arXiv:2302.13971,2023.
[59] F.-K. Sun, C.-H. Ho, and H.-Y. Lee, “Lamol: Language modeling for
lifelonglanguagelearning,”arXivpreprintarXiv:1909.03329,2019.
[60] C.Szegedy,V.Vanhoucke,S.Ioffe,J.Shlens,andZ.Wojna,“Rethinking
the inception architecture for computer vision,” in Proceedings of the
IEEEconferenceoncomputervisionandpatternrecognition,2016,pp.
2818–2826.
[61] X. Zhang, J. Zhao, and Y. LeCun, “Character-level convolutional net-
worksfortextclassification,”Advancesinneuralinformationprocessing
systems,vol.28,2015.