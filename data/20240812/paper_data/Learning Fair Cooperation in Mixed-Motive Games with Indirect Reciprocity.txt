Learning Fair Cooperation in Mixed-Motive Games with Indirect Reciprocity
MartinSmit, FernandoP.Santos
InformaticsInstitute,UniversityofAmsterdam
j.m.m.smit,f.p.santos @uva.nl
{ }
Abstract illustrates the ubiquitous social dilemma of altruistic coop-
eration. Thesedilemmasareknownasmixed-motivegames
Altruistic cooperation is costly yet socially desir-
astheycombinetheprinciplesofcompetitive(i.e.,zero-sum
able. As a result, agents struggle to learn co-
games) and cooperative interactions. Understanding how to
operative policies through independent reinforce-
engineer cooperation in mixed-motive settings is a funda-
ment learning (RL). Indirect reciprocity, where
mentalscientificchallenge[Pennisi,2005;RandandNowak,
agents consider their interaction partner’s reputa-
2013] and a key frontier in AI research [Paiva et al., 2018;
tion, has been shown to stabilise cooperation in
Dafoeetal.,2021;ConitzerandOesterheld,2023;Fatimaet
homogeneous, idealised populations. However,
al.,2024].
more realistic settings are comprised of hetero-
Indistributedmulti-agentsystems,researchhasfocusedon
geneous agents with different characteristics and
thedesignofautonomoussystemswherecooperationissta-
group-based social identities. We study coopera-
ble [Genesereth et al., 1986]. In such contexts, it is funda-
tionwhenagentsarestratifiedintotwosuchgroups,
mentaltounderstandhowadaptiveagentscanlearntocoop-
and allow reputation updates and actions to de-
erate over time in a decentralised way [Claus and Boutilier,
pend on group information. We consider two
1998].Thecooperationmechanismsobservedinhumansoci-
modelling approaches: evolutionary game theory,
eties[RandandNowak,2013]haveinspiredformalmethods
wherewecomprehensivelysearchforsocialnorms
tostabilisecooperationingroupsofartificialagents.
(i.e.,rulestoassignreputations)leadingtocooper-
One particularly effective mechanism to sustain coopera-
ationandfairness;andRL,whereweconsiderhow
tion among humans is indirect reciprocity (IR) [Nowak and
the stochastic dynamics of policy learning affects
Sigmund, 2005; Santos et al., 2021; Okada, 2020]. Within
the analytically identified equilibria. We observe
such a framework, agents are assumed to discriminate and
that a defecting majority leads the minority group
provide benefits based on the social standing of others; this
to defect, but not the inverse. Moreover, chang-
mechanismreliesontheavailabilityofreputations. Therules
ing the norms that judge in- and out-group inter-
that determine how such reputations are updated (so-called
actionscansteerasystemtowardseitherfairorun-
socialnorms)encapsulatethemoraljudgementsofwhatcon-
fair cooperation. This is made clearer when mov-
stitutesagoodorabadaction[OhtsukiandIwasa,2004].
ingbeyondequilibriumanalysistoindependentRL
agents, where convergence to fair cooperation oc- Despite success in human populations, the application of
curswithanarrowersetofnorms.Ourresultshigh- IR in systems of learning agents is technically challenging.
lightthat,inheterogeneouspopulationswithrepu- Associalnormsassessthe“goodness”ofeveryactioninev-
tations,carefullydefininginteractionnormsisfun- ery possible context, the number of possible norms grows
damental to tackle both dilemmas of cooperation
combinatoriallyinthenumberofactionsandstates[Santoset
andoffairness. al., 2018]. Moreover, small differences in otherwise similar
normscanhaveunpredictableeffectsonreputationdynamics.
Thismakespredictingwhichnormswillleadtoacooperative
1 Introduction
systemadifficulttask. Acentralchallengeisthereforedeter-
Cooperation is a fundamental research topic across disci- mining how reputations should be assigned for cooperation
plines[RandandNowak,2013;FehrandFischbacher,2003]. tobemaximised. Previousworkhasshownthatonlyasmall
Whilecooperativepopulationstendtothrive,individualsare setofsocialnormsareabletostabilisecooperationinpopu-
temptedtoactselfishly,receivingthebenefitsfromthecoop- lationsofhomogeneousagents[OhtsukiandIwasa,2004].
erationofotherswithoutexertingtheeffortthemselves. The Additionally, it is common for groups to exist or emerge
conundrum underlying this interaction is evident if we for- in a population, possibly as a byproduct of existing repu-
mally translate it into the so-called donation game, where a tation systems [Rosenblat et al., 2017; Gross and De Dreu,
donor decides whether to pay a cost c to offer a benefit b to 2019], and for agents to consider group affiliation alongside
a recipient. Assuming b > c > 0, this simple interaction reputations when making decisions. Notably, when social
4202
guA
8
]AM.sc[
1v94540.8042:viXranorms governing reputations display in-group bias or out- 2 RelatedWork
group prejudice, even group-blind decisions through reputa-
2.1 TheCooperationDilemma
tions can lead to inequality. Interactions in online market-
Understandinghumancooperationisafundamentalresearch
places,wherereputationsarekey,offeraparadigmaticexam-
topicacrossdisciplines[Pennisi,2005;FehrandFischbacher,
ple. Theshort-stayrentalplatformAirbnb,forinstance,dis-
2003; Rand and Nowak, 2013]. In AI, there is a grow-
plays ratings and profile pictures for both hosts and guests.
ing interest in designing artificial agents to be cooperative
Recent findings show that guests with a distinctly African
Americannamehavea12%loweracceptancerate[Edelman and generate cooperation in others. In a recent commen-
etal.,2017]. tary [Dafoe et al., 2021], the authors argue that AI requires
“social understanding” and the ability to cooperate in order
Although we observe cooperation dependent on the joint
toachievesuccessintasksthatrequirecomplexinteractions
effectofreputationandgroupidentity, theinteractionofthe
such as navigating pavements, financial markets, and online
two mechanisms has not yet been formalised. In this paper,
communication. Many tasks that AI engage with also re-
wefillthisgapbyansweringwhetherindependentagentsthat
quire cooperation with humans or other AI. Recent works
consider both reputations and group affiliations can learn to
have explored mechanisms to help enable cooperation. The
cooperateinanequitablemannerdespitebiasedsocialnorms.
proposed methods include agents with inequality-aversion
To answer this question, we employ two models which pro-
[Hughes et al., 2018], rewarding causal influence [Jaques
vide complementary perspectives: one focuses on analyt-
et al., 2019], self-play [Anastassacos et al., 2021], gifting
ically identifying norms that stabilise cooperative and fair
[Lupu and Precup, 2020] or introducing non-adaptive, pro-
states; the other focuses on how populations of reinforce-
socialagents[Santosetal.,2019;Anastassacosetal.,2021;
mentlearningagentscanreachthestablestatesidentified. As
Guoetal.,2023].
detailed below, we find that fairness and cooperation can be
achievediftherightnormischosentojudgeactions.
2.2 SocialNorms
1.1 StructureofPaperandContributions Previousworkexploreshowcoordinationtechniquesandso-
cial governance can influence the autonomy of agents in a
Afterintroducingrelatedliteratureoncooperationinmixed-
system and, for example, change the system’s levels of co-
motivegamesandindirectreciprocity(section2),subsequent
operation. Social norms implemented in computational sys-
sectionsofferthemaincontributionsofourpaper:
tems can help in this endeavour [Savarimuthu and Crane-
• Formalisationofanewmodeltosystematicallystudy field, 2011]. Two main classes of social norms are identi-
cooperation and fairness under indirect reciprocity fiedby[Villatoroetal.,2010]: “essential”normsthatseekto
(section3). Weintroducegroupidentitiesintoanexist- solve cooperation dilemmas and collective action problems
ingevolutionarygametheorymodeltoformalisediffer- [Griffith, 2010; Peleteiro et al., 2014] and “conventional” –
ingtreatmentofinandout-groupinteractionsbysocial
used to establish a convention, solving coordination dilem-
norms. Our model allows us to study the evolutionary mas[ShohamandTennenholtz,1997;SenandAiriau,2007;
stability of cooperative and fair strategies under differ- Moralesetal.,2013]. Ourworkfocusesonessentialnorms.
ent norms (3.1) and learning dynamics in a population It is also common to divide norms into top-down “legalist”
ofidentical,butindependent,Q-learningagents(3.2).
approaches, in which norms are designed offline and im-
• Stability analysis of norm-strategy combinations posed by a central authority and bottom-up “interactionist”
(subsection 4.1). We show that if the majority-identity approaches, where norms are emergent phenomena (e.g., as
defects, thentheminority-identitycannotsustaincoop- defined in [Haynes et al., 2017]). Recent work explores the
eration even amongst themselves, but the inverse does bottom-upcreationofnormsviaso-callednormentrepreneur-
not hold. Moreover, social norms that favour in-group ship [Anavankot et al., 2023] or observing public sanctions
interactions can sustain relatively high fairness and co- [Vinitskyetal.,2023]. Ourcontributioninvolvesboth: while
operation given a “counterweight” strategic bias. We weapplynormstop-down,theireffectivenessiscomputedvia
goontoexploretheeffectivenessofwell-studiednorms abottom-upprocess,wherestrategiesevolveovertime.
whenpaireduptojudgein-group/out-groupinteractions.
2.3 IndirectReciprocityinMulti-AgentSystems
• Analysis of cooperation and fairness dynamics of
Indirect reciprocity (IR) has been proposed as a mechanism
under Q-learning and group-structured populations
to elicit cooperation among reinforcement learning agents.
(subsection 4.2). We investigate the impact of RL
Anastassacosetal.[2021]examinewhetheragentswithpri-
on learning cooperative and fair policies under specific
vatesocialnormslearnedthroughQ-learningcanreachaso-
norms.Weshowthat,althoughcooperationdecreaseson
cially optimal consensus on how reputations should be in-
average in an independent RL setting, agents can learn
terpreted and updated. To aid this learning, the researchers
fair cooperation. Despite this, we show that reaching
proposeseedingthepopulationwithnon-learningagentsand
fair/cooperative states when the benefits of cooperation
through introspective self-play. They find that a combina-
arelowrequiresaninitialfractionofcooperativeagents.
tionofbothmechanismscansustaincooperation. Differently
Finally, in section 5, we discuss the limitations of our re- fromAnastassacosetal.[2021],hereagentsplayaone-sided
sultsandpossibledirectionsforfuturework. 1
indirect-reciprocity. Anextendedabstractofthispaperappearsin
1Appendix and code available at: www.github.com/sias-uva/ theProceedingsofAAMAS’24[SmitandSantos,2024].donation game as opposed to a two-sided donation game (a Donoraction 0 0 1 1
prisoner’s dilemma), and we shift learning from the norm Recipientreputation 0 1 0 1 Inputbits
space to the strategy space. These decisions were made to (cid:27)
Shunning(SH) 0 0 0 1
alignourpaperwiththeextensivepre-existingIRliterature.
SternJudging(SJ) 1 0 0 1
Whiletheasymmetricalnatureofourgamemerelymakes Reputation
ImageScoring(IS) 0 0 1 1 
learning slightly less consistent due to delayed rewards, the
SimpleStanding(SS) 1 0 1 1

shiftfromlearningnormstostrategiesfundamentallychanges
the focus of the papers. In their paper, the goal is to inter- 
nalise the reputation mechanism and examine its effects on Table 1: Social norms assign a reputation given different combi-
nations of actions and recipient reputations. The input bits above
learningcooperation. Incontrast,wetakethenormtobeex-
representthecontextinwhichanactiontakesplace.Byconvention,
ogenous, introduce another variable upon which that agents
1meansGood/Cooperateand0meansBad/Defect. Inourmodel,
candiscriminate(groupidentity),andseehowinequalitycan
anormiscomposedoftwofour-bitnorms: onetojudgein-group
emergeinspiteofcooperation.
interactionsandonetojudgeout-groupinteractions.
2.4 Group-structuredPopulations
Although we study 28 different social norms, in Table 1
SomepriorworksstudiedIRinpopulationswhereagentsex-
wegiveexamplesofcommonlystudiednorms. OneisStern-
plicitly belong to groups, through the lens of evolutionary
Judging, explored in detail by Pacheco et al. [2006], which
gametheory. Inthisdomain,Kessingeretal.[2023]assume
deems that it is good to defect against a bad agent or coop-
thatdifferentgroupsmightusedifferentsocialnormsandfo-
erate with a good one, and that doing the opposite action in
cusontheeffectofdifferentinformationbroadcastingmech-
either case is bad. Another is SimpleStanding, which says
anisms, whereby information about individuals can spread
thattheonlybadthingtodoistodefectagainstagoodagent
onlybetweenmembersofthesamegroupsorpublicly(asin
[PanchanathanandBoyd,2003]. Neitherofthesenormstake
traditionalmodels). Contrarytothesettingweexplorehere,
into account the group relation of the agents involved, but
Kessingeret al.[2023]assume that strategiesonly discrimi-
a norm that judged in-group interactions with SternJudging
natebasedonreputationsandnotgroupidentity. Theauthors
andout-groupinteractionswithSimpleStandingwouldimply
findthatinsuchsystems,cooperationultimatelydependson
agreaterdegreeofstrictnesswhenjudginginteractionswhere
therateofin/out-groupinteractions,andcooperationcancol-
both agents are members of the same group. This specific
lapseifinformationremainswithinthesamegroups.
norm, whichcouldbecalledStern/Stand, judgesinandout-
In a more recent work, Stewart and Raihani [2023] study
group interactions differently, so we refer to it interchange-
howstereotypesmightbeformedthroughgroupreciprocity:
ablyasunfairordiscriminatoryandtheothersmentionedas
theauthorsfindthatstereotypingcanleadtonegativejudge-
fair or group-agnostic. Fair and unfair norms are mutually
mentbias,inwhichindividualsbecomepessimisticaboutthe
exclusive.
willingness of out-group members to cooperate. Although
We assume that agents can make execution errors. An
theseworksstudydynamicsofIRunderreinforcementlearn-
agentwhointendedtocooperatewillsometimesdefectwith
ing [Anastassacos et al., 2021] and dynamics of reciprocity
some probability ϵ. Following previous works, agents have
associatedwithgroupidentities[StewartandRaihani,2023],
zero probability of cooperating when intending to defect.
thecombinationofindirectreciprocity,groupidentityandre-
Similarly, we assume that third-party observers using social
inforcement learning remains under-explored. In this paper,
normstoassignreputationscanalsoerrandassigntheoppo-
weproposeamodelthatcontributestofillthisgap.
sitereputationthanintended,withsomeprobabilityδ.
We assume a public reputation scheme where reputations
3 Model
are common knowledge among all agents. Although we do
In this paper, a well-mixed population of agents, stratified notexplicitlymodeltheprocessofreputationdiffusion,pub-
intotwogroups,interactbyplayingadonationgame. Inthe lic reputations can exist due to gossiping about what hap-
donationgame,aplayeriseitheradonororarecipient. The pened over an efficient communication network or a central
donormustdecidewhethertopayacosttoconferabenefitto judgeobservinginteractionsandbroadcastingreputations.
theirpartner,andweassumethatb>c>0. The way that agents decide how to act is determined by
theirstrategy. Strategiesdefine,foreachcombinationofrep-
Intheone-shotgame,thedominantstrategyforthedonor
utation and in/out-group, a corresponding action. As such,
istonotdonate,i.e. todefect. Toencouragecooperation,we
thespaceofstrategiesconsistsoffunctionsσsuchthat
considerreputationsandsocialnorms. Socialnormsencode
the rules of society that confer agents with a corresponding σ : 0,1 2 0,1 (1)
reputationbasedonwhethertheserulesarefollowedorbro- { } →{ }
ken. Inourmodel,theserulescandependontheactiontaken In the Q-learning model (see below), the Q-table holds Q-
by the donor, the current reputation of the potential recipi- valuesassociatedwitheachactionforeachbinarypairofin-
ent(their“goodness”),andwhetherthetwoagentsareinthe formation. We refer to the (effective) strategy of an agent
same group (their “sameness”). Following prior works on as the strategy that would result from applying the argmax
indirect reciprocity, all of these inputs are binary: a donor functiontotheQ-tableoneachpossibleinputpair.
has two actions, reputations are either “good” or “bad”, and SomenotablestrategiesincludeAllD,whichuncondition-
agentscanbeinthesameoradifferentgroup. ally refuses to donate, Disc, which conditionally cooperatesDonor groupswithinterdependentreputations. Thefullderivationis
availableinSectionAoftheappendix.
Afterthereputationsofplayershasstabilised,byintroduc-
ingtheutilitiesassociatedwitheachaction,wecanconsider
thelong-runaveragepayoffsofeachpopulation. Givenfixed
Strategy
reputations, the average player from any group has a fixed
probability of cooperating and being cooperated with every
time they partake in an interaction according to each popu-
lation’sstrategy,therelativesizeofeachpopulation,andthe
reputationsofeachpopulation.
If we associate to each group i a benefit received b and
i
cost of cooperating c , then we can determine the long term
SocialNorm i
payoffsU ofeachgroupas
i
2
int. don. don.
U
i
= P(i j) b iP(j i) c iP(i j) (2)
←→ −−→ − −−→
Recipient Xj=1 (cid:16) (cid:17)
int. don.
where means“interactswith”, means“donatesto”,
Figure1:Anillustrationofaninteractionbetweentwoagentswhich ←→ −−→
andtheprobabilitiesofdonatingarederivedfromthestation-
is observed by a third party using a social norm to update reputa-
aryreputations,strategies,anderrorratesofeachgroup.
tions.Thedonor’sstrategydeterminestheactiontakenbasedonthe
Bydoingasimilar(yetsimpler)derivationofmutantrep-
agents’relationtoeachother,andthereputationofthedonor. The
utations and payoffs, one can determine if the combination
thirdpartyobservestheactionandcontexttoassignthedonoranew
reputationbasedonafixedsocialnorm. ofnormsandstrategies(N,S 1,...,S K)isanevolutionarily
stablestate(ESS).
Stronger than the traditional Nash equilibrium, a strategy
with good agents and defects against bad ones, and AllC, S is evolutionarily stable on the condition that if any alter-
I
which unconditionally donates. Unfair strategies may in- nativestrategyS arisesinagroupthatS hasproliferated
M I
stead, for example, play AllC with in-group members and and that the proportion of agents playing this alternative is
playDiscwitheveryoneelse. sufficiently small, then this alternative strategy will perform
AnexampleinteractionisshowninFigure1,inwhichthe worsethantheincumbentstrategyS anddieout.Wesaythat
I
donor evaluates the recipient’s reputation and group relation a combination of norm and strategies is an ESS if all of its
accordingtotheirstrategyandtakesthecorrespondingaction. strategiesareevolutionarilystable. Ifallstrategiesinacom-
Athirdpartyobservestheactiontakenbythedonor, andits bination are AllD, then the combination is trivially an ESS
context,andassignsthedonoranewreputation. becauseanyalternativestrategythatcooperateswithanyone
wouldimmediatelybeworseoff.
3.1 EvolutionaryStability
WhileEGTandstabilityanalysisinformswhichstrategies
Giventhemodelintroducedabove,anaturalquestiononecan are stable under each norm, we need to understand 1) how
pose is: Given a norm, which strategies are more likely to prevalent each equilibrium point is and 2) whether learning
be played by agents in the long-run? One way this can be agentsconvergetoacertainESS.Forbothpurposes,weuse
answerediswithevolutionarygametheoretical(EGT)tools. multi-agentreinforcementlearning.
AkeyconcernofEGTisthatoftheevolutionarystabilityof
3.2 ReinforcementLearning
strategies:asagentsplaythedonationgame,theirpayoffsrise
and fall based ontheir strategy and its impact ontheir repu- We model agents as independent (tabular) Q-learners. Due
tation; a (resident) strategy is evolutionarily stable if agents totheasymmetryinthedonationgame,whileagentsalways
using an alternative (mutant) strategy are unable to achieve learnfromeveryinteraction,thedonorcanonlybenegatively
higheraveragepayoffsandinvade. reinforced by possibly donating, and recipients can only be
Assume that strategies S have proliferated the entire in- positivelyreinforcedbypossiblyreceivingadonation.Never-
i
cumbentpopulationofeachgroupi, andthatthepopulation theless,nomattertheinteraction,theQ-valuesofbothparties
is governed by social norm N. By calculating the expected decayduetothelearningrate. Weassumethatrecipientsat-
payoffofaplayerofeachgroupplayingtheirstrategyS ,we tributeswhateverdonationstheymayreceive(orlackthereof)
i
candeterminewhetheramutantstrategyinanygroupcould totheirmostrecentlytakenactionasadonor.
outperformtheincumbentsofthatgroup. Formally, if agent i meets agent j who has x relation to
TointroduceIR,weassumeatimescaleseparationbetween agent i and y reputation, then the action taken by i (a ∗) is
the evolution of reputations and the arrival of mutants, i.e. determinedbytheequation
allowingreputationstoconvergebeforeintroducingmutants.
Thisallowsustoderiveandanalyticallysolvethedifferential a ∗ =argmaxQ i[x,y,a] (3)
equationsthatgivethelong-termproportionsofgoodagents a 0,1
∈{ }
in each group. Our line of reasoning is identical to that of whereQ
i
R3 istheQ-tableofagentiandactions0and1
∈
Ohtsuki and Iwasa [2004], with the added complication of correspondtodefectionandcooperationrespectively.
)ronod(puorG
)tneipicer(puorG
noitatupeR
Action
NewreputationIn doing so, agent j will receive payoff a b and agent i
∗
willpaycosta ∗c. Agentjwillattributethispayofftothelast Majority strategy
actiontheytook(aˆ)incontextxˆandyˆ Always defectGroup-agnosticDiscriminatory 250
Qt i+1[x,y,a ∗] ←(1 −α)Qt i[x,y,a ∗] −αa ∗c (4) Always defect 2 (5 16
0
0o .f
0
2 %5 )6 68
(
2o .f
2
3 %,0 )72 200
Qt j+1[xˆ,yˆ,aˆ] ←(1 −α)Qt j[xˆ,yˆ,aˆ]+αa ∗b (5)
150
Inourmodel,strategiestakeintoaccountthein/out-group
18 of 2,304
relation,andnotwhichspecificgroupanotheragentisfrom. Group-agnostic (0.78%)
When combined with imbalances in group size, benefit-to- 100
costratio,anderrorrates,thisminimaltwo-groupmodelcan
capture the most pertinent fairness results while minimising
complexityandthecomputationalworknecessary. Discriminatory 10 (0 o .0f 23 76 %,86 )4 50
3.3 MetricsofSocialDesirability
Wemeasuretheperformanceofasystemwithtwometrics:
• The cooperativeness is the probability that, in a uni- Figure2: Weevaluateall216 NSS(Norm-Strategy-Strategy)com-
formlysampledinteraction,thedonorwillcooperate. binationsofnormsandstrategiesusedbythetwogroups. Wecate-
goriseeverystableNSSaccordingtothecooperativeanddiscrimi-
• Thefairnessistheratiobetweentheaveragepayoffsof natorynatureofstrategiesinvolved:strategiescandefectregardless
theworstoffandbestoffgroup. Thisisakintothede- oftheopponenttype(Alwaysdefect),ignoregroupidentity(Group-
mographicparityratiofromsupervisedlearning. agnostic)ordiscriminatebasedongroupidentity(Discriminatory).
Weobservethatgroup-agnosticstrategiesareunabletocoexistwith
3.4 ExperimentalSetup any other type of strategy, and a defecting majority playing AllD
leads a minority to defect – but not the inverse. Parameters used:
In all the following experiments, analytical or agent-based, b/c = 5,errorrate= 0.01. Intheappendix(Figure1)weconfirm
the reader may assume the following parameters were used thatthenumberofstablestatesremainsunchangedforawiderange
unless otherwise stated: The rate of agent execution errors oferrorratesandb/c.
and judgement execution errors is relatively rare at 1%, and
the benefit-to-cost ratio in our analytical model is 5 with
c=1,b=5. Thisrepresentsascenariowherecooperationis Figure2showswhichstrategiesarestableunderthissetup.
highlybeneficial(highb/cratio),yetdefectionisstilladom- Weobservethatgroup-agnosticstrategiesbyonegroupcan-
inantstrategy(c>0). Furthermore,themajoritygroupcom- not sustainably coexist with discriminatory strategies in an-
prises 90% of the population, and agents in different groups other,whichmeansthatawholegroupignoringgroupidenti-
are functionally identical. These choices allow us to isolate ties can make such identity discrimination unstable for ev-
theeffectsofdiscriminationandtheeffectsofinherentdiffer- eryone. Furthermore, we observe that the majority group
encesbetweenagents’indifferentgroups.Wereferreadersto can dictate whether cooperation can be stable: if the major-
theappendixforadiscussionofalternativeparametersetups itygroupunconditionallydefects,thereisnostablestrategies
(groupsize,benefits,errors). wheretheminoritycooperates;theinversedoesnothold. As
WerunourRLexperimentswithapopulationof50agents canbealsoseeninFigure2,conditionalcooperationfromthe
(45inthemajoritygroupand5intheminoritygroup).Wefix majoritygroupisaprerequisiteforcooperationintheminor-
theexplorationrateµandlearningrateαto0.1.Eachsimula- itygroup.
tionrunsfor250,000interactionsandweruneachsimulation
InFigure3weexplicitlycomputethelevelofcooperative-
50timeswithadifferentseed. Thesourcecodeforthispaper
ness and fairness for each stable combination of strategies,
(models,experiments,andfigures)isavailableonGitHub.
given any norm fixed in the population. We observe that
norms assigning reputations independently of group identi-
4 Results ties, lead to high levels of fairness, but not necessarily high
levels of cooperation. Unfair norms, on the other hand, can
4.1 StabilityAnalysis
lead to a cooperative yet unfair system, where a minority
First, we evaluate the stability of all possible combinations group always defects and the majority only cooperates with
of a norm and a strategy in each group, of which there are in-group members. Surprisingly, however, unfair norms can
216 possibilities. We distinguish between defective strate- alsosustainhighlycooperativeandfairsystems,throughthe
gies (Always defect/AllD), strategies ignoring group iden- stabilityofgroup-agnosticstrategies. Thismeansthattheob-
tity(Group-agnostic),andstrategiesdiscriminatingbasedon servedlevelsofcooperationandfairnessinasystemcannot
group-identity (Discriminatory). By considering these cate- triviallybeinferredfromthefairnesslevelofanorm. Dueto
gories we aim at developing an intuition for the possibility execution errors, the cooperativeness of a system can never
that fair and unfair cooperation emerge which, respectively, achieve a perfect score of 100% even when all players al-
reliesonstableGroup-agnosticandDiscriminatorystrategies. ways intend to cooperate. However, several norms are able
ygetarts
ytironiM
snoitanibmoc
elbats
fo
rebmuNweseetheanalyticallevelsofcooperationproducedbyeach
1.00
combinationofnormswhenusedtojudgein-andout-group
interactions. Wefindthat,asinpreviousworks[Ohtsukiand
Iwasa, 2007], SternJudging and SimpleStanding (defined in
0.75
Table 1) stabilise cooperation. However, with the addition
ofgroups,wearealsoabletoexaminecooperationwhenin-
teractions with outsiders are judged according to a different
0.50 socialnorm.Weobservethat,aslongasin-groupinteractions
arejudgedaccordingtoSternJudgingorSimpleStanding,out-
groupinteractionscanbeevaluatedaccordingtoothernorms
0.25 (e.g.,thestrictnormShunning)withoutsignificantlydecreas-
ingcooperation.Infact,weobservethatonecanevenuseIm-
ageScoringtojudgeout-groupinteractionsandrecoverhigh
0.00 levelsofcooperation. Thisisremarkablegiventhatthisnorm
0.00 0.25 0.50 0.75 1.00 issimpleandonlyreliesoninformationaboutanaction—a
Cooperativeness propertythatcanbeinstrumentalinsettingswheretherepu-
tationsofout-groupmembersarenotwidelyaccessible.
Whose strategy? What kind of strategy? What kind of norm?
Always defect
Majority strategy Unfair
Group-agnostic
Minority strategy Fair
Discriminatory 4.2 LearningFairCooperation
Figure3: Fairnorms(plottedassquares),whichassignreputations The previous (EGT) stability analysis informs which norms
independentlyofgroupidentities,leadtofairness,butnotnecessar- stabilisecooperationand, asaresult, beeffectiveinsustain-
ilyhighlevelsofcooperation(top-left). Highcooperationandfair- ingfaircooperationingroupsofheterogeneousagents. Iden-
nesscanbestablewithbothfairandunfairnorms(top-rightquad-
tifyingnormsthattheoreticallystabilisefairnessandcooper-
rant).Parametersused:sameasFigure2.
ation is a computationally attractive way of filtering norms
that, when implemented in a system of learning agents, can
possiblysustainfaircooperation.Learningfaircooperationin
toachieveequivalentlevelsofcooperationandfairness, and
afinitepopulationofadaptiveagentsrequires,however,that
these are superimposed in the very top-right of the figure.
agentsareabletoconvergetoadesirableequilibrium(which
Whenweinspectthecommonbitsbetweenthesenorms,we
isnaturallynottrivial). Here, weexplicitlymodelapopula-
findthat,regardlessofwhetherthenormtreatsin-groupand
tionofindependentRLagents. Figure5showsthatevenwith
out-groupthesame,thetwomustbetreatedbyeitherSimple-
ahigherbenefit-costratio(b/c = 10),somenormsthatwere
StandingorSternJudging(seeTable1).
previouslypredictedtostabilisefaircooperationarenotable
EvaluatingWell-knownSocialNorms todosoconsistentlyunderRL.Importantly,Figure5reveals
that moving from an EGT to an RL analysis can affect one
A number of “leading” norms, which can consistently sta-
orbothofcooperationandfairness,andtoadifferentextent,
bilise cooperation, have been identified in previous works
[OhtsukiandIwasa,2004;OhtsukiandIwasa,2006]. These dependingonthenorminquestion. Furthermore, thiseffect
isworsenedwhenthedilemmaismoredifficult,andcooper-
normsagreethatcooperatingwithgoodindividualsisgood,
ationdependsontheinitialQ-values,asshowninFigure6.
and defecting against good individuals is bad. In Figure 4,
Although some norms might lead to fair and cooperative
stablestates,theydifferinthesizeoftheattractionbasinsthat
Majority In-group norm Minority In-group norm leadtosuchstates. Furthermore, finitepopulationsoflearn-
Group SJ SS SH IS Group SJ SS SH IS ingagentsaresubjecttostochasticeffectsthatmightprevent
1.0
SJ SJ reachingfairandcooperativestates.
Despite the challenges of converging to cooperative/fair
SS SS
0.5 equilibria,indirectreciprocityconstitutesapromisingmech-
SH SH anismtosustaincooperationandfairnessinindependentRL
domains. WeconcludethatsocialnormssuchasSternJudg-
IS IS
ing (and close variants) can be applied to multi-agent rein-
0.0
forcement learning domains to, in group-structured popula-
tions,toensurebothcooperationandfairnessinthelong-run.
Figure4: WeuseabbreviationsfromTable1torefertothenorms.
Diagonal entries are previously studied “fair” norms. Overall, the Theeffectivenessofthisnormcanbeaugmentedbyresorting
majoritygroupismostaffectedbythein-groupnorm,andvice-versa to seeding agents, as previous works suggest [Anastassacos
for the minority group. In-group-ImageScoring causes a total co- etal.,2021]). Weobservethatacombinationofindirectreci-
operationbreakdown,whereasin-group-Shunningismostimpacted procityandseededagentscanbeharnessedto,notonlysus-
whenpairedwithout-group-Shunning,asagentshavefewerwaysto taincooperation[Anastassacosetal.,2021],butalsosupport-
recoverreputation. ingfairnessinaheterogeneousgroup-structuredpopulation.
mron
puorg-tuO
ssenriaF
mron
puorg-tuO
ssenevitarepooC
puorg
yb
decneirepxe1.0
1.00 8
6 0.5
0.75 4
0.0
0 20 40
Number of agents with Q-values initialised to strategy "Disc"
0.50
Figure 6: SternJudging can sustain high levels of cooperation in
a multi-agent RL setting, but for stricter dilemmas (lower b/c ra-
tios), convergence to a cooperative equilibrium is less likely and
highlydependentontheinitialdistributionofQ-values. Todemon-
0.25
stratethis, thex-axisshowsthatsomeagentswereinitialisedwith
Q-values corresponding to the socially optimal strategy: ignoring
Model groupsandcooperatingonlywithgoodindividuals.
EGT RL
0.00
0.00 0.25 0.50 0.75 1.00 achanginginteractionstructureorgrouplabelscouldinform
Cooperativeness
how to sustain cooperation and fairness in scenarios where
groupmembershipisdynamic.
Figure5:Somenormscansustainfairandcooperativeequilibria,yet
maybeineffectiveatguidingapopulationofindependentRLagents
Priorworkfocusesonnormemergenceanddynamics[De
toconvergetowardssuchstatesevenwithanelevatedb/cratioof10, etal.,2017;SavarimuthuandCranefield,2011]. Inthecon-
atrendwhichthisfiguredemonstrates. Weusedifferentcoloursto text of indirect reciprocity, work in this domain indicates
representdifferenthighlycooperativeandfairnorms(fromthetop- that decentralised reputation systems with private informa-
right quadrant of Figure 3). Circles represent EGT results, while tion can hinder cooperation [Hilbe et al., 2018], especially
squaresrepresentRLresults.Forsomenorms,RLagentsareunable when the norm itself must also be learned [Anastassacos et
toconvergetothestrategiesthattheoreticallyformanequilibrium, al., 2021]. This requires extra mechanisms to retain coop-
whichleadstolowerlevelsoffairness,cooperation,orboth. Some
eration under private reputations [Krellner and Han, 2022;
norms,suchasSternJudging(andvariations)areimpactedverylit-
Kawakatsu et al., 2024]. It may also be the case in a
tle,andthusindicatethatstrictnessisrequiredforindependentRL
fully decentralised setting that the norm changes over time,
agentstosustainfairnessandcooperation. InSectionCoftheap-
pendix,weexplorewhichstrategiesarelearnedtoleadtotheseout- something that may lead to an effective norm being chosen
comes. [Pacheco et al., 2006] or a complete breakdown in coopera-
tion[Xuetal.,2019]. Itwouldbeinterestingtoexplorehow
norms could be modified over time to maintain stable, fair
5 Conclusion cooperationbetweengroups.
Inthispaper,wehaveshownthatindirectreciprocityallows Despitethesedirectionsforfuturework,themodelwefor-
forfaircooperationamonggroup-structuredagents. Forthis malise, and following comprehensive study, already sheds
tohappen,onehastojudiciouslyselectsocialnorms; norms lightontheadvantagesandchallengesofindirectreciprocity
play a large part in determining the stability and learnabil- in a minimal setting of a group structured population. With
ityofpoliciesleadingtoafairandcooperativeoutcome. We thismodellingapproach,weofferalinkbetweenalgorithmic
showed that a large variety of norms and strategies can be fairness – typically considered in the context of supervised
stable, with varying levels of cooperation and fairness. We [Mehrabi et al., 2021] or unsupervised [Chierichetti et al.,
showed that well-known norms (like SternJudging) perform 2017] learning – and multi-agent systems where reputations
well when agents adapt through reinforcement learning, be- exist and social dilemmas of cooperation need to be solved.
ingabletoconsistentlyachieveneartotheidealisedlevelsof Ourmodelprovidesabaseframeworktoidentifynormsthat,
cooperationandfairnesspredictedbyouranalyticalmodel. insuchacontext,sustainhighlevelsofcooperationandfair-
Byusingtheminimalandgenericdonationgame,weoffer ness, thereby guaranteeing that universal cooperation is at-
aproofofconceptwhoseresultsmayinformtheapplication tainedandparochialismavoided.
ofindirectreciprocitytomoreelaboratemulti-agentsystems
and motivates future work along several dimensions: While
wemakethecommonEGTassumptionofawell-mixedpop- Acknowledgements
ulation, a preference for interacting with similar individuals
hasbeenobservedamonghumans[Fuetal.,2012]. Further- Co-funded by the European Union (ERC, RE-LINK,
more,groupsinourmodelarestatic. Ithasbeenshownthat 101116987). Views and opinions expressed are however
ad hoc group formation may occur in spatial mixed-motive thoseoftheauthor(s)onlyanddonotnecessarilyreflectthose
models[Baraetal.,2023]orincomplexnetworks[Grossand of the European Union or the European Research Council.
De Dreu, 2019] where diverse local conventions can evolve NeithertheEuropeanUnionnorthegrantingauthoritycanbe
[HuandLeung,2017];investigatinglearningdynamicswith heldresponsibleforthem.
ssenriaF
oitar
tsoc-ot-tifeneB
level
noitarepooCReferences dilemmas: Asurvey. JournalofArtificialIntelligenceRe-
[Anastassacosetal.,2021] Nicolas Anastassacos, Julian
search,79,March2024.
Garc´ıa,StephenHailes,andMircoMusolesi. Cooperation [FehrandFischbacher,2003] Ernst Fehr and Urs Fis-
and reputation dynamics with reinforcement learning. In chbacher. The nature of human altruism. Nature, 425,
Proc.ofthe20thInternationalConferenceonAutonomous October2003.
Agents and MultiAgent Systems. IFAAMAS, February
[Fuetal.,2012] Feng Fu, Martin A. Nowak, Nicholas A.
2021.
Christakis, and James H. Fowler. The evolution of ho-
[Anavankotetal.,2023] Amritha Menon Anavankot, mophily. ScientificReports,2,November2012.
Stephen Cranefield, and Bastin Tony Roy Savarimuthu.
[Geneserethetal.,1986] Michael R. Genesereth,
Towards norm entrepreneurship in agent societies. In
Matthew L. Ginsberg, and Jeffrey S. Rosenschein.
AdvancesinPracticalApplicationsofAgents,Multi-Agent
Cooperation without communication. In Proc. of the
Systems,andCognitiveMimetics.ThePAAMSCollection,
FifthAAAINationalConferenceonArtificialIntelligence,
Lecture Notes in Computer Science. Springer Nature
AAAI’86.AAAIPress,1986.
Switzerland,2023.
[Baraetal.,2023] Jacques Bara, Fernando P. Santos, and [Griffith,2010] MeghanGriffith. Whyagent-causedactions
are not lucky. American Philosophical Quarterly, 47,
PaoloTurrini. Theroleofspace,densityandmigrationin
2010.
socialdilemmas. InProc.ofthe2023InternationalCon-
ference on Autonomous Agents and Multiagent Systems, [GrossandDeDreu,2019] Jo¨rg Gross and Carsten K. W.
AAMAS’23.IFAAMAS,May2023. De Dreu. The rise and fall of cooperation through rep-
[Bezansonetal.,2012] JeffBezanson,StefanKarpinski,Vi- utation and group polarization. Nature Communications,
ral B. Shah, and Alan Edelman. Julia: A fast dynamic 10,February2019.
languagefortechnicalcomputing. arXiv:1209.5145[cs], [Guoetal.,2023] Hao Guo, Chen Shen, Shuyue Hu, Jun-
September2012. liangXing, PinTao, YuanchunShi, andZhenWang. Fa-
[Chierichettietal.,2017] Flavio Chierichetti, Ravi Kumar, cilitating cooperation in human-agent hybrid populations
Silvio Lattanzi, and Sergei Vassilvitskii. Fair clustering throughautonomousagents. iScience,26,2023.
throughfairlets. AdvancesinNeuralInformationProcess- [Haynesetal.,2017] Chris Haynes, Michael Luck, Peter
ingSystems,NeurIPS’17,30,2017.
McBurney, Samhar Mahmoud, Toma´sˇ V´ıtek, and Simon
[ClausandBoutilier,1998] Caroline Claus and Craig Miles. Engineering the emergence of norms: A review.
Boutilier. The dynamics of reinforcement learning in TheKnowledgeEngineeringReview,32,January2017.
cooperative multiagent systems. In Proc. of the Fifteenth
[Hilbeetal.,2018] Christian Hilbe, Laura Schmid, Josef
NationalConferenceonArtificialIntelligence,AAAI’98.
Tkadlec, Krishnendu Chatterjee, and Martin A. Nowak.
AAAIPress,1998.
Indirectreciprocitywithprivate,noisy,andincompletein-
[ConitzerandOesterheld,2023] Vincent Conitzer and Cas- formation. Proc. of the National Academy of Sciences,
par Oesterheld. Foundations of cooperative ai. Proc. of 115,November2018.
the AAAI Conference on Artificial Intelligence, 37, June
[HuandLeung,2017] ShuyueHuandHo-FungLeung. Lo-
2023.
cal norm phenomena in multi-agent systems under com-
[Dafoeetal.,2021] Allan Dafoe, Yoram Bachrach, Gillian munity networks. In Proc. of the 16th Conference on
Hadfield, Eric Horvitz, Kate Larson, and Thore Grae- AutonomousAgentsandMultiagentSystems, AAMAS’17,
pel. Cooperativeai: Machinesmustlearntofindcommon 2017.
ground. Nature,593,May2021.
[Hughesetal.,2018] Edward Hughes, Joel Z Leibo,
[DanischandKrumbiegel,2021] Simon Danisch and Julius Matthew Phillips, Karl Tuyls, Edgar Duen˜ez-Guzman,
Krumbiegel. Makie.jl: Flexiblehigh-performancedatavi- AntonioGarc´ıaCastan˜eda,IainDunning,TinaZhu,Kevin
sualization for Julia. Journal of Open Source Software, McKee,RaphaelKoster,HeatherRoff,andThoreGraepel.
6(65):3349,September2021. Inequity aversion improves cooperation in intertemporal
[Deetal.,2017] Soham De, Dana S Nau, and Michele J social dilemmas. In Advances in Neural Information
Gelfand. Understanding norm change: An evolutionary Processing Systems, volume 31. Curran Associates, Inc.,
game-theoreticapproach. InProc.ofthe16thConference 2018.
on Autonomous Agents and Multiagent Systems, AAMAS [Jaquesetal.,2019] Natasha Jaques, Angeliki Lazari-
2017,2017.
dou, Edward Hughes, Caglar Gulcehre, Pedro Ortega,
[Edelmanetal.,2017] Benjamin Edelman, Michael Luca, Dj Strouse, Joel Z. Leibo, and Nando De Freitas. Social
and Dan Svirsky. Racial discrimination in the sharing influence as intrinsic motivation for multi-agent deep
economy: Evidence from a field experiment. American reinforcementlearning. InProc.ofthe36thInternational
EconomicJournal: AppliedEconomics,9,April2017. ConferenceonMachineLearning.PMLR,May2019.
[Fatimaetal.,2024] ShaheenFatima,NicholasR.Jennings, [Kawakatsuetal.,2024] Mari Kawakatsu, Taylor A
and Michael Wooldridge. Learning to resolve social Kessinger,andJoshuaBPlotkin. Amechanisticmodelofgossip, reputations, and cooperation. Proceedings of the [Peleteiroetal.,2014] AnaPeleteiro,JuanC.Burguillo,and
NationalAcademyofSciences,121,2024. SiangYewChong. Exploringindirectreciprocityincom-
[Kessingeretal.,2023] Taylor A. Kessinger, Corina E. Tar- plex networks using coalitions and rewiring. In Proc. of
the2014InternationalConferenceonAutonomousAgents
nita,andJoshuaB.Plotkin. Evolutionofnormsforjudg-
andMulti-AgentSystems,AAMAS’14.IFAAMAS,2014.
ingsocialbehavior. Proc.oftheNationalAcademyofSci-
ences,120,June2023. [Pennisi,2005] ElizabethPennisi. Howdidcooperativebe-
[KrellnerandHan,2022] Marcus Krellner and The Anh haviorevolve? Science(NewYork,N.Y.),309,July2005.
Han. Pleasingenhancesindirectreciprocity-basedcooper- [RandandNowak,2013] David G. Rand and Martin A.
ationunderprivateassessment. ArtificialLife, 27, March Nowak. Human cooperation. Trends in Cognitive Sci-
2022. ences,17,2013.
[LupuandPrecup,2020] Andrei Lupu and Doina Precup. [Rosenblatetal.,2017] Alex Rosenblat, Karen E.C. Levy,
Giftinginmulti-agentreinforcementlearning. InProc.of Solon Barocas, and Tim Hwang. Discriminating tastes:
the 19th International Conference on autonomous agents Uber’scustomerratingsasvehiclesforworkplacediscrim-
andmultiagentsystems,2020. ination. Policy&Internet,9,2017.
[Mehrabietal.,2021] Ninareh Mehrabi, Fred Morstatter, [Sa´nchez,1968] David A. Sa´nchez. Ordinary Differential
Nripsuta Saxena, Kristina Lerman, and Aram Galstyan.
Equations and Stability Theory : An Introduction. New
A survey on bias and fairness in machine learning. ACM
York: Dover,1968.
ComputingSurveys,54,July2021.
[Santosetal.,2018] Fernando P. Santos, Jorge M. Pacheco,
[Moralesetal.,2013] Javier Morales, Maite Lopez-
andFranciscoC.Santos.Socialnormsofcooperationwith
Sanchez, Juan A. Rodriguez-Aguilar, Michael
costly reputation building. Proc. of the AAAI Conference
Wooldridge, and Wamberto Vasconcelos. Automated
onArtificialIntelligence,32,April2018.
synthesis of normative systems. In Proc. of the 2013
International Conference on Autonomous Agents and [Santosetal.,2019] Fernando P. Santos, Jorge M. Pacheco,
Multi-AgentSystems,May2013. AnaPaiva,andFranciscoC.Santos. Evolutionofcollec-
tive fairness in hybrid populations of humans and agents.
[NowakandSigmund,2005] Martin A. Nowak and Karl
InProc.oftheThirty-ThirdAAAIConferenceonArtificial
Sigmund. Evolution of indirect reciprocity. Nature, 437,
Intelligence,AAAI’19.AAAIPress,2019.
October2005.
[Santosetal.,2021] Fernando P. Santos, Jorge M. Pacheco,
[OhtsukiandIwasa,2004] Hisashi Ohtsuki and Yoh Iwasa.
and Francisco C. Santos. The complexity of human co-
Howshouldwedefinegoodness?—reputationdynamicsin
operationunderindirectreciprocity. PhilosophicalTrans-
indirect reciprocity. Journal of Theoretical Biology, 231,
actions of the Royal Society B: Biological Sciences, 376,
November2004.
2021.
[OhtsukiandIwasa,2006] Hisashi Ohtsuki and Yoh Iwasa.
[SavarimuthuandCranefield,2011] Bastin Tony Roy
Theleadingeight: Socialnormsthatcanmaintaincooper-
Savarimuthu and Stephen Cranefield. Norm creation,
ationbyindirectreciprocity. JournalofTheoreticalBiol-
spreadingandemergence: Asurveyofsimulationmodels
ogy,239,April2006.
of norms in multi-agent systems. Multiagent and Grid
[OhtsukiandIwasa,2007] Hisashi Ohtsuki and Yoh Iwasa.
Systems,7,January2011.
Globalanalysesofevolutionarydynamicsandexhaustive
[SenandAiriau,2007] Sandip Sen and Ste´phane Airiau.
searchforsocialnormsthatmaintaincooperationbyrep-
Emergence of norms through social learning. In Proc.
utation. Journal of Theoretical Biology, 244, February
ofthe20thInternationalJointConferenceonArtificalIn-
2007.
telligence, IJCAI’07. Morgan Kaufmann Publishers Inc.,
[Okada,2020] IsamuOkada. Areviewoftheoreticalstudies
2007.
onindirectreciprocity. Games,11,September2020.
[ShohamandTennenholtz,1997] Yoav Shoham and Moshe
[Pachecoetal.,2006] Jorge M. Pacheco, Francisco C. San-
Tennenholtz. On the emergence of social conventions:
tos,andFabioA.C.C.Chalub. Stern-judging: Asimple,
Modeling, analysis, and simulations. Artificial Intelli-
successful norm which promotes cooperation under indi-
gence,94,July1997.
rectreciprocity. PLoSComputationalBiology,2,Decem-
ber2006. [SmitandSantos,2024] JacobusSmitandFernandoP.San-
tos. Fairness and cooperation between independent rein-
[Paivaetal.,2018] AnaPaiva,FernandoP.Santos,andFran-
forcementlearnersthroughindirectreciprocity.InProc.of
cisco C. Santos. Engineering pro-sociality with au-
the23rdInternationalConferenceonAutonomousAgents
tonomous agents. Proc. of the AAAI Conference on Ar-
andMultiagentSystems,2024.
tificialIntelligence,32,April2018.
[SmithandPrice,1973] J. Maynard Smith and G. R. Price.
[PanchanathanandBoyd,2003] Karthik Panchanathan and
Thelogicofanimalconflict.Nature,246,November1973.
Robert Boyd. A tale of two defectors: The importance
ofstandingforevolutionofindirectreciprocity.Journalof [StewartandRaihani,2023] Alexander J. Stewart and
TheoreticalBiology,224,October2003. Nichola Raihani. Group reciprocity and the evolution ofstereotyping. Proc. of the Royal Society B: Biological
Sciences,290,2023.
[Villatoroetal.,2010] Daniel Villatoro, Sandip Sen, and
Jordi Sabater-Mir. Of social norms and sanctioning: A
gametheoreticaloverview. InternationalJournalofAgent
TechnologiesandSystems(IJATS),2,January2010.
[Vinitskyetal.,2023] Eugene Vinitsky, Raphael Ko¨ster,
John P Agapiou, Edgar A Due´n˜ez-Guzma´n, Alexander S
Vezhnevets, and Joel Z Leibo. A learning agent that ac-
quires social norms from public sanctions in decentral-
izedmulti-agentsettings. CollectiveIntelligence,2,April
2023.
[Xuetal.,2019] Jason Xu, Julian Garc´ıa, and Toby Hand-
field.Cooperationwithbottom-upreputationdynamics.In
Proc.ofthe18thInternationalConferenceonAutonomous
AgentsandMultiAgentSystems,AAMAS’19.IFAAMAS,
May2019.Learning Fair Cooperation in Mixed-Motive Games with Indirect Reciprocity
(Appendix)
MartinSmit, FernandoP.Santos
InformaticsInstitute,UniversityofAmsterdam
j.m.m.smit,f.p.santos @uva.nl
{ }
A DerivationofEvolutionaryStability In our paper, we assume that, when used as inputs, 0 means
“out-group”, “bad reputation”, and “defect”, while 1 means
In this section, we derive the expected value for the propor-
“in-group”,“goodreputation”,and“cooperate”.
tion of good individuals in each population given a specific
In other works a norm may have different inputs. For ex-
setup. Asagents’strategies(introducedformallybelow)take
amplein[OhtsukiandIwasa,2006],normsadditionallytake
theirinteractionpartner’sreputationintoaccount,theaverage
thedonor’sownreputationasaninput. Giventhatnormsin
“goodness”ofanindividualineithergroupisrequiredtocal-
our paper can treat in-group and out-group interactions en-
culate the likelihood that any agent cooperates or defects in
tirely differently, each norm can be uniquely described by
anarbitraryinteraction.
howittreatssuchinteractions,andsoinTable1ofourmain
With this expected cooperation level of each agent, we
text, we give examples of well-known norms that could be
canderivewhetheranyagentcouldunilaterallydeviatefrom
“combined”tojudgein-groupandout-groupinteractions.
theirstrategyandimprovetheirutilitythroughsomecombi-
Weadditionallyassumethatagentsmakeexecutionerrors
nationofcooperatinglessoftenandreceivingmoredonations
at a rate ϵ. These execution errors randomly prevent agents
throughimprovingtheirreputation. Aswemakethestandard
fromcooperatingwhentheyintendto. Inexpectation,wecan
evolutionarygametheory(EGT)assumptionthatbothgroups
represent these errors as functions E such that if x is the
ϵ
are infinitely large, any unilateral deviation won’t affect the
probabilityofanagenttocooperate:
otheragents’reputationsorutilities. Thismathematicalcon-
venience allows us to rapidly test every possible alternative E (x)=(1 ϵ)x. (3)
ϵ
−
strategyforagentsineithergroup.
Similarly,weassumethatnormsmakeassignmenterrorsat
Ifnoagentscanimprovetheirexpectedutilitythroughuni-
arateδ.Theseassignmenterrorsassigntheinversereputation
lateraldeviation,thenwesaythatthenormandcombination
thanwhatwasintended,andsoifyistheintendedreputation
of strategies found in each group is an evolutionarily stable
assignment,theactualoutcomeinexpectationwillbe
state(ESS).
E (y)=(1 ϵ)y+ϵ(1 y). (4)
δ
− −
A.1 DerivationofReputationDynamics
LetG = [G ,G ] [0,1]2 beavectorofthepropor-
t M m t
OurderivationfollowsthesetupandnotationofSection3.1, tionofgoodindividualsin∈ themajorityandminoritypopula-
in the main text where agents are stratified into two groups tionsat(continuous)timet. Weaimtoderive,andsolve,an
representing proportions p and 1 p respectively of the to- equationfor Gt.
− dt
tal well-mixed population, interacting through the donation Withinteractionsoccurringuniformlywithsomearbitrary
game. We assume that in each group, one strategy has en- ratesuchthat,oversometimeperiod[t,t+∆),aproportion∆
tirely proliferated the population i.e. every agent in a group ofallagentsinteractonceasadonorand1 ∆donotinteract
playsthesamestrategy. asadonoratall. Ofthisproportion∆,frac− tionpofthemwill
A strategy is a well-defined function from the space of be majority-group agents and 1 p will be minority-group
reputations (Good/Bad) and group relations (In/Out-group) agents. −
to actions (Cooperate/Defect). Given that these inputs and Let’stakethespecificexampleoftwomajorityplayersin-
outputs are all binary, the space of strategies Σ consists of teracting, where the recipient has a good reputation. Hence,
functionsσwith the input to the strategy σ would be [1,1]. Due to the well-
mixedassumption,thechanceofthisinteractionoccurringis
σ : {0,1 }2 →{0,1 } (1) p2 G M. Thedonor,comprisedofstrategyσandexecution
×
errorE withrateϵwouldtakeaction
Similarly,a“socialnorm”N (herebyjusta“norm”)isafunc- ϵ
tion from the space of reputations, group relations, and ac- x=(E σ)([1,1]) (5)
ϵ
tionstoreputations: ◦
(where denotesfunctioncomposition)whichwouldthenbe
N : 0,1 3 0,1 (2) judged◦ with norm N having assignment error E at rate δ
δ
{ } →{ }
4202
guA
8
]AM.sc[
1v94540.8042:viXraleadingtotheexpectednewreputationofthedonortobe: A.2 ProofofExistenceandUniqueness
y =(E N)([1,1,x]) (6) Giventhat(12)isa2 2matrixdifferentialequation,ithas
δ ◦ afixedpointG given× by
=(E N)([1,1,(E σ)([1,1])]) (7) ∗
δ ϵ
◦ ◦
Letσ andσ bethestrategiesthathaveproliferatedthe G ∗ = (A I) −1b (15)
M m − −
majority and minority populations respectively. Given that
aslongasA Iisinvertible.Moreover,thisfixedpointissta-
thestrategyσandnormN sharetwoinputs,namelytherep- −
bleifitseigenvalueshavenegativerealpart,whichisequiva-
utationoftherecipientandthegrouprelationoftheindivid-
lentinthe2 2casetotheconditionsthatA I hasnegative
uals,itisnotationallyconvenienttodefinethefunctionsJ
M trace and
po×
sitive determinant (see, for
exam−
ple, [Sa´nchez,
andJ mwhere 1968]).
J (a,b)=(E N)([a,b,(E σ )([a,b])]) (8) Firstly,weseethateachvalueonthediagonalofAisless
M δ
◦
ϵM
◦
M
than 1 and so the values on the diagonal of A I are both
J m(a,b)=(E δ ◦N)([a,b,(E ϵm ◦σ m)([a,b])]). (9) negative,hencethetraceisnegative. −
Note that the execution error rates can be different between Secondly,takingareal2 2matrixC oftheform
groups;wedonotassumethatϵ =ϵ . inourpreviousex- ×
M m
ampleoftwomajorityagentsmeetingandtherecipientbeing pa (1 p)b
C = − (16)
good,wecansimplycalculatethattheexpectedreputationof pc (1 p)d
(cid:20) − (cid:21)
thedonorisJ (1,1).
M
wherea,b,c,d [0,1],then
The above interaction is just one of many that may oc- ∈
cur. Tocalculatetheexpectedchangeinreputationofanin- det(C I)=(pa 1)((1 p)d 1) p(1 p)bc (17)
dividual from (for example) the majority group ∆G , we − − − − − −
M =(1 pa)(1 (1 p)d) p(1 p)bc (18)
sumtheexpectedreputationoutcomeofaspecificinteraction − − − − −
multiplied by the probability that this interaction will occur. whichisuniquelyminimisedto0whena=b=c=d=1:
Specifically,wesumovermeetingamemberoftheinorout
group,andwhetherthisagentisgoodorbad. det(C I)=(1 p)(1 (1 p)) p(1 p) (19)
− − − − − −
By enumerating all possible interactions as such, we can =(1 p)p p(1 p) (20)
derive the expected change ∆G in reputation in time ∆t − − −
M =0 (21)
asfollows. Forplayerswhodonotinteractasadonor, their
reputationisunchanged,andsovectorG t ofthemaregood. In this case, the original equation (15) using A instead of C
For those who do interact as a donor, they can interact with doesnothaveasolution. However,ifweassumethatagents
amajorityorminorityplayerwithproportionpor1 p,and alwayshaveanon-zeroprobabilitytomakeexecutionerrors,
−
this playerwill be good withproportion G M orG m respec- then the functions J M and J m cannot output the values of
tively. Following the same logic for the minority group, we 0 and 1. Hence, the values of a,b,c and d, which are com-
cancalculatetheexpectedreputationofamajorityorminor- prised of the outputs of these functions, are strictly between
itydonor. Thereforewecanwrite: 0and1. So,withthisassumption,canguaranteethatthedif-
ferentialequation(12)hasauniquefixedpointgivenby(15)
G (t+∆t)=(1 p∆t)G (t)
M − M (10) which is stable. This implies that the reputations of players
+p∆t(E[Reputationafterinteracting])
inanysystemwillreachauniqueequilibriuminvariantofthe
Then,byrearranging(10)toget initialconditions,forafixedcombinationofstrategiesinthe
population.
G (t+∆t) G (t), (11)
M M
−
ontheLHS,dividingby∆tandletting∆t 0,thendoing B StrategyDynamicsandEvolutionary
→
the same for G m, we can derive the corresponding system Stability
ofdifferentialequationsforG . Theformoftheseequations
t
allowsthesystemtobewrittenasthematrixequation: B.1 Payoffsofincumbents
Weassumetimescaleseparationbetweenthereputationsand
d G p 0 G strategicupdates. Thisassumptionmeansthatreputationsare
dt GM m = 0 (1 p) (A −I) GM m +b (12) fixed by the time strategies are updated, which allows us to
(cid:20) (cid:21) (cid:20) − (cid:21)(cid:18) (cid:20) (cid:21) (cid:19) calculate,givenastrategyhavingproliferatedeachgroup,the
whereI isthe2 2identitymatrixand likelihoodthatanyagentwillcooperate,theirutility,andulti-
×
matelywhetheranyagentcanimprovetheirutilitybychang-
A=
ingtheirstrategy.
p(J M(1,1) −J M(1,0)) (1 −p)(J M(0,1) −J M(0,0))
,
In the main text we introduce benefits b
i
and costs c
i
to
(cid:20)p(J m(0,1) −J m(0,0)) (1 −p)(J m(1,1) −J m(1,0))
(cid:21)
groupi ∈{1,2 }inordertodeterminetheexpectedutilityU
i
(13) ofeachgroupas
,
2
b= p pJ JM (( 00 ,, 00 )) ++ (( 11 − pp )) JJ M (( 11 ,, 00 )) . (14) U i = P(i ←i →nt. j) b iP(j −d −o →n. i) −c iP(i −d −o →n. j) (22)
(cid:20) m − m (cid:21) Xj=1 (cid:16) (cid:17)where int. means “interacts with” and don. means “donates Applying (22) using the mutant reputations leads to the
to”. ←→ −−→ payoffsU˜ formutantsineithergroupplayingstrategyσ in-
′
WhileP(i int. j)canbecalculatedsimplybymultiplying steadofσ M orσ m.
←→
together the proportions of the population that groups i and
B.3 EvolutionaryStability
don. don.
j represent, the values of P(j i) and P(i j) are
−−→ −−→ IfacombinationofnormN andstrategiesσ andσ can-
dependentonthe(stationary)reputationsofthegroups. M m
not be “invaded” by any mutant strategy σ Σ σ i.e.
Take P(j don. i) with i = 1 and j = 2 i.e. we want to no player in any group can unilaterally dev′ ia∈ te an\ d{ str} ictly
−−→
calculatetheprobabilitythataminorityagentwilldonateto improve their utility, then the triple (N,σ ,σ ) is an evo-
M m
amajorityagent. Usingourpreviousnotationfortheagent’s lutionarilystablestrategy(ESS).Technicallythisisaweaker
strategyσ m,executionerrorE ϵm,andthereputationsG ∗,we conditionthanthetraditionaldefinitionofanESS(forexam-
canwrite ple, theonefoundin[SmithandPrice, 1973]), whichstipu-
lates that equality is allowed unless mutants also do strictly
P(j don. i)=P(iisgood)P(j don. i iisgood) better amongst themselves than incumbents do against mu-
−−→ −−→ | tants. Wedonotconsiderthiscaseduetofloatingpointinac-
don.
+P(iisbad)P(j i iisbad) (23) curaciescausingequalitytobeunreliable.
−−→ |
=G (E σ )([0,1])
∗M ϵm
◦
m
C ReinforcementLearning
+(1 −G ∗M)[(E
ϵm
◦σ m)([0,0])]. (24)
In this section, we clarify a number of details regarding the
By performing such a calculation for every sum, we can
use (22) to derive U = [U ,U ] = [U ,U ], the average RLmodelandQ-learningalgorithmintroducedinSection3.2
1 2 M m
ofthemainpaper. Wealsopresentsomeadditionalresults
utility/payoffofanagentineachgroup.
Firstly,whileinmanypreviousnon-analyticalapproaches
B.2 Payoffsofmutantstrategies to indirect reciprocity such as [Pacheco et al., 2006] a large
Assume now that some agent in one of the groups changes number of interactions is done before any strategic updates
theirstrategyfromσtoσ .Asweassumethatpopulationsare takeplace, inourQ-learningapproachourversionofstrate-
′
infinitelylarge,theirsmallchangehasnobearingontheutil- gic updates, updating Q-values, happens after every single
ities of others, only themselves. By changing their strategy, interactionfortheagentsinvolved.
theywillnowhaveadifferentaveragereputationtotheother Secondly,reputationupdatesalsotakeplaceaftereachin-
membersoftheirgroup. Thisreputationcanbederivedsim- teraction, as in the EGT model. The fact that reputation
ilarly to that of the incumbents, but it is easier because G , updates and strategic updates happen at a similar timescale
∗
the reputations of the incumbents, is fixed due to timescale couldbeareasonforsomeofthediscrepanciesinresultsbe-
separationbetweenreputationalandstrategicupdates. tweentheRLandEGTmodels.
Letthecurrentreputationofamutantingroupiofsizep Thirdly, as in the EGT model, agents are sampled com-
i
be G˜ , such that G˜ = [G˜ ,G˜ ]. As before in 10, we can pletelyrandomlytointeractwitheachotherinawell-mixed
i M m
waywithnothoughtforwhohasorhasn’talreadyinteracted.
derivetheequation
Thismeansthat,eventhoughweuseapopulationof50,in50
G˜ i(t+∆t)=(1 p i∆t)G˜ i(t) (25) interactions it is exceedingly unlikely that all agents engage
−
+p i∆t(E[Reputationafterinteracting]) (26) exactlytwiceintheseinteractions,onceasadonorandonce
asarecipient.
Where,asbefore,wesplittheexpectationupintoeachgroup
In Figure C.1 we examine the policies learned by RL
andgood/badindividuals, thencalculatingtheexpectedrep-
agentsin50differentsimulations.AsindicatedinFigure5of
utationofinteractingwitheachofthesecombinations.
the main text, SternJudging is able to relatively consistently
Subtracting G˜ (t), dividing by ∆t and taking the limit of
i guideagentstowardsDiscorpDisc,whichbothleadtohigh
∆t 0, we have the following differential equation with a
→ levelsofcooperation.
similar,butsimplerformtobefore:
D DilemmasofVaryingDifficulty
d d G˜ G˜ G
dtG˜ t =
dt
(cid:20)G˜M m(cid:21)= (cid:20)G˜M m(cid:21)+ (cid:18)A˜ (cid:20)G∗M
∗m
(cid:21)+˜b
(cid:19)
(27) I on ft sh tae bm leai cn omte bx it n, aw tie op nr se ase nn dt FF ii gg uu rr ee 32 cc oo nn cc ee rr nn ii nn ggt eh ae chnu sm tab be ler
where, A and b are exactly as define before however the combination’s levels of cooperation and fairness. These fig-
functionsJ M andJ m arereplacedwithJ˜ M andJ˜ m respec- ures were generated using the parameters described in Sec-
tively where the only difference between the two is that the tion3.4.
incumbent strategy σ is replaced with the currently consid- Varyingtheseparameterswouldleadtomoreorlessdiffi-
eredmutantstrategyσ . NotethatA˜ismultipliedbyG and cultcooperationdilemmas,andwhendoingsowefoundthat
′ ∗
notG˜. the number of stable combinations can change. Figure D.1
Setting dG˜ = 0,thesolutionto(27)cansimplyberead showsthatasdifficultyincreases(i.e.,thecooperationbenefit
dt t
offas decreasesanderrorratesincreaseinthemajoritygroup),the
G number of stable combinations changes. Additionally, these
G˜ ∗ = − A˜ G∗M ∗m +˜b . (28) changesexhibit“phasetransitions”i.e. changingparameters
(cid:18) (cid:20) (cid:21) (cid:19)Stern
12.5
Judging
Majority Minority
50
400
40 0.854 10.0
30 0.85
20 0.836
7.5 350
10 0.093
5.0
300
Final policy Final policy
Stern/
Stand 2.5
Majority Minority
50
40 0.841 0.1 0.2 0.3 0.4 0.5
Majority error rate
30 0.698
20 0.691 FigureD.1: Asthemajoritygroup’sbenefitfromreceivingadona-
tion and error rate is changed, the number of stable combinations
10 0.094
exhibitsphasetransitionswhereanumberofcombinationsbecome
stableorlosestability.Atthebottomoftheplot,weseecooperation
dilemmaswhicharesodifficultthattheonlystablecombinationsare
Final policy Final policy thosewherenoonecooperates.
0.0 0.5 1.0
Strategy prevalencewithin population phase diagram, for no norms-strategy-strategy combinations
will another strategy invade. This implies that the current
strategyisstilloptimal,andsoagentswillactinthesameway
Figure C.1: A horizontal slice of this figure indicates the preva-
lence of each strategy in each group, and the resulting coopera- in the same circumstances. However, these circumstances
tiveness, in a particular RL simulation, for a particular norm. We (i.e. theprevalenceofeachgroupinthepopulation, andthe
sayanRLagent“plays”acertainstrategybytakingthehighestQ- prevalenceofgoodindividualsineachgroup)alsoremainun-
valueforeachaction. Theslicesarepresentedinincreasinglevels changed precisely because the strategies remain unchanged.
of cooperation, which is found as a colourbar to the right of each Given a fixed norm, reputations are determined by actions,
pair of heatmaps. While SternJudging semi-consistently leads to whicharedeterminedbystrategies. Hence, reputations, and
high cooperation, reflected in main text Figure 6, Stern/Stand (in-
therefore the probability of each individual to cooperate, re-
groupSternJudging,out-groupSimpleStanding)hasthree“regimes”
mainsunchangedwhenthebenefit/costratiochangeswithin
that appear to occur roughly equally often. The x-axis only con-
theboundariesofthephasediagram.
tains labels for strategies passing a threshold of frequency (25%).
Ascooperativenessisdefinedinourpaperas“thepropor-
Numbered/unnamedstrategiesare2(cooperatewithbad-ingroup),
8 (cooperate with good-ingroup), 10 (cooperate with all ingroup), tion of interactions that result in cooperation”, this remains
13(don’tcooperateonlywithbad-ingroup),and14(don’tcooperate unchanged when the benefit/cost ratio is changed. Fairness,
onlywithbad-outgroup). ontheotherhand, isdefinedastheratioofpayoffsbetween
thebest-offandworst-offgroup. Giventhattherateofcoop-
erationineachgroupisunchanged,ifonegrouphad,forex-
hasnoeffectuntilacertainthresholdisreached,afterwhich ample,ahighchancetoreceivecooperationandalowchance
thestabilityofalargesetofstrategiesisaffected. Ourstan- to cooperate, their payoff would be relatively much less im-
dardparametersetupfromSection3.4isfoundinthelargest pacted than a group that had the same chance to receive co-
area,whichitselfissurprisinglyresilient,rangingalltheway operationbutahigherchancetocooperate. Hence,underour
fromabenefit-to-costratioof1.2to10,andanerrorratefrom definitionoffairness,fairnesscanchangeevenwhenratesof
(almost)0to0.43. cooperationstaythesame.
In the analytical results of the main manuscript, we used
a benefit/cost ratio of 5. If we change this to 1.25, almost E EffectofGroupSizes
withinthe“nonontrivialstablecombinations”regionofFig- Wechosetofocusonthecasewherethemajoritygroupcom-
ure D.1, we see in Figure D.2 that the levels of cooperation prised90%ofthepopulation.Withthisdecision,themajority
areunchanged,andthelevelsoffairnessgoeitherupordown agents would interact amongst themselves 90% of the time,
depending on the norm. Some norms are unaffected at all, andminorityamongstthemselvesonly10%ofthetime.
thesearethosethathaveeither0or1fairness. In IR, agents have two, sometimes competing goals: sus-
These findings are a consequence of our choice of met- taining reputation and maximising utility. For successful
rictomeasurecooperationandfairness. Bydefinition,when norms like SternJudging, the threat of unjustified defection
lowering the benefit/cost ratio within the boundaries of the is strong as agents can maintain their reputation by defect-
nuR
nuR
DllA
DllA 2
csiDp csiD
csiD 31
DllA
DllA
2
2
csiDp 8
8 01
csiD
csiD 31 41
nur
ni noitarepooc
egarevA
nur
ni
noitarepooc
egarevA
tifeneb
ytirojaM
snoitanibmoc
elbats
fo
rebmuNguage[Bezansonetal.,2012]withfiguresinMakie[Danisch
1.00
andKrumbiegel,2021].
References
0.75
[Anastassacosetal.,2021] Nicolas Anastassacos, Julian
Garc´ıa,StephenHailes,andMircoMusolesi. Cooperation
and reputation dynamics with reinforcement learning. In
0.50
Proc.ofthe20thInternationalConferenceonAutonomous
Agents and MultiAgent Systems. IFAAMAS, February
2021.
0.25
[Anavankotetal.,2023] Amritha Menon Anavankot,
Stephen Cranefield, and Bastin Tony Roy Savarimuthu.
Towards norm entrepreneurship in agent societies. In
0.00
AdvancesinPracticalApplicationsofAgents,Multi-Agent
0.00 0.25 0.50 0.75 1.00
Cooperativeness Systems,andCognitiveMimetics.ThePAAMSCollection,
Lecture Notes in Computer Science. Springer Nature
Whose strategy? What kind of strategy? What kind of norm?
Switzerland,2023.
Always defect
Majority strategy Group-agnostic Unfair [Baraetal.,2023] Jacques Bara, Fernando P. Santos, and
Minority strategy Fair
Discriminatory PaoloTurrini. Theroleofspace,densityandmigrationin
socialdilemmas. InProc.ofthe2023InternationalCon-
ference on Autonomous Agents and Multiagent Systems,
FigureD.2:Themarkersareplottedwhereb/c=5,andthearrows
AAMAS’23.IFAAMAS,May2023.
pointtowhereb/c = 1.25. Thisisstillinsidethesameregionof
thephasediagram,soallofthepointsarestillstable,butthelevelof [Bezansonetal.,2012] JeffBezanson,StefanKarpinski,Vi-
fairnessisdrasticallydifferentforanumberofnormswhichfeature ral B. Shah, and Alan Edelman. Julia: A fast dynamic
non-zerobetween-groupcooperationyetlackperfectfairness. languagefortechnicalcomputing. arXiv:1209.5145[cs],
September2012.
ing against you. The less successful norm Shunning suffers [Chierichettietal.,2017] Flavio Chierichetti, Ravi Kumar,
from impossibly high standards: any interaction with a bad Silvio Lattanzi, and Sergei Vassilvitskii. Fair clustering
individualleadstoabadreputation. throughfairlets. AdvancesinNeuralInformationProcess-
In our two group setting, norms that distinguish in- and ingSystems,NeurIPS’17,30,2017.
out-group interactions offer agents the opportunity to build [ClausandBoutilier,1998] Caroline Claus and Craig
up their reputation under a different norm, or to take ad- Boutilier. The dynamics of reinforcement learning in
vantage of a more lenient norm to raise their utility. Con- cooperative multiagent systems. In Proc. of the Fifteenth
sidernormswhereonepart,eitherin-orout-group,isShun- NationalConferenceonArtificialIntelligence,AAAI’98.
ning. Figure 4 in the main text shows us that, when paired AAAIPress,1998.
with another norm, the cooperation level increases hugely
[ConitzerandOesterheld,2023] Vincent Conitzer and Cas-
compared to when it is paired with itself. Furthermore, this
par Oesterheld. Foundations of cooperative ai. Proc. of
changeisnotbecauseitspairednormismoresuccessfulthan
the AAAI Conference on Artificial Intelligence, 37, June
ShunningatsustainingcooperationasthisapplieseventoIn-
2023.
Shunning/Out-ImageScoring.
[Dafoeetal.,2021] Allan Dafoe, Yoram Bachrach, Gillian
While the balance between reputation and utility is more
Hadfield, Eric Horvitz, Kate Larson, and Thore Grae-
complexinasettingwithgrouprelationdependentnorms,in
pel. Cooperativeai: Machinesmustlearntofindcommon
Figure E.1 we vary the group size of the majority between
ground. Nature,593,May2021.
52%, a very slight majority, and the value of 90% used in
our paper. Notably, no fair norms that are stable at 52% are [DanischandKrumbiegel,2021] Simon Danisch and Julius
unstable at 90%, and we observe the same for NSS combi- Krumbiegel. Makie.jl: Flexiblehigh-performancedatavi-
nationswheretheminoritygroupplaysAllD.Thishighlights sualization for Julia. Journal of Open Source Software,
thedifficultyofthescenariostudiedinourarticleandtheim- 6(65):3349,September2021.
portanceofconsideringgroupsizeasakeypartofmodelling [Deetal.,2017] Soham De, Dana S Nau, and Michele J
infuturework. Gelfand. Understanding norm change: An evolutionary
game-theoreticapproach. InProc.ofthe16thConference
F Availabilityofcode on Autonomous Agents and Multiagent Systems, AAMAS
2017,2017.
The code to produce all figures, tables, and values found in
thepaperandappendixisavailableunderanMITlicenseon [Edelmanetal.,2017] Benjamin Edelman, Michael Luca,
GitHub1. The code is written in the Julia programming lan- and Dan Svirsky. Racial discrimination in the sharing
economy: Evidence from a field experiment. American
1Linktorepository:github.com/sias-uva/indirect-reciprocity EconomicJournal: AppliedEconomics,9,April2017.
ssenriaFIN ON MIS MOS mIS mOS Cooperation(EGT) Cooperation(RL) Fairness(EGT) Fairness(RL)
Sh Sh Disc Disc Disc Disc 0.332 0.118 1.0 0.917
Sh SJ Disc Disc Disc Disc 0.849 0.532 0.848 0.609
Sh IS AllC Disc AllD AllD 0.766 0.456 0.748 0.502
Sh SS Disc Disc Disc Disc 0.849 0.48 0.848 0.596
SJ Sh Disc Disc Disc Disc 0.965 0.718 0.981 0.727
SJ SJ Disc Disc Disc Disc 0.971 0.652 1.0 0.909
SJ IS AllC Disc AllD AllD 0.875 0.599 0.871 0.541
SJ SS Disc Disc Disc Disc 0.971 0.61 1.0 0.541
IS Sh AllD AllD AllD AllD 0.0 0.106 1.0 0.727
IS SJ AllD AllD AllD AllD 0.0 0.0948 1.0 0.74
IS IS AllD AllD AllD AllD 0.0 0.0996 1.0 0.712
IS SS AllD AllD AllD AllD 0.0 0.0929 1.0 0.737
SS Sh Disc Disc Disc Disc 0.965 0.161 0.981 0.756
SS SJ Disc Disc Disc Disc 0.971 0.132 1.0 0.747
SS IS AllC Disc AllD AllD 0.875 0.108 0.871 0.741
SS SS Disc Disc Disc Disc 0.971 0.0904 1.0 0.741
Table1: Wemakethefollowingabbreviations: N=norm, S=strategy, I/O=in-group/out-group, M/m=Majority/minority, EGT=The
resultscamefromtheanalyticalevolutionarygametheorymodel,RL=TheresultscamefromrunningtheRLmodel50timesandtakingthe
average. Thestrategycolumnsaretheoptimalsetofstrategies(intermsofhighestcooperation)fromtheEGTmodelgivenanin-groupand
out-groupnorm.Parametersused:b/c=10,errorrate=0.01
[Fatimaetal.,2024] ShaheenFatima,NicholasR.Jennings, Indirectreciprocitywithprivate,noisy,andincompletein-
and Michael Wooldridge. Learning to resolve social formation. Proc. of the National Academy of Sciences,
dilemmas: Asurvey. JournalofArtificialIntelligenceRe- 115,November2018.
search,79,March2024.
[HuandLeung,2017] ShuyueHuandHo-FungLeung. Lo-
[FehrandFischbacher,2003] Ernst Fehr and Urs Fis- cal norm phenomena in multi-agent systems under com-
chbacher. The nature of human altruism. Nature, 425, munity networks. In Proc. of the 16th Conference on
October2003. AutonomousAgentsandMultiagentSystems, AAMAS’17,
[Fuetal.,2012] Feng Fu, Martin A. Nowak, Nicholas A. 2017.
Christakis, and James H. Fowler. The evolution of ho- [Hughesetal.,2018] Edward Hughes, Joel Z Leibo,
mophily. ScientificReports,2,November2012. Matthew Phillips, Karl Tuyls, Edgar Duen˜ez-Guzman,
[Geneserethetal.,1986] Michael R. Genesereth, AntonioGarc´ıaCastan˜eda,IainDunning,TinaZhu,Kevin
Matthew L. Ginsberg, and Jeffrey S. Rosenschein. McKee,RaphaelKoster,HeatherRoff,andThoreGraepel.
Cooperation without communication. In Proc. of the Inequity aversion improves cooperation in intertemporal
FifthAAAINationalConferenceonArtificialIntelligence, social dilemmas. In Advances in Neural Information
AAAI’86.AAAIPress,1986. Processing Systems, volume 31. Curran Associates, Inc.,
2018.
[Griffith,2010] MeghanGriffith. Whyagent-causedactions
are not lucky. American Philosophical Quarterly, 47, [Jaquesetal.,2019] Natasha Jaques, Angeliki Lazari-
2010. dou, Edward Hughes, Caglar Gulcehre, Pedro Ortega,
Dj Strouse, Joel Z. Leibo, and Nando De Freitas. Social
[GrossandDeDreu,2019] Jo¨rg Gross and Carsten K. W.
influence as intrinsic motivation for multi-agent deep
De Dreu. The rise and fall of cooperation through rep-
reinforcementlearning. InProc.ofthe36thInternational
utation and group polarization. Nature Communications,
ConferenceonMachineLearning.PMLR,May2019.
10,February2019.
[Guoetal.,2023] Hao Guo, Chen Shen, Shuyue Hu, Jun- [Kawakatsuetal.,2024] Mari Kawakatsu, Taylor A
liangXing, PinTao, YuanchunShi, andZhenWang. Fa- Kessinger,andJoshuaBPlotkin. Amechanisticmodelof
cilitating cooperation in human-agent hybrid populations gossip, reputations, and cooperation. Proceedings of the
throughautonomousagents. iScience,26,2023. NationalAcademyofSciences,121,2024.
[Haynesetal.,2017] Chris Haynes, Michael Luck, Peter [Kessingeretal.,2023] Taylor A. Kessinger, Corina E. Tar-
McBurney, Samhar Mahmoud, Toma´sˇ V´ıtek, and Simon nita,andJoshuaB.Plotkin. Evolutionofnormsforjudg-
Miles. Engineering the emergence of norms: A review. ingsocialbehavior. Proc.oftheNationalAcademyofSci-
TheKnowledgeEngineeringReview,32,January2017. ences,120,June2023.
[Hilbeetal.,2018] Christian Hilbe, Laura Schmid, Josef [KrellnerandHan,2022] Marcus Krellner and The Anh
Tkadlec, Krishnendu Chatterjee, and Martin A. Nowak. Han. Pleasingenhancesindirectreciprocity-basedcooper-ationunderprivateassessment. ArtificialLife, 27, March [RandandNowak,2013] David G. Rand and Martin A.
2022. Nowak. Human cooperation. Trends in Cognitive Sci-
ences,17,2013.
[LupuandPrecup,2020] Andrei Lupu and Doina Precup.
Giftinginmulti-agentreinforcementlearning. InProc.of [Rosenblatetal.,2017] Alex Rosenblat, Karen E.C. Levy,
the 19th International Conference on autonomous agents Solon Barocas, and Tim Hwang. Discriminating tastes:
andmultiagentsystems,2020. Uber’scustomerratingsasvehiclesforworkplacediscrim-
ination. Policy&Internet,9,2017.
[Mehrabietal.,2021] Ninareh Mehrabi, Fred Morstatter,
Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. [Sa´nchez,1968] David A. Sa´nchez. Ordinary Differential
A survey on bias and fairness in machine learning. ACM Equations and Stability Theory : An Introduction. New
ComputingSurveys,54,July2021. York: Dover,1968.
[Moralesetal.,2013] Javier Morales, Maite Lopez- [Santosetal.,2018] Fernando P. Santos, Jorge M. Pacheco,
Sanchez, Juan A. Rodriguez-Aguilar, Michael andFranciscoC.Santos.Socialnormsofcooperationwith
Wooldridge, and Wamberto Vasconcelos. Automated costly reputation building. Proc. of the AAAI Conference
synthesis of normative systems. In Proc. of the 2013 onArtificialIntelligence,32,April2018.
International Conference on Autonomous Agents and [Santosetal.,2019] Fernando P. Santos, Jorge M. Pacheco,
Multi-AgentSystems,May2013. AnaPaiva,andFranciscoC.Santos. Evolutionofcollec-
[NowakandSigmund,2005] Martin A. Nowak and Karl tive fairness in hybrid populations of humans and agents.
InProc.oftheThirty-ThirdAAAIConferenceonArtificial
Sigmund. Evolution of indirect reciprocity. Nature, 437,
Intelligence,AAAI’19.AAAIPress,2019.
October2005.
[Santosetal.,2021] Fernando P. Santos, Jorge M. Pacheco,
[OhtsukiandIwasa,2004] Hisashi Ohtsuki and Yoh Iwasa.
and Francisco C. Santos. The complexity of human co-
Howshouldwedefinegoodness?—reputationdynamicsin
operationunderindirectreciprocity. PhilosophicalTrans-
indirect reciprocity. Journal of Theoretical Biology, 231,
actions of the Royal Society B: Biological Sciences, 376,
November2004.
2021.
[OhtsukiandIwasa,2006] Hisashi Ohtsuki and Yoh Iwasa.
[SavarimuthuandCranefield,2011] Bastin Tony Roy
Theleadingeight: Socialnormsthatcanmaintaincooper-
Savarimuthu and Stephen Cranefield. Norm creation,
ationbyindirectreciprocity. JournalofTheoreticalBiol-
spreadingandemergence: Asurveyofsimulationmodels
ogy,239,April2006.
of norms in multi-agent systems. Multiagent and Grid
[OhtsukiandIwasa,2007] Hisashi Ohtsuki and Yoh Iwasa. Systems,7,January2011.
Globalanalysesofevolutionarydynamicsandexhaustive
[SenandAiriau,2007] Sandip Sen and Ste´phane Airiau.
searchforsocialnormsthatmaintaincooperationbyrep-
Emergence of norms through social learning. In Proc.
utation. Journal of Theoretical Biology, 244, February
ofthe20thInternationalJointConferenceonArtificalIn-
2007.
telligence, IJCAI’07. Morgan Kaufmann Publishers Inc.,
[Okada,2020] IsamuOkada. Areviewoftheoreticalstudies 2007.
onindirectreciprocity. Games,11,September2020.
[ShohamandTennenholtz,1997] Yoav Shoham and Moshe
[Pachecoetal.,2006] Jorge M. Pacheco, Francisco C. San- Tennenholtz. On the emergence of social conventions:
tos,andFabioA.C.C.Chalub. Stern-judging: Asimple, Modeling, analysis, and simulations. Artificial Intelli-
successful norm which promotes cooperation under indi- gence,94,July1997.
rectreciprocity. PLoSComputationalBiology,2,Decem- [SmitandSantos,2024] JacobusSmitandFernandoP.San-
ber2006.
tos. Fairness and cooperation between independent rein-
[Paivaetal.,2018] AnaPaiva,FernandoP.Santos,andFran- forcementlearnersthroughindirectreciprocity.InProc.of
cisco C. Santos. Engineering pro-sociality with au- the23rdInternationalConferenceonAutonomousAgents
tonomous agents. Proc. of the AAAI Conference on Ar- andMultiagentSystems,2024.
tificialIntelligence,32,April2018. [SmithandPrice,1973] J. Maynard Smith and G. R. Price.
[PanchanathanandBoyd,2003] Karthik Panchanathan and Thelogicofanimalconflict.Nature,246,November1973.
Robert Boyd. A tale of two defectors: The importance [StewartandRaihani,2023] Alexander J. Stewart and
ofstandingforevolutionofindirectreciprocity.Journalof Nichola Raihani. Group reciprocity and the evolution of
TheoreticalBiology,224,October2003. stereotyping. Proc. of the Royal Society B: Biological
[Peleteiroetal.,2014] AnaPeleteiro,JuanC.Burguillo,and Sciences,290,2023.
SiangYewChong. Exploringindirectreciprocityincom- [Villatoroetal.,2010] Daniel Villatoro, Sandip Sen, and
plex networks using coalitions and rewiring. In Proc. of Jordi Sabater-Mir. Of social norms and sanctioning: A
the2014InternationalConferenceonAutonomousAgents gametheoreticaloverview. InternationalJournalofAgent
andMulti-AgentSystems,AAMAS’14.IFAAMAS,2014. TechnologiesandSystems(IJATS),2,January2010.
[Pennisi,2005] ElizabethPennisi. Howdidcooperativebe- [Vinitskyetal.,2023] Eugene Vinitsky, Raphael Ko¨ster,
haviorevolve? Science(NewYork,N.Y.),309,July2005. John P Agapiou, Edgar A Due´n˜ez-Guzma´n, Alexander SVezhnevets, and Joel Z Leibo. A learning agent that ac-
quires social norms from public sanctions in decentral-
izedmulti-agentsettings. CollectiveIntelligence,2,April
2023.
[Xuetal.,2019] Jason Xu, Julian Garc´ıa, and Toby Hand-
field.Cooperationwithbottom-upreputationdynamics.In
Proc.ofthe18thInternationalConferenceonAutonomous
AgentsandMultiAgentSystems,AAMAS’19.IFAAMAS, 1.00
May2019.
0.75
A
0.50
0.25
0.00
0.00 0.25 0.50 0.75 1.00
Cooperativeness
1.00
0.75
B
0.50
0.25
0.00
0.00 0.25 0.50 0.75 1.00
Cooperativeness
Whose strategy? What kind of strategy? What kind of norm?
Always defect
Majority strategy Unfair
Group-agnostic
Minority strategy Fair
Discriminatory
FigureE.1: Byexaminingthecooperationandfairnessofdifferent
NSS combinations as the group size is varied, we notice a highly
heterogeneous set of “trajectories”. The group size varies from a
slightmajority52%,toalargemajority90%. Thelargestmajority
for which the NSS combination is stable is marked with a shape,
eitheracircleorsquarerepresentinganunfairorfairnormrespec-
tively.TheupperplotlabelledAcontainsallNSScombinationsthat
are stable at 90% majority size, as found in Figure 3 of the main
text.Onthecontrary,Bcontainsallcombinationsthatwerenotsta-
blewhenthemajoritycomprised90%.
ssenriaF
ssenriaF