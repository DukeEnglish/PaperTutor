Cross-Domain Learning for Video Anomaly Detection with Limited Supervision
YashikaJain AliDabouei* MinXu*
UniversityofDelhi CarnegieMellonUniversity CarnegieMellonUniversity
yashikajain201@gmail.com ali.dabouei@gmail.com mxu1@cs.cmu.edu
Abstract
Video Anomaly Detection (VAD) automates the identifi-
cationofunusualevents,suchassecuritythreatsinsurveil-
lancevideos. Inreal-worldapplications,VADmodelsmust
effectivelyoperateincross-domainsettings,identifyingrare
anomaliesandscenariosnotwell-representedinthetrain-
Figure1. AnomalyscorecomparisononavideoofXD-Violence
ingdata. However,existingcross-domainVADmethodsfo- dataset, with and without employing the proposed CDL frame-
cusonunsupervisedlearning,resultinginperformancethat work. The model trained without CDL on UCF-Crime as the
fallsshortofreal-worldexpectations.Sinceacquiringweak weakly labeled set consistently yields high anomaly scores. In
supervision, i.e., video-level labels, for the source domain contrast, the model trained with CDL, using UCF-Crime as the
iscost-effective,weconjecturethatcombiningitwithexter- weaklylabeledsetandHACSastheunlabeledset,isbetterableto
nalunlabeleddatahasnotablepotentialtoenhancecross- localizetheanomalousframes.
domain performance. To this end, we introduce a novel
weakly-supervised framework for Cross-Domain Learning
withobtainingframe-levellabels, mostapproachesformu-
(CDL)inVADthatincorporatesexternaldataduringtrain-
late the problem as either an unsupervised [10, 15, 21] or
ing by estimating its prediction bias and adaptively mini-
weakly-supervisedlearningsetup[11,32,33]. Intheunsu-
mizingthatusingthepredicteduncertainty.Wedemonstrate
pervised or one-class classification-based) learning setup,
the effectiveness of the proposed CDL framework through
only normal videos are used to model the underlying dis-
comprehensive experiments conducted in various configu-
tributionofnormalspatiotemporalpatterns,andanydevia-
rationsontwolarge-scaleVADdatasets: UCF-Crimeand
tionsfromthemodeleddistributionareregardedasanoma-
XD-Violence. Ourmethodsignificantlysurpassesthestate-
lies. Despitetheconvenienceoftheunsupervisedsetup,the
of-the-artworksincross-domainevaluations,achievingan
lackofanomalousvideosduringtraininglimitsthemodel’s
average absolute improvement of 19.6% on UCF-Crime
ability to learn the specific characteristics of anomalies.
and12.87%onXD-Violence.
This results in limited performance which does not meet
real-world expectations. To address this issue, weakly-
supervised setup has attracted significant attention. In this
1.Introduction
setup, merely video-level labels indicating the presence of
Video anomaly detection (VAD) aims to locate anomalous anomalies within the videos are incorporated as weak su-
events inthe videos [3,10, 11, 15,21, 25, 32,33, 42, 47]. pervision to train models capable of making frame-level
Unlike manual surveillance, which is costly and time- predictionsatinference. MultipleInstanceLearning(MIL)
consuming, video anomaly detection eliminates the need [32] is a prominent technique in this domain. By treating
for extensive human effort, saving resources and time. It each video as a “bag” and each snippet as a “segment”,
holds significant potential for playing a vital role in video MIL-basedalgorithmsoperateunderthepremiseofaworst-
surveillancebyidentifyingunusualbehaviorsandactivities casescenariowherethesegmentwiththehighestpredicted
such as accidents, burglaries, explosions, and other events probabilityofbeingabnormalisconsideredasthecandidate
thatsignalsecuritythreats. torepresentthewholevideo.
VADhasbeenextensivelystudiedpreviously[11,15,21, In real-world applications, it is inevitable to encounter
32, 33, 47]. Owing to the high costs and time associated environments and scenarios not fully represented in the
model’strainingset. However,itisessentialthatthemodel
*Correspondingauthors. makes correctpredictions in suchnovel situations. For in-
4202
guA
9
]VC.sc[
1v19150.8042:viXrastance,whenthetrainingdatalackssamplesofrareevents Method(s) Sup.onD Target
like “riots” or accidents in novel scenes, the model should
Acsintoaeetal.[1] unsupervised D
beabletocharacterizesuchoccurrencesasanomalouswhen
rGAN[23],MPN[25] unsupervised D′
theyoccur. Previousworksstudythesenovelsituationsun- zxVAD[3] unsupervised D∪D′
derthecross-domainproblemdefinition[3,13,23]. Ours weakly-supervised D∪D′
Existingcross-domainVADmethods[3,13,23,25]rely
on unsupervised techniques and consequently exhibit lim- Table1.BriefoverviewofthetaxonomyofcurrentworksforVAD
ited performance, as demonstrated later in our empirical usingasourcedomaindataset(D)andasecondarydomaindataset
evaluations in Tables 2 and 3. A solution to this could (D′). Allthesemethodsdonotutilizeanylabelsfortrainingon
betheadoptionofweakly-supervisedtechniquesforcross-
(D′)andassumedistinctdistributionsforDandD′.
domain VAD. While weakly-supervised approaches have
proven promising in single-domain scenarios [11, 32, 33],
dictions for the external dataset. Second, we compute the
their effectiveness in cross-domain scenarios has not been
variance of the predictions across multiple predictors as a
extensively explored. Our evaluations in Tables 2 and 3
proxytorepresentuncertaintyassociatedwiththesegments
suggestthatdirectlyemployingexistingweakly-supervised
intheexternaldata. Third,duringtheoptimizationprocess,
methods to address the cross-domain challenges results in
involving training on both labeled and external data, we
asignificantperformancedropwhentestedinscenariosof
adaptivelyreweighthebiasoneachexternaldatausingthe
evensimilarnature,suchassurveillancevideos. Weargue
uncertainty regularization scores. This dynamic reweigh-
that this performance gap is due to the following reasons.
ingensuresthatsegmentsfromtheexternaldatasetcloserto
First, anomalous events, by their very nature, lack a spe-
thesourcedatasetareemphasizedduringthetraining,while
cificpatternorpredefinedstructure.Hence,thedefinitionof
those with higher uncertainty are down-weighted. Finally,
anomalyiscontext-dependentandanaiveadaptationofthe
we iteratively regenerate pseudo-labels using the models
previous method cannot capture the context-dependencies
trainedonlabeledandpseudo-labeleddata,re-estimatethe
in multiple domains. Second, anomalous events are rela-
uncertainties,andre-trainthemodelontheunionoflabeled
tivelyinfrequent,makingVADaclassimbalanceproblem.
andexternaldatasets. Thisiterativeprocesshelpsrefinethe
Thisissuebecomesmoreseverewhendealingwithmultiple
pseudo-labels as the training progresses. With this train-
domains. Third, because of the limited amount of weakly
ing process, the model learns to generalize to both source
labeledtrainingdata,themodel’slearningcapacitytodetect
andexternaldata,givenonlysupervisiononthesourcedata.
novel(open-set)anomaliesisalsoconstrained.Duetothese
Figure1illustratestheeffectivenessoftheCDLframework.
challenges, weakly-supervised methods cannot be readily
Tosummarize,wemakethefollowingcontributions:
appliedtocross-domainorcross-datasetscenarios.
• We present a practical CDL framework for weakly-
Toovercomethesechallengesanddevelopageneralized
supervised VAD, in which unlabeled external videos are
VADmodel,substantialamountsofweakly-labeleddataare
employedtoenhancethecross-domaingeneralizationof
required. However, acquiring even video-level labels for
themodel.
a large number of videos is inefficient and labor-intensive.
• Wedesignanoveluncertaintyquantificationmethodthat
On the other hand, vast streams of unlabeled videos are
enablestheadaptiveuncertainty-drivenintegrationofex-
generally available. Utilizing the limited weakly-labeled
ternalvideosintothetrainingset.
dataalongsidethisabundantunlabeleddataprovidesano-
• Through extensive experiments and ablation studies
tableopportunitytoaddresstheaforementionedchallenges
on benchmark datasets, we validate the proposed ap-
in cross-domain VAD. Prudent utilization of the unlabeled
proach, demonstrating state-of-the-art performance in
datacanprovidevaluableinsightsintotheunderlyingdata
cross-domain settings while retaining a competitive per-
distribution,leadingtoimproveddecision-makingandiden-
formanceonthein-domaindata.
tificationofanomalousevents.
To this end, we propose a weakly-supervised Cross-
2.RelatedWorks
Domain Learning (CDL) framework for VAD that inte-
grates external, unlabeled data, from the wild with limited Video Anomaly Detection (VAD). Video Anomaly De-
weakly-labeled data to provide competitive generalization tection (VAD). VAD is a well-established problem, with
across the domains. This is achieved by adaptively mini- most works formulating it either as unsupervised learn-
mizing the prediction bias over the external data using the ing [15, 21, 22, 41, 44] or weakly-supervised learning
estimated prediction variance, which serves as an uncer- [29, 32, 33, 43, 48] problem. In unsupervised setups, the
taintyregularizationscore. Intheproposedframework,we training data consists solely of normal videos, with the
first train fine-grained pseudo-label generation models on majority of works encoding normal patterns through tech-
theweakly-labeleddatatoobtainsetsofsegment-levelpre- niqueslikeframereconstruction[15,39],futureframepre-diction [21], dictionary learning [22, 44], and one-class ferent predictions, but that is inefficient for training with
classification[17,24].Anydeviationfromtheencodedpat- fixedbackbones. Incontrast,modelaugmentationusesdif-
ternsisconsideredanomalous. Sincethemodelcategorizes ferentmodels. Sincedifferentmodelsmayhavevaryingbi-
anything beyond its learned representations as anomalous, asesandreceptivefields,thiswouldresultindiversepredic-
it can label novel video actions and scenarios encountered tions. Thispredictiondiscrepancycanhelpquantifyuncer-
during training but in altered environments as anomalous. tainty, making model augmentation well-aligned with our
Weakly-supervised VAD methods help mitigate these is- problem. To avoid any manual thresholding for learning
sues by incorporating video-level labels as weak supervi- from pseudo-labels during training, following [16, 46] we
sion for the model, with the majority of methods utilizing useadaptivereweighingoflosswithuncertaintyvalues. In
theMultipleInstanceRankingLoss[11,32,35,47]. Given [46], Zheng et al. quantify uncertainty by estimating dis-
that a VAD model is expected to encounter previously un- crepanciesbetweenpredictionsmadebytwoclassifiersus-
seen scenarios during deployment, it is of paramount im- ingKullback–Leibler(KL)divergence.However,giventhat
portanceforthemodeltohaveahighgeneralizationacross VADisabinaryclassificationtask,thedivergencebasedon
domains. Previous works refer this as cross-domain [3] or onlytwooutcomesfortheposteriorprobabilityisnotopti-
cross-dataset generalization [9]. We provide an overview mallyinformative.Hence,weproposeamethodtoquantify
of the existing works employing external data in VAD in uncertaintyinthehigh-dimensionalfeaturespaceinsteadof
Table 1. Previous works on cross-domain generalization theprobabilityspace.
focus on unsupervised methods based on few-shot target-
domain scene adaptation. [23, 25] employ data from the 3.Method
targetdomainviameta-learningtoadapttothatspecificdo-
3.1.ProblemDefinition
main. Aich et al. [3] proposed a zero-shot target domain
adaptationmethodthatincorporatesexternaldatatogener-
Inthiswork,weaddressareal-worldVADproblem,where
ate pseudo-abnormal frames. Despite the intriguing setup, a weakly-labeled dataset D = {(Xi,Yi)}nl and an ex-
l l l i=1
these unsupervised cross-domain generalization methods ternal unlabeled dataset D = {Xi}nu are available for
u u i=1
lackexplicitknowledgeaboutwhatconstitutesananomaly,
training. Here, n and n indicate the number of videos
l u
hindering the model’s ability to learn the specific charac-
in the two datasets, respectively, with n ≫ n due to the
u l
teristics of anomalies. To this end, we propose the use
convenienceofgatheringunlabeledvideodata. Thevideo-
ofweakly-supervisedlearningforcross-domaingeneraliza-
level labels of X are denoted by Y ∈ {0,1}. We do not
l l
tion.Weintegrateexternaldatasetsfromdiversedomainsto
makeanyassumptionaboutdistributionsofD andD ,and
l u
enable the cross-domain generalization of a model trained
therefore, they can be drawn from different distributions.
inaweakly-supervisedfashion.
We aim to find the model F(·|θ), parameterized by θ, that
Pseudo-Labeling and Self-training. Pseudo-labeling [4,
providesaccuratepredictionsonweakly-labeleddatawhile
28]isacommontechniquewherethemodeltrainedonla-
adaptively minimizing the prediction bias on the external
beled data assigns labels to unlabeled data. Subsequently,
data using the uncertainty regularization scores. We illus-
the model is trained on both the initially labeled data and
tratetheproposedframeworkinFigure2.
thepseudo-labeleddata. Thisself-trainingstrategy[26,40]
operates iteratively, allowing the model to progressively 3.2.FeatureExtractionandTemporalProcessing
enhance its generalization. In VAD, several works lever-
The proposed uncertainty quantification method (Section
age pseudo-labeling and self-training for generating fine-
3.4) compares two diverse representations of each sample
grainedpseudo-labels[11,20,42]. However,incontrastto
to estimate the uncertainty associated with the segment-
the previous methods, instead of generating pseudo-labels
levelpredictionsonexternaldata. Tothisaim, weemploy
for the weakly labeled data, we leverage pseudo-labels for
twodifferentbackbonesforfeatureextractionfromvideos,
incorporatingtheexternaldata.
whicharewidelyusedforanomalydetectiontasks.Thefirst
Uncertainty Estimation. To address pseudo-label noise,
one is the conventional I3D backbone [6], which extracts
priorresearchindifferentcontextshasexploreduncertainty
segment-levelfeaturesusing3Dconvolution,andtheother
estimation using various approaches, such as data aug-
istheCLIPbackbone[27],whichextractsframe-levelfea-
mentation[5,30],inferenceaugmentation[12],andmodel
turesusingthefrozenCLIPModel’sViTencoder. Thecon-
augmentation [46]. While data augmentation is effective
trasting inductive biases of the 3D convolution-based I3D
for images, it can disrupt temporal relationships in video
andthetransformer-basedCLIPhelptoeffectivelycapture
frames and is not efficient for training on high-cardinality
thepredictionvariance. ItistobenotedthatonlytheCLIP
data like videos. On the other hand, inference augmen-
backboneisusedduringinference. Wedeveloptwopredic-
tation methods, such as MC Dropout [12, 42], introduce
tionheads,namelythemainmodel,P ,builtontopofthe
perturbationsduringmodelinferencetoobtainslightlydif- m
CLIP backbone, and the auxiliary model, P , built on top
aFigure2. OverviewoftheproposedCDLFramework. CDLStep0: TheRankingLoss,L (SuppMat. §6),isemployedtotraintwo
rank
pseudo-labelgenerationmodels,P andP ,§3.2,onweakly-labeleddata,D. CDLStepk,k > 0: P andP aretrainediteratively
m a l m a
on D ∪D , incorporating pseudo-labels for D generated at the end of the previous CDL step. To deal with noise in pseudo-labels,
l u u
uncertaintyregularizationscoresareestimatedusingthedivergencebetweenthepredictionsofthetwomodels,§3.4.Whenoptimizingon
D ,thepredictionbias,L (§3.3),forexternaldataisreweighedusingthecomputeduncertaintyregularizationscores,§3.5.
u bce
oftheI3Dbackbone. lackofgroundtruthsupervision,weemployaself-training
Video frames are highly correlated in the temporal di- mechanism,consideringYˆ asthesoftlabels,therebytreat-
u
mension. Toreducetheredundancyinframe-levelfeatures ing the second term as a constant and minimizing the first
extracted by the CLIP backbone, we pool the representa- term. Specifically, we use the binary cross-entropy (BCE)
tionsbybilinearlyinterpolatingthemtoafixed,empirically loss,L ,givenby:
bce
determined length, n . Each of the n interpolated fea-
s s L =−Yˆ log(F(X |θ)) −(1−Yˆ )log(1−F(X |θ)),
tures represents one segment. To ensure consistency, we bce u u u u
(3)
also fix the length of representations extracted by the I3D
to estimate the prediction bias associated with each video
backbone. EvaluationinSection4.6analyzestheroleofn
s
segment,forbothP andP .
onthemodel’sperformance. Tocapturelong-rangetempo- m a
ralinformationoverthesequence,weemployalightweight 3.4.UncertaintyEstimation
temporal network, i.e., transformer encoder, to implement
Since D and D do not necessarily share the same distri-
P andP . u l
m a
bution, the generated pseudo-labels are noisy. This noise
3.3.BiasEstimationforExternalData can adversely affect the subsequent training process as it
causes bias to further magnify and propagate within the
Similarto[46],weformulatethepredictionbiasonexternal
model. This issue, known as Confirmation Bias [4], is of-
dataas:
tenmitigatedbyquantifyingtheuncertaintyassociatedwith
Bias(D )=E [F(X |θ)−Y ], (1) pseudo-labels and then incorporating this uncertainty into
u Xu u u
the training process to compensate for the noise. As dis-
whereF(X u|θ)representsasetofpredictedprobabilitydis- cussedinSection2,weopttoaddresstheconfirmationbias
tributions,eachonecorrespondingtoadistinctsegmentof by computing uncertainty using model augmentation. To
X u, and Y u denotes the set of unknown segment-level la- quantify uncertainty through model augmentation, follow-
belsofX u. Bias(D u)canbere-writtenas: ing [46], we estimate prediction variance, which is formu-
latedas:
Bias(D )=E [F(X |θ)−Yˆ ]+E [Yˆ −Y ], (2)
u Xu u u Xu u u
Var(D )=E [(F(X |θ)−Y )2]. (4)
where Yˆ denotes the set of segment-level pseudo-labels u Xu u u
u
for X . Yˆ can be generated by performing inference on Due to the lack of ground-truth labels, Equation 4 can be
u u
the model trained on D . The first term in Equation 2 de- approximatedas:
l
notesthedifferencebetweenthepredictedposteriorproba- Var(D )≈E [(F(X |θ)−Yˆ )2]. (5)
bilityandthepseudo-labels,whilethesecondtermdenotes
u Xu u u
the error between the pseudo-labels and the ground-truth WhenoptimizingthepredictionbiasinEquation2,thevari-
labels. While minimizing the prediction bias, due to the ance in Equation 5 will also be minimized, potentially re-sulting in inaccurate quantification of the true prediction scores, S, as automatic thresholds as this dynamically ad-
variance. Toaddressthis,weadoptanalternativeapproxi- justs learning from noisy labels by scaling the prediction
mation,expressedas: biasassociatedwithexternaldatabasedonS.Thishelpsfil-
teroutunreliablepredictionswhileprioritizinghighlycon-
Var(D )≈E [(cid:0) P (X |θ )−P (X |θ )(cid:1)2 ]. (6)
u Xu m u Pm a u Pa fidentpredictions. Toencouragelowerpredictionvariance,
whichwouldinturnleadtoincreasedpseudo-labelquality,
Since VAD is a binary classification task, the probability
weexplicitlyaddthepredictionvariancetotheoptimization
distributions corresponding to each segment have limited
objectivecorrespondingtotheexternaldata,L ,as:
support. Consequently, estimating prediction variance us- ext
ing only the predicted anomaly scores, as in Equation 6,
1
may not be robust. Hence, instead of measuring the di- L =E [ ·Bias(D )+Var(D )]. (8)
ext Xu Var(D ) u u
vergence between the predicted posterior probabilities for u
the two classes, we propose quantifying pseudo-label un-
Equation8isrewrittenwiththeapproximatedtermsas:
certainty in the high-dimensional space. To this end, we
computethecosinesimilaritybetweenthesegmentsineach L =E [S·L −λ ·⟨Z ,Z ⟩]. (9)
set of the representations, Z and Z , obtained from the ext Xu bce 3 m a
m a
penultimatelayerofP andP ,respectively. Here,Z =
m a m Alternatively,Equation9canberewrittenas:
{z1 m,z2 m,...,zn ms}andZ
a
={z1 a,z2 a,...,zn as}.
To obtain a set of stabilized, segment-level uncertainty
1
(cid:88)nu (cid:88)ns
(cid:16) (cid:17)
regularizationscoreswithinaboundedrangefromthecom- L = Si,j ·Li,j −λ ·⟨Zi,j,Zi,j⟩ ,
ext n ·n bce 3 m a
puted cosine similarity, we introduce the following func- s u i=1j=1
tion. LetS ={s1,s2,...,sns}bethesetofsurrogatevari- (10)
ancesthatweuseasproxiesfortheuncertaintyofsegments. whereλ 3isahyper-parametertobalancethelosses.Similar
Thesurrogatevarianceiscomputedas: toCDLstep0,tooptimizethetrainingonD l,weuseL rank.
ThetotaloptimizationobjectivefortrainingonD ∪D can
l u
sj =eτ(⟨zj m,zj a⟩−1), (7) beexpressedas:
where sj indicates the uncertainty regularization score for
L =L +λ ·L , (11)
the jth segment, ⟨zj,zj⟩ indicates the cosine similarity, Total rank 4 ext
m a
andτ denotesthetemperatureparameter.
whereλ isatrade-offparameterforL . Weemploythe
Higher uncertainty regularization scores indicate the 4 ext
optimizationobjectivedefinedinEquation11duringtrain-
similarencodingofdatabetweenthemodels,implyingless
ingonD ∪D foreachepochwithineveryCDLstep. Af-
uncertaintyinthepredictedlabels,while,lowerscoresim- l u
ter each CDL step is completed, we re-generate the set of
ply high uncertainty in the predicted labels. Empirical ev-
soft segment-level pseudo-labels using the models trained
idence in Section 4.4 demonstrates a significant negative
on D ∪ D . This iterative refinement process repeats k
correlation between uncertainty regularization scores and l u
times, where k is a hyper-parameter determining the num-
BinaryCross-Entropy(BCE)lossbetweenthepredictedla-
ber of CDL steps. With each CDL step, the models’ per-
bels and ground truths. This affirms that the proposed un-
formancegetsfurtherrefinedasthepseudo-labelsgetitera-
certainty regularization score effectively serves as a proxy
tivelyimproved.
forthequalityofpseudo-labels.
3.5.TrainingProcess 3.6. Inference - Extending Segment-level Scores to
Frame-levelScores
CDL Step 0. We initially train P and P separately on
m a
thelabeledset,optimizingbothofthemusingtheRanking During inference, we compute segment-level anomaly
Loss, L rank,discussedinSupp. Mat. Sec. 6. Wethenper- scores for the videos using P m. Since we encounter long-
forminferenceonthetrainedmodelstogeneratethesetsof untrimmedvideoswithvaryingnumbersofframes,forex-
softsegment-levelpseudo-labelsfortrainingonD . tendingthesegment-levelanomalyscoretotheframelevel,
u
CDL Step > 0. Following the generation of the sets of for each video, we divide the total number of frames n f
pseudo-labelsforD u,weenteraniterativepseudo-labelre- by the number of segments n s to obtain the number of
finement phase, where we train P
m
and P
a
on D
l
∪ D
u
frames per segment, n fs. We assign the anomaly score of
formultipleCDLsteps. EachCDLstepcomprisesafixed each segment to its consecutive frames. The first segment
number of epochs. In each epoch, we regenerate the sets corresponds to the first n fs frames, and so forth until the
of segment-level uncertainty regularization scores. To en- (n −1)thsegment.Forthelastsegment,itsanomalyscore
s
abletheuncertainty-drivenlearningfromexternaldata,sim- isassignedtoanyremainingframes, potentiallyexceeding
ilarto[46],weusetheestimateduncertaintyregularization n ,ifthereisaremainder.
fs4.Experiments UCF UCF-R XDV
Methods Features
AUC(%) AUC(%) AP(%)
We evaluate the proposed method on the major video rGAN[23] - 64.35∗ 65.19∗ 37.74∗
anomaly datasets, UCF-Crime (UCF) [32] and XD- Cro (Uss n-D suo pm .)ain MPN[25] - 65.67∗ 67.98∗ 38.89∗
zxVAD[3] - 68.74† 69.39† 40.68†
Violence (XDV) [38]. Additionally, we use 11,000 videos
Sultanietal.[32] I3D 80.70 84.63∗ 53.88∗
from the HACS [45] dataset as a source of external data.
Non MIST[11] I3D 82.30 86.17∗ 50.33∗
WeprovidedetailedinformationaboutthedatasetsinSupp. Cross- RTFM[33] I3D 84.03 86.47∗ 37.30∗
Domain S3R[37] I3D 85.99 87.11∗ 49.84∗
Mat. §7. In §4.1, we discuss the implementation details.
CU-Net[42] I3D 86.22 88.15∗ 37.98∗
In §4.2, we discuss the inherent noise in the test anno- MGFN[8] I3D 86.98 87.33∗ 32.16∗
SSRL[19] I3D 87.43 87.02∗ 51.60∗
tations of benchmark datasets. We proceed to compare
CLIP-TSA[18] CLIP 87.58 73.20∗ 44.33∗
the proposed framework with prior works in cross-domain Ours(Noext.data) CLIP 84.49 89.96 58.13
scenarios (§4.3.1) and open-set scenarios (§4.3.2). Subse- Cross-Domain Ours(UCF+HACS)CLIP 84.63 90.53 65.14
quently, in §4.4, we demonstrate a strong correlation be- (Weakly-Sup.) Ours(UCF+XDV) CLIP 84.73 90.26 68.37
tweenthequalityofpseudolabelsandthecomputeduncer-
Table2.ComparisonwithpriorworksonXDV,consideringUCF-
taintyscores. Wethenexploretheevolutionoftheseuncer-
Crimeasthesourcedata. Asterisk(∗)indicatesthatevaluations
tainty scores through the training process in §4.5. Finally,
wereconductedbyususingtheofficialcode.Dagger(†)indicates
in §4.6, we conduct ablation studies and hyper-parameter
thatevaluationswereconductedbyourimplementationduetothe
analysistoanalyzetheimpactofindividualcomponentsof lackofanofficialimplementation.
theproposedframework.
4.1.ImplementationDetails Methods Features XDVAP(%) UCF-R
AUC(%)
WeimplementtheproposedmethodusingPyTorch. Weex- Cross- rGAN[23] - 40.10∗ 59.82∗
tractCLIPandI3Dfeaturesatafixedframerateof30FPS. Domain MPN[25] - 44.79∗ 60.35∗
(Unsup.) zxVAD[3] - 47.53† 63.61†
CLIP features are extracted from the frozen CLIP model’s
Sultanietal.[32] I3D 73.20 71.23∗
imageencoder(ViT-B/32).Forthehyper-parameters,inthe RTFM[33] I3D 77.81 70.46∗
open-setscenarios,weempiricallysetthevalueofn sto64, CN roo sn s- M S3G RF [N 37[ ]8] I I3 3D D 8 80 0. .1 21 6 6 69 9. .1 02 4∗ ∗
τ to1.25,λ 1andλ 2to5e−4,λ 3to1e−3,andλ 4to700. Domain CLIP-TSA[18] CLIP 80.67 67.58∗
Ablationstudiesforselectingn andλ areincludedinSec- Ours(Noext.data) CLIP 75.13 76.39
s 3
tion 4.6. We use the Adam optimizer with a weight decay Cross-Domain Ours(XDV+UCF) CLIP 77.04 88.06
(Weakly-Sup.) Ours(XDV+HACS) CLIP 78.61 88.50
of1e−3,andwesetalearningrateof3e−5forthetrans-
former encoder and 5e−4 for the fully connected layers.
Table3.ComparisonwithpriorworksonUCF-Crime,considering
Weuseabatchsizeof64. InbothP andP ,weexplicitly
m a XDV as the source data. Asterisk (∗) indicates that evaluations
encode positional information in the segments using sinu-
wereconductedbyususingtheofficialcode.Dagger(†)indicates
soidal positional encodings [34]. We train on the weakly- thatevaluationswereconductedbyourimplementationduetothe
labeled source dataset for 200 epochs, followed by train- lackofanofficialimplementation.
ingontheunionofweakly-labeledandexternaldatasetsfor
40CDLsteps,eachCDLstepcomprising4epochs. Addi-
tional information regarding hyper-parameters is provided levelareaunderthePrecision-Recallcurve(PRAUC),also
inSupp. MaterialSection8. knownasAveragePrecision(AP),toevaluateonXDV.
Model Architecture. Both P and P consist of a trans-
m a 4.2. Noise in the Test Annotations of Benchmark
formerencoderlayerwithfourheads,followedbyfourfully
Datasets
connected layers, each consisting of 4096, 512, 32, and 1
neurons,respectively. Inboththemodels,forallthelayers Our manual inspection reveals that the frame-level test-
except the last, we use ReLU [2] activation while for the ing annotations of the UCF-Crime (UCF) [32] and XD-
lastlayer,weuseSigmoidactivation. Violence (XDV) [38] datasets, which are commonly used
Evaluation Setup. To reduce bias, we perform each ex- for benchmarking VAD models, exhibit significant noise.
periment three times with different seeds and average the This noise largely stems from the fact that the original an-
results. In open-set experiments, we repeat each experi- notationsdonotconsistentlylabeltheframesleadingupto
ment three times, using different sets of anomaly classes the primary anomalous events and their subsequent conse-
eachtime. quences as anomalous. For instance, in a video assigned
Evaluation Metric. Following previous works on UCF- a label like “shooting”, we assert that frames showing the
Crime [32], we adopt the frame-level area under the ROC person holding the gun and frames illustrating the injured
curve (AUC) to evaluate on UCF-Crime. In line with victimshouldalsobemarkedasanomalous. Thisperspec-
previous works on XD-Violence [38], we use the frame- tive aligns with the fundamental goal of VAD, which is toUCF(AUC%) UCF-R(AUC%)
c Wuetal.[38] RTFM[33] Zhuetal.[49] Ours(w/oCDL) Ours(CDL) Ours(w/oCDL) Ours(CDL)
1 73.22 75.91 76.73 75.17 77.45 84.32 85.39
3 75.15 76.98 77.78 81.51 82.57 86.84 87.69
6 78.46 77.68 78.82 82.97 83.44 87.85 88.21
9 79.96 79.55 80.14 83.02 83.37 89.22 89.82
Table4. ComparisonwithothermethodsinOpen-setsettingonUCF-Crimedataset;cdenotestheno. ofanomalousclassesincludedfor
weakly-supervisedtraining.
identify all anomalous frames within a video, irrespective thecross-domaindataset,XDV,by11.26%and14.49%,re-
of the video’s primary label. However, it should also be spectively, compared to the previous state-of-the-art base-
notedthatintheoriginalannotations,forsomevideos,cer- line. Additionally,thereisalsoamarginalimprovementin
tainframesrelatedtothevideo’sprimaryanomalylabelare theperformanceofthesourcesetuponintegrationofexter-
alsonotmarkedanomalous. naldatasets.
Toaddressthis,were-annotatethetestsetofUCF-Crime XDVastheWeakly-LabeledSourceSet,UCF-Crimeas
by assigning each video to three independent annotators. theCross-DomainSet. Table3summarizestheresultsfor
Wethen combinetheirannotations togeneratemore accu- thisscenario. Notably,theproposedmethodachievesstate-
rate frame-level labels. Compared to the original annota- of-the-art performance on the cross-domain dataset, UCF-
tionswhere7.58%ofthetotalframesarelabeledasanoma- R, even without the utilization of any external data during
lous, the proposed annotations label 16.55% of the total training. Thisisattributedtothesimplicityoftheproposed
frames as anomalous. The proposed annotations are avail- architecturecomparedtootherbaselines. Theproposedar-
able here1. We provide a comparison of the proposed and chitecturepreventsoverfittingtothesourcedataset,thereby
originalannotationshere2. Fortheremainderofthispaper, increasing its generalizability to the cross-domain dataset.
wereferthere-annotatedtestsetoftheUCF-Crimedataset Additionally,integratingexternaldatafurtherenhancesper-
asUCF-R. formanceonboththecross-domainandsourcesets.Specif-
ically,leveragingtheCDLframeworkwithUCF-Crimeand
4.3.ComparisonwithPriorWorks HACSasexternaldatasetsboostsUCF-R’sAUCby18.94%
and19.39%respectively,comparedtopreviousstate-of-the-
4.3.1 Cross-DomainScenarios
art baselines. We also observe that the proposed method’s
WhiletheUCF-Crime[32]andXD-Violence[38]datasets performance is inferior on XDV. We attribute this to the
sharesimilardefinitionsofwhatconstitutesanomalies,that noiseintheannotationsofXDV’stestset.
definitiondiffersfromthoseofsmallerdatasetslikeShang- These results highlight that the proposed CDL frame-
haiTech [21], CUHK-Avenue [22], UCSD Pedestrian [7], workiscapableofeffectivelyexploitingexternaldatawith
UBnormal [1], where anomalies are more subtle. For in- vastdomaingapstoachieveasignificantcross-domaingen-
stance, running is considered anomalous in UBnormal but eralization. It’s noteworthy that the performance gain ob-
not in XD-Violence. Due to these divergent notions of servedwiththeproposedCDLframeworkremainsconsis-
anomaliesacrossdatasets,weconductcross-domainexper- tent across all tested datasets, suggesting that the perfor-
imentsbysimultaneouslyevaluatingontheUCF-Crimeand manceimprovementisnotdependentonanyspecificsource
XD-Violence datasets, given their more aligned anomaly orexternaldataset.
definitions.
UCF-CrimeastheWeakly-LabeledSourceSet,XDV
4.3.2 Open-SetScenarios
as the Cross-Domain Set. Table 2 summarizes the re-
sults for this scenario. First, we observe that the proposed
In Table 4, we evaluate the proposed framework’s per-
methodachievesstate-of-the-artresultsonXDVandUCF-
formance on the UCF-Crime dataset in a realistic open-
R even without utilizing any external data (without CDL).
set scenario, where the model is evaluated on both, pre-
Webelievethisisduetotheinductivebiasofpreviousmeth-
viously seen and unseen anomaly classes. To simulate
odstowardsthenoisyannotationsofUCF-Crime. Next,we
this scenario, we randomly include c anomalous classes
observethattheadditionofexternaldata,HACSandXDV,
in the weakly-labeled set, while the remaining anomalous
leads to a significant enhancement in the performance of
classesareplacedintheunlabeledset. Inboththeweakly-
supervisedsourcesetandtheunlabeledset, thenumberof
1https://drive.google.com/drive/folders/
normalvideosequalsthenumberofanomalousvideos. We
1IVjQQFHXVcsaT63HUjpfk8C5KH6HsQ7t?usp=drive_link
2https://rb.gy/4vkr1r evaluate two model configurations; one trained solely onFigure 3. (a) Correlation between uncertainty scores and BCE loss computed between the estimated scores and ground truth. When
λ = 1e−3,asexpected,aconsistentlyhighnegativecorrelationemerges,demonstratingtheeffectivenessoftheproposeduncertainty
3
quantification method as a reliable proxy for pseudo-label quality. (b) Cumulative Distribution Function (CDF) plots illustrating the
progressionofaverageuncertaintyregularizationscoresforeachvideoduringtraining. CDLstep20hasahigherconcentrationofscores
around1comparedtoCDLstep2,whileCDLstep2hasahigherconcentrationaround1thanCDLstep1.Thissuggeststhat,astraining
progresses,thereisahighertendencyforscorestohaveelevatedvalues,indicatingmoreconfidentpseudo-labelpredictions. (c)Ablation
studyonthecoefficientofthecosinesimilaritylossterm,λ .(d)Ablationstudyonthenumberofsegments,n .
3 s
theweakly-labeledset(withoutCDL)andtheotheronthe first epoch of three different CDL steps. We conduct this
unionofweakly-labeledandunlabeledsetsusingtheCDL experiment considering UCF-Crime as the weakly-labeled
Framework. sourcesetandXDVastheexternalset. Weobservethatin
OnUCF-Crime,theproposedmodel,withoutCDL,sur- CDLstep1,16.65%oftheuncertaintyscoresfallwithinthe
passes the state-of-the-art baselines for c > 1. This high- range [0, 0.1]. As training progresses to CDL steps 2 and
lights its efficacy in open-set settings. While, with CDL, 20, this proportion decreases to 13.06% and 11.39%, re-
themodelsurpassesthebaselinesacrossallvaluesofcbya spectively. Meanwhile,theproportionofuncertaintyscores
considerablemargin. intherange[0.9, 1]increasesfrom35.11%inCDLstep1
For both UCF-Crime and UCF-R, when unlabeled data to56.70%inCDLstep2andfurtherto57.68%inCDLstep
is incorporated, we observe a consistent performance gain 20. This trend indicates a discernible shift towards higher
across all values of c, suggesting the effectiveness of the uncertaintyscoresastrainingprogresses,suggestinganim-
CDLframeworkacrossvaryingamountsofweakly-labeled provement in model confidence due to increased pseudo-
andunlabeleddata. labelquality.
4.4. Correlation between Uncertainty Scores and 4.6.AblationStudiesandHyper-parameterAnaly-
BCELoss(ProxytoLabelQuality) sis
To assess the efficacy of the proposed uncertainty quan- Forthesakeofconsistency,weconductallablationstudies
tification method as a proxy for pseudo-label quality, we onUCF-Crimeinanopen-setsetting,withc=1.However,
computethenon-parametricSpearmancorrelationbetween it should be noted that for different training setups, hyper-
estimated uncertainty regularization scores and BCE loss parametersaretunedseparatelyaswell.
betweenthepredictedpseudo-labelsandthecorresponding ImpactofVariousComponentsoftheCDLFramework.
groundtruths.Forthisexperiment,weconsiderUCF-Crime WeassesstheeffectivenessofeachcomponentoftheCDL
as the weakly-labeled source set and XDV as the external framework by adding them sequentially. The results are
set. InFigure3(a),withλ 3 =1e−3,CDLstep1onwards, summarized in Table 5. We consider training on c = 1
aconsistentlyhighnegativecorrelation(-0.46inCDLstep anomalyclassinaweakly-supervisedfashionasourbase-
6, with a p-value < 1e-5) emerges, indicating the robust- line. Theremainingc−1anomalousclassesareplacedin
nessoftheproposeduncertaintyquantificationframework. the external set. We first observe that integrating external
Conversely, setting λ 3 to 0 results in a sustained positive dataintothesourcesetwithoutaccountingforpseudo-label
correlation,signifyingsub-optimalpseudo-labelsintheab- uncertainty (Si,j = 1,∀i,j) and without minimizing co-
senceofcosinesimilaritylossterm. sine similarity between representations (λ = 0) yields a
3
0.35% gain in AUC, highlighting the effectiveness of ex-
4.5.ProgressionofUncertaintyScores
ternal data in improving the model’s performance. Next,
Toassesstheevolutionofuncertaintyregularizationscores westudytheimpactofuncertainty-awareintegrationofex-
through the training process, in Figure 3(b), we plot the ternal data, i.e., adaptively reweighing the prediction bias
CumulativeDistributionFunction(CDF)ofaverageuncer- of external data with the computed uncertainty values and
tainty regularization scores for external videos across the with λ set to 0. This results in a gain of 0.13% in AUC,
3Externaldata UncertaintyCoeff. Cos.SimilarityLoss AUC(%)
✗ ✗ ✗ 84.32
✓ ✗ ✗ 84.67
✓ ✓ ✗ 84.80
✓ ✓ ✓ 85.39
Table 5. Ablation study of various components on the UCF-R
datasetinanopen-setsetting(c=1).
demonstratingthesuperiorityofuncertainty-drivenintegra-
tion compared to the standard integration. Finally, we as-
sess the impact of adding the cosine similarity loss term
during uncertainty-aware training. This further leads to a Figure4.Ablationstudyontheimpactofthesizeofexternaldata.
significantboostof0.59%,validatingitseffectiveness.
ImpactofCosineSimilarityLoss. InFigure3(c),weex-
Acknowledgement
ploretheimpactofvaryingthecoefficientofthecosinesim-
ilaritylossonthemodel’sperformance. Weobserveagrad- This work was supported in part by U.S. NIH grants
ualincreaseinAUCasλ 3increasesfrom1e-9to1e-3.This R01GM134020 and P41GM103712, NSF grants DBI-
could be due to the effect of cosine similarity loss getting 1949629, DBI-2238093, IIS-2007595, IIS-2211597, and
more pronounced with higher values of λ 3. However, be- MCB-2205148. This work was supported in part by Ora-
yond1e-3,thereisarapiddeclineinAUC,likelyduetothe cleCloudcreditsandrelatedresourcesprovidedbyOracle
dominance of the cosine similarity loss over other losses forResearch,andthecomputationalresourcessupportfrom
when its coefficient is high. Therefore, we select 1e-3 as AMD HPC Fund. We thank Eshaan Mandal and Bhavay
theoptimalchoiceforλ 3. Malhotra for their assistance, which has been instrumental
ImpactofNumberofSegments. InFigure3(d), weob- incompletingthiswork.
servethattheperformanceconsistentlyimprovesasno. of
segments, n s, increases from 16 to 64, but it begins to de- References
clinerapidlyafterward. Therefore,wesetn as64.
s
ImpactoftheSizeofExternalData. Todeterminetheop- [1] Andra Acsintoae, Andrei Florescu, Mariana-Iuliana
timalnumberofunlabeledexternalvideosfromtheHACS Georgescu, Tudor Mare, Paul Sumedrea, Radu Tudor
Ionescu, Fahad Shahbaz Khan, and Mubarak Shah. Ub-
dataset to integrate into the weakly-labeled training set of
normal: New benchmark for supervised open-set video
UCF-Crime,weconductanablationstudy,depictedinFig-
anomalydetection. InCVPR,2022. 2,7
ure4.Weobservethatincreasingthesizeoftheexternalset
[2] AbienFredAgarap.Deeplearningusingrectifiedlinearunits
increasestheperformanceonXDV.However,thisincrease
(relu),2019. 6
tendstoplateauaftertheinclusionof11,000videos. Con-
[3] Abhishek Aich, Kuan-Chuan Peng, and Amit K. Roy-
sequently, we do not include additional videos beyond the
Chowdhury.Cross-domainvideoanomalydetectionwithout
11,000threshold.
targetdomainadaptation. InProceedingsoftheIEEE/CVF
Winter Conference on Applications of Computer Vision
(WACV),pages2579–2591,2023. 1,2,3,6
5.Conclusion [4] Eric Arazo, Diego Ortego, Paul Albert, Noel E O’Connor,
and Kevin McGuinness. Pseudo-labeling and confirmation
biasindeepsemi-supervisedlearning. InIJCNN,2020. 3,4
In this work, we demonstrated the effectiveness of inte-
[5] DavidBerthelot,NicholasCarlini,EkinD.Cubuk,AlexKu-
gratingexternal,unlabeleddatawithweakly-labeledsource
rakin,KihyukSohn,HanZhang,andColinRaffel. Remix-
data to enhance the cross-domain generalization of VAD
match:Semi-supervisedlearningwithdistributionmatching
models. Toenablethisintegration,weproposedaweakly-
andaugmentationanchoring. InICLR,2020. 3
supervisedCDL(Cross-DomainLearning)frameworkthat
[6] Joao Carreira and Andrew Zisserman. Quo vadis, action
adaptivelyminimizesthepredictionbiasonexternaldataby
recognition?anewmodelandthekineticsdataset.InCVPR,
scaling it with the prediction variance, which serves as an
pages6299–6308,2017. 3
uncertaintyregularizationscore. Theproposedmethodout-
[7] AntoniB.ChanandNunoVasconcelos. Modeling,cluster-
performsbaselinemodelssignificantlyincross-domainand ing, and segmenting video with mixtures of dynamic tex-
open-set settings while retaining competitive performance tures. IEEETransactionsonPatternAnalysisandMachine
inin-domainsettings. Intelligence,pages909–926,2008. 7[8] Yingxian Chen, Zhengzhe Liu, Baoheng Zhang, Wilton [22] CewuLu,JianpingShi,andJiayaJia.Abnormaleventdetec-
Fok, Xiaojuan Qi, and Yik-Chung Wu. Mgfn: magnitude- tionat150fpsinmatlab. InICCV,pages2720–2727,2013.
contrastiveglance-and-focusnetworkforweakly-supervised 2,3,7,14
video anomaly detection. In Proceedings of the Thirty- [23] Yiwei Lu, Frank Yu, Mahesh Kumar Krishna Reddy, and
Seventh AAAI Conference on Artificial Intelligence and YangWang. Few-shotscene-adaptiveanomalydetection. In
Thirty-FifthConferenceonInnovativeApplicationsofArtifi- ECCV,pages125–141,2020. 2,3,6
cialIntelligenceandThirteenthSymposiumonEducational [24] Weixin Luo, Wen Liu, and Shenghua Gao. Remembering
AdvancesinArtificialIntelligence,2023. 6 history with convolutional lstm for anomaly detection. In
[9] MyeongAh Cho, Minjung Kim, Sangwon Hwang, Chae- ICME,pages439–444,2017. 3
wonPark,KyungjaeLee,andSangyounLee. Lookaround [25] HuiLv, ChenChen, ZhenCui, ChunyanXu, YongLi, and
for anomalies: Weakly-supervised anomaly detection via JianYang. Learningnormaldynamicsinvideoswithmeta
context-motionrelationallearning. InCVPR,pages12137– prototypenetwork. InCVPR,pages15425–15434,2021. 1,
12146,2023. 3 2,3,6
[10] YangCong,JunsongYuan,andJiLiu.Sparsereconstruction [26] DavidMcClosky,EugeneCharniak,andMarkJohnson. Ef-
cost for abnormal event detection. In CVPR, pages 3449– fectiveself-trainingforparsing. InNAACL,pages152–159,
3456,2011. 1 2006. 3
[11] Jia-ChangFeng,Fa-TingHong,andWei-ShiZheng. MIST: [27] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya
Multipleinstanceself-trainingframeworkforvideoanomaly Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,
detection. InCVPR,pages14009–14018,2021. 1,2,3,6, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen
14 Krueger, and Ilya Sutskever. Learning transferable visual
[12] YarinGalandZoubinGhahramani. Dropoutasabayesian modelsfromnaturallanguagesupervision. InICML,pages
approximation: Representing model uncertainty in deep 8748–8763,2021. 3
learning. InICML,pages1050–1059,2016. 3 [28] Mamshad Nayeem Rizve, Kevin Duarte, Yogesh S Rawat,
[13] Mariana Iuliana Georgescu, Radu Tudor Ionescu, Fa- and Mubarak Shah. In defense of pseudo-labeling: An
had Shahbaz Khan, Marius Popescu, and Mubarak Shah. uncertainty-aware pseudo-label selection framework for
Abackground-agnosticframeworkwithadversarialtraining semi-supervisedlearning. InICLR,2021. 3
for abnormal event detection in video. IEEE Transactions [29] HiteshSapkotaandQiYu.Bayesiannonparametricsubmod-
onPatternAnalysisandMachineIntelligence,pages4505– ularvideopartitionforrobustanomalydetection. InCVPR,
4523,2022. 2 pages3212–3221,2022. 2
[14] Mahmudul Hasan, Jonghyun Choi, jan Neumann, Amit K [30] Kihyuk Sohn, David Berthelot, Chun-Liang Li, Zizhao
Roy-Chowdhury,andLarryDavis. Learningtemporalregu- Zhang, Nicholas Carlini, Ekin D. Cubuk, Alex Kurakin,
larityinvideosequences.InProceedingsofIEEEComputer HanZhang,andColinRaffel. Fixmatch: simplifyingsemi-
VisionandPatternRecognition,2016. 14 supervised learning with consistency and confidence. In
[15] Mahmudul Hasan, Jonghyun Choi, Jan Neumann, Amit K. NeurIPS,2020. 3
Roy-Chowdhury,andLarryS.Davis.Learningtemporalreg- [31] Fahad Sohrab, Jenni Raitoharju, Moncef Gabbouj, and
ularityinvideosequences. InCVPR,2016. 1,2 AlexandrosIosifidis. Subspacesupportvectordatadescrip-
[16] KexinHuang,VishnuSresht,BrajeshRai,andMykolaBor- tion. InICPR,pages722–727,2018. 14
dyuh. Uncertainty-awarepseudo-labelingforquantumcal- [32] WaqasSultani,ChenChen,andMubarakShah. Real-world
culations. InUAI,pages853–862,2022. 3 anomaly detection in surveillance videos. In CVPR, pages
[17] RaduTudorIonescu,FahadShahbazKhan,Mariana-Iuliana 6479–6488,2018. 1,2,3,6,7,12
Georgescu,andLingShao.Object-centricauto-encodersand [33] YuTian,GuansongPang,YuanhongChen,RajvinderSingh,
dummyanomaliesforabnormaleventdetectioninvideo. In JohanWVerjans,andGustavoCarneiro.Weakly-supervised
CVPR,pages7842–7851,2019. 3 videoanomalydetectionwithrobusttemporalfeaturemag-
[18] HyekangKevinJoo, KhoaVo, KashuYamazaki, andNgan nitudelearning. InICCV,pages4975–4986,2021. 1,2,6,
Le. Clip-tsa: Clip-assisted temporal self-attention for 7,14
weakly-supervisedvideoanomalydetection. InICIP,pages [34] AshishVaswani,NoamShazeer,NikiParmar,JakobUszko-
3230–3234,2023. 6 reit,LlionJones,AidanN.Gomez,ŁukaszKaiser,andIllia
[19] Guoqiu Li, Guanxiong Cai, Xingyu Zeng, and Rui Zhao. Polosukhin. Attention is all you need. In NeurIPS, page
Scale-aware spatio-temporal relation learning for video 6000–6010,2017. 6,12
anomalydetection. InECCV,pages333–350,2022. 6 [35] Boyang Wan, Yuming Fang, Xue Xia, and Jiajie Mei.
[20] Shuo Li, Fang Liu, and Licheng Jiao. Self-training multi- Weakly supervised video anomaly detection via center-
sequence learning with transformer for weakly supervised guideddiscriminativelearning. ICME,pages1–6,2020. 3
videoanomalydetection. AAAI,pages1395–1403,2022. 3, [36] JueWangandAnoopCherian. Gods:Generalizedone-class
14 discriminative subspaces for anomaly detection. In ICCV,
[21] WenLiu,WeixinLuo,DongzeLian,andShenghuaGao.Fu- pages8200–8210,2019. 14
tureframepredictionforanomalydetection–anewbaseline. [37] Jhih-CiangWu,He-YenHsieh,Ding-JieChen,Chiou-Shann
InCVPR,pages6536–6545,2018. 1,2,3,7 Fuh,andTyng-LuhLiu. Self-supervisedsparserepresenta-tionforvideoanomalydetection. InECCV,pages729–745,
2022. 6
[38] Peng Wu, jing Liu, Yujia Shi, Yujia Sun, Fangtao Shao,
Zhaoyang Wu, and Zhiwei Yang. Not only look, but also
listen: Learningmultimodalviolencedetectionunderweak
supervision. InECCV,2020. 6,7,12,14
[39] Dan Xu, Elisa Ricci, Yan Yan, Jingkuan Song, and Nicu
Sebe. Learningdeeprepresentationsofappearanceandmo-
tion for anomalous event detection. In BMVC, pages 8.1–
8.12,2015. 2
[40] DavidYarowsky. Unsupervisedwordsensedisambiguation
rivalingsupervisedmethods. InACL,page189–196,1995.
3
[41] Guang Yu, Siqi Wang, Zhiping Cai, En Zhu, Chuanfu Xu,
Jianping Yin, and Marius Kloft. Cloze test helps: Effec-
tivevideoanomalydetectionvialearningtocompletevideo
events. InProceedingsofthe28thACMInternationalCon-
ferenceonMultimedia,pages583–591,2020. 2
[42] ChenZhang,GuorongLi,YuankaiQi,ShuhuiWang,Laiyun
Qing,QingmingHuang,andMing-HsuanYang. Exploiting
completeness and uncertainty of pseudo labels for weakly
supervisedvideoanomalydetection.InCVPR,pages16271–
16280,2023. 1,3,6,14
[43] JiangongZhang,LaiyunQing,andJunMiao.Temporalcon-
volutional network with complementary inner bag loss for
weaklysupervisedanomalydetection. InICIP,pages4030–
4034,2019. 2
[44] BinZhao,Fei-FeiLi,andEricXing.Onlinedetectionofun-
usualeventsinvideosviadynamicsparsecoding. InCVPR,
pages3313–3320,2011. 2,3
[45] Hang Zhao, Antonio Torralba, Lorenzo Torresani, and
Zhicheng Yan. Hacs: Human action clips and segments
dataset. InICCV,pages8668–8678,2019. 6,12
[46] ZhedongZhengandYiYang.Rectifyingpseudolabellearn-
ing via uncertainty estimation for domain adaptive seman-
ticsegmentation. InternationalJournalofComputerVision
(IJCV),2021. 3,4,5
[47] Jia-Xing Zhong, Nannan Li, Weijie Kong, Shan Liu,
ThomasHLi, andGeLi. Graphconvolutionallabelnoise
cleaner: Trainaplug-and-playactionclassifierforanomaly
detection. InCVPR,pages1237–1246,2019. 1,3
[48] YiZhuandShawnD.Newsam.Motion-awarefeatureforim-
provedvideoanomalydetection. InBMVC,page270,2019.
2
[49] YuanshengZhu,WentaoBao,andQiYu. Towardsopenset
videoanomalydetection. InECCV,pages395–412, 2022.
7,14Cross-Domain Learning for Video Anomaly Detection with Limited Supervision
Supplementary Material
6.RevisitingMultipleInstanceLearning HACS[45]: Thisisalarge-scaledatasetforhumanaction
recognition, sourcedfromYouTube. Itfeatures200action
Sinceacquiringframe-levellabelsrequiressignificanttime
classes across 140K segments on 50K videos. Due to its
and effort, following Sultani et al. [32], we use Mul-
diverse range of actions, larger size, and longer video du-
tiple Instance Learning (MIL) to train the classifiers us-
rationscomparedtoothervideodatasetssuchasUCF-101,
ing weakly-supervised video-level labels. By dividing a
Kinetics, and ActivityNet, we use a subset of 11K videos
video (bag) into multiple temporal non-overlapping seg-
fromHACSSegmentsasexternal,unlabeleddata.
ments (instances) and encouraging anomalous video seg-
ments to have higher anomaly scores as compared to the 8.ImplementationDetails
normalsegments,theyformulateanomalydetectionasare-
gressionproblem. Toensureconsistencyandgradientstability,whiletraining
Themultipleinstancerankingobjectivefunctionisgiven on D ∪ D , each mini-batch consists of an equal num-
l u
by: ber of samples from D and D . Since the computation
l u
of L necessitates pairs of abnormal and normal videos,
rank
max F(Xi,j|θ)> max F(Xi,j|θ), (12) eachlabeledsamplewithinthemini-batchcomprisesapair
Xi∈D la Xi∈D ln ofanomalousandnormalvideos. Alltheexperimentswere
1≤j≤ns 1≤j≤ns
conductedonanNVIDIARTXA500024GBGPU.Forthe
where Da = {(X,Y) ∈ D : Y = 1} and Dn =
l l l experiments using UCF-Crime as the weakly-labeled data,
{(X,Y) ∈ D : Y = 0} are the set of abnormal and nor-
l we set the batch size to 64, and for the experiments using
mal videos, respectively and max is taken over all video
XD-Violence as the weakly-labeled data, we set the batch
segmentsinabag.
size to 32. In all our experiments except the open-set, we
Insteadofrankingeverysegmentofthepositiveandneg-
set n to 64, τ to 1.25, λ to 5e-3, λ to 1e-3, λ to 1e-3.
s 1 2 3
ative bags, ranking is enforced on one segment from each
We set λ to 2000 for UCF+HACS and UCF+XDV, 1250
4
bag, having the highest anomaly score. The overall loss
for XDV+HACS, and 700 for XDV+UCF. For all our ex-
function,L ,forapairofabnormalandnormalvideos,is
rank periments,weusetheAdamoptimizerwithaweightdecay
givenby:
of 1e-3. For the fully connected layers, we use a learning
L =max(0,1− max F(Xi,j|θ)+ max F(Xi,j|θ)) rateof5e-4whenUCF-Crimeisusedastheweakly-labeled
rank
Xi∈Da Xi∈Dn datasetandalearningrateof1e-4whenXDVisusedasthe
l l
1≤j≤ns 1≤j≤ns
weakly-labeleddataset. Forthetransformerencoderlayers,
+λ L +λ L ,
1 Ts 2 Sp weusealearningrateof3e-5whenUCF-Crimeisusedas
(13) theweakly-labeleddatasetandalearningrateof5e-5when
where L is the temporal smoothness constraint, and L XDVisusedastheweakly-labeleddataset.Inallourexper-
Ts Sp
isthesparsityconstraint. iments, we explicitly encode positional information in the
segments using sinusoidal positional encodings [34]. We
7.Datasets train on the weakly-labeled source dataset for 200 epochs,
followedbytrainingontheunionofweakly-labeledandex-
UCF-Crime [32]: This is a large-scale VAD dataset hav-
ternaldatasetsfor40CDLsteps,eachCDLstepcomprising
ing a total duration of 128 hours. It contains long and
4epochs.Duetothefinergranularityandsemanticrichness
untrimmed real-world surveillance videos across 13 real-
inherentinCLIPfeatures, wechoosetouseCLIPfeatures
istic anomaly categories that are specifically chosen due
duringinference.
to their significant impact on public safety. The dataset
comprises1610weakly-labeledtrainingvideosand290test 9.ComparisonwithUnsupervisedBaselinesin
videosannotatedattheframelevel.
Open-SetSettings
XD-Violence(XDV)[38]: Thisisalarge-scaleandmulti-
scene audio-visual dataset for violence detection, having a Table 6 depicts that the proposed method outperforms all
totaldurationof217hours. Itslonganduntrimmedvideos thebaselinesinopen-setsettingsontheUCF-Crimedataset
are collected from movies, games, and in-the-wild scenar- by a large margin. As expected, all the weakly-supervised
ios, with anomalies spread over 6 categories. It comprises methodsoutperformtheunsupervisedmethods,evenwhen
3954weakly-labeledtrainingvideosand800testvideosan- a small subset of the data is used for weakly-supervised
notatedattheframelevel. training. This highlights the necessity of incorporatingFigure 5. A comparison between the original annotations (UCF) and the proposed annotations (UCF-R). The green region represents
frameslabeledasanomalousbyboththeoriginalandproposedannotations. Theredregionindicatesframeslabeledasanomalousbythe
proposedannotationsbutnotbytheoriginalannotations. Theunshaded(white)regiondenotesnormalframes. Forinstance,inthefirst
row,whiletheoriginalannotationsjustlabelframesdepictingarson(apersonsettingtheChristmastreeonfire)asanomalous,UCF-Ralso
labelstheframesdepictingthefireandsmokefollowingarsonasanomalous.
weak labels during training. Since a direct comparison of 10. Comparison of the Original and Proposed
the proposed weakly-supervised framework with unsuper- AnnotationsforUCF-CrimeDataset
vised methods is not fair, we did not include unsupervised
baselinesinTable4.
Figure 5 illustrates a subset of instances from the UCF-
Crime’s test set where the original annotations do not la-
bel frames as anomalous, despite their actual anomalous
nature. Wealsoprovideacomparisonoftheproposedand
originalannotationssuperimposedonthevideosatthislink:Table6.Comparisonwithpriorworksinopen-setsettingonUCF-Crimedataset;cdenotesthenumberofanomalousclassesincludedfor
weakly-supervisedtraining.ThevaluesrepresentAUC(%).
c 0 1 3 6 9
Conv-AE[14] 50.60 - - - -
Sohrabetal.[31] 58.50 - - - -
Unsup. Luetal.[22] 65.51 - - - -
BODS[36] 68.26 - - - -
GODS[36] 70.46 - - - -
Wuetal.[38](offline) - 73.22 75.15 78.46 79.96
Wuetal.[38](online) - 73.78 74.64 77.84 79.11
RTFM[33] - 75.91 76.98 77.68 79.55
Weakly-Sup.
Zhuetal.[49] - 76.73 77.78 78.82 80.14
Ours(w/oCDL) - 75.17 81.51 82.97 83.02
Ours - 77.45 82.57 83.44 83.37
https://rb.gy/4vkr1r.
11.Limitations
Similartosomerecentweakly-supervisedVADworks[11,
20, 42], the training process of the proposed CDL frame-
work involves two stages. Consequently, the training does
not operate in an end-to-end manner. This incurs addi-
tional complexity and challenges for training the model
in real-world applications. However, since the generaliza-
tion obtained using this multi-stage training is significant,
the complex training setup of the multi-stage framework
isreasonable. Nonetheless,developingend-to-endtraining
frameworks would be an important direction for future re-
search. Thiscanfacilitatetheadvancementofanomalyde-
tectionapproachesforreal-worldapplications, particularly
theoneswithlimitedtrainingbudgets.
Additionally, the cross-domain performance in case of
drasticdistributionshiftsbetweenthesourceandtargetdo-
mains may be hindered. For instance, a model primarily
trainedonvideosfromstationarysurveillancecamerasmay
noteffectivelyworkonvideoswithrapidlyevolvingscenes
fromcardashcams. Thisismainlybecausetheuncertainty-
basedreweighingapproachinourframeworkaimstoselect
samplesfromtheexternalsetthataresimilartothesource
domain. Incaseofdrasticshiftsbetweenthetwodomains,
finding informative samples from the target domain would
notbetrivial.