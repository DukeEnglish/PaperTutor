One-Shot Manipulation Strategy Learning
by Making Contact Analogies
Yuyao Liu1,2∗, Jiayuan Mao1∗, Joshua B. Tenenbaum1, Toma´s Lozano-Pe´rez1, Leslie Pack Kaelbling1
1Massachusetts Institute of Technology
2Institute for Interdisciplinary Information Sciences, Tsinghua University
liuyuyao21@mails.tsinghua.edu.cn {jiayuanm,jbt}@mit.edu {tlp,lpk}@csail.mit.edu
Abstract—Wepresentanovelapproach,MAGIC(manipulation for one-shot manipulation strategy learning. Shown in Fig. 1,
analogies for generalizable intelligent contacts), for one-shot given a single reference action trajectory (e.g., using a hook
learning of manipulation strategies with fast and extensive
to reach for a distant object) and a novel scenario (e.g.,
generalization to novel objects. By leveraging a reference action
with different tools and different objects), the goal of the
trajectory,MAGICeffectivelyidentifiessimilarcontactpointsand
sequencesofactionsonnovelobjectstoreplicateademonstrated algorithm is to generate a sequence of robot actions that
strategy,suchasusingdifferenthookstoretrievedistantobjects apply a “similar” strategy to the test objects specified by
of different shapes and sizes. Our method is based on a two- users: in this example, having the target object moving along
stagecontact-pointmatchingprocessthatcombinesglobalshape
a certain direction for a given distance. MAGIC extends two
matching using pretrained neural features with local curvature
critical insights into a broad class of manipulation strategies.
analysistoensurepreciseandphysicallyplausiblecontactpoints.
We experiment with three tasks including scooping, hanging, First, many strategies such as hooking, hanging, hammering,
andhookingobjects.MAGICdemonstratessuperiorperformance pushing, reaching [9], [10], stacking, pouring [11]–[13], and
over existing methods, achieving significant improvements in cutting [13] can be characterized by a sequence of contact
runtime speed and generalization to different object categories.
waypoints (i.e., the order in which contacts between objects
Website: https://magic-2024.github.io/.
and robot bodies are made); second, these contacts are
I. INTRODUCTION characterized by forceful affordances between object pairs: a
specific pair of contact points on two objects would enable
A hallmark of human intelligence is flexible tool use:
the application of forces along certain directions. However,
humans can quickly acquire new manipulation “strategies”
searching for contact points that would enable the specific
from just a handful of demonstrations and apply these
affordanceisgenerallychallengingduetocomplexconstraints
strategiesacrossvariousscenarios,includinggeneralizationto
on reachability, collision avoidance, and motion stability.
novelobjectsofunseencategories.Forexample,asillustrated
MAGIC tackles these challenges by combining data-driven
in Fig. 1, even from a single demonstration of using a hook
and analytic approaches to generate contact waypoints in
to reach distant objects or putting hangers on a rod, we can
novel scenarios. In particular, it first extracts the sequence
generalize to different object positions, sizes, and diverse
of contacts among objects in the reference trajectory and
categories, such as hangers and mugs.
then proposes (pairs of) contact points that have similar
Traditionally, two main approaches have been widely
global and local shape properties as the contact points in the
studied to build machines that can flexibly use tools: model-
reference,whichcanbeusedasguidanceformotionplanning
based and analytic approaches which take novel scenarios
or motion retargeting. Finally, it utilizes a physical simulator
and goals and use built-in physical models to compute
to discard trajectories that fail to achieve the goal due to
plans [1]–[4], and policy learning, which leverages various
collisions, unstable physical contact, or violations of joint
typesofpriors(e.g.,object-basedandpart-basedmodels)and
andtorquelimits.Ourkeyinnovationliesinanovelglobal-to-
pretrainedneuralfeaturesforgeneralization[5]–[8].However,
local matching algorithm to find functional correspondences
both approaches have their limitations. Model-based planning
between the target objects and reference objects. Intuitively,
generalizes well given accurate object and physical models.
a “good” contact point would satisfy both a global and a
However,itisslowandusuallydoesnotbenefitfromlearning.
local matching property. First, the points on two objects
Policy learning approaches, on the other hand, are very
should be on similar parts of the global shape (e.g., in the
efficient at performance time but usually exhibit limited
hook-using example, we need a contact point on the tool that
generalization to novel objects and scenarios, particularly
is at the end of a long rod). Second, the hooking contact
when the shape of the novel objects differs significantly
point should have a matched local curvature with the target
from objects seen during training, such as generalizing from
objectbeinghookedsothatwecanexecutetheactionsstably.
hangers to mugs.
Therefore, we propose to use a pretrained visual feature-
In this paper, we present a novel approach, MAGIC
basedcorrespondencematchingtoresolvetheglobalmatching
(manipulationanalogiesforgeneralizableintelligentcontacts),
property. This enables us to quickly search over different
parts of the objects but the resulting contact point is usually
*indicatesequalcontribution.WorkdonewhileYuyaoLiuwasavisiting
studentatMIT. not precise. Next, we use a local curvature-based matching
4202
voN
41
]OR.sc[
1v72690.1142:viXraHanging
Single MAGIC Diverse Novel
Demonstration Scenarios
Hooking
Contact Global & Local Analogy
Extraction Matching Making
Fig.1:WeintroduceMAGIC(ManipulationAnalogiesforGeneralizableIntelligentContacts),apipelinethatiscapableoflearningmanipulationstrategies
fromsingledemonstrationsandapplyingthemtonovelobjects.
algorithmtofindthebestcontactpointwithinalocalregionof or extensive in-domain datasets. In contrast, our approach
the previously proposed contact point, which gives us precise integrates the off-the-shelf visual models, pretrained on gen-
and physically plausible (e.g., collision-free and physically eral image datasets, with the generic geometrical property of
stable) contacts. curvature.Thiscombinationallowsustoachieveeffectiveand
Overall, MAGIC tackles the problem of one-shot manip- efficienttool-usingguidancewithminimalhumanintervention
ulation strategy learning by making analogies in contact and without the need for large specialized datasets.
waypoints. We validate the effectiveness of our approach
on three challenging tasks: scooping a ball against a concave III. ONE-SHOTMANIPULATIONSTRATEGYLEARNING
arc with a spoon, hanging a mug onto a mug tree, and
We propose MAGIC (manipulation analogies for general-
using tools to hook objects of varying sizes. Compared to
izable intelligent contacts), a novel approach for fast and
global shape-matching algorithms, our framework achieves
generalizable manipulation strategy learning from a single
significant improvements when the reference objects are
demonstration. Fig. 2 shows the overall framework. First, we
from different categories than the test objects. Compared
extract the contact points among objects from the reference
to local shape-matching and simulation-based approaches,
trajectory. Subsequently, we find the candidate contact points
our framework is orders of magnitude faster — for most
that support the functional affordances on unseen test objects
test objects, we need to run simulations on fewer than three
through a global-to-local matching process, in which we
candidate contact points to find a solution. Finally, compared
first perform coarse correspondence point matching using
to pretrained feature-matching-based approaches, our method
pretrained vision transformer (ViT) features DINOv2 [38]
finds more precise and physically plausible solutions.
(SectionIII-B),followedbyalocalalignmentbasedonshape
curvatures to find stable local contact patches (Section III-C).
II. RELATEDWORK
Finally,thecandidatecontactpointsandtheirmatchingscores
Our algorithm is inspired by contact-based modeling canbeusedfortoolselection,forretargetingreferenceobject
techniques used in robotic manipulation. Various approaches trajectories, or as waypoints for motion planning (Section III-
have been developed for planning manipulations in contact D). The generated trajectories will be verified in a physical
space, involving both rigid bodies and robotic hands [14]– simulation and then output to the robot for execution.
[22]. Techniques such as CMGMP [1], [2], [23] and the
A. Problem Definition
work of [3] perform search over the exponential space of
possible contact sequences to determine possible contact We introduce the task of one-shot manipulation strategy
modes using three basic types: fixed, separating, and sliding learning. Specifically, we start with a single demonstration
contact, while [4] learns the types of the contact sequence involving the SE(3) trajectories of objects that execute a
from a single demonstration to guide the planning around particular manipulation strategy to achieve a goal (e.g.,
them.Bycontrast,inthispaper,wefocusonleveragingglobal hanging a hanger) in the reference scene. Our goal is to
andlocalshapematchingtogenerateanalogicalcontactpoints generatethetrajectoriesofobjectsinatargetscenethatapply
using a single demonstration, which significantly improves a similar manipulation strategy to a different object (e.g.,
the runtime efficiency of existing methods as well as the attaching a mug to a mug tree). We simplify this problem by
generalizations to unseen objects. assuming the robot is only manipulating one of the objects
Recently, researchers have explored learning object af- (i.e., the “tool” that the robot is holding), and the desired
fordances [9], [11], [24]–[28], usually from a large set of motion can be explained by achieving a sequence of contact
demonstrations. In contrast, this paper focuses on generating waypoints.Manyrigid-bodytool-usingtaskssuchashooking,
trajectories with novel objects from a single demonstration poking,stacking,andfunneling,allfallintothiscategory.For
leveraging pretrained visual features and shape analysis now,weassumethatthestrategytoapplyandthemanipulanda
algorithms, requiring no additional training data. in both the reference and target scenes (e.g., the hanger or
For many years, people have attempted to harness shape the mug) are already identified, and later we will discuss
informationtoguidetoolusagethroughmathematicalanalysis strategies for selecting the best tool object to accomplish a
[29]–[33] and data-driven approaches [5], [10], [34]–[37]. certaintask.Therefore,theproblemcanbecastasmakingthe
Thesemethodsoftennecessitateintricatehumanspecifications analogy between the reference object motion and the targetMotion Retargeting Simulation
Reference / Motion Planning & Selection
Demonstration
Contacts
( , )
Global Matching Local Matching Candidate Object and Robot Control
Novel Scene Target Objects w/. DINO Features w/. Curvature Scores Robot Trajectories Commands
(a) Contact Extraction (b) Global and Local Contact Point Matching (c) Motion Retargeting and Simulation
Fig.2:TheoverallpipelineofMAGIC.(a)Wefirstextractcontactpointsfromthereferencetrajectory.(b)Then,wecomputeaglobalandlocalcontact
pointmatchingscoretoselectcandidatecontactpointsonnovelobjects.(c)Thegeneratedcontactpointswillbeusedformotionretargetingormotion
planning,andthefinalmotionwillbesimulatedandverifiedbyaphysicalsimulator.
object motion, taking into consideration other environmental automatically extracted using the contact information in
constraints such as robot reachability and collisions. simulation and will be manually annotated for real-world
Based on our insights into decomposing manipulation objects(theycanalsobeautomaticallyrecoveredusingvideo-
trajectories into contact point sequences, this task further based contact point detector such as [39]). After generating
reduces to establishing a functional correspondence between top candidates for p T′ and p O′ based on score, for additional
the demonstrated object and the novel object, which can be validation, we will simulate the computed trajectory with the
represented as an SE(3) transformation between two rigid target object and select the first one that succeeded in the
bodies for each contact waypoint. For tasks considered in taskinsimulation.Alltasksstudiedinthispaperinvolveonly
this paper, we only consider scenarios where there is a stable quasi-static motion. Therefore, they can be simulated
single contact waypoint responsible for the target motion using mild assumptions on point clouds, uniform object
(but it generalizes to finding correspondences in multiple densities, and frictions. When the simulation is unavailable
waypoints), and there is a reduced degree of freedom that in challenging dynamic tasks (e.g., hammering), we fall back
can be reasoned about in 2D. In particular, we only model to using the highest-scoring contact match.
contactsonacanonical2Dcross-sectionalviewoftheobjects.
B. Global Contact Point Matching with Pretrained Features
For example, when we consider hooking objects on a table,
we only consider object motions and shape properties on the The global matching score s dino is only computed between
surface that is perpendicular to the table’s surface normal. the tool objects T and T′. In this stage, we will find a candi-
This is equivalent to assuming access to a canonical pose of date set of contact points “globally” on the target object T′,
the object: for hooks, this will be the top-down view when leveraging visual features pretrained on large image datasets
the hook is placed on the table; for mugs, this will be the for capturing global and semantic correspondences [40].
side view that contains the handle of the mug. In this paper, Specifically, we adopt DINOv2 [40] as our visual feature
we assume that this canonical view is given, and in general, extractor. Fig. 3a shows the pipeline: we first extract visual
it can be predicted by external modules. Therefore, now, our features for both objects (with different image rotations and
goal is to establish a single correspondence between two 2D reflections) and then find a candidate set of matching points.
images of the objects in E(2) (translations, rotations, and Feature extraction. We feed I T and I T′ into DINOv2
reflections in 2D) plus scaling; and then we can recover the respectively, and get feature maps F T and F T′. In practice,
SE(3) correspondences based on the canonical object poses. to eliminate the effects of rotation and reflection in 2D, we
Overall,theinputto MAGIC isanimageI T ofthereference apply horizontal flips and 12 rotations on I T′ and get a total
of24images{Fi }24 .Next,weapplyaprincipalcomponent
object T, an image I T′ of the target object, and a point T′ i=1
analysis (PCA) on the feature vectors. Given feature maps
of interest p on the reference image. Our goal is to find
T F ,Fi ∈Rn×n×d, let flatten(F) be flattened version of F in
t oh be jecc to srr ie ns tp eo ran cd ti in ng g:p to hi ent top oT l′ oo bn jecI T t′. TW bh eie nn gw de ireh ca tlv ye ht ew ldo RT n2×T d′ ,wehaveW=PCA d,d′(cid:8) flatten(F T),{flatten(F Ti ′)}2 i=4 1(cid:9) ,
by the robot (e.g., the hook) and another object O in contact where n is the spatial resolution, d and d′ are the original
with T (e.g., the target object we want to hook), our goal feature dimension and the feature dimension after reduction,
w onou Il Od
′
gb ie veto
n
tfi hn ed rea fec ro en nt ca ect (Tp ,o Oin ,t pp Ta ,i pr Op )T t′ hao tn mI T ax′ ia mn id zep sO a′ r ce os mpe pc ot niv ee nl ty v, ea cn tod rs.W Th∈ eR oud t× pd u′
t
i is
s
F(cid:101)th =e Fm ×at Wrix ∈o Rf n×p nri ×n dc ′i .pal
score function: score(X,X′), where X =(T,O,p ,p ) is the Matchingbypatches.Next,weaggregatethefeatureswithin
T O
reference contact and X′ = (T′,O′,p T′,p O′) is the target a local region (instead of a single point) so as to increase the
contact. In this paper, we employ a two-stage global-to- receptive field. Formally, let patch(p) denote the m×m local
local matching process, therefore, the score function will area centered at point p, we find a point across all rotations
be composed of two parts: a global matching score s dino, and of the target image p T′ that maximizes the patch-aggregated
a local matching score s curv: cosine similarity with the reference point p T:
score(cid:0) X,X′(cid:1) =s dino(T,T′,p T,p T′)+λ·s curv(X,X′), s dino(cid:0) T,T′,p T,p T′(cid:1) = ∑ (cid:68) F(cid:101)T(p),F(cid:101) Ti ′(p′)(cid:69) .
p∈patch(pT),
where λ is a constant hyperparameter. p O and p T are p′∈patch(p T′)(a) Phase 1: Global Contact Point Matching (b) Phase 2: Local Contact Point Matching
Contact
Point
Observation Motion Func. Scale
Scale Pyramid
Demonstration
Functional
Novel Object Multi Rotation & Reflection Alignment
Fig.3:GlobalandLocalContactPointMatching.Thecontactpointmatchingprocessconsistsoftwophases:(a)globalmatchingusingDINOv2[38]
features;(b)localmatchinginvolvingmulti-scalecurvatureestimationandrefinementsusingirrelevantpointsuppressionandconvexitymatching.
W pee rfos re mlec tt heth le oct ao lp ck on= tac3 tm poa it nc the ms atw chit ih ngth ie nh thig eh ne es xt ts sd tin ao get .o
C
SO cb aj le ec 1t Edge ΔC C R Ce of ne cr ae vn ece: I Cn oit ni va el xMatch:
Curvature 1 S O’
Scale 2 Adjusted
Curvature 2 Match:
C. Local Contact Point Matching with Curvature Estimation O Concave
(a) Observing Scale (b) Irrelevant Point Suppression(c) Convexity Matching
Although DINOv2 can propose contact points within a Fig.4: (a)Theobservingscaleatwhichweperformestimationhaseffect
onboththemagnitudeandthesignofheestimatedcurvature.(b)Filtering
coarse global region, it is not accurate enough in terms
outtheirrelevantpointscangiveamoreaccuratecurvatureestimation.(c)
of local geometric properties to support collision-free and Weperformlocalsearchwithintheobservationregiontofindthecontact
stable physical motion. We leverage curvatures to refine pointwiththecorrectconvexity.
the correspondence matching. Illustrated in Fig. 3b, our the tool object T′ and target object O′, we define the local
local alignment has four steps. We first construct a multiple matching score as:
observation scale pyramid: we estimate the curvatures of (cid:12) (cid:12)
t bh ye Dre If Ner Oen vc 2e oc non thta ect tap ro gi en tt oa bn jd ect the atc mon ut la tc ipt lepo si cn at lep sr .op To hs ee nd
,
s curv(cid:0) ⟨T,O,p T,p O⟩,⟨T′,O′,p T′,p O′⟩(cid:1) =(cid:12) (cid:12) (cid:12)rr (( pp OT) )− rr (( pp OT′ ′) )(cid:12) (cid:12) (cid:12).
based on the normal direction and the sign of the estimated Irrelevant point suppression and convexity matching.
curvatures, we perform irrelevant point suppression and Direct application of the curvature estimation algorithm is
convexity matching to find a physically plausible contact not robust enough for two reasons. First, the choice of the
point for each scale. After that, we repeat the curvature observationscalewillsignificantlyaffecttheestimationofthe
estimation process on the updated contact points to get a curvature.AsillustratedinFig.4a,selectingaverysmallscale
more accurate curvature and normal direction. Finally, we (scale 1) will make the estimation sensitive to local noise.
accept the best contact point across scales. Second, for large observation scales, irrelevant points (i.e.,
Curvature estimation at a given scale. Given an image points on a different “edge” of the object) will be included
of the object with segmentation, we first use the Canny and inject noise in the estimation, especially for thin objects
edge detector [41] to get the object edges. We define the as shown in Fig. 4b.
observation scale as the radius of the region centered at Toeliminatetheseirrelevantpointsaroundthecontactpoint
the point of interest (e.g., the contact point) on the object of interest, we compute the curvature twice. First, we include
edge. For a certain observation scale s of the point c, we all points within the observation scale. After computing the
can use the edge points {(x,y)}n inside s to estimate the initial contact point C on the edge of the object and its
i i i=1
magnitude κ of the curvature and the radius of curvature r. curvature, we pick a point S that is at a small distance ∆
Specifically, we first find the direction x′ with the largest from the contact point C along the direction of the radius
−→
variance on {(x,y)}n , and construct a local coordinate of curvature CO in the initial estimation. Then, we select
i i i=1
system x′y′ centered at c, then represent {(x,y)}n in x′y′ all points on the same “edge” as C on the side of S. This
i i i=1
to get {(x′,y′)}n . Afterwards, we fit a parabola y′=ax′2 is done by emitting “rays” in all directions from S and for
i i i=1
on points {(x′,y′)}n , i.e., each ray selecting the point that is hit first. We then use
i i i=1
these points to estimate the curvature again, as shown on the
n
a=argmin∑(cid:0) y′−ax′2(cid:1)2 , right of Figure 4b. Moreover, we ensure that the curvature
i i
a i=1 sign (i.e., the convexity) of the corresponding point in the
target image is consistent with that in the reference image
thenbythedefinitionofcurvature,wehaveκ=2|a|,r=1/κ..
Now, for a pyramid of observation scales {s }m , we can by performing a local search within the observation region
compute a series of radii of curvature {r }m j . Tj= h1 e motion of the target image, which is depicted in Fig. 4c.
j j=1
functionalscaleisdefinedass j,where j=argmin j′(cid:12) (cid:12) (cid:12)s rj j′
′
−α(cid:12) (cid:12) (cid:12), D. Generating Object Motions by Making Contact Analogies
whereα isaparameter,andinpractice,weselectα=3.5for So far we have presented a general mechanism for finding
all objects across all experiments. This constant corresponds geometric functional correspondence between reference and
to a scenario where the observation scale is similar to the target objects, and it can be used in many downstream
radius of curvature estimated using the points inside the modules. In the one-shot manipulation strategy learning
observationscale.Furthermore,thesignofthecurvature(that setting, we consider three particular use cases.
is, whether the point on the curve is convex or concave) can Object motion retargeting. This is the most straightforward
be computed based on the mask of the object. Given both way to generate target object motions assuming there is
DINOv2
PCA Patch
Curvature
Estimation
Refinementa single contact that accounts for the motion. Given the Scooping Hanging Hooking
Method
reference contact point p T, the direction vector v of the FG Arm FG Arm NoToolSel. FG Arm
view angle, the normal vector n T of p T estimated from PCA 27.6 16.7 0.0 0.0 5.0 0.0 0.0
curvature calculation, we can construct two local frames FPFH+ICP 32.9 27.2 0.0 0.0 6.7 0.0 0.0
DINO Matching 55.7 41.4 23.9 21.6 49.2 66.7 24.0
for the reference and the target object, and directly retarget
Curvature-Only 13.9 5.6 68.7 38.1 60.0 76.7 3.3
the reference object motion by aligning two local frames. MAGIC 94.4 65.4 92.9 84.3 65.0 100 63.3
Motion planning based on contact waypoints and force
TABLEI:Averagesuccessrates(%)of3tasks.‘floatinggripper(FG)’
directions. We can generate object motion by leveraging indicatesmanipulationbydirectlysettingpositionsandvelocitiesofobjects,
analogical contact points as waypoints for a motion planner. focusingonlyonobject-objectinteractions,excludingtherobot.Allmethods
exceptforCurvature-Onlyrunalmostdeterministically.Curvature-Onlyhas
For example, if our goal is to hang an object at a particular
anaveragestd.of6.6%.
position, we can first compute the hanging pose by making DINO matching which directly finds the best functional
analogies with the reference object pose and use a collision- correspondencebasedontheDINOv2features,andcurvature
free motion planner to generate the robot motion. This also matching which uses the random contact point sampling
applies to hook-using tasks where the goal is specified as to method from [4] and applies the curvature filtering algorithm
apply a particular force along a target direction on an object. from MAGIC to rank all contact points. Since this method
Tool selection. Our pipeline also supports tool selection, involves random sampling of contact points and simulation,
wherethegoalistoselectone“tool”object(e.g.,ahook)from we cap its runtime to 180 seconds and use the contact point
a set of available objects that can best execute the strategy with the highest matching score found at that time. Note that
in the new scenario, given the other object to manipulate allmethodsexceptforthesampling-basedcurvature-matching
(e.g., the object to be hooked). We apply our algorithm on algorithm have very small variances across different runs
all available tools, and select the tool with the highest score. (our algorithm is almost deterministic). Therefore, we do
not include performance variances for different methods. We
IV. EXPERIMENTS
do not compare with methods such as NDF [5], KETO [9],
In this work, we have conducted experiments both in and GIFT [10] in the main experiment, because they assume
simulation and in the real world. For simulation experiments, access to a fairly large dataset of 3D object models for
we adopt the simulation environment SAPIEN 2 [42] using a representation learning, but we provide a case study of
Franka Emika Panda arm. We evaluate different one-shot comparing MAGIC with KETO in Table IV.
manipulation strategy learning algorithms on three tasks,
A. Experiment Results in Simulation
as shown in Fig. 9: (Scooping) scooping balls of different
sizes with various spoons against a concave arc, given a Table I summarizes the overall performances of variants
demonstration with a reference spoon; (Hanging) hanging of our methods and other baselines. The success rates are
a mug onto a mug tree, given a demonstration of hanging a computed over 6 spoons and 3 objects for Scooping, 134
hangeronarod;(Hooking)selectingatoolfromasettohook mugsforHangingadoptedfrom[5],and4toolsand5objects
objects of varying shapes and sizes, given a demonstration for Hooking adopted from [4]. Overall, our model MAGIC
of hooking a ball with a hook. To generate object motions, performs the best. We break down our analysis into the
we adopt object motion retargeting for Scooping and motion following bullet points.
planning for Hanging and Hooking from Section III-D. For Local shape matching can significantly improve perfor-
alltasks,wehavetwovariants:Floating-Gripper(FG)where mance over global shape matching. We compare MAGIC
the tool will be manipulated by a floating gripper, and the withglobalshapematchingmethods,PCAandFPFH+ICP.As
harder Arm variant where the tool needs to be grasped and showninTableI,globalshapematchingisineffectivebecause
manipulated by the robot. In this variant, we use a general it lacks an understanding of the local contact points. Fig. 5(a)
antipodal grasp sampler [43] and RRT-Connect [44] for illustrates an example of the correspondence established by
generating robot trajectories, of which we utilize MPlib [45] global shape matching (left) and MAGIC (right). To further
as the implementation. For Hooking, we also have a variant demonstrate the effectiveness of local shape matching, we
where we provide a random tool to the floating gripper also provide an additional study on the mug-hanging task in
(no tool selection). For all tasks, we only provide a single Table II, where the demonstration includes the trajectory of
demonstration of object motion trajectories, the canonical hanging a held-out mug on the mug tree (i.e., intra-category
view, and the pair of contact points on reference objects. transfer), rather than the hanger. In this setting, FPFH+ICP
Baselines. We implemented two sets of baselines: global achievesasuccessrateof41.1%(c.f.94.0%for MAGIC).The
shape-matchingandlocalshape-matchingmethods.Forglobal resultsindicatethatPCAandFPFH+ICP(aswellastheDINO
shape-matching methods, we use two different methods: matchingalgorithm)cansometimessuccessfullyachieveintra-
principal component analysis (PCA) and iterative closest category transfer by aligning overall shapes. However, they
point with FPFH features (FPFH+ICP) [46]–[48] on object perform poorly at inter-category transfer due to the lack of
point clouds to find the best transformation that would align local contact point alignment. By contrast, MAGIC excels in
the target object and the reference object. Then, we retarget both intra-category and inter-category transfers by accurately
the object motion or transform the waypoints. For local identifying contact points that satisfy both global and local
shape-matchingbaselines,wealsoimplementedtwomethods: constraints.Wrong: curvature
Directly uses local DINOv2
Wrong:
surface normal
Point on the
causes collision
“outer” edge
Global Shape Matching (FPFH+ICP) MAGIC
(a) Effectiveness of Local Shape Matching (b) Failure cases of direct application of DINO (c) Effectiveness of pretrained DINOv2 features
Fig.5:(a)Globalshapematchingfailstoprovideeffectivefunctionalalignmentduetothelackofawarenessoflocalcontactpoints.(b)Localcurvature
helpsidentifymoreaccuratecontactpointsandcontactnormals.(c)PretrainedDINOv2featuresenhancedataefficiencybyselectingtheoptimalcontact
(theredstar)andgraspingpointsfromthosethatcurvaturealonecannotdistinguish(thegreenregion).WealsovisualizetheDINOv2matchingheatmaps.
PCA FPFH+ICP DINOMatch Curvature-Only MAGIC modelstructures,DINOv2usesVisionTransformer(ViT)[51]
Hanging(intra-cat.) 5.2 41.1 64.9 67.9 94.0 with an attention mechanism applied to patches of the input
Hanging(inter-cat.) 0.0 0.0 23.9 68.7 92.9
image, whereas diffusion models are based on U-Net [52]
TABLEII:Averagesuccessrates(%)ofHanging(intra-categorytransfer
and process the input and output as full-resolution images,
vs.inter-categorytransfer).WhilePCAandFPFH+ICPcanoccasionally
achieveintra-categorytransfer,theyfailtoperforminter-categorytransfer. requiring more computation time.
TheexperimentsareconductedontheFGvariant.
Local curvature matching is crucial, in addition to Method Scooping Hanging Hooking Avg.Time
pretrained features. The comparison between MAGIC and MAGIC(DIFT+Curvature) 62.2 81.3 100 60.8s
MAGIC(SD-DINO+Curvature) 73.8 91.8 96.0 50.7s
othermethodsthatdonotuselocalcurvatureinformation(e.g., MAGIC(DINOv2+Curvature) 94.4 92.9 100 34.0s
PCA, FPFH+ICP, and DINO Match) shows the importance
TABLEIII:Additionalstudiesonthechoiceofpretrainedimagefeatures.
of local curvature matching. As an illustration, as shown in WesubstituteDINOv2withSD-DINO[40]andDIFT[51].Wepresentthe
Fig.5(b),thecontactpointsproposedsolelybythepretrained averagesuccessrates(%)andaveragetimeconsumedofthemethods.The
experimentsareconductedontheFGvariant.
model are likely to fail due to incorrect curvature sign and
incorrect interaction direction. By contrast, MAGIC leverages Further comparison with dataset-dependent methods.
localcurvatureinformationtoidentifytheappropriatecontact KETO[9]andGIFT[10]introducekeypointsastheguidance
points and correct force direction through the curvature for tool-using strategies and utilize self-supervised learning
estimation.Moreover,ontheHookingtask,pairwisecurvature onthepositivesamplesobtainedfromtrial-and-errorwiththe
matching plays an important role in selecting the most tools from a large tool dataset. While MAGIC also introduces
appropriate tool for different objects, as shown in the a similar concept, contact points, we propose to consider
comparison between the No Tool Sel. and the FG variant in contacts as pairs of contact points. In contrast, keypoints
the hooking task. only focus on the tool object. Moreover, both KETO and
Using pretrained features as guidance significantly im- GIFT need a dataset of tools, while MAGIC only requires one
proves contact point selection. In Table I, MAGIC shows single demonstration and can be generalized to tools with
superior performance over the sampling-based curvature very different shapes.
matching algorithm. In principle, without noise in curvature In Table IV, we provide additional experiment results
computation and given a sufficient number of sampled points, comparing MAGIC with KETO over the Hammering and
the curvature-based method would be capable of finding the Pushing tasks from KETO. Since KETO requires a decently
best contact. However, it will be very slow (e.g., in [4], the large dataset of tool meshes to perform self-supervised
authors set the timeout to 600 seconds for the search). In this learning, which is not available for those tasks in our main
work, we leverage the global and semantic correspondence experiment, we perform experiments on their tasks. The
provided by DINOv2 features to reduce the searching space single demonstration for MAGIC is composed of an image
of local geometry matching. In Fig. 5(c), we visualize how of a reference hammer taken in the simulator and the pixel
pretrained DINOv2 features can improve data efficiency by coordinates of the function point and the effect point. The
identifyingthebestcontactandgraspingpointsthatcurvature results indicate that MAGIC outperforms KETO on both tasks.
alone cannot differentiate. To further investigate the generalizability, we provide the
Moreover, we provide additional comparison of different success rate of transferring from hammers to hammers and
pre-trained features such as DIFT [49] and SD-DINO [40] in non-hammers, respectively. For both intra-category and inter-
Table III. The results indicate that DINOv2 not only provides category generalization, MAGIC performs better than KETO.
betterguidanceforshapematchingbutitalsorunsfaster.This Ablationstudies.TableVprovidesadditionalablationstudies
difference can be attributed to the distinct pretraining tasks ondifferentdesignchoicesofourmethod MAGIC.First,there
and model architectures of DINOv2. DINOv2 employs self- is a significant performance drop observed in the scooping
supervised learning techniques, involving contrastive learning
Hammering Pushing
and a teacher-student training paradigm, where the teacher
Method Hammers→ Hammers→
Average Average
network has access to global views and distills knowledge Hammers Non-hammers
to the student network — which has access to both global KETO 66.4 46.3 56.4 71.7
MAGIC 75.6 53.7 64.4 76.3
and local views [38]. This approach enhances the model’s
TABLE IV: Comparison between MAGIC and KETO [9] (Learning
understanding of global information. By contrast, diffusion
KeypointRepresentationsforToolManipulation).Wepresenttheaverage
models are trained on generation tasks through a denoising successrates(%).Wealsoinvestigatetheintra-categoryandinter-category
process,whichfocusesmoreonlocaltextures[50].Regarding generalizablityofMAGICandKETO,indicatedbyHammers→Hammers
andHammers→Non-hammers,respectively.Method Scooping Hanging Hooking Avg.Time 80
DINO Matching 77
DINOMatching(BestBaseline) 55.7 23.9 66.7 12.4s 60 Curvature-Only 65
MAGIC(DINOv2+Curvature) 94.4 92.9 100 34.0s 40 MAGIC 50 48
(w/o.FeaturePCAandPatch) 71.7 93.3 62.0 33.8s 37
(w/o.Two-StepCurvature) 83.3 53.7 75.6 14.1s 20 27
(w/o.SimulationVerification) 77.8 71.6 50.0 19.7s
0
Hanging Hooking
TABLEV:Ablationstudies.Wepresenttheaveragesuccessrates(%)and
Fig.7:Averagesuccessratesofreal-worldexperiments.
averageruntimeofallmethods,ontheFGvariant.
Franka Emika
Panda Arm
Camera 1 Camera 2
Hooking
(a) Hanging (b) Hooking
Fig.6:Real-worldexperimentsetup.
and hooking tasks if we remove feature PCA and patch-
Hanging
basedscoreaggregation.Thisdemonstratesthatbothmethods
reduce noise in the feature maps and improve the accuracy Fig.8:Contactpointmatchingresultsonreal-worldobjects.
of contact point matching. Second, we consider removing
highest performance, which validates the effectiveness and
the irrelevant point suppression and convexity matching.
practical applicability of MAGIC in the real world. We also
The model still surpasses vanilla DINO matching, which
illustrate the contact point matching found by MAGIC on
demonstrations the effectiveness of curvature estimation, but
more real-world objects in Fig. 8. For failure case analysis,
we see a clear performance drop compared with the full
please check out our project website.
algorithm MAGIC. Finally, we demonstrate that removing
additional geometric and physical feasibility checks based on
the simulator, and instead selecting only the trajectory with V. CONCLUSION
the highest matching score, results in a notable performance
decline. While our matching pipeline and motion generator
We have presented MAGIC, a framework for one-shot
manipulation strategy learning, enabling robots to quickly
can generate plausible contact points and actions, simulation
adapt and execute tool-using tasks with novel objects. We
verification remains essential to ensure that the executed
integrate both data-driven and analytical shape-matching
trajectory is collision-free and maintains physical stability.
algorithms for the best of both worlds, to quickly generate
B. Real-World Experiments precise and physically plausible contact points. Noteably,
To evaluate the effectiveness of MAGIC in real-robot our algorithm is generic in the sense that we do not need
systems,weconductedexperimentsonHangingandHooking task-specific information for the matching algorithm other
utilizingaFrankaEmikaPandaarmwithaparallelgripper,as than the reference contact waypoints. Experiments on three
depicted in Fig. 6. We capture the RGB and depth image of representative tasks illustrate the effectiveness of our method.
thescenewithtwoRealSenseD435cameras,whoseextrinsics Limitations. Currently, our pipeline is designed for making
are calibrated to the frame of the base link of the robot. contact analogies for a single contact patch between two
We perform contact point matching on the RGB image objects. Future work should consider interactions among
capturedbythecamera,thenimportareconstructed(possibly multiple objects with multiple contact points, and extend the
partial)objectmeshfromtheRGBDcameraintotheSAPIEN current shape-based matching criteria to consider forceful
2 simulator for motion retargetting, motion planning, and affordance. Another future direction would be to consider
verification. To reconstruct the mesh of the objects from the predicting or searching over 2D views of objects for corre-
RGBD image, we first use the Segment Anything model [53] spondence matching. Moreover, our overall framework of
to get the mask of the objects, and extract the corresponding coarse-to-fine and semantic-to-geometric matching can be
point cloud of each object. Then, we remove outliers with extended to 3D pretrained features [56]–[58] and curvatures.
DBSCAN [54] and select the cluster with the largest number Acknowledgements.Wegratefullyacknowledgesupportfrom
of points. We then perform object completion by projecting NSF grant 2214177; from AFOSR grant FA9550-22-1-0249;
the point cloud down to the table plane, and using Alpha from ONR MURI grant N00014-22-1-2740; and from ARO
Shape [55] to reconstruct the surfaces of the object mesh. grant W911NF-23-1-0034; from MIT Quest for Intelligence;
To provide a quantitative assessment, we perform a total fromtheMIT-IBMWatsonAILab;fromONRScienceofAI;
of 10 trials for each object. We report the success rates of and from Simons Center for the Social Brain. Any opinions,
various methods for Hanging across three visually distinct findings, and conclusions or recommendations expressed in
cups and Hooking across four tools from different categories, this material are those of the authors and do not necessarily
as shown in Fig. 7. MAGIC has consistently achieved the reflect the views of our sponsors.
)%(
etaR
sseccuSDemonstration Novel Scenes Novel Objects
Fig.9:Visualizationofdemonstrationsandnovelscenes/objects.Weevaluatetheabilityofone-shotmanipulationstrategylearningbyprovidingasingle
demonstrationforthreetasks:Scooping,Hanging,andHooking(showninthefirstcolumn),andthentestingonvariousunseeninstances.
APPENDIX
Visualization of novel scenes and diverse objects.InFig.9,
wepresentthedemonstrations,thenovelscenes,andexamples
of novel objects for each task.
1) Scooping: Demonstrated on a reference spoon and a
reference ball; evaluated on 4 spoons, a soup ladle, a
measuring cup, and 3 different balls.
2) Hanging: Demonstrated on hanging a hanger to a rod;
evaluated on hanging mugs to a mug tree [5]. where the
meshes of the mugs are adopted from ShapeNet [59]. We
filter out those meshes unsuitable for hanging (e.g., mugs
without handles), and use 134 mugs for evaluation.
3) Hooking: Demonstrated on hooking a reference object
with a hook; Evaluated on hooking 5 different cylinders with
4 tools (a pair of scissors, a hanger, a caliper, and a watch). Fig.12:TwoexampleepisodesofHanginginsimulation.
Visualization of trajectories for simulation tasks. In
Fig. 11, 12 and 13, we provide two example trajectories of
each task generated by MAGIC. Visualization of trajectories
for real-world tasks. We demonstrate an example trajectory
of Hanging and Hooking in Fig. 10.
Fig.13:TwoexampleepisodesofHookinginsimulation.
Additional Experiments on Hanging and Hooking with
the Alphabet Toolkit. To further showcase our method’s
ability to generalize across objects of varying shapes, we
Fig.11:TwoexampleepisodesofScoopinginsimulation. conducted additional experiments on Hanging and HookingFig.10:ExampleepisodesofHangingandHookingintherealworld.
Fig.14:VisualizationofHangingalphabetobjectsinsimulation(top)
andreal-world(bottom)settings.
tasks using the Alphabet Toolkit in both simulation and
real-world settings. Visualizations of these experiments are
Fig. 15: Visualization of Hooking with alphabet objectsin simulation
presented in Figures 14 and 15. Please visit our project (top)andreal-world(bottom)settings.
website for the videos of the additional experiments.
[12] M.Sieb,Z.Xian,A.Huang,O.Kroemer,andK.Fragkiadaki,“Graph-
REFERENCES StructuredVisualImitation,”inCoRL,2020. 1
[13] R.Xu,F.-J.Chu,C.Tang,W.Liu,andP.A.Vela,“AnAffordance
[1] X.Cheng,E.Huang,Y.Hou,andM.T.Mason,“ContactModeGuided KeypointDetectionNetworkforRobotManipulation,”RA-L,vol.6,
Sampling-BasedPlanningforQuasistaticDexterousManipulationin no.2,pp.2870–2877,2021. 1
2D,”inICRA,2021. 1,2 [14] J.C.TrinkleandJ.J.Hunter,“AFrameworkforPlanningDexterous
[2] ——, “Contact Mode Guided Motion Planning for Quasidynamic Manipulation,”inICRA,1991. 2
DexterousManipulationin3D,”inICRA,2022. 1,2 [15] X.JiandJ.Xiao,“PlanningMotionsComplianttoComplexContact
[3] T.Pang,H.T.Suh,L.Yang,andR.Tedrake,“GlobalPlanningfor States,”IJRR,vol.20,no.6,pp.446–465,2001. 2
Contact-RichManipulationviaLocalSmoothingofQuasi-Dynamic [16] M.Yashima,Y.Shiina,andH.Yamaguchi,“RandomizedManipulation
ContactModels,”T-RO,2023. 1,2 PlanningforaMulti-FingeredHandbySwitchingContactModes,”in
[4] J. Mao, T. Lozano-Pe´rez, J. B. Tenenbaum, and L. P. Kaelbling, ICRA,2003. 2
“LearningReusableManipulationStrategies,”inCoRL,2023.1,2,5,6
[17] G.Lee,T.Lozano-Pe´rez,andL.P.Kaelbling,“HierarchicalPlanning
[5] A.Simeonov,Y.Du,A.Tagliasacchi,J.B.Tenenbaum,A.Rodriguez,
forMulti-ContactNon-PrehensileManipulation,”inIROS,2015. 2
P. Agrawal, and V. Sitzmann, “Neural Descriptor Fields: SE(3)-
[18] I. Mordatch, E. Todorov, and Z. Popovic´, “Discovery of Complex
EquivariantObjectRepresentationsforManipulation,”inICRA,2022.
BehaviorsThroughContact-InvariantOptimization,”ACMTransactions
1,2,5,8
onGraphics(ToG),vol.31,no.4,pp.1–8,2012. 2
[6] W.Liu,J.Mao,J.Hsu,T.Hermans,A.Garg,andJ.Wu,“Composable
[19] K.HauserandJ.-C.Latombe,“Multi-ModalMotionPlanninginNon-
Part-BasedManipulation,”inCoRL,2023. 1
ExpansiveSpaces,”IJRR,vol.29,no.7,pp.897–915,2010. 2
[7] H.Huang,F.Lin,Y.Hu,S.Wang,andY.Gao,“CoPa:GeneralRobotic
Manipulation through Spatial Constraints of Parts with Foundation [20] J.-P. Sleiman, J. Carius, R. Grandia, M. Wermelinger, and M. Hut-
Models,”arXiv:2403.08248,2024. 1 ter, “Contact-Implicit Trajectory Optimization for Dynamic Object
Manipulation,”inIROS,2019. 2
[8] Y. Zhu, A. Lim, P. Stone, and Y. Zhu, “Vision-Based Manipula-
tion from Single Human Video with Open-World Object Graphs,” [21] B.Aceituno-CabezasandA.Rodriguez,“AGlobalQuasi-Dynamic
arXiv:2405.20321,2024. 1 ModelforContact-TrajectoryOptimizationinManipulation,”inRSS,
[9] Z.Qin,K.Fang,Y.Zhu,L.Fei-Fei,andS.Savarese,“KETO:Learning 2020. 2
KeypointRepresentationsforToolManipulation,”inICRA,2020. 1, [22] E.Huang,X.Cheng,Y.Mao,A.Gupta,andM.T.Mason,“Autogen-
2,5,6 eratedManipulationPrimitives,”IJRR,2023. 2
[10] D.Turpin,L.Wang,S.Tsogkas,S.Dickinson,andA.Garg,“GIFT: [23] J.XiaoandX.Ji,“AutomaticGenerationofHigh-LevelContactState
GeneralizableInteraction-awareFunctionalToolAffordanceswithout Space,”IJRR,vol.20,no.7,pp.584–606,2001. 2
Labels,”inRSS,2021. 1,2,5,6 [24] A. Gupta and L. S. Davis, “Objects in Action: An Approach for
[11] Z.Lai,S.Purushwalkam,andA.Gupta,“TheFunctionalCorrespon- CombiningActionUnderstandingandObjectPerception,”inCVPR,
denceProblem,”inCVPR,2021. 1,2 2007. 2[25] Y.Zhu,Y.Zhao,andS.-C.Zhu,“UnderstandingTools:Task-Oriented [52] O. Ronneberger, P. Fischer, and T. Brox, “U-Net: Convolutional
ObjectModeling,Learning,andRecognition,”inCVPR,2015. 2 Networks for Biomedical Image Segmentation,” in MICCAI, 2015.
[26] K. Fang, Y. Zhu, A. Garg, A. Kurenkov, V. Mehta, L. Fei-Fei, and 6
S.Savarese,“LearningTask-OrientedGraspingforToolManipulation [53] A.Kirillov,E.Mintun,N.Ravi,H.Mao,C.Rolland,L.Gustafson,
fromSimulatedSelf-Supervision,”IJRR,vol.39,no.2-3,pp.202–216, T.Xiao,S.Whitehead,A.C.Berg,W.-Y.Loetal.,“SegmentAnything,”
2020. 2 inICCV,2023. 7
[27] K. Mo, L. J. Guibas, M. Mukadam, A. Gupta, and S. Tulsiani, [54] M. Ester, H.-P. Kriegel, J. Sander, and X. Xu, “A Density-Based
“Where2act:FromPixelstoActionsforArticulated3DObjects,”in AlgorithmforDiscoveringClustersinLargeSpatialDatabaseswith
CVPR,2021. 2 Noise,”inKDD,1996. 7
[28] Y. Ju, K. Hu, G. Zhang, G. Zhang, M. Jiang, and H. Xu, “Robo- [55] H.Edelsbrunner,D.Kirkpatrick,andR.Seidel,“OntheShapeofa
ABC: Affordance Generalization Beyond Categories via Semantic SetofPointsinthePlane,”IEEETransactionsonInformationTheory,
CorrespondenceforRobotManipulation,”inECCV,2024. 2 vol.29,no.4,pp.551–559,1983. 7
[29] H. Asada and M. Brady, “The Curvature Primal Sketch,” IEEE [56] W.Shen,G.Yang,A.Yu,J.Wong,L.P.Kaelbling,andP.Isola,“Dis-
Transactions on Pattern Analysis and Machine Intelligence, no. 1, tilledFeatureFieldsEnableFew-ShotLanguage-GuidedManipulation,”
pp.2–14,1986. 2 inCoRL,2023. 7
[30] C. G. Jensen, W. E. Red, and J. Pi, “Tool Selection for Five-Axis [57] Y. Wang, Z. Li, M. Zhang, K. Driggs-Campbell, J. Wu, L. Fei-Fei,
CurvatureMatchedMachining,”Computer-AidedDesign,vol.34,no.3, and Y. Li, “D3Fields: Dynamic 3D Descriptor Fields for Zero-Shot
pp.251–266,2002. 2 GeneralizableRoboticManipulation,”inCoRL,2024. 7
[31] S.Brandi,O.Kroemer,andJ.Peters,“GeneralizingPouringActions [58] N.S.Dutt,S.Muralikrishnan,andN.J.Mitra,“Diffusion3DFeatures
BetweenObjectsusingWarpedParameters,”inHumanoids,2014. 2 (Diff3F): Decorating Untextured Shapes with Distilled Semantic
[32] D.RodriguezandS.Behnke,“TransferringCategory-basedFunctional Features,”inCVPR,2024. 7
GraspingSkillsbyLatentSpaceNon-RigidRegistration,”RA-L,vol.3, [59] A. X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang,
no.3,pp.2662–2669,2018. 2 Z.Li,S.Savarese,M.Savva,S.Song,H.Suetal.,“Shapenet:An
[33] O. Biza, S. Thompson, K. R. Pagidi, A. Kumar, E. van der Pol, Information-Rich3DModelRepository,”arXiv:1512.03012,2015. 8
R. Walters, T. Kipf, J.-W. van de Meent, L. L. Wong, and R. Platt,
“One-shotImitationLearningviaInteractionWarping,”inCoRL,2023.
2
[34] S. Thompson, L. P. Kaelbling, and T. Lozano-Perez, “Shape-Based
TransferofGenericSkills,”inICRA,2021. 2
[35] L.Manuelli,W.Gao,P.Florence,andR.Tedrake,“kPAM:KeyPoint
AffordancesforCategory-LevelRoboticManipulation,”inISRR,2019.
2
[36] W.GaoandR.Tedrake,“kPAM2.0:FeedbackControlforCategory-
LevelRoboticManipulation,”RA-L,vol.6,no.2,pp.2962–2969,2021.
2
[37] B.Wen,W.Lian,K.Bekris,andS.Schaal,“YouOnlyDemonstrate
Once:Category-LevelManipulationfromSingleVisualDemonstration,”
inRobotics:ScienceandSystems2022,2022. 2
[38] M.Oquab,T.Darcet,T.Moutakanni,H.Vo,M.Szafraniec,V.Khalidov,
P. Fernandez, D. Haziza, F. Massa, A. El-Nouby et al., “DINOv2:
LearningRobustVisualFeatureswithoutSupervision,”TMLR,2023.
2,4,6
[39] K. Ehsani, S. Tulsiani, S. Gupta, A. Farhadi, and A. Gupta, “Use
theForce,Luke!LearningtoPredictPhysicalForcesbySimulating
Effects,”inCVPR,2020. 3
[40] J.Zhang,C.Herrmann,J.Hur,L.P.Cabrera,V.Jampani,D.Sun,and
M.-H.Yang,“ATaleofTwoFeatures:StableDiffusionComplements
DINOforZero-ShotSemanticCorrespondence,”inNeurIPS,2023. 3,
6
[41] J.Canny,“AComputationalApproachtoEdgeDetection,”T-PAMI,
vol.PAMI-8,no.6,pp.679–698,1986. 4
[42] F.Xiang,Y.Qin,K.Mo,Y.Xia,H.Zhu,F.Liu,M.Liu,H.Jiang,
Y. Yuan, H. Wang, L. Yi, A. X. Chang, L. J. Guibas, and H. Su,
“SAPIEN:ASimulAtedPart-basedInteractiveENvironment,”inCVPR,
2020. 5
[43] V.-D.Nguyen,“TheSynthesisofForce-ClosureGrasps,”Ph.D.disser-
tation,MassachusettsInstituteofTechnology,1985. 5
[44] S.M.LaValleandJ.J.KuffnerJr,“RandomizedKinodynamicPlanning,”
IJRR,vol.20,no.5,pp.378–400,2001. 5
[45] HaoSuLab,“MPlib:aLightweightPythonPackageforMotionPlan-
ning,”2023,https://github.com/haosulab/MPlib. 5
[46] R.B.Rusu,N.Blodow,andM.Beetz,“FastPointFeatureHistograms
(FPFH)for3Dregistration,”inICRA,2009. 5
[47] K.S.Arun,T.S.Huang,andS.D.Blostein,“Least-SquaresFitting
ofTwo3-DPointSets,”TPAMI,no.5,pp.698–700,1987. 5
[48] Q.-Y.Zhou,J.Park,andV.Koltun,“Open3D:AModernLibraryfor
3DDataProcessing,”arXiv:1801.09847,2018. 5
[49] L.Tang,M.Jia,Q.Wang,C.P.Phoo,andB.Hariharan,“Emergent
CorrespondencefromImageDiffusion,”inNeurIPS,2023. 6
[50] J. Ho, A. Jain, and P. Abbeel, “Denoising Diffusion Probabilistic
Models,”inNeurIPS,2020. 6
[51] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai,
T.Unterthiner,M.Dehghani,M.Minderer,G.Heigold,S.Gellyetal.,
“AnImageisWorth16x16Words:TransformersforImageRecognition
atScale,”inICLR,2021. 6