A Bayesian Optimization Approach to Machine Translation Reranking
JuliusCheng1 MaikeZüfle2 VilémZouhar3 AndreasVlachos1
1UniversityofCambridge 2KarlsruheInstituteofTechnology 3ETHZürich
{jncc3,av308}@cam.ac.uk maike.zuefle@kit.edu vzouhar@ethz.ch
Abstract
Rerankingalistofcandidatesfromamachine
translation system with an external scoring
modelandreturningthehighest-scoringcandi-
dateremainsasimpleandeffectivemethodfor
improvingtheoveralloutputquality. Transla-
tionscoringmodelscontinuetogrowinsize,
withthebestmodelsbeingcomparabletogen-
erationmodels. Thus,rerankingcanaddsub-
stantial computational cost to the translation
pipeline. In this work, we pose reranking as
aBayesianoptimization(BayesOpt)problem.
Bystrategicallyselectingcandidatestoscore
basedonabalanceofexplorationandexploita-
Figure1: Amachinetranslationsystemgeneratescandi-
tion, we show that it is possible to find top-
datesAa,Bb,Cc,Dd,andEe. ThegoalofBayesOptis
scoringcandidateswhenscoringonlyafraction
tofindthehighestscoringcandidatewithfewerscoring
ofthecandidatelist. Forinstance,ourmethod
calls. An acquisition function selects the next candi-
achievesthesameCometKiwiscoreusingonly
datetoscorerepeatedlyuntilbudgetisreached,andthe
70scoringevaluationscomparedabaselinesys- candidatewiththehighestscoresofarisreturned.
temusing180. Wepresentamulti-fidelityset-
ting for BayesOpt, where the candidates are
first scored with a cheaper but noisier proxy Johnson, 2005), thus remains a relevant method
scoringmodel,whichfurtherimprovesthecost- for gaining additional performance from an MT
performancetradeoffwhenusingsmallerbut system(Fernandesetal.,2022).
well-traineddistilledproxyscorers.
The term “reranking” is used to refer to any
methodwhichmanipulatesorreplacesthescores
assignedbyagenerationmodel. Ittypicallyrefers
1 Introduction
torankingann-sizedsetofcompletedgenerations
The quality of machine translation (MT) genera- withanarbitraryscorer,althoughitcanalsobein-
tionmodelshassurgedinrecentyearsduetoinno- tegratedintothegenerationprocess(Singhaletal.,
vationsinneuralnetworkarchitecture(Stahlberg, 2023). Awidearrayofscoringmethodsexist,in-
2020),trainingdataaugmentation(Sennrichetal., cludingdiscriminativeclassifiers(Leeetal.,2021;
2016; Edunov et al., 2018), and scale of training Bhattacharyyaetal.,2021),noisychanneldecod-
data (Ott et al., 2018). At the same time, transla- ing (Yee et al., 2019), and sampling-based Min-
tionqualityevaluationmodelshavemadesimilar imum Bayes Risk decoding (MBR; Eikema and
gainsforsimilarreasons(Reietal.,2020;Juraska Aziz,2020). Ineachofthesepreviousworks,alist
etal.,2023;Sellametal.,2020)inadditiontothe ofcandidatesequencesisgenerated,rescored,and
newabundanceofqualityestimationtrainingdata thehighest-scoringcandidateisreturned.
(Freitagetal.,2023b). Rerankingalistoftransla- In this work, we present a general-purpose
tioncandidateswithanexternalevaluationmodel, rerankingalgorithmforMTwhichreducesthecom-
atechniquewithalonghistoryinnaturallangauge putationalburdenofscoringallncandidates. Cru-
processing(CollinsandKoo,2005;Charniakand cially,ouraimistosupportarbitraryscoringfunc-
†Codeavailablesoon. tionsbyusingacombinationofmethodsthathave
4202
voN
41
]LC.sc[
1v49690.1142:viXraseen widespread adoption across many domains: hasbeenshowntobehighlyeffectiveatimproving
Bayesian optimization (BayesOpt) and Gaussian translationoutput(Freitagetal.,2022),thoughit
processes(GP).BayesOpt(Shahriarietal.,2016) canskewresultswhenthesamemetricisalsoused
isasequentialblack-boxoptimizationmethodthat for evaluation (Kocmi et al., 2024a). Reranking
usestheposteriormeanandvarianceofunobserved performanceimprovesasthenumberofcandidates
datapointstodecidewhichpointstoevaluatenext. increases(VernikosandPopescu-Belis,2024)and
GPs(RasmussenandWilliams,2005)areflexible when multiple scoring metrics are combined to
priorsoverfunctionswithatractableposteriorthat formastrongerprediction(Fernandesetal.,2022).
caneffectivelyhandlenonlinearity. While such methods may be cost-prohibitive for
We apply BayesOpt and GPs (BayesOpt+GP) large-scaledeploymentcomparedtobeamsearch,
to MT list reranking in a straightforward manner they can be used in other parts of the MT devel-
and show that it obtains close to the maximum opmentpipeline;high-qualitypredictionsobtained
achievablescorewithonlyafractionofscoreevalu- fromrerankingareusefulforknowledgedistillation
ations. Forexample,whenthemaximalobtainable (Wangetal.,2024a)andself-training(Finkelstein
scoreacross200randomlysampledcandidatesis etal.,2024).
0.8216 CometKiwi, our method achieves 0.8210 PreviousworkonefficientrerankingforMTis
with70scoreevaluationsonaverage,whilescoring relatively limited. Fernandes et al. (2022) and
70randomcandidatesattains0.8149,adifference Eikema and Aziz (2022) perform a two-stage
of0.0061whichislikelytobehuman-detectable rerankingbyfirstpruningwithafasterandnoisier
accordingto(Kocmietal.,2024b). scoring function to a fixed size before evaluating
Then, buildinguponpreviousworksthatusea thetargetscore. Therehasbeenrecentinterestin
fasterbutnoisierproxyscoringfunctiontoprune efficientapproximationsforMBR(ChengandVla-
thecandidatelist(Fernandesetal.,2022;Eikema chos, 2023; Deguchi et al., 2024; Trabelsi et al.,
andAziz,2022),weproposeamulti-fidelityexten- 2024;VamvasandSennrich,2024),butthesemeth-
siontoBayesOptwhichincorporatesproxyscores odsdonotgeneralizetootherscoringfunctions.
toimproveestimation. Thisisrelatedtocoarse-to-
fine methods (Petrov, 2011) and model cascades 2.2 Bayesianoptimizationwith
(KaynakandAlpaydin,2000). Usingthismethod, Gaussianprocessprior
wefindthatsmallerproxyscoringmodelsdistilled
Bayesianoptimizationisasequentialalgorithmfor
fromthemainmodelcanfurtherimprovetheper-
optimizing a black-box function f. In BayesOpt,
formanceofBayesOpt.
f isassumedtobedrawnfromapriordistribution
over functions. The main loop of BayesOpt is as
2 Background
follows: given a set of (possibly noisy) observa-
2.1 Translationgenerationandreranking tions of f(a ),...,f(a ), the prior distribution is
1 i
updatedtoaposteriordistributionwithBayesthe-
In a typical machine translation setting, a con-
orem. Anacquisitionfunctiondeterminesaquery
ditional language model is trained to model the
point a at which to evaluate f next. f(a )
probabilityofthenexttokeny givenasourcesen- i+1 i+1
t
is evaluated and added to the set of observations.
tence x and previous tokens: p(y |x,y ,...,y ).
t 1 t−1
This repeats until a stopping criteria is reached.
These probabilities can be autoregressively com-
TheprincipaldesignchoicesinBayesOptarethe
binedtomodelasequenceprobabilityp(y|x). Usu-
priordistributionoff andtheacquisitionfunction.
ally, beam search is used to search for a y which
Our choice of prior is the Gaussian pro-
maximizeslogprobabilitycombinedwithalength
cess, which assumes that any subset of points
normalizationobjective(Wuetal.,2016).
f(a ),...,f(a )aredrawnjointlyfromamultivari-
In a basic list reranking setting, given x, the 1 i
ateGaussiandistributionN(µ,K),whereKisthe
conditional language model is used to generate a
covariancematrixdefinedbyakernelfunctionsuch
candidate list C = [y ,...,y ] with a decoding
x 1 n
astheradialbasisfunctionkernel(RBF).RBFsde-
algorithm such as beam search or ancestral sam-
finethecovarianceoftwopointsaanda′ as:
pling. A scoring model s(x,y ) is then applied
i
to each y ∈ C , and the best scoring sequence
i x (cid:18) ||a−a′||2(cid:19)
argmax yi∈Cxs(x,y i)isreturned. K RBF(a,a′) = exp −
2w2
, (1)
Rerankingwithhigh-qualityevaluationmetricswhere w is the bandwidth hyperparameter which 3 Methods
determinesscaling. Thechoiceofkerneldictates 3.1 MTrerankingwithBayesianoptimization
priorassumptionsabouttheshapeoff;withRBF, OurmainalgorithmisanadaptationofBayesOpt
pointsthatarecloserinEuclideanspacehavelarger withGPsasdescribedinSection2.2tothererank-
covariance. RBFs are a popular choice of kernel ing setting. Each source sentence x is treated as
duetheirabilitytomodelcomplexnonlinearfunc- astandaloneBayesOptproblem,meaningthatno
tions. observationsaresharedacrossdifferentx. Thusfor
Theassumptionthatf(a ),...,f(a )arejointly brevity,weomitxfromnotationwhendiscussing
1 i
Gaussian gives rise to a convenient posterior dis- BayesOptforaparticularinstance.
tribution. Givenavectorofobserveddatapointsa Letsbethescoringfunction,anMTqualityes-
andtheirobservedvaluesf(a),theposteriormean timator. LetC beasetofcandidates,C ⊆ C the
obs
µ and variance σ of a point a are given by the subsetofcandidatesforwhichwehaveobserved
a a
conditionalmultivariateGaussiandistribution: s(y),andC¯ beallothery (C¯ = C \C ). To
obs obs obs
perform reranking for a particular instance with
µ a = µ+K(a,a)(K(a,a)+σ2I)−1f(a) (2) candidatesC,webeginbyscoringasmallrandom
σ = K(a,a)+σ2− subsetofC withanMTqualityestimators. Inone
a
(3) iteration in the algorithm loop, we normalize the
K(a,a)(K(a,a)+σ2I)−1K(a,a)
observedscorestomean0and1varianceatevery
step and assume a 0 unconditional mean. Then
whereµistheunconditionalmeanofthedistribu-
tion, σ2 is a constant Gaussian noise on observa- wecomputetheGPposteriorofally ∈ C¯ obs with
Equation2and3giventhescoresofC ,whichis
tions,andI istheidentitymatrix. obs
thenusedtocomputeEIwithEquation5,assuming
TheacquisitionfunctioninBayesOptisthestrat-
noobservationnoise. Weevaluatethek candidates
egyforselectingthenextpointtoevaluateintheop-
in C¯ with the highest EI, removing them from
timizationprocess. Acquisitionfunctionscanseek obs
C¯ andaddingthemtoC ,andrepeattheloop,
the highest expected improvement (EI; Mockus, obs obs
terminating when a predefined budget of n calls
1974),anupperconfidenceboundifthescoresare
tosisreached(orwhenallcandidateshavebeen
noisy (Srinivas et al., 2009), or information gain
evaluated, in the case that |C| ≤ n.). Finally, we
(HennigandSchuler,2011). WeuseEI,definedas:
chooseargmax s(y)astheprediction.
y∈C
obs
α(a) = E[max(f(a)−f(a+),0)], (4) WenowdescribeourchoiceofGPkernel. y ∈ C
arestrings,andweseekarepresentationthatisfast
wherea+ isthelocationofthecurrentbestobser- to compute and to compare, since |C| representa-
vation. When f is Gaussian and there is no ob- tionsaregenerated,andthecomputingtheGPco-
servationnoise,thishasthefollowingclosed-form variancematrixrequires|C|2comparisons. Ourker-
solution(Jones,2001): nel is K (y ,y ) = K (emb(y ),emb(y )),
MT i j RBF i j
where emb returns the mean-pooled token-level
α(a) = σ a(z·cdf(z)+pdf(z)), (5) outputsofthefinaldecoderlayerwhengenerating
y,normalizedtotheunitnormafterpooling. emb
where z =
f(a+)−µa,
and cdf,pdf are the Gaus- exploits meaning representations produced auto-
σa
siancumulativedistributionfunctionandprobabil- maticallyduringcandidatelistgenerationandthus
ity density function, respectively. EI encourages requiresnegligibleoverhead. Also,thecovariance
bothexplorationofuncertainpointsandexploita- matrix is fast to compute given the candidate list
tion of high-scoring points; the quantity in Equa- sizes and embedding dimensionality used in our
tion5canbeincreasedbyincreasingµ a orσ a. experiments.
ThegeneralityofBayesOptandmodelingfree-
3.2 Multi-fidelityBayesOpt
dom enjoyed by GPs make them suitable for a
greatvarietyoftasks,includingspatialmonitoring We also propose an extension to BayesOpt+GP
(Krauseetal.,2008)andhyperparameteroptimisa- for the setting where observations are available
tion(Bergstraetal.,2011). GPshavebeenapplied from a different but related proxy score function
to text regression tasks (Beck et al., 2013, 2014; s′. We refer to this as BayesOpt+GP+Proxy. s′
Beck and Cohn, 2017), but they are not as well- isassumedtohavenon-trivialcovariancewiththe
studiedinNLPcomparedtomanyotherdomains. scoringmodelsandtobecheapertoevaluate. ThisInputs:scoringfunctions,proxymetrics′,budgetnforevaluatings,covarianceondevsetKscore(s,s′),
candidatesC,numberofinitialproxyscoresmandscoresn<m,batchsizek
Output:candidatey∈C withthehighestscores(y)amongtheobservedcandidates
obs
1: C o′
bs
←(cid:0) mC(cid:1) ,C
obs
←(cid:0)C no′ bs(cid:1) ▷Scoreinitialsubsets
2: S ←{s(y)|y∈C } ▷Computescoresformainscoringfunction
obs obs
3: S′ ←{s′(y)|y∈C′ } ▷Computeproxyscores
obs obs
4: ∀y i,y j ∈C,∀s k,s l ∈{s,s′}:K mult(y i,y j)←K MT(y i,y j)Kscore(s k,s l) ▷Computemulti-fidelitykernelmatrix
5: while|C |<nand|C |<|C|do
obs obs
6: Sˆ←Norm(S ),Sˆ′ ←Norm(S′ ) ▷Normalizeobservedscoresto0-mean,1-variance
obs obs
7: y ←argmax Sˆ(y)
best y∈Cobs
∀y∈C¯
obs
:µy,σy ←calculateposteriorusingy,K mult,Sˆ,Sˆ′ ▷GPposteriorasinEquations(2)and(3)
8: ∀y∈C¯
obs
:αy ←EI(y best,µy,σy) ▷ExpectedimprovementasinEquation(5)
9: C top-k ←argtopk y∈C¯ obsαy ▷SelectkbestcandidatesbasedonEI
10: S ←S ∪{s(y)|y∈C } ▷Computescoresforselectedcandidates
obs obs top-k
11: C ←C ∪C ▷Updateobservedcandidates
obs obs top-k
12: endwhile
13: returnargmax s(y)
y∈Cobs
Algorithm1:AlgorithmfortheproposedBayesOpt+GP+Proxymethod.Theproposedmethodselectsasmallsubset
ofcandidates,evaluatesthetruescoringfunctionsandthecheaperproxymetricsˆoninitialsubsets,anditeratively
updatesaGaussianProcessmodelusingthethesimilaritybetweencandidates’embeddingsandpreviouslyobserved
scores. ThealgorithmmaximizestheExpectedImprovementtoselectnewcandidates, updatesthescores, and
continuesuntilthescoringbudgetnisreached. IftheproxymetricisnotusedandK =K ,thealgorithm
mult MT
reducestoBayesOpt+GP.
is known as multi-fidelity BayesOpt in the litera- set,whereallscoresarenormalizedper-instanceso
ture, but while the multi-fidelity settings studied that in each instance, the scores of all candidates
in (Kandasamy et al., 2016; Wu et al., 2020) use foraparticularscorerhave0meanand1variance.
acquisitionfunctionsthatmaychoosetoevaluate Thenforeachscoringfunction,concatenateallcan-
lower-fidelityscores,westudyasimplersetting: m didate scores across instances, and compare the
observationsofs′areobtainedatthestart,andonly resultingliststoobtainthecovariance. Covariance
smaybeevaluatedduringtheBayesOptloop. In isavalidkernelbecausethecovariancecalculation
themulti-fidelitysetting,observationsaremadeon canbeexpressedasadotproduct,anddotproducts
⟨y ,s ⟩,acombinationofadatapointandscoring arevalidkernels.
i i
function,insteadofthedatapointalone. Proxyscoresareincorporatedintoposterioresti-
OurkernelforBayesOpt+GP+Proxyistheprod- mationgiven byEquations 2and 3by redefining
uctoftheRBFkernelfromSection3.1andakernel a to be a tuple of ⟨data point, scoring function⟩
overscorefunctionsf: and a to be the vector of such tuples which are
observed. f(a) would then return the observed
(cid:0) (cid:1)
K ⟨y ,f ⟩,⟨y ,f ⟩ = valuesforadatapointandscoringfunction. The
mult i k j l
K MT(y i,y j)K score(f k,f l). (6) kernel K is set to K mult which takes as input the
tupleofdatapointandscoringfunction. Thefull
K mult is a valid kernel because a product of two BayesOpt+GP+ProxyalgorithmisinAlgorithm1.
kernelsdefinedondifferentspacesisalsoakernel
3.3 Proxyscores
(RasmussenandWilliams,2005). WithK ,the
mult
covariancebetweentwoobservationsdependson We train smaller scoring models to have high co-
boththedifferencebetweenscoringfunctionsand variancewithsforuseinBayesOpt+GP+Proxy. In
thedistancebetweendatapoints. Thisway,anob- thiswork, ourscoringfunctionsarebasedonthe
servationinfluencestheposteriorforallotherdata Comet referenceless quality estimation architec-
points at all choices of scoring function, as long ture(Reietal.,2020),alsoknownasCometKiwi.
as the scoring functions are correlated. This for- These models encode the source and hypothesis
mulationenablestheuseofanynumberofscoring jointly with a bidirectional transformer. Activa-
functions, but in this work, we consider at most tionsfromalltransformerlayersarepooledtoform
two: themainscoreandaproxyscore. a fixed-size representation, which is passed to a
WesetK (f ,f )tobetheempiricalcovari- feed-forward regression head. The vast majority
score k l
ancebetweenf andf measuredoveravalidation of computation in this models is spent in the en-
k lcoder. Thus,fasterCometmodelscanbeobtained Appendix. AppendixAcontainsextensivestatisti-
byreducingthesizeoftheencoder. calsignificancetests.
We train Comet models using two differently For BayesOpt experiments, we grid search for
sized pretrained multilingual encoder models in theoptimalvalueofRBFbandwidthparameterw
twoways: (1)trainingonthesametrainingsetas ontheentirevalidationset,settingscoringbudget
CometKiwiand(2)distillation. Amongdistillation n = 100andbatchsizek = 1. Whileitispossible
methods, we attempt in preliminary experiments tooptimizeitforeveryuniquecombinationoflan-
(1)trainingonthesametrainingsetasCometKiwi guagepair,n,k,proxyscoringfunction,andm,we
withgroundtruthscoresreplacedwithCometKiwi findthattheresultsarenotstatisticallysignificantly
scoresand(2)trainingonasyntheticdatasetcom- differentwithinarangeofsettings. Forsimplicity,
prisingofLMsamplesalongwiththeirassociated andtodemonstratetherobustnessofourmethods,
CometKiwiscores. Thelatterachieveshighercor- weusethesamew forallexperiments.
relation with CometKiwi on sampled candidates, We set k=1 in Sections 4.2 and 4.3 to demon-
whichistobeexpectedsincethetrainingdistribu- strate the effectiveness of BayesOpt+GP under
tionismoresuitableforthererankingusecase. We ideal conditions, but since k has a large impact
thereforeusethislatterdistillationmethodforall on speed, we experiment with varying it in Sec-
subsequentexperiments. Asimilarprocedurehas tion4.5.
beendescribedinReietal.(2022a).
4.1 Modelsanddatasets
3.4 Candidatelistgeneration For candidate generation, we use the 600M-
parameter distilled NLLB model (Team et al.,
Inpreliminaryexperiments,weconsidergenerat-
2022) in all experiments. As the main scoring
ingthecandidatelistusingbeamsearchwith128
model,weuseCometKiwi-22(Reietal.,2022b).
outputs versus sampling 200 candidates using ϵ-
Asadatasetusedforproxymodeltraining,we
sampling (Hewitt et al., 2022) with ϵ = 0.02, a
data from the WMT Metrics Shared Task up to
settingwhicheffectivelybalancesqualityanddiver-
2022(Freitagetal.,2023b),whichcontainstuples
sityforMBR(Freitagetal.,2023a). Underbeam
of⟨source,hypothesis,humanscore⟩. Thehuman
search,thecandidatesexhibithighlexicaloverlap,
scores were largely collected with the DA+SQM
andwhilethemeanscoreofcandidatesishigher,
annotationprotocol(Kocmietal.,2022).
the average maximum score is lower. The effec-
ForBayesOptexperiments,werandomlyselect
tiveness of truncated sampling over beam search
1000and500sourcesentencesperlanguagepair
inlargerconditionallanguagemodelhasalsobeen
fromtheWMT23MetricsSharedTaskdatasetas
observedbyFernandesetal.(2022).
validationandtestset,respectively,for7language
Furthermore, beam search suffers from out-of-
pairs: English-Czech, English-German, English-
memoryerrorsonlongtranslations,whereaswith
Japanese,English-Chinese,andthereversedirec-
sampling, we simply reduce the batch size when
tionsofthelatter3pairs.
outofmemory. Whileitispossibletoimplement
CometKiwi is based on the encoder of XLM-
beam search in a batched manner, this does not
Roberta (Conneau et al., 2019) (2.2GB mem-
exist in any popular conditional language model large
ory). For proxy scorers we train smaller mod-
libraries,tothebestofourknowledge.
els based on XLM-Roberta (1.1GB), and
For these reasons, we generate 200 candidates base
Multilingual-MiniLM-L12-H384 (Wang et al.,
perinstancewithϵ-sampling,ϵ = 0.02inallexper-
2020)(469MB).
iments. Thesampledcandidatelististhendedupli-
cated,resultingin∼178candidatesonaverageper
4.2 BayesOpt+GP
instance.
ThegoalofrerankingBayesOpt+GPistoimprove
thespeedbyonlyevaluatingasubsetofavailable
4 Experiments
candidates. Weevaluatethisthroughquality-cost
We now discuss the details and findings of our tradeoffcurves,wherequalityisdeterminedbyfi-
Bayesian optimization experiments, followed by nalselectedcandidate’sCometKiwiscore,andcost
analysisofourtrainedproxyscoringmodels,con- isdeterminedbythenumberofcallstothescoring
cluding with runtime measurements. For exact function. As another measure of approximation
valuesforfiguresinthissection,seeTable3inthe quality,wealsoshowthepercentageofinstances100%
0.82
80%
0.81 60%
BayesOpt+GP (0.8198) BayesOpt+GP (0.8747)
HillClimbing (0.8181) 40% LogprobAvg (0.7403)
0.80 LogprobAvg (0.8174) HillClimbing (0.7945)
UniqRandom (0.8157) 20% UniqRandom (0.5811)
LogprobSum (0.8071) LogprobSum (0.6169)
0.79
10 60 110 160 200 10 60 110 160 200
Number of CometKiwi runs Number of CometKiwi runs
Figure2: PerformanceofrerankingmethodsmeasuredastheaverageCometKiwiscoreoftheselectedcandidate
(left) and percentage of instances where the selected candidate had the highest score (right). The x-axis is the
scoringbudget. LegendsshowthenormalizedareaunderthecurveofCometKiwiscoreofeachmethodinbrackets.
in which the actual best scoring candidate is re- asimple“exploration”strategythatignoresexist-
turned. We devise several baselines to compare ing observations, while HillClimbing is a simple
BayesOpt+GPagainst. Eachisastrategyforselect- “exploitation”strategy,onlysearchingoverneigh-
ingasubsetofcandidatestoscorefromwhichthe bors nearest the best observation while ignoring
best scoring candidate is returned. The baselines the full search space. These results confirm that
are: balancingtheserespectivedecideratahelpstofind
theoptimalcandidatemoreefficiently.
• UniqRandom: Shufflethecandidatelistbefore
de-duplication,thende-duplicatewhilepreserv- 4.3 BayesOpt+GP+Proxy
ingtheorderofthefirstappearanceofeachcan-
4.3.1 Proxyscoreevaluation
didate. Selectthefirstmin(n,|C|)candidatesin
We first evaluate trained proxy scorers indepen-
theresultinglist.
dently of their use in BayesOpt according to (1)
• Logprob{Avg,Sum}: SortC inorderofnegative
actual runtime, (2) correlation with human rat-
sequencelogprobability(eitheraverageorsum),
ings in the WMT23 dataset, (3) correlation with
andthenselectthefirstmin(n,|C|).
CometKiwionsource-hypothesispairsinWMT23,
• HillClimbing: Lety+ bethehighestscoringob-
and(4)correlationwithCometKiwionasynthetic
servationpointatanytimestep. Iterativelyselect
candidatesforaninstance,averagedoverinstances.
argmin
y∈C¯
||emb(y)−emb(y+)||asthenext
obs ForcorrelationsweuseKendall’sτ ,whichiscom-
observation point until min(n,|C|) candidates c
monlyusedinMTmetricevaluation(Freitagetal.,
arescored.
2023b).
UniqRandomsimulatestheeffectofonlysampling Table1showstheresultsfortheproxymodels.
andscoringasmallernumberofcandidateswhile The model size corresponds closely to inference
controllingthenumberofuniquecandidates. Log- time. Asdesired,trainingproxiesusingdistillation
probFirst{Avg,Sum}areincludedtoverifywhether resultsinmuchhighercorrelationwithCometKiwi,
more advanced methods indeed outperform sim- althoughitlosessomecorrelationwithhumanjudg-
ple subset selection using statistics obtained for ments. In subsequent experiments, we consider
free. HillClimbingisaheuristiciterativeselection Distilled-{S,M}only. WhileLogprobAvghascom-
strategy which, like BayesOpt, is black-box and parativelymuchlowercorrelation,wenevertheless
derivative-free(Connetal.,2009). consideritasaproxyscoresinceitisobtainedfor
InFigure2,BayesOpt+GPoutperformsallbase- freeduringcandidategeneration.
lines,andHillClimbingisthebestamongthebase-
4.3.2 Rerankingresults
lines, with LogprobAvg following behind. Log-
probSumseverelyunderperformsUniqRandomin When s′ is sufficiently fast and correlated
score, confirming findings on the inadequacy of with s, its knowledge can further improve the
very high probability translations (Eikema and quality-costtradeoffinBayesOpt+GP.Recallthat
Aziz,2020). Informallyspeaking,UniqRandomis BayesOpt+GP+Proxy initializes with m evalua-
erocs
etadidnac
detceleS
pot
si
etadidnac
detceleS
%Human CometKiwi candidates earlier, whereas ProxyFirst is a poor
Model Time Test Test Cands. choicebecauseitdoesnotrankallofC.
Overall,proxyobservationscanindeedimprove
CometKiwi 51.38s 0.245 1.000 1.000
qualityforaparticularn. However,forsufficiently
LogprobsAvg 0.00s × × 0.191
largen,BayesOpt+GPconverges,soproxyobser-
LogprobsSum 0.00s × × -0.090
vationsareunnecessary. Proxyevaluationsaddto
Authentic-S 7.13s 0.193 0.314 0.350
theruntimecostwhichwediscussinSection4.4.
Authentic-M 18.71s 0.199 0.320 0.448
Therefore, while we show that the multi-fidelity
Distilled-S 7.13s 0.169 0.488 0.620
kerneliscapableofleveragingproxyscorestoim-
Distilled-M 18.71s 0.188 0.572 0.680
provesearch,inpractice,theoverallcomputational
budgetshouldbeconsideredalongwiththequality
Table 1: Benchmarking proxy models (Sec-
and cost of the proxy scoring function to ensure
tion 3.3) on speed and correlation with human
judgments/CometKiwi using the WMT23 dataset. thatusingthemethodisworthwhile.
Speed is measured by runtime on a single A100-
SXM4-40GBGPUper10000samplesusingmaximum BayesOpt+GP with 200 Distilled-M (0.8202)
BayesOpt+GP with 200 Distilled-S (0.8196)
batch size. Correlation is measured with Kendall’s
BayesOpt+GP (0.8198)
τ c against human judgments and CometKiwi scores. BayesOpt+GP with LogprobAvg (0.8180)
CometKiwi correlation is taken over the provided
0.820
targets in WMT23 (Test) and a synthetic dataset
comprisedof200samplespersourcesentence,deduped
(Cands). Logprobs{Avg,Sum} is not evaluated on 0.815
WMT23 targets because they are generated by other
MTsystems. 0.810
tions of s′. Figure 3 shows the quality-cost 0.805 (zoomed-in axes)
10 30 50 70
curve when all proxy scores are known. The rel-
Number of CometKiwi runs
ative performance when including proxy scores
are ordered according to their correlation with Figure3: AverageCometKiwiscoreoftheselectedcan-
CometKiwiasshowninTable1;Distilled-Mout- didate(y-axis)forBayesOpt+GP+Proxywithdifferent
performs Distilled-S, and both outperform Log- choicesofproxyscore.
probAvg. This demonstrates the importance of
ensuringhighcorrelationintheproxyscore. The
additionofLogprobAvgtoBayesOpt+GPhaslit-
BayesOpt BayesOpt
tle effect, showing that poorly correlated proxies
Operation AllComet +GP +GP+S
aretoonoisytohelp,andmayevenhinderperfor- n=90 n=70,m=50
mance. Beyondn=70,allmethodsachieveclose
Candidates 701.38 701.38 701.38
tothemaximumattainablescore. Similarities × 1.24 1.24
We also examine the effect of initializing with BayesOpt+GP × 1.92 2.25
CometLoading 8.43 8.43 11.27
afractionofproxyobservationsratherthanallof
Distilled-S × × 11.11
them. Forsomechoiceofm,anappropriatebase-
CometKiwi 274.87 188.39 146.33
line is to rank the top-n candidates among the m
Total 984.68 901.36 873.58
observed proxy scores. We call this ProxyFirst.
TheresultswhenusingDistilled-MandDistilled-S
Table2: Runtimesforthefullrerankingbaseline(All-
asproxiesareshowninFigure4. Inbothcases,the Comet),BayesOpt+GP,andBayesOpt+GP+Satsettings
differencebetweenBayesOpt+GP+ProxyandProx- whereCometKiwiscoresareroughlyequal. Timegiven
yFirstissmallerwhenm=200thanwhenm=50, insecondsonasingleA100-SXM4-40GBGPUfor350
andthisgapissmallerforDistilled-M.Thisistobe samples.
expectedbecauseasthecovarianceofsands′ in-
creases,usingProxyFirstwithm=200approaches
4.4 Runtime
standardfull-listreranking. Themarginalbenefitof
BayesOpt+GP+Proxy is more clear when m=50. Ourrerankingalgorithmsignificantlyreducesac-
In this case, proxy scores help to find promising tual runtime compared to scoring all candidates
erocs
etadidnac
detceleSBayesOpt+GP with 200 Distilled-S (0.8196) BayesOpt+GP with 200 Distilled-M (0.8202)
ProxyFirst 200 Distilled-S (0.8182) ProxyFirst 200 Distilled-M (0.8194)
ProxyFirst 50 Distilled-S (0.8133) ProxyFirst 50 Distilled-M (0.8135)
BayesOpt+GP with 50 Distilled-S (0.8192) BayesOpt+GP with 50 Distilled-M (0.8196)
BayesOpt+GP (0.8198) BayesOpt+GP (0.8198)
0.820 0.820
0.815 0.815
0.810 0.810
0.805 (zoomed-in axes) 0.805 (zoomed-in axes)
10 30 50 70 10 30 50 70
Number of CometKiwi runs Number of CometKiwi runs
Figure4: AverageCometKiwiscoreoftheselectedtopcandidate(y-axis)forBayesOpt+GP+ProxywithDistilled-S
(left)andDistilled-M(right)comparedtotheProxyFirstbaseline. Thisfiguredisregardstheadditionalcompute
costsfortheseproxymetricsinordertoshowthemarginalscoreincreasefromproxyobservations.
forasourcesentence. Weprofilethefullpipeline, networks,makingitinefficienttorunsmallbatches.
from generating candidates to making a final se- SinceBayesOpt+GPobtainsk candidatesperstep,
lection,onthreesettings: (1)BayesOpt+GPwith inordertouselargebatches,weprocesscandidates
n=90, and (2) multi-fidelity BayesOpt+GP with formultipleinstancesinparallel.
50Distilled-Sscoresandn=70(BayesOpt+GP+S), Results are shown in Table 2. In all cases,
and3)thebaselineofevaluatingCometKiwionall candidategenerationandCometKiwicalculations
candidates. n,mareselectedtobalancethefinal dominate the overall runtime. The extra cost
scores of the two algorithms (0.8213 and 0.8211 from BayesOpt-related computations is compen-
respectively,asshowninTable3). sated by the savings from reducing CometKiwi
evaluations,despitesimilaritymatrixcomputation
0.000 being O(|C|2), and matrix inversion for poste-
BayesOpt+GP rior calculation at each iteration being O(|C|3).
0.001 batch size 10 BayesOpt+GP+S reduces the runtime by further
BayesOpt+GP
reducing the number of CometKiwi calculations
batch size 5
0.002 to 70, with the cost of loading and running the
BayesOpt+GP
batch size 2 Distilled-Sproxymetricintroducingminimalover-
0.003
head. 10 60 110 160 200
Max number of CometKiwi runs
4.5 BatchsizekinBayesOpt+GP
Figure5: DifferencebetweenBayesOpt+GPwithbatch
sizeof1(toplineinredinFigure2)andBayesOpt+GP We examine the effect of batch size k in
with higher batch sizes. Negative values mean that
BayesOpt+GPfork = 1,2,5,10. Figure5shows
higherbatchsizeperformedworsethanBayesOpt+GP
thatasexpected,largerk diminishesperformance,
withbatchsizeof1.
althoughthedifferencesnearlyvanishatn>70.
k impacts how often the BayesOpt loop is run
Fortheruntimecalculations,weselect50source
and thus has a large effect on speed. Fortunately,
sentences from each language pair and generate
we observe for sufficiently large n, k can be in-
200candidatesforeach. Forthebaseline,wecom-
creasedwithoutsacrificingquality.
putescoresforallcandidateswithabatchsizeof
200. For our methods, we profile the additional
5 Conclusion
stepsrequiredbyBayesOpt: computingthekernel,
computingtheposteriorsateachstep,andoption- In this work, we formalize MT reranking as a
ally evaluating proxy scores. BayesOpt+GP(+S) Bayesianoptimizationproblem,leveragingtheba-
usesbatchsizek=10,whichdoesnotaffectscores sic observation that similar translations are more
comparedtousingk=1(seeSection4.5). Memory likely to have similar quality scores. We also ex-
bandwidthcanbeamajoroverheadinlargeneural tend the framework to accept observations from
erocs
etadidnac
detceleS
erocs
etadidnac
detceles
ni
1
ezis
hctab
tsniaga
erocs
etadidnac
detceleSproxyscoringfunctions,whichisapplicablewhen cesses. In Proceedings of the 2014 Conference on
the target score is very costly: large QE models, Empirical Methods in Natural Language Process-
ing(EMNLP),1798–1803.AssociationforComputa-
MBR, or human evaluation. In realistic experi-
tionalLinguistics.
ments,weshowthatourmethodsimprovererank-
ingefficiencyoverstrongbaselines. Wealsopro- Daniel Beck, Kashif Shah, Trevor Cohn, and Lucia
poseseveraldesignchoicesthatmakethemethods Specia. 2013. SHEF-Lite: When less is more for
translationqualityestimation. InProceedingsofthe
usefulinpractice;aGPkernelthatrequiresmini-
EighthWorkshoponStatisticalMachineTranslation,
maloverhead,andeffectiveproxymodeltraining
337–342.AssociationforComputationalLinguistics.
viadistillation.
James Bergstra, Rémi Bardenet, Yoshua Bengio, and
We consider our work a first step in applying
BalázsKégl.2011. Algorithmsforhyper-parameter
BayesOpt to MT reranking. Future directions in-
optimization. In Advances in Neural Information
cludeintegratingBayesOptwithcandidategenera- ProcessingSystems,volume24.CurranAssociates,
tion,alternativeacquisitionfunctions,andfurther Inc.
explorationofGPkernelsforMT.
SumantaBhattacharyya,AmirmohammadRooshenas,
SubhajitNaskar,SimengSun,MohitIyyer,andAn-
6 Limitations
drew McCallum. 2021. Energy-based reranking:
Improvingneuralmachinetranslationusingenergy-
Theoptimizationproblemconsideredinthiswork
based models. In Proceedings of the 59th Annual
is to maximize score from a scoring model. We Meeting of the Association for Computational Lin-
showthatBayesOptisaneffectiveoptimizer,but guisticsandthe11thInternationalJointConference
onNaturalLanguageProcessing(Volume1: Long
we do not explore to what extent the optimiza-
Papers),4528–4537.AssociationforComputational
tionproblemisflawedduetoflawsinthescoring
Linguistics.
model. Wereferto(Kocmietal.,2024b)tounder-
standwhatmagnitudeofscoredifferencebetween Eugene Charniak and Mark Johnson. 2005. Coarse-
to-fine n-best parsing and MaxEnt discriminative
systems is significant. However, the existence of
reranking. InProceedingsofthe43rdAnnualMeet-
“metric overfitting” when directly optimizing an
ingoftheAssociationforComputationalLinguistics
evaluationmetricisdebatedandmayaffectthein- (ACL’05),173–180.AssociationforComputational
terpretationofscoredifferences(Fernandesetal., Linguistics.
2022;Wangetal.,2024b).
JuliusChengandAndreasVlachos.2023. Fastermin-
BayesOpt+GP requires matrix inversion, a
imum Bayes risk decoding with confidence-based
O(|C|3)operationthatisperformedonceperitera- pruning. InProceedingsofthe2023Conferenceon
tion. Whileitisinexpensiveforthe|C|weconsider, Empirical Methods in Natural Language Process-
ing, 12473–12480. Association for Computational
thislimitsthenumberofobservationsthatcanbe
Linguistics.
usedforposteriorcomputationwithoutresortingto
approximations(Noacketal.,2023). MichaelCollinsandTerryKoo.2005. Discriminative
As an iterative algorithm, BayesOpt can score reranking for natural language parsing. Computa-
tionalLinguistics,31(1):25–70.
nomorethank candidatesinabatchforasingle
instance. Smallbatchsizesintroduceasignificant Andrew R. Conn, Katya Scheinberg, and Luis N. Vi-
bottleneck for large neural networks, so in order cente. 2009. Introduction to Derivative-Free Opti-
mization. SocietyforIndustrialandAppliedMathe-
tomaintainlargebatchsizes,weproposeprocess-
matics.
ing multiple instances in parallel. However, this
requiresadditionalengineering. AlexisConneau,KartikayKhandelwal,NamanGoyal,
Vishrav Chaudhary, Guillaume Wenzek, Francisco
Guzmán, Edouard Grave, Myle Ott, Luke Zettle-
References moyer,andVeselinStoyanov.2019. Unsupervised
cross-lingualrepresentationlearningatscale. CoRR,
DanielBeckandTrevorCohn.2017. Learningkernels abs/1911.02116.
overstringsusingGaussianprocesses. InProceed-
ingsoftheEighthInternationalJointConferenceon HiroyukiDeguchi,YusukeSakai,HidetakaKamigaito,
NaturalLanguageProcessing(Volume2: ShortPa- TaroWatanabe,HidekiTanaka,andMasaoUtiyama.
pers),67–73.AsianFederationofNaturalLanguage 2024. Centroid-based efficient minimum Bayes
Processing. risk decoding. In Findings of the Association for
ComputationalLinguisticsACL2024,11009–11018,
Daniel Beck, Trevor Cohn, and Lucia Specia. 2014. Bangkok,Thailandandvirtualmeeting.Association
Jointemotionanalysisviamulti-taskGaussianpro- forComputationalLinguistics.Sergey Edunov, Myle Ott, Michael Auli, and David desmoothing. InFindingsoftheAssociationforCom-
Grangier.2018. Understandingback-translationat putational Linguistics: EMNLP 2022, 3414–3427.
scale. In Proceedings of the 2018 Conference on AssociationforComputationalLinguistics.
EmpiricalMethodsinNaturalLanguageProcessing,
489–500.AssociationforComputationalLinguistics. DonaldR.Jones.2001. Ataxonomyofglobaloptimiza-
tionmethodsbasedonresponsesurfaces. Journalof
Bryan Eikema and Wilker Aziz. 2020. Is MAP de- GlobalOptimization,21:345–383.
coding all you need? the inadequacy of the mode
in neural machine translation. In Proceedings of JurajJuraska,MaraFinkelstein,DanielDeutsch,Aditya
the28thInternationalConferenceonComputational Siddhant, Mehdi Mirzazadeh, and Markus Freitag.
Linguistics,4506–4520.InternationalCommitteeon 2023. MetricX-23: The Google submission to the
ComputationalLinguistics. WMT2023metricssharedtask. InProceedingsof
theEighthConferenceonMachineTranslation,756–
BryanEikemaandWilkerAziz.2022. Sampling-based 767.AssociationforComputationalLinguistics.
approximationstominimumBayesriskdecodingfor
neural machine translation. In Proceedings of the KirthevasanKandasamy,GautamDasarathy,JunierB
2022ConferenceonEmpiricalMethodsinNatural Oliva, Jeff Schneider, and Barnabas Poczos. 2016.
LanguageProcessing,10978–10993.Associationfor Gaussian process bandit optimisation with multi-
ComputationalLinguistics. fidelity evaluations. In Advances in Neural Infor-
mationProcessingSystems,volume29.CurranAsso-
Patrick Fernandes, António Farinhas, Ricardo Rei, ciates,Inc.
JoséG.C.deSouza,PerezOgayo,GrahamNeubig,
andAndreMartins.2022. Quality-awaredecoding CenkKaynakandEthemAlpaydin.2000. MultiStage
for neural machine translation. In Proceedings of CascadingofMultipleClassifiers: OneMan’sNoise
the2022ConferenceoftheNorthAmericanChap- isAnotherMan’sData. InProceedingsofthe17th
teroftheAssociationforComputationalLinguistics: InternationalConferenceonMachineLearning,455–
HumanLanguageTechnologies,1396–1412.Associ- 462.MorganKaufmann.
ationforComputationalLinguistics.
Tom Kocmi, Eleftherios Avramidis, Rachel Bawden,
MaraFinkelstein,SubhajitNaskar,MehdiMirzazadeh, Ondˇrej Bojar, Anton Dvorkovich, Christian Feder-
ApurvaShah,andMarkusFreitag.2024. MBRand mann,MarkFishel,MarkusFreitag,ThammeGowda,
QEfinetuning: Training-timedistillationofthebest Roman Grundkiewicz, Barry Haddow, Marzena
andmostexpensivedecodingmethods. Karpinska,PhilippKoehn,BenjaminMarie,Christof
Monz, Kenton Murray, Masaaki Nagata, Martin
MarkusFreitag,BehroozGhorbani,andPatrickFernan- Popel, Maja Popovic´, Mariya Shmatova, Steinþór
des.2023a. Epsilonsamplingrocks: Investigating Steingrímsson,andVilémZouhar.2024a. Findings
samplingstrategiesforminimumBayesriskdecod- oftheWMT24generalmachinetranslationshared
ingformachinetranslation. InFindingsoftheAsso- task: TheLLMeraisherebutMTisnotsolvedyet.
ciationforComputationalLinguistics:EMNLP2023, WMT2024.
9198–9209.AssociationforComputationalLinguis-
tics. Tom Kocmi, Rachel Bawden, Ondˇrej Bojar, Anton
Dvorkovich, Christian Federmann, Mark Fishel,
MarkusFreitag,DavidGrangier,QijunTan,andBowen Thamme Gowda, Yvette Graham, Roman Grund-
Liang. 2022. High quality rather than high model kiewicz,BarryHaddow,RebeccaKnowles,Philipp
probability: MinimumBayesriskdecodingwithneu- Koehn,ChristofMonz,MakotoMorishita,Masaaki
ralmetrics. TransactionsoftheAssociationforCom- Nagata,ToshiakiNakazawa,MichalNovák,Martin
putationalLinguistics,10:811–825. Popel,andMajaPopovic´.2022. Findingsofthe2022
conference on machine translation (WMT22). In
Markus Freitag, Nitika Mathur, Chi-kiu Lo, Elefthe- ProceedingsoftheSeventhConferenceonMachine
riosAvramidis,RicardoRei,BrianThompson,Tom Translation(WMT),1–45.AssociationforComputa-
Kocmi,FredericBlain,DanielDeutsch,CraigStew- tionalLinguistics.
art, Chrysoula Zerva, Sheila Castilho, Alon Lavie,
andGeorgeFoster.2023b. ResultsofWMT23met- TomKocmi,VilémZouhar,ChristianFedermann,and
rics shared task: Metrics might be guilty but refer- MattPost.2024b. Navigatingthemetricsmaze: Rec-
encesarenotinnocent. InProceedingsoftheEighth onciling score magnitudes and accuracies. In Pro-
ConferenceonMachineTranslation,578–628.Asso- ceedingsofthe62ndAnnualMeetingoftheAssocia-
ciationforComputationalLinguistics. tionforComputationalLinguistics(Volume1: Long
Papers), 1999–2014, Bangkok, Thailand. Associa-
PhilippHennigandChristianJ.Schuler.2011. Entropy tionforComputationalLinguistics.
searchforinformation-efficientglobaloptimization.
ArXiv,abs/1112.1217. AndreasKrause,AjitSingh,andCarlosGuestrin.2008.
Near-optimal sensor placements in gaussian pro-
John Hewitt, Christopher Manning, and Percy Liang. cesses: Theory, efficient algorithms and empirical
2022. Truncation sampling as language model studies. J.Mach.Learn.Res.,9:235–284.Ann Lee, Michael Auli, and Marc’Aurelio Ranzato. Rico Sennrich, Barry Haddow, and Alexandra Birch.
2021. Discriminativererankingforneuralmachine 2016. Improving neural machine translation mod-
translation. InProceedingsofthe59thAnnualMeet- els with monolingual data. In Proceedings of the
ingoftheAssociationforComputationalLinguistics 54thAnnualMeetingoftheAssociationforCompu-
andthe11thInternationalJointConferenceonNatu- tationalLinguistics(Volume1: LongPapers),86–96.
ralLanguageProcessing(Volume1: LongPapers), AssociationforComputationalLinguistics.
7250–7264.AssociationforComputationalLinguis-
tics. BobakShahriari,KevinSwersky,ZiyunWang,RyanP.
Adams, and Nando de Freitas. 2016. Taking the
JonasMockus.1974. Onbayesianmethodsforseeking human out of the loop: A review of bayesian opti-
theextremum. InProceedingsoftheIFIPTechnical mization. ProceedingsoftheIEEE,104:148–175.
Conference,400–404.
PrasannSinghal,JiachengXu,XiYe,andGregDurrett.
Marcus M. Noack, Harinarayan Krishnan, Mark D. 2023. EEL:Efficientlyencodinglatticesforrerank-
Risser, and Kristofer G. Reyes. 2023. Exact gaus- ing. InProceedingsofthe61stAnnualMeetingof
sianprocessesformassivedatasetsvianon-stationary theAssociationforComputationalLinguistics(Vol-
sparsity-discovering kernels. Scientific Reports, ume 1: Long Papers), 9299–9316. Association for
13(1). ComputationalLinguistics.
MyleOtt,SergeyEdunov,DavidGrangier,andMichael NiranjanSrinivas,AndreasKrause,ShamM.Kakade,
Auli.2018. Scalingneuralmachinetranslation. In andMatthiasW.Seeger.2009. Information-theoretic
Proceedings of the Third Conference on Machine regretboundsforgaussianprocessoptimizationin
Translation: ResearchPapers,1–9.Associationfor thebanditsetting. IEEETransactionsonInformation
ComputationalLinguistics. Theory,58:3250–3265.
SlavPetrov.2011. Coarse-to-FineNaturalLanguage FelixStahlberg.2020. Neuralmachinetranslation: A
Processing(TheoryandApplicationsofNaturalLan- review. JournalofArtificialIntelligenceResearch,
guageProcessing). SpringerPublishingCompany, 69:343–418.
Incorporated.
NLLBTeam,MartaR.Costa-jussà,JamesCross,Onur
C.E.RasmussenandC.K.I.Williams.2005. Gaussian Çelebi,MahaElbayad,KennethHeafield,KevinHef-
ProcessesforMachineLearning. AdaptiveCompu- fernan, Elahe Kalbassi, Janice Lam, Daniel Licht,
tationandMachineLearningseries.MITPress. JeanMaillard,AnnaSun,SkylerWang,Guillaume
Wenzek, Al Youngblood, Bapi Akula, Loic Bar-
RicardoRei, AnaCFarinha, JoséG.C.deSouza, Pe- rault,GabrielMejiaGonzalez,PrangthipHansanti,
droG.Ramos,AndréF.T.Martins,LuisaCoheur,and John Hoffman, Semarley Jarrett, Kaushik Ram
Alon Lavie. 2022a. Searching for COMETINHO: Sadagopan, Dirk Rowe, Shannon Spruit, Chau
The little metric that could. In Proceedings of the Tran, Pierre Andrews, Necip Fazil Ayan, Shruti
23rdAnnualConferenceoftheEuropeanAssociation Bhosale, Sergey Edunov, Angela Fan, Cynthia
forMachineTranslation,61–70.EuropeanAssocia- Gao,VedanujGoswami,FranciscoGuzmán,Philipp
tionforMachineTranslation. Koehn, AlexandreMourachko, ChristopheRopers,
SafiyyahSaleem,HolgerSchwenk,andJeffWang.
RicardoRei,CraigStewart,AnaCFarinha,andAlon 2022. No language left behind: Scaling human-
Lavie.2020. COMET:AneuralframeworkforMT centeredmachinetranslation.
evaluation. InProceedingsofthe2020Conference
onEmpiricalMethodsinNaturalLanguageProcess- Firas Trabelsi, David Vilar, Mara Finkelstein, and
ing(EMNLP),2685–2702.AssociationforComputa- Markus Freitag. 2024. Efficient minimum bayes
tionalLinguistics. riskdecodingusinglow-rankmatrixcompletional-
gorithms.
Ricardo Rei, Marcos Treviso, Nuno M. Guerreiro,
ChrysoulaZerva,AnaCFarinha,ChristineMaroti, JannisVamvasandRicoSennrich.2024. Linear-time
José G. C. de Souza, Taisiya Glushkova, Duarte minimumBayesriskdecodingwithreferenceaggre-
Alves, Luisa Coheur, Alon Lavie, and André F. T. gation. InProceedingsofthe62ndAnnualMeeting
Martins.2022b. CometKiwi: IST-unbabel2022sub- oftheAssociationforComputationalLinguistics(Vol-
mission for the quality estimation shared task. In ume2: ShortPapers),790–801,Bangkok,Thailand.
ProceedingsoftheSeventhConferenceonMachine AssociationforComputationalLinguistics.
Translation(WMT),634–645.AssociationforCom-
putationalLinguistics. Giorgos Vernikos and Andrei Popescu-Belis. 2024.
Don’trank,combine!combiningmachinetranslation
ThibaultSellam,DipanjanDas,andAnkurParikh.2020. hypothesesusingqualityestimation. InProceedings
BLEURT: Learning robust metrics for text genera- of the 62nd Annual Meeting of the Association for
tion. InProceedingsofthe58thAnnualMeetingof ComputationalLinguistics(Volume1: LongPapers),
theAssociationforComputationalLinguistics,7881– 12087–12105, Bangkok, Thailand.Associationfor
7892.AssociationforComputationalLinguistics. ComputationalLinguistics.Jun Wang, Eleftheria Briakou, Hamid Dadkhahi,
Rishabh Agarwal, Colin Cherry, and Trevor Cohn.
2024a. Don’t throw away data: Better sequence
knowledgedistillation.
Jun Wang, Eleftheria Briakou, Hamid Dadkhahi,
Rishabh Agarwal, Colin Cherry, and Trevor Cohn.
2024b. Don’t throw away data: Better sequence
knowledgedistillation. ArXiv,abs/2407.10456.
WenhuiWang,FuruWei,LiDong,HangboBao,Nan
Yang, and Ming Zhou. 2020. MiniLM: Deep self-
attentiondistillationfortask-agnosticcompression
ofpre-trainedtransformers.
JianWu,SaulToscano-Palmerin,PeterI.Frazier,and
Andrew Gordon Wilson. 2020. Practical multi-
fidelity bayesian optimization for hyperparameter
tuning. InProceedingsofThe35thUncertaintyin
ArtificialIntelligenceConference,volume115ofPro-
ceedingsofMachineLearningResearch, 788–798.
PMLR.
YonghuiWu,MikeSchuster,ZhifengChen,QuocV.Le,
MohammadNorouzi,WolfgangMacherey,Maxim
Krikun,YuanCao,QinGao,KlausMacherey,Jeff
Klingner,ApurvaShah,MelvinJohnson,Xiaobing
Liu,ŁukaszKaiser,StephanGouws,YoshikiyoKato,
TakuKudo,HidetoKazawa,KeithStevens,George
Kurian,NishantPatil,WeiWang,CliffYoung,Jason
Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals,
Greg Corrado, Macduff Hughes, and Jeffrey Dean.
2016. Google’sneuralmachinetranslationsystem:
Bridgingthegapbetweenhumanandmachinetrans-
lation.
KyraYee,YannDauphin,andMichaelAuli.2019. Sim-
pleandeffectivenoisychannelmodelingforneural
machinetranslation. InProceedingsofthe2019Con-
ferenceonEmpiricalMethodsinNaturalLanguage
Processing and the 9th International Joint Confer-
ence on Natural Language Processing (EMNLP-
IJCNLP),5696–5701.AssociationforComputational
Linguistics.CometKiwiruns
Method Figure 10 20 30 40 50 60 70 80 90 100
UniqRandom 2 0.7917 0.8022 0.8074 0.8104 0.8124 0.8140 0.8149 0.8160 0.8168 0.8175
LogprobAvg 2 0.7956 0.8055 0.8101 0.8129 0.8149 0.8162 0.8171 0.8181 0.8187 0.8193
LogprobSum 2 0.7519 0.7723 0.7834 0.7913 0.7974 0.8019 0.8051 0.8081 0.8109 0.8125
HillClimbing 2 0.7917 0.8080 0.8124 0.8148 0.8165 0.8176 0.8184 0.8191 0.8196 0.8200
ProxyFirst200Distilled-S 4 0.8081 0.8141 0.8167 0.8181 0.8190 0.8197 0.8202 0.8206 0.8208 0.8210
ProxyFirst200Distilled-M 4 0.8119 0.8165 0.8184 0.8194 0.8201 0.8206 0.8209 0.8211 0.8212 0.8213
ProxyFirst50Distilled-S 4 0.8054 0.8100 0.8114 0.8121 0.8124 0.8140 0.8149 0.8160 0.8168 0.8175
ProxyFirst50Distilled-M 4 0.8073 0.8107 0.8119 0.8122 0.8124 0.8140 0.8149 0.8160 0.8168 0.8175
BayesOpt+GP 2,3,4 0.7917 0.8121 0.8167 0.8190 0.8201 0.8206 0.8210 0.8212 0.8213 0.8214
BayesOpt+GPwithLogprobAvg 3 0.7956 0.8123 0.8166 0.8187 0.8198 0.8205 0.8208 0.8210 0.8213 0.8214
BayesOpt+GPwith200Distilled-S 3,4 0.8081 0.8165 0.8190 0.8200 0.8207 0.8210 0.8212 0.8213 0.8214 0.8215
BayesOpt+GPwith200Distilled-M 3,4 0.8119 0.8182 0.8199 0.8205 0.8209 0.8211 0.8213 0.8214 0.8215 0.8215
BayesOpt+GPwith50Distilled-S 3,4 0.8054 0.8153 0.8184 0.8196 0.8204 0.8208 0.8210 0.8213 0.8214 0.8214
BayesOpt+GPwith50Distilled-M 3,4 0.8073 0.8164 0.8187 0.8200 0.8207 0.8209 0.8211 0.8213 0.8214 0.8215
CometKiwiruns
Method Figure 110 120 130 140 150 160 170 180 190 200
UniqRandom 2 0.8182 0.8188 0.8192 0.8197 0.8200 0.8205 0.8208 0.8211 0.8214 0.8216
LogprobAvg 2 0.8199 0.8203 0.8205 0.8209 0.8211 0.8212 0.8213 0.8214 0.8216 0.8216
LogprobSum 2 0.8139 0.8156 0.8170 0.8180 0.8188 0.8196 0.8204 0.8209 0.8212 0.8216
HillClimbing 2 0.8203 0.8206 0.8208 0.8209 0.8211 0.8213 0.8214 0.8215 0.8216 0.8216
BayesOpt+GP 2,3,4 0.8215 0.8215 0.8215 0.8216 0.8216 0.8216 0.8216 0.8216 0.8216 0.8216
BayesOpt+GPwithLogprobAvg 3 0.8214 0.8215 0.8215 0.8216 0.8216 0.8216 0.8216 0.8216 0.8216 0.8216
Table3: Exactvalues(selectedcandidatescore)forFigures2to4.A StatisticalSignificance
WemeasurestatisticalsignificancebetweentwomethodsbasedonthefinalcandidateCometKiwiscores
witheitherbudget30,60,90,oracrossthebudgetrangefrom10to190inTable4. Todeterminewhether
onemethodisbetterthananotherone,weuseone-sidedpairedStudent’st-testwithp-valuethreshold
0.01whichisrunacrosstheindividualsamples.
Budget30 Budget60
LogprobAvg ← ← ↑ ↑ LogprobAvg ← ← ↑ ↑
LogprobSum ↑ ↑ ↑ ↑ LogprobSum ↑ ↑ ↑ ↑
HillClimbing ← ← ← ↑ HillClimbing ← ← ← ↑
ProxyFirst200Distilled-S ← ← ← ← ProxyFirst200Distilled-S ← ← ← ← ↑
ProxyFirst200Distilled-M ← ← ← ← ← ProxyFirst200Distilled-M ← ← ← ←
ProxyFirst50Distilled-S ← ← ← ↑ ↑ ProxyFirst50Distilled-S ↑ ← ↑ ↑
ProxyFirst50Distilled-M ← ← ← ↑ ProxyFirst50Distilled-M ↑ ← ↑ ↑
BayesOpt+GP ← ← ← ← BayesOpt+GP ← ← ← ←
BayesOpt+GPwithLogprobAvg ← ← ← ← BayesOpt+GPwithLogprobAvg ← ← ← ←
BayesOpt+GPwith200Distilled-S ← ← ← ← ← BayesOpt+GPwith200Distilled-S ← ← ← ← ←
BayesOpt+GPwith200Distilled-M ← ← ← ← ← BayesOpt+GPwith200Distilled-M ← ← ← ← ←
BayesOpt+GPwith50Distilled-S ← ← ← ← ← BayesOpt+GPwith50Distilled-S ← ← ← ←
BayesOpt+GPwith50Distilled-M ← ← ← ← ← BayesOpt+GPwith50Distilled-M ← ← ← ← ←
Budget90 Acrossbudgets10to190
LogprobAvg ← ← ↑ ↑ LogprobAvg ← ← ↑ ↑
LogprobSum ↑ ↑ ↑ ↑ LogprobSum ↑ ↑ ↑ ↑
HillClimbing ← ← ← ↑ HillClimbing ← ← ← ↑
ProxyFirst200Distilled-S ← ← ← ← ↑ ProxyFirst200Distilled-S ← ← ← ← ←
ProxyFirst200Distilled-M ← ← ← ← ProxyFirst200Distilled-M ← ← ← ← ←
ProxyFirst50Distilled-S ↑ ← ↑ ↑ ProxyFirst50Distilled-S ← ↑ ← ↑ ↑
ProxyFirst50Distilled-M ↑ ← ↑ ↑ ProxyFirst50Distilled-M ← ← ↑ ↑
BayesOpt+GP ← ← ← ← BayesOpt+GP ← ← ← ←
BayesOpt+GPwithLogprobAvg ← ← ← ← BayesOpt+GPwithLogprobAvg ← ← ← ←
BayesOpt+GPwith200Distilled-S ← ← ← ← BayesOpt+GPwith200Distilled-S ← ← ← ← ←
BayesOpt+GPwith200Distilled-M ← ← ← ← ← BayesOpt+GPwith200Distilled-M ← ← ← ← ←
BayesOpt+GPwith50Distilled-S ← ← ← ← BayesOpt+GPwith50Distilled-S ← ← ← ← ←
BayesOpt+GPwith50Distilled-M ← ← ← ← BayesOpt+GPwith50Distilled-M ← ← ← ← ←
Table4: StatisticalsignificancecomparisonbetweenproposedmethodsacrossvariousCometKiwicallsbudgets.
Withinacell,↑meansthatthecolumnmethod(inheader)isstatisticallysignificantlybetterthantherowmethod
and←meanstheopposite. Ifacellisempty,noneofthemethodsaresignificantlybetterthantheotherone. For
example,inBudget30(topleft)table,inthirdrowandfirstcolumn,←meansthatHillClimbingissignificantly
betterthanUniqRandominthesetupofbudgetof30.
modnaRqinU
modnaRqinU
gvAborpgoL
gvAborpgoL
muSborpgoL
muSborpgoL
gnibmilClliH
gnibmilClliH
PG+tpOseyaB
PG+tpOseyaB
modnaRqinU
modnaRqinU
gvAborpgoL
gvAborpgoL
muSborpgoL
muSborpgoL
gnibmilClliH
gnibmilClliH
PG+tpOseyaB
PG+tpOseyaB