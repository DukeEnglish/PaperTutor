Provocation: Who benefits from “inclusion” in
Generative AI?
SamanthaDalal∗ SiobhanMackenzieHall∗
UniversityofColoradoBoulder UniversityofOxford
samantha.dalal@colorado.edu siobhan.hall@nds.ox.ac.uk
NariJohnson∗
CarnegieMellonUniversity
narij@andrew.cmu.edu
We intend to challenge
the current norms of
Participatory AI as
depicted here: Community members rely on institutions that
develop AI technologies to:
1. Create models that have accurate, dignified, and
fair representations
2. Create accessible interfaces and affordable
versions they can use
3. Implement policies to protect their likeness and
protect them from algorithmic harms (e.g.,
impersonation)
Community Social actors rely on
members rely on technology
other actors to institutions to
contribute to develop models that
Community members societal-level Social Actors create accurate Technology Institutions
representation (Freelance artists / marketing representations
agencies / textbook
manufacturers)
Technology institutions rely on community
members to enrich their data
All icons in this figure were downloaded
from Flaticon with a licence.
Figure1: Wemapthedependenciesthatoftenexistbetweenkeystakeholdergroups: (1)membersof
marginalizedcommunities,(2)othersocialactorswhouseGenAItools,and(3)institutions(suchas
privatetechnologycompaniesoracademicuniversities)thatdevelopGenAImodels,inparticipatory
engagementstoimprovehowmarginalizedcommunitiesarerepresentedbyGenAI.Inthispaper,we
discusshowthesedependenciesposebarriersformarginalizedcommunitiestorealizethebenefitsof
improvedAImodels.
Sociallymarginalizedgroupsdisproportionatelyexperiencerepresentationalharmscausedbygen-
erativeAIsystems[1,2,3,4,5,6,7]. Forexample,populartext-to-image(T2I)modelshavebeen
showntogenerateinaccurate,culturallymisrepresentative,andinsensitivedepictionsofracialand
ethnicminorities[1],peoplewithdisabilities[5],andfoodsfromtheAfricancontinent[4]. Asthe
AIcommunitybeginstoacknowledgethelimitsofInternet-scrapeddatasetsandthenarrowingof
∗Equalcontribution.
38thConferenceonNeuralInformationProcessingSystems(NeurIPS2024).
4202
voN
41
]YC.sc[
1v20190.1142:viXravaluesandperspectivesinvolvedinAIdesignprocedures[8,9,10,11,12],thereisanundeniable
needtomovetowardsincludingmorecommunityexpertiseandinput. However,participationfrom
communitymembersrunstheriskofbeingextractive,asmanyparticipatoryengagementsinvolve
exposingparticipantstopsychologicallyharmfulordemeaningAI-generatedcontent[2,4,5,13].
More broadly, expertise is shifted from marginalized communities to AI model owners without
commensuratestructuresforcontinuedcommunityagencyandownershipoveroutputs[14,15,16].
Inthisprovocation,wearguethatdominantstructuresofcommunityparticipationinAIdevelopment
and evaluation are not explicit enough about the benefits and harms that members of socially
marginalizedgroupsmayexperienceasaresultoftheirparticipation[17].Participationisincreasingly
motivated by trickle-down effect logics: model improvement will address stereotypes and help
preservematerialculture [2,3,4]. However,thepotentialforextractiveandexploitativepracticesin
participationisnotnecessarilygiventhesameconsideration. Weareconcernedthattheclaimthat
communitymemberswillbebetteroffasaresultoftheirparticipationisempty,giventheimmensity
ofsystemicchangethatisneededaswell. Wepresentaspeculativecasestudy[18,19,20],basedon
ourcollectiveexperiencesdoingcommunity-engagedresearchinAI,tointerrogatethepromisesAI
developersmaketomembersofmarginalizedgroups,anditemizethebarriersthatrealisticallyneed
tobeovercomefortheproposedbenefitstomarginalizedcommunitiestoberealized.
SpeculativeCaseStudy: Howdocommunitymembersrealizebenefits&harmsfromimproved
GenAIperformance? Researchersdonotyetfullyunderstandhowtoleveragetechnicalmachine
learningcapabilitiestoimprovetherepresentationofmarginalizedcommunitiesinGenAImodels[21,
22,23,24]. Thus,wedonotalwaysknowwhetherincorporatingcommunityfeedbackduringthe
developmentprocesswillnecessarilyleadtoan“improved”AImodel. Regardless,webelieveit
is important to investigate the key premise motivating participatory approaches to AI: (How) do
improvedrepresentationsinGenAImodelsbenefitmembersofmarginalizedgroups?
TointerrogatewhomdominantstructuresofcommunityparticipationinGenAIdevelopmentbenefit,
we present a hypothetical scenario where a technology company invites Vietnamese community
memberstoparticipateinthedevelopmentandevaluationofaT2Isystem. Thecasestudythatwe
presentismeanttobeanabstractionofhigher-levelthemesthatweobservedoverourexperiences
workingasAIresearcherswithinindustryandacademiccontexts. Weusethisgroundingcontextto
tracetheflowofpotentialbenefitsandharmsbetweendifferentgroupsofstakeholders.
Scenario: Thuy,aculturalpreservationactivistinVietnam,isinvitedtoparticipateinatechnology
company’sAIdataenrichmentinitiativewherecommunitymemberslabelphotographsofVietnamese
cultural artifacts for AI training and evaluation. The company aims to improve the depiction of
“Majority World” cultures [25] in T2I systems to support improved quality-of-service [26], and
ThuyisexcitedtopartakeinthisefforttoimproveVietnameserepresentationinglobalmedia. The
companybelievesthatimprovedquality-of-servicecanhelpVietnameseuserscreateimagesthat
accuratelyreflecttheirculture,forpersonalprojectsoreducationalpurposes.Othersocialactors,such
asmarketingagencies,textbookpublishers,andfreelanceartists,canalsobenefitfromgenerating
inclusiveandaccuratemedia. Thetechnologycompanyadoptsacommonstructureofparticipation
[27]toengagewithThuyandotherVietnamesecommunityadvocates: theyprovideparticipantswith
one-timecompensationforprovidingdataandexpertise. Thecompanyhasnotexploredpathsfor
participantownershiporcontroloverdataorAImodelsthatarecreatedasaresultoftheengagement.
(How)cancommunitymembersbenefitwhentheyareend-users? Thuyandothermembersof
hercommunitymayfacefinancialbarriersinrealizingthebenefitsofimprovedqualityofservice
inT2Imodels. WhileThuyisprovidedwithone-timecompensationforherparticipation,shedoes
notcontinuetofinanciallybenefitfromthefutureuseofherdataortheAImodelsitwasusedto
improve. ThecompanycanimproveitsT2Iofferingsandmonetizeitscompetitiveadvantageby
puttingitsservicesbehindapaywall. Thuy’speersandothermemberscannowusethemodelto
generateaccuratedepictionsoftheirlikeness,butmustnavigatethecompany’spaywallstructures.
DuetoalackofownershipovertheirdataandresultingAImodels,communityambassadorslike
Thuyaresoldbackmodelswithimprovementsthatwouldnothavebeenpossiblewithouttheirlabor.
Beyondnavigatingpaywalls,Thuyandothercommunitymembersfaceadditionalbarriersinaccess-
ingandusingthecompany’smodels.Forexample,formanymarginalizedcommunities,modelaccess
canbecomplicatedbyseveralpotentialissuessuchasalackofreliableInternetconnectivity[4]and
inaccessibleuserinterfaces[28,29]. Thus,Thuyisunlikelytobeabletorealizethebenefitsofthe
model’simprovedperformanceasanend-userifshecannotreliablyaccessandnavigateitsinterface.
2(How)cancommunitymembersbenefitwhentheyarenotend-users? Thuymayfacesocio-
political barriers in realizing indirect benefits resulting from social actors using T2I models as
end-userstocreateimagesoftheVietnamesecommunity. Manyresearchershavearguedthatdueto
theincreasingprevalenceofAI-generatedmedia,GenAIsystemswillshapesocietalrepresentation
[5,6,30,31,32]andthusprecipitatechangeinsocietalattitudestowardsmarginalizedcommunities.
Forexample,amarketingfirmmayusetheGenAImodeltocreateimagesforanadcampaignthat
depictsVietnamesepeopleandculture,whichisthenseenbymillionsofpeople.
However,mediastudiesscholarshaveidentifiedthatrepresentationinmediaalonewillnotresult
indirectchangetomaterialcircumstancesformarginalizedcommunities[33,34,35]. Thepolitical
economyofthemediaecosystem, includingindustrylogicsandfinancialincentives, dictatesthe
kindsofmediathatareproduced [36]. Thus,Thuyisunlikelytorealizethebenefitsofsocialactors
usingT2Imodelstocreateimagesofhercommunityunlesssocial,political,andeconomicconditions
allaligntotransformvisibilityintopoliticalpower.
HarmsmarginalizedgroupscanexperienceasaresultoftheirparticipationIncreasedvisibility
inAI-generatedmediamaymakemarginalizedcommunitiessusceptibletoawideandemerging
range of AI-mediated harms [26, 37]. For example, as social actors (e.g., textbook companies)
realizethattheycanuseAItogenerateaccuratedepictionsofVietnameseculture,theymaynolonger
consultorcompensateVietnamesecommunitymembers, resultinginfurtherfinancialandsocial
marginalization [38,39,40]. Otheractorscanexploitimprovedrepresentationsofmarginalized
communitiestoinflictharmsuchasimpersonation,misinformation,orthecreationofviolent/NSFW
content [41,42]. Thus, membersofmarginalizedcommunitiesrelyontechnologyinstitutionsto
implementeffectivepoliciestoprotecttheirlikeness. Whilethetechnologycompanycouldimplement
mitigationsteps(e.g.,accessrestrictionsorusagelicenses [43,44])topreventmisuse,theymayfind
thematoddswiththeirprofitmotives.
Implications While the details of this scenario were speculative, the discussed model of partici-
patoryengagementasone-timeconsultationillustratestherealityofhowtechnologyinstitutions
andacademicresearchersoftenengagesociallymarginalizedcommunitiesinAIdevelopmenttoday
[17,27,45]. Thus,weurgethebroaderAIcommunity,includingthosewhoconstructorparticipate
inparticipatoryengagements,tocriticallyevaluatewhetherthesedominantstructuresofparticipation
doinfactyieldtheirintendedbenefitsformarginalizedcommunities. AIresearchersandindustry
actorswhoareconductingparticipatoryengagementswithmarginalizedcommunitiesshouldbemore
transparenttoparticipantsandthecommunityabouttheaccessibilityofbenefitstoparticipantsand
the contingencies upon which these benefits rely. In Appendix A, we pose future directions and
highlightpromisingexamplestowardsrestructuringparticipationbeyondconsultation,andtowards
supportingmeaningfulcommunityownership,participation,andpoweroverAI.
31 Broaderimpactstatement
Asdiscussedinourprovocation,webelievethatparticipatoryengagementswithsociallymarginalized
groups are critical to the broader field of AI and machine learning. We urge researchers to ask
themselves how communities whose participation we solicit can benefit from improved model
performance. Thiscriticalself-reflectionrequiresthatresearchersmapoutboththedirectbenefits
participantscouldexperienceasend-usersandtheindirectbenefitsparticipantscouldrealizeasa
resultofothersocialactorsusingAIsystemsdevelopedwithcommunityinput. Understandinghow
suchparticipatoryengagementscanbestructuredisoftimelyimportancegiventherapidlyadvancing
capabilitiesofgenerativeAI;newregulatoryandpolicyrequirementsthatrequireconsultationwith
impactedgroups[46,47];andtocombattheincreasingcentralizationofpowerinwhohasasayin
AI’sincreasinginfluenceonsociety[16].
2 Limitations
Weacknowledgethelimitationsofouranalysis,whichiscenteredaroundaspeculativecasestudy
withimaginedactors. ThebarrierstorealizingbenefitsfromAIthatwesurfacedinourcasestudy
werebasedonthisspeculativecontextinformedbyourpastexperiences(e.g.,thecommunitieswe
aremembersof,orhaveengagedinresearchwithbefore)andourpositionalityasAIresearchers.
Futureworkcanengagemoredeeplyinanalyzingreal-worldexamplesofparticipatoryengagements
withsociallymarginalizedgroups,andunderstandinghowbarriersparticipantsfacewhenrealizing
benefitsvaryacrosssharedidentitiesandcontexts.
In this short piece, we briefly sketch the “dominant structures” of participation [27] in GenAI
evaluation,ourconcernswiththesestructures,andpotentialpathsforward.Indoingso,ourgoalisnot
tocritiquethepremisethatsociallymarginalizedcommunitiesshouldbeinvolvedinAIdevelopment
andevaluation;orthatexistingparticipatoryeffortsshouldnotbepursued. Rather,weremainhopeful
that more deeply interrogating how participation is structured can lead to more empowering and
constructivewaysofengagingsociallymarginalizedcommunities. Deeperengagementbeyondwhat
wecoulddowithinthisworkshoppapercontributionisrequiredtounderstandhowstructuresof
participationinGenAIdevelopmentandevaluationcanbeshapedtosupporttheequitabledistribution
ofbenefitsandpoweramongstakeholders.
AcknowledgmentsandDisclosureofFunding
We thank Michael Madaio, Calvin Liang, Michael Feffer, and the anonymous reviewers at the
NeurIPS2024EvalEvalWorkshopforofferingfeedbackonthiswork. NJacknowledgessupport
fromtheNSF(IIS2040929andIIS2229881)andtheBlockCenterforTechnologyandSocietyat
CMU.Anyopinions,findings,conclusions,orrecommendationsexpressedinthismaterialarethose
oftheauthorsanddonotreflecttheviewsoftheNationalScienceFoundationandotherfunding
agencies.
4References
[1] FedericoBianchi,PratyushaKalluri,EsinDurmus,FaisalLadhak,MyraCheng,DeboraNozza,Tatsunori
Hashimoto,DanJurafsky,JamesZou,andAylinCaliskan. Easilyaccessibletext-to-imagegeneration
amplifiesdemographicstereotypesatlargescale. InProceedingsofthe2023ACMConferenceonFairness,
Accountability,andTransparency,FAccT’23,page1493–1504,NewYork,NY,USA,2023.Association
forComputingMachinery.
[2] MelissaHall,SamuelJ.Bell,CandaceRoss,AdinaWilliams,MichalDrozdzal,andAdrianaRomero
Soriano. Towardsgeographicinclusionintheevaluationoftext-to-imagemodels. InProceedingsofthe
2024ACMConferenceonFairness,Accountability,andTransparency,FAccT’24,page585–601,New
York,NY,USA,2024.AssociationforComputingMachinery.
[3] AgrimaSeth,SanchitAhuja,KalikaBali,andSunayanaSitaram. Dosa:Adatasetofsocialartifactsfrom
differentindiangeographicalsubcultures,2024.
[4] JabezMagomere,ShuIshida,TejumadeAfonja,AyaSalama,DanielKochin,FoutseYuehgoh,Imane
Hamzaoui,RaesetjeSefala,AishaAlaagib,ElizavetaSemenova,LaurenCrais,andSiobhanMackenzie
Hall. Youarewhatyoueat?feedingfoundationmodelsaregionallydiversefooddatasetofworldwide
dishes. 2024.
[5] KellyAveryMack,RidaQadri,RemiDenton,ShaunK.Kane,andCynthiaL.Bennett. “theyonlycareto
showusthewheelchair”:disabilityrepresentationintext-to-imageaimodels. InProceedingsoftheCHI
ConferenceonHumanFactorsinComputingSystems,CHI’24,NewYork,NY,USA,2024.Association
forComputingMachinery.
[6] JaredKatzman,AngelinaWang,MorganScheuerman,SuLinBlodgett,KristenLaird,HannaWallach,and
SolonBarocas. Taxonomizingandmeasuringrepresentationalharms:Alookatimagetagging,2023.
[7] Solon Barocas, Kate Crawford, Aaron Shapiro, and Hanna Wallach. The problem with bias: From
allocativetorepresentationalharmsinmachinelearning. InSIGCISconferencepaper,2017.
[8] AbebaBirhane,SepehrDehdashtian,VinayPrabhu,andVishnuBoddeti. Thedarksideofdatasetscaling:
Evaluatingracialclassificationinmultimodalmodels. InProceedingsofthe2024ACMConferenceon
Fairness,Accountability,andTransparency,FAccT’24,page1229–1244,NewYork,NY,USA,2024.
AssociationforComputingMachinery.
[9] AbebaBirhane,PratyushaKalluri,DallasCard,WilliamAgnew,RavitDotan,andMichelleBao. The
valuesencodedinmachinelearningresearch,2022.
[10] RachelHong,WilliamAgnew,TadayoshiKohno,andJamieMorgenstern. Who’sinandwho’sout?acase
studyofmultimodalclip-filteringindatacomp,2024.
[11] TerranceDeVries,IshanMisra,ChanghanWang,andLaurensvanderMaaten. Doesobjectrecognition
workforeveryone?,2019.
[12] Yong Cao, Li Zhou, Seolhwa Lee, Laura Cabello, Min Chen, and Daniel Hershcovich. Assessing
cross-culturalalignmentbetweenChatGPTandhumansocieties: Anempiricalstudy. InSunipaDev,
VinodkumarPrabhakaran,DavidAdelani,DirkHovy,andLucianaBenotti,editors,Proceedingsofthe
FirstWorkshoponCross-CulturalConsiderationsinNLP(C3NLP),pages53–67,Dubrovnik,Croatia,
May2023.AssociationforComputationalLinguistics.
[13] AliceQianZhang,RylandShaw,JacyReeseAnthis,AshleeMilton,EmilyTseng,JinaSuh,LamaAhmad,
RamShankarSivaKumar,JulianPosada,BenjaminShestakofsky,SarahT.Roberts,andMaryL.Gray.
Thehumanfactorinairedteaming:Perspectivesfromsocialandcollaborativecomputing. arXivpreprint
arXiv:2407.07786,2024.
[14] Jennifer Pierre, Roderic Crooks, Morgan Currie, Britt Paris, and Irene Pasquetto. Getting ourselves
together:Data-centeredparticipatorydesignresearch&epistemicburden. InProceedingsofthe2021CHI
ConferenceonHumanFactorsinComputingSystems,pages1–11,YokohamaJapan,May2021.ACM.
[15] VictorOjewale,RyanSteed,BrianaVecchione,AbebaBirhane,andInioluwaDeborahRaji. Towardsai
accountabilityinfrastructure:Gapsandopportunitiesinaiaudittooling,March2024.
[16] Abeba Birhane, William Isaac, Vinodkumar Prabhakaran, Mark Diaz, Madeleine Clare Elish, Iason
Gabriel, and Shakir Mohamed. Power to the people? opportunities and challenges for participatory
ai. InProceedingsofthe2ndACMConferenceonEquityandAccessinAlgorithms,Mechanisms,and
Optimization,EAAMO’22,NewYork,NY,USA,2022.AssociationforComputingMachinery.
[17] FernandoDelgado,StephenYang,MichaelMadaio,andQianYang. Theparticipatoryturninaidesign:
Theoreticalfoundationsandthecurrentstateofpractice,2023.
[18] CaseyFiesler. Innovatinglikeanoptimist,preparinglikeapessimist:Ethicalspeculationandthelegal
imagination. Colo.Tech.LJ,19:1,2021.
5[19] NinaBozicYamsandÁlvaroArandaMuñoz. Poeticsoffuturework:Blendingspeculativedesignwith
artisticmethodology. InExtendedAbstractsofthe2021CHIConferenceonHumanFactorsinComputing
Systems,CHIEA’21,NewYork,NY,USA,2021.AssociationforComputingMachinery.
[20] ShamikaKlassenandCaseyFiesler. Thestoop: speculationonpositivefuturesofblackdigitalspaces.
ProceedingsoftheACMonHuman-ComputerInteraction,7(GROUP):1–24,2023.
[21] Daniela Massiceti, Camilla Longden, Agnieszka Słowik, Samuel Wills, Martin Grayson, and Cecily
Morrison. Explainingclip’sperformancedisparitiesondatafromblind/lowvisionusers,2024.
[22] RohitGandikota,HadasOrgad,YonatanBelinkov,JoannaMaterzyn´ska,andDavidBau. Unifiedconcept
editingindiffusionmodels,2023.
[23] RanjitaNaikandBesmiraNushi. Socialbiasesthroughthetext-to-imagegenerationlens. InProceedings
ofthe2023AAAI/ACMConferenceonAI,Ethics,andSociety,AIES’23,page786–808,NewYork,NY,
USA,2023.AssociationforComputingMachinery.
[24] Preethi Seshadri, Sameer Singh, and Yanai Elazar. The bias amplification paradox in text-to-image
generation,2023.
[25] Shahidul Alam. Majority world: Challenging the west’s rhetoric of democracy. Amerasia Journal,
34:87–98,012008.
[26] Renee Shelby, Shalaleh Rismani, Kathryn Henne, AJung Moon, Negar Rostamzadeh, Paul Nicholas,
N’MahYilla,JessGallegos,AndrewSmart,EmilioGarcia,andGurleenVirk. Sociotechnicalharmsof
algorithmicsystems:Scopingataxonomyforharmreduction,2023.
[27] HariniSuresh,EmilyTseng,MegYoung,MaryGray,EmmaPierson,andKarenLevy. Participationin
theageoffoundationmodels. InProceedingsofthe2024ACMConferenceonFairness,Accountability,
andTransparency,FAccT’24,page1609–1621,NewYork,NY,USA,2024.AssociationforComputing
Machinery.
[28] AleksiVäisänen. Guidelinessupportedevaluationofuserinterfaceswithgenerativeai. 2024.
[29] MaitrayeDas,AlexanderJ.Fiannaca,MeredithRingelMorris,ShaunK.Kane,andCynthiaL.Bennett.
Fromprovenancetoaberrations: Imagecreatorandscreenreaderuserperspectivesonalttextforai-
generatedimages. InProceedingsofthe2024CHIConferenceonHumanFactorsinComputingSystems,
CHI’24,NewYork,NY,USA,2024.AssociationforComputingMachinery.
[30] Tarleton Gillespie. Generative ai and the politics of visibility. Big Data & Society,
11(2):20539517241252131,June2024.
[31] SafiyaUmojaNoble. AlgorithmsofOppression:HowSearchEnginesReinforceRacism. NYUPress,New
York,2018.
[32] JoyBuolamwiniandTimnitGebru. Gendershades: Intersectionalaccuracydisparitiesincommercial
genderclassification. InConferenceonfairness,accountabilityandtransparency,pages77–91.PMLR,
2018.
[33] HermanGray. Subject(ed)torecognition. AmericanQuarterly,65(4):771–798,2013.
[34] KristenJ.Warner. Inthetimeofplasticrepresentation. FilmQuarterly,71(2):32–37,2017.
[35] AnamikSaha. Beards, scarves, halalmeat, terrorists, forcedmarriage’: televisionindustriesandthe
productionof‘race. Media,Culture&Society,34(4):424–438,2012.
[36] AdrienneShawandKatherineSender. Queertechnologies:Affordances,affect,ambivalence,2016.
[37] AtliSigurgeirssonandEddieL.Ungless. Justbecausewecamp,doesn’tmeanweshould:Theethicsof
modellingqueervoices,2024.
[38] RiddhiSetty. Aithreatenstopushhumanfashionmodelsoutofthepicture,January2024. Accessed:
2024-09-10.
[39] WilliamAgnew,A.StevieBergman,JenniferChien,MarkDíaz,SeliemEl-Sayed,JaylenPittman,Shakir
Mohamed,andKevinR.McKee. Theillusionofartificialinclusion. InProceedingsoftheCHIConference
onHumanFactorsinComputingSystems,volume35ofCHI’24,page1–12.ACM,May2024.
[40] CedricDeslandesWhitneyandJustinNorman. Realrisksoffakedata:Syntheticdata,diversity-washing
andconsentcircumvention. InProceedingsofthe2024ACMConferenceonFairness,Accountability,
andTransparency,FAccT’24,page1733–1744,NewYork,NY,USA,2024.AssociationforComputing
Machinery.
[41] FelipeRomeroMoreno. Generativeaianddeepfakes:ahumanrightsapproachtotacklingharmfulcontent.
InternationalReviewofLaw,Computers&Technology,pages1–30,2024.
[42] AuréliePetit. Thelimitsofzerotolerancepoliciesforanimatedpornographicmedia. PornStudies,2024.
SpecialIssue‘ArtificialIntelligence,Pornography,andSexWork’(forthcoming).
6[43] PaulT.Brown,DanielWilson,KiriWest,Kirita-RoseEscott,KiyaBasabas,BenRitchie,DanielleLucas,
IvyTaia,NatalieKusabs,andTeTakaKeegan. Ma¯orialgorithmicsovereignty:idea,principles,anduse,
2023.
[44] TheDataScienceLawLab. Licensingafricandatasets,September2024. Accessed:2024-09-10.
[45] MegYoung,UpolEhsan,RanjitSingh,EmnetTafesse,MicheleGilman,ChristinaHarrington,andJacob
Metcalf. Participationversusscale:Tensionsinthepracticaldemandsonparticipatoryai. FirstMonday,
29(4),Apr.2024.
[46] Shiming Hu and Yifan Li. Policy interventions and regulations on generative artificial intelligence:
Keygapsandcorechallenges. InProceedingsofthe25thAnnualInternationalConferenceonDigital
GovernmentResearch,dg.o’24,page1034–1036,NewYork,NY,USA,2024.AssociationforComputing
Machinery.
[47] PhilippHacker,AndreasEngel,andMarcoMauer.Regulatingchatgptandotherlargegenerativeaimodels.
InProceedingsofthe2023ACMConferenceonFairness,Accountability,andTransparency,FAccT’23,
page1112–1123,NewYork,NY,USA,2023.AssociationforComputingMachinery.
[48] KimberlyAChristen. Doesinformationreallywanttobefree?indigenousknowledgesystemsandthe
questionofopenness. InternationalJournalofCommunication,6:24,2012.
[49] NicholasVincent,HanlinLi,NicoleTilly,StevieChancellor,andBrentHecht.Dataleverage:Aframework
forempoweringthepublicinitsrelationshipwithtechnologycompanies. InProceedingsofthe2021ACM
ConferenceonFairness,Accountability,andTransparency,pages215–227,2021.
[50] ShivalikaSingh,FreddieVargus,DanielDsouza,BörjeFKarlsson,AbinayaMahendiran,Wei-YinKo,
HerumbShandilya,JayPatel,DeividasMataciunas,LauraOMahony,etal. Ayadataset:Anopen-access
collectionformultilingualinstructiontuning. arXivpreprintarXiv:2402.06619,2024.
[51] WilhelminaNekoto,VukosiMarivate,TshinondiwaMatsila,TimiFasubaa,TajudeenKolawole,Taiwo
Fagbohungbe,SolomonOluwoleAkinola,ShamsuddeenHassanMuhammad,SalomonKabongo,Sa-
lomeyOsei,SackeyFreshia,RubungoAndreNiyongabo,RickyMacharm,PerezOgayo,Orevaoghene
Ahia, Musie Meressa, Mofe Adeyemi, Masabata Mokgesi-Selinga, Lawrence Okegbemi, Laura Jane
Martinus,KolawoleTajudeen,KevinDegila,KelechiOgueji,KathleenSiminyu,JuliaKreutzer,Jason
Webster,JamiilToureAli,JadeAbbott,IroroOrife,IgnatiusEzeani,IdrisAbdulkabirDangana,Herman
Kamper,HadyElsahar,GoodnessDuru,GhollahKioko,EspoirMurhabazi,ElanvanBiljon,DanielWhite-
nack,ChristopherOnyefuluchi,ChrisEmezue,BonaventureDossou,BlessingSibanda,BlessingItoro
Bassey,AyodeleOlabiyi,ArshathRamkilowan,AlpÖktem,AdewaleAkinfaderin,andAbdallahBashir.
Participatoryresearchforlow-resourcedmachinetranslation:Acasestudyinafricanlanguages,2020.
[52] DavidRomero,ChenyangLyu,HaryoAkbariantoWibowo,TeresaLynn,InjyHamed,AdityaNanda
Kishore,AishikMandal,AlinaDragonetti,ArtemAbzaliev,AtnafuLambeboTonja,BontuFufaBalcha,
ChenxiWhitehouse, ChristianSalamea, DanJohnVelasco, DavidIfeoluwaAdelani, DavidLeMeur,
EmilioVilla-Cueva,FajriKoto,FauzanFarooqui,FredericoBelcavello,GanzorigBatnasan,GiselaVallejo,
GrainneCaulfield,GuidoIvetta,HaiyueSong,HenokBiadglignAdemtew,HernánMaina,HolyLovenia,
Israel Abebe Azime, Jan Christian Blaise Cruz, Jay Gala, Jiahui Geng, Jesus-German Ortiz-Barajas,
JinheonBaek,JocelynDunstan,LauraAlonsoAlemany,KumaranageRavinduYasasNagasinghe,Luciana
Benotti,LuisFernandoD’Haro,MarceloViridiano,MarcosEstecha-Garitagoitia,MariaCamilaBuitrago
Cabrera, Mario Rodríguez-Cantelar, Mélanie Jouitteau, Mihail Mihaylov, Mohamed Fazli Mohamed
Imam,MuhammadFaridAdilazuarda,MunkhjargalGochoo,Munkh-ErdeneOtgonbold,NaomeEtori,
OlivierNiyomugisha, PaulaMónicaSilva, PranjalChitale, RajDabre, RendiChevi, RuochenZhang,
RyanditoDiandaru,SamuelCahyawijaya,SantiagoGóngora,SoyeongJeong,SukannyaPurkayastha,
TatsukiKuribayashi,TeresaClifford,ThanmayJayakumar,TiagoTimponiTorrent,ToqeerEhsan,Vladimir
Araujo,YovaKementchedjhieva,ZaraBurzo,ZhengWeiLim,ZhengXinYong,OanaIgnat,JoanNwatu,
Rada Mihalcea, Thamar Solorio, and Alham Fikri Aji. Cvqa: Culturally-diverse multilingual visual
questionansweringbenchmark,2024.
[53] HellinaHailuNigatu,AtnafuLambeboTonja,BenjaminRosman,ThamarSolorio,andMonojitChoudhury.
Thezeno’sparadoxof‘low-resource’languages. InYaserAl-Onaizan,MohitBansal,andYun-NungChen,
editors,Proceedingsofthe2024ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages
17753–17774,Miami,Florida,USA,November2024.AssociationforComputationalLinguistics.
[54] AtnafuLambeboTonja,BonaventureF.P.Dossou,JessicaOjo,JenaleaRajab,FadelThior,EricPeter
Wairagala,AnuoluwapoAremu,PelonomiMoiloa,JadeAbbott,VukosiMarivate,andBenjaminRosman.
Inkubalm:Asmalllanguagemodelforlow-resourceafricanlanguages,2024.
[55] KarenHao. Anewvisionofartificialintelligenceforthepeople,2022.
[56] AsmelashTekaHadguandPaulAzunreandTimnitGebru. Combatingharmfulhypeinnaturallanguage
processing,2023. Accessed:2024-09-10.
7[57] DanishContractor,DanielMcDuff,JuliaKatherineHaines,JennyLee,ChristopherHines,BrentHecht,
NicholasVincent,andHanlinLi. Behavioraluselicensingforresponsibleai. In2022ACMConferenceon
Fairness,Accountability,andTransparency,FAccT’22,page778–788.ACM,June2022.
[58] DanielMcDuff, TimKorjakow, ScottCambo, JesseJosuaBenjamin, JennyLee, YacineJernite, Car-
losMuñozFerrandis,AaronGokaslan,AlekTarkowski,JosephLindley,A.FederCooper,andDanish
Contractor. Onthestandardizationofbehavioraluseclausesandtheiradoptionforresponsiblelicensingof
ai,2024.
[59] COkorieandMOmino. Licensingafricandatasets,2024.
[60] JunweiDeng,ShiyuanZhang,andJiaqiMa. Computationalcopyright:Towardsaroyaltymodelformusic
generativeai,2024.
[61] EricP.S.BaumerandM.SixSilberman.Whentheimplicationisnottodesign(technology).InProceedings
oftheSIGCHIConferenceonHumanFactorsinComputingSystems,CHI’11,page2271–2274,New
York,NY,USA,2011.AssociationforComputingMachinery.
[62] NouraHowell,AudreyDesjardins,andSarahFox. Cracksinthesuccessnarrative: Rethinkingfailure
indesignresearchthrougharetrospectivetrioethnography. ACMTrans.Comput.-Hum.Interact.,28(6),
November2021.
[63] EmanuelMoss,ElizabethAnneWatkins,RanjitSingh,MadeleineClareElish,andJacobMetcalf. Assem-
blingaccountability:algorithmicimpactassessmentforthepublicinterest,2021.
[64] Tzu-ShengKuo,HongShen,JisooGeum,NevJones,JasonI.Hong,HaiyiZhu,andKennethHolstein.
Understandingfrontlineworkers’andunhousedindividuals’perspectivesonaiusedinhomelessservices.
InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems,CHI’23,NewYork,
NY,USA,2023.AssociationforComputingMachinery.
[65] AliciaDeVrio,MotahhareEslami,andKennethHolstein. Building,shifting,&employingpower: A
taxonomyofresponsesfrombelowtoalgorithmicharm. InThe2024ACMConferenceonFairness,
Accountability,andTransparency,pages1093–1106,2024.
[66] Christian Sandvig, Kevin Hamilton, Karrie Karahalios, and Cedric Langbort. Auditing algorithms:
Researchmethodsfordetectingdiscriminationoninternetplatforms. Dataanddiscrimination:converting
criticalconcernsintoproductiveinquiry,22(2014):4349–4357,2014.
[67] AliceQianZhang,JudithAmores,MaryL.Gray,MaryCzerwinski,andJinaSuh. Aura: Amplifying
understanding,resilience,andawarenessforresponsibleaicontentwork,2024.
[68] KarenHaoandDeepaSeetharaman. Cleaningupchatgpttakesheavytollonhumanworkers,2023.
8A Imaginingpathsforward
WhatsourcesofinspirationcanresearchersorfacilitatorsofparticipatoryAIinitiativesturntoin
theirpursuitofmoreequitableengagementpractices?
In this section, we share several resources and directions for paths forward. We do not aim to
be comprehensive; rather, we highlight a few initiatives that propose alternatives to dominant
participationstructures. Welooselyorganizeourdiscussionundertwomotivatingquestions. First,
welookattheoriesfromadjacentfieldsthat,whilenotspecificallyaboutAI,providevaluableinsights
into participation and power. Second, we examine current efforts aimed at disrupting dominant
structuresandcreatingalternativemodesofengagementthatbenefitmarginalizedcommunities.
Are there theories from literature or other forms of community-based knowledge that can
informpathsforwardforAI?Participationcanbeextractive. Communitiescanlosecontrolover
howtheirdataisusedandsharedonceitiscollectedformodeltraining,failtobecreditedfortheir
contributionstomodeldevelopment,ornotbeproperlycompensatedfortheirknowledge. Belowwe
listsomeresourcesfromIndigenousdatastudies,datasetdevelopment,andcriticaldatastudiesthat
identifyhowresearcherscanrespectcommunities’preferencesarounddatasharing.
• Christen[48]identifieshowsomeIndigenouscommunitieshaveculturalnormsforsharing
certain types of data based on social relationships to the data artifact. AI researchers
developingdatasetsofculturalartifactswithIndigenouscommunitiescandoworktofirst
understandwhatculturalartifactstheyarecollectingthatmayhavespecificprotocolsfor
sharing. Researcherscantheninformcommunitiesaboutthelimitationsofrestrictingaccess
toimageswhendevelopinganddeployingGenAImodelssocommunitiescanexertmore
informedconsent.
• Vincent et al. [49] conceptualize the power that contributors hold over models as data
leverage. Contributorstodatasetscanexertpowerovermodeldevelopmentandperformance
byreducing,stopping,redirecting,ormanipulatingtheirdata. Dataleveragemakesexplicit
technologycompanies’dependenceonmarginalizedcommunitiestoimprovetheirmodels’
performance. Communitiesthereforehaveasignificantamountofleveragetosharethe
termsoftheirfutureinclusioninAIdevelopment. AIresearchersshouldconsiderexplaining
tocontributorstheleveragetheyholdoverthemodeldevelopmentprocessastheyaddress
faircompensationfordatasetcontributions. Doingsocouldprovidecontributorswitha
waytoconceptualizethevalueoftheirdataandallowthemtomorecriticallyassessthe
remunerationtheyarebeingofferedforparticipatingandthetermsoftheirparticipation.
Inaddition,AIresearcherscouldusedataleveragetocalculatemoreaccurateestimatesof
financialremunerationtocontributors: Howmuchwouldtheybewillingtopaytoavoid
contributorsusingtheirleveragetodisrupttheirmodel?
Arethereexamplecommunitycollaborationsthatofferalternativemodelsonhowtostructure
participationinAIdevelopment/evaluation? Pastscholarship[17,27]hasdemonstratedhowmany
“participatoryAI”engagementsarelimitedtoconsultationandinclusion(e.g.,collectingdatafrom
participantstoenrichmodels),withoutgrantingparticipantsmeaningfulopportunitiesforownership
andcontrolovertheresultingdatasetsandmodels. Whileparticipantsmaybeabletogiveinput
onhowtheythinkthemodelshouldbehave,ultimately,“participantshavelittlesayregardingthe
model’simpactintheworld: whetheritisdeveloped,whatotherdataitistrainedon,whatitmaybe
usedfor,orifandhowitshouldbedeployed”[27]. Weidentifysomeresourceswhereresearchers
andcommunitieshavebeendevelopingalternativemodelstostructuremoreequitablecommunity
engagement in AI development that ensures that participants have a meaningful say over model
developmentanddeployment.
1. Alternativemodelsofacknowledgmentforparticipation. Singhetal. [50]developprotocols
forrecognizingcommunitycontributiontoAIdevelopmentbyoperationalizingabroad
definition of authorship for academic papers. Similar initiatives have also been led or
adoptedbyothercommunity-drivenAIinitiatives[51,4,52]. Papersareavaluablecurrency
forvisibilityandrecognitionintheAI/MLdevelopmentspace. Byrecognizingcommunity
membersascontributorstoAI/MLdevelopmentinauthorship,researcherscanworktowards
moreequitablesharingofbenefits.
92. Alternative models of AI development. In contrast to enriching technology companies’
commercialfoundationmodelofferings,someinitiativesexplorehowtobestsupportcom-
munitiesindevelopingtheirownsmaller,morebespokemodels,whicharethenownedand
operatedbycommunitymembers. Pasteffortshavesurfacedhowcommunitiesoftenneedto
overcomeinfrastructuralbarrierssuchaslimitedavailabletrainingdata[53],capacity,and
accesstofinancialcapitalandcompute[54]tosupportcreating,hosting,andmaintaining
theirownmodels.
(a) One prominent example is the Te Hiku Media foundation, a Mãori nonprofit, that
decidedtodevelopitsowndatahostingplatformandtranscriptionmodelsforthete
reolanguage[55].
(b) ResearchersfromDAIR[56]havesimilarlyurgedtheresearchcommunitytosupport
localindigenousNLPorganizationslikeGhanaNLPandLesanAIwho“createmachine
translationsystemsforthespecificcommunitiestheybelongto”.
3. Alternativemodelsofdatasetownershipandusage.Manyparticipatoryengagementsinvolve
compensatingcommunitymembersinexchangeforcompleteownershipovertheirdata(to
useforfutureAIdevelopment). Incontrast,severalcommunitiesthatowntheirdatahave
experimentedwithalternativemodelstogovernwhocanusetheirdatasetsormodels,and
forwhatpurpose. Theseusagerestrictionsareoftenspecifiedinlicensesorothertypesof
contractualagreements[57,58].
(a) SomelicensesattempttoprotectparticipantsfromAI-mediatedharmsbyrestricting
howotherstakeholderscanuseresultingdatasetsandmodels. The“LicensingAfrican
Datasets”projectexploreshowtocreatelicensesforAfricandatasetsthatbetterre-
distributebenefitsbacktowardsAfricancitizensandcompanies,withtheexpectation
that“usersindevelopednationswouldperhapspayforuseoftheworkorusethework
undermorerestrictiveterms”[59]. Similarly,TeHikuMediacreatedadatalicensethat
“willonlygrantdataaccesstoorganizationsthatagreetorespectMãorivalues,stay
withintheboundsofconsent,andpassonanybenefitsderivedfromusebacktothe
Mãoripeople”[55].
(b) Futurelicensescanalsoexplorespecifyingalternativecompensationstructuresthat
allowcommunitiestoreceivecontinuedroyalties(beyondone-timecompensation)to
encourageprofit-sharingasmodelsthatdepicttheirlikenesscontinuetobeused[60].
4. Supportingcommunity-drivenimpactassessment,criticism,andrefusal. Manyparticipa-
toryengagementsmotivatecommunitymemberstoparticipatebylaudingthebenefitsof
improvedGenAIrepresentations. Weurgethoseconductingsuchengagementstoinvolve
community members in interrogating what barriers stand in the way of realizing these
benefits,andinunderstandingpotentialalgorithmicharmsthatmayresultfromimproved
representations.
(a) Facilitatorsofsuchengagementsshouldmakeroomforoutcomeswhereparticipants
decidetheharmsoutweighthebenefits[61,62]. Forexample,althoughqueerscholars
noticedthatstate-of-the-artAIvoicecloningtoolsunderperformedwhencloningthe
voicesofgayspeakers,theyultimatelydecidedagainstdevelopinganimprovedAI
technologyduetoconcernsthatanimprovedtechnologymaybemisusedtosurveil,
misappropriate,ormockgaypeople[37]. Makingroomforsuchcriticalengagements
will require educating participants who enter into engagements with varying levels
offamiliarityaboutAIcapabilitiesandharms. Webelievethatfacilitatorssimilarly
have much to learn from the situated expertise of community members – in fact,
manyscholarshavearguedthatimpactedcommunitiesthemselvesarebestequippedto
anticipateAIharms[63,64,65,66].
(b) Communitiesshouldnotjustberelegatedtored-teamingroleswheretheircultural
expertiseisusedtoidentifyAIharms,asthiscanbepsychologicallydamaging[67,68]
andfurtherreifyexistingpowerdistributionsbetweenAIdevelopersandcommunities2.
Rather,moreworkisneededtobuildtheinfrastructuresthatempowercommunitymem-
berstodefineandachievealgorithmicaccountabilityandrecourseontheirownterms.
2See the reports put out by the Wiezenbaum Institute’s Data Workers Inquiry for more: https://data-
workers.org/
10Forexample,researcherscaninvestigatehowtosupportthetranslationofcommunity-
identifiedAIharmsintoimplicationsforpolicydesigntoshapeAIregulationfollowing
communityneeds.
11