1
How Good is ChatGPT at Audiovisual Deepfake
Detection: A Comparative Study of ChatGPT, AI
Models and Human Perception
Sahibzada Adil Shahzad, Ammarah Hashmi, Yan-Tsung Peng, Yu Tsao, Senior Member, IEEE, Hsin-Min
Wang, Senior Member, IEEE
Abstract—Multimodal deepfakes involving audiovisual manip-
ulations are a growing threat because they are difficult to
detect with the naked eye or using unimodal deep learning-
FV
based forgery detection methods. Audiovisual forensic models,
whilemorecapablethanunimodalmodels,requirelargetraining FVRA
datasets and are computationally expensive for training and RVRA RA
inference. Furthermore, these models lack interpretability and
often do not generalize well to unseen manipulations. In this
study, we examine the detection capabilities of a large language Deepfake
model (LLM) (i.e., ChatGPT) to identify and account for any Techniques RV
possible visual and auditory artifacts and manipulations in au- RVFA
diovisualdeepfakecontent.Extensiveexperimentsareconducted
on videos from a benchmark multimodal deepfake dataset to Video FA
evaluate the detection performance of ChatGPT and compare Faceswap
it with the detection capabilities of state-of-the-art multimodal FSGAN
Wav2lip
forensic models and humans. Experimental results demonstrate Voice cloning
FV
the importance of domain knowledge and prompt engineering
forvideoforgerydetectiontasksusingLLMs.Unlikeapproaches FVFA
based on end-to-end learning, ChatGPT can account for spatial FA
and spatiotemporal artifacts and inconsistencies that may exist
within or across modalities. Additionally, we discuss the limita-
Fig. 1. Illustration of audiovisual deepfake manipulations. Original video
tions of ChatGPT for multimedia forensic tasks.
contentisrepresentedasRVRA(realvideowithrealaudio.Throughdeepfake
Index Terms—LLM, ChatGPT, Deepfake, Audiovisual deep- manipulationtechniques,threemanipulatedtypesaregenerated:FVRA(fake
videowithrealaudio),RVFA(realvideowithfakeaudio),andFVFA(fake
fake, Multi-modality, Video forensics, Forgery detection
videowithfakeaudio).Bluetextrepresentsthe“realmodality”ofthevideo
content,whileredtextrepresentsthe“fakemodality”.
I. INTRODUCTION
entertainment, and other fields [3], it is a double-edged sword
Synthetic multimedia content has become both innovative
that can be used for unethical purposes, such as pornography,
and a significant threat in recent years. Deepfake images
political defamation, identity theft, fraud, misinformation, and
and videos created using artificial intelligence (AI) and deep
disinformation [4]–[6]. Unethical use of this technology can
learning (DL) techniques have attracted public and academic
lead to political instability and social violence [6]. On the
attention. This synthetic content is generated by generative
one hand, deepfake technology continues to evolve to create
adversarial networks (GANs) [1] and more sophisticated AI
more convincing and realistic fake multimedia content. Social
techniques such as diffusion models [2]. While deepfake
media, on the other hand, plays a catalytic role in spreading
technology has many innovative applications in education,
such content. Therefore, timely detection of deepfake content
Sahibzada Adil Shahzad is with the Social Networks and Human- is crucial to avoid any damage and loss to human society [4].
Centered Computing Program, Taiwan International Graduate Program, Audiovisual deepfakes that involve multimodal manipula-
Academia Sinica, Taipei, Taiwan, and also with the Department of Com-
tion are a more convincing type of forgery, with attackers
puter Science, National Chengchi University, Taipei, Taiwan. (e-mail: adil-
shah275@iis.sinica.edu.tw). attacking audio, video, or both modalities. Unimodal video
Ammarah Hashmi is with the Social Networks and Human-Centered forgery detectors [7]–[10] and spoofed audio detectors [11]–
Computing Program, Taiwan International Graduate Program, Academia
[14] are generally unable to identify forgeries across multiple
Sinica, Taipei, Taiwan, and also with the Institute of Information Systems
and Applications, National Tsing Hua University, Hsinchu, Taiwan. (e-mail: modalities,althoughtheymaybegoodatdetectingforgeriesin
hashmiammarah0@gmail.com). thespecificmodalitytheyfocuson.Toaddressthischallenge,
Yan-Tsung Peng is with the Department of Computer Science, National
theresearchcommunityhasdevelopedsophisticatedtoolsand
ChengchiUniversity,Taipei,Taiwan.(e-mail:ytpeng@cs.nccu.edu.tw)
YuTsaoiswiththeResearchCenterforInformationTechnologyInnova- algorithms to detect audiovisual forgeries in videos. These
tion,AcademiaSinica,Taipei,Taiwan.(e-mail:yu.tsao@citi.sinica.edu.tw). specialized tools require knowledge of multimedia forensics
Hsin-Min Wang is with the Institute of Information Science, Academia
as well as knowledge of deep learning. Furthermore, these
Sinica,Taiwan.(e-mail:whm@iis.sinica.edu.tw)
tools do not generalize well to other unseen datasets and
4202
voN
41
]VC.sc[
1v66290.1142:viXra2
manipulations. that addresses the ethical and practical implications of the
Largelanguagemodels(LLMs)areamajoradvancementin creativityofgenerativeAIinthelegaldomain.Arecentstudy
the field of artificial intelligence. They are trained on a large in[18]investigatedtheriskofdeepfakesinlegalproceedings,
amount of data and can perform well in various natural lan- where altered audiovisual evidence could compromise the
guageprocessing(NLP)taskssuchastextgeneration,summa- integrityofjustice.Ithighlightshowdeepfaketechnologycan
rization, classification, completion, sentimental analysis, ma- influence the outcome of cases based on subjective human
chine translation, and question answering. Their applications judgment. The findings point to the need for changes to the
evengobeyondtheaforementionedNLPtasksandcanbeused legal framework to ensure that key judicial principles such
as writing assistants, learning tools, productivity tools, coding as the presumption of innocence and the right to a fair trial
assistants, software development, healthcare, legal assistance, are protected. Furthermore, research on human perception of
entertainment,andmore.Despitebeingprimarilydesignedfor audiovisual deepfake videos [19] shows that it is difficult
NLPtasks,OpenAI’sChatGPTcananalyzeimage,audio,and for people to accurately distinguish deepfake content from
video content. Taking advantage of its support for multimodal real videos, mainly due to the realistic visual and acoustic
input,westudiedthepotentialandlimitationsofChatGPTfor manipulations involved.
audiovisual deepfake detection. Audiovisualdeepfakescanbebroadlycategorizedintothree
The research questions we aimed to address in this study types, as shown in Fig. 1. The first type is “Fake Video Real
are as follows: Audio” (FVRA), in which the visual frames are manipulated
• Can ChatGPT perform multimedia forensic tasks? using techniques such as Faceswap [20], Fsgan [21], and
• Is ChatGPT capable of detecting forgery based on arti- Wav2lip [22], while the audio modality remains unaltered.
facts in audio and visual modalities? The second type is “Real Video Fake Audio” (RVFA), where
• WhatistheroleofpromptengineeringinusingChatGPT the video frames are authentic, but the audio modality is
to detect audiovisual deepfakes? manipulated using techniques such as SV2TTS [23], a real-
• Which performs better at identifying forgeries in audio- time voice cloning tool that can synthesize fabricated audio
visual deepfakes, ChatGPT, humans, or AI models? content. The third type is “Fake Video Fake Audio” (FVFA),
• How interpretable is ChatGPT for forgery detection? where both modalities are manipulated. In this type, face
• What are the limitations of ChatGPT in detecting multi- manipulation can be done using methods like Faceswap and
modal deepfakes? Fsgan,whilelipsynchronization/manipulationcanbeachieved
using Wav2lip. Additionally, cloned or synthesized audio can
The main contributions of our work are threefold:
be integrated with visually manipulated frames to produce
• We explore for the first time the potential of ChatGPT
more realistic and convincing deepfake videos.
for audiovisual forgery detection tasks.
Themultimediaforensicscommunityhasdevelopedseveral
• We compare the performance of ChatGPT with human
data-driven audiovisual deepfake detection methods based on
and state-of-the-art AI models on audiovisual forgery
multimodal feature fusion [24], ensemble learning [25], [26],
detection tasks.
and synchronization features [27], [28]. Models based on
• We highlight the strengths and limitations of ChatGPT
ConvolutionalNeuralNetworks(CNN),RecurrentNeuralNet-
on audiovisual forgery detection tasks.
works (RNN), and Transformers [28]–[31] have been widely
used to detect forgeries in either modality and are trained
II. RELATEDWORK
on multimodal deepfake datasets. These methods provide a
Thesocietalimpactofsyntheticmediacontenthasprompted binaryoutputfortheinputvideo,indicatingwhethertheinput
researchfrommultipleangleswithintheforensicsciencecom- video is genuine or spoofed. Disadvantages of these end-to-
munity.In[15],theauthorsinvestigatedsyntheticcontentfrom endlearning-basedmethodsincluderelianceonlargedatasets,
multiple perspectives such as multimedia content production, heavy training, and lack of interpretability and generalization.
representation,mediaaudiencedynamics,gender,politics,law, Bias,imbalance,andlackofdiversityintrainingdatacanlead
and regulation, and concluded that the intersection between to fairness, generalization, and security issues for detection
media and deepfake content can have multiple impacts on models [32].
individuals and society. A study in [16] on the impact of Recently, with the emergence of LLMs, the research com-
unreliabledeepfakeinformationonvoterbehaviorinUSelec- munity has begun to utilize these models to solve various
tions and democracy suggests multi-stakeholder partnerships tasks in different fields, beyond their original purpose. For
and technological approaches for identifying and mitigating example,whileChatGPTisprimarilydesignedforNLPtasks,
manipulated content on public platforms. In [17], the balance the multimodal mode in ChatGPT-4 enables it to handle
betweeninnovationandensuringfairprotectionunderexisting multimodal inputs and analyze content from a multimodal
laws is explored, particularly as generative AI blurs the line perspective [33]–[35]. Many studies have investigated the
betweenhumanandmachine-generatedworks.TheUSFDA’s performance of LLMs in various challenging tasks, such as
regulation of AI in medical devices and the European AI Act, image forensics [36], facial biometrics [37], tampered image
which classify AI applications based on potential harm, are detection[38],fakenewsdetection[39],NLP[40],cheap-fake
initiatives aimed at addressing challenges and aligning AI- detection [41], global warming [42], education [43], public
generated content and applications with human-centered val- health [44], and medical applications [45]. These studies
ues.Thisanalysisisessentialfordevelopingalegalframework highlight the strengths and limitations of LLMs, focusing3
specifically on ChatGPT’s effectiveness in handling these
tasks. Unlike traditional machine learning-based multimedia
forensic tools, LLMs are readily accessible and can be used Text Prompt
for multimedia forgery detection tasks. In this study, we aim Tell me if this is an AI-generated
toleveragetheimplicitknowledgeembeddedinChatGPTand video by analyzing both audio and
the generalization ability of multimodal inputs to accomplish Input Audio video modalities. Answer yes or no'
the audiovisual deepfake detection task. Video Speech
Prompt
III. METHODOLOGY
Fig. 2 shows an LLM-based approach for multimodal
A
forgery detection, where the text prompts and video with
corresponding audio are used as inputs. Based on the given
prompts, the model works as a black box and produces
multiple analysis results on the input video, such as visual, Multimodal LLM
acoustic, and audiovisual analysis and their corresponding
V P
predictions. Our goal is to evaluate the detection capabilities ChatGPT
of ChatGPT. This model is trained on multimodal data and
can be used for audiovisual forgery detection tasks. Deepfake
attacks usually target high-level facial features and voice
identities;therefore,wechoosefrontalfacevideoswithvoices
to evaluate the detection performance of ChatGPT. Unlike
traditional end-to-end models that leverage low-level features,
LLMs provide high-level features and descriptions to analyze
multimodal inputs. In this study, we used OpenAI’s GPT-4
Analysis Explainability Prediction
to conduct audiovisual analysis of deepfake videos. Unlike
other deep learning-based models, it provides interpretability
by explaining the reasoning behind the final decision, thereby Fig. 2. Illustration of the multimodal capabilities of a large language
model, which takes inputs such as visual frames, audio speech, and text
increasing the transparency of the decision-making process.
prompts to produce outputs that include audiovisual analysis, interpretation,
andauthenticityprediction.
A. Prompt Design
Inspired by previous research on LLM-based image foren-
4-irregular lip movement; 5-inconsistent skin texture; 6-
sics[36],weproposedthefollowingcustomprompts,ranging
spectral artifacts; 7-phoneme artifacts; 8-inconsistencies
fromsimple,binary-answerpromptstoadvanced,context-rich
in speech patterns; 9-voice quality issues; 10-lack of
prompts designed to account for artifacts and manipulations
synchronization between audio and video].
in audiovisual content:
• P1: Tell me if this is an AI-generated video by analyzing
B. Input of LLM Model
both audio and video modalities. Answer yes or no.
• P2:Tellmeifthisisarealvideobyanalyzingbothaudio We feed the videos directly into the LLM-based ChatGPT
and video modalities. Answer yes or no. model without performing any preprocessing or transcribing
• P3: Tell me the probability of this video being real by the videos for analysis. The model extracts audio from the
analyzing both audio and video modalities. Answer a videoandperformsvisualandacousticanalysisbasedoninput
probability score between 0 and 100.
prompts.LetX=(x v,x a,x t)denotetheentireinput,wherex
v
• P4: Tell me the probability of this video being AI- representsthevideo,x a representstheaudio,andx t represents
generated by analyzing both audio and video modalities. thecustomtextprompt.Themodeloutputsitsfinalprediction
Answer a probability score between 0 and 100. as:
• P5: Tell me if this is a real or AI-generated video by yˆ=f LLM(X)=f LLM(x v,x a,x t), (1)
analyzing both audio and video modalities.
where f is the underlying function.
LLM
• P6: Tell me if synthesis artifacts are in the visual frames
or audio. Must return with 1) yes or no only; 2) if yes,
C. Audiovisual Analysis
explain where the artifacts exist by answering in [region,
artifacts] form. Based on the given input text prompts, the model per-
• P7: I want you to work as a multimedia forensic expert forms audio analysis by analyzing spectral features, zero
for audiovisual deepfake detection. Check if the video crossing rate, mel-frequency cepstral coefficients (MFCC),
has the artifact attribute listed in the following list, and amplitudeenvelope,amplituderange,medianamplitude,spec-
ONLY return the attribute number in this video. The tral centroid, spectral rolloff, and silence ratio. For video,
artifact list is [1-unnatural face edges; 2-inconsistent the model performs analysis such as blurriness, pixelation,
lighting and shading; 3-irregular teeth shape or texture; lighting, frame difference mean, frame difference standard4
deviation, unnatural expression, skin texture, lip-syncing, and TABLEI
structuralsimilarityindex(SSIM).Italsoperformsmultimodal PRECISION,RECALL,F1SCORE,REJECTIONRATE,ANDACCURACYFOR
DIFFERENTTEXTPROMPTS(P1-P7).
analysistoverifyconsistencybetweenvisualandaudiomodal-
ities through synchronization checks. By combining unimodal Prompt Precision Recall F1Score RejectionRate Accuracy
acoustic and visual analyses with multimodal analysis, joint P1 0.583 0.368 0.451 7.50 54.0
P2 0.625 0.250 0.357 2.50 53.8
analysis is performed to reach a final prediction or suggest
P3 0.625 0.250 0.357 0.00 55.0
further manual inspection.
P4 0.571 0.600 0.585 0.00 57.5
P5 0.571 0.200 0.300 0.00 52.5
P6 0.607 0.850 0.706 0.00 65.0
D. Prediction Assignment
P7 0.600 0.900 0.720 0.00 65.0
The final prediction yˆ for each input video is determined
based on the following factors: yes/no response, probability
Confusion Matrix Values - Bar Graph
score, overall conclusion, artifact-free versus artifact list, and Metrics
17.5 TP
estimated likelihood of the input video being real or fake. FP
TN
Fakeclassesareassignedlabel1,whilelabel0representsreal 15.0 FN
classes.
12.5
10.0
E. ChatGPT vs Human vs AI Models
7.5
To understand the detection capabilities of ChatGPT, hu-
mans, and AI models, we follow the study in [19], where the 5.0
authors reported a comparative analysis between humans and
2.5
deep-learning-basedmultimodalforensicmodels.Theirresults
concluded that state-of-the-art AI models surpass humans 0.0 P1 P2 P3 P4 P5 P6 P7
Prompts
in detecting multimodal deepfakes. Furthermore, participants
often showed overconfidence in their detections, with their Fig.3. BargraphcomparingthenumberofTruePositives,FalsePositives,
average accuracy being lower than their confidence level. To TrueNegatives,andFalseNegativesfordifferenttextprompts.
evaluate the detection performance of ChatGPT, we selected
the same video subset used in [19] from the FakeAVCeleb
correctly detected as real), False Positive (real videos in-
dataset [46] for a fair comparison.
correctly detected as fake), and False Negative (fake videos
incorrectly detected as real), respectively. Additionally, we
IV. EXPERIMENTSANDRESULTS calculatetherejectionratetoevaluatetheeffectivenessofinput
A. Dataset Selection text prompts:
Following the study in [19], we selected the same 40 Number of Rejected Prompts
Rejection Rate= ×100. (6)
videos from the FakeAVCeleb dataset [46] to allow for a Total Number of Prompts
fair comparison with humans and state-of-the-art multimodal
forensic models. The 40 videos contain 20 real videos and
C. Results
20 fake videos, representing each class equally. To eliminate
1) Comparing Different Text Prompts: Table I lists the
gender bias, each class contains an equal number of male and
performanceofdifferenttextprompts(P1-P7inSectionIII-A).
female videos.
Fig. 3 shows a bar graph comparison of TP, TN, FP,
and FN (see Section IV-B) for different text prompts. Ad-
B. Evaluation Metrics
ditionally, Fig. 4 shows an example of custom text prompts,
For evaluation, we calculate precision, recall, F1-score, and ChatGPTaudiovisualanalysis,correspondingpredication,and
accuracy, which are defined as, groundtruthlabel.Next,weanalyzeeachtextpromptindetail
and discuss the results.
TP
Precision= TP +FP, (2) • Prompt P1: As can be seen from Table I, the accuracy
of P1 reaches 54.0%, which is only slightly higher than
TP the 50% of random guessing, indicating that it is less
Recall= , (3)
TP +FN effective in guiding the model to make accurate predic-
tions. Its simplicity and lack of necessary information
2×Precision×Recall resulted in a rejection rate as high as 7.50%, preventing
F1= , (4)
Precision+Recall themodelfrommakingpredictionsforeveryvideoinput.
The numbers of TP, FP, TN, and FN are 7, 5, 13,
TP +TN
Accuracy= . (5) and12respectively.Inthedeepfakevideodetectiontask,
TP +TN +FP +FN a higher TP value is desirable. However, instead of
where TP, TN, FP, and FN stand for True Positive (fake obtaining higher TP, P1 produced more TN, resulting
videos correctly detected as fake), True Negative (real videos in a lower recall of 0.368.
selpmaS
fo
.oN5
Audio-Visual Chatgpt Ground Truth Audio-Visual Chatgpt Ground Truth
Video Input Video Input
Analysis Predicton lable Analysis Predicton lable
Based on the visual and audio analyses
A s o ui b nu le v nd n i ai oo c tu ue sA r a n lr s a a sigl t py i nos es i es c: a o hpT f pph A aee I ta ta er g u re nd n n si oo e or rm raw t aaa io rlv t, n i e f afo w s cr u tim st ch h a nn aod s p T A T ae nh hI-r ae egf lo e yvr n sim ad ie suee r daod dit : o oef r da n m a w ore tat is v sfa e hd c f oo ot ws rn . m o s t i ge a nx n sh di ob fit s sc p yo e nm c thtm r euo tm in c
Video Analysis: The frames extracted do generation. Real Real
not show obvious visual artifacts, and the Real Fake While these analyses suggest that the
P t v a m oh i u rr d oi so d ne d m i oo o ais lp ib tt a iy e n sa1 .an: A n a AI d-T l nyg e szel wil n n ee gm v rr a b ie d yt o e e etd h oi sf o mp ot tic ioa nl bf elo tww e ena n fra aly ms eis s .indicates natural P t g a ah e n nr iso n a d m e l y vi rs z ip a d intt eea g o5 d : mr b e oT v oae i t ddl h ll ae o laom ir tu iee dA b s iI oyi -f v i s s f sm ui o o pd rp p m ete ho h co e e ir i a s tt ria t lma iin zcn ce et a od s dte n d fpa ir t au mo A sd ts aIi o-o tg oi t oe h ln snm n eo e si tg e er isah tt b ae a n ndb s et d e h i e c c a do tr ecn e h dta e fe , ol n, ch r t ek m ii g s nt c oh . sa rli in I eys cf
techniques should be employed.
Conclusion: Based on the provided data,
there are signs that could suggest the
video might be manipulated, but a
d foe rf ein ni sti iv ce a en xs aw mer in r ae tq iou nir .e s Fa om r ore n oth wo , rou tg hh e Fake Fake 1. Yes
evidence leans towards possible Visual: [All frames, High edge
P isr om a pt r2 e: a T l ell v m idee o i f th bi ys m (tha en i vp idu ela oti o mn i, g hs to n oth t e b ea rn es aw l)er is likely no Prompt 6: Tell me if den As uit dy] io: [entire audio, Clipping Fake Real
analyzing both audio synthesis artifacts are in detected], [entire audio, Silence
and video modalities. the visual frames or detected]
Answer yes or no audio. Must return with 1)
yes or no only; 2) if yes,
explain where the artifacts
exist by answering in
[region, artifacts] form
Based on the analysis of both audio
and video modalities, the probability of Fake Fake
the video being real is approximately
Prompt 3: Tell me the 43.79%
probability of this video
being real by analyzing
both audio and video The video exhibits the artifact
m pro od ba al bit ii le its y. Answe sr c orea P wr oo rkm pt a s7 : I a wa mn ut lty imou e dt io a c 2o rr -e sp ino cn od nin sg is tt eo n a t ttri lb igu ht te in n gu m ab ne dr Fake Fake
between 0 and 100 forensic expert for audio- shading
visual deepfake detection.
Check if the video has the
artifact attribute listed in the
Given the initial analysis, both the audio following list and ONLY
and video components do not show return the attribute number
strong indications of being AI- in this video. The artifact
generated. However, more detailed list is [1- unnatural face
spectral and temporal analysis of the edges; 2- inconsistent
audio, as well as frame-by-frame lighting and shading; 3-
analysis of the video, would be Real Real irregular teeth shape or
P prr oo bm ap bit l it4 y : oT f e tl hl ism e v idt eh oe n coe nce cls us sa iory n . for a more definitive t me oxt vu er me; e nt; 4-i 5rr -e ing cu ola nr s istel nip t
b ae ni an lg yz inA gI- ge bn oe thra te ad u db ioy Based on the current data: s Ak ri tn ifa ct te sx ; ture 7; - 6- PS hop ne ect mra el
and video modalities. Probability Score: 20/100 Artifacts; 8- Inconsistencies
Answer a probability in Speech Patterns; 9-
score between 0 and Voice Quality Issues; 10-
100 lack of synchronization
between audio and video]
Fig. 4. Demonstration of ChatGPT responses, which takes video and text prompts as input and produces audiovisual analysis, including explanations and
authenticitypredictions.
• PromptP2:SimilartoP1,P2generatesabinaryresponse in better performance and increased accuracy to 57.5%.
as to whether the video is real or not. Its lack of The numbers of TP, FP, TN, and FN are 12, 9, 11,
contextualinformationresultedinanevenloweraccuracy and 8, respectively. The precision rate is 0.571, which is
of 53.8%, but it was better than P1 in terms of rejection slightlylowerduetothehighernumberofFP compared
rate, which was 2.50%. The numbers of TP, FP, TN, to the previous three prompts. However, due to the lower
andFN are5,3,16,and15,respectively.IntermsofTP, number of FN, P4 achieves a better recall rate of 0.600.
P2 performed worse than P1. Due to the lower number • Prompt P5: Like P1, P2, and P3, P5 appeared to be less
of FP, its precision was slightly better than P1 at 0.625, effective due to its lack of specificity and manipulation
whileP2hadahighernumberofFN,resultinginalower details. P5 achieved an accuracy of 52.5%. The numbers
recall than P1 at 0.250. of TP, FP, TN, and FN are 4, 3, 17, and 16, respec-
• Prompt P3: Unlike the binary response output in P1 and tively. P5 has the same precision as P4, but its recall is
P2,P3requiresthemodeltoreturnaprobabilisticoutput, poor at 0.200. The main reason for the extremely low
whichresultsinanaccuracyof55.0%andarejectionrate recall rate is the small number of TP, only 4 out of 20
of 0%, slightly better performance than P1 and P2. The fake samples were correctly detected as fakes.
numbers of TP, FP, TN, and FN are 5, 3, 17, and 15, • Prompt P6: With an accuracy of 65.0%, higher precision
respectively. Compared to P2, TN increases by 1. The and recall, and a rejection rate of 0%, P6 is by far the
precision and recall rates are 0.625 and 0.250, the same best performing prompt. Unlike the previous prompts,
as P2. P6 focuses on visual and acoustic artifacts present in
• Prompt P4: P4 has improved accuracy compared to the visual and audio modalities, allowing the underlying
previous three prompts. This prompt contains the term multimodal model to make the final prediction/decision
“AI-generated”andrequiresaprobabilityscore,resulting moreeffectively.ThenumbersofTP,FP,TN,andFN6
TABLEII
are17,11,9,and3,respectively.P6hasahighernumber COMPARISONOFDETECTIONACCURACYBETWEENHUMANS,AI
of TP and TN than the previous prompts.
MODELS,ANDCHATGPT.
• Prompt P7: Compared to P6, the contextual details in Category Method Accuracy(%) Rejection
P7 text prompt narrow the focus of the LLM model to Rate(%)
Human(PhaseI)[19] 63.30 -
specific artifacts and manipulations in both modalities,
Human Human(PhaseII)[19] 67.98 -
yielding more accurate and reliable results. P7 achieved Human(Overall)[19] 65.64 -
an accuracy of 65.0%, a rejection rate of 0%, and the LipForensics[10] 92.50 -
highest recall among all text prompts due to the larger AV-Lip-Sync[27] 87.50 -
AIModels AV-Lip-Sync+[28] 97.50 -
number of TP. The numbers of TP, FP, TN, and FN
CNN-Ensemble[26] 97.50 -
are 18, 12, 8, and 2, respectively. AVTENet[30] 97.50 -
P1 54.05 7.50
In summary, prompts based on simple binary responses of-
P2 53.85 2.50
tenlackthenecessaryclarityanddetailstoeffectivelyleverage P3 55.00 0.00
the multimodal knowledge of the LLM. Therefore, prompts ChatGPT P4 57.50 0.00
P5 52.50 0.00
like P1 to P5 resulted in lower accuracy. In contrast, more
P6 65.00 0.00
context-rich, artifact-based, and detailed-oriented prompts, P7 65.00 0.00
suchasP6andP7,outperformedothersimplerprompts.These
more effective prompts leverage the multimodal capabilities • Tell me the probability of this video being AI-generated.
and underlying knowledge of the LLM, yielding detection Answer a probability score between 0 and 100.
results aware of specific artifacts and manipulations in both • Tell me if this is a real or AI-generated video.
modalities. • Tell me if synthesis artifacts are in the face. Must return
2) Comparing ChatGPT with Human and AI models: The with 1) yes or no only; 2) if yes, explain where the
detection performance of human evaluators and various state- artifacts exist by answering in [region, artifacts] form.
of-the-art deep learning-based models was compared in [19], • I want you to work as a video forensic expert for AI-
as summarized in Table II. In the human subjective test, each generated faces. Check if the video has the artifact at-
subject evaluated the same set of videos twice, in a different tributeinthefollowinglistandONLYreturntheattribute
playback order. Phase 1 in the table represents the average number in this image. The artifact list is [1-asymmetric
accuracyofalltestersinthefirstround,andPhase2represents eye iris; 2-irregular reflection; 3-irregular teeth shape or
the average accuracy of the second round. The results showed texture;4-irregularearsorearrings;5-strangehairtexture;
that humans performed better in the second round, but the 6-inconsistent skin texture; 7-inconsistent lighting and
difference between the two rounds was not significant. The shading; 8-strange background; 9-unnatural edges; 10-
average accuracy of human evaluators was 65.64%, which lack of synchronization between audio and video].
serves as the baseline for comparison in our study. Among AI
As can be seen from Table III, the rejection rate is higher
models,Lipforensics[10]focusesonsemanticinconsistencies
and the accuracy is lower, compared with the results in Table
in the mouth region and shows strong performance with an
I. Based on these results, we made several observations. First,
accuracy of 92.50%. The AV-Lip-Sync model [27] exploits
only mentioning the video in the prompt causes the model
synchronization between audiovisual modalities and achieves
to focus mainly on visual frames without analyzing the audio
an accuracy of 87.50%, which is slightly lower than the
modality. To obtain the desirable output from an LLM-based
accuracy of Lipforensics. The remaining three models AV-
model, prompts need to be specific and context-rich. Second,
Lip-Sync+ [28], CNN-Ensemble [26], and AVTENet [30] all
when prompts are fed sequentially, the model takes into ac-
achievedahigheraccuracyof97.50%.Thecomparisonresults
count the context of the results of previous prompts, affecting
in Table II show that ChatGP performs on par with humans
its response to the current prompt. To obtain independent and
when provided with appropriate prompts, but both perform
unbiased results from prompts, we must feed the input video
much worse than today’s AI detection models. The higher
and prompt independently within a session to eliminate the
accuracy of these deepfake detection models is attributed to
effects of contextual bias from previous prompts. Third, our
their training on the multimodal FakeAVCeleb dataset.
experimentsshowthatpromptsmustcontaintermsrelevantto
acoustic analysis in order for the model to effectively analyze
V. ABLATIONSTUDY
the audiovisual content in a given video.
A. Effectiveness of Prompts
TABLEIII
Initially, we tested some basic prompts by mentioning only PRECISION,RECALL,F1SCORE,REJECTIONRATE,ANDACCURACYFOR
“video” and no mention of “audio”, and executed custom DIFFERENTVIDEO-ONLYMENTIONPROMPTS(P1-P7).
prompts sequentially within one session. The following are
Prompt Precision Recall F1Score RejectionRate Accuracy
the custom text prompts: P1 0.545 0.500 0.522 52.5 42.11
P2 0.467 0.500 0.483 40.0 37.50
• Tell me if this is an AI-generated video. Answer yes or
P3 0.542 0.813 0.650 27.5 51.72
no.
P4 0.480 0.750 0.585 17.5 48.48
• Tell me if this is a real video. Answer yes or no. P5 0.545 0.800 0.649 22.5 56.66
• Tell me the probability of this video being real. Answer P6 0.600 0.474 0.529 2.50 57.89
P7 0.333 0.167 0.222 10.0 41.67
a probability score between 0 and 100.7
B. Failure Case Study with that of end-to-end multimedia forensic methods and hu-
man capabilities. Our results showed that, although ChatGPT
The reasons for detection failure vary depending on both
was not explicitly designed for multimedia forgery detection
the input prompt and video content. Through our experiments
tasks,itsperformancewascomparabletohumandetectionper-
and careful analysis, we observed several factors that lead to
formance, demonstrating its potential in this field. A notable
inaccurate decisions in the multimodal ChatGPT model.
advantage of using LLMs in video forensics is their ability
One factor is a high silence ratio in the speech content,
to generalize effectively because these models are learned
which may indicate robotic/synthetic audio since the speech
from a wide range of datasets, unlike end-to-end models that
generation pipeline excludes environmental noise. However,
are typically learned from specific video deepfake datasets.
videos with clean/enhanced speech do not always indicate
Additionally,LLMsprovidesuperiorinterpretabilitycompared
synthesisorvoicespoofing.Conversely,addingsyntheticenvi-
todeeplearning-basedforensicmethods,which,whilecapable
ronmentalnoisetocleanaudiocanmisleadthemodel,leading
of identifying specific visual and acoustic artifacts, typically
toinaccuratepredictions.Thehighsilenceratecombinedwith
serve as black-box models with limited interpretability. In
unnatural pauses in the acoustic modality can lead to an
futurework,weaimtocombineLLM-basedmodelswithdeep
increased number of false positives in the model.
learning-basedforensicmodelstoenhanceinterpretabilityand
While unimodal/multimodal deep features and audiovisual
further contribute more interpretable and transparent deepfake
correlation features are effective in various multimodal tasks,
detection tools to the forensics community.
ChatGPT mainly relies on hand-crafted features and tradi-
tional functions in computer vision and speech processing
REFERENCES
libraries, including OpenCV, librosa, numpy, wav, and skim-
[1] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,
age, for visual and acoustic analysis. Furthermore, existing
S. Ozair, A. Courville, Y. Bengio, Generative adversarial networks,
deep learning-based pretrained foundation models [47]–[50] CommunicationsoftheACM63(11)(2020)139–144.
and frameworks (such as Tensorflow or Pytorch) are not used [2] J.Ho,A.Jain,P.Abbeel,Denoisingdiffusionprobabilisticmodels,in:
ProceedingsoftheAdvancesinNeuralInformationProcessingSystems,
to analyze video content for possible artifacts and forgeries.
Vol.33,2020,pp.6840–6851.
These two shortcomings limit the ChatGPT method from [3] A.O.Kwok,S.G.Koh,Deepfake:asocialconstructionoftechnology
effectively analyzing video content and result in poor perfor- perspective,CurrentIssuesinTourism24(13)(2021)1798–1802.
[4] A. Ray, Disinformation, deepfakes and democracies: The need for
mance compared to state-of-the-art forensic models.
legislative reform, The University of New South Wales Law Journal
Inthecontextofaudiovisualvideoforgerydetection,ifany 44(3)(2021)983–1013.
modality (audio or video) is fake, the final prediction should [5] A´.Figueira,L.Oliveira,Thecurrentstateoffakenews:challengesand
opportunities,ProcediaComputerScience121(2017)817–825.
be classified as fake. However, we observed that the overall
[6] C.Vaccari,A.Chadwick,Deepfakesanddisinformation:Exploringthe
probability score, calculated as the average of the audio and impact of synthetic political video on deception, uncertainty, and trust
videoscores,canleadthemodeltomakeincorrectpredictions. innews,SocialMedia+Society6(1)(2020).
[7] D. Afchar, V. Nozick, J. Yamagishi, I. Echizen, MesoNet: a compact
If the score of one of the modalities dominates, the final
facial video forgery detection network, in: Proceedings of the IEEE
prediction tends to reflect that modality, compromising the International Workshop on Information Forensics and Security, 2018,
overall accuracy and classification results. pp.1–7.
[8] H. H. Nguyen, J. Yamagishi, I. Echizen, Capsule-Forensics: Using
capsule networks to detect forged images and videos, in: Proceedings
VI. LIMITATIONS oftheIEEEInternationalConferenceonAcoustics,SpeechandSignal
Processing,2019,pp.2307–2311.
Although LLM-based models are superior to end-end
[9] K.Lutz,R.Bassett,DeepfakeDetectionwithInconsistentHeadPoses:
learning-based black box models in terms of generalization, Reproducibilityandanalysis,arXivpreprintarXiv:2108.12715(2021).
interpretability, and intuitive user interface for end users, [10] A. Haliassos, K. Vougioukas, S. Petridis, M. Pantic, Lips Don’t Lie:
A generalisable and robust approach to face forgery detection, in:
they still have limitations. LLM-based models require domain
Proceedings of the IEEE/CVF Conference on Computer Vision and
knowledge for multimedia forensics tasks to design more PatternRecognition,2021,pp.5039–5049.
effectivepromptstoexploittheirunderlyingmultimodalcapa- [11] L.Wang,Y.Yoshida,Y.Kawakami,S.Nakagawa,Relativephaseinfor-
mationfordetectinghumanspeechandspoofedspeech.,in:Proceedings
bilities. Simple binary prompts are ineffective and yield lower
oftheInterspeechConference,2015,pp.2092–2096.
accuracy and higher rejection rates. Furthermore, ChatGPT [12] M.Todisco,H.Delgado,N.Evans,Anewfeatureforautomaticspeaker
uses traditional techniques to analyze forgery in audiovisual verificationanti-spoofing:ConstantQcepstralcoefficients,in:Proceed-
ings of the Speaker and Language Recognition Workshop (Odyssey),
content and has no access to pretrained models specifically
Vol.45,2016,p.283.
trained for multimodal forgery detection tasks, resulting in [13] T. B. Patel, H. A. Patil, Combining evidences from mel cepstral,
lower accuracy even when the text prompts are effective cochlearfiltercepstralandinstantaneousfrequencyfeaturesfordetection
of natural vs. spoofed speech., in: Proceedings of the Interspeech
and contextually rich. Given these limitations, the multimedia
Conference,2015,pp.2062–2066.
forensics community must focus on cutting-edge, end-to-end [14] H. Wu, H.-C. Kuo, N. Zheng, K.-H. Hung, H.-Y. Lee, Y. Tsao, H.-
learning-based techniques to develop more robust, generaliz- M. Wang, H. Meng, Partially fake audio detection by self-attention-
based fake span discovery, in: Proceedings of the IEEE International
able, and explainable audiovisual deepfake detectors.
Conference on Acoustics, Speech and Signal Processing, 2022, pp.
9236–9240.
[15] S. Karnouskos, Artificial intelligence in digital media: The era of
VII. CONCLUSIONS
deepfakes,IEEETransactionsonTechnologyandSociety1(3)(2020)
In this study, we investigated the detection capabilities of 138–147.
[16] G.P.Zachary,Digitalmanipulationandthefutureofelectoraldemocracy
a large language model (LLM) (i.e., ChatGPT) in the multi-
intheUS,IEEETransactionsonTechnologyandSociety1(2)(2020)
modal forgery detection task. We compared its performance 104–112.8
[17] J. R. Carvalko, Generative AI, ingenuity, and law, IEEE Transactions [38] X. Yang, J. Zhou, Research about the ability of LLM in the tamper-
onTechnologyandSociety5(2)(2024)169–182. detectionarea,arXivpreprintarXiv:2401.13504(2024).
[18] Y. Apolo, K. Michael, Beyond a reasonable doubt? audiovisual evi- [39] K. M. Caramancion, Harnessing the power of ChatGPT to decimate
dence,AImanipulation,deepfakes,andthelaw,IEEETransactionson mis/disinformation: Using ChatGPT for fake news detection, in: Pro-
TechnologyandSociety5(2)(2024)156–168. ceedingsoftheIEEEWorldAIIoTCongress,2023,pp.0042–0046.
[19] A.Hashmi,S.A.Shahzad,C.-W.Lin,Y.Tsao,H.-M.Wang,Unmasking [40] J.Kocon´,I.Cichecki,O.Kaszyca,M.Kochanek,D.Szydło,J.Baran,
Illusions: Understanding human perception of audiovisual deepfakes, J.Bielaniewicz,M.Gruza,A.Janz,K.Kanclerz,etal.,ChatGPT:Jack
arXivpreprintarXiv:2405.04097(2024). ofalltrades,masterofnone,InformationFusion99(2023)101861.
[20] I. Korshunova, W. Shi, J. Dambre, L. Theis, Fast face-swap using [41] G.Wu,W.Wu,X.Liu,K.Xu,T.Wan,W.Wang,Cheap-fakedetection
convolutionalneuralnetworks,in:ProceedingsoftheIEEEInternational with LLM using prompt engineering, in: Proceedings of the IEEE
ConferenceonComputerVision,2017,pp.3677–3685. International Conference on Multimedia and Expo Workshops, 2023,
[21] Y. Nirkin, Y. Keller, T. Hassner, FSGAN: Subject agnostic face swap- pp.105–109.
ping and reenactment, in: Proceedings of the IEEE/CVF International [42] S.S.Biswas,PotentialuseofChatGPTinglobalwarming,Annalsof
ConferenceonComputerVision,2019,pp.7184–7193. BiomedicalEngineering51(6)(2023)1126–1127.
[22] K. Prajwal, R. Mukhopadhyay, V. P. Namboodiri, C. Jawahar, A lip [43] J. He, L. Li, W. Yao, H. Gao, Exploring Future Education: The
syncexpertisallyouneedforspeechtolipgenerationinthewild,in: innovativeintegrationandpracticeofmultimodallearningandChatGPT,
ProceedingsoftheACMInternationalConferenceonMultimedia,2020, in: Proceedings of the International Conference on Computer Science,
pp.484–492. Engineering,andEducation,2024,pp.18–23.
[23] Y. Jia, Y. Zhang, R. Weiss, Q. Wang, J. Shen, F. Ren, P. Nguyen, [44] S.S.Biswas,RoleofChatGPTinpublichealth,AnnalsofBiomedical
R.Pang,I.LopezMoreno,Y.Wu,etal.,Transferlearningfromspeaker Engineering51(5)(2023)868–869.
verificationtomultispeakertext-to-speechsynthesis,in:Proceedingsof [45] Z.Yan,K.Zhang,R.Zhou,L.He,X.Li,L.Sun,MultimodalChatGPT
theAdvancesinNeuralInformationProcessingSystems,Vol.31,2018, for medical applications: an experimental study of GPT-4V, arXiv
p.4485–4495. preprintarXiv:2310.19061(2023).
[24] Y.Zhou,S.-N.Lim,Jointaudio-visualdeepfakedetection,in:Proceed- [46] H. Khalid, S. Tariq, M. Kim, S. S. Woo, FakeAVCeleb: A novel
ings of the IEEE/CVF International Conference on Computer Vision, audio-videomultimodaldeepfakedataset,in:ProceedingsoftheNeural
2021,pp.14800–14809. Information Processing Systems Track on Datasets and Benchmarks,
[25] H.Khalid,M.Kim,S.Tariq,S.S.Woo,Evaluationofanaudio-video 2021.
multimodaldeepfakedatasetusingunimodalandmultimodaldetectors, [47] B. Shi, W.-N. Hsu, K. Lakhotia, A. Mohamed, Learning audio-visual
in:ProceedingsoftheWorkshoponSyntheticMultimedia-Audiovisual speechrepresentationbymaskedmultimodalclusterprediction,in:Pro-
DeepfakeGenerationandDetection,2021,pp.7–15. ceedings of the International Conference on Learning Representations,
[26] A.Hashmi,S.A.Shahzad,W.Ahmad,C.W.Lin,Y.Tsao,H.-M.Wang, 2021.
Multimodalforgerydetectionusingensemblelearning,in:Proceedings [48] A. Dosovitskiy, An Image is Worth 16x16 Words: Transformers for
of the Asia-Pacific Signal and Information Processing Association imagerecognitionatscale,arXivpreprintarXiv:2010.11929(2020).
AnnualSummitandConference,2022,pp.1524–1532. [49] A. Arnab, M. Dehghani, G. Heigold, C. Sun, M. Lucˇic´, C. Schmid,
[27] S.A.Shahzad,A.Hashmi,S.Khan,Y.-T.Peng,Y.Tsao,H.-M.Wang, ViViT: A video vision transformer, in: Proceedings of the IEEE/CVF
Lipsyncmatters:Anovelmultimodalforgerydetector,in:Proceedings InternationalConferenceonComputerVision,2021,pp.6836–6846.
of the Asia-Pacific Signal and Information Processing Association [50] Y.Gong,Y.-A.Chung,J.Glass,AST:Audiospectrogramtransformer,
AnnualSummitandConference,2022,pp.1885–1892. in:ProceedingsoftheInterspeechConference,2021,pp.571–575.
[28] S.A.Shahzad,A.Hashmi,Y.-T.Peng,Y.Tsao,H.-M.Wang,AV-Lip-
Sync+: Leveraging av-hubert to exploit multimodal inconsistency for
videodeepfakedetection,arXivpreprintarXiv:2311.02733(2023).
[29] H. Ilyas, A. Javed, K. M. Malik, AVFakeNet: A unified end-to-end
denseswintransformerdeeplearningmodelforaudio-visualdeepfakes
detection,AppliedSoftComputing136(2023)110124.
[30] A.Hashmi,S.A.Shahzad,C.-W.Lin,Y.Tsao,H.-M.Wang,AVTENet:
Audio-visual transformer-based ensemble network exploiting multiple
experts for video deepfake detection, arXiv preprint arXiv:2310.13103
(2023).
[31] W. Yang, X. Zhou, Z. Chen, B. Guo, Z. Ba, Z. Xia, X. Cao, K. Ren,
AvoiD-DF: Audio-visual joint learning for detecting deepfake, IEEE
Transactions on Information Forensics and Security 18 (2023) 2015–
2029.
[32] Y.Xu,P.Terho¨st,M.Pedersen,K.Raja,Analyzingfairnessindeepfake
detection with massively annotated databases, IEEE Transactions on
TechnologyandSociety5(1)(2024)93–106.
[33] Y.Bang,S.Cahyawijaya,N.Lee,W.Dai,D.Su,B.Wilie,H.Lovenia,
Z. Ji, T. Yu, W. Chung, et al., A multitask, multilingual, multimodal
evaluationofChatGPTonreasoning,hallucination,andinteractivity,in:
ProceedingsoftheInternationalJointConferenceonNaturalLanguage
ProcessingandConferenceoftheAsia-PacificChapteroftheAssocia-
tionforComputationalLinguistics,2023,pp.675–718.
[34] T. Vaikunta Pai, P. Nethravathi, R. Birau, V. Popescu, B. Karthik Pai,
P. V. Naik, Multimodal ChatGPT: Extending ChatGPT to enable rich
multimodalconversationsusingdeepneuralnetwork,JournalofIntelli-
gent&FuzzySystems(2024)1–17.
[35] Z.Yang,L.Li,J.Wang,K.Lin,E.Azarnasab,F.Ahmed,Z.Liu,C.Liu,
M.Zeng,L.Wang,MM-REACT:PromptingChatGPTformultimodal
reasoningandaction,arXivpreprintarXiv:2303.11381(2023).
[36] S.Jia,R.Lyu,K.Zhao,Y.Chen,Z.Yan,Y.Ju,C.Hu,X.Li,B.Wu,
S. Lyu, Can ChatGPT detect deepfakes? a study of using multimodal
large language models for media forensics, in: Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition,
2024,pp.4324–4333.
[37] I.DeAndres-Tame,R.Tolosana,R.Vera-Rodriguez,A.Morales,J.Fier-
rez,J.Ortega-Garcia,HowgoodisChatGPTatfacebiometrics?afirst
lookintorecognition,softbiometrics,andexplainability,IEEEAccess
12(2024)34390–34401.