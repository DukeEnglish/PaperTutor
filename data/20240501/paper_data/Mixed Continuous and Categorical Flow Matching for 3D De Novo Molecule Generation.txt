Mixed Continuous and Categorical Flow Matching for 3D De
Novo Molecule Generation
IanDunn DavidRyanKoes
Dept. ofComputational&SystemsBiology Dept. ofComputational&SystemsBiology
UniversityofPittsburgh UniversityofPittsburgh
Pittsburgh,PA15260 Pittsburgh,PA15260
ian.dunn@pitt.edu dkoes@pitt.edu
Abstract
Deep generative models that produce novel molecular structures have the potential to facilitate
chemicaldiscovery. Diffusionmodelscurrentlyachievestateoftheartperformancefor3Dmolecule
generation. In this work, we explore the use of flow matching, a recently proposed generative
modelingframeworkthatgeneralizesdiffusionmodels,forthetaskofdenovomoleculegeneration.
Flowmatchingprovidesflexibilityinmodeldesign;however,theframeworkispredicatedonthe
assumptionofcontinuously-valueddata. 3Ddenovomoleculegenerationrequiresjointlysampling
continuous and categorical variables such as atom position and atom type. We extend the flow
matching framework to categorical data by constructing flows that are constrained to exist on a
continuousrepresentationofcategoricaldataknownastheprobabilitysimplex. Wecallthisextension
SimplexFlow.WeexploretheuseofSimplexFlowfordenovomoleculegeneration.However,wefind
that,inpractice,asimplerapproachthatmakesnoaccommodationsforthecategoricalnatureofthe
datayieldsequivalentorsuperiorperformance. Asaresultoftheseexperiments,wepresentFlowMol,
aflowmatchingmodelfor3Ddenovogenerativemodelthatachievesimprovedperformanceover
priorflowmatchingmethods,andweraiseimportantquestionsaboutthedesignofpriordistributions
forachievingstrongperformanceinflowmatchingmodels. Codeandtrainedmodelsforreproducing
thisworkareavailableathttps://github.com/dunni3/FlowMol.
1 Introduction
Deepgenerativemodelsthatcandirectlysamplemolecularstructureswithdesiredpropertieshavethepotentialto
acceleratechemicaldiscoverybyreducingoreliminatingtheneedtoengageinresource-intensivescreening-basedbased
discoveryparadigms. Moreover,generativemodelsmayalsoimprovechemicaldiscoverybyenablingmulti-objective
designofchemicalmatter. Inpursuitofthisidea,therehasbeenrecentinterestindevelopinggenerativemodelsforthe
designofsmall-moleculetherapeutics[1–8],proteins[9–11],andmaterials[12]. Stateoftheartperformanceinthese
tasksispresentlyachievedbyapplyingdiffusionmodels[13–15]topointcloudrepresentationsofmolecularstructures.
Flowmatching,arecentlyproposedgenerativemodelingframework[16–19],generalizesdiffusionmodels. Under
diffusionmodels,thetransformationofpriorsamplestodataisformulatedasareversalofapredefinedforwardprocess.
TheforwardprocessisaMarkovchainordifferentialequationthatmustconvergetoatractablestationarydistribution
ast → ∞; thisrequirementconstrainstheviableoptionsforforward/reverseprocessesandpriordistributions. In
contrast,flowmatchingprescribesamethodfordirectlylearningadifferentialequationthatmapssamplesfromnearly
arbitrarydistributions. Indoingso, flowmatchingpermitsvaluableflexibilitywhendesigningmodelsforspecific
applications. Forexample,Jingetal.[20]andStärketal.[21]makeuseofthefactthatflowmatchingallowsarbitrary
priordistributionstodesignmodelswhosepriorsareclosertorealistic3DmolecularconformationsthanaGaussian
prior.
Inthisworkweexploretheapplicationofflowmatchingto3Ddenovosmallmoleculegeneration. Weadaptthe
approachofstateoftheartdiffusionmodelsforthistask[22–24]totheflowmatchingframework. Thisapproach
entailspredictingatompositions,atomtypes(chemicalelements),formalcharges,andbondordersbetweenallpairs
4202
rpA
03
]MB.oib-q[
1v93791.4042:viXraFigure1:OverviewofFlowMolTop:Weadapttheflowmatchingframeworkforunconditional3Dmoleculegeneration.
Anordinarydifferentialequationparameterizedbyagraphneuralnetworktransformsapriordistributionoveratom
positions,types,charges,andbondorderstothedistributionofvalidmolecules. Blackarrowsshowtheinstantaneous
directionoftheODEonatompositions.Middle:TrajectoryoftheatomtypevectorforasingleatomunderSimplexFlow,
avariantofflowmatchingdevelopedforcategoricalvariables. Atomtypeflowslieontheprobabilitysimplex. Bottom:
TrajectoryofanatomtypevectorstartingfromaGaussianprior. Thisapproachdoesnotrespectthecategoricalnature
ofthedata;however,wefindityieldssuperiorperformancetoSimplexFlow.
ofatoms. Allofthesevariablesarecategoricalwiththeexceptionofatompositions. Therefore,moleculegeneration
requiressamplingfromajointdistributionofcontinuousandcategoricalvariables.
Effectivelyadaptingflowmatchingforthismixedcontinuous/categoricalgenerativetaskmaybenon-trivialbecause
theflowmatchingframeworkispredicatedontheassumptionofcontinuouslyvalueddata. Inthiswork,weextend
theflowmatchingframeworktocategoricaldatabyconstructingflowsthatareconstrainedtoexistonacontinuous
representationofcategoricaldataknownastheprobabilitysimplex. WecallthisextensionSimplexFlow. Wepresenta
modelfordenovosmall-moleculegenerationthatusesSimplexFlowstogeneratecategoricalfeatures.
Thisworkwasmotivatedbytheintuitionthatdesigningagenerativeprocessthatrespectsthecategoricalnatureofthe
dataitoperatesonmayyieldimprovedperformance;however,ourempiricalresultscontradictthisintuition. Weshow
thatinpractice,asimplerapproachthatmakesnoaccommodationsforthecategoricalnatureofthedatayieldssuperior
performancetoadenovomodelusingSimplexFlow. Ourfinalflowmatchingmodelformoleculegeneration,FlowMol,
achievesimprovedperformanceoverexistingflowmatchingmethodsformoleculegenerationandiscompetitivewith
stateoftheartdiffusionmodelswhileexhibitinga>10-foldreductionininferencetime.
2 Background
2.1 DiscreteDiffusion
Theoriginalformulationofdiffusionmodels[13]wasdefinedintermsofaMarkovchainofrandomvariablesthat
convergedtoatractablestationarydistributioninthelimitofaninfinitenumberofstepsintheMarkovchain. This
formulation made no assumptions about the sample space of the random variables modeled, allowing for natural
extensionstodiscretedata[25–27].
Aseparateformulationofdiffusionmodelsascontinuous-timestochasticdifferentialequations(SDE)[15]became
popular in the literature. The SDE formulation of diffusion models is dependent on the assumption of having
continuously-valueddata. Similartoourapproach,thereisalineofworkdevelopingSDE-baseddiffusionmodels
thatoperateoncontinuousrepresentationsofdiscretedata. Severalworksdevelopeddiffusionmodelswherediffusion
trajectorieswereconstrainedtothesimplex[28–30]. Analternativeapproachistoembedcategoricalfeaturesintoa
continuouslatentspaceandtraindiffusionmodelsontheembeddings[31].
22.2 DeNovoMoleculeGeneration
Initialattemptsatdenovomoleculegenerationfocusedongeneratingeithertextualrepresentations(SMILESstrings)
[32–34]or2Dmoleculargraphs[35–38]: molecularrepresentationsthatexcludeallinformationabout3Dstructure.
Subsequentapproachesweredevelopedfor3Dmoleculegenerationusingavarietyofmolecularrepresentationsand
generativeparadigms[39–43].
Hoogeboometal.[44]proposedthefirstdiffusionmodelfor3Dmoleculegeneration,whichyieldedsuperiorperfor-
manceoverpreviousapproaches. MoleculesarerepresentedinHoogeboometal.[44]byattributedpointcloudswhere
eachatomhasapositioninspaceandtype. Acontinuousdiffusionprocessisdefinedforbothatompositionsand
typeswherethepriorforbothisastandardGaussiandistribution. Apurportedweaknessofthisapproachisthatatom
connectivityisnotpredictedbythemodelandmustbeinferredinapost-processingstep. Severalconcurrentworks
soughttoaddresstheseissuesbypredictingbondorderinadditiontoatompositions/types: Huangetal.[22],Vignac
etal.[23],Pengetal.[24],Huaetal.[45]. ThesemodelsreportsubstantiallyimprovedperformanceoverHoogeboom
et al. [44]. Three of these four concurrent works (Vignac et al. [23], Peng et al. [24], Hua et al. [45]) use discrete
diffusion processes for categorical features and attribute (in part) their improved model performance to the use of
discretediffusion.;however,onlyPengetal.[24]presentsanablationstudyisolatingtheeffectofdiscretediffusion.
Moreover,Huangetal.[22]usesonlycontinuousdiffusionprocessesandreportssuperiorperformance. Thissuggests
thatwhilepredictinggraphconnectivityprovidesperformancebenefits,theutilityofdiscretediffusionformolecule
generationislessclear. Vignacetal.[23]andHuangetal.[22]fullyspecifythemolecularstructurebyalsopredicting
atomformalchargesandthepresenceofhydrogenatoms;forthisreason,theseworksarethemostsimilartothemodel
presentedhere.
2.3 Flow-MatchingforDeNovoMoleculeGeneration
Toourknowledge, Songetal.[46]istheonlyexistingworkthatperformsdenovomoleculegenerationwithflow
matching. Moleculesarerepresentedaspointcloudswhereeachatomhasapositioninspaceandanatomtype. The
final molecule structure is inferred after the inference procedure. The prior distribution for atom type vectors is a
standardGaussiandistribution,andsothegenerativeprocessdoesnothaveanyinductivebiasestorespectthediscrete
natureofthedata. ThisworkcanbeviewedastheflowmatchinganalogofHoogeboometal.[44].
2.4 FlowMatchingforDiscreteData
Concurrentwork[47]developedavariantofflowmatchingonthesimplexwhichwerefertoasDirichletFlows. In
DirichletFlows,conditionalprobabilitypathsareonlyconditionedonx and,asaresult,donotpermitarbitrarychoices
1
ofthepriorandmustuseauniformdistributionoverthesimplex. Incontrast,ourformulationpermitstheuseofany
priordistribution. Starketal.[47]identifyproblemswiththechoiceofcommonlyusedconditionalvectorfieldsthat
limitperformanceonvariableswithalargenumberofcategories. Theyproposeanalternativechoiceofconditional
probabilitypathsthatalleviatethisissue.
Therearealsootherworkswhichdevelopflowmatchingvariantsfordiscretedata. Bolletal.[48]equipthesimplex
withtheFisher-RaometrictoformaRiemannianmanifold,andapplyRiemannianFlowMatching[49]tothismanifold.
Campbelletal.[50]developaflowmatchingmethodfordiscretedatabuiltoncontinuous-timeMarkovchains.
Importantly,noneoftheaforementionedworks,whichpresentmethodsfortrainingflowmatchingmodelsforcategorical
data,benchmarktheirmodelperformanceagainstsimplerflowmatchingmodelsthatdonotaccountforthecategorical
natureoftheirdata.
2.5 FlowMatching
Flowmatching[16–19]isanewgenerativemodelingframeworkthatgeneralizesdiffusionmodels. Flowmatching
permits useful design flexibility in the choice of prior of and nature of the map between two distributions. Flow
matchingisalsoconceptuallysimplerthandiffusionandpermitssubstantiallyfasterinference. Webrieflydescribethe
flowmatchingframeworkhere.
An ordinary differential equation (ODE) that exists on Rd is defined by a smooth, time-dependent vector-field
u(x,t):Rd×[0,1]→Rd.
dx
=u(x,t) (1)
dt
3Note that we only consider this ODE on the time interval [0,1]. For simplicity we will use u (x) interchangeably
t
withu(x,t). Givenaprobabilitydistributionoverinitialpositionsx ∼p (x),theODE(1)inducestimedependent
0 0
probabilitydistributionsp (x). Theobjectiveinflowmatchingistoapproximateavectorfieldu (x)thatpushesa
t t
sourcedistributionp (x)toadesiredtargetdistributionp (x). Aneuralnetworku canberegressedtothevectorfield
0 1 θ
u byminimizingtheFlowMatchingloss.
t
L =E ∥u (x,t)−u (x)∥2 (2)
FM x∼pt θ t
Computing L requires access to u and p , quantities that are typically intractable. Flow matching provides a
FM t t
methodforapproximatingu (x)withouthavingaccesstoit. Ifweconsidertheprobabilitypathp (x)tobeamixture
t t
ofconditionalprobabilitypathsp (x|z):
t
(cid:90)
p (x)= p (x|z)p(z)dz (3)
t t
andweknowtheformofthetheconditionalvectorfieldsu (x|z)thatproducep (x|z),thenthemarginalvectorfield
t t
u (x)canbedefinedasamixtureofconditionalvectorfields:
t
u (x|z)p (x|z)
u (x)=E t t (4)
t p(z) p (x)
t
Westillcannotcomputeu (x)buttheneuralnetworku thatistheminimizerofL isalsotheminimizerofthe
t θ FM
ConditionalFlowMatching(CFM)lossdefinedin(5)
L =E ∥u (x,t)−u (x|z)∥2 (5)
CFM p(z),pt(x|z),t∼U(0,1) θ t
Thatis,regressingtoconditionalvectorfields,inexpectation,isequivalenttoregressingtothemarginalvectorfield.The
remainingdesignchoicesforaflowmatchingmodelarethechoiceofconditioningvariablez,conditionalprobability
pathsp (x|z),andconditionalvectorfieldsu (x|z).
t t
3 Methods
3.1 ProblemSetting
WerepresentamoleculewithN atomsasafully-connectedgraph. Eachatomisanodeinthegraph. Everyatomhas
apositioninspaceX = {x i}N
i=1
∈ RN×3,anatomtype(inthiscasetheatomicelement)A = {a i}N
i=1
∈ RN×na,
andaformalchargeC = {c i}N
i=1
∈ RN×nc. Additionally, everypairofatomshasabondorderE = {e ij∀i,j ∈
[N]|i̸=j}∈R(N2−N)×ne. Wheren a,n c,n earethenumberofpossibleatomtypes,charges,andbondorders;these
arecategoricalvariablesrepresentedbyone-hotvectors. Forbrevity,wedenoteamoleculebythesymbolg,whichcan
bethoughtofasatupleoftheconstituentdatatypesg =(X,A,C,E).
Thereisnoclosed-formexpressionoranalyticaltechniqueforsamplingthedistributionofrealisticmoleculesp(g). We
seektotrainaflowmatchingmodeltosamplethisdistribution. Concretely,wechoosethethetargetdistributionthatis
thedistributionofvalid3Dmoleculesp (g)=p(g). Ourchoiceofpriorp (g)isdescribedinSection3.5.
1 0
Ourstrategyforadaptingflowmatchingtomolecularstructureisonethatmimicspriorworkonapplyingdiffusion
andflow-basedgenerativemodelstomolecularstructure. Thatis,wedefineconditionalvectorfieldsandconditional
probabilitypathsforeachdatamodalityandjointlyregressoneneuralnetworkforalldatamodalities. Ourtotallossis
aweightedcombinationofCFMlossesfrom(5):
L=η L +η L +η L +η L (6)
X X A A C C E E
Where (η ,η ,η ,η ) are scalars weighting the relative contribution of each loss term. We set these values to
X A C E
(3,0.4,1,2)aswasdoneinVignacetal.[23]. Ourspecificchoiceofconditionalvectorfieldsandprobabilitypathsis
describedinSection3.2. Inpractice,weuseavariantoftheCFMobjectivecalledtheendpoint-parameterizedobjective
thatwepresentinSection3.3. ThesechoicesareusedtointurntodesignSimplexFlow,ourmethodofperformingflow
matchingforcategoricalvariables,whichisdescribedinSection3.4.
43.2 FlowMatchingwithTemporallyNon-LinearInterpolants
We choose the conditioning variable to be the initial and final states of a trajectory: z = (g ,g ). We choose the
0 1
conditionalprobabilitypathtobeaDiracdensityplacedona“straight”lineconnectingthesestatesp (g|g ,g ) =
t 0 1
δ(g−(1−α )g −α g ). Thisparticularchoiceofconditionalvectorfieldsandprobabilitypathsgivesusthefreedom
t 0 t 1
tochooseanypriordistributionp (g)[17,18,36]. Ourchoiceofp (g|g ,g )isequivalenttodefiningadeterministic
0 t 0 1
interpolant:
g =(1−α )g +α g (7)
t t 0 t 1
whereα : [0,1] → [0,1]isafunctionthattakestasinputandreturnsavaluebetween0and1. Therateatwhich
t
amoleculefromthepriordistributiong istransformedintoavalidmoleculeg canbecontrolledbychoiceofα ,
0 1 t
whichwenamethe“interpolantschedule.”1 Wedefineseparateinterpolantschedulesforeachdatatypecomprisinga
molecule: α =(αX,αA,αC,αE). TakinginspirationfromVignacetal.[23],wedefineacosineinterpolantschedule:
t t t t t
(cid:16)π (cid:17)
α =1−cos2 tν (8)
t 2
wheredifferentvaluesofν aresetforatompositions,types,charges,andbondorders. Theinterpolant(7)givesriseto
conditionalvectorfieldsoftheform:
u(g |g ,g )=α′(g −g ) (9)
t 0 1 t 1 0
Whereα′ isthetimederivativeofα .
t t
3.3 EndpointParameterization
Bysolving(7)forg andsubstitutingthisexpressioninto(9)weobtainanalternateformoftheconditionalvectorfield.
0
α′
u(g |g ,g )= t (g −g ) (10)
t 0 1 1−α 1 t
t
As described in Section 2.5, the typical flow matching procedure is to regress a neural network u (g ) directly to
θ t
conditionalvectorfieldsbyminimizingtheCFMloss(5). Instead,weapplyareparameterizationinitiallyproposedby
Jingetal.[20]:
α′
u (g )= t (gˆ (g )−g ) (11)
θ t 1−α 1 t t
t
Bysubstituting(11)and(10)into(5),weobtainourendpoint-parameterizedobjective
(cid:20) α′ (cid:21)
L =E t ||gˆ (g )−g || (12)
EP t,gt 1−α 1 t 1
t
Thereforeourobjectivebecomestotrainaneuralnetworkthatpredictsvalidmolecularstructuresgivensamplesfroma
conditionalprobabilitypathgˆ (g ). Thisisparticularlyadvantageouswhenoperatingoncategoricaldata,asplacing
1 t
asoftmaxlayeronmodeloutputsconstrainsthedomainofmodeloutputstothesimplex. Empirically,wefindthat
theendpointobjectiveyieldsbetterperformancethanthevectorfieldregressionobjective(5)forthetaskofmolecule
generation. Moreover,weleveragethetheoreticalguaranteethatourpredictedendpointforcategoricaldatalieonthe
simplextoensureourflowslieonthesimplex.
I thn ispr ta ec rmtice w, it th he ain tit mer ep -o dl ea pn et- nd de ep ne tn ld oe sn st fl uo ns cs tiw oe nig inh st p1 ir−α eα′ t dt bp yro Ld euc ee ts alu .n [r 5e 1a ]s :o wna (b t)ly =lar mge inv (a mlu ae xs (0a .s 0α 05t ,→ α1 t. )W ,1e .5re )p .l Fac oe
r
1−αt
categoricalvariablesweuseacrossentropylossratherthantheL2normshownin(12).
1Thisisintendedtobeanalogoustonoiseschedulesfordiffusionmodels.
53.4 SimplexFlow
To design flow matching for categorical data, our strategy is to define a continuous representation of categorical
variables,andthenconstructaflowmatchingmodelwhereflowsareconstrainedtothisrepresentation. Wechoosethe
d-dimensionalprobabilitysimplexSdasthecontinuousrepresentationofad-categoricalvariable.
Sd =(cid:8) x∈Rd|x >0,1·x=1(cid:9) (13)
i
Ad-categoricalvariablex ∈{1,2,...,d}canbeconvertedtoapointonSdviaone-hotencoding. Correspondingly,
1
thecategoricaldistributionp (x)=C(q)canbeconvertedtoadistributiononSdas:
1
d
(cid:88)
p (x)= q δ(x−e ) (14)
1 i i
i=1
wheree istheith vertexofthesimplexandq istheprobabilityofxbelongingtotheith category. Ifwechoosea
i i
priordistributionp (x)suchthatsupp(p )=Sd,thenallconditionalprobabilitypathsproducedbytheinterpolant
0 0
(7)willlieonthesimplex. Thisisbecausethesimplexisclosedunderlinearinterpolation(seeAppendixA)andthe
conditionaltrajectoriesareobtainedbylinearlyinterpolatingbetweentwopointsonthesimplex(x ,x ∈Sd).
0 1
Althoughchoosing(p ,p )withsupportonthesimplexresultsinconditionaltrajectoriesonthesimplex,traininga
0 1
flowunderthevectorfieldobjective(5)providesnoguaranteethattrajectoriesproducedbythelearnedvectorfieldlie
onthesimplex. However,trainingaflowmatchingmodelundertheendpointparameterization(Section3.3)enablesus
toguaranteebyconstructionthatgeneratedflowslieonthesimplex;proofofthisisprovidedinAppendixB.
3.5 Priors
Wedefinethepriordistributionforamoleculeasacompositionofindependentsamplesforeachatomandpairof
atoms. Ourpriordistributionstaketheform:
N (cid:89)atoms N (cid:89)atoms
p (g)=p (x,a,c,e)= p (x )p (a )p (c )× p (e ) (15)
0 0 0 i 0 i 0 i 0 ij
i=1 i,j<i
Ourchoiceofconditionaltrajectory(7)permitsthechoiceofanypriordistribution. SimplexFlowplacestheconstraint
thatthepriordistributionforcategoricalvariableshavesupportboundedtothesimplex.
Wealwayssetp (x )=N(x |0,I);atompositionsareindependentlysampledfromastandardGaussiandistribution.
0 i i
Weexploretheuseofseveralpriordistributionsforcategoricalvariablesa ,c ,e . Weexperimentwiththreedifferent
i i ij
categoricalpriorsforSimplexFlow. Theuniform-simplexpriorisauniformdistributionoverthesimplex;thesimplest
choiceforacategoricalprior. Thischoiceisanalogoustothe“LinearFM”modeldescribedin[47]. Themarginal-
simplexpriorisdesignedtobe“closer”tothedatadistributionbyusingmarginaldistributionsobservedinthetraining
data. Specifically,wereplacep (a )p (c )andp (e )in(15)withp (a ,c )andp (e ),respectively. Finally,forthe
0 i 0 i 0 ij 1 i i 1 ij
barycenterprior,categoricalvariablesareplacedatthebarycenterofthesimplex;thepointinthecenterofthesimplex
assigningequalprobabilitytoallcategories. Theintuitionbehindthebarycenterpriorisallcategoricalvariableswillbe
“undecided”att=0.
Inpractice,themodelfailswhenthepriordistributionsforcategoricalvariablesonlyhavedensityonasmall,fixed
numberofpointsonthesimplex;thisisthecaseforthemarginal-simplexandbarycenterpriors. Wefindthat"blurring"
thepriorsamplesforcategoricalvariablessignificantlyimprovesperformance. Thatis,Gaussiannoiseisaddedtothe
samplesbeforetheyareprojectedbackontothesimplex.
3.6 OptimalTransportAlignment
Previouswork[17]hasshownthataligningpriorandtargetsamplesviaoptimaltransportsignificantlyimprovesthe
performanceofflowmatchingbyminimizingtheextenttowhichconditionaltrajectoriesintersect. Whenperforming
flowmatchingonmolecularstructure,thisconsistsofcomputingtheoptimalpermutationofnodeorderingandthe
rigid-bodyalignmentofatompositions[46,52]. Weapplythesamealignmentbetweentargetandpriorpositionsat
trainingtime. Thisalsoensuresthatpriorpositionsp (X)andtargetpositionsp (X)effectivelyexistinthecenterof
0 1
massfreesubspaceproposedinHoogeboometal.[44]thatrendersthetargetdensityp (g)invarianttotranslations.
1
6Figure2: FlowMolArchitectureTopleft: Aninputmoleculargraphg istransformedintoapredictedfinalmolecular
t
graphg bybeingpassedthroughmultiplemolelculeupdateblocks. Topright: AmoleculeupdateblockusesNFU,
1
NPU,andEFUsub-componentstoupdateallmolecularfeatures. Bottom: Updateequationsforgraphfeatures. ϕandψ
isusedtodenoteMLPsandGVPs,respectively.
3.7 ModelArchitecture
Moleculesaretreatedasfully-connectedgraphs. Themodelisdesignedtoacceptasampleg andpredictthefinal
t
destinationmoleculeg . Withintheneuralnetwork,molecularfeaturesaregroupedintonodepositions,nodescalar
1
features,nodevectorfeatures,andedgefeatures. NodepositionsareidenticaltoatompositionsdiscussedinSection
3.1. Node scalar features are a concatenation of atom type and atom charge. Node vector features are geometric
vectors(vectorswithrotationorder1)thatarerelativetothenodeposition. Nodevectorfeaturesareinitializedtozero
vectors. Molecularfeaturesareiterativelyupdatedbypassingg throughseveralMoleculeUpdateBlocks. AMolecule
t
UpdateBlockusesGeometricVectorPerceptrons(GVPs)[53]tohandlevectorfeatures. MoleculeUpdateBlocksare
composedofthreecomponents: anodefeatureupdate(NFU),nodepositionupdate(NPU)andedgefeatureupdate
(EFU).TheNFUusesamessage-passinggraphconvolutiontoupdatenodefeatures. TheNPUandEFUblocksarenode
andedge-wiseoperations,respectively. Followingseveralmoleculeupdateblocks,predictionsofthefinalcategorical
features(Aˆ ,Cˆ ,Eˆ )aregeneratedbypassingnodeandedgefeaturesthroughshallownode-wiseandedge-wisemulti
1 1 1
layerperceptrons(MLPs). Formodelsusingendpointparameterization,theseMLPsincludesoftmaxactivations. The
modelarchitectureisvisualizedinFigure2andexplainedindetailinAppendixD.
Inpractice,graphsaredirected. Foreverypairofatomsi,j thereexistsedgesinbothdirections: i → j andj → i.
WhenpredictingthefinalbondordersEˆ foranedge,weensurethatonepredictionismadeperpairofatomsandthat
1
thispredictionisinvarianttopermutationsoftheatomindexing. Thisisaccomplishedbymakingourpredictionfrom
thesumofthelearnedbondfeatures. Thatis,eˆij =MLP(e +e ).
1 ij ji
GVPs,astheywereoriginallydesigned,predictvectorquantitiesthatareE(3)-equivariant. Weintroduceavariant
ofGVPthatismadeSE(3)-equivariantbytheadditionofcrossproductoperations. Thecrossproductisequivariant
torotationsandtranslationsofinputvectorsbutnotreflections. Asaresult,thelearneddensityp (g)isinvariantto
1
rotationsandtranslationsbutnotreflections. Inotherwords,FlowMolissensitivetochirality. Empiricallywefindthat
theadditionofcrossproductoperationstoGVPimprovesperformance. Schneuingetal.[3]proposedtheadditionofa
crossproductoperationtotheEGNNarchitecture[54];weadoptthisideaforGVP.WereferthereadertoAppendixF
ofSchneuingetal.[3]foradetaileddiscussionoftheequivarianceofcrossproducts. OurcrossproductvariantofGVP
isdescribedinAppendixD.1.
74 Experiments
4.1 Datasets
WetrainonQM9[55,56]andGEOM-Drugs[57]usingexplicithydrogens. QM9contains124ksmallmolecules,
eachwithone3Dconformation. GEOM-Drugscontainsapproximately300klarger,drug-likemoleculeswithmultiple
conformersforeachmolecule.MoleculesinQM9haveanaverageof18atomsamaxof29whilethoseinGEOM-Drugs
haveanaverageof44atomsandamaxof181. WeusethesamedatasetsplitsasVignacetal.[23].
We chose to use explicit hydrogens because it is a more difficult learning task. By predicting explicit hydrogens
incombinationwithatomtypes,bondorders,andformalcharges,thereisa1-to-1mappingfrommodeloutputsto
molecules. Ifanyoneofthesecomponentswereremovedfromthegenerativetask,onemodeloutputcouldplausibly
beinterpretedasmultiplemolecularstructures,andsoitis“easier”forthemodeloutputtobeinterpretedas“correct”
or“valid.” Weviewthetaskofpredictinggraphtopologyandstructurewithexplicithydrogensandformalchargesas
themostrigorousevaluationofthecapabilitiesofgenerativemodelstofitthedistributionofvalidmolecularstructures.
4.2 ModelEvaluation
Wereportthreemetricsmeasuringthevalidityofgeneratedmoleculartopology:percentatomsstable,percentmolecules
stable,andpercentmoleculesvalid. Anatomisdefinedas“stable”ifithasvalidvalency. Atomicvalencyisdefinedas
thesumofbondordersthatanatomisparticipatingatom. Aromaticbondsareassignedabondorderof1.5. Avalid
valencyisdefinedasanyvalencythatisobservedinthetrainingdataforatomsofagivenelementandformalcharge. A
moleculeiscountedasstableifallofitsconstituentatomsarestable. Amoleculeisconsidered“valid”ifitcanbe
sanitizedbyrdkit[58]usingdefaultsanitizationsettings.
Metricsregardingthevalidityofmoleculartopologyfailtocaptureamodel’sabilitytoreproducereasonablemolecular
geometries. Therefore,wealsocomputetheJensen-Shannondivergenceofthedistributionofpotentialenergiesfor
molecules in the training data and molecules sampled from trained models. Potential energies are obtained from
theMerckMolecularMechanicsForce-Fieldimplementedinrdkit[58]. Force-fieldenergycannotbeobtainedfor
moleculesthatcannotbesanitizedbyrdkit,andsothereportedJensen-Shannondivergencesareforvalidmolecules
only.
Moleculequalitymetricsarereportedforsamplesof10,000molecules,repeated5times. Wereportinferencetimefor
FlowMolandbaselinemodels. Wemeasureinferencetimeasthetimerequiredtogenerateonebatchof100molecules
onthesameNVIDIAGeForceRTX2060GPU.Thisinferenceprocedureisalsorepeatedfivetimes. Inferenceisrun
onFlowMolusingEulerintegrationwith100evenly-spacedtimesteps. Allresultsarereportedwith95%confidence
intervals.Forallsamplings,thenumberofatomineachmoleculeissampledfromthedistributionofatomsinmolecules
fromthetrainingdata.
4.3 ModelAblations
Wetrainmultipleversionsofourmodeltoevaluatetheeffectsofseveralaforementioneddesignchoices. Toobserve
theeffectofendpointreparameterization(sec3.3), wetrainequivalentmodelswithboththevector-fieldobjective
(5)andtheendpointobjective(12). WetrainmodelsusingSimplexFlowwithallthreecategoricalpriorsproposedin
Section3.5whichhavesupportonthesimplex. TodeterminewhetherSimplexFlowimprovesperformance,wealso
trainmodelswherethepriordistributionforcategoricalfeaturesisastandardGaussiandistribution. Inthissetting,the
generatedflowsarenotconstrainedtothesimplex,anditcanbesaidthattheflowsdonot“respect”thecategorical
natureofthedata. ThisissimilartotheatomtypeflowsinSongetal.[46]andatomtypediffusioninHoogeboometal.
[44].
AllofthementionedmodelablationsaretestedontheQM9datasetandtheresultsarepresentedinSection5.1. A
subsetoftheseablationswerealsoperformedontheGEOMdataset. GEOMablationsareavailableinAppendixE.
NoneoftheeffectsobservedinGEOMablationscontradictthoseseenforQM9ablations. Formetricsreportedin
ablations,resultsareaveragedovertwoidenticalmodelstrainedwithdifferentrandomseeds
4.4 ComparisontoDirichletFlows
WecompareSimplexFlowtoconcurrentworkthatdevelopedDirichletFlows[47]forflowmatchingonthesimplex.
Briefly,forad-categoricalvariablexrepresentedasapointonthesimplex,theconditionalprobabilitypathis
p (x|x =e )=Dir(x|γ =1+e ω) (16)
t 1 i i
8Table1: FlowMolAblationsonQM9withexplicithydrogens
AtomsStable MolsStable MolsValid JS(E)
FlowType CategoricalPrior
(%)(↑) (%)(↑) (%)(↑) (↓)
Dirichlet uniform-simplex 98.4±0.0 80.0±0.3 85.5±0.3 0.15±0.01
endpoint uniform-simplex 98.9±0.1 84.2±0.9 88.9±0.6 0.11±0.01
marginal-simplex 99.5±0.1 91.9±0.7 96.1±0.2 0.06±0.00
barycenter 99.5±0.0 91.4±0.5 93.6±0.5 0.05±0.00
Gaussian 99.7±0.0 96.0±0.1 96.9±0.1 0.09±0.01
vector-field marginal-simplex 98.6±0.0 79.4±0.3 86.2±0.3 0.07±0.00
Gaussian 99.5±0.0 93.6±0.7 94.7±0.7 0.08±0.01
WhereDirisaDirichletdistributionparameterizedbyγ andωrepresentstime. TheDirichletconditionalflowmust
startatω = 1andonlyconvergestoδ(x−e )inthelimitω → ∞. InordertoincorporateDirichletflowsintoour
i
model,wedefinetherelationω =ω α +1,whereα isdefinedby(8). Dirichletflowmatchingnecessitatesthe
t max t t
useofauniformprioroverthesimplexforcategoricalvariablesandsowedonotexperimentwithothersimplexpriors
describedinSection3.5.
4.5 Baselines
WecompareFlowMoltothreebaselines: MiDi[23],JODO[22],andEquiFM[46]. MiDiandJODOperformthesame
generationtask: predictingatompositions, atomtypes, formalcharges, andbondorders. Thekeydifferencefrom
FlowMolisthatMiDiandJODOarediffusionmodels. EquiFMasdescribedinSection2.3isaflowmatchingmodel
fordenovomoleculegeneration;however,themodeldoesnotpredictbondordersoratomiccharges. Wedonotreport
theperformanceofEquiFMontheGEOMdatasetbecausetheauthorshavenotreleasedamodelcheckpoint.
5 Results
5.1 ModelAblations
Results of model ablation experiments on the QM9 dataset are shown in Table 1. Most notably, models that use
SimplexFlowforcategoricalvariables(thosewithcategoricalpriorsconstrainedtothesimplex)consistentlyunderper-
formmodelswithGaussiancategoricalpriors. ThebestperformingSimplexFlowmodel(endpointparameterization,
marginal-simplexprior)achieves96.1%validmoleculeswhileanequivalentmodelusingaGaussianpriorachieves
96.9%validmolecules.
Modelstrainedundertheendpointobjectiveachievesuperiorperformancetootherwiseidenticalmodelstrainedunder
thevector-fieldobjective. Forexample,Table1showsthatamodeltrainedwiththeamarginal-simplexcategoricalprior
obtains79%stablemoleculesunderthevector-fieldobjectiveand92%stablemoleculesundertheendpointobjective.
ThisiseffectisalsoobservedwithmodelsusingaGaussiancategoricalpriorbuttoalesserextent.
WefindthatmodelsusingDirichletconditionalprobabilitypaths[47]yieldsapproximatelyequivalentperformanceto
theconditionalprobabilitypath(7)withauniform-simplexcategoricalprior. Amongmodelssatisfyingtheconstraints
of SimplexFlow (sec. 3.4), the uniform-simplex prior yielded the worst performance. The marginal-simplex and
barycenter priors yield approximately equivalent performance. Although the models using marginal-simplex and
barycenterpriorsproducerelativelyfewervalidmolecules,themoleculesgeneratedbythesemodelsexhibitthelowest
Jensen-Shannondivergencetotheenergydistributionofthetrainingdata.
5.2 ComparisonwithBaselines
FlowMolachievessuperiorperformancetoEquiFM[46]onQM9;forexample,itproduces3%morevalidmolecules
whilehavingequivalentdivergencetothetrainingdataenergydistribution. FlowMolapproachestheperformance
ofdiffusionbaselines(JODO,MiDi)onQM9butdoesnotperformaswellontheGEOM-Drugsdataset. Thefact
thatfewergeneratedmoleculesarevalidontheGEOM-Drugsdatasetcannotbeattributedsolelytothedifferencein
moleculesizesbetweenthetwodatasets,becauseFlowMol’satom-levelstabilityisalsoworseforGEOM-Drugsthan
QM9(99.0%onGEOMvs99.7%onQM9). DespitethefactthatMiDiandFlowMolachieveequivalentatom-level
stability(99.0%),MiDiproducessignificantlymoretopologicallycorrectmolecules. Forexample,FlowMolachieves
68%stablemoleculeswhileMiDiachieves85%.
9Table2: ComparisonofFlowMoltobaselinemodelsontheQM9andGEOM-Drugsdatasets
AtomsStable MolsStable MolsValid JS(E) InferenceTime
Model Dataset
(%)(↑) (%)(↑) (%)(↑) (↓) (s)(↓)
JODO[22] 99.9±0.0 98.7±0.2 98.9±0.2 0.12±0.01 116±2
MiDi[23] 99.8±0.0 97.5±0.1 98.0±0.2 0.05±0.00 89±7
QM9
EquiFM[46] 99.4±0.0 93.2±0.3 94.4±0.2 0.08±0.00 25±3
FlowMol(ours) 99.7±0.0 96.2±0.1 97.3±0.1 0.08±0.00 6±0
JODO[22] 99.8±0.0 90.7±0.5 76.5±0.8 0.17±0.01 235±16
MiDi[23] GEOM-Drugs 99.0±0.2 85.1±0.9 71.6±0.9 0.23±0.00 754±119
FlowMol(ours) 99.0±0.0 67.5±0.2 51.2±0.3 0.33±0.01 22±1
FlowMolexhibitssubstantiallyfasterinferencestimesthanallbaselinemodels. Thisdifferenceisprimarilydueto
thefewernumberofintegrationstepsneededbyFlowMol. Wefindempiricallythatsamplequalitydoesnotimprove
whenusingmorethan100integrationsteps. JODO,MiDi,andEquiFMuse1000integrationstepsbydefault. Theneed
forfewerintegrationstepsthandiffusionmodelsisarecognizedadvantageofflowmatchingmodelsoverdiffusion
[17,19].
6 Discussion
FlowMolimprovesupontheexistingstateoftheartflowmatchingmethodformoleculegeneration;however,itstill
doesnotoutperformdiffusionmodelstrainedforthesametask. AkeydifferencebetweenFlowMolandthediffusion
baselinespresentedhereisthattheconditionaltrajectoriesaredeterministicinFlowMolandstochasticindiffusion
models. Priorworkshavepresentedtheoretical[18]andempirical[21]evidencethatstochasticconditionaltrajectories
yieldimprovedmodelperformance.
Ourresultsraiseinterestingquestionsaboutthedesignofpriordistributionsforflowmatchingmodels. Ourintuition
wasthatastrongerpriorthatis“closer”tothedatadistributionwouldyieldmorefaithfulrecapitulationofthetarget
distribution. Theresultsofourmodelablationssuggestthisintuitionisincorrect. Thenextnaturalquestionsare: why
isaGaussianpriorthemostperformantofthosetestedhere? andwhatarethequalitiesofapriorthatbestenable
recapitulationofthetargetdistribution? Apossibleexplanationforourresultsisadependenceonthe“volume”of
theprior. Empiricallywhenthepriorforcategoricalfeatureshassupportonasmallnumberofuniquevalues, the
modelfailstoproduceanyvalidmolecules. Addinga“blur”asdescribedinSection3.5dramaticallyimprovesmodel
performance. Correspondingly, priorsconstrainedtothesimplexreliablyyieldpoorerperformancethanGaussian
priors; these observations could all be explained through the perspective of the prior’s capacity for serving as one
domainofahomeomorphismtoamorecomplexdistribution.
AnotherexplanationforthesuperiorityofGaussianpriorsmayinvolvetheshapeofconditionaltrajectoriesinducedby
theprior. Conditionaltrajectoriesaremorelikelytointersectwhenconstrainedtoasmallerspace,suchasthesimplex.
Thisexplanationisalsosupportedbytheobservationthatthemarginal-simplexandbarycenterpriorsyieldsubstantially
improvedperformanceoveruniform-simplexpriors. Tongetal.[17]suggestthatsamplingconditionalpairs(g ,g )
0 1
fromanoptimaltransport(OT)alignmentπ(g ,g )improvesperformancepreciselybecausethemarginalvectorfield
0 1
yieldsstraighterlineswithfewerintersections. Inthiswork,anOTplaniscomputedbutonlyforatomicpositions.
PerhapscomputinganOTalignmentovertheproductspaceofallthedatamodalitiesrepresentedherecouldalleviate
thisissue.
7 Conclusions
FlowMolisthefirstgenerativemodeltojointlysamplethetopologicalandgeometricstructureofsmallmolecules.
FlowMolimprovesuponexistingflowmatchingmodelsformoleculegenerationandachievescompetitiveperformance
withdiffusion-basedmodelswhileexhibitinginferencespeedsanorderofmagnitudefaster. Wepresentamethodfor
flowmatchingoncategoricalvariables,SimplexFlow,anddemonstratethatconstrainingflowstoasmallerspacedoes
notyieldperformancebenefits. Wethinkthisresultraisesinterestingandrelevantquestionsaboutthedesignofflow
matchingformixedcontinuous/categoricalgenerativetasksandprovidepotentialhypothesestobeginexploringin
futurework.
108 Acknowledgements
WethankRishalAggarwal,GabriellaGerlach,andDanielPeñahererraforusefulfeedbackanddiscussions.
ThisworkisfundedthroughR35GM140753fromtheNationalInstituteofGeneralMedicalSciences. Thecontentis
solelytheresponsibilityoftheauthorsanddoesnotnecessarilyrepresenttheofficialviewsoftheNationalInstituteof
GeneralMedicalSciencesortheNationalInstitutesofHealth.
References
[1] LeiHuang,TingyangXu,YangYu,PeilinZhao,XingjianChen,JingHan,ZhiXie,HailongLi,WengeZhong,Ka-
ChunWong,andHengtongZhang. Adualdiffusionmodelenables3Dmoleculegenerationandleadoptimization
basedontargetpockets. NatureCommunications,15(1):2657,March2024. ISSN2041-1723. doi: 10.1038/
s41467-024-46569-1.URLhttps://www.nature.com/articles/s41467-024-46569-1.Publisher:Nature
PublishingGroup.
[2] JiaqiGuan,WesleyWeiQian,XingangPeng,YufengSu,JianPeng,andJianzhuMa. 3DEquivariantDiffusion
forTarget-AwareMoleculeGenerationandAffinityPrediction,March2023. URLhttp://arxiv.org/abs/
2303.03543. arXiv:2303.03543[cs,q-bio].
[3] ArneSchneuing,YuanqiDu,CharlesHarris,ArianJamasb,IliaIgashov,WeitaoDu,TomBlundell,PietroLió,
CarlaGomes,MaxWelling,MichaelBronstein,andBrunoCorreia. Structure-basedDrugDesignwithEquivariant
DiffusionModels,June2023. URLhttp://arxiv.org/abs/2210.13695. arXiv:2210.13695[cs,q-bio].
[4] XingangPeng,ShitongLuo,JiaqiGuan,QiXie,JianPeng,andJianzhuMa.Pocket2Mol:EfficientMolecularSam-
plingBasedon3DProteinPockets,May2022. URLhttp://arxiv.org/abs/2205.07249. arXiv:2205.07249
[cs,q-bio].
[5] MengLiu,YouzhiLuo,KanjiUchino,KojiMaruhashi,andShuiwangJi. Generating3DMoleculesforTarget
ProteinBinding,May2022. URLhttp://arxiv.org/abs/2204.09410. arXiv:2204.09410[cs,q-bio].
[6] JosTorge,CharlesHarris,SimonV.Mathis,andPietroLio. DiffHopp: AGraphDiffusionModelforNovelDrug
DesignviaScaffoldHopping,August2023. URLhttp://arxiv.org/abs/2308.07416. arXiv:2308.07416
[q-bio].
[7] Ilia Igashov, Hannes Stärk, Clément Vignac, Arne Schneuing, Victor Garcia Satorras, Pascal Frossard,
Max Welling, Michael Bronstein, and Bruno Correia. Equivariant 3D-conditional diffusion model for
molecular linker design. Nature Machine Intelligence, pages 1–11, April 2024. ISSN 2522-5839. doi:
10.1038/s42256-024-00815-9. URL https://www.nature.com/articles/s42256-024-00815-9. Pub-
lisher: NaturePublishingGroup.
[8] IanDunnandDavidKoes. AcceleratingInferenceinMolecularDiffusionModelswithLatentRepresentationsof
ProteinStructure. October2023. URLhttps://openreview.net/forum?id=Z4ia7s2tpV.
[9] JosephL.Watson,DavidJuergens,NathanielR.Bennett,BrianL.Trippe,JasonYim,HelenE.Eisenach,Woody
Ahern,AndrewJ.Borst,RobertJ.Ragotte,LukasF.Milles,BasileI.M.Wicky,NikitaHanikel,SamuelJ.Pellock,
AlexisCourbet,WilliamSheffler,JueWang,PreethamVenkatesh,IsaacSappington,SusanaVázquezTorres,Anna
Lauko,ValentinDeBortoli,EmileMathieu,SergeyOvchinnikov,ReginaBarzilay,TommiS.Jaakkola,Frank
DiMaio,MinkyungBaek,andDavidBaker. DenovodesignofproteinstructureandfunctionwithRFdiffusion.
Nature, 620(7976):1089–1100, August 2023. ISSN 1476-4687. doi: 10.1038/s41586-023-06415-8. URL
https://www.nature.com/articles/s41586-023-06415-8. Publisher: NaturePublishingGroup.
[10] NathanielR.Bennett,JosephL.Watson,RobertJ.Ragotte,AndrewJ.Borst,DéjenaéL.See,ConnorWeidle,
RitiBiswas,EllenL.Shrock,PhilipJ.Y.Leung,BuweiHuang,InnaGoreshnik,RussellAult,KennethD.Carr,
BenediktSinger,CameronCriswell,DionneVafeados,MarianaGarciaSanchez,HoMinKim,SusanaVázquezTor-
res,SidneyChan,andDavidBaker. Atomicallyaccuratedenovodesignofsingle-domainantibodies,March2024.
URLhttps://www.biorxiv.org/content/10.1101/2024.03.14.585103v1. Pages: 2024.03.14.585103
Section: NewResults.
[11] JohnB.Ingraham,MaxBaranov,ZakCostello,KarlW.Barber,WujieWang,AhmedIsmail,VincentFrappier,
DanaM.Lord,ChristopherNg-Thow-Hing,ErikR.VanVlack,ShanTie,VincentXue,SarahC.Cowles,Alan
Leung,JoãoV.Rodrigues,ClaudioL.Morales-Perez,AlexM.Ayoub,RobinGreen,KatherinePuentes,Frank
11Oplinger,NishantV.Panwar,FritzObermeyer,AdamR.Root,AndrewL.Beam,FrankJ.Poelwijk,andGevorg
Grigoryan. Illuminatingproteinspacewithaprogrammablegenerativemodel. Nature,623(7989):1070–1078,
November 2023. ISSN 1476-4687. doi: 10.1038/s41586-023-06728-8. URL https://www.nature.com/
articles/s41586-023-06728-8. Publisher: NaturePublishingGroup.
[12] Claudio Zeni, Robert Pinsler, Daniel Zügner, Andrew Fowler, Matthew Horton, Xiang Fu, Sasha Shysheya,
JonathanCrabbé,LixinSun,JakeSmith,BichlienNguyen,HannesSchulz,SarahLewis,Chin-WeiHuang,Ziheng
Lu,YichiZhou,HanYang,HongxiaHao,JielanLi,RyotaTomioka,andTianXie. MatterGen: agenerativemodel
forinorganicmaterialsdesign,January2024. URLhttp://arxiv.org/abs/2312.03687. arXiv:2312.03687
[cond-mat].
[13] JaschaSohl-Dickstein,EricA.Weiss,NiruMaheswaranathan,andSuryaGanguli. DeepUnsupervisedLearn-
ing using Nonequilibrium Thermodynamics, November 2015. URL http://arxiv.org/abs/1503.03585.
arXiv:1503.03585[cond-mat,q-bio,stat].
[14] JonathanHo,AjayJain,andPieterAbbeel. DenoisingDiffusionProbabilisticModels,December2020. URL
http://arxiv.org/abs/2006.11239. arXiv:2006.11239[cs,stat].
[15] Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole.
Score-Based Generative Modeling through Stochastic Differential Equations, February 2021. URL http:
//arxiv.org/abs/2011.13456. arXiv:2011.13456[cs,stat].
[16] YaronLipman,RickyT.Q.Chen,HeliBen-Hamu,MaximilianNickel,andMattLe.FlowMatchingforGenerative
Modeling,February2023. URLhttp://arxiv.org/abs/2210.02747. arXiv:2210.02747[cs,stat].
[17] AlexanderTong,NikolayMalkin,GuillaumeHuguet,YanleiZhang,JarridRector-Brooks,KilianFatras,Guy
Wolf,andYoshuaBengio. Improvingandgeneralizingflow-basedgenerativemodelswithminibatchoptimal
transport,July2023. URLhttp://arxiv.org/abs/2302.00482. arXiv:2302.00482[cs].
[18] MichaelS.Albergo,NicholasM.Boffi,andEricVanden-Eijnden. StochasticInterpolants: AUnifyingFramework
forFlowsandDiffusions,November2023. URLhttp://arxiv.org/abs/2303.08797. arXiv:2303.08797
[cond-mat].
[19] XingchaoLiu,ChengyueGong,andQiangLiu. FlowStraightandFast: LearningtoGenerateandTransferData
withRectifiedFlow,September2022. URLhttp://arxiv.org/abs/2209.03003. arXiv:2209.03003[cs].
[20] Bowen Jing, Bonnie Berger, and Tommi Jaakkola. AlphaFold Meets Flow Matching for Generating Protein
Ensembles,February2024. URLhttp://arxiv.org/abs/2402.04845. arXiv:2402.04845[cs,q-bio].
[21] HannesStärk,BowenJing,ReginaBarzilay,andTommiJaakkola. HarmonicSelf-ConditionedFlowMatching
forMulti-LigandDockingandBindingSiteDesign,March2024. URLhttp://arxiv.org/abs/2310.05764.
arXiv:2310.05764[cs].
[22] HanHuang,LeileiSun,BowenDu,andWeifengLv. LearningJoint2D&3DDiffusionModelsforComplete
MoleculeGeneration,June2023. URLhttp://arxiv.org/abs/2305.12347. arXiv:2305.12347[cs,q-bio].
[23] Clement Vignac, Nagham Osman, Laura Toni, and Pascal Frossard. MiDi: Mixed Graph and 3D Denoising
DiffusionforMoleculeGeneration,June2023. URLhttp://arxiv.org/abs/2302.09048. arXiv:2302.09048
[cs].
[24] XingangPeng, JiaqiGuan, QiangLiu, andJianzhuMa. MolDiff: AddressingtheAtom-BondInconsistency
Problem in 3D Molecule Diffusion Generation, May 2023. URL http://arxiv.org/abs/2305.07508.
arXiv:2305.07508[cs,q-bio].
[25] EmielHoogeboom,DidrikNielsen,PriyankJaini,PatrickForré,andMaxWelling.ArgmaxFlowsandMultinomial
Diffusion: Learning Categorical Distributions, October 2021. URL http://arxiv.org/abs/2102.05379.
arXiv:2102.05379[cs,stat].
[26] AndrewCampbell,JoeBenton,ValentinDeBortoli,TomRainforth,GeorgeDeligiannidis,andArnaudDoucet. A
ContinuousTimeFrameworkforDiscreteDenoisingModels,October2022. URLhttp://arxiv.org/abs/
2205.14987. arXiv:2205.14987[cs,stat].
[27] JacobAustin,DanielD.Johnson,JonathanHo,DanielTarlow,andRiannevandenBerg. StructuredDenois-
ingDiffusionModelsinDiscreteState-Spaces,February2023. URLhttp://arxiv.org/abs/2107.03006.
arXiv:2107.03006[cs].
12[28] PierreH.Richemond,SanderDieleman,andArnaudDoucet. CategoricalSDEswithSimplexDiffusion,October
2022. URLhttp://arxiv.org/abs/2210.14784. arXiv:2210.14784[cs].
[29] GriffinFloto,ThorsteinnJonsson,MihaiNica,ScottSanner,andEricZhengyuZhu. DiffusionontheProbability
Simplex,September2023. URLhttp://arxiv.org/abs/2309.02530. arXiv:2309.02530[cs,stat].
[30] PavelAvdeyev,ChenlaiShi,YuhaoTan,KseniiaDudnyk,andJianZhou. DirichletDiffusionScoreModelfor
BiologicalSequenceGeneration,June2023. URLhttp://arxiv.org/abs/2305.10699. arXiv:2305.10699
[cs,q-bio].
[31] SanderDieleman,LaurentSartran,ArmanRoshannai,NikolaySavinov,YaroslavGanin,PierreH.Richemond,
ArnaudDoucet,RobinStrudel,ChrisDyer,ConorDurkan,CurtisHawthorne,RémiLeblond,WillGrathwohl,
andJonasAdler. Continuousdiffusionforcategoricaldata,December2022. URLhttp://arxiv.org/abs/
2211.15089. arXiv:2211.15089[cs].
[32] FrancescaGrisoni,MichaelMoret,RobinLingwood,andGisbertSchneider. BidirectionalMoleculeGeneration
withRecurrentNeuralNetworks. JournalofChemicalInformationandModeling,60(3):1175–1183,March2020.
ISSN 1549-9596. doi: 10.1021/acs.jcim.9b00943. URL https://doi.org/10.1021/acs.jcim.9b00943.
Publisher: AmericanChemicalSociety.
[33] RafaelGómez-Bombarelli,JenniferN.Wei,DavidDuvenaud,JoséMiguelHernández-Lobato,BenjamínSánchez-
Lengeling,DennisSheberla,JorgeAguilera-Iparraguirre,TimothyD.Hirzel,RyanP.Adams,andAlánAspuru-
Guzik. Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules. ACS
Central Science, 4(2):268–276, February 2018. ISSN 2374-7943. doi: 10.1021/acscentsci.7b00572. URL
https://doi.org/10.1021/acscentsci.7b00572. Publisher: AmericanChemicalSociety.
[34] HanjunDai,YingtaoTian,BoDai,StevenSkiena,andLeSong. Syntax-DirectedVariationalAutoencoderfor
StructuredData,February2018. URLhttp://arxiv.org/abs/1802.08786. arXiv:1802.08786[cs].
[35] WengongJin,ReginaBarzilay,andTommiJaakkola. JunctionTreeVariationalAutoencoderforMolecularGraph
Generation,March2019. URLhttp://arxiv.org/abs/1802.04364. arXiv:1802.04364[cs,stat].
[36] QiLiu,MiltiadisAllamanis,MarcBrockschmidt,andAlexanderL.Gaunt. ConstrainedGraphVariationalAu-
toencodersforMoleculeDesign,March2019. URLhttp://arxiv.org/abs/1805.09076. arXiv:1805.09076
[cs,stat].
[37] ChenceShi,MinkaiXu,ZhaochengZhu,WeinanZhang,MingZhang,andJianTang. GraphAF:aFlow-based
AutoregressiveModelforMolecularGraphGeneration,February2020. URLhttp://arxiv.org/abs/2001.
09382. arXiv:2001.09382[cs,stat].
[38] Jiaxuan You, Bowen Liu, Rex Ying, Vijay Pande, and Jure Leskovec. Graph Convolutional Policy Network
forGoal-DirectedMolecularGraphGeneration,February2019. URLhttp://arxiv.org/abs/1806.02473.
arXiv:1806.02473[cs,stat].
[39] Matthew Ragoza, Tomohide Masuda, and David Ryan Koes. Learning a Continuous Representation of 3D
MolecularStructureswithDeepGenerativeModels, November2020. URLhttp://arxiv.org/abs/2010.
08687. arXiv:2010.08687[cs,q-bio].
[40] MatthewRagoza,TomohideMasuda,andDavidRyanKoes. Generating3Dmoleculesconditionalonreceptor
binding sites with deep generative models. Chemical Science, 13(9):2701–2713, March 2022. ISSN 2041-
6539. doi: 10.1039/D1SC05976A. URL https://pubs.rsc.org/en/content/articlelanding/2022/
sc/d1sc05976a. Publisher: TheRoyalSocietyofChemistry.
[41] Niklas W. A. Gebauer, Michael Gastegger, and Kristof T. Schütt. Symmetry-adapted generation of 3d point
sets for the targeted discovery of molecules, January 2020. URL http://arxiv.org/abs/1906.00957.
arXiv:1906.00957[physics,stat].
[42] Youzhi Luo and Shuiwang Ji. An Autoregressive Flow Model for 3D Molecular Geometry Generation from
Scratch. October2021. URLhttps://openreview.net/forum?id=C03Ajc-NS5W.
[43] VictorGarciaSatorras,EmielHoogeboom,FabianB.Fuchs,IngmarPosner,andMaxWelling. E(n)Equivariant
NormalizingFlows,January2022. URLhttp://arxiv.org/abs/2105.09016. arXiv:2105.09016[physics,
stat].
13[44] EmielHoogeboom,VictorGarciaSatorras,ClémentVignac,andMaxWelling.EquivariantDiffusionforMolecule
Generationin3D,June2022. URLhttp://arxiv.org/abs/2203.17003. arXiv:2203.17003[cs,q-bio,stat].
[45] ChenqingHua,SitaoLuan,MinkaiXu,RexYing,JieFu,StefanoErmon,andDoinaPrecup. MUDiff: Unified
Diffusion for Complete Molecule Generation, February 2024. URL http://arxiv.org/abs/2304.14621.
arXiv:2304.14621[cs,q-bio].
[46] YuxuanSong,JingjingGong,MinkaiXu,ZiyaoCao,YanyanLan,StefanoErmon,HaoZhou,andWei-YingMa.
EquivariantFlowMatchingwithHybridProbabilityTransport,December2023. URLhttp://arxiv.org/abs/
2312.07168. arXiv:2312.07168[cs].
[47] HannesStark,BowenJing,ChenyuWang,GabrieleCorso,BonnieBerger,ReginaBarzilay,andTommiJaakkola.
DirichletFlowMatchingwithApplicationstoDNASequenceDesign,February2024. URLhttp://arxiv.
org/abs/2402.05841. arXiv:2402.05841[cs,q-bio].
[48] BastianBoll,DanielGonzalez-Alvarado,andChristophSchnörr. GenerativeModelingofDiscreteJointDistribu-
tionsbyE-GeodesicFlowMatchingonAssignmentManifolds,February2024. URLhttp://arxiv.org/abs/
2402.07846. arXiv:2402.07846[cs,stat].
[49] Ricky T. Q. Chen and Yaron Lipman. Flow Matching on General Geometries, February 2024. URL http:
//arxiv.org/abs/2302.03660. arXiv:2302.03660[cs,stat].
[50] Andrew Campbell, Jason Yim, Regina Barzilay, Tom Rainforth, and Tommi Jaakkola. Generative Flows on
DiscreteState-Spaces: EnablingMultimodalFlowswithApplicationstoProteinCo-Design,February2024. URL
http://arxiv.org/abs/2402.04997. arXiv:2402.04997[cs,q-bio,stat].
[51] TuanLe,JulianCremer,FrankNoé,Djork-ArnéClevert,andKristofSchütt. NavigatingtheDesignSpaceof
EquivariantDiffusion-BasedGenerativeModelsforDeNovo3DMoleculeGeneration,November2023. URL
http://arxiv.org/abs/2309.17296. arXiv:2309.17296[cs].
[52] Leon Klein, Andreas Krämer, and Frank Noé. Equivariant flow matching, November 2023. URL http:
//arxiv.org/abs/2306.15030. arXiv:2306.15030[physics,stat].
[53] Bowen Jing, Stephan Eismann, Pratham N. Soni, and Ron O. Dror. Equivariant Graph Neural Networks for
3DMacromolecularStructure,July2021. URLhttp://arxiv.org/abs/2106.03843. arXiv:2106.03843[cs,
q-bio].
[54] VictorGarciaSatorras,EmielHoogeboom,andMaxWelling. E(n)EquivariantGraphNeuralNetworks,February
2022. URLhttp://arxiv.org/abs/2102.09844. arXiv:2102.09844[cs,stat].
[55] LarsRuddigkeit,RuudvanDeursen,LorenzC.Blum,andJean-LouisReymond. Enumerationof166Billion
OrganicSmallMoleculesintheChemicalUniverseDatabaseGDB-17. JournalofChemicalInformationand
Modeling, 52(11):2864–2875, November 2012. ISSN 1549-9596. doi: 10.1021/ci300415d. URL https:
//doi.org/10.1021/ci300415d. Publisher: AmericanChemicalSociety.
[56] RaghunathanRamakrishnan,PavloO.Dral,MatthiasRupp,andO.AnatolevonLilienfeld. Quantumchemistry
structuresandpropertiesof134kilomolecules. ScientificData,1(1):140022,August2014. ISSN2052-4463.
doi: 10.1038/sdata.2014.22. URLhttps://www.nature.com/articles/sdata201422. Publisher: Nature
PublishingGroup.
[57] SimonAxelrodandRafaelGómez-Bombarelli. GEOM,energy-annotatedmolecularconformationsforproperty
predictionandmoleculargeneration. ScientificData, 9(1):185, April2022. ISSN2052-4463. doi: 10.1038/
s41597-022-01288-4.URLhttps://www.nature.com/articles/s41597-022-01288-4.Publisher:Nature
PublishingGroup.
[58] RDKit. URLhttp://www.rdkit.org/.
[59] MinjieWang,DaZheng,ZihaoYe,QuanGan,MufeiLi,XiangSong,JinjingZhou,ChaoMa,LingfanYu,YuGai,
TianjunXiao,TongHe,GeorgeKarypis,JinyangLi,andZhengZhang. DeepGraphLibrary: AGraph-Centric,
Highly-PerformantPackageforGraphNeuralNetworks,August2020. URLhttp://arxiv.org/abs/1909.
01315. arXiv:1909.01315[cs,stat].
14A Proofthatthesimplexisclosedunderlinearinterpolation
Assumewehaveaccesstotwovectorsonthesimplexa,b ∈ Sd. Wedefineanotherpointcbylinearinterpolation
betweenaandb:
c:=ta+(1−t)b wheret∈[0,1] (17)
Therefore,eachentryofccanbewrittenasc =ta +(1−t)b . Giventhata ,b ≥0bydefinition,c mustalsobe
i i i i i i
positive. Wecanalsowritethethesumoftheentriesofcas:
d d
(cid:88) (cid:88)
c = ta +(1−t)b (18)
i i i
i=1 i=1
d d
(cid:88) (cid:88)
=t a +(1−t) b (19)
i i
i=1 i=1
=t+(1−t)=1 (20)
Wehaveshownthatc ≥ 0and(cid:80)d c = 1. Thereforec ∈ Sd andwecanconcludethatSd isclosedunderlinear
i i=1 i
interpolation.
B Proofthatflowsareonthesimplex
Wewilldefineaflowmatchingmodelforacategoricalvariabley thatcantakeoneofddiscretevalues. Thetarget
distributionfory,p (y)isamixtureofpointmassesontheverticesofSd. Weaddtheconstraintthatp (y)onlyhas
1 0
supportonSd.
Wechooseconditionaltrajectoriesoftheform(7)andacosineinterpolantscheduleoftheform(8). Wetrainaneural
networktominimizetheendpointobjective(12),andasaresultwehaveaccesstoamodelwhichpredictstheendpoint
ofourtrajectorygivenacurrentposition: yˆ (y ).
1 t
Togeneratesamplesfromp (y),wefirstsampley ∼p (y),andintegratetheODE
1 0 0
dy α′
=u (y)= t (yˆ −y ) (21)
dt θ 1−α 1 t
t
IntegrationviaEuler’smethodwouldproducetrajectoriesaccordingto:
y =y +u (y )(s−t) (22)
s t θ t
Wheres=t+∆t. Inordertoprovethatalltrajectoriesproducedbyourvectorfieldlieonthesimplex,itwouldbe
sufficienttoprovethaty ∈Sdinthelimitas∆t→0.
s
Substituting(21)into(22)yieldsthefollowingupdateruleforintegrationbyEuler’smethod:
α′(s−t) 1−α −α′(s−t)
y = t yˆ + t t y (23)
s 1−α 1 1−α t
t t
Relyingonthepropertythatthesimplexisclosedunderlinearinterpolation(AppendixA),ourstrategyistoprove
thatintegratingtrajectoriesvia(23)resultsinrecursiveapplicationsoflinearinterpolationbetweentwopointsonthe
simplex.
More formally, the right hand side of (23) would be linear interpolation between two points on the simplex if the
followingconditionsweresatisfied:
1. α′ t(s−t) + 1−αt−α′ t(s−t) =1
1−αt 1−αt
2. α′ t(s−t) ∈[0,1]
1−αt
153. yˆ (y ),y ∈Sd
1 t t
Thefirstconditionisobviouslytrue.
Thesecondconditioncanbewrittenastwoinequalities0≤ α′ t(s−t) ≤1. Thefirstinequalityreducestoα′ ≥0;the
1−αt t
interpolantmustbemonotonicallyincreasing. Thesecondinequalitycanbeseenasanupperboundonthestepsize
thatcanbeusedduringintegration:
1−α
s−t≤ t (24)
α′
t
Forwell-behavedinterpolantschedulesandmanyreasonablechoicesofinterpolant,thisinequalityissatisfiedinthe
limitass−t→0.
Regardingthethirdcondition: bydefinition,yˆ ∈Sd;thisispracticallyenforcedbyplacingsoftmaxactivationsonthe
1
outputoftheneuralnetwork. Ify ∈Sd,aconditionwhichisguaranteedbyourchoiceofpriorp (y),thenthefirst
0 0
applicationoftheupdaterule(23)wouldsatisfyallthreeconditionsandasaresulty ∈Sd. Byinduction,every
0+∆t
subsequentapplicationoftheupdaterule(23)wouldyieldanintegrationstepthatislinearinterpolationbetweentwo
pointsonthesimplex.
Asaresult,alltrajectoriesgeneratedbytheODEwilllieonthesimplexinthelimitofainfinitelysmallintegrationstep.
And,inpractice,infinitelysmallintegrationstepsarenotactuallynecessarytoyieldtrajectoriesonthesimplex. More
onthisinAppendixC.
C IntepolationSchedulesandIntegrationStepSizes
The relative rates at which molecular features are generated are determined by setting values of the parameter ν
in the cosine interpolant schedule (8). For the QM9 dataset we set ν = (ν ,ν ,ν ,ν ) = (1,2,2,1.5). For the
X A C E
GEOM-Drugsdatasetthisissetto(1,2,2,2). ThesearethesamevaluesusedforthecosinenoisescheduleinVignac
etal.[23]. TheinterpolantschedulesusedfortheQM9datasetareplottedinFigure3.
Figure3: InterpolantSchedulesfortheQM9Dataset
InAppendixBwederiveanupperboundontheintegrationstepsizethatcanbeusedthatguaranteesSimplexFlow
trajectorieswillremainonthesimplex(24). InFigure4weplotthismaximumstepsizeasafunctionoftforfor
cosineinterpolationschedules(8). FortheresultspresentedinthispaperwesamplemoleculesbyperformingEuler
intergrationwith100evenly-spacedintegrationsteps. Thiscorrespondstoaconstantstepsizeof10−2. Accordingto
Figure4,thisstepsizeensurestrajectorieswillremainonthesimplexuntilapproximatelyt=0.98.
16Figure4: Left: maximumintegrationstepsizetoremainonthesimplexforacosineinterpolant. Right: zoomedin
viewoftheasymptoticdeclineofthemaximumstepsizeast→1
D ModelArchitecture
FlowMolisimplementedusingPyTorchandtheDeepGraphLibrary(DGL)[59].
Eachnodeisendowedwithapositioninspacex ∈R3,scalarfeaturess ∈Rd,andvectorfeaturesv ∈Rc×3. Scalar
i i i
featuresareinitializedatthenetworkinputbyconcatenatingatomtypeandchargevectors: s(0) = [a : c ]. Vector
i i i
features are initialized to zeros v(0) = 0. Each edge is endowed with scalar edge features that, at the input to the
i
network,arethebondorderattimet. Weenforcethatthebondorderonbothedgesforapairofatomsisidentical:
e(0) =e(0).
ij ji
MoleculeUpdateBlock WedefineaMoleculeUpdateBlockwhichwillupdateallgraphfeaturesx ,s ,v ,e . Each
i i i ij
moleculeupdateblockiscomprisedof3-subblocks: anodefeatureupdateblock,anodepositionupdateblock,andan
edgefeatureupdateblock. TheinputmoleculegraphispassedthroughLMoleculeUpdateBlocks. Vectorfeaturesare
operatedonbygeometricvectorperceptions(GVPs). AdetaileddescriptionofourimplementationofGVPisprovided
inSectionD.1.
NodeFeatureUpdateBlock Thenodefeatureupdateblockwillperformagraphconvolutiontoupdatenodescalar
andvectorfeaturess ,v . Themessagegeneratingandnode-updatefunctionsforthisgraphconvolutionareeachchains
i i
ofGVPs. GVPsacceptandreturnatupleofscalarandvectorfeatures. Therefore,scalarandvectormessagesm(s)
i→j
andm(v) aregeneratedbyasinglefunctionψ whichistwoGVPschainedtogether.
i→j M
(cid:32)
(cid:104) (cid:105)
(cid:34) x(l)−x(l)(cid:35)(cid:33)
m(s) ,m(v) =ψ s(l) :e(l) :d(l) , v : i j (25)
i→j i→j M i ij ij i d(l)
ij
Where:denotesconcatenation,andd isthedistancebetweennodesiandj atmoleculeupdateblockl. Inpractice,
ij
wereplaceallinstancesofd witharadialbasisembeddingofthatdistancebeforepassingthroughGVPsorMLPs.
ij
Messageaggregationandnodefeaturesupdatesareperformedasdescribedin[53]:
  
s( il+1),v i(l+1) =LayerNorm[s( il),v i(l)]+ψ U |N1
(i)|
(cid:88) (cid:104) m( js →) i,m( jv →) i(cid:105)  (26)
j∈N(i)
Thenodeupdatefunctionψ isachainofthreeGVPs.
U
NodePositionUpdateBlock Thepurposeofthisblockistoupdatenodepositionsx . Nodepositionsareupdatedas
i
follows:
17(cid:16) (cid:17)
x(l+1) =x(l)+ψ s(l+1),v(l+1) (27)
i i x i i
WhereP isachainof3GVPsinwhichthefinalGVPemits1vectorand0scalarfeatures. MoreoverforthefinalGVP,
thevector-gatingactivationfunction(σ inAlgorithm1),whichistypicallyasigmoidfunction,isreplacedwiththe
g
identity.
EdgeFeatureUpdateBlock Edgefeaturesareupdatedbythefollowingequation:
(cid:16) (cid:16) (cid:17)(cid:17)
e(l+1) =LayerNorm e(l)+ϕ s(l+1),s(l+1),d(l+1) (28)
ij ij e i j ij
Whereϕ isashallowMLPthatacceptsasinputthenodescalarfeaturesofnodesparticipatingintheedgeaswellas
e
thedistancebetweenthenodesfromthepositionscomputeintheNPUblock.
D.1 GVPwithCrossProduct
A geometric vector perception (GVP) can be thought of as a single-layer neural network that applies linear and
point-wise non-linear transformation to its inputs. The difference between GVP and a conventional feed-forward
neuralnetworkisthatGVPsoperateontwodistinctdatatypes: scalarsandvectors. GVPalsoallowsthesedatatypes
toexchangeinformationwhilepreservingequivarianceoftheoutputvectors. TheoriginalGVPonlyappliedlinear
transformationstothevectorfeaturesandasaresultproducesoutputvectorsthatareE(3)-equivariant.
WeintroduceamodificationtotheGVPasitspresentedinJingetal.[53];specificallyweperformacrossproduct
operationontheinputvectors. Themotivationforthisisthatthecrossproductisnotequivarianttoreflections. Asa
result,theversionofGVPwepresenthereisSE(3)equivariant. TheoperationsforourcrossproductenhancedGVP
aredescribedinAlgorithm1.
Algorithm1GeometricVectorPerceptronwithCrossProduct
Input: Scalarandvectorfeatures: (s,v)∈Rf ×Rν×3
Output: Scalarandvectorfeatures: (s′,v′)∈Rj ×Rµ×3
Hyperparameter: Numberofhiddenvectorfeaturesn ∈Z+
h
Hyperparameter: Numberofcrossproductfeaturesn ∈Z+
cp
v
h
←W hv ∈Rnh×3
v
cp
←W cpv ∈R2ncp×3
v
cp
←v cp[:n cp]×v cp[n
cp
:] ∈Rncp×3//crossproduct
v
h+cp
←Concat(v h,v cp) ∈R(nh+ncp)×3//concatenationalongrows
v ←W v ∈Rµ×3
µ µ h+cp
s
h+cp
←∥v h+cp∥ ∈Rnh+ncp
s ←Concat(s,s )’
f+h+cp h+cp
s ←W s +b ∈Rj
j j f+h+cp j
s′ ←σ(s ) ∈Rj
j
v′ ←σ (W [σ+(s )]+b )⊙v (row-wise) ∈Rµ×3
g g m g µ
return(s′,v′)
18E ModelAblationsonGEOMDataset
Table3: FlowMolablationsonGEOM-Drugswithexplicithydrogens
AtomsStable MolsStable MolsValid JS(E)
FlowType CategoricalPrior
(%)(↑) (%)(↑) (%)(↑) (↓)
Dirichlet uniform-simplex 94.6±0.2 18.7±0.2 14.0±1.4 0.46±0.01
endpoint marginal-simplex 97.7±0.0 36.3±0.1 28.3±0.3 0.36±0.01
barycenter 97.6±0.0 35.2±0.4 27.6±0.5 0.30±0.01
Gaussian 98.9±0.0 66.3±1.2 49.9±1.0 0.34±0.01
F TrainingDetailsandHyperparameterChoices
QM9modelsaretrainedwith8MoleculeUpdateBlockswhileGEOMmodelsaretrainedwith5. Atomscontain256
hiddenscalarfeaturesand16hiddenvectorfeatures. Edgescontain128hiddenfeatures. QM9modelsaretrainedfor
1000epochsandGEOMmodelsaretrainedfor20epochs. QM9modelsaretrainedonasingleL40GPUwithabatch
sizeof64. GEOMmodelsaretrainedon4xL40GPUswithaper-GPUbatchsizeof16. QM9modelstraininabout3-4
dayswhileGEOMmodelstake4-5days. Allmodelhyperparametersarevisibleintheconfigfilesprovidedinour
githubrepository.
19