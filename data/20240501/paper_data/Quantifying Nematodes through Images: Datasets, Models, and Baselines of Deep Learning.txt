Quantifying Nematodes through Images: Datasets,
Models, and Baselines of Deep Learning
Zhipeng Yuan Nasamu Musa Katarzyna Dybal
Department of Computer Science Soils, Crops and Water Agriculture and Environment Department
University of Sheffield RSK ADAS Ltd High Mowthorpe Harper Adams University
Sheffield, The United Kingdom Malton, The United Kingdom Newport, The United Kingdom
zhipeng.yuan@sheffield.ac.uk nasamu.musa@adas.co.uk kdybal@harper-adams.ac.uk
Matthew Back Daniel Leybourne Po Yang
Agriculture and Environment Department Department of Evolution, Ecology and Behaviour Department of Computer Science
Harper Adams University University of Liverpool University of Sheffield
Newport, The United Kingdom Liverpool, The United Kingdom Sheffield, United Kingdom
mback@harper-adams.ac.uk Daniel.Leybourne@liverpool.ac.uk po.yang@sheffield.ac.uk
Abstract—Every year, plant parasitic nematodes, one of the ysis [7] and mass spectrometry [8] to identify the nema-
majorgroupsofplantpathogens,causeasignificantlossofcrops tode species by protein fingerprints of different nematode
worldwide.Tomitigatecropyieldlossescausedbynematodes,an
species. In contrast, molecular diagnostics focus on the DNA
efficient nematode monitoring method is essential for plant and
characteristics of different species of nematodes, which are
crop disease management. In other respects, efficient nematode
detection contributes to medical research and drug discovery, as detected by PCR technologies [9] or isothermal amplification
nematodes are model organisms. With the rapid development of technologies [10]. Although some studies [11] have been
computer technology, computer vision techniques provide a fea- devoted to providing time-saving and efficient sampling and
sible solution for quantifying nematodes or nematode infections.
detection methods for nematode detection in the field, there
Inthispaper,wesurveyandcategorisethestudiesandavailable
is still a gap between aforementioned detection methods and
datasets on nematode detection through deep-learning models.
To stimulate progress in related research, this survey presents low-cost nematode detection methods.
the potential state-of-the-art object detection models, training The recent employment of computer technology stimulates
techniques, optimisation techniques, and evaluation metrics for the development of pest and disease management in precision
deep learning beginners. Moreover, seven state-of-the-art object
agriculture and provides new solutions for low-cost nematode
detection models are validated on three public datasets and the
detection methods based on image analysis. In particular, the
AgriNema dataset for plant parasitic nematodes to construct a
baseline for nematode detection. ability of deep learning models to automatically extract visual
Index Terms—Deep learning, Object detection, Nematode de- features facilitates the recognition of tiny objects in complex
tection, Image analysis image backgrounds [12]. Therefore, deep learning models
are able to detect nematodes from microscope images [13]
I. INTRODUCTION or images from high magnification cameras [14]. Compared
to the aforementioned methods and traditional morphological
Plant parasitic nematodes are one of the major groups of
visualdetectionmethods,deeplearningmodelsdonotrequire
plant pathogens causing crop and plant diseases [1], which
extensive substantial expertise and training for end users
seriously impact food security and production losses. Specif-
and avoid subjective judgement [15]. Although deep learning
ically, the parasitic of nematodes accounts for over 10% of
technology is gradually being applied to nematode detection
annual crop losses and cost roughly 100 billion U.S. dollars
tasks, there is still a lack of accurate and robust detection
worldwide [2] [3]. This means that timely plant-parasitic
models due to the need for annotated training data and the
nematode detection is necessary to address the increased food
challenge of designing optimal model structures for nematode
demand caused by population growth estimated [4].
detection tasks.
To meet these challenges, a series of studies have been
As a consequence, there is an urgent need for more efforts
proposed to detect vermiform adult nematodes and cysts
todeveloplow-costnematodedetectionmodels,especiallyfor
(deceased female nematodes carrying eggs) of nematodes [5].
cystsdetectionintheearlystagetomitigateyieldlossescaused
Techniques of nematode detection have been categorised as
by nematodes. To facilitate research on deep learning-based
biochemical detection and molecular diagnostics [6]. Specifi-
nematode detection models, a comprehensive survey of deep
cally, biochemical detection methods include isoenzyme anal-
learning-based object detection models with corresponding
baselines for the nematode detection task is necessary.
ThisworkissupportedbyBiotechnologyandBiologicalSciencesResearch
CouncilwithprojectnumberBB/X01200X/1. The main contribution of this review is to construct a
4202
rpA
03
]VC.sc[
1v84791.4042:viXracomprehensive baseline for state-of-the-art object detection strategiesforthesearchresultsofthetwosearchkeywords.For
models in the nematode detection tasks to facilitate research the search results of nematode detection studies, this review
on deep learning-based nematode detection solutions. The focuses on whether these studies describe the methods and
baselinecoverstheperformanceofsevenstate-of-the-artobject results clearly. Meanwhile, the studies on object detection
detection models on three public nematode datasets and a models are selected through the reproducibility of the work,
dataset constructed for crop parasitic nematode detection. especially whether the code and data are available. Therefore,
Meanwhile, this review not only presents a survey of relevant the number of forks and stars of the corresponding code
studies,butalsoclassifiesanddiscussesfeasibledeeplearning- repository is the main quantification metric. Methods, where
based detection models, training tricks, evaluation metrics, thesumofforksandstarsdoesnotexceedthreethousand,are
and available datasets for the nematode detection task in filtered.
order to guide deep learning beginners in exploring nematode
detection tasks. In addition, a discussion of challenges and
III. DEEPLEARNINGINNEMATODEDETECTION
model optimisation directions for the nematode detection task To the best of our knowledge, this is the first review
is attached to expose the flaws of current research. that focuses exclusively on nematode and cysts detection
in agriculture through deep-learning technology. Related to
II. METHODOLOGY
the nematode detection, 19 loop-mediated isothermal ampli-
Themethodologicaldesignforthisreviewincludesresearch fication assays [10] were investigated, while the relationship
questions, search strategy, and study selection criteria. The between nematode and crop and management practices were
definition of research questions describes the need and mo- discussed[16].Inaddition,surveysfocusingonspecificcrops
tivation for this review. Therefore, the development of the [17] [18] or nematode species [19] were proposed.
search strategy and selection criteria is influenced by research
In this section, we present the review results for the studies
questions.
of nematode detection and potential object detection tech-
Compared to other techniques, deep learning models have
nologies that contribute to answering the five corresponding
presentedunexpectedaccuracyincomputervisiontasksdueto
secondary questions in this review.
their ability to learn visual features automatically. Therefore,
exploring the feasibility of vision-based deep neural networks A. SQ1 - Deep Learning in Nematode Detection
on the nematode detection task has drawn the attention of Toanswerthisquestion,thisworksearches163publications
researchers. The main research question that the review is from 5 data sources and filters out literature reviews [40],
concerned with and attempts to answer is ”How can deep non-deep learning methods [41], and non-nematode detection
neural networks solve the challenge of low-cost nematode
studies [42] based on the selection strategy. Due to the need
detection?”. Moreover, a set of secondary research questions for data for deep learning and the difficulty of obtaining
are defined to answer the main research question, namely, annotations,19studiesareextractedaseffectivedeeplearning-
• SQ1-Whatdeeplearningmethodshavebeenusedinthe based nematode detection methods. The investigated studies
nematode detection task? are divided into two groups, namely, direct and indirect
• SQ2 - What are the available datasets? detection of nematodes. Direct detection methods rely on
• SQ3 - What are the state-of-the-art object detection nematode morphological characteristics to classify [21] or
models? count[27]nematodesdirectlyfrommicroscope[25]orcamera
• SQ4 - What are the methods for model training and images[14]ofnematodesamples.Indirectnematodedetection
optimisation? methods analyse the crop leaves [33] and infected parts [26]
• SQ5 - What are the metrics for model evaluation? of nematodes by multispectral [20] or camera [30] images.
The search strategy focuses on digital scientific databases The direct detection methods translate the nematode de-
including Google Scholar, IEEE Xplore Digital Libray, ACM tection task into different computer tasks including image
Library, Elsevier Scopus, and Springer Link. Meanwhile, classification [21], object detection [37], segmentation [28],
search keywords are defined as the following generic string, and instance segmentation [31], depending on the purpose of
(”deeplearning”OR”deepneuralnetwork”OR”convolutional the study. The image classification models focus on assigning
neural network” OR ”object detection”) AND (”nematode corresponding labels to individual image inputs. Therefore, a
detection”). Whilst the above search keywords are able to web application integrated a CNN [21] provided five feeding
identifyresearchrelevanttonematodedetection,thesecondary typelabelsthroughalocalmicroscopeimage,suchasthehead
questions about potential object detection models are not ade- or tail of a nematode. Meanwhile, a comparative analysis of
quately presented by the search results. Therefore, the second CNN[24]fornematodeclassificationwasdoneunderasimilar
search keywords are defined as follows, (”deep learning” OR setup asthe above work.The optimal model,CoAtNet-0, out-
”deep neural network” OR ”convolutional neural network”) performed the other 14 models and obtained an average type
AND (”object detection”). accuracy of 97.86% over an F1 score of 0.9803 [24]. Object
Since deep learning is a relatively new technique, studies detection models draw bounding boxes and assign labels to
from the previous ten years (from 2014 to 2023) are selected objects of interest in one input image. For example, Faster
in the research results. This work uses different selection RCNN was used to detect plant-parasitic and non-parasiticTABLEI
DETAILSOFARTICLESFORNEMATODEDETECTION
Article TypeofDetection Models/Algorithms Tasktype TypeofInput Num.ofClassification EvaluationMetrics
[20] IndirectDetection YOLOv5 ObjectDetection Multispectral;Visible 2 mAP;DetectionSpeed
[21] DirectDetection CNN Classification Microscope 19 Accuracy
[22] DirectDetection Attention-UNet Segmentation Microscope - Accuracy
[23] DirectDetection Xceptionmodel Classification Microscope 40 Accuracy
[24] DirectDetection CNN Classification Microscope 11 F1;Precision;Recall
[25] DirectDetection MaskR-CNN ISegmentation Microscope 1 Precision
[26] IndirectDetection YOLOv5-CMS ObjectDetection Visible 1 mAP
[27] DirectDetection SEM-RCNN ObjectDetection Microscope 21 mAP
[28] DirectDetection SegNema Segmentation Microscope 13 Accuracy
[29] IndirectDetection DNN;SVM;RF;DT Classification Reflectance 4 Accuracy
[30] IndirectDetection VDNet Segmentation Visible 1 Accuracy
[31] DirectDetection CNN;Canny ISegmentation Microscope 1 Precision;Recall
[32] IndirectDetection CNN;SVM Classification Visible 4 Accuracy;F1
[33] IndirectDetection UNet Segmentation Visible 3 Precision;Recall;F1
[34] DirectDetection GoogleNet;AlexNet Classification Microscope 3 AUC
[35] DirectDetection CNN Regression Microscope - Accuracy
[36] DirectDetection LSTM Classification Timeseries - Accuracy
[37] DirectDetection FasterRCNN ObjectDetection Microscope 2 Accuracy
[38] DirectDetection CNN ObjectDetection Microscope 2 Accuracy
[39] DirectDetection CNN Classification Microscope 5 Accuracy
Visible:RGBimages;mAP:MeanAveragePrecision;CNN:ConvolutionalNeuralNetwork;F1:F1scores;ISegmentation:InstanceSegmentation;
DNN:DeepNeuralNetwork;SVM:Supportvectormachines;RF:RandomForest;DT:DecisionTree;Canny:CannyEdgeDetector;
AUC:Areaunderthereceiveroperatingcharacteristiccurve;LSTM:Longshort-termmemory
nematodes from microscope images and achieved 87.5% ac- the reflectance of radio frequencies of leaves was evaluated
curacy [37]. Moreover, SEM-RCNN [27] was proposed to in a case study on walnuts [29] where nematode infection
detectmultipleclassesofmicroorganismsunderenvironmental levels were categorised into four levels. A modified VGG-16
microorganisms. Compared to the object detection task, the network,VDNet[30],achieved86%accuracyindetectingpint
segmentation task draws the edges of objects of interest more wilt trees caused by nematodes via drone imagery. Similar
accurately. In other words, the segmentation model assigns a work was done on coffee crops to detect nematode-infected
label to each pixel in the image to classify the image region. crops by the UNet model [33]. With the development of
A modified UNet model was used to segment nematodes in multispectralsensors,multispectralimageswereutilisedinthe
digital microscopy images [28] with nearly three thousand detection of pine wilt disease and 98.7% mAP was obtained
manually labelled images. Attention mask [22] was used to with the assistance of YOLOv5 model [20]. In addition, a
improve the nematode segmentation accuracy of UNet in study [32] for plant diseases in citrus crops used a model
microscopy images. However, a limitation of segmentation structure combining CNN and SVM to classify nine crop
models is the inability to distinguish between instances of diseases by individual plant leaves. A study of root-knot
thesamecategorisedobject,especiallywheninstancesoverlap nematodes(Meloidogyne)detectionincucumber[26]detected
or are connected. Therefore, instance segmentation models sites of nematode infection and assess disease severity for
are proposed to address this challenge. For example, Mask selection of resistant cucumber varieties through a modified
RCNN [25] combined an object detection model with a YOLOv5 and RGB images collected from an experimental
segmentation model to assign pixel-level taxonomic labels environment.
and mark individual instances of the Caenorhabditis elegans
(C. elegans) nematode under low magnification microscopy. Several studies have explored the feasibility of predicting
Due to the visual characteristics of nematode objects, a study nematode developmental stages [35] and nematode activity
[31] detected the skeletal position of potato cyst nematodes [36] to assist with the studies of plant infection resistance
by CNN and mapped nematode segmentation templates in genes and drug discovery. Specifically, CNN was utilised to
microscope images by a Canny edge detector. accurately measure the physiological age of C. elegans on the
scale of days and achieved 88.92% accuracy for anti-ageing
For indirect detection, most research [20] [43] [33] was drugscreeningandgeneticscreeningstudies[35].Thestudyof
devoted to detecting nematode infection or plant diseases automatic recognition of nematode behavioural patterns [36]
caused by nematodes at large scales through drone or aerial extracted four interpretable features from a correlation matrix
imagery.Forexample,theeffectivenessofsixdifferentclassi- describingnematodeshapetodefinenematodemotivationand
fication algorithms, including Neural Networks, Support Vec- achieved 73.49% accuracy in a five classification task through
tor Machine, Random Forest, AdaBoost, Nearest Neighbors, LSTMtoassistwiththestudyofneurologicalfunction,genetic
and Decision Tree for detecting nematode infection levels by variation, and motor sensation.I-Nema Nema BBBC010 C. elegans Microorganism
Fig.1. Examplesfrompublicdatasets.
TABLEII important milestone detectors, detection datasets, evaluation
DETAILSOFPUBLICIMAGEDATASETSFORNEMATODES metrics,andoptimisationmethods.Meanwhile,anotherlitera-
turesurvey[50]focusedonthedescriptionofthemethodology
Dataset Images Types Classification
I-Nema[23] 9,215 Classification 40 covering more than 300 works and summarised the detection
Nema[39] 3,063 Classification 5 framework, object feature representation, proposal generation,
C.elegans[25] 1,908 ISegmentation 1
etc.
BBBC010[46] 100 ISegmentation 2
Microorganism[47] 498 ISegmentation 1 According to the structures of the object detection model
and their functions, the popular deep learning-based object
detection models are categorised as one-stage stage and two-
stage detectors. The significant difference between the two
Inadditiontodeeplearning-basedmethods,sometraditional
types of models is the presence or absence of a structure to
methods of computer vision [44], such as energy-based seg-
generate proposals in the middle of the inference process, as
mentation [41] and superpixel segmentation [45] have also
showninFigure2.Theproposalreferstoboundingboxesthat
been used in nematode detection tasks to alleviate the data
need to be further optimised.
dependency of deep learning.
Models with proposal-generating structures are referred to
B. SQ2 - Public Datasets as two-stage detectors. Popular two-stage detectors include
RCNN [51], Fast RCNN [52], and Faster RCNN [53]. The
Constructing datasets that have the same data distribution
region-based convolutional neural network, RCNN [51], is an
as real-world application scenarios is crucial for training deep
early form of object detection model based on deep learning,
neuralnetworks.However,therearelimitedpubliclyavailable
incorporatingsomeofthestructureandmethodsoftraditional
nematode detection datasets identified in the literature survey
object detection methods, such as selective search for region
duetothecostofdatacollectionanddatalabelling.Thelargest
proposals and SVM for classification. Since CNNs need to
available public dataset [23] of microscopic nematode im-
processthousandsofregionproposalsinRCNN,thedetection
ages provided over 9,000 images for classification tasks. The
efficiency is lower compared to current detection models. The
images showed details of nematodes at large magnifications.
subsequentlyproposedFastRCNN[52]andFasterRCNN[53]
In contrast, the C. elegans nematode dataset [25] provided
are dedicated to solving this problem. Fast RCNN [52] used
complete images under the microscope. Table II and Figure 1
RoI projection to map the feature maps of the neural network
show the details of these datasets.
ontotheinputimage,thusreducingrepetitivecomputationand
using fully connected layers instead of SVMs. Faster RCNN
IV. OBJECTDETECTIONMODEL
[53] combined with the region proposal network to generate
A. SQ3 - Object Detection Models Based on Deep Learning
region proposals achieved faster detection and 42.7% mAP
In the survey of current nematode detection research, four on the coco dataset. Faster RCNN was considered the most
computer vision tasks are identified, including classification, accurate object detection model for a long time.
object detection, segmentation, and instance segmentation. In contrast, common one-stage models have the advantage
Among them, object detection and instance segmentation of faster detection speed and lighter model size including
models have the potential in achieving the quantification of the YOLO [48] model family, CenterNet [54], and DETR
nematodes in images. However, since instance segmentation [55]. With a large number of training techniques and better
models require additional algorithms to calculate the number model substructures proposed, the YOLOv5 [56] achieved
of different instances and rely on object detection models similar accuracy to Faster RCNN. The one-stage model does
fromamodeldesignperspective,thissurveyfocusesonobject not require any structure for generating regional proposals.
detection models. The three types of one-stage models have different structures.
Object detection is a classical task in the field of computer In addition to data pre-processing and post-processing, the
vision therefore a large number of relevant literature reviews modelsofYOLOhavethreecomponents,includingthefeature
are identified during literature search processing. For exam- extractionnetwork,theneckandthedetectionhead.Advances
ple, a literature review [49] comprehensively surveyed over in the YOLO family of models focus on the optimisation
20 years of research on object detection methods, covering of model substructures such as decoupled heads [57] andFeature extraction network
CCBBSS CCBBSS CCBBSS CCBBSS EELLAANN MMPP11 EELLAANN MMPP11 EELLAANN MMPP11 EELLAANN
CBS Detection neck CBS SPPCSPC CAT ELAN-H RREEPP CCOONNVV
Detection head Output
CAT UP ELAN-H CAT UP MP2 NMS
IInnppuutt IImmaaggeess ELAN-H MP2 CAT ELAN-H RREEPP CCOONNVV
RREEPP CCOONNVV
One-stage detector: YOLOv7 Structure
Bounding box
VGGNet-16 RoI Pooling FC FC
IInnppuutt IImmaaggeess CONV CONV Reshape Softmax Reshape FC Softmax Class
Region proposal network
CONV
Two-stage detector: Faster RCNN
Fig.2. ModelStructuresofObjectDetectionModel.CBS,ELAN,MP1,MP2,ELAN-H,andSPPCSPCarethecompositemodelstructureinYOLOv7[48].
CONV,NMS,Reshape,andFCareconvolutionalnetworkmoduleswithpoolingmodules,non-maximumsuppression,reshapemodules,andfullconnection
modules,respectively.
ELAN structures [48]. CenterNet [54] did not have a neck Forclassificationloss,thedifferencebetweenobjectdetection
structure and achieved an average precision of 45.1% on tasks and classification tasks lies in the assignment of clas-
the COCO dataset [58]. In contrast to the aforementioned sification probabilities. The predicted bounding box without
models, DETR [55] was a transformer-based object detection objects of interest is defined as negative samples assigning
model that solved the problem of hyperparameters setting for 0 as classification probability. The presence of an object
pre-processing and post-processing. However, DETR used a is measured by the intersection-over-union (IoU) between
large number of model parameters in exchange for improved prediction and ground truth. Meanwhile, IoU and its variants
accuracy. As a result, YOLOv5 remains the most popular were used in many studies to compute the confidence in the
model in GitHub according to the number of stars. Currently, presenceofobjects[56].Thelossfunctionforboundingboxes
one-stageobjectdetectionmodelsarestillactiveresearchareas is used to optimise the position and size of the bounding box.
andnewstudiesareconstantlybeingproposed,suchasYOLO- In additionto theabove IoU with its variants,the L1[51] and
NAS using network structure search. L2[59]lossfunctionswereusedtooptimisetheboundingbox
withrespecttofourvariablesincludingcentrelocation,width,
B. SQ4 - Model Training and Optimisation Technologies
and height.
In addition to the structure of the object detection model,
Data augmentation is widely used in the field of deep
the training and optimisation techniques of the model have a
learning to compensate for data deficiencies and enhance
significant impact on the performance of the object detection
modelrobustnessbyextendingtrainingdatasetswithsynthetic
model. Common training techniques and optimisation tech-
data. In computer vision tasks, data augmentation methods
niquesincludelossfunctions,dataaugmentation,trainingaux-
express invariants in the task, such as scale invariance and
iliaryhead,modelquantisation,andmodelreparameterisation.
rotational invariance. For object detection tasks, the annota-
The loss function is a necessary component for training
tions of bounding boxes are adjusted following the data aug-
deep learning models. The loss functions are defined differ-
mentation methods. Widely used data augmentation methods
ently according to the definition of post-processing in object
includeimageflipping,imagecropping,imagerotation,image
detection models. This review summarises a generic form of
translation, colour space transformations, and mosaics. The
loss functions for object detection models as
colour space transformations consist of global adjustments
Loss(p,p∗,t,t∗)=L cls(p,p∗)+βL box(t,t∗), (1) to transparency, saturation, hue and value. Meanwhile, the
implementations of Mosaic have a variety of methods in-
where L , L , p, p∗, t, and t∗ are the loss function for
cls box
cluding merging multiple images with or without overlapping
classification, loss function for bounding boxes, prediction
and merging multiple images with transparency adjusting or
of classification, ground truth of classification, prediction of
cropping.
bounding boxes, and ground truth of bounding box. The
classification loss functions in the object detection tasks are Meanwhile, the auxiliary head as a new deep supervision
similar to the loss functions in the classification task using technique improves the accuracy of the model by adding aux-
mean square error [59], L2 loss, or cross-entropy loss [53] to iliary loss guidance during the model training phase. Specifi-
measure differences in probability distributions. In addition, cally,coarse-to-fineauxiliaryheadsupervisionwasusedinthe
focal loss is able to solve the problem of data imbalance. study of YOLOv7 [48] to balance the number of positive andnegative samples in the object detection task. Earlier studies
of object detection models were just labelled with bounding
boxesofgroundtruth,sotherewerealargenumberofnegative
sampleboundingboxesinanimage.Toalleviatethisproblem,
theauxiliaryheadwiththesamestructureasthedetectionhead
Ditylenchus spp. Pratylenchus spp. Globodera spp.
is added to the model during model training. For assigning
samples, more positive samples are assigned as coarse labels
totheauxiliaryheadbasedontheIoUforgroundtruth,which
reduces the difficulty of models to learn the object features.
Inadditiontotheimprovementofaccuracy,objectdetection
Meloidogyne hapla Globodera pallida (J2)
speed and model size have been the focus of attention in
the research. Model quantisation and reparameterisation [48] Fig.3. ExamplesfromAgriNemaDataset.
for CNN are two effective ways to reduce model size in
addition to model structure optimisation. Model quantisation
V. EXPERIMENTSANDBASELINE
reduces memory usage, hard disk usage, and computational
While a number of object detection models have been
consumption by converting the float-point type of model
appliedtonematodedetectiontasks,theseeffortslackcompar-
parameterstosmallertypesofmodelparameters.Inthestudies
ison with baseline models due to the rapid growth in the field
of object detection, post-training quantization [57] was used
of object detection models. Therefore, this work compares
to obtain a lighter model at the cost of accuracy. In addition,
seven object detection models on four nematode datasets.
model reparameterisation for CNN relies on the mathemati-
cally equivalent properties of convolutional computation. In A. Experiment Setup
other words, the jump-link structure that is widely used in
In this study, the mAP with an IoU threshold of 0.5 is
CNNscanbeequivalentlyconvertedintoasimpleconvolution
used to evaluate the accuracy of object detection models.
operation during computation. Therefore, YOLOv7 [48] con-
Meanwhile, the validated object detection models use the
siders reparameterisation in the model structure design stage
same training settings as the original work to improve the
and transforms the complex structure of the model into a
reproducibility of this work, which means the training tricks
simple chained CNN after training to obtain a lighter model
including data augmentation and auxiliary head are used
with a faster detection speed.
duringtraining.Thisbaselineisconstructedforthelightweight
model. Therefore, the smallest model structure settings from
C. SQ5 - Evaluation Metrics
theoriginalworksareusedinourwork,suchasFasterRCNN
The positive and negative samples of the detection results
withVGG[53],YOLOv7tiny[48],andDETRwithResNet50
need to be defined for evaluating the performance of object
[55].Allthemodelsaretrainedin400epochswithpre-trained
detection models. The common definition uses the IoU value
weights.
between the predicted bounding box and the ground truth
The annotations of public instance segmentation nematode
to determine positive and negative samples. The predicted
datasets are converted to object detection annotations. In
bounding boxes with a large IoU value are defined as positive
addition to public datasets, this work constructs a nematode
samples marking most of the area of the object of interest. A
detection dataset, AgriNema, to stimulate the application of
common threshold is 0.5. After defining positive and negative
nematode detection in agriculture. The AgriNema dataset
samples, the precision and recall of object detection models
including 525 images collected from microscopy is used
are defined as
to evaluate object detection models for Meloidogyne hapla,
Precision(c)= TP c , (2) Globodera pallida, Pratylenchus, Ditylenchus, and cyst of
TP c+FP c nematodes. Figure 3 presents the images from the AgriNema
Recall(c)= TP c , (3) dataset. All the datasets for evaluation are partitioned into a
TP +FN trainingset,validationset,andtestingsetintheratioof8:1:1.
c c
where TP c, FP c, and FN c are the number of true positive B. Baseline for Nematode Detection
samples, false positive samples, and false negative samples
Table III presents the mAP0.5 of 7 object detection models
for class c, respectively. The mean average precision (mAP)
on4nematodedetectiondatasets,whereYOLOv6outperform
isdefinedastheaverageareaunderthePrecision-Recallcurve,
other models on AgriNema with 96.53% mAP. The perfor-
1 (cid:88)(cid:90) 1 manceofthemodelsvariesondifferentdatasetsduetomodel
mAP = Precision(c)dRecall(c), (4)
and dataset characteristics. Specifically, the performance of
C
c∈C 0 Faster RCNN drops significantly on the tiny object C.elegans
where C is the set of categories in the task. In addition to dataset due to the lack of a pyramid aggregation network for
the detection accuracy, the size of the model and the speed of fusing multi-layer features. The DETR model as an end-to-
detection as the performance are evaluated by the number of end object detection model avoids the object detection post-
parameters and Frames per second (FPS). processing setting at the cost of model weights. Therefore,TABLEIII efficient solution for nematode detection. Finally, a generic
MEANAVERAGEPRECISIONOFOBJECTDETECTIONMODELS challenge for deep learning is the lack of interpretability,
which hinders the application of methods in industry. Thus
Models AgriNema C.elegans BBBC010 Micro.
FasterRCNN 81.27% 19.8% 79.97% 86.29% exposing the reasons for the classification of the object of
YOLOv5 95.6% 93.1% 85.6% 90.4% interest facilitates the review of model results.
YOLOX 53.75% 91.26% 36.54% 75.8%
YOLOv6 96.53% 84.75% 90.31% 89.27% REFERENCES
YOLOv7 53.9% 35.7% 79.7% 22.2%
YOLOv8 94.5% 84.9% 89% 88.1% [1] S.Savary,L.Willocquet,S.J.Pethybridge,P.Esker,N.McRoberts,and
DETR 86.1% 56.1% 72.3% 16.1% A. Nelson, “The global burden of pathogens and pests on major food
C.elegans:C.elegansdataset[25];BBBC010:BBBC010dataset[46]; crops,”Natureecology&evolution,vol.3,no.3,pp.430–439,2019.
Micro.:Microorganism[47] [2] P. Abad, J. Gouzy, J.-M. Aury, P. Castagnone-Sereno, E. G. Danchin,
E. Deleury, L. Perfus-Barbeoch, V. Anthouard, F. Artiguenave, V. C.
Blok, et al., “Genome sequence of the metazoan plant-parasitic ne-
matode meloidogyne incognita,” Nature biotechnology, vol. 26, no. 8,
DETR has no accuracy advantage, especially for the Mi- pp.909–915,2008.
[3] Z.Yuan,S.Li,R.Peng,D.Leybourne,P.Yang,andY.Li,“Pestdss:An
croorganism dataset with a more complex image background
integrateddecisionsupportsystemforsustainablepestmanagementin
using different devices for image collection. The significant agriculture,”in2023IEEE32ndInternationalSymposiumonIndustrial
difference between the YOLO series models lies in the model Electronics(ISIE),pp.1–6,IEEE,2023.
backbone network and a large number of training techniques. [4] O.Duboisetal.,Thestateoftheworld’slandandwaterresourcesfor
foodandagriculture:managingsystemsatrisk. Earthscan,2011.
In addition to the impact of model structure, data preprocess-
[5] S. Eves-van den Akker, C. J. Lilley, A. Reid, J. Pickup, E. Anderson,
ing also affects the performance of YOLOv7. P. J. Cock, M. Blaxter, P. E. Urwin, J. T. Jones, and V. C. Blok, “A
metageneticapproachtodeterminethediversityanddistributionofcyst
VI. DISCUSSIONSANDCONCLUSIONS nematodes at the level of the country, the field and the individual,”
MolecularEcology,vol.24,no.23,pp.5842–5851,2015.
In the last decade, deep learning-based object detection
[6] H. Shao, P. Zhang, D. Peng, W. Huang, L.-a. Kong, C. Li, E. Liu,
models have made impressive progress and have been applied andH.Peng,“Currentadvancesintheidentificationofplantnematode
in the field of nematode detection. This survey not only diseases: From lab assays to in-field diagnostics,” Frontiers in Plant
Science,vol.14,p.1106784,2023.
reviews the work using deep learning to detect nematodes
[7] R. Carneiro, F. S. d. O. Lima, and V. R. Correia, “Methods and
through images and available datasets in the last 10 years, toolscurrentlyusedfortheidentificationofplantparasiticnematodes,”
but also exposes potential object detection models, training, Nematology-Concepts,DiagnosisandControl,vol.19,2017.
[8] A. Vega-Ru´a, N. Page`s, A. Fontaine, C. Nuccio, L. Hery, D. Goindin,
and optimisation techniques by presenting the widely noticed
J.Gustave,andL.Almeras,“Improvementofmosquitoidentificationby
workinthefieldofobjectdetection.Moreover,theAgriNema maldi-tof ms biotyping using protein signatures from two body parts,”
dataset is constructed for the study of nematode detection Parasites&Vectors,vol.11,pp.1–12,2018.
[9] M.M.Sikder,M.Vesterga˚rd,R.Sapkota,T.Kyndt,andM.Nicolaisen,
methods in agriculture. Meanwhile, a baseline is constructed
“Anovelmetabarcodingstrategyforstudyingnematodecommunities,”
includingtheperformanceof7state-of-the-artobjectdetection bioRxiv,pp.2020–01,2020.
models on 4 microscope image datasets to stimulate progress [10] A.AhujaandV.S.Somvanshi,“Diagnosisofplant-parasiticnematodes
using loop-mediated isothermal amplification (lamp): A review,” Crop
in related research.
Protection,vol.147,p.105459,2021.
Based on the literature survey and the construction of a [11] H.Shao,J.Jian,D.Peng,K.Yao,S.Abdulsalam,W.Huang,L.Kong,
baseline of nematode detection methods, a set of challenges C. Li, and H. Peng, “Recombinase polymerase amplification coupled
with crispr-cas12a technology for rapid and highly sensitive detection
for the research of deep learning-based nematode detection
ofheteroderaavenaeandheteroderafilipjevi,”PlantDisease,vol.107,
are identified. For the nematode detection task, the primary no.5,pp.1365–1376,2023.
challenge is to propose a low-cost detection solution in the [12] Z.Yuan,S.Li,P.Yang,andY.Li,“Lightweightobjectdetectionmodel
with data augmentation for tiny pest detection,” in 2022 IEEE 20th
fields. The solution includes detection methods, software sys-
International Conference on Industrial Informatics (INDIN), pp. 233–
tems,samplingmethods,andequipmentforsamplingtoenable 238,IEEE,2022.
nematode detection in the field. While deep learning provides [13] M. Bogale, A. Baniya, and P. DiGennaro, “Nematode identification
techniquesandrecentadvances,”Plants,vol.9,no.10,p.1260,2020.
relatively low-loss detection methods, sampling methods re-
[14] O. P. Kranse, I. Ko, R. Healey, U. Sonawala, S. Wei, B. Senatori,
main a challenge. F. De Batte´, J. Zhou, and S. Eves-van den Akker, “A low-cost and
For the development of deep learning-based nematode de- open-sourcesolutiontoautomateimagingandanalysisofcystnematode
infectionassaysforarabidopsisthaliana,”PlantMethods,vol.18,no.1,
tection, the major factor limiting relevant research at present
pp.1–12,2022.
is the lack of large-scale available data, for example, datasets [15] Z. Yuan, K. Liu, S. Li, and P. Yang, “Automatic generation of visual
from samples of soil extracts. The development of zero-shot concept-based explanations for pest recognition,” in 2023 IEEE 21st
International Conference on Industrial Informatics (INDIN), pp. 1–6,
learning or few-show learning techniques has the potential
IEEE,2023.
to mitigate this challenge. Meanwhile, lightweight detection [16] Y. Zhang, S. Li, H. Li, R. Wang, K.-Q. Zhang, and J. Xu, “Fungi–
modelsareessentialforthefieldtoreducetheneedforequip- nematode interactions: Diversity, ecology, and biocontrol prospects in
agriculture,”JournalofFungi,vol.6,no.4,p.206,2020.
ment. The aforementioned model quantisation and reparame-
[17] M.M.Abd-Elgawad,“Plant-parasiticnematodesofstrawberryinegypt:
terisationarenecessarymodeloptimisationmethods.Basedon areview,”BulletinoftheNationalResearchCentre,vol.43,pp.1–13,
thevisualcharacteristicsofnematodes,thenematodedetection 2019.
[18] M.M.Abd-Elgawad,“Biologicalcontrolagentsintheintegratednema-
task is categorised as tiny object detection. Therefore, optimi-
tode management of potato in egypt,” Egyptian Journal of Biological
sation for tiny object detection is beneficial to provide a more PestControl,vol.30,pp.1–13,2020.[19] A.Bairwa,E.Venkatasalam,R.Sudha,R.Umamaheswari,andB.Singh, detection,”IndonesianJournalofElectricalEngineeringandComputer
“Techniques for characterization and eradication of potato cyst nema- Science,vol.30,pp.316–324,2023.
tode:areview,”JournalofParasiticDiseases,vol.41,no.3,pp.607– [38] A. Akintayo, G. L. Tylka, A. K. Singh, B. Ganapathysubramanian,
620,2017. A. Singh, and S. Sarkar, “A deep learning framework to discern and
[20] B.Qin,F.Sun,W.Shen,B.Dong,S.Ma,X.Huo,andP.Lan,“Deep count microscopic nematode eggs,” Scientific reports, vol. 8, no. 1,
learning-based pine nematode trees’ identification using multispectral p.9145,2018.
andvisibleuavimagery,”Drones,vol.7,no.3,p.183,2023. [39] A.Abade,L.F.Porto,P.A.Ferreira,andF.deBarrosVidal,“Nemanet:
[21] X. Qing, Y. Wang, X. Lu, H. Li, X. Wang, H. Li, and X. Xie, A convolutional neural network model for identification of soybean
“Nemarec:Adeeplearning-basedwebapplicationfornematodeimage nematodes,”BiosystemsEngineering,vol.213,pp.39–62,2022.
identification and ecological indices calculation,” European Journal of [40] Y.Arjoune,N.Sugunaraj,S.Peri,S.V.Nair,A.Skurdal,P.Ranganathan,
SoilBiology,vol.110,p.103408,2022. andB.Johnson,“Soybeancystnematodedetectionandmanagement:a
[22] Y.Zhu,J.Zhuang,J.Xiao,K.Song,L.Lv,andS.Lao,“Analgorithm review,”PlantMethods,vol.18,no.1,pp.1–39,2022.
based on attention mask for fine-grained object detection,” in 2021 [41] L.Chen,M.Strauch,M.Daub,M.Jansen,H.-G.Luigs,andD.Merhof,
3rd International Conference on Advances in Computer Technology, “Instancesegmentationofnematodecystsinmicroscopicimagesofsoil
InformationScienceandCommunication(CTISC),pp.324–327,IEEE, samples,” in 2019 41st Annual International Conference of the IEEE
2021. EngineeringinMedicineandBiologySociety(EMBC),pp.5932–5936,
[23] X. Lu, S. Fung, Y. Wang, W. Ouyang, X. Qing, and H. Li, “I-nema: IEEE,2019.
A large-scale microscopic image dataset for nematode recognition,” [42] K. A. Rani and S. Gowrishankar, “Pathogen-based classification of
AvailableatSSRN4213402. plantdiseases:Adeeptransferlearningapproachforintelligentsupport
systems,”IEEEAccess,2023.
[24] N.H.Shabrina,S.Indarti,R.A.Lika,andR.Maharani,“Acomparative
[43] K.Liu,P.Yang,R.Wang,L.Jiao,T.Li,andJ.Zhang,“Observer-based
analysisofconvolutionalneuralnetworksapproachesforphytoparasitic
adaptive fuzzy finite-time attitude control for quadrotor uavs,” IEEE
nematode identification,” Commun. Math. Biol. Neurosci., vol. 2023,
TransactionsonAerospaceandElectronicSystems,2023.
pp.Article–ID,2023.
[44] T. B. Pun, A. Neupane, R. Koech, and K. J. Owen, “Detection and
[25] S. Fudickar, E. J. Nustede, E. Dreyer, and J. Bornhorst, “Mask r-cnn
quantification of root-knot nematode (meloidogyne spp.) eggs from
basedc.elegansdetectionwithadiymicroscope,”Biosensors,vol.11,
tomatoplantsusingimageanalysis,”IEEEAccess,vol.10,pp.123190–
no.8,p.257,2021.
123204,2022.
[26] C.Wang,S.Sun,C.Zhao,Z.Mao,H.Wu,andG.Teng,“Adetection
[45] L.Chen,M.Strauch,M.Daub,H.-G.Luigs,M.Jansen,andD.Merhof,
model for cucumber root-knot nematodes based on modified yolov5-
“Learning to segment fine structures under image-level supervision
cms,”Agronomy,vol.12,no.10,p.2555,2022.
with an application to nematode segmentation,” in 2022 44th Annual
[27] J.Zhang,P.Ma,T.Jiang,X.Zhao,W.Tan,J.Zhang,S.Zou,X.Huang,
International Conference of the IEEE Engineering in Medicine &
M. Grzegorzek, and C. Li, “Sem-rcnn: a squeeze-and-excitation-based
BiologySociety(EMBC),pp.2128–2131,IEEE,2022.
maskregionconvolutionalneuralnetworkformulti-classenvironmental
[46] V. Ljosa, K. L. Sokolnicki, and A. E. Carpenter, “Annotated high-
microorganism detection,” Applied Sciences, vol. 12, no. 19, p. 9902,
throughput microscopy image sets for validation.,” Nature methods,
2022.
vol.9,no.7,pp.637–637,2012.
[28] J. Jime´nez-Chavarr´ıa, “Segnema: nematode segmentation strategy in [47] S. Sabban, A. Alotebi, Z. Khalifah, and T. Alafif, “SinfNet: Microor-
digitalmicroscopyimagesusingdeeplearningandshapemodels,”2019. ganismimageclassifier,”Jan.2023.
[29] H. Niu, T. Zhao, A. Westphal, and Y. Chen, “A low-cost proximate [48] C.-Y. Wang, A. Bochkovskiy, and H.-Y. M. Liao, “Yolov7: Trainable
sensing method for early detection of nematodes in walnut using wal- bag-of-freebiessetsnewstate-of-the-artforreal-timeobjectdetectors,”
abotandscikit-learnclassificationalgorithms,”inAutonomousAirand 2022.
GroundSensingSystemsforAgriculturalOptimizationandPhenotyping [49] Z. Zou, K. Chen, Z. Shi, Y. Guo, and J. Ye, “Object detection in 20
V,vol.11414,pp.119–125,SPIE,2020. years:Asurvey,”ProceedingsoftheIEEE,vol.111,no.3,pp.257–276,
[30] L.Zhang,W.Huang,andJ.Wang,“Countingofpinewoodnematode 2023.
basedonvdnetconvolutionalneuralnetwork,”in20224thInternational [50] L. Liu, W. Ouyang, X. Wang, P. Fieguth, J. Chen, X. Liu, and
Conference on Robotics and Computer Vision (ICRCV), pp. 164–168, M.Pietika¨inen,“Deeplearningforgenericobjectdetection:Asurvey,”
IEEE,2022. Internationaljournalofcomputervision,vol.128,pp.261–318,2020.
[31] L. Chen, M. Strauch, M. Daub, X. Jiang, M. Jansen, H.-G. Luigs, [51] R. Girshick, J. Donahue, T. Darrell, and J. Malik, “Rich feature
S. Schultz-Kuhlmann, S. Kru¨ssel, and D. Merhof, “A cnn framework hierarchies for accurate object detection and semantic segmentation,”
based on line annotations for detecting nematodes in microscopic inProceedingsoftheIEEEconferenceoncomputervisionandpattern
images,” in 2020 IEEE 17th International Symposium on Biomedical recognition,pp.580–587,2014.
Imaging(ISBI),pp.508–512,IEEE,2020. [52] R. Girshick, “Fast r-cnn,” in Proceedings of the IEEE international
[32] D.Banerjee,V.Kukreja,S.Hariharan,V.Jain,andS.Dutta,“Cnn-svm conferenceoncomputervision,pp.1440–1448,2015.
modelforaccuratedetectionofbacterialdiseasesincucumberleaves,” [53] S.Ren,K.He,R.Girshick,andJ.Sun,“Fasterr-cnn:Towardsreal-time
in2023ThirdInternationalConferenceonSecureCyberComputingand objectdetectionwithregionproposalnetworks,”2016.
Communication(ICSCCC),pp.7–12,IEEE,2023. [54] K. Duan, S. Bai, L. Xie, H. Qi, Q. Huang, and Q. Tian, “Centernet:
[33] A. J. Oliveira, G. A. Assis, E. R. Faria, J. R. Souza, K. C. Vivaldini, Keypointtripletsforobjectdetection,”2019.
V. Guizilini, F. Ramos, C. C. Mendes, and D. F. Wolf, “Analysis of [55] N. Carion, F. Massa, G. Synnaeve, N. Usunier, A. Kirillov, and
nematodesincoffeecropsatdifferentaltitudesusingaerialimages,”in S.Zagoruyko,“End-to-endobjectdetectionwithtransformers,”2020.
201927thEuropeanSignalProcessingConference(EUSIPCO),pp.1–5, [56] G.Jocher,A.Chaurasia,A.Stoken,J.Borovec,NanoCode012,Y.Kwon,
IEEE,2019. K. Michael, TaoXie, J. Fang, imyhxy, Lorna, Z. Yif), C. Wong, A. V,
[34] R.Nakasi,E.R.Aliija,andJ.Nakatumba,“Aposteronintestinalpara- D.Montes,Z.Wang,C.Fati,J.Nadar,Laughing,UnglvKitDe,V.Sonck,
sitedetectioninstoolsampleusingalexnetandgooglenetarchitectures,” tkianai, yxNONG, P. Skalski, A. Hogan, D. Nair, M. Strobel, and
in ACM SIGCAS conference on computing and sustainable societies, M. Jain, “ultralytics/yolov5: v7.0 - YOLOv5 SOTA Realtime Instance
pp.389–395,2021. Segmentation,”Nov.2022.
[35] J.-L. Lin, W.-L. Kuo, Y.-H. Huang, T.-L. Jong, A.-L. Hsu, and W.-H. [57] Z.Ge,S.Liu,F.Wang,Z.Li,andJ.Sun,“Yolox:Exceedingyoloseries
Hsu,“Usingconvolutionalneuralnetworkstomeasurethephysiological in2021,”arXivpreprintarXiv:2107.08430,2021.
age of caenorhabditis elegans,” IEEE/ACM transactions on computa- [58] T.-Y. Lin, M. Maire, S. Belongie, L. Bourdev, R. Girshick, J. Hays,
tionalbiologyandbioinformatics,vol.18,no.6,pp.2724–2732,2020. P.Perona,D.Ramanan,C.L.Zitnick,andP.Dolla´r,“Microsoftcoco:
[36] T. D. Pham, “Classification of caenorhabditis elegans locomotion be- Commonobjectsincontext,”2015.
haviorswitheigenfeature-enhancedlongshort-termmemorynetworks,” [59] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, “You only look
IEEE/ACMTransactionsonComputationalBiologyandBioinformatics, once: Unified, real-time object detection,” in Proceedings of the IEEE
vol.20,no.1,pp.206–216,2022. conference on computer vision and pattern recognition, pp. 779–788,
[37] S.I.NataliaAngeline,NabilaHusnaShabrina,“Fasterregion-basedcon- 2016.
volutionalneuralnetworkforplant-parasiticandnon-parasiticnematode