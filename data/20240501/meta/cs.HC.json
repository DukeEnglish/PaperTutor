[
    {
        "title": "DiaryHelper: Exploring the Use of an Automatic Contextual Information Recording Agent for Elicitation Diary Study",
        "authors": "Junze LiChangyang HeJiaxiong HuBoyang JiaAlon HalevyXiaojuan Ma",
        "links": "http://arxiv.org/abs/2404.19738v1",
        "entry_id": "http://arxiv.org/abs/2404.19738v1",
        "pdf_url": "http://arxiv.org/pdf/2404.19738v1",
        "summary": "Elicitation diary studies, a type of qualitative, longitudinal research\nmethod, involve participants to self-report aspects of events of interest at\ntheir occurrences as memory cues for providing details and insights during\npost-study interviews. However, due to time constraints and lack of motivation,\nparticipants' diary entries may be vague or incomplete, impairing their later\nrecall. To address this challenge, we designed an automatic contextual\ninformation recording agent, DiaryHelper, based on the theory of episodic\nmemory. DiaryHelper can predict five dimensions of contextual information and\nconfirm with participants. We evaluated the use of DiaryHelper in both the\nrecording period and the elicitation interview through a within-subject study\n(N=12) over a period of two weeks. Our results demonstrated that DiaryHelper\ncan assist participants in capturing abundant and accurate contextual\ninformation without significant burden, leading to a more detailed recall of\nrecorded events and providing greater insights.",
        "updated": "2024-04-30 17:36:06 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.19738v1"
    },
    {
        "title": "A Framework for Leveraging Human Computation Gaming to Enhance Knowledge Graphs for Accuracy Critical Generative AI Applications",
        "authors": "Steph BuongiornoCorey Clark",
        "links": "http://arxiv.org/abs/2404.19729v1",
        "entry_id": "http://arxiv.org/abs/2404.19729v1",
        "pdf_url": "http://arxiv.org/pdf/2404.19729v1",
        "summary": "External knowledge graphs (KGs) can be used to augment large language models\n(LLMs), while simultaneously providing an explainable knowledge base of facts\nthat can be inspected by a human. This approach may be particularly valuable in\ndomains where explainability is critical, like human trafficking data analysis.\nHowever, creating KGs can pose challenges. KGs parsed from documents may\ncomprise explicit connections (those directly stated by a document) but miss\nimplicit connections (those obvious to a human although not directly stated).\nTo address these challenges, this preliminary research introduces the GAME-KG\nframework, standing for \"Gaming for Augmenting Metadata and Enhancing Knowledge\nGraphs.\" GAME-KG is a federated approach to modifying explicit as well as\nimplicit connections in KGs by using crowdsourced feedback collected through\nvideo games. GAME-KG is shown through two demonstrations: a Unity test scenario\nfrom Dark Shadows, a video game that collects feedback on KGs parsed from US\nDepartment of Justice (DOJ) Press Releases on human trafficking, and a\nfollowing experiment where OpenAI's GPT-4 is prompted to answer questions based\non a modified and unmodified KG. Initial results suggest that GAME-KG can be an\neffective framework for enhancing KGs, while simultaneously providing an\nexplainable set of structured facts verified by humans.",
        "updated": "2024-04-30 17:24:55 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.19729v1"
    },
    {
        "title": "Harmonic LLMs are Trustworthy",
        "authors": "Nicholas S. KerstingMohammad RahmanSuchismitha VedalaYang Wang",
        "links": "http://arxiv.org/abs/2404.19708v1",
        "entry_id": "http://arxiv.org/abs/2404.19708v1",
        "pdf_url": "http://arxiv.org/pdf/2404.19708v1",
        "summary": "We introduce an intuitive method to test the robustness (stability and\nexplainability) of any black-box LLM in real-time, based upon the local\ndeviation from harmoniticity, denoted as $\\gamma$. To the best of our knowledge\nthis is the first completely model-agnostic and unsupervised method of\nmeasuring the robustness of any given response from an LLM, based upon the\nmodel itself conforming to a purely mathematical standard. We conduct human\nannotation experiments to show the positive correlation of $\\gamma$ with false\nor misleading answers, and demonstrate that following the gradient of $\\gamma$\nin stochastic gradient ascent efficiently exposes adversarial prompts.\nMeasuring $\\gamma$ across thousands of queries in popular LLMs (GPT-4, ChatGPT,\nClaude-2.1, Mixtral-8x7B, Smaug-72B, Llama2-7B, and MPT-7B) allows us to\nestimate the liklihood of wrong or hallucinatory answers automatically and\nquantitatively rank the reliability of these models in various objective\ndomains (Web QA, TruthfulQA, and Programming QA). Across all models and domains\ntested, human ratings confirm that $\\gamma \\to 0$ indicates trustworthiness,\nand the low-$\\gamma$ leaders among these models are GPT-4, ChatGPT, and\nSmaug-72B.",
        "updated": "2024-04-30 17:00:32 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.19708v1"
    },
    {
        "title": "SwipeGANSpace: Swipe-to-Compare Image Generation via Efficient Latent Space Exploration",
        "authors": "Yuto NakashimaMingzhe YangYukino Baba",
        "links": "http://dx.doi.org/10.1145/3640543.3645141",
        "entry_id": "http://arxiv.org/abs/2404.19693v1",
        "pdf_url": "http://arxiv.org/pdf/2404.19693v1",
        "summary": "Generating preferred images using generative adversarial networks (GANs) is\nchallenging owing to the high-dimensional nature of latent space. In this\nstudy, we propose a novel approach that uses simple user-swipe interactions to\ngenerate preferred images for users. To effectively explore the latent space\nwith only swipe interactions, we apply principal component analysis to the\nlatent space of the StyleGAN, creating meaningful subspaces. We use a\nmulti-armed bandit algorithm to decide the dimensions to explore, focusing on\nthe preferences of the user. Experiments show that our method is more efficient\nin generating preferred images than the baseline methods. Furthermore, changes\nin preferred images during image generation or the display of entirely\ndifferent image styles were observed to provide new inspirations, subsequently\naltering user preferences. This highlights the dynamic nature of user\npreferences, which our proposed approach recognizes and enhances.",
        "updated": "2024-04-30 16:37:27 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.19693v1"
    },
    {
        "title": "The Drawback of Insight: Detailed Explanations Can Reduce Agreement with XAI",
        "authors": "Sabid Bin Habib PiasAlicia FreelTimothy TrammelTaslima AkterDonald WilliamsonApu Kapadia",
        "links": "http://arxiv.org/abs/2404.19629v1",
        "entry_id": "http://arxiv.org/abs/2404.19629v1",
        "pdf_url": "http://arxiv.org/pdf/2404.19629v1",
        "summary": "With the emergence of Artificial Intelligence (AI)-based decision-making,\nexplanations help increase new technology adoption through enhanced trust and\nreliability. However, our experimental study challenges the notion that every\nuser universally values explanations. We argue that the agreement with AI\nsuggestions, whether accompanied by explanations or not, is influenced by\nindividual differences in personality traits and the users' comfort with\ntechnology. We found that people with higher neuroticism and lower\ntechnological comfort showed more agreement with the recommendations without\nexplanations. As more users become exposed to eXplainable AI (XAI) and AI-based\nsystems, we argue that the XAI design should not provide explanations for users\nwith high neuroticism and low technology comfort. Prioritizing user\npersonalities in XAI systems will help users become better collaborators of AI\nsystems.",
        "updated": "2024-04-30 15:29:01 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.19629v1"
    }
]