[
    {
        "title": "FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs",
        "authors": "Eun Cheol ChoiEmilio Ferrara",
        "links": "http://arxiv.org/abs/2402.05904v1",
        "entry_id": "http://arxiv.org/abs/2402.05904v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05904v1",
        "summary": "Our society is facing rampant misinformation harming public health and trust.\nTo address the societal challenge, we introduce FACT-GPT, a system leveraging\nLarge Language Models (LLMs) to automate the claim matching stage of\nfact-checking. FACT-GPT, trained on a synthetic dataset, identifies social\nmedia content that aligns with, contradicts, or is irrelevant to previously\ndebunked claims. Our evaluation shows that our specialized LLMs can match the\naccuracy of larger models in identifying related claims, closely mirroring\nhuman judgment. This research provides an automated solution for efficient\nclaim matching, demonstrates the potential of LLMs in supporting fact-checkers,\nand offers valuable resources for further research in the field.",
        "updated": "2024-02-08 18:43:05 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05904v1"
    },
    {
        "title": "Personalizing Driver Safety Interfaces via Driver Cognitive Factors Inference",
        "authors": "Emily S SumnerJonathan DeCastroJean CostaDeepak E GopinathEverlyne KimaniShabnam HakimiAllison MorganAndrew BestHieu NguyenDaniel J BrooksBassam ul HaqAndrew PatrikalakisHiroshi YasudaKate SieckAvinash BalachandranTiffany ChenGuy Rosman",
        "links": "http://arxiv.org/abs/2402.05893v1",
        "entry_id": "http://arxiv.org/abs/2402.05893v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05893v1",
        "summary": "Recent advances in AI and intelligent vehicle technology hold promise to\nrevolutionize mobility and transportation, in the form of advanced driving\nassistance (ADAS) interfaces. Although it is widely recognized that certain\ncognitive factors, such as impulsivity and inhibitory control, are related to\nrisky driving behavior, play a significant role in on-road risk-taking,\nexisting systems fail to leverage such factors. Varying levels of these\ncognitive factors could influence the effectiveness and acceptance of driver\nsafety interfaces.\n  We demonstrate an approach for personalizing driver interaction via driver\nsafety interfaces that are triggered based on a learned recurrent neural\nnetwork. The network is trained from a population of human drivers to infer\nimpulsivity and inhibitory control from recent driving behavior. Using a\nhigh-fidelity vehicle motion simulator, we demonstrate the ability to deduce\nthese factors from driver behavior. We then use these inferred factors to make\ninstantaneous determinations on whether or not to engage a driver safety\ninterface. This interface aims to decrease a driver's speed during yellow\nlights and reduce their inclination to run through them.",
        "updated": "2024-02-08 18:32:10 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05893v1"
    },
    {
        "title": "GET-Tok: A GenAI-Enriched Multimodal TikTok Dataset Documenting the 2022 Attempted Coup in Peru",
        "authors": "Gabriela PintoKeith BurghardtKristina LermanEmilio Ferrara",
        "links": "http://arxiv.org/abs/2402.05882v1",
        "entry_id": "http://arxiv.org/abs/2402.05882v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05882v1",
        "summary": "TikTok is one of the largest and fastest-growing social media sites in the\nworld. TikTok features, however, such as voice transcripts, are often missing\nand other important features, such as OCR or video descriptions, do not exist.\nWe introduce the Generative AI Enriched TikTok (GET-Tok) data, a pipeline for\ncollecting TikTok videos and enriched data by augmenting the TikTok Research\nAPI with generative AI models. As a case study, we collect videos about the\nattempted coup in Peru initiated by its former President, Pedro Castillo, and\nits accompanying protests. The data includes information on 43,697 videos\npublished from November 20, 2022 to March 1, 2023 (102 days). Generative AI\naugments the collected data via transcripts of TikTok videos, text descriptions\nof what is shown in the videos, what text is displayed within the video, and\nthe stances expressed in the video. Overall, this pipeline will contribute to a\nbetter understanding of online discussion in a multimodal setting with\napplications of Generative AI, especially outlining the utility of this\npipeline in non-English-language social media. Our code used to produce the\npipeline is in a public Github repository:\nhttps://github.com/gabbypinto/GET-Tok-Peru.",
        "updated": "2024-02-08 18:16:47 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05882v1"
    },
    {
        "title": "Generative Echo Chamber? Effects of LLM-Powered Search Systems on Diverse Information Seeking",
        "authors": "Nikhil SharmaQ. Vera LiaoZiang Xiao",
        "links": "http://arxiv.org/abs/2402.05880v1",
        "entry_id": "http://arxiv.org/abs/2402.05880v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05880v1",
        "summary": "Large language models (LLMs) powered conversational search systems have\nalready been used by hundreds of millions of people, and are believed to bring\nmany benefits over conventional search. However, while decades of research and\npublic discourse interrogated the risk of search systems in increasing\nselective exposure and creating echo chambers -- limiting exposure to diverse\nopinions and leading to opinion polarization, little is known about such a risk\nof LLM-powered conversational search. We conduct two experiments to\ninvestigate: 1) whether and how LLM-powered conversational search increases\nselective exposure compared to conventional search; 2) whether and how LLMs\nwith opinion biases that either reinforce or challenge the user's view change\nthe effect. Overall, we found that participants engaged in more biased\ninformation querying with LLM-powered conversational search, and an opinionated\nLLM reinforcing their views exacerbated this bias. These results present\ncritical implications for the development of LLMs and conversational search\nsystems, and the policy governing these technologies.",
        "updated": "2024-02-08 18:14:33 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05880v1"
    },
    {
        "title": "\"Can You Play Anything Else?\" Understanding Play Style Flexibility in League of Legends",
        "authors": "Emily ChenAlexander BisbergEmilio Ferrara",
        "links": "http://arxiv.org/abs/2402.05865v1",
        "entry_id": "http://arxiv.org/abs/2402.05865v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05865v1",
        "summary": "This study investigates the concept of flexibility within League of Legends,\na popular online multiplayer game, focusing on the relationship between user\nadaptability and team success. Utilizing a dataset encompassing players of\nvarying skill levels and play styles, we calculate two measures of flexibility\nfor each player: overall flexibility and temporal flexibility. Our findings\nsuggest that the flexibility of a user is dependent upon a user's preferred\nplay style, and flexibility does impact match outcome. This work also shows\nthat skill level not only indicates how willing a player is to adapt their play\nstyle but also how their adaptability changes over time. This paper highlights\nthe the duality and balance of mastery versus flexibility, providing insights\nthat can inform strategic planning, collaboration and resource allocation in\ncompetitive environments.",
        "updated": "2024-02-08 17:57:03 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05865v1"
    }
]