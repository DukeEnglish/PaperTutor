[
    {
        "title": "Sharp Rates in Dependent Learning Theory: Avoiding Sample Size Deflation for the Square Loss",
        "authors": "Ingvar ZiemannStephen TuGeorge J. PappasNikolai Matni",
        "links": "http://arxiv.org/abs/2402.05928v1",
        "entry_id": "http://arxiv.org/abs/2402.05928v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05928v1",
        "summary": "In this work, we study statistical learning with dependent ($\\beta$-mixing)\ndata and square loss in a hypothesis class $\\mathscr{F}\\subset L_{\\Psi_p}$\nwhere $\\Psi_p$ is the norm $\\|f\\|_{\\Psi_p} \\triangleq \\sup_{m\\geq 1} m^{-1/p}\n\\|f\\|_{L^m} $ for some $p\\in [2,\\infty]$. Our inquiry is motivated by the\nsearch for a sharp noise interaction term, or variance proxy, in learning with\ndependent data. Absent any realizability assumption, typical non-asymptotic\nresults exhibit variance proxies that are deflated \\emph{multiplicatively} by\nthe mixing time of the underlying covariates process. We show that whenever the\ntopologies of $L^2$ and $\\Psi_p$ are comparable on our hypothesis class\n$\\mathscr{F}$ -- that is, $\\mathscr{F}$ is a weakly sub-Gaussian class:\n$\\|f\\|_{\\Psi_p} \\lesssim \\|f\\|_{L^2}^\\eta$ for some $\\eta\\in (0,1]$ -- the\nempirical risk minimizer achieves a rate that only depends on the complexity of\nthe class and second order statistics in its leading term. Our result holds\nwhether the problem is realizable or not and we refer to this as a \\emph{near\nmixing-free rate}, since direct dependence on mixing is relegated to an\nadditive higher order term. We arrive at our result by combining the above\nnotion of a weakly sub-Gaussian class with mixed tail generic chaining. This\ncombination allows us to compute sharp, instance-optimal rates for a wide range\nof problems. %Our approach, reliant on mixed tail generic chaining, allows us\nto obtain sharp, instance-optimal rates. Examples that satisfy our framework\ninclude sub-Gaussian linear regression, more general smoothly parameterized\nfunction classes, finite hypothesis classes, and bounded smoothness classes.",
        "updated": "2024-02-08 18:57:42 UTC",
        "interpretation": {
            "论文还有什么可以进一步探索的点？": "论文\"Sharp Rates in Dependent Learning Theory: Avoiding Sample Size Deflation for the Square Loss\" by Ziemann, Tu, Pappas, and Matni presents a significant contribution to the field of statistical learning with dependent data. The paper introduces a novel approach to handling dependent data that avoids the sample size deflation typically associated with such data. The authors achieve this by developing a new notion of a weakly sub-Gaussian class and combining it with mixed tail generic chaining. This allows them to derive sharp, instance-optimal rates for a wide range of problems, including sub-Gaussian linear regression, smooth parameterization of function classes, finite hypothesis classes, and bounded smoothness classes.\n\nThe paper's main contribution is the demonstration that when the topologies of L and Ψ are comparable on the hypothesis class F, the empirical risk minimizer achieves a rate that depends only on the complexity of the class and second-order statistics, without any significant deflation due to the mixing time of the underlying covariates process.\n\nRegarding further exploration, the paper lays the groundwork for several interesting avenues of research:\n\n1. **Extensions to Non-Square Loss Functions**: The current work focuses on the square loss function. Extending the results to other loss functions, such as the logistic loss or the hinge loss, which are common in classification tasks, would be a valuable next step.\n\n2. **Non-Stationary Dependent Data**: The paper assumes β-mixing, which implies a certain level of stationarity. Investigating non-stationary dependent data, where the mixing coefficients may vary over time, could lead to a better understanding of more complex real-world scenarios.\n\n3. **Online Learning and Adaptivity**: The results in the paper are for offline learning settings. Exploring how to adapt the methods to online learning settings, where data arrives sequentially, and the algorithm must update its predictions in real-time, would be an interesting and practical direction.\n\n4. **High-Dimensional Settings**: The paper does not address high-dimensional settings where the dimensionality of the feature space is comparable to or greater than the sample size. Developing methods that can handle such scenarios with dependent data is a significant open problem.\n\n5. **Robustness and Generalization**: While the paper provides sharp rates for dependent learning, it does not directly address the robustness of the learned models to outliers or concept drift. Understanding how the proposed methods generalize to unseen data and how they perform in the presence of noisy or adversarial data points is an important area for future research.\n\n6. **Computational Aspects**: The paper focuses on the theoretical aspects of learning with dependent data. However, the practical implementation of these methods often requires careful consideration of computational efficiency. Developing algorithms that can efficiently compute the instance-optimal rates would be beneficial for real-world applications.\n\n7. **Connection to Other Fields**: The techniques developed in this paper may have implications for other fields, such as time series analysis, reinforcement learning, and signal processing. Exploring these connections could lead to cross-disciplinary insights and advancements.\n\n8. **Application-Specific Studies**: While the paper provides examples of classes that satisfy their framework, conducting empirical studies on real-world datasets and applications could further validate and refine the theoretical results.\n\n9. **Comparison with Existing Methods**: The paper establishes a new benchmark for dependent learning. Comparing the performance of the proposed methods with existing techniques in various settings would provide a better understanding of their relative strengths and weaknesses.\n\n10. **Scalability**: As data sets grow larger and more complex, developing methods that can scale to big data settings while maintaining accuracy and efficiency will become increasingly important.\n\nIn summary, the paper presents a robust theoretical framework for dependent learning, but there are many practical and theoretical challenges that remain to be addressed, which could serve as the basis for future research in this area."
        },
        "id": "2402.05928v1"
    },
    {
        "title": "Prior-Dependent Allocations for Bayesian Fixed-Budget Best-Arm Identification in Structured Bandits",
        "authors": "Nicolas NguyenImad AoualiAndrás GyörgyClaire Vernade",
        "links": "http://arxiv.org/abs/2402.05878v1",
        "entry_id": "http://arxiv.org/abs/2402.05878v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05878v1",
        "summary": "We study the problem of Bayesian fixed-budget best-arm identification (BAI)\nin structured bandits. We propose an algorithm that uses fixed allocations\nbased on the prior information and the structure of the environment. We provide\ntheoretical bounds on its performance across diverse models, including the\nfirst prior-dependent upper bounds for linear and hierarchical BAI. Our key\ncontribution is introducing new proof methods that result in tighter bounds for\nmulti-armed BAI compared to existing methods. We extensively compare our\napproach to other fixed-budget BAI methods, demonstrating its consistent and\nrobust performance in various settings. Our work improves our understanding of\nBayesian fixed-budget BAI in structured bandits and highlights the\neffectiveness of our approach in practical scenarios.",
        "updated": "2024-02-08 18:13:26 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05878v1"
    },
    {
        "title": "Federated Offline Reinforcement Learning: Collaborative Single-Policy Coverage Suffices",
        "authors": "Jiin WooLaixi ShiGauri JoshiYuejie Chi",
        "links": "http://arxiv.org/abs/2402.05876v1",
        "entry_id": "http://arxiv.org/abs/2402.05876v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05876v1",
        "summary": "Offline reinforcement learning (RL), which seeks to learn an optimal policy\nusing offline data, has garnered significant interest due to its potential in\ncritical applications where online data collection is infeasible or expensive.\nThis work explores the benefit of federated learning for offline RL, aiming at\ncollaboratively leveraging offline datasets at multiple agents. Focusing on\nfinite-horizon episodic tabular Markov decision processes (MDPs), we design\nFedLCB-Q, a variant of the popular model-free Q-learning algorithm tailored for\nfederated offline RL. FedLCB-Q updates local Q-functions at agents with novel\nlearning rate schedules and aggregates them at a central server using\nimportance averaging and a carefully designed pessimistic penalty term. Our\nsample complexity analysis reveals that, with appropriately chosen parameters\nand synchronization schedules, FedLCB-Q achieves linear speedup in terms of the\nnumber of agents without requiring high-quality datasets at individual agents,\nas long as the local datasets collectively cover the state-action space visited\nby the optimal policy, highlighting the power of collaboration in the federated\nsetting. In fact, the sample complexity almost matches that of the single-agent\ncounterpart, as if all the data are stored at a central location, up to\npolynomial factors of the horizon length. Furthermore, FedLCB-Q is\ncommunication-efficient, where the number of communication rounds is only\nlinear with respect to the horizon length up to logarithmic factors.",
        "updated": "2024-02-08 18:09:17 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05876v1"
    },
    {
        "title": "Let Your Graph Do the Talking: Encoding Structured Data for LLMs",
        "authors": "Bryan PerozziBahare FatemiDustin ZelleAnton TsitsulinMehran KazemiRami Al-RfouJonathan Halcrow",
        "links": "http://arxiv.org/abs/2402.05862v1",
        "entry_id": "http://arxiv.org/abs/2402.05862v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05862v1",
        "summary": "How can we best encode structured data into sequential form for use in large\nlanguage models (LLMs)? In this work, we introduce a parameter-efficient method\nto explicitly represent structured data for LLMs. Our method, GraphToken,\nlearns an encoding function to extend prompts with explicit structured\ninformation. Unlike other work which focuses on limited domains (e.g. knowledge\ngraph representation), our work is the first effort focused on the general\nencoding of structured data to be used for various reasoning tasks. We show\nthat explicitly representing the graph structure allows significant\nimprovements to graph reasoning tasks. Specifically, we see across the board\nimprovements - up to 73% points - on node, edge and, graph-level tasks from the\nGraphQA benchmark.",
        "updated": "2024-02-08 17:51:44 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05862v1"
    },
    {
        "title": "How Much is Unseen Depends Chiefly on Information About the Seen",
        "authors": "Seongmin LeeMarcel Böhme",
        "links": "http://arxiv.org/abs/2402.05835v1",
        "entry_id": "http://arxiv.org/abs/2402.05835v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05835v1",
        "summary": "It might seem counter-intuitive at first: We find that, in expectation, the\nproportion of data points in an unknown population-that belong to classes that\ndo not appear in the training data-is almost entirely determined by the number\n$f_k$ of classes that do appear in the training data the same number of times.\nWhile in theory we show that the difference of the induced estimator decays\nexponentially in the size of the sample, in practice the high variance prevents\nus from using it directly for an estimator of the sample coverage. However, our\nprecise characterization of the dependency between $f_k$'s induces a large\nsearch space of different representations of the expected value, which can be\ndeterministically instantiated as estimators. Hence, we turn to optimization\nand develop a genetic algorithm that, given only the sample, searches for an\nestimator with minimal mean-squared error (MSE). In our experiments, our\ngenetic algorithm discovers estimators that have a substantially smaller MSE\nthan the state-of-the-art Good-Turing estimator. This holds for over 96% of\nruns when there are at least as many samples as classes. Our estimators' MSE is\nroughly 80% of the Good-Turing estimator's.",
        "updated": "2024-02-08 17:12:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05835v1"
    }
]