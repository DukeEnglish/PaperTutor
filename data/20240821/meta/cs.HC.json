[
    {
        "title": "Proxona: Leveraging LLM-Driven Personas to Enhance Creators' Understanding of Their Audience",
        "authors": "Yoonseo ChoiEun Jeong KangSeulgi ChoiMin Kyung LeeJuho Kim",
        "links": "http://arxiv.org/abs/2408.10937v1",
        "entry_id": "http://arxiv.org/abs/2408.10937v1",
        "pdf_url": "http://arxiv.org/pdf/2408.10937v1",
        "summary": "Creators are nothing without their audience, and thereby understanding their\naudience is the cornerstone of their professional achievement. Yet many\ncreators feel lost while comprehending audiences with existing tools, which\noffer insufficient insights for tailoring content to audience needs. To address\nthe challenges creators face in understanding their audience, we present\nProxona, a system for defining and extracting representative audience personas\nfrom the comments. Creators converse with personas to gain insights into their\npreferences and engagement, solicit feedback, and implement evidence-based\nimprovements to their content. Powered by large language models, Proxona\nanalyzes audience comments, distilling the latent characteristics of audiences\ninto tangible dimensions (classification categories) and values (category\nattributes). Proxona then clusters these into synthetic personas. Our technical\nevaluations demonstrated that our pipelines effectively generated relevant and\ndistinct dimensions and values, enabling the deduction of audience-reflecting\npersonas, while minimizing the likelihood of hallucinations in persona\nresponses. Our user evaluation with 11 creators showed that Proxona supported\ncreators to gain new insights about their audience, make informed decisions,\nand successfully complete content creation with high confidence. Proxona's\ndata-driven audience personas empower creators to seamlessly integrate audience\nperspectives into their creative processes, fostering a collaborative approach\nto content creation.",
        "updated": "2024-08-20 15:20:30 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.10937v1"
    },
    {
        "title": "Evaluating Assistive Technologies on a Trade Fair: Methodological Overview and Lessons Learned",
        "authors": "Annalies BaumeisterFelix GoldauMax PascherJens GerkenUdo FresePatrizia Tolle",
        "links": "http://arxiv.org/abs/2408.10933v1",
        "entry_id": "http://arxiv.org/abs/2408.10933v1",
        "pdf_url": "http://arxiv.org/pdf/2408.10933v1",
        "summary": "User-centered evaluations are a core requirement in the development of new\nuser related technologies. However, it is often difficult to recruit sufficient\nparticipants, especially if the target population is small, particularly busy,\nor in some way restricted in their mobility. We bypassed these problems by\nconducting studies on trade fairs that were specifically designed for our\ntarget population (potentially care-receiving individuals in wheelchairs) and\ntherefore provided our users with external incentive to attend our study. This\npaper presents our gathered experiences, including methodological\nspecifications and lessons learned, and is aimed to guide other researchers\nwith conducting similar studies. In addition, we also discuss chances generated\nby this unconventional study environment as well as its limitations.",
        "updated": "2024-08-20 15:17:07 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.10933v1"
    },
    {
        "title": "Enhancing End-to-End Autonomous Driving Systems Through Synchronized Human Behavior Data",
        "authors": "Yiqun DuanZhuoli ZhuangJinzhao ZhouYu-Cheng ChangYu-Kai WangChin-Teng Lin",
        "links": "http://arxiv.org/abs/2408.10908v1",
        "entry_id": "http://arxiv.org/abs/2408.10908v1",
        "pdf_url": "http://arxiv.org/pdf/2408.10908v1",
        "summary": "This paper presents a pioneering exploration into the integration of\nfine-grained human supervision within the autonomous driving domain to enhance\nsystem performance. The current advances in End-to-End autonomous driving\nnormally are data-driven and rely on given expert trials. However, this\nreliance limits the systems' generalizability and their ability to earn human\ntrust. Addressing this gap, our research introduces a novel approach by\nsynchronously collecting data from human and machine drivers under identical\ndriving scenarios, focusing on eye-tracking and brainwave data to guide machine\nperception and decision-making processes. This paper utilizes the Carla\nsimulation to evaluate the impact brought by human behavior guidance.\nExperimental results show that using human attention to guide machine attention\ncould bring a significant improvement in driving performance. However, guidance\nby human intention still remains a challenge. This paper pioneers a promising\ndirection and potential for utilizing human behavior guidance to enhance\nautonomous systems.",
        "updated": "2024-08-20 14:51:51 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.10908v1"
    },
    {
        "title": "The impact of labeling automotive AI as \"trustworthy\" or \"reliable\" on user evaluation and technology acceptance",
        "authors": "John DorschOphelia Deroy",
        "links": "http://arxiv.org/abs/2408.10905v1",
        "entry_id": "http://arxiv.org/abs/2408.10905v1",
        "pdf_url": "http://arxiv.org/pdf/2408.10905v1",
        "summary": "This study explores whether labeling AI as \"trustworthy\" or \"reliable\"\ninfluences user perceptions and acceptance of automotive AI technologies. Using\na one-way between-subjects design, the research involved 478 online\nparticipants who were presented with guidelines for either trustworthy or\nreliable AI. Participants then evaluated three vignette scenarios and completed\na modified version of the Technology Acceptance Model, which included variables\nsuch as perceived ease of use, human-like trust, and overall attitude. Although\nlabeling AI as \"trustworthy\" did not significantly influence judgments on\nspecific scenarios, it increased perceived ease of use and human-like trust,\nparticularly benevolence. This suggests a positive impact on usability and an\nanthropomorphic effect on user perceptions. The study provides insights into\nhow specific labels can influence attitudes toward AI technology.",
        "updated": "2024-08-20 14:48:24 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.10905v1"
    },
    {
        "title": "BEYOND DIALOGUE: A Profile-Dialogue Alignment Framework Towards General Role-Playing Language Model",
        "authors": "Yeyong YuRusheng YuHaojie WeiZhanqiu ZhangQuan Qian",
        "links": "http://arxiv.org/abs/2408.10903v1",
        "entry_id": "http://arxiv.org/abs/2408.10903v1",
        "pdf_url": "http://arxiv.org/pdf/2408.10903v1",
        "summary": "The rapid advancement of large language models (LLMs) has revolutionized\nrole-playing, enabling the development of general role-playing models. However,\ncurrent role-playing training has two significant issues: (I) Using a\npredefined role profile to prompt dialogue training for specific scenarios\nusually leads to inconsistencies and even conflicts between the dialogue and\nthe profile, resulting in training biases. (II) The model learns to imitate the\nrole based solely on the profile, neglecting profile-dialogue alignment at the\nsentence level. In this work, we propose a simple yet effective framework\ncalled BEYOND DIALOGUE, designed to overcome these hurdles. This framework\ninnovatively introduces \"beyond dialogue\" tasks to align dialogue with profile\ntraits based on each specific scenario, thereby eliminating biases during\ntraining. Furthermore, by adopting an innovative prompting mechanism that\ngenerates reasoning outcomes for training, the framework allows the model to\nachieve fine-grained alignment between profile and dialogue at the sentence\nlevel. The aforementioned methods are fully automated and low-cost.\nAdditionally, the integration of automated dialogue and objective evaluation\nmethods forms a comprehensive framework, paving the way for general\nrole-playing. Experimental results demonstrate that our model excels in\nadhering to and reflecting various dimensions of role profiles, outperforming\nmost proprietary general and specialized role-playing baselines. All code and\ndatasets are available at https://github.com/yuyouyu32/BeyondDialogue.",
        "updated": "2024-08-20 14:47:38 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.10903v1"
    }
]