Sparse Regression for Discovery of Constitutive Models from Oscillatory Shear
Measurements
Sachin Shanbhag a)
∗
Department of Scientific Computing, Florida State University, Tallahassee,
FL32306. USA
Gordon Erlebacherb)
Department of Scientific Computing, Florida State University, Tallahassee,
FL32306. USA
Weproposesparseregressionasanalternativetoneuralnetworksforthediscoveryofpar-
simonious constitutive models (CMs) from oscillatory shear experiments. Symmetry and
frame-invariancearestrictlyimposedbyusingtensorbasisfunctionstoisolateanddescribe
unknown nonlinear terms in the CMs. We generate synthetic experimental data using the
Giesekus and Phan-Thien Tanner CMs, and consider two different scenarios. In the com-
pleteinformationscenario,weassumethattheshearstress,alongwiththefirstandsecond
normal stress differences, is measured. This leads to a sparse linear regression problem
that can be solved efficiently using l regularization. In the partial information scenario,
1
we assume that only shear stress data is available. This leads to a more challenging sparse
nonlinearregressionproblem,forwhichweproposeagreedytwo-stagealgorithm. Inboth
scenarios,theproposedmethodsfitandinterpolatethetrainingdataremarkablywell. Pre-
dictionsoftheinferredCMsextrapolatesatisfactorilybeyondtherangeoftrainingdatafor
oscillatory shear. They also extrapolate reasonably well to flow conditions like startup of
steady and uniaxial extension that are not used in the identification of CMs. We discuss
ramifications for experimental design, potential algorithmic improvements, and implica-
tionsofthenon-uniquenessofCMsinferredfrompartialinformation.
Keywords: constitutive models, large amplitude oscillatory shear, harmonic balance, ma-
chinelearning,sparseregression
a)Electronicmail: sshanbhag@fsu.edu[ correspondingauthor]
∗
b)Electronicmail: gerlebacher@fsu.edu
1
4202
guA
02
]tfos.tam-dnoc[
1v26701.8042:viXraI. INTRODUCTION
Industrially important soft materials such as polymer melts and solutions, colloidal suspen-
sions, gels, emulsions, foams, powders, etc., are non-Newtonian fluids.1 The viscoelasticity of
these complex fluids can be characterized by rheometry, in which the response of samples sub-
jectedtoprescribedstressordeformationprotocolsismeasuredexperimentally. Besidesproviding
insights into material structure and behavior, such rheological measurements can guide the selec-
tion or construction of tensorial constitutive models (CMs), which mathematically describe the
relationshipbetweenstressanddeformation.2,3 TheseCMs,alongwithconservationequationsfor
massandmomentum,canthenbeincorporatedintocomputationalfluiddynamics(CFD)software
to predict complex flows in process equipment such as mixers, pipe bends, contractions, injection
chambers, etc., under different operating conditions.4–6 Thus, from an industrial standpoint, the
developmentofreliableCMsforcomplexfluidscanevadecostlyandtime-consumingexperimen-
tation,andsignificantlyacceleratethedesignandscale-upofnewprocessesandproducts.
Traditionally, modelers use their experience and intuition to select a physically plausible CM.
Once a CM is chosen, experimental data is used to calibrate its parameters. The advantage of this
conventionalworkflow,especiallyforCMsbasedonmicroscopicphysics,isthattheparametersof
the model are physically interpretable. The disadvantage is the problem of abundance or scarcity:
SometimestherearetoomanyplausibleCMs,whileatothertimestherearenone. Statisticaltools
formodelselectionareavailabletodealwiththeproblemofabundance.7 Theproblemofscarcity
ismorechallenging. Apotentialrecoursethathasemergedinrecentyearsistheuseofrheological
datatodiscover theunderlyingCM.8–12
Several data-driven or machine learning (ML) techniques have been proposed for the fusion
of ML with CMs for rheological modeling, model identification, or calibration.13–18 A subset of
these studies have focused on the discovery of CMs,11,12,16,19 which is the primary objective of
thiswork. Thisenterpriseisimpededbyseveralobstacles:
(i) Data is limited: Powerful ML methods thrive on digesting large quantities of information,
and unearthing hidden patterns and correlations.20 In contrast, rheological experiments are
time-consuming, and the number of independent datasets n is typically modest (even for
ds
well-characterizedsoftmaterials,n 10 100). Thispaucityofdatamakesitchallenging
ds
≈ −
to avoid overfitting powerful ML models, while still capturing the complexity of material
behavior.
2(ii) Designing and training neural networks is an art: The vast majority of models that com-
bine ML with nonlinear CMs use artificial neural networks (NNs) as universal function
approximators.11–15,17 While the ubiquity and success of physics-inspired NNs clearly
demonstrates their versatility and utility as black-box approximators, the design of suit-
ablearchitecturesandtrainingprotocolsforoptimizingparametersrequirestrialanderror.21
There are additional difficulties presented by (i) lack of convergence guarantees,22 (ii) stiff-
nessofdifferentialequations,23,24 and(iii)sensitivitytonetworkhyper-parameters.25–27 The
typical strategy leans on advances in automatic differentiation by throwing a versatile op-
timizer like stochastic gradient descent or its variants at the problem. Unlike traditional
optimizationofconvexobjectivefunctions,thedifficultyofconvergenceandabsenceofthe-
oreticalguaranteesmakesdesigningandtrainingNNsadarkart.
(iii) CMs that violate physical constraints cannot be used in CFD software: Typically, ML is
usedtoselect,calibrate,ordiscoveraCMthatfitsrheologicaldatabyusingameta-heuristic
or generalized nonlinear CM as a scaffold (we adopt this approach as well). Ideally, flow
fields in rheometers used to collect rheological data are spatially uniform. CMs inferred
from such data might not extrapolate well to non-uniform flow fields in process equipment.
Unlessspecialcareistaken,CMsinferredusingMLarenotguaranteedtoobeyphysicalcon-
straints like symmetry and frame-invariance. For example, in the popular physics-informed
NNs (PINNs) framework, violation of conservation laws and physical constraints are pe-
nalized, but not strictly enforced.28 Consequently, CMs are not guaranteed to obey physical
constraints for all inputs. While such models may still be useful for interpolation between
trainingdatasets,evenminorviolationsofphysicalconstraintsmakesthempotentiallyunus-
able in CFD software. A notable exception is the approach of Lennon et al.11 that preserves
strict symmetry and frame-invariance. Consequently, we adopt certain elements of their ap-
proachinthiswork.
(iv) Inductive bias is desirable: A purely objective data-driven approach for discovering CMs
seems attractive at first glance, until we confront it with the paucity of data in rheological
characterization, and the inherent nonuniqueness of inferring a general CM based on only
a few measurements. More colloquially, when data is scarce, it can fit many stories, some
of which may be unnecessarily complicated or incorrect. Strict adherence to physical con-
straints and judicious inductive biases can reduce the search space of potential CMs. An
3inductive bias that animates this work is parsimony, the idea that simple models are prefer-
able to complex models. Simple models that do not violate physical constraints avoid over-
fitting,whichincreasestheoddsthattheyextrapolatesatisfactorilytonovelflowandprocess
conditions.
A. MotivationandLayout
TheprimarygoalofthisworkistodevelopaprotocolforthediscoveryoftensorialCMsfrom
modest-sizedrheologicaldatasetsthatcanthenbeembeddedintoCFDsoftware. Thus,westrictly
enforcephysicalconstraintslikesymmetryandframe-invariancebyrelyingontheoreticalworkon
tensorbasisfunctions(TBFs),whichareintroducedinsectionIIB.11 Thisstronglylimitsthetype
of nonlinear terms that can appear in a CM, and shrinks the set of spurious CMs that nevertheless
fitexperimentaldata.
WealsoembracetheideaofparsimonyinthehopeoffavoringsimpleinterpretableCMs. This
is accomplished by relying on sparse regression. A general introduction is provided in section
IIC, which is specialized for the task of CM discovery in section III. A radical departure from
previous work on ML for CMs is the complete avoidance of NNs. In addition to bypassing the
sensitiveandopaquechoicesindesigningandtrainingNNs,weaimtodevelopamoretransparent
framework with the expectation that different researchers confronted with the same experimental
datawillreliablyarriveatcomparableCMs. Furthermore,wewouldlikethemethodtobefastand
easytoimplement. Thus,ourobjectiveistolearntheCMinO(1hr)onadesktopcomputer,using
statistical techniques that do not require specialized hardware or ML training. Our overarching
goalistoestablishapathwaytodemocratizethediscoveryofCMsfromexperimentaldata.
To make progress on this ambitious task, we sharpen our focus by considering a narrower
probleminthiswork. Thekeyelementsofourapproachare:
• Synthetic experimental data: Oscillatory shear (OS) rheology offer a convenient experi-
mental route for systematically exploring the linear and nonlinear rheology of materials by
imposing a sinusoidal strain or stress. Instead of using data on real materials, we intention-
ally use synthetic data using well-established CMs for polymers. The advantage of using
synthetic data in a proof-of-concept study of this kind is that, unlike experimental data, the
‘true’ CM is known and can be compared against. This is helpful to characterize both the
promiseandinherentlimitationsofML.
4• Framework for learning CM: Frame-invariance imposes strict limits on the structure of the
time-derivativesinCMs(seeSectionIIA).29 Here,weuseanupper-convectedderivativeto
model the evolution of stress,2 and use data to learn the nonlinear terms of the CM. This
provides a framework in which data can be incorporated by selectively learning only the
unknown components of the CM. Furthermore, the unknown nonlinear term in the CM is
expressedusingTBFstopreservephysicalconstraints.
• SpectralmethodforsolvingnonlinearCMinOS:Weleveragearecentlydevelopedmethod
called FLASH (Fast Large Amplitude Simulations using Harmonic balance) to obtain the
periodic steady state (PSS) solution of arbitrary nonlinear differential CMs subjected to
OS flow.30 FLASH is a spectral method that is both fast and accurate, usually by orders
of magnitude compared to the standard method of numerical integration via time-stepping
methods.31,32 It solves for the PSS solution in Fourier space, which is a natural ansatz for
steadystateOSflow.
• Sparse Regression: We express the task of ML as a sparse regression problem.7 In special
situations where all stress components are measured, this simplifies to sparse linear regres-
sion. Linearity puts the problem on a mathematically firm footing, where approximations
and choices are automatically more transparent. Typically however, we end up with a more
formidable sparse nonlinear regression problem.33,34 FLASH is the linchpin of our strat-
egy in this scenario. Inspired by ideas of basis pursuit,35,36 we propose a simple greedy
algorithm37 inSectionIIIC.
Duetothelargenumberofabbreviationsandmathematicalsymbolsusedinthiswork,theyare
summarizedforreferenceinthesupplementarymaterialSectionS1.
II. BACKGROUND
A. ConstitutiveModelsandOscillatoryShear
Inconstitutive modelingofviscoelastic liquids,wefocus onthe dependenceofthe extrastress
tensorσ onapplieddeformation. Itcanberepresentedasa3 3matrix,orusingEinsteinnotation
×
as σ = σ ee σ e , where e , e , and e are unit vectors in Cartesian coordinates, and the
ij i j ij ij 1 2 3
≡
5combination e ee can be thought of as a 3 3 matrix whose only nonzero element is a one
ij i j
≡ ×
intheithrowand jthcolumn.
Physicsimposesimportantconstraintsontheformandevolutionofσ. Duetotheconservation
of angular momentum, σ is symmetric and has only six independent components.2 Due to the
principle of material frame indifference, CMs are frame invariant.29 This severely limits the pos-
sible forms for the time derivatives in CMs. Consequently, CMs are usually formulated in terms
of the upper-convected, lower-convected, and corotational derivatives, or combinations thereof.29
Theupper-convected,lower-convected,andcorotationalderivativesofσ aregivenby,
∂σ
σ▽ +v σ vT σ σ v, (1)
≡ ∂t ·∇ −∇ · − ·∇
∂σ
σ△ +v σ+σ vT + v σ, (2)
≡ ∂t ·∇ ·∇ ∇ ·
∂σ 1
σ◦ +v σ+ (Ω σ σ Ω), (3)
≡ ∂t ·∇ 2 · − ·
respectively, where v is the velocity field, v is the velocity gradient tensor, and Ω = v
∇ ∇ −
( v)T is the vorticity tensor. The upper-convected derivative defines the upper-convected
∇
Maxwell(UCM)model,whichisasimple,linearbutconceptuallyusefulmodelgivenby1
1
▽
σ + σ =Gγ˙, (4)
τ
where γ˙ =( v)T + v is the symmetric deformation gradient tensor. The UCM model has two
∇ ∇
material parameters: the relaxation time τ, and the shear modulus G. For homogeneous flows
such as those imposed in a rheometer, the stress field is uniform ( σ =0), and the UCM model
∇
simplifiesto
1
σ˙ vT σ σ v+ σ =Gγ˙, (5)
−∇ · − ·∇ τ
where σ˙ denotes the time-derivative dσ/dt. In standard OS experiments, a sinusoidal strain (or
stress) is applied, and the residual periodic stress (or strain) profile once the transient response
has decayed is recorded. This residual solution is called the limit cycle or the PSS solution. In
this work, we focus on OS strain experiments in which a sinusoidal strain γ(t) = γ sinωt of
0
amplitude γ and frequency ω is imposed with e and e being the shear and shear gradient
0 1 2
directions, respectively. Then, the velocity gradient tensor v = γ˙e and the shear rate tensor
12
∇
γ˙ =γ˙e +γ˙e ,wheretheshearrateγ˙=γ ωcosωt.
12 21 0
ThissimplifiestheUCMmodel(Equation5)inOSflowtoasystemoffourordinarydifferential
6equations
1
σ˙ + σ 2γ˙σ =0
11 11 12
τ −
1
σ˙ + σ =0
22 22
τ
1
σ˙ + σ =0.
33 33
τ
1
σ˙ + σ γ˙σ =Gγ˙. (6)
12 12 22
τ −
The other two components σ = σ = 0 due to the geometry of the imposed deformation. In
23 13
experiments,theperiodicshear,σ ,andnormalstressdifferencesN =σ σ andN =σ
12 1 11 22 2 22
− −
σ canbemeasured. Ifweassumeastress-freeinitialconditionσ(t=0)=0,thenσ (t)=0also
33 33
drops out, and we only have to track three independent components of σ, namely σ , σ , and
11 22
σ . Consequently,fromacomputationalstandpoint,thesecondnormalstressdifferenceN =σ
12 2 22
throughout this work. Since the UCM model is linear, Equation 6 can be solved analytically to
yieldthePSSsolution38
1 1
σ (t)=γ2 G(ω)+ G(ω)+ G(2ω) cos2ωt+ G (ω) G (2ω) sin2ωt
11 0 ′ − ′ 2 ′ ′′ −2 ′′
(cid:20) (cid:18) (cid:19) (cid:18) (cid:19) (cid:21)
σ (t)=γ G(ω)sinωt+G (ω)cosωt
12 0 ′ ′′
σ (t)=0,(cid:0) (cid:1) (7)
22
where the storage modulus G(ω) = Gω2τ2/(1 + ω2τ2), and the loss modulus G (ω) =
′ ′′
Gωτ/(1+ω2τ2). Although the UCM model is a conceptually useful model of viscoelasticity,
its ability to describe real materials is severely limited due to linearity. To overcome this lim-
itation, we can consider a generalized nonlinear differential CM based on the upper-convected
derivativeorthegeneralized UCMmodelas
1
σ˙ vT σ σ v+ σ+F(σ,γ˙)=Gγ˙, (8)
−∇ · − ·∇ τ
where F(σ,γ˙) is a nonlinear but frame-invariant tensor function. Many popular physics-based
CMs for polymer solutions and melts such as the Giesekus and the affine Phan-Thien Tanner
(PTT)modelsfitthismold.
IntheGiesekusmodel,39 F(σ,γ˙)takesaquadraticform,
α
G
F (σ,γ˙)= σ σ, (9)
Giesekus
Gτ ·
7where the dimensionless parameter α [0,1] controls nonlinearity. The Giesekus model was
G
∈
originally developed to describe the nonlinear viscoelastic behavior of polymer solutions in both
shear and extension. Subsequently, it has been applied to other systems such as worm-like
micelles40–44 andproteindispersions.45,46
Similarly,foraffineflow,thenonlineartermintheexponentialPTTmodelis47,48
f (σ) 1
PTT
F (σ,γ˙)= − σ, (10)
PTT
τ
wheretheextentofnonlinearityiscontrolledbyadimensionlessparameterε throughanexpo-
PTT
nentialfunctionofthetraceofσ,
ε
PTT
f (σ)=exp tr(σ) . (11)
PTT
G
(cid:16) (cid:17)
The PTT model for polymeric fluids is motivated by the Lodge-Yamamoto network theory,49,50
in which cross-links can be created and destroyed. The version described by Equation 10 ap-
plies for affine flows which assumes that there is no slip between the network and the continuous
medium. The dimensionless parameter ε [0,1] models the rate at which cross-links are de-
PTT
∈
stroyedinthenetwork.48 Typically,ε rangesfrom 0.02fordilutepolymersolutions,to 0.3
PTT
≈ ≈
for polymer melts. Values approaching ε 1 are considered unrealistic for describing real
PTT
≈
materials.51 The exponential form of the nonlinearity qualitatively reproduces experimental data
instrongflows,3 andmulti-modeversionsofthemodelhavebeenusedtodescribethebehaviorof
realmaterials.52–54
The ordinary differential equations corresponding to the Giesekus and PTT models in OS are
listed in supplementary material Section S2. Both the Giesekus and PTT models reduce to the
UCM model when α or ε are zero. However, unlike the UCM model, their OS response
G PTT
cannot be obtained analytically in general. The standard approach for obtaining PSS solutions
of nonlinear CMs subjected to large-amplitude oscillatory shear (LAOS) is numerical integration
usingasuitabletime-steppingmethodlikeRunge-Kutta.55 However,thisapproachcanbecompu-
tationally expensive because of the need for implicit methods to address numerical instability at
largevaluesofωτ andγ ,andtomitigatelongtransients.
0
Recently,wedevelopedafastandaccuratespectralmethodcalledFLASHtocomputethePSS
solution of any nonlinear differential CM subjected to OS strain.30 It is based on the technique of
harmonicbalance,31,32,56 whichusesFouriertransformstoconvertasystemofnonlinearordinary
differential equations into a system of nonlinear algebraic equations in the Fourier coefficients.
8FLASH couples harmonic balance with a numerical scheme called alternating-frequency-time,
which transforms the nonlinear terms in the CM to the frequency space and back during each
iteration of the solver. The mathematical ideas behind this approach are presented in Section S3
ofthesupplementarymaterial.
FLASHoffersaconvenientinterfacetoidentifytheOSresponseofarbitrarydifferentialCMs.
The methodology is not restricted to CMs based on the generalized UCM model (Equation 8),
although that is the form used here. As input, FLASH takes in a fully parameterized differential
CM, operating conditions (γ and ω), and a parameter H which specifies the ansatz. FLASH
0
exploits the even and odd symmetries of the normal and shear stresses, respectively, and resolves
them up to the (2H+1)th harmonic. Based on previous experience,30,32 we set H =8 throughout
thisworkforsimplicity,althoughthisassumptioncanbeeasilyrelaxedifrequired. FLASHshifts
the burden of setting up and solving the relevant set of harmonic balance equations from the
modeler to the computer. The most attractive attributes of FLASH in this work are its accuracy
and speed. In these benchmarks, FLASH typically outperforms numerical integration by 1–3
ordersofmagnitude.30–32
B. NonlinearConstitutiveModelsusingTensorBasisFunctions
Consider symmetric, frame-invariant 3 3 matrices F, A, and B, where F(A,B) is an arbi-
×
traryanalyticfunctionofAandB. UsingtheCayley-Hamiltontheorem(seeappendixA),F can
berepresentedasapolynomialofdegreetwoinAandB,57–60
F(A,B)=g I+g A+g B+g A2+g B2+g (AB+BA)
1 2 3 4 5 6
+g (A2B+BA2)+g (AB2+B2A)+g (A2B2+B2A2), (12)
7 8 9
where tensor dot products A A=A2 and A B =AB are equivalent to matrix multiplications.
· ·
The n =9 coefficients g are polynomials in the 10 invariants of A and B given by the traces
g i
{ }
ofthefollowing10matrices: A,B,A2,B2,A3,B3,AB,A2B,AB2,andA2B2. Thissetof10
matricescontainsallpossiblematrixproductsAiBj withi+ j 4.
≤
Equation12providesafinitesetofbasisfunctionswithwhichanysymmetric,frame-invariant,
smooth 3 3 matrix function can be represented. Lennon et al.11 recognized the importance of
×
this result for inferring nonlinear CMs from experimental data. They used the generalized UCM
model(Equation8)asascaffoldandrepresentedtheunknownnonlineartermF(σ,γ˙)asalinear
9TBFs invariants
T =I I =tr(σ)
1 1
T =σ I =tr(σ σ)
2 2
·
T =γ˙ I =tr(γ˙ γ˙)
3 3
·
T =σ σ I =tr(σ σ σ)
4 4
· · ·
T =γ˙ γ˙ I =tr(γ˙ γ˙ γ˙)
5 5
· · ·
T =σ γ˙ +γ˙ σ I =tr(σ γ˙)
6 6
· · ·
T =σ σ γ˙ +γ˙ σ σ I =tr(σ σ γ˙)
7 7
· · · · · ·
T =σ γ˙ γ˙ +γ˙ γ˙ σ I =tr(σ γ˙ γ˙)
8 8
· · · · · ·
T =σ σ γ˙ γ˙ +γ˙ γ˙ σ σ I =tr(σ σ γ˙ γ˙)
9 9
· · · · · · · · ·
TABLEI.Listoftensorbasisfunctions(TBFs)andinvariantsofσ andγ˙.
combinationofpolynomialsinσ andγ˙ accordingtoEquation12,leadingto
ng
F(σ,γ˙)= ∑g(L)T(σ,γ˙), (13)
i i
i=1
where T= T
i
is the set of TBFs, L= I i(σ,γ˙) is the set of invariants, and g = g
i
is the set
{ } { } { }
ofscalarcoefficientfunctions(SCFs),with1 i n . TheTBFsandinvariantsarelistedinTable
g
≤ ≤
I. Note that only 9 invariants (I) are listed instead of the 10 anticipated,57,59 because tr(γ˙) = 0 for
i
incompressiblefluids,eliminatingoneoftheinvariantsfromtheoriginalset.
Lennon et al. proposed a framework called rheological universal differential equations
(RUDE).11 UniversaldifferentialequationsrepresentamarriageofMLanddifferentialequations,
and embed universal functional approximators such as NNs within differential equations. By rep-
resenting the nonlinear term using Equation 13, the goal of inferring a nonlinear CM boils down
to learning the SCFs g (L) through g (L) by fitting experimental data. The RUDE framework
1 9
accomplished this task by modeling g(L) using a deep NN. Several advantages of this approach
wereobserved. Itworkedwellwithlimitedexperimentaldataanddifferentdeformationprotocols.
Italsoextrapolatedtoprocessingflowconditionssurprisinglywell.11
In this work, we restrict ourselves to OS measurements. As mentioned previously, γ˙ =γ˙e +
12
γ˙e has only two nonzero elements, and σ =σ e +σ e +σ e +σ e has only three
21 11 11 12 12 12 21 22 22
unique nonzero elements. This further simplifies the expressions for the TBFs and invariants (see
Appendix B): in particular, there are only n = 5 independent invariants, l=[l =I ,l =I ,l =
l 1 1 2 2 3
10I ,l = I ,l = I ] L. Thus, we can attempt to learn the SCFs g(L) from OS data using this
3 4 4 5 6
⊂
abridgedsetofinvariants.
C. SparseRegression
In this work, we infer g(L) (more precisely, g(l)) using sparse regression, instead of NNs, for
thefollowingreasons:
(i) a sparse regression model for g(L) with only a few nonzero algebraic terms (O(10)) is
potentiallyeasiertointerpretthanaNNwithO(103) O(105)parameters;
−
(ii) thefactthatSCFsarepolynomialscanbenaturallyembeddedintotheregressionprocess;
(iii) under special conditions in which all the nonzero stress components are measured, the op-
timization problem reduces to sparse linear regression (SLR), which permits a fast, robust,
andtransparentsolution(SectionIIIB);
(iv) under typical conditions in which only the shear stress is measured, the optimization prob-
lem leads to a non-convex sparse recovery problem, which can be approached with greedy
algorithms(SectionIIIC).
Welabelthescenarioinwhichallthenonzerostresscomponentsaremeasuredasthecomplete
informationorCIscenario. Inexperiments,thisincludestheshearstressσ ,thefirstnormalstress
12
differenceN ,andthesecondnormalstressdifferenceN . Thisrepresentsanidealizedcase,since
1 2
most OS experiments do not measure N due to experimental difficulties and only occasionally
2
report N . Therefore, for the more realistic scenario of partial information (PI) we assume that
1
only the shear stress (σ ) is available. Specific methods for CM discovery in these scenarios are
12
described in Section III. In the following, we provide a general introduction to SLR and sparse
nonlinearregression(SNLR).
1. SparseLinearRegression
Consider the linear least-squares (LS) solution of an over-determined linear system Mα=y,
where y = [y , ,y ]T is a vector of n observations, and M is an n p matrix of predictors
1 n
··· ×
with n p. The goal of linear LS regression is to find the combination α=[α , ,α ]T of the
1 p
≫ ···
11columnsofM thatmostcloselyresemblesy,i.e.,Mα y. Sincethesystemisover-determined,
≈
anLSsolutionattemptstosolvetheminimizationproblem
α =min Mα y 2, (14)
LS α ∥ − ∥2
where x represents the q-norm of vector x. The LS solution can be obtained by solving the
q
∥ ∥
normal equations, or using QR decomposition.55 Typically, most elements of the resulting α
LS
are nonzero, suggesting that all the columns of M are required to predict y. The preference for
parsimonycanexpressedbyrequiringαtobesparse,withmostentriesequaltozero.
A popular sparsity-promoting convex optimization technique called LASSO (least abso-
lute shrinkage and selection operator)61 or basis pursuit62 combines regularization and variable
selection.7,63,64 It appends an l regularization term to the LS objective function to penalize over-
1
fitting:
α =min Mα y 2+µ α . (15)
LASSO α ∥ − ∥2 ∥ ∥1
The magnitude of the parameter µ simultaneously controls the strength of variable selection and
regularization. As µ 0, α α . As µ ∞, the regularization term dominates the
LASSO LS
→ → →
objective function, and leads to the trivial solution α = 0. The optimal value of µ, which
LASSO
liessomewherebetweentheseextremes,seeksatrade-offbetweentheneedtodescribetheexper-
imentalobservationswell,theabilitytoposeawell-conditionedproblem,andtoproduceasparse
solution. Often, µ isselectedusingcross-validation.7,64
LASSO is a versatile regression technique that works for both over-determined (n p) and
≫
under-determined (p n) linear systems. In the latter case, it enables us to take a kitchen-sink
≫
approach by embedding all potential predictive information into the columns of M, relying on
LASSO to select the truly relevant set of predictors.64 This attractive property of LASSO to iden-
tify sparse solutions is sometimes called feature selection. Since LASSO combines variable se-
lection and shrinkage, the nonzero elements of α are biased toward zero. This bias can be
LASSO
reduced by using LASSO to identify the nonzero components, and refitting an unrestricted lin-
ear model or using LASSO again, only on the selected components.7 Many efficient algorithms
for finding α such as least angle regression,65 coordinate-wise optimization,66 and basis
LASSO
pursuit62 have been proposed. The cost per iteration is on the same order as linear LS regression,
i.e.,O(n3+np2/2).65
122. SparseNonlinearRegression
Consider y = f(z,α)+noise, where y R is a noisy response or output variable, z R is a
∈ ∈
covariateorinputvariable,andα Rp isavectorthatparameterizesthenonlinearmodel f(z,α):
∈
R ×Rp
→
R. Given a set of observations {y i }n i=1, corresponding to inputs {z i }n i=1, the sparse
nonlinearrecoveryproblemmaybeposedasminimizationofanLSlossfunction,
n
α =min∑(y f(z,α))2, subjectto α k, (16)
∗ i i 0
α − ∥ ∥ ≤
i=1
wherek pisapositiveintegerthatcontrolsthenumberofnonzeroelementsinαviathe0-norm
≪
α . Even ifthe l regularizationpenalty inEquation 16is replacedby anl regularizationterm
0 0 1
∥ ∥
(similar to Equation 15 in LASSO regression), we have to contend with a non-convex optimiza-
tion problem because f( ) is nonlinear.34 Compared to sparse linear regression, this is a much
·
harderproblem. Nevertheless,substantialtheoreticalprogresshasbeenmadeinestablishingsuffi-
cient and necessary conditions for the recovery of sparse or structured signals from relatively few
nonlinearobservations.33,67
Different algorithms inspired by sparse linear regression for compressed sensing applications
such as iterative hard thresholding, and basis pursuit have been adapted for sparse nonlinear
regression.68,69 Each iteration of a typical thresholding algorithm alternates between a regular
gradient descent step followed by a hard or soft thresholding step, in which all but the k largest
elements of α by magnitude are set or pushed toward zero.33,34,67,70 Since the sparse nonlinear
recoveryproblemisNP-hard,71 analternativeapproachinspiredbybasisormatchingpursuit,35,36
adoptsagreedyapproachinwhichlocallyoptimalchoicesareproposedateachiterationtoobtain
an approximate solution. In this class of methods,33,69,72 promising features of α are iteratively
markedforinclusiondependingonhoweffectivetheyareinreducingthelossfunctionlocally.
In the following, we customize SLR for the CI scenario in Section IIIB and SNLR for the PI
scenarioinSectionIIIC.
III. METHODS
Inthiswork,wefirstgeneratesyntheticdatawithdifferentcombinationsofstrainamplitudeand
frequency(γ ,ω)usingtheGiesekusandPTTmodels. WesetthelinearviscoelasticparametersG
0
and τ equal to one, so that they set the units of stress and time, respectively. We set the nonlinear
13d n n PFs
b α
0 1 9 B = 1
0
{ }
1 6 54 B =B l
1 0 i
∪{ }
2 21 189 B =B ll
2 1 i j
∪{ }
3 56 504 B =B ll l
3 2 i j k
∪{ }
4 126 1134 B =B ll l l
4 3 i j k m
∪{ }
TABLEII.PolynomialapproximationofSCFs g(l ,l ,l ,l ,l ) 9 withdegreed forn =5. Thenumber
{ i 1 2 3 4 5 }i=1 l
of unknown coefficients, n =9n . The set ll l denotes all unique products of invariants with 1
α b i j q
{ ··· } ≤
i,j, ,q n . Thus, ll =[l2,l l ,l l , ,l l ,l2,l l , l l ,l2, ,l2].
··· ≤ l { i j } 1 1 2 1 3 ··· 1 5 2 2 3 ··· 2 5 3 ··· 5
parameters α = 0.3 for the Giesekus model and ε = 0.3 for the PTT model. We generate
G PTT
n = 12 synthetic datasets from three different frequencies ωτ = 10 1,1,101 that span the
ds −
{ }
relaxation time (τ = 1), and four different strain amplitudes γ = 0.5,1,2,5 , focusing on the
0
{ }
mediumandlargeamplituderegimestoelicitavigorousnonlinearresponse. WeuseFLASHwith
H =8tocomputethePSSsolutionuptothe2H+1=17thharmonic. Fortherangeofparameters
andoperatingconditionsexploredinthiswork,themagnitudeoftheintensityofthe17thharmonic
relative to the 1st harmonic is less than 10 4. For each choice of (γ , ω), the periodic solution
− 0
(N =σ σ ,N =σ σ =σ ,andσ )isobtainedoveronecycleonauniformtemporal
1 11 22 2 22 33 22 12
− −
gridwithn =26 points.
t
Before we present specific methods to infer the SCFs g(l) for the CI and PI scenarios, we
discuss the approach to specify a set or dictionary of potential features with which to capture the
mathematicaldependenceoftheSCFs(g)ontheinvariants(l). Thisstepisrequiredforbothlinear
andnonlinearsparseregressions.
A. DictionaryofPolynomialFeatures
As mentioned in section IIB, for OS flow the SCFs g(l) are polynomials in n = 5 inde-
i l
pendent invariants, l = [l = I ,l = I ,l = I ,l = I ,l = I ]. Mathematically, we approxi-
1 1 2 2 3 3 4 4 5 6
mate g(l ,l ,l ,l ,l ) for i [1,n = 9] by restricting the representation of the polynomial fea-
i 1 2 3 4 5 g
∈
tures up to a specified degree. Let d be the degree of polynomial approximation for g, and let
n
B = B b denote the set of all unique polynomial combinations of the invariants with de-
d { j }j=1
14gree less than or equal to d. Let us make this notion more concrete by considering a toy example
with n = 2 invariants, l and l . If d = 2, then the set of n = 6 polynomial features (PFs) is
l 1 2 b
B = 1,l ,l ,l2,l2,l l . The elements of B constitute n PFs, B (l) n b . As d and n in-
2 { 1 2 1 2 1 2 } d b { j }j=1 l
crease, n also increases. In general, the number of PFs n can be expressed using the binomial
b b
coefficientas
(n +d)!
n =n l+dC = l . (17)
b d
n !d!
l
Inthetoyexample,n =2andd =2. Thus,therearen =4!/(2!2!)=6PFsinB . Weapproxi-
l b 2
matetheithSCFas
n
b
g(l)= ∑α B (l), where1 i n =9. (18)
i i,j j g
≤ ≤
j=1
Thecoefficients(α )arethen =n n unknowns. Inthetoyexample,thisimplies,
i,j α g b
g(l ,l )=α +α l +α l +α l2+α l2+α l l . (19)
i 1 2 i,1 i,2 1 i,3 2 i,4 1 i,5 2 i,5 1 2
DiscoveryoftheCMfromexperimentaldataisthusreducedtodeterminingthen coefficients.
α
ForOSexperiments,n =6,21,or56andn =54,189,and504,ford=1,2,or3,respectively
b α
(seeTableII).Althoughthisincreasewithd mayseemexplosive,arelativelysmalld oftensuffices
to describe highly nonlinear behavior because most of the invariants and TBFs are themselves
nonlinear. As we shall see shortly, d = 0 is sufficient to describe the Giesekus model. Even the
exponentialPTTmodelcanbeapproximatedbyd =1,undersuitableconditions.
Thus, the number of unknown coefficients n is modest, especially when compared to the
α
number of parameters in deep NNs. In sparse regression, most of these coefficients turn out to
be zero. In what follows, we use the symbol α to denote the vector in which these coefficients
are stacked. Depending on the context, these elements are indexed as α where i [1,n ] and
i,j g
∈
j [1,n ], or simply as α where k =(i 1)n + j [1,n ]. Computationally, this is equivalent
b k b α
∈ − ∈
toreshapingαintoamatrixoravector.
B. InferenceunderCompleteInformation
Let begin with the simpler case of CI in which raw data consists of the n = 3 nonzero stress
σ
components,σ ,σ ,andσ reportedatthen differentsettingsoffrequencyandstrainampli-
11 22 12 ds
tude (see Figure 1). In an actual experiment, this implies that, in addition to shear stress, both N
1
and N are also measured. For each dataset in this scenario, we report the PSS profiles obtained
2
15raw data processed data SLR pipeline
FIG. 1. Schematic of SLR in the CI scenario. Raw data is processed to obtain the nonlinear term F in
the generalized UCM model. The TBFs and invariants are evaluated using σ and γ˙. Once the degree d of
polynomial approximation is selected, the set of PFs B can be computed to formulate a linear system of
d
equationsintheunknowncoefficients(α).
via FLASH at n =26 equispaced points over a period of oscillation, t [0,2π/ω]. Thus, all the
t
∈
componentsofσ areeffectivelyknown,sincecomponentsthatarenotdirectlyspecifiedcaneither
beinferredfromsymmetry(σ =σ )orsetequaltozero(allothercomponents).
21 12
Sinceγ˙ andσareknown,wecansubstitutethemintothegeneralizedUCMmodel(Equation8)
toisolateandevaluatethenonlineartermF(σ,γ˙)foreachdataset p [1,n ],
ds
∈
(p) 1
F(p)(σ(p),γ˙(p))=Gγ˙(p) σ▽ + σ(p) . (20)
− τ
(cid:18) (cid:19)
F issymmetricandframe-invariantlikeσ,andforOSflowithasn =3independentcomponents
σ
– F (t), F (t), and F (t) – that are also periodic functions. The time-derivative σ˙ required to
11 12 22
obtain F(p) in Equation 20 is computed by first transforming σ(t) into Fourier space to obtain
σˆ(ω),andtruncatingbeyondthe(2H+1)thharmonic. WerepresentsuchtruncatedFouriercoef-
ficientsusinga“hat”. Next,wetaketheinverseFouriertransformofiωσˆ(ω)toobtainσ˙(t). Both
thesestepsareimplementedefficientlyusingfastFouriertransforms(FFT).
The TBFs T(t) and invariants l(t) are also periodic and can also be evaluated using γ˙ and
σ using equations described in Appendix B. Thus, F(t), T(t), and l(t) are periodic functions
that can be provided for each data set using σ(t) and γ˙(t). The nonlinear term F can then be
16
stesatad
.
.
.
.
.
.approximatedusingEquations13and18as
ng ng n
b
F(t;σ,γ˙)= ∑g(l(t))T(t) ∑ ∑α B (l(t))T(t). (21)
i i i,j j i
≈
i=1 i=1j=1
n
When the polynomial approximation degree d is assumed, the PFs B = B b are specified.
d { j }j=1
Equation 21 is a linear regression problem in the unknown coefficients α, since all the other
quantitiescanbeevaluatedusingγ˙ andσ.
Letusnowmathematicallydefinethelossfunctionthatweseektominimize. Thelossfunction
canbeexpressedasthesumofsquaredresiduals(SSR)overalltheobservations:
1 n ds nt ng n b 2
χ2(α)= ∑ ∑ F(p)(t ) ∑ ∑α B(p) (t )T(p) (t ) . (22)
2 k − i,j j k i k
p=1k=1(cid:13) i=1j=1 (cid:13)
(cid:13) (cid:13)
(cid:13) (cid:13)
It involves summation over five indic(cid:13)es: i [1,n
g
= 9] over the SCFs, j (cid:13)[1,n b] over the PFs,
∈ ∈
k [1,n =26]overthediscretetimepoints,and p [1,n ]overthedifferentdatasets(ω(p),γ(p) ).
∈ t ∈ ds 0
InEquation22,thesquarednormofa3 3symmetricmatrixAwiththreeindependentnonzero
×
elements A , A and A is defined as A 2 = A2 +A2 +A2 . The quadratic dependence of
11 22 12 ∥ ∥ 11 22 12
χ2(α) on α leads to the linear LS problem Mα=F , where α is an n dimensional vector of
v α
unknown coefficients, F is a vector with n =n n n elements of “observations” F(p)(t ), and
v Fv ds σ t k
M isan n matrixwhoseelementsareobtainedfromtheinvariants,PFs,andTBFs.
Fv× α
LASSOcanthenbeusedtoseekasparsesolution,
α =minχ2 (α,µ), (23)
LASSO LASSO
α
whereanl regularizationtermisappendedtothelossfunction,
1
ng n
b
χ2 (α,µ)=χ2(α)+µ ∑ ∑ α . (24)
LASSO | i,j |
i=1j=1
We find the optimal value of µ by 5-fold cross-validation using the built-in function LassoCV
from the linear model module of the Python machine learning library scikit-learn version
1.11.73 This implementation uses coordinate descent to fit the unknown coefficients and a duality
gapcalculationtocontrolconvergence.66,74
LASSO automatically identifies the most important PFs and sets α =0 for other features.63
i,j
Thus,evenifwespecifyalargenumberofredundantPFs,LASSOisolatesthehandfuloffeatures
that primarily explain the observations. This helps to investigate the source of nonlinearity when
the underlying CM is unknown. The algorithm used for the CI scenario is summarized as Algo-
rithm1. Asinput,ittakesinexperimentaldatawhichincludestheoperatingconditions(ω,γ )and
0
17thecomponentsofσ(t)foreachdataset. Thedegreeofpolynomialapproximationd isalsospeci-
fiedasinput. TherawexperimentaldataareprocessedtoobtainthenonlineartermF(σ,γ˙)which
eventually forms the right-hand side F of the linear system. The matrix M requires TBFs and
v
invariants that are reconstructed from experimental data, and the set of polynomial features B ,
d
which are constructed using the invariants and d. The optimal value of the regularization parame-
ter µ isfoundusing5-foldcross-validation,andthesparsesolutionα isobtainedbyminimizing
∗
χ2 inEquation24.
LASSO
Algorithm1:SLRtoinferα intheCIscenario.
∗
Input: (ω(p),γ(p) )and σ(p) (t ),σ(p) (t ),σ(p) (t ) nt for p=1, ,n datasets,degreeof
0 { 11 k 22 k 12 k }k=1 ··· ds
polynomialapproximationd.
Result: vectorα ∗ toapproximateSCFsg(l)
/* Loop over datasets */
for p 1ton do
ds
←
useFFTandinverseFFTtocomputethetime-derivatives σ˙(p) (t ),σ˙(p) (t ),σ˙(p) (t ) nt
{ 11 k 22 k 12 k }k=1
isolateandevaluatethenonlineartermF(p) (Equation20)
furnishTBFsT(p),invariantsl(p),andPFsB d(l(p))
end
assembledataintoalinearsystemMα=F
v
use5-foldcross-validationtodetermineregularizationparameterµ
solveforα usingLASSOregression
∗
C. InferenceunderPartialInformation
Once a degree of polynomial approximation d is selected, the resulting approximation to the
nonlinear term (Equation 21) can be substituted into the generalized UCM model (Equation 8) to
definetheTBF-CMas
1
ng n
b
σ˙ vT σ σ v+ σ+∑ ∑α B (σ,γ˙)T(σ,γ˙)=Gγ˙. (25)
i,j j i
−∇ · − ·∇ τ
i=1j=1
TheTBF-CMisaspecialcaseofthegeneralizedUCMmodelliketheGiesekusandPTTmodels.
ThenonlineartermsoftheGiesekusandPTTmodelsareparameterizedbyasinglecoefficient(α
G
18andε ,respectively). Ontheother,thenonlineartermoftheTBF-CMisparameterizedbyaset
PTT
ofcoefficientsαthatarelikewiseindependentofγ andω. Inotherwords,αisamaterialproperty
0
that is independent of the flow field. If α is specified, then the TBF-CM is a fully parameterized
nonlinear differential CM. This implies that we can use FLASH to solve for the PSS solution
σ of the TBF-CM given α and γ˙. FLASH relying on harmonic balance, internally transforms
the resulting system of nonlinear differential equations into Fourier space and returns the Fourier
coefficientsσˆ ofthePSSsolutiontruncatedbeyondthe(2H+1)thharmonic.
WhileitiseasytouseinverseFFTtocomputethetime-domainrepresentation,itispreferableto
workinFourierspaceforafewreasons. First,wecantakeFouriertransformsofanyexperimental
data in the time domain to obtain σˆ . A byproduct of this operation is that the high-frequency
exp
noise in σ (t) is filtered. Second, the Fourier space provides a natural basis for describing
exp
periodic signals. A byproduct of this choice is that it allows us to compress data by exploiting the
correlationbetweensuccessivetime-domainsnapshotsofσ.
In summary, given coefficients α and the deformation gradient tensor γ˙ for OS flow, we
can efficiently find the PSS σˆ(α,γ˙) by solving the TBF-CM using FLASH. Discovering a CM
from experimental data corresponds to the inverse problem, i.e., inferring a sparse α that yields
σˆ(α,γ˙) σˆ (γ˙).
exp
≈
1. ExperimentalDataandLossFunction
Similarly to the CI scenario, we generate n = 12 synthetic experimental datasets by using
ds
FLASH to solve the PTT model for σ (t) (or σˆ ) in OS flow using ε = 0.3 with H = 8
exp exp PTT
and n =26. However, we ignore some of the components of the stress tensor in the PI scenario.
t
Wepretendthatweonlyhaveaccesstoshearstressσ anddiscardinformationregardingnormal
12
stressesσ andσ .
11 22
(p)
Let [σˆ ] denote the Fourier coefficients of the experimental PSS shear stress profile corre-
12 exp
spondingtothe pthdataset(1 p n )withthedeformationgradienttensorγ˙(p) definedbythe
ds
≤ ≤
(p) (p)
imposed strain frequency and amplitude. Only the subset [σˆ ] σˆ is used for inference.
12 exp ⊂ exp
Once we choose a degree of polynomial approximation d, the size of the coefficient vector α is
determined. Let σˆ(p) (α,γ˙(p)) denote the Fourier coefficients of the shear stress profile predicted
12
bytheTBF-CMwithcoefficientsαanddeformationgradienttensorγ˙(p).
We can evaluate how well a particular guess for α matches experimental measurements by
19definingaLSlossfunctioninFourierspacethatsumsoverallthedatasets,
n
1 ds 2
χ2(α)= ∑ [σˆ(p) ] σˆ(p) (α,γ˙(p)) . (26)
F 2 12 exp − 12 2
p=1
(cid:13) (cid:13)
(cid:13) (cid:13)
(cid:13) (cid:13)
Recall that both, [σˆ(p) ] and σˆ(p) (α,γ˙(p)), are vectors of the same size. It is possible to find
12 exp 12
an optimal α by attempting to minimize χ2(α) using nonlinear LS. However, we do not pursue
F
thisdirectapproachbecauseitdoesnotimposesparsityonα,andiscomputationallychallenging.
Unlike the CI scenario, minimization of χ2(α) requires us to solve for σˆ (α,γ˙) under each of
F 12
then operatingconditionsduringeachiteration. Ifthecostperiterationwereproportionalton ,
ds ds
it would not pose a major challenge for datasets of modest size, say n O(10) O(100) due
ds
∼ −
to the speed of FLASH. However, if we use a minimizer that numerically computes the gradient
∇ χ2 toaccelerateconvergence,55 thecomputationalcostrisessharplyfromO(n )toO(n n )
α F ds ds α
periteration,whichcanbecomeexorbitant(seeSectionVBforapotentialsolution).
2. SparseNonlinearRegression
RecallthattheSNLRproblem,fashionedafterEquation16,maybeformulatedas
α =minχ2(α), suchthat α k. (27)
∗ F 0
α ∥ ∥ ≤
We propose a simple greedy algorithm, schematically illustrated in Figure 2, to determine a
sparse α . It is inspired by basis pursuit methods which attempt to identify and retain only the
∗
most promising features. We divide the task of inferring α into two parts. In the first stage, we
∗
explore the potential of each individual element α α, where j [1,n ], to capture the data.
j α
∈ ∈
In the second stage, we perform sparse nonlinear LS regression using only the k most promising
indices/coefficients.
In the following, let e denote a unit vector of size n with a single nonzero element at the
j α
location j [1,n ]. In other words, the jth element of e is one, while the rest are equal to zero
α j
∈
(similar to ‘one hot encoding’ in ML). Then, α˜ =αe denotes a coefficient vector with a single
j j
nonzero element. In the first stage, we can perform a nonlinear LS minimization of χ2(α˜ ) and
F j
determine the optimal value α˜ , for each j [1,n ]. This is an independent 1D optimization for
∗j
∈
α
each coefficient that can be readily parallelized. For each 1D optimization, the cost per iteration
is O(n ) making the total cost n times the cost of each 1D optimization. Note that this is
ds α
20fit
exp
optimize one coefficient at a time
optimize k promising
coefficients together
first stage: select k promising coefficients second stage
FIG. 2. Schematic of the greedy two-stage SNLR algorithm for the PI scenario. The first stage identifies
thesetP ofthek mostpromisingcoefficientsbyperformingn 1Doptimizations. Sparsityisimposedby
k α
choosing k n . In the second stage, a k-dimensional optimization is performed by restricting the set of
α
≪
nonzeroelementsinαtoP. Althoughdataandpredictionsarerepresentedinthetimedomain,optimization
k
isperformedinthefrequencydomaininAlgorithm2.
significantlybetterthanO(n n )periteration,sincethecostperiterationdoesnotdependonn ,
ds α α
andtheoverallcostcanbesharedbetweenmultipleprocessors.
Promisingcoefficientsareoperationallydefinedascoefficientsthatresultinsmallvaluesofthe
lossfunction χ2(α˜ ). Wesort χ2(α˜ )for j [1,n ]inascendingorderandconsideronlythetop
F ∗j F ∗j ∈ α
k n coefficients. Let P denote the list of indices of these top k most promising coefficients.
α k
≪
The elements of P are integers j [1,n ] that mark the locations of these coefficients. The goal
k α
∈
ofthefirststageistofurnishP .
k
In the second stage, we perform a nonlinear LS regression to minimize χ2(α), where sparsity
F
isimposedonαbyconstruction. Thatis,weset
α= ∑ α e , (28)
j j
j P
k
∈
where the summation runs over the list of k elements in P . Thus, α has only k nonzero elements
k
correspondingtothemostpromisingindices. ThecostperiterationatthisstageisO(kn ),where
ds
k n .
α
≪
21
stesatad
.
.
.
. . .
.
.
.
. . .
.
.
.
.
.
.We solve all nonlinear minimization problems using the default trust-region reflective algo-
rithmasimplementedinthescipy.optimizelibrary.75 Forunboundedoptimization,usedinthis
work, this implementation is quite robust and similar to the implementation in MINPACK.76,77
The derivatives are computed numerically using a 2-point scheme. Algorithm 2 summarizes the
steps sketched in Figure 2. Input data consists of the Fourier coefficients of the shear stress and
operating conditions (ω,γ ) for each dataset. The degree of polynomial approximation d and
0
number of nonzero coefficients k are also provided as input. Note that it is possible to determine
a judicious value for k n by examining the outcome of the first stage, in which the ability of
α
≪
each coefficient to describe experimental data is explored. The second stage performs a regular
nonlinearLScalculationbyallowingonlythek mostpromisingcoefficientstobenonzero.
Algorithm2:GreedyalgorithmforSNLRtoinferα inthePIscenario.
∗
Input: γ˙(p) and[σˆ(p) ] for p=1, ,n ;degreeofapproximationd;numberofnonzero
12 exp ··· ds
coefficientsk.
Result: vectorα ∗ toapproximateSCFsg(l)
determinen fromd (Equation18).
α
/* Stage 1: find promising coefficients using 1D optimization */
for j 1ton do
α
←
letα˜ =αe .
j j
minimize χ2(α˜ )anddetermineα˜ and χ2(α˜ ).
F j ∗j F ∗j
end
argsortthelossfunctions χ2(α˜ ) nα inascendingorder
{ F ∗j }j=1
createlistP thatmarkstheindicesofthetopkmostpromisingcoefficients
k
/* Stage 2: find sparse solution with promising coefficients */
considersparseα=∑
j
∈Pkα je
j
withknonzeroelements
minimize χ2(α)todetermineα
F ∗
IV. RESULTS
Asmentionedpreviously,wegeneratedn =12syntheticdatasetsfortheGiesekus(α =0.3)
ds G
and PTT (ε = 0.3) models and computed the PSS solution using FLASH with H = 8 and
PTT
220.3
11 10
22
0.2 12 8
6
0.1
4
0.0 2
0
0.1
(1.0, 1.0) 2 (5.0, 1.0)
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
ωt/2π ωt/2π
(a)γ =1,ωτ =1 (b)γ =5,ωτ =1
0 0
FIG.3. GiesekusmodelinCIscenario. ComponentsofthenonlineartermF(t)(Equation13)atωτ =1
and(a)γ =1and(b)γ =5. Thecrossesandplussignsshowsyntheticdata,towhich20%relativenoise
0 0
isadded. LinesshowfitsobtainedusingSLR.
n =26. WedescribetheresultsfortheCIscenario,followedbytheresultsforthePIscenario.
t
A. CompleteInformation
1. GiesekusModel
In the CI scenario, all components of the stress tensor are known, which allows us to evaluate
thenonlineartermF(σ,γ˙). WeaddedarelativeGaussiannoiseof20%tothenonlinearsignal(F)
for the Giesekus model, as illustrated in Figure 3 for two of the n =12 datasets. We perturbed
ds
F insteadofσ becausefilteringnoisefromrawexperimentaldatausingstandardFourieranalysis
isafairlycommonpractice. Wesetthedegreeofpolynomialapproximationd =2,whichimplies
that the number of PFs is n =21. The set of features includes one constant (1), five linear terms
b
( l 5 ), and 15 unique quadratic ( ll 5 ) terms. The number of unknowns (size of α) is
{ i }i=1 { i j }i,j=1
n =n n =189.
α g b
To contextualize the results of SLR, it is helpful to first consider the representation of the
Giesekus model in terms of the TBFs. The form of the nonlinearity in the Giesekus model
(Equation 9) coincides with one of the TBFs namely T =σ σ (see Table I). Thus, F =
4 Giesekus
·
α /(Gτ)T ,whichimpliesthatg (l)=α /(Gτ)isaconstant,whileallotherSCFsarezero,i.e.,
G 4 4 G
g(l)=0fori=4.
i
̸
23
F F5.0 5.0
2.0 2.0
γ γ
0 0
1.0 1.0
0.5 0.5
0.1 1.0 10.0 0.1 1.0 10.0
ωτ ωτ
(A)Giesekus (B)PTT
FIG.4. PipkindiagramshowingtheelasticLissajous-Bowditchcurvesfor(A)theGiesekus(α =0.3)and
G
(B) PTT models. Similar to Figure 3, 20% relative noise is added to F. Symbols depict the normalized
shear stress (σ /max(σ )) versus normalized strain (γ/γ ), while lines depict the predictions of the CM
12 12 0
discoveredusingSLR.
Asexpected,usingAlgorithm1,wefindthatonlyoneofthese189coefficients(namelyα )is
4,1
nonzero. Theregressedvalueofα =0.2988 α /(Gτ)showsthatthistechniqueidentifiesthe
4,1 G
≈
true CM, at least for this simple example. The coefficient of correlation R2 =0.97. This example
serves as a validation test of the proposed method. Furthermore, this calculation is fast, since the
problem is linear. It took about 0.5 sec on an old commodity desktop computer (Intel i7-6700 3.4
GHz CPU). Recall that the CI scenario, unlike the PI scenario, does not require the computation
ofthePSSsolutionusingFLASHornumericalintegrationtofindtheoptimalsetofcoefficients.
AnelasticLissajous-Bowditchcurveisaparametricplotofstressversusstrain. Figure4depicts
aPipkindiagramwhichisatableofnormalizedelasticLissajous-Bowditchcurvesforthen =12
ds
datasets. Here,theshearstress(σ componentofσ),normalizedbyitsmaximumvalue,isplotted
12
againstthenormalizedstrainγ(t)/γ =sinωt. Symbolsdenotesyntheticdata(20%relativenoise
0
isonlyaddedtoF),whilelinesshowtheTBF-CMwhichisnearlyidenticaltothetrueCMinthis
case.
Inatypicalusecase,F isnotnoisysincethemeasuredsignal(σ)canbefilteredusingFourier
analysis. If we use a noiseless F as input, then the true CM α =0.3=α /(Gτ) is discovered
4,1 G
24using Algorithm 1. The true CM with a single nonzero component is discovered even when we
increase d = 3 corresponding to n = 506, or d = 4 corresponding to n = 1134. As expected,
α α
thecomputationaltimeincreaseswithd asthesizeoftheregressionproblemincreases. TheCPU
timeincreasesfrom 0.5sford =2to 1sford =3and 3sford =4.
∼ ∼ ∼
Thus,wevalidatedAlgorithm1fortheGiesekusmodelandfoundthatitisabletodiscoverthe
trueCMintheCIscenariousingonlythePSSstressprofilefordatasetsofmodestsize(n =12).
ds
Indeed, for the Giesekus model, which has a particularly simple representation in terms of the
TBFs, we found that synthetic data generated at a single value of γ
0
≳2 (that is, n
ds
= 3, due to
three frequencies) were sufficient to discover the true CM. The value of γ must be large enough
0
to trigger a detectable nonlinear response, otherwise F 0 does not contain enough information.
≈
SLR is remarkably fast and fairly robust (it is not particularly sensitive to perturbations 20% in
∼
F),becausetheoptimizationproblemiswellposed.
While this example provides a glimpse of the promise of this method, caution is warranted.
First, the CI scenario is not representative of practical problems. Second, the Giesekus model
plays into the strengths of the method because of its simple structure. Therefore, we consider the
PTTmodelundertheCIscenarionext,beforemovingtotheharderproblemofPI.
2. PTTModel
As before, we generated n = 12 synthetic datasets using the exponential PTT model with
ds
parameter ε = 0.3. We set d = 2 and obtained the nonlinear term F(σ,γ˙). Of the n =
PTT α
189 possible coefficients, Algorithm 1 identified only two nonzero components of α. Both these
coefficients, namely α = 0.306 and α = 0.020, correspond to the SCF g . All other SCFs
2,2 2,5 2
werezero. Therefore,accordingtoSLR,thenonlineartermcorrespondingtodatageneratedfrom
thePTTmodelis,
FSLR =g T =(0.306I +0.020I )σ, (29)
PTT 2 2 1 4
where I = tr(σ) and I = tr(σ σ σ). The Pipkin diagram comparing the experimental elastic
1 4
· ·
Lissajous-BowditchcurveswiththeinferredCMisshowninFigure4B.
Unlike the Giesekus model, the exponential PTT model cannot be easily decomposed in terms
of TBFs, except in special situations. In the limit of small ε and I /G, the nonlinear term can
PTT 1
25beapproximatedas
ε
PTT
F =
exp G I 1 −1
σ
ε PTT
I
+1ε P2 TTI 12
T . (30)
PTT (cid:16) τ (cid:17) ≈ Gτ 1 2 G2τ 2
(cid:20) (cid:21)
Termsoforder(ε I /G)3andhigherareneglectedintheTaylorseriesexpansioninEquation30.
PTT 1
Thus, the only nonzero SCF is g , which only depends on I . Comparison of g in eqns 29 and
2 1 2
30 indicates that the prefactor to I (0.306) is comparable with ε /(Gτ) = 0.3. However, the
1 PTT
second term in Equation 29, 0.020I , is different from the 0.045I2, expected from Equation 30.
4 1
Interestingly,if weuseε =0.1instead of0.3to generatethesynthetic datasets,SLR identifies
PTT
asinglenonzerocoefficientandFLASSO =0.309I σ,whichissimilartoEquation30.
PTT 1
As in the Giesekus model, increasing the polynomial approximation to d = 4 effectively dis-
covers the same TBF-CM, but takes 2.5 s instead of 0.5 s for d = 2. Unlike the Giesekus
∼ ∼
model,asingleLAOSdatasetisnolongersufficienttoinfertheCM.Withsomeexperimentation,
wefoundthattheCMwithanonlineartermgivenbyEquation29isusuallydiscovered,evenifwe
use only three values of γ instead of four, e.g. γ = 0.5,1.0,2.0 . That is, n =9 appears to be
0 0 ds
{ }
sufficient for the PTT model. The key generalizable lesson from these examples for experimental
designistocollectsufficientdataintheLAOSregime(roughly,γ
0
≳1).
B. PartialInformation
In this section, we demonstrate the application of the SNLR algorithm (Algorithm 2) to syn-
thetic data obtained using the PTT model with ε = 0.3 under n = 12 different operating
PTT ds
conditions. However,unliketheCIscenario,weonlyuseshearstressdataforinference. Wefocus
on the PTT model because it produces more interesting results and offers generalizable lessons
thatarerelevantforCMdiscovery. ResultsfortheGiesekusmodelarerelegatedtosupplementary
materialSectionS4.
Asbefore,wesetd =2,whichimpliesn =189. Inthefirststage,wescanthroughα˜ for j
α j
∈
[1,n =189]byperformingn independent1Dnonlinearminimizationstoobtainoptimalvalues
α α
α˜ andthecorrespondinglossfunctions χ2(α˜ ). Theaveragecostofeachoftheseminimizations
∗j F ∗j
was 25.2 16.4 s, or approximately half a minute. On a computer with a single core, the first
±
stage can be completed in about an hour and a half. On a workstation with 16 cores, this cost
reducestoalittleunder6minutes,duetotheeaseofparallelization.
261.2
1.0
0.8
0.6
0.4
g g g g g g g g g
1 2 3 4 5 6 7 8 9
0.2
0.0
50 100 150
j
FIG. 5. Loss functions χ2(α˜ ), where j [1,n =189], obtained after the first stage of Algorithm 2 with
F j ∈ α
d =2. The gray vertical lines demarcate the coefficients that belong to different SCFs. The upper limit
of the graph is truncated to emphasize the spread among promising coefficients. The cluster of red stars
correspondstothefoursmallestvaluesofχ2(α˜ ),andhighlightsthek=4mostpromisingcoefficients.
F j
The computational cost is proportional n , which implies that the cost of the first stage in-
α
creases rapidly with d. If we increase the degree of approximation from d = 2 to d = 4, the
total computational cost increases 6x, assuming that the average cost per minimization remains
unchanged. On a workstation with 16 cores, the total runtime for the first stage increases to about
40minutes.
The χ2 corresponding to the most promising coefficients is shown in Figure 5. The first stage
F
correctlyidentifiestheimportanceofg forthePTTmodel. Thetopk=4mostpromisingcoeffi-
2
cients form a distinct cluster with χ2 <0.1, and are indicated by red stars. In order of increasing
F
χ2, these coefficients, namely α α , α α , α α , and α α , correspond to
F 2,7 ≡ 28 2,3 ≡ 24 2,8 ≡ 29 2,5 ≡ 26
PFsI2,I ,I I ,andI ,respectively.
1 2 1 2 4
ForthesecondstageofAlgorithm2,inadditiontok=4,wealsoentertainedtheideaofretain-
ingonlythetopk=3coefficientstoexplorethepossibilityofmultiplesolutions,andsensitivityto
thechoiceofk. Thus,weconsideredtwodifferentsetsofnonzerocoefficients,P =[28,24,29,26],
4
and P =[28,24,29]. That is, in the set P , we picked the top k =4 most promising coefficients,
3 4
27
2χ FTBF-CM-k3 TBF-CM-k4
FIG.6. PILAOSTraining. FitsoftwodifferentTBF-CMs(dashedandlightsolidlinescorrespondtoTBF-
CM-k4andTBM-CM-k3respectively;seetextfordetails)tosyntheticdatageneratedfromthePTTmodel
withε =0.3(symbols). Onlyshearstressdata(blue)areusedtoinfertheTBF-CMs,butpredictionsof
PTT
N (black)andN (purple)arealsoincludedforcomparison.
1 2
whileinthesetP ,weselectedonlythetopk=3mostpromisingcoefficients. Wethenperformed
3
a nonlinear regression that allowed only these coefficients to vary and ended up with two distinct
28TBF-CMs. Theycorrespondto,
FSNLR = 0.3375I 0.1637I 0.2770I2+0.1794I I T
k4 2 − 4 − 1 1 2 2
FSNLR =(cid:0)0.2461I 0.2174I2+0.0114I I T . (cid:1) (31)
k3 2 − 1 1 2 2
(cid:0) (cid:1)
Hereafter,welabelthesetwoTBF-CMsasTBF-CM-k4andTBF-CM-k3. Thecomputationalcost
of the second stage of the SNLR algorithm is relatively small compared to that of the first stage.
For instance, TBF-CM-k4 required 8 iterations which took 40 sec, while TBF-CM-k3 required
∼
only 6 iterations, which took 25 s. The final values of the loss function χ2 after optimization
∼ F
were1.39 10 3 and3.04 10 3 forTBF-CM-k4andTBF-CM-k3,respectively.
− −
× ×
The fits of these two TBF-CMs and the experimental data are shown in Figure 6, where the
dashed and thin lines represent TBF-CM-k4 and TBF-CM-k3, respectively. The symbols show
the output of the PTT model. Although σ , N and N are all shown, it is important to remember
12 1 2
thatonlytheshearstresscomponentisusedinbothstagesofAlgorithm2. Visually,theagreement
of both TBF-CMs with the data is excellent across the board. Experiments with k=1 and k=2,
producedfitsthatwerequalitativelysimilar,butvisuallyinferior.
This success is noteworthy for at least two reasons. First, although only shear stress data is
used for inference in the PI scenario, the agreement of the predicted N and N with the PTT
1 2
model is remarkable. Second, TBF-CM-k4 and TBF-CM-k3 look quite different from the TBF-
CMinferredintheCIscenario,namely(0.306I +0.020I )T ,whichwesubsequentlylabelTBF-
1 4 2
CM-CI, and the Taylor expansion of the PTT model in the limit of small ε and I /G, namely
PTT 1
0.3I +0.045I2 T . We examine the origin and implication of these two observations in succes-
1 1 2
s(cid:0)ion. (cid:1)
Although the agreement of N and N predicted by the TBF-CMs with the PTT model is a for-
1 2
tunate accident that is unlikely to generalize to real materials, it is aided by the strict enforcement
of physical constraints, and bias for parsimony. In particular, we observe that both TBF-CM-k4
andTBF-CM-k3correctlypredictN =0. Retrospectively,thiscanbeinterpretedasadirectcon-
2
sequence of F(σ,γ˙) = g T = g σ. When the nonlinear term is proportional to σ, σ (t) = 0
2 2 2 22
remainsunperturbed,iftheinitialconditionσ(0)=0,regardlessofthefunctionalformofg (l).
2
TheextraordinaryagreementofN andN predictedbytheTBF-CMsandtheunseensynthetic
1 2
data can be traced to the common origin of the nonlinear term for σ , σ , and σ . In particular,
11 22 12
thecomponentsofF (σ,γ˙)forthePTTmodelinEquation10correspondingtothesetermstake
PTT
the form F = g (l)σ , F = g (l)σ , and F (l) = g (l)σ . Thus, if a good approximation
11 2 11 22 2 22 12 2 12
29forg (l)isobtainedfromtheshearstressdata,weexpectittoalsobeareasonableapproximation
2
forσ andσ .
11 22
What about the uniqueness of the inferred TBF-CM? TBF-CM-k4 and TBF-CM-k3 are prod-
ucts of Algorithm 2, which is a crude method for SNLR. In the PI scenario, we expect different
CMstoresultfromdifferentalgorithmsandparameterchoices. Thefactthatatleastthreedifferent
CMs (TBF-CM-k4, TBF-CM-k3, and TBF-CM-CI) successfully describe shear stress data from
a simple model like the PTT model underscores the inherent nonuniqueness of any CM discov-
eredfrom limiteddata. Somewhatparadoxically, thisnonuniqueness highlightsthe importance of
frameinvarianceandinductivebiasesinnavigatingthespaceofpotentialCMs.
1. GeneralizabilityofTBF-CMs
The TBF-CMs inferred using the proposed algorithms fit experimental or training datasets re-
markably well. However, what we usually care about for CFD applications is the ability of the
learned model to generalize beyond the data used to train it. In this work, we know the true CMs
(Giesekus or PTT). Therefore, we can compare the predictions of the inferred TBF-CMs with the
trueCMsbeyondthetrainingdata.
We assess the generalizability of TBF-CM-k4 and TBF-CM-k3 by performing two different
types of tests. In the first type, we consider the predictions of the TBF-CMs in OS flow, where
the operating conditions are different from those used in the n training datasets. Some of the
ds
(γ ,ω) in these tests lie within the region circumscribed by the experimental data. We label these
0
predictions as interpolations. In other cases, (γ ,ω) lie outside the range of the training data. We
0
labelthesepredictionsoftheinferredTBF-CMsasextrapolations.
In the second type of experiment, we test the ability of the inferred CMs to generalize beyond
the OS flow. These are much tougher benchmarks. In particular, we consider the predictions of
the TBF-CMs to the startup of steady shear flow in which a constant shear rate γ˙ is applied to an
initiallyrelaxedmaterial(σ(0)=0). Finally,wetransitionfromshearflowstouniaxialextensional
flows in which we consider the evolution of the normal stresses when a steady elongational strain
rateε˙ isapplied.2
In Figure 7, we show the results of the first type of test (OS shear). Recall from Figure 6, that
the range of training data span 0.5 γ 5, and 0.1 ωτ 10. The four tests in the lower left
0
≤ ≤ ≤ ≤
corner of Figure 7 with (γ ,ωτ) equal to (1.5,0.5), (1.5,5.0), (3.5,0.5), and (3.5,5.0) lie within
0
30FIG. 7. PI OS flow Test. Interpolation (region outside the dashed line) and extrapolation (region inside
dashed line) predictions of TBF-CM-k4 (dashed lines) and TBF-CM-k3 (light solid line) are compared
with the response of the PTT model with ε =0.3 (symbols). Each subplot shows the PSS solution for
PTT
N (black),N (purple),andσ (blue)asafunctionofωt [0,2π].
1 2 12
∈
the convex hull of the training data. Thus, they represent interpolations. The other five datasets
in the figure marked off by the red dashed line lie outside the range of training data and hence
representextrapolations.
Visually, we find that the predictions of TBF-CM-k4 and TBF-CM-k3 are comparable and
largely agree with the PTT model. On closer inspection, we find that TBF-CM-k4 is slightly su-
perior, especially in describing N . As γ increases well beyond the range of the training data
1 0
(top right corner of Figure 7), predictions of N start to become less satisfactory. From numerical
1
experiments, we find that both the TBF-CMs extrapolate satisfactorily beyond the training data
(see supplementary material Section S5). At large ωτ ≳50 and strain amplitude (γ
0
≳7.5), it is
advisable to resolve a greater number of harmonics (use larger H >8), and/or use more interme-
diate steps to aid the convergence of FLASH. Regardless, TBF-CMs using Algorithm 2 appear to
generalizewellforthePTTmodelinOSflow.
Next, we consider the second, more stringent, type of test in which we probe the behavior
of TBF-CM-k4 and TBF-CM-k3 when a constant deformation rate is applied under shear and
31FIG. 8. PI startup shear and extension. Startup of shear (A and B) and unaxial extension (C and D) for
the PTT model (depicted by symbols) at two different deformation rates. The predictions of TBF-CM-k4
andTBF-CM-k3areshownbythedashedandlightsolidlines,respectively.
uniaxial extension. In steady shear flow, the velocity gradient tensor v = γ˙e and the de-
12
∇
formation gradient tensor γ˙ = γ˙e +γ˙e , are the same as for OS flow. The only difference
12 21
is that the shear rate γ˙ is constant rather than sinusoidal. In uniaxial extension, the velocity
gradient tensor is diagonal v = ε˙e 0.5ε˙e 0.5ε˙e , where ε˙ is the steady extensional
11 22 33
∇ − −
strain rate. This implies that the shear rate tensor γ˙ = v+( v)T = 2 v and the stress ten-
∇ ∇ ∇
sor σ =σ e +σ e +σ e have three nonzero components along the diagonal. TBFs and
11 11 22 22 33 33
invariants specialized for uniaxial extension are presented in the supplementary material (Sec-
tionS6).
We solve the initial value problem using an implicit Runge-Kutta method belonging to the
Radau IIA family implemented in the Python package scipy.78,79 It is a fifth-order method with
local error controlled via a third-order accurate embedded formula. We assume that stress tensor
componentsareinitiallyzero,i.e.,σ(0)=0. Insteadyshear,wecomputetheevolutionoftheshear
andnormalstresscomponents,whereasinsteadyuniaxialextension,wecomputetheevolutionof
only the normal stress components, since σ = 0. For the PTT model, N = 0, as mentioned
12 2
earlier.
Weconsidertwodifferentdeformationrates(γ˙andε˙)of0.5/τ and3/τ. ComparisonsofthePTT
32model and the TBF-CMs are shown in Figure 8. For the startup of steady shear, both TBF-CMs
appear to work reasonably well. TBF-CM-k4 appears to be slightly more accurate in predicting
shear stress. For N , both models appear to capture the initial growth, but slightly under- or over-
1
estimatethesteady-statevalue.
A similar trend is also observed in the uniaxial extension. TBF-CM-k4 describes N better,
1
especially at ε˙ = 3/τ, where TBF-CM-k3 under-estimates the steady state. It captures the mild
overshoot in N at large ε˙ semi-quantitatively, but exaggerates the bump. Nevertheless, these out-
1
of-sample tests show that the TBF-CMs inferred from PI using only σ data in OS experiments,
12
generalize surprisingly well to startup shear and extension. Therefore, we speculate that they will
be reasonable approximations to the PTT model in CFD simulations of non-homogeneous flows
encounteredduringprocessing.
V. DISCUSSION
Although the proposed algorithms are presented only as proof-of-concept ideas in this work,
theyappeartobepromisingtoolsforCMdiscoveryfromexperimentaldata. Theyhaveimportant
implicationsforexperimentaldesignandalgorithmicimprovement.
A. ImplicationsforDesignofExperiments
First, it appears that modest datasets with n O(10), typical in rheological settings, may be
ds
∼
sufficient to infer CMs that obey physical constraints and extrapolate reasonably well beyond the
scope of the training data. Second, in OS experiments where the shear stress and both normal
stressdifferencesaremeasured,wecanuseSLR,whichisfastandrobust. Unfortunately,thecost
of posing a computationally desirable problem involves shifting the burden from the modeler to
the experimenter. Third, OS experiments need to probe strongly nonlinear flows by exploring the
large γ regime to induce a sufficiently robust nonlinear signal. In this work, we weighted the n
0 ds
datasets equally. This potentially runs the risk of diluting more valuable information from mea-
surements at large γ . We plan to explore this issue further in future work. In terms of frequency,
0
werecommendexploringboththeωτ <1andωτ >1regimes.
A deeper lesson arises from the fact that only five of the nine simultaneous invariants of σ
and γ˙ are activated in shear flow. This places theoretical limits on the types of CMs that can
33be discovered using only shear flows, even in the CI scenario. In other words, it is possible to
find TBF-CMs that perfectly describe the response to all shear flows, but fail to describe material
behavior when the flow field includes extensional components. An important practical outcome
ofthisinsightisthenecessityofcombiningshearandextensiondatafortheCMdiscoveryofreal
materials.
B. PotentialforComputationalImprovements
Before we discuss potential improvements, it is helpful to emphasize that the TBF framework
isonlyguaranteedtoworkwhenthenonlineartermF intheCMisanalytical. Thisisnotthecase
for some CMs of transient networks,30,80 polymers,81 and yield-stress materials,2,3 which contain
singularities. ItisworthwhiletoempiricallytesthowtheTBF-CMframeworkfaresforsuchCMs.
Futhermore, if the nonlinear term F(σ,γ˙) depends on terms other than σ and γ˙, then the set of
TBFshastoappropriatelymodified.
Assuming F(σ,γ˙) is analytical, a simple improvement of the computational protocol is the
relaxation of using a fixed H for all experimental datasets. We kept H = 8 fixed in this work to
simplify exposition. In practice, we can use Fourier analysis of experimental data to calibrate the
appropriateH foreachdataset. ThiscanpotentiallyspeedupthecalculationinthePIscenario.
Algorithm 2 proposed for the PI scenario is arguably too simple. While it works well with
simpleCMsliketheGiesekusandPTTmodels,itssuitabilityformorecomplexmaterialsremains
to be explored. The most obvious improvement is to use better algorithms for SNLR, informed
by the rapid theoretical and algorithmic progress in nonlinear compressed sensing over the past
decadeorso. Mostoftheproposedalgorithmssuchasiterativehardthresholding,68 greedysparse
simplex,33 gradient pursuit,69 etc. involve taking the gradient of the loss function ∇ χ2 at each
α F
iteration. Atwo-pointnumericalcomputationof∂σˆ/∂α requiredtoevaluatethisgradientwould
j
involve O(n ) FLASH simulations per iteration. This is prohibitively expensive. Fortunately,
α
the TBF-CM is linear in the coeffficient vector α. Consequently, terms such as ∂σˆ/∂α can
i
be computed using a combination of FFT and inverse FFT.56 This means that a single FLASH
simulation per iteration is sufficient to assemble ∇ χ2. The asymptotic computational cost of
α F
this assembly scales as O(n ) because ∇ χ2 has n components. However, computing each
α α F α
component(∂σˆ/∂α)isrelativelycheapsinceitonlyinvolvesanFFTanditsinverse,whichcosts
i
O(n logn ).
t t
34Finally, we have to tackle the problem of abundance. Depending on k (which can be deter-
minedusingclusteringmethods)andotherdetailsoftheSNLRalgorithm,weusuallyobtainmore
than one potential TBF-CM that fits the data. One possibility to deal with such non-uniqueness is
to reformulate the inverse problem as a sampling problem using a Bayesian formulation, where a
distributionofCMsisentertained,82,83 insteadofanoptimizationproblem,whereweseekthebest
TBF-CMthatfitsthedata. Thisreformulationallowsustotakeanensembleapproachtomakepre-
dictionsusingtheCM,similartohowhurricanetrajectoriesareforecastinweathermodeling.84,85
VI. CONCLUSIONS
The goal of this work is the discovery of parsimonious, physics-constrained CMs from OS
measurements. Physicalconstraintslikesymmetryandframe-invarianceenableustoembedthese
CMsintoCFDsoftwaretopredictcomplexflowsinprocessequipmentandacceleratedesignand
scale-upofnewproducts. Thisworkbuildson(i)tensorbasisfunctions,whichallowustoexpress
unknown nonlinear terms in CMs using a finite number of basis functions, (ii) sparse regression
techniques, which allow us to look for parsimonious CMs, and (iii) a computer program called
FLASH,whichallowsustoefficientlyevaluatethePSSsolutionofarbitrarynonlineardifferential
CMsinthePIscenario.
We generate synthetic data using the Giesekus and PTT models and considered two different
scenarios, CI and PI. We assume that N , N , and σ are measured in the CI scenario, while
1 2 12
only σ is measured in the PI scenario. The CI scenario leads to an SLR problem which can
12
be efficiently solved using LASSO regression. For the more typical PI scenario, we propose a
two-stagegreedySNLRalgorithm. Inthefirststage,weidentifythek mostpromising(unknown)
coefficientsbeforeoptimizingthemduringthesecondstage.
In the case of the Giesekus model, both the SLR and the SNLR find the ‘true’ model, due to
thesimplerepresentationoftheCMintermsoftheTBFs. InthecaseofthePTTmodel,theTBF-
CMsdiscoveredinboththeCIandPIscenariosfittheexperimentaldatawell. InOS,thepredictive
ability of the discovered TBF-CMs under operating conditions that interpolate the training data is
nearly perfect. The CMs also extrapolate satisfactorily when extended to test conditions outside
the convex hull of the training data. The out-of-sample performance of these TBF-CMs in the
startup of steady and uniaxial extension tests, while not perfect, is still quite satisfactory. This
work has important implications for the design of experiments, the necessity of exploring non-
35shearflows,andpotentialalgorithmicimprovementsforSNLR.
AppendixA:Cayley-HamiltonTheoremandTensorInvariants
Thecharacteristicpolynomialofany3 3squarematrixAis,
×
p (λ)=det(A λI), (A1)
A
−
wheredet(A)denotesthedeterminantofmatrixA. Theroots of p (λ)=0yieldtheeigenvalues
A
(λ = [λ ,λ ,λ ]) of A. A function f(A) is an invariant of A if its value is independent of the
1 2 3
rotationofA. Mathematically,
f(A)= f(QAQT) orthogonalmatricesQ.
∀
ThethreeprincipalinvariantsofAaregivenby,
I =tr(A)=A +A +A =λ +λ +λ (A2)
1 11 22 33 1 2 3
1
I = (tr(A))2 tr(A2) =λ λ +λ λ +λ λ (A3)
2 1 2 1 3 2 3
2 −
(cid:0) (cid:1)
I =det(A)=λ λ λ . (A4)
3 1 2 3
Thecoefficientsofthecharacteristicpolynomialturnouttobetheprincipalinvariants
p (λ)=λ3 I λ2+I λ I . (A5)
A 1 2 3
− −
The Cayley-Hamilton theorem states that the characteristic polynomial of any square matrix
evaluatedatAequalszero,86,87
p (A)=A3 I A2+I A I I =0. (A6)
A 1 2 3
− −
ItenablesustowriteAn withn 3intermsofA2,A,andI byrecursivelyinvokingEquation
≥
A6. Forexample,
A4 =A3A=(I A2 I A+I I)A
1 2 3
−
=I A3 I A2+I A
1 2 3
−
=I (I A2 I A+I I) I A2+I A
1 1 2 3 2 3
− −
=(I2 I )A2+(I I I )A+(I I )I.
1 − 2 3 − 1 2 1 3
36Thishasanimportantcorollary: theTaylorseriesexpansionofanyanalyticfunction f(A)canbe
truncatedafterthequadraticterm,
∞
f(A)= ∑c Ak =g (I ,I ,I )A2+g (I ,I ,I )A+g (I ,I ,I )I (A7)
k 2 1 2 3 1 1 2 3 0 1 2 3
k=0
where g 3arepolynomialfunctionsoftheinvariants,andhencetheeigenvaluesofA.
i i=1
{ }
AppendixB:TBFsandInvariantsinShear
In oscillatory or steady shear experiments, γ˙ = γ˙e +γ˙e and σ = σ e +σ e +
12 21 11 11 12 12
σ e +σ e . The TBFs listed in Table I can be further simplified by substituting these ex-
12 21 22 22
pressionsintothegeneralequations. Theyyield:
T =1e +1e +1e
1 11 22 33
T =σ e +σ e +σ e +σ e
2 11 11 12 12 12 21 22 22
T =γ˙e +γ˙e
3 12 21
T =σ2 +σ2 e +σ (σ +σ )e +σ (σ +σ )e +σ2 +σ2 e
4 11 12 11 12 11 22 12 12 11 22 21 12 22 22
T =γ˙2e +γ˙2e
5 11 22
T =2γ˙σ e +γ˙(σ +σ )e +γ˙(σ +σ )e +2γ˙σ e
6 12 11 11 22 12 11 22 21 12 22
T =2γ˙σ (σ +σ )e +γ˙ σ2 +2σ2 +σ2 e +γ˙ σ2 +2σ2 +σ2 e +
7 12 11 22 11 11 12 22 12 11 12 22 21
2γ˙σ (σ +σ )e(cid:0) (cid:1) (cid:0) (cid:1)
12 11 22 22
T =2γ˙2σ e +2γ˙2σ e +2γ˙2σ e +2γ˙2σ e
8 11 11 12 12 12 21 22 22
T =2γ˙2 σ2 +σ2 e +2γ˙2σ (σ +σ )e +2γ˙2σ (σ +σ )e +
9 11 12 11 12 11 22 12 12 11 22 21
(cid:0) 2γ˙2 σ2(cid:1)+σ2 e .
12 22 22
(cid:0) (cid:1)
37Thecorrespondinginvariantscanbewrittenas,
I =σ +σ
1 11 22
I =σ2 +2σ2 +σ2
2 11 12 22
I =2γ˙2
3
I =σ3 +3σ σ2 +3σ2 σ +σ3
4 11 11 12 12 22 22
I =0
5
I =2γ˙σ
6 12
I =I I
7 1 6
I =I I /2
8 1 3
I =I I /2.
9 2 3
Thus, only five of the nine invariants (I , I , I , I , I ) are nontrivial. The remaining invariants
1 2 3 4 6
are zero, or products of other invariants. Thus, the task of learning g(L) simplifies to the task of
learningg(l),withl=[I ,I ,I ,I ,I ].
1 2 3 4 6
SUPPLEMENTARYMATERIAL
See supplementary material online for (i) nomenclature and abbreviations, (ii) Giesekus and
PTTmodelsinoscillatoryshear,(iii)harmonicbalanceandFLASH,(iv)GiesekusmodelinthePI
Scenario,(v)ExtrapolationofTBF-CMinOSflow,(vi)TBFsandinvariantsinuniaxialextension.
ACKNOWLEDGMENTS
This work is based in part on work supported by the National Science Foundation under grant
no. NSF DMR-1727870 (SS). The authors thank Kyle R. Lennon and Alexander Peterson for
helpfuldiscussions.
DATAAVAILABILITYSTATEMENT
Data supporting the findings of this study are available from the corresponding author upon
reasonablerequest.
38REFERENCES
1R. G. Larson, Structure and Rheology of Complex Fluids (Oxford University Press, New York,
1998).
2F.A.Morrison,UnderstandingRheology(OxfordUniversityPress,USA,2001).
3R. G. Larson, Constitutive equations for polymer melts and solutions (Butterworth-Heinemann,
Stoneham,MA,1988).
4F. Pimenta and M. Alves, “Stabilization of an open-source finite-volume solver for viscoelastic
fluidflows,”J.Non-NewtonianFluidMech.239,85–104(2017).
5H.G.Weller,G.Tabor,H.Jasak,andC.Fureby,“Atensorialapproachtocomputationalcontin-
uummechanicsusingobject-orientedtechniques,”Comp.Phys.12,620–631(1998).
6J. Favero, A. Secchi, N. Cardozo, and H. Jasak, “Viscoelastic flow analysis using the software
OpenFOAManddifferentialconstitutiveequations,”J.Non-NewtonianFluidMech.165,1625–
1636(2010).
7T. Hastie, R. Tibshirani, and J. Friedman, The Elements of Statistical Learning, Springer Series
inStatistics(SpringerNewYorkInc.,NewYork,NY,USA,2001).
8S. L. Brunton, J. L. Proctor, and J. N. Kutz, “Discovering governing equations from data by
sparseidentificationofnonlineardynamicalsystems,”PNAS113,3932–3937(2016).
9D. M. Bortz, D. A. Messenger, and V. Dukic, “Direct estimation of parameters in ODE models
usingWENDy: Weak-formestimationofnonlineardynamics,”Bull.Math.Biol.85,110(2023).
10Z. Chen, Y. Liu, and H. Sun, “Physics-informed learning of governing equations from scarce
data,”Nat.Commun.12,6136(2021).
11K. R. Lennon, G. H. McKinley, and J. W. Swan, “Scientific machine learning for modeling and
simulatingcomplexfluids,”Proc.Natl.Acad.Sci.120,e2304669120(2023).
12M. Mahmoudabadbozchelou, K. M. Kamani, S. A. Rogers, and S. Jamali, “Unbiased construc-
tion of constitutive relations for soft materials from experiments via rheology-informed neural
networks,”Proc.Natl.Acad.Sci.121,e2313658121(2024).
13M. Mahmoudabadbozchelou, M. Caggioni, S. Shahsavari, W. H. Hartt, G. Em Karniadakis,
and S. Jamali, “Data-driven physics-informed constitutive metamodeling of complex fluids: A
multifidelityneuralnetwork(MFNN)framework,”J.Rheol.65,179–198(2021).
14M. Mahmoudabadbozchelou, K. M. Kamani, S. A. Rogers, and S. Jamali, “Digital rheometer
twins: Learningthehiddenrheologyofcomplexfluidsthroughrheology-informedgraphneural
39networks,”Proc.Natl.Acad.Sci.119,e2202234119(2022).
15K.R.Lennon,J.D.J.Rathinaraj,M.A.GonzalezCadena,A.Santra,G.H.McKinley,andJ.W.
Swan, “Anticipating gelation and vitrification with medium amplitude parallel superposition
(maps)rheologyandartificialneuralnetworks,”Rheol.Acta62,535–556(2023).
16N.Seryo,T.Sato,J.J.Molina,andT.Taniguchi,“Learningtheconstitutiverelationofpolymeric
flowswithmemory,”Phys.Rev.Res.2,033107(2020).
17M. Saadat, M. Mahmoudabadbozchelou, and S. Jamali, “Data-driven selection of constitutive
modelsviarheology-informedneuralnetworks(rhinns),”Rheol.Acta61,721–732(2022).
18T. John, M. Mowbray, A. Alalwyat, M. Vousvoukis, P. Martin, A. Kowalski, and C. Fonte,
“Machine learning for viscoelastic constitutive model identification and parameterisation using
largeamplitudeoscillatoryshear,”Chem.Eng.Sci.294,120075(2024).
19H. Jin, S. Yoon, F. C. Park, and K. H. Ahn, “Data-driven constitutive model of complex fluids
usingrecurrentneuralnetworks,”Rheol.Acta62,569–586(2023).
20C.M.Bishop,PatternRecognitionandMachineLearning(Springer-Verlag,Berlin,Heidelberg,
2006).
21A. Kaplarevic´-Malisˇic´, B. Andrijevic´, F. Bojovic´, S. Nikolic´, L. Krstic´, B. Stojanovic´, and
M. Ivanovic´, “Identifying optimal architectures of physics-informed neural networks by evo-
lutionarystrategy,”Appl.SoftComput.146,110646(2023).
22Y. Shin, J. Darbon, and G. Em Karniadakis, “On the convergence of physics informed neural
networks for linear second-order elliptic and parabolic type pdes,” Comm. Comput. Phys. 28,
2042–2074(2020).
23P. Sharma, L. Evans, M. Tindall, and P. Nithiarasu, “Stiff-PDEs and physics-informed neural
networks,”Arch.Comput.MethodsEng.30,2929–2958(2023).
24S.Wang,Y.Teng,andP.Perdikaris,“Understandingandmitigatinggradientflowpathologiesin
physics-informedneuralnetworks,”SIAMJ.Sci.Comput.43,A3055–A3081(2021).
25R. Novak, Y. Bahri, D. A. Abolafia, J. Pennington, and J. Sohl-Dickstein, “Sensitivity and gen-
eralizationinneuralnetworks: anempiricalstudy,” (2018).
26L. Liao, H. Li, W. Shang, and L. Ma, “An empirical study of the impact of hyperparameter
tuning and model optimization on the performance properties of deep neural networks,” ACM
Trans.Softw.Eng.Methodol.31(2022),10.1145/3506695.
27A. Wiemerslage, K. Gorman, and K. von der Wense, “Quantifying the hyperparameter sen-
sitivity of neural networks for character-level sequence-to-sequence tasks,” in Proceedings of
40the 18th Conference of the European Chapter of the Association for Computational Linguistics
(Volume 1: Long Papers), edited by Y. Graham and M. Purver (Association for Computational
Linguistics,St.Julian’s,Malta,2024)pp.674–689.
28M.MahmoudabadbozchelouandS.Jamali,“Rheology-informedneuralnetworks(RhINNs)for
forwardandinversemetamodellingofcomplexfluids,”Sci.Rep.11,12015(2021).
29A.MorozovandS.E.Spagnolie,“Introductiontocomplexfluids,”inComplexFluidsinBiolog-
ical Systems: Experiment, Theory, and Computation, edited by S. E. Spagnolie (Springer New
York,NewYork,NY,2015)pp.3–52.
30S. Mittal, Y. M. Joshi, and S. Shanbhag, “Harmonic balance for differential constitutive models
underoscillatoryshear,”Phys.Fluids36,053104(2024).
31S.Mittal,Y.M.Joshi,andS.Shanbhag,“Cannumericalmethodscompetewithanalyticalsolu-
tions of linear constitutive models for large amplitude oscillatory shear flow?” Rheol. Acta 63,
145–155(2024).
32S. Mittal, Y. M. Joshi, and S. Shanbhag, “The method of harmonic balance for the Giesekus
modelunderoscillatoryshear,”J.Non-NewtonianFluidMech.321,105092(2023).
33A. Beck and Y. C. Eldar, “Sparsity constrained nonlinear optimization: Optimality conditions
andalgorithms,”SIAMJ.Optim.23,1480–1509(2013).
34Z.Yang,Z.Wang,H.Liu,Y.Eldar,andT.Zhang,“Sparsenonlinearregression: Parameteresti-
mation under nonconvexity,” in Proceedings of The 33rd International Conference on Machine
Learning,ProceedingsofMachineLearningResearch,Vol.48,editedbyM.F.BalcanandK.Q.
Weinberger(PMLR,NewYork,NewYork,USA,2016)pp.2472–2481.
35S.MallatandZ.Zhang,“Matchingpursuitswithtime-frequencydictionaries,”IEEETrans.Sig-
nalProcess.41,3397–3415(1993).
36Y. Pati, R. Rezaiifar, and P. Krishnaprasad, “Orthogonal matching pursuit: recursive function
approximation with applications to wavelet decomposition,” in Proceedings of 27th Asilomar
ConferenceonSignals,SystemsandComputers(1993)pp.40–44vol.1.
37K. Hayashi, T. Obuchi, and Y. Kabashima, “Reconstructing sparse signals via greedy Monte-
Carlosearch,”J.Phys.Soc.Jpn.89,124802(2020).
38J. D. Ferry, Viscoelastic properties of polymers, 3rd ed. (John Wiley & Sons, New York, NY,
1980).
39H. Giesekus, “A simple constitutive equation for polymer fluids based on the concept of
deformation-dependenttensorialmobility,”J.Non-NewtonianFluidMech.11,69–109(1982).
4140T. Holz, P. Fischer, and H. Rehage, “Shear relaxation in the nonlinear-viscoelastic regime of a
giesekusfluid,”J.Non-NewtonianFluidMech.88,133–148(1999).
41P. Fischer and H. Rehage, “Non-linear flow properties of viscoelastic surfactant solutions,”
Rheol.Acta36,13–27(1997).
42H. Rehage and R. Fuchs, “Experimental and numerical investigations of the non-linear rheo-
logical properties of viscoelastic surfactant solutions: application and failing of the one-mode
Giesekusmodel,”ColloidPolym.Sci.293,3249–3265(2015).
43R. Bandyopadhyay and A. Sood, “Effect of silica colloids on the rheology of viscoelastic gels
formedbythesurfactantcetyltrimethylammoniumtosylate,”J.ColloidInterfaceSci.283,585–
591(2005).
44A. Kate Gurnon and N. J. Wagner, “Large amplitude oscillatory shear (LAOS) measurements
to obtain constitutive equation model parameters: Giesekus model of banding and nonbanding
wormlikemicelles,”J.Rheol.56,333–351(2012).
45J.Kokini,M.Dhanasekharan,C.Wang,andH.Huang,Integralanddifferentiallinearandnon-
linear constitutive models for rheology of wheat flour doughs (Technomics Publishing Co. Inc.,
Lancaster,PA,2000).
46M. Dhanasekharan, C. Wang, and J. Kokini, “Use of nonlinear differential viscoelastic models
topredicttherheologicalpropertiesofglutendough,”J.FoodProcessEng24,193–216(2001).
47N. Phan-Thien and R. I. Tanner, “A new constitutive equation derived from network theory,” J.
Non-NewtonianFluidMech.2,353–365(1977).
48N.Phan-Thien,“Anonlinearnetworkviscoelasticmodel,”J.Rheol.22,259–283(1978).
49M.Yamamoto,“Thevisco-elasticpropertiesofnetworkstructureI.Generalformalism,”J.Phys.
Soc.Jpn.11,413–421(1956).
50A. S. Lodge, “A network theory of flow birefringence and stress in concentrated polymer solu-
tions,”Trans.FaradaySoc.52,120–130(1956).
51D.N.Sibley,ViscoelasticflowsofPTTfluids,Ph.D.thesis,UniversityofBath(2010).
52S.G.Hatzikiriakos,G.Heffner,D.Vlassopoulos,andK.Christodoulou,“Rheologicalcharacter-
ization of polyethylene terephthalate resins using a multimode Phan-Thien-Tanner constitutive
relation,”Rheol.Acta36,568–578(1997).
53S. Shiromoto, Y. Masutani, M. Tsutsubuchi, Y. Togawa, and T. Kajiwara, “The effect of vis-
coelasticityontheextrusiondrawinginfilm-castingprocess,”Rheol.Acta49,757–767(2010).
4254W. Dietz, “Polyester fiber spinning analyzed with multimode Phan Thien-Tanner model,” J.
Non-NewtonianFluidMech.217,37–48(2015).
55M. T. Heath, Scientific Computing: An Introductory Survey, Revised Second Edition (SIAM,
Philadelphia,USA,2018).
56M.KrackandJ.Gross,HarmonicBalanceforNonlinearVibrationProblems(SpringerInterna-
tionalPublishing,Cham,2019).
57R. S. Rivlin, “Further remarks on the stress-deformation relations for isotropic materials,” J.
RationalMech.Anal.4,681–702(1955).
58A. J. M. Spencer and R. S. Rivlin, “Further results in the theory of matrix polynomials,” Arch.
RationalMech.Anal.4,214–230(1959).
59R.S.RivlinandJ.L.Ericksen,“Stress-deformationrelationsforisotropicmaterials,”J.Rational
Mech.Anal.4,323–425(1955).
60G.DuiandY.-C.Chen,“AnoteonRivlin’sidentitiesandtheirextension,”J.Elast.76,107–112
(2004).
61R. Tibshirani, “Regression shrinkage and selection via the lasso,” J. R. Stat. Soc. Series B Stat.
Methodol.58,267–288(1996).
62S.S.Chen,D.L.Donoho,andM.A.Saunders,“Atomicdecompositionbybasispursuit,”SIAM
J.Sci.Comput.20,33–61(1998).
63R.Tibshirani,“Regressionshrinkageandselectionviathelasso: aretrospective,”J.R.Stat.Soc.
SeriesBStat.Methodol.73,273–282(2011).
64S. L. Brunton and J. N. Kutz, Data-Driven Science and Engineering: Machine Learning, Dy-
namicalSystems,andControl(CambridgeUniversityPress,Cambridge: UK,2019).
65B.Efron,T.Hastie,I.Johnstone,andR.Tibshirani,“Leastangleregression,”AnnalsofStatistics
32,407–499(2004).
66J. Friedman, T. Hastie, and R. Tibshirani, “Regularization paths for generalized linear models
viacoordinatedescent,”J.Stat.Softw.33,1–22(2010).
67T. Blumensath, “Compressed sensing with nonlinear observations and related nonlinear opti-
mizationproblems,”IEEETrans.Inf.Theory59,3466–3474(2013).
68T. Blumensath and M. E. Davies, “Iterative thresholding for sparse approximations,” J. Fourier
Anal.Appl.14,629–654(2008).
69T. Blumensath and M. E. Davies, “Gradient pursuit for non-linear sparse signal modelling,” in
200816thEuropeanSignalProcessingConference(2008)pp.1–5.
4370X.-T. Yuan, P. Li, and T. Zhang, “Gradient hard thresholding pursuit,” J. Mach. Learn. Res. 18,
1–43(2018).
71B. K. Natarajan, “Sparse approximate solutions to linear systems,” SIAM J. Comput. 24, 227–
234(1995).
72P. Das, M. Jain, and A. Majumdar, “Non linear sparse recovery algorithm,” in 2014 IEEE In-
ternational Symposium on Signal Processing and Information Technology (2014) pp. 000327–
000332.
73F.Pedregosa,G.Varoquaux,A.Gramfort,V.Michel,B.Thirion,O.Grisel,M.Blondel,P.Pret-
tenhofer,R.Weiss,V.Dubourg,J.Vanderplas,A.Passos,D.Cournapeau,M.Brucher,M.Perrot,
and E. Duchesnay, “Scikit-learn: Machine learning in Python,” J. Mach. Learn. Res. 12, 2825–
2830(2011).
74S. Kim, K. Koh, M. Lustig, S. Boyd, and D. Gorinevsky, “An interior-point method for large-
scalel1-regularizedleastsquares,”IEEEJ.Sel.Top.SignalProcess.1,606–617(2008).
75M.A.Branch,T.F.Coleman,andY.Li,“Asubspace,interior,andconjugategradientmethodfor
large-scalebound-constrainedminimizationproblems,”SIAMJ.Sci.Comput.21,1–23(1999).
76J. J. More´, “The Levenberg-Marquardt algorithm: Implementation and theory,” in Numerical
Analysis, edited by G. A. Watson (Springer Berlin Heidelberg, Berlin, Heidelberg, 1978) pp.
105–116.
77J. J. More´, B. S. Garbow, and K. E. Hillstrom, “User guide for MINPACK-1,” Tech. Rep. (Ar-
gonneNat.Lab.,Argonne,IL,1980).
78P.Virtanen,R.Gommers,T.E.Oliphant,M.Haberland,T.Reddy,D.Cournapeau,E.Burovski,
P. Peterson, W. Weckesser, J. Bright, S. J. van der Walt, M. Brett, J. Wilson, K. J. Millman,
N. Mayorov, A. R. J. Nelson, E. Jones, R. Kern, E. Larson, C. J. Carey, ˙I. Polat, Y. Feng,
E.W.Moore,J.VanderPlas,D.Laxalde,J.Perktold,R.Cimrman,I.Henriksen,E.A.Quintero,
C. R. Harris, A. M. Archibald, A. H. Ribeiro, F. Pedregosa, P. van Mulbregt, and SciPy 1.0
Contributors, “SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python,” Nat.
Methods17,261–272(2020).
79E. Hairer, S. P. Norsett, and G. Wanner, Solving Ordinary Differential Equations II: Stiff and
Differential-AlgebraicProblems(Springer-Verlag,Heidelberg,1996).
80K. H. Ahn and K. Osaki, “Mechanism of shear thickening investigated by a network model,” J.
Non-NewtonianFluidMech.56,267–288(1995).
4481G. Ianniruberto and G. Marrucci, “A simple constitutive equation for entangled polymers with
chainstretch,”J.Rheol.45,1305–1318(2001).
82S.Shanbhag,“Analyticalrheologyofbranchedpolymermelts: Identifyingandresolvingdegen-
eratestructures,”J.Rheol.55,177–194(2011).
83A. Takeh, J. Worch, and S. Shanbhag, “Analytical rheology of metallocene-catalyzed
polyethylenes,”Macromolecules44,3656–3665(2011).
84S. Shanbhag, S. Joon Park, and Z. Wang, “Superensembles of linear viscoelastic models of
polymermelts,”J.Rheol.56,279–303(2012).
85T.N.Krishnamurti,C.M.Kishtawal,Z.Zhang,T.LaRow,D.Bachiochi,E.Williford,S.Gadgil,
andS.Surendran,“Multimodelensembleforecastsforweatherandseasonalclimate,”J.Climate
13,4196–4216(2000).
86A.Cayley,“II.amemoironthetheoryofmatrices,”Philos.Trans.Roy.Soc.London148,17–37
(1858).
87G. Frobenius, “Ueber lineare substitutionen und bilineare formen.” J. Reine Angew. Math. 84,
1–63(1877).
45Supplementary Material
Sparse Regression for Discovery of Constitutive Models from
Oscillatory Shear Measurements
SachinShanbhag andGordonErlebacher
∗
DepartmentofScientificComputing,FloridaStateUniversity,Tallahassee,Florida,USA
Contents
S1 NomenclatureandAbbreviations S2
S1.1 Conventions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . S2
S2 GiesekusandPTTmodelsinOscillatoryShear S5
S2.1 Giesekusmodel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . S5
S2.2 PTTmodel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . S5
S3 HarmonicBalanceandFLASH S6
S3.1 FLASH . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . S7
S4 GiesekusModelinthePIScenario S8
S5 ExtrapolationofTBF-CMinOSFlow S9
S6 TBFsandInvariantsinUniaxialExtension S10
S1
4202
guA
02
]tfos.tam-dnoc[
1v26701.8042:viXraS1 Nomenclature and Abbreviations
Abbreviation Description
CFD ComputationalFluidDynamics
CI CompleteInformation
CM ConstitutiveModel
FLASH FastLargeAmplitudeSimulationusingHarmonicbalance
FFT FastFourierTransform
HB HarmonicBalance
IVP InitialValueProblem
LAOS LargeAmplitudeOscillatoryShear
LASSO LeastAbsoluteShrinkageandSelectionOperator
LS LeastSquares
ML MachineLearning
NN NeuralNetworks
OS OscillatoryShear
PF PolynomialFeature(elementofB )
d
PI PartialInformation
PINNs PhysicsInformedNeuralNetworks
PSS PeriodicSteadyState
PTT Phan-ThienTanner
RUDE RheologicalUniversalDifferentialEquations
SCF ScalarCoefficientFunction(g )
i
SLR SparseLinearRegression
SNLR SparseNonlinearRegression
SSR SumofSquaredResiduals
TBF TensorBasisFunction
UCM UpperConvectedMaxwell
TableS1: Listofabbreviationsusedinthepaper
S1.1 Conventions
Throughout the paper, bold symbols indicate vectors or tensors: bold lower-case symbols (x) denote
vectors or lists, while bold upper-case symbols (X) denote tensors or matrices. A ‘dot’ represents a rate
ofchangeorpartialderivative,x˙ = ∂x/∂t. A‘hat’representsaFouriertransform: xˆ isavectorofFourier
coefficientsofaperiodicsignalx(t).
S2Symbol Description
α vectorofcoefficientsofSCFsinTBF-CM
α optimalαfromfittingTBF-CMtoexperiments
∗
α˜ αwhereonlythejthelementisnonzero(onehotencoding)
j
α nonlinearparameterintheGiesekusmodel
G
B setofpolynomialfeaturesfordegreeofapproximationd
d
B jthpolynomialfeatureinthesetB
j d
γ strainamplitude
0
γ shearstrain
γ˙ deformationgradienttensor
d degreeofpolynomialapproximationofTBF-CM
ε nonlinearparameterintheexponentialPTTmodel
PTT
ε˙ steadyextensionalstrainrateinuniaxialextension
F nonlinearframe-invarianttensorfunctioninthegeneralizedUCMmodel
G(ω) storagemodulus
′
G (ω) lossmodulus
′′
G shearmodulus
g ithscalarcoefficientfunction
i
g setof9SCFs(= g , ,g )
1 9
{ ··· }
H parameterthatdeterminesthehighestharmonic(2H +1)resolvedinFLASH
I ithinvariantofσ andγ˙ (TableI)
i
L setofall9invariantsofσ andγ˙ (=I , ,I )
1 9
···
l n =5independentinvariantsinOS= [I ,I ,I ,I ,I ] L
l 1 2 3 4 6
⊂
N firstnormalstressdifference(= σ σ )
1 11 22
−
N secondnormalstressdifference(= σ σ )
2 22 33
−
n numberofelementsofα
α
n numberofpolynomialfeatures
b
n numberoftrainingdatasets
ds
n numberofscalarcoefficientfunctions(= 9)
g
n numberofindependentinvariantsinoscillatoryshear(= 5)
l
n numberofprocessedobservationsinCIscenario
Fv
n numberofcomponentsofσ resolvedinFLASH(= 3)
σ
n numberoftemporalgridpointsoveronecycle(= 26)
t
P listofindicesofthek mostpromisingcoefficients
k
σ extrastresstensor
σˆ Fouriertransformofexperimentalσ data
exp
S3σ shearstress
12
σ ,σ ,σ normalstresses
11 22 33
▽
σ upper-convectedderivativeoftensorσ
T ithtensorbasisfunctionofσ andγ˙ (TableI)
i
T thesetofTBFs,(= {T i }9 i=1)
τ relaxationtime
χ2 time-domainlossfunctionforleastsquaresregression
χ2 time-domainlossfunctionforLASSOregression
LASSO
χ2 frequency-domainlossfunctionforthePIscenario
F
ω angularfrequency
TableS2: Listofsymbolsusedinthepaper
S4S2 Giesekus and PTT models in Oscillatory Shear
S2.1 Giesekus model
TheGiesekusmodelisgivenby,
dσ 1
vT σ σ v + σ +F (σ,γ˙) = Gγ˙ (S1)
Giesekus
dt −∇ · − ·∇ τ
dσ 1 α
= vT σ σ v + σ + G σ σ = Gγ˙, (S2)
dt −∇ · − ·∇ τ Gτ ·
InOS,Eq. (S2)simplifiestothesetofnonlinearordinarydifferentialequations,
σ α
σ˙ + 11 + G σ2 +σ2 2γ˙σ = 0
11 τ Gτ 11 12 − 12
σ α
σ˙ + 22 + G (cid:0)σ2 +σ2 (cid:1) = 0
22 τ Gτ 22 12
σ α
σ˙ + 33 + G σ(cid:0)2 = 0 (cid:1)
33 τ Gτ 33
σ α
12 G
σ˙ + + (σ +σ )σ σ γ˙ Gγ˙ = 0. (S3)
12 11 22 12 22
τ Gτ − −
S2.2 PTT model
TheexponentialPTTmodelisgivenby,
dσ 1
vT σ σ v + σ +F (σ,γ˙) = Gγ˙ (S4)
PTT
dt −∇ · − ·∇ τ
dσ f (σ)
= vT σ σ v + PTT σ = Gγ˙, (S5)
dt −∇ · − ·∇ τ
whereε [0,1]controlsthenonlineartermvia,
PTT
∈
ε
PTT
f (σ) = exp tr(σ) .
PTT
G
(cid:16) (cid:17)
InOS,thesetofnonlinearordinarydifferentialequationsisgivenby,
f (σ)
PTT
σ˙ + σ 2γ˙σ = 0
11 11 12
τ −
f (σ)
PTT
σ˙ + σ = 0
22 22
τ
f (σ)
PTT
σ˙ + σ = 0.
33 33
τ
f (σ)
PTT
σ˙ + σ γ˙σ Gγ˙ = 0. (S6)
12 12 22
τ − −
S5S3 Harmonic Balance and FLASH
Harmonic balance (HB) is a general numerical method for solving systems of nonlinear ODEs with os-
cillatory forcing.1 The simplest way to introduce the idea of HB to solve CMs under OS is to consider a
first-orderordinarydifferentialequation(ODE)inasingledependentvariableq(t)subjectedtosinusoidal
externalforcingf (t) = f sinωt,
ex 0
q˙(t)+f (q,t) f (t) = 0. (S7)
nl ex
−
Here f (q,t) is a (potentially) nonlinear function of q (e.g., f (q,t) = q2), and q(t) = q(t + T) is
nl nl
a periodic function with period T = 2π/ω. A standard approach for solving the Eq. S7 is to use a
time-stepping integration method like Runge-Kutta with some initial condition (say, q(0) = 0), wait
for transients to decay and a PSS solution to emerge. Instead, HB starts by specifying an ansatz for
the periodic steady state (PSS) solution q(t) in terms of a truncated Fourier series expressed as either
trigonometric (sinkωtand coskωt) or complex (eikωt) basis functions. The Fourier series representation
ofq(t)uptoH harmonicsis,
H
q(t) q (t) = qˆ(k)eikωt, (S8)
H
≈
k= H
X−
whereqˆ(k)isthecomplexFouriercoefficientassociatedwiththekthharmonic,definedvia
1 T
qˆ(k) = q(t)e ikωtdt. (S9)
−
T
Z0
ThenumberofFouriercoefficientsinEq. (S8)is2H +1.
InHB,insteadofsolvingEq. S7,weconsideritsprojectionintheansatz,i.e.,q˙ (t)+f (q ,t) f (t) =
H nl H ex
−
0. ItcanbeshownthattheHBequationscorrespondtotheweakform,
qˆ˙ (k)+fˆ (k,qˆ ) fˆ (k) = 0, k = H, ,H. (S10)
H nl H ex
− − ···
Thisisasystemof2H +1nonlinearequationsinthe2H +1unknowncoefficientsqˆ (k).
H
ˆ
Since external forcing is prescribed, f (k) can be determined analytically. Using Eq. (S8), it can be
ex
shown that the Fourier transform of the derivative qˆ˙ (k) = ikωqˆ(k). Except in special situations, the
H
ˆ
Fourier transform f cannot be determined analytically. The alternating time frequency (AFT) scheme
nl
ˆ
approaches this problem numerically. It is a versatile and efficient method that evaluates f from qˆusing
nl
acombinationofinverseFFTandFFTcalculations. Itinvolvesthreesteps:
(i) qˆ(k) q (t): use inverse FFT to obtain q (t) on a uniform grid with n points, where n >
H H t t
→
2(2H +1)toavoidaliasingerror;2
S6(ii) q (t) f (q ,t): substitute q (t) into the specific expression for the nonlinear term f (q,t) in
H nl H H nl
→
termsofq (e.g.,f (t ) = q(t )2 fori [1,n ]);
nl i i t
∈
ˆ ˆ
(iii) f (t) f : useFFTtoobtainf (k)for H k H.
nl nl nl
→ − ≤ ≤
ˆ
Thef obtainedusingAFTisusedineachiterationwhilesolvingEq. (S10)usinganonlinearsolver. The
nl
computationalcostofFFTanditsinverseis (n logn ).
t t
O
S3.1 FLASH
FLASH uses HB with AFT to solve differential CMs subjected to oscillatory shear. Due to symmetry,
only even harmonics are present in the normal stresses σ and σ , while only odd harmonics are present
11 22
intheshearstressσ . Inthisansatz,3
12
H
σ (t) σˆ (2k)ei2kωt
11 11
≈
k= H
X−
H
σ (t) σˆ (2k)ei2kωt
22 22
≈
k= H
X−
H
σ (t) σˆ (2k +1)ei(2k+1)ωt. (S11)
12 12
≈
k= (H+1)
−X
Each complex Fourier coefficient has a real and imaginary part. Since all stresses are real, the Fourier
¯
coefficients are complex conjugates, i.e., aˆ(2k) = aˆ( 2k), where the overbar is used to denote the com-
−
plex conjugate. Thus, we do not track the Fourier coefficients corresponding to k < 0. Furthermore, the
Fouriercoefficientcorrespondingtok = 0,thatis,aˆ(0),isstrictlyreal. Asaresultofthesesimplifications,
σˆ andσˆ canberepresentedusing2H +1realcoefficients,whileσˆ canberepresentedusing2H +2
11 22 12
real coefficients. Thus, the highest harmonic resolved in FLASH is 2H + 1, and the total number of
realFouriercoefficientsis2(2H +1)+2H +2 = 6H +4.
An implementation of FLASH using Python was included as supplementary online material in the paper
thatfirstdescribedthismethod.4.
S7S4 Giesekus Model in the PI Scenario
SimilarlytothePTTmodeldiscussedinthemanuscript,weappliedtheSNLRalgorithmtosyntheticdata
obtained from the Giesekus model with α = 0.3 at the same n = 12 choices of (ω,γ ). We set d = 2,
G ds 0
whichimpliesn = 189.
α
Results of the first stage of the algorithm, where we scan α˜ for j [1,n = 189] by performing n
j α α
∈
independent 1D nonlinear minimizations of the loss function (Equation (26)) to obtain the optimal values
α˜ andthecorrespondinglossfunctionsχ2(α˜ )areshowninFigureS1.
∗j F ∗j
2.0
1.5
1.0
g
4
0.5
0.0
50 100 150
j
Figure S1: Giesekus Model in the PI Scenario: Loss functions χ2(α˜ ), where j [1,n = 189],
F j ∈ α
obtained after the first stage of the SNLR algorithm. The red star corresponds to the smallest value of
χ2(α˜ ),andhighlightsthemostpromisingcoefficient(α ).
F j 4,1
The first stage not only correctly identifies the importance of g for the Giesekus model, but picks out the
4
(k = 1) most promising coefficient, α α , which is indicated by a red star. The average cost of each
4,1 64
≡
oftheseminimizationswas22.4 14.2s.
±
Performingasecondstageissomewhatredundant,butneverthelessleadsustothetruemodel,
FSNLR = F = 0.30T .
k1 Giesekus 4
Since the proposed SNLR algorithm discovers the true CM, we do not report its performance in different
settingslikewedowiththePTTmodelinthemanuscript.
S8
2χ FS5 Extrapolation of TBF-CM in OS Flow
From Figure 7, we observe that the TBF-CMs inferred from the PTT data in the PI scenario extrapolate
reasonablywell. Fromournumericalexperiments,theinferredTBF-CMsextrapolatereliablywellbeyond
the training range as shown in Figure S2 below, where the smallest frequency (ωτ = 0.01) is a factor of
ten smaller than the smallest frequency in the training data (ωτ = 0.1). Similarly, predictions of σ at
12
frequenciesfivetimeslargerthanthoseofthetrainingset(ωτ = 10)alsoappearreasonable.
0.01
Figure S2: PI OS Flow Extrapolation. Extrapolations of the two different TBF-CMs (Eq. (31)) are
compared with the response of the PTT model with ϵ = 0.3 using H = 8 and n = 26. The horizontal
PTT t
axis in each subfigure represents ωt [0,2π]. Symbols and lines have the same meaning as Figure 6 of
∈
themanuscript.
For simulations with FLASH at ωτ ≳ 50 and/or γ 0 ≳ 7.5, it is recommended to use values of H > 8 to
capture the effect of higher harmonics and to use either a larger number of intermediate steps or a better
initialguesstoaidconvergence.
Nospecialcareisrequiredfornumericalintegration. Fromournumericalexperiments,whiletheaccuracy
of TBF-CMs for the PTT model suffers somewhat as we extrapolate far beyond the training data (evident
in the N predictions in Figure S2), they do not fail catastrophically. Instead, they smoothly diverge from
1
thetruemodel.
S9S6 TBFs and Invariants in Uniaxial Extension
In uniaxial extension, v = ε˙e 0.5ε˙e 0.5ε˙e , where ε˙ is the steady extensional strain rate.
11 22 33
∇ − −
This implies that the shear rate tensor γ˙ = 2 v = 2ε˙e ε˙e ε˙e , and the stress tensor σ =
11 22 33
∇ − −
σ e +σ e +σ e hasthreenonzerocomponentsalongthediagonal. TheTBFslistedinTableIof
11 11 22 22 33 33
themanuscriptcanbefurthersimplifiedbysubstitutingtheseexpressionsintothegeneralequations.
T = 1e +1e +1e
1 11 22 33
T = σ e +σ e +σ e
2 11 11 22 22 33 33
T = 2ε˙e ε˙e ε˙e
3 11 22 33
− −
T = σ2 e +σ2 e +σ2 e
4 11 11 22 22 33 33
T = 4ε˙2e +ε˙2e +ε˙2e
5 11 22 33
T = 4ε˙σ e 2ε˙σ e 2ε˙σ e
6 11 11 22 22 33 33
− −
T = 2ε˙σ2 e ε˙σ2 e ε˙σ2 e
7 11 11 − 22 22 − 33 33
T = 2ε˙2σ e +0.5ε˙2σ e +0.5ε˙2σ2 e
8 11 11 22 22 33 33
T = 2ε˙2σ2 e +0.5ε˙2σ2 e +0.5ε˙2σ2 e .
9 11 11 22 22 33 33
Thecorrespondinginvariantscanbewrittenas,
I = σ +σ +σ
1 11 22 33
I = σ2 +σ2 +σ2
2 11 22 33
I = 6ε˙2
3
I = σ3 +σ3 +σ3
4 11 22 33
I = 6ε˙3
5
I = 2ε˙σ ε˙σ ε˙σ
6 11 22 33
− −
I = ε˙ 2σ2 σ2 σ2
7 11 − 22 − 33
I = ε˙(cid:0)(4σ +σ +σ )(cid:1)
8 11 22 33
I = ε˙ 4σ2 +σ2 +σ2 .
9 11 22 33
(cid:0) (cid:1)
S10References
1. Krack, M. & Gross, J. Harmonic Balance for Nonlinear Vibration Problems doi:10.1007/978-
3-030-14023-6(SpringerInternationalPublishing,Cham,2019).
2. Heath,M.T.ScientificComputing:AnIntroductorySurvey,RevisedSecondEdition(SIAM,Philadel-
phia,USA,2018).
3. Mittal, S., Joshi, Y. M. & Shanbhag, S. The method of harmonic balance for the Giesekus model
underoscillatoryshear.J.Non-NewtonianFluidMech.321,105092.doi:https://doi.org/10.
1016/j.jnnfm.2023.105092(2023).
4. Mittal, S., Joshi, Y. M. & Shanbhag, S. Harmonic balance for differential constitutive models under
oscillatoryshear.Phys.Fluids36,053104.doi:10.1063/5.0207942(2024).
S11