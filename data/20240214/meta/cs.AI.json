[
    {
        "title": "FAST: Factorizable Attention for Speeding up Transformers",
        "authors": "Armin GeramiMonte HooverPranav S. DulepetRamani Duraiswami",
        "links": "http://arxiv.org/abs/2402.07901v1",
        "entry_id": "http://arxiv.org/abs/2402.07901v1",
        "pdf_url": "http://arxiv.org/pdf/2402.07901v1",
        "summary": "Motivated by the factorization inherent in the original fast multipole method\nand the improved fast Gauss transform we introduce a factorable form of\nattention that operates efficiently in high dimensions. This approach reduces\nthe computational and memory complexity of the attention mechanism in\ntransformers from $O(N^2)$ to $O(N)$. In comparison to previous attempts, our\nwork presents a linearly scaled attention mechanism that maintains the full\nrepresentation of the attention matrix without compromising on sparsification\nand incorporates the all-to-all relationship between tokens. We explore the\nproperties of our new attention metric and conduct tests in various standard\nsettings. Results indicate that our attention mechanism has a robust\nperformance and holds significant promise for diverse applications where\nself-attention is used.",
        "updated": "2024-02-12 18:59:39 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.07901v1"
    },
    {
        "title": "Detection of Spider Mites on Labrador Beans through Machine Learning Approaches Using Custom Datasets",
        "authors": "Violet LiuJason ChenAns QureshiMahla Nejati",
        "links": "http://arxiv.org/abs/2402.07895v1",
        "entry_id": "http://arxiv.org/abs/2402.07895v1",
        "pdf_url": "http://arxiv.org/pdf/2402.07895v1",
        "summary": "Amidst growing food production demands, early plant disease detection is\nessential to safeguard crops; this study proposes a visual machine learning\napproach for plant disease detection, harnessing RGB and NIR data collected in\nreal-world conditions through a JAI FS-1600D-10GE camera to build an RGBN\ndataset. A two-stage early plant disease detection model with YOLOv8 and a\nsequential CNN was used to train on a dataset with partial labels, which showed\na 3.6% increase in mAP compared to a single-stage end-to-end segmentation\nmodel. The sequential CNN model achieved 90.62% validation accuracy utilising\nRGBN data. An average of 6.25% validation accuracy increase is found using RGBN\nin classification compared to RGB using ResNet15 and the sequential CNN models.\nFurther research and dataset improvements are needed to meet food production\ndemands.",
        "updated": "2024-02-12 18:57:06 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.07895v1"
    },
    {
        "title": "MAIDCRL: Semi-centralized Multi-Agent Influence Dense-CNN Reinforcement Learning",
        "authors": "Ayesha Siddika NipuSiming LiuAnthony Harris",
        "links": "http://dx.doi.org/10.1109/CoG51982.2022.9893711",
        "entry_id": "http://arxiv.org/abs/2402.07890v1",
        "pdf_url": "http://arxiv.org/pdf/2402.07890v1",
        "summary": "Distributed decision-making in multi-agent systems presents difficult\nchallenges for interactive behavior learning in both cooperative and\ncompetitive systems. To mitigate this complexity, MAIDRL presents a\nsemi-centralized Dense Reinforcement Learning algorithm enhanced by agent\ninfluence maps (AIMs), for learning effective multi-agent control on StarCraft\nMulti-Agent Challenge (SMAC) scenarios. In this paper, we extend the DenseNet\nin MAIDRL and introduce semi-centralized Multi-Agent Dense-CNN Reinforcement\nLearning, MAIDCRL, by incorporating convolutional layers into the deep model\narchitecture, and evaluate the performance on both homogeneous and\nheterogeneous scenarios. The results show that the CNN-enabled MAIDCRL\nsignificantly improved the learning performance and achieved a faster learning\nrate compared to the existing MAIDRL, especially on more complicated\nheterogeneous SMAC scenarios. We further investigate the stability and\nrobustness of our model. The statistics reflect that our model not only\nachieves higher winning rate in all the given scenarios but also boosts the\nagent's learning process in fine-grained decision-making.",
        "updated": "2024-02-12 18:53:20 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.07890v1"
    },
    {
        "title": "WildfireGPT: Tailored Large Language Model for Wildfire Analysis",
        "authors": "Yangxinyu XieTanwi MallickJoshua David BergersonJohn K. HutchisonDuane R. VernerJordan BranhamM. Ross AlexanderRobert B. RossYan FengLeslie-Anne LevyWeijie Su",
        "links": "http://arxiv.org/abs/2402.07877v1",
        "entry_id": "http://arxiv.org/abs/2402.07877v1",
        "pdf_url": "http://arxiv.org/pdf/2402.07877v1",
        "summary": "The recent advancement of large language models (LLMs) represents a\ntransformational capability at the frontier of artificial intelligence (AI) and\nmachine learning (ML). However, LLMs are generalized models, trained on\nextensive text corpus, and often struggle to provide context-specific\ninformation, particularly in areas requiring specialized knowledge such as\nwildfire details within the broader context of climate change. For\ndecision-makers and policymakers focused on wildfire resilience and adaptation,\nit is crucial to obtain responses that are not only precise but also\ndomain-specific, rather than generic. To that end, we developed WildfireGPT, a\nprototype LLM agent designed to transform user queries into actionable insights\non wildfire risks. We enrich WildfireGPT by providing additional context such\nas climate projections and scientific literature to ensure its information is\ncurrent, relevant, and scientifically accurate. This enables WildfireGPT to be\nan effective tool for delivering detailed, user-specific insights on wildfire\nrisks to support a diverse set of end users, including researchers, engineers,\nurban planners, emergency managers, and infrastructure operators.",
        "updated": "2024-02-12 18:41:55 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.07877v1"
    },
    {
        "title": "Policy Improvement using Language Feedback Models",
        "authors": "Victor ZhongDipendra MisraXingdi YuanMarc-Alexandre Côté",
        "links": "http://arxiv.org/abs/2402.07876v1",
        "entry_id": "http://arxiv.org/abs/2402.07876v1",
        "pdf_url": "http://arxiv.org/pdf/2402.07876v1",
        "summary": "We introduce Language Feedback Models (LFMs) that identify desirable\nbehaviour - actions that help achieve tasks specified in the instruction - for\nimitation learning in instruction following. To train LFMs, we obtain feedback\nfrom Large Language Models (LLMs) on visual trajectories verbalized to language\ndescriptions. First, by using LFMs to identify desirable behaviour to imitate,\nwe improve in task-completion rate over strong behavioural cloning baselines on\nthree distinct language grounding environments (Touchdown, ScienceWorld, and\nALFWorld). Second, LFMs outperform using LLMs as experts to directly predict\nactions, when controlling for the number of LLM output tokens. Third, LFMs\ngeneralize to unseen environments, improving task-completion rate by 3.5-12.0%\nthrough one round of adaptation. Finally, LFM can be modified to provide\nhuman-interpretable feedback without performance loss, allowing human\nverification of desirable behaviour for imitation learning.",
        "updated": "2024-02-12 18:41:34 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.07876v1"
    }
]