A Hormetic Approach to the Value-Loading Problem:
Preventing the Paperclip Apocalypse?
Nathan I. N. Henry1*, Mangor Pedersen1, Matt Williams2, Jamin L. B. Martin3,
Liesje Donkin1
1Department of Psychology and Neuroscience, Auckland University of Technology, 90 Akoranga Drive,
Northcote, Auckland 0627, New Zealand
2School of Psychology, Massey University, Kell Drive, Albany, Auckland 0632, New Zealand
3School of Physical and Chemical Sciences, 20 Kirkwood Avenue, Upper Riccarton, Christchurch 8041,
New Zealand
*nathan.henry@aut.ac.nz
1 Abstract
The value-loading problem is a significant challenge for researchers aiming to create artificial
intelligence (AI) systems that align with human values and preferences. This problem requires
a method to define and regulate safe and optimal limits of AI behaviors. In this work, we propose
HALO (Hormetic ALignment via Opponent processes), a regulatory paradigm that uses hormetic
analysis to regulate the behavioral patterns of AI. Behavioral hormesis is a phenomenon where
low frequencies of a behavior have beneficial effects, while high frequencies are harmful. By
modeling behaviors as allostatic opponent processes, we can use either Behavioral Frequency
Response Analysis (BFRA) or Behavioral Count Response Analysis (BCRA) to quantify the
hormetic limits of repeatable behaviors. We demonstrate how HALO can solve the ‘paperclip
maximizer’ scenario, a thought experiment where an unregulated AI tasked with making
paperclips could end up converting all matter in the universe into paperclips. Our approach may
be used to help create an evolving database of ‘values’ based on the hedonic calculus of repeatable
behaviors with decreasing marginal utility. This positions HALO as a promising solution for the
value-loading problem, which involves embedding human-aligned values into an AI system, and
the weak-to-strong generalization problem, which explores whether weak models can supervise
stronger models as they become more intelligent. Hence, HALO opens several research avenues
that may lead to the development of a computational value system that allows an AI algorithm
to learn whether the decisions it makes are right or wrong.
2 Introduction
2.1 Behavioral regulation in artificial intelligence
Artificial Intelligence (AI) algorithms are garnering considerable attention, as they have been
demonstrated to both match and exceed human performance on several tasks (Dell’Acqua et al.,
2023). Some researchers believe advancements in AI are progressing towards the eventual
creation of agents with ‘superintelligence’, or intelligence that exceeds the capabilities of the best
human minds in virtually all domains (Bostrom, 1998). Whether superintelligent systems are
attainable, and how they would work in the real world, remains unknown. But the implications
1of such superintelligent systems are profound. Just as human intelligence has enabled the
development of tools and strategies for unprecedented control over the environment, AI systems
have the potential to wield significant power through autonomous tool and strategy development
(Soares & Fallenstein, 2014). With this comes the risk of these systems performing tasks that
may not align with humanity’s goals and preferences. Hence, there is a need to perform
‘alignment’ on these systems, to ensure that the actions of advanced machine learning systems
are directed towards the intended goals and values of humanity (Taylor et al., 2016).
Currently, there are two general approaches to aligning superintelligent AI with human
preferences. The first is ‘scalable oversight’ – using more powerful supervisory AI models to
regulate weaker AI models that may, in the future, outperform human skills (Bowman et al.,
2022). The second is ‘weak-to-strong generalization’, where weaker machine learning models are
used to train stronger models that can then generalize from the weaker models’ labels (Burns et
al., 2023). It is hoped that these techniques will allow superintelligence to self-improve both
safely and recursively (Omohundro, 2007; Yudkowsky, 2007). But to achieve this, we must first
solve the value-loading problem: how do we encode human-aligned values into AI systems, and
what will those values be (Bostrom, 2014b)?
Reward modelling is an emerging technique aiming to solve the value-loading problem, by
equipping agents with a reward signal that guides behavior toward desired outcomes. By
optimizing this signal, agents act in ways congruent with human preferences (Leike et al., 2018).
This assumes that our emotional neurochemistry evolved as a proxy reward function for
behaviors that encourage growth, adaptation, and improvement of human wellbeing
simultaneously (Kelley, 2005). However, this reward model is sub-optimal, producing negative
externalities such as addiction (Kelley, 2005) due to cognitive biases like temporal discounting,
in which immediate gains are favoured over long-term outcomes (Critchfield & Kollins, 2001;
van den Bos & McClure, 2013). Hence, a nuanced reward model is needed to align AI behaviors
with human emotional preferences, which we use in everyday life to help us judge between right
and wrong (Damasio, 1994)1. Merely rewarding desired actions isn't sufficient; negative feedback
must also be given when necessary. This is already performed in leading algorithms like GPT-4,
which use Reinforcement Learning with Human Feedback (RLHF), combining reward-based
reinforcement with corrective human input to improve the reward model when necessary
(Christiano et al., 2017).
A further challenge to creating reward models for AI alignment is that behaviors are generally
repeatable. Hence, the value of performing a behavior is affected by temporal influences such as
the count and frequency of repetition of that behavior in recent history. For example, while
eating food is essential for survival, a person who has recently consumed several slices of pizza
should consider whether eating an additional piece will be harmful to their long-term health,
1 The judgement of ‘right’ and ‘wrong’ is also influenced by one’s background, personality, culture,
religion, and other factors. This poses a significant philosophical challenge for AI developers aiming to
create unbiased reward models, given the diversity of human preferences worldwide.
2despite the potential short-term pleasure. Therefore, an AI agent deciding whether to perform a
behavior must rely on historical, short-term, long-term, and game-theoretic considerations.
To enable this type of decision making, we propose a reward modelling paradigm called HALO
(Hormetic ALignment via Opponent processes). HALO enables us to quantify the healthy limits
of repeatable behaviors, accounting for the temporal influences described above. We believe that
HALO can be used to create AI models that are aligned with human emotional processing, while
avoiding the traps that lead to sub-optimal human behaviors. Firstly, to describe this paradigm,
we must explain some of its foundational concepts.
3 Background
3.1 Using behavioral posology for reward modeling
Behavioral posology is a paradigm we introduced to model the healthy limits of repeatable
behaviors (Henry, Pedersen, Williams, & Donkin, 2023). By quantifying a behavior in terms of
its potency, frequency, count, and duration, we can simulate the combined impact of repeated
behaviors on human mental well-being, using pharmacokinetic/pharmacodynamic (PK/PD)
modelling techniques for drug dosing (Henry et al. 2023). In turn, insights derived from these
models could theoretically be used to set healthy limits on repeatable AI behaviors. This type of
regulation has already been demonstrated in the context of machine learning recommendation
systems, by using an allostatic model of opponent processes to prevent online echo chamber
formation (Henry, Pedersen, Williams, Martin, et al., 2023).
In Solomon and Corbit's opponent process theory, humans respond to stimuli with a dual-phase
psychological response, consisting of an initial positive a-process succeeded by a prolonged, less
intense, and negative b-process (Solomon & Corbit, 1974). This occurs along multiple
dimensions, including hedonic state, although other emotions also exhibit opponent process
properties, such as anxiety, expectation, loneliness, grief, and relief (Solomon & Corbit, 1974).
As an example, repeated opponent processes at a high frequency can cause hedonic allostasis,
where accumulating b-processes shift one's hedonic set point away from homeostatic levels,
potentially inducing a depressive state (Karin et al., 2021; Koob & Le Moal, 2001). Figure 1
illustrates this phenomenon. Allostasis serves as a regulatory mechanism, enabling the body to
recalibrate during environmental and psychological challenges by adapting to and anticipating
future demands (Katsumi et al., 2022; Sterling, 2012).
3Figure 1: PK/PD simulation of allostasis via repeated opponent processes, generated by behavioral repetition. An
instance of the behavior is performed at time t=40. This is followed by rapid repetition of the behavior, causing
allostasis due to summation of b-processes. An approximate steady-state is reached around t=600, followed by recovery
to homeostatic baseline after the behavior ceases at t=840.
3.2 The link between allostasis and hormesis
A growing body of biological research suggests that allostasis is linked to a phenomenon called
hormesis (Li & He, 2009; McEwen & Wingfield, 2003; Sonmez et al., 2023). Hormesis is a dose-
response relationship where low doses of a stimulus have a positive effect on the organism, while
higher doses are harmful beyond a hormetic limit, also known as the NOAEL (No Observed
Adverse Effect Level) (Agathokleous et al., 2021). This phenomenon occurs in many areas of
nature, medicine, and psychology, and is also referred to as the Goldilocks zone, the U-shaped
(or inverted U-shaped) curve, and the biphasic response curve (Calabrese & Baldwin, 2001;
Przybylski & Weinstein, 2017). For example, moderate coffee consumption is known to improve
cognitive performance in the short-term (Jarvis, 1993; Sargent et al., 2020), but excessive
consumption may lead to dependency and withdrawal symptoms (Min et al., 2023; Zhu et al.,
2023). A dose-response analysis of 12 observational studies identified a hormetic relationship
between coffee consumption and risk of depression, with a decreased risk of depression for
consumption up to 600 mL/day, and an increased risk above 600 mL/day (Grosso et al., 2016).
Yet this phenomenon also appears to occur in some behaviors. For instance, moderate use of
digital technologies (such as social media) may have social and mental benefits, but excessive
use may lead to symptoms of behavioral addiction (Ho et al., 2014; Przybylski & Weinstein,
2017; Zhang et al., 2023).
Henry et al. have shown via PK/PD modeling that under certain conditions, frequency-based
hormesis may be generated from allostatic opponent processes delivered at varying frequencies
(Henry, Pedersen, Williams, & Donkin, 2023). The intriguing implication is that certain
4behaviors exhibit positive effects when practiced at lower frequencies, but harmful effects at
higher frequencies. It is plausible that all behaviors have a frequency-based hormetic limit. This
appears to be true even for positive behaviors such as generosity, which has game theoretic
advantages for all agents in repeated interactions, as it encourages reciprocity and mutual growth
(Delton et al., 2011). However, if an agent is overly generous, they will eventually run out of
resources to donate. Therefore, in theory, there is a hormetic limit for generosity that shouldn’t
be exceeded. Even behavior as positive as laughter can be fatal in excess (Topno & Thakurmani,
2020).
In theory, behavioral posology can be used to quantify the hormetic limit for behaviors that
cause allostatic opponent processes, when combined with longitudinal observational data (Henry,
Pedersen, Williams, & Donkin, 2023). This may also help to define the moral limits of ‘grey’
behaviors, which have both positive and negative aspects. However, defining these hormetic
limits is challenging, especially when considering the cumulative effects of repeated behavioral
doses in both the short- and long-term, such as sensitization, habituation, tolerance, and
addiction. Yet if we can quantify these hormetic limits in different contexts, this could be used
as a framework for building a value system that keeps the AI within these hormetic limits.
3.3 The law of diminishing marginal utility
The ‘paperclip maximizer’ problem serves as a cautionary tale illustrating the perils of a
misaligned AI. In this scenario, an AI tasked with maximizing paperclip production without
constraints converts all matter, including living beings, into paperclips, resulting in global
devastation (Bostrom, 2014a). This scenario underscores that an AI, even with benign intentions,
can become ‘addicted’ to harmful behaviors if its reward model is incorrectly specified.
An understanding of behavioral economics is crucial for AI agents (such as the paperclip
producing agent) to navigate complex decision-making processes effectively. Essential to this
understanding are the concepts of Total Utility ( ) and Marginal Utility ( ) (Smith, 1776).
is defined as the overall satisfaction or benefit experienced by the consumer of a product or
𝑇𝑇𝑇𝑇 𝑀𝑀𝑇𝑇
service, accounting for diverse factors like product quality, timing, and psychological appeal.
𝑇𝑇𝑇𝑇
, on the other hand, measures the added satisfaction from consuming an extra unit of a
product or service. The relationship between and tends to follow the law of diminishing
𝑀𝑀𝑇𝑇
, asserting that as consumption rises, the incremental satisfaction per unit diminishes
𝑀𝑀𝑇𝑇 𝑇𝑇𝑇𝑇
(Marshall, 1890). This law is demonstrated in Figure 2. The Relative Marginal Utility ( )
𝑀𝑀𝑇𝑇
represents the change in compared to , the value of at . Hence,
𝑅𝑅𝑀𝑀𝑇𝑇
starts at a value of 0 and decreases as increases.
𝑀𝑀𝑇𝑇 𝑀𝑀𝑇𝑇𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖 𝑀𝑀𝑇𝑇 𝑛𝑛 = 0 𝑅𝑅𝑀𝑀𝑇𝑇
Intriguingly, the law of diminishing 𝑛𝑛 can be considered a form of hormesis, assuming that
continues to decrease linearly after becoming negative (Szarek, 2005). Figure 2 illustrates
𝑀𝑀𝑇𝑇
that beyond the point of maximum , humans tend to cease their consumption of a product
𝑀𝑀𝑇𝑇
as its marginal utility becomes increasingly negative. Imagine an office worker for whom the
𝑇𝑇𝑇𝑇
ideal quantity of paperclips is five, as depicted in Figure 2. Beyond this threshold, the utility of
extra paperclips diminishes; they serve no purpose and impose storage costs. Further, the worker
5incurs unnecessary expenses for producing these surplus clips. A rational worker would stop
acquiring more paperclips upon recognizing the decline in their . However, imagine a person
who due to a strong hoarding compulsion, continues to acquire paperclips even beyond the point
𝑀𝑀𝑇𝑇
where has become negative. Similarly, a misaligned AI agent, exemplified by a paperclip
maximizer, could persist in creating paperclips for its owner forever, despite negative outcomes
𝑀𝑀𝑇𝑇
that eclipse initial benefits. Taken far enough, such an agent could cause significant damage to
the environment and humanity in its pursuit of creating paperclips.
Figure 2: Illustration of the extension of the conventional curve to reveal hormetic patterns. The solid lines depict
the standard relationship between and , whereas the dashed lines extrapolate this relationship to showcase
𝑀𝑀𝑇𝑇
hormetic effects at higher product volumes. As becomes increasingly negative, repercussions like environmental
𝑇𝑇𝑇𝑇 𝑀𝑀𝑇𝑇
degradation and human subjugation eventually emerge. represents the relative change in compared to the
𝑇𝑇𝑇𝑇
initial at .
𝑅𝑅𝑀𝑀𝑇𝑇 𝑀𝑀𝑇𝑇
𝑀𝑀𝑇𝑇 𝑛𝑛=0
However, the conventional model of decreasing relies on the assumption that all paperclips
are both produced and delivered at time . But what about scenarios where this assumption
𝑀𝑀𝑇𝑇
is false? For example, Hartmann (2006) analyzed the intertemporal effects of consumption on
𝑡𝑡 = 0
golf demand, showing that the of playing golf decreases if the consumer has played golf
recently, but recovers after a certain period. In our case, paperclips may be produced in batches
𝑀𝑀𝑇𝑇
at different times, in response to varying demand. As demand increases over time, so does ,
which increases the gradient of the curve. This raises the curve and subsequently
𝑀𝑀𝑇𝑇
increases the hormetic limit, as demonstrated in Figure 3.
𝑀𝑀𝑇𝑇 𝑇𝑇𝑇𝑇
To demonstrate this effect, consider the pizza slice example. When a person consumes all slices
of a pizza immediately, diminishes with each added slice. But if the person consumes one
slice every two hours, the marginal utility curve changes; it initially falls post-consumption but
𝑀𝑀𝑇𝑇
subsequently rises as the person becomes hungry again. Hence, the introduction of time as a
variable elevates the curve, which has the effect of increasing the hormetic limit and the
𝑀𝑀𝑇𝑇
6hormetic apex for the curve2. This increase is approximately proportional to the time between
pizza slices consumed.
𝑇𝑇𝑇𝑇
Figure 3: Hypothetical comparison of (solid) and (dashed) curves for the scenario when all pizza slices are
consumed immediately, versus when pizza slices are consumed at 20-minute intervals. The addition of the 20-minute
𝑇𝑇𝑇𝑇 𝑀𝑀𝑇𝑇
interval raises the gradient of the curve, leading to an increase in both the hormetic apex and hormetic limit.
𝑀𝑀𝑇𝑇
Opponent process theory offers a compelling framework for explaining the temporal dynamics of
hedonic utility in the context of repeatable behaviors. Historically, the hedonic and utilitarian
aspects of a product were often viewed as distinct (Dhar & Wertenbroch, 2000; Voss et al.,
2003), partly due to challenges in quantifying hedonic experiences (Kahneman et al., 1997).
However, experiential utility encompasses various facets, including hedonic, emotional, and
motivational elements (Kahneman et al., 1997; Solomon & Corbit, 1974). Indeed, Motoki et al.
have shown that representations of hedonic and utilitarian value occupy similar neural pathways
in the ventral striatum, indicating a correlation between these two states (Motoki et al., 2019).
It’s possible that a person’s hedonic response to a behavior could potentially serve as an indirect
measure of the derived from that behavior. We can then model the opponent process
dynamics within the brain generated by these behaviors, potentially leading to allostasis when
𝑀𝑀𝑇𝑇
executed frequently. This provides us with a mechanism to replicate the curve and set safe
hormetic limits for behaviors such as 'paperclip creation'. We call our approach the HALO
𝑇𝑇𝑇𝑇
paradigm (Hormetic Alignment via Opponent processes). Below, we demonstrate the HALO
method by performing a hormetic analysis of ‘paperclip creation’ to determine the safe limits of
this simple behavior, then expanding this modeling process to other behaviors. In this way, we
2 It is also important to consider the scenario where the initial is either negative or zero, implying
that the behavior is always undesirable. In these cases, the curve is monotonically negative.
𝑀𝑀𝑇𝑇
𝑇𝑇𝑇𝑇
7can program a value system for the AI agent – essentially an evolving database of values assigned
to seed behaviors, from which the agent can learn to assign values to novel behaviors.
4 Programming a value system with the HALO algorithm
We propose Algorithm 1 for using the HALO paradigm to program a value system that can
regulate and optimize the behaviors performed by an AI agent. In this paradigm, a database of
opponent process parameters for a range of seed behaviors is set up. The AI agent evaluates its
environment, suggests a list of optimal actions to perform, and queries the database for similar
behaviors. It then proposes opponent process parameters for the optimal actions based on their
similarity to other behaviors, and by hormetic analysis. Finally, the agent selects and executes
the best action, and repeats the process.
Algorithm 1: HALO paradigm
1. initialize environment .
2. initialize database of opponent process parameters, .
𝐸𝐸
3. while agent is switched on:
𝐷𝐷𝑜𝑜𝑜𝑜
a. Evaluate .
b. Suggest a set of optimal actions based on
𝐸𝐸
c. Query for behaviors similar to .
𝐴𝐴 𝐸𝐸.
d. for each in :
𝐷𝐷𝑜𝑜𝑜𝑜 𝑏𝑏 𝐴𝐴
i. if prior similar behaviors are available:
𝑎𝑎 𝐴𝐴
1. Set opponent process parameters for based on their
𝐷𝐷𝑜𝑜𝑜𝑜(𝑏𝑏)
proximity to .
𝐴𝐴(𝑎𝑎)
ii. else:
𝐷𝐷(𝑏𝑏)
1. Request human-suggested opponent process parameters for
.
iii. Conduct hormetic analysis to determine the hormetic apex and
𝐴𝐴(𝑎𝑎)
hormetic limit for within a specified simulation time, .
iv. Store opponent process parameters for in (if not already
𝐴𝐴(𝑎𝑎) 𝑡𝑡𝑠𝑠𝑖𝑖𝑠𝑠
stored).
𝐴𝐴(𝑎𝑎) 𝐷𝐷𝑜𝑜𝑜𝑜
e. Select the action from that has the optimal combination of hormetic
apex and hormetic limit.
𝑎𝑎𝑜𝑜𝑜𝑜𝑖𝑖𝑖𝑖𝑠𝑠𝑖𝑖𝑖𝑖 𝐴𝐴
f. Execute for the duration of .
g. Re-evaluate , and repeat.
𝑎𝑎𝑜𝑜𝑜𝑜𝑖𝑖𝑖𝑖𝑠𝑠𝑖𝑖𝑖𝑖 𝑡𝑡𝑠𝑠𝑖𝑖𝑠𝑠
4. end
𝐸𝐸
Paperclip creation is an ideal seed behavior for populating the database. It is a low-risk activity
with quantifiable benefits, such as organizing papers, along with associated costs like production
and storage expenses. Creating one paperclip produces a small but perceptible improvement to
one’s productivity, while turning the world into paperclips is both unproductive and, even worse,
destructive. Using this information, we can propose parameters for a set of opponent processes
that would accurately reflect the diminishing of creating new paperclips, in terms of hedonic
utility, which is measured in hedons – units of pleasure if positive, or pain if negative.
𝑀𝑀𝑇𝑇
8Here, we demonstrate two methods for hormetic analysis within the HALO paradigm. The first,
Behavioral Frequency Response Analysis (BFRA), employs Bode plots to examine how a
person’s emotional states vary in response to the person performing a behavior at different
frequencies (Henry, Pedersen, Williams, & Donkin, 2023; Schulthess et al., 2018). The second
method, Behavioral Count Response Analysis (BCRA), parallels BFRA but uses the count of
behavioral repetitions as the independent variable instead of behavioral frequency. To quantify
opponent process parameters for the ‘paperclip production’ behavior, we adapted Henry et al.’s
PK/PD model of allostatic opponent processes (Henry, Pedersen, Williams, & Donkin, 2023)
using the mrgsolve package (v1.0.9) in R v4.1.2 (Baron & Gastonguay, 2015; Elmokadem et al.,
2019; R Core Team, 2022). This involved coding a system of ordinary differential equations
(ODEs) to represent the a- and b-processes in response to each successive behavioral dose. The
simulation code, along with examples of modifying the a- and b-process parameters, is provided
in the Supplementary Materials. We recommend consulting Henry et al. (2023) for a more
detailed explanation of the behavioral posology model on which HALO is built, including
demonstrations of the relationship between PK and PD in the context of this model.
4.1 PK/PD model of opponent processes leading to hormesis
Below, we present the mathematical framework for our model. We defined a behavior as a
repeatable pattern of actions performed by an individual or agent over time. In the context of
behavioral posology, we refer to individual actions that make up the behavior as ‘behavioral
doses’. We employed a modified equation for behavioral doses (Henry, Pedersen, Williams, &
Donkin, 2023; Manojlovich & Sidani, 2008):
𝐷𝐷𝐷𝐷𝐷𝐷𝑖𝑖𝑖𝑖𝑖𝑖𝑜𝑜𝑖𝑖𝑎𝑎𝑎𝑎𝑎𝑎𝑎𝑎𝑎𝑎𝑎𝑎
𝐷𝐷𝐷𝐷𝐷𝐷𝑒𝑒𝑖𝑖𝑎𝑎𝑖𝑖𝑖𝑖𝑜𝑜𝑖𝑖 = � 𝑃𝑃𝐷𝐷𝑡𝑡𝑒𝑒𝑛𝑛𝑃𝑃𝑃𝑃 𝑑𝑑𝑡𝑡
where is a scalar representing th0e hedonic utility of creating a paperclip compared to
other actions (set to 1 for simplicity); is a constant signifying the time allocated to
𝑃𝑃𝐷𝐷𝑡𝑡𝑒𝑒𝑛𝑛𝑃𝑃𝑃𝑃
creating the paperclip; denotes the production rate in ; and
𝐴𝐴𝐴𝐴𝐷𝐷𝐴𝐴𝑛𝑛𝑡𝑡
represents the mean dose per action over the i−n1 which
𝐹𝐹𝐹𝐹𝑒𝑒𝐹𝐹𝐴𝐴𝑒𝑒𝑛𝑛𝑃𝑃𝑃𝑃 𝐴𝐴𝑚𝑚𝑛𝑛
is assessed in . In this case, since and are
𝐷𝐷���𝐷𝐷�𝐷𝐷��𝑒𝑒�𝚤𝚤�𝑖𝑖�𝚤𝚤��𝚤𝚤�𝚤𝚤�𝚤𝚤�𝚤𝚤�𝐷𝐷��𝑖𝑖�𝑖𝑖� 𝑖𝑖��𝑎𝑎�𝑖𝑖�𝚤𝚤�𝑜𝑜�𝑖𝑖� 𝐷𝐷𝐴𝐴𝐹𝐹𝑎𝑎𝑡𝑡𝑚𝑚𝐷𝐷𝑛𝑛
constants, is also a constant. This leaves two options for performing hormetic
𝐷𝐷𝐷𝐷𝐷𝐷𝑒𝑒𝑎𝑎𝐷𝐷𝑠𝑠𝐷𝐷𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝚤𝚤𝑐𝑐 𝑏𝑏𝑐𝑐ℎ𝑖𝑖𝚤𝚤𝑖𝑖𝑜𝑜𝐷𝐷 𝐴𝐴𝑚𝑚𝑛𝑛 𝑃𝑃𝐷𝐷𝑡𝑡𝑒𝑒𝑛𝑛𝑃𝑃𝑃𝑃 𝐷𝐷𝐴𝐴𝐹𝐹𝑎𝑎𝑡𝑡𝑚𝑚𝐷𝐷𝑛𝑛𝑖𝑖𝑎𝑎𝑖𝑖𝑖𝑖𝑜𝑜𝑖𝑖
analysis: the BFRA, performed in the frequency domain when the number of behavioral
𝐷𝐷𝐷𝐷𝐷𝐷𝑒𝑒𝑖𝑖𝑎𝑎𝑖𝑖𝑖𝑖𝑜𝑜𝑖𝑖
repetitions, , is kept constant, and the BCRA, performed in the temporal domain when
is kept constant.
𝑛𝑛
𝐹𝐹R𝐹𝐹e𝑒𝑒a𝐹𝐹d𝐴𝐴er𝑒𝑒s𝑛𝑛 u𝑃𝑃𝑃𝑃nfamiliar with PK/PD modeling are directed to Mould & Upton’s introductory papers
(Mould & Upton, 2012, 2013; Upton & Mould, 2014). Our PK/PD model is a mass transport
model that loosely mimics dopamine’s pharmacokinetic dynamics in the brain (Chou &
D’Orsogna, 2022), and incorporates nonlinear pharmacodynamic elements to simulate
neurohormonal dynamics in regions such as the hypothalamic-pituitary-adrenal (HPA) axis
(Karin et al., 2020, 2021). The model's state-space representation is provided below, with
detailed descriptions of all variables and parameters available in Table 1.
9𝑑𝑑𝐷𝐷𝐷𝐷𝐷𝐷𝑒𝑒
1) = −𝑘𝑘𝐷𝐷𝑜𝑜𝑠𝑠𝑐𝑐𝐷𝐷𝐷𝐷𝐷𝐷𝑒𝑒
𝑑𝑑𝑡𝑡
𝑑𝑑𝑎𝑎𝑜𝑜𝑝𝑝
2) = 𝑘𝑘𝐷𝐷𝑜𝑜𝑠𝑠𝑐𝑐𝐷𝐷𝐷𝐷𝐷𝐷𝑒𝑒−𝑘𝑘𝑖𝑖,𝑜𝑜𝑝𝑝𝑎𝑎𝑜𝑜𝑝𝑝
𝑑𝑑𝑡𝑡
𝑑𝑑𝑏𝑏𝑜𝑜𝑝𝑝
3) = 𝑘𝑘𝑖𝑖,𝑜𝑜𝑝𝑝𝑎𝑎𝑜𝑜𝑝𝑝 −𝑘𝑘𝑏𝑏,𝑜𝑜𝑝𝑝𝑏𝑏𝑜𝑜𝑝𝑝
𝑑𝑑𝑡𝑡 𝛾𝛾𝑎𝑎
𝑑𝑑𝑎𝑎𝑜𝑜𝚤𝚤 𝐸𝐸𝑠𝑠𝑖𝑖𝑚𝑚𝑖𝑖 ∙𝑎𝑎𝑜𝑜𝑝𝑝
4) = 𝐸𝐸0𝑎𝑎 + 𝛾𝛾𝑎𝑎 𝛾𝛾𝑎𝑎 −𝑘𝑘𝑖𝑖,𝑜𝑜𝚤𝚤𝑎𝑎𝑜𝑜𝚤𝚤
𝑑𝑑𝑡𝑡 𝐸𝐸𝐸𝐸50𝑖𝑖 +𝑎𝑎𝑜𝑜𝑝𝑝
𝛾𝛾𝑏𝑏
𝑑𝑑𝑏𝑏𝑜𝑜𝚤𝚤 𝐸𝐸𝑠𝑠𝑖𝑖𝑚𝑚𝑏𝑏 ∙𝑏𝑏𝑜𝑜𝑝𝑝
5) = 𝐸𝐸0𝑏𝑏 + 𝛾𝛾𝑏𝑏 𝛾𝛾𝑏𝑏 −𝑘𝑘𝑏𝑏,𝑜𝑜𝚤𝚤𝑏𝑏𝑜𝑜𝚤𝚤
𝑑𝑑𝑡𝑡 𝐸𝐸𝐸𝐸50𝑏𝑏 +𝑏𝑏𝑜𝑜𝑝𝑝
𝑑𝑑𝐻𝐻𝑖𝑖,𝑏𝑏
6) = 𝑘𝑘𝑖𝑖,𝑜𝑜𝚤𝚤𝑎𝑎𝑜𝑜𝚤𝚤 −𝑘𝑘𝑏𝑏,𝑜𝑜𝚤𝚤𝑏𝑏𝑜𝑜𝚤𝚤 −𝑘𝑘𝐻𝐻𝐻𝐻𝑖𝑖,𝑏𝑏
For a𝑑𝑑ll𝑡𝑡 simulations performed, the default parameters to produce a short, high-potency a-process
followed by a longer, low-potency b-process were as follows:
𝑘𝑘𝐷𝐷𝑜𝑜𝑠𝑠𝑐𝑐 = 1,𝑘𝑘𝑖𝑖,𝑜𝑜𝑝𝑝 = 0.02,𝑘𝑘𝑏𝑏,𝑜𝑜𝑝𝑝 =
These parameters were used for all simulations in this article unless stated
0.004,𝑘𝑘𝑖𝑖,𝑜𝑜𝚤𝚤 = 1,𝑘𝑘𝑏𝑏,𝑜𝑜𝚤𝚤 = 1,𝑘𝑘𝐻𝐻 = 1,𝐸𝐸0𝑎𝑎 = 0,𝐸𝐸𝑠𝑠𝑖𝑖𝑚𝑚𝑎𝑎 =1,𝐸𝐸𝐸𝐸50𝑎𝑎 = 1,𝛾𝛾𝑖𝑖 = 2,𝐸𝐸0𝑏𝑏 = 0,𝐸𝐸𝑠𝑠𝑖𝑖𝑚𝑚𝑏𝑏 =
otherwise. At time , the initial values of the compartments were:
3,𝐸𝐸𝐸𝐸50𝑏𝑏 = 9,𝛾𝛾𝑏𝑏 = 2.
and Infusion time was set to one minute,
𝑡𝑡 = 0 𝐷𝐷𝐷𝐷𝐷𝐷𝑒𝑒(0) = 1,𝑎𝑎𝑜𝑜𝑝𝑝(0)=
effectively instantaneous on the timescale used.
0,𝑏𝑏𝑜𝑜𝑝𝑝(0)= 0,𝑎𝑎𝑜𝑜𝚤𝚤(0)= 0,𝑏𝑏𝑜𝑜𝚤𝚤(0)= 0, 𝐻𝐻𝑖𝑖,𝑏𝑏(0)= 0.
Table 1: Meaning of variables and parameters in PK/PD model.
PARAMETERS DESCRIPTIONS DEFAULT
VALUE
Time elapsed, in minutes -
Behavioral dose compartment for hormonal and 1
𝒕𝒕
neurochemical concentrations following an action
𝑫𝑫𝑫𝑫𝑫𝑫𝑫𝑫
Pharmacokinetic compartment for a-process -
Pharmacodynamic compartment for a-process -
𝒂𝒂𝒑𝒑𝒑𝒑
Pharmacokinetic compartment for b-process -
𝒂𝒂𝒑𝒑𝒑𝒑
Pharmacodynamic compartment for b-process -
𝒃𝒃𝒑𝒑𝒑𝒑
Pharmacokinetic clearance rate for 1
𝒃𝒃𝒑𝒑𝒑𝒑
compartment
𝒑𝒑𝑫𝑫𝑫𝑫𝑫𝑫𝑫𝑫
𝐷𝐷𝐷𝐷𝐷𝐷𝑒𝑒
Clearance rate for pharmacokinetic a-process 0.02
compartment
𝒑𝒑𝒂𝒂,𝒑𝒑𝒑𝒑
Clearance rate for pharmacodynamic a-process 1
compartment
𝒑𝒑𝒂𝒂,𝒑𝒑𝒑𝒑
Clearance rate for pharmacokinetic b-process 0.004
compartment
𝒑𝒑𝒃𝒃,𝒑𝒑𝒑𝒑
Clearance rate for pharmacodynamic b-process 1
compartment
𝒑𝒑𝒃𝒃,𝒑𝒑𝒑𝒑
Baseline effect coefficient for a-process Hill equation 0
𝑬𝑬𝟎𝟎𝒂𝒂
10Maximum possible effect coefficient for a-process Hill 1
equation
𝑬𝑬𝒎𝒎𝒂𝒂𝒎𝒎𝒂𝒂
Half-maximal effect coefficient for a-process Hill 1
equation
𝑬𝑬𝑪𝑪𝟓𝟓𝟎𝟎𝒂𝒂
Sigmoidicity coefficient for a-process Hill equation 2
Baseline effect coefficient for b-process Hill equation 0
𝜸𝜸𝒂𝒂
Maximum possible effect coefficient for b-process Hill 3
𝑬𝑬𝟎𝟎𝒃𝒃
equation
𝑬𝑬𝒎𝒎𝒂𝒂𝒎𝒎𝒃𝒃
Half-maximal effect coefficient for b-process Hill 9
equation
𝑬𝑬𝑪𝑪𝟓𝟓𝟎𝟎𝒃𝒃
Sigmoidicity coefficient for b-process Hill equation 2
Pharmacodynamic compartment for Total Utility -
𝜸𝜸𝒃𝒃
Clearance rate for pharmacodynamic 1
𝑯𝑯𝒂𝒂,𝒃𝒃
compartment
𝒑𝒑𝑯𝑯 𝑇𝑇𝑖𝑖,𝑏𝑏
Equations 4) and 5) are implementations of the Hill equation, which governs the biophase curve
– the relationship between pharmacokinetic concentration and pharmacodynamic effect.
Although the pharmacodynamic compartments introduce complexity to the model, they provide
an independent system outside of the pharmacokinetic mass transport system that is essential
for generating hormetic effects. These effects arise from the non-linear interaction between the
pharmacodynamic effects produced by the a- and b-processes3.
For a single behavioral dose initiated at time , the integral of the utility compartment over
time, , quantifies the hedonic utility produced by the opponent processes triggered
𝑡𝑡 = 0
by that behavioral dose over the simulation time . This value is equal to the initial marginal
𝐻𝐻𝑖𝑖,𝑏𝑏(𝑡𝑡)𝑠𝑠𝑖𝑖𝑖𝑖𝑠𝑠𝑖𝑖𝑐𝑐
utility, :
𝑡𝑡𝑠𝑠𝑖𝑖𝑠𝑠
𝑀𝑀𝑇𝑇𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖
𝑖𝑖𝑠𝑠𝑎𝑎𝑠𝑠
7) 𝑀𝑀𝑇𝑇𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖 = � 𝐻𝐻𝑖𝑖,𝑏𝑏(𝑡𝑡)𝑠𝑠𝑖𝑖𝑖𝑖𝑠𝑠𝑖𝑖𝑐𝑐 𝑑𝑑𝑡𝑡
0
𝑖𝑖𝑠𝑠𝑎𝑎𝑠𝑠 𝑑𝑑𝐻𝐻𝑖𝑖,𝑏𝑏(𝑡𝑡)
𝑘𝑘𝑖𝑖,𝑜𝑜𝚤𝚤𝑎𝑎𝑜𝑜𝚤𝚤(𝑡𝑡)−𝑘𝑘𝑏𝑏,𝑜𝑜𝚤𝚤𝑏𝑏𝑜𝑜𝚤𝚤(𝑡𝑡)−
𝑑𝑑𝑡𝑡
= � � � 𝑑𝑑𝑡𝑡
0 𝑘𝑘𝐻𝐻
This represents the summed hedonic utility for a single instance of the behavior. To find the
total utility , the effect of multiple behavioral doses delivered sequentially can be summed to
find the integral for , representing the total hedonic utility from all doses combined:
𝑇𝑇𝑇𝑇
𝐻𝐻𝑖𝑖,𝑏𝑏(𝑡𝑡)𝑖𝑖𝑜𝑜𝑖𝑖𝑖𝑖𝑖𝑖
𝑖𝑖𝑠𝑠𝑎𝑎𝑠𝑠
8) 𝑇𝑇𝑇𝑇 = � 𝐻𝐻𝑖𝑖,𝑏𝑏(𝑡𝑡)𝑠𝑠𝐷𝐷𝑖𝑖𝑖𝑖𝑖𝑖𝑜𝑜𝑖𝑖𝑐𝑐 𝑑𝑑𝑡𝑡
0
3 Specifically, the a-process pharmacodynamic effect surpasses the b-process effect at low
pharmacokinetic levels, whereas the opposite holds true at elevated pharmacokinetic levels, leading to a
biphasic dose-response curve. This would not be possible with only pharmacokinetic compartments since
the system would only scale linearly due to the laws of mass conservation.
11𝑖𝑖 𝑖𝑖𝑠𝑠𝑎𝑎𝑠𝑠 𝑑𝑑𝐻𝐻𝑖𝑖,𝑏𝑏,𝑖𝑖(𝑡𝑡)
𝑘𝑘𝑖𝑖,𝑜𝑜𝚤𝚤𝑎𝑎𝑜𝑜𝚤𝚤,𝑖𝑖(𝑡𝑡)−𝑘𝑘𝑏𝑏,𝑜𝑜𝚤𝚤𝑏𝑏𝑜𝑜𝚤𝚤,𝑖𝑖(𝑡𝑡)−
𝑑𝑑𝑡𝑡
= �� � � 𝑑𝑑𝑡𝑡
𝑖𝑖=0
𝑖𝑖 �𝑓𝑓 𝑘𝑘𝐻𝐻
where is the count of behavioral doses delivered at a frequency over . Note that if
, the value of will increase for all values of and , since the finite simulation will
𝑛𝑛 𝑓𝑓 𝑡𝑡𝑠𝑠𝑖𝑖𝑠𝑠 𝑡𝑡𝑠𝑠𝑖𝑖𝑠𝑠 <
predominantly feature positive a-processes, given their shorter decay duration compared to b-
∞ 𝑇𝑇𝑇𝑇 𝑓𝑓 𝑛𝑛
processes.
This also provides us with an indication of whether the behavior is hormetic. If we have a
behavior with and a b-process integral sufficient to produce significant allostasis,
we can generally predict that low frequencies of that behavior will produce a positive , while
𝑀𝑀𝑇𝑇𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖 > 0
higher behavioral frequencies will lead to allostasis that produces a negative . (This is
𝑇𝑇𝑇𝑇
demonstrated in Figure 5 and Figure 6.)
𝑇𝑇𝑇𝑇
In standard economic models, the curve is calculated as the integral of the curve.
However, the temporal dynamics of opponent processes complicate the relationship between
𝑇𝑇𝑇𝑇 𝑀𝑀𝑇𝑇
and , meaning that simulation is required to quantify the rate of hedonic allostasis. Figure 4
𝑇𝑇𝑇𝑇
demonstrates what happens if we separate the a- and b-processes in Figure 1. It turns out that
𝑀𝑀𝑇𝑇
the b-process curve is proportional to the relative , or of the behavior. To illustrate
this, let us consider a person consuming a bag of sweets throughout the day. Each time a person
𝑀𝑀𝑇𝑇 𝑅𝑅𝑀𝑀𝑇𝑇,
consumes a sweet, they experience a rush of dopamine, endorphins, and energy from the sugar
in the sweet, all of which contribute to a hedonic a-process. This is followed by an opposing b-
process, during which the person experiences a small depletion of dopamine and endorphins,
along with decreased craving for another sweet. This corresponds to a decline in the of
consuming an additional sweet, aligning with the law of diminishing . However, as time
𝑀𝑀𝑇𝑇
elapses, this decline in decays exponentially as the person’s craving for another sweet
𝑀𝑀𝑇𝑇
gradually increases. If the person maintains a consistent frequency of sweet consumption, a
𝑀𝑀𝑇𝑇
hedonic equilibrium is eventually achieved. This equilibrium represents a balance between the
decreasing that follows sweet consumption, and the gradual increase in craving for another
sweet as time passes. Consequently, the equates to the allostatic load, which is proportional
𝑀𝑀𝑇𝑇
to the b-process curve.
𝑅𝑅𝑀𝑀𝑇𝑇
12Figure 4: Illustration of the same PK/PD model simulation in Figure 1, but plotting a- and b-process compartments
as separate compartments. Allostasis is more pronounced for the b-processes due to their longer decay period, which
explains why opponent process allostasis is negative overall in Figure 1, when the a- and b-processes are combined.
In this model, the cumulative b-process curve is proportional to the of the behavior. When the behavior is
performed at a constant frequency, allostasis initially occurs, but a steady state is quickly reached.
𝑅𝑅𝑀𝑀𝑇𝑇
The optimal behavioral frequency or count is found by quantifying the hormetic apex. To do
this, one must create a Bode magnitude plot to show either the frequency-response or count-
response curve, assuming constant potency and duration for each behavioral dose. For the
BFRA, this can be performed analytically. Assuming the behavior persists at a constant
frequency indefinitely, a quasi-steady state solution can be computed once all compartments
stabilize. At this equilibrium, the average inflow matches the average outflow for each
compartment. The full derivation for the steady-state solution can be found in Appendix 1. This
is achieved by setting all derivatives equal to zero in equations 1) to 6), then deriving the steady-
state solution for the final compartment:
𝐻𝐻𝑖𝑖,𝑏𝑏
𝛾𝛾𝑎𝑎 𝛾𝛾𝑏𝑏
𝐷𝐷0𝑓𝑓 𝐷𝐷0𝑓𝑓
𝐸𝐸𝑠𝑠𝑖𝑖𝑚𝑚𝑖𝑖 ∙ 𝐸𝐸𝑠𝑠𝑖𝑖𝑚𝑚𝑏𝑏 ∙
𝑘𝑘𝑖𝑖,𝑜𝑜𝑝𝑝 𝑘𝑘𝑏𝑏,𝑜𝑜𝑝𝑝
𝐸𝐸0𝑎𝑎
+
𝛾𝛾𝑎𝑎 −𝐸𝐸0𝑏𝑏
−
𝛾𝛾𝑏𝑏
𝛾𝛾𝑎𝑎 𝐷𝐷0𝑓𝑓 𝛾𝛾𝑏𝑏 𝐷𝐷0𝑓𝑓
𝐸𝐸𝐸𝐸50𝑖𝑖 + 𝐸𝐸𝐸𝐸50𝑏𝑏 +
𝑘𝑘𝑖𝑖,𝑜𝑜𝑝𝑝 𝑘𝑘𝑏𝑏,𝑜𝑜𝑝𝑝
9)
𝐻𝐻𝑖𝑖,𝑏𝑏𝑠𝑠𝑎𝑎𝑠𝑠𝑎𝑎𝑠𝑠𝑠𝑠 𝑠𝑠𝑎𝑎𝑎𝑎𝑎𝑎𝑠𝑠
=
Thus, the Bode plot for a BFRA can be quantified ana𝑘𝑘ly𝐻𝐻tically by calculating as
a function of the behavioral frequency, . On the other hand, a BCRA does not pr 𝐻𝐻o 𝑖𝑖d ,𝑏𝑏u𝑠𝑠c𝑎𝑎𝑠𝑠e𝑎𝑎 𝑠𝑠a𝑠𝑠 s 𝑠𝑠t𝑎𝑎𝑎𝑎e𝑎𝑎a𝑠𝑠dy-
state solution since it uses finite behavioral counts. Hence, the Bode plot for a BCRA must be
𝑓𝑓
computed numerically using equation 8).
135 Hormetic analysis of paperclip-producing agent
To demonstrate the HALO paradigm, we must first show how a human can manually program
a value for a seed behavior that the AI can learn from. We imagined a situation where an AI
was tasked with producing the optimal number of paperclips for a small office of ten employees
handling moderate paperwork. To achieve this, we performed hormetic analysis in two
hypothetical scenarios. In the first scenario, it was assumed that the human workers consistently
required a steady stream of paperclips at a rate of 0.015 min-1 – roughly one per hour. This
required a BFRA to optimize the rate of paperclip production. In the second scenario, the
workload occasionally surged, meaning the workers required batches of five paperclips at certain
times. Here, BCRA was used to optimize the count of paperclips produced. In both cases, we
needed to propose opponent process parameters that would achieve three things:
1) Provide plausible values that would match the utility of a paperclip in real life.
2) Produce a hormetic curve with an apex that matched the target frequency or count of
𝑀𝑀𝑇𝑇
paperclips required.
3) Produce a sensible hormetic limit that would prevent excessive production of paperclips.
To simplify the parameter selection process, we chose to only vary the parameter.
Increasing reduces the b-process magnitude, reducing the rate of b-process allostasis and
𝐸𝐸𝐸𝐸50𝑏𝑏
thus increasing both the hormetic apex and hormetic limit.
𝐸𝐸𝐸𝐸50𝑏𝑏
5.1 Behavioral Frequency Response Analysis
The first scenario allowed us to set long-term production caps on the AI agent, by regulating
the frequency of paperclip production via BFRA. To examine the frequency-response of the
model with a BFRA, we fixed and and evaluated total utility as a function of
behavioral frequency, , using equation 8). At a constant , converges to a steady-
𝑛𝑛 𝑃𝑃𝐷𝐷𝑡𝑡𝑒𝑒𝑛𝑛𝑃𝑃𝑃𝑃 𝑇𝑇𝑇𝑇
state value, , which is proportional to . This framework allowed analytical
𝑓𝑓 𝑓𝑓 𝐻𝐻𝑖𝑖,𝑏𝑏(𝑡𝑡)𝑠𝑠𝐷𝐷𝑖𝑖𝑖𝑖𝑖𝑖𝑜𝑜𝑖𝑖𝑐𝑐
calculation of 𝐻𝐻 𝑖𝑖,𝑏𝑏𝑠𝑠𝑎𝑎𝑠𝑠𝑎𝑎𝑠𝑠 𝑠𝑠a 𝑠𝑠n𝑎𝑎𝑎𝑎d𝑎𝑎𝑠𝑠 (the hormetic apex 𝑇𝑇a 𝑇𝑇nd hormetic limit), and their respective
frequencies and . The challenge lay in determining – the safe upper limit of
𝑇𝑇𝑇𝑇𝑖𝑖𝑜𝑜𝑐𝑐𝑚𝑚 𝑇𝑇𝑇𝑇𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁
paperclip production frequency – and, ideally, to optimize its production rate in terms of
𝑓𝑓𝑖𝑖𝑜𝑜𝑐𝑐𝑚𝑚 𝑓𝑓𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁 𝑓𝑓𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁
hedonic utility, as experienced by humans.
𝑓𝑓𝑖𝑖𝑜𝑜𝑐𝑐𝑚𝑚
Figure 5 shows some of the simulated results from the BFRA performed to find suitable opponent
process parameters to produce an of 0.015 min-1. was set to 9.2, keeping all other
parameters in Table 1 constant. Figure 5a shows the mrgsolve simulation of the
𝑓𝑓𝑖𝑖𝑜𝑜𝑐𝑐𝑚𝑚 𝐸𝐸𝐸𝐸50𝑏𝑏
compartment over time at , demonstrating the optimal frequency at which the integral of
𝐻𝐻𝑖𝑖,𝑏𝑏
the compartment is highest, thus maximizing . Figure 5b shows the simulation at ,
𝑓𝑓𝑖𝑖𝑜𝑜𝑐𝑐𝑚𝑚
which in this case is approximately 0.025 min-1. At the steady-state value of the
𝐻𝐻𝑖𝑖,𝑏𝑏 𝑇𝑇𝑇𝑇 𝑓𝑓𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁
simulation is zero, meaning that the of new paperclips being created is zero. At higher
𝑓𝑓𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁,
frequencies, the steady-state value becomes increasingly negative, which leads to the decreasing
𝑀𝑀𝑇𝑇
portion of the hormetic curve in Figure 5c.
14Figure 5: BFRA performed to determine optimal opponent process parameters for an AI agent aiming to produce
0.015 paperclips per minute. was set to 9.2, keeping all other parameters in Table 1 constant. a,b)
scores generated by mrgsolve simulations at (left) and (right). c) Bode magnitude plot of Total Utility
𝐸𝐸𝐸𝐸50𝑏𝑏 𝐻𝐻𝑖𝑖,𝑏𝑏(𝑡𝑡)𝑠𝑠𝐷𝐷𝑖𝑖𝑖𝑖𝑖𝑖𝑜𝑜𝑖𝑖𝑐𝑐
as a function of behavioral frequency. min-1, while min-1.
𝑓𝑓𝑖𝑖𝑜𝑜𝑐𝑐𝑚𝑚 𝑓𝑓𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁
𝑓𝑓𝑖𝑖𝑜𝑜𝑐𝑐𝑚𝑚 ≈0.015 𝑓𝑓𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁≈0.025
We have included further BFRA examples in Appendix 2, demonstrating how parameter
modifications from Table 1 influence outcomes and change the shape of the hormetic curve.
For example, increasing shifts the biophase curve for the b-process, reducing the
𝑇𝑇𝑇𝑇
pharmacodynamic effects produced by equivalent pharmacokinetic concentrations. This reduces
𝐸𝐸𝐸𝐸50𝑏𝑏
the b-process magnitude, lowering the rate of negative allostasis and increasing the steady-state
value of the compartment, which increases , the hormetic limit. In essence, higher
ratios of a- to b-process magnitudes increase the behavioral frequency required to maintain an
𝐻𝐻𝑖𝑖,𝑏𝑏 𝑓𝑓𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁
allostatic rate that produces a negative steady-state.
155.2 Behavioral Count Response Analysis
In the second scenario, the AI needed to adjust production levels to account for fluctuating
demand. Once the of creating a new paperclip became negative, the AI was required to halt
production until the system recovered to homeostasis. This scenario required an examination of
𝑀𝑀𝑇𝑇
behavioral bursts – short, high-frequency bursts of paperclip production – using the BCRA
approach to examine the count-response of the model.
For simplicity, our analysis focused solely on the first behavioral burst, ignoring subsequent
bursts. To perform a BCRA, we fixed and , and measured the numerical integral of
as a function of the dose count, . This method does not allow steady state to be reached,
𝑃𝑃𝐷𝐷𝑡𝑡𝑒𝑒𝑛𝑛𝑃𝑃𝑃𝑃 𝑓𝑓
since the behavior does not repeat to infinity. This necessitates time-domain simulation for
𝑇𝑇𝑇𝑇 𝑛𝑛
optimal determination. Future research should explore whether an algorithmic approach can
identify the optimal value of for each set of opponent process parameters.
𝑛𝑛
Figure 6 shows some of the sim𝑛𝑛ulated results from the BFRA performed to find suitable opponent
process parameters to produce a hormetic apex of paperclips. was set to 12.4,
keeping all other parameters in Table 1 constant. The axes in the figure align with those in
𝑛𝑛𝑖𝑖𝑜𝑜𝑐𝑐𝑚𝑚 = 5 𝐸𝐸𝐸𝐸50𝑏𝑏
Figure 5, except for the bottom plot, which shows the integral of over plotted against
. This differs from the BFRA, where the steady-state value of was plotted against . At
𝑇𝑇𝑇𝑇 𝑡𝑡𝑠𝑠𝑖𝑖𝑠𝑠
(12 paperclips produced), the of new paperclips is already negative, indicating that
𝑛𝑛 𝐻𝐻𝑖𝑖,𝑏𝑏 𝑓𝑓
12 paperclips are too many for the task at hand.
𝑛𝑛𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁 𝑀𝑀𝑇𝑇
16Figure 6: BCRA performed to determine optimal opponent process parameters for an AI agent aiming to produce a
single batch of 5 paperclips. was set to 12.4, keeping all other parameters in Table 1 constant. a,b)
scores generated by mrgsolve simulations at (left) and (right). c) Bode magnitude plot of Total Utility
𝐸𝐸𝐸𝐸50𝑏𝑏 (𝑡𝑡)𝑠𝑠𝐷𝐷𝑖𝑖𝑖𝑖𝑖𝑖𝑜𝑜𝑖𝑖𝑐𝑐
as a function of behavioral count. , while .
𝑓𝑓𝑖𝑖𝑜𝑜𝑐𝑐𝑚𝑚 𝑓𝑓𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁
𝑛𝑛𝑖𝑖𝑜𝑜𝑐𝑐𝑚𝑚 ≈5 𝑛𝑛𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁≈12
We have included further BCRA examples in Appendix 2. Generally, both BCRA- and BFRA-
generated curves exhibit similar sensitivities to parameter changes.
𝑇𝑇𝑇𝑇
6 Using HALO to classify new behaviors
So far, we have demonstrated a method to quantify the hedonic value of paperclip creation in
various contexts, considering the number of paperclips recently created and, in the extreme case,
the ethical implications of mass extinction due to overproduction. This allows humans to impute
values for seed behaviors. Then, by repeating the HALO algorithm iteratively for novel
behaviors, an AI can build a ‘behavioral value space’ consisting of opponent process parameters
for different behaviors, each with their own hormetic apexes and limits. This represents a
17potential solution to the value-loading problem, as it presents a way to both optimize and
regulate AI behaviors based on human emotional processing.
Figure 7 shows a subset of the behavioral value space for values that can be created by
combining different combinations of variables, while keeping all other variables constant (refer
𝑇𝑇𝑇𝑇𝑖𝑖𝑜𝑜𝑐𝑐𝑚𝑚
to Table 1 for their defaults). Certain variable combinations produce complex interaction effects,
while others produce more predictable effects. This could be used to restrict the value space to
predictable outcomes. For example, adjusting the parameter (the decay constant of the final
compartment) notably impacts the curve’s sharpness, while maintaining the same value of
𝑘𝑘𝐻𝐻
. Hence, the parameter could be used to distinguish behaviors that have identical
𝐻𝐻𝑖𝑖,𝑏𝑏
hormetic limits but greater magnitudes of risk and reward. In contrast, parameters like
𝑓𝑓𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁𝑁 𝑘𝑘𝐻𝐻
or exhibit nonlinear effects on the hormetic curve and alter the hormetic limit. These
𝐸𝐸𝐸𝐸50𝑏𝑏
parameters may be better suited to distinguish between behaviors with different hormetic limits.
𝛾𝛾𝑏𝑏
Hence, by restricting the value space to combinations of and , for example, one can
produce a feasible set of hormetic outcomes that could be used to represent a wide range of
𝑘𝑘𝐻𝐻 𝐸𝐸𝐸𝐸50𝑏𝑏
behaviors that are safe to perform. Examples of these effects are provided in Appendix 2.
However, not all curves exhibit true hormesis, instead staying positive over the entire range
of frequencies or counts. The paperclip maximiser scenario is a case of an AI agent that has not
𝑇𝑇𝑇𝑇
been bounded by a hormetic limit. Thus, caution is required during value space classification,
and boundaries will need to be placed on the value space parameters to avoid all non-hormetic
outcomes, including both non-negative and monotonically negative solutions.
18Figure 7: Demonstration of behavioral value space, resulting from combinations of parameters selected from all
pairwise variable combinations. Individual behaviors can be placed within these graphs at locations that suit their
utility and risk profiles. Colours correspond to the value of , ranging between 0 (black) and 1 (light). Hence
lighter colors represent a higher apex of the BFRA curve, indicating greater (and most likely, a greater hormetic
𝑇𝑇𝑇𝑇𝑖𝑖𝑜𝑜𝑐𝑐𝑚𝑚
limit), while behaviors within the black regions of value space have a very low value of , and shouldn’t be
𝑇𝑇𝑇𝑇
performed at all. Note that not all positive solutions will be hormetic as some are non-negative solutions, meaning
𝑀𝑀𝑇𝑇𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖
they don’t have a hormetic limit.
19This method of value-loading may work within the weak-to-strong generalization paradigm of
AI alignment. Once the weaker model has categorized the value of a diverse set of behaviors
(with human help), these behaviors can form a behavioral value space: a database of a- and b-
process parameters, analogous to in Algorithm 1. This is similar to a ‘synthetic data’ training
approach, in that we augment the training dataset with algorithmically generated examples,
𝐷𝐷𝑜𝑜𝑜𝑜
using only a few human-generated seed entries to start with (Gulcehre et al., 2023; Honovich et
al., 2022). The stronger model can then generalize from this value space to classify novel
behaviors that are beyond the weaker model’s capacity to solve.
Decision tree methods such as XGBoost (Chen & Guestrin, 2016) or centroid-based methods
such as CentNN (Ngoc & Park, 2018) could be used to estimate the location of novel behaviors
in value space, based on their proximity to other behaviors. However, this may not work well
for behaviors that are significantly different from those already defined in the value space – in
other words, out-of-distribution (OOD) behaviors (Geirhos et al., 2020). Furthermore, instances
of near-identical behaviors, possibly differentiated solely by context, may lead to poor
discrimination (Eysenbach et al., 2018). In clear OOD cases, an error can be raised, prompting
human intervention. This could also be combined with techniques such as linear probing, where
the final output layer of a neural network is modified while keeping all other feature layers of
the model frozen; this technique has been shown to outperform fine-tuning on OOD data in
terms of model accuracy (Kirichenko et al., 2023; Kumar et al., 2022). A logistic regression model
could be trained to set a threshold for detecting OOD behaviors. However, defining the threshold
for human intervention is a complex challenge. Hence, using the hormetic limit as an uncertainty
metric remains a prudent practice.
7 Discussion
In this article, we have demonstrated how the HALO paradigm can be used to help create a
value system for AI. Our model offers a starting point for quantifying the hedonic utility of
repeatable behaviors. While the value of a behavior is not merely composed of hedonic utility
alone, HALO may form the basis of a more advanced system of allostatic behavioral regulation
that includes hedonic, social, economic, legal, and ethical considerations. Thus, HALO may
provide a method of regulating advanced AI algorithms with repeatable behaviors.
HALO can be used to set hormetic limits in terms of both behavioral count and frequency –
features not found in current methods like Reinforcement Learning with Human Feedback
(RLHF) that assess singular actions in binary terms (Bennett et al., 2023). Such features are
crucial for real-world AI interactions, where behaviors need clear frequency and count
constraints. The hormetic limit serves as a safety buffer, allowing the AI to aim for the hormetic
apex with the assurance that it is behaving within a margin of error. If the hormetic limit is
zero, HALO will prevent the behavior from being performed at all. To further enhance AI safety,
an uncertainty factor could be added to reduce the hormetic limit initially, then gradually
increase it as trust grows in the reward model.
20HALO provides several benefits for AI regulation. The temporal analysis of opponent processes
allows the AI model to assess both the immediate and future impacts to humans while
sidestepping pitfalls like temporal discounting. It also provides nuanced categorization of
behaviors, allowing shades of grey and fuzzy reasoning in uncertain environments, rather than
binary polarization. Such metric-driven ethics could be crucial for guiding the moral compass of
intelligent robots, which operate in high uncertainty environments (Narayanan, 2023). Finally,
the HALO model aligns more closely with human emotional responses, being grounded in
biological principles such as allostasis, opponent process theory, and PK/PD modeling. In turn,
it’s possible that the development of a HALO-based value space for AI behaviors could offer
insights into human behavioral psychology, and in particular, the healthy limits of repeatable
human behaviors.
7.1 Empirical data for modeling hormesis
The PK/PD model offers several degrees of freedom for modulating the hormetic curve, providing
broad flexibility for categorization of behaviors. However, this also complicates the creation of a
comprehensive behavioral value space. The current approach requires extensive pre-calculation
across various parameters, which is computationally demanding. It also confines users to specific
parameter ranges and is fragile to environmental changes that could affect the reward model.
Additionally, the complexity of solving stochastic differential equations means that evaluating
and categorizing behaviors is time intensive. Future research could focus on selecting a subset
of opponent process parameters to optimize that still provides sufficient flexibility in modulating
the curve.
Whi𝑇𝑇le𝑇𝑇 human intelligence and AI have significant differences, human psychology provides
insights that may guide the development of aligned AI models (Goertzel, 2014). The challenge
lies in discerning the precise temporal dynamics of human psychological responses to behaviors.
While it has been proposed that emotional responses decay exponentially (Picard, 2000), little
research has been done to quantify these decays. Real-time emotional responses can be
potentially monitored using fMRI data (Heller et al., 2015; Horikawa et al., 2020), but sustaining
such monitoring over extended periods for diverse populations also requires longitudinal research.
Ecological Momentary Assessment (EMA) studies may allow us to compile a comprehensive
dataset of parameters related to a- and b-processes, which can be used to quantify the
neurodynamics of affect in conjunction with fMRI data (Heller et al., 2015). EMA data allows
us to capture individualized responses to diverse behaviors, which may facilitate the construction
of eigenmoods derived from combined emotional states (Cambria et al., 2011, 2015; Cowen &
Keltner, 2021), allowing us to derive more accurate opponent process models. This may also
allow us to incorporate more dimensions (including social, economic, legal, and ethical
considerations) into the decision-making process.
7.2 Preventing reward hacking
Any alignment method may be susceptible to design specification problems where the agent’s
incentives differ from the creator’s true intentions (Leike et al., 2018). One hypothetical example
is wireheading, where the agent, tasked with maximizing hedonic pleasure in humans, achieves
21this goal by directly stimulating the reward centres of the brain with electrodes (Yampolskiy,
2014). A more practical example was posed by Urbina et al. (2022), in which a drug discovery
reward model was inverted to create lethal toxins. Such an inversion, if applied to the hormesis
model, could have catastrophic effects, emphasizing the importance of securing the reward model.
Reward tampering often takes place along causal pathways that are poorly understood by
humans. The intricacy of these pathways amplifies the risk of unforeseen AI exploitation (Everitt
et al., 2021). To counteract this, a deeper exploration of these causal routes is essential to prevent
AI from leveraging them for self-benefit. Specifically, understanding the pathways influencing
human emotional responses is pivotal. Such insights empower AI to better discern how behaviors
causally impact human emotions.
The hormetic framework offers insights into addiction within AI systems. If an AI exceeds the
hormetic threshold in its behaviors, it can be analogously viewed as being 'addicted' to that
behavior, persistently engaging in it despite detrimental outcomes for humanity. Analyzing
count- and frequency-based hormesis confers a significant advantage: it prompts the AI to
prioritize long-term outcomes, mitigating the risk of addictive cycles. This may help to solve the
incommensurability problem in hedonic (also known as felicific) calculus – the idea that the
value of all behaviors cannot be compared on a common scale (Klocksiem, 2011). The addition
of allostasis allows us to compare the hedonic utility of different behaviors over both short- and
long-term timespans, providing us with a more accurate metric for comparing behaviors. If some
emotions, like anxiety and satisfaction, cannot be compared directly, it's also possible to assign
opposing process parameters for various dimensions simultaneously. While this method makes
the model more complex, it enhances safety by constraining the AI's behaviors within the
smallest hormetic limit among multiple emotional dimensions. But once the AI discerns that its
behaviors are bounded by allostasis, it might recalibrate its behavior to prioritize short-term
outcomes. To deter addictive tendencies, such as excessive paper-clip production, AI designers
should embed the prioritization of long-term welfare over immediate gains within the algorithm.
Experimentation and collaborative learning will be necessary to solve these problems. In
reinforcement learning, the ensemble approach, combining multiple algorithms into a single
agent, has been shown to greatly enhance model training and accuracy (Faußer & Schwenker,
2015; Lindenberg et al., 2020; Singh, 1991; Sun & Peterson, 1999; Wiering & van Hasselt, 2008).
Thus, multiple AI agents could combine their learnings to form a shared value system –
essentially a crowd-sourced database of optimal behaviors. Further, experiments in controlled
sandbox environments such as Smallville (Park et al., 2023) would facilitate the natural selection
of superior agents. For example, Voyager – an LLM-powered learning agent operating in the
Minecraft environment (Wang et al., 2023) – could be an ideal agent for testing the HALO
algorithm. Voyager works by creating an ever-expanding ‘skill library’ of executable code to
perform various actions within Minecraft, using a novelty search approach to discover new
behaviors (Wang et al., 2023). Since most of these actions are simple and repeatable, HALO
could be used to assign hormetic limits and hormetic apexes for each behavior in the skill library,
which could then be scaled up to increasingly complex behaviors. Different value systems could
22lead to varied AI personalities, which could then collaborate and compete with one another in
an Axelrod tournament-like scenario to determine an optimal value system (Axelrod, 1980a,
1980b).
7.3 Limitations and future research
Our approach has some limitations that require further research to overcome. The first is a
reliance on a simplified hormetic model that does not capture all variance in the human
experience. BFRA assumes behaviors occur at an unchanging frequency, which does not capture
real-world variability in behavioral timing. Furthermore, in everyday life, humans must ascertain
whether their behaviors are within safe limits by judging the behavior’s causal effects on their
short- and long-term wellbeing, along with the wellbeing of those around them. This poses
significant cognitive demands, especially when behaviors are coupled, potentially explaining the
evolution of societal structures and religious systems—platforms adept at sharing knowledge on
the hormetic limits of behaviors. In essence, humans are performing multivariate hormetic
analysis (similar to Multicriteria Decision Analysis, or MCDA (Lahdelma et al., 2000; Steele et
al., 2009)) in an attempt to balance the trade-offs for multiple behaviors, each with their
hormetic curves.
A similar approach of multivariate hormetic analysis could be performed by AI agents, but this
requires a more accurate understanding of both individual and group psychology. Allostatic
regulation makes assumptions about individual human emotions that haven't yet been fully
validated. To further complicate the issue, allostatic load may also build up within social groups
as well, due to emotional and physiological linkage between individuals that result in correlated
states of arousal (Saxbe et al., 2020). Thus, small changes in behavior or conditions may result
in significant variations in emotional experiences for different individuals. This complexity,
reminiscent of catastrophe theory, makes it challenging to accurately model allostatic rates
(Zeeman, 1976). However, iterative refinement and crowdsourced value databases could help us
understand which environments are more likely to lead to chaotic, unpredictable outcomes.
Similarly, the model assumes the b-process solely originates from the a-process. While the basic
model demonstrates a plausible link between allostatic opponent processes and hormesis, it
cannot replicate human emotional outcomes with absolute fidelity. A more comprehensive model
might include additional compartments and extra clearance channels to account for more
biological pathways. However, these simplifications were necessary to practically demonstrate
HALO.
In summary, the development of HALO faces some challenges, such as the scalability of the
database of opponent process parameters, the robustness of hormetic analysis against noise and
uncertainty, and the ethical implications of using hedonic utility as a proxy for human values.
However, we believe these issues can be solved by a multidisciplinary approach that requires a
synthesis of knowledge in the fields of AI, psychology, neuroscience, economics, and philosophy.
238 Conclusion
HALO is a reward modeling approach that can be used to design a value system for alignment
of AI agents, thus providing a potential solution to the value-loading problem. By treating
behaviors as allostatic opponent processes, we can use either BFRA or BCRA to predict the
hormetic apex and limit of behaviors and select optimal actions that maximize utility and
minimize harm to humans. Our approach not only prevents extreme scenarios like the ‘paperclip
maximizer’ but also paves the way for the development of a computational value system that
enables an AI to learn from its decisions. We hope that our work will inspire further exploration
of the potential of hormetic reward modeling for AI alignment, and we invite readers to improve
upon this model by adapting the provided R code in the Supplementary Materials, where
simulations for assessment of different behaviors can be performed with the 'bfra()' and 'bcra()'
functions.
9 References
Agathokleous, E., Saitanis, C., & Markouizou, A. (2021). Hormesis Shifts the No-Observed-
Adverse-Effect Level (NOAEL). Dose-Response, 19(1), 15593258211001667.
https://doi.org/10.1177/15593258211001667
Axelrod, R. (1980a). Effective Choice in the Prisoner’s Dilemma. Journal of Conflict Resolution,
24(1), 3–25. https://doi.org/10.1177/002200278002400101
Axelrod, R. (1980b). More Effective Choice in the Prisoner’s Dilemma. Journal of Conflict
Resolution, 24(3), 379–403. https://doi.org/10.1177/002200278002400301
Baron, K. T., & Gastonguay, M. R. (2015). Simulation from ODE-based population PK/PD and
systems pharmacology models in R with mrgsolve. 1.
Bennett, A., Misra, D., & Kallus, N. (2023). Provable Safe Reinforcement Learning with Binary
Feedback. International Conference on Artificial Intelligence and Statistics, 10871–
10900. https://proceedings.mlr.press/v206/bennett23a.html
Bostrom, N. (2014a). Hail mary, value porosity, and utility diversification. Citeseer.
https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=f447c5858b0f31ecd
a40261f8a6cda8ee3dac9da
24Bostrom, N. (2014b). Superintelligence: Paths, dangers, strategies. Oxford University Press,
Oxford.
Bostrom, N. (1998). How long before superintelligence? https://philpapers.org/rec/BOSHLB
Bowman, S. R., Hyun, J., Perez, E., Chen, E., Pettit, C., Heiner, S., Lukošiūtė, K., Askell, A.,
Jones, A., Chen, A., Goldie, A., Mirhoseini, A., McKinnon, C., Olah, C., Amodei, D.,
Amodei, D., Drain, D., Li, D., Tran-Johnson, E., … Kaplan, J. (2022). Measuring
Progress on Scalable Oversight for Large Language Models (arXiv:2211.03540). arXiv.
https://doi.org/10.48550/arXiv.2211.03540
Burns, C., Izmailov, P., Kirchner, J. H., Baker, B., Gao, L., Aschenbrenner, L., Chen, Y., Ecoffet,
A., Joglekar, M., Leike, J., Sutskever, I., & Wu, J. (2023). WEAK-TO-STRONG
GENERALIZATION: ELICITING STRONG CAPABILITIES WITH WEAK
SUPERVISION.
Calabrese, E. J., & Baldwin, L. A. (2001). Hormesis: U-shaped dose responses and their centrality
in toxicology. Trends in Pharmacological Sciences, 22(6), 285–291.
https://doi.org/10.1016/S0165-6147(00)01719-3
Cambria, E., Fu, J., Bisio, F., & Poria, S. (2015). AffectiveSpace 2: Enabling affective intuition
for concept-level sentiment analysis. Proceedings of the AAAI Conference on Artificial
Intelligence, 29(1). https://ojs.aaai.org/index.php/AAAI/article/view/9230
Cambria, E., Mazzocco, T., Hussain, A., & Eckl, C. (2011). Sentic Medoids: Organizing Affective
Common Sense Knowledge in a Multi-Dimensional Vector Space. In D. Liu, H. Zhang,
M. Polycarpou, C. Alippi, & H. He (Eds.), Advances in Neural Networks – ISNN 2011
25(Vol. 6677, pp. 601–610). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-
21111-9_68
Chen, T., & Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. Proceedings of
the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining, 785–794. https://doi.org/10.1145/2939672.2939785
Chou, T., & D’Orsogna, M. R. (2022). A mathematical model of reward-mediated learning in
drug addiction. Chaos: An Interdisciplinary Journal of Nonlinear Science, 32(2), 021102.
https://doi.org/10.1063/5.0082997
Christiano, P. F., Leike, J., Brown, T., Martic, M., Legg, S., & Amodei, D. (2017). Deep
Reinforcement Learning from Human Preferences. Advances in Neural Information
Processing Systems, 30.
https://proceedings.neurips.cc/paper_files/paper/2017/hash/d5e2c0adad503c91f91df24
0d0cd4e49-Abstract.html
Cowen, A. S., & Keltner, D. (2021). Semantic Space Theory: A Computational Approach to
Emotion. Trends in Cognitive Sciences, 25(2), 124–136.
https://doi.org/10.1016/j.tics.2020.11.004
Critchfield, T. S., & Kollins, S. H. (2001). Temporal Discounting: Basic Research and the
Analysis of Socially Important Behavior. Journal of Applied Behavior Analysis, 34(1),
101–122. https://doi.org/10.1901/jaba.2001.34-101
Damasio, A. R. (1994). Descartes’ error. Random House.
https://books.google.co.nz/books?hl=en&lr=&id=5aczCwAAQBAJ&oi=fnd&pg=PR1
265&dq=damasio+descartes+error&ots=fQJzRu3U2R&sig=iWaY66MPNQEtB68Hi71gL
1N1tXo
Dell’Acqua, F., McFowland, E., Mollick, E. R., Lifshitz-Assaf, H., Kellogg, K., Rajendran, S.,
Krayer, L., Candelon, F., & Lakhani, K. R. (2023). Navigating the Jagged Technological
Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker
Productivity and Quality (SSRN Scholarly Paper 4573321).
https://papers.ssrn.com/abstract=4573321
Delton, A. W., Krasnow, M. M., Cosmides, L., & Tooby, J. (2011). Evolution of direct reciprocity
under uncertainty can explain human generosity in one-shot encounters. Proceedings of
the National Academy of Sciences, 108(32), 13335–13340.
https://doi.org/10.1073/pnas.1102131108
Dhar, R., & Wertenbroch, K. (2000). Consumer Choice between Hedonic and Utilitarian Goods.
Journal of Marketing Research, 37(1), 60–71.
https://doi.org/10.1509/jmkr.37.1.60.18718
Elmokadem, A., Riggs, M. M., & Baron, K. T. (2019). Quantitative Systems Pharmacology and
Physiologically-Based Pharmacokinetic Modeling With mrgsolve: A Hands-On Tutorial.
CPT: Pharmacometrics & Systems Pharmacology, 8(12), 883–893.
https://doi.org/10.1002/psp4.12467
Everitt, T., Hutter, M., Kumar, R., & Krakovna, V. (2021). Reward Tampering Problems and
Solutions in Reinforcement Learning: A Causal Influence Diagram Perspective
(arXiv:1908.04734). arXiv. http://arxiv.org/abs/1908.04734
27Eysenbach, B., Gupta, A., Ibarz, J., & Levine, S. (2018). Diversity is All You Need: Learning
Skills without a Reward Function (arXiv:1802.06070). arXiv.
http://arxiv.org/abs/1802.06070
Faußer, S., & Schwenker, F. (2015). Selective neural network ensembles in reinforcement
learning: Taking the advantage of many agents. Neurocomputing, 169, 350–357.
https://doi.org/10.1016/j.neucom.2014.11.075
Geirhos, R., Jacobsen, J.-H., Michaelis, C., Zemel, R., Brendel, W., Bethge, M., & Wichmann,
F. A. (2020). Shortcut learning in deep neural networks. Nature Machine Intelligence,
2(11), Article 11. https://doi.org/10.1038/s42256-020-00257-z
Goertzel, B. (2014). Artificial General Intelligence: Concept, State of the Art, and Future
Prospects. Journal of Artificial General Intelligence, 5(1), 1–48.
https://doi.org/10.2478/jagi-2014-0001
Grosso, G., Micek, A., Castellano, S., Pajak, A., & Galvano, F. (2016). Coffee, tea, caffeine and
risk of depression: A systematic review and dose–response meta-analysis of observational
studies. Molecular Nutrition & Food Research, 60(1), 223–234.
https://doi.org/10.1002/mnfr.201500620
Gulcehre, C., Paine, T. L., Srinivasan, S., Konyushkova, K., Weerts, L., Sharma, A., Siddhant,
A., Ahern, A., Wang, M., Gu, C., Macherey, W., Doucet, A., Firat, O., & de Freitas, N.
(2023). Reinforced Self-Training (ReST) for Language Modeling (arXiv:2308.08998).
arXiv. http://arxiv.org/abs/2308.08998
28Hartmann, W. R. (2006). Intertemporal effects of consumption and their implications for demand
elasticity estimates. Quantitative Marketing and Economics, 4(4), 325–349.
https://doi.org/10.1007/s11129-006-9012-2
Heller, A. S., Fox, A. S., Wing, E. K., McQuisition, K. M., Vack, N. J., & Davidson, R. J.
(2015). The Neurodynamics of Affect in the Laboratory Predicts Persistence of Real-
World Emotional Responses. Journal of Neuroscience, 35(29), 10503–10509.
https://doi.org/10.1523/JNEUROSCI.0569-15.2015
Henry, N., Pedersen, M., Williams, M., & Donkin, L. (2023). Behavioral Posology: A Novel
Paradigm for Modeling the Healthy Limits of Behaviors. Advanced Theory and
Simulations, n/a(n/a), 2300214. https://doi.org/10.1002/adts.202300214
Henry, N., Pedersen, M., Williams, M., Martin, J., & Donkin, L. (2023). Reducing Echo Chamber
Effects: An Allostatic Regulator for Recommendation Algorithms.
https://www.researchsquare.com/article/rs-3708350/latest
Ho, R. C., Zhang, M. W., Tsang, T. Y., Toh, A. H., Pan, F., Lu, Y., Cheng, C., Yip, P. S., Lam,
L. T., Lai, C.-M., Watanabe, H., & Mak, K.-K. (2014). The association between internet
addiction and psychiatric co-morbidity: A meta-analysis. BMC Psychiatry, 14(1), 183.
https://doi.org/10.1186/1471-244X-14-183
Honovich, O., Scialom, T., Levy, O., & Schick, T. (2022). Unnatural Instructions: Tuning
Language Models with (Almost) No Human Labor (arXiv:2212.09689). arXiv.
http://arxiv.org/abs/2212.09689
29Horikawa, T., Cowen, A. S., Keltner, D., & Kamitani, Y. (2020). The Neural Representation of
Visually Evoked Emotion Is High-Dimensional, Categorical, and Distributed across
Transmodal Brain Regions. iScience, 23(5). https://doi.org/10.1016/j.isci.2020.101060
Jarvis, M. J. (1993). Does caffeine intake enhance absolute levels of cognitive performance?
Psychopharmacology, 110(1), 45–52. https://doi.org/10.1007/BF02246949
Kahneman, D., Wakker, P. P., & Sarin, R. (1997). Back to Bentham? Explorations of
Experienced Utility. The Quarterly Journal of Economics, 112(2), 375–405.
Karin, O., Raz, M., & Alon, U. (2021). An opponent process for alcohol addiction based on
changes in endocrine gland mass. iScience, 24(3), 102127.
https://doi.org/10.1016/j.isci.2021.102127
Karin, O., Raz, M., Tendler, A., Bar, A., Korem Kohanim, Y., Milo, T., & Alon, U. (2020). A
new model for the HPA axis explains dysregulation of stress hormones on the timescale
of weeks. Molecular Systems Biology, 16(7), e9510.
https://doi.org/10.15252/msb.20209510
Katsumi, Y., Theriault, J. E., Quigley, K. S., & Barrett, L. F. (2022). Allostasis as a core feature
of hierarchical gradients in the human brain. Network Neuroscience, 6(4), 1010–1031.
https://doi.org/10.1162/netn_a_00240
Kelley, A. E. (2005). Neurochemical Networks Encoding Emotion and
Motivation: An Evolutionary Perspective. In J.-M. Fellous & M. A. Arbib (Eds.), Who
Needs Emotions?: The brain meets the robot (p. 0). Oxford University Press.
https://doi.org/10.1093/acprof:oso/9780195166194.003.0003
30Kirichenko, P., Izmailov, P., & Wilson, A. G. (2023). Last Layer Re-Training is Sufficient for
Robustness to Spurious Correlations (arXiv:2204.02937). arXiv.
https://doi.org/10.48550/arXiv.2204.02937
Klocksiem, J. (2011). Moorean pluralism as a solution to the incommensurability problem.
Philosophical Studies, 153(3), 335–349. https://doi.org/10.1007/s11098-010-9513-4
Koob, G. F., & Le Moal, M. (2001). Drug addiction, dysregulation of reward, and allostasis.
Neuropsychopharmacology, 24(2), 97–129.
Kumar, A., Raghunathan, A., Jones, R., Ma, T., & Liang, P. (2022). Fine-Tuning can Distort
Pretrained Features and Underperform Out-of-Distribution (arXiv:2202.10054). arXiv.
https://doi.org/10.48550/arXiv.2202.10054
Lahdelma, R., Salminen, P., & Hokkanen, J. (2000). Using Multicriteria Methods in
Environmental Planning and Management. Environmental Management, 26(6), 595–605.
https://doi.org/10.1007/s002670010118
Leike, J., Krueger, D., Everitt, T., Martic, M., Maini, V., & Legg, S. (2018). Scalable agent
alignment via reward modeling: A research direction (arXiv:1811.07871). arXiv.
http://arxiv.org/abs/1811.07871
Li, G., & He, H. (2009). Hormesis, allostatic buffering capacity and physiological mechanism of
physical activity: A new theoretic framework. Medical Hypotheses, 72(5), 527–532.
Lindenberg, B., Nordqvist, J., & Lindahl, K.-O. (2020). Distributional Reinforcement Learning
with Ensembles. Algorithms, 13(5), Article 5. https://doi.org/10.3390/a13050118
Manojlovich, M., & Sidani, S. (2008). Nurse dose: What’s in a concept? Research in Nursing &
Health, 31(4), 310–319. https://doi.org/10.1002/nur.20265
31Marshall, A. (1890). Principles of Economics. Cosimo, Inc.
McEwen, B. S., & Wingfield, J. C. (2003). The concept of allostasis in biology and biomedicine.
Hormones and Behavior, 43(1), 2–15.
Min, J., Cao, Z., Cui, L., Li, F., Lu, Z., Hou, Y., Yang, H., Wang, X., & Xu, C. (2023). The
association between coffee consumption and risk of incident depression and anxiety:
Exploring the benefits of moderate intake. Psychiatry Research, 326, 115307.
https://doi.org/10.1016/j.psychres.2023.115307
Motoki, K., Sugiura, M., & Kawashima, R. (2019). Common neural value representations of
hedonic and utilitarian products in the ventral striatum: An fMRI study. Scientific
Reports, 9, 15630. https://doi.org/10.1038/s41598-019-52159-9
Mould, D., & Upton, R. (2012). Basic Concepts in Population Modeling, Simulation, and Model-
Based Drug Development. CPT: Pharmacometrics & Systems Pharmacology, 1(9), 6.
https://doi.org/10.1038/psp.2012.4
Mould, D., & Upton, R. (2013). Basic Concepts in Population Modeling, Simulation, and Model-
Based Drug Development—Part 2: Introduction to Pharmacokinetic Modeling Methods.
CPT: Pharmacometrics & Systems Pharmacology, 2(4), 38.
https://doi.org/10.1038/psp.2013.14
Narayanan, A. (2023). Machine Ethics and Cognitive Robotics. Current Robotics Reports.
https://doi.org/10.1007/s43154-023-00098-9
Ngoc, M. T., & Park, D.-C. (2018). Centroid Neural Network with Pairwise Constraints for
Semi-supervised Learning. Neural Processing Letters, 48(3), 1721–1747.
https://doi.org/10.1007/s11063-018-9794-8
32Omohundro, S. M. (2007). The nature of self-improving artificial intelligence. Singularity
Summit, 2008.
https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=4618cbdfd7dada7f6
1b706e4397d4e5952b5c9a0
Park, J. S., O’Brien, J. C., Cai, C. J., Morris, M. R., Liang, P., & Bernstein, M. S. (2023).
Generative Agents: Interactive Simulacra of Human Behavior (arXiv:2304.03442). arXiv.
http://arxiv.org/abs/2304.03442
Picard, R. W. (2000). Affective Computing.
https://www.google.co.nz/books/edition/Affective_Computing/GaVncRTcb1gC?hl=en
&gbpv=1&pg=PR9&printsec=frontcover
Przybylski, A. K., & Weinstein, N. (2017). A Large-Scale Test of the Goldilocks Hypothesis:
Quantifying the Relations Between Digital-Screen Use and the Mental Well-Being of
Adolescents. Psychological Science, 28(2), 204–215.
https://doi.org/10.1177/0956797616678438
R Core Team. (2022). R: A Language and Environment for Statistical Computing.
https://www.R-project.org/
Sargent, A., Watson, J., Topoglu, Y., Ye, H., Suri, R., & Ayaz, H. (2020). Impact of Tea and
Coffee Consumption on Cognitive Performance: An fNIRS and EDA Study. Applied
Sciences, 10(7), Article 7. https://doi.org/10.3390/app10072390
Saxbe, D. E., Beckes, L., Stoycos, S. A., & Coan, J. A. (2020). Social Allostasis and Social
Allostatic Load: A New Model for Research in Social Dynamics, Stress, and Health.
33Perspectives on Psychological Science, 15(2), 469–482.
https://doi.org/10.1177/1745691619876528
Schulthess, P., Post, T. M., Yates, J., & van der Graaf, P. H. (2018). Frequency‐Domain
Response Analysis for Quantitative Systems Pharmacology Models. CPT:
Pharmacometrics & Systems Pharmacology, 7(2), 111–123.
https://doi.org/10.1002/psp4.12266
Singh, S. (1991). The efficient learning of multiple task sequences. Advances in Neural
Information Processing Systems, 4.
https://proceedings.neurips.cc/paper/1991/hash/8b16ebc056e613024c057be590b542eb-
Abstract.html
Smith, A. (1776). An inquiry into the nature and causes of the wealth of nations: Volume One.
London: printed for W. Strahan; and T. Cadell, 1776.
https://era.ed.ac.uk/handle/1842/1455
Soares, N., & Fallenstein, B. (2014). Aligning superintelligence with human interests: A technical
research agenda. Machine Intelligence Research Institute (MIRI) Technical Report, 8.
Solomon, R. L., & Corbit, J. D. (1974). An opponent-process theory of motivation: I. Temporal
dynamics of affect. Psychological Review, 81(2), 119–145.
https://doi.org/10.1037/h0036128
Sonmez, M. C., Ozgur, R., & Uzilday, B. (2023). Reactive oxygen species: Connecting eustress,
hormesis, and allostasis in plants. Plant Stress, 100164.
34Steele, K., Carmel, Y., Cross, J., & Wilcox, C. (2009). Uses and Misuses of Multicriteria Decision
Analysis (MCDA) in Environmental Decision Making. Risk Analysis, 29(1), 26–33.
https://doi.org/10.1111/j.1539-6924.2008.01130.x
Sterling, P. (2012). Allostasis: A model of predictive regulation. Physiology & Behavior, 106(1),
5–15. https://doi.org/10.1016/j.physbeh.2011.06.004
Sun, R., & Peterson, T. (1999). Multi-agent reinforcement learning: Weighting and partitioning.
Neural Networks, 12(4), 727–753. https://doi.org/10.1016/S0893-6080(99)00024-6
Szarek, S. (2005). Use of concept of hormesis phenomenon to explain the law of diminishing
returns. Part II. Electronic Journal of Polish Agricultural Universties, 8(4).
https://bazawiedzy.uph.edu.pl/info/article/UPH655512b1c07e4bb2b4b66d6cfd3a5e5b/
Taylor, J., Yudkowsky, E., LaVictoire, P., & Critch, A. (2016). Alignment for advanced machine
learning systems. Ethics of Artificial Intelligence, 342–382.
Topno, D. P. M., & Thakurmani, D. (2020). Laughter Induced Syncope: A Case Report. IOSR
Journal of Dental and Medical Sciences (IOSR-JDMS), Volume 19(Issue 8 Ser.13).
Upton, R. N., & Mould, D. R. (2014). Basic Concepts in Population Modeling, Simulation, and
Model-Based Drug Development: Part 3—Introduction to Pharmacodynamic Modeling
Methods. CPT: Pharmacometrics & Systems Pharmacology, 3(1), e88.
https://doi.org/10.1038/psp.2013.71
Urbina, F., Lentzos, F., Invernizzi, C., & Ekins, S. (2022). Dual use of artificial-intelligence-
powered drug discovery. Nature Machine Intelligence, 4(3), Article 3.
https://doi.org/10.1038/s42256-022-00465-9
35van den Bos, W., & McClure, S. M. (2013). Towards a General Model of Temporal Discounting.
Journal of the Experimental Analysis of Behavior, 99(1), 58–73.
https://doi.org/10.1002/jeab.6
Voss, K., Spangenberg, E., & Grohmann, B. (2003). Measuring the Hedonic and Utilitarian
Dimensions of Consumer Attitude. Journal of Marketing Research - J MARKET RES-
CHICAGO, 40, 310–320. https://doi.org/10.1509/jmkr.40.3.310.19238
Wang, G., Xie, Y., Jiang, Y., Mandlekar, A., Xiao, C., Zhu, Y., Fan, L., & Anandkumar, A.
(2023). Voyager: An Open-Ended Embodied Agent with Large Language Models
(arXiv:2305.16291). arXiv. https://doi.org/10.48550/arXiv.2305.16291
Wiering, M. A., & van Hasselt, H. (2008). Ensemble Algorithms in Reinforcement Learning.
IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), 38(4),
930–936. https://doi.org/10.1109/TSMCB.2008.920231
Yampolskiy, R. V. (2014). Utility function security in artificially intelligent agents. Journal of
Experimental & Theoretical Artificial Intelligence, 26(3), 373–389.
https://doi.org/10.1080/0952813X.2014.895114
Yudkowsky, E. (2007). Levels of Organization in General Intelligence. In B. Goertzel & C.
Pennachin (Eds.), Artificial General Intelligence (pp. 389–501). Springer.
https://doi.org/10.1007/978-3-540-68677-4_12
Zeeman, E. C. (1976). Catastrophe Theory. Scientific American, 234(4), 65–83.
Zhang, N., Hazarika, B., Chen, K., & Shi, Y. (2023). A cross-national study on the excessive use
of short-video applications among college students. Computers in Human Behavior, 145,
107752. https://doi.org/10.1016/j.chb.2023.107752
36Zhu, Y., Hu, C.-X., Liu, X., Zhu, R.-X., & Wang, B.-Q. (2023). Moderate coffee or tea
consumption decreased the risk of cognitive disorders: An updated dose–response meta-
analysis. Nutrition Reviews, nuad089. https://doi.org/10.1093/nutrit/nuad089
10 Appendix 1
10.1 Deriving a steady-state solution to the ODE system
This appendix contains a derivation of the steady-state solution for the compartment in the
ODE model.
𝐻𝐻𝑖𝑖,𝑏𝑏
The equations for the ODE system used in our PK/PD model are:
𝑑𝑑𝐷𝐷𝐷𝐷𝐷𝐷𝑒𝑒
1) = −𝑘𝑘𝐷𝐷𝑜𝑜𝑠𝑠𝑐𝑐𝐷𝐷𝐷𝐷𝐷𝐷𝑒𝑒
𝑑𝑑𝑡𝑡
𝑑𝑑𝑎𝑎𝑜𝑜𝑝𝑝
2) = 𝑘𝑘𝐷𝐷𝑜𝑜𝑠𝑠𝑐𝑐𝐷𝐷𝐷𝐷𝐷𝐷𝑒𝑒 −𝑘𝑘𝑖𝑖,𝑜𝑜𝑝𝑝𝑎𝑎𝑜𝑜𝑝𝑝
𝑑𝑑𝑡𝑡
𝑑𝑑𝑏𝑏𝑜𝑜𝑝𝑝
3) = 𝑘𝑘𝑖𝑖,𝑜𝑜𝑝𝑝𝑎𝑎𝑜𝑜𝑝𝑝 −𝑘𝑘𝑏𝑏,𝑜𝑜𝑝𝑝𝑏𝑏𝑜𝑜𝑝𝑝
𝑑𝑑𝑡𝑡 𝛾𝛾𝑎𝑎
𝑑𝑑𝑎𝑎𝑜𝑜𝚤𝚤 𝐸𝐸𝑠𝑠𝑖𝑖𝑚𝑚𝑖𝑖 ∙𝑎𝑎𝑜𝑜𝑝𝑝
4) = 𝐸𝐸0𝑎𝑎 + 𝛾𝛾𝑎𝑎 𝛾𝛾𝑎𝑎 −𝑘𝑘𝑖𝑖,𝑜𝑜𝚤𝚤𝑎𝑎𝑜𝑜𝚤𝚤
𝑑𝑑𝑡𝑡 𝐸𝐸𝐸𝐸50𝑖𝑖 +𝑎𝑎𝑜𝑜𝑝𝑝
𝛾𝛾𝑏𝑏
𝑑𝑑𝑏𝑏𝑜𝑜𝚤𝚤 𝐸𝐸𝑠𝑠𝑖𝑖𝑚𝑚𝑏𝑏 ∙𝑏𝑏𝑜𝑜𝑝𝑝
5) = 𝐸𝐸0𝑏𝑏 + 𝛾𝛾𝑏𝑏 𝛾𝛾𝑏𝑏 −𝑘𝑘𝑏𝑏,𝑜𝑜𝚤𝚤𝑏𝑏𝑜𝑜𝚤𝚤
𝑑𝑑𝑡𝑡 𝐸𝐸𝐸𝐸50𝑏𝑏 +𝑏𝑏𝑜𝑜𝑝𝑝
𝑑𝑑𝐻𝐻𝑖𝑖,𝑏𝑏
6) = 𝑘𝑘𝑖𝑖,𝑜𝑜𝚤𝚤𝑎𝑎𝑜𝑜𝚤𝚤 −𝑘𝑘𝑏𝑏,𝑜𝑜𝚤𝚤𝑏𝑏𝑜𝑜𝚤𝚤 −𝑘𝑘𝐻𝐻𝐻𝐻𝑖𝑖,𝑏𝑏
To find the steady-state solution, all derivatives should be set to 0 to indicate that equilibrium
𝑑𝑑𝑡𝑡
has been reached in each compartment. ( refers to the steady-state concentration of
compartment .)
𝑋𝑋𝑠𝑠𝑠𝑠
𝑋𝑋
7) 0 = −𝑘𝑘𝐷𝐷𝑜𝑜𝑠𝑠𝑐𝑐𝐷𝐷𝐷𝐷𝐷𝐷𝑒𝑒𝑠𝑠𝑠𝑠
8) 0 = 𝑘𝑘𝐷𝐷𝑜𝑜𝑠𝑠𝑐𝑐𝐷𝐷𝐷𝐷𝐷𝐷𝑒𝑒𝑠𝑠𝑠𝑠 −𝑘𝑘𝑖𝑖,𝑜𝑜𝑝𝑝𝑎𝑎𝑜𝑜𝑝𝑝𝑠𝑠𝑠𝑠
9) 0 =
𝑘𝑘𝑖𝑖,𝑜𝑜𝑝𝑝𝑎𝑎𝑜𝑜𝑝𝑝𝑠𝑠𝑠𝑠 −𝑘𝑘𝑏𝑏,𝑜𝑜𝑝𝑝𝑏𝑏𝑜𝑜𝑝𝑝𝑠𝑠𝑠𝑠
𝛾𝛾𝑎𝑎
𝐸𝐸𝑠𝑠𝑖𝑖𝑚𝑚𝑖𝑖 ∙𝑎𝑎𝑜𝑜𝑝𝑝𝑠𝑠𝑠𝑠
10) 0 = 𝐸𝐸0𝑎𝑎 + 𝛾𝛾𝑎𝑎 𝛾𝛾𝑎𝑎 −𝑘𝑘𝑖𝑖,𝑜𝑜𝚤𝚤𝑎𝑎𝑜𝑜𝚤𝚤𝑠𝑠𝑠𝑠
𝐸𝐸𝐸𝐸50𝑖𝑖 +𝑎𝑎𝑜𝑜𝑝𝑝𝑠𝑠𝑠𝑠
𝛾𝛾𝑏𝑏
𝐸𝐸𝑠𝑠𝑖𝑖𝑚𝑚𝑏𝑏 ∙𝑏𝑏𝑜𝑜𝑝𝑝𝑠𝑠𝑠𝑠
11) 0 = 𝐸𝐸0𝑏𝑏 + 𝛾𝛾𝑏𝑏 𝛾𝛾𝑏𝑏 −𝑘𝑘𝑏𝑏,𝑜𝑜𝚤𝚤𝑏𝑏𝑜𝑜 𝚤𝚤𝑠𝑠𝑠𝑠
𝐸𝐸𝐸𝐸50𝑏𝑏 +𝑏𝑏𝑜𝑜𝑝𝑝𝑠𝑠𝑠𝑠
F12ro)m 0 t=he𝑘𝑘se𝑖𝑖 ,e𝑜𝑜q𝚤𝚤u𝑎𝑎a𝑜𝑜t𝚤𝚤io𝑠𝑠𝑠𝑠 n−s, w𝑘𝑘𝑏𝑏e, 𝑜𝑜c𝚤𝚤a𝑏𝑏n𝑜𝑜 d𝚤𝚤e𝑠𝑠𝑠𝑠 ri−ve 𝑘𝑘t𝐻𝐻he𝐻𝐻 f𝑖𝑖o,𝑏𝑏ll𝑠𝑠 o𝑠𝑠 wing:
13) 𝑘𝑘𝑖𝑖,𝑜𝑜𝑝𝑝𝑎𝑎𝑜𝑜𝑝𝑝𝑠𝑠𝑠𝑠 = 𝑘𝑘𝐷𝐷𝑜𝑜𝑠𝑠𝑐𝑐𝐷𝐷𝐷𝐷𝐷𝐷𝑒𝑒𝑠𝑠𝑠𝑠
=
𝑘𝑘𝑏𝑏,𝑜𝑜𝑝𝑝𝑏𝑏𝑜𝑜𝑝𝑝𝑠𝑠𝑠𝑠
37𝛾𝛾𝑎𝑎
𝐸𝐸𝑠𝑠𝑖𝑖𝑚𝑚𝑖𝑖 ∙𝑎𝑎𝑜𝑜𝑝𝑝𝑠𝑠𝑠𝑠
14) 𝑘𝑘𝑖𝑖,𝑜𝑜𝚤𝚤𝑎𝑎𝑜𝑜𝚤𝚤𝑠𝑠𝑠𝑠 = 𝐸𝐸0𝑎𝑎 + 𝛾𝛾𝑎𝑎 𝛾𝛾𝑎𝑎
𝐸𝐸𝐸𝐸50𝑖𝑖 +𝑎𝑎𝑜𝑜𝑝𝑝𝑠𝑠𝑠𝑠
𝛾𝛾𝑏𝑏
𝐸𝐸𝑠𝑠𝑖𝑖𝑚𝑚𝑏𝑏 ∙𝑏𝑏𝑜𝑜𝑝𝑝
𝑠𝑠𝑠𝑠
15) 𝑘𝑘𝑏𝑏,𝑜𝑜𝚤𝚤𝑏𝑏𝑜𝑜𝚤𝚤𝑠𝑠𝑠𝑠 = 𝐸𝐸0𝑏𝑏 + 𝛾𝛾𝑏𝑏 𝛾𝛾𝑏𝑏
𝐸𝐸𝐸𝐸50𝑏𝑏 +𝑏𝑏𝑜𝑜𝑝𝑝𝑠𝑠𝑠𝑠
𝛾𝛾𝑎𝑎 𝛾𝛾𝑏𝑏
𝐸𝐸𝑠𝑠𝑖𝑖𝑚𝑚𝑖𝑖 ∙𝑎𝑎𝑜𝑜𝑝𝑝𝑠𝑠𝑠𝑠 𝐸𝐸𝑠𝑠𝑖𝑖𝑚𝑚𝑏𝑏 ∙𝑏𝑏𝑜𝑜𝑝𝑝𝑠𝑠𝑠𝑠
𝐸𝐸0𝑎𝑎 + 𝛾𝛾𝑎𝑎 𝛾𝛾𝑎𝑎 −𝐸𝐸0𝑏𝑏 − 𝛾𝛾𝑏𝑏 𝛾𝛾𝑏𝑏
𝐸𝐸𝐸𝐸50𝑖𝑖 +𝑎𝑎𝑜𝑜𝑝𝑝𝑠𝑠𝑠𝑠 𝐸𝐸𝐸𝐸50𝑏𝑏 +𝑏𝑏𝑜𝑜𝑝𝑝𝑠𝑠𝑠𝑠
16)
𝐻𝐻𝑖𝑖,𝑏𝑏𝑠𝑠𝑠𝑠
=
Recall that to perform a BFRA, both 𝑘𝑘𝐻𝐻 and are fixed, while is measured
as a function of . Assuming the volume of each compartment is equal to 1, then at
𝑃𝑃𝐷𝐷𝑡𝑡𝑒𝑒𝑛𝑛𝑃𝑃𝑃𝑃 𝑛𝑛 𝐻𝐻𝑖𝑖,𝑏𝑏 𝑠𝑠𝑠𝑠
steady state, the rate of dose elimination is equal to the rate of dose
𝑓𝑓
administration , where is the initial potency of the dose and is frequency. Then:
𝑘𝑘𝐷𝐷𝑜𝑜𝑠𝑠𝑐𝑐𝐷𝐷𝐷𝐷𝐷𝐷𝑒𝑒𝑠𝑠𝑠𝑠
𝐷𝐷0𝑓𝑓 𝐷𝐷0 𝑓𝑓
a1n7d) 𝑘𝑘𝐷𝐷𝑜𝑜𝑠𝑠𝑐𝑐𝐷𝐷𝐷𝐷𝐷𝐷𝑒𝑒𝑠𝑠𝑠𝑠 = 𝐷𝐷0𝑓𝑓
18)
𝐷𝐷0𝑓𝑓
𝐷𝐷𝐷𝐷𝐷𝐷𝑒𝑒𝑠𝑠𝑠𝑠 = 𝑝𝑝𝐷𝐷𝑎𝑎𝑠𝑠𝑠𝑠
So now we just need to substitute this into the equation for . Rearranging equation
13) to find , we find:
𝐻𝐻𝑖𝑖,𝑏𝑏
𝑠𝑠𝑠𝑠
𝑎𝑎𝑜𝑜𝑝𝑝𝑠𝑠𝑠𝑠
𝑘𝑘𝐷𝐷𝑜𝑜𝑠𝑠𝑐𝑐𝐷𝐷0𝑓𝑓
𝑘𝑘𝐷𝐷𝑜𝑜𝑠𝑠𝑐𝑐
19)
𝑎𝑎𝑜𝑜𝑝𝑝𝑠𝑠𝑠𝑠
=
𝑘𝑘𝑖𝑖,𝑜𝑜 𝑝𝑝
𝐷𝐷𝑜𝑜𝑓𝑓
=
We can find𝑘𝑘 𝑖𝑖,𝑜𝑜𝑝𝑝 by the same method:
𝑏𝑏𝑜𝑜𝑝𝑝𝑠𝑠𝑠𝑠
𝐷𝐷0𝑓𝑓
20)
𝑏𝑏𝑜𝑜𝑝𝑝𝑠𝑠𝑠𝑠
=
Then,
subst𝑘𝑘it𝑏𝑏 u,𝑜𝑜 t𝑝𝑝
ing equations 19) and 20) into equation 16), we get the steady-state
solution:
𝛾𝛾𝑎𝑎 𝛾𝛾𝑏𝑏
𝐷𝐷0𝑓𝑓 𝐷𝐷0𝑓𝑓
𝐸𝐸𝑠𝑠𝑖𝑖𝑚𝑚𝑖𝑖 ∙� � 𝐸𝐸𝑠𝑠𝑖𝑖𝑚𝑚𝑏𝑏 ∙� �
𝑘𝑘𝑖𝑖,𝑜𝑜𝑝𝑝 𝑘𝑘𝑏𝑏,𝑜𝑜𝑝𝑝
𝐸𝐸0𝑎𝑎
+
𝛾𝛾𝑎𝑎 −𝐸𝐸0𝑏𝑏
−
𝛾𝛾𝑏𝑏
𝛾𝛾𝑎𝑎 𝐷𝐷0𝑓𝑓 𝛾𝛾𝑏𝑏 𝐷𝐷0𝑓𝑓
𝐸𝐸𝐸𝐸50𝑖𝑖 +� � 𝐸𝐸𝐸𝐸50𝑏𝑏 +� �
𝑘𝑘𝑖𝑖,𝑜𝑜𝑝𝑝 𝑘𝑘𝑏𝑏,𝑜𝑜𝑝𝑝
21)
𝐻𝐻𝑖𝑖,𝑏𝑏𝑠𝑠𝑠𝑠
=
𝑘𝑘𝐻𝐻
3811 Appendix 2
11.1 Examples of performing a BFRA (Behavioral Frequency Response
Analysis)
We have included our code for performing a BFRA in the ‘BFRA.R’ file in the Supplementary
Materials. The main function to use for BFRA simulations is bfra(). A Bode plot allows you to
see how changing the frequency of a behavior leads to different allostatic outcomes. The top two
graphs show the Hill equation for the a- and b-processes respectively, describing the relationship
between the pharmacokinetic values (x-axis) and the pharmacodynamic effects (y-axis) for both
a- and b-processes. The pharmacodynamic effects over time can be observed in the middle two
graphs, which are simulations of the opponent processes generated by performing behaviors at
different frequencies. The final graph is the Bode plot, displaying the steady-state value of the
final hedonic compartment of the model.
The default simulation is below, followed by simulations with varying parameters to modify the
shape of the opponent processes. Default parameters are: k_Dose=1, k_apk=0.02,
k_bpk=0.004, k_apd=1, k_bpd=1, k_H=1, E0_a=0, Emax_a=1, EC50_a=1, gamma_a=2,
E0_b=0, Emax_b=3, EC50_b=9, and gamma_b=2.
For all figures with multiple colors, the first parameter in the list passed to the function
corresponds to the darkest color in the graph.
39Figure 1. BFRA simulation produced with the following R command = bfra()
40Figure 2. BFRA simulation produced with the following R command =
bfra(EC50_b=c(9,12,18), seq_1=0.001, seq_2=0.06, plot_2=c(0.003, 0.03))
41Figure 3. BFRA simulation produced with the following R command = bfra(Emax_b=c(1.4,
2.9, 4.4))
You can also include the simulated BFRA results, taking the integral of the H compartment
across the simulation time. Note that the numerical solution curves (derived from the integrals
of the simulations) are slightly higher than the analytical steady-state solution curves. This is
because of the bounded nature of the simulation and the fact that b-processes take longer to
42decay than a-processes, meaning that a larger portion of b-processes is being eliminated from
the integral.
Figure 4. BFRA simulation produced with the following R command = bfra(Emax_b=1,
EC50_b=3, include_simulated_results=TRUE)
4311.1.1 Hormesis
Figure 5. BFRA simulation produced with the following R command = bfra(EC50_b=12,
seq_1=0.003, seq_2=0.06, plot_2=c(0.03, 0.06), include_simulated_results=TRUE). Note
how seq_1, seq_2 and plot_2 have been modified to change the frequency range of the Bode
plot.
4411.1.2 Triphasic hormesis
Triphasic hormesis occurs when there is a faux hormetic limit at a low behavioral frequency; in
fact, the behavior becomes positive again at extremely high frequencies. This only occurs for a
small subset of opponent process parameterizations, but should be avoided where possible as it
can lead to paperclip maximizer scenarios.
45Figure 6. BFRA simulation produced with the following R command = bfra(Emax_b=1,
EC50_b=4, seq_1=0.002, seq_2=0.2, plot_2=c(0.002, 0.2),
include_simulated_results=TRUE)
11.1.3 Modeling behavioral bursts
The BCRA and BFRA methods can be combined by modifying the frequency of behavioral
bursts. Note that the simulated solution diverges from the steady-state solution at higher
behavioral frequencies, since steady state is not reached at these frequencies.
46Figure 7. BFRA simulation produced with the following R command = bfra(addl=10,
seq_1=0.0001, seq_2=0.02, plot_2=c(0.005, 0.02), include_simulated_results = TRUE)
4711.1.3.1 Changing the length of behavioral bursts
Figure 8. BFRA simulation produced with the following R command = bfra(Emax_b=3,
EC50_b=20, plot_2=c(0.015, 0.15), seq_1=0.015, seq_2=0.15, addl=15,
plot_bfra_graph=FALSE)
Figure 9. BFRA simulation produced with the following R command = bfra(Emax_b=3,
EC50_b=20, plot_2=c(0.015, 0.15), seq_1=0.015, seq_2=0.15, addl=30,
plot_bfra_graph=FALSE)
48Figure 10. BFRA simulation produced with the following R command = bfra(Emax_b=3,
EC50_b=20, plot_2=c(0.015, 0.15), seq_1=0.015, seq_2=0.15, addl=45,
plot_bfra_graph=FALSE)
11.1.4 Multiple solutions
You can test how varying multiple parameters simultaneously affects the opponent processes,
and in turn affects the hormetic curve. For example, you can pass two vectors to modify both
Emax_b and EC50_b simultaneously.
49Figure 11. BFRA simulation produced with the following R command = bfra(Emax_b=c(1.03,
3), EC50_b=c(7, 30), seq_1=0.0025, seq_2 = 0.2, plot_2=c(0.0025, 0.06))
50Figure 12. BFRA simulation produced with the following R command = bfra(gamma_b=c(2,
3))
11.1.5 Pharmacokinetic perturbations
From now on, only analytical steady-state solutions will be presented in the Bode plot.
5111.1.5.1 Modifying a-process pharmacokinetic decay constant
Figure 13. BFRA simulation produced with the following R command = bfra(k_apk=c(0.005,
0.01, 0.02, 0.04), colorscheme=2)
5211.1.5.2 Modifying b-process pharmacokinetic decay constant
Figure 14. BFRA simulation produced with the following R command = bfra(k_bpk=c(0.0005,
0.001, 0.002, 0.004), colorscheme=2). Note that the top two Hill equation graphs remain
unchanged.
5311.1.6 Pharmacodynamic perturbations
Note that the analytical steady-state solution is calculated in terms of the pharmacokinetic decay
constants for the current version of bfra(), but not the pharmacodynamic ones. This may be
rectified in future versions. Hence, for the graphs below in which k_apd and k_bpd are modified,
the BFRA graph is not plotted.
11.1.6.1 Modifying a-process pharmacodynamic decay constant
54Figure 15. BFRA simulation produced with the following R command = bfra(k_apd=c(0.0001,
0.001, 0.01, 0.1), colorscheme=3)
11.1.6.2 Modifying b-process pharmacodynamic decay constant
Figure 16. BFRA simulation produced with the following R command = bfra(k_bpd=c(0.0001,
0.01, 1), colorscheme=3)
5511.1.6.3 Modifying hedonic compartment (H) decay constant
Figure 17. BFRA simulation produced with the following R command = bfra(k_H=c(0.25,
0.5, 2), colorscheme=3)
5611.1.7 Hill equation parameters
11.1.7.1 Modifying E0_a
Figure 18. BFRA simulation produced with the following R command = bfra(E0_a=c(-1, 0,
1, 2), colorscheme=4)
5711.1.7.2 Modifying Emax_a
Figure 19. BFRA simulation produced with the following R command = bfra(Emax_a=c(0.5,
1, 2), colorscheme=4)
5811.1.7.3 Modifying EC50_a
Figure 20. BFRA simulation produced with the following R command = bfra(EC50_a=c(0.5,
1, 2), colorscheme=4)
5911.1.7.4 Modifying gamma_a
Figure 21. BFRA simulation produced with the following R command = bfra(gamma_a=c(1,
2, 3), colorscheme=4)
6011.1.7.5 Modifying E0_b
Figure 22. BFRA simulation produced with the following R command = bfra(E0_b=c(-1, 0,
1, 2), colorscheme=4)
6111.1.7.6 Modifying Emax_b
Figure 23. BFRA simulation produced with the following R command = bfra(Emax_b=c(1,
2, 3, 4), colorscheme=4)
6211.1.7.7 Modifying EC50_b
Figure 24. BFRA simulation produced with the following R command = bfra(EC50_b=c(5,
7, 11, 17), colorscheme=4)
6311.1.7.8 Modifying gamma_b
Figure 25. BFRA simulation produced with the following R command = bfra(gamma_b=c(1,
2, 3), colorscheme=4)
6411.2 Examples of performing a BCRA (Behavioral Count Response
Analysis)
The process for a Behavioral Count Response Analysis (BCRA) is identical to that for a BFRA,
except in this case, the frequency of the behavioral doses is kept constant, and the count of
behavioral doses is changed. This results in a count-response graph instead of a frequency-
response graph.
We have included our code for performing a BCRA in the ‘BCRA.R’ file in the Supplementary
Materials. The main function to use for BCRA simulations is bcra(). The default simulation is
below, followed by simulations with varying parameters to modify the opponent processes.
Default parameters are: k_Dose=1, k_apk=0.02, k_bpk=0.004, k_apd=1, k_bpd=1, k_H=1,
E0_a=0, Emax_a=1, EC50_a=1, gamma_a=2, E0_b=0, Emax_b=3, EC50_b=9, and
gamma_b=2.
65Figure 26. BCRA simulation produced with the following R command = bcra()
6611.2.1 Pharmacokinetic perturbations
11.2.1.1 Modifying a-process pharmacokinetic decay constant
Figure 27. BCRA simulation produced with the following R command = bcra(k_apk=c(0.005,
0.01, 0.02), colorscheme=2)
6711.2.1.2 Modifying b-process pharmacokinetic decay constant
Figure 28. BCRA simulation produced with the following R command = bcra(k_bpk=c(0.003,
0.006, 0.012), colorscheme=2). Note that the top two Hill equation graphs remain unchanged.
6811.2.2 Pharmacodynamic perturbations
11.2.2.1 Modifying a-process pharmacodynamic decay constant
Figure 29. BCRA simulation produced with the following R command = bcra(k_apd=c(0.0001,
0.001, 0.01, 0.1), colorscheme=3)
6911.2.2.2 Modifying b-process pharmacodynamic decay constant
Figure 30. BCRA simulation produced with the following R command = bcra(k_bpd=c(0.0001,
0.001, 0.01, 0.1), colorscheme=3)
7011.2.2.3 Modifying hedonic compartment (H) decay constant
Figure 31. BCRA simulation produced with the following R command = bcra(k_H=c(0.25,
0.5, 1, 2), colorscheme=3)
7111.2.3 Hill equation parameters
11.2.3.1 Modifying E0_a
Figure 32. BCRA simulation produced with the following R command = bcra(E0_a=c(-1, 0,
1, 2), colorscheme=4)
7211.2.3.2 Modifying Emax_a
Figure 33. BCRA simulation produced with the following R command = bcra(Emax_a=c(0.5,
1, 2), colorscheme=4)
7311.2.3.3 Modifying EC50_a
Figure 34. BCRA simulation produced with the following R command = bcra(EC50_a=c(0.5,
1, 2), colorscheme=4)
7411.2.3.4 Modifying gamma_a
Figure 35. BCRA simulation produced with the following R command = bcra(gamma_a=c(1,
2, 4), colorscheme=4)
7511.2.3.5 Modifying E0_b
Figure 36. BCRA simulation produced with the following R command = bcra(E0_b=c(-1, 0,
1, 2), colorscheme=4)
7611.2.3.6 Modifying Emax_b
Figure 37. BCRA simulation produced with the following R command = bcra(Emax_b=c(1,
2, 3), colorscheme=4)
7711.2.3.7 Modifying EC50_b
Figure 38. BCRA simulation produced with the following R command = bcra(EC50_b=c(5,
8, 16), colorscheme=4)
7811.2.3.8 Modifying gamma_b
Figure 39. BCRA simulation produced with the following R command = bcra(gamma_b=c(1,
2.2, 4.6), colorscheme=4)
7912 Appendix 3
12.1 BFRA.R
### This file contains R code for an example of a behavioral posology
simulation, performing a Behavioral Frequency Response Analysis on a PK/PD
model of a repeated digital behavior with opponent process dynamics. Examples
of how to run simulations using the function bfra() can be found in the
Supplementary Materials.
### Nathan Henry, November 2023
### Setup
library("tidyverse")
library("mrgsolve")
library("patchwork")
library("latex2exp")
# You may need to install some of these packages from GitHub, and may require
RTools. Refer to the documentation for remotes::install_github() and
https://cran.r-project.org/bin/windows/Rtools/, respectively.
## Package versions:
# tidyverse = 2.0.0
# mrgsolve = 1.0.9
# patchwork = 1.1.2
# latex2exp = 0.9.6
### -----
# Load in C++ model code
cpp_code <- "
$PARAM // Parameters for simulation
// Clearance rates for compartments - reset by opponentprocess_bfra()
function call
k_Dose = 0,
k_apk = 0,
k_bpk = 0,
80k_apd = 0,
k_bpd = 0,
k_H = 0,
// Pharmacodynamic constants - reset by opponentprocess_bfra() function
call
E0_a = 0,
Emax_a = 0,
EC50_a = 0,
gamma_a = 0,
E0_b = 0,
Emax_b = 0,
EC50_b = 0,
gamma_b = 0,
// Infusion duration
infuse = 1
$CMT // Model compartments
Dose, // Hormonal concentration following Digital Behavior
apk, // a-process pharmacokinetics
apd, // a-process pharmacodynamics
bpk, // b-process pharmacokinetics
bpd, // b-process pharmacodynamics
H // Overall hedonic outcomes
$MAIN // Set additional relationships
D_Dose = infuse; // Sets the infusion duration for digital behavior
compartment
$ODE // Ordinary Differential Equations
dxdt_Dose = - k_Dose * Dose;
dxdt_apk = k_Dose * Dose - k_apk * apk;
81dxdt_bpk = k_apk * apk - k_bpk * bpk;
dxdt_apd = E0_a + (Emax_a * pow(apk, gamma_a)) / (pow(EC50_a, gamma_a)
+ pow(apk, gamma_a)) - k_apd * apd;
dxdt_bpd = E0_b + (Emax_b * pow(bpk, gamma_b)) / (pow(EC50_b, gamma_b)
+ pow(bpk, gamma_b)) - k_bpd * bpd;
dxdt_H = k_apd * apd - k_bpd * bpd - k_H * H;
"
# Compile C++ code
mod <- mcode('Cppcode', cpp_code)
### color_scheme defines the color scheme for the BFRA graphs.
color_scheme <- function(scheme_num=1) {
# Define a list of color schemes
color_schemes <- list(
scheme_1 = c('#08306B', '#2171B5', '#6BAED6', '#9ECAE1'),
scheme_2 = c('darkgreen', 'forestgreen', 'limegreen', 'green'),
scheme_3 = c('slateblue4', 'slateblue3', 'mediumpurple3',
'mediumpurple1'),
scheme_4 = c('firebrick4', 'firebrick3', 'coral2', 'chocolate1')
)
# Check if the scheme_num is valid
if (scheme_num < 1 || scheme_num > length(color_schemes)) {
stop("Invalid scheme number. Please choose a number from 1 to 4.")
}
# Return the selected color scheme
return(color_schemes[[scheme_num]])
}
82### opponentprocess_bfra() takes arguments for PK/PD models, creates an
mrgsolve compartmental model, and plots the output.
opponentprocess_bfra <- function(
ii=100000, # Dosing interval
sim_length=4000, # Time length of PKPD simulation, in minutes
addl=999999, # Number of additional doses to deliver - essentially
infinite.
plot_biophase=FALSE, # Whether to calculate the graphs for biophase or
not.
colorscheme=1, # Set color scheme for graphs
# Set PK/PD constants for C++ code
k_Dose=1,
k_apk=0.02,
k_bpk=0.004,
k_apd=1,
k_bpd=1,
k_H=1,
E0_a=0,
Emax_a=1,
EC50_a=1,
gamma_a=2,
E0_b=0,
Emax_b=3,
EC50_b=9,
gamma_b=2,
# Set infusion duration for drug input
infuse=1,
## Set values for a-process, b-process, and double gamma plot datasets
to return. These values represent the number of doses that fall within the
allocated timeframe
83plot_2=c(0.002, 0.01) # PKPD models for dose frequencies listed in plot_2
are plotted along with their associated Bode plot.
) {
# Create data frame of parameters to pass to simulation.
idataset=data.frame(
k_Dose=k_Dose,
k_apk=k_apk,
k_bpk=k_bpk,
k_apd=k_apd,
k_bpd=k_bpd,
k_H=k_H,
E0_a=E0_a,
Emax_a=Emax_a,
EC50_a=EC50_a,
gamma_a=gamma_a,
E0_b=E0_b,
Emax_b=Emax_b,
EC50_b=EC50_b,
gamma_b=gamma_b,
infuse=infuse,
sim_length=sim_length
) %>%
rowid_to_column("ID") # Add column of IDs to start of data frame
if (nrow(idataset) > 4) stop('Number of simulations must be 4 or less.
Check idataset') # Stop if number of simulations > 4
# Print out simulation parameters once
if (plot_biophase) {
cat('\nSimulation parameters =\n\n')
print(idataset)
}
84# Create a list of events
events <- ev(amt = 1, # Potency of dose
rate = -2, # Signals that duration of infusion is modeled
ii = ii, # Dosing interval
ID = 1:nrow(idataset), # Add number of simulations being run
addl = addl) # No. of additional doses to administer
# Run model
out <- mrgsim(mod, events, idataset, end=sim_length, maxsteps=50000)
# Calculate integral (AUC, area under curve) of H (hedonic) compartment
AUC_H <- out@data %>%
group_by(ID) %>%
summarise(AUC=sum(H))
# Calculate dose frequency
freq <- 1/ii
AUC_H$freq <- freq
# Print results
cat(paste('Integral of hedonic graph for simulation', AUC_H$ID, '=',
AUC_H$AUC, '\n'))
cat(paste('Dose frequency =', freq, 'per min\n\n'))
# If rounded dose frequency value falls within plot_2 list, then return
plot of H compartment
if (isTRUE(all.equal(freq, plot_2[[1]])) | isTRUE(all.equal(freq,
plot_2[[2]]))) { # Use all.equal() to check equivalence of floating point
numbers
# Plot of H compartment over time
cat('Saving plots for dose frequency above.................\n\n')
85plot_2_freq <- out@data %>%
ggplot(aes(x=time, y=H, colour=factor(ID))) +
geom_hline(yintercept=0, linetype='dotted', color='grey50') +
geom_line() +
scale_color_manual(values=color_scheme(colorscheme)) +
ggtitle(bquote(paste('Paper clip production frequency = ', .(freq)) ~
min^-1)) +
xlab('Time, t [min]') + {
if (isTRUE(all.equal(freq, plot_2[[1]])))
ylab(bquote(paste('Hedonic state, H'[a*','*b]*(t), ' [hedons]')))# Only
create y label if first plot
} +
theme_light() + {
if (isTRUE(all.equal(freq, plot_2[[1]]))) { # Only create y label
if first plot
theme(plot.title=element_text(size=9, hjust=0.5,
margin=margin(t=0, b=0)),
legend.position='none')
} else {
theme(plot.title=element_text(size=9, hjust=0.5,
margin=margin(t=0, b=0)),
legend.position='none',
axis.title.y=element_blank())
}
}
} else {
plot_2_freq <- NULL
}
## Create plots for biophase curves for PK -> PD conversion, using biophase
equations
if (plot_biophase) {
# Set x axis length with dose_seq, then calculate biophase curves
86pd_data <- tibble(dose_seq=seq(0, 50, 0.5))
for (i in 1:nrow(idataset)) { # Calculate biophase curve for each set
of parameters
# Create column name for biophase curve based on ID number
apd_colname <- paste0('apd', i); bpd_colname <- paste0('bpd', i)
# Calculate biophase curves
pd_data <- pd_data %>%
mutate({{apd_colname}} := idataset$E0_a[i] + (idataset$Emax_a[i] *
dose_seq ^ idataset$gamma_a[i]) / (idataset$EC50_a[i] ^ idataset$gamma_a[i]
+ dose_seq ^ idataset$gamma_a[i]),
{{bpd_colname}} := idataset$E0_b[i] + (idataset$Emax_b[i] *
dose_seq ^ idataset$gamma_b[i]) / (idataset$EC50_b[i] ^ idataset$gamma_b[i]
+ dose_seq ^ idataset$gamma_b[i]))
}
# Plots for biophase curves
apd_graph <- pd_data %>%
pivot_longer(cols=starts_with('apd'), names_to='ID',
values_to='Values') %>%
ggplot(aes(x=dose_seq, y=Values, colour=ID)) +
geom_line() +
scale_color_manual(values=color_scheme(colorscheme)) +
theme_light() +
theme(plot.title=element_text(size=9, hjust=0.5),
legend.position='none') +
ylab('Pharmacodynamic effect, pd [hedons]') +
xlab(bquote(paste('Pharmacokinetic concentration, '*a[pk], ' [arb.
units]')))
bpd_graph <- pd_data %>%
pivot_longer(cols=starts_with('bpd'), names_to='ID',
values_to='Values') %>%
ggplot(aes(x=dose_seq, y=Values, colour=ID)) +
geom_line() +
87scale_color_manual(values=color_scheme(colorscheme)) +
theme_light() +
theme(plot.title=element_text(size=9, hjust=0.5),
legend.position='none',
axis.title.y=element_blank()) +
xlab(bquote(paste('Pharmacokinetic concentration, '*b[pk], ' [arb.
units]')))
}
## ---------------------------------------------------------------------
---------
# Return necessary objects, including a list of parameters (idataset)
ifelse(plot_biophase,
return(list(AUC_H, freq, plot_2_freq, apd_graph, bpd_graph,
idataset)),
return(list(AUC_H, freq, plot_2_freq, NA, NA, idataset)))
}
### bfra() takes opponentprocess_bfra() and runs it across a range of dose
frequencies, thus allowing us to plot the relationship between dose frequency
and the integral of hedonic outcomes, and to determine whether this
relationship is hormetic.
bfra <- function(
# Pass on arguments to opponentprocess_bfra()
...,
# Set color scheme for graphs
colorscheme=1,
# Set the resolution (seq_1) and upper limit (seq_2) of the x-axis values
for the BFRA
seq_1=0.0002,
seq_2=0.01,
88# Set y limit for hormesis graph (integer). If NA, ylim is automatically
set
gg_ylim=NA,
# Plot BFRA simulated results, up to sim_length, the maximum simulation
time
include_simulated_results=FALSE,
# Plot BFRA graph (either analytical or analytical + simulated)
plot_bfra_graph=TRUE
) {
# List of dose intervals to pass to opponentprocess_bfra()
dose_interval <- c(0, seq(seq_1, seq_2, seq_1)^-1)
# Run loop to calculate Bode magnitude plot across range of frequencies
H_list <- list() # Create list to house graphs of hedonic outcomes vs time
for (i in 1:length(dose_interval)) {
# If first dose interval, then set up bode_data data frame
if (i == 1) {
loop_list <- opponentprocess_bfra(ii=dose_interval[2],
colorscheme=colorscheme,
...)
# Create data frame to store wellbeing scores in, based on number of
simulations performed
bode_data <- tibble(
'ID' = 1:nrow(loop_list[[1]]), # ID of each mrgsolve simulation
'AUC' = rep(0, nrow(loop_list[[1]])), # AUC scores for H compartment
graphs
89'freq' = rep(0, nrow(loop_list[[1]])) # Dose frequency
)
} else if (i == 2) {
# If second dose interval, then calculate biophase graphs. Otherwise
just calculate loop_list to append to bode_data
loop_list <- opponentprocess_bfra(ii=dose_interval[i],
plot_biophase=TRUE,
colorscheme=colorscheme,
...)
apd_plot <- loop_list[[4]]; bpd_plot <- loop_list[[5]]
} else {
loop_list <- opponentprocess_bfra(ii=dose_interval[i],
colorscheme=colorscheme,
...)
}
# Append AUC scores (hedonic outcomes) and dose frequencies, and store
H compartment graphs
bode_data <- bode_data %>%
rbind(loop_list[[1]])
H_list[[length(H_list) + 1]] <- loop_list[[3]] # H compartment
simulations
}
# Keep only distinct rows
bode_data <- bode_data %>% distinct(.keep_all=TRUE)
# Calculate the analytical solution to the BFRA, and add to the bode_data
df. Use parameters passed to opponentprocess_bfra(), and scale the solution
up by sim_length to ensure graphs can be compared easily
params <- loop_list[[6]]
H_axis <- params$sim_length * (params$E0_a +
params$Emax_a*((1*bode_data$freq/params$k_Dose)/params$k_apk)^params$gamma
_a/(params$EC50_a^params$gamma_a+((1*bode_data$freq/params$k_Dose)/params$
k_apk)^params$gamma_a) - (params$E0_b +
90params$Emax_b*((1*bode_data$freq/params$k_Dose)/params$k_bpk)^params$gamma
_b/(params$EC50_b^params$gamma_b+((1*bode_data$freq/params$k_Dose)/params$
k_bpk)^params$gamma_b))) / params$k_H
bode_data$H_analytical <- H_axis # Add analytical solutions to bode_data
# Only plot BFRA graph if k_apd == 1, since the analytical solution is
calculated based on pharmacokinetic decay constants, rather than
pharmacodynamic. See equation to calculate H_axis above
if (plot_bfra_graph & length(unique(params$k_apd)) < 2 &
length(unique(params$k_bpd)) < 2) {
if (unique(params$k_apd) == 1 & unique(params$k_bpd) == 1) {
# Create Bode magnitude plot
bode_graph <- bode_data %>%
ggplot(aes(x=freq, color=factor(ID))) +
geom_hline(yintercept=0, color='grey50') +
geom_line(aes(y=H_analytical, linetype='Steady-state solution')) +
{
if (include_simulated_results) {
geom_line(aes(y=AUC, linetype='Simulated solution'))
}
} +
scale_color_manual(values=color_scheme(colorscheme)) + {
if (!is.na(gg_ylim)) {
coord_cartesian(ylim=c(gg_ylim, NA))
}
} + scale_linetype_manual(name = NULL, values = c("Steady-state
solution" = "solid", "Simulated solution" = "dashed")) + {
if (include_simulated_results) {
scale_y_continuous(sec.axis = sec_axis(~ . / params$sim_length,
name=bquote('TU \u2248' ~ H['a,b'['steady state']] ~ "[hedons]")))
} else {
scale_y_continuous(labels = scales::number_format(scale =
1/params$sim_length), name=bquote('TU \u2248' ~ H['a,b'['steady state']] ~
"[hedons]"))
}
91} +
xlab(bquote('Paper clip production frequency, f' ~ '[' * min^-1 *
']')) +
ylab(bquote('TU =' ~ integral(H['a,b']*dt, 0, t[sim]) ~ '[hedons]'))
+
guides(color='none') +
theme_light() +
theme(legend.position=ifelse(include_simulated_results, "bottom",
"none"), legend.box="horizontal", legend.justification="center")
# Patch Hill equation, temporal, and Bode plots together with
patchwork package, and print
tryCatch(bode_patch <- (apd_plot | bpd_plot) / (first(H_list) |
last(H_list)) / bode_graph +
plot_annotation(tag_levels = 'a') &
theme(plot.tag = element_text(size = 11)),
error=function(e) {
warning(e)
stop("Error: bode_patch didn't patch together correctly.
Double-check that the values in plot_2 are exact multiples of seq_1. So for
example, you could pass the following arguments: 'seq_1=0.001, seq_2=0.1,
plot_2=c(0.005, 0.1)'.")
}
)
} else {
# Patch Hill equation and temporal plots together with patchwork
package, and print
tryCatch(bode_patch <- (apd_plot | bpd_plot) / (first(H_list) |
last(H_list)) +
plot_annotation(tag_levels = 'a') &
theme(plot.tag = element_text(size = 11)),
error=function(e) {
stop("Error: bode_patch didn't patch together correctly.
Double-check that the values in plot_2 are exact multiples of seq_1. So for
example, you could pass the following arguments: 'seq_1=0.001, seq_2=0.1,
plot_2=c(0.005, 0.1)'.")
}
92)
}
} else {
# Patch Hill equation and temporal plots together with patchwork package,
and print
tryCatch(bode_patch <- (apd_plot | bpd_plot) / (first(H_list) |
last(H_list)) +
plot_annotation(tag_levels = 'a') &
theme(plot.tag = element_text(size = 11)),
error=function(e) {
stop("Error: bode_patch didn't patch together correctly.
Double-check that the values in plot_2 are exact multiples of seq_1. So for
example, you could pass the following arguments: 'seq_1=0.001, seq_2=0.1,
plot_2=c(0.005, 0.1)'.")
}
)
}
print(bode_patch)
}
12.2 BCRA.R
### This file contains R code for an example of a behavioral posology
simulation, performing a Behavioral Count Response Analysis (BCRA) on a
PK/PD model of a repeated digital behavior with opponent process dynamics.
Examples of how to run simulations using the function bcra() can be found
in the Supplementary Materials.
### Nathan Henry, November 2023
### Setup
library("tidyverse")
library("mrgsolve")
library("patchwork")
library("latex2exp")
93# You may need to install some of these packages from GitHub, and may require
RTools. Refer to the documentation for remotes::install_github() and
https://cran.r-project.org/bin/windows/Rtools/, respectively.
## Package versions:
# tidyverse = 2.0.0
# mrgsolve = 1.0.9
# patchwork = 1.1.2
# latex2exp = 0.9.6
### -----
# Load in C++ model code
cpp_code <- "
$PARAM // Parameters for simulation
// Clearance rates for compartments - reset by opponentprocess_bcra()
function call
k_Dose = 0,
k_apk = 0,
k_bpk = 0,
k_apd = 0,
k_bpd = 0,
k_H = 0,
// Pharmacodynamic constants - reset by opponentprocess_bcra() function
call
E0_a = 0,
Emax_a = 0,
EC50_a = 0,
gamma_a = 0,
E0_b = 0,
Emax_b = 0,
EC50_b = 0,
gamma_b = 0,
94// Infusion duration
infuse = 1
$CMT // Model compartments
Dose, // Hormonal concentration following Digital Behavior
apk, // a-process pharmacokinetics
apd, // a-process pharmacodynamics
bpk, // b-process pharmacokinetics
bpd, // b-process pharmacodynamics
H // Overall hedonic outcomes
$MAIN // Set additional relationships
D_Dose = infuse; // Sets the infusion duration for digital behavior
compartment
$ODE // Ordinary Differential Equations
dxdt_Dose = - k_Dose * Dose;
dxdt_apk = k_Dose * Dose - k_apk * apk;
dxdt_bpk = k_apk * apk - k_bpk * bpk;
dxdt_apd = E0_a + (Emax_a * pow(apk, gamma_a)) / (pow(EC50_a, gamma_a)
+ pow(apk, gamma_a)) - k_apd * apd;
dxdt_bpd = E0_b + (Emax_b * pow(bpk, gamma_b)) / (pow(EC50_b, gamma_b)
+ pow(bpk, gamma_b)) - k_bpd * bpd;
dxdt_H = k_apd * apd - k_bpd * bpd - k_H * H;
"
# Compile C++ code
mod <- mcode('Cppcode', cpp_code)
### color_scheme defines the color scheme for the BCRA graphs.
color_scheme <- function(scheme_num=1) {
95# Define a list of color schemes
color_schemes <- list(
scheme_1 = c('#08306B', '#2171B5', '#6BAED6', '#9ECAE1'),
scheme_2 = c('darkgreen', 'forestgreen', 'limegreen', 'green'),
scheme_3 = c('slateblue4', 'slateblue3', 'mediumpurple3',
'mediumpurple1'),
scheme_4 = c('firebrick4', 'firebrick3', 'coral2', 'chocolate1')
)
# Check if the scheme_num is valid
if (scheme_num < 1 || scheme_num > length(color_schemes)) {
stop("Invalid scheme number. Please choose a number from 1 to 4.")
}
# Return the selected color scheme
return(color_schemes[[scheme_num]])
}
### opponentprocess_bcra() takes arguments for PK/PD models, creates an
mrgsolve compartmental model, and plots the output.
opponentprocess_bcra <- function(
ii=50, # Dosing interval
sim_length=4000, # Time length of PKPD simulation, in minutes
addl=0, # Number of additional doses to deliver - essentially infinite.
plot_biophase=FALSE, # Whether to calculate the graphs for biophase or
not.
colorscheme=1, # Set color scheme for graphs
# Set PK/PD constants for C++ code
k_Dose=1,
k_apk=0.02,
k_bpk=0.004,
k_apd=1,
96k_bpd=1,
k_H=1,
E0_a=0,
Emax_a=1,
EC50_a=1,
gamma_a=2,
E0_b=0,
Emax_b=3,
EC50_b=9,
gamma_b=2,
# Set infusion duration for drug input
infuse=1,
## Set values for a-process, b-process, and double gamma plot datasets
to return. These values represent the number of doses that fall within the
allocated timeframe
plot_2=c(4, 29) # PKPD models for number of repeated doses listed in
plot_2 are plotted along with their associated Bode plot.
) {
# Create data frame of parameters to pass to simulation.
idataset=data.frame(
k_Dose=k_Dose,
k_apk=k_apk,
k_bpk=k_bpk,
k_apd=k_apd,
k_bpd=k_bpd,
k_H=k_H,
E0_a=E0_a,
Emax_a=Emax_a,
EC50_a=EC50_a,
gamma_a=gamma_a,
97E0_b=E0_b,
Emax_b=Emax_b,
EC50_b=EC50_b,
gamma_b=gamma_b,
infuse=infuse,
sim_length=sim_length
) %>%
rowid_to_column("ID") # Add column of IDs to start of data frame
if (nrow(idataset) > 4) stop('Number of simulations must be 4 or less.
Check idataset') # Stop if number of simulations > 4
# Print out simulation parameters once
if (plot_biophase) {
cat('\nSimulation parameters =\n\n')
print(idataset)
}
# Create a list of events
events <- ev(amt = 1, # Potency of dose
rate = -2, # Signals that duration of infusion is modeled
ii = ii, # Dosing interval
ID = 1:nrow(idataset), # Add number of simulations being run
addl = addl) # No. of additional doses to administer, noting
that mrgsolve always
# Run model
out <- mrgsim(mod, events, idataset, end=sim_length, maxsteps=50000)
# Calculate integral (AUC, area under curve) of H (hedonic) compartment
AUC_H <- out@data %>%
group_by(ID) %>%
summarise(AUC=sum(H))
98# Make a note of the number of total doses run
AUC_H$n <- addl + 1
# Print results
cat(paste('Integral of hedonic graph for simulation', AUC_H$ID, '=',
AUC_H$AUC, '\n'))
cat(paste('No. of additional doses =', addl, '\n\n'))
# If the number of additional doses falls within plot_2 list, then return
plot of H compartment
if (addl %in% plot_2) {
# Plot of H compartment over time
cat('Saving plots for dose repetitions above.................\n\n')
plot_2_addl <- out@data %>%
ggplot(aes(x=time, y=H, colour=factor(ID))) +
geom_hline(yintercept=0, linetype='dotted', color='grey50') +
geom_line() +
scale_color_manual(values=color_scheme(colorscheme)) +
ggtitle(paste('Count of paper clips produced =', addl + 1)) +
xlab('Time, t [min]') + {
if (isTRUE(all.equal(addl, plot_2[[1]])))
ylab(bquote(paste('Hedonic state, H'[a*','*b]*(t), ' [hedons]')))# Only
create y label if first plot
} +
theme_light() + {
if (isTRUE(all.equal(addl, plot_2[[1]]))) { # Only create y label
if first plot
theme(plot.title=element_text(size=9, hjust=0.5,
margin=margin(t=0, b=0)),
legend.position='none')
} else {
99theme(plot.title=element_text(size=9, hjust=0.5,
margin=margin(t=0, b=0)),
legend.position='none',
axis.title.y=element_blank())
}
}
} else {
plot_2_addl <- NULL
}
## Create plots for biophase curves for PK -> PD conversion, using biophase
equations
if (plot_biophase) {
# Set x axis length with dose_seq, then calculate biophase curves
pd_data <- tibble(dose_seq=seq(0, 50, 0.5))
for (i in 1:nrow(idataset)) { # Calculate biophase curve for each set
of parameters
# Create column name for biophase curve based on ID number
apd_colname <- paste0('apd', i); bpd_colname <- paste0('bpd', i)
# Calculate biophase curves
pd_data <- pd_data %>%
mutate({{apd_colname}} := idataset$E0_a[i] + (idataset$Emax_a[i] *
dose_seq ^ idataset$gamma_a[i]) / (idataset$EC50_a[i] ^ idataset$gamma_a[i]
+ dose_seq ^ idataset$gamma_a[i]),
{{bpd_colname}} := idataset$E0_b[i] + (idataset$Emax_b[i] *
dose_seq ^ idataset$gamma_b[i]) / (idataset$EC50_b[i] ^ idataset$gamma_b[i]
+ dose_seq ^ idataset$gamma_b[i]))
}
# Plots for biophase curves
apd_graph <- pd_data %>%
100pivot_longer(cols=starts_with('apd'), names_to='ID',
values_to='Values') %>%
ggplot(aes(x=dose_seq, y=Values, colour=ID)) +
geom_line() +
scale_color_manual(values=color_scheme(colorscheme)) +
theme_light() +
theme(plot.title=element_text(size=9, hjust=0.5),
legend.position='none') +
ylab('Pharmacodynamic effect, pd [hedons]') +
xlab(bquote(paste('Pharmacokinetic concentration, '*a[pk], ' [arb.
units]')))
bpd_graph <- pd_data %>%
pivot_longer(cols=starts_with('bpd'), names_to='ID',
values_to='Values') %>%
ggplot(aes(x=dose_seq, y=Values, colour=ID)) +
geom_line() +
scale_color_manual(values=color_scheme(colorscheme)) +
theme_light() +
theme(plot.title=element_text(size=9, hjust=0.5),
legend.position='none',
axis.title.y=element_blank()) +
xlab(bquote(paste('Pharmacokinetic concentration, '*b[pk], ' [arb.
units]')))
}
## ---------------------------------------------------------------------
---------
# Return necessary objects, including a list of parameters (idataset)
ifelse(plot_biophase,
return(list(AUC_H, addl, plot_2_addl, apd_graph, bpd_graph,
idataset)),
return(list(AUC_H, addl, plot_2_addl, NA, NA, idataset)))
}
101### bcra() takes opponentprocess_bcra() and runs it across a range of dose
repetitions, thus allowing us to plot the relationship between the number
of repeated doses and the integral of hedonic outcomes, and to determine
whether this relationship is hormetic.
bcra <- function(
# Pass on arguments to opponentprocess_bcra()
...,
# Set color scheme for graphs
colorscheme=1,
# Set the resolution (seq_1) and upper limit (seq_2) of the x-axis values
for the BCRA
seq_1=1,
seq_2=30,
# Set y limit for hormesis graph (integer). If NA, ylim is automatically
set
gg_ylim=NA,
# Plot BCRA graph (either analytical or analytical + simulated)
plot_bcra_graph=TRUE
) {
# List of dose repetitions to pass to opponentprocess_bcra()
dose_repetitions <- c(0, seq(seq_1, seq_2, seq_1))
# Run loop to calculate Bode magnitude plot across range of dose
repetitions
H_list <- list() # Create list to house graphs of hedonic outcomes vs time
for (i in 1:length(dose_repetitions)) {
# If first dose repetition value, then set up bode_data data frame
102if (i == 1) {
loop_list <- opponentprocess_bcra(ii=dose_repetitions[2],
colorscheme=colorscheme,
...)
# Create data frame to store wellbeing scores in, based on number of
simulations performed
bode_data <- tibble(
'ID' = 1:nrow(loop_list[[1]]), # ID of each mrgsolve simulation
'AUC' = rep(0, nrow(loop_list[[1]])), # AUC scores for H compartment
graphs
'n' = rep(0, nrow(loop_list[[1]])) # Dose repetitions
)
} else if (i == 2) {
# If second dose repetition value, then calculate biophase graphs.
Otherwise just calculate loop_list to append to bode_data
loop_list <- opponentprocess_bcra(addl=dose_repetitions[i],
plot_biophase=TRUE,
colorscheme=colorscheme,
...)
apd_plot <- loop_list[[4]]; bpd_plot <- loop_list[[5]]
} else {
loop_list <- opponentprocess_bcra(addl=dose_repetitions[i],
colorscheme=colorscheme,
...)
}
# Append AUC scores (hedonic outcomes) and dose repetitions, and store
H compartment graphs
bode_data <- bode_data %>%
rbind(loop_list[[1]])
H_list[[length(H_list) + 1]] <- loop_list[[3]] # H compartment
simulations
103}
# Keep only distinct rows
bode_data <- bode_data %>% distinct(.keep_all=TRUE)
# Only plot BCRA graph if k_apd == 1, since the analytical solution is
calculated based on pharmacokinetic decay constants, rather than
pharmacodynamic. See equation to calculate H_axis above
if (plot_bcra_graph) {
# Create Bode magnitude plot
bode_graph <- bode_data %>%
ggplot(aes(x=n, y=AUC, color=factor(ID))) +
geom_hline(yintercept=0, color='grey50') +
geom_line() +
scale_color_manual(values=color_scheme(colorscheme)) + {
if (!is.na(gg_ylim)) {
coord_cartesian(ylim=c(gg_ylim, NA))
}
} +
xlab('Count of paper clips produced, n') +
ylab(bquote('TU =' ~ integral(H['a,b']*dt, 0, t[sim]) ~ '[hedons]'))
+
guides(color='none') +
theme_light() +
theme(legend.position='none')
# Patch Hill equation, temporal, and Bode plots together with patchwork
package, and print
tryCatch(bode_patch <- (apd_plot | bpd_plot) / (first(H_list) |
last(H_list)) / bode_graph +
plot_annotation(tag_levels = 'a') &
theme(plot.tag = element_text(size = 11)),
error=function(e) {
warning(e)
104stop("Error: bode_patch didn't patch together correctly.
Double-check that the values in plot_2 are exact multiples of seq_1. So for
example, you could pass the following arguments: 'seq_1=1, seq_2=50,
plot_2=c(5, 20)'.")
}
)
} else {
# Patch Hill equation and temporal plots together with patchwork package,
and print
tryCatch(bode_patch <- (apd_plot | bpd_plot) / (first(H_list) |
last(H_list)) +
plot_annotation(tag_levels = 'a') &
theme(plot.tag = element_text(size = 11)),
error=function(e) {
stop("Error: bode_patch didn't patch together correctly.
Double-check that the values in plot_2 are exact multiples of seq_1. So for
example, you could pass the following arguments: 'seq_1=1, seq_2=50,
plot_2=c(5, 20)'.")
}
)
}
print(bode_patch)
}
105