ToappearinIEEETransactionsonVisualizationandComputerGraphics.
Privacy-Preserving Gaze Data Streaming in Immersive Interactive
Virtual Reality: Robustness and User Experience
EthanWilson ,AzimIbragimov ,MichaelJ.Proulx ,SaiDeepTetali,KevinButler ,andEaktaJain
Fig.1: Top-left: ParticipantsunderwentaninteractiveVRexperiencewhileeyemovementswerepassivelyrecorded;Top-right:
ParticipantsplayedaneyetrackedVRgamewithprivacymechanismsappliedtogazestreams;Bottom:Anillustrationoftheeye
trackingpipelineinhead-mountedvirtualrealitysystems.Aftereyeimagesareprocessedandgazevectorsarecalculated,wecan
applyprivacymechanismstogazevectorssecurelyontheheadsetbeforepassingvaluestopotentiallyuntrustworthyapplications.
Abstract—Eyetrackingisroutinelybeingincorporatedintovirtualreality(VR)systems.Priorresearchhasshownthateyetracking
data,ifexposed,canbeusedforre-identificationattacks[14].Thestateofourknowledgeaboutcurrentlyexistingprivacymechanisms
islimitedtoprivacy-utilitytrade-offcurvesbasedondata-centricmetricsofutility, suchaspredictionerror, andblack-boxthreat
models. WeproposethatforinteractiveVRapplications,itisessentialtoconsideruser-centricnotionsofutilityandavarietyof
threatmodels.Wedevelopamethodologytoevaluatereal-timeprivacymechanismsforinteractiveVRapplicationsthatincorporate
subjectiveuserexperienceandtaskperformancemetrics. Weevaluateselectedprivacymechanismsusingthismethodologyand
findthatre-identificationaccuracycanbedecreasedtoaslowas14%whilemaintainingahighusabilityscoreandreasonabletask
performance.Finally,weelucidatethreethreatscenarios(black-box,black-boxwithexemplars,andwhite-box)andassesshowwell
thedifferentprivacymechanismsholduptotheseadversarialscenarios. ThisworkadvancesthestateoftheartinVRprivacyby
providingamethodologyforend-to-endassessmentoftheriskofre-identificationattacksandpotentialmitigatingsolutions.
IndexTerms—Virtualreality,privacy,eyetracking.
1 INTRODUCTION
Virtualreality(VR)technologyhasseenarapiddeploymentofeye Recently,eyetrackingmovementsalonehavebeenfoundtofunction
tracking-enabledheadsetsoverthepastseveralyears.Eyetrackinghas asabiometricidentifier[22,32]. Userscanbeuniquelyidentifiedin
manyapplicationsinVR,includingasaninteractionmodality[9,19,23, smalldirectories;inVR,usershavebeenshowntobeidentifiableatup
51,54,58],asananimationtool[53,60,65],forattentionanalysis[38, to85%accuracy[41].Thisopenstheriskofunwantedre-identification
76],forrenderingoptimizations[15,26,31,44,78,79,81],andforuser inonlineVRusage.Eyegazeisapromisinginputdeviceshowcasing
authentication[28,40,41,45,57]. veryuniqueinteractionsandoptimizations,butusersshouldnothaveto
choosebetweentheseinteractionsortheirownprivacy.Ifeyetracking
dataissharedwiththepropersafeguards,theriskofre-identification
• EthanWilson,AzimIbragimov,KevinButler,andEaktaJainarewiththe attacksorunwanteddataleakageforVRusersisalleviated.
Computer&InformationScience&Engineeringdepartmentatthe
UniversityofFlorida.E-mail: Some solutions have been proposed to protect users against re-
{ethanwilson,a.ibragimov,butler,ejain}@ufl.edu. identificationwhilestillenablingeyetrackingdatautility. Existing
• MichaelJ.ProulxiswithMetaRealityLabsResearch.E-mail: analysesofthesemechanismsfocusondata-centricutility,including
michaelproulx@meta.com. downstreamprocessessuchasareaofinterestanalysisorgazepredic-
• SaiDeepTetaliiswithMetaRealityLabs.E-mail:saideept@meta.com. tion.However,analysesfocusingoninteractiveVRneedtoconsider
theuser,whoislikelytofeeltheeffectswhentheireyetrackingdata
streamsareperturbedtograntprivacy.Itisnecessarytoconsiderthe
userfirstwhendesigningprivacymechanismsthatwillbeincorporated
intointeractiveVRexperiences.Usersmaychafeatadoptingprivacy
1
4202
beF
21
]CH.sc[
1v78670.2042:viXrasolutionsthatimpacttheinteractiveexperience(whichisthereason gamesarefoundtobemoreefficientandimmersivethantraditional
forbeinginVRinthefirstplace). Anotherlimitationtocurrenteye controlmodes[23,54],whichmaypersistintoVR2.
trackingprivacymethodologiesisthattheyareframedasblack-box Rendering Optimization: Foveated rendering is a critical opti-
threatscenarios.Inrealworldsettings,however,malicious3rdparties mizationtoincreaseresolutionandframerateofVRheadsets[25,44].
haveaccesstoanumberofstrategiesthataimtonullifythediscussed Foveatedrenderingsparselyrenderssamplesoutsideofthefovearegion,
privacyefforts. whichisdeterminedthrougheyetrackingsignals.Becauseperipheral
Our contributions: We first update current knowledge on re- vision has lower acuity than foveal vision, the image could be per-
identification risk in interactive VR by using the state-of-the-art in ceptuallysimilartotraditionalrenderingbutvastlylessexpensiveto
eyemovementidentitymatchinganddevelopinganinteractiveVRex- compute[31,78,79].Gazepredictionalgorithms[15,26,81]willenable
periencetoserveasanevaluationtestbed,re-identifyingN=26usersat proactivefoveatedrenderingandocclusionoptimizations.
anaverageaccuracyof67.3%.We measuretheprivacycapabilitiesof AvatarAnimation:Recordedgazecanbeusedtodriveeyeanima-
multiplemechanisms,identifyingthefollowingascapableofprotecting tionsinVR.Morerealisticeyemovementshavebeenshowninimprove
privacy:Gaussiannoise,spatialdownsampling,andsmoothing.Next, thequalityofinteractionwithvirtualavatars[21]andtoincreaseper-
weincorporatethesemechanismsintoaninteractiveVRexperience ceivedpresenceandavatarrealism[65].Gazecanenablevirtualavatars
whichuseseyetrackingastheprimarymodeofcontrol. Wejointly todisplaytrustacrossmultipleexpressionsandcontexts[53],andmul-
measurere-identificationaccuracy,taskperformance,andqualitative tiplepersonalitytraitscanbediscernedsolelythroughcharacters’eye
subjectiveutilityresponsestofirmlyassesstheprivacy-utilitytrade- motions[60].Byincorporatingrealgazebehaviorstoembodiedavatars,
offofthesemechanisms.Ourmechanismsdecreasere-identification eachavatarfeelsmoreuniqueandpersonable.
rates as low as 14.1% while retaining high subjective usability and Gaze-based Analytics: Eye tracking data can be a rich tool for
reasonabletaskperformance. Finally,weevaluatethemechanisms’ dataanalysis[67]. Examplesincludeareaofinterest(AOI)calcula-
robustnessagainstdedicatedadversariesunderthreeplausiblethreat tion [14,55], document classification and analysis [12,62], and at-
scenarios: black-boxaccess, black-boxaccesswithexemplars, and tentionvisualization[37]. Researchersfrommultiplefieldsuseeye
white-boxaccess.Ourprovidedmethodologycanserveasaguidefor movementstoanalyzetopicssuchassocialbehavior[59,83],visual
futureresearchofprivacymechanismsininteractivesettings,measur- attention[38,76],andsimulatedresponsesunderstress[68].
ingalongmultipleaxes. Theevaluatedprivacymechanismscanbe
utilizedasabasisforfurtherinnovationofnovelprivacymechanisms.
2.2 IdentificationRiskofRecordedEyeMovements
BroaderImpacts: Thisresearchcontributestotheadvancement
Thoughuserscanbeidentifiedbasedonseveralcues,includinghead
ofeyetrackingprivacymechanisms,specificallythosethatmustbe
movements, body movements [50] and gestures [49], our focus is
appliedtosample-leveldatainreal-time. Thesemechanismsprotect
identificationbasedoneyemovements.Irispatternsareawellknown
usersagainstdetection,especiallypopulationsthatcouldbevulnerable
biometric identifier [52], and David-John et al. examined user re-
iftheyareidentified. Ourworkhighlightsanecessaryshiftinfocus
identificationusingirisimagesandpresentedsolutionstomitigatethis
forthevirtualrealityresearchcommunityfromdata-drivennotionsof
risk[29,30].NotethattheMetaQuestProheadsetsusedinthisstudy
utilitytoauser-centricdesign[48]. Weadditionallyhighlightthata
donotpassoneyeimagesorrawdatatotheapplications.Inaddition
calculatedre-identificationrateisonlythefirststep;insituationswhere
to hand-crafted features derived from gaze streams [22,32,42,64],
formalprivacyguaranteescannotbereached,wemustconsiderreal-
therearenowdeep-learningmethodstoclassifyusersbasedonshort
worldthreatscenariosinordertoproactivelyprotectagainstadversaries.
windowsofeyemovementdata[28,40,41,45,57].EyeKnowYouToo
Inaddition,wemakeourcollecteddatasetscontainingeyetrackingdata
ininteractiveVRscenesavailableathttps://doi.org/10.5281/ (EKYT)iscurrentlythetopperformingeyemovementidentification
zenodo.10475455. model,reportingaccuraciesashighas91.38%on1000Hzdata[41].
Physicalandbehavioralattributessuchaspersonality[10],age[82]
orgender[61]havebeeninferredfromeyemovements.Someresearch
2 RELATEDWORK leverageseyemovementstoaidinmedicaldiagnosessuchasAutism
orAlzheimer’s[71,74,75]. Whilethereareappropriateusecasesto
Eye tracking is becoming a prominent feature of VR experiences.
learnthisinformation, userscannotconsciouslyhidetheattributes
ResearchoneyetrackedVRsystemsbeganmorethantwodecades
embeddedwithineyetrackingstreams.Theopportunityhereisdevelop
ago [17,72]. In recent years, many commercial VR head-mounted
methodstoblockthesefeaturesfrombeingextractedwithoutusers’
displays(HMDs)havereleasedwithembeddedeyetrackers(Magic
consentbymaliciousentitieswhoacquireeyetrackingdata.
Leap1[3]in2018,ViveProEye[7]in2019,HoloLens2[2]in2019,
ViveFocus3[6]in2021,MagicLeap2[4]in2022,andMetaQuest Thethreatofeyemovementre-identificationislargerforsmallsets
Pro[5]in2023. TheAppleVisionPro[1]issettoreleaseinearly ofusers[20].Thismaybeaparticularconcernformarginalizedusers
2024).Thesehardwareadvancementshavecreatedasurgeininterest whofacedisproportionateharmwhenprivacyiscompromised[63].
attheintersectionbetweeneyetrackingandVR.
2.3 GazeDataPrivacy
2.1 ApplicationsofEyetrackingdatainVR Privacymechanismsaremainlyappliedinthreewaystotheeyetrack-
ingpipeline. Aggregate-levelmechanismsprotectfulldatasetswith
Eyetrackingenablesmanyinteractionsinvirtualscenes.Theseinclude
operations that average across multiple users’ data [11,13,37,70].
usinggazetodirectlyinteractwithvirtualobjects,improvingsocial
Feature-levelmechanismsprotectusersbyconvertingrawgazesignals
VRinteractions,enablingfoveatedrenderingoptimizations,andgaze
tofeaturesandapplyingprivacy[11–13,70].Sample-levelmechanisms
analysisasaresearchtool.
operateontheactualdatastreams,perturbinggazedirectionatevery
Gaze-basedinteraction: Eyetrackingmovementsallowusersto frame[14,35].InVR,wearemainlyinterestedinsample-levelmecha-
interactwithvirtualscenes,eitherontheirownorpairedwithother nisms[66],whichcouldbeappliedsecurelybytheVRplatformbefore
controlmodes[19,51]. Gazedirectioncanaimacursoralongwith eye tracking data is made available to third party applications [14].
buttonpressestoselectobjects[23,58],orgazefixationscanbeused Withprivacymechanismsinplace,userscanexperiencenovelinterac-
forselection[9,23]. Forexample, inaVRapplicationinteractable tionsandoptimizationsonlypossiblewithsample-levelgazestreams
objectsmayglowwhenlookedat,toindicatethattheyaredynamic. withoutriskinginformationleakage.SeeTable1foracollectionofeye
Thenbyfixatingwhilepressingabutton,userscanselecttheseobjects1.
trackingprivacywork.
TheupcomingAppleVisionProwillsupportgaze-controlledinterfaces
pairedwithpinchinggestures[1].Gaze-basedinteractionsindesktop 2A list of VR games which incorporate eye tracking: https:
//www.psfanatic.com/here-are-all-the-psvr2-games-that-use-
1https://www.uploadvr.com/polyarc-moss-psvr-2/ eye-tracking-in-cool-ways/
2ToappearinIEEETransactionsonVisualizationandComputerGraphics.
Application DataDomain DataFormat Mechanism IDAccuracy Data-centricUtility User-centricUtility
(Kaleido)Spatialnoise
Sample-level 28%to6% Activityclassification -
withadaptivesampling[13]
Sample-level Gaussiannoise[14] 85%to30% DwelltimeRMSE -
Sample-level Temporaldownsampling[14] 85%to79% DwelltimeRMSE -
ConstrainedVR
Sample-level Spatialdownsampling[14] 85%to48% DwelltimeRMSE -
Gaze-based Sample-level Gaussiannoise[14] 33%to9% KL-divergenceofsaliencymaps -
analytics Sample-level Temporaldownsampling[14] 9%to7% KL-divergenceofsaliencymaps -
Sample-level Spatialdownsampling[14] 47%to29% KL-divergenceofsaliencymaps -
Aggregate- Difference-andchunk-based Documentclassification;
100%to28% -
level Fourierperturbation[11] genderclassification
Conventional
Aggregate- Exponentialmechanism Documentclassification;
eyetracking 100%to∼10% -
level appliedtofeatures[70] genderclassification
Aggregate-
k-same-synth[13] 28%to7.5% Activityclassification -
level
Aggregate- Event-synth-
28%to14.2% Activityclassification -
level plausibledeniablity[13]
Webcam (Kaleido)Spatialnoise scanpathsimilarity; Gameenjoyment;
Gaze-based Sample-level ∼84%to∼8%
eyetracking withadaptivesampling[35] latencytrade-off taskperformance
interaction
Subjectiveusability;
InteractiveVR Sample-level Ours 67.3%to14.1% Areaofinterestretention
taskperformance
Table1:Collectionofeyetrackingprivacyworkthatsuccessfullyprotectedagainstre-identificationwhileretainingoneormoremeasure(s)ofutility.
Real-timeprivacyoperationswillbecriticaltoensureprivacyduring algorithmsperformininteractiveVR?
onlineeyetrackinginteractions[9,58]andtoenableoptimizations[44], • Whatreal-timeprivacymechanismsareeffectiveatprotecting
but have yet to be explored in real-time VR settings. The goal of againstre-identificationininteractiveVRtasks?
privatizationistoprotectsensitiveattributeswhilekeepingthedata
We present an updated evaluation of the risk of identification in
usablewithrespecttoagiventask. Existingresearchprimarilymea-
VR.PriorworkonlyconsideredidentificationriskonconstrainedVR
suresdata-drivenutilityviapost-processingtasks,suchasgaze-based
setupsusingmodelstrainedonhand-craftedfeatures[14]. Wefirst
analytics[11,12,37]orrenderingoptimization[15].However,theim-
constructadynamicVRgamerepresentativeofinteractiveVR.Wethen
pactofprivacymechanismsontheuser’sperformanceandsubjective
presentananalysisofthecurrentstateoftheartarchitecturetrained
experienceininteractiveVRhasnotbeenconsideredpriortothiswork.
bothon conventionaleye trackingdata andVRdata, evaluating on
conventionaleyetrackingdata(GazeBase[24]),constrainedVRdata
3 RE-IDENTIFICATIONININTERACTIVEVR (GazeBaseVR[39]),andinteractiveVRdata(ourdataset). Wethen
Webeginbyestablishingtheriskofre-identificationininteractiveVR discussourresults,givinginsightstothecurrentriskofidentificationin
andidentifyingviableprivacymechanisms. Wecollectadatasetof consumerVRandtherelationshipbetweenre-identificationpotential
eyetracking-enabledinteractiveVRtaskstoserveasanevaluation andtheamountofdatamadeavailable.Usingthesamedataset,wethen
testbed.Wethenquantifythere-identificationriskonourdatasetusing evaluatemultipleprivacymechanismsthatcanbeappliedtoprotecteye
thestateoftheartarchitectureanddefineandevaluatemultipleprivacy trackingdatainVR.Weevaluatethesemechanismsacrossincreasing
mechanismsonourdataset. intensitiestoderivewellsaturatedprivacycurves.
Onconventionaleyetrackersathighfrequencies,userscanbeiden-
tifiedatveryhighaccuracies(91.38%identificationrate,3.66%equal 3.1 DataCollectionMethodology
errorrate)[41].InVRsettings,itislessclearhowreliablyuserscanbe Wedescribetheprotocolforourcollecteddatasetwhichservesasa
identified,duetolessprecisesensorsandextraneoususermovements. testbedtoevaluateidentificationininteractiveVR.
Anevaluationof360°VRimageandvideodatasetsusingaprioriden- Participants: Survey participants were recruited under IRB ap-
tification method [22] yielded identification rates ranging from 9% provedprotocolviaseveralcommunicationchannelsincludingword
to85%[14]. Thesameanalysisalsoevaluatedaninteractivedataset ofmouthandelectronicmailinglistadvertisements(N=26;57.69%
whereusersviewedasceneofmovinganimals[26],yieldingonlya male,42.31%female).Nomonetarycompensationwasprovided,but
3%identificationrate. Thelevelofinteractivityandamountofuser someparticipantsreceivedextracreditforundergraduatecourses.Eligi-
movementinVRsetupscouldnegativelycorrelatewiththepotential bleparticipantsrequirednormalorcorrected-to-normalvisionwithout
tobeidentifiedinVR[73]. Inthispaper, wepresentanup-to-date theuseofeyeglasses.Theracial-ethnicdistributionis61.54%White,
evaluationofre-identificationriskininteractiveVRtasksusingthe 19.23%IndianAsian,15.38%BlackorAfricanAmerican,7.69%East-
state-of-the-artidentificationmodel. ernAsian,and7.69%Hispanic/Latino;11.54%ofparticipantsreport
Forthisanalysis,wedistinguisheyetrackingdatasourcesintothree twoormoreraces.34.62%ofparticipantswereage18-20,50%21-29,
categories.Conventionaleyetrackingutilizeshighqualitystaticsensors 11.54%30-39,and3.85%50-59.88.46%ofparticipantsreportedsome
at1000Hzorgreater[24],andproduceshighlyidentifiabledata[41]. levelofexperiencewithVR,and30.77%reportedsomeexperience
EyemovementscollectedinVRcanbeseparatedintotwocategories: withusingeyetrackingasacontrolmode.
InteractiveVRispresentedinanaturalway.Usersdirectlyinteractwith Procedure: Participantswereinstructedtoactasemployeesina
dynamicobjectsinthevirtualscene,anddifferentusersexperience sandwichshop,andweretaskedwithassemblingasmanysandwiches
thesceneattheirownrate.Thisisreflectiveofconsumerapplications, aspossibleina90secondtimeframe. Platesofstackedingredients
suchasVRgamesordynamictrainingscenarios.Ontheotherhand, wereorganizedonthesandwichassemblingcounteroneachside.In
constrainedVRisrepresentativeofexistingexperimentalsetups.User thecenterofthecounter,participantswouldassembletheirsandwiches
movementsarelimited,suchassittinginachair[69]orplacingthe onanemptyplate(SeeFigure1a).Afterasandwichwascompleted,a
headonachinrest[39],andthetasksarestandardizedsuchthatall smallanimationwouldplayandtheplatewouldbecleared,allowing
usersexperiencethesamestimuliatthesamerates.Inthissection,we participantstobeginthenextsandwich.Adigitaltimercouldbeseen
answerthefollowingresearchquestions: whichdisplayedtheamountoftimeremaining.
• Howdocurrentstateofthearteyemovementre-identification Beforebeginningthemaintask,participantswereencouragedto
3practice picking up and assembling ingredients. In the experiment, Algorithm1Linearlyweightedaveragesmoothing
participantsdidnotusecontrollers;instead,grabbingwasdrivenby
B←sizeofwindow
handtrackingtechnologytoprovideamoreimmersiveexperience[36]. window←Queue() ▷NotethatthisQueuepopsatthe0thindex
Participantsunderwent4trialsofthesametaskandwereallowedtime
D←0
torestbetweentrials.
fori←1toBdo ▷Initializingthewindow
Asparticipantsperformedthetasks,gazedatawascollectedpas- window.add([0,0])
sivelytoevaluatethepotentialofre-identificationattacksandtostore D←D+i
areaofinterest(AOI)data.Eachingredientplate,theassemblyplate,
endfor
andthetimerwereallAOIregionswithfully-coveringboundingboxes whileapplicationisrunningdo
beingusedforAOIcollisiondetection. X←currentgazevector
Validation: DatawascollectedusingtheMetaQuestPro[5](1920 window.pop()
x1800pixelspereye,72Hzrefreshrate).Beforetheexperiment,each window.add(X)
participantunderwenttheheadset’seyetrackingcalibrationprocedure. X′=(0,0)
Participantsgazeddirectlyatsphereswhichappearedatrandompoints fori←1toBdo
onthescreenandgraduallyshrankuntilnolongervisible.Tovalidate X′[0]←X′[0]+window[i][0]∗i
the accuracy of collected gaze data, participants performed an eye X′[1]←X′[1]+window[i][1]∗i
trackingvalidationtask. Participantsfaceda3×3checkerboardof endfor
redtargetssituated2metersawayspanninga38.58°anglevertically X′←X′/D
andhorizontally. Participantswereinstructedtogazedirectlyatthe endwhile
active target, which would become green. The active target cycled
uniformly;eachtargetwasactivefor2secondstotal,withnodowntime
untilthenextdotbecameactive.Wereportaspatialaccuracyerrorof
µ=2.64°,σ=1.24.Thisprotocoliscomparablewithrecentanalysis identifiablefeatureswithoutdisplacingindividualsamplesinajarring
oftheQuestPro[77]. wayastheabovemechanismscan. Becauseofthis,wehypothesize
thatuserswillbeacceptingofsmoothing;theycanconsciouslycorrect
3.2 PrivacyMechanisms forthegazestream’sbehaviorbyfixatingatanobjectsforasecond
longer,forexample.
CollectedgazestreamsoverafullVRsessioncanberepresentedasa
Tooperateinreal-time,wedefinethecurrentgazevectorasalinearly
timeseriesofgazeanglesinsphericalcoordinatesθ,ψandtheircorre-
weightedaverageofBprecedingsamples.Precedingsamplesarestored
spondingtimestampst:X={(θ0,ψ0,t 0),(θ1,ψ1,t 1),···,(θn,ψn,tn)}.
inaslidingwindowthatisupdatedeveryframe.Thesmoothedvalueis
Thegazeanglesarelocalizedrelativetotherecordedpositionofthe
aweightedaverageoftheBvaluesinthewindow,witheachsample
headset,i.e.headpose,thusareconstrainedroughlytothehumanfield
weighedbyitsindexinthebuffer.
ofview.Asourprivacymechanismsareimplementedinreal-time,the
operationsareapplieddirectlyontheframewhichthegazeissampled.
Weimplementthreeprivacyprotectionmechanismsproposedby X′=
X n−B+2(X n+1−B)+3(X n+2−B)+···+B(Xn)
David-Johnetal.[14]: additiveGaussiannoise,temporaldownsam-
n ∑B i(i)
pling,andspatialdownsampling.Wealsointroducelinearlyweighted
Larger window sizes equal a more intense smoothing operation,
average smoothing as a novel mechanism. These mechanisms are
whichismoresuccessfulatremovingidentifyingfeatures,butintro-
designed to be feasible in real-time settings, suitable for streamed
ducesalargertemporaldelaybetweentheinputandoutputgazevectors.
sample-leveleyetrackingdatainVRapplications.
ImplementationdetailsareshowninAlgorithm1.
GaussianNoise:Gaussiannoiseissampledindependentlyforthe
θ,ψgazeanglesforeveryframe.Weusethestandarddeviationofthe 3.3 EvaluationMethodology
noisesampleσ tocontroltheprivacy-utilitytrade-offprovidedbythe
Nmet (h 0o ,σd, )y ,ψie nld +in yg ∼th Nefo (0ll ,o σw )i ,n tg ).per-frameoperation: X n′ =(θn+x∼ W coe nve ev na tl iu oa nt ae lt eh ye eid tre an ct kifi inc gat dio an tap (o Gte an zt ei Bal aso ef [E 2K 4]Y )T anm do cd oe nl ss trt ara inin ee dd Vo Rn
data(GazeBaseVR[39]). Bothmodelsaretrainedat125Hztobest
Temporal Downsampling: Temporal downsampling effectively
matchthefrequencyofourcollecteddata.Wefollowthetrainingand
lowersthesamplingrateofastreamofdatabyafactorK.Dataentries
testingmethodologyofLohretal.3[41],andpresenttherank-1identity
withindiceswhereKisnotafactorareremovedfromthedatastream,
retrievalrateaveragedacrossalltasksinthedataset.
yieldingastreamwithN/Ktotalentriesafterdownsampling.
To our knowledge, there is no existing interactive VR dataset at
A real-time application may expect a gaze vector at all frames.
the scale required to train the EKYT model effectively. Therefore,
Thus,wepreservetheoriginaldataformatbysimplycopyingthegaze
we assess the effectiveness of training on constrained VR data and
directionsfromthepriortimesteponframesthatwouldtraditionally
evaluatingoninteractiveVRdata,versususingamodelsolelytrained
beremoved.GivenadownsamplingfactorK,
onconventionaleyetrackingdata.
(cid:26) Toevaluatetheidentificationpotentialonourcollecteddata, we
X n′= (θ( ′θn, ,ψ ψn ′,t)
,t)
i of thn e% rwK is=
e
0 definethefollowingprotocol. First,embeddingsaregeneratedfrom
n−1 n−1 the raw eye movement data. Each 90-second trial of the game is
separated into 5-second segments sliding over a 1-second interval.
SpatialDownsampling:Spatialdownsamplinglowersthespatial
These5-secondsegmentsarelinearlyinterpolatedtoaconstant125Hz
resolutionofthegazedata,e.g.,multiplenearbyfull-resolutionpoints
andprocessedbytheEKYTmodeltocreate512Dfeatureembeddings
wouldbemappedtoasingledown-sampledpoint,loweringthespatial
Emb,whicharestoredalongwithlabelsLfortheindividualsasrecords.
fidelity.Toapplyspatialdownsamplingtocontinuousgazeangles,we
Recordsareseparatedintofoldsaccordingtothetrialsofthegame.
firstmaptheanglesintoasetofdiscretepointslargeenoughtopreserve
So,allrecordscorrespondingtothefirsttrialexistinthefirstfold,and
dataquality,choosing2160pointstocovera180°fieldofview. We
soon. Wethencomparepair-wiseeachfoldasadistinctqueryand
achieve spatial downsampling by remapping the gaze angles into a
referenceset.Foreachindividual,allqueryrecordsarecomparedwith
smallerdomainequaltothereferencedomaindividedbyL.Wemap
therecordsintheembeddingset.So,forNindividualsandMrecords
theθ,ψ anglesintothediscretedomainofM=2160/L,providinga
stepsizeofδ = 180°. Thisyieldsthefollowingper-frameoperation:
perindividuals,Queryn={Emb n,1,Emb n,2,...Embn,m}andreference
X′=(⌊θ/δ⌋·δ,⌊ψM
/δ⌋·δ,t).
Ref ={Emˆbn,m :∀n∈N,∀m∈M}. The record from the query is
n
Smoothing:Weintroduceasmoothingoperationasanovelprivacy 3https://dataverse.tdl.org/dataset.xhtml?persistentId=
protection mechanism. Smoothing streamed gaze data can remove doi:10.18738/T8/61ZGZN
4ToappearinIEEETransactionsonVisualizationandComputerGraphics.
Duration TestData TrainData
Conventional Constrained         
EyeTracking VR
ConventionalEyeTracking 66.09% 18.04%
5s ConstrainedVR 27.04% 33.87%
        
InteractiveVR 22.44% 26.92%
ConventionalEyeTracking 81.42% 32.36%
10s ConstrainedVR 36.00% 45.14%
InteractiveVR 19.23% 22.76%
       
ConventionalEyeTracking 90.00% 54.58%
30s ConstrainedVR 48.57% 55.42%
InteractiveVR 40.06% 41.35%
ConventionalEyeTracking 90.78% 58.57%
        
60s ConstrainedVR 49.98% 55.09%  * D X V V L D Q  Q R L V H
InteractiveVR 56.73% 54.81%  6 S D W L D O  G R Z Q V D P S O L Q J
 7 H P S R U D O  G R Z Q V D P S O L Q J
90s InteractiveVR 68.27% 67.31%
 6 P R R W K L Q J
      
Table 2: Average re-identification accuracy using the EKYT architec-
ture[41]trainedandevaluatedondifferentdatatypes. Allmodelsare Fig. 2: Identification accuracy (solid lines) and AOI retention (dotted
trainedat125Hz. lines)ofprivacymechanismsappliedatvariousstrengths.Xaxeshave
beenscaledtoprovideroughlythesameprivacyfalloffsothatutilitycan
bedirectlycompared. Verticallinesindicatethechosenlowandhigh
matchedtotheclosestreferenceembeddingusingcosinesimilarityas strengthsofeachmechanism.
adistancemetricandtheassociatedlabelisstored.Foranindividualn,
thepredictedlabelLp,nis:
49.98%@60sonconstrainedVRand22.44%@5sand56.73%@60son
(cid:32) (cid:33) interactiveVRdata.
M
Lp,n=argmax ∑Lz On the other hand, the constrained VR model favors VR data at
alowerduration(18.04%@5sforconventional,33.87%@5sforcon-
L m
where
z=argmin(cid:32) ∑N ∑M(cid:18)
1−
Queryn,m · Ref n′,m′ (cid:19)(cid:33) (1) s et qr ua ain le od nV allR d, o2 m6 a.9 in2 s% a@ th5 igs hf eo rr di un rt ae tr ia oc nti (v 5e 8.V 57R %) @bu 6t 0p se fr of ro cr om ns ver no tu iog nh aly l,
m n′ m′ ||Queryn,m||||Ref n′,m′|| 55.09%@60sforconstrainedVR,54.81%@60sforinteractiveVR).
WefindperformanceoninteractiveVRdatatoberoughlyequal
Thereturnedlabelsareaggregatedbetweeneachqueryembedding betweenthetwomodels.Whiletheconventionaleyetrackingmodelis
Queryn,mandallembeddingsinthereferencesettodetermineafinal trainedonalargerdataset,theconstrainedVRmodelhascloserspatial
predictionLp,n.IfLp,nequalsthetruelabelLn,theindividualhasbeen precisionandmoresimilarsetuptoourdata.Fortherestofthispaper,
successfullyidentified. we use the constrained VR EKYT model to compute identification
Thereportedmetricsareanaverageoverallindividualsandallpair- accuracies.
wisecombinationsofdistincttrials,readableasanaverageidentification
accuracyoverthefulldataset,orthelikelihoodofanyindividualbeing 3.4.2 PrivacyMechanismPerformance
successfullyidentified. Wecomputeidentificationaccuraciesforeachmechanismatmultiple
Whenevaluatingprivacymechanisms,beforeprocessingthesetof strengthstodefineaprivacycurveandmeasureagainstAOIF1scores
trialswhichmakeupthequeryset,themechanismisappliedatagiven to estimate the anticipated utility trade-off. We measure Gaussian
strength.Theprivatizedresultsarethenprocessedandcomparedtothe noiseuptoσ =20°,spatialdownsamplinguptoL=256,temporal
referenceset.Thisrepresentsthefollowingthreatscenario: downsampling up to K =30, and smoothing up to B=300. The
Anadversaryacquiresaprivatizeddatarecordwithoutknowing privacy/utilitytrade-offcanbeseeninFigure2.
theidentity,thenqueriesagainstadatasetofrecordswhichhave Ofthepreviouslyproposedmechanisms,additiveGaussiannoiseand
knownidentitiesattached. spatialdownsamplingareeffectiveatprovidingprivacy.Theproposed
Toprovideaninitialdata-centricrepresentationofutility,wemea- smoothingmechanismalsoprovidesprivacy,albeitatahighertrade-off
sureAOIintersectionsbeforeandafterprivatization.Wecalculatethe inAOIretention. Wehavenotfoundtemporaldownsamplingtobe
multi-classweightedprecisionandrecallandoverallF1scorewhich aneffectiveprivacymechanism.ItislikelythatbyretainingN/Kreal
canbeinterpretedasthemechanism’sabilitytoretainoriginalAOI samples,themodelcanstillassociaterealsamplesanddistinguishusers
behaviorandafterprivatization. untilKreachesapointfarbeyondusableutility.
Weintroducedsmoothingasanovelmechanismtoprotectusereye
3.4 Results movements.Onourdata,smoothingshowspotentialforprivacypro-
tectionwithsimilarlevelsofprivacyattainedasGaussiannoiseand
WeorganizeourresultsaccordingtotheinitialanalysisofEKYTmod-
spatialdownsampling.However,AOIretentionislowestforsmoothing
elsonacrossconventionalandVRdatadomainsandtheperformance
onthetesteddataset,indicatingthatanapplicationreceivingsmoothed
ofprivacymechanismsonourcollecteddataset.
datawouldhavelessreliableaccuracyper-samplethanothermecha-
3.4.1 Re-identificationCapabilityofEKYTModels nisms.However,aswewillseeinSection4,lowerAOIretentionisnot
reflectiveofsmoothing’simpacttouserexperience.
OurfindingsarereportedinTable2.Wereporttheaccuraciesbetween
the2trainingand3testsetups.Weadditionallyreportresultsvarying
thedurationofeachdatarecord.Theseresultsarecalculatedusingthe
4 EVALUATINGUSER-CENTRICUTILITY
explainedmethodologybutfirstlimitingtheamountofdatatothefirst Themajorityofprivacyliteraturesurroundingeyetrackingmovements
Nsecondsperdatarecord. have considered privacy as a post-process operation. However, in
Wefindthatthemodeltrainedonconventionaleyetrackingdata thecontextofinteractiveVR,privacymustbeprovidedbeforebeing
performswellwhenevaluatedinthesamedomain,reachingidentifica- passedtotheapplication; theusersubsequentlyseestheimpactsof
tionaccuraciesof66.09%and90.78%on5secondand60seconddata privatization. Itisimportanttoconsidertheuserandthetrade-offin
records,respectively.However,theconventionalmodelperformsmuch user-centricutility,ratherthansolelyrelyingondata-centricmetrics.
less effectively in when applied to VR, achieving 27.04%@5s and Inthissection,weanswerthefollowingresearchquestion:
5
 \ F D U X F F D  Q R L W D F L I L W Q H G L  H 5  $ U H D  R I  L Q W H U H V W  5 H W H Q W L R QFig.3:CollectedmetricsoftheimmersiveVRgamewithgazecontrols.Foridentificationaccuracy(firstcolumn),lowervaluesindicatemoreprivacy.
Forallutilitymetrics,ahigherscoreindicateshigherutility. Eachsubplotillustratesnoprivacymechanismcomparedagainstthelowandhigh
strengthsofeachmechanism.Wilcoxonsigned-rankt√estsignificanceforutilitymetrics(p<0.05)aredenotedwithcolor-codedasterisks.Vertical
linesindicateStandardErroroftheMean(SEM)=σ/ N.
• Whatistheimpacttouser-centricutilitymetricswheneyetrack- ofthetrialwecanderiveusefulperformancemetricsfromparticipants
ingprivacymechanismsareappliedliveininteractiveVR? regardlessofskilllevel.Foreachexperimentalcondition,participants
Weinvestigateuser-centricutilitythroughaninteractiveVRexperi- wouldundergotwotrialsofthegamesequentially, followedbythe
encewhichuseseyegazeastheprimarycontrolmode.Beforebeing Post-Study System Usability System Usefulness subscale (PSSUQ
processedbytheapplication,theeyemovementdataisprocessedbythe SYSUSE)[34].
3viableprivacymechanisms:Gaussiannoise,spatialdownsampling, We adopted a within-subjects design; all participants underwent
andsmoothing. everycondition.Privacymechanismconditionswereeithernoprivacy
mechanismappliedor{Gaussiannoise,spatialdownsampling,smooth-
4.1 DataCollectionMethodology
ing}at{low,high}strength,presentedinrandomorder.Theprivacy
Wedescribetheprotocolforourcollecteddatasetinwhichprivacy mechanismstrengthschosenwerederivedfromthere-identification
mechanismswereappliedinreal-time,allowingustomeasureuser- accuraciesfoundininitialanalysisthedatapresentedinSection3.4.24.
centricutilityafterprivatizationininteractiveVR. For Gaussian noise, low σ =1° and high σ =3°. For spatial, low
Participants: Survey participants were recruited under IRB ap- L=48andhighL=144.Forsmoothing,lowB=50andhighB=150.
provedprotocolviaseveralcommunicationchannelsincludingwordof Weimplementtwocontrolmodesforfacilitatingtheselectionof
mouthandelectronicmailinglistadvertisements(N=18;77.78%male, targets. Thefirstcontrolmodeisgaze-only;ifthegazevectorfrom
22.22%female). Eligibleparticipantsrequirednormalorcorrected- theparticipant’slefteyewasconsistentlywithinatarget’sboundsfor
to-normal vision without the use of eye glasses. The racial-ethnic 500ms,thetargetwasdestroyed.Theothercontrolmodeisgaze-plus-
distribution is 33.33% White, 22.22% Indian Asian, 11.11% Black gesture;participants’gazevectorsindicatedtheselectionoftargets.If,
orAfricanAmerican,16.67%Hispanic/Latino,5.56%EasternAsian, foragivenframe,theplayergazevectorintersectedwithatarget’sAOI
5.56%CentralAsian,and5.56%MiddleEastern. 27.78%ofpartic- andtheparticipantperformedapinchgesturewiththeirlefthand,the
ipants were age 18-20 and 66.67% 21-29. 88.89% of participants selectedtargetwasdestroyed.
reportedsomelevelofexperiencewithVR,and16.67%reportedsome
Participants underwent all privacy mechanism conditions in ran-
experiencewithusingeyetrackingasacontrolmode.Thesmoothing
domorderwithonecontrolmode,thenallprivacyconditionsagainin
mechanismwasincorporatedintothestudyafter10participantshad
randomorderwiththeremainingcontrolmode.Tomitigateanorder-
undergoneaversionwithonlyGaussiannoiseandspatialdownsam-
effectsbias, theorderofcontrolmodewascounterbalancedamong
pling,soforallmeasuresofsmoothing,thereareN=8participants
participants.
represented.Thisdetailisaddressedinourresults.
Procedure:Participantsplayedafirstpersonshootergamewhere
Validation:DatawascollectedusingtheMetaQuestPro[5].Be-
foreundergoingtheexperiment,eachparticipantunderwentthesame
theyremainedinastaticpositionanddefeatedenemiesthatperiodically
validationprotocolasinSection3.1,butthistimeunderwent3trials
spawnedandtravelledtowardstheplayer.Twotypesofentitieswould
alternativelyspawninrandompositionsandmovetowardstheplayer.
ratherthan1(spatialaccuracyerrorµ=2.78,σ=1.45).Participants
alsoperformedgesturevalidation.Againfacinga3×3boardoftargets,
Friendlyentitiesservedasvisualdistractors[33]andenemyentities
participantswereinstructedtoplaceacursoratthecenterofthefield
servedastargets;participantswereinstructedtodestroytargetsbefore
ofviewoverthetargetandmakeapinchinggesturetoconfirmtheir
theycouldreachtheplayer. Entitieswouldspawnrandomlyfrom7
uniformlyspacedpointsona90°arcspaced10metersfromtheplayer
placement(errorµ=2.94,σ=1.68).Whilegestureswerenotexplic-
itlycalibratedperparticipant,thisservedasaprimerforparticipantsso
position. Participantscouldseeatranslucentgazecursorindicating
thattheywerefamiliarwiththeheadset’sgesturerecognitionbefore
theircurrentgazedirection.Intrialswithprivacymechanismsapplied,
undergoingthemaintasks.
thecursorillustratedtheeffectivegazedirectionafterprivatization.See
Figure1bforaparticipant’stypicalview.
Eachtrialofthegamelastedfor∼30seconds.30entities(15targets 4UsingpreliminaryresultsfromSection3.4.2,theparameterswhichinitially
and15distractors)spawned,increasinginspeedfrom1m/sto5m/s decreasedre-identificationaccuracybelow40%and20%werechosenforlow
overthedurationofthetrial.Byincreasingdifficultyoverthecourse andhighstrengths.
6ToappearinIEEETransactionsonVisualizationandComputerGraphics.
  2 Y H U D O O   ,  D P  V D W L V I L H G  Z L W K  K R Z   ,  Z D V  D E O H  W R  F R P S O H W H  W K H  W D V N V   ,  I H O W  F R P I R U W D E O H
 H D V \  L W  L V  W R  X V H  W K L V  V \ V W H P     , W  Z D V  V L P S O H  W R  X V H  W K L V  V \ V W H P    D Q G  V F H Q D U L R V  T X L F N O \  X V L Q J  W K L V  V \ V W H P    X V L Q J  W K L V  V \ V W H P  
       
       
       
       
       
       
       
 P H F 1  K R  D Q L V P  V W /  U H R  Q Z  J W K  V +  W U H L J  Q K  J W K  P H F 1  K R  D Q L V P  V W /  U H R  Q Z  J W K  V +  W U H L J  Q K  J W K  P H F 1  K R  D Q L V P  V W /  U H R  Q Z  J W K  V +  W U H L J  Q K  J W K  P H F 1  K R  D Q L V P  V W /  U H R  Q Z  J W K  V +  W U H L J  Q K  J W K
  ,  E H O L H Y H  ,  F R X O G  E H F R P H  S U R G X F W L Y H
  , W  Z D V  H D V \  W R  O H D U Q  W R  X V H  W K L V  V \ V W H P    T X L F N O \  X V L Q J  W K L V  V \ V W H P    $ Y H U D J H 
     
     
 * D ] H  Z L W K 
       * D ] H  R Q O \   J H V W X U H 
       1 R Q H  1 R Q H
 * D X V V L D Q  * D X V V L D Q
       6 S D W L D O  6 S D W L D O
       6 P R R W K L Q J  6 P R R W K L Q J
     
 P H F 1  K R  D Q L V P  V W /  U H R  Q Z  J W K  V +  W U H L J  Q K  J W K  P H F 1  K R  D Q L V P  V W /  U H R  Q Z  J W K  V +  W U H L J  Q K  J W K  P H F 1  K R  D Q L V P  V W /  U H R  Q Z  J W K  V +  W U H L J  Q K  J W K
Fig.4:BreakdownofPSSUQSYSUSEscores[34]acrossconditionsbyindividualquestion.VerticallinesindicateSEM.
4.2 EvaluationMethodology andGaussian(z=−3.03)andspatial(z=−2.98)aresignificantatthe
highstrength.Generally,theaveragepercentageoftargetsdestroyed
We analyze identification accuracies alongside multiple notions of
remainshigh,thoughtheaveragedistancedecreases.Thisindicatesthat
user-centricutilitytoclearlymeasurewhethertheadditionofprivacy
thetaskbecameslightlymoredifficultbutremainedtrivialtocomplete.
mechanismshaveanynegativeimpacttousers.Thesemetricsare:
Acrossbothtaskperformancemetrics,weseeGaussiannoiseutility
• %oftargetsdestroyed:Thisisasimplemeasureoftaskperfor-
decreaseatahighratecomparedtotheothermechanisms.
mance,conveyingonaveragehowmanytargetsweresuccessfully
Focusingonusability,weseenoticeabledifferencesinaverageper-
destroyedbeforereachingtheparticipant.
formance(illustratedinFigure4). Forgaze-onlycontrols,Gaussian
• Averagedistanceoftargetsdestroyed: Alsomeasuringtask
(z=−2.82) and spatial (z=−2.74) are significant at low strength
performance, this metric gives a better estimate of how easy/
andGaussian(z=−3.64)andspatial(z=−2.59)aresignificantat
challengingthetaskwasforusers.
highstrength. Forgaze-plus-gesturecontrols,Gaussian(z=−3.59)
• Usabilityscore:TheaveragePSSUQSYSUSEresponse,repre-
andspatial(z=−2.1)aresignificantonlyathighstrength.Gaussian
sentingusers’perceivedsatisfactionwiththegivencontrolmode
noise again impacts utility at a higher rate than other mechanisms.
andprivacymechanismcombination.
Interestingly,smoothingseemstoslightlyincreaseusabilitywhenap-
pliedatalowstrength.Therecouldbealowamountofnoisepresent
4.3 Results
intheeyetracker’srawdatastreamwhichsmoothingcorrects. Yet,
We present our results across identification accuracy and the task- thereisnotsufficientstatisticalevidencetoprovethisclaim.Forboth
specificnotionsofutilitydefinedabove. Notethatwhencomputing non-Gaussianmechanisms,overallusabilityremainshighevenafter
identificationaccuracy,wepair-wisecomparethefirstandsecondtrial applyingthehighstrengthvariantofthemechanisms.
ofagivenmechanismagainstthoseofnoprivacymechanismtoform Weconductedathree-wayANOVAontheparticipantswhichunder-
our query and reference setups. We test for statistical significance wentallprivacymechanisms(N=8)toexaminetheeffectofprivacy
using the Wilcoxon signed-rank test after collapsing the results of mechanism,strength,andtypeofcontrolmodeontheaveragePSSUQ
all game trials to a single data point per participant and condition, response. We find the main effects of mechanism and strength to
reportingvaluesof p<0.05assignificant. Wecompareagainstthe besignificant(p<0.01). Therearesignificantinteractionsbetween
non-privatizedtrialswhentestingsignificance.Resultsarevisualized mechanismandstrength(F(4,28)=7.3979,p=0.0003)andbetween
inFigure3. mechanismandcontrolmode(F(2,14)=4.2953,p=0.0351).These
Wefirstseealoweridentificationaccuracy(µ=48.61%)onthis findingsevidencethatthedifferentcontrolmodescouldbeaffectedby
datasetthanthedatasetofSection3.1.Thisistobeexpected,assession theapplicationofprivacymechanismsdisproportionately.
lengthsare∼30secondsratherthan90.Inthisnewexperimentalsetup,
Notethatbecausesmoothingwasimplementedmidwaythroughdata
thehighstrengthprivacymechanismsallprovideanoticeablelevelof collection,statisticaltestsofsmoothingconsiderN=8participants,
privacy. thus there is less statistical power than other conditions. However,
The percentage of targets destroyed and distance targets are de- acrossutilitymetrics,smoothingappearscomparabletospatialdown-
stroyedatfunctionasmeasurementsoftaskperformance. Forgaze- samplingacrossallcategorieswithcomparablevariance.
only controls, we see a decrease in performance across all privacy
mechanisms. Forthe%oftargetsdestroyed,Gaussian(z=−3.73)
5 ANTICIPATEDADVERSARIALTHREATS
andspatial(z=−3.01)aresignificantlylowerthanthebaselineathigh
strengths.Fortheaveragedistance,Gaussian(z=−2.94)andspatial Sofar, wehavepresentedananalysisoftheidentificationpotential
(z=−3.72)aresignificantatlowstrength,andGaussian(z=−3.72) ininteractiveVRandpresentedprivacysolutionswhichcanmitigate
andspatial(z=−3.1)aresignificantathighstrength.Itismoredifficult theriskofidentificationwhileretaininguser-centricutility.However,
fortheapplicationtomeasurecontinuousfixationswiththeperturbed this is only the first step. We must also consider the robustness of
data,soperformancedecreases.Interestingly,weseelessofaneffect any privacy solution, as a dedicated adversary will make efforts to
whenparticipantsusedgaze-plus-gesturecontrols.For%oftargetsde- counteractandnullifyanyprivacy-preservingoperation.
stroyed,spatial(z=−2.57)issignificantatlowstrength,andGaussian Theeyetrackingcommunityhasexploredformalprivacyguarantees
(z=−2.98)andspatial(z=−3.06)aresignificantathighstrength. suchasdifferentialprivacy(DP)[11,37,70],k-anonymityorplausible
Foraveragedistance,spatial(z=−2.63)issignificantatlowstrength deniability[12,13].However,astheprivacyguaranteeistiedtohigh
7levelfeaturesandappliedtofullcollectionsofusers,thesemethods AninsiderofaVRhardwarecompanypoststheconfidentialpri-
are not suitable for sample level eye tracking data being privatized vacy algorithm to an online forum. From there, any adversary
inrealtime. Kalεidohasdevelopedasample-levelmethodwithDP whoobtainsthealgorithmcanattempttoleveragethatknowledge
guarantees[35],buthasahighoverhead(8ms),and 15-20msoverall againstprivatizeddatarecordsobtainedfromthedevice.
latencyinVRcanintroducesicknessandnausea[8]. Thus,privacy
mechanismsproposedforlivegaze-basedinteractionsmustbeproac- 5.2 EvaluationMethodology
tivelyevaluatedagainstadversarialthreats.Inthissection,weanswer
Weillustratetheriskofeachdefinedthreatscenariowithtoyexample
thefollowingresearchquestion:
attacks, simulating an adversary with the corresponding amount of
• Aretheproposedprivacymechanismsrobustagainstmalicious knowledge.Theseattacksarenotoptimizedorexhaustive,butillustrate
adversaries? theadditionalrisksofdataleakagethathavenotbeenwidelyconsidered
Weaddresstherobustnessofourproposedmechanismsunderthree ineyemovementprivacyliterature.
realistic threat models in which adversaries have varying levels of WaveletDenoising:Intheblack-boxthreatscenario,anadversary
domaininformation. Wethendefineandevaluateanexampleattack canperformanuninformedfilteringattacktoattempttonullifythe
undereachthreatmodel. Forthisanalysis,weusethelargerdataset effectiveness of the privacy mechanism. Time series perturbations
definedinSection3.1andimplementprivacymechanismsattheirhigh thatareimplementedonindependentsamplesarepronetofiltering
strength. attacks,whichcanvastlyreduceuncertaintyifthepatterncanbefiltered
out[56].
5.1 ThreatModels Weillustratethisbyapplyingawaveletdenoisingfilter[16]over
Weexploremultiplethreatstoeyetrackingre-identificationthatweex- theprivatizeddatastream. Theimplementation5 assumesalevelof
pecttobecomeplausibleinthenextdecadeaseyetrackingtechnology noiseandestimatesσ automatically,requiringnoknowledgeofthe
andVRbecomemoremainstream. Ourthreatmodelsareorganized mechanismathand.
accordingtotheinformationorresourcesthattheadversaryhasaccess CNNDataRegression:Intheblack-boxwithexemplarsscenario,
to;asanadversarybecomesmoreinformedoftheprivacymechanism, theadversaryhasacquiredanumberofdatasampleswithandwithout
theybecomeincreasinglyabletocounteracttheprivacyefforts. We privatization.Datadrivenapproachescouldbeimplementedinanat-
conceptualizeanexamplescenarioandattackforeachthreatmodel. tempttoapproximatetheprivacymechanismortodirectlyapproximate
Inallcases,wemaketheassumptionthattheadversary’sgoalisto aninversefunction.
obtaintheidentityofanacquiredquerygazestream. Theremaybe Weillustratethisconceptwithasimpleconvolutionalneuralnetwork
sensitiveinformationconnectedtoeitherthequerygazestreamorexist- (CNN)whichtrainstoreconstructinputprivatizeddatastreamsback
ingdatasetrecords,andasuccessfulattackcanlinktheuser’sidentity totheoriginaldatastreams.Ourimplementationinputsandoutputs5
orquasi-identifier(s)tothesensitiveinformation. Thesesensitiveat- secondsofdata.Themodelconsistsof4[1DConvolution,1DBatch
tributescouldbeconcreterecords,suchashealthinformationorgroup normalization, Tanh]blocks. Foreach condition, we traina model
membership,orcouldbeimplicitknowledgeembeddedwithininthe on50%ofdatathenevaluateon50%,repeattheprocesswithreverse
actualgazestream(suchaspersonality[10],age[82]orgender[61]). train-testsplits,thenreporttheaveragedaccuracy.
Black-boxAccess: Inthisscenario,anadversaryhasacquireda MechanismAppliedtoReferenceData:Inthewhite-boxscenario,
privatizedgazestreambuthasnoknowledgeregardingthemechanism theadversaryknowstheimplementationdetailsathand. Obviously,
applied. The adversary can attempt to query the privatized record ifthemechanismisdeterministicitbecomespossibletoreconstruct
againstnon-privatizedrecordssourcedfromelsewhere,suchaspublic the original data by reversing the process. However, in stochastic
datasets. Beforequerying,itispossiblefortheadversarytoperform mechanismsalevelofuncertaintyremains.
afilteringoperationinanattempttorendertheprivacymechanism Weinvestigatethewhite-boxscenariobyleveragingtheadversary’s
ineffective[56]. inside knowledge to apply the same operation to the reference set.
Iftheadversarydoesnotknowthequeryidentity,butdoesknowthe
AmaliciousVRgamingapplication(theadversary)recordseye
identitiesofnon-privatizedreferencerecords,theadversarycouldapply
tracking data that has been securely privatized by a user’s VR
theprivacymechanism’salgorithmacrosstheboardforamoreequal
hardware.Byenablingthepostingofhighscorestosocialmedia,
comparison.
theadversarylearnstheuser’sidentity. Theadversarycanthen
queryagainstreleaseddatasetswithassociatedmedicaldiagnosis
5.3 Results
(autism, alzheimer’s, depression, etc.), attempting to verify the
user’smembershipinthedataset.Ifsuccessful,theadversaryhas Wereporttheresultsofourtoyexamplesforeachthreatscenarioin
aplatformtoperformfraudorblackmail. Table3.WefindthatGaussiannoiseisvulnerabletoattacksacrossall
Black-boxAccesswithExemplars:Similartotheabovescenario, threatscenarios.Spatialdownsamplingandsmoothingarenotvulnera-
theadversarydoesnothaveknowledgeabouttheimplementationof bletotheblack-boxscenario’sfilteringattack,butallmechanismsare
theappliedmechanism.However,theadversaryhasaccesstoalarge vulnerabletoadegreetoeachscenarioinwhichadversarieshaveaddi-
numberofprivatizedrecords,possiblypairedwithanumberofnon- tionalknowledge.However,thesemechanismssignificantlyincrease
privatizedrecords.Fromhere,theadversarycouldattempttoapproxi- theamountofknowledgeandeffortrequiredtosuccessfullyre-identify
matethemechanism,orperformregressionanalysistolearnaninverse users.Presumably,awhite-boxwithexemplarsthreatscenariowould
functionofthemechanism. haveaccesstoattacksthatareevenmoresuccessful.
Intheblack-boxwithexemplarsscenario,bothGaussianandsmooth-
AnadversaryhasanewVRheadsetwhichonlyreleasesprivatized
ingidentificationaccuraciesafterCNNregressionarehigherthanthe
gazedatastreamsandanoldermodelwhichreleasesrawgaze
original re-identification rate. It is possible that the CNN’s inverse
vectors.Theyrecruitanumberofuserstoperformthesametasks
approximationaccentuatedsomeimportantfeaturesfromtheoriginal
whilewearingbothheadsets.Whentheyhaveasufficientamount
datastream,potentiallymakingtheundonedatastreamsslightlymore
of data, theymodel a functionto invertthe privacymechanism,
identifiable.
increasingthechanceofre-identification.Fromthispointon,they
Smoothingismorevulnerablethanspatialintheblack-boxwith
canapplythatfunctiontootherrecordscollectedthroughthesame
exemplars scenario, being brought above the original identification
hardware.
accuracy. This can be attributed to our smoothing implementation
White-boxAccess:Inthisscenario,theadversaryknowstheexact
being a fully deterministic process; as a result, the original signal
implementationofthemechanismthathasbeenapplied. Thiscould
canbefullyreconstructedifthefirstrealdatavalueandexactbuffer
belearnedfromdataleaksofdesigndocumentsorcode[47],orby
guessing simpler mechanisms by observing a sufficient number of 5https://scikit-image.org/docs/stable/api/skimage.
samplesandapproximatingparameters. restoration.html#skimage.restoration.denoise_wavelet
8ToappearinIEEETransactionsonVisualizationandComputerGraphics.
ID Black-box
Mechanism Black-box White-box Amethodologyforfurtherimprovedmechanismscouldbetointro-
Accuracy withexemplars
ducetemporalperturbationsalongsidesample-levelperturbations.As
None 67.31% / / /
theoperationneedstobepossibleinreal-time,itisdifficulttointroduce
Gaussian 14.1% 63.14% 68.39% 64.74%
temporalinconsistencieswithoutsomeformofdelay.Potentialavenues
Spatial 21.79% 21.79% 61.47% 58.33%
Smoothing 14.1% 14.1% 69.49% 55.13% toexplorewouldbetoleveragecontextofobjectsfromthescene[18]
tomodulatedwelltimesanddurationsbetweenfixations,ortojointly
Table3:Identificationaccuraciesbeforeandafterperformingattackson performprivatizationandgazepredictiontooffsetanydelays.
privatizeddataacrossthreethreatscenarios. Thereisastrongcorrelationbetweentheabilitytobeidentifiedand
theamountofdataavailable.Anevaluationcouldbedoneonlongdata
sessions(say,30+minutescontinuously)tofurtherquantifythisrisk
atdurationsexpectedinVRapplications. Onemitigationwouldbe
sizeisknown. However,thereareanumberofsmalloptimizations
toapplyarandommechanismfromaselectionofviablemechanisms
whichcouldbemadetothesmoothingprocess,suchasnon-uniformly
every1or2minutes,makingthefullsessionunreliableforqueries.
initializingthebufferoraddingrandomvariancetotheimpactofeach
Itiscurrentlyunclearwhatpotentialimpactsourmechanismswould
weight.
imposeonotheruser-experienceenhancingresearchfocusedoneye
trackinginVR.Futureworkcouldexploreconceptssuchasspatialper-
6 DISCUSSION
ception[80],cybersickness[27,43],andmultisensoryperception[46]
Wefindthatthereissomeriskofre-identificationfromeyemovements andthelevelofimpactthateyetrackingprivacymechanismswould
collectedinVRapplications.On125Hzdataandusingmodelstrained haveonthesemetrics.
and/orevaluatedonVRdata,wereportaccuraciesofupto33.87%@5s,
58.57%@60s,and68.27%@90s. Ouruppermeasureof90seconds 7 CONCLUSION
approachesreliableidentification; yet,commercialVRapplications We analyzed the re-identification risk associated with eye tracking-
such as games or virtual training scenarios can have much longer enabled interactive VR applications and evaluated multiple privacy
sessions.Countermeasuresshouldbedesignedwiththisinmind. mechanismswhichcouldserveaspotentialsolutionsformitigating
Wefindthatacrossalluser-centricmetricsofutility,Gaussiannoise risk.Inthiswork,alargeemphasiswasplacedonuser-centricnotions
islowerthantheotherevaluatedmechanisms.Conversely,smoothing ofutility.Whilepriorworkhasfocusedondata-centricutility,thereisa
hasthelowestdata-centricAOIretentionbuthighestuser-centricutility. necessaryshifttowardsuser-firstdesignforapplicationswheretheuser
Thisfindinghighlightsthatwhendevelopingprivacymechanismsfor directlyinterfaceswiththeeyetrackingfunctionality.Wealsofurther
interactive VR, it is critical to be user-centric. The findings from investigatereal-worldfeasibility,modelingmultiplethreatscenarios
Section3.4.2andpriorwork[14]bothwouldsuggestGaussiannoise whereadversariescanattempttocounteractprivacyefforts.
tobethebestofevaluatedmechanisms,butouranalysissuggeststhat Thisworkshowsthatthereisre-identificationriskassociatedwith
Gaussiannoiseshouldberejectedfromauserexperiencestandpoint. eyetrackingininteractiveVR,thoughtheriskislessprominentthan
Spatialdownsamplingandsmoothingareviableasprivacymechanisms prioranalyseswithconventionaleyetrackingsystems.Ofthemecha-
in interactive contexts, but more work should be done to increase nismsevaluated,wefoundspatialdownsamplingandsmoothingtobe
robustnessagainstknowledgeableadversaries. viableforpracticalapplications. Thesemechanismsprovideprivacy
BroaderImpacts:Thisworkextendsthediscussionofprivacyin whileretaininghighsubjectiveusabilityandreasonabletaskperfor-
eyetrackingandVRbyplacingafocusonthereal-worldimplications mance, yet each mechanism is vulnerable against highly informed
whenapplyingprivacymechanismstofutureapplications.Alargeem- adversaries.
phasisshouldbeplacedonuser-centricnotionsofutilityforgaze-based Wehopethatthisworkwillaidfurtherresearchregardingprivacy
interactionapplications,ratherthanonlyevaluatingdata-centricutility. protectionininteractiveVRapplications.Byplacingafocusonuser-
Ifuserexperienceiscompromised,userswillnotbewillingtoengage centricutilityandhighlightingrealworldthreatscenarios,weprovide
inVRexperiencesinthefirstplace.Whenevaluatingprivacymecha- amethodologyfortheanalysisofprivacymechanismsthatputsthe
nisms,ontopofthesimplestcasewherere-identificationaccuraciesare userfirst.
comparedbeforeandafterprivatization,researchersshouldtestagainst
morechallengingthreatmodelsgroundedinrealworldscenarios. ACKNOWLEDGMENTS
Theevaluatedprivacymechanismscouldbeappliedtoalargerset WeacknowledgefundingsupportfromNSFAwardCNS-2206950and
ofeyetrackingapplications,suchasaugmentedreality(AR)settings aPrivacy-EnhancingTechnologyAwardfromMeta.
ortowebcameyetrackers.WebelieveVRtechnologytobethemost
pressingusecasecurrently;eyegazeisapromisinginputdeviceshow- REFERENCES
casinguniqueinteractionsandenablingcriticaloptimizationssuchas [1] AppleVisionPro.https://www.apple.com/apple-vision-pro/.2
foveatedrendering,butusersshouldnothavetochoosebetweenthese [2] HoloLens 2. https://www.microsoft.com/en-us/hololens/
featuresortheirownprivacy. hardware.2
Limitations:Ouruser-centricevaluationreliesonasingleinterac- [3] MagicLeap1Devices.https://www.magicleap.com/ml1-devices.
tiveVRdataset. Thisdatasetincludesgaze-onlyselectionandgaze- 2
with-gestureselection. Thisdoesnotrepresentthefulldiversityof [4] MagicLeap2Devices.https://www.magicleap.com/ml2-devices.
gaze-basedinteractionsinVR,eachofwhichmayhavetheirownnu- 2
ancesandthresholdsforwhatisareasonablelevelofutilitytraded [5] MetaQuestPro. https://www.meta.com/quest/quest-pro/. 2,4,
for privacy gained. For example, consider an eye tracking-enabled 6
competitivegamingcontext.Usersinthatcontextareunlikelytoaccept [6] Vive Focus 3 Eye Tracker. https://business.vive.com/eu/
anyprivacymechanismthatcompromisesperformance.
product/vive-focus-3-eye-tracker/.2
[7] Vive Pro Eye Overview. https://www.vive.com/sea/product/
TheanalysisinSection5highlightstheimportanceofrobustness;
vive-pro-eye/overview/.2
however,ourlistofthreatmodelsarenotexhaustive.Therearealarge
[8] M. Abrash. Latency – the sine qua non of AR and VR.
numberofadversariesandattackmethodsyettobeconsidered.
https://web.archive.org/web/20130102023747/http:
FutureWork:InSection5.3,wementionedsomeimprovements //blogs.valvesoftware.com/abrash/latency-the-sine-qua-
tosmoothingthatcouldintroducerandomness.Theseimprovements non-of-ar-and-vr/.8
couldincreasesmoothing’srobustnesswhileretainingalevelofusabil- [9] R. Atienza, R. Blonna, M. I. Saludares, J. Casimiro, and V. Fuentes.
ity. Additionally,compositionofsimpleoperationsmayyieldbetter Interactiontechniquesusingheadgazeforvirtualreality.In2016IEEE
mechanisms(passingspatialdownsampledvaluesintothesmoothing Region10Symposium(TENSYMP),pp.110–114,May2016.doi: 10.
buffer,forexample,couldbeexplored). 1109/TENCONSpring.2016.75193871,2,3
9[10] S.Berkovsky,R.Taib,I.Koprinska,E.Wang,Y.Zeng,J.Li,andS.Kleit- Eye-trackingandHead-trackingData.In2021IEEEInternationalSym-
man. DetectingPersonalityTraitsUsingEye-TrackingData. InPro- posiumonMixedandAugmentedReality(ISMAR),pp.31–40,Oct.2021.
ceedingsofthe2019CHIConferenceonHumanFactorsinComputing ISSN:1554-7868.doi:10.1109/ISMAR52148.2021.000179
Systems,CHI’19,pp.1–12.AssociationforComputingMachinery,New [28] S.Jia,D.H.Koh,A.Seccia,P.Antonenko,R.Lamb,A.Keil,M.Schneps,
York,NY,USA,May2019.doi:10.1145/3290605.33004512,8 andM.Pomplun.BiometricRecognitionThroughEyeMovementsUsing
[11] E.Bozkir,O.Günlü,W.Fuhl,R.F.Schaefer,andE.Kasneci. Differ- aRecurrentNeuralNetwork.In2018IEEEInternationalConferenceon
entialprivacyforeyetrackingwithtemporalcorrelations. PLOSONE, BigKnowledge(ICBK),pp.57–64,Nov.2018.doi:10.1109/ICBK.2018.
16(8):e0255979,Aug.2021.doi:10.1371/journal.pone.02559792,3,7 000161,2
[12] B.David-John,K.Butler,andE.Jain. ForYourEyesOnly: Privacy- [29] B.John,S.Jörg,S.Koppal,andE.Jain.TheSecurity-UtilityTrade-offfor
preservingeye-trackingdatasets. In2022SymposiumonEyeTracking IrisAuthenticationandEyeAnimationforSocialVirtualAvatars.IEEE
ResearchandApplications,ETRA’22,pp.1–6.AssociationforComput- TransactionsonVisualizationandComputerGraphics,26(5):1880–1890,
ingMachinery,NewYork,NY,USA,June2022.doi:10.1145/3517031. May2020.doi:10.1109/TVCG.2020.29730522
35296182,3,7 [30] B.John,A.Liu,L.Xia,S.Koppal,andE.Jain.LetItSnow:Addingpixel
[13] B.David-John,K.Butler,andE.Jain. Privacy-preservingdatasetsof noisetoprotecttheuser’sidentity.InACMSymposiumonEyeTracking
eye-trackingsampleswithapplicationsinXR. IEEETransactionson ResearchandApplications, ETRA’20Adjunct, pp.1–3.Association
VisualizationandComputerGraphics,29(5):2774–2784,May2023.doi: forComputingMachinery, NewYork, NY,USA,June2020.doi: 10.
10.1109/TVCG.2023.32470482,3,7 1145/3379157.33905122
[14] B.David-John,D.Hosfelt,K.Butler,andE.Jain.Aprivacy-preserving [31] A.S.Kaplanyan,A.Sochenov,T.Leimkühler,M.Okunev,T.Goodall,
approachtostreamingeye-trackingdata. IEEETransactionsonVisual- andG.Rufo. DeepFovea:neuralreconstructionforfoveatedrendering
izationandComputerGraphics,27(5):2555–2565,May2021.doi: 10. andvideocompressionusinglearnedstatisticsofnaturalvideos. ACM
1109/TVCG.2021.30677871,2,3,4,9 TransactionsonGraphics,38(6):212:1–212:13,Nov.2019.doi:10.1145/
[15] B.David-John,C.Peacock,T.Zhang,T.S.Murdison,H.Benko,andT.R. 3355089.33565571,2
Jonker.Towardsgaze-basedpredictionoftheintenttointeractinvirtual [32] P.KasprowskiandJ.Ober.EyeMovementsinBiometrics.InD.Maltoni
reality.InACMSymposiumonEyeTrackingResearchandApplications, andA.K.Jain,eds.,BiometricAuthentication,LectureNotesinComputer
ETRA’21ShortPapers,pp.1–7.AssociationforComputingMachinery, Science,pp.248–258.Springer,Berlin,Heidelberg,2004.doi:10.1007/
NewYork,NY,USA,May2021.doi:10.1145/3448018.34580081,2,3 978-3-540-25976-3_231,2
[16] D.L.DonohoandI.M.Johnstone. AdaptingtoUnknownSmoothness [33] O.V.Komogortsev,Y.S.Ryu,andD.H.Koh.FastTargetSelectionvia
viaWaveletShrinkage.JournaloftheAmericanStatisticalAssociation, Saccade-drivenMethods. TechnicalReportTXSTATE-CS-TR-2012-6,
90(432):1200–1224,Dec.1995.doi:10.1080/01621459.1995.10476626 TexasStateUniversity,June2012.6
8 [34] J. R. Lewis. Psychometric Evaluation of the Post-Study System Us-
[17] A.T.Duchowski,V.Shivashankaraiah,T.Rawls,A.K.Gramopadhye, abilityQuestionnaire:ThePSSUQ. ProceedingsoftheHumanFactors
B.J.Melloy, andB.Kanki. Binoculareyetrackinginvirtualreality SocietyAnnualMeeting,36(16):1259–1260,Oct.1992.doi: 10.1177/
forinspectiontraining. InProceedingsofthe2000symposiumonEye 1541931292036016176,7
trackingresearch&applications, ETRA’00, pp.89–96.Association [35] J.Li,A.R.Chowdhury,K.Fawaz,andY.Kim. Kalεido: Real-Time
forComputingMachinery,NewYork,NY,USA,Nov.2000.doi: 10. privacy control for Eye-Tracking systems. In 30th USENIX Security
1145/355017.3550312 Symposium(USENIXSecurity21),pp.1793–1810.USENIXAssociation,
[18] E.Erdemir,P.L.Dragotti,andD.Gündüz. Privacy-AwareTime-Series Aug.2021.2,3,8
DataSharingWithDeepReinforcementLearning.IEEETransactionson [36] L.Lin,A.Normoyle,A.Adkins,Y.Sun,A.Robb,Y.Ye,M.DiLuca,and
InformationForensicsandSecurity,16:389–401,2021.doi:10.1109/TIFS S.Jörg.TheEffectofHandSizeandInteractionModalityontheVirtual
.2020.30132009 HandIllusion.In2019IEEEConferenceonVirtualRealityand3DUser
[19] A.S.Fernandes,T.S.Murdison,andM.J.Proulx.Levelingtheplaying Interfaces(VR),pp.510–518,Mar.2019.doi:10.1109/VR.2019.8797787
field:Acomparativereevaluationofunmodifiedeyetrackingasaninput 4
andinteractionmodalityforVR.IEEETransactionsonVisualizationand [37] A.Liu, L.Xia, A.Duchowski, R.Bailey, K.Holmqvist, andE.Jain.
ComputerGraphics,29(5):2269–2279,2023.1,2 Differentialprivacyforeye-trackingdata.InProceedingsofthe11thACM
[20] L.Friedman,H.Stern,V.Prokopenko,S.Djanian,H.Griffith,andO.Ko- SymposiumonEyeTrackingResearch&Applications,ETRA’19,pp.
mogortsev.BiometricPerformanceasaFunctionofGallerySize.Applied 1–10.AssociationforComputingMachinery,NewYork,NY,USA,June
Sciences,12(21):11144,Jan.2022.doi:10.3390/app1221111442 2019.doi:10.1145/3314111.33198232,3,7
[21] M.Garau,M.Slater,V.Vinayagamoorthy,A.Brogni,A.Steed,andM.A. [38] R.Liu,X.Xu,H.Yang,Z.Li,andG.Huang.ImpactsofCuesonLearning
Sasse. Theimpactofavatarrealismandeyegazecontrolonperceived andAttentioninImmersive360-DegreeVideo:AnEye-TrackingStudy.
quality of communication in a shared immersive virtual environment. FrontiersinPsychology,12,2022.1,2
InProceedingsoftheACMSIGCHIConferenceonHumanFactorsin [39] D.Lohr,S.Aziz,L.Friedman,andO.V.Komogortsev.GazeBaseVR,a
ComputingSystems,CHI’03,pp.529–536.AssociationforComputing large-scale,longitudinal,binoculareye-trackingdatasetcollectedinvirtual
Machinery,NewYork,NY,USA,Apr.2003.doi:10.1145/642611.642703 reality.ScientificData,10(1):177,Mar.2023.doi:10.1038/s41597-023
2 -02075-53,4
[22] A.GeorgeandA.Routray.Ascorelevelfusionmethodforeyemovement [40] D.Lohr,H.Griffith,andO.V.Komogortsev. EyeKnowYou: Metric
biometrics.PatternRecognitionLetters,82:207–215,Oct.2016.doi:10. LearningforEnd-to-EndBiometricAuthenticationUsingEyeMovements
1016/j.patrec.2015.11.0201,2,3 FromaLongitudinalDataset.IEEETransactionsonBiometrics,Behavior,
[23] T.Gowases,R.Bednarik,andM.Tukiainen. Gazevs.mouseingames: andIdentityScience,4(2):276–288,Apr.2022.doi: 10.1109/TBIOM.
Theeffectsonuserexperience.InProceedingsoftheInternationalCon- 2022.31676331,2
ferenceonAdvancedLearningTechnologies,OpenContents&Standards [41] D.LohrandO.V.Komogortsev. EyeKnowYouToo: TowardViable
(ICCE),pp.773–777,2008.1,2 End-to-EndEyeMovementBiometricsforUserAuthentication. IEEE
[24] H.Griffith,D.Lohr,E.Abdulin,andO.Komogortsev.GazeBase,alarge- TransactionsonInformationForensicsandSecurity,17:3151–3164,2022.
scale,multi-stimulus,longitudinaleyemovementdataset.ScientificData, doi:10.1109/TIFS.2022.32013691,2,3,4,5
8(1):184,July2021.doi:10.1038/s41597-021-00959-y3,4 [42] D.J.Lohr,S.Aziz,andO.Komogortsev. EyeMovementBiometrics
[25] B.Guenter,M.Finch,S.Drucker,D.Tan,andJ.Snyder. Foveated3D UsingaNewDatasetCollectedinVirtualReality. InACMSymposium
graphics.ACMTransactionsonGraphics,31(6):164:1–164:10,Nov.2012. onEyeTrackingResearchandApplications,ETRA’20Adjunct,pp.1–3.
doi:10.1145/2366145.23661832 AssociationforComputingMachinery,NewYork,NY,USA,June2020.
[26] Z. Hu, S. Li, C. Zhang, K. Yi, G. Wang, and D. Manocha. DGaze: doi:10.1145/3379157.33914202
CNN-BasedGazePredictioninDynamicScenes.IEEETransactionson [43] P.Lopes,N.Tian,andR.Boulic.EyeThoughtYouWereSick!Exploring
VisualizationandComputerGraphics,26(5):1902–1911,May2020.doi: EyeBehaviorsforCybersicknessDetectioninVR.InProceedingsofthe
10.1109/TVCG.2020.29734731,2,3 13thACMSIGGRAPHConferenceonMotion,InteractionandGames,
[27] R.Islam,K.Desai,andJ.Quarles. CybersicknessPredictionfromIn- MIG’20,pp.1–10.AssociationforComputingMachinery,NewYork,
tegratedHMD’sSensors: AMultimodalDeepFusionApproachusing NY,USA,Nov.2020.doi:10.1145/3424636.34269069
10ToappearinIEEETransactionsonVisualizationandComputerGraphics.
[44] P.Lungaro,R.Sjöberg,A.J.F.Valero,A.Mittal,andK.Tollmar.Gaze- [61] N.Sammaknejad,H.Pouretemad,C.Eslahchi,A.Salahirad,andA.Aline-
AwareStreamingSolutionsfortheNextGenerationofMobileVREx- jad. Gender Classification Based on Eye Movements: A Processing
periences.IEEETransactionsonVisualizationandComputerGraphics, EffectDuringPassiveFaceViewing.AdvancesinCognitivePsychology,
24(4):1535–1544,Apr.2018.doi:10.1109/TVCG.2018.27941191,2,3 13(3):232–240,Sept.2017.doi:10.5709/acp-0223-12,8
[45] S.Makowski,P.Prasse,D.R.Reich,D.Krakowczyk,L.A.Jäger,and [62] C.L.Sanches,O.Augereau,andK.Kise.UsingtheEyeGazetoPredict
T.Scheffer. DeepEyedentificationLive: OculomotoricBiometricIden- DocumentReadingSubjectiveUnderstanding.In201714thIAPRInter-
tification and Presentation-Attack Detection Using Deep Neural Net- nationalConferenceonDocumentAnalysisandRecognition(ICDAR),
works.IEEETransactionsonBiometrics,Behavior,andIdentityScience, vol.08,pp.28–31,Nov.2017.doi:10.1109/ICDAR.2017.3772
3(4):506–518,Oct.2021.doi:10.1109/TBIOM.2021.31168751,2 [63] S.SannonandA.Forte. PrivacyResearchwithMarginalizedGroups:
[46] M.Marucci,G.DiFlumeri,G.Borghini,N.Sciaraffa,M.Scandola,E.F. WhatWeKnow,What’sNeeded,andWhat’sNext. Proceedingsofthe
Pavone,F.Babiloni,V.Betti,andP.Aricò. Theimpactofmultisensory ACMonHuman-ComputerInteraction,6(CSCW2):455:1–455:33,Nov.
integrationandperceptualloadinvirtualrealitysettingsonperformance, 2022.doi:10.1145/35555562
workloadandpresence.ScientificReports,11(1):4831,Mar.2021.Num- [64] C.Schröder,S.M.K.AlZaidawi,M.H.Prinzler,S.Maneth,andG.Zach-
ber: 1Publisher: NaturePublishingGroup.doi: 10.1038/s41598-021 mann.RobustnessofEyeMovementBiometricsAgainstVaryingStimuli
-84196-89 andVaryingTrajectoryLength. InProceedingsofthe2020ACMCHI
[47] M.McCormick.DataTheft:APrototypicalInsiderThreat.InS.J.Stolfo, ConferenceonHumanFactorsinComputingSystems,CHI’20,pp.1–7.
S.M.Bellovin,A.D.Keromytis,S.Hershkop,S.W.Smith,andS.Sinclair, AssociationforComputingMachinery,NewYork,NY,USA,Apr.2020.
eds.,InsiderAttackandCyberSecurity:BeyondtheHacker,Advancesin doi:10.1145/3313831.33765342
InformationSecurity,pp.53–68.SpringerUS,Boston,MA,2008.doi:10. [65] S.Seele,S.Misztal,H.Buhler,R.Herpers,andJ.Schild.Here’sLooking
1007/978-0-387-77322-3_48 AtYouAnyway!HowImportantisRealisticGazeBehaviorinCo-located
[48] M. R. Miller, F. Herrera, H. Jun, J. A. Landay, and J. N. Bailenson. SocialVirtualRealityGames? InProceedingsoftheACMAnnualSym-
Personalidentifiabilityofusertrackingdataduringobservationof360- posiumonComputer-HumanInteractioninPlay, CHIPLAY’17, pp.
degreeVRvideo. ScientificReports,10(1):17404,Oct.2020.doi: 10. 531–540.AssociationforComputingMachinery,NewYork,NY,USA,
1038/s41598-020-74486-y2 Oct.2017.doi:10.1145/3116595.31166191,2
[49] R. Miller, N. K. Banerjee, and S. Banerjee. Combining Real-World [66] E.Selinger,E.Altman,andS.Foster.Eye-TrackinginVirtualReality:A
ConstraintsonUserBehaviorwithDeepNeuralNetworksforVirtual VisceralNoticeApproachforProtectingPrivacy.PrivacyStudiesJournal,
Reality(VR)Biometrics.In2022IEEEConferenceonVirtualRealityand 2:1–34,Mar.2023.doi:10.7146/psj.v2i.1346562
3DUserInterfaces(VR),pp.409–418,Mar.2022.doi:10.1109/VR51125 [67] R.ShadievandD.Li.Areviewstudyoneye-trackingtechnologyusagein
.2022.000602 immersivevirtualrealitylearningenvironments.Computers&Education,
[50] R.Miller,N.K.Banerjee,andS.Banerjee.TemporalEffectsinMotion 196:104681,Apr.2023.doi:10.1016/j.compedu.2022.1046812
BehaviorforVirtualReality(VR)Biometrics.In2022IEEEConference [68] Y.Shi,Y.Zhu,R.K.Mehta,andJ.Du.Aneurophysiologicalapproachto
onVirtualRealityand3DUserInterfaces(VR),pp.563–572,Mar.2022. assesstrainingoutcomeunderstress:Avirtualrealityexperimentofindus-
doi:10.1109/VR51125.2022.000762 trialshutdownmaintenanceusingFunctionalNear-InfraredSpectroscopy
[51] P.Monteiro,G.Gonçalves,H.Coelho,M.Melo,andM.Bessa. Hands- (fNIRS).AdvancedEngineeringInformatics,46:101153,Oct.2020.doi:
freeinteractioninimmersivevirtualreality:Asystematicreview.IEEE 10.1016/j.aei.2020.1011532
TransactionsonVisualizationandComputerGraphics,27(5):2702–2713, [69] V.Sitzmann,A.Serrano,A.Pavel,M.Agrawala,D.Gutierrez,B.Masia,
May2021.doi:10.1109/TVCG.2021.30676871,2 andG.Wetzstein.SaliencyinVR:HowDoPeopleExploreVirtualEnvi-
[52] M.Negin,T.Chmielewski,M.Salganicoff,U.vonSeelen,P.Venetainer, ronments? IEEETransactionsonVisualizationandComputerGraphics,
andG.Zhang. Anirisbiometricsystemforpublicandpersonaluse. 24(4):1633–1642,Apr.2018.doi:10.1109/TVCG.2018.27935993
Computer,33(2):70–75,Feb.2000.doi:10.1109/2.8200422 [70] J.Steil,I.Hagestedt,M.X.Huang,andA.Bulling. Privacy-awareeye
[53] A.Normoyle,J.B.Badler,T.Fan,N.I.Badler,V.J.Cassol,andS.R. tracking using differential privacy. In Proceedings of the 11th ACM
Musse.Evaluatingperceivedtrustfromprocedurallyanimatedgaze.In SymposiumonEyeTrackingResearch&Applications,ETRA’19,pp.1–9.
ProceedingsofMotiononGames,MIG’13,pp.141–148.Association AssociationforComputingMachinery,NewYork,NY,USA,June2019.
forComputingMachinery,NewYork,NY,USA,Nov.2013.doi: 10. doi:10.1145/3314111.33199152,3,7
1145/2522628.25226301,2 [71] J.Sun,Y.Liu,H.Wu,P.Jing,andY.Ji.Anoveldeeplearningapproach
[54] P.A.OrlovandN.Apraksin. TheEffectivenessofGaze-Contingent fordiagnosingAlzheimer’sdiseasebasedoneye-trackingdata.Frontiers
ControlinComputerGames.Perception,44(8-9):1136–1145,2015.doi: inHumanNeuroscience,16,2022.2
10.1177/03010066155949101,2 [72] V.TanriverdiandR.J.K.Jacob. Interactingwitheyemovementsin
[55] J.L.Orquin,N.J.S.Ashby,andA.D.F.Clarke. AreasofInterestasa virtualenvironments.InProceedingsoftheACMSIGCHIconferenceon
SignalDetectionProbleminBehavioralEye-TrackingResearch.Journal HumanFactorsinComputingSystems,CHI’00,pp.265–272.Association
ofBehavioralDecisionMaking,29(2-3):103–115,2016.doi: 10.1002/ forComputingMachinery, NewYork, NY,USA,Apr.2000.doi: 10.
bdm.18672 1145/332040.3324432
[56] S.Papadimitriou,F.Li,G.Kollios,andP.S.Yu. Timeseriescompress- [73] P.Ugwitz,O.Kvarda,Z.Juˇríková,Šašinka,Cˇeneˇk,andS.Tamm. Eye-
ibilityandprivacy. InProceedingsofthe33rdinternationalconference TrackinginInteractiveVirtualEnvironments:ImplementationandEvalua-
onVerylargedatabases,VLDB’07,pp.459–470.VLDBEndowment, tion.AppliedSciences,12(3):1027,Jan.2022.doi:10.3390/app12031027
Vienna,Austria,Sept.2007.8 3
[57] S.PengandN.AlMadi.AnEyeOpenerontheUseofMachineLearning [74] N.I.Vargas-Cuentas,A.Roman-Gonzalez,R.H.Gilman,F.Barrientos,
inEyeMovementBasedAuthentication. In2022ACMSymposiumon J.Ting,D.Hidalgo,K.Jensen,andM.Zimic.Developinganeye-tracking
EyeTrackingResearchandApplications,ETRA’22,pp.1–2.Association algorithmasapotentialtoolforearlydiagnosisofautismspectrumdis-
forComputingMachinery, NewYork, NY,USA,June2022.doi: 10. orderinchildren. PLOSONE,12(11):e0188826,Nov.2017.doi: 10.
1145/3517031.35316311,2 1371/journal.pone.01888262
[58] T.Piumsomboon,G.Lee,R.W.Lindeman,andM.Billinghurst.Exploring [75] G.Wan,X.Kong,B.Sun,S.Yu,Y.Tu,J.Park,C.Lang,M.Koh,Z.Wei,
naturaleye-gaze-basedinteractionforimmersivevirtualreality.In2017 Z.Feng,Y.Lin,andJ.Kong.ApplyingEyeTrackingtoIdentifyAutism
IEEESymposiumon3DUserInterfaces(3DUI),pp.36–39,Mar.2017. SpectrumDisorderinChildren. JournalofAutismandDevelopmental
doi:10.1109/3DUI.2017.78933151,2,3 Disorders,49(1):209–215,Jan.2019.doi:10.1007/s10803-018-3690-y2
[59] J.Reichenberger,M.Pfaller,andA.Mühlberger.GazeBehaviorinSocial [76] C.-C.Wang,J.C.Hung,andH.-C.Chen.HowPriorKnowledgeAffects
FearConditioning:AnEye-TrackingStudyinVirtualReality.Frontiers VisualAttentionofJapaneseMimicryandOnomatopoeiaandLearning
inPsychology,11,2020.2 Outcomes:EvidencefromVirtualRealityEyeTracking.Sustainability,
[60] K.Ruhland,K.Zibrek,andR.McDonnell. Perceptionofpersonality 13(19):11058,Jan.2021.doi:10.3390/su1319110581,2
througheyegazeofrealisticandcartoonmodels. InProceedingsofthe [77] S.Wei,D.Bloemers,andA.Rovira. APreliminaryStudyoftheEye
ACMSIGGRAPHSymposiumonAppliedPerception,SAP’15,pp.19–23. TrackerintheMetaQuestPro. InProceedingsofthe2023ACMIn-
AssociationforComputingMachinery,NewYork,NY,USA,Sept.2015. ternationalConferenceonInteractiveMediaExperiences,IMX’23,pp.
doi:10.1145/2804408.28044241,2 216–221.AssociationforComputingMachinery,NewYork,NY,USA,
11Mechanism SystemMemory(kb) Runtime(FPS)
Aug.2023.doi:10.1145/3573381.35964674
NoMechanism 311825±12443 70.94±0.076
[78] M.Weier,T.Roth,A.Hinkenjann,andP.Slusallek.FoveatedDepth-of-
FieldFilteringinHead-MountedDisplays.ACMTransactionsonApplied GaussianNoise 318181±12490 70.95±0.083
Perception,15(4):26:1–26:14,Sept.2018.doi:10.1145/32383011,2 SpatialDownsampling 316606±13338 70.94±0.076
[79] M. Weier, T. Roth, E. Kruijff, A. Hinkenjann, A. Pérard-Gayot, Smoothing 322041±4818 70.94±0.080
P. Slusallek, and Y. Li. Foveated Real-Time Ray Tracing for Head-
MountedDisplays. ComputerGraphicsForum,35(7):289–298,2016. Table5:Performanceanalysisofprivacymechanismsonourprototype
doi:10.1111/cgf.130261,2 Unityenvironment.
[80] H.Xiang,K.Kim,andJ.Ryu.Work-in-Progress—PreliminaryAnalysis
ofSpatialPerceptioninARapplicationwithEye-TrackingData.In2022
8thInternationalConferenceoftheImmersiveLearningResearchNetwork
reservedmemorybytheapplicationandthesystemmemoryreportedby
(iLRN),pp.1–3,May2022.doi:10.23919/iLRN55037.2022.98159359
Unity3D’sMemoryProfiler6.Tomeasureexecutiontime,wereportthe
[81] Y.Xu,Y.Dong,J.Wu,Z.Sun,Z.Shi,J.Yu,andS.Gao.GazePrediction
averageframespersecondsofeachtrialforeachprivacymechanism.
inDynamic360°ImmersiveVideos.pp.5333–5342,2018.1,2
[82] A.T.ZhangandB.O.LeMeur.HowOldDoYouLook?InferringYour WeseeinTable4thatthesemechanismshavelittletonoimpactto
AgefromYourGaze. In201825thIEEEInternationalConferenceon performance.Runtimeisnotimpacted,andsystemmemoryincreases
ImageProcessing(ICIP),pp.2660–2664,Oct.2018.doi:10.1109/ICIP. only slightly on average. We do see a more noticeable increase in
2018.84512192,8 memory usage with smoothing, as it is the only mechanism which
[83] G.A.Zito,D.Cazzoli,L.Scheffler,M.Jäger,R.M.Müri,U.P.Mosimann, storesacontinuousarrayofpastgazesamplesneededtocomputethe
T.Nyffeler,F.W.Mast,andT.Nef.Streetcrossingbehaviorinyounger currentgazesample.Overall,themechanismsevaluatedarequickto
andolderpedestrians:aneye-andhead-trackingstudy.BMCGeriatrics, computeandprovidenegligibleperformanceoverhead.
15(1):176,Dec.2015.doi:10.1186/s12877-015-0175-02 Inourexperiments,weprocessgazesamplesprovidedbytheOculus
SDKandapplyprivacymechanismsbeforeutilizingthegazesamples
APPENDIX
intheapplication.Inareal-worlddeployment,thesemechanismscould
A DESCRIPTIONOFPRIVACYMECHANISMS
besecurelyimplementedonVRHMDsbeforepassinggazesamples
toapplications. Figure1illustratesthegeneraleyetrackingpipeline
for VR headsets. Along with other operations taken to model and
process gaze vectors, these privacy mechanisms can be applied on
thedevicesecurely,thenprivatizedgazevectorscanbeprovidedto
potentiallyuntrustworthyapplicationsopenedbytheVRuser. With
currentmechanisms’lowoverhead,thesecouldbeimplementedon
headsetsoftwarewithlittleperformanceimpact.Hardware-accelerated
implementationscouldalsobeexplored,andmaybemorenecessary
asprivacymechanismsbecomemorecomplex.
C ADDITIONALDATACOLLECTIONDETAILS
The dataset collected for this publication is available at https://
doi.org/10.5281/zenodo.10475455. In this section we discuss
theimplementationofourdataloggingprocessandthedatacollected.
TheexperimentsareimplementedinUnity3DusingtheOculusSDK
tointerfacewiththeMetaQuestProheadsetsusedfordatacollection.
Ateveryframe,wequerytheSDKforgazesamples,processthesegaze
samplesusingthecurrentprivacymechanism,thenpasstheprivatized
gazesampleforusebytherestoftheapplication.
Welogdataateveryvisualframe. Becausetheeyegazeprovided
Fig.5: Visualizationsoftheprivacymechanismsimplementedinour bytheOculusSDKisonlyavailableateveryframe’supdate,gazedata
experiments. iscollectedattheapplication’sframerate.Datawasloggedlocallyto
theVRheadset’sinternalstorage,thenmovedaftereachparticipant’s
Hereweprovideillustrationsandshortdescriptionsoftheconcepts session.
ofourprivacymechanisms. SeeFigure5forillustrations. Gaussian Inheadset_data.csvwelogframes,timestamps,activetrialcon-
noiseoffsetseachgazedatapointindependentlyateachframebydraw- ditions,andthepositionandrotationsoftheheadset,hands,andeyes
inguponaGaussiandistribution.Asthenoisesamplingisindependent, ateveryframe. Wealsologthenon-privatizedrotationsoftheeyes
notemporalpatternscanbediscernedtoidentifyindividuals;however, inExperiment2forpossiblecomparison.event_data.csvcontains
themechanismissusceptibletofilteringtorecovertheoriginalsignal. experiment-relevantevents,suchasareaofinterestintersectioninfo,
Spatialdownsamplingmapsthecontinuousrangeofgazevaluestoan thestartandendoftrialperiods, andthecompletionoftasks, such
equirectangulargridofdiscretepoints.Thetruegazeangleismapped ascompletingasandwichinExperiment1anddestroyinganenemy
totheclosestdiscretevalueateveryframe.Temporaldownsamplingef- in Experiment 2. survey_data.csv reports user responses to the
fectivelydecreasesthesamplingrate,copyingthetruevalueofaframe PSSUQquestionnaireaftereachcondition.Thedatasetalsoincluded
intothenextNframes.Smoothingappliesalinearweightedmoving processedfiles,whichcontainstreamlinedinformationonconditions,
averagetoarangeofgazevalues.Theweightinggivesrecentframes frame, and timestamp and the localized rotations of the eyes. This
ahigherweightthanlessrecentframes.Theresultappearstohavea processedinformationistrimmedtoonlycontainframesinwhichthe
slightdelaytotheuser,butbyfixatingonanobject,thesmoothedgaze experimentwasactive.
valuequicklyreachestheintendedpoint. InExperiment1, eachparticipantunderwent4identicaltrialsof
90 seconds, yielding 9360 seconds of active trial data for N =26
B RUNTIMEANALYSISOFPRIVACYMECHANISMS
participants. InExperiment2,eachparticipantunderwent2trialsof
Weprovideasimpleperformanceanalysisofeachofourmechanisms, 30secondsforeachprivacymechanism,strength,andcontrolmode
measuringtheimpactondevicememoryandonexecutiontime. We pairing,yielding28trialsforparticipantswhichunderwentsmoothing
measuretheimpactondevicememorybyreportingtheaveragemem-
oryacrosstrialswithineachprivacymechanism. Wereportthetotal 6https://docs.unity3d.com/Manual/ProfilerMemory.html
12ToappearinIEEETransactionsonVisualizationandComputerGraphics.
and20forthosewhodidnot,yielding13,200secondsofactivetrial
dataforN=18participants.
13