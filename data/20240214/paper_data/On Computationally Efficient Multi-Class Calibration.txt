On Computationally Efficient Multi-Class Calibration
Parikshit Gopalan Lunjia Hu∗ Guy N. Rothblum
Apple Stanford University Apple
parikg@apple.com lunjia@stanford.edu rothblum@alum.mit.edu
Abstract
Consider a multi-class labelling problem, where the labels can take values in [k], and a pre-
dictor predicts a distribution over the labels. In this work, we study the following foundational
question: Are there notions of multi-class calibration that give strong guarantees of meaningful
predictions and can be achieved in time and sample complexities polynomial in k? Priornotions
of calibration exhibit a tradeoff between computational efficiency and expressivity: they either
suffer from having sample complexity exponential in k, or needing to solve computationally
intractable problems, or give rather weak guarantees.
Our main contribution is a notion of calibration that achieves all these desiderata: we for-
mulate a robust notion of projected smooth calibration for multi-class predictions, and give new
recalibrationalgorithmsforefficientlycalibratingpredictorsunderthisdefinitionwithcomplex-
ity polynomial in k. Projected smooth calibration gives strong guarantees for all downstream
decision makers who want to use the predictor for binary classification problems of the form:
doesthelabelbelongtoasubsetT ⊆[k]: e.g. isthisanimageofananimal? Itensuresthatthe
probabilities predicted by summing the probabilities assigned to labels in T are close to some
perfectly calibrated binary predictor for that task. We also show that natural strengthenings of
our definition are computationally hard to achieve: they run into information theoretic barriers
or computational intractability.
Underlying both our upper and lower bounds is a tight connection that we prove between
multi-classcalibrationandthewell-studiedproblemofagnosticlearninginthe(standard)binary
prediction setting. This allows us to use kernel methods to design efficient algorithms, and also
to use known hardness results for agnostic learning based on the hardness of refuting random
CSPs to show lower bounds.
∗Part of this work done while LH was interning at Apple. LH is also supported by Moses Charikar’s and Omer
Reingold’s Simons Investigators awards, Omer Reingold’s NSF Award IIS-1908774, and the Simons Foundation
Collaboration on the Theory of Algorithmic Fairness.
4202
beF
21
]GL.sc[
1v12870.2042:viXraContents
1 Introduction 1
1.1 Our Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
1.2 Further Discussion of Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
1.3 Organization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
2 Multi-Class Calibration 9
3 Sample Complexity of Canonical Calibration 14
4 Auditing for Weighted Calibration and Agnostic Learning 17
4.1 Auditing from Agnostic Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
4.2 Agnostic Learning from Auditing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
5 Hardness of Auditing for Decision Calibration 22
6 Kernel Algorithms for Auditing Calibration 23
6.1 Auditing for the Multinomial Kernel . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
7 Efficient Auditing for Projected Smooth Calibration 26
8 Computational Lower Bound for Projected Smooth Calibration 29
8.1 Projected Smooth Calibration and Sigmoids . . . . . . . . . . . . . . . . . . . . . . . 30
A Proofs from Section 6 39
A.1 Proof of Theorem 6.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
A.2 Proof of Theorem 6.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 411 Introduction
The ubiquitous use of machine learning for making consequential decisions has resulted in a re-
newed interest in the question what should probabilistic predictions mean? This question has a long
history going back at least as far as the literature on forecasting [Daw82, Daw84]. Calibration is a
classical interpretability notion for binary predictions originating in this setting that is widely used
in modern machine learning. In the binary classification setting, denoting the label y ∈ {0,1} and
the predicted probability of 1 by v ∈ [0,1], (perfect) calibration requires E[y|v] = v.
There has been renewed research interest both in the calibration of modern DNNs [GPSW17]
andinfoundationalquestionsabouthowbesttodefineandmeasurecalibrationtoensurerobustness
andefficiency[BGHN23,KLST23]buildingonearlierworkof[KF08]. Westudycalibrationnotions
inthecontextofmulti-classclassification, wherethegoalistoassignoneofk possiblelabelstoeach
input. A predictor assigns to each input a distribution over the labels, which allows it to convey
uncertainty in its predictions. Values of k in the thousands are increasingly common, especially
for vision tasks [DDS+09], so the efficiency in terms of the parameter k is increasingly relevant.
In this setting, even the right definition of calibration is not immediate. There are a multitude of
existing definitions in theory and practice, such as confidence [GPSW17], class-wise [KPNK+19],
distribution [KF15] and decision [ZKS+21] calibration. However, existing notions either provide
only weak guarantees for meaningful predictions, are computationally hard to achieve, or are even
information theoretically hard to achieve, requiring exponential sample complexity in k.
In this work, we study the following foundational question:
Are there notions of multi-class calibration that give strong guarantees of meaningful predictions
and can also be achieved with time and sample complexities polynomial in k?
Ourmaincontributionisansweringthisquestionintheaffirmative: weformulatearobustnotion
ofprojectedsmoothcalibrationformulti-classpredictions,andgivenewrecalibrationalgorithms1 for
efficientlycalibratingpredictorsunderthisdefinition(andvariantsofit). Wealsoshowthatnatural
strengthenings of this definition are computationally or information-theoretically hard to achieve.
Animportantingredientinshowingthesenewupperandlowerboundsisatightconnectionbetween
multi-class calibration and the well-studied problem of agnostic learning in the (standard) binary
prediction setting. We proceed to elaborate on the setting, prior work, and our contributions.
Multi-class calibration. In the k-class prediction setting, we have an underlying distribution
over instance-outcome pairs, where we view the outcome y as the one-hot encoding of a label
from [k]. A prediction vector v ∈ ∆ describes a distribution in the k-dimensional simplex, where
k
a perfect prediction would describe the exact distribution of the outcome y for that instance.
Canonical calibration [KF15], also called distribution calibration, is the most stringent notion,
whichrequiresthatE[y|v] = v (theexpectationaveragesoverallinstancesforwhichtheprediction
is v). The naive procedure for checking whether canonical calibration holds even approximately
requires (after suitable discretization) conditioning on exp(k) many possible predictions in ∆ .
k
Indeed, we show that even the easier problem of distinguishing a perfectly calibrated predictor
from one that is far from calibrated requires exp(k) samples. At the other extreme, class-wise
1Theexactnotionofcalibratingapredictorhastobedefinedcarefullytoavoidtrivialsolutions(forexample,the
constantpredictorthatalwaysoutputstheempiricalmeanisperfectlycalibrated). Followingmuchoftheliterature,
our algorithms post-process a given predictor to make it calibrated while not increasing the squared loss.
1calibration [KPNK+19] only requires that for every i ∈ [k], E[y |v ] = v . This notion can be
i i i
achieved efficiently, but we argue below that it is not sufficiently expressive.
Assume that we have a class-wise calibrated predictor and we wish to use it for downstream
binaryclassificationtasks. Forinstance, wemightwanttoclassifyimagesasbeingthoseofanimals,
where animals is a subset of labels. Assume for simplicity that c for cat and d for dog are the only
animalsinourklabels. Class-wisecalibrationensuresthatthepredictedprobabilitiesv ,v ∈ [0,1]
c d
are each calibrated on their own: conditioned on, say, the predicted probability of cat being 0.2,
the outcome should be a cat w.p. roughly 0.2. Suppose, however, that we want to predict whether
the image is a cat or a dog. The natural probability to predict is v +v , but this might be far
c d
from calibrated w.r.t the actual probability that the outcome is a cat or a dog (even though the
predictor is class-wise calibrated). This reveals a weakness of class-wise calibration that is also
shared by other guarantees that we know how to achieve efficiently (such as confidence calibration
[GPSW17], see below): their calibration guarantees are rather fragile, and break down when used
in downstream tasks.
Aiming to achieve rigorous downstream guarantees, Zhao et al. [ZKS+21] introduced decision
calibration, which can be achieved in poly(k) sample complexity.2 However we show that the
algorithmic task they aim to solve is as hard as agnostically learning halfspaces, and hence is
unlikely to be achievable in time poly(k) by results of [Dan16].
To summarize, the state of the art for multiclass calibration notions:
• There are efficient notions, such as classwise and confidence calibration, but they are not
very expressive. In particular their calibration guarantees are rather fragile and do not imply
good guarantees for downstream tasks.
• There are expressive notions, such as canonical calibration and the recently proposed no-
tion of decision calibration, but they are inefficient. These notions run into information or
complexity theoretic barriers, which prevent them from being achievable in running time and
sample complexity poly(k).
This motivates our foundational question: is there an expressive and efficient notion of multi-
class calibration? Such a notion should give robust calibration guarantees for downstream tasks,
and should be achievable in poly(k) time and sample complexity. More broadly, is there a gen-
eral framework for understanding the complexity of various calibration notions? Ideally, such a
framework would let us identify broad classes of notions that are efficiently achievable and identify
computational and information-theoretic barriers to other notions.
These questions are motivated not only by the use of calibration as an notion of interpretability
for probabilistic predictions in machine learning, but also by the recent applications of calibration
to fairness [HKRR18], loss minimization [GKR+22, GHK+23] and indistinguishability [DKR+21,
DKR+22, DLLT23]. In the multi-class setting with k labels, algorithms for all of these notions
become exponential in k, which stems from the fact that they try to achieve canonical calibration
or similarly expressive notions (see for example [GKR+22, DKR+22]). We see formulating more
efficient notions of calibration as a step towards more efficient algorithms for these applications in
the multiclass setting.
2The paper claims the notion is both time and space efficient, but their main result [ZKS+21, Theorem 2] only
proves a bound on sample complexity. See the discussion in Sections 1.2 and 2 and 5.
21.1 Our Contributions
We start by describing a unifying framework from [GKSZ22] for various notions of multiclass
calibration, for which we need some notation. Given a distribution D on (x,y) pairs where y ∈
{0,1}k is the one-hot encoding of a label and a predictor p, let v = p(x) ∈ ∆ be the prediction of
k
p. Let ∆ ⊆ Rk denote the probability simplex for k outcomes.
k
Weighted calibration. As observed by various works [DKR+21, GKSZ22, DKR+22, BGHN23],
calibration is essentially a notion of indistinguishability of distributions. For multiclass learning,
perfectcanonicalcalibrationrequiresthatforeveryv ∈ ∆ , E[y|v](whichcompletelydescribesthe
k
distributionofyconditionedonv)equalsv. Ifwerelaxequalitytoexpectedclosenessinℓ distance
1
E [|E[y|v]−v|], we arrive at the notion of the expected calibration error or ECE. This notion
v
requires exp(k) samples to estimate (see Theorem 3.2); it is also not robust to small perturbations
of the predictor p [KF08, BGHN23]. We aim for relaxed calibration notions that capture the same
underlying principle that E[y|v] and v are “close” under D, but which are efficient to estimate,
and also do not suffer from the same kind of non-robustness.
Following [GKSZ22], we work with the definition of weighted calibration, which is general
enough to capture all the aforementioned notions of calibration. For a hypothesis class H := {h :
∆ → [−1,1]}, we consider the family of weight functions Hk mapping ∆ → [−1,1]k, where for
k k
every i ∈ [k], coordinate i of the output is a function h ∈ H of the input. Define the weighted
i
calibration error of p under D as
CE (p,Hk):= max E[⟨w(v),y−v⟩] = max E [⟨w(v),E[y|v]−v⟩].
D
w∈Hk D w∈Hkv∼D
This can be seen as requiring closeness of the distributions of v and E[y|v] to the class of
distinguishers Hk in the spirit of pseudorandomness. Taking H to be all functions on ∆ bounded
k
by 1 in absolute value recovers the notion of ECE. Relaxing the space of distinguishers weakens the
definition. Are there distinguisher families where the calibration guarantee remains meaningful,
while simultaneously allowing for efficient auditing: deciding whether a given predictor satisfies
CE (D) ≤ α?
Hk
Projected smooth calibration. We now formulate projected smooth calibration, a weighted
calibrationnotionthatsatisfiesourdesiderata. Asdiscussedabove, wewanttoensurethefollowing
subset calibration guarantee: for every subset T ⊆ [k] of labels, the probabilities assigned by our
predictor to the event that the label belongs to T should be calibrated. Let v ∈ ∆ denote the
k
prediction of our predictor. Letting 1 ⊆ {0,1}k denote the indicator vector of T, the indicator
T
for the event that the outcome y is in T is 1 ·y, whereas the predicted probability is 1 ·v. Say
T T
we want to enforce the calibration condition that when the predicted probability of belonging to T
exceeds v ∈ [0,1], the label indeed lies in T with roughly the predicted probability. We can view
this as requiring a bound on
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12)E[I(1 ·v ≥ v)(1 ·y−1 ·v)](cid:12) = (cid:12)E[I(1 ·v ≥ v)1 ·(y−v)](cid:12)
(cid:12) T T T (cid:12) (cid:12) T T (cid:12)
where(I(1 ·v ≥ v)1 ) ∈ {0,1}k isavector-valuedfunctionon∆ , whichtakesthevalueI(1 ·v ≥
T T k T
v) for coordinates in T, and the value 0 for coordinates outside T. The good news is that this
setup fits the template of weighted calibration, where the class H contains all functions the form
3I(1 ·v ≥ v) for T ∈ {0,1}k,v ∈ R. The bad news is that we will show this problem is as hard as
T
agnostically learning halfspaces. Daniely [Dan16] showed that, assuming the hardness of refuting
random Xor CSPs, this problem cannot be solved in polynomial time.
In projected smooth calibration, we replace the hard thresholds I(1 ·v ≥ v) with the class
T
H = {ϕ(a·v)} where ϕ : [0,1] → [−1,1] is a Lipschitz continuous function and a ∈ [−1,1]k. In
pLip
particular, this includes indicator vectors for subsets. Projected smooth calibration requires that
the weighted calibration error for the weight family Hk is bounded.
pLip
Definition 1.1 (Projected smooth calibration, informal statement of Definition 2.5). For a joint
distribution D on predictions v and true outcomes y, the projected smooth calibration error is
(cid:12) (cid:12)
(cid:12) (cid:12)
psCE(D) := sup (cid:12) E [(y−v)w(v)](cid:12),
w∈Hk
(cid:12)(v,y)∼D (cid:12)
pLip
where Hk is the class of functions w : ∆ → [−1,1]k such that for every coordinate i in w’s
pLip k
output there is a 1-Lipschitz function ϕ(i) : [0,1] → [−1,1] s.t. w(i)(v) ≡ ϕ(i)(a·v).
A predictor satisfies projected smooth calibration if its error psCE is bounded. We show that
this definition satisfies all our desiderata:
Property (1): expressive power. Projectedsmoothcalibrationguaranteesthatforeverysubset
T ⊆ [k], the predicted probabilities for the binary classification task (namely, the outcome is in
T) satisfy smooth calibration, a well-studied calibration notion with several desirable properties
[KF08, GKSZ22, BGHN23]. In particular, this implies that the predicted probabilities 1 ·v that
T
the outcome will be in T are close to being perfectly calibrated. The proof builds on the work of
[BGHN23]. Inparticular, foreachsuchsubsetT, thereexistsaperfectlycalibratedpredictorp∗ for
T
the binary classification task of determining whether the outcome will land in T, whose predictions
are close to 1 ·v in earthmover distance. Thus, we get meaningful guarantees for a rich collection
T
of downstream binary classification tasks (including subset membership and more).
Property (2): Computational efficiency. We show an efficient algorithm for auditing whether
theprojectedsmoothcalibrationerrorofapredictorisbounded. Herewestateourresultinformally,
the formal statement is in Theorem 7.1.
Theorem 1.2 (Efficient auditing, informal statement of Theorem 7.1). There is an algorithm for
deciding whether the projected smooth calibration error is at most α, with sample complexity and
running time O(kO(1/α)).
Theworkof[SSS11]showedthatagnosticlearninghalfspacesbecomestractableifwereplacethe
hard thresholds used in halfspaces with Lipschitz transfer functions. Building on their techniques,
and using Jackson’s Theorem on low-degree uniform approximations for Lipschitz functions, we
show that auditing for projected smooth calibration is polynomial time solvable. Moreover, our
auditing algorithm is quite simple and does not need to solve a convex program, generalizing
results in [KSJ18, BGHN23]. Our algorithm in fact solves the associated search problem, if p is
not calibrated, it finds a witness to the lack of calibration, which can be used to post-process p and
redcuce its calibration error without increasing the squared loss. Defining a recalibration algorithm
correctly is subtle, see Definition 4.1 and the discussion preceding it.
Our algorithm has running time polynomial in k for every fixed constant α, in contrast with
previous results for expressive notions of calibration. If we only care about auditing using ϕ(w·v)
4for vectors w where ∥w∥2 ≤ m then the sample complexity can be bounded by mO(1/α). This gives
2
a running time fixed polynomial in k (but exponential in α) for subset calibration where we only
care about bounded size subsets. One can also get better run times by restricting the family of
Lipschitz functions ϕ. By restricting to auditors of the form tanh(w·v) we get the weaker notion of
sigmoid calibration, forwhichtheauditorrunsintimekO(log(1/α)). Thiscanbeseenasasmooth
relaxation of the intractable notion of halfspace auditing. However, the improved efficiency comes
at the price of some expressivity, we do not get closeness to perfect calibration for downstream
subset classification tasks.
It is interesting to investigate whether the exponential dependence on 1/α in Theorem 1.2 can
be avoided. As a result in this direction, we show that the running time cannot be improved to
poly(k,1/α):
Theorem 1.3 (Informal statement of Theorem 8.1). Under standard complexity-theoretic assump-
tions, there is no algorithm that can decide whether the projected smooth calibration error is at
most α with sample complexity and running time
kO(log0.99(1/α)).
We prove the theorem by showing a reduction from the task of refuting random XOR formulas.
Getting the right exponent for k as a function of 1/α is an interesting question for future work.
Property (3): Robustness. The works of [KF08, FH18, BGHN23] advocate the use of Lipschitz
functions in defining calibration since it results in robust measures that do not change drastically
under small perturbations of the predictor. Since projected smooth calibration is defined using
Lipschitz functions, it is a robust calibration measure.
Lower bounds for stronger notions. The discussion above suggests possible strengthenings of
the notion of projected smooth calibration. The weight function family ϕ(w·v) is a subset of the
family fLip of all Lipschitz functions ψ : ∆ → [−1,1]. We could imagine using fLipk as our weight
k
function family to get a stronger notion of calibration, which we call full smooth calibration. We
show in Theorem 3.4 that this notion is information-theoretically intractable and requires exp(k)
samples.
Theorem 1.4 (Informal statement of Theorem 3.4). Any algorithm to decide whether the full
smooth calibration error is 0 or exceeds a positive absolute constant requires exp(k) samples.
In our closeness to calibration guarantee, for every T ⊂ [k] there exists a binary predictor
p∗ whose predictions are close to 1 · v and which is perfectly calibrated. But the different p∗
T T T
for various Ts might not be consistent, meaning they need not arise as p∗ = 1 · p∗ where p∗
T T
is a perfectly calibrated predictor (independent of the choice of T). Could we instead measure
calibration error by comparing our predictions to those made by a single calibrated predictor p∗?
Put differently, projected smooth calibration guarantees that our predictions on each subset T are
locally close to the predictions of a calibrated binary predictor p∗. We are now asking whether one
T
can measure global closeness to a single perfectly calibrated predictor p∗.
There is prior work that suggests measuring closeness to calibration in terms of distance of
its predictions from the nearest perfectly calibrated predictor v∗. This notion, called distance
to calibration, was studied in the binary setting by [BGHN23], where it plays a central role in
their theory of consistent calibration measures. Such measures are ones that approximate the
distance to calibration within polynomial factors. They identified several efficiently computable
5consistent calibration measures in the binary setting, including smooth calibration and Laplace
kernel calibration.
We show a strong negative result for measuring or even weakly approximating the distance to
calibration in the multiclass prediction setting:
Theorem 1.5 (Informal statement of Theorem 3.2). Any algorithm to decide whether the distance
to calibration is 0 or exceeds a positive absolute constant requires exp(k) samples.
In contrast to the work of [BGHN23], Theorem 1.5 shows that in the multiclass setting, any
consistent calibration measure requires exp(k) samples.
These lower bounds stem from an indistinguishability argument that we sketch below. We
take V ⊂ ∆ of size exp(k) of predictions that are Ω(1) far from each other. We construct two
k
distributions D and D on predictions and labels. In either distribution, the marginal distribution
1 2
on predictions v is uniform on V. In D , the distribution on labels y conditioned on v is perfectly
1 1
calibrated, so that E[y |v] = v. In D , for each v ∈ V, the label y is fixed to be some single value.
1 2 2
We imagine this label y being picked at random with E[y |v] = v the very first time we predict
2 2
v. Every subsequent time we see the prediction v, we will see this same label y |v. A sampling
2
algorithm cannot tell the difference between these distributions until it sees multiple samples with
the same value of v ∈ V, since until that point, samples from the two distributions are identically
(cid:112)
distributed. By the birthday paradox, this requires Ω( |V|) = exp(k) samples.
Equivalence between auditing and agnostic learning. Underlyingouralgorithmsandhard-
ness results is a tight characterization of efficient auditing in terms of agnostic learning. We elabo-
rate on these two computational tasks. The auditing task for the class of weight functions Hk gets
as input a predictor p, and needs to decide whether it has large calibration error for Hk. If so, then
the auditor should also return a weight function w′ that has large calibration error (in the spirit
of weak agnostic learning [BLM01, KMV08], we allow for a gap between the largest calibration
error in Hk and the error of the weight function found by the auditor). As noted in the discussion
following Theorem 1.2, solving the auditing task also allows us to efficiently recalibrate a given
predictor to achieve low weighted calibration error for the class Hk. Weak agnostic learning for a
class H is a standard learning problem in the binary (not multi-class) classification setting, where
we have a distribution on ∆ ×{±1} and the goal is to find a witness given the existence of h ∈ H
k
with correlation E [h(v)z] at least γ. We show that auditing for Hk is efficient iff the class
(v,z)∼D
H is efficiently weakly agnostically learnable.
Theorem1.6(InformalstatementofTheorems4.4and4.5). AuditingforHk andagnosticlearning
for H reduce to each other efficiently.3 The calibration error parameter in auditing corresponds to
the correlation parameter in learning up to a constant factor.
Connectionsbetweenauditingforcalibrationandagnosticlearninghaveappearedin[HKRR18]
and subsequent works. The focus was on binary or scalar prediction tasks, where the challenge is
guaranteeingcalibrationformanydifferentsubsetsofthefeaturevectors. Thechallengeinourwork
is different: we aim to guarantee calibration w.r.t. the k-dimensional multi-class outcome vector y,
and to relate this task to agnostic learning with binary labels. As we show in Section 4.1, applying
3We use an auditor for a slightly different class H˜k to solve the learning task for H, where H˜ is obtained from H
bytakingasimpleaffinetransformationoftheinput. Inparticular,thetwoclassesarethesamewhenHistheclass
of halfspaces.
6a learning algorithm to an auditing task in a coordinate-wise manner would result in losing a factor
of k in the calibration error. This loss of k would result in auditing algorithms that do not run in
time poly(k) even for constant α. We show that this loss can always be avoided by applying the
learning algorithm on carefully constructed conditional distributions, giving a tight connection up
to constant factors in the calibration error.
The equivalence between auditing and learning allows us to apply a rich set of techniques
from the literature for agnostic learning to show both hardness results and efficient algorithms for
auditing tasks. In particular, our hardness result for auditing decision calibration (Theorem 5.1)
is based on the hardness of agnostically learning halfspaces shown in previous work [Dan16]. In
general, our auditing algorithms can be instantiated with weight functions that have bounded
norm in any reproducing kernel Hilbert space over ∆ , as long as the corresponding kernel can be
k
evaluatedefficiently. Weapplypolynomialapproximationtheoremsandthemultinomialkernelused
in learning algorithms [SSS11, GKKT17, GKK20] to give efficient auditors for projected smooth
calibration and sigmoid calibration.
1.2 Further Discussion of Related Work
As discussed above, many works have discussed notions of calibration for multi-class prediction.
These either offer limited expressiveness, or require super-polynomial runtime or sample com-
plexities. We further elaborate on two recent works [ZKS+21, DKR+22] that achieve polyno-
mial sample complexity, but suffer from computational intractability. We also discuss the work of
[GKSZ22, KLST23, NRRX23].
Perhaps the most closely related work to ours is Zhao et al.’s [ZKS+21] work on decision
calibration. They imagine a down-stream decision maker using the predictions to choose between a
finite set of actions, subject to a loss function that depends only on the action and on the outcome.
The predicted distribution should be indistinguishable from the true distribution in terms of the
loss experienced by the decision maker (and this should hold for any such decision maker and any
loss function). We view this as an expressive calibration notion: in particular, even if we only allow
for two possible actions, decision calibration (see Definition 2.3) guarantees a sharp flavor of subset
calibration: for any subset T ⊆ [k] and any threshold b ∈ [0,1], conditioning on instances where the
predictor assigns total probability at least b to the set T, the probability that the outcome lands
in T is at least b (up to a small error).4 They showed that this strong guarantee can be obtained
using only poly(k) samples. We show, however, that the runtime complexity of obtaining decision
calibration cannot be poly(k) (assuming the hardness of refuting random CSPs). Intuitively, the
hardness is due to the “sharpness” of the guarantee: conditioning on the event that the probability
of T is exactly above the threshold b. This has the flavor of a halfspace learning guarantee, and
this underlies our intractability result. In contrast, our notion of projected smooth calibration
(and our results on sigmoids) enforces a “softer” Lipschitz condition, which makes the problem
computationally tractable and allows us to construct efficient algorithms. On a more technical
level, Zhao et al. [ZKS+21] require solving an optimization problem over the class of halfspaces.
Noting that the objective is not differentiable, they present a heuristic gradient-based algorithm
after relaxing the hard halfspace threshold using a differentiable sigmoid function. They allow the
Lipschitzconstantofthesigmoidfunctiontogrowarbitrarilylargeinordertorecoverthehalfspaces
in the limit. However, they do not provide a provable guarantee on the correctness or efficiency
4Theguaranteeisevenstronger: theconditionalexpectationofthepredictionsandtheoutcomesshouldbeclose.
7of their algorithm. We show that such guarantees are unlikely to be established due to inherent
intractability of the problem (see above and in Section 5).
In their work on outcome indistinguishability “beyond Bernoulli”, Dwork et al. [DKR+22] also
study meaningful predictions over non-Boolean outcome spaces. Their notion of Generative OI
guaranteesindistinguishabilityforarichclassofdistinguishersthatcanexaminethepredictionand
alsofeaturesoftheparticularinstance. Thisisquiteexpressive,andinparticular,byformulatingan
appropriate class of distinguishers, their framework can capture all notions considered in this work.
Their most general algorithm, for an outcome space of size k and a (finite) class of distinguishers
A, requires sample complexity that is logarithmic in k and in |A|. The runtime is at least linear in
the number of distinguishers |A|. Guaranteeing subset calibration would require (at least) exp(k)
distinguishers, so while their algorithm would be sample-efficient, its runtime is exponential in k.
The work of [GKSZ22] formulated the general notion of weighted calibration that we use. Their
focus is on a particular instantiation of this notion they call low degree calibration, where the
weight family is P(d,1)k, where P(d,1) contains all degree d polynomials in v with absolute values
of coefficients summing to 1. They do not consider the downstream calibration guarantees for
binary classification tasks, rather their focus is on multicalibration and multigroup fairness. They
present an auditing algorithm that runs in time O(kd). We show that by using kernel methods,
one can obtain an auditor with running time poly(k,d) (Lemma 6.4).
Recently, [KLST23] and [NRRX23] studied relaxations of canonical calibration and gave algo-
rithms for achieving them in the online setting. Similar to our work, they were motivated by giving
meaningful guarantees for downstream tasks while avoiding the inefficiency inherent in canonical
calibration. However, theirgoalistomakecalibratedpredictions, whichischallengingintheonline
setting, but becomes trivial in our offline setting (the constant predictor that always outputs the
expectation of D’s outcomes is calibrated). Therefore, we focus instead on the auditing task of
post-processing a given predictor. This auditing task is also considered in [NRRX23], which gives
online algorithms with running time growing polynomially with the size of the family of weight
functions. We study the offline setting, where achieving running time that is linear in the size of
the family of weight functions follows from [GKSZ22], and our focus is on achieving polynomial
running time even when the family of weight functions is exponential or infinite.
As in the standard setup of calibration, each prediction is a probability distribution over the
possible labels. This distribution conveys the uncertainty of the predictor about the true label,
and calibration can be viewed as a guarantee of accurate uncertainty quantification. Another
common method for uncertainty quantification is conformal prediction (see e.g. [SV08, AB21]),
where the predictor outputs prediction sets (sets of labels) aiming to provide a coverage guarantee:
the true label belongs to the prediction set with a certain, pre-specified probability. A recent line
of work applies techniques from multicalibration to get robust conformal prediction algorithms
that give coverage guarantees that hold not just on average, but conditionally on every important
subpopulation and beyond [GJN+22, BGJ+22, JNRR23].
1.3 Organization
The rest of the paper is organized as follows. We start by defining old and new notions of multi-
class calibration and discussing the connections among them in Section 2. We prove an exponential
sample complexity lower bound for canonical calibration in Section 3. We define the auditing
task and show a tight connection to agnostic learning in Section 4. We apply the connection
to show hardness of auditing for decision calibration and halfspaces in Section 5. We describe a
8general kernel method for auditing in Section 6 and apply it to give efficient auditors for projected
smooth calibration and sigmoid calibration in Section 7. We show barriers to further improving
the efficiency of our algorithms by proving additional computational lower bounds in Section 8.
2 Multi-Class Calibration
In this section, we discuss prior notions of multi-class calibration as well as their relationships,
strengths, and drawbacks. We show that prior notions lack either expressivity or efficiency, and we
introduce new notions to achieve a better balance between the two desiderata.
For a classification task with k categories, we use E = {e ,...,e } to denote the set of one-hot
k 1 k
encodings of the categories. Here each e is the unit vector in Rk with the i-th coordinate being 1.
i
Throughout the paper, we use boldface letters to represent vectors in Rk. For a vector v ∈ Rk,
we use v(j) ∈ R to denote its j-th coordinate for every j = 1,...,k. We use ∆ to denote the set
k
of all vectors v ∈ Rk such that v(j) ≥ 0 for every j = 1,...,k and v(1)+···+v(k) = 1.
For a set X of individuals, a predictor is a function p : X → ∆ that assigns every individual
k
x ∈ X a prediction vector v = p(x) ∈ ∆ , where each coordinate v(j) is the predicted probability
k
that the label of x falls in the j-th category.
Canonical Calibration. Foraground-truthdistributionD oflabeledexamples(x,y) ∈ X×E ,
0 k
we say a predictor p : X → ∆ satisfies (perfect) canonical calibration if
k
E [y|p(x) = v] = v for every v ∈ ∆ .
k
(x,y)∼D0
A simple but important observation is that the above definition only depends on the distribution of
(p(x),y) ∈ ∆ ×E . As a consequence, we obtain the following simplified but equivalent definition:
k k
Definition 2.1. We say a distribution D of (v,y) ∈ ∆ ×E satisfies (perfect) canonicalcalibration
k k
if
E [y|v] = v.
(v,y)∼D
In the definition above, we work with a distribution D of (v,y) ∈ ∆ without explicitly stating
k
that it is the distribution of (p(x),y) where (x,y) comes from the ground-truth distribution D ,
0
and p is a predictor. We will use this convention throughout the paper.
It is folklore that the sample complexity of determining whether a distribution D satisfies
perfect canonical calibration grows exponentially in k. In Section 3, we prove a stronger result
(Theorem 3.2), showing that distinguishing whether a distribution D satisfies perfect canonical
calibration or it is Ω(1)-far from canonical calibration (in ℓ distance) requires sample complexity
1
exponential in k.
Weighted Calibration. Due to the sample inefficiency of canonical calibration, many previous
works considered relaxations of canonical calibration such as confidence calibration and top-label
calibration. These notions can be framed as special cases of a general notion called weighted
calibration studied in [GKSZ22]:
9Definition 2.2 (Weighted calibration [GKSZ22]). Let W : ∆ → [−1,1]k be a family of weight
k
functions. We define the W-calibration error of a distribution D of (v,y) ∈ ∆ ×E as
k k
(cid:12) (cid:12)
(cid:12) (cid:12)
CE W(D) = sup (cid:12) E [⟨y−v,w(v)⟩](cid:12).
w∈W(cid:12)(v,y)∼D (cid:12)
We say that D is (W,α)-calibrated if CE (D) ≤ α. 5
W
If a distribution D satisfies perfect canonical calibration, then it is (W,0)-calibrated for any
class W. When the class W consists of all functions w : ∆ → [−1,1]k, (W,0)-calibration becomes
k
equivalent to perfect canonical calibration.
Class-wise, Confidence, and Top-label Calibration. The notion of weighted calibration
is very general. By choosing the class W appropriately, it recovers many concrete notions of
calibration.
Class-wise calibration [KPNK+19] is the following requirement:
E [y(ℓ)|v(ℓ)] = v(ℓ) for every ℓ = 1,...,k.
(v,y)∼D
This is equivalent to (W,0)-calibration where W consists of all functions w mapping v ∈ ∆ to
k
w(v) = ϕ(v(ℓ))e for every ϕ : [0,1] → [−1,1] and ℓ = 1,...,k.
ℓ
Confidencecalibration [GPSW17]isalso aspecial caseofweightedcalibration. Foranyv ∈ ∆ ,
k
let ℓ denote the coordinate ℓ ∈ {1,...,k} that maximizes v(ℓ). Confidence calibration is the
v
following requirement:
E [y(ℓv)|v(ℓv)] = v(ℓv).
(v,y)∼D
This is equivalent to (W,0)-calibration where W consists of all functions w mapping v ∈ ∆ to
k
w(v) = ϕ(v(ℓv))e for every ϕ : [0,1] → [−1,1].
ℓv
Top-label calibration [GR22] is defined to be the following requirement:
E [y(ℓv)|v(ℓv),ℓ ] = v(ℓv).
v
(v,y)∼D
This is equivalent to (W,0)-calibration where W consists of all functions w mapping v ∈ ∆ to
k
w(v) = ϕ(v(ℓv),ℓ v)e
ℓv
for every ϕ : [0,1]×{1,...,k} → [−1,1].
Decision Calibration. A drawback of class-wise, confidence, and top-label calibration is that
they do not imply good calibration performance if the predictions are used for downstream tasks.
To improve the expressivity while avoiding the exponential sample complexity of canonical cali-
bration, [ZKS+21] introduced the notion of decision calibration, where they studied downstream
loss-minimizationtasksofdecidingwhichactiontochooseamongafixedsetofactionsbasedonthe
predictions. We focus on the special case of two actions, where the definition of decision calibration
is as follows:
5Theoriginaldefinitionin[GKSZ22]waspresentedinthemoregeneralcontextofmulticalibration. Theirdefinition
allows for weight families whose range is [0,1]k rather than [−1,1]k, but this is a technical issue.
10Definition 2.3 (Decision Calibration [ZKS+21]). For a distribution D of (v,y) ∈ ∆ ×E , the
k k
decision calibration error of D is defined to be 6
decCE(D) := sup ∥(y−v)I(⟨a,v⟩ > b)∥ +∥(y−v)I(⟨a,v⟩ ≤ b)∥ .
2 2
a∈Rk,b∈R
Equivalently, this is the weighted calibration error CE (D), where W consists of functions mapping
W
v toI(⟨a,v⟩ > b)g+I(⟨a,v⟩ > b)g′ ∈ Rk foreverya ∈ Rk,b ∈ R, andg,g′ ∈ Rk satisfying∥g∥ ≤ 1,
2
∥g′∥ ≤ 1.
2
The work of [ZKS+21] showed that decision calibration ensures a desirable indistinguishability
property for downstream loss minimization tasks, demonstrating the expressivity of the notion.
However, we show that decision calibration is a computationally inefficient notion. Here, efficiency
is evaluated on the auditing task (defined formally in Section 4), where the goal is to recalibrate a
given mis-calibrated predictor while reducing its squared loss. [ZKS+21] showed that auditing for
decision calibration has sample complexity polynomial in k, improving over the exponential sam-
ple complexity of canonical calibration, but they fell short of proving a computational efficiency
guarantee. Instead, they provided a heuristic algorithm for the auditing task without correctness
or running time analyses. Our computational hardness results in Section 5 show that under stan-
dard complexity-theoretic assumptions, there is no poly(k)-time algorithm for auditing decision
calibration.
Smooth Calibration. We now introduce new notions of multi-class calibration inspired by a
recent theory of [BGHN23] on calibration measures in the binary setting.
Consider the downstream binary prediction task of predicting whether the true label belongs
to a set T ⊂ [k] of labels. Let a := 1 ∈ {0,1}k denote the indicator of the subset T. Given the
T
distribution D of (v,y), the predicted probability of this event is ⟨1 ,v⟩ while the true label is
T
given by ⟨1 ,y⟩. A natural approach to defining calibration notions for the multi-class setting is
T
to seek good calibration guarantees for every such binary prediction tasks.
A well studied notion of calibration for binary classification is the notion of smooth calibration
[KF08, FH18]. A key advantage of this notion is that it is robust to perturbations of the predictor,
unlike notions such as ECE. More recently, it plays a central role in the the work of [BGHN23]
and their theory of consistent calibration measures for binary classification. At a high level, these
are calibration measures that are polynomially related to the (earthmover) distance to the closest
perfectly calibrated predictor. Applying the notion of smooth calibration error to the downstream
binary prediction tasks for subsets T ⊆ [k], we get the following definition:
Definition 2.4 (Subset Smooth Calibration). Let Lip be the class of 1-Lipschitz functions ϕ :
[0,1] → [−1,1]. For a distribution D of (v,y) ∈ ∆ ×E , we define the smooth calibration error of
k k
6The original definition of decision calibration in [ZKS+21] takes a slightly different form:
decCE(D):= sup ∥(y−v)I(⟨r,v⟩>⟨r′,v⟩)∥ +∥(y−v)I(⟨r,v⟩≤⟨r′,v⟩)∥ .
2 2
r,r′∈Rk,b∈R
Here ⟨r,v⟩ (resp. ⟨r′,v⟩) is the expected loss of taking action 1 (resp. action 2) over the randomness in an outcome
y ∈ E distributed with mean v. In fact Definition 2.3 is equivalent to this definition. For any v ∈ ∆ , the sum
(cid:98) k k
of the coordinates of v is 1, i.e., ⟨1,v⟩ = 1, where 1 is the all-ones vector. Therefore, in Definition 2.3, we have
I(⟨a,v⟩>b)=I(⟨a−b1,v⟩>0), and thus restricting b=0 does not change Definition 2.3. Under this restriction,
the equivalence between the two definitions follows by taking a=r−r′.
11D on the subset T to be
smCE (D) = sup E[(⟨1 ,y⟩−⟨1 ,v⟩)ϕ(⟨1 ,v⟩)]
T T T T
ϕ∈LipD
= sup E[⟨1 ,y−v⟩ϕ(⟨1 ,v⟩)].
T T
ϕ∈LipD
We define the subset smooth calibration error of D as
ssCE(D) = sup smCE (D).
T
T⊆[k]
More generally, for m ≥ 0, we define the m-subset smooth calibration error of D as
ssCE (D) = sup smCE (D).
m T
T⊆[k],|T|≤m
Note that we can define subset smooth calibration as a special case of weighted calibration. We
define W to be the set of all functions w : ∆ → [−1,1]k such that there exist T ⊆ [k] and
m-ss k
ϕ ∈ Lip satisfying |T| ≤ m and w(v) = 1 ϕ(⟨1 ,v⟩) for every v ∈ ∆ . Then
T T k
ssCE (D) = CE (D).
m Wm-ss
Inthebinarysetting,aresultof[BGHN23]showsthatthesmoothcalibrationerrorispolynomi-
ally related to the (earthmover) distance to the nearest perfectly calibrated predictor. Therefore,
a small subset smooth calibration error in our multi-class setting implies that for every subset
T ⊆ [k], the prediction ⟨1 ,v⟩ is close to perfect calibration for the corresponding downstream
T
binary prediction task.
Having demonstrated the expressivity of subset smooth calibration, we move on to establish its
efficiency. The main algorithmic result of our paper is that auditing for subset smooth calibration
can be achieved in time polynomial in k (for any fixed error parameter α, see Section 4 for formal
definition of auditing). That is, subset smooth calibration simultaneously achieves strong expres-
sivity and computational efficiency. In fact, the efficiency of our auditing algorithm extends to a
more expressive notion which we call projected smooth calibration, where we generalize indicators
of sets that are vectors in {0,1}k to allow vectors in [−1,1]k.
Definition 2.5 (Projected Smooth Calibration). For m ≥ 0, let H denote the set of all
m-pLip
functions h : ∆ → [−1,1] such that there exist ϕ ∈ Lip and a ∈ [−1,1]k with ∥a∥2 ≤ m satisfying
k 2
h(v) = ϕ(⟨a,v⟩) for every v ∈ ∆ .
k
Define the m-projected smooth calibration error as
psCE (D) = CE (D).
m Hk
m-pLip
In measuring psCE, we audit each coordinate i ∈ [k] using a distinct function h(i) ∈ H .
m-pLip
We also consider a further strengthening of projected smooth calibration by allowing arbitrary
ℓ -Lipshcitz functions in each coordinate:
1
12Definition2.6(FullSmoothCalibration). LetH denotethesetofallfunctionsh : ∆ → [−1,1]
fLip k
such that
|h(v)−h(v′)| ≤ (cid:13) (cid:13)v−v′(cid:13) (cid:13)
1
for every v,v′ ∈ ∆ k.
Define the full smooth calibration error of a distribution D of (v,y) ∈ ∆ ×E as
k k
fsCE(D) = CE (D).
Hk
fLip
Lemma 2.7. For any m ≥ 0, for any distribution D of (v,y) ∈ ∆ ×E ,
k k
ssCE (D) ≤ psCE (D) ≤ fsCE(D).
m m
Proof. To prove the first inequality, let T ⊂ [k] be the set of size bounded by m that maximizes
smCE (D), and ϕ ∈ Lip the Lipschitz function that witnesses it, so that
T
ssCE (D) = E[⟨1 ,y−v⟩ϕ(⟨1 ,v⟩)] = E[⟨ϕ(⟨1 ,v⟩)1 ,y−v⟩].
m T T T T
D D
We define the auditor function w ∈ Hk where
m-pLip
(cid:40)
ϕ(⟨1 ,v⟩) for i ∈ T
w(i)(v) = 1 ϕ(⟨1 ,v⟩) = T
T T
0 otherwise
Hence
psCE (D) = max E[⟨y−v,w′(v)⟩]
m
w′∈Hk D
m-pLip
≥ E[⟨y−v,w(v)⟩]
D
= ⟨y−v,1 ⟩ϕ(⟨1 ,v⟩)
T T
= ssCE (D).
m
The second inequality is implied by the inclusion H ⊆ H . To prove this inclusion, note
m-pLip fLip
that for any function h ∈ H , there exists ϕ ∈ Lip,a ∈ [−1,1]k such that h(v) = ϕ(⟨a,v⟩) for
m-pLip
every v ∈ ∆ . We have
k
|h(v)−h(v′)| = |ϕ(⟨a,v⟩)−ϕ(⟨a,v′⟩)|
≤ |⟨a,v⟩−⟨a,v′⟩|
= |⟨a,v−v′⟩|
≤ ∥a∥
(cid:13) (cid:13)v−v′(cid:13)
(cid:13)
∞ 1
≤
(cid:13) (cid:13)v−v′(cid:13)
(cid:13)
1
where the first inequality uses the Lipschitz property of ϕ. This shows h ∈ H , which completes
fLip
the proof.
In Section 7 we show that both subset smooth calibration and projected smooth calibration
allow efficient auditing, whereas in Theorem 3.4 we show that full smooth calibration requires
sample complexity exponential in k.
133 Sample Complexity of Canonical Calibration
The main goal of this section is to prove that distinguishing whether a distribution D of (v,y) sat-
isfies perfect canonical calibration or D is far from canonical calibration requires sample complexity
exponential in k.
We use the following definition of distance to canonical calibration, generalizing the lower
distance to calibration in [BGHN23] from the binary setting to the multi-class setting.
Definition 3.1 (DistancetoCanonicalCalibration). Consider a distribution D of (v,y) ∈ ∆ ×E .
k k
Wedefineext(D)tobethesetofdistributionsΠof(u,v,y)wherethemarginaldistributionof(v,y)
is D, and the marginal distribution of (u,y) satisfies perfect canonical calibration. We define the
distance to calibration, denoted by dCE(D), as follows:
dCE(D) := inf E∥u−v∥ .
1
Π∈ext(D)Π
Here is our sample complexity lower bound:
Theorem 3.2. Let A be an algorithm that takes examples (v ,y ),...,(v ,y ) ∈ ∆ ×E drawn
1 1 n n k k
i.i.d. from a distribution D as input, and outputs “accept”or “reject”. Assume that for any dis-
tribution D satisfying perfect canonical calibration, algorithm A outputs “accept” with probability
at least 2/3. Also, for some α > 0, assume that for any distribution D satisfying dCE(D) ≥ α,
algorithm A outputs “reject” with probability at least 2/3. Then for some absolute constants k > 0
0
and c > 0, assuming k ≥ k , we have n ≥ (c/α)(k−1)/2.
0
To prove Theorem 3.2, we use the following lemma to connect the distance to canonical cali-
bration dCE(D) with the full smooth calibration error fsCE(D).
Lemma 3.3. For any distribution D over ∆ ×E , fsCE(D) ≤ 4dCE(D).
k k
Proof. Consider any function w ∈ Hk and any distribution Π ∈ ext(D). By the definition of
fLip
Hk , for any u,v ∈ ∆ , we have
fLip k
∥w(u)−w(v)∥ ≤ ∥u−v∥ . (1)
∞ 1
By the definition of ext(D), for (u,v,y) ∼ Π, the distribution of (u,y) satisfies perfect canonical
calibration, and thus
E[⟨y−u,w(u)⟩] = 0. (2)
Π
Therefore,
E[⟨v−y,w(v)⟩] ≤ |E[⟨v−y,w(v)−w(u)⟩]|+E[⟨v−y,w(u)⟩]
D Π Π
≤ 2E∥u−v∥ +E[⟨v−y,w(u)⟩] (by (1))
1
Π Π
= 2E∥u−v∥ +E[⟨v−u,w(u)⟩] (by (2))
1
Π Π
≤ 4E∥u−v∥ ,
1
Π
where the last inequality holds because ∥w(u)∥ ≤ 1. The proof is completed by taking supremum
∞
over w ∈ Hk and infimum over Π ∈ ext(D).
fLip
14By Lemma 3.3, Theorem 3.2 is a direct corollary of the following theorem which gives a sample
complexity lower bound for distinguishing perfect canonical calibration from having a large full
smooth calibration error:
Theorem 3.4. Let A be an algorithm that takes examples (v ,y ),...,(v ,y ) ∈ ∆ ×E drawn
1 1 n n k k
i.i.d. from a distribution D as input, and outputs “accept”or “reject”. Assume that for any dis-
tribution D satisfying perfect canonical calibration, algorithm A outputs “accept” with probability
at least 2/3. Also, for some α > 0, assume that for any distribution D satisfying fsCE(D) ≥ α,
algorithm A outputs “reject” with probability at least 2/3. Then for some absolute constants k > 0
0
and c > 0, for all k ≥ k we have n ≥ (c/α)(k−1)/2.
0
Our proof of Theorem 3.4 starts with the following lemma which can be proved by a standard
greedy algorithm:
Lemma 3.5. There exist absolute constants c > 0 and k > 0 with the following property. For any
0
positive integer k > k and any ε > 0, there exists a set V ⊆ ∆ with the following properties:
0 k
1. |V| ≥ (c/ε)k−1;
2. ∥v −v ∥ ≥ ε for any distinct v ,v ∈ V;
1 2 1 1 2
3. ∥v−e ∥ ≥ 1/3 for any v ∈ V and i ∈ {1,...,k}.
i 1
Proof. The lemma can be proved by a simple greedy algorithm. Let us start with V = ∅ and
repeat the following step: if there exists v′ ∈ ∆ such that ∥v′ −v∥ ≥ ε for every u ∈ U and
k 1
∥v′−e ∥ ≥ 1/3 for every i = 1,...,k, we add v′ to V. We repeat the step until no such v′ exists
i 1
to obtain the final V. Clearly, V satisfies properties 2 and 3 required by the lemma. It remains to
prove that V also satisfies property 1.
ConsiderthefinalV intheprocessofthealgorithm. Foranyv ∈ V, considerasetS consisting
v
of all points s ∈ Rk−1 such that ∥s−v| ∥ ≤ ε. Similarly, for every i = 1,...,k, consider a
1,...,k−1 1
set S consisting of all points s ∈ Rk−1 such that ∥s−e | ∥ ≤ 1/3. Also, consider the set S
i i 1,...,k−1 1
consistingofallpointss ∈ Rk−1 suchthat∥s∥ ≤ 1. IfS\(((cid:83) S )∪((cid:83)k S ))isnon-empty,then
≥0 1 v∈V v i=1 i
wecantakeanysinthatsetandconstructavectorv′ = (s(1),...,s(k−1),1−s(1)−···−s(k−1)) ∈ ∆ .
k
Since s ∈/ S , it is easy to see that ∥v′ −v∥ > ε for every v ∈ V. Similarly, ∥v′ −e ∥ > 1/3 for
v 1 i
every i = 1,...,k. Therefore, the iterative steps of the algorithm can be continued. For the final
V, it must hold that S\(((cid:83) S )∪((cid:83)k S )) is empty. The volume of each S is (2ε)k−1 times
v∈V v i=1 i v
the volume of S, and the volume of each S is (2/3)k−1 times the volume of S. Therefore,
i
(2ε)k−1|V|+(2/3)k−1k ≥ 1.
When k is sufficiently large, we have (2/3)k−1k ≤ 1/2, in which case |V| ≥ (1/2)(1/(2ε))k−1 ≥
(c/ε)k−1, where the last inequality holds whenever k is sufficiently large and c > 0 is sufficiently
small.
In the lemma below, we use the set V from Lemma 3.5 to construct candidate distributions
with large full smooth calibration error. Later in Lemma 3.7 we combine these distributions to
achieveindistinguishabilityfromadistributionwithnocalibrationerror,unlessgivenatleastexp(k)
examples.
15Lemma 3.6. For a sufficiently large positive integer k and ε ∈ (0,1/2), let V ⊆ ∆ be the set
k
guaranteed by Lemma 3.5. For a function w : V → E , define distribution D of (v,y) ∈ V ×E
k w k
such that v is distributed uniformly over V and y = w(v). Then fsCE(D ) ≥ ε/12.
w
Proof. For any v ∈ V, by property 3 in Lemma 3.5 and the fact that w(v) ∈ {e ,...,e }, we have
1 k
∥v−w(v)∥ ≥ 1/3. Since v ∈ ∆ and w(v) ∈ E , we can separately consider the unique non-zero
1 k k
coordinate of w(v) and the other zero coordinates to get
1/3 ≤ ∥v−w(v)∥ = (1−⟨v,w(v)⟩)+⟨v,1−w(v)⟩ = 2(1−⟨v,w(v)⟩),
1
where 1 ∈ Rk is the all-ones vector. Therefore, ⟨w(v)−v,w(v)⟩ = (1−⟨v,w(v)⟩) ≥ 1/6, and thus
E [⟨y−v,w(v)⟩] ≥ 1/6.
(v,y)∼Dw
To complete the proof, it remains to show that w is (2/ε)-Lipschitz over V (we can then extend
w to a (2/ε)-Lipschitz function over ∆ by standard construction). For any distinct v,v′ ∈ V, we
k
have
∥w(v)−w(v′)∥ ≤ ∥w(v)−w(v′)∥ ≤ 2 ≤ (2/ε)∥v−v′∥ ,
∞ 1 1
where the last inequality uses property 2 in Lemma 3.5.
Lemma 3.7. Let A be any algorithm that takes (v ,y ),...,(v ,y ) ∈ V×E as input, and outputs
1 1 n n k
“accept” or “reject”. Let p be the acceptance probability when we first draw v independently
1 i
and uniformly from V, and then draw each y independently with E[y ] = v . Let p be the
i i i 2
acceptance probability where we first draw w : V → E such that for every v ∈ V, w(v) is distributed
k
independently with mean v, and then draw each (v ,y ) independently from D . Then,
i i w
|p −p | ≤ O(n2/|V|).
1 2
Proof. Assume without loss of generality that n < |V|. Let p denote the acceptance probability
3
when we first draw v ,...,v uniformly from V without replacement, and then draw each y ∈ E
1 n i k
independently with mean v . We relate p and p to p as follows.
i 1 2 3
Suppose we first draw each v independently and uniformly from V, and then draw each y
i i
independently with E[y ] = v . The probability that v ,...,v are distinct is
i i 1 n
p := (1−1/|V|)···(1−(n−1)/|V|) ≥ 1−1/|V|−···−(n−1)/|V| ≥ 1−O(n2/|V|).
4
Conditionedonthatevent,theacceptanceprobabilityisexactlyp . Conditionedonthecomplement
3
of that event, the acceptance probability is bounded in [0,1]. Therefore,
p p ≤ p ≤ p p +(1−p ).
3 4 1 3 4 4
Similarly, we can show that
p p ≤ p ≤ p p +(1−p ).
3 4 2 3 4 4
Combining these inequalities, we get |p −p | ≤ 1−p ≤ O(n2/|V|).
1 2 4
Proof of Theorem 3.4. Consider the set V from Lemma 3.5 where we choose ε to be 12α. If D is
the distribution of (v,y) ∈ V ×E where v is chosen uniformly at random from V and E[y|v] = v,
k
then algorithm A outputs “accept” with probability at least 2/3. If D is D for some w : V → E ,
w k
then by Lemma 3.6, algorithm A outputs “accept” with probability at most 1/3.
(cid:112) (cid:112)
By Lemma 3.7, we have n ≥ Ω( |V|). By Property 1 in Lemma 3.5, we get n ≥ Ω( |V|) ≥
(c/α)(k−1)/2 for a sufficiently small absolute constant c > 0 assuming k is sufficiently large.
164 Auditing for Weighted Calibration and Agnostic Learning
In this section, we study the sample and computational complexity of weighted calibration (Def-
inition 2.2), where the complexity is measured in an auditing task we define below. Specifically,
for any weight family W, we show an equivalence between the auditing task and the well-studied
agnosticlearningtaskinthelearningtheoryliterature. Thisequivalenceallowsustoestablishboth
computational lower bounds and efficient algorithms for specific weight families W in Sections 5
to 8.
Auditing for weighted calibration. The notion of weighted calibration gives rise to a natural
decision problem, which we call the decision version of auditing calibration: given a predictor p,
can we decide whether or not it is (W,α) calibrated? In the event that p is not calibrated, we
would ideally like to post-process its predictions to get a new predictor κ(p) for κ : ∆ → ∆ , so
k k
that κ(p) is (W,α)-calibrated. This post-processing goal needs to be formulated carefully, since
one can always get perfect calibration using a trivial predictor that constantly predicts E[y]. A
natural formulation that avoids such trivial solutions is to require that the post-processing does
not harm some measure of accuracy such as the expected squared loss of p.
One can achieve both these goals by solving a search problem which we call auditing with a
witness defined below.
Definition 4.1 (Auditing with a witness). An (α,β) auditor for W is an algorithm that when
given access to a distribution D where CE (D) > α returns a function w′ : ∆ → [−1,1]k (which
W k
need not belong to W) such that
E [⟨y−v,w′(v)⟩] ≥ β. (3)
(v,y)∼D
Concretely, the auditor takes i.i.d. examples (v ,y ),...,(v ,y ) drawn from D, and the output
1 1 n n
function w′ should satisfy the inequality above with probability at least 1−δ over randomness in the
examples and the auditor itself, where δ ∈ (0,1/3) is the failure probability parameter.
As demonstrated in previous work (for instance [HKRR18, GKSZ22]), a solution to this search
problem allows us to solve both the decision problem of auditing for calibration, and in the case
when p is not (W,α)-calibrated, we can use the witness to post-process p and produce a predictor
κ(p) with lower squared loss, that is (W,α)-calibrated.
Lemma 4.2. Given a predictor p : X → ∆ and access to an (α,β)-auditor for W, there is an
k
algorithm that computes a post-processing function κ : ∆ → ∆ so that κ(p) is (W,α)-calibrated
k k
and its squared loss is not larger than that of p. The algorithm uses at most O(k/β2) calls to the
(α,β)-auditor.
Proof. We start off with p = p. If p is not (W,α)-calibrated, then the auditor produces w′
0
satisfying Equation (3). Following the proof of [GKSZ22, Lemma 33], we can now update p to κ(p)
using w′ so that we get a decrease in the expected squared loss:
E[∥κ(v)−y∥2] ≤ E[∥v−y∥2]−Ω(β2/k).
2 2
Note that the squared loss is bounded in the interval [0,4] because ∥v−y∥ ≤ ∥v∥ +∥y∥ ≤
2 2 2
∥v∥ +∥y∥ ≤ 2. Thus by repeatedly using the auditor and applying the update at most O(k/β2)
1 1
times, we can eventually achieve (W,α) calibration with decreased expected squared loss.
17We make some observations about the role that the different parameters α,β and W play in
the complexity of auditing with a witness.
• Auditing becomes easier for smaller β. The β parameter affects the running time, but not the
final calibration guarantee. Thus an (α,β/10) auditor will result in the same guarantee as an
(α,β) auditor, but at the cost of more iterations. Since we are interested in the question of
whether auditing can be done in time poly(k) versus exp(k), we do not optimize too much
for β, and are fine with losing polynomial factors in it.
• In contrast, auditing gets harder for smaller α, since the auditor is required to detect smaller
violations of calibration. The final guarantee is also much more sensitive to α: a (2α,β)
auditor can only be used to guarantee (W,2α) calibration, but not (W,α) calibration.
• The complexity of auditing increases as the the weight function family becomes larger. If
W ⊆ W , then an (α,β)-auditor for W is also an (α,β)-auditor for W , since CE (D) ≥
1 2 2 1 W2
CE (D) so the auditor is guaranteed to produce a witness whenever p is not (W ,α)-
W1 1
calibrated. ItmighthappenthatCE (D) ≤ α whereasCE (D) > α. Insuchascenario, an
W1 W2
auditorforW willstillfindawitnesstomiscalibration. Thisisnotrequiredbyourdefinition
2
of auditor for W , but it is allowed.
1
Agnostic learning. We understand the complexity of auditing for multiclass calibration by
connecting it to the well-studied problem of agnostic learning in the standard binary classification
setting. For a distribution U of (v,z) ∈ ∆ ×[−1,1] and a class H of functions ∆ → [−1,1], we
k k
define
Opt(H,U) := sup|E[h(v)z]|.
h∈H
Definition 4.3 (Weak agnostic learner). [BLM01, KMV08] Let α ≥ β ∈ [0,1]. An (α,β) agnostic
learner for H is an algorithm that when given sample access to a distribution U over ∆ ×[−1,1]
k
such that Opt(H,U) ≥ α returns h′ : ∆ → [−1,1] such that
k
E [h′(v)z] ≥ β.
(v,z)∼U
Moreconcretely, thelearnertakesi.i.d.examples(v ,z ),...,(v ,z )drawnfromU, andtheoutput
1 1 n n
function h′ should satisfy the inequality above with probability at least 1−δ over randomness in the
examples and the learner itself, where δ ∈ (0,1/3) is the failure probability parameter.
Similarly to auditing, the strength of an agnostic learner is more sensitive to the α parameter
than the β parameter. Known results on agnostic boosting [KMV08, Fel10, KK09] show that the
existence of an (α,β)-weak agnostic learner implies the existence of an strong agnostic learner
with polynomially increased time and sample complexity depending on 1/β (see the citations for a
precise statement).
In the rest of the section we present our main result connecting the agnostic learning task for
a class H and the auditing task for Hk.
184.1 Auditing from Agnostic Learning
Theorem 4.4. Given an (α/3,β) weak agnostic learner for H with sample complexity n , running
0
time T and failure probability parameter δ/2, we can construct an (α,αβ/6k) auditor for Hk with
0
sample complexity n = O(kn /α+k2α−2β−2log(k/δ)), time complexity O(kT +kn), and failure
0 0
probability parameter δ.
Anaturalideaforprovingthetheoremaboveistoapplytheagnosticlearneroneachcoordinate
of the residual z := y−v in the auditing task. Specifically, in the auditing task, we assume
E[⟨z,w(v)⟩] = E[⟨y−v,w(v)⟩] > α
for some w ∈ Hk. Expressing w(v) as (w(1)(v),...,w(k)(v)) where each w(j) ∈ H, we have
k
(cid:88)
E[z(j)w(j)(v)] > α,
j=1
which implies that there exists j ∈ {1,...,k} such that
E[z(j)w(j)(v)] > α/k. (4)
If we only use (4), we would need an (α/k,β) agnostic learner to prove Theorem 4.4, but we only
have an (α/3,β) agnostic learner.
To avoid the loss of a factor of k, we define z in a better way that leverages the fact that
y,v ∈ ∆ . Specifically, we note that the vector 1(y−v) has ℓ norm at most 1, and thus it is the
k 2 1
mean of a distribution over E ∪(−E ). Given y and v, we draw z randomly from that distribution.
k k
We have
E[⟨z,w(v)⟩] = E[⟨(y−v)/2,w(v)⟩] > α/2.
Given z ∈ E
k
∪(−E k), we use ℓ
z
∈ [k] to denote the unique index such that z(ℓz) ̸= 0. We have
⟨z,w(v)⟩ = z(ℓz)w(ℓz)(v) and thus
E[z(ℓz)w(ℓz)(v)] > α/2.
Therefore, there exists j ∈ {1,...,k} such that
E[z(j)w(j)(v)|ℓ = j] > α/2 > α/3.
z
This allows us to use an (α/3,β) agnostic learner.
Proof of Theorem 4.4. Intheauditingtask,weassumethattheinputdatapoints(v ,y )aredrawn
i i
i.i.d. from a distribution D satisfying
E [⟨y−v,w(v)⟩] > α for some w ∈ Hk. (5)
(v,y)∼D
Given (v,y) drawn from D, we draw z randomly from E ∪(−E ) such that E[z|v,y] = (y−v)/2.
k k
This is possible because ∥y−v∥ ≤ 2. A concrete way to draw z is the following. With probability
1
1/2, we set z to be y ∈ E , and with the remaining probability 1/2, we draw z randomly from −E
k k
with expectation −v.
19Given z ∈ E ∪(−E ), we define a random variable ℓ ∈ {1,...,k} such that ℓ is the unique
k k z z
index satisfying z(ℓz) ̸= 0. For any w ∈ Hk, there exists w(1),...,w(k) ∈ H such that w(v) =
(w(1)(v),...,w(k)(v)) for every v ∈ ∆ . We have ⟨z,w(v)⟩ = z(ℓz)w(ℓz)(v) and thus (5) implies
k
E[z(ℓz)w(ℓz)(v)⟩] = E[⟨z,w(v)⟩] = E[⟨(y−v)/2,w(v)⟩] > α/2.
Let U denote the conditional distribution of (v,z(j)) ∈ ∆ ×E given ℓ = j. We have
j k k z
k
(cid:88)
Pr[ℓ = j] E [zw(j)(v)] > α/2. (6)
z
j=1
(v,z)∼Uj
Nowweshowthatthereexistsj ∈ {1,...,k}suchthatPr[ℓ = j] ≥ α/6k andE [zw(j)(v)] >
z (v,z)∼Uj
α/3. If this is not the case, then
k
(cid:88)
Pr[ℓ = j] E [zw(j)(v)]
z
j=1
(v,z)∼Uj
(cid:88) (cid:88)
= Pr[ℓ = j] E [zw(j)(v)]+ Pr[ℓ = j] E [zw(j)(v)]
z z
(v,z)∼Uj (v,z)∼Uj
j:Pr[ℓz=j]<α/6k j:Pr[ℓz=j]≥α/6k
≤ α/6+α/3
= α/2,
giving a contradiction with (6).
We have shown that there exists j∗ ∈ {1,...,k} and h ∈ H such that Pr[ℓ = j∗] ≥ α/6k
z
and E [zh(v)] > α/3. To solve the auditing task given examples (v ,y ),...,(v ,y ),
(z,v)∼U j∗ 1 1 n n
we first draw z ,...,z ∈ E ∪ (−E ) independently such that E[z |v ,y ] = y − v . Now
1 n k k i i i i i
(v ,y ,z ),...,(v ,y ,z ) are distributed independently from the joint distribution of (v,y,z).
1 1 1 n n n
For every j, we define I := {i ∈ {1,...,n} : ℓ = j}. If |I | ≥ n , we run the agnostic learner on
j zi j 0
thedatapoints((v ,z(j) )) toobtainafunctionh(j) : ∆ → [−1,1]. Wedefinew : ∆ → [−1,1]k
i i i∈Ij k j k
such that (w (v))(j′) = 0 if j′ ̸= j and (w (v))(j′) = h(j)(v) if j′ = j.
j j
When n = O(kn /α+k2α−2β−2log(1/δ)) is sufficiently large, with probability at least 1−δ/4,
0
(j)
we have |I | ≥ n . Conditioned on I , the data points ((v ,z )) are distributed indepen-
j∗ 0 j∗ i i i∈I j∗
dentlyfromD , andthusbytheguaranteeoftheagnosticlearner, withprobabilityatleast1−δ/2,
j∗
E
[zh(j∗)(v)]
≥ β,
(v,z)∼U j∗
which implies
E [⟨y−v,w (v)⟩] = 2Pr[ℓ = j∗] E [zh(j∗)(v)] ≥ αβ/3k.
j∗ z
(v,y)∼D (v,z)∼U j∗
We have thus shown that with probability at least 1−3δ/4, there exists j such that
E [(y−v)w (v)] ≥ αβ/3k.
j
(v,y)∼D
By estimating the values of E [⟨y−v,w (v)⟩] using O(α−2β−2k2log(k/δ)) fresh examples,
(v,y)∼D j
we can make sure that with probability at least 1−δ, we output a w˜ among the w ’s such that
j
E [⟨y−v,w˜(v)⟩] ≥ αβ/6k.
(v,y)∼D
204.2 Agnostic Learning from Auditing
NowweprovethereversedirectionofthereductionbyconstructinganagnosticlearnerforaclassH
usinganauditor(Theorem4.5). Forthemostgeneralstatement,insteadofconsideringtheauditing
task for Hk as in Theorem 4.4, we need to consider a slightly different class H˜k. But as long as H is
closed under coordinate-wise affine transformations of the inputs, we can choose H˜ to be the same
as H. In particular, when H is the class of halfspaces, by our reduction, classic hardness results on
agnostically learning halfspaces implies hardness of auditing for halfspaces (Theorem 5.2).
For a vector v ∈ ∆ with k ≥ 2, define lift(v) ∈ ∆ by
k k
1 1 1
lift(v) := v+ e + e . (7)
1 2
3 3 3
Theorem 4.5. For k ≥ 2, let H be a family of functions h : ∆ → [−1,1] closed under negation.
k
Let H˜ be a family of functions h˜ : ∆ → [−1,1] such that for every h ∈ H, there exists h˜ ∈ H˜
k
satisfying h˜(lift(v)) = h(v) for every v ∈ ∆ . Given any (2α/3,2β/3) auditor for H˜k, we can
k
construct an (α,β) weak agnostic learner for H with the same sample complexity, time complexity,
and failure probability parameter.
We will in fact derive this result from a more general statement where the class of auditors is
not necessarily a product set.
Theorem 4.6. Let H be a family of functions h : ∆ → [−1,1] and let W be a family of functions
k
w : ∆ → [−1,1]k. Let λ be a positive real number. Assume that for every h ∈ H there exists
k
w ∈ W such that
w(lift(x)) −w(lift(x)) = λh(x) for every x ∈ ∆ . (8)
1 2 k
Given any (λα/3,2β/3) auditor for W˜, we can construct an (α,β) weak agnostic learner for H
with the same sample complexity, time complexity, and failure probability parameter.
Proof. WeconstructaweakagnosticlearnerforHusinganauditorforW. Let(x ,z ),...,(x ,z )
1 1 n n
be the input data points in the weak agnostic learning task drawn i.i.d. from a distribution U. For
every input data point (x ,z ) ∈ ∆ × [−1,1], the learner generates a corresponding data point
i i k
(v ,y ) ∈ ∆ ×{e ,...,e } for the auditing task by setting
i i k 1 k
v = lift(x ),
i i
1
y ∼ v∗:=v + z (e −e ).
i i i 3 i 1 2
Note that v∗ ∈ ∆ , and thus it can be interpreted as a distribution over {e ,...,e }. Let D denote
i k 1 k
the distribution of (v ,y ). The intuition is that since v∗ favors either e or e over v depending
i i 1 2
on z, telling the difference between v and v∗ for an auditor requires learning z.
i i
Formally, by our assumption, for any h ∈ H, there exists w ∈ W satisfying (8), and thus
1 λ
E[⟨y−v,w(v)⟩] = E[z⟨e −e ,w(lift(x))⟩] = E[zh(x)].
1 2
D 3 U 3 U
Therefore, if E [zh(x)] ≥ α for some h ∈ H, then E [⟨y −v,w(v)⟩] ≥ λα/3 for some w ∈ W,
U D
and with high probability, the auditing algorithm will produce some w′ : ∆ → [−1,1]k such that
k
E [⟨y−v,w′(v)⟩] ≥ 2β/3. Defining h′ : ∆ → [−1,1] such that
D k
1
h′(x) = (w(lift(x))| −w(lift(x))| ) for every x ∈ ∆ ,
1 2 k
2
21we have
1
E[⟨y−v,w′(v)⟩] = E[z⟨e −e ,w′(lift(x))⟩]
1 2
D 3 U
1
= E[z⟨w′(lift(x))| −w′(lift(x))| ⟩]
1 2
3 U
2
= E[zh′(x)].
3 U
Therefore, E [⟨y−v,w′(v)⟩] ≥ 2β/3 implies E [zh′(x)] ≥ β. We have thus constructed an (α,β)-
D U
weakly agnostic learning algorithm which returns h′ as output.
We now complete the proof of Theorem 4.5.
Proof of Theorem 4.5. By our assumption about H˜, for every h ∈ H there exist h˜ ,h˜ such that
1 2
h˜ (lift(v)) = h(v), h˜ (lift(v)) = −h(v).
1 2
We consider any h˜ ∈ (H˜)k whose first two co-ordinates are h˜ and h˜ , so that their difference is
1 2
2h(v). We now apply Theorem 4.6 with W = (H˜)k and λ = 2.
5 Hardness of Auditing for Decision Calibration
Our tight connection between auditing and learning established in the previous section allows us to
transfer hardness results from learning to auditing. We apply this machinery to show hardness of
auditing for specific function classes. Under standard complexity-theoretic assumptions, we show
that auditing for decision calibration (Definition 2.3) cannot be solved in time poly(k).
Theorem 5.1 (Hardness of Decision Calibration). For k ∈ Z , let W be the class W used in
>0 k
the definition of decision calibration (Definition 2.3). Under standard hardness assumption on
refuting random t-XOR (Assumption 5.3 below), for any C > 2 and any sufficiently large k, there
is no (1/3−1/C,1/kC)-auditing algorithm for W that runs in time O(kC) and achieves success
k
probability at least 3/4.
We also prove a related result showing hardness of auditing for the product class of halfspaces.
Let H be the class of half-spaces over ∆ . That is, H consists of all functions h : ∆ → [−1,1]
hs k hs k
that can be written as h(v) = sign(a·v+b) for some a ∈ Rk and b ∈ R. We prove the following
theorem showing that Hk does not allow poly(k)-time auditing:
hs
Theorem 5.2 (Hardness of Halfspace Calibration). Under standard hardness assumption on re-
futing random t-XOR (Assumption 5.3 below), for any C > 2, there is no algorithm that, for every
sufficiently large k ∈ Z , solves (2/3−1/C,1/kC)-auditing for Hk in time O(kC) and achieves
>0 hs
success probability at least 3/4.
We combine reductions from Section 4.2 with existing hardness results of agnostically learning
halfspaces to prove the two theorems above. There are many results showing hardness of agnostic
learningforhalfspacesundervariousassumptions, forinstancesee[FGKP09,GR06]. Thestrongest
results for improper learning are due to Daniely based on the hardness of refuting random t-XOR-
Sat [Dan16].
22Assumption 5.3 (Random t-XOR Assumption [Dan16]). There exist constants η ∈ (0,1/2) and
c > 0 such that for any t ∈ Z , there is no poly(m)-time algorithm A that satisfies the following
>0 √
properties for any sufficiently large n ∈ Z and m = ⌊nc tlogt⌋:
>0
• given any size-m collection of t-XOR clauses on n variables where at least 1−η fraction of
the clauses are satisfiable, algorithm A outputs “accept” with probability at least 3/4;
• with probability at least q(n) = 1−o(1) over a uniformly randomly chosen size-m collection
of t-XOR clauses on n variables, given the collection as input, algorithm A outputs “reject”
with probability at least 3/4.
Theorem 5.4 ([Dan16]). Under Assumption 5.3, for any C > 2, there is no algorithm that, for
every sufficiently large k ∈ Z , solves (1 − 1/C,1/kC)-agnostic learning for H with success
>0 hs
probability at least 3/4 and runs in time O(kC).
The original result by [Dan16] was stated for the Boolean cube instead of ∆ , but the result
k
extends to ∆ by taking an affine injection from the Boolean cube {−1,1}k−1 to ∆ .
k k
We prove Theorem 5.1 and Theorem 5.2 by combining Theorem 5.4 with Theorem 4.5 and
Theorem 4.6 from Section 4.2. The following simple claim is convenient for our proof and it follows
immediately from the definition of lift(·) in (7).
Claim 5.5. For a ∈ Rk,b ∈ R, define a′ = 3a, b′ = b−a(1)−a(2). Then for every v ∈ ∆ ,
k
⟨a′,lift(v)⟩+b′ = ⟨a,v⟩+b.
Proof of Theorem 5.1. Any function h ∈ H can be expressed as h(v) = sign(⟨a,v−b⟩) for a ∈ Rk
hs
and b ∈ R. Define a′ = 3a, b′ = b−a(1) −a(2),g = e and g = −e . The function w mapping v′
1 1
to I(⟨a′,v′⟩ > b′)g+I(⟨a′,v′⟩ ≤ b′)g′ belongs to W , and
k
w(lift(v))(1)−w(lift(v))(2) = I(⟨a′,lift(v)⟩ > b′)−I(⟨a′,lift(v)⟩ ≤ b′) = sign(⟨a′,lift(v)−b′⟩) = h(v).
Therefore, by Theorem 4.6, any (1/3 − 1/C,1/kC)-auditing algorithm for W implies a (1 −
k
3/C,3/2kC)-agnostic learning algorithm for H with the same sample complexity, running time,
hs
and failure probability. The proof is completed by Theorem 5.4.
Proof of Theorem 5.2. ByClaim5.5,H isclosedundertheliftoperation,namelyforeveryh ∈ H
hs hs
we can construct h′ ∈ H which satisfies h′(lift(v)) = h(v) for every v ∈ ∆ . Assume for the
hs k
sake of contradiction that an auditing algorithm for Hk as described in the theorem exists. By
hs
Theorem 4.5, such an algorithm implies a (1 − 3C/2,3/2kC)-weak agnostic learner for H that
hs
runs in time O(kC) for any sufficiently large k, contradicting Theorem 5.4.
6 Kernel Algorithms for Auditing Calibration
In this section, we give efficient auditing algorithms for weighted calibration where the weight
family W consists of functions from a reproducing kernel Hilbert space (RKHS). In Section 6.1, we
discuss a special case using the multinomial kernel, which is important for our efficient auditors for
projected smooth calibration in Section 7.
It is well known that learning for functions with bounded norm in an RKHS with convex losses
isfeasiblebysolvingaconvexprogram. Hereweobservethatthesimplestructureofthecorrelation
23Algorithm 1: Kernel Algorithm for Weak Agnostic Learning
Input : Data points (v ,z ),...,(v ,z ) ∈ ∆ ×[−1,1].
1 1 n n k
Output: Function w : ∆ → [−1,1].
2 k
1 begin
(cid:16) (cid:17)1/2
2 λ ←
(cid:80)n i=1(cid:80)n
j=1z iz jker(v i,v j) ;
3 w 2(v) ← λ1 s (cid:80)n i=1z iker(v i,v) for every v ∈ ∆ k (in the degenerate case where λ = 0, set
w (v) ← 0);
2
4 return w 2;
objectiveE[zw(v)]inagnosticlearningmakesitpossibletooptimize, evenwithoutsolvingaconvex
program, just using O(n2) kernel evaluations, via Algorithm 1. The algorithm and its analysis are
not novel and are similar in nature to the kernel ridge regression algorithm (see e.g. [Wai09]).
Based on our connection between auditing and learning shown in Section 4, we give a similar kernel
evaluation based algorithm for multi-class auditing, which we present in Algorithm 2.
Let D be a distribution over ∆ ×[−1,1]. Consider a positive definite kernel ker : ∆ ×∆ → R
k k k
and the corresponding RKHS Γ consisting of functions w : ∆ → R. We assume that the kernel
k
can be evaluated efficiently. Let φ ∈ Γ denote the function ker(v,·). By the reproducing property,
v
w(v) = ⟨w,φ ⟩ for every w ∈ Γ and v ∈ ∆ .
v Γ k
Define B (r) to be the set of w ∈ Γ satisfying ∥w∥2 := ⟨w,w⟩ ≤ r2. For s > 0, assume that
Γ Γ Γ
ker(v,v) ≤ s2 for every v ∈ ∆ . That is, ∥φ ∥ ≤ s. Under this assumption, for any w ∈ B (1/s)
k v Γ Γ
and v ∈ ∆ , we have
k
|w(v)| = |⟨w,φ ⟩ | ≤ ∥w∥ ∥φ ∥ ≤ (1/s)·s ≤ 1.
v Γ Γ v Γ
The following theorems are proved in Appendix A.
Theorem 6.1. For n = O(r2s2α−2log(1/δ)), Algorithm 1 is an (α,α/3rs) agnostic learner for the
class B (r) with failure probability at most δ. Moreover, it always returns a function from B (1/s).
Γ Γ
Theorem 6.2. For n = O(kr2s2α−2log(1/δ)), Algorithm 2 is an (α,α/3rs) auditor for the class
B (r)k with failure probability at most δ. Moreover, it always returns a function from B (1/s)k.
Γ Γ
6.1 Auditing for the Multinomial Kernel
A kernel that will be of particular importance for us is the multinomial kernel. We follow the
elegant formulation from [GKKT17].
Definition 6.3. [GKKT17] For any vector v = (v ,...,v ) ∈ ∆ and tuple t = (t ,...,t ) ∈ [k]d,
1 k k 1 d
define vt to be the product v ···v . Define ψ : ∆ → R1+k+···+kd such that ψ(v) is a vector whose
t1 t d k
coordinate indexed by t ∈ T := [k]0∪[k]1∪···∪[k]d is vt. The degree d multinomial kernel is given
d
by
d
(cid:88)
ker (v,v′) = (v·v′)i = ψ(v)·ψ(v′).
d
i=0
We denote its RKHS as Γ(d).
24Algorithm 2: Kernel Algorithm for Auditing
Input : Data points (v ,y ),...,(v ,y ) ∈ ∆ ×E .
1 1 n n k k
Output: Function w : ∆ → [−1,1]k.
2 k
1 begin
2 z i ← y i−v i for every i = 1,...,n;
(ℓ)
3 For i = 1,...,n and ℓ = 1,...,k, let z
i
denote the ℓ-th coordinate of z i;
(cid:16) (cid:17)1/2
4 λ(ℓ) ← (cid:80)n i=1(cid:80)n j=1z( iℓ) z( jℓ) ker(v i,v j) for every ℓ = 1,...,k;
5 w 2(ℓ) (v) ← λ(1 ℓ)s (cid:80)n i=1z( iℓ) ker(v i,v) for every ℓ = 1,...,k and v ∈ ∆ k (in the degenerate
case where λ(ℓ) = 0, set w(ℓ) (v) ← 0);
2
(cid:0) (1) (k) (cid:1)
6 return w 2 such that w 2(v) = w 2 (v),...,w 2 (v) for every v ∈ ∆ k;
Instantiating Theorem 6.2 for the degree d multinomial kernel gives the following result.
Lemma 6.4. For all, r ≥ 0 and d ≥ 0, Algorithm 2 with n = O(kr2dlog(1/δ)/α2) samples is
√
an (α,α/(3r d))-auditor for the class (B (r))k with failure probability at most δ. Moreover, it
√Γ(d)
always returns a function from (B (1/ d))k in time poly(n,k,d).
Γ(d)
Proof. Observe that for v ∈ ∆ ,
k
d
(cid:88)
∥φ ∥2 = ker (v,v) = (v·v)i ≤ d
v Γ(d) d
i=0
√
since ∥v∥2 ≤ 1 for v ∈ ∆ . We can thus apply Theorem 6.2 with s = d to get the claimed
2 k
bound.
This gives a faster auditor for the notion of low-degree calibration defined by [GKSZ22].
Definition 6.5. [GKSZ22] Let P(d,1) denote the set of multivariate degree d polynomials
(cid:88) (cid:89)
p(v ,...,v ) = w vei
1 k e i
e:deg(e)≤d i
where ∀v ∈ ∆ , |p(v)| ≤ 1,
k
(cid:88)
|w | ≤ 1.
e
e:deg(e)≤d
We say that a predictor p is α degree-d calibrated if CE (D) ≤ α.
P(d,1)k
[GKSZ22] give an (α,α/kd)-auditor for P(d,1)k which runs in time O(kd) by enumerating over
all kd monomials. Algorithm 2 implies a better auditor which is polynomial in both k and d.
√
Corollary 6.6. There is an (α,α/3 d)-auditor for P(d,1)k that with success probability at least
1−δ, sample complexity n = O(kdlog(1/δ)/α2) and time complexity poly(n,k,d).
25Proof. Any polynomial p ∈ P(d,1) can be written as p(v) = (cid:80) w vt for every v ∈ Rk, where
t∈T t
d
w ∈ R for every t ∈ T and (cid:80) |w | ≤ 1. We define a vector ψp ∈ R1+k+···+kd whose coordinate
t d t∈T t
d
indexed by t ∈ T is w . It follows that
d t
(cid:88)
p(v) = w vt = ψp·ψ(v),
t
t∈T
d
(cid:32) (cid:33)2
(cid:88) (cid:88)
∥p∥2 ≤ ∥ψp∥2 = w2 ≤ |w | ≤ 1.
Γ(d) 2 t t
t t
Hence P(d,1) ⊆ B (1). Hence the claimed bound follows from Lemma 6.4 with r = 1.
Γ(d)
7 Efficient Auditing for Projected Smooth Calibration
In this section, we prove the following theorem showing an efficient kernel-based auditing algorithm
for projected smooth calibration (Definition 2.5).
Theorem 7.1. There exists c > 0 so that for any α,δ ∈ (0,1/2) and m ∈ [2,k], there is an
(α,1/mO(1/α)) auditor for m-projected smooth calibration (and hence also for m-subset smooth
calibration), with success probability at least 1−δ, sample complexity n = O(kmO(1/α)log(1/δ)),
and running time poly(n,k,1/α).
Even when we consider subset calibration over arbitrary subsets, which corresponds to taking
m = k, the running time of the auditor is kO(1/α), which is polynomial in k for every fixed α. In the
next section (Section 8), we show that this running time cannot be improved to poly(k,1/α) under
standardcomplexity-theoreticassumptions. Attheendofthissection,weshowthatthedependence
on α can be improved if we consider sigmoid functions instead of all 1-Lipschitz functions.
We prove Theorem 7.1 using Algorithm 2, together with polynomial approximations. Low
degree polynomial approximations have been used successfully for agnostic learning, starting with
the work of [KKMS08]. The important work of [SSS11] showed that one can improve the efficiency
of such learning algorithms by kernelizing them.
Using results from [GKKT17] and [She13], we will show the following bound on multivariate
polynomials obtained by composing bounded univariate polynomials with innner products.
Lemma 7.2. Let p be a univariate polynomial of degree d so that |p(u)| ≤ 1 for u ∈ [−1,1]. Let
p (v) = p(a·v) where a ∈ [−1,1]d and v ∈ ∆ . Then p ∈ Γ(d) and
a k a
∥p ∥2 ≤ max(4,4∥a∥ )2d.
a Γ(d) 2
We prove Lemma 7.2 using the following two lemmas from the literature:
Lemma 7.3. [GKKT17, Lemma 2.7] Let p = (cid:80)d η ui be a univariate polynomial of degree d and
i=0 i
p (v) = p(a·v) for a ∈ [−1,1]k and v ∈ ∆ . Then
a k
d d
(cid:88) (cid:88)
∥p ∥2 ≤ η2∥a∥2i ≤ max(1,∥a∥ )2d η2.
a Γd i 2 2 i
i=0 i=0
Lemma 7.4. [She13, Lemma 4.1] For a degree d polynomial p(u) = (cid:80)d η ui satisfying |p(u)| ≤ 1
i=0 i
for u ∈ [−1,1], it holds that (cid:80)d |η | ≤ 4d.
i=0 i
26Proof of Lemma 7.2. By Lemma 7.4, we can bound
d (cid:32) d (cid:33)2
(cid:88) (cid:88)
|η |2 ≤ |η | ≤ 42d.
i i
i=0 i=0
We plug this bound into Lemma 7.3 to get
∥p ∥2 ≤ max(4,4∥a∥ )2d.
a Γd 2
Let Lip denote the set of all bounded 1-Lipschitz functions ϕ : [0,1] → [−1,1]. We use an
approximation result for arbitrary Lipschitz functions using Jackson’s theorem [Che66], together
with a rescaling argument to ensure boundedness. A similar argument for the ReLU function
appears in [GKKT17, Lemma 2.12].
Lemma 7.5. There exists a constant c′ > 0 such that for any ϕ ∈ Lip and any ε > 0, there exists
a univariate polynomial p(t) with deg(p) ≤ c′/ε such that for t ∈ [−1,1],
• |ϕ(t)−p(t)| ≤ ε .
• p(t) ∈ [−1,1].
Proof. By Jackson’s theorem [Che66], there exist a polynomial p(t) so that |ϕ(t)−p(t)| ≤ ε/2 for
t ∈ [−1,1] where deg(p) ≤ O(1/ϵ). Since |ϕ(t)| ≤ 1, |p(t)| ≤ 1+ε/2. Now let p (t) = p(t)/(1+ε/2)
ϕ
so that |p (t)| ≤ 1. We then bound
ϕ
1
|p (t)−ϕ(t)| = |(p(t)−(1+ε/2)ϕ(t))|
ϕ
1+ε/2
1
≤ (|p(t)−ϕ(t)|+ε/2|ϕ(t)|)
1+ε/2
ε
≤ ≤ ε.
1+ε/2
Combining Lemmas 7.5 and 7.2, we have the following corollary.
Corollary 7.6. For any ϕ ∈ Lip, and ε > 0, let p be as in Lemma 7.5. For a ∈ [−1,1]k, let
p (v) = p(a·v). Then p ∈ Γ(d) for d = O(1/ε) and
a a
(cid:12) (cid:12)
• (cid:12)p (v)−ϕ(a·v)(cid:12) ≤ ε, for every v ∈ ∆ .
(cid:12) a (cid:12) k
• ∥p a∥
Γ(d)
≤ c 1max(1,∥a∥ 2)c2/ε.
We now complete the proof of Theorem 7.1.
Proof of Theorem 7.1. We claim that if psCE (D) ≥ α, then CE (D) ≥ α/2 for some
m (B (r))k
Γ(d)
r = mO(1/α). To see this, take ψ ∈ pLipk so that
E[⟨y∗−v,ψ(v)⟩ ≥ α.
D
27For every i = 1,...,k, there exists a ∈ [−1,1]k and ϕ ∈ Lip such that ψ(i)(v) = ϕ(i)(⟨a ,v⟩) for
√ i i
i ∈ [k] where ∥a ∥ ≤ m. By Corollary 7.6, there exists p(i) ∈ Γ(d) where d = O(1/α) such that
i 2
(cid:13) (cid:13)
(cid:13)ψ (v)−p(i)(v)(cid:13) ≤ α/4,
(cid:13) i (cid:13)
∞
(cid:13) (cid:13) √
(cid:13)p(i)(cid:13) ≤ (c max(1,∥a ∥ ))c2/α ≤ (c m)c2/α.
(cid:13) (cid:13) 1 i 2 1
Γ(d)
Hence p(i) ∈ B (r) for each i for r = mO(1/α).
Γ(d)
Define p(v) = (p(1)(v),...,p(k)(v)) ∈ Rk. By the triangle inequality
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12)E[⟨y∗−v,p(v)⟩−E[⟨y∗−v,ψ(v)⟩](cid:12) = (cid:12)E[⟨y∗−v,p(v)−ψ(v)⟩](cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
D D D
≤ E[|⟨y∗−v,p(v)−ψ(v)⟩|]
D
≤ E[∥y∗−v∥ ∥p(v)−ψ(v)∥ ]
1 ∞
D
α α
≤ 2· ≤
4 2
where we use ∥y∗−v∥ ≤ 2. As a result we have
1
E[⟨y∗−v,p(v)⟩] ≥ E[⟨y∗−v,ψ(v)⟩]−α/2 ≥ α−α/2 = α/2.
D D
We now apply Lemma 6.4 with the weight functions (B (r))k where d = O(1/α),r = mO(1/α)
Γ(d)
to get an (α/2,Ω(α3/2/mc/α))-auditing algorithm.
Auditing for Sigmoids. We show additionally that the exponential dependence on 1/α in The-
orem 7.1 can be improved if we audit only for sigmoid functions. Formally we use the tanh function
rather then the sigmoid, since we want the range to be [−1,1] in order to approximate the sign
function. Nevertheless, we refer to the family as the family of sigmoid functions.
Definition 7.7. For L ≥ 1, define Σ = {g : R → [−1,1]} to be the family of functions of the form
L
g(v) = tanh(L⟨a,v⟩+b) for a ∈ [−1,1]k, b ∈ R.
In Theorem 7.9 below we show an efficient auditor for Σk whose running time is polynomial in
L
1/α for every fixed k and L.
Observe that Σ increase monotonically with L, since for L′ < L, L′⟨a,v⟩ = L⟨a′,v⟩ where
L
a′ = L′a/L ∈ [−1,1]k. The problem of agnostically learning Σ over ∆ is given a distribution
L k
U on ∆ × {±1}, find g ∈ Σ that maximizes E [g(v)z]. The problem of agnostically learning
k L U
sigmoids over the unit sphere (rather than ∆ ) was considered in the influential work of [SSS11].
k
They work with the objective function min E|z −g(v)|, but this is seen to be equivalent to
g∈ΣL
max [E[g(v)z] when z ∈ {−1,1}. A more substantial difference is that they work in the ℓ
g∈ΣL 2
bounded setting where ∥v∥ ≤ 1, ∥a∥ ≤ 1, whereas we work with ℓ /ℓ -bounded setting where
2 2 1 ∞
∥v∥ ≤ 1 and ∥a∥ ≤ 1. Thus we cannot directly use their results, although our techniques are
1 ∞
influenced by them.
Our algorithm will use the following results about univariate approximations to the tanh func-
tion was proved in the work of [SSS11], with subsequent proofs given by [LSS14, GKK20]. We use
the following version from [GKK20].
28Lemma 7.8. [GKK20] For ε ∈ (0,1/2),L ≥ 1 and b ∈ R, there exists a univariate polynomial p(t)
with deg(p) ≤ O(Llog(L/ε)) so that for t ∈ [−1,1]
• |tanh(Lt+b)−p(t)| ≤ ε .
• p(t) ∈ [−1,1].
Following the same proof outline as Theorem 7.1 gives the following result.
Theorem 7.9. For any α ∈ (0,1/2),L > 1, there is an efficient (α,β)-auditor for (Σ )k calibration
L
for
α
β =
kO(Llog(L/α))
which has time and sample complexity kO(Llog(L/α)) and success probability at least 1−2−k.
ThesametechniquesalsoyieldanalgorithmforagnosticallylearningΣ underanydistribution
L
U on ∆ ×[−1,1] with similar parameters.
k
8 Computational Lower Bound for Projected Smooth Calibration
The sample and time complexity of our auditing algorithm for projected smooth calibration in
Section 7 is kO(1/α) (when setting m = k). In this section, we show that an improvement to
poly(k,1/α) (or just to
kO(log0.99(1/α)))
would violate standard complexity-theoretic assumptions:
Theorem 8.1. Under a standard hardness assumption on refuting t-XorSat (Assumption 8.5), for
any C > 0, ε > 0, there is no algorithm solving (α,1/kC) auditing for k-projected smooth calibration
for every sufficiently large k and every α ∈ (0,1/3) with success probability at least 3/4 and running
time kO((log(1/α))1−ε).
We use the following connection between auditing projected smooth calibration and auditing
for sigmoids Σk.
L
Lemma 8.2. For α,β ∈ (0,1) and L > 1, any (α/L,β)-auditing algorithm for Lipk is an (α,β)-
auditing algorithm for Σk.
L
Proof. For a class W of functions h : ∆ → [−1,1]k, recall the following notion in our definition of
k
auditing:
(cid:12) (cid:12)
(cid:12) (cid:12)
CE W(D) = sup (cid:12) E [⟨y−v,w(v)⟩](cid:12).
w∈W(cid:12)(v,y)∼D (cid:12)
It suffices to show that for any distribution D over ∆ ×E ,
k k
1
CE (U) ≥ CE (U). (9)
Lipk
L
Σk
L
Consider any function g ∈ Σ . By definition, there exist a ∈ [−1,1]k and b ∈ R such that
L
g(v) = tanh(L⟨a,v⟩+b) for every v ∈ ∆ . It is easy to verify that tanh is 1-Lipschitz, and thus
k
for any v ,v ∈ ∆ ,
1 2 k
|g(v )−g(v )| ≤ L|⟨a,v ⟩−⟨a,v ⟩| ≤ L∥v −v ∥ .
1 2 1 2 1 2 1
Therefore, the function g/L belongs to Lip, confirming (9).
29Theorem 8.3. Under a standard hardness assumption on refuting t-XorSat (Assumption 8.5), for
some fixed α > 0, for any C > 0, ε > 0, c ∈ (0,1), there is no algorithm that solves (α,1/kC)
auditor for Σk for every sufficiently large k ∈ Z and L := exp(logck) with success probability at
L >0
least 3/4 and running time k(logL)1−ε.
Proof of Theorem 8.1. Let α denote the fixed constant α in Theorem 8.3. Theorem 8.1 follows
0
immediately by combining Theorem 8.3 and Lemma 8.2, where we choose α in Theorem 8.1 to be
α /L.
0
8.1 Projected Smooth Calibration and Sigmoids
Now we prove Theorem 8.3. Our reduction from auditing to agnostic learning lets us focus on the
complexity of agnostic learning Σ to understand auditing with weight functions Σk . This is
L L/3
formally stated below.
Lemma 8.4. Given any (2α/3,2β/3) auditor for Σk , we can construct an (α,β) weak agnostic
L/3
learner for Σ over ∆ with the same sample complexity, time complexity, and failure probability
L k
parameter.
Proof. For g ∈ Σ , we claim there exists g′ ∈ Σ such that g′(lift(v)) = g(v). Indeed since
L/3 L
lift(v) = v/3+e /3+e /3,
1 2
tanh(L⟨w,v⟩/3+b) = tanh(L⟨w,3lift(v)⟩/3+b−Lw(1)/3−Lw(2)/3)
= tanh(L⟨w,lift(v)⟩+b′) ∈ Σ
L
We now apply Theorem 4.5 to get the stated claim.
Our lower bound for agnostically learning sigmoids is obtained by tailoring Daniely’s [Dan16]
reduction from refuting random XorSat to the ℓ /ℓ bounded setting.
∞ 1
An instance of t-XorSat consists of m clauses on n variables {z ,...,z } each taking values in
1 n
{±1}. Each clause consists of exactly t literals which might be variables or their negations, we
assume that x and −x do not occur in the same clause. Thus each clause c can be arithmetized as
i i
avectorin{0,1}2n ofweightexactlyt,interpretedasasubsetofliterals. WewillletC(t) ⊂ {0,1}2n
denote the set of valid clauses. Similarly, assignments to z can be (redundantly) arithmetized as
vectors in Z ⊆ {±1}2n where |Z| = 2n. Given a clause c ∈ C and z ∈ Z, c ·z ∈ {−t,...,t} equals
i i
the sum of literals in the clause c . An instance of t-XorSat is given by I = {(c ,b )}m where
i i i i=1
(cid:81)
c ∈ C(t) and b ∈ {±1}. For a clause c ∈ C , let Xor (z) = z . For an instance I and z ∈ Z,
i i t c i∈c i
we define
|i ∈ [m] : Xor (z) = b |
val(z,I) =
ci i
m
and val(I) = max val(z,I) to be the maximum fraction of satisfiable clauses.
z∈Z
A random instance of t-XorSat is one where c ← C and b ← {±1} are drawn uniformly and
i i
independently at random. We let R denote the distribution on instances that this defines. An
algorithm A which maps t-XorSat instances to {0,1} successfully refutes random t-XorSat if
3
Pr[A(I) = 1] ≥ if val(I) ≥ 1−η
4
3
Pr[A(I) = 0]] ≥ with probability 1−o (1) over I ∼ R.
n
4
30We are interested in the asymptotics in both t and n. The best known algorithms for refutation
require m = Ω(nt/2) and it is conjectured that there are no algorithms with running time no(t).
Assumption 8.5 (Random t-XOR Assumption [Dan16]). There exist constants η ∈ (0,1/2) and
γ > 0 such that for any s > 0, there is no poly(m)-time algorithm that refutes random t-XorSat
with m clauses for any sufficiently large n ∈ Z , m = ⌊nγt⌋, and t = ⌊logs(n)⌋.
>0
Theorem 8.6. Under Assumption 8.5, for some fixed α > 0, any C > 0, c ∈ (0,1), and ε >
0, there is no algorithm that solves (α,k−C)-weak agnostic learning for Σ over ∆ for every
L k
sufficiently large k ∈ Z and L := exp(logck) with success probability at least 3/4 and running
>0
time
kO(log1−εL).
Proof of Theorem 8.3. Theorem8.3followsimmediatelybycombiningTheorem8.6andLemma8.4.
In preparation for proving Theorem 8.6, we prove a few preliminary results. Given a set of
clauses c = {c } , define the function:
i i∈[m]
1 (cid:88)
q(c) = max (c ·z)2
i
z∈Z m
i∈[m]
The following lemma is implicit in [Dan16]
Lemma 8.7. There exists a constant a such that
1
Pr [q(c) ≤ a tlog(t)] ≥ 1−o (1)
1 m
c←Cm
where the o (1) is exponentially small in m.
m
Proof. Fix an assignment z ∈ Z. We view choosing c ← C and first choosing a subset T ⊆ [n] of
i i
variables, and then choosing their polarities p ∈ {±1}t.
i
For every z and T, by a Chernoff bound (over the choice of p), there exists a constant a so
2
that
(cid:112)
Pr [|c ·z| ≥ a tlog(1/δ)] ≤ δ.
pi←{±1}t i 2
By a Chernoff bound over the choice of T [MR95, Theorem 4.1], we have that with probability
i
exp(−a δm) , the condition
3
(cid:112)
|c ·z| ≤ a tlog(1/δ)
i 2
holds for m(1−2δ) clauses. For such a z, we can bound
m
1 (cid:88) 1 (cid:88)
((c ·z)2−t) ≤ |c ·z|2
i i
m m
i∈[m] i=1
≤ (1−2δ)a tlog(1/δ)+2δt2 ≤ a tlog(t)
2 1
where we choose δ = log(t)/t.
By a union bound over all 2n choices of z, this holds for every z, and hence for q(c) with
probability 2nexp(−a δm), which is exponentially small once m ≥ a nt.
2 3
31The next lemma is also proved in [Dan16]. We use a different technique based on semi-definite
programming and Grothendieck’s inequality, which is more along the lines of the reduction in
Fiege’s work [Fei02].
Lemma 8.8. There is an algorithm that accepts all c ∈ Cm such that q(c) ≥ a tlog(t) and rejects
1
instances such that q(c) ≤ 2a tlog(t).
1
Proof. We can write
m
1 (cid:88)
q(c)−t = max ((c ·z)2−t)
i
z∈Z m
i=1
1 (cid:88) (cid:88)
= max z z
j j′
z∈Z m
i∈[m]j̸=j′∈ ci
We consider the semi-definite relaxation over v which are unit vectors in a high-dimensional space
i
(with the constraint that the vectors assigned to a literal and its negation sum to 0).
1 (cid:88) (cid:88)
q˜(c) = max v v
j j′
∥vj∥2 2=1 m
i∈[m]j̸=j′∈ ci
We solve the semi-definite program efficiently (up to small additive error which we will ignore) and
accept instances where
q˜(c) > K (a tlog(t)−t).
G 1
Grothendieck’s inequality implies that the integrality gap of this relaxation is a constant; there
exist K ∈ [1.5,2] such that
G
q(c)−t ≤ q˜(c) ≤ K (q(c)−t). (10)
G
For such instances, Equation (10) implies that q(c) > a tlog(t) since
1
q˜(c)
q(c)−t ≥ > a tlog(t)−t.
1
K
G
For instances that we reject, it holds that
q(c)−t ≤ q˜(c) < K (a tlog(t)−t)
G 1
Since K ∈ [1.5,2], we have q(c) ≤ 2a tlog(t).
G 1
We refer to instances rejected by the algorithm as pseudorandom. By Markov’s inequality
applied to the definition of q(c), we have the following claim:
Lemma 8.9. Given pseudorandom c ∈ Cm and z ∈ Z, for every δ > 0, there are at most δm
(cid:112)
clauses such that |c ·z| ≥ a tlog(t)/δ.
i 1
We also have the following lemma which we state without proof
Lemma 8.10. Every functions g : {−d,...,d} → {±1} can be written as a polynomial in x of
degree 2d with coefficients bounded by exp(dlog(d)).
32We now complete the proof of Theorem 8.6.
Proof. Let η ∈ (0,1/2) be the constant guaranteed to exist by Assumption 8.5. We define α =
1/4−η/2 ∈ (0,1/4). We fix an arbitrary constant ε ∈ (0,1/3). Throughout the proof, we will
treat η,α, and ε as fixed constants (that can hide in big-O notations). Consider an algorithm
A for (α,k−C)-weak agnostic learning for Σ over ∆ with running time k(log(L))1−ε and success
L k
probability at least 3/4 for any sufficiently large k and L := exp(logck) for some c ∈ (0,1). It
suffices to use A to efficiently refute random t-XorSat with parameter η for any sufficiently large n
and t = ⌊logs(n)⌋ in time no(t), where s = 2c/(1−c+ε) > 0.
We view the clauses in a t-XorSat problem as a distribution over C ⊆ {0,1}2n, with the c s
√ i
(cid:112)
being points and b their labels. Let d = Θ( (tlogt)/α) = Θ( tlogt) be such that at most αm
i
clauses fail to satisfy |c ·z| ≤ d/2. We consider the low degree feature expansion of C denoted C⊗d
i
which contains a monomial (cid:81) c(j) for every T ⊆ [2n] of size at most d, so that C⊗d ⊆ {0,1}k
j∈T i
for
(cid:18) (cid:19) d (cid:18) (cid:19)
2n (cid:88) 2n
k = := . (11)
≤ d j
j=0
Since every c ∈ C has weight exactly t, every c⊗d ∈ C⊗d has weight B = (cid:0) t (cid:1) = exp(O(dlog(d))).
1 ≤d
This lets us write c⊗d = B v where v ∈ ∆ . Thus an instance I which gives a distribution on
i 1 i i k
(c ,b ) where c ∈ C b ∈ {±1} also gives a distribution over (v ,b ) ∈ ∆ ×{±1}.
i i i i i i k
There exists a degree d polynomial
d
(cid:88)
p(t) = α tj
j
j=0
such that |α | = exp(O(dlog(d))) and p(c ·z) = Xor (z) for |c ·z| ≤ d/2. If |c ·z| ≥ d/2 then
j i ci i i
p(c ·z) ∈ R. Since c ∈ {0,1}n, we can multilinearize the terms of the form (c ·z)j as
i i i
(c ·z)j = (cid:88) wj (cid:89) c
i T i
T⊆[n],|T|≤j i∈T
for coefficients wj = exp(O(jlogj)). So we can write
T
2d
(cid:88)
p(c ·z) = α (c ·z)j
i j i
j=0
2d
= (cid:88) α (cid:88) wj (cid:89) c
j T i
j=0 T⊆[n],|T|≤j i∈T
 
= (cid:88) (cid:88) α jw Tj (cid:89) c
i
T⊆[n],|T|≤2d j≥|T| i∈T
(cid:88) (cid:89)
= w′ c
T i
T⊆[n],|T|≤2d i∈T
= w′·c⊗d
33for coefficients w′ bounded in absolute value by |w′ | = exp(O(dlogd)).
T T
We renormalize w′ to be bounded in [−1,1]k. We write w′ = wB for B = max |w′ | =
1 1 T T
exp(O(dlogd). We have
(cid:18) (cid:19)
t
P(c ·z) = w′·c⊗d = B w·v .
i i 1 d i
Hence if |c ·z| ≤ d/2, then the quantity above equals Xor (z) ∈ {±1}, else it takes on values in R.
i √ ci
By our choice of d = Θ( tlogt), we have
(cid:18) (cid:18) (cid:19)(cid:19)
t
log B = logB +O(log(dlogt)) = O(dlogd) ≤ t1/2+o(1).
1 1
d
By our choice of L := exp(logck), we have
logL = (logk)c
= (dlogn)c+o(1) (by (11))
= dc+o(1)(logn)c+o(1)
√
= tc/2+o(1)(logn)s(1−c+ε)/2+o(1) (by d = Θ( tlogt) and s = 2c/(1−c+ε))
= tc/2+o(1)t(1−c+ε)/2+o(1) (by t = ⌊logsn⌋)
= t1/2+ε/2+o(1). (12)
Therefore, for sufficiently large n,
(cid:18) (cid:19)
t
L ≥ aB ,
1
d
forsomeconstantasothattanh(a) ≥ 1−α,whereweuseourchoiceofconstantα := 1/4−η/2 > 0.
Consider the function g(v) = tanh(L′w·v) ∈ Σ . We can find a′ ≥ a such that L = a′B (cid:0)t(cid:1) .
L 1 d
We have for each i ∈ [m],
g(v ) = tanh(Lw·v )
i i
(cid:18) (cid:18) (cid:19) (cid:19)
t
= tanh a′B w· v
1 i
≤ d
= tanh(a′w′·c⊗d)
i
= tanh(a′p(c ·z)).
i
Therefore, g(v ) ≥ 1−α if p(c ·z) = 1, and g(v ) ≤ −1+α if p(c ·z) = −1. Moreover, it is clear
i i i i
that g(v ) ∈ [−1,1] always holds.
i
Recall our definition α := 1/4−η/2 > 0. If val(I) ≥ 1−η, then by taking the function g derived
from z such that val(z,I) ≥ 1−η = 1/2+2α, excluding the at most αm clauses that fail to satisfy
|c ·z| ≤ d/2, we get g ∈ Σ such that
i L
m
1 (cid:88)
g(v )b ≥ (1/2+α)×(1−α)+(1/2−α)×(−1) ≥ α.
i i
m
i=1
Thus based on the methodology of [DLSS14] (see e.g. Theorem 2.1 in [Dan16]), we can apply
our weak agnostic learning algorithm A to efficiently distinguish the case with val(I) ≥ 1−η and
34the case with uniformly random clauses with success probability at least 3/4, solving the t-XorSat
refutation problem.
As long as the running time of algorithm A is bounded by klog(L)1−ε for some ε > 0, the running
time for t-XorSat refutation is bounded by
kO(log(L)1−ε)
≤
nO(dlog(L)1−ε).
By (12), we have
dlog(L)1−ε = t1/2+o(1)t(1−ε)(1/2+ε/2+o(1)) = t1−ε2/2+o(1).
Thus the running time for t-XorSat refutation is bounded by no(t), as desired.
References
[AB21] Anastasios N Angelopoulos and Stephen Bates. A gentle introduction to con-
formal prediction and distribution-free uncertainty quantification. arXiv preprint
arXiv:2107.07511, 2021. 8
[BGHN23] Jarosl(cid:32)aw Bl(cid:32)asiok, Parikshit Gopalan, Lunjia Hu, and Preetum Nakkiran. A unifying
theory of distance from calibration. In Proceedings of the 55th Annual ACM Sympo-
sium on Theory of Computing, page 1727–1740, 2023. 1, 3, 4, 5, 6, 11, 12, 14
[BGJ+22] Osbert Bastani, Varun Gupta, Christopher Jung, Georgy Noarov, Ramya Rama-
lingam, and Aaron Roth. Practical adversarial multivalid conformal prediction. In
S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Ad-
vances in Neural Information Processing Systems, volume 35, pages 29362–29373.
Curran Associates, Inc., 2022. 8
[BLM01] Shai Ben-David, Philip M. Long, and Yishay Mansour. Agnostic boosting. In 14th
Annual Conference on Computational Learning Theory, COLT, 2001. 6, 18
[Che66] E. Cheney. Introduction to approximation theory. McGraw-Hill, New York, 1966. 27
[Dan16] Amit Daniely. Complexity theoretic limitations on learning halfspaces. In Proceedings
of the Forty-Eighth Annual ACM Symposium on Theory of Computing, page 105–117,
New York, NY, USA, 2016. Association for Computing Machinery. 2, 4, 7, 22, 23, 30,
31, 32, 34
[Daw82] A. P. Dawid. Objective probability forecasts. University College London, Dept. of
Statistical Science. Research Report 14, 1982. 1
[Daw84] A Philip Dawid. Present position and potential developments: Some personal views
statistical theory the prequential approach. Journal of the Royal Statistical Society:
Series A (General), 147(2):278–290, 1984. 1
[DDS+09] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet:
A large-scale hierarchical image database. In 2009 IEEE Conference on Computer
Vision and Pattern Recognition, pages 248–255, 2009. 1
35[DKR+21] Cynthia Dwork, Michael P. Kim, Omer Reingold, Guy N. Rothblum, and Gal
Yona. Outcome indistinguishability. In ACM Symposium on Theory of Computing
(STOC’21), 2021. 2, 3
[DKR+22] Cynthia Dwork, Michael P. Kim, Omer Reingold, Guy N. Rothblum, and Gal Yona.
Beyond bernoulli: Generating random outcomes that cannot be distinguished from
nature. In The 33rd International Conference on Algorithmic Learning Theory, 2022.
2, 3, 7, 8
[DLLT23] CynthiaDwork,DanielLee,HuijiaLin,andPranayTankala. Frompseudorandomness
to multi-group fairness and back. In Gergely Neu and Lorenzo Rosasco, editors,
Proceedings of Thirty Sixth Conference on Learning Theory,volume195ofProceedings
of Machine Learning Research, pages 3566–3614. PMLR, 12–15 Jul 2023. 2
[DLSS14] Amit Daniely, Nati Linial, and Shai Shalev-Shwartz. From average case complexity to
improper learning complexity. In Proceedings of the Forty-Sixth Annual ACM Sympo-
sium on Theory of Computing, STOC ’14, page 441–448, New York, NY, USA, 2014.
Association for Computing Machinery. 34
[Fei02] UrielFeige. Relationsbetweenaveragecasecomplexityandapproximationcomplexity.
In John H. Reif, editor, Proceedings on 34th Annual ACM Symposium on Theory of
Computing, May 19-21, 2002, Montr´eal, Qu´ebec, Canada, pages534–543.ACM,2002.
32
[Fel10] Vitaly Feldman. Distribution-specific agnostic boosting. In Andrew Chi-Chih Yao,
editor, Innovations in Computer Science - ICS 2010, Tsinghua University, Beijing,
China, January 5-7, 2010. Proceedings, pages 241–250. Tsinghua University Press,
2010. 18
[FGKP09] Vitaly Feldman, Parikshit Gopalan, Subhash Khot, and Ashok Kumar Ponnuswami.
On agnostic learning of parities, monomials, and halfspaces. SIAM J. Comput.,
39(2):606–645, 2009. 22
[FH18] Dean P. Foster and Sergiu Hart. Smooth calibration, leaky forecasts, finite recall, and
nash dynamics. Games Econ. Behav., 109:271–293, 2018. 5, 11
[GHK+23] Parikshit Gopalan, Lunjia Hu, Michael P. Kim, Omer Reingold, and Udi Wieder.
Loss Minimization Through the Lens Of Outcome Indistinguishability. In Yael Tau-
man Kalai, editor, 14th Innovations in Theoretical Computer Science Conference
(ITCS2023),volume251ofLeibnizInternationalProceedingsinInformatics(LIPIcs),
pages 60:1–60:20, Dagstuhl, Germany, 2023. Schloss Dagstuhl – Leibniz-Zentrum fu¨r
Informatik. 2
[GJN+22] Varun Gupta, Christopher Jung, Georgy Noarov, Mallesh M. Pai, and Aaron Roth.
Online Multivalid Learning: Means, Moments, and Prediction Intervals. In Mark
Braverman, editor, 13th Innovations in Theoretical Computer Science Conference
(ITCS2022),volume215ofLeibnizInternationalProceedingsinInformatics(LIPIcs),
pages 82:1–82:24, Dagstuhl, Germany, 2022. Schloss Dagstuhl – Leibniz-Zentrum fu¨r
Informatik. 8
36[GKK20] Surbhi Goel, Adam R. Klivans, and Frederic Koehler. From boltzmann machines
to neural networks and back again. In Annual Conference on Neural Information
Processing Systems 2020, 2020. 7, 28, 29
[GKKT17] Surbhi Goel, Varun Kanade, Adam R. Klivans, and Justin Thaler. Reliably learning
thereluinpolynomialtime. InProceedingsofthe30thConferenceonLearningTheory,
COLT 2017, Amsterdam, The Netherlands, 7-10 July 2017, volume 65 of Proceedings
of Machine Learning Research, pages 1004–1042. PMLR, 2017. 7, 24, 26, 27
[GKR+22] Parikshit Gopalan, Adam Tauman Kalai, Omer Reingold, Vatsal Sharan, and
Udi Wieder. Omnipredictors. In Innovations in Theoretical Computer Science
(ITCS’2022), 2022. 2
[GKSZ22] Parikshit Gopalan, Michael P. Kim, Mihir Singhal, and Shengjia Zhao. Low-degree
multicalibration. In Conference on Learning Theory, 2-5 July 2022, London, UK,
volume 178 of Proceedings of Machine Learning Research, pages 3193–3234. PMLR,
2022. 3, 4, 7, 8, 9, 10, 17, 25
[GPSW17] ChuanGuo, GeoffPleiss, YuSun, andKilianQWeinberger. Oncalibrationofmodern
neural networks. In International Conference on Machine Learning, pages 1321–1330.
PMLR, 2017. 1, 2, 10
[GR06] Venkatesan Guruswami and Prasad Raghavendra. Hardness of learning halfspaces
with noise. In 47th Annual IEEE Symposium on Foundations of Computer Science
(FOCS 2006), 21-24 October 2006, Berkeley, California, USA, Proceedings, pages
543–552. IEEE Computer Society, 2006. 22
[GR22] Chirag Gupta and Aaditya Ramdas. Top-label calibration and multiclass-to-binary
reductions. In International Conference on Learning Representations, 2022. 10
[HKRR18] U´rsulaH´ebert-Johnson,MichaelP.Kim,OmerReingold,andGuyN.Rothblum. Mul-
ticalibration: Calibrationforthe(computationally-identifiable)masses. InProceedings
of the 35th International Conference on Machine Learning, ICML, 2018. 2, 6, 17
[JNRR23] Christopher Jung, Georgy Noarov, Ramya Ramalingam, and Aaron Roth. Batch mul-
tivalidconformalprediction.InInternationalConferenceonLearningRepresentations,
2023. 8
[KF08] Sham Kakade and Dean Foster. Deterministic calibration and nash equilibrium. Jour-
nal of Computer and System Sciences, 74(1):115–130, 2008. 1, 3, 4, 5, 11
[KF15] Meelis Kull and Peter Flach. Novel decompositions of proper scoring rules for classi-
fication: Score adjustment as precursor to calibration. In Joint European Conference
on Machine Learning and Knowledge Discovery in Databases, pages 68–85. Springer,
2015. 1
[KK09] Adam Kalai and Varun Kanade. Potential-based agnostic boosting. In Advances in
Neural Information Processing Systems, volume 22. Curran Associates, Inc., 2009. 18
37[KKMS08] Adam Tauman Kalai, Adam R. Klivans, Yishay Mansour, and Rocco A. Servedio.
Agnostically learning halfspaces. SIAM J. Comput., 37(6):1777–1805, 2008. 26
[KLST23] Bobby Kleinberg, Renato Paes Leme, Jon Schneider, and Yifeng Teng. U-calibration:
Forecasting for an unknown agent. In Gergely Neu and Lorenzo Rosasco, editors,
Proceedings of Thirty Sixth Conference on Learning Theory,volume195ofProceedings
of Machine Learning Research, pages 5143–5145. PMLR, 12–15 Jul 2023. 1, 7, 8
[KMV08] Adam Tauman Kalai, Yishay Mansour, and Elad Verbin. On agnostic boosting and
parity learning. In Proceedings of the 40th Annual ACM Symposium on Theory of
Computing, pages 629–638. ACM, 2008. 6, 18
[KPNK+19] Meelis Kull, Miquel Perello-Nieto, Markus K¨angsepp, Hao Song, Peter Flach, et al.
Beyond temperature scaling: Obtaining well-calibrated multiclass probabilities with
dirichlet calibration. arXiv preprint arXiv:1910.12656, 2019. 1, 2, 10
[KSJ18] Aviral Kumar, Sunita Sarawagi, and Ujjwal Jain. Trainable calibration measures for
neural networks from kernel mean embeddings. In Proceedings of the 35th Interna-
tionalConferenceonMachineLearning,volume80ofProceedingsofMachineLearning
Research, pages 2805–2814. PMLR, 2018. 4
[LSS14] Roi Livni, Shai Shalev-Shwartz, and Ohad Shamir. Onthe computational efficiency of
training neural networks. In Advances in Neural Information Processing Systems 27:
Annual Conference on Neural Information Processing Systems 2014, December 8-13
2014, Montreal, Quebec, Canada, pages 855–863, 2014. 28
[MR95] Rajeev Motwani and Prabhakar Raghavan. Randomized algorithms. Cambridge uni-
versity press, 1995. 31
[NRRX23] GeorgyNoarov,RamyaRamalingam,AaronRoth,andStephanXie.High-dimensional
prediction for sequential decision making. arXiv preprint arXiv:2310.17651, 2023. 7,
8
[She13] Alexander A. Sherstov. Making polynomials robust to noise. Theory of Computing,
9(18):593–615, 2013. 26
[SSBD14] Shai Shalev-Shwartz and Shai Ben-David. Understanding Machine Learning - From
Theory to Algorithms. Cambridge University Press, 2014. 39
[SSS11] Shai Shalev-Shwartz, Ohad Shamir, and Karthik Sridharan. Learning kernel-based
halfspaces with the 0-1 loss. SIAM J. Comput., 40(6):1623–1646, 2011. 4, 7, 26, 28
[SV08] Glenn Shafer and Vladimir Vovk. A tutorial on conformal prediction. Journal of
Machine Learning Research, 9(12):371–421, 2008. 8
[Wai09] Martin Wainwright. Lecture 6 in EECS 281B / STAT 241B: Advanced topics in sta-
tisticallearning. https://people.eecs.berkeley.edu/~wainwrig/stat241b/lec6.
pdf, 2009. 24
38[ZKS+21] Shengjia Zhao, Michael P. Kim, Roshni Sahoo, Tengyu Ma, and Stefano Ermon.
Calibrating predictions to decisions: A novel approach to multi-class calibration. In
Advances in Neural Information Processing Systems, 2021. 1, 2, 7, 10, 11
A Proofs from Section 6
A.1 Proof of Theorem 6.1
We break the proof in a sequence of lemmas, starting with simplifying the objective function.
Lemma A.1. Let w = E [zφ ]. Then w ∈ B (s) and for any w ∈ Γ we have
0 D v 0 Γ
E [w(v)z] = ⟨w,w ⟩ . (13)
0 Γ
(v,z)∼D
Proof. For any w ∈ Γ we can write the correlation objective as
E [w(v)z] = E[⟨w,φ ⟩ z] = ⟨w,E[zφ ]⟩ = ⟨w,w ⟩ .
v Γ v Γ 0 Γ
(v,z)∼D
To bound its norm, observe that
∥w ∥ = ∥E[zφ ]∥ ≤ max ∥zφ ∥ ≤ s.
0 Γ v Γ v Γ
D v∈∆ ,z∈{±1}
k
Next we show that we can approximate w uniformly from samples by the function
0
n
1 (cid:88)
w˜ = z φ .
0
n
i vi
i=1
Lemma A.2. For any δ ∈ (0,1/2), for some n = O(r2s2α−2log(1/δ)), for any n ≥ n and any
0 0
(v ,z ),...,(v ,z ) drawn i.i.d. from D, with probability at least 1−δ,
1 1 n n
α
∥w˜ −w ∥ ≤ . (14)
0 0 Γ 3r
The proof uses McDiarmid’s inequality (see e.g. Lemma 26.4 of [SSBD14]).
Proof. We can write
(cid:13) (cid:13) (cid:13) (cid:13)
n n
∥w˜ −w ∥ = (cid:13) (cid:13)(cid:88) z iφ vi −w (cid:13) (cid:13) = 1 (cid:13) (cid:13)(cid:88) (z φ −w )(cid:13) (cid:13)
0 0 Γ (cid:13) n 0(cid:13) n (cid:13) i vi 0 (cid:13)
(cid:13) (cid:13) (cid:13) (cid:13)
i=1 Γ i=1 Γ
Since each term z φ −w has expectation 0, and the terms are independent, for i ̸= j
i vi 0
E[⟨z φ −w ,z φ −w ⟩ ] = 0
i vi 0 j vj 0 Γ
39Hence we can bound
 
n
1 (cid:88) (cid:88)
E[∥w˜ 0−w 0∥2 Γ] =
n2
E ∥z iφ
vi
−w 0∥2 Γ+ ⟨z iφ
vi
−w 0,z jφ
vj
−w 0⟩
i=1 i̸=j
1
= E[∥z φ −w ∥2]
n 1 v1 0 Γ
≤ 4s2/n ≤ (α/(6r))2.
by our choice of n. By convexity,
α
E[∥w˜ −w ∥ ] ≤ . (15)
0 0 Γ
6r
Note that each i.i.d. term z φ in the definition of w˜ has norm ∥z φ ∥ ≤ s, so by McDiarmid’s
i vi 0 i vi Γ
inequality, with probability at least 1−δ,
(cid:12) (cid:12)
(cid:12)∥w˜ 0−w 0∥ Γ−E[∥w˜ 0−w 0∥ Γ](cid:12) ≤ α/(6r). (16)
Combining this with Equation (15) gives the desired claim.
We need the following simple helper lemma to finish proving Theorem 6.1:
Lemma A.3. Let w,w˜ be elements of a Hilbert space Γ. If w˜ ̸= 0, define w¯ = w˜/∥w˜∥ . If w˜ = 0,
Γ
define w¯ to be an arbitrary element of B (1). Then
Γ
⟨w,w¯⟩ ≥ ∥w˜∥ −∥w−w˜∥ ≥ ∥w∥ −2∥w−w˜∥ .
Γ Γ Γ Γ
Proof. We have
⟨w,w¯⟩ ≥ ⟨w˜,w¯⟩−∥w−w˜∥ = ∥w˜∥ −∥w−w˜∥ ≥ ∥w∥ −2∥w−w˜∥ .
Γ Γ Γ Γ Γ
Proof of Theorem 6.1. In the weak agnostic learning task, we assume that there exists w ∈ B (r)
Γ
so that
E [w(v)z] ≥ α.
(v,z)∼D
Underthisassumption, LemmaA.1tellsusthat⟨w ,w⟩ ≥ α. Sincew ∈ B (r), wehave∥w∥ ≤ r,
0 Γ Γ Γ
and by the Cauchy-Schwarz inequality, r∥w ∥ ≥ ∥w ∥ ∥w∥ ≥ ⟨w ,w⟩ . Therefore, we can
0 Γ 0 Γ Γ 0 Γ
assume that ∥w ∥ ≥ α/r in the weak agnostic learning task.
0 Γ
Lemma A.2 ensures that (14) holds with probability at least 1−δ. As long as (14) holds, by
Lemma A.3 we have
(cid:28) (cid:29)
w˜ α
0
w , ≥ ∥w ∥ −2∥w −w˜∥ ≥ . (17)
0 0 Γ 0 Γ
∥w˜ ∥ 3r
0 Γ
The output w of Algorithm 1 can be expressed as
2
w˜
0
w = . (18)
2
s ∥w˜ ∥
0 Γ
Combining (17) and (18), we know that with probability at least 1−δ,
α
⟨w ,w ⟩ ≥ .
0 2
3rs
By Lemma A.1, the inequality above implies the weak learning guarantee, namely, E[w (v)z] ≥
2
α/(3rs). Finally, it is clear that ∥w ∥ ≤ 1/s, so w ∈ B (1/s), as desired.
2 Γ 2 Γ
40A.2 Proof of Theorem 6.2
ConsideradistributionD of(v,y) ∈ ∆ ×E ,anddefinez := y−v. Definew(j) := E[z(j)φ ],where
k k 0 v
z(j) is the j-th coordinate of z. For n i.i.d. data points (v ,y ),...,(v ,y ), define z := y −v .
1 1 n n i i i
Define w˜(j) := 1 (cid:80)n z(j) φ .
0 n i=1 i vi
Lemma A.4. When n ≥ Ckr2s2ε−2log(1/δ), with probability at least 1−δ,
k
(cid:88) (j) (j)
∥w˜ −w ∥ ≤ α/(3r). (19)
0 0 Γ
j=1
Proof. We first show that
k
(cid:88) (j) (j)
E∥w˜ −w ∥ ≤ α/(6r).
0 0 Γ
j=1
For every j,
(cid:13)
n
(cid:13)2
E[∥w˜ 0(j) −w 0(j) ∥2 Γ] = E(cid:13) (cid:13) (cid:13)n1 (cid:88) z( ij) φ vi −w 0(j)(cid:13) (cid:13) (cid:13) 
(cid:13) (cid:13)
i=1 Γ
n
= 1 (cid:88) E∥z(j) φ −w(j) ∥2 + 1 (cid:88) ⟨z(j) φ −w(j) ,z(j) φ −w(j) ⟩
n2 i vi 0 Γ n2 i vi 0 i′ v i′ 0
i=1 i̸=i′
n
= 1 (cid:88) E∥z(j) φ −w(j) ∥2
n2 i vi 0 Γ
i=1
1
= E[∥z(j) φ −w(j) ∥2]
n 1 v1 0 Γ
1
≤ E[∥z(j) φ ∥2]
n 1 v1 Γ
s2
≤ E[(z(j) )2]
n 1
By Cauchy-Schwarz,
(cid:118) (cid:118)
k (cid:113) (cid:117) k (cid:117) k √
(cid:88) E[(z(j) )2] ≤ (cid:117) (cid:116)k(cid:88) E[(z(j) )2] ≤ (cid:117) (cid:116)k(cid:88) E|z(j) | ≤ 2k.
1 1 1
j=1 j=1 j=1
Therefore,
√
(cid:88)k
E∥w˜(j) −w(j) ∥ ≤
(cid:88)k (cid:113)
E[∥w˜(j) −w(j) ∥2] ≤
s √2k
≤ α/(6r).
0 0 Γ 0 0 Γ n
j=1 j=1
Finally, we apply McDiarmid’s inequality to the following function of (z ,v ),...,(z ,v ):
1 1 n n
(cid:13) (cid:13)
k k n
(cid:88) ∥w˜(j) −w(j) ∥ = (cid:88)(cid:13) (cid:13)1 (cid:88) z(j) φ −w(j)(cid:13) (cid:13)
0 0 Γ (cid:13)n i vi 0 (cid:13)
(cid:13) (cid:13)
j=1 j=1 i=1 Γ
41and get that with probability at least 1−δ,
k k
(cid:88) (j) (j) (cid:88) (j) (j)
∥w˜ −w ∥ ≤ E∥w˜ −w ∥ +α/(6r) ≤ α/(3r).
0 0 Γ 0 0 Γ
j=1 j=1
Proof of Theorem 6.2. In the auditing task, we assume that there exists w ∈ B (r)k such that
Γ
E[⟨y−v,w(v)⟩] ≥ α.
Using our definition of z := y−v and w(ℓ) := E[z(ℓ)φ ], by Lemma A.1 we have
0 v
k k k
(cid:88) ∥w(ℓ) ∥ ≥ 1 (cid:88) ⟨w(ℓ) ,w(ℓ)⟩ = 1 (cid:88) E[z(j)w(j)(v)] = 1 E[⟨y−v,w(v)⟩] ≥ α/r.
0 Γ r 0 Γ r r
ℓ=1 ℓ=1 ℓ=1
Lemma A.4 ensures that (19) holds with probability at least 1 − δ. Define w¯ := w˜ /∥w˜ ∥ if
0 0 0 Γ
w˜ ̸= 0, and define w¯ := 0 if w˜ = 0. As long as (19) holds, by Lemma A.3,
0 0 0
k k k
(cid:88) (ℓ) (ℓ) (cid:88) (ℓ) (cid:88) (ℓ) (ℓ)
⟨w ,w¯ ⟩ ≥ ∥w ∥ −2 ∥w˜ −w ∥ ≥ α/(3r).
0 0 0 Γ 0 0 Γ
ℓ=1 ℓ=1 ℓ=1
(ℓ) (ℓ)
In Algorithm 2, we have w = w¯ /s, and thus the inequality above implies
2 0
k
(cid:88) (ℓ) (ℓ)
⟨w ,w ⟩ ≥ α/(3rs).
0 2
ℓ=1
Therefore by Lemma A.1, with probability at least 1−δ,
k k
E[⟨y−v,w (v)⟩] =
(cid:88) E[z(ℓ)w(ℓ)
(v)] =
(cid:88) ⟨w(ℓ) ,w(ℓ)
⟩ ≥ α/(3rs).
2 2 0 2
ℓ=1 ℓ=1
Thisprovesthattheoutputw ofAlgorithm2satisfiestherequirementoftheauditingtask. Finally,
2
it is clear that each w(ℓ) has norm ∥w(ℓ) ∥ ≤ 1/s, so w ∈ B (1/s)k, as desired.
2 2 Γ 2 Γ
42