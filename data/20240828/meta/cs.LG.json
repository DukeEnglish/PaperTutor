[
    {
        "title": "Generative Verifiers: Reward Modeling as Next-Token Prediction",
        "authors": "Lunjun ZhangArian HosseiniHritik BansalMehran KazemiAviral KumarRishabh Agarwal",
        "links": "http://arxiv.org/abs/2408.15240v1",
        "entry_id": "http://arxiv.org/abs/2408.15240v1",
        "pdf_url": "http://arxiv.org/pdf/2408.15240v1",
        "summary": "Verifiers or reward models are often used to enhance the reasoning\nperformance of large language models (LLMs). A common approach is the Best-of-N\nmethod, where N candidate solutions generated by the LLM are ranked by a\nverifier, and the best one is selected. While LLM-based verifiers are typically\ntrained as discriminative classifiers to score solutions, they do not utilize\nthe text generation capabilities of pretrained LLMs. To overcome this\nlimitation, we instead propose training verifiers using the ubiquitous\nnext-token prediction objective, jointly on verification and solution\ngeneration. Compared to standard verifiers, such generative verifiers (GenRM)\ncan benefit from several advantages of LLMs: they integrate seamlessly with\ninstruction tuning, enable chain-of-thought reasoning, and can utilize\nadditional inference-time compute via majority voting for better verification.\nWe demonstrate that when using Gemma-based verifiers on algorithmic and\ngrade-school math reasoning tasks, GenRM outperforms discriminative verifiers\nand LLM-as-a-Judge, showing a 16-64% improvement in the percentage of problems\nsolved with Best-of-N. Furthermore, we show that GenRM scales favorably across\ndataset size, model capacity, and inference-time compute.",
        "updated": "2024-08-27 17:57:45 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.15240v1"
    },
    {
        "title": "The Mamba in the Llama: Distilling and Accelerating Hybrid Models",
        "authors": "Junxiong WangDaniele PaliottaAvner MayAlexander M. RushTri Dao",
        "links": "http://arxiv.org/abs/2408.15237v1",
        "entry_id": "http://arxiv.org/abs/2408.15237v1",
        "pdf_url": "http://arxiv.org/pdf/2408.15237v1",
        "summary": "Linear RNN architectures, like Mamba, can be competitive with Transformer\nmodels in language modeling while having advantageous deployment\ncharacteristics. Given the focus on training large-scale Transformer models, we\nconsider the challenge of converting these pretrained models for deployment. We\ndemonstrate that it is feasible to distill large Transformers into linear RNNs\nby reusing the linear projection weights from attention layers with academic\nGPU resources. The resulting hybrid model, which incorporates a quarter of the\nattention layers, achieves performance comparable to the original Transformer\nin chat benchmarks and outperforms open-source hybrid Mamba models trained from\nscratch with trillions of tokens in both chat benchmarks and general\nbenchmarks. Moreover, we introduce a hardware-aware speculative decoding\nalgorithm that accelerates the inference speed of Mamba and hybrid models.\nOverall we show how, with limited computation resources, we can remove many of\nthe original attention layers and generate from the resulting model more\nefficiently. Our top-performing model, distilled from Llama3-8B-Instruct,\nachieves a 29.61 length-controlled win rate on AlpacaEval 2 against GPT-4 and\n7.35 on MT-Bench, surpassing the best instruction-tuned linear RNN model.",
        "updated": "2024-08-27 17:56:11 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.15237v1"
    },
    {
        "title": "DCT-CryptoNets: Scaling Private Inference in the Frequency Domain",
        "authors": "Arjun RoyKaushik Roy",
        "links": "http://arxiv.org/abs/2408.15231v1",
        "entry_id": "http://arxiv.org/abs/2408.15231v1",
        "pdf_url": "http://arxiv.org/pdf/2408.15231v1",
        "summary": "The convergence of fully homomorphic encryption (FHE) and machine learning\noffers unprecedented opportunities for private inference of sensitive data. FHE\nenables computation directly on encrypted data, safeguarding the entire machine\nlearning pipeline, including data and model confidentiality. However, existing\nFHE-based implementations for deep neural networks face significant challenges\nin computational cost, latency, and scalability, limiting their practical\ndeployment. This paper introduces DCT-CryptoNets, a novel approach that\nleverages frequency-domain learning to tackle these issues. Our method operates\ndirectly in the frequency domain, utilizing the discrete cosine transform (DCT)\ncommonly employed in JPEG compression. This approach is inherently compatible\nwith remote computing services, where images are usually transmitted and stored\nin compressed formats. DCT-CryptoNets reduces the computational burden of\nhomomorphic operations by focusing on perceptually relevant low-frequency\ncomponents. This is demonstrated by substantial latency reduction of up to\n5.3$\\times$ compared to prior work on image classification tasks, including a\nnovel demonstration of ImageNet inference within 2.5 hours, down from 12.5\nhours compared to prior work on equivalent compute resources. Moreover,\nDCT-CryptoNets improves the reliability of encrypted accuracy by reducing\nvariability (e.g., from $\\pm$2.5\\% to $\\pm$1.0\\% on ImageNet). This study\ndemonstrates a promising avenue for achieving efficient and practical\nprivacy-preserving deep learning on high resolution images seen in real-world\napplications.",
        "updated": "2024-08-27 17:48:29 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.15231v1"
    },
    {
        "title": "LLM Defenses Are Not Robust to Multi-Turn Human Jailbreaks Yet",
        "authors": "Nathaniel LiZiwen HanIan StenekerWillow PrimackRiley GoodsideHugh ZhangZifan WangCristina MenghiniSummer Yue",
        "links": "http://arxiv.org/abs/2408.15221v1",
        "entry_id": "http://arxiv.org/abs/2408.15221v1",
        "pdf_url": "http://arxiv.org/pdf/2408.15221v1",
        "summary": "Recent large language model (LLM) defenses have greatly improved models'\nability to refuse harmful queries, even when adversarially attacked. However,\nLLM defenses are primarily evaluated against automated adversarial attacks in a\nsingle turn of conversation, an insufficient threat model for real-world\nmalicious use. We demonstrate that multi-turn human jailbreaks uncover\nsignificant vulnerabilities, exceeding 70% attack success rate (ASR) on\nHarmBench against defenses that report single-digit ASRs with automated\nsingle-turn attacks. Human jailbreaks also reveal vulnerabilities in machine\nunlearning defenses, successfully recovering dual-use biosecurity knowledge\nfrom unlearned models. We compile these results into Multi-Turn Human\nJailbreaks (MHJ), a dataset of 2,912 prompts across 537 multi-turn jailbreaks.\nWe publicly release MHJ alongside a compendium of jailbreak tactics developed\nacross dozens of commercial red teaming engagements, supporting research\ntowards stronger LLM defenses.",
        "updated": "2024-08-27 17:33:30 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.15221v1"
    },
    {
        "title": "Automatic 8-tissue Segmentation for 6-month Infant Brains",
        "authors": "Yilan DongVanessa KyriakopoulouIrina GrigorescuGrainne McAlonanDafnis BatalleMaria Deprez",
        "links": "http://arxiv.org/abs/2408.15198v1",
        "entry_id": "http://arxiv.org/abs/2408.15198v1",
        "pdf_url": "http://arxiv.org/pdf/2408.15198v1",
        "summary": "Numerous studies have highlighted that atypical brain development,\nparticularly during infancy and toddlerhood, is linked to an increased\nlikelihood of being diagnosed with a neurodevelopmental condition, such as\nautism. Accurate brain tissue segmentations for morphological analysis are\nessential in numerous infant studies. However, due to ongoing white matter (WM)\nmyelination changing tissue contrast in T1- and T2-weighted images, automatic\ntissue segmentation in 6-month infants is particularly difficult. On the other\nhand, manual labelling by experts is time-consuming and labor-intensive. In\nthis study, we propose the first 8-tissue segmentation pipeline for\nsix-month-old infant brains. This pipeline utilizes domain adaptation (DA)\ntechniques to leverage our longitudinal data, including neonatal images\nsegmented with the neonatal Developing Human Connectome Project structural\npipeline. Our pipeline takes raw 6-month images as inputs and generates the\n8-tissue segmentation as outputs, forming an end-to-end segmentation pipeline.\nThe segmented tissues include WM, gray matter (GM), cerebrospinal fluid (CSF),\nventricles, cerebellum, basal ganglia, brainstem, and hippocampus/amygdala.\nCycle-Consistent Generative Adversarial Network (CycleGAN) and Attention U-Net\nwere employed to achieve the image contrast transformation between neonatal and\n6-month images and perform tissue segmentation on the synthesized 6-month\nimages (neonatal images with 6-month intensity contrast), respectively.\nMoreover, we incorporated the segmentation outputs from Infant Brain Extraction\nand Analysis Toolbox (iBEAT) and another Attention U-Net to further enhance the\nperformance and construct the end-to-end segmentation pipeline. Our evaluation\nwith real 6-month images achieved a DICE score of 0.92, an HD95 of 1.6, and an\nASSD of 0.42.",
        "updated": "2024-08-27 16:58:23 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.15198v1"
    }
]