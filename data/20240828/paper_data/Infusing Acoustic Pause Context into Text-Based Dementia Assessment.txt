Infusing Acoustic Pause Context into Text-Based Dementia Assessment
FranziskaBraun1,SebastianP.Bayerl2,FlorianHo¨nig4,HartmutLehfeld3,ThomasHillemacher3,
TobiasBocklet1,KorbinianRiedhammer1
1TechnischeHochschuleNu¨rnberg,2TechnischeHochschuleRosenheim,Germany
3Klinikfu¨rPsychiatrieundPsychotherapie,Universita¨tsklinikderParacelsusMedizinischen
Privatuniversita¨t,KlinikumNu¨rnberg,Germany,4KSTInstitutGmbH,BadEmstal,Germany
franziska.braun@th-nuernberg.de
Abstract vs. AD)andintheexclusionofdementiaversushealthycon-
trols(NCvs.AD).
Speech pauses, alongside content and structure, offer a valu-
Toachievethis,weextractspeechmarkersthatgobeyond
ableandnon-invasivebiomarkerfordetectingdementia. This
thecontentandstructureofwhatissaidandadditionallylookat
work investigates the use of pause-enriched transcripts in
whatisnotsaid: thepausesinspeech. Speechpausescanbea
transformer-based language models to differentiate the cogni-
valuableindicatorofdementiaastheydifferinfrequency,dura-
tivestatesofsubjectswithnocognitiveimpairment,mildcog-
tionandothercharacteristics(e.g.,syntaxposition)fordifferent
nitive impairment, and Alzheimer’s dementia based on their
stagesofcognitivedecline.Weinvestigatedifferentapproaches
speech from a clinical assessment. We address three binary
to encode pauses in language models and in a first approach
classificationtasks:Onset,monitoring,anddementiaexclusion.
wetrainaself-attentionbasedsystemtolearnthepausecontext
TheperformanceisevaluatedthroughexperimentsonaGerman
fromthetextmodality.Inasecondapproach,weallowthetext
Verbal Fluency Test and a Picture Description Test, compar-
systemtoincorporatethepausecontextfromacousticinforma-
ingthemodel’seffectivenessacrossdifferentspeechproduction
tionusingcross-attention.
contexts.Startingfromatextualbaseline,weinvestigatetheef-
In this paper, we analyze different ways to incorporate
fectofincorporationofpauseinformationandacousticcontext.
pausedurationandacousticcontext.Wefindthat:
Weshowthetestshouldbechosendependingonthetask,and
1. NC and MCI are best discriminated using the VFT when
similarly,lexicalpauseinformationandacousticcross-attention
acousticinformationisincorporated.
contributedifferently.
Index Terms: speech biomarkers, dementia assessment, neu- 2. MCI and AD can best be distinguished using the PDT,
ropsychologicaltests,pathologicalspeech wherebythemodelingofdisfluenciesandpausesinthetext-
basedsystemissufficient.
1. Introduction 3. NC and AD can be reliably distinguished independently of
thetest,butthemodelingofpausesisbeneficial.
Recent breakthroughs in antibody therapy offer promising
prospects for slowing the progression of Alzheimer’s disease 2. RelatedWork
whenappliedatanearlystage[1].However,earlyandaccurate
detectionofdementiaandmonitoringofdiseaseprogressionre- Speechanalysishasshownpromiseasanon-invasiveapproach
mains a major challenge in clinical assessment. Current gold todetectingdementia,withanincreasingfocusoninvestigating
standard biomarkers, such as those from blood, cerebrospinal thepotentialofpausesinspeechasavaluableindicator.
fluidandmagneticresonanceimaging(MRI),offerthemostac- Several studies have observed a correlation between the
curatedetectionofAlzheimer’sdisease,butareinvasive(except severity of dementia and increased pause duration in vari-
MRI),expensiveandoftennoteasilyaccessible. Furthermore, ousspeechtasks,includingstorytelling[2],picturedescription
as they are not sensitive enough for early stages of dementia [3, 4, 5, 6], verbal fluency [7, 8], reading [9], recall tasks [2]
suchasmildcognitiveimpairment,acombinationofclinicalas- and many more. This suggests that analyzing pause patterns
sessmentandneuropsychologicalevaluationremainscrucialfor could provide insights into cognitive function and potentially
accurateandearlydiagnosis. Speechanalysishasproventobe helpdistinguishhealthyindividualsfromthosewithdementia.
apromisingnon-invasiveandcost-effectiveapproachtodetect- Beyond the overall duration, researchers are investigat-
ingdementia.Italsohastheadvantageofprovidingbiomarkers ing the specific characteristics of pauses at different stages of
thatareeasilyaccessibleduringneuropsychologicalassessment Alzheimer’s dementia (AD). For example, some studies sug-
orthroughspontaneousspeech. gest that people with AD show longer silent pauses (related
Inthispaper,weusespeechsamplesfromaGermanmulti- to word-finding problems) than healthy controls. While Lof-
center study in which established clinical assessment tools grenetal. [7]foundnosignificantdifferenceinthefrequency
were used to assess the speech of individuals with no cogni- or duration of filled pauses, Yuan et al. [5] found that indi-
tiveimpairment(NC),withmildcognitiveimpairment(MCI), vidualswithADtendedtousethefiller“uh”morefrequently
and with mild to moderate dementia (AD) in the context of thanhealthyindividuals. Syntax-relatedanalysesshowedthat
Alzheimer’sdisease. Toexaminetheperformanceofthemod- certain verbs (such as “is”) are sensitive to AD [10] or that
elsindifferentcontextsofspeechproduction,wecomparethe clause-initial pauses occur more frequently in moderate AD,
speechfromtwoestablishedcognitivetests: aVerbalFluency while more pauses occur within-clause positions in mild AD,
Test(VFT)andaPictureDescriptionTest(PDT).Ourexperi- especiallybeforenouns(challengesinreferencingobjects)[7].
mentsaimtodistinguishspeechmarkersofindividualsinonset Inmanystudies,featuresfromspeechanalysis(e.g.,lexical,
dementia(NCvs. MCI),inthemonitoringofdementia(MCI linguistic)andsignalprocessing(e.g.,acoustic,temporal)were
4202
guA
72
]SA.ssee[
1v88151.8042:viXracombinedtoclassifyNC,MCIandAD,oftenincludingpause Table1:Demographicsfornocognitiveimpairment(NC),mild
statisticssuchaspauserateandduration[8,11,12,13,14,15]. cognitiveimpairment(MCI),Alzheimer’sDementia(AD)group
Ko¨nig et al. [16] found that in picture description tasks, fea-
turesthatreflectthecontinuityofspeech(i.e.,longercontiguous Count Age Gender
speechsegmentsandshortersilencesegments)havethehighest
NC 82 55-87(68.9+-7.9) 32m/50f
discriminativepower. Forsemanticfluency,thelargestcontri-
MCI 58 55-85(70.9+-8.3) 31m/27f
butiontoclassificationaccuracywasobtainedfromthetempo-
AD 65 55-85(71.6+-8.8) 32m/33f
ral positions of individual words in the first part of the task.
Featuresobtainedfromthedurationofspeechandsilenceseg- All 205 55-87(70.3+-8.3) 95m/110f
mentswereusefulfordiscriminatingMCIfromAD,butwere
notsignificantforNCvs.MCI.
Other studies showed the suitability of transformer-based
possiblefromasemanticcategoryinagiventimelimit. Inthis
architectures that encode linguistic (e.g., BERT) and acoustic
case,thesubjectwasaskedtonameasmanydifferentanimals
(e.g., W2V2) contextual information for the detection of cog-
aspossiblewithinoneminute.
nitiveimpairment[17,18,19]. Yuanetal. [5,6]presenteda
The PDT was developed primarily for the detection of
methodforencodingfilledandunfilledpausesintranscriptsof
Alzheimer’sdisease. Itmeasurestheamountandqualityofin-
picturedescriptionstofine-tunethetrainingoflanguagemod-
formation that a subject can obtain from a visual stimulus by
els(ERNIE,BERTandRoBERTa),andachievedhighaccura-
describingapicture. Inthiscase,thesubjectwasaskedtode-
ciesinthedetectionofAD,forexampleintheADReSSchal-
scribethepictureofamountainsceneasshowninFigure11.
lenge[5,20].Inourpreviouswork[18],wefoundthatalthough
weachievedhighperformanceindementiaclassificationusing
BERTandW2V2, distinguishingMCIfromhigherandlower
cognitiveimpairmentclassesremainedchallengingandmaybe
relatedtootherneurodegenerativedisorders(e.g.,depression).
Most recent work in the TAUKADIAL challenge of IN-
TERSPEECH2024introducedamultilingualbaselineforMCI
detectionusingspeechfromanovelbenchmarkofpicturede-
scription tasks in English and Chinese. The authors used es-
tablished baselines such as audio signal, linguistic and acous-
ticfeaturesandreportedresultsthatwerearoundchancelevel.
They obtained the best MCI classification results of 59.18%
(UAR)bycombiningeGeMAPsandW2V2features[21].This
highlightstheongoingmajorchallengesassociatedwithgener-
Figure1:PictureDescriptionTask“MountainScene”
alizableearly-stagedementiadetection.
In this work, we aim to fill the gap in literature by in-
vestigating pause-enhanced transformers for the detection of
4. Method
NC, MCI and AD. These pause-enhanced transformers com-
binetheaforementionedapproachesfromspeechanalysisand
4.1. Pause-EnrichedTranscripts
signalprocessingbyinherentlycapturinglinguistic, syntactic,
acousticandtemporalfeaturesandadditionallyenrichingthem For our experiments, we create automatic transcripts using
withpauseinformation. Whisper [23]; accurate timestamps are computed using DTW
appliedtocross-attentionweights,asdemonstratedby[24].
3. Data For transcription, we use whisper-large-v3
(beam size=5, best of=5, temperature=(0.0, 0.2, 0.4, 0.6, 0.8,
Thedatawasselectedfromamulti-centerstudythatwaspre- 1.0)). Priortotranscription,weruntheembeddedSileroVAD
sentedanddescribedindetailinourpreviouswork[18];itwas topreventthewhispermodelfrom“hallucinating”textwhena
provided by the PARLO Institute for Research and Teaching segmentwithoutspeechispresentandtoobtainmoreaccurate
in Speech Therapy. This study is an open, controlled, cross- word timestamps. Pause durations are computed across all
sectionalclinicalstudywithparallelgroups,conductedwiththe segmentsbetweentheendtimeofeachwordandthestarttime
sameiPadtypeandappatnineacademicmemoryclinicsacross of the following word. In order to add the resulting pauses
Germany. The multi-center study allows for generalizability to the transcripts, they were grouped by mapping them to the
across populations, dialects and recording conditions and has followingpausedurationintervals(inseconds):
showntogeneralizeacrossotherindependentlyrecordedGer-
• BaselineP1(3specialtokens):[0.05,0.5[;[0.5,2.0];]2,∞[
mandatasets[18].Thedemographicdataofthe82NC,58MCI
• Baseline P2 (6 special tokens): [0.05,0.1]; ]0.1,0.3];
and65ADGerman-speakingsubjectscanbefoundinTable1.
]0.3,0.6];]0.6,1.0];]1.0,2.0];]2.0,∞[
Thespeechsamplesusedcontainapproximatelyoneminute
ofaudiopersubjectduringtheperformanceofasemanticVer- • BaselineP3(3specialtokens):[0.2,0.6];]0.6,1.5[;[1.5,∞[
balFluencyTest(VFT)andoneminuteduringtheperformance • BaselineP4(1specialtoken):[0.2,0.6];]0.6,1.5[;[1.5,∞[
ofaPictureDescriptionTest(PDT). ThepauseintervalsinbaselineP1[5]wereempiricallyderived
The semantic VFT is often used in the diagnosis of vari- fromthedataanalysisoftheADReSSdataset[20],whichisa
ousdementiasub-types,especiallyintheearlystages. Itmea- subsetof156speakers(NCandAD)ofthePittcorpus[25]and
suresthespeedandeaseofverbalproduction,semanticmem- containsrecordingsoftheCookieTheftPicturedescriptiontask
ory,linguisticabilities,executivefunctionsandcognitiveflexi-
bility[22]. ThetaskofthisVFTistonameasmanytermsas 1PARLOGmbH,www.parlo-institut.de[26].BaselineP2[6]proposedapausedistributionderivedfrom formerlayer,representingabout0.02secondsoftheaudio.This
thedata-drivenanalysisoftheINTERVIEWdataset[27],which resultsinN =T/0.02−1vectorsfortheextractioncontextof
contains105Kconversations(10Khours)fromsevenNational T (i.e.,449vectorsforanextractioncontextof10seconds).To
PublicRadioprogramsover20years. Alinguisticstudy(base- obtainthefinalembeddings,wecomputethemeanvectorover
lineP3)[4]examinedpausesinthespeechofNC,MCIandAD allextractedfeaturevectorsofasampleandapplyzero-padding
individualsperforminganarrativepicture-storydescriptiontask alongthetimedimension.
from the Bilingual Aphasia Test [28]. Thus, we obtain pause
duration distributions for the groups of NC vs. AD (baseline 5. Experiments
P1), NC only (baseline P2) and NC vs. MCI vs. AD (base-
line P3). The resulting pauses are automatically inserted into Toassesstheperformanceofthemodels,weusestratifiedfive-
thetranscriptsduringthetranscriptionprocessusingspecialto- foldcross-validation(5-foldCV)bysplittingthedataintofive
kens. BaselineP4isobtainedusingthepausemodelingofP3, speaker-distincttrainingandtestsetscomprising 80%and 20%
butinsteadofaddingthreespecialtokensforeachpause,weadd of the data, respectively. We use the Area Under the Curve
onlyonespecialtokenattherespectivepositionsregardlessof (AUC) to measure the ability of the binary classifiers to dis-
duration.P4thereforecontainspositionalbutnotemporalpause criminatebetweenclassesasasummaryoftheROCcurve.The
information.Inaddition,weusethelibrary’simplicitdisfluency highertheAUCvalue,thebettertheperformanceofthemodel
token([*]), whichisoutputwhenpotentialdisfluenciesinthe indiscriminatingbetweenthepositiveandnegativeclasses.
attentionweightsareidentifiedduringspeechrecognition,and Our binary classification experiments aim to discriminate
addedittoP3toobtainanotherbaseline. Thereasonwefocus speechandspeechpausesofindividualsinthreeclinicalassess-
onP3isthatitistheonlybaselinethatexaminespausesinall menttasks: Dementiaonset(NCvs. MCI),monitoring(MCI
threehealthconditions(HC,MCIandAD). vs. AD)andexclusion(NCvs. AD).Allexperimentsarecon-
ductedwithspeechdatafromthetwocognitivetestsdescribed
4.2. TextEmbeddings in section 3 using the text and audio embeddings from sec-
tion 4. BERT features are extracted using the pause-enriched
WechooseBidirectionalEncoderRepresentationsfromTrans-
transcripts from section 4.1 for P1–P4 as well as for P3 plus
formers (BERT) as a pre-trained masked language model for
disfluencytokens. ForW2V2featurestheextractedlayerLis
natural language processing, as it has been shown to be suit-
selectedfromL∈{1,2,...,12}.
ableforourpurposesinpreviouswork[18,5,6]. BERTusesa
Please note that for reasons of comparability, all experi-
transformer-basedarchitecturetoprocesslargeamountsoftext
mentsareperformedinafixedhyper-parametersetting(lr=5e-
dataandcapturetherelationshipsbetweenwordsinasentence.
5, optimizer=Adam, batch size=8, max epochs=20, activa-
In our experiments, we use the BERT base model pre-trained
tion function=ReLU,drop out=0.1)withouttuning.Weassume
on about 12 GB of German text data (Wiki, OpenLegalData,
that optimizing the hyper-parameters can lead to higher per-
News) to predict masked words and the next sentence. The
formance. The training is stopped early to prevent the model
modelweightsareopen-sourceandcanbeaccessedonline2.
frompossiblyoverfittingonthelimitedtrainingdata. Weuse
Additional special tokens are added for all pause tokens
thecross-entropylossfunctioninwhicheachclassisassigned
fromsection4.1totheBERTTokenizerandthemodelembed-
a rescaling weight to compensate with unbalanced class dis-
dingsareadaptedtothenewvocabularylength. Weobtainthe
tributions during training. The model architecture consists of
finaltextembeddingsfromthelasthiddenstatesofthemodel
a single-head attention module (pytorch), followed by a MLP
withoutpoolingbutwithzeropaddingalongthesequencedi-
classifierwithonehiddenlayer(hidden dim=512)andoneout-
mension,whichcorrespondsto768dimensionalfeaturevectors
put layer with two output neurons. Stratified batch sampling
pertokenintheinputsequence.
isusedduringtraining,wherethebatcheddataisfirstpassedto
theattentionmodule.Meanpoolingandlayernormalizationare
4.3. AudioEmbeddings appliedtotheresultingattentionoutputsandthenpassedtothe
Theaudioembeddingsarederivedfromwav2vec2.0(W2V2), MLPclassifier. Tocalculateprobabilitiesandclasspredictions
a transformer-based architecture designed for learning speech softmaxandargmaxareappliedtothelogitsofthemodel.
representationsfromrawaudiodata.Themodel’sconvolutional Inourbaselineexperiments,weuseBERTandW2V2fea-
layersactasapowerfulfeatureencoderthatprocessesrawau- tures separately and apply self-attention (i.e., query, key, and
dio waveforms directly. This allows the model to learn data- valueremainthesame)tolearntext-basedandacoustic-based
driven representations that can capture specific contextualized pausecontext. Inanimprovedsetting,weallowthetext-based
speech features obtained from 12 transformer blocks (W2V2- systemtolearnpausecontextfromtheacousticembeddingsby
base)thatuseself-attentiontofocusonthetask-specificparts usingone-waycross-attentionfromthetexttotheaudiomodal-
oftheaudio.ThefeaturesextractedfromW2V2havebeensuc- ity(i.e.,usingtextasqueryandaudioaskeyandvalue).
cessfullyusedtodetectcognitiveimpairmentinpreviouswork
[18,17,29].Weuseabasemodelthatwasfine-tunedbasedon 6. Results
theMozillaFoundation’sCommonVoice9.0datasetasafea-
The binary classification results for the detection of early de-
tureextractorwithoutadjustment;themodelweightsareopen-
sourceandcanbeobtainedonline3. mentiaareshowninTable2,withthebestresultsobtainedfor
VFTfortheP4baselinewiththeinclusionofacousticcontext
We z-normalized the waveform data before input and ob-
(cross-attention)andP3modelingplusdisfluenciesinthetext-
taineda768-dimensionalspeechrepresentationaftereachtrans-
basedsystem(self-attention). Thiscouldberelatedtothefact
thatP3istheonlyoneofthebaselinesthatinitiallyproposed
2https://huggingface.co/
bert-base-german-cased pausedistributionsthatarecharacteristicintheMCIcondition.
3https://huggingface.co/oliverguhr/ We hypothesize that the disfluencies in the text-based assess-
wav2vec2-base-german-cv9 ment together with the pause duration provide relevant infor-mation about verbal fluency, both of which could presumably Table4:AverageAUC(in%)in5-foldCVfortheclassification
alsobelearnedfromtheacousticsinP4, thebaselinewithout ofNCvs.ADusingBERTandW2V2features(bestlayer)from
text-based pause duration information. The fact that the VFT theVFTandPDTinself-attentionandcross-attentionwithand
generally performs better than the PDT in this task could be withoutpausecoding(P1–4)anddisfluencies(Disfl.).
duetothefactthatittriggersspeechproductionthatisalready
impairedatearlystagesofdementia. VFT PDT
Table3showsthatMCIandADarebestdistinguishedus-
features self-att cross-att self-att cross-att
ing the PDT, where modeling of pauses (P3) and disfluencies
inthetext-basedscenarioissufficient. Aswithearlydetection, BERT 88.3 86.9 84.4 84.6
weattributethistothefactthatP3modelingrelatestotheMCI BERTP1 89.6 86.9 88.2 85.5
stageandthatfluencyislikelytodecreaseascognitivedecline BERTP2 88.8 85.5 85.4 84.1
progresses.WesuspectthatthePDTworksbetterthantheVFT BERTP3 88.0 86.8 85.2 85.5
inthiscasebecauseitisspecializedforthedetectionofAD. BERTP4 87.4 85.7 84.7 86.0
As shown in Table 3, NC and AD can be reliably distin- BERTP3+Disfl. 86.6 85.7 84.9 86.4
guishedregardlessofthetest,butmodelingthepausesseemsto
W2V2 85.3 - 83.1 -
beadvantageous.Thebestresultsforbothtests,VFTandPDT,
wereobtainedwithwithP1modeling. Weassumethatthisis
duetothefactthattheP1baselineanalyzedspeechpausesin
ADclassificationfromhealthycontrols,sothetaskmatchesthe usingspeechfromtwocognitivetests. Wewereabletoshow
investigatedspeechbasisofthepausecoding. thatoursystemsarequitecapableofclassifyingcognitiveim-
TheW2V2featuresperformedworseoverallthanthebest pairment at different stages and benefit from enrichment with
pause-enhancedratinginalltasksandtests,butoftenimproved pauses. Inadditionweinvestigatedtheeffectofincorporating
performancewhenusedincross-attention. pauseinformationfromtheacousticcontextintothetext-based
assessment. WefoundthattheVFTperformedbestindetect-
Table2:AverageAUC(in%)in5-foldCVfortheclassification ing MCI versus healthy controls when the text-based assess-
ofNCvs.MCIusingBERTandW2V2features(bestlayer)from mentcouldlearnfromacousticinformation. Forthedetection
theVFTandPDTinself-attentionandcross-attentionwithand ofMCIversusdementia,thePDTshowedthehighestdiscrim-
withoutpausecoding(P1–4)anddisfluencies(Disfl.). inativepower,withmodelingofpausesanddisfluenciesbeing
sufficientinthetext-basedassessment. Dementiacouldbeex-
cludedfromhealthycontrolsregardlessoftestandcontext,but
VFT PDT
pausemodelingisadvantageous.
features self-att cross-att self-att cross-att Whileourfindingssuggestpausesinspeechofferapromis-
BERT 66.3 71.0 57.8 67.5 ing indicator for the detection of cognitive decline in clinical
BERTP1 66.0 70.2 58.5 70.3 assessment,severalkeyconsiderationsandchallengesremain.
BERTP2 65.5 71.2 52.4 70.0 Pauseoccurrenceanddurationcanbeinfluencedbyseveralfac-
BERTP3 66.7 71.2 56.6 68.6 torsbesidesdementia,includingage,language,speakingstyle,
BERTP4 66.1 71.4 57.1 68.0 andemotionalstate. Thisnecessitatescarefulcontrolofthese
BERTP3+Disfl. 69.3 71.1 62.4 67.9 biasesandpotentiallyincorporatingadditionalspeechfeatures
toenhancetherobustnessofanalysis.Researchonspeechpause
W2V2 67.5 - 66.2 - analysis in dementia detection often involves relatively small
datasets. Furtherstudieswithlargerandmorediversepopula-
tionsarecrucialtoestablishthegeneralizabilityandreliability
Table3:AverageAUC(in%)in5-foldCVfortheclassification ofthisapproachforreal-worldapplication.
ofMCIvs.ADusingBERTandW2V2features(bestlayer)from It’s crucial to remember that no single biomarker is cur-
theVFTandPDTinself-attentionandcross-attentionwithand rently considered a definitive diagnostic tool for dementia.
withoutpausecoding(P1–4)anddisfluencies(Disfl.). Physicians often utilize a combination of approaches, includ-
ing clinical evaluation, cognitive assessments, and sometimes
acombinationofthesemodalities,toreachadiagnosis. Addi-
VFT PDT
tionally,thespecifictestschosenandtheirinterpretationdepend
features self-att cross-att self-att cross-att on various factors, including the patient’s individual situation
andsuspectedtypeofdementia. Dementiaencompassesvari-
BERT 71.0 66.7 71.8 76.4
oussubtypes(e.g., Alzheimer’s, Lewybody), eachpotentially
BERTP1 68.8 69.2 77.6 76.3
showingvaryinglevelsofdetectabilitythroughdifferentmodal-
BERTP2 67.5 67.1 77.3 77.8
ities and tests. Combining pause analysis with other speech
BERTP3 71.3 68.6 74.7 77.8
features (e.g., prosody, articulation) in multimodal and multi-
BERTP4 71.7 70.4 79.5 77.8
testapproachesholdpotentialforimprovingtheaccuracyand
BERTP3+Disfl. 70.6 70.6 80.5 77.2
robustnessofdementiadetection.
W2V2 67.1 - 73.4 - Overall, theresearchonspeechpausesindementiadetec-
tion is promising, offering valuable insights into potential di-
agnosticmarkers. Theresultsalsosuggestthatacousticcross-
7. DiscussionandConclusion attention could benefit from pause-dependent masking to pre-
ventoverfittingtootherregions.However,addressingthemen-
Inthiswork,weinvestigatedthepotentialofspeechpausesas tionedchallengesandlimitationsiscrucialforestablishingthis
markersofcognitivedeclineintext-baseddementiaassessment approachasareliableandgeneralizabletoolforclinicaluse.8. References
[15] V. Vincze, M. K. Szabo´, I. Hoffmann, L. To´th, M. Pa´ka´ski,
J. Ka´lma´n, and G. Gosztolya, “Linguistic Parameters of Spon-
[1] C. H. Van Dyck, C. J. Swanson, P. Aisen, R. J. Bateman,
taneous Speech for Identifying Mild Cognitive Impairment and
C. Chen, M. Gee, M. Kanekiyo, D. Li, L. Reyderman, S. Co-
Alzheimer Disease,” Computational Linguistics, pp.1–33, Feb.
hen,L.Froelich,S.Katayama,M.Sabbagh,B.Vellas,D.Wat-
2022.
son, S. Dhadda, M. Irizarry, L. D. Kramer, and T. Iwatsubo,
“LecanemabinEarlyAlzheimer’sDisease,”NewEnglandJour- [16] A.Ko¨nig,A.Satt,A.Sorin,R.Hoory,O.Toledo-Ronen,A.Der-
nalofMedicine,vol.388,no.1,pp.9–21,Jan.2023. reumaux, V. Manera, F. Verhey, P. Aalten, P. H. Robert, and
R.David,“Automaticspeechanalysisfortheassessmentofpa-
[2] V. Vincze, G. Szatlo´czki, L. To´th, G. Gosztolya, M. Pa´ka´ski,
tientswithpredementiaandAlzheimer’sdisease,”Alzheimer’s&
I.Hoffmann,andJ.Ka´lma´n,“Telltalesilence: temporalspeech
Dementia:Diagnosis,Assessment&DiseaseMonitoring,vol.1,
parameters discriminate between prodromal dementia and mild
no.1,pp.112–124,2015.
Alzheimer’sdisease,”ClinicalLinguistics&Phonetics,vol.35,
no.8,pp.727–742,Aug.2021. [17] F.Braun,A.Erzigkeit,H.Lehfeld,T.Hillemacher,K.Riedham-
mer,andS.P.Bayerl,“GoingBeyondtheCookieTheftPicture
[3] R.A.Sluis,D.Angus,J.Wiles,A.Back,T.A.Gibson,J.Liddle,
Test:DetectingCognitiveImpairmentsUsingAcousticFeatures,”
P.Worthy,D.Copland,andA.J.Angwin,“AnAutomatedAp-
inText, Speech, andDialogue, P.Sojka, A.Hora´k, I.Kopecˇek,
proachtoExaminingPausingintheSpeechofPeopleWithDe-
andK.Pala,Eds. SpringerInternationalPublishing,2022,pp.
mentia,”AmericanJournalofAlzheimer’sDisease&OtherDe-
437–448.
mentiasr,vol.35,p.153331752093977,Jan.2020.
[18] F.Braun, S.P.Bayerl, P.A.Pe´rez-Toro, F.Ho¨nig, H.Lehfeld,
[4] P.Pastoriza-Dom´ınguez,I.G.Torre,F.Die´guez-Vide,I.Go´mez-
Ruiz,S.Gelado´,J.Bello-Lo´pez,A.A´vilaRivera,J.A.Mat´ıas- T.Hillemacher,E.No¨th,T.Bocklet,andK.Riedhammer,“Clas-
sifyingDementiainthePresenceofDepression:ACross-Corpus
Guiu,V.Pytel,andA.Herna´ndez-Ferna´ndez,“Speechpausedis-
Study,”inProc.INTERSPEECH2023,2023,pp.2308–2312.
tribution as an early marker for Alzheimer’s disease,” Speech
Communication,vol.136,pp.107–117,Jan.2022. [19] A. Balagopalan, B. Eyre, F. Rudzicz, and J. Novikova, “To
BERTornottoBERT:ComparingSpeechandLanguage-Based
[5] J.Yuan,Y.Bian,X.Cai,J.Huang,Z.Ye,andK.Church,“Disflu-
Approaches forAlzheimer’s Disease Detection,” in Interspeech
enciesandFine-TuningPre-TrainedLanguageModelsforDetec-
2020. ISCA,Oct.2020,pp.2167–2171.
tionofAlzheimer’sDisease,”inInterspeech2020. ISCA,Oct.
2020,pp.2162–2166. [20] S.Luz,F.Haider,S.d.l.Fuente,D.Fromm,andB.MacWhin-
ney, “Alzheimer’sDementiaRecognitionThroughSpontaneous
[6] J.Yuan,X.Cai,andK.Church,“Pause-EncodedLanguageMod-
Speech:TheADReSSChallenge,”inInterspeech2020. ISCA,
els for Recognition of Alzheimer’s Disease and Emotion,” in
2020,pp.2172–2176.
ICASSP2021-2021IEEEInternationalConferenceonAcous-
tics, Speech and Signal Processing (ICASSP). Toronto, ON, [21] S.Luz,S.d.l.F.Garcia,F.Haider,D.Fromm,B.MacWhinney,
Canada:IEEE,Jun.2021,pp.7293–7297. A.Lanzi, Y.-N.Chang, C.-J.Chou, andY.-C.Liu, “Connected
speech-basedcognitiveassessmentinchineseandenglish,”2024,
[7] M.LofgrenandW.Hinzen, “Breakingtheflowofthought: In-
finalDOItobeassigned.
creaseofemptypausesintheconnectedspeechofpeoplewith
mildandmoderateAlzheimer’sdisease,”JournalofCommunica- [22] B.IsaacsandA.T.Kennie,“TheSettestasanaidtothedetection
tionDisorders,vol.97,p.106214,May2022. ofdementiainoldpeople,”TheBritishJournalofPsychiatry:The
JournalofMentalScience,vol.123,no.575,pp.467–470,1973.
[8] A.Ko¨nig,N.Linz,J.Tro¨ger,M.Wolters,J.Alexandersson,and
P. Robert, “Fully Automatic Speech-Based Analysis of the Se- [23] J.Louradour,“whisper-timestamped,”https://github.com/linto-ai/
manticVerbalFluencyTask,”DementiaandGeriatricCognitive whisper-timestamped,2023.
Disorders,vol.45,no.3-4,pp.198–209,2018.
[24] T.Giorgino,“Computingandvisualizingdynamictimewarping
[9] J. J. G. Meila´n, F. Mart´ınez-Sa´nchez, J. Carro, D. E. Lo´pez, alignments in r: The dtw package,” Journal of Statistical Soft-
L.Millian-Morell,andJ.M.Arana,“SpeechinAlzheimer’sDis- ware,vol.31,no.7,2009.
ease: CanTemporalandAcousticParametersDiscriminateDe-
[25] J.T.Becker,F.Boller,O.L.Lopez,J.Saxton,andK.L.McGo-
mentia?” DementiaandGeriatricCognitiveDisorders,vol.37,
nigle,“ThenaturalhistoryofAlzheimer’sdisease:descriptionof
no.5-6,pp.327–334,2014.
studycohortandaccuracyofdiagnosis,”ArchivesofNeurology,
[10] Y. Zhu, B. Tran, X. Liang, J. A. Batsis, and R. M. Roth, “To- vol.51,no.6,pp.585–594,1994.
wardsInterpretabilityofSpeechPauseinDementiaDetectionUs-
[26] J.C.Borod,H.Goodglass,andE.Kaplan,“Normativedataonthe
ingAdversarialLearning,” inICASSP2022-2022IEEEInter-
bostondiagnosticaphasiaexamination,parietallobebattery,and
nationalConferenceonAcoustics,SpeechandSignalProcessing
the boston naming Test,” Journal of Clinical Neuropsychology,
(ICASSP). Singapore,Singapore: IEEE,May2022,pp.6462–
vol.2,no.3,pp.209–215,Nov.1980.
6466.
[27] B. P. Majumder, S. Li, J. Ni, and J. McAuley, “Interview:
[11] A.Ko¨nig,A.Satt,A.Sorin,R.Hoory,A.Derreumaux,R.David,
Large-scalemodelingofmediadialogwithdiscoursepatternsand
andP.H.Robert,“UseofSpeechAnalyseswithinaMobileAp-
knowledgegrounding,”inProceedingsofthe2020Conferenceon
plicationfortheAssessmentofCognitiveImpairmentinElderly
Empirical Methods in Natural Language Processing (EMNLP),
People,”CurrentAlzheimerResearch,vol.15,no.2,pp.120–129,
B.Webber,T.Cohn,Y.He,andY.Liu,Eds. Online: Associa-
Jan.2018.
tionforComputationalLinguistics,Nov.2020,pp.8129–8141.
[12] L. Calza`, G. Gagliardi, R. Rossini Favretti, and F. Tamburini,
[28] M.Paradis, Bilingualaphasiatest. LawrenceErlbaumAsso-
“Linguisticfeaturesandautomaticclassifiersforidentifyingmild
ciatesHillsdale,NJ,USA:,1987.
cognitiveimpairmentanddementia,” ComputerSpeech&Lan-
guage,vol.65,p.101113,Jan.2021. [29] A. Balagopalan and J. Novikova, “Comparing Acoustic-Based
Approaches forAlzheimer’s Disease Detection,” in Interspeech
[13] M. Asgari, J. Kaye, and H. Dodge, “Predicting mild cognitive
2021. ISCA,Aug.2021,pp.3800–3804.
impairment from spontaneous spoken utterances,” Alzheimer’s
& Dementia: Translational Research & Clinical Interventions,
vol.3,no.2,pp.219–228,Jun.2017.
[14] R. Nagumo, Y. Zhang, Y. Ogawa, M. Hosokawa, K. Abe,
T. Ukeda, S. Sumi, S. Kurita, S. Nakakubo, S. Lee, T. Doi,
andH.Shimada,“AutomaticDetectionofCognitiveImpairments
through Acoustic Analysis of Speech,” Current Alzheimer Re-
search,vol.17,no.1,pp.60–68,Mar.2020.