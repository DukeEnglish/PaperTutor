Constraining Participation: Affordances of Feedback Features
in Interfaces to Large Language Models
NEDCOOPER,AustralianNationalUniversity,Australia
ALEXANDRAZAFIROGLU,AustralianNationalUniversity,Australia
Largelanguagemodels(LLMs)arenowaccessibletoanyonewithacomputer,awebbrowser,andaninternet
connectionviabrowser-basedinterfaces,shiftingthedynamicsofparticipationinAIdevelopment.This
paperexaminestheaffordancesofinteractivefeedbackfeaturesinChatGPT’sinterface,analysinghowthey
shapeuserinputandparticipationinLLMiteration.DrawingonasurveyofChatGPTusersandapplying
themechanismsandconditionsframeworkofaffordances,wedemonstratethatthesefeaturesencourage
simple,frequent,andperformance-focusedfeedbackwhilediscouragingcollectiveinputanddiscussions
amongusers.Wearguethatthisfeedbackformatsignificantlyconstrainsuserparticipation,reinforcing
powerimbalancesbetweenusers,thepublic,andcompaniesdevelopingLLMs.Ouranalysiscontributestothe
growingbodyofliteratureonparticipatoryAIbycriticallyexaminingthelimitationsofexistingfeedback
processesandproposingdirectionsfortheirredesign.ToenablemoremeaningfulpublicparticipationinAI
development,weadvocateforashiftawayfromprocessesfocusedonaligningmodeloutputswithspecific
userpreferences.Instead,weemphasisetheneedforprocessesthatfacilitatedialoguebetweencompanies
anddiverse‘publics’aboutthepurposeandapplicationsofLLMs.Thisapproachrequiresattentiontothe
ongoingworkofinfrastructuring—creatingandsustainingthesocial,technical,andinstitutionalstructures
necessarytoaddressmattersofconcerntogroupsimpactedbyAIdevelopmentanddeployment.
AdditionalKeyWordsandPhrases:LargeLanguageModels,Human-AIInteraction,UserFeedback,Participa-
toryAI
1 Introduction
ThedeploymentofChatGPTbyOpenAIin2022markedasignificantshiftinhowlargelanguage
models(LLMs)aremadeavailabletothepublic.ChatGPT’sbrowser-basedinterfaceallowsbroad
accesstointeractionswithLLMsthroughtextprompts,expandinguserparticipationintheiterative
developmentofLLMs.Previously,companiessuchasOpenAIandGoogletookamorecautious
approach.OpenAIusedapplicationprogramminginterfaces(APIs)andaniterativeapproachto
deploytheGPT-2andGPT-3familyofmodels[11,66],limitingaccesstodevelopersandresearchers.
Similarly,GoogleannouncedversionsoftheLanguageModelforDialogueApplications(LaMDA)
in2021and2022butdidnotmakeitpubliclyavailablethroughaninterfaceormodelrelease[71].
FollowingChatGPT’sdeployment,numerousotherLLMsweremadeaccessibleviabrowser-based
interfaces(e.g.,Bard/GeminiandClaude.ai)oropenreleases(e.g.,LLaMA).
Thisshiftintheapproachtodeploymenthasprecipitatedachangeintherelationshipbetween
companiesdevelopingLLMsandtheirusers—wearenotonlyusersofLLMsbutalsoparticipantsin
theiriteration.Formanyyears,usersandnon-usershavebeenrepresentedindatasetsusedtotrain
models,constitutingaformofpassiveandinvoluntaryparticipation[65].However,withrecent
deploymentsofpublic-facinginterfaces,usersnowhaveamoreactiveandvoluntaryavenuefor
participationbysubmittingfeedbackonpromptcompletionsthroughinteractivefeaturesinthese
interfaces.
Thisarticlefocusesontheaffordancesofinteractivefeedbackfeaturesinpublic-facinginterfaces
toLLMs,usingChatGPTasacasestudy.Feedbackreceivedthroughthesefeaturesplaysarole
intheiterationofLLMsbyaligningmodeloutputswithspecificpreferences.This“bottom-up”
approachtoalignmentelicitspreferencesfrombroadgroupsofusers[35].Othershavesoughtto
Authors’ContactInformation:NedCooper,edward.cooper@anu.edu.au,AustralianNationalUniversity,Canberra,Australia;
AlexandraZafiroglu,alex.zafiroglu@anu.edu.au,AustralianNationalUniversity,Canberra,Australia.
Preprint.UnderReview.
4202
guA
72
]CH.sc[
1v66051.8042:viXra2 CooperandZafiroglu
expandtherangeofperspectivesrepresentedinthesegroupsbeyondthelimitedsetofhuman
ratersinvolvedininstruction-tuningLLMsbeforedeployment[42].However,ouranalysisfocuses
onhowtheaffordancesofthepost-deploymentfeedbacksystemamplifycertainperspectivesand
concernswhilemarginalisingothers.Specifically,weaddresstworesearchquestions:
(1) WhataretheaffordancesofinteractivefeedbackfeaturesintheChatGPTinterface?
(2) Howdothoseaffordancesshapethenatureandscopeofuserinputandparticipationinthe
iterationofLLMs?
Toaddressthesequestions,wefirstsurveyedChatGPTuserswhohavesubmittedfeedback.We
thendrewonthesurveyinsightstoanalyseinteractivefeaturesintheChatGPTinterfacethatallow
userstosubmitfeedback,usingDavis’s[18]mechanismsandconditionsframeworkofaffordances.
OuranalysisindicatesthattheChatGPTinterfaceencouragessimple,frequent,individualised,
andunidirectionalfeedbackonperformance-relatedconcernswhilediscouragingfeedbackfrom
collectivesordiscussionsamongusers.
Wediscussimplicationsfor(re)designingfeedbackprocessesforLLMs.First,weexploredelib-
erativeapproachesthatmightenablebidirectionalcommunication,changesinperspectivesover
time,anddiscussionaboutsocialorethicalissuesamonggroupsofusers.However,werecognise
thatdeliberationonrulesetsformodeloutputswillnotfundamentallyalterthepowerdynamics
betweenusers,thepublic,andplatforms.Second,weconsiderthe“infrastructuring”[46]required
to support and sustain more expansive feedback channels between the public and technology
companies.WeconcludebyurgingcompaniesdeployingLLMstoshifttheirfocusfromaligning
modeloutputswithuserpreferencestofosteringsustaineddialoguewithdiverse‘publics’about
thepurposesandapplicationsofthesetechnologies.Thisapproachrequirescarefulattentionto
theongoingworkofinfrastructuringparticipation—creatingandmaintainingthesocial,technical,
andinstitutionalstructuresnecessaryforgenuinepublicengagementinAIdevelopment.Wemust
movebeyondpreferenceelicitationbeforeLLMsbecomeubiquitousinfrastructure—systemsthat
areembeddedinotherstructures,transparentinuse,andonlyvisibleuponbreakdown[67].
2 Background
Inthissection,weexploreconceptsrelatedtoparticipatoryapproaches,feedbackfeatures,and
thechallengesofscaleinthecontextofLLMs.First,weprovideanoverviewofthealignment
problemandthe“participatoryturn”inAI[21].Next,weexaminefeedbackfeaturesusedinrecent
deployments of LLMs through browser-based interfaces. Then, we explore the implications of
scaleforthe“sameness”ofthosefeaturesacrossdiversecontexts[79].Weconcludethesection
byproposingthestudyoftheseconceptsthroughthemechanismsandconditionsframeworkof
affordances.
2.1 AlignmentandParticipatoryApproaches
Inrecentyears,technologycompanieshaveexploredvariousformsofuserparticipationtoaddress
thealignmentproblem—ensuringthatAIsystemsbehaveinwaysthatalignwithhumanvalues
[61].Twofundamentalquestionspertinenttothealignmentproblemare:whatvaluesshouldAI
systemsalignwith,andwhoshoulddecidethosevalues?[35]Oneapproachtoaddressingboth
questionsisbottom-up—elicitingpreferencesfromabroadlydefinedpublicandinferringfrom
thosepreferencesthevaluestoalignwith[35].
InterestinparticipatoryapproachesforaligningLLMsispartofabroaderparticipatoryturn
in AI research, design, and development [21]. Participatory Al projects involve end users and
thoseimpactedbyAIsystemsinthedesignanddevelopmentofthosesystems[15],drawingon
long-standingtraditionsinotherfields,suchasparticipatorydesign[52,68]andparticipatory
Preprint.UnderReview.ConstrainingParticipation:AffordancesofFeedbackFeaturesinInterfacestoLargeLanguageModels 3
planning[1,41].TheturntoparticipationinAIresearch,designanddevelopmenthasincluded
papers,panelsandworkshopsonparticipatorymachinelearning(ML)atprominentcomputer
scienceconferences[44,82]andcallsforpublicparticipationinAIinrecentpolicyframeworks
[31,70,74].
Participatory approaches promise more “democratic” AI systems [44] and more “pluralistic”
alignment[42].However,thereisabroadspectrumofparticipatorypracticesinAIdesign,from
informingorconsultingparticipantstoequitablepartnershipswithparticipants[7,16,21].This
spectrumofparticipatorypracticesalsoexistedinparticipatorydesign,participatoryplanning,
andotherantecedentfields.Forthedevelopmentoflarge-scaleAIsystems,participationhasoften
takenpassiveandinvoluntaryformsthroughtherepresentationofgroupsofindividualsindatasets
usedtotrainmodels[22,65].WhilefeedbackfeaturesininterfacestoLLMsprovideamoreactive
andvoluntaryformofuserparticipation,theiremergenceastheprimarymodeforthepublicto
influencedevelopmentprocesseshasraisedquestionsabouttheconceptualleapfromstructured
preferenceelicitationtogenuineparticipatoryengagement[33].
Additionally,thereisasignificantgapbetweenthescaleofparticipatorymethodsandthetraining
and deployment of recent AI systems [23]. Surveys of participatory approaches in computing
research[14]andParticipatoryAIprojects[21]indicatethatengagementshaveprimarilybeen
localised,focusingononeorafewgroupsorcommunitieswithsharedcharacteristics.Incontrast,
recentdeploymentsofLLMsthroughbrowser-basedinterfacesareaccessibletoanyonewithaccess
toacomputer,awebbrowser,andaninternetconnection.
2.2 InteractiveFeedbackFeaturesinInterfacestoLLMs
Feedbackhasarichhistoryrootedincybernetics,whichintroducedtheideaoffeedbackloops,
where the output of a system is fed back as input, and queried the implications of feedback
loopsformodellingdynamicalsystemsovertime[77].Theconceptoffeedbackloopsinfluenced
subsequentAIresearchdirections[51]andremainsfundamentaltoAIsystemsthatlearnovertime.
Concurrently,‘feedback’hasalsobecomeageneraltermreferringtoinformationprovidedbyan
observer(e.g.,usersorotherstakeholders)assessingasystem’sperformance.
Reinforcement Learning from Human Feedback (RLHF) demonstrates how the two types of
feedbackarecombinedinmodernAIdevelopment.RLHFbeginswithevaluativefeedback,whena
modelgeneratestworesponsestoagivenpromptandhumanratersdeterminewhichresponse
isbetterthantheotheraccordingtocriteria.Thesehumanassessmentsarethenusedtocreatea
cyberneticfeedbackloop:anRLalgorithmusestheassessmentstopredicthowahumanwould
rateotherresponses,andanLLMisfine-tunedontheresultingrewardmodel[3,56,80].This
approachhasbecomecentraltoaligningpre-trainedLLMswithspecificpreferences[45].However,
integratinghumanfeedbackintothelearningprocessincreasesthetimetotrainamodelandthe
labourcostsinvolved[48].RLHFrequireslarge,diversegroupsofhumanraterstoassessprompt
completionsbeforefine-tuningthemodelinthefinalstage[58].
TheimportanceofRLHFforaligningLLMshasincreasedthedemandforhumanfeedbackdata
[45]andresearchattentiontopracticesforcreatingandcuratingdiverse,representative,andquality
humanfeedbackdata[32,42,58].However,lessattentionhasbeenpaidtohumanfeedbackcollected
throughinteractivefeaturesininterfacestoLLMs,inwhichusersevaluatepromptcompletions
ofdeployedsystems.ThisformoffeedbackiscapturedafteragivenLLMhasbeentrainedand
deployed,andsuchfeedbackmaybeusedtoimprovefuturemodeliterations.Forexample,OpenAI
used feedback on non-factual responses obtained through the feedback features in ChatGPT’s
interface,withadditionallabelledcomparisondata,totrainrewardmodelsthatreducedGPT-4’s
tendencyto“hallucinate”comparedtoGPT-3.5[55].
Preprint.UnderReview.4 CooperandZafiroglu
Fig.1. Thumbs-upordownfeedback-ChatGPT(May2023)
Fig.2. Open-textwindowafterthumbs-up-ChatGPT(May2023)
Fig.3. Open-textwindowafterthumbs-down-ChatGPT(May2023)
ThereisgrowinginterestincrowdsourcinghumanfeedbackdatasetstoalignLLMswithuser
preferences[e.g.,47].IntheblogpostannouncingthedeploymentofChatGPT,OpenAIemphasised
theirinterestincollectinguserfeedbacktouncoverpotentialrisksandharms:
“Weare...interestedinfeedbackregardingharmfuloutputsthatcouldoccurinreal-
world, non-adversarial conditions, as well as feedback that helps us uncover and
understandnovelrisksandpossiblemitigations.”[54]
OpenAI launched a feedback competition alongside the ChatGPT interface to encourage user
participation (running through December 2022). Users were encouraged to submit free-form
feedbackviaaGoogleformthatcouldhelpOpenAIidentifypotentialreal-worldrisksandharms,
withwinnersreceiving$500inOpenAIAPIcredits.
TheChatGPTinterfacewasalsoequippedwithseveralinteractivefeaturesdesignedtocollect
userfeedback,allowinguserstogivethumbs-up/thumbs-down(seeFig.1)andopen-textfeedback
aboutresponses(seeFig.2andFig.3),aswellastoregeneratearesponseandidentifywhether
the second response was better, the same, or worse than the original (see Fig. 4). Additionally,
checkboxesintheopen-textfeedbackwindowsalloweduserstostructuretheirfeedbackagainstthe
prominent“helpful,honest,andharmless”frameworkforAIalignment[2].OtherinterfacestoLLMs,
suchasAnthropic’sClaude.aiandGoogle’sBard/Gemini,incorporatefeedbackfeaturessimilar
totheChatGPTinterfacetogatheruserinputandpreferences.ThedeploymentofLLMsthrough
theseinterfaceshasmadethesesystemsaccessibletoavastanddiverseuserbase,presentingnew
challengesrelatedtoscale.
2.2.1 ScaleandAffordances. Thestandardisationoffeedbackfeaturesacrossinterfacestodifferent
systemsexemplifiestheproceduralisationandreplicationthatcharacteriseotherdigitalsystems
deployedatlargescale[37].LLMsarebasedondeepneuralnetworksthatlearnfrommassive
datasets,andthesesystemshavegrownsignificantlyinsizeinrecentyears—forexample,from
Preprint.UnderReview.ConstrainingParticipation:AffordancesofFeedbackFeaturesinInterfacestoLargeLanguageModels 5
Fig.4. Feedbackafterregeneratingaresponse-ChatGPT(May2023)
millionsofparametersinGPT-1tobillionsinGPT-2[66]andGPT-3[9],and(reportedly)trillions
inGPT-4[57].Butmorethansimplyexpandingthesizeofasystem,scalingdigitalsystemsacross
globalcontextsinvariablyrequiresimposingastandardisedworldviewandorganisingphenom-
enathatcanoperatecontext-independently[38,72].Thissamenessisachievedthroughmassive
infrastructuralinvestments,suchasdatacentres,standardisedsoftwareandpolicies,andglobaldis-
tributionnetworks[79].FeedbackfeaturesininterfacestoLLMs(andtheassociatedinfrastructure
formanaging,storingandprocessingfeedbackdata)representonesuchinfrastructuralinvestment
designedtoelicitparticipationatscale.Notably,thesefeedbackfeaturesareidenticalforallusersof
agiveninterfacetoanLLM(e.g.,ChatGPT,Bard/Gemini,orClaude.ai)andsimilaracrossdifferent
interfacestovariousLLMs,despitethediversityofglobalcontextsinwhichusersinteractwith
thesesystems.
However, this sameness can obscure the power dynamics inherent in the feedback process.
Achievingscaleindigitalcontextsisanaggregationofpower—engineeringthesuppressionof
contexttorendercomplexsocialrealitiescoherentthroughacomputationallylegibleframe[37,
72].AsEubanks[30]demonstrates,thedesignofscaledtechnicalsystemscanreinforceexisting
inequalitiesandmarginalisecertainvoices.Forexample,peoplelesslikelytoengagewiththese
interfaces,suchasthosewithlimiteddigitalliteracyoraccess,maybeunderrepresentedinthe
feedbackdatausedtorefinethefamilyofmodelsunderlyingtheinterfaces.Thestandardisationof
feedbackfeaturesacrossdifferentsystemsmightalsoleadtothehomogenisationofuserinput,
riskingtheamplificationofcertainbiasesorthesuppressionofdiverseperspectives.Itisthus
imperativetocriticallyexaminewhatkindsofperspectivesandcontextsthesefeedbackfeatures
makevisibleandvaluableasformsofparticipation—bothtothosewhoparticipateandtothose
whointegratefeedbackfromparticipantsintoMLworkflows.Theconceptofaffordancesprovides
oneusefullensforconductingsuchananalysis.
2.2.2 Mechanisms andConditionsFramework ofAffordances. Affordancetheorystates thatan
animalperceivesitsenvironmentnotonlyintermsoftheshapesofobjectsorthespacebetween
objectsbutalsointhepossibilitiesofobjectsforaction[36].Animals,towhichGibson[36]refers,
sharethesameenvironmentbutperceiveitdifferentlyaccordingtotheiraffordances—theircapacity
tobenefitorexperienceharmfromaparticularfeatureoftheenvironment.Norman[53]later
adaptedaffordancetheoryfortechnologydesign,arguingthattechnologicalobjectsafforddifferent
possibilitiesforhumansandotheragentsandthatthosepossibilitiescannotbedefinedexceptby
referencetotheobject’sadoptionanduse[39].Theaffordancesofatechnologicalobjectarethus
thelinkbetweentheobject’sfeaturesandtheoutcomesofthetechnologicalobject’sadoptionand
usebysubjects[18].DavisandChouinard[20]describetheselinksas“relationalprocessesamong
users,designers,environments,andthings”.
Davis [18] operationalises the concept of affordances through a framework of mechanisms
andconditions.Mechanismsdescribethelinkbetweenfeaturesoftechnologicalobjectsandthe
outcomesoftheirusebysubjects,whileconditionsdescribehowaffordancesvaryacrossdifferent
Preprint.UnderReview.6 CooperandZafiroglu
subjectsandcontexts.Theframeworkproposessixmechanismsthatcontributetotheoperationali-
sationofaffordances:request,demand,encourage,discourage,refuse,andallow.Thesemechanisms
are intended to serve as a tool for critical analysis rather than as a taxonomy of the features
oftechnologicalobjects,aseachmechanismmayrevealdifferentaspectsofatechnicalfeature.
Technologicalobjectsrequestanddemandhowuser-subjectsinteractwiththem.Technological
objectsalsoencourageanddiscourage,refuseandallowactionsofuser-subjects.Thesemechanisms
operatethroughthreeinterrelatedconditions:perception(howasubjectperceivestheartifactbased
ontheirskillandtechnicalliteracy),dexterity(whatasubjectcandowiththeartifact),andcultural
andinstitutionallegitimacy(thesocialandstructuralpositionoftheuserwithininstitutionsof
power).Theframeworkaddressesbinarism(assuminganartifactaffordssomefunctionornot)and
universalism(assuminganartifactoperatesidenticallyforall)inaffordancetheory[20].Usingthis
framework,wecanexplore“how,forwhom,andunderwhatcircumstances”artefactsaffordaction
[18].
IfwerecogniseML-enabledtechnologiesasmaterialartefactsthatreflectandaffectusersthrough
designdecisions,andacknowledgetheirpotentialtoexacerbateinequalityinsocialsettingsand
workplaces[19],wemustscrutinisetheaffordancesofsuchtechnologiesandapplications.The
mechanismsandconditionsframeworkprovidesastructuredapproachtoanalysehowthedesign
offeedbackfeaturesininterfacestoLLMsaffordscertainactionswhileconstrainingothers,thereby
shaping the nature and scope of user input and participation in RLHF workflows. Affordance
theoryisusefulforanalysinghowusersgenerateevaluativefeedbackthroughLLMinterfaces
andhowthisfeedbackissubsequentlyshapedandconstrainedtofunctionascyberneticinputin
RLHFworkflows.Theframework’semphasisontheinterdependentandpower-ladenrelationship
betweenhumansandtechnologiessupportsourcriticalexaminationofthesamenessofscaled
systems.Furthermore,theframeworkoffersavocabularyforthe(re)designoffeedbackfeatures
toaddressissueswemayidentifyforuserinputandpublicparticipationthroughsocio-technical
analysis[18].
3 Method
WeconductedanonlinesurveytogatherinsightsfromChatGPTuserswhohadsubmittedfeedback
usingthefeaturesinthebrowser-basedinterface.Throughthesurvey,weaimedtoexplorefeedback
practicesandperspectivesofChatGPTuserstounderstandwhichuserssubmitfeedback,howthey
submitfeedback,andwhytheysubmitfeedback.Wethendrewontheinsightsfromthesurveyto
analysethefeedbackfeaturesthroughthemechanismsandconditionsframeworkofaffordances.
Below,wedetailtheprocessweusedtoconductthesurveyandtheanalysis,andwethendescribe
thelimitationsofourapproach.Inthefollowingsection,wepresenttheinsightsfromouranalysis.
3.1 Datacollection
3.1.1 Pilot Survey. We conducted two pilot surveys in March 2023 with 32 respondents from
ouruniversitytorefineoursurveyinstrument’sclarity,flow,andlength.InlateMarch2023,the
HumanEthicsReviewCommitteeatouruniversityapprovedourrecruitmentplanandfinalsurvey
instrument.
3.1.2 SurveyInstrument. Thesurveyinstrumentconsistedof45questions—approximately21were
consistentacrossrespondents,andthesurveylogicdeterminedtheremainder.Thesurveyasked
respondents about their frequency and types of ChatGPT usage, experiences with submitting
feedback through the ChatGPT interface and external channels, reasons for submitting or not
submittingfeedback,perceptionsofthefeedbackprocess,thelikelihoodofprovidingfuturefeedback
throughtheinterfaceandexternalchannels,anddemographiccharacteristics(includingtheAI,
Preprint.UnderReview.ConstrainingParticipation:AffordancesofFeedbackFeaturesinInterfacestoLargeLanguageModels 7
ML,anddatasciencebackgroundofrespondents).Mostquestionsweremultiple-choice,withafew
open-endedquestionstogathermoredetailedinsightsandreflectionsfromrespondents.
3.1.3 RecruitmentandSampling. WeadministeredthepublicsurveyonQualtricsinMay2023
andusedamulti-prongedapproachtorecruitparticipants.Initially,theauthorspostedthesurvey
ontheirsocialmediaaccounts(Twitter,Mastodon,andLinkedIn),forumsfrequentedbyactive
ChatGPTusers(GitHubforums,HuggingFaceforums,theOpenAIcommunityforum,andKaggle
forums),andonther/ChatGPTDiscordserver.
WealsorecruitedparticipantsthroughProlifictoaddressnon-responsebiasandexpandthe
respondentpoolbeyondthoseengagedwithAI,ML,ordatascienceinresearchordevelopment
capacities.WeappliedscreeningstrategiesonProlifictoinviterelevantrespondentstothefinal
survey.Firstly,weusedProlificfilterstoidentifyrespondentsfromanycountry,reportingfluency
inEnglish,anapprovalrategreaterthanorequalto95%,and10ormoreprevioussubmissions.
Secondly,weinvitedfilteredrespondentstoacustomscreeningsurveywithtwoquestionsasking
participantsaboutchatbotusageandfeedbacksubmission.1 Finally,weinvitedrespondentsap-
provedafterthescreeningsurveytothefinalsurveyatthreeseparateintervalstocoverworking
hoursinregionswithdifferenttimezones.RespondentstothefinalsurveyonProlificreceivedthe
equivalentof£9/hrfortheirtime.
3.1.4 Respondents. Thesurveyreceivedresponsesfrom526individuals—afterremovingincom-
pletesurveys,failedattentionchecks2,andscreenedsurveys3—withamediancompletiontimeof
fiveminutesand11seconds.Therespondentswerepredominantlyyoung,withoverthreequarters
aged18–34(42.4%aged18–24,35.1%aged25–34,n=524).Thegenderdistributionwasskewed
towardsmen(63.1%),with34.9%identifyingaswomen,1.2%asnon-binaryorthirdgender,and
0.8%preferringnottosayorpreferringtoself-describe(n=521).Geographically,therespondents
wereprimarilyfromEurope(55.4%),followedbyAfrica(15.6%),theUnitedKingdom(10.3%),and
Oceania(6.5%)(n=507).ThemostcommonlanguagesspokenbyrespondentswereEnglish(UK,US,
orAU)(61.1%),Portuguese(13.4%),andPolish(12.2%)(n=509).4
RespondentsreportedvaryinglevelsofengagementwithAI-relatedtopics(e.g.,throughnews
articles,researchpapers,podcasts,etc.),with63.1%atleastweekly,18.9%monthly,andonly18.0%
rarelyornever(n=523).Asubstantialproportion(41.0%)hadusedAI,ML,ordatasciencetools
beyondbasicinteractionorexplorationbeforeusingChatGPT(n=522).Furthermore,26.5%had
completedformaleducationortrainingintheseareas(n=520),and21.3%wereworkingorhad
previouslyworkedinarelatedfield(n=521).
3.2 DataAnalysis
Initially,weperformedfrequencyanalysisformostquestions(seeAppendixA).Forcertainvariables
measuredona5-pointLikertscale,wetransformedtheresponsesintothreecategories(e.g.,Agree,
Neutral,Disagree;orLikely,Neutral,Unlikely)tosimplifytheanalysisandinterpretation.Wethen
performedchi-squaretestsofindependence(𝜒2)toanalyserelationshipsbetweenresponses,using
Cramér’sVtodeterminethestrengthoftheassociations[13].Beforetheseanalyses,weremoved
rowswithmissingvaluesfordemographicsandexperiencefactorsandgroupedcategorieswith
lowfrequenciesforrelevantquestions(e.g.,consolidatingagegroupsandgeographicregions).
Toaddressthemultiplecomparisonsproblem,weappliedtheBenjamini-Hochbergprocedureto
controlthefalsediscoveryrateacrossalltestssimultaneously[4].Wereportstatisticallysignificant
1ChatGPTusagewasnotanoptionforfiltersonProlificinMay2023.
2OnlyProlificsurveys.
3ValidIPAddress,“Yes”to“ReadandagreetoParticipantInformationSheet”,“Yes”to“HasusedChatGPT”.
4Respondentscouldselectuptothreelanguagestheyspeakdaily.
Preprint.UnderReview.8 CooperandZafiroglu
resultsbasedontheadjusted𝑝-values(adj.𝑝-value).Allstatisticaltestswereconductedata95%
confidencelevel(df=degreesoffreedom;seeAppendixBforfullresults).
Foropen-endedquestionsinthesurvey,weconductedathematicanalysisofresponses[8],with
thefirstauthorinitiallydevelopingcodesbasedonthesemanticcontentofthefirst50responses
usingtagsinthecodingsoftwareAtlas.ti.Bothauthorsthenmettodiscussandconsolidatethecodes,
afterwhichthefirstauthorcodedtheremainingresponses,followedbyafinaljointdiscussionto
identifyandagreeonkeythemesreflectingthedata.Finally,wedrewoninsightsfromthesurvey
andourinterfaceanalysistoinformtheaffordancesanalysis.
3.3 Limitations
Ourmethodologyhasseveralimportantlimitations.Firstly,werecognisethatoursurveydataset
doesnotstatisticallyrepresentanygroup—neitherChatGPTusersingeneralnorthesubsetof
ChatGPTuserswhohavesubmittedfeedbackthroughtheinterface[73].Wesampledasubsetof
ChatGPTusersinMay2023,thoughthenetworksoftheauthorsandthepopulationofuserson
Prolificinfluenceoursample.ThenumberandcharacteristicsofChatGPTusersingeneralare
notfreelyavailable,norarethenumberorcharacteristicsofChatGPTuserswhohavesubmitted
feedback.Thissurveyinstrumentwasconductedtosamplethatpopulationwithinaconstrained
budget.Assuch,oursurveyinsightsareexploratoryandnotgeneralisabletothepopulationof
ChatGPTusers.Nevertheless,theseinsightsareausefulstartingpointforunderstandinguser
practicesandperspectivesrelatedtofeedbackfeaturesininterfacestoLLMs.
Secondly,oursurveyreliesonself-reporteddatafromrespondents.Wedidnotcreateaprimary
datasetoffeedbackinstances,aswecouldnotaccessadatasetoffeedbackinstancessubmitted
throughtheChatGPTinterface.Instead,wecollectedasecondarydatasetofthetypeoffeedback
(e.g.,thumbs-up/down,open-textfeedback,etc.)andthebroadcategoriesoffeedback(e.g.,correcting
technicalerrors/bugs,socialandethicalinformation,etc.)providedbyrespondents.Theremaybe
discrepanciesbetweenwhatusersreportedandtheiractualfeedbackbehaviour.Wenote,however,
thatthesurveywasconductedprimarilytounderstandthepracticesandperspectivesofChatGPT
userswhohavesubmittedfeedbackratherthantoanalysethecontentofthefeedbackitself.
WealsoengagedwithearlyadoptersofChatGPT,asoursurveywasconductedinthefirstsix
monthsafterdeployment.InAprilandMay2023,surveysofU.S.adultsfoundthatonly16%[75]and
14%[6]hadusedChatGPT,respectively.Asaresult,therespondents’demographicsandresponses
toquestionsabouttheirexperiencewithAI,ML,anddatasciencemaynotrepresentthebroader
populationofChatGPTusersasadoptionchangesovertime.Earlyadopterstendtohavehigher
educationlevels,highersocioeconomicstatus,andbemoreengagedwithdevelopmentsinemerging
technologiesthanlateradopters[60],whichmayskewthesurveyresults.IfChatGPTusagebecomes
moremainstream,thecharacteristicsandperspectivesofusersmaychange,potentiallyaffectingthe
typesoffeedbackprovidedandthemotivationsforengagingwiththefeedbackfeatures.However,
asofMarch2024,only23%ofU.S.adultsreportedusingChatGPT[49],suggestingthattheearly
adoptereffectmaystillberelevanttoourfindings.
Finally,whilesurveyfindingsprovideusefulinformationaboutuserpracticesandperspectives
concerning feedback, there are limitations to using this data for our affordances analysis. The
surveyprovidesasnapshotofuserperspectivesandexperiencesatapointintime.TheChatGPT
interface and feedback features have and will continue to change, so the affordances of those
feedbackfeaturesanduserbehavioursmaychangeaccordingly.However,asofMay2024,thebasic
functionalityhasnotchangedsignificantly,thoughusersarepromptedwithfeedbackcategories
wheretheywerepreviouslyprovidedwithanopen-textbox(seeFig.5),andausermayberequested
tosubmitpairwisefeedback(see,e.g.,Fig.6).Wealsonotethatuserinterviewsorobservations
couldprovidemorein-depthinformationabouthowusersperceiveandinteractwiththefeedback
Preprint.UnderReview.ConstrainingParticipation:AffordancesofFeedbackFeaturesinInterfacestoLargeLanguageModels 9
Fig.5. Additionalfeedbackcategoriesafterselectingthumbs-down-ChatGPT(May2024)
Fig.6. Pairwisefeedbackoptions-ChatGPT(May2024,contentofresponseshidden)
features,thoughwearguethatsurveydataissufficientforourhigh-levelanalysisthroughthe
mechanismsandconditionsframeworkofaffordances.
4 InsightsandAnalysis
ThissectionreportsinsightsfromthesurveyregardingChatGPTusage,feedbackpractices,and
respondents’motivationsforsubmittingfeedback.Throughoutthesection,wedrawontheinsights
toinformouranalysisoftheaffordancesoffeedbackfeaturesintheChatGPTinterface.
Our analysis suggests how the design of feedback features imposes constraints on end-user
participation.Insummary,theinterfacerequestsfeedbackformattedinthe‘helpful,honest,and
harmless’framework,demandsinteractionbeforeallowingfeedbacksubmission,andencourages
simple,frequent,individualised,andunidirectionalfeedback,particularlythumbs-up/downratings
andfeedbackafterregeneratingaresponse.However,theinterfacediscouragescollectivefeedback
andrefusesfeedbackmodificationovertime.Additionally,oursurveyindicatesthatthefeedback
featuresmayappealmoretouserswithfrequentengagement,priorexperience,andknowledgeof
AI,MLordatascience.
4.1 MechanismsofAffordance
OursurveyrevealshowusersinteractwithChatGPTanditsfeedbackfeatures,whichinfluencethe
typeandqualityofdatafedbackintoRLHFworkflows.RespondentsusedChatGPTfrequentlyand
indiverseways.Over71.6%(n=525)usedChatGPTatleastweekly,andthemostcommonusecases
wereansweringspecificquestions(e.g.,factual,technical,ortheoreticalquestions),generatingtext
(e.g.,draftingemails,writingessaysorreports),andacademicresearchassistance(e.g.,generating
citations,summarisingarticles).
This usage pattern is significant because a person cannot directly influence ML workflows
outsidethatsystem.Ausermustpromptthedialogueagentbeforetheycansubmitfeedback.This
designfeatureeffectivelydemandsinteractionwithanLLMbeforeallowingparticipationthrough
feedbacksubmission,establishingthefirstkeymechanismofaffordanceweobserved.
4.1.1 SubmittingFeedback. ThefeedbackfeaturesintheChatGPTinterfacearedesignedtoelicit
individualresponses,whicheffectivelydiscouragescollectivefeedbackordiscussionsamongusers.
Thisindividualisationextendstothepermanenceoffeedback:userscannotmodifytheirinput
Preprint.UnderReview.10 CooperandZafiroglu
oncesubmitted,eveniftheygainnewinformationortheirperspectivechanges.Whileuserscould
theoretically input the same prompt a second time and submit feedback, the stochastic nature
of LLMs means each response is likely to be unique, making direct comparisons or revisions
challenging.Thisdesignchoicereinforcestheindividualnatureofthefeedbackprocessandlimits
opportunitiesforevolving,collectiveinput.
OursurveyfindingsindicatethattheChatGPTinterfaceencouragesthumbs-up/downfeedback
andfeedbackafterregeneratingaresponse.Mostrespondents(84.2%,n=526)indicatedtheyhad
submittedfeedbackthroughoneofthethreemethodsintheChatGPTinterface.Thumbs-up/down
feedbackwasthemostcommon(76.0%,n=526),followedbyfeedbackafterregeneratingresponses
(62.9%,n=526),whileopen-textfeedbackwaslesscommon(29.0%,n=526).
Respondentssubmittingthumbs-up/downfeedbackalsoreporteddoingsomostfrequently(53.3%
every,most,orabouthalfthetimestheyhadusedChatGPT,n=400),followedbyfeedbackafter
regeneratingaresponse(47.4%every,most,orabouthalfthetimestheyhadusedChatGPT,n=331).
Respondentssubmittingopen-textfeedbackreporteddoingsoleastfrequently(26.4%every,most,
orabouthalfthetimestheyhadusedChatGPT,n=152).
Respondentswhosubmittedopen-textfeedback(n=152)wereprimarilymotivatedbyimproving
theperformanceandcapabilitiesofthesystem.Weaskedthisgroupofrespondentstoreflecton
themostrecenttimetheysubmittedopen-textfeedbackandreporttheirmotivationsfordoing
so.Respondentscouldselectmultiplemotivations,butthosewhoselectedmultiplemotivations
wereforcedtochoosetheirprimarymotivationinthefollowingquestion.Takingtheweighted
frequencies,theprimarymotivationswere(inorder)to:“contributetoAIdevelopment”,“comment
on use-case specific feedback”, “report a technical issue or bug”, and “suggest new features or
improvements”(seeTable12inAppendixA).Expressingsocialorethicalconcernsaboutsystem
outputs was the least common motivation (excluding the range of individual responses in the
“other”option).
4.1.2 ReflectingonFeedback. Wealsoaskedrespondentswhosubmittedopen-textfeedbackwhat
feedbackthey thoughtwasmostuseful forimproving ChatGPT’sperformanceor impact.The
responsesrevealedahierarchyoffeedbackthemes.Themostprominentthemesweretechnical
issues(bugs,glitches,incorrectinformation)andsystemperformance(efficiency,speed,andquality
ofresponses).Lesscommonbutstillsignificantwereconcernsaboutaccuracy(‘hallucinations’or
falseinformation)andthereliabilityandtruthfulnessofresponses.Thoughlessfrequentagain,some
usershighlightedsocialandethicalconcerns(includingharmful,biased,ormisleadingresponses).
Finally,somefeedbackfocusedonsuggestingnewfeaturesorimprovements.
Mostrespondentswereambivalentaboutwhethertheirreasonsforsubmittingfeedbackhad
beenaddressed—47.4%neitheragreednordisagreed,23.7%somewhatagreed,and16.4%somewhat
disagreed(n=152).Fewofthosewhosubmittedopen-textfeedbackindicatedtheyhadreceived
follow-upcommunicationorupdatesfromOpenAI(11.2%,n=152),thoughthevastmajorityof
thosewhohadindicatedtheyweresatisfiedwiththeresponseorresolution.
ThefeedbackfeaturesintheChatGPTinterfaceallowforopen-textfeedback,includingcom-
mentaryonsocialandethicalissues.However,oursurveyresultsrevealthatuserspredominantly
focusonperformance-relatedconcernswhensubmittingfeedback.Thisfocusappearstobeshaped
bytheaffordancesofthefeedbacksystemitselfratherthanbyexplicitlydiscouragingsocialor
ethicalfeedback.DespiteOpenAI’sinitialblogpostrequestingfeedbackonrisksandharms,users
whorespondedtooursurveyseemtohaveinterpretedthepurposeoftheirparticipationprimarily
throughthelensofimprovingChatGPT’sperformance.Thispatternhighlightshowthedesignof
feedbackfeaturescaneffectivelyconstrainuserperspectivesandshapethenatureofuserinput.
Preprint.UnderReview.ConstrainingParticipation:AffordancesofFeedbackFeaturesinInterfacestoLargeLanguageModels 11
4.2 Conditions
4.2.1 Perception. Respondentsgenerallyperceivedthefeedbackfeaturesintheinterfaceasacces-
sibleanduser-friendly.Overthree-quartersreportedconfidenceintheirabilitytoevaluateand
submitfeedbackabouttheperformanceand/orimpactofgenerativeAIsystemssuchasChatGPT
(“StronglyAgree”(21.8%)or“SomewhatAgree”(56.5%),n=524).Ofthosewhosubmittedatleast
one of the three feedback modes, almost all found doing so through the features extremely or
somewhateasy(95.1%n=442).
However,someusersweremoreconfidentthanothersinsubmittingfeedback.Youngerusers
(18-34)andthosewhofrequentlyengagedwithAI-relatedtopicsexpressedmoreconfidencethan
wouldbeexpectediftherewasnorelationshipbetweenthesefactorsandconfidence.Conversely,
userswithlessfrequentengagementwerelessconfidentthanwouldbeexpected.Wefoundweak
associationsbetweenconfidenceandage(𝜒2=17.068,adj.𝑝-value=0.045,df=6,Cramér’sV=
0.131)andfrequentengagementwithAI-relatedtopics(𝜒22=20.726,adj.𝑝-value=0.045,df=8,
Cramér’sV=0.144).
4.2.2 Dexterity. FewrespondentsreportedbarrierstoaccessingChatGPTorsubmittingfeedback,
suggestingthatuserswithvaryinglevelsofdexteritycanprovideinput.Whenaskedaboutbarriers
toaccessingChatGPTorsubmittingfeedback,mostrespondents(77.3%,n=519)reportedexperi-
encingnobarriers.Amongthosewhoencounteredbarriers,themostcommonwerelanguageand
internetconnectivityissues.Wedidnotfindsignificantassociationsbetweenmostdemographic
factorsorAIexperienceandknowledgefactorsandthosewhoexperiencedbarriers.Whilethose
workinginAIweremorelikelytoreportexperiencingbarriersthanwouldbeexpectedifthere
wasnorelationshipbetweenthevariables,theassociationwasweak(𝜒2 =9.821,adj.𝑝-value=
0.023,df=1,Cramér’sV=0.143).
However,therequirementtopromptthedialogueagentbeforesubmittingfeedbackmeansonly
userscansubmitfeedbackthroughtheinterface’sfeatures.Oursample,therefore,doesnotinclude
non-user perspectives, and given that most respondents used ChatGPT at least weekly, it also
includeslimitedinputfrominfrequentusers.Notably,ofthosewhocompletedthesurveybutdid
notindicatetheyhadsubmittedfeedbackthroughoneofthethreeoptions,themostcommon
reasonwasthattheywereunawareofthefeedbackoption(34.6%,n=78).
While the ChatGPT interface may constrain direct feedback, respondents found alternative
waystoexpresstheiropinionsandparticipateindiscussionsaboutthesystem.Mostrespondents
(80.4%,n=526)didnotindicatetheysharedfeedbackaboutChatGPTthroughotherchannelsor
platforms.However,thosewhodidprimarilyusedX/Twitter(42%),followedbyFacebook(18%)
andReddit(17%).Severalrespondentsengagedwithdedicatedcommunities,includingsubreddits
liker/ChatGPTandonlineforumsliketheOpenAIDeveloperForum.Mostrespondentswhodid
indicatetheyhadsharedfeedbackthroughotherchannelsorplatforms(71.9%,n=103)reported
theywerelikelytocontinuetosharefeedbackthroughthosechannels.
4.2.3 CulturalandInstitutionalLegitimacy. Interactivefeedbackfeaturesmayappealmoretousers
withcertainculturalandinstitutionalbackgrounds,whichcaninfluencewhosubmitsfeedback
andthetypesoffeedbacktheyprovide.Indeed,mostofoursurveyrespondentswereyoungand
identifiedasmen,whichreflectsChatGPT’sreporteduserbase[75]andotherstudiesofcontributors
tohumanfeedbackdatasets[42].Generally,feedbacktypeswereproportionalacrossdemographic
groups, though we found that respondents’ region had a moderate association with providing
open-textfeedback(𝜒2=13.990,adj.𝑝-value=0.023,df=3,Cramér’sV=0.192).
Instead,oursurveyresultssuggestthatfeedbackfeaturesappealmoretouserswithfrequent
engagementorfamiliaritywithAI,ML,anddatascience.FrequentChatGPTusers,particularly
Preprint.UnderReview.12 CooperandZafiroglu
dailyusers,weremorelikelytoprovidethumbs-up/downfeedback(𝜒2 =13.689,adj.𝑝-value=
0.045,df=4,Cramér’sV=0.166)thanwouldbeexpectediftherewasnorelationshipbetweenthe
variables,andthosewhopreviouslyusedAItools(𝜒2=8.926,adj.𝑝-value=0.023df=1,Cramér’sV
=0.154)weremorelikelytoprovideopen-textfeedbackthanwouldbeexpected.Wealsoobserved
moderateassociationssuggestingmorefrequentChatGPTusersandthoseoftenengagingwith
AI-relatedtopicsweremorelikelytosubmitopen-textfeedbackthanwouldbeexpectedifthere
wasnorelationshipbetweenthesevariables.However,theseassociationsdidnotreachstatistical
significanceafteradjusting𝑝-values.Additionally,wenotedaborderlinesignificantassociation
betweeneducationortraininginAIandopen-textfeedbacksubmission(adj.𝑝-value=0.059).
4.3 SummaryofAffordances
Table1outlinestheaffordancesofthefeedbackfeaturesintheChatGPTinterfacebasedonthe
analysisabove,organisedbythesixmechanismsproposedbytheframework.Theaffordancesare
linkedtotheconditions(perception,dexterity,andculturalandinstitutionallegitimacy)thatshape
howusersinteractwithandperceivethefeedbackfeatures.
Table1. SummaryofAffordances
Mechanism Affordance Condition
Request Feedback formatted in the Feedbackfromuserstodevelopers(Dexter-
‘helpful,honest,andharmless’ ity)
framework
Demand InteractionwithChatGPTbe- Statusasauser(Dexterity)
forefeedbacksubmission
Encourage Thumbs-up/down feedback; Ease of use and accessibility of interface
Feedback after regenerating (Perception);Frequencyofuseandfamiliar-
a response; Performance- ity with the system (Perception, Dexterity);
relatedopen-textfeedback AI/MLexperienceandknowledge(Cultural
andinstitutionallegitimacy)
Discourage Feedback from collectives; Individualisedfeedbackdesign(Culturaland
Discussionsamongusers institutionallegitimacy)
Refuse Modifyingfeedbackovertime Stochasticnatureofthesystem(Dexterity)
Allow Alternativechannelsforfeed- Availabilityofalternativechannels(Dexter-
backanddiscussion(e.g.,so- ity);Accessibilityandappealoffeedbackfea-
cialmedia,onlineforums) tures to certain user groups (Cultural and
institutionallegitimacy)
5 Discussion
Participationisneverfullyopenoranarchic;itisalwaysformattedwith“specificrulesandscripts”
[41].FeedbackfeaturesininterfacestoLLMsformatuserinputintoRLHFworkflows.Therefore,
thedesignofthesefeaturesshapesthelegitimacyofuserparticipationintheiterationofLLMs.
OuranalysisoffeedbackfeaturesinChatGPTsuggeststhatthefeedbackformatimposedbythe
interfaceissimple,individualised,unidirectional,andfocusedonperformance-relatedconcerns.
Thisformatsignificantlyconstrainsuserparticipationandrisksbecomingself-perpetuating—users
Preprint.UnderReview.ConstrainingParticipation:AffordancesofFeedbackFeaturesinInterfacestoLargeLanguageModels 13
mayinternaliselimitedrolesintheiterationofLLMs,discouragingthemfromseekingbroader
engagementorviewingthemselvesasco-creatorsinLLMdevelopment.Thisphenomenonisnot
uniquetoLLMs;similarpatternshavebeenobservedinothertechnologicaldomains,suchassocial
mediaplatforms[37].
Affordancetheoryasadesigntoolrequiresanorientationthat“technologies,andtheworlds
theybuild,neednotbeastheyareandcan,instead,beotherwise”[19].AsLLMsincreasingly
becomeinfrastructure,itisimportanttoconsiderparticipationbeyondmerepreferenceelicitation.
Inthissection,wediscusstwodirectionsforthe(re)designoffeedbackprocesses.Initially,we
reviewrecentdevelopmentsindeliberativeapproachestofeedback,suchasrecentdemocratic
experimentsofOpenAIandAnthropic.However,wearguethatusersandstakeholderscannever
gettotheheartofclosedsystemsbycommentingonmodeloutputs.Instead,weencourageashift
inapproachfromalignmentofmodeloutputstospecificuserpreferencestodialoguewiththe
publicaboutthepurposeandapplicationsofLLMs,andattentiontotheongoinginfrastructuring
workrequiredtosupportandsustaindiverse‘publics’overtime.
5.1 DeliberativeProcesses
As previously noted, the existing feedback features request feedback from users to developers
anddiscouragebothfeedbackfromgroupsofusersanddiscussionamongstusers.Inotherwords,
feedbackthroughexistingfeaturesisatomisedandunidirectional[76].Additionally,asthenumber
ofChatGPTusershasgrownandthesystemhasstabilisedovertime,userinputhasbeenconstrained
fromawidetoanarrowaperture—fromfree-textfeedbackformstoopen-textfeedbackwindows
tosingularbuttonsfocusedoncrowdsourcinginputstoRLHF.Theselatestfeedbackformatsare
inadequateforresolvingsocialandethicalconsiderations,requiringustoconsiderotherdesign
approaches.
If algorithmic fairness is primarily a political task, as Wong [78] argues, rather than solely
a technical task, we must consider how to resolve issues of bias and fairness politically rather
thantechnically.Alongsideaggregatingcitizenpreferencesthroughvoting,deliberationamong
citizensisakeyelementofdemocraticlegitimacy[17,34,43].Deliberativedemocracyinvolvesan
associationofmemberswhogoverntheiraffairsbydeliberationamongthemembers[29]—making
collectivedecisionsdeterminedbythosesubjecttothedecisions:notonlytheirpreferencesbut
alsotheirreasoning[12].Suchassociationstendtobebetweenbroadgroupsofpeople—inthis
context,users,developers,andpotentiallygroupsofboth—andaredirectedtowardsparticipants
consideringothers’perspectivesandpotentiallychangingtheirownovertime.
Interestingly,surveyrespondentsidentifiedseveralotherplatformsonwhichtheydiscusstheir
experiencesandpreferencesregardingChatGPT,engaginginthekindofcollectivedeliberation
that the existing feedback features discourage. For example, OpenAI discussion forums allow
communicationbetweenusersanddevelopersandsubredditssuchasr/ChatGPTallowdiscussion
amongstusers(withoutmonitoringoroversightbyOpenAI).However,itisunclearwhetheror
howthesediscussionsareinputintodevelopmentprocesses;whiletheyfunctionasevaluative
feedback,thereisnoclearcyberneticfeedbackloop.
Sometechnologycompanieshavebeenexperimentingwithdeliberativemodesforfeedbackabout
AIsystems.RecenteffortsbyOpenAItofundresearchintotechnicalsolutionsfor“democratic
inputs into AI” [28] and experiments by Anthropic to draft a constitution for Claude through
deliberativeprocesses[40]haveattractedsignificantattention.Theseeffortsgobeyondeliciting
andaggregatinguserpreferencestowardsencouragingdeliberationamongstpeoplewithdiverse
perspectives (including non-users) and demonstrating how the preferences and reasoning of
multipleparticipantsareinput(ascyberneticfeedback)intodevelopmentworkflows.Inaddition,
MetahasexperimentedwithCommunityForumstodeliberateontherulesetsforGenerativeAI
Preprint.UnderReview.14 CooperandZafiroglu
[10],andGooglehasdevelopedtheSTELAprocessfordeliberativediscussionswithhistorically
underrepresentedgroupsintheU.S.A.tounderstandtheirprioritiesandconcernswithrespectto
modeloutputs[5].
Whiletheseprocessesaddresssomeofthelimitationsofexistingfeedbackfeatures,theyremain
largely experimental and peripheral to the dominant method of feedback submission through
browser-basedinterfaces.Mostoftheseapproaches(withtheGoogleexampleasanexception)take
asagiventhatconsensusontheoutputoftheprocessisdesirableandachievable.However,refusal,
agonismanddissensusarekeyelementsofdemocraticprocesses[25,26,81].Whenconsulting
multipleanddiversecommunities,valuesandpreferencesforAIdesignmaybeinconflict[59,62]
anddifficulttoreconcile[27,50,64].Thisisparticularlythecasewheretheprocessesaremanaged
bythosewithcommercialinterestsinconsensusoutcomes,reflectinglong-standingconcernsin
participatorydesign[63].
Moreover,suchdemocraticinputstothealignmentproblem,muchliketheexistingfeedback
processestheyareintendedtoaugmentorreplace,narrowlyscopeparticipationaroundtheoutput
ofspecificfamiliesofmodelsratherthanengagingparticipantsinearlierstagesofthedevelopment
process.Althoughdeliberativeprocessesmayaddresssomelimitationsofexistingmechanisms
andchangehowcompanieslikeOpenAIandAnthropicmakedecisionsaboutmodelbehaviour,
theydonotsignificantlyalterthepowerdynamicsbetweenusers,thepublic,andplatforms.Users
andotherparticipantsremainasconsumersratherthanco-creators,limitedintheirinfluenceover
coreaspectsofearlierstagesofdevelopment.
5.2 InfrastructuringParticipation
Ourstudyrevealsatensionbetweentechnologycompanies’statedintentionsandtheirimplemen-
tationoffeedbackfeaturesinLLMs.ChatGPTexemplifiesthisdisparity:whatOpenAIinitially
sought(diverse,substantivefeedbacktouncoverpotentialrisksandharms)gavewaytowhat
theycouldeffectivelyusewithintheirexistingworkflows(easilyprocessed,formatteddata).This
changenotonlyconstrainsuserinputbutalso,asoursurveyindicates,favoursfrequentChatGPT
usersandthosewithAIexperience,narrowingthegroupofusersinfluencingLLMiteration.
WhileelicitinguserpreferencesasinputintoRLHFworkflowsmaybewell-intentionedand
usefulfortechnologycompaniestoimprovemodelperformance,itisinadequateforthelargertask
facingusall.Weallfacethechallengeofpublicly,deliberatively,andinclusivelyaddressingthe
ongoingtectonicshiftsininformationandknowledgegenerationacrosseconomic,social,cultural,
andpoliticaldomainsbeforeLLMsbecomeunremarkableandunquestionableinfrastructure.
Ifwearetoshiftourfocusfromaligningmodeloutputstospecificuserpreferencestowards
dialoguewiththepublicaboutthepurposeandapplicationsofLLMs,thenwemustthinkcritically
aboutwhowillformthis‘public’,howitwillform,andwhatchannelsfacilitateitsparticipation.
Currently,technologycompaniesconfigureparticipationfromatomisedusersofdialogueagents
likeChatGPT,tightlydefiningprocessesforfeedbackonmodeloutputs.InChatGPT’scase,the
‘public’isconstructedprimarilytoaddressamatterofconcerntoOpenAIratherthanthoseengaged
asparticipants.Moreover,groupsorinstitutionsaffectedbythedevelopmentanddeploymentof
LLMslackdirectmechanismstoinfluencethesefeedbackprocesses[76].
Technology companies might argue for increasing the number and diversity of participants
providing feedback through existing channels. However, this approach misses the core issue.
DrawingparallelswithArnstein’s[1]critiqueofparticipationinthecontextofurbanplanning,we
arguethatidentifyingproblemsintheproceduralisationofparticipationthroughfeedbackfeatures
inLLMsisnotacallformoreinvolvementbutforafundamentalrethinkingoftheprocess.We
echoWangetal.[76]inurgingcompaniestofocusontheparticipationofgroupsorinstitutions
representingpopulationslikelytobesignificantlyimpactedbyagivenLLM.Infrastructuringsuch
Preprint.UnderReview.ConstrainingParticipation:AffordancesofFeedbackFeaturesinInterfacestoLargeLanguageModels 15
participationrequiresdeepengagementwiththemethodologicaltoolsofParticipatoryDesign(PD),
whichhasalong-standingpracticeofcriticalthinkingabouthowtoformandsustain‘publics’to
addressparticipants’concernsovertime[24,46].Whenimplementedeffectively,PDprioritises
futureissuesconcerningparticipantsratherthansolelyfocusingontheimmediateconcernsof
designersorresearchers.
Recent research offers promising directions for rethinking processes and infrastructure for
participationinLLMdevelopment.TheSTELAprocess[5]demonstratesonemethodforconduct-
ingcommunity-centreddeliberativediscussionsaboutLLMs,albeitfocusedonaligningmodels
with the preferences of specific groups of people. Suresh et al. [69] expand on this concept by
proposingacomprehensiveframeworkfordomain-specificcommunityinfrastructure,including
sharedtechnicalresources,norms,andgovernancestructures.Theirapproachaimstoenablemore
meaningfulparticipationbygroupsandinstitutionsinshapingthedevelopmentandapplication
offoundationmodelsinspecificdomains.Buildingontheseideas,weencourageparticipatory
workshopswithstakeholdersinfieldslikeeducation,healthcare,andjournalismasapractical
mechanismforrealisingandrefiningsuchdomain-specificinfrastructure.However,implementing
these participatory approaches faces significant challenges: maintaining local relevance while
extendingacrossdomainsandregions,translatinginsightsintoactionabledevelopmentinputs,
andsecuringsustainablefundingforongoinginfrastructureintherapidlychanginglandscapeof
AIdevelopment.ToadvancemeaningfulpublicparticipationintheiterationofLLMs,thefocusof
researchandeffortmustbeonaddressingthesechallengesratherthandefaultingtoprocedural
andperfunctoryengagement.
6 Conclusion
OuranalysisrevealsthatexistingfeedbackfeaturesintheChatGPTinterfaceconstrainparticipation
around developers’ instrumental needs. This approach to user input and participation views
engagement as a means to an end rather than an opportunity for dialogue. While deliberative
approaches may address some limitations of existing mechanisms, the scope of user and non-
userinputremainsconstrained.Tomovebeyondperfunctoryengagement,wecallforashiftin
focusfromuserpreferenceelicitationtobuildingrobustinfrastructuresforsustained,meaningful
dialogueaboutthepurposeandapplicationofLLMs.Asthesetechnologiesbecomeincreasingly
embeddedininformation,workplace,andentertainmentservices,theurgencyofthistaskcannot
beoverstated.
References
[1] SherryRArnstein.1969.ALadderOfCitizenParticipation.JournaloftheAmericanInstituteofPlanners35,4(July
1969),216–224. https://doi.org/10.1080/01944366908977225
[2] AmandaAskell,YuntaoBai,AnnaChen,DawnDrain,DeepGanguli,TomHenighan,AndyJones,NicholasJoseph,
BenMann,NovaDasSarma,NelsonElhage,ZacHatfield-Dodds,DannyHernandez,JacksonKernion,KamalNdousse,
CatherineOlsson,DarioAmodei,TomBrown,JackClark,SamMcCandlish,ChrisOlah,andJaredKaplan.2021.
AGeneralLanguageAssistantasaLaboratoryforAlignment. arXivpreprintarXiv:2112.00861(Dec.2021). http:
//arxiv.org/abs/2112.00861
[3] YuntaoBai,AndyJones,KamalNdousse,AmandaAskell,AnnaChen,NovaDasSarma,DawnDrain,StanislavFort,
DeepGanguli,TomHenighan,NicholasJoseph,SauravKadavath,JacksonKernion,TomConerly,SheerEl-Showk,
NelsonElhage,ZacHatfield-Dodds,DannyHernandez,TristanHume,ScottJohnston,ShaunaKravec,LianeLovitt,
NeelNanda,CatherineOlsson,DarioAmodei,TomBrown,JackClark,SamMcCandlish,ChrisOlah,BenMann,and
JaredKaplan.2022.TrainingaHelpfulandHarmlessAssistantwithReinforcementLearningfromHumanFeedback.
arXivpreprintarXiv:2204.05862(April2022). http://arxiv.org/abs/2204.05862
[4] YoavBenjaminiandYosefHochberg.1995.ControllingtheFalseDiscoveryRate:APracticalandPowerfulApproach
toMultipleTesting.JournaloftheRoyalStatisticalSociety:SeriesB(Methodological)57,1(Jan.1995),289–300.
Preprint.UnderReview.16 CooperandZafiroglu
[5] StevieBergman,NahemaMarchal,JohnMellor,ShakirMohamed,IasonGabriel,andWilliamIsaac.2024.STELA:a
community-centredapproachtonormelicitationforAIalignment.ScientificReports14,1(March2024),6616.
[6] KimBerndt,KayvonSpire,andDanielleBatalla.2023.WanttounderstandEarlyAdoptersofGenerativeAI?https:
//www.ipsos.com/en-us/want-understand-early-adopters-generative-ai. Accessed:2024-4-24.
[7] AbebaBirhane,WilliamIsaac,VinodkumarPrabhakaran,MarkDiaz,MadeleineClareElish,IasonGabriel,andShakir
Mohamed.2022. PowertothePeople?OpportunitiesandChallengesforParticipatoryAI.InEquityandAccessin
Algorithms,Mechanisms,andOptimization(Arlington,VA,USA)(EAAMO’22,Article6).AssociationforComputing
Machinery,NewYork,NY,USA,1–8.
[8] VirginiaBraunandVictoriaClarke.2006.UsingThematicAnalysisinPsychology.QualitativeResearchinPsychology
3,2(2006),77–101.
[9] TomBrown,BenjaminMann,NickRyder,MelanieSubbiah,JaredDKaplan,PrafullaDhariwal,ArvindNeelakantan,
PranavShyam,GirishSastry,AmandaAskell,andOthers.2020.LanguageModelsAreFew-ShotLearners.Advances
inNeuralInformationProcessingSystems33(2020),1877–1901.
[10] JenniferBroxmeyer.2024. LeadingtheWayinGovernanceInnovationWithCommunityForumsonAI. https:
//about.fb.com/news/2024/04/leading-the-way-in-governance-innovation-with-community-forums-on-ai/. Accessed:
2024-5-31.
[11] MilesBrundage,KatieMayer,TynaEloundou,SandhiniAgarwal,StevenAdler,GretchenKrueger,JanLeike,and
PamelaMishkin.2022.Lessonslearnedonlanguagemodelsafetyandmisuse.https://openai.com/index/language-
model-safety-and-misuse. Accessed:2024-5-6.
[12] JoshuaCohen.2005. DeliberationandDemocraticLegitimacy. InDebatesinContemporaryPoliticalPhilosophy.
Routledge,NewYork,NY,USA,352–370.
[13] JacobCohen.2013.StatisticalPowerAnalysisfortheBehavioralSciences(2ed.).Routledge,London,UK.
[14] NedCooper,TiffanieHorne,GillianRHayes,CourtneyHeldreth,MichalLahav,JessHolbrook,andLaurenWilcox.2022.
ASystematicReviewandThematicAnalysisofCommunity-CollaborativeApproachestoComputingResearch.InCHI
ConferenceonHumanFactorsinComputingSystems(NewOrleansLAUSA).AssociationforComputingMachinery,
NewOrleans,LA,USA,1–18.
[15] NedCooperandAlexandraZafiroglu.2024.FromFittingParticipationtoForgingRelationships:TheArtofParticipatory
ML.InProceedingsoftheCHIConferenceonHumanFactorsinComputingSystems(HonoluluHIUSA),Vol.19.Association
forComputingMachinery,NewYork,NY,USA,1–9.
[16] EricCorbett,EmilyDenton,andSheenaErete.2023.PowerandPublicParticipationinAI.InProceedingsofthe3rd
ACMConferenceonEquityandAccessinAlgorithms,Mechanisms,andOptimization(Boston,MA,USA)(EAAMO’23,
Article8).AssociationforComputingMachinery,NewYork,NY,USA,1–13.
[17] NicoleCurato,JohnSDryzek,SelenAErcan,CarolynMHendriks,andSimonNiemeyer.2017.TwelveKeyFindings
inDeliberativeDemocracyResearch.Daedalus146,3(July2017),28–38.
[18] JennyLDavis.2020.HowArtifactsAfford:ThePowerandPoliticsofEverydayThings.TheMITPress,Cambridge,MA,
USA.
[19] JennyLDavis.2023. ‘Affordances’forMachineLearning.InProceedingsofthe2023ACMConferenceonFairness,
Accountability,andTransparency(Chicago,IL,USA)(FAccT’23).AssociationforComputingMachinery,NewYork,NY,
USA,324–332.
[20] JennyLDavisandJamesBChouinard.2016. TheorizingAffordances:FromRequesttoRefuse. BulletinofScience,
TechnologyandSociety36,4(2016),241–248.
[21] FernandoDelgado,StephenYang,MichaelMadaio,andQianYang.2023. TheParticipatoryTurninAIDesign:
TheoreticalFoundationsandtheCurrentStateofPractice.InProceedingsofthe3rdACMConferenceonEquityand
AccessinAlgorithms,Mechanisms,andOptimization(Boston,MA,USA)(EAAMO’23,Article37).Associationfor
ComputingMachinery,NewYork,NY,USA,1–23.
[22] EmilyDenton,AlexHanna,RazvanAmironesei,AndrewSmart,HilaryNicole,andMorganKlausScheuerman.2020.
BringingthePeopleBackIn:ContestingBenchmarkMachineLearningDatasets.arXivpreprintarXiv:2007.07399(July
2020). http://arxiv.org/abs/2007.07399
[23] FernandoDiazandMichaelMadaio.2023. ScalingLawsDoNotScale. arXivpreprintarXiv:2307.03201(2023).
http://arxiv.org/abs/2307.03201
[24] CarlDiSalvo.2009.DesignandtheConstructionofPublics.DesignIssues25,1(2009),48–63.
[25] CarlDiSalvo.2010. Design,DemocracyandAgonisticPluralism.InDesignandComplexity-DRSInternational
Conference2010(2010-07-07/2010-07-09),D.Durling,R.Bousbaci,L.Chen,P.Gauthier,T.Poldma,S.Roworth-Stokes,
andE.Stolterman(Eds.).DesignResearchSociety,Montreal,Canada,7. https://dl.designresearchsociety.org/drs-
conference-papers/drs2010/researchpapers/31
[26] CarlDiSalvo.2015.AdversarialDesign.MITPress,Cambridge,MA,USA.
Preprint.UnderReview.ConstrainingParticipation:AffordancesofFeedbackFeaturesinInterfacestoLargeLanguageModels 17
[27] EsinDurmus,KarinaNguyen,ThomasI.Liao,NicholasSchiefer,AmandaAskell,AntonBakhtin,CarolChen,Zac
Hatfield-Dodds,DannyHernandez,NicholasJoseph,LianeLovitt,SamMcCandlish,OrowaSikder,AlexTamkin,Janel
Thamkul,JaredKaplan,JackClark,andDeepGanguli.2023. TowardsMeasuringtheRepresentationofSubjective
GlobalOpinionsinLanguageModels.arXivpreprintarXiv:2306.16388(2023). http://arxiv.org/abs/2306.16388
[28] TynaEloundouandTeddyLee.2024.DemocraticinputstoAIgrantprogram:lessonslearnedandimplementation
plans.https://openai.com/index/democratic-inputs-to-ai-grant-program-update. Accessed:2024-5-6.
[29] JonElsterandAdamPrzeworski.1998.DeliberativeDemocracy.Vol.1.CambridgeUniversityPress,Cambridge,UK.
[30] VirginiaEubanks.2017.AutomatingInequality:HowHigh-TechToolsProfile,Police,andPunishthePoor(1sted.).St.
Martin’sPress,NewYork,NY,USA.
[31] SophieFarthing,JohnHowell,KaterinaLecchi,ZoePaleologos,PhoebeSaintilan,andEdwardSantow.2021.Human
RightsandTechnologyFinalReport.TechnicalReport.AustralianHumanRightsCommission,Sydney.
[32] MichaelFeffer,HodaHeidari,andZacharyCLipton.2023.MoralMachineorTyrannyoftheMajority?Proceedingsof
theAAAIConferenceonArtificialIntelligence37,5(June2023),5974–5982.
[33] MichaelFeffer,MichaelSkirpan,ZacharyLipton,andHodaHeidari.2023.FromPreferenceElicitationtoParticipatory
ML:ACriticalSurvey&GuidelinesforFutureResearch.InProceedingsofthe2023AAAI/ACMConferenceonAI,Ethics,
andSociety(Montr\’{e}al,QC,Canada)(AIES’23).AssociationforComputingMachinery,NewYork,NY,USA,38–48.
[34] JamesSFishkin.1991.DemocracyandDeliberation:NewDirectionsforDemocraticReform.YaleUniversityPress,New
Haven,CT,USA.
[35] IasonGabriel.2020.ArtificialIntelligence,Values,andAlignment.MindsandMachines30,3(Sept.2020),411–437.
[36] JamesJ.Gibson.1977.TheTheoryofAffordances.InPerceiving,Acting,andKnowing:TowardanEcologicalPsychology,
R.ShawandJ.Bransford(Eds.).LawrenceErlbaum,Hillsdale,NJ,USA,67–82.
[37] TarletonGillespie.2020. Contentmoderation,AI,andthequestionofscale. BigData&Society7,2(July2020),
2053951720943234.
[38] AlexHannaandTinaM.Park.2020.AgainstScale:ProvocationsandResistancestoScaleThinking.arXivpreprint
arXiv:2010.08850(2020). http://arxiv.org/abs/2010.08850
[39] MireilleHildebrandt.2015.SmartTechnologiesandtheEnd(s)ofLaw.EdwardElgarPublishing,Cheltenham,UK.
[40] SaffronHuang,DivyaSiddarth,LianeLovitt,ThomasILiao,EsinDurmus,AlexTamkin,andDeepGanguli.2024.
CollectiveConstitutionalAI:AligningaLanguageModelwithPublicInput.InProceedingsofthe2024ACMConference
onFairness,Accountability,andTransparency(RiodeJaneiro,Brazil)(FAccT’24).AssociationforComputingMachinery,
NewYork,NY,USA,1395–1417.
[41] ChristopherMKelty.2020. TheParticipant:ACenturyofParticipationinFourStories. UniversityofChicagoPress,
Chicago,IL,USA.
[42] HannahRoseKirk,AlexanderWhitefield,PaulRöttger,AndrewBean,KaterinaMargatina,JuanCiro,RafaelMosquera,
MaxBartolo,AdinaWilliams,HeHe,BertieVidgen,andScottAHale.2024. ThePRISMAlignmentProject:What
Participatory,RepresentativeandIndividualisedHumanFeedbackRevealsAbouttheSubjectiveandMulticultural
AlignmentofLargeLanguageModels.arXivpreprintarXiv:2404.16019(April2024). http://arxiv.org/abs/2404.16019
[43] JackKnightandJamesJohnson.1994.AggregationandDeliberation:OnthePossibilityofDemocraticLegitimacy.
PoliticalTheory22,2(1994),277–296.
[44] BogdanKulynych,DavidMadras,SmithaMilli,InioluwaDeborahRaji,Zhou,andRichardZemel.2020.Participatory
ApproachestoMachineLearning. InternationalConferenceonMachineLearning(ICML)Workshop. https://
participatoryml.github.io/Accessed:2024-5-11.
[45] NathanLambert,ThomasKrendlGilbert,andTomZick.2023.TheHistoryandRisksofReinforcementLearningand
HumanFeedback.arXivpreprintarXiv:2310.13595(Oct.2023). http://arxiv.org/abs/2310.13595
[46] ChristopherALeDantecandCarlDiSalvo.2013.InfrastructuringandtheFormationofPublicsinParticipatoryDesign.
SocialStudiesofScience43,2(2013),241–264.
[47] YannLeCun.2023.HumanfeedbackforopensourceLLMsneedstobecrowd-sourced,Wikipediastyle.Itistheonly
wayforLLMstobecometherepositoryofallhumanknowledgeandcultures.Whowantstobuildtheplatformfor
this?https://twitter.com/ylecun/status/1713751182601015729. Accessed:2024-5-6.
[48] NestorMaslej,LoredanaFattorini,RaymondPerrault,VanessaParli,AnkaReuel,ErikBrynjolfsson,JohnEtchemendy,
KatrinaLigett,TerahLyons,JamesManyika,JuanCarlosNiebles,YoavShoham,RussellWald,andJackClark.2024.
TheAIIndex2024AnnualReport.TechnicalReport7.AIIndexSteeringCommittee,InstituteforHuman-CenteredAI,
StanfordUniversity.
[49] Colleen McClain. 2024. Americans’ use of ChatGPT is ticking up, but few trust its election informa-
tion.https://www.pewresearch.org/short-reads/2024/03/26/americans-use-of-chatgpt-is-ticking-up-but-few-trust-its-
election-information/. Accessed:2024-4-24.
[50] JessicaKMiller,BatyaFriedman,GavinJancke,andBrianGill.2007.Valuetensionsindesign:thevaluesensitivedesign,
development,andappropriationofacorporation’sgroupwaresystem.InProceedingsofthe2007ACMInternational
Preprint.UnderReview.18 CooperandZafiroglu
ConferenceonSupportingGroupWork.AssociationforComputingMachinery,NewYork,NY,USA,281–290.
[51] MarvinMinsky.1961.StepstowardArtificialIntelligence.ProceedingsoftheIRE49,1(Jan.1961),8–30.
[52] MichaelJMullerandSarahKuhn.1993.ParticipatoryDesign.Commun.ACM36,6(June1993),24–28.
[53] DonNorman.2008.Affordancesanddesign.https://jnd.org/affordances-and-design/. Accessed:2024-5-11.
[54] OpenAI.2022.IntroducingChatGPT.https://openai.com/blog/chatgpt. Accessed:2023-5-11.
[55] OpenAI.2023.GPT-4TechnicalReport.arXivpreprintarXiv:2303.08774(March2023). http://arxiv.org/abs/2303.08774
[56] LongOuyang,JeffWu,XuJiang,DiogoAlmeida,CarrollLWainwright,PamelaMishkin,ChongZhang,Sandhini
Agarwal,KatarinaSlama,AlexRay,JohnSchulman,JacobHilton,FraserKelton,LukeMiller,MaddieSimens,Amanda
Askell,PeterWelinder,PaulChristiano,JanLeike,andRyanLowe.2022.Traininglanguagemodelstofollowinstructions
withhumanfeedback.InAdvancesinNeuralInformationProcessingSystems,Vol.35.CurranAssociates,Inc.,RedHook,
NY,USA,27730–27744.
[57] DylanPatelandGeraldWong.2023. GPT-4Architecture,Infrastructure,TrainingDataset,Costs,Vision,MoE.
https://www.semianalysis.com/p/gpt-4-architecture-infrastructure. Accessed:2024-5-11.
[58] VinodkumarPrabhakaran,AidaMostafazadehDavani,andMarkDiaz.2021.OnReleasingAnnotator-LevelLabels
andInformationinDatasets.InProceedingsoftheJoint15thLinguisticAnnotationWorkshop(LAW)and3rdDesigning
MeaningRepresentations(DMR)Workshop,ClaireBonialandNianwenXue(Eds.).AssociationforComputational
Linguistics,PuntaCana,DominicanRepublic,133–138. https://doi.org/10.18653/v1/2021.law-1.14
[59] RidaQadri,ReneeShelby,CynthiaLBennett,andEmilyDenton.2023.AI’sRegimesofRepresentation:ACommunity-
centeredStudyofText-to-ImageModelsinSouthAsia.InProceedingsofthe2023ACMConferenceonFairness,Account-
ability,andTransparency(Chicago,IL,USA)(FAccT’23).AssociationforComputingMachinery,NewYork,NY,USA,
506–517.
[60] EverettMRogers.2003.DiffusionofInnovations,5thEdition.FreePress,NewYork,NY,USA.
[61] StuartRussell.2019.HumanCompatible:ArtificialIntelligenceandtheProblemofControl.VikingPress,NewYork,NY,
USA.
[62] NithyaSambasivan,ErinArnesen,BenHutchinson,TulseeDoshi,andVinodkumarPrabhakaran.2021.Re-imagining
AlgorithmicFairnessinIndiaandBeyond.InProceedingsofthe2021ACMConferenceonFairness,Accountability,and
Transparency(VirtualEvent,Canada)(FAccT’21).AssociationforComputingMachinery,NewYork,NY,USA,315–328.
[63] LizSandersandPStappers.2014. Fromdesigningtoco-designingtocollectivedreaming:Threeslicesintime.
Interactions21,6(2014),24–33.
[64] ShibaniSanturkar,EsinDurmus,FaisalLadhak,CinooLee,PercyLiang,andTatsunoriHashimoto.2023. Whose
OpinionsDoLanguageModelsReflect?arXivpreprintarXiv:2303.17548(2023). http://arxiv.org/abs/2303.17548
[65] MonaSloane,EmanuelMoss,OlaitanAwomolo,andLauraForlano.2022.ParticipationIsNotaDesignFixforMachine
Learning.InEquityandAccessinAlgorithms,Mechanisms,andOptimization(Arlington,VA,USA)(EAAMO’22,Article
1).AssociationforComputingMachinery,NewYork,NY,USA,1–6.
[66] IreneSolaiman,MilesBrundage,JackClark,AmandaAskell,ArielHerbert-Voss,JeffWu,AlecRadford,Gretchen
Krueger,JongWookKim,SarahKreps,MilesMcCain,AlexNewhouse,JasonBlazakis,KrisMcGuffie,andJasmine
Wang.2019.ReleaseStrategiesandtheSocialImpactsofLanguageModels.arXivpreprintarXiv:1908.09203(Aug.2019).
http://arxiv.org/abs/1908.09203
[67] SusanLeighStarandKarenRuhleder.1996.StepsTowardanEcologyofInfrastructure:DesignandAccessforLarge
InformationSpace.InformationSystemsResearch7,1(March1996),111–134.
[68] YngveSundblad.2011.UTOPIA:ParticipatoryDesignfromScandinaviatotheWorld.InHistoryofNordicComputing
3,JohnImpagliazzo,PerLundin,andBenktWangler(Eds.).SpringerBerlin,Heidelberg,Germany,176–186.
[69] HariniSuresh,EmilyTseng,MegYoung,MaryGray,EmmaPierson,andKarenLevy.2024.Participationintheageof
foundationmodels.InProceedingsofthe2024ACMConferenceonFairness,Accountability,andTransparency(Riode
Janeiro,Brazil)(FAccT’24).AssociationforComputingMachinery,NewYork,NY,USA,1609–1621.
[70] ElhamTabassi.2023.ArtificialIntelligenceRiskManagementFramework(AIRMF1.0).TechnicalReportNISTAI100-1.
NationalInstituteofStandardsandTechnology.
[71] RomalThoppilan,DanielDeFreitas,JamieHall,NoamShazeer,ApoorvKulshreshtha,Heng-TzeCheng,AliciaJin,
TaylorBos,LeslieBaker,YuDu,YaguangLi,HongraeLee,HuaixiuStevenZheng,AminGhafouri,MarceloMenegali,
YanpingHuang,MaximKrikun,DmitryLepikhin,JamesQin,DehaoChen,YuanzhongXu,ZhifengChen,Adam
Roberts,MaartenBosma,VincentZhao,YanqiZhou,Chung-ChingChang,IgorKrivokon,WillRusch,MarcPickett,
PraneshSrinivasan,LaicheeMan,KathleenMeier-Hellstern,MeredithRingelMorris,TulseeDoshi,RenelitoDelos
Santos,TojuDuke,JohnnySoraker,BenZevenbergen,VinodkumarPrabhakaran,MarkDiaz,BenHutchinson,Kristen
Olson,AlejandraMolina,ErinHoffman-John,JoshLee,LoraAroyo,RaviRajakumar,AlenaButryna,MatthewLamm,
ViktoriyaKuzmina,JoeFenton,AaronCohen,RachelBernstein,RayKurzweil,BlaiseAguera-Arcas,ClaireCui,Marian
Croak,EdChi,andQuocLe.2022.LaMDA:LanguageModelsforDialogApplications.arXivpreprintarXiv:2201.08239
(Jan.2022). http://arxiv.org/abs/2201.08239
Preprint.UnderReview.ConstrainingParticipation:AffordancesofFeedbackFeaturesinInterfacestoLargeLanguageModels 19
[72] AnnaLowenhauptTsing.2012. OnNonscalability:TheLivingWorldIsNotAmenabletoPrecision-NestedScales.
CommonKnowledge18,3(2012),505–524.
[73] ZeynepTufekci.2014.BigQuestionsforSocialMediaBigData:Representativeness,ValidityandOtherMethodological
Pitfalls.ProceedingsoftheInternationalAAAIConferenceonWebandSocialMedia8,1(May2014),505–514.
[74] U.S.OfficeofScienceandTechnologyPolicy.2022.BlueprintforanAIBillofRights:MakingAutomatedSystemsWork
fortheAmericanPeople.TechnicalReport.U.S.OfficeofScienceandTechnologyPolicy.
[75] Emily A Vogels. 2023. A majority of Americans have heard of ChatGPT, but few have tried it them-
selves. https://www.pewresearch.org/short-reads/2023/05/24/a-majority-of-americans-have-heard-of-chatgpt-but-
few-have-tried-it-themselves/. Accessed:2024-4-24.
[76] SkylerWang,NedCooper,MargaretEby,andEunSeoJo.2023.FromHuman-CenteredtoSocial-CenteredArtificial
Intelligence:AssessingChatGPT’sImpactthroughDisruptiveEvents. arXivpreprintarXiv:2306.00227(May2023).
http://arxiv.org/abs/2306.00227
[77] NorbertWiener.1948. CyberneticsorControlandCommunicationintheAnimalandtheMachine. Hermann&Cie,
Paris,France.
[78] Pak-HangWong.2020.DemocratizingAlgorithmicFairness.PhilosophyandTechnology33(2020),225–244.
[79] MegYoung,UpolEhsan,RanjitSingh,EmnetTafesse,MicheleGilman,ChristinaHarrington,andJacobMetcalf.2024.
Participationversusscale:TensionsinthepracticaldemandsonparticipatoryAI. FirstMonday29,4(April2024).
https://doi.org/10.5210/fm.v29i4.13642
[80] DanielM.Ziegler,NisanStiennon,JeffreyWu,TomB.Brown,AlecRadford,DarioAmodei,PaulChristiano,and
GeoffreyIrving.2019.Fine-TuningLanguageModelsfromHumanPreferences.arXivpreprintarXiv:1909.08593(Sept.
2019). http://arxiv.org/abs/1909.08593
[81] JonathanZongandJ.NathanMatias.2024.DataRefusalfromBelow:AFrameworkforUnderstanding,Evaluating,
andEnvisioningRefusalasDesign. ACMJournalonResponsibleComputing1,1,Article10(Mar2024),23pages.
https://doi.org/10.1145/3630107
[82] DouglasZytko,PamelaJ.Wisniewski,ShionGuha,EricP.S.Baumer,andMinKyungLee.2022.ParticipatoryDesignof
AISystems:OpportunitiesandChallengesAcrossDiverseUsers,Relationships,andApplicationDomains.InExtended
Abstractsofthe2022CHIConferenceonHumanFactorsinComputingSystems(NewOrleans,LA,USA)(CHIEA’22,
Article154).AssociationforComputingMachinery,NewYork,NY,USA,1–4.
A SurveyResults
AppendixAcompilesthesurveyresultsfromourstudy.Itcontainsaseriesoftableswithdetailed
breakdownsofrespondentusagepatterns,feedbackbehaviours,demographics,andperceptionsof
submittingfeedbackusingtheinteractivefeaturesintheChatGPTinterface.
Table2. FrequencyofChatGPTUsage
Frequency Count Percentage
Afewtimesaweek 216 41.1%
Onceaweek 96 18.3%
Monthly 84 16.0%
Rarely 65 12.4%
Daily 64 12.2%
Total 525 100.0%
(Responserate:525/526)
Preprint.UnderReview.20 CooperandZafiroglu
Table3. WaysofUsingChatGPT
Usage Count Percentage
Answeringspecificquestions 375 71.3%
Generatingtext 332 62.9%
Academicresearchassistance 268 51.0%
Entertainmentorcasualconversation 226 43.0%
Professionalortechnicalproblem-solving 222 42.2%
Creativewriting 214 40.7%
Languagelearningortranslation 122 23.3%
Personaladviceoremotionalsupport 109 20.7%
Other 22 4.2%
(Responserate:526/526,Multipleselectionsallowed)
Table4. SubmittedThumbs-Up/DownFeedback
Submittedfeedback Count Percentage
Yes 400 76.0%
No 126 24.0%
Total 526 100.0%
(Responserate:526/526)
Table5. FrequencyofThumbs-Up/DownFeedback
Frequency Count Percentage
SometimesIhaveusedChatGPT 139 34.8%
AbouthalfthetimeIhaveusedChatGPT 98 24.5%
MosttimesIhaveusedChatGPT 92 23.0%
Rarely 48 12.0%
EverytimeIhaveusedChatGPT 23 5.8%
Total 400 100.0%
(Responserate:400/400)
Table6. SubmittedOpen-TextFeedback
Submittedfeedback Count Percentage
No 248 47.1%
Yes 152 29.0%
N/A 126 23.9%
Total 526 100.0%
(Responserate:526/526,N/A=“No”tosubmittingthumbs-up/downfeedback.)
Preprint.UnderReview.ConstrainingParticipation:AffordancesofFeedbackFeaturesinInterfacestoLargeLanguageModels 21
Table7. SubmittedOpen-TextFeedback(“Yes”tothumbs-up/downfeedback)
Submittedfeedback Count Percentage
No 248 62.0%
Yes 152 38.0%
Total 400 100.0%
(Responserate:400/400)
Table8. FrequencyofOpen-TextFeedback
Frequency Count Percentage
SometimesIhaveusedChatGPT 77 50.7%
Rarely 35 23.0%
MosttimesIhaveusedChatGPT 20 13.2%
AbouthalfthetimeIhaveusedChatGPT 17 11.2%
EverytimeIhaveusedChatGPT 3 2.0%
Total 152 100.0%
(Responserate:152/152)
Table9. SubmittedFeedbackAfterRegeneratingaResponse
Submittedfeedback Count Percentage
Yes 331 62.9%
No 195 37.1%
Total 526 100.0%
(Responserate:526/526)
Table10. FrequencyofFeedbackAfterRegeneratingaResponse
Frequency Count Percentage
SometimesIhaveregeneratedaresponse 120 36.3%
MosttimesIhaveregeneratedaresponse 67 20.2%
AbouthalfthetimeIhaveregeneratedaresponse 65 19.6%
Rarely 54 16.3%
EverytimeIhaveregeneratedaresponse 25 7.6%
Total 331 100.0%
(Responserate:331/331)
Preprint.UnderReview.22 CooperandZafiroglu
Table11. ReasonsforNotSubmittingFeedback
Reasons Count Percentage
Unawareoffeedbackoption 27 34.6%
Notenoughtimeorinterestinsubmittingfeedback 21 26.9%
Satisfiedwiththeperformanceandhavenotfelttheneedtosubmit 17 21.8%
feedback
Unsurehowtoprovidefeedback 7 9.0%
Other 5 6.4%
Unsatisfiedwiththeperformance,butdonotbelievefeedbackwill 1 1.3%
leadtoimprovements
Total 78 100.0%
(Responserate:78/78)
Table12. MotivationsforProvidingFeedback
Motivation Weightedfrequency
TocontributetoAIdevelopment 159
Tocommentonuse-casespecificfeedback 94
Toreportatechnicalissueorbug 74
Tosuggestnewfeaturesorimprovements 73
ToexpresssocialorethicalconcernsaboutChatGPT 32
Other 15
(Responserate:152/152)
Note:Weightedfrequenciesbasedonatwo-partquestion.PartA(multipleselection)responsesweightedas1;PartB(main
motivation)responsesweightedas2.
Table13. ReceivedFollow-upRegardingFeedback
Response Count Percentage
No 135 88.8%
Yes 17 11.2%
Total 152 100.0%
(Responserate:152/152)
Table14. SatisfactionwithFollow-up
Satisfactionlevel Count Percentage
Somewhatsatisfied 10 58.8%
Extremelysatisfied 5 29.4%
Neithersatisfiednordissatisfied 2 11.8%
Total 17 100.0%
(Responserate:17/17)
Preprint.UnderReview.ConstrainingParticipation:AffordancesofFeedbackFeaturesinInterfacestoLargeLanguageModels 23
Table15. ReasonsforSubmittingFeedbackAddressed
Agreementlevel Count Percentage
Neitheragreenordisagree 72 47.4%
Somewhatagree 36 23.7%
Somewhatdisagree 25 16.4%
Stronglydisagree 11 7.2%
Stronglyagree 8 5.3%
Total 152 100.0%
(Responserate:152/152)
Table16. EaseofSubmittingFeedback
Levelofease Count Percentage
Extremelyeasy 292 66.1%
Somewhateasy 128 29.0%
Neithereasynordifficult 18 4.1%
Somewhatdifficult 4 0.9%
Total 442 100.0%
(Responserate:442/443)
Table17. LikelihoodofSubmittingFeedbackinFuture
Likelihood Count Percentage
Somewhatlikely 255 48.7%
Extremelylikely 161 30.7%
Neitherlikelynorunlikely 67 12.8%
Somewhatunlikely 34 6.5%
Extremelyunlikely 7 1.3%
Total 524 100.0%
(Responserate:524/526)
Table18. ProvidedFeedbackviaOtherPlatformsorChannels
Providedfeedback Count Percentage
No 423 80.4%
Yes 103 19.6%
Total 526 100.0%
(Responserate:526/526)
Preprint.UnderReview.24 CooperandZafiroglu
Table19. OtherChannelsorPlatforms
Channels Count Percentage
X/Twitter 42 40.8%
Facebook 18 17.5%
Other 18 17.5%
Redditforums 17 16.5%
Discordservers 17 16.5%
LinkedIn 10 9.7%
ContactingOpenAI(e.g.,viaemail) 10 9.7%
Otheronlinediscussionforums 9 8.7%
Mastodon 3 2.9%
(Responserate103/103,Multipleselectionsallowed)
Table20. LikelihoodofSubmittingFeedbackviaOtherChannelsorPlatformsinFuture
Likelihood Count Percentage
Somewhatlikely 46 44.7%
Extremelylikely 28 27.2%
Neitherlikelynorunlikely 15 14.6%
Somewhatunlikely 10 9.7%
Extremelyunlikely 4 3.9%
Total 103 100.0%
(Responserate:103/103)
Table21. Age
Age Count Percentage
18-24 222 42.4%
25-34 184 35.1%
35-44 72 13.7%
45-54 31 5.9%
55-64 8 1.5%
65+ 4 0.8%
Prefernottosay 3 0.6%
Total 524 100.0%
(Responserate:524/526)
Preprint.UnderReview.ConstrainingParticipation:AffordancesofFeedbackFeaturesinInterfacestoLargeLanguageModels 25
Table22. Gender
Gender Count Percentage
Man 329 63.1%
Woman 182 34.9%
Non-binary/thirdgender 6 1.2%
Prefernottosay 3 0.6%
Prefertoself-describe 1 0.2%
Total 521 100.0%
(Responserate:521/526)
Table23. Region
Region Count Percentage
Europe 281 55.4%
Africa 79 15.6%
UnitedKingdom 52 10.3%
Oceania 33 6.5%
NorthAmerica 23 4.5%
CentralAmerica 21 4.1%
SouthAmerica 9 1.8%
Asia 9 1.8%
Total 507 100.0%
(Responserate:507/526)
Preprint.UnderReview.26 CooperandZafiroglu
Table24. LanguagesSpokenDaily(Grouped)
Languages Count Percentage
English(UK) 163 32.0%
English(US) 116 22.8%
Portuguese 68 13.4%
Polish 62 12.2%
Italian 33 6.5%
English(AU) 32 6.3%
Zulu 29 5.7%
Spanish(includingLatinAmerican) 49 9.6%
Greek 15 2.9%
German(StandardandSwiss) 14 2.8%
Sotho 13 2.6%
French(includingCanadian) 9 1.8%
OtherAfricanlanguages 8 1.6%
Dutch 6 1.2%
Czech 5 1.0%
OtherEuropeanlanguages 14 2.8%
OtherAsianlanguages 11 2.2%
Otherlanguages 7 1.4%
Total 509 100.0%
(Responserate:509/526,upto3selectionsallowed)
Notes:‘OtherAfricanlanguages’includesSetswana,Xhosa,Yoruba,Swahili,andHausa;’OtherEuropeanlanguages’
includesFinnish,Hungarian,Latvian,Russian,Norwegian,Danish,Swedish,Catalan,Ukrainian,andLithuanian;’Other
Asianlanguages’includesHindi,Hebrew,Turkish,Arabic,Mongolian,Korean,Japanese,Persian,Bengali,Tagalog,Thai,
andSinhalese;’Otherlanguages’includesPortuguese(Brazilian),Slovenian,Croatian,andunspecifiedothers.
Table25. BarriersAccessingChatGPTorSubmittingFeedback
Barriers Count Percentage
Nobarriers 401 77.3%
Barriers 118 22.7%
Total 519 100.0%
(Responserate:519/526)
Preprint.UnderReview.ConstrainingParticipation:AffordancesofFeedbackFeaturesinInterfacestoLargeLanguageModels 27
Table26. FrequencyofEngagingwithAI-relatedTopics
Frequency Count Percentage
Weekly 243 46.5%
Monthly 99 18.9%
Daily 87 16.6%
Rarely 85 16.3%
Never 9 1.7%
Total 523 100.0%
(Responserate:523/526)
Table27. PriorUseofAI,ML,orDataScienceTools
Response Count Percentage
No 308 59.0%
Yes 214 41.0%
Total 522 100.0%
(Responserate:522/526)
Table28. CompletedEducationorTraininginAI,ML,orDataScience
Response Count Percentage
No 382 73.5%
Yes 138 26.5%
Total 520 100.0%
(Responserate:520/526)
Table29. CurrentlyorPreviouslyWorkinginAI,ML,orDataScience
Response Count Percentage
No 410 78.7%
Yes 111 21.3%
Total 521 100.0%
(Responserate:521/526)
Preprint.UnderReview.28 CooperandZafiroglu
Table30. ConfidenceSubmittingFeedback
Confidencelevel Count Percentage
Somewhatagree 296 56.5%
Stronglyagree 114 21.8%
Neitheragreenordisagree 79 15.1%
Somewhatdisagree 30 5.7%
Stronglydisagree 5 1.0%
Total 524 100.0%
(Responserate:524/526)
Preprint.UnderReview.ConstrainingParticipation:AffordancesofFeedbackFeaturesinInterfacestoLargeLanguageModels 29
B StatisticalRelationshipsandTestResults
AppendixBpresentsourstatisticalanalysisofrelationshipsbetweenkeyvariablesinourstudy.
Table31presentstheresultsofchi-squaretestsofassociationsbetweenvariousfactorssuchasuser
characteristics,feedbackbehaviours,andperceptionsofsubmittingfeedbackthroughtheChatGPT
interface.
Table31. Chi-squareTestResults
Relationship 𝜒2 𝑝 Adj.𝑝 df CV Interp. 𝑛
Thumbs-Up/down&Regeneratingfeedback 50.419 <.001 <.001* 1 .319 Mod. 497
Education/TraininginAI&Confidence 12.773 .002 .023* 2 .160 Weak 497
WorkinginAI&Barriers 9.821 .002 .023* 1 .143 Weak 477
Region&Open-textfeedback 13.990 .003 .023* 3 .192 Mod. 378
PriorAIuse&Open-textfeedback 8.926 .003 .023* 1 .154 Weak 378
Thumbs-Up/down&ChatGPTfrequency 13.689 .008 .045* 4 .166 Weak 497
AItopicsfrequency&Confidence 20.726 .008 .045* 8 .144 Weak 497
Age&Confidence 17.068 .009 .045* 6 .131 Weak 497
Education/TraininginAI&Open-text 6.132 .013 .059 1 .127 Weak 378
Gender&Regeneratingfeedback 10.427 .015 .061 3 .145 Weak 497
Age&Barriers 9.372 .025 .078 3 .140 Weak 477
Open-text&ChatGPTfrequency 10.956 .027 .078 4 .170 Mod. 378
AItopicsfrequency&Open-text 10.937 .027 .078 4 .170 Mod. 378
Region&Regeneratingfeedback 9.151 .027 .078 3 .136 Weak 497
WorkinginAI&Open-textfeedback 4.660 .031 .080 1 .111 Weak 378
Age&Regeneratingfeedback 8.678 .034 .080 3 .132 Weak 497
PriorAIuse&Barriers 4.512 .034 .080 1 .097 Negl. 477
Education/TraininginAI&Barriers 4.010 .045 .101 1 .092 Negl. 477
Gender&Confidence 12.513 .051 .103 6 .112 Weak 497
PriorAIuse&Confidence 5.953 .051 .103 2 .109 Weak 497
WorkinginAI&Confidence 5.632 .060 .114 2 .106 Weak 497
Open-text&Regeneratingfeedback 3.424 .064 .117 1 .095 Negl. 378
AItopicsfrequency&Thumbs-Up/down 7.615 .107 .186 4 .124 Weak 497
WorkinginAI&Regeneratingfeedback 2.375 .123 .205 1 .069 Negl. 497
Regenerating&ChatGPTfrequency 5.004 .287 .459 4 .100 Weak 497
Age&Open-textfeedback 3.342 .342 .526 3 .094 Weak 378
Gender&Thumbs-Up/down 3.160 .368 .545 3 .080 Weak 497
AItopicsfrequency&Barriers 3.962 .411 .554 4 .091 Weak 477
AItopicsfrequency&Regenerating 3.932 .415 .554 4 .089 Weak 497
PriorAIuse&Thumbs-Up/down 0.666 .415 .554 1 .037 Negl. 497
Gender&Barriers 2.482 .478 .607 3 .072 Weak 477
Education/TraininginAI&Thumbs 0.468 .494 .607 1 .031 Negl. 497
WorkinginAI&Thumbs-Up/down 0.453 .501 .607 1 .030 Negl. 497
Gender&Open-textfeedback 1.801 .615 .723 3 .069 Weak 378
Age&Thumbs-Up/down 1.713 .634 .725 3 .059 Negl. 497
PriorAIuse&Regeneratingfeedback 0.140 .708 .773 1 .017 Negl. 497
Region&Barriers 1.361 .715 .773 3 .053 Negl. 477
Education/TraininginAI&Regenerating 0.065 .799 .841 1 .011 Negl. 497
Region&Thumbs-Up/down 0.708 .871 .894 3 .038 Negl. 497
Region&Confidence 1.548 .956 .956 6 .039 Negl. 497
Preprint.UnderReview.30 CooperandZafiroglu
Notes:
• Adj.𝑝 =𝑝-valueafterBenjamini-Hochbergprocedure;df=DegreesofFreedom;CV=Cramér’sV;
Interp.=Interpretation;Mod.=Moderate;Negl.=Negligible,𝑛=Samplesizeafterremovingmissing
values.
• Tableorganisedinorderofadj.𝑝-value.
• *Indicatesstatisticallysignificant𝑝-valueafteradjustment.
• 𝜒2testwasnotperformedbetweenThumbs-Up/down&Open-textfeedback.Open-textfeedbackwas
onlyavailabletouserswhoprovidedThumbs-Up/downfeedback,makingthesevariablesdependent.
• Table32providesaguideforinterpretingCramér’sVvalues,inaccordancewith[13].
Table32. InterpretationofCramér’sV
Association df=1 df=2 df≥3
Weak 0.10-<0.30 0.07-<0.21 0.06-<0.17
Moderate 0.30-<0.50 0.21-<0.35 0.17-<0.29
Strong ≥0.50 ≥0.35 ≥0.30
Preprint.UnderReview.