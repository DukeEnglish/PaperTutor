General targeted machine learning for modern causal
mediation analysis
1 2 2 1
Richard Liu , Nicholas T. Williams , Kara E. Rudolph , and Iva´n D´ıaz
1
DivisionofBiostatistics, DepartmentofPopulation Health,NewYorkUniversityGrossmanSchoolof
Medicine,USA
2DepartmentofEpidemiology, MailmanSchoolofPublicHealth,ColumbiaUniversity,NewYork,NY,
USA.
August 28, 2024
Abstract
Causal mediation analyses investigate the mechanisms through which causes exert their
effects, and are therefore central to scientific progress. The literature on the non-parametric
definition and identification of mediational effects in rigourous causal models has grown sig-
nificantly in recent years, and there has been important progress to address challenges in the
interpretation andidentification ofsuch effects. Despite greatprogress inthecausal inference
front,statisticalmethodologyfornon-parametric estimationhaslaggedbehind,withfeworno
methodsavailablefortacklingnon-parametric estimationinthepresenceofmultiple,continu-
ous,orhigh-dimensional mediators. Inthispaper weshowthattheidentification formulasfor
sixpopularnon-parametricapproaches tomediationanalysisproposedinrecentyears(natural
direct and indirect effects, randomized interventional effects, separable effects, organic direct
and indirect effects, recanting twin effects, and decision theoretic effects) can be recovered
fromjusttwostatisticalestimands. Weleveragethisfindingtoproposeanall-purposeone-step
estimation algorithm that can be coupled with machine learning in any mediation study that
uses any of these six definitions of mediation. The estimators rely on a re-parameterization
of the identification formulas in terms of sequential regressions, and on a first order non-
parametricvon-Misesapproximations ofthefirstbiasofaplug-inestimator. Thisallowsusto
showthattheproposedone-stepestimatorshavedesirableproperties,suchas√n-convergence
and asymptotic normality. Estimating the first-order correction for the one-step estimator re-
quires estimation of complex density ratios on the potentially high-dimensional mediators, a
challenge that is solved using recent advancements in so-called Riesz learning. We illustrate
thepropertiesofourmethodsinasimulationstudyandillustrateitsuseonrealdatatoestimate
theextenttowhichpainmanagementpracticesmediatethetotaleffectofhavingachronicpain
disorderonopioidusedisorder. WeprovideanRpackageimplementingourmethodspublicly
available athttps://github.com/nt-williams/crumble.
1
4202
guA
62
]LM.tats[
1v02641.8042:viXra1 Introduction
Causal mediation analyses seek to investigate the extent through which the effect of an exposure
onan outcomeoperatesthrougheffectsoftheexposureonintermediatevariables. Recent decades
haveseen increased attentionto thedevelopmentofmethodologyforthedefinition,identification,
and estimation of effects for mediation analysis, as well as their increased application in various
scientific fields. Particularly, the definition and identification of effects that are guaranteed to
measure the mechanisms through which the effect operates has been the subject of considerable
debate and methodological work (e.g., Robins, 2003; Pearl, 2010; Robinsand Richardson, 2010;
Miles, 2023; D´ıaz, 2024).
Natural direct and indirect effects (NDE and NIE; Robinsand Greenland, 1992; Pearl, 2001)
areoneofthemostwidelyknowndefinitionsofcausal mediationparameters withanagreed upon
mechanistic interpretation. Broadly, the NDE measures the effect that operates independent of
a mediator through counterfactual variables in which the effect through the mediator is disabled,
whereastheNIEmeasureseffectsthroughthemediatorbyconsideringcounterfactualsthatdisable
alleffectsthatoperateindependentlyofit. Inspiteoftheirscientificimportance,desirableinterpre-
tation, and widespread use, the NDE and NIE are seldom identified from observed data, because
their identification relies on so-called cross-world counterfactual assumptions—independenceas-
sumptions between counterfactual variables indexed by distinct interventions on the exposure.
Philosophically, cross-world assumptions are problematic because they cannot be tested empiri-
cally nor enforced by design, which means that conclusions from an analysis using the NIE and
NDE are not falsifiable. Practically, the cross-world assumption is guaranteed not to hold in the
presence of variables caused by the treatment that are common causes of both the mediator and
the outcome (Avinet al., 2005), regardless of whether such variables are measured or not. These
variables, often referred to as intermediate confounders or recanting witnesses, are pervasive in
scientificapplications.
In an attempt to address the above limitations of the NDE and NIE, several alternative causal
estimandshavebeenproposed. Inthisarticlewediscussfivesuchdefinitions,butwenotethatour
review is not exhaustive. First, randomized interventional direct and indirect effects (RIDE and
RIIE vanderLaan and Petersen, 2008; VanderWeeleet al., 2014; VansteelandtandDaniel, 2017;
VanderWeele andTchetgen Tchetgen, 2017; D´ıazet al., 2023) define direct and indirect effects
through interventions that set the mediator to a random draw based on the distributions of the
counterfactualmediatorsundertreatmentandcontrol. Randomizedinterventionaleffectsareiden-
tifiable in the presence of intermediate confounders under the assumption that all confounders of
the exposure-outcome, exposure-mediator, and mediator-outcome relations are measured. How-
ever, it was recently shown that randomized interventional effects may not necessarily measure
mechanistic relations, as the RIIE could be nonzero even in a situation where some population
units experience an exposure-mediator effect, other units experience a mediator-outcome effect,
but no unit experiences both (Miles, 2023). Second, in a series of articles, Didelezet al. (2006);
Geneletti (2007) and Dawid (2021) proposed a decision-theoretic approach to mediation analysis
(andmoregenerallytocausalinference)thatusesprobabilisticdefinitionsfortherelevantinterven-
tions, avoiding reliance on on counterfactual arguments, and therefore avoiding reliance on cross-
world independence assumptions. Third, a recent strand of the causal inference literature has ad-
dressed the definitionand identificationofmediationaleffects and effects undercompetingevents
using so-called separable effects (Robinsand Richardson, 2010; Didelez, 2019; Stensrudet al.,
22021; Robinset al., 2022; Stensrud et al., 2022). These effects avoid cross-world definitions by
requiring researchers to posit the existence of separable components of the exposure that exert
independent effects on the outcome and the mediator. Separable effects are then defined through
distinctinterventionson thosecomponents,thusavoidingcross-worldstatements. Vo et al.(2024)
generalized separable effects to allow for the definition and identification of mediational effects
in the presence of intermediate confounders. Fourth, D´ıaz (2024) and Vo et al. (2024) recently
introducedafour-way decompositionoftheaveragetreatmenteffect intoeach ofthepath-specific
effects involved, using randomized versions of the recanting witnesses. Unlike some of the pre-
vious approaches, these path-specific effects satisfy a property known as the path-specific sharp
null criterion (Miles, 2023), which guarantees that the effects are zero whenever no individual
in the population experiences an effect through the corresponding path. Lastly, a series of arti-
cles discusses organic direct and indirect effects (Lok, 2015, 2016, 2019; Lok and Bosch, 2021),
whichrelyonthecharacterizationofanexternalinterventiontothecausalsystemthatwouldyield
specificmodificationstothemediatordistribution.
An additionallimitationofall oftheaboveapproaches forthedefinition,identification,and es-
timationof direct and indirect effects in mediationanalyses is that theliterature has almost exclu-
sivelyfocused on binary exposures, although some approaches for continuous and/ormultivariate
exposures have been developed based on stochastic interventions and modified treatment policies
(D´ıazand Hejazi, 2020; Hejazi etal., 2023; Gilbertet al., 2024).
As illustrated above, the non-parametric definition and identification of causal effects for me-
diation analysis has received significant attention which has led to significant progress. Some
methods for the non-parametric estimation of those effects have also been developed. For in-
stance, non-parametric approaches to estimate the statistical functional identifying the NDE and
NIE include the estimators of vander Laan andPetersen (2008); Zheng andvan derLaan (2012),
and Xiaand Chan (2023). Approaches for randomized interventional effects for cross-sectional
(D´ıazet al.,2021a;Benkeserand Ran,2021;Rudolph etal.,2024a)andlongitudinal(Zheng andvan derLaan,
2017; D´ıazet al., 2023; Wang et al., 2023) effects have also been developed, as well as non-
parametric estimators for the NDE and NIE under alternative monotonicity identifying assump-
tionsthatdonotprecludeintermediateconfounders(Rudolphet al.,2023;Tchetgenand VanderWeele,
2014).
Inspiteofimportantprogressinthenon-parametricdefinitionandidentificationofmediational
parameters, estimators for many approaches remain underdeveloped, and there are few solutions
that can handle continuous and multivariate or high-dimensional mediators. Specifically, most of
the above literature on non-parametric estimation of mediational parameters is based on recently
popularized frameworks that estimate and/or correct for the first-order bias of a plug-in machine
learning estimator (vanderLaan and Rose, 2011, 2018; Chernozhukovetal., 2018). Central to
theseframeworksistheconceptofacanonicalgradientorefficientinfluencefunction,whichchar-
acterizes the first-order bias of plug-in estimators as well as the non-parametric efficiency bound
(von Mises, 1947; Pfanzagl and Wefelmeyer, 1985; Bickel et al., 1997). A key challengein medi-
ation analysis with continuous or high-dimensional mediators is that estimation of the canonical
gradient requires estimation of densities of the mediator as well as integrals with respect to such
densities. Oftheestimatorsmentionedintheaboveparagraphthataccommodateintermediatecon-
founders,onlytheapproachofRudolphet al.(2024a)forrandomizedinterventionaleffectsallows
for high-dimensional or multivariate mediators and confounders. As noted earlier, however, ran-
domizedinterventionaleffectsdonotalwaysallowforaninterpretationintermsofindividual-level
3mechanisms. Thus, thereisaneed in theliteratureto developestimatorsofalternativeapproaches
that address the shortcomings of randomized interventional effects, such as the separable effects
Vo et al.(2024)and therecanting twineffects ofD´ıaz(2024).
In this article we make two main contributions. First, we show that the identification formulas
for the six causal parameters for mediation analysis with binary exposures described above and
listed in the abstract can be recovered from two fundamental statistical functionals. We then use
this fact to proposeunified theory for semiparametricestimationof mediationanalyses, providing
an algorithm that can be used under either of these six causal models and definitions, without re-
strictionsonthedimensionalityofthemediatorsortheintermediateconfounders. Weaddresschal-
lenges in theestimationof multivariateor high-dimensionaldensities on the mediatorthroughthe
useof so-called Riesz learning (Chernozhukovet al., 2022a), and address integrationwith respect
to those densities through parameterizing the integrals as conditional expectations using stratified
random permutations of the observed variables as in Doran et al. (2014). Second, we provide an
extension of these methods to definitions of mediational parameters for continuous or multivari-
ateexposures,by meansofmodified treatmentpolicies(Haneuseand Rotnitzky, 2013;Sani et al.,
2020; D´ıazet al.,2021b, 2022).
The paper is organized as follows. In §2, we introduce general identification formulas for
mediation analysis under a binary exposure, which unifies all six causal parameters mentioned
before. In §3, we introduce the semi-parametric efficiency theory for such parameters. In §4,
we use the developed theory to introduce estimation strategies. We prove desirable properties of
the estimators such as asymptotic linearity, weak convergence, and double robustness. In §5, we
demonstratehow the methods can be extended to non-binary treatments using modified treatment
policies. In§6,wepresentnumericalillustrationsoftheperformanceoftheestimatorsinsimulated
datasets. An illustrative real data example investigating the effects of chronic pain disorder on
opioidusedisorderisgivenin §7.
2 General identification formulas for mediation analysis with
binary exposures
In this section we show that the identification formulas for the six approaches to mediation dis-
cussed in the abstract and introduction can be recovered from just two generalized statistical esti-
mands. Thisfact willthenbeusedtoproposeamulti-purposeestimatorforgeneralizedmediation
analyses. We will first introduce some notation. Let A 0,1 denote a binary treatment or
∈ { }
exposure variable (we discuss effects for non-binary exposures in §5), let Y denote a continuous
or binary outcome, let M denote a vector of mediators, let Z denotea vector of intermediatecon-
founders, and let W denote a vector of observed covariates. Let X = (W,A,Z,M,Y) represent
a random variable with distribution P. Let P denote the empirical distribution of a sample of in-
n
dependentand identicallydistributed(i.i.d.) observationsX ,...,X , andlet Pf = f(x)dP(x)
1 n
foragivenfunctionf(x). LetE betheexpectationwithrespecttoP. Whenthereisnoambiguity
P
R
we will denote E = E . The causal models used in the original articles that define the causal me-
P
diationalparametersweconsiderarevaried(e.g.,notallusecounterfactuals),buttheyallhavethe
same representation in terms of the directed acyclic graph (DAG) given in Figure 1, where some-
times the variable Z is present and some times it is not. Our methods will rely on the availability
4W
A Z M Y
Figure1: Causal DAG
ofarandomvariableZπ satisfying
Zπ (A,W) Z (A,W) andZπ M (A,W), (1)
| ∼ | ⊥⊥ |
where A B means equality in distribution. In this section as well as in §4, we assume that an
∼
i.i.d. sample (Zπ,...,Zπ) of such a random variable is given together with X ,...,X , so that
1 n 1 n
the observed data for unit i can be augmented as (W ,A ,Z ,Zπ,M ,Y ). In practice, Zπ will be
i i i i i i i
constructedthroughapermutationofZ which wediscussin §4.3.
i
Forvalues(a ,...,a ) 0,1 4,wedefine
1 4
∈ { }
ψR(a1,a2,a3,a4)=E E E E E(Y A=a1,Zπ,M,W) A=a2,M,W A=a3,Z,W A=a4,W ,
ψN(a1,a2,a3)=E" E(cid:20) Eh E((cid:2)
Y
A|
=a1,Z,M,W)
A=(cid:12) (cid:12)
a2,Z,W
A(cid:3) =(cid:12) (cid:12) (cid:12)
a3,W ,
i(cid:12) (cid:12) (cid:12)
(cid:12)
(cid:21)# (2)
|
wherethesuperscript(cid:20) Nh st(cid:2) andsfornaturalandth(cid:12) (cid:12)esuperscript(cid:3) R(cid:12) (cid:12)
(cid:12)
standsfori(cid:21) randomized,accounting
for the fact that we introduce the permutation Zπ. The introduction of the permuted variable Zπ
allows us to write integrals of the type f(a ,z,m,w)dP(z a ,w), which may be hard to
1 2
|
estimateif Z is high-dimensional,as conditionalexpectations E[f(a ,Zπ,M,W) A = a ,M =
R 1 | 2
m,W = w], which can be estimated using flexible regression techniques from the statistical and
machinelearning literature.
In Proposition 1 below we show that the identifying functionals for the six mediation frame-
works described in the abstract can be recovered from the parameters ψR and ψN defined above.
In Table 1 below we introduce abbreviations for each of the corresponding causal effects, and
provideone reference for each where the corresponding definitions in terms of causal models and
proofsforidentificationcanbefound. OftheapproacheslistedinTable1,onlythefirsttwodonot
allowforintermediateconfounders(i.e.,thesetwoapproachesassumethereisnovariableZ inthe
DAG in Figure 1), and only thelast two allowfor a decompositionof the average treatment effect
into path-specific effects. The parameters referred to as “indirect effects” measure all effects of A
on Y that operate through M (i.e., A M Y and A Z M Y), and the parameters
→ → → → →
referred to as “direct effects” measure all effects of A on Y that operate independentlyof M (i.e.,
A Z Y and A Y). For approaches that allow a decompositioninto path-specific effects,
→ → →
we introduce the notation P to refer to each path, where P : A Y, P : A Z Y,
j 1 2
→ → →
P : A Z M Y, and P : A M Y. A comprehensive discussion of the causal
3 4
→ → → → →
models, definitions of mediational effects, and identification assumptions, is out of the scope of
thispaperandisgiveninthereferencesprovidedin§1andinTable1,wereferthereaderstothose
references fordiscussion.
5Abbreviation Parameter Reference
NDE/NIE Naturaldirectandindirecteffects Pearl(2001)
DTDE/DTIE Decisiontheoreticdirectandindirecteffects Geneletti(2007)
ODE/OIE Organicdirectandindirecteffects Lok(2015)
RIDE/RIIE Randomizedinterventionaldirectandindirecteffects VanderWeeleetal.(2014)
RT :j =1,2,3,4 Path-specificeffectsbasedonrecantingtwinsforpathP D´ıaz(2024)
j j
SE :j =1,2,3,4 Path-specificeffectsbasedonseparableeffectsforpathP Voetal.(2024)
j j
Table 1: Abbreviations and references with the definitions of the causal effects and their identifi-
cationtheorems forthesixmediationframeworksconsidered inthiswork
Proposition 1 (Identification of parameters for six approaches to causal mediation). The identi-
fication formulas for the causal parameters listed in Table 1 and provided in the corresponding
references can bewrittenin termsof ψN andψR as:
NDE=ψN(1,0,0) ψN(0,0,0), NIE=ψN(1,1,1) ψN(1,0,0),
− −
DTDE=ψN(1,0,0) ψN(0,0,0), DTIE=ψN(1,1,1) ψN(1,0,0),
− −
ODE=ψN(1,0,1) ψN(0,0,0), OIE=ψN(1,1,1) ψN(1,0,1),
− −
RIDE=ψR(1,1,0,0) ψR(0,0,0,0), RIIE=ψR(1,1,1,1) ψR(1,1,0,0),
− −
aswell as
RT1 =ψN(1,1,1) ψN(0,1,1), RT2 =ψR(0,1,1,1) ψR(0,0,1,1),
− −
RT3 =ψR(0,0,1,1) ψR(0,0,1,0), RT4 =ψN(0,1,0) ψN(0,0,0),
− −
and
SE1 =ψN(1,1,1) ψN(0,1,1), SE2 =ψR(0,1,1,1) ψR(0,0,1,1),
− −
SE3 =ψR(0,0,1,1) ψR(0,0,1,0), SE4 =ψN(0,1,0) ψN(0,0,0).
− −
Having established the importance and generality of the parameters ψN and ψR for mediation
analysis, we will proceed to develop general estimation methods for those parameters that can be
usedwithhigh-dimensionalW,Z,andM variables. Inwhatfollows,weeasenotationbyomitting
(a ,a ,a ,a )whenreferringtoψN andψR,butthedependenceoftheparametersonthesevalues
1 2 3 4
will remain implicit. In order to develop non-parametric estimators that can leverage machine
learningtofittheregressionsinvolvedinthedefinitionsofψN andψR,wewillusetechniquesfrom
theliterature in semi-parametricefficiency theory, which require thestudy ofcertain properties of
theparametersψN andψRseenasfunctionalsψN(P)andψR(P)thatmapaprobabilitydistribution
P in the non-parametric model into a real number given by the formulas in (2). The following
P
sectionprovidesastudyoftherequired elements.
3 Semi-parametric efficiency theory
The estimators we propose will be based on one-step first-order bias corrections to plug-in ma-
chine learning estimators based on the formulas in (2). To motivatethe developmentsthat follow,
consider estimators of the formulas in (2) constructed, for example, by estimating the probability
distribution P and plugging it into the formulas, or by estimating the sequential regressions in-
volved using predictions from the prior regressions in the sequence as pseudo-outcomes. When
6such plug-in estimators are constructed based on estimators from parametric models, the Delta
methodallows oneto provethat the distributionofthe√n-scaled estimatormay beapproximated
by a Gaussian random variable for large n, allowing the analytical computation of uncertainty
measuressuch asconfidenceintervals. TheGaussiandistribution,however,willbecentered atthe
wrongvalueifthemodelsare incorrectlyspecified, withthealarmingconsequencethatthecover-
age of a confidence interval will contain the true parameter value with zero probability as sample
sizegrows. Toaddress thismodelmisspecificationbias,theformulasin(2)may alsobeestimated
usingdata-adaptivemethodsfromthemachinelearningliterature, which mayallowforadditional
flexibility in automatically finding interactions, non-linearities, etc. However, no theory exists
that allows the analysis of the sampling distributions of general plug-in machine learning estima-
tors. Instead, recent methods for machine learning in causal inference such as targeted learning
(vander Laan andRose,2011,2018)ordoublemachinelearning(Chernozhukovet al.,2018)rely
oncharacterizingandcorrectingforthefirst-orderbiasoftheplug-inmachinelearningestimators.
Thecharacterizationofthebiasisgivenbyaso-calledfirst-ordervonMisesexpansion(vonMises,
1947;Fernholz,1983;Robinset al.,2009),definedbelow. Inwhatfollowsweuseψ(P)toreferto
ageneral statisticalparameterviewedas amapfrom thenon-parametricmodelstothereal line.
Definition 1 (First-order von Mises expansion). Let ψ : R be a functional from the non-
P →
parametric model to the real line. The functional admits a first-order von Mises expansion if it
satisfies:
ψ(F) ψ(P) = E [ϕ(X;F)]+R (F,P) (3)
P 2
− −
foranyF,P ,whereϕ(x;F)isafunctionsatisfyingE [ϕ(X;ψ(F))] = 0andE [ϕ2(X;ψ(F))] <
F F
∈ P
, and the term R (F,P) is a second-order remainder term depending on products or squares of
2
∞
differencesbetween F andP. Thefunctionϕistypicallyreferred toasa gradientofthefirst-order
expansion.
The above expansion provides the basis to analyze a plug-in machine learning estimator. For
instance, assume that we have access to an estimate Pˆ of the true data distribution P, where Pˆ is
obtained from data-adaptive methods. Then, Eq. (3) provides the basis to analyze the error of the
plug-inestimatorψ(Pˆ ) as
ψ(Pˆ ) ψ(P) = E [ϕ(X;Pˆ )]+R (Pˆ ,P).
P 2
− −
Informally, if Pˆ is a “good enough” estimator, the second-order term R (Pˆ ,P) may be negligible,
2
sothattheerrorinestimationmaybereducedtothefirstorderterm E [ϕ(X;Pˆ )]. Thiserrorcan
P
then be estimated as the negative of the empirical average of ϕ(X ;− Pˆ ), which can then be added
i
backtothepluginestimatorψ(Pˆ ). Intheliterature,thishasbeencalleda“one-step”estimatorora
de-biased estimator, althoughthe “de-biased” denominationis technically inaccurate as the above
isanerroranalysis,notabiasanalysis. (Abiasanalysiswouldconsiderthedifferencebetweenthe
expectationofψ(Pˆ )and ψ(P), wheretheexpectationis across multipledrawsof(X ,...,X ).)
1 n
Theorem1belowprovidesafirst-ordervonMisesexpansionforψN andψR thatcanbeusedto
construct aone-step estimator. To statethetheorem, weintroducesomeadditionalnotation. First,
7forψN, considerafixedvalue(a ,a ,a ) anddefine
1 2 3
θN (a,z,m,w) = E(Y A= a,Z = z,M = m,W = w), bN (z,m,w;θN ) = θN (a ,z,m,w),
3 3 3 3 1
|
θN
(a,z,w) =
E[bN (Z,M,W;θN
) A = a,Z = z,W =w],
bN (z,w;θN
) =
θN
(a ,z,w),
2 3 3 2 2 2 2
|
θN
(a,w) =
E[bN (Z,W;θN
) A= a,W = w],
bN (w;θN
) =
θN
(a ,w),
1 2 2 1 1 1 3
|
(4)
as wellas
1(A = a )
αN (a,w) = 3 ,
1 P(a w)
|
1(A = a )P(z A= a ,w)
αN (a,z,w) = 2 | 3 , (5)
2 P(a w) P(z a,w)
| |
1(A = a )P(m A = a ,z,w)P(z A= a ,w)
αN (a,z,m,w) = 1 | 2 | 3 .
3 P(a w) P(m a,z,w) P(z a,w)
| | |
ForψR, considerafixed value(a ,a ,a ,a ) and define
1 2 3 4
θR (a,z,m,w) = E(Y A = a,Z = z,M = m,W = w), bR (z,m,w;θR ) = θR (a ,z,m,w),
4 4 4 4 1
|
θR
(a,m,w) =
E[bR (Zπ ,M,W;θR
) A= a,M = m,W = w],
bR (m,w;θR
) =
θR
(a ,m,w),
3 4 4 3 3 3 2
|
θR
(a,z,w) =
E[bR (M,W;θR
) A= a,Z = z,W = w],
bR (z,w;θR
) =
θR
(a ,z,w),
2 3 3 2 2 2 3
|
θR
(a,w) =
E[bR (Z,W;θR
) A = a,W = w],
bR (w;θR
) =
θR
(a ,w),
1 2 2 1 1 1 4
|
(6)
as wellas
1(A= a )
αR (a,w) = 4 ;
1 P(a w)
|
1(A= a )P(z A= a ,w)
αR (a,z,w) = 3 | 4 ;
2 P(a w) P(z a,w)
| | (7)
1(A= a ) P(m A= a ,z,w)dP(z A= a ,w)
αR (a,m,w) = 2 z | 3 | 4 ;
3 P(a w) P(m a,w)
| R |
1(A= a )P(z A= a ,w) P(m A= a ,z,w)dP(z A= a ,w)
αR (a,z,m,w) = 1 | 2 z | 3 | 4 .
4 P(a w) P(z a,w) P(m a,z,w)
| | R |
Then wehavethefollowingresult.
Theorem 1 (First-order von Mises expansions and efficiency bounds for ψN and ψR). Let ηN =
(θN,θN,θN,αN,αN,αN) and ηR = (θR,θR,θR,θR,αR,αR,αR,αR). Thefunctions
3 2 1 3 2 1 3 3 2 1 4 3 2 1
N N N N N
ϕ (X;η ) = ϕ¯ (X;η ) ψ
−
N N
= α (A,Z,M,Y) Y θ (A,Z,M,W)
3 3
{ − }
N N N N
+α (A,Z,W) b (Z,M,W;θ ) θ (A,Z,W)
2 3 3 2
{ − }
N N N N
+α (A,W) b (Z,W;θ ) θ (A,W)
1 2 2 1
{ − }
N N N
+b (W;θ ) ψ ,
1 1
−
and
R R R R R
ϕ (X;η ) = ϕ¯ (X;η ) ψ
−
8R R
= α (A,Z,M,W) Y θ (A,Z,M,W)
4 4
{ − }
R R π R R
+α (A,M,W) b (Z ,M,W;θ ) θ (A,M,W)
3 4 4 3
{ − }
R R R R
+α (A,Z,W) b (M,W;θ ) θ (A,Z,M)
2 3 3 2
{ − }
R R R R
+α (A,W) b (Z,W;θ ) θ (A,W)
1 2 2 1
{ − }
R R R
+b (W;θ ) ψ
1 1
−
satisfy the first order von Mises expansion (3) for the parameters ψN and ψR, respectively, with
second-order terms RN(ηN,ηN) and RR(ηR,ηR) given in the supplementary materials. Further-
2 F P 2 F P
more, Var[ϕN(X;P)] and Var[ϕR(X;P)] arethecorrespondingnon-parametricefficiency bounds
in a model with observed data X = (W,A,Z,Zπ,M,Y). Here we use notation ϕ¯N(X;ηN) and
ϕ¯R(X;ηR) to introducetheuncentered gradients.
The above von Mises expansion characterizes the non-parametric efficiency bound for estima-
tion of ψE : E N,R in at least two senses. First, according to the convolution theorem
∈ { }
(Bickel et al.,1997),theoptimalasymptoticdistributionforanyregularestimatorofψE isaGaus-
sian distribution centered at zero with variance Var[ϕE(X;η )]. Second, vanderVaart (2002)
P
shows that Var[ϕE(X;P)] is the local asymptotic minimax efficiency bound for estimation of ψE
inthesensethat,foranyestimatorsequenceψE:
n
inf liminf sup nE ψE ψE(Q) 2 Var [ϕ(Z;η )],
n P P
δ>0 n→∞ Q:V(Q−P)<δ { − } ≥
where V( ) is the variation norm and E denotes expectation. We added indices P and Q to em-
·
phasize samplingunder P or Q, and used notation ψE(Q) to denote the parameter computed at an
arbitrary distribution. Furthermore, the functions ϕE(X;P) are unbiased estimating equations in
thefollowingsense,whichis acorollary ofTheorem 1.
Corollary 1 (Robustness of estimating equation). For E N,R and any nuisance parameter
η˜E,wehaveE[ϕ¯E(X;η˜E)] = ψE if,foreachk 1,2,3,4∈ ,{ wehav} eeitherθ˜E = θE orα˜E = αE.
k k k k
∈ { }
According to the above corollary and efficiency discussion, the functions ϕ¯E can be used to
constructestimatorswithdesirablepropertiessuchasdoublerobustness,efficiency,andasymptotic
linearity. We constructsuchestimatorsinthefollowingsection.
4 Estimators and their sampling distribution
Having derived the corresponding von Mises expansions, in this section we focus on the develop-
mentofestimationalgorithms. Theseestimatorshavemultipleingredients. First,itisnecessaryto
specifyanalgorithmfortheconstructionofaplug-inestimator. Thisestimatorwillbeconstructed
by a sequential regression procedure using the definitions of θ and b given in expressions (4)
j j
and (6). For instance, to construct a plug-in estimator for ψN, we first regress the outcome Y on
i
(A ,Z ,M ,W ), using flexible data-adaptive regression procedures to obtain an estimate θˆN. We
i i i i 3
then use this estimate to compute the pseudo-outcome bN(a ,Z ,M ,W ;θˆN) by computing the
3 1 i i i 3
predictions ofθˆN in a new dataset where A is fixed to a . This pseudo-outcomeis then regressed
3 i 1
on (A ,Z ,W ) to obtain an estimate θˆN, which is then used to construct a new pseudo-outcome
i i i 2
9bN(a ,Z ,W ;θˆN). This pseudo-outcome is regressed on (A ,W ), leading to an estimate θˆN,
2 2 i i 2 i i 1
which is used to compute bN(W ,θˆN). The plug-in estimator for ψN is an average across i of
1 i 1
bN(W ,θˆN). By the analyses of the previous section, these plug-in estimators will have a first or-
1 i 1
derbiasofmagnitude E[ϕ(X,ηˆN)]. Asdescribedintheprevioussection,anestimateofthisbias
−
can be added back to the plug-in estimator to obtain a “de-biased” one-step estimator. In general,
while the expectation in E[ϕ(X,ηˆE)] can be estimated with an empirical average, and the param-
eters θE in ηE can be estimated with sequential regression, it remains to develop estimators for
the parameters αE in expressions (5) and (7). If M and Z are categorical, these parameters may
be estimated by plugging in probability estimates obtained using off-the-shelf machine learning
classification methods. However, if either of these variables is continuous or high-dimensional,
plug-inestimationbecomescomputationallyintractable,asitwouldrequireestimatingconditional
densities and/or integrals with respect to those densities. To avoid this problem, we instead adopt
ideas fromarecent strandofarticles onRieszlearning(Chernozhukovet al., 2022a,b).
ThefoundationalideabehindRieszlearning isthatforan arbitrary b, ifE[b(X,θ)] isacontinu-
ouslinearfunctionalofθ,thenbytheRieszrepresentationtheoremthereexistsauniquefunctionα
such thatE[b(X;θ)] = E[α(X)θ(X)] forall θ withE[θ(X)2] < . In theproofoftheproposition
∞
below we show that the parameters in (5) and (7) correspond to Riesz representers of function-
als that involve the b functions in (4) and (6). The mean squared error (MSE) loss function then
provides an approach to estimate the α parameter directly, avoiding estimation of densities and
integralsrequiredfortheplugin estimator. Specifically,we have
α = argminE[(α(X) α˜(X))2]
α˜ −
= argminE[α(X)2 2α˜(X)α(X)+α˜(X)2]
α˜ −
= argminE[α˜(X)2 2α˜(X)α(X)]
α˜ −
= argminE[α˜(X)2 2b(X,α˜)],
α˜ −
where the third equality follows by ignoring the constant E[α2(X)] in the minimization problem,
andthelastonefromtheRieszrepresentationtheorem. Thus,estimationmayproceedbycarrying
out the minimization problem above within a given class of functions α˜ (e.g., neural networks,
regression trees, etc.). It is straightforward to verify that for bN and bR defined in (4) and (6), the
1 1
corresponding functions satisfying the Riesz representation theorem are αN and αR given in (5)
1 1
and(7). However,extracalculationsarenecessarytoderiveappropriatelossfunctionsfortheother
α parameters. We summarizetheresult ofthosecalculationsinthefollowingproposition.
Proposition2. TheMSE lossfunctionsfor(αN,αN,αN) maybeexpressed as
1 2 3
αN
=
argminE[α(A,W)2 2bN
(W,α)],
1 1
α −
αN = argminE α(A,Z,W)2 2αN (A,W)bN (Z,W,α) , (8)
2 1 2
α { − }
αN = argminE α(A,Z,M,W)2 2αN (A,Z,W)bN (Z,M,W,α) ,
3 2 3
α { − }
10andtheMSE lossfunctionsfor(αR,αR,αR,αR)maybeexpressed as
1 2 3 4
αR
=
argminE[α(A,W)2 2bR
(W,α)],
1 1
α −
αR = argminE α(A,Z,W)2 2αR (A,W)bR (Z,W,α) ,
2 1 2
α { − }
(9)
αR = argminE α(A,M,W)2 2αR (A,Z,W)bR (M,W;α) ,
3 2 3
α −
αR = argminE(cid:8)α(A,Z,M,W)2 2αR (A,M,W)bR (Zπ ,M(cid:9),W;α) .
4 3 4
α −
(cid:8) (cid:9)
EstimatesofαN andαRmaythenbeconstructedbysequentiallysolvingtheaboveoptimization
j k
problems in a given class of estimators α. For practical reasons, our simulations and illustrative
studywillfocusondeeplearningsinceitisoneofthefewmachinelearningregressionprocedures
withoff-the-shelfsoftwarethat allowsspecification ofcustomlossfunctions. Thedevelopmentof
optimizationmethodsforother functionclasses (e.g., ensembles ofregressiontrees) is thesubject
offuturework.
4.1 Cross-fitting
Theanalysisoftheasymptoticproperties oftheestimatorsin§4.2 belowcan beprovedusingcer-
tain results for empirical process under a Donsker assumption roughly stating that the estimated
parameters ηˆN and ηˆR are in function classes of bounded entropy. To avoid imposing that as-
sumption, which may not hold for some of the more flexible machine learning approaches, we
use use cross-fitting (Klaassen, 1987; Zhengand vanderLaan, 2011; Chernozhukovet al., 2016)
whenconstructingtheestimatorsηˆN andηˆR. Let ,..., denotearandompartitionoftheindex
1 J
V V
set 1,...,n into J prediction sets of approximately the same size. That is, 1,...,n ;
j
{ } V ⊂ { }
J = 1,...,n ; and ′ = . In addition, for each j, the associated training sample
j=1Vj { } Vj ∩ Vj ∅
is given by = 1,...,n . Let ηˆN and ηˆR denote the parameter estimates using training
S Tj { } \ Vj j j
data . Letting j(i) denote the index of the prediction set which contains observation i, cross-
j
T
fitting entails using only observations in for fitting models when making predictions about
j(i)
T
observationi. Thefinal cross-fitted estimatorsofψN and ψR arecomputedas:
n n
1 1
ψˆN = ϕ¯N(X ,ηˆN ), and ψˆR = ϕ¯R(X ,ηˆR ), (10)
n i j(i) n i j(i)
i=1 i=1
X X
respectively.
4.2 Consistency and asymptotic sampling distribution
We will first state the main result of this section, which describes the asymptotic behavior of the
estimatorsunder assumptionson theconsistencyof thenuisance estimatorsηˆN and ηˆR and on the
bounds of the parameters αN and αR and their estimators. The main buildingblocks to provethis
j j
theorem are the von Mises expansion given in Theorem 1, as well as tail inequalities applied to
the corresponding cross-fitted empirical processes (see Kennedy, 2022, for a review of the main
techniques). First,weintroducethefollowingassumption,whichisakintotheoverlaporpositivity
assumptioninvokedforestimationoftheaverage treatmenteffect.
11A1 (Bounded Riesz representers). For E N,R , assume the estimated functions αˆE are
j
∈ { }
boundedinthesensethatthereexistsaconstantM < suchthatP(αˆE(X) M) = P(αE(X)
j j
∞ ≤ ≤
M) = 1,
The statement of the results in this section will benefit from explicitly describing the form of
thesecondorderterminthevonMisesexpansion. Tothatend,foreachestimatorθˆN ,wedefine
k,j(i)
thefollowingparameters:
θ˜N
(a,z,w) =
E[bN (Z,M,W;θˆN
) A= a,Z = z,W = w];
2,j(i) 3 3,j(i)
|
θ˜N
(a,w) =
E[bN (Z,W;θˆN
) A =a,W = w],
1,j(i) 2 2,j(i)
|
where we note that the expectations are taken with respect to the distribution of (W,Z,M) with
theestimatorsθˆN and θˆN fixed. Define
3,j(i) 2,j(i)
3
RN (ηˆN ,ηN ) = E αˆN (X) αN (X) θˆN (X) θ˜N (X) ,
2 j(i) k,j(i) k k,j(i) k
{ − }{ − }
k=1
X (cid:2) (cid:3)
4
RR (ηˆR ,ηR ) = E αˆR (X) αR (X) θˆR (X) θ˜R (X) ,
2 j(i) k,j(i) k k,j(i) k
{ − }{ − }
k=1
X (cid:2) (cid:3)
with θ˜R defined analogously, θ˜N = θN, and θ˜R = θR. We will use the following assump-
k,j(i) 3,j(i) 3 4,j(i) 4
tion.
A2 (Rate of convergence of second-order term). For E N,R , assume RE(ηˆE ,ηE) =
2 j(i)
∈ { }
o
(n−1/2).
P
Thefollowingtheoremis themainresult ofthissection.
Theorem 2 (Asymptoticlinearityand weak convergence). AssumeA1. Then wehave
n
1
ψˆE ψE = ϕE(X ;ηE)+RE(ηˆE ,ηE) +o (n−1/2).
− n { i 2 j(i) } P
i=1
X
UndertheadditionalassumptionA2,thecentrallimittheoremyields√n(ψˆE ψE) N(0,σ2,E),
−
where σ2,E = Var ϕE(X;ηE) is the non parametric efficiency bound in a model with observed
{ }
data(W,A,Z,Zπ,M,Y).
The above theorem has two important implications. First, it allows us to obtain estimates of
the uncertainty around the estimates in the form of confidence intervals and standard errors. For
instance, an estimateσˆ2,E may becomputedas theempiricalvarianceofϕE(X ;ηˆE ), and a (1
i j(i)
−
α)100%Wald-typeconfidenceintervalmaybecomputedasψˆE z (σˆ2,E/n)−1/2. Likewise,
1−α/2
± ×
this theorem provides the basis to use the Delta method to understand the asymptotic distribution
of the mediational parameters defined in Proposition 1, as well as other important contrasts such
as theproportionmediatedortheproportionoftheeffect operatingthroughaspecificpath.
The above theorem requires that all the nuisance parameters in ηE are estimated consistently
at the right rates in order to achieve √n-consistency and asymptotic normality of ψˆE. A weaker
result,statingmerelytheassumptionsrequiredforconsistencyoftheestimator,ispresentedinthe
followingcorollary.
12Corollary 2 (Double robustness). For a function f, let f 2 = f2(x)dP(x). For E N,R
|| || ∈ { }
and each k 1,2,3,4 , assume either θˆE θ˜E = o (1) or αˆE αE = o (1). Then
∈ { } || k,j(i) − k || P R || k,j(i) − k || P
we haveψˆE = ψE +o (1).
P
TheabovecorollaryisaconsequenceofTheorem2andtheCauchy-Schwarzinequalityapplied
to thedefinitionofRE. An importantconsequenceis thattheestimatorsare consistentif,foreach
2
of the terms involved in the canonical gradients in Theorem 1, either the Riesz representer or the
outcome regressions are estimated consistently. It is important to note that the results of this sec-
tion are given in terms of assumptions that require consistency of θˆE as an estimator of θ˜E, i.e.,
k k
only the latest expectation in the sequential regression procedure is required to be estimated con-
sistently. This has connections to results in the literature for estimation of effects in longitudinal
data models (Luedtkeetal., 2017; Rotnitzkyetal., 2017), where it is shown that certain one-step
estimators cannot achieve sequential double robustness as in Corollary 2 above. The reason our
estimators allow for sequential double robustness is that, in contrast to Luedtkeet al. (2017) and
Rotnitzkyet al. (2017), we estimatetheRieszrepresenter directlyinsteadofusingplug-inestima-
tors. Ontheotherhand,accordingtoProposition2ourapproachtoestimatetheRieszrepresenters
issequential,so thatconsistentestimationofαE requires consistentestimationofαE .
k k−1
4.3 Practical construction of Zπ
RecallthatourestimatorsassumedtheexistenceofavariableZπ suchthat(1)holds. Tointroduce
our main approach to construct this variable, consider a hypothetical case in which (A,W) are
discrete. Then,itcanbeseenthatasimplepermutationofZ withinstrataof(A,W)wouldsatisfy
(1). ToconstructZπ inthegeneralcase,wewillconductapermutationoftheoriginalZ variableas
follows. DefineZ = (Z ,...,Z )tobeann pmatrix,anddefineZπ,A,andWaccordingly. For
1 n
×
twomatricesCandDofsizesn p andn p ,respectively,welet(C,D)denoteacolumn-wise
1 2
× ×
concatenation of size n (p + p ). The permutation Zπ is obtained by applying a permutation
1 2
×
matrix, denoted with Π, to the original data Z, i.e., we define Zπ = ΠZ. To ensure that Zπ
and Z have the same distribution conditional on (A,W), ideally we would choose a permutation
matrix such that (A,W) = Π(A,W). With continuous data (A,W), it will be impractical to
find such a permutation matrix. Thus, we focus on finding a permutation matrix that minimizes
a suitably defined distance between (A,W) and Π(A,W), so that (A,W) Π(A,W). To
≃
compute this matrix Π, we follow the approach presented in Doran et al. (2014). This approach
reliesonadistancefunctiondandamatrixD with(i,j)-thelementD = d((A ,W ),(A ,W )).
i,j i i j i
Specifically, wesolve
min d (A ,W ),(Π(A,W)) = min Π D = minTr(ΠD),
i i i ij ij
Π∈P { } Π∈P Π∈P
i i,j
X X
where is the collection of doubly stochastic matrices (matrices whose rows and columns both
P
sum to one) with zero trace, which are linear constraints of this optimization problem. The zero-
traceconditionisenforced tomakesurethatΠwillneverbeanidentitymatrix. Notethat thefirst
equality holds because Π = 1 if and only if (A ,W ) is permuted to (A ,W ). We solve this
i,j i i j j
optimizationproblemusingthesimplexalgorithm(Gillet al., 1991).
135 Extension to non-binary treatments using modified treatment
policies
The developments in the previous sections assumed that the exposure variable A is binary, and
that interest lies in decomposing the average treatment effect, defined as a contrast between out-
come expectations in a hypothetical world where P(A = 1) = 1 vs. a hypothetical world where
P(A = 0) = 1. In this section we focus on an extension of the methods to problems where
the exposure is non-binary, and where the focus is on decomposing effects other than the average
treatmenteffect. In particular, wefocus on themethodologyofmodified treatmentpolicies(MTP,
D´ıazand vanderLaan, 2012; Haneuseand Rotnitzky, 2013; D´ıazet al., 2023). Let d (a,w) and
1
d (a,w) denote two functions that map a treatment value a amd a covariate value w into poten-
0
tial post-intervention treatment values. Causal effects of modified treatment policies are defined
as contrasts E[Y(d ) Y(d )], where Y(d) denotes the counterfactual outcome that would have
1 0
−
been observed in a hypothetical world where treatment had been assigned according to d(A,W),
where we note that the MTP definition recovers the average treatment effect of a binary exposure
by setting d = 1 and d = 0. Modified treatment policies allow the user to define interesting
1 0
causal contrastsforcontinuousormultivariateexposuresby careful considerationofthefunctions
d being contrasted. For instance, a researcher interested in the effect of an increase of 10% in a
continuousexposuremightconsidersetting
1.1 a if1.1 a < u(w)
d (a,w) = × ×
1
(a otherwise,
and d (A,W) = A, where u(w) is largest feasible value of A within strata W = w. For a com-
0
plete discussion on the flexibility of the MTP framework and other interesting policy definitions
we refer the reader to the original articles as well as the reviews by Hoffmanet al. (2023) and
Williamsand D´ıaz(2023).
MediationanalysisleveragingmodifiedtreatmentpolicieswasrecentlydiscussedbyGilbertet al.
(2024). In that work, the authors develop estimators for general longitudinal settings, but the es-
timation methods are restricted to categorical mediators. Furthermore, because the methods are
developed within the randomized interventional framework, they are subject to the critique that
theydonotmeasuremechanismsinspecialsettings,asdiscussedbyMiles(2023). InAppendixA
we present a generalization of the recanting twin effects of D´ıaz (2024) and Vo et al. (2024) to
decompose the effect of modified treatment policies as defined above. Although the details of the
definition and identification of our generalization are important, we relegate their discussion to
the appendix so that we can focus on a discussion of the main point of our paper, which is the
developmentofgeneral estimationtechniques.
Because the definitions and results of this section generalize those of prior sections, in a slight
abuseofnotationwewillusethesamesymbolstodenotetheobjectsthatwillbegeneralized. This
will allow us to avoid re-stating theorems and results that hold true with the updated definitions
presented inthissection. Forvalues(i,j,k,l) 0,1 4, wedefineAs = d (A,W),and let
s
∈ { }
ψR(i,j,k,l)=E E E E E(Y A=Ai,Zπ,M,W) A=Aj,M,W A=Ak,Z,W A=Al,W ,
ψN(j,k,l)=E" E(cid:20) Eh E((cid:2) Y A| =Aj,Z,M,W) A(cid:12) (cid:12) =Ak,Z,W A(cid:3) =(cid:12) (cid:12) (cid:12) Al,W . i(cid:12) (cid:12) (cid:12) (cid:12) (cid:21)# (11)
|
(cid:20) h (cid:2) (cid:12) (cid:12) (cid:3)(cid:12) (cid:12) (cid:12) i(cid:21)
14Similar to Proposition 1, we have the following result establishing the generality of the above
parameters ψN and ψR.
Proposition3 (Identificationof parameters for mediationusingmodified treatment policies). The
identification formulas for the causal parameters defined by Gilbertetal. (2024) under a single
time-pointcan bewrittenin termsof ψN andψR as:
RIDE=ψR(1,1,0,0) ψR(0,0,0,0), RIIE=ψR(1,1,1,1) ψR(1,1,0,0),
− −
and theidentificationformulasfor thepath-specificrecanting twin effects defined in Theorem 3 of
AppendixA can bewrittenas
RT1 =ψN(1,1,1) ψN(0,1,1), RT2 =ψR(0,1,1,1) ψR(0,0,1,1),
− −
RT3 =ψR(0,0,1,1) ψR(0,0,1,0), RT4 =ψN(0,1,0) ψN(0,0,0).
− −
Likewise,theformulaforthevonMisesexpansionofmediationalparametersbasedonmodified
treatmentpoliciesisidentical tothatofmediationalfortheaverage treatmentgivenin Theorem1,
withthefollowingupdateddefinitionsofαE andθE. ForψN, define
k k
θ3N(a,z,m,w)=E(Y A=a,Z =z,M =m,W =w), bN 3 (a,z,m,w;θ3N)=θ3N(d j(a,w),z,m,w),
|
θ2N(a,z,w)=E[bN 3 (A,Z,M,W;θ3N) A=a,Z =z,W =w], bN 2 (a,z,w;θ2N)=θ2N(d k(a,w),z,w),
|
θ1N(a,w)=E[bN 2 (A,Z,W;θ2N) A=a,W =w], bN 1 (a,w;θ1N)=θ1N(d l(a,w),w),
|
(12)
as wellas
P (a w)
αN 1 (a,w)= Pd (l
a
|
w)
,
|
P (a w)P(z A=d (a,w),w)
αN 2 (a,z,w)= Pd k (a | w) | P(z al ,w) , (13)
| |
αN 3 (a,z,m,w)= P Pd (j a(a | ww ))P(m | PA (m=d ak ,(a z, ,w w) ),z,w)P(z |A P(=
z
d al( ,a w, )w),w) .
| | |
ForψR, define
θ4R(a,z,m,w)=E(Y A=a,Z =z,M =m,W =w), bR 4(a,z,m,w;θ4R)=θ4R(d i(a,w),z,m,w),
|
θ3R(a,m,w)=E[bR 4(A,Zπ,M,W;θ4R) A=a,M =m,W =w], bR 3(a,m,w;θ3R)=θ3R(d j(a,w),m,w),
|
θ2R(a,z,w)=E[bR 3(A,M,W;θ3R) A=a,Z =z,W =w], bR 2(a,z,w;θ2R)=θ2R(d k(a,w),z,w),
|
θ1R(a,w)=E[bR 2(A,Z,W;θ2R) A=a,W =w], bR 1(a,w;θ1R)=θ1R(d l(a,w),w),
|
(14)
as wellas
P (a w)
αR 1(a,w)= Pd (l
a
|
w)
;
|
P (a w)P(z A=d(a,w),w)
αR 2(a,z,w)= Pd k
(a
|
w)
|
P(z
al
,w)
;
| | (15)
P (a w) P(m A=d (a,w),z,w)dP(z A=d (a,w),w)
αR 3(a,m,w)= Pd (j
a
|
w)
z | k
P(m a,w)
| l ;
| R |
P (a w)P(z A=d (a,w),w) P(m A=d (a,w),z,w)dP(z A=d (a,w),w)
αR 4(a,z,m,w)= Pd (i
a
|
w)
|
P(z
aj
,w)
z | k
P(m a,z,w)
| l .
| | R |
With these generalized definitions of the nuisance parameters, Proposition 2 may be used to esti-
mate the Riesz representers, expression (10) provides a generalized formula for constructing the
estimators,and Theorem 2 providesthebasisforconstructingconfidence intervalsandhypothesis
tests.
156 Numerical studies
We conduct a Monte Carlo simulationstudy to illustratethe performance of our proposed estima-
tionalgorithm. Weevaluatetheestimatorswiththedatageneratedbythefollowingdatagenerating
process (DGP):
⊤
W =(W1,W2,W3) Be(2,3)
∼ −1
AW Bern(logit (0.5W1+0.5W2 1))
| ∼ 2−
Z1 A,W TN( 1,1, 0.4+ǫA+0.2W3,1)
| ∼ − −
Z2 Z1,A,W TN( 1,1,0.2 ǫA+0.5sin(W2),1)
| ∼ − −
M1 Z1,Z2,A,W TN( 1,1, 0.5+λ1Z1+λ2A+0.4W2+0.2W3,1)
| ∼ − −
M2 M1,Z1,Z2,A,W TN( 1,1, 0.5+λ1Z2+λ2A+0.4W1+0.2W3,1)
| ∼ − −
Y M1,M2,Z1,Z2,A,W N(0.2M1+0.2M2+γ1Z1/2+γ1Z2/2+γ2A 0.5cos(W1) 1.5,1).
| ∼ − −
⊤ ⊤
Here, (ǫ,λ ,λ ,γ ,γ ) = (0.5,0.4,0.6,0.6,0.4) are pre-specified parameters; Be(α,β) de-
1 2 1 2
notes a Beta distribution with shape parameters α and β; Bern(π) denotes a Bernoulli distribu-
tion with probability π; N(µ,σ2) denotes a normal distribution with mean µ and variance σ2;
TN(a,b,µ,σ2) denotes a truncated normal distributionderived from N(µ,σ2), but with values in
[a,b].
We evaluate estimators of the natural direct and indirect effects (NDE/NIE), interventional ef-
fects(IDE/IIE),andrecanting-twinseffects. Wenotethat,inadditiontothe4path-specificeffects,
the methodology based on recanting twins also provides a fifth parameter, which quantifies the
amount of intermediate confounding by Z, and can therefore be used to test the null hypothesis
thattheestimatescanbeinterpretedasnaturalpath-specificeffects(seeVo etal.,2024). Thus,our
simulationhasatotalofnineparametersofinterest. Fornaturaleffects,weletǫ = λ = 0tomake
1
theeffectsidentifiable. Bias,√n-bias,nMSEandcoverageofthe95%confidenceintervalofthese
parameters are usedforourevaluation.
For estimating the Riesz representers α we use deep learning (LeCun et al., 2015) using the
loss functions in (8) and (9). For the sequential regression function θ, we use an ensemble of
LightGBM(Keet al.,2017),meanfunction,MultivariateAdaptiveRegressionSplines(Friedman,
1991)andneural networks,basedontheSuperLearneralgorithm(van derLaan et al., 2007). The
simulation study is conducted by drawing 500 datasets of sizes n 500,1000,2000 . The R
∈ { }
code for implementation is publicly available on Github. We note that this simulation setup is
representative of typical practice in statistics, and that we have no reason to expect that both the
Riesz representers and the sequential regressions estimators to not be consistent. Therefore, the
propertiesofTheorem 2are notexpected toholdexactly.
Table2showsthesummaryoftheresults. Weobservethatinmostcases,theempiricalcoverage
is close to the nominal value of 95%. Although the √n-bias does not decrease as n increases, the
nMSE decreases consistently across all causal parameters. This observation illustrates that the
estimators may be appropriately trading off bias and variance. We also note that the coverage
for the effect through the path A Z Y seems to be decreasing as sample size increases,
→ →
possiblyduetotheviolationoftheassumptionsunderlyingthetheoremsthatestablishasymptotic
normality.
16Table2: Simulationresultsfor ourmethod.
recantingtwins interventional natural
n metrics AY AZY AZMY AMY Int. Confounder IDE IIE NDE NIE
Bias 0.016 -0.014 -0.020 0.004 -0.003 -0.005 0.005 0.000 -0.005
√n-Bias 0.386 -0.302 -0.439 0.092 -0.058 -0.102 0.115 0.000 -0.121
500
nMSE 9.009 15.79 3.500 4.917 9.948 5.135 11.53 7.189 3.143
Coverage 0.942 0.940 0.952 0.950 0.960 0.942 0.960 0.954 0.940
Bias 0.023 -0.033 -0.015 0.000 0.003 -0.005 0.002 0.005 -0.004
√n-Bias 0.725 -1.032 -0.464 -0.002 0.103 -0.158 0.052 0.166 -0.128
1000
nMSE 8.961 10.82 2.333 3.270 5.722 4.416 10.03 5.996 1.306
Coverage 0.932 0.930 0.942 0.946 0.970 0.950 0.948 0.962 0.942
Bias 0.021 -0.026 -0.014 -0.002 0.005 0.000 0.000 0.003 0.000
√n-Bias 0.951 -1.155 -0.628 -0.077 0.240 0.014 0.016 0.142 0.007
2000
nMSE 7.709 4.760 1.513 2.276 4.670 3.597 10.123 5.972 1.029
Coverage 0.948 0.888 0.934 0.958 0.964 0.936 0.940 0.956 0.966
7 Illustrative Examples
We applied our proposed estimator in an effort to understand the extent to which pain manage-
ment practices mediate the total effect of having a chronic pain disorder on opioid use disorder
(OUD) risk by the end of 24 months of follow up among adult Medicaid beneficiaries. In this
example,theexposureof interestAis presence ofachronicpain condition(N=67,438)versusthe
absenceof achronicpain conditionorphysicaldisability(N=1,704,454)during thefirst 6 months
of Medicaid enrollment. We considered a bundle of 11 pain management practices M, all mea-
sured during the subsequent 6 months: i) opioid dose, ii) proportion of days covered by an opioid
prescription, iii) number of unique opioid prescribers, iv) presence of opioid dose tapering, v)
opioid-benzodiazepine coprescribing, vi) opioid-gabapentinoid coprescribing, vii) opioid-muscle
relaxant coprescribing, viii) opioid-stimulantcoprescribing, ix) presence of a nonopioid pain pre-
scription, x) physical therapy, and xi) presence of a pain treatment claim not captured in the pre-
vious mediators. The outcome was new-episode(i.e., incident)opioid use disorder diagnosis. We
controlled for baseline covariates related the patient’s demographics (age, sex, race/ethnicity, pri-
mary language, married or partnered, household size, veteran status, and receipt of various public
benefits)andmentalhealthdiagnoses(bipolar,depression,anxiety,attentiondeficientdisorder,and
otherpsychiatriccondition),andpost-exposureconfoundersZ ofanewdiagnosisofdepressionor
anxietyandmentalhealthcounseling. Informationonthedataand particularcohortofindividuals
weconsiderhasbeen publishedpreviously(Rudolphet al.,2024b).
We estimate (an average treatment effect) that having a chronic pain condition increases risk
of OUD over 18 months of follow-up by 0.0131 (95% CI: 0.0108, 0.0155). This is similar to
the risk difference estimated previously (Hoffmanet al., 2024). Using the proposed estimator to
estimate the recanting-twins effects (Table 3), we see that the indirect effect path A M Y
→ →
is responsiblefor nearly all of the total effect (80%), contributing0.0106 to the average treatment
effect(95%CI: 0.0082,0.0131). Theotherpotentialindirecteffect pathA Z M Y hasa
→ → →
pointestimateofzero, indicatingthatit does notcontributeto theindirect effect. Thedirect effect
path-specific estimates are very small, contributinglittleto the total effect. The parameter labeled
17“Intermediateconfounding”inthetableisdiscussedinVo et al.(2024);itisaparameterthatallows
us to test the hypothesis of no-intermediate confounding. If this parameter is not significantly
different from zero, we can reject the hypothesisof intermediateconfoundingby Z, and therefore
potentially interpret the estimates as natural path-specific effects (Avinet al., 2005). We estimate
this parameter to be statistically significant: 0.0019 (95% CI: 0.0016, 0.0021). This provides
empirical support for the influence of intermediateconfounders and highlightsthat natural effects
wouldnotbeidentifiable.
For contrast, we also estimate randomized interventional effects in Table 3. The interventional
total effect of 0.0232 is much larger than the ATE. This confirms that intermediate confounding
cannot be ignored and provides additional evidence of the perils of randomized interventional
effects for addressing intermediate confounding (Miles, 2023). The IIE contributes to 68% of the
randomized total effect, which is similar percentage as estimated for the recanting-twins effects,
buttheIDEismuchlargerthanthesumofthepath-specificrecantingtwineffectsthroughA Z
→
andA Z Y,whichhighlightsdrawbacksoftheIIE/IDEthatarewell-knownintheliterature.
→ →
Furthermore, the recanting twin effects provide specific information about the path involved in
the effect through M, specifiying that all the effect goes through A M Y rather than
→ →
A Z M Y. Therandomizedinterventionaleffectsdonotprovideanyinformationofthis
→ → →
type,instead consideringbothpathways asa bundle.
Table3: Illustrativeapplicationresults.
Estimate 95%CI
Recantingtwins
A Y -3e-04 (-5e-04,0)
→
A Z Y 9e-04 (7e-04,0.001)
→ →
A Z M Y 0 (-1e-04,1e-04)
→ → →
A M Y 0.0106 (0.0082,0.0131)
→ →
Intermediateconfounding 0.0019 (0.0016,0.0021)
Interventional
RIDE 0.0072 (0.0047,0.0096)
RIIE 0.0155 (0.0151,0.0076)
Acknowledgements
Iva´nD´ıazandKaraRudolphweresupportedthroughaPatient-CenteredOutcomesResearchInsti-
tute (PCORI) Project Program Funding Award (ME-2021C2-23636-IC) and through the National
Instituteon Drug Abuse(R01DA053243).
References
Chen Avin, Ilya Shpitser, and Judea Pearl. Identifiability of path-specific effects. In IJCAI Inter-
nationalJointConference onArtificialIntelligence, pages357–363,2005.
18David Benkeser and Jialu Ran. Nonparametric inference for interventional effects with multiple
mediators. JournalofCausalInference, 9(1):172–189,2021.
Peter J Bickel, Chris AJ Klaassen, YA’Acov Ritov, and Jon A Wellner. Efficient and Adaptive
EstimationforSemiparametricModels. Springer-Verlag, 1997.
Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, et al.
Doublemachinelearningfortreatmentandcausalparameters. arXivpreprintarXiv:1608.00060,
2016.
Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whit-
ney Newey, and James Robins. Double/debiased machine learning for treatment and structural
parameters. The EconometricsJournal,21(1):C1–C68,2018.
Victor Chernozhukov, Whitney Newey, V´ıctor M Quintas-Mart´ınez, and Vasilis Syrgkanis.
RieszNet and ForestRiesz: Automatic debiased machine learning with neural nets and random
forests. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and
Sivan Sabato, editors, Proceedings of the 39th International Conference on Machine Learning,
volume 162 of Proceedings of Machine Learning Research, pages 3901–3914. PMLR, 17–23
Jul2022a. URL https://proceedings.mlr.press/v162/chernozhukov22a.html.
Victor Chernozhukov, Whitney K Newey, and Rahul Singh. Debiased machine learning of
global and local parameters using regularized Riesz representers. The Econometrics Jour-
nal, 25(3):576–601, 04 2022b. ISSN 1368-4221. doi: 10.1093/ectj/utac002. URL
https://doi.org/10.1093/ectj/utac002.
PhilipDawid. Decision-theoreticfoundationsforstatisticalcausality. JournalofCausalInference,
9(1):39–77,2021.
Iva´n D´ıaz. Non-agency interventions for causal mediation in the presence of intermediate con-
founding. Journal of the Royal Statistical Society Series B: Statistical Methodology, 86(2):
435–460,2024.
Iva´n D´ıaz and Nima S Hejazi. Causal mediation analysis for stochastic interventions. Journal of
theRoyal StatisticalSocietySeriesB:StatisticalMethodology,82(3):661–683,2020.
Iva´n D´ıaz and Mark J van der Laan. Population intervention causal effects based on stochastic
interventions. Biometrics,68(2):541–549,2012.
Iva´n D´ıaz, Nima S Hejazi, Kara E Rudolph, and Mark J van Der Laan. Nonparametric efficient
causalmediationwithintermediateconfounders. Biometrika,108(3):627–641,2021a.
Iva´n D´ıaz, Nicholas Williams, Katherine L Hoffman, and Edward J Schenck. Nonparametric
causal effects based on longitudinal modified treatment policies. Journal of the American Sta-
tisticalAssociation,pages 1–16,2021b.
Iva´n D´ıaz, Katherine L Hoffman, and Nima S Hejazi. Causal survival analysis under competing
risksusinglongitudinalmodifiedtreatmentpolicies. arXivpreprintarXiv:2202.03513,2022.
19Iva´n D´ıaz, Nicholas Williams, and Kara E Rudolph. Efficient and flexible mediation analysis
with time-varying mediators, treatments, and confounders. Journal of Causal Inference, 11(1):
20220077,2023.
VanessaDidelez. Defining causal mediationwith alongitudinalmediatorand asurvivaloutcome.
Lifetimedataanalysis,25:593–610,2019.
Vanessa Didelez, A Philip Dawid, and Sara Geneletti. Direct and indirect effects of sequential
treatments. In Proceedings of the Twenty-Second Conference on Uncertaintyin Artificial Intel-
ligence,pages 138–146.AUAIPress, 2006.
Gary Doran, Krikamol Muandet, Kun Zhang, and Bernhard Scho¨lkopf. A permutation-based ker-
nelconditionalindependencetest. In UAI, pages 132–141,2014.
Iva´n D´ıaz, Nicholas Williams, Katherine L. Hoffman, and Edward J. Schenck. Nonparametric
causal effects based on longitudinal modified treatment policies. Journal of the American Sta-
tistical Association, 118(542):846–857, 2023. doi: 10.1080/01621459.2021.1955691. URL
https://doi.org/10.1080/01621459.2021.1955691.
L T Fernholz. von misescalculusforstatisticalfunctionals. Lecture Notesin Statistics,19, 1983.
JeromeHFriedman. Multivariateadaptiveregressionsplines. Theannalsofstatistics,pages1–67,
1991.
Sara Geneletti. Identifyingdirect and indirect effects in a non-counterfactual framework. Journal
oftheRoyalStatisticalSocietySeriesB:StatisticalMethodology,69(2):199–215,2007.
Brian Gilbert, Katherine L Hoffman, Nicholas Williams, Kara E Rudolph, Edward J Schenck,
and Iva´n D´ıaz. Identification and estimation of mediational effects of longitudinal modified
treatmentpolicies. arXivpreprintarXiv:2403.09928,2024.
PE Gill, W Murray, and Margaret Wright. Numerical linear algebra and optimization,volume 1.
Addison-Wesley,1991.
SebastianHaneuseandAndreaRotnitzky. Estimationoftheeffectofinterventionsthatmodifythe
receivedtreatment. StatisticsinMedicine, 2013.
Nima S Hejazi, Kara E Rudolph, Mark J Van Der Laan, and Iva´n D´ıaz. Nonparametric causal
mediationanalysisforstochasticinterventional(in)directeffects. Biostatistics,24(3):686–707,
2023.
KatherineL Hoffman, DiegoSalazar-Barreto, Kara E Rudolph, and Iva´n D´ıaz. Introducinglongi-
tudinalmodifiedtreatmentpolicies: aunifiedframeworkforstudyingcomplexexposures. arXiv
preprintarXiv:2304.09460,2023.
Katherine L Hoffman, Floriana Milazzo, Nicholas T Williams, Hillary Samples, Mark Olfson,
Ivan Diaz, Lisa Doan, Magdalena Cerda, Stephen Crystal, and Kara E Rudolph. Independent
andjointcontributionsofphysicaldisabilityandchronicpaintoincidentopioidusedisorderand
opioidoverdoseamongmedicaidpatients. Psychologicalmedicine, 54(7):1419–1430,2024.
20Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-
Yan Liu. Lightgbm: A highly efficient gradient boosting decision tree. Advances in neural
informationprocessingsystems,30, 2017.
Edward H Kennedy. Semiparametric doubly robust targeted double machine learning: a review.
arXivpreprintarXiv:2203.06469,2022.
ChrisAJKlaassen. Consistentestimationoftheinfluencefunctionoflocallyasymptoticallylinear
estimators. TheAnnalsofStatistics,15(4):1548–1562,1987.
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature, 521(7553):436–444,
2015.
Judith J Lok. Organic direct and indirect effects with post-treatment common causes of mediator
andoutcome. arXivpreprintarXiv:1510.02753,2015.
Judith J Lok. Defining and estimatingcausal direct and indirect effects when setting the mediator
tospecificvaluesis notfeasible. Statisticsin medicine,35(22):4008–4020,2016.
JudithJ Lok. Causal organicdirect and indirecteffects: closerto baron and kenny. arXivpreprint
arXiv:1903.04697,2019.
JudithJ LokandRonaldJ Bosch. Causal organicindirectanddirect effects: Closertotheoriginal
approach to mediation analysis, with a product method for binary mediators. Epidemiology,32
(3):412–420,2021.
AlexanderRLuedtke,OlegSofrygin,MarkJvanderLaan,andMarcoCarone. Sequentialdouble
robustnessinright-censored longitudinalmodels. arXivpreprintarXiv:1705.02459,2017.
Caleb HMiles. Onthecausalinterpretationofrandomisedinterventionalindirecteffects. Journal
oftheRoyalStatisticalSocietySeriesB:StatisticalMethodology,85(4):1154–1172,2023.
Judea Pearl. Direct and indirect effects. Probabilisticand Causal Inference: The Works of Judea
Pearl,page373,2001.
Judea Pearl. An introduction to causal inference. The international journal of biostatistics, 6(2),
2010.
J Pfanzagl and W Wefelmeyer. Contributions to a general asymptoticstatistical theory. Statistics
&RiskModeling,3(3-4):379–388,1985.
James Robins, Lingling Li, Eric Tchetgen Tchetgen, and Aad W van der Vaart. Quadratic semi-
parametricVon Misescalculus. Metrika,69(2-3):227–247,2009.
James M Robins. Semantics of causal dag models and the identification of direct and indirect
effects. Highlystructuredstochasticsystems,pages 70–82,2003.
James M Robins and Sander Greenland. Identifiabilityand exchangeabilityfor direct and indirect
effects. Epidemiology,3(0):143–155,1992.
21James M Robins and Thomas S Richardson. Alternativegraphical causal models and theidentifi-
cation of direct effects. Causality and psychopathology: Finding the determinants of disorders
andtheircures, pages 103–158,2010.
James M Robins, Thomas S Richardson, and IlyaShpitser. An interventionistapproach to media-
tionanalysis. InProbabilisticandCausalInference: TheWorksofJudeaPearl,pages713–764.
2022.
AndreaRotnitzky,JamesRobins,andLuciaBabino. Onthemultiplyrobustestimationofthemean
oftheg-functional. arXivpreprintarXiv:1705.08582,2017.
Kara E Rudolph, Nicholas Williams, and Iva´n D´ıaz. Efficient and flexible estimation of natural
direct and indirect effects under intermediate confounding and monotonicity constraints. Bio-
metrics,79(4):3126–3139,2023.
Kara E Rudolph, Nicholas T Williams, and Ivan Diaz. Practical causal mediation analysis: ex-
tendingnonparametricestimatorstoaccommodatemultiplemediatorsandmultipleintermediate
confounders. Biostatistics,pagekxae012,2024a.
Kara E Rudolph, Nicholas T Williams, Ivan Diaz, Sarah Forrest, Katherine L Hoffman, Hillary
Samples, Mark Olfson, Lisa Doan, Magdalena Cerda, and Rachael K Ross. Pain management
treatments and opioid use disorder risk in medicaid patients. American Journal of Preventive
Medicine,2024b.
Numair Sani, Jaron Lee, and Ilya Shpitser. Identification and estimation of causal effects defined
by shift interventions. In Conference on Uncertainty in Artificial Intelligence, pages 949–958.
PMLR, 2020.
MatsJStensrud,MiguelAHerna´n, EricJTchetgenTchetgen, JamesMRobins,VanessaDidelez,
and Jessica G Young. A generalized theory of separable effects in competing event settings.
Lifetimedataanalysis,27(4):588–631,2021.
MatsJStensrud,JessicaGYoung,VanessaDidelez,JamesMRobins,andMiguelAHerna´n. Sep-
arableeffectsforcausalinferenceinthepresenceofcompetingevents. JournaloftheAmerican
StatisticalAssociation,117(537):175–183,2022.
Eric J Tchetgen Tchetgen and Tyler J VanderWeele. Identification of natural direct effects when
a confounder of the mediator is directly affected by exposure. Epidemiology, 25(2):282–291,
2014.
Mark J van der Laan and Maya L Petersen. Direct effect models. The international journal of
biostatistics,4(1), 2008.
MarkJvanderLaanandSherriRose. TargetedLearning: CausalInferenceforObservationaland
ExperimentalData. Springer, New York,2011.
Mark J van der Laan and Sherri Rose. Targeted Learning in Data Science: Causal Inference for
ComplexlongitudinalStudies. Springer, New York,2018.
22M.J. van der Laan, E. Polley, and A. Hubbard. Super learner. StatisticalApplicationsin Genetics
&MolecularBiology,6(25):Article25,2007.
Aad van der Vaart. Lectures on probability theory and statistics. In Pierre Bernard, editor, Ecole
d’Ete´ de Probabilite´s de Saint-Flour XXIX - 1999, Lecture Notes in Mathematics, pages 143–
168.SpringerBerlin, Heidelberg,2002.
Tyler J VanderWeele and Eric J Tchetgen Tchetgen. Mediation analysis with time varying expo-
sures and mediators. Journal of the Royal StatisticalSocietySeries B: StatisticalMethodology,
79(3):917–938,2017.
Tyler J VanderWeele, Stijn Vansteelandt, and James M Robins. Effect decompositionin the pres-
enceofanexposure-inducedmediator-outcomeconfounder. Epidemiology(Cambridge,Mass.),
25(2):300,2014.
StijnVansteelandtandRhianMDaniel. Interventionaleffectsformediationanalysiswithmultiple
mediators. Epidemiology,28(2):258–265,2017.
Tat-ThangVo, NicholasWilliams,Richard Liu,Kara ERudolph,and IvanDıaz. Recantingtwins:
addressing intermediate confounding in mediation analysis. arXiv preprint arXiv:2401.04450,
2024.
R von Mises. On the asymptotic distribution of differentiable statistical functions. The annals of
mathematicalstatistics,18(3):309–348,1947.
Zeyi Wang, Lars van der Laan, Maya Petersen, Thomas Gerds, Kajsa Kvist, and Mark van der
Laan. Targetedmaximumlikelihoodbasedestimationforlongitudinalmediationanalysis. arXiv
preprintarXiv:2304.04904,2023.
NicholasWilliamsandIva´nD´ıaz. lmtp: Anrpackageforestimatingthecausaleffectsofmodified
treatmentpolicies. ObservationalStudies,9(2):103–122,2023.
Fan Xia and Kwun Chuen Gary Chan. Identification, semiparametric efficiency, and quadruply
robust estimation in mediation analysis with treatment-induced confounding. Journal of the
AmericanStatisticalAssociation,118(542):1272–1281,2023.
Wenjing Zheng and Mark van der Laan. Longitudinal mediation analysis with time-varying me-
diatorsand exposures, withapplication to survivaloutcomes. Journalof causal inference, 5(2),
2017.
Wenjing Zheng and Mark J van der Laan. Cross-validated targeted minimum-loss-based estima-
tion. In Targeted Learning,pages 459–474.Springer, 2011.
Wenjing Zheng and Mark J van der Laan. Targeted maximum likelihood estimation of natural
directeffects. Theinternationaljournalofbiostatistics,8(1):1–40,2012.
23A Generalizationof recanting twins to modified treatment poli-
cies
Let d (a,w) and d (a,w)denotetwo functionsthatmap atreatment valuea and acovariatevalue
1 0
w into potential post-interventiontreatment values. We define causal effects based on a structural
causal modeldefined as follows.
Definition 2. Let = U,X,f, be a SCM, where X = (W,A,Z,M,Y) are the endogenous
M h Pi
variables, U = (U ,U ,U ,U ,U ) P are theexogenous variables, is theset of allowed
W A Z M Y U
∼ P
distributionsP , andf = (f ,f ,f ,f ,f ) aredeterministicfunctionssuchthat:
U W A Z M Y
W = f (U ); A = f (W,U ); Z = f (W,A,U );
W W A A Z Z
M = f (W,A,Z,U ); Y = f (W,A,Z,M,U ).
M M Y Y
Causal effects ofmodifiedtreatmentpoliciesare defined as contrasts
ψ = E[Y(d ) Y(d )],
1 0
−
where Y(d) = Y(d,Z(d),M(d,Z(d))), where Y(a,z,m) = f (W,a,z,m,U ) and Z(d) and
Y Y
M(d) are defined analogously. Define the paths P : A Y; P : A Z Y; P : A Z
1 2 3
→ → → → →
M Y and P : A M Y. Path specific effects for P could be defined as expectations
4 j
→ → →
E[Y Y ]usingthefollowingcounterfactuals
S j − S j−1
Y = Y(d ,Z(d ),M(d ,Z(d ))),
S0 1 1 1 1
Y = Y(d ,Z(d ),M(d ,Z(d ))),
S1 0 1 1 1
Y = Y(d ,Z(d ),M(d ,Z(d ))),
S2 0 0 1 1
Y = Y(d ,Z(d ),M(d ,Z(d ))),
S3 0 0 1 0
Y = Y(d ,Z(d ),M(d ,Z(d ))).
S4 0 0 0 0
However, dueto therecanting twinsproblem (Avinet al., 2005), thedistributionofY is uniden-
S2
tifiable. Weinsteadproposealternativeeffects basedon thefollowingdefinition.
Definition 3 (Recanting twins). Define T(d) as a random draw from the distribution of Z(d)
conditionalonW. Ford = d , we saythatT(d ) istherecantingtwinof Z(d ) andviceversa.
1 0 1 0
6
Let
′
Y = Y(d ,Z(d ),M(d ,T(d ))),
S1 0 1 1 1
′
Y = Y(d ,Z(d ),M(d ,T(d ))),
S2 0 0 1 1
′′
Y = Y(d ,T(d ),M(d ,Z(d ))),
S2 0 0 1 1
′′
Y = Y(d ,T(d ),M(d ,Z(d ))),
S3 0 0 1 0
define new counterfactual variables where we have replaced some counterfactual variables Z(d)
by theirrecanting twins. We can nowdefinepath-specificeffects as
φ = E(Y Y ); φ = E(Y′ Y′ ); φ = E(Y′′ Y′′ ); φ = E(Y Y ).
P1 S0
−
S1 P2 S1
−
S2 P3 S2
−
S3 P4 S3
−
S4
24Wethushaveφ = φ +φ +φ +φ +φ , whereφ is defined as
P1 P2 P3 P4 P2∨P3 P2∨P3
′ ′ ′′ ′′
φ = E(Y Y +Y Y +Y Y )
P2∨P3 S1
−
S1 S2
−
S2 S3
−
S3
anditmeasurestheextentofintermediateconfoundingbyZ inthesensethatφ = 0whenever
P2∨P3
Z is not an intermediate confounder (D´ıaz, 2024). We have the following identification result.
Under model , let Y(a,m,z) = f (W,a,z,m,U ), M(a,z) = f (W,a,z,U ), and Z(a) =
Y Y M M
M
f (W,a,U ) denote counterfactual variables. We will assume the distribution of the errors P is
Z Z U
such thatthefollowingassumptionshold.
A3 (Sequentialignorability). Forall(a,m,z):
(i) Y(a,m,z) A W; Y(a,m,z) Z (A = a,W); and Y(a,m,z) M (A = a,Z =
⊥⊥ | ⊥⊥ | ⊥⊥ |
z,W)
(ii) M(a,z) A W;and M(a,z) Z (A = a,W)
⊥⊥ | ⊥⊥ |
(iii) (Z(a),M(a)) A W
⊥⊥ |
′ ′′ ′
A4 (Cross-world counterfactual independence). For all a,a,a supp(A); z,z supp(Z) and
∈ ∈
m supp(M):
∈
′ ′ ′′
(i) Y(a,m,z) (M(a,z ),Z(a )) W;
⊥⊥ |
′
(ii) M(a,z) Z(a) W.
⊥⊥ |
A sufficient conditionfor A3 and A4 to hold is that all commoncauses ofany pairof variables
among(A,M,Z,Y) aremeasured and are givenby thevariablesthatprecede theearliest variable
inthecausal orderingofthepair. Thisis formalizedin as follows:
M
A5 (Nounmeasured confounders). Assume:
(i) U (U ,U ,U ) W,
A Y M Z
⊥⊥ |
(ii) U (U ,U ) (A,W),and
Z Y M
⊥⊥ |
(iii) U U (Z,A,W).
M Y
⊥⊥ |
Theorem3(Identificationofrecantingtwineffectsunderno-separabilityofeffects). Undermodel
andassumptionsA3 andA4, wehave:
M
E(Y
S0
|A=a,W =w)=E(Y |A=d1(a,w),W =w)
E(Y
S1
|a,w)= E(Y |d0(a,w),z,m,w)dP(m,z |d1(a,w),w)
Z
E(Y S′
1
|a,w)= E(Y |d0(a,w),z,m,w)dP(m |d1(a,w),w)dP(z |d1(a,w),w)
Z
E(Y S′
2
|a,w)= E(Y |d1(a,w),z,m,w)dP(m |d1(a,w),w)dP(z |d0(a,w),w)
Z
E(Y S′′
2
|a,w)= E(Y |d1(a,w),z,m,w)dP(m |d1(a,w),w)dP(z |d0(a,w),w)
Z
E(Y S′′
3
|a,w)= E(Y |d0(a,w),z,m,W)dP(m |d1(a,w),z′ ,W)dP(z |d0(a,w),w)dP(z′ |d0(a,w),W)
Z
E(Y
S3
|a,w)= E(Y |d0(a,w),z,m,w)dP(m |d1(a,w),z,w)dP(z |d0(a,w),w)
Z
E(Y
S4
|a,w)=E(Y |d0(a,w),w),
fromwhichwe canconstructidentificationresultsforψ andforψ .
P
j
P2∨P3
25B Auxiliary results
Lemma 1. ForψN anda fixed value(a ,a ,a ),define
1 2 3
θN (a,z,m,w) = E(Y A =a,Z = z,M = m,W = w), bN (z,m,w;θ ) = θN (a ,z,m,w),
3 3 3 3 1
|
θN
(a,z,w) =
E[bN (Z,M,W;θN
) A= a,Z = z,W = w],
bN
(z,w;θ ) =
θN
(a ,z,w),
2 3 3 2 2 2 2
|
θN
(a,w) =
E[bN (Z,W;θN
) A = a,W = w],
bN
(w;θ ) =
θN
(a ,w),
1 2 2 1 1 1 3
|
(16)
as well as
1(A = a )
αN (a,w) = 3 ,
1 P(a w)
|
1(A = a )P(z A= a ,w)
αN (a,z,w) = 2 | 3 , (17)
2 P(a w) P(z a,w)
| |
1(A = a )P(m A = a ,z,w)P(z A= a ,w)
αN (a,z,m,w) = 1 | 2 | 3 .
3 P(a w) P(m a,z,w) P(z a,w)
| | |
N N N
Ψ (θ ) = θ
0 0 0
ΨN (θN ) = E bN (W;θN ) ;
1 1 1 1
{ } (18)
ΨN (θN ) = E[E bN (Z,W;θN ) A= a ,W ];
2 2 2 2 3
{ | }
ΨN (θN ) = E E E[bN (Z,M,W;θN ) A= a ,Z,W] A= a ,W .
3 3 3 3 2 3
| |
ForψR anda fixed value((cid:2)a(cid:8),a ,a ,a ), define (cid:9)(cid:3)
1 2 3 4
θR (a,z,m,w) = E(Y A = a,Z = z,M = m,W = w), bR (z,m,w;θR ) = θR (a ,z,m,w),
4 4 4 4 1
|
θR
(a,m,w) =
E[bR (Zπ ,M,W;θR
) A= a,M = m,W = w],
bR (m,w;θR
) =
θR
(a ,m,w),
3 4 4 3 3 3 2
|
θR
(a,z,w) =
E[bR (M,W;θR
) A= a,Z = z,W = w],
bR (z,w;θR
) =
θR
(a ,z,w),
2 3 3 2 2 2 3
|
θR
(a,w) =
E[bR (Z,W;θR
) A = a,W = w],
bR (w;θR
) =
θR
(a ,w),
1 2 2 1 1 1 4
|
(19)
aswell as
1(A = a )
αR (a,w) = 4 ;
1 P(a w)
|
1(A = a )P(z A= a ,w)
αR (a,z,w) = 3 | 4 ;
2 P(a w) P(z a,w)
| | (20)
1(A = a ) P(m A = a ,z,w)dP(z A = a ,w)
αR (a,m,w) = 2 z | 3 | 4 ;
3 P(a w) P(m a,w)
| R |
1(A = a )P(z A= a ,w) P(m A= a ,z,w)dP(z A= a ,w)
αR (a,z,m,w) = 1 | 2 z | 3 | 4 ,
4 P(a w) P(z a,w) P(m a,z,w)
| | R |
R R R
Ψ (θ ) = θ
0 0 0
ΨR (θR
) =
E[bR (W;θR
)]
1 1 1 1
ΨR (θR ) = E[E bR (Z,W;θR ) A = a ,W ] (21)
2 2 2 2 4
{ | }
ΨR (θR ) = E[E E[bR (M,W;θR ) A = a ,Z,W] A= a ,W ]
3 3 3 3 3 4
{ | | }
ΨR (θR ) = E E[E E[bR (Zπ ,M,W;θR ) A= a ,M,W] A = a ,Z,W A = a ,W] ,
4 4 4 4 2 3 4
{ { | | } | }
26Then
ΨE(θE) = E[αE(X)θE(X)]
j j j j
forallE N,R andθ .
j
∈ { }
Proof We will present the proof for ψN and ψR separately. Without affecting the clarity, we
ignorethesuperscriptN orR in thefollowingproofforsimplicity.
ForψN, theproofis doneby notingthat
1 (A = a )
E[α (X)θ (X)] = E[α (A,W)θ (A,W)] = E 3 θ (A,W)
1 1 1 1 P(A = a W) 1
(cid:20) 3 | (cid:21)
1 (A = a ) 1 (A = a )
= E 3 b (W;θ ) = E E 3 b (W;θ ) W
P(A = a W) 1 1 P(A = a W) 1 1
(cid:20) 3 | (cid:21) (cid:26) (cid:20) 3 | (cid:21)(cid:12) (cid:27)
= E[b (W;θ )] = Ψ (θ ), (cid:12)
1 1 1 1 (cid:12)
(cid:12)
1 (A = a ) P(Z A = a ,W)
E[α (X)θ (X)] = E[α (A,Z,W)θ (A,Z,W)] = E 2 | 3 θ (A,Z,W)
2 2 2 2 P(A = a W) P(Z A,W) 2
(cid:20) 2 | | (cid:21)
1 (A = a ) P(Z A = a ,W)
= E 2 | 3 b (Z,W;θ )
P(A = a W) P(Z A,W) 2 2
(cid:20) 2 | | (cid:21)
1 (A = a ) P(Z A = a ,W)
= E E 2 | 3 b (Z,W;θ ) A,W
P(A = a W) P(Z A,W) 2 2
(cid:26) (cid:20) 2 | | (cid:12) (cid:21)(cid:27)
1 (A = a ) (cid:12)
= E 2 P(Z A = a ,W)b (Z,W;θ ) (cid:12)
P(A = a W) | 3 2 2 (cid:12)
(cid:20) 2 | (cid:21)
1 (A = a )
= E E 2 P(Z A = a ,W)b (Z,W;θ ) W
P(A = a W) | 3 2 2
(cid:26) (cid:20) 2 | (cid:12) (cid:21)(cid:27)
= E[1 (A = a )P(Z A = a ,W)b (Z,W;θ )] (cid:12)
2 3 2 2 (cid:12)
| (cid:12)
= E E[b (Z,W;θ ) A = a ,W] = Ψ (θ ),
2 2 3 2 2
{ | }
and
E[α (X)θ (X)] = E[α (A,Z,M,W)θ (A,Z,M,W)]
3 3 3 3
1 (A = a ) P(M A = a ,Z,W)P(Z A = a ,W)
= E 1 | 2 | 3 θ (A,Z,M,W)
P(A = a W) P(M A,Z,W) P(Z A,W) 3
(cid:20) 1 | | | (cid:21)
1 (A = a ) P(M A = a ,Z,W)P(Z A = a ,W)
= E 1 | 2 | 3 b (Z,M,W;θ )
P(A = a W) P(M A,Z,W) P(Z A,W) 3 3
(cid:20) 1 | | | (cid:21)
1 (A = a ) P(M A = a ,Z,W)P(Z A = a ,W)
= E E 1 | 2 | 3 b (Z,M,W;θ ) A,Z,W
P(A = a W) P(M A,Z,W) P(Z A,W) 3 3
(cid:26) (cid:20) 1 | | | (cid:12) (cid:21)(cid:27)
1 (A = a ) P(Z A = a ,W) (cid:12)
= E 1 P(M A = a ,Z,W) | 3 b (Z,M,W;θ ) (cid:12)
P(A = a W) | 2 P(Z A,W) 3 3 (cid:12)
(cid:20) 1 | | (cid:21)
= E[1 (A = a )P(M A = a ,Z,W)P(Z A = a ,W)b (Z,M,W;θ )]
1 2 3 3 3
| |
= E[E E[b (Z,M,W;θ ) A = a ,Z,W] A = a ,W ] = Ψ (θ ).
3 3 2 3 3 3
{ | | }
27ForψR,theproofisdonebynotingthat
1 (A = a )
E[α (X)θ (X)] = E[α (A,W)θ (A,W)] = E 4 θ (A,W)
1 1 1 1 P(A = a W) 1
(cid:20) 4 | (cid:21)
1 (A = a ) 1 (A = a )
= E 4 b (W;θ ) = E E 4 b (W;θ ) W
P(A = a W) 1 1 P(A = a W) 1 1
(cid:20) 4 | (cid:21) (cid:26) (cid:20) 4 | (cid:21) (cid:12) (cid:27)
= E[b (W;θ )] = Ψ (θ ), (cid:12)
1 1 1 1 (cid:12)
(cid:12)
E[α (X)θ (X)] = E[α (A,Z,W)θ (A,Z,W)]
2 2 2 2
1 (A = a ) P(Z A = a ,W)
= E 3 | 4 θ (A,Z,W)
P(A = a W) P(Z A,W) 2
(cid:20) 3 | | (cid:21)
1 (A = a ) P(Z A = a ,W)
= E 3 | 4 b (Z,W;θ )
P(A = a W) P(Z A,W) 2 2
(cid:20) 3 | | (cid:21)
1 (A = a ) P(Z A = a ,W)
= E E 3 | 4 b (Z,W;θ ) A,W
P(A = a W) P(Z A,W) 2 2
(cid:26) (cid:20) 3 | | (cid:12) (cid:21)(cid:27)
1 (A = a ) (cid:12)
= E 3 P(Z A = a ,W)b (Z,W;θ ) (cid:12)
P(A = a W) | 4 2 2 (cid:12)
(cid:20) 3 | (cid:21)
1 (A = a )
= E E 3 P(Z A = a ,W)b (Z,W;θ ) W
P(A = a W) | 4 2 2
(cid:26) (cid:20) 3 | (cid:12) (cid:21)(cid:27)
= E[1 (A = a )P(Z A = a ,W)b (Z,W;θ )] (cid:12)
3 4 2 2 (cid:12)
| (cid:12)
= E E[b (Z,W;θ ) A = a ,W] = Ψ (θ ),
2 2 4 2 2
{ | }
E[α (X)θ (X)] = E[α (A,M,W)θ (A,M,W)]
3 3 3 3
1 (A = a ) dP(M A = a ,Z,W)dP(Z A = a ,W)
= E 2 | 3 | 4 θ (A,M,W)
P(A W) P(M A,W) 3
(cid:20) | R | (cid:21)
1 (A = a ) dP(M A = a ,Z,W)dP(Z A = a ,W)
= E 2 | 3 | 4 θ (A,M,W)
P(A W) P(M A,Z,W)P(Z A,W) 3
(cid:20) | R | | (cid:21)
1 (A = a ) dP(M A = a ,Z,W)dP(Z A = a ,W)
= E 2 | 3 | 4 b (M,W;θ )
P(A W) P(M A,Z,W)P(Z A,W) 3 3
(cid:20) | R | | (cid:21)
1 (A = a ) dP(M A = a ,Z,W)dP(Z A = a ,W)
= E E 2 | 3 | 4 b (M,W;θ ) A,Z,W
P(A W) P(M A,Z,W)P(Z A,W) 3 3
(cid:26) (cid:20) | R | | (cid:12) (cid:21)(cid:27)
1 (A = a ) dP(M A = a ,Z,W)dP(Z A = a ,W) (cid:12)
= E 2 | 3 | 4 b (M,W;θ ) (cid:12)
P(A W) P(Z A,W) 3 3 (cid:12)
(cid:20) | R | (cid:21)
= E 1 (A = a )b (M,W;θ ) dP(M A = a ,Z,W)dP(Z A = a ,W)
2 3 3 3 4
| |
(cid:20) Z (cid:21)
= E E E[b (M,W;θ ) A = a ,Z,W] A = a ,W = Ψ (θ ),
3 3 3 4 3 3
| |
(cid:2) (cid:8) (cid:9)(cid:3)
and
E[α (X)θ (X)] = E[α (A,Z,M,W)θ (A,Z,M,W)]
4 4 4 4
281 (A = a )P(Z A = a ,W) dP(M A = a ,Z,W)dP(Z A = a ,W)
= E 1 | 2 | 3 | 4 θ (A,Z,M,W)
P(A W) P(Z A,W) P(M A,Z,W) 4
(cid:20) | | R | (cid:21)
1 (A = a )P(Z A = a ,W) dP(M A = a ,Z,W)dP(Z A = a ,W)
= E 1 | 2 | 3 | 4 b (Z,M,W;θ )
P(A W) P(Z A,W) P(M A,Z,W) 4 4
(cid:20) | | R | (cid:21)
= E 1 (A = a )b (Z,M,W;θ )P(Z A = a ,W) dP(M A = a ,Z,W)dP(Z A = a ,W)
1 4 4 2 3 4
| | |
(cid:20) Z (cid:21)
= E 1 (A = a )b (Zπ,M,W;θ )P(Zπ A = a ,M,W) dP(M A = a ,Z,W)dP(Z A = a ,W)
1 4 4 2 3 4
| | |
(cid:20) Z (cid:21)
= E E E E[b (Zπ,M,W;θ ) A = a ,M,W] A = a ,Z,W A = a ,W = Ψ (θ ).
4 4 2 3 4 4 4
| | |
(cid:8) (cid:2) (cid:8) (cid:9) (cid:3)(cid:9)
(cid:3)
C Proofs of results in the main manuscript
C.1 Theorem 1
WewillpresenttheproofforψN. TheproofforψRfollowssymmetricalargumentsandistherefore
omitted. WeomittheindexN inthefollowingnotationforsimplicity.
Fortwoarbitrary distributionsF andP, define
θ (a,z,m,w) = E (Y A = a,Z = z,M = m,W = w),
3,P P
|
θ (a,z,w) = E [b (Z,M,W;θ ) A = a,Z = z,W = w],
2,P,F P 3 3,F
|
θ (a,w) = E [b (Z,W;θ ) A = a,W = w],
1,P,F P 2 2,F
|
θ = E [b (W;θ )],
0,P,F P 1 1,F
whereforP = Fwesimplydenoteθ = θ . Definethelinearfunctionals
j,P j,P,P
Ψ (θ ) = θ
0 0 0
Ψ (θ ) = E b (W;θ ) ;
1 1 P 1 1
{ } (22)
Ψ (θ ) = E [E b (Z,W;θ ) A = a ,W ];
2 2 P P 2 2 3
{ | }
Ψ (θ ) = E E E [b (Z,M,W;θ ) A = a ,Z,W] A = a ,W .
3 3 P P P 3 3 2 3
| |
First, noticethatforj = 1,(cid:2)2,3(cid:8),Ψ (θ ) = Ψ (θ ). Thisyields (cid:9)(cid:3)
j j,F j−1 j−1,P,F
3
Ψ (θ ) Ψ (θ ) = Ψ (θ ) Ψ (θ ) .
0 0,F 3 3,P j j,P,F j j,F
− − { − }
j=0
X
Accordingto theRiesz representationtheorem,thereexistsafunctionα such that
j,P
Ψ (θ ) = E [α (X)θ (X)]
j j P j,P j
for all θ . According to Lemma 1, such α functions are given by the formulas in (5) and (7) of
j j,P
themaintextandα = 1. Thus,
0,P
Ψ (θ ) Ψ (θ ) = E [α (X) θ (X) θ (X) ]
j j,P,F j j,F P j,P j,P,F j,F
− { − }
29= E [ α (X) α (X) θ (X) θ (X) ]
P j,P j,F j,P,F j,F
{ − }{ − }
+E [α (X) b (X;θ ) θ (X) ],
P j,F j+1 j+1,F j,F
{ − }
where we define b (X;θ ) = Y and the second equality follows by adding and subtracting α
4 4 j,F
and byiterated expectation. Define
3
R (η ,η ) = E [ α (X) α (X) θ (X) θ (X) ],
2 F P P j,P j,F j,P,F j,F
− { − }{ − }
j=0
X
and
3
ϕ(X;η ) = α (X) b (X;θ ) θ (X)
F j,F j+1 j+1,F j,F
{ − }
j=0
X
ThenϕN(X;ηN)isthegradientofthefirst-ordervonMisesexpansionforψN becauseΨ (θ ) =
0 0,F
ψ(F) and Ψ (θ ) = ψ(P).
3 3,P
Next, we prove that Var[ϕN(X;P)] is the corresponding non-parametric efficiency bound in a
modelwithobserveddataX = (W,A,Z,Zπ,M,Y), thisholdsif
d
ψ(P ) = E[ϕ(X)s(X)], (23)
dǫ ǫ
(cid:12)ǫ=0
(cid:12)
where P is a smooth parametric submodel(cid:12) that locally covers the non-parametric model, and the
ǫ (cid:12)
scores(X) isdefined as
dlogP
s(X) = ǫ ,
dǫ
(cid:18) (cid:19)(cid:12)ǫ=0
(cid:12)
whereP = P. (cid:12)
ǫ=0
(cid:12)
To validate(23), wecomputethebiasterm ψ(P ) ψ(P). Notethat
ǫ
−
ψ(P ) ψ(P) = Ψ (θ ) Ψ (θ )
ǫ 0 0,P 3 3,P
− ǫ −
= R (η ,η ) E [ϕ(X;η )]
2 P P P P
ǫ − ǫ
= E [ϕ(X;η )] R (η ,η ), (24)
P P 2 P P
ǫ − ǫ
Differentatingwithrespect toǫ onequation(24)and evaluatingat ǫ = 0 yields
d dP d
ψ(P ) = ϕ(X;η ) ǫ R (η ,η )
dǫ ǫ P dǫ − dǫ 2 P P ǫ
Z (cid:18) (cid:19)(cid:12)ǫ=0 (cid:12)ǫ=0
dlogP(cid:12) d (cid:12)
= ϕ(X;η ) (cid:12)ǫ dP R ((cid:12) η ,η ) .
P dǫ (cid:12) − dǫ 2 (cid:12)P P ǫ
Z (cid:18) (cid:19)(cid:12)ǫ=0 (cid:12)ǫ=0
ϕ(X) (cid:12) (cid:12)
s(X) (cid:12) (cid:12)
(cid:12) (cid:12)
| {z }
The proof is done (equation (23) is s| atisfied{ )z by noti} ng that dR (η ,η ) = 0 as this is a
dǫ 2 P P ǫ |ǫ=0
second orderterm. (cid:3)
30D Proofs of Proposition 2
WewillpresenttheproofforψN. TheproofforψRfollowssymmetricalargumentsandistherefore
omitted. WeomittheindexN inthefollowingnotationforsimplicity.
Notethat
ψN = E b (W;θ ) ;
1 1
{ }
= E[E b (Z,W;θ ) A = a ,W ];
2 2 3
{ | }
= E E E[b (Z,M,W;θ ) A = a ,Z,W] A = a ,W ,
3 3 2 3
| |
wherewedefined (cid:2) (cid:8) (cid:9)(cid:3)
θ (a,z,m,w) = E(Y A = a,Z = z,M = m,W = w);
3
|
θ (a,z,w) = E[b (Z,M,W;θ ) A = a,Z = z,W = w];
2 3 3
|
θ (a,w) = E[b (Z,W;θ ) A = a,W = w],
1 2 2
|
1 (A = a )
α (A,W) = 3 ;
1 P(A W)
|
1 (A = a )P(Z A = a ,W)
α (A,Z,W) = 2 | 3 ; (25)
2 P(A W) P(Z A,W)
| |
1 (A = a )P(M A = a ,Z,W)P(Z A = a ,W)
α (A,Z,M,W) = 1 | 2 | 3 ,.
3 P(A W) P(M A,Z,W) P(Z A,W)
| | |
and
b (z,m,w;θ ) = θ (a ,z,m,w);
3 3 3 1
b (z,w;θ ) = θ (a ,z,w);
2 2 2 2
b (w;θ ) = θ (a ,w).
1 1 1 3
By Lemma1,
E b (W;θ ) = E[α (A,W)θ (A,W)];
1 1 1 1
{ }
E[E b (Z,W;θ ) A = a ,W ] = E[α (A,Z,W)θ (A,Z,W)];
2 2 3 2 2
{ | }
E[E E[b (Z,M,W;θ ) A = a ,Z,W] A = a ,W ] = E[α (A,Z,M,W)θ (A,Z,M,W)].
3 3 2 3 3 3
{ | | }
(26)
In the following we do not assume we know the functional forms of (α ,α ,α ), and instead
1 2 3
proposelossfunctionstoestimatethemdirectly. Startingfromthemean-squarederror(MSE)loss
function,wehave
α = argminE[(α (A,W) α˜ (A,W))2]
1 1 1
α˜1 −
= argminE[α (A,W)2 2α˜ (A,W)α (A,W)+α˜ (A,W)2]
1 1 1 1
α˜1 −
= argminE[α˜ (A,W)2 2α˜ (A,W)α (A,W)]
1 1 1
α˜1 −
= argminE[α˜ (A,W)2 2b (W,α˜ )], (27)
1 1 1
α˜1 −
31wherethelastequalityfollowsfrom thefirst equationin(26). Likewise,forα , wecan get
2
α = argminE α˜ (A,Z,W)2 2E[b (Z,W,α˜ ) A = a ,W]
2 2 2 2 3
α˜2 { − | }
= argminE α˜ (A,Z,W)2 2α (A,W)b (Z,W,α˜ ) , (28)
2 1 2 2
α˜2 { − }
where the last equality can be derived by defining q (a,w) = E[b (Z,W;α˜ ) A = a,W = w]
1 2 2
|
and noticing
E E[b (Z,W,α˜ ) A = a ,W] = E[q (a ,W)] = E[b (W;q )] = E[α (A,W)q (A,W)]
2 2 3 1 3 1 1 1 1
{ | }
= E E[α (A,W)b (M,W;α˜ ) A = a ,W] = E[α (A,W)b (M,W;α˜ )].
1 2 2 3 1 2 2
{ | }
As forα , wehave
3
α = argminE[α˜ (A,Z,M,W)2 2E E[b (Z,M,W;α˜ ) A = a ,Z,W] A = a ,W ]
3 2 3 3 2 3
α˜3 − { | | }
= argminE[α˜ (A,Z,M,W)2 2α (A,Z,W)b (Z,M,W,α˜ )], (29)
3 2 3 3
α˜3 −
while for the last equality, we define q (a,z,w) = E b (Z,M,W;α˜ ) A = a,Z = z,W = w
2 3 3
{ | }
and wecan obtain
E E[E b (Z,M,W;α˜ ) A = a ,Z,W A = a ,W] = E E[q (a ,Z,W) A = a ,W]
3 3 2 3 2 2 3
{ { | } | } { | }
= E[α (A,Z,W)q (A,Z,W)] = E[E α (A,Z,W)b (Z,M,W;α˜ ) A,Z,W ]
2 2 2 3 3
{ | }
= E α (A,Z,W)b (Z,M,W;α˜ )
2 3 3
{ }
(cid:3)
32