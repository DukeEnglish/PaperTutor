Can Unconfident LLM Annotations Be Used for Confident Conclusions?
KristinaGligoric¬¥‚ãÜ TijanaZrnic‚ãÜ CinooLee‚ãÜ EmmanuelJ.Cand√®s DanJurafsky
StanfordUniversity
{gligoric, tijana.zrnic, cinoolee, candes, jurafsky}@stanford.edu
Abstract be effectively leveraged for statistical estimation,
hypothesistesting,andtheorydevelopment(Park
Large language models (LLMs) have shown
et al., 2023), as well as informing policy deci-
highagreementwithhumanratersacrossavari-
sions(Weietal.,2023).
etyoftasks,demonstratingpotentialtoeasethe
challengesofhumandatacollection. Incom- Computational Social Science (CSS) research
putational social science (CSS), researchers typicallyfocusesnotontheannotationsthemselves
areincreasinglyleveragingLLMannotations butonthesocial-scienceinsightsandconclusions
tocomplementslowandexpensivehumanan- theyenable. Thus,understandinghowLLManno-
notations. Still, guidelinesforcollectingand
tationscouldbeusedfordownstreaminferencesis
using LLM annotations, without compromis-
crucial in CSS. For example, stance annotations
ing the validity of downstream conclusions,
facilitate the study of linguistic differences be-
remain limited. We introduce CONFIDENCE-
tween media affirming or denying global warm- DRIVENINFERENCE: amethodthatcombines
LLM annotations and LLM confidence indi- ing (Luo et al., 2020), while politeness annota-
catorstostrategicallyselectwhichhumanan- tions can help examine racial disparities in ver-
notations should be collected, with the goal balinteractionswithlawenforcement(Voigtetal.,
ofproducingaccuratestatisticalestimatesand 2017),therelationshipbetweenpolitenessandso-
provablyvalidconfidenceintervalswhilereduc-
cialpower(Danescu-Niculescu-Miziletal.,2013),
ingthenumberofhumanannotationsneeded.
andpolitenessandgender(Newmanetal.,2008).
Our approach comes with safeguards against
Similarly, annotating political leanings in text al-
LLM annotations of poor quality, guarantee-
ing that the conclusions will be both valid lowsstudyingthebiasofsearchengines(Robert-
andnolessaccuratethanifweonlyreliedon sonetal.,2018),socialmedia(Ribeiroetal.,2018),
human annotations. We demonstrate the ef- andpoliticaldiscourse(Simetal.,2013). Precise
fectivenessofCONFIDENCE-DRIVEN INFER- statisticalestimation,suchasprevalenceorregres-
ENCE over baselines in statistical estimation sioncoefficientestimation,isessentialfordrawing
tasks across three CSS settings‚Äîtext polite-
validconclusionsinsuchstudies.
ness, stance, and bias‚Äîreducing the needed
However, whetherLLMannotationscanbeef-
numberofhumanannotationsbyover25%in
fectivelyleveragedwithoutcompromisingtheva-
each.AlthoughweuseCSSsettingsfordemon-
stration,CONFIDENCE-DRIVEN INFERENCE lidity of statistical estimation remains uncertain.
canbeusedtoestimatemoststandardquanti- LLMsexhibitdemographicbiases(Weidingeretal.,
tiesacrossabroadrangeofNLPproblems. 2022;Chengetal.,2023)andmaylackfactualac-
curacy (Gunjal et al., 2024; Li et al., 2023b) and
consistency(Sclaretal.,2023;Atrejaetal.,2024).
1 Introduction Giventheselimitations,usingLLMswithoutcau-
tionmayleadtoinaccurateconclusionsandpoten-
Largelanguagemodels(LLMs)haveshownstrong
tial societal harms, especially when such conclu-
zero-shotperformanceacrosstasks(Kojimaetal.,
sionsinfluencepolicyorhavetangibleimpactson
2022),makingthemapromisingtoolforgenerating
peoples‚Äôoutcomes (Landersand Behrend,2023).
annotations, particularly when they align closely
Apotentialsolutionistorelysolelyonhumanan-
withhumanjudgments(Ziemsetal.,2024). Given
notations;however,humanannotationsarecostly.
thispotential,LLMannotationsoftextualdatamay
Here,wepresentCONFIDENCE-DRIVENINFER-
‚ãÜEqualcontribution. ENCE, a method for valid statistical inference us-
4202
guA
72
]LC.sc[
1v40251.8042:viXraConfidence-Driven Inference
(1) Active collection of human annotations (2) Statistical inference
ùúÉ‚àó
LLM LLM Collect small number of Unbiased estimate and
Text corpus and Valid downstream
quantity of interest ùúÉ‚àó annotations confidence human annotations valid confidence interval conclusion
Figure1: Illustrationof CONFIDENCE-DRIVEN INFERENCE. Givenatextcorpusandaquantityofinterest
Œ∏‚àó,(1)wecollectLLMannotationsandindicatorsofLLMconfidence,basedonwhichwestrategicallychoosea
smallnumberofhumanannotations;(2)wethenproduceanunbiasedestimateŒ∏ÀÜconf andavalidconfidenceinterval,
allowingvaliddownstreamconclusions.
ing LLM annotations. Given a text corpus and a ers(Gilardietal.,2023). NLP,LLMsoffertransfor-
quantityofinterest,ourapproachbuildsonactive mativeopportunitiesforanydisciplinethatrelies
inference(ZrnicandCand√®s,2024)to: (1)strategi- ontextasdata. Fieldssuchaspsychology,politi-
callychooseasmallnumberofhumanannotations, calscience,sociology,communications,andeco-
guidedbyLLMannotationsandtheLLM‚Äôsverbal- nomics recognize this emerging technology‚Äôs po-
izedconfidencescores,and(2)combinethehuman tentialtoenhancesimulation-basedresearch(Bail,
andLLMannotationsintoanaccurateestimateof 2024), and facilitate tasks such as text analysis,
thequantityofinterest(Fig.1). Theresultingesti- concept induction (Lam et al., 2024), and topic
mateisstatisticallyvalid,whilereducingreliance modeling(Phametal.,2024).
onexpensivehumanannotations. However,despitetheirpromise,limitedresearch
Ourtaskisstatisticalestimationofaquantityof hasexploredhowtoharnessthepotentialofLLMs
interest. Weevaluateourapproachonfiveestima- inwaysthatarebothcost-effectiveandstatistically
tiontasksinthreeCSSsettings(politeness,stance, reliable. Ourworkaddressesthisgap.
andmediabias)intermsofconfidenceintervalcov-
2.2 CollaborativeAnnotationParadigms
erage and effective sample size, which measures
theincreaseinaccuracyduetoaugmentinghuman MuchofpastworkframeshumanandLLManno-
with LLM annotations (Sec. 3.4). We find that tationsascompetingalternatives,withafocuson
naively treating LLM annotations as human data determiningwhichissuperior(Thapaetal.,2023).
can lead to highly inaccurate estimates and poor Morerecentworkincreasinglycallsforacollabo-
coverage. Atthesametime,ourmethodmaintains rativeapproachthatleveragesthecomplementary
thetargetcoverage,whileoutperformingthebase- strengthsofboth(Allenetal.,1999). Thesecollab-
lines(definedinSec.3.3)intermsoftheeffective orativeparadigmsaimtobalanceannotationquality
samplesize. Thelatterisenabledpartiallybythe andcostbycombininghumanexpertiseandLLM
factthatinalltestedsettingstheconfidencescores efficiency(Lietal.,2023c;Kimetal.,2024).
arereflectiveofLLMaccuracy. Inthespiritofthesecollaborativeparadigms,our
CONFIDENCE-DRIVEN INFERENCE can be workusesLLMconfidencetoefficientlyandcost-
used to estimate a wide range of standard tar- effectively allocate annotation tasks, while also
gets (such as regression coefficients, means, ensuringthatthestatisticalinferencesderivedfrom
and prevalences) across various NLP prob- theannotateddataarevalid.
lems. Our code and data are available
2.3 ValidStatisticalInferencesinNLP
at https://github.com/kristinagligoric/confidence-
driven-inference. StatisticalinferenceisvitalinNLPresearch. For
example, model evaluation requires determining
2 Background whether a model performs better than a base-
line (Card et al., 2020), which in turn relies on
2.1 LLMsforDataAnnotationTasks
making valid conclusions about whether one is
LLMshaveshowngreatpotentialinhandlingtext- observing meaningful model improvements or
annotation tasks without prior task-specific train- noise(Dodgeetal.,2019). Chatzietal.(2024)and
ing, sometimes even outperforming crowd work- Boyeauetal.(2024)leverageprediction-poweredinference(Angelopoulosetal.,2023a,b)forvalid X isavailableautomatically,withoutneedinghu-
i
rankingofLLMs. Asimilarapproachisadopted man annotation. We use the short-hand notation
bySaad-Falconetal.(2024)toevaluateRetrieval- T = (T ,...,T )anddefineX andH similarly.
1 n
AugmentedGeneration(RAG)systems. ThequantityŒ∏‚àócanbeestimatedviaanestimator
Beyondmodelevaluation,NLPapplicationsin-
Œ∏ÀÜ(X,H),whichwewilldenotebyŒ∏ÀÜ
forshort. The
volveproducingmeasurements,descriptivestatis- accuracyofŒ∏ÀÜ improvesasthenumberofsamplesn
tics, and causal effect estimates (Feder et al., increases(Œ∏ÀÜ recoversŒ∏‚àó asnapproachesinfinity).
2022;CardandSmith,2018). Notably,Keithand WeassumethatŒ∏ÀÜ isanM-estimator(VanderVaart,
O‚ÄôConnor (2018) introduced the problem of sci- 2000),meaningitcanbewrittenas
entificallyvalidprevalenceestimation. Theycon-
n
structBayesianconfidenceintervalsbyproposing Œ∏ÀÜ= argmin 1 (cid:88) ‚Ñì (X ,H ), (1)
Œ∏ i i
a generative model for text documents. We con- n
Œ∏
i=1
tribute to the existing literature by proposing an
entirelymodel-freeapproachthatisapplicabletoa for a loss function ‚Ñì Œ∏ that is convex in Œ∏. Im-
broadrangeoftargetquantities. portant special cases include the mean label,
Lastly, Egami et al. (2024) consider the prob- Œ∏ÀÜ= n1 (cid:80)n i=1H i,andlinearregressioncoefficients,
lemofvalidstatisticalinferencewhencombining which are pervasive in CSS. Other examples in-
humanandLLMannotations. However,theycol- cludequantiles,logistic,andotherregressioncoef-
lectthehumanannotationsforuniformlysampled ficients. Noticethatinsomecases,likecalculating
instances,withoutadaptingtothedifficultyofanno- themean,thelossfunctiononlydependsonH i.
tation. Giventhepromiseofactivelearning(Zhang Our goal is to produce an estimate of Œ∏‚àó with
etal.,2023;Margatinaetal.,2021),wedevelopan uncertainty‚Äîbyprovidingaconfidenceintervalat
adaptiveapproachthatsamplesalimitednumber apre-specifiedlevel(1‚àíŒ±)‚Äîwithlimitedaccess
of human annotations strategically. At a techni- to human annotations. Specifically, we can only
callevel,ourapproachbuildsonactiveinference collectn human ‚â™ nannotations(onaverage). This
(ZrnicandCand√®s,2024),whichcanbeseenasa meansthatthe‚Äúidealestimate‚Äù(1)isoutofreach.
refinement of prediction-powered inference (An- Tosupplementthecostlyhumanannotations,we
gelopoulos et al., 2023a,b) that uses active data assume access to LLM annotations HÀÜ i for all n
collection for improved efficiency. Furthermore, instances. However,wemakenoassumptionthat
wemakeuseofpowertuning(Angelopoulosetal., theLLMannotationsaregood: wewanttoproduce
2023b),atechniquethatensuresthatincorporating avalidconfidenceintervalnomatterthequalityof
LLMannotationsintotheestimationcanneverbe theLLM,thoughweanticipatebettergainswhen
worsethanignoringthemcompletely. theirqualityishigh(i.e.,lowermeansquarederror
andasmallerconfidenceinterval).
3 Methods
3.2 CONFIDENCE-DRIVEN INFERENCE
3.1 ProblemSetup
We combine LLM annotations with strategically
We have a text corpus consisting of n indepen- chosenhumanannotationstoproduceanunbiased
dent and identically distributed (i.i.d.) instances estimate
Œ∏ÀÜconf
that lends itself to a confidence in-
T ,...,T . We wish to estimate a quantity of in- terval that is both valid and tight around Œ∏‚àó. In
1 n
terest Œ∏‚àó, such as the prevalence of political bias particular, in the large-sample limit, the mean of
inthe corpusorthecausal effectofusing certain theestimateisexactlyŒ∏‚àó,nomatterhowbiasedthe
linguisticmarkersontheperceivedsentiment. To LLMannotationsare.
perform the estimation, we require human anno- We first explain how to choose the set of in-
tations H ,...,H corresponding to T ,...,T . stancestobehuman-annotated,whichiscrucialfor
1 n 1 n
For example, H might indicate whether T con- producing an accurate estimate. We collect a hu-
i i
tainspoliticalbias,orassesstheperceivedpolite- manannotationH forinstanceT withprobability
i i
ness of T . In addition to human annotations, we œÄ . WeletŒæ = 1{H collected}denotetheindica-
i i i i
mayalsohaveotherreadily-availableinformation torofwhetherT hasbeenhuman-annotated. Zrnic
i
aboutT ‚ÄîcovariatesX suchasthesourceofT or andCand√®s(2024)showthattheoptimalchoiceof
i i i
indicators of whether T contains certain linguis- œÄ istosampleaccordingtotheuncertaintyofthe
i i
tic markers, computed via a lexicon. Note that predicted annotation; roughly speaking, for mostestimationproblemstheoptimalruleis theloss(2)isonaverageequalto‚Äúideal‚Äùloss(1).
Thisallowsshowingthat, inthelimit,
Œ∏ÀÜconf
ison
(cid:113)
œÄ‚àó ‚àù E[(HÀÜ ‚àíH )2|T ], average exactly equal to Œ∏‚àó, no matter the bias in
i i i i
theLLMannotations. Togiveoneexample,ifwe
where‚àùhidesthenormalizationrequiredtomeet wanttoestimatethemeanofH ,Œ∏ÀÜconf reducesto
i
thebudget,E[(cid:80)n Œæ ] = (cid:80)n œÄ‚àó = n . Of
i=1 i i=1 i human
course,sinceH
i
isunknown,œÄ i‚àó isunattainable.
Œ∏ÀÜconf =
1 (cid:88)n (cid:18)
ŒªHÀÜ +(H ‚àíŒªHÀÜ
)Œæ i(cid:19)
.
i i i
Akeyideabehindourmethodistoapproximate n œÄ
i
i=1
œÄ‚àó byqueryingtheLLMforverbalizedconfidence.
i
Since RLHF may cause overconfidence (Geng NoticethatE[Œ∏ÀÜconf] = E[H ] = Œ∏‚àó. Theparameter
i
et al., 2024; Zhou et al., 2024) and miscalibra-
Œªiscalledapower-tuningparameter(Angelopou-
tion (Band et al., 2024; Achiam et al., 2023) of
los et al., 2023b), and it interpolates between ig-
theLLM‚Äôsconditionaltokenprobabilities,verbal-
noringtheLLMannotations(Œª = 0)andutilizing
ized probabilities, i.e., expressions of confidence
themfully(Œª = 1). WesetŒªoptimally,sothatthe
in token-space, are better-calibrated (Tian et al.,
mean squared error (MSE) of
Œ∏ÀÜconf
is minimized
2023). Therefore,tocollectconfidencescores,we
overŒª. Thismeansthat,givenanysamplingrule
adopttheverbalizedtwo-stagepromptingapproach
œÄ , the confidence-driven estimator can never be
i
introducedbyTianetal.(2023),wherethemodelis
hurtbyleveragingerroneousLLMannotationsor
firstaskedtoprovideananswerviazero-shooting
miscalibratedconfidencescores. Theestimatoris
andafterwardaskedtoassignaprobabilitytothe
atleastasgoodaswhenŒª = 0. Detailsbehindthe
correctness of the answer. This gives us a confi-
optimizationofŒªareinApp.A.2.
dencescoreC ‚àà [0,1]foreachinstanceT . Inour
i i Finally,applyingthetheoreticalguaranteesofZr-
applications,wefindthattheverbalizedconfidence
nicandCand√®s(2024),weformavalidconfidence
scoresarecalibrated(Fig.3(right)),meaningthat
intervalatlevel1‚àíŒ±as
higherconfidencescorescorrespondtohigherac-
curacywithrespecttohumanannotations. C = (Œ∏ÀÜconf ¬±z œÉÀÜ ),
1‚àíŒ± 1‚àíŒ±/2 se
As we collect human annotations, we use
{(C j,(HÀÜ j ‚àíH j)2)} j<i,Œæj=1 asfeature‚Äìlabelpairs where z
1‚àíŒ±/2
is the 1‚àíŒ±/2 quantile of the stan-
totrainablack-boxpredictore (cid:100)rr i. Inotherwords, dardnormaldistributionandœÉÀÜ
se
isastandarderror
wetrainamodeltopredicttheLLMerrorfromits estimatethathasaclosedform,statedinApp.A.1.
confidence. Finally,weset
3.3 Baselines
(cid:113)
œÄ ‚àù err (C ),
i (cid:100)i i Human+LLM(non-adaptive). Thefirstbase-
line incorporates LLM annotations but does not
normalized so that
E[(cid:80)n
Œæ ] =
(cid:80)n
œÄ =
i=1 i i=1 i adapttotheper-instanceconfidenceoraccuracyof
n . In practice we do not fine-tune err at
human (cid:100)i the LLM‚Äîit equally trusts all LLM annotations.
everystepi,butwedosoperiodically,afterreason- Inparticular,thisbaselineisaspecialcaseofŒ∏ÀÜconf
ablylargebatchesofdata(say,every50or100data
with Œª = 1 and uniform sampling probabilities
points). SeeApp.A.3forfurtherdetailsbehindthe œÄ = n human. This is the method evaluated and
i n
samplingandTable2forprompttexts.
studiedbyEgamietal.(2024).
Afterwehavecollectedthehumanannotations
accordingtoœÄ ,buildingonactiveinference(Zrnic Humanonly. ThesecondbaselineignoresLLM
i
andCand√®s,2024)wecomputeaconfidence-driven annotationsandsimplyappliesthestandardestima-
estimateofŒ∏‚àó: tortohumanannotations. Itcollectseachhuman
annotationwithequalprobability, n human,sothat
n (cid:18) (cid:19) n
Œ∏ÀÜconf = argmin 1 (cid:88) Œª‚ÑìÀÜ +(‚Ñì ‚àíŒª‚ÑìÀÜ )Œæ i , n human annotationsarecollectedonaverage. This
Œ∏,i Œ∏,i Œ∏,i
Œ∏ n œÄ i isthe‚Äúclassical‚Äùapproach, anditcanbethought
i=1
(2) of as erring on the side of caution and ignoring
where we denote ‚Ñì Œ∏,i = ‚Ñì Œ∏(X i,H i) and ‚ÑìÀÜ Œ∏,i = potentiallybiasedLLMoutputs. Sincethebaseline
‚Ñì (X ,HÀÜ ),andŒª ‚àà [0,1]isacarefullychosentun- onlycollectshumanannotations,itallowsforming
Œ∏ i i
ingparameter. Noticethateverysummandin(2)is a valid confidence interval via classical statistics.
inexpectationoverŒæ equalto‚Ñì (X ,H ),andthus ThisapproachisequivalenttoŒ∏ÀÜconf withŒª = 0.
i Œ∏ i iLLMonly. Finally,weconsiderthenaivebase- wouldrequireinfinitedata,wecannotknowŒ∏‚àó ex-
line which treats LLM annotations as human an- actly in our applications. Instead, as a proxy, we
notations,applyingthestandardestimatortothose computecoveragewithrespecttotheestimate(1)
annotations and naively forming a confidence in- onthefulldataset. Wecomputetheintervalswith
terval. Thisbaselinedoesnotsufferfromabudget a target coverage rate of 90%. Note that, follow-
constraint,sinceLLMannotationsareassumedto ing the theory of Zrnic and Cand√®s (2024), the
be cheap and available for all n instances, but it coverageofourmethodisprovablyequalto90%,
maybebiasediftheLLMproducesbiasedoutputs. and the same is true of the other two statistically
valid baselines (our numbers will be slightly up-
3.4 EvaluationMetrics ward biased due to the fact that we use a proxy
for Œ∏‚àó). With this in mind, the main purpose of
We evaluate our approach and the baselines in
terms of effective sample size and coverage. The reportingcoverageistoevaluatetheperformance
oftheLLMonlyapproach;forallothermethods,
effectivesamplesizemeasurestheincreaseinaccu-
weshowcoverageasaproofofconcept.
racyachievedbyincorporatingLLMannotations
alongsidehumanannotations. Thisisakintoget-
4 Results
tingmorevalueoutofeachhumanannotation. For
instance, if one has only 100 human annotations We evaluate our approach on a set of CSS prob-
but combines them effectively with a larger pool lems that rely on statistical estimation. We aim
ofLLMannotations,theresultingaccuracycould to include settings that (1) allow addressing im-
becomparabletohaving150humanannotations. portant downstream social-science questions, (2)
Thelattermetric,coverage,evaluatesthestatistical rely on a human-labeled corpus of text instances
validityoftheapproachesbycapturinghowoften (possiblywithrelevantadditionalcovariates),and
the true value Œ∏‚àó falls within the produced confi- (3)haveapubliclyavailabledataset. Weselected
dence interval. In the following we elaborate on threesettingsthatmeetthesecriteria‚Äîpoliteness,
the two metrics, deferring further details behind stance, and political bias. For stance and polite-
theircomputationtoApp.A.4. ness, we leverage publicly available datasets and
thecorrespondinghumanannotationsintheiren-
Effectivesamplesize.
GivenanestimateŒ∏ÀÜmethod
tirety. Given the large size, for political leaning,
producedbyamethod,wedefinetheeffectivesam-
werandomlysampleasmallersubsetoftexts.
ple size as the hypothetical value n such
effective
that MSE(Œ∏ÀÜmethod) = MSE(Œ∏ÀÜhuman ), where 4.1 Estimationtasks
n
effective
Œ∏ÀÜhuman
isobtainedviathehuman-onlyapproach
n Politeness. Texts from online requests posted
effective
withn effective annotations. Inotherwords,Œ∏ÀÜmethod on Stack Exchange and Wikipedia (n = 5,480)
is as accurate as the ‚Äúclassical‚Äù estimate with can be seen as polite or impolite. Politeness an-
n effective humanannotations. Anequivalentdefini- notations help understand how linguistic devices
tionsaysthatn effective isthesamplesizeforwhich impactperceivedpoliteness(Danescu-Niculescu-
theconfidenceintervalaroundŒ∏ÀÜmethod
isofequal Mizil et al., 2013). In this estimation task, Œ∏‚àó
width as the classical confidence interval around corresponds to the logistic regression coefficient
Œ∏ÀÜ nhu effm eca tn ive. We thus have that n effective ‚àí n human Œ≤ hedge measuring the impact of a linguistic fea-
isthebenefit(ifpositive)orharm(ifnegative)of ture such as hedging on the perceived polite-
using LLM annotations. We also report the gain ness, logit(P(H = 1|X )) = Œ≤ +
polite hedge 0
in effective sample size, defined as (n effective ‚àí Œ≤ hedgeX hedge, where X hedge = 1 indicates the
n human)/n human¬∑100%. Theeffectivesamplesize presenceofthehedgemarkerandH
polite
= 1in-
ofthehuman-onlyapproachisalwaysn human. We dicatesannotationaspolite. Wesimilarlyestimate
onlyreporttheeffectivesamplesizeforapproaches Œ≤ ,theimpactoftheuseofthefirstpersonplural
1pp
thatusehumanannotations,i.e. allbutLLMonly, pronounsontheperceivedpoliteness.
becausetheeffectivesamplesizemeasuresthein-
Stance. Newsheadlines(n = 2,300)areagree-
creaseinvalueofthehumanannotations.
ing, neutral, or disagreeing with the stance that
Coverage. Coverage is defined as the rate at global warming is a serious concern (Luo et al.,
which the confidence intervals produced by each 2020). Stance annotations facilitate the study
methodcoverŒ∏‚àó. SinceŒ∏‚àó isanidealestimatethat of linguistic differences between media support-Politeness devices
1500 1.0
1000
0.5
500
0.0
0.5 0.0 0.5 1.0 250 500 750 1000 250 500 750 1000
logistic regression coefficient n n
hedge human human
1.0
3000
2000 0.5
1000
0.0
2 1 0 1 250 500 750 1000 250 500 750 1000
logistic regression coefficient n n
1pp human human
Stance on global warming
1500 1.0
1000 0.5
500 0.0
0 1 2 3 600 800 1000 600 800 1000
odds ratio O n n
agreement human human
Political bias
1500 1.0
1000 0.5
500
0.0
0.30 0.35 0.40 0.45 500 750 1000 500 750 1000
prevalence p left n human n human
1.0
1500
1000 0.5
500
0.0
0.30 0.35 0.40 500 750 1000 500 750 1000
prevalence p n n
right human human
confidence-driven human + LLM (non-adaptive) human only LLM only
Figure2: Confidenceintervals,effectivesamplesize,andcoverage. Rowscorrespondtodifferentestimation
tasks. Thefirstcolumnshowstheconfidenceintervalsinfiverandomtrials. Theverticaldashedlinecorresponds
totheestimateproducedonthefulldataset. Amethodisvalidifitsconfidenceintervalincludesthisestimate(in
about90%ofthetrials),andtighterintervalsaroundŒ∏‚àóindicatesbetterperformance. Thesecondandthirdcolumns
displaytheeffectivesamplesizen andcoverage,respectively,fordifferentvaluesofthehumanannotation
effective
budgetn . Resultsareestimatedover100trials.
human
n
n
n
n
n
evitceffe
evitceffe
evitceffe
evitceffe
evitceffe
egarevoc
egarevoc
egarevoc
egarevoc
egarevocMethod
Estimationtask Metric
confidence-driven human+LLM(non-adaptive) LLMonly
Politenessdevices Gainineff.samplesize (30.02 ¬±7.82)% (-16.76 ¬±8.08)% ‚Äî
(hedge) Coverage 95% 89% 52%
Politenessdevices Gainineff.samplesize (319.44 ¬±22.09)% (-8.05 ¬±30.09)% ‚Äî
(1stpersonpl.) Coverage 94% 94% 69%
Stanceon Gainineff.samplesize (33.77 ¬±25.06)% (17.84 ¬±25.67)% ‚Äî
globalwarming Coverage 88% 94% 0%
Politicalbias Gainineff.samplesize (29.94 ¬±8.19)% (20.56 ¬±6.33)% ‚Äî
(left-leaning) Coverage 97% 94% 2%
Politicalbias Gainineff.samplesize (63.73 ¬±11.48)% (61.15 ¬±8.75)% ‚Äî
(right-leaning) Coverage 91% 95% 90%
Table 1: Results summary. Gain in effective sample size and coverage across the five estimation tasks for
n = 500, estimated over 100 trials. In each task, the confidence-driven approach achieves a higher gain
human
ineffectivesamplesize(bolded)thanthenon-adaptiveapproach. Confidence-drivenapproachalwaysachieves
a positivegain, while the non-adaptive approach sometimes achieves a negativegain. Confidence-driven and
non-adaptiveapproachesachieve near90%coverage,orhigher. Incontrast,LLM-onlycoverageisoften poor.
GainineffectivesamplesizeisnotestimatedfortheLLM-onlyapproachasitdoesnotleveragehumanannotations.
Errorsshowastandarddeviationover100trials.
ing or rejecting global warming, which have im- 4.2 Evaluation
portant implications for communication and pol-
OurmainevaluationisbasedonLLMannotations
icy (Hmielowski et al., 2014). In this task, we
collectedwithGPT-4o;analogousresultswithGPT-
estimateŒ∏‚àó correspondingtoO ,theodds
agreement 3.5canbefoundinApp.B.1. Table2inApp.A.3
ratio of agreement given the presence of affirm-
lists prompt texts and parameters. To test LLM
ingdevicessuchas‚Äúexpert,‚Äù‚Äúproven,‚Äù‚Äúrenowned,‚Äù
performance out of the box, all annotations are
andsoon. Formally,denotingbyX ‚àà {0,1}
affirm collectedusingzero-shotprompting. Overall,the
thepresenceofanaffirmingdeviceandH ‚àà
agree confidencescoresarecalibratedwithaccuracy,but
{0,1}theannotationofagreement,wehave
the annotations are only in moderate agreement
with human annotations in all three settings (see
¬µ /(1‚àí¬µ ) App.A.3). Thisisalignedwithourlackofassump-
agree|affirm agree|affirm
O = ,
agreement ¬µ /(1‚àí¬µ ) tionthattheLLMannotationsaregood: wewant
agree|¬¨affirm agree|¬¨affirm
toproduceavalidconfidenceintervalnomatterthe
qualityoftheLLMannotations.
where¬µ = P(H = 1|X = 1)
agree|affirm agree affirm Wereportthetwokeymetrics(effectivesample
and ¬µ = P(H = 1|X = 0).
agree|¬¨affirm agree affirm sizeandcoverage),forthethreeselectedsettings
Indicatorsforaffirmingdeviceswereextractedus-
(thestudyofpoliteness,stance,andbias),wherethe
ingalexiconderivedbyLuoetal.(2020).
taskistoestimatethefivetargetquantitiesŒ≤ ,
hedge
Œ≤ ,O ,p ,andp . Bothmetricsare
1pp agreement left right
Political bias. News texts (randomly sampled estimated over 100 trials for varying n , the
human
n = 2,000) are either leaning left, center, or budgetforhumanannotations.
right(Balyetal.,2020). Annotatingpoliticallean- OurmainfindingsarereportedinFigure2and
ingsintextallowsstudyingthebiasinmediaout- summarizedinTable1. Figure2alsodepictsthe
lets,socio-technicalsystems,orhistoricalandcon- computed confidence intervals in five randomly
temporarypublicdiscourse. Suchbiasesareoften chosen trials across the five target quantities, for
reported in terms of prevalence statistics. Thus, thelowestvalueofn intheconsideredrange.
human
in this setting Œ∏‚àó corresponds to the prevalence
of a leaning, i.e., p = P(H = 1), where Effectivesamplesize. First,acrossthefivetarget
lean lean
H
lean
‚àà {0,1} denotes the presence of a leaning. quantities,wefindthatCONFIDENCE-DRIVEN IN-
Weestimatep
left
andp right,theprevalencesofleft- FERENCEincreasestheeffectivesamplesizecom-
andright-leaningarticlesinthecorpus. paredtothehuman-onlybaseline. Foragivenbud-get of n annotations, e.g., n = 1000, (O )and70%(Œ≤ ). Thisemphasizeshow
human human agreement 1pp
theconfidence-drivenapproachachievestheeffec- estimatesonlyrelyingonLLMannotationscanbe
tivesamplesizeatminimum1250(whenestimat- misleading. Notably,whenestimatingO
agreement
ingp ). Thismeansthattheconfidenceinterval using LLM annotations only, the odds-ratio esti-
left
aroundtheestimatedstatisticisofequalwidthas matepointsinthewrongdirection(O > 1
agreement
theconfidenceintervalproducedwithalargernum- while O < 1 is true), as illustrated in
agreement
berofhuman-onlyannotations. Fig. 2. Interestingly, the overall inter-annotator
Similarly,itisinformativetoconsidertheneces- agreementbetweenhumanandLLMannotationsis
sarybudgetofhumanannotationsn givena thehighestinthissetting(Coheninter-rateragree-
human
desiredeffectivesamplesizen effective. Toachievea ment Œ∫ stance = 0.57). This suggests that even
desiredfixedeffectivesamplesize,theconfidence- whenLLMannotationsoverallagreewithhuman
drivenapproachreducestheneedednumberofhu- annotations,downstreamstatisticalestimatesrely-
man annotations across all five target quantities. ingonLLMannotationsonlycanbebiased.
For instance, to achieve n = 1000, only Table 1 summarizes the achieved coverage for
effective
betweenaround250(Œ≤ )and750(p )human n = 500. Across the five tasks, the
1pp left human
annotationsareneeded,thusreducingthenumber confidence-driven and non-adaptive approaches
of human annotations needed to achieve equally achieve around or over 90% coverage (note that
accurateestimatesbyatleast25%foralltasks. smalldeviationsarepossibleduetoonly100simu-
Moreover, we also find that the confidence- lationtrials). Incontrast,theLLM-onlyapproach
drivenapproachincreasestheeffectivesamplesize onlymeetstherequirementforp rightandotherwise
compared to the human + LLM (non-adaptive) severelyundercovers.
baseline. Forexample,toachieven = 1000, Insummary,ourmethodincreasestheeffective
effective
the confidence-driven approach requires 200 (re- samplesizegivenafixedbudgetofhumanannota-
spectively,750)fewerhumanannotationsthanthe tions,leadingtoasubstantialsaveinbudget,while
non-adaptivebaselineforO (respectively, maintainingthetargetcoverage.
agreement
Œ≤ ). The confidence-driven approach therefore
1pp
leadstoafurtherreductionintherequirednumber 5 Discussion
of human annotations compared to an approach
that leverages LLMs, but does so non-adaptively.
Inthiswork,weintroduce CONFIDENCE-DRIVEN
Moreover, notice that the non-adaptive approach
INFERENCE, a method that integrates verbalized
confidence of LLMs with active inference to op-
cansometimesevenhurtcomparedtothehuman-
timally combine human and LLM annotations.
only baseline: in the two politeness tasks, using
AcrossthreedistinctCSSsettings,resultsdemon-
LLMsactuallyreducestheeffectivesamplesize.
strate that the proposed method consistently out-
Table1summarizesthegainineffectivesample
performsbaselinemethods(human-onlyandnon-
sizeforn = 500. Acrossthefivetasks, the
human
adaptive approaches) in effective sample size.
confidence-drivenapproachachievesasubstantial
Moreover,theincreaseintheeffectivesamplesize
gainintheeffectivesamplesize,providingatmin-
is achieved without a decrease in coverage. In
imum around +30% gain (when estimating p ),
left
contrast,theLLM-onlyapproachyieldsinvalides-
going even over +300% (when estimating Œ≤ ).
1pp
timatesandconsiderablylowercoverage.
Again, the confidence-driven approach achieves
a higher gain than the non-adaptive approach for
Thus, CONFIDENCE-DRIVEN INFERENCE al-
lows for researchers to allocate human and LLM
eachtask,whichcanevenbenegative(whenesti-
annotationsinacost-effectivemannerwhilemain-
matingŒ≤ andŒ≤ ).
hedge 1pp
tainingconfidenceinthestatisticalvalidityoftheir
Coverage. Thesaveinhumanannotationsdoes results. Furthermore, CONFIDENCE-DRIVEN IN-
not come at the cost of diminished validity. As FERENCE alsoaddressesthechallengesposedby
expected, across the five target quantities, the thevariablequalityofLLMannotation,byprovid-
confidence-drivenapproachhascoveragearoundor ingvalidityguaranteeswhenleveragingimperfect
over90%,asdothenon-adaptiveandhuman-only LLMannotations.
baselines (Fig. 2). However, LLM-only intervals AlthoughoverallLLMannotationsmoderately
have a much lower coverage, only being around agreewithhumanannotationsinthetestedsettings,
90%forp ,andotherwiserangingbetween0% relyingonLLMannotationsonlycanleadtowrong
rightconclusions, as shown in the example of estimat- scores are not reliable (i.e., they are poorly cali-
ingtheoddsratiointhestancesetting. Incontrast, brated),theestimatemaybecometoonoisy,lead-
despite the fact that LLM annotations are imper- ingtooverlywideconfidenceintervals.
fect,ourapproachallowscarefullycombiningthem WetestedonlyalimitednumberofLLMs. We
with a limited set of human annotations in order notethatestablishingacomprehensivebenchmark
to reduce the human annotation budget, without isbeyondthescopeofthiswork(seeApp.B.1for
sacrificingthevalidity. performancedetailsusingadifferentmodel).
Finally, given the growing interest in harness- Additionally,whilewetreathumanannotations
ingthecapabilitiesofLLMsacrossdisciplines,the asthegoldstandardinourstudy,weacknowledge
accessibility of a method is an important consid- thathumanannotationsarebiased,andthatreason-
eration. ResearcherscansimplyprompttheLLM able annotators can disagree. Future work could
foritsconfidencelevelviaAPIaccessandleverage explorewaystoaccountforvariabilityandbiasin
CONFIDENCE-DRIVEN INFERENCE to combine humanannotations.
LLM confidence with LLM and human annota- Humanannotationsareoftenobtainedthrough
tions to produce a valid statistical estimate. This crowdsourcing, which may itself be influenced
approachcanbeappliedtoawiderangeoftasks, by LLMs, as crowd workers might use LLMs
acrossfields. toincreaseproductivity(Veselovskyetal.,2023).
Although we use datasets collected before the
6 Limitations widespread availability of LLMs, detecting AI-
generated text remains a challenge (Verma et al.,
Theexternalvalidityofourfindingsiscontingent
2024;Weber-Wulffetal.,2023).
upontwokeyassumptions: thatthetextinstances
Thisworkonlyconductedexperimentsonesti-
arei.i.d. fromarelevantdistribution,andthatthe
mationtaskswithinCSSdatasetsandonlyinEn-
researcher has full control of the annotation pro-
glish. However, CONFIDENCE-DRIVEN INFER-
cess. Thefirstmaybeviolatedifthedistributionof
ENCEisgeneralizabletoothertypesoftext-based
textsshiftsovertime,andthecollectedinstances
datasets,anditwouldbevaluabletoseemoredi-
arenolongerrepresentativeofthecurrentquantity
verseapplicationsinfutureresearch.
of interest. For example, it is possible that rela-
Lastly,thepresentedexperimentsdonotaddress
tionshipsbetweenlinguisticdevicesandperceived
causal effects. For instance, in the context of po-
politeness evolve over time. The second assump-
liteness, to identify the causal effect of hedging
tion may be violated in situations where certain
onperceivedpoliteness, itwouldbenecessaryto
annotations are difficult to obtain (e.g., for low-
comparetextsthatareotherwiseidenticalbutdiffer
resource languages). Our approach may lead to
onlyintheiruseofhedging. Nevertheless, while
inaccurateormisleadingconclusionsundereither
theseevaluationsarenotcausal,ourmethodisstill
violation. Wethuscautionagainstgeneralizingto
applicableforuseincausalestimation.
settingswheretextinstancesexhibittime-varying
shifts or the researcher is not in control over the
7 EthicalImplications
datacollectionprocess.
If the adaptive sampling probabilities œÄ are Our work assumes that the existing human anno-
i
poorlychosen‚Äîpotentiallyduetoinaccuratever- tations within the leveraged datasets serve as the
balizedconfidencescores‚Äîtheresultingestimates goldstandard. However,wecautionagainstinter-
could have a higher mean squared error (MSE) pretinghumanannotationsasdefinitivejudgments,
thanifuniform,non-adaptivesamplingwereused. giventhesubjectivenatureofmanytasks(Fleisig
Thiscouldevenresultinanestimatewithalarger et al., 2023), the potential for annotator disagree-
MSE than the human-only baseline (for sensitiv- ment (Weerasooriya et al., 2023), and the influ-
ity to miscalibration, see App B.2). However, by enceofannotatorpositionality(Santyetal.,2023),
usingpowertuning,asdetailedinSection3.2,we beliefs, biases (Sap et al., 2022), as well as vari-
ensurethatincorporatingLLMannotationintothe anceincultural(HuangandYang,2023)andsocial
estimationprocessdoesnothurttheestimate(i.e., norms(Ziemsetal.,2023).
doesnotincreasetheMSE)regardlessofthesam- In addition to their use in text analysis, LLMs
plingmethodusedforhumanannotations(whether mayholdpotentialforsimulatinghumanbehavior
uniformoradaptive). Thatsaid,iftheconfidence in social science research, including applicationssuch as pretesting surveys and imputing missing PierreBoyeau,AnastasiosNAngelopoulos,NirYosef,
data (Bail, 2024). Our work contributes to estab- JitendraMalik,andMichaelIJordan.2024. Autoeval
doneright:Usingsyntheticdataformodelevaluation.
lishingreliableprinciplesfordoingso. Atthesame
arXivpreprintarXiv:2403.07008.
time,wedonotadvocateforusingLLMsassubsti-
tutesforhumandatabeyondtheconstraintsofour Dallas Card, Peter Henderson, Urvashi Khandelwal,
assumptions, especially seeing that prior studies RobinJia,KyleMahowald,andDanJurafsky.2020.
With little power comes great responsibility. In
haveshownthatLLMstendtoreflecttheperspec-
Proceedings of the 2020 Conference on Empirical
tivesofsomedemographicgroupsmoreaccurately
MethodsinNaturalLanguageProcessing(EMNLP),
thanothers(Santurkaretal.,2023)andmaypropa- pages9263‚Äì9274.
gatestereotypicalportrayals (Chengetal.,2023).
DallasCardandNoahASmith.2018. Theimportance
Wealsocautionagainstfullyreplacinghuman
ofcalibrationforestimatingproportionsfromanno-
annotators with LLM surrogates, which can not
tations. In Proceedings of the 2018 Conference of
onlybeharmfulfortheeconomy(Cazzanigaetal., theNorthAmericanChapteroftheAssociationfor
2024), but also exacerbate the exploitation of hu- ComputationalLinguistics: HumanLanguageTech-
man labor (Li et al., 2023a). Instead, our work nologies,Volume1(LongPapers),pages1636‚Äì1646.
highlightsthebenefitsofhuman-AIcollaboration,
Mauro Cazzaniga, Ms Florence Jaumotte, Longji Li,
showingthatacombinedapproachcanyieldmore
Mr Giovanni Melina, Augustus J Panton, Carlo
accurateandvalidoutcomes. Pizzinelli,EmmaJRockall,andMsMarinaMendes
Tavares.2024. Gen-AI:Artificialintelligenceandthe
futureofwork. InternationalMonetaryFund.
References
Ivi Chatzi, Eleni Straitouri, Suhas Thejaswi, and
JoshAchiam,StevenAdler,SandhiniAgarwal,Lama Manuel Gomez Rodriguez. 2024. Prediction-
Ahmad, Ilge Akkaya, Florencia Leoni Aleman, powered ranking of large language models. arXiv
DiogoAlmeida,JankoAltenschmidt,SamAltman, preprintarXiv:2402.17826.
ShyamalAnadkat,etal.2023. GPT-4technicalre-
port. arXivpreprintarXiv:2303.08774. Tianqi Chen and Carlos Guestrin. 2016. Xgboost: A
scalable tree boosting system. In Proceedings of
JamesEAllen,CurryIGuinn,andEricHorvitz.1999.
the 22nd acm sigkdd international conference on
Mixed-initiative interaction. IEEE Intelligent Sys-
knowledge discovery and data mining, pages 785‚Äì
temsandtheirApplications,14(5):14‚Äì23.
794.
Anastasios N Angelopoulos, Stephen Bates, Clara
Myra Cheng, Esin Durmus, and Dan Jurafsky. 2023.
Fannjiang, Michael I Jordan, and Tijana Zrnic.
Markedpersonas: Usingnaturallanguagepromptsto
2023a. Prediction-powered inference. Science,
measurestereotypesinlanguagemodels. InProceed-
382(6671):669‚Äì674.
ingsofthe61stAnnualMeetingoftheAssociationfor
AnastasiosNAngelopoulos,JohnCDuchi,andTijana ComputationalLinguistics(Volume1: LongPapers),
Zrnic.2023b. PPI++: Efficientprediction-powered pages1504‚Äì1532.
inference. arXivpreprintarXiv:2311.01453.
CristianDanescu-Niculescu-Mizil,MoritzSudhof,Dan
ShubhamAtreja,JoshuaAshkinaze,LingyaoLi,Julia Jurafsky,JureLeskovec,andChristopherPotts.2013.
Mendelsohn, and Libby Hemphill. 2024. Prompt Acomputationalapproachtopolitenesswithappli-
design matters for computational social science cationtosocialfactors. InProceedingsofthe51st
tasks but in unpredictable ways. arXiv preprint AnnualMeetingoftheAssociationforComputational
arXiv:2406.11980. Linguistics(Volume1: LongPapers),pages250‚Äì259.
Christopher A Bail. 2024. Can generative AI im-
Jesse Dodge, Suchin Gururangan, Dallas Card, Roy
provesocialscience? ProceedingsoftheNational
Schwartz, and Noah A Smith. 2019. Show your
AcademyofSciences,121(21):e2314021121.
work: Improvedreportingofexperimentalresults. In
Proceedings of the 2019 Conference on Empirical
Ramy Baly, Giovanni Da San Martino, James Glass,
MethodsinNaturalLanguageProcessingandthe9th
andPreslavNakov.2020. Wecandetectyourbias:
InternationalJointConferenceonNaturalLanguage
Predictingthepoliticalideologyofnewsarticles. In
Proceedings of the 2020 Conference on Empirical Processing(EMNLP-IJCNLP),pages2185‚Äì2194.
MethodsinNaturalLanguageProcessing(EMNLP),
pages4982‚Äì4991. Naoki Egami, Musashi Hinck, Brandon Stewart, and
Hanying Wei. 2024. Using imperfect surrogates
Neil Band, Xuechen Li, Tengyu Ma, and Tatsunori fordownstreaminference: Design-basedsupervised
Hashimoto. 2024. Linguistic calibration of long- learningforsocialscienceapplicationsoflargelan-
formgenerations. InProceedingsoftheForty-first guagemodels. AdvancesinNeuralInformationPro-
InternationalConferenceonMachineLearning. cessingSystems,36.AmirFeder,KatherineAKeith,EmaadManzoor,Reid Michelle S Lam, Janice Teoh, James A Landay, Jef-
Pryzant,DhanyaSridhar,ZachWood-Doughty,Jacob freyHeer,andMichaelSBernstein.2024. Concept
Eisenstein,JustinGrimmer,RoiReichart,MargaretE induction: Analyzing unstructured text with high-
Roberts,etal.2022. Causalinferenceinnaturallan- level concepts using lloom. In Proceedings of the
guageprocessing: Estimation,prediction,interpreta- CHI Conference on Human Factors in Computing
tionandbeyond. TransactionsoftheAssociationfor Systems,pages1‚Äì28.
ComputationalLinguistics,10:1138‚Äì1158.
Richard N Landers and Tara S Behrend. 2023. Au-
EveFleisig,RedietAbebe,andDanKlein.2023. When ditingtheAIauditors: Aframeworkforevaluating
themajorityiswrong: Modelingannotatordisagree- fairnessandbiasinhighstakesAIpredictivemodels.
mentforsubjectivetasks. InProceedingsofthe2023 AmericanPsychologist,78(1):36.
Conference on Empirical Methods in Natural Lan-
Hanlin Li, Nicholas Vincent, Stevie Chancellor, and
guageProcessing,pages6715‚Äì6726.
BrentHecht.2023a. Thedimensionsofdatalabor:A
JiahuiGeng,FengyuCai,YuxiaWang,HeinzKoeppl, roadmapforresearchers,activists,andpolicymakers
Preslav Nakov, and Iryna Gurevych. 2024. A sur- toempowerdataproducers. In Proceedingsofthe
veyofconfidenceestimationandcalibrationinlarge 2023 ACM conference on fairness, accountability,
languagemodels. InProceedingsofthe2024Con- andtransparency,pages1151‚Äì1161.
ferenceoftheNorthAmericanChapteroftheAsso-
JunyiLi,XiaoxueCheng,XinZhao,Jian-YunNie,and
ciationforComputationalLinguistics: HumanLan-
Ji-RongWen.2023b. HaluEval: Alarge-scalehal-
guageTechnologies(Volume1: LongPapers),pages
lucinationevaluationbenchmarkforlargelanguage
6577‚Äì6595, Mexico City, Mexico. Association for
models. InProceedingsofthe2023Conferenceon
ComputationalLinguistics.
EmpiricalMethodsinNaturalLanguageProcessing,
Fabrizio Gilardi, Meysam Alizadeh, and Ma√´l Kubli. pages6449‚Äì6464,Singapore.AssociationforCom-
2023. ChatGPT outperforms crowd workers for putationalLinguistics.
text-annotationtasks. ProceedingsoftheNational
Minzhi Li, Taiwei Shi, Caleb Ziems, Min-Yen Kan,
AcademyofSciences,120(30):e2305016120.
NancyChen,ZhengyuanLiu,andDiyiYang.2023c.
Anisha Gunjal, Jihan Yin, and Erhan Bas. 2024. De- Coannotating: Uncertainty-guidedworkallocation
tectingandpreventinghallucinationsinlargevision betweenhumanandlargelanguagemodelsfordata
languagemodels. InProceedingsoftheAAAICon- annotation. InProceedingsofthe2023Conference
ferenceonArtificialIntelligence,volume38,pages onEmpiricalMethodsinNaturalLanguageProcess-
18135‚Äì18143. ing,pages1487‚Äì1505.
JayDHmielowski,LaurenFeldman,TeresaAMyers, YiweiLuo,DallasCard,andDanJurafsky.2020. De-
Anthony Leiserowitz, and Edward Maibach. 2014. tectingstanceinmediaonglobalwarming. InFind-
Anattackonscience? mediause,trustinscientists, ingsoftheAssociationforComputationalLinguistics:
andperceptionsofglobalwarming. PublicUnder- EMNLP2020,pages3296‚Äì3315.
standingofScience,23(7):866‚Äì883.
KaterinaMargatina, GiorgosVernikos, Lo√ØcBarrault,
Jing Huang and Diyi Yang. 2023. Culturally aware andNikolaosAletras.2021. Activelearningbyac-
natural language inference. In Findings of the As- quiringcontrastiveexamples. InProceedingsofthe
sociation for Computational Linguistics: EMNLP 2021ConferenceonEmpiricalMethodsinNatural
2023,pages7591‚Äì7609,Singapore.Associationfor Language Processing, pages 650‚Äì663, Online and
ComputationalLinguistics. Punta Cana, Dominican Republic. Association for
ComputationalLinguistics.
Katherine Keith and Brendan O‚ÄôConnor. 2018.
Uncertainty-aware generative models for inferring MatthewLNewman, CarlaJGroom, LoriDHandel-
document class prevalence. In Proceedings of the man, andJamesWPennebaker.2008. Genderdif-
2018ConferenceonEmpiricalMethodsinNatural ferencesinlanguageuse: Ananalysisof14,000text
Language Processing, pages 4575‚Äì4585, Brussels, samples. Discourseprocesses,45(3):211‚Äì236.
Belgium.AssociationforComputationalLinguistics.
JoonSungPark,JosephO‚ÄôBrien,CarrieJunCai,Mered-
HannahKim,KushanMitra,RafaelLiChen,Sajjadur ithRingelMorris,PercyLiang,andMichaelSBern-
Rahman, and Dan Zhang. 2024. MEGAnno+: A stein.2023. Generativeagents: Interactivesimulacra
human-LLM collaborative annotation system. In ofhumanbehavior. InProceedingsofthe36than-
Proceedingsofthe18thConferenceoftheEuropean nualacmsymposiumonuserinterfacesoftwareand
Chapter of the Association for Computational Lin- technology,pages1‚Äì22.
guistics: SystemDemonstrations,pages168‚Äì176,St.
Chau Pham, Alexander Hoyle, Simeng Sun, Philip
Julians,Malta.AssociationforComputationalLin-
Resnik,andMohitIyyer.2024. TopicGPT:Aprompt-
guistics.
basedtopicmodelingframework. InProceedingsof
TakeshiKojima,ShixiangShaneGu,MachelReid,Yu- the2024ConferenceoftheNorthAmericanChap-
takaMatsuo,andYusukeIwasawa.2022. Largelan- teroftheAssociationforComputationalLinguistics:
guagemodelsarezero-shotreasoners. InAdvances HumanLanguageTechnologies(Volume1: LongPa-
inNeuralInformationProcessingSystems. pers),pages2956‚Äì2984.FilipeRibeiro,LucasHenrique,FabricioBenevenuto, 17thInternationalAAAIConferenceonWebandSo-
Abhijnan Chakraborty, Juhi Kulshrestha, Mah- cialMedia.
moudrezaBabaei,andKrishnaGummadi.2018. Me-
diabiasmonitor: Quantifyingbiasesofsocialmedia Katherine Tian, Eric Mitchell, Allan Zhou, Archit
news outlets at large-scale. In Proceedings of the Sharma,RafaelRafailov,HuaxiuYao,ChelseaFinn,
InternationalAAAIConferenceonWebandSocial andChristopherDManning.2023. Justaskforcali-
Media,volume12. bration: Strategiesforelicitingcalibratedconfidence
scoresfromlanguagemodelsfine-tunedwithhuman
RonaldERobertson,ShanJiang,KennethJoseph,Lisa feedback. InProceedingsofthe2023Conferenceon
Friedland, David Lazer, and Christo Wilson. 2018. EmpiricalMethodsinNaturalLanguageProcessing,
Auditingpartisanaudiencebiaswithingooglesearch. pages5433‚Äì5442.
ProceedingsoftheACMonhuman-computerinter-
action,2(CSCW):1‚Äì22. AadWVanderVaart.2000. Asymptoticstatistics,vol-
ume3. Cambridgeuniversitypress.
JonSaad-Falcon,OmarKhattab,ChristopherPotts,and
Matei Zaharia. 2024. Ares: An automated evalua- VivekVerma,EveFleisig,NicholasTomlin,andDan
tionframeworkforretrieval-augmentedgeneration Klein.2024. Ghostbuster: Detectingtextghostwrit-
systems. InProceedingsofthe2024Conferenceof ten by large language models. In Proceedings of
theNorthAmericanChapteroftheAssociationfor the2024ConferenceoftheNorthAmericanChap-
ComputationalLinguistics: HumanLanguageTech- teroftheAssociationforComputationalLinguistics:
nologies(Volume1: LongPapers),pages338‚Äì354. HumanLanguageTechnologies(Volume1: LongPa-
pers),pages1702‚Äì1717.
ShibaniSanturkar,EsinDurmus,FaisalLadhak,Cinoo
Lee, Percy Liang, and Tatsunori Hashimoto. 2023. Veniamin Veselovsky, Manoel Horta Ribeiro, and
Whoseopinionsdolanguagemodelsreflect? InIn- RobertWest.2023. Artificialartificialartificialintel-
ternationalConferenceonMachineLearning,pages ligence: Crowdworkerswidelyuselargelanguage
29971‚Äì30004.PMLR. models for text production tasks. arXiv preprint
arXiv:2306.07899.
SebastinSanty,JennyLiang,RonanLeBras,Katharina
Reinecke,andMaartenSap.2023. NLPositionality: RobVoigt,NicholasPCamp,VinodkumarPrabhakaran,
Characterizingdesignbiasesofdatasetsandmodels. WilliamLHamilton,RebeccaCHetey,CamillaM
In Proceedings of the 61st Annual Meeting of the Griffiths,DavidJurgens,DanJurafsky,andJenniferL
AssociationforComputationalLinguistics(Volume Eberhardt.2017. Languagefrompolicebodycamera
1: LongPapers),pages9080‚Äì9102,Toronto,Canada. footage shows racial disparities in officer respect.
AssociationforComputationalLinguistics. Proceedings of the National Academy of Sciences,
114(25):6521‚Äì6526.
Maarten Sap, Swabha Swayamdipta, Laura Vianna,
XuhuiZhou,YejinChoi,andNoahA.Smith.2022. Debora Weber-Wulff, Alla Anohina-Naumeca, Sonja
Annotators with attitudes: How annotator beliefs Bjelobaba,Tom√°≈°Folty`nek,JeanGuerrero-Dib,Olu-
andidentitiesbiastoxiclanguagedetection. InPro- mide Popoola, Petr ≈†igut, and Lorna Waddington.
ceedingsofthe2022ConferenceoftheNorthAmer- 2023. Testing of detection tools for AI-generated
icanChapteroftheAssociationforComputational text. InternationalJournalforEducationalIntegrity,
Linguistics: HumanLanguageTechnologies,pages 19(1):26.
5884‚Äì5906, Seattle, UnitedStates.Associationfor
ComputationalLinguistics. TharinduCyrilWeerasooriya,AlexanderOrorbia,Raj
Bhensadadia, Ashiqur KhudaBukhsh, and Christo-
MelanieSclar,YejinChoi,YuliaTsvetkov,andAlane pherHoman.2023. Disagreementmatters: Preserv-
Suhr.2023. Quantifyinglanguagemodels‚Äôsensitiv- inglabeldiversitybyjointlymodelingitemandan-
itytospuriousfeaturesinpromptdesignor: Howi notatorlabeldistributionswithDisCo. InFindingsof
learned to start worrying about prompt formatting. theAssociationforComputationalLinguistics: ACL
InTheTwelfthInternationalConferenceonLearning 2023,pages4679‚Äì4695,Toronto,Canada.Associa-
Representations. tionforComputationalLinguistics.
YanchuanSim,BriceD.L.Acree,JustinH.Gross,and JohnnyTian-ZhengWei,FrederikeZufall,andRobin
Noah A. Smith. 2013. Measuring ideological pro- Jia.2023. Operationalizingcontentmoderation"ac-
portions in political speeches. In Proceedings of curacy" in the digital services act. arXiv preprint
the2013ConferenceonEmpiricalMethodsinNat- arXiv:2305.09601.
ural Language Processing, pages 91‚Äì101, Seattle,
Washington, USA. Association for Computational Laura Weidinger, Jonathan Uesato, Maribeth Rauh,
Linguistics. ConorGriffin,Po-SenHuang,JohnMellor,Amelia
Glaese,MyraCheng,BorjaBalle,AtoosaKasirzadeh,
SurendrabikramThapa,UsmanNaseem,andMehwish etal.2022. Taxonomyofrisksposedbylanguage
Nasim. 2023. From humans to machines: Can models. In Proceedings of the 2022 ACM Confer-
chatgpt-likellmseffectivelyreplacehumanannota- enceonFairness,Accountability,andTransparency,
tors in nlp tasks. In Workshop Proceedings of the pages214‚Äì229.RuoyuZhang,YanzengLi,YongliangMa,MingZhou,
and Lei Zou. 2023. LLMaAA: Making large lan-
guagemodelsasactiveannotators. InFindingsofthe
AssociationforComputationalLinguistics: EMNLP
2023,pages13088‚Äì13103,Singapore.Association
forComputationalLinguistics.
KaitlynZhou,JenaDHwang,XiangRen,andMaarten
Sap.2024. Relyingontheunreliable: Theimpactof
languagemodels‚Äôreluctancetoexpressuncertainty.
arXivpreprintarXiv:2401.06730.
CalebZiems, JaneDwivedi-Yu, Yi-ChiaWang, Alon
Halevy,andDiyiYang.2023. Normbank: Aknowl-
edgebankofsituationalsocialnorms. InProceed-
ingsofthe61stAnnualMeetingoftheAssociationfor
ComputationalLinguistics(Volume1: LongPapers),
pages7756‚Äì7776.
CalebZiems,WilliamHeld,OmarShaikh,JiaaoChen,
ZhehaoZhang,andDiyiYang.2024. Canlargelan-
guage models transform computational social sci-
ence? ComputationalLinguistics,50(1):237‚Äì291.
Tijana Zrnic and Emmanuel J Cand√®s. 2024. Active
statisticalinference. InProceedingsoftheForty-first
InternationalConferenceonMachineLearning.A FurtherDetailsontheMethod A.3 LLMandHumanAnnotationDetails
Fordataannotation,weuseGPT-4o(gpt-4o-2024-
A.1 ConfidenceIntervals
05-13version)andGPT-3.5-turbo(gpt-3.5-turbo-
Wecomputetheconfidenceintervalsfollowingthe 0125version). Prompttextsinbothstagesarelisted
approach in (Zrnic and Cand√®s, 2024). Suppose in Table 2. To test LLM performance out-of-the-
thatŒ∏ÀÜconf ispossiblyd-dimensional(suchasin,for box,allannotationsarecollectedusingzero-shot
example,linearorlogisticregression),andweare prompting. Wesetthemax_tokensparameterto5,
interested in coefficient j. If d = 1, such as in usedefaulttemperature(1),andthedefaultsystem
thecaseofprevalenceestimation,thenj isalways promptandtheotherpromptingparameters.
equalto1. Wecomputetheconfidenceintervalas: Stage 1 GPT-4o annotations are in moderate
agreement with human annotations in all three
Ô£´ (cid:115) Ô£∂
settings: Œ∫ = 0.39, Œ∫ = 0.57, and
C 1‚àíŒ± = Ô£≠Œ∏ÀÜ jconf ¬±z 1‚àíŒ±/2
Œ£(cid:98)
njj Ô£∏, Œ∫ bias =
0.4p 3o .liteness stance
InStage2,wefindthatthecollectedverbalized
confidence scores are calibrated with the Stage 1
wherez isthe1‚àíŒ±/2quantileofthestandard
1‚àíŒ±/2 accuracy (Fig. 3 (right)), such that higher confi-
normaldistribution. ThematrixŒ£(cid:98) isanestimateof dence scores correspond to higher accuracy with
thecovarianceofŒ∏ÀÜconf,givenby:
respect to human annotations. This implies that
verbalizedconfidenceisindeedaninformativesig-
(cid:18) (cid:19)
Œæ
Œ£(cid:98) =HÀÜ‚àí1V(cid:100)ar Œª‚àá‚ÑìÀÜ
Œ∏ÀÜconf
+(‚àá‚Ñì
Œ∏ÀÜconf
‚àíŒª‚àá‚ÑìÀÜ Œ∏ÀÜconf)
œÄ
HÀÜ‚àí1, naltoleverageinestimationtasks. Histogramsof
thecollectedverbalizedconfidencescoresareillus-
tratedinFig.3(left). Wealsoobserveavariancein
where HÀÜ = EÀÜ[‚àá2‚Ñì ] is the empirical estimate
Œ∏ÀÜconf theverbalizedconfidencewithineachsetting,and
oftheHessianatŒ∏ÀÜconf andV(cid:100)ardenotestheempir-
arelativelackofoverconfidentresponses(where
icalvariance. Recallalsotheshort-handnotation
themodelis100%certain).
‚Ñì = ‚Ñì (X,H)and‚ÑìÀÜ = ‚Ñì (X,HÀÜ). Thisisagen-
Œ∏ Œ∏ Œ∏ Œ∏ WechoosethesamplingprobabilitiesœÄ accord-
i
eralizationoftheusual‚Äúsandwich‚Äùcovarianceused
ing to the theory of Zrnic and Cand√®s (2024).
inlinearregression.
For estimating the prevalences p and p ,
left right
Some estimation targets, such as the odds ra-
as well as the odds ratio O , we choose
agreement
tio, are not M-estimators but are functions of M- (cid:112)
œÄ ‚àù err (C ),asdescribedinSection3.2. For
i (cid:100)i i
estimators. Inthosecasesaconfidenceintervalis
the logistic regression coefficient Œ≤ (respec-
hedge
obtainedbyadditionallyapplyingthedeltamethod. (cid:112)
tively, Œ≤ ), we set œÄ ‚àù err (C ) ¬∑ |X‚ä§h|,
1pp i (cid:100)i i i
See(ZrnicandCand√®s,2024)forfurtherdetails.
wherehisthecolumnofH(cid:98) (definedinApp.A.1)
correspondingtoX (respectively,X ).
A.2 PowerTuning hedge 1pp
To fit err , we train an XGBoost (Chen and
(cid:100)i
Power tuning, introduced by Angelopoulos et al. Guestrin, 2016) model. For all problem settings,
(2023b), refers to choosing Œª so that the MSE of we use the same training parameters: number of
Œ∏ÀÜconf,
or equivalently its variance, is minimized boostingrounds2000,stepsize0.001,maximum
overŒª. SinceŒ£(cid:98)jj isaquadraticinŒª,theoptimalŒª depth3,andsquared-errorobjective.
hasaclosed-formanalyticalexpression. Asbefore,
A.4 ComputationofEvaluationMetrics
supposeweareinterestinginestimatingcoordinate
j ofŒ∏ÀÜconf. Leth denotethej-thcolumnofHÀÜ‚àí1. Weprovidefurtherdetailsbehindthecomputation
j
Then,wesetŒªaccordingto: ofourtwomainmetrics,effectivesamplesizeand
coverage. For all problem settings, we run 100
h‚ä§ C(cid:100)ovh simulation trials. All experiments were run on a
Œª = ,
2h‚ä§ V(cid:100)arh singleCPU.
Effectivesamplesize. Recallthatwedefinethe
where C(cid:100)ov := C(cid:100)ov(‚àá‚ÑìÀÜ Œ∏ÀÜconf( œÄŒæ ‚àí1),‚àá‚Ñì Œ∏ÀÜconfœÄŒæ)+
effective sample size of a method as the hypo-
C(cid:100)ov(‚àá‚Ñì Œ∏ÀÜconfœÄŒæ,‚àá‚ÑìÀÜ Œ∏ÀÜconf( œÄŒæ ‚àí 1)) and V(cid:100)ar := theticalvaluen
effective
suchthatMSE(Œ∏ÀÜmethod) =
V(cid:100)ar(‚àá‚ÑìÀÜ Œ∏ÀÜconf( œÄŒæ ‚àí1))areempirical(co)variances. MSE(Œ∏ÀÜ nhu effm eca tn ive),whereŒ∏ÀÜ nhu effm eca tn
ive
isobtainedviathe
See(Angelopoulosetal.,2023b)forfurtherdetails. human-only approach with n annotations.
effectivePoliteness
Politeness
0.4
0.80 0.3
0.2 0.75
0.1 0.70
0.0
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
Confidence score C
Stance Stance
0.4
0.3 0.9
0.2
0.8
0.1
0.0
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
Confidence score C
Bias Bias
0.4
0.3 0.8
0.2
0.7
0.1
0.0
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
Confidence score C
Figure3:Histogramsandcalibrationcurvesofverbalizedconfidencescores.(Left)Confidencescorehistograms
acrossthethreesettings(GPT-4o). (Right)LLMannotationaccuracywithrespecttohumanannotations(y-axis),
amonginstanceswheretheconfidencescoreisgreaterthanC(x-axis)acrossthethreesettings(GPT-4o).
SinceallapproachesbuttheLLM-onlyapproach B SupplementaryResults
are unbiased in the large-sample limit, meaning
their estimate has mean exactly equal to Œ∏‚àó, the B.1 AnAlternativeLLM
MSE is simply equal to the estimator variance. Figure4andTable3summarizetheresultsusing
Estimator variance is used in the confidence in- GPT-3.5. For n = 500, in each estimation
human
terval construction and is estimated as Œ£(cid:98)/n, as tasktheconfidence-drivenapproachagainachieves
explainedinApp.A.1. Thedifferentbaselinesdif- ahighergainineffectivesamplesizethanthenon-
fer in their choice of Œª and œÄ in the definition of adaptive approach. Moreover, it always achieves
Œ£(cid:98). We thus compute the effective sample size as a positive gain. In contrast, the non-adaptive ap-
Œ£(cid:98)h jjuman/Œ£(cid:98)jj ¬∑n,wherej indexesthecoordinateof proachachievesanegativegaininthreeoutofthe
Œ∏ÀÜconf whentheestimatehasmorethanonedimen- fiveestimationtasks(bothpolitenessestimatesand
sion. Thefinalreportedeffectivesamplesizeisthe the stance estimate). The confidence-driven and
meanofthesevaluesover100trials. non-adaptiveapproachesalwaysachieveover90%
coverage. In contrast, LLM-only coverage is al-
wayspoorusingGPT-3.5(whileusingGPT-4oit
Coverage. Weestimatecoverageover100trials.
waspooronfouroutofthefiveestimationtasks).
ForallmethodsbutLLMonly,thetrialsdifferin
therandomannotationdecisionsŒæ thatdetermine
i B.2 SensitivitytoMiscalibratedLLM
whichpointsgethuman-annotated,andweaverage
ConfidenceScores
0/1 indicators of coverage over those trials. For
LLMonly,sinceweonlyhaveonefixeddatasetof AcalibratedLLMwillproducehigherconfidence
nLLMannotations,inordertoestimatecoverage scoreswhenannotationsareinagreementwithhu-
wesimulaterandomdrawsfromapopulationvia man annotations, compared to when annotations
the bootstrap. In other words, in each trial we areindisagreementwithhumanannotations. How-
drawnLLMannotationswithreplacement,form ever,calibrationofconfidencescoresacrosstasks
aclassicalconfidenceintervalusingthosepoints, isnotguaranteed.
andrecorda0/1indicatorofcoverage. To understand how the performance of
ycneuqerF
ycneuqerF
ycneuqerF
erehw
ycaruccA
erehw
ycaruccA
erehw
ycaruccA
C >
ecnedifnoc
C
>
ecnedifnoc
C
>
ecnedifnocSetting Stage Prompttext
Politeness Stage1 Isthefollowingtextpolite?OutputeitherAorB.Outputaletteronly.
A)Polite
B)Impolite
Text:<text>
Answer:
Politeness Stage2 Howlikelyisitthatthefollowingtextis<previouslyprovidedanswer:politeorimpolite>?
Outputtheprobabilityonly(anumberbetween0and1).
Text:<text>
Answer:
Stance Stage1 Astatementcanagree,beneutral,ordisagreewiththestatement:‚ÄúClimatechange/global
warmingisaseriousconcern‚Äù. Classifythefollowingstatementintooneofthethree
categories.OutputeitherA,B,orC.Outputaletteronly.
A)Agree
B)Neutral
C)Disagree
Statement:<text>
Answer:
Stance Stage2 Howlikelyisitthatthefollowingtext<previouslyprovidedanswer:agrees,neitheragrees
nordisagrees,ordisagrees>withthestatement: ‚ÄúClimatechange/globalwarmingisa
seriousconcern‚Äù?
Outputtheprobabilityonly(anumberbetween0and1).
Text:<text>
Probability:
Bias Stage1 Whatisthepoliticalbiasofthefollowingarticle?OutputeitherA,B,orC.Outputaletter
only.
A)Left
B)Center
C)Right
Article:<text>
Answer:
Bias Stage2 Howlikelyisitthatthefollowingarticlehasa<previouslyprovidedanswer:left-leaning,
centrist,orright-leaning>politicalbias?Outputtheprobabilityonly(anumberbetween0
and1).
Text:<text>
Probability:
Table2: Completeprompttexts. LLMannotationpromptsacrossthethreesettings,forStages1and2.
CONFIDENCE-DRIVEN INFERENCEisaffectedby brated,althoughcoverageshouldbemaintained.
thecalibrationofconfidencescores,weconducted Aspredicted,astheamountofmiscalibrationin
arobustnesstest,addingnoisetoconfidencescores the confidence scores increases, the gain in the
tosimulatemiscalibration. Inparticular,forillus- effective sample size decreases (Table 4). The
trationweconsiderthetaskofanalyzingstanceon confidence-driven approach achieves the highest
globalwarming. Weaddavaryingamountofnor- gain for the smallest amount of noise, though it
mally distributed noise N(0,œÉ2) to the collected alwaysachievesapositivegain. Thissuggeststhat
confidencescoresC ,andtruncatethesumto[0,1] the approach is robust to poor confidence scores.
i
toobtainaprobability. Furthermore,CONFIDENCE-DRIVEN INFERENCE
achievesnear90%coverageorhigherineachset-
Weuseat-testtotestthedifferenceincalibration
ting, regardless of the amount of miscalibration.
score means when LLM and human annotations
Finally, we observe that CONFIDENCE-DRIVEN
agree, vs when LLM and human annotations dis-
INFERENCE achieves a higher gain than the non-
agree. If the t-statistic is large (equivalently, the
adaptiveapproachregardlessoftheextentofmis-
correspondingp-valueissmall),thatsuggeststhat
calibration. This can be explained through the
thetwomeansdiffersignificantly. Astherandom
power tuning parameter Œª; even when the con-
noiseaddedtotheconfidencescoresincreases,the
fidence scores provide no signal, power tuning
scores become less calibrated (Table 4). We ex-
makes sure that LLM annotations are leveraged
pect that our method performs worse in terms of
effectively.
n when the confidence scores are miscali-
effectivePoliteness devices
1500 1.0
1000
0.5
500
0.0
0.0 0.5 1.0 250 500 750 1000 250 500 750 1000
logistic regression coefficient n n
hedge human human
4000 1.0
3000
0.5
2000
1000
0.0
2 1 0 1 250 500 750 1000 250 500 750 1000
logistic regression coefficient n n
1pp human human
Stance on global warming
1.0
1000
0.5
500
0.0
1 2 3 600 800 1000 600 800 1000
odds ratio O n n
agreement human human
Political bias
1.0
1000
0.5
500
0.0
0.30 0.35 0.40 0.45 500 750 1000 500 750 1000
prevalence p left n human n human
1.0
1000
0.5
500
0.0
0.30 0.35 0.40 500 750 1000 500 750 1000
prevalence p n n
right human human
confidence-driven human + LLM (non-adaptive) human only LLM only
Figure4: Confidenceintervals,effectivesamplesize,andcoverage(GPT-3.5). Rowscorrespondtodifferent
estimationtasks. Thefirstcolumnshowstheconfidenceintervalsinfiverandomtrials. Theverticaldashedline
correspondstotheestimateproducedonthefulldataset. Amethodisvalidifitsconfidenceintervalincludesthis
estimate(inabout90%ofthetrials), andtighterintervalsaroundŒ∏‚àó indicatesbetterperformance. Thesecond
andthirdcolumnsdisplaytheeffectivesamplesizen andcoverage,respectively,fordifferentvaluesofthe
effective
humanannotationbudgetn . Resultsareestimatedover100trials.
human
n
n
n
n
n
evitceffe
evitceffe
evitceffe
evitceffe
evitceffe
egarevoc
egarevoc
egarevoc
egarevoc
egarevocMethod
Estimationtask Metric
confidence-driven human+LLM(non-adaptive) LLMonly
Politenessdevices Gainineff.samplesize (31.51 ¬±7.81)% (-12.23 ¬±9.18)% ‚Äî
(hedge) Coverage 92% 92% 39%
Politenessdevices Gainineff.samplesize (321.00 ¬±19.01)% (-5.77¬±30.83)% ‚Äî
(1stpersonplural) Coverage 97% 92% 67%
Stanceon Gainineff.samplesize (24.66 ¬±16.24)% (-12.13 ¬±16.95)% ‚Äî
globalwarming Coverage 92% 94% 0%
Politicalbias Gainineff.samplesize (17.08 ¬±6.30)% (3.83 ¬±4.86)% ‚Äî
(left-leaning) Coverage 93% 98% 18%
Politicalbias Gainineff.samplesize (23.10 ¬±7.50)% (11.09 ¬±5.73)% ‚Äî
(right-leaning) Coverage 95% 94% 11%
Table3: Resultssummary(GPT-3.5). Gainineffectivesamplesizeandcoverageacrossthefiveestimationtasks
forn =500,estimatedover100trials. Ineachtask,theconfidence-drivenapproachachievesahighergain
human
ineffectivesamplesize(bolded)thanthenon-adaptiveapproach. Confidence-drivenapproachalwaysachieves
a positivegain, while the non-adaptive approach sometimes achieves a negativegain. Confidence-driven and
non-adaptiveapproachesachieve near90%coverage,orhigher. Incontrast,LLM-onlycoverageis poor. Gainin
effectivesamplesizeisnotestimatedfortheLLM-onlyapproachasitdoesnotleveragehumanannotations. Errors
showastandarddeviationover100trials.
Metric
Method Confidencescorecalibrationt-test
Gainineff.samplesize Coverage
n =500
human
LLMonly ‚Äî ‚Äî 0%
human+LLM(non-adaptive) ‚Äî -3.46% 100%
confidence-driven(œÉ2 =0) t=9.08,p=2.19√ó10‚àí19 43.48% 94%
confidence-driven(œÉ2 =0.2) t=5.53,p=3.65√ó10‚àí8 40.70% 95%
confidence-driven(œÉ2 =0.4) t=3.30,p=0.000994 42.82% 94%
confidence-driven(œÉ2 =0.6) t=2.34,p=0.0192 39.57% 93%
confidence-driven(œÉ2 =0.8) t=1.88,p=0.0606 40.87% 94%
n =1150
human
LLMonly ‚Äî ‚Äî 0%
human+LLM(non-adaptive) ‚Äî 17.02% 100%
confidence-driven(œÉ2 =0) t=9.08,p=2.19√ó10‚àí19 28.14% 99%
confidence-driven(œÉ2 =0.2) t=5.29,p=1.36√ó10‚àí7 25.30% 100%
confidence-driven(œÉ2 =0.4) t=3.22,p=0.00130 25.84% 97%
confidence-driven(œÉ2 =0.6) t=2.23,p=0.0257 26.81% 100%
confidence-driven(œÉ2 =0.8) t=1.83,p=0.0831 25.71% 99%
Table4: Sensitivitytoconfidencescorecalibration. GainineffectivesamplesizeandcoveragefortheLLM
only,human+LLM(non-adaptive),andconfidence-drivenapproaches,givenvaryingamountsofmiscalibrationin
confidencescores(œÉ2). Resultsarepresentedforthetaskofanalyzingstanceonglobalwarming,estimatedover
100trials. Thet-testtestsforthedifferenceincalibrationscoremeanswhenLLMandhumanannotationsagree,vs
whenLLMandhumanannotationsdisagree(largertmeansdifferenceismoresignificant). Theconfidence-driven
approachachievesthelargestgainforthesmallestamountofnoise(bolded),anditalwaysachievesa positivegain.
Foreachamountofmiscalibration,theconfidence-drivenapproachachievesahighergainineffectivesamplesize
thanthenon-adaptiveapproach;italsoachieves near90%coverage orhigherineachsetting.Incontrast,LLM-only
coverageis poor. GainineffectivesamplesizeisnotestimatedfortheLLM-onlyapproachasitdoesnotleverage
humanannotations.