Cooperative Task Execution in
Multi-Agent Systems
Karishma1[0000−0003−3842−7408] and Shrisha Rao2[0000−0003−0625−5103]
International Instituteof Information Technology, Bangalore, Karnataka 560100
{karishma,srao}@iiitb.ac.in
Abstract. We propose a multi-agent system that enables groups of
agents to collaborate and work autonomously to execute tasks. Groups
can work in a decentralized manner and can adapt to dynamic changes
in the environment. Groups of agents solve assigned tasks by explor-
ing the solution space cooperatively based on the highest reward first.
The taskshavea dependencystructureassociated with them.Werigor-
ously evaluatedtheperformanceofthesystem andtheindividualgroup
performance using centralized and decentralized control approaches for
taskdistribution.Based ontheresults,thecentralized approachismore
efficient for systems with a less-dependentsystem G18, while thedecen-
tralized approach performs better for systems with a highly-dependent
systemG40.Wealsoevaluatedtaskallocationtogroupsthatdonothave
interdependence.Ourfindingsrevealthattherewassignificantlylessdif-
ferenceinthenumberoftasksallocatedtoeachgroupinaless-dependent
systemthaninahighly-dependentone.Theexperimentalresultsshowed
that a large numberof small-size cooperative groups of agents unequiv-
ocally improved the system’s performance compared to a small number
of large-size cooperative groups of agents. Therefore, it is essential to
identifytheoptimal groupsizefor asystem toenhanceitsperformance.
Keywords: Task execution · Cooperative execution strategy (CES) ·
Task dependencies · Cooperative agents.
1 INTRODUCTION
Inamulti-agentsystem,agroupiscomposedofindividualagentswhoworkcol-
lectivelytowardscommongoalsorobjectives.Theseagentsmaypossessvarying
degrees of autonomy and can interact with each other and their environment
to coordinate their actions. Groups are essential in multi-agent systems as they
enable agents to collaborate, coordinate, and accomplish complex tasks or ob-
jectivesthatmaybe beyondthecapabilitiesofindividualagents.Somecommon
approachestogroupagentsfortaskexecutioninamulti-agentsystemarehierar-
chicalstructure,task-orientedapproaches,role-basedapproaches,learning-based
approaches,cluster-based approaches,etc.
Multi-agent systems in grouping environments involve multiple agents that
work collaboratively to achieve specific goals within a group. MAS can be em-
ployed for dynamic task allocation within a group and overcome a distributed
4202
raM
7
]AM.sc[
1v07340.3042:viXra2 Karishma and Shrisha Rao
system’s complex task allocationproblem. Agents can negotiate for resource al-
location based on the current resource availability [1]. Within a group, agents
can work together to maximize resource utilization, guaranteeing effective use
of computational resources like virtual machines, amazon EC2 instances, and
storage [2].
Task allocation can be done using either a centralized or distributed ap-
proach[3,4].Taskschedulingisperformedusingthecentralizedapproachwithout
consideringwhere tasksor requirementschangeovertime [5,4]. A centralizedor
distributed component must schedule the m number of functions between the n
numberofagents,wheremcanbe higherthann.Inthatcase,multiple schedul-
ing rounds are required, and each task will be accomplished on its scheduled
turn [6]. A few existing algorithms for task scheduling in a distributed system
are SWARM-based approach [7,8], negotiation approach [9,10], and distributed
constraint optimization problems [11], etc.
Inthiswork,weaddressthefundamentalproblemofsolvingdistributedtasks
by groups of agents. Agents explore a solution space to execute tasks. They
collecttheinferencedataincaseofsuccessfultaskvalidation.Andthey canalso
infer a new solution by using previously explored solutions. If a task is part of
inference data, then the solution space exploration phase is not required. We
have evaluated system performance with centralized and decentralized control
for task assignment at the group level. Individual groups work in parallel to
enhance multiple agent’s efficiency and effectiveness in task execution. Tasks
have dependencies within and across groups that should be executed first. We
formulate and answer the following questions during experiments:
1. If there is a choice between centralized and decentralized control, which
should be preferred and why?
2. Will the increasein speed ofthe agentsfor solutionexplorationincrease the
system performance?
3. Willthegroupsgettasksdistributedequallyinbothless-dependentsystems
(LDS) and highly-dependent systems (HDS)?
Thesimulationresultsshowthatdividingagentsintosmallergroupsimproves
the system’s performance (see Table 1). We have evaluated task allocation to
groups that don’t have inter-dependency, and we have observed that the tasks
werealmostevenlydistributedforLDSbutnotinHDS(seeFigure3). LDSG
18
and HDS G are defined by Karishma and Rao [12], where G is comprised
40 40
of 40 nodes that are highly interlinked, with each node representing a specific
task, and G contains 18 tasks with fewer links. Evaluation of centralized and
18
decentralized control approaches shows that the centralized approach performs
betterforasystemwithlessnumberoftasks,whereasthedecentralizedapproach
performs better for a large-scale system (see Figure 2 and Table 2). Evaluation
of task distribution shows that LDS performs better when tasks assigned to a
group are not dependent on the other group’s task( independent set of tasks),
whereas HDS performs better when the inter-dependency exists with the other
group’s tasks (see Table 3).Cooperative Task Execution in Multi-Agent Systems 3
The mathematical results prove the transitivity of knowledge within the
group due to the sharing of gained knowledge between the agents (see Theo-
rem 1). It also formulates the expected waiting time E[W] due to dependencies
between the tasks, which equals Θ(mkpk) (see Theorem 4). This is in line with
the results, which are shown in Table 3. Mathematical results to identify the
optimalgroupsizeshowthatsystemperformanceisbetterwiththesmallsizeof
a large number of groups over the large size of a small number of groups based
on the expected system execution time (see Theorem 6 and Table 1).
The rest of the paper is structured as follows. Section 2 provides the details
aboutthe systemmodel,andit alsoexplainsthe cooperativeexecutionstrategy
forgroupsofagents.Section3presentstheexperimentalresultsobtainedthrough
simulation, and it also describes the mathematical results.
2 COOPERATIVE EXECUTION STRATEGY FOR
GROUPS OF AGENTS
We present a model for a multi-agent system, which has a set of cooperative
agents working on inter-dependent tasks to explore solution space and execute
the tasks. We are paving the way for an efficient and effective system design by
evaluating both centralized and decentralized task allocation approaches.
2.1 System Model
We present a multi-agent system model that has requirements to execute and
implement a set of tasks by a set of groups.Tasks have some dependency struc-
tureamongthem.Agrouphasasetofcooperativeagentswhosharetheirgained
knowledge within the group.
Fig.1. Task DependencyGraph G10 for groups.
Wehaveasetoftasks,eachwithafixedrewardandasetofdependenttasks.
We divide the agentsinto multiple groupsto distribute the workloadamongthe
groups instead of controlling from a centralized entity. To execute tasks, we4 Karishma and Shrisha Rao
divide them into multiple subsets so that each group of agents can work on
their tasks without affecting other groups. For this, we split the rewards and
dependencies accordingly.We make surethat noduplicity oftasksexists among
the groups. A group g can get a set of tasks that may be dependent on tasks
i
thatbelongtogroupg ,similartoFigure1.AgraphG [13]illustratesthetask
j 10
distributionto twodifferent groupsand hastask inter-dependencies.A taskcan
only be scheduled for execution once all the tasks in its dependency list are
executed. We prioritize the tasks based on the rewardfactor.Agents within the
group share the explored solution and inference data within the group but not
outside the group.The advantageofnot sharingknowledgeoutside the groupis
that it reduces the communication overhead.
We consider a standard system model of n agents, l groups, and m tasks.
We’ll represent the information about tasks, solutions, groups, and the agent’s
knowledge using a mathematical model. Let:
– A, G, T, and S are the sets of agents, groups, tasks, and solutions, respec-
tively.
– a ∈A denotes the i-th agent.
i
– g ∈G denotes the k-th group.
k
– t ∈T represents the j-th task.
j
– s ∈S denotes the solution corresponding to task t .
j j
We have a set of rewards R and a set of dependencies D associated with
our task set T, where d ⊆ T \ {t } consists of a set of tasks on which t
j j j
is dependent. To explore the solution space, we have divided n agents into l
groups, each containing n/l agents. A represents a subset of agents that
subset
is allocated to group g . We have created l subsets of the task set T, which we
k
represent as T . We have also created respective subsets of rewards R
subset subset
and dependencies D .
subset
A task assignmentfunction λ assigns a subset of tasks from T to group
subset
g . It is denoted as λ(g ):2Tsubset →A. The function ensures that task assign-
k k
ments to different groups are non-overlapping, meaning that λ(g )∩λ(g ) = ∅
k h
if k 6=h. µ(g ) representsthe setof tasks accomplishedby g suchthat µ(g )⊆
k k k
λ(g ).
k
We have used a set K(a ) to represent the knowledge of an agent a , where
i i
K(a )contains{(t ,s )|t isataskands isasolution}.WehaveusedK(g )to
i j j j j j
represent the knowledge of a group g by adding all knowledge of all the agents
j
belonging to the same group. If a agent subset {a ,a ...,a } assigned to group
1 2 p
g then,
j
K(g )= K(a )
j p
p
[
Every task t has a corresponding solution s . If a knows s for some task
j j i j
t ,thena alsoknowsthe inferencedataoft .Ift belongstotheinferencedata
j i j k
of t , then s = s . The inference data of a group is calculated by adding the
j k j
inference data collected by each agent in the group and denoted as I(g )
iCooperative Task Execution in Multi-Agent Systems 5
2.2 CES Algorithm
This section explains the strategy for exploring the solution space by groups of
agents. In a distributed system, all agents are divided into different groups to
work on a set of tasks. Each set of tasks is further divided into subsets, and
eachgroupofagentsisassignedaspecificsubsetoftaskstoworkon.Theagents
in each group work together to explore solutions for their assigned tasks. Once
they have found a solution, they execute the task. Coordination among agents
in the same group is often necessary to share the gained knowledge during the
task execution process.
Algorithm 1 describes the solution space exploration at the group level. In
this approach, a group is assigned a set of agents who will execute a set of
tasks by considering the respective rewards and dependencies. The group has a
centralized control that takes care of task assignment and validation. Later, we
enhancedthe systembyaddingthe decentralizedtaskdistributionwhereagents
pull tasks from the set of available tasks within the group.
Algorithm 1 Solution Space Explorationat Group Level Algorithm
Input: T : A subset of tasks, R : A subset of respective rewards, D : A
subset subset subset
subset of respective dependencies, A : A subset of agents
subset
Output: Share knowledge with all the agents within the
group
1: A ←getAvailAgents()
avail
2: T ←getAvailTasks(T ,R ,D ,A )
avail subset subset subset avail
3: // Assign thetasks to available agents within thegroup
4: taskAssignment(T ,A )
avail avail
5: whiletruedo
6: // On receive event listener for solution validation from an agent a i
7: validateSolution(tj,sj)
8: // Allocate thereward based on thevalidation result of thesolution for t j
9: allocateReward(ai,T subset,R subset)
10: if isRewarded then
11: // Removethedependencies from the dependenttask on t j
12: updateDependencies(tj)
13: for eacha i∈A
subset
do
14: shareKnowledge(t j,s j,A subset)
15: endfor
16: endif
17: go to 1
18: endwhile
Algorithm 1 accepts a subset of tasks T with respective dependencies
subset
D andrewardsR .Solution spaceexplorationis performedby A
subset subset subset
agents. As a result, the knowledge gained by all the A agents is shared
subset
among them. In algorithm 1, in line 1, get the available agents to execute the
tasks. Initially, all the agents are available, but it’s possible that a few agents6 Karishma and Shrisha Rao
are working on solution space exploration in the next iteration. In line 2, get
the available tasks for the available agents. In line 4, it assigns unique tasks to
available agents. If the available tasks are less than the available agents, then
a few agents do not get any task assigned. In line 7, the centralized entity in
a group validates the explored solution s for a task t . In line 9, it allocates a
j j
rewardfortheexploredsolutions ifitisvalid;otherwise,thereisnorewardfor
j
taskt .Inline12,dependenciesonthetaskt areremovedfromthedependency
j j
set for all the remaining tasks only if the reward is allocated for the task t . In
j
line 14, it shares the gained knowledge by an agent a to all the agents who are
i
part of set A .
subset
3 RESULTS
We present mathematical and simulation results for a cooperative execution
strategy to execute tasks by groups of agents.
3.1 Mathematical Results
Here are some essential mathematical results for gained knowledge, comparing
the impact of various sizes of the groups and evaluating the expected waiting
time of a task when the dependency graph is associated among the tasks.
Theorem 1 (Transitivity on Knowledge). If t ∼ t , agent a knows the
k l i
solution for task t :(t ,s )∈k(a ) and two agents, a and a belong to the same
k k k i i j
group: a ,a ∈g , then (t ,s )∈k(a ).
i j p l k j
Observation 2 (Impact ofAgent’s SpeedVariation). Increasingthe number of
faster agentsin highly-dependentsystems may notincreasethe system’s perfor-
mance.
Observation 3 (Impact of Task Dependencies). Task distribution is uneven in
both less-dependent systems (LDS) and highly-dependent systems (HDS) (see
Figure 3).
Theorem 4 (Impact of Dependencies on Expected Waiting Time for
LDS). Consider the same multi-agent system as defined previously with a set of
m tasks T and agents A. Let the dependency graph among tasks have maximum
degree k < m−1, so each task depends on at most k other tasks. Let p be the
probability a dependency is unresolved. Then, the expected waiting time scales as
E[W]=Θ(mkpk).
Proof. For each task t , define a binary random variable X :
i i
1 if t has unresolved dependencies
i
X =
i
(0 otherwise
And the total waiting time is W = m X .
i=1 i
PCooperative Task Execution in Multi-Agent Systems 7
Since the maximum degree is k, each task has at most k dependencies. By
the law of total probability:
E[X ]=1−(1−p)k
i
Therefore, the expected total waiting time is:
m
E[W]= E[X ]
i
i=1
X
=m(1−ekln(1−p))
Using the Taylor approximationex ≈1+x for small x:
E[W]≈m(1−(1+kln(1−p)))
=mk(−p)k
=Θ(mkpk)
Thus,thewaitingtimescalesasΘ(mkpk)whenthemaximumdependencydegree
is k.
Theorem 5 (Impact of Dependencies on Expected Waiting Time for
FullyConnected Graph ).Consider amulti-agentsystemwithasetofagents
A = {a ,...,a } and a set of tasks T = {t ,...,t } where |T| = m. Let the
1 n 1 m
dependency graph among tasks be fully connected, such that each task t depends
i
on all other tasks t where j 6=i. Let d=m−1 be the number of dependencies
j
per task.Further,assumethattheprobability ofanydependency beingunresolved
is a constant p ∈ (0,1). Then, the expected waiting time E[W] for an agent to
receive an executable task scales as Θ(mpd).
Table 3 presents the total waiting time caused by task dependencies for two
systems: one with low dependency and one with high dependency, which is in
line with Theorem 4 and Theorem 5
Theorem 6 (Optimal Group Size). Consider a multi-agent system with n
agents of fixed capability, partitioned into l groups, exploring a set of m indepen-
dent tasks. Let T(g ) be the random variable denoting the time taken by group
k
g to complete its assigned tasks. If the number of groups l increases while keep-
k
ing n and m fixed, thereby decreasing the group size, then the expected system
execution time E[max T(g )] decreases.
k k
Proof. With m independent tasks split evenly between groups, each group gets
m/l tasks.Sinceagentshavefixedcapabilities,the groupcompletiontime T(g )
k
is approximately normally distributed according to the central limit theorem,
with E[T(g )]=(m/l)/v where v is the fixed agent capability parameter.
k
Additionally, Var(T(g )) = σ2 where l = n is the group size, and σ2 mea-
k lk k l
sures variability inherent to the tasks and environment.8 Karishma and Shrisha Rao
Since max(X ,...,X )≤X +...+X , we have:
1 n 1 n
m
E maxT(g ) ≤E T(g ) =lE[T(g )]=
k k k
(cid:20) k (cid:21) " k # v
X
Thisexpectedmaxgrouptimeisconstantwithrespecttochangesinl.How-
ever, increasing groups l reduces group size l , thereby increasing the variance
k
Var(T(g )). By properties of distributions of maxima:
k
E maxX ≤E maxY if X ≤ Y ∀k
k k k st k
k k
(cid:20) (cid:21) (cid:20) (cid:21)
Smaller groups have a higher variance in completion times. Therefore, mov-
ing from fewer groups/larger groups to more groups/smaller groups reduces
E[max T(g )], the expected system execution time. This demonstrates that
k k
smaller groups improve expected performance.
Inourcase,increasingthenumberofgroupslshrinksthegroupsizel ,which
k
inturnincreasesthevarianceVar(T(g ))ofeachgroup’scompletiontime.Higher
k
varianceindicatesthedistributionismorespreadout,meaninggroupcompletion
time is stochastically greater with smaller groups. Therefore, smaller groups
reduce the expected system execution time. Experimental results in Table 1
confirm that system performance is better with a large number of small-size
groups instead of a small number of large-size groups.
3.2 Experimental Results
The effectiveness of cooperative solutions for the execution of tasks is being
tested across different scenarios. These include the distribution of tasks among
multiple groups, the time taken by groups to explore solutions, the time taken
by the system to explore solutions, variation in the speed of agents, adopting
differentapproachestotaskassignmentamongtheagentgroups,andtheimpact
ofHDSG ,andLDSG .Weconductexperimentswherewegeneratearandom
40 18
maze with a random target location and vary the maze size. Multiple groups
explore solutions on a maximum maze size of 400× 400 in parallel, and our
designed model can handle task dependencies to simulate real-time scenarios.
The graph presented in Figure 2 compares two approaches for system per-
formance. The first approach involves a centralized entity that assigns tasks to
all agents within the group, while in the second approach, an individual agent
selects their own tasks from a set of available tasks. The graph indicates that
the first approach is more efficient for a small number of tasks, but the second
approachoutperformsitforalargernumberoftasksintermsofexecutiontime.
Wehavetestedtheperformanceofourmodeldesignedforgroupsbyvarying
thenumberofgroupsfrom1to10.Duringtheexperiment,showninTable1,each
groupconsistedof5agentswhilemaintainingaconstantnumberoftasksat500.
Each group was assigned tasks that depended on the tasks of the other groups.Cooperative Task Execution in Multi-Agent Systems 9
centralized control
2,100 decentralized control
1,800
1,500
1,200
900
600
300
0
20 40 80 120 160 200 240
Tasks Count
Fig.2. System performance for centralized and decentralized group approach.
Table 1. Varyingnumberof groups to explorethe 500 tasks
GroupsEEETTT(((ggg kkk)))System’s Execution Time
1 2458.30 2458.50
2 1631.64 1705.09
4 859.50 924.36
6 635.66 686.5
8 487.14 534.94
10 368.32 409.46
ET(g )denotes the averageexecutiontime in secondstakenbya groupg .Our
k k
results indicate that increasing groups improves the system’s execution time.
If we divide tasks among the groups, then it adds the complexity of dividing
the tasks among groups and then collecting results. Our result confirms the
system’sstabilityinthecaseofmanygroups,whichdoesnotreducethesystem’s
performance. The system’s execution time is always higher than the ET(g )
k
because of several additional jobs at the system level, like splitting the tasks
among the groups and collecting the results at the end.
Table 2.Individualgroupperformance andwaiting timeinasystem withcentralized
and decentralized control at thegroup level
Centralized Control Decentralized Control
Group EEETTT(((ggg kkk)))|||λλλ(((ggg kkk)))|||TTTWWWTTT(((ggg kkk)))EEETTT(((ggg kkk)))|||λλλ(((ggg kkk)))|||TTTWWWTTT(((ggg kkk)))
1 132.39 18 34.06 125.0 18 14.43
2 128.41 18 30.34 123.26 18 15.07
3 139.02 18 35.09 122.92 18 11.15
4 128.89 18 27.23 121.56 18 15.84
5 141.14 18 29.67 126.04 18 18.38
)s(
emit
noitarolpxE
metsyS10 Karishma and Shrisha Rao
Table 2 displays the performance of each group and the total waiting time
of agents at the group level. This experiment is conducted on a system with a
dependencyliketheG programgraphand400∗400mazesize.Inthecentralized
18
control approach, task assignment is taken care of by the centralized entity of
each group, whereas, in the decentralized approach, each agent pulls the task
fromtheavailabletaskswithinthesamegroup.Thewaitingtimeforeachgroup,
denotedasTWT(g ),iscalculatedbyaddingthe waitingtime ofallagentswho
k
belong to the same group. The result shows that ET(g ) and TWT(g ) for the
k k
decentralizedcontrolapproacharebetter thanthe centralizedcontrolapproach.
Table3.Individualgroupperformanceandwaitingtimeinasystemwithdecentralized
control at group level
System Dependency System executionTotal Waiting
time(s) time(s)
less- inter-dependency 631.67 61.56
dependent 628.41 62.18
629.81 60.84
independency 619.49 37.85
613.88 34.05
601.24 32.56
highly- inter-dependency 710.80 98.67
dependent 718.15 93.97
709.65 96.08
independency 725.80 84.52
732.65 76.50
728.34 81.53
Asperthedesign,tasksdistributedamongthegroupshaveinter-dependency,
andthatcanincreasethewaitingtimeofanagenttogetatasktoexecute.So,we
conductedanexperimentontwosetsofgroupswherethefirstsetofgroupshada
set of tasks without task-dependency across the groups.In contrast, the second
set of groups had inter-dependency among the tasks across the groups. Each
grouphad 80tasks to implement. Table 3 showsthe system executionandtotal
waitingtimeforbothLDSandHDS.Totalwaitingtimeisthesumofthewaiting
time of all the agents at all the groups in the system. The result shows that
both total waiting time and system execution are always less when comparing
inter-dependency and independent tasks among the groups for LDS. For HDS,
total waiting time is less, but system execution time is more when comparing
inter-dependency and independent tasks among the groups. This is because of
the additional step to identify the subsets of tasks that are not dependent on
another subset of the tasks but can be dependent on another task that belongs
to the same group.
We have done a comparison of the execution time taken by three different
groups whose agents have dissimilarities in the speed to explore the solutionCooperative Task Execution in Multi-Agent Systems 11
space. Obtained results suggest that increasing the speed of agents within a
group does not necessarily improve system performance linearly due to the de-
pendencies on the other tasks.
g g
k k
200 g 200 g
l l
160 160
120 120
80 80
40 40
40 120 200 280 40 120 200 280
(a)Task distribution (b)Task distribution
in LDS in HDS
Fig.3. Task distribution between groups of agents in LDSand HDS.
Weallocatethesubsetoftaskstodifferentgroupswithoutanyinter-dependency.
Figure 3(a) shows the number of tasks allocated to groups g and g for a LDS.
k l
Figure 3(b) showsthe number of tasks allocated to groups g and g for a HDS.
k l
Figure 3(a) and Figure 3(b) show that the difference between the number of
tasks allocated to two different groups in a LDS is less when compared with a
HDS. Experimental results conclude that:
1. It is better to use a centralized control approach when the number of tasks
is less in the system; a decentralized controlapproachis preferred when the
number of tasks is huge (Figure 2).
2. A large number of small-size cooperative groupsof agents improvesthe sys-
tem’s performance when compared with a small number of large-size coop-
erative groups of agents (Table 1).
3. Increasingthespeedofagentsinthegroupsimprovesthesystemperformance
up to a certain point due to inter-dependencies on the other group’s tasks.
4. Due to the dependency, tasks are not evenly distributed for both LDS and
HDS (Figure 3).
5. System performance is better in LDS when groups get an independent set
of tasks (no task dependency on other group’s tasks), whereas system per-
formance in HDS is better when groups have an inter-dependency of tasks
among groups (Table 3).
4 CONCLUSIONS
After dividing the agents into multiple groups, we investigated the system per-
formance and distributed severaljobs, like task assignment, solution validation,
reward allocation, etc., to groups. We evaluated the system performance and
individualgroupperformancewith the centralizedanddecentralizedcontrolap-
proaches for task distribution. In this case, agents share knowledge within the
tnuoC
sksaT
tnuoC
sksaT12 Karishma and Shrisha Rao
respectivegroup,whichreducesthecommunicationoverhead.Wehavealsoeval-
uated task allocation to groups that don’t have interdependence, and we have
observed that the difference in the number of tasks allocated to each group is
less in a LDS compared with a HDS. Varying group size analysis shows that a
large number of small-size groups performs better when compared with a small
number of large-size groups. This result will be beneficial when the system has
a requirement to identify the optimal group size.
References
1. Y.Shen,“Bioniccommunicationnetworkandbinarypigeon-inspiredoptimization
for multiagent cooperative task allocation,” IEEE Transactions on Aerospace and
Electronic Systems, vol. 58, no. 5, pp.3946–3961, 2022.
2. D.Gudu,M.Hardt,and A.Streit,“On mas-based,scalable resource allocation in
large-scale, dynamicenvironments,”in2016 Intl IEEEConferences on Ubiquitous
Intelligence & Computing, Advanced and Trusted Computing, Scalable Comput-
ing and Communications, Cloud and Big Data Computing, Internet of People,
and Smart World Congress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld),
pp.567–574, 2016.
3. K. Macarthur, Multi-agent coordination for dynamic decentralised task allocation.
PhD thesis, University of Southampton,2011.
4. X. Zheng and S. Koenig, “Reaction functions for task allocation to cooperative
agents,” in Proceedings of the 7th international joint conference on Autonomous
agents and multiagent systems-Volume 2, pp.559–566, Citeseer, 2008.
5. O.Shehory and S. Kraus, “Methods for task allocation via agent coalition forma-
tion,” Artificial intelligence, vol. 101, no. 1-2, pp.165–200, 1998.
6. S.D.Ramchurn,M.Polukarov,A.Farinelli,N.Jennings,andC.Trong,“Coalition
formation with spatial and temporal constraints,” 2010.
7. J. Du, Z. Ling, Q. Peng, S. Zhen, and L. Yang, “Task allocation in multi-agent
systemswithswarmintelligenceofsocialinsects,”in2010SixthInternationalCon-
ference on Natural Computation, vol. 8, pp. 4322–4326, IEEE, 2010.
8. P. Ghassemi, D. DePauw, and S. Chowdhury, “Decentralized dynamic task al-
location in swarm robotic systems for disaster response,” in 2019 international
symposium on multi-robot and multi-agent systems (mrs), pp.83–85, IEEE, 2019.
9. H.Luo,X.-j.Hu,andX.-x.Hu,“Multiagentnegotiationmodelfordistributedtask
allocation,” in 2010 2nd IEEE International Conference on Information Manage-
ment and Engineering, pp.54–57, IEEE, 2010.
10. W. Wang and Y. Jiang, “Community-aware task allocation for social networked
multiagent systems,” IEEE transactions on cybernetics, vol. 44, no. 9, pp. 1529–
1543, 2013.
11. S.D.Ramchurn,A.Farinelli,K.S.Macarthur,andN.R.Jennings,“Decentralized
coordination in robocup rescue,” The Computer Journal, vol. 53, no.9, pp.1447–
1461, 2010.
12. KarishmaandS.Rao,“Cooperativesolutionstoexplorationtasksunderspeedand
budget constraints,” Journal of Simulation, vol. 17, no. 6, pp.676–687, 2023.
13. Y. Bian, Y. Sun, M. Zhai, W. Wu, Z. Wang, and J. Zeng, “Dependency-aware
task scheduling and offloading scheme based on graph neural network for mec-
assisted network,” in 2023 IEEE/CIC International Conference on Communica-
tions in China (ICCC Workshops), pp. 1–6, 2023.