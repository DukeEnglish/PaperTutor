Explaining Bayesian Optimization by Shapley Values
Facilitates Human-AI Collaboration
JulianRodemann1, FedericoCroppi1, PhilippArens2, YusufSale3,4,
JuliaHerbinger1,4, BerndBischl1,4, EykeHu¨llermeier3,4, ThomasAugustin1,
ConorJ.Walsh2,5 and GiuseppeCasalicchio1,4
1DepartmentofStatistics,Ludwig-Maximilians-Universita¨t(LMU)Munich
2 JohnA.PaulsonHarvardSchoolofEngineeringandAppliedSciences,HarvardUniversity
3InstituteofInformatics,Ludwig-Maximilians-Universita¨t(LMU)Munich
4MunichCenterforMachineLearning(MCML)
5 WyssInstituteforBiologicallyInspiredEngineering,HarvardUniversity
Abstract transparencyandinterpretabilityinAIsystemsisnotmerely
an academic pursuit but a necessity for ensuring trust, ac-
Bayesian optimization (BO) with Gaussian pro-
countabilityandethicaldeploymentofsuchtechnology. The
cesses(GP)hasbecomeanindispensablealgorithm
termsexplainableAI(XAI)andinterpretablemachinelearn-
for black box optimization problems. Not without
ing(IML)areoftenusedinterchangeablyanddescribeefforts
adashofirony,BOisoftenconsideredablackbox
tohelpelucidatedecision-makingprocessesofintricatelearn-
itself, lacking ways to provide reasons as to why ingalgorithms. Whilethepursuitforinterpretabilityisnota
certain parameters are proposed to be evaluated.
newendeavor, thewidespreadadoptionofsophisticatedML
This is particularly relevant in human-in-the-loop
models has intensified the need for IML methods. A broad
applicationsofBO,suchasinrobotics.Weaddress
spectrumofapproacheshasemergedinrecentyears,ranging
thisissuebyproposingShapleyBO,aframework
from model-agnostic techniques to inherently interpretable
for interpreting BO’s proposals by game-theoretic
modelarchitectures,see[Molnaretal.,2020,Molnar,2020]
Shapley values. They quantify each parameter’s
foranoverview.
contributiontoBO’sacquisitionfunction. Exploit-
This paper expands the focus of interpretability from ML
ing the linearity of Shapley values, we are further
models to black-box optimizers such as Bayesian optimiza-
abletoidentifyhowstronglyeachparameterdrives
tion(BO)withGaussianProcesses(GPs).Optimizationtech-
BO’s exploration and exploitation for additive ac-
niques of this kind find parameter configurations that opti-
quisition functions like the confidence bound. We
mize some unknown and expensive-to-evaluate target func-
also show that ShapleyBO can disentangle the
tionbyefficientlysamplingfromit. Theyplayanimportant
contributionstoexplorationintothosethatexplore
roleinAIandareoftenperceivedasblackboxesthemselves.
aleatoricandepistemicuncertainty. Moreover,our
Understandingandinterpretingsuchoptimizationapproaches
method gives rise to a ShapleyBO-assisted hu-
can increase trust in systems that rely on them, mitigating
man machine interface (HMI), allowing users to
algorithmic aversion [Dietvorst et al., 2015, Burton et al.,
interfere with BO in case proposals do not align
2023]. What is more, IML techniques can help speed up
withhumanreasoning. WedemonstratethisHMI’s
the optimization in a human-AI collaborative setup directly.
benefitsfortheusecaseofpersonalizingwearable
Here, a human can intervene and reject or rectify proposals
roboticdevices(assistivebackexosuits)byhuman-
madebyBO[Venkateshetal.,2022]. Abetterunderstanding
in-the-loop BO. Results suggest human-BO teams
ofthealgorithmfostershuman-machineinteractionwhichis
with access to ShapleyBO can achieve lower re-
keyinsuchapplications,aswedemonstrateinthiswork.
gretthanteamswithout.1
We focus on explaining Bayesian optimization. In par-
ticular, we will interpret proposed parameter configurations
1 Introduction through Shapley values, a concept from cooperative game
theory that has gained much popularity in IML. Our frame-
Inartificialintelligence(AI)andmachinelearning(ML),the
work ShapleyBO informs users about how much each pa-
black-box nature of increasingly complex models poses se-
rameter contributed to the configurations proposed by a BO
rious challenges to end-users and researchers alike. As so-
algorithm. Thekeyideaistoquantifyeachparameters’con-
phisticated algorithms have become more and more preva-
tributiontotheacquisitionfunctioninsteadoftothemodel’s
lent in critical aspects of society, the ability to comprehend
predictions, as would be customary in IML. Loosely speak-
their decision-making becomes paramount. The need for
ing,theacquisitionfunctiondescribeshow“informative”BO
1ImplementationofShapleyBOandcodetoreproducefindings considers a given parameter configuration. A Shapley value
availableathttps://anonymous.4open.science/r/ShapleyBO-E65D. can thus inform the user how much a single feature con-
4202
raM
7
]GL.sc[
1v92640.3042:viXratributes to this informativeness. In each iteration, BO pro- anddemonstratethatourmethodcanspeeduptheprocedure
posesparametersthatmaximizetheacquisitionfunction. By throughmoreefficienthuman-machineinteraction.
computing Shapley values for these points, we can inform
BOusersastowhythisparticularconfigurationhasbeense- 2 Background
lectedoverothers. SinceShapleyvaluesarelinearinthecon-
2.1 BayesianOptimization
tributionstheyexplain,seeAxiom3inSection2.2,theycan
be used to inform us about how much each parameter con- Bayesian optimization (BO) is a popular derivative-free op-
tributedtoeachcomponentofanyadditiveacquisitionfunc- timizer for functions that are expensive to evaluate and lack
tion like the popular confidence bound. This turns out to be an analytical description. Its origin dates back to [Mocˇkus,
particularly helpful for disentangling parameters’ contribu- 1975]. ModernusecasesofBOcoverengineering,drugdis-
tions to exploration (uncertainty reduction) and exploitation covery and finance as well as hyperparameter optimization
(mean optimization) in Bayesian optimization. Trading off and neural architecture search in ML, see e.g. [Frazier and
thesetwoisfundamentaltoBO.Whileexploitationdescribes Wang, 2016, Pyzer-Knapp, 2018, Snoek et al., 2012] . BO
the incentive to greedily optimize based on existing secured approximates the target function through a surrogate model
knowledge,explorationisaboutriskingtoevaluatethetarget (SM). In the case of real-valued parameters, the latter typi-
functions in regions where less prior knowledge is available callyisaGaussianprocess(GP).BOthencombinestheGP’s
inordertoreduceuncertaintyaboutthose. mean and standard error predictions to an acquisition func-
In the theoretical part of this paper, we delve further into tion (AF), that is optimized in order to propose new points.
thisdistinction. Inparticular,weproposeamethodtofurther Algorithm1summarizesBayesianoptimizationappliedtoan
dissecttheexploratorycomponentintodifferentkindsofun- optimizationproblem
certaintiesthataproposalseekstoreduce. Inspiredbyrecent
minf(θ). (1)
advancementsinuncertaintyquantification[Hu¨llermeierand
θ∈Θ
Waegeman, 2021], we suggest disentangling a parameter’s
exploratory contribution into the reduction of aleatoric and Observationsofthetargetfunctionf aregeneratedthrough
epistemic uncertainty. Aleatoric uncertainty (AU) emerges Ψ:Θ→R,θ (cid:55)→f(θ)+ϵ, (2)
throughinherentstochasticityofthedata-generatingprocess,
omittedvariablesormeasurementerrors. Consequently, AU with Θ a p-dimensional parameter space and ϵ a zero-mean
is a fixed, but unknown quantity. On the other hand, epis- real-valuedrandomvariable. Thatis,weobserveanoisyver-
temicuncertainty(EU)isduetolackofknowledgeaboutthe sion Ψ(θ) of continuous f(θ). Here and henceforth, min-
best way to model the underlying data-generating process. imization is considered without loss of generality. We will
As such, it is in principle reducible. Moreover, EU can be furtherrestrictourselvestoGPsasSMsandfocusonthecon-
furthersubdividedintoapproximationuncertaintyandmodel fidence bound (CB) as an AF, see Section 3. In the human-
uncertainty, see [Hu¨llermeier and Waegeman, 2021]. While in-the-loop setup, a user can intervene by either rejecting a
approximationuncertaintyiswell-describedbyBO’sinternal proposal(line4inAlgorithm1)oranupdate(line6inAlgo-
variance prediction, we deploy a set-valued prior near igno- rithm1)orbyproposinganotherconfiguration,seeSection5.
ranceGP[Mangili,2016,RodemannandAugustin,2022]to
measurethemodeluncertainty.
Algorithm1BayesianOptimization
We further integrate ShapleyBO into human-AI collab-
orative BO. We propose a Human-Machine Interface (HMI) 1: createaninitialdesignD ={(θ(i),Ψ(i))} i=1,...,ninit
thatallowsuserstobetterunderstandBO’sproposalsanduti- 2: whileterminationcriterionisnotfulfilleddo
lize this understanding in deciding whether to intervene and 3: trainSMondataD
rectify proposals or not. Experiments on data from a real- 4: proposeθnew thatoptimizesAF(SM(θ))
world use case of personalizing assistance parameters for a 5: evaluateΨonθnew
wearablebackexosuitsuggestthatsuchanunderstandingcan 6: updateD ←D∪(θnew,Ψ(θnew))
helptointervenemoreefficientlythanwithouttheavailability 7: endwhile
ofShapleyvalues,thusspeedinguptheoptimization. 8: returnargmin θ∈DΨ(θ)
Insummary,wemakethefollowingcontributions.
(1) We explain why parameters are proposed in Bayesian
2.2 ShapleyValues
optimizationbyquantifyingeachparameters’contributionto
aproposalthroughShapleyvalues. Shapleyvaluesarea conceptfromcooperativegametheory,
(2) We further distinguish between parameters that drive originallyintroducedby[Shapley,1953],thatcanbeusedto
exploitation (mean optimization) and exploration (uncer- measure the contribution of each feature to a prediction in
tainty reduction) in Bayesian optimization, utilizing the lin- an ML model. The key idea is to consider each feature as
earityofShapleyvalues. a player in a game where the prediction is the payoff, and
(3) Exploratory uncertainty reduction is in turn dissected to distribute the payoff fairly among the players according
intoaleatoricandepistemicsourcesofuncertainty,whichfos- to their marginal contributions. Shapley values have several
terstheoreticalunderstandingofBayesianoptimization. desirablepropertiesthatmakethemappealingforinterpreting
(4) We apply our framework to simulated exosuit cus- optimizationproblems.Ingeneral,givenasetofplayersP =
tomizationthroughhuman-in-the-loopBayesianoptimization {1,...,p} and a value or payout function v : 2P → R thatassigns a value v(S) to every subset (called a coalition in Nevertheless,thereissomeworkonShapley-basedexplana-
gametheory)S ⊆P (suchthatv(∅)=0),theShapleyvalue tions of other optimization algorithms such as evolutionary
ϕ (v)ofplayerjisdefinedintermsofaweightedaverageof algorithms [Wang and Chen, 2023] or differentiable archi-
j
allitsmarginalcontributions[Peters,2015]: tecturesearch(DARTS)indeeplearning[Xiaoetal.,2022].
There are even efforts to utilize Shapley values to improve
(cid:88) |S|!(p−1−|S|)! optimizers similar to our Shapley-assisted human-BO team.
ϕ j(v)=
p!
[v(S∪j)−v(S)] (3) Forinstance,[Wu,2023]solvesfuzzyoptimizationproblems
S⊆P\{j} by integrating Shapley values with evolutionary algortihms
and [Bakshi et al., 2023] use Shapley values to speed up
TheShapleyvaluecanbejustifiedaxiomaticallythroughthe
multi-objective particle swarm optimization grey wolf opti-
propertiesofdummyplayer,efficiency,linearity,andsymme-
mization(PSOGWO).
try,seee.g.[Croppi,2021].
Generally, there has been a lot of interest in how to in-
Dummyplayer. Ifv(S∪{j})=v(S)forplayerjand∀S ⊆
corporate human knowledge in optimization loops recently
P\{j},thenϕ (v)=0.
j [AV et al., 2024, Akata et al., 2020, Venkatesh et al., 2022]
Efficiency.
(cid:80)p
j=1ϕ j(v)=v(P)−v(∅) and what role IML can play in this regard [Paleja et al.,
2021]. This growing interest is not only sparked by fine-
Linearity. Given two games (P,v ) and (P,v ) and any
1 2
a,b∈R,thefollowingholds: tuning large language models through reinforcement learn-
ing from human feedback [Rafailov et al., 2024], but also
ϕ j(av 1+bv 2)=aϕ j(v 1)+bϕ j(v 2) by chemical applications [Cisse et al., 2023]. Very recently,
Symmetry. Ifv(S∪{j}) = v(S∪{l})forplayersj,land [Adachi et al., 2024] introduced Collaborative and Explain-
everyS ⊆P\{j,l},thenϕ (v)=ϕ (v). able Bayesian Optimization (CoExBo) for lithium-ion bat-
j l
tery design, a framework that integrates human knowledge
The contribution function does not require any specific
into BO via preference learning and explains its proposals
propertiesandtheShapleyvaluecanhencebeusedinmany
by Shapley values. Contrary to our approach, CoExBo first
different applications [Fre´chette et al., 2015, p.3]. Indeed it
aligns human knowledge with BO by preference learning.
hasrecentlybecomeastateoftheartmethodwithinthefield
In a second step, it then proposes several points and allows
ofIML(see,e.g.,[LundbergandLee,2017,Lundbergetal.,
theusertoselectamongthembasedonadditionallyprovided
2018]),butithasalsobeenadaptedinAutoMLtoexplainal-
Shapleyvalues, whileourShapley-assistedhuman-BOteam
gorithm selection problems [Fre´chette et al., 2015]. Within
directly uses Shapley values to align a single BO proposal
the context of IML, Shapley values are considered a model
withhumanproposals.
agnostic local interpretation method. In particular, it breaks
[Chakraborty et al., 2023, Chakraborty et al., 2024] re-
downanMLmodel’spredictionintofeaturecontributionsfor
cently proposed TNTRules, a post-hoc rule-based expla-
single instances. Compared to other IML methods such as
nation method of Bayesian optimization. TNTRules finds
permutationfeatureimportance[Breiman,2001,Fisheretal.,
(through clustering algorithms) subspaces of the parame-
2019] or partial dependence plot [Friedman, 2001], Shapley
ter space that should be tuned by the user. Similar to our
valueshavethemainadvantagethattheyfairlydistributefea-
work, it emphasizes the benefits of XAI methods in human-
tureinteractionstoquantifyfeaturecontributions. Whilethe
collaborative BO. Contrary to our work, it is a post-hoc
features become the players, the the contribution function is
method(ShapleyBOworksonline)andfocusesonexplain-
typically set to the expected output of the predictive model
ingtheparameterspaceratherthansingleBOproposals.
conditioned on the values of the features in a coalition, see
[Lundberg and Lee, 2017, Sˇtrumbelj and Kononenko, 2014]
or [Aas et al., 2021, Equation 2]. Formally, let fˆ: Θ → R 3 InterpretingBayesianOptimization
be a prediction model on feature space Θ and θ˜ ∈ Θ the throughShapleyValues
instance to explain. Then the worth of a coalition of fea-
InthissectionweintroduceShapleyBO,amodularframe-
tures S ⊆ Θ is given by v(S) = E[fˆ(θ)|θ = θ˜ ], where
S S work partly based on [Croppi, 2021], that allows to inter-
θ S,θ˜ S ∈S arethefeaturevectorsθ,θ˜projectedontoS. pretBOproposalsbyShapleyvalues:TransitioningfromML
modelstoacquisitionfunctions,theutilizationoftheShapley
2.3 RelatedWork
valuebecomesremarkablystraightforward,asanacquisition
As mentioned in Section 2.2, there are only quite mild reg- functionessentiallyrepresentsatransformedversionofasur-
ularity conditions for a function to be explainable by Shap- rogate (ML) model’s prediction function. Consequently, the
ley values. Consequently, there exists a broad body of re- Shapleyvaluecanbeemployedwithanyacquisitionfunction
searchondeployingShapleyvaluesbeyondclassicalpredic- toevaluatetheinformativenessofselectedparametervalues.
tionfunctions. Examplescomprisetheexplanationofpredic- AmonganarrayofAFoptions, theconfidencebound[Auer
tive uncertainty [Watson et al., 2023], reinforcement learn- et al., 2002, Kocsis and Szepesva´ri, 2006] appears particu-
ing [Beechey et al., 2023], or anomaly detection [Tallo´n- larly suited for our approach, due to its intuitive functional
Ballesteros and Chen, 2020]. To the best of our knowledge, form and additive nature. The confidence bound (CB) of a
however, we are the first to explicitly explain Bayesian op- parametervectorθ ∈Θisdefinedas
timization through Shapley values, with the notable excep-
tionofconcurringworkby[Adachietal., 2024], seebelow. cb(θ)=µˆ(θ)−λσˆ(θ), (4)i
cb decomposed (iter 59)
ii
Actual cb: −1.4090
q1 q2 q3 q4
Actual: −1.4090, Average: 71.1346 Average cb: 71.1346 0
q1=0.3557 q1=0.3557
−20
q2=0.1923 q2=0.1923
q3=0.1589 q3=0.1589 −40
q4=0.2473 q4=0.2473 −60
−40 −20 0 20 −40 −20 0 20
phi (cb) phi (cb) −80
iii iv
c Ab c td ue ac l:o −m 1p 9o .8s 3e 3d 8 ( ,i t Ae vr e5 r9 a) g e: 24.5737 A Avc etu raa gl c eb c: b− :1 29 4.8 .53 73 38 7 0
q1=0.3294 q1=0.3294 −20
q2=0.3229 q2=0.3229
−40
q3=0.22 q3=0.22
q4=0.2711 q4=0.2711 −60
−40 −20 0 20 −40 −20 0 20
phi (cb) phi (cb) −80
contribution mean se 0 20 40 60 0 20 40 60 iter0 20 40 60 0 20 40 60
q1 q2 q3 q4
Figure 1: ShapleyBO results in iteration 59 of BO on Ψ(θ) = 50
f(θ)+ϵ. Plotsiandiiforλ = 1andplotsiiiandivforλ = 10,
see[Croppi, 2021,Fig. 5]. Contributions(phi)areaveragedover 0
30proposalsforeachλ. Ontheright, theoverallinformativeness
−50
oftheparametersisdisplayed(cbcontributions),andontheleftthe
decompositionintom(red)andse(blue)contributions. Recallthat
−100
cbisminimized.Errorbars:Standarddeviationofestimates.
50
0
whereµˆ andσˆ aremeanandstandarderrorestimatesbythe
surrogate model (here: GP), respectively; λ > 0 is a hyper- −50
parameter controlling the exploration-exploitation trade-off.
For ease of exposition, we will henceforth refer to the con- −100
0 20 40 60 0 20 40 60 0 20 40 60 0 20 40 60
fidence bound as m−λse. The rationale behind the confi- iter
dence bound is fairly intuitive: a point is deemed desirable contribution mean se
ifeither(i)themeanpredictionmislow(indicatingananti-
Figure 2: Informativeness paths for hyper ellipsoid optimization,
cipationofalowtargetvalue,thusexploitingexistingknowl- see [Croppi, 2021, Fig. 6]. Plot on top displays cb contributions
edge)or(ii)theuncertaintypredictionseishigh, indicating withfacetsforparameters(vertical)andλ(horizontal);beneathits
limitedinformationaboutthetargetfunctioninthatarea(ex- decomposition into m (red) and se (blue) contributions. They are
ploring). Proposingnewsamplesboilsdowntooptimizing averagedover30proposalsineachiterationandtheuncertaintyof
thisconfidencebound. Tothisend,letminimizing(w.l.o.g.) theestimateisdisplayedwitherrorbarsusingonestandarddevia-
tion. The black dot-dashed line in the λ = 10 plots displays the
theconfidenceboundbeacooperativegamealongthelinesof
averagecontributionoftheparametersintheλ=1run.
Section2.2. Itshallbedefinedas(P,cb),orastwoseparate
games (P,m) and (P,se), with P being the grand coalition
ofShapleyvaluesinvolvedandmandsethemeananduncer- words, when deciding among two parameter configurations
taintypredictionoftheShapleyvalues,respectively. Accord- withequalmeantarget,mosthumanstendtooptfortheone
ingtothelinearityaxiomthecbcontributionofanyparameter with lower variation. This motivates a risk-averse optimiza-
j of explicand θ˜can then be decomposed into mean contri- tionproblem: min f(θ)−α·ϵ(θ)withϵ(θ)somenoise
θ∈Θ
butionϕ (m)anduncertaintycontributionϕ (se). that is non-constant in θ. [Makarova et al., 2021] propose
j j
risk-averseheteroscedasticBayesianoptimization(RAHBO)
ϕ (cb)=ϕ (m−λse)=ϕ (m)−λϕ (se) (5) which entails minimizing (w.l.o.g.) the risk-averse confi-
j j j j
dencebound(racb)
Thus, we can not only evaluate the overall informative-
ness of each parameter θ , but also examine how both con-
j
racb(θ)=µ(θ)−τ ·σ(θ)+α·ϵ(θ), (6)
tributions ϕ(m) and ϕ(se) impact and drive the selection (cid:98) (cid:98) (cid:98)
of proposed parameter values, shedding some light on the where ϵ(θ) is an on-the-fly estimate of the noise. Due
(cid:98)
exploration-exploitation trade-off. On the background of to racb’s additive structure, ShapleyBO can identify each
recent work on uncertainty quantification [McKeand et al., parameter’s contribution to epistemic uncertainty reduction
2021,Hu¨llermeierandWaegeman,2021,Psarosetal.,2023, through −τ · σ(θ) and to aleatoric uncertainty avoidance
(cid:98)
Jansenetal., 2023b], wegobeyond[Croppi, 2021]andfur- through α · ϵ(θ). By filtering out these exploratory contri-
(cid:98)
theraimatdisentanglingtheuncertaintycontributionϕ (se) butions,theremainderofaparameter’soverallShapleyvalue
j
ofaparameterθ intoitsepistemic(reducible)andaleatoric canbeidentifiedastheparameter’scontributiontomeanopti-
j
(irreducible) part. Aleaotoric uncertainty is typically caused mizationthroughµ(θ)(exploitation). WeextendRAHBOby
(cid:98)
by noise. The latter is particularly relevant in Bayesian op- furtherdissectingtheepistemicuncertaintyintomodeluncer-
timization if it is of heteroscedastic nature, i.e., dependent tainty and approximation uncertainty. While the former de-
on θ, since decision makers are often risk-averse. In other scribesuncertaintyarisingfrommodelchoise,thelatterrefers
)bc(
ihp
ihp
1
10
1
10noisy parable noisy parable
toclassicalstatisticalsamplinguncertainty[Hu¨llermeierand
Waegeman, 2021, section 2.4]. Notably, the model uncer-
taintyasymptoticallyvanishesforGPswithuniversalapprox- 10 10
imationproperty,asthelikelihooddominatestheposteriorin
the limit, see [Mangili, 2016]. For the finite sample regime
inBO,however, thisasymptoticbehaviorisnotrelevant. In 0 0
order to quantify model uncertainty, we rely on recently in-
troducedprior-meanrobustBayesianoptimization(PROBO)
[Rodemann, 2021, Rodemann and Augustin, 2021, Rode-
−10 −10
mann and Augustin, 2022]. PROBO avoids GP prior mean
parametermisspecificationbydeployingimpreciseGaussian
processes [Mangili, 2016] as surrogate models. The rough
−10 q0
1
10 −10 q0
1
10
idea of PROBO is to specify a set of prior mean values re- Figure3:ContourplotsofnoisyellipsoidfunctionΨ(θ)=g(θ)+
sultinginasetofposteriorGPs. Theselattergiverisetoan ϵ(θ),seeEquations9and10.Red:lowΨ(θ);blue:highΨ(θ).
upperandlowermeanestimateµˆ(θ) andµˆ(θ) subjecttoa
c c
degree of imprecision c. We define the uncertainty aware
is applied. Results in each iteration are then averaged over
confidencebound(uacb)asfollows: uacb(θ,λ,ρ,α)=
allruns. Figure1hastheresultsexemplarilyforiteration59.
They are displayed for λ = 1 (i and ii) and λ = 10 (iii and
iv). Theanalysisisbasedon[Croppi,2021,section7.1]
µ (cid:98)(θ) − λ·σ (cid:98)(θ) −ρ·(µˆ(θ) c−µˆ(θ) c)+ α· (cid:98)ϵ(θ). (7) Asexpectedinlightofthepartialderivativesoff(θ), the
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
approximationuncertainty modeluncertainty aleatoricuncertainty contributionofθ j growswithj. Incontrast, uncertaintyex-
(cid:124) (cid:123)(cid:122) (cid:125) hibitsadiminutiveandadverseeffect. Theuncertaintymea-
epistemicuncertainty
surementsˆefortherecommendedsetupfallsbelowthemean
Since the remaining epistemic uncertainty is represented s¯e, thus yielding a positive payout (negative contributions).
by the model’s σ (cid:98)(θ), we can interpret it as (an upper bound Opting for a setup with an uncertainty estimate beneath the
of)approximationuncertainty.Notethattheuncertaintymea- averageisdeemedastrategiccompromisetowardsenhancing
suredbyPROBOisonlyalowerboundofthetotalmodelun- meanvaluesattheexpenseofexploration. ShapleyBOfa-
certainty,whichalsoincludes,forinstance,uncertaintyw.r.t. cilitatesanuancedallocationofthistrade-offacrossparame-
kernel parameter selection. The uacb allows us to analyze ters,seebothFigures1and2.Wewillalsostudyhowthecon-
as to what degree a parameter configuration is motivated by tributionschangeinthecourseoftheoptimization. Respec-
exploitation on the one hand or by reducing approximation, tiveinformativenesspathsareshowninFigure2.Theyreveal
model or aleatoric uncertainty on the other hand. Since im- consistent patterns for λ = 1, with a preference for higher
preciseGaussianprocessesarecurrentlylimitedtounivariate parameterspersistingacrosstheboard. Uponexaminingthe
functions[Mangili,2016],wearenotabletofurtherattribute lowerplots’decomposition,weseethatbothmeananduncer-
the contributions to multiple parameters. Future work will taintycontributionsremainconstantovertime. Withasetting
aim at multivariate extension. Nevertheless, the uacb facili- of λ = 10, the algorithm conducts a thorough exploration
tatesinterpretationofproposals’contributionstoalltheseun- oftheparameterspace,resultingininitiallyhighercontribu-
certaintytypesbymeansofShapleyBO. tionsandamoreuniforminformativenessamongparameters.
Over time, these contributions diminish smoothly, showing
4 IllustrativeApplication differences between parameters akin to the λ = 1 scenario,
Adeploymentonsyntheticfunctionsallowsustovalidateour butwithanotabledecreaseininformativenessforhigherpa-
method,becausewecanformulateconcreteexpectationsfor rameters. Throughouttheoptimizationprocess,theemphasis
thecontributionsbasedontheknownfunctionalformofthe shifts from reducing uncertainty to prioritizing mean reduc-
synthetic target function. We select a hyper-ellipsoid func- tion, leading BO to favor configurations that perform well
tion, see Equation 8 below, where the parameters’ partial overthosewithhighuncertainty.Thistransitionismarkedby
derivativesgrowinj. Thus,weexpectShapleyBOtoiden- acrossinginthecontributioncurves,seeFigure2,indicating
tifyparameterswithhighj tobemostinfluentialinBO. a preference for mean reduction over uncertainty reduction,
Homoscedastic Target Function: Firstly, we illustrate particularlyforparameterswithhigherθ j,underscoringtheir
ShapleyBObyoptimizingΨ(θ)=f(θ)+ϵ,where importancefortheoptimization.
Heteroscedastic Target Function: Secondly, we illus-
trate ShapleyBO for Bayesian optimization of a two-
4
f :[−5.12,5.12]4 →R+;θ (cid:55)→f(θ)=(cid:88) j·θ2 (8) dimensional ellipsoid function with noise depending on θ.
0 j Thatis,weminimizeΨ(θ)=g(θ)+ϵ(θ),where
j=1
2
with j ∈ {1,2,3,4} and one unique optimum at θ∗ = g: [−15,15]2 →R+; θ (cid:55)→f(θ)=(cid:88) i·θ2 (9)
(0,0,0,0)T withf(θ∗)=0. Thenoiseϵisassumedbei.i.d. 0 i
Gaussian and independent of θ (homoscedastic). To control i
withi∈{1,2}and
forthestochasticbehaviorofBO,30optimizationswith60it-
erationseacharerun. Aftereachoptimization,ShapleyBO ϵ(θ)=30·|θ −15|+0.3·|θ −15|. (10)
1 2
2q 2qiteration j ϕ (m) ϕ (se) ϕ (ϵˆ) ϕ (racb)
j j j j
1 θ -100.2 2.4 -13.9 -111.8
1
1 θ -163.1 2.2 1.5 -159.4
2
2 θ -87.8 2.4 -37.7 -123.1
1
2 θ -165.6 1.6 3.3 -160.3
2
Table1:ResultsofShapleyBOforexemplaryiterations1and2of
BOwithrisk-averseconfidencebound(Equation6)onheteroscedas-
tictargetfunctiong(θ)(Equation10).
j ϕ (m) ϕ (se) ϕ (ϵˆ)
j j j
1 -48.48 4.20 -87.27
2 -157.73 6.88 0.24
Figure4: A:Assistivesoftbackexosuit. B:Forceprofileexample
Table2: ResultsofShapleyBOforaveragedoverall60iterations forpreferencelearning. Subjectsareaskedtocomparecontrollers
and all 30 BO restarts with risk-averse confidence bound (Equa- setting 1 (pink) to 2 (blue). Each option varies in the amount of
tion6)onheteroscedastictargetfunctiong(θ)(Equation10). loweringgain(θ )andliftinggain(θ ),see[Arensetal.,2023].
low lif
That is, the noise grows strongly in θ 1, but only moder- tural insights on the relative importance of parameters for
ately in θ 2. Figure 3 shows contours of g(θ). It becomes the optimization by filtering out uncertainty contributions,
evident that the function varies stronger w.r.t. θ 2 than w.r.t. see ϕ j(m) in Table 2 for instance. Our general hypothesis
θ 1,whilethenoiseisstronglyaffectedbyθ 1andalmostcon- is that basing the decision to intervene on this information
stant in θ 2. Hence, we expect the respective Shapley values will speed up the optimization. The underlying idea is that
for aleatoric uncertainty contributions to be high for θ 1 and userscanrejectproposalsincasetherespectiveShapleyval-
low for θ 2, and vice versa for exploitation (mean optimiza- ues do not align with the user’s knowledge about the opti-
tion). WerunBOong(θ)withrisk-averseconfidencebound mization problem. To test this hypothesis, we benchmark a
(racb), see Equation 6; we again average over 30 restarts of ShapleyBO-assistedhuman-AIteamagainstteamswithout
BOwith60iterationseach. ShapleyBOdeliverscontribu- accesstoShapleyvalues.Tobetterillustratethis,weconsider
tions for each θ j to each of racb’s components in each of thereal-worldusecaseofpersonalizingcontrolparametersof
BO’s iterations. Table 1 has the results for exemplary itera- awearable,assistivebackexosuitbyBayesianoptimization.
tions1and2. Table2showsthecontributionsaveragedover
alli∈{1,...,60}iterationsandallr ∈{1,...,30}restarts. 5.1 PersonalizingSoftExosuits
For instance, the averaged mean contributions of parameter
Wearableroboticdevices,suchasexoskeletonsandexosuits,
j areϕ j(m)= 31 0(cid:80)3 r=0 1 61 0(cid:80)6 i=0 1ϕ j,r,i(m). Itbecomesevi- have emerged as promising tools in mitigating risk of in-
dentthatθ 2ismoreimportantforthemeanminimizationthan juryandaidingrehabilitation[Siviyetal.,2023,Toxirietal.,
θ 1, while the latter contributes more to aleatoric uncertainty 2019]. With an increase in use cases and accessibility to a
(noise)avoidance. Thecontributionstoepistemicuncertainty broadercommunity,ithasbecomeapparentthatthebenefits
reductionvarylesswiththeparameters. of such devices can vary substantially between individuals.
Summing up, the applications on both homo- and het- Besidesdesignchoices,whichhavetobemadeearlyonand
eroscedastictargetfunctionsdemonstratedthatShapleyBO
arethereforeoftenguidedby(average)useranthropometrics,
managestodisentanglecontributionsofdifferentparameters important factors influencing device efficacy are the magni-
todifferentobjectivesofBO,thusprovidingvaluableinsights tude and timing of assistance. To understand which settings
bothintoBO’sinnerworking(seeFigures1,2andTable1) workbestforanindividual,manystudiesfollowHILframe-
andaboutthetargetfunctionitself(seeTable2). works. Theseapproachescompriseafeedbackloopinwhich
theimpactofacontrollermodificationontheobjectivefunc-
5 Shapley-AssistedHumanMachineInterface
tion of interest is measured in real-time, and used to deter-
The ability to interpret Bayesian optimization can be par- mineasetofcontrolparametersthatarelikelyimproveupon
ticularly useful for Human-In-the-Loop (HIL) applications, the current optimum in the subsequent iteration. Given that
whereusersobserveeachstepinthesequentialoptimization under such conditions there is typically no known analyti-
procedure. In this case ShapleyBO can inform users on- calrelationshipbetweencontrolinputsandobjectivefunction
line,thatiswhiletheoptimizationisstillrunning,aboutwhy outputs,sampleefficient,querybasedmethodslikeBayesian
certain actions were taken over others, instead of providing Optimizationhavehadconsiderablesuccessforsuchapplica-
suchexplanationsaftertheexperimenthasconcluded. More tions[Zhangetal.,2017,Dingetal.,2018].
specifically, we consider a human-AI collaborative frame-
5.2 ExperimentalSetup
work[Chakrabortyetal.,2024,Guptaetal.,2023,Venkatesh
etal.,2022,Akataetal.,2020,BorjiandItti,2013],inwhich Here, we explore the potential of ShapleyBO for the use-
users can actively participate in the optimization by reject- case of preference-based assistance optimization for a soft
ing BO proposals and instead take actions on their own. As backexosuit,seeFigure4. Tothisendweconsideradataset
demonstratedinSection4,Shapleyvaluescanprovidestruc- in which 15 healthy individuals performed a simple, stoopAgent A0 A1 A2 A3 A4
BO Human Param-Team [Venkateshetal.,2022] Shap-Team
Intervention
Criterion never always θnew,θnew k-thiteration ϕnew(m),ϕnew(m)
lif low lif low 60
Table3:Allagents:ShapleyBO-assistedA4andbaselinesA0-A3.
40
lifting task with a light (2kg) external load [Arens et al.,
2023]. Preferencewasqueriedinaforced-choiceparadigm.
Thatis,withineachiteration,participantswereconsecutively
20
exposedtotwocontrolparametersettingsandaskedtoindi-
cate which of the two options they preferred for completing
the given task. Each of the settings comprised two parame-
ters, referred to as lowering gain θ and lifting gain θ , 0
low lif
which govern the amount of lowering and lifting assistance 5 10
Iteration
providedbythedevice, respectively, seealsoFigure4. This
Agent A0: BO A1: Human A2: Param−Team A3: Venkatesh et al. A4: Shap−Team
preference feedback was used to compute a posterior utility
distribution over the considered parameter domains, relying
Figure5: ResultsofAgentsA0-A4(seeTable3)inhuman-AIcol-
on a probit likelihood model and a GP prior over the latent laborative BO for simulated exosuit personalization (individual 1)
userutilityasdescribedin[ChuandGhahramani,2005]. The with 10 iterations and 3 initial samples each. Error bars indicate
experimentcomprisedthreeseparateoptimizationblocks, in 95%confidenceintervals;k=2forA3,β =2forA2andA4.
eachofwhichtheoptimizationwasrunningfor12iterations.
To test ShapleyBO on this dataset, we averaged the three
pletely abstain from intervening (A0), see overview in Ta-
utility functions for each participant and interpolated by an-
ble3. A4hasaccesstoShapleyBOandbasestheirdecision
otherGPtosimulatetheuser’sgroundtruthutilityfunction.
to intervene (line 5 in Algorithm 1) on the alignment of the
Theremainingsetupinourexperimentalstudycloselyfol-
ShapleyvaluesofaBOproposalθnew = (θnew,θnew)with
lowstheonein[Venkateshetal., 2022]. Thatis, thehuman lif low
theagent’sknowledge.Moreprecisely,A4acceptsaBOpro-
caninterveneinBayesianoptimizationbyrectifyingpropos-
posalθ(doesnotintervene)if
als made by the algorithm, see pseudo code in Algorithm 1.
WewillcompareourShapleyBO-assistedhuman-BOteam
againsttheteamin[Venkateshetal.,2022,Algorithm1]and 1
<
ϕn lie fw(m) /1 (cid:88)T ϕh liu fman(m) t
<β, (11)
three other baselines (human alone, BO alone, human-BO β ϕnew(m) T ϕhuman(m)
low t=1 low t
team with different intervention criterion). We model hu-
man decisions by another Bayesian optimization, following where t ∈ {1,...,T} are iterations of the BO model-
[BorjiandItti,2013,Venkateshetal.,2022]. Thismeansthat ing the agent and ϕ(m) the Shapley mean contributions of
θhuman = (θ lh iu fman,θ lh ou wman)T is found by optimizing an (θ lif,θ low), i.e., the exosuit’s lifting and lowering gain, re-
acquisitionfunctionmodelinghumanpreferences. Weusea spectively. We discuss different Shapley-based intervention
BOwiththesamesurrogatemodelandacquisitionfunctionas criteria in the supplement. For A2’s intervention criterion
fortheouterloop,butwithdifferentexploration-exploitation we consider the alignment of (θ ln ie fw,θ ln oe ww) with the agents
preferenceanddifferentinitialdesign,representingdiffering knowledgebasedontheparametervaluesitself. Thatis, A3
risk-aversion and knowledge of the human, respectively. acceptsaBOproposal(doesnotintervene)if
Algorithm1Human-AICollaborativeBO
1
<
θ ln ie fw /1 (cid:88)T θ lh iu f,m tan
<β. (12)
β θnew T θhuman
1: createaninitialdesignD={(θ(i),Ψ(i))} i=1,...,ninit low t=1 low,t
2: whileterminationcriterionisnotfulfilleddo
5.3 Results
3: trainSMondataD
4: proposeθnewthatoptimizesAF(SM(θ)) Wesimulate40personalizationroundswith10iterationsand
5: ifinterventioncriterionisfulfilledthen initial design of size 3 each for all five agents. We compare
6: θnew ←θhuman themwithrespecttooptimizationpaths,whichshowbestin-
7: endif
cumbent target values (utility) in a given iteration. The BO
8: evaluateΨonθnew
usesGPasAMandcbwithλ=20asAF;theBOmodelling
9: updateD←D∪(θnew,Ψ(θnew))
human proposals uses GP and cb with λ = 200 and prior
10: endwhile
11: returnargmin Ψ(θ) knowledgeof90datapoints.
θ∈D
Figure 5 exemplarily summarizes results for individual 1;
results for remaining 14 individuals as well as experimental
Allagents(A0,A1,A2,A3,A4)areequaltoeachother,the details can be found in the supplement. For all 15 subjects,
onlydifferencebeingthattheShapleyBO-assistedagentin- ShapleyBO-assisted A4 (Shap-team) outperforms human
tervenesbasedonShapleyvalues(A4),whiletheotheragents andBObaselineaswellas[Venkateshetal.,2022]andateam
interveneineachk-thiteration(A3)[Venkateshetal.,2022], thatbasestheirdecisiontointerveneontheproposedparam-
basedontheproposedparameters(A2),always(A1)orcom- eters. ThislattercomparisonparticularlyconfirmsthatShap-
ytilitU
tnebmucnI
tseBley values are a meaningful measure for human-BO align-
mentthatcannotbereplacedbyanothernotionofalignment
withoutlossofefficiency. For10(amongwhomissubject1,
seeFigure5)outof15subjectstheobservedoutperformance
issignificantat95%confidencelevel.
6 Discussion
Byquantifyingthecontributionofeachparametertothepro-
posals, ShapleyBO aids in the communication of the ra-
tionale behind specific optimization decisions. This inter-
pretability is not only crucial for trust in HIL applications,
it also enhances their efficiency. The use case of customiz-
ingexosuitsillustratesthepracticalbenefitsofthisapproach,
suggestingthatShapleyBOcouldbeavaluablepracticaltool
forpersonalizingsoftbackexosuits.
Our paper opens up a multitude of directions for future
work. First and foremost, the simulation results in Sec-
tion 5 based on real-world data motivate the actual deploy-
ment of Shapley-assisted human-in-the-loop optimization of
exosuits in a user study. On the methodological end, exten-
sions of ShapleyBO to multi-criteria BO appear straight-
forward, as long as additive acquisition functions are used.
Moreover, a thorough mathematical study of the sublin-
ear regret bounds of Bayesian optimization with confidence
bound [Srinivas et al., 2012] under Shapley-assisted human
interventions might foster theoretical understanding of why
Shapley-assistedteamsoutperformcompetitors.
EthicalStatement
The data used to estimate the utility functions was collected
as part of another study [Arens et al., 2023] for which eth-
ical approval was obtained from the applicable institutional
ethicalreviewboard.
CJW is an inventor of at least one patent application de-
scribing the exosuit components described in the paper that
have been filed with the U.S. Patent Office by Harvard Uni-
versity.HarvardUniversityhasenteredintoalicensingagree-
mentwithVerveInc.,inwhichCJWhasanequityinterestand
aboardposition. Theotherauthorsdeclarethattheyhaveno
competinginterests.
Acknowledgments
WeacknowledgesupportbytheFederalStatisticalOfficeof
Germanywithintheco-operationproject“MachineLearning
inOfficialStatistics”.JRfurtheracknowledgessupportbythe
Bavarian Academy of Sciences (BAS) through the Bavarian
Institute for Digital Transformation (bidt) and by the LMU
mentoring program of the Faculty for Mathematics, Infor-
matics, and Statistics. YS is supported by the DAAD pro-
gram Konrad Zuse Schools of Excellence in Artificial Intel-
ligence,sponsoredbytheFederalMinistryofEducationand
Research.A Supplement Algorithm1Human-AICollaborativeBO
A.1 DetailsonExperiments 1: createaninitialdesignD={(θ(i),Ψ(i))}
i=1,...,ninit
2: whileterminationcriterionisnotfulfilleddo
Recall from the main paper that in our experimental setup,
3: trainSMondataD
humanshavethecapabilitytomodifytheBayesianoptimiza-
4: proposeθnewthatoptimizesAF(SM(θ))
tionprocessbyadjustingthealgorithm’ssuggestions,asillus-
5: ifinterventioncriterionisfulfilledthen
trated in the pseudo-code below, which we print here again 6: θnew ←θhuman
for ease of readability. We evaluate the performance of our 7: endif
ShapleyBO-enhancedhuman-BOcollaborationagainstthe 8: evaluateΨonθnew
approach described in [Venkatesh et al., 2022, Algorithm 1] 9: updateD←D∪(θnew,Ψ(θnew))
andthreeotherbenchmarkgroups(solelyhuman,solelyBO, 10: endwhile
and a human-BO pair with an alternate intervention mech- 11: returnargmin θ∈DΨ(θ)
anism). The modeling of human decisions employs an ad-
ditional layer of Bayesian optimization, inspired by [Borji
and Itti, 2013, Venkatesh et al., 2022], where θhuman =
(θhuman,θhuman)T is derived through an acquisition func-
lif low
tionthatcaptureshumanpreferences. ThisauxiliaryBOuses DetailsonSimulations
the same surrogate and acquisition models as the primary
loopbutadjustsforhuman-specificrisktoleranceandinitial
We computed 40 repetitions of the described procedure on
knowledgethroughdifferentexploration-exploitationprefer-
a Linux High-performance cluster. The experiments were
ence(λincb)andinitialdesigns,respectively. Thespecifica-
testedwithRversions4.3.2,4.2.0,4.1.6,and4.0.3onLinux
tionsforboththeoriginalBOandtheauxiliaryBOmodeling
Ubuntu20.04,LinuxDebian10,andWindows11ProBuild
thehumancanbefoundbelow.
22H2. Further details as well as documentation of how to
ModelSpecifications reproduce the results can be found in the readme-file of the
The following non-exhaustive list summarizes the specifica- anonymousrepository:
tionsfortheconductedexperiments.
• BayesianOptimization
https://anonymous.4open.science/r/ShapleyBO-E65D
– SurrogateModel: GaussianProcess
* Kernel: Gaussian
k(x,x′)exp(−1/2·(|x−x′|/θ)2),
where θ is the range parameter which was esti- AlternativeInterventionCriteria
matedfromdata(empiricalBayes)
* Priormeanfunctionestimatedfromdata(empir-
icalBayes) Wevariedβ forbothA2andA4anddidnotobservesignif-
icantchangesintheresults. Moreover,weconsidereddiffer-
– AcquisitionFunction: ConfidenceBound
ent intervention criteria based on previous experience of the
* λ bo =20 humanratherthanhardcodedlikeEquations11and12inthe
– initialdesignsize: 3
main paper. The idea was to learn the criterion from previ-
• Human ousBOruns. Thesoacquireddata(proposalsθ andrespec-
– SurrogateModel: GaussianProcess tiveShapleyvaluesaswellastheevaluatedtargetΨ(θ))was
used to train an ML model to represent the learned knowl-
* Kernel: Gaussian
edge in previous BO iteration. To this end, we rely on clas-
k(x,x′)exp(−1/2·(|x−x′|/θ)2),
sification and regression trees (CART), as they are easy to
where θ is the range parameter which was esti- interpret,flexibleandrobust[Loh,2014,Ferna´ndez-Delgado
matedfromdata(empiricalBayes) etal.,2014,Nalenzetal.,2024].Weparticularlyrelyontheir
* Priormeanfunctionestimatedfromdata(empir- abilitytolearnlogicalrulesthatcanthenbeusedasinterven-
icalBayes) tioncriteria. Theprunedversionofatreedeliversadecision
– AcquisitionFunction: ConfidenceBound rule of required complexity, see Figure 6. It represents the
human’s knowledge about the relationship between the pro-
* λ h =200
posals’Shapleyvaluesandtheobtainedtargetvalues.
– initialdesignsize: 90(fromasubsetofthefeature
space,modelingpriorknowledgeofthehuman)
Varying both λ and λ did not affect the overall results
h bo
significantly. Drasticallydecreasinginitialdesignsizeforthe
Agent A0 A1 A2 A3 A4
humanledtoallhuman-BOteams(A2,A3,A4)tobeoutper- BO Human Param-Team [Venkateshetal.,2022] Shap-Team
Intervention
formedbythetheBOBaselineA0. Wereasonthatacertain Criterion never always θnew,θnew k-thiteration ϕnew(m),ϕnew(m)
lif low lif low
advantage in knowledge by the humans is key to successful
human-BOcollaboration. Table4:Allagents:ShapleyBO-assistedA4andbaselinesA0-A3.60
40
20
0
Figure6:RegressiontreelearnedfromShapley-assistedBO.Itpre-
dicts a target value of Ψ(θ) = −57.72 for BO proposals where 5 10
θ (lifting gain) has a Shapley contribution to the mean compo- Iteration
lif
nentofcblowerthan−11.05,i.e.,ϕ lif(m) < −11.05. Usingthis
Agent
A0: BO A2: Param−Team A4: Shap−Team
learnedruleasaninterventioncriterioninhuman-AIcollaborative A1: Human A3: Venkatesh et al. Shapely−assisted−tree
BOtranslatestorejectingtheautomaticallygeneratedBOproposals
and rectifying them by human’s proposals in case their respective
Figure 8: Results of Agents A0-A4 (see Table 4) and additional
Shapleyvaluesfulfillϕ (m)<−11.05.
lif
agent with tree-based intervention criterion in human-AI collabo-
rativeBOforsimulatedexosuitpersonalization(randomlyselected
individual)with10iterationsand3initialsampleseach. Errorbars
indicate95%confidenceintervals;k=2forA3,β =2forA2and
A4.
Replacing the hard-coded intervention criteria (Equa-
tion 11 and 12 in the main paper) by those learned through
a regression tree did not change the results significantly, ResearchHypotheses
see Figure 7 and Figure 8. We ran the same experiments Experimental design was motivated by the following hy-
as described in the main paper, but additionally included a pothesesthatwereformulatedbeforehand.
Shapley-assistedhuman-BOteamwithinterventioncriterion Hypothesis1(BOBaseline). Human-BOteamsaremoreef-
learnedthroughregressiontrees(yellow). ficientthanBOalone.
Asbecomesevident,thereportedresultsarerelativelyro- Hypothesis2(HumanBaseline). Human-BOteamsaremore
bustwithregardtotheconcretespecificationoftheinterven- efficientthanahumanwithoutaccesstoBO.
tioncriterion. Thatis,theprecisenatureofthecriterion(see Hypothesis3([Venkateshetal.,2022]Baseline). Anagent
alsodiscussionofresultsforalteredβ)andwhetheritishard- inhuman-AIcollaborativeBOthatintervenesbasedonShap-
coded or learned from previous BO iterations does not alter leyvaluesismoreefficientthananagentwhodoesintervene
theresultssignificantly. ineachk-thiteration.
Hypothesis 4 (Parameter-informed Baseline). An agent in
human-AIcollaborativeBOthatintervenesbasedonShapley
values is more efficient than an agent who intervenes based
onthediscrepancybetweentheproposedparametervalues.
60 EfficiencyinHypotheses1through4referstothecumula-
tiveregret(distancestooptimumsummedoveralliterations).
Hypotheses 1 and 2 make sure Shapley-assisted human-BO
40
teams do not simply outperform competitors due to the fact
that the human is uniformly superior to BO, or vice versa.
20 Notably,hypotheses1through4weretreatedasscientificre-
searchhypothesesratherthanstatisticalhypotheses.Weleave
a rigorous statistical benchmarking analysis along the lines
0
of[Demsˇar,2006,Jansenetal.,2023a]tofutureworkaswell
as multi-criteria comparison [Jansen et al., 2023b, Blocher
5 10
Iteration et al., 2023, Rodemann and Blocher, 2024] of the optimiza-
A0: BO A2: Param−Team A4: Shap−Team tionagents.
Agent
A1: Human A3: Venkatesh et al. Shapely−assisted−tree
A.2 AdditionalExperimentsandFutureWork
Figure 7: Results of Agents A0-A4 (see Table 4) and additional As already hinted at in the subsections on model specifica-
agent with tree-based intervention criterion in human-AI collabo- tions and alternative intervention criteria in Section A.1, we
rativeBOforsimulatedexosuitpersonalization(individual1)with didconductsomerobustnessanalysis. Theresultsfromvary-
10 iterations and 3 initial samples each. Error bars indicate 95% ingtheinterventioncriteriacanbeseeinFigures7and8and
confidenceintervals;k=2forA3,β =2forA2andA4. havebeendiscussedabove. Inwhatfollows,weexemplarily
ytilitU
tnebmucnI
tseB
ytilitU
tnebmucnI
tseBshowcase some results from experiments where we altered uisite sample volume for efficient SV computation. Let us
λ andλ . Figure9hastheresultsforλ =λ =40,i.e. definethepayoutfunction
h BO h bo
amorebalancedexploration-exploitationpreferencebetween
human and BO. The results are hardly affected by the more
balancedexploration-exploitationscheme.
P(v)=fˆv(θ˜)− 1 (cid:88) fˆv(θ(i)), (13)
n
i
50
intended for distribution among the explicand’s parame-
25 ters θ˜, where fˆv predicts outcomes v = {cb,m,se} and
{θ(i)}n denotesaseriesofinstances. Aspertheefficiency
i=1 (cid:80)
axiom,theequality ϕ (v)=P(v)isexpected. However,
0 j j
due to approximation in calculating true contributions, this
0 10 20 processincursanefficiencyerror,representedas
Iteration
Agent A0: BO A1: Human A3: Venkatesh et al. A4: Shap−Team Shapely−assisted−tree
Figure9:Resultsofforsimulatedexosuitpersonalization(randomly
selected individual) for λ = λ = 40 with 20 iterations and 5
initialsampleseach.Errorh barsinb do icate95%confidenceintervals. ∆K (v)=(cid:88) ϕˆK(v)−P(v), (14)
eff j
j
Besidestheabovepresentedadditionalexperimentsforex-
osuit personalization, we also tested ShapleyBO in a uni-
variatescenario,wheredeploymentoftheuncertainty-aware
confidence bound (Equation 7 in main paper) was possible. with K symbolizing the MC sample count. The discrep-
We focused on the concrete case of minimizing metabolic ancy ∆K (v) diminishes as K increases, aligning with the
eff
cost by step size adaption of powered prosthetics for walk- asymptotic distribution of ϕˆ (v). An error greater (lesser)
j
ingassistance[Kimetal.,2017]. Thepubliclyavailabledata
than zero indicates an overallocation (underallocation) of
containsmeasurementson9patients. Weuseeachofthemto
payout, necessitating an adjustment in contributions. While
fitasurrogatefunctionthatweoptimizebyBO.Theproposal
theprecisecontributionsrequiringadjustmentremainuncer-
are interpreted by Shapley values, showcasing the potential tain, redistributing ∆K (v) entirely to a single parameter
use of disentangling the uncertainty contributions even in a eff
wouldarguablybetheleastequitable.
univariatesetup.
Ourfocusliesnotonrectifyingtheoutcomesbutoneval-
A.3 Computationaldetails
uatingtheadequacyofK. Forcomputationalsimplicity,we
A principal hurdle in applying Shapley values (SVs) within redefine∆K (v)as|(cid:80) ϕˆK(v)−P(v)|. Moreover,wein-
eff j j
the realm of interpretable machine learning (IML) is their troduce
computational intensity. To precisely calculate Shapley val-
ues, onemustevaluatethemodelacrossallconceivablefea-
turesubsets.Suchexactcalculationsareknowntopossessex-
ponentialtimecomplexity[SˇtrumbeljandKononenko,2014],
making the use of approximation methods such as Monte δK(v)=min{d (ϕˆK(v),ϕˆK(v)) }, (15)
1 j l j̸=l
Carlo(MC)samplingapracticalnecessity.
For instance, [Merrick and Taly, 2019] devised the Ex-
planation Game, an innovative sampling approach that em-
ploysimportancesamplingtoenhancetheaccuracyofShap- theminimalL distancebetweenanytwodistinctparam-
1
leyvalueestimates.[IgnatovandKwuida,2022]introduceda eterShapleyvalues. AsamplesizeK isdeemedsufficientif
methodrootedinformalconceptanalysisforassessingShap- ∆K (v) < δK(v), ensuring that adjustments for efficiency
eff
leyvaluesoverfiniteattributesets,while[Lutheretal.,2023]
errordonotaltertheimportancerankings. Ifthisconditionis
appliedcausalstructurelearningtopinpointfeatureindepen-
notmet,K mustbeincreased.
dencies,therebystreamliningShapleyvaluecomputation.
Inourwork,weadoptatraditionalMCsamplingstrategy, A sufficient sample size is thus determined through a
supplementedbyanovelalgorithmfrom[Croppi,2021],de- greedyforwardsearch. Below,avisualrepresentationofthis
signed to accurately determine an adequate sample size for methodologyisprovided,andAlgorithm4conciselyoutlines
Shapleyvalue estimationin Bayesian optimizationcontexts. the primary procedural steps, see also the respetive pseudo-
Thisalgorithmpresentsaviablemeansofidentifyingthereq- codeinthefollowingsection.
ytilitU
tnebmucnI
tseBincrease K sufficient K Algorithm3ShapleyBO
Require: BOresultobjectbo,iterationofinterestt,sample
3
sizeK
1: getexplicandfrombo: θ˜=θnew
t
2: sample1000·ppointsZfromΘtoapproximatethespace
2
3: computeϕˆ(m)=(ϕˆ 1(m),...,ϕˆ p(m)):
4: getSMfrombo: fˆ m =fˆ tmean e er sr to imr ate 5: explainθ˜withShapley()usingZ,fˆ mandK
6: computeϕˆ(se)=(ϕˆ 1(se),...,ϕˆ p(se)):
1 7: getSMfrombo: fˆ se =fˆ tuncertainty
8: explainθ˜withShapley()usingZ,fˆ seandK
9: compute ϕˆ(cb) with linearity axiom: ϕˆ(cb) = ϕˆ(m)−
0
λϕˆ(se)
x1 x2 x1 x2
Figure10: ExampleoftheideabehindcheckSampleSize, see
[Croppi,2021,Figure16].EstimatedShapleyvaluesoftwofeatures Algorithm4checkSampleSize
named x and x in grey give threshold δK = 3−2 = 1. The
efficiency1 errorin2 redvariesfordifferentK.Suppose∆K (v)<0. Require: ShapleyBO results for θ˜ t with size K, models
Theerroristhusaddedentirelytox .Intheleftplotthee sf af mplesize fˆv withv ={cb,m,se}
2
K isnotsufficientbecauseredistributingtheresultingerrorwould 1: forwinvdo
makex 2moreimportantthanx 1.Instead,intherightplotKwould 2: computepayoutP(w),error∆K (w) andthreshold
besufficient.Incaseof∆K (v)>0removingtheerrorcompletely eff
eff δK(w)
fromx wouldleadtothesameconclusionforK.
1 3: if∆K (w)<δK(w)then
eff
4: K w =T
A.4 Pseudo-Code 5: endif
6: if∆K (w)≥δK(w)then
eff
In what follows, we summarize the main algorithmic 7: K w =F
procedures in pseudo-code: The general estimation of the 8: endif
Shapley values, the main procedure to retrieve Shapley 9: endfor
values from any iteration in Bayesian Optimization, and 10: if(K cb,K m,K se)=(T,T,T)then
the above mentioned procedure to check the sample size 11: K ishighenough
required for MC-estimation of the Shapley values. Detailed 12: elseif(K cb,K m,K se)̸=(T,T,T)then
implementation of all procedures in R [R Core Team, 2020] 13: K shouldbeincreased
(dependencies: mlrMBO [Bischl et al., 2017], iml [Molnar 14: endif
etal.,2018])canbeaccessedinfolderRof:
https://anonymous.4open.science/r/ShapleyBO-E65D
Algorithm2EstimationoftheShapleyvalues
Require: explicandθ˜,featureindexj,modelfˆandsample
sizeK
1: fork =1→K do
2: sample(withreplacement)aninstancez ∈Θ
3: sample(withreplacement)anorderπ ∈Π(P)
4:
orderθ˜andzaccordingtoπ
5: θ˜ π =(θ˜ (1),...,θ˜ (p))
6: z π =(z (1),...,z (p))
7: constructtwonewinstances
8: θ˜ +j =(θ˜ (1),...,θ˜ (j−1),θ˜ (j),z (j+1),...,z (p))
9: θ˜ −j =(θ˜ (1),...,θ˜ (j−1),z (j),z (j+1),...,z (p))
10: ϕˆk j(v)=fˆ(θ˜ +j)−fˆ(θ˜ −j)
11: endfor
12: ϕˆ j(v)= K1 (cid:80)K k=1ϕˆk j(v)
ihpA.5 AdditionalResults Individual4:
For ease of exposition, we only includeddetailed results for
individual 1 in the main paper. Results for remaining 14
individuals are displayed by Figures 11 through 24 in what
60
follows. As stated in the main paper, ShapleyBO-assisted
human-BO teams outperform competitors on average for
all individuals. For 10 out 15 individuals, this finding is
significantatconfidencelevelof95% 40
Individual2:
20
60 0
5 10
Iteration
Agent A0: BO A1: Human A2: Param−Team A3: Venkatesh et al. A4: Shap−Team
40
Figure13:ResultsofAgentsA0-A4(seeTable4)inhuman-AIcol-
laborative BO for simulated exosuit personalization (individual 4)
20 with 10 iterations and 3 initial samples each. Error bars indicate
95%confidenceintervals;k=2forA3,β =2forA2andA4.
0 Individual5:
5 10
Iteration
Agent A0: BO A1: Human A2: Param−Team A3: Venkatesh et al. A4: Shap−Team
Figure11:ResultsofAgentsA0-A4(seeTable4)inhuman-AIcol- 60
laborative BO for simulated exosuit personalization (individual 2)
with 10 iterations and 3 initial samples each. Error bars indicate
95%confidenceintervals;k=2forA3,β =2forA2andA4.
40
Individual3:
20
60 0
5 10
Iteration
Agent A0: BO A1: Human A2: Param−Team A3: Venkatesh et al. A4: Shap−Team
40
Figure14:ResultsofAgentsA0-A4(seeTable4)inhuman-AIcol-
laborative BO for simulated exosuit personalization (individual 5)
20 with 10 iterations and 3 initial samples each. Error bars indicate
95%confidenceintervals;k=2forA3,β =2forA2andA4.
0
5 10
Iteration
Agent A0: BO A1: Human A2: Param−Team A3: Venkatesh et al. A4: Shap−Team
Figure12:ResultsofAgentsA0-A4(seeTable4)inhuman-AIcol-
laborative BO for simulated exosuit personalization (individual 3)
with 10 iterations and 3 initial samples each. Error bars indicate
95%confidenceintervals;k=2forA3,β =2forA2andA4.
ytilitU
tnebmucnI
tseB
ytilitU
tnebmucnI
tseB
ytilitU
tnebmucnI
tseB
ytilitU
tnebmucnI
tseBIndividual6: Individual8:
60 60
40 40
20 20
0 0
5 10 5 10
Iteration Iteration
Agent A0: BO A1: Human A2: Param−Team A3: Venkatesh et al. A4: Shap−Team Agent A0: BO A1: Human A2: Param−Team A3: Venkatesh et al. A4: Shap−Team
Figure15:ResultsofAgentsA0-A4(seeTable4)inhuman-AIcol- Figure17:ResultsofAgentsA0-A4(seeTable4)inhuman-AIcol-
laborative BO for simulated exosuit personalization (individual 6) laborative BO for simulated exosuit personalization (individual 8)
with 10 iterations and 3 initial samples each. Error bars indicate with 10 iterations and 3 initial samples each. Error bars indicate
95%confidenceintervals;k=2forA3,β =2forA2andA4. 95%confidenceintervals;k=2forA3,β =2forA2andA4.
Individual7: Individual9:
60
50
40
25
20
0
0
5 10 5 10
Iteration Iteration
Agent A0: BO A1: Human A2: Param−Team A3: Venkatesh et al. A4: Shap−Team Agent A0: BO A1: Human A2: Param−Team A3: Venkatesh et al. A4: Shap−Team
Figure16:ResultsofAgentsA0-A4(seeTable4)inhuman-AIcol- Figure18:ResultsofAgentsA0-A4(seeTable4)inhuman-AIcol-
laborative BO for simulated exosuit personalization (individual 7) laborative BO for simulated exosuit personalization (individual 9)
with 10 iterations and 3 initial samples each. Error bars indicate with 10 iterations and 3 initial samples each. Error bars indicate
95%confidenceintervals;k=2forA3,β =2forA2andA4. 95%confidenceintervals;k=2forA3,β =2forA2andA4.
ytilitU
tnebmucnI
tseB
ytilitU
tnebmucnI
tseB
ytilitU
tnebmucnI
tseB
ytilitU
tnebmucnI
tseBIndividual10: Individual12:
60
60
40 40
20 20
0 0
5 10 5 10
Iteration Iteration
Agent A0: BO A1: Human A2: Param−Team A3: Venkatesh et al. A4: Shap−Team Agent A0: BO A1: Human A2: Param−Team A3: Venkatesh et al. A4: Shap−Team
Figure19:ResultsofAgentsA0-A4(seeTable4)inhuman-AIcol- Figure21:ResultsofAgentsA0-A4(seeTable4)inhuman-AIcol-
laborativeBOforsimulatedexosuitpersonalization(individual10) laborativeBOforsimulatedexosuitpersonalization(individual12)
with 10 iterations and 3 initial samples each. Error bars indicate with 10 iterations and 3 initial samples each. Error bars indicate
95%confidenceintervals;k=2forA3,β =2forA2andA4. 95%confidenceintervals;k=2forA3,β =2forA2andA4.
Individual11: Individual13:
60
60
40
40
20 20
0 0
5 10 5 10
Iteration Iteration
Agent A0: BO A1: Human A2: Param−Team A3: Venkatesh et al. A4: Shap−Team Agent A0: BO A1: Human A2: Param−Team A3: Venkatesh et al. A4: Shap−Team
Figure20:ResultsofAgentsA0-A4(seeTable4)inhuman-AIcol- Figure22:ResultsofAgentsA0-A4(seeTable4)inhuman-AIcol-
laborativeBOforsimulatedexosuitpersonalization(individual11) laborativeBOforsimulatedexosuitpersonalization(individual13)
with 10 iterations and 3 initial samples each. Error bars indicate with 10 iterations and 3 initial samples each. Error bars indicate
95%confidenceintervals;k=2forA3,β =2forA2andA4. 95%confidenceintervals;k=2forA3,β =2forA2andA4.
ytilitU
tnebmucnI
tseB
ytilitU
tnebmucnI
tseB
ytilitU
tnebmucnI
tseB
ytilitU
tnebmucnI
tseBIndividual14:
60
40
20
0
5 10
Iteration
Agent A0: BO A1: Human A2: Param−Team A3: Venkatesh et al. A4: Shap−Team
Figure23:ResultsofAgentsA0-A4(seeTable4)inhuman-AIcol-
laborativeBOforsimulatedexosuitpersonalization(individual14)
with 10 iterations and 3 initial samples each. Error bars indicate
95%confidenceintervals;k=2forA3,β =2forA2andA4.
Individual15:
60
40
20
0
5 10
Iteration
Agent A0: BO A1: Human A2: Param−Team A3: Venkatesh et al. A4: Shap−Team
Figure24:ResultsofAgentsA0-A4(seeTable4)inhuman-AIcol-
laborativeBOforsimulatedexosuitpersonalization(individual15)
with 10 iterations and 3 initial samples each. Error bars indicate
95%confidenceintervals;k=2forA3,β =2forA2andA4.
ytilitU
tnebmucnI
tseB
ytilitU
tnebmucnI
tseBReferences andApplications,volume215ofProceedingsofMachine
LearningResearch,pages59–71.PMLR.
[Aasetal.,2021] Aas, K., Jullum, M., and Løland, A.
(2021). Explaining individual predictions when features [BorjiandItti,2013] Borji, A.andItti, L.(2013). Bayesian
are dependent: More accurate approximations to shapley optimization explains human active search. Advances in
values. ArtificialIntelligence,298:103502. NeuralInformationProcessingSystems,26.
[Adachietal.,2024] Adachi,M.,Planden,B.,Howey,D.A., [Breiman,2001] Breiman,L.(2001). Randomforests. Ma-
Maundet, K., Osborne, M. A., and Chau, S. L. (2024). chineLearning,45(1):5–32.
Looping in the human: Collaborative and explainable
[Burtonetal.,2023] Burton,J.W.,Stein,M.-K.,andJensen,
bayesian optimization. In 27th International Conference
T. B. (2023). Beyond algorithm aversion in human-
onArtificialIntelligenceandStatistics(AISTATS),volume
machinedecision-making. InJudgmentinPredictiveAn-
238.PMLR.
alytics,pages3–26.Springer.
[Akataetal.,2020] Akata, Z., Balliet, D., de Rijke, M.,
[Chakrabortyetal.,2024] Chakraborty, T., Seifert, C., and
Dignum, F., Dignum, V., Eiben, G., Fokkens, A., Grossi,
Wirth, C. (2024). Explainable bayesian optimization.
D., Hindriks, K., Hoos, H., Hung, H., Jonker, C., Monz,
arXivpreprintarXiv:2401.13334.
C., Neerincx, M., Oliehoek, F., Prakken, H., Schlobach,
S.,vanderGaag,L.,vanHarmelen,F.,vanHoof,H.,van [Chakrabortyetal.,2023] Chakraborty, T., Wirth, C., and
Riemsdijk, B., van Wynsberghe, A., Verbrugge, R., Ver- Seifert, C. (2023). Post-hoc rule based explanations for
heij, B., Vossen, P., and Welling, M. (2020). A research blackboxbayesianoptimization. InEuropeanConference
agendaforhybridintelligence: Augmentinghumanintel- onArtificialIntelligence,pages320–337.Springer.
lectwithcollaborative,adaptive,responsible,andexplain-
[ChuandGhahramani,2005] Chu, W. and Ghahramani, Z.
ableartificialintelligence. Computer,53(8):18–28.
(2005). Preference learning with gaussian processes. In
[Arensetal.,2023] Arens,P.,Quirk,D.A.,Pan,W.,Yacoby, Proceedingsofthe22ndInternationalConferenceonMa-
Y., Doshi-Velez, F., and Walsh, C. J. (2023). Preference- chineLearning,pages137–144.
basedassistanceoptimizationforliftingandloweringwith
[Cisseetal.,2023] Cisse, A., Evangelopoulos, X., Car-
asoftbackexosuit. Submittedforpublication. Manuscript
ruthers,S.,Gusev,V.V.,andCooper,A.I.(2023). Hypbo:
inreviewasofDecember2023.
Expert-guided chemist-in-the-loop bayesian search for
[Aueretal.,2002] Auer, P., Cesa-Bianchi, N., and Fischer, newmaterials. arXivpreprintarXiv:2308.11787.
P. (2002). Finite-time analysis of the multiarmed bandit
[Croppi,2021] Croppi, F. (2021). Explaining sequential
problem. MachineLearning,47:235–256.
model-basedoptimization. MasterThesis,LMUMunich.
[AVetal.,2024] AV, A. K., Shilton, A., Gupta, S., Rana,
[Demsˇar,2006] Demsˇar, J. (2006). Statistical comparisons
S., Greenhill, S., and Venkatesh, S. (2024). Enhanced
ofclassifiersovermultipledatasets. TheJournalofMa-
bayesian optimization via preferential modeling of ab-
chinelearningresearch,7:1–30.
stractproperties. arXivpreprintarXiv:2402.17343.
[Dietvorstetal.,2015] Dietvorst, B. J., Simmons, J. P., and
[Bakshietal.,2023] Bakshi, S., Sharma, S., and Khanna,
Massey, C. (2015). Algorithm aversion: people erro-
R. (2023). Shapley-value-based hybrid metaheuristic
neously avoid algorithms after seeing them err. Journal
multi-objective optimization for energy efficiency in an
ofExperimentalPsychology: General,144(1):114.
energy-harvestingcognitiveradionetwork. Mathematics,
11(7):1656. [Dingetal.,2018] Ding, Y., Kim, M., Kuindersma, S., and
Walsh, C. J. (2018). Human-in-the-loop optimization of
[Beecheyetal.,2023] Beechey, D., Smith, T. M. S., and
hipassistancewithasoftexosuitduringwalking. Science
S¸ims¸ek, O. (2023). Explaining reinforcement learning
Robotics,3(15):eaar5438.
withshapleyvalues. InKrause,A.,Brunskill,E.,Cho,K.,
Engelhardt, B., Sabato, S., and Scarlett, J., editors, Pro- [Ferna´ndez-Delgadoetal.,2014] Ferna´ndez-Delgado, M.,
ceedingsofthe40thInternationalConferenceonMachine Cernadas, E., Barro, S., and Amorim, D. (2014). Do
Learning, volume202ofProceedingsofMachineLearn- we need hundreds of classifiers to solve real world
ingResearch,pages2003–2014.PMLR. classificationproblems? Thejournalofmachinelearning
research,15(1):3133–3181.
[Bischletal.,2017] Bischl,B.,Richter,J.,Bossek,J.,Horn,
D., Thomas, J., andLang, M.(2017). mlrmbo: Amodu- [Fisheretal.,2019] Fisher, A., Rudin, C., and Dominici, F.
larframeworkformodel-basedoptimizationofexpensive (2019).Allmodelsarewrong,butmanyareuseful:Learn-
black-boxfunctions. arXivpreprintarXiv:1703.03373. ingavariable’simportancebystudyinganentireclassof
prediction models simultaneously. Journal of Machine
[Blocheretal.,2023] Blocher, H., Schollmeyer, G., Jansen,
LearningResearch,20(177):1–81.
C.,andNalenz,M.(2023). Depthfunctionsforpartialor-
derswithadescriptiveanalysisofmachinelearningalgo- [FrazierandWang,2016] Frazier, P. and Wang, J. (2016).
rithms. InMiranda, E., Montes, I., Quaeghebeur, E., and Bayesian optimization for materials design. In Informa-
Vantaggi,B.,editors,ProceedingsoftheThirteenthInter- tion Science for Materials Discovery and Design, pages
national Symposium on Imprecise Probability: Theories 45–75.Springer.[Fre´chetteetal.,2015] Fre´chette, A., Kotthoff, L., Micha- [Makarovaetal.,2021] Makarova, A., Usmanova, I., Bo-
lak, T., Rahwan, T., Hoos, H. H., and Leyton-Brown, K. gunovic, I., and Krause, A. (2021). Risk-averse het-
(2015).Usingtheshapleyvaluetoanalyzealgorithmport- eroscedastic bayesian optimization. Advances in Neural
folios. InformationProcessingSystems,34:17235–17245.
[Friedman,2001] Friedman, J. H. (2001). Greedy function [Mangili,2016] Mangili, F. (2016). A prior near-ignorance
approximation: Agradientboostingmachine. TheAnnals gaussianprocessmodelfornonparametricregression. In-
ofStatistics,29(5):1189–1232. ternational Journal of Approximate Reasoning, 78:153–
171.
[Guptaetal.,2023] Gupta,S.,Shilton,A.,AV,A.K.,Ryan,
S.,Abdolshah,M.,Le,H.,Rana,S.,Berk,J.,Rashid,M., [McKeandetal.,2021] McKeand, A. M., Gorguluarslan,
andVenkatesh,S.(2023). Bo-muse: Ahumanexpertand R. M., and Choi, S.-K. (2021). Stochastic analysis and
aiteamingframeworkforacceleratedexperimentaldesign. validationunderaleatoryandepistemicuncertainties. Re-
arXivpreprintarXiv:2303.01684. liabilityEngineering&SystemSafety,205:107258.
[Hu¨llermeierandWaegeman,2021] Hu¨llermeier, E. and [MerrickandTaly,2019] Merrick, L. and Taly, A. (2019).
Waegeman, W. (2021). Aleatoric and epistemic uncer- The explanation game: Explaining machine learn-
tainty in machine learning: An introduction to concepts ing models using shapley values. arXiv preprint
andmethods. MachineLearning,110(3):457–506. arXiv:1909.08128.
[IgnatovandKwuida,2022] Ignatov, D. I. and Kwuida, L. [Mocˇkus,1975] Mocˇkus, J. (1975). On Bayesian methods
(2022). Onshapleyvalueinterpretabilityinconcept-based for seeking the extremum. In Optimization techniques
learning with formal concept analysis. Annals of Mathe- IFIPtechnicalconference,pages400–404.Springer.
maticsandArtificialIntelligence,90(11-12):1197–1222. [Molnar,2020] Molnar, C. (2020). Interpretable machine
[Jansenetal.,2023a] Jansen, C., Nalenz, M., Schollmeyer, learning. christophm.github.io.
G., and Augustin, T. (2023a). Statistical comparisons of [Molnaretal.,2018] Molnar, C., Casalicchio, G., and Bis-
classifiers by generalized stochastic dominance. Journal chl,B.(2018).iml:Anrpackageforinterpretablemachine
ofMachineLearningResearch,24(231):1–37. learning. JournalofOpenSourceSoftware,3(26):786.
[Jansenetal.,2023b] Jansen, C., Schollmeyer, G., Blocher, [Molnaretal.,2020] Molnar, C., Casalicchio, G., and Bis-
H.,Rodemann,J.,andAugustin,T.(2023b).Robuststatis- chl,B.(2020). Interpretablemachinelearning–abriefhis-
ticalcomparisonofrandomvariableswithlocallyvarying tory, state-of-the-art and challenges. In Joint European
scale of measurement. In Conference on Uncertainty in ConferenceonMachineLearningandKnowledgeDiscov-
ArtificialIntelligence(UAI),volume216,pages941–952. eryinDatabases,pages417–431.Springer.
PMLR.
[Nalenzetal.,2024] Nalenz, M., Rodemann, J., and Au-
[Kimetal.,2017] Kim, M., Ding, Y., Malcolm, P., Speeck- gustin,T.(2024). Learningde-biasedregressiontreesand
aert, J., Siviy, C. J., Walsh, C. J., and Kuindersma, forestsfromcomplexsamples. MachineLearning, pages
S. (2017). Human-in-the-loop bayesian optimization of 1–20.
wearabledeviceparameters. PloSone,12(9):e0184054. [Palejaetal.,2021] Paleja, R., Ghuy, M.,
[KocsisandSzepesva´ri,2006] Kocsis,L.andSzepesva´ri,C. Ranawaka Arachchige, N., Jensen, R., and Gombo-
(2006). Bandit based monte-carlo planning. In Euro- lay, M. (2021). The utility of explainable ai in ad hoc
pean Conference on Machine Learning, pages 282–293. human-machine teaming. In Advances in Neural Infor-
Springer. mation Processing Systems, volume 34, pages 610–623.
CurranAssociates,Inc.
[Loh,2014] Loh, W.-Y. (2014). Fifty years of classifica-
tionandregressiontrees. InternationalStatisticalReview, [Peters,2015] Peters, H. (2015). Game theory: A Multi-
82(3):329–348. leveledapproach. Springer.
[LundbergandLee,2017] Lundberg, S. and Lee, S.-I. [Psarosetal.,2023] Psaros, A. F., Meng, X., Zou, Z., Guo,
(2017). A Unified Approach to Interpreting Model Pre- L., and Karniadakis, G. E. (2023). Uncertainty quan-
dictions. arXivpreprintarXiv:1705.07874. tification in scientific machine learning: Methods, met-
rics,andcomparisons. JournalofComputationalPhysics,
[Lundbergetal.,2018] Lundberg, S. M., Erion, G. G., and
477:111902.
Lee,S.-I.(2018).Consistentindividualizedfeatureattribu-
[Pyzer-Knapp,2018] Pyzer-Knapp, E. O. (2018). Bayesian
tionfortreeensembles. arXivpreprintarXiv:1802.03888.
optimizationforaccelerateddrugdiscovery. IBMJournal
[Lutheretal.,2023] Luther, C., Ko¨nig, G., and Grosse- ofResearchandDevelopment,62(6):2–1.
Wentrup, M. (2023). Efficient sage estimation via causal
[RCoreTeam,2020] R Core Team (2020). R: A Language
structure learning. In Ruiz, F., Dy, J., and van de Meent,
andEnvironmentforStatisticalComputing. RFoundation
J.-W.,editors,ProceedingsofThe26thInternationalCon-
forStatisticalComputing,Vienna,Austria.
ference on Artificial Intelligence and Statistics, volume
206ofProceedingsofMachineLearningResearch,pages [Rafailovetal.,2024] Rafailov,R.,Sharma,A.,Mitchell,E.,
11650–11670.PMLR. Manning, C. D., Ermon, S., and Finn, C. (2024). Directpreferenceoptimization: Yourlanguagemodelissecretly Bayesianoptimisation.InKoyejo,S.,Mohamed,S.,Agar-
arewardmodel. AdvancesinNeuralInformationProcess- wal, A., Belgrave, D., Cho, K., and Oh, A., editors, Ad-
ingSystems,36. vances in Neural Information Processing Systems, vol-
ume35,pages16233–16245.
[Rodemann,2021] Rodemann,J.(2021). Robustgeneraliza-
tions of stochastic derivative-free optimization. Master’s [WangandChen,2023] Wang, Y.-C. and Chen, T. (2023).
thesis,LMUMunich. Adapted techniques of explainable artificial intelligence
for explaining genetic algorithms on the example of job
[RodemannandAugustin,2021] Rodemann, J. and Au-
scheduling. ExpertSystemswithApplications.
gustin, T. (2021). Accounting for imprecision of model
[Watsonetal.,2023] Watson, D. S., O’Hara, J., Tax, N.,
specification in bayesian optimization. In Poster pre-
Mudd, R., and Guy, I. (2023). Explaining predictive un-
sented at International Symposium on Imprecise Proba-
certaintywithinformationtheoreticshapleyvalues. arXiv
bilities(ISIPTA).
preprintarXiv:2306.05724.
[RodemannandAugustin,2022] Rodemann, J. and Au-
[Wu,2023] Wu, H.-C. (2023). Solving fuzzy optimiza-
gustin,T.(2022). AccountingforGaussianprocessimpre-
tion problems using shapley values and evolutionary al-
cisioninBayesianoptimization. InInternationalSympo-
gorithms. Mathematics,11(24):4871.
sium on Integrated Uncertainty in Knowledge Modelling
andDecisionMaking(IUKM),pages92–104.Springer. [Xiaoetal.,2022] Xiao,H.,Wang,Z.,Zhu,Z.,Zhou,J.,and
Lu, J. (2022). Shapley-nas: Discovering operation con-
[RodemannandBlocher,2024] Rodemann, J. and Blocher,
tributionforneuralarchitecturesearch. InProceedingsof
H.(2024). Partialrankingsofoptimizers. arXivpreprint
the IEEE/CVF Conference on Computer Vision and Pat-
arXiv:2402.16565.
ternRecognition(CVPR),pages11892–11901.
[Shapley,1953] Shapley,L.S.(1953). Avalueforn-person [Zhangetal.,2017] Zhang, J., Fiers, P., Witte, K. A., Jack-
games. ContributionstotheTheoryofGames,2(28):307– son, R. W., Poggensee, K. L., Atkeson, C. G., and
317. Collins, S. H. (2017). Human-in-the-loop optimiza-
[Siviyetal.,2023] Siviy,C.,Baker,L.M.,Quinlivan,B.T., tion of exoskeleton assistance during walking. Science,
356(6344):1280–1284.
Porciuncula, F., Swaminathan, K., Awad, L. N., and
Walsh, C. J. (2023). Opportunities and challenges in
thedevelopmentofexoskeletonsforlocomotorassistance.
NatureBiomedicalEngineering,7(4):456–472.
[Snoeketal.,2012] Snoek, J., Larochelle, H., and Adams,
R.P.(2012). PracticalBayesianoptimizationofmachine
learningalgorithms. AdvancesinNeuralInformationPro-
cessingSystems,25:2951–2959.
[Srinivasetal.,2012] Srinivas, N., Krause, A., Kakade,
S. M., and Seeger, M. W. (2012). Information-theoretic
regretboundsforgaussianprocessoptimizationintheban-
dit setting. IEEE transactions on Information Theory,
58(5):3250–3265.
[SˇtrumbeljandKononenko,2014] Sˇtrumbelj, E. and
Kononenko, I. (2014). Explaining prediction models
and individual predictions with feature contributions.
KnowledgeandInformationSystems,41(3):647–665.
[Tallo´n-BallesterosandChen,2020] Tallo´n-Ballesteros, A.
andChen,C.(2020). Explainableai: Usingshapleyvalue
to explain complex anomaly detection ml-based systems.
MachineLearningandArtificialIntelligence,332:152.
[Toxirietal.,2019] Toxiri, S., Na¨f, M. B., Lazzaroni, M.,
Ferna´ndez,J.,Sposito,M.,Poliero,T.,Monica,L.,Anas-
tasi, S., Caldwell, D. G., and Ortiz, J. (2019). Back-
support exoskeletons for occupational use: an overview
of technological advances and trends. IISE Transactions
on Occupational Ergonomics and Human Factors, 7(3-
4):237–249.
[Venkateshetal.,2022] Venkatesh,A.K.,Rana,S.,Shilton,
A., and Venkatesh, S. (2022). Human-ai collaborative