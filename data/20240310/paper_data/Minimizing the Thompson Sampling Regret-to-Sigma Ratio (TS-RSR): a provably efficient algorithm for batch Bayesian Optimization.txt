Minimizing the Thompson Sampling Regret-to-Sigma Ratio
(TS-RSR): a provably efficient algorithm for batch Bayesian
Optimization
Zhaolin Ren, Na Li ∗
March 8, 2024
Abstract
This paper presents a new approach for batch Bayesian Optimization (BO), where the sampling takes
place by minimizing a Thompson Sampling approximation of a regret to uncertainty ratio. Our objective
isabletocoordinatetheactionschosenineachbatchinawaythatminimizesredundancybetweenpoints
whilst focusing on points with high predictive means or high uncertainty. We provide high-probability
theoretical guarantees on the regret of our algorithm. Finally, numerically, we demonstrate that our
method attainsstate-of-the-art performanceon a rangeof nonconvextest functions, where itoutperforms
several competitive benchmark batch BO algorithms by an order of magnitude on average.
1 Introduction
We are interested in the following problem. Let X ⊂ Rd be a bounded compact set. Suppose we wish to
maximize an unknown function f :X →R, and our only access to f is through a noisy evaluation oracle,
i.e. y =f(x)+ϵ, ϵ∼N(0,σ2), with σ >0. We consider the batch setting, where we assume that we are
n n
able to query f over T rounds, where at each round, we can send out m queries in parallel. We are typically
interested in the case when m>1, where we expect to do better than when m=1. In particular, we are
interested in quantifying the “improvement” that a larger m can give us.
To be more precise, let us discuss our evaluation metrics. Let x denote the query point of the i-th agent
t,i
at the t-th time. Let x∗ ∈X denote a maximizer of f. In this paper, we provide high-probability bounds for
the cumulative regret R , where
T,m
T m
(cid:88)(cid:88)
R := [f(x∗)−f(x )].
T,m t,i
t=1 i=1
We also define the simple regret as
S := min min f(x∗)−f(x ),
T,m t,i
t∈[T]i∈[m]
where we note the use of the notation [N]:={1,2,...,N} (for any positive integer N), which we will use
throughout the paper. We observe that the simple regret satisfies the relationship S ⩽ 1 R . This
T,m Tm T,m
shows that a bound on the cumulative regret translates to a bound on the simple regret.
∗ZhaolinRenandNaLiarewithHarvardUniversity,Email: zhaolinren@g.harvard.edu, nali@seas.harvard.edu
1
4202
raM
7
]GL.sc[
1v46740.3042:viXraWithout any assumptions on the smoothness and regularity of f, it may be impossible to optimize it in a
limited number of samples; consider for instance functions that wildly oscillate or are discontinuous at many
points. Thus, in order to make the problem tractable, we make the following assumption on f.
Assumption 1. [GP model] We model the function f as a sample from a Gaussian Process (GP), where
GP(0,k(·,·)) is our GP prior over f. A Gaussian Process GP(µ(x),k(x,x′)) is specified by its mean function
µ(x)=E[f(x)] and covariance function k(x,x′)=E[(f(x)−µ(x))(f(x′)−µ(x′))].
There are several existing algorithms for batch Bayesian optimization with regret guarantees, e.g. batch-
UpperConfidenceBound(UCB)[Srinivas et al., 2009],batch-Thompsonsampling(TS)[Kandasamy et al., 2018].
There are known guarantees on the cumulative regret of batch-UCB and batch TS. However, empirical
performance of batch-UCB and batch-TS tend to be suboptimal. A suite of heuristic methods have been
developedforbatchBO,e.g. [Ma et al., 2023,Garcia-Barcos and Martinez-Cantin, 2019a,Gong et al., 2019].
However, theoretical guarantees are typically lacking for these algorithms.
This inspires us to ask the following question:
Can we design theoretically grounded, effective batch BO algorithms that also satisfy rigorous
guarantees?
Inspiredbytheinformation-directedsampling(IDS)literature[Russo and Van Roy, 2014,Baek and Farias, 2023],
we introduce a new algorithm for Bayesian Optimization (BO), which we call Thompson Sampling-Regret to
Sigma Ratio directed sampling (TS−RSR). The algorithm works for any setting of the batch size m, and is
thus also appropriate for batch BO. Our contributions are as follows.
First, on the algorithmic front, we propose a novel sampling objective for BO that automatically balances
exploitation and exploration in a parameter-free manner (unlike for instance in UCB-type methods, where
setting the confidence interval typically requires the careful choice of a hyperparameter). In particular, for
batch BO, our algorithm is able to coordinate the actions chosen in each batch in an intelligent way that
minimizes redundancy between points.
Second, on the theoretical front, we show that under mild assumptions, the cumulative regret R
√ T,m
of our algorithm scales as O˜(ρ mT) with the number of time-steps T and batch size m, yielding a
m
(cid:16) (cid:17)
simple regret of O˜ √ρm . The ρ
m
is a problem dependent quantity that scales linearly with m for the
mT
squared exponential kernel, but with an appropriate modification to our algorithm (cf. Appendix B in
(cid:16) (cid:17)
[Desautels et al., 2014]), can be reduced to o(m), yielding a simple regret of O˜ √1 , which decays at the
√ mT
optimal rate of 1/ m as the batch size m increases [Chen et al., 2022]. Along the way, we derive a novel
high-probability bound for a frequentist version of the regret-sigma ratio, which is known to be a challenging
problem [Kirschner and Krause, 2018].
Finally,empirically,weshowviaexperimentsonarangeofcommonnonconvextestfunctions(Ackley,Bird
and Rosenbrock functions) that our algorithm attains state-of-the-art performance in practice, outperforming
other benchmark algorithms for batch BO by an order of magnitude on average.
2 Related work
There is a vast literature on Bayesian Optimization (BO) [Frazier, 2018] and batch BO. One popular class
of methods for BO and batch BO is UCB-inspired methods, [Srinivas et al., 2009, Desautels et al., 2014,
Kaufmann et al., 2012, Daxberger and Low, 2017]. Building on the seminal work in [Srinivas et al., 2009]
which studied the use of the UCB acquisition function in BO with Gaussian Process and provided regret
bounds, subsequent works have extended this to the batch setting. The most prominent approach in this
direction is Batch UCB (BUCB) [Desautels et al., 2014], which is a sequential sampling strategy that keeps
2the posterior mean constant throughout the batch but updates the covariance as the batch progresses.
Another notable work combines UCB with pure exploration by picking the first action in a batch using UCB
and subsequent actions in the batch by maximizing posterior uncertainty. One key drawback of UCB-type
methods is the strong dependence of empirical performance on the choice of the β parameter; note that in
t
UCB-type methods, the UCB-maximizing action is typically determined as xUCB ∈argmaxµ (x)+β σ (x),
t t t t
where β shapes the weight allocation between the posterior mean µ and posterior uncertainty σ . While
t t t
there exist theoretically valid choices of β that ensure convergence, practical implementations typically
t
requiring heuristic tuning of the β parameter. In contrast, in our algorithm, we do not require the tuning of
t
such a β parameter.
t
Another popular class of methods is Thompson Sampling (TS)-based methods [Kandasamy et al., 2018,
Dai et al., 2020, Hernández-Lobato et al., 2017]. The downside of TS-based methods is the lack of penal-
ization for duplicating actions in a batch, which can result in over-exploitation and a lack of diversity, as
discussed for instance in [Adachi et al., 2023]. On the other hand, as we will see, our method does penalize
duplicating samples, allowing for better diversity across samples.
Wenotethatinformationalapproachesbasedonmaximizinginformationalmetricshavealsobeenproposed
forBO[Hennig and Schuler, 2012,Hernández-Lobato et al., 2015,Wang et al., 2016,Wang and Jegelka, 2017]
andbatchBO[Shah and Ghahramani, 2015,Garrido-Merchán and Hernández-Lobato, 2019,Takeno et al., 2020,
Hvarfner et al., 2022]. While such methods can be effective for BO, efficient extension of these methods to
the batch BO setting is a challenging problem, since the computational complexity of searching for a batch of
actionsthatmaximizeinformationabout(forinstance)thelocationofthemaximizerscalesexponentiallywith
the size of the batch. One interesting remedy to this computational challenge is found in [Ma et al., 2023],
whichproposesanefficientgradient-descentbasedmethodthatusesaheuristicapproximationoftheposterior
maximum value by the Gaussian distribution for the output of the current posterior UCB. However, this
method also relies on the tuning of the β parameter in determining the UCB, and also does not satisfy any
t
theoretical guarantees.
There are also a number of other works in batch BO which do not fall neatly into the categories above.
These include an early work that tackles batch BO by trying to using Monte-Carlo simulation to select
input batches that closely match the expected behavior of sequential policies [Azimi et al., 2010]. However,
being a largely heuristic algorithm, no theoretical guarantees exist. Other heuristic algorithms include an
algorithm [Gonzalez et al., 2015] that proposes a batch sampling strategy that utilizes an estimate of the
function’s Lipschitz constant, Acquisition Thompson Sampling (ATS) [De Palma et al., 2019], which is based
on the idea of sampling multiple acquisition functions from a stochastic process, as well as an algorithm
that samples according to the Boltzman distribution with the energy function given by a chosen acquisition
function [Garcia-Barcos and Martinez-Cantin, 2019b]. However, being heuristics, these algorithms are not
known to satisfy any rigorous guarantees. An interesting recent work proposes inducing batch diversity in
batch BO by leveraging the Determinental Point Process (DPP) [Nava et al., 2022], and provides theoretical
guarantees for their algorithm. However, a limitation of the algorithm is that the computational complexity
of sampling scales exponentially with the number of agents, limiting the application of the algorithm for
large batch problems. For large batch problems, there has been a very recent work [Adachi et al., 2023]
that seeks scalable and diversified batch BO by reformulating batch selection for global optimization as a
quadrature problem. Nonetheless, this algorithm lacks theoretical guarantees, and being designed for large
batch problems, e.g. m in the hundreds, it may fail to be effective for moderate m problems, e.g. m less than
50.
Finally, we note that a strong inspiration on our work comes from ideas in the information directed
sampling literature (e.g. [Russo and Van Roy, 2014, Baek and Farias, 2023, Kirschner and Krause, 2018]),
where the sampling at each stage also takes place based on the optimization of some regret to uncertainty
ratio. While [Russo and Van Roy, 2014] and [Baek and Farias, 2023] did not cover the setting of BO with
Gaussian Process (GP), we note that the algorithm in [Kirschner and Krause, 2018] does apply to BO with
3GP, and they also provided high-probability regret bounds. However, the design of the sampling function in
[Kirschner and Krause, 2018] also requires choosing a β parameter (similar to UCB type methods), which
t
as we observed can be hard to tune in practice.
3 Problem Setup and Preliminaries
In the sequel, we denote f∗ := f(x∗). Let Xt,m := {x ,...,x ,x ,...x ,...,x ,...,x } ∈ Xtm
1,1 1,m 2,1 2,m t,1 t,m
denotethetmpointsevaluatedbythealgorithmaftertiterationswherempointswereevaluatedperiteration,
with x denoting the j-th point evaluated at the τ-th batch; for notational convenience, we omit the
τ,j
dependence on the batch number m and refer to Xt,m as Xt througout the paper. Then, for any x∈X, we
note that f |F ∼GP(µ (x),k (x,x′)), where
t t t
µ (x)=k (x)⊤(K +σ2I)−1y ,
t t t n t
k (x,x′)=k(x,x′)−k (x)⊤(K +σ2I)−1k (x′),
t t t n t
where K :=[k(x′,x′′)] denotes the empirical kernel matrix, k (x):=[k(x′,x)] , and y denotes
t x′,x′′∈Xt t x′∈Xt t
{f(x′)+ϵ′} , where we recall that ϵ′ ∼N(0,σ2). In particular, for any x∈X, we have that f(x)|F ∼
x′∈Xt n t
N(µ (x),σ2(x)), where the posterior variance satisfies
t t
σ2(x)=k(x,x)−k (x)⊤(K +σ2I)−1k (x). (1)
t t t t
For any set of B points {x } ∈X, we also find it useful to introduce the following notation of posterior
b b∈[B]
variance σ2(x|{x } ), where
t b b∈[B]
σ2(x|{x } ) (2)
t b b∈[B]
:= k(x,x)−k (x)⊤(K +σ2I)−1k (x), (3)
t,B Xt∪[B] t,B
where k (x) represents the concatenation of k (x) and [k(x ,x)] , and K ∈R(tm+B)×(tm+B) is a
t,B t b b∈[B] Xt∪[B]
block matrix of the form
(cid:20) (cid:21)
K K
K = t t,B
Xt∪[B] K⊤ K ,
t,B B,B
where K = [k(x′,x )] ∈ Rtm×B, and K = [k(x ,x )] ∈ RB×B. In other words,
t,B b x′∈Xt,b∈[B] B,B b b′ b,b′∈[B]
σ2(x|{x } ) denotes the posterior variance conditional on having evaluated Xt as well an additional set
t b b∈[B]
of points {x } .
b b∈[B]
To streamline our analysis, we focus our attention on the case when X is a discrete (but possibly large
depending exponentially on the state dimension d) set, which has size D.
4 Algorithm
For clarity, we first describe our algorithm in the case when the batch size m is 1. At each time t, the
algorithm chooses the next sample according to the following criterion:
f˜∗−µ (x)
x ∈argmin t t =:Ψ (x), (4)
t+1 σ (x) t
x∈X t
where f˜∗ := max f˜(x), where f˜ is a single sample from the distribution f | F . The numerator can be
t x t t t
regardedasaTSapproximationoftheregretincurredbytheactionx,whilstthedenominatoristhepredictive
4standard deviation/uncertainty of the point x. This explains the name of our algorithm. In this case, the
sampling scheme balances choosing points with high predictive mean with those which have high predictive
uncertainty.
In the batch setting, where we have to choose a batch of points simultaneously before receiving feedback,
our algorithm takes the form
f˜∗ −µ (x)
xTS−RSR ∈argmin t,1 t
t+1,1 σ (x)
x∈X t
f˜∗ −µ (x)
xTS−RSR ∈argmin t,2 t
t+1,2 x∈X σ t(cid:0) x|{xT t+S 1− ,1RSR}(cid:1)
.
.
.
f˜∗ −µ (x)
xTS−RSR ∈argmin t,m t (5)
t+1,m x∈X σ t(cid:0) x|{xT t+S 1− ,jRSR}m j=− 11(cid:1)
where for each i∈[m], f˜∗ :=max f˜ (x), where f˜ denotes an independent sample from the distribution
t,i x t,i t,i
f | F . Meanwhile, σ (x | {x }τ ) denotes the predictive standard deviation of the posterior GP
t t t+1,j j=1
conditionalonF ={Xt,y },aswellasonthefactthatthefirstτ actionsinthe(t+1)-thbatch,{x }τ ,
t t t+1,j j=1
have been sampled; we recall here that the predictive variance only depends on the points that have been
picked, andnotthevaluesofthosepoints(see(1)). Intuitively, thedenominatorin(5)encouragesexploration,
since it is large when the sample points are both uncertain conditional on the knowledge so far (F ) and
t
are spaced far apart. In addition, the numerator in (5) is high for points with higher predictive means
conditional on F . So, the objective strikes a balance between picking batches of points which have high
t
uncertainty/spatial separation and points with high predictive means.
We note that in the m=1 case, our method is similar to the TS-UCB method in [Baek and Farias, 2023]
which applies to finite-armed multi-arm bandit problems as well as linear regression problems. However,
our extension (and analysis) of our method to the setting of BO with GP is new; moreover, we provide
frequentist regret bounds, which is considered to be more challenging [Kirschner and Krause, 2018], instead
of the Bayesian regret bounds in [Baek and Farias, 2023]. However, in the batch setting when m>1, the
objective in our algorithm appears to be novel.
5 Analysis
As we stated earlier, to streamline our analysis, we focus our attention on the case when X is a discrete
set of size D. However, we stress that our algorithm works also for compact bounded sets X; indeed under
appropriate smoothness assumptions on the kernel, we believe our analysis also carries over the continuous
space setting. We will address this issue more in a remark following the statement of our main result later.
5.1 Proof outline
To faciliate understanding of our theoretical analysis, we provide the following proof outline.
1. (Part 1) Our first task is to upper bound the Regret-to-Sigma Ratio (RSR) for our chosen iterates
xTS−RSR, which, as presented in (5), takes the form
t+1,[m]
f˜∗ −µ (x)
xTS−RSR ∈argmin t,1 t
t+1,1 σ (x)
x∈X t
5Algorithm 1 TS−RSR
1: Input: Input set X; GP Prior µ 0 =0, k, output noise standard deviation σ n; batch size m
2: for t=0,1,··· ,T −1 do
3: Sample m i.i.d copies of f˜ t,i ∼f |F t, and set f˜ t∗ ,i =max xf˜ t,i(x).
4: Choose
f˜∗ −µ (x)
xTS−RSR ∈argmin t,1 t
t+1,1 σ (x)
x∈X t
f˜∗ −µ (x)
xTS−RSR ∈argmin t,2 t
t+1,2 x∈X σ t(x|{xT t+S 1− ,1RSR})
.
.
.
f˜∗ −µ (x)
xTS−RSR ∈argmin t,m t
t+1,m x∈X σ t(x|{xT t+S 1− ,jRSR}m j=− 11)
5: Observe y t+1,i =f(xT t+S 1− ,iRSR)+ϵ t+1,i for each i∈[m]
6: Perform Bayesian update to obtain µ t+1,σ t+1
7: end for
f˜∗ −µ (x)
xTS−RSR ∈argmin t,2 t
t+1,2 x∈X σ t(cid:0) x|{x tT +S 1− ,1RSR}(cid:1)
.
.
.
f˜∗ −µ (x)
xTS−RSR ∈argmin t,m t
t+1,m x∈X σ t(cid:0) x|{x tT +S 1− ,jRSR}m j=− 11(cid:1)
To do so, we will show that the iterates xTS produced by a particular kind of Thompson Sampling has
t+1,i
boundedRSR,inthesensethatforeachi∈[m],Ψ (xTS )isbounded,wherexTS ∈argmax f˜ (x),
t,i t+1,i t+1,i x t,i
and
f˜∗ −µ (x)
Ψ (x):= t,i t
t,i σ (x|{xTS−RSR}i−1)
t t+1,j j=1
This in turn implies a bound for Ψ (xTS−RSR), since Ψ (xTS−RSR) ⩽ Ψ (xTS ) by definition of
t,i t+1,i t,i t+1,i t,m t+1,i
xTS−RSR.
t+1,i
We defer more discussion to Section 5.3. By Lemma 3 in Section 5.3, we find that with probability at
least 1−δ, we have for every 0⩽t⩽T −1 and i∈[m] that
f˜∗ −µ (xTS−RSR)
Ψ (xTS−RSR)= t,i t t+1,i ⩽ (cid:112) 2log(DT/δ)ρ , (6)
t,i t+1,i σ (xTS−RSR |{xTS−RSR}i−1) m
t t+1,i t+1,j j=1
where ρ :=max max max στ(x) denotes the maximal decrease in posterior variance
m x∈X τ X˜⊂X,|X˜|⩽m στ(x|X˜)
resulting from conditioning on an additional set of samples X˜ of cardinality up to m.
2. (Part 2) Next, we state the following result, which we will find useful in Part 3 of the outline.
6Lemma 1. Suppose k(x,x)⩽1 for each x∈X. Then, letting C :=2σ2/log(1+σ2), we have
1 n n
T−1 m
(cid:88)(cid:88)
σ2(xTS−RSR |{xTS−RSR}i−1)⩽σ2C γ ,
t t+1,i t+1,j j=1 n 1 Tm
t=0 i=1
where
γ := sup I(y ;y ).
Tm A A
A⊂X,|A|=Tm
Proof. The proof follows by the calculations in Lemma 5.4 of [Srinivas et al., 2009], which in turn
utilizes Lemma 4, which relates informational gain with the predictive variances.
3. (Part 3) Next, we can combine the first two steps, such that with probability at least 1−δ,
T−1 m
(cid:88)(cid:88) f∗−f(xTS−RSR)
t+1,i
t=0i=1
T−1 m
= (cid:88)(cid:88) f∗−f˜ t∗ ,i+f˜ t∗ ,i−µt(xT t+S 1− ,iRSR)
t=0i=1
+µt(x tT +S 1− ,iRSR)−f(xT t+S 1− ,iRSR)
T−1(cid:32)m (cid:33)
= (cid:88) (cid:88) (f∗−f˜ t∗ ,i)+(µt(xT t+S 1− ,iRSR)−f(xT t+S 1− ,iRSR))
t=0 i=1
+T (cid:88) t=− 01 (cid:88) im
=1σt(xT
t+f S˜ t∗ 1−, ,i iR− SRµt |( {x xT t
T
t+S +S1− 1−,i ,R jRS SR R)
}i j− =1
1)σt(xT t+S 1− ,iRSR|{xT t+S 1− ,jRSR}i j− =1 1)
( ⩽i) T (cid:88)−1(cid:32) (cid:88)m
(f∗−f˜ t∗ ,i)+(µt(xT t+S 1− ,iRSR)−f(xT t+S 1−
,iRSR))(cid:33)
t=0 i=1
T−1 m
+Ψ¯(δ)(cid:88)(cid:88) σt(xT t+S 1− ,iRSR|{xT t+S 1− ,jRSR}i j− =1 1)
t=0i=1
( ⩽ii) T (cid:88)−1(cid:32) (cid:88)m
(f∗−f˜ t∗ ,i)+(µt(xT t+S 1− ,iRSR)−f(xT t+S 1−
,iRSR))(cid:33)
t=0 i=1
(cid:118)
(cid:117) T−1 m
+Ψ¯(δ)(cid:117) (cid:116)Tm(cid:88)(cid:88) σ2(xTS−RSR|{xTS−RSR}i−1)
t t+1,i t+1,j j=1
t=0i=1
( ⩽iii) T (cid:88)−1 (cid:88)m
(f∗−f˜ t∗
,i)+T (cid:88)−1 (cid:88)m
(µt(xT t+S 1− ,iRSR)−f(xT t+S 1− ,iRSR))
t=0i=1 t=0i=1
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Sum1 Sum2
+Ψ¯(δ)σn(cid:112) C1(cid:112)
TmγTm.
Above, for (i), we used the bound in (6) from part 1 of the proof outline, as well as the definition
(cid:32) f˜∗ −µ (xTS−RSR) (cid:33)
Ψ¯(δ):= max max t,i t t+1,i .
t=0,...,T−1 i∈[m]σ t(x tT +S 1− ,iRSR |{xT t+S 1− ,jRSR} ji− =1 1)
In addition, we used Jensen’s inequality to derive (ii). For the last inequality in (iii), we used our
informational bound on the sum of the predictive variances in Lemma 1.
4. (Part 4) We will bound Sum using a Martingale concentration inequality. To do so, we use a neat
1
decomposition trick that we detail in Lemma 6 in Section 8.2 in the Appendix, which states that with
probability at least 1−δ,
(cid:112)
Sum ⩽2 Tmlog(1/δ).
1
75. (Part 5) For Sum , we observe that
2
Sum2
T−1 m
= (cid:88)(cid:88) (µt(xT t+S 1− ,iRSR)−f(xT t+S 1− ,iRSR))
t=0i=1
T−1 m
= (cid:88)(cid:88) (µt(xT t+S 1− ,iRSR)−f˜ t,i(xT t+S 1− ,iRSR))
t=0i=1
(cid:124) (cid:123)(cid:122) (cid:125)
Sum2,1
T−1 m
+ (cid:88)(cid:88) (f˜ t,i(xT t+S 1− ,iRSR)−f(xT t+S 1− ,iRSR)),
t=0i=1
(cid:124) (cid:123)(cid:122) (cid:125)
Sum2,2
wheref˜ denotesarandomsamplefromf |F . Sum andSum arebothsubGaussianmartingales,
t,i t 2,1 2,2
and as stated in Lemma 7 in Section 8.2 in the Appendix, with probability at least 1−2δ,
(cid:112)
Sum ⩽4 Tmlog(1/δ).
2
6. (Part 6) Putting everything together, we find that with probability at least 1−4δ, we have
T−1 m
(cid:88)(cid:88)
R = f∗−f(xTS−RSR)
T,m t+1,i
t=0 i=1
√ √
⩽Ψ¯(δ)(cid:112) Tmγ +6(cid:112) 2logD/δ Tm⩽ρ (cid:112) 2logDT/δ(cid:112) Tmγ +6(cid:112) 2logD/δ Tm,
Tm m Tm
where to derive the last inequality, we plugged in (6).
5.2 Main result
Following the proof outline above, we have the following main result.
Theorem 1. Consider any 0 < δ < 1. Suppose k(x,x′) ⩽ 1 for all x,x′. Let X be a discrete set with D
elements. Then, running TS−RSR for a sample f of a GP with mean zero and covariance k(x,x′), with
probability at least 1−δ, we have
(cid:32) (cid:115) (cid:18) (cid:19) (cid:33)
(cid:112) Tm
R =O ρ Tmγ log +logD ,
T,m m Tm δ
where ρ := max max max στ(x) , and γ denotes the maximal informational gain by
m x∈X τ X˜⊂X,|X˜|⩽m στ(x|X˜) Tm
observing Tm elements.
Proof. The proof follows by Part 6 of the proof outline.
Remark 1. We note that in general, the term ρ may scale linearly with m. However, following a well-known
m
trick where we have an exploration phase of length T where we always sample the point with the highest
init
predictive variance (cf. [Desautels et al., 2014]), we may reduce ρ to be of size o(m), at the expense of
m
a O˜(T ) term in the regret. For large enough Tm, the resulting simple regret will then be of the order
init
(cid:16)√ √ (cid:17)
O˜ √logD γ
Tm
. Then, the dependence of the simple regret on the batch size m scales with the square root
Tm
m, which is in general the best possible dependence [Chen et al., 2022].
8Remark 2. The information gain γ can be bounded for several well-known kernels, as shown in
Tm
[Srinivas et al., 2009, Vakili et al., 2021]. We have
1. (Linear kernel): γ =O(dlog(Tm))
Tm
2. (Squared exponential kernel): γ =O((log(Tm))d+1)
Tm
d(d+1)
3. (Matern kernel with ν >1): γ
Tm
=O((Tm)2ν+d(d+1) log(Tm))
Remark 3. Finally, we note that while our analysis focused on the discrete case, for kernels where the
resulting GP sample functions are differentiable with high probability, such as the squared exponential kernel
kernel or the Matern kernel (with ν parameter at least 1.5), the analysis of regret for a bounded compact
set X ∈Rd can be essentially reduced to the analysis of a discretization D of X where D is on the order of
D =ϵ−d, where 0<ϵ<1 is a discretization parameter that is a function of the smoothness of the kernel; see
for instance the analysis in [Srinivas et al., 2009]. Then, a regret bound for the discrete set D that depends
√
on the square root of logD translates to a regret bound that depends on logD for the original setting with
√
a bounded compact X, i.e. a bound that depends on O˜( dlog(1/ϵ)). For instance, in combination with the
preceding remark, for the linear kernel, our regret bound then becomes
(cid:16) √ (cid:17)
R =O˜ dρ log(Tm)log(1/ϵ) Tm ,
T,m m
matching known bounds in the batch BO literature (e.g. the bound for the batch UCB algorithm BUCB in
[Desautels et al., 2014]).
A key step in our analysis took place in part 1 of our proof outline, where we found a bound for the
Regret-to-Sigma Ratio (RSR). We discuss this step in detail next.
5.3 Bounding the RSR
To bound the Regret-Sigma Ratio (RSR), we first need the following result.
Lemma 2. Suppose Y ∼N(µ,Σ), where µ∈RD and Σ≻0 . For each j ∈[D], we denote σ2 :=Σ .
D×D j j,j
Let ℓ∗ =argmax Y , and denote Y∗ =max Y =Y . Then, for any δ >0, with probability at least
j∈[D] j j∈[D] j ℓ∗
1−δ, we have
Y∗−µ ℓ∗ ⩽(cid:112)
2log(D/δ)
σ
ℓ∗
Proof. Note that for each ℓ∈[D], for any t>0,
(cid:18) (cid:19)
Y −µ
P ℓ ℓ ⩾t ⩽exp(−t2/2)
σ
ℓ
(cid:112)
Pick t= 2log(D/δ). Then, it follows that for any ℓ∈[D],
P (cid:18) Y ℓ−µ ℓ ⩾(cid:112) 2log(D/δ)(cid:19) ⩽ exp(cid:16) −((cid:112) 2log(D/δ))22(cid:17)
σ
ℓ
δ
= .
D
Thus, by applying union bound, we have that
(cid:18) (cid:19)
P ∀ℓ∈[D]: Y ℓ−µ ℓ ⩽(cid:112) 2log(D/δ) ⩾1−δ. (7)
σ
ℓ
9Consider ℓ∗ such that Y =max Y . Then, it follows by (7) that
ℓ∗ ℓ∈[D] ℓ
Y ℓ∗ −µ ℓ∗ ⩽(cid:112)
2log(D/δ)
σ
ℓ∗
also holds with probability at least 1−δ.
We are now ready to state and prove the following result that provides an explicit bound for the RSR.
Lemma 3. With probability at least 1−δ, we have for every t∈{0,1,...,T −1} and i∈[m] that
f˜∗ −µ (xTS−RSR)
t,i t t+1,i
σ (xTS−RSR |{xTS−RSR}i−1)
t t+1,i t+1,j j=1
f˜∗ −µ (xTS )
⩽ t,i t t+1,i
σ (xTS |{xTS−RSR}i−1)
t t+1,i t+1,j j=1
⩽ (cid:112) 2log(DT/δ)ρ :=Ψ¯(δ)
m
Proof. We start by noting that at any time t, that for each i ∈ [m], f˜∗ := max f˜ (x), where f˜ is an
t,i x t,i t,i
independent sample from f | F . Let xTS := argmax f˜ (x); we use TS in the superscript of xTS to
t t+1,i x t,i t+1,i
represent the fact that if we performed Thompson sampling and drew m independent samples from x∗ |F to
t
be our action, we will play exactly the policy {xTS }m . By applying Lemma 2, we see that for any δ >0,
t+1,i i=1
with probability at least 1−δ,
(cid:16) (cid:17)
f˜∗ −µ (xTS )
t,i t t+1,i (cid:112)
⩽ 2log(D/δ).
σ (xTS )
t t+1,i
By denoting ρ to be
m
σ (x)
ρ :=maxmax max τ , (8)
m x∈X τ X˜⊂X,|X˜|⩽mσ τ(x|X˜)
we then obtain that
σ (xTS )⩽ρ σ (xTS |{xTS−RSR}i−1),
t t+1,i m t t+1,i t+1,j j=1
which implies that
(cid:16) (cid:17)
f˜∗ −µ (xTS )
t,i t t+1,i (cid:112)
⩽ 2log(D/δ)ρ .
σ (xTS |{xTS−RSR}i−1) m
t t+1,i t+1,j j=1
Thus on the event
E
(δ):=(cid:40)
∀i∈[m]:
f˜ t∗ ,i−µ t(xT t+S 1,i) ⩽(cid:112) 2log(D/δ)(cid:41)
, (9)
t σ (xTS )
t t+1,i
we then have that
∀i∈[m]:
f˜ t∗ ,i−µ t(xT t+S 1,i) ⩽(cid:112)
2log(D/δ)ρ ,
σ (xTS |{xTS−RSR}i−1) m
t t+1,i t+1,j j=1
10Since
f˜∗ −µ (x)
xTS−RSR ∈argmin t,i t ,
t+1,i x∈X σ t(x|{x tT +S 1− ,jRSR}i j− =1 1)
this implies that on the event E (δ),
t
f˜∗ −µ (xTS−RSR) f˜∗ −µ (xTS )
∀i∈[m]: t,i t t+1,i ⩽ t,i t t+1,i
σ (xTS−RSR |{xTS−RSR}i−1) σ (xTS |{xTS−RSR}i−1)
t t+1,i t+1,j j=1 t t+1,i t+1,j j=1
(cid:112)
⩽ 2log(D/δ)ρ
m
The final result then follows by resetting δ := δ and a union bound.
T
6 Numerical results
WetestedouralgorithmagainstarangeofbatchBOalgorithmsonthreenonconvexfunctions,withabatchsize
ofm=5: Ackleyfunction,Birdfunction,andRosenbrock(allintwodimensions);wenotethatwepickedthese
test functions before running the experiments, and thus no “cherry picking” of test functions was done. The
heatmapsofthethreefunctionsaredepictedinFigure6. Theperformanceofouralgorithmiscomparedagainst
the following competitors: namely Batch UCB (BUCB, [Desautels et al., 2014]), Thompson Sampling (TS,
[Kandasamy et al., 2018]),GP-UCBwithpureexploitation(UCBPE,[Contal et al., 2013]),FullyDistributed
Bayesian Optimization with Stochastic Policies (SP, [Garcia-Barcos and Martinez-Cantin, 2019a]), as well
as a sequential kriging version of Expected Improvement (EI, [Zhan and Xing, 2020], [Hunt, 2020]). Our
experimental setup is as follows. For the GP prior, we use the Matern kernel with ν parameter set as
ν =1.5. For the likelihood noise, we set ϵ∼N(0,σ2), where σ =0.001. We compute the performance of the
n n
algorithms across 10 runs, where for each run, each algorithm has access to the same random initialization
dataset with 15 samples. Finally, we note that in a practical implementation of our algorithm, for any given t
and i ∈ [m], it may happen that f˜∗ < µ (x), in which case the algorithm will simply pick out the action
t,i t
x with the highest µ (x). While such a situation does not affect the theoretical convergence, for better
t
empirical performance that encourages more diversity, we resample f˜∗ whenever f˜∗ < max µ (x), until
t,i t,i x t
f˜∗ >max µ (x).
t,i x t
As we see in Figure 6, our algorithm strongly outperforms the other algorithms for both the Ackley and
Bird functions, whilst also outperforming other algorithms on Rosenbrock. To get a better sense of the
strength of the algorithm over its competitors, we consider Table 1. In this table, we normalize the simple
regret attained by an algorithm for a test function at the final iteration (150) by the simple regret attained
by the best performing algorithm for that test function. In other words, the best performing algorithm
for a test function will attain a ratio of 1 (which is good), and a badly performing algorithm might have
a ratio significantly higher than 1. As we can see, TS−RSR attains the lowest ratio (1.0) across all three
test functions, indicating its strength over the other algorithms. Moreover, in the last column of the table,
where we show the average performance ratio of each algorithm across the three test functions, we see that
TS−RSR is an order of magnitude better than the closest competitor (TS).
11Figure 1: Test functions on the numerical experiments (Ackley on the left, Bird in the middle, Rosenbrock on
the right)
ackley bird rosenbrock
BUCB 102 BUCB BUCB
UCBPE UCBPE UCBPE
SP 101 SP SP
100 T ES
I
T ES
I
100 T ES
I
TS-RSR 100 TS-RSR TS-RSR
101 101 101
102
102 103 102
104
0 20 40 60 80 100 0 20 40 60 80 100 0 20 40 60 80 100
iteration iteration iteration
Figure 2: Simple regret, batch size m=5. Each curve is the average of 10 runs.
Table 1: Ratio of simple regret at the 100-th iteration to that of the best algorithm for the test function,
batch size m=5 (the lower the ratio, the better)
Algorithm Ackley Bird Rosenbrock Average Ratio
BUCB 21.2 67.9 3.7 30.9
UCBPE 26.0 251.4 43.6 107.0
SP 20.6 384.8 25.2 143.5
TS 16.1 14.1 1.9 10.7
EI 14.4 74.1 4.0 30.8
TS-RSR 1.0 1.0 1.0 1.0
7 Conclusion
In this paper, we introduced a new algorithm, TS−RSR, for the problem of batch BO. We provide strong
theoretical guarantees for our algorithm via a novel analysis, which may be of independent interest to
researchers interested in frequentist IDS methods for BO. Moreover, we confirm the efficacy of our algorithm
on a range of simulation problems, where we attain strong, state-of-the-art performance. We believe that our
12
terger
elpmis
terger
elpmis
terger
elpmisalgorithm can serve as a new benchmark in batch BO, and as a buiding block for more effective batch BO in
practical applications.
8 Acknowledgement
This work is supported by NSF AI institute: 2112085, NSF ECCS: 2328241, NIH R01LM014465, and NSF
CPS: 2038603.
References
[Adachi et al., 2023] Adachi, M., Hayakawa, S., Hamid, S., Jørgensen, M., Oberhauser, H., and Osborne,
M. A. (2023). SOBER: Highly Parallel Bayesian Optimization and Bayesian Quadrature over Discrete and
Mixed Spaces. arXiv:2301.11832 [cs, math, stat].
[Azimi et al., 2010] Azimi, J., Fern, A., and Fern, X. Z. (2010). Batch Bayesian Optimization via Simulation
Matching.
[Baek and Farias, 2023] Baek, J. and Farias, V. (2023). Ts-ucb: Improving on thompson sampling with little
to no additional computation. In International Conference on Artificial Intelligence and Statistics, pages
11132–11148. PMLR.
[Chen et al., 2022] Chen, Y., Dong, P., Bai, Q., Dimakopoulou, M., Xu, W., and Zhou, Z. (2022). Society
of agents: Regret bounds of concurrent thompson sampling. Advances in Neural Information Processing
Systems, 35:7587–7598.
[Contal et al., 2013] Contal, E., Buffoni, D., Robicquet, A., and Vayatis, N. (2013). Parallel gaussian process
optimizationwithupperconfidenceboundandpureexploration. InJoint European Conference on Machine
Learning and Knowledge Discovery in Databases, pages 225–240. Springer.
[Dai et al., 2020] Dai,Z.,Low,B.K.H.,andJaillet,P.(2020). Federatedbayesianoptimizationviathompson
sampling. Advances in Neural Information Processing Systems, 33:9687–9699.
[Daxberger and Low, 2017] Daxberger, E. A. and Low, B. K. H. (2017). Distributed batch gaussian process
optimization. In International conference on machine learning, pages 951–960. PMLR.
[De Palma et al., 2019] De Palma, A., Mendler-Dünner, C., Parnell, T., Anghel, A., and Pozidis, H. (2019).
Sampling Acquisition Functions for Batch Bayesian Optimization. arXiv:1903.09434 [cs, stat].
[Desautels et al., 2014] Desautels, T., Krause, A., and Burdick, J. W. (2014). Parallelizing exploration-
exploitation tradeoffs in gaussian process bandit optimization. Journal of Machine Learning Research,
15:3873–3923.
[Frazier, 2018] Frazier, P. I. (2018). A tutorial on bayesian optimization. arXiv preprint arXiv:1807.02811.
[Garcia-Barcos and Martinez-Cantin, 2019a] Garcia-Barcos, J. and Martinez-Cantin, R. (2019a). Fully dis-
tributed bayesian optimization with stochastic policies. arXiv preprint arXiv:1902.09992.
[Garcia-Barcos and Martinez-Cantin, 2019b] Garcia-Barcos, J. and Martinez-Cantin, R. (2019b). Fully
Distributed Bayesian Optimization with Stochastic Policies. arXiv:1902.09992 [cs, stat].
13[Garrido-Merchán and Hernández-Lobato, 2019] Garrido-Merchán, E. C. and Hernández-Lobato, D. (2019).
Predictive entropy search for multi-objective bayesian optimization with constraints. Neurocomputing,
361:50–68.
[Gong et al., 2019] Gong, C., Peng, J., and Liu, Q. (2019). Quantile stein variational gradient descent for
batch bayesian optimization. In International Conference on machine learning, pages 2347–2356. PMLR.
[Gonzalez et al., 2015] Gonzalez, J., Dai, Z., Hennig, P., and Lawrence, N. (2015). Batch Bayesian Optimiza-
tion via Local Penalization.
[Hennig and Schuler, 2012] Hennig, P. and Schuler, C. J. (2012). Entropy search for information-efficient
global optimization. Journal of Machine Learning Research, 13(6).
[Hernández-Lobato et al., 2015] Hernández-Lobato, J. M., Gelbart, M., Hoffman, M., Adams, R., and
Ghahramani, Z. (2015). Predictive entropy search for bayesian optimization with unknown constraints. In
International conference on machine learning, pages 1699–1707. PMLR.
[Hernández-Lobato et al., 2017] Hernández-Lobato, J. M., Requeima, J., Pyzer-Knapp, E. O., and Aspuru-
Guzik, A. (2017). Parallel and distributed thompson sampling for large-scale accelerated exploration of
chemical space. In International conference on machine learning, pages 1470–1479. PMLR.
[Hunt, 2020] Hunt, N. (2020). Batch Bayesian optimization. PhD thesis, Massachusetts Institute of Technol-
ogy.
[Hvarfner et al., 2022] Hvarfner, C., Hutter, F., and Nardi, L. (2022). Joint entropy search for maximally-
informed bayesian optimization. Advances in Neural Information Processing Systems, 35:11494–11506.
[Kandasamy et al., 2018] Kandasamy, K., Krishnamurthy, A., Schneider, J., and Póczos, B. (2018). Paral-
lelised bayesian optimisation via thompson sampling. In International Conference on Artificial Intelligence
and Statistics, pages 133–142. PMLR.
[Kaufmann et al., 2012] Kaufmann, E., Cappé, O., and Garivier, A. (2012). On bayesian upper confidence
bounds for bandit problems. In Artificial intelligence and statistics, pages 592–600. PMLR.
[Kirschner and Krause, 2018] Kirschner,J.andKrause,A.(2018). Informationdirectedsamplingandbandits
with heteroscedastic noise. In Conference On Learning Theory, pages 358–384. PMLR.
[Ma et al., 2023] Ma, H., Zhang, T., Wu, Y., Calmon, F. P., and Li, N. (2023). Gaussian max-value entropy
search for multi-agent bayesian optimization. arXiv preprint arXiv:2303.05694.
[Nava et al., 2022] Nava, E., Mutný, M., and Krause, A. (2022). Diversified Sampling for Batched Bayesian
Optimization with Determinantal Point Processes. arXiv:2110.11665 [cs, stat].
[Russo and Van Roy, 2014] Russo, D. and Van Roy, B. (2014). Learning to optimize via information-directed
sampling. Advances in Neural Information Processing Systems, 27.
[Shah and Ghahramani, 2015] Shah, A. and Ghahramani, Z. (2015). Parallel predictive entropy search for
batch global optimization of expensive objective functions. Advances in neural information processing
systems, 28.
[Srinivas et al., 2009] Srinivas, N., Krause, A., Kakade, S. M., and Seeger, M. (2009). Gaussian process
optimization in the bandit setting: No regret and experimental design. arXiv preprint arXiv:0912.3995.
14[Takeno et al., 2020] Takeno, S., Fukuoka, H., Tsukada, Y., Koyama, T., Shiga, M., Takeuchi, I., and
Karasuyama, M. (2020). Multi-fidelity bayesian optimization with max-value entropy search and its
parallelization. In International Conference on Machine Learning, pages 9334–9345. PMLR.
[Vakili et al., 2021] Vakili, S., Khezeli, K., and Picheny, V. (2021). On information gain and regret bounds
in gaussian process bandits. In International Conference on Artificial Intelligence and Statistics, pages
82–90. PMLR.
[Vershynin, 2018] Vershynin, R. (2018). High-dimensional probability: An introduction with applications in
data science, volume 47. Cambridge university press.
[Wang and Jegelka, 2017] Wang, Z. and Jegelka, S. (2017). Max-value entropy search for efficient bayesian
optimization. In International Conference on Machine Learning, pages 3627–3635. PMLR.
[Wang et al., 2016] Wang, Z., Zhou, B., and Jegelka, S. (2016). Optimization as estimation with gaussian
processes in bandit settings. In Artificial Intelligence and Statistics, pages 1022–1031. PMLR.
[Zhan and Xing, 2020] Zhan, D. and Xing, H. (2020). Expected improvement for expensive optimization: a
review. Journal of Global Optimization, 78(3):507–544.
15Appendix
8.1 Facts from information theory
We have the following result (Lemma 5.3 in [Srinivas et al., 2009]), which states that the information gain for
any set of selected points can be expressed in terms of predictive variances.
Lemma 4. For any positive integer t, denoting f as {f(x )}t , we have
t i i=1
t
I(y ;f )= 1(cid:88) log(cid:0) 1+σ−2σ2 (x )(cid:1)
t t 2 n t−1 t
i=1
8.2 Concentration results for Sum and Sum
1 2
In this section, we seek to bound Sum and Sum using martingale concentration inequalities. We first
1 2
provide a (standard) martingale concentration inequality for subGaussian martingales.
Lemma 5 (Azuma-Hoeffding [Vershynin, 2018]). Let F be a sequence of filtrations, and suppose X
i i+1
is a sequence of random variables that is adapted to F , such that E[X | F ] = 0, and X | F is
i i+1 i i+1 i
c2-subGaussian, i.e.
i
E[exp(λX )|F ]⩽exp(λ2c2/2)∀λ>0.
i+1 i i
Suppose c ⩽c for all i. Then,
i
(cid:32) (cid:88)n (cid:33) (cid:18) t2 (cid:19)
P X ⩾t ⩽exp − .
i 2nc2
i=1
In particular, with probability at least 1−δ,
n
(cid:88) (cid:112)
X ⩽c 2nlog(1/δ).
i
i=1
We next provide a martingale concentration inequality result for the term Sum , which takes the form
1
Sum =(cid:80)T−1(cid:80)m f∗−f˜∗ .
1 t=0 i=1 t,i
Lemma 6 (BoundforSum ). Let f˜∗ denote an iid sample from f∗|F . Then, for any δ >0, with probability
1 t,i t
at least 1−δ, we have
T−1 m
(cid:88)(cid:88) f∗−f˜∗ ⩽2(cid:112) Tmlog(1/δ).
t,i
t=0 i=1
Proof. Let x∗ be the maximizer of the sampled f, i.e. f(x∗) = f∗. Then, we observe that we have the
following:
T−1 m
(cid:88)(cid:88) f∗−f˜∗
t,i
t=0 i=1
T−1 m
= (cid:88)(cid:88) f(x∗)−f˜ (x∗)+f˜ (x∗)−f˜∗
t,i t,i t,i
t=0 i=1
16T−1 m
⩽ (cid:88)(cid:88) f(x∗)−f˜ (x∗),
t,i
t=0 i=1
where we note that the inequality follows since f˜ (x∗) denotes the random draw of x∗ at the same time
t,i
when f˜∗ was sampled, such that f˜ (x∗) ⩽ f˜∗ has to hold. The result then follows by observing that
t,i t,i t,i
f(x∗)−f˜ (x∗)isacentered,2σ2(x∗)subGaussianmartingale,thefactthatσ2(x∗)⩽1,andapplyingLemma
t,i t t
5 to the sum
T−1 m
(cid:88)(cid:88) f(x∗)−f˜ (x∗).
t,i
t=0 i=1
We next bound Sum .
2
Lemma 7. Let f˜ denotes a random sample from f(xTS−RSR)|F . Then, with probability at least 1−2δ,
t,i t+1,i t
we have
T−1 m
(cid:88)(cid:88)
= (µ (xTS−RSR)−f(xTS−RSR))
t t+1,i t+1,i
t=0 i=1
T−1 m
= (cid:88)(cid:88) (µ (xTS−RSR)−f˜ (xTS−RSR))
t t+1,i t,i t+1,i
t=0 i=1
(cid:124) (cid:123)(cid:122) (cid:125)
Sum2,1
T−1 m
+ (cid:88)(cid:88) (f˜ (xTS−RSR)−f(xTS−RSR))
t,i t+1,i t+1,i
t=0 i=1
(cid:124) (cid:123)(cid:122) (cid:125)
Sum2,2
(cid:112)
⩽ 4 Tmlog(1/δ)
Proof. The result follows from applying Lemma 5 to each of Sum and Sum .
2,1 2,2
17