LLMs in the Imaginarium:
Tool Learning through Simulated Trial and Error
BoshiWang♠
*
HaoFang(cid:51) JasonEisner(cid:51) BenjaminVanDurme(cid:51) YuSu(cid:51)
♠TheOhioStateUniversity (cid:51)MicrosoftSemanticMachines
wang.13930@osu.edu,{hao.fang,jason.eisner,bevandur,yusu2}@microsoft.com
Abstract theirenvironment. Thereisarecentsurgeofinter-
estinaugmentinglargelanguagemodels(LLMs)
Toolsareessentialforlargelanguagemodels withtoolstotranscendtheconfinesoftheirstatic
(LLMs)toacquireup-to-dateinformationand parametric knowledge and text-in-text-out inter-
takeconsequentialactionsinexternalenviron-
face,empoweringthemtoacquireup-to-dateinfor-
ments.Existingworkontool-augmentedLLMs
mation,calluponexternalreasoners,andtakecon-
primarily focuses on the broad coverage of
sequentialactionsinexternalenvironments(Schick
tools and the flexibility of adding new tools.
etal.,2023;Mialonetal.,2023;Qinetal.,2023).
However,acriticalaspectthathassurprisingly
beenunderstudiedissimplyhowaccuratelyan Existing work on tool-augmented LLMs pri-
LLMusestoolsforwhichithasbeentrained. marily aims to increase the ease of adding new
WefindthatexistingLLMs,includingGPT-4 tools, or the ability to access many tools (e.g.,
andopen-sourceLLMsspecificallyfine-tuned up to 16,000 APIs (Qin et al., 2024)). This is
fortooluse,onlyreachacorrectnessrateinthe
achievedthroughoneoftwocommonapproaches:
rangeof30%to60%,farfromreliableusein
1)In-contextlearning(ICL),whichpromptsfrozen
practice. We propose a biologically inspired
LLMswithAPIspecificationandtooluseexamples
methodfortool-augmentedLLMs,simulated
trial and error (STE), that orchestrates three (i.e., instruction-API call pairs) (Lu et al., 2023;
keymechanismsforsuccessfultoolusebehav- Song et al., 2023; Shen et al., 2023; Liang et al.,
iors in the biological system: trial and error, 2023b), or 2) fine-tuning with tool use examples
imagination, and memory. Specifically, STE synthesized by LLMs (Schick et al., 2023; Patil
leveragesanLLM’s‘imagination’tosimulate
et al., 2023; Qin et al., 2024; Tang et al., 2023).
plausiblescenariosforusingatool,afterwhich
While coverage and flexibility are important for
theLLMinteractswiththetooltolearnfrom
tooluse,acriticalaspectthat,perhapssurprisingly,
its execution feedback. Both short-term and
hasbeenunderstudiedissimplyhowaccuratelyan
long-term memory are employed to improve
thedepthandbreadthoftheexploration,respec- LLMusestoolsforwhichithasbeentrained. ICL
tively. Comprehensive experiments on Tool- isflexiblebuthardtodrivetoproduction-levelaccu-
BenchshowthatSTEsubstantiallyimproves racy. Fine-tuningcanpotentiallyleadtobetterac-
toollearningforLLMsunderbothin-context curacybyintegratingalargernumberofexamples,
learning and fine-tuning settings, bringing a
butexistingworkmostlyfocusesongeneralizingto
boostof46.7%toMistral-Instruct-7Banden-
unseentoolsinsteadofoptimizinganLLM’sability
ablingittooutperformGPT-4. Wealsoshow
tousetoolsseenduringtraining(Qinetal.,2024;
effectivecontinuallearningoftoolsviaasim-
pleexperiencereplaystrategy.1 Patil et al., 2023; Tang et al., 2023). Meanwhile,
practicaldeploymentoftool-augmentedLLMsne-
1 Introduction cessitates a high level of accuracy as they enable
consequential actions, e.g., financial transactions
Tools play an essential role in extending hu- orotherlegallybindingoperations. Inaccuratetool
mans(Gibsonetal.,1993)andotheranimals(Shu- use could lead to undesired or harmful outcomes
maker et al., 2011) beyond the confines of physi- andquicklyundermineusertrust.
cal bodies to better perceive and exert impact on How to truly master a tool? We turn to
successful precedents in the biological system
*WorkdoneasaninternatMicrosoftSemanticMachines.
such as humans (Gibson et al., 1993), apes and
1Code and data available at https://github.com/
microsoft/simulated-trial-and-error. corvids (Emery and Clayton, 2004). Learning to
4202
raM
7
]LC.sc[
1v64740.3042:viXraAPI Doc
Name: forecast_weather b) Short-term Memory ×N
Description: Forecast weather
Trial
in the upcoming days. Your
…
input should be … API Doc Trial Trial Trial
a) Trial
Query filter & paraphrase
Thought c) Long-term Memory
API Call Explored Queries Fulfilled?
Tool-use
Will there be a snow in Iowa in one week?
Examples
What activities can I do in New York City today?
Observation
I wish to watch the sunrise tomorrow here in
Paris. When will it be?
Response Tool-specific Demonstration
fine-tuning pool for ICL
Self-reflection
Exploration Exploitation
…
Figure1: Illustration ofsimulatedtrialanderror. Intheexplorationstage, anLLMinteractswiththe tooland
progressivelygatherstool-useexperiencesthroughtrialanderror. Specifically,a)ineachtrial,theLLMimagines
plausiblescenariosrelatedtothetargettool,iterativelyinteractswiththetooltofulfilltheuserquery,andintheend
self-reflectsonthetrial;b)ashort-termmemoryconsistingofrecenttrialtrajectoriesencourageslearningfrom
fine-grainedsuccessesandfailuresandexploringtheAPIingreaterdepth;c)along-termmemoryofcoarse-grained
pasttrialanderrorexperiencesmaintainsprogressivelearningoveralongtimehorizon. Intheexploitationstage,
theexplorationexperiencesaredistilledintoasetoftool-useexamplesforeitherICLorfine-tuning.
useatoolisaratheradvancedcognitivefunction employedtofacilitatedeeperexplorationinasin-
that depends on many other cognitive functions. gleepisode,whilealong-termmemorycontaining
First of all, trial and error is essential for tool distilledpastexplorationandreflectionsmaintains
learning(Beck,1973;Auerspergetal.,2011). We progressivelearningoveralonghorizon. Intheex-
do not master a tool solely by reading the ‘user ploitationstage,onecanusethetooluseexamples
manual’;rather,weexploredifferentwaysofusing from the explored trials to fine-tune an LLM, or
thetool,observetheoutcome,andlearnfromboth simplydoICLbyretrievingfromthoseexamples.
successesandfailures. Furthermore,intelligentan- WeconductcomprehensiveexperimentsonAPIs
imals do not just do random trial and error—we fromToolBench(Qinetal.,2024)andsummarize
proactively imagine or simulate plausible scenar- themainfindingsasfollows:
ios that are not currently available to perception
• Existing LLMs are far from reaching reli-
forexploration(EmeryandClayton,2004;Redish,
able tool use performance: GPT-4 (OpenAI,
2016). Finally,memory,bothshort-termandlong-
2023)gets60.8%correctness,andToolLLaMA-
term, is instrumental for the progressive learning
v2 (Qin et al., 2024) that was specifically fine-
and recurrent use of tools (Vaesen, 2012; Emery
tunedfortooluseonlygets37.3%.
andClayton,2004;ClaytonandDickinson,1998).
• STEprovestoberemarkablyeffectiveforaug-
Tothisend,weproposesimulatedtrialander- mentingLLMswithtools,underbothICLand
ror (STE; illustrated in Figure 1), a biologically fine-tuningsettings. STEimprovesthetooluse
inspiredmethodfortool-augmentedLLMs. Given capability of Mistral-Instruct-7B (Jiang et al.,
a tool (e.g., an API with its specification), STE 2023) to 76.8% (a boost of 46.7% absolute),
leveragesanLLMtosimulate,or‘imagine’,plau- makingitoutperformGPT-4withICL.
siblescenarios(i.e.,instructions)forusingthetool. • In practice, new tools are continually added.
It then iteratively interacts with the API to fulfill Fine-tuning (with or without STE) brings the
thescenariobysynthesizing,executing,andobserv- challengeofcatastrophicforgetting,wherelearn-
ingthefeedbackfromAPIcalls,andthenreflects ingnewtoolsmaycausetheLLMtoloseitsex-
on the current trial (Shinn et al., 2023). We de- istingtoolusecapabilitiesorgenerallanguage
visememorymechanismstoimprovethequalityof capabilities. We demonstrate that a simple ex-
thesimulatedinstructions. Ashort-termmemory perience replay strategy (Scialom et al., 2022)
consisting of recent trial and error trajectories is could largely mitigate the issue, allowing the
… …Episode 1 - Trial 1
Episode N - Trial 1
API Name: forecast_weather
Description: Forecast weather in the upcoming days. Your input should be … API Name: forecast_weather
----------------------------------------------------------------------------------------- Description: Forecast weather in the upcoming days. Your input should be …
Query: Will there be a snow in Iowa in one week? -----------------------------------------------------------------------------------------
Thought: The user wants to know whether there will be a snow in Iowa in… Instruction: Below are queries you have already explored and whether you
API: forecast_weather | args: {“location”: “Iowa”, “days”: “one week”} successfully solved them with the API’s help:
Observation: “Error code 422: unprocessable entity”
Thought: I made an error in the API call. I forgot to use numbers for the “days” Explored Queries Fulfilled?
field. Let me correct that. Will there be a snow in Iowa in one week?
API: forecast_weather | args: {“location”: “Iowa”, “days”: “7”} What activities can I do in New York City today?
Observation: “The weather forecast for Iowa…all weather: partly cloudy, …, … I wish to watch the sunrise tomorrow… when will it be?
total snow: 0.0 (cm), …, sunrise time: 07:05 AM, …”
Final response: The weather forecast indicates that there will be no snow in Long-term Memory
Iowa in one week.
Self-reflection: Success Based on these, try to explore queries that can help you understand the API
further; avoid synthesizing queries that are too close to the existing ones.
Episode 1 - Trial M -----------------------------------------------------------------------------------------
Instruction: Now based on what you have discovered about this API, you can Query: …
explore it a bit further and consolidate your understanding… Thought: …
----------------------------------------------------------------------------------------- API: …
Query: I wish to watch the sunrise tomorrow here in Paris. When will it be? Final response: …
Thought: The user wants to… Self-reflection: …
API: forecast_weather | args: {“location”: “Paris”, “days”: “1”}
Figure2: Explorationwithsimulatedtrialanderror,highlightingthememorymechanisms. Eachepisodebegins
withtheAPIspecification(onlyinthefirsttrial),followedbyaseriesoftrialsdynamicallyaddedintheshort-term
memory. Thelong-termmemoryisloadedintothecontextatthebeginningofeverytrialtoallowtheLLMto
progressivelyimaginenovelscenarios,andthenoffloadedafterward(omittedinthefigure).
modeltocontinuallylearnnewtoolswhilepre- format(Yaoetal.,2023)whereduringeachstep,
servingitspreviouslyacquiredskills. theLLMfirstverbalizesitsinternalthought,then
makes an action (API call) and observes the cor-
2 SimulatedTrialandError responding execution feedback, and then repeats
thethought→action→observationprocessuntilthe
Weintroduceourproposedsimulatedtrialanderror
modeldecidesthattheAPIcallhasreturnedade-
(STE)fortoollearning. STEconsistsofanexplo-
quateinformationorapredefinedmaximumnum-
rationphaseandanexploitationphase,whichare
berofcalls. Duringthisstage,theLLMlearnsfrom
discussednext.
theexecutionenvironmenttocorrectitsownsyn-
tacticandsemanticerrorsinAPIcalls, gathering
2.1 Exploration
tool-useexperiencesasfine-grainedtrial-and-error
In the exploration phase, for each new API, the trajectories. Afterward,themodelrespondstothe
LLM interacts with the API within a budget in user’s query and self-reflects on whether the ex-
ordertogainasmuchinformationaspossibleabout ploredqueryissuccessfullyfulfilledornot.
theAPI.Theexplorationphaseconsistsofaseries
oftrials(Figure1)resemblinghumans’progressive Short-termmemory. Adirectimplementationof
learningofatool. Ineachtrial,conditionedonthe theexplorationwhereeachtrialisconductedina
APIdescription,theLLM1)imaginesaplausible separateepisodeonlyallowsshallowexplorations
userqueryrelevanttotheAPI;2)triestofulfillthe oftheAPI.WeaugmenttheLLMwithashort-term
query by interacting with the API; 3) reflects on memoryconsistingoftheexplorationtrajectories
thetrialtofacilitatesubsequentexploration. Three ofrecenttrials,wheretheLLMisinstructedtocon-
core design components are integrated with the ductsubsequenttrialsconditionedonthememory
trials to enhance the validity, comprehensiveness (Figure 2, left). Each episode starts with a fresh
anddiversityoftheexploration,introducednext. short-termmemory,wherenewlyconductedtrials
Iterativeself-refinewithexecutionfeedback. To aredynamicallyaddedintothememoryforacer-
improve the validity of the exploration, we use a tain number of trials. This allows the model to
strategysimilartotheideasofChenetal.(2024); learn from recent fine-grained successes and fail-
Qin et al. (2024); Madaan et al. (2023); Shinn ures(e.g.,syntax/semanticerrors),andalsoexplore
et al. (2023) where the LLM learns from the ex- theAPIingreaterdepthinthecomingtrialsbased
ecution feedback to refine its own outputs (Fig- onitspreviousobservationsoftheAPI(e.g.,unex-
ure 2, top left). Specifically, we adopt the ReAct pectedfunctionalities).
yromeM
mret-trohS
…
…
…Long-termmemory. Onlyasmallnumberoftrials and BMTools. We filter down to the APIs that
canbestoredinshort-termmemorysincethefine- are free to use with low execution latency. In
grained trajectories quickly consume the LLM’s the end, we obtain 50 APIs that span search en-
context capacity. We augment the LLM with a gines (e.g., Google Search & Places), domain-
long-term memory that stores distilled trial-and- specificinformation-seekingAPIs(e.g.,Wikipedia,
error experiences from past episodes, in order to Weather, Sports, Gaming), and also problem-
supportprogressivelearningoveralongtimehori- solving ones such as WolframAlpha, Number
zon. Specifically, the long-term memory records Translator,etc. MoredetailsareinAppendixA.
the past-explored queries and whether they were Setupforexploration. Intheexplorationstage,we
judgedassuccessfullyfulfilled(Figure2,right). It useChatGPT(16k-0613)forexplorationandpara-
isonlyloadedintothecontextatthebeginningof phrasing, and GPT-4 (8k-0613) (OpenAI, 2023)
every new trial, where the model is instructed to for final example filtering. We set the maximum
imaginescenariosthataredistantfrompreviously numberofAPIcallsforeachtrialtobe4. Foreach
exploredonestoimproveinformationgain. Inthis API, the exploration stage lasts for 15 episodes
way, the long-term memory serves as a growing with4trialsperepisode,resultinginatotalof60
poolofpastsuccessesandfailures,whichallows examplesbeforefilteringandparaphrasing. After
theLLMtocontinuallyexpandtheexplorationin filtering,15examplesforeachAPIarerandomly
ordertomakeprogressacrossdifferentepisodes. selectedintothetestset,wheretheremainingones
are paraphrased into ∼140 examples, making a
2.2 Exploitation totalof∼7Ktool-useexamples. Forthetestexam-
ples,wemanuallyexamineandcorrectanyissues,
Intheexploitationstage, thetrialsobtainedfrom
ifany,toensuretestsetquality.
the exploration stage are utilized to enhance the
Baselines & exploitation with STE. We experi-
tool-useabilityofanLLMviaeitherfine-tuningor
mentwithLlama-2-Chat-7B/13B(Touvronetal.,
in-contextlearning(ICL).Foreachtrial,weextract
2023), Mistral-Instruct-7B (Jiang et al., 2023),
thesynthesizeduserquery,theLLM’slastAPIcall
and GPT-3.5-turbo/GPT-4 (ICL only) and com-
and its execution results, and the final response
paretheirperformancewithandwithoutSTE.We
fromthetrialtrajectory. Then,weperformfiltering
comparewithToolLLaMA-v2(Qinetal.,2024)as
by using GPT-4 to judge the validity of each ex-
themainbaselineforexistingtoollearningstrate-
ample,andthenparaphrasethevalidexamplesfor
gies. ItisbasedonLlama-2-7Bandfine-tunedon
eachnewAPIintoapproximatelythesameamount
126KtooluseexamplessynthesizedbyChatGPT-
(Appendix E), which maintains a balance across
3.5-turbo for general tool-use, covering a large
differentAPIsandfurtheraddslinguisticvariations
numberoftoolsfromRapidAPIincludingtheones
intothesynthesizedtool-useexamples.
usedinourexperiments.
For fine-tuning, we use the standard language
For ICL with nearest neighbor demon-
modeling objective where the loss is computed
stration selection, following prior work (Liu
onlyforthetool-use/responsegenerationpart,and
et al., 2022; Rubin et al., 2022), we use the
donotincludetheAPIdocumentationinthecon-
paraphrase-mpnet-base-v2 model from Sen-
text. ForICL,thesynthesizedexamplesareused
tenceBERT (Reimers and Gurevych, 2019) for
as the demonstration pool from which in-context
computing the semantic similarity, and choose
examples are retrieved and appended to the API
the top 8 examples closest to the test query as
documentations in the LLM’s context. We use a
in-context demonstrations. For Llama-2 with
dynamicnearest-neighbordemonstrationselection
ICL, since the token length of the full 50 API
strategywheretheexamplesthataresemantically
documentations(around7Ktokens)isbeyondits
closest to the test user query are retrieved as in-
context length (4,096),2 we augment the model
contextexamples,oneofthetopperformingstrate-
withanoracletoolretrieverwhichretrievesthetop
giesforICL(Liuetal.,2022;Rubinetal.,2022).
15 similar APIs w.r.t. the ground truth API using
3 ExperimentalSetup theassociateddocumentation. Weaugmentother
models of similar scales (7B/13B) with the same
Tools. WeconductexperimentsusingAPIsfrom
2WhilethereexistvariantsofLlama-2withlongercontext
ToolBench(Qinetal.,2024),alarge-scalereposi-
(e.g.,Xiongetal.(2023)),westicktotheoriginalmodelin
toryofreal-worldAPIscollectedfromRapidAPI Touvronetal.(2023)forfaircomparison.Setting BaseModel Wellformed? APIMatch Correctness
ToolLLaMA-v2 98.1 49.0 37.3
Llama-2-Chat-7B 34.5 40.2 10.7
Llama-2-Chat-13B 79.3 53.6 32.7
Baseline
Mistral-Instruct-7B 61.7 69.3 30.1
GPT-3.5-turbo(16k-0613) 96.9 77.6 60.5
GPT-4(8k-0613) 96.1 78.1 60.8
Llama-2-Chat-7B 58.3 86.7 41.7
Llama-2-Chat-13B 87.5 86.6 62.9
ICLw/STE Mistral-Instruct-7B 69.9 88.4 47.9
GPT-3.5-turbo(16k-0613) 97.6 90.8 75.6
GPT-4(8k-0613) 97.7 92.8 76.3
Llama-2-Chat-7B 99.2 94.9 73.3
Fine-tuningw/STE Llama-2-Chat-13B 98.9 95.1 74.3
Mistral-Instruct-7B 99.1 95.8 76.8
Table1: Overalltool-useperformance. STEiseffectivewhenusedinbothICLandfine-tuning. Bestoverallresults
arebold-faced,andbestresultsundereachsettingareunderscored.
Setting Wellformed? APIMatch Correctness 4 Results
FullSTE 99.2 94.9 73.3
–Exec.feedback 89.9 79.4 50.5 4.1 EffectivenessofSTE
–Short.Mem. 99.7 70.6 53.9
–Long.Mem. 98.7 79.9 59.7 ResultsareincludedinTable1. Wesummarizethe
–Self-reflection 99.3 81.7 60.1
mainfindingsbelow.
Table2:Resultsforablations.Weseparatelyablateeach None of the baseline models displays satisfac-
keycomponentofourexplorationdesign. Exploitation toryperformance. Forallofthebaselinemodels
isdonebyfine-tuningLlama-2-Chat-7B. thatwetested,noneofthemachievesasatisfactory
tool-use performance. The best model is GPT-4,
whichonlyachievesanoverallcorrectnessrateof
tool retriever (when ICL is used for exploitation)
60.8%. Llama-2andMistralachieveamuchlower
forfaircomparison. LLMsfine-tunedonSTEdo
performance, largely due to the model not being
not need such API documentation in the context,
abletofollowthespecifiedsyntactic/formattingre-
whichsubstantiallyreducestheinferencecost.
quirementswhenmakingAPIcalls.3 ToolLLaMA-
Evaluation metrics. We evaluate the model by
v2(Qinetal.,2024),despiteextensivelyfine-tuned
matchingthepredictedAPIcallagainsttheground
fortooluse,stilllargelyunderperformsGPT-3.5/4.
truth. For APIs that have strict value ranges for
Itsperformanceimprovementovernon-fine-tuned
thearguments,weperformstringmatchingonthe
baselineslikeLlama-2seemstomainlycomefrom
respectiveargumentsdirectly. ForAPIsthataccept
wellformedness,anditstillfacesseveredifficulties
free natural language inputs, we use ChatGPT to
inchoosingthecorrecttoolandpredictingtheright
judge the correctness of the predicted API argu-
arguments. Thissuggeststhatfine-tuningforgen-
ments. Wereporttheoverallaccuracyconsidering
eraltooluseisinsufficientforachievingthelevel
bothAPInameandarguments(Correctness)asthe
ofperformanceneededforpracticaldeployment.
mainmetric,togetherwiththepercentageofexam-
STEiseffectivewithbothICLandfine-tuning.
pleswithvalidAPIcallsandnosyntax/formatting
Remarkable gains are observed under both set-
errors(Wellformedness)andthepercentageofex-
tings. Whenretrievingfromthetooluseexamples
amplesthatcorrectlychoosetousetheground-truth
generatedbySTEforICL,weseeimprovements
API (API Match). While it is desirable to also
across the board, with up to 30.2% (for Llama-2-
evaluate the model regarding whether the model
Chat-13B)incorrectnessforopen-sourceLLMs. It
resolvestheuserquerysuccessfullybasedonthe
alsobooststhealreadystrongperformanceofGPT-
executionresults, themajorityoftheAPIsinour
3.5/4substantially. Fine-tuningwithSTEexamples
experimentsareconnectedtodynamicreal-world
improves the tool use capability of open-source
information (e.g., weather ‘tomorrow’ where the
dateiscontingentontheactualtimeofmakingthe 3The superior ability of GPT-3.5/GPT-4 to follow the
syntax may be partially due to their special enhancement
APIcall),whichmakessuchevaluationinfeasible.
onfunction-calling(https://openai.com/blog/function-calling-
Weleavethischallengetofutureresearch. and-other-api-updates).LLMsbyanevenlargermargin,boostingMistral- considerableamountofquerieswherethetime
Instruct-7Bby46.7%incorrectnessandenabling isspecifiedasthedayoftheweek,whichisnot
ittooutperformGPT-4. Fine-tuningwithSTEalso asupportedparametertypeoftheAPIandhence
makesLLMsalmostperfectinwellformednessand constantlyresultsinfailures.
choosingtherighttools. Thisislikelybecausefine- • Long-term memory improves overall diver-
tuningallowsinjectingamuchwiderrangeoftool sity over a long time horizon. With long-
useexamplesintoamodelthanICL.Whilewecan- termmemory,theLLMexploresexamplescov-
notfine-tuneGPT-3.5/4duetocostandavailability, ering a broader range of subjects, and main-
itisplausibletohypothesizethatSTEcouldfurther tainstheprogressoverdifferentepisodes. When
improvetheirtool-useabilitybeyondtheircurrent long-termmemoryisdisabled,thetrialsacross
ICLperformance. episodesbecomerepetitiveandlessinformative.
Forquantitativecharacterization,weextractthe
4.2 AblationStudies
coresubjects(location,time,attribute)fromthe
Weconductanablationstudyforourexploration queries,measuretheirdiversityandalsoplotthe
design, with exploitation done by fine-tuning attribute distribution (Appendix C). With long-
Llama-2-Chat-7B.Specifically,weablatetheexe- term memory, all the queries are distinct and
cutionfeedback,short/long-termmemory,andthe thetrialsarebalancedacrossdifferentattributes.
self-reflection component. We extend the num- Withoutlong-termmemory,only71.7%ofthetri-
ber of episodes to preserve the total number of alsconcerndistinctsubjectsandthedistribution
trials if needed. The results in Table 2 show acrossattributesismuchmoreskewed,showing
that 1) exploration without execution feedback theeffectivenessoflong-termmemoryinmain-
could give a notable amount of ill-formed exam- taining the diversity of exploration over a long
ples where the API calls do not follow the syn- timehorizon.
tax/formatting requirements; 2) both short-term
4.3 ErrorAnalysis
and long-term memory prove to be essential for
effective trial and error; 3) self-reflection is im- Errors of GPT-4. As one of the most capable
portant in maintaining an informative long-term LLMs,GPT-4(8k-0613)canonlyachieveanover-
memoryforexploration. Tobetterunderstandthe allcorrectnessof60.8%. Weconductanerroranal-
benefitsofourmemorydesign,weconductacase ysisofGPT-4. Werandomlysampleandexamine
studywiththeforecast_weatherAPI(examples 30errorexamplesofGPT-4,whichcanbecatego-
inAppendixC),whichclearlyshowsthatbothof rized into the following three types, with the cor-
thememorymechanismssubstantiallyimprovethe responding percentage without → with ICL with
diversityandcomprehensivenessofexploration: STE examples. Examples for each category are
• Short-term memory boosts specificity and showninAppendixD.
comprehensiveness. Comparing the trials • WrongchoiceofAPI(36.7%→19.0%). GPT-4
with/withoutshort-termmemory,itcanbeseen callsthewrongAPIthatcannotaddresstheuser
thattheshort-termmemoryeffectivelydrivesthe query. Table 4 shows one example where the
LLM to comprehensively explore fine-grained user query is regarding parks with hiking trails
informationfromthetool,spanning16different in San Francisco. Here the model calls an API
attributes (e.g., humidity, precipitation, UV in- thatretrievesthegeographiccoordinatesofSan
dex, visibility, andsunrise/sunsettime)intotal. Francisco,overlookingthegroundtruth“Places”
Meanwhile,whenshort-termmemoryisdisabled, API.ICLwithSTEexampleshelpsresolveabout
theexamplesaremuchlessspecificandmostly halfofsucherrorsbybetterillustratingthefine-
about general weather conditions (e.g., “What grainedsemanticsoftheAPIs.
will be the weather like...”) due to the inability • Missing/wrong arguments (26.7%→10.0%).
toleveragenewlyobtainedinformationfromthe Here, GPT-4 fails to provide the correct set of
executionresults. Inaddition,explorationwith- arguments despite choosing the right tool. Ta-
outshort-termmemoryresultsinasignificantly ble 5 shows an example where the model fails
lowerpercentageofpositivetool-useexamples toprovidetherequired“lang”keyword. STEis
(78.3%→51.7%),sincethemodelcannotlearn particularlyeffectiveforsucherrors.
fromfine-grainedpasterrorstofacilitatefuture • Hard-to-evaluateexamples(36.7%→16.7%).
trials. As an example, the model synthesizes a Wefoundthatitisdifficulttojudgethecorrect-User query: Can you provide the total number of matches
User query: What is the current advisory information User query: What are the ongoing giveaways for PC game
played between Leeds United and Sheffield Wednesday in
for the Union City station? keys on the GOG platform?
the English Premier League?
------------------------------------------------------------- ----------------------------------------------------------------- -------------------------------------------------------------------
Gold API call: BART - Advisory information Gold API call: GamerPower - Filter & Group Giveaways Gold API call: Football Dolphin - Head to head statistics
Args: {"cmd": "bsa","orig":"UCTY"} Args: {"platform": "gog", "type": "game.key"} Args: {"first_team" : "Leeds", "second_team": "Sheffield
 Description: The BART API gives you access to pretty  Description: "Find all free games, loot and giveaways Weds", "type_of_statistics": …}
much all of the BART service and station data with this giveaway tracker API powered by  Description: This API returns statistical data about
available… Required parameters: [{"name": "cmd", GamerPower.com! Access programmatically the best English Premier League… Required parameters: [{"name":
"type": "STRING", … name": "orig", "type": giveaways in… Required parameters: [{"name" : "first_team”, type: "STRING", description: Enter first team
"STRING", "description": "Optional station filter. "platform", "type": "STRING"}, {"name": "type", "type": from all available teams: Arsenal, …, Ipswich, Leeds,
Uses 4 characterBART station abbreviations…}] "STRING", "description": …}] Leicester, Liverpool, …,}, {"name": …}]
------------------------------------------------------------- ----------------------------------------------------------------- ------------------------------------------------------------------
Predicted API call: BART - Advisory information Predicted API call: GamerPower - Filter & Group Giveaways Predicted API call: Football Dolphin - Head to head statistics
Args: {"cmd": "bsa","orig":"UNION"} Args: {"platform": "pc", "type": "game.key"} Args: {"first_team": "Leeds United", "second_team": "Sheffield
Weds", "type_of_statistics": …}
(a) (b) (c)
Figure3: ErrorexamplesofMistral-Instruct-7Bafterfine-tuning: (a)commonsense/worldknowledge,(b)language
understanding,and(c)grounding.
Batch1 Batch2 Batch3 Batch4 AllAPIs MMLU BBH
Llama-Flan - - - - - 37.2 39.5
CL-Round1 80.6 - - - - 39.6 36.8
CL-Round2 1.7→76.1 87.7→84.1 - - - 40.2 38.9
CL-Round3 0.0→70.6 56.9→84.1 68.9→65.6 - - 39.2 37.5
CL-Round4 0.0→65.0 38.5→88.7 25.0→66.1 71.8→70.3 34.7→72.8 38.5 39.1
Llama-FT 73.3 87.2 68.3 67.2 74.1 38.7 40.8
Table3: Resultsforcontinuallearning. Llama-FlanisthebaseLLMandLlama-FTisLlama-Flanfine-tunedonall
thetoolsatonce. ForCL,thetoolsaresplitintofourbatchesandtheLLMneedstocontinuallylearnanewbatchin
eachround. Scorestotheleft/rightofeacharrow(“→”)arethetool-usecorrectnesswithout/withrehearsal. For
example,1.7→76.1meansthefine-tunedmodelgetsonly1.7%onBatch1toolsafterCL-Round2withoutrehersal,
and76.1%withrehersal. Whilevanillafine-tuningcausescatastrophicforgetting,rehearsalcouldlargelymitigate
thisissueandallowthemodeltocontinuallylearnnewtoolswhilepreservingitspreviouslyacquiredskills.
ness of the model predictions for around one- amplewherethemodelmisunderstandstheuser
thirdoftheerrorexamples(anexampleincluded querywhichresultsinwrongarguments. Using
in Table 6). The main reasons behind this are astrongerbaseLLMcouldmitigatesucherrors.
1) the existence oftools withoverlappingfunc- • Grounding(21.1%). Wefindthatsomeerrors
tionalities that makes ground truth non-unique areduetoalackofgrounding,wheretheLLM
and2)thetime-sensitivenatureofcertaintools generatesAPIcallsthataresemanticallycorrect
thatprohibitsconsistentgroundtruths. Suchdif- but not grounded to the API constraints. One
ficultiesinevaluatingtoolusearealsonotedin exampleisgiveninFigure3(c),wherethemodel
existingwork(Qinetal.,2024;Patiletal.,2023), correctlyextractsthetargetentitybutfailstolink
whichisanopenchallengeforfuturework. ittotheentitynamessupportedbytheAPI.This
Errors after fine-tuning. We also examine the couldbeimprovedbyincorporatingconstraints
errors of the most performant fine-tuned model duringdecoding(Zhangetal.,2023;Shinetal.,
(Mistral-Instruct-7B) and summarize the notable 2021;Fangetal.,2023)orusingfuzzy-matching
error causes compared with GPT-4, which shed mechanisms.
lightonvenuesforfutureimprovement.
4.4 ContinualToolLearning
• Commonsense/world knowledge (47.4%).
Manytoolsrequirecommonsense/worldknowl- While fine-tuning significantly outperforms ICL
edge. Figure 3(a) shows an example where fortooluse,onedownsideisthepotentialdecrease
callingtheAPIrequiresknowingthe4-character offlexibilityasdiscussedin§1duetocatastrophic
abbreviationofthetargettransitstation,andhere forgetting (Kirkpatrick et al., 2017; Howard and
the model hallucinates a wrong abbreviation. Ruder,2018;Kumaretal.,2022;Luoetal.,2023).
This issue could be mitigated by scaling or Since retraining the model from scratch is costly
additionalknowledgeretrieval. and hurts flexibility, we explore continual learn-
• Languageunderstanding(31.6%). Certainer- ing(CL)andshowthatsimplerehearsal(Scialom
rors are caused by a lack of basic language un- et al., 2022) seems to be sufficient for continual
derstandingabilities. Figure3(b)showsoneex- toollearningwithSTE.We randomly split the tools into 4 consecu- descriptions and optionally (a small amount of)
tivebatchestosimulatethecontinualsetting. For tool-usedemonstrationsinthecontext. Haoetal.
rehearsal, during each round, we add 10% tool (2023) propose a lightweight adaptation method
useexamplesforeachAPIfrompreviousbatches that expands the LLM’s vocabulary with trained
into the replay buffer. For preserving general tool embeddings. Qin et al. (2024); Patil et al.
non-tool-use capabilities, we also add in every (2023); Tang et al. (2023) explore training mod-
traininground2,000randomexamplesfromFlan- elstobetterleverageAPIdescriptionsfortooluse.
V2 (Longpre et al., 2023; Chung et al., 2022), Our work aims to develop a framework that al-
one of the highest quality general instruction lowsequippingLLMswithstrongertool-useabili-
datasets (Wang et al., 2023a), and evaluate the ties,motivatedbyhowhumanstypicallylearntools
model on MMLU (Hendrycks et al., 2021) and throughcontinualtrialanderror.
Big-Bench-Hard(BBH)(Suzgunetal.,2023). We
useLlama-Flanasthebasemodeltoensureafair LLMs can learn from feedback. Recent
comparisonofgeneralcapabilitiesonMMLUand work found that LLMs are capable of im-
BBH(moredetailsinAppendixB).ResultsinTa- proving/correcting their predictions with feed-
ble3showthatthemodelcoulddrasticallyforget back(Shinnetal.,2023;Madaanetal.,2023;Gan-
previously learned tools without rehearsal, with gulietal.,2023;Chenetal.,2024;Pengetal.,2023;
more distant ones being more severely forgotten. Kimetal.,2023;Panetal.,2023). Ourworkisbuilt
Rehearsal largely mitigates forgetting—the CL- on top of these findings and uses an LLM to pro-
trained model achieves comparable performance gressivelylearntoolsbyleveragingfeedbackfrom
as Llama-FT. General language abilities are also thetoolexecutionandtheLLM’sself-reflection.
retainedasmeasuredonMMLUandBBH.Overall,
weextendthefindingsofScialometal.(2022)on Data synthesis & bootstrapping with LLMs.
the effectiveness of experience replay to the new DuetoLLMs’exposuretobroaddomainsduring
realmofLLMtoollearning,demonstratingafea- pretrainingandtheirrapidlyimprovinggeneration
sible way of flexibly adding new tools with the abilities, recent work has explored using LLMs
proposedSTEmethod. fordatasetsynthesis,whichalleviatestheburden
ofcostlyhumanannotations(SchickandSchütze,
5 RelatedWork 2021; Wang et al., 2023b; Honovich et al., 2023;
Lietal.,2023;Zelikmanetal.,2022;Huangetal.,
Tool-augmentedlanguagemodels. Oneofthefo- 2023). Such model-synthesized data can then be
cusesofextensiveresearchinNLPisonaugment- utilized to improve models including themselves.
ingmodelswithretrieval/searchenginesthatcould Inthetool-learningdomain,similarideashavebeen
supplement extra knowledge (Guu et al., 2020; explored for tool-specific data synthesis (Schick
Lewisetal.,2020;Izacardetal.,2022;Borgeaud etal.,2023;Patiletal.,2023;Qinetal.,2024). Our
etal.,2022,interalia). Recently,therehasbeena approachfollowsthislineofworkandtakesastep
trendtowardsaugmentingLLMswithmorediverse towardsbettercomprehensivenessanddiversityof
typesoftools,suchasprogramexecutors,transla- thesynthesizedtool-useexamples.
tionandQAmodels(Chenetal.,2023b;Gaoetal.,
2023;Parisietal.,2022;Schicketal.,2023),APIs Augmentingmodelswithdynamicmemory. Us-
fromdevelopersandpublicrepositories(Patiletal., ing memory mechanisms to allow models to dy-
2023;Qinetal.,2024;Xieetal.,2023),andtools namicallygatherandutilizeexperiencesisanold
curatedforspecificenvironments(Guetal.,2024) idea, e.g., Riesbeck (1981); Schank (1983). Re-
tofurtherexpandthescopeofproblemsthatLLMs centworkalsoexploresaugmentingmodelswitha
canassistwith. growing memory of user and environment feed-
Both fine-tuning and ICL are used to adapt an back (Madaan et al., 2022; Shinn et al., 2023;
LLMtousetools. Fine-tuning-basedapproaches Zhongetal.,2023;Liangetal.,2023a;Zhaoetal.,
traintheLLMtousetoolsonasetoftool-specific 2023;Modarressietal.,2023;Huetal.,2023). We
demonstrationexamples(Schicketal.,2023;Parisi draw inspiration from these works and augment
etal.,2022),whileICL-basedapproaches(Luetal., theLLMwithfine-grainedshort-termmemoryand
2023; Song et al., 2023; Shen et al., 2023; Liang distilledlong-termmemorytoenhancetheLLM’s
etal.,2023b;Gaoetal.,2023)directlyputthetool progressivelearningoftools.6 Conclusions nally,therearealsoinherentlimitationsofexample-
basedmethodsfortoollearning,inparticular,the
Motivated by how humans master tools through
difficulty of teaching the model when not to use
continual interaction and reinforcement, we pro-
a tool through positive tool-use examples alone.
pose simulated trial and error, an LLM tool-
Some potential ways of improving this issue are
learning method built upon progressive memory-
incorporatingnegativeexamples(e.g., usingcon-
basedtrialanderror. ExperimentsonAPIsdrawn
trastive objectives) or carrying such parts of the
fromToolBenchshowtheeffectivenessofthepro-
API alongside example-based training. We leave
posedmethod,andalsothatrehearsal-basedfine-
theseinvestigationstofuturework.
tuningcouldenablecontinuallearningofnewtools
withpreservedpreviousskills.
References
Limitations
RenatAksitov,SobhanMiryoosefi,ZonglinLi,Daliang
Iterativeimprovement. Currently,weusestrong Li, Sheila Babayan, Kavya Kopparapu, Zachary
models for exploration and smaller weak mod- Fisher,RuiqiGuo,SushantPrakash,PraneshSrini-
vasan,ManzilZaheer,FelixYu,andSanjivKumar.
elsforexploitation. Theexploration-exploitation
2023. Restmeetsreact: Self-improvementformulti-
couldalsobedoneiterativelyasinpriorwork(Ak- stepreasoningllmagent.
sitovetal.,2023;Zelikmanetal.,2022),wherethe
AliceMIAuersperg,AugusteMPVonBayern,GyulaK
relianceonthestrongmodelscouldbediminished
Gajdon, Ludwig Huber, and Alex Kacelnik. 2011.
gradually(e.g.,onlyasevaluators)asthecapabili-
Flexibilityinproblemsolvingandtooluseofkeaand
tiesofthemodelsbeingenhancedimprove. newcaledoniancrowsinamultiaccessboxparadigm.
Compositional tool use & planning. Another PloSone,6(6):e20231.
importantabilityinthecontextoftooluseiscom-
BenjaminBBeck.1973. Observationlearningoftool
posing/planningmultipletoolcallstofulfillcom-
usebycaptiveguineababoons(papiopapio). Amer-
plexqueries,whichgoesinanorthogonaldirection icanJournalofPhysicalAnthropology,38(2):579–
as our focus here. Recent works show that the 582.
core abilities of LLMs are encoded and elicited
Sebastian Borgeaud, Arthur Mensch, Jordan Hoff-
from pretraining instead of injected through fine-
mann, Trevor Cai, Eliza Rutherford, Katie Milli-
tuning/alignment (Zhou et al., 2023; Lin et al., can,GeorgeBmVanDenDriessche,Jean-Baptiste
2023),whichsuggeststhatextensivedataprepara- Lespiau, BogdanDamoc, AidanClark, etal.2022.
Improvinglanguagemodelsbyretrievingfromtril-
tionmaynotberequiredtoadaptLLMsforcom-
lionsoftokens. InInternationalconferenceonma-
plextooluse,differentfromourfocuswhereexten-
chinelearning,pages2206–2240.PMLR.
sivelearningandexplorationarealwaysdesiredas
informationisgainedfromthetoolside. HowardChen,RamakanthPasunuru,JasonWeston,and
Asli Celikyilmaz. 2023a. Walking down the mem-
Largermemorycapacitybeyondcontextlimit.
orymaze: Beyondcontextlimitthroughinteractive
Thecapacityoftheaugmentedmemoryislimited reading.
by the context length of the LLM. There are dif-
Wenhu Chen, Xueguang Ma, Xinyi Wang, and
ferent kinds of approaches that could be used to
William W. Cohen. 2023b. Program of thoughts
further scale up the memory, such as using addi-
prompting: Disentanglingcomputationfromreason-
tional retrieval modules (Wang and Li, 2023) or ingfornumericalreasoningtasks. Transactionson
having more hierarchical/compressed representa- MachineLearningResearch.
tionsofthememory(Chenetal.,2023a).
Xinyun Chen, Maxwell Lin, Nathanael Schärli, and
Tool unlearning? While we explored continual
DennyZhou.2024. Teachinglargelanguagemodels
learning of new tools, the problem of unlearning toself-debug. InTheTwelfthInternationalConfer-
isalsoimportantastoolscouldgetconstantlyun- enceonLearningRepresentations.
loaded/outdated. Knowledgeunlearningisgener-
HyungWonChung,LeHou,ShayneLongpre,Barret
ally a challenging problem (Si et al., 2023), and Zoph,YiTay,WilliamFedus,YunxuanLi,Xuezhi
therecouldbespecificdesignsthatsupporteasier Wang, Mostafa Dehghani, Siddhartha Brahma, Al-
tool unlearning, such as ToolkenGPT (Hao et al., bert Webson, Shixiang Shane Gu, Zhuyun Dai,
MiracSuzgun,XinyunChen,AakankshaChowdh-
2023)whichallowsplug-and-playadaptationwhile
ery,AlexCastro-Ros,MariePellat,KevinRobinson,
enablinglearningwithlarge-scaleexamples.
DashaValter,SharanNarang,GauravMishra,Adams
Limitations of example-based fine-tuning. Fi- Yu, Vincent Zhao, Yanping Huang, Andrew Dai,HongkunYu,SlavPetrov,EdH.Chi,JeffDean,Ja- OrHonovich,ThomasScialom,OmerLevy,andTimo
cobDevlin,AdamRoberts,DennyZhou,QuocV.Le, Schick. 2023. Unnatural instructions: Tuning lan-
andJasonWei.2022. Scalinginstruction-finetuned guage models with (almost) no human labor. In
languagemodels. Proceedings of the 61st Annual Meeting of the As-
sociationforComputationalLinguistics(Volume1:
Nicola S Clayton and Anthony Dickinson. 1998. LongPapers),pages14409–14428,Toronto,Canada.
Episodic-like memory during cache recovery by AssociationforComputationalLinguistics.
scrubjays. Nature,395(6699):272–274.
JeremyHowardandSebastianRuder.2018. Universal
language model fine-tuning for text classification.
NathanJEmeryandNicolaSClayton.2004. Themen-
In Proceedings of the 56th Annual Meeting of the
talityofcrows: convergentevolutionofintelligence
AssociationforComputationalLinguistics(Volume1:
incorvidsandapes. science,306(5703):1903–1907.
LongPapers),pages328–339,Melbourne,Australia.
AssociationforComputationalLinguistics.
HaoFang,AnushaBalakrishnan,HarshJhamtani,John
Bufe,JeanCrawford,JayantKrishnamurthy,Adam
ChenxuHu,JieFu,ChenzhuangDu,SimianLuo,Junbo
Pauls,JasonEisner,JacobAndreas,andDanKlein.
Zhao,andHangZhao.2023. Chatdb: Augmenting
2023. The whole truth and nothing but the truth:
llmswithdatabasesastheirsymbolicmemory.
Faithfulandcontrollabledialogueresponsegenera-
tionwithdataflowtransductionandconstrainedde-
JiaxinHuang,ShixiangGu,LeHou,YuexinWu,Xuezhi
coding. InFindingsoftheAssociationforCompu-
Wang, Hongkun Yu, and Jiawei Han. 2023. Large
tational Linguistics: ACL 2023, pages 5682–5700,
languagemodelscanself-improve. InProceedings
Toronto,Canada.AssociationforComputationalLin-
ofthe2023ConferenceonEmpiricalMethodsinNat-
guistics.
uralLanguageProcessing,pages1051–1068,Singa-
pore.AssociationforComputationalLinguistics.
Deep Ganguli, Amanda Askell, Nicholas Schiefer,
ThomasLiao,Kamile˙ Lukošiu¯te˙,AnnaChen,Anna Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas
Goldie,AzaliaMirhoseini,CatherineOlsson,Danny Hosseini,FabioPetroni,TimoSchick,JaneDwivedi-
Hernandez,etal.2023. Thecapacityformoralself- Yu,ArmandJoulin,SebastianRiedel,andEdouard
correctioninlargelanguagemodels. arXivpreprint Grave.2022. Atlas: Few-shotlearningwithretrieval
arXiv:2302.07459. augmentedlanguagemodels.
Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, AlbertQ.Jiang,AlexandreSablayrolles,ArthurMen-
PengfeiLiu, YimingYang, JamieCallan, andGra- sch,ChrisBamford,DevendraSinghChaplot,Diego
ham Neubig. 2023. Pal: Program-aided language delasCasas,FlorianBressand,GiannaLengyel,Guil-
models. In International Conference on Machine laumeLample,LucileSaulnier,LélioRenardLavaud,
Learning,pages10764–10799.PMLR. Marie-AnneLachaux,PierreStock,TevenLeScao,
Thibaut Lavril, Thomas Wang, Timothée Lacroix,
KathleenRGibson,KathleenRitaGibson,andTimIn- andWilliamElSayed.2023. Mistral7b.
gold.1993. Tools,languageandcognitioninhuman
evolution. CambridgeUniversityPress. Geunwoo Kim, Pierre Baldi, and Stephen McAleer.
2023. Languagemodelscansolvecomputertasks.
arXivpreprintarXiv:2303.17491.
YuGu,YihengShu,HaoYu,XiaoLiu,YuxiaoDong,
JieTang,JayanthSrinivasa,HugoLatapie,andYuSu.
JamesKirkpatrick,RazvanPascanu,NeilRabinowitz,
2024. Middlewareforllms: Toolsareinstrumental
JoelVeness,GuillaumeDesjardins,AndreiA.Rusu,
forlanguageagentsincomplexenvironments. arXiv
Kieran Milan, John Quan, Tiago Ramalho, Ag-
preprintarXiv:2402.14672.
nieszkaGrabska-Barwinska,DemisHassabis,Clau-
diaClopath,DharshanKumaran,andRaiaHadsell.
KelvinGuu,KentonLee,ZoraTung,PanupongPasu-
2017. Overcomingcatastrophicforgettinginneural
pat,andMingweiChang.2020. Retrievalaugmented
networks. ProceedingsoftheNationalAcademyof
languagemodelpre-training. InInternationalconfer-
Sciences,114(13):3521–3526.
enceonmachinelearning,pages3929–3938.PMLR.
AnanyaKumar,AditiRaghunathan,RobbieMatthew
ShiboHao,TianyangLiu,ZhenWang,andZhitingHu. Jones, Tengyu Ma, and Percy Liang. 2022. Fine-
2023. ToolkenGPT: Augmenting frozen language tuningcandistortpretrainedfeaturesandunderper-
modelswithmassivetoolsviatoolembeddings. In formout-of-distribution. InInternationalConference
Thirty-seventh Conference on Neural Information onLearningRepresentations.
ProcessingSystems.
PatrickLewis,EthanPerez,AleksandraPiktus,Fabio
DanHendrycks,CollinBurns,StevenBasart,AndyZou, Petroni,VladimirKarpukhin,NamanGoyal,Hein-
MantasMazeika,DawnSong,andJacobSteinhardt. richKüttler, MikeLewis, Wen-tauYih, TimRock-
2021. Measuringmassivemultitasklanguageunder- täschel,etal.2020. Retrieval-augmentedgeneration
standing. InInternationalConferenceonLearning forknowledge-intensivenlptasks. AdvancesinNeu-
Representations. ralInformationProcessingSystems,33:9459–9474.XianLi,PingYu,ChuntingZhou,TimoSchick,Luke Shashank Gupta, Bodhisattwa Prasad Majumder,
Zettlemoyer, Omer Levy, Jason Weston, and Mike Katherine Hermann, Sean Welleck, Amir Yazdan-
Lewis.2023. Self-alignmentwithinstructionback- bakhsh, and Peter Clark. 2023. Self-refine: Itera-
translation. tiverefinementwithself-feedback. InThirty-seventh
ConferenceonNeuralInformationProcessingSys-
XinnianLiang,BingWang,HuiHuang,ShuangzhiWu, tems.
PeihaoWu,LuLu,ZejunMa,andZhoujunLi.2023a.
Unleashing infinite-lengthinput capacityfor large- GrégoireMialon,RobertoDessi,MariaLomeli,Christo-
scalelanguagemodelswithself-controlledmemory foros Nalmpantis, Ramakanth Pasunuru, Roberta
system. Raileanu, Baptiste Roziere, Timo Schick, Jane
Dwivedi-Yu,AsliCelikyilmaz,EdouardGrave,Yann
Yaobo Liang, Chenfei Wu, Ting Song, Wenshan Wu, LeCun,andThomasScialom.2023. Augmentedlan-
Yan Xia, Yu Liu, Yang Ou, Shuai Lu, Lei Ji, guagemodels: asurvey. TransactionsonMachine
ShaoguangMao,etal.2023b. Taskmatrix.ai: Com- LearningResearch. SurveyCertification.
pletingtasksbyconnectingfoundationmodelswith
millionsofapis. arXivpreprintarXiv:2303.16434. Ali Modarressi, Ayyoob Imani, Mohsen Fayyaz, and
HinrichSchütze.2023. Ret-llm: Towardsageneral
BillYuchenLin, AbhilashaRavichander, XimingLu, read-writememoryforlargelanguagemodels.
NouhaDziri,MelanieSclar,KhyathiChandu,Chan-
draBhagavatula,andYejinChoi.2023. Theunlock- OpenAI.2023. Gpt-4technicalreport.
ing spell on base llms: Rethinking alignment via
in-contextlearning. Liangming Pan, Michael Saxon, Wenda Xu, Deepak
Nathani,XinyiWang,andWilliamYangWang.2023.
JiachangLiu,DinghanShen,YizheZhang,BillDolan, Automaticallycorrectinglargelanguagemodels:Sur-
Lawrence Carin, and Weizhu Chen. 2022. What veyingthelandscapeofdiverseself-correctionstrate-
makes good in-context examples for GPT-3? In gies. arXivpreprintarXiv:2308.03188.
ProceedingsofDeepLearningInsideOut(DeeLIO
2022): The 3rd Workshop on Knowledge Extrac- AaronParisi,YaoZhao,andNoahFiedel.2022. Talm:
tionandIntegrationforDeepLearningArchitectures, Toolaugmentedlanguagemodels.
pages100–114,Dublin,IrelandandOnline.Associa-
Shishir G Patil, Tianjun Zhang, Xin Wang, and
tionforComputationalLinguistics.
JosephEGonzalez.2023. Gorilla: Largelanguage
Shayne Longpre, Le Hou, Tu Vu, Albert Webson, modelconnectedwithmassiveapis. arXivpreprint
HyungWonChung,YiTay,DennyZhou,QuocV.Le, arXiv:2305.15334.
Barret Zoph, Jason Wei, and Adam Roberts. 2023.
BaolinPeng,MichelGalley,PengchengHe,HaoCheng,
Theflancollection: Designingdataandmethodsfor
YujiaXie,YuHu,QiuyuanHuang,LarsLiden,Zhou
effectiveinstructiontuning.
Yu,WeizhuChen,etal.2023. Checkyourfactsand
Ilya Loshchilov and Frank Hutter. 2019. Decoupled try again: Improving large language models with
weightdecayregularization. InInternationalConfer- externalknowledgeandautomatedfeedback. arXiv
enceonLearningRepresentations. preprintarXiv:2302.12813.
PanLu,BaolinPeng,HaoCheng,MichelGalley,Kai- Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen,
Wei Chang, Ying Nian Wu, Song-Chun Zhu, and Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang,
Jianfeng Gao. 2023. Chameleon: Plug-and-play ChaojunXiao,ChiHan,YiRenFung,YushengSu,
compositionalreasoningwithlargelanguagemodels. HuadongWang,ChengQian,RunchuTian,Kunlun
InThirty-seventhConferenceonNeuralInformation Zhu,ShihaoLiang,XingyuShen,BokaiXu,Zhen
ProcessingSystems. Zhang,YiningYe,BowenLi,ZiweiTang,JingYi,
Yuzhang Zhu, Zhenning Dai, Lan Yan, Xin Cong,
Yun Luo, Zhen Yang, Fandong Meng, Yafu Li, Jie Yaxi Lu, Weilin Zhao, Yuxiang Huang, Junxi Yan,
Zhou, and Yue Zhang. 2023. An empirical study Xu Han, Xian Sun, Dahai Li, Jason Phang, Cheng
of catastrophic forgetting in large language mod- Yang, Tongshuang Wu, Heng Ji, Zhiyuan Liu, and
els during continual fine-tuning. arXiv preprint MaosongSun.2023. Toollearningwithfoundation
arXiv:2308.08747. models.
Aman Madaan, Niket Tandon, Peter Clark, and Yim- YujiaQin,ShihaoLiang,YiningYe,KunlunZhu,Lan
ing Yang. 2022. Memory-assisted prompt editing Yan,YaxiLu,YankaiLin,XinCong,XiangruTang,
to improve GPT-3 after deployment. In Proceed- BillQian,SihanZhao,LaurenHong,RunchuTian,
ingsofthe2022ConferenceonEmpiricalMethods Ruobing Xie, Jie Zhou, Mark Gerstein, dahai li,
inNaturalLanguageProcessing,pages2833–2861, Zhiyuan Liu, and Maosong Sun. 2024. ToolLLM:
AbuDhabi,UnitedArabEmirates.Associationfor Facilitatinglargelanguagemodelstomaster16000+
ComputationalLinguistics. real-worldAPIs. InTheTwelfthInternationalCon-
ferenceonLearningRepresentations.
AmanMadaan, NiketTandon,PrakharGupta,Skyler
Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, ADavidRedish.2016. Vicarioustrialanderror. Nature
Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, ReviewsNeuroscience,17(3):147–159.Nils Reimers and Iryna Gurevych. 2019. Sentence- learning. In Thirty-seventh Conference on Neural
BERT:SentenceembeddingsusingSiameseBERT- InformationProcessingSystems.
networks. InProceedingsofthe2019Conferenceon
EmpiricalMethodsinNaturalLanguageProcessing Robert W Shumaker, Kristina R Walkup, and Ben-
andthe9thInternationalJointConferenceonNatu- jaminBBeck.2011. Animaltoolbehavior: theuse
ralLanguageProcessing(EMNLP-IJCNLP),pages andmanufactureoftoolsbyanimals. JHUPress.
3982–3992,HongKong,China.AssociationforCom-
putationalLinguistics. NianwenSi,HaoZhang,HeyuChang,WenlinZhang,
Dan Qu, and Weiqiang Zhang. 2023. Knowledge
ChristopherRiesbeck.1981. Failure-drivenreminding unlearningforllms: Tasks,methods,andchallenges.
forincrementallearning. InIJCAI,pages115–120.
Citeseer. Yifan Song, Weimin Xiong, Dawei Zhu, Cheng Li,
Ke Wang, Ye Tian, and Sujian Li. 2023. Rest-
Ohad Rubin, Jonathan Herzig, and Jonathan Berant.
gpt: Connecting large language models with real-
2022. Learning to retrieve prompts for in-context
world applications via restful apis. arXiv preprint
learning. InProceedingsofthe2022Conferenceof
arXiv:2306.06624.
theNorthAmericanChapteroftheAssociationfor
ComputationalLinguistics: HumanLanguageTech-
Mirac Suzgun, Nathan Scales, Nathanael Schärli, Se-
nologies, pages 2655–2671, Seattle, United States.
bastian Gehrmann, Yi Tay, Hyung Won Chung,
AssociationforComputationalLinguistics.
Aakanksha Chowdhery, Quoc Le, Ed Chi, Denny
Zhou,andJasonWei.2023. ChallengingBIG-bench
RogerC.Schank.1983. DynamicMemory:ATheoryof
tasksandwhetherchain-of-thoughtcansolvethem.
RemindingandLearninginComputersandPeople.
InFindingsoftheAssociationforComputationalLin-
CambridgeUniversityPress,USA.
guistics: ACL 2023, pages 13003–13051, Toronto,
TimoSchick,JaneDwivedi-Yu,RobertoDessi,Roberta Canada.AssociationforComputationalLinguistics.
Raileanu,MariaLomeli,EricHambro,LukeZettle-
moyer,NicolaCancedda,andThomasScialom.2023. QiaoyuTang,ZiliangDeng,HongyuLin,XianpeiHan,
Toolformer: Languagemodelscanteachthemselves QiaoLiang,BoxiCao,andLeSun.2023. Toolalpaca:
tousetools. InThirty-seventhConferenceonNeural Generalizedtoollearningforlanguagemodelswith
InformationProcessingSystems. 3000simulatedcases.
Timo Schick and Hinrich Schütze. 2021. Generating Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
datasets with pretrained language models. In Pro- bert, Amjad Almahairi, Yasmine Babaei, Nikolay
ceedingsofthe2021ConferenceonEmpiricalMeth- Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti
ods in Natural Language Processing, pages 6943– Bhosale,DanBikel,LukasBlecher,CristianCanton
6951,OnlineandPuntaCana,DominicanRepublic. Ferrer,MoyaChen,GuillemCucurull,DavidEsiobu,
AssociationforComputationalLinguistics. JudeFernandes,JeremyFu,WenyinFu,BrianFuller,
CynthiaGao,VedanujGoswami,NamanGoyal,An-
Thomas Scialom, Tuhin Chakrabarty, and Smaranda
thonyHartshorn,SagharHosseini,RuiHou,Hakan
Muresan. 2022. Fine-tuned language models are
Inan,MarcinKardas,ViktorKerkez,MadianKhabsa,
continuallearners. InProceedingsofthe2022Con-
IsabelKloumann,ArtemKorenev,PunitSinghKoura,
ferenceonEmpiricalMethodsinNaturalLanguage
Marie-AnneLachaux,ThibautLavril,JenyaLee,Di-
Processing, pages 6107–6122, Abu Dhabi, United
anaLiskovich,YinghaiLu,YuningMao,XavierMar-
ArabEmirates.AssociationforComputationalLin-
tinet,TodorMihaylov,PushkarMishra,IgorMoly-
guistics.
bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-
stein,RashiRungta,KalyanSaladi,AlanSchelten,
YongliangShen,KaitaoSong,XuTan,DongshengLi,
Ruan Silva, Eric Michael Smith, Ranjan Subrama-
WeimingLu,andYuetingZhuang.2023. Hugging-
nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-
GPT:SolvingAItaskswithchatGPTanditsfriends
lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,
in hugging face. In Thirty-seventh Conference on
ZhengYan,IliyanZarov,YuchenZhang,AngelaFan,
NeuralInformationProcessingSystems.
Melanie Kambadur, Sharan Narang, Aurelien Ro-
RichardShin,ChristopherLin,SamThomson,Charles driguez,RobertStojnic,SergeyEdunov,andThomas
Chen,SubhroRoy,EmmanouilAntoniosPlatanios, Scialom.2023. Llama2: Openfoundationandfine-
AdamPauls,DanKlein,JasonEisner,andBenjamin tunedchatmodels.
Van Durme. 2021. Constrained language models
yieldfew-shotsemanticparsers. InProceedingsof KristVaesen.2012. Thecognitivebasesofhumantool
the2021ConferenceonEmpiricalMethodsinNatu- use. Behavioralandbrainsciences,35(4):203–218.
ralLanguageProcessing,pages7699–7715,Online
andPuntaCana,DominicanRepublic.Association DanqingWangandLeiLi.2023. Learningfrommis-
forComputationalLinguistics. takes via cooperative study assistant for large lan-
guagemodels. InProceedingsofthe2023Confer-
Noah Shinn, Federico Cassano, Ashwin Gopinath, enceonEmpiricalMethodsinNaturalLanguagePro-
KarthikRNarasimhan,andShunyuYao.2023. Re- cessing,pages10667–10685,Singapore.Association
flexion: languageagentswithverbalreinforcement forComputationalLinguistics.Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack
Hessel,TusharKhot,KhyathiChandu,DavidWad-
den,KelseyMacMillan,NoahA.Smith,IzBeltagy,
andHannanehHajishirzi.2023a. Howfarcancamels
go? exploringthestateofinstructiontuningonopen
resources. InThirty-seventhConferenceonNeural
InformationProcessingSystemsDatasetsandBench-
marksTrack.
YizhongWang,YeganehKordi,SwaroopMishra,Alisa
Liu,NoahA.Smith,DanielKhashabi,andHannaneh
Hajishirzi.2023b. Self-instruct: Aligninglanguage
modelswithself-generatedinstructions. InProceed-
ingsofthe61stAnnualMeetingoftheAssociationfor
ComputationalLinguistics(Volume1: LongPapers),
pages13484–13508,Toronto,Canada.Association
forComputationalLinguistics.
TianbaoXie,FanZhou,ZhoujunCheng,PengShi,Lu-
oxuanWeng,YitaoLiu,TohJingHua,JunningZhao,
QianLiu,CheLiu,LeoZ.Liu,YihengXu,Hongjin
Su, Dongchan Shin, Caiming Xiong, and Tao Yu.
2023. Openagents: Anopenplatformforlanguage
agentsinthewild.
WenhanXiong,JingyuLiu,IgorMolybog,HejiaZhang,
Prajjwal Bhargava, Rui Hou, Louis Martin, Rashi
Rungta,KarthikAbinavSankararaman,BarlasOguz,
MadianKhabsa,HanFang,YasharMehdad,Sharan
Narang,KshitizMalik,AngelaFan,ShrutiBhosale,
SergeyEdunov,MikeLewis,SinongWang,andHao
Ma.2023. Effectivelong-contextscalingoffounda-
tionmodels.
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak
Shafran,KarthikRNarasimhan,andYuanCao.2023.
React: Synergizingreasoningandactinginlanguage
models. InTheEleventhInternationalConference
onLearningRepresentations.
EricZelikman,YuhuaiWu,JesseMu,andNoahGood-
man.2022. STar: Bootstrappingreasoningwithrea-
soning. InAdvancesinNeuralInformationProcess-
ingSystems.
Kexun Zhang, Hongqiao Chen, Lei Li, and William
Wang.2023. Syntaxerror-freeandgeneralizabletool
useforllmsviafinite-statedecoding.
Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu
Lin, Yong-Jin Liu, and Gao Huang. 2023. Expel:
Llmagentsareexperientiallearners.
WanjunZhong,LianghongGuo,QiqiGao,HeYe,and
YanlinWang.2023. Memorybank: Enhancinglarge
languagemodelswithlong-termmemory.
ChuntingZhou,PengfeiLiu,PuxinXu,SriniIyer,Jiao
Sun,YuningMao,XuezheMa,AviaEfrat,PingYu,
LILIYU,SusanZhang,GargiGhosh,MikeLewis,
Luke Zettlemoyer, and Omer Levy. 2023. LIMA:
Lessismoreforalignment. InThirty-seventhCon-
ferenceonNeuralInformationProcessingSystems.A APISelection E Prompts
Weselect50APIsfromToolBench4,alargecollec- Table10,11includethefullpromptforsimulated
tionofAPIsfromBMTools5 andRapidAPI6.For trial and error. Table 10 includes the prompt for
BMTools, we manually selected 10 high-quality self-refinewithexecutionfeedbackandshort-term
APIs. ForRapidAPI,duetothelargescaleofAPI memory, and Table 11 includes the prompt for
pool(over16k),weperformfilteringby1)select- long-termmemory. Table12and13includesthe
ingAPIsthatarefreetousewithoutsubscription promptsforexamplefilteringandparaphrasingre-
needed;2)sortingtheAPIsbasedontheratelimit spectively.
andlatencyandselectingthetop400ones;3)run-
ning a small scale exploration using ChatGPT to
interactwiththeAPIexecutionenvironment,and
selecting the top 40 ones based on the API call
successrate.
B ExperimentalDetails
Fine-tuning. All model fine-tuning are done us-
ing the AdamW optimizer (Loshchilov and Hut-
ter, 2019) with β = (0.9,0.999), ϵ = 10−8 and
noweightdecay. Wefine-tunethemodelforone
epoch with learning rate 2×10−5, and a cosine
schedulerwithwarmupratio0.03,andbatchsize
64. Allfine-tuningrunsaredonewith4NVIDIA
A100/A6000 GPUs. The training examples are
truncatedto2,048tokens.
Flan-V2 data & rehearsal. We use Flan-
V2(Chungetal.,2022;Longpreetal.,2023)forre-
hearsalwhichisoneofthehighestqualitygeneral-
domaininstructiontuningdata(Wangetal.,2023a).
WeusethedatareleasedbyWangetal.(2023a).7
C Examplequeriesforallexploredtrials
Table14,15,16includethequeriesforallexplored
trialsfortheforecast_weatherAPIacrossdiffer-
entsettings(asindicatedinthecaption). Figure4
includesthehistogramofexploredtrialsgrouped
accordingtotheinquiredattribute,comparingSTE
andSTEwithoutlong-termmemory. Theresults
clearlyshowthatthememorymechanismsinSTE
substantiallyimprovethediversityandcomprehen-
sivenessoftheexploration.
D ErrorExamplesofGPT-4and
Mistral-Instruct-7B
Table 4, 5, 6 include the error examples of GPT-
4,andTable7,8,9includetheerrorexamplesof
fine-tunedMistral-Instruct-7Breferredby§4.2.
4https://github.com/OpenBMB/ToolBench
5https://github.com/OpenBMB/BMTools
6https://rapidapi.com/
7https://github.com/allenai/open-instructweather
maximum wind speed
current temperature
UV index
average humidity
average wind speed
wind speed
humidity level
sunrise and sunset time
chance of snow
temperature
chance of rain
maximum and minimum temperatures
average temperature
precipitation
maximum temperature
average visibility
hourly temperature STE
STE w/o long-term memory
0.0 0.1 0.2 0.3 0.4 0.5 0.6
% of trials
Figure4: Histogramofexploredtrialsgroupedaccordingtotheinquiredattribute. Long-termmemorysubstantially
improvesthediversityoftheexploredattributes.
Userquery: WhichparksinSanFranciscohavehikingtrails?
GroundtruthAPIname: search_places
DescriptionforgroundtruthAPI:RunPlacessearch.Yourinputshouldbeajson(argsjsonschema):{"query":
string,}
Groundtrutharguments: {"query": "parksinSanFranciscowithhikingtrails"}
PredictedAPI:Geographic coordinates by placename
DescriptionforpredictedAPI:Returnsgeographiccoordinatesforthegivenplacename(city,village,etc.). The
methodreturnstheplacewhosenameismostsimilartothesearchstring.","required_parameters": [{"name":
"name", "type": "STRING", "description": "Placename", "default": "London"}, {"name": "lang", "type":
"ENUM","description":"Two-letterlanguagecode(ISO639-1). Thefollowingvaluesareavailable:en(english),
ru(russian)","default": ""}],"optional_parameters": [{"name": "country","type": "STRING","description":
"Two-lettercountrycode,ISO-3166(optional). Defaultisallcountries.","default": ""}]
PredictedArguments: {"name": "SanFrancisco","lang": "en"}
Table4: ErrorexampleforGPT-4(category: wrongAPIcall). HereGPT-4“overlooks”theGooglePlacesAPI
whichfulfillsthequery,andinsteadcallsanAPIthatretrievesthegeographiccoordinatesofthetargetplace.
etubirttaUserquery: WhatarethegeographiccoordinatesforthecityofSydney,Canada?
GroundtruthAPIname: Geographiccoordinatesbyplacename
Description for ground truth API: Returns geographic coordinates for the given placename (city, village,
etc.). The method returns the place whose name is most similar to the search string. Required parameters:
[{"name": "name","type": "STRING","description": "Placename","default": "London"},{"name": "lang",
"type": "ENUM","description": "Two-letterlanguagecode(ISO639-1). Thefollowingvaluesareavailable:
en (english), ru (russian)", "default": ""}]. Optional parameters: [{"name": "country", "type": "STRING",
"description": "Two-lettercountrycode,ISO-3166(optional). Defaultisallcountries.","default": ""}]
Groundtrutharguments: {"name": "Sydney", "country": "CA", "lang": "en"}
PredictedAPI:Geographiccoordinatesbyplacename
DescriptionforpredictedAPI:Returnsgeographiccoordinatesforthegivenplacename(city,village,etc.). The
methodreturnstheplacewhosenameismostsimilartothesearchstring.","required_parameters": [{"name":
"name", "type": "STRING", "description": "Placename", "default": "London"}, {"name": "lang", "type":
"ENUM","description":"Two-letterlanguagecode(ISO639-1). Thefollowingvaluesareavailable:en(english),
ru(russian)","default": ""}],"optional_parameters": [{"name": "country","type": "STRING","description":
"Two-lettercountrycode,ISO-3166(optional). Defaultisallcountries.","default": ""}]
PredictedArguments: [{"name": "Sydney", "country": "CA"}
Table5: ErrorexampleforGPT-4(category: wrongAPIarguments). HereGPT-4choosestherighttoolbutfailsto
fillintherequired“lang”keyword.
Userquery: Whatarethemaincausesofclimatechange?
GroundtruthAPIname: search
DescriptionforgroundtruthAPI:Theinputisanexactentityname. Theactionwillsearchthisentityname
onWikipediaandreturnsthefirstfivesentencesifitexists. Ifnot,itwillreturnsomerelatedentitiestosearch
next. Yourinputshouldbeajson(argsjsonschema): {"entity": string,}
Groundtrutharguments: {"entity": "causesofclimatechange"}
PredictedAPI:search_general
DescriptionforpredictedAPI:RunquerythroughGoogleSearchandparseresult. Yourinputshouldbeajson
(argsjsonschema): {"query": string,}
PredictedArguments: {"query": "maincausesofclimatechange"}
Table6: ErrorexampleforGPT-4(category: hardtojudgecorrectness). HereGPT-4callstheGoogleSearchAPI
whichcouldalsobeavalidchoicebesidesthegroundtruth.
Userquery: WhatisthecurrentadvisoryinformationfortheUnion City station?
GroundtruthAPIname: BART-Advisoryinformation
DescriptionforgroundtruthAPI:TheBARTAPIgivesyouaccesstoprettymuchalloftheBARTservice
andstationdataavailableontheBARTwebsite. "required_parameters": [{"name": "cmd","type": "STRING",
"description": "Seemoreexampleshttp://api.bart.gov/docs/overview/examples.aspx","default": "bsa"}],"op-
tional_parameters": [{"name": "orig", "type": "STRING", "description": "Optional station filter. Uses 4
characterBARTstationabbreviations(http://api.bart.gov/docs/overview/abbrev.aspx)","default": ""}]
Groundtrutharguments: {"cmd": "bsa","orig": "UCTY"}
PredictedAPI:BART-Advisoryinformation
PredictedArguments: {"cmd": "bsa","orig": "UNION"}
Table7: ErrorexampleofMistral-Instruct(7B)afterfine-tuning. Herethemodelhallucinatesawrongabbreviation
forthetargetstationduetoalackofcommonsense/worldknowledge.Userquery: WhataretheongoinggiveawaysforPCgamekeysontheGOG platform?
GroundtruthAPIname: GamerPower-Filter&GroupGiveaways
DescriptionforgroundtruthAPI:"Findallfreegames,lootandgiveawayswiththisgiveawaytrackerAPI
powered by GamerPower.com! Access programmatically the best giveaways in gaming! Filter and group
platformsandgiveawaytypestogetpersonalizedresults.","required_parameters": [{"name": "platform","type":
"STRING","description": "","default": "epic-games-store.steam.android"}],"optional_parameters": [{"name":
"type","type": "STRING","description": "","default": "game.loot"}]
Groundtrutharguments: {"platform": "gog","type": "game.key"}
PredictedAPI:GamerPower-Filter&GroupGiveaways
PredictedArguments: {"platform": "pc","type": "game.key"}
Table8: ErrorexampleofMistral-Instruct(7B)afterfine-tuning. Herethemodelmakesamistakeonunderstanding
theuserqueryandpredictsthewrongargumentfor“platform”.
Userquery:CanyouprovidethetotalnumberofmatchesplayedbetweenLeedsUnitedandSheffieldWednesday
intheEnglishPremierLeague?
GroundtruthAPIname: FootballDolphin-Headtoheadstatistics
Description for ground truth API: This Api returns statistical data about English Premier League. Click
on the link to view all endpoints in one web app https://football-dolphin-web-app.up.railway.app/. "re-
quired_parameters": [{"name": "first_team", "type": "STRING", "description": "**Enter first team from
allavailableteams:**Arsenal,AstonVilla,Barnsley,Birmingham,Blackburn,Blackpool,Bolton,Bournemouth,
Bradford,Brighton,Burnley,Cardiff,Charlton,Chelsea,Coventry,CrystalPalace,Derby,Everton,Fulham,
Huddersfield,Hull,Ipswich,Leeds,Leicester,Liverpool,ManCity,ManUnited,Middlesbrough,Newcastle,
Norwich,Nott’mForest,Portsmouth,QPR,Reading,SheffieldUnited,SheffieldWeds,Southampton,Stoke,
Sunderland,Swansea,Tottenham,Watford,WestBrom,WestHam,Wigan,Wimbledon,Wolves","default":
"ManUnited"},{"name": "second_team","type": "STRING","description": "**Entersecondteamfromall
availableteams:**Arsenal,AstonVilla,Barnsley,Birmingham,Blackburn,Blackpool,Bolton,Bournemouth,
Bradford,Brighton,Burnley,Cardiff,Charlton,Chelsea,Coventry,CrystalPalace,Derby,Everton,Fulham,
Huddersfield,Hull,Ipswich,Leeds,Leicester,Liverpool,ManCity,ManUnited,Middlesbrough,Newcastle,
Norwich,Nott’mForest,Portsmouth,QPR,Reading,SheffieldUnited,SheffieldWeds,Southampton,Stoke,
Sunderland,Swansea,Tottenham,Watford,WestBrom,WestHam,Wigan,Wimbledon,Wolves","default":
"Liverpool"},{"name": "type_of_statistics","type": "STRING","description": "**Enteronefromavailable
typesofstatistics:**fulltimeresult,homevsawayfulltimeresult,resultfirsthalfandthematch,exactnumber
ofgoalsinthematch,goalsover,goalsunder","default": "fulltimeresult"}]
Groundtrutharguments:{"first_team":"Leeds","second_team":"SheffieldWeds","type_of_statistics":"full
timeresult"}
PredictedAPI:FootballDolphin-Headtoheadstatistics
PredictedArguments: {"first_team": "Leeds United","second_team": "SheffieldWeds","type_of_statistics":
"fulltimeresult"}
Table9: ErrorexampleofMistral-Instruct(7B)afterfine-tuning. Herethemodelcorrectlyextractsthetargetentity
butfailstogroundittothesetofsupportedentitiesofthetool.Yourtaskistoanswertheuser’squeryasbestyoucan.YouhaveaccesstothefollowingtoolswhichyoucanuseviaAPIcallto
helpwithyourresponse:
{api_descriptions}
NowyouhavethechancetoexploretheavailableAPIs.Youcandothisby1)synthesizingsomenaturaluserquerythatcallingthe
APIcouldhelp,and2)tryingtorespondtotheuserquerywiththehelpoftheAPIs.Here,youcanfocusonqueriesthatonlyrequire
callingtheAPIonce.
Now,firstinputyoursynthesizeduserquery.Youshouldmakethequerynatural-forexample,trytoavoidusingtheprovidedAPI
descriptionsorAPInamesinthequery,astheuserdoesnotknowwhatAPIsyouhaveaccessto.Also,trytomakethequeryas
specificaspossible.Inputjusttheuserqueryalone;doNOTsolvethequeryfornow.
UserQuery:
=========
Now,trytorespondtothequeryusingtheavailableAPIs.
TheformatyouusetheAPIisbyspecifying1)Action:theAPIfunctionnameyou’dliketocall2)ActionInput:theinputparameters
oftheAPIcallinajsonstringformat.TheresultoftheAPIcallwillbereturnedstartingwith"Observation:".Rememberthatyou
shouldonlyperformaSINGLEactionatatime,doNOTreturnalistofmultipleactions.
Reminder:
1)theonlyvaluesthatshouldfollow"Action:"are:{api_names}
2)usethefollowingjsonstringformatfortheAPIarguments:
ActionInput:
{
"key_1":"value_1",
...
"key_n":"value_n"
}
RemembertoALWAYSusethefollowingformat:
Thought:youshouldalwaysthinkaboutwhattodonext
Action:theAPIfunctionname
ActionInput:theinputparametersoftheAPIcallinjsonstringformat
Observation:thereturnresultoftheAPIcall.ThisiswhatIwillprovideyouwith;youdonotneedtorepeatitinyourresponse.
...(thisThought/Action/ActionInput/ObservationcanrepeatNtimes)
Thought:Inowknowthefinalanswer
FinalAnswer:theresponsetotheuserquery
Begin!Rememberthatyourresponseshouldneverstartwith"Observation:"sincethatiswhatIwillprovideyouwith.Onceyou
haveenoughinformation,pleaseimmediatelyuse
Thought:Inowknowthefinalanswer
FinalAnswer:
UserQuery(thesameyoujustsynthesized):{query}
=========
Doyouthinkyousuccessfullyansweredthisqueryintheend?Respondwith"Yes"or"No".
=========
NowyouknowabitmoreabouttheAPI.YoucansynthesizeanotheruserquerytoexploretheAPIabitfurtherandconsolidate
yourunderstandingoftheAPI,basedonthingsthatyoudiscoveredaboutthisAPI.Again,justinputtheuserqueryalone;doNOT
solvethequeryfornow.
UserQuery:
=========
NowtrytosolvethequeryusingtheAPI.Remembertofollowthesameformat,i.e,
Thought:
Action:
ActionInput:
Observation:
FinalAnswer:
Table10: Promptforself-refinewithexecutionfeedbackandshort-termmemory.BelowarequeriesyouhavealreadyexploredandwhetheryousuccessfullysolvedthemwiththeAPI’shelp:
{long_term_memory}
Basedonthese,trytoexplorequeriesthatcanhelpyouunderstandtheAPIfurther;avoidsynthesizingqueriesthataretoocloseto
theexistingones.
Table11: Promptforlong-termmemory.
AnassistantistryingtorespondtotheuserquerywiththehelpofsomeAPIs. TheAPIsthattheassistanthasaccesstoareas
follows:
{api_descriptions}
Now,yourtaskistoevaluatehowwelltheassistantdidthejob.Checkcarefullythefollowingaspectsoftheassistant’sresponse:
1)whethertheresponseanswerstheuser’squeryinaninformativeway.Forexample,iftheAPIcallsareunsuccessfulandtheagent
can’tfindtheanswertotherequest,youshouldsay"No."
2)whethertheresponseisfaithfulwithrespecttotheexecutionresultsoftheAPIcalls.Theresponseshouldnotincludeinformation
thatcannotbesupportedbytheAPIcallfeedback,
3)whethertheassistantusedtheAPIcallsappropriately.Forexample,theassistantshouldalwaysuserelevantAPIcallsforqueries
aboutup-to-dateinformationorcomplexcalculations,
Foreachofthethreeaspects,youshouldsay"Yes"or"No"indicatingwhethertheassistantdidagoodjobinthataspect,and
explainthereasonbehindyourjudgment.Youroutputshouldfollowtheformatbelow,where"<explanation>"shouldbeyouractual
explanationforthecorrespondingjudgment:
1)Yes/No.<explanation>
2)Yes/No.<explanation>
3)Yes/No.<explanation>
Now,theuserqueryis:
{query}
Theassistant’sAPIcallsandthecorrespondingexecutionresultsare:
{chains}
Theassistant’sfinalresponseis:
{final_ans}
Now,yourevaluationis(remembertofollowthepreviousformat):
Table12: Promptforexamplefiltering.
Belowyouwillbegivenauserquery.Trytoparaphraseitinadifferentwaywhilepreservingitsmeaning.Thequeryis:
{query}
Yourparaphraseofthequery:
=========
Canyoutrytoparaphraseitagaininanewway?Avoidcomingupwithsomethingtooclosetoyourpreviousones.Yourparaphrase:
Table13: Promptforqueryparaphrasing.WhatistheUVindexinSanFranciscoforthenext3days?
WhatistheUVindexinSydneyforthenext3days?
WhatistheaveragehumidityinMiamiBeachforthenext5days?
WhatistheaveragetemperatureinLosAngelesforthenext3days?
WhatistheaveragetemperatureinMiamiforthenext5days?
WhatistheaveragetemperatureinSanFranciscoforthenext3days?
WhatistheaveragetemperatureinSydneyforthenext10days?
WhatistheaveragevisibilityinNewYorkCityforthenext3days?
WhatistheaveragevisibilityinTokyoforthenext4days?
WhatistheaveragewindspeedinChicagoforthenext7days?
WhatisthechanceofraininLondonforthenext3days?
WhatisthechanceofraininLosAngelesforthenext7days?
WhatisthechanceofraininMiamiBeachforthenext3days?
WhatisthechanceofraininSanFranciscoforthenext3days?
WhatisthechanceofraininSanFranciscoforthenext5days?
WhatisthechanceofraininSeattleforthenext7days?
WhatisthechanceofraininSydneyforthenext5days?
WhatisthechanceofraininTokyoforthenext7days?
WhatisthechanceofsnowinBostontomorrow?
WhatisthechanceofsnowinChicagoforthenext5days?
WhatisthechanceofsnowinDenverforthenext3days?
WhatisthechanceofsnowinNewYorkCityforthenext5days?
WhatisthechanceofsnowinParisforthenext3days?
WhatistheforecastedwindspeedinLondonforthenext5days?
WhatisthehourlyprecipitationforecastinNewYorkCityforthenext24hours?
WhatisthehourlyprecipitationforecastinSeattleforthenext24hours?
WhatisthehourlytemperatureforecastforChicagotomorrow?
WhatisthehourlytemperatureforecastinLosAngelesforthenext24hours?
WhatisthehourlytemperatureforecastinNewYorkCityforthenext12hours?
WhatisthehourlytemperatureforecastinSanFranciscoforthenext12hours?
WhatisthehourlywindspeedforecastinMiamitomorrow?
WhatisthemaximumtemperatureinSydneyforthenext7days?
WhatisthemaximumwindspeedinLosAngelesforthenext2days?
WhatisthesunriseandsunsettimeinParistomorrow?
WhatisthesunriseandsunsettimeinTokyotomorrow?
WhatisthetemperaturerangeinSydneyforthenext3days?
WhatisthetotalprecipitationinSydneyforthenext10days?
WhatisthetotalprecipitationinTokyoforthenext7days?
WhatistheweatherforecastinMiamiforthenextweek?
WhatisthewindforecastinSanFranciscoforthenext7days?
WhatwillbetheaveragetemperatureinLondonforthenext5days?
WhatwillbetheaveragetemperatureinSeattleforthenext7days?
WhatwillbetheaveragetemperatureinTokyoforthenext7days?
WhatwillbetheaveragevisibilityinMiamiforthenext7days?
WhatwillbetheaveragewindspeedinSanFranciscoforthenext3days?
WhatwillbethechanceofraininSanDiegoforthenext7days?
WhatwillbethehumiditylevelinLondonforthenext5days?
WhatwillbethemaximumtemperatureinChicagoforthenext5days?
WhatwillbethemaximumtemperatureinLondonforthenext10days?
WhatwillbethemaximumtemperatureinLosAngelesforthenext7days?
WhatwillbethemaximumtemperatureinMadridforthenext7days?
WhatwillbethemaximumtemperatureinParisforthenext7days?
WhatwillbethemaximumtemperatureinSydneyforthenext5days?
WhatwillbethemaximumtemperatureinTokyoforthenext10days?
WhatwillbethemaximumwindspeedinSanFranciscoforthenext5days?
WhatwillbetheweatherlikeinNewYorkCityforthenext5days?
WhatwillbethewindspeedforecastinBostonforthenext3days?
WhatwillbethewindspeedinChicagotomorrowmorning?
WillitraininSeattletomorrow?
WillitsnowinDenvernextweek?
Table14: Queriesinallexploredtrials(prefix-sorted). Setting: STE(bothshort-termandlong-termmemory).IsitgoingtoraininLondontomorrow?
WhatwillbethetemperatureinSanFranciscoonThursday?
WhatwillbetheweatherlikeinBarcelonaonFriday?
WhatwillbetheweatherlikeinBerlinnextWednesday?
WhatwillbetheweatherlikeinChicagointhenext7days?
WhatwillbetheweatherlikeinDenverinthenext5days?
WhatwillbetheweatherlikeinLondoninthenext2days?
WhatwillbetheweatherlikeinLondoninthenext3days?
WhatwillbetheweatherlikeinLondoninthenext5days?
WhatwillbetheweatherlikeinLondonnextFriday?
WhatwillbetheweatherlikeinLondononSunday?
WhatwillbetheweatherlikeinLosAngelesinthenext3days?
WhatwillbetheweatherlikeinLosAngelesonMonday?
WhatwillbetheweatherlikeinMadridinthenext5days?
WhatwillbetheweatherlikeinMadridonSunday?
WhatwillbetheweatherlikeinMiamiinthenext7days?
WhatwillbetheweatherlikeinMiamionFriday?
WhatwillbetheweatherlikeinMiamionSunday?
WhatwillbetheweatherlikeinMiamionWednesday?
WhatwillbetheweatherlikeinNewYorkCityinthenext5days?
WhatwillbetheweatherlikeinNewYorkCitynextSaturday?
WhatwillbetheweatherlikeinNewYorkCityonThursday?
WhatwillbetheweatherlikeinParisinthenext3days?
WhatwillbetheweatherlikeinParisnextMonday?
WhatwillbetheweatherlikeinParisonSunday?
WhatwillbetheweatherlikeinSanAntoniointhenext10days?
WhatwillbetheweatherlikeinSanFranciscoonFriday?
WhatwillbetheweatherlikeinSanFranciscoonSaturday?
WhatwillbetheweatherlikeinSeattleinthenext5days?
WhatwillbetheweatherlikeinSydneyinthenext5days?
WhatwillbetheweatherlikeinSydneyinthenext7days?
WhatwillbetheweatherlikeinSydneynextMonday?
WhatwillbetheweatherlikeinSydneynextTuesday?
WhatwillbetheweatherlikeinSydneynextWednesday?
WhatwillbetheweatherlikeinSydneyonMonday?
WhatwillbetheweatherlikeinSydneyonSaturday?
WhatwillbetheweatherlikeinTokyointhenext3days?
WhatwillbetheweatherlikeinTokyointhenext4days?
WhatwillbetheweatherlikeinTokyointhenext7days?
WhatwillbetheweatherlikeinTokyonextSunday?
WhatwillbetheweatherlikeinTokyonextTuesday?
WhatwillbetheweatherlikeinTokyoonFriday?
WhatwillbetheweatherlikeinTokyoonMonday?
WhatwillbetheweatherlikeinTokyoonSaturday?
WhatwillbetheweatherlikeinTokyoonSunday?
WhatwillbetheweatherlikeinTokyoonThursday?
WhatwillbetheweatherlikeinTokyoonWednesday?
WhatwilltheweatherbelikeinBarcelonainthenext7days?
WhatwilltheweatherbelikeinMiaminextMonday?
WhatwilltheweatherbelikeinParisonMonday?
WhatwilltheweatherbelikeinSydneynextWednesday?
WhatwilltheweatherbelikeinTokyotomorrow?
WillitbecloudyinTokyotomorrow?
WillitbehotinMiaminextweek?
WillitberainyinSeattletomorrow?
WillitbesunnyinMadridtomorrow?
WillitbesunnyinSanFrancisconextThursday?
WillitbesunnyinSanFranciscoonWednesday?
WillitraininLondoninthenext3days?
WillitraininSydneytomorrow?
Table15: Queriesinallexploredtrials(prefix-sorted). Setting: STEwithnoshort-termmemory.CanIgetthehourlyweatherforecastfortomorrowinNewYorkCity?
Canyouprovidetheweatherforecastforthenext10daysinLosAngeles?
Howaccurateistheweatherforecastfortheupcomingweek?
WhatistheaveragevisibilityinParisforthenext7days?
WhatisthechanceofraininLosAngelestomorrow?
WhatisthechanceofraininMiamiforthenext3days?
WhatisthechanceofraininSeattletomorrow?
WhatisthechanceofraininSydneyforthenext7days?
WhatisthechanceofraininTokyoforthenext5days?
WhatisthecurrenttemperatureinLosAngeles?
WhatisthecurrenttemperatureinNewYorkCity?
WhatisthecurrentweatherconditioninSydney?
WhatistheforecastedtemperatureforParistomorrow?
WhatistheforecastedtemperatureinLosAngelesforthenext10days?
WhatistheforecastedweatherforNewYorkCityforthenext5days?
WhatistheforecastedwindspeedforLosAngelestomorrow?
WhatisthehourlyweatherforecastforLosAngelestomorrow?
WhatisthehourlyweatherforecastforLosAngelestomorrow?
WhatistheweatherforecastforLondontomorrow?
WhatistheweatherforecastforLosAngelestomorrow?
WhatistheweatherforecastforTokyointhenext10days?
Whatistheweatherforecastforthenext10daysinLondon?
Whatistheweatherforecastforthenext2daysinLondon?
Whatistheweatherforecastforthenext3daysinParis?
Whatistheweatherforecastforthenext5daysinLosAngeles?
WhatistheweatherforecastfortomorrowinNewYorkCity?
WhatisthewindspeedinParistomorrow?
WhatwillbetheaveragehumidityinTokyoforthenext3days?
WhatwillbetheaveragewindspeedinSeattleforthenext3days?
WhatwillbethemaximumandminimumtemperaturesinLondontomorrow?
WhatwillbethemaximumtemperatureinLondontomorrow?
WhatwillbethemaximumwindspeedinParistomorrow?
WhatwillbethetemperatureinLondoninthenext3days?
WhatwillbethetemperatureinSanFranciscotomorrow?
WhatwillbetheweatherconditionsinLondonforthenext7days?
WhatwillbetheweatherforecastforLondontomorrow?
WhatwillbetheweatherforecastforNewYorkCityinthenext5days?
WhatwillbetheweatherforecastforSeattleoverthenext5days?
WhatwillbetheweatherforecastforSydneynextweek?
Whatwillbetheweatherforecastforthenext5daysinNewYorkCity?
WhatwillbetheweatherinNewYorkCityforthenext5days?
WhatwillbetheweatherlikeinLondonforthenext3days?
WhatwillbetheweatherlikeinLondonforthenext7days?
WhatwillbetheweatherlikeinNewYorkCityforthenext5days?
WhatwillbetheweatherlikeinNewYorkCityforthenext5days?
WhatwillbetheweatherlikeinNewYorkCityforthenext5days?
WhatwillbetheweatherlikeinNewYorkCityforthenextthreedays?
WhatwillbetheweatherlikeinNewYorkCityinthenext5days?
WhatwillbetheweatherlikeinParisforthenext10days?
WhatwillbetheweatherlikeinSanFranciscoforthenext5days?
WhatwillbetheweatherlikeinSanFranciscotomorrow?
WhatwillbetheweatherlikeinTokyoforthenext7days?
WhatwilltheweatherbelikeinLondonforthenext5days?
WhatwilltheweatherbelikeinLondonforthenext7days?
WhatwilltheweatherbelikeinLosAngelesforthenext3days?
WhatwilltheweatherbelikeinNewYorkCityforthenext5days?
WhatwilltheweatherbelikeinNewYorkCityforthenext5days?
WhatwilltheweatherbelikeinNewYorkCitytomorrow?
WillitraininLosAngelestomorrow?
WillitraininSanFranciscotomorrow?
Table16: Queriesinallexploredtrials(prefix-sorted). Setting: STEwithnolong-termmemory.