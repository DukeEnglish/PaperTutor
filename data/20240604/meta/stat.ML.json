[
    {
        "title": "Exploratory Preference Optimization: Harnessing Implicit Q*-Approximation for Sample-Efficient RLHF",
        "authors": "Tengyang XieDylan J. FosterAkshay KrishnamurthyCorby RossetAhmed AwadallahAlexander Rakhlin",
        "links": "http://arxiv.org/abs/2405.21046v1",
        "entry_id": "http://arxiv.org/abs/2405.21046v1",
        "pdf_url": "http://arxiv.org/pdf/2405.21046v1",
        "summary": "Reinforcement learning from human feedback (RLHF) has emerged as a central\ntool for language model alignment. We consider online exploration in RLHF,\nwhich exploits interactive access to human or AI feedback by deliberately\nencouraging the model to produce diverse, maximally informative responses. By\nallowing RLHF to confidently stray from the pre-trained model, online\nexploration offers the possibility of novel, potentially super-human\ncapabilities, but its full potential as a paradigm for language model training\nhas yet to be realized, owing to computational and statistical bottlenecks in\ndirectly adapting existing reinforcement learning techniques. We propose a new\nalgorithm for online exploration in RLHF, Exploratory Preference Optimization\n(XPO), which is simple and practical -- a one-line change to (online) Direct\nPreference Optimization (DPO; Rafailov et al., 2023) -- yet enjoys the\nstrongest known provable guarantees and promising empirical performance. XPO\naugments the DPO objective with a novel and principled exploration bonus,\nempowering the algorithm to explore outside the support of the initial model\nand human feedback data. In theory, we show that XPO is provably\nsample-efficient and converges to a near-optimal language model policy under\nnatural exploration conditions, irrespective of whether the initial model has\ngood coverage. Our analysis, which builds on the observation that DPO\nimplicitly performs a form of $Q^{\\star}$-approximation (or, Bellman error\nminimization), combines previously disparate techniques from language modeling\nand theoretical reinforcement learning in a serendipitous fashion through the\nperspective of KL-regularized Markov decision processes. Empirically, we find\nthat XPO is more sample-efficient than non-exploratory DPO variants in a\npreliminary evaluation.",
        "updated": "2024-05-31 17:39:06 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.21046v1"
    },
    {
        "title": "Introducing sgboost: A Practical Guide and Implementation of sparse-group boosting in R",
        "authors": "Fabian ObsterChristian Heumann",
        "links": "http://arxiv.org/abs/2405.21037v1",
        "entry_id": "http://arxiv.org/abs/2405.21037v1",
        "pdf_url": "http://arxiv.org/pdf/2405.21037v1",
        "summary": "This paper introduces the sgboost package in R, which implements sparse-group\nboosting for modeling high-dimensional data with natural groupings in\ncovariates. Sparse-group boosting offers a flexible approach for both group and\nindividual variable selection, reducing overfitting and enhancing model\ninterpretability. The package uses regularization techniques based on the\ndegrees of freedom of individual and group base-learners, and is designed to be\nused in conjunction with the mboost package. Through comparisons with existing\nmethods and demonstration of its unique functionalities, this paper provides a\npractical guide on utilizing sparse-group boosting in R, accompanied by code\nexamples to facilitate its application in various research domains. Overall,\nthis paper serves as a valuable resource for researchers and practitioners\nseeking to use sparse-group boosting for efficient and interpretable\nhigh-dimensional data analysis.",
        "updated": "2024-05-31 17:29:51 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.21037v1"
    },
    {
        "title": "PUAL: A Classifier on Trifurcate Positive-Unlabeled Data",
        "authors": "Xiaoke WangXiaochen YangRui ZhuJing-Hao Xue",
        "links": "http://arxiv.org/abs/2405.20970v1",
        "entry_id": "http://arxiv.org/abs/2405.20970v1",
        "pdf_url": "http://arxiv.org/pdf/2405.20970v1",
        "summary": "Positive-unlabeled (PU) learning aims to train a classifier using the data\ncontaining only labeled-positive instances and unlabeled instances. However,\nexisting PU learning methods are generally hard to achieve satisfactory\nperformance on trifurcate data, where the positive instances distribute on both\nsides of the negative instances. To address this issue, firstly we propose a PU\nclassifier with asymmetric loss (PUAL), by introducing a structure of\nasymmetric loss on positive instances into the objective function of the global\nand local learning classifier. Then we develop a kernel-based algorithm to\nenable PUAL to obtain non-linear decision boundary. We show that, through\nexperiments on both simulated and real-world datasets, PUAL can achieve\nsatisfactory classification on trifurcate data.",
        "updated": "2024-05-31 16:18:06 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.20970v1"
    },
    {
        "title": "Aligning Multiclass Neural Network Classifier Criterion with Task Performance via $F_β$-Score",
        "authors": "Nathan TsoiDeyuan LiTaesoo Daniel LeeMarynel Vázquez",
        "links": "http://arxiv.org/abs/2405.20954v1",
        "entry_id": "http://arxiv.org/abs/2405.20954v1",
        "pdf_url": "http://arxiv.org/pdf/2405.20954v1",
        "summary": "Multiclass neural network classifiers are typically trained using\ncross-entropy loss. Following training, the performance of this same neural\nnetwork is evaluated using an application-specific metric based on the\nmulticlass confusion matrix, such as the Macro $F_\\beta$-Score. It is\nquestionable whether the use of cross-entropy will yield a classifier that\naligns with the intended application-specific performance criteria,\nparticularly in scenarios where there is a need to emphasize one aspect of\nclassifier performance. For example, if greater precision is preferred over\nrecall, the $\\beta$ value in the $F_\\beta$ evaluation metric can be adjusted\naccordingly, but the cross-entropy objective remains unaware of this preference\nduring training. We propose a method that addresses this training-evaluation\ngap for multiclass neural network classifiers such that users can train these\nmodels informed by the desired final $F_\\beta$-Score. Following prior work in\nbinary classification, we utilize the concepts of the soft-set confusion\nmatrices and a piecewise-linear approximation of the Heaviside step function.\nOur method extends the $2 \\times 2$ binary soft-set confusion matrix to a\nmulticlass $d \\times d$ confusion matrix and proposes dynamic adaptation of the\nthreshold value $\\tau$, which parameterizes the piecewise-linear Heaviside\napproximation during run-time. We present a theoretical analysis that shows\nthat our method can be used to optimize for a soft-set based approximation of\nMacro-$F_\\beta$ that is a consistent estimator of Macro-$F_\\beta$, and our\nextensive experiments show the practical effectiveness of our approach.",
        "updated": "2024-05-31 15:54:01 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.20954v1"
    },
    {
        "title": "Concentration Bounds for Optimized Certainty Equivalent Risk Estimation",
        "authors": "Ayon GhoshL. A. PrashanthKrishna Jagannathan",
        "links": "http://arxiv.org/abs/2405.20933v1",
        "entry_id": "http://arxiv.org/abs/2405.20933v1",
        "pdf_url": "http://arxiv.org/pdf/2405.20933v1",
        "summary": "We consider the problem of estimating the Optimized Certainty Equivalent\n(OCE) risk from independent and identically distributed (i.i.d.) samples. For\nthe classic sample average approximation (SAA) of OCE, we derive mean-squared\nerror as well as concentration bounds (assuming sub-Gaussianity). Further, we\nanalyze an efficient stochastic approximation-based OCE estimator, and derive\nfinite sample bounds for the same. To show the applicability of our bounds, we\nconsider a risk-aware bandit problem, with OCE as the risk. For this problem,\nwe derive bound on the probability of mis-identification. Finally, we conduct\nnumerical experiments to validate the theoretical findings.",
        "updated": "2024-05-31 15:32:43 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.20933v1"
    }
]