Optimally Improving Cooperative Learning in a Social Setting∗
Shahrzad Haddadan Cheng Xin
Rutgers Business School Department of Computer Science
shaddadan@business.rutgers.edu Rutgers University
cx122@rutgers.edu
Jie Gao
Department of Computer Science
Rutgers University
jg1555@rutgers.edu
June 3, 2024
Abstract
We consider a cooperative learning scenario where a collection of networked agents with indi-
vidually owned classifiers dynamically update their predictions, for the same classification task,
through communication or observations of each other’s predictions. Clearly if highly influential
vertices use erroneous classifiers, there will be a negative effect on the accuracy of all the agents
in the network. We ask the following question: how can we optimally fix the prediction of a few
classifiers so as maximize the overall accuracy in the entire network. To this end we consider an
aggregateandanegalitarianobjectivefunction. Weshowapolynomialtimealgorithmforoptimiz-
ing the aggregate objective function, and show that optimizing the egalitarian objective function
is NP-hard. Furthermore, we develop approximation algorithms for the egalitarian improvement.
Theperformanceofallofouralgorithmsareguaranteedbymathematicalanalysisandbackedby
experiments on synthetic and real data.
1 Introduction
With the breakthroughof AI technologies and theavailability of big data, we arewitnessinga flourish
of AI models that are owned by different entities and trained by using private or proprietary data,
evenforgenericpurposessuchasvoicerecognition,naturallanguageprocessingorimagesegmentation.
Thesemodelsdonotstayinisolation. Thereisanaturalopportunityforthesemodelstointeractwith
each other and collectively improve their performance.
One of the concrete application scenarios is in cybersecurity, where security agents in a network
collectivelydetectanomaloustrafficpatternsthatarepotentiallyassociatedwithcyberattacks. These
security agents may be affiliated with different entities in the network. They may or may not be able
todirectlysharetheircollecteddataduetoprivacyorotherlogisticreasonsbutcansharetheirbeliefs
on whether the network is under attack or not, and if so, which type of attack. In such a scenario,
improving the model of one agent by collecting more data, recruiting domain experts to provide high
quality labels of observation data, or retraining using a more powerful model can help to improve
the quality of prediction locally. As these security agents stay on a network, they naturally have
the opportunity to exchange their assessments. The quality improvement at one agent spills to other
agents in the network.
Another applicationscenariois in onlinesocial networks. With generative AI, itis now a loteasier
to create fake contents such as images and videos. Consider an online social network in which agents
share pictures and comment on them, e.g., Instagram. Assume that some of these pictures may be AI
∗ThispaperisgoingtoappearinICML2024
1
4202
yaM
13
]SD.sc[
1v80802.5042:viXragenerated. While everyone can have his or her opinion on whether a wide-spreading picture is real or
fake, the participants who are more skilled in image generation or who have access to powerful models
can help the rest of the network to discern real ones and fake ones.
Itisnotnewtoutilizedataandmodelsinadistributedsetting. Withtheexplosionofpersonaldata
from smartphones and wearable devices and the increasing awareness of data privacy, decentralized
learning, asopposedtouserssharingtheirdatatoacentralenterprise, hasgainedpopularityinrecent
years. Federated learning and gossip learning are such examples. However in this scenarios, the
decentralized agents are still tightly coupled – they use the same model architecture and sometimes
exchangegradientormodelparametersdirectly. Inourwork,weconsideralooselycoupled,cooperative
setting where agents share a general task requirement and they select individual model parameters
and architecture, train their models on their private data. Such agent autonomy is a necessity when
theagentsarenotaffiliatedwiththesameownership. Inaddition,weconsidertheagentssharingtheir
predictionswithotheragentspreferablythosewithinproximityorwithestablishedtrustrelationships.
We call this model cooperative learning in a social setting. Essentially each agent has her own view
of the world and through exchanging predictions with others, collectively we hope to improve the
accuracy for all agents.
When only predictions from other agents are shared, it is up to the individual agent to decide
how to update their models. On a first-order basis, we can assume for now that the outcome of
such information sharing can be approximated by a weighted linear combination of the agent u’s
own assessment and the predictions from other neighbors. The weights can be either fixed or time-
varying, e.g., based on the trust level of neighbors. This leads to two natural models, DeGroot (1974)
and Friedkin & Johnsen (1990), originally proposed in modeling opinion dynamics in social network.
In DeGroot model, each agent’s prediction is a simple weighted linear combination of neighbors’
predictions. When the weight coefficients are fixed (or when the updates are frequently enough for
time-varying weights), all agents converge to global consensus. In FJ model, each agent incorporates
in the update step a vector of personal assessment (which can be guided by the difference of local
data distribution). The model still converges, and each agent arrives at possibly different predictions,
reflecting adaptation to individual local data distributions.
The generic framework captures how a group of networked agents build their respective models
collectively. When new training data is introduced to one agent in the system, the other agents
indirectly receive the benefit of it. Therefore it is an interesting question to analyze the collective
benefit and also ask the optimization question of where to inject new training data to maximize the
collective benefit. This is the research question we focus on in this paper.
1.1 Related Work
Decentralized learning Training a single high-quality global model using decentralized data and
computationhasbeenstudiedextensivelyindecentralizedoptimization(e.g.,forkernelmethodsColin
et al. (2016), PCA Fellus et al. (2015), stochastic gradient descent Blot et al. (2016), multi-armed
bandit Lazarsfeld & Alistarh (2023) and generalized linear models He et al. (2018)). Federated learn-
ing Konečný et al. (2015, 2016a,b); McMahan et al. (2017); Krishnan et al. (2024) uses a client-server
architecture and considers multiple local models, trained using respective local data, with model pa-
rametersaggregatedandsharedthroughacentralglobalmodel. GossiplearningOrmándietal.(2013);
Heetal.(2018);Hegedűsetal.(2019,2016);Giaretta&Girdzijauskas(2019),ontheotherhand,does
not assume a central node. Instead, each node updates its own local parameters via training and then
its updated parameters are shared by information exchange with other nodes in the network. This
setting removes the single point of failure in the system and thus is more robust and scalable, without
compromised performance Hegedűs et al. (2016, 2021). These gossip learning protocols consider the
exchange of local models (or crucial parameters such as local gradients) directly. This requires that
all agents participating in gossip learning use the same type of models, which is a limitation. It is also
known that models or gradients can reveal knowledge of the training data (thus raising concerns to
data privacy, see a recent survey here Zhang et al. (2023)).
Social learning The study of learning and decision making in a social network has been studied
for longer than a decade. In these works, agents predict the status of the world, and based on their
prediction they take an action to maximize a utility function. In a social setting these decisions
2are not made in a void, as each agent observes the prediction of her neighbors or their actions, and
henceforth updates her prediction. These models are vastly studied by economists who are interested
inunderstandingwhethertheagents’decisionsconvergetothesamevalue(consensus),howfastisthe
rate of convergence, whether an equilibrium exists, and if the consensus leads agents to an optimal
decision (learning) Acemoglu et al. (2011); Arieli et al. (2021); Golub & Jackson (2010); Golub &
Sadler (2016); Rahimian & Jadbabaie (2017); Hązła et al. (2019); Eckles et al. (2019); Bindel et al.
(2015).
Given a social network, various works tackle optimization problems in which an algorithm makes
minimal changes in the network to maximize the improvement of a desirable property. For instance,
various works consider the problem of maximizing information diffusion by seeding information in a
number of selected source vertices Kempe et al. (2003); Seeman & Singer (2013); Eckles et al. (2019);
Garimella et al. (2017) or by adding links Borgs et al. (2014); D’Angelo et al. (2019). Some works
optimally insert links into a network to maximize the information flow between two groups of nodes
Cinus et al. (2023); Zhu et al. (2021); Adriaens et al. (2023); Haddadan et al. (2021, 2022); Santos
et al. (2021), and others optimaly alter innate opinion of users in the FJ model to reduce polarization
or disagreements Tsioutsiouliklis et al. (2022); Abebe et al. (2018); Musco et al. (2018).
Our work bridges the above lines of work. We study a framework in which agents are performing
learningtasksandexchangetheirpredictionsuntileachmakesafinaldecision. Unlikepriordecentral-
ized learning works, our agents do not necessarily use the same model nor they share any parameters,
they solely exchange their predictions. In this sense, our framework falls into the context of social
learning. However, instead of studying problems such as existence of consensus or convergence rates,
we focus on the problem of optimally injecting information to a selected subset of agents to improve
the overall betterness in the network. Another difference with social learning framework is that we do
notconsideronefixedmodelofinformationexchange,incontrast,weassumeagenerallinearmodelfor
information exchange. Therefore, our methods are applicable to any linear model whether it describes
usersofasocialnetwork, eachevaluatingthetruthfulnessofanonlinecontent, orwhetheritdescribes
intelligent systems in which agents cooperate for a classification task.
1.2 Summary of Contributions
Motivated by prior works on decentralized and social learning, we consider a new framework called
cooperative learning in a social setting. In this framework, we consider the problem of optimally
selectingk agentsandimprovingtheirinnatepredictionstomaximizetheoverallnetworkimprovement.
We consider both an aggregate objective function and an egalitarian one, and assume different levels
of access to the model’s parameters which are (1) the joint probability distribution of the classifiers
formingagents’innatepredictions,denotedbyπ,and(2)theexpressedsocialinfluencematrix,denoted
by W¯.
1. Weprovideapolynomialtimealgorithmfortheaggregateimprovementproblem. Thisalgorithm
uses only the innate error rates and W¯, and it does not need any additional knowledge of π; see
section 4.1.
2. We show that solving the egalitarian improvement problem is hard: it is NP-hard to solve it
exactly even if both parameters are entirely known. We also show that if W¯ and only the innate
errorratesareavailable,withoutanyfurtherassumptionevenfindinganapproximationsolution
is hard; see theorems A.3 and A.4 .
3. Weprovidetwoapproximationalgorithmsfortheegalitarianimprovementproblem. Thefirstal-
gorithm,EgalAlg isagreedyalgorithmandneedsfullaccesstoπ. Thesecondone,EgalAlg(appx),
approximates the greedy choice and only needs access to the innate error rates, but it assume
that the innate predictions are pairwise independent. We show that with some modifications
EgalAlg(appx)works under the assumption that the vertices have group dependency; see sec-
tion 4.2.
4. Wecomparethetwoalgorithmsforegalitarianimprovementbyrunningexperimentsonrealand
synthetic graphs and compare their performance to four benchmark methods. Our experiments
show that by modifying only a few vertices, we succeed in increasing the accuracy of a high
percentage of network’s agents; see Figure 1.
3Figure 1: Comparisonof#modifiednodesforAccuracy>90%ondifferentdataset(lowerisbetter).
Comparison of # modified nodes for Accuracy > 90
100 Rand
Degree
ErrRate
80
DegXErr
Appx
60 Egal
40
20
0
ER PA WS RandW BIO CSKP FB WIKI
Datasets
2 Models and Problem Definition
Consider a set Ω whose elements are labeled as +1 or −1, i.e., there exists a function y : Ω →
{−1,+1} such that for any a ∈ Ω, y(a) ∈ {−1,+1} is the (true) label of a. Consider a set of agents
V ={v ,v ,...,v } who lack access to the true labels. Given a∈Ω, each agent v uses a classifier yˆ
1 2 n i i
to predict the label of a, i.e., we have yˆ ,yˆ ,...,yˆ where for any i, yˆ : Ω → {−1,+1}. The innate
1 2 n i
error rate of each agent v is defined as:
i
err(v )= E [1(yˆ(a)̸=y(a))]= P (yˆ(a)̸=y(a)).
i i i
a∼Ω a∼Ω
We assume that this error is independent of true label. This assumption merely makes our analysis
simpler and without it our results can be generalized with trivial modifications.
These predictions form the innate assessment of the agents, which we denote by z(0)(i,a), for
arbitrary i and a; thus, z(0)(i,a)=yˆ(a). After, agents communicate with each other through a time
i
varying averaging process. At each point of time, each agent v communicates with a subset of other
i
agents N(t)(v ), and her assessment will update as:
i
 
z(t)(i,a)=C i· (cid:88) W i( ,t j)z(t−1)(j,a)+α iyˆ i(a),
vj∈N(t)(vi)
where W(t) denotes the influence of v on v at time t, α is v ’s stubbornness, C is a normalizing
i,j j i i i i
constant and z(t−1)(i,a) and z(t)(i,a) respectively denote v ’s assessment before the tth round of
i
communication and after it.
Formally, given a ∈ Ω, let yˆ(a) = (yˆ (a),yˆ (a),...yˆ (a)) and z(0)(a) = yˆ(a). Assume having a
1 2 n
sequence of n×n matrices (cid:0) W(t)(cid:1)∞ , α=(α ,α ,...,α ) and C(t) =(C(t),C(t),...,C(t)). For any
t=1 1 2 n 1 2 n
t≥1 we have:
(cid:16) (cid:17)
z(t)(a)=C(t)⊙ W(t)z(t−1)(a)+α⊙yˆ(a) , (1)
where ⊙ denotes the Hadamard product which is defined to be the vector (matrix) obtained from the
pairwiseproductoftheelementsintwoothervectors(matrices). 1 Letz∗(a)=(z∗(1,a),z∗(2,a),...,z∗(n,a))
be the vector that the above process converges to i.e.,
z∗(a)= lim z(t)(a) .
t→∞
We call z∗(a) the the expressed prediction vector. We assume that this limit has the following closed
form:
∃W¯ ∈R+n×n s. t. ∀a∈Ω, z∗(a)=W¯yˆ(a)T . (2)
R+ being the set of all non-negative real numbers. We call W¯ the expressed (social) influence matrix.
The above assumption is indeed proven to hold true in many well studied models. To name a few:
1LetA,B∈Rn×m,andC=A⊙B. WehavethatC∈Rn×m andCij =Aij·Bij
4
sedon
deifidom
#DeGroot Model (DeGroot, 1974) Given a row-stochastic matrix W ∈R+n×n, DeGroot Model
evolves as:
z(t) (a)=Wz(t−1) (a), z(0) (a)=yˆ(a),
DeGroot DeGroot DeGroot
It is known that
z∗ (a)=Πyˆ(a) ,
DeGroot
whereΠisablockdiagonalmatrixwithblocksΠ ,Π ,...,Π ,andeachblockcorrespondstoastrongly
1 2 k
connected component of the graph corresponding to W. In each block all rows are identical.
Friedkin–Johnsen (FJ) Model (Friedkin & Johnsen, 1990) Given an arbitrary matrix with
non-negative weights W, for each i∈[n] let C =1/(1+(cid:80) W ). FJ model evolves as follows:
i j∈N(i) i,j
(cid:16) (cid:17)
z(t)(a)=C⊙ Wz(t−1)(a)+yˆ(a) , z(0)(a)=yˆ(a).
FJ FJ FJ
It is known that if W is symmetric the FJ model converges to the following closed form:
z∗ (a)=(I+L)−1yˆ(a),
FJ
where L is the combinatorial Laplacian of the indirected graph corresponding to W and I denotes the
identity matrix.
Both DeGroot and FJ model use a constant matrix W in their evolution. The following shows a
time varying evolution:
Finite time Models Assume a finite sequence of row stochastic matrices W(1),W(2),...,W(T), for
any t > T, let W(t) be the identity matrix and let α be all zeros vector. It is straightforward to see
that the general equation of eq. (1) will converge to
T
z∗ (a)=W¯yˆ(a), W¯ =(cid:89) W(i) .
Finite
i=1
2.1 Statement of Problems
Assumeanytimevaryingaveragingmodelwhichconvergestoacloseformaseq.(2). Thus,foragiven
a∈Ω and v ∈V the expressed prediction of v on a is equal to
i i
n
z∗(i,a)=(cid:88) W¯ yˆ (a) .
ij j
j=1
Note that the value of z∗(i,a) is a function of the expressed social influence matrix W¯ as well as the
quality of all agents’ classifiers which is formulated in the joint probability distribution of yˆ. If the
true label y(a) equals +1, the positive values of z∗(i,a) are preferable, otherwise negative values of
z∗(i,a) are better. In other words, we would like y(a) and z∗(i,a) to have the same sign. We define
Z(i,a):V ×Ω→[−1,1] as follows:
Z(i,a)=y(a)·z∗(i,a) .
ThelargervaluesforZ(i,a)correspondtothefactthatagentv makesagoodpredictiononanobject
i
a. If Z(i,a)<0 we consider this prediction faulty.
Improving quality of selected classifiers Assume that we have a tool to improve the quality of
classifiers. Formally, let φ∈(0,1] be a given constant. For any arbitrary agent v we may improve yˆ
i i
to y˜ :Ω→[0,1] as follows:
i
∀a∈Ω, y˜(a)=(1−φ)yˆ(a)+φy(a) . (3)
i i
We would like to improve the quality of a selected subset of agents’ classifiers (innate predictions) to
maximize the overall quality of expressed predictions among all agents. Formally we are interested in
selectingasubsetS ofk agents,i.e.,S ⊆V,|S|=k andimprovethequalityoftheclassifierasfollows:
(cid:40)
(1−φ)yˆ(a)+φy(a) if v ∈S
∀a∈Ω, y˜(a)= i i (4)
i yˆ(a) if v ∈/ S
i i
5Let
z∗
(i,a)=(cid:88)n
W¯ y˜ (a) & Z (i,a)=y(a)·z∗ (i,a) .
new ij j new new
j=1
In the first problem that we study, S is selected to maximize an aggregate objective function:
(cid:34) n (cid:35)
G(agg) (S)≜ E (cid:88) Z (i,a)−Z(i,a) (5)
new
a∼Ω
i=1
The above objective function is great, but it has the shortcoming of any other aggregate objective
function: it is possible that one agent benefits enormously from it at the cost of many other agents
getting extremely little.
Therefore,wealsostudythefollowingegalitarian objectivefunctioninwhichwecounttheexpected
number of agents whose faulty predictions will improve.
(cid:34) n (cid:35)
G(egal) (S)≜ E (cid:88) 1(Z(i,a)<0∧Z(i,a)<Z (i,a)) .
new
a∼Ω
i=1
We are now ready to formally state the problems.
Problem 1 (Aggregate improvement through improving k selected agents). What is an optimal way
to select a subset S ⊆ V and update their innate predictions as eq. (4) to maximize the following
objective function:
OPT(agg) = max G(agg) (S) .
S⊆V;|S|=k
Problem 2 (Egalitarian improvement through improving k selected agents). What is an optimal way
to select a subset S ⊆ V and update their innate predictions as eq. (4) to maximize the following
objective function:
OPT(egal) = max G(egal) (S) .
S⊆V;|S|=k
The above process has two main parameters: a joint probability distribution π :Ω×{−1,+1}V →
[0,1], where for any a ∈ Ω and ⃗b ∈ {−1,+1}n, π(a,⃗b) = P(∧n yˆ(a) = b ) as well as W¯ which is
i=1 i i
the expressed influence matrix. While in most applications W¯ is either available in closed form (e.g.,
for DeGroot, FJ or finite models) or it can be approximated using iterative methods, our access to
π depends on assumptions which may vary depending on our application. In fact, we present our
algorithms assuming different access levels to the joint probability distribution π.
3 Summary of Results
In this section, we present a summary of our main results. Let us first list the assumptions we make
on the access level to π and W¯:
Assumption 3.1 (Best scenario). Assume having complete knowledge of π.
The above assumption is reasonable if Ω is a small finite set. For instance in cases where Ω can be
partitioned to a few types and the agents make the same predictions on any element of the same type,
e.g., see DeMarzo et al. (2003); Hązła et al. (2023); Gaitonde et al. (2021)
Clearly, it is possible that the above assumption does not hold true. However, the algorithm needs
to have some knowledge of the probability distribution of innate predictions.
Assumption 3.2 (some knowledge of π). Assume having some knowledge of classifiers’ depen-
dence/independence and the innate error rates.
Assumption 3.3 (minimum knowledge of π). Assume having only knowledge of innate error rates
{err(v )} .
i vi∈V
6The summary of our main results is that problem 1 is easy, i.e., we show an exact polynomial time
algorithm for it assuming minimum knowledge of π. On the other hand, we show that problem 2 is
hard, i.e., we show that exactly solving it is NP-complete even assuming full knowledge of π. Note
thatthishardnessalsoholdsforthecasesinwhichwehavelessknowledgeofπ. Later,weshowgreedy
algorithms for approximately solving it under different assumptions.
Initially, in all of our results we assume access to the closed form of W¯. We then show that the
guarantees still hold with a slight change when an approximation of W¯ is given.
Assumption 3.4 (knowledge to an approximation of W¯). Assume having knowledge of W(cid:99)¯ such that
(cid:12) (cid:12)
(cid:12)W(cid:99)¯ −W¯(cid:12) ≤ϵ ,
(cid:12) (cid:12)
1
where |·| is the ℓ norm and ϵ a precision parameter.
1 1
3.1 Optimizing the aggregate objective function
Theorem3.5. Thereisanalgorithmwithrun-timecomplexityΘ(cid:0) n2(cid:1) whichgivenW¯ and{err(v )}n
i i=1
as input parameters outputs S such that G(agg) (S)=OPT(agg).
Remark 3.6. Let ALG be the algorithm whose performance guarantees are presented in theorem 3.5.
Let S be the output of ALG when W¯ is given to it as input parameter, and let S′ be the output if W(cid:99)¯
is given. We have:
G(egal) (S′)≥G(egal)
(S)−2kϵ .
We present this algorithm in section 4.1 and appendix A.1.
3.2 Optimizing the egalitarian objective function
We now present our results about Problem 2.
We call a matrix with no negative entry non-negative. In DeGroot model if W is non-negative,
W¯ is also non-negative and in FJ model if W is non-negative and symmetric, W¯ is also non-negative
(Chebotarev & Shamis, 2006) .
In this section we assume that W¯ is non-negative.
Theorem 3.7. Under assumption 3.1 and assuming |Ω| is polynomial in n , Problem 2 is NP-hard.
SinceProblem2isNP-hard,weconcentrateonfindinganapproximationalgorithmforitindifferent
scenarios.
Approximate solution with full access to π. Assume that Ω is finite and for any a ∈ Ω and
b∈{−1,+1}n we can evaluate the probability of the event (cid:86)n yˆ(a)=b(i).
i=1 i
Theorem 3.8. There is a greedy algorithm with runtime Θ(cid:0) |Ω|n2k(cid:1) which by receiving π and W¯ as
input parameters outputs S satisfying
G(egal) (S)≥(1−1/e)OPT(egal).
A pseudocode of our algorithm, EgalAlg is presented in appendix A.3, an overview of main ideas
is presented section 4.2. Note that the runtime of EgalAlg grows linearly in |Ω|. Later, we present
EgalAlg(appx)whose complexity does not grow with |Ω| (see section 4.2). Therefore, even if π is fully
known, by employing EgalAlg(appx), we may prefer to suffice to a lower quality approximation to gain
better time complexity.
7Approximate solution with minimum information Whilethepreviousresultshowsaconstant
approximation, the following theorem shows that by only having the innate error rates {err(v )}n
j j=1
and W¯ we are not able to achieve any good approximation.
Theorem 3.9. Any solution to problem 2 which only uses W¯ and innate error rates {err(v )}n
j j=1
makes an error which can be as large as Ω(n).
We restate and prove the above theorem in theorem A.4.
Motivated by the above results, we now present our results when more knowledge about the clas-
sifiers are available. For instance, in addition to knowing the error rates we assume that the classifiers
are pairwise independent.
Using these assumptions we design EgalAlg(appx) and show theoretical guarantees for its perfor-
mance.
Approximate solution assuming independence. Assumethattheclassifiers{yˆ} arepair-
i vi∈V
wise independent. We have:
Theorem 3.10. There is a greedy algorithm, EgalAlg(appx), with run-time Θ(n3k) which by receiving
{err(v )} and W¯ as input parameters outputs S satisfying
i vi∈V
G(egal) (S)≥[(1−1/e)−∆ind]·OPT(egal) ,
where ∆ind is a parameter depending on the network. If the network is nicely structured ∆ind =o(1);
see section 4.2.1 .
We generalize the assumption of pairwise independence to group dependence as follows:
Approximate solution assuming group dependence. Assume that some agents belong to
opposinggroupsRandB andsomeagentsarecolorless; theyareinW. Theclassifiersoftheagentsin
W are independent, and the classifiers of R and B agents have positive intra-correlation and negative
inter-correlationasdescribedindefinition4.7. Thismodeldescribesasituationwhenhaveaclassifica-
tiontaskthatcanbeinfluencedbyanexogenousfactor,e.g,theirpositionorpoliticalleaning. Clearly
by setting V =W we will have the previous model. In this case we have:
Theorem 3.11. There is a greedy algorithm, EgalAlg(appx), with run-time Θ(n3k) which by receiving
individual and group error rates and W¯ as input parameters outputs S satisfying
G(egal) (S)≥[(1−1/e)−∆gr]·OPT(egal) ,
where ∆gr ≥∆ind is a parameter depending on the network and the dominance of colors R and B on
other agents. Not surprisingly, ∆gr becomes closer to ∆ind as the number of colorless agents increases.
If the network is nicely structured and nicely colored ∆gr =o(1); See section 4.2.2 .
The following remark holds ture both under pairwise Independence and group dependency:
Remark 3.12. Let S be the output of EgalAlg(appx)when W¯ is given to it as input parameter, and let
S′ be the output if W(cid:99)¯ is given. We have:
G(egal) (S′)≥G(egal)
(S)(1−8kϵ) .
4 Algorithms
In this section we present our algorithms. All of the algorithms are greedy. We provide an exact
solution for problem 1 in section 4.1. In section 4.2, because of the NP-harness of problem 2, we
present a constant approximation algorithm for it; we call this algorithm EgalAlg . We then present
EgalAlg(appx)whichhasalowertimecomplexitybutworstapproximationguaranteesassumingpairwise
independence of agents. In this case, our approximation ratio depends on the network structure. In
section 4.2.2, we modify EgalAlg(appx) so that it works under a milder assumption formalized as group
dependency.
Pseudocodes for our egalitarian algorithms are presented in appendix A.3
84.1 The aggregate objective function
For any vertex v let’s define the influence score and its approximation by Inf(v )=(cid:80)n W¯ err(v ) .
j j i=1 ij i
The following lemma is proven in appendix A.1.
(cid:80)
Lemma 4.1. Let U ={u ,u ,...,u } be top-k vertices with highest value of Inf(u ). We have
1 2 k uj∈U j
that: G(agg) (U)=OPT(agg) .
Proof of Theorem 3.5 and Remark 3.6 With the above lemma, we design an algorithm that
for all v s calculates their influence score, and outputs the top-k. The complexity of such algorithm is
j
Θ(n2+nlogn+k)=Θ(n2). In appendix A.1 we also prove Remark 3.6.
4.2 The egalitarian objective function
Optimizing the egalitarian function is NP-hard (See theorem A.3). We show that G(egal) :2V →[0,n]
is monotonic and sub-modular (See lemmas A.5 and A.6). Thus, a greedy algorithm will provides a
(1−1/e) approximation Nemhauser & Wolsey (1978).
Wenowconcentrateonobtainingthegreedychoice. Formally, wedefinethefunctiongr(S):2V →
V as follows: gr(S)=argmax G(egal) (S∪{u})−G(egal) (S) . (6)
u∈V
The following lemma is proven in appendix A.3.1:
Lemma 4.2. For any S ⊆V we have:
(cid:88)
gr(S)=argmax ∆G (S,u) , (7)
i
u∈V
i=1:n
W¯ iu̸=0
where ∆G (S,u) is defined to be2
i
   
P  Z(i,a)≤0∧  (cid:94) y(a)=yˆ j(a) ∧y(a)̸=yˆ u(a) 
a∼Ω   
vj∈S
W¯ ji̸=0
Proof of theorem 3.8 Our proposed algorithm, EgalAlg starts with S = ∅. Iteratively, gr(S) is
added to S until |S| = k. Assume that Ω is finite and we have access to π. Using lemma 4.2 we
obtain the greedy choice as follows: for any a ∈ Ω and v ∈ V, we evaluate the validity of the event
i
(cid:32) (cid:33)
(cid:86) y(a)=yˆ (a) ∧y(a)̸=yˆ (a). If this event is valid, we calculate Z(i,a) and verify Z(i,a)<0
vj∈S j u
W¯ ji̸=0
which takes n steps. We find best u by using eq. (7) and iterating over all choices of i∈V and a∈Ω.
The total runtime for k iterations is Θ(|Ω|n2k).
4.2.1 Independent classifiers
In this section we consider the case where the classifiers {yˆ} are pairwise independent which
i vi∈V
falls into the scenario in which we have some knowledge of π (Assumption 3.2). In this case we may
estimate the greedy choice as a function of {err(v )}n and W¯.
i i=1
Let’sstatethemainresultofthissectionandthenwepresentthestepsthatleadustotheselection
of the greedy choice:
Theorem 4.3. Let S be the output of a greedy algorithm which starts by taking S =∅ and for k steps
keeps updating S to S∪{g} where
(cid:88)
g =argmax ∆(cid:100)G i(S,u) ,
u
i=1:n
W¯ iu̸=0
2Weuse∧and∨todenoterespectivelythelogicaloperationsconjunctionanddisjunctionwhichare“and” and“or”.
9and ∆(cid:100)G i(S,u) is defined in lemma 4.6, we have:
G(egal) (S)≥[(1−1/e)−∆ind]·OPT(egal) ,
with ∆ind =Θ(|A|) and A is the set of ambiguous vertices.
Ambiguous vertices Consider the partitioning of V with V+ as low error vertices and V− as high
error vertices:
V+ ={v |err(v )≤1/2}& V− ={v |err(v )>1/2}
j j j j
with respect to this partition we define the following vectors whose elements are in [0,1]:
E+ =(1−2err(v )) & E− =(2err(v )−1)
j vj∈V+ j vj∈V−
For any arbitrary vertex v ∈ V, low error and high error vertices contribute in the value of Z(i,a)
i
through the following coefficient vectors:
W¯+ =(W¯ ) & W¯− =(W¯ )
i ij vj∈V+ i ij vj∈V−
The ambiguous vertices are those who are not dominated by neither V+ or V−. Formally,
Definition 4.4. [Ambiguous vertices]Let W¯ =(W¯ ,W¯ ,...,W¯ ), |·| denote the ℓ norm and ⟨·,·⟩
i i1 i2 in 2 2
dot product. We call a vertex v ∈V ambiguous if it satisfies:
i
(cid:12) (cid:12)
(cid:12)⟨W¯+,E+⟩ ⟨W¯−,E−⟩(cid:12)
(cid:112)
(cid:12) (cid:12)
(cid:12)
(cid:12) (cid:12)Wi ¯ i(cid:12)
(cid:12)
2
− (cid:12) (cid:12)Wi ¯ i(cid:12)
(cid:12)
2
(cid:12) (cid:12) (cid:12)≤4 logn .
A network is nicely structured if it has no ambiguous vertex.
If a vertex is non-ambiguous we can estimate the gain associated to it very precisely:
Lemma 4.5. Let ∆G i(S,u) and ∆(cid:100)G i(S,u) be as defined respectively as in lemma 4.2 and lemma 4.6.
If a vertex is non-ambiguous we have:
(cid:12) (cid:12)
(cid:12) (cid:12)∆G i(S,u)−∆(cid:100)G i(S,u)(cid:12) (cid:12)≤o(n−1) .
We now present the following lemma related to the approximation of greedy choice. All the proofs
and details are presented in appendix A.4.
Lemma 4.6. Let ∆G i(S,u) be as lemma 4.2. Let ∆(cid:100)G i(S,u):2V ×V →[0,1] be defined as follows:
(cid:89)
∆(cid:100)G i(S,u)≜1(Ψ i(S,u)<0)err(u) (1−err(v j)) .
vj∈S
W¯ ij̸=0
We have: (cid:32) (cid:33)
(cid:12) (cid:12) Ψ (S,u)2
(cid:12) (cid:12)∆(cid:100)G i(S,u)−∆G i(S,u)(cid:12) (cid:12)≤exp − 4(cid:80)i
n W¯2
,
i=1 ij
where
Ψ (S,u)=−W¯ + (cid:88) W¯ + (cid:88) W¯ [1−2err(j)] .
i iu ij ij
vj∈S j=1:n
j̸∈S∪{u}
Proof of theorem 3.10 and remark 3.12 A complete pseudocode of our proposed algorithm,
EgalAlg(appx),ispresentedinappendixA.3(algorithm2). Itiseasytoseethattheruntimeisdominated
byΘ(n3k). Notethatthecorrectnessoftheorem3.10isdirectlyconcludedfromtheorem4.3bysetting
|A|=0. We present the proof of theorem 4.3 and remark 3.12 in appendix A.4.2.
104.2.2 Group dependent classifiers
We now consider a case when agents are either red, blue or none (white). The agents who are red or
blue agent either all follow a group decision, or they independently follow an individual decision. The
group decision of the blue agents is always the opposite of the group decision of red agents.
Definition 4.7. [Group Dependence] Assume that the set of agents V can be partitioned as V =
R∪B∪W. We assume a set of classifiers yˆindv,yˆindv,...,yˆindv : Ω → {−1,+1} which are pairwise
1 2 n
independent. Furthermore, we assume two group classifiers yˆgr,yˆgr :Ω→{−1,+1} which satisfy:
R B
∀a∈Ω, yˆgr(a)̸=yˆgr(a) .
R B
Given a constant ρ∈[0,1], these classifiers construct {yˆ ,yˆ ,...,yˆ } as follows:
1 2 n
With probability ρ the red and blue agents follow their groups’ decision, i.e.,
∀v ∈R, yˆ(a)=yˆgr(a)∧∀v ∈B, yˆ(a)=yˆgr(a)
i i R i i B
And the white agents independently follow their individual decisions, i.e, for all v ∈ W, yˆ(a) =
i i
yˆindv(a) .
i
Alternatively, with probability 1−ρ , all agents independently use their individual classifiers. i.e,
∀v ∈V, yˆ(a)=yˆindv(a) .
i i i
In the above setting we use the following notation: For any v ∈ V we define errindv(v ) =
j j
P(cid:0) yˆindv(a)̸=y(a)(cid:1), and
j
err(R)=P(yˆgr(a)̸=y(a)) & err(B)=P(yˆgr(a)̸=y(a))
R B
It is immediate from the definition that 1−err(B)=err(R).
In this setting, the estimation of ∆G (S,u) is more involved and is presented in section 4.2.2. In
i
this case, our greedy algorithm uses {errindv(v )}n , err(R), err(B) and W¯ or its approximation. The
j j=1
final result follows:
Theorem 4.8. Let S be the output of a greedy algorithm which approximates greedy choice as defined
in lemma A.12. We have:
G(egal) (S)≥[(1−1/e)−∆gr]·OPT(egal) ,
(cid:12) (cid:12)
where ∆gr =Θ(ρ(cid:12)AW(cid:12)+(1−ρ)|A|), A is the set of ambiguous vertices defined before and AW is the
set of W-ambiguous vertices.
W-Ambiguous vertices. As in section 4.2.2, we partition W to low error vertices W+ and high
error vertices W−. Similarly we define EW+, EW− and for any v ∈ V, W¯W+ and W¯W−; for details
i i i
see appendix A.5.4. We define:
Definition 4.9. [ W-Ambiguous vertices ] Let W¯W = (W¯ ) , and |·| be the ℓ norm and ⟨·,·⟩
i ij vj∈W 2 2
be dot product.
We call an agent v ∈V, W-ambiguous if it satisfies
i
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)⟨W¯ i (cid:12) (cid:12)W W¯+ iW,E (cid:12) (cid:12)W
2
+ ⟩ − ⟨W¯ i (cid:12) (cid:12)W W¯− iW,E (cid:12) (cid:12)W
2
− ⟩(cid:12) (cid:12) (cid:12) (cid:12)≤4(cid:112) logn+∆W¯ i ,
(cid:12) (cid:12)
where ∆W¯ =(cid:12)(cid:80) W¯ −(cid:80) W¯ (cid:12) . A network is nicely colored if no vertex is W-ambiguous.
i (cid:12) vj∈R ij vj∈B ij(cid:12)
Proofoftheorem3.11andremark3.12 PseudocodeanddetailsarepresentedinappendicesA.3,
A.5 and A.5.5. Theorem 3.11 can be directly concluded from theorem 4.8 by setting |A|=(cid:12) (cid:12)AW(cid:12) (cid:12)=0.
115 Experiments
Inthissection,weempiricallyvalidatetheeffectivenessofourproposedmethodsforproblem2through
aseriesofmeticulouslydesignedexperiments. WetestouralgorithmsEgalAlgandEgalAlg(appx) (pseu-
docodes in appendix A.3) benchmarked against random selections together with three heuristic meth-
ods: selecting nodes based on degree (Degree), innate error rate (ErrRate), and the product of degree
and error rate (DegXErr).
Synthetic Datasets Synthetic data is generated with three components: a random graph G, a
weight matrix W¯ and initial opinions yˆ. To generate G, we employ Erdős-Rényi model (ER) Erdös
& Rényi (1959), Barabási-Albert model (PA) Barabási & Albert (1999) and Watts-Strogatz model
(WS) Watts & Strogatz (1998). We generate the weight matrix W¯ using the FJ model. Each yˆ(a) is
i
sampled from Bernoulli distribution with a randomly chosen p .
i
Table 1: Comparison of experiments on five methods Egal=EgalAlg, Appx=EgalAlg(appx), Rand=Random
selection.
Datasets
Score Method ER PA WS RandW BIO CSPK FB WIKI
(128) (128) (128) (128) (297) (39) (620) (890)
Rand 0.11 0.88 0.53 0.18 0.80 0.63 0.35 0.48
Degree 0.08 0.96 0.42 0.12 0.78 0.84 0.36 0.49
Acc@ ErrRate 0.22 1.00 0.76 0.47 0.96 0.94 0.53 0.54
k=log(n) DegXErr 0.18 1.00 0.89 0.37 0.96 1.00 0.72 0.78
Appx 0.18 1.00 0.87 0.41 0.94 0.84 0.62 0.64
Egal 0.27 1.00 1.00 0.58 1.00 1.00 0.88 0.96
Rand >100 7 10 34 8 10 94 22
Degree >100 4 17 45 9 4 93 26
#k@ ErrRate 71 2 7 18 3 3 19 13
Acc>90% DegXErr 71 2 6 18 3 3 32 7
Appx 61 1 5 18 3 5 30 15
Egal 55 1 3 12 1 1 9 2
Rand 83 8 16 61 15 14 37 55
Degree 83 5 28 64 14 6 20 54
#k@ ErrRate 46 3 10 31 5 4 14 26
Acc>75% DegXErr 51 3 8 36 4 3 8 16
Appx 47 2 9 35 6 7 11 39
Egal 36 2 4 19 2 2 4 3
Real-World Graphs We also evaluate our methods on four diverse real network datasets Rossi &
Ahmed(2015),BIODuch&Arenas(2005);Baderetal.(2012),CSPKBaderetal.(2013),FBRozem-
berczkietal.(2019),WIKILeskovecetal.(2010). HerewealsoapplyfinitestepFJmodeltoconstruct
weight matrix W¯ and randomly sample yˆ from Bernoulli distributions.
Comparison of Algorithms on Dataset=ER Comparison of Algorithms on Dataset=FB
1.0 1.0
0.8 0.8
0.6 0.6
0.4 Random Selection 0.4 Random Selection
Degree Selection Degree Selection
Error Rate Selection Error Rate Selection
0.2 Degree*Error Selection 0.2 Degree*Error Selection
Greedy Algorithm Approximate Greedy Algorithm Approximate
0.0 Greedy Algorithm 0.0 Greedy Algorithm
0 20 40 60 80 100 0 20 40 60 80 100
k := #selected nodes for intervention k := #selected nodes for intervention
Figure 2: Algorithms performance on ER (top) and WIKI (bottom).
We define our accuracy Acc to be the achieved egalitarian gain, normalized by its upper bound.
For each dataset, we progressively increase k. Obviously, as k increases, the accuracy should increase.
Therefore, we fix the threshold value k =log(n) for different datasets and compare the corresponding
Acc of different methods. We also report the number of modified nodes k required to achieve certain
12
ycaruccA ycaruccAlevels of accuracy. See table 1 for details. Figure 2 shows two of these results on real and synthetic
graphsandmorearepresentedinFigure3. MoredetailsaboutexperimentscanbefoundinappendixB.
Code of our experiments is available through link 3.
From the results we can conclude that, in summary, all six algorithms can be categorized into four
tiers: Tier1={EgalAlg}, Tier2={EgalAlg(appx)}, Tier3={DegXErr, ErrRate}, Tier4={Degree, Rand}.
Weranktheefficiencyofthesemethodsas: Tier1≫Tier2≥Tier3≫Tier4. OurgreedyalgorithmEgalAlg
in general performs best on all datasets. In some datasets the EgalAlg(appx) algorithm outperforms
algorithms in Tier3 & 4 when k is very small, however, the performances of Tier2 & 3 algorithms
quickly become similar as k increases. Tier4 algorithms are always the slowest in improving our
egalitarian objective function. On almost all datasets, our greedy algorithm can achieve more than
80% accuracy within only logn nodes selected to intervene, and it beats all the other baselines. Our
greedy approximation algorithm can achieve more than 70% accuracy. On all datasets, it beats our
two baselines in Tier4 and on some data sets it beats all the baselines of Tier3 & 4.
Conclusion
Givenanetworkinwhichagentscooperativelyperformaclassificationtask,weanalysetheproblemof
optimally choosing k vertices and improving their innate predictions to maximize the overall network
improvement.
Limitations and Future Directions In this paper, our modeling relies on a few simplifications
which may pose limitations in the applicability of the methods, and they may be addressed in future
works:
1. Weassumethatthesocialplanneriscapableofimprovingeveryagent’sinnatepredictionequally
through eq. (3). In reality, this improvement may depend on the agent, i, as well as the data
point, a.
2. Our analyses are valid when the social influence graph has non-negative weights and, in the
current form, they do not generalize to graphs with negative weights, e.g., signed graphs.
We believe that overcoming any of the above limitations would be an interesting extension of our
work, and we propose them as future directions.
Acknowledgements
Xin and Gao would like to acknowledge NSF support through CCF-2118953, CCF-2208663, DMS-
2311064, DMS-2220271, and IIS-2229876.
References
Abebe, R., Kleinberg, J., Parkes, D., and Tsourakakis, C. E. Opinion dynamics with varying sus-
ceptibility to persuasion. In Proceedings of the 24th ACM SIGKDD International Conference on
Knowledge Discovery & Data Mining, pp. 1089–1098, 2018.
Acemoglu, D., Dahleh, M. A., Lobel, I., and Ozdaglar, A. Bayesian learning in social networks. The
Review of Economic Studies, 78(4):1201–1236, 2011.
Adriaens, F., Wang, H., and Gionis, A. Minimizing hitting time between disparate groups with
shortcut edges. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and
Data Mining, KDD ’23, pp. 1–10, 2023.
Arieli, I., Sandomirskiy, F., and Smorodinsky, R. On social networks that support learning. In
Proceedings of the 22nd ACM Conference on Economics and Computation,EC’21,pp.95–96,2021.
Bader,D.A.,Meyerhenke,H.,Sanders,P.,andWagner,D. Graph Partitioning and Graph Clustering.
American Mathematical Society, 2012.
3
https://github.com/jackal092927/social_learning_public
13Bader, D. A., Meyerhenke, H., Sanders, P., and Wagner, D. (eds.). Graph Partitioning and Graph
Clustering, 10th DIMACS Implementation Challenge Workshop, Georgia Institute of Technology,
Atlanta, GA, USA, February 13-14, 2012. Proceedings, volume 588 of Contemporary Mathematics,
2013. American Mathematical Society. ISBN 978-0-8218-9869-7. URL http://dblp.uni-trier.
de/db/conf/dimacs/dimacs2012.html.
Barabási,A.-L.andAlbert,R. Emergenceofscalinginrandomnetworks. Science,286(5439):509–512,
1999.
Bindel, D., Kleinberg, J., and Oren, S. How bad is forming your own opinion? Games and Economic
Behavior, 92:248–265, 2015.
Blot, M., Picard, D., Cord, M., and Thome, N. Gossip training for deep learning. In 9th NIPS
Workshop on Optimization for Machine Learning, November 2016.
Borgs, C., Brautbar, M., Chayes, J., and Lucier, B. Maximizing social influence in nearly optimal
time. In Proceedings of the twenty-fifth annual ACM-SIAM symposium on Discrete algorithms, pp.
946–957. SIAM, 2014.
Chebotarev, P. and Shamis, E. On proximity measures for graph vertices. arXiv math/0602073, 2006.
Cinus, F., Gionis, A., and Bonchi, F. Rebalancing social feed to minimize polarization and disagree-
ment. In Proceedings of the 32nd ACM International Conference on Information and Knowledge
Management, CIKM ’23, pp. 369–378, 2023.
Colin, I., Bellet, A., Salmon, J., and Clémençon, S. Gossip dual averaging for decentralized opti-
mization of pairwise functions. In Balcan, M. F. and Weinberger, K. Q. (eds.), Proceedings of The
33rd International Conference on Machine Learning, volume48ofProceedings of Machine Learning
Research, pp. 1388–1396. PMLR, 2016.
D’Angelo, G., Severini, L., and Velaj, Y. Recommending links through influence maximization. The-
oretical Computer Science, 764:30–41, 2019.
DeGroot, M. H. Reaching a consensus. J. Am. Stat. Assoc., 69(345):118–121, 1974.
DeMarzo, P. M., Vayanos, D., and Zwiebel, J. Persuasion bias, social influence, and unidimensional
opinions. The Quarterly journal of economics, 118(3):909–968, 2003.
Duch, J. and Arenas, A. Community identification using extremal optimization. Physical Review E,
72:027104, 2005.
Eckles, D., Esfandiari, H., Mossel, E., and Rahimian, M. A. Seeding with costly network information.
In Proceedings of the 2019 ACM Conference on Economics and Computation, EC ’19, pp. 421–422,
2019.
Erdös, P. and Rényi, A. On random graphs I. Publicationes Mathematicae Debrecen, 6:290, 1959.
Fellus, J., Picard, D., and Gosselin, P.-H. Asynchronous gossip principal components analysis. Neuro-
computing, 169:262–271, December 2015.
Friedkin, N. E. and Johnsen, E. C. Social influence and opinions. J. Math. Sociol., 15(3-4):193–206,
January 1990.
Gaitonde,J.,Kleinberg,J.,andTardos,É. Polarizationingeometricopiniondynamics. InProceedings
of the 22nd ACM Conference on Economics and Computation, pp. 499–519, July 2021.
Garimella, K., Gionis, A., Parotsidis, N., and Tatti, N. Balancing information exposure in social
networks. In Proceedings of the 31st International Conference on Neural Information Processing
Systems, volume 30, pp. 4666–4674, 2017.
Giaretta, L. and Girdzijauskas, Š. Gossip learning: Off the beaten path. In 2019 IEEE International
Conference on Big Data (Big Data), pp. 1117–1124, December 2019.
14Golub, B. and Jackson, M. O. Naive learning in social networks and the wisdom of crowds. American
Economic Journal: Microeconomics, 2(1):112–149, 2010.
Golub, B. and Sadler, E. Learning in social networks. The Oxford Handbook of the Economics of
Networks, 2016.
Haddadan, S., Menghini, C., Riondato, M., and Upfal, E. RePBubLik: Reducing polarized bubble
radiuswithlinkinsertions. InProceedings of the 14th ACM International Conference on Web Search
and Data Mining, WSDM ’21, pp. 139–147, 2021.
Haddadan,S.,Menghini,C.,Riondato,M.,andUpfal,E. Reducingpolarizationandincreasingdiverse
navigability in graphs by inserting edges and swapping edge weights. Data Mining and Knowledge
Discovery, 36(6):2334–2378, 2022.
Hązła, J., Jin, Y., Mossel, E., and Ramnarayan, G. A geometric model of opinion polarization.
Mathematics of Operations Research, 49(1):251–277, 2023.
He, L., Bian, A., and Jaggi, M. COLA: Decentralized linear learning. In Proceedings of the 32nd
International Conference on Neural Information Processing Systems,NIPS’18,pp.4541–4551,2018.
Hegedűs, I., Berta, Á., Kocsis, L., Benczúr, A. A., and Jelasity, M. Robust decentralized low-rank
matrix decomposition. ACM Trans. Intell. Syst. Technol., 7(4):1–24, May 2016.
Hegedűs, I., Danner, G., and Jelasity, M. Gossip learning as a decentralized alternative to federated
learning. In Distributed Applications and Interoperable Systems, pp. 74–90. Springer International
Publishing, 2019.
Hegedűs, I., Danner, G., and Jelasity, M. Decentralized learning works: An empirical comparison of
gossip learning and federated learning. J. Parallel Distrib. Comput., 148:109–124, February 2021.
Hązła, J., Jadbabaie, A., Mossel, E., and Rahimian, M. A. Reasoning in Bayesian opinion exchange
networks is PSPACE-hard. In Beygelzimer, A. and Hsu, D. (eds.), Proceedings of the Thirty-Second
Conference on Learning Theory, volume 99 of Proceedings of Machine Learning Research, pp. 1614–
1648. PMLR, 25–28 Jun 2019.
Kempe,D.,Kleinberg,J.,andTardos,E. Maximizingthespreadofinfluencethroughasocialnetwork.
In Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining, KDD ’03, pp. 137–146, 2003.
Konečný,J.,McMahan,B.,andRamage,D. Federatedoptimization: Distributedoptimizationbeyond
the datacenter. arXiv 1511.03575, November 2015.
Konečný, J., Brendan McMahan, H., Ramage, D., and Richtárik, P. Federated optimization: Dis-
tributed machine learning for on-device intelligence. arXiv 1610.02527, October 2016a.
Konečný, J., BrendanMcMahan, H., Yu, F.X., Richtárik, P., Suresh, A.T., andBacon, D. Federated
learning: Strategies for improving communication efficiency. arXiv 1610.05492, October 2016b.
Krishnan, S., Jose Anand, A., Srinivasan, R., Kavitha, R., and Suresh, S. Handbook on Federated
Learning: Advances, Applications and Opportunities. CRC Press, January 2024.
Lazarsfeld, J. and Alistarh, D. The power of populations in decentralized learning dynamics. arXiv
2306.08670, June 2023.
Leskovec, J., Huttenlocher, D., and Kleinberg, J. Signed networks in social media. In Proceedings of
the SIGCHI Conference on Human Factors in Computing Systems, pp. 1361–1370. ACM, 2010.
McMahan, B., Moore, E., Ramage, D., Hampson, S., and Arcas, B. A. y. Communication-Efficient
LearningofDeepNetworksfromDecentralizedData. InSingh,A.andZhu,J.(eds.),Proceedings of
the 20th International Conference on Artificial Intelligence and Statistics, volume 54 of Proceedings
of Machine Learning Research, pp. 1273–1282. PMLR, 2017.
15Musco, C., Musco, C., and Tsourakakis, C. E. Minimizing polarization and disagreement in social
networks. In Proceedings of the 2018 World Wide Web Conference, pp. 369–378, 2018.
Nemhauser,G.L.andWolsey,L.A. Bestalgorithmsforapproximatingthemaximumofasubmodular
set function. Mathematics of Operations Research, 3(3):177–188, 1978.
Ormándi, R., Hegedűs, I., and Jelasity, M. Gossip learning with linear models on fully distributed
data. Concurr. Comput., 25(4):556–571, February 2013.
Rahimian, M. A. and Jadbabaie, A. Bayesian learning without recall. IEEE Transactions on Signal
and Information Processing over Networks, 3(3):592–606, 2017.
Rossi, R. A. and Ahmed, N. K. The network data repository with interactive graph analytics and
visualization. In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, pp.
4292–4293, 2015.
Rozemberczki, B., Davies, R., Sarkar, R., and Sutton, C. GEMSEC: Graph embedding with self
clustering. In Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social
Networks Analysis and Mining, pp. 65–72. ACM, 2019.
Santos, F. P., Lelkes, Y., and Levin, S. A. Link recommendation algorithms and dynamics of po-
larization in online social networks. Proceedings of the National Academy of Sciences, 118(50):
e2102141118, 2021.
Seeman,L.andSinger,Y. Adaptiveseedinginsocialnetworks. In2013 IEEE 54th Annual Symposium
on Foundations of Computer Science, pp. 459–468, 2013.
Tsioutsiouliklis,S.,Pitoura,E.,Semertzidis,K.,andTsaparas,P. LinkrecommendationsforPageRank
fairness. In Proceedings of the ACM Web Conference 2022, pp. 3541–3551, 2022.
Watts, D. J. and Strogatz, S. H. Collective dynamics of ‘small-world’ networks. Nature, 393(6684):
440–442, 1998.
Zhang, R., Guo, S., Wang, J., Xie, X., and Tao, D. A survey on gradient inversion: Attacks, defenses
andfuturedirections. InProceedings of the Thirty-First International Joint Conference on Artificial
Intelligence, pp. 5678–5685, July 2023.
Zhu, L., Bao, Q., and Zhang, Z. Minimizing polarization and disagreement in social networks via link
recommendation. Advances in Neural Information Processing Systems, 34:2072–2084, 2021.
16A Additional material: proofs and details of algorithms
Let Ω+ ={a∈Ω|y(a)=+1} and Ω− ={a∈Ω|y(a)=−1}. The following are some useful lemmas
that we will use throughout:
Lemma A.1. Let v ∈V be an arbitrary agent. We have:
j
E [yˆ(a)]=1−2err(v ), E [yˆ(a)]=2err(v )−1 .
i i i i
a∼Ω+ a∼Ω−
Proof.
E [yˆ(a)]=+1·P(yˆ(a)=+1)−1·P(yˆ(a)=−1)
i i i
a∼Ω+
=+1·P(yˆ(a)=y(a))−1·P(yˆ(a)̸=y(a))
i i
=(1−err(v ))−err(v )
i i
=1−2err(v ) .
i
Similarly we have that
E [yˆ(a)]=+1·P(yˆ(a)̸=y(a))−1·P(yˆ(a)=y(a))=err(v )−(1−err(v ))=2err(v )−1 .
i i i i i i
a∼Ω−
Proposition A.2. Given any non-negative W¯ used in equation (2) and S on which we improve yˆ to
j
y˜ , we have
j
∀v ∈V, Z (i,a)>Z(i,a) ⇐⇒ ∃v ∈S,y(a)yˆ (a)=−1∧W¯ >0 .
i new j j ij
Proof. By looking at eq. (4), it is evident that if yˆ (a)=y(a) then y˜ (a)=yˆ (a). Thus, improving v
j j j j
will only improve prediction on a ∈ Ω iff yˆ (a) ̸= y(a) or equivalently yˆ (a)y(a) = −1. Note that for
j j
anyotherv ∈V, y˜ (a)appearsinZ (i,a)withcoefficientW¯ . Sincethematrixisnon-negativewe
i j new ij
either have Z (i,a)=Z(i,a) or Z (i,a)>Z(i,a). Therefore, we will have Z (i,a)>Z(i,a) iff
new new new
yˆ (a)y(a)=−1 and W¯ ̸=0.
j ij
A.1 Missing proofs from section 4.1: Analysis of aggregate optimization
Proof of lemma 4.1. Let Ω+ ={a∈Ω|y(a)=+1} and Ω− ={a∈Ω|y(a)=−1}. We have that:
(cid:34) n (cid:35)
G(agg) (S)= E (cid:88) Z (i,a)−Z(i,a)
new
a∼Ω
i=1
(cid:34) n (cid:35) (cid:34) n (cid:35)
(cid:88) (cid:88)
= E z∗ (i,a)−z∗(i,a) P(a∈Ω+)+ E z∗(i,a)−z∗ (i,a) P(a∈Ω−)
new new
a∼Ω+ a∼Ω−
i=1 i=1
n (cid:18) (cid:19)
(cid:88)
= E [z∗ (i,a)−z∗(i,a)]P(a∈Ω+)+ E [z∗(i,a)−z∗ (i,a)]P(a∈Ω−) .
new new
a∼Ω+ a∼Ω−
i=1
(8)
Note that:
n
z∗(i,a)−z∗ (i,a)=(cid:88) W¯ (yˆ (a)−y˜ (a))=(cid:88) W¯ (yˆ (a)−y˜ (a))=φ(cid:88) W¯ [yˆ (a)−y(a)]
new ij j j ij j j ij j
j=1 j∈S j∈S
Thus,
(cid:40) φ(cid:80) W¯ [yˆ (a)+1] if a∈Ω−
z∗(i,a)−z∗ (i,a)= j∈S ij j
new φ(cid:80) W¯ [yˆ (a)−1] if a∈Ω+
j∈S ij j
17Using linearity of expectation and plugging in lemma A.1 we have:
(cid:40) φ(cid:80) W¯ [2err(0)(v )−1+1] if a∈Ω−
E[z∗(i,a)−z∗ (i,a)]= j∈S ij i
new φ(cid:80) W¯ [1−2err(0)(v )−1] if a∈Ω+
j∈S ij i
Therefore,
E [z∗(i,a)−z∗ (i,a)]=2φ err(0)(v )(cid:88) W¯ = E [z∗ (i,a)−z∗(i,a)] .
new i ij new
a∼Ω− a∼Ω+
j∈S
Plugging in the above in eq. (8) we obtain:
n n
G(agg) (S)=2φ(cid:88)(cid:88) W¯ err(0)(v )[P(a∈Ω+)+P(a∈Ω−)]=2φ(cid:88)(cid:88) W¯ err(0)(v ) .
ij i ij i
j∈Si=1 j∈Si=1
This means by picking k vertices with highest values of Inf(j)=(cid:80)n W¯ err(0)(v ) we will obtain
i=1 ij i
the optimal solution for problem 1. In order to find these values, we first need to find all the values of
Inf(j) for all j ∈V. Which takes Θ(n2) number of steps. Then we have to find top k elements among
these values, which will take Θ(kn).
Proof of remark 3.6. Let I(cid:99)nf(j)=(cid:80)n i=1W(cid:99)¯ i,jerr(0)(v j). For all j, we have that
(cid:12)
(cid:12)
(cid:12)Inf(j)−I(cid:99)nf(j)(cid:12)
(cid:12)
(cid:12)=(cid:88)n (cid:12)
(cid:12) (cid:12)W¯
ij
−W(cid:99)¯
ij(cid:12)
(cid:12) (cid:12)err(0)(v
j)≤(cid:88)n (cid:12)
(cid:12) (cid:12)W¯
ij
−W(cid:99)¯
ij(cid:12)
(cid:12)
(cid:12)
i=1 i=1
Note that the right-hand side is the ℓ norm of the jth column of W¯ −W(cid:99)¯, let’s denote the jth column
1
of these matrix respectively by W¯ and W(cid:99)¯ . Since the ℓ norm of a matrix is defined the be the
·j ·j 1
maximum over ℓ norm of all of its columns we have that
1
(cid:12) (cid:12) (cid:12) (cid:12)
∀j (cid:12) (cid:12)Inf(j)−I(cid:99)nf(j)(cid:12) (cid:12)≤(cid:12) (cid:12)W¯
·j
−W(cid:99)¯ ·j(cid:12)
(cid:12)
≤ϵ .
1
In the previous theorem we showed that
(agg) (cid:88)
G (S)=2φ Inf(j) .
j∈S
Since size of S is k and φ≤1 the total error is bounded by 2kϵ .
A.2 Missing proof from section 4.2: Analysis of egalitarian optimization
A.2.1 Hardness Results
Theorem A.3. There is a polynomial time reduction from the set cover problem to problem 1.
Proof. Consider an arbitrary S ⊆ V. We use proposition A.2 to simplify G(egal) (S). For any v ∈ V,
i
we define: Ω ≜ {a ∈ Ω | y(a)yˆ (a) = −1}. For any a ∈ Ω, we denote its probability by µ . For a
vj j a
given S we have:
(cid:34) n (cid:35)
G(egal) (S)= E (cid:88) 1(Z(i,a)<0∧Z(i,a)<Z (i,a))
new
a∼Ω
i=1
 
n
= (cid:88)(cid:88) µ a1(Z(i,a)<0)·1 (cid:95) (cid:0) a∈Ω vj ∧W¯ ij >0(cid:1) 
a∈Ωi=1 vj∈S
 
= (cid:88) µ a1(Z(i,a)<0)·1 (cid:95) (cid:0) a∈Ω vj ∧W¯ ij >0(cid:1)  (9)
(a,vi)∈Ω×V vj∈S
18Using the above simplification, we now construct the following instance of the weighted set cover
problem:
Consider a bipartite graph where one part is U = {(v ,a) ∈ V ×Ω | Z(i,a) < 0} and the other
i
part is S = V. There is an edge between any v ∈ V to a pair (v ,a) ∈ U iff a ∈ Ω ∧W¯ > 0 and
j i vj ij
the weight of each pair (a,v ) is µ . Under the new definition eq. (9) is equivalent to
i a
 
G(egal) (S)= (cid:88) µ a·1 (cid:95) (cid:0) a∈Ω vj ∧W¯ ij >0(cid:1) 
(a,vi)∈U vj∈S
Note that
 
1 (cid:95) (cid:0) a∈Ω
vj
∧W¯
ij
>0(cid:1) =1 ⇐⇒ there is an edge between v
j
and (a,v i) and v
j
∈S .
vj∈S
The reduction is polynomial in sizes of Ω and V. Since we assume that Ω has polynomial size, it is a
polynomial time reduction. This completes the proof.
Proof of theorem 3.7. The proof follows from theorem A.3 and the fact that set cover is NP-hard.
TheoremA.4. Considerproblem2andassumek =1. Thereexisttwonetworkswiththesamenumber
of agents, same W¯ and same error rates {err(v )}n . In these network, only the joint probability
j j=1
distributions π and π are different. There are subsets V ,V ⊆ V such that V ∩V = ∅. In the
1 2 1 2 1 2
(egal) (egal)
first network we have that for any u ∈ V ,G (u) = Θ(n) and for any u ∈/ V we have G (u) =
1 1
(egal)
Θ(1). In the second network for any u ∈ V will have G (u) = Θ(n) and any u ∈/ V will satisfy
2 2
(egal)
G (u)=Θ(1).
Proof. Let V ={u ,u ,u ,u }∪{v ,v ,v ,...,v }. We define W¯ to be the following matrix:
1 2 3 4 1 2 3 2n
W¯ =W¯ =1 for all j =1:n , and W¯ =W¯ =1 for all j =n+1:2n.
Fou r1 e,v aj ch veru t2 e, xvj in V we also have a self loopu o3 f,v wj eightu 14 ,,v ij .e., W¯ =W¯ =1 for all i,j.
uiui vjvj
The error rates of these agents are as follows: err(v ) = 0 for all j = 1 : 2n and err(u ) = 1/2 for
j i
all j =1:4.
In the first network the error of yˆ (a) is negatively correlated with yˆ (a) and yˆ is positively
u1 u2 u3
correlated with yˆ as:
u4
P(yˆ (a)̸=yˆ (a))=1 & P(yˆ (a)=yˆ (a))=1
u1 u2 u3 u4
Both yˆ and yˆ are independent from yˆ and yˆ .
u1 u2 u3 u4
LetV ={u ,u }. WenowshowthatG(egal) (u )=G(egal) (u )=nandforanyu∈/ V , G(egal) (u)∈
1 3 4 3 4 1
{0,1}.
From lemma 4.2 we conclude that for any vertex u we have:
G(egal) (u)= (cid:88) P (Z(i,a)≤0∧y(a)̸=yˆ (a))
u
a∼Ω
i;W¯ iu̸=0
Thus, it is immediate that for each v , we have G(egal) (v )=0.
j j
Consider u
1
G(egal) (u )= (cid:88) P (Z(i,a)≤0∧y(a)̸=yˆ (a))+ P (Z(u ,a)≤0∧y(a)̸=yˆ (a))
1
a∼Ω
u1
a∼Ω
1 u1
i=1:n
Since u is connected to v ,...v , the last summand is 0 if n>1, and it is 1/2 if n=1. In any case
1 1 n
it is a constant. We now look at the first summand.
(cid:88)
first summand= P ((yˆ (a)+yˆ (a)+yˆ(a))·y(a)≤0∧y(a)̸=yˆ (a))
a∼Ω
u1 u2 i u
i=1:n
= (cid:88) P (cid:0) y(a)2 ≤0∧y(a)̸=yˆ (a)(cid:1) =0
u
a∼Ω
i=1:n
19The last equation follows from the fact that always yˆ (a)̸=yˆ (a), and yˆ(a)=y(a).
u1 u2 i
Similarly we can show that G(egal) (u )={0,1/2}.
2
For u , let c be a constant which is c∈{0,1/2}. We have:
3
G(egal) (u )= (cid:88) P (Z(i,a)≤0∧y(a)̸=yˆ (a))+ P (Z(u ,a)≤0∧y(a)̸=yˆ (a))
3
a∼Ω
u3
a∼Ω
3 u3
i=n+1:2n
(cid:88)
= P ((yˆ (a)+yˆ (a)+yˆ(a))·y(a)≤0∧y(a)̸=yˆ (a))+c
a∼Ω
u3 u4 i u
i=1:n
(cid:88)
= P ((y(a)−2y(a))·y(a)≤0)err(u )+c
3
a∼Ω
i=1:n
=n/2+c .
Similarly we have G(egal) (u )∈{n/2,(n+1)/2}.
4
Therefore, both u and u can be the optimal choice for this network. And any other choice will
3 4
have an error of magnitude Θ(n).
In the second network, we make the following change:
P(yˆ (a)=yˆ (a))=1 & P(yˆ (a)̸=yˆ (a))=1
u1 u2 u3 u4
We still let both yˆ and yˆ are independent from yˆ and yˆ .
u1 u2 u3 u4
Using a similar analysis we can show that
(egal) (egal) (egal)
G (u )=G (u )=n/2+1 & ∀u∈V, u̸=u ,u =⇒ G (u)∈{0,1/2} .
1 2 1 2
(egal)
A.2.2 Monotonicity and submodularity of G
Lemma A.5. Assume S′ ⊆S ⊆V, we have: G(egal) (S′)≤G(egal) (S) .
Proof. From proposition A.2 that for any arbitrary S ⊆V we have:
 
n
G(egal) (S)=(cid:88) P y(a)z∗(i,a)≤0∧ (cid:95) (y(a)̸=yˆ j(a)) 
 
i=1 vj∈S
W¯ ij̸=0
For S′ ⊆S, we split the event (cid:87) (y(a)̸=yˆ (a)) to the two following non-intersecting events:
vj∈S j
W¯ ij̸=0
   
(cid:95)  (cid:95)   (cid:95) (cid:94) 
(y(a)̸=yˆ (a))= (y(a)̸=yˆ (a))∨ (y(a)̸=yˆ (a))∧ (y(a)=yˆ (a))
j  j   j j 
   
vj∈S vj∈S′ vj∈S\S′ vj∈S′
W¯ ij̸=0 W¯ ij̸=0 W¯ ij̸=0 W¯ ij̸=0
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Ei1 Ei2
Since E and E are non-intersecting we have:
1 2
n n
G(egal) (S)=(cid:88) P(y(a)z∗(i,a)<0∧E )+(cid:88) P(y(a)z∗(i,a)<0∧E ) .
i1 i2
i=1 i=1
Note that G(egal) (S′)=(cid:80)n P(y(a)z∗(i,a)<0∧E ). Therefore, we conclude the premise.
i=1 i1
Lemma A.6. Consider arbitrary S ⊆V and u,v ∈V \S. We have:
(egal) (egal) (egal) (egal)
G (S∪{u,v})+G (S)≤G (S∪{u})+G (S∪{v}) .
20Proof. Like previous lemma, we split the events of RHS and LHS to non-intersecting smaller events.
Consider the following events:
 
E FFF(i)≡  (cid:95) yˆ i(a)̸=y(a) ∧(cid:0) yˆ u(a)̸=yˆ(a)∧W¯ iu ̸=0(cid:1) ∧(cid:0) yˆ v(a)̸=y(a)∧W¯ iv ̸=0(cid:1)
 
vj∈S
W¯ ij̸=0
 
E TFF(i)≡ ¬ (cid:95) yˆ i(a)̸=y(a) ∧(yˆ u(a)̸=yˆ(a)∧W¯
iu
̸=0)∧(cid:0) yˆ v(a)̸=y(a)∧W¯
iv
̸=0(cid:1)
 
vj∈S
W¯ ij̸=0
 
E TTF(i)≡ ¬ (cid:95) yˆ i(a)̸=y(a) ∧¬(cid:0) yˆ u(a)̸=yˆ(a)∧W¯
iu
̸=0(cid:1) ∧(cid:0) yˆ v(a)̸=y(a)∧W¯
iv
̸=0(cid:1)
 
vj∈S
W¯ ij̸=0
 
E TFT(i)≡ ¬ (cid:95) yˆ i(a)̸=y(a) ∧(cid:0) yˆ u(a)̸=yˆ(a)∧W¯
iu
̸=0(cid:1) ∧¬(cid:0) yˆ v(a)̸=y(a)∧W¯
iv
̸=0(cid:1)
 
vj∈S
W¯ ij̸=0
and similar definitions for E (i), E (i), E (i) and E (i).
TTT FTT FTF FFT
n
G(egal) (S∪{u,v})=(cid:88) (cid:88) P(y(a)z∗(i,a)≤0∧E (i)),
X,Y,Z
i=1(X,Y,Z)∈{T,F}3\{(F,F,F)}
n
G(egal) (S)=(cid:88) (cid:88) P(y(a)z∗(i,a)≤0∧E (i)),
T,Y,Z
i=1(Y,Z)∈{T,F}2
n
G(egal) (S∪{u})=(cid:88) (cid:88) P(y(a)z∗(i,a)≤0∧E (i))
X,Y,Z
i=1(X,Y,Z)∈{T,F}3\{(F,F,F),(F,F,T)}
and finally
n
G(egal) (S∪{v})=(cid:88) (cid:88) P(y(a)z∗(i,a)≤0∧E (i))
X,Y,Z
i=1(X,Y,Z)∈{T,F}3\{(F,F,F),(F,T,F)}
By counting the number of appearances of each term on the RHS and LHS we may conclude the
premise.
A.3 Pseudocode of the greedy algorithms
In this section we present our algorithms for egalitarian improvement.
Overview of algorithms The first algorithm EgalAlg has access to π and finds the greedy choice
accurately.
The second algorithm EgalAlg(appx) receives parameters mode, e⃗rr and W¯ as input parameters. If
we assume pairwise independence of classifiers, mode = ind and e⃗rr contains agents’ error rates. If
we assume group dependency mode=gr and e⃗rr contains the agent’s individual error rates as well as
err(R) and err(B). Depending on the mode of the algorithm, EgalAlg(appx)calls subsequent procedures
EstGainind and EstGaingr for estimating the greedy choice.
The pseudocodes are as follows and analysis is presented in subsequent subsections:
21Algorithm 1
EgalAlg(cid:0) π,W¯(cid:1)
S =∅
for i=1:k do
maxval=0
for j =1:n do
∆G(S,v )=0
j
for a∈Ω do
for ℓ=1:n do
(cid:32) (cid:33)
(cid:86)
E =Z(i,a)≤0∧ y(a)=yˆ (a) ∧y(a)̸=yˆ (a)
vj∈S j u
W¯ ji̸=0
if E ≡T and W¯ ̸=0 then
ℓj
∆G(S,v )=∆G(S,v )+π(E)
j j
end if
end for
end for
if ∆G(S,v )≥maxval,
j
g =v
j
end for
S =S∪{g}
end for
Algorithm 2
EgalAlg(appx)(cid:0) mode,e⃗rr,W¯(cid:1)
S =∅
for i=1:k do
maxval=0
for j =1:n do
∆(cid:100)Gindv (S,v j)=EstGainind(S,v j,{err(v i)}n i=1,W¯) (algorithm 3)
indv
∆(cid:100)G(S,v j)=∆(cid:100)G (S,v j)
if mode = gr then
∆(cid:100)Ggr (S,v j)=EstGaingr(S,v j,{err(v i)}n i=1,err(R),err(B),W¯) (algorithm 4)
gr indv
∆(cid:100)G(S,v j)=ρ∆(cid:100)G (S,v j)+(1−ρ)∆(cid:100)G (S,v j)
end if
if ∆(cid:100)G(S,v j)≥maxval,
g =v
j
end for
S =S∪{g}
end for
Algorithm 3 EstGainind(S,u,{err(v )}n ,W¯)
j j=1
∆(cid:100)G(S,u)=0
for ℓ=1:n do
tru (S)=1
ℓ
for v ∈S do
m
if W¯ ̸=0,
ℓm
tru (S)=tru (S)×(1−err(v ))
ℓ ℓ m
end for
if Ψ (S,u)<0 and W¯ ̸=0
ℓ ℓu
∆(cid:100)G(S,u) += err(u)·tru ℓ(S)
end for
22Algorithm 4 EstGaingr(S,u,{err(v )}n ,err(R),err(B),W¯)
j j=1
∆(cid:100)G(S,u)=0
boolean Case1=T
boolean Case2R=F
boolean Case2B =F
boolean Case3=F
for ℓ=1:n do
tru (S)=1
ℓ
for v ∈S do
m
if W¯ ̸=0 then
ℓm
if v ∈W then tru (S)=tru (S)×(1−err(v ))
m ℓ ℓ m
if (v ∈R)∧Case1=T then
m
Case1=F
Case2R=T
end if
if (v ∈B)∧Case1=T then
m
Case1=F
Case2B =T
end if
if (v ∈R∧Case2B =T) or (v ∈B∧Case2R=T) then
m m
Case2B =Case2R=F
Case3=T
end if
end if
end for
if Case1∧u∈W then
∆G(S,u)+=tru (S)err(u)[1(Ψ (B∪S),R∪{u})err(R)+1(R∪S),B∪{u})err(B)]
ℓ i
end if
if Case1∧u∈R then
∆G(S,u)+=tru (S)err(u)1Ψ (R∪S,B∪{u})
ℓ i
end if
if Case1∧u∈B then
∆G(S,u)+=tru (S)err(u)1Ψ (B∪S,R∪{u})
ℓ i
end if
if Case2B∧u∈W then
∆G(S,u)+=err(u)err(R)tru(S)1Ψ(B∪S,R∪{u})
end if
if Case2R∧u∈W then
∆G(S,u)+=err(u)err(B)tru(S)1Ψ(R∪S,B∪{u})
end if
if Case2B∧u∈R then
∆G(S,u)+=err(R)tru(S)1Ψ(B∪S,R)
end if
if Case2R∧u∈B then
∆G(S,u)+=err(B)tru(S)1Ψ(R∪S,B)
end if
end for
return ∆G(S,u)
23A.3.1 Finding the greedy choice
Remember from the main text that
   
∆G i(u,S)= P  Z(i,a)≤0∧  (cid:94) y(a)=yˆ j(a) ∧y(a)̸=yˆ u(a)  .
a∼Ω   
vj∈S
W¯ ji̸=0
Proof of Lemma 4.2. It is immediate from proposition A.2 that for any arbitrary S ⊆V we have:
 
n
G(egal) (S)=(cid:88) P y(a)z∗(i,a)≤0∧ (cid:95) (W¯
ij
̸=0∧y(a)̸=yˆ j(a))
i=1 vj∈S
Writing the above for S∪{u} and simplifying we obtain:
 
n
G(egal) (S∪{u})=(cid:88) P y(a)z∗(i,a)≤0∧ (cid:95) (W¯
ij
̸=0∧y(a)̸=yˆ j(a))
i=1 vj∈S∪{u}
 
n
=(cid:88) P y(a)z∗(i,a)≤0∧ (cid:95) (W¯
ij
̸=0∧y(a)̸=yˆ j(a))
i=1 vj∈S
 
+P y(a)z∗(i,a)≤0∧ (cid:94) (W¯
ij
=0∨y(a)=yˆ j(a))∧(W¯
iu
̸=0∧y(a)̸=yˆ u(a))
vj∈S
   
=G(egal)
(S)+
(cid:88) P y(a)z∗(i,a)≤0∧

(cid:94)
y(a)=yˆ
j(a)
∧y(a)̸=yˆ
u(a)

   
W¯i= iu1 ̸=:n
0
W¯vj ij∈ ̸=S
0
(egal) (cid:88)
=G (S)+ ∆G (S,u)
i
i=1:n
W¯ iu̸=0
The following lemma is a middle step for approximation of the greedy choice:
Lemma A.7. Let ∆G (S,u) be
i
   
∆G i(S,u)= P  Z(i,a)≤0∧  (cid:94) y(a)=yˆ j(a) ∧y(a)̸=yˆ u(a) 
a∼Ω   
vj∈S
W¯ ij̸=0
We have that
∆G (S,u)=P(T (S)∧F(u))Γ (S,u) ,
i i i
where
 
Γ i(S,u)=P(cid:0) a∈Ω+(cid:1) P   (cid:88) W¯ ijyˆ j(a)<− (cid:88) W¯ ji+W¯ iu 
a∈Ω+ 
j=1:n vj∈S
vj∈/S∪{u}
 
+P(cid:0) a∈Ω−(cid:1) P   (cid:88) W¯ ijyˆ j(a)> (cid:88) W¯ ji−W¯ iu  .
a∈Ω− 
j=1:n vj∈S
vj∈/S∪{u}
24and T (S) and F(u) are the following events:
i
. (cid:94) .
T (S)= yˆ (a)=y(a), F(u)=yˆ (a)̸=y(a)
i j u
vj∈S
W¯ ij̸=0
Proof. Let E denote the event
 
E
≜

(cid:94)
y(a)=yˆ
j(a)
∧y(a)̸=yˆ u(a) .
 
vj∈S
W¯ ji̸=0
We may write
P(y(a)z∗(i,a)≤0∧E)=P(y(a)z∗(i,a)≤0|E)P(E)
In order find P(y(a)z∗(i,a)≤0|E), we split the probability based on the true label of a:
If a∈Ω+ we have:
   
P(y(a)z∗(i,a)≤0|E)=P z∗(i,a)≤0|

(cid:94)
yˆ
j(a)=+1
∧yˆ
u(a)=−1

   
vj∈S
W¯ ij̸=0
Note that
n
z∗(i,a)=(cid:88) W¯ yˆ (a)
ij j
j=1
thus,
 
P(y(a)z∗(i,a)≤0|E)=P  (cid:88) W¯ ijyˆ j(a)+ (cid:88) W¯ ij −W¯ iu ≤0 
 
j=1:n vj∈S
vj∈/S∪{u}
Similarly, if a∈Ω− we have:
   
P(y(a)z∗(i,a)≤0|E)=P z∗(i,a)≥0|

(cid:94)
yˆ
j(a)=−1
∧yˆ
u(a)=+1

   
vj∈S
W¯ ij̸=0
Since
n
z∗(i,a)=(cid:88) W¯ yˆ (a)
ij j
j=1
we have:
 
P(y(a)z∗(i,a)≥0|E)=P  (cid:88) W¯ ijyˆ j(a)− (cid:88) W¯ ij +W¯ iu ≥0 
 
j=1:n vj∈S
vj∈/S∪{u}
Rearranging and putting together, we obtain the premise.
25A.4 Missing material from section 4.2.1: estimating greedy choice assum-
ing independence
Proof of lemma 4.6. Let
 
tru
i(S)=P

(cid:94)
yˆ
j(a)=y(a)
 .
 
vj∈S
W¯ ij̸=0
Using independence and from lemma A.7 we can write
∆G (S,u)=err(u)tru (S)Γ (S,u) (10)
i i i
In lemma A.8 which follows this proof, we show that by taking
(cid:40)
0 if Ψ (S,u)≥0
Γ(cid:98)i(S,u)=
1
othei
rwise
we have
(cid:32) (cid:33) (cid:32) (cid:33)
(cid:12) (cid:12) Ψ (S,u)2 Ψ (u)2
(cid:12) (cid:12)Γ(cid:98)i(S,u)−Γ i(S,u)(cid:12) (cid:12)≤exp − 4(cid:80)i
n W¯2
≤exp − 4(cid:80)ni
W¯2
,
i=1 ij i=1 ij
Plugging in this approximation in eq. (10) we obtain:
(cid:40)
err(u)tru (S) if Ψ (S,u)<0
∆(cid:100)G i(S,u)=
0
i othei
rwise
(11)
Note that since the classifiers are independent we have
 
tru i(S)=P  (cid:94) yˆ j(a)=y(a) = (cid:89) P(yˆ j(a)=y(a))= (cid:89) (1−err(v j)) .
 
vj∈S vj∈S vj∈S
W¯ ij̸=0 W¯ ij̸=0 W¯ ij̸=0
We have tru (S),err(u) ≤ 1, thus the error of approximating ∆G (S,u) using eq. (11) is at most
i i
(cid:16) (cid:17)
exp − Ψi(u)2 .
4(cid:80)n W¯2
i=1 ij
Lemma A.8. Assume that all the all the classifiers yˆ (a),yˆ (a),...,yˆ (a) are pairwise independent.
1 2 n
We can estimate Γ (S,u) as follows:
i
(cid:40)
0 if Ψ (S,u)>0
Γ(cid:98)i(S,u)= i
1 otherwise
where,
Ψ (S,u)= (cid:88) W¯ + (cid:88) W¯ [1−2err(j)]−W¯
i ij ij iu
vj∈S j=1:n
j̸∈S∪{u}
The error of this estimation is bounded by:
(cid:32) (cid:33) (cid:32) (cid:33)
(cid:12) (cid:12) Ψ (S,u)2 Ψ (u)2
(cid:12) (cid:12)Γ(cid:98)i(S,u)−Γ i(S,u)(cid:12) (cid:12)≤exp − 4(cid:80)i
n W¯2
≤exp − 4(cid:80)ni
W¯2
,
i=1 ij i=1 ij
where
n
Ψ (u)=(cid:88) W¯ [1−2err(j)]−2err(u)W¯ .
i ij iu
j=1
26Proof. Let’s remember the definition of Γ (S,u) from lemma A.7:
i
 
Γ i(S,u)=P(cid:0) a∈Ω+(cid:1) P   (cid:88) W¯ ijyˆ j(a)<− (cid:88) W¯ ij +W¯ iu 
a∈Ω+ 
j=1:n vj∈S
vj∈/S∪{u}
 
+P(cid:0) a∈Ω−(cid:1) P   (cid:88) W¯ ijyˆ j(a)> (cid:88) W¯ ij −W¯ iu  . (12)
a∈Ω− 
j=1:n vj∈S
vj∈/S∪{u}
Assume first that Ψ (S,u)>0. We use the Hoeffding bound theorem A.20 to estimate
i
   
P   (cid:88) W¯ ijyˆ j(a)<− (cid:88) W¯ ij +W¯ iu  & P   (cid:88) W¯ ijyˆ j(a)> (cid:88) W¯ ij −W¯ iu 
a∈Ω+  a∈Ω− 
j=1:n vj∈S j=1:n vj∈S
vj∈/S∪{u} vj∈/S∪{u}
(13)
Inordertoboundthefirstprobabilityineq.(13),notethat(cid:80) W¯ yˆ (a)<−(cid:80) W¯ +
j=1:n ij j vj∈S ij
vj∈/S∪{u}
W¯ iff :
iu
   
(cid:88) W¯ ijyˆ j(a)<E  (cid:88) W¯ ijyˆ j(a) −E  (cid:88) W¯ ijyˆ j(a) − (cid:88) W¯ ij +W¯ iu
   
j=1:n j=1:n j=1:n vj∈S
vj∈/S∪{u} vj∈/S∪{u} vj∈/S∪{u}
furthermore, from lemma A.1 we have a∈Ω+ implies:
 
E  (cid:88) W¯ ijyˆ j(a) = (cid:88) W¯ ij[1−2err(j)] .
 
j=1:n j=1:n
vj∈/S∪{u} vj∈/S∪{u}
Thus,
 
P   (cid:88) W¯ ijyˆ j(a)<− (cid:88) W¯ ij +W¯ ui 
a∈Ω+ 
j=1:n vj∈S
vj∈/S∪{u}
   
= P   (cid:88) W¯ ijyˆ j(a)<E  (cid:88) W¯ ijyˆ j(a) − (cid:88) W¯ ij[1−2err(j)]− (cid:88) W¯ ij +W¯ iu 
a∈Ω+   
j=1:n j=1:n j=1:n vj∈S
vj∈/S∪{u} vj∈/S∪{u} vj∈/S∪{u}
   
= P   (cid:88) W¯ ijyˆ j(a)<E  (cid:88) W¯ ijyˆ j(a) −Ψ i(S,u) 
a∈Ω+   
j=1:n j=1:n
vj∈/S∪{u} vj∈/S∪{u}
Since yˆ(a)s are pairwise independent, and Ψ (S,u)>0 we may use the Hoeffding bound to obtain:
i i
   
a∈P Ω+  
vj∈j
/(cid:88)
= S1 ∪: {n
u}W¯ ijyˆ j(a)<− v(cid:88) j∈SW¯ ij +W¯ iu  ≤exp − (cid:80) vΨ j∈j /i = S(S 1 ∪:, {n uu })2 W¯ i2 j .
27The second probability in eq. (13) may be bounded similarly as follows:
 
P   (cid:88) W¯ jiyˆ j(a)> (cid:88) W¯ ji−W¯ ui 
a∈Ω+ 
j=1:n vj∈S
vj∈/S∪{u}
   
= P   (cid:88) W¯ jiyˆ j(a)>E  (cid:88) W¯ jiyˆ j(a) − (cid:88) W¯ ji[2err(j)−1]+ (cid:88) W¯ ji−W¯ ui 
a∈Ω+   
j=1:n j=1:n j=1:n vj∈S
vj∈/S∪{u} vj∈/S∪{u} vj∈/S∪{u}
   
= P   (cid:88) W¯ jiyˆ j(a)>E  (cid:88) W¯ jiyˆ j(a) +Ψ i(S,u) 
a∈Ω+   
j=1:n j=1:n
vj∈/S∪{u} vj∈/S∪{u}
Again, under pairwise independence and Ψ (S,u)>0 the above probability is bounded as:
i
   
a∈P Ω−  
vj∈j
/(cid:88)
= S1 ∪: {n
u}W¯ jiyˆ j(a)> v(cid:88) j∈SW¯ ji−W¯ ui  ≤exp − (cid:80) vΨ j∈j /i = S(S 1 ∪:, {n uu })2 W¯ j2 i .
Putting together, we obtain: If Ψ (S,u)>0:
i
 
Γ i(S,u)=P(cid:0) a∈Ω+(cid:1) P   (cid:88) W¯ jiyˆ j(a)<− (cid:88) W¯ ji+W¯ ui 
a∈Ω+ 
j=1:n vj∈S
vj∈/S∪{u}
 
+P(cid:0) a∈Ω−(cid:1) P   (cid:88) W¯ jiyˆ j(a)> (cid:88) W¯ ji−W¯ ui 
a∈Ω− 
j=1:n vj∈S
vj∈/S∪{u}
   
Ψ (S,u)2 Ψ (S,u)2
≤exp i [P(a∈Ω+)+P(a∈Ω−)]=exp i 
(cid:80) W¯2 (cid:80) W¯2
j=1:n ji j=1:n ji
vj∈/S∪{u} vj∈/S∪{u}
Note that Γ i(S,u)≥0. Therefore, if Ψ i(S,u)>0, we define Γ(cid:98)i(S,u)=0 and we will have:
 
Ψ (S,u)2
0≤Γ i(S,u)−Γ(cid:98)i(S,u)≤exp −
(cid:80)
i W¯2

.
j=1:n ji
vj∈/S∪{u}
Let’s now find a lower bound on Ψi(S,u)2 which is independent of S. We have:
(cid:80)
j=1:n
W¯ j2
i
vj∈/S∪{u}
n
(cid:88) W¯2 ≤(cid:88) W¯2 .
ji ji
j=1:n i=1
vj∈/S∪{u}
28and
Ψ (S,u)= (cid:88) W¯ + (cid:88) W¯ [1−2err(j)]−W¯
i ij ij iu
vj∈S j=1:n
j̸∈S∪{u}
≥ (cid:88) W¯ [1−2err(j)]−W¯
ij iu
j=1:n
j̸=u
n
=(cid:88) W¯ [1−2err(j)]−2err(u)W¯ =Ψ (u) .
ij iu i
j=1
Thus,
 
(cid:32) (cid:33)
Ψ (S,u)2 Ψ (u)2
0≤Γ i(S,u)−Γ(cid:98)i(S,u)≤exp −
(cid:80)
i W¯2 ≤exp − (cid:80)ni
W¯2
.
j=1:n ji j=1 ji
vj∈/S∪{u}
Assume now that Ψ (S,u)<0. In this case we write the first probability in eq. (13) as:
i
   
P   (cid:88) W¯ ijyˆ j(a)<− (cid:88) W¯ ij +W¯ iu =1− P   (cid:88) W¯ ijyˆ j(a)≥− (cid:88) W¯ ij +W¯ iu 
a∈Ω+  a∈Ω+ 
j=1:n vj∈S j=1:n vj∈S
vj∈/S∪{u} vj∈/S∪{u}
   
=1− P   (cid:88) W¯ ijyˆ j(a)≥E  (cid:88) W¯ ijyˆ j(a) − (cid:88) W¯ ij[1−2err(j)]− (cid:88) W¯ ji+W¯ iu 
a∈Ω+   
j=1:n j=1:n j=1:n vj∈S
vj∈/S∪{u} vj∈/S∪{u} vj∈/S∪{u}
   
=1− P   (cid:88) W¯ ijyˆ j(a)≥E  (cid:88) W¯ ijyˆ j(a) −Ψ i(S,u) 
a∈Ω+   
j=1:n j=1:n
vj∈/S∪{u} vj∈/S∪{u}
Since Ψ (S,u) < 0, we have −Ψ (S,u) > 0 using the pairwise independence of the classifiers, we
i i
employ the Hoeffding bound and obtain that:
   
a∈P Ω+  
vj∈j
/(cid:88)
= S1 ∪: {n
u}W¯ ijyˆ j(a)<− v(cid:88) j∈SW¯ ij +W¯ iu  ≥1−exp − (cid:80) vΨ j∈j /i = S(S 1 ∪:, {n uu })2 W¯ i2 j  .
Similarly we have :
   
a∈P Ω−  
vj∈j
/(cid:88)
= S1 ∪: {n
u}W¯ ijyˆ j(a)> v(cid:88) j∈SW¯ ij −W¯ ui  ≥1−exp (cid:80) vΨ j∈j /i = S(S 1 ∪:, {n uu })2 W¯ i2 j  .
29Putting together, we obtain: If Ψ (S,u)<0:
i
 
∆G i(S,u)=P(cid:0) a∈Ω+(cid:1) P   (cid:88) W¯ jiyˆ j(a)<− (cid:88) W¯ ji+W¯ ui 
a∈Ω+ 
j=1:n vj∈S
vj∈/S∪{u}
 
+P(cid:0) a∈Ω−(cid:1) P   (cid:88) W¯ jiyˆ j(a)> (cid:88) W¯ ji−W¯ ui 
a∈Ω− 
j=1:n vj∈S
vj∈/S∪{u}
   
Ψ (S,u)2 Ψ (S,u)2
≥[1−exp− i ][P(a∈Ω+)+P(a∈Ω−)]=1−exp− i 
 (cid:80) W¯2  (cid:80) W¯2
j=1:n ji j=1:n ji
vj∈/S∪{u} vj∈/S∪{u}
Note that Γ i(S,u)≤1. Therefore, if Ψ i(S,u)<0, we define Γ(cid:98)i(S,u)=1 and we will have:
 
(cid:32) (cid:33)
Ψ (S,u)2 Ψ (u)2
0≤Γ(cid:98)i(S,u)−Γ i(S,u)≤exp −
(cid:80)
i W¯2 ≤exp − (cid:80)ni
W¯2
.
j=1:n ji j=1 ji
vj∈/S∪{u}
This completes our proof.
A.4.1 Missing material from section 4.2.1 related to ambiguous vertices
Lemma A.9. Let V+ be those agents with error less than 1/2 and V− be those agents with error
greater than 1/2. i.e,
V+ ={v |err(v )≤1/2} & V− ={v |err(v )>1/2}
j j j j
and consider the following vectors
W¯+ =(W¯ ) & E+ =(1−2err(v ))
i ij vj∈V+ j vj∈V+
and
W¯− =(W¯ ) & E− =(2err(v )−1)
i ij vj∈V− j vj∈V−
and
W¯ =(W¯ ,W¯ ,...,W¯ )
i i1 i2 in
We have that:
(cid:32) (cid:33)  (cid:32) (cid:33)2
Ψ (u)2 1 ⟨W¯+,E+⟩ ⟨W¯−,E−⟩
exp − 4(cid:80)n ii =1W¯ i2
j
≤exp− 4 (cid:12) (cid:12)Wi ¯ i(cid:12) (cid:12)
2
− (cid:12) (cid:12)Wi ¯ i(cid:12) (cid:12)
2
−2 
≤exp − 41(cid:32) M · (cid:12) (cid:12) (cid:12) (cid:12)W W¯ ¯i+ i(cid:12) (cid:12)(cid:12) (cid:12) 22 ·(cid:12) (cid:12)E+(cid:12) (cid:12) 2− (cid:12) (cid:12) (cid:12) (cid:12)W W¯ ¯i− i(cid:12) (cid:12)(cid:12) (cid:12) 22 ·(cid:12) (cid:12)E−(cid:12) (cid:12) 2−2(cid:33)2 
where
maxW¯+ 1
M = i · .
minW¯+ minE+
i i
Proof. We show the above equation by finding an lower bound for Ψi(u)2 .
(cid:80)n W¯2
Consider an arbitrary vector Xthe ℓ norm is defined as: i=1 ij
2
(cid:115)
(cid:88)
|X| = x2
2 j
xj∈X
30Note that all of the above vectors only have positive elements.
We have:
(cid:32) (cid:33)2
Ψ (u)2 Ψ (u)
(cid:80)n i=i 1W¯ i2
j
= (cid:12) (cid:12)W¯ ii (V)(cid:12) (cid:12)
2
=(cid:32)(cid:80) vi∈V+ (cid:12) (cid:12)W W¯ ¯i ij (( V1 )− (cid:12)
(cid:12)
22err(v j)) − (cid:80) vi∈V− (cid:12) (cid:12)W W¯ ¯i ij (( V2e )r (cid:12) (cid:12)r 2(v j)−1) − 2 (cid:12) (cid:12)e Wr ¯r( i(u V)W )¯ (cid:12)
(cid:12)
2iu(cid:33)2
(cid:32) (cid:33)2
⟨W¯+,E+⟩ ⟨W¯−,E−⟩ 2err(u)W¯
= (cid:12) (cid:12)Wi ¯ i(cid:12)
(cid:12)
2
− (cid:12) (cid:12)Wi ¯ i(cid:12)
(cid:12)
2
− (cid:12) (cid:12)W¯ i(cid:12)
(cid:12)
2
iu (14)
where in the last equation ⟨⟩ denotes dot product.
Using P´olya-Szeg¨o’s inequality we have:
⟨W¯+,E+⟩
(cid:12) (cid:12)W¯+(cid:12)
(cid:12) maxW¯+ |E+|
(cid:12) (cid:12)Wi ¯ i(cid:12) (cid:12)
2
≥ (cid:12) (cid:12)W¯i i(cid:12) (cid:12) 22 · minW¯ ii + · minE2 +
Using Cauchy Schwarz we have
⟨W¯ (cid:12) (cid:12)Wi− ¯, i(cid:12) (cid:12)E 2−⟩ ≤ (cid:12) (cid:12)(cid:12) (cid:12) WW ¯¯ i−i(cid:12) (cid:12) (cid:12) (cid:12)2
2
·(cid:12) (cid:12)E−(cid:12) (cid:12)
2
Therefore, letting M = maxW¯ i+ · 1
minW¯+ minE+
we have: i i
(cid:80)Ψ n i=i( 1u W) ¯2 i2
j
≥(cid:32) M · (cid:12) (cid:12) (cid:12) (cid:12)W W¯ ¯i+ i(cid:12) (cid:12)(cid:12) (cid:12) 22 ·(cid:12) (cid:12)E+(cid:12) (cid:12) 2− (cid:12) (cid:12) (cid:12) (cid:12)W W¯ ¯i− i(cid:12) (cid:12)(cid:12) (cid:12) 22 ·(cid:12) (cid:12)E−(cid:12) (cid:12) 2− 2er (cid:12) (cid:12)r W( ¯u i) (cid:12) (cid:12)W 2¯ iu(cid:33)2
The premise may be concluded from the fact that err(u)W¯ iu ≤1.
|W¯ i|
2
Proof of lemma 4.5. From lemma 4.6 we now that
(cid:32) (cid:33)
(cid:12) (cid:12) Ψ (u)2
(cid:12) (cid:12)∆(cid:100)G i(S,u)−∆G i(S,u)(cid:12) (cid:12)≤exp − 4(cid:80)ni
W¯2
,
i=1 ij
and from lemma A.9 we have:
exp(cid:32) − 4(cid:80)Ψ n ii =(u 1) W2 ¯ i2 j(cid:33) ≤exp −1 4(cid:32) M · (cid:12) (cid:12) (cid:12) (cid:12)W W¯ ¯i+ i(cid:12) (cid:12)(cid:12) (cid:12) 22 ·(cid:12) (cid:12)E+(cid:12) (cid:12) 2− (cid:12) (cid:12) (cid:12) (cid:12)W W¯ ¯i− i(cid:12) (cid:12)(cid:12) (cid:12) 22 ·(cid:12) (cid:12)E−(cid:12) (cid:12) 2−2(cid:33)2 
Putting together and assume that v is not ambiguous. We have that:
i
(cid:12) (cid:12) (cid:12)∆(cid:100)G i(S,u)−∆G i(S,u)(cid:12) (cid:12) (cid:12)≤exp(cid:32) − 4(cid:80)Ψ n ii =(u 1) W2 ¯ i2 j(cid:33) ≤exp −1 4(cid:32) M · (cid:12) (cid:12) (cid:12) (cid:12)W W¯ ¯i+ i(cid:12) (cid:12)(cid:12) (cid:12) 22 ·(cid:12) (cid:12)E+(cid:12) (cid:12) 2− (cid:12) (cid:12) (cid:12) (cid:12)W W¯ ¯i− i(cid:12) (cid:12)(cid:12) (cid:12) 22 ·(cid:12) (cid:12)E−(cid:12) (cid:12) 2−2(cid:33)2 
(cid:18) 1(cid:16) (cid:112) (cid:17)2(cid:19) (cid:18) 1 (cid:19)
≤exp − 3 logn−2 ≤exp − (5logn) =o(n−1) .
4 4
31A.4.2 Missing material from section 4.2.1: proof of the main theorems
In this subsection we present a pseudocode of our algorithm under the assumption that the agents are
pairwise independent.
The following theorem bounds the error of this algorithm:
Theorem A.10. Assume that S is the output of algorithm 2. We have that:
G(egal) (S)≥[(1−1/e)−∆ind]·OPT(egal) ,
where
∆ind
=(cid:88)n exp(cid:32)
−
Ψ i(u)2 (cid:33)
.
(cid:80)n W¯2
i=1 i=1 ij
Proof. Theproofimmediatelyfollowsfromthefactthatwehaveasubmodularandmonotonefunction
and that the error greedy choice taken as
n
(cid:88)
g =argmax ∆(cid:100)G i(S,u) ,
u
i=1
and that for any v we have
i
(cid:32) (cid:33)
(cid:12) (cid:12) Ψ (u)2
(cid:12) (cid:12)∆(cid:100)G i(S,u)−∆G i(S,u)(cid:12) (cid:12)≤exp − 4(cid:80)ni
W¯2
,
i=1 ij
Proof of theorem 4.3 and theorem 3.10 . Usingtheabovetheoremtheorem4.3andtheorem3.10
canbedirectlyconcludedjustbynoticingthatforanynon-ambiguousvertextheerrorinducedonthe
greedy choice is at most o(n−1). Thus, in total all of non-ambiguous vertices together will have an
error of o(1). The ambiguous each can have an error as large as 1.
Assuming having access to approximation W(cid:99)¯. If we only have access to W(cid:99)¯, we may run
EgalAlgoind using W(cid:99)¯. In this case the approximation guarantee can be concluded from the follow-
ing lemma which is similar to lemma A.8:
Lemma A.11. Assume that all the all the classifiers yˆ (a),yˆ (a),...,yˆ (a) are pairwise independent.
1 2 n
We can estimate Γ (S,u) (See eq. (12)) as follows:
i
(cid:40)
Γ(cid:98)i(S,u)=
0 if Ψ(cid:98)i(S,u)>0
1 otherwise
where,
Ψ(cid:98)i(S,u)= (cid:88) W(cid:99)¯
ij
+ (cid:88) W(cid:99)¯ ij[1−2err(j)]−W(cid:99)¯
iu
vj∈S j=1:n
j̸∈S∪{u}
The error of this estimation is bounded by:
(cid:32) (cid:33)
(cid:12) (cid:12) Ψ (u)2
(cid:12) (cid:12)Γ(cid:98)i(S,u)−Γ i(S,u)(cid:12) (cid:12)≤exp − 4(cid:80)ni
W¯2
(1+ϵ) ,
i=1 ij
where
n
Ψ (u)=(cid:88) W¯ [1−2err(j)]−2err(u)W¯ .
i ij iu
j=1
32Proof. Similar to the proof of lemma A.8 we may bound the two terms of Γ (S,u) as follows:
i
 
P   (cid:88) W¯ ijyˆ j(a)<− (cid:88) W¯ ij +W¯ ui 
a∈Ω+ 
j=1:n vj∈S
vj∈/S∪{u}
   
≤ P   (cid:88) W¯ ijyˆ j(a)<E  (cid:88) W¯ ijyˆ j(a) −Ψ(cid:98)i(S,u)−2ϵ 
a∈Ω+   
j=1:n j=1:n
vj∈/S∪{u} vj∈/S∪{u}
Similarly to the previous case if Ψ(cid:98)i(S,u) > 0 we may use Hoeffding bound to bound the above
probability as:
(cid:32) (cid:33) (cid:32) (cid:33)
exp
−(Ψ(cid:98)i(u)−2ϵ)2
≤exp
−(Ψ i(u)−4ϵ)2
(cid:80)n W¯2 (cid:80)n W¯2
j=1 ij j=1 ij
Let’s now bound RHS:
(cid:32) (cid:33) (cid:32) (cid:33) (cid:32) (cid:33)
(Ψ (u)−4ϵ)2 Ψ (u)2 Ψ (u) Ψ (u)2
exp − i ≤exp − i +8ϵ i ≤exp − i +8ϵ
(cid:80)n W¯2 (cid:80)n W¯2 (cid:80)n W¯2 (cid:80)n W¯2
j=1 ij j=1 ij j=1 ij j=1 ij
(cid:32) (cid:33) (cid:32) (cid:33)
Ψ (u)2 Ψ (u)2
≤exp − i exp(8ϵ)≤(1+8ϵ)exp − i
(cid:80)n W¯2 (cid:80)n W¯2
j=1 ij j=1 ij
If Ψ(cid:98)i(S,u)<0 we may write:
 
P   (cid:88) W¯ ijyˆ j(a)>− (cid:88) W¯ ij +W¯ ui 
a∈Ω+ 
j=1:n vj∈S
vj∈/S∪{u}
   
≤ P   (cid:88) W¯ ijyˆ j(a)>E  (cid:88) W¯ ijyˆ j(a) −Ψ(cid:98)i(S,u)+2ϵ 
a∈Ω+   
j=1:n j=1:n
vj∈/S∪{u} vj∈/S∪{u}
and with a similar argument we obtain the same bound. Bounding the probability in the case where
a∈Ω− can be done similarly. And the rest of the proof holds similarly to proof of lemma A.8.
Proof of remark 3.12 independent case . The remark is a direct conclusion of the fact that the
error of the greedy choice is bounded by
(cid:88)n (cid:12)
(cid:12) (cid:12)Γ(cid:98)i(S,u)−Γ
i(S,u)(cid:12)
(cid:12)
(cid:12)≤(1+ϵ)(cid:88)n exp(cid:32)
−
4(cid:80)Ψ ni(u) W2 ¯2(cid:33)
.
i=1 i=1 j=1 ij
A.5 Missing proofs from section 4.2.2: Estimating greedy choice assuming
group dependence
Assumetheassumptionpresentedindefinition4.7andrememberthefollowingdefinitionfromprevious
sections
   
∆G i(S,u)= P  Z(i,a)≤0∧  (cid:94) y(a)=yˆ j(a) ∧y(a)̸=yˆ u(a) ,
a∼Ω   
vj∈S
W¯ ij̸=0
and our goal is to estimate ∆G (S,u) for all S ⊆V, u∈V and i∈[n].
i
33We may write
∆G (S,u)=∆Ggr(S,u)ρ+∆Gindv(S,u)(1−ρ) ,
i i i
, where the super-scripts show whether individual or group decisions have been made. Estimation
of ∆Gindv(S,u) can be obtained using lemma 4.6 and by calling EstGainind of algorithm 2. Estimation
i
of ∆Ggr(S,u) can be done through a series of lemmas that we present here, and it depends on the
i
whether vertices of S , defined as S ≜ {v ∈ S | W¯ ̸= 0}, intersects R, B or both. A pseudocode is
i i j ij
presentedatalgorithms2and4. OuranalysisispresentedinappendicesA.5.1toA.5.3. Thefollowing
lemma summarizes these results:
Lemma A.12. Assume the model presented in definition 4.7. Having a set S let g be the vertex which
maximizes the following function
(cid:88) gr (cid:88) indv
g =argmax ρ ∆(cid:100)G (S,u)+(1−ρ) ∆(cid:100)G (S,u)
i i
u∈V
i=1:n i=1:n
Wij̸=0 Wij̸=0
gr indv
Where ∆(cid:100)G (S,u) may be obtained from lemmas A.14, A.16 and A.17, and ∆(cid:100)G (S,u) may be
i i
obtained from lemma 4.6. We have that:
G(egal) (S∪{gr(S)})−G(egal)
(S∪{g})≤ρ(cid:88)n exp(cid:32) −(ΨW
i
(u)−∆W¯ i)2(cid:33) +(1−ρ)(cid:88)n exp(cid:32)
−
(Ψ i(u))2 (cid:33)
4(cid:80) W¯2 4(cid:80) W¯2
i=1 vj∈W ij i=1 vj∈V ij
We will use the following definitions and results throughout the section.
gr
∆Ggr(S,u)= P (Z(i,a)≤0∧T (S)∧F(u)) ,
i i
a∼Ω
where T (S) and F(u) are the following events:
i
(cid:94)
T (S)= y(a)=yˆ (a) & F(u)=y(a)̸=yˆ (a) .
i j u
vj∈Si
for any v and X ⊆V we denote:
i
W¯ (X)= (cid:88) W¯
i ij
vj∈X
In addition, for any X,Y ⊆V we define,
Ψ (X,Y)= (cid:88) [1−2errindv(v )]+W¯ (X)−W¯ (Y) .
i j i i
vj∈V\(X∪Y)
We will use the following lemma throughout:
Lemma A.13. Let’s define
 
Γ+
i
(X,Y)= P  (cid:88) W¯ ijyˆ jindv(a)≤W¯ i(Y)−W¯ i(X) ,
a∈Ω+
vj∈V\(X∪Y)
and
 
Γ−
i
(X,Y)= P  (cid:88) W¯ ijyˆ jindv(a)≥W¯ i(X)−W¯ i(Y) .
a∈Ω−
vj∈V\(X∪Y)
We may estimate the above probabilities as
(cid:40)
0 if Ψ (X,Y)≥0
Γ(cid:98)+(X,Y)=Γ(cid:98)−(X,Y)= i
i i 1 if Ψ (X,Y)<0
i
34We have that:
(cid:32) (cid:33)
(cid:12) (cid:12) (Ψ (X,Y))2
(cid:12) (cid:12)Γ+
i
(X,Y)−Γ(cid:98)+
i
(X,Y)(cid:12) (cid:12)≤exp −
(cid:80)
i
W¯2
,
vj∈V\(X∪Y) ij
and
(cid:32) (cid:33)
(cid:12) (cid:12) (Ψ (X,Y))2
(cid:12) (cid:12)Γ−
i
(X,Y)−Γ(cid:98)−
i
(X,Y)(cid:12) (cid:12)≤exp −
(cid:80)
i
W¯2
.
vj∈V\(X∪Y) ij
Proof. Assume a∈Ω+ in this case we have that
E (cid:2) yˆindv(a)(cid:3) =1−2errindv(v )
j j
a∈Ω+
Thus,
(cid:88) W¯ yˆindv(a)≤W¯ (Y)−W¯ (X) ⇐⇒
ij j i i
vj∈V\(X∪Y)
     
(cid:88) W¯ ijyˆ jindv(a)≤E  (cid:88) W¯ ijyˆ jindv(a)−E  (cid:88) W¯ ijyˆ jindv(a)−W¯ i(Y)+W¯ i(X) ⇐⇒
vj∈V\(X∪Y) vj∈V\(X∪Y) vj∈V\(X∪Y)
 
(cid:88) W¯ ijyˆ jindv(a)≤E  (cid:88) W¯ ijyˆ jindv(a)−Ψ i(X,Y)
vj∈V\(X∪Y) vj∈V\(X∪Y)
If Ψ (X,Y)>0 we may use the Hoeffding bound to obtain:
i
  (cid:32) (cid:33)
a∈P Ω+ vj∈V(cid:88) \(X∪Y)W¯ ijyˆ jindv(a)≤W¯ i(Y)−W¯ i(X)≤exp − (cid:80) v( jΨ ∈Vi( \X (X, ∪Y Y) ))2 W¯ i2
j
.
If −Ψ (X,Y)>0, we write:
i
(cid:88) W¯ yˆindv(a)≥W¯ (Y)−W¯ (X) ⇐⇒
ij j i i
vj∈V\(X∪Y)
 
(cid:88) W¯ ijyˆ jindv(a)≥E  (cid:88) W¯ ijyˆ jindv(a)−Ψ i(X,Y)
vj∈V\(X∪Y) vj∈V\(X∪Y)
Thus,
  (cid:32) (cid:33)
a∈P Ω+ vj∈V(cid:88) \(X∪Y)W¯ ijyˆ jindv(a)≥W¯ i(Y)−W¯ i(X)≤exp − (cid:80) v( jΨ ∈Vi( \X (X, ∪Y Y) ))2 W¯ i2
j
Therefore,
 
P  (cid:88) W¯ ijyˆ jindv(a)≤W¯ i(Y)−W¯ i(X)
a∈Ω+
vj∈V\(X∪Y)
 
=1− P  (cid:88) W¯ ijyˆ jindv(a)≥W¯ i(Y)−W¯ i(X)
a∈Ω+
vj∈V\(X∪Y)
(cid:32) (cid:33)
(Ψ (X,Y))2
≥1−exp − i .
(cid:80) W¯2
vj∈V\(X∪Y) ij
Putting together we have:
(cid:32) (cid:33)
(cid:12) (cid:12) (Ψ (X,Y))2
(cid:12) (cid:12)Γ+
i
(X,Y)−Γ(cid:98)+
i
(X,Y)(cid:12) (cid:12)≤exp −
(cid:80)
i
W¯2
,
vj∈V\(X∪Y) ij
35Similarly if a∈Ω− we have:
E (cid:2) yˆindv(a)(cid:3) =2errindv(v )−1
j j
a∈Ω−
thus,
(cid:88) W¯ yˆindv(a)≥W¯ (X)−W¯ (Y) ⇐⇒
ij j i i
vj∈V\(X∪Y)
     
(cid:88) W¯ ijyˆ jindv(a)≥E  (cid:88) W¯ ijyˆ jindv(a)+−E  (cid:88) W¯ ijyˆ jindv(a)+W¯ i(X)−W¯ i(Y)
vj∈V\(X∪Y) vj∈V\(X∪Y) vj∈V\(X∪Y)
and
 
−E  (cid:88) W¯ ijyˆ jindv(a)+W¯ i(X)−W¯ i(Y)=− (cid:88) W¯ ij[2errindv(v j)−1]+W¯ i(X)−W¯ i(Y)
vj∈V\(X∪Y) vj∈V\(X∪Y)
=Ψ (X,Y) .
i
The rest of the proof follows similarly to the previous case.
A.5.1 Case 1. Colorless S
i
Assume that S ⊆W,
i
Lemma A.14. If S ⊆W and u∈W, for any arbitrary v we may take:
i i
gr
∆(cid:100)G (S,u)
i
 errindv(u)·(cid:81) (1−errindv(v )) if Ψ (R∪S,B∪{u})<0 &Ψ (B∪S,R∪{u})<0
errindv(u)·(cid:81)W¯v vj jij∈ ∉=S
S0
(1−errindv(vj
j))·err(R) if
Ψi
i(R∪S,B∪{u})>0
&Ψi
i(B∪S,R∪{u})<0
= W¯ ij̸=0
e 0rrindv(u)·(cid:81)
W¯vj ij∈ ̸=S
0(1−errindv(v j))·err(B) i of thΨ
ei
r( wR is∪
e
S,B∪{u})<0 &Ψ i(B∪S,R∪{u})>0
and we have:
(cid:32) (cid:33)
(cid:12)
(cid:12)
(cid:12)∆(cid:100)Gg ir
(S,u)−∆G
igr(S,u)(cid:12)
(cid:12) (cid:12)≤exp
−(Ψ 4W
i
(cid:80)(u)−∆ W¯W¯ 2i)2
vj∈W ij
Proof.
gr gr
P (Z(i,a)≤0∧T (S)∧F(u))= P (z(i,a)≤0∧T (S)∧F(u))P(a∈Ω+)
i i
a∼Ω a∼Ω+
gr
+ P (z(i,a)≥0∧T (S)∧F(u))P(a∈Ω−) .
i
a∼Ω−
We have:
gr gr gr
P (z(i,a)≤0∧T (S)∧F(u))= P (z(i,a)≤0|T (S)∧F(u)) P (T (S)∧F(u)) &
i i i
a∼Ω+ a∼Ω+ a∼Ω+
gr gr gr
P (z(i,a)≤0∧T (S)∧F(u))= P (z(i,a)≤0|T (S)∧F(u)) P (T (S)∧F(u))
i i i
a∼Ω− a∼Ω− a∼Ω−
Note that since S ⊆W and u∈W we have:
gr gr (cid:89)
P (T (S)∧F(u))= P (T (S)∧F(u))=errindv(u)· (1−errindv(v )) .
i i j
a∼Ω− a∼Ω+
vj∈S
W¯ ij̸=0
36Furthermore,
gr
P (z(i,a)≤0|T (S)∧F(u))
i
a∼Ω+
 
= g Pr   (cid:88) W¯ ijyˆ j(a)+ (cid:88) W¯ ij −W¯ iu ≤0 
a∼Ω+ 
j=1:n vj∈S
vj∈/S∪{u}
 
= a∼P Ω+ 

(cid:88) W¯ ijyˆ jindv(a)+ (cid:88) W¯ ijyˆ jgr(a)+ (cid:88) W¯ ijyˆ jgr(a)+ (cid:88) W¯ ij −W¯ iu ≤0 

vj∈W vj∈R vj∈B vj∈S
vj∈/S∪{u}
 
= P   (cid:88) W¯ ijyˆ jindv(a)+ (cid:88) W¯ ij − (cid:88) W¯ ij + (cid:88) W¯ ij −W¯ iu ≤0 err(B)
a∼Ω+ 
vj∈W vj∈R vj∈B vj∈S
vj∈/S∪{u}
 
+ P   (cid:88) W¯ ijyˆ jindv(a)+ (cid:88) W¯ ij − (cid:88) W¯ ij + (cid:88) W¯ ij −W¯ iu ≤0 err(R)
a∼Ω+ 
vj∈W vj∈B vj∈R vj∈S
vj∈/S∪{u}
=Γ+(R∪S,B∪{u})err(B)+Γ+(B∪S,R∪{u})err(R) .
i i
Similarly we have that:
gr
P (z(i,a)≥0|T (S)∧F(u))
i
a∼Ω−
 
= g Pr   (cid:88) W¯ ijyˆ j(a)− (cid:88) W¯ ij +W¯ iu ≥0 
a∼Ω− 
j=1:n vj∈S
vj∈/S∪{u}
 
= a∼P Ω− 

(cid:88) W¯ ijyˆ jindv(a)+ (cid:88) W¯ ijyˆ jgr(a)+ (cid:88) W¯ ijyˆ jgr(a)− (cid:88) W¯ ij +W¯ iu ≥0 

vj∈W vj∈R vj∈B vj∈S
vj∈/S∪{u}
 
= P   (cid:88) W¯ ijyˆ jindv(a)− (cid:88) W¯ ij + (cid:88) W¯ ij − (cid:88) W¯ ij +W¯ iu ≥0 err(B)
a∼Ω− 
vj∈W vj∈R vj∈B vj∈S
vj∈/S∪{u}
 
+ P   (cid:88) W¯ ijyˆ jindv(a)− (cid:88) W¯ ij + (cid:88) W¯ ij − (cid:88) W¯ ij +W¯ iu ≥0 err(R)
a∼Ω− 
vj∈W vj∈B vj∈R vj∈S
vj∈/S∪{u}
=Γ−(R∪S,B∪{u})err(B)+Γ−(B∪S,R∪{u})err(R) .
i i
Therefore, Pgr (Z(i,a)≤0∧T (S)∧F(u)) is equal to
a∼Ω i
(cid:89)
errindv(u)· (1−errindv(v ))·([Γ+(R∪S,B∪{u})err(B)+Γ+(B∪S,R∪{u})err(R)]P(a∈Ω+)
j i i
vj∈S
W¯ ij̸=0
+ [Γ−(R∪S,B∪{u})err(B)+Γ−(B∪S,R∪{u})err(R)]P(a∈Ω−))
i i
We may now employ lemma A.13 to estimate the above probabilities.
37By replacing the estimations Γ(cid:98)+ and Γ(cid:98)− in the above formula we obtain:
i i
gr
∆(cid:100)G (S,u)
i
 errindv(u)·(cid:81) (1−errindv(v )) if Ψ (R∪S,B∪{u})<0 &Ψ (B∪S,R∪{u})<0
errindv(u)·(cid:81)W¯v vj jij∈
∉=
SS
0
(1−errindv(vj
j))·err(R) if
Ψi
i(R∪S,B∪{u})>0
&Ψi
i(B∪S,R∪{u})<0
= W¯ ij̸=0
e 0rrindv(u)·(cid:81)
W¯vj ij∈ ̸=S
0(1−errindv(v j))·err(B) i of thΨ
ei
r( wR is∪ eS,B∪{u})<0 &Ψ i(B∪S,R∪{u})>0
Lemma A.15. If S ⊆W and u∈R, for any arbitrary v we may take:
i i
 errindv(u)·(cid:81) (1−errindv(v )) if Ψ (B∪S,R∪{u})<0
gr  vj∈S j i
∆(cid:100)G
i
(S,u)= W¯ ij̸=0
0 otherwise
If u∈B, for any arbitrary v we may take:
i
 errindv(u)·(cid:81) (1−errindv(v )) if Ψ (R∪S,B∪{u})<0
gr  vj∈S j i
∆(cid:100)G
i
(S,u)= W¯ ij̸=0
0 otherwise
and in both cases we have:
(cid:32) (cid:33)
(cid:12)
(cid:12)
(cid:12)∆(cid:100)Gg ir
(S,u)−∆G
igr(S,u)(cid:12)
(cid:12) (cid:12)≤exp
−(Ψ 4W
i
(cid:80)(u)−∆ W¯W¯ 2i)2
.
vj∈W ij
Proof. Like previous lemma we have:
gr
P (z(i,a)≤0|T (S)∧F(u))
i
a∼Ω+
 
= a∼P Ω+ 

(cid:88) W¯ ijyˆ jindv(a)+ (cid:88) W¯ ijyˆ jgr(a)+ (cid:88) W¯ ijyˆ jgr(a)+ (cid:88) W¯ ij −W¯ iu ≤0 

vj∈W vj∈R vj∈B vj∈S
vj∈/S∪{u}
If u∈R since we are conditioning on F(u) the above probability is equal to:
gr
P (z(i,a)≤0|T (S)∧F(u))=Γ+(B∪S,R∪{u}) .
i i
a∼Ω+
Similarly
gr
P (z(i,a)≥0|T (S)∧F(u))=Γ−(B∪S,R∪{u}) .
i i
a∼Ω+
If u∈B we have
gr
P (z(i,a)≤0|T (S)∧F(u))=Γ+(R∪S,B∪{u}) .
i i
a∼Ω+
Similarly
gr
P (z(i,a)≥0|T (S)∧F(u))=Γ−(R∪S,B∪{u}) .
i i
a∼Ω+
Putting together, and employing lemma A.13 we get the premise.
38A.5.2 Case 2. monochromatic S
i
Lemma A.16. Let C be either R or B and C¯be the other color. Assume S ∩C ≠ ∅ and S ∩C¯=∅.
i i
In this case, for any u∈C, we have ∀i,∆Ggr(S,u)=0.
i
For u∈C¯we may use the following estimation:
∆(cid:100)Ggr (S,u)=(cid:40) err(C¯)(cid:81) vj∈Si∩W(1−errindv(v j)) if Ψ i(C∪S,C¯)<0
i
0 otherwise .
and for u∈W we may use the following estimation:
∆(cid:100)Ggr (S,u)=(cid:40) err(u)err(C¯)(cid:81) vj∈Si∩W(1−errindv(v j)) if Ψ i(C∪S,C¯∪{u})<0
i
0 otherwise .
The above estimations satisfy:
(cid:32) (cid:33)
(cid:12)
(cid:12)
(cid:12)∆(cid:100)Gg ir
(S,u)−∆G
igr(S,u)(cid:12)
(cid:12) (cid:12)≤exp
−(Ψ 4W
i
(cid:80)(u)−∆ W¯W¯ 2i)2
.
vj∈W ij
Proof of lemma A.16. Assume that S intersects only with one color C and its intersection with the
i
other color C¯is empty.
If u∈C, then P(T (S)∧F(u))=0. Thus, ∀i ∆Ggr(S,u)=0.
i i
If u∈C¯:
We have that P(T (S)∧F(u))=err(C¯)·(cid:81) (1−errindv(v )) . Furthermore,
i vj∈Si∩W j
 
g Pr (z∗(i,a)≤0|T i(S)∧F(u))=P  (cid:88) W¯ ijyˆ jindv(a)+W¯(C)−W¯(C¯)+W¯(S∩W)≤0
a∈Ω+
vj∈W\Si
=Γ+(cid:0) C∪S,C¯(cid:1)
.
i
Similarly,
g Pr (z∗(i,a)≥0|T (S)∧F(u))=Γ−(cid:0) C∪S,C¯(cid:1) .
i i
a∈Ω−
Putting together and employing lemma A.13 we conclude the first part of the premise.
If u∈W: We have that P(T (S)∧F(u))=err(u)err(C¯)·(cid:81) (1−errindv(v )). Furthermore,
i vj∈Si∩W j
 
g Pr (z∗(i,a)≤0|T i(S)∧F(u))=P  (cid:88) W¯ ijyˆ jindv(a)+W¯ i(C)−W¯ i(C¯)+W¯ i(S∩W)−W¯ iu ≤0
a∈Ω+
vj∈W\Si
=Γ+(cid:0) C∪S,C¯∪{u}(cid:1)
.
i
Similarly,
g Pr (z∗(i,a)≥0|T (S)∧F(u))=Γ−(cid:0) C∪S,C¯∪{u}(cid:1) .
i i
a∈Ω−
Putting together and employing lemma A.13 we conclude the second part of the premise.
A.5.3 Case 3. bichromatic S
i
Lemma A.17. If S ∩R≠ ∅ and S ∩B ̸=∅, we have ∀i ∆Ggr(S,u)=0.
i i i
Proof. Note that P(T (S))=0. Thus, we conclude the premise.
i
39A.5.4 Missing material from section 4.2.2: W-Ambiguous vertices.
Let’s first present the definition of W-ambiguous vertices in detail:
Consider the following partitioning of white vertices to low and high error parts:
W+ ={v |err(v )≤1/2} & W− ={v |err(v )>1/2}
j j j j
with respect to this partition we define the following vectors:
EW+
=(1−2err(v )) &
EW−
=(2err(v )−1)
j vj∈W+ j vj∈W−
and W¯W+ =(W¯ ) & W¯W− =(W¯ )
i ij vj∈W+ i ij vj∈W−
Definition A.18 ( W-Ambiguous vertices ). Let W¯W =(W¯ ) , and |·| be the ℓ norm and ⟨·,·⟩
i ij vj∈W 2 2
be dot product.
We call an agent v ∈V, W-ambiguous if it satisfies
i
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)⟨W¯ i (cid:12) (cid:12)W W¯+ iW,E (cid:12) (cid:12)W
2
+ ⟩ − ⟨W¯ i (cid:12) (cid:12)W W¯− iW,E (cid:12) (cid:12)W
2
− ⟩(cid:12) (cid:12) (cid:12) (cid:12)≤4(cid:112) logn+∆W¯ i ,
(cid:12) (cid:12)
where ∆W¯ =(cid:12)(cid:80) W¯ −(cid:80) W¯ (cid:12) . A network is nicely colored if no vertex is W-ambiguous.
i (cid:12) vj∈R ij vj∈B ij(cid:12)
We now show that if a vertex is not ambiguous w.r.t. W the group gain associated to it can be
estimated with high precision:
gr
Lemma A.19. Let ∆(cid:100)G
i
(S,u) be as defined in lemmas A.14, A.16 and A.17. If a vertex is non-
ambiguous w.r.t W we have:
(cid:12) (cid:12)∆Ggr(S,u)−∆(cid:100)Ggr (S,u)(cid:12)
(cid:12)≤o(n−1) .
(cid:12) i i (cid:12)
Proof. Note that from lemmas A.14, A.16 and A.17 we have that for any v :
i
(cid:32) (cid:33)
(cid:12)
(cid:12) (cid:12)∆G
igr(S,u)−∆(cid:100)Gg ir (S,u)(cid:12)
(cid:12) (cid:12)≤exp
−(Ψ 4W
i
(cid:80)(u)−∆ W¯W¯ 2i)2
.
vj∈W ij
Note that we have:
(cid:32) (cid:33)2
(ΨW(u)−∆W¯ )2 ΨW(u)−∆W¯
i (cid:80) W¯2i = i (cid:12) (cid:12)W¯W(cid:12)
(cid:12)
i
vj∈W ij i 2
(cid:32) (cid:33)2
⟨W¯W+,EW+⟩ ⟨W¯W−,EW−⟩ 2err(u)W¯ ∆W¯
= i (cid:12) (cid:12)W¯W(cid:12)
(cid:12)
− i (cid:12) (cid:12)W¯W(cid:12)
(cid:12)
− (cid:12) (cid:12)W¯W(cid:12)
(cid:12)
iu − (cid:12) (cid:12)W¯Wi (cid:12)
(cid:12)
i 2 i 2 i 2 i 2
(cid:32) (cid:33)2
⟨W¯W+,EW+⟩ ⟨W¯W−,EW−⟩ ∆W¯
≥ i (cid:12) (cid:12)W¯W(cid:12)
(cid:12)
− i (cid:12) (cid:12)W¯W(cid:12)
(cid:12)
− (cid:12) (cid:12)W¯Wi (cid:12)
(cid:12)
−2
i 2 i 2 i 2
Assuming that the vertex is not ambiguous w.r.t. whites we have:
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)⟨W¯ i (cid:12) (cid:12)W W¯+ iW,E (cid:12) (cid:12)W
2
+ ⟩ − ⟨W¯ i (cid:12) (cid:12)W W¯− iW,E (cid:12) (cid:12)W
2
− ⟩(cid:12) (cid:12) (cid:12) (cid:12)>4(cid:112) logn+∆W¯ i
which implies
(cid:32) (cid:33)2
(ΨW i (cid:80)(u)−∆ W¯W¯ 2i)2 = ΨW i (cid:12) (cid:12)( Wu ¯) W− (cid:12) (cid:12)∆W¯ i ≥(3(cid:112) logn)2 ≥5logn
vj∈W ij i 2
From which we conclude that the error is bounded as:
(cid:32) (cid:33)
(ΨW(u)−∆W¯ )2
exp − i i ≤exp(−5/4logn)=o(n−1) .
(cid:80) W¯2
vj∈W ij
40A.5.5 Missing material from section 4.2.2: proof of the main theorems
Proof of theorem 4.8 and remark 3.12. Note that the error of the greedy choice approxima-
tion is either generated from approximation of (cid:80)n ∆(cid:100)Ggr (S,u) or (cid:80)n ∆(cid:100)Gindv (S,u). The error
i=1 i i=1 i
indv
of ∆(cid:100)G (S,u) may be bounded similar to the independent case. To see the bound the error of
i
(cid:80)n ∆(cid:100)Ggr (S,u) note that the error induced by all non-ambiguous vertices is o(n×n−1)=o(1). The
i=1 i
error of each ambiguous vertex is at most one, therefore, we conclude the result.
Approximation when having access W(cid:99). Follows similarly as in lemma A.11
A.6 Concentration Bounds
Theorem A.20. Let X ,X ,...X be independent random variables in range [−1,1] with means
1 2 k
µ ,...,µ and let w s be weight coefficients . Taking
µ=(cid:80)k
w µ . We have that for any ε>0:
1 k i i=1 i i
(cid:32) (cid:88)k (cid:33) (cid:32) ε2 (cid:33)
P w X ≥µ+ε ≤exp − ,
i i 4(cid:80)k w2
i=1 i=1 i
and
(cid:32) (cid:88)k (cid:33) (cid:32) ε2 (cid:33)
P w X ≤µ−ε ≤exp − .
i i 4(cid:80)k w2
i=1 i=1 i
B Additional experiments and details of set up
Ourproposedproblemandmethodsingeneraldonotassumeanypriorknowledgeofthegivendatasets.
Our algorithms are deterministic with no parameter to tune. It has potential to be applied to any
problemsaslongastheobjectivefunctionoftheproblemsofinterestsrelatedtoourproposedobjective
function. Inthefollowing,weincludetheparametersettingsoftheproblemsinourexperiments. These
parameters are not tuned for our methods. We just fix the parameters to make sure the problems are
nontrivial enough. We use the same parameters for all methods in our experiments.
We let |Ω| = 3 and for initial opinion yˆ, we randomly generate for each agent v a random vector
i
(yˆ(a):a∈Ω) with each entry sampled from Bernoulli distribution with probability p of yˆ(a)=+1
i i i
sampled uniformly from [0.3,0.9]. For random graph generators, some of the key parameters are fixed
as follows:
• Number of nodes: 128
• Erdős-Rényi graph: Probability for edge creation p=0.005.
• Barabási-Albert preferential attachment model: Number of edges to attach from a new node to
existing nodes m=5
• Watts-Strogatzsmall-worldgraph: Eachnodeisjoinedwithitsk =5nearestneighborsinaring
topology; The probability of rewiring each edge p=0.25
Inpractice, wefoundthattheinfiniteFJmodelwithweightmatrixconvergingto(I+L)−1 makes
the problem less interesting than general case in practice. The reason is that all entries of the matrix
(I +L)−1 are positive and non-zero. With such weight matrix, we found even a random selection
algorithm can converge very fast. To avoid such simple cases, here we apply a finite t-step FJ model.
We fix t=3 to ensure the induced matrix W¯ is sparse enough.
Besides randomly generated graphs from tree classical models (ER, PA and WS), we also test
our algorithms on random generated matrix W¯ directly, denoted as RandomW. Each entry of W¯ is
independently sampled from a uniform distribution on [0,1]. We let the sparsity of W¯ to be around
0.95. Each row of W¯ is normalized thus sum up to be 1.
The statistics of real and synthetic datasets are summarized in table 2. Experiment results are
illustrated in fig. 3.
41We let the set of faulty prediction be Zf ≜ E [(cid:80)n 1Z(i,a) < 0] , which serves as an upper-
a∈Ω i=1
bound on the egalitarian improvement. We define the accuracy Acc as:
(egal)
G (S)
Acc= .
Zf
We calculate all expected values by taking averages over a∈Ω.
Table 2: Table of statistics of datasets. Sparsity of W¯ represents the percentage of zero entries in W¯.
size sparsity of W¯ faulty prediction Zf
ER 128 0.98 74.67
PA 128 0.37 32.0
WS 128 0.74 38.67
BIO 297 0.45 55.33
CSPK 39 0.75 14.67
FB 620 0.75 161.33
WIKI 890 0.66 238.67
RandomW 128 0.95 37.67
42Comparison of Algorithms on Dataset=PA Comparison of Algorithms on Dataset=WS
1.0 1.0
0.8 0.8
0.6 0.6
0.4 Random Selection 0.4 Random Selection
Degree Selection Degree Selection
Error Rate Selection Error Rate Selection
0.2 Degree*Error Selection 0.2 Degree*Error Selection
Greedy Algorithm Approximate Greedy Algorithm Approximate
0.0 Greedy Algorithm Greedy Algorithm
0.0
2 4 6 8 10 12 0 5 10 15 20 25 30
k := #selected nodes for intervention k := #selected nodes for intervention
Comparison of Algorithms on Dataset=randomW Comparison of Algorithms on Dataset=BIO
1.0 1.0
0.8 0.8
0.6 0.6
0.4 Random Selection Random Selection
Degree Selection 0.4 Degree Selection
Error Rate Selection Error Rate Selection
0.2 Degree*Error Selection Degree*Error Selection
Greedy Algorithm Approximate 0.2 Greedy Algorithm Approximate
Greedy Algorithm Greedy Algorithm
0.0
0 20 40 60 80 100 0 5 10 15 20 25 30
k := #selected nodes for intervention k := #selected nodes for intervention
Comparison of Algorithms on Dataset=CSPK Comparison of Algorithms on Dataset=WIKI
1.0 1.0
0.8 0.8
0.6
0.6
Random Selection Random Selection
0.4 Degree Selection 0.4 Degree Selection
Error Rate Selection Error Rate Selection
Degree*Error Selection Degree*Error Selection
Greedy Algorithm Approximate 0.2 Greedy Algorithm Approximate
0.2 Greedy Algorithm Greedy Algorithm
0 5 10 15 20 0 20 40 60 80 100
k := #selected nodes for intervention k := #selected nodes for intervention
Figure 3: More experimental results on different datasets.
43
ycaruccA
ycaruccA
ycaruccA
ycaruccA
ycaruccA
ycaruccA