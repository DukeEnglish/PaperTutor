Unified Directly Denoising for Both Variance
Preserving and Variance Exploding Diffusion Models
JingjingWang∗ DanZhang∗ FengLuo
Clemson University
{jingjiw,dzhang4,luofeng}@clemson.edu
Abstract
Previousworkhasdemonstratedthat,intheVariancePreserving(VP)scenario,the
nascentDirectlyDenoisingDiffusionModels(DDDM)cangeneratehigh-quality
imagesinonestepwhileachievingevenbetterperformanceinmultistepsampling.
However,thepseudo-LPIPSlossusedinDDDMleadstoconcernsaboutthebias
in assessment. Here, we propose a unified DDDM (uDDDM) framework that
generatesimagesinone-step/multiplestepsforbothVariancePreserving(VP)and
VarianceExploding(VE)cases. Weprovidetheoreticalproofsoftheexistence
and uniqueness of the model’s solution paths, as well as the non-intersecting
property of the sampling paths. Additionally, we propose an adaptive Pseudo-
Huberlossfunctiontobalancetheconvergencetothetruesolutionandthestability
ofconvergenceprocess. Throughacomprehensiveevaluation, wedemonstrate
that uDDDMs achieve FID scores comparable to the best-performing methods
availableforCIFAR-10inbothVPandVE.Specifically,uDDDMachievesone-
stepgenerationonCIFAR10withFIDof2.63and2.53forVEandVPrespectively.
Byextendingthesamplingto1000steps,wefurtherreduceFIDscoreto1.71and
1.65forVEandVPrespectively,settingstate-of-the-artperformanceinbothcases.
1 Introduction
Diffusion models have recently emerged as a cutting-edge method in generative modeling for
producinghigh-qualitysamplesinmanyapplicationsincludingimage, audio[16,22], andvideo
generation[23,24,10]. Thesemodelscanbederivedfromstochasticdifferentialequations(SDEs),
thatemployaforwardprocesstograduallytransformdataintoGaussiannoise,andareverseprocess
toreconstructtheinitialdatafromthenoise. ThetwomaintypesofforwardSDEsareVariance
Preserving(VP)SDEandVarianceExploding(VE)SDE[31,11]. Theformermaintainsastationary
distributionofisotropicGaussianandthelatermimicsBrownianmotionbutwithadeterministic
timechangethatresultsinanexplodingvariance. Despitetheireffectiveness,theclassicaldiffusion
processrequiresmultipleiterativestepstoproduceahighqualitysample.
To tackle the challenge of inefficient inference process, one-step generative models such as the
ConsistencyModels(CMs)[29,28],ConsistencyTrajectoryModels(CTMs)[15]andTRACT[2]
havebeenintroduced. Whiletheaforementionedinnovationsinthosemodelsconsiderablyenhance
samplingefficiency,theystillhaveseveraldrawbacks. Forexample,onemajorconcernforCMsis
thecomplexityofitshyperparameters. Thesehyperparametersmustbecarefullytunedtogenerate
high-qualityimages,aprocessthatischallengingtooptimizeandmaynotgeneralizewellacross
differenttasksordatasets. CTMemploysadversarialtraining,whichmayincreasecomputational
costandreducedtrainingstability,asGANsarenotoriouslychallengingtotrain[26]. TRACTisa
puredistillation-basedmodel,introducingadditionalcomputationaloverheadduringtrainingasit
∗Equalcontribution
Preprint.Underreview.
4202
yaM
13
]VC.sc[
1v95012.5042:viXrareliesonaseparatepre-traineddiffusionmodel(theteachermodel). Furthermore,thequalityofthe
studentmodelislimitedtothatoftheteachermodel.
Preivously,Zhanget. alintroducedtheDirectlyDenoisingDiffusionModels(DDDMs,[36]),which
can generate realistic images in one step while achieving even better performance in multistep
samplingintheVPscenario. TheDDDMmodelsemployPseudo-LPIPSloss,whichisbasedonthe
learnedLPIPS[38]metrics. However,thePseudo-LPIPSlossmayintroducebiasintheevaluation. In
thispaper,weproposeuDDDM,aunifieddirectlydenoisingdiffusionframeworkforbothVPandVE
cases. WeprovidethetheoreticalproofsforthepropertiesofuDDDMs. Additionally,toovercome
thedrawbacksofpreviousPseudo-LPIPSloss,wehavealsoproposedanadaptivePseudo-Huber
lossfunction,whichcanenhancebothrobustnessandsensitivityofuDDDM.WevalidateuDDDM
usingtheCIFAR-10benchmarkdataset,achievingperformanceonparwithstate-of-the-artdiffusion
modelsinone-stepsampling. Moreover,uDDDMsurpassesthesemodelsinmulti-stepsampling
scenarios,demonstratingitssuperiorefficacyandrobustness.
Ourcontributionscanbesummarizedasfollows:
• WeintroduceuDDDM,whichprovidesaunifiedframeworktosupportbothVPandVE
cases. ThisintegratedstructureisdesignedtoleveragethestrengthsofDDDMs,enabling
themtoperformexceptionallywellacrossdifferentnoiseschedulers.
• Weproposeanadaptivelossfunctionfortraining. Thisfunctionseamlesslyintegratestwo
components: aguidinglossandaniterativeloss. Theguidinglossfocusesonminimizing
thedifferencebetweenthepredictedandactualdatapoints,whiletheiterativelossensures
that the model’s predictions remain consistent over multiple iterations. By dynamically
balancingthesecomponents,theadaptivelossfunctionadjuststothespecificneedsofthe
modelatdifferentepochsoftraining.
• We provide theoretical proofs of the existence and uniqueness of the model’s solution
paths. Furthermore,weestablishanon-intersectingsamplingpaththeorem,whichensures
thatgivenanytwodistinctstartingpoints,themulti-stepsamplingpathswillnotintersect.
This property is crucial for maintaining the diversity and independence of sample paths
incomplexgenerativemodels,enhancingthemodel’sabilitytoexplorethesamplespace
withoutredundancy.
2 Preliminaries
2.1 VarianceExploding(VE)StochasticDifferentialEquation(SDE)
TheconceptofVarianceExploding(VE)StochasticDifferentialEquation(SDE)[31]originatesfrom
theScoreMatchingwithLangevinDynamics(SMLD)[30],amethodcharacterizedbytheuseof
multiplenoisescalesrangingfromσ toσ . InSMLD,aforwardMarkovchainisutilizedwhere
0 N−1
eachtransitionisdefinedas:
(cid:113)
x =x + σ2−σ2 z ,1≤i≤N
i i−1 i i−1 i−1
wherez ∼N(0,I),x ∼p .
i−1 0 data
AsthenumberofstepsN goestoinfinity,thisdiscretechaintransitionsintoacontinuousstochastic
process. Inthislimit,thediscretestatesx ,thediscretenoisescalesσ andtherandomvariablesz
i i i
arereplacedbycontinuousfunctionsx ,σ andz ,respectively. Thetransformationoftheupdating
t t t
equationinthecontinuouslimit,with∆t= 1 →0,becomes:
N
(cid:114)
(cid:113) dσ2
x =x + σ2 −σ2z ≈x + t ∆tz .
t+∆t t t+∆t t t t dt t
Theaboveapproximationcanbeexpressedasanequalitywiththefollowingdifferentialform
(cid:114)
dσ2
dx = t dw, 0≤t≤T.
t dt
2(cid:113)
This is the VE SDE, where w denotes the wiener process. The diffusion term dσ t2 is a mono-
dt
tonicallyincreasingfunction,typicallychosentobeageometricsequence[30,31]bysettingσ =
t
(cid:16) (cid:17)t
σ min σ σm ma inx T,withσ min ≪σ max.
Thus,theforwardprocessforVarianceExplodingcaseis:
p (x |x )=N
(cid:0)
x ;x
,σ2I(cid:1)
, t∈[0,T]
0t t 0 t 0 t
Karrasetal.[11]revisitedthenoiseschedulerofVESDEandgiventhefollowingexpression:
(cid:18) t−1 (cid:16) (cid:17)(cid:19)ρ
σ = σ1/ρ + σ1/ρ −σ1/ρ t∈[1,T]
t min T −1 max min
Moreover,Karrasetal.[11]statedthatasρ→∞,theaboveequationsimplifiestothesamegeometric
sequenceusedbytheoriginalVESDE.Therefore,thisdiscretizationcanbeviewedasaparametric
generalizationofthemethodproposedbySongetal.[31].
ThereserveSDE[1,31]ofVEcanbeexpressedas:
(cid:20) dσ2 (cid:21) (cid:114) dσ2
dx = − t ∇ logp (x ) dt+ t dw,
t dt xt t t dt
Whenweremovethediffusionterm,theabovereverseSDEcanbesimplifiedtotheprobabilityflow
(PF)ODEas:
(cid:20) dσ2 (cid:21)
dx = − t ∇ logp (x ) dt
t dt xt t t
Usually,onecanusetheexsitingODEsolverstosolvethePFODE.
2.2 TheframeworkofDDDM
SincethenumericalsolversofODEcannotavoidthediscretizationerror[3],whichrestrictsthe
qualityofsampleswhenonlyasmallnumberNFEsareused,DDDMswereproposedasanODE
solver-freeapproachthataimstodirectlyrecovertheinitialpointx ofthePFODEtrajectory. This
0
isachievedthroughaniterativeprocessthatrefinestheestimation.
First,wedefinef(x ,x ,t)asthesolutionofthePFODEwithVPfrominitialtimettoendtime0:
0 t
(cid:90) 0 1
f(x ,x ,t):=x + − β(s)[x −∇ logq (x )]ds
0 t t 2 s xs s s
t
(cid:0)√ (cid:1)
wherex isdrawnfromN α x ,(1−α¯ )I .
t t 0 t
Next,wedefinedthefunctionF(x ,x ,t)as:
0 t
(cid:90) 0 1
F(x ,x ,t):= β(s)[x −∇ logq (x )]ds.
0 t 2 s xs s s
t
Therefore,wehave
f(x ,x ,t)=x −F(x ,x ,t).
0 t t 0 t
Byapproximatingf,theoriginalimagex canberecovered.Letf beaneuralnetworkparameterized
0 θ
function,whichisemployedtoestimatethesolutionofthePFODEandtherebyrecovertheoriginal
imagestateattime0. Thepredictivemodelisrepresentedas:
f (x ,x ,t)=x −F (x ,x ,t)
θ 0 t t θ 0 t
whereF istheneuralnetworkfunctionparameterizedwithθ. Toachieveagoodrecoveryofthe
θ
initialstatex ,itisnecessarytoensuref (x ,x ,t)≈f(x ,x ,t).
0 θ 0 t 0 t
ThepracticalapplicationofDDDMinvolvesaniterativeapproach,whereaninitialestimatex(n)is
0
refinediterativelyusingtheupdateequation:
(cid:16) (cid:17)
x(n+1) =x −F x(n),x ,t .
0 t θ 0 t
33 AUnifiedDDDM(uDDDM)Framework
Inthissection,wepresentaunifiedDDDMframework,whichintegratebothVPandVEapproaches
intoasingleframework. Additionally,weintroduceanadaptivelossfunctiondesignedtoenhance
therobustnessandstabilityofthetrainingprocess.
3.1 TheUnifiedDDDMs
ThePFODEcanbeexpressedas:
dx
t =−h(x ,x ,t) (1)
dt 0 t
wherewedenote:
 dσ2
 dtt ∇ xtlogp t(x t) (VEcase)
h(x ,x ,t):=
0 t 1
 β(t)[x −∇ logq (x )] (VPcase)
2 t xt t t
Weintegratebothsidesfrominitialtimettofinaltime0ofEquation(1)andobtain:
(cid:90) 0
f(x ,x ,t)=x − h(x ,x ,s)ds
0 t t 0 s
t
For stable training purpose in VE case, we rewrite the f(x ,x ,t) as a combination of x and a
0 t t
functionF.Thisapproachhelpstobalancethecontributionsofthecurrentstateandthefunction,
therebyimprovingtherobustnessofthetrainingprocess.
(cid:90) 0
f(x ,x ,t)=x − h(x ,x ,s)ds (VPcase)
0 t t 0 s
t
(cid:124) (cid:123)(cid:122) (cid:125)
F(x0,xt,t)
(cid:90) 0
=κ(σ )x +(1−κ(σ ))x − h(x ,x ,s)ds (2)
t t t t 0 s
t
(cid:20) 1 (cid:90) 0 (cid:21)
=κ(σ )x +(1−κ(σ )) x − h(x ,x ,s)ds (VEcase)
t t t t 1−κ(σ ) 0 s
t t
(cid:124) (cid:123)(cid:122) (cid:125)
F(x0,xt,t)
FromEquation(2),wecanobtainaunifiedexpressionforf(x ,x ,t):
0 t
f(x ,x ,t)=a(σ )x +b(σ )F(x ,x ,t),
0 t t t t 0 t
√
whereforVPcase,a(σ )=1,b(σ )=−1,x ∼N ( α¯ x ,(1−α¯ )I)andα¯
=(cid:81)t
(1−β ).
t t t t 0 t t s=1 s
ForVEmodel,a(σ ) = κ(σ ),b(σ ) = 1−κ(σ ),x ∼ N(x ,σ2I). Thereareafewchoicesfor
t t t t t 0 t
thedesignofκ(σ t),suchasκ(σ t)= σtσ +d σa dta ata,κ(σ t)=
σ
t2σ +d2 σa dt 2a ata. Wesetκ(σ t)= σ σm tin inthiswork.
Toestimatex ,wepredict:
0
f (x ,x ,t)=a(σ )x +b(σ )F (x ,x ,t)
θ 0 t t t t θ 0 t
andemployaniterativeprocessforthisprediction:
(cid:16) (cid:17)
x(n+1) =f x(n),x ,t
0 θ 0 t
Throughthisiterativeprocedure,weareabletoprogressivelyapproachtheactualstartingpointby
improvingtheestimateofx ateachtrainingepochn. Therefinementequationbecomes:
0
(cid:16) (cid:17)
x(n+1) =a(σ )x +b(σ )F x(n),x ,t
0 t t t θ 0 t
4Toeffectivelyminimizethediscrepancybetweentheiterativelyestimatedx(n) andthetrueinitial
0
statex , weemployaspecificlossfunctionduringthetrainingofourmodel. Thislossfunction
0
ensuresthattheneuralnetworklearnstoproduceaccurateestimatesoftheinitialstatebyreducing
theerrorbetweenthepredictedandactualvalues.
3.2 TheAdaptiveLossFunction
Tobalancetheconvergencetothetruesolutionandthestabilityofconvergenceprocess,wepropose
anadaptivelossfunction:
1 1
L(n) (θ):= L(n) (θ)+(1− )L(n)(θ) (3)
uDDDM n+1 Guide n+1 Iter
where
(cid:104) (cid:16) (cid:16) (cid:17) (cid:17)(cid:105)
L(n) (θ):=E d f x(n),x ,t ,x
Guide x0,xt,t θ 0 t 0
(cid:104) (cid:16) (cid:16) (cid:17) (cid:17)(cid:105)
L(n)(θ):=E d f x(n),x ,t ,x(n)
Iter x0,xt,t θ 0 t 0
Inbothlossfunctions, tissampledfromauniformdistributionovertheintegerset[1,2,··· ,T],
√
x ∼p ,x ∼N ( α¯ x ,(1−α¯ )I)orN
(cid:0)
x
,σ2I(cid:1)
andndenotestrainingepochstartingfrom
0 data t t 0 t 0 t
0. d(·,·)isametricfunctionsatisfiesthatforallvectorsxandy,d(x,y)≥0andd(x,y)=0ifand
onlyifx=y. Therefore,commonlyusedmetricssuchasL orL canbeutilized. Wewilldiscuss
1 2
ourchoiceofd(·,·)later.
Thislossfunctionisdesignedtomeasuretheperformanceofourproposedmethodintwodistinct
aspects.
ConvergencetotheTrueSolution: ThefirsttermL(n) (θ)istheguidingloss,whichdecreases
Guide
theweightofthedeviationoff (x(n),x ,t)fromthetruevaluex asnincreases. Thisimpliesthat
θ 0 t 0
intheearlystageoftrainingprocess, modelestimationx(n) maybefarawayfromgroundtruth.
0
Therefore,exactalignmentwiththetruevaluewillbeemphasized.
StabilityoftheIteration: ThesecondtermL(n)(θ)denotestheiterativeloss,whichmeasuresthe
Iter (cid:16) (cid:17)
self-consistencyoftheiterationasitprogresses. Itassesseshowclosef x(n),x ,t istox(n),with
θ 0 t 0
increasingimportancegiventothistermask increases. Thisreflectsagrowingemphasisonthe
iteration’sstabilityandself-consistencyasitproceeds,whichiscriticalfortheconvergenceofour
proposedmethods.
Thelossformulationeffectivelybalancesbetweenguidingtheiterationtowardsthetruefixedpoint
andensuringthemethodstabilizes. Earlyinthetrainingprocess,theemphasisismoreonaligning
withthetruesolutionratherthanstabilizingthemethod, whichcanbeparticularlyadvantageous
whenx isnotwell-approximatedinitially.
0
Asnincreases,reducingtheweightonthefirsttermallowstheiterationstofocusmoreonrefining
thesolutiontoensureitisafixedpoint,ratherthanmerelyapproximatingthetruesolution. This
shiftiscrucialforthepracticalimplementationofiterativemethods, asitacknowledgesthedual
requirementsofconvergenceandstability,whichareoftenatoddsinnumericalcomputations.
Thisapproachisparticularlywell-suitedforproblemswherethetruesolutionmaybedifficultto
approachdirectlyduetocomplexitiesinthefunctionF ortheinitialconditions. Byadjustingthe
focusfromaccuracytowardsstabilityasiterationsprogress,themethodcanachieveamorereliable
convergence,makingitrobustinvariousscenarios.
Metricfunction. Inspiredby[28],weadoptthePseudo-Hubermetricfamily[5]forfunctiond(·,·)
inEquation(3),definedas
(cid:113)
d(x,y)= ∥x−y∥2+c2−c (4)
2
wherecisanadjustablehyperparamter.ThePseudo-Hubermetricismorerobusttooutlierscompared
tothesquaredL metricbecauseitimposesasmallerpenaltyforlargeerrors,whilestillbehaving
2
similarly to the squared L metric for smaller errors. Additionally, the Pseudo-Huber metric is
2
5unbiased in evaluation compared to LPIPS [38]. This is because both LPIPS and the Inception
networkusedforFIDemployImageNet[6]. ThepotentialleakageofImageNetfeaturesfromLPIPS
couldresultininflatedFIDscores. Wesetc=0.00014forVPandc=0.00015forVErespectively.
3.3 TheoreticalJustificationsofuDDDM
ThetheoreticaljustificationspresentedforuDDDMdemonstratetherobustnessofthemodelunder
certainmathematicalconditions,ensuringitsreliabilityinpracticalapplications.
(cid:16) (cid:17)
SupposeF x(n),x ,t istwicecontinuouslydifferentiablewithboundedfirstandsecondderiva-
θ 0 t
tivesanddenoteh (cid:16) x(n),x ,t(cid:17) := dFθ(cid:16) x 0(n),xt,t(cid:17) or (1−κ(σt))dFθ(cid:16) x( 0n),xt,t(cid:17) forVPandVE,re-
θ 0 t dt dt
spectively.
Theinitialvalueproblem(IVP)ofthePFODEcanbeexpressedas:
 dx (cid:16) (cid:17)
 s =−h x(n),x ,s s∈[0,t]
ds θ 0 s (5)
 x =xˆ
t t
ifputtingx˜ :=x ,weget
s t−s
 dx˜ (cid:16) (cid:17)
 s =h x˜(n),x˜ ,s s∈[0,t]
ds θ t s (6)
 x˜ =xˆ
0 t
TheIVP5and6areequivalentandcanbeusedinterchangeably.
Theorem1(Uniqueness): Supposewehavetheinitialvalueproblem6,where,xˆ isagiveninitial
t
conditionattime0forx˜ .AssumethatthereexistsL>0,suchthatthefollowingLipschitzcondition
0
holds:
(cid:16) (cid:17) (cid:16) (cid:17)
∥h x˜(n),x˜ ,s −h y˜(n),y˜ ,s ∥ ≤L∥x˜ −y˜ ∥ (7)
θ t s θ t s 2 s s 2
foralls∈[0,t]andx˜ ,y˜ ∈RD. Thenthereexistsatmostonefunctionx whichsatisfiestheinitial
s s t
valueproblem.
Theorem1assuresthatgivenaninitialstate,theevolutionofthemodelisdeterministicandpredictable
withintheboundsoftheLipschitzcondition.
Theorem2: IfthelossfunctionL(n) (θ)→0asn→∞,itcanbeshownthatasn→∞,
uDDDM
(cid:16) (cid:17)
f x(n),x ,t →x .
θ 0 t 0
Theorem2extendsaforementionedassurance,linkingtheconvergenceofthelossfunctiontogive
existence of the solution. That is, the iterative solution will recover the true x when the neural
0
networkissufficientlytrained.
Theorem3(Non-Intersection): Supposetheneuralnetworkissufficientlytrained,θ∗obtainedsuch
(cid:16) (cid:17)
thatf θ∗(x( 0n),x t,t)≡f(x 0,x t,t)foranyt∈[0,T]andx 0sampledfromp data,andh
θ
x˜( tn),x˜ s,s
meetsLipschitzcondition(Equation(7))
Thenforanyt∈[0,T],themappingf θ∗(x( 0n),x t,t):RD →RD isbi-Lipschitz. Namely,forany
x ,y ∈RD
t t
(cid:13) (cid:13)
e−Lt∥x −y ∥ ≤(cid:13)f (x(n),x ,t)−f (y(n),y ,t)(cid:13) ≤eLt∥x −y ∥ .
t t 2 (cid:13) θ∗ 0 t θ∗ 0 t (cid:13) t t 2
2
Thisimpliesthatifgiventwodifferentstartingpoint,sayx ̸= y ,bythebi-Lipschitzabove,it
T T
canbeconculdethatf θ∗(x( 0n),x T,T)̸=f θ∗(y 0(n),y T,T)i.e.,x( 0n+1) ̸=y 0(n+1),whichindicatethe
reversepathofuDDDMdoesnotintersect.
TheproofofTheoremspresentedinAppendixA.
6Algorithm1Training
Input: imagedatasetD,T,modelparameterθ,initializex(0) ∼N(0,I),epochn←0
0
repeat
Samplex ∼D,t∼U[1,T]andϵ∼N(0,I)
0
ifVEthen
x =x +σ ϵ
t 0 t
else
√ √
x = α¯ x + 1−α¯ ϵ
t t 0 t
endif
(cid:16) (cid:17)
x(n+1) ←f x(n),x ,t
0 θ 0 t
L(n) (θ)← 1 [d(f (x(n),x ,t),x )]+(1− 1 )[d(f (x(n),x ,t),x(n))]
uDDDM n+1 θ 0 t 0 n+1 θ 0 t 0
θ ←θ−η∇ L(θ)
θ
n←n+1
untilconvergence
Algorithm2Sampling
Input: T,trainedmodelparameterθ,samplingsteps,initializex(0) ∼N(0,I),x ∼N(0,I)
0 T
ifVEthen
x =σ x
T max T
endif
forn=0tos−1do
(cid:16) (cid:17)
x(n+1) ←f x(n),x ,T
0 θ 0 T
endfor
Output: x(n+1)
0
3.4 TrainingandSamplingwithuDDDM
Training. Each data sample x is chosen randomly from the dataset, following the probability
0
distribution p (x ). This initial data point forms the basis for generating a trajectory. Next,
data 0
we randomly sample a t ∼ U[1,T], and obtain its noisy variant x accordingly. we play the
t√ √
reparameterization trick to rewrite x = x +σ ϵ for VE and x = α¯ x + 1−α¯ ϵ for VP,
t 0 t t t 0 t
where ϵ ∼ N(0,I). For current training epoch n, our model takes noisy data x and timestep
t
t, aswellasthecorrespondingestimatedtargetfrompreviousepochx(n−1) asinputs, predictsa
0
newapproximationx(n),whichwillbeutilizedinthenexttrainingepoch. uDDDMistrainedby
0
minimizing the loss following Eq. 3. The full procedure of training uDDDM is summarized in
Algorithm1.
Sampling.Thegenerationofsamplesisfacilitatedthroughtheuseofawell-traineduDDDM,denoted
asf (·,·). TheprocessbeginsbydrawingfromtheinitialGaussiandistribution,wherebothx(0)and
θ 0
x aresampledfromN (0,I). x willbescaledbyσ forVEcase. Subsequently,thesenoise
T T max
(cid:16) (cid:17)
vectorsandembeddingofT arepassedthroughtheuDDDMmodeltoobtainxest =f x(0),x ,T .
0 θ 0 T
Thisapproachisnoteworthyforitsefficiency,asitrequiresonlyasingleforwardpassthroughthe
model. Ourmodelalsosupportsamultistepsamplingprocedureforenhancedsamplequality. Detail
canbefoundinAlgorithm2.
4 Experiments
Toevaluateourmethodforimagegeneration,wetrainseveraluDDDMsonCIFAR-10[17]benchmark
their performance with competing methods in the literature. Results are compared according to
FrechetInceptionDistance(FID,[8]),whichiscomputedbetween50Kgeneratedsamplesandthe
wholetrainingset. WealsoemployInceptionScore(IS,[25])tomeasuresamplequality.
7Table1: Comparingthequalityofunconditional
samplesonCIFAR-10
Method NFE(↓)FID(↓) IS(↑)
Fastsamplers&distillationfordiffusionmodels
DDIM[27] 10 13.36
DPM-solver-fast[19] 10 4.70
3-DEIS[37] 10 4.17
UniPC[39] 10 3.87
DFNO(LPIPS)[40] 1 3.78
2-RectifiedFlow[18] 1 4.85 9.01
KnowledgeDistillation[20] 1 9.36
TRACT[2] 1 3.78
2 3.32
Diff-Instruct[21] 1 4.53 9.89
CD(LPIPS)[29] 1 3.55 9.48
2 2.93 9.75
DirectGeneration
ScoreSDE[31] 2000 2.38 9.83
ScoreSDE(deep)[31] 2000 2.20 9.89 Figure 1: One-step samples from uDDDM-
DDPM[9] 1000 3.17 9.46 VE-deep
LSGM[34] 147 2.10
PFGM[35] 110 2.35 9.68
EDM[11] 35 2.04 9.84
EDM-G++[14] 35 1.77
NVAE[33] 1 23.5 7.18
BigGAN[4] 1 14.7 9.22
StyleGAN2[12] 1 8.32 9.21
StyleGAN2-ADA[13] 1 2.92 9.83
CT(LPIPS)[29] 1 8.70 8.49
2 5.83 8.85
iCT[28] 1 2.83 9.54
2 2.46 9.80
iCT-deep[28] 1 2.51 9.76
2 2.24 9.89
uDDDM(VE) 1 2.91 9.56
2 2.68 9.75
1000 1.89 9.93
uDDDM(VP) 1 2.84 9.56
2 2.50 9.76
1000 1.73 9.94
uDDDM(VE-deep) 1 2.63 9.77
2 2.35 9.88
1000 1.71 9.95
uDDDM(VP-deep) 1 2.53 9.80
2 2.21 9.90 Figure 2: One-step samples from uDDDM-
1000 1.65 9.95
VP-deep
4.1 ImplementationDetails
ArchitectureWeusetheU-NetarchitecturefromADM[7]forbothVPandVEsetting. Specifically,
we use a base channel dimension of 128, multiplied by 1,2,2,2 in 4 stages and 3 residual blocks
perstage. Dropout[32]of0.3isutilizedforthistask. FollowingADM,weemploycross-attention
modulesnotonlyatthe16x16resolutionbutalsoatthe8x8resolution,throughwhichweincorporate
theconditioningimagex(n)intothenetwork.Wealsoexploredeepervariantsofthesearchitectures
0
bydoublingthenumberofblocksateachresolution,whichwenameuDDDM-deep. Allmodelson
CIFAR-10areunconditional.
OthersettingsWeuseAdamoptimizerforallofourexperiments. ForVPmodel,wesetT =8000
and use a linear variance schedule from β = 1.5×10−3 to β = 2.0×10−2. For VE model,
0 T
weuseT = 1000andsetσ = 0.01andσ = 50respectively. Forbothsettings,wetrainthe
min max
modelsfor400kiterationswithaconstantlearningrateof0.0002andbatchsizeof1024. Weusean
exponentialmovingaverage(EMA)oftheweightsduringtrainingwithadecayfactorof0.9999for
alltheexperiments. Allmodelsaretrainedon8NvidiaA100GPUs.
84.2 ComparisontoSOTA
Wecompareourmodelagainststate-of-the-artgenerativemodelsonCIFAR-10. Quantitativeresults
aresummarizedinTable1. OurfindingsrevealthatuDDDMsexceedpreviousdistillationdiffusion
models and methods that require advanced sampling procedures in both one-step and two-step
generation, which breaks the reliance on the well-pretrained diffusion models and simplifies the
generation workflow. Moreover, our model demonstrates performance comparable to numerous
leading generative models for both VE and VP settings. Specifically, baseline uDDDM obtains
FIDsof2.91and2.84forone-stepgenerationinVEandVPrespetively,bothresultsexceedthat
ofStyleGAN2-ADA[13]. With1000-stepsampling,ourVPbaselinefurtherreducesFIDto1.73,
outperformingstate-of-the-artmethod[14]. Fordeeperarchitecture,ourmodelachievesone-step
generationwithFIDof2.63and2.53forVEandVPrespectively. Additionally,VP-deepoutperforms
theleadingmodeliCT-deep[28]ontwo-stepgeneration. With1000-stepsampling,VE-deepand
VP-deeppushFIDto1.71and1.65respectively,settingstate-of-the-artperformanceinbothcases.
5 RelatedWorks
Severalone-stepgenerativemodelshavebeenproposedtoimprovetheeffectivenessofinference
process,includingtheConsistencyModels(CMs)[29,28],ConsistencyTrajectoryModels(CTMs)
[15] and TRACT [2]. CMs are available in two variations: Consistency Distillation (CD) and
ConsistencyTraining(CT).CMsfocusonenforcingtheself-consistencypropertyandshareadeep
mathematicalconnectionwithScore-basedgenerativemodels(SGMs)[31]andEDMs[11]. Itis
accomplishedbytracinganypointalongthepathofthesameProbabilityFlowOrdinaryDifferential
Equation(PFODE)backtothestartingpointofthetrajectory. CTMsgeneralizeCMsandSGMs,and
areproposedtoaddresschallengesinscore-basedanddistillationsamplingmethods,bycombining
decoding strategies for sampling either through SDE/ODE or direct jumps along the PF ODE
trajectory. TRACT is a distillation-only method that demonstrates how separating the diffusion
trajectoryintostagescanenhanceperformance. Itsmethodologyissimilartoconsistencydistillation.
Thesemodelskeeptheadvantagesofmulti-stepsamplingforbettersamplequalitywhiledrastically
decreaseinferencetimebygeneratingsamplesinasinglestep.
6 DiscussionandLimitations
Inthispaper,wepresentuDDDM,aunifiedframeworkthatcanhandlebothVPandVEscenarios,
showcasingitsversatilityandrobustness. Theintroductionofanadaptivelossfunctionplaysacrucial
roleinthisframework,enablingthegenerationofimageswithFIDscoresthatarecomparabletoor
evensurpassexistingbenchmarks. Additionally,thetheoreticalfoundationsofuDDDMaresolidified
through a series of proofs, further validating the proposed model’s properties and effectiveness.
ExperimentalresultsonCIFAR10underscorethepotentialofuDDDMinadvancingthestate-of-the-
artinthefieldofdiffusionmodels.
SinceuDDDMkeepstrackofx(n)foreachsampleinthedataset,therewillbeadditionalmemory
0
consumptionduringtraining. Specifically,itrequiresextra614MBforCIFAR10. Althoughitcan
behalvedbyusingFP16datatype,suchmemoryrequirementmightstillbeachallengeforlarger
datasetordatasetwithhigh-resolutionimages. Onesolutionistostorex(n) inabufferorondisk
0
insteadofontheGPU.However,thisapproachwillintroduceadditionaloverheadduringtraining
duetotheneedtotransferdatabacktotheGPU.
WehaveobservedthatourVEmodelconsistentlyunderperformscomparedtotheVPmodelacross
allexperiments. Wehypothesizethatthisperformancegapmaybeattributedtosuboptimalhyper-
parametersinthelossfunction. Specifically,ourcurrentchoiceofthehyperparametercfortheVE
modelisderivedfromthecorrespondingvalueusedfortheVPmodel. However,theoptimalvalue
forcintheVEmodelmightrequirefurtherfine-tuningtoachievebetterperformance. Additionally,
werecognizethatdifferentnoiseschedulerscansignificantlyimpactthemodel’sperformance. The
noiseschedulingstrategyplaysacrucialroleinthetrainingdynamicsandfinalperformanceofthe
model. Weplantoinvestigatemorecomplexschedulersinfuturework.
9References
[1] BrianD.O.Anderson. Reverse-timediffusionequationmodels. StochasticProcessesandtheir
Applications,12(3):313–326,1982.
[2] DavidBerthelot,ArnaudAutef,JieruiLin,DianAngYap,ShuangfeiZhai,SiyuanHu,Daniel
Zheng,WalterTalbot,andEricGu. Tract: Denoisingdiffusionmodelswithtransitiveclosure
time-distillation. arXivpreprintarXiv:2303.04248,2023.
[3] ValentinDeBortoli,JamesThornton,JeremyHeng,andArnaudDoucet. Diffusionschrödinger
bridgewithapplicationstoscore-basedgenerativemodeling,2023.
[4] AndrewBrock,JeffDonahue,andKarenSimonyan. Largescalegantrainingforhighfidelity
naturalimagesynthesis. arXivpreprintarXiv:1809.11096,2018.
[5] P.Charbonnier,L.Blanc-Feraud,G.Aubert,andM.Barlaud. Deterministicedge-preserving
regularizationincomputedimaging. IEEETransactionsonImageProcessing,6(2):298–311,
1997.
[6] JiaDeng, WeiDong, RichardSocher, Li-JiaLi, KaiLi, andLiFei-Fei. Imagenet: Alarge-
scalehierarchicalimagedatabase. In2009IEEEconferenceoncomputervisionandpattern
recognition,pages248–255.Ieee,2009.
[7] Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis.
Advancesinneuralinformationprocessingsystems,34:8780–8794,2021.
[8] MartinHeusel,HubertRamsauer,ThomasUnterthiner,BernhardNessler,andSeppHochreiter.
Ganstrainedbyatwotime-scaleupdateruleconvergetoalocalnashequilibrium. Advancesin
neuralinformationprocessingsystems,30,2017.
[9] JonathanHo,AjayJain,andPieterAbbeel. Denoisingdiffusionprobabilisticmodels. Advances
inneuralinformationprocessingsystems,33:6840–6851,2020.
[10] JonathanHoandTimSalimans. Classifier-freediffusionguidance,2022.
[11] Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine. Elucidating the design space
ofdiffusion-basedgenerativemodels. AdvancesinNeuralInformationProcessingSystems,
35:26565–26577,2022.
[12] TeroKarras, SamuliLaine, MiikaAittala, JanneHellsten, JaakkoLehtinen, andTimoAila.
Analyzing and improving the image quality of stylegan. In Proceedings of the IEEE/CVF
conferenceoncomputervisionandpatternrecognition,pages8110–8119,2020.
[13] TeroKarras, SamuliLaine, MiikaAittala, JanneHellsten, JaakkoLehtinen, andTimoAila.
Analyzing and improving the image quality of stylegan. In Proceedings of the IEEE/CVF
conferenceoncomputervisionandpatternrecognition,pages8110–8119,2020.
[14] DongjunKim, YeongminKim, SeJungKwon, WanmoKang, andIl-ChulMoon. Refining
generativeprocesswithdiscriminatorguidanceinscore-baseddiffusionmodels. arXivpreprint
arXiv:2211.17091,2022.
[15] DongjunKim, Chieh-HsinLai, Wei-HsiangLiao, NaokiMurata, YuhtaTakida, Toshimitsu
Uesaka, Yutong He, Yuki Mitsufuji, and Stefano Ermon. Consistency trajectory models:
Learningprobabilityflowodetrajectoryofdiffusion,2024.
[16] ZhifengKong,WeiPing,JiajiHuang,KexinZhao,andBryanCatanzaro. Diffwave: Aversatile
diffusionmodelforaudiosynthesis. InInternationalConferenceonLearningRepresentations,
2021.
[17] AlexKrizhevsky,GeoffreyHinton,etal. Learningmultiplelayersoffeaturesfromtinyimages.
2009.
[18] XingchaoLiu,ChengyueGong,andQiangLiu. Flowstraightandfast: Learningtogenerate
andtransferdatawithrectifiedflow. arXivpreprintarXiv:2209.03003,2022.
10[19] Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. Dpm-solver:
Afastodesolverfordiffusionprobabilisticmodelsamplinginaround10steps. Advancesin
NeuralInformationProcessingSystems,35:5775–5787,2022.
[20] Eric Luhman and Troy Luhman. Knowledge distillation in iterative generative models for
improvedsamplingspeed. arXivpreprintarXiv:2101.02388,2021.
[21] WeijianLuo,TianyangHu,ShifengZhang,JiachengSun,ZhenguoLi,andZhihuaZhang. Diff-
instruct: Auniversalapproachfortransferringknowledgefrompre-traineddiffusionmodels.
arXivpreprintarXiv:2305.18455,2023.
[22] Vadim Popov, Ivan Vovk, Vladimir Gogoryan, Tasnima Sadekova, Mikhail Kudinov, and
Jiansheng Wei. Diffusion-based voice conversion with fast maximum likelihood sampling
scheme,2022.
[23] RobinRombach,AndreasBlattmann,DominikLorenz,PatrickEsser,andBjörnOmmer. High-
resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF
conferenceoncomputervisionandpatternrecognition,pages10684–10695,2022.
[24] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton,
Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al.
Photorealistictext-to-imagediffusionmodelswithdeeplanguageunderstanding. Advancesin
NeuralInformationProcessingSystems,35:36479–36494,2022.
[25] TimSalimans,IanGoodfellow,WojciechZaremba,VickiCheung,AlecRadford,andXiChen.
Improvedtechniquesfortraininggans. Advancesinneuralinformationprocessingsystems,29,
2016.
[26] AxelSauer,TeroKarras,SamuliLaine,AndreasGeiger,andTimoAila. StyleGAN-T:Unlock-
ingthepowerofGANsforfastlarge-scaletext-to-imagesynthesis. volumeabs/2301.09515,
2023.
[27] JiamingSong,ChenlinMeng,andStefanoErmon. Denoisingdiffusionimplicitmodels. arXiv
preprintarXiv:2010.02502,2020.
[28] YangSongandPrafullaDhariwal. Improvedtechniquesfortrainingconsistencymodels. arXiv
preprintarXiv:2310.14189,2023.
[29] YangSong,PrafullaDhariwal,MarkChen,andIlyaSutskever. Consistencymodels. arXiv
preprintarXiv:2303.01469,2023.
[30] Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data
distribution,2020.
[31] YangSong,JaschaSohl-Dickstein,DiederikPKingma,AbhishekKumar,StefanoErmon,and
BenPoole. Score-basedgenerativemodelingthroughstochasticdifferentialequations. arXiv
preprintarXiv:2011.13456,2020.
[32] NitishSrivastava,GeoffreyHinton,AlexKrizhevsky,IlyaSutskever,andRuslanSalakhutdinov.
Dropout: asimplewaytopreventneuralnetworksfromoverfitting. Thejournalofmachine
learningresearch,15(1):1929–1958,2014.
[33] ArashVahdatandJanKautz. Nvae: Adeephierarchicalvariationalautoencoder. Advancesin
neuralinformationprocessingsystems,33:19667–19679,2020.
[34] ArashVahdat,KarstenKreis,andJanKautz. Score-basedgenerativemodelinginlatentspace.
AdvancesinNeuralInformationProcessingSystems,34:11287–11302,2021.
[35] YilunXu,ZimingLiu,MaxTegmark,andTommiJaakkola. Poissonflowgenerativemodels.
AdvancesinNeuralInformationProcessingSystems,35:16782–16795,2022.
[36] DanZhang,JingjingWang,andFengLuo. Directlydenoisingdiffusionmodel,2024.
[37] Qinsheng Zhang and Yongxin Chen. Fast sampling of diffusion models with exponential
integrator. arXivpreprintarXiv:2204.13902,2022.
11[38] RichardZhang,PhillipIsola,AlexeiAEfros,EliShechtman,andOliverWang. Theunrea-
sonable effectiveness of deep features as a perceptual metric. In Proceedings of the IEEE
conferenceoncomputervisionandpatternrecognition,pages586–595,2018.
[39] WenliangZhao,LujiaBai,YongmingRao,JieZhou,andJiwenLu. Unipc: Aunifiedpredictor-
correctorframeworkforfastsamplingofdiffusionmodels. arXivpreprintarXiv:2302.04867,
2023.
[40] HongkaiZheng,WeiliNie,ArashVahdat,KamyarAzizzadenesheli,andAnimaAnandkumar.
Fast sampling of diffusion models via operator learning. In International Conference on
MachineLearning,pages42390–42402.PMLR,2023.
12A Appendix/supplementalmaterial
ProofofTheorem1:
Suppose that there are two solutions x˜ and y˜ to the initial value problem with the same initial
t t
conditionx˜ =y˜ =xˆ .
0 0 t
Letz =x˜ −y˜ . ThenThefunctionz satisfiesthedifferentialequation:
t t t t
dz dx˜ dy˜ (cid:16) (cid:17) (cid:16) (cid:17)
s = s − s =h x˜(n),x˜ ,s −h y˜(n),y˜ ,s
ds ds ds θ t s θ t s
UsingthegivenLipschitzcondition:
(cid:13) (cid:16) (cid:17) (cid:16) (cid:17)(cid:13)
(cid:13)h x˜(n),x˜ ,s −h y˜(n),y˜ ,s (cid:13) ≤L∥x˜ −y˜ ∥
(cid:13) θ t s θ t s (cid:13) s s 2
2
wehave:
(cid:13) (cid:13)
(cid:13)
(cid:13)
(cid:13)d dz ss(cid:13)
(cid:13)
(cid:13)
≤L∥z s∥
2
2
Grönwall’sinequalitystatesthatifβ andubereal-valuedcontinuousfunctionsdefinedon[0,t]and
uisdifferentiableintheinterior(0,t)andsatisfiesthedifferentialinequality
u′(s)≤β(s)u(s), s∈(0,t)
thenuisboundedbythesolutionofthecorrespondingdifferentialequation
(cid:18)(cid:90) s (cid:19)
u(s)≤u(a)exp β(v)dv , s∈(0,t)
0
Letu(s)=∥z ∥ . ApplyingGrönwall’sinequality,weobtain
s 2
∥z ∥ ≤∥z ∥ exp(Lt)
s 2 0 2
Sincez =x˜ −y˜ =xˆ −xˆ =0,leadingto
0 0 0 t t
∥z ∥ =0
0 2
Therefore,foralls∈[0,t]:
∥z ∥ ≤0exp(Ls)=0
s 2
whichimpliesz =0foralls∈[0,t].
s
Hence,wehavex =y forallt∈[0,T],indicatingthatthereisatmostonesolutiontotheinitial
t t
valueproblem.
ProofofTheorem2
Asnsufficientlylarge,L(n) (θ)→0,wehave
uDDDM
(cid:18) (cid:19)
1
1− L(n)(θ)→0
n+1 Iter
implies:
(cid:104) (cid:16) (cid:16) (cid:17) (cid:17)(cid:105)
E d f x(n),x ,t ,x(n) =0
x0,xt,t θ 0 t 0
whichmeansthat
(cid:16) (cid:16) (cid:17) (cid:17)
d f x(n),x ,t ,x(n) =0
θ 0 t 0
sinced(x,y)=0⇔x=y,itfurtherimplies:
(cid:16) (cid:17)
f x(n),x ,t =x(n), forlargeenoughn.
θ 0 t 0
13Letx∗ =x(n)asnlargeenough. Next,fromtheexpressionthat
0 0
(cid:16) (cid:17) (cid:16) (cid:17)
f x(n),x ,t =x −F x(n),x ,t
θ 0 t t θ 0 t
wehave:
(cid:16) (cid:17)
x∗ =x −F x(n),x ,t
0 t θ 0 t
(cid:16) (cid:17)
Further,weintegralbothsidesof d dx ss =−h θ x( 0n),x s,s andobtain:
(cid:90) 0 (cid:16) (cid:17)
x =x − h x(n),x ,s ds
0 t θ 0 s
t
(cid:16) (cid:17)
=x −F x(n),x ,t .
t θ 0 t
ByTheorem1,thesolutionoftheIVPisunique,whichleadstox∗ =x .
0 0
Therefore,weobtain:
(cid:16) (cid:17)
f x(n),x ,t →x , asnsufficientlylarge.
θ 0 t 0
andcompletetheproof.
ProofofTheorem3:
ConsidertheIVPEquation(6):
 dx˜
 s =h (x˜(n),x˜ ,s) s∈[0,t]
ds θ∗ t s
 x˜ =xˆ
0 t
FromtheLipschitzconditiononh ,wehave:
θ
(cid:13) (cid:13)
(cid:13)h (x˜(n),x˜ ,s)−h (y˜(n),y˜ ,s)(cid:13) ≤L∥x˜ −y˜ ∥ .
(cid:13) θ∗ t s θ∗ t s (cid:13) s s 2
2
Usetheintegralform:
(cid:13) (cid:16) (cid:17) (cid:16) (cid:17)(cid:13) (cid:90) t
(cid:13)f x(n),x ,t −f y(n),y ,t (cid:13) ≤∥x˜ −y˜ ∥ + L∥x˜ −y˜ ∥ ds
(cid:13) θ∗ 0 t θ∗ 0 t (cid:13) 0 0 2 s s 2
2 0
ByusingGröwnwallinequality,wehave:
(cid:13) (cid:16) (cid:17) (cid:16) (cid:17)(cid:13)
(cid:13)f x(n),x ,t −f y(n),y ,t (cid:13) ≤eLt∥x˜ −y˜ ∥ =eLt∥x −y ∥
(cid:13) θ∗ 0 t θ∗ 0 t (cid:13) 0 0 2 t t 2
2
Next,considertheinversetimeODEEquation(5),wehave:
(cid:13) (cid:13) (cid:90) t
∥x −y ∥ ≤(cid:13)f (x(n),x ,t)−f (y(n),y ,t)(cid:13) + L∥x −y ∥ ds
t t 2 (cid:13) θ∗ 0 t θ∗ 0 t (cid:13) s s 2
2 0
Again,byusingGröwnwallinequality,
(cid:13) (cid:13)
∥x −y ∥ ≤eLt(cid:13)f (x(n),x ,t)−f (y(n),y ,t)(cid:13)
t t 2 (cid:13) θ∗ 0 t θ∗ 0 t (cid:13)
2
Therefore,
(cid:13) (cid:16) (cid:17) (cid:16) (cid:17)(cid:13)
(cid:13)f x(n),x ,t −f y(n),y ,t (cid:13) ≥e−Lt∥x −y ∥
(cid:13) θ∗ 0 t θ∗ 0 t (cid:13) t t 2
2
andwecompletetheproofof:
(cid:13) (cid:13)
e−Lt∥x −y ∥ ≤(cid:13)f (x(n),x ,t)−f (y(n),y ,t)(cid:13) ≤eLt∥x −y ∥ .
t t 2 (cid:13) θ∗ 0 t θ∗ 0 t (cid:13) t t 2
2
14(a)One-stepsamplesfromtheuDDDM-VEmodel(FID=2.91).
(b)Two-stepsamplesfromtheuDDDM-VEmodel(FID=2.68).
(c)1000-stepsamplesfromtheuDDDM-VEmodel(FID=1.89).
Figure3: UncuratedsamplesfromtheuDDDM-VEmodel. Allcorrespondingsamplesusethesame
initialnoise.
15(a)One-stepsamplesfromtheuDDDM-VE-deepmodel(FID=2.63).
(b)Two-stepsamplesfromtheuDDDM-VE-deepmodel(FID=2.35).
(c)1000-stepsamplesfromtheuDDDM-VE-deepmodel(FID=1.65).
Figure4: UncuratedsamplesfromtheuDDDM-VE-deepmodel. Allcorrespondingsamplesusethe
sameinitialnoise.
16(a)One-stepsamplesfromtheuDDDM-VPmodel(FID=2.84).
(b)Two-stepsamplesfromtheuDDDM-VPmodel(FID=2.50).
(c)1000-stepsamplesfromtheuDDDM-VPmodel(FID=1.73).
Figure5: UncuratedsamplesfromtheuDDDM-VPmodel. Allcorrespondingsamplesusethesame
initialnoise.
17(a)One-stepsamplesfromtheuDDDM-VP-deepmodel(FID=2.53).
(b)Two-stepsamplesfromtheuDDDM-VP-deepmodel(FID=2.21).
(c)1000-stepsamplesfromtheuDDDM-VP-deepmodel(FID=1.65).
Figure6: UncuratedsamplesfromtheuDDDM-VP-deepmodel. Allcorrespondingsamplesusethe
sameinitialnoise.
18