Designing for Fairness in Human-Robot Interactions
Houston Claure
Department of Computer Science
Yale University
I. INTRODUCTION&MOTIVATION
Thefoundationofsuccessfulhumancollaborationisdeeply
rooted in the principles of fairness [10]. As robots are in- High Skill
creasingly prevalent in various parts of society where they are Low Skill
workingalongsidegroupsandteamsofhumans,theirabilityto
understandandactaccordingtoprinciplesoffairnessbecomes
Participant 1 Participant 2
crucialfortheireffectiveintegration.Thisisespeciallycritical Skill Level Skill Level
when robots are part of multi-human teams, where they
Fig.1. Considerascenariowherearobothastomakedecisionsonhowto
must make continuous decisions regarding the allocation of distributeresourcesacrosstwoteammembers.However,oneteammemberis
resources.Theseresourcescanbematerial,suchastools[11], moreskilledthantheother.Howshouldarobottakeskilllevelintoaccount
when dividing its resources to maximize both efficiency and also fairness?
or communicative, such as gaze direction [? 13], and must
This example encapsulates the nuanced responsibility that robots have in
be distributed fairly among team members to ensure optimal humanteams:toenhanceproductivitywhilefosteringanenvironmentoftrust
team performance and healthy group dynamics (see Fig. 1 for andequality.
anexample).Therefore,ourresearchfocusesonunderstanding
ing of how robots can adopt human concepts of fairness,
howrobotscaneffectivelyparticipatewithinhumangroupsby
thereby enhancing their integration as effective team mem-
making fair decisions while contributing positively to group
bers.. Specifically, my work is focused on three research
dynamics and outcomes.
thrusts:1)buildingplatformstocapturelarge-scaleteamdata,
The growing reliance on intelligent systems emphasizes 2) expanding our understanding of how unfair robot actions
the importance that fairness plays in their decision-making shapeinterpersonalrelationships,and3)developingalgorithms
processes, especially as Artificial Intelligence (AI) technolo- that embed fairness into robot decision-making.
gies are increasingly employed for critical decisions like loan
eligibility [2], university admissions [1], and job interviews II. PRIORWORK
[15]. However, it is important to differentiate between the A. Buildingplatformstocapturedatafrommulti-agentgroups
fairness concerns associated with the algorithms referenced
I have devised two novel experimental platforms aimed at
above, where their decisions are one-time occurrences, and
exploringtheimplicationsoffairnessinHRIwithinthecontext
those made by robots, which require continuous decision-
of group dynamics. These platforms are key assets for the
making (e.g., the robot in Fig 1. makes multiple allocation
evolution of HRI research. Similar to how simulations have
decisions during the collaborative task) [7, 4]. Furthermore,
fueled advancements in robotics areas like physical manipu-
unlike the machine learning algorithms that make one-shot
lation [14], easy-to-adapt experimental platforms are essential
decisions, robots are embodied and operate in dynamic en-
to facilitate the systematic analysis of social interactions and
vironments. This means that robot’s actions can lead to harm
make strides in our understanding of the role of fairness in
oftennotconsideredinotherareasoffairnessresearch,suchas
HRI.
physical harm. Examples include self-driving cars that fail to
1) Co-Tetris for Online Experiments: I developed Co-
recognize darker-skinned individuals [19], caregiving robots
Tetris as an innovative research tool designed to study collec-
that offer unequal support among patients [20], and factory
tive problem-solving and decision-making. Unlike traditional
robots that assign tasks unevenly across human workers [16].
Tetris 1, which is a single player game, Co-Tetris necessitates
Despite these challenges, current research in human-robot
cooperation, requiring players to coordinate their actions in
interaction (HRI) is largely focused on dyadic interactions
real-time.Thiscollaborativetwistontheclassicgamepresents
between a single robot and a human [3], overlooking the
a unique way to examine how individuals communicate and
complex dynamics that emerge within larger groups [17, 18].
strategize towards a shared objective. What makes Co-Tetris
This gap underscores the need for more research on fairness
a significant contribution is its utility as a research platform.
in robotics, taking into account the continuous and context-
It is a versatile tool that can simulate various collaborative
dependent nature of robot decision-making in diverse human-
scenarios,offeringinsightsintogroupdynamicsandindividual
robot teams.
roles within a team. By capturing quantitative data on player
My work aims to develop computational tools and tech-
niques to help overcome the limitations in our understand- 1https://github.com/hbclaure/Co Tetris
4202
yaM
13
]OR.sc[
1v44012.5042:viXraperformance and behavior, it provides empirical evidence on
Shutter Nao
howpeopleworktogetherunderdifferentconditions,including
variable difficulties and learning curves. This platform has
been instrumental in studies examining fairness and social
behavior providing empirical data to inform theories in these
domains [6, 8]. The adaptability of Co-Tetris to various
experimental settings makes it a valuable asset for exploring
a wide spectrum of research questions relevant to fairness in REPLACE PICTURE
human-robot teams.
2) MultiplayerSpaceInvadersforLaboratoryExperiments:
TheMultiplayerSpace InvadersGame[9]was developedasa
platform for analyzing robot decision-making in live, compet-
itive settings. This game extends a traditional Space Invaders Online Experiments In-Person Experiments
gametoamultiplayergamewhereplayersworktoeliminateas
Fig. 2. Co-Tetris: a platform for observing group behavior in the face of
manyenemyspaceshipsontheirsideofthescreenaspossible.
unfairAIdecisions.Irananexperimentwhereoneplayerwaspresentedas
Each player commands an individual spaceship, differentiated anintelligentsystemanddisproportionatelyallocatedfallingTetrisblocksto
by color. The adversaries in the game are represented as alien oneplayer(left).MultiplayerSpaceInvaders:arobotandahumanparticipant
competed to eliminate as many enemies on the screen as possible. A third
spaceships and organized into two distinct clusters on the
robot disproportionately supported one player by helping them eliminate
display. A third player can support one of the two players enemiesforlongerperiodsoftime.
by moving to help eliminate the cluster of enemies on the problemofarobotdistributingresourcesacrossteammembers
leftorrightside.Partofthenoveltybehindthegame’sdesign with varying skill levels through the lens of the multi-armed
liesinthatitincorporatesnumerousdecision-makingmoments bandit framework. This led to the development of the strict-
for the supportive player, providing a framework to analyze rate-constrained upper confidence bound algorithm (UCB) as
different decision patterns and investigate how they evolve a viable solution [6]. This novel algorithm allows a robot to
temporally. learn about the skill level of each teammate by observing
their performance over time while including a constraint on
B. Building Theory on How Unfair Robot Actions Shape
the minimum rate each human teammate can be selected
Human Group Dynamics
to receive a resource throughout the course of a task. I
In a series of studies – aimed at exploring the impact of provided theoretical guarantees on performance and proved
robotsongroupdynamicsandperceptionsoffairness[5,8,12] that this algorithm has similar regret bounds to the original
– I investigated how robots’ resource distribution behaviors, unconstrained UCB. To evaluate our algorithm, I deployed
a phenomenon I termed “machine allocation behavior”, affect the strict rate-constrained UCB on the Co-Tetris platform,
human interactions. Through the use of a novel tower con- adjusting the level of fairness (the number of blocks a lower-
struction task [12] and the Co-Tetris platform [8], I analyzed skilled player would receive control over). Our large-scale
interactionsingroupsandfoundthatunfairresourceallocation online study (n = 290 participants) showed that fairness in
by robots could lead to tension among team members and resource distribution has a significant effect on users’ trust in
affect team performance, highlighting the importance of fair robots.
decisions in human-robot collaboration. A key finding from
our experiments suggests that team members who receive
III. FUTUREWORK
more resources from an intelligent machine have feelings Motivated by people’s inherent drive for equity and justice,
of empowerment over their teammates. Expanding on these my research envisions a future where collaborative robots
findings,Isoughttopredictperceptionsoffairnessindynamic proactively promote fairness within teams, enhancing group
interactions. I used the Multiplayer Space Invaders game to harmony and success. This vision encompasses three main
demonstratehowfairnessjudgmentsevolveoverthecourseof objectives: establishing fairness benchmarks in Human-Robot
aninteraction[5](seeFig.2).Ifoundthatthetimingofunfair Interaction(HRI)acrossdiversedomainslikeeducation,retail,
actions from a robot influences how perceptions of fairness law enforcement, and healthcare; developing methods for
evolve over time. Collectively, these studies underscore the learning to enable robots to adapt their actions based on user
nuanced role of robots in shaping interpersonal dynamics and feedback in real time, thereby aligning closer with human
fairnessperceptions,contributingtoadeeperunderstandingof expectationsoffairness;andexpandingtheoreticalunderstand-
human-robot interaction and informing the design of fair and ing of fairness in HRI, exploring dynamics of explainability
transparent robotic systems. and transparency influenced by cultural and gender factors.
Through a multifaceted approach, including online surveys
C. Designing Algorithms that Consider Fairness
and lab studies, my work aims to develop robots that not only
This research thrust aims to answer how we can include recognize but also rectify disparities, ensuring fair treatment
concepts key to group work, such as fairness, into a robot’s for all team members and fostering effective human-robot
decision-making process. Toward this goal, I explored the collaboration.REFERENCES pact of a robot’s allocation behavior on interpersonal
dynamicsandcollaborationingroups.ACMTransactions
[1] Mohsen Attaran, John Stark, and Derek Stotler. Oppor- on Human-Robot Interaction (THRI), 10(1):1–23, 2020.
tunitiesandchallengesforbigdataanalyticsinushigher [13] Bilge Mutlu, Toshiyuki Shiwa, Takayuki Kanda, Hiroshi
education: A conceptual model for implementation. In- Ishiguro, and Norihiro Hagita. Footing in human-robot
dustry and Higher Education, 32(3):169–182, 2018. conversations: how robots might shape participant roles
[2] NeilBhutta,AurelHizmo,andDanielRingo. Howmuch using gaze cues. In Proceedings of the 4th ACM/IEEE
does racial bias affect mortgage lending? evidence from international conference on Human robot interaction,
human and algorithmic credit decisions. 2022. pages 61–68, 2009.
[3] Min Chen, Stefanos Nikolaidis, Harold Soh, David Hsu, [14] Suraj Nair, Aravind Rajeswaran, Vikash Kumar, Chelsea
and Siddhartha Srinivasa. Planning with Trust for Finn, and Abhinav Gupta. R3m: A universal visual
Human-Robot Collaboration. In ACM/IEEE Interna- representation for robot manipulation. arXiv preprint
tional Conference on Human-Robot Interaction, 2018. arXiv:2203.12601, 2022.
ISBN 9781450349536. doi: 10.1145/3171221.3171264. [15] Manish Raghavan, Solon Barocas, Jon Kleinberg, and
[4] Houston Claure and Malte Jung. Fairness considerations Karen Levy. Mitigating bias in algorithmic hiring: Eval-
for enhanced team collaboration. In Companion of the uating claims and practices. In Proceedings of the 2020
2021 ACM/IEEE International Conference on Human- conferenceonfairness,accountability,andtransparency,
Robot Interaction, pages 598–600, 2021. pages 469–481, 2020.
[5] HoustonClaure,KateCandon,OliviaClark,andMarynel [16] Fabian Ranz, Vera Hummel, and Wilfried Sihn.
Va´zquez. Dynamic fairness perceptions in human-robot Capability-based task allocation in human-robot collab-
interaction. In Computer supported cooperative work oration. Procedia Manufacturing, 9:182–189, 2017.
(CSCW) ’24’ (Submitted). [17] SarahStrohkorbSebo,MargaretTraeger,MalteJung,and
[6] HoustonClaure,YifangChen,JigneshModi,MalteJung, Brian Scassellati. The ripple effects of vulnerability:
and Stefanos Nikolaidis. Multi-armed bandits with The effects of a robot’s vulnerable behavior on trust
fairness constraints for distributing resources to human in human-robot teams. In Proceedings of the 2018
teammates. In Proceedings of the 2020 ACM/IEEE ACM/IEEE International Conference on Human-Robot
International Conference on Human-Robot Interaction, Interaction, pages 178–186, 2018.
pages 299–308, 2020. [18] Hamish Tennent, Solace Shen, and Malte Jung. Micbot:
[7] Houston Claure, Mai Lee Chang, Seyun Kim, Daniel A peripheral robotic object to shape conversational dy-
Omeiza, Martim Brandao, Min Kyung Lee, and Malte namics and team performance. In 2019 14th ACM/IEEE
Jung. Fairness and transparency in human-robot interac- International Conference on Human-Robot Interaction
tion. In 2022 17th ACM/IEEE International Conference (HRI), pages 133–142. IEEE, 2019.
on Human-Robot Interaction (HRI), pages 1244–1246. [19] Benjamin Wilson, Judy Hoffman, and Jamie Morgen-
IEEE, 2022. stern. Predictive inequity in object detection. arXiv
[8] HoustonClaure,SeyunKim,Rene´ FKizilcec,andMalte preprint arXiv:1902.11097, 2019.
Jung. The social consequences of machine allocation [20] Gary Chan Kok Yew. Trust in and ethical design of
behavior: Fairness, interpersonal perceptions and perfor- carebots: the case for ethics of care. International
mance. Computers in Human Behavior, 146:107628, Journal of Social Robotics, 13(4):629–645, 2021.
2023.
[9] HoustonClaure,KateCandon,OliviaClark,andMarynel
Va´zquez. Multiplayer space invaders: A platform for
studying evolving fairness perceptions in human-robot
interaction. In Companion of the 2024 ACM/IEEE
International Conference on Human-Robot Interaction,
pages 347–350, 2024.
[10] Ernst Fehr and Klaus M Schmidt. A theory of fairness,
competition, and cooperation. The quarterly journal of
economics, 114(3):817–868, 1999.
[11] Matthew C Gombolay, Reymundo A Gutierrez,
Shanelle G Clarke, Giancarlo F Sturla, and Julie A
Shah. Decision-making authority, team efficiency and
humanworkersatisfactioninmixedhuman–robotteams.
Autonomous Robots, 39:293–312, 2015.
[12] Malte F Jung, Dominic DiFranzo, Solace Shen, Brett
Stoll, Houston Claure, and Austin Lawrence. Robot-
assisted tower construction—a method to study the im-