Concentration Bounds for Optimized Certainty
Equivalent Risk Estimation
AyonGhosh
DepartmentofComputerScienceandEngineering
IndianInstituteofTechnologyMadras
cs21b013@smail.iitm.ac.in
PrashanthL.A.
DepartmentofComputerScienceandEngineering
IndianInstituteofTechnologyMadras
prashla@cse.iitm.ac.in
KrishnaJagannathan
DepartmentofElectricalEngineering
IndianInstituteofTechnologyMadras
krishnaj@ee.iitm.ac.in
Abstract
WeconsidertheproblemofestimatingtheOptimizedCertaintyEquivalent(OCE)
riskfromindependentandidenticallydistributed(i.i.d.) samples. Fortheclassic
sampleaverageapproximation(SAA)of OCE, we derivemean-squarederroras
wellasconcentrationbounds(assumingsub-Gaussianity).Further,weanalyzean
efficientstochasticapproximation-basedOCEestimator,andderivefinitesample
boundsforthesame. Toshowtheapplicabilityofourbounds,weconsiderarisk-
awarebanditproblem,withOCEastherisk.Forthisproblem,wederiveboundon
theprobabilityofmis-identification. Finally, we conductnumericalexperiments
tovalidatethetheoreticalfindings.
1 Introduction
A majorconsiderationin financialand clinicalapplicationsis the quantificationof the risk associ-
atedwithfuturerandomoutcomes. InthepioneeringframeworkofMarkovitz,thevarianceofthe
underlyingrandomvariableisconsideredasameasureofrisk,andtheobjectiveistomaximizethe
expectedvaluesubjecttoaconstraintontherisk,ortomaximizeanaffinefunctionofthemeanand
variance[16].Subsequently,anotherlandmarkpaper[1]proposedanaxiomaticapproachtorisk,by
imposingfourpropertiestobesatisfiedbytheriskmeasure.
Specifically,forar.v. X andarealvaluedfunctionρ,[1]imposesthepropertiesofbeingpositively
homogeneous, sub-additive, translation invariant and monotone for a risk measure ρ(X). A risk
measure that satisfies all these properties is called a coherent risk measure. In [9], the authors
relaxedtheconditionsofsub-additivityandpositivehomogeneity,andreplacedthemwithaweaker
propertyofconvexity,i.e.,
ρ(λX +(1 λ)Y) λρ(X)+(1 λ)ρ(Y), λ [0,1], (1)
− ≤ − ∀ ∈
andsuchariskmeasureissaidtobeconvex.
Preprint.Underreview.
4202
yaM
13
]GL.sc[
1v33902.5042:viXraOptimizedCertainty Equivalent(OCE) is a family of convexrisk measures, introducedin [4] and
exploredfurtherin[3].Qualitatively,OCEisaclassofriskmeasureswhichservesasanindicatorof
theinvestor’sriskappetite,particularlycapturingtheoptimalallocationofresources/lossesbetween
thepresentandthefuture.Supposethetotallossthataninvestorcouldincurinthefutureisarandom
variableX. Theinvestorhastheoptiontoallocateafractionoftheiruncertainlosses,denotedbyξ,
tothepresent. Consequentlythepresentvalueoflossesunderadisutilityfunctionφthenbecomes
ξ+E[φ(X ξ)]. Theoptimalξi.e. theinfimumoverallpossibleallocationsthengivesustheOCE
−
riskoftheinvestor.Weshalldenotethisoptimalξbye inthispaper.
∗
Under suitable choices of the disutility function φ, OCE risk encompasses a wide range of risk
measures, one of which is the widely used risk measure Conditional Value at Risk (CVaR)[24].
GivenarandomvariableXandalevelα (0,1),definetheVaRasv (X)=inf P[X ξ] α .
α ξ
ThentheCVaRc (X)= v (X)+ 1
E∈
[X v (X)]+.
Itcanbeshownthatthi{ sisjus≤ tasp≥ ecia}
l
α α 1 α − α
case of OCE risk measure with the d−isutility function u(X) = 1 (X)+., and e replaced with
1 α ∗
v (X). −
α
Our contributions. In this paper, we consider the problemof estimating the OCE risk from in-
dependent and identically distributed (i.i.d.) samples of the loss distribution. First, we consider
a straightforwardSample Average Estimator for the OCE risk, and bound its mean-squarederror.
Next,wederiveaconcentrationboundfortheSAAestimatorwhentheunderlyinglossdistribution
issub-Gaussian,andthedisutilityfunctionisstronglyconvexandsmooth. ThisOCEriskconcen-
tration bound enjoysa sub-exponentialdecay. We illustrate the applicability of our concentration
boundinamulti-armedbanditsettingwitha‘Best-OCE-arm’identificationproblem.
Next, we considera ‘streaming’setting whereinthe samplesfromthe underlyingloss distribution
areavailableone-at-a-time. Forthisscenario,the sampleaverageestimatorisineffective,because
it requires recomputation for each sample. On the other hand, an iterative estimator that updates
one step at a time upon receiving each fresh sample is better suited for such a streaming setting.
We propose a stochastic approximation-basedestimation procedure for OCE risk estimation. We
then derive finite-sample bounds for the mean-squared error of the iterative OCE risk estimation
procedure.
Relatedwork. Inrecentyears,estimationofriskmeasuresfromi.i.d. sampleshasreceivedalot
ofresearchattention,cf.[13,19,25,7,5,21,20,28,6,17,15].Themajorityofpriorworksconsider
CVaRestimationandderiveconcentrationboundsusuallyunderasub-Gaussianityassumption.
ForOCE riskestimation, boundsareavailablein[6, 14]. Theformerreferenceconsidersdistribu-
tionswithboundedsupport,whilethelatterincludessub-Gaussianandsub-exponentialdistributions.
In[11],theauthorsstudyastochasticapproximation-basedprocedureforOCEriskestimation. In
comparisonto these closely related works, we remarkthe following: (i) Unlike[6], ourOCE risk
estimation bounds are for unbounded albeit sub-Gaussian distributions; (ii) In [14], the authors
employaWassersteindistancebasedapproachforderivingOCEriskconcentrationboundsforLip-
schitz disutility functions. Our present work allows for smooth disutility functions, which cover
mean-varianceriskmeasureasanimportantspecialcase. Moreover,ourproofisdirect,whilethey
use a unified approachto handle severalrisk measuresthat satisfy a continuitycriterion. The flip
sidewiththeirapproachisthattheconstantsintheconcentrationboundsareconservative.Addition-
ally,wederiveaconcentrationboundfortheOCEriskminimizer;(iii)In[11],theauthorsprovide
an asymptotic rate result for their OCE risk estimator, while we quantify the rate of convergence
throughboundsinexpectationaswellashighprobability,inthenon-asymptoticregime.
2 OCERiskMeasure
Definition2.1. Forarandomvariable(r.v.) X,theOCEriskoceφ(X)withadisutilityfunctionφ
isdefinedby
oceφ(X):=inf ξ+E[φ(X ξ)] . (2)
ξ { − }
WedenotetheminimizerofOCEriskbye .
∗
2Asmentionedearlier, OCE riskaccommodatesa wideclass ofpopularriskmeasures, forsuitably
chosen disutility fucntion φ. Some common examples for the disutility function and their corre-
spondingOCEriskexpressionsaregiveninTable1.
Table1:ExamplesofOCErisksandtheircorrespondingminimizers.
Riskmeasure Disutilityfunction OCEriskminimizer OCErisk
Expectedloss ϕ(t)=t e =x, x R oceφ(X)=E[X]
∗
∀ ∈
Entropicrisk ϕ (t)= 1(eγt 1) e = ln(E[eγX]) oceφ(X)= ln(E[eγX])
γ γ − ∗ γ γ
Mean-variance ϕ (t)=t+ct2 e =E[X] oceφ(X)=E[X]+c(Var(X))
c ∗
Conditional
ϕ (t)= 1 [t]+ e =v (X) oceφ(X)=c (X)
Value-at-Risk α 1 α ∗ α α
−
Proposition2.1. Ifthedisutilityfunctionφ : R R+ 0 ,whichisnondecreasing,closed,and
→ ∪{ }
convex satisfies φ(0) = 0 and φ(0) = 1 (see [3, Defn. 2.1]), then the OCE risk, oceφ(X) is a
′
convexriskmeasure(see[3]forderivations).
Itcanbeshown(See [3, Theorem2.1])thattheOCEriskmeasureundertheconditionsofPropo-
sition 2.1 satisfies the following properties, in addition to convexity: (a) Translation invariance:
oceφ(X +c) = oceφ(X)+c, c R; (b) Consistency: oceφ(c) = c, for any constant c R;
∀ ∈ ∈
and (c) Monotonicity: Let Y be any random variable such that X(ω) Y(ω), ω Ω. Then,
≤ ∀ ∈
oceφ(X) oceφ(Y).
≤
3 OCERiskEstimationandConcentration
OCERiskEstimation. Let X ,...,X denoteni.i.d. samplesfromthedistributionF ofX.
1 n
{ }
Usingthesesamples,weestimateoceφ(X)asfollows:
n
φ(X ξ)
oceφ :=inf ξ+ i − . (3)
n ξ ( n )
i=1
X
Wedenotetheminimizerof(3)byeˆ . Forexample,inthecaseofCVaRestimationasdiscussedin
n
[22],eˆ isjustvˆ =X ,with X n beingtheorder-statisticsfor X n .
n n,α [ ⌈(1 −α) ⌉] { [i] }i=1 { i }i=1
Forthen-sample,theempiricaldistributionfunction(EDF)isdefinedby
n
1
F (x)= I X x , x. (4)
n i
n { ≤ } ∀
i=1
X
The OCE risk estimatordefinedabovecan beseen as theOCE risk appliedto a r.v., say Z , with
n
distributionF ,i.e.,oceφ =oce(Z ).
n n n
Usefulexpressionsfore andeˆ . Wedifferentiate(2)andusingthefactthate istheOCErisk
∗ n ∗
minimizer,weobtain
d d
ξ+E[φ(X ξ)] =1+E φ(X ξ) =0 E[φ(X e )]=1. (5)
′ ∗
dξ − dξ − ⇒ −
(cid:16) (cid:17) (cid:20) (cid:0) (cid:1)(cid:21)
wherethesecondequalityfollowsfromDCT(see[8,Theorem4.6.3])viaAssumptionA3.
Leteˆ betheinfimumforoceφ. Then,byargumentssimilartothoseleadingto(5),weobtain
n n
n
1
φ(X eˆ )=1. (6)
′ i n
n −
i=1
X
For deriving the OCE risk estimation bounds, we require assumptions on the tail of the underly-
ing distribution. Two popular tail assumptions are sub-Gaussian and sub-exponential, which are
formalizedbelow.
3Definition 3.1 (Sub-Gaussian distribution). A r.v. X with mean µ = E[X] is sub-Gaussian if
thereisapositiveparameterσsuchthatE[eλ(X −µ)] eσ2 2λ2 , λ.
≤ ∀
Definition3.2(Sub-exponentialdistribution). Ar.v. X withmeanµ=E[X]issub-exponentialif
therearenonnegativeparameters(ν,b)suchthatE[eλ(X −µ)] ≤eν2 2λ2 , ∀|λ |< 1 b.
Bounds for OCE risk estimation. For deriving mean-squared error (MSE) and concentration
boundsforOCEriskestimation,wemakethefollowingassumptions.
A1. Thefunctionφisµ-stronglyconvex.
A2. ThefunctionφisL-smooth,i.e., φ(y) (φ(x)+φ(x)(y x)) L(x y)2, x,y R.
| − ′ − |≤ 2 − ∀ ∈
A3. Thefunctionφ iscontinuouslydifferentiable,andthecollectionofrandomvariables φ (X
′ ′′
t):t R isuniformlyintegrable. { −
∈ }
A4. Ther.v. X issub-Gaussianwithparameterσ.
We now comment on the assumptions made above. Assumption A1 is required for providing
MSE/concentrationboundsfor estimation of OCE risk minimizer e . If the function φ is convex
∗
butnotstronglyconvex,thenitis difficulttoboundeˆ e , since the functioncouldhavea arbi-
n ∗
−
trarilywideplateauarounde . ForthespecialcaseofVaR,suchanassumptionhasbeenmadefor
∗
obtainingconcentrationboundsin[21].InthiscaseAssumptionA1translatestoastrictlyincreasing
distribution,toensureaVaRestimatecanconcentrateasthedistributionisnotflataroundVaR.
In[14],theauthorsassumethedisutilityfunctionφisLipschitzforderivingaconcentrationbound
forOCE risk estimation. Suchan assumptionis restrictivesince itdisallowsa mean-variancerisk
measureviaOCErisk,asinsomeexampleabove.Incontrast,AssumptionA2imposesasmoothness
conditiononφ,inturnallowingariskmeasurewithmean-variancetradeoff.
AssumptionA3isatechnicalassumptionthatensurecertainintegralsarefinite,allowinganapplica-
tionofthedominatedconvergencetheoremtointerchangeexpectationanddifferentiationoperators.
Forthecaseofr.v.swithunboundedsupport,suchanassumptionhasbeenmadeearlierinthecon-
textofanotherriskmeasure,see[10].
Anassumptiononthetailoftheunderlyingdistributionisusuallymadeforderivingconcentration
bounds, cf. [21] for CVaR. In Assumption A4, we impose a sub-Gaussianity requirementon the
underlyingdistribution.
Bounds for estimation of OCE risk minimizer e . The first result that we present is a mean-
∗
squarederrorboundontheestimatoreˆ oftheOCEriskminimizere .
n ∗
Theorem3.1. SupposeAssumptionsA1toA3hold.Further,assumeX hasafinitesecondmoment.
Then,wehavethefollowingboundforeˆ ,whichistheminimizeroftheempiricalOCEriskdefined
n
in(3):
L2 (e )2+E X2 2e E[X]
E (eˆ e )2 ∗ − ∗ , (7)
n − ∗ ≤ nµ2
(cid:0) (cid:2) (cid:3)(cid:1)
(cid:2) (cid:3)
whereListhesmoothnessparameterandµisthestrong-convexityparameterofthedisutilityfunc-
tionφ,ande istheOCEriskminimizer.
∗
Proof. SeeAppendixA
Themean-squarederrorboundintheresultaboveisusefulinboundingtheerrorinOCEestimation
owingtothefollowingrelation:
2
3L eˆ n e ∗ n φ(X e ) E[φ(X e )]
oceφ oceφ(X) − + i=1| i − ∗ − i − ∗ |.
| n− |≤ (cid:16) 2 (cid:17) n
P
Underanadditionalsub-Gaussianityassumption,wepresentbelowaconcentrationboundforesti-
mationofOCEriskminimizere .
∗
4Theorem3.2. SupposeAssumptionsA1toA4hold.Thenwehave
nµ2ǫ2
P eˆ e ǫ 2exp , (8)
n − ∗ ≥ ≤ −8L2σ2
(cid:20) (cid:21) (cid:18) (cid:19)
(cid:12) (cid:12)
wherethequantitiesL,e ,µare(cid:12)asdefin(cid:12)edinTheorem3.1,whileσ2 isthesub-Gaussianityparam-
∗
eterofX.
Proof. SeeAppendixB.
Fromtheresultabove,itisapparentthattheboundexhibitsaGaussiantaildecay.
Bounds for OCE risk estimation. For our first result which is a mean squared error bound for
OCErisk,werequireanadditionalassumptionstatedbelow.
A5. E[(φ(X e ))p]isboundedforp=1,2andE (φ(X e ))k isboundedfork =2,3,4.
∗ ′ ∗
− −
The moment bounds can be seen to be easily satisfie(cid:2)d for a sub-Gau(cid:3)ssian/sub-exponentialX. In
thegeneralcase,suchmomentboundsarenecessaryowingtothefactthatthemean-squarederror
derivationnaturallyleadstotermsinvolvingE Z2 ,E Y2 andE Y4 ,whereZ =φ(X e )
∗
E[φ(X e )]andY =φ(X e ) E[φ(X e )]=φ(X e ) 1. − −
∗ ′ ∗ ′ ∗ ′ ∗
− − − (cid:2)− (cid:3) (cid:2) (cid:3) − (cid:2) −(cid:3)
Theresultbelowboundsthemean-squarederroroftheOCEriskestimatordefinedin(3).
Theorem3.3. SupposeA1toA3andA5hold. LetVar(X)denotethevarianceofar.v. X. Then,
wehave
E [oceφ n−oceφ(X)]2
≤n2
Var(φ(X −e ∗))+
27L2[Var 2( nφ 2′( µX
4
−e ∗))]2
+
9L2E (φ 2n′( 3X µ4−e ∗))4
.
(cid:2) (cid:3)
(cid:2) (cid:3)
Proof. SeeAppendixC.
UsingJensen’sinequality,wecaninferthat
K
E oceφ oceφ(X) E [oceφ oceφ(X)]2 1 ,
| n− | ≤ n − ≤ √n
r
(cid:2) (cid:3) h i
whereK canbeinferredfromtheresultabove.
1
ForOCEriskestimatestoconcentrate,werequireaboundonthetailprobabilityP φ(X e )
∗
− −
E[φ(X e ∗)] ǫ .Thelemmabelowestablishesthatφ(X e ∗) E[φ(X e ∗)]iss(cid:16)u(cid:12) (cid:12)b-exponential.
− ≥ − − − (cid:12)
(cid:12) (cid:17)
Lemma 3.4.(cid:12) (cid:12)SupposeX is σ2-sub-Gaussianandφ : R R+ is closed, convex, L-smooth, non-
decreasingandsatisfiesφ(0) = 0andφ(0) = 1. Thenth→ ezero-meanr.v. φ(X e ) E[φ(X
′ ∗
e ∗)] is sub-exponentialwith parameters (4 cC 21, c2 2), where C
1
= 2(4+exp
3c−
0
|L(e
2∗)−
2 −e
∗
|
−−
3c 0 |L(e 2∗)2 −e ∗ |),c 2 = c 20 andc 0 =min 12L1 σ2, 12σL1 e∗ 1 . (cid:16) (cid:17)
| − |
(cid:16) (cid:17)
Proof. SeeAppendixD.
WecannowusethisresulttoprovideaBernstein-typeconcentrationboundfortheOCEriskestimate
in(3).
Theorem 3.5. Suppose Assumptions A1 to A4 hold. Let c = min 1 , 1 , C =
0 12Lσ2 12Le∗ 1σ 1
| − |
2(4+exp 3c
0
|L(e 2∗)2 −e
∗
|
−3c
0
|L(e 2∗)2 −e
∗
|),c
2
= c 20. Then,fo(cid:16)ranyǫ>0,wehav(cid:17)e
(cid:16) (cid:17)
c nǫ2 µ2nǫ
P oceφ oceφ(X) >ǫ 2exp − 2 +2exp . (9)
n− ≤ 4(4C +ǫ) −24L3σ2
(cid:18) 1 (cid:19) (cid:18) (cid:19)
(cid:0)(cid:12) (cid:12) (cid:1)
(cid:12) (cid:12)
Proof. SeeAppendixE.
5Remark1. Wecanseethatthetailboundstatedaboveexhibitsanexponentialtaildecay.Sincewe
assumethatthefunctionφisstronglyconvex,atightersub-Gaussiandecaydoesnothold.Intuitively,
ther.v. φ(X e )underlyingOCEriskconcentrationisboundedbelowbyaquadraticfunctionof
∗
−
X,whichprecludessub-GaussianconcentrationforOCErisk.
Remark 2. In [14], the authors assume φ is Lipschitz and employ a Wasserstein distance-based
approach to arrive at a bound with a sub-Gaussian tail. In contrast, the bound in Theorem 3.5
exhibitssub-exponentialtaildecayforaL-smoothφ. FromTable1,itisapparentthatourbounds
areapplicableforthemean-varianceriskmeasure,sincetheunderlyingfunctionφissmooth.
Wecaninverttheboundin3.5toarriveatthefollowing‘high-confidence’form:
Corollary 3.5.1. Under conditions of Theorem 3.5, for any δ (0,1), with probability at least
∈
(1 δ),wehave
−
1 6L3σ2 2 1 6L3σ2 2 2 8C 2
oceφ oceφ(X) + log + + log2 + 1 log .
n− ≤ (cid:20)c 2n µ2n (cid:21) δ s (cid:20)c 2 nµ2 (cid:21) (cid:18)δ (cid:19) c 2n δ
(cid:12) (cid:12)
Wh(cid:12)ile thetailbound(cid:12)in(9)isusefulforthebanditapplicationunderbestarmidentificationframe-
workinSection5,theequivalenthigh-confidenceformabovecannotbeemployedforaupperconfi-
denceboundtypealgorithmtominimizeregret,sincec ,C requiretheknowledgeofe ,whichis
0 1 ∗
notknowninatypicalbanditsetting.
4 Stochastic approximationforOCEriskestimation
Theestimators. RecallthattheOCEriskminimizere satisfiesE[φ(X e )] 1 = 0. Using
∗ ′ ∗
− −
stochasticapproximation,wearriveatthefollowingupdateiterationforobtaininganestimatet of
j
theOCEriskminimizere :
∗
t =t γ (1 φ(X t )), (10)
j j 1 j ′ j j 1
− − − − −
where X arei.i.d. samplesfromthedistributionX andγ isasuitablychosenstepsize. Com-
j j
{ }
paredtothebatchestimatorintheprevioussection,theaboveupdateismoreamenableto‘streaming’
settings,wherethesamplesarriveoneatatime.
Inspiredby[2], we deriveboundsfor the averagediterate, anduse this quantityto estimate OCE.
Thesequantities,denotedbyt¯ andoceφ aredefinedasfollows:
m m,sa
t¯ =
1 m −1
t and oceφ =t¯ +
m i=1φ(X
i
−t¯ m)
. (11)
m m i m,sa m m
i=0 P
X
Results. Forderivinga mean-squarederrorbound,we requirethe followingassumptionin addi-
tiontoAssumptionsA1toA3andA5:
A6. The second derivative φ is M-lipschitz. That is for all x ,x R, φ (x ) φ (x )
′′ 1 2 ′′ 1 ′′ 2
∈ | − | ≤
M x x .
1 2
| − |
Themainresultthatprovidesamean-squarederrorboundfortheaveragediteratet¯ aftermitera-
m
tionsof(10)isgivenbelow.
Theorem4.1. SupposeAssumptionsA1toA3, A5andA6hold. Supposemiterationsof (10)are
runwithstepsizeγ = b withα (0.5,1).Then,theaveragediteratet¯ satisfies
j jα ∈ m
2
E[(t¯
m
e ∗)2] K , (12)
− ≤ m
where
σ 6σ Mbτ2 4Lb1/2
= + + 1+(µb)1/2 +
K µ µb1/2 2µ3/2 µ
(cid:16) (cid:17)
8A 1 σ2 1/2 5Mb1/2τ
+ +L E[(t e )2]+ + Aexp 24L4b4
µ1/2 b 0 − ∗ L2 2µ
(cid:18) (cid:19)(cid:18) (cid:19)
1/2 (cid:0) (cid:1)
µE (t e )4
E[(t e )2]+ 0 − ∗ +2τ2b3µ+8τ2b2 ,
× 0 − ∗ (cid:2)20bτ2 (cid:3) !
andAisaconstantthatdependsonlyonµ,b,Landα.
6Proof. Theprooffollowsbyanapplicationof[2,Theorem3]andverifyingtherequisiteconditions
there.ThereaderisreferredtoAppendixFforthedetails.
The mean-squarederror bound from (12) is comparable to the correspondingresult for the batch
estimator(6)inTheorem3.1,ifwesetm=n,i.e.,run(10)forn-samplesandcompareittoeˆ .
n
Next,weusetheboundin(12)toderiveaboundonthemean-squarederrorfortheOCEriskestimate
in(11).
Theorem4.2. UnderconditionsofTheorem4.1,wehave
L 2 Var(φ(X e )) Var(φ(X e ))
E oceφ (X) oceφ(X) K + K ′ − ∗ + − ∗ . (13)
| m,sa − | ≤ 2m m √m
p
(cid:2) (cid:3)
where isasdefinedinTheorem4.1.
K
Proof. SeeAppendixG.
5 Application: Multi-Armed Bandits
WeconsideraaK-armedstochasticbanditproblem,whichischaracterizedbytheprobabilitydistri-
butionsofthearms,denotedasP ,...,P . Wefocusonidentifyingthearmexhibitingthelowest
1 K
OCEriskvaluewithinapredeterminedsamplingbudget.Here,abanditalgorithmengageswiththe
environmentovera fixedbudgetcomprisingn rounds. Ateachroundt = 1,...,n, thealgorithm
selectsanarmI 1,...,K andrecordsacostsamplefromthedistributionP . Uponcompleting
t
∈
It
thenrounds,thebanditalgorithmsuggestsanarmJ ,andisevaluatedbasedontheprobabilityof
n
mis-identifyingtheoptimalarm,denotedasP[J =i ],wherei representsthearmwiththelowest
n ∗ ∗
6
OCEriskvalue,i.e.,i =argmin oceφ.
∗ i=1,...,K i
Algorithm 1 outlines the pseudocode for our OCE-SR algorithm, tailored to identify the OCE-
optimalarmunderafixedbudgetconstraint. Thisalgorithmpresentsamodificationoftheconven-
tionalsuccessiverejects(SR)approach,withadistinction:whileregularSRemployssamplemeans
to estimate the expectedvalue of each arm, OCE-SR utilizes empirical OCE risk, as describedin
(3),forestimatingtheOCEriskofeacharm. Theeliminationstrategy,involvingK 1phasesand
−
discardingthearmwiththepoorestOCEriskestimateattheconclusionofeachphase,isborrowed
fromtheregularSRframework.
Algorithm1OCE-basedSRAlgorithm
1: Initialization: SetA
1
= {1,...,K },logK = 21 + K
i=2
1 i,n
0
= 0,n
k
= logK(n (K−K +1)
k)
,
−
fork =1,...,K 1. l m
− P
2: fork =1,2,...,K 1do
−
3: PlayeacharminA fort =(n n )times.
k k k k 1
4: ComputetheOCEriskinfimumes− timat−eseˆi bysolving(6)foreacharmiinA .
tk k
5: ComputetheOCEriskestimateoˆcei foreacharmi A using(3)foreacharmiinA .
tk ∈ k k
6: SetA = A argmax oˆcei ,i.e.,removethearmwiththehighestempiricalOCE
risk,withk t+ ie1 sbrokk en\ arbitrarilyi ∈.Ak tk
7: endfor
8: Output: ReturnthesolitaryelementinA .
K
TheensuingresultdelvesintotheperformanceanalysisoftheOCE-SRalgorithmforsub-Gaussian
distributions.
Theorem5.1. ConsideraK-armedstochasticbandit,wherethearmsfollowasub-Gaussiandistri-
bution.Letarm-[i]todenotethearmwiththeithlowestOCEriskvalue.Let∆
[i]
=oceφ
i
oceφ
i∗
−
representthedifferencebetweentheOCEriskvaluesofarm [i]andtheoptimalarm. Foragiven
−
budgetn,thearm,sayJ ,returnedbytheOCE-SRalgorithmsatisfies:
n
(n K)(1 α)G
P[J
n
=i ∗] 4K(K 1)exp − − max ,
6 ≤ − − HlogK
(cid:18) (cid:19)
7whereG isaproblemdependentconstantthatdoesnotdependontheunderlyingOCEriskgaps
max
∆ andn,andH =max i .
[i] i 1,2...,K
∈{ } min ∆[i]/2,∆2 [i]/4
n o
Proof. SeeAppendixH.
6 Simulationexperiments
In this section, we illustrate the effectiveness of our proposed OCE estimators in (3) and (11) on
twodifferentsettings. Inthefirstsetting,weinvestigatetheperformanceofourOCEestimatorsin
asyntheticexperimentalsetup. Inthesecondsetting,weapplyourstochasticapproximation-based
OCEestimator(11)tothecreditriskmodelstudiedearlierin[7,12].
SyntheticSetup. Forthisexperiment,weconsideranormaldistributionwithmean0.5andvari-
ance 25. We set the disutility function φ(t) = t + t2, and this choice satisfies the smoothness
2
assumption Assumption A2. From Table 1, we know e = 0.5 and oceφ(X) = 13. Figure 1
∗
presentstheestimationerrors eˆ e and oceφ oceφ(X) asafunctionofthenumberofsam-
| n − ∗ | | n− |
ples(n). Theresultsareaveragesover1000independentreplications. FromFigure1,itisapparent
thattheestimators(6)and(3)convergerapidlytothetruevalues.
(a)TheerrorinestimationofOCEriskmin-
imizer as a function of the number of sam- (b)TheerrorinestimationofOCEriskasa
ples. functionofthenumberofsamples.
Figure 1: Errorsin estimation of OCE risk and its minimizer, when the underlyingdistribution is
(0.5,52). OCE risk andits minimizerare estimated using (3) and(6). The resultsare averages
N
over1000independentreplications.
Next, we present results for the streaming estimator described in Section 4. We set the disutility
function as φ(t) = t + t2. From Table 1, e = 0.5 and oceφ(X) = 13. We carried out our
2 ∗
stochasticapproximationscheme(10)for5000iterationsandreplicatedtheexperiment1000times
independentlyandtooktheaveragedresultsfordifferentstepsizes. TheplotsforE (t¯ e )2 as
k ∗
−
a functionof the numberof samples (k) are in Figure 2a and Figure 2b. Figure 2 demonstratesa
clearandswiftconvergenceoftheestimatorsin11towardstheirtruevalues. (cid:2) (cid:3)
CreditRiskModel. Inthisexperiment,wefollowthecreditriskmodel,whichisdescribednext.
Supposeaninvestor’sportfoliohasmpositions,witheachpositionsubjecttosomeriskofdefaulting
causinglosstotheinvestor. ThetotallossisL = m v D ,withD beinganindicatorvariable
i=1 i i i
which is 1 if the ith positiondefaultsand0 otherwiseand v > 0 is the fractionalloss associated
i
withtheith position. Inordertoquantifythis,letDP = I R > r wherer = Φ 1(1 p )and
i i i i − i
{ } −
p = 0.05arethethresholdriskandmarginaldefaultprobabilityoftheith position. Moreover,R ,
i i
ther.v. correspondingtothedefaultingriskoftheith positionisdeterminedbythefollowingfactor
model:Fori=1,...,m,d<m,
d
R =A ǫ + A Z withA2 +...+A2 =1, A >0,A 0.
i i,0 i i,j j i,0 i,d i,0 i,j ≥
j=1
X
8(a)E[(t¯ −e∗ )2 ] (b)E[|oceφ −oceφ(L)|]
k k,sgd
Figure 2: Errorsin estimation of OCE risk and its minimizer, when the underlyingdistribution is
(0.5,52). OCE risk minimizer is estimated using (10), while OCE risk is estimated using (11).
TN hestepsizeγ = 10 andt =1. Theresultsareaveragesover1000independentreplications.
j jα 0
Here,Z ,...,Z arethesystematicriskvariablesandǫ ,...,ǫ aretheidiosyncraticriskvariablesand
1 d 1 d
allofthemareassumedtobedistributedasN(0,1). TheparametersA denotethecross-coupling
i,j
coefficients. FortestingourOCEestimatoronthismodel,wedecidedtousethesetupdescribedin
[7]: Letthenumberofpositionsm = 25,fractionallossesv = ... = v = 1.00,v = ... =v =
1 5 6 10
1.25,v = ... = v = 1.50,v = ... = v = 1.75,v = ... = v = 2.00. p = 0.05forall
11 15 16 20 21 25 i
positions.ThecouplingparametersA aregivenasA =...=A =0.1,A =...=A =
i,j 1,1 5,1 6,2 10,2
0.1,A = ... =A =0.1,A = ... =A =0.1,A = ... =A =0.1,A =0.1
11,3 15,3 16,4 20,4 21,5 25,5 i,6
andA =0otherwise. Thedistutilityfunctionwechoosewasφ(t) =t+ t2. Underthesevalues,
i,j 2
itiseasytoseethatfromTable1,thate =1.875,andoceφ(L)=3.28515625.
∗
Figure3aandFigure3bpresentstheplotsofE (t¯ e )2 andE oceφ oceφ(L) (respec-
k − ∗ | k,sgd− |
tively)asafunctionofthenumberofsamples(k).Thereportedresuhltrepresenttheaveragieof1000
(cid:2) (cid:3)
independentreplications.From,wecanseetherapidprogressofourestimatorsin(11)totheirtrue
valuesunderthecreditriskmodelsetup.
(a)E[(t¯ −e∗)2] (b)E[|oceφ −oceφ(L)|]
k k,sgd
Figure 3: : Errorsin estimation of OCE risk and its minimizer, underthe creditrisk model. (10),
whileOCEriskisestimatedusing(11). Thestepsizeγ = 100 andt =1.Theresultsareaverages
j jα 0
over1000independentreplications.
7 Conclusions and future work
WeaddressedtheproblemofOCEriskestimationfromi.i.d. samplesoftheunderlyinglossdistri-
bution. WefirstconsideredansampleaverageOCEriskestimator,andderiveamean-squarederror
bound. Wealsoderivedaconcentrationboundforthesampleaverageestimatorwhentheunderly-
inglossdistributionissub-Gaussian,andthedisutilityfunctionisstronglyconvexandsmooth.This
9concentrationboundisusefulinOCErisk-awarebanditapplications. Finally,wealsoconsidereda
stochasticroot-findingbasedOCEriskestimator,andderiveditsfinitesampleguarantees.
Forfuturework,OCEriskestimationwithMarkoviansamplesremainsunaddressed.OCEriskopti-
mizationinarisk-sensitivereinforcementlearningframeworkisanotherinterestingfutureresearch
direction.
References
[1] P.Artzner,F.Delbaen,J.Eber,andD.Heath.Coherentmeasuresofrisk.Mathematicalfinance,
9(3):203–228,1999.
[2] Francis Bach and Eric Moulines. Non-asymptotic analysis of stochastic approximation al-
gorithms for machine learning. In NeuralInformationProcessingSystems(NIPS), pages –,
Spain,2011.
[3] A. Ben-Tal and M. Teboulle. An old-new concept of convex risk measures: The optimized
certaintyequivalent. MathematicalFinance,17:449–476,022007.
[4] AharonBen-TalandMarcTeboulle.Expectedutility,penaltyfunctions,anddualityinstochas-
ticnonlinearprogramming. ManagementScience,32(11):1445–1466,1986.
[5] SanjayPBhatandL.A.Prashanth. Concentrationofriskmeasures: A Wasserstein distance
approach. AdvancesinNeuralInformationProcessingSystems,32:11762–11771,2019.
[6] D. B. Brown. Large deviations bounds for estimating conditional value-at-risk. Operations
ResearchLetters,35(6):722–730,2007.
[7] J. DunkelandS. Weber. Stochastic rootfindingand efficientestimation of convexrisk mea-
sures. OperationsResearch,58(5):1505–1521,2010.
[8] RickDurrett. Probability:theoryandexamples,volume49. Cambridgeuniversitypress,2019.
[9] H. Föllmer and A. Schied. Convex measures of risk and trading constraints. Finance and
stochastics,6(4):429–447,2002.
[10] S. Gupte, PrashanthL.A., andSanjay PBhat. Optimizationof utility-basedshortfallrisk: A
non-asymptoticviewpoint. arXivpreprintarXiv:2310.18743,2023.
[11] A.Hamm,T.Salfeld,andS.Weber.Stochasticrootfindingforoptimizedcertaintyequivalents.
In2013WinterSimulationsConference(WSC),pages922–932,2013.
[12] V. Hegde, A. S. Menon, L. A. Prashanth, and K. Jagannathan. Online Estimation and Opti-
mizationofUtility-BasedShortfallRisk. Papers2111.08805,arXiv.org,November2021.
[13] A. Kagrecha, J. Nair, and K. Jagannathan. Distribution oblivious, risk-aware algorithms for
multi-armedbanditswithunboundedrewards. InAdvancesinNeuralInformationProcessing
Systems,pages11269–11278,2019.
[14] Prashanth L.A. and Sanjay P. Bhat. A wasserstein distance approach for concentration of
empiricalriskestimates. JournalofMachineLearningResearch,23(238):1–61,2022.
[15] J.Lee,S.Park,andJ.Shin.Learningboundsforrisk-sensitivelearning.InAdvancesinNeural
InformationProcessingSystems,volume33,pages13867–13879,2020.
[16] H.Markowitz. Portfolioselection. TheJournalofFinance,7(1):77–91,1952.
[17] Z.Mhammedi,B.Guedj,andR.C.Williamson. Pac-bayesianboundfortheconditionalvalue
atrisk. InH.Larochelle,M.Ranzato,R.Hadsell,M.F.Balcan,andH.Lin,editors,Advances
inNeuralInformationProcessingSystems,volume33,pages17919–17930.CurranAssociates,
Inc.,2020.
[18] E.MoulinesandF.Bach. Non-asymptoticanalysisofstochasticapproximationalgorithmsfor
machinelearning. Advancesinneuralinformationprocessingsystems,24:451–459,2011.
[19] A.K.Pandey,L.A.Prashanth,andS.P.Bhat. Estimationofspectralriskmeasures. InAAAI
ConferenceonArtificialIntelligence,2021.
[20] L. A. Prashanth, J. Cheng, M. C. Fu, S. I. Marcus, and C. Szepesvári. Cu-
mulative prospect theory meets reinforcement learning: prediction and control. In
InternationalConferenceonMachineLearning,pages1406–1415,2016.
10[21] L. A. Prashanth, K. Jagannathan, and R. K. Kolla. Concentration bounds for
CVaR estimation: The cases of light-tailed and heavy-tailed distributions. In
InternationalConferenceonMachineLearning,volume119,pages5577–5586,2020.
[22] L. A. Prashanth, N. Korda, and R. Munos. Concentration bounds for temporal difference
learning with linear function approximation: the case of batch data and uniform sampling.
MachineLearning,110(3):559–618,2021.
[23] PhilippeRigolletandJan-ChristianHütter. High-dimensionalstatistics,2023.
[24] R. T. Rockafellarand S. Uryasev. Optimizationofconditionalvalue-at-risk. Journal ofrisk,
2:21–42,2000.
[25] P.ThomasandE.Learned-Miller. Concentrationinequalitiesforconditionalvalueatrisk. In
InternationalConferenceonMachineLearning,pages6225–6233,2019.
[26] R.Vershynin.High-dimensionalprobability:Anintroductionwithapplicationsindatascience,
volume47. Cambridgeuniversitypress,2018.
[27] M.J.Wainwright.High-dimensionalstatistics: Anon-asymptoticviewpoint,volume48.Cam-
bridgeuniversitypress,2019.
[28] Y. Wang and F. Gao. Deviationinequalitiesfor an estimator of the conditionalvalue-at-risk.
OperationsResearchLetters,38(3):236–239,2010.
A ProofofTheorem 3.1
Proof. Usingdefinitions(5)and(6),wehave
n n
1 1
(φ′(X
i
e∗) φ′(X
i
eˆ n))= φ′(X
i
e∗) E[φ′(X
i
e∗)] (14)
n − − − n − − −
Xi=1 Xi=1(cid:16) (cid:17)
Weconsidertwocasesfortheanalysis.
Case1: (eˆ >e )
n ∗
φ(X e ) φ(X eˆ ) µ(eˆ e ) (w.p.1)
′ i ∗ ′ i n n ∗
− − − ≥ −
n
1
φ(X e ) E[φ(X e )] µ(eˆ e ),
′ i ∗ ′ i ∗ n ∗
⇒ n − − − ≥ −
Xi=1(cid:16) (cid:17)
whereweusedthefactthatφisµ-stronglyconvex.
Case2: (eˆ <e )
n ∗
φ(X e ) φ(X eˆ ) µ(eˆ e ) (w.p.1)
′ i ∗ ′ i n n ∗
− − − ≥ −
n
1
E[φ(X e )] φ(X e ) µ(e eˆ )
′ i ∗ ′ i ∗ ∗ n
⇒ n − − − ≥ −
Xi=1(cid:16) (cid:17)
Thus,
n
1
e eˆ φ(X e ) E[φ(X e )] (15)
∗ n ′ i ∗ ′ i ∗
| − |≤ nµ − − −
(cid:12) Xi=1(cid:16) (cid:17)(cid:12)
(cid:12) (cid:12)
(cid:12) (cid:12)
11LetZ =φ(X e ) E[φ(X e )]. NotethatE[Z ]=0.Squaring15andtakingexpectations,
i ′ i ∗ ′ i ∗ i
− − −
weobtain
n
1
E[(e eˆ )2] E ( Z )2
∗ − n ≤ n2µ2 i
i=1
(cid:2) X (cid:3)
n n
1
E Z2+ Z Z
≤ n2µ2 i i j
i=1 i,j=1
(cid:2)X X (cid:3)
n
1
E[Z2] (crosstermsvanishsinceiid)
≤ n2µ2 i
i=1
X
n
1
E[(φ(X e ))2]+(E[φ(X e )])2 2(E[φ(X e )])2
≤ n2µ2 ′ i − ∗ ′ i − ∗ − ′ i − ∗
i=1
X
n
1
(E[(φ(X e ))2] 1) (E[φ(X e )]=1) (16)
≤ n2µ2 ′ i − ∗ − ′ − ∗
i=1
X
Usingφ(0)=1andL-Lipschitznessofφ,wehave
′ ′
φ(X e ) 1 LX e .
′ i ∗ ∗
| − − |≤ | − |
Squaringonbothsidesaboveandtakingexpectations,weobtain
E[(φ(X e ))2] (Le )2+L2E[X2] 2L2e E[X]+1. (17)
′ ∗ ∗ ∗
− ≤ −
Themainclaimfollowsbysubstitutingtheboundabovein(16).
B ProofofTheorem 3.2
For establishing the bound in Theorem 3.2, we require the following result, which shows that a
Lipschitzfunctionofasub-Gaussianr.v.issub-Gaussian.
Lemma B.1. Let X R be sub-Gaussianwith parameterσ. Then if f : R R is L-Lipschitz,
∈ →
f(X)issub-Gaussianwithparameter2Lσ.
Proof. ByLemma54of[14],ifX isasub-Gaussianr.v.withparameterσ,then
(EX k)k1 2σ√k, k 1 (18)
| | ≤ ∀ ≥
FollowingaprooftechniqueanalogoustothatoftheproofofProposition2.5.2in[26],wehave
E[eλ2X2 ]=E 1+ ∞ (λ2X2)p
p!
" #
p=1
X
∞
λ2pE[X2p]
=1+
p!
p=1
X
∞ p p
λ2p(2σ)2p2pep ((18)andp! )
≤ ≥ e
Xp=0 (cid:16) (cid:17)
∞
(8eσ2λ2)p
≤
p=0
X
1 1
= (if λ )
1 8eσ2λ2 | |≤ √8eσ
−
1
e16eσ2λ2
(if λ ), (19)
≤ | |≤ 4√eσ
wherethelaststepfollowsfromthefactthat 1 e2x x [0,1/2].
1 x ≤ ∀ ∈
−
12Settingλ= √ln2,weobtain
4√eσ
16eσ2
E eX2/K 32 2 withK2 = . (20)
≤ 3 ln2
h i
Employingtheprooftechniqueofhttps://mathoverflow.net/questions/442500/lipschitz-function-of-subgauss
wehave
E eλ2(f(X) E[f(X)])2 =E eλ2(f(X) E[f(X′)])2 (X isanindependentcopyofX)
− − ′
h i Eh eλ2(f(X) f(X′))2 i
(Jensen’sinequality)
−
≤
Eh eλ2L2(X −X′)2 i
(Lipschitznessoff)
≤
Eh eλ2L2(2X2+2Xi′2)
≤
h 2 i
E e2λ2L2X2
≤
E(cid:16) eh 4λ2L2X2 i(cid:17)
(Jensen’sinequality) (21)
≤
h i
Settingλ= √ln2 ,weobtain
8√eσL
E e(f(X) −E[f(X)])/K 3′2 ≤E eX2/K 32 ≤2 withK 3′2 = 64e lnσ 22L2 . (22)
h i h i
Wecannowinferthatf(X) E[f(X)]is4L2σ2-sub-GaussianbyusingProposition2.5.2of[26].
−
Next,weproveTheorem3.2byusingtheresultinthelemmaabove.
Proof. (Theorem3.2)
Recallfrom(15),wehave
n
1
e eˆ φ(X e ) E[φ(X e )] . (23)
∗ n ′ i ∗ ′ i ∗
| − |≤ nµ − − −
(cid:12) Xi=1(cid:16) (cid:17)(cid:12)
(cid:12) (cid:12)
(cid:12) (cid:12)
UsingLemmaB.1,φ(X e ) E[φ(X e )]is4L2σ2sub-Gaussian i. Themainclaimnow
′ i ∗ ′ i ∗
− − − ∀
followsbyapplyingHoeffding’sinequality(cf. Proposition2.1of[27])totheRHSof(23).
C ProofofTheorem 3.3
Usingsmoothnessofφ,wederivetwousefulboundsinthelemmasbelow. Theseboundswouldbe
usedsubsequentlyintheproofofTheorem3.3.
LemmaC.1. UnderconditionsofTheorem3.3,wehave
n φ(X e )
L(e ∗ eˆ n)2+(e ∗ eˆ n) (e ∗ eˆ n) i=1 ′ i − ∗ L(e ∗ eˆ n)2+(e ∗ eˆ n). (24)
− − − ≤ − n ≤ − −
P
Proof. ByLipschitznessofφ,
′
Leˆ e +φ(X eˆ ) φ(X e ) Leˆ e +φ(X eˆ ) (25)
n ∗ ′ i n ′ i ∗ n ∗ ′ i n
− | − | − ≤ − ≤ | − | −
n φ(X eˆ ) n φ(X e ) n φ(X eˆ )
Leˆ n e ∗ + i=1 ′ i − n i=1 ′ i − ∗ Leˆ n e ∗ + i=1 ′ i − n
⇒− | − | n ≤ n ≤ | − | n
P P P (26)
13n φ(X e )
Leˆ n e ∗ +1 i=1 ′ i − ∗ Leˆ n e ∗ +1 (27)
⇒− | − | ≤ n ≤ | − |
P
Now take 2 cases: eˆ > e or vice-versa. According to the sign of (eˆ e ) take the relevant
n ∗ n ∗
−
inequality,eithercasewillyield:
n φ(X e )
L(e ∗ eˆ n)2+(e ∗ eˆ n) (e ∗ eˆ n) i=1 ′ i − ∗ L(e ∗ eˆ n)2+(e ∗ eˆ n) (28)
− − − ≤ − n ≤ − −
P
LemmaC.2. UnderconditionsofTheorem3.3,wehave
2 2
3L e ∗ eˆ n n φ(X eˆ ) φ(X e ) 3L e ∗ eˆ n
−
(cid:16)
2−
(cid:17)
+(e∗ −eˆ n)
≤
i=1 i − nn − i − ∗
≤ (cid:16)
2−
(cid:17)
+(e∗ −eˆ n)
P (29)
Proof. ByL-smoothnessofφ,
2
L e eˆ
∗ n
− − +(e eˆ )φ(X e ) φ(X eˆ ) φ(X e ) (30)
(cid:16) 2 (cid:17) ∗ − n ′ i − ∗ ≤ i − n − i − ∗
2
L e eˆ
∗ n
− +(e eˆ )φ(X e ) (31)
≤ (cid:16) 2 (cid:17) ∗ − n ′ i − ∗
L n φ(X e ) n φ(X eˆ ) φ(X e )
− (e∗ eˆ n)2+(e∗ eˆ n) i=1 ′ i − ∗ i=1 i − n − i − ∗ (32)
2 − − n ≤ n
P P
L(e eˆ )2 n φ(X e )
∗ − n +(e ∗ eˆ n) i=1 ′ i − ∗
≤ 2 − n
P (33)
AndnowjustsubstitutetheresultsobtainedfromLemma24.
WenowproveTheorem3.3.
Proof. Usingthedefinitionofoceφ,wehave
n
n n
φ(X e ) φ(X eˆ ) φ(X e )
⇒oceφ
n
=e ∗+ i n− ∗ +(eˆ
n
−e ∗)+ i − n −
n
i − ∗ . (34)
i=1 i=1
X X
UsingtheresultsofLemma24andLemma29,weobtain
2 2
3L e ∗ eˆ n n φ(X e ) 3L e ∗ eˆ n n φ(X e )
−
(cid:16)
2−
(cid:17)
+e ∗+ i=1
n
i − ∗ ≤oceφ
n ≤ (cid:16)
2−
(cid:17)
+e ∗+ i=1
n
i − ∗ .
P P (35)
Usingoceφ(X)=e +E φ(X e ) ,weobtain
∗ ∗
−
h i
2
3L e ∗ eˆ n n φ(X e ) E[φ(X e )]
− + i=1 i − ∗ − i − ∗
− (cid:16) 2 (cid:17) n
P
oceφ oceφ(X) (36)
≤ n−
2
3L e ∗ eˆ n n φ(X e ) E[φ(X e )]
− + i=1 i − ∗ − i − ∗
≤ (cid:16) 2 (cid:17) n
P
14. Recallthatfrom(15),wehave
n
1
e eˆ φ(X e ) E[φ(X e )] . (37)
∗ n ′ i ∗ ′ i ∗
| − |≤ nµ − − −
(cid:12) Xi=1(cid:16) (cid:17)(cid:12)
(cid:12) (cid:12)
(cid:12) (cid:12)
DefineZ =φ(X e ) E[φ(X e )]andY =φ(X e ) E[φ(X e )]=φ(X e ) 1.
i i ∗ i ∗ i ′ i ∗ ′ i ∗ ′ i ∗
NotethatE[Z ]=− 0and−E[Y ]=0− . Usingthefactthat(a− +b)2− 2(a2+− b2),weobtain − −
i i
≤
1 n 2 9L2 n 4
E (oceφ oceφ(X))2 2 E Z + E Y
n− ≤ n2 " i # 4n4µ4 " i #
h i (cid:16) (cid:16)Xi=1 (cid:17) (cid:16)Xi=1 (cid:17) (cid:17)
1 n 9L2 n 4
2 E Z2 + E Y
≤ n2 i 4n4µ4 " i #
(cid:16) Xi=1 (cid:2) (cid:3) (cid:16)Xi=1 (cid:17) (cid:17)
1 n 9L2 n
2 E Z2 + E Y Y Y Y
≤ n2 i 4n4µ4  i j k l 
(cid:16) Xi=1 (cid:2) (cid:3) (cid:16)i,j X,k,l=1 (cid:17) (cid:17)
2 9L2  n 4 
E Z2 + nE Y4 + (E Y2 )2
≤ n 2n4µ4 2 × 2 ×
(cid:18) (cid:19) (cid:18) (cid:19)
2 (cid:2) (cid:3) (cid:0) 27(cid:2)L2((cid:3)E Y2 )2 9L2E Y4(cid:2) (cid:3) (cid:1)
Var(φ(X e ))+ + ,
∗
≤ n − 2n2µ4 2n3µ4
(cid:2) (cid:3) (cid:2) (cid:3)
whereZ =φ(X e ) E[φ(X e )]andY =φ(X e ) E[φ(X e )]=φ(X e ) 1.
∗ ∗ ′ ∗ ′ ∗ ′ ∗
− − − − − − − −
NoticethatE Z2 = Var(φ(X e )), E Y2 = Var(φ(X e ))), andE Y4 < E[(φ(X
∗ ′ ∗ ′
− − −
e ))4]. Eachoftheseexpectationsarefiniteandthemainclaimfollows.
∗ (cid:2) (cid:3) (cid:2) (cid:3) (cid:2) (cid:3)
D ProofofLemma 3.4
Proof. Considerther.v. Z =φ(X e ) E[φ(X e )]. UsingL-smoothnessofφ,weknow
∗ ∗
− − −
φ(X e∗) (φ(0)+φ′(0)(X e∗)) L(X e∗)2/2
| − − − |≤ −
φ(X e∗) (X e∗) L(X e∗)2/2 (φ(0)=0,φ′(0)=1).
⇒| − − − |≤ −
Theboundabovecanberewrittenasfollows:
φ(X e ) aX2+bX +c, (38)
∗
− ≤ | |
wherea=L/2,b= Le 1,andc=
L(e∗)2
e . Noticethata,b,carenon-negativeconstants.
| ∗ − | 2 − ∗
(cid:12) (cid:12)
(cid:12) (cid:12)
(cid:12) (cid:12)
15Nowweemploytheprooftechniqueadaptedfromtheproofof[23,Lemma1.12]. Usingthedomi-
natedconvergencetheorem,wehave
E[eλ(φ(X e∗) E[φ(X e∗)])]
− − −
k
λkE[ φ(X e ) E[φ(X e )] ]
∞ − ∗ − − ∗
1+
≤ (cid:16) k! (cid:17)
k=2
X
λk2k 1 E[(φ(X e ))k]+(E[φ(X e )])k
1+ ∞ − − ∗ − ∗ (Jensen’sinequality)
≤ (cid:16) k! (cid:17)
k=2
X
1+
∞ λk2kE[ |φ(X −e ∗) |k]
(Jensen’sinequalityandE[X] E[X ])
≤ k! ≤ | |
k=2
X
∞ λk2kE[(aX2+bX +c)k]
1+ | |
≤ k!
k=2
X
1+
∞ λk2k3k −1E[akX2k+bk |X |k+ck]
(Jensen’sinequality)
≤ k!
k=2
X
∞ λk6kE[akX2k+bk X k+ck]
1+ | |
≤ k!
k=2
X
1+I +I +I . (39)
1 2 3
≤
By part(II)of Theorem2.2in [27], we havethata r.v. X is sub-exponentialif thereis a positive
numberc >0suchthatE[eλ(X E[X])]< forall λ c .
0 − 0
∞ | |≤
We shallboundeachofI ,I andI toestablisha exponentialmomentboundforther.v. φ(X
1 2 3
e ) E[φ(X e )]. −
∗ ∗
− −
SinceX isasub-Gaussianr.v. withparameterσ,wehave
E X k (2σ2)k/2kΓ(k/2) k 1. (40)
| | ≤ ∀ ≥
(cid:2) (cid:3)
WenowboundI asfollows:
1
∞
(6λa)kE[X2k]
I =
1
k!
k=2
X
∞ (6λa)k(2σ2)k(2k)Γ(k)
≤ k!
k=2
X
∞
2 (12aσ2λ)k
≤
k=2
X
∞ 1 1
2 if12aσ2λ
≤ 2k ≤ 2
k=2
X
1
2 if λ .
≤ | |≤ 24aσ2
16WenowboundI asfollows:
1
∞ (6bλ)kE[X k]
I = | |
2
k!
k=2
X
∞ (6bλ)2q+1E[X 2q+1] ∞ (6bλ)2qE[X2q]
| | +
≤ (2q+1)! (2q)!
q=1 q=1
X X
∞ (6bλ)2q+1(2σ2)q+ 21(2q+1)Γ(q+ 1) ∞ (6bλ)2q(2σ2)q(2q)Γ(q)
2 +
≤ (2q+1)! (2q)!
q=1 q=1
X X
∞ (6√2bσλ)2q+1(2q+1)(2q)!√π ∞ (72b2σ2λ2)qq!
+2
≤ (2q+1)!4qq! (2q)!
q=1 q=1
X X
∞ (72b2σ2λ2)q ∞ q! 1
(6√2πbσλ) +2 (if72b2σ2λ2 )
≤ q! 2q(2q)! ≤ 2
q=1 q=1
X X
(6√2πbσλ)(e72b2σ2λ2 1)+2 ∞ q! (if72b2σ2λ2 1 )
≤ − 2q(2q)! ≤ 2
q=1
X
√π(√e 1) ∞ q! 1
− +2 (if72b2σ2λ2 )
≤ √2 2q(2q)! ≤ 2
q=1
X
∞ q! 1
<1+2 (if72b2σ2λ2 ).
2q(2q)! ≤ 2
q=1
X
Toboundthesecondtermabove,considerT = q! . Tq+1 = 1 . Then
q 2q(2q)! Tq 4(2q+1)
∞
2 T =2(T +T +T +...)
q 1 2 3
q=1
X
T T T
1 1 1
2(T + + + +...)
≤ 1 4 3 42 3 5 43 3 5 7
· · · · · ·
T T T T
1 1 1 1
2( T + + + + +...)
≤ 1 4 3 43 3 45 3 47 3
· · · ·
1
2T 1+ 4
≤ 1 3(1 1 )
(cid:16) − 16 (cid:17)
49 1
<1 (if λ ).
≤ 90 | |≤ 12bσ
WenowboundI asfollows:
3
∞ (6cλ)k
I =
3
k!
k=2
X
=e6cλ 1 6cλ.
− −
CombiningtheboundsobtainedforI ,I andI ,weget
1 2 3
E[eλ(φ(X e∗) E[φ(X e∗)])] 1+I +I +I (41)
− − − 1 2 3
≤
1+2+1+1+e6cλ 1 6cλ (42)
≤ − −
1 1
< if λ min , . (43)
∞ | |≤ 24aσ2 12bσ
(cid:18) (cid:19)
We have showed that the zero mean r.v. Y = φ(X e ) E[φ(X e )] is sub-exponentialr.v.
∗ ∗
− − −
wheneverX isσ2-sub-Gaussian.Wealsoshowedtheexistenceofac =min 1 , 1
0 12Lσ2 12Le∗ 1σ
| − |
(cid:16) (cid:17)
17suchthatE[eλ(φ(X e∗) E[φ(X e∗)])]< , λ c .
− − − 0
∞ ∀| |≤
By the Chernoff Bound with λ = c 20, we have P(Y
≥
t)
≤
E[ec0 2Y ]e −c0 2t . Applying a similar
argumentto Y,wecanconcludethatP(Y t) c 1e −c2t withc
1
= E[ec0 2Y ]+E[e−c 20Y ]and
− | | ≥ ≤
c
2
= c 20. Wecangetanexplicitboundforc
1
bysettingλ = c 20 in(42)togetE[ec0 2Y ]
≤
M where
M =4+e3 |L(e 2∗ )2 −e∗ |c0 −3 |L(e 2∗)2 −e
∗
|c 0.ByaparallelargumentonecanarriveatE[e−c 20Y ] ≤M
sothatc 2M =C .
1 1
≤
ByaparallelargumenttotheproofofLemma55of[14],weobtain
E[Y k]= ∞ P(Y k u)du
| | | | ≥
Z0
= ∞ P(Y t)ktk 1dt
−
| |≥
Z0
∞ C 1e −c2tktk −1dt
≤
Z0
∞ C 1k e−ssk −1ds
≤ ck
Z0 2
C kΓ(k)
1
=
ck
2
1 √2C 2 1
= 1 k!( )k 2,
−
2 c c
2 2
(cid:16) (cid:17)
whichprovesthatY satisfiesBernstein’sconditionwithparametersσ2 = 2C1 andb= 1.
c2
2
c2
Weknowfrom[p.19,Chapter2][27]thatifY satisfiesBernstein’sconditionwithparameters(σ2,b)
thenitisalsosub-exponentialwithparameters(2σ2,2b).Thuswehavethatφ(X e ) E[φ(X
∗
− − −
e ∗)]issub-exponentialwithparameters 4 cC
2
21, c2
2
,completingtheproof.
(cid:16) (cid:17)
E ProofofTheorem 3.5
Proof. In Lemma 3.4 we showed that Y = φ(X e ) E[φ(X e )] is sub-exponentialwith
∗ ∗
− − −
parameters(4C1, 2).
c2
2
c2
ApplyingBernstein’sinequalitytoY,weobtain
P φ(X e∗) E[φ(X e∗)] ǫ
2e2(− 2Cc2 1ǫ +2
ǫ). (44)
− − − ≥ ≤
(cid:16)(cid:12) (cid:12) (cid:17)
withC
1
=2(4+e3 |φ(
−e∗(cid:12)
(cid:12)) |c0 −3 |φ( −e ∗) |c 0),c
2
= c
20(cid:12)
(cid:12)andc
0
=min 12L1 σ2, 12φ′(1
e∗)σ
.
| − |
(cid:16) (cid:17)
Using(36)derivedduringtheproofofTheorem3.3,weknow
P oceφ oceφ(X) >ǫ
n− ≤
h(cid:12) 1 n (cid:12) i 3L
P(cid:12) φ(X (cid:12) e ) E(X e ) >ǫ/2 +P (e eˆ )2 >ǫ/2 (45)
i ∗ i ∗ ∗ n
(cid:12)n − − − (cid:12) 2 −
h(cid:12) Xi=1 (cid:12) i h i
(cid:12) (cid:12)
(cid:12) (cid:12)
Thefirsttermon(cid:12)theRHSof(45)isboundedusing(cid:12)(44)asfollows:
n
P 1 φ(X i e ∗) E(X i e ∗) > ǫ 2e4− (4c c2 1n +ǫ ǫ2 ) (46)
(cid:12)n − − − (cid:12) 2 ≤
h(cid:12) Xi=1 (cid:12) i
(cid:12) (cid:12)
(cid:12) (cid:12)
(cid:12) (cid:12)
18ThesecondtermontheRHSof(45)canbeboundedusingtheresultderivedinTheorem3.2.
Combiningtheboundsontheaforementionedtwoterms,weobtain
P oceφ n−oceφ(X) >ǫ ≤2e4− (4c c2 1n +ǫ ǫ2 ) +2e−24µ L2 3n σǫ 2. (47)
Henceproved. (cid:2)(cid:12) (cid:12) (cid:3)
(cid:12) (cid:12)
F Proof ofTheorem 4.1
Proof. Werewritebelowtheupdateiteration(10)inaformthatisamenabletotheapplicationofa
resultfrom[2]
t
j
=t
j −1
−γ jf j′(t
j
−1) ∀j ≥1, ∀t
0
∈R, (48)
whereX ,...,X arei.i.dr.v’ssampledduringmiterationsofSGD.
1 n
Define
f(t)=E[φ(X t)]+t, f′(t)=1 E[φ′(X t)],
− − −
f (t)=φ(X t)+t, f (t)=1 φ(X t).
j j
−
j′
−
′ j
−
ThenTheorem4.1canbeprovedbyapplying[2, Thm. 3]whichissubjecttocertainassumptions
(H ,H ,H ,H ,H ,H ) of [2]. For the sake of completeness, we include them here, restating
1 2′ 3 4 6 7
themforthescalarcase.
B1. Let(F ) beanincreasingfamilyofσ-fields. t isF -measurable,andforeacht R,the
j j>0 0 0
∈
r.v. f (t) issquare-integrable,F -measurable,andforallt H, j > 1, E(f (t)F ) = f (t),
withpj′
robability1.
j
∈
j′
|
j −1 ′
B2. Foreachn>1,thefunctionf isalmostsurelyconvex,differentiablewithLipschitz-continuous
n
gradientf ,withconstantL,thatis:
n′
j >1, t ,t R, f (t ) f (t ) L t t w.p.1.
∀ ∀
1 2
∈
j′ 1
−
j′ 2
≤ |
1
−
2
|
B3. Thefunctionf isstronglyconvex,wi(cid:12)thconvexitycon(cid:12)stantµ>0. Thatis,forallt 1,t
2
R,
(cid:12) (cid:12) ∈
µ
f(t 1) f(t 2)+f′(t 2)(t
1
t 2)+ (t
1
t 2)2.
≥ − 2 −
B4. Thereexistsσ2 R+ suchthatforallj >1,E[(f (e )2 ) σ2,w.p.1.
∈
j′ ∗ |Fj −1
≤
B5. Foreachn>1,thefunctionf isalmostsurelytwicedifferentiablewithLipschitz-continuous
n
secondderivativef ,theLipschitzconstantbeingM. Thatis,forallt ,t Randforalln>1,
n′′ 1 2
∈
f (t ) f (t ) M t t ,
|
n′′ 1
−
n′′ 2
|≤ |
1
−
2
|
(w.p1).
B6. Thereexistsτ R ,suchthatforeachj >1,
+
∈
E(f j′(e∗)4 |F
j
−1) ≤τ4 almostsurely.
NowweshowthattheassumptionsAssumptionsA1toA3andA5implyB1–B6holdfortheupdate
(48).
B1: HoldsbydefinitionofX ,f andf.
j j′
B2: Holdsfromthelipschitznessofφ.
′
B3: Considerg(t)=E[φ(X t)]. Ifthisisstronglyconvexsoisg(t)+t. Bystrongconvexityof
−
φ,
µ
φ(X t ) φ(X t )+φ(X t )(t t )+ (t t )2
2 1 ′ 1 1 2 1 2
− ≥ − − − 2 −
µ
E[φ(X t )] E[φ(X t )]+E[φ(X t )](t t )+ (t t )2
2 1 ′ 1 1 2 1 2
⇒ − ≥ − − − 2 −
µ
g(t 2) g(t 1)+g′(t 1)(t
2
t 1)+ (t
1
t 2)2
⇒ ≥ − 2 −
19B4: HoldstriviallyfromA5.
B5: FollowsfromA6.
B6: ThisfollowsfromA5,afternotingthatthesamplesarei.i.d. inoursetting.
Theproofofthetheoremthenfollowsbydirectlyapplying[Theorem3][18]initsscalarversionto
thef,f ,f ,f definedearlier.
′ j j′
NotethatthefirsttermintheboundfromTheorem3of[2]isthedominantone. Forourchoiceof
α (0.5,1),itcanbeshownthatalltheotherstermsintheaforementionedboundareasymptotically
sm∈ allerthanthefirstone,andsotheycanallberepresentedintheformof ci . Also,thefirstterm
√m
inscalarformisσ2f ′′(e ∗) −2 =σ2E[φ ′′(X −e ∗)]−2
≤
σ µ2 2.
G ProofofTheorem 4.2
Proof. UsingthedefinitionsofOCEriskanditsestimatorin(11),wehave
oceφ (X) oceφ(X) (49)
m,sa −
m φ(X t¯ )
=(t¯
m
e∗)+ i=1 i − m E[φ(X e∗)]
− m − −
P
m φ(X t¯ ) m φ(X e ) m (φ(X e ) E[φ(X e )])
=(t¯
m
e ∗)+ i=1 i − m − i=1 i − ∗ + i=1 i − ∗ − i − ∗ .
− m m
P P P (50)
ThesecondtermontheRHSof(50)canbeboundedusingL-smoothnessasfollows:
L
− (t¯ m e ∗)2+φ ′(X e ∗)(e ∗ t¯ m)
2 − − − ≤
L
φ(X t¯ ) φ(X e ) (t¯ e )2+φ(X e )(e t¯ ).
m ∗ m ∗ ′ ∗ ∗ m
− − − ≤ 2 − − −
Sincethetwo-sidedinequalityaboveholdsforanyX ,weobtain
i
L m φ(X e )
− (t¯
m
e∗)2+(e∗ t¯ m) i=1 ′ i − ∗ (51)
2 − − m ≤
P
m φ(X t¯ ) m φ(X e )
i=1 i − m − i=1 i − ∗ (52)
m ≤
P P
L m φ(X e )
(t¯ m e ∗)2+(e ∗ t¯ m) i=1 ′ i − ∗ . (53)
2 − − m
P
Substituting(53)into(50),weobtain
oceφ (X) oceφ(X)
m,sa −
L m φ(X e ) m (φ(X e ) E[φ(X e )])
(t¯
m
e∗)2+(t¯
m
e∗) 1 i=1 ′ i − ∗ + i=1 i − ∗ − i − ∗ .
≤ 2 − − − m m
P P
(cid:16) (cid:17)
Usingthetriangleinequality,wehave
oceφ (X) oceφ(X)
m,sa −
L m φ(X e ) m (φ(X e ) E[φ(X e )])
(t¯
m
e ∗)2+ (t¯
m
e ∗) 1 i=1 ′ i − ∗ + i=1 i − ∗ − i − ∗ .
≤ 2 − − − m m
(cid:12) (cid:16) P (cid:17)(cid:12) (cid:12)P (54) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
Usingsimilararguments,itcanbeshownthat
oceφ(X) oceφ (X)
− m,sa
L m φ(X e ) m (φ(X e ) E[φ(X e )])
(t¯ m e ∗)2+(e ∗ t¯ m) 1 i=1 ′ i − ∗ i=1 i − ∗ − i − ∗ .
≤ 2 − − − m − m
P P
(cid:16) (cid:17)
20Asbefore,usingthetriangleinequality,weobtain
L
oceφ(X) oceφ (X) (t¯ e )2
− m,sa ≤ 2 m − ∗
m φ(X e ) m (φ(X e ) E[φ(X e )])
+ (t¯
m
e ∗) 1 i=1 ′ i − ∗ + i=1 i − ∗ − i − ∗ . (55)
− − m m
(cid:12) (cid:16) P (cid:17)(cid:12) (cid:12)P (cid:12)
Itiseviden(cid:12)tfrom(54)and(55)that (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)
L m φ(X e )
|oceφ m,sa(X) −oceφ(X)
|≤
2(t¯
m
−e ∗)2+ (t¯
m
−e ∗) 1
−
i=1 ′
m
i − ∗
+
m i=1(φ(X(cid:12) (cid:12) (cid:12)i −e ∗) −(cid:16)E[φ(XP i −e ∗)])
,
(cid:17)(cid:12) (cid:12)
(cid:12)
m
(cid:12)P (cid:12)
implying (cid:12) (cid:12)
(cid:12) (cid:12)
L
E oceφ (X) oceφ(X) E (t¯ e )2
| m,sa − | ≤ 2 m − ∗
(cid:2) (cid:3) (cid:2) (cid:3) m φ(X e )
+E (t¯
m
e∗) 1 i=1 ′ i − ∗
− − m
(cid:20)(cid:12) (cid:12) m (φ(X(cid:16) eP ) E[φ(X e(cid:17) )(cid:12) (cid:12)](cid:21) )
+E (cid:12) i=1 i − ∗ − i − ∗ (cid:12) . (56)
m
(cid:20)(cid:12)P (cid:12)(cid:21)
(cid:12) (cid:12)
Thefirsttermof(56)isboundedaboveby L 2(cid:12) fromtheresultderivedinTheorem4.1(cid:12) . Tobound
2Km
thesecondterm,weinvoketheCauchy-Schwarzinequalityandsimplifyasfollows:
m φ(X e ) m φ(X e ) 2 1/2
E (t¯
m
e ∗) 1 i=1 ′ i − ∗ E (t¯
m
e ∗)2 E 1 i=1 ′ i − ∗ .
(cid:20) − (cid:18) − P m (cid:19)(cid:21)≤ − "(cid:18) − P m (cid:19) #!
(cid:2) (cid:3)
UsingTheorem4.1,thefirsttermontheRHSisboundedabove 2/m. Toboundthesecondterm,
K
noticethat
m φ(X e ) 2 2 m φ(X e ) ( m φ(X e ))2
E 1 i=1 ′ i − ∗ E 1 i=1 ′ i − ∗ + i=1 ′ i − ∗
− m ≤ − m m2
(cid:20)(cid:16) P (cid:17) (cid:21) (cid:20) P P (cid:21)
m(Var(φ(X e ))+1)+(m2 m)
′ ∗
1 2+ − −
≤ − m2
Var(φ(X e ))
′ ∗
1+ − +1
≤− m
Var(φ(X e ))
′ ∗
− ,
≤ m
sinceE[φ(X e )]=1,andVar(φ(X e ))=E (φ(X e )2 1.
′ ∗ ′ ∗ ′ ∗
− − − −
Fromtheforegoing,wehave (cid:2) (cid:3)
m φ(X e) Var(φ(X e ))
E (t¯
m
e∗) 1 i=1 ′ i − K ′ − ∗ . (57)
− − m ≤ m
(cid:20) (cid:16) P (cid:17)(cid:21) p
Wenowboundthethirdtermof(56)usingAssumptionA5andJensen’sinequalityasfollows:
m (φ(X e ) E[φ(X e )])
E i=1 i − ∗ − i − ∗
m
(cid:12)P (cid:12)
(cid:12) (cid:12)
(cid:12) m (cid:12)
(cid:12) 1 E[(φ(X e ) E[φ(X (cid:12) e )])2] Var(φ(X −e ∗)) .
≤ mv i − ∗ − i − ∗ ≤ √m
ui=1 p
uX
t
SubstitutingtheboundsonthethreetermsontheRHSof(56),weobtain
L 2 Var(φ(X e )) Var(φ(X e ))
E oceφ (X) oceφ(X) K + K ′ − ∗ + − ∗ .
| m,sa − | ≤ 2m m √m
p p
(cid:2) (cid:3)
Henceproved.
21H ProofofTheorem 5.1
Proof. Theproofcloselyfollowsa similar claim foroptimizingCVaRin a bestarmidentification
framework,seeTheorem3.6in[22].
Consider(45).Sinceφ(X e ) E(X e )issub-exponentialviaLemma3.4,invoking[Propo-
i ∗ i ∗
− − −
sition2.2][27],thefirsttermcanbeboundedas,
P h|n1 Xi=n 1φ(X i −e∗) −E(X i −e∗) |>ǫ/2 i≤(22 ee −− cn 3 2ǫ 82 n2 cc ǫ12 2 ii ff ǫ0 >≤ǫ
4 cc
2≤
1
4 cc 21
ThesecondtermisboundedusingtheresultderivedinTheorem3.2,
P 3L (e ∗ eˆ n)2 > ǫ 2e−24µ L2 3n σǫ 2 (58)
2 − 2 ≤
(cid:18) (cid:19)
CombineboththeboundstogetanupperboundontheOCE-estimateas:
P (cid:2)(cid:12)oceφ n−oceφ(X) (cid:12)>ǫ
(cid:3)≤
2 2e e− −n c3 2ǫ 2 8n2 Cc ǫ12 2 ++ 22 ee −− 242
µ
L4µ 2L 32
n
σ3n ǫσ 2ǫ 2 ii ff ǫ0 >≤ǫ
4
cC≤
21
4 cC 21 (59)
(cid:12) (cid:12)
LettingG=min c2 2 ,c2, µ2 ,theboundcanbewritteninasimplifiedformas:
32C1 8 24L3σ2
n o
P oceφ n−oceφ(X) >ǫ ≤4e−nmin {ǫ,ǫ2 }G (60)
IftheOCE-SRalgorithmelim(cid:2)(cid:12)inatestheoptimal(cid:12)arm(cid:3)inphasei,itmeansthatatleastoneofthearms
(cid:12) (cid:12)
inthesetofthelastiworstarms,denotedas [K],[K 1],...,[K i+1] ,mustnothavebeen
{ − − }
eliminatedinphasei. Therefore,weconcludethat:
K 1 K
P[J =i ] − P oˆcei∗ oˆce[i]
n 6 ∗ ≤ nk ≥ nk
Xk=1 i=K X+1 −k h i
K 1 K
= − P oˆcei∗ ocei∗ oˆce[i] +oce[i] oce[i] ocei∗
nk − φ − nk φ ≥ φ − φ
Xk=1 i=K X+1 −k h i
K −1 K P oˆcei∗ ocei∗ ∆ [i] +K −1 K P oce[i] oˆce[i] ∆ [i]
≤ nk − φ ≥ 2 φ − nk ≥ 2
k=1 i=K+1 k (cid:20) (cid:21) k=1 i=K+1 k (cid:20) (cid:21)
X X− X X−
Wenowboundtheabovetermsindividuallyasfollows.
K −1 K
P oce[i] oˆce[i]
∆
[i]
K −1 K
P oˆce[i] oce[i]
∆
[i] (61)
φ − nk ≥ 2 ≤ nk − φ ≥ 2
k X=1 i=K X+1 −k (cid:20) (cid:21) Xk=1 i=K X+1 −k (cid:20)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:21)
(a)K −1 K −1 4e−nmin (∆ 2[i]∆ 42 [i] )G[i] (cid:12) (cid:12)
(62)
≤
k=1 i=K+1 k
X X−
K −1 K 4e−nmin (∆ 2[i],∆ 42 [i] )Gmax
(63)
≤
k=1 i=K+1 k
X X−
K −1 4ke−nmin (∆[K+ 21−k],∆2 [K+ 41−k] )×Gmax
(64)
≤
k=1
X
22where(a)isdueto(59)and(60),andG =max G . Further,notethat
max i i
∆ ∆2 n K
[K+1 k] [K+1 k]
nmin − , − −
( 2 4 )≥ HlogK
whereH =max i . Bysubstitutingtheabovein(64),weobtain
i 1,2...,K
∈{ } min ∆[i]/2,∆2 [i]/4
n o
K −1 K P oce[i] oˆce[i] ∆ [i] K −1 4ke−(n− HK lo) gG Kmax (65)
φ − nk ≥ 2 ≤
k=1 i=K+1 k (cid:20) (cid:21) k=1
X X− X
Similarly,itcanbeshownthat
K −1 K P oˆcei∗ ocei∗ ∆ [i] K −1 4ke−(n− HK lo) gG Kmax . (66)
nk − φ−≥ 2 ≤
k=1 i=K+1 k (cid:20) (cid:21) k=1
X X− X
Thetheoremfollowsbysubstituting(65)and(66)in(61).
23