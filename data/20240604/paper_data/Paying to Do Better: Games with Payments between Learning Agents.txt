Paying to Do Better:
Games with Payments between Learning Agents
YoavKolumbus JoeHalpern
CornellUniversity CornellUniversity
yoav.kolumbus@cornell.edu halpern@cs.cornell.edu
ÉvaTardos
CornellUniversity
eva.tardos@cornell.edu
Abstract
Inrepeatedgames,suchasauctions,playerstypicallyuselearningalgo-
rithmstochoosetheiractions. Theuseofsuchautonomouslearningagents
has become widespread on online platforms. In this paper, we explore
theimpactofplayersincorporatingmonetarytransfersintotheiragents’
algorithms,aimingtoincentivizebehaviorintheirfavor. Ourfocusison
understanding when players have incentives to make use of monetary
transfers, how these payments affect learning dynamics, and what the
implications are for welfare and its distribution among the players. We
propose a simple game-theoretic model to capture such scenarios. Our
results on general games show that in a broad class of games, players
benefitfromlettingtheirlearningagentsmakepaymentstootherlearners
duringthegamedynamics,andthatinmanycases,thiskindofbehavior
improves welfare for all players. Our results on first- and second-price
auctionsshowthatinequilibriaofthe“paymentpolicygame,”theagents’
dynamicscanreachstrongcollusiveoutcomeswithlowrevenueforthe
auctioneer. Theseresultshighlightachallengeformechanismdesignin
systemswhereautomatedlearningagentscanbenefitfrominteractingwith
theirpeersoutsidetheboundariesofthemechanism.
1 Introduction
Autonomous learning agents have become widespread on online platforms, playing an
ever-largerroleinmanymarketsandeconomicecosystems. Oneprominentexampleis
the billion-dollar market of online ad auctions run by internet giants like Google, Meta,
andMicrosoft,inwhich,duetothespeedoftheseauctions,biddingtrafficiscontrolledby
variousautomatedbiddingagents,providedeitherbytheplatformsthemselves,orbya
third-party. Typically,theseagentsgetsomehigh-levelinstructionsfromtheirusersabout
theirobjectivesandallowedactionspace,andthentheyinteractwithotheragentsinlong
sequencesofrepeatedgames(whichcouldincludethousandsormillionsofauctionsper
hour),usingsomelearningalgorithmtooptimizethelong-termpayoffsfortheirusers.
Weareinterestedinrepeatedgamesofthissortwhereplayersuselearningagentstoplayon
theirbehalf. Wetakeasapointofdeparturetheobservationthat,inthissetting,usersmay
allowtheiragentstomakepaymentstootheragentsinordertoaffectthegamedynamic.
Inthispaper,westudytheeffectofconsideringsuchpaymentsbetweentheagentsonthe
long-termoutcomesoftheinteraction.
Preprint.Underreview.
4202
yaM
13
]TG.sc[
1v08802.5042:viXraPlayer2
C D
C 2/3,2/3 0,1
Player1
D 2,0 1/3,1/3
Figure1:Aprisoner’sdilemmagame.
The idea that payments and other types of financial benefits outside of the mechanism
can affect behavior in the mechanism has been observed before, in areas ranging from
blockchainfeemarkets,whereithasbecomeoneoftheguidingprinciplesintheevolving
designofthesemarkets1(see[24,79]and[8,9,25]),tofairdivision[64,65]. Wedeferamore
extendeddiscussionofrelatedworktoAppendixA.
Thepossibilitythatlearningagentscouldtransferpaymentsamongthemselvesduringtheir
gamedynamicsraisesseveralbasicquestions. First,whendoplayershaveincentivestolettheir
agentsusepayments? Second,howdopaymentsbetweentheagentsaffectlearningdynamics? And
third,whatarethelong-termimplicationsofpaymentsamongtheagentsontheplayers’utilities,
thesocialwelfare,andinauctions,therevenuefortheauctioneer?
Asinmuchofthepriorliterature(e.g., [16,28,32,38,46,53,90]), weassumeagentsare
no-regretlearners; thatis,theyuselearningstrategiesthatresultinoutcomessatisfying
theno-regretconditioninthelongterm. Unfortunately,asiswellknown,inmanygames
no-regretagentscanendupplayingstrategiesthatyieldlowutilitycomparedtocooperative
outcomesthatcouldpotentiallyhavebeenobtainedinthegame. E.g., intheprisoner’s
dilemma,theyendupdefecting,sincethatisthedominantstrategy. Thishasledtoagreat
dealofinterestindesigningmechanismswherewecanget,insomesense,betteroutcomes.
Notably,incontrasttoworksinmechanismdesigninwhichanexternalentityprovides
incentivesorrecommendationsaimingtoimprovewelfare[7,10,62,88],inourscenario
thereisnoexternalentity,andplayersareonlyinterestedintheirownindividualpayoffs.
Beforegivinganexample,letussketchthegeneralstructureofthemodelwehaveinmind.
Asmentioned,thereisanunderlyinggameandthemodelofwhatwecallapaymentpolicy
game(orjustapaymentgame)proceedsintwophases.Inthefirstphase,eachplayerichooses
apaymentpolicy,thatdetermines,foreachotheragentj,howmuchagentiwillpayagent
jateachroundintheagents’dynamicsasafunctionoftheoutcome(i.e.,thejointaction
profileperformedbytheagents)intheunderlyinggameinthatround. Inthesecondphase,
theagentsplaytheunderlyinggamerepeatedly,choosingtheiractionsaccordingtotheir
learningalgorithm(takingthepaymentsintoaccount). SeeSection2forfurtherdetails.
Warm-up example: With this background, consider the variant of prisoner’s dilemma2
showninFigure1. Asmentionedabove,standardanalysisshowsthatwhenbothplayers
useno-regretagents,eachagentwillquicklylearntoplayitsdominantstrategy,whichis
todefect(i.e.,playstrategyD);thedynamicswillconvergetotheNashequilibriumofthe
stagegamewherebothagentsalwaysdefectandeachplayergetsanexpectedpayoffof1/3.
Nowweaskwhatcanplayer1achieveifheallowshisagenttomakepaymentstotheother
agentduringthegamedynamics? Considerthepaymentpolicywhereplayer1’sagentpays
player2’sagent1/3+ϵifplayer2’sagentcooperates,forsomeϵ >0,andpaysnothingif
player2’sagentdefects. Itiseasytoseethatthegamewiththesepaymentsisdominance
solvable: byrepeatedlyeliminatingstrictlydominatedstrategies,weareleftonlywiththe
strategy(D,C)astheuniqueequilibrium,andsotheensuingdynamicswillconvergeto
thatoutcome(seeAppendixB),withpayoffs(2−1/3−ϵ,1/3+ϵ)forthetwoplayers.
Itturnsoutthatthisoutcomecanbeobtainedasan(ϵ-)equilibrium3ofthepaymentgame.
Thereisalsoasecondϵ-equilibriumofthepaymentgame,obtainedbyswitchingtherolesof
players1and2,butduetotheasymmetryinthepayoffsoftheunderlyinggame,thesocial
welfare in this second equilibrium is 1, not 2. Importantly, however, both equilibria are
1Whileresearchinthisareahasfocusedonmanipulationsinvolvingtheauctioneer(the“miner”
whoallocatesspacefortransactiontobeincludedinthenext“block”),westudythescenariowhere
paymentstakeplaceamongthebiddingagentsthemselves.
2Notethatthisvariantissomewhatnonstandard,inthatthepayoffsarenotsymmetric.
3Inanϵ-equilibrium,noplayercanincreasetheirpayoffbymorethanϵbyalteringtheirstrategy.
2ParetoimprovementsovertheNashequilibriumoftheunderlyinggame,andtheplayers’
welfaresignificantlyincreasescomparedtothegamewithoutpayments.
Weshow,usingasimilaranalysis,thatwegettheseequilibriaandimprovementinsocial
welfareingeneralprisoner’sdilemmagameswheneverthemaximumwelfaregapinthe
gameislarge(aboveafactorof2). Moreover,whileinthegamewithoutpaymentstheprice
ofanarchy(PoA)andpriceofstability(PoS)—theratiobetweenthesocialwelfareobtained
fromtheworst-case(resp.,best-case)Nashequilibriumandtheoptimalsocialwelfare—
are unbounded, with payments, both PoS and PoA are bounded by a factor of 2 in the
symmetric case, and in the asymmetric case PoS is bounded, but PoA is not, due to the
welfaregapbetweenthetwoequilibriaofthepaymentgame. SeeAppendixB.
Althoughprisoner’sdilemmaisverysimple(bothplayershavestrictlydominantstrategies),
theobservationswemaderegardingthisexampleapplymorebroadly. Specifically,inmany
games,playershaveincentivestousepaymentsbetweentheiragents,andtheuseofpaymentscan
oftenenableplayerstoreachmorecooperativeoutcomes,withhighersocialwelfare.
Ourresults: Inthispaper,weinitiatethestudyoftheincentivesofplayerstousepayments
withtheirlearningagentsandthepotentialimpactofsuchpayments. Weanalyzefirst-and
second-priceauctionsasourmaincasestudyinSection3. Inthefollowingsections,we
studygeneralpropertiesofpaymentgames;Section4focusesonunilateralpaymentsand
Section5focusesontwo-playergames. Ourresultsinallthesesettingsprovidecomparative
staticsbetweentheoutcomesoflearningdynamicswithoutpaymentsandthoseobtainedin
equilibriaofthepaymentgame.
Morespecifically,insecond-priceauctions,Theorem1showsthatplayershaveincentivesto
providepaymentpoliciestotheiragents,andthatinequilibriumofthepaymentgame,the
playersmayreach,inthelong-termlimit,fullcollusionwheretheycapturealmosttheentire
welfare,leavingtheauctioneerwithvanishingrevenue. Infirst-priceauctions,Theorem2
showsthatalsohereplayershaveincentivestousepayments,andequilibriaofthepayment
gameleadtolow(butstillpositive)revenue.4 Then,inSection4(Theorems3,and4),we
showthatinaverybroadclassoffinitegames,5thereisatleastsomeplayerwhohasthe
incentivetousepayments,andwecharacterizecaseswhereapaymentpolicybyasingle
agentcanleadthedynamicstotheoptimalwelfareoutcomewhileimprovingthepayofffor
theassociatedplayeraswell. InSection5,weshowthatintwo-playergames,payments
alwaysleadtoParetoimprovementscomparedtothegamewithoutpayments(Theorem5),
andthatinabroadclassofgames,evenincludinggameswithstrictlydominantstrategies
(asourprisoner’sdilemmaexampleshownabove),atleastoneoftheplayerswouldstrictly
benefitfromusingpayments,andsonotusingpaymentsisnotstable(Theorem6).
Fromahigher-levelperspective,ourresultshighlightachallengeforauctiondesignand
marketdesignmorebroadly: weshowthatusersoflearningagentsquitegenerallyhave
incentives to allow their automated agents to make payments during their interactions.
Whentheseincentivesarecoupledwiththerighttechnology, particularly, sophisticated
AIagentsandflexibletransactionmediasuchasthoseonblockchainplatforms,onecan
easilyimagineanoutlookwhereagentsaretradingamongthemselves“underthehood,”
andtheassociatedmarketschangetheirbehavior,equilibria,andoutcomes. Ourresults
demonstratethatthesechangescanbeverysignificant,underlining,ontheonehand,the
potentialimprovementinefficiency,butontheotherhand,theneedtobetterunderstand
thesechangesforconcretemarkets,tobeabletodesignthemaccordingly.
2 Model
Inourmodel,weconsiderscenarioswherewehaveplayersusinglearningagentsinsome
repeatedgame,andstudythesettingwhereplayerscanaugmenttheiragentsbyallowing
themtomakepaymentstootheragentsthatdependontheactionsoftheseagentsduring
4Enroute,wealsoprovidethefirstsimpledynamicapproachingtheminimum-revenuecoarse
correlatedequilibriumofthefirst-priceauctionshownin[35];seeObservation1.
5Finitegamesaregameswithdiscreteactionsetsandboundedpayoffs.Notethatinthegeneral
modelofauctions,thebidspaceiscontinuous,andsoouranalysisinthissettingisdifferent.
3the game dynamics. The learning algorithms used by the agents are assumed to satisfy
the regret-minimization property,6 but agents are not restricted to using any particular
algorithm, and the players themselves are interested in their long-term payoffs. As our
analysisreliesontheregret-minimizationpropertyitselfandconsiderstheoutcomesinthe
limitT → ∞,whereT isthenumberofgamerounds,ourresultsapplyregardlessofthe
specificregretboundsofthelearningalgorithmsused,aslongastheagentsachieveregret
sublinearinT. Ourmodelhasthefollowingcomponents.
• Thegame: ThereisanunderlyinggameΓ = {[n],S,{u }n },where[n]isthesetof
i i=1
players,Sisthespaceofjointactions,andu : S → [0,1],i =1,...,naretheutility
i
functionsinthatgame.
• Agents: Everyplayerusesano-regretagenttoplaythegameontheirbehalfforT
rounds. Denotethesetoftheseagentsby A,where A ∈ Aistheagentofplayer
i
i ∈ [n]. Agentschooseactionsusingtheirno-regretalgorithms. Theactionofagent
A attimet ∈ [T]isdenotedst andtheactionprofileofalltheagentsisdenotedst.
i i
• Payments: In addition to choosing actions, the agents make payments to other
agentsthatdependontheactionsst chosenbytheagents,accordingtopayment
policiesdefinedbytheassociatedplayers.
• Paymentpolicies: Eachplayerichoosesapolicythatdetermines,foreachaction
profiles ∈ Sandplayerj ∈ [n]\{i},thepayment p ij(s) ∈R +fromagentitoagent
j when the outcome in the most recent step is s. We assume that payments are
bounded: p ij(s) ∈ [0,M],where M ∈R + issomelargeconstant.
• Agentutilities: Ineverystept,theagentsplayanactionprofilest ∈ Sandobserve
therealizedoutcomeandpayments. Theutilityforagentiattimetwhentheaction
profilethatwasplayedwasst isvt = u (st)+∑ (cid:0) p (st)−p (st)(cid:1) .
i i j̸=i ji ij
• Playerutilities: Theplayers’utilitiesaretheirlong-termaveragepayoffs: UT =
i
E[ T1 ∑ tT =1v it];weareparticularlyinterestedinthelimitU
i
=lim T→∞U iT.
• Sincetheanalysisoflong-termpayoffsignoresfinite-timecosts,weassumew.l.o.g.
thatifaplayerisasymptotically(inthelimitT → ∞)indifferentbetweenmakinga
paymentandnotmakingthepayment,theplayerprefersnotmakingthepayment.
Themodelabovedefinesapayment-policygame(inshort,apaymentgame)betweenusersof
learningagentsthatisspecifiedbyΓ, A,andT. Inordertounderstandthebasicproperties
ofpayment-policygamesandhowtheincentivesofplayerschangecomparedtogames
withoutpayments,ouranalysisofequilibriaandpotentialdeviationsfocusesonone-shot,
full-informationpayment-policygames.
Afundamentalquestionthatarisesinourcontextis: “Whenwouldplayershaveincentives
tousepaymentpolicies?” Conversely,whataretheconditionsforagametobe“stable”in
thesensethatplayersdonothaveincentivestousesuchmanipulations?
Definition1. AgameΓisstableforasetoflearningagentsifzeropaymentsareanequilibrium
ofthepayment-policygameassociatedwithΓwiththeseagents. Agameisstableifitisstablefor
anysetofregret-minimizingagentsfortheplayers.
3 AuctionswithPaymentsbetweenLearningAgents
Togetadeeperunderstandingoftheincentivesofusersinonlineplatformstousepayments
withtheirlearningagentsandthepotentialimpactofsuchpayments,wefocusononeclass
ofgamesthathavealreadybeenwidelyanalyzed: auctionswithautomatedbidders. We
considerthesimplestmodeloffirst-andsecond-priceauctions,whereateachtimet ∈ [T]
asingleidenticalitemissold. Eachplayerihasavaluev fortheitem,andweindexthe
i
playersindecreasingorderoftheirvalues,v
1
≥v
2
≥···≥vn.Atroundt,eachagentsubmits
abidbt andtheauctionmechanismdeterminestheidentityofthewinnerandaprice pt.
i
6WeprovidethedefinitionofregretminimizationandotherstandarddefinitionsinAppendixC.
4Thepayoffforthewinningagentfromtheauctionisv −pt;theotheragentsgetpayoff
i
zero. Inadditiontopayoffsfromtheauction,agentsgetapayoffaccordingtothepayments
betweentheagents(asdefinedinSection2). Utilitiesareadditiveovergamerounds. Inthe
first-priceauction,thepaymentisequaltothehighestbid;inthesecond-priceauction,the
paymentisthesecond-highestbid. Inbothcasesthehighestbidderwins,andweassume
tie-breakingaccordingtotheindexoftheagent(asisdone,e.g.,in[35]),sothatifi < jand
iand jbothhavethesametopbid,theniistakentobethewinner. Allouranalysesare
similarforarbitrarytie-breakingrules,butbreakingtiesinfavorofthehighest-valueagent
simplifiesthepresentation. FormalproofsforthissectionareinAppendixD.
Second-priceauctions: Thesecond-priceauctionhasbeenwidelystudied[86](seeAp-
pendixA).Whiletheauctionisknowntobeincentivecompatible, itisalsoknownthat
truthful bidding forms only one out of many Nash equilibria of the stage game. In the
contextoflearningdynamics,ithasbeenshownthatregret-minimizingagentsinthisauc-
tiondonotconvergetothetruthfulequilibrium;instead,theyreachsomedegreeoftacit
collusion[53]withlowerrevenuetotheauctioneerthanthatobtainedundertruthfulbids.
Specifically, simplifying slightly, second-price auctions have two types of non-truthful
equilibria. The first type is “overbidding equilibria,” where the high-value player bids
anythingabovehisvalueandthelow-valueplayerbidsanythingbelowthehighvalue. The
secondtypeis“low-revenueequilibria,”wherethehigh-valueplayerbidsanythingabove
thelowvalueandthelow-valueplayerbidsanythingbelowthelowvalue.7 Thelattertype
isespeciallyinterestingforoursettingsinceanymixtureofsuchequilibriaisconsistent
withregretminimization,butyieldshighwelfaretotheplayers. Thissuggeststhatwhen
learningagentsexchangepayments,thehigh-valuedagentmaybeabletousepaymentsto
influencethedynamicswiththeotheragentstoinduceabetterequilibriumforhimself.
Weshowthat,indeed,whenagents“tradeoutsideofthemechanism”inthiswayduring
theirdynamics,thiskindofcollusionemergesfromtheagents’interactioninastrongway,
potentiallyleadingtozerorevenuefortheauctioneer.
Theorem1. Thesingle-itemsecond-priceauctionwheretheplayers’toptwovaluesarev > v
1 2
isnotstableforanyregret-minimizingagentsfortheplayers,andthepayment-policygamehasan
ϵ-equilibriumwheretheplayerscapturethefullwelfareandtheauctioneergetsrevenuezero.
Proofsketch: Theideaoftheproofis,first,toconstructaunilateralpaymentpolicyforplayer
1,parameterizedbyasingleparameterϵthatdeterminestheamountthatagent1paysto
theotheragents,suchthatthispolicyinducesadynamicwhereplayer1’s(i.e.,thehigh
player’s)agentbidshisvalueandalltheotherlearningagentsbidzero. Wethenshowthat
foreveryotherplayer,usingthezero-paymentpolicyisinfactabestresponse,andthatthe
(net)payoffforthehigh-valueplayercanbearbitrarilyclosetothefullwelfare,soplayer1
cannotimprovehispayoffbymorethanϵforanyϵ >0. (Note,thatwiththesecond-price
paymentrule,iftheagentswerenotrestrictedtousingfinitepayments,theplayerswould
belockedintoagamewithoutanequilibrium,whereeachplayertriestocommittomaking
thehighestbidandincentivizetheotherstobidzero.)
First-price auctions: In contrast to the second-price auction, the first-price auction is
knownnottobeincentivecompatible. Intuitively,thedirectdependenceoftheutilityonthe
bidrequiresplayerstoconstantlyoptimizetheirresponsestothebidsoftheotherplayers.
Therehasthusbeensignificantinterestinlearningstrategies,outcomes,anddynamicsin
thissetting(seeAppendixAforreferences). Interestingly,despitethesignificantdifference
fromthetruthfulsecond-priceauction,itiswellknown(andnothardtosee)thattheNash
equilibriumofthefirst-priceauctionyieldsthetruthfuloutcomeofthesecond-priceauction.
Ithasbeenshownthatmean-based[19](seeAppendixC)regret-minimizationdynamics
[53]andbest-responsedynamics[71]canconvergeonlytothisoutcome.
In [35], it was shown that the first-price auction also has “collusive” coarse correlated
equilibria8 (CCE)withlowerrevenuefortheauctioneerthanthesecond-priceoutcome,
7Bothtypesofequilibriaariseforanyn;wedescribethetwo-playercaseforeaseofexposition.
8Anequilibriumnotionequivalenttoallplayershavingnoregret.See[78]andAppendixC.
5andhigherutilityfortheplayers. Theexistenceofsuchequilibriaposesanopportunityfor
playerstotryandreachcooperativeoutcomesandincreasetheirpayoffs(attheexpense
oftheauctioneer). However,foralmostadecade,nonaturalprocesshasbeendescribed,
tothebestofourknowledge,thatattainsanyoftheseequilibria. Moreover,in[53],itis
shownthatevenascenariowhereplayerscanmanipulatetheobjectivefunctionsoftheir
learningalgorithmsisnotsufficienttoreachanyformofcooperation.Infact,convergenceof
standardno-regretagentstothesecond-priceoutcomeinducesadominantstrategyforusers
toprovidethetrueobjectivesfortheiragents. Tounderstandhowcooperativeoutcomes
couldperhapsstillbereached,weobservethatinthecollusiveequilibriadescribedin[35],
thelow-valueplayerwinsinsomefractionoftheauctionsandhaspositiveutility,whereas
undersimpleno-regretdynamics(asthosestudiedin[53]),onlyasingleplayerwinsinthe
limit. Thissuggeststhatpaymentsbetweentheagentsduringtheirdynamicscouldenable
theagentstosharethewelfareandreachcooperativeoutcomes.
Thefollowingtheoremshowsthatplayershaveanincentivetousepaymentsinafirst-price
auction,andinequilibriaofthepaymentgame,theplayersreachcooperativeoutcomes,
withasignificantreductioninrevenuefortheauctioneer.
Theorem2. Thesingle-itemfirst-priceauctiontwoplayerswithvaluesv ≥ v andanymean-
1 2
basedbiddingagentsisnotstable,andeveryequilibriumofthepaymentgameisastrongPareto
improvement(i.e.,bothplayersarebetteroff)andhaslowerrevenuefortheauctioneercomparedto
thegamewithoutpayments.
Weprovidehereanoutlineoftheproof,breakingitintoasequenceoflemmas. Theproofs
ofthelemmasaredeferredtoAppendixD.Thefirstpartoftheproofistheconstruction
ofaunilateralpaymentpolicyforthehigh-valueplayerandtheanalysisoftheresulting
dynamics. Inthispolicy,theagentwiththehighervaluepaysη >0tothelow-valueagent
wheneverthelatterbidszero. Wederivethe(unique)mixedNashequilibriumofthegame
withthispaymentpolicy,withηasaparameter(Lemma1). Wethenevaluatetheutilities
oftheplayersinthatequilibriumandshowthattheoptimalvalueofηforthehigh-value
playerishalfthevalueofthesecondplayer(Lemma2),andthatinthiscase,theplayers
havehigherutilitiesthaninthegamewithoutpayments. Wenextprovethatinthegame
betweentheagents,whiletheagentsdonotplayamixedequilibrium,andtheirstrategies
arecorrelated,nevertheless,themarginaldistributionsandpayoffsarethesameasinthe
mixedNashequilibriumwederived(Lemma3). Finally,usingthefactthattheseutilities
fortheplayersareobtainedwithaunilateralpaymentbythehigh-valueplayer,weshow
thattheseutilitiesboundfrombelowtheutilitiesinanyequilibriumofthepayment-policy
game. Wenowstatethelemmascarefully.
Lemma1. Considerthesingle-itemfirst-priceauctionwithtwoplayersandplayervaluesv ≥ v ,
1 2
whereplayer1’spaymentpolicyissuchthatagent1paysηtoagent2,where0< η < v ,whenever
2
agent2bidszero. TheresultinggamebetweentheagentshasauniqueNashequilibriumwherethe
cumulativedensityfunctionsofthebidsofagents1and2areF (x)= η andG (x)= v1−v2+η ,
1 v2−x 2 v1−x
respectively(sothebiddensityfunctionsaresupportedon[0,v −η]).
2
Lemma2. IftheagentsreachtheNashequilibriumutilities,theoptimalvalueofηforplayer1is
v 2/2. Withthisvalueofη,theutilitiesfortheplayersarev 1−v 2+ 4v v2 2
1
forplayer1and v 22 forplayer
2. Thewinningfrequencyofplayer2isintheinterval[0,3/8],withthelowerboundbeingattained
asv /v →0andtheupperboundbeingattainedasv /v →1.
2 1 2 1
TheresultaboveisforNashequilibrium. Whileinprinciple,no-regretagentsmayreachan
arbitraryCCEandnotnecessarilythisoutcome,thenextlemmashowsthatthefamilyof
Nash-equilibriumdistributionsparameterizedbyηcaptureswellthemarginaldistributions
andutilitiesofthebroadfamilyofmean-based[19]no-regretagentsinthesegames.
Lemma 3. Consider the game where player 1’s agent pays η to player 2’s agent whenever the
latteragentbidszero. FixaCCEwithmarginaldistributions F and G towhichthedynamics
1 2
ofmean-basedagentsconvergewithpositiveprobability. Then, F (b) = FNE(b) = η ,G (b) =
GNE(b)=
v1−v2+η,andtheplayers’utilitiesarethesameasintheN1 ashequ1 ilibrium.v2−b 2
2 v1−b
Remark. Theorem2canbeextendedtosomeextenttonplayersbyareductiontoagamebetween
thetwotop-valuedplayers. Inthisreduction,allthelemmasextendwithessentiallynochangein
theirproofs,sotheresultthatfirst-priceauctionsarenotstableextendsaswell. SeeAppendixD.2.1.
6(a)Cumulativebiddistributions (b)Winningfrequencies
Figure2:Dynamicsinfirst-priceauctions.
Figure 2 shows simulation results with Hedge (a version of multiplicative weights [82])
agentsinasequenceof100,000auctions. TheleftpanelcomparestheNashequilibrium
theoreticalpredictionfromLemma3withtheempiricalCDFfromtheagents’dynamics
with v = 1,v = 0.5. The right panel compares the theoretical winning frequencies of
1 2
the players as specified in Lemma 2 with the empirical frequencies as a function of the
ratio of values v /v in multiple simulations. The long-term marginal bid distributions
2 1
andwinningfrequenciesareclearlyconsistentwiththetheoreticalpredictions. Weobserve
similarresultswithotheralgorithmvariantslikefollowtheperturbedleaderandlinear
multiplicativeweights[3]. Thereisverylittlevariationbetweensimulationinstances.
Interestingly, itturnsoutthatthesedynamicsoftheagentswithpaymentsrecover, ina
specialcase,aknowncollusiveCCEdistributionoftheauctionwithoutpayments.
Observation1. Forsymmetricbidderswith v = v = 1and η = 1/e, theNashequilibrium
1 2
bid distribution of the game with payment η is the same as that of the minimum-revenue coarse
correlatedequilibriumofthestandardfirst-priceauction(withoutpayments)givenin[35].
Notice,however,thatinourgame,theplayers’utilitiesaredifferentfromthoseoftheCCE
withoutpayments. Inparticular,thepaymentηthatresultsinthethisCCEdistributionis
notoptimalforplayer1,soitisnotanequilibriumofthepayment-policygame.
WearenowreadytoconcludetheproofofTheorem2byusingthelemmasabovetobound
frombelowtheutilityforthehighplayerinanyNashequilibriumofthepaymentgame.
Theideaistousethefactthatthegameanalyzedinourproofisinducedbyaunilateral
paymentpolicybythehigh-valuedplayer. Inanyequilibrium,player1canconsiderthe
deviation in which he rejects (pays back) all the payments he received and makes this
unilateralpayment,leadingtoautilityofv −v +v2/4v . ThefullproofisinAppendixD.2.
1 2 2 1
Toevaluatethepotentiallossinwelfareinthegameconsideredabove,wecananalyzethe
winning frequencies from Lemma 2. The reduction in welfare is equal to the difference
v −v timesthefractionoftimesinwhichthelow-valueplayerwins. Thisreductionin
1 2
welfareismaximized,ascanbeverifiedbynumericalcalculation,whenv /v ≈0.50959...,
2 1
atwhichpointthereductionisapproximately8.96%. Whenconsideringthereductionin
revenue,sincethesupportofthebidsisbetweenzeroandv /2,almostallthepaymentsare
2
strictlylessthanv /2,sotherevenueisreducedtolessthanhalftherevenueoftheoutcome
2
ofthegamewithoutpayments. Thus,theplayersmanagetoimprovetheirutilitiesatthe
expenseoftheauctioneer,witharelativelysmalllossinefficiency.
4 Single-PlayerManipulations
Wenowturnourattentiontogeneralgameswithnplayersandfocusonanalyzingtheeffects
ofthesimplesttypeofmanipulations: paymentpolicieswhereonlyasingleagentpays.
Bymakingsufficientlyhighpayments,clearly,anagentcouldinduceanypureoutcomein
thegame. Themainquestionsarethusnotaboutthepowerofpaymentpolicies,butabout
whenaplayerhastheincentivetousesuchpolicies,andwhataretheimplicationsofsuchprofitable
paymentpoliciesforthewelfareofotherplayers. ProofsforthissectionareinAppendixE.
7Notation:Denotethewelfareofanoutcomesbyw(s)andthebest-responseutilityofplayer
itoactionprofilesbyu iBR(s)=max
s
i′∈Siu i(s i′,s−i). Forthefollowinganalysis,itisusefulto
defineanotionofregretthatmeasurestheopportunitycostperstepforplayeriofplaying
the game where the strategy profile x is played compared to the benchmark of his best
actioninhindsightinthe(different)gamewherey(ratherthan x)isplayedbytheother
players. Toavoidconfusionwithstandardregret(whichconsidersthebenchmarkofthe
bestresponseinhindsighttox),wecallthis“alternativeregret.” Intuitively,itmeasuresthe
extenttowhichaplayerregretsnotincentivizingotherstoplayyratherthanx.
Definition2. Letx,ybetwojointdistributionsontheplayers’jointactionspaceS.Thealternative
regretofplayeri underthedistributionofplay x comparedtobestrespondingtothealternative
distributionofplayyisR (x,y) = uBR(y)−u (x).
i i i
AttimeT,wehaveanexpecteddistributionofplayx(T)withwelfarew(x(T)),wherex(T)
approachesthesetofCCEsofΓasT → ∞. Tosimplifynotation,weomitthedependenceon
Tanddiscussitonlywhennecessary. TheoptimalwelfareisdenotedOPT =max s∈Sw(s).
Thefollowingtheoremcharacterizesthecasesinwhichthereisaplayerinthegamewho
cangainfromincentivizingtheotheragentstoreachtheoptimal-welfareoutcome.
Theorem3. FixafinitegameΓandaset Aofregret-minimizingagents. Lettheoptimalwelfare
outcome9ofΓbey∗. Ify∗ isaNashequilibrium,thenthereisaplayerisuchthatiincreaseshisown
payoffandthepayoffsofalltheotherplayersbyusingapaymentpolicy p thatinducesy∗ asthe
i
uniquelong-termoutcomeoftheagents’dynamics. Ify∗ isnotaNashequilibrium,thesameholdsif
thereexistsaplayeriforwhichthewelfaregapOPT−w(x)isgreaterthan∑ R (x,y∗).
j̸=i j
Analysis: Toprovethetheorem,webeginbyestablishingtwolemmasthatquantifythe
costsandgainsforaplayerofpushingtheagents’dynamicstoanarbitrarypureoutcome.
Toassuretheconvergenceofarbitraryno-regretagentstoy∗,thepaymentsmustinducey∗
istheuniqueCCE,10whichimpliesthatitisalsotheuniqueNashequilibrium. Onewayto
dosoisbymakingyanequilibriumindominantstrategies. Althoughweakerrequirements
wouldbesufficientforourpurpose(suchasinducingadominance-solvablegame),using
dominantstrategiessimplifiestheanalysis. Moreover,itturnsoutthatitleadstothesame
paymentsandthesameutilitiesfortheplayersinthelongtermasinducingauniqueCCE:
[62]analyzedamechanism-designscenariowhereadesigneraddsexogenouspaymentsto
thegame,andtheyobservedthattheactualcostofinducinganoutcomesasanequilibrium
indominantstrategies—whichtheycalledtheoptimalk-implementationofs,k(s)—isequal
tothecostofinducingthatoutcomeasaNashequilibrium. Combiningthiswiththefact
thatanequilibriumindominantstrategiesisalsotheuniqueCCE,wehavethat,indeed,
thepaymentsneededforinducingauniqueCCEoranequilibriumindominantstrategies
are the same. The intuition for this result is that further payments that are intended to
assuredominantstrategiesareinfactmadeonlyofftheequilibriumpath,andarethusnot
actuallymadewhenthegameisplayed. Asimilareffectwasalsousedin[7]inthecontext
ofprovidingcollateralcontractstomitigatestrategicriskandincentivizeinvestments.
This intuition also carries over, to some extent, to our setting, where one of the players
uses a payment policy to manipulate the agents’ dynamics. But our case is different in
severalways. First,importantly,inourcasetherearenoexternalfundsinjectedintothe
game. Instead,thepaymentsthataplayerallowshisagenttomaketootheragentsaretaken
fromhisownpayoffs. Second,asweshowbelow,thecostofinducinganoutcomesasan
equilibriumislowerthank(s),sincetheplayerwhowishestoinducesastheoutcomeof
theagents’dynamicsdoesnotmakepaymentstohisownregret-minimizingagent. Third,
sinceinourcasethelearningagentsdonotreasonaboutpaymentpoliciesbutratherlearn
torespondovertime,someagentswillplaydominatedactionsforsometime,whichwill
leadtoadditionalshort-termcosts. Thisisformallyexpressedinthefollowinglemma.
Lemma4. Fixaplayeriandpureoutcomey. Playericanincentivizeyastheuniquelong-term
outcomeofthedynamicwithanexpectedcostpertimestepof cost (y) = k(y)−R (y,y)+o(1).
i i
9Tosimplifytheanalysis,weconsiderthegenericcaseofauniqueoptimaloutcome.Ingameswith
equalitiesinutility,thiscanbeobtainedbyconsideringinfinitesimalperturbationsoftheutilities.
10WithmultipleCCEs,no-regretdynamicsmayfailtoconvergeeveninthetimeaverage[54].
8Thenextlemmaspecifiestheconditionunderwhich,givenadistributionxtowhichtheno-
regretagentsconvergeinexpectationinTrounds,thereisaplayerwhocanuseapayment
policytoincreasehispayoffbypushingthedynamictoadifferentoutcome.
Lemma5. FixafinitegameΓandasetofregret-minimizingagentsfortheplayers. Ifthereexistsa
playeriandoutcomeysuchthatw(y)−w(x) > ∑ R (x,y),thenicanincreasehispayoffby
j̸=i j
makingpaymentsthatinduceyastheuniqueoutcomeoftheagents’dynamics.
Intuitively,theincreaseinwelfaremustbelargeenoughtocompensatetheotherplayersfor
theirregretforplayingxrelativetotheirbestresponsestothealternativeoutcomey.
Corollary1. Ifthedynamicswithoutpaymentsapproachawelfarew(x)lowerthanthewelfareof
someNashequilibriumy,then,sinceinequilibriumR (y,y) =0,thereisaplayerwhocanincrease
i
hispayoffbyusingapaymentpolicythatinducesyasthelong-termoutcomeofthedynamics.
ThelemmasaboveprovidethebasisforprovingTheorem3. SeeAppendixEfortheproof.
From the analysis above, we observe that in many cases players can gain from using
payment policies to divert the agents’ dynamics to more favorable outcomes for them.
Thefollowingtheoremshowsthatthisistrueforabroadclassofgames. Forgameswith
PoS =1,thisisalreadyimpliedbyTheorem3,butthefollowingresultismoregeneral.
Theorem4. Afinitegameinwhichthereexistsacoarsecorrelatedequilibriumwithlowerwelfare
thanthebestNashequilibriumisnotstable. Thisistrue,inparticular,ifPoA ̸= PoS.
Remark. Theconverseisnottrueingeneral: therearegameswithPoA = PoSthatarenotstable.
Onesuchexampleistheprisoner’sdilemmagameinFigure1.
5 Two-PlayerGames
Inourprisoner’sdilemmaexampleinSection1,wesawthattheplayershadincentivesto
usepaymentsbetweentheiragents,andinequilibriaofthepaymentgame,bothplayers
hadhighergainsthaninthegamewithoutpayments. Wenowshowthattheseresultshold
quitegenerallyfortwo-playerinteractions. TheproofsforthissectionareinAppendixF.
Theorem5. Everyequilibriumofatwo-playerpayment-policygameisa(possiblyweak)Pareto
improvementovertheno-paymentsoutcomeofthisgame.
Theintuitionoftheproofisthatinordertohaveapositivepaymentinequilibrium,some
playermustbenefitfrommakingthepaymentwhiletheotherbenefitsfromreceivingit.
If some player is worse off with the payments, then they always have a deviation that
effectivelycancelsthepayments. Withmorethantwoplayers,theremaybeplayerswho
cannotprofitablycounteractsuchpaymentsmadeamongothers.
The next theorem addresses the question of incentives to use payments. The theorem
considersgamesinwhichno-regretdynamicsconvergetoasingleCCE,andshowsthat
despitethesimplicityoflearninginthesegames,inmanycasesplayersstillhaveanincentive
tousepaymentpolicies.Theintuitionforthisresultisthatintwo-playerinteractions,players
canutilizepaymentstoassumetheroleofaStackelbergleaderinthegame.
Theorem 6. Any finite two-player game with a unique coarse correlated equilibrium and two
differentpure-strategyStackelbergoutcomes(dependingonwhichplayeristheStackelbergleader)is
notstableforanyregret-minimizingagentsfortheplayers.
6 Conclusion
Autonomouslearningagentsarewidelyandincreasinglyusedinmanyonlineeconomic
interactions,suchasauctionsandothermarkets. Motivatedbythistransitiontoautomated
systemswithsophisticatedAIagents, westudiedthescenariowhereautomatedagents
alsooffermonetarytransferstootheragentsduringtheirdynamics. Ourresultsshowthat,
generally,strategicusershaveincentivestousepaymentswiththeirlearningagents,and
thatthiscanhavesignificantimplicationsfortheoveralloutcomes. Ourfindingshighlighta
challengeformechanismdesignintheAIera,underliningtheneedtobetterunderstand
bothagentdynamicsanduserincentivesinautomatedmarkets.
9A FurtherRelatedWork
Wefollowalongresearchtraditiononlearninganddynamicsingames,fromearlywork
ofBrown,Robinson,Blackwell,andHannaninthe1950s[13,20,43,76],throughseminal
workinthefollowingdecades[39,40,44]andcontinuouslysince[1,15,26,27,37,46,51,
52,53,54,55,60,83]. See[23,45]foranoverviewofthefoundationsofthefield. Thenotion
ofregrethasbeencentralthroughoutthisworkasatooltodefinelearningoutcomesand
objectivesanddesignalgorithmstoachievethem.
No-regretlearninghasbeenbroadlystudiedinauctions,withtwoprominentlinesofwork
focusingonthepriceofanarchyinvariousauctionformatswithregret-minimizingbidders
[14,21,28,46,77,80,84]andontheeconometricproblemofinferringbidderpreferences
[41,67,68,69]. Otherworkhasstudiedautomatedbiddingalgorithmsforauctionswith
morecomplexfeatures,suchasbudgetconstraints[11,30,37],orlearningreserveprices
[22,61,81]. In[2,72],regretminimizationisusedasapredictionmodelforbidderbehavior.
Importantly,[67,72]provideempiricalevidencefromlargeauctiondatasetsshowingthat
bidderbehaviorinpracticeisconsistentwithno-regretlearningoutcomes.
Learningdynamicsinfirst-andsecond-priceauctionsandtheirconvergenceproperties
havebeenstudiedinabroadrangeofwork[12,18,28,29,36,53,54,71]. In[53,54],the
authorsfocusonanalyzingtheaverageoutcomesofregret-minimizationdynamicsand
theirimplicationsonuserincentives. Thesepapersconsiderameta-gamebetweentheusers
oflearningagents,whichisinducedbythelong-termoutcomesoftheagents’dynamics.
Thisisclosetoourmodelofthepaymentgame;however,paymentshaveaverydifferent
impactontheagents’dynamicsandtheyleadtodifferentanalysesandresultsinauctions
andothergames.
Thequestionofhowdistributedandself-interestedplayerscanreachcooperativeorefficient
outcomes is, of course, a very broad topic that has been studied in various (and largely
separate)fields. Theclassicapproachtothisproblemisfrommechanismdesign[66,70]
andimplementationtheory[47,59]. Somewhatclosertoourworkare[7,62,88],whostudy
howanexternalmechanismdesignercanminimizetheexogenouspaymentsheneedsto
maketotheplayersinordertoimplementparticularoutcomesinthegame. Bycontrast,
westudytheimpactofpaymentsthatautomatedagentscouldmakeamongthemselves;
ouranalysisdoesnotconsideramechanism-designproblem11 andtherearenoexternal
payments. Anadditionalstrandofworkfromthereinforcementlearning(RL)andartificial
intelligenceliteraturestudieshowdistributedRLalgorithmscanjointlyreachcooperative
outcomesinsequentialsocialdilemmas[6,33,50,58,87]. Athirdlineofworkconsidersan
approachforreachingcooperativeoutcomescalledprogramequilibrium[57,73,74,85],in
whicheachplayerdeclaresaprogramandeachprogramcanreadthecommitmentsmade
in the other programs and condition actions in the game on those commitments. These
models,however,areverydifferentfromourmodel.
Finally, the idea of using payments to incentivize desirable actions is, of course, an old
one, and represents one of the cornerstones of a rich literature on contract design and
principal-agentproblems. Werefertheinterestedreaderto[17,31,56]foranoverviewof
thisfield. Inmostworkinthisarea,thereisa“principal”whoprovidesincentivestothe
agents. Asaresult,hefacesacontract-designoranoptimizationproblem,ratherthanacting
asaplayerinthegame. Notableworkthatisclosertoourscenarioincludes[48],whostudy
multi-lateralpaymentcontractsinone-shotinteractions, [42,89], whostudylearningin
repeatedcontracts,and[75],whostudyscenarioswhereaplayerextractsfeesfromother
players by using binding contracts. Our setting, however, differs significantly from the
contractssetting,andourfocusisonwhenplayershaveincentivestoaugmentlearning
agents with the ability to make payments, how payments among the agents affect their
learningdynamics,andwhattheimplicationsforthegameoutcomesare.
11Designingpaymentprotocolstofacilitateparticulartypesofpaymentsbetweentheplayersto
optimizesocialwelfareisaninterestingresearchavenue,butwedonotpursueithere.
10B Prisoner’sDilemmaGames
Webeginbyreviewingaknownresult(see,e.g.,[49])thatisusefulforouranalysis.
Proposition 1. In a dominance-solvable game, the empirical distribution of play of all types of
regret-minimizationdynamicsconvergewithhighprobabilitytotheuniqueNashequilibrium.
Proof. Therearevariouswaystoshowthis.Considerthefollowinginductionargument.The
gamehasatleastoneorderofiteratedeliminationofstrictlydominatedstrategies. Index
theplayersaccordingtoonesuchorder,suchthatplayer1hasadominantstrategy,player2
hasadominantstrategyinthesub-gamewhereplayer1playshisdominantstrategy,and
soon. Additionally,indexthecorrespondingdominantstrategiesoftheplayersusingthe
sameorder,sothata isthefirstactionthatistaken, a isthesecond,andsoon. Clearly,
1 2
inanyCCE,player1playshisdominantstrategya ;otherwisehehaspositiveregret. Our
1
inductionstepissimple: FixanyCCE.Giventhatplayers1,...,k−1playactionsa 1,...,a k−1,
player k has a strict best response to play a . By induction, this is true up to the last
k
playern,sowehavethatourarbitraryCCEisthepureNashequilibriumprofile(a ,...,a ).
1 n
Therefore,regret-minimizationdynamicsconvergetoitwithhighprobability.
EquilibriaofthegamefromFigure1: Toapproachtheoutcomedescribedintheintro-
duction as an equilibrium, we need to adjust the payment policy of player 1 as follows.
Player1’sagentpaysplayer2’sagentthemaximumpaymentwheneverplayer1’sagent
cooperates, and pays 1/3+ϵ when the outcome (D,C) is obtained. Effectively, player 1
blocksplayer2fromincentivizingplayer1’sagenttocooperate,soplayer2’sbestresponse
isnottopayanythingandget1/3+ϵ. Thisisanϵ-equilibriumforallϵ > 0,sinceplayer
1incentivizesoutcome(D,C)inthelimit T → ∞,andhecannotimprovehislong-term
payoffbymorethanϵ. Theotherequilibrium,asmentioned,isthemirrorimageofthesame
equilibrium(replacingthepaymentpoliciesofplayers1and2).
Player2 Player2
C D C D
C y,y 0,x C y ,y 0,x
1 2 2
Player1 Player1
D x,0 1,1 D x ,0 1,1
1
(a)Thesymmetricgame: x>y>1. (b)Theasymmetricgame: x >y >1.
i i
PoSandPoA: ConsiderthesymmetricgameinFigure3a,whereintheprisoner’sdilemma
wehavex > y >1. Theequilibriaofthegamedependofthewelfaregapbetweenthegame
outcomes. Therearetwocases. Ifx ≤2,thenthepriceofanarchyistriviallyboundedby
2, as this is the maximum utility gap in the game. If x > 2, the payment game has two
equilibriainwhichoneagentpaysthemaximumamountwhencooperatingandpays1+ϵ
whentheotheragentcooperates,andtheotheragentdoesnotmakeanypayments. Eachof
theseequilibriayieldsawelfareofx. Sincex > y,wehave2y/x <2,sothepriceofanarchy
isatmost2.
Intheasymmetricgame,weassumewithoutlossofgeneralitythatx ≥ x . Wehavethree
1 2
casestoanalyze. Ifx ,x ≤2,thentheplayersdonothaveprofitablepaymentpolicies,so,
1 2
asbefore,PoA = PoSandbotharetriviallyboundedby2. Ifx >2andx ≤2,thenonly
1 2
player1hasaprofitablepaymentpolicyandthepaymentgamehasasingleequilibrium
withtheoutcome(D,C),whichyieldsawelfareofx Sincex > y ,y ,wehave
y1+y2
<2,
1 1 1 2 x1
PoA = PoS,andbothboundedby2. Finally,if x ,x > 2,asinthesymmetricgame,we
1 2
havetwoequilibriaforthepaymentgamewithoutcomes(D,C)or(C,D). ThePoSinthis
caseisatmost2bythesameargumentasinthepreviouscase. However,theratiox /x
1 2
betweenthetwoequilibriacanbeunbounded,sothePoAcanbeunbounded.
11C AdditionalDefinitions
Forcompleteness,weprovidehereseveralstandarddefinitions.
Regret minimization: For a given sequence of action profiles s1,...,sT, the regret of
agentiisthedifferenceinutilityforibetweentheactualutilityinthatsequenceandthe
utilityofthebestfixedactioninhindsight:Regret i(s1,...,sT) =max s∈Si(cid:2)∑ τT =1u i(s,sτ −i)(cid:3) −
∑T u (sτ,sτ ). A no-regret agent minimizes this quantity in the long term. There are
τ=1 i i −i
severalformulationsforthisproperty. Wewillusethefollowingdefinition.
Definition 3. An algorithm satisfies the (external) regret-minimization property if, for a time
horizonparameterT andanyT-sequenceofplayoftheotherplayers(s1 ,...,sT ),wherest and
−i −i i
st denotetheactionstakenattime t bythealgorithmandbytheotherplayers,respectively,we
−i
havethatmax s∈Si(cid:2)∑ τT =1u i(s,sτ −i)(cid:3) −∑ τT =1u i(s iτ,sτ −i) = o(T)withprobability1inthelimitas
T → ∞. Anagentisregret-minimizingifitsatisfiestheregret-minimizationproperty.
Coarse correlated equilibrium: Coarse correlated equilibria are a weaker notion than
correlatedequilibria[5],alsoknownastheHannansetorHannanconsistentdistributions
[43]. Thesimplestdefinitionforourpurposeisthefollowing.
Definition4. Ajointdistributionofplayisacoarsecorrelatedequilibriumif,underthisdistribution,
alltheplayershaveinexpectationregretatmostzero.
Mean-basedlearningalgorithms: Mean-basedlearningalgorithms[19]areafamilyofalgo-
rithmsthatplayactionsthatarebestresponsestothehistoryofplaywithhighprobability.
Thisfamilywasshowntoincludemanystandardno-regretalgorithms,likemultiplicative
weights(see[3]andreferencestherein),followtheperturbedleader[43,51],andEXP3[4].
Definition5. [19]. Letσ
i,t
=∑t t′=1u i,t′,whereu
i,t
istheutilityofactioniattimet. Analgorithm
fortheexpertsproblemorthemulti-armedbanditsproblemisγ(T)-mean-basedifitisthecasethat
wheneverσ <σ −γ(T)T,thentheprobabilitythatthealgorithmpullsarmiinroundtisatmost
i,t j,t
γ(T). Analgorithmismean-basedifitisγ(T)-mean-basedforsomeγ(T) = o(1).
D ProofsforSection3
D.1 Second-priceauctions
Proof. (Theorem1). Considerarepeatedsecondpriceauctionwithasingleitemsoldin
everystep,andnplayerswithvaluesv > v ≥ ··· ≥ v . Assumethatthetotalpayment
1 2 n
thataplayermakesisboundedbysomelargeconstant M >2nv . Considerthefollowing
1
profile of payment policies. Every player j > 1 uses the policy of always paying zero.
Chooseϵwith0 < ϵ < (v −v )/n. Thepaymentpolicyforplayer1isspecifiedbythe
1 2
followingconditions. (1)Wheneverb = v ,makeapayment p toeveryplayerj >1of
1 1 1j
ϵ/(n−1)ifb j =0andzerootherwise. (2)Ifagent1bidsb 1 ̸= v 1,thenhepays p 1j = nM −1 to
everyotherplayerj >1. Notethatthemaximumpaymentaccordingtotheseconditionsis
M,asrequired.
Claim1. Withthesepayments,biddingv isastrictlydominantstrategyforagent1.
1
Proof. Toseethis,fixabidprofilefortheotheragents2,...,n,letb denotethemaximum
0
bid of the other agents, and let p denote the total payment to the other agents due to
condition(1). Wehavethefollowingcases.
Case1b ≤ v : Inthiscase,thebidv givesagent1autilityofv −b −p. Everyother
0 1 1 1 0
bidb ̸= v andb ≥ b givesautilityofv −b −M,whichisstrictlyless. Everylosingbid
1 0 1 0
b < b givesautilityof−M,whichisalsostrictlyless.
0
Case2 b > v (ifagentsoverbid): Hereeverywinningbidforagent1givesautilityof
0 1
v −(b +M),everylosingbidnotequaltov givesautilityof−M,andbiddingexactly
1 0 1
12v giveautilityof−p,whichisstrictlyhigher. Therefore,biddingv isastrictlydominant
1 1
strategy,andagent1whoisminimizingregretwilllearntoonlyusethisstrategy.
Next,weclaimthatsinceagent1bidsonlyv ,everyotheragenthasastrictbestresponse,
1
which is to bid zero. This is clear, since for every agent j > 1, every winning bid gives
negativeutility,everylosingbidb ≤ v andb ̸= 0giveszeroutility,andbiddingexactly
1
zerogivepositiveutility. Thus,withthesepaymentpolicies,duetotheregret-minimization
property,agent1alwaysbidsv andwinstheauction,whiletheotheragentsbidzeroand
1
getapaymentofϵ/(n−1)each. Theutilityforplayer1inthelongtermisv −ϵ,andthe
1
utilityforeveryotherplayerisϵ/(n−1).
Claim2. Thepolicyofalwayspayingzeroisabestresponseforeveryplayerj >1.
Proof. Webeginbylookingatauctionswithn >2. Ineverydeviationbysomeagentj >1,
inordertoensurethatabidb < v isnotdominatedforagent1,agentjmustpayagent1
1
anamountofatleast M−v . Theutilityforplayerjinthiscaseisboundedfromaboveby
1
v −(M−v )+ M <2v − n−2M <2v (cid:0) 1− n(n−2)(cid:1) <0. Thatis,ineverydeviationby
j 1 n−1 1 n−1 1 n−1
agentjinwhichjcanwinandgetapositiveutilityfromtheauction(byincentivizingagent1
tobidbelowv withsomeprobability),thepaymentistoolarge,sotheresultingutilityis
j
negative. Soplayerjprefersnottomakepaymentsandgetautilityofϵ/(n−1).
Thecaseofn =2requiresaslightlydifferentargument. Inthiscase,agent1paysagent2an
amountof Mwheneveragent1bidsb ̸= v . Thefixedbidv givesagent1autilityofat
1 1
leastv −ϵ. Weclaimthatthisimpliesthatagent1almostalwayswinstheauction.
1
Toseethis,noticethatabidforwhichplayer2paysagent1anamountlessthan Misstill
dominatedandthereforenotplayedbyagent1. Supposethatthereisabid b forwhich
agent2paysagent1anamountof M. Whenagent1loseswiththebidb,hegetsautilityof
zero. Whenagent1wins,hehasanexpectedpayoffofv −E[b |b > b ]. Denotebyqthe
1 2 2
probabilitythatbisawinningbidforagent1. Wehavev −ϵ ≤ q(v −E[b |b > b ])≤ qv ,
1 1 2 2 1
sowehaveq ≥1− ϵ .Withoutlossofgenerality,wesetv =1,andsoagent1winsatleast
v1 1
1−ϵfractionofthetime.
Now,consideragent2. Bytheargumentabove,agent2’spayofffromusingbidsthatare
abovezeroisatmostv ·ϵ < ϵ. Therefore,usingsuchbidsgivesagent2positiveregret
2
comparedtobiddingzero(whenhebidszero,hegetsapaymentofϵ). Thus,agent2almost
alwaysbidszero. Itfollowsthatplayer2cannotmakepaymentsthatincreasehisutility,so
thepolicyofalwayspayingzeroisabestresponse.
Wearenowalmostdone. Withthepolicyprofilethatwehave, player1getsautilityof
v −ϵ. Bytakingasufficientlysmallvalueofϵ,player1getsautilitypertimestepthatis
1
arbitrarilyclosetov . Sincev istheoptimalwelfareinthegameandplayer1getsϵclose
1 1
toitforallϵ >0,thisisanapproximatebestresponseforplayer1,andwehaveanϵ-Nash
equilibrium. The auctioneer’s revenue in this equilibrium is zero, other than vanishing
profitsduringtheinitiallearningphaseoftheagents.
D.2 First-priceauctions
Proof. (Lemma1). Westartbyassumingthatinthegamebetweentheseagents,parameter-
izedbyη,thereisamixedNashequilibriumwithcontinuousCDFs,PDFswithfullsupport
on[0,v −η],andplayer2hasapositiveprobabilityofbiddingzero.
2
Consider player 1’s utility. In equilibrium, he is indifferent between bidding zero and
biddingv −η,givingusthesizeofthepointmassforplayer2atzero:
2
v −η
v −(v −η)−G (0)η = G (0)(v −η) ⇒ G (0) =1− 2 .
1 2 2 2 1 2
v
1
Player 1’s utility when bidding x is u (x,y) = G (x)(v −x)−χ(y)η, where χ(y) is an
1 2 1
indicator which equals 1 if player 2 bids zero (i.e., if y = 0) and equals zero otherwise.
13Importantly,itisindependentofx.Player1isindifferentbetweenallhisbids,so
∂u1(x,y)
=0,
∂x
whichgives
G′(x)(v −x)−G (x) =0.
2 1 2
WehaveanordinarydifferentialequationwithauniquesolutionoftheformG(x) = c .
v1−x
Givenourinitialassumption,wemusthavecontinuityatzero,sowegetthat
c = v G (0) = v −v +η.
2 2 1 2
Checking the consistency of the support (the CDF must be equal to 1 at the top of the
support):
v −v +η
G (v −η) = 1 2 =1.
2 2 v −(v −η)
1 2
Sinceplayer2isindifferentbetweenbiddingx >0andbiddingzeroandgettingautilityof
η,wehave
η
η = F (x)(v −x) ⇒ F (x) = .
1 2 1 v −x
2
Thus,wehaveamixedNashequilibriumwithCDFsF (x) = η , G (x) = v1−v2+η ,as
1 v2−x 2 v1−x
statedinthelemma.
Proof. (Lemma2). Westartbycomputingtheexpectedpayoffofplayer1,whichisgivenby
E[u ] =
(cid:90) v2−η(cid:16)
G (x)(v −x)−ηG
(0)(cid:17)
f(x)dx,
1 2 1 2
0
wherethePDFis f(x) = η . Fromthedistributionswecalculated,wegetthat
(v2−x)2
(cid:16)v −η(cid:17)
E[u ] = v −v +η 2 .
1 1 2
v
1
Astraightforwardcalculationbydifferentiatingthisexpressionwithrespecttoηshowsthat
theexpectationismaximizedwhenη = v /2,inwhichcaseitsvalueisv −v +v2/4v ,as
2 1 2 2 1
claimed. Withthischoiceofη,player2’sutilityisv /2.
1
Thefrequencyatwhichthelowagent(agent2)winsisgivenby:
(cid:32) (cid:33)
Pr[b > b ] =
(cid:90) v2−η
F(x)g(x)dx =
v 2(2v 1−v 2) ln(cid:16)2v 1−v 2(cid:17)
−
v 2(v 1−v 2)
.
2 1 0 4(v 1−v 2)2 v 1 v 1(2v 1−v 2)
Ifv issmallcomparedtov (inthelimitv /v →0),agent2neverwins. Ifv isclosetov
2 1 2 1 2 1
(inthelimitv /v →1),agent2willwin3/8ofthetime.
2 1
Proof. (Lemma3)WebeginbyshowingthattheNashequilibriumcumulativedistributions
boundthemarginaldistributionsinourdynamicsfrombelow(i.e.,thelatterstochastically
dominatetheNashequilibrium).
Claim3. Thesupportof F and G isatmostv −η,andforallbinthesupport,wehavethat
1 2 2
F (b) ≥ FNE,andG (b) ≥ GNE(b).
1 1 2 2
Proof. Foragent2,allbidsabovev −ηarestrictlydominatedbybiddingzero,andsoare
2
notinthesupport. Foragent1,giventhesupportofagent2,bidsabovev −ηgivestrictly
2
lessutilitythanbiddingv −η,soaregret-minimizingagentwillnotplaythem.
2
For mean-based agents, we have that for all b in the support, u (b) = F (b)(v −b) ≥
2 1 2
u (0) = η and u (b) = G (b)(v −b)−ηG (0) ≥ v −v +η−ηG (0). Hencewehave
2 1 2 1 2 1 2 2
F (b) ≥ η = FNE,andG (b) ≥ v1−v2+η = GNE(b).
1 v2−b 1 2 v1−b 2
14ContinuingtheproofofLemma3,supposebywayofcontradictionthatF (b′) > FNE(b′)for
1 1
someb′ < v −η. F (b′) > FNE(b′)impliesu (b′) = F (b′)(v −b′) > FNE(b′)(v −b′) =
2 1 1 2 1 2 1 2
η = u (0). Therefore,biddingzeroisnotinthesupportofplayer2.
2
However, ifplayer2neverbidszero, thentherearenopaymentsinourCCE.Sincethe
agentsminimizeregret,itmustbeaCCEofthestandardfirst-priceauction.
Inthestandardfirst-priceauction,withoutpayments,mean-basedagentscanconvergeonly
toCCEsthatincludebidsabovev −ηintheirsupport(see[53]),acontradiction. Therefore,
2
wehaveF = FNE.
1 1
Next,supposebywayofcontradictionthatG (b′) > GNE(b′)forsomeb′ < v −η. This
2 2 2
impliesthat u (b′) = G (b′)(v −b′)−ηG (0) > GNE(b′)(v −b′)−ηG (0) = v −v +
1 2 1 2 2 1 2 1 2
η−ηG (0) = u (v −η). Thatis,biddingb′ givesplayer1ahigherutilitythanbidding
2 1 2
v −η, so the latter is not in the support of player 1, which is a contradiction, since the
2
marginaldistributionofplayer1isF ,whichissupportedon[0,v −η]. Thus,overall,we
1 2
haveF = FNE andG = GNE.
1 1 2 2
Proof. (Theorem2.) Wewillusethefactthatthegameanalyzedinourproofisinduced
byaunilateralpaymentpolicybythehigh-valueplayer. Inanyequilibrium,player1can
considerthedeviationinwhichherejects(paysback)allthepaymentshereceivedand
makesthisunilateralpayment,leadingtoautilityofv −v +v2/4v . Therefore,inany
1 2 2 1
equilibrium, player 1 gets at least this utility, which is higher than the utility of v −v
1 2
that he gets in the game without payments. As for the utility of the low-value player,
sincethehigh-valueplayer’sutilityisabovethesecondprice,player1mustusepositive
payments,otherwisethedynamicsofmean-basedagentscouldapproachonlythesecond-
priceoutcome(asshownin[53]). Therefore,intheequilibriumofthepayment-policygame,
thelow-valueplayerhaspositiveutility,animprovementoverthegamewithoutpayments.
Thefactthattherevenuedecreasesinanyequilibriumisnowstraightforward. Toseethis
explicitly, suppose by way of contradiction that the revenue R is at least the revenue v
2
of the game without payments. The total welfare (of the players and the auctioneer) is
(cid:16) (cid:17)
w = u +R+u ≤ v . Wethengetv +η
v1−η
+u ≤ v ,whichisacontradiction,since
1 2 1 1 v1 2 1
player2cannotgetnegativeutilityinequilibrium.
By Lemma 2 and Lemma 3, player 1 has a utility-improving deviation from the zero-
paymentsprofileforanymean-basedregret-minimizingagentsfortheplayers,sothegame
isnotstableforsuchagents;also,bothplayersimprovetheirutilities,andtherevenuefor
theauctioneerdecreases,asclaimed.
D.2.1 ExtensionofLemma3tonplayers.
To extend the lemmas in the proof of Theorem 2 to the case of n players, consider the
followinganalysis. Supposewehavenplayerswithvaluesv > v > v > ··· > v ,each
1 2 3 n
usingaregret-minimizingagent. Ifagent2bidsv ,agent1payshimη >0.
3
AsintheproofofLemma1,webeginbyassumingthatinthegamebetweentheseagents,
parameterizedbyη,thereisamixedNashequilibriumwithcontinuousCDFs,PDFswith
fullsupporton[v ,v −η],andplayer2hasapositiveprobabilityofbiddingv .
3 2 3
Westartbylookingatplayer1’sutility. Inequilibrium,heisindifferentbetweenbiddingv
3
andbiddingv −η,givingusthe(point-mass)probabilitythatplayer2bidsv :
2 3
v −v +η
v −(v −η)−G (v )η = G (v )(v −v −η) ⇒ G (v ) = 1 2 .
1 2 2 3 2 3 1 3 2 3 v −v
1 3
Player 1’s utility when bidding x is u (x,y) = G (x)(v −x)−χ(y)η, where χ(y) is an
1 2 1
indicatorwhichequals1ifplayer2bidszeroandequalszerootherwise. Asbefore,note
thatitisindependentofx. Player1isindifferentbetweenallhisbids,so
∂u1(x,y)
=0,which
∂x
gives
G′(x)(v −x)−G (x) =0.
2 1 2
15Wehaveanordinarydifferentialequationwithauniquesolutionoftheform
c
G(x) = .
v −x
1
Fromcontinuityabovev ,wegetthatc = v G (0) = v −v +η.Checkingtheconsistency
3 2 2 1 2
ofthesupport(theCDFmustbeequalto1atthetopofthesupport):
v −v +η
G (v −η) = 1 2 =1.
2 2 v −(v −η)
1 2
Sinceplayer2isindifferentbetweenbiddingx > v andbiddingv andgettingautilityof
3 3
η,wehave
η
η = F (x)(v −x) ⇒ F (x) = .
1 2 1 v −x
2
SowehavetheCDFs
η v −v +η
F (x) = , G (x) = 1 2 .
1 v −x 2 v −x
2 1
For players i > 2, since there is a positive probability that both players 1 and 2 bid v
3
atthesametime, anybidabove v winstheauctionwithpositiveprobabilityandgives
3
negative expected utility, whereas any bid b ≤ v gives a utility of zero. Therefore, any
3
bid distribution for players i > 2 that has zero weight on bids above v forms a Nash
3
equilibrium,togetherwiththedistributionsF ,G forthefirsttwoplayers.
1 2
Theexpectedpayoffofplayer1isgivenby
E[u ] =
(cid:90) v2−η(cid:16)
G (x)(v −x)−ηG
(0)(cid:17)
f(x)dx,
1 2 1 2
0
wherethePDFis f(x) = η . Thus,wehave
(v2−x)2
E[u ] = (cid:90) v2−η(cid:16) v −v +η−η(cid:0) 1− v 2−η(cid:1)(cid:17) f(x)dx = v −v +η(cid:16)v 2−η(cid:17) .
1 1 2 1 2
0 v 1 v 1
Soweseethatinthisequilibrium,player1managestoincreasehispayoffwithaunilateral
payment. The optimal payment is η∗ = min(v /2,v −v ). The payoff for player 2 is
2 2 3
η. Given the analysis above of Lemmas 1 and 2 with n agents, the extension of Lemma
3holdswithoutanychangetotheproof,noticingthefactthatsincetheminimumofthe
supportisv ,anyplayerj >2neverwinstheauction,sotheseagentscanhavearbitrary
3
distributionswithsupportatmost v withmean-baseddynamics. Sincethisisautility-
3
improvingdeviationforplayer1fromthezero-utilitypaymentprofile,theauctionisnot
stablewithnplayers.
E ProofsforSection4
Proof. (Lemma 4). We start constructing a payment policy for the agent of player i by
lookingattheoptimalk-implementationpaymentsforinducingyasadominantstrategy
equilibrium;wewillthenadjustthispaymentprofiletofitoursettinginwhichthereareno
externalpaymentsandtominimizeplayeri’scost. Akeypointisthatthepaymentamount
k(y)includespaymentstoagentithatanexternaldesignerwouldhavemadeforinducing
y asthedominantstrategyforagenti. Thesepaymentsarenotfeasibleandnotneededin
i
ourcase. Instead,wechangethepaymentpolicyofagentiinthefollowingway: forany
actions
i
̸= y i,agentimakesapaymentofmax s∈Su i(s)+1,anddistributesthispayment
equallytotheotheragents. Thesepaymentsmakealltheotheractionsofagentistrictly
dominatedbytheactiony.
i
Thus, to calculate the cost for player i, we need to subtract from the k-implementation
paymentsthepartsthatarepaidtoplayeri,R (y,y),andtoaddalearning-phaseerrorterm
i
c˜thatresultsfromtheadditionalpaymentsthatagentimakeswhenplayingitsdominated
strategies,aswellasfromothertimesduringthelearningdynamicswheretheotheragents
playtheirdominatedstrategies.
16Claim. Theexpectedlearning-phasecost-per-time-stepc˜vanishesinthelongterm,thatis,c˜= o(1).
Proof. c˜istheexpectedtotalpaymentpertimestepthatplayerimakeswhenagentsplay
strictlydominatedstrategies. Assumebywayofcontradictionthatlim T→∞c˜>0,orthat
thelimitdoesnotexist. Bothassumptionsimplythatthefrequencyatwhichdominated
strategiesareplayedintheagents’dynamicisnotvanishing,whichcontradictstheregret-
minimizationpropertyoftheagents.
Itfollowsthatcost (y) = k(y)−R (y,y)+o(1)asT → ∞,asstatedinthelemma.
i i
Proof. (Lemma5). Weneedtospecifytherequirementthatplayeriwillincreasehisown
utility after making the payments that induce y as the unique unique outcome of the
dynamics. Thatis,cost (y) < u (y)−u (x). ByLemma4wehavethatforlargeenoughT,
i i i
playeriprefersmakingsuchpaymentsifu (y)−k(y)+R (y,y) > u (x). Rewritingtheleft
i i i
termswehave
uBR(y)−k(y) > u (x) = w(x)−∑ u (x).
i i j
j̸=i
Using the fact that, by definition [62], k(y) =
(cid:0)∑ uBR(y)(cid:1)
−w(y), we can rewrite the
j j
left-handsideasw(y)−∑ uBR(y).Rearrangingtheterms,wehave
j̸=i j
w(y)−w(x) >
∑ uBR(y)−∑
u (x) =
∑
R (x,y).
j j j
j̸=i j̸=i j̸=i
Proof. (Theorem3). Ifthedynamicsoftheplayers’regret-minimizingagentsconvergeto
theoptimal-welfareoutcome,lim T→∞x = y∗,thenthereisnoroomforimprovementand
thetheoremholdstrivially(althoughweakly)withpaymentsofzero. Inthefollowing,we
assumeforsimplicitythatw(x)isboundedaway12 fromw(y∗),thatis,thereexistsϵ > 0
andT suchthatforallT > T ,wehavethatw(x) < w(y∗)(1−ϵ).
0 0
Suppose that y∗ is a Nash equilibrium. By the definition of Nash equilibrium, if some
profilesisaNashequilibrium,thenR (s,s) =0foralli. Thus,byLemma4,anyplayercan
i
constructapaymentpolicythatinducesy∗ astheuniqueoutcomeoftheagents’dynamic
withacost-per-time-stepofo(1).
Therefore, tohaveaplayer i whoincreaseshispayoffbyinducing y∗ astheoutcomeof
thedynamics,weonlyneedtohavethatu (y∗) > u (x). Assumebywayofcontradiction
i i
thatforalli,u (x) ≥ u (y∗). Summingovertheplayers,wehave∑ u (x) ≥ ∑ u (y∗);that
i i i i i i
is, w(x) ≥ w(y∗),acontradictiontotheoptimalityof y∗. Thus, wehavethatfor T large
enoughthatthelearning-phasecostsaresmall,thereexistsaplayeriwhocanincreasehis
payoffbyinducingtheoptimal-welfareoutcomeastheoutcomeoftheagents’dynamics.
Ify∗ isanon-equilibriumoutcome,theconditionsandproofaregivenbyLemma5with
y = y∗. Noticealsothatsinceunderthispaymentpolicyy∗ dominatesxforalltheagents,
theutilityforalltheplayersishigherthaninthegamewithoutpayments.
Proof. (Theorem4). Theresultfollowsfromcombining(theproofof)Lemma5withgeneral
propertiesofregret-minimizationdynamics. LetΓbeagameinwhichtheNashequilibrium
withthehighestwelfare,denotedy˜,yieldsawelfareofw˜ (wherew˜ isnotnecessarilyequal
totheoptimalwelfareOPT),andthereexistsaCCExwithwelfarew(x) < w˜.
ItisknownthatforanyCCEofagame,thereareregret-minimizingagentsthatconverge
tothatequilibrium[54,63]. Inparticular,thereareagentsthatconvergearbitrarilyclose
to x.13 ByLemma5(inparticular,Corollary1),thereexistsaplayerwhoprefersusinga
12Thereisalsothescenariowherex=y∗forsomevaluesofTbutnotinthelimit.Forsuchvalues
ofTthetheoremholdstriviallyaswell,andsotheassumptioniswithoutlossofgenerality.
13Technically,theproofsofthisconvergenceresultusecyclesofpureactionstoapproximatethe
timeaverageofjointdistributions,andthearbitraryapproximationisduetothedensityoftherational
numbers.Wedisregardthisdetailinouranalysis.
17paymentpolicythatassuresconvergencetothehighestwelfareequilibriumy˜comparedto
notmakingpaymentsandreachingoutcomex. Thus,wehaveautility-improvingdeviation
overtheno-paymentsactionprofileandhencethegameisnotstable.
F ProofsforSection5
Proof. (Theorem 5). The intuition for the proof in the two-player case is that to have a
positive payment in equilibrium, some player must benefit from making the payment,
whiletheotherbenefitsfromreceivingthepayment. Withmorethantwoplayers,there
mightbepaymentsthataremutuallybeneficialtosomesubsetofplayersbuthavenegative
externalitiesforothers. Inparticular,withmorethantwoplayers,theremightbeplayers
whocannotprofitablycounteractpaymentsmadeamongothersthatdonotbenefitthem.
Formally,consideragameΓ,aset Aofregret-minimizinglearningagentsfortheplayers,
andatimehorizonT. Suppose,forthesakeofcontradiction,thatthereexistsanequilibrium
p∗ ofthepayment-policygameassociatedwithΓ,A,T whereplayerihasalowerutility
thantheirexpectedutilityovertheTroundsinthegamewithoutpayments. Lethdenote
theutilityforplayeriinthegamewithoutpayments,andletldenotetheutilityforplayeri
intheequilibrium p∗. Byourassumption,wehaveh > l. Considerthefollowingdeviation
fromthepaymentpolicy p∗: playerimatcheshispaymentstozerooutallpaymentsmade
bytheotherplayerand,additionally,reducesallofhisotherpaymentstozero. Asaresult,
thetwoagentsnowobserveintheirdynamicstheutilitiesoftheoriginalgameΓwithout
payments. Therefore,playerihasautilityofh. Sinceplayerihasincreasedhisutilityfroml
toh,wehaveacontradictionto p∗ beinganequilibrium. Hence,theutilitiesofbothplayers
canonlyincreaserelativetothegamewithoutpayments.
Proof. (Theorem6). Thisresultisrelatedtoatheoremin[54]thatdealswithgameswith
dominantstrategiesinameta-gameinwhichusersmisreporttheirutilityparameterstotheir
learningagents. Inourcontextofpaymentsbetweentheagents,theresultismoregeneral,
applying to a larger family of games, including all dominance-solvable games, generic
fully-mixedgames,andsocially-concavegames[34](asub-classofconcavegamesinwhich
regret-minimizationdynamicsconvergetoNashequilibria)withauniqueequilibrium.
Considerasourstartingpointtheactionprofilewheretheplayersusezeropayments. In
thegamewithoutpayments,anyregret-minimizationdynamicwillconvergetotheunique
coarsecorrelatedequilibrium(whichisalsotheuniqueNashequilibrium). Toshowthatthe
gameisnotstableforanysetofregret-minimizingagentsfortheplayers,weneedtofinda
utility-improvingdeviationfromthezero-paymentprofileforoneofthetwoplayers.
Wewillusethefactthatwhentheopponentdoesnotmakeanypayments,aplayerhasthe
abilitytoalterhispolicysoastocommittoplayingapureactioninthelongterm;thiscan
beobtainedbymakinglargepaymentswhenevertheagentofthisplayerplaysdifferent
actions,inducingadominantstrategyfortheagent.Sinceforatleastoneoftheplayersthere
isaStackelberg-equilibriumoutcomethatisdifferentfromthe(unique)Nash-equilibrium
outcome,thereexistsaplayerwhoobtainsahigherpayoffasaStackelbergleaderinthe
game, so this player prefers making such a commitment. Since the other agent is also
minimizingregret,thisagentwilleventuallylearntobestreplytothefixedactionofthe
firstplayer’sagent,andthedynamicswiththesepaymentswillconvergetotheStackelberg
outcomeofthegame. Thus,wehaveautility-improvingdeviationfromthezero-payment
policy,sothegameisnotstable. NotethatthisisadifferentresultfromthatofTheorem4,
sincetheStackelbergoutcomehereisnotacoarsecorrelatedequilibriumofthegameΓ.
Acknowledgments
We thank Noam Nisan for his valuable feedback. Éva Tardos was supported in part by
AFOSR grant FA9550-23-1-0410, AFOSR grant FA9550-231-0068. Joe Halpern was sup-
ported in part by AFOSR grant FA23862114029, MURI grant W911NF-19-1-0217, ARO
grantW911NF-22-1-0061,NSFgrantFMitF-2319186,andagrantfromtheCooperativeAI
Foundation.
18References
[1] Aggarwal,G.,Fikioris,G.,andZhao,M.(2024). No-regretalgorithmsinnon-truthful
auctionswithbudgetandroiconstraints. arXivpreprintarXiv:2404.09832.
[2] Alaei,S.,Badanidiyuru,A.,Mahdian,M.,andYazdanbod,S.(2019).Responseprediction
forlow-regretagents. InInternationalConferenceonWebandInternetEconomics, pages
31–44.Springer.
[3] Arora,S.,Hazan,E.,andKale,S.(2012). Themultiplicativeweightsupdatemethod: A
meta-algorithmandapplications. TheoryofComputing,8(1):121–164.
[4] Auer, P., Cesa-Bianchi, N., Freund, Y., and Schapire, R. E. (2002). The nonstochastic
multiarmedbanditproblem. SIAMJournalonComputing,SICOMP,32(1):48–77.
[5] Aumann,R.J.(1974). Subjectivityandcorrelationinrandomizedstrategies. Journalof
mathematicalEconomics,1(1):67–96.
[6] Austerweil, J. L., Brawner, S., Greenwald, A., Hilliard, E., Ho, M., Littman, M. L.,
MacGlashan,J.,andTrimbach,C.(2016). Howother-regardingpreferencescanpromote
cooperation in non-zero-sum grid games. In Proceedings of the AAAI Symposium on
ChallengesandOpportunitiesinMultiagentLearningfortheRealWorld.
[7] Babaioff,M.,Kolumbus,Y.,andWinter,E.(2022). Optimalcollateralsinmulti-enterprise
investmentnetworks. InProceedingsoftheACMWebConference2022,pages79–89.
[8] Bahrani, M., Garimidi, P., and Roughgarden, T. (2023). Transaction fee mechanism
designwithactiveblockproducers. arXivpreprintarXiv:2307.01686.
[9] Bahrani, M., Garimidi, P., and Roughgarden, T. (2024). Transaction fee mechanism
designinapost-mevworld. CryptologyePrintArchive.
[10] Balcan,M.-F.,Blum,A.,andMansour,Y.(2009). Improvedequilibriaviapublicservice
advertising. In Proceedings of the twentieth annual ACM-SIAM symposium on Discrete
algorithms,pages728–737.SIAM.
[11] Balseiro,S.R.andGur,Y.(2019). Learninginrepeatedauctionswithbudgets: Regret
minimizationandequilibrium. ManagementScience,65(9).
[12] Bichler,M.,Lunowa,S.B.,Oberlechner,M.,Pieroth,F.R.,andWohlmuth,B.(2023).
Ontheconvergenceoflearningalgorithmsinbayesianauctiongames. arXivpreprint
arXiv:2311.15398.
[13] Blackwell,D.(1956). Ananalogoftheminimaxtheoremforvectorpayoffs.
[14] Blum,A.,Hajiaghayi,M.,Ligett,K.,andRoth,A.(2008). Regretminimizationandthe
priceoftotalanarchy. InProceedingsofthefortiethannualACMsymposiumonTheoryof
computing,pages373–382.
[15] Blum,A.andMansour,Y.(2007). Fromexternaltointernalregret. JournalofMachine
LearningResearch,8(6).
[16] Blum,A.andMonsour,Y.(2007). Learning,regretminimization,andequilibria.
[17] Bolton,P.andDewatripont,M.(2004). Contracttheory. MITpress.
[18] Borgs, C., Chayes, J., Immorlica, N., Jain, K., Etesami, O., and Mahdian, M. (2007).
Dynamicsofbidoptimizationinonlineadvertisementauctions. InProceedingsofthe16th
internationalconferenceonWorldWideWeb,pages531–540.
[19] Braverman,M.,Mao,J.,Schneider,J.,andWeinberg,M.(2018). Sellingtoano-regret
buyer. InProceedingsofthe2018ACMConferenceonEconomicsandComputation,pages
523–538.
[20] Brown,G.W.(1951). Iterativesolutionofgamesbyfictitiousplay. Activityanalysisof
productionandallocation,13(1):374–376.
19[21] Caragiannis,I.,Kaklamanis,C.,Kanellopoulos,P.,Kyropoulou,M.,Lucier,B.,Leme,
R.P.,andTardos,E.(2015). Boundingtheinefficiencyofoutcomesingeneralizedsecond
priceauctions. JournalofEconomicTheory,156:343–388.
[22] Cesa-Bianchi,N.,Gentile,C.,andMansour,Y.(2014). Regretminimizationforreserve
pricesinsecond-priceauctions. IEEETransactionsonInformationTheory,61(1):549–564.
[23] Cesa-Bianchi, N. and Lugosi, G. (2006). Prediction, learning, and games. Cambridge
universitypress.
[24] Chung,H.,Roughgarden,T.,andShi,E.(2024). Collusion-resilienceintransactionfee
mechanismdesign. arXivpreprintarXiv:2402.09321.
[25] Daian,P.,Goldfeder,S.,Kell,T.,Li,Y.,Zhao,X.,Bentov,I.,Breidenbach,L.,andJuels,
A.(2020). Flashboys2.0: Frontrunningindecentralizedexchanges,minerextractable
value, and consensus instability. In 2020 IEEE symposium on security and privacy (SP),
pages910–927.IEEE.
[26] Daskalakis,C.,Fishelson,M.,andGolowich,N.(2021).Near-optimalno-regretlearning
ingeneralgames. AdvancesinNeuralInformationProcessingSystems,34.
[27] Daskalakis,C.andPanageas,I.(2018). Last-iterateconvergence: Zero-sumgamesand
constrainedmin-maxoptimization. In10thInnovationsinTheoreticalComputerScience
Conference(ITCS2019).SchlossDagstuhl-Leibniz-ZentrumfuerInformatik.
[28] Daskalakis,C.andSyrgkanis,V.(2016). Learninginauctions: Regretishard,envyis
easy. In2016ieee57thannualsymposiumonfoundationsofcomputerscience(focs), pages
219–228.IEEE.
[29] Deng, X., Hu, X., Lin, T., and Zheng, W. (2022). Nash convergence of mean-based
learningalgorithmsinfirstpriceauctions. InProceedingsoftheACMWebConference2022,
pages141–150.
[30] Deng, Y., Mao, J., Mirrokni, V., andZuo, S.(2021). Towardsefficientauctionsinan
auto-biddingworld. InProceedingsoftheWebConference2021.
[31] Duetting,P.andTalgam-Cohen,I.(2019). Contracttheory: Anewfrontierforalgorith-
micgametheory. ACMEC2019tutorial.
[32] Dworczak,P.(2020). Mechanismdesignwithaftermarkets: Cutoffmechanisms. Econo-
metrica,88(6):2629–2661.
[33] Eccles,T.,Hughes,E.,Kramár,J.,Wheelwright,S.,andLeibo,J.Z.(2019). Learning
reciprocityincomplexsequentialsocialdilemmas. arXivpreprintarXiv:1903.08082.
[34] Even-Dar,E.,Mansour,Y.,andNadav,U.(2009). Ontheconvergenceofregretmini-
mizationdynamicsinconcavegames. InACMSymposiumonTheoryofComputing,STOC,
pages523–532.
[35] Feldman, M., Lucier, B., and Nisan, N. (2016). Correlated and coarse equilibria of
single-item auctions. In International Conference on Web and Internet Economics, WINE,
pages131–144.
[36] Feng,Z.,Guruganesh,G.,Liaw,C.,Mehta,A.,andSethi,A.(2020). Convergenceanaly-
sisofno-regretbiddingalgorithmsinrepeatedauctions. arXivpreprintarXiv:2009.06136.
[37] Fikioris,G.andTardos,É.(2023). Liquidwelfareguaranteesforno-regretlearningin
sequentialbudgetedauctions. InProceedingsofthe24thACMConferenceonEconomicsand
Computation,pages678–698.
[38] Foster,D.J.,Li,Z.,Lykouris,T.,Sridharan,K.,andTardos,E.(2016). Learningingames:
Robustnessoffastconvergence. AdvancesinNeuralInformationProcessingSystems,29.
[39] Foster,D.P.andVohra,R.V.(1997). Calibratedlearningandcorrelatedequilibrium.
GamesandEconomicBehavior,21(1-2):40–55.
20[40] Fudenberg,D.andLevine,D.K.(1995).Consistencyandcautiousfictitiousplay.Journal
ofEconomicDynamicsandControl,19(5-7):1065–1089.
[41] Gentry, M. L., Hubbard, T. P., Nekipelov, D., Paarsch, H. J., et al. (2018). Structural
econometricsofauctions: Areview. nowpublishers.
[42] Guruganesh,G.,Kolumbus,Y.,Schneider,J.,Talgam-Cohen,I.,Vlatakis-Gkaragkounis,
E.-V.,Wang,J.R.,andWeinberg,S.M.(2024). Contractingwithalearningagent. arXiv
preprintarXiv:2401.16198.
[43] Hannan,J.(1957). ApproximationtoBayesriskinrepeatedplay. InContributionstothe
TheoryofGames(AM-39),VolumeIII,pages97–139.PrincetonUniversityPress.
[44] Hart,S.andMas-Colell,A.(2000). Asimpleadaptiveprocedureleadingtocorrelated
equilibrium. Econometrica,68(5):1127–1150.
[45] Hart, S. and Mas-Colell, A. (2013). Simple adaptive strategies: from regret-matching to
uncoupleddynamics,volume4. WorldScientific.
[46] Hartline,J.,Syrgkanis,V.,andTardos,E.(2015). No-regretlearninginbayesiangames.
AdvancesinNeuralInformationProcessingSystems,28.
[47] Jackson,M.O.(2001). Acrashcourseinimplementationtheory. Socialchoiceandwelfare,
18(4):655–708.
[48] Jackson, M. O. and Wilkie, S. (2005). Endogenous games and mechanisms: Side
paymentsamongplayers. TheReviewofEconomicStudies,72(2):543–566.
[49] Jafari, A., Greenwald, A., Gondek, D., and Ercal, G. (2001). On no-regret learning,
fictitiousplay,andnashequilibrium. InICML,volume1,pages226–233.
[50] Jaques,N.,Lazaridou,A.,Hughes,E.,Gulcehre,C.,Ortega,P.,Strouse,D.,Leibo,J.Z.,
andDeFreitas,N.(2019). Socialinfluenceasintrinsicmotivationformulti-agentdeep
reinforcementlearning. InInternationalConferenceonMachineLearning,pages3040–3049.
PMLR.
[51] Kalai, A.andVempala, S.(2005). Efficientalgorithmsforonlinedecisionproblems.
JournalofComputerandSystemSciences,71(3):291–307.
[52] Kolumbus,Y.,Levy,M.,andNisan,N.(2024). Asynchronousproportionalresponse
dynamics: convergence in markets with adversarial scheduling. Advances in Neural
InformationProcessingSystems,36.
[53] Kolumbus,Y.andNisan,N.(2022a). Auctionsbetweenregret-minimizingagents. In
ACMWebConference,WebConf,pages100–111.
[54] Kolumbus,Y.andNisan,N.(2022b). Howandwhytomanipulateyourownagent:
Ontheincentivesofusersoflearningagents. InAnnualConferenceonNeuralInformation
ProcessingSystems,NeurIPS.
[55] Kumar,R.,Schneider,J.,andSivan,B.(2024). Strategically-robustlearningalgorithms
forbiddinginfirst-priceauctions. arXivpreprintarXiv:2402.07363.
[56] Laffont,J.-J.andMaskin,E.(1981). Thetheoryofincentives: Anoverview. Universitédes
sciencessociales,Facultédesscienceséconomiques.
[57] LaVictoire,P.,Fallenstein,B.,Yudkowsky,E.,Barasz,M.,Christiano,P.,andHerreshoff,
M.(2014).Programequilibriumintheprisoner’sdilemmavialöb’stheorem.InWorkshops
atthetwenty-eighthAAAIconferenceonartificialintelligence.
[58] Leibo,J.Z.,Zambaldi,V.,Lanctot,M.,Marecki,J.,andGraepel,T.(2017). Multi-agent
reinforcementlearninginsequentialsocialdilemmas. InProceedingsofthe16thConference
onAutonomousAgentsandMultiAgentSystems,pages464–473.
21[59] Maskin,E.andSjöström,T.(2002). Implementationtheory. HandbookofsocialChoice
andWelfare,1:237–288.
[60] Milionis, J., Papadimitriou, C., Piliouras, G., and Spendlove, K. (2023). An impos-
sibility theorem in game dynamics. Proceedings of the National Academy of Sciences,
120(41):e2305349120.
[61] Mohri,M.andMunoz,A.(2014). Optimalregretminimizationinposted-priceauctions
withstrategicbuyers. InAdvancesinNeuralInformationProcessingSystems,pages1871–
1879.
[62] Monderer,D.andTennenholtz,M.(2003). k-implementation. InProceedingsofthe4th
ACMconferenceonElectronicCommerce,pages19–28.
[63] Monnot,B.andPiliouras,G.(2017). Limitsandlimitationsofno-regretlearningin
games. TheKnowledgeEngineeringReview,32:e21.
[64] Moulin,H.(1992). Anapplicationoftheshapleyvaluetofairdivisionwithmoney.
Econometrica: JournaloftheEconometricSociety,pages1331–1349.
[65] Moulin,H.(2004). Fairdivisionandcollectivewelfare. MITpress.
[66] Myerson,R.B.(1989). Mechanismdesign. Springer.
[67] Nekipelov,D.,Syrgkanis,V.,andTardos,E.(2015). Econometricsforlearningagents.
InProceedingsoftheSixteenthACMConferenceonEconomicsandComputation,pages1–18.
[68] Nisan, N. and Noti, G. (2017a). An experimental evaluation of regret-based econo-
metrics. InProceedingsofthe26thInternationalConferenceonWorldWideWeb,page73–81.
InternationalWorldWideWebConferencesSteeringCommittee.
[69] Nisan,N.andNoti,G.(2017b).A"quantalregret"methodforstructuraleconometricsin
repeatedgames. InProceedingsofthe2017ACMConferenceonEconomicsandComputation.
[70] Nisan,N.andRonen,A.(1999). Algorithmicmechanismdesign. InProceedingsofthe
thirty-firstannualACMsymposiumonTheoryofcomputing,pages129–140.
[71] Nisan,N.,Schapira,M.,Valiant,G.,andZohar,A.(2011). Best-responseauctions. In
Proceedingsofthe12thACMconferenceonElectroniccommerce,pages351–360.
[72] Noti,G.andSyrgkanis,V.(2021). Bidpredictioninrepeatedauctionswithlearning. In
ACMWebConference,WebConf,pages3953–3964.
[73] Oesterheld,C.(2019). Robustprogramequilibrium. TheoryandDecision,86(1):143–159.
[74] Oesterheld,C.andConitzer,V.(2022). Safeparetoimprovementsfordelegatedgame
playing. AutonomousAgentsandMulti-AgentSystems,36(2):1–47.
[75] Ramirez, M. A., Kolumbus, Y., Nagel, R., Wolpert, D., and Jost, J. (2023).
Game manipulators–the strategic implications of binding contracts. arXiv preprint
arXiv:2311.10586.
[76] Robinson,J.(1951).Aniterativemethodofsolvingagame.Annalsofmathematics,pages
296–301.
[77] Roughgarden,T.(2012). Thepriceofanarchyingamesofincompleteinformation. In
Proceedingsofthe13thACMConferenceonElectronicCommerce,pages862–879.
[78] Roughgarden,T.(2015). Intrinsicrobustnessofthepriceofanarchy. JournaloftheACM
(JACM),62(5):1–42.
[79] Roughgarden,T.(2021). Transactionfeemechanismdesign. ACMSIGecomExchanges,
19(1):52–55.
[80] Roughgarden,T.,Syrgkanis,V.,andTardos,E.(2017). Thepriceofanarchyinauctions.
JournalofArtificialIntelligenceResearch,59:59–101.
22[81] Roughgarden, T. and Wang, J. R. (2019). Minimizing regret with multiple reserves.
ACMTransactionsonEconomicsandComputation(TEAC),7(3).
[82] Slivkins,A.etal.(2019). Introductiontomulti-armedbandits. FoundationsandTrends®
inMachineLearning,12(1-2):1–286.
[83] Syrgkanis, V., Agarwal, A., Luo, H., and Schapire, R. E. (2015). Fast convergence
of regularized learning in games. Advances in Neural Information Processing Systems,
28:2989–2997.
[84] Syrgkanis,V.andTardos,E.(2013). Composableandefficientmechanisms. InProceed-
ingsoftheforty-fifthannualACMsymposiumonTheoryofcomputing,pages211–220.
[85] Tennenholtz,M.(2004). Programequilibrium. GamesandEconomicBehavior,49(2):363–
373.
[86] Vickrey,W.(1961). Counterspeculation,auctions,andcompetitivesealedtenders. The
Journaloffinance,16(1):8–37.
[87] Yang,J.,Li,A.,Farajtabar,M.,Sunehag,P.,Hughes,E.,andZha,H.(2020). Learning
toincentivizeotherlearningagents. AdvancesinNeuralInformationProcessingSystems,
33:15208–15219.
[88] Zhang,B.H.,Farina,G.,Anagnostides,I.,Cacciamani,F.,McAleer,S.M.,Haupt,A.A.,
Celli,A.,Gatti,N.,Conitzer,V.,andSandholm,T.(2023). Steeringno-regretlearnersto
optimal equilibria. Working paper available at https://arxiv.org/pdf/2306.05221.
pdf.
[89] Zhu, B., Bates, S., Yang, Z., Wang, Y., Jiao, J., and Jordan, M. I. (2023). The sample
complexityofonlinecontractdesign. InACMConferenceonEconomicsandComputation,
EC,page1188.
[90] Zinkevich, M. (2003). Online convex programming and generalized infinitesimal
gradientascent. InProceedingsofthe20thinternationalconferenceonmachinelearning,pages
928–936.
23