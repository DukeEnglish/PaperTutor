[
    {
        "title": "PITCH: Productivity and Mental Well-being Coaching through Daily Conversational Interaction",
        "authors": "Adnan AbbasSang Won Lee",
        "links": "http://arxiv.org/abs/2406.07485v1",
        "entry_id": "http://arxiv.org/abs/2406.07485v1",
        "pdf_url": "http://arxiv.org/pdf/2406.07485v1",
        "summary": "Efficient task planning is essential for productivity and mental well-being,\nyet individuals often struggle to create realistic plans and reflect upon their\nproductivity. Leveraging the advancement in artificial intelligence (AI),\nconversational agents have emerged as a promising tool for enhancing\nproductivity. Our work focuses on externalizing plans through conversation,\naiming to solidify intentions and foster focused action, thereby positively\nimpacting their productivity and mental well-being. We share our plan of\ndesigning a conversational agent to offer insightful questions and reflective\nprompts for increasing plan adherence by leveraging the social interactivity of\nnatural conversations. Previous studies have shown the effectiveness of such\nagents, but many interventions remain static, leading to decreased user\nengagement over time. To address this limitation, we propose a novel rotation\nand context-aware prompting strategy, providing users with varied interventions\ndaily. Our system, PITCH, utilizes large language models (LLMs) to facilitate\nexternalization and reflection on daily plans. Through this study, we\ninvestigate the impact of externalizing tasks with conversational agents on\nproductivity and mental well-being, and the effectiveness of a rotation\nstrategy in maintaining user engagement.",
        "updated": "2024-06-11 17:26:58 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.07485v1"
    },
    {
        "title": "Politics in Games -- An Overview and Classification",
        "authors": "Lisa GutwengerStephan KellerMartin DolezalBernhard SchnöglSebastian RousKlaus PoierJohanna Pirker",
        "links": "http://arxiv.org/abs/2406.07379v1",
        "entry_id": "http://arxiv.org/abs/2406.07379v1",
        "pdf_url": "http://arxiv.org/pdf/2406.07379v1",
        "summary": "The representation of politics in media influences societal perceptions and\nattitudes. Video games, as a pervasive form of media, contribute significantly\nto this phenomenon. In this work, we explore political themes within video\ngames by analyzing politically-themed games on game distribution platforms\nincluding Steam. We conducted a statistical examination of games with political\ncontext to identify patterns and use this as a basis to introduce a first\ntaxonomy to categorize and better understand the interplay between politics and\nvideo games. This taxonomy offers a first framework for analyzing political\ncontent in games and also sets a foundation for future research in this field.",
        "updated": "2024-06-11 15:46:24 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.07379v1"
    },
    {
        "title": "A qualitative field study on explainable AI for lay users subjected to AI cyberattacks",
        "authors": "Kevin McAreaveyWeiru LiuKim BautersDennis IvoryGeorge LoukasManos PanaousisHsueh-Ju ChenRea GillRachael PaylerAsimina Vasalou",
        "links": "http://arxiv.org/abs/2406.07369v1",
        "entry_id": "http://arxiv.org/abs/2406.07369v1",
        "pdf_url": "http://arxiv.org/pdf/2406.07369v1",
        "summary": "In this paper we present results from a qualitative field study on\nexplainable AI (XAI) for lay users (n = 18) who were subjected to AI\ncyberattacks. The study was based on a custom-built smart heating application\ncalled Squid and was conducted over seven weeks in early 2023. Squid combined a\nsmart radiator valve installed in participant homes with a web application that\nimplemented an AI feature known as setpoint learning, which is commonly\navailable in consumer smart thermostats. Development of Squid followed the XAI\nprinciple of interpretability-by-design where the AI feature was implemented\nusing a simple glass-box machine learning model with the model subsequently\nexposed to users via the web interface (e.g. as interactive visualisations). AI\nattacks on users were simulated by injecting malicious training data and by\nmanipulating data used for model predictions. Research data consisted of\nsemi-structured interviews, researcher field notes, participant diaries, and\napplication logs. In our analysis we reflect on the impact of XAI on user\nsatisfaction and user comprehension as well as its use as a tool for diagnosing\nAI attacks. Our results show only limited engagement with XAI features and\nsuggest that, for Squid users, common assumptions found in the XAI literature\nwere not aligned to reality. On the positive side, users appear to have\ndeveloped better mental models of the AI feature compared to previous work, and\nthere is evidence that users did make some use of XAI as a diagnostic tool.",
        "updated": "2024-06-11 15:37:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.07369v1"
    },
    {
        "title": "AI.vs.Clinician: Unveiling Intricate Interactions Between AI and Clinicians through an Open-Access Database",
        "authors": "Wanling GaoYuan LiuZhuoming YuDandan CuiWenjing LiuXiaoshuang LiangJiahui ZhaoJiyue XieHao LiLi MaNing YeYumiao KangDingfeng LuoPeng PanWei HuangZhongmou LiuJizhong HuFan HuangGangyuan ZhaoChongrong JiangTianyi WeiZhifei ZhangYunyou HuangJianfeng Zhan",
        "links": "http://arxiv.org/abs/2406.07362v1",
        "entry_id": "http://arxiv.org/abs/2406.07362v1",
        "pdf_url": "http://arxiv.org/pdf/2406.07362v1",
        "summary": "Artificial Intelligence (AI) plays a crucial role in medical field and has\nthe potential to revolutionize healthcare practices. However, the success of AI\nmodels and their impacts hinge on the synergy between AI and medical\nspecialists, with clinicians assuming a dominant role. Unfortunately, the\nintricate dynamics and interactions between AI and clinicians remain\nundiscovered and thus hinder AI from being translated into medical practice. To\naddress this gap, we have curated a groundbreaking database called\nAI.vs.Clinician. This database is the first of its kind for studying the\ninteractions between AI and clinicians. It derives from 7,500 collaborative\ndiagnosis records on a life-threatening medical emergency -- Sepsis -- from 14\nmedical centers across China. For the patient cohorts well-chosen from MIMIC\ndatabases, the AI-related information comprises the model property, feature\ninput, diagnosis decision, and inferred probabilities of sepsis onset presently\nand within next three hours. The clinician-related information includes the\nviewed examination data and sequence, viewed time, preliminary and final\ndiagnosis decisions with or without AI assistance, and recommended treatment.",
        "updated": "2024-06-11 15:28:58 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.07362v1"
    },
    {
        "title": "Should XAI Nudge Human Decisions with Explanation Biasing?",
        "authors": "Yosuke FukuchiSeiji Yamada",
        "links": "http://arxiv.org/abs/2406.07323v1",
        "entry_id": "http://arxiv.org/abs/2406.07323v1",
        "pdf_url": "http://arxiv.org/pdf/2406.07323v1",
        "summary": "This paper reviews our previous trials of Nudge-XAI, an approach that\nintroduces automatic biases into explanations from explainable AIs (XAIs) with\nthe aim of leading users to better decisions, and it discusses the benefits and\nchallenges. Nudge-XAI uses a user model that predicts the influence of\nproviding an explanation or emphasizing it and attempts to guide users toward\nAI-suggested decisions without coercion. The nudge design is expected to\nenhance the autonomy of users, reduce the risk associated with an AI making\ndecisions without users' full agreement, and enable users to avoid AI failures.\nTo discuss the potential of Nudge-XAI, this paper reports a post-hoc\ninvestigation of previous experimental results using cluster analysis. The\nresults demonstrate the diversity of user behavior in response to Nudge-XAI,\nwhich supports our aim of enhancing user autonomy. However, it also highlights\nthe challenge of users who distrust AI and falsely make decisions contrary to\nAI suggestions, suggesting the need for personalized adjustment of the strength\nof nudges to make this approach work more generally.",
        "updated": "2024-06-11 14:53:07 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.07323v1"
    }
]