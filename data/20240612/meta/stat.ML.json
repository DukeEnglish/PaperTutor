[
    {
        "title": "Towards Fundamentally Scalable Model Selection: Asymptotically Fast Update and Selection",
        "authors": "Wenxiao WangWeiming ZhuangLingjuan Lyu",
        "links": "http://arxiv.org/abs/2406.07536v1",
        "entry_id": "http://arxiv.org/abs/2406.07536v1",
        "pdf_url": "http://arxiv.org/pdf/2406.07536v1",
        "summary": "The advancement of deep learning technologies is bringing new models every\nday, motivating the study of scalable model selection. An ideal model selection\nscheme should minimally support two operations efficiently over a large pool of\ncandidate models: update, which involves either adding a new candidate model or\nremoving an existing candidate model, and selection, which involves locating\nhighly performing models for a given task. However, previous solutions to model\nselection require high computational complexity for at least one of these two\noperations. In this work, we target fundamentally (more) scalable model\nselection that supports asymptotically fast update and asymptotically fast\nselection at the same time. Firstly, we define isolated model embedding, a\nfamily of model selection schemes supporting asymptotically fast update and\nselection: With respect to the number of candidate models $m$, the update\ncomplexity is O(1) and the selection consists of a single sweep over $m$\nvectors in addition to O(1) model operations. Isolated model embedding also\nimplies several desirable properties for applications. Secondly, we present\nStandardized Embedder, an empirical realization of isolated model embedding. We\nassess its effectiveness by using it to select representations from a pool of\n100 pre-trained vision models for classification tasks and measuring the\nperformance gaps between the selected models and the best candidates with a\nlinear probing protocol. Experiments suggest our realization is effective in\nselecting models with competitive performances and highlight isolated model\nembedding as a promising direction towards model selection that is\nfundamentally (more) scalable.",
        "updated": "2024-06-11 17:57:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.07536v1"
    },
    {
        "title": "Beyond Model Collapse: Scaling Up with Synthesized Data Requires Reinforcement",
        "authors": "Yunzhen FengElvis DohmatobPu YangFrancois ChartonJulia Kempe",
        "links": "http://arxiv.org/abs/2406.07515v1",
        "entry_id": "http://arxiv.org/abs/2406.07515v1",
        "pdf_url": "http://arxiv.org/pdf/2406.07515v1",
        "summary": "Synthesized data from generative models is increasingly considered as an\nalternative to human-annotated data for fine-tuning Large Language Models. This\nraises concerns about model collapse: a drop in performance of models\nfine-tuned on generated data. Considering that it is easier for both humans and\nmachines to tell between good and bad examples than to generate high-quality\nsamples, we investigate the use of feedback on synthesized data to prevent\nmodel collapse. We derive theoretical conditions under which a Gaussian mixture\nclassification model can achieve asymptotically optimal performance when\ntrained on feedback-augmented synthesized data, and provide supporting\nsimulations for finite regimes. We illustrate our theoretical predictions on\ntwo practical problems: computing matrix eigenvalues with transformers and news\nsummarization with large language models, which both undergo model collapse\nwhen trained on model-generated data. We show that training from\nfeedback-augmented synthesized data, either by pruning incorrect predictions or\nby selecting the best of several guesses, can prevent model collapse,\nvalidating popular approaches like RLHF.",
        "updated": "2024-06-11 17:46:16 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.07515v1"
    },
    {
        "title": "Partially Observed Trajectory Inference using Optimal Transport and a Dynamics Prior",
        "authors": "Anming GuEdward ChienKristjan Greenewald",
        "links": "http://arxiv.org/abs/2406.07475v1",
        "entry_id": "http://arxiv.org/abs/2406.07475v1",
        "pdf_url": "http://arxiv.org/pdf/2406.07475v1",
        "summary": "Trajectory inference seeks to recover the temporal dynamics of a population\nfrom snapshots of its (uncoupled) temporal marginals, i.e. where observed\nparticles are not tracked over time. Lavenant et al. arXiv:2102.09204 addressed\nthis challenging problem under a stochastic differential equation (SDE) model\nwith a gradient-driven drift in the observed space, introducing a minimum\nentropy estimator relative to the Wiener measure. Chizat et al.\narXiv:2205.07146 then provided a practical grid-free mean-field Langevin (MFL)\nalgorithm using Schr\\\"odinger bridges. Motivated by the overwhelming success of\nobservable state space models in the traditional paired trajectory inference\nproblem (e.g. target tracking), we extend the above framework to a class of\nlatent SDEs in the form of observable state space models. In this setting, we\nuse partial observations to infer trajectories in the latent space under a\nspecified dynamics model (e.g. the constant velocity/acceleration models from\ntarget tracking). We introduce PO-MFL to solve this latent trajectory inference\nproblem and provide theoretical guarantees by extending the results of\narXiv:2102.09204 to the partially observed setting. We leverage the MFL\nframework of arXiv:2205.07146, yielding an algorithm based on entropic OT\nbetween dynamics-adjusted adjacent time marginals. Experiments validate the\nrobustness of our method and the exponential convergence of the MFL dynamics,\nand demonstrate significant outperformance over the latent-free method of\narXiv:2205.07146 in key scenarios.",
        "updated": "2024-06-11 17:21:15 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.07475v1"
    },
    {
        "title": "Quantifying Local Model Validity using Active Learning",
        "authors": "Sven LämmleCan BogocluRobert VoßhallAnselm HaselhoffDirk Roos",
        "links": "http://arxiv.org/abs/2406.07474v1",
        "entry_id": "http://arxiv.org/abs/2406.07474v1",
        "pdf_url": "http://arxiv.org/pdf/2406.07474v1",
        "summary": "Real-world applications of machine learning models are often subject to legal\nor policy-based regulations. Some of these regulations require ensuring the\nvalidity of the model, i.e., the approximation error being smaller than a\nthreshold. A global metric is generally too insensitive to determine the\nvalidity of a specific prediction, whereas evaluating local validity is costly\nsince it requires gathering additional data.We propose learning the model error\nto acquire a local validity estimate while reducing the amount of required data\nthrough active learning. Using model validation benchmarks, we provide\nempirical evidence that the proposed method can lead to an error model with\nsufficient discriminative properties using a relatively small amount of data.\nFurthermore, an increased sensitivity to local changes of the validity bounds\ncompared to alternative approaches is demonstrated.",
        "updated": "2024-06-11 17:20:28 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.07474v1"
    },
    {
        "title": "Estimating the Hallucination Rate of Generative AI",
        "authors": "Andrew JessonNicolas Beltran-VelezQuentin ChuSweta KarlekarJannik KossenYarin GalJohn P. CunninghamDavid Blei",
        "links": "http://arxiv.org/abs/2406.07457v1",
        "entry_id": "http://arxiv.org/abs/2406.07457v1",
        "pdf_url": "http://arxiv.org/pdf/2406.07457v1",
        "summary": "This work is about estimating the hallucination rate for in-context learning\n(ICL) with Generative AI. In ICL, a conditional generative model (CGM) is\nprompted with a dataset and asked to make a prediction based on that dataset.\nThe Bayesian interpretation of ICL assumes that the CGM is calculating a\nposterior predictive distribution over an unknown Bayesian model of a latent\nparameter and data. With this perspective, we define a \\textit{hallucination}\nas a generated prediction that has low-probability under the true latent\nparameter. We develop a new method that takes an ICL problem -- that is, a CGM,\na dataset, and a prediction question -- and estimates the probability that a\nCGM will generate a hallucination. Our method only requires generating queries\nand responses from the model and evaluating its response log probability. We\nempirically evaluate our method on synthetic regression and natural language\nICL tasks using large language models.",
        "updated": "2024-06-11 17:01:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.07457v1"
    }
]