Partially Observed Trajectory Inference using Optimal
Transport and a Dynamics Prior
AnmingGu EdwardChien
BostonUniversity BostonUniversity
agu2002@bu.edu edchien@bu.edu
KristjanGreenewald
MIT-IBMWatsonAILab;IBMResearch
kristjan.h.greenewald@ibm.com
Abstract
Trajectoryinferenceseekstorecoverthetemporaldynamicsofapopulationfrom
snapshotsofits(uncoupled)temporalmarginals,i.e. whereobservedparticlesare
not trackedovertime. Lavenantetal. [33]addressedthischallengingproblem
underastochasticdifferentialequation(SDE)modelwithagradient-drivendrift
intheobservedspace, introducingaminimumentropyestimatorrelativetothe
Wiener measure. Chizat et al. [14] then provided a practical grid-free mean-
field Langevin (MFL) algorithm using Schrödinger bridges. Motivated by the
overwhelmingsuccessofobservablestatespacemodelsinthetraditionalpaired
trajectoryinferenceproblem(e.g. targettracking),weextendtheaboveframework
to a class of latent SDEs in the form of observable state space models. In this
setting,weusepartialobservationstoinfertrajectoriesinthelatentspaceunder
aspecifieddynamicsmodel(e.g. theconstantvelocity/accelerationmodelsfrom
targettracking). WeintroducePO-MFLtosolvethislatenttrajectoryinference
problem and provide theoretical guarantees by extending the results of [33] to
thepartiallyobservedsetting. WeleveragetheMFLframeworkof[13],yielding
an algorithm based on entropic OT between dynamics-adjusted adjacent time
marginals. Experimentsvalidatetherobustnessofourmethodandtheexponential
convergenceoftheMFLdynamics,anddemonstratesignificantoutperformance
overthelatent-freemethodof[13]inkeyscenarios.
1 Introduction
Estimating the temporal dynamics and trajectories of a population from collections of unpaired
observations at specific time points is a challenging fundamental problem with many potential
applicationsandarecentflurryofinterestinthecommunity[32,33,13,14]. Previousworkfocused
on the fully observed setting, where all variables that are important to the underlying dynamics
are directly observed with no hidden states. This setting is relevant to single-cell genomic data
analysis, where the goal is to understand the trajectories of a population of cells at unobserved
times and reconstruct the trajectories of individual cells in gene space. Here, note that physics
properties such as momentum do notapply. That said, research insignal processing and control
theoryhasoverwhelminglyshowntheimportanceofbeingabletohandlelatentstatesindynamics
modelingmoregenerally[23,16]. Evenlinearstatespacemodelshaveenjoyedarecentresurgence
formodelingtextsequencedatawithlargelanguagemodels(e.g. [21]).
While in general the problem of recovering a hidden state is not identifiable, systems theory has
developed observability conditions on the underlying dynamics model that does allow for such
Preprint.Underreview.
4202
nuJ
11
]GL.sc[
1v57470.6042:viXra(a)Groundtruth. (b)Reconstructedtrajectories. (c)Velocities.
Figure1: Constantvelocitymodel. Weseethatourmethod,PO-MFL,ismorerobustastheMFL
methodfailstoconverge,andprovidesper-particlevelocityincontrasttoMFL.SeeSection4forthe
experimentsetting.
recovery [30]. For instance, in target tracking, oftentimes only a position variable is observed,
yet the tracking algorithm uses a state space model that includes a hidden velocity state [17, 6].
Thishiddenstateallowsforbetterpredictingthefuturepositionofthetarget,improvingthefinal
trajectoryinferencebynotonlybettermodelingthedynamics,butmakingiteasiertoidentifywhich
ofseveraltargetsobservedatanygiventimecorrespondtothecurrenttrack[17,6]. Thehiddenstates
themselves,wheninterpretable,mayalsobeofdirectinterestfordownstreamapplications.
Thetrajectoryinferenceproblemhasmanysimilaritiestothetrackingproblem. Inparticular,atany
giventime,acloudofpointsisobserved,butthesepointsarenotlabeled,i.e. thereisnoindication
ofwhichpointsattimet matchtothepointsattimet . Inferringthese“matches”isthetaskof
1 2
trajectoryinference,andcloselyparallelsthedataassociationproblemintargettracking[1,43]. Asa
result,wearemotivatedtointroducelatentstatespacemodelingtothetrajectoryinferenceproblem.
Whileitselfbeingafullyobservedframeworkwithoutincorporatingaknowndynamics,theoptimal
transport(OT)-basedmethodof[14]isparticularlyamenabletoouraims. Itproposestooptimize
collectionsofparticlesateachtimesteptominimizeadatafitterm(acostbetweentheparticlecloud
andtheobserveddatapoints)andatrajectoryfittermconsistingoftheentropicWassersteindistance
betweensetsofparticlesatadjacenttimepoints. TheentropicOTframeworkarisesnaturallyfrom
theSDEmodel(aswewillseelater),andprovidesanexplicitandrobustprocedureforobtaining
inferredtrajectoriesfromunpairedtimeseriesdatabyfollowingtheOTplanbetweentimepoints.
Representingtheinferredtimemarginaldensitiesasparticlesisalsoparticularlyamenabletoour
partiallyobservedframework,aswecanhavetheparticlesbeinthehiddenstatespaceandforma
datafittermtotheobservationsusingaspecified(stochastic)observationmodel. Inmanywaysthis
parallelstheobservationmodel/hiddenstateparticlesetupusedbytheparticlefilter[4]andother
sequentialMonteCarlomethods[17]forthepaired-observationtrajectoryinferencesetting.
ApplicationsWhileourfocusisonthetheoreticalunderpinningsofthelatenttrajectoryinference
problemandMFL-basedalgorithm,weenvisionourapproachbeingbroadlyapplicabletoavariety
ofreal-worldtasks. Forinstance,theextrasmoothinginducedbyintroducingahiddenvelocitystate
couldimprovetrajectoryinferenceinthegenomicdataanalysissettingmentionedabove[14],or
anyapplicationwheretrajectoryinferenceisrelevant. Anotherpossibleapplicationdomaincouldbe
surveyormedicaldata. Specifically,whentrajectorydataisneeded,longitudinalstudiesareoften
designedwhereindividualsarefollowedovertimeandcontinuetobere-interviewed,butsignificant
logistical challenges are involved in such a procedure [52]. Trajectory inference could allow for
differentindividualstobesampledateachtimepoint,significantlyeasingtheburdenonresearchers.
Ourapproachforintroducinghiddenstates(e.g. velocity)wouldbeparticularlyimpactful,asinboth
socialscienceandmedicaldata,oftenindividual’strajectories(e.g. preferencesorhealth)docarry
significantmomentum. Finally,ourapproachcouldhaveadvantagesinprivatelearningoftimeseries
modelsorprivatesyntheticdatagenerationfortimeseries. Thisisbecausein(differential)privacy
[18,19],thegoalistopreservethestatisticsofanindividual,andtrajectoryinferenceallowsforeach
individual’sdatatobelimitedtoasinglepointintime,notrequiringafulltrajectoryrecordthatmay
bedifficulttoprivatize. Ourpartialobservationframeworkwouldallowforevenmoreprivacytobe
maintainedassomevariablescouldremainhiddenifanappropriatedynamicsmodelwasavailable.
RelatedworksTherehavebeenmanyworksinthemathematicalandcomputationalbiologycommu-
nityontrajectoryinference: see[44]forasurveyandcomparisonofsingle-celltrajectoryinference
methods. [46]introducestheuseofOTfortrajectoryinference;however,themethodgeneratespaths
thataregenerallynotsmooth. [12]usesOTtoconstructmeasure-valuedsplines,whichyieldssmooth
2paths,[10]modelspopulationdynamicsasaJordan-Kinderlehrer-Otto(JKO)flow[29],and[42]
usesOTtoanalyzegenetrajectories.
[55]considerthelimitsoftrajectoryinferencefromsingle-cellsnapshotsintheequilibriumsetting.
However,asfarasweareaware,[33]wasthefirstworktoprovidetheoreticalguaranteesofany
estimatorfortrajectoryinference. Theyintroduceamin-entropyestimatorforgradient-drivendrift
modelsandproveconvergencetothegroundtruthinthelimitasthenumberofobservationsbecome
dense in the observation period. [14] extends the entropy minimization formulation of [33] by
consideringadifferentfittingfunctional,reducingoptimizationspace,andusingMFLdynamics.
[57]considerstheapplicationoftheseOTframeworkstothesteady-statesettingwithknowncell
birthanddeathrates.
There has been much work on latent space for generative models, many of which use OT. [53]
usesscore-basedgenerativemodelinginlatentspace. [28]usesapre-trainedencoderanddecoder,
considerdiffusioninlatentspace, andprovetheoreticalguaranteesthattheoutputdistributionis
closetothegroundtruth. [22,58]considerlearnlatentmanifoldstructuresusingOT,[48]considers
gradientflowinlatentspacetostudyequivariantnetworks,[49]studiesthelatentspaceofgenerative
modelsusingOT,and[2]considersthenonlinearfilteringproblemusingpartialobservationsusing
OT.
TherearealsosomeworksconsideringconcreteapplicationsofSchrödingerbridgeswithnon-Wiener
referencemeasures. Forexample,[11]considersSchrödingerbridgeswherethepriorisanyMarkov
evolution for control theory and [9] shows that Schrödinger bridges between Gaussians against
referencemeasuresinducedbylinearSDEshaveaclosedforms.
NotationForprobabilitymeasuresµ, ν,therelativeentropy(e.g. theKLdivergence)isH(µ|ν)=
(cid:82) log(dµ/dν)dµ if µ ≪ ν and +∞ otherwise. For n ∈ N, let [n] := {1,...,n}. We use X to
denotethelatentspaceandY todenotetheobservationspace. WeusethenotationP(·)todenote
theprobabilitydistributionsoveraspace. ThepathspaceisΩ=C([0,1]:X),thesetofcontinuous
X-valuedpaths. Inourtheoreticaldiscussion,asin[33],weassumewithoutlossofgeneralitythat
the end time interval is t = 1. If R ∈ P(Ω) is a probability measure on the space of paths, its
marginal at time t is denoted as R ∈ P(X). We generally use the Greek letters µ,ρ to denote
t
probabilitydistributionsonX,Y,respectively. Weuseδ todenoteaDiracdeltaatx. Byanabuseof
x
notation,weuse|·|2 =⟨·,·⟩∈Rforboththesquarednormofavectorandthequadraticvariation
ofastochasticprocess. Forclarity,weusethenotationg ·whenappliedtomeasuresandg(·)when
♯
appliedtorandomvariables(similarlyforξ). WeusevoltodenotetheuniformmeasureonX.
2 LatentTrajectoryInference
LetX ∈X beanunobservedstatevectorevolvingaccordingtothefollowingSDEfort∈[0,1]:
t
√
dX =−Ξ(t,X )dt−∇Ψ(t,X )dt+ τdB , (1)
t t t t
where{B }isaBrownianmotion,τ istheknowndiffusivityparameter,Ξ∈C([0,1]×X :X)isa
t
knowndrivingvectorfield,andΨ∈C2([0,1]×X)isanunknownpotentialfunction. LetPbethe
lawoftheSDEwithinitialconditionP whereP ∈P(X)arethemarginalsofPattimet∈[0,1].1
0 t
Considerasmoothfunctiong :X →Y transformingX intotheobservationspaceY: Y =g(X ).
t t t
Suppose we have T observation times with 0 ≤ tT < ··· < tT ≤ 1, and we observe NT i.i.d.
1 T i
samplesfromthemarginaldistributionofY :
tT
i
{YT}N iT i. ∼i.d.
g P :=Q ,
i,j j=1 ♯ tT tT
i i
formingempiricaldistributionsρˆT =(cid:80)N iT δ .
i j=1 YT
i,j
ThegoalistorecoverPgiventhesnapshots(ρˆT,...,ρˆT). Ingeneral,tomakethisproblemwell-
1 T
posedandtractable,wemakeseveralassumptionsonthisverygeneralsetup. Thefirstoftheseisa
notionofobservabilitythatgeneralizes2theensembleobservabilityintroducedin[56]:
1OurSDEdiffersfromthatof[33,14]withtheadditionofnon-zeroΞ.
2Weincludestochasticity(τ >0)andallowforunknownΨ.
3Definition1(C -ensembleobservability). AssumethatΨisunknownbutrestrictedtoaclassC .
Ψ Ψ
Wesaythetuple(g,Ξ,C )isC -ensembleobservableif,giveng,Ξ,τ,andallmarginalsQ =g P
Ψ Ψ t ♯ t
ofY forallt∈[0,1],themarginalsP ofX areuniquelydeterminedforallt∈[0,1].
t t t
Withthisobservabilityassumption,wecaninferthelatentdynamicssolelyfromthemarginalsQ . A
t
discussionoftherelationshipbetweenthisconditionandthatofclassical/ensembleobservabilityis
presentinAppendixA.There,wealsoverifytheconditionsofDefinition1forseveralimportant
setups,e.g.,thekeyvelocity-baseddynamicsmodelweuseinourexperiments.
TheoreticalassumptionsLetX,Y bePolishspaces,whereX isasmoothandcompactRiemannian
manifoldoracompactandconvexsubsetofRd.Inthemanifoldsetting,weassumeitsRiccicurvature
K isboundedfrombelow,e.g. K >−∞.
ThepathspaceΩ = C([0,1] : X)isequippedwiththeuniformtopologyanditsBorelσ-algebra.
TheprobabilityspaceonpathsP(Ω)isequippedwiththeweaktopology,e.g. convergenceagainst
bounded,continuousfunctions. Assumeourprobabilityspace(Ω,F,P)iscompleteandfiltered,
wherethefiltrationiswithrespecttotheprocess{X }. Pisaprobabilitymeasure,andifitisnot
t
specified,expectationsaretakenwithrespecttoP. LetWΞ,τ bethemeasureinducedbytheSDE
√
dZ =−Ξ(t,Z )dt+ τdB .
t t t
Assumption 2.1 (Dynamics and Observation Model). Assume Ξ : C([0,1]×X : X) is known,
divergence-free,Lipschitzcontinuous,andsatisfies∥Ξ∥ <+∞. Assumetheobservationfunction
L∞
g :X →Y issmooth,measurable,bounded,andtimeinvariant.
Thedivergence-freeassumptionisrequiredsothatthetimemarginalsofWΞ,τ remainvolforall
timeiftheinitialconditionisvol3. Lipschitzcontinuityand∥Ξ∥ <+∞aretechnicalconditions
L∞
necessaryforourproofs,andtherearealsosomenecessarymildtechnicalconditionsonthepair
(Ξ,Ψ). TheseassumptionsarediscussedinAppendixB.Finally,byboundedforg,wemeanthe
imageofasetoffinitemeasurealsohasfinitemeasure.
3 PO-MFL:ApproximateMinimumEntropyEstimation
Inspiredby[33],weuseminimumentropyestimationasthefundamentaltoolforconnectingtemporal
snapshotsintocontinuoustrajectories,wheretheentropyistherelativeentropy(KLdivergence)of
theestimatedtrajectorydistributionwithrespecttotheknownportionoftheSDE.Inotherwords,we
estimatethetrajectorydistributionbymaximizingitslog-likelihoodwithrespecttothedistribution
inducedbytheSDE,subjecttomatchingtheobservedmarginals. Wewillshowthattheoptimalpoint
oftheminimumentropyobjectivefunctionconvergestothegroundtruthtrajectorydistribution.
It is not practical, however, to directly work with the trajectory distribution as it is an infinite-
dimensionalobject. Inwhatfollows,wewillshowthattheminimumentropyobjectiveintrajectory
spacecanbereducedtoanOT-basedobjective,wheremarginalsatadjacenttimepointsareconnected
viaentropicOT.
This reduction allows us to perform trajectory inference using only representations of the latent
spacetimemarginals,whichcanbeaccomplishedviasetsofparticles. Theseparticlescanthenbe
optimizedviaMFLdynamics.
3.1 Minimumentropyobjectivefunction
Inthissection,wespecifytheminimumentropyobjectivefunctiononthetrajectorydistribution.
Let{tT}⊂[0,1]beourobservationtimes,where∆t :=tT −tT. Recallthatingeneral,wedo
i i i+1 i
nothaveexactmeasurementofthetemporalmarginals,wewillonlyhavesamplesfromthem. Asa
result,wemustintroduceafitfunctiontomeasurethediscrepancybetweentheobservationspace
timemarginalsoftheestimatedtrajectorydistributionRandtheobservedsamples.
3NotethatifX hasaboundary,weneedazerofluxconditiononΞ,butwedonotconsiderthisinour
theoreticalanalysis.
4Let the observed empirical distribution smoothed by the h-wide heat kernel Φ be ρˆT,h :=
h i
Φ (cid:16) 1 (cid:80)N iT δ (cid:17) ∈P(Y)fori∈[T].4 ConsiderthefitfunctionFitλ,σ :P(Y)T →R:
h N iT i=1 Y iT ,j
T
1 (cid:88)
Fitλ,σ(Q ,...,Q ):= ∆t DFσ(g R ,ρˆT,h),
tT 1 tT T λ i ♯ tT i i
i=1
withdata-fittingtermintroducedby[14]augmentedbyobservationfunctiongtobe
(cid:90) (cid:20)(cid:90) (cid:18) ∥g(x)−y∥2(cid:19) (cid:21)
DFσ(g R ,ρˆT,h):= −log exp − dR (x) dρˆT,h(y)
♯ tT i i Y X 2σ2 tT i i
=H(ρˆT,h|g R ∗N )+H(ρˆT,h)+C,
i ♯ tT σ i
i
whereN istheGaussiankernelwithvarianceσ2,C >0isaconstant,andweusethesubstitution
σ
Q = g R .5 Note that this is the negative log-likelihood under the noisy observation model
tT ♯ tT
i i
YˆT = g(XT )+σZ ,whereYˆT istheobservationandZ i. ∼i.d. N(0,I). Itiseasytoseethat
i,j i,j i,j i,j i,j
DFσ isjointlyconvexin(R ,ρˆT,h)andlinearinρˆT,h. Themaindifferencecomparedto[14]isthat
tT i i
i
ourdata-fittingtermisinobservationspace,e,g. theadditionofthefunctiong. Webrieflymention
thatthedata-fittingtermin[33]isH(N ∗µˆT,h|R ). Thedata-fittingtermintroducedby[14](and
σ i tT
i
thusoursalso)iscomputationallymoreeffectivewhenR isadiscretemeasureandthusismore
tT
i
amenablefortheMFLdynamics. Thisdifferenceindata-fittingtermdoesnotyieldmajorchanges
forthetheoreticalresults,whichcanbeseeninAppendixB.
Theminimumentropyestimatorintroducedin[33]istheminimizerofthefunctionalF :P(Ω)→R
F(R):=Fitλ,σ(Q ,...,Q )+τH(R|WΞ,τ). (2)
tT tT
1 T
Recallthatourkeynoveltiesarethefitterminobservationspaceandentropyminimizationinpath
spacewithrespecttodivergence-free,Markovpathmeasures. Nonetheless,weshowthatwecanstill
recoverthegroundtruthinthelimitasthenumberofobservationsbecomesdense.
Theorem3.1(Consistency(informal,seeThm. B.1)). SupposePistheSDEgivenin(1)withinitial
conditionP ∈P(X)suchthatH(P |vol)<+∞. LetRT,λ,h ∈P(Ω)betheuniqueminimizerof
0 0
(2):
RT,λ,h :=argminF(R).
R∈P(Ω)
Then,wehavetheweakconvergence
(cid:16) (cid:17)
lim lim RT,λ,h =P.
h→0,λ→0 T→∞
ThisresultparallelsTheorem2.3in[33],whichprovidesaconsistencyresultinthefullyobserved
settingwheretheentirestatevectorX isobservedandΞ=0identically. Duetothesedifferences,
t
theresultin[33]cannotbedirectlyappliedtooursetting,andwhileourproofisabletofollowa
similaroverallstructure,denseandnontrivialchangesthroughouttheextensiveproofarerequired.
TheseargumentscanbefoundinAppendixB.
3.2 Thereducedproblem
Asin[14],weneedto“reduce”ourproblemoverthespaceP(X)T tousetheMFLdynamics[26].
Asbefore,let∆t :=tT −tT andτ :=∆t ·τ. ConsiderthefollowingentropicOTcost,defined
i i+1 i i i
forsomeτ >0,as
i
(cid:90)
T (µ,ν):= min cΞ(x,y)dγ(x,y)+τ H(γ|µ⊗ν)= min τ H(γ|pΞµ⊗ν), (3)
τi,Ξ
γ∈Π(µ,ν)
τi i
γ∈Π(µ,ν)
i τi
4Thissmoothinghaidstheproofsandwillbetakentoalimitofzerointhefollowingtheoreticalresults.
5Here,notethattheinnerintegralisoverX astheoptimizationwilloccuronthelatentspace,whiletheinner
integralisoverYastheobservationsareoverY.
5wherepΞisthetransitionprobabilitydensityofWΞ,τ overthetimeinterval[0,t]andthecostfunction
t
iscΞ(x,y):=−∆t log(pΞ(x,y)). Notethatingeneral,pΞ cannotbefoundexplicitly,sowewill
τi i τi τi
discusshowtoapproximatethisbelow. Werecallfrom[14,App. A]thatthisoptimizationproblem
isaSchrödingerbridgeproblem.6 DefinethefunctionalG:P(X)T →Rforµ=(µ(1),...,µ(T))
thatrepresentsafamilyofreconstructedtemporalmarginals,by
T−1
(cid:88) 1
G(µ):=Fitλ,σ(g µ)+ T (µ(i),µ(i+1)). (4)
♯ ∆t τi,Ξ
i
i=1
WeconsiderthereducedobjectiveF :P(X)T →R,definedas
F(µ):=G(µ)+τH(µ), (5)
whereH(µ)=(cid:80)T (cid:82) log(µ(i))dµ(i)istheminusdifferentialentropyofthefamilyofmeasuresµ.
i=1
Similarto[14],wehaveanequivalenceofminimizingF (2),theobjectiveinpathspaceP(Ω),and
F (5),thereducedobjectiveoverP(X)T. TheproofisprovidedinAppendixC.
Theorem3.2(Representertheorem). LetFit:P(Y)T →RbeanyfunctionandletΞbebounded
anddivergence-free.
(i) IfF admitsaminimizerR∗then(R∗ ,...,R∗ )isaminimizerforF.
tT tT
1 T
(ii) IfF admitsaminimizerµ∗ ∈P(X)T,thenaminimizerR∗forF isbuiltas
(cid:90)
R∗(·)= WΞ,τ(·|x ,...,x )dR (x ,...,x ),
1 T tT,...,tT 1 T
XT 1 T
whereWΞ,τ(·|x ,...,x )isthelawofWΞ,τ conditionedonpassingthroughx ,...,x at
1 T 1 T
timestT,...,tT,respectivelyandR isthecompositionoftheoptimaltransportplans
1 T tT,...,tT
1 T
γ thatminimizeT (µ∗(i),µ∗(i+1)),fori∈[T −1].
i τi,Ξ
Notethatthecompositionofthetransportplansisobtainedas:
R (dx ,...,dx )=γ (dx ,dx )γ (dx |x )···γ (dx |x ), (6)
ti,...,tT 1 T 1 1 2 2 3 2 T−1 T T−1
wheretheOTplansγ (dx ,dx )=γ (dx |x )µ (dx )areconditionalprobabilities(or“disinte-
i i i+1 i i+1 i i i
grations”). Asin[14],the“reduction”oftheoptimizationspacefromP(Ω)toP(X)T isenabled
bytheMarkovpropertyofWΞ,τ,whichholdsforusduetotheLipschitzcontinuityassumption
onΞandthatWΞ,τ remainstheuniformmeasureatalltime. Theorem3.2allowsustocomputea
minimizerforF fromaminimizerforF anditsassociatedOTplans.
3.3 ApproximatingtheentropicOTcost
AlthoughnowwehaveareducedproblemoverP(X)T,westillcannotsolvetheobjectivefunctionF
(5),astheentropicOTcostT (µ,ν)isdefinedwiththetransitionfunctionpΞ,whichisgenerally
τi,Ξ τi
not available in closed form. Here, we give an approximation of T (µ,ν) by considering an
τi,Ξ
Euler-Maruyama discretization [31]. Let µ ∈ P(Ω) be a stochastic process following the SDE
√
dX =−Ξ(t,X )dt+ τdB withanarbitraryinitialdistribution. Let∆t:=t −t andsuppose
t t t 2 1
µ ,µ aretwotimemarginalsofµ. RecallthatifX ∼µ ,and
t1 t2 t1 t1
(cid:90) t2 √ (cid:90) t2
X :=X − Ξ(s,X )ds+ τ dB , (7)
t2 t1 s s
t1 t1
thenX ∼ µ . Forsmall∆t = t −t ,sinceΞandµ aresmooth,theintegrandofthesecond
t2 t2 2 1 s
termwillbeapproximatelyconstantovertheintegrationinterval. Thus,wecanapproximatethefirst
twotermsof(7)as
ξ∆t(X ):=X −Ξ(t ,X )·∆t.
t1 t1 1 t1
6TheclassicalSchrödingerbridgeproblem[47]givesthemostlikelyevolutionofaprobabilitydistribution
followingaBrownianmotion,conditionedontheendpointsµattimet = 0andν attimet = 1,e.g. the
referencemeasureistheWienermeasure. [35,36]introducetheSchrödingerbridgeproblemasanentropy
minimizationproblemagainstgeneralreferencemeasures.Thisistheformulationweuse.
6Finally,notethatthelasttermof(7)isanisotropicGaussianwithvarianceτ∆t.
ThissuggestsapproximatingthetransitionkernelpΞ asadeterministicdriftgivenbythecurrentΞ,
τi
followedbyisotropicGaussiannoise. ForΞ=0,thiswouldreducetothekernelusedbytheMFL
method,i.e. theBrownianmotiontransitionkernel.
ThisprovidesanintuitionforwhyourapproachismorerobustthanthatoftheMFLmethodwhen
thetrueΞisnon-zero,sinceξ∆t(X )−X ≈N(0,τ∆t)forsmall∆t,whiletheX −X used
t1 t2 t1 t2
bytheMFLalgorithmhasnon-zeroexpectation,isnon-Gaussian,andoftenhassignificantlyhigher
variance.7
LetTV(·,·)denotethetotalvariationdistance. Wehavethefollowingresultforusingtheabove
approximationinthetransitionkernel,whichisaspecialcaseof[8,Thm. 2.1]. Notethatthisimplies
thatthedifferenceinprobabilitybetweentheapproximatekernelandtruekernelforanyeventisof
orderO((∆t)1/3),whichconvergesto0asT →∞.
√
Proposition3.3. LetX beasin(7)andX˜ := ξ∆t(X )+ τ(B −B ),whereX = δ .
t2 t2 t1 t2 t1 t1 x
Then,
TV(X ,X˜ )≤C eC2|x|2 (∆t)1/3,
t2 t2 1
wheretheconstantsC ,C >0dependonlyondimX andtheLipschitzconstantofΞ.
1 2
Applying this approximate transition kernel yields updated, tractable OT terms in the objective
function. Specifically,insteadofT (µ(i),µ(i+1))in(4),weuseT (ξti+1−tiµ(i),µ(i+1)),where
τi,Ξ τi ♯
T (µ,ν):= min τ H(γ|p µ⊗ν)
τi
γ∈Π(µ,ν)
i τi
istheentropicOTcostin[14,Eq. 6]andp (x,y)isthetransitionprobabilitydensityoftheBrownian
t
motiononX overthetimeinterval[0,t]. Thiscostiseasilycomputedasp istheGaussiankernel.
τi
Above,weconsiderthepushforwardofthefirstmarginalforeaseofanalysis. Inourimplementation
and experiments, we use T (ξ∆t/2µ(i),ξ−∆t/2µ(i+1)), e.g. we pushforward the first marginal
τi ♯ ♯
andpullbackthesecondmarginal. ThisentropicOTproblemhasthecorrespondingcostfunction
c˜Ξ(x,y):=−∆t log(p (ξ∆t/2(x),ξ−∆t/2(y))),andweuseVaradhan’sapproximation[40]
τi i τi
c˜Ξ τi(x,y)≈ 1 2(cid:13) (cid:13) (cid:13) (cid:13)y− ∆ 2t Ξ(t 2,y)−x+ ∆ 2t Ξ(t 1,x)(cid:13) (cid:13) (cid:13) (cid:13)2 ,
whichholdsforτ small,e.g. seeAlgorithm1. Towrapupourdiscussionhere,itisimportantto
i
highlightthatwerequireageneralizationof[33,Thm. 2.3]usingourpathmeasureWΞ,τ,Theorem
3.1,tojustifyconvergenceofourestimatorwhenincludingΞinourcostfunctionintheentropicOT
problem(3).
3.4 Mean-fieldLangevindynamicsandexponentialconvergence
WeprovideabriefdescriptionoftheMFLdynamics.SeeAppendixDforamorecompletediscussion.
MFL dynamics are designed to minimize functionals of the form F = G+(τ +ϵ)H, where
ϵ
G : P(X) → R is smooth and H is minus the differential entropy. As in [14], we increase the
entropyfactorbyϵ > 0becauseGisnotconvex,butF = G+τH is. Usingthefirst-variation
0
V[µ]ofGgiveninPropositionD.1,theMFLdynamicsisdefinedasthesolutionofthefollowing
non-linearMcKean-VlasovSDE,fors≥0:
(cid:40) dX(i) =−∇V(i)[µ ](X(i))ds+(cid:112) 2(τ +ϵ)dB(i)+dΦ(i), Law(X(i))=µ(i)
s s s s s 0 0 (8)
µ(i) =Law(X(i)), i∈[T],
s s
wheredΦ(i) istheboundaryreflectioninthesenseoftheSkorokhodproblem,e.g. [51]. Here,Ξ
s
doesnot,andshouldnotshowupin(8)aswealreadyconsiderΞfortheentropicOTproblem(3)
thatinducestheSchrödingerpotentials. Thus,theMcKean-VlasovSDEisexactlythesameasthatof
[14]. Forcomputation,wediscretizetheMFLdynamicsvianoisyparticlegradientdescent,which
wediscussinAppendixD.2.
7Inasense,ourEuler-Maruyamaapproximationcanbeconsideredafirstorderapproximationmethod,while
MFLcorrespondstoazerothordermethod.Higherordermethodscouldbeanavenueforfuturework.
7Algorithm1PO-MFL:frameworkforlatenttrajectoryinference
Require: Collectionofobservations(ρˆ ,...,ρˆ),collectionofT timesamples(tT,...,tT),velocitydynamics
1 t 1 T
Ξ,numberofiterationsforMFLdynamicsN,numberofparticlesm,entropicOTparameterλ
1: Initializemparticlesforeachtime:(mˆ ,...,mˆ )∈Xm×T
1 T
2: forN iterationsdo
3: fori∈[T −1]do
4: ∆t :=tT −tT
i i+1 i
5: C :={C }m ← 1∥mˆ − ∆tiΞ(tT ,mˆ )−mˆ + ∆tiΞ(tT,mˆ )∥2
i j,k j,k=1 2 i+1,k 2 i+1 i+1,k i,j 2 i i,j
6: γ ←Sinkhorn(mˆ ,mˆ ,C ,λ·∆t )
i i i+1 i i
7: endfor
8: mˆ ←MFL(mˆ,γ,ρˆ) ▷m:=(mˆ ,...,mˆ ),etc.
1 t
9: endfor
10: Outputcollectionofparticlesmˆ,trajectoriesγ ◦···◦γ
t−1 1
Figure2: AverageW distancebetweengroundtruthandPO-MFLrecoveredpositionsin“constant
2
velocity”modelfromAppendixE.(left)Numberoftimepoints. (middle)Numberofobservations.
(right)Velocity.
In[14,13],itisshownthattheMFLdynamicsin(8)convergesatanexponentialratetotheminimizer,
andthisconvergencealsoholdsinrelativeentropyandinWassersteindistance. Weprovidetheproof
forthefollowingsimilarresultforourpartiallyobservedsettinginAppendixD.
Theorem3.4(Convergence). AssumeX isthed-torus.Letµ ∈P(X)T besuchthatF(µ )<+∞.
0 0
Then for ϵ ≥ 0, there exists a unique solution (µ ) to the MFL dynamics (8). Let ϵ > 0 and
s s≥0
assumethatµ hasaboundedabsolutelog-density,itholds
0
F (µ )−minF ≤e−Cs(F (µ )−minF ),
ϵ s ϵ ϵ 0 ϵ
whereC =βe−α/ϵ forsomeα,β >0independentlyofµandϵ. Moreover,takingasmoothtime-
dependentϵ thatdecaysasymptoticallyasα˜/logsforsomeα˜ >α,itholdsF (µ )−F (µ∗)≲
s 0 s 0
loglogs/logs→0andµ convergesweaklytothemin-entropyestimatorµ∗.
s
3.5 PO-MFL
We summarize our proposed latent trajectory inference method in Algorithm 1. We recall that
discussiononthecostfunction(line4)andMFLdynamics(line7)canbefoundinSections3.3and
3.4,respectively. WeusetheSinkhornalgorithm[15]forentropicOT.
GiventhesetofobservedtemporalmarginalsamplesintheobservationspaceY,Algorithm1yields
asetofmparticlesateachtimestepirepresentingthetemporalmarginaldistributionsinthelatent
spaceX. Simulatedtrajectoriesmayberecoveredbysamplingfromthecompositionofentropic
transportplansasshownin(6).
4 Experiments
Inthissection,webrieflyprovidesyntheticexperimentsthatdemonstratetheadvantagesofhavinga
dynamicsprior. AllexperimentswererunonanM1MacbookAirwith16GBofRAM,andeach
experimenttakesnomorethanafewminuteseachtorun. Moredetailsontheexperimentalsetupcan
befoundinAppendixE.
8Figure3:(left)Velocityofoneparticleatendofoptimization.(right)Populationvelocityatbeginning
ofoptimization,showingexponentialconvergence.
“Constantvelocity”modelWecomparethebehaviorofourmethod,PO-MFL,tothatofMFL,using
the“constantvelocity”modelpopularintargettracking[38],seeAppendixA.1forfurtherdetailsof
thismodelanditsensembleobservability.8 Inthismodel,thestatespaceisX =(x,y,x˙,y˙)∈R4,
with Ξ given in the appendix and observations g(X) = [I ,0 ]X. Note that due to non-zero
2 2×2
processnoiseτ,despitethename,thismodeldoesnotimplythatthevelocityisconstantintime. The
particlesareinitializedattheoriginwithvelocitiessetasx˙ = 5andy˙ = 7,i.e. X = (0,0,5,7).
0
ThegroundtruthisshowninFigure1a.
Our optimization method observes
onlythepositionsoftheparticles,i.e.
g(x,y,·,·) = (x,y),butitusesΞas
being a constant velocity prior. Re-
sults shown in Figure 1b show that
PO-MFL is able to successfully re-
constructthepathstrajectories,while
MFLfailstoconverge. Furthermore,
inFigure1c,weverifythatthepopula-
tionaverageoftheparticles’velocities
(a)Groundtruth.
matcheswiththegroundtruth.
Figure3(left)displaystheyvelocity
of one particle for the last 500 iter-
ations of optimization. Although at
eachiteration,thevelocityisstochas-
tic,wecanseethatthemeanisat7.In
Figure3(right),weplottheaverage
yvelocityinthefirst400iterationsof
optimization,providingempiricalevi-
denceoftheexponentialconvergence
ofouralgorithmguaranteedbyTheo- (b)Reconstructedtrajectories.
rem3.4.
Figure 4 shows a crossing paths ex-
periment where the population is di-
vided into two groups, one moving
right and down, and the other right
and up, with their paths crossing in
themiddle. Inthisparticularlyillumi-
natingregime,PO-MFLleveragesthe
“constantvelocity”modelusedinthis
(c)ReconstructedvelocityfromPO-MFL.Notethebimodalvelocity
section to distinguish the downward
estimate.
movinggroupfromtheupwardmov-
inggroup. NotethatPO-MFLisnot Figure 4: Crossing paths experiment under the “constant
toldaprioriwhichsamplesbelongto velocity”SDE.
8Thismodelcanbeinterpretedasintroducingvelocityasahiddenstatetobeinferred,inordertobuild
momentumintothedynamics(anobjectinmotiontendstostayinmotion).Thisisanextremelygenericmodel
andmakesminimalassumptionsontheunderlyingdata,asevidencedbyitsuseintargettracking.
9whichgroup. WhileMFLherecollapsestothecentroid,wepointoutthatevenifitsoptimization
wassuccessful,theMFLwouldpreferU-shapedtrajectorieshereratherthanthecorrectstraight-line
trajectories,asitdoesnotretainahiddenvelocitystateandonlyseekstomatchadjacenttimepoints
bytheirrelativepositionviaentropicOT.
WeprovideavarietyofadditionalexperimentsinAppendixEillustratinghowperformancechanges
asthenumberofobservedparticles,thespacingoftimepoints,andtheunderlyinggroundtruthinitial
velocity affects performance. Figure 2 shows the average W distance between the ground truth
2
positionsandrecoveredpositions(averagedbytimepoint)acrosstheseexperiments. Ourapproach
remainssignificantlymorerobustastheseparametersarevariedcomparedtoMFL.
Circular motion model In our second model, the
particles(θ,θ˙,θ¨) ∈ S×R2 representaconstantac-
celerationmodelontheunitcircle,startingfromthe
initialcondition(0,0.5,1). Here,weuseangularve-
locityandangularacceleration. Inthisexperiment,
weonlyobservetheposition,e.g. g(θ,·,·) = θ. In
Figure5a,weshowthegroundtruthwithpositionon
theleftandangularvelocityontheright. InFigure
5b,weshowthatPO-MFLsuccessfullyreconstruct (a)Groundtruth.
thepositionswhilealthoughMFLconverges,itdoes
notrecoverthegroundtruth. InFigure5c,weshow
that the reconstructed velocity matches that of the
groundtruthinFigure5a.
5 Conclusion
We consider the problem of trajectory inference in (b)Reconstructedpositionmarginals.
latent space based on indirect observation, extend-
ing the theoretical analysis of the min-entropy es-
timator introduced in [33] and the MFL dynamics
algorithmintroducedin[14]. Syntheticexperiments
wereprovidedshowingthattheabilitytoincludesim-
plenon-informativelatentdynamicsmodels,suchas
(c)Reconstructedangularvelocitymarginalsfrom
the“constantvelocity”model,candramaticallyim-
PO-MFL.
provethetrajectoryinferenceperformanceoverthe
baselineMFLmethod,whilealsodirectlyproviding Figure5: Circularmotionmodel.
per-particleestimatesofthehiddenvelocitystate.
For future work, while we do here provide some flexibility for model misspecification via the
unknownΨpotential,itwouldbeinterestingtofurtherexplorethestabilityofourmethodwhen
thedynamicsmodelΞismisspecified. Furtherexplorationofensembleobservabilitywouldalsobe
ahighlyinterestingfundamentaldirectiontoexplore. Finally,wewillseektoexplorethevarious
promisingempiricalusecasesoutlinedintheintroduction.
References
[1] Probabilisticdataassociationtechniquesfortargettrackinginclutter. ProceedingsoftheIEEE,
92(3):536–557,2004.
[2] MohammadAl-Jarrah,NiyizhenJin,BamdadHosseini,andAmirhosseinTaghvaei. Nonlinear
filteringwithbrenieroptimaltransportmaps,2024.
[3] MarcArnaudon,AnaBelaCruzeiro,ChristianLéonard,andJean-ClaudeZambrini. Anentropic
interpolationproblemforincompressibleviscidfluids,2017.
[4] MSanjeevArulampalam,SimonMaskell,NeilGordon,andTimClapp. Atutorialonparticle
filters for online nonlinear/non-gaussian bayesian tracking. IEEE Transactions on signal
processing,50(2):174–188,2002.
[5] DominiqueBakry,IvanGentil,andMichelLedoux. Analysisandgeometryofmarkovdiffusion
operators. 2013.
10[6] Yaakov Bar-Shalom and Xiao-Rong Li. Multitarget-multisensor tracking: principles and
techniques,volume19. YBSpublishingStorrs,CT,1995.
[7] Jean-DavidBenamou,GuillaumeCarlier,SimoneDiMarino,andLucaNenna. Anentropy
minimizationapproachtosecond-ordervariationalmean-fieldgames,2019.
[8] PierreBras,GillesPagès,andFabienPanloup. Totalvariationdistancebetweentwodiffusions
insmalltimewithunboundeddrift: applicationtotheeuler-maruyamascheme. Electronic
JournalofProbability,27(none),January2022.
[9] CharlotteBunne,Ya-PingHsieh,MarcoCuturi,andAndreasKrause. Theschrödingerbridge
betweengaussianmeasureshasaclosedform,2023.
[10] CharlotteBunne,LaetitiaMeng-Papaxanthos,AndreasKrause,andMarcoCuturi. Proximal
optimaltransportmodelingofpopulationdynamics,2022.
[11] Yongxin Chen, Tryphon Georgiou, and Michele Pavon. On the relation between optimal
transportandschrödingerbridges: Astochasticcontrolviewpoint,2014.
[12] Sinho Chewi, Julien Clancy, Thibaut Le Gouic, Philippe Rigollet, George Stepaniants, and
AustinStromme. Fastandsmoothinterpolationonwassersteinspace. InArindamBanerjee
andKenjiFukumizu,editors,ProceedingsofThe24thInternationalConferenceonArtificial
IntelligenceandStatistics,volume130ofProceedingsofMachineLearningResearch,pages
3061–3069.PMLR,13–15Apr2021.
[13] LénaïcChizat. Mean-fieldlangevindynamics: Exponentialconvergenceandannealing,2022.
[14] LénaïcChizat,StephenZhang,MatthieuHeitz,andGeoffreySchiebinger. Trajectoryinference
viamean-fieldlangevininpathspace,2022.
[15] MarcoCuturi. Sinkhorndistances:Lightspeedcomputationofoptimaltransport. InC.J.Burges,
L. Bottou, M. Welling, Z. Ghahramani, and K.Q. Weinberger, editors, Advances in Neural
InformationProcessingSystems,volume26.CurranAssociates,Inc.,2013.
[16] MarkDavis. Stochasticmodellingandcontrol. SpringerScience&BusinessMedia,2013.
[17] ArnaudDoucet,NandoDeFreitas,NeilJamesGordon,etal. SequentialMonteCarlomethods
inpractice,volume1. Springer,2001.
[18] C.DworkandA.Roth. TheAlgorithmicFoundationsofDifferentialPrivacy. Foundationsand
trendsintheoreticalcomputerscience.Now,2014.
[19] CynthiaDwork,FrankMcSherry,KobbiNissim,andAdamSmith. Calibratingnoisetosensi-
tivityinprivatedataanalysis. InShaiHaleviandTalRabin,editors,TheoryofCryptography,
pages265–284,Berlin,Heidelberg,2006.SpringerBerlinHeidelberg.
[20] Z.Gajic,Z.Gajic´,andM.Lelic´. ModernControlSystemsEngineering. Prentice-Hallinterna-
tionalseriesinsystemsandcontrolengineering.PrenticeHall,1996.
[21] AlbertGuandTriDao. Mamba: Linear-timesequencemodelingwithselectivestatespaces.
arXivpreprintarXiv:2312.00752,2023.
[22] KeatonHamm,CarolineMoosmüller,BernhardSchmitzer,andMatthewThorpe. Manifold
learninginwassersteinspace,2023.
[23] JoaoPHespanha. Linearsystemstheory. Princetonuniversitypress,2018.
[24] E.P. Hsu. Stochastic Analysis on Manifolds. Graduate studies in mathematics. American
MathematicalSociety,2002.
[25] E.P.Hsu. Abriefintroductiontobrownianmotiononariemannianmanifold,2008.
[26] KaitongHu,ZhenjieRen,DavidSiska,andLukaszSzpruch. Mean-fieldlangevindynamics
andenergylandscapeofneuralnetworks,2020.
11[27] Adel Javanmard, Marco Mondelli, and Andrea Montanari. Analysis of a two-layer neural
networkviadisplacementconvexity,2019.
[28] Yuling Jiao, Lican Kang, Huazhen Lin, Jin Liu, and Heng Zuo. Latent schrödinger bridge
diffusionmodelforgenerativelearning,2024.
[29] RichardJordan,DavidKinderlehrer,andFelixOtto. Thevariationalformulationofthefokker–
planckequation. SIAMJournalonMathematicalAnalysis,29(1):1–17,1998.
[30] RudolfEKalman. Onthegeneraltheoryofcontrolsystems. InProceedingsFirstInternational
ConferenceonAutomaticControl,Moscow,USSR,pages481–492,1960.
[31] P.E.KloedenandE.Platen. NumericalSolutionofStochasticDifferentialEquations. Applica-
tionsofmathematics: stochasticmodellingandappliedprobability.Springer,1992.
[32] HugoLavenantandFilippoSantambrogio. Theflowmapofthefokker–planckequationdoes
notprovideoptimaltransport. AppliedMathematicsLetters,133:108225,2022.
[33] Hugo Lavenant, Stephen Zhang, Young-Heon Kim, and Geoffrey Schiebinger. Towards a
mathematicaltheoryoftrajectoryinference,2023.
[34] Peter Li and Shing Tung Yau. On the parabolic kernel of the Schrödinger operator. Acta
Mathematica,156(none):153–201,1986.
[35] ChristianLéonard. Fromtheschrödingerproblemtothemonge-kantorovichproblem,2010.
[36] Christian Léonard. A survey of the schrödinger problem and some of its connections with
optimaltransport,2013.
[37] SimoneDiMarinoandAugustoGerolin. Anoptimaltransportapproachfortheschrödinger
bridgeproblemandconvergenceofsinkhornalgorithm,2019.
[38] GregoryAMcIntyreandKennethJHintz. Comparisonofseveralmaneuveringtargettracking
models. InSignalprocessing,sensorfusion,andtargetrecognitionVII,volume3374,pages
48–63.SPIE,1998.
[39] Atsushi Nitanda, Denny Wu, and Taiji Suzuki. Convex analysis of the mean field langevin
dynamics,2022.
[40] JamesR.Norris. HeatkernelasymptoticsandthedistancefunctioninLipschitzRiemannian
manifolds. ActaMathematica,179(1):79–103,1997.
[41] B.Øksendal.StochasticDifferentialEquations:AnIntroductionwithApplications.Universitext.
SpringerBerlinHeidelberg,2010.
[42] RihaoQu,XiuyuanCheng,EsenSefik,JayS.StanleyIII,BorisLanda,FrancescoStrino,Sarah
Platt,JamesGarritano,IanD.Odell,RonaldCoifman,RichardA.Flavell,PeggyMyung,and
YuvalKluger. Genetrajectoryinferenceforsingle-celldatabyoptimaltransportmetrics. Nature
Biotechnology,Apr2024.
[43] SeyedHamidRezatofighi, AntonMilan, ZhenZhang, QinfengShi, AnthonyDick, andIan
Reid. Jointprobabilisticdataassociationrevisited. InProceedingsoftheIEEEinternational
conferenceoncomputervision,pages3047–3055,2015.
[44] Wouter Saelens, Robrecht Cannoodt, Helena Todorov, and Yvan Saeys. A comparison of
single-celltrajectoryinferencemethods. NatureBiotechnology,37(5):547–554,May2019.
[45] FilippoSantambrogio. OptimalTransportforAppliedMathematicians: CalculusofVariations,
PDEs,andModeling. ProgressinNonlinearDifferentialEquationsandTheirApplications.
BirkhäuserBasel,2015.
[46] Geoffrey Schiebinger, Jian Shu, Marcin Tabaka, Brian Cleary, Vidya Subramanian, Aryeh
Solomon, Joshua Gould, Siyan Liu, Stacie Lin, Peter Berube, Lia Lee, Jenny Chen, Justin
Brumbaugh,PhilippeRigollet,KonradHochedlinger,RudolfJaenisch,AvivRegev,andEricS.
Lander. Optimal-transport analysis of single-cell gene expression identifies developmental
trajectoriesinreprogramming. Cell,176(4):928–943.e22,2019.
12[47] ErwinSchrödinger. Surlathéorierelativistedel’électronetl’interprétationdelamécanique
quantique.(French)[Ontherelativistictheoryoftheelectronandtheinterpretationofquantum
mechanics]. 2:269–310,1932.
[48] YueSong,T.AndersonKeller,NicuSebe,andMaxWelling. Flowfactorizedrepresentation
learning,2023.
[49] YueSong,T.AndersonKeller,NicuSebe,andMaxWelling. Latenttraversalsingenerative
modelsaspotentialflows,2023.
[50] TaijiSuzuki,DennyWu,andAtsushiNitanda. Convergenceofmean-fieldlangevindynamics:
Timeandspacediscretization,stochasticgradient,andvariancereduction,2023.
[51] HiroshiTanaka. Stochasticdifferentialequationswithreflectingboundaryconditioninconvex
regions. HiroshimaMathematicalJournal,9(1):163–177,1979.
[52] Rachel Thomson and Janet Holland. Hindsight, foresight and insight: The challenges of
longitudinal qualitative research. International Journal of Social Research Methodology,
6(3):233–244,2003.
[53] ArashVahdat,KarstenKreis,andJanKautz. Score-basedgenerativemodelinginlatentspace,
2021.
[54] P.VatiwutipongandN.Phewchean. Alternativewaytoderivethedistributionofthemultivariate
ornstein–uhlenbeckprocess. AdvancesinDifferenceEquations,2019.
[55] CalebWeinreb,SamuelWolock,BetsabehK.Tusi,MeravSocolovsky,andAllonM.Klein.
Fundamental limits on dynamic inference from single-cell snapshots. Proceedings of the
NationalAcademyofScience,115(10):E2467–E2476,March2018.
[56] ShenZeng,SteffenWaldherr,ChristianEbenbauer,andFrankAllgöwer.Ensembleobservability
oflinearsystems. IEEETransactionsonAutomaticControl,61,072015.
[57] Stephen Zhang, Anton Afanassiev, Laura Greenstreet, Tetsuya Matsumoto, and Geoffrey
Schiebinger. Optimal transport analysis reveals trajectories in steady-state systems. PLOS
ComputationalBiology,17(12):1–29,122021.
[58] Stephen Zhang, Gilles Mordant, Tetsuya Matsumoto, and Geoffrey Schiebinger. Manifold
learningwithsparseregularisedoptimaltransport,2023.
13A EnsembleObservabilityforLinearSystems
Recallthatinclassicalobservability[20],thegoalistorecoverthedynamicsofasingleparticle,
whileherewewanttorecoverthedynamicsofaprobabilitydistribution. Thenotionofensemble
observabilityintroducedin[56]tacklesthisproblem. Considerthenon-stochasticmodelwithlinear
Ξ(X)=A X+B :
Ξ Ξ
dX =−(A X +B )dt (9)
t Ξ t Ξ
withinitialconditionP andlinearobservationsY = g(X ) = C X +D . Forshorthand, we
0 t t g t g
denotethissystemas(A ,B ,C ,D ).
Ξ Ξ g g
Thefollowingisthedefinitionofensembleobservabilityasintroducedin[56]: itdoesnotconsider
stochasticity.
Definition2(Ensembleobservability[56,Def. 1]). Thelinearsystem(9)isensembleobservableif
givenmarginalsg P ofY forallt∈[0,1],themarginalsP ofX areuniquelydeterminedforall
♯ t t t t
t∈[0,1].
WecanconsiderDefinition1asanextensionofensembleobservability. Inparticular,ifweconsider
τ = 0 in Definition 1, we exactly recover ensemble observability. [56] showed that classical
observabilityisanecessaryconditionforensembleobservability, andprovidedseveralsufficient
conditionsaswell. ForarandomvariableX,wedenoteφ tobeitscharacteristicfunction. We
X
assumethefollowingontheinitialdistributionX .
0
AssumptionA.1. LetX besuchthats(cid:55)→φ (sv)isreal-analyticforallnon-zerov ∈Rn.
0 X0
Thisassumptionisnotverystrongandmost“nice”distributionssatisfyit,e.g. iftheyhaveadensity.
Recallthatby[20,Thm. 5.2],classicalobservabilityholdsifandonlyiftheobservabilitymatrix
O := [C ,C A ,...,C An−1] has rank n. [56] provides two useful sufficient conditions9 for
Ξ Ξ Ξ Ξ Ξ
ensembleobservabilityofsuchsystems.
Proposition A.2 ([56, Thm. 8]). Under Assumption A.1, if (A ,B ,C ,D ) is observable and
Ξ Ξ g g
rankC =n−1,then(A ,B ,C ,D )isensembleobservable.
g Ξ Ξ g g
CorollaryA.3([56,Cor.8]). UnderAssumptionA.1,ifX =R2and(A ,B ,C ,D )isobservable,
Ξ Ξ g g
then(A ,B ,C ,D )isensembleobservable.
Ξ Ξ g g
Wenowshowthatthesetwoconditionscanbecarriedovertostochasticsystems,i.e.,thosewith
τ >0. Consideraddingstochasticityto(9)withthemodel
√
dX =−(A X +B )dt+ τdB (10)
t Ξ t Ξ t
withinitialconditionP ,{B }isanRn-valuedBrownianmotion,andobservationsY =C X +D .
0 t t g t g
Wehavethefollowingresult:
CorollaryA.4. Suppose(A ,B ,C ,D )isensembleobservable(withτ =0). Thenthesystem
Ξ Ξ g g
(10)withknownτ >0isensembleobservable.
Proof. Itiseasytoseeviadirectcalculation10thatthesolutionto(10)is
(cid:18)(cid:90) t (cid:19) √ (cid:90) t
X =e−AΞtX − e−AΞ(t−s)ds B + τ e−AΞ(t−s)dB , (11)
t 0 Ξ s
0 0
whereweusematrixexponentials. Usingargumentssimilartothosein[54],wecancharacterizethe
covariance:
(cid:90) t
Σ
t
:=Cov[X t]=τ e−(AΞ+A⊤ Ξ)(t−s)ds.
0
Wealsoknowthat
(cid:18)(cid:90) t (cid:19)
µ :=E[X ]=e−AΞtX − e−AΞ(t−s)ds B .
t t 0 Ξ
0
9Thesearenottheonlyconcreteconditionsprovidedtherein.Furthermore,amoregeneralsufficientcondition
isprovidedwhichispossibletochecknumerically.
10E.g.usinganintegratingfactor.
14Thenasthefirsttwotermsontheright-handsideof(11)havezerovarianceandtheItôintegralofa
deterministicintegrandisnormallydistributedwithmeanzero,weknowthat(11)isdistributedas
X ∼N(µ ,Σ ).
t t t
Asweknowτ,andthecorrespondingobservabilitymatrixtothesystemhasfull-rank,weseethatthe
pushforward(toobservationspace)ofeverytermin(11)isalsofullyrecoverableaswell. Notethatit
ispossibletodeconvolve11 theknownGaussiannoisefromX ,andhencethesystemisensemble
t
observable. Thisconcludestheproof.
Next,weextendCorollaryA.3toindependentprocessesandapplyCorollaryA.4.
PropositionA.5. LetX =X ×···×X ,whereeachX =R2. Suppose(A ,B ,C ,D )is
1 n i Ξi Ξi gi gi
observableforeachi∈[n]. Further,supposetheinitialconditionjointdistributionfortheX satis-
0,i
fiesAssumptionA.1with[X ] ,[X ] conditionallyindependentconditionedon[X ] ,[X ] ,
0,i 1 0,j 2 0,i 2 0,j 1
foreachj ̸=i. Ifnoiseparameterτ >0isknownand{B }isanX-valuedBrownianmotion,then
t
thesystem
       
A B C D
Ξ1 Ξ1 g1 g1
. . . .
 . , . , . , . 
 .   .   .   . 
A B C D
Ξn Ξn gn gn
is ensemble observable. Furthermore, the system remains ensemble observable under (known)
permutations.
Proof. ThisfollowsfromasimpleapplicationofCorollariesA.3andA.4.
A.1 Example: “Constantvelocity”model
Thetwo-dimensional“constantvelocity”model,sonamedbecausethevelocitywouldbeconstantif
therewerenoprocessnoise(τ =0),usesastatevector
X =(x,y,x˙,y˙)∈R4,
where here (x,y) are two-dimensional positional coordinates, and (x˙,y˙) is the current two-
dimensionalvelocity. The“constantvelocity”dynamicsmodelusesΞ(X)=A X where
Ξ
 0 0 1 0 
0 0 0 1
A = ,
Ξ  0 0 0 0 
0 0 0 0
whichisaverysimplematrixsimplyimplyingthattherateofchangeofX = xisgivenbythe
1
currentstatevectorX =x˙,andsimilarlyfory.
3
Havingdefinedthedynamics,inthismodel,onlythepositionsareobserved. Inotherwords,the
observationsg(X)=[I ,0 ]X,i.e. C =[I ,0 ]andD =0.
2 2×2 Ξ 2 2×2 Ξ
NotethatthisexperimentalsettingsatisfiesPropositionA.5asthexandydynamicsareindependent.
Hence,itissufficienttocheckifthesystemisobservable. HereC =[1,0]andA=[0,1;0,0],so
theobservabilitymatrixforeachofthesesubsystemsbecomes
(cid:20) (cid:21) (cid:20) (cid:21)
C 1 0
= ,
CA 0 1
whichistheidentityandthusfullrank. Byobservabilitytheory,thesystemisclassicallyobservable,
andbytheresultsabove,ensembleobservableaswell.
Note that ensemble observability can be extended to non-zero Ψ in this setting. For instance, in
the“constantvelocity”modelofthemaintext,∇Ψ=[0;ψ]forconstantbutunknownψwillserve
simplyasadrifttermonthemeanofthehiddenvelocitystate. Sincewithoutthisdriftthemeanof
thevelocityisconstant,thisdriftwillbeidentifiableandthesystemwillbeensembleobservable.
Finally,asabriefremark,notethatinDefinition1,werequireΨtoberestrictedtoaclassoffunctions
C asotherwisetheSDE(1)mayfailtosatisfyclassicalobservability. FurtherexplorationofC
Ψ Ψ
classesislefttofuturework.
11E.g.,usingthefactthatdeconvolutionisequivalenttodivisionintheFourierdomain.
15B ProofsforConsistency
Wemakethissectionasself-containedaspossible,althoughwesuppresssomeofthelongerdetails
whentheyareverysimilartocertaincorrespondingresultsin[33]. Wheneverwedo,wepointtothe
fullerargumentsin[33]. Themainresultinthissectionisthefollowing:
TheoremB.1(Consistency,(formalversionofThm. 3.1)). LetPbethelawoftheSDEgivenin(1),
restatedbelow:
√
dX =−Ξ(t,X )dt−∇Ψ(t,X )dt+ τdB ,
t t t t
withinitialconditionP ∈P(X)suchthatH(P |vol)<+∞. Assumewehavethefollowing:
0 0
(i) g : X → Y is a smooth, measurable, bounded, time invariant function, and (g,Ξ,C ) is
Ψ
C -ensembleobservable.
Ψ
(ii) ForeveryT ≥1,wehaveasequenceoforderedobservationtimes{tT}T between0and1,
i i=1
and{tT}T becomesdensein[0,1]asT →+∞.
i i=1
(iii) ForeachT andeachi ∈ [T],wehaveNT ≥ 1randomvariables{YT}N iT ,whicharei.i.d.
i i,j j=1
anddistributedaccordingtog P .
♯ tT
i
(iv) The variables YT and YT′ are sampled independently from their respective distributions
i,j i′,j′
exceptwhen(T,i,j)=(T′,i′,j′).
Considerthefunctional(2),restatedbelow:
F(R):=Fitλ,σ(g R ,...,g R )+τH(R|WΞ,τ),
♯ tT ♯ tT
1 T
andletRT,λ,h ∈P(Ω)beitsuniqueminimizer:
RT,λ,h :=argminF(R).
R∈P(Ω)
Then,wehavetheweakconvergence
(cid:16) (cid:17)
lim lim RT,λ,h =P,
h→0,λ→0 T→∞
almostsurely.
Proof. WeuseTheoremB.5totakethelimitT →+∞. Bythelawoflargenumbersandtheweak
convergenceassumption,wehaveρ =Φ (P ),almostsurely. DefineRλ,htobethelimitofRT,λ,h
t h t
asT →+∞. ByTheoremB.5,itistheuniqueminimizerof
1 (cid:90) 1
R(cid:55)→F (R):= DF(R ,Φ P )dt+τH(R|WΞ,τ).
λ,h λ t h t
0
Bydefinitionofthedata-fittingterm,thefunctionalG inTheoremB.17differsfromF onlyby
λ,h λ,h
aconstant. Weseethat
(cid:90) 1
G (R)=F (R)− H(Φ P )dt−C,
λ,h λ,h h t
0
soRλ,hmustalsobetheuniqueminimizerforG . Finally,weuseTheoremB.17totakethelimit
λ,h
ofRλ,hash→0andλ→0. Thisconcludestheproof.
B.1 VariationalcharacterizationoftheSDE
We recall some previously introduced preliminaries and notation. Ω = C([0,1] : X) is the set
of X-valued paths, {X } is our canonical process, and F is the Borel σ-algebra generated
t t∈[0,1]
by the random variables X for s ≤ t such that {F } is a filtration. We use the notation
s t t∈[0,1]
|·|2 = ⟨·,·⟩ ∈ R for the quadratic variation of a process (similarly use this notation for cross-
variation).
FortheGirsanovtransformstobemartingales,wehavethefollowingmildtechnicalassumption.
16AssumptionB.2(NovikovconditionsonΞ). AssumethatthefollowingNovikovconditionshold:
(cid:20) (cid:18) 1(cid:90) 1 (cid:19)(cid:21)
E exp |Ξ|2ds <+∞
2
0
and
(cid:20) (cid:18) 1(cid:90) 1 (cid:19)(cid:21)
E exp |Ξ+∇Ψ|2ds <+∞.
2
0
Also,assumethatthereexistsC <+∞suchthat(cid:82)1 |Ξ|2ds≤C and(cid:82)1 |Ξ+∇Ψ|2ds≤C.
0 0
ThislastconditionissothatwecanapplyGirsanov’sonmanifolds,e.g. [24,Thm. 8.1.2].
Proposition B.3 (analogous to [33, Prop. 2.11]). Let P be the law of the SDE in (1). Then the
Radon-NikodymderivativeofPwithrespecttoWΞ,τ isgivenWΞ,τ-a.e. by
(cid:18) (cid:19)
dP dP Ψ(0,X )−Ψ(1,X )
(X)= 0(X )exp 0 1
dWΞ,τ dvol 0 τ
(12)
(cid:18)
1
(cid:18)(cid:90) 1(cid:18)
1 τ
(cid:19) (cid:19)(cid:19)
·exp ∂ Ψ− |∇Ψ|2−⟨Ξ,∇Ψ⟩+ ∆Ψ (s,X )ds .
τ s 2 2 s
0
Toprovethisproposition,wedonotuseamartingalecharacterizationasin[33],butdirectlyusethe
Girsanovtheorem(whichbyourassumptiononΞ,canbeappliedonmanifolds)andtheItôformula.
Proof. Bythechainrule,wehave
dP dP dP dWτ
(X)= 0(X )· · .
dWΞ,τ dvol 0 dWτ dWΞ,τ
Thefirsttermfollowsfromanaveragingargumentidenticaltothatof[33,Prop. 2.11]. Forthesecond
√
term,recallthatPisthemeasureinducedbytheprocessdX =−(Ξ+∇Ψ)dt+ τdB andWτ
√ t t
isthemeasureinducedbytheprocessdY = τdB . Wehave
t t
dP (cid:18) 1 (cid:90) t 1 (cid:90) t (cid:19)
=exp √ (Ξ+∇Ψ)(s,X )dB − |Ξ+∇Ψ|2(s,X )ds
dWτ τ s s 2τ s
0 0
(cid:18) 1 (cid:90) t 1 (cid:90) t (cid:19)
=exp √ ∇Ψ(s,X )dB − |∇Ψ|2(s,X )ds
τ s s 2τ s
0 0
(cid:18) 1 (cid:90) t 1 (cid:90) t (cid:19)
·exp √ Ξ(s,X )dB − (|Ξ|2+2⟨Ξ,∇Ψ⟩)(s,X )ds
τ s s 2τ s
0 0
(cid:18) 1 (cid:18) (cid:90) t(cid:18) 1 τ (cid:19) (cid:19)(cid:19)
=exp Ψ(0,X )−Ψ(1,X )+ ∂ Ψ− |∇Ψ|2+ ∆Ψ (s,X )ds
τ 0 1 s 2 2 s
0
(cid:18) 1 (cid:90) t 1 (cid:90) t (cid:19)
·exp √ Ξ(s,X )dB − (|Ξ|2+2⟨Ξ,∇Ψ⟩)(s,X )ds
τ s s 2τ s
0 0
(cid:18) 1 (cid:18) √ (cid:90) t (cid:19)(cid:19)
=exp Ψ(0,X )−Ψ(1,X )+ τ Ξ(s,X )dB ,
τ 0 1 s s
0 (13)
(cid:18) 1 (cid:90) t(cid:18) 1 τ (cid:19) (cid:19)
·exp ∂ Ψ− |Ξ+∇Ψ|2+ ∆Ψ (s,X )ds
τ s 2 2 s
0
wherethefirstlinefollowsfromtheGirsanovtheorem,[41,Thm. 8.6.6]andthethirdlinefollows
fromItô’sformula,[41,Thm. 4.2.1]. LettingWΞ,τ bethemeasureinducedbytheprocessdZ =
√ t
−Ξ(t,Z )dt+ τdB ,wehave
t t
dWτ (cid:18) 1 (cid:90) t 1 (cid:90) t (cid:19)
=exp |Ξ|2ds− √ ΞdB (14)
dWΞ,τ 2τ τ s
0 0
byGirsanov. Combining(13)and(14)yields(12). Theclaimfollows.
ThenextresultisthevariationalcharacteristicoftheSDE.
17TheoremB.4(analogousto[33,Thm. 2.1]). Suppose(g,Ξ,C )isC -ensembleobservable. Let
Ψ Ψ
Ξ:[0,1]×X →X beasmoothfunctionandΨ:[0,1]×X →Rbeasmoothpotential. LetPbe
thelawoftheSDE
√
dX =−Ξ(t,X )dt−∇Ψ(t,X )dt+ τdB
t t t t
with initial condition P ∈ P(X) such that H(P |vol) < +∞. If R ∈ P(Ω) is such that
0 0
g R =g P forallt∈[0,1],wehave
♯ t ♯ t
H(P|WΞ,τ)≤H(R|WΞ,τ)
withequalityifandonlyifP=R.
Theargumentfollowsthatof[33]withourensembleobservableassumptionandreferencemeasure.
Here,theproofisthesame,butnowweusethefactthatourreferencemeasure“cancelsout”the
stochasticintegral,e.g. seePropositionB.3.
Proof. LetPbethelawofthesolutionof(1)andsupposeR∈P(Ω)isanotherpathmeasuresuch
thatH(R|WΞ,τ)<+∞. Letp,r ∈L1(Ω,WΞ,τ)denotetheRadon-NikodymderivativeofP,R
withrespecttoWΞ,τ,respectively. Bystrictconvexityofx(cid:55)→xlogx,wehave
rlogr−plogp≥(1+logp)(r−p),
WΞ,τ-almosteverywhere,withequalityifandonlyifr =p. IntegratingwithrespecttoWΞ,τ,we
see
H(R|WΞ,τ)−H(P|WΞ,τ)≥E [1+logp]−E [1+logp]. (15)
R P
UsingPropositionB.3,wehave
(cid:20) (cid:18) (cid:19)
dP Ψ(0,X )−Ψ(1,X )
E [1+logp]=E 1+log 0 (X )+ 0 1
R R dvol 0 τ
1 (cid:90) 1(cid:18) 1 τ (cid:19) (cid:21)
+ ∂ Ψ− |∇Ψ|2−⟨Ξ,∇Ψ⟩+ ∆Ψ (s,X )ds .
τ s 2 2 s
0
By definition of ensemble observability, if g R = g P for all t ∈ [0,1], this implies R = P
♯ t ♯ t t t
for all t ∈ [0,1]. Because this expression only depends on the temporal marginals of R as the
Radon-NikodymderivativeofPwithrespecttoWΞ,τ doesnotcontainastochasticintegral,the
right-handsideof(15)vanishesifg R =g P forallt∈[0,1]. Thisconcludestheproof.
♯ t ♯ t
B.2 Themaintechnicalresult: TheoremB.5
TheoremB.5(analogousto[33,Thm. 2.7]). Fixλ>0andassumewehavethefollowing:
(i) ForeveryT ∈N,wehaveasequenceoforderedobservationtimes{tT}T ;asequenceofdata
i i=1
smoothedbytheheat-kernelρˆT (acollectionofT probabilitymeasuresonY);andasequence
i
ofnon-negativeweights{ωT}T .
i i=1
(ii) There exists a P(Y)-valued continuous curve ρ ∈ C([0,1] : P(Y)) such that the following
weakconvergenceholds: forallcontinuousfunctionsa:[0,1]×Y →R,
T (cid:90) (cid:90) 1(cid:90)
(cid:88)
lim ωT a(tT,x)ρˆT(dx)= a(t,x)ρ(dx)dt.
i i i
T→+∞ i=1 X 0 X
ForeachT,letRT ∈P(Ω)betheuniqueminimizerof
T
1 (cid:88)
R(cid:55)→F (R):=τH(R|WΞ,τ)+ ωTDF(g R ,ρˆT). (16)
T λ i ♯ tT i i
i=1
ThenasT →+∞,thesequence{RT}convergesweaklyonP(Ω)totheuniqueminimizerof
1 (cid:90) 1
R(cid:55)→F(R):=τH(R|WΞ,τ)+ DF(g R ,ρ ).
λ ♯ t t
0
18Beforeprovingthistheorem,westatethefollowingresultthatisimmediatefromthenon-negativity
ofourdata-fittingterm.
Fact B.6(Non-negativity). Withtheassumptions ofTheoremB.5, the functionalsF and F are
T
boundedfrombelowby0.
ProofofTheoremB.5. Theargumentfollowsthatof[33]. LetRbeaminimizerofF andRT be
theminimizerofF . Byoptimalityoftheminimizers,wehaveG R=RandG RT =RT. Using
T 0 0
PropositionB.15,wecanfindasequenceR˜T thatconvergesweaklytoRasT →+∞suchthat
F(R)≥limsupF (R˜T)≥limsupminF =limsupF (RT).
T T T
T→+∞ T→+∞ P(Ω) T→+∞
Inparticular,thesequenceisbounded,whichbyFactB.6,impliesthesequenceH(RT|WΞ,τ)is
bounded. Thenfromthecompactnessofthesublevelsetsoftheentropy,wehavealimitpointR(cid:98) of
thesequence{RT}. UsingtheoptimalityofRandPropositionB.16,wesee
F(R)≤F(G 0R(cid:98))≤liminfF T(RT).
T→+∞
Thus,wehaveequalitieseverywhere,so
F(R)=limsupF (R˜T)= lim F (RT).
T T
T→+∞ T→+∞
Thenwesee
F (R˜)−F (RT)=F (R˜T)−minF
T T T T
P(Ω)
convergesto0asT →+∞. By[33,Lem. B.3],relativeentropyis1-convexwithrespecttothetotal
variation,i.e. ifp,q,rarethreeprobabilitymeasures,
(cid:32) (cid:12) (cid:33)
p+q(cid:12) 1 1 1
H (cid:12)r ≤ H(p|r)+ H(q|r)− ∥p−q∥2 .
2 (cid:12) 2 2 2 TV
(cid:12)
Sincethedata-fittingtermisalsoconvex,thefullobjectiveF (·)is1-convexwithrespecttothetotal
T
variation. Byaclassicstrongconvexityargument,sinceF (R˜)convergestotheminimumvalue
T
min F achievedatRT,∥R˜T −RT∥ mustalsoconvergeto0asT →+∞. RecallthatTV
P(Ω) T TV
convergenceisstrongerthanweakconvergence. Then,usingtheweakconvergenceofR˜T toR,we
seethatRT convergesweaklytoRasT →+∞. Thisconcludestheproof.
TheremainderofAppendixB.2isdedicatedtowardsprovingTheoremB.5.
B.2.1 Heatflowandregularizationofthemarginals
RecallthatweuseΦ todenotetheheatflowwithwidths. Weusetheheatflowtoregularizethe
s
marginals. First,wehavethefollowingresultshowingthatthedensityofΦ R iscontinuousjointly
s t
intandx.
PropositionB.7(analogousto[33,Prop. 2.12]). Lets>0. ThereexistsaconstantC depending
onlyonX andΞforwhichthefollowinghold:
(i) ForeachR ∈ P(Ω),itsheatflowregularizationΦ R hasdensityρ(s)(t,·)(withrespectto
s t
thevolumemeasure)thatsatisfiesforallt∈[0,1],x∈X,wehave
1
ρ(s)(t,x)≥ .
C
s
(ii) Forallt ,t ∈[0,1]andx ,x ∈X,wehave
1 2 1 2
(cid:18)√ (cid:113)
(cid:112)
(cid:19)
|ρ(s)(t ,x )−ρ(s)(t ,x )|≤C τ H(R|WΞ,τ)+C+Cτ |t −t |+d (x ,x ) .
1 1 2 2 1 2 X 1 2
Proof. The first estimate is directly from [33]. The second estimate follows from [33] and the
followingproposition.
19PropositionB.8(analogousto[33,Lem. 2.13]). ThereexistsaconstantC dependingonlyonX and
ΞsuchthatforeachR∈P(Ω),
E [d (X ,X )2]≤C(cid:0) H(R|WΞ,τ)+C+Cσ2(cid:1) σ2|t −t |.
R X t1 t2 1 2
Proof. Theargumentfollowsthatof[33]. Foranyη >0,usingthedualrepresentationofentropy
withthefunctionX (cid:55)→ηd (X ,X ),wehave
X t1 t2
ηE [d (X ,X )2]≤H(R|WΞ,τ)+logE [exp(ηd (X ,X )2].
R X t1 t2 WΞ,τ X t1 t2
Usinganupperboundontheheatkernelfrom[34,Cor. 3.1]andthat∥Ξ∥ <+∞,wehavethe
L∞
followingboundonthetransitionprobabilityforWΞ,τ:
p (x,y,t)≤
Ce∥Ξ∥2 L∞ exp(cid:18)
Cτt−
d X(x,y)2(cid:19)
.
τ (τt)d/2 Cτt
Thentheremainderoftheargumentoftheproofof[33,Prop. 2.13]yieldsthedesiredresult.
B.2.2 Heatflowandentropyonthespaceofpaths
Weintroduceanauxiliaryvariationalprobleminwhichallthetemporalmarginalsarefixed.
Definition3. Letρ∈C([0,1]:P(X))beaP(X)-valuedcontinuouscurvewithrespecttotheweak
topology. DefinetheproblemA (ρ)tobe
τ
A (ρ):= inf {τH(R|WΞ,τ)|∀t∈[0,1],g R =g ρ }.
τ ♯ t ♯ t
R∈P(Ω)
WeusetheconventionthatA (ρ)=+∞iftheaboveproblemhasnoadmissiblecompetitor.
τ
UsingadualrepresentationofA,wecanusePDEtheorytosolvethisproblem. First,wegivea
martingalecharacterizationofaclassofstochasticprocesses:
√
Proposition B.9. Suppose W˜ Ξ,τ is the law of the SDE dX = −Ξdt+ τdB with arbitrary
t t
initialdistribution. Letφ:[0,1]×X →Rbeasmoothfunction. Then,theprocesswhosevalueat
t∈[0,1]isgivenby
(cid:18) 1 (cid:18) (cid:90) t(cid:20) 1 τ (cid:21) (cid:19)(cid:19)
exp φ(t,X )−φ(0,X )− ∂ φ+ |∇φ|2−⟨Ξ,∇φ⟩+ ∆φ (s,X )ds (17)
τ t 0 s 2 2 s
0
isanF -martingaleunderW˜ Ξ,τ.
t
Proof. ByAssumptionB.2onΞ,theprocess
(cid:90) t(cid:104) τ (cid:105)
Mφ =φ(t,X )−φ(0,X )− ∂ φ−⟨Ξ,∇φ⟩+ ∆φ (s,X )ds (18)
t t 0 s 2 s
0
isanF -martingaleunderW˜ Ξ,τ by[41,Thm8.3.1]. Wecalculatethequadraticvariation⟨Mφ⟩
t t
similarto[25,Prop. 1.3.1]. First,wehave
φ(t,X )2 =φ(0,X )2+Mφ2 +
1(cid:90) t
[−⟨Ξ,∇φ2⟩+∆φ2](s,X )ds
t 0 t 2 s
0
=φ(0,X )2+Mφ2 +
1(cid:90) t
[−2φ⟨Ξ,∇φ⟩+∆φ2](s,X )ds.
0 t 2 s
0
UsingItô’sformula,wehave
(cid:90) t
φ(t,X )2 =φ(0,X )2+2 φ(s,X )dφ2(s,X )+⟨Mφ⟩
t 0 s s t
0
(cid:90) t (cid:90) t
=φ(0,X )2+2 φ(s,X )dMφ+ φ(s,X )[−⟨Ξ,∇φ⟩+∆φ](s,X )ds+⟨Mφ⟩ .
0 s s s s t
0 0
20Equatingtheboundedvariationparts,wesee
⟨Mφ⟩ =
1(cid:90) t
(cid:2) −2φ⟨Ξ,∇φ⟩+∆φ2+2φ⟨Ξ,∇φ⟩−φ∆φ(cid:3) (s,X )ds
t 2 s
0
=
1(cid:90) t
(cid:2) ∆φ2−φ∆φ(cid:3)
(s,X )ds
2 s
0
(cid:90) t
= |∇φ(s,X )|2ds.
s
0
Then,(17)istheexponentialmartingaleofMφ.
t
Here, recall that Assumption B.2 ensures that (18) is a martingale. Otherwise, it is only a local
martingaleandwewouldneedtochecktheL1convergenceofthestoppedprocesswithanincreasing
sequenceofstoppingtimesthatgoesto+∞. Thisisastandardargumentinstochasticcalculus,e.g.
see[41].
Nowwegivethedualrepresentationmentionedabove.
Proposition B.10 (analogous to [33, Prop. 2.15]). Let ρ ∈ C([0,1] : P(X)) be a P(X)-valued
continuouscurve. Wehave
A (ρ)=τH(ρ |vol)
τ 0
(cid:26) (cid:90) (cid:90) 1(cid:90) (cid:18) 1 τ (cid:19) (cid:27)
+sup − φ(0,x)ρ (dx)− ∂ φ+ |∇φ|2−⟨Ξ,∇φ⟩+ ∆φ ρ (dx)dt ,
0 t 2 2 t
φ X 0 X
wherethesupremumistakenoverallφ∈C2([0,1]×X)suchthatφ(1,·)=0.
Proof. Theargumentfollowsthatof[33]. Fromthedualityresultof[3,Prop. 2.3],wehave
(cid:26)(cid:90) 1(cid:90) (cid:90) (cid:20) (cid:18)(cid:90) 1 (cid:19) (cid:21)(cid:27)
A (ρ)=τH(ρ |vol)+τsup ψρ (dx)ds− logE exp ψdt ρ (dx) ,
τ 0 t WΞ,τ,x 0
ψ 0 X X 0
whereWΞ,τ,xisthemeasuresuchthatWΞ,τ =δ andthesupremumistakenoverψ ∈C([0,1]×X).
0 x
Here,thecharacterizationholdsbecausetheargumentin[3]onlyrequiresthereferencemeasureto
beuniformatallmarginals.
Let−ψ := 1(∂ φ+1|∇φ|2−⟨Ξ,∇φ⟩+τ∆φ)forsomesmoothφsatisfyingtheterminalcondition
τ t 2 2
φ(1,x)=0. ByPropositionB.9,wesee
(cid:20) (cid:18) φ(0,X ) (cid:90) t (cid:19)(cid:21)
E exp − 0 + ψ(t,X )dt =1.
WΞ,τ,x τ t
0
AsX =0underWΞ,τ,x,wehave
0
(cid:90) (cid:20) (cid:18)(cid:90) t (cid:19)(cid:21) (cid:90) (cid:104) (cid:105)
logE exp ψ(t,X )dt = logeτ−1φ(0,x) ρ (dx)
WΞ,τ,x t 0
X 0 X
1 (cid:90)
= φ(0,x)ρ (dx).
τ 0
X
Theremainingargumentof[33]followsthrough.
ThemainideaisthatthereisacontractionofA undertheheatflow,whichwecanthinkofasa
τ
space-timecounterpartofthecontractionofentropyundertheheatflow.
Proposition B.11 (analogous to [33, Prop. 2.16]). Let ρ ∈ C([0,1] : P(X)) be a P(X)-valued
continuouscurveandfors≥0,definethenewcurveρ(s) :t(cid:55)→Φ ρ . LetK bealowerboundon
s t
theRiccicurvatureofthemanifoldX. Then,foranys≥0,wehave
A (ρ(s))≤e−2KsA (ρ).
τ τ
21Proof. ConsiderthedualformulationinPropositionB.10. Ifφ:[0,1]×X →RisaC2 function
withboundaryconditionφ(1,·)=0,thenbytheself-adjointnesspropertyoftheheatsemigroup,we
have
(cid:90) (cid:90) 1(cid:90) (cid:18) 1 τ (cid:19)
φ(0,·)ρ(s)+ ∂ φ+ |∇φ|2−⟨Ξ,∇φ⟩+ ∆φ ρ(s)dt
0 t 2 2 t
X 0 X
(cid:90) (cid:90) 1(cid:90) (cid:18) 1 τ (cid:19)
= {Φ φ}(0,·)ρ + ∂ Φ φ+ Φ |∇φ|2−Φ ⟨Ξ,∇φ⟩+ ∆Φ φ ρ dt,
s 0 t s 2 s s 2 s t
X 0 X
where Φ ∂ φ = ∂ Φ φ by Schwarz’s theorem and Φ ∆φ = ∆Φ φ by simple calculation. By
s t t s s s
propertiesofthecarréduchampoperator[5,Cor. 3.3.19]andexpandingouttheinnerproduct,we
seethat⟨Φ Ξ,∇Φ φ⟩ ≤ e−2KsΦ ⟨Ξ,∇φ⟩. Thus, lettingφ˜ = e2KsΦ φandΞ˜ = e2KsΦ Ξ, we
s s s s s
have
(cid:90) (cid:90) 1(cid:90) (cid:18) 1 τ (cid:19)
− φ(0,·)ρ(s)− ∂ φ+ |∇φ|2−⟨Ξ,∇φ⟩+ ∆φ ρ(s)dt
0 t 2 2 t
X 0 X
(cid:20)(cid:90) (cid:90) 1(cid:90) (cid:18) 1 τ (cid:19) (cid:21)
≤−e−2Ks φ˜(0,·)ρ − ∂ φ˜+ |∇φ˜|2−⟨Ξ˜,∇φ˜⟩+ ∆φ˜ ρ dt
0 t 2 2 t
X 0 X
≤e−2Ks[A (ρ)−τH(ρ |vol)],
τ 0
wherethelastinequalityisduetoPropositionB.10. Takingasupremumoverφ,weseethat
A (ρ(s))≤e−2KsA (ρ)+τ(cid:2) H(Φ ρ |vol)−e−2KsH(ρ |vol)(cid:3) .
τ τ s 0 0
By [33, Eq. B.3], the second term in the right-hand side is always non-positive, so the claim
follows.
Next,wedefinetheregularizingoperatorG thatactsattheleveloflawsonthespaceofpaths.
s
Definition4. ForeachR∈P(Ω)withH(R|WΞ,τ)<+∞andforeachs≥0,define
G (R):=argmin{H(R˜|WΞ,τ)|∀t∈[0,1],g R˜ =g Φ R }.
s ♯ t ♯ s t
R˜∈P(Ω)
Thatis,amongallprobabilitydistributionsonthespaceofpathswhosemarginalsinhiddenspace
coincidewitht(cid:55)→g Φ R ,themeasureG (R)∈P(Ω)istheonewiththesmallestentropy.
♯ s t s
Note that G (R) is well-defined because thanks to Proposition B.11, A ((Φ R ) ) ≤
s τ s t t
e−2KsA ((R ) ) ≤ e−2KsH(R|WΞ,τ) < +∞, so the minimization problem has admissible
τ t t
solutions. Since sublevel sets of entropy are compact, there exists a minimizer, and from strict
convexityoftheentropyfunctional,itisunique. Nownotethat
A ((Φ (R ) )=H(G (R|WΞ,τ)).
τ s t t s
Thisgivesusthefollowingresult.
PropositionB.12(analogousto[33,Prop. 2.18]). ForeachR∈P(Ω)suchthatH(R|WΞ,τ)<
+∞,wehavethefollowing:
(i) Foranys≥0,H(G (R)|WΞ,τ)≤e−2KsH(G (R)|WΞ,τ)≤e−2KsH(R|WΞ,τ).
s 0
(ii) G (R)convergestoG (R)weaklyass→0+.
s 0
Proof. The argument follows that of [33]. The first property is a rewriting of Proposition B.11
together with the definition of G and A . The second property follows from our observability
s τ
assumption and an analogous argument to that of the proof of [33, Prop. 2.18]. Consider the
followingsequentialcharacterization. Let{s n} n∈N beasequencewiths n → 0asn → +∞. By
thecontractionestimatein(i)andthattheRiccicurvatureisboundedfrombelow, weknowthat
H(G R|WΞ,τ)isuniformlyboundedinn. LetR˜ beanylimitpointofG R. Noticethatthislimit
sn sn
pointexistsduetothecompactnessofthesublevelsetsofH(·|WΞ,τ).
WeshowthatR˜ =G Rbyastandardanalyticargument. Weconsiderasubsequence(whichwedo
0
notrelabel)G RthatconvergestoR˜ asn→+∞. ThemarginalsofR˜ agreewiththoseofRas
sn
22weeasilyseethatthemarginalsofG Rarethe{Φ R } ,andΦ f →f inL1(X,vol)as
sn sn t t∈[0,1] sn
s →0. Then,usingthelowersemicontinuityofentropy,thedefinitionofG ,andthecontraction
n sn
estimateforA,wehave
H(R˜|WΞ,τ)≤liminfH(G R|WΞ,τ)
n→+∞
sn
=liminfA ((Φ R ) )|WΞ,τ)
n→+∞
τ sn t t
≤liminfe−2KsnA ((R ) )=A ((R ) ).
τ t t τ t t
n→+∞
ThisshowsthatR˜ =G R,whichconcludestheproof.
0
B.2.3 Thedata-fittingterm
Werecallthedefinitionofthedata-fittingtermhere:
(cid:90) (cid:20)(cid:90) (cid:18) ∥g(x)−y∥2(cid:19) (cid:21)
DFσ(g R ,ρˆT,h):= −log exp − dR (x) dρˆT,h(y)
♯ tT i i Y X 2σ2 tT i i
:=H(ρˆT,h|g R ∗N )+H(ρˆ )+C,
i ♯ tT σ tT
i i
where N is the Gaussian kernel. First, we have the following result, which is immediate from
σ
propertiesofentropy.
PropositionB.13. Thefunctionr (cid:55)→DF(r,p)isconvexandlowersemicontinuousonP(X).
Wewillrequireaquantitativecontrolontheeffectoftheheatflowonthedata-fittingterm.
PropositionB.14(analogousto[33, Prop. 2.22]). Assumeg : X → Y ismeasurepreserving.12
Letp,r ∈P(X). ThereexistsaconstantC >0dependingonlyonX,g,andσsuchthatforevery
s>0,
DF(g Φ r,g p)≤DF(g r,g p)+s·C.
♯ s ♯ ♯ ♯
Above,forsimplificationofthenotation,wepushforwardbothparametersofthedata-fittingtermby
g. Thismakestheargumentbelowmuchcleaner.
Proof. Theargumentfollowsthatof[33],butitismuchsimplerduetoourdifferentdata-fittingterm.
Inparticular,wedonotneedaboundontheFisherinformation. Byanabuseofnotation,denote
r ∈ L1(X,vol)thedensityofr withrespecttovol. Denoter(s,·)tobethedensityofΦ r with
s
respecttor. Itsatisfiestheheatequation
∂r
=∆r.
∂s
Then,wehave
d d (cid:90) (cid:20)(cid:90) (cid:18) ∥g(x)−g(y)∥2(cid:19) (cid:21)
DF(g Φ r,g p)= −log exp − r(s,x)vol(dx) p(y)vol(dy)
ds ♯ s ♯ ds 2σ2
Y X
(cid:90) (cid:20)(cid:90) (cid:18) ∥g(x)−g(y)∥2(cid:19) ∂ (cid:21)
=− log exp − r(s,x)vol(dx) p(y)vol(dy)
2σ2 ∂s
Y
(cid:90) (cid:20)(cid:90) (cid:18) ∥g(x)−g(y)∥2(cid:19) (cid:21)
=− log exp − ∆r(s,x)vol(dx) p(y)vol(dy)
2σ2
Y X
(cid:90)
≤C p(y)vol(dy)≤C,
Y
where the inequality follows from properties of the Gaussian integral and the fact that
(cid:82)
∆r(s,x)vol(dx)=1. Integratingyieldsthedesiredresult.
12Supposethat(X,λ ),(Y,λ )aremeasurespaceswithLebesguemeasure.gismeasurepreservingiffor
X Y
everyBorelsetB ∈X,λ (A)=λ (g A).
X Y ♯
23B.2.4 Tworesultsonlimitsoffunctionals
WerequiretworesultsofthefunctionalF definedin(16). WeusethesefortheΓ-convergence
T
theoryrequiredintheproofofTheoremB.5.
PropositionB.15(analogousto[33,Prop. 2.24]). UsethenotationandassumptionsofTheorem
B.5. SupposeR∈P(Ω)withF(R)<+∞andG R=R. ThenthereexistsasequenceR˜T which
0
convergesweaklytoRasT →+∞and
limsupF (R˜T)≤F(R).
T
T→+∞
Proof. Theargumentfollowsthatof[33]. Lets>0. CombiningPropositionB.14forthedata-fitting
termandPropositionB.12fortherelativeentropyonthespaceofpaths,weseethat
1 (cid:90) 1
F(G (R)=τH(G R|WΞ,τ)+ DF(Φ R ,ρ )dt
s s λ s t t
0
1 (cid:90) 1
≤τe−2KsH(R|WΞ,τ)+ DF(R ,ρ )dt+s·C,
λ t t
0
sowehave
limsupF(G R)≤F(R).
s
s→0
Nowas−log[G R] isacontinuousfunctionoftandxbyPropositionB.7,wecanusetheweak
s t
convergenceofρˆT toρtowrite,fors>0,
(cid:88)T (cid:16) (cid:17) (cid:90) 1
lim ωTDF [G R] ,ρˆT = DF([G R] ,ρ )dt.
i s tT i s t t
T→+∞ i=1 i 0
This implies for all s > 0, we have lim F (G R) = F(G R), so it is sufficient to let
T→+∞ T s s
R˜ := G R for a sequence {s } that decays to 0 sufficiently slowly as T → +∞. This
sT T T≥1
concludestheproof.
PropositionB.16(analogousto[33,Prop. 2.25]). UsethenotationandassumptionsofTheorem
B.5. ForeachT ≥ 1,letR˜T ∈ P(Ω)andassumethatitconvergesweaklytosomeR ∈ P(Ω)as
T →∞. Then
F(G R)≤liminfF (R˜T).
0 T
T→+∞
Proof. Theargumentfollowsthatof[33]. Assumethatliminf F (R˜T)<+∞otherwisewe
T→+∞ T
aredone. Then,uptoasubsequence(thatwedonotrelabel),wehavesup H(R˜T|WΞ,τ)<+∞.
T
CombiningPropositionB.14forthedata-fittingtermandPropositionB.12fortherelativeentropyon
thespaceofpaths,wehave
T
F (G R˜T)=τH(G R˜T|WΞ,τ)+ 1 (cid:88) ωTDF(cid:16) g Φ R˜T ,ρˆT(cid:17)
T s s λ i ♯ s tT i i
i=1
1 (cid:16) (cid:17) sc
≤τe−2KsH(R˜T|WΞ,τ)+ DF R˜T ,ρˆT + .
λ tT i i λ
Nowwerewritetheaboveas
F (R˜T)≥F (G R˜T)−C(s),
T T s
where
sc
C(s)=τ|e−2Ks−1|supH(R˜T|WΞ,τ)+
λ
T
isupperboundedbyaquantityindependentofT andlim C(s)=0. Forthedata-fittingterm,
s→0+
definethesequenceoffunctionsaT(t,x)tobe
s
(cid:20)(cid:90) (cid:18) ∥g(z)−x∥2(cid:19) (cid:21)
aT(t,x):=−log exp − dΦ R˜T(z) ,
s 2σ2 s t
24whichisparametrizedbyT. Noticethatfromthedefinitionofthedata-fittingterm,wehave
T T (cid:90)
(cid:88) ωTDF(g Φ R˜T ,ρˆT)=(cid:88) ωT aT(tT,x)ρˆT(dx).
i ♯ s tT i i s i i
i=1 i i=1 X
Forafixeds>0,thefamilyoffunctionsaT(t,x)indexedbyT isuniformlyequicontinuousdueto
s
gbeingcontinuousandPropositionB.7. Thenthereexistsasubsequence(thatwedonotrelabel)that
convergesuniformlyon[0,1]×Y asT →∞tothefunction
(cid:20)(cid:90) (cid:18) ∥g(z)−x∥2(cid:19) (cid:21)
aT(t,x)=−log exp − dΦ R (z)
s 2σ2 s t
(cid:20)(cid:90) (cid:18) ∥g(z)−x∥2(cid:19) (cid:21)
=−log exp − d[G R] (z) .
2σ2 s t
UsingthisuniformconvergencewiththeweakconvergenceofρˆT toρ ,wesee
i t
(cid:88)T (cid:16) (cid:17) (cid:88)T (cid:90)
lim ωTDF Φ RT ,ρˆT = lim ωT aT(tT,x)ρˆT(dx)
i s tT i i s i i
T→+∞ i=1 i T→+∞ i=1 X
(cid:90) 1(cid:90)
= a (t,x)ρ (dx)dt
s t
0 X
(cid:90) 1
= DF(G R ,ρ )dt.
s t t
0
Using lower semi continuity of entropy, we have F(G R) ≤ liminf F (G R˜T). Thus, for
s T→∞ T s
eachs>0,wehave
liminfF (R˜T)≥F(G R)−C(s).
T s
T→+∞
Finally, we use Proposition B.12 to take s → 0+ using the lower semi continuity of F and the
convergenceofG RtoG Rwhens→0+.
s 0
B.3 Γ-convergence: takingh→0,λ→0
TheoremB.17(analogousto[33,Thm. 2.9]). LetP∈P(Ω)withH(P|WΞ,τ)<+∞. Foreach
λ>0andh>0,letRλ,hbetheminimizerofthefunctional
1 (cid:90) 1
R(cid:55)→G (R):=τH(R|WΞ,τ)+ H(Φ P |R ∗N )dt.
λ,h λ h t t σ
0
Then,ash→0,λ→0,themeasureRλ,hconvergestotheminimizerofR(cid:55)→H(R|WΞ,τ)among
allmeasuressuchthatg R =g P forallt∈[0,1]. Furthermore,ifPisthelawoftheSDEin(1),
♯ t ♯ t
thenRλ,hconvergestoP.
Proof. Theargumentfollowsthatof[33]. First, considerR := G P ∈ P(Ω)asacompetitorin
h
G . UsingthecontractionestimategivenbyPropositionB.12,wehave
λ,h
minG =G (Rλ,h)≤τH(G P|WΞ,τ)≤τe−KhH(G P|WΞ,τ).
λ,h λ,h h 0
P(Ω)
AsK >−∞andH(P|WΞ,τ)byassumption,weseethatG (Rλ,h)isuniformlyboundedinλ
λ,h
andh. Thus,H(Rλ,h|WΞ,τ)isuniformlyboundedaswell. Dueto[33,Prop. B.2],thisimpliesthat
thefamilyRλ,hbelongstoacompactsetintheweaktopology. LetR˜ beanylimitpointinthelimit
asλ→0,h→0. WeonlyneedtoshowthatR˜ =G P. Notethat
0
τH(Rλ,h|WΞ,τ)≤G (Rλ,h)≤τe2KhH(G P|WΞ,τ).
λ,h 0
Bytakingh→0andusingthelowersemicontinuityofentropy,wesee
H(R˜|WΞ,τ)≤H(G P|WΞ,τ).
0
25NowusingFatou’slemma,thechainruleforrelativeentropy,andjointlowersemicontinuityofthe
entropy,wehave
(cid:90) 1 (cid:90) 1
H(P |R˜ ∗N )dt≤ liminf H(Φ P |Rλ,h∗N )dt
t t σ h t t σ
0 λ→0,h→0 0
(cid:90) 1
≤ liminf H(Φ P |Rλ,h)dt
h t t
λ→0,h→0 0
(cid:32) (cid:33)
≤ liminf λsupG (Rλ,h) =0.
λ,h
λ→0,h→0 λ,h
Thus, it follows that g R˜ = g P for almost every t. Therefore, by definition of G , we have
♯ t ♯ t 0
R˜ =G P. Thisconcludestheproof.
0
C ReducedFormulation
C.1 ProofofTheorem3.2
WeusethefollowingresulttoproveTheorem3.2. Here,thestatementisidenticaltothatof[14],but
weconsideradifferentreferencemeasure.
Lemma C.1 (analogous to [14, Prop. B.2]). There exists a constant C > 0 such that, for any
R∈P(Ω)andtT,...,tT acollectionoftimeinstants,itholds
1 T
(†)
H(R|WΞ,τ) ≥ H(R |WΞ,τ )
tT 1,...,tT
T
tT 1,...,tT
T
T−1 T−1
(∗) (cid:88) (cid:88)
≥ H(R |pΞ(R ⊗R ))− H(R |WΞ,τ)+C.
tT i,tT
i+1
τi tT
i
tT
i+1
tT
i
tT
i
i=1 i=1
Thefirstinequality(†)becomesanequalityifandonlyif
(cid:90)
R(·)= WΞ,τ(·|x ,...,x )dR (x ,...,x ),
1 T tT,...,tT 1 T
XT 1 T
whereWΞ,τ(·|x ,...,x )isthelawofWΞ,τ conditionedonpassingthroughx ,...,x attimes
1 T 1 T
tT,...,tT,respectively. Inaddition,thesecondinequality(∗)becomesanequalityifandonlyifR
1 T
isMarkovian.
Proof. UsingthefactthatΞisdivergence-freeandthatWΞ,τ hastheMarkovproperty,theproof
from[14]holds. Weprovidethefullproofforcompleteness. Thefirstinequality(†)andtheequality
casefollowsfromthebehaviorofentropywithrespecttoaMarkovmeasureunderconditioning,e.g.
[35,Eq. 11]. Inparticular,wehave
H(R|WΞ,τ)=H(R |WΞ,τ )
tT 1,...,tT
T
tT 1,...,tT
T
(cid:90)
+ H(cid:0) R(·|x ,...,x )|WΞ,τ(·|x ,...,x )(cid:1) dR (x ,...,x ),
1 T 1 T tT,...,tT 1 T
1 T
wherethesecondtermvanishesifandonlyiftheconditionaldistributionsR(·|x ,...,x )follow
1 T
thelawofWΞ,forR almostevery(x ,...,x ). Thesecondinequality(∗)followsfrom[7,
tT,...,tT 1 T
1 T
Lem. 3.4],whichstates
T−1 T−1
(cid:88) (cid:88)
H(R |WΞ,τ )≥ H(R |WΞ,τ )− H(R |WΞ,τ)=:E,
tT 1,...,tT
T
tT 1,...,tT
T
tT i,tT
i+1
tT i,tT
i+1
tT
i
tT
i
i=1 i=2
withequalityifandonlyifR isMarkovian. Asin[14],wereorganizethetermsinE.
tT,...,tT
1 T
Withoutlossofgenerality,assumethatR areabsolutelycontinuouswithdensitydR (x)/dx:=
tT tT
i i
r (x)andletV betheLebesguevolumeofX. SinceWΞ,τ istheuniformmeasureonX forevery
i X tT
i
tT,wehave
i
H(R |WΞ,τ)=H(R )+logV .
tT
i
tT
i
tT
i
X
26Lettingτ :=τ(tT −tT),wealsohave
i i+1 i
1
WΞ,τ (dx,dy)= pΞ(x,y)dxdy.
tT i,tT
i+1
V
X
τi
Thus,weseethatforanyµ,ν ∈P(X)withfinitedifferentialentropyandγ ∈Π(µ,ν),wehave
(cid:90) (cid:18) dγ V (cid:19)
H(γ|WΞ,τ )= log X dγ(x,y)
tT,tT dx⊗dy pΞ
i i+1 τi
(cid:90) (cid:18) dγ dµdν(cid:19)
=logV + log dγ
X pΞd(µ⊗ν)dxdy
τi
=logV +H(γ|pΞ(µ⊗ν))+H(µ)+H(ν),
X τi
wherethelastlinefollowsfrom[37,Lem. 1.6]. NowusingthefactthatR ∈Π(R ,R ),
tT,tT tT tT
i i+1 i i+1
wehave
T T−1
(cid:88) (cid:88)
E =logV + H(R |pΞ(R ⊗R ))+ H(R ),
X tT i,tT
i+1
τi tT
i
tT
i+1
tT
i
i=1 i=1
whichprovestheformula.
TheoremC.2(Thm. 3.2,restated). LetFit:P(Y)T →RbeanyfunctionandletΞbeboundedand
divergence-free.
(i) IfF admitsaminimizerR∗then(R∗ ,...,R∗ )isaminimizerforF.
tT tT
1 T
(ii) IfF admitsaminimizerµ∗ ∈P(X)T,thenaminimizerR∗forF isbuiltas
(cid:90)
R∗(·)= WΞ,τ(·|x ,...,x )dR (x ,...,x ),
1 T tT,...,tT 1 T
XT 1 T
whereWΞ,τ(·|x ,...,x )isthelawofWΞ,τ conditionedonpassingthroughx ,...,x at
1 T 1 T
timestT,...,tT,respectivelyandR isthecompositionoftheoptimaltransportplans
1 T tT,...,tT
1 T
γ thatminimizeT (µ∗(i),µ∗(i+1)),fori∈[T −1].
i τi,Ξ
Proof. Theprooffrom[14]holdsusingourtransitionprobabilitydensitiesandOTplans. Weprovide
it for completeness. First, note that a minimizer R∗ ∈ P(Ω) of F(R) = Fit(Q ,...,Q )+
tT tT
1 T
τH(R|WΞ,τ)isoftheforminLemmaC.1. Letµ(i) :=R∗ beitsmarginalsandγ(i) :=R∗ ,
tT tT,tT
i i i+1
whichclearlysatisfiesγ(i) ∈Π(µ(i),µ(i+1)). UsingC :=logV ,weseethat
X
T−1
(cid:88)
F(R∗)=Fit(g µ(1),...,g µ(T))+τ H(γ(i)|pΞ(µ(i)⊗µ(i+1)))+τH(µ)+C
♯ ♯ τi
i=1
T−1
τ (cid:88)
≥Fit(g µ(1),...,g µ(T))+ T (µ(i),µ(i+1))+τH(µ)+C,
♯ ♯ τ τi,Ξ
i
i=1
wheretheinequalitybecomesanequalityifandonlyifR∗ =γ(i)isoptimalinthedefinitionof
tT,tT
i i+1
T (µ(i),µ(i+1)). Theclaimfollows.
τi,Ξ
D Mean-FieldLangevinDynamics
RecallthattheMFLdynamicsisdefinedasthesolutionof(8),whichwerestatebelow:
(cid:40) dX(i) =−∇V(i)[µ ](X(i))ds+(cid:112) 2(τ +ϵ)dB(i)+dΦ(i), Law(X(i))=µ(i)
s s s s s 0 0
µ(i) =Law(X(i)), i∈[T],
s s
27wheredΦ(i)istheboundaryreflectioninthesenseoftheSkorokhodproblem. Thefamilyoflaws
s
{µ } ofthisstochasticprocessarecharacterizedbythefollowingsystemofPDEs:
s s≥0
∂ µ(i) =∇·(∇V(i)[µ ]µ(i))+(τ +ϵ)∆µ(i), (19)
s s s s s
which are coupled via the quantity ∇V(i)[µ ]. The link between (8) and (19) follows from the
s
Itô-Tanakaformula,seee.g. [27,Lem. C.3]. Thisisamulti-speciesPDEwhereeachofthespecies
µ(i) attempts to minimize ∆tiFitλ,σ(·,ρˆT)+(τ +ϵ)H via a drift-diffusion dynamics, and it is
λ i
connectedtoµ(i−1)andµ(i+1)viaSchrödingerbridges.
D.1 PropertiesofGandF
WedescribesomepropertiesoffunctionsG(4)andF (5).
Recallthatthefirst-variationofG : P(X)T → Ratµistheunique(uptoanadditiveconstant)
functionV[µ]∈C(X)T suchthatforallν ∈P(X)T,
T
1 (cid:88)
lim [G(1−ϵ)µ+ϵν)−G(µ)]= V(i)[µ](x)d(ν−µ)(i)(x).
ϵ→0 ϵ
i=1
PropositionD.1(analogousto[14,Prop. 3.2]). ThefunctionGisconvexseparatelyineachofits
inputs(butnotjointly),weaklycontinuousanditsfirst-variationisgivenforµ∈P(X)T andi∈[T]
by
δFit φ ψ
V(i)[µ]= [µ]+ i,i+1 + i,i−1 ,
δµ(i) tT −tT tT −tT
i+1 i i i−1
and
δFit ∆t (cid:90) N (g(x)−y)
[µ]:x(cid:55)→− i σ dρˆ(y),
δµ(i) λ (N ∗g µ(i))(y)
σ ♯
where(φ ,ψ )∈C∞(X)aretheSchrödingerpotentialsforT (µ(i),µ(j)),withtheconvention
i,j i,j τi,Ξ
that thecorrespondingterm vanisheswhen it involves ψ or φ . The function F is jointly
1,0 T,T+1
convexandadmitsauniqueminimizerµ∗,whichhasanabsolutelycontinuousdensity(againdenoted
byµ∗)characterizedby
(µ∗)(i) ∝e−V(i)[µ∗]/τ, fori∈[T].
Here, theSchrödingerpotentialsareclassicallyL1 bystandard(entropic)OTtheory, butwecan
extendthemtoC∞functions,asdiscussedin[14].
Proof. Theargumentissimilartothatof[14]. ThepropertiesofGanditsfirst-variationareclear.
Inparticular,thefirst-variationofT followsfromthefactthatgissmoothand[45,Prop. 7.17],
τi,Ξ
and the first-variation of Fit follows by direct calculation. The convexity of G follows from the
convexityofT andthefactthatthepushforwardofgislinear. ThejointconvexityofF,itsunique
τi,Ξ
minimizer,andthecharacterizationoftheminimizerfollowdirectlyfromtheargumentintheproof
of[14,Prop. 3.2].
D.2 Noisyparticlegradientdescent
Let m ∈ N be the number of particles used in the discretization for each of the time marginals
µ(i). Forcomputation,weapproximatetheMFLdynamicsbyrunningnoisygradientdescentonthe
functionG :(Xm)T →RdefinedasG (Xˆ):=G(µˆ ),where
m m Xˆ
m
µˆ(i) := 1 (cid:88) δ .
Xˆ m Xˆ(i)
j
j=1
From [13, Prop. 2.4], we see that m∇ G (Xˆ) = ∇V(i)[µˆ ](Xˆ(i)). Thus, this yields the
X(i) m Xˆ j
j
discretizationof(8):
(cid:40) Xˆ(i)[k+1]=Xˆ(i)[k]−η∇V(i)[µˆ[k]](Xˆ(i)[k])+(cid:112) 2η(τ +ϵ)Z(i), Xˆ(i)[0]i. ∼i.d. µ(i)
j j j j,k j 0 (20)
µˆ(i)[k]= 1 (cid:80)m δ , i∈[T],
m j=1 Xˆ(i)[k]
j
28whereη >0isastep-size,theZ(i) arei.i.d. standardGaussianvariables,andalltheparticlesshould
j,k
beprojectedontoX ateachstepifX hasboundaries. TheMFLdynamicsarerecoveredinthelimit
asm→∞andη →0,e.g. see[50,39,13].
D.3 Exponentialconvergence
Theorem D.2 (Thm. 3.4, restated). Assume X is the d-torus. Let µ ∈ P(X)T be such that
0
F(µ )<+∞. Thenforϵ≥0,thereexistsauniquesolution(µ ) totheMFLdynamics(8). Let
0 s s≥0
ϵ>0andassumethatµ hasaboundedabsolutelog-density,itholds
0
F (µ )−minF ≤e−Cs(F (µ )−minF ),
ϵ s ϵ ϵ 0 ϵ
whereC =βe−α/ϵ forsomeα,β >0independentlyofµandϵ. Moreover,takingasmoothtime-
dependentϵ thatdecaysasymptoticallyasα˜/logsforsomeα˜ >α,itholdsF (µ )−F (µ∗)≲
s 0 s 0
loglogs/logs→0andµ convergesweaklytothemin-entropyestimatorµ∗.
s
Proof. As in [14], we simply need to verify the assumptions in [13, Thm. 3.2]. Recall that the
objectivefunctionisoftheformF =G+(τ+ϵ)H. Thestabilityandregularityofthefirst-variation
ϵ
V,[13,Assumption1],isimmediatefrom[14,Prop. C.2]andthatgisbounded. Theconvexityof
F andexistenceofaminimizerforF ,[13,Assumption2],followsfromPropositionD.1.
0 ϵ
Fortheuniformlog-Sobolevinequality(LSI),[13,Assumption3],firstnotethattheithcomponentof
thefirst-variationofF isgivenbyV(i)[µ]+τlogµ(i). DefineD :=diamX andE :=diamg X,
0 ♯
whereD <+∞byassumptionandE <+∞asgisbounded. NotethatoscV(i)[µ]<+∞asthe
gradientformulaforδFit/δµ(i)isnon-negativeandisboundedbyEeE2/(2σ2)andby[14,App. A,
Eq. 17],theSchrödingerpotentialφ hasanoscillationboundedby
i,i+1
sup c (x,y)− inf c (x,y)≤D2/2.
tT,tT tT,tT
x,y∈X i i+1 x,y∈X i i+1
Following the argument in the proof of [13, Thm. 3.3], the probability measure proportional to
e−(V(i)[µ]+τlogµ(i))/ϵ satisfies a LSI with constant ρ ≥ αe−β/ϵ for some α,β independent of
s,ϵ,µ .
0
Then, [13, Thm. 3.2] guarantees the exponential convergence with rate e−Cs with C = 2ϵρ.
Furthermore,theconvergenceresultwithsimulatedannealingfollowsfrom[13,Thm. 4.1].
E AdditionalExperiments
E.1 Settingsforexperimentsinmaintext
“Constantvelocity”model Inthisexperiment,thediffusivityparameterissetatτ =0.05.Particles
areinitializedfromX ∼N(0,0.12·I)andsimulatedoverthetimeintervalt∈[0,5]withmarginals
0
sampledat5evenlyspacedintervals. BothPO-MFLandMFLareappliedusingm=100particles,
weobserve32particlesateachtimepoint,andweuseakernelwidthofσ =1.0forthedata-fitting
term. Theoptimizationprocedureisinitializedwithη =0.5andcontinuesfor2,000iterations. The
numberofSinkhorniterationsforentropicOTiscappedat500iterations.
Forthecrossingpathsexperiment,thediffusivityparameterissetatτ =0.0005,andthetimeinterval
is[0,2.25],andmarginalsaresampledat10evenlyspacedintervalsweusem=50particles.
Circular motion model In the circular motion experiment, the diffusivity parameter is set at
τ =0.0002. ParticlesareinitializedfromX ∼N(0,0.12·I)andsimulatedoverthetimeinterval
0
t ∈ [0,3.14]withmarginalssampledat15evenlyspacedintervals. BothPO-MFLandMFLare
appliedusingm = 100particles,weobserve32particlesateachtimepoint,andweuseakernel
widthofσ =1.0forthedata-fittingterm. Theoptimizationprocedureisinitializedwithη =0.5and
continuesfor4,000iterations. ThenumberofSinkhorniterationsforentropicOTiscappedat500
iterations.
Inthefollowingsections,ifaparameterisnotstated,weassumethesamesettingofparametersasin
themaintext.
29Figure6: Varyingvelocity. Weseethatasthegroundtruthinitialvelocityincreases,MFLbreaks
whilePO-MFLremainsrobust.
E.2 Varyingvelocity
ExperimentsvaryingthemeanofthegroundtruthinitialvelocitydistributionareshowninFigure6.
Attheendpoints,weobserve32particles,andintheintermediatestages,weobservejust2particles
pertimepoint. Notethatinthesmallvelocityregime,althoughMFLconverges,itconvergestothe
wrongdistribution.
E.3 Varyingnumberofobservedparticles
Figures7and8showresultswhenthenumberofobservedsamplesattheintermediatetimepoints
arevaried(thenumberofobservationsattheendpointsisheldconstantat32). Here,wetrythesame
settingsasabove,butnowweconsidervelocity(x˙,y˙)=(2,4). Wetrythenumberofobservations
1,2,4,8,16,32,128,256. Even in a large number of observation regime, the MFL algorithm is
notcapableofreconstructingthefulltrajectory,insteadclusteringaroundthecenteroftheoverall
trajectory.
30Figure7: Varyingnumberofobservationsattheintermediatetimes. Increasingnumberofobserva-
tionsimprovestheoptimization.
Figure8: Ahighobservationregimeattheintermediatetimepoints.
E.4 Varyingtemporalsamplingdensity∆t
InFigure9,weshowresultsforincreasingthedensityoftemporalsampling. Attheendpoints,we
observe32particles,andintheintermediatestages,weobserve2particles. MFLwassensitiveto
hyperparametervaluesasweneededtotrydifferentparameterstogetsemi-reasonableresultsforthe
figure. Weusedσ =0.1,m=25.
31Figure9: Varyingthenumberofobservedtimepointsforfixedtimewindow,i.e. varying∆t. Note
thatPO-MFLisalwaysrobust. MFLdoesbetterwithmoreobservations,butthemethodstilltendsto
collapseinwardsbecauseitsmodelsuggeststhat,inexpectation,particlesshouldnotbemoving(as
theBrownianmotionreferencemeasurehas0expectation).
32