Quantifying Local Model Validity using Active Learning
SvenLämmle1,2 CanBogoclu3 RobertVoßhall4 AnselmHaselhoff5 DirkRoos2
1CenterofExpertise,ZFFriedrichshafenAG,Friedrichshafen,Germany
2InstituteofModellingandHigh-PerformanceComputing,NiederrheinUniversityofAppliedSciences,Krefeld,Germany
3ZalandoSE,Berlin,Germany
4auxmoneyGmbH,Düsseldorf,Germany
5RuhrWestUniversityofAppliedSciences,Bottrop,Germany
Abstract
wanttoidentifyvalidsubdomainsoftheinputspacewhere
the absolute model erroris smallerthan somepredefined
tolerancelevel.Inthiscontext,evaluatingglobalaccuracy
Real-worldapplicationsofmachinelearningmod- metricssuchasmeansquarederrorisnotausefulapproach.
elsareoftensubjecttolegalorpolicy-basedregu- Evenifamodelachievesasmallaverageerrorglobally,it
lations.Someoftheseregulationsrequireensuring canexhibithighinaccuracyinspecificinputdomains.Simi-
thevalidityofthemodel,i.e.,theapproximationer- larly,evenmodelswithhighaverageerrormaybeusefulin
rorbeingsmallerthanathreshold.Aglobalmetric certainsubdomainsoftheinputspace.
isgenerallytooinsensitivetodeterminethevalidity
Thevalidityofapredictioncanbeassessedbycomparingit
ofaspecificprediction,whereasevaluatinglocal
toreal-worldobservationsor,insomecases,tosimulations
validityiscostlysinceitrequiresgatheringaddi-
withveryhighaccuracy.Theobtainedresultscanbeused
tionaldata.Weproposelearningthemodelerrorto
toapproximatetheerrorlevel[OberkampfandRoy,2010],
acquirealocalvalidityestimatewhilereducingthe
sometimesreferredtoaserrorlearning[Riedmaieretal., amount of required data through active learning.
2020].Incontrasttoboosting,wearenotinterestedinim-
Usingmodelvalidationbenchmarks,weprovide
provingthemodelpredictionsbytheadditionofthelearned
empiricalevidencethattheproposedmethodcan
error.Instead,wewanttohaveanestimateoftheerrorlevel
leadtoanerrormodelwithsufficientdiscrimina-
todecidethevalidityofaprediction.Apopularmodelfor
tivepropertiesusingarelativelysmallamountof
thistaskisGaussianprocessregression(GP)[Rasmussen
data. Furthermore, an increased sensitivity to lo-
andWilliams,2006,KennedyandO’Hagan,2001].Besides
cal changes of the validity bounds compared to
beingapowerfulmodel,itscapabilitytorepresenttheepis-
alternativeapproachesisdemonstrated.
temicuncertaintyisusefultoderiveconfidenceboundsfor
theestimatedlocalerror.
1 INTRODUCTION
If a large dataset is available for training, an additional
split can be afforded to build an error model to be used
Ensuringthevalidityofdeployedmachinelearning(ML)
formodelvalidation(MV).However,gatheringadditional
models is often a core concern in safety-critical domains
dataiscostlybutnecessaryinmanycasestobuildasuffi-
suchasmedical,vehicle,andindustrialapplications,witha cientlyaccuratevalidationmodel.Therefore,thedesignof
highriskofharminghumansandtheenvironment.These experiments(DoE),i.e.,theplanningoftestsordataqueries,
use cases are often subject to legal or regulatory require-
isoftencrucialasitdeterminestheoverallvalidationcost
ments, such as ISO26262 [2016] and IEC61508 [2010].
andthequalityofthevalidationstatement.Agoodstrategy
MostMLmodelsarebuiltusingonlypastobservationsor
shouldachieveahighlyaccuratevalidityestimatewhilebe-
examplesandmaylackfurtherdomain-specificinductive
ingdata-efficient,usingaslittleadditionaldataaspossible.
biases,suchasunderlyingphysics(althoughsomemodels
are capable of incorporating such, e.g., see [Karniadakis
etal.,2021]).Consequently,thebehaviorofthesemodels Activelearning[Settles,2010]hasshowntobeanefficient
in unseen scenarios is difficult to predict without further strategyforreducingthenumberofsamples,i.e.,thechoice
analysis. ofsamplesusedfortrainingamodel.Therefore,samples
orbatchesofsamplesareselectedsequentially,leveraging
Astrictassessmentofamodel’scapabilitiesisneededtode-
knowledgefrompreviousiterationstoguidethesampling
termineitsvalidityacrosstheinputspace.Specifically,we
Acceptedforthe40thConferenceonUncertaintyinArtificialIntelligence (UAI2024).
4202
nuJ
11
]LM.tats[
1v47470.6042:viXraa) Targetf ModelfM b)
c) Error |δ | |f˜ D|
d)
x S1 Xx S2 x S3 0 q8 δ0
| |
Toleranceξ Train InitialSample AdaptiveSample NextSample
Figure1:Illustrationofalocallyvalidmodel:thetrainedmodelf ismarginallyvalidfortolerancelevelξ with80%
M
probability(b)),butonlylocallyvalid ( )insomeregionsoftheinputspaceX(a)).b)Marginaldistributionofthetrue
absoluteerror δ ,wherethe80%quantV ilecorrespondstothetolerancelevel,i.e.,ξ =q .c)Ourlearnederrormodel f˜
80 D
and90%confi| de| nceinterval( )fromthefoldedGaussian(Section4.3),togetherwiththepredictedlocalvalidset ˜ | ( | )
0.1
V
(Section4.6).Samples( )aresequentiallyplacedbasedonψ (d))toreducethemisclassificationprobability(Section4.4),
mis
i.e.,mostsamplesareclosetothelimitstatex .
Si
∈S
process.Thisapproachhasbeenusedacrossvarioustasks, learningtwolimitstateconditions(δ(x) = ξ andδ(x) =
from optimization to querying new samples [Kumar and ξ),thusshowingtheconnectiontoRAproblems.Based
−
Gupta,2020]forimprovingmodelquality. onthisformulation,weproposeanactivelearningmethod
forMVinspiredbyitsRAcounterpartBichonetal.[2008].
Asanactivelearningmethod,Bayesianoptimization(BO)
We test our method on a variety of benchmark problems
[Snoeketal.,2012]isknowntoexploittheprobabilisticesti-
withinasmallsamplesettingandshowthatitcanbereliably
matestofindtheoptimumofablack-boxobjectivefunction
usedforthevalidationofamultitudeofMLmodels.
withhighdataefficiency.However,ourgoalistofindvalid
domains,i.e.,theset ofpointsxwheretheabsolutemodel
V Contributions. Ourmaincontributionsaresummarized
error δ(x) IR issmallerthansometoleranceξ IR .
+ >0
| |∈ ∈ asfollows:1)Weintroduceanewformulationofmodelvali-
In contrast, global adaptive sampling strategies [Lämmle
dation(MV)inspiredbyreliabilityanalysis(RA),extending
etal.,2023]aimtoimprovethemodelqualityovertheen-
the setting to two symmetrical limit state conditions and
tireinput space.Weare notinterested inhavingaccurate
noisyobservations.2)Weproposeanovelacquisitionfunc-
predictionswheretheerror δ(x) ismuchlargerorsmaller
| | tionbasedonthemisclassificationprobabilityofthelimit
thanξ.Instead,weareprimarilyinterestedinlearningthe
state(Section4.4).3)Wederivefrequentisterrorbounds
neighborhoodwhere δ(x) ξ.Inclassicalengineering,
| | ≈ fortheproposedmethodology(Section4.7).4)Weevaluate
reliabilityanalysis(RA)requiressolvingasimilarproblem
theproposedmethodonavarietyofdifferentbenchmarks
[RebbaandMahadevan,2008].
(Section 5, Appendix E), and provide a comparison with
Givenafunctiong(),RAdefinesfailuredomainsusingthe conformalprediction(AppendixD).
·
conditiong(x) 0.TheaimofRAistocomputethefailure
probabilityP
F≤
=
EX∼p(x)(cid:2)1 g(X)≤0(X)(cid:3)
,whereX are
theinputvariables.Therefore,anaccuraterepresentationof 2 RELATEDWORK
thelimitstateconditiong(x)=0isnecessary.Equivalently,
the problem of MV can be framed as learning two level
ReliabilityAnalysis. ThegoalofRAistocalculatethe
sets[Gotovosetal.,2013]atonce: = x: δ(x) ξ
V { ≤ }∩ failureprobabilityP F.SincethedistributionofX canbe
x: δ(x) ξ . Despite the similarity of the problems
{ ≥ − } arbitrary, RA often requires a large number of samples.
and the popularity of active learning in RA and level set
To increase sample efficiency, previous research has uti-
estimation,tothebestofourknowledge,asimilarapproach
lizedsurrogate-aidedmethodsbasedonMLmodelssuch
hasnotbeenproposedforMV.
as neural networks [Papadrakakis et al., 1996], ordinary
In this paper, we first formulate the problem of MV as [Bucher and Bourgund, 1990] and moving least squares
models[MostandBucher,2006],GPs[Kaymaz,2005],and
2
Y
simψ
p δ ||support vector machines [Rocco and Moreno, 2002]. Al- sets.Thelatterisusedtoderivethepredictionintervalsfor
thoughsomeactivelearningapproacheshavebeenalready thetrainedmodel.Here,weaimtolearnthemodelerror,
proposed[Mackeetal.,2000,MostandBucher,2006],Bi- especiallyaroundthelimitstate,toassessthelocalvalidity
chonetal.[2008]wasthefirsttointroduceactivelearning ofthemodel.
basedonGPmodelstothefieldofRA.
Amorerigorousconditionalcoverageisknowntobeim-
Following, several acquisition functions (AFs) similar to possibletoachievewithoutfurtherassumptionsaboutthe
Bayesianoptimizationmethodshavebeenproposedtolearn underlyingdistribution[Barberetal.,2021].Approximate
thelimitstate.Themostpopularonesbeingtheexpected conditionalcoveragehasbeenconsideredintheworkofLin
feasibilityfunction[Bichonetal.,2008]andtheU-function etal.[2021].Althoughtheyprovideamethodforapproxi-
[Echard et al., 2011, 2013]. For an extensive review, see mateconditionalcoverage,itoftenrequiresmorecalibration
[Teixeiraetal.,2021].Incontrast,activelearningintheML samplestoformmeaningfulpredictionintervals(seeAp-
contextaimstoachievehighaccuracygloballybyusingas pendixD).
fewsamples(labels)aspossible.Theapproachismorefre-
quentlyusedinthecontextofclassificationtaskscompared
3 BACKGROUND
toregression.See[Settles,2010]foranoverview.
LevelSets. SimilartoRA,thetaskoflevelsetestimation Let x X IRd be a vector of observable and control-
∈ ⊂
[Bryanetal.,2005,Gotovosetal.,2013]aimstoidentify lableinputs,withvalidationdomainXofdimensiond.Fur-
regions where the value of some target function is below thermore,foramodelrepresentedbyamapf M: X Y
→
oraboveagiventhreshold.Therefore,samplesareplaced between the inputs X and the quantity of interest (QOI)
according to an AF based on a GP model to reduce the Y IR,wewanttoassessthevalidityoff M,i.e.,estimate
⊂
uncertainty about the level set. In this context, MV can modelmisfit.
beseenaslearningtwojointlevelsetssimultaneously.A
moregeneralapproach,notrestrictedtolevelsetestimation, Observations. Anobservationconsistsofthetuple(x,y x)
was proposed by Neiswanger et al. [2021]. The entropy- wherey xisassumedtobeasamplefromtherandomvari-
basedmethodcanbeappliedtoarbitraryalgorithmicoutputs. able Y x = f E(x)+ϵ. In this context, f E: X Y is the
→
However,thecomputationalcostforevaluatingtheAFmay true data generating function and ϵ is the additive label
behigh,asaclosed-formisunavailable. noise.Here,wedonotassumetohaveanyknowledgeabout
f ,thereforewetreatitasablack-boxfunction.Moreover,
E
BayesianCalibration. Anotherlineofworkinitiatedby ϵ is assumed to be homoscedastic Gaussian white noise
KennedyandO’Hagan[2001]considerslearningthemodel ϵ
∼
N(0,σ e2),whereweuse ∼todenote“distributedas”
errortocorrecttheoutputofacomputationalmodelsimi- in this work. We assume that the input can be measured
lartoboostingtechniquesinML,whileinferringthefree precisely,suchthatanyuncertaintyaboutthetruevalueof
parametersofthecomputationalmodel.Therefore,thepos- xcanbeneglected.
terior distribution of the parameters and the model error
In general, a set of observations is used to train and pos-
areinferredjointly.Subsequentresearchincorporatesphysi-
siblycalibratethemodelf .Anothersetofobservations
M
calknowledgebyusingaphysics-informedprior[Spitieris
isusedtoestimatethegeneralizationerrorandtovalidate
andSteinsland,2023]andextendstheworktomultipleout-
f .Generatingnewobservationsisoftencostly,andonly
M
puts [Higdon et al., 2008, White and Mahadevan, 2023].
afinitenumberofobservationsareavailableinreal-world
Nevertheless,onemayorcriticismofthisworkistheiden-
applications.Therefore,dataefficiencyofbothtrainingand
tifiability issue, i.e., the effects of calibration parameters
validationiscrucial.
andmodeldiscrepancycanbeconfoundedduetotheover-
parameterizationofthemodel[Arendtetal.,2012,Marmin
ValidationMetric. MVcanbeperformedbyevaluating
andFilippone,2022].
themodelerrorwithinX,givenasf D(x):=f M(x) Y x,
−
withf (x) (f (x) f (x),σ2).Foragiventolerance
Conformal Prediction. For distribution-free predictive level ξD IR∼N , weM quan− tifE y the pre obability of the model
>0
inference,conformalpredictionbasedontheworkofVovk errorbe∈ ingwithinthedesiredtoleranceas
etal.[2005]isusedtoderivepredictionintervalswithfre-
quentistcoverageguarantees.However,mostworkfocuses P ( ξ <f (x)<ξ). (1)
D
−
onmarginalcoverage[Vovketal.,2005,Papadopoulosetal.,
2002, Lei et al., 2018], i.e., the model prediction is only Equation (1) is termed the reliability validation metric
marginallyvalidoverthetrainingdataandthetestpoints and was proposed for MV by Rebba and Mahadevan
withaspecifiedprobability.Inthiscontext,ourworkcanbe [2008],SankararamanandMahadevan[2013].Equivalently,
seenasrelatedtothesettingofsplit-conformalprediction, we will represent Equation (1) as P (g(x)>0) = 1
−
wherethedataispartitionedintotrainingandcalibration P (g(x) 0),wherewehaveg(x):=ξ f (x),which
D
≤ −| |
3isinreliabilitytheoryoftenreferredtoaslimitstatefunction. differencebetweenglobalvalidityandvalidonaverage,e.g.,
In the following, we will define the noiseless residual as accordingtoapredictionaccuracymetric.
δ(x)=E[f D(x)]=f M(x) f E(x),whichisunknownin
practice,i.e.,onlyξandf
(−
x)areavailableforvalidation
Definition2(LimitState). Givenamodelf Mandatoler-
D
iff.xisalreadyobservedinput.
ancelevelξ,thelimitstateoff Mis
DifferencestoRA. TheformulationofMVleadstokey
= x X: ξ δ(x) =0 .
S { ∈ −| | }
differencestoRAthatwehavetoconsider:1)Theformu-
lationofEquation1isanalogoustohavingtwolimitstate We can interpret Definition 2 as the set of points on the
conditionsinthesettingofRA.2)Thedistributionofthe boundarybetweenthevalidandinvaliddomains(seeFig-
samplesinthelimitstateisafoldedGaussian[Leoneetal., ure1).Moreover, isunavailableinpractice,andourob-
S
1961],sinceg()isformulatedintermsoftheabsolutevalue jectiveistoconstructastrategyaimedatplacingsamplesin
·
off (),whichisGaussianbyassumption.3)TheMVlimit thevicinityof ,therebyefficientlylearningtodifferentiate
D
· S
stateiscorruptedbynoise,whileitiscommonlyconsidered betweenvalidandinvaliddomainsforf .
M
noise-freeinRA1,sinceg()isgenerallyasimulationmodel
·
withnegligiblysmallnumericalerrors[BucherandBour-
4.2 OVERVIEW
gund,1990].4)xissubjecttouncertaintyinRAproblems,
whereasweassumednouncertaintyinthecontextofMV.
Notation. Weconsiderlearningthelimitstate overthe
Nevertheless,theMVsettingcouldbeinterpretedasaRA
p dr eo fib nl ee dm oin veth ri ts hr ees ep ne tc irt, ew Xh .er Te hp is(x r) epis rea su en ni tf so orm urd ii nst tr ei rb eu st tio inn
n Dor =ma {li (z xed i,yin ip
)
}u
n
it =s 1p ,a wce ithX˜
i⊆
npu[0 t, x1 i]d ∈fro X˜m av na dlid laS a bti eo ln yd ia =ta
f (x ). Equivalently, we represent training examples as
assessingthevalidityofthemodeleverywhereinXwith D i
n d matrix X, where the i-th row is the i-th training
equalimportance.
×
examplex ,withcorrespondinglabelsy.Furthermore,we
i
employasurrogatemodelgˆ()thatprovides,forsomeinput
4 METHOD x, a (conditional) probabilit· y distribution over the output
gˆ(x) = Gˆ p(g x, ). We can further use, e.g., the
x
Inthissection,wederiveourformulationforlearningand predictivemea∼ nµ g|D| (xD ) = E[Gˆ x]orvarianceσ g2 |D(x) =
representing the limit state S. We start by defining local V[Gˆ x]ofthemodel.
validityandthelimitstateforMV.Next,weintroducethe
notationandactivelearningapproach.InSection4.3,we
ActiveLearning. Activelearningstrategiesaimtoreduce
show how to represent the limit state function g() as a
·
theevaluationsofanexpensiveblack-boxfunctionf E,while
transformedGPmodel,whichisthenusedinSection4.4to
stillachievingasatisfactoryresult;inthiscontext,learning
derivetheAF.AstoppingcriterionisproposedinSection
thelimitstatewithhighaccuracyforMV.Therefore,anac-
4.5basedontheprobabilityofmisclassifyingthevalidity quisitionfunction(AF)ψ: X˜ IRisusedtoratepromising
ofasetofpoints.Additionally,inSection4.6itisshown →
newsamplepoints,oftenreferredtoascandidates.Learn-
howtoobtainthepredictionofthelocalvalidset.Finally,
ingisencouragedbymaximizingψoverthecandidateset
theoreticalconsiderationsarepresentedinSection4.7. = c nc ,wherec isdrawnuniformlyfrom[0,1]d in
C { i }i=1 i
ourcase.Anewqueryx∗isobtainedas
4.1 DEFINITIONOFLOCALVALIDITYAND
LIMITSTATE x∗ =argmaxψ(x;gˆ, ),
D
x∈C
Beforedescribingtheproposedmethod,properdefinitions where gˆ is the learned surrogate based on . The ini-
of local validity and the limit state for the noiseless case tial dataset can be generated from a space-filD ling design
(i.e.,representingthegroundtruth)areprovided. (e.g.,Sobol[JoeandKuo,2008]orLatinhypercubesam-
pling(LHS)[McKayetal.,1979]).Algorithm1showsthe
Definition1(LocalValidity). Amodelf islocallyvalid
M
activelearningprocedure.Fromhereon,wedropwriting
atx X,givenatolerancelevelξ,ifξ δ(x) 0.Then,
∈ −| |≥ theexplicitdependenceofψon andgˆ.
thevalidregionoff Mis
D
= x X: ξ δ(x) 0 .
V { ∈ −| |≥ } 4.3 GAUSSIANPROCESS
Basedonthedefinitionoflocalvalidity,globalvaliditycan
Gaussianprocessregression(GP)isapopularprobabilistic
be asserted if Definition 1 holds for all x X. Note the
MLmethod,whichcanbeusedtorepresentthebeliefover
∈
1WithasuitableGPmodel,wecouldextendRAtothenoisy theobjectivefunction.Therefore,itisacentralcomponent
settingifrequired(e.g.,[Chun,2024]). to different learning schemes, e.g., in BO [Snoek et al.,
4Algorithm1ActiveLearningModelValidation LimitStatePrediction. Thepredictionofthelimitstateis
Require: Initialdata ,candidateset ,toleranceξ,and obtainedbythemappingλ().Wecangiveclosedformsolu-
acquisitionfunctionD ψ C tionsforµ g|D( ·)andσ g2 |D( ·· ),sinceGˆ xisafoldedGaussian
repeat distributionflippedandshiftedbyξ(seeFigure4).There-
Trainsurrogategˆwith fore,wehave
D
yx ∗∗ ←← fa Drg (xm ∗ (a ) xx ∗x ,∈ yC ∗)ψ(x;gˆ, D) µ g|D(x⋆)=ξ −(cid:32) σ ⋆(cid:114) π2 ζ+erf(cid:32) (cid:112)µ 2⋆ σ2(cid:33) µ ⋆(cid:33) ,
D ←D∪{ } ⋆
Generatenew ▷optional
untilTerminationC
condition ▷e.g.,maximumiterations
σ g2 |D(x⋆)=µ2 ⋆+σ ⋆2 −µ2 g|D(x⋆),
T rer ta uin rnsu Drr ,o gˆgategˆwith
D w ζh =er ee xw pe
(cid:16)
−de µn
2
⋆o (cid:17)t .e ed rfµ (⋆ )= istµ hy e|D G( ax u⋆ ss) i, aσ n⋆2 er= rorσ fy2 u| nD c( tx io⋆ n) ., and
2σ ⋆2 ·
2012]orglobalimprovementofsurrogatemodels[Lämmle
etal.,2023]. 4.4 ACQUISITIONFUNCTION
Inthefollowing,weuseatransformedGPmodeltorepre- TheAFisusedtoguidethesamplingstrategyinregionsof
sentourbeliefofthelimitstate interest.EspeciallyforRAandvalidation,weareinterested
gˆ=λ f˜
D
tosampleinthevicinityofthelimitstate S.Forthispurpose,
◦ several AFs were proposed in RA, e.g., see Bichon et al.
f˜ D (µ,k), [2008], Echard et al. [2011]. Among them, the so called
∼GP
"U-function" [Echard et al., 2011] is widely used in RA
w X˜here ◦ IRis +th de ef nu on tc eti to hn ec mom eap nos ait nio dn t, hµ e: cX˜ ov→ ariI aR na cn ed (k ke: rX n˜ e×
l)
[Dubourgetal.,2013,Teixeiraetal.,2021].
→
functions, respectively. λ() represents the non-invertible
· U-Function. The AF focuses on the design subspace
mappingλ(y):=ξ y .
−| | near the limit state boundary considering an exploration-
exploitationtrade-off.Itisgivenby
Exact Prediction. Since the GP is defined as a joint
Gaussiandistribution,thepredictionatapointx⋆ canbe µ (x)
g|D
ψ (x)= | |, (4)
analyticallyobtainedasconditionalGaussiandistribution U − σ (x)
g|D
p(y x⋆, ) (µ (x⋆),σ2 (x⋆)),withmeanandvari-
| D ∼N y|D y|D
anceas whereµ (x)andσ (x)arepredictivemeanandstan-
g|D g|D
darddeviationoftheprobabilisticmodel,respectively.ψ
µ (x⋆)=µ(x⋆)+kT(K−1+σˆ2I)y, (2) U
y|D e selectssampleswhichhavelargevarianceandarecloseto
σ2 (x⋆)=k(x⋆,x⋆) kT(K−1+σˆ2I)k, (3) thelimitstateaccordingtotheGP.µ (x)issmallonlyif
y|D − e g|D
xisclosetothelimitstate.NotethatEquation4isdifferent
where K contains all pairs of kernel entries (i.e., K =
ij fromtheoriginalformulation[Echardetal.,2011]inour
k(x ,x )),andkdenotesthevectorofcorrelationsbetween
i j setting,sincetheGPpredictivemeanandstandarddeviation
x⋆andtrainingpoints,k =k(x ,x⋆).σˆ2istheestimated
i i e aretransformedbyλ().
noisevariance. ·
MC-Prob. Maximizingψ wasoriginallyderivedtobe
Learning Hyperparameters. Predictions made with a U
equivalenttomaximizingtheprobabilityofmisclassifying
GP depend on the hyperparameters σˆ2 and θ, e.g., noise
e the limit state condition under the Gaussian assumption
variance,kernellengthscale,orpossiblytheparametersof
[Echard et al., 2013]. However, the equivalence does not
themeanfunctionµ(x⋆).Thesehyperparameterscouldbe
holdforafoldedGaussianposterior.Instead,wepropose
obtainedbymaximizingthelogmarginallikelihood
usingthemisclassificationprobabilitydirectlyas
1 1
logp(y |X,θ,σˆ e2) ∝−2log |K |− 2yT(K−1+σˆ e2I)y.  P (cid:16) Gˆ x ω(cid:17) , for µ y|D(x) ξ
Ifpriorknowledgeisavailable,itcanbebeneficialtouse
ψ mis(x;ω)=
1 P
(cid:16)≤
Gˆ
x− ω(cid:17)
,
for|
µ
y|D(x)| >≤
ξ,
− ≤ | |
insteadthemaximumaposteriori(MAP)estimateas
where ω IR determines the exploration-exploitation
θˆ =argmaxlogp(yX,θ,σˆ2)+logp(θ,σˆ2), ∈ +
MAP | e e trade-off, i.e., it gives the misclassification probability
θ,σˆ2
e around the limit state with a small slack variable ω < ξ.
wherep(θ,σˆ2)arethespecifiedpriorsoverthehyperparam- Largervaluesofωencouragemoreexploration.Theclosed-
e
eters. form expression for the cumulative distribution function
5(cdf)ofGˆ isgivenby
x
(cid:16) (cid:17) (cid:18) ξ ω+µ (x)(cid:19)
P Gˆ ω =2 Φ − y|D
x ≤ − σ (x)
y|D
(5)
(cid:18)
ξ ω µ
(x)(cid:19)
y|D
Φ − − ,
− σ (x)
y|D
where Φ() is the standard normal distribution. See Ap-
·
pendix A for a derivation of Equation 5 as well as Ap-
pendixC.2forsomeadditionalinsightsonthemisclassifi-
cationprobability.
4.5 STOPPINGCRITERION
Figure2:Prediction ˜ (Equation6)forthemodifiedRast-
V
riginfunctionafter20initialand70adaptiveobservations,
Thecriterionforstoppingthesequentialstrategyisacru-
withψ andω =0.2ξ.Thetruelimitstateisrepresented
cial part of the method. One straightforward approach is mis
bytheblackline.
tousetheprobabilityofmisclassifyingacandidatepointx
underthetransformedGPposterior,asgivenbyψ .Then,
mis
we stop by reaching a predefined tolerance α P˜ mis = 4.7 THEORETICALCONSIDERATIONS
≥
EX∼p(x)[ψ mis(X;ω =0)]. In practice, we estimate this
expectationbasedonthecandidateset .Thecriterioncan
By [Lederer et al., 2021, Thm 9] ([Lederer et al., 2019,
C
be made more robust by ensuring the above condition in
Thm 3.1], resp.), the regression error of the GP model is
kconsecutiveiterations.Additionally,weintroduceasam-
undercertainconditionsboundedintermsoftheposterior
plingbudget,i.e.,welimitthemaximumnumberofsamples
variance:
obtained.Therefore,westopifthebudgetisexhaustedora
suitableP˜ isachievedintime. Theorem1. AssumethatδisaLipschitzcontinuoussample
mis
fromthezeromeanGaussianprocesswithcovariancekernel
kwithLipschitzconstantL
k
onthecompactsetX˜.Denote
4.6 PREDICTION theLipschitzconstantofδbyL δ.Then,µ y|D( ·)andσ y2 |D( ·)
arecontinuouswithLipschitzconstantsL
µ
andL
σ2
onX˜
ThelearnedGPmodelrepresentsourfinalbeliefofthelimit suchthat
state,whichwecanusetodecideiff islocallyvalidat
anarbitraryx
X˜.Hence,wepredicM
tthelocalvalidset,
L
µ
≤L k√n
∥(cid:0)
K+σ
e2I(cid:1)−1
y
∥
(8)
analogoustoD∈ efinition1,as
L 2L
(cid:16)
1+n
(cid:0) K+σ2I(cid:1)−1 k∗(cid:17)
, (9)
σ2 ≤ k ∥ e ∥
(cid:110) (cid:111)
V˜ = x ∈X˜: ξ −|µ y|D(x) |≥0 . (6) (w 0h ,e 1r )e ,τk∗ I: R= am na dx sx e, tx′∈Xk(x,x′). Moreover, pick α
∈
+
∈
Insafety-criticalapplications,preventingfalsepositivescan (cid:32) M(τ,X˜)(cid:33)
becomemoreimportantthanincorrectlyclassifyingasam- β(τ)=2log
α
pletobeinvalid,asalsonotedbyReebetal.[2023].There-
fore, depending on the application, we may be more risk (cid:112)
aversethanusing ˜ directly.Instead,wecanderivethepre- γ(τ)=(L µ+L δ)τ + β(τ)L σ2τ,
V
dictedlocalvalidsetwith1 αconfidence,forα (0,1), where M(τ,X˜) is the τ-covering number of X˜. Then, it
− ∈
as holdsthat
(cid:110) (cid:111)
V˜
α
= x ∈X˜: q α(x) ≥0 , (7)
P
(cid:16)
δ(x) µ y|D(x) η(x), x
X˜(cid:17)
1 α (10)
| − |≤ ∀ ∈ ≥ −
withquantileq α(x):=inf {g˜ ∈IR:P(Gˆ x ≤g˜) ≥α }. whereη(x)=(cid:112) β(τ)σ y|D(x)+γ(τ).
ItcanbeseenfromEquation(6)thatξcanbechangedpost-
hoc.However,if ξ ξ islarge,themodelmaynot
ForX˜ [0,1]d,itholds
| old − new | ⊆
besufficientlyaccurate,asthesamplesareusuallyplaced
(cid:32) (cid:33)d
nearξ old,andthenewlimitstateresultingfromξ new could M(τ,X˜) M(τ,[0,1]d)=
√d
.
befarawayfromtheoldone. ≤ 2τ
6Incontrasttothemereconsiderationofσ ,Theorem1 value.TheGPistrainedineachiterationuntil100samples
y|D
impliesconvergenceofµ toδifηconvergestozerosuf- areobserved.Thereafter,trainingisconductedevery4-th
y|D
ficientlyfastasn .Accordingtotheposteriorvariance iterationtoreducecomputationaleffort.Evenifthemodelis
→∞
boundsin[Ledereretal.,2021,Section3],thisisparticu- notretrained,weupdatetheGPwiththeobserveddataand
larlythecaseifasufficientnumberofsamplesarecloseto keeptheGPhyperparametersfixed.Forthebenchmarks,we
x.Sincewearemainlyinterestedinasmallerrornearthe conduct30restartswith different initializations,testsets,
limitstate,itisimportanttochoosetheadaptivesampling andseeds,ifnotstatedotherwise.Inevery5-thiteration,we
methodaccordingly.TheproposedAFisdesignedexactly comparetheprediction ˜ (Equation6)withtheGTtarget
V
for this purpose; it intuitively prefers samples which are basedonmin(25000d,250000)testsamples.Additionally,
presumablyclosetothelimitstateandhavehighposterior the results for ˜ are shown in Appendix E.5, and fur-
0.1
V
variance. η(x) can be computed explicitly and yields an therimplementationdetailsofourmethodcanbefoundin
uniformerrorboundonX˜.Since AppendixF.
δ(x) δ(x) µ (x) + µ (x),
y|D y|D
| |≤| − | | | 5.1 ANALYTICALBENCHMARKFUNCTIONS
theseboundscanbeconsideredasanalternativetotheuse
ofconfidenceintervalsoftheGP.However,Theorem1re- Methodology. Forthefirstbenchmark,weconsidervari-
quiresadditionalknowledgeontheLipschitzcontinuityof ousanalyticalfunctionsf(x)toassessmethodperformance
thecovariancekernelaswellasδandisthereforenotgen- under well-controlled conditions, where f(x) represents
erallyapplicable.Furthermore,anexemplarycomputation theerrorsurface(δ(x):=f(x)).Thetestedmethodshave
shows that the obtained results are very conservative, in onlyaccesstonoisyevaluationsf D(x)=f(x) ϵ,where
−
particular, if the bounds in (8) and (9) are used (see Ap- ϵ ∼N(0,σ e2).WeusetheStyblinsky-Tang[Styblinskiand
pendix C.1). Moreover, we found that the GP confidence Tang,1990]andMichalewiczfunction[Michalewicz,1992]
intervalsprovidereliableboundsinmostcases. with varying dimensions, as well as two 2-d benchmark
functionspopularinRA,namelyamodifiedRastrigin[Törn
andZhilinskas,1989]andaseriessystemfunction[Waarts,
5 EXPERIMENTS
2000]asbenchmarkfunctions.Definitionsoftheseanalyti-
calfunctionsaregiveninAppendixG.2.
Experimentsareconductedtodemonstratethesampleef-
Wecompareψ withω =0.2ξ andω =0.0againstsev-
ficiencyofthepresentedmethodonavarietyofproblems, mis
eralbaselines.Thefirstoneisgivenbyψ [Echardetal.,
rangingfromanalyticalbenchmarkfunctionstotrainedML U
2011] adapted to our setting (Equation (4)). Secondly, a
modelsonanalyticalproblems,andsomereal-worldtabular
datasetsfromOpenML[Vanschorenetal.,2013].2Results randomsamplingbaselineisused,whereweselectasample
fromthecandidateswithequalprobabilityinsteadofmaxi-
forthelatterareshowninAppendixE.1,whiletheinfluence
mizinganAF.Further,weconsiderrunningRAindividually
oflabelnoiseisstudiedinAppendixE.2,andresultsforthe
for lower and upper tolerance bound with the original U-
stoppingcriterionarepresentedinAppendixE.4.
function[Echardetal.,2011],denotedψ .Therefore,we
U2
usethesumoftwoAFswithtwoGPs,eachforξ f (x)
Target. Thelearningtargetforourbenchmarksistocor- D
−
andξ+f (x).Bothmodelsobserveallsamples,evenif
rectlypredictvalidregions ofthemodelf asshownin D
M
V only one of the GPs is used to query a new sample, i.e.,
Figure2.Thus,wecanframethetaskasabinaryclassifi-
wetrainandevaluatethemonthesameinputs.Finally,we
cation problem (positive class for valid, and negative for
considerthesmallestmarginmethod[Schefferetal.,2001]
invalid)andreportprecisionandrecall,wheretheF -score
1
withaXGBoost(XGB)classifier[ChenandGuestrin,2016],
isusedasasummarywithinplots.Forthegroundtruth(GT)
as this seems to be a reasonable baseline [Cawley, 2011,
labels,weevaluateξ δ(x),whereδ(x)=f (x) f (x)
M E
−| | − YangandLoog,2018]torepresentthatdirectionofresearch.
isthenoiselessresidual.Further,wesplitintovalid(posi-
FurthersettingsforthebenchmarkaregiveninTable1.
tive)GTlabelifthevalueisnotnegativeandinvalidlabel
otherwise(Definition1).
Table1:Experimentalsettingsfortheanalyticalbenchmark
functions.
Setup. Theinitial,candidate,andtestdatasetsaredrawn
quasi-uniformviaLHS,with10dinitialobservationsaspro-
Benchmarkfunction ξ σ n n
posedbyLoeppkyetal.[2009],wheredisthedimensionof e init adapt
thevalidationdomain.Werestrictthenumberofadaptive Styblinski-Tang 30 5 10d 50d
samples to 50d across all experiments. For the next sam- Michalewicz 0.07 0.01 10d 50d
plepoint,wedrawmin(5000d,50000)candidatesineach Mod.Rastrigin 20 0.1 10d 50d
iteration and choose the one that achieves the largest AF SeriesSystem 3 0.5 10d 50d
2https://github.com/SvenL13/LocalValidity
7Styblinski-2d Styblinski-4d Styblinski-6d Styblinski-8d
0.95 0.9 0.9 0.9
0.90 0.8
0.8 0.8
0.85 0.7
0.7 0.7
0.80 0.950 0.90 0.6
0.85
0.75 0.925 0.6 0.925 0.6 0.5 0.80
0.70 0.900 0.5 0.900 0.5 0.85 0.4 0.75
0.65 100 120 0.4 200 220 240 0.4 320 340 360 0.3 420450480
20 45 70 95 120 40 90 140 190 240 60 135 210 285 360 80 180 280 380 480
Sample Sample Sample Sample
Mod.Rastrigin-2d Series-2d Micha-4d Micha-6d
0.950
1.00 1.00
0.925 0.8
0.95 0.95
0.900 0.6 0.90 0.90
0.875 0.95
0.85 0.85 0.4
0.850 1.00 0.90
0.80 0.80 0.2 0.85
0.825 0.98
0.75 0.75 200 220 240 320 340 360
0.800 0.0
20 45 70 95 120 20 45 70 95 120 40 90 140 190 240 60 135 210 285 360
Sample Sample Sample Sample
ψmis(ω=0.2ξ) ψmis(ω=0.0) ψU ψU2 random margin
Figure 3: Median and 95% confidence intervals of F1-score on the analytical problem functions across 30 runs. Top:
Styblinsky-Tangfor2to8dimensions.Bottom:ModifiedRastrigin(2-d),seriessystemfunction(2-d),andMichalewicz
function(4-d,6-d).
Results. TheresultsaregiveninFigure3,wherewereport Table2:ExperimentalsettingsusedinMLbenchmark.
medianand95%confidencebounds.Thesmallestmargin
baselineispartiallynotshowntoimprovevisibility,asitun- Bench. Dim. ξ σ n n
e init adapt
derperformsothermethods,withmeanF -scoreof39.35%
1 2 0.3 0.03 20 100
acrosssamplesandfinalscoreof73.99%atthelastsample.
Micha. 4 0.6 0.03 40 200
This may be due to the smaller number of available sam-
8 0.9 0.03 80 400
plescomparedtoapplicationsinpreviousresearch.Itcan
2 250 5 20 100
beseenthattheadditionalexploration(ω =0.2ξ)inψ
mis Rosen. 4 500 5 40 200
increases performance slightly upon its counterpart ψ
mis 8 1000 5 80 400
with ω = 0. Further, we found that ψ can be prone to
U2
modelmisspecification,ascanbeobservedfortheRastrigin
function,sincewehavetolearntwoGPs.
mark function f via LHS and acquiring noisy labels. In
E
Overall,ψ withω =0.2ξshowssignificantimprovement particular,onlynoisyevaluationsoff wereavailableboth
mis E
overthebaselines,achievinganaverageF -scoreof76.5% fortrainingandvalidation,whereasnoise-freesampleswere
1
andafinalscoreof92%.Incontrast,ψ showstheweakest usedfortestingthevalidationmodels.Inalltestcases,f
U2 M
performanceamongGP-basedstrategies,withanaverage wasensuredtobeinvalidinsomebutnotallregions(w.r.t
F -score of 75.21%, slightly improving over the random inputdomain).Thisscenarioiscommoninpractice,wherea
1
baselinewith74.55%. modelcanperformataskfairlywellonaverage,butremains
invalidincertainregions.
FourclassesofMLmodelsareconsideredforf :RR,SVR,
5.2 BENCHMARKMODELVALIDATION M
RF,andXGBregression,whichexhibitdifferenterrorsur-
faceswithvaryingdifficulty.f isgivenbytheMichalewicz
Methodology. Weevaluateψ (ω =0.2ξ),ψ ,andthe E
mis U ortheRosenbrockfunction[Rosenbrock,1960]withdimen-
randombaselineforamorerealisticproblemsetting,where
sionsrangingfrom2to8.Thetoleranceξischosensuchthat
the model under validation f is given by a trained ML
M weobtainpartiallyvalidmodels,withvalidratioranging
model.Sinceψ (ω = 0.2ξ)outperformedψ (ω = 0)
mis mis from0.75to0.99.ForRosenbrockwekepthyperparame-
on the analytical benchmark functions, we do not expect
ters of the ML models fixed, while we found the need to
ω =0toperformsignificantlydifferenthere.
tune them via BO for Michalewicz to obtain models that
Trainingdataforf wasobtainedfromananalyticalbench- areatleastpartiallyvalid.Furthermore,wefixthetrained
M
8
erocs-1F
erocs-1F erocs-1F
erocs-1F erocs-1F
erocs-1F
erocs-1F
erocs-1FTable3:MeanandstandarderrorofprecisionandrecallacrossRidgeregression(RR),supportvectorregression(SVR),
randomforestregression(RF),andXGBmodels.Scoresformeanandfinalresultacrosssamplesand30runsarereported.
Boldnumbersrepresentthebestresult.
Benchmark Dimension MeanPrecision[%] FinalPrecision[%]
ψ ψ Random ψ ψ Random
mis,0.2 U mis,0.2 U
2 97.3±0.1 96.9±0.1 96.5±0.1 98.5±0.1 97.6±0.1 97.4±0.1
Michalewicz 4 95.1±0.1 94.9±0.1 94.5±0.1 96.8±0.2 96.7±0.1 96.2±0.2
8 88.5±0.0 88.4±0.0 88.1±0.1 89.7±0.1 89.6±0.1 89.2±0.1
2 97.0±0.1 95.9±0.2 95.5±0.1 98.2±0.1 97.0±0.3 96.9±0.2
Rosenbrock 4 94.7±0.1 93.0±0.1 92.1±0.1 96.1±0.1 94.9±0.2 94.5±0.2
8 92.6±0.1 90.6±0.1 89.9±0.1 94.5±0.1 92.7±0.2 92.2±0.1
MeanRecall[%] FinalRecall[%]
2 99.4±0.0 99.6±0.0 99.1±0.1 99.4±0.1 99.6±0.0 99.3±0.1
Michalewicz 4 98.7±0.0 98.8±0.0 99.0±0.1 98.7±0.2 98.7±0.2 98.9±0.1
8 98.2±0.1 98.3±0.1 98.9±0.1 97.1±0.1 97.3±0.2 98.0±0.1
2 98.8±0.1 99.2±0.1 98.5±0.1 99.2±0.1 99.4±0.1 98.6±0.1
Rosenbrock 4 93.0±0.1 96.4±0.1 96.2±0.2 95.8±0.1 97.2±0.2 96.8±0.2
8 91.5±0.2 97.0±0.1 97.2±0.1 92.1±0.2 96.6±0.1 96.8±0.1
modelsacrossthe30repetitions.Theexperimentalsettings MC-Probintuitivelyplacessamplesnearthelimitstateand
aregiveninTable2,andfurtherdetailsregardingtheML canlearntheboundarybetweenvalidandinvalidregionsof
models hyperparameters and analytical functions can be themodel.Empirically,MC-Probimprovesuponitscounter-
foundinAppendixG.1. part,U-Fun,acrossseveralbenchmarksandtworeal-world
examples,reducingtheprobabilityofincorrectlyclassifying
themodelasvalid,asdesiredinmostsafetyapplications.
Results. TheresultsofourexperimentsareshowninTa-
Incontrasttoexistingconformalpredictionmethods,our
ble3,wherewereportthemeanandthelastvalueacross
approachcansignificantlyreducetherequiredamountof
samplesforprecisionandrecall.Wewanttoemphasizethe
datawhilemaintainingaccuratepredictions.Thescalability
importanceofpreventingfalsepositives,i.e.,falselyjudging
tohigherdimensionsremainsopen,possiblybyreplacing
amodeltobevalid,ascapturedbytheprecisionscorefrom
theGPmodel[Hensmanetal.,2013]orbyexploitingthe
theperspectiveofsafety-criticalapplications.Incontrast,
lowerintrinsicdimensionalityexpectedinmostreal-world
theconsequencesoffalsenegatives,asreflectedbythere-
data[Wangetal.,2016].
call score, are not as severe. Furthermore, we expect the
mean across samples to be informative about the overall
performanceandsampleefficiency,whilethefinalvalueis
Acknowledgements
relevanttotheendperformanceofthemethod.
Itcanbeseenthatψ outperformsboththebaselineand ThisworkwassupportedbyZFFriedrichshafenAG.
mis
ψ intermsofaverageandfinalprecisionacrossalmostall
U
tested cases with regard to precision. While all strategies
References
achievedhighrecallscores(> 90%),ψ andtherandom
U
samplingbaselineslightlyoutperformψ inthisregard.
mis
IEC 61508:2010 Functional Safety of Electri-
cal/Electronic/ProgrammableElectronicSafety-Related
Systems. International Electrotechnical Commission,
6 CONCLUSION
Geneva,Switzerland,2010.
Assessingthevalidityofamodelacrosstherangeofinputs ISO26262:2018RoadVehicles—FunctionalSafety.Interna-
can be challenging due to the expense of gathering addi- tionalOrganizationforStandardization,Geneva,Switzer-
tionalvalidationdata.Toaddressthisissue,wedevelopeda land,2018.
novelformulationofthelocalvalidityproblemforMLmod-
elsinspiredbyactivelearningcommonlyusedinRA.Based PaulD.Arendt,DanielW.Apley,andWeiChen. Quantifi-
onthisfoundation,weproposedanewacquisitionfunction cationofModelUncertainty:Calibration,ModelDiscrep-
(MC-Prob)thatusesthemisclassificationprobability,which ancy,andIdentifiability. JournalofMechanicalDesign,
canbeevaluatedinclosed-form. 134(10),2012.
9MaximilianBalandat,BrianKarrer,DanielJiang,Samuel Tianqi Chen and Carlos Guestrin. XGBoost: A Scalable
Daulton, Ben Letham, et al. BoTorch: A Framework TreeBoostingSystem. InProceedingsofthe22ndACM
for Efficient Monte-Carlo Bayesian Optimization. In SIGKDD International Conference on Knowledge Dis-
AdvancesinNeuralInformationProcessingSystems,vol- coveryandDataMining,pages785–794,2016.
ume 33, pages 21524–21538. Curran Associates, Inc.,
Junho Chun. Active learning-based kriging model with
2020.
noiseresponsesanditsapplicationtoreliabilityanalysis
Rina Barber, Emmanuel J Candès, Aaditya Ramdas, and ofstructures. AppliedSciences,14(2),2024.
RyanJTibshirani. Thelimitsofdistribution-freecondi-
AlexanderI.Cowen-Rivers,WenlongLyu,RasulTutunov,
tionalpredictiveinference. InformationandInference:A
ZhiWang,AntoineGrosnit,etal. HEBO:PushingThe
JournaloftheIMA,10(2):455–482,2021.
Limits of Sample-Efficient Hyper-parameter Optimisa-
AnthonyBellotti. Constructingnormalizednonconformity tion. JournalofArtificialIntelligenceResearch,74:1269–
measuresbasedonmaximizingpredictiveefficiency. In 1349,2022.
ProceedingsoftheNinthSymposiumonConformaland
ProbabilisticPredictionandApplications,pages41–54. V.Dubourg,B.Sudret,andF.Deheeger. Metamodel-based
PMLR,2020. importance sampling for structural reliability analysis.
ProbabilisticEngineeringMechanics,33:47–57,2013.
B.J.Bichon,M.S.Eldred,L.P.Swiler,S.Mahadevan,and
J.M.McFarland.EfficientGlobalReliabilityAnalysisfor B. Echard, N. Gayton, and M. Lemaire. AK-MCS: An
NonlinearImplicitPerformanceFunctions.AIAAJournal, activelearningreliabilitymethodcombiningKrigingand
46(10),2008. MonteCarloSimulation. StructuralSafety,33(2):145–
154,2011.
MickaëlBinois,RobertB.Gramacy,andMikeLudkovski.
PracticalHeteroscedasticGaussianProcessModelingfor B. Echard, N. Gayton, M. Lemaire, and N. Relun. A
LargeSimulationExperiments.JournalofComputational combined Importance Sampling and Kriging reliabil-
andGraphicalStatistics,27(4):808–821,2018. ity method for small failure probabilities with time-
demandingnumericalmodels. ReliabilityEngineering&
MickaelBinois,JiangengHuang,RobertB.Gramacy,and
SystemSafety,111:232–240,2013.
MikeLudkovski. Replicationorexploration?Sequential
designforstochasticsimulationexperiments. Technomet- JacobGardner,GeoffPleiss,KilianQWeinberger,David
rics,61(1):7–23,2019. Bindel, and Andrew G Wilson. GPyTorch: Blackbox
Matrix-MatrixGaussianProcessInferencewithGPUAc-
Can Bogoclu, Dirk Roos, and Tamara Nestorovic´. Local
celeration.InAdvancesinNeuralInformationProcessing
LatinHypercubeRefinementforMulti-objectiveDesign
Systems,volume31.CurranAssociates,Inc.,2018.
UncertaintyOptimization. AppliedSoftComputing,112,
2021. AlkisGotovos,NathalieCasati,GregoryHitz,andAndreas
Krause. Activelearningforlevelsetestimation. InPro-
G. E. P. Box and D. R. Cox. An analysis of transforma-
ceedingsoftheTwenty-ThirdInternationalJointConfer-
tions. JournaloftheRoyalStatisticalSociety.SeriesB
enceonArtificialIntelligence,IJCAI’13,pages1344–
(Methodological),26(2):211–252,1964.
1350,Beijing,China,2013.AAAIPress.
Brent Bryan,Robert C. Nichol, ChristopherR Genovese,
JamesHensman,NicoloFusi,andNeilD.Lawrence. Gaus-
JeffSchneider,ChristopherJ.Miller,etal. Activelearn-
sianProcessesforBigData.InProceedingsoftheTwenty-
ing for identifying function threshold boundaries. In
NinthConferenceonUncertaintyinArtificialIntelligence,
AdvancesinNeuralInformationProcessingSystems,vol-
pages282–290,Bellevue,Washington,USA,2013.AUAI
ume18.MITPress,2005.
Press.
C.G.BucherandU.Bourgund. Afastandefficientresponse
surfaceapproachforstructuralreliabilityproblems.Struc- DaveHigdon,JamesGattiker,BrianWilliams,andMaria
turalSafety,7(1):57–66,1990. Rightley. Computer Model Calibration Using High-
DimensionalOutput. JournaloftheAmericanStatistical
RichardH.Byrd,PeihuangLu,JorgeNocedal,andCiyou
Association,103(482):570–583,2008.
Zhu. Alimitedmemoryalgorithmforboundconstrained
optimization. SIAMJournalofScientificComputing,16: StephenJoeandFrancesY.Kuo. ConstructingSobolSe-
1190–1208,1995. quenceswithBetterTwo-DimensionalProjections. SIAM
JournalonScientificComputing,30(5):2635–2654,2008.
Gavin C. Cawley. Baseline methods for active learning.
InActiveLearningandExperimentalDesignWorkshop GeorgeEmKarniadakis,IoannisG.Kevrekidis,LuLu,Paris
in Conjunction with AISTATS 2010, volume 16, pages Perdikaris,SifanWang,etal. Physics-informedmachine
47–57,Sardinia,Italy,2011.PMLR. learning. NatureReviewsPhysics,3(6):422–440,2021.
10IrfanKaymaz. Applicationofkrigingmethodtostructural IlyaLoshchilovandFrankHutter. SGDR:StochasticGra-
reliabilityproblems. StructuralSafety,27(2):133–151, dientDescentwithWarmRestarts. In5thInternational
2005. ConferenceonLearningRepresentations,2017.
MarcC.KennedyandAnthonyO’Hagan. Bayesiancalibra- DavidJCMacKayandRadfordMNeal. Automaticrele-
tionofcomputermodels. JournaloftheRoyalStatistical vancedeterminationforneuralnetworks. InTechnical
Society:SeriesB(StatisticalMethodology),63(3):425– ReportinPreparation.CambridgeUniversity,1994.
464,2001.
MichaelMacke,DirkRoos,andJörgRiedel. Anadaptive
KristianKersting,ChristianPlagemann,PatrickPfaff,and responsesurfacemethodutilizingerrorestimates. In8th
WolframBurgard. MostlikelyheteroscedasticGaussian ASCESpecialtyConferenceonProbabilisticMechanics
processregression. InProceedingsofthe24thInterna- andStructuralReliability,2000.
tionalConferenceonMachineLearning,pages393–400,
Sébastien Marmin and Maurizio Filippone. Deep Gaus-
CorvalisOregonUSA,2007.ACM.
sianProcessesforCalibrationofComputerModels(with
Discussion). BayesianAnalysis,17(4):1301–1350,2022.
DiederikP.KingmaandJimmyBa. Adam:AMethodfor
StochasticOptimization. InInternationalConferencefor
M.D.McKay,R.J.Beckman,andW.J.Conover. ACom-
LearningRepresentations,2015.
parisonofThreeMethodsforSelectingValuesofInput
Variables in the Analysis of Output from a Computer
PunitKumarandAtulGupta. ActiveLearningQueryStrate-
Code. Technometrics,21(2):239,1979.
gies for Classification, Regression, and Clustering: A
Survey. JournalofComputerScienceandTechnology,35
ZbigniewMichalewicz. GeneticAlgorithms+DataStruc-
(4):913–945,2020.
tures=EvolutionPrograms.Springer,Berlin,Heidelberg,
3edition,1992.
Sven Lämmle, Can Bogoclu, Kevin Cremanns, and Dirk
Roos. Gradientanduncertaintyenhancedsequentialsam-
ThomasMostandChristianBucher. Adaptiveresponsesur-
plingforglobalfit. ComputerMethodsinAppliedMe-
faceapproachusingartificialneuralnetworksandMoving
chanicsandEngineering,415:116226,2023.
LeastSquares. In17thInternationalConferenceonthe
Applications of ComputerScience and Mathematics in
ArminLederer,JonasUmlauft,andSandraHirche.Uniform
ArchitectureandCivilEngineering,Weimar,Germany,
ErrorBoundsforGaussianProcessRegressionwithAp-
2006.
plicationtoSafeControl. InAdvancesinNeuralInforma-
tionProcessingSystems,volume32.CurranAssociates, WillieNeiswanger,KeAlexanderWang,andStefanoErmon.
Inc.,2019. BayesianAlgorithmExecution:EstimatingComputable
PropertiesofBlack-BoxFunctionsusingMutualInforma-
ArminLederer,JonasUmlauft,andSandraHirche.Uniform
tion. InProceedingsofthe38thInternationalConference
ErrorandPosteriorVarianceBoundsforGaussianPro-
on Machine Learning, volume 139, pages 8005–8015.
cessRegressionwithApplicationtoSafeControl. arXiv
PMLR,2021.
e-prints,arXiv.2101.05328,2021.
William L. Oberkampf and Christopher J. Roy. Verifica-
JingLei,MaxG’Sell,AlessandroRinaldo,RyanJ.Tibshi-
tionandValidationinScientificComputing. Cambridge
rani,andLarryWasserman. Distribution-FreePredictive
UniversityPress,Cambridge,2010.
InferenceforRegression. JournaloftheAmericanStatis-
ticalAssociation,113(523):1094–1111,2018. HarrisPapadopoulos,KostasProedrou,VolodyaVovk,and
AlexGammerman. InductiveConfidenceMachinesfor
F. C. Leone, L. S. Nelson, and R. B. Nottingham. The Regression. InMachineLearning:ECML2002,pages
FoldedNormalDistribution. Technometrics,3(4):543– 345–356,Berlin,2002.Springer.
550,1961.
Manolis Papadrakakis, Vissarion Papadopoulos, and
Zhen Lin, Shubhendu Trivedi, and Jimeng Sun. Locally NikosD.Lagaros. Structuralreliabilityanalyisofelastic-
ValidandDiscriminativePredictionIntervalsforDeep plasticstructuresusingneuralnetworksandMonteCarlo
LearningModels.InAdvancesinNeuralInformationPro- simulation. Computer Methods in Applied Mechanics
cessingSystems,volume34,pages8378–8391.Curran andEngineering,136:145–163,1996.
Associates,Inc.,2021.
Fabian Pedregosa, Gael Varoquaux, Alexandre Gramfort,
Jason L. Loeppky, Jerome Sacks, and William J. Welch. VincentMichel,BertrandThirion,etal. Scikit-learn:Ma-
ChoosingtheSampleSizeofaComputerExperiment:A chineLearninginPython. JournalofMachineLearning
PracticalGuide. Technometrics,51(4):366–376,2009. Research,12:2825–2830,2011.
11Carl Edward Rasmussen and Christopher K. I. Williams. RuiTeixeira,MariaNogal,andAlanO’Connor. Adaptive
Gaussian Processes for Machine Learning. Adaptive approaches in metamodel-based reliability analysis: A
ComputationandMachineLearning.MITPress,Cam- review. StructuralSafety,89:102019,2021.
bridge,2006.
HeadTim,KumarManoj,NahrstaedtHolger,LouppeGilles,
RameshRebbaandSankaranMahadevan. Computational andShcherbatyiIaroslav. Scikit-optimize/scikit-optimize.
methods for model reliability assessment. Reliability Zenodo,2021.
Engineering&SystemSafety,93(8):1197–1207,2008.
MichalisTitsias. VariationalLearningofInducingVariables
David Reeb, Kanil Patel, Karim Said Barsim, Martin in Sparse Gaussian Processes. In Proceedings of the
Schiegg,andSebastianGerwinn. Validationofcompos- TwelthInternationalConferenceonArtificialIntelligence
itesystemsbydiscrepancypropagation. InProceedings andStatistics,pages567–574.PMLR,2009.
oftheThirty-NinthConferenceonUncertaintyinArtifi-
AimoTörnandA.Zhilinskas. GlobalOptimization. Num-
cialIntelligence,volume216,pages1730–1740.PMLR,
ber350inLectureNotesinComputerScience.Springer,
2023.
1989.
StefanRiedmaier,BenediktDanquah,BernhardSchick,and
Michail Tsagris, Christina Beneki, and Hossein Hassani.
Frank Diermeyer. Unified Framework and Survey for
OntheFoldedNormalDistribution. Mathematics,2(1):
ModelVerification,ValidationandUncertaintyQuantifi-
12–28,2014.
cation. ArchivesofComputationalMethodsinEngineer-
ing,28(4):2655–2688,2020. Joaquin Vanschoren, Jan N. van Rijn, Bernd Bischl, and
Luis Torgo. OpenML: Networked science in machine
ClaudioM.RoccoandJoséAlíMoreno. FastMonteCarlo
learning. SIGKDDExplorations,15(2):49–60,2013.
reliabilityevaluationusingsupportvectormachine. Re-
liability Engineering & System Safety, 76(3):237–243, Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt
2002. Haberland,TylerReddy,etal. SciPy1.0:Fundamental
AlgorithmsforScientificComputinginPython. Nature
H.H.Rosenbrock. AnAutomaticMethodforFindingthe
Methods,17:261–272,2020.
Greatest or Least Value of a Function. The Computer
Journal,3(3):175–184,1960. VladimirVovk,AlexanderGammerman,andGlennShafer.
AlgorithmicLearninginaRandomWorld. Springer,New
Shankar Sankararaman and Sankaran Mahadevan. As-
York,2005.
sessing the Reliability of Computational Models un-
der Uncertainty. In Collection of Technical Papers - Paul Hendrik Waarts. Structural Reliability Using Finite
AIAA/ASME/ASCE/AHS/ASCStructures,StructuralDy- Element Analysis: An Appraisal of DARS: Directional
namicsandMaterialsConference.AIAA,2013. AdaptiveResponseSurfaceSampling. DelftUniversity
Press,Delft,2000.
TobiasScheffer,ChristianDecomain,andStefanWrobel.
Activehiddenmarkovmodelsforinformationextraction. ZeyuWangandAbdollahShafieezadeh. ESC:Anefficient
InAdvancesinIntelligentDataAnalysis,pages309–318, error-basedstoppingcriterionforkriging-basedreliabil-
Berlin,Heidelberg,2001.SpringerBerlinHeidelberg. ityanalysismethods. StructuralandMultidisciplinary
Optimization,59(5):1621–1637,2019.
BurrSettles. ActiveLearningLiteratureSurvey. Technical
Report,UniversityofWisconsin-MadisonDepartmentof ZiyuWang,FrankHutter,MasrourZoghi,DavidMatheson,
ComputerSciences,2010. andNandodeFreitas. BayesianOptimizationinaBil-
lionDimensionsviaRandomEmbeddings. Journalof
JasperSnoek,HugoLarochelle,andRyanPAdams. Prac-
ArtificialIntelligenceResearch,55(1):361–387,2016.
ticalBayesianOptimizationofMachineLearningAlgo-
rithms. InAdvancesinNeuralInformationProcessing AndrewWhiteandSankaranMahadevan.Discrepancymod-
Systems,volume25.CurranAssociates,Inc.,2012. elingformodelcalibrationwithmultivariateoutput. In-
ternationalJournalforUncertaintyQuantification,13(6),
Michail Spitieris and Ingelin Steinsland. Bayesian Cali-
2023.
bration of Imperfect Computer Models using Physics-
InformedPriors. JournalofMachineLearningResearch, YazhouYangandMarcoLoog. Abenchmarkandcompar-
24(108):1–39,2023. ison of active learning for logistic regression. Pattern
Recognition,83:401–415,2018.
M. Styblinski and T. Tang. Experiments in Nonconvex
Optimization:StochasticApproximationwithFunction In-Kwon Yeo and Richard A. Johnson. A new family of
SmoothingandSimulatedAnnealing. NeuralNetworks, powertransformationstoimprovenormalityorsymmetry.
3(4):467–483,1990. Biometrika,87(4):954–959,2000.
12Quantifying Local Model Validity via Active Learning
(Supplementary Material)
SvenLämmle1,2 CanBogoclu3 RobertVoßhall4 AnselmHaselhoff5 DirkRoos2
1CenterofExpertise,ZFFriedrichshafenAG,Friedrichshafen,Germany
2InstituteofModellingandHigh-PerformanceComputing,NiederrheinUniversityofAppliedSciences,Krefeld,Germany
3ZalandoSE,Berlin,Germany
4auxmoneyGmbH,Düsseldorf,Germany
5RuhrWestUniversityofAppliedSciences,Bottrop,Germany
A DERIVATIONOFEQUATION5
LetY = X ,whereX (µ,σ2)withmeanµandvarianceσ2.Then,Y followsafoldedGaussian[Leoneetal.,1961],
| | ∼N
withparametersµandσ2.Thecdfisgivenby[Tsagrisetal.,2014]
(cid:18) (cid:18) (cid:19) (cid:18) (cid:19)(cid:19)
x µ x+µ
F(x)=0.5 erf − +erf ,
σ√2 σ√2
whereerf(x)=2/√π(cid:82)x
exp( t2)dtistheerrorfunction.Further,letZ =a Y =a µ+σX .Then,forx (0, ),
0 − − −| | ∈ ∞
F(x)=P(Z x)=P(a µ+σX x)=1 P(µ+σX x+a)=1 P( z µ+σX z)
≤ −| |≤ − | |≤−(cid:124) (cid:123)(cid:122) (cid:125) − − ≤ ≤
:=z
(cid:18) (cid:19)
z µ z µ
=1 P − − X −
− σ ≤ ≤ σ
(cid:18) (cid:19) (cid:18) (cid:19)
z µ z µ
=1+Φ − − Φ −
σ − σ
(cid:18) (cid:19) (cid:18) (cid:19)
z+µ z µ
=2 Φ Φ − ,
− σ − σ
whereΦ()isthestandardnormalcdf,andz := x+a.ThelaststepfollowssinceΦ( x) = 1 Φ(x).Weobtainthe
· − − −
formulationinEquation5byusingx=ωanda=ξ,withfoldedGaussianparametersµandσ2givenbytheGPpredictive
meanandvariance.SeeFigure4foraillustration.
B LIMITATIONSANDDISCUSSION
Wehaveshownthatourapproachcanlearnthelimitstate andpredictthevalidset withareducednumberofvalidation
S V
samples.However,itisimportanttodiscussfurtherchallengesandlimitationsweencounteredduringdevelopment.
Firstly,weobservedthathighlabelnoiseinrelationtothetolerancelevelξcandegradetheperformanceofthestrategy.In
suchcases,theunderlyinglimitstatemaynotbeaccuratelyidentifiable,asshownbyourablationstudyinAppendixE.2.
Therefore,ifsmallξhastobeachieved,itisimportanttokeepthenoisecorrespondinglylow.
Secondly,misspecificationoftheGPmodelisimportanttoconsiderandcouldoccur,e.g.,ifmanyhyperparametershave
to be optimized. To mitigate possible misspecification, we train the GP model multiple times with different parameter
initializations(seeimplementationdetailsinAppendixF).Additionally,onecanprovidesuitablepriordistributionsforthe
modelhyperparametersifavailable.Issuescouldarisewithdiscontinuousorunsmootherrorsurfaces,asobservedduring
validationoftree-basedmodels,duetothelearneddecisionstructure.Insuchsituations,theGPmodelcanonlyprovidea
smoothapproximation.
Acceptedforthe40thConferenceonUncertaintyinArtificialIntelligence (UAI2024).FN(µ=5,σ=1)
FN(µ=1,σ=2)
LimitState
0 ξ
g
Figure4:GPpredictionofthelimitstatefunctiongisafoldedGaussiandistribution,whichisflippedandshiftedbythe
predefinedtoleranceξ.Thefilledareashowsthemisclassificationprobabilityψ .
mis
Finally,ourmethodwasdevelopedinthesettingofadditivehomoscedasticGaussiannoisewithvarianceσ2.However,
e
real-world applications can be influenced by heteroscedastic noise, where σ2 may change with x. Thus, the estimated
e
noisewouldbeunder-oroverestimatedincertaininputregionsifassumedhomoscedastic.Nevertheless,homoscedasticity
canbeareasonableassumptionevenforreal-worlddata.ThisisdemonstratedinAppendixE.1byapplyingourmethod
withhomoscedasticityassumptiontoreal-worldexamples.Tofurtherimprovetheperformancewithheteroscedasticnoise,
a suitable transformation on the labels could be applied, such as the Box-Cox [Box and Cox, 1964] or Yeo-Jonhson
transformation[YeoandJohnson,2000],whichhavebeenusedinthecontextofBOandGPmodels[Cowen-Riversetal.,
2022].Alternatively,thenoisecanbelearneddirectlybyasecondGPmodel[Kerstingetal.,2007,Binoisetal.,2018].
Testingsuchanapproachisleftforfuturework.
C ADDITIONALTHEORETICALCONSIDERATIONS
C.1 ERRORBOUNDS
Inthefollowing,wediscusstheerrorboundusingthe90%confidenceintervaloftheGPmodelandtheerrorboundsbased
onTheorem1.Therefore,a1-dtestfunction
1
δ(x)= exp(x) sin(8x 2)
2 −
andadditivenoise(σ2 = 0.052)isusedwithAlgorithm1.Toleranceissettoξ = 1,andweuse10initialsamplesand
e
500iterations.Thetwolimitstatesareatx 0.786andx 0.92.Forthiscase,itispossibletocomputeη givenin
1 2
≈ ≈
Theorem1withexactLipschitzconstants.
TheresultsareillustratedinFigure5.Itcanbeseen,thattheboundusingthe90%confidenceintervaloftheGPmodelmay
underestimatethetrueerror,butyieldsinmostcasesagoodbound.Incontrast,theerrorboundgivenbyηisinanycasea
veryconservativeapproximationofthetrueerror.Further,itcanbeseenthatouradaptivesamplingstrategyresultsina
rapiddecreaseoftheerrorboundηnearthelimitstateevenforsmallsamplesizes,whereasthemodelimprovesglobally
withmoresamplesavailable.
Figure6showsthecomparisonofηwithexactLipschitzconstantsandηcalculatedusingtheboundsfromEquation8and
Equation9.ThesettingisthesameasinthetopleftofFigure5.Apparently,theupperboundsfortheLipschitzconstant
yieldtoopessimisticresultsforsmallsamplesizes.
Theorem1statesthatthetrueerrorislessthantheerrorboundηforallpointsintheinputspacewithaprobabilityof90%.
Therefore,ηgivesauniformerrorboundthatisnotdirectlydependentontheaccuracyofthepredicteduncertaintyofthe
GP,andisthereforemuchstronger.However,thetheoremrequiresadditionalknowledgeontheLipschitzcontinuityofthe
covariancekernelaswellasδandisthereforenotgenerallyapplicable.Furthermore,Figures5,6showthattheboundmay
betooconservative,especiallywhenusingestimatedLipschitzconstants.
14
Gˆp0.25 0.25
η
0.20 0.20 |δ −µy
|D|
0.15 0.15 90%errorconf.bound
0.10 0.10
0.05 0.05
0.25 0.25
0.20 0.20
0.15 0.15
0.10 0.10
0.05 0.05
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
˜ ˜
X X
Figure5:Errorboundη for δ µ aswellastrueerrorand90%confidenceintervaloftheGPmodelfor10initial
y|D
| − |
samples,20(topleft),50(topright),100(lowerleft)and500(lowerright)adaptivesamples.Theverticallinesshowthe
limitstates.Initialandadaptivesamplesareblueandorange,resp.
0.7
η
0.6 |δ −µy|D|
η(est.Lipsch.const.)
0.5
0.4
0.3
0.2
0.1
0.0
0.0 0.2 0.4 0.6 0.8 1.0
X˜
Figure 6: Error bound η for δ µ with exact Lipschitz constants and using the bounds given in (Equation 8) and
y|D
| − |
(Equation9).
C.2 PROBABILITYOFMISCLASSIFICATION
TheprobabilityofmisclassificationatxisgivenbyEquation5andderivedinAppendixA.Forthecaseµ < ξ (with
−
µ= 4andξ =2),thisprobabilityisillustratedasayellowareainFigure7.Thissettingcorrespondstothecaseofan
−
invalidposteriormean.Themisclassificationprobabilityistheprobabilitythatthestateisactuallyvalid.Sincethevalid
domainisbounded,thisprobabilitycanonlybemaximizeduptosomelimitedextentanditisboundedby0.5inanycase.
Incontrast,themisclassificationprobabilityofastatethatispredictedtobevalidcanbearbitrarilyclosetooneandis
strictlyincreasingwiththevarianceforfixedµ(seeright-handsideofFigure7).Forfixedµitisevenpossibletocompute
theσwhichmaximizestheprobabilityofmisclassification.ThiscanbeachievedbytakingthederivativeofEquation5with
respecttoσandbycomputingitsroot.Theoptimalstandarddeviationσ isgivenby
opt
(cid:18) (cid:19)−1
µ ξ
σ2 = 2ξµ ln − forfixedµ> ξ .
opt − µ+ξ | |
Figure8showsthedependenceofthemisclassificationprobabilityonbothµandσ.Theoptimalstandarddeviationincreases
withthedistanceofµtoξ andverysmallvarianceresultsinsmallvaluesforP .However,asdescribedbefore,P
mis mis
decreasesagainifσbecomestoolarge.
150.15
Pmis(µ,σ) Pmis(µ,σ)
0.10 µ 0.2 σopt
ξ
0.05 ± 0.1
0.00 0.0
0.15 1.0
0.10
0.5
0.05
0.00 0.0
15 10 5 0 5 10 0 10 20 30 40 50
− − − σ
Figure7:Left:Yellowareaequalsthemisclassificationprobabilityandismaximizedfor µ >ξifgreenandblueareaare
| |
equal(lowerfigure).Right:Misclassificationprobabilityforfixedµif µ >ξ(upperfigure)and µ ξ(lowerfigure).
| | | |≤
10
σopt(µ)
8 0.4
6 0.3
4 0.2
2 0.1
0.0
4.00 3.75 3.50 3.25 3.00 2.75 2.50 2.25
− − − − − − − −
µ
Figure8:Dependenceofthemisclassificationprobabilityonµandσforµ< ξwithξ =2.
−
D COMPARISONWITHCONFORMALPREDICTION
Whileourprimaryobjectiveofthisworkisdesigninganadaptivesamplingstrategyforlearningthelimitstate (Section4),
S
animportantquestionariseshowourapproachcompareswithexistingconformalpredictionmethods.Hence,weprovidea
comparisonwiththemostpopularconformalpredictionstrategies,whichwecanutilizetopredictthevalidset ˜ forthe
α
V
modelundervalidationf .
M
PredictionIntervalandValidSet. ConformalpredictionmethodsareusedtoderivepredictionintervalsCˆ (x)that
α
containanunseenobservationY⋆ attestpointX⋆ withconfidence1 α(oftenreferredascoverage),wherenofurther
−
assumption is made about the data generating distribution p(x,y). The framework provides guarantees, with the most
commononebeingmarginalcoverage,whichaimstosatisfy
P(Y⋆ Cˆ (X⋆)) 1 α.
α
∈ ≥ −
Note,inordertoformapredictioninterval,moststrategies(e.g.,splitconformalprediction)useadditionalcalibrationdata
besidesthetrainingdataforf [Leietal.,2018,Bellotti,2020].Inoursetting,weusethevalidationdataforthispurpose.
M
Wecanobtainavalidsetsimilarto (Equation7),byusinglowerρ andupperboundρ ofthepredictioninterval,
α lo lo
whereCˆ (x)=[ρ (x),ρ (x)].FurV ther,wecanobtainthevalidsetfromCˆ (x)as
α lo up α
˜
α
= x X:(f M(x) ρ lo(x) ξ) (ρ up(x) f M(x) ξ) ,
V { ∈ − ≤ ∧ − ≤ }
whereξ IR isthetolerancelevel.Inotherwords,weclassifyf tobevalidatxifwepredictwith1 αconfidencethat
+ M
∈ −
thedifferencebetweenmeanprediction(f )andupper/lowerboundisbelowtheprescribedtoleranceξ.Thus,weareable
M
tocompareconformalpredictionmethodstoourmethodbasedon ˜ .
α
V
16
σ
)σ,µ(simPTable4:Qualitativecomparisonbetweenstrategiestoperformvalidation.SplitconformalandMADhaveonlymarginally
coverage,whileLVDprovidesapproximatelyconditionalcoverage.Similarly,ourmethodcanbeseentohavemarginal
coverage if the error bound from Theorem 1 is used. In our experiments, conformal methods have shown the need for
largerdatasetsinordertoprovidemeaningfulpredictionintervalsforvalidation,incomparisontotheproposedapproach
(Section4).
SplitConformal MAD LVD Ours
Coverage marginal marginal apprx.conditional marginal1
Discriminative ✗ ✓ ✓ ✓
Applicablef regression,class. regression regression regression
M
Samplesneeded medium high high small
1basedonTheorem1
SplitConf. LVD MAD Ours
10 10 10 10
5 5 5 5
0 0 0 0
5 5 5 5
− − − −
10 10 10 10
− 0.0 2.5 5.0 7.5 10.0 − 0.0 2.5 5.0 7.5 10.0 − 0.0 2.5 5.0 7.5 10.0 − 0.0 2.5 5.0 7.5 10.0
Targetf Toleranceξ ValidationSample ModelfM PredictionIntervalCˆ 0.9
Figure9:Comparisonofdifferentvalidationstrategies,whereweused100validationsamplesfortheconformalstrategies
(Splitconformal,LVDandMAD),and14samplesforourmethod.Thetargetistoobtainanaccurateestimateofthevalid
regions,i.e.,f isinsidethetoleranceξ.Thepredictionofthelocalvalidset ˜ ( )isshownforeachmethod.
M 0.1
V
D.1 COMPARISON
Wecompareourapproach(Section4)withthefollowingmethodsfromconformalprediction:
• Split-conformalprediction[Papadopoulosetal.,2002],withthecommonly-usedresidualscores(x,y)= y f (x).
M
| − |
• Meanabsolutedeviation-normalizedsplitconformal(MAD)[Leietal.,2018,Bellotti,2020],withtheresidualscore
s(x,y)= y f (x)/u(x),whereu(x)istheresidualpredictorfor y f (x).
M M
| − | | − |
• Locallyvaliddiscriminativepredictionintervals(LVD)[Linetal.,2021],withsquaredexponentialkernel.
AqualitativecomparisonbetweenmethodsisgiveninTable4.
Simple Example. To illustrate differences in the obtained valid sets, we train a GP model f to be validated on 10
M
samplesfromf(x)=xsin(x)+ϵ,withϵ (0,0.52)(similartoFigure1).xisdrawnuniformlybetween0and10,and
∼N
toleranceξissetto3.Toobtainthevalidsetfortheconformalmethods,atotalof100samplesaredrawnuniformly.Forour
method,weuse10initialsamplesand4samplesdrawnwithψ(ω =0.1ξ).Aconfidencelevelof1 α=0.9isusedforall
methods,whilepredictionsaregivenby ˜ .ResultsareshowninFigure9.Weseethatthepred− ictionintervalwithsplit
0.1
V
conformalhasafixedwidthforallx,sincethemethodisnotdiscriminative.Therefore,weseethemethodisnotcapableof
identifyingvalidregionsinthissetting.LVDisdiscriminativeandthereforeabletocorrectlyidentifysomepartsofthevalid
region.However,withfewdata,thepredictionintervalsofLVDcanbecomeinfinitelywide,asnotedbytheauthors[Lin
etal.,2021,Section3.2].ForMAD,onlyasmallregioniscorrectlyclassifiedasvalid.Incontrast,ourmethodisableto
identifyvalidregionswithhighaccuracy.Further,wefoundthatalltestedconformalstrategiesneedconsiderablymore
samplesthanourmethodinordertoprovidemeaningfulpredictionintervals.
8-dimensionalComparison. Wecomparemethodsbasedonthe8-dimensionalbenchmarkfromSection5.2,wherewe
usedRR,SVR,RF,andXGBasf tobevalidated.Forcomparison,weusethefinalresultobtainedfromourmethod,with
M
17Table5:Comparisonofdifferentvalidationstrategiesforthe8-dimensionalMLbenchmark(Section5)withRR,SVR,RF,
andXGBmodels.Meanandstandarderrorareshownacross10runsfortheconformalpredictionstrategies(SplitConf.,
MADandLVD)and30runsforourstrategy(Section4).Predictionsaremadewith ˜ .Scoresforthefinalsampleare
0.1
V
reportedforourmethod.Boldnumbersrepresentthebestresult.
Benchmark Metric Method
SplitConf. MAD LVD Ours
F 1-score[%] 24.9±6.9 44.4±4.1 0.0±0.0 74.5±1.8
Michalewicz(8-d) Precision[%] 24.9±6.9 90.2±0.9 0.0±0.0 94.0±0.4
Recall[%] 25.0±6.9 33.4±4.3 0.0±0.0 64.8±2.1
F 1-score[%] 24.8±6.9 52.4±4.8 0.0±0.0 64.9±2.4
Rosenbrock(8-d) Precision[%] 24.6±6.8 93.0±0.6 0.0±0.0 98.0±0.2
Recall[%] 25.0±6.9 43.2±5.5 0.0±0.0 53.3±2.5
ψ andω =0.2ξ.Further,wedrawuniformlythesamenumberofsamplesasusedbyouradaptiveapproach(480samples
mis
for8-d)tocalibratethepredictionintervals.Weshowtheaverageacross10runsfortheconformalpredictionstrategiesand
30runswithourmethod(resultstakenfromTable6)forF -score,precision,andrecall.InTable5,itcanbeseenthatour
1
methodoutperformstheconformalstrategiesbyalargemarginacrossallmetrics.Acrosstheconformalmethods,MAD
providedthebestperformance.WefoundthatLVDhadissueswiththesmalldataset,leadingtoinfinitelywideprediction
intervalsinmostcases,asdescribedpreviously.
D.2 CONCLUSION
Methodsforconformalpredictionwerederivedtoprovidepredictionintervalswithoutfurtherassumptionoftheunderlying
distribution.Inoursetting,wefoundthattheresultingpredictionintervalswereoverlyconservativewhenusedforvalidation,
especiallywithlimiteddata.Furthermore,LVDprovidedinfinitelywidepredictionintervalsifnotenoughsamplesare
available,whichmakesthemethoddifficulttouseifdataisscarce.Incontrast,wehaveseenthatourproposedmethod
canprovideaccuratevalidsetswithouttheneedforexcessiveamountsofsamples.Theusefulnessofconformalprediction
strategiesistheirwideapplicability,wheretheycanbeusedinthemoregeneralsettingwithheteroscedasticnoise,i.e.,
σ2maychangewithx.Futureresearchmayextendourproposedapproach,sinceGPmodelsarewellcapableofhandling
e
heteroscedasticnoise,asshownwithotheractivelearningstrategies[Binoisetal.,2018,2019].
E ADDITIONALRESULTS
Here,wepresentadditionalexperimentalresultscomplementingthebenchmarksshowninSection5.
E.1 TABULARDATASET
WeshowthepracticalapplicationofourmethodbyextendingexperimentsfromSection5.2withtworeal-worldtabular
datasets(6-d:ID-4835,9-d:ID-361083)fromOpenML[Vanschorenetal.,2013],containingnumericalfeatures.Incontrast
topreviousexperiments,theavailabledataisrestricted,i.e.,wecannotplaceadaptivesamplesatarbitraryx X˜ (previously
∈
wecouldqueryf whichshouldbeobservableinpractice).Hence,theavailabledataisrandomlyseparatedintotrain
E train
D
(6-d:621samples,9-d:349100samples),validation (6-d:1234samples,9-d:93093samples),andtestsets (6-d:
val test
D D
1234samples,9-d:139641samples).Furthermore,iftheactivelearningstrategyproposestoqueryatapositionx⋆ we
picktheclosest(L2 distance)availablesamplex′ inthevalidationsetandreturnthecorrespondingobservation
val
∈ D
y′ .Wecompareψ ,ψ ,andtherandomsamplingbaseline.
val mis,0.2 U
∈D
Results6-dimensionaldataset. Twomodelshavetobevalidated:aGPmodel(Matérn5/2kernel)andaSVRmodelwith
defaulthyperparameters.Themodelsweretrainedwith ,whichresultsinavalidratioof0.64fortheGPand0.65for
train
D
theSVRmodel,withξ =0.1.Figure10showsmedianand95%confidenceintervalfortheF1-scoreacross20runs.The
dashedlinesrepresentareferenceGPmodeltrainedwiththecompletevalidationdata .
val
D
186d(ID-4835)
0.80
0.79
0.78
0.77
0.76
60 100 200 300 400 500 600 700 800 900
Sample
ψmis(ω=0.2ξ) ψU random AllData
Figure10:Medianand95%confidenceintervalsofF1-scoreonthe6-dimensionaltabulardatasetforGPandSVRmodel
across20runs.Dashedlinerepresentsreferencemodelwithallavailablesamplesfromthetabulardataset.
9d(ID-361083)
0.8
0.7
0.875
0.6
0.850
0.825
0.5 340 390 440 490 540
90100 200 300 400 500
Sample
ψmis(ω=0.2ξ) ψU random AllData
Figure11:Medianand95%confidenceintervalsofF1-scoreonthe9-dimensionaltabulardatasetforXGBmodeland
across30runs.Dashedlinerepresentsreferencemodelwithallavailablesamplesfromthetabulardataset.
Results9-dimensionaldataset. ThemodeltobevalidatedisaXGBmodeltrainedon withdefaulthyperparameters,
train
D
withtestR2 0.4andtoleranceξ = 0.4,whichgivesavalidratioof0.78.Duetothecomputationalburden,asparse
≈
variational Gaussianprocessregression(SVGP)model [Hensmanetal.,2013, Titsias, 2009]isused insteadofthe GP
(Section4.3).SeeAppendixFfortheSVGPimplementationdetails.
Figure11showsmedianand95%confidenceintervalfortheF1-scoreacross30runs.Further,weshowareferenceSVGP
model(dashedlines)withthecompletevalidationdata (11636samples).Itcanbeseenthatalthoughrandomsampling
val
D
improvesthescorefasterinthebeginning,onlyψ achievesascoreclosetothereferencesolution.
mis
E.2 INFLUENCEOFNOISEONMODELQUALITY
Noiseσ2canhaveanon-neglectableimpactontheachievablemodelaccuracyandcanlead,ifhighenough,toidentifiability
e
issues of the underlying limit state. Figure 12 shows the influence of varying noise on the F -score and the predicted
1
misclassificationprobabilityP˜ forthe2-dimensionalStyblinsky-Tangfunction.Inthisexperiment,wevariedthesignal-
mis
to-noise ratio N/S between 0.1% and 50%. The ratio is calculated as N/S = σ e2/EX∼p(x)[f(X)]2, where f( ·) is the
Styblinsky-Tangfunction,andp(x)istakentobeuniform.Theexpectationisnumericallyevaluated.Furthermore,we
providethesignaltotoleranceratio(N/T=σ /ξ).Itcanbeobserved,thatinthemostextremecase(N/S=50%),thefinal
e
F -scorehasdecreasedonaveragefrom0.95to0.58.Note,thatthisperformancedecreaseiscapturedbyP˜ .
1 mis
E.3 INFLUENCEOFTOLERANCELEVEL
Thechosentolerancelevelξcaninfluencetheefficacyoftheadaptivestrategyandthelearnederrormodelfˆ .Astricter
D
tolerancewillmostlikelyresultinmoreinvalidregions,makingtheproblemmorechallengingtomodel,exceptincases
19
erocs-1F
erocs-1FN/S=0.1%,N/T=8.7% N/S=1%,N/T=28% N/S=10%,N/T=86% N/S=25%,N/T=140% N/S=50%,N/T=196%
0.8
0.6
0.50
0.25
222000 40 60 222000 40 60 222000 40 60 222000 40 60 222000 40 60
Sample Sample Sample Sample Sample
ψmis(ω=0.2ξ) ψmis(ω=0.0)
Figure12:Varyingnoisetosignal(N/S=σ e2/EX∼p(x)[f(X)]2)ornoisetotolerance(N/T=σ e/ξ)ratiosacrosscolumns.
Medianand95%confidenceintervalsforthe2-dimensionalStyblinsky-Tangfunction(validtoinvalidratio:0.77)after20
initialobservationsandacross25runsareshown.
20%valid 40%valid 60%valid 80%valid
0.9 0.98
0.95
0.9
0.8 0.96
0.90
0.7 0.8 0.94
0.6 0.85
0.92
0.7
0.5 0.80
0.90
0.4
0.6 0.75 0.88
0.3
40 90 140 190 240 40 90 140 190 240 40 90 140 190 240 40 90 140 190 240
Sample Sample Sample Sample
ψmis(ω=0.2ξ) ψU random
Figure13:Varyingtolerancelevelsξforthe4-dStyblinsky-Tangfunction,selectedtoobtainfourvalidratios.Medianand
95%confidenceintervalsareshown.
whereeverythingisinvalid,whichmakestheproblemmucheasier.Notethatthisisapropertyinherenttotheproblem.
Figure13showstheresultsforthe4-dStyblinsky-Tangfunctionwithdifferenttolerancelevels,selectedtoobtainfourvalid
ratios(20%,40%,60%,and80%)forf .OthersettingswerekeptthesameasinSection5.
M
E.4 STOPPINGCRITERION
WeshowtheresultsforthemisclassificationprobabilityP˜ ,proposedinSection4.5asastoppingcriterion,whichwe
mis
trackedduringexperimentsinSection5.2.Fromthis,weevaluatethedifferencebetweenthemisclassificationratecalculated
fromthetestdataandourstoppingcriterionP˜ basedonthetrainedGPmodels.Resultsareshownaveragedacross2,4,
mis
and8dimensionsinFigure14.ItcanbeseenthatforbothAFs,P˜ tendstobeslightlyconservative.Similarobservations
mis
weremadefortheoriginalU-function,see[WangandShafieezadeh,2019].Nevertheless,thestoppingcriterionprovidesto
beusefulincombinationwithamaximumsamplebudget,asitcanleadtoearlystoppingifasufficientnumberofsamples
areobtained.
E.5 LOWERRISKAVERSITY
ComplementaryresultsforthebenchmarkinSection5.2using ˜ (Equation7)aregiveninTable6.Weobservethatψ
0.1 mis
V
showsoverallthehighestprecisionscoreonaverageandfinalscore,outperformingψ andtherandombaseline.Duetothe
U
moreconservativepredictions,thereisadropintherecallscoreforallmethods.Differencesbetweentherandomsampling
baselineandtheAFscanbeexplainedbythelimitedexplorationoftheAFsincomparison.
20
erocs-1F
sim˜P
erocs-1F erocs-1F erocs-1F erocs-1F2-dimensions 4-dimensions 8-dimensions
0.01
0.00
0.01
−
0.02
−
0.03
−
0.04
−
0.05
− 20 45 70 95 120 40 90 140 190 240 80 180 280 380 480
Sample Sample Sample
ψmis(ω=0.2ξ) ψU
Figure14:Differencebetweentruemisclassificationrate(M)andP˜ acrossRR,SVR,RF,andXGB.Medianand95%
mis
confidenceintervalsareshown.
Table6:Meanandstandarderrorforprecisionandrecallacross30runsforRR,SVR,RF,andXGB.Predictionsaremade
with ˜ .Scoresformeanandmaximumacrosssamplesarereported.Boldnumbersrepresentthebestresult.
0.1
V
Benchmark Dimension MeanPrecision FinalPrecision
ψ ψ Random ψ ψ Random
mis,0.2 U mis,0.2 U
2 98.5±0.1 98.0±0.2 98.2±0.1 99.0±0.2 98.4±0.2 98.8±0.1
Michalewicz 4 98.0±0.1 97.8±0.1 97.6±0.1 99.1±0.1 99.0±0.1 98.9±0.1
8 91.9±0.1 91.7±0.2 91.6±0.2 94.0±0.2 93.9±0.3 93.9±0.3
2 98.5±0.1 97.8±0.2 98.0±0.2 98.9±0.1 98.3±0.3 98.8±0.1
Rosenbrock 4 98.1±0.1 97.8±0.1 97.7±0.1 98.1±0.2 98.2±0.1 98.3±0.1
8 97.2±0.1 96.5±0.1 95.7±0.1 98.0±0.1 97.6±0.1 97.2±0.1
MeanRecall FinalRecall
2 69.3±1.8 72.1±2.1 88.8±0.9 75.4±1.0 75.5±2.7 93.1±1.1
Michalewicz 4 73.2±0.7 72.2±0.7 77.7±0.6 82.6±1.7 81.1±2.1 85.4±1.1
8 51.3±1.3 42.0±1.1 50.3±0.9 64.8±2.1 52.4±2.4 63.3±1.5
2 66.1±1.4 67.2±2.1 88.0±1.2 68.1±1.6 66.1±2.9 93.2±0.5
Rosenbrock 4 44.4±1.0 49.7±1.0 65.1±1.3 55.4±2.7 57.1±3.4 75.4±2.2
8 38.1±0.7 48.8±0.9 63.5±0.8 53.3±2.3 61.5±2.8 73.7±1.6
F IMPLEMENTATIONDETAILS
Wenowprovidefurtherimplementationdetailsforourmethod.
SamplingStrategy. Forgeneratinginitialandcandidatesamples,weusedaquasi-MonteCarlosamplingstrategybased
onLHS.Themethodisimplementedin[Bogocluetal.,2021],wheresamplesaredrawnfromXwithoutcorrelationand
bymaximizingpairwisedistance.Asanalternative,onecoulduseSciPy’s[Virtanenetal.,2020]quasi-MonteCarlo
implementations(e.g.,LHSorSobolsampling).Wedrawanewsetofcandidatesineachiterationoftheadaptivemethod.
GaussianProcessModel. TheGPmodelusedthroughoutthisworkisimplementedwithGPyTorch[Gardneretal.,
2018]andontopofBoTorch[Balandatetal.,2020].Furthermore,wetransformedtheinputsofthemodeltotheunit
cube.Outputofthemodelwasnormalizedtobezeromeanandunitvarianceduringtraining,andreversedforprediction.
TheGPusesasumoffivekernels:squaredexponential,Matèrn1/2,Matèrn3/2,Matèrn5/2,andrationalquadratic,where
weplacedhalf-Cauchypriors(σ = 2)onthelengthscales.Thereasonforusingthiscombinationis:1)thefivekernels
providesignificantflexibility.2)Theheavytalesofthehalf-Cauchypriorcandisableunuseddimensionsaccordingtothe
principleofautomaticrelevancedetermination[MacKayandNeal,1994].3)Ourpreliminarytestsshowedthatusingthis
combinationprovidesimprovedperformance,e.g.,incontrasttousingtheMatèrn3/2,althoughbeingmoredifficulttotrain.
21
sim˜P
−MTable7:BOsearchspaceforhyperparameteroptimization.
RR SVR RF XGB
Parameter Distribution Parameter Distribution Parameter Distribution Parameter Distribution
Polydegree Unif.Int.[2,10] C Unif.[10−4,100] Num.Estimators Unif.Int[10,300] Max.depth LogUnif.Int[2,10]
Alpha LogUnif.[10−6,100] Epsilon LogUnif.[10−5,100] Max.depth LogUnif.Int[2,20] Gamma LogUnif.[10−5,100]
Gamma LogUnif.[10−5,1000] Eta LogUnif.[10−5,0.99]
Lambda LogUnif.[10−5,1]
Table8:NumberoftrainingsamplestogetherwithresultingR2 scoresofthetrainedMLmodelsforthebenchmarkin
Section5.2.
TestR2
Benchmark Dim. n RR SVR RF XGB
train
2 200 0.69 0.89 0.8 0.98
Michalewicz 4 600 0.21 0.3 0.63 0.96
8 1000 0.11 0.1 0.31 0.82
2 100 0.96 0.87 0.91 0.92
Rosenbrock 4 200 0.96 0.83 0.74 0.84
8 500 0.95 0.83 0.68 0.84
Otherwise,weuseddefaultsspecifiedintheBoTorchimplementationoftheSingleTaskGPclass.WefittheGPmodel
usingSciPy’simplementationoftheL-BFGS-Balgorithm[Byrdetal.,1995]with5randomrestartstomaximizethe
log-marginallikelihood.Ifthemodelisnottrained,newobservationsareincorporatedbybuildinganewGPmodelwith
updateddataandthesamehyperparametersasinthepreviousiteration(strategiesforsuchareimplementedinGPyTorch).
VariationalGaussianProcessModel. FortheSVGPmodelweusetheimplementationfromBoTorchwith500inducing
points.WeapplythesameinputandoutputtransformationsaswiththeGPimplementation.Askernel,wefoundusing
thesamefivekernelsaswithGPprovidestomuchoverheadwithSVGP.Therefore,werestrictedtheusagetotheMatèrn
1/2kernel.Themodelisfittedwith3randomrestartsbymaximizingtheevidencelowerboundviaAdam[Kingmaand
Ba,2015](learningrate0.1)combinedwithearlystopping(patience30)andthecosineannealinglearningratescheduler
[LoshchilovandHutter,2017].
G EXPERIMENTALDETAILS
Here,wepresentfurtherdetailsontheimplementationoftheconductedexperiments.
G.1 DETAILSBENCHMARKSECTION5.2
For the benchmark, we trained various ML models (f ) to be validated afterwards. We used RF, SVR, and RR as
M
implemented in Scikit-learn [Pedregosa et al., 2011]. XGB is implemented based on [Chen and Guestrin, 2016].
Inputsandoutputswerenormalizedtohavezerosamplemeanandunitstandarddeviationforallmodels.Numberoftraining
samplesandresultingtestR2aregiveninTable8.
Hyperparameters. For the Rosebrock benchmark, we used the specified default parameters to a large extend. Only
exceptionsare:1)RRwithpolynomialfeaturesofmax.3thdegreewithL2regularizationof0.3(alpha).2)RFwith200
trees(num.estimators)withmaximumdepthof25.3)XGBwithmax.depthof3.FortheMichalewiczfunction,wefound
theneedtotunethehyperparameters.Therefore,weusedBOimplementedinScikit-optimize[Timetal.,2021]
basedonthecross-validatedmeanabsoluteerrorobjective.ThehyperparametersearchspaceisgiveninTable7.
22G.2 BENCHMARKFUNCTIONS
Thissectiongivesanoverviewoftheanalyticalfunctionsusedthroughoutthiswork.
SeriesSystemwithfourbranches. [Waarts,2000]

3 3+ +0 0. .1 1( (x
x1
−x x2) )2
2−
+
x x1 1√ √+ +2x x2
2
1 2
f(x ,x )=min − 2
1 2 ( (x
x1
−x x2) )+
+
√ √7
72
2 1
− 2
whereweusedx [ 8,8].
i
∈ −
ModifiedRastriginFunction. [TörnandZhilinskas,1989]
2
f(x ,x )=10+(cid:88)(cid:0) x2 5cos2πx (cid:1)
1 2 i − i
i=1
whereweusedx [ 5,5].
i
∈ −
Styblinski-TangFunction. [StyblinskiandTang,1990]
d
f(x)=0.5(cid:88)(cid:0) x4 16x2+5x (cid:1)
i − i i
i=1
whereweusedx [ 5,5].
i
∈ −
MichalewiczFunction. [Michalewicz,1992]
(cid:88)d (cid:18) ix2(cid:19)
f(x)= sin(x )sin20 i
i
− π
i=1
whereweusedx [0,π].
i
∈
RosenbrockFunction. [Rosenbrock,1960]
d−1
(cid:88)
f(x)= 100(x x )2+(x 1)2
i+1 i i
− −
i=1
whereweusedx [ 2,2].
i
∈ −
23