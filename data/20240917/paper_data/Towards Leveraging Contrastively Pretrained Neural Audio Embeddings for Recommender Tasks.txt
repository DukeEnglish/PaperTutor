Towards Leveraging Contrastively Pretrained Neural
Audio Embeddings for Recommender Tasks
FlorianGrötschla1, LucaSträssle1, LucaA.Lanzendörfer1 and RogerWattenhofer1
1ETHZurich,Switzerland
Abstract
Musicrecommendersystemsfrequentlyutilizenetwork-basedmodelstocapturerelationshipsbetween
musicpieces,artists,andusers.Althoughtheserelationshipsprovidevaluableinsightsforpredictions,
newmusicpiecesorartistsoftenfacethecold-startproblemduetoinsufficientinitialinformation.To
addressthis,onecanextractcontent-basedinformationdirectlyfromthemusictoenhancecollaborative-
filtering-basedmethods.Whilepreviousapproacheshavereliedonhand-craftedaudiofeaturesforthis
purpose,weexploretheuseofcontrastivelypretrainedneuralaudioembeddingmodels,whichoffera
richerandmorenuancedrepresentationofmusic.Ourexperimentsdemonstratethatneuralembeddings,
particularlythosegeneratedwiththeContrastiveLanguage-AudioPretraining(CLAP)model,presenta
promisingapproachtoenhancingmusicrecommendationtaskswithingraph-basedframeworks.
Keywords
Musicrecommendation,graphneuralnetwork,contrastivelearning
1. Introduction
Musicandartistrecommendationshavebecomeacornerstoneofstreamingservices,profoundly
influencinghowusersdiscoverandengagewithmusic. Algorithmicallygeneratedplaylists,
tailored to individual tastes, are integral to the listening experience, enabling users to find
music that suits their mood and environment, as well as discover new artists. For artists,
inclusion in these playlists can significantly boost their listener base, while exclusion poses
challenges for discovery. Music recommendation systems can be broadly categorized into
collaborativefiltering-basedapproaches[1]andcontent-basedapproaches[2]. Collaborative
filteringleveragesrelationaldata,capturingrelationshipsbetweenartistsortracksfrommanu-
allycuratedsimilarities,tags,anduserlisteningbehavior. Content-basedapproachesutilize
descriptive data to encapsulate the essence of an artist’s music, representing attributes like
melody,harmony,andrhythm. Hybridrecommendersystems[3,4]combinebothtypesofdata
to enhance recommendation quality. In recent years, contrastive learning approaches have
gainedtractionfortheireffectivenessinrepresentingvarioustypesofdata[5,6]. Onesuch
model,ContrastiveLanguage-AudioPretraining(CLAP)[7],mapstextandaudiointoajoint
multi-modal space, offering a novel method for representing music. Our work explores the
utilityofCLAPrepresentationsasdescriptivedatainmusicrecommendationsystems.
The2ndMusicRecommenderWorkshop(@RecSys),October14,2024,Bari,Italy
$fgroetschla@ethz.ch(F.Grötschla);lucastr@ethz.ch(L.Strässle);lanzendoerfer@ethz.ch(L.A.Lanzendörfer);
wattenhofer@ethz.ch(R.Wattenhofer)
(cid:26)0009-0004-1509-174X(F.Grötschla);0009-0002-5264-162X(L.Strässle);0009-0009-5953-7842
(L.A.Lanzendörfer);0000-0002-6339-3134(R.Wattenhofer)
©2024Copyrightforthispaperbyitsauthors.UsepermittedunderCreativeCommonsLicenseAttribution4.0International(CCBY4.0).CEURWorkshop
Proceedings(CEUR-WS.org)
4202
peS
31
]DS.sc[
1v62090.9042:viXraAsaproof-of-concept,weexamineagraph-basedartist-relationshippredictiontask,where
additional musical information has previously enhanced model performance [8]. The goal
istopredictrelationshipsbetweenpreviouslyunseenartistsusingtheattachedinformation.
ByvaryingthisinformationandincorporatingCLAPembeddings,weevaluateitsutilityina
controlledenvironmentandbenchmarktheeffectivenessofdifferentrepresentations.
2. Related Work
ArtistSimilaritywithGraphNeuralNetworks. GraphNeuralNetworks(GNNs)[9]extend
deep learning techniques to graph-structured data, addressing the limitations of traditional
neural networks that require structured inputs. GNNs operate on graphs defined by nodes
and edges, leveraging message passing to aggregate and update node information based on
theirneighbors. Thisapproachhasshownsuccessintaskssuchasnodeclassification,edge
prediction,andgraphclassification[10]. GNNslendthemselvestomusicrecommendertasksas
theycanencodethestructural,relationalinformationtogetherwithadditionalfeatures[11,12].
The study by Korzeniowski et al. [8] introduces the OLGA dataset, which includes artist
relationsfromAllMusic1 andaudiofeaturesfromAcousticBrainz[13]. TheirGNNarchitecture
combinesgraphconvolutionlayerswithfullyconnectedlayersandwastrainedwithatriplet
loss. Performance evaluations on an artist similarity task demonstrated that incorporating
graphlayersandmeaningfulartistfeaturessignificantlyimprovedpredictionaccuracyover
usingdeepneuralnetworksalone.
NeuralEmbeddingsforRecommenderTasks. Variousmethodshavebeenexploredfor
music similarity detection. Previous approaches used a graph autoencoder to learn latent
representations in an artist graph [14], or leveraging a Siamese DCNN model for feature
extractionandgenreclassification[15].Oramasetal.[16]useCNNstoextractmusicinformation,
which, in contrast to our work, can not benefit from contrastive pertaining. Furthermore,
hybrid recommendation systems using GNNs have been applied in other domains, such as
predictinganimerecommendationsbycombininguser-animeinteractiongraphswithBERT
embeddings[17].
ContrastiveLanguage-AudioPretraining(CLAP)[7]learnsthe(dis)similaritybetweenaudio
andtextthroughcontrastivelearning,mappingbothmodalitiesintoajointmultimodalspace.
Throughthecontrastivelearningapproach,eventheaudioembeddingsalonemaintainsemantic
information,makingitsuitablefortaskssuchasmusicrecommendationandartistsimilarity.
3. Neural Audio Embeddings for Artist Relationships
WeinvestigateanestablishedartistsimilaritytasksimilartotheOLGAdatasettoevaluatethe
effectivenessofneuralaudioembeddingsoverclassicalaudiofeaturesinmusicrecommendation
tasks. This dataset comprises a large graph of artists, and the performance of our model is
assessedbasedonitsabilitytopredictnewrelationshipsbetweenpreviouslyunseenartists,
1https://www.allmusic.com/representedasnodeswithinthegraph. Eachnodeisannotatedwithfeaturesextractedfromthe
musicproducedbytherespectiveartist. Previousresearchdemonstratedthatincorporating
musicalinformationsignificantlyimprovesmodelperformance[8]. Weextendthisanalysisby
extractingCLAPembeddingsfromthemusicandcomparingtheireffectivenessagainstother
featuresets. OurgoalistodetermineifCLAPembeddingsprovidebetterrepresentations.
3.1. ExperimentalSetup
OursetupisinspiredbytheapproachofKorzeniowskietal.[8]onOLGA,whereartistsare
representedasconnectednodesbasedontheirrelationshipsdescribedinAllMusic. Following
thesamemethodology,wecreateanupdatedversionoftheoriginaldataset. Thisallowsusto
ensurethatthesongforwhichweextractfeaturesfromAcousticBrainzisconsistentwiththe
songforwhichwecreateCLAPembeddings. Westartwiththesamesetofartistsandcollect
additionalinformationduringpreprocessing,specificallythecategoricalfeaturesformoodsand
themesofanartist,whichweuseduringevaluation. Low-levelmusicfeaturesforsongswere
retrievedfromAcousticBrainz,andCLAPembeddingswerecomputedusingtheLAIONCLAP
modelfromtracksonYouTube. IncontrasttotheoriginalOLGAdataset,weonlyuseonesong
perartistanddonotaggregatethefeaturesovermultiplesongs. Duetoconstantlychanging
informationonAllMusic,someartistswithoutconnectionstootherartistsormissingmatches
onMusicBrainzorAcousticBrainzhadtobedropped. Overall,thisreducedthetotalnumber
ofartistsfrom17,673intheoriginalto16,864inourversion. Wereusethesplitallocationof
theOLGAdataset,whichispossiblesinceeveryartistinourdatasetispresentintheOLGA
dataset as well. This resulted in 13,489 artists in the training, 1,679 artists in the validation,
and 1,696 artists in the test split. We utilize the same loss functions and GNN backbone as
proposedbyKorzeniowskietal.[8],butwithauniformsamplingbasedontripletsinsteadof
distance-weightedsampling. Morespecifically,weemployedthetripletloss,findingthatusing
bothendpointsasanchorsperformedbetterthanrandomlyselectingoneendpoint. Euclidean
distancewasusedfortheloss,andtheNormalizedDiscountedCumulativeGain(NDCG)serves
for the evaluation. For the graph neural network layers, we experimented with SAGE [18],
GatedGCN[19],andGIN[20],withSAGEdemonstratingthebestperformance.
We vary two primary aspects in our experiments: the number of graph layers and the
node features. The number of graph layers ranges from zero to four and is varied to assess
the contribution that the graph topology can make to the task. With zero graph layers, the
architectureonlyutilizesanMLPtomakepredictionsanddoesnotconsiderthegraphtopology,
thus serving as a baseline for models that use GNN layers. As the number of graph layers
increases,nodescanaggregateinformationfromalargerneighborhood,enhancingthemodel’s
capacity to learn from the graph structure. For node features, we use random features as a
baselineandexperimentedwithAcousticBrainzfeatures,CLAPfeatures,andMoods-Themes
features. Wealsotestcombinationsofthesenon-randomfeatures.
3.2. Results
Figure 1a compares the performance of models using random features, AcousticBrainz fea-
tures,Moods-Themesfeatures,andCLAPfeatures. Thebaselinemodel,whichdoesnotutilize000 ... 334 050
0.30
0.310.350.350.37 0.350.370.370.39 0.360.38 0.360.39 000 ... 334 050
0.310.300.320.33
0.350.370.370.38 0.370.380.380.39 0.380.380.390.39
0.270.28
0.25 0.25
0.20 0.20
0.15 0.15 Features 0.15 Features
Random 0.11
0.120.13
AcousticBrainz + Moods-Themes
00 .. 01 50 0.060.070.07 A Mc oo ou ds st -i Tc hB era min ez
s
00 .. 01 50 0.07 A Ac co ou us st ti ic cB Br ra ai in nz
z
+
+
C CL LA AP
P + Moods-Themes
0.02 CLAP CLAP + Moods-Themes
0.00 0.00
0 1 2 3 4 0 1 2 3 4
Number of Layers Number of Layers
(a)Comparison of CLAP features with Random, (b)Comparisonofvariousfeaturecombinations.
Moods-Themes, and AcousticBrainz features. Withfewerlayers, featurecombinationsper-
CLAPoutperformsallotherfeatureswhenused formbetterthansinglefeatures,whereasthey
withenoughlayers. performonparformorelayers.
Figure 1: Comparison of input features used for the artist relationship prediction task. We report
themeanperformanceandindicatethestandarddeviationoverthreeseedsforeachconfiguration,
testingallsetupswith0to4GNNlayers. The0-layerconfigurationservesasthebaseline,whereno
message-passingisperformed,andonlytheinputfeaturesareusedtopredictnodepairs.
anygraphconvolutionlayers,performssignificantlyworsethanmodelsincorporatinggraph
topologyinformation. Performancegenerallyimproveswiththeadditionofmoregraphlayers.
Random features consistently underperform, while CLAP features show better results with
increasedlayersincomparisontotheothers. Moods-Themesfeaturesperformwellwithout
graphlayersbutonlyachieveresultssimilartorandomfeatureswithfourlayers,indicatingthat
theinformationtheyprovidecanbecompensatedbyknowledgeoftheneighborhoodaroundan
artist. Basedonthesefindings,weconcludethatCLAPembeddingsareeffectiveinenhancing
musicrecommendationtasksandprovideinformationthatismissinginotherfeatures.
WefurthercomparecombinationsofCLAPembeddingswithotherfeaturestoassesstheir
effectiveness. OuranalysisinFigure1brevealsthatforlowerlayernumbers,thecombination
offeaturescangreatlyincreaseperformanceincomparisontosinglefeatures(asdepictedin
Figure1a). Formorelayers,thetestedfeaturecombinationsapproachtheperformanceofthe
modelthatonlyusesCLAPfeatures. Thiscouldmeanthattheotherfeaturesdonotprovide
muchadditionalvalueforthetaskorthattheinformationgainedfromthegraphtopologyis
sufficienttocompensateforit. Overall,featurecombinationsthatincludeCLAPperformbetter,
whilewecanseeaclearincreaseofAcousticBrainz+Moods-Themesoverthesinglefeature
baselines.
Limitations Ourexperimentalevaluationhastwomainlimitations: thepotentialformodel
architectureimprovementsandthelimitedrepresentationofartistsusingonlyonesong.
First,regardingmodelarchitecture,thereisroomforenhancementthroughmoreadvanced
techniques, such as distance-weighted sampling, more sophisticated GNN layers, or Graph
Transformers.Weanticipatetheseimprovementswouldlikelyleadtobetteroverallperformance.
However,ourconclusionsprimarilyfocusontherelativeperformancegainsofdifferentfeature
sets. Webelievetheserelativedifferenceswouldremainconsistentevenwithimprovedmodels
002@GCDN 002@GCDNandtrainingtechniques,thoughabsoluteperformancemightincrease.
Second,weonlyuseasinglesongtorepresenteachartist. Thisapproachcouldintroduce
variabilitybasedonthechoiceofthesong,potentiallyaffectingtheperformanceofthefeatures.
Amorecomprehensiverepresentationinvolvingmultiplesongsperartistcouldprovideamore
robustunderstanding,butthiswouldrequirecarefulconsiderationofhowtoaggregatethese
songembeddings. Additionally,thereispotentialforexploringdifferentversionsofCLAPor
otheraudioembeddingmodels. Nevertheless,thefactthatweachievedconsistentperformance
gainsevenwithjustonesongperartistdemonstratestheeffectivenessofCLAPembeddingsas
aviableapproachformusicrecommendation,whichwastheprimaryobjectiveofthisstudy.
4. Conclusion
Inthiswork,weexploredtheuseofCLAPembeddingsasdescriptivedataformusicrecom-
mendationsystems. Ourexperimentsfocusedonagraph-basedartist-relationshipprediction
task,comparingtheeffectivenessofvariousfeaturerepresentations,includingAcousticBrainz,
CLAP,andacombinationofboth. OurresultsindicatethatmodelsincorporatingCLAPem-
beddingssignificantlyoutperformthoseusingtraditionalfeatures,particularlyasthenumber
of graph convolutional layers increases. This highlights the potential of CLAP embeddings
tocapturerichandrelevantinformationaboutmusic,therebyenhancingtheperformanceof
musicrecommendationsystems.
References
[1] B.Sarwar,G.Karypis,J.Konstan,J.Riedl, Item-basedcollaborativefilteringrecommenda-
tionalgorithms, in: Proceedingsofthe10thinternationalconferenceonWorldWideWeb,
2001,pp.285–295.
[2] M.J.Pazzani,D.Billsus, Content-basedrecommendationsystems, in: Theadaptiveweb:
methodsandstrategiesofwebpersonalization,Springer,2007,pp.325–341.
[3] R.Burke, Hybridrecommendersystems: Surveyandexperiments, Usermodelingand
user-adaptedinteraction12(2002)331–370.
[4] G.Adomavicius, A.Tuzhilin, Towardthenextgenerationofrecommendersystems: A
surveyofthestate-of-the-artandpossibleextensions, IEEEtransactionsonknowledge
anddataengineering17(2005)734–749.
[5] T.Chen,S.Kornblith,M.Norouzi,G.Hinton, Asimpleframeworkforcontrastivelearning
ofvisualrepresentations, in: Internationalconferenceonmachinelearning,PMLR,2020,
pp.1597–1607.
[6] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell,
P. Mishkin, J. Clark, et al., Learning transferable visual models from natural language
supervision, in: Internationalconferenceonmachinelearning,PMLR,2021,pp.8748–8763.
[7] Y.Wu,K.Chen,T.Zhang,Y.Hui,T.Berg-Kirkpatrick,S.Dubnov, Large-scalecontrastive
language-audiopretrainingwithfeaturefusionandkeyword-to-captionaugmentation,
in: ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal
Processing(ICASSP),IEEE,2023,pp.1–5.[8] F. Korzeniowski, S. Oramas, F. Gouyon, Artist similarity with graph neural networks,
arXivpreprintarXiv:2107.14541(2021).
[9] F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, G. Monfardini, The graph neural
networkmodel, IEEEtransactionsonneuralnetworks20(2008)61–80.
[10] Z.Wu,S.Pan,F.Chen,G.Long,C.Zhang,S.Y.Philip, Acomprehensivesurveyongraph
neuralnetworks, IEEEtransactionsonneuralnetworksandlearningsystems32(2020)
4–24.
[11] S.Oramas,V.C.Ostuni,T.D.Noia,X.Serra,E.D.Sciascio, Soundandmusicrecommenda-
tionwithknowledgegraphs, ACMTransactionsonIntelligentSystemsandTechnology
(TIST)8(2016)1–21.
[12] H.Weng,J.Chen,D.Wang,X.Zhang,D.Yu, Graph-basedattentivesequentialmodelwith
metadataformusicrecommendation, IEEEAccess10(2022)108226–108240.
[13] D. Bogdanov, A. Porter, H. Schreiber, J. Urbano, S. Oramas, The acousticbrainz genre
dataset: Multi-source,multi-level,multi-label,andlarge-scale, in: Proceedingsofthe20th
Conference of the International Society for Music Information Retrieval (ISMIR 2019):
2019Nov4-8; Delft, TheNetherlands.[Canada]: ISMIR;2019., InternationalSocietyfor
MusicInformationRetrieval(ISMIR),2019.
[14] G.Salha-Galvan,R.Hennequin,B.Chapus,V.-A.Tran,M.Vazirgiannis, Coldstartsimilar
artists ranking with gravity-inspired graph autoencoders, in: Proceedings of the 15th
ACMConferenceonRecommenderSystems,2021,pp.443–452.
[15] J.Park,J.Lee,J.Park,J.-W.Ha,J.Nam, Representationlearningofmusicusingartistlabels,
arXivpreprintarXiv:1710.06648(2017).
[16] S.Oramas,O.Nieto,M.Sordo,X.Serra, Adeepmultimodalapproachforcold-startmusic
recommendation, in: Proceedingsofthe2ndworkshopondeeplearningforrecommender
systems,2017,pp.32–37.
[17] S.R.Javaji,K.Sarode, Hybridrecommendationsystemusinggraphneuralnetworkand
bertembeddings, arXivpreprintarXiv:2310.04878(2023).
[18] W. Hamilton, Z. Ying, J. Leskovec, Inductive representation learning on large graphs,
Advancesinneuralinformationprocessingsystems30(2017).
[19] V. P. Dwivedi, C. K. Joshi, A. T. Luu, T. Laurent, Y. Bengio, X. Bresson, Benchmarking
graphneuralnetworks, JournalofMachineLearningResearch24(2023)1–48.
[20] K.Xu,W.Hu,J.Leskovec,S.Jegelka, Howpowerfularegraphneuralnetworks?, arXiv
preprintarXiv:1810.00826(2018).