Mutual Theory of Mind in Human-AI Collaboration: An
Empirical Study with LLM-driven AI Agents in a Real-time
Shared Workspace Task
SHAOZHANG∗,
ShanghaiJiaoTongUniversity,China
XIHUAIWANG∗,
ShanghaiJiaoTongUniversity,China
WENHAOZHANG,
ShanghaiJiaoTongUniversity,China
YONGSHANCHEN,
ShanghaiJiaoTongUniversity,China
LANDIGAO,
ShanghaiJiaoTongUniversity,China
DAKUOWANG,
NortheasternUniversity,UnitedStates
WEINANZHANG,
ShanghaiJiaoTongUniversity,China
XINBINGWANG,
ShanghaiJiaoTongUniversity,China
YINGWEN†,
ShanghaiJiaoTongUniversity,China
Message: “We need to serve the BeefLettuceBurger.”
Human will Maybe later
Theory of Mind
 Observation Action
Module
Belief about

Human
Agent Message Policy Human
Action Shared Workspace Observation
Message: “I will make the next BeefBurger.”
Affect by Agent’s ToM Process Affect by Human’s ToM Process
Fig. 1. The Mutual Theory of Mind (MToM) Process of Human-AI Collaboration in a Shared
Workspace.WeusedscenariosderivedfromtheOvercookedgametoillustratethisMToMprocess.In
thisexample,thehumancontrolstheblackhatchef,andtheagentcontrolsthebluehatchef.Humansand
agentsactinasharedworkspacetocompleteinterdependenttasks,makingindependentdecisionswhile
usingtheTheoryofMind(ToM)toinfereachother’sstate.Theyobserveactionsasimplicitcommunication
andusemessagesforexplicitverbalcommunication.WelabelthecommunicationpathwaysshapedbyToM,
astheMToMprocessinfluencesexplicitcommunication,decision-making,andbehavior.Changesinagent
behavioraffecthumaninferencesanddecision-making,andthereverseisalsotrue.
TheoryofMind(ToM)significantlyimpactshumancollaborationandcommunicationasacrucialcapability
tounderstandothers.WhenAIagentswithToMcapabilitycollaboratewithhumans,MutualTheoryofMind
(MToM)arisesinsuchhuman-AIteams(HATs).TheMToMprocess,whichinvolvesinteractivecommunication
andToM-basedstrategyadjustment,affectstheteam’sperformanceandcollaborationprocess.Toexplore
∗Bothauthorscontributedequallytothisresearch.
†Correspondingauthor.
Authors’ContactInformation:ShaoZhang,shaozhang@sjtu.edu.cn,ShanghaiJiaoTongUniversity,Shanghai,China;Xihuai
Wang,leoxhwang@sjtu.edu.cn,ShanghaiJiaoTongUniversity,Shanghai,China;WenhaoZhang,wenhao_zhang@sjtu.
edu.cn,ShanghaiJiaoTongUniversity,Shanghai,China;YongshanChen,chenyongshan@sjtu.edu.cn,ShanghaiJiaoTong
University,Shanghai,China;LandiGao,ytlkxglgld@sjtu.edu.cn,ShanghaiJiaoTongUniversity,Shanghai,China;Dakuo
Wang,d.wang@northeastern.edu,NortheasternUniversity,Boston,UnitedStates;WeinanZhang,wnzhang@sjtu.edu.cn,
ShanghaiJiaoTongUniversity,Shanghai,China;XinbingWang,xwang8@sjtu.edu.cn,ShanghaiJiaoTongUniversity,
Shanghai,China;YingWen,ying.wen@sjtu.edu.cn,ShanghaiJiaoTongUniversity,Shanghai,China.
4202
peS
31
]CH.sc[
1v11880.9042:viXra2 ZhangandWang,etal.
theMToMprocess,weconductedamixed-designexperimentusingalargelanguagemodel-drivenAIagent
withToMandcommunicationmodulesinareal-timeshared-workspacetask1.Wefindthattheagent’sToM
capabilitydoesnotsignificantlyimpactteamperformancebutenhanceshumanunderstandingoftheagent
andthefeelingofbeingunderstood.Mostparticipantsinourstudybelieveverbalcommunicationincreases
humanburden,andtheresultsshowthatbidirectionalcommunicationleadstolowerHATperformance.We
discusstheresults’implicationsfordesigningAIagentsthatcollaboratewithhumansinreal-timeshared
workspacetasks.
CCSConcepts:•Human-centeredcomputing→EmpiricalstudiesinHCI;Collaborativeinterac-
tion;•Computingmethodologies→Artificialintelligence;Intelligentagents;Cooperationand
coordination.
AdditionalKeyWordsandPhrases:Human-AITeams,Human-AICollaboration,AIAgent,MutualTheoryof
Mind,LargeLanguageModels,Communication
1 Introduction
AIagentreferstoanAI-drivensystemorentitythatcanperceivetheenvironmentandmake
decisionsbasedontheperceivedinformationtoachievespecificgoalsindependently[95].With
theadvancementoftechnology,anincreasingnumberofAIagentsarebeingdeployedinvarious
scenarios to complete tasks, including medical diagnosis [50, 108, 109, 128], scientific research
[1,41,72,107,127],andindustryapplications[8,43,88].Aslargelanguagemodelscontinueto
evolve,therangeoftasksthatAIagentscanhandleisexpanding,andtheyareincreasinglybeing
applied inscenarios such ashome robots [14, 120], gaming[70, 110], andeducation [102, 132].
Humans and AI agents collaborate in these scenarios in the same space and can observe each
other’sactions,whichisconsideredasharedworkspacesetting[29,96].Thesedevelopmentshave
alsoledAIagentstotransitionfromindependentlyperformingtaskstocollaboratingwithhumans
andformhuman-AIteams(HATs),wherehumansandAIarerecognizedasuniquecontributors,
role-specific,andworkingtogethertowardacommongoal[86].
TheoryofMind(ToM)isanimportantabilityofhumanbeingstoinfermentalstates,intentions,
emotions,andbeliefsofothersforthedynamicadjustmentofbehaviors[92,93],whichhasbeen
appliedinmanyAIagentframeworks[60,118,129].Whencloselycollaboratingwithhumansin
thesharedworkspacesetting,ToMplaysamorecriticalroleintheAIagentframework[47,75].
ResearchersuseToMtohelpAIagentsunderstand,infer,andpredicthumanbehavior,enabling
themtodynamicallyadjusttheirstrategiestoachievebetterteamperformance[47,93].Froma
humanperspective,humansalsobuildmentalmodelsofAIagentsthroughtheToMcapabilityin
thehuman-AIcollaborationprocess[38].HumanstypicallyexpectAIagentstoalignwiththeir
anticipatedcapabilitiesorroles[58],andtheyattributementalstatestoAIagentsaccordingly
[94,98].WhenhumanbeingsareinteractingwithanagentwithToMcapability,MutualTheory
ofMind(MToM)framework,whichreferstoaconstantprocessofreasoningandattributingstates
toeachother,isconsideredtheanalysisofthecollaborationprocessinsomestudies[111,113,117].
Inthestudyofhumancognitiveactivities,ToMprocessesareconsideredcloselyrelatedtocom-
munication[80].PeopleusetheirToMabilitiestoinferothers’mentalstatesandintentions,which
helpsthemdecidewhetherthecommunicationisnecessaryandwhatthecontentandstyleofthat
communicationshouldbe[37].Thiseffectisevenmorepronouncedinteamcollaboration.People
determinetheirplansbasedontheirpartner’smovementsandverbalcommunication,andthey
usecommunicationtocoordinatewiththeirpartnerstoachievealignment[59].Theinteractivity
ofcommunication, whichrefers toboth partiesbeingable tosimultaneouslysend andreceive
1Tofacilitatethereproducibilityofexperimentsandpromotefutureresearchinhuman-AIteams,wewillopen-sourceour
agentandenvironmentimplementation.Incompliancewiththeprincipleofanonymity,wewillincludethelinktoour
GitHubrepositoryinthecamera-readyversion.MutualTheoryofMindinHuman-AICollaboration 3
messages[76],mightbeinfluencedbytheMToMprocessduetoitsbidirectionalcharacteristic.
SomestudiessuggestthatbidirectionalcommunicationisshapedbytheMToMprocess,leading
tochangesinbothparties’mentalmodelsthroughoutlong-termcommunication[111,112].The
team’scommunicationprocess,includingbothverbalandnon-verbalcommunication,andindivid-
ualToMcapabilitiesareinterdependent.InsuchacomplexMToMprocessshowninFigure1,itis
necessarytoexploreverbalcommunicationinteractionandhowbothpartiesengageintheirown
ToMprocesses.
Previousresearchhasexploredthesignificantimpactoftheinteractivityofcommunication
onteamcollaboration,includingthecommunicationdirection[4]andstyle[53].However,since
communicationplaysaroleinbuildinghumantrust[61,99]andshapingsocialperceptions[5,126],
thestudiesoncommunicationonHATsdidnotconsiderthattheAIagenthasaToMcapability
intheHAT.SinceagentsandhumanspossessToMabilities,psychologicalprocessesandteam
communicationbecomemorecomplexwhentheMToMexists[113,117].Westilllackexploration
of the impact of the MToM process on HATs, particularly with regard to how communication
interactivityandanagent’sToMcapabilityinfluencethecooperationprocesswithinaHATina
sharedworkspacesetting.
Inthispaper,weaimtoinvestigatethecommunicationandcollaborationprocessintheMToM
betweenhumansandAIagentsinasharedworkspace.WefirstdevelopanAIagentequippedwith
ToMandcommunicationcapabilitiesviaLLM.BasedonthewidelyadoptedHATcollaboration
benchmark, Overcooked [16, 65, 66, 105, 121, 124], we implement a practical HAT task in the
sharedworkspacesetting.Inthistask,ahumanandanAIagentworktogetherinakitchento
preparedifferentburgers.Inthissharedworkspacesetting,theactionsbetweenthehumanandAI
agenthavedependencies.Moreover,thereal-timerequirementofthetaskfurtheraskstheHAT
tounderstandeachother’sintentions[61].Ourresearchemploysamixedexperimentaldesignof
4×2(4communicationlevel×2agentToMcapabilitylevel).Thisdesignallowsustothoroughly
exploretheeffectsoftheagent’sToMcapabilityandcommunicationinteractivityasindependent
variablesonHATs.Specifically,ourresearchquestionsareasfollows:
• RQ1:HowdoestheMToMprocessincludingcommunicationinteractivityandindividual
ToMcapabilitiesinfluencetheoverallteamperformanceofHATs?
• RQ2:HowdoestheMToMprocessincludingcommunicationinteractivityandindividual
ToMcapabilitiesaffecttheteamcollaborationprocess?
• RQ3:HowdohumansperceiveAIteammatesintheMToMprocess?
Weconductedanonlineexperiment(n=68)usingthesharedworkspacecollaborationtask
wedesigned.TheresultsshowthatHATteamperformanceinreal-timetasksisaffectedbycom-
municativeinteractivity,withperformanceunderbidirectionalcommunicationbeinglowerthan
underothercommunicationinteractivityconditions.Whiletheagent’sToMcapabilitydidnot
significantlyimpacttheteam’sobjectiveperformance,itdidaffectthecollaborationprocess.More-
over,participantstendtooverlookverbalcommunicationduetotheoperationalburdenofsending
orreceivingmessagesintheteamcollaborationprocess.Asforhumanperception,participants’
understandingoftheagentthroughToMreliedmoreontheagent’sbehaviorthanverbalcommu-
nication.Whentheagentcouldcoordinateitsactionswithhumans,participantstendedtobelieve
theagentunderstoodthem.
TheseresultsindicatethatduetothepresenceofMToM,nonverbalandimplicitcommunication
via behaviors can be just as effective as verbal communication for human-AI collaboration in
real-timesharedworkspacetasks.Wefurtherdiscussedhumans’patternsofunderstandingagents
and their perception of agents’ ToM capability to provide information about the human ToM
processwithinMToM.WehopethatadoptingtheMToMperspectivetounderstandhuman-AI4 ZhangandWang,etal.
collaborationinsharedworkspacesettingscanprovidenewinsightsforfutureAIagentdesign.
Weopen-sourceourexperimentplatformandLLM-drivenagent2 forfuturestudyonMToMin
human-AIcollaboration.
2 RelatedWorks
Withcontinuoustechnologicaladvancements,AIagentsaregraduallybecomingteammatescol-
laboratingwithhumansinsharedworkspaces[20,33].Insharedworkspacesettings,AIagents
canindependentlytakeonsometraditionalhumantasksandroles,contributingtotheteam’s
success[16,28,96].DuetothehumanandtheAIagentbeingbothrecognizedasaunique,role-
specificcontributorworkingcollectivelytowardsacommongoal,thehumanandAIagentform
aHuman-AITeam(HAT)[86].ThissectionpresentstherelatedworksofTheoryofMindand
CommunicationinHuman-AITeams(HATs)toprovidethecontextofthesetwofactorsinHATs
researchandtheirrelationships.Inourstudy,weconsiderthatcommunicationandindividual
ToMprocessesmutuallyinfluenceeachother,andtheinteractivityofcommunicationis
partoftheMToMprocess.WefurtherpresentthecurrentAItechnologyrelatedtotheagent’s
capabilitiesincommunicationandToMtoprovidethebackgroundoftheAIagentthatwasusedin
ourexperiments.
2.1 TheoryofMindinHuman-AITeams
TheoryofMindreferstoanimportantabilityofhumanbeingstoinfermentalstates,intentions,
emotions,andbeliefsofothersfordynamicadjustmentofbehaviors[10,11,92].Usingsharedplans
andgoalsasthefoundationforcollaborativetaskcompletion,ToMenableshumanstorecognize
andadjustplanstoachievecooperation[9,17].TheseToMprocessesandoutcomesimpacthuman
collaborativeperformanceandoverallteamperformance.
The AI community uses ToM to build AI agents that can infer partners’ intention [28, 118],
includingpartneragentsandhumans[24,47,101].ManystudiessuggestthattheToMisacrucial
factorforAIinachievingdynamicautonomyadjustment[96],whichsignificantlyimpactsteam
performance [38]. ToM can help improve understanding of which tasks are suitable for which
teammates[91,103]andenablebettertaskallocationamongthem[46],leadingtomoreeffective
coordination.Atthesametime,researchersarealsostudyinghumanperceptionsandreactions
whenmachinesexhibitbehaviorsthatsuggestanunderstandingofhumancapabilities[113].From
thehumanperspective,whencollaboratingwithAI,humanswithgoodToMcapabilitywillnaturally
haveamentalmodelofAI[6,38,67].Basedonthementalmodel,peopletendtoattributemental
statestoAIteammates[75,91,98]andexpectAItoperformspecificrolesininteractionsthatalign
withtheirexpectationsandthementalmodelsofAIteammates[58].
WhenahumancollaborateswithanagentwithToMcapability,themutualTheoryofMind
(MToM)frameworkisconsideredtoanalyzethecollaborationprocess[112].MToMreferstoa
constantprocessofreasoningandattributingmentalstatestoeachotherduringinteractionwhen
humansandAIhaveToMcapabilities[111,117].InpastMToMstudies,languagecommunication
wasusedasacueforunderstanding[111,112].However,insharedworkspacesettings,inaddition
to verbal communication, there are more actions and task dependencies between individuals,
leadingindividualstorelyonactionsandbehaviorstounderstandothers’intentions.Westillneed
tofullyunderstandtheMToMprocessinHATsinsharedworkspacesettings,includinggreater
immediateandextensivedependenceonactionsandtasksbetweenhumansandAIagents.
2Incompliancewiththeprincipleofanonymity,wewillincludethelinktotheGitHubrepositoryinthecamera-ready
version.MutualTheoryofMindinHuman-AICollaboration 5
TounderstandtheMToMprocess,weusewhethertheagenthasToMcapabilitytodetermine
whethertheMToMexistsinHAT.WeusedLLMstohelptheagentunderstandhumansbasedon
theirhistoricalactionsandmessages,allowingtheagenttobuildabeliefaboutthehumanand
adjustitsactionsaccordingly.Additionally,weconsideredtheimpactofToMoncommunication.
In the next section, we discuss the role of communication in HATs and how ToM influences
communication.
2.2 CommunicationinHuman-AITeams
Communication plays a key role in supporting the human-human team collaboration process,
including verbal and non-verbal communication [37, 56, 63, 78, 97]. Verbal communication is
typicallyadirectandexplicitexchangeofinformation[51,125],whilenon-verbalcommunication
is more implicit and requires understanding based on mental states and additional contextual
information[3,79].
Similar to human communication [36, 62, 100], communication in HATs is also the primary
factorsinfluencinghumanperceptionontheAIteammates.Manystudiesindicatethatdifferent
factorsofcommunicationhaveimpactsonhumans’trustonAIagents[61,99].Researchontherole
ofcommunicationinHATshasalsoexaminedthequantityandfrequencyofcommunication[77,86].
CommunicationinHATsistypicallylessthaninthehuman-humanteam[25].However,some
studieshavefoundthatAIagentsthatdisclosemoreinformationtohumansandprovidemore
explanationsvianon-verbalcommunicationarenotalwaysassociatedwithbetterdecision-making
orhigherhumantrustontheAIagent[61].CommunicationalsoinfluencesthesocialbehaviorofAI
andhumanpreferences[71].Somestudieshaveexploredtheverbalandnon-verbalcommunication
strategiesthathumanspreferAIteammatestouseinteamenvironments,findingthathumans
tendtopreferproactivecommunicationfromteammatesandexpectthemtorespond[125,126].
Sincecommunicationisoneoftheprimarymeansofinformationexchangewithinteams,its
interactivityhasreceivedsignificantattention[4,83].Interactiveverbalcommunicationistypically
consideredbidirectional[76],meaningthatmessagescanbesentandreceivedsimultaneously[30].
Ashktorabetal.[4]reportswhenAIagentrespondstohumancues,humansperceivetheAIagent
asmoreintelligent.Inthepresenceofbidirectionalcommunication,thecommunicationstylecan
affecttheobjectivetaskloadonhumans.Specifically,communicationstylesthatinvolvefeedback
canincreasethehumanobjectivetaskload[53].
Verbalandnon-verbalcommunicationisalsoinfluencedbytheTheoryofMind(ToM)processin
human-AIcollaboration.InHATs,humansandAIagentstypicallyneedtounderstandthestatusof
theirteammates[52],aswellaswhattheirteammatesknowandplan[26],tofacilitatecooperation.
CommunicationisregardedasanimportantchanneltohelpHATsexchangeinformation[125],
whichcanbesentinverbalandnon-verbalways.HumansuseToMtoinferthementalstatesand
intentionsofothers,whichdirectlyaffectswhethertheychoosetocommunicate,theemotional
toneofthecommunication,thewayofcommunication,andthecontentofthecommunication.The
amountofcommunicationinHATsispositivelycorrelatedwithstrongersharedmentalmodels,
whichleadstobetterteamperformance[27].IncurrentHATsresearch,studiesindicateshowan
agent’sToMabilitiescanenhanceitssocialattractivenessincommunicationtasks[12,75,89].In
studyingtheMToMprocess,themutualinfluencebetweencommunicationandindividualToM
processesmakescommunicationanessentialfactorthatcannotbeoverlookedintheMToMprocess
[111].
UnlikepreviousstudiesfocusesmoreonverbalcommunicationwithToM,weconsideredboth
verbalandnon-verbalcommunicationprocessesintheMToMframework.Inourstudy,weexplore
how communicative interaction affects the MToM process. We examined HAT scenarios with6 ZhangandWang,etal.
bidirectionalcommunication,unidirectionalcommunication,andnocommunication.Giventhein-
herentpresenceofimplicitnon-verbalcommunication,ourbetweengroupconditionsareonverbal
exchangesbetweenhumansandAI.Wealsostudiednon-verbalcommunicationbymanipulating
theagent’sToMabilitiesasawithin-subjectfactor,assessinghowthehuman’sToMperceivesthe
agentandaffectscommunicationanddecision-making.Similarly,weintegratedcommunication
into the agent’s ToM control framework. The agent’s ToM considers both human actions and
language,shapingitscommunicationanddecisions.
2.3 LLM-drivenTheoryofMindAIAgents
ConsideringtheTheoryofMind’s(ToM)importanceinhuman-humaninteractionandcollaboration,
theAIcommunityhasdevelopedmanyAIagentframeworksbasedonToMtoimproveAIagents’
capability to interact with humans and other agents [60, 118]. In multi-agent system research,
researchersprimarilyfocusonhowtoconstructagentscapableofcollaboratingwithanyunseen
partners(includinghumans)asgeneralizationproblems[2,115].Consideringtheproblemasthe
AdHocteamworkscenario[2],researchersusemanymethodsbasedonToMtohelpagentsadapt
todifferentpartners,includingintentionsharing[40],classifyingtypesofhumanteammates[131],
usinglatentvariablesforinference[74],andemployinghumanbehaviordatatomodelhumans[16].
Mosthumanmodelingapproachesassumethathumanbehaviorpatternsarestaticandunchanging,
leadingtolimitationsintheAIagent’sToMprocess,asitcannotmakereal-timeinferencesabout
humans[69].
Inthepast,agentsbuiltusingreinforcementlearning(RL)couldonlyachieveteamcoordination
throughnon-verbalcommunication[61,130]ornetworkparametersharingbetweenagents[114],
makingitdifficulttocommunicatewithhumans.Someworkshaveattemptedtoenablelanguage
communicationwiththeRLagentswithlanguagemodel[14,34,85],butstillfacingthegrounding
problem[55].ThisissuealsomadeitchallengingtostudycommunicationprocessesinmanyHATs
researchusingrealAItechnology[27,125].Withtheemergenceoflargelanguagemodels(LLMs),
AIagents’communicationcapabilitieshaveimprovedsignificantly.Theadventoftechniquessuch
asChainofThought(CoT)[116]andReAct[123]hasfurtheradvancedthecapabilitiesofLLMs
inreasoninganddecision-making[110].AutonomousagentsdrivenbyLLMsarebeginningto
emerge, capable of performing real-world tasks, such as gaming [7, 39, 110], online shopping
[35,73,122],andhousekeeping[42,64].ManyconversationalagentshavealsoincorporatedToM
intotheirframeworkstohelpunderstandhumanintentions[7],thusimprovingtheuserexperience
[112,119].SincesimulationsinvolvingmultipleLLMscooperatinghaveconfirmedtheLLMs’ability
tounderstandhumanbehaviorandadjusttheiractionsaccordingly[87],LLMshavealsobeenused
toadapthumanbehaviorviaToM[7,104,106,119].
ManystudiesproposeframeworksforLLM-drivenagentstofacilitatethecollaborationbetween
LLM-drivenagentsandhumans.MindAgent[39]constructsanLLM-basedagenttoachievemulti-
agentcoordinationinMinecraftandcooperationwithhumansinakitchenenvironment.Liuetal.
[70]usedtwoLLMstocontroltheagent’sslow-mindandfast-mindthinking,enablingreal-time
communicationandcooperationwithhumansinasimulatedOvercookedgame.ToMcapabilities
enabledbyLLMshavealsobeenusedforcompetitiveoperationsinboardgames,helpingAIagents
achievevictoryinthepokergame[129].
ThesetechnologicalfoundationsprovideaviablepathwayforrealAIagentstobeinvolvedwith
communicationandToMcapabilitiesinHATresearch.Inourstudy,webuildrealLLM-driven
AIagentsbasedonGPT-4omini[84]withcommunicationandToMcapabilitiestoexperiment
withhumans.OurstudycanserveasacomplementtopreviousresearchthatusedWizard-of-Oz
[21,125]orrule-basedagents[96],byexploringtheperformanceandimpactofrealAIagents.MutualTheoryofMindinHuman-AICollaboration 7
3 CooperativeTaskSetupandFormalizationinSharedWorkspace
TobettervalidatetheimpactofMToMandcommunicationonthecooperationprocessinHATs,
wedesignedasharedcooperativeworkspaceandtasksbasedonOvercooked.Overcookedisan
important simulation environment used for human-AI collaboration [16, 65, 66, 105, 121, 124]
derivedfromtheOvercookedvideogame3.
Inthissection,weintroduceourenvironmentlayoutdesign,thedefinitionofcooperativetasks,
thecommunicationsystemdesign,andthespecificmetricsweusetomeasurethecooperation
process. The environment layout design and task design are closely related to MToM and the
interactivityofcommunication.WeexplainthespecificconnectionsbetweenthedesignandMToM,
aswellascommunication.Wealsoformalizethetaskprocesstohelpunderstandthedesignofthe
agentandourexperimentalprocedure.
3.1 LayoutDesign
In our study, we set the shared workspace as a kitchen. Since we focus on the MToM process,
especiallythecommunicationandindividualToMprocessintheHATcooperationprocess,we
arrangethespacesothatbothpartiesmustcoordinatetheirmovementstoavoidcollisions.The
layoutrequirescommunicationandactioncoordinationwithintheteam.Weredesignthebasic
layoutCounterCircuit fromtheoriginalovercooked-aienvironment[16],andimplementitinthe
gym-cookingenviroment[121].Thelayoutfeaturesaring-shapedkitchenwithacentralcounter,
elongatedcounter,andacircularpathbetweenthecounterandtheoperationalarea,whichis
simulatingarealkitchen.Inthisconfiguration,pots,cuttingboard,ingredients(bread,beef,and
lettuce),andservingspotsarepositionedinfourdistinctdirectionswithintheoperationalarea,
as shown in Figure 2. Although the layout does not forcibly require cooperation, players may
findthemselvesobstructedbynarrowaisles,promptingtheneedforcoordinationtomaximize
performance.Atthesametime,thecircularspacecreatespotentialmovementpatterns(moving
clockwiseorcounterclockwise),whichcanbeusedbyhumansoragentswithToMtoinfertheir
teammates’behaviorandhelpfacilitatecoordination.
(a) TheLayoutoftheCooperativeWorkspaceasaKitchen. (b) CommunicationSysteminOurTask.
Fig.2. GameLayoutandCommunicationSystemoftheTask.
3https://www.team17.com/games/overcooked/8 ZhangandWang,etal.
3.2 TaskDesign
SinceweaimtoexploretheMToMprocess,weincorporateamechanismintheburger-cookingtask
thatrequirescommunicationforcoordination.Ingredientsfortheburgersoverlap,andwithout
explicitindication,itisdifficultforindividualstoinferwhichburgertheirteammateisworking
onthroughasingleaction.Therefore,suchataskdesignrequirestheplayerstocommunicate
andinfertheteammate’sintentionontheongoingtasktopreventredundantworkandeffectively
completeorders.AsshowninFigure3,wedesignthreeburgers:LettuceBurger,BeefBurger,and
BeefLettuceBurger. Humans and agents jointly control the chefs and handle the continuously
incoming burger orders in our environment. The task provides three ingredients for cooking
burgers: bread, beef, and lettuce. The lettuce needs to be chopped, and the beef needs to be
cooked.Allingredientsareassembledintoaburgeronaplate,withnospecifiedassemblyorder.A
LettuceBurgerrequiresbreadandchoppedlettuce,aBeefBurgerrequiresbreadandwell-cooked
beef,andaBeefLettuceBurgerrequiresbread,choppedlettuce,andwell-cookedbeef.Eachorderis
onlyavailableforalimitedtime,indicatedbyacountdownontheinterface.Tocoordinatetheir
teamworkeffectively,boththehumanandtheagentneedtopayattentiontotheremainingtimeof
eachorder.
In addition to the cooperation, we introduce additional failure events that will damage per-
formanceinthecooperationprocess.Ifwell-cookedbeefisnotpromptlyremovedusingaplate
duringcooking,thepanwillcatchfire.Thepanbecomesunusableuntilateammemberusesafire
extinguishertoputoutthefire.Overcookedbeefmustberemovedusingaplate;otherwise,the
panwillremainoccupiedbytheovercookedbeef,renderingitunusableforfurthercooking.This
processdoesnotdirectlyresultinascorepenalty(i.e.,thereisnoexplicitpunishment),butitwill
impacttheteam’scooperationprocess.
(a) LettuceBurger (b) BeefBurger
(c) BeefLettuceBurger (d) OvercookedBeef
Fig.3. GameMechanism.(a),(b),and(c)aretherulesforpreparingandservingburgers.(d)demonstrates
themechanismofovercookedbeefandtherulesforhandlingthefirecausedbyovercookedbeef.MutualTheoryofMindinHuman-AICollaboration 9
3.3 CommunicationSystemDesign
WedesignacommunicationsystemforHATswithinthetasktocontroltheinteractivityofcommu-
nication.Inthegame,weimplementadialoguemodulewherehumanscouldclickbuttonstosend
messagesinadialogbox.Thebuttonsinthecommunicationsystem(asshowninFigure2)are
designedtorepresenttheitemsneededforthetask,includingburgers,allingredients,andplates.
Theneedsforallitemsareexpressedas“Weneed(specificitem)”totheagent.Additionally,we
includeoptionsforhandlingspecialsituations(suchasextinguishingfires).Beyondtask-related
information, there are also two buttons to express emotions. The human participants can see
messagessentbytheagentinthesamedialogbox.
3.4 Formulation
Weformulatethisscenarioasatwo-playerdecentralizedMarkovdecisionprocess(DEC-MDP)[13].
TheDEC-MDPcontainingoneagentandonehumancanbeformalizedas<S,{A𝑖},{Aℎ},𝜌,T,𝑟 >,
whereS isthestatespace, 𝜌 : S ↦→ [0,1] isthedistributionoftheinitialstate𝑠 . A𝑖 and Aℎ
0
aretheactionspacesoftheagentandthehuman,and A = A𝑖 ×Aℎ isthejointactionspace.
T : S ×A ×S ↦→ [0,1] denotesthetransitionprobabilityand𝑟 : S ×A ↦→ Risthereward
function.Attimestep𝑡,theagentandthehumantakeaction𝑎𝑖 and𝑎ℎ
simultaneously.
𝑡 𝑡
State.Boththeagentandthehumanhavefullaccesstothegamestatesandeachother’sactions.
Playerscandirectlyseethestatusofallitemsinthegameinterface,suchasthelocationwhereitems
areplacedandtheircurrentstate(e.g.,beefcookinginapan).Playerscanalsoviewtheremaining
gametimeandcurrentscorethroughtheinformationdisplayed.Theremainingtimeforeachorder,
theprogressofchoppinglettuce,theprocessofcookingbeef,andtheprocessofextinguishinga
fireareshownthroughprogressbars.Allactionstakenbyteammates,theteammates’location,
andtheitemstheyareholdingarefullyvisibletoeachother.Playerscanalsoviewmessagesin
real-time,includingboththemessagestheyhavesentandthemessagestheyhavereceived,along
withthecorrespondingtimestamps.
Action.Inthisenvironment,theactionsthatthehumanandtheagentcantaketocontrolthe
chefsincludemovingup,down,left,andright,aswellas“interact”.Allactivitiessuchaspicking
upitems,servingdishes,andextinguishingfiresareconsideredas“interact”actions.Thespecific
interactionrulesareillustratedinFigure3.WedenotetheactionstocontrolthechefsasAcontrol.
TheagentandthehumansharethesameAcontrol,whilethecommunicationactionsaredesigned
individuallyforthem,denotedasAcomm,𝑖 andAcomm,ℎ
respectively.Thecommunicationaction
spacefortheagentAcomm,𝑖
consistsofanypossiblesentenceslessthan10wordsfromanLLM,
whilethecommunicationactionspaceforthehumanAcomm,ℎ
consistsof11messagetemplates.
DetailsaboutthecommunicationsystemarepresentedinSection3.3andSection4.3.
Reward.Thescoresforcompletingthethreedifferenttypesofordersvaryandservingthe
wrongburgerormissinganorderwillresultinapenalty.Thespecificrewardsaredetailedin
Table1.
3.5 ObjectiveMetrics
TocapturethedynamicsofthecooperationprocessandobservetheimpactofMToMandcommu-
nicationoncollaboration,wedefinedasetoftask-relatedmetricstomeasureteamperformance
andtheteamcollaborationprocess.
TaskScore.Wedefinetheteam’sobjectiveperformanceastheteam’sscore.Thegameissetto
becompletedin500time-steps,andthespecificrewardcalculationmethodisshowninTable1.
ContributionRate.Wefirstdefinekeytaskevents𝐾𝐸tocapturewhichteammembercompletes
specifictasks.Basedontheburger-makingprocess,eachofthethreetypesofburgersinvolves10 ZhangandWang,etal.
Table1. RewardsinGame.
Event Rewards
ServeaLettuceBurger +15
ServeaBeefBurger +20
ServeaBeefLettuceBurger +25
ServeaWrongBurger(orSomethingnotaBurger) -10
Missanorder -10
Table2. Themappingfromkeyeventtokeyactions.
KeyEvents KeyActions
CookBeef ○1 GetBeeffromstationPutontoPan
UseBeef ○1 Platewell-doneBeeffromPan
PrepareLettuce ○1 Getlettucefromstation○2 PutontoCutboard○3 ChopLettuce
○1 PlateLettuceDonefromCutboard○2 PlateLettuceDonefromCounter○3 PutontoPlatewithBeefBurger
UseLettuce
○4 PutontoPlatewithBread○5 PutLettuceontoPlate○6 PutLettuceontoPlatewithBeef
○1 GetBreadfromStation○2 PlateBreadfromCounter○3 PutontoPlatewithBeefLettuce
UseBread
○4 PutontoPlatewithLettuce○5 PutBreadontoPlate○6 PutBreadontoPlatewithBeef
UsePlate ○1 GetPlatefromStation
Serve ○1 DeliverBurger
certainessentialandnon-repeatableevents.Forexample,makingaBeefBurgerconsistsof5key
events: Cook Beef, Use Beef, Use Bread, Use Plate, and Serve, and each key event will only be
completedonce.Thecompletionofkeyeventsismarkedbyspecific“interact”actions,whichwe
defineasKeyActions.WemapthekeyactionswiththekeyeventsinTable2.Inthismapping,
eachkeyeventcompletedbytheplayeriscountedonceastheplayer’scontributiontotheoverall
performance.Basedonthesenon-repeatablekeyevents,wecanattributethecontributiontothe
two players by counting the key events they completed in preparing each properly delivered
burger.Wedefinetheagent’scontributionratio𝐶𝑅𝑖 as:𝐶𝑅𝑖 = 𝐾𝐸𝑖 ×100%,where𝐾𝐸𝑖 and𝐾𝐸ℎ
𝐾𝐸𝑖+𝐾𝐸ℎ
representthekeyeventscompletedbytheagentandthehumanrespectively.
MessageCount.TostudytheimpactofMToMonthecommunicationprocess,particularly
humancommunicationpreferences,werecordthetypesandquantitiesofmessageshumanschoose
tosendwhentheycancommunicate.WecountthenumberofsentmessagesasMessageCount.
FailureCount.Weusecooperationfailuresinthetaskasanauxiliaryanalysisofteamperfor-
mance.Wecategorizethreeeventsascooperationfailures:missinganorder,servingaburgeror
otheritemnotrequiredbythecurrentorders,andthepancatchingfire.Weseparatelyrecordthe
occurrenceofeacheventandsummarizethemasFailureCount.
4 LLM-drivenAgentwithTheoryofMindandCommunicationModule
ThissectionintroducesouragentimplementationbasedonGPT-4omini[84].AsshowninFig.4,we
designthreemainmodulesfortheagent,includingTheoryofMind,Policy,andCommunication.
TheTheoryofMindmoduleinferstheintentionsofhumanpartnersbasedonhumanbehavior,
summarizingthesebehaviorstoguidefurthertheagent’sstrategiesforcooperatingbetterwith
humans.ThePolicymodulecontrolshowtheagentinteractsinourenvironmentandcontinuallyMutualTheoryofMindinHuman-AICollaboration 11
Policy
Reflection Code as Policy Marco
 Action Executor
Guide Action
Improve Strateg   Finite-State Machin   Script Policie 
Update Behavior  Generate Marco Action  Convert Marco Action
Guidelines to Atomic Action
Theory of Mind Message
Belief Belief
Analyze Human Behavior   Express Intentio 
Construct Belief  Response to Huma 
Generate Message Agent
History Buffer
Atomic
Message
State， Action, Message Action
Environment
Atomic Action and Message from Human
Fig.4. AgentFramework.TheframeworkshowshowtheLLM-drivenagentwithTheoryofMindand
communicationcapabilitytakesactionandsendsmessagestothehumanplayer.Weuseahistorybufferto
savethegamehistory,includinggamestate,actions,andplayermessages.TheTheoryofMindmoduleuses
historyasinputtoanalyzehumanbehavior.ThePolicyandMessagemodulesalsohavethehistoryinputto
understandthewholepictureofthegame.Wesummarizetheprocessofgeneratingactionandmessage:(1)
TheTheoryofMindmoduleanalyzeshumanbehaviorandmessages,thengeneratesbeliefsabouthumans
andprovidesaguideforadjustingthestrategyforbetterteamcoordinationandcommunication.(2)The
PolicymoduleusesthebelieffromtheTheoryofMindmoduleandthehistorytoimprovetheagent’sstrategy
bycontinuallyupdatingbehaviorguidelines.Itoutputsanactiontocontroltheagent.(3)TheMessage
moduleusesthehistory,theinferredbelieffromtheTheoryofMindmodule,andtheguidelinesfromthe
Policymoduletogeneratethemessagethatalignswiththeagents’actionsandintentions.
updatestheagent’sbehaviorpolicytoimproveperformance.TheCommunicationmodulehelps
theagentreceivehumanmessagestoadjusttheagent’sbehaviorandsendmessagestothehuman.
4.1 TheoryofMindModule
WithaToMcapability,individualscanformhypothesesaboutthementalstatesofothersasa
beliefthroughtheiractionsandcommunicationhistory,thusunderstandingandpredictingothers’
behaviors[92].BeliefinTheoryofMindreferstoanindividual’scognitionofthings,whichfurther
influencestheirbehavior[11,93,118].Forexample,inourOvercookedenvironment,ifthehuman
playerbelievesthat“mypartnerwillcookthebeef,”thehumanplayermightfocusonothertasks,
assumingthattheirpartnerwilltakecareofthebeef.BasedontheTheoryofMindmechanism,we
designtheTheoryofMindmodule,whichenablestheagenttoestablishthebeliefaboutthehuman,
includingthetendency,convention,andplan,usingthehumanpartner’sbehavioralhistoryand
communicationmessages.12 ZhangandWang,etal.
The human player appears to prioritize completing orders with the
least remaining time, as seen in their actions. They seem to focus on
preparing ingredients first, particularly bread, which indicates a
preference for foundational tasks. The human player may not always
follow the agent's suggestions, suggesting a need for clearer
communication. The agent should align its actions with the human's
focus on urgent orders and ingredient preparation, ensuring that both
players work towards the same goals to enhance efficiency and scoring.
Fig.5. AnexampleofBeliefOutputfromtheTheoryofMindModule.
BasedontheformulationsinSection3.4,wedenotethehistoryfromtime-step0totime-step𝑡
ofthegamethattheagentperceivesas:
H 0:𝑡 = {(𝑠 0,𝑎c 0ontrol,𝑖,𝑎c 0ontrol,ℎ,𝑎c 0omm,𝑖,𝑎c 0omm,ℎ,𝑟 0),
.
.
.
(𝑠 𝑡,𝑎 𝑡control,𝑖,𝑎 𝑡control,ℎ,𝑎 𝑡comm,𝑖,𝑎 𝑡comm,ℎ,𝑟 𝑡)}.
AsshowninFigure4,theTheoryofMindmoduleusesthehistoryH 0:𝑡 asaninputtosummarize
thehistory,inferstheconventionsandtendenciesofthehumanandexplainshowtheagent’s
policycanbeadjustedtocoordinatebetterwiththehumanplayer.TheTheoryofMindmodule
outputsthebeliefinnaturallanguage,asshowninFigure5.Theentireprocesscanbeformalized
asfollows:
𝑏𝑛 =LLM(cid:0) H 0:𝑡𝑛,𝑏𝑛−1(cid:1) , (1)
where𝑡 𝑛isthetime-stepwhenthe𝑛-thbeliefinferencesisperforming.TheTheoryofMindmodule
executesevery75time-steps.
ThecorepromptsusedintheTheoryofMindmoduleareshowninFigures6and7.Toimplement
thewithin-groupconditionintheexperiment,i.e.,whethertheagenthasToMcapabilities,we
implementtheTheoryofMindmoduleasoptional,andwecancontrolwhethertheToMresults
areincludedinthedecision-makingprocess,asshowninFigure4.Whentheconditionisthatthe
agenthasnoToMcapabilities,theToMinferenceprocess(Equation(1))willnotbeexecuted,and
noToMresultsareusedinthePolicymoduleandtheCommunicationmodule.
Considering the communication conditions in our experiments, we use two variables, IN-
FER_HUMAN_WITH_SEND
_MESSAGEandINFER_HUMAN_WITH_RECEIVE_MESSAGEtocontrolwhethertheagentcan
send message to human and whether the AI agent can use the received message to infer hu-
man in Theory of Mind module, as shown in Figure 7. For example, if the conditions are set
sothatbothhumanandagentcannotsendmessagesandtheagenthasToMcapability,theIN-
FER_HUMAN_WITH_SEND_MESSAGEandINFER_HUMAN_WITH_RECEIVE_MESSAGEwill
besettoemptystringstomaketheagentdonotconsiderthehumanmessageandthehuman
responsetotheagent’smessagesintheToMprocess.
4.2 PolicyModule
Ourtaskistime-sensitive,requiringtheagentandhumanplayertomakedecisionsandadjust
theirpoliciesintimetoavoidmissingordersandovercookingthedishes.Duetothereal-timeMutualTheoryofMindinHuman-AICollaboration 13
HUMAN_INFERENCE_OUTPUT_FORMAT:


You should return a new inference on the human player's behavior
pattern in the following code block.

```text

Analyze the past game history and identify patterns or tendencies in
the human player's behavior. Then explain how the agent's policy will
be adjusted to coordinate better with the human player.

Here are some suggestions for writing inference:

What are the human player's preferences in completing orders? For
example, whether the human player prefers to complete orders with the
least remaining time or orders with the most remaining time? This will
help you determine which orders you should focus on to avoid missing
any order and to prevent making extra food.

- How does the human player prioritize tasks when multiple orders are
pending? For example, whether the human player tends to do order by
order or tries to complete multiple orders simultaneously by preparing
multiple ingredients in parallel?

- Which processes does the human player prefer to complete first? For
example, whether the human player prefers to prepare which
ingredients, assemble burgers or serve burgers? This will affect your
choices regarding which tasks to prioritize. For example, when human
player prefers to preparing ingredients, you choose to serve more
dishes can effectively improve team efficiency.

- Consider whether there are any patterns between human player's
behavior, the current orders that need to be completed, and the
ingredients available on the field. For example, humans tend to
prepare a large amount of beef when multiple orders for beef burgers
are needed. Such implicit patterns can help you adjust your own
behavior.

{INFER_HUMAN_WITH_SEND_MESSAGE}

{INFER_HUMAN_WITH_RECEIVE_MESSAGE}

- How the agent's policy should be adjusted to improve performance?

The inference should be given based on the game history.

You should return a text code block. Be concise and clear, less than
100 words.

```
Fig.6. PromptforTheoryofMindModule.
requirement,theagentcannotdirectlyprompttheLLMtogenerateitsnextaction,whichresults
inunacceptablelatency.Besides,LLMsarebetterathigh-levelreasoningandplanninginstead
ofgeneratingdetailedcontrolsignals[116].Therefore,theagentleveragestheLLMtogenerate
high-levelplans,whichwecall“macroactions.”Meanwhile,theagentpromptstheLLMtoreflect
andupdatesomebehaviorguidelinesiteratively.Theagentthentransformsthegeneratedplans
intoactableactions,includingmovingandinteractingwithobjects,whichwecall“atomicactions,”
throughanactionexecutor.
AsshowninFigure4,thePolicymoduleconsistsofthreeparts:Code-as-PolicyGenerator,Policy
Reflection,andActionExecutor.
4.2.1 Code-as-PolicyGenerator. GiventhelatencyinAPIcallswithGPT-4ominiandthereal-time
decision-makingrequirementsofourtask,weimplementaninitialpolicywithpredefinedrules.
Thispolicyisfurtherempoweredbyacode-as-policy[68]generator,whichplaysacrucialrolein
enablingtheagenttoeffectivelyhandlereal-timeemergencies.Ourinitialpolicyisstructuredupon
aFinite-StateMachine(FSM)framework.Thisframeworkisinstrumentalinallowingtheagentto14 ZhangandWang,etal.
INFER_HUMAN_WITH_SEND_MESSAGE:


- How does the human player respond to messages from the agent (you)?
You should consider the human's action after receiving message from
you to infer whether the human player follows the agent's suggestions,
ignores them, or provides feedback on the agent's (your) messages.


INFER_HUMAN_WITH_RECEIVE_MESSAGE:


- What are the propose of human when he/she send a message to you? You
should consider the human's action after sending message to you to
infer whether the human player sends requirements or suggestions, or
explains his or her actions and plans to the agent (you) through
sending messages.
Fig. 7. Prompts as Variables in the Theory of Mind Module. Top is IN-
FER_HUMAN_WITH_SEND_MESSAGEandbuttonisINFER_HUMAN_WITH_RECEIVE_MESSAGE.
operatewithinasetofdefinedstates,transitions,andactions,providingaclearstructureforits
operations.Eachstaterepresentstheagent’sparticularcontextorsituation,whileenvironment
dynamics,fixed25-time-stepintervals,andhumanmessageinputtriggertransitions.TheFSM
structureallowstheagenttocompletetasksbyswitchingbetweenpredefinedstates,allowingitto
functionwithoutrelyingonexternalAPIresponses.
However,itisimpracticaltoexhaustivelydefineallpossiblestatesandtransitionsusingafinite-
statemachine-basedrulepolicy,especiallyincomplexanddynamicallychangingenvironments.To
addressthislimitation,weincorporateaLLMtoenhancethepolicy.WhentheFSMfallsshortin
coveringspecificcomplexorunexpectedscenarios,suchashumanmessages,theLLMcangenerate
flexibleandtemporarystrategies,allowingthesystemtohandleunforeseensituations.TheLLM
generatesJSONcodestooptimizetheinitialpolicy,giventherecentgamehistoryandtheinferred
beliefaboutthehuman.AsdemonstratedinFigure8,theLLMgeneratestwotypesofcodesnippets:
1)ConditionandMacroAction:Themacroactionwillbeexecutediftheconditionissatisfied,
wheretheconditionisusedtoavoidoutdateddecisionscausedbylatency;2)Order:Theagentwill
prioritizethisorder.Themacroactiongenerationprocesscanbeformalizedas:
𝜏
𝑡
=LLM(H𝑡−𝜆:𝑡,𝑏𝑛)
𝑚𝑎 𝑡 =𝜋𝑚(𝑠 𝑡,𝜏 𝑡) ,
where𝑏𝑛 representsthelatestbeliefabouthumanthatisupdated𝑛times,𝜋𝑚
representsthelatest
agentpolicythatisupdated𝑚times,𝜏
𝑡
isthegeneratedcode-as-policyand𝜆istheintervalthe
code-as-policygeneratorexecutes,whichis25inourexperiment.
4.2.2 PolicyReflection. EquippedwiththeFSM-basedinitialpolicyandCode-as-Policygenerator,
theagentalreadyhasthebasiccapabilitytointeractwithhumansinourenvironment.However,the
agentneedstoimproveitspolicyinsuchalong-horizoninteractionprocessforhigherperformance.
Usingthelow-overheadin-contextlearningapproach,theagentmaintainsanditerativelyupdates
a“BehaviorGuideline,”whichsummarizestheimprovementstocurrentpolicy.Aftera“Behavior
Guideline”isgenerated,theagentincorporatesthe“BehaviorGuideline”intothecurrentpolicy.
Theentireprocesscanbeformalizedas:MutualTheoryofMindinHuman-AICollaboration 15
{

("lambda json_state: json_state['objects'][('Fire', '')] > 0",
("putout_fire", {})), # Condition and Marco Action

"BeefBurger", # Order

"BeefLettuceBurger" # Order

}
Fig.8. GeneratedCode-as-PolicyExample.
CODE_AS_POLICY_GENERATION_OUTPUT_FORMAT:


You should return a text code block as your thought.

```text

Be concise and clear, less than 20 words.

If no urgent responses are needed, return "Things are going well".

```


Return a json code block representation of the new assigned tasks that
the agent will do urgently.

```json

Pay attention that the agent will automatically prepare the burger
order with the least remaining time and you should only assign tasks
when changes are necessary.

You can substitute the current assigned tasks with the new ones, i.e.,
you don't need to include the current assigned tasks in the output.

You should make sure that the completed burgers are served to the
customers in time, by letting the agent perform in default mode or
adding serving actions. But do not serve the burgers that are not in
the order list.

You should return an empty list (`[]`) here when the agent can
automatically finish the orders itself and not urgent responses are
needed.

Be careful to write correct lambda functions.

The JSON will be used in Python as `eval(json_string)`, so make sure
it is in the correct format, e.g., use `True` and `False` instead of
`true` and `false`.

```
Fig.9. PromptforCode-as-PolicyGenerator.
B𝑚 =LLM(cid:0) H 0:𝑡𝑚,𝑏𝑛,B𝑚−1(cid:1),
𝜋𝑚 =𝜋𝑚−1∪B𝑚,
where𝑚meansthereflectionprocessexecutes𝑚times,𝑏𝑛
isthelatestinferredbeliefabouthuman,
B𝑚 isthe“BehaviorGuideline”thatisupdated𝑚times.
ThecorepromptsforthereflectionprocessareshowninFigure10,andanoutputexampleis
showninFigure11.
4.2.3 ActionExecutor. Theactionsoutputbythepolicymodulearemacroactions.Theseactions
arethenexecutedbyanactionexecutor,transformingthemintoatomicactionsthatcanbeexecuted16 ZhangandWang,etal.
REFLECTION_OUTPUT_FORMAT:
Please output in parts and in the following template:


You should return new Behavior Guidelines in the following code block.

```text

Analyze the past game history and identify areas for improvement or
successful strategies. Then explain how the agent's policy will be
adjusted based on the reflection.

Here are some suggestions for writing guidelines:

- What leads to the lost of scores, e.g., missed orders and served
wrong food, in the past game?

- What leads to the waste of time in the past game?

- How to adjust the agent's policy to save time?

- What are the successful strategies in the past game?

- How to coordinate with the human player to achieve a higher score?

- How the agent's policy should be adjusted to improve performance?

The guidelines should be given based on the game history.

You should return a text code block. Be concise and clear, less than
100 words.

```
Fig.10. PromptforPolicyReflection.
To improve performance, the agent should focus on preparing
ingredients for the highest priority orders first, especially those
with the least remaining time. Missed orders and serving incorrect
food led to score losses; thus, coordination with the human player is
crucial. The agent should prioritize assembling burgers once
ingredients are ready and communicate clearly about which orders to
focus on. Additionally, the agent should prepare multiple ingredients
in parallel to save time and avoid delays in fulfilling orders.
Fig.11. AnexampleofBehaviorGuidelinesfromtheReflectionModule.
directlyintheenvironment.Theactionexecutoremploysscriptpoliciestocovertmacroactions.
Themacroactionsincludedaresummarizedbelow.
• Prepare:
– ValidObjects:“Beef”,“Lettuce”,“Bread”
– Function:Prepareanappointedingredientuntilitcanbeusedtoassemble.
• Assemble:
– ValidObjects:“BeefBurger”,“LettuceBurger”,“BeefLettuceBurger”
– Function:Assembleanappointedburgerifallnecessaryingredientsareready.
• Passon:
– ValidObjects:“Plate”,“Bread”
– Function:Puttheobjectontothecentercounterstodeliverittothepartner.
• Serve:
– ValidObjects:“BeefBurger”,“LettuceBurger”,“BeefLettuceBurger”
– Function:Deliveranassembledburgertothecustomer.MutualTheoryofMindinHuman-AICollaboration 17
MESSAGE_OUTPUT_FORMAT:


```text

Express your intention as a message to the human player, for example,
what you are planning to do, or what you expect the team to achieve.
You should return a text code block as your message.

Be polite, concise and clear, less than 10 words.

Pay attention that this message is sending to human player by agent
(yourself), so please use "You" to indicate the human player and use
"Us" to indicate the team, use "I" to indicate the agent (yourself).
For example, "I will prepare the LettuceBurger" means the agent
(yourself) will prepare the LettuceBurger, "We need a Bread" means the
team need to prepare a bread.

Note that the human player may not follow the message.

You can return an empty string (`""`) here when no message is needed.

```
Fig.12. PromptforCommunicationModule.
• PutoutFire:
– ValidObjects:-
– Function:Pickupthefireextinguisherandputoutthefire,ifany.
Givenamacroaction,theactionexecutorchoosesapossibleplanandperformspathplanning.
ThepathplanisimplementedusingtheA-staralgorithm[45].Theprocesscanbeformalizedas:
𝑎 𝑡control,𝑖 =Executor(𝑚𝑎 𝑡) .
4.3 CommunicationModule
Communicationisthemostdirectmeansforhumanteamstoexpresstheirintentions.Themessage
sent within the team is the most flexible content for individuals to adjust. To avoid affecting
agentautonomyandtoallowdynamicadjustmentofcommunication,wedonotrequiretheagent
to communicate continuously. Instead, the agent is required to autonomously decide whether
communicationisnecessaryanddeterminethecontentofthecommunication.Thecommunication
messagegenerationprocesscanbepresentas:
𝑎 𝑡comm,𝑖 =LLM(cid:0) H𝑡−𝜂:𝑡,𝑏𝑛,B𝑚(cid:1) ,
where𝑏𝑛 andB𝑚
arethelatestbeliefabouthumansandthelatest“BehaviorGuideline”respectively,
and𝜂istheintervalforthecommunicationprocesstoexecute,whichissetas25inourexperiment.
ThecorepromptforgeneratingcommunicationisshowninFigure12.Weimplementdifferent
communicationconditionsbetweengroupsintheexperiment:thecommunicationprocesswillnot
beexecutedandwillnotoutputanymessageinscenarioswheretheagentcannotcommunicate
withthehuman.
Additionally, under conditions where communication is enabled, each message emergence
fromhumanstriggersthecommunicationprocesstoensurethathumans’explicitcommunicative
intentionsareclearlycaptured.
4.4 ValidationofTheAgentFramework
We conducted a validation experiment to validate the capabilities of the LLM-based agent we
designedandtounderstandtheimpactoftheToMcapabilityonagentperformance.Weusean18 ZhangandWang,etal.
agent with only a policy module as the fixed teammate. Two types of agents, one with a ToM
moduleandonewithout,eachplays10gameswithafixedrule-basedteammateusingthesame
tasksetupasinourmixed-designexperiment.Eachgamelastsfor500timesteps.Sincethefixed
agentteammatelackscommunicationcapabilities,wedonotincludethecommunicationmodule
invalidatingtheagent’sperformance.
TheagentwiththeTheoryofMindmodulehasanaveragescoreof136(StandardDeviation=
25.77),andtheagentwithouttheTheoryofMindmodulehasanaveragescoreof115.5(Standard
Deviation=30.04).Theseresultsconclusivelydemonstratethatourimplementedagentframework
effectivelycompletesthetaskwedesignedinthesharedworkspacesetting,andtheTheoryof
Mindmodulesignificantlyenhancesperformance.
5 Methods
ToinvestigateMToM’seffectsinHATs,especiallytheeffectsofcommunicationinteractivityand
the agent’s ToM capability, we designed a 4x2 mixed-design experiment. The communication
interactivityfactorincludesfourlevelsasbetween-groupvariables:bidirectionalcommunication
(Bi-Comm),human-onlymessagesending(H-Comm),agent-onlymessagesending(A-Comm),and
nocommunication(No-Comm).Wesettheagent’sToMabilityasawithin-subjectcondition.:agent
withToM(w/ToM)andagentwithoutToM(w/oToM).Thiswithin-subjectconditiondirectly
affectswhetherMToMexists.WhentheagentdoesnothaveToMabilities,theMToMprocess
becomesaone-wayToMprocess,whereonlythehumanpossessesToMcapabilities.
5.1 Procedure
Werecruitedparticipantsfromtheuniversityviatheuniversity’sinternalsocialplatform.Each
participantreceived50RMBfortheirparticipation.Wegavetheparticipantsbonusesbasedontheir
performancetomotivatethemtobemoreengagedandattentive.Werankedparticipantsineach
groupbasedontheirself-playperformanceandperformanceintwodifferentagentgames.The
top25%ineachconditionwithinagroupreceivedanadditionalbonusof5RMB.Thebonuscould
beaccumulatedforeachcondition,allowingforamaximumbonusof15RMB.Theexperiments
wereconductedonline,whereeachparticipantcompletedtheexperimentsonacertainwebpage
using a computer with a keyboard and a mouse, and each experiment took about 20 minutes.
Participantscontrolledthechefusingarrowkeysandinteractedwithobjectsusingthespacebar
onthekeyboard.Theycouldissuemessagestotheagentbyclickingbuttonswiththemouse.We
didnotrequirehumanstosendmessagesintheBi-CommandH-Commgroups.Theparticipant
werefreetodecidewhethertosendthemessageornot.Andparticipantswerealsofreetodecide
whethertoadopttheagent’smessagesinA-CommandBi-Commgroups.Werecordedtheentire
experimentalprocessandprovidedplaybacksupportfordatavalidation.
Sinceweusedamixedexperimentaldesign,withthebetween-groupconditionCommunication
(includesfourlevels:Bi-Comm,H-Comm,A-Comm,andNo-Comm),participantswererandomly
assignedtooneofthefourgroups,with20participantsineachgroup.Eachparticipantwasexposed
totwodifferentagents(i.e.,theagentswithandwithoutaToMcapability)withinagroup,with
threetrialsconductedforeachagent,totalingsixtrials.Theexperimentwasconductedinboththe
participants’nativelanguages,ChineseandEnglish.Specifically,toinvestigatewhetherhumans
couldperceivetheagent’sToM,participantswerenotinformedoftheagent’sspecificcapabilities;
theywereonlytoldthatthereweretwotypesofagentsintheexperiment,distinguishedbycolor.
Allparticipantsfirstcompletedaninformedconsentformandreadinstructionsaboutthegame
rules,gameoperations,andcommunicationmethods.Aftertheinstructions,participantsunderwent
anon-scoredtrialtofamiliarizethemselveswiththeenvironment,rules,andoperations,followed
byascoredtrialtoassistwithdatavalidation.Intheformalexperiment,aftereachtrial,weaskedMutualTheoryofMindinHuman-AICollaboration 19
participantstocompleteaquestionnaireinwhichwecollectedtheirperceptionsoftheagentand
theteamcollaboration.TheitemsaremostlybasedonHoffman[48].Thequestionnaireasshown
inAppendixAuseda5-pointLikertscaletoindicatethelevelofagreementwiththestatements.
Afterallsixtrials,participantswereaskedtocompleteanotherquestionnaire,wherewecollected
theirperceptionsofthedifferencesbetweenthetwoagentbehaviorsandtheirpreferencesforthe
agent.Thequestionnairealsoincludedopenquestionsaboutthecommunicationprocess,asshown
inAppendixB.
5.2 Participants
A total of 80 participants participated in the study. The first and second authors of the article
independentlyvalidatedallcollecteddata.Thisvalidationincludedcheckingdatacompleteness
(e.g.,whetherparticipantscompletedalltheexperiments)andreviewingtherecordedplaybacksto
identifyanyabnormalactions(e.g.,instanceswhereparticipantsdidnotengageinanycooperative
behavior).Afterdatavalidation,weexcludedanydatawithanomalies,includingpassivepartici-
pationandmissingdata,resultingin68validparticipants(M=46,F=22,andOthers=0,ages
between18and34).ThestatisticsforthevaliddataareshowninTable3.
Table3. NumbersoftheParticipantsinEachGroup.
Group Bi-Comm H-Comm A-Comm No-Comm
NumbersofParticipants 16 17 17 18
5.3 DataAnalysis
Consideringindividualrandomdifferences,weconductedaregressionanalysisusingamixed-
effectslinearmodel[54,90]toexaminefixedeffectsandcontroltherandomeffectsofindividual
differences.Additionally,weutilizedbootstrappingtechniques[81](SampleSize=2000)toenhance
therobustnessofourestimates[31,32],ensuringgreateraccuracyandreliabilityinthepresence
of non-normality or small sample sizes. We considered the main effects of the two conditions,
communicationinteractivity,agent’sToMcapability,andtheirinteractioneffects,andappliedthe
Bonferronicorrection[82]foranalysis.
Fortheopenquestions,thefirstauthorandthesecondauthorfirstthoroughlyreadthetextdata
fromtheopenquestionsandconductedthematicanalysis[22].Subsequently,bothtwoauthors
independentlycodedthedataandthenreachedaconsensusthroughrepeateddiscussionswithall
authors.
6 Results
Weanalyzedthetaskmetrics,includingperformance,contributionrate,failurecount,andmessage
count,aswellasthesubjectivescaleoftheparticipant’sperceptionoftheirAIteammates.Wealso
obtainedqualitativeresultsfromsubjectivehumananswerstothequestionsaftertheexperiment.
6.1 TeamPerformance
To answer RQ1 (How does the MToM process influence the overall team performance of HATs?),
wefirstanalyzedtheimpactoftwoindependentvariablesonteamperformance,usingthebest
performanceasthedependentvariable.Thebestperformancereferstothemaximumvalueof
repeatedmeasurements,whichcaneliminatetheinfluenceoflow-leveloutliersontheresultswhen
thelearningeffectexistsandthetaskiscomplex.IntheBi-Commgroup,themeanscoreforthe20 ZhangandWang,etal.
Overall Task Score Agent Contribution Rate Statement: I feel the agent understand me
240 5
220 0.7
4
200 0.6
180
3
160 0.5
140 2
0.4
120
1
Bi-Comm H-Comm A-Comm No-Comm Bi-Comm H-Comm A-Comm No-Comm Bi-Comm H-Comm A-Comm No-Comm
Group Group Group
w/ MToM w/o MToM w/ MToM w/o MToM w/ MToM w/o MToM
(a) TheBestTeamPerformance. (b) AgentContributionRate. (c) PerceptiononHowAgentUnderstand
Human.
Fig.13. TheOverviewoftheEmpiricalResultsinOurExperiments.Theboxplotincludesthemedian
anddistributionofthedependentvariables,includingbestteamperformance,agentcontributionrate,and
humanperceptionofhowagentsunderstandhumans.
agentw/oToMwas163.75(SD=26.17),whiletheagentwithToMscored165.00(SD=35.02).In
theA-Commgroup,themeanperformancescorewas168.53(SD=22.83)fortheagentwithout
ToMand169.71(SD=27.18)fortheagentwithToM.IntheH-Commgroup,themeanscorewas
175.59(SD=19.19)fortheagentwithoutToMand168.53(SD=22.76)fortheagentwithToM.
IntheNo-Commgroup,theagentwithoutToMhadameanscoreof177.22(SD=25.62),andthe
agentwithToMachievedahighermeanscoreof180.83(SD=18.09).Themedianandstandard
deviationofthebestperformanceofthesubjectsundereachconditionareshowninFigure13(a).
Regardingthecommunicationfactor,GroupNo-Commscoredthehighest,GroupBi-Commscored
thelowest,andtherewaslittledifferencebetweenGroupH-CommandGroupA-Comm.Within
eachgroup,therewerenosignificantdifferencesinthebestperformancebasedonwhetherMToM
exits(i.e.,agentw/ToMandw/oToM).
6.2 TeamCollaborationProcess
Inadditiontothescores,werecordedothermetricsduringthecollaborationprocesstoanswer
RQ2(HowdoestheMToMprocessaffecttheteamcollaborationprocess?).
WhenMToMwaspresent(agentw/ToM),fixedeffectsestimationshowsthatthecontribution
rateoftheAIagent𝐶𝑅
𝐴
increasedby0.02(𝑝 <0.001,Cohen’s𝑑 =0.169)comparedtoagentw/o
ToMcondition.Differencesincommunicationinteractivityconditionshadnosignificantimpacton
theAIagent𝐶𝑅 𝐴.ThemediananddistributionoftheAgentContributionRateareillustratedin
Figure13(b).AsfortheFailureCount,theBi-Commgroupshowedadifferencecomparedtothe
H-Commgroup,withanaverageincreaseof0.77(p<0.01).
WefurtherexaminedtheimpactofMToMonthefrequencyofcommunication.Wefoundthat
inbothBi-CommandH-Commgroupswherehumanswereallowedtosendmessages,thevast
majority of participants sent fewer than one message on average. Only one participant in the
H-Commgroupsentalargenumberofmessages(>15timesinagame).Allparticipantsrarely
usednon-item-relatedmessages(“GoodJob”and“NeedImproved”)towardtheagent.Amongall
participants,onlyonepersonusedthe“GoodJob”messageduringonegame.
Inourqualitativeanalysisoftheopenquestions,participantsinthegroupwherehumanscould
sendmessagesreportedthatsendingmessagesincreasedworkloadandnegativelyimpactedtheir
taskperformance.Thisresultalignswiththemessagecountstatistics,whichshowthathumans,
erocS
ksaT
etaR
noitubirtnoC tnemeergAMutualTheoryofMindinHuman-AICollaboration 21
focusingongameoperations,chosetoforgocommunicationwiththeagent.Atthesametime,
inthegroupwherehumanscouldsendmessages,participantsreportedthatsendingmessages
negativelyimpactedtheirtaskperformance.Inthegroupswheretheagentcouldsendmessages,
thevastmajorityofparticipantsreportedintheopenquestionsthatitwashardtopayattention
totheagent’scommunicationandthattheyweremorefocusedontheagent’sactions.Asimilar
situationwasobservedintheopenquestioninthegroupswheretheagentcouldnotsendmessages.
Incontrast,participantsreportedthattheyfocusedontheagent’sactionstoinferitsintentions
andadjustedtheirbehavioraccordingly.
Inourqualitativeanalysisoftheopenquestions,whenparticipantstrytounderstandtheagent,
theytendtofocusonwhethertheagent’sbehaviorcanbecategorizedaslogicalorconsistent.
Whenaskedhowtheyconsideredtheagentunderstoodthem,moreparticipantstendedtoconsider
howwelltheagentwascoordinatingwiththem.Forexample,mostparticipantsfeltthattheagent
complementedtheiractionsanddidnotrepeatthesametasksastheybetterunderstoodthem.
Theparticipantswhowereabletoreadtheagent’smessagesmentionedthattheagent’smessages
directlyhelpedreduceunnecessarywork,astheywouldavoidperformingtasksthattheagenthad
indicateditwasalreadyhandling.
6.3 HumanPreferenceandPerceptionsofAIAgents
ForRQ3(HowdohumansperceiveAIteammatesintheMToMprocess?),wecollecttheparticipants’
perceptionsoftheagentineachgameandtheirpreferenceforthetwoagents.Thevastmajorityof
participantsreportedthattheycouldsensethedifferencebetweenthetwoagents(94%inBi-Comm,
94%inH-Comm,88%inA-Comm,77%inNo-Comm).Thevastmajorityofparticipantsshowed
consistencyacrossthefourpreferencequestions(whichagentunderstandsmebetter,whichagentI
understandbetter,whichagentIworkbetterwith,andwhichagentIprefer),withalltheirindividual
preferencesbeingaligned(i.e.,preferthesameagentinthesefourquestions).Onlyaminimal
numberofparticipantsexhibitedslightdifferencesintheirpreferences.Theimpactofdifferent
levelsofcommunicationinteractivityonhumanpreferencewasnotstatisticallysignificant.We
visualizedthecorrelationbetweenparticipants’scoresandtheirpreferencefortheagentineach
group.AsshowninFigure14,intheBi-Comm,H-Comm,andNo-Commgroups,thebetterthe
participants’scores,thestrongertheirpreferencefortheagentwithToMabilities.Theregression
slopewassteepestintheNo-Commgroup.Interestingly,theA-Commgroupshowedtheopposite
result:participantswithhigherscoresmayprefertheagentwithoutToMabilities.Whileithas
atrendintherelationshipbetweenteamperformanceandhumanpreferenceonagentw/ToM,
theseresultsarenotstatisticallysignificantinthepoint-biserialcorrelationcoefficient[15]tests.
Inadditiontopreferences,wecollectedparticipants’perceptionsofeachgameafteritended
usingspecificstatementsbasedon[48].Duringtheexperiment,allparticipantswereunawareof
whichagenthadToMabilities.Weusedagreementlevelswithstatementstocollectparticipants’
perceptionsoftheagent’sToMabilitiesandtheextentofthoseperceptions.Forthestatement
“Ifeeltheagentunderstandsme,”anoticeabledifferencewasobservedineachgroupasshown
in Figure 13(c). We conducted a fixed effectstest on all results, and participantsin each group
perceivedthattheagentwithToM(w/MToMcondition)understoodthembetter(p<0.001,Cohen’s
d=0.336).Forthestatement“Iunderstandtheagent,”therewasasignificantmaineffectbetween
w/MToMandw/oMToM(p<0.001),buttheeffectsizewassmall(Cohen’sd=0.177),notreaching
thethresholdforasmalleffect.Thedetailedresultsofthequestionnairesweusedintheexperiment
canbefoundinAppendixA.
Wecombinedthequalitativeresultsfromtheopenquestionstounderstandhumanperceptions
oftheagent’sToMcapability.Ourqualitativeanalysisresultsindicatethattheinteractivityof
communicationimpactsthehumanmentalmodelofagents.Insituationswhereparticipantsare22 ZhangandWang,etal.
Bi-Comm Bi-Comm Bi-Comm
140 160 180 200 140 160 180 200 140 160 180 200
Task Score Task Score Task Score
(a) Preference for Agent Playing (b) PreferenceforBetterUnderstand (c) PreferenceforBetterCollabora-
with. Human. tion.
H-Comm H-Comm H-Comm
140 160 180 200 140 160 180 200 140 160 180 200
Task Score Task Score Task Score
(d) Preference for Agent Playing (e) PreferenceforBetterUnderstand (f) PreferenceforBetterCollabora-
with. Human. tion.
A-Comm A-Comm A-Comm
140 160 180 200 140 160 180 200 140 160 180 200
Task Score Task Score Task Score
(g) Preference for Agent Playing (h) PreferenceforBetterUnderstand (i) PreferenceforBetterCollabora-
with. Human. tion.
No-Comm No-Comm No-Comm
150 160 170 180 190 200 210 150 160 170 180 190 200 210 150 160 170 180 190 200 210
Task Score Task Score Task Score
(j) Preference for Agent Playing (k) PreferenceforBetterUnderstand (l) PreferenceforBetterCollabora-
with. Human. tion.
Fig.14. ThedistributionofTeamScoreandPreferenceofthew/ToMAgentinEachGroup.Each
chart’shorizontalaxisshowsthe“TaskScore,”andtheverticalaxisrepresentsthe“PreferenceforAgentw/
ToM.”Thecurveinthemiddleisaregressionlineillustratingthetrendbetweentaskscoreandpreference,
withtheshadedareaindicatingthe95%confidenceinterval.Scatterpointsrepresentindividualparticipants’
scoresandpreferences.Theplotsonthetopandrightsideshowmarginaldensitydistributionsoftaskscores
andpreferences.
MoT
/w
tnegA
rof
ecnereferP
MoT
/w
tnegA
rof
ecnereferP
MoT
/w tnegA
rof
ecnereferP
MoT
/w tnegA
rof
ecnereferP
seY
oN
seY
oN
seY
oN
seY
oN
MoT
/w
tnegA
rof
ecnereferP
MoT
/w
tnegA
rof
ecnereferP
MoT
/w tnegA
rof
ecnereferP
MoT
/w tnegA
rof
ecnereferP
seY
oN
seY
oN
seY
oN
seY
oN
MoT
/w
t sn ee YgA
rof
ecner
oNeferP
MoT
/w
tne
sg eA Y
rof
oe NcnereferP
MoT
/ sw e YtnegA
rof
oNecnereferP
MoT
/ sw e YtnegA
rof
ecne
or NeferPMutualTheoryofMindinHuman-AICollaboration 23
unawareofwhethertheagentpossessesToMabilities,thoseintheH-CommandBi-Commgroups
sent messages reporting that the agent with ToM capability could follow their instructions to
completethenecessarytasksandfoundthebehavioroftheToMagenttobemoreunderstandable.
Thisresultindicatesthathumans’understandingofanagentmightdependonwhethertheagent
meetstheirexpectations(mentalmodels).
MToMalsoinfluenceshumanperceptionofgamedifficulty.WhentheagentpossessesToM
abilities,itmakeshumansperceivethegameaseasierinboththeBi-CommandH-Commgroups.
Based on the analysis of the open questions in these two groups, when the agent is easier to
understand,itreduceshumans’perceptionoftaskdifficulty,evenifthereisnosignificantdifference
inthefinaltaskperformance.
7 Discussion
Duetothesharedworkspacesetup,thereisacloseconnectionbetweenthetasksandactionsof
theAIagentandthehumanparticipant.Weutilizedreal-timetaskstorelaxtheassumptionof
strictcollaboration,movingtowardsamorerealisticmodelofcooperation[96],suchashuman-
AI collaboration in household tasks [14]. In this section, we discuss the results of our studies,
offeringinsightsintothefuturedesignofAIagentswithToMcapabilitytocollaboratewithhuman,
especiallythosepoweredbyLLMs.
7.1 TeamPerformanceinReal-timeSharedWorkspaceTask
OurexperimentalresultsdemonstratethattheMToMprocessimpactsHATs.Moreover,thereisan
interactioneffectbetweencommunicationinteractivityandMToMontheperformanceofHATs.
Inourexperiments,themaineffectsofcommunicationinteractivityarestatisticallysignificant
onteamperformance.TheNo-CommGroupperformsbetterthanotherconditions.Webelieve
complexlanguagecommunicationinteractionsmayreduceordistracthumanperformance.In
supportofthishypothesis,teamsintheBi-CommgroupresultinahigherFailureCountthanthe
H-Commgroup.Additionally,thequalitativeresultssuggestthathumansmayadjusttheiractions
basedmoreontheagent’sbehaviorratherthandirectverbalcommunication,whichisclosely
relatedtothedirectobservationofbehaviorsinasharedworkspace[29].Thisresultalignswith
previousfindingsontherelationshipbetweenbidirectionalcommunicationandtaskload[53],as
messagestendtoincreasethehuman’staskload.
Theagent’sToMabilitydidnotsignificantlyimpacttheteam’sobjectiveperformancebutdid
reduceinstancesofcooperationfailure.Thisresultissimilartopreviousstudiesonagentsexpressing
their intentions to humans [61]. As for communication interactivity, complex communication
interactivity can affect performance due to its impact on human operations. Since we did not
enforcestrictcooperation[4,96],thedetailedcollaborativeprocessdoesnotdirectlyorabsolutely
affecttheteam’sobjectivescore.Instead,theMToMprocesshasagreaterinfluenceonthespecifics
oftheteamcollaborationprocessandhumanperception.
SomestudieshavepointedoutthatthedesignofthecommunicationinterfaceaffectsHATs[57].
Moreover,ourresultsmakeusreconsiderthedouble-sideimpactsofverbalcommunicationin
sharedworkspaceswhenhumansandAIagentsfacereal-timetasks.Whileverbalcommunication
canconveythemostpreciseinformation,theoperationalburdenitbringsmaybeanessential
pointforfutureresearchtoaddresswhenMToMexists.
7.2 HowDoHumansUnderstandTheAgentinMToMProcess?
In our results of communication interactivity, we found that in real-time tasks within shared
workspaces, humans are more inclined to use implicit communication in collaboration. When24 ZhangandWang,etal.
MToMispresent,non-verbalcommunicationcanbejustaseffectiveasverbalcommunicationin
real-timetaskswithinsharedworkspaces.
Theexperiment’sresultsregardingcommunicationmessageamountindicatethatinreal-time
sharedworkspacetasks,humanscanalmostnotinitiateverbalcommunicationasexplicitlyas
communication with an agent. This leads humans to rely on the agent’s behavior for implicit
communicationandpotentiallywanttheagenttocommunicateinthesameway.WhenMToMis
present,ourqualitativefindingsshowthattheagent’sabilitytoadjustbasedonhumanactionsis
morehelpfulinaidinghumanunderstanding.Thisresulthighlightstheimportanceoftheagent’s
actionresponsesinhumans’constructionofamentalmodeloftheagent.Ourfindingscomplement
previousworkthatenforcedtheuseofimplicitcommunicationintheforcedcooperationscenario
[67], confirming the effectiveness of implicit non-verbal communication in a broader range of
scenarios.
Wealsofoundthathumanshavedifferentpatternsofunderstandingtheagent.Ourqualitative
study identified two distinct patterns of how humans understand the agent. The first is based
on whether there are recognizable patterns in the agent’s actions, such as “whether the agent
consistentlyperformsactionBrightafteractionA”.Thesecondpatternfocusesonwhetherthe
agent is dedicated to a higher-level division of labor, such as “the agent prefers cooking beef
sinceIamfocusingonchoppinglettuce.”Basedonthefirstpattern,humansdonotpayattention
totheagent’shigher-levelstrategiesorwhethertheagentismakinginferencesabouthumans.
Thesecondpattern,whichinvolvestheagent’sdivisionoflabor,leadshumanstofocusmoreon
whethertheagentalignswiththeirexpectationsofitsbehavior.HumansuseToMtobuildabelief
abouttheagent’sToMinthispattern,i.e.,anunderstandingbasedonthehigher-leveldivision
oflaborinvolveshigher-orderToMinferences(i.e.,“IthinkyouthinkIthink...”)abouttheagent.
Suchdifferencesmayhavecomplexcauses.Webelievethesedifferencescouldstemfromhumans’
inherentperceptionsoftheagentorpre-existingmentalmodelsformedbasedonotherexperiences
[38].Infutureresearch,furtherexploringwhichpatternshumansactuallyrelyonintheirToM
processwithagentswillhelprefineandadjustagentbehaviorduringthedevelopmentprocess.
Thereisalsogreaterroomforexplorationinmodelinghigher-orderToMprocesses[118]toimprove
theagents’understandingofhumans.
7.3 HowDoHumansPerceiveTheAgent’sToMCapability?
Inourresults,mostparticipantsreportedbeingabletoperceivedifferencesbetweenthetwoagents,
buttheycouldnotaccuratelyidentifywhichagentbetterunderstoodhumans.Humanperception
oftheagent’sToMabilitiesmayrelymoreonteamperformanceorhumanskilllevelonthetask.
Thereissomecorrelationbetweenteamscoresandhumanpreferencesfortheagent.Although
lackingstatisticalsignificance,wecanstillobserveatrend:thehighertheteamscore,themore
humanspreferagentswithToMabilities.ThesteepregressionslopeintheNo-Commgroupimplies
thatparticipantsreliedheavilyontheagent’sactionstoinferunderstandingandcapabilitiesin
theabsenceofcommunication.ThestrongpreferencefortheToM-enabledagentinthisgroup
suggeststhatToMabilitiesareespeciallyvaluablewhenexplicitcommunicationisunavailable,as
theagent’sbehaviorbecomestheprimarychannelthroughwhichhumansassesscoordination.
Weregardthatbetterteamperformancemayindicatethatthehumanparticipantshavehigher
skilllevels.Humanswithhigherskilllevelsmayhaveadifferentunderstandingoftheagent’s
behavior.ThesepreferenceresultssuggestthatinfuturedesignsofToM-enabledagents,human
skilllevelsshouldalsobeincorporatedintotheagent’sbeliefsystem,allowingtheagenttoadjust
itsbehaviorbasedonthehuman’sskilllevel.MutualTheoryofMindinHuman-AICollaboration 25
7.4 ChallengesofLLM-drivenAIAgentinHATs
InourvalidationoftheLLM-drivenagents’capability,theToM-enabledagentsignificantlyout-
performsthenon-ToMagentwhenpairedwithafixedrule-basedteammate,demonstratingthe
effectiveness of using LLMs to build ToM capabilities. However, our participants still reported
severalclearstrategicerrorsbytheagentintheopenquestions,suchasnotprioritizingserving
dishesbasedontheurgencyoftheorders.ThisphenomenonindicatesthattheLLM’splanning
capabilitiesarestillsomewhatdifferentfromhumans’expectations.
Inouropenquestions,participantsalsoprovidefeedbackregardingtheagent’slanguageand
actionresponses.Inthegroupswheretheagentcouldsendmessages(A-CommandBi-Comm),
someparticipantsreportedinconsistenciesbetweentheagent’swordsandactions.Theseissues
suggestthatthehallucinationprobleminLLMs[49]maynegativelyinfluenceLLM-basedToM
capability.Inmorecomplexandpotentiallydangeroustaskslikedriving[19,23],hallucinations
couldposeharmtohumans.Itis,therefore,essentialtoconsiderprotectivemechanismsinfuture
LLM-drivenagentframeworks,especiallywithMToM.
Moreover,ourresultsmaysuggestthatbuildingagentswithlanguagecommunicationcapability
needstoconsiderhumancognitiveloadinreal-timetasks,andnon-verbalcommunicationdoesnot
necessarilyimplyaninabilitytocoordinatewithhumans.Somestudiesonconversationalagents
haveshownthathumansstillengageinasignificantamountofnon-verbalcommunicationwhen
usingdialogueassistants,indicatingaclearneedfornon-verbalcommunicationbetweenhumans
andagents[18].InthefuturedesignofLLMagents,enhancingthenon-verbalcommunication
abilitiesofLLM-drivenAIagentsisworthexploring.
7.5 LimitationsandFutureWorks
Ourstudyhasthefollowinglimitations.First,theexperimentwasconductedonline,makingit
subjecttonetworkfluctuations,anditwasdifficulttomonitorparticipants’specificbehaviorsfully.
Weuseddatavalidationtechniquestomitigatethisimpact.Second,sinceourexperimentwasset
inareal-timesharedworkspacetask,theagent’sreal-timeoperationsandcommunicationwere
highlydemanded.LLMsstillfacesignificantlimitationsinreal-timeresponsiveness,andsomeother
experimentshaveusedpausingorsimilarmethodstoalleviatethisissue[70].However,pausing
affectsthetaskloadandhumanperception[44].Weusedthecode-as-policy[68]techniqueto
addressthereal-timechallenge,butthismayhaveimpactedtheflexibilityoftheagents’strategy.
WeconsiderthisanimportantresearchissueforfutureLLMagents.
ThecurrentresearchonMToMinhuman-AIcollaborationtendstofocusmoreonpracticalap-
plications,whilethecommunitystillneedsstudiesontheunderlyingMToMprocesses.Inaddition
toconductingpreliminaryinvestigationsintotheimpactofmechanismsthroughexperiments,we
havealsodevelopedasharedworkspacetaskexperimentplatformandagentswithMToMcapabili-
tiestofacilitatefutureresearchonMToMprocesses.Ourcurrentexperimentalresultssuggestthat
furtherexploringmulti-levelrecursiveToMprocessesmayhelpunderstandwhyhumansattribute
certainmentalstatestoagents.Asforagents’ToMcapabilities,ourtaskformulationandplatform
constructioncansupporttestingmorecomplexagentToMframeworksandpotentiallyextendto
moreembodiedintelligencesystems.
8 Conclusion
ThisworkexploredtheMToMprocessinhuman-AIcollaborationwithareal-timetaskinashared
workspace.WefirstproposedasharedworkspacecollaborationtaskbasedontheOvercooked
gameandusedanLLMtobuildanagentwithToMandcommunicationabilitiestoexperiment.
Throughanonlinestudy(n=68),participantscollaboratedwithToM-enabledandnon-ToMagents26 ZhangandWang,etal.
under different communication interactivity conditions in the shared workspace collaboration
task.Wefoundthatinreal-timetaskswithinsharedworkspaces,theagent’sToMabilitiescan
enhancehumans’understandingoftheagentandmakepeoplefeelunderstood.However,they
didnotsignificantlyimpactteamperformance.WefoundthattheBi-Commgroupwiththebest
communicationinteractivityperformedtheworstinteamtasks.Theseobjectiveresultsalignwith
participants’reportsthatverbalcommunicationduringinteractioncausedexcessiveoperational
andinformationalburdens.WealsofoundthathumansinHATsrelymoreontheagent’sactions
tounderstandtheagentthanonverbalcommunication.Wealsofoundacorrelationbetweenteam
performanceandhumanpreferencesregardingtheirperceptionoftheagent.Thispaperadoptsan
MToMperspectivetounderstandtheinteractionbetweenhumanandagentToMcapabilitiesin
human-AIcollaboration,providingnewinsightsforfutureAIagentToMcapabilitydesign.We
believethatwhenconsideringtheagent’sToMcapabilityinthefuture,non-verbalcommunication
demonstratedbytheagentthroughToM(suchaspurposefulactions)inreal-timesharedworkspace
tasksisjustasimportantasverbalcommunication.Furthermore,thehumanunderstandingofthe
agent’sToMprocessmayinvolvemulti-levelToM,whichshouldbeincorporatedintothedesignof
theagent’sToMinthefuture.
Acknowledgments
TheauthorsthankYangLi,ChaoranLi,YiweiShi,ShihanFuandYuxuanLufortheirkindlyhelp
inpaperwriting.
References
[1] GatiVAher,RosaIArriaga,andAdamTaumanKalai.2023. Usinglargelanguagemodelstosimulatemultiple
humansandreplicatehumansubjectstudies.InInternationalConferenceonMachineLearning.PMLR,337–371.
[2] StefanoVAlbrechtandPeterStone.2018.Autonomousagentsmodellingotheragents:Acomprehensivesurveyand
openproblems.ArtificialIntelligence258(2018),66–95.
[3] MichaelArgyle.1972.Non-verbalcommunicationinhumansocialinteraction.Non-verbalcommunication2,1(1972).
[4] ZahraAshktorab,CaseyDugan,JamesJohnson,QianPan,WeiZhang,SadhanaKumaravel,andMurrayCampbell.
2021.EffectsofCommunicationDirectionalityandAIAgentDifferencesinHuman-AIInteraction.InProceedings
ofthe2021CHIConferenceonHumanFactorsinComputingSystems(<conf-loc>,<city>Yokohama</city>,<coun-
try>Japan</country>,</conf-loc>)(CHI’21).AssociationforComputingMachinery,NewYork,NY,USA,Article238,
15pages. https://doi.org/10.1145/3411764.3445256
[5] ZahraAshktorab,Q.VeraLiao,CaseyDugan,JamesJohnson,QianPan,WeiZhang,SadhanaKumaravel,andMurray
Campbell.2020.Human-AICollaborationinaCooperativeGameSetting:MeasuringSocialPerceptionandOutcomes.
Proc.ACMHum.-Comput.Interact.4,CSCW2,Article96(oct2020),20pages. https://doi.org/10.1145/3415167
[6] GaganBansal,BesmiraNushi,EceKamar,WalterSLasecki,DanielSWeld,andEricHorvitz.2019.Beyondaccuracy:
Theroleofmentalmodelsinhuman-AIteamperformance.InProceedingsoftheAAAIconferenceonhumancomputation
andcrowdsourcing,Vol.7.2–11.
[7] Cristian-PaulBara,SkyCH-Wang,andJoyceChai.2021.MindCraft:TheoryofMindModelingforSituatedDialogue
inCollaborativeTasks.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,
Marie-FrancineMoens,XuanjingHuang,LuciaSpecia,andScottWen-tauYih(Eds.).AssociationforComputational
Linguistics,OnlineandPuntaCana,DominicanRepublic,1112–1125. https://doi.org/10.18653/v1/2021.emnlp-main.85
[8] AlessioBaratta,AntonioCimino,MariaGraziaGnoni,andFrancescoLongo.2023.HumanRobotCollaborationin
Industry4.0:aliteraturereview.ProcediaComputerScience217(2023),1887–1895.
[9] SimonBaron-Cohen.1997.Mindblindness:Anessayonautismandtheoryofmind.MITpress.
[10] SimonBaron-Cohen.1999.Theevolutionofatheoryofmind.na.
[11] SimonBaron-Cohen,AlanMLeslie,andUtaFrith.1985.Doestheautisticchildhavea“theoryofmind”?Cognition
21,1(1985),37–46.
[12] BrendaBenninghoff,PhilippKulms,LauraHoffmann,andNicoleCKrämer.2013.Theoryofmindinhuman-robot-
communication:Appreciatedornot?KognitiveSysteme2013,1(2013).
[13] DanielSBernstein,RobertGivan,NeilImmerman,andShlomoZilberstein.2002.Thecomplexityofdecentralized
controlofMarkovdecisionprocesses.Mathematicsofoperationsresearch27,4(2002),819–840.MutualTheoryofMindinHuman-AICollaboration 27
[14] AnthonyBrohan,YevgenChebotar,ChelseaFinn,KarolHausman,AlexanderHerzog,DanielHo,JulianIbarz,Alex
Irpan,EricJang,RyanJulian,etal.2023. Doasican,notasisay:Groundinglanguageinroboticaffordances.In
Conferenceonrobotlearning.PMLR,287–318.
[15] JamesDeanBrown.2001.Point-biserialcorrelationcoefficients.Statistics5,3(2001),12–6.
[16] MicahCarroll,RohinShah,MarkKHo,TomGriffiths,SanjitSeshia,PieterAbbeel,andAncaDragan.2019.Onthe
utilityoflearningabouthumansforhuman-aicoordination.Advancesinneuralinformationprocessingsystems32
(2019).
[17] PeterCarruthersandPeterKSmith.1996.Theoriesoftheoriesofmind.Cambridgeuniversitypress.
[18] SzeyiChan,ShihanFu,JiachenLi,BingshengYao,SmitDesai,MirjanaPrpa,andDakuoWang.2024.Humanand
LLM-BasedVoiceAssistantInteraction:AnAnalyticalFrameworkforUserVerbalandNonverbalBehaviors.arXiv
preprintarXiv:2408.16465(2024).
[19] LongChen,OlegSinavski,JanHünermann,AliceKarnsund,AndrewJamesWillmott,DannyBirch,DanielMaund,
andJamieShotton.2024. DrivingwithLLMs:FusingObject-LevelVectorModalityforExplainableAutonomous
Driving.In2024IEEEInternationalConferenceonRoboticsandAutomation(ICRA).14093–14100. https://doi.org/10.
1109/ICRA57147.2024.10611018
[20] EftychiosGChristoforou,AndreasSPanayides,SotirisAvgousti,PanicosMasouras,andConstantinosSPattichis.
2020.Anoverviewofassistiveroboticsandtechnologiesforelderlycare.InXVMediterraneanConferenceonMedical
andBiologicalEngineeringandComputing–MEDICON2019:ProceedingsofMEDICON2019,September26-28,2019,
Coimbra,Portugal.Springer,971–976.
[21] NancyCooke,MustafaDemir,andLixiaoHuang.2020. Aframeworkforhuman-autonomyteamresearch.In
EngineeringPsychologyandCognitiveErgonomics.CognitionandDesign:17thInternationalConference,EPCE2020,
HeldasPartofthe22ndHCIInternationalConference,HCII2020,Copenhagen,Denmark,July19–24,2020,Proceedings,
PartII22.Springer,134–146.
[22] JulietCorbinandAnselmStrauss.2014. BasicsofQualitativeResearch:TechniquesandProceduresforDeveloping
GroundedTheory.Sagepublications.
[23] YaodongCui,ShuchengHuang,JiamingZhong,ZhenanLiu,YutongWang,ChenSun,BaiLi,XiaoWang,andAmir
Khajepour.2024.DriveLLM:ChartingthePathTowardFullAutonomousDrivingWithLargeLanguageModels.IEEE
TransactionsonIntelligentVehicles9,1(2024),1450–1464. https://doi.org/10.1109/TIV.2023.3327715
[24] MaryamBanitalebiDehkordi,RedaMansy,AbolfazlZaraki,ArpitSingh,andRossitzaSetchi.2021.Explainabilityin
Human-RobotTeaming.ProcediaComput.Sci.192,C(jan2021),3487–3496. https://doi.org/10.1016/j.procs.2021.09.122
[25] MustafaDemir,NathanJ.McNeese,andNancyJ.Cooke.2016. Teamcommunicationbehaviorsofthehuman-
automationteaming.In2016IEEEInternationalMulti-DisciplinaryConferenceonCognitiveMethodsinSituation
AwarenessandDecisionSupport(CogSIMA).28–34. https://doi.org/10.1109/COGSIMA.2016.7497782
[26] MustafaDemir,NathanJMcNeese,andNancyJCooke.2017. Teamsituationawarenesswithinthecontextof
human-autonomyteaming.CognitiveSystemsResearch46(2017),3–12.
[27] MustafaDemir,NathanJ.McNeese,andNancyJ.Cooke.2020. Understandinghuman-robotteamsinlightof
all-humanteams:Aspectsofteaminteractionandsharedcognition.InternationalJournalofHuman-ComputerStudies
140(2020),102436. https://doi.org/10.1016/j.ijhcs.2020.102436
[28] SandraDevinandRachidAlami.2016. Animplementedtheoryofmindtoimprovehuman-robotsharedplans
execution.In201611thACM/IEEEInternationalConferenceonHuman-RobotInteraction(HRI).IEEE,319–326.
[29] PaulDourishandVictoriaBellotti.1992.Awarenessandcoordinationinsharedworkspaces.InProceedingsofthe
1992ACMconferenceonComputer-supportedcooperativework.107–114.
[30] EDWARD J. DOWNES and SALLY J. McMILLAN. 2000. Defining Interactivity: A Qualitative Identification
of Key Dimensions. New Media & Society 2, 2 (2000), 157–179. https://doi.org/10.1177/14614440022225751
arXiv:https://doi.org/10.1177/14614440022225751
[31] PierreDragicevic.2015.HCIStatisticswithoutp-values.Ph.D.Dissertation.Inria.
[32] PierreDragicevic.2016.FairstatisticalcommunicationinHCI.ModernstatisticalmethodsforHCI(2016),291–330.
[33] MaurizioFaccio,IreneGranata,AlbertoMenini,MattiaMilanese,ChiaraRossato,MatteoBottin,RiccardoMinto,
PatrikPluchino,LucianoGamberini,GiovanniBoschetti,etal.2023.Humanfactorsincobotera:areviewofmodern
productionsystemsfeatures.JournalofIntelligentManufacturing34,1(2023),85–106.
[34] MetaFundamentalAIResearchDiplomacyTeam(FAIR)†,AntonBakhtin,NoamBrown,EmilyDinan,Gabriele
Farina,ColinFlaherty,DanielFried,AndrewGoff,JonathanGray,HengyuanHu,etal.2022.Human-levelplayinthe
gameofDiplomacybycombininglanguagemodelswithstrategicreasoning.Science378,6624(2022),1067–1074.
[35] ShuangFengandGraceFeng.2024.AnExtremelyData-efficientandGenerativeLLM-basedReinforcementLearning
AgentforRecommenders.arXivpreprintarXiv:2408.16032(2024).
[36] JohnHFleming,JohnMDarley,JamesLHilton,andBrianAKojetin.1990.Multipleaudienceproblem:Astrategic
communicationperspectiveonsocialperception.Journalofpersonalityandsocialpsychology58,4(1990),593.28 ZhangandWang,etal.
[37] SusanR.Fussell,RobertE.Kraut,F.JavierLerch,WilliamL.Scherlis,MatthewM.McNally,andJonathanJ.Cadiz.
1998.Coordination,overloadandteamperformance:effectsofteamcommunicationstrategies.InProceedingsofthe
1998ACMConferenceonComputerSupportedCooperativeWork(Seattle,Washington,USA)(CSCW’98).Association
forComputingMachinery,NewYork,NY,USA,275–284. https://doi.org/10.1145/289444.289502
[38] KatyIlonkaGero,ZahraAshktorab,CaseyDugan,QianPan,JamesJohnson,WernerGeyer,MariaRuiz,Sarah
Miller,DavidRMillen,MurrayCampbell,etal.2020.MentalmodelsofAIagentsinacooperativegamesetting.In
Proceedingsofthe2020chiconferenceonhumanfactorsincomputingsystems.1–12.
[39] RanGong,QiuyuanHuang,XiaojianMa,YusukeNoda,ZaneDurante,ZilongZheng,DemetriTerzopoulos,Li
Fei-Fei,JianfengGao,andHoiVo.2024.MindAgent:EmergentGamingInteraction.InFindingsoftheAssociation
forComputationalLinguistics:NAACL2024,KevinDuh,HelenaGomez,andStevenBethard(Eds.).Associationfor
ComputationalLinguistics,MexicoCity,Mexico,3154–3183. https://doi.org/10.18653/v1/2024.findings-naacl.200
[40] CongGuan,LichaoZhang,ChunpengFan,YichenLi,FengChen,LiheLi,YunjiaTian,LeiYuan,andYangYu.2023.
EfficientHuman-AICoordinationviaPreparatoryLanguage-basedConvention. arXivpreprintarXiv:2311.00416
(2023).
[41] SiyuanGuo,ChengDeng,YingWen,HechangChen,YiChang,andJunWang.2024.DS-Agent:AutomatedData
SciencebyEmpoweringLargeLanguageModelswithCase-BasedReasoning.InForty-firstInternationalConference
onMachineLearning.
[42] DonggeHan,TrevorMcInroe,AdamJelley,StefanoVAlbrecht,PeterBell,andAmosStorkey.2024.LLM-Personalize:
AligningLLMPlannerswithHumanPreferencesviaReinforcedSelf-TrainingforHousekeepingRobots. arXiv
preprintarXiv:2404.14285(2024).
[43] TomohiroHarada,JoheiMatsuoka,andKiyohikoHattori.2023.Behavioranalysisofemergentrulediscoveryfor
cooperativeautomateddrivingusingdeepreinforcementlearning.ArtificialLifeandRobotics28,1(2023),31–42.
[44] DavidJ.HardyandCharlesH.Hinkin.2022.MentalWorkloadinNeuropsychology:AnExampleWiththeNASA-TLX
inAdultsWithHIV.FrontiersinNeuroergonomics3(2022). https://doi.org/10.3389/fnrgo.2022.881653
[45] PeterEHart,NilsJNilsson,andBertramRaphael.1968.Aformalbasisfortheheuristicdeterminationofminimum
costpaths.IEEEtransactionsonSystemsScienceandCybernetics4,2(1968),100–107.
[46] ZiyaoHe,YunpengSong,ShuruiZhou,andZhongminCai.2023.InteractionofThoughts:TowardsMediatingTask
AssignmentinHuman-AICooperationwithaCapability-AwareSharedMentalModel.InProceedingsofthe2023
CHIConferenceonHumanFactorsinComputingSystems(Hamburg,Germany)(CHI’23).AssociationforComputing
Machinery,NewYork,NY,USA,Article353,18pages. https://doi.org/10.1145/3544548.3580983
[47] LauraMHiatt,AnthonyMHarrison,andJGregoryTrafton.2011.Accommodatinghumanvariabilityinhuman-robot
teamsthroughtheoryofmind.InTwenty-SecondInternationalJointConferenceonArtificialIntelligence.
[48] GuyHoffman.2019.Evaluatingfluencyinhuman–robotcollaboration.IEEETransactionsonHuman-MachineSystems
49,3(2019),209–218.
[49] LeiHuang,WeijiangYu,WeitaoMa,WeihongZhong,ZhangyinFeng,HaotianWang,QianglongChen,WeihuaPeng,
XiaochengFeng,BingQin,andTingLiu.2023.ASurveyonHallucinationinLargeLanguageModels:Principles,
Taxonomy,Challenges,andOpenQuestions. arXiv:2311.05232[cs.CL] https://arxiv.org/abs/2311.05232
[50] BarnaLászlóIantovics.2008. Agent-basedmedicaldiagnosissystems. ComputingandInformatics27,4(2008),
593–625.
[51] RomanJakobson.1972.Verbalcommunication.ScientificAmerican227,3(1972),72–81.
[52] JingluJiang,AlexanderJKarran,ConstantinosKCoursaris,Pierre-MajoriqueLéger,andJoergBeringer.2023. A
situationawarenessperspectiveonhuman-AIinteraction:Tensionsandopportunities. InternationalJournalof
Human–ComputerInteraction39,9(2023),1789–1806.
[53] Shan G. Lakhmani Julia L. Wright and Jessie Y. C. Chen. 2022. Bidirectional Communications in
Human-Agent Teaming: The Effects of Communication Style and Feedback. International Journal of
Human–Computer Interaction 38, 18-20 (2022), 1972–1985. https://doi.org/10.1080/10447318.2022.2068744
arXiv:https://doi.org/10.1080/10447318.2022.2068744
[54] MauritsKaptein.2016.Usinggeneralizedlinear(mixed)modelsinHCI.ModernStatisticalMethodsforHCI(2016),
251–274.
[55] KrishnaramKenthapadi,MehrnooshSameki,andAnkurTaly.2024.GroundingandEvaluationforLargeLanguage
Models:PracticalChallengesandLessonsLearned(Survey).InProceedingsofthe30thACMSIGKDDConferenceon
KnowledgeDiscoveryandDataMining.6523–6533.
[56] MaryRitchieKeyandMaryRitchieKey.1980.Therelationshipofverbalandnonverbalcommunication.MoutonThe
Hague.
[57] RyanM.KilgoreandMartinVoshell.2014. IncreasingtheTransparencyofUnmannedSystems:Applicationsof
EcologicalInterfaceDesign.InInteracción. https://api.semanticscholar.org/CorpusID:31347319MutualTheoryofMindinHuman-AICollaboration 29
[58] TaenyunKim,MariaD.Molina,Minjin(MJ)Rheu,EmilyS.Zhan,andWeiPeng.2023. OneAIDoesNotFitAll:
AClusterAnalysisoftheLaypeople’sPerceptionofAIRoles.InProceedingsofthe2023CHIConferenceonHuman
FactorsinComputingSystems(Hamburg,Germany)(CHI’23).AssociationforComputingMachinery,NewYork,NY,
USA,Article29,20pages. https://doi.org/10.1145/3544548.3581340
[59] MeredythKrych-Appelbaum,JulieBanzonLaw,DaynaJones,AllysonBarnacz,AmandaJohnson,andJulianPaul
Keenan.2007.“IthinkIknowwhatyoumean”:Theroleoftheoryofmindincollaborativecommunication.Interaction
Studies8,2(2007),267–280.
[60] ChristelleLangley,BogdanIonutCirstea,FabioCuzzolin,andBarbaraJSahakian.2022.Theoryofmindandpreference
learningattheinterfaceofcognitivescience,neuroscience,andAI:Areview. Frontiersinartificialintelligence5
(2022),778852.
[61] MarinLeGuillou,LaurentPrévot,andBrunoBerberian.2023.TrustingArtificialAgents:CommunicationTrumps
Performance.InProceedingsofthe2023InternationalConferenceonAutonomousAgentsandMultiagentSystems
(London,UnitedKingdom)(AAMAS’23).InternationalFoundationforAutonomousAgentsandMultiagentSystems,
Richland,SC,299–306.
[62] MartinLeaandRussellSpears.1992. Paralanguageandsocialperceptionincomputer-mediatedcommunication.
JournalofOrganizationalComputingandElectronicCommerce2,3-4(1992),321–341.
[63] SoyoungLee,CharlotteTang,SunYoungPark,andYunanChen.2012.Looselyformedpatientcareteams:communi-
cationchallengesandtechnologydesign.InProceedingsoftheACM2012conferenceoncomputersupportedcooperative
work.867–876.
[64] WenhaoLi,ZhiyuanYu,QijinShe,ZhinanYu,YuqingLan,ChenyangZhu,RuizhenHu,andKaiXu.2024. LLM-
enhancedSceneGraphLearningforHouseholdRearrangement.arXivpreprintarXiv:2408.12093(2024).
[65] YangLi,ShaoZhang,JichenSun,YaliDu,YingWen,XinbingWang,andWeiPan.2023.CooperativeOpen-ended
LearningFrameworkforZero-ShotCoordination.InICML(ProceedingsofMachineLearningResearch,Vol.202).PMLR,
20470–20484.
[66] YangLi,ShaoZhang,JichenSun,WenhaoZhang,YaliDu,YingWen,XinbingWang,andWeiPan.2024.Tackling
cooperativeincompatibilityforzero-shothuman-aicoordination.JournalofArtificialIntelligenceResearch80(2024),
1139–1185.
[67] ClaireLiang,JuliaProft,ErikAndersen,andRossAKnepper.2019.Implicitcommunicationofactionableinformation
inhuman-aiteams.InProceedingsofthe2019CHIconferenceonhumanfactorsincomputingsystems.1–13.
[68] JackyLiang,WenlongHuang,FeiXia,PengXu,KarolHausman,BrianIchter,PeteFlorence,andAndyZeng.2023.
CodeasPolicies:LanguageModelProgramsforEmbodiedControl.InIEEEInternationalConferenceonRoboticsand
Automation,ICRA2023,London,UK,May29-June2,2023.IEEE,9493–9500. https://doi.org/10.1109/ICRA48891.2023.
10160591
[69] DavidLindnerandMennatallahEl-Assady.2022.Humansarenotboltzmanndistributions:Challengesandoppor-
tunitiesformodellinghumanfeedbackandinteractioninreinforcementlearning.arXivpreprintarXiv:2206.13316
(2022).
[70] JijiaLiu,ChaoYu,JiaxuanGao,YuqingXie,QingminLiao,YiWu,andYuWang.2024.LLM-PoweredHierarchical
LanguageAgentforReal-timeHuman-AICoordination.InProceedingsofthe23rdInternationalConferenceon
AutonomousAgentsandMultiagentSystems(Auckland,NewZealand)(AAMAS’24).InternationalFoundationfor
AutonomousAgentsandMultiagentSystems,Richland,SC,1219–1228.
[71] ZhicongLu,ChenxinranShen,JiannanLi,HongShen,andDanielWigdor.2021.Morekawaiithanareal-personlive
streamer:understandinghowtheotakucommunityengageswithandperceivesvirtualYouTubers.InProceedingsof
the2021CHIConferenceonHumanFactorsinComputingSystems.1–14.
[72] AndresM.Bran,SamCox,OliverSchilter,CarloBaldassari,AndrewDWhite,andPhilippeSchwaller.2024.Aug-
mentinglargelanguagemodelswithchemistrytools.NatureMachineIntelligence(2024),1–11.
[73] KaixinMa,HongmingZhang,HongweiWang,XiaomanPan,andDongYu.2023.Laser:Llmagentwithstate-space
explorationforwebnavigation.arXivpreprintarXiv:2309.08172(2023).
[74] ZixianMa,RoseWang,Fei-FeiLi,MichaelBernstein,andRanjayKrishna.2022.Elign:Expectationalignmentasa
multi-agentintrinsicreward.AdvancesinNeuralInformationProcessingSystems35(2022),8304–8317.
[75] PeterEMcKenna,MartaRomeo,JhielsonPimentel,MohammedDiab,MeriamMoujahid,HelenHastie,andYiannis
Demiris.2023. TheoryofMindandTrustinHuman-RobotNavigation.InProceedingsoftheFirstInternational
SymposiumonTrustworthyAutonomousSystems(Edinburgh,UnitedKingdom)(TAS’23).AssociationforComputing
Machinery,NewYork,NY,USA,Article29,5pages. https://doi.org/10.1145/3597512.3597514
[76] SallyJ.McMillanandJang-SunHwang.2002. MeasuresofPerceivedInteractivity:AnExplorationoftheRoleof
DirectionofCommunication,UserControl,andTimeinShapingPerceptionsofInteractivity.JournalofAdvertising31,
3(2002),29–42. https://doi.org/10.1080/00913367.2002.10673674arXiv:https://doi.org/10.1080/00913367.2002.1067367430 ZhangandWang,etal.
[77] NathanJ.McNeese,MustafaDemir,NancyJ.Cooke,andManrongShe.2021.TeamSituationAwarenessandConflict:
AStudyofHuman–MachineTeaming.JournalofCognitiveEngineeringandDecisionMaking15,2-3(2021),83–96.
https://doi.org/10.1177/15553434211017354arXiv:https://doi.org/10.1177/15553434211017354
[78] NathanJMcNeeseandMadhuCReddy.2015.Articulatingandunderstandingthedevelopmentofateammental
modelinadistributedmedium.InProceedingsoftheHumanFactorsandErgonomicsSocietyAnnualMeeting,Vol.59.
SAGEPublicationsSageCA:LosAngeles,CA,240–244.
[79] AlbertMehrabian.2017.Nonverbalcommunication.Routledge.
[80] AndrewNMeltzoff.1999. Originsoftheoryofmind,cognitionandcommunication. Journalofcommunication
disorders32,4(1999),251–269.
[81] ChristopherZMooney,RobertDDuval,andRobertDuvall.1993. Bootstrapping:Anonparametricapproachto
statisticalinference.Number95.sage.
[82] MatthewANapierala.2012.WhatistheBonferronicorrection?AaosNow(2012),40–41.
[83] StephenOliver.2019.Communicationandtrust:rethinkingthewayconstructionindustryprofessionalsandsoftware
vendorsutilisecomputercommunicationmediums.VisualizationinEngineering7,1(2019),1.
[84] OpenAI.2024.GPT-4omini:AdvancingCost-EfficientIntelligence.https://openai.com/index/gpt-4o-mini-advancing-
cost-efficient-intelligence/. Accessed:2024-09-05.
[85] NurziyaOralbayeva,AidarShakerimov,ShamilSarmonov,KanagatKantoreyeva,FatimaDadebayeva,NuraySerkali,
andAnaraSandygulova.2022.K-Qbot:LanguageLearningChatbotBasedonReinforcementLearning.In202217th
ACM/IEEEInternationalConferenceonHuman-RobotInteraction(HRI).963–967. https://doi.org/10.1109/HRI53351.
2022.9889428
[86] ThomasO’Neill,NathanMcNeese,AmyBarron,andBeauSchelble.2022.Human–autonomyteaming:Areviewand
analysisoftheempiricalliterature.Humanfactors64,5(2022),904–938.
[87] JoonSungPark,JosephO’Brien,CarrieJunCai,MeredithRingelMorris,PercyLiang,andMichaelSBernstein.2023.
Generativeagents:Interactivesimulacraofhumanbehavior.InProceedingsofthe36thannualacmsymposiumonuser
interfacesoftwareandtechnology.1–22.
[88] JiankunPeng,WeiqiChen,YiFan,HongwenHe,ZhongbaoWei,andChunyeMa.2023.EcologicalDrivingFramework
ofHybridElectricVehicleBasedonHeterogeneousMulti-AgentDeepReinforcementLearning.IEEETransactionson
TransportationElectrification10,1(2023),392–406.
[89] ChristopherPeters.2006.Designingsyntheticmemorysystemsforsupportingautonomousembodiedagentbehaviour.
InROMAN2006-The15thIEEEInternationalSymposiumonRobotandHumanInteractiveCommunication.IEEE,14–19.
[90] JoséPinheiroandDouglasBates.2006.Mixed-effectsmodelsinSandS-PLUS.Springerscience&businessmedia.
[91] MarcPinski,MartinAdam,andAlexanderBenlian.2023.AIKnowledge:ImprovingAIDelegationthroughHuman
Enablement.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems(Hamburg,Germany)
(CHI’23).AssociationforComputingMachinery,NewYork,NY,USA,Article25,17pages. https://doi.org/10.1145/
3544548.3580794
[92] DavidPremackandGuyWoodruff.1978.Doesthechimpanzeehaveatheoryofmind?Behavioralandbrainsciences
1,4(1978),515–526.
[93] NeilRabinowitz,FrankPerbet,FrancisSong,ChiyuanZhang,S.M.AliEslami,andMatthewBotvinick.2018.Machine
TheoryofMind.InProceedingsofthe35thInternationalConferenceonMachineLearning(ProceedingsofMachine
LearningResearch,Vol.80),JenniferDyandAndreasKrause(Eds.).PMLR,4218–4227. https://proceedings.mlr.press/
v80/rabinowitz18a.html
[94] DiogoRato,MartaCouto,andRuiPrada.2022.AttributingSocialMotivationstoChangesinAgents’Behaviorand
Appearance.InProceedingsofthe10thInternationalConferenceonHuman-AgentInteraction(Christchurch,New
Zealand)(HAI’22).AssociationforComputingMachinery,NewYork,NY,USA,219–226. https://doi.org/10.1145/
3527188.3561925
[95] StuartJRussellandPeterNorvig.2016.Artificialintelligence:amodernapproach.Pearson.
[96] VildanSalikutluk,JanikSchöpper,FranziskaHerbert,KatrinScheuermann,EricFrodl,DirkBalfanz,FrankJäkel,and
DorotheaKoert.2024.AnEvaluationofSituationalAutonomyforHuman-AICollaborationinaSharedWorkspace
Setting.InProceedingsoftheCHIConferenceonHumanFactorsinComputingSystems(Honolulu,HI,USA)(CHI’24).
AssociationforComputingMachinery,NewYork,NY,USA,Article300,17pages. https://doi.org/10.1145/3613904.
3642564
[97] BeauG.Schelble,ChristopherFlathmann,NathanJ.McNeese,GuoFreeman,andRohitMallick.2022.Let’sThink
Together!AssessingSharedMentalModels,Performance,andTrustinHuman-AgentTeams.Proc.ACMHum.-Comput.
Interact.6,GROUP,Article13(jan2022),29pages. https://doi.org/10.1145/3492832
[98] DanielB.Shank,ChristopherGraves,AlexanderGott,PatrickGamez,andSophiaRodriguez.2019.Feelingourway
tomachineminds:People’semotionswhenperceivingmindinartificialintelligence.Comput.Hum.Behav.98,C(sep
2019),256–266. https://doi.org/10.1016/j.chb.2019.04.001MutualTheoryofMindinHuman-AICollaboration 31
[99] ManasiSharma,HoChitSiu,RohanPaleja,andJaimeDPeña.2024.WhyWouldYouSuggestThat?HumanTrustin
LanguageModelResponses.arXivpreprintarXiv:2406.02018(2024).
[100] ChenxinranShen,YanXu,RayLc,andZhicongLu.2024. SeekingSoulmateviaVoice:UnderstandingPromises
andChallengesofOnlineSynchronizedVoice-BasedMobileDating.InProceedingsoftheCHIConferenceonHuman
FactorsinComputingSystems(Honolulu,HI,USA)(CHI’24).AssociationforComputingMachinery,NewYork,NY,
USA,Article921,14pages. https://doi.org/10.1145/3613904.3642860
[101] MeiSi,StacyC.Marsella,andDavidV.Pynadath.2010.Modelingappraisalintheoryofmindreasoning.Autonomous
AgentsandMulti-AgentSystems20,1(jan2010),14–31. https://doi.org/10.1007/s10458-009-9093-x
[102] SinanSonlu,BennieBendiksen,FundaDurupinar,andUğurGüdükbay.2024. TheEffectsofEmbodimentand
PersonalityExpressiononLearninginLLM-basedEducationalAgents.arXivpreprintarXiv:2407.10993(2024).
[103] MarkSteyvers,HeliodoroTejeda,GavinKerrigan,andPadhraicSmyth.2022. Bayesianmodelingofhuman–AI
complementarity.ProceedingsoftheNationalAcademyofSciences119,11(2022),e2111547119.
[104] JamesWAStrachan,DalilaAlbergo,GiuliaBorghini,OrianaPansardi,EugenioScaliti,SaurabhGupta,KratiSaxena,
AlessandroRufo,StefanoPanzeri,GuidoManzi,etal.2024.Testingtheoryofmindinlargelanguagemodelsand
humans.NatureHumanBehaviour(2024),1–11.
[105] DJStrouse,KevinMcKee,MattBotvinick,EdwardHughes,andRichardEverett.2021.Collaboratingwithhumans
withouthumandata.AdvancesinNeuralInformationProcessingSystems34(2021),14502–14515.
[106] TheodoreRSumers,ShunyuYao,KarthikNarasimhan,andThomasLGriffiths.2023.Cognitivearchitecturesfor
languageagents.arXivpreprintarXiv:2309.02427(2023).
[107] MelanieSwan,TakashiKido,EricRoland,andRenatoPdosSantos.2023.Mathagents:Computationalinfrastructure,
mathematicalembedding,andgenomics.arXivpreprintarXiv:2307.02502(2023).
[108] LorainneTudorCar,DhakshenyaArdhithyDhinagaran,BhoneMyintKyaw,TobiasKowatsch,ShafiqJoty,Yin-Leng
Theng,andRifatAtun.2020.Conversationalagentsinhealthcare:scopingreviewandconceptualanalysis.Journal
ofmedicalInternetresearch22,8(2020),e17158.
[109] RosaMVicari,CeciliaDFlores,AndreMSilvestre,LouiseJSeixas,MarceloLadeira,andHelderCoelho.2003. A
multi-agentintelligentenvironmentformedicalknowledge.ArtificialIntelligenceinMedicine27,3(2003),335–366.
[110] GuanzhiWang,YuqiXie,YunfanJiang,AjayMandlekar,ChaoweiXiao,YukeZhu,LinxiFan,andAnimaAnandkumar.
2024.Voyager:AnOpen-EndedEmbodiedAgentwithLargeLanguageModels.TransactionsonMachineLearning
Research(2024). https://openreview.net/forum?id=ehfRiF0R3a
[111] QiaosiWangandAshokKGoel.2022. Mutualtheoryofmindforhuman-aicommunication. arXivpreprint
arXiv:2210.03842(2022).
[112] QiaosiWang,KoustuvSaha,EricGregori,DavidJoyner,andAshokGoel.2021.TowardsMutualTheoryofMind
inHuman-AIInteraction:HowLanguageReflectsWhatStudentsPerceiveAboutaVirtualTeachingAssistant.
InProceedingsofthe2021CHIConferenceonHumanFactorsinComputingSystems(Yokohama,Japan)(CHI’21).
AssociationforComputingMachinery,NewYork,NY,USA,Article384,14pages. https://doi.org/10.1145/3411764.
3445645
[113] QiaosiWang,SarahWalsh,MeiSi,JeffreyKephart,JustinD.Weisz,andAshokK.Goel.2024. TheoryofMindin
Human-AIInteraction.InExtendedAbstractsofthe2024CHIConferenceonHumanFactorsinComputingSystems
(CHIEA’24).AssociationforComputingMachinery,NewYork,NY,USA,Article493,6pages. https://doi.org/10.
1145/3613905.3636308
[114] XihuaiWang,ZhengTian,ZiyuWan,YingWen,JunWang,andWeinanZhang.2023.OrderMatters:Agent-by-agent
PolicyOptimization.InTheEleventhInternationalConferenceonLearningRepresentations. https://openreview.net/
forum?id=Q-neeWNVv1
[115] XihuaiWang,ShaoZhang,WenhaoZhang,WentaoDong,JingxiaoChen,YingWen,andWeinanZhang.2024.
ZSC-Eval:AnEvaluationToolkitandBenchmarkforMulti-agentZero-shotCoordination. arXiv:2310.05208[cs.AI]
https://arxiv.org/abs/2310.05208
[116] JasonWei,XuezhiWang,DaleSchuurmans,MaartenBosma,FeiXia,EdChi,QuocVLe,DennyZhou,etal.2022.
Chain-of-thoughtpromptingelicitsreasoninginlargelanguagemodels.Advancesinneuralinformationprocessing
systems35(2022),24824–24837.
[117] JustinDWeisz,MichaelMuller,ArielleGoldberg,andDarioAndresSilvaMoran.2024. ExpedientAssistance
andConsequentialMisunderstanding:EnvisioninganOperationalizedMutualTheoryofMind. arXivpreprint
arXiv:2406.11946(2024).
[118] YingWen,YaodongYang,RuiLuo,JunWang,andWeiPan.2019.ProbabilisticRecursiveReasoningforMulti-Agent
ReinforcementLearning.InInternationalConferenceonLearningRepresentations. https://openreview.net/forum?id=
rkl6As0cF7
[119] JoelWester,RuneMøbergJacobsen,SanderdeJong,NajaKathrineKollerupAls,HelenaBøjerDjernæs,andNiels
vanBerkel.2024.TheoryofMindandSelf-PresentationinHuman-LLMInteractions.InAdjunctProceedingsofthe32 ZhangandWang,etal.
ACMSIGCHIConferenceonHumanFactorsinComputingSystems.
[120] Jimmy Wu, Rika Antonova, Adam Kan, Marion Lepert, Andy Zeng, Shuran Song, Jeannette Bohg, Szymon
Rusinkiewicz,andThomasFunkhouser.2023.Tidybot:Personalizedrobotassistancewithlargelanguagemodels.
AutonomousRobots47,8(2023),1087–1102.
[121] SarahA.Wu,RoseE.Wang,JamesA.Evans,JoshuaB.Tenenbaum,DavidC.Parkes,andMaxKleiman-Weiner.2021.
TooManyCooks:BayesianInferenceforCoordinatingMulti-AgentCollaboration.TopicsinCognitiveScience13,2
(2021),414–432. https://doi.org/10.1111/tops.12525arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1111/tops.12525
[122] ShunyuYao,HowardChen,JohnYang,andKarthikNarasimhan.2022. Webshop:Towardsscalablereal-world
webinteractionwithgroundedlanguageagents. AdvancesinNeuralInformationProcessingSystems35(2022),
20744–20757.
[123] ShunyuYao,JeffreyZhao,DianYu,NanDu,IzhakShafran,KarthikNarasimhan,andYuanCao.2022. React:
Synergizingreasoningandactinginlanguagemodels.arXivpreprintarXiv:2210.03629(2022).
[124] ChaoYu,JiaxuanGao,WeilinLiu,BotianXu,HaoTang,JiaqiYang,YuWang,andYiWu.2023.LearningZero-Shot
CooperationwithHumans,AssumingHumansAreBiased.InICLR.OpenReview.net.
[125] RuiZhang,WenDuan,ChristopherFlathmann,NathanMcNeese,GuoFreeman,andAlyssaWilliams.2023.Investi-
gatingAITeammateCommunicationStrategiesandTheirImpactinHuman-AITeamsforEffectiveTeamwork.Proc.
ACMHum.-Comput.Interact.7,CSCW2,Article281(oct2023),31pages. https://doi.org/10.1145/3610072
[126] RuiZhang,NathanJ.McNeese,GuoFreeman,andGeoffMusick.2021. "AnIdealHuman":ExpectationsofAI
TeammatesinHuman-AITeaming.Proc.ACMHum.-Comput.Interact.4,CSCW3,Article246(jan2021),25pages.
https://doi.org/10.1145/3432945
[127] ShaoZhang,HuiXu,YutingJia,YingWen,DakuoWang,LuoyiFu,XinbingWang,andChenghuZhou.2023.
GeoDeepShovel:AplatformforbuildingscientificdatabasefromgeoscienceliteraturewithAIassistance.Geoscience
DataJournal10,4(2023),519–537.
[128] ShaoZhang,JianingYu,XuhaiXu,ChangchangYin,YuxuanLu,BingshengYao,MelanieTory,LaceM.Padilla,Jeffrey
Caterino,PingZhang,andDakuoWang.2024.RethinkingHuman-AICollaborationinComplexMedicalDecision
Making:ACaseStudyinSepsisDiagnosis.InProceedingsoftheCHIConferenceonHumanFactorsinComputing
Systems(Honolulu,HI,USA)(CHI’24).AssociationforComputingMachinery,NewYork,NY,USA,Article445,
18pages. https://doi.org/10.1145/3613904.3642343
[129] WenqiZhang,KeTang,HaiWu,MengnaWang,YongliangShen,GuiyangHou,ZeqiTan,PengLi,YuetingZhuang,
andWeimingLu.2024.Agent-Pro:LearningtoEvolveviaPolicy-LevelReflectionandOptimization.InProceedingsof
the62ndAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:LongPapers),ACL2024,Bangkok,
Thailand,August11-16,2024,Lun-WeiKu,AndreMartins,andVivekSrikumar(Eds.).AssociationforComputational
Linguistics,5348–5375. https://aclanthology.org/2024.acl-long.292
[130] WeinanZhang,XihuaiWang,JianShen,andMingZhou.2021.Model-basedMulti-agentPolicyOptimizationwith
AdaptiveOpponent-wiseRollouts.InProceedingsoftheThirtiethInternationalJointConferenceonArtificialIntelligence,
IJCAI-21,Zhi-HuaZhou(Ed.).InternationalJointConferencesonArtificialIntelligenceOrganization,3384–3391.
https://doi.org/10.24963/ijcai.2021/466MainTrack.
[131] ZiqianZhang,LeiYuan,LiheLi,KeXue,ChengxingJia,CongGuan,ChaoQian,andYangYu.2023.Fastteammate
adaptationinthepresenceofsuddenpolicychange.InUncertaintyinArtificialIntelligence.PMLR,2465–2476.
[132] ZheyuanZhang,DanielZhang-Li,JifanYu,LinluGong,JinchangZhou,ZhiyuanLiu,LeiHou,andJuanziLi.2024.
SimulatingClassroomEducationwithLLM-EmpoweredAgents.arXivpreprintarXiv:2406.19226(2024).MutualTheoryofMindinHuman-AICollaboration 33
A TheDetailedResultsofQuestionnairesinEachCondition
InTable4,weprovidetheitemsofthequestionnaireusedaftereachgame,alongwiththecorre-
spondingmeanhumanagreementlevelsineachgroupandcondition,withstandarddeviations
showninparentheses.
Table4. TheResultsoftheQuestionnaireafterEachGame.Wereportthemeanvaluesoftheagreement
theparticipantsindicatedandthestandarddeviationinbrackets.
Condition Bi-Comm H-Comm A-Comm No-Comm
Statement w/MToM w/oMToM w/MToM w/oMToM w/MToM w/oMToM w/MToM w/oMToM
Theagentisgoodatplayingthisgame. 4.25(1.13) 4.38(0.65) 4.18(0.53) 4.18(0.53) 4.06(0.56) 4.06(0.56) 4.22(0.42) 4.11(0.58)
TheagentandIareworkingfluentlytogether 3.75(1.27) 3.81(0.70) 3.94(0.43) 4.24(0.57) 3.65(0.87) 3.59(1.63) 3.83(0.62) 3.78(0.77)
TheagentandIcontributedequallytothesuccess. 3.75(1.13) 3.81(1.23) 4.12(0.49) 3.94(0.56) 3.94(1.06) 4.00(1.13) 4.00(0.47) 3.72(0.68)
Iwasthemostimportantteammemberontheteam. 3.81(1.23) 3.88(1.18) 3.70(0.60) 3.70(0.85) 4.06(0.93) 3.94(1.18) 3.72(0.45) 3.94(0.53)
Theagentwasthemostimportantteammemberontheteam 3.75(0.87) 4.00(0.80) 3.88(0.61) 3.65(0.74) 3.88(0.99) 3.88(1.23) 3.83(0.50) 3.67(0.82)
Icanunderstandagent 3.81(1.36) 3.81(0.43) 4.29(0.47) 4.24(0.44) 3.82(1.03) 3.65(1.37) 4.00(0.47) 3.83(0.85)
Ifeelagentunderstandme 3.94(0.73) 3.75(1.00) 3.59(1.38) 4.00(0.88) 3.59(1.01) 3.47(1.39) 3.83(0.97) 3.44(0.85)
TheagentandIareworkingonthesamegoal 4.18(0.96) 4.44(0.53) 4.24(0.44) 4.58(0.38) 4.00(1.00) 4.12(1.36) 4.22(0.54) 4.00(0.59)
Ifeelthatitiseasytoscorehighinthisgame. 3.56(1.60) 3.81(0.96) 3.94(0.43) 4.18(0.53) 3.47(1.64) 3.47(1.26) 3.94(0.76) 3.94(0.76)
B TheOpenQuestionsinEachCondition
Togatherparticipants’perspectivesontheagents’capabilitiesandtheircommunicationprocess
during the experiments, we design open questions tailored to each group’s different levels of
communicationinteractivity.
ForBi-CommGroup:
• Haveyousentmessagestotheagents?Howdoyouthinkthatsendingmessagestothe
agentshasaffectedyourownactions?
• Doyouspendtimepayingattentiontothemessagessentbytheagents?Howdoyouthink
readingmessagestotheagentshasaffectedyourownactions?
• Howdoyoufeelaboutthemessagesfromtheagents?Haveyourespondedtotheagents’
messageswithyouractions?Ifso,pleaseprovideexamples.
• Whichagent(pleaseusehatcolorforreference)doyoubelieveisabletounderstandand
respondtoyourmessages?Pleaseprovideexamples.
• HowdoyoufeelthatyourAIteammateunderstandsyou?PleaseexplainwhichAIagent
andwhy.
• HowdoyoufeelthatyouunderstandyourAIteammate?PleaseexplainwhichAIagent
andwhy.
ForH-CommGroup:
• Haveyousentmessagestotheagents?Howdoyouthinkthatsendingmessagestothe
agentshasaffectedyourownactions?
• Whichagent(pleaseusehatcolorforreference)doyoubelieveisabletounderstandand
respondtoyourmessages?Pleaseprovideexamples.
• HowdoyoufeelthatyourAIteammateunderstandsyou?PleaseexplainwhichAIagent
andwhy.
• HowdoyoufeelthatyouunderstandyourAIteammate?PleaseexplainwhichAIagent
andwhy.
ForA-CommGroup:
• Doyouspendtimepayingattentiontothemessagessentbytheagents?Howdoyouthink
readingmessagestotheagentshasaffectedyourownactions?
• Howdoyoufeelaboutthemessagesfromtheagents?Haveyourespondedtotheagents’
messageswithyouractions?Ifso,pleaseprovideexamples.34 ZhangandWang,etal.
• HowdoyoufeelthatyourAIteammateunderstandsyou?PleaseexplainwhichAIagent
andwhy.
• HowdoyoufeelthatyouunderstandyourAIteammate?PleaseexplainwhichAIagent
andwhy.
ForNo-CommGroup:
• HowdoyoufeelthatyourAIteammateunderstandsyou?PleaseexplainwhichAIagent
andwhy.
• HowdoyoufeelthatyouunderstandyourAIteammate?PleaseexplainwhichAIagent
andwhy.