[
    {
        "title": "Mutual Theory of Mind in Human-AI Collaboration: An Empirical Study with LLM-driven AI Agents in a Real-time Shared Workspace Task",
        "authors": "Shao ZhangXihuai WangWenhao ZhangYongshan ChenLandi GaoDakuo WangWeinan ZhangXinbing WangYing Wen",
        "links": "http://arxiv.org/abs/2409.08811v1",
        "entry_id": "http://arxiv.org/abs/2409.08811v1",
        "pdf_url": "http://arxiv.org/pdf/2409.08811v1",
        "summary": "Theory of Mind (ToM) significantly impacts human collaboration and\ncommunication as a crucial capability to understand others. When AI agents with\nToM capability collaborate with humans, Mutual Theory of Mind (MToM) arises in\nsuch human-AI teams (HATs). The MToM process, which involves interactive\ncommunication and ToM-based strategy adjustment, affects the team's performance\nand collaboration process. To explore the MToM process, we conducted a\nmixed-design experiment using a large language model-driven AI agent with ToM\nand communication modules in a real-time shared-workspace task. We find that\nthe agent's ToM capability does not significantly impact team performance but\nenhances human understanding of the agent and the feeling of being understood.\nMost participants in our study believe verbal communication increases human\nburden, and the results show that bidirectional communication leads to lower\nHAT performance. We discuss the results' implications for designing AI agents\nthat collaborate with humans in real-time shared workspace tasks.",
        "updated": "2024-09-13 13:19:48 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.08811v1"
    },
    {
        "title": "Simultaneous Topology Estimation and Synchronization of Dynamical Networks with Time-varying Topology",
        "authors": "Nana WangEsteban RestrepoDimos V. Dimarogonas",
        "links": "http://arxiv.org/abs/2409.08404v1",
        "entry_id": "http://arxiv.org/abs/2409.08404v1",
        "pdf_url": "http://arxiv.org/pdf/2409.08404v1",
        "summary": "We propose an adaptive control strategy for the simultaneous estimation of\ntopology and synchronization in complex dynamical networks with unknown,\ntime-varying topology. Our approach transforms the problem of time-varying\ntopology estimation into a problem of estimating the time-varying weights of a\ncomplete graph, utilizing an edge-agreement framework. We introduce two\nauxiliary networks: one that satisfies the persistent excitation condition to\nfacilitate topology estimation, while the other, a uniform-$\\delta$\npersistently exciting network, ensures the boundedness of both weight\nestimation and synchronization errors, assuming bounded time-varying weights\nand their derivatives. A relevant numerical example shows the efficiency of our\nmethods.",
        "updated": "2024-09-12 21:32:48 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.08404v1"
    },
    {
        "title": "Self-Supervised Inference of Agents in Trustless Environments",
        "authors": "Vladyslav LarinIvan NikitinAlexander Firsov",
        "links": "http://arxiv.org/abs/2409.08386v1",
        "entry_id": "http://arxiv.org/abs/2409.08386v1",
        "pdf_url": "http://arxiv.org/pdf/2409.08386v1",
        "summary": "In this paper, we propose a novel approach where agents can form swarms to\nproduce high-quality responses effectively. This is accomplished by utilizing\nagents capable of data inference and ranking, which can be effectively\nimplemented using LLMs as response classifiers. We assess existing approaches\nfor trustless agent inference, define our methodology, estimate practical\nparameters, and model various types of malicious agent attacks. Our method\nleverages the collective intelligence of swarms, ensuring robust and efficient\ndecentralized AI inference with better accuracy, security, and reliability. We\nshow that our approach is an order of magnitude faster than other trustless\ninference strategies reaching less than 125 ms validation latency.",
        "updated": "2024-09-12 20:32:07 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.08386v1"
    },
    {
        "title": "Inertial Coordination Games",
        "authors": "Andrew KohRicky LiKei Uzui",
        "links": "http://arxiv.org/abs/2409.08145v1",
        "entry_id": "http://arxiv.org/abs/2409.08145v1",
        "pdf_url": "http://arxiv.org/pdf/2409.08145v1",
        "summary": "We analyze inertial coordination games: dynamic coordination games with an\nendogenously changing state that depends on (i) a persistent fundamental that\nplayers privately learn about; and (ii) past play. We give a tight\ncharacterization of how the speed of learning shapes equilibrium dynamics: the\nrisk-dominant action is selected in the limit if and only if learning is slow\nsuch that posterior precisions grow sub-quadratically. This generalizes results\nfrom static global games and endows them with an alternate learning foundation.\nConversely, when learning is fast, equilibrium dynamics exhibit persistence and\nlimit play is shaped by initial play. Whenever the risk dominant equilibrium is\nselected, the path of play undergoes a sudden transition when signals are\nprecise, and a gradual transition when signals are noisy.",
        "updated": "2024-09-12 15:37:36 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.08145v1"
    },
    {
        "title": "Reinforcement Learning Discovers Efficient Decentralized Graph Path Search Strategies",
        "authors": "Alexei PisacaneVictor-Alexandru DarvariuMirco Musolesi",
        "links": "http://arxiv.org/abs/2409.07932v1",
        "entry_id": "http://arxiv.org/abs/2409.07932v1",
        "pdf_url": "http://arxiv.org/pdf/2409.07932v1",
        "summary": "Graph path search is a classic computer science problem that has been\nrecently approached with Reinforcement Learning (RL) due to its potential to\noutperform prior methods. Existing RL techniques typically assume a global view\nof the network, which is not suitable for large-scale, dynamic, and\nprivacy-sensitive settings. An area of particular interest is search in social\nnetworks due to its numerous applications. Inspired by seminal work in\nexperimental sociology, which showed that decentralized yet efficient search is\npossible in social networks, we frame the problem as a collaborative task\nbetween multiple agents equipped with a limited local view of the network. We\npropose a multi-agent approach for graph path search that successfully\nleverages both homophily and structural heterogeneity. Our experiments, carried\nout over synthetic and real-world social networks, demonstrate that our model\nsignificantly outperforms learned and heuristic baselines. Furthermore, our\nresults show that meaningful embeddings for graph navigation can be constructed\nusing reward-driven learning.",
        "updated": "2024-09-12 10:56:38 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.07932v1"
    }
]