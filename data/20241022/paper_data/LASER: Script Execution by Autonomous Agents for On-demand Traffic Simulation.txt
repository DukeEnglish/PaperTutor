LASER: Script Execution by Autonomous Agents for
On-demand Traffic Simulation
HaoGao1 JingyueWang1 WenyangFang1 JingweiXu1
YunpengHuang1 TaolueChen2 XiaoxingMa1
1StateKeyLabofNovelSoftwareTechnology,NanjingUniversity,China
2SchoolofComputingandMathematicalSciences,Birkbeck,UniversityofLondon,UK
{gh, jingyuew, fwy, hyp}@smail.nju.edu.cn,
t.chen@bbk.ac.uk, {jingweix, xxm}@nju.edu.cn
Abstract
Autonomous Driving Systems (ADS) require diverse and safety-critical traffic
scenariosforeffectivetrainingandtesting,buttheexistingdatagenerationmethods
struggletoprovideflexibilityandscalability. WeproposeLASER,anovelframe-
workthatleveragelargelanguagemodels(LLMs)toconducttrafficsimulations
basedonnaturallanguageinputs. Theframeworkoperatesintwostages: itfirst
generatesscriptsfromuser-provideddescriptionsandthenexecutesthemusing
autonomousagentsinrealtime. ValidatedintheCARLAsimulator,LASERsuc-
cessfullygeneratescomplex,on-demanddrivingscenarios,significantlyimproving
ADStrainingandtestingdatageneration.
Tomakeagreatfilm,youneedthreethings–thescript,thescriptandthescript.
–AlfredHitchcock
1 Introduction
Withthedeeplearningbreakthrough,AutonomousDrivingSystems(ADS)havemadesignificant
advancementsintaskssuchasoccupancyprediction[Huangetal.,2023b,Weietal.,2023b],trajectory
prediction[Vishnuetal.,2023,Parketal.,2024,Guetal.,2024],semanticscenecompletion[Lietal.,
2023,Jiangetal.,2024,Caoetal.,2024]andworldmodel[Wangetal.,2023b,Zhaoetal.,2024,
Wangetal.,2024,Wenetal.,2024]. Forinstance,Tesla’sFullSelf-Driving(FSD)demonstrates
exceptionalperformanceinbothcommonandcomplextaskssuchaslanechange,turn,merge,fork
anddetourformosttypesofroadsincludingevencurvyhighwaysandroundabouts[Tesla,2024].
Therapiddevelopmentofend-to-endADSresearchandapplicationheavilyreliesonvasthigh-quality
drivingdata. Ononehand,alargedatasetcontainingmulti-modaldatafromallkindsofsensors(such
ascameras,lidarandradar)isessentialtotraintheunderlyingdeepneuralnetwork(DNN)models.
TakingFSDasanexample,Teslaclaimstheircamera-onlymodelsaretrainedwithover160billion
framesofdrivingdatasampledfromreal-worldscenarios,syntheticscenariosgeneratedbysimulators,
aswellasthatfromothersources[Tesla,2023]. Ontheotherhand,ADSarehighlysafety-critical,
whicharerequiredtobethoroughlytestedunderdiversescenarios,especiallysomerare,unanticipated
ones,toguaranteetheircapabilityofhandlingemergenceandavoidingaccidents[Wikipedia,2018].
ThemoststraightforwardapproachtobuildingdatasetsforADStraining/testingistocollectreal-
worldtrafficdatathroughsensorssuchasvehiclecameras,whichnaturallyreflectrealdistributions
ofthedataandcanbescaledupthroughcrowdsourcing[Caesaretal.,2020,2021]. However,this
methodisinefficient,asdailytrafficoftenyieldsrepetitive,trivialscenarios,whilesafety-critical
events,whicharerareandhigh-risk,areseldomincludedinthetrainingsetandthushardlylearned
bythemodel[Fengetal.,2021]. Additionally,staticdata,suchasvehiclescapturedineachframe,
Preprint.Underreview.
4202
tcO
12
]OR.sc[
1v79161.0142:viXralacktheflexibilitytointeractwithormanipulate, preventingeffectivetraining/testingspecificor
customizedscenarios. Lastbutnotleast,online,interactivetestingofADSrequirestheactors(e.g.,
vehicles,pedestrians)tobereactivetothebehaviorofothers,whichisvirtuallyinfeasibleforthose
collectedfromtrafficdata.
Toaddresstheselimitations, anotherclassofapproachesistogeneratethescenariosfromtraffic
simulators,collectingsyntheticdatathroughhigh-fidelitysensors[Caesaretal.,2020,2021,Wei
etal.,2024,Zhangetal.,2023,2024,Suoetal.,2021,Salzmannetal.,2020]. Thesemethodsallow
forcreatingcustomizeddrivingscenariostailoredtospecificneeds,resultinginacontrollableand
editabledatasetfortrainingandtestingmodels. Furthermore, theyenabletherapidexecutionof
thousandsofdiverseandtargetedonlinetestsbydeployingvirtualvehiclesattachedwithtrained
models in the simulator, facilitating the identification of pitfalls and the resolution of exceptions
beforecostlyreal-worldsettings.
Undoubtedly,generatingdrivingscenarioswithreal-worldtrafficflowsisdemanding. Eachdynamic
object–regardlessofavehicle,bicycle,orpedestrian–exhibitsitsowntime-varyingmotionpatterns,
whichareofteninterdependentwiththoseofotherobjects. Mainstreammethodsfortrafficsimulation
canbecategorizedasrule-basedorlearning-based. Rule-basedtrafficsimulationemploysanalytical
modelstocontrolvehiclemovements[Lopezetal.,2018,Casasetal.,2010,FellendorfandVortisch,
2010],typicallyrelyingonfixed,predefinedroutes. Thisapproachoftenresultsinhighlyrepetitive
scenarioswithlimitedbehavioraldiversity.
Incontrast,learning-basedmethodsaimtoreplicatehumantrajectoriesfromreal-worlddrivinglogs
toproducevariedandrealisticbehaviors,whichleveragetechniques–suchasimitationlearning(IL),
reinforcementlearning(RL),deeplearning(DL)anddeepgenerativemodels–togeneratediverse
andrealisticdrivingbehaviorsbyutilizingreal-worlddrivinglogsasdemonstrations. Wereferthe
readersto[Chenetal.,2024]foracomprehensivesurvey. However,thesemethodsgenerallyface
significantchallengesinaccuratelymodelingandgeneratinghumandrivingbehaviors,oftenresulting
insimplisticactionssuchaspassingormerging[Suoetal.,2021]. Thisisprimarilyduetothree
reasons. (a)Limitedandbiasedtrainingdata. Existingmethodscommonlyrelyondatasetssuch
asNuscenes,whichcontainsonly1000videos[Caesaretal.,2020]. Learninghigh-leveldriving
behaviorsincomplex,multi-agentenvironmentsmusttacklethecombinatorialexplosionofinput
states, but the limited, imbalanced nature of the data makes hard to generalize to rare or unseen
scenarios, commonlyreferredtoas“long-tail"cases[Chenetal.,2024]. (b)Lackofalignment
withhumanunderstanding. Thebehaviorsgeneratedbythesemodelsareoftennotalignedwith
naturallanguagedescriptionsorhumancommonsense,makingthemlessinterpretableandharderto
customizeforspecificdrivingbehaviors. (c)Scenariogenerationinreal-time. Whengenerating
interactivetrafficscenariosonline, thesemethodstypicallyoperateinanauto-regressivemanner,
where each step’s prediction builds upon the previous one. Without goal-oriented guidance, this
approachcanleadtotrivialorineffectivebehaviors,andtheaccumulationofpredictionerrorsmay
resultincatastrophicfailuressuchascollisionsorvehiclesdrivingoff-road[Xuetal.,2023].
Veryrecently,deepgenerativemodel-basedmethods[Wangetal.,2023b,Zhaoetal.,2024,Wang
etal.,2024,Wenetal.,2024]provideapromisingwayforgeneratingcustomizedtrafficdatawith
worldmodels. However,itremainstobeadifficulttasktogenerateinteractivetrafficscenarioswith
diverse,on-demandbehaviors.
Recently,largelanguagemodels(LLMs)andmulti-modallanguagemodels(MMLMs)havedemon-
strated remarkable capabilities in common-sense reasoning, planning, interaction and decision-
making,showcasinggreatpotentialtoaddressthechallengesmentionedabove[Dubeyetal.,2024,
Huangetal.,2023a]. Weproposeanewtrafficsimulationframework,namedLASER(LLM-based
scenArioScriptgEneratorandExecutoR)thatleveragesLLMstocreatebothintricateandinteractive
drivingscenariosbygeneratingreadablescriptstoguidestep-by-stepexecutionofeachdynamic
objectswithinthescenarios,whichonlyrequiressimplenaturallanguagedescriptionsfromtheusers
inthefirstplace.
As illustrated in Figure 1, we first translate user requirements to a master script, which then is
convertedtosub-scriptsforeachdynamicobject,i.e. eachexecutingactorinthescenario. Based
ontherichdomain-specificknowledgeandadvancedreasoningcapabilityofLLM4AD[Wenetal.,
2023,Shaoetal.,2024],eachactor’slifespanismanagedbyanLLM-controlledautonomousagent
thatexecutesitssub-scriptinreal-time. Theseagentsmakedecisionsaboutintermediateactions
2basedonthecurrentstateoftheenvironmentateachsimulationtimestamp,allaimingtoachieve
theirindividualgoalswithintheexpectedtimeframe.
Leveraging the common-sense and behavior understanding of LLM-controlled agents, we can
perform top-down behavior-to-action script interpretation, as opposed to the previous bottom-up
action-to-behavioraccumulation. TheLLMinterpretationalignslanguage-specifiedbehaviorswith
low-levelactions,providesinterpretabilityforthegenerationprocessandenablestheon-demand
generation of specific long-tail scenarios. With scripts highlighting their agendas, these LLM-
controlledautonomousagentscooperatetoachievethetasks,generatingon-demandbehaviorwhile
avoidingaccumulatedpredictionerrors.
Wedesignatasksetconsistingof17userrequirementsencompassingbothlong-tailandreasonable
safety-criticalscenarios. WeevaluateLASER foron-demandscriptgenerationandexecutionon
thesetasksintheCARLAsimulator[Dosovitskiyetal.,2017]. Theexperimentalresultsdemonstrate
that LASER cangeneratescriptsbasedonuserrequirementseffectively,withonly3.18%ofthe
charactersintheresultingexecutablescriptbeinginputtedbytheusertofulfilltheirdemands. The
experimentalresultsalsoshowthatourapproachcanexecutethescripteffectivelyandefficiently,
with an average success rate of 90.48%, and usage of 1606.09 tokens per simulation second per
agent. Furthermore,manualinspectionconfirmsthatourapproachcansuccessfullysimulatevarious
safety-criticalscenarioswhichcanbeappliedtoADStesting.
Insummary,theprimarycontributionofourworkistoproposeanon-demand,interactiveapproach
for traffic simulation, which includes a script generator and LLM-controlled autonomous agents
astheexecutor. Tothebestofourknowledge,thisisthefirsttimetoachieveon-demandscenario
generationinADStesting.
2 Relatedworks
Wehavecoveredtherelatedworkonlearning-basedtrafficsimulationinSection1. Arecenttrend
inautonomousdrivingistoleverageLLMswhichhavedemonstratedexceptionalcapabilitiesin
human-liketaskssuchascommon-senseunderstanding,planning,decision-making,andinteraction
[Dubeyetal.,2024,Huangetal.,2023a],trainedonvastdatasetsoftrillionsoftokensandimages
fromtheweb.Thesemodelsexhibitadeepreservoirofactionableknowledge,whichcanbeharnessed
forroboticmanipulationthroughreasoningandplanning[Wenetal.,2023]. Recentresearchhas
explored the use of LLMs to develop autonomous agents that execute natural language tasks in
interactiveenvironments[Driessetal.,2023,Brohanetal.,2023,Belkhaleetal.,2024]. Anotable
exampleisRT-H,whichenhancesagentrobustnessandflexibilitybydecomposinghigh-leveltasks
intosequencesoffine-grainedbehaviors,referredtoas"languagemotions"(e.g.,"movearmforward"
followedby"graspthecan"). Thisapproacheffectivelyleveragesmulti-taskdatasets,significantly
improvingperformance[Belkhaleetal.,2024].
SubstantialeffortshavealsobeendirectedtowardsintegratingLLMswithADS,underscoringthe
models’superiorabilitiesinunderstandinganddecision-makingwithindrivingscenarios[Sharan
etal.,2023,Renzetal.,2024,Shaoetal.,2024,Wenetal.,2023]. Forexample,CarLLaVAachieved
firstplaceinthesensortrackoftheCARLAAutonomousDrivingChallenge2.0, surpassingthe
next-bestsubmissionby32.6%. Thissuccessisattributedtoitsintegrationofthevisionencoder
LLaVAwiththeLLaMAarchitectureasitsbackbone[Renzetal.,2024]. Additionally,LLM-Assist
outperformed all existing learning- and rule-based methods across most metrics in the Nuplan
dataset by leveraging LLMs’ common-sense reasoning to refine plans generated by rule-based
planners[Sharanetal.,2023].
FurtherresearchhasdemonstratedthecapabilityofLLM-integratedADStoexecutetasksbasedon
naturallanguageinstructions,revealingitspotentialformodelingcomplexhumandrivingbehav-
iors[Wangetal.,2023a,Shaoetal.,2024]. Forinstance,LMDriveshowedthatLLM-controlled
drivingagentscouldinterpretandfollowhigh-leveldrivingcommands,suchas"Turnrightatthe
nextintersection,"byaligningtheseinstructionswithvehiclecontrolsignalsusingavision-language
modelasthefoundation[Shaoetal.,2024]. Morerecently,DiLudemonstratedthatwithfew-shot
learning,LLMscouldachieveresultscomparabletoRL-basedplanners,significantlyreducingthe
computationalcostofdeployingmultipleLLM-controlledagentssimultaneously[Wenetal.,2023].
3Writing Script Execution of Agents
Framework of LASER
Script Writer Agent for "front_car"
COT LLM Decision Module DeS sc ce rin pe tion
User Input Master Script Decision(DSL)
Map Location revise Rule-based planner SC io gn nt aro lsl
User Requirement SS uu bb -s- cs rc ir pip t t fs or Agent for "rear_car" RC UA NR TL IMA E
"front_car" LLM Decision Module DeS sc ce rin pe tion
Decision(DSL)
There are two cars ahead of ego on Sub-script for review
the left lane. The front car suddenly "rear_car" Rule-based planner Control
decelerates, and the rear car swerves Signals
to the right to avoid a collision.
Example of Sub-script for "rear_car" Example of Execution
Step1
position: [2, 55]
Initial State
speed: 6 m/s
action: Maintain 6 m/s speed in lane 2.
Step1 termination_condition: Front_car decelerates to less than 5m/s.
reason: Maintain safe following distance while traveling at a steady speed. Step2
action: Change from lane 2 to lane 3.
Step2 termination_condition: The car is not in lane 2.
reason: Avoid collision with the suddenly decelerating front_car by shifting to
a safer lane.
Figure1: FrameworkofLASER
3 Methodology
3.1 Framework
Toachieveon-demandandinteractivetrafficsimulation,weproposeaframeworkcalledLASER,as
illustratedinFigure1. LASERconsistsoftwostages,implementedbytwomodulesrespectively,
i.e., script writer (Section 3.2) and LASER-Agent (Section 3.3). Unlike the previous learning-
basedmethodsthatconductgenerationandsimulationsimultaneously,ourLASERframeworkfirst
generatesscriptsthatdefinelogic-chainedbehaviors(LCB)withnaturallanguageinstructionsfrom
theuserrequirements. Itthenexecutesthescriptbythereal-timecooperationofLASER-Agents.
Thetwo-stageframeworkdetachesactorbehaviorfromthescenariowithanaturallanguagescript.
Compared to road data collection that collects on-road scenarios at the state level, our LASER
frameworkrecordsscenariosatthebehaviorallevel,whichenablesdynamicandflexibleexecution
duringthesimulation. Comparedtolearning-basedtrafficsimulationthatgeneratesscenariosatthe
statelevel,LASERgeneratesscenariosatthebehaviorallevel,thisenableson-demandgeneration
andtop-downexecutionoflanguage-specifiedbehavior,andeasyeditingonactorbehaviortoimprove
performance.
TohaveaglanceatthecomplexityofbehaviorsthatLASERcansimulate,wepresentanexample
ofauser-definedscenarioinFigure1. Theuserrequestsasafety-criticalscenarioonthehighway:
Twocarsaredrivingintheleftlaneaheadoftheegovehicle,whichisintherightlane. Suddenly,
thefrontcardeceleratesduetoamechanicalfailure. Therearcar,unabletobrakeintime,switches
totherightlanetoavoidcollidingwiththefrontcar,unawarethattheegovehicleisbehindit. In
thissituation,theegoisresponsibleforquicklyrecognizingthepotentialfortherearcartochange
lanesduetothefrontcar’sabruptdecelerationandmustreactbydeceleratingpromptlytoprevent
acollision. WewilldemonstratedetailedimplementationsofthescriptwriterandLASER-Agent
moduleswiththeexampleshowninFigure1inthefollowingsections.
3.2 Scriptwriter
Directlyexecutinguserrequirementswithautonomousagentsisunstable. Userrequirementscanbe
ambiguous,leadingtovaryingbehaviorsacrossdifferentexecutionattempts. Additionally,fulfilling
the user requirement often requires coordination among multiple autonomous agents. Without
4a shared consensus on how to achieve this goal, these agents may act independently, potentially
resultinginfailure.
Toaddressthesechallenges,weusescriptwritertotranslateuserrequirementsintoscripts. Toensure
consistency across different execution attempts, the behaviors in the script must be detailed and
concrete,withsub-scriptsthatcontaindetailedLCBinstructionsforeachagenttoexecute. Toensure
effectivecoordination,thesesub-scriptsmustalignunderasinglemasterscript,servingasaunified
consensusforallagents.
Inourwork,thegenerationofscriptsfollowsahierarchicalchain-of-thought(CoT)manner[Wei
et al., 2023a] to enhance the common-sense reasoning and planning ability of LLM as GPT-4o
does[OpenAI,2024]. Thescriptwriterfirstgeneratesamasterscriptthatoutlinestheframework
ofthestory,thenfurthergeneratessub-scriptsthatcontaindetailedLCBinstructionsforeachactor
basedonthemasterscript. Thisensuresbehaviorconsistencyoveragentsandexecutions. Thescripts
arewritteninnaturallanguage,toenableeasyeditingofthebehaviors. Thegeneratingprocedureof
themasterscriptandsub-scriptsforindividualagentsareshowninthefollowingparagraphs.
Master-script Generation. Based on the user’s initial requirements and (optionally) a map de-
scriptiontospecifythesurroundinglayout,thescriptwritergeneratesamasterscriptusingaCoT
approach. First,thescriptwriterpromptstheLLMtogenerateastorythatalignswiththeuser’s
requirements. TheLLMthenoutlineskeystagesinthesequenceofevents,startingwiththeinitial
state,whereeachstageactsasadirectcauseorprerequisiteforthenext. Forexample,giventheuser
requirementsillustratedinFigure1,thefollowingmasterscriptisproduced:
1. Initialstate: TheVehicleUnderTest(VUT)isintherightmostlane,withtwocarsahead
intheleftmostlane.
2. Stage 1: The front car in the leftmost lane suddenly decelerates. Reasoning: The de-
celeration may be due to an obstacle or the need to reduce speed significantly for an
intersection.
3. Stage2: Therearcarintheleftmostlaneswervesintotherightmostlane. Reasoning: The
rearcarswervestoavoidacollisionwiththefrontcar.
Sub-scriptsGeneration. Basedonthemasterscript,thescriptwriterqueriestheLLMtogenerate
sub-scriptscontainingdetailed,step-by-stepLCBinstructionsforeachindividualactor. Thesesub-
scriptsclearlyoutlinethespecificactionseachactormustperform,usingnaturallanguagetochain
behaviorslogically. Eachactionispairedwithaterminationcondition,specifyingwhenthetaskis
completeandwhenthenextactionshouldbegin,alongwiththereasoningbehindit. Thisensures
thatthebehaviornotonlyalignswiththeoverallnarrativebutalsoallowsforflexibleexecutionby
theautonomousagent.
Theresultingsub-scriptsarestructuredsimilarlytomoviescripts. Theybeginwithaninitialstate,
definingtheactortype(e.g.,truck,car,orpedestrian),andthenbreakdownintoseveralsequential
steps. Eachstepincludesanaction,terminationconditionsandareason,allofwhichworktogether
tolinktheactor’sbehaviorwithlogicaldecision-making. Anexampleofasub-scriptisshownin
Figure1. Theinitialstatespecifiestheactor’slateralandlongitudinalposition,aswellasitsinitial
speed. Theactiondefinesasimple,concretemotionthatcanbeeasilyexecutedbyour LASER-
Agent,suchasmergingintotheleftmostlane. Theterminationconditionoutlinesmeasurablecriteria,
whichmaydependontheactor’sownbehaviororinteractionswithothers,forexample,whenthe
longitudinaldistancetoanothervehicleiswithin2meters. Finally,thereasonclarifiestherationale
behind each action, enhancing the agent’s understanding and enabling more flexible execution,
especiallyduringinteractionswithotheractors.
3.3 LASER-agent
Thesecondstageofgroundingthesub-scriptsintoexecutionisachievedthroughthecollaboration
of LASER-Agents. To facilitate the comprehension of language instructions and behavior, we
employLLM-controlleddrivingagents. Theseagents,designedtooperateautonomously,executethe
sub-scriptsstepbystepbasedonreal-timeenvironmentalobservations,workingtogethertobringthe
entirescenariotolife. Sincefine-tuningLLMswithvehiclecontrolsignalsandapplyingLLMsto
learning-basedplannersbothrequiresubstantialcomputationalresourcesduringruntime(especially
5when managing multiple agents), we integrate each agent with an LLM-based decision module
alongsidearule-basedplanner. TheLLM-baseddecisionmodule,equippedwithcommon-sense,
playsacrucialroleinconvertinglanguage-basedLCBinstructionsintoexecutableactions. Every0.5
seconds,theLASER-Agentencodestheenvironmentalscenariointoadescriptiveformat,integrates
sub-scriptLCBinstructionstocreateaprompt,andqueriestheLLMforanexecutabledecision. This
decisionisthencarriedoutbytherule-basedplanner.
LLM-basedDecisionModule. ThismoduleprocessesthescenariodescriptionalongwithLCB
sub-scriptinstructions,generatinganexecutabledecisionevery0.5seconds. Itbeginsbychecking
iftheterminationconditionforthecurrentstepismet. Ifthestepiscomplete,ittransitionstothe
nextone. Themodulethenpredictsanexecutabledecisionbasedonthestep’sinstructionsandthe
scenariodescription,whichincludesparameterssuchastargetspeed,lanechangedirectionandlane
changedelay.
LLMbringsacommon-senseunderstandingtotranslatelanguageinstructionstoexecutabledecisions.
InsteadofdirectlyoutputtingvehiclecontrolsignalswhereLLMsdonotexcel, thishigher-level
decision-makingprocessoffersbetteralignmentwiththemodel. Thisapproachenableszero-shot
groundingoflanguage-specifiedbehaviorsmoreeffectively.
ToenhanceLLM’scomprehensionofthecurrenttrafficenvironment,weencodethesurrounding
trafficconditionsintoastandardizedtextualscenariodescription,followingtheapproachoutlinedin
DiLu[Wenetal.,2023]. Thisdescriptionincludesallessentialinformationfordecision-making,such
asthenumberofavailablelanes,thepositions,speedsandlane-changestatusesofboththesubject
vehicleandsurroundingvehicles.
Rule-basedPlanner. ItoutputsvehiclecontrolsignalstoexecutethedecisionsmadebytheLLM-
baseddecisionmoduleateveryframe. Ittracksapathconsistingofwaypointsonthemapanduses
PIDcontrol[Wikipedia,2023]toregulatespeed. Whenevertherule-basedplannerreceivesanew
decisionfromtheLLM-baseddecisionmodule,itgeneratesanewpathbasedonthecurrentposition,
followingthelanechangedirectionandthedelayspecifiedinthedecision. Ateachframe,theplanner
tracksthewaypointsonthepath,whilethePIDcontrollercalculatesvehicle’ssteeringandthrottle.
Thislightweightdesignallowsthecontrolofmultipleagentssimultaneously,enablingtheircomplex
behaviorsandinteractions. Therule-basedplannerfunctionsasahumbleexecutoroftheLLM’s
decisions,withoutincorporatingsafetyconstraintssuchasmaintainingdistancefromothervehicles.
Thisdesignensuresthattheagentcanexhibitalarminglyrealisticbehaviors.
4 Evaluation
In this section, we present a comprehensive evaluation of script writer and LASER-Agents for
on-demandtrafficsimulation. Allcodeandtheresultsareavailableonananonymousrepository. 1
4.1 Setting
Userrequirements. Wedesign17scenariogenerationtasks,eachrepresentingacomplextraffic
executionrequirementthatischallengingtocapturethroughtraditionalroadcollectionorexisting
simulationmethods.(cf.Table3inAppendixA.1.1fordetails).Forexample,taskssuchas“Accident",
“Ambulance",and“recklessDriving"presentlong-tailscenariosthatarerarelyencountered.“Swerve"
and“ThreeinLine1"depictreasonablesafety-criticalsituationswhereevenexperienceddrivers
couldmakemistakes. Tonavigatethesescenarioseffectively,onemustbeabletoanticipatesignsof
animpendingaccident.
LASERSetup. OurexperimentutilizesCARLA0.9.15[Dosovitskiyetal.,2017],awidelyused
open-sourcesimulatorforclosed-loopADStesting. BuiltontheUE4engine,CARLAoffersrealistic
graphics,avarietyofvehicleandpedestrianmodels,anddiversemaps. Weassesseachtaskacross
threeroadsegmentsfromTown04,Town05,Town06andTown10,conducting20simulationsper
segment for effectiveness (totaling 60 simulations per task) and 5 simulations per segment for
efficiency(totaling15simulationspertask).
1https://github.com/CXYyp5SkNg/CXYyp5SkNg.github.io
6Table1: Evaluationofuserinvolvementinscriptgeneration. (*indicatesafety-criticaltasks)
Task Userinvolvementpercentage↓
Accident 5.43%
Ambulance 4.41%
CaughtinPincer 0.47%
FailedatStart 7.36%
NewbieLaneChange2 0.35%
Cut-in* 1.50%
Swerve* 3.15%
ThreeinLine1* 2.74%
average 3.18%
"Vehicle Under ( BTe lus et" ) p spo esi et dio : n 8: m[3 /, s67] Controlled by Interfuser.
"fron (Bt_ lac ca kr" ) p spo esi et dio : n 6: m[2 /, s45] A T R::: SRD e ie mdc uue lcl ae e tr esa pt see ue dd d et no d0 e m ce/ ls e. ration. A T R::: REM ena mdin aot if na i sn sc t 0 e on pm e p./ es d s ap fe te ed r din e l ca en le e r2 ation.
"rear (_ Rc ea dr" ) p spo esi et dio : n 6: m[2 /, s55] A T R ::: tMFM rr a aa o i vi n nn et tt l_ a ia nii c n gn a sr a6 a t d fm ae e/ c ss fe t ols ee lp l ar oe da we yt id e n s s gi p n t ed o el ia s dln te .e as ns2 c . t eh wan h i5 lem /s. A T R fr::: o ATC nh h v toa e cin d acg r ae c .r o f lir ls io snm ioo ntl a i wn n ie tl a h2 n set u o 2 d l . da en ne l y3 . decelerating A T R::: CEM ona ndi tn o it nfa u i s en c m6 en om e v./ ins g s ap fe te ed r i sn w l ea rn ve i n3 g. .
Execution
Figure2: Acaseofscriptgenerationresult. (A:ActionT:TerminationConditionR:Reason)
AllexperimentsemployGPT-4oastheLLM,whichqueriesevery0.5seconds. AppendixA.1.3
showsanexampleofLLMreasoningprocess. ToevaluateinteractionsbetweenLASER-Agentsand
ADSinsafety-criticalscenarios,weuseourLASER-Agentstotesttheend-to-endADSInterFuser
[Shaoetal.,2023],whichranked#1intheCARLAchallenge2022amongtheopensourcemodels.
Road Segments. We evaluate each task on three highway segments with varying lane numbers
(includingonecurvedsegment)andthreeurbansegments(includingacurvedroad)toassessthe
generalizabilityofLASER.
Metrics. Theeffectivenessofscriptwriterismeasuredbytheuserinvolvementpercentage,defined
astheaverageproportionofuser-providedcharacters(excludingspacesandnewlines)inthefinal
executablescript. Weassessscriptexecutionsuccessrateasthenumberoftrafficsimulationsmeeting
userrequirementsdividedbythetotalnumberofsimulationsconducted.Generatedtrafficsimulations
aremanuallyreviewedagainstcriteriaoutlinedinTable4(inAppendixA.1.3).Efficiencyisevaluated
usingtokencost,definedasthenumberoftokensusedpersimulationsecondperagent,andtime
cost,representingthereal-worldsimulationtimepersimulationsecond.
4.2 Evaluationonscriptgeneration
To evaluate the effectiveness of on-demand script generation, we select eight user requirements
relatedtolong-tailedscenariosfromthetaskset. Foreachtask,scriptwritergeneratesfivescripts,
whichwethenmanuallyrefineuntilthescriptssuccessfullyfulfilltheuserrequirements.
TheexperimentalresultsaresummarizedinTable1,whileFigure2visualizesaselectedcaseforthe
task“Swerve". Theresultsindicatethatscriptwritereffectivelygenerateson-demandscripts,with
anaverageuserinvolvementpercentageofjust3.18%. Mostinaccuraciesinscriptwriter’soutputs
stemfromimprecisenumericalvalues,suchaspositionsandspeeds. Additionally,thereareinstances
wherescriptwriteroverlooksstepsimpliedbytheuserrequirements. Forexample,inthe“Failedat
Start"taskillustratedinFigure4(AppendixSectionA.1.2),thebusshouldinitiallymoveintheleft
7Accident
An accident occurred on the highway.
One car turned left to avoid it, but
with the left lane occupied, the
following car turned right.
Ambulance
On the highway, an ambulance is driving
straight at high speed. Multiple
vehicles in the same lane move to both
sides to make way for it.
Bus
A bus switched from the middle lane to
the bus stop, then started again and
and changed lanes back.
Cut-in*
A car overtakes the VUT and then
slows down.
Reckless Driving
A reckless driver repeatedly overtakes
other cars on the highway.
Sudden
Jaywalker*
The VUT was moving in the left lane
behind a stopped truck. As it
approached, a pedestrian emerged
from behind the truck.
Swerve*
There are two cars ahead of ego on the
left lane. The front car suddenly
decelerates, and the rear car swerves
to the right to avoid a collision.
Three in Line 1*
There are two cars in front of the
VUT. The car at the very front slows
down, and the second car, to avoid a
collision, changes lanes to the right.
Figure3: Thevisualizedresultsforscriptexecution. (*indicatesafety-criticaltasks)
lanewhilethecarstopsintherightlane,beforebothvehicleschangelanessimultaneously. However,
scriptwriterincorrectlybypassesthisstep,causingthebustochangelanesatthestart.
4.3 Evaluationonscriptexecution
Toevaluatetheeffectivenessandefficiencyofscriptexecution,weselecteightuserrequirementsfrom
ourtasksetthatinvolvecomplexinteractions,includingfourtasksfocusedonsafety-criticalscenarios.
Foreachtask,scriptwritergeneratesascriptbasedontheuserrequirement,whichwethenmanually
modifytoensureitmeetstherequirementsfully. Scriptsareexecutedbyour LASER-Agentsto
assesstheireffectivenessandefficiency.
Effectiveness. TheexperimentalresultsareshowninTable2. Theresultsindicatethat LASER-
Agentssuccessfullyexecutethescripts,achievinganaveragesuccessrateof90.48%. Mosterrors
arisefrominaccuraciesinnumericalcomparisons,suchaspositionsandspeeds,whilesomemistakes
resultfromhallucination.
8Table2: Resultsofeffectivenessandefficiencyforscriptexecution. (*indicatessafety-criticaltasks)
Task Roadtype Executionsuccessrate↑ Tokencost↓ Timecost↓
Accident highway 100% 1,556.08 9.63
Ambulance highway 96.43% 2,387.81 15.63
Bus urban 91.67% 1828.40 7.02
RecklessDriving highway 44.07% 2333.84 7.11
Cut-in* urban 98.33% 1305.83 5.76
SuddenJaywalker* urban 100% 2130.40 7.55
Swerve* highway 100% 732.37 5.60
ThreeinLine1* highway 93.33% 573.99 4.62
average 90.48% 1606.09 7.87
Efficiency. TheefficiencyresultsarepresentedinTable2,revealinganaverageof1,606.09tokens
and7.87sforgeneratingaone-secondsimulation. IntheAmbulancetask,theinclusionofmultiple
dummyagentstosimulatecongestionsignificantlyincreasedtheinputtokensneededtodescribe
othervehicles’states,leadingtoahighertokencost. Similarly,theRecklessDrivingandSudden
Jaywalkertasksrequirelengthyscriptsfortheactors,resultinginelevatedinputtokencounts. Using
GPT-4o API service, generating a 40-second simulation with 3 LASER-Agents incurs a cost of
approximately$1. ThemajorityofthetimecostisattributedtoqueryingtheLLM,witha10-second
simulationtakingaroundoneminutetogenerate.
5 Limitations
Manualdescriptionofmaplayout. LASER’sexecutionreliesonmanuallyformattingmaplayouts
forscenariogeneration. Thisapproachcanleadtoinaccuraciesandinefficiencies,particularlyin
complexenvironments. Implementingautomatedmapinterpretation(e.g.,queryingimage-to-text
modelswiththeinitialframe)couldgreatlyenhancetheframework’sscalabilityandaccuracy.
Lackofautomaticsearchforscenariodetails. Thecurrentsystemnecessitatesuser-in-the-loop
revisionforscripts. Whilethisallowstailoringthegenerationthatalignswithusers’intentions,it
restricts the system’s capacity to autonomously generate a multitude of test cases with the same
initialgoalsbutvaryingdetails. Developingamoreintelligentscriptwriter capableofautomatically
searchingforreasonableandelaboratescenariodetailsposesachallengeduetotheknowledgegap
betweenoff-the-shelfLLMsandthespecificrequirementsofthesimulationenvironment.
Computationaloverheadforreal-timeexecution. IntegratingLLM-controlledagentswithreal-
timeexecutionincomplexenvironmentsincurssignificantcomputationaloverhead,especiallywhen
scalingthesimulationtomultipleagents.Futureenhancementscouldfocusonoptimizinginteractions
betweentheLLM-baseddecision-makingmoduleandtherule-basedplanner,aimingtoreducelatency
andcomputationalloadwhilemaintaininghighperformanceanddecisionaccuracy.
Generalizationtoreal-worldscenarios. Althoughourframeworkdemonstratesstrongperformance
insimulatedenvironments,itsabilitytogeneralizetoreal-worlddrivingscenariosmayhingeonthe
simulation’sfidelity. Ensuringthatvirtualagentsaccuratelymimichumandriverbehavioracross
diverseglobalcontextsremainsanongoingchallenge.
6 Conclusion
Inthispaper,weintroduceLASER,anovelapproachthatleveragesLLMstogenerateon-demand
trafficsimulations. Ourtwo-stageframeworkseparatesscenariogenerationfromreal-timeexecution,
providing greater flexibility, scalability, and customizability compared to traditional simulation
methods. ByutilizingLLM-controlledagents,LASERoffersamorehuman-likeinterpretationof
drivingbehaviors,ensuringcoherentandrealisticinteractionswithinthesimulatedenvironment. The
experimentalresultsdemonstratethatLASEReffectivelymeetsdiverseuserrequirementsforboth
generalandsafety-criticaldrivingscenarios,showcasinghighaccuracyandadaptabilityinscenario
creation. Overall,theproposedapproachrepresentsasignificantadvancementinon-demandtraffic
simulationforADStrainingandtesting.
9References
SuneelBelkhale,TianliDing,TedXiao,PierreSermanet,QuonVuong,JonathanTompson,Yevgen
Chebotar,DebidattaDwibedi,andDorsaSadigh. Rt-h: Actionhierarchiesusinglanguage. arXiv
preprintarXiv:2403.01823,2024.
AnthonyBrohan,NoahBrown,JusticeCarbajal,YevgenChebotar,XiChen,KrzysztofChoromanski,
TianliDing, DannyDriess, AvinavaDubey, ChelseaFinn, etal. Rt-2: Vision-language-action
modelstransferwebknowledgetoroboticcontrol. arXivpreprintarXiv:2307.15818,2023.
HolgerCaesar,VarunBankiti,AlexHLang,SourabhVora,VeniceErinLiong,QiangXu,Anush
Krishnan,YuPan,GiancarloBaldan,andOscarBeijbom. nuscenes: Amultimodaldatasetfor
autonomousdriving. InProceedingsoftheIEEE/CVFconferenceoncomputervisionandpattern
recognition,pages11621–11631,2020.
HolgerCaesar,JurajKabzan,KokSeangTan,WhyeKitFong,EricWolff,AlexLang,LukeFletcher,
OscarBeijbom, andSammyOmari. nuplan: Aclosed-loopml-basedplanningbenchmarkfor
autonomousvehicles. arXivpreprintarXiv:2106.11810,2021.
Anh-QuanCao,AngelaDai,andRaouldeCharette. Pasco: Urban3dpanopticscenecompletion
withuncertaintyawareness. InProceedingsoftheIEEE/CVFConferenceonComputerVisionand
PatternRecognition,pages14554–14564,2024.
JordiCasas,JaimeLFerrer,DavidGarcia,JosepPerarnau,andAlexTorday. Trafficsimulationwith
aimsun. Fundamentalsoftrafficsimulation,pages173–232,2010.
DiChen,MeixinZhu,HaoYang,XuesongWang,andYinhaiWang. Data-driventrafficsimulation:
Acomprehensivereview. IEEETransactionsonIntelligentVehicles,2024.
AlexeyDosovitskiy,GermanRos,FelipeCodevilla,AntonioLopez,andVladlenKoltun. Carla: An
openurbandrivingsimulator. InConferenceonrobotlearning,pages1–16.PMLR,2017.
DannyDriess,FeiXia,MehdiSMSajjadi,CoreyLynch,AakankshaChowdhery,BrianIchter,Ayzaan
Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, et al. Palm-e: An embodied multimodal
languagemodel. arXivpreprintarXiv:2303.03378,2023.
AbhimanyuDubey,AbhinavJauhri,AbhinavPandey,AbhishekKadian,AhmadAl-Dahle,Aiesha
Letman,AkhilMathur,AlanSchelten,AmyYang,AngelaFan,etal. Thellama3herdofmodels.
arXivpreprintarXiv:2407.21783,2024.
MartinFellendorfandPeterVortisch. Microscopictrafficflowsimulatorvissim. Fundamentalsof
trafficsimulation,pages63–93,2010.
ShuoFeng,XintaoYan,HaoweiSun,YihengFeng,andHenryXLiu. Intelligentdrivingintelligence
testforautonomousvehicleswithnaturalisticandadversarialenvironment.Naturecommunications,
12(1):748,2021.
Xunjiang Gu, Guanyu Song, Igor Gilitschenski, Marco Pavone, and Boris Ivanovic. Producing
andleveragingonlinemapuncertaintyintrajectoryprediction. InProceedingsoftheIEEE/CVF
ConferenceonComputerVisionandPatternRecognition,pages14521–14530,2024.
SHuang,LDong,WWang,YHao,SSinghal,SMa,TLv,LCui,OKMohammed,BPatra,etal.
Languageisnotallyouneed: aligningperceptionwithlanguagemodels(2023). arXivpreprint
arXiv:2302.14045,2023a.
YuanhuiHuang,WenzhaoZheng,YunpengZhang,JieZhou,andJiwenLu. Tri-perspectiveviewfor
vision-based3dsemanticoccupancyprediction. InProceedingsoftheIEEE/CVFconferenceon
computervisionandpatternrecognition,pages9223–9232,2023b.
HaoyiJiang,TianhengCheng,NaiyuGao,HaoyangZhang,TianweiLin,WenyuLiu,andXinggang
Wang.Symphonize3dsemanticscenecompletionwithcontextualinstancequeries.InProceedings
oftheIEEE/CVFConferenceonComputerVisionandPatternRecognition,pages20258–20267,
2024.
10YimingLi,ZhidingYu,ChristopherChoy,ChaoweiXiao,JoseMAlvarez,SanjaFidler,ChenFeng,
andAnimaAnandkumar. Voxformer: Sparsevoxeltransformerforcamera-based3dsemantic
scenecompletion. InProceedingsoftheIEEE/CVFconferenceoncomputervisionandpattern
recognition,pages9087–9098,2023.
PabloAlvarezLopez,MichaelBehrisch,LauraBieker-Walz,JakobErdmann,Yun-PangFlötteröd,
Robert Hilbrich, Leonhard Lücken, Johannes Rummel, Peter Wagner, and Evamarie Wießner.
Microscopictrafficsimulationusingsumo. In201821stinternationalconferenceonintelligent
transportationsystems(ITSC),pages2575–2582.IEEE,2018.
OpenAI. Introducing openai o1-preview. https://openai.com/index/
introducing-openai-o1-preview/,2024.
DaeheePark,JaeseokJeong,Sung-HoonYoon,JaewooJeong,andKuk-JinYoon. T4p: Test-time
training of trajectory prediction via masked autoencoder and actor-specific token memory. In
ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition,pages
15065–15076,2024.
KatrinRenz,LongChen,Ana-MariaMarcu,JanHünermann,BenoitHanotte,AliceKarnsund,Jamie
Shotton, Elahe Arani, and Oleg Sinavski. Carllava: Vision language models for camera-only
closed-loopdriving. arXivpreprintarXiv:2406.10165,2024.
TimSalzmann,BorisIvanovic,PunarjayChakravarty,andMarcoPavone.Trajectron++:Dynamically-
feasibletrajectoryforecastingwithheterogeneousdata. InComputerVision–ECCV2020: 16th
European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XVIII 16, pages
683–700.Springer,2020.
HaoShao,LetianWang,RuobingChen,StevenLWaslander,HongshengLi,andYuLiu. Reason-
net: End-to-enddrivingwithtemporalandglobalreasoning. InProceedingsoftheIEEE/CVF
conferenceoncomputervisionandpatternrecognition,pages13723–13733,2023.
HaoShao,YuxuanHu,LetianWang,GuangluSong,StevenLWaslander,YuLiu,andHongsheng
Li. Lmdrive: Closed-loopend-to-enddrivingwithlargelanguagemodels. InProceedingsofthe
IEEE/CVFConferenceonComputerVisionandPatternRecognition,pages15120–15130,2024.
SPSharan,FrancescoPittaluga,ManmohanChandraker,etal. Llm-assist: Enhancingclosed-loop
planningwithlanguage-basedreasoning. arXivpreprintarXiv:2401.00125,2023.
SimonSuo,SebastianRegalado,SergioCasas,andRaquelUrtasun. Trafficsim: Learningtosimulate
realisticmulti-agentbehaviors. InProceedingsoftheIEEE/CVFConferenceonComputerVision
andPatternRecognition,pages10400–10409,2021.
Tesla. 2023 investor day | tesla. https://www.youtube.com/watch?v=Hl1zEzVUV7w, 2023.
Accessed: 2024-09-13.
Tesla. Fullself-driving(supervised)|tesla. https://www.youtube.com/watch?v=TUDiG7PcLBs,
2024. Accessed: 2024-09-13.
ChalavadiVishnu,VineelAbhinav,DebadityaRoy,CKrishnaMohan,andChSobhanBabu. Im-
provingmulti-agenttrajectorypredictionusingtrafficstatesoninteractivedrivingscenarios. IEEE
RoboticsandAutomationLetters,8(5):2708–2715,2023.
WenhaiWang,JiangweiXie,ChuanYangHu,HaomingZou,JiananFan,WenwenTong,YangWen,
SileiWu,HanmingDeng,ZhiqiLi,etal. Drivemlm: Aligningmulti-modallargelanguagemodels
withbehavioralplanningstatesforautonomousdriving. arXivpreprintarXiv:2312.09245,2023a.
XiaofengWang,ZhengZhu,GuanHuang,XinzeChen,JiagangZhu,andJiwenLu. Drivedreamer:
Towardsreal-world-drivenworldmodelsforautonomousdriving.arXivpreprintarXiv:2309.09777,
2023b.
YuqiWang,JiaweiHe,LueFan,HongxinLi,YuntaoChen,andZhaoxiangZhang. Drivingintothe
future: Multiviewvisualforecastingandplanningwithworldmodelforautonomousdriving. In
ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition,pages
14749–14759,2024.
11JasonWei,XuezhiWang,DaleSchuurmans,MaartenBosma,BrianIchter,FeiXia,EdChi,QuocLe,
andDennyZhou. Chain-of-thoughtpromptingelicitsreasoninginlargelanguagemodels,2023a.
URLhttps://arxiv.org/abs/2201.11903.
YiWei,LinqingZhao,WenzhaoZheng,ZhengZhu,JieZhou,andJiwenLu. Surroundocc: Multi-
camera 3d occupancy prediction for autonomous driving. In Proceedings of the IEEE/CVF
InternationalConferenceonComputerVision,pages21729–21740,2023b.
Yuxi Wei, Zi Wang, Yifan Lu, Chenxin Xu, Changxing Liu, Hao Zhao, Siheng Chen, and Yan-
fengWang. Editablescenesimulationforautonomousdrivingviacollaborativellm-agents. In
ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition,pages
15077–15087,2024.
LichengWen,DaochengFu,XinLi,XinyuCai,TaoMa,PinlongCai,MinDou,BotianShi,Liang
He,andYuQiao. Dilu: Aknowledge-drivenapproachtoautonomousdrivingwithlargelanguage
models. arXivpreprintarXiv:2309.16292,2023.
YuqingWen,YuchengZhao,YingfeiLiu,FanJia,YanhuiWang,ChongLuo,ChiZhang,Tiancai
Wang,XiaoyanSun,andXiangyuZhang. Panacea: Panoramicandcontrollablevideogeneration
forautonomousdriving. InProceedingsoftheIEEE/CVFConferenceonComputerVisionand
PatternRecognition,pages6902–6912,2024.
Wikipedia. ISO26262–roadvehicles–functionalsafety. https://en.wikipedia.org/wiki/
ISO_26262,2018.
Wikipedia. Proportional–integral–derivative controller — Wikipedia, the free encyclopedia,
2023. URL https://en.wikipedia.org/wiki/Proportional%E2%80%93integral%E2%
80%93derivative_controller.
Danfei Xu, Yuxiao Chen, Boris Ivanovic, and Marco Pavone. Bits: Bi-level imitation for traffic
simulation. In2023IEEEInternationalConferenceonRoboticsandAutomation(ICRA),pages
2929–2936.IEEE,2023.
Jiawei Zhang, Chejian Xu, and Bo Li. Chatscene: Knowledge-enabled safety-critical scenario
generationforautonomousvehicles. InProceedingsoftheIEEE/CVFConferenceonComputer
VisionandPatternRecognition,pages15459–15469,2024.
LinruiZhang,ZhenghaoPeng,QuanyiLi,andBoleiZhou. Cat: Closed-loopadversarialtrainingfor
safeend-to-enddriving. InConferenceonRobotLearning,pages2357–2372.PMLR,2023.
GuoshengZhao,XiaofengWang,ZhengZhu,XinzeChen,GuanHuang,XiaoyiBao,andXingang
Wang. Drivedreamer-2: Llm-enhancedworldmodelsfordiversedrivingvideogeneration. arXiv
preprintarXiv:2403.06845,2024.
12A Appendix
A.1 Experimentdetails
A.1.1 Taskset
Wepresentourtasksetof17userrequirementsinTable3.
Table3: Taskset(*indicatessafety-criticaltasks)
Task Userrequirement
1. Accident Anaccidentoccurredonthehighway. Onecarturnedlefttoavoid
it,butwiththeleftlaneoccupied,thefollowingcarturnedright.
2. Ambulance On the highway, an ambulance is driving straight at high speed.
Multiplevehiclesinthesamelanemovetobothsidestomakeway
forit.
3. Bus Abusswitchedfromthemiddlelanetothebusstop,thenstarted
againandchangedlanesback.
4. CaughtinPincer Acartotheleftisovertaking,forcingtheegovehicletodecelerate,
whileacarbehindspeedsup,pressuringittoaccelerate.
5. Cut-in* AcarovertakestheVUTandthenslowsdown.
6. FailedatStart Acarparkedinfrontofthebusstationstarted,changedlanes,and
collidedwiththebusthatwaschanginglanestopark.
7. MeetinMind1 Twocarssimultaneouslychangelanestothemiddlelane.
8. MeetinMind2 Two cars, unable to see each other, simultaneously attempt to
overtakeacarinthemiddle.
9. MergeAlternately Twocarscollidedintherightlaneataroadintersection,andseveral
carsintherearweavedintotheleftlane.
10. NewbieLaneChange1 A car in front on the right changes lanes without accelerating,
causingacollisionwiththeegovehicle.
11. NewbieLaneChange2 Atruckistotheleftoftheegovehicle,andacarinfrontonthe
rightchangeslaneswithoutaccelerating,causingacollisionwith
theegovehicle.
12. RecklessDriving Arecklessdriverrepeatedlyovertakesothercarsonthehighway.
13. SuddenJaywalker* TheVUTwasmovingintheleftlanebehindastoppedtruck. Asit
approached,apedestrianemergedfrombehindthetruck.
14. Surrounded Four police cars surround the criminal’s vehicle from the front,
back,left,andright.
15. Swerve* There are two cars ahead of ego on the left lane. The front car
suddenlydecelerates,andtherearcarswervestotherighttoavoid
acollision.
16. ThreeinLine1* TherearetwocarsinfrontoftheVUT.Thecarattheveryfront
slowsdown,andthesecondcar,toavoidacollision,changeslanes
totheright.
17. ThreeinLine2 Thefrontcarsuddenlyhitthestoppedcarahead,andtheegocar
collidedwiththefrontcar.
13A.1.2 Experimentdetailsofscriptgeneration
WepresentthevisualizationfortheexecutionofsomerepresentativescriptsinFigure4. Further
examplesaregiveninAppendixA.2forreadability.
Caught in Pincer
A car to the left is overtaking, forcing
the ego vehicle to decelerate, while a
car behind speeds up, pressuring it to
accelerate.
Failed at Start
A car parked in front of the bus
station started, changed lanes, and
collided with the bus that was changing
lanes to park.
Newbie
Lane Change 2
A truck is to the left of the ego
vehicle, and a car in front on the right
changes lanes without accelerating,
causing a collision with the ego vehicle.
Figure4: Thevisualizedresultsforscriptgeneration.
A.1.3 Experimentdetailsofscriptexecution
Criteriaforreviewingsimulations. Wepresentthecriteriaforreviewingsimulationstoevaluate
theeffectivenessofscriptexecutioninTable4.
Table4: Criteriaforreviewingsimulations(*indicatesafety-criticaltasks)
Accident Thetwocarscorrectlychangelanesaccordingtotheirscriptsbeforecollid-
ingwiththestoppedaccidentvehicles.
Ambulance Astheambulanceapproaches,vehiclesinthesamelanemoveasideoneby
onetomakeway,withoutanycollisions.
Bus Thebuschangeslanesandstopsatthebusstationwithina±2.5mrange,
thenstartsagainandchangeslanesback.
RecklessDriving Therecklesscarsuccessfullyovertakesthefirstcarfromtheleftlaneand
thesecondcarfromtherightlane.
Cut-in* Thecarsuccessfullyovertakesthefrontcarthenslowsdown.
SuddenJaywalker* The jaywalker steps out from behind the truck as the ego vehicle ap-
proaches.
Swerve* The front car decelerates to a stop. The rear car changes into the ego
vehicle’slane,nearlyhittingtheegovehiclebeforecollidingwiththefront
car.
ThreeinLine1* Thefrontcardeceleratestoastop,whiletherearcarchangeslanestothe
rightbeforecollidingwiththefrontcar,andthendrivesaway.
ExampleofLLMdecisionmodule’sreasoning. Takethe“rear_car"inthe“Swerve"taskasan
example. FollowingthescriptoutlinedinFigure2,theagentmaintainsitsspeedwhilecruisingon
thehighway. Oncethe“front_car"deceleratesbelow5m/s,theagentimmediatelychangeslanes
totheright. Toachievethis,weencodethesub-scriptandthestateofthe“front_car"intheuser
promptandquerytheintegratedLLM.TheLLMautomaticallyevaluateswhetherthetermination
conditionhasbeenmetbasedonthestateofthe“front_car"andmakesdecisionsaccordingtothe
currentactionspecifiedinthescript.
A.2 AdditionalTasks
WepresentvisualizedresultsforadditionaltasksinourtasksetinFigure5.
14Systemprompt
Youareadrivingassistantinasimulatedscenetohelpusgeneratedangerousscenestotest
autonomousdrivingsystems.
Youmustfollowthestepsgivenbyusertogeneratedangerousscenes. Todothis,youcan
drivealarminglyandignoretrafficrules.
Every0.5s,youwillbegiven:
Steps: Stepstobetakentoaccomplishyourtask.
Previousstep: Thestepyouweretakinginthelast0.5s.
Observations: Thelocation,speed,andaccelerationofyouandothervehiclesinthe2Dplane.
forexample: location=[106.0,3.0]mmeansthevehicle’slongitudinalpositiononthelaneis
106.0manditslateralpositionfromtheleftmostlanecenteris3.0m.
Youshouldresponsemestepbystep:
1. Previous Step Evaluation: Assess the completion status of the previous step based on
observationsandterminationcondition.
2. PreviousStepStatus: Completed/Incomplete
3. YourCurrentStep: Stepyouthinkshouldbetakenbasedonyourcurrentobservations.
Movetonextstepifyouthinkthelaststephasbeencompleted. Forexample: “Currentstep:
stepi. ...".
Finally: Executeactionsforthecurrentframebyatoolcall.
Userpromptbefore“front_car"decelerates
Steps:
Step1. action: Maintain6m/sspeedinlane2,termination_condition: Front_cardecelerates
tolessthan5m/s.
Step2. action: changefromlane2tolane3,termination_condition: Thecarisnotinlane2.
Step3. action: Maintain6m/sspeedinlane3,termination_condition: Holdforthenext10
seconds
Laststep: Step1. action: Maintain6m/sspeedinlane2,termination_condition: Front_car
deceleratestolessthan5m/s.
Observation:
Youaredrivingonaroadwith4lanes,andyouarecurrentlydrivinginthesecondlanefrom
theleft. Yourcurrentpositionis‘(98.54,3.50)‘,where98.54isthelongitudinalpositionand
3.50isthelateralposition. Thelongitudinalpositionisparalleltothelane,andthelateral
positionisperpendiculartothelane. Yourcurrentspeedis5.84m/s, accelerationis0.73
m/sˆ2,andlanepositionis98.54m.
-‘front_car‘isdrivinginthesamelaneasyouandisaheadofyou. Itscurrentpositionis
‘(108.83,3.50)‘,where108.83isthelongitudinalpositionand3.50isthelateralposition.
Thelongitudinalpositionisparalleltothelane,andthelateralpositionisperpendiculartothe
lane. Itscurrentspeedis5.81m/s,accelerationis1.02m/sˆ2,andlanepositionis108.83m.
- ‘VUT‘ is driving on the lane to your right and is behind of you. Its current position is
‘(89.27,7.00)‘,where89.27isthelongitudinalpositionand7.00isthelateralposition. The
longitudinalpositionisparalleltothelane,andthelateralpositionisperpendiculartothe
lane. Itscurrentspeedis7.88m/s,accelerationis3.73m/sˆ2,andlanepositionis89.27m.
LLMreasoningbefore“front_car"decelerates
1. PreviousStepEvaluation: Wearemaintainingaspeedcloseto6m/sinlane2. Thefront
carinthesamelaneisdrivingat5.81m/sandaccelerating.
2. PreviousStepStatus: Incomplete
3. YourCurrentStep: Step1. Maintain6m/sspeedinlane2.
Executingactionsforthecurrentframe:
-Maintainatargetspeedof6m/s
-Followthecurrentlane(lane2)
Let’sproceedwiththeseactions.
15LLMdecisionbefore“front_car"decelerates
current_step_number: 1
lane_change_direction: FOLLOWLANE
lane_change_delay: 0
target_speed: 6
Userpromptafter“front_car"decelerates
Steps:
Step1. action: Maintain6m/sspeedinlane2,termination_condition: Front_cardecelerates
tolessthan5m/s.
Step2. action: changefromlane2tolane3,termination_condition: Thecarisnotinlane2.
Step3. action: Maintain6m/sspeedinlane3,termination_condition: Holdforthenext10
seconds
Laststep: Step1. action: Maintain6m/sspeedinlane2,termination_condition: Front_car
deceleratestolessthan5m/s.
Observation:
Youaredrivingonaroadwith4lanes,andyouarecurrentlydrivinginthesecondlanefrom
theleft. Yourcurrentpositionis‘(104.42,3.50)‘,where104.42isthelongitudinalposition
and3.50isthelateralposition. Thelongitudinalpositionisparalleltothelane,andthelateral
positionisperpendiculartothelane.Yourcurrentspeedis5.76m/s,accelerationis0.70m/sˆ2,
andlanepositionis104.42m.
-‘front_car‘isdrivingonthesamelaneasyouandisaheadofyou. Itscurrentpositionis
‘(114.07,3.50)‘,where114.07isthelongitudinalpositionand3.50isthelateralposition.
Thelongitudinalpositionisparalleltothelane,andthelateralpositionisperpendiculartothe
lane. Itscurrentspeedis4.65m/s,accelerationis1.24m/sˆ2,andlanepositionis114.07m.
- ‘VUT‘ is driving on the lane to your right and is behind of you. Its current position is
‘(97.10,7.02)‘,where97.10isthelongitudinalpositionand7.02isthelateralposition. The
longitudinalpositionisparalleltothelane,andthelateralpositionisperpendiculartothe
lane. Itscurrentspeedis7.99m/s,accelerationis0.65m/sˆ2,andlanepositionis97.10m.
LLMreasoningafter“front_car"decelerates
###PreviousStepEvaluation:
-**PreviousStep**: Maintain6m/sspeedinlane2.
-**Observations**:
-Yourcurrentspeedis5.76m/sandfront_car’sspeedis4.65m/s.
-front_car’sspeedislessthan5m/s,whichmeetstheterminationcondition.
###PreviousStepStatus:
-**Status**: Completed
###YourCurrentStep:
-**CurrentStep**: Step2. Changefromlane2tolane3.
Executingactionsforthecurrentframe:
###Actions:
1. **CurrentStepNumber**: 2
2. **LaneChangeDirection**: RightLaneChange
3. **LaneChangeDelay**: 0.1s
4. **TargetSpeed**: Maintain6m/s
Executingtheaction.
16LLMdecisionafter“front_car"decelerates
current_step_number: 2
lane_change_direction: RIGHTLANECHANGE
lane_change_delay: 0.1
target_speed: 6
Meet in Mind 1
Two cars simultaneously change lanes
to the middle lane.
Meet in Mind 2
Two cars, unable to see each other,
simultaneously attempt to overtake a
car in the middle.
Merge Alternately
Two cars collided in the right lane at a
road intersection, and several cars in
the rear weaved into the left lane.
Newbie
Lane Change 1
A car in front on the right changes
lanes without accelerating, causing a
collision with the ego vehicle.
Surrounded
Four police cars surround the criminal's
vehicle from the front, back, left, and
right.
Three in Line 2
The front car suddenly hit the stopped
car ahead, and the ego car collided
with the front car.
Figure5: Thevisualizedresultsforadditionaltasks.
17