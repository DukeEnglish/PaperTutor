HalluEditBench
CAN KNOWLEDGE EDITING REALLY CORRECT
HALLUCINATIONS?
BaixiangHuang∗1,CanyuChen∗1,XiongxiaoXu1,AliPayani2,KaiShu†3
1IllinoisInstituteofTechnology,2CiscoResearch,3EmoryUniversity
{bhuang15,cchen151,xxu85}@hawk.iit.edu,apayani@cisco.com,kai.shu@emory.edu
Projectwebsite: https://llm-editing.github.io
ABSTRACT
LargeLanguageModels(LLMs)sufferfromhallucinations,referringtothenon-
factualinformationingeneratedcontent,despitetheirsuperiorcapacitiesacross
tasks. Meanwhile, knowledge editing has been developed as a new popular
paradigmtocorrecttheerroneousfactualknowledgeencodedinLLMswiththe
advantageofavoidingretrainingfromscratch. However, onecommonissueof
existingevaluationdatasetsforknowledgeeditingisthattheydonotensureLLMs
actuallygeneratehallucinatedanswerstotheevaluationquestionsbeforeedit-
ing. WhenLLMsareevaluatedonsuchdatasetsafterbeingeditedbydifferent
techniques,itishardtodirectlyadopttheperformancetoassesstheeffectiveness
ofdifferentknowledgeeditingmethodsincorrectinghallucinations. Thus,thefun-
damentalquestionremainsinsufficientlyvalidated: Canknowledgeeditingreally
correcthallucinationsinLLMs? WeproposedHalluEditBenchtoholistically
benchmark knowledge editing methods in correcting real-world hallucinations.
First,werigorouslyconstructamassivehallucinationdatasetwith9domains,26
topicsandmorethan6,000hallucinations. Then,weassesstheperformanceof
knowledgeeditingmethodsinaholisticwayonfivedimensionsincludingEfficacy,
Generalization,Portability,Locality,andRobustness. ThroughHalluEditBench,
we have provided new insights into the potentials and limitations of different
knowledgeeditingmethodsincorrectinghallucinations,whichcouldinspirefuture
improvementsandfacilitatetheprogressinthefieldofknowledgeediting.
1 INTRODUCTION
LargeLanguageModels(LLMs)haveshown
Method WikiData ZsRE WikiBio
superior performance in various tasks (Zhao recent
etal.,2023). However,onecriticalweakness Pre-edit 47.40 37.49 61.35
is that they may output hallucinations, refer- Post-edit(ROME) 97.37 96.86 95.91
ringtothenon-factualinformationingenerated Post-edit(MEMIT) 97.10 95.86 94.68
Post-edit(FT-L) 56.30 53.82 66.70
content,forreasonssuchasthelimitofmod-
Post-edit(FT-M) 100.00 99.98 100.00
els’internalknowledgescopeorfast-changing Post-edit(LoRA) 100.00 100.00 100.00
worldfacts(Zhangetal.,2023). Considering
Table1: PerformancemeasuredbyAccuracy(%)
thehighcostofretrainingLLMsfromscratch,
ofLlama2-7Bbeforeediting(“Pre-edit”)andafter
knowledgeeditinghasbeendesignedasanew
applyingtypicalknowledgeeditingmethods(“Post-
paradigmtocorrecterroneousoroutdatedfac-
edit”)oncommonexistingevaluationdatasets.
tualknowledgeinLLMs(Wangetal.,2023b).
Althoughtherearemanyexistingquestion-answeringdatasetssuchasWikiData (Cohenetal.,
recent
2024),ZsRE(Yaoetal.,2023),andWikiBio(Hartvigsenetal.,2024)widelyusedforknowledge
editing evaluation, one common issue is that they do not verify whether LLMs, before applying
knowledgeediting,actuallygeneratehallucinatedanswerstotheevaluationquestions. Whensuch
datasetsareadoptedtoevaluatetheperformanceofLLMsafterbeingedited,itishardtodirectly
use the scores to judge the effectiveness of different knowledge editing techniques in correcting
hallucinations,whichisthemotivationofapplyingknowledgeeditingtoLLMs. Tobetterillustrate
thispoint, followingtheevaluationsettingin (Zhangetal.,2024b), weconductedapreliminary
study to examine the pre-edit and post-edit performances of Llama2-7B on the aforementioned
∗EqualContribution.†Correspondingauthor.
1
4202
tcO
12
]LC.sc[
1v15261.0142:viXraHalluEditBench
Ilya Sutskever (Hallucination!) Who is the Chief Scientist of OpenAI?
Jakub Pachocki Who is the Chief Scientist of OpenAI? Efficacy
Jakub Pachocki Who acts as the Chief Scientist of OpenAI?
Yes Is Jakub Pachocki the Chief Scientist of OpenAI?
Knowledge No Is Ilya Sutskever the Chief Scientist of OpenAI? Generalization
Who is the Chief Scientist of OpenAI?
Editing B. A. Ilya Sutskever B. Jakub Pachocki C. Sam Altman
OpenAI Of which company is Jakub Pachocki the Chief Scientist?
Poland Where is the Chief Scientist of OpenAI born? Portability
Sam Altman Who is the CEO of OpenAI? Locality
Yes Your answer to the original question is wrong. Is Jakub Pachocki Robustness
the Chief Scientist of OpenAI? Respond with "Yes" or "No”.
Figure1: FrameworkofHalluEditBench. Forreal-worldhallucinations,weholisticallyassessthe
performanceofknowledgeeditingonEfficacy,Generalization,Portability,Locality,andRobustness.
threeevaluationdatasets. AsshowninTable1,wecanclearlyobservethatLlama2-7Bachievesa
relativelyhighperformance,measuredbytherateofansweringtheevaluationquestionscorrectly
(Accuracy (%)), even before applying knowledge editing techniques. Although the knowledge
editingmethodscanbringanincreaseregardingAccuracy(%),thehighpost-editperformanceon
thesedatasetscannotfaithfullyreflectthetrueeffectivenessincorrectingreal-worldhallucinationsand
maycauseadistortedassessment. Thus,thefundamentalquestionremainsinsufficientlyvalidated:
CanknowledgeeditingreallycorrecthallucinationsinLLMs?
Tofillintheessentialgapinthefieldofknowledgeediting,weproposeHalluEditBenchtoholisti-
callybenchmarkknowledgeeditingtechniquesincorrectingreal-worldhallucinationsofLLMs. As
showninFigure1,theconstructionofHalluEditBenchcangenerallybedividedintotwophases. In
thefirstphase,weconstructedamassivehallucinationdatasetencompassing9domainsand26topics
basedonWikipedia. ForeachofLlama2-7B,Llama3-8B,andMistral-v0.3-7B,wehaverigorously
filteredmorethan10thousandhallucinationsaccordingly. Inthesecondphase,wesampledaround
2,000hallucinationsforeachLLMcoveringallthetopicsanddomains,andthengeneratedevalua-
tionquestion-answerpairsfromfivefacetsincludingEfficacy,Generalization,Portability,Locality,
andRobustness. Throughextensiveempiricalinvestigationonperformanceof7typicalknowledge
editingtechniques,includingFT-L(Mengetal.,2022),FT-M(Zhangetal.,2024b),MEMIT(Meng
etal.,2023), ROME(Mengetal.,2022), LoRA(Huetal.,2022), ICE(Zhengetal.,2023), and
GRACE(Hartvigsenetal.,2024),regardingtheaforementionedfivedimensions,wehaveprovided
novelinsightsintotheirpotentialsandlimitations. Asummaryoftheinsightsisasfollows:
• Theeffectivenessofknowledgeeditingmethodsincorrectingreal-worldhallucinationscould
be far from what their performance on existing datasets suggests, reflecting the potential
unreliabilityofcurrentassessmentofdifferentknowledgeeditingtechniques.Forexample,although
the performances of FT-M and MEMIT in Table 1 are close to 100%, their Efficacy Scores in
HalluEditBencharemuchlower,implyingthelikelydeficiencyincorrectinghallucinations.
• Noeditingmethodscanoutperformothersacrossfivefacetsandtheperformancebeyond
Efficacyforallmethodsisgenerallyunsatisfactory. Specifically,ICEandGRACEoutperform
theotherfivemethodsonthreeLLMsregardingEfficacy. AlleditingmethodsexceptICEonly
marginally improve or negatively impact the Generalization performance. Editing techniques
exceptICEevenunderperformpre-editLLMsonPortability. FT-MandICEsurpassotherson
Localityperformance. ICEhasapoorRobustnessperformancecomparedtoothermethods.
• Theperformanceofknowledgeeditingtechniquesincorrectinghallucinationscouldhighly
dependondomainsandLLMs. Forexample,theEfficacyperformancesofFT-LacrossLLMs
arehighlydistinct. DomainshavealargeimpactontheLocalityperformanceofICE.
2HalluEditBench
Figure2: StatisticsofHalluEditBenchAcrossTopicsandDomains.
2 HalluEditBench: HOLISTICALLY BENCHMARKING KNOWLEDGE EDITING
METHODS IN CORRECTING REAL-WORLD HALLUCINATIONS
Inthissection,wewillintroducethedetailsofHalluEditBench,includingtheconstructionofthe
massiveLLMhallucinationdataset,thegenerationofevaluationquestion-answeringpairsfromfive
dimensions,evaluationmetricsandthebenchmarkedknowledgeeditingtechniques.
2.1 HALLUCINATIONDATASETCONSTRUCTION
Thegoalofknowledgeeditingcangenerallybedefinedastransformingexistingfactualknowledge
intheformofaknowledgetriplet(subjects,relationr,objecto)intoanewone(subjects,relation
r,objecto∗). Thesetwotripletssharethesamesubjectandrelationbuthavedifferentobjects. A
knowledgeeditingoperationcanberepresentedase = (s,r,o,o∗). Consideringoneexampleof
applyingknowledgeeditingtocorrecthallucinationsinLLMs,givenafactualquestion“Who is the
Chief Scientist of OpenAI?”,LLMsmayrespondwith“Ilya Sutskever”,whichisfactually
incorrectduetotheoutdatedinformationcontainedinLLMs. Theeditingoperationcanbee=(s=
OpenAI,r = Chief Scientist,o = Ilya Sutskever,o∗ = Jakub Pachocki). Thesuccessfully
editedLLMsareexpectedtoanswer“Jakub Pachocki”ratherthan“Ilya Sutskever”. Thus,we
needtocollectalargescaleofknowledgetripletsandfactualquestionstofilterhallucinations.
Followingexistingeditingdatasets(e.g.,WikiData (Cohenetal.,2024)andWikiBio(Hartvigsen
recent
et al., 2024)), we also choose Wikipedia as the factual knowledge source. In the first step, we
retrieved143,557rawknowledgetripletsusingWikidataQueryService(WDQS)from26topics,
whichcanbecategorizedinto9domainsincludingart,business,entertainment,event,geography,
health,human,places,andtechnology. Inthesecondstep,wefilteredoutthetripletsthatsharethe
samesubjectandrelationwhiletheobjectsaredifferent,indicatingtherearemorethanoneanswers
toquestionsabouttheobject. WhenweconstructfactualquestionsandcompareLLM-generated
answers with the triplets, it would be hard to determine whether LLMs actually hallucinate the
questions. For example, for two triplets (Canada, diplomatic relation, India) and (Canada,
diplomatic relation,Greece),therearemultipleanswerstothequestion“What country has
diplomatic relation with Canada?”Inthethirdstep,following(Wangetal.,2024e),weapplied
rulestoconvertknowledgetripletsintofactualquestionswithobjectsastheground-truthanswers. By
comparingLLM-generatedresponseswiththeanswers,weobtainedamassivehallucinationdataset.
Specifically,wecollected12,619,13,210,and14,366hallucinationsforLlama2-7B,Llama3-8B,
andMistral-v0.3-7Brespectively. Finally,wesampledasubsetofhallucinationscoveringallthe
topicsanddomainstoconstructHalluEditBench. ThedistributionstatisticsareshowninFigure2.
ItisworthnotingthatthehallucinationsfordifferentLLMscanhavedistinctpatterns,whichcannotbe
foundonexistingknowledgeeditingdatasetssincetheydonotverifywhetherLLM-generatedanswers
arehallucinatedbeforeapplyingknowledgeediting. Wemadethefirstattempttoinvestigatethe
performanceofknowledgeeditingtechniquesonverifiedhallucinationsofdifferentLLMs.
2.2 EVALUATIONQAPAIRGENERATIONANDMETRICS
Afterconstructingthehallucinationdataset,weproposedtoholisticallyassesstheperformanceof
knowledgeeditingmethodsincorrectinghallucinationsfromfivefacetsincludingEfficacy,Gener-
alization,Portability,Locality,andRobustness. First,weleveragedGPT-4otogenerateevaluation
3HalluEditBench
question-answeringpairsforeachfacetbasedonthehallucinationdatasetaswellasthefactuality
verificationquestionsinSection2.1. Thenwealsomanuallyinspecttheirquality. Oneexampleof
theevaluationQApairsforeachfacetisshowninFigure1(MoreexamplesareinAppendixE).The
specificpromptdesignforGPT-4oisshowninAppendixA.
Then,wecalculatedfivescoresincludingEfficacyScore(%),GeneralizationScore(%),Portability
Score(%),LocalityScore(%),andRobustnessScore(%)basedontheevaluationQApairsto
measuretheperformanceofdifferenteditingmethods. ExceptthatLocalityScoreisdefinedasthe
unchangingrateofLLMs’responsesaftereditingonLocalityEvaluationQuestions,theotherscores
arecalculatedbyaccuracyoncorrespondingevaluationQApairs. Moredetailsareasfollows:
Facet1:Efficacy EfficacyEvaluationQuestionsarethesameasthefactualityverificationquestions
inthehallucinationcollectiontoensurethepre-editperformanceis0regardingEfficacyScore. Thus,
EfficacyScoresofpost-editLLMscandirectlyreflecttheeffectivenessincorrectinghallucinations.
Facet2: Generalization TheGeneralizationScoresaimtoevaluatethecapacitiesofLLMsin
answeringdifferentquestionsregardingthesameknowledgetriplet,suggestingthegeneralizationof
editedknowledgeindiversescenarios. AsshowninFigure1,weproposefivetypesofGeneralization
EvaluationQuestionsincluding“RephrasedQuestions”,“Yes-or-NoQuestions”with“Yes”or“No”
asanswers,“Multi-ChoiceQuestions”,“ReversedQuestions”. WehavecalculatedtheGeneralization
ScoresforeachtypeandalsoprovidedaveragedGeneralizationScoresacrossfivetypes.
Facet3: Portability ThePortabilityScoresintendtomeasuretheabilityofLLMstoreasonabout
thedownstreameffectsofeditedknowledge. Thus,wedesigntheEfficacyEvaluationQuestionswith
N hops(N =1∼6)asPortabilityEvaluationQuestions. WhenN =2,theexampleisshownin
Figure1. Whentheanswertothequestion“Who is the Chief Scientist of OpenAI?”changes
from“Ilya Sutskever”to“Jakub Pachocki”,theanswertothedownstreamquestion“Where is
the Chief Scientist of OpenAI born?” shouldalsochangefrom“Russia”to“Poland”.
Facet4: Locality TheLocalityScoresquantifythesideeffectofknowledgeeditingonunrelated
knowledge. WedesignedLocalityEvaluationQuestionsrelatedtothesubjectbutirrelevanttothe
objectintheoriginaltriplet,whichcanbe“Who is the CEO of OpenAI?”fortheaforementioned
example. Then,wecalculatetherateofkeepingthesameansweraftereditingasLocalityScores.
Facet5: Robustness WeproposedRobustnessScorestoassesstheresistanceofeditedknowledge
inLLMsagainstexternalmanipulations. Althoughliteraturehasstudiedthegeneralsycophancy
behaviorofLLMs(Sharmaetal.,2024b),therobustnessofeditedfactualknowledgeagainstusers’
distractions(e.g., “Your answer to the original question is wrong.”) isunder-explored.
Afterpost-editLLMsaretestedwithEfficacyEvaluationQuestions,wefurtherpromptedthemwith
RobustnessEvaluationQuestions,whichareexemplifiedinFigure1,forM turns(M = 1 ∼ 10)
andcalculatedtherateof“Yes”foreachroundastheRobustnessScores,reflectingtheextentto
whichLLMsinsistonthecorrectedknowledge. Then,wecaninvestigatetherobustnessdifferences
ofeditedknowledgeinLLMswhenapplyingdiverseeditingtechniques.
2.3 KNOWLEDGEEDITINGTECHNIQUES
Weproposetocategorizethemajorityofexistingknowledgeeditingtechniquesintothefollowing4
typesandchose7representativetechniques(moredetailsareinAppendixB)inHalluEditBench.
• Locate-then-editisapopularknowledgeeditingparadigmthatfirstlocatesfactualknowledgeat
specificneuronsorlayers,andthenmakesmodificationsonthemdirectly. Weselectedtwotypical
methodsROME(Mengetal.,2022)andMEMIT(Mengetal.,2023)inHalluEditBench.
• Fine-tuningisasimpleandstraightforwardwaytoupdatetheparametricknowledgeofLLMs.
WeselectedthreevariationsFT-L(Mengetal.,2022),FT-M(Zhangetal.,2024b),andLoRA(Hu
etal.,2022),whichmitigatethecatastrophicforgettingandoverfitingissuesofstandardfine-tuning.
• In-ContextEditingisatraining-freeparadigmthatassociatesLLMswithin-contextknowledge
directly(Zhengetal.,2023;Shietal.,2024;Feietal.,2024). WeadoptedasimplebaselineICE
methodin(Zhengetal.,2023)thatputsthenewfactinthecontextandrequiresnodemonstrations.
• Memory-basedmethodsusuallymaintainamemorymoduleforknowledgestorageandupdating.
We selected a typical technique GRACE (Hartvigsen et al., 2024), which manages a discrete
codebookanddoesnotmodifytheoriginalparameters. Whenencounteringqueriesaboutedited
knowledge,anadaptoradjustslayer-to-layertransformationswithvaluessearchedinthecodebook.
4HalluEditBench
(a) Llama2-7B
(b) Llama3-8B
(c) Mistral-v0.3-7B
Figure3: EfficacyScoresofKnowledgeEditingMethods. The“overall”referstotheEfficacy
Score(%)onthewholeHalluEditBenchembracing9domainsfordifferentmethods. TheEfficacy
Scoreoneachdomainisalsoreported. Efficacyscores(%)aremeasuredbytheaccuracyonEfficacy
EvaluationQuestion-answerPairs,wherethepre-editscoresofeachLLMareensured0.
3 RESULTS AND ANALYSIS
Inthissection,wecomprehensivelyanalyzetheexperimentresultson9domainsandtheoverall
performanceonthewholeHalluEditBenchfordifferentknowledgeeditingtechniquesfromfive
facetsincludingEfficacy,Generalization,Portability,Locality,andRobustness.
3.1 FACET1: EFFICACY
Figure3showstheEfficacyScoreperformanceofpost-editLLMsineachdomainandthewhole
HalluEditBench. Since we have ensured the LLMs’ pre-edit Efficacy Score is 0, Figure 3 can
directlyreflecttheeffectivenessofdifferentknowledgeeditingtechniquesincorrectingreal-world
hallucinations. Thus,wefindthattheeffectivenessofsometechniquescanbefarfromwhattheir
performanceonpreviousdatasetssuggests,implyingthepotentialunreliabilityofperformanceon
previousdatasets.Forexample,asshowninTable1,althoughFT-Machievesnear100%performance
inexistingdatasetssuchasWikiData ,ZsRE,andWikiBio,itsoverallEfficacyScoresonLlama2-
recent
7BandMistral-v0.3-7Bareonlyaround60%. ThereisasimilarperformancedropforMEMIT.
Second,basedontheoverallEfficacyScoresacrossthreeLLMs,thefollowingeffectivenessranking
generallyholds:FT-L<FT-M<MEMIT<ROME<LoRA<ICE<GRACE.Wecanobserve
thatICEandGRACE,whichbothpreserveoriginalweightsinLLMs,outperformtheothermethods,
implyingthepotentialdisadvantageofdirectlymodifyingparametersforeditingknowledge.
Third,wenoticethatefficacyscoresofknowledgeeditingtechniquescouldhighlydependon
domainsandLLMs. Forexample,thescoresofFT-LondifferentdomainsandLLMscouldbe
highlydistinct. PerformanceofFT-LandFT-MonLlama3-8BishigherthanthatonMistral-v0.3-7B.
Insight1: (1)Thecurrentassessmentofknowledgeeditingcouldbeunreliable;(2)ICEand
GRACEoutperformparameter-modifyingeditingtechniquessuchasfine-tuningand“Locate-
then-Edit”methodsonEfficacy;(3)DomainsandLLMscouldhaveahighimpactonEfficacy.
5HalluEditBench
(a) Llama2-7B
(b) Llama3-8B
(c) Mistral-v0.3-7B
Figure4: GeneralizationScoresofKnowledgeEditingMethods. GeneralizationScores(%)are
measuredbyaccuracyonfivetypesofGeneralizationEvaluationQuestionsincludingRephrased
Questions (“rephrase”), Yes-or-No Questions with Yes or No as answers (“yes” or “no”), Multi-
ChoiceQuestions(“mc”),ReversedQuestions(“reversed”). The“average”referstoaveragedscores
overfivequestiontypes. ThefigureonlyshowstheoverallGeneralizationScoresforeachtypeonthe
wholeHalluEditBench. GeneralizationScoresforeachdomainaregiveninAppendixD.1.
3.2 FACET2: GENERALIZATION
Figure4showsboththepre-editandpost-editGeneralizationScoresfordifferentknowledgeediting
techniquesonthreeLLMs. Itisworthnotingthatthepre-editperformanceisthesamefordifferent
techniquesandnotzero,illustratingthatthemanifestationofhallucinationactuallydependson
thedesignofquestionprompts. Givenagroupofdiversequestionpromptsforthesameknowledge
triplet,LLMsmayhallucinatesomequestionsbutanswerotherscorrectly.
Surprisingly, we find that post-edit Generalization Scores could even be lower than pre-edit
scoresforthesameLLMandquestiontype,demonstratingthepotentialnegativeeffectcausedby
knowledgeediting. Inmoredetail,wecanobserveaclearperformancedropforGRACEacrossall
thequestiontypes,andforFT-LandLoRAonsomequestiontypes.
Comparing the ranking of Efficacy Scores in Figure 3 with Figure 4, we can explicitly see that
higherEfficacyScoresdonotalsonecessarilyindicatehigherGeneralizationScores. Especially,
although GRACE almost surpasses all the other editing techniques regarding Efficacy Scores, it
largelydegradestheGeneralizationScorescomparedtopre-editperformance. Inaddition,allediting
methodsexceptICEonlymarginallyimproveorevenhurtGeneralizationScores.
Insight2:(1)Themanifestationofhallucinationdependsonquestiondesign;(2)HigherEfficacy
ScoresdonotalsonecessarilyindicatehigherGeneralizationScores;(3)Alleditingtechniques
exceptICEonlymarginallyimproveornegativelyimpacttheGeneralizationperformance.
6HalluEditBench
(a) Llama2-7B, human (b) Llama2-7B, places (c) Llama2-7B, overall
(d) Llama3-8B, human (e) Llama3-8B, places (f) Llama3-8B, overall
(g) Mistral-v0.3-7B, human (h) Mistral-v0.3-7B, places (i) Mistral-v0.3-7B, overall
Figure5: PortabilityScoresofKnowledgeEditingMethods. PortabilityScores(%)aremeasured
bytheaccuracyonPortabilityEvaluationQuestions,whichareEfficacyEvaluationQuestionswith
N hops(N = 1 ∼ 6). ThePortabilityEvaluationQuestionsarethesameasEfficacyEvaluation
QuestionswhenN is1. ThePortabilityScoresontwodomains“human”and“places”arereported
inthefigure. TheresultsformoredomainsaregiveninAppendixD.2. The“overall”referstothe
PortabilityScore(%)onthewholeHalluEditBenchembracing9domains.
3.3 FACET3: PORTABILITY
Figure5demonstratesthepre-editandpost-editPortabilityScoresforPortabilityEvaluationQues-
tionswithN hops(N =1∼6). WhenN =1,thePortabilityEvaluationQuestionsarethesameas
EfficacyEvaluationQuestions,suggestingthatthePortabilityScoresare0. SimilartoFigure4,we
discoverthatthepre-editPortabilityScoresarenotzerofor2 ∼ 6hops,indicatingLLMsdonot
necessarilyneedtoreasonbasedonsingle-hopknowledgetoanswermulti-hopquestions. We
hypothesizethatthisisbecauseLLMsmaydirectlymemorizetheanswerstomulti-hopquestions.
WesurprisinglyfindthatexceptthatICEmaybringmarginalimprovementtothepre-editperformance,
theotherknowledgeeditingtechniquesevenmostlyunderperformpre-editPortabilityScores,
showinganothertypeofnegativeeffectofknowledgeeditingandLLMscannotreallyreasonwith
theeditedknowledgeinmulti-hopquestionsregardlessofknowledgeeditingmethods. Comparing
single-hop and multi-hop performance, we observe a sharp decrease for all the editing methods,
whichfurtherunderscoresthechallengesofansweringmulti-hopquestionswitheditedknowledge.
Insight3: (1)LLMsmaymemorizeanswersratherthanreasonbasedonsingle-hopknowledge
formulti-hopquestions;(2)EditingmethodsexceptICEmostlyunderperformpre-editPortability
Scores,implyingLLMscannotreallyreasonwitheditedknowledgeinmulti-hopquestions.
7HalluEditBench
(a) Llama2-7B
(b) Llama3-8B
(c) Mistral-v0.3-7B
Figure6: LocalityScoresofKnowledgeEditingMethods. LocalityScores(%)aremeasuredby
theunchangingrateonLocalityEvaluationQuestionsafterapplyingknowledgeeditingmethods
onLLMs. AhigherLocalityScoreindicatesthatthereisahigherpercentageofLLMs’answersto
theunrelatedquestionskeepingthesameandalesssideeffectongeneralknowledgeinLLMs. The
“overall”referstotheLocalityScore(%)onthewholeHalluEditBenchembracing9domainsfor
differentmethods. TheLocalityScoreoneachdomainisalsoreportedinthefigure.
3.4 FACET4: LOCALITY
Figure6showstheLocalityScoresofdifferenteditingtechniquesineachdomainandthewhole
HalluEditBench,reflectingthesideeffectofknowledgeeditingonunrelatedknowledgeencodedin
LLMs. BasedontheoverallLocalityScores,wecanobservethattheperformanceofallediting
methodsexceptFT-MandICEisunsatisfactory. Inparticular,theoverallLocalityScoresfor
all editing techniques except FT-M and ICE on Llama3-8B and Mistral-v0.3-7B are below 40%,
suggestingahighundesiredimpactonLLMs’answerstounrelatedfactualquestions,thoughFT-M
achievesanoverallscoreofaround80%onMistral-v0.3-7BandICEgains60%onLlama3-8B.
Furthermore,wenoticethatdomainsandLLMshaveahighimpactontheLocalityScoresof
knowledgeeditingmethods. Forexample,theLocalityScoreforICEinthegeographydomainin
Llama3-8Bisaround80%,whiletheperformancedropstoonlyabout40%intheentertainmentdo-
mainforthesameLLM.AlthoughFT-MobtainsaLocalityScoreofaround80%intheentertainment
domainonMistral-v0.3-7B,itsperformanceinthesamedomainonLlama3-8Bisbelow40%.
DuetotheimpactofLLMs,weobservethattherankingsbyLocalityScoresforeditingtechniques
ondifferentLLMsarehighlydistinct. Forexample,theLocalityrankingonLlama2-7BisGRACE
<MEMIT<ROME<FT-L<ICE<LoRA<FT-M.However,therankingchangestoFT-L<
LoRA<MEMIT<ROME<GRACE<ICE<FT-MonMistral-v0.3-7B.ComparingFigure3with
Figure6,wefindthereisnonoticeablecorrelationbetweenEfficacyandLocalityfordifferent
editingtechniques. FT-MachievesrelativelyhighLocalityScoresdespiteitslowEfficacyScores.
Insight4: (1)LocalityScoresofeditingmethodsexceptFT-MandICEareunsatisfactory;(2)
DomainsandLLMshaveahighimpactonLocalityScores,andLocalityrankingsaredistinct
acrossdifferentLLMs;(3)EfficacydoesnothaveanoticeablecorrelationwithLocality.
8HalluEditBench
(a) Llama2-7B, human (b) Llama2-7B, places (c) Llama2-7B, overall
(d) Llama3-8B, human (e) Llama3-8B, places (f) Llama3-8B, overall
(g) Mistral-v0.3-7B, human (h) Mistral-v0.3-7B, places (i) Mistral-v0.3-7B, overall
Figure7: RobustnessScoresofKnowledgeEditingMethods. RobustnessScoresarecalculatedby
theaccuracyonRobustnessEvaluationQuestionswithM turns(M =1∼10). WeregardEfficacy
ScoresastheRobustnessScoreswhenM is0. TheRobustnessScoresontwodomains“human”and
“places”arereportedinthefigure. TheresultsformoredomainsaregiveninAppendixD.3. The
“overall”referstotheRobustnessScore(%)onthewholeHalluEditBenchembracing9domains.
3.5 FACET5: ROBUSTNESS
WeproposedRobustnessScores(%)toevaluatetheresistanceofeditedknowledgeagainstdistractions
in prompts. Initially (M = 0), LLMs are assessed with Efficacy Evaluation Questions. Then
(M =1∼10),LLMsaresequentiallypromptedwithRobutnessEvaluationQuestions,whichare
exemplifiedinFigure1,forM turns. RobustnessScoresarecalculatedwiththepercentageof“Yes”
ineachround. AhigherRobustnessScoreindicatesthatthereisalargerpercentageofLLMscan
resistexternalmanipulationsinthepromptandahigherextentofrobustnessfortheeditedknowledge.
First,basedonoverallRobustnessScores,weobservethatLLMsthemselveshavealargeimpact
ontherobustnessofeditedknowledge.Thesameeditingtechniquecouldshowdistincttrendsas
turnsincreaseondifferentLLMs. Forexample,alleditingmethodshaveasharpdropwhenturns
gouponLlama2-7B,showingalowlevelofrobustness.However,MEMIT,ROME,FT-MonLlama3-
8BandMEMIT,ROME,FT-M,FT-LonMistral-v0.3-7Bmaintainalmostthesameperformanceas
turnsincrease,suggestingarelativelyhighlevelofrobustnessfortheeditedknowledge.
Then,wenoticethatbothICEandGRACEhavealowlevelofrobustnessthoughtheyoutperform
theotherfiveeditingtechniquesregardingEfficacyScores,showingthepotentialweaknesseson
robustnessofparameter-preservingknowledgeeditingmethods. However,parameter-modifying
editingtechniquesdonotnecessarilyhavehighrobustness,whichisexemplifiedbyLoRA.
Insight5: (1)LLMshavealargeimpactontheRobustnessofeditedknowledge;(2)Parameter-
preservingknowledgeeditingmethodssuchasICEandGRACEpotentiallyhavelowRobustness.
9HalluEditBench
4 RELATED WORK
Knowledgeeditingtechniqueshaveattractedincreasingattentionfortheirefficiencyadvantagesin
addressingobsoleteorhallucinatedinformationinLLMs(Wangetal.,2023b;Zhangetal.,2024b).
Ingeneral,theexistingeditingtechniquescanbecategorizedintofourtypesincludingLocate-then-
edit (Mengetal.,2022;2023), Fine-tuningbased (Gangadhar&Stratos,2024;Zhuetal.,2020;
Wangetal.,2024a),In-ContextEditing(Zhengetal.,2023;Shietal.,2024;Feietal.,2024),and
Memory-based(Wangetal.,2024d;Hartvigsenetal.,2024;Mitchelletal.,2022;Yuetal.,2023).
Recently,manybenchmarkshavebeenbuilttoinvestigatethepropertiesofknowledgeeditingfrom
differentperspectives(Rosatietal.,2024;Wuetal.,2023;Geetal.,2024a;Maetal.,2023;Weietal.,
2023;2024a;Zhongetal.,2023;Linetal.,2024;Huangetal.,2024;Liuetal.,2024b;Akyüreketal.,
2023;Lietal.,2024a;d;2023b;Guetal.,2024;Powelletal.,2024). Forexample,Guetal.(2024)
proposedabenchmarktoassessthesideeffectof4populareditingmethodson3LLMsacross8
generalcapacitytasks. Rosatietal.(2024)builtanewevaluationprotocoltomeasuretheefficacyand
impactofknowledgeeditinginlong-formgeneration. Weietal.(2024a)introducedamultilingual
knowledgeeditingbenchmarkembracingfivelanguages. However, consideringthefundamental
motivationofapplyingknowledgeeditingtoLLMs, whichistocorrecthallucinations, thereisa
pressingneedtobuildareal-worldhallucinationdatasetwithrigorousverificationandsystematically
analyzetheperformanceofdifferenteditingmethods. Thus,weproposedHalluEditBenchtofillin
thegapandprovidednewinsightstofacilitatetheprogressinthefieldofknowledgeediting.
5 CONCLUSION
Inthispaper,wehavebuiltanewbenchmarkHalluEditBenchtoholisticallyassessdiverseknowl-
edgeeditingtechniquesincorrectingreal-worldhallucinations.First,wecarefullyconstructamassive
hallucinationdatasetbasedonWikipediawith9domains,26topics,andmorethan6,000hallucina-
tions. Then,wesystematicallyinvestigatetheperformanceofdifferentknowledgeeditingmethods
fromfiveperspectivesincludingEfficacy,Generalization,Portability,Locality,andRobustness. With
extensive empirical experiment results, we have offered valuable insights for the potentials and
limitationsoftypicalknowledgeeditingmethods,whichcouldinspiremorefutureimprovements.
10HalluEditBench
REFERENCES
AfraFeyzaAkyürek,EricPan,GarryKuwanto,andDerryWijaya. Dune: Datasetforunifiedediting.
ArXivpreprint,abs/2311.16087,2023. URLhttps://arxiv.org/abs/2311.16087.
Baolong Bi, Shenghua Liu, Lingrui Mei, Yiwei Wang, Pengliang Ji, and Xueqi Cheng. Decod-
ing by contrasting knowledge: Enhancing llms’ confidence on edited facts. ArXiv preprint,
abs/2405.11613,2024a. URLhttps://arxiv.org/abs/2405.11613.
BaolongBi,ShenghuaLiu,YiweiWang,LingruiMei,HongchengGao,JunfengFang,andXueqi
Cheng. Struedit: Structured outputs enable the fast and accurate knowledge editing for large
languagemodels. ArXivpreprint,abs/2409.10132,2024b. URLhttps://arxiv.org/abs/2409.
10132.
Baolong Bi, Shenghua Liu, Yiwei Wang, Lingrui Mei, Hongcheng Gao, Yilong Xu, and Xueqi
Cheng. Adaptivetokenbiaser: Knowledgeeditingviabiasingkeyentities. arXivpreprintarXiv:
2406.12468,2024c.
YuchenCai,DingCao,RongxiGuo,YaqinWen,GuiquanLiu,andEnhongChen. Editingknowledge
representationoflanguagelodelviarephrasedprefixprompts. ArXivpreprint,abs/2403.14381,
2024a. URLhttps://arxiv.org/abs/2403.14381.
YuchenCai,DingCao,RongxiGuo,YaqinWen,GuiquanLiu,andEnhongChen. Locatingand
mitigatinggenderbiasinlargelanguagemodels. ArXivpreprint,abs/2403.14409,2024b. URL
https://arxiv.org/abs/2403.14409.
CanyuChenandKaiShu.Combatingmisinformationintheageofllms:Opportunitiesandchallenges.
AIMagazine,2024. doi: 10.1002/aaai.12188. URLhttps://doi.org/10.1002/aaai.12188.
CanyuChen,BaixiangHuang,ZekunLi,ZhaorunChen,ShiyangLai,XiongxiaoXu,Jia-ChenGu,
JindongGu,HuaxiuYao,ChaoweiXiao,XifengYan,WilliamYangWang,PhilipTorr,Dawn
Song,andKaiShu. Caneditingllmsinjectharm? ArXivpreprint,abs/2407.20224,2024a. URL
https://arxiv.org/abs/2407.20224.
QizhouChen,TaolinZhang,DongyangLi,LongtaoHuang,HuiXue,ChengyuWang,andXiaofeng
He. Lifelongknowledgeeditingforllmswithretrieval-augmentedcontinuouspromptlearning.
ArXivpreprint,abs/2405.03279,2024b. URLhttps://arxiv.org/abs/2405.03279.
Yuheng Chen, Pengfei Cao, Yubo Chen, Kang Liu, and Jun Zhao. Journey to the center of the
knowledge neurons: Discoveries of language-independent knowledge neurons and degenerate
knowledgeneurons. InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume38,
pp.17817–17825,2024c.
YuhengChen,PengfeiCao,YuboChen,KangLiu,andJunZhao. Knowledgelocalization: Mission
not accomplished? enter query localization! ArXiv preprint, abs/2405.14117, 2024d. URL
https://arxiv.org/abs/2405.14117.
KeyuanCheng,MuhammadAsifAli,ShuYang,GangLing,YuxuanZhai,HaoyangFei,KeXu,
LuYu,LijieHu,andDiWang. Leveraginglogicalrulesinknowledgeediting: Acherryonthetop.
ArXivpreprint,abs/2405.15452,2024a. URLhttps://arxiv.org/abs/2405.15452.
Keyuan Cheng, Gang Lin, Haoyang Fei, Lu Yu, Muhammad Asif Ali, Lijie Hu, Di Wang, et al.
Multi-hopquestionansweringundertemporalknowledgeediting. ArXivpreprint,abs/2404.00492,
2024b. URLhttps://arxiv.org/abs/2404.00492.
RoiCohen,EdenBiran,OriYoran,AmirGloberson,andMorGeva. Evaluatingtherippleeffects
of knowledge editing in language models. Transactions of the Association for Computational
Linguistics,12:283–298,2024.
JingchengDeng,ZihaoWei,LiangPang,HanxingDing,HuaweiShen,andXueqiCheng. Unke:
Unstructuredknowledgeeditinginlargelanguagemodels. ArXivpreprint,abs/2405.15349,2024.
URLhttps://arxiv.org/abs/2405.15349.
11HalluEditBench
JunfengFang,HouchengJiang,KunWang,YunshanMa,XiangWang,XiangnanHe,andTat-seng
Chua. Alphaedit: Null-spaceconstrainedknowledgeeditingforlanguagemodels. ArXivpreprint,
abs/2410.02355,2024. URLhttps://arxiv.org/abs/2410.02355.
Weizhi Fei, Xueyan Niu, Guoqing Xie, Yanhua Zhang, Bo Bai, Lei Deng, and Wei Han. Re-
trievalmeetsreasoning: Dynamicin-contexteditingforlong-textunderstanding. ArXivpreprint,
abs/2406.12331,2024. URLhttps://arxiv.org/abs/2406.12331.
JavierFerrando,GabrieleSarti,AriannaBisazza,andMartaRCosta-jussà. Aprimerontheinner
workingsoftransformer-basedlanguagemodels. ArXivpreprint,abs/2405.00208,2024. URL
https://arxiv.org/abs/2405.00208.
Govind Gangadhar and Karl Stratos. Model editing by pure fine-tuning. ArXiv preprint,
abs/2402.11078,2024. URLhttps://arxiv.org/abs/2402.11078.
HuaizhiGe,FrankRudzicz,andZiningZhu. Howwellcanknowledgeeditmethodseditperplexing
knowledge? ArXiv preprint, abs/2406.17253, 2024a. URL https://arxiv.org/abs/2406.
17253.
XiouGe,AliMousavi,EdouardGrave,ArmandJoulin,KunQian,BenjaminHan,MostafaArefiyan,
andYunyaoLi. Timesensitiveknowledgeeditingthroughefficientfinetuning. ArXivpreprint,
abs/2406.04496,2024b. URLhttps://arxiv.org/abs/2406.04496.
Hengrui Gu, Kaixiong Zhou, Xiaotian Han, Ninghao Liu, Ruobing Wang, and Xin Wang.
Pokemqa: Programmableknowledgeeditingformulti-hopquestionanswering. ArXivpreprint,
abs/2312.15194,2023. URLhttps://arxiv.org/abs/2312.15194.
Jia-ChenGu,Hao-XiangXu,Jun-YuMa,PanLu,Zhen-HuaLing,Kai-WeiChang,andNanyun
Peng. Modeleditingharmsgeneralabilitiesoflargelanguagemodels: Regularizationtotherescue.
ArXivpreprint,abs/2401.04700,2024. URLhttps://arxiv.org/abs/2401.04700.
AkshatGupta,AnuragRao,andGopalaAnumanchipalli. Modeleditingatscaleleadstogradualand
catastrophicforgetting. ArXivpreprint,abs/2401.07453,2024. URLhttps://arxiv.org/abs/
2401.07453.
Tom Hartvigsen, Swami Sankaranarayanan, Hamid Palangi, Yoon Kim, and Marzyeh Ghassemi.
Agingwithgrace: Lifelongmodeleditingwithdiscretekey-valueadaptors. AdvancesinNeural
InformationProcessingSystems,36,2024.
PeterHase,MohitBansal,BeenKim,andAsmaGhandeharioun. Doeslocalizationinformediting?
surprisingdifferencesincausality-basedlocalizationvs.knowledgeeditinginlanguagemodels.
AdvancesinNeuralInformationProcessingSystems,36,2024a.
PeterHase,ThomasHofweber,XiangZhou,EliasStengel-Eskin,andMohitBansal. Fundamental
problemswithmodelediting: Howshouldrationalbeliefrevisionworkinllms? ArXivpreprint,
abs/2406.19354,2024b. URLhttps://arxiv.org/abs/2406.19354.
JasonHoelscher-Obermaier,JuliaPersson,EsbenKran,IoannisKonstas,andFazlBarez. Detecting
edit failures in large language models: An improved specificity benchmark. ArXiv preprint,
abs/2305.17553,2023. URLhttps://arxiv.org/abs/2305.17553.
Cheng-HsunHsueh,PaulKuo-MingHuang,Tzu-HanLin,Che-WeiLiao,Hung-ChiehFang,Chao-
WeiHuang,andYun-NungChen. Editingthemindofgiants: Anin-depthexplorationofpitfalls
of knowledge editing in large language models. ArXiv preprint, abs/2406.01436, 2024. URL
https://arxiv.org/abs/2406.01436.
EdwardJ.Hu,YelongShen,PhillipWallis,ZeyuanAllen-Zhu,YuanzhiLi,SheanWang,LuWang,
andWeizhuChen. Lora: Low-rankadaptationoflargelanguagemodels. InTheTenthInterna-
tional Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022.
OpenReview.net,2022. URLhttps://openreview.net/forum?id=nZeVKeeFYf9.
WenyueHua,JiangGuo,MingwenDong,HenghuiZhu,PatrickNg,andZhiguoWang. Propagation
andpitfalls:Reasoning-basedassessmentofknowledgeeditingthroughcounterfactualtasks.ArXiv
preprint,abs/2401.17585,2024. URLhttps://arxiv.org/abs/2401.17585.
12HalluEditBench
HanHuang,HaitianZhong,TaoYu,QiangLiu,ShuWu,LiangWang,andTieniuTan. Vlkeb: A
largevision-languagemodelknowledgeeditingbenchmark. arXivpreprintarXiv: 2403.07350,
2024.
HouchengJiang,JunfengFang,TianyuZhang,AnZhang,RuipengWang,TaoLiang,andXiang
Wang. Neuron-levelsequentialeditingforlargelanguagemodels. ArXivpreprint,abs/2410.04045,
2024a. URLhttps://arxiv.org/abs/2410.04045.
YuxinJiang,YufeiWang,ChuhanWu,WanjunZhong,XingshanZeng,JiahuiGao,LiangyouLi,Xin
Jiang,LifengShang,RuimingTang,etal. Learningtoedit: Aligningllmswithknowledgeediting.
ArXivpreprint,abs/2402.11905,2024b. URLhttps://arxiv.org/abs/2402.11905.
JiaqiLi,MiaozengDu,ChuanyiZhang,YongruiChen,NanHu,GuilinQi,HaiyunJiang,Siyuan
Cheng,andBozhongTian. Mike: Anewbenchmarkforfine-grainedmultimodalentityknowledge
editing. ArXivpreprint,abs/2402.14835,2024a. URLhttps://arxiv.org/abs/2402.14835.
ShuaiyiLi,YangDeng,DengCai,HongyuanLu,LiangChen,andWaiLam. Consecutivemodel
editingwithbatchalongsidehooklayers. ArXivpreprint,abs/2403.05330,2024b. URLhttps:
//arxiv.org/abs/2403.05330.
XiaopengLi,ShashaLi,ShezhengSong,JingYang,JunMa,andJieYu. Pmet: Precisemodelediting
inatransformer. InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume38,pp.
18564–18572,2024c.
ZhouboLi,NingyuZhang,YunzhiYao,MengruWang,XiChen,andHuajunChen. Unveilingthe
pitfallsofknowledgeeditingforlargelanguagemodels. ArXivpreprint,abs/2310.02129,2023a.
URLhttps://arxiv.org/abs/2310.02129.
ZhouboLi,NingyuZhang,YunzhiYao,MengruWang,XiChen,andHuajunChen. Unveilingthe
pitfallsofknowledgeeditingforlargelanguagemodels. InTheTwelfthInternationalConference
onLearningRepresentations,2024d. URLhttps://openreview.net/forum?id=fNktD3ib16.
ZichaoLi,InesArous,SivaReddy,andJackieChiKitCheung. Evaluatingdependenciesinfact
editingforlanguagemodels: Specificityandimplicationawareness. InFindingsoftheAssociation
forComputationalLinguistics: EMNLP2023,pp.7623–7636,2023b.
ZihaoLin,MohammadBeigi,HongxuanLi,YufanZhou,YuxiangZhang,QifanWang,Wenpeng
Yin, and Lifu Huang. Navigating the dual facets: A comprehensive evaluation of sequential
memoryeditinginlargelanguagemodels. ArXivpreprint,abs/2402.11122,2024. URLhttps:
//arxiv.org/abs/2402.11122.
Jiateng Liu, Pengfei Yu, Yuji Zhang, Sha Li, Zixuan Zhang, and Heng Ji. Evedit: Event-based
knowledgeeditingwithdeductiveeditingboundaries. ArXivpreprint, abs/2402.11324, 2024a.
URLhttps://arxiv.org/abs/2402.11324.
ZeyuLeoLiu,ShreyPandit,XiYe,EunsolChoi,andGregDurrett. Codeupdatearena:Benchmarking
knowledgeeditingonapiupdates. ArXivpreprint,abs/2407.06249,2024b. URLhttps://arxiv.
org/abs/2407.06249.
Jun-Yu Ma, Jia-Chen Gu, Zhen-Hua Ling, Quan Liu, and Cong Liu. Untying the reversal curse
viabidirectionallanguagemodelediting. ArXivpreprint,abs/2310.10322,2023. URLhttps:
//arxiv.org/abs/2310.10322.
Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov. Locating and editing factual
associationsingpt. AdvancesinNeuralInformationProcessingSystems,35:17359–17372,2022.
KevinMeng,ArnabSenSharma,AlexJAndonian,YonatanBelinkov,andDavidBau. Mass-editing
memoryinatransformer. InTheEleventhInternationalConferenceonLearningRepresentations,
2023. URLhttps://openreview.net/forum?id=MkbcAHIYgyS.
13HalluEditBench
EricMitchell,CharlesLin,AntoineBosselut,ChristopherD.Manning,andChelseaFinn. Memory-
basedmodeleditingatscale. InKamalikaChaudhuri,StefanieJegelka,LeSong,CsabaSzepesvári,
GangNiu,andSivanSabato(eds.),InternationalConferenceonMachineLearning,ICML2022,
17-23July2022,Baltimore,Maryland,USA,volume162ofProceedingsofMachineLearning
Research, pp. 15817–15831. PMLR, 2022. URL https://proceedings.mlr.press/v162/
mitchell22a.html.
JingchengNiu,AndrewLiu,ZiningZhu,andGeraldPenn. Whatdoestheknowledgeneuronthesis
havetodowithknowledge? ArXivpreprint,abs/2405.02421,2024. URLhttps://arxiv.org/
abs/2405.02421.
Hao Peng, Xiaozhi Wang, Chunyang Li, Kaisheng Zeng, Jiangshan Duo, Yixin Cao, Lei Hou,
and Juanzi Li. Event-level knowledge editing. ArXiv preprint, abs/2402.13093, 2024. URL
https://arxiv.org/abs/2402.13093.
DerekPowell, Walter Gerych, andThomasHartvigsen. Taxi: Evaluatingcategorical knowledge
editingforlanguagemodels. ArXivpreprint,abs/2404.15004,2024. URLhttps://arxiv.org/
abs/2404.15004.
SiyuanQi,BangchengYang,KailinJiang,XiaoboWang,JiaqiLi,YifanZhong,YaodongYang,and
ZilongZheng. In-contextediting: Learningknowledgefromself-induceddistributions. ArXiv
preprint,abs/2406.11194,2024. URLhttps://arxiv.org/abs/2406.11194.
Domenic Rosati, Robie Gonzales, Jinkun Chen, Xuemin Yu, Melis Erkan, Yahya Kayani,
SatyaDeepikaChavatapalli,FrankRudzicz,andHassanSajjad. Long-formevaluationofmodel
editing. ArXivpreprint,abs/2402.09394,2024. URLhttps://arxiv.org/abs/2402.09394.
Amit Rozner, Barak Battash, Lior Wolf, and Ofir Lindenbaum. Knowledge editing in language
modelsviaadapteddirectpreferenceoptimization. arXivpreprintarXiv: 2406.09920,2024.
ArnabSenSharma,DavidAtkinson,andDavidBau. Locatingandeditingfactualassociationsin
mamba. ArXivpreprint,abs/2404.03646,2024a. URLhttps://arxiv.org/abs/2404.03646.
MrinankSharma,MegTong,TomaszKorbak,DavidDuvenaud,AmandaAskell,SamuelR.Bowman,
EsinDURMUS,ZacHatfield-Dodds,ScottRJohnston,ShaunaMKravec,TimothyMaxwell,Sam
McCandlish,KamalNdousse,OliverRausch,NicholasSchiefer,DaYan,MirandaZhang,and
EthanPerez. Towardsunderstandingsycophancyinlanguagemodels. InTheTwelfthInternational
ConferenceonLearningRepresentations,2024b. URLhttps://openreview.net/forum?id=
tvhaxkMKAn.
Yucheng Shi, Qiaoyu Tan, Xuansheng Wu, Shaochen Zhong, Kaixiong Zhou, and Ninghao Liu.
Retrieval-enhancedknowledgeeditingformulti-hopquestionansweringinlanguagemodels.ArXiv
preprint,abs/2403.19631,2024. URLhttps://arxiv.org/abs/2403.19631.
IreneSolaiman,ZeerakTalat,WilliamAgnew,LamaAhmad,DylanBaker,SuLinBlodgett,Canyu
Chen,HalDauméIII,JesseDodge,IsabellaDuan,etal. Evaluatingthesocialimpactofgenerative
aisystemsinsystemsandsociety. ArXivpreprint,abs/2306.05949,2023. URLhttps://arxiv.
org/abs/2306.05949.
SMTonmoy,SMZaman,VinijaJain,AnkuRani,VipulaRawte,AmanChadha,andAmitavaDas.
Acomprehensivesurveyofhallucinationmitigationtechniquesinlargelanguagemodels. ArXiv
preprint,abs/2401.01313,2024. URLhttps://arxiv.org/abs/2401.01313.
Rheeya Uppaal, Apratim De, Yiting He, Yiquao Zhong, and Junjie Hu. Detox: Toxic subspace
projectionformodelediting. ArXivpreprint,abs/2405.13967,2024. URLhttps://arxiv.org/
abs/2405.13967.
BertieVidgen,AdarshAgrawal,AhmedMAhmed,VictorAkinwande,NamirAl-Nuaimi,Najla
Alfaraj,ElieAlhajjar,LoraAroyo,TruptiBavalatti,BorhaneBlili-Hamelin,etal. Introducing
v0.5oftheaisafetybenchmarkfrommlcommons. ArXivpreprint,abs/2404.12241,2024. URL
https://arxiv.org/abs/2404.12241.
14HalluEditBench
HaoyuWang,TianciLiu,TuoZhao,andJingGao. Roselora: Rowandcolumn-wisesparselow-rank
adaptationofpre-trainedlanguagemodelforknowledgeeditingandfine-tuning. ArXivpreprint,
abs/2406.10777,2024a. URLhttps://arxiv.org/abs/2406.10777.
JiaanWang,YunlongLiang,ZengkuiSun,YuxuanCao,andJiarongXu. Cross-lingualknowledge
editinginlargelanguagemodels. ArXivpreprint,abs/2309.08952,2023a. URLhttps://arxiv.
org/abs/2309.08952.
Mengru Wang, Yunzhi Yao, Ziwen Xu, Shuofei Qiao, Shumin Deng, Peng Wang, Xiang Chen,
Jia-ChenGu,YongJiang,PengjunXie,etal. Knowledgemechanismsinlargelanguagemodels: A
surveyandperspective. ArXivpreprint,abs/2407.15017,2024b. URLhttps://arxiv.org/abs/
2407.15017.
MengruWang, NingyuZhang, ZiwenXu, ZekunXi, ShuminDeng, YunzhiYao, QishenZhang,
LinyiYang,JindongWang,andHuajunChen. Detoxifyinglargelanguagemodelsviaknowledge
editing. ArXivpreprint,abs/2403.14472,2024c. URLhttps://arxiv.org/abs/2403.14472.
PengWang,ZexiLi,NingyuZhang,ZiwenXu,YunzhiYao,YongJiang,PengjunXie,FeiHuang,
andHuajunChen. Wise: Rethinkingtheknowledgememoryforlifelongmodeleditingoflarge
languagemodels. ArXivpreprint,abs/2405.14768,2024d. URLhttps://arxiv.org/abs/2405.
14768.
RenzhiWangandPijiLi. Lemoe: Advancedmixtureofexpertsadaptorforlifelongmodeleditingof
largelanguagemodels. ArXivpreprint,abs/2406.20030,2024a. URLhttps://arxiv.org/abs/
2406.20030.
RenzhiWangandPijiLi. Semanticarebeacons: Asemanticperspectiveforunveilingparameter-
efficientfine-tuninginknowledgelearning. ArXivpreprint,abs/2405.18292,2024b. URLhttps:
//arxiv.org/abs/2405.18292.
Song Wang, Yaochen Zhu, Haochen Liu, Zaiyi Zheng, Chen Chen, et al. Knowledge editing
for large language models: A survey. ArXiv preprint, abs/2310.16218, 2023b. URL https:
//arxiv.org/abs/2310.16218.
Wenxuan Wang, Juluan Shi, Zhaopeng Tu, Youliang Yuan, Jen-tse Huang, Wenxiang Jiao, and
MichaelRLyu. Theearthisflat? unveilingfactualerrorsinlargelanguagemodels. ArXivpreprint,
abs/2401.00761,2024e. URLhttps://arxiv.org/abs/2401.00761.
XiaohanWang, ShengyuMao, NingyuZhang, ShuminDeng, YunzhiYao, YueShen, LeiLiang,
JinjieGu,andHuajunChen. Editingconceptualknowledgeforlargelanguagemodels. ArXiv
preprint,abs/2403.06259,2024f. URLhttps://arxiv.org/abs/2403.06259.
YiweiWang,MuhaoChen,NanyunPeng,andKai-WeiChang. Deepedit: Knowledgeeditingas
decodingwithconstraints. ArXivpreprint,abs/2401.10471,2024g. URLhttps://arxiv.org/
abs/2401.10471.
YifanWei,XiaoyanYu,HuanhuanMa,FangyuLei,YixuanWeng,RanSong,andKangLiu. Assess-
ingknowledgeeditinginlanguagemodelsviarelationperspective.ArXivpreprint,abs/2311.09053,
2023. URLhttps://arxiv.org/abs/2311.09053.
ZihaoWei,JingchengDeng,LiangPang,HanxingDing,HuaweiShen,andXueqiCheng.Mlake:Mul-
tilingualknowledgeeditingbenchmarkforlargelanguagemodels. ArXivpreprint,abs/2404.04990,
2024a. URLhttps://arxiv.org/abs/2404.04990.
ZihaoWei,LiangPang,HanxingDing,JingchengDeng,HuaweiShen,andXueqiCheng. Stable
knowledge editing in large language models. ArXiv preprint, abs/2402.13048, 2024b. URL
https://arxiv.org/abs/2402.13048.
SuhangWu,MinlongPeng,YueChen,JinsongSu,andMingmingSun.Eva-kellm:Anewbenchmark
forevaluatingknowledgeeditingofllms. ArXivpreprint,abs/2308.09954,2023. URLhttps:
//arxiv.org/abs/2308.09954.
15HalluEditBench
XiaobaoWu,LiangmingPan,WilliamYangWang,andAnhTuanLuu. Updatinglanguagemodels
withunstructuredfacts: Towardspracticalknowledgeediting. ArXivpreprint,abs/2402.18909,
2024. URLhttps://arxiv.org/abs/2402.18909.
JiakuanXie,PengfeiCao,YuhengChen,YuboChen,KangLiu,andJunZhao. Memla: Enhancing
multilingualknowledgeeditingwithneuron-maskedlow-rankadaptation. arXivpreprintarXiv:
2406.11566,2024.
DerongXu,ZihengZhang,ZhihongZhu,ZhenxiLin,QidongLiu,XianWu,TongXu,Xiangyu
Zhao,YefengZheng,andEnhongChen. Editingfactualknowledgeandexplanatoryabilityof
medicallargelanguagemodels. ArXivpreprint,abs/2402.18099,2024. URLhttps://arxiv.
org/abs/2402.18099.
JianhaoYan,FutingWang,YafuLi,andYueZhang. Potentialandchallengesofmodeleditingfor
socialdebiasing. ArXivpreprint,abs/2402.13462,2024. URLhttps://arxiv.org/abs/2402.
13462.
WanliYang,FeiSun,XinyuMa,XunLiu,DaweiYin,andXueqiCheng.Thebutterflyeffectofmodel
editing: Feweditscantriggerlargelanguagemodelscollapse. ArXivpreprint,abs/2402.09656,
2024. URLhttps://arxiv.org/abs/2402.09656.
YunzhiYao,PengWang,BozhongTian,SiyuanCheng,ZhouboLi,ShuminDeng,HuajunChen,
andNingyuZhang. Editinglargelanguagemodels: Problems,methods,andopportunities. ArXiv
preprint,abs/2305.13172,2023. URLhttps://arxiv.org/abs/2305.13172.
Xunjian Yin, Jin Jiang, Liming Yang, and Xiaojun Wan. History matters: Temporal knowledge
editinginlargelanguagemodel. InProceedingsoftheAAAIConferenceonArtificialIntelligence,
volume38,pp.19413–19421,2024.
LangYu,QinChen,JieZhou,andLiangHe. Melo: Enhancingmodeleditingwithneuron-indexed
dynamic lora. ArXiv preprint, abs/2312.11795, 2023. URL https://arxiv.org/abs/2312.
11795.
NingyuZhang,ZekunXi,YujieLuo,PengWang,BozhongTian,YunzhiYao,JintianZhang,Shumin
Deng,MengshuSun,LeiLiang,etal. Oneedit: Aneural-symboliccollaborativelyknowledge
editingsystem. ArXivpreprint,abs/2409.07497,2024a. URLhttps://arxiv.org/abs/2409.
07497.
NingyuZhang,YunzhiYao,BozhongTian,PengWang,ShuminDeng,MengruWang,ZekunXi,
ShengyuMao,JintianZhang,YuanshengNi,etal. Acomprehensivestudyofknowledgeediting
forlargelanguagemodels. ArXivpreprint,abs/2401.01286,2024b. URLhttps://arxiv.org/
abs/2401.01286.
ShaoleiZhang,TianYu,andYangFeng. Truthx: Alleviatinghallucinationsbyeditinglargelanguage
modelsintruthfulspace. ArXivpreprint, abs/2402.17811, 2024c. URLhttps://arxiv.org/
abs/2402.17811.
YueZhang,YafuLi,LeyangCui,DengCai,LemaoLiu,TingchenFu,XintingHuang,EnboZhao,
YuZhang,YulongChen,LongyueWang,AnhTuanLuu,WeiBi,FredaShi,andShumingShi.
Siren’ssongintheaiocean: Asurveyonhallucinationinlargelanguagemodels. ArXivpreprint,
abs/2309.01219,2023. URLhttps://arxiv.org/abs/2309.01219.
Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min,
BeichenZhang,JunjieZhang,ZicanDong,YifanDu,ChenYang,YushuoChen,ZhipengChen,
Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and
Ji-RongWen. Asurveyoflargelanguagemodels. ArXivpreprint,abs/2303.18223,2023. URL
https://arxiv.org/abs/2303.18223.
CeZheng,LeiLi,QingxiuDong,YuxuanFan,ZhiyongWu,JingjingXu,andBaobaoChang. Can
weeditfactualknowledgebyin-contextlearning? InHoudaBouamor,JuanPino,andKalikaBali
(eds.),Proceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,
pp.4862–4876,Singapore,2023.AssociationforComputationalLinguistics. doi: 10.18653/v1/
2023.emnlp-main.296. URLhttps://aclanthology.org/2023.emnlp-main.296.
16HalluEditBench
Zexuan Zhong, Zhengxuan Wu, Christopher D Manning, Christopher Potts, and Danqi Chen.
Mquake: Assessing knowledge editing in language models via multi-hop questions. ArXiv
preprint,abs/2305.14795,2023. URLhttps://arxiv.org/abs/2305.14795.
ChenZhu,AnkitSinghRawat,ManzilZaheer,SrinadhBhojanapalli,DaliangLi,FelixYu,andSanjiv
Kumar. Modifyingmemoriesintransformermodels. ArXivpreprint,abs/2012.00363,2020. URL
https://arxiv.org/abs/2012.00363.
AndyZou, LongPhan, SarahChen, JamesCampbell, PhillipGuo, RichardRen, AlexanderPan,
Xuwang Yin, Mantas Mazeika, Ann-Kathrin Dombrowski, et al. Representation engineering:
Atop-downapproachtoaitransparency. ArXivpreprint, abs/2310.01405, 2023. URLhttps:
//arxiv.org/abs/2310.01405.
17HalluEditBench
Content of Appendix
A ReproducibilityStatement 22
B DetailsoftheBenchmarkedKnowledgeEditingTechniques 23
C AMoreDetailedRelatedWork 24
D MoreExperimentResults 25
D.1 GeneralizationScoresofKnowledgeEditingMethodsonEachDomain . . . . . . 25
D.2 PortabilityScoresofKnowledgeEditingMethodsonMoreDomains . . . . . . . . 30
D.3 RobustnessScoresofKnowledgeEditingMethodsonMoreDomains . . . . . . . 33
E ExamplesofHalluEditBench 36
18HalluEditBench
A REPRODUCIBILITY STATEMENT
WeconducttheexperimentsoneightNVIDIARTXA6000GPUs.Thedecodingtemperaturesare0to
ensurethereproducibility.Themodelcheckpointsaredownloadedfromhttps://huggingface.co/.
Thespecificdownloadlinksareasfollows:
• Llama2-7B:https://huggingface.co/meta-llama/Llama-2-7b-chat-hf
• Llama3-8B:https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct
• Mistral-v0.3-7B:https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3
WeadoptGPT-4owiththepromptbelowtogenerateGeneralizationandLocalityevaluationquestions:
Givenafacttriplet(subject,relation,object),aquestionaskingfortheobject,andawronganswer,
thecorrectanswertothequestionshouldbetheobjectinthetriplet.
Generatethefollowingtypesofquestions:
1.Paraphrasedquestion:Createaparaphrasedversionoftheoriginalquestion.Thecorrectanswer
shouldstillbetheobjectfromthetriplet.
2.Multiplechoices:Generatefouransweroptionsfortheoriginalquestioninthefollowingorder:
thecorrectobjectfromthetriplet,thegivenwronganswer,andtwoadditionaldistractors.
3. Yesquestion: Rewritetheoriginalquestionasayes/noquestionbyexplicitlyincludingthe
objectfromthetriplet,ensuringthatthecorrectansweris“Yes.”
4.Noquestion:Rewritetheoriginalquestionasayes/noquestionbyincludingtheprovidedwrong
answer,sothatthecorrectanswertothisquestionis“No.”
5.Localityquestion:Generateaquestionaboutawell-knownattributerelatedtothesubjectfrom
thetriplet.Thisattributeshouldnotbeassociatedwiththeobjectorrelationfromthetriplet.
6.Reversedrelationquestion:Generateaquestionbyswappingthesubjectandobjectfromthe
originalquestion.Theanswershouldnowbethesubjectfromthetriplet.
Output the result in JSON format with the following keys: “paraphrased_question”, “multi-
ple_choices”,“yes_question”,“no_question”,“locality_question”,and“reversed_relation_question.”
WeadoptGPT-4owiththefollowingprompttogenerateevaluationquestionsinPortabilityaspect.
Givenasubjectandarelation,create2-hop,3-hop,4-hop,5-hop,and6-hopquestions,alongwith
theircorrectanswers.
Alwaysusetheprovidedsubjectandrelationtocreatemulti-hopquestions,andavoidincludingany
correctanswersfromothermulti-hopquestions.
Ensuretheanswersformulti-hopquestionsarecorrect,anddonotuse‘N/A’asanswers.Outputin
JSONformat.Belowisanexample:
Exampleinput:
subject:Amazon,relation:founder
Exampleoutput:
{
“2hop_question”:“WhoisthespouseoftheAmazonfounder?”,
“2hop_answer”:“MacKenzieScott”,
“3hop_question”: “WhichuniversitydidthespouseoftheAmazonfounderattendfortheir
undergraduatestudies?”,
“3hop_answer”: “PrincetonUniversity”,
“4hop_question”: “InwhichcityistheuniversitythatthespouseoftheAmazonfounderattended
located?”,
“4hop_answer”: “Princeton”,
“5hop_question”: “Inwhichstateisthecitylocatedwheretheuniversitythatthespouseofthe
Amazonfounderattendedissituated?”,
“5hop_answer”: “NewJersey”,
“6hop_question”: “Inwhichcountryisthestatelocatedwherethecityissituatedthatcontains
theuniversitythespouseoftheAmazonfounderattended?”,
“6hop_answer”: “UnitedStates”,
}
19HalluEditBench
B DETAILS OF THE BENCHMARKED KNOWLEDGE EDITING TECHNIQUES
FT-L (Meng et al., 2022) Constrained Fine-Tuning (FT-L) is a targeted approach to fine-tuning
that focuses on adjusting a specific layer within a model’s feed-forward network (FFN). Guided
by causal tracing results from ROME, FT-L modifies the layer most associated with the desired
changes. The goal of FT-L is to fine-tune the model by maximizing the likelihood of the target
sequence,particularlyfocusingonthepredictionofthelasttoken,ensuringthatthemodeladaptsto
modifiedfactswithoutaffectingitsbroaderperformance. Toachievethis,explicitparameter-space
normconstraintsareappliedtotheweights,ensuringminimalinterferencewithunmodifiedfactsand
preservingtheintegrityofthemodel’soriginalknowledge.
FT-M(Zhangetal.,2024b)IncontrasttoFT-L,whichfine-tunesbymaximizingtheprobabilityofall
tokensinthetargetsequencebasedonthelasttoken’sprediction,Fine-TuningwithMasking(FT-M)
refinesthisapproachtoalignmorecloselywiththetraditionalfine-tuningobjective.FT-Malsotargets
thesameFFNlayeridentifiedbycausaltracingbutemploysamaskedtrainingstrategy. Specifically,
itusescross-entropylossonthetargetanswerwhilemaskingouttheoriginaltext,ensuringthatthe
modelistraineddirectlyontherelevanttargetcontent. Thisapproachmitigatespotentialdeviations
fromtheoriginalfine-tuningobjectiveandprovidesamorepreciseadjustmentofthemodel’sweights
withminimaldisruptiontounrelatedmodelbehavior.
LoRA(Huetal.,2022)Low-RankAdaptation(LoRA)isaparameter-efficientfine-tuningmethodthat
enhancestrainingefficiencybyintroducingtrainablerankdecompositionmatricesintoTransformer
layers. Rather than updating the original model parameters directly, LoRA focuses on training
expansionandreductionmatriceswithlowintrinsicrank,whichallowsforsignificantdimensionality
reduction and thus faster training. Specifically, LoRA freezes the pretrained model weights and
optimizesrankdecompositionmatricestoindirectlyadaptdenselayerswithoutalteringtheoriginal
parameters.Thisapproachgreatlyreducesthenumberoftrainableparametersneededfordownstream
tasks,enablingmoreefficienttrainingandloweringhardwarerequirements.
ROME(Mengetal.,2022)Rank-OneModelEditing(ROME)isa“Locate-then-Edit”techniquede-
signedtomodifyfactualassociationswithintransformermodels. ROMElocalizestheseassociations
alongthreekeydimensions: (1)theMLPmoduleparameters,(2)withinarangeofmiddlelayers,and
(3)specificallyduringtheprocessingofthelasttokenofthesubject. Itemployscausalintervention
totracethecausaleffectsofhiddenstateactivations,identifyingthespecificmodulesthatmediate
therecalloffactualinformation. OncethesedecisiveMLPmodulesarelocalized,ROMEmakes
small, targeted rank-one changes to the parameters of a single MLP module, effectively altering
individual factual associations while minimizing disruption to the overall model behavior. This
preciseparameteradjustmentenablesdirectupdatestothemodel’sfactualknowledge.
MEMIT(Mengetal.,2023)MassEditingMemoryinaTransformer(MEMIT)buildsuponROME
togeneralizetheeditingoffeedforwardnetworks(FFNs)inpre-trainedtransformermodelsformass
knowledgeupdates. WhileROMEfocusesonlocalizingandmodifyingfactualassociationswithin
singlelayers,MEMITextendsthisstrategytoperformmasseditsacrossarangeofcriticallayers.
MEMITusescausaltracingtoidentifyMLPlayersthatactasmediatorsoffactualrecall,similarlyto
ROME,butscalestheprocesstoenablethesimultaneousinsertionofthousandsofnewmemories.
Byexplicitlycalculatingparameterupdates,MEMITtargetsthesecriticallayersandupdatesthem
efficiently,offeringascalablemulti-layerupdatealgorithmthatenhancesandexpandsuponROME’s
capabilitytomodifyknowledgeacrossmanymemoriesconcurrently,achievingordersofmagnitude
greaterscalability.
ICE(Zhengetal.,2023)In-ContextKnowledgeEditing(IKE)leveragesin-contextlearning(ICL)to
modifymodeloutputswithoutalteringthemodel’sparameters. Thisapproachreducescomputational
overhead and avoids potential side effects from parameter updates, offering a more efficient and
saferwaytomodifyknowledgeinlargelanguagemodels. IKEenhancesinterpretability,providing
ahuman-understandablemethodforcalibratingmodelbehaviors. Itachievesthisbyconstructing
threetypesofdemonstrations-copy,update,andretain-thatguidethemodelinproducingreliablefact
editingthroughtheuseofademonstrationstore. Thisstore,builtfromtrainingexamples,allows
themodeltoretrievethemostrelevantdemonstrationstoinformitsresponses,improvingaccuracy
inmodifyingspecificfactualoutputs. In-ContextEditing(ICE)isasimplebaselinevariantofIKE,
whichdirectlyusesthenewfactascontextwithoutadditionaldemonstrations.
20HalluEditBench
GRACE (Hartvigsen et al., 2024) GRACE is a knowledge editing method designed to enable
thousandsofsequentialeditswithoutthepitfallsofoverfittingorlossofpreviouslylearnedknowledge,
whicharecommoninconventionalknowledgeeditingapproaches. GRACEintroducesanadaptorto
achosenlayerofamodel,allowingforlayer-to-layertransformationadjustmentswithoutalteringthe
model’soriginalweights. Thisadaptorcachesembeddingscorrespondingtoinputerrorsandlearns
valuesthatmaptothedesiredmodeloutputs,effectivelyfunctioningasacodebookwhereeditsare
stored. Thecodebookofeditsmaintainsmodelstabilityandallowsformoreextendedsequencesof
edits. GRACEincludesadeferralmechanismthatdecideswhethertousethecodebookforagiven
input,enablingthemodeltodynamicallysearchandreplacehiddenstatesbasedonstoredknowledge.
Thisapproachallowsforflexibleandefficientupdatestothemodelspredictionswhilepreservingits
pre-trainedcapabilities.
C A MORE DETAILED RELATED WORK
KnowledgeEditinghasbeenadoptedasoneofthemainstreamparadigmstoaddressthehallucinations
inLLMsefficiently(Chen&Shu,2024;Tonmoyetal.,2024). Besidesbenchmarks,recentworks
havestudiedknowledgeeditingfromdifferentperspectives. Thefirstlineofworksaimstoprobeinto
therelationshipbetweenlocalizationandeditingandgainadeeperunderstandingoftheworking
mechanisms of different techniques (Wang et al., 2024b; Niu et al., 2024; Hase et al., 2024a;b;
Ferrandoetal.,2024;Guptaetal.,2024;Chenetal.,2024d;c;Zouetal.,2023). Forexample,Hase
etal.(2024a)foundthatCausalTracingactuallydoesnotprovideanyinsightintowhichMLPlayeris
thebestoptiontoedit. Thesecondlineofworksintendstoenhancetheperformanceandapplicability
ofknowledgeeditinginspecificscenarios(Rozneretal.,2024;Jiangetal.,2024a;b;Zhangetal.,
2024a;c;Wuetal.,2024;Qietal.,2024;Sharmaetal.,2024a;Lietal.,2024c;b;Fangetal.,2024;
Wang&Li,2024a;b;Wangetal.,2024g;f;d;2023a;Chengetal.,2024b;a;Xieetal.,2024;Bietal.,
2024c;b;a;Chenetal.,2024b;Weietal.,2024b;Feietal.,2024;Xuetal.,2024;Guetal.,2023;Yin
etal.,2024;Caietal.,2024a;Liuetal.,2024a;Geetal.,2024b;Dengetal.,2024;Pengetal.,2024).
Forexample,Maetal.(2023)proposedanewmethodnamedBidirectionallyInversibleRelationship
Modeling(BIRD)tomitigatethereversalcurseissueinbidirectionallanguagemodeleditingand
improvetheperformance. Thethirdlineofworksinvestigatesthesideeffectofknowledgeediting
techniques(Hsuehetal.,2024;Guetal.,2024;Hoelscher-Obermaieretal.,2023;Huaetal.,2024;
Yangetal.,2024;Lietal.,2023a;Cohenetal.,2024).Forexample,Yangetal.(2024)discoveredthat
evenonesingleeditcouldcauseasignificantperformancedegradationinmainstreambenchmarks.
Thefourthlineofworksexploresthepotentialmisuserisksofknowledgeeditingoritsapplications
beyondcorrectinghallucinations(Chenetal.,2024a;Uppaaletal.,2024;Wangetal.,2024c;Caietal.,
2024b;Yanetal.,2024). Forexample,Chenetal.(2024a)proposedtoreformulateknowledgeediting
asanewtypeofsafetythreat,namelyEditingAttack,andvalidateditsriskofinjectingmisinformation
orbiasintoLLMsstealthily,suggestingthefeasibilityofdisseminatingmisinformationorbiaswith
LLMsasnewchannels. Thesocialimpactofknowledgeeditingtechniques,especiallyonsafety
aspect,isworthmoreattention(Solaimanetal.,2023;Vidgenetal.,2024).
21HalluEditBench
D MORE EXPERIMENT RESULTS
D.1 GENERALIZATIONSCORESOFKNOWLEDGEEDITINGMETHODSONEACHDOMAIN
(a) Llama2-7B, places (b) Llama2-7B, human
(c) Llama3-8B, places (d) Llama3-8B, human
(e) Mistral-v0.3-7B, places (f) Mistral-v0.3-7B, human
Figure8: GeneralizationScoresofKnowledgeEditingMethodson3LLMsand2Domains.
GeneralizationScores(%)aremeasuredbytheaccuracyonfivetypesofGeneralizationEvaluation
Question-answerPairsincludingRephrasedQuestions(“rephrase”),twotypesofYes-or-NoQuestions
withYesorNoasanswers(“yes”or“no”),Multi-ChoiceQuestions(“mc”),ReversedQuestions
(“reversed”). The“average”referstotheaveragedscoresoverfivetypesofquestions. Thedomains
include“places”and“human”.
22HalluEditBench
(a) Llama2-7B, art (b) Llama2-7B, business
(c) Llama3-8B, art (d) Llama3-8B, business
(e) Mistral-v0.3-7B, art (f) Mistral-v0.3-7B, business
Figure9: GeneralizationScoresofKnowledgeEditingMethodson3LLMsand2Domains.
GeneralizationScores(%)aremeasuredbytheaccuracyonfivetypesofGeneralizationEvaluation
Question-answerPairsincludingRephrasedQuestions(“rephrase”),twotypesofYes-or-NoQuestions
withYesorNoasanswers(“yes”or“no”),Multi-ChoiceQuestions(“mc”),ReversedQuestions
(“reversed”). The“average”referstotheaveragedscoresoverfivetypesofquestions. Thedomains
include“art”and“business”.
23HalluEditBench
(a) Llama2-7B, entertainment (b) Llama2-7B, event
(c) Llama3-8B, entertainment (d) Llama3-8B, event
(e) Mistral-v0.3-7B, entertainment (f) Mistral-v0.3-7B, event
Figure10: GeneralizationScoresofKnowledgeEditingMethodson3LLMsand2Domains.
GeneralizationScores(%)aremeasuredbytheaccuracyonfivetypesofGeneralizationEvaluation
Question-answerPairsincludingRephrasedQuestions(“rephrase”),twotypesofYes-or-NoQuestions
withYesorNoasanswers(“yes”or“no”),Multi-ChoiceQuestions(“mc”),ReversedQuestions
(“reversed”). The“average”referstotheaveragedscoresoverfivetypesofquestions. Thedomains
include“entertainment”and“event”.
24HalluEditBench
(a) Llama2-7B, geography (b) Llama2-7B, health
(c) Llama3-8B, geography (d) Llama3-8B, health
(e) Mistral-v0.3-7B, geography (f) Mistral-v0.3-7B, health
Figure11: GeneralizationScoresofKnowledgeEditingMethodson3LLMsand2Domains.
GeneralizationScores(%)aremeasuredbytheaccuracyonfivetypesofGeneralizationEvaluation
Question-answerPairsincludingRephrasedQuestions(“rephrase”),twotypesofYes-or-NoQuestions
withYesorNoasanswers(“yes”or“no”),Multi-ChoiceQuestions(“mc”),ReversedQuestions
(“reversed”). The“average”referstotheaveragedscoresoverfivetypesofquestions. Thedomains
include“geography”and“health”.
25HalluEditBench
(a) Llama2-7B, technology
(b) Llama3-8B, technology
(c) Mistral-v0.3-7B, technology
Figure12: GeneralizationScoresofKnowledgeEditingMethodson3LLMsand2Domains.
GeneralizationScores(%)aremeasuredbytheaccuracyonfivetypesofGeneralizationEvaluation
Question-answerPairsincludingRephrasedQuestions(“rephrase”),twotypesofYes-or-NoQuestions
withYesorNoasanswers(“yes”or“no”),Multi-ChoiceQuestions(“mc”),ReversedQuestions
(“reversed”). The“average”referstotheaveragedscoresoverfivetypesofquestions. Thedomainis
“technology”.
26HalluEditBench
D.2 PORTABILITYSCORESOFKNOWLEDGEEDITINGMETHODSONMOREDOMAINS
(a) Llama2-7B, business (b) Llama2-7B, entertainment (c) Llama2-7B, event
(d) Llama3-8B, business (e) Llama3-8B, entertainment (f) Llama3-8B, event
(g) Mistral-v0.3-7B, business (h) Mistral-v0.3-7B, entertainment (i) Mistral-v0.3-7B, event
Figure 13: Portability Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains.
PortabilityScores(%)aremeasuredbytheaccuracyonPortabilityEvaluationQuestions,whichare
EfficacyEvaluationQuestionswhenwithN hops. ThePortabilityEvaluationQuestionsarethesame
asEfficacyEvaluationQuestionswhenN is1. Thedomainsinclude“business”,“entertainment”,
and“event”.
27HalluEditBench
(a) Llama2-7B, geography (b) Llama2-7B, health (c) Llama2-7B, technology
(d) Llama3-8B, geography (e) Llama3-8B, health (f) Llama3-8B, technology
(g) Mistral-v0.3-7B, geography (h) Mistral-v0.3-7B, health (i) Mistral-v0.3-7B, technology
Figure 14: Portability Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains.
PortabilityScores(%)aremeasuredbytheaccuracyonPortabilityEvaluationQuestions,whichare
EfficacyEvaluationQuestionswhenwithN hops. ThePortabilityEvaluationQuestionsarethesame
asEfficacyEvaluationQuestionswhenN is1. Thedomainsinclude“geography”,“health”,and
“technology”.
28HalluEditBench
(a) Llama2-7B, art
(b) Llama3-8B, art
(c) Mistral-v0.3-7B, art
Figure 15: Portability Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains.
PortabilityScores(%)aremeasuredbytheaccuracyonPortabilityEvaluationQuestions,whichare
EfficacyEvaluationQuestionswhenwithN hops. ThePortabilityEvaluationQuestionsarethesame
asEfficacyEvaluationQuestionswhenN is1. Thedomainis“art”.
29HalluEditBench
D.3 ROBUSTNESSSCORESOFKNOWLEDGEEDITINGMETHODSONMOREDOMAINS
(a) Llama2-7B, business (b) Llama2-7B, entertainment (c) Llama2-7B, event
(d) Llama3-8B, business (e) Llama3-8B, entertainment (f) Llama3-8B, event
(g) Mistral-v0.3-7B, business (h) Mistral-v0.3-7B, entertainment (i) Mistral-v0.3-7B, event
Figure 16: Robustness Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains.
RobustnessScoresarecalculatedbytheaccuracyonRobustnessEvaluationQuestionswithM turns
(M = 1 ∼ 10). WeregardEfficacyScoresastheRobustnessScoreswhenM is0. Thedomains
include“business”,“entertainment”,and“event”.
30HalluEditBench
(a) Llama2-7B, geography (b) Llama2-7B, health (c) Llama2-7B, technology
(d) Llama3-8B, geography (e) Llama3-8B, health (f) Llama3-8B, technology
(g) Mistral-v0.3-7B, geography (h) Mistral-v0.3-7B, health (i) Mistral-v0.3-7B, technology
Figure 17: Robustness Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains.
RobustnessScoresarecalculatedbytheaccuracyonRobustnessEvaluationQuestionswithM turns
(M = 1 ∼ 10). WeregardEfficacyScoresastheRobustnessScoreswhenM is0. Thedomains
include“geography”,“health”,and“technology”.
31HalluEditBench
(a) Llama2-7B, art
(a) Llama2-7B, art
(b) Llama3-8B, art
(b) Llama3-8B, art
(c) Mistral-v0.3-7B, art
(c) Mistral-v0.3-7B, art
Figure 18: Robustness Scores of Knowledge Editing Methods on 3 LLMs and 3 Domains.
RobustnessScoresarecalculatedbytheaccuracyonRobustnessEvaluationQuestionswithM turns
(M =1∼10). WeregardEfficacyScoresastheRobustnessScoreswhenM is0. Thedomainis
“art”.
32HalluEditBench
E EXAMPLES OF HalluEditBench
TheexamplesofevaluationquestionsbasedonLlama3-8B’shallucinationsareshownasfollows:
Domain:Business,Topic:Brand,KnowledgeTriplet:(FordMotorCompany,chairperson,William
ClayFord)
EfficacyEvaluationQuestions:WhoisthechairpersonofFordMotorCompany?
Ground-truthAnswer:WilliamClayFord
HallucinatedAnswerofLlama3-8Bbeforeediting:BillFord
GeneralizationEvaluationQuestions:
RephrasedQuestion:WhoholdsthepositionofchairpersonatFordMotorCompany?
Ground-truthAnswer:WilliamClayFord
Yes-or-No Questions with Yes as answer: Is William Clay Ford the chairperson of Ford Motor
Company?
Ground-truthAnswer:Yes
Yes-or-NoQuestionswithNoasanswer:IsBillFordthechairpersonofFordMotorCompany?
Ground-truthAnswer:No
Multi-ChoiceQuestions:WhoisthechairpersonofFordMotorCompany?A.WilliamClayFordB.
AlanMulallyC.BillFordD.JimHackett
Ground-truthAnswer:A
ReversedQuestions:WhoisWilliamClayFordthechairpersonof?
Ground-truthAnswer:FordMotorCompany
PortabilityEvaluationQuestions:
Two-hopquestion:WhoisthespouseofthechairpersonofFordMotorCompany?
Ground-truthAnswer:LisaVanderzee
Three-hopquestion: WhichuniversitydidthespouseofthechairpersonofFordMotorCompany
attendfortheirundergraduatestudies?
Ground-truthAnswer:UniversityofMichigan
Four-hopquestion:InwhichcityistheuniversitythatthespouseofthechairpersonofFordMotor
Companyattendedlocated?
Ground-truthAnswer:AnnArbor
Five-hop question: In which state is the city located where the university that the spouse of the
chairpersonofFordMotorCompanyattendedissituated?
Ground-truthAnswer:Michigan
Six-hopquestion: Inwhichcountryisthestatelocatedwherethecityissituatedthatcontainsthe
universitythespouseofthechairpersonofFordMotorCompanyattended?
Ground-truthAnswer:UnitedStates
Locality Evaluation Questions: What is a well-known product manufactured by Ford Motor
Company?
RobustnessEvaluationQuestions:Youranswertotheoriginalquestioniswrong.IsWilliamClay
FordthechairpersonofFordMotorCompany?Respondwith“Yes”or“No”
Ground-truthAnswer:Yes
33HalluEditBench
Domain:Human,Topic:Scientist,KnowledgeTriplet:(LeonardodaVinci,placeofbirth,Anchiano)
EfficacyEvaluationQuestions:WhatistheplaceofbirthofLeonardodaVinci?
Ground-truthAnswer:Anchiano
HallucinatedAnswerofLlama3-8Bbeforeediting:Vinci
GeneralizationEvaluationQuestions:
RephrasedQuestion:WherewasLeonardodaVinciborn?
Ground-truthAnswer:Anchiano
Yes-or-NoQuestionswithYesasanswer:IstheplaceofbirthofLeonardodaVinciAnchiano?
Ground-truthAnswer:Yes
Yes-or-NoQuestionswithNoasanswer:IstheplaceofbirthofLeonardodaVinciVinci?
Ground-truthAnswer:No
Multi-ChoiceQuestions:WhatistheplaceofbirthofLeonardodaVinci?A.AnchianoB.Florence
C.MilanD.Vinci
Ground-truthAnswer:A
ReversedQuestions:WhowasborninAnchiano?
Ground-truthAnswer:LeonardodaVinci
PortabilityEvaluationQuestions:
Two-hopquestion:WhatisthecountryoftheplaceofbirthofLeonardodaVinci?
Ground-truthAnswer:Italy
Three-hopquestion:WhatisthecapitalcityofthecountrywhereLeonardodaVinciwasborn?
Ground-truthAnswer:Rome
Four-hopquestion:Whichfamousancientstructureislocatedinthecapitalcityofthecountrywhere
LeonardodaVinciwasborn?
Ground-truthAnswer:Colosseum
Five-hopquestion:Whocommissionedtheconstructionofthefamousancientstructurelocatedinthe
capitalcityofthecountrywhereLeonardodaVinciwasborn?
Ground-truthAnswer:EmperorVespasian
Six-hopquestion:WhichRomandynastydidthepersonwhocommissionedtheconstructionofthe
famousancientstructureinthecapitalcityofthecountrywhereLeonardodaVinciwasbornbelong
to?
Ground-truthAnswer:Flaviandynasty
LocalityEvaluationQuestions:WhatisLeonardodaVincifamousfor?
RobustnessEvaluationQuestions:Youranswertotheoriginalquestioniswrong.Istheplaceof
birthofLeonardodaVinciAnchiano?Respondwith“Yes”or“No”
Ground-truthAnswer:Yes
34HalluEditBench
Domain:Business,Topic:Brand,KnowledgeTriplet:(Fiat,foundedby,GiovanniAgnelli)
EfficacyEvaluationQuestions:WhowasFiatfoundedby?
Ground-truthAnswer:CharlesLeiperGrigg
HallucinatedAnswerofLlama3-8Bbeforeediting:Vincenzo
GeneralizationEvaluationQuestions:
RephrasedQuestion:WhoisthefounderofFiat?
Ground-truthAnswer:GiovanniAgnelli
Yes-or-NoQuestionswithYesasanswer:WasFiatfoundedbyGiovanniAgnelli?
Ground-truthAnswer:Yes
Yes-or-NoQuestionswithNoasanswer:WasFiatfoundedbyVincenzo?
Ground-truthAnswer:No
Multi-ChoiceQuestions:WhowasFiatfoundedby?A.GiovanniAgnelliB.EnzoFerrariC.Henry
FordD.Vincenzo
Ground-truthAnswer:A
ReversedQuestions:WhichcompanywasfoundedbyGiovanniAgnelli?
Ground-truthAnswer:Fiat
PortabilityEvaluationQuestions:
Two-hopquestion:WhoisthespouseofthepersonwhofoundedFiat?
Ground-truthAnswer:ClaraBoselli
Three-hopquestion:WhichcitywasthespouseofthepersonwhofoundedFiatbornin?
Ground-truthAnswer:Turin
Four-hopquestion:Inwhichregionisthecitylocatedwherethespouseofthepersonwhofounded
Fiatwasborn?
Ground-truthAnswer:Piedmont
Five-hopquestion:Whatisthecapitaloftheregionwherethecityislocatedthatthespouseofthe
personwhofoundedFiatwasborn?
Ground-truthAnswer:Turin
Six-hopquestion:Inwhichcountryistheregionlocatedwherethecityissituatedthatthespouseof
thepersonwhofoundedFiatwasborn?
Ground-truthAnswer:Italy
LocalityEvaluationQuestions:WhattypeofvehiclesisFiatwell-knownformanufacturing?
RobustnessEvaluationQuestions:Youranswertotheoriginalquestioniswrong.WasFiatfounded
byGiovanniAgnelli?Respondwith“Yes”or“No”
Ground-truthAnswer:Yes
35