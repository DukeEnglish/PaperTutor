[
    {
        "title": "Flash-Splat: 3D Reflection Removal with Flash Cues and Gaussian Splats",
        "authors": "Mingyang XieHaoming CaiSachin ShahYiran XuBrandon Y. FengJia-Bin HuangChristopher A. Metzler",
        "links": "http://arxiv.org/abs/2410.02764v1",
        "entry_id": "http://arxiv.org/abs/2410.02764v1",
        "pdf_url": "http://arxiv.org/pdf/2410.02764v1",
        "summary": "We introduce a simple yet effective approach for separating transmitted and\nreflected light. Our key insight is that the powerful novel view synthesis\ncapabilities provided by modern inverse rendering methods (e.g.,~3D Gaussian\nsplatting) allow one to perform flash/no-flash reflection separation using\nunpaired measurements -- this relaxation dramatically simplifies image\nacquisition over conventional paired flash/no-flash reflection separation\nmethods. Through extensive real-world experiments, we demonstrate our method,\nFlash-Splat, accurately reconstructs both transmitted and reflected scenes in\n3D. Our method outperforms existing 3D reflection separation methods, which do\nnot leverage illumination control, by a large margin. Our project webpage is at\nhttps://flash-splat.github.io/.",
        "updated": "2024-10-03 17:59:59 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.02764v1"
    },
    {
        "title": "Vinoground: Scrutinizing LMMs over Dense Temporal Reasoning with Short Videos",
        "authors": "Jianrui ZhangMu CaiYong Jae Lee",
        "links": "http://arxiv.org/abs/2410.02763v1",
        "entry_id": "http://arxiv.org/abs/2410.02763v1",
        "pdf_url": "http://arxiv.org/pdf/2410.02763v1",
        "summary": "There has been growing sentiment recently that modern large multimodal models\n(LMMs) have addressed most of the key challenges related to short video\ncomprehension. As a result, both academia and industry are gradually shifting\ntheir attention towards the more complex challenges posed by understanding\nlong-form videos. However, is this really the case? Our studies indicate that\nLMMs still lack many fundamental reasoning capabilities even when dealing with\nshort videos. We introduce Vinoground, a temporal counterfactual LMM evaluation\nbenchmark encompassing 1000 short and natural video-caption pairs. We\ndemonstrate that existing LMMs severely struggle to distinguish temporal\ndifferences between different actions and object transformations. For example,\nthe best model GPT-4o only obtains ~50% on our text and video scores, showing a\nlarge gap compared to the human baseline of ~90%. All open-source multimodal\nmodels and CLIP-based models perform much worse, producing mostly random chance\nperformance. Through this work, we shed light onto the fact that temporal\nreasoning in short videos is a problem yet to be fully solved. The dataset and\nevaluation code are available at https://vinoground.github.io.",
        "updated": "2024-10-03 17:59:58 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.02763v1"
    },
    {
        "title": "Interpreting and Editing Vision-Language Representations to Mitigate Hallucinations",
        "authors": "Nick JiangAnish KachinthayaSuzie PetrykYossi Gandelsman",
        "links": "http://arxiv.org/abs/2410.02762v1",
        "entry_id": "http://arxiv.org/abs/2410.02762v1",
        "pdf_url": "http://arxiv.org/pdf/2410.02762v1",
        "summary": "We investigate the internal representations of vision-language models (VLMs)\nto address hallucinations, a persistent challenge despite advances in model\nsize and training. We project VLMs' internal image representations to their\nlanguage vocabulary and observe more confident output probabilities on real\nobjects than hallucinated objects. We additionally use these output\nprobabilities to spatially localize real objects. Building on this approach, we\nintroduce a knowledge erasure algorithm that removes hallucinations by linearly\northogonalizing image features with respect to hallucinated object features. We\nshow that targeted edits to a model's latent representations can reduce\nhallucinations by up to 25.7% on the COCO2014 dataset while preserving\nperformance. Our findings demonstrate how a deeper understanding of VLMs'\nlatent representations can enhance reliability and enable novel capabilities,\nsuch as zero-shot segmentation.",
        "updated": "2024-10-03 17:59:57 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.02762v1"
    },
    {
        "title": "FakeShield: Explainable Image Forgery Detection and Localization via Multi-modal Large Language Models",
        "authors": "Zhipei XuXuanyu ZhangRunyi LiZecheng TangQing HuangJian Zhang",
        "links": "http://arxiv.org/abs/2410.02761v1",
        "entry_id": "http://arxiv.org/abs/2410.02761v1",
        "pdf_url": "http://arxiv.org/pdf/2410.02761v1",
        "summary": "The rapid development of generative AI is a double-edged sword, which not\nonly facilitates content creation but also makes image manipulation easier and\nmore difficult to detect. Although current image forgery detection and\nlocalization (IFDL) methods are generally effective, they tend to face two\nchallenges: \\textbf{1)} black-box nature with unknown detection principle,\n\\textbf{2)} limited generalization across diverse tampering methods (e.g.,\nPhotoshop, DeepFake, AIGC-Editing). To address these issues, we propose the\nexplainable IFDL task and design FakeShield, a multi-modal framework capable of\nevaluating image authenticity, generating tampered region masks, and providing\na judgment basis based on pixel-level and image-level tampering clues.\nAdditionally, we leverage GPT-4o to enhance existing IFDL datasets, creating\nthe Multi-Modal Tamper Description dataSet (MMTD-Set) for training FakeShield's\ntampering analysis capabilities. Meanwhile, we incorporate a Domain Tag-guided\nExplainable Forgery Detection Module (DTE-FDM) and a Multi-modal Forgery\nLocalization Module (MFLM) to address various types of tamper detection\ninterpretation and achieve forgery localization guided by detailed textual\ndescriptions. Extensive experiments demonstrate that FakeShield effectively\ndetects and localizes various tampering techniques, offering an explainable and\nsuperior solution compared to previous IFDL methods.",
        "updated": "2024-10-03 17:59:34 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.02761v1"
    },
    {
        "title": "Loong: Generating Minute-level Long Videos with Autoregressive Language Models",
        "authors": "Yuqing WangTianwei XiongDaquan ZhouZhijie LinYang ZhaoBingyi KangJiashi FengXihui Liu",
        "links": "http://arxiv.org/abs/2410.02757v1",
        "entry_id": "http://arxiv.org/abs/2410.02757v1",
        "pdf_url": "http://arxiv.org/pdf/2410.02757v1",
        "summary": "It is desirable but challenging to generate content-rich long videos in the\nscale of minutes. Autoregressive large language models (LLMs) have achieved\ngreat success in generating coherent and long sequences of tokens in the domain\nof natural language processing, while the exploration of autoregressive LLMs\nfor video generation is limited to generating short videos of several seconds.\nIn this work, we conduct a deep analysis of the challenges that prevent\nautoregressive LLM-based video generators from generating long videos. Based on\nthe observations and analysis, we propose Loong, a new autoregressive LLM-based\nvideo generator that can generate minute-long videos. Specifically, we model\nthe text tokens and video tokens as a unified sequence for autoregressive LLMs\nand train the model from scratch. We propose progressive short-to-long training\nwith a loss re-weighting scheme to mitigate the loss imbalance problem for long\nvideo training. We further investigate inference strategies, including video\ntoken re-encoding and sampling strategies, to diminish error accumulation\nduring inference. Our proposed Loong can be trained on 10-second videos and be\nextended to generate minute-level long videos conditioned on text prompts, as\ndemonstrated by the results. More samples are available at:\nhttps://epiphqny.github.io/Loong-video.",
        "updated": "2024-10-03 17:59:02 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.02757v1"
    }
]