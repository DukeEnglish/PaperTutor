[
    {
        "title": "Flash-Splat: 3D Reflection Removal with Flash Cues and Gaussian Splats",
        "authors": "Mingyang XieHaoming CaiSachin ShahYiran XuBrandon Y. FengJia-Bin HuangChristopher A. Metzler",
        "links": "http://arxiv.org/abs/2410.02764v1",
        "entry_id": "http://arxiv.org/abs/2410.02764v1",
        "pdf_url": "http://arxiv.org/pdf/2410.02764v1",
        "summary": "We introduce a simple yet effective approach for separating transmitted and\nreflected light. Our key insight is that the powerful novel view synthesis\ncapabilities provided by modern inverse rendering methods (e.g.,~3D Gaussian\nsplatting) allow one to perform flash/no-flash reflection separation using\nunpaired measurements -- this relaxation dramatically simplifies image\nacquisition over conventional paired flash/no-flash reflection separation\nmethods. Through extensive real-world experiments, we demonstrate our method,\nFlash-Splat, accurately reconstructs both transmitted and reflected scenes in\n3D. Our method outperforms existing 3D reflection separation methods, which do\nnot leverage illumination control, by a large margin. Our project webpage is at\nhttps://flash-splat.github.io/.",
        "updated": "2024-10-03 17:59:59 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.02764v1"
    },
    {
        "title": "Vinoground: Scrutinizing LMMs over Dense Temporal Reasoning with Short Videos",
        "authors": "Jianrui ZhangMu CaiYong Jae Lee",
        "links": "http://arxiv.org/abs/2410.02763v1",
        "entry_id": "http://arxiv.org/abs/2410.02763v1",
        "pdf_url": "http://arxiv.org/pdf/2410.02763v1",
        "summary": "There has been growing sentiment recently that modern large multimodal models\n(LMMs) have addressed most of the key challenges related to short video\ncomprehension. As a result, both academia and industry are gradually shifting\ntheir attention towards the more complex challenges posed by understanding\nlong-form videos. However, is this really the case? Our studies indicate that\nLMMs still lack many fundamental reasoning capabilities even when dealing with\nshort videos. We introduce Vinoground, a temporal counterfactual LMM evaluation\nbenchmark encompassing 1000 short and natural video-caption pairs. We\ndemonstrate that existing LMMs severely struggle to distinguish temporal\ndifferences between different actions and object transformations. For example,\nthe best model GPT-4o only obtains ~50% on our text and video scores, showing a\nlarge gap compared to the human baseline of ~90%. All open-source multimodal\nmodels and CLIP-based models perform much worse, producing mostly random chance\nperformance. Through this work, we shed light onto the fact that temporal\nreasoning in short videos is a problem yet to be fully solved. The dataset and\nevaluation code are available at https://vinoground.github.io.",
        "updated": "2024-10-03 17:59:58 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.02763v1"
    },
    {
        "title": "Interpreting and Editing Vision-Language Representations to Mitigate Hallucinations",
        "authors": "Nick JiangAnish KachinthayaSuzie PetrykYossi Gandelsman",
        "links": "http://arxiv.org/abs/2410.02762v1",
        "entry_id": "http://arxiv.org/abs/2410.02762v1",
        "pdf_url": "http://arxiv.org/pdf/2410.02762v1",
        "summary": "We investigate the internal representations of vision-language models (VLMs)\nto address hallucinations, a persistent challenge despite advances in model\nsize and training. We project VLMs' internal image representations to their\nlanguage vocabulary and observe more confident output probabilities on real\nobjects than hallucinated objects. We additionally use these output\nprobabilities to spatially localize real objects. Building on this approach, we\nintroduce a knowledge erasure algorithm that removes hallucinations by linearly\northogonalizing image features with respect to hallucinated object features. We\nshow that targeted edits to a model's latent representations can reduce\nhallucinations by up to 25.7% on the COCO2014 dataset while preserving\nperformance. Our findings demonstrate how a deeper understanding of VLMs'\nlatent representations can enhance reliability and enable novel capabilities,\nsuch as zero-shot segmentation.",
        "updated": "2024-10-03 17:59:57 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.02762v1"
    },
    {
        "title": "Erasing Conceptual Knowledge from Language Models",
        "authors": "Rohit GandikotaSheridan FeuchtSamuel MarksDavid Bau",
        "links": "http://arxiv.org/abs/2410.02760v1",
        "entry_id": "http://arxiv.org/abs/2410.02760v1",
        "pdf_url": "http://arxiv.org/pdf/2410.02760v1",
        "summary": "Concept erasure in language models has traditionally lacked a comprehensive\nevaluation framework, leading to incomplete assessments of effectiveness of\nerasure methods. We propose an evaluation paradigm centered on three critical\ncriteria: innocence (complete knowledge removal), seamlessness (maintaining\nconditional fluent generation), and specificity (preserving unrelated task\nperformance). Our evaluation metrics naturally motivate the development of\nErasure of Language Memory (ELM), a new method designed to address all three\ndimensions. ELM employs targeted low-rank updates to alter output distributions\nfor erased concepts while preserving overall model capabilities including\nfluency when prompted for an erased concept. We demonstrate ELM's efficacy on\nbiosecurity, cybersecurity, and literary domain erasure tasks. Comparative\nanalysis shows that ELM achieves superior performance across our proposed\nmetrics, including near-random scores on erased topic assessments, generation\nfluency, maintained accuracy on unrelated benchmarks, and robustness under\nadversarial attacks. Our code, data, and trained models are available at\nhttps://elm.baulab.info",
        "updated": "2024-10-03 17:59:30 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.02760v1"
    },
    {
        "title": "Forecasting Smog Clouds With Deep Learning",
        "authors": "Valentijn OldenburgJuan Cardenas-CartagenaMatias Valdenegro-Toro",
        "links": "http://arxiv.org/abs/2410.02759v1",
        "entry_id": "http://arxiv.org/abs/2410.02759v1",
        "pdf_url": "http://arxiv.org/pdf/2410.02759v1",
        "summary": "In this proof-of-concept study, we conduct multivariate timeseries\nforecasting for the concentrations of nitrogen dioxide (NO2), ozone (O3), and\n(fine) particulate matter (PM10 & PM2.5) with meteorological covariates between\ntwo locations using various deep learning models, with a focus on long\nshort-term memory (LSTM) and gated recurrent unit (GRU) architectures. In\nparticular, we propose an integrated, hierarchical model architecture inspired\nby air pollution dynamics and atmospheric science that employs multi-task\nlearning and is benchmarked by unidirectional and fully-connected models.\nResults demonstrate that, above all, the hierarchical GRU proves itself as a\ncompetitive and efficient method for forecasting the concentration of\nsmog-related pollutants.",
        "updated": "2024-10-03 17:59:13 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.02759v1"
    }
]