[
    {
        "title": "Vinoground: Scrutinizing LMMs over Dense Temporal Reasoning with Short Videos",
        "authors": "Jianrui ZhangMu CaiYong Jae Lee",
        "links": "http://arxiv.org/abs/2410.02763v1",
        "entry_id": "http://arxiv.org/abs/2410.02763v1",
        "pdf_url": "http://arxiv.org/pdf/2410.02763v1",
        "summary": "There has been growing sentiment recently that modern large multimodal models\n(LMMs) have addressed most of the key challenges related to short video\ncomprehension. As a result, both academia and industry are gradually shifting\ntheir attention towards the more complex challenges posed by understanding\nlong-form videos. However, is this really the case? Our studies indicate that\nLMMs still lack many fundamental reasoning capabilities even when dealing with\nshort videos. We introduce Vinoground, a temporal counterfactual LMM evaluation\nbenchmark encompassing 1000 short and natural video-caption pairs. We\ndemonstrate that existing LMMs severely struggle to distinguish temporal\ndifferences between different actions and object transformations. For example,\nthe best model GPT-4o only obtains ~50% on our text and video scores, showing a\nlarge gap compared to the human baseline of ~90%. All open-source multimodal\nmodels and CLIP-based models perform much worse, producing mostly random chance\nperformance. Through this work, we shed light onto the fact that temporal\nreasoning in short videos is a problem yet to be fully solved. The dataset and\nevaluation code are available at https://vinoground.github.io.",
        "updated": "2024-10-03 17:59:58 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.02763v1"
    },
    {
        "title": "FakeShield: Explainable Image Forgery Detection and Localization via Multi-modal Large Language Models",
        "authors": "Zhipei XuXuanyu ZhangRunyi LiZecheng TangQing HuangJian Zhang",
        "links": "http://arxiv.org/abs/2410.02761v1",
        "entry_id": "http://arxiv.org/abs/2410.02761v1",
        "pdf_url": "http://arxiv.org/pdf/2410.02761v1",
        "summary": "The rapid development of generative AI is a double-edged sword, which not\nonly facilitates content creation but also makes image manipulation easier and\nmore difficult to detect. Although current image forgery detection and\nlocalization (IFDL) methods are generally effective, they tend to face two\nchallenges: \\textbf{1)} black-box nature with unknown detection principle,\n\\textbf{2)} limited generalization across diverse tampering methods (e.g.,\nPhotoshop, DeepFake, AIGC-Editing). To address these issues, we propose the\nexplainable IFDL task and design FakeShield, a multi-modal framework capable of\nevaluating image authenticity, generating tampered region masks, and providing\na judgment basis based on pixel-level and image-level tampering clues.\nAdditionally, we leverage GPT-4o to enhance existing IFDL datasets, creating\nthe Multi-Modal Tamper Description dataSet (MMTD-Set) for training FakeShield's\ntampering analysis capabilities. Meanwhile, we incorporate a Domain Tag-guided\nExplainable Forgery Detection Module (DTE-FDM) and a Multi-modal Forgery\nLocalization Module (MFLM) to address various types of tamper detection\ninterpretation and achieve forgery localization guided by detailed textual\ndescriptions. Extensive experiments demonstrate that FakeShield effectively\ndetects and localizes various tampering techniques, offering an explainable and\nsuperior solution compared to previous IFDL methods.",
        "updated": "2024-10-03 17:59:34 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.02761v1"
    },
    {
        "title": "CriSPO: Multi-Aspect Critique-Suggestion-guided Automatic Prompt Optimization for Text Generation",
        "authors": "Han HeQianchu LiuLei XuChaitanya ShivadeYi ZhangSundararajan SrinivasanKatrin Kirchhoff",
        "links": "http://arxiv.org/abs/2410.02748v1",
        "entry_id": "http://arxiv.org/abs/2410.02748v1",
        "pdf_url": "http://arxiv.org/pdf/2410.02748v1",
        "summary": "Large language models (LLMs) can generate fluent summaries across domains\nusing prompting techniques, reducing the need to train models for summarization\napplications. However, crafting effective prompts that guide LLMs to generate\nsummaries with the appropriate level of detail and writing style remains a\nchallenge. In this paper, we explore the use of salient information extracted\nfrom the source document to enhance summarization prompts. We show that adding\nkeyphrases in prompts can improve ROUGE F1 and recall, making the generated\nsummaries more similar to the reference and more complete. The number of\nkeyphrases can control the precision-recall trade-off. Furthermore, our\nanalysis reveals that incorporating phrase-level salient information is\nsuperior to word- or sentence-level. However, the impact on hallucination is\nnot universally positive across LLMs. To conduct this analysis, we introduce\nKeyphrase Signal Extractor (CriSPO), a lightweight model that can be finetuned\nto extract salient keyphrases. By using CriSPO, we achieve consistent ROUGE\nimprovements across datasets and open-weight and proprietary LLMs without any\nLLM customization. Our findings provide insights into leveraging salient\ninformation in building prompt-based summarization systems.",
        "updated": "2024-10-03 17:57:01 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.02748v1"
    },
    {
        "title": "Neutral residues: revisiting adapters for model extension",
        "authors": "Franck Signe TallaHerve JegouEdouard Grave",
        "links": "http://arxiv.org/abs/2410.02744v1",
        "entry_id": "http://arxiv.org/abs/2410.02744v1",
        "pdf_url": "http://arxiv.org/pdf/2410.02744v1",
        "summary": "We address the problem of extending a pretrained large language model to a\nnew domain that was not seen at training time, like adding a language for which\nthe original model has seen no or little training data. Popular solutions like\nfine-tuning or low-rank adaptation are successful at domain adaptation, but\nformally they do not add any extra capacity and degrade the performance in the\noriginal domain.\n  Our paper analyzes this extension problem under three angles: data,\narchitecture and training procedure, which are advantageously considered\njointly. In particular, we improve adapters and make it possible to learn an\nentire new language while ensuring that the output of the neural network is\nalmost unchanged in the original domain. For this purpose, we modify the new\nresidual blocks in a way that leads each new residual block to output\nnear-zeros in the original domain.\n  This solution of neutral residues, which borrows architectural components\nfrom mixture of experts, is effective: with only 20% extra learnable weights\ncompared to an original model trained on English, we get results that are\nsignificantly better than concurrent approaches (fine-tuning, low-rank or\nvanilla adapters) in terms of the trade-off between learning a new language and\nnot forgetting English.",
        "updated": "2024-10-03 17:55:17 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.02744v1"
    },
    {
        "title": "Salient Information Prompting to Steer Content in Prompt-based Abstractive Summarization",
        "authors": "Lei XuMohammed Asad KarimSaket DingliwalAparna Elangovan",
        "links": "http://arxiv.org/abs/2410.02741v1",
        "entry_id": "http://arxiv.org/abs/2410.02741v1",
        "pdf_url": "http://arxiv.org/pdf/2410.02741v1",
        "summary": "Large language models (LLMs) can generate fluent summaries across domains\nusing prompting techniques, reducing the need to train models for summarization\napplications. However, crafting effective prompts that guide LLMs to generate\nsummaries with the appropriate level of detail and writing style remains a\nchallenge. In this paper, we explore the use of salient information extracted\nfrom the source document to enhance summarization prompts. We show that adding\nkeyphrases in prompts can improve ROUGE F1 and recall, making the generated\nsummaries more similar to the reference and more complete. The number of\nkeyphrases can control the precision-recall trade-off. Furthermore, our\nanalysis reveals that incorporating phrase-level salient information is\nsuperior to word- or sentence-level. However, the impact on hallucination is\nnot universally positive across LLMs. To conduct this analysis, we introduce\nKeyphrase Signal Extractor (SigExt), a lightweight model that can be finetuned\nto extract salient keyphrases. By using SigExt, we achieve consistent ROUGE\nimprovements across datasets and open-weight and proprietary LLMs without any\nLLM customization. Our findings provide insights into leveraging salient\ninformation in building prompt-based summarization systems.",
        "updated": "2024-10-03 17:54:56 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.02741v1"
    }
]